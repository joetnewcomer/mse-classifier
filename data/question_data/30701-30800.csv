,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Why is a random variable called so despite being a function?,Why is a random variable called so despite being a function?,,"According to my knowledge, its a function $P(X)$ which includes all the possible outcomes a random event.","According to my knowledge, its a function $P(X)$ which includes all the possible outcomes a random event.",,"['probability', 'terminology']"
1,What equity is necessary to offer the doubling cube in Backgammon (dice game),What equity is necessary to offer the doubling cube in Backgammon (dice game),,"Edit: This question is a lot shorter than it is. Don't get intimidated. If you know backgammon, just skip to question 2. In Backgammon, each game is played for one point (or one dollar) between two players. There is a die, called the doubling cube , which has the numbers $2, 4, 8, ...$, in the middle of the board (it is not 'owned' by anyone). The players take turns rolling two regular dice (not the doubling cube) and moving. But before each roll, a player can 'offer the cube' (or 'offer to double', 'double', etc.) which is basically saying ""Hey, why don't we play this game for 2 points"". The other player can drop , or refuse the cube, and lose one point, or may accept , or take , the cube, in which case the game continues for twice as many points as before. A player's equity in the game is the probability that he'll win a cubeless game, where cubeless means neither player can offer the cube (or a one point game). (For backgammon players who know the rules, I'm ignoring gammons and backgammons, so the equity equals the probability of winning. Edit: As @Henning Makholm's first answer indicates, I also do not want to include the equity of owning the doubling cube. I have two questions, but I know the answer to the first one and I think I'm calculating it right. 1) What equity does the player receiving the cube require in order to accept it? Answer, I'm told, is $.25$? The receiving player will accept the double when the expected value of taking it is greater than the expected value of dropping (which automatically loses him $1$ point). $p$ is the probability (equals equity) of the receiving player winning (are you guys following all this?). $E(take) \ge E(drop) \\ 2p-2(1-p) \ge -1 \\p > .25$ I'm nearly certain that's correct, so 2) What equity is required for a player to offer the cube (offer to double the game's stakes)? How is that calculated? We don't know whether the cube's recipient will accept or not. I start the same as question 1: The giver will double when his expected value of doubling is greater than his EV of not doubing (duh!). If $EV(rolling)$ is $p-(1-p)$, and $EV(doubling)$ is $2p-2(1-p)$, then $E(doubling) > E(rolling) \\ 2p-2(1-p) > p-(1-p) \\ p > .5$ Which can't possibly be correct. While I'm not BG expert, I did used to play for (small amounts) of money in NYC. There is no way in heck that I would double with 51% chances. OK, that's all I got. How do we figure this out? Thanks.","Edit: This question is a lot shorter than it is. Don't get intimidated. If you know backgammon, just skip to question 2. In Backgammon, each game is played for one point (or one dollar) between two players. There is a die, called the doubling cube , which has the numbers $2, 4, 8, ...$, in the middle of the board (it is not 'owned' by anyone). The players take turns rolling two regular dice (not the doubling cube) and moving. But before each roll, a player can 'offer the cube' (or 'offer to double', 'double', etc.) which is basically saying ""Hey, why don't we play this game for 2 points"". The other player can drop , or refuse the cube, and lose one point, or may accept , or take , the cube, in which case the game continues for twice as many points as before. A player's equity in the game is the probability that he'll win a cubeless game, where cubeless means neither player can offer the cube (or a one point game). (For backgammon players who know the rules, I'm ignoring gammons and backgammons, so the equity equals the probability of winning. Edit: As @Henning Makholm's first answer indicates, I also do not want to include the equity of owning the doubling cube. I have two questions, but I know the answer to the first one and I think I'm calculating it right. 1) What equity does the player receiving the cube require in order to accept it? Answer, I'm told, is $.25$? The receiving player will accept the double when the expected value of taking it is greater than the expected value of dropping (which automatically loses him $1$ point). $p$ is the probability (equals equity) of the receiving player winning (are you guys following all this?). $E(take) \ge E(drop) \\ 2p-2(1-p) \ge -1 \\p > .25$ I'm nearly certain that's correct, so 2) What equity is required for a player to offer the cube (offer to double the game's stakes)? How is that calculated? We don't know whether the cube's recipient will accept or not. I start the same as question 1: The giver will double when his expected value of doubling is greater than his EV of not doubing (duh!). If $EV(rolling)$ is $p-(1-p)$, and $EV(doubling)$ is $2p-2(1-p)$, then $E(doubling) > E(rolling) \\ 2p-2(1-p) > p-(1-p) \\ p > .5$ Which can't possibly be correct. While I'm not BG expert, I did used to play for (small amounts) of money in NYC. There is no way in heck that I would double with 51% chances. OK, that's all I got. How do we figure this out? Thanks.",,"['probability', 'recreational-mathematics', 'dice']"
2,Union of two events is at least as likely as the product of the events' probabilities [closed],Union of two events is at least as likely as the product of the events' probabilities [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 21 days ago . Improve this question If $A$ and $B$ aren't disjoint and $A \cup B \neq \Omega$ , then is $P(A \cup B) \geq P(A)P(B)$ ? My only idea is to use $P(A \cup B) = P(A) + P(B) - P(A \cap B)$ but there's a minus in front of the intersection and the events don't have to be independent.","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 21 days ago . Improve this question If and aren't disjoint and , then is ? My only idea is to use but there's a minus in front of the intersection and the events don't have to be independent.",A B A \cup B \neq \Omega P(A \cup B) \geq P(A)P(B) P(A \cup B) = P(A) + P(B) - P(A \cap B),['probability']
3,How do I solve a probability problem involving permutations and having two steps?,How do I solve a probability problem involving permutations and having two steps?,,"The problem: A man spends 7 nights in a city.    He has a list of the 8 best Italian restaurants and the 9 best Chinese restaurants. How many ways can he eat 7 meals at these restaurants, assuming a different restaurant each night and he wishes to alternate between Italian and Chinese food. I first tried using permutations using $n=17$ and $r=7$. The result: $98.017.920$. Then knowing I had to do something with alternating the restaurants and assuming that he starts with an Italian restaurant, there would be 4 Italian and 3 Chinese restaurants. So I used permutations for Ital. $n=8,r=4$ and Chin. $n=9,r=3$ for $1680$ and $504$ respectively. I divided the product but I know that is not the answer. I don't have a good grasp of when to use permutations or combinations. Any help in clearing this up would be greatly appreciated. Thank you","The problem: A man spends 7 nights in a city.    He has a list of the 8 best Italian restaurants and the 9 best Chinese restaurants. How many ways can he eat 7 meals at these restaurants, assuming a different restaurant each night and he wishes to alternate between Italian and Chinese food. I first tried using permutations using $n=17$ and $r=7$. The result: $98.017.920$. Then knowing I had to do something with alternating the restaurants and assuming that he starts with an Italian restaurant, there would be 4 Italian and 3 Chinese restaurants. So I used permutations for Ital. $n=8,r=4$ and Chin. $n=9,r=3$ for $1680$ and $504$ respectively. I divided the product but I know that is not the answer. I don't have a good grasp of when to use permutations or combinations. Any help in clearing this up would be greatly appreciated. Thank you",,['probability']
4,UK Lottery Odds Calculation Error,UK Lottery Odds Calculation Error,,"I found the probability topic in stats and mechanics to be very interesting, and I attempted to try using it to calculate the odds of winning the UK National Lottery, but failed. My calculation was (1/59*1/58*1/57*1/56*1/55*1/54). The reason was that in the NL there are 6 balls dropped, and the possible outcomes range from 1 to 59. I reasoned that since all 6 need to match, I could assume that each outcome could be treated as an isolated selection, and that my first ball match odds were 1/59 as a result, then if the first ball matches (which it must), the next is 1/58 and so on. The odds I calculated were orders of magnitude less likely than the correct value. What is wrong with my attempt, and why is the correct formula quoted as ""59!/(6!*(59-6)!)""?","I found the probability topic in stats and mechanics to be very interesting, and I attempted to try using it to calculate the odds of winning the UK National Lottery, but failed. My calculation was (1/59*1/58*1/57*1/56*1/55*1/54). The reason was that in the NL there are 6 balls dropped, and the possible outcomes range from 1 to 59. I reasoned that since all 6 need to match, I could assume that each outcome could be treated as an isolated selection, and that my first ball match odds were 1/59 as a result, then if the first ball matches (which it must), the next is 1/58 and so on. The odds I calculated were orders of magnitude less likely than the correct value. What is wrong with my attempt, and why is the correct formula quoted as ""59!/(6!*(59-6)!)""?",,"['probability', 'statistics', 'lotteries']"
5,The gambler makes 100 bets and wins 10. How much money does he have at the end?,The gambler makes 100 bets and wins 10. How much money does he have at the end?,,"A gambler who makes 100 bets of $1, each at payoff odds of 8 to 1.   He wins 10 of these bets and loses 90. How many dollars has the gambler gained overall? I don't seem to understand what ""odds of 8 to 1"" means. Can someone please explain this to me?","A gambler who makes 100 bets of $1, each at payoff odds of 8 to 1.   He wins 10 of these bets and loses 90. How many dollars has the gambler gained overall? I don't seem to understand what ""odds of 8 to 1"" means. Can someone please explain this to me?",,"['probability', 'algebra-precalculus', 'terminology', 'word-problem', 'gambling']"
6,What is the expected number of red apples left when all the green apples are picked?,What is the expected number of red apples left when all the green apples are picked?,,We have 4 green apples and 60 red apples. Each time we pick one out without replacement. Then what is the expected number of red apples left when all 4 green apples are picked?,We have 4 green apples and 60 red apples. Each time we pick one out without replacement. Then what is the expected number of red apples left when all 4 green apples are picked?,,"['probability', 'discrete-mathematics']"
7,Probability of guessing a PIN-code,Probability of guessing a PIN-code,,"A friend and I recently talked about this problem: Say my friend feels a little adventurous and tells me that exactly three of four digits of his PIN-code are the same, what is the probability that I will guess it in three tries? At first I thought this shouldn't be too difficult to count, but the digit restriction threw me off. Essentially I want to count how many possible PIN-codes there are with the restriction that $3$ of $4$ digits are the same. I tried thinking in terms of using sums, but I got stuck. I actually ended up making a quick MATLAB-script that computed the number of possible PIN-codes using a brute force method. Assuming that my script is correct there are $360$ codes that abide by this restriction out of a total of $10^4=10\hspace{4 px}000$ possible PIN-codes. Using this it is easy to calculate the rest, but I am now wondering how one might go about this in a more elegant way. A PIN-code is a $4$-digit number where the possible digits are $0,1,2,...,9$. So for my question two examples of possible codes are $3383$ and $2999$. Let's assume that there are no further restrictions, although in reality there likely are, and that each digit is equally likely. It is important to note that I do not know if it is $0,1,...,8$, or $9$ that appears three times. This question is not homework or anything, it is really just for curiosity. Thanks for any help! (By the way I saw this question: Combinatorics and Probability Problem but it did not help me.) EDIT: I made an error in my script. Updated.","A friend and I recently talked about this problem: Say my friend feels a little adventurous and tells me that exactly three of four digits of his PIN-code are the same, what is the probability that I will guess it in three tries? At first I thought this shouldn't be too difficult to count, but the digit restriction threw me off. Essentially I want to count how many possible PIN-codes there are with the restriction that $3$ of $4$ digits are the same. I tried thinking in terms of using sums, but I got stuck. I actually ended up making a quick MATLAB-script that computed the number of possible PIN-codes using a brute force method. Assuming that my script is correct there are $360$ codes that abide by this restriction out of a total of $10^4=10\hspace{4 px}000$ possible PIN-codes. Using this it is easy to calculate the rest, but I am now wondering how one might go about this in a more elegant way. A PIN-code is a $4$-digit number where the possible digits are $0,1,2,...,9$. So for my question two examples of possible codes are $3383$ and $2999$. Let's assume that there are no further restrictions, although in reality there likely are, and that each digit is equally likely. It is important to note that I do not know if it is $0,1,...,8$, or $9$ that appears three times. This question is not homework or anything, it is really just for curiosity. Thanks for any help! (By the way I saw this question: Combinatorics and Probability Problem but it did not help me.) EDIT: I made an error in my script. Updated.",,"['probability', 'combinatorics']"
8,Sum of random numbers is divisible by $10$,Sum of random numbers is divisible by,10,"Suppose that $15$ three-digit numbers have been randomly chosen and we are about to add them. What is the probability that the sum would be divisible by $10$? If there were only two or three random numbers we could enumerate the cases in which last digit comes out to be $0$ and hence calculate probability but for $15$ numbers that seems messy so is there a smart way to do it Edit: I have tried another approach which finds the possible sums of $15$ three-digit numbers and then find the sums divisible by $10$ in the same range. So I get: Number of Sums divisible by $10$ in $[1500,14985]=1349$ Total Number of Sums in $[1500,14985]=13486$ And then $P=\frac{1349}{13486}$, but as a comment suggests that this approach does not cater for the fact that a sum may be reached in a multiple of ways. So how can we cater for this fact? I am guessing may be multinomial can be of help ?","Suppose that $15$ three-digit numbers have been randomly chosen and we are about to add them. What is the probability that the sum would be divisible by $10$? If there were only two or three random numbers we could enumerate the cases in which last digit comes out to be $0$ and hence calculate probability but for $15$ numbers that seems messy so is there a smart way to do it Edit: I have tried another approach which finds the possible sums of $15$ three-digit numbers and then find the sums divisible by $10$ in the same range. So I get: Number of Sums divisible by $10$ in $[1500,14985]=1349$ Total Number of Sums in $[1500,14985]=13486$ And then $P=\frac{1349}{13486}$, but as a comment suggests that this approach does not cater for the fact that a sum may be reached in a multiple of ways. So how can we cater for this fact? I am guessing may be multinomial can be of help ?",,"['probability', 'random-variables']"
9,Mutually exclusive events,Mutually exclusive events,,"Working my way through the following problem: Problem Suppose that $E$ and $F$ are mutually exclusive events of an experiment.  Show that if independent trials of this experiment are performed,  then $E$ will occur before $F$ with probability $\frac{ P( E)}{P( E) + P( F)}.$ I have the following come up with the following solution: Solution Since $P( E^c) = P( F)$ Therefore $\frac{ P( E)}{ P( E) + P( F)} = \frac{ P( E)}{ 1 - P( F) + P( F)} = \frac{ P( E)}{ 1} = P( E)$ But I am unsure if I am able to assume $P( E^c) = P( F)$ as a given? As well, I am particularly confused by the answer in the solution manual which makes it's argument as follows: Solution Manual If $E$ and $F$ are mutually exclusive events in an experiment,  then $P( E \cup F) = P( E) + P( F)$ . We desire to compute the probability that $E$ occurs before $F$ , which we will denote by $p$ . To compute $p$ we condition on the three mutually exclusive events $E$ , $F$ , or $(E \cup F )^c$ . This last event are all the outcomes not in $E$ or $F$ . Letting the event $A$ be the event that $E$ occurs before $F$ , we have that $p = P( A|E) P( E) + P( A|F) P(F ) + P( A|(E \cup F )^c) P( (E \cup F )^c)$ $P( A|E) = 1$ $P( A|F) = 0$ $P( A|(E \cup F)^c) = p$ since if neither $E$ or $F$ happen the next experiment will have $E$ before $F$ (and thus event $A$ with probability $p$ ). Thus we have that $p = P( E) + p P( (E \cup F)^c)$ $= P( E) + p (1 − P( E \cup F))$ $= P( E) + p (1 − P( E) − P( F))$ Solving for $p$ gives $p = \frac{ P( E)}{ P( E) + P( F)}$ as we were to show. Specifically his statement since if neither $E$ or $F$ happen the next experiment will have $E$ before $F$ (and thus event $A$ with probability $p$ )","Working my way through the following problem: Problem Suppose that and are mutually exclusive events of an experiment.  Show that if independent trials of this experiment are performed,  then will occur before with probability I have the following come up with the following solution: Solution Since Therefore But I am unsure if I am able to assume as a given? As well, I am particularly confused by the answer in the solution manual which makes it's argument as follows: Solution Manual If and are mutually exclusive events in an experiment,  then . We desire to compute the probability that occurs before , which we will denote by . To compute we condition on the three mutually exclusive events , , or . This last event are all the outcomes not in or . Letting the event be the event that occurs before , we have that since if neither or happen the next experiment will have before (and thus event with probability ). Thus we have that Solving for gives as we were to show. Specifically his statement since if neither or happen the next experiment will have before (and thus event with probability )",E F E F \frac{ P( E)}{P( E) + P( F)}. P( E^c) = P( F) \frac{ P( E)}{ P( E) + P( F)} = \frac{ P( E)}{ 1 - P( F) + P( F)} = \frac{ P( E)}{ 1} = P( E) P( E^c) = P( F) E F P( E \cup F) = P( E) + P( F) E F p p E F (E \cup F )^c E F A E F p = P( A|E) P( E) + P( A|F) P(F ) + P( A|(E \cup F )^c) P( (E \cup F )^c) P( A|E) = 1 P( A|F) = 0 P( A|(E \cup F)^c) = p E F E F A p p = P( E) + p P( (E \cup F)^c) = P( E) + p (1 − P( E \cup F)) = P( E) + p (1 − P( E) − P( F)) p p = \frac{ P( E)}{ P( E) + P( F)} E F E F A p,"['probability', 'probability-theory']"
10,On Martingale betting system,On Martingale betting system,,"I was reading the Martingale betting system on wikipedia and there is something not completely clear to me. The article says at some point However, the gambler's expected value does indeed remain zero because   the small probability that he will suffer a catastrophic loss exactly   balances with his expected gain. It is widely believed that casinos   instituted betting limits specifically to stop Martingale players, but   in reality the assumptions behind the strategy are unsound. Players   using the Martingale system do not have any long-term mathematical   advantage over any other betting system or even randomly placed bets. I don't quite understand this. If you keep doubling, it is true that you might encounter catastrophic losses, but the probability that you get 5 heads in a row is 1/32, quite low, and it decreases to zero exponentially. Thus, to me it seems that it should be rare , assuming that the probability of head is .5, to have to play more than 6/7 rounds in real life.","I was reading the Martingale betting system on wikipedia and there is something not completely clear to me. The article says at some point However, the gambler's expected value does indeed remain zero because   the small probability that he will suffer a catastrophic loss exactly   balances with his expected gain. It is widely believed that casinos   instituted betting limits specifically to stop Martingale players, but   in reality the assumptions behind the strategy are unsound. Players   using the Martingale system do not have any long-term mathematical   advantage over any other betting system or even randomly placed bets. I don't quite understand this. If you keep doubling, it is true that you might encounter catastrophic losses, but the probability that you get 5 heads in a row is 1/32, quite low, and it decreases to zero exponentially. Thus, to me it seems that it should be rare , assuming that the probability of head is .5, to have to play more than 6/7 rounds in real life.",,"['probability', 'statistics']"
11,"Suppose $X_n\sim \text{Poisson}(n)$. Show that $\sqrt{X_n}-\sqrt{n}\overset{d}\to \mathcal N(0,1/4)$.",Suppose . Show that .,"X_n\sim \text{Poisson}(n) \sqrt{X_n}-\sqrt{n}\overset{d}\to \mathcal N(0,1/4)","Suppose $X_n\sim \text{Poisson}(n)$. Show that $\sqrt{X_n}-\sqrt{n}\overset{d}\to \mathcal N(0,1/4)$. I already know that $(X_n-n)/\sqrt{n}\overset{d}\to \mathcal N(0,1)$. How to do next to go through the proof?","Suppose $X_n\sim \text{Poisson}(n)$. Show that $\sqrt{X_n}-\sqrt{n}\overset{d}\to \mathcal N(0,1/4)$. I already know that $(X_n-n)/\sqrt{n}\overset{d}\to \mathcal N(0,1)$. How to do next to go through the proof?",,"['probability', 'probability-theory', 'measure-theory', 'statistics', 'probability-distributions']"
12,"If an event $A$ is independent from $B$ and $C$, is A also independent from $B \cap C$? [closed]","If an event  is independent from  and , is A also independent from ? [closed]",A B C B \cap C,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question $A$ and $B$ are independent. $A$ and $C$ are independent. Are $A$ and $B \cap C$ also independent?","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question $A$ and $B$ are independent. $A$ and $C$ are independent. Are $A$ and $B \cap C$ also independent?",,"['probability', 'independence']"
13,probability that a sum of 3 is rolled before a sum of 5 is rolled in a sequence of rolls of the dice from a four sided die.,probability that a sum of 3 is rolled before a sum of 5 is rolled in a sequence of rolls of the dice from a four sided die.,,I am stuck at this problem- A pair of four-sided dice is rolled and the sum is determined.   What is the probability that a sum of 3 is rolled before a sum of 5 is rolled   in a sequence of rolls of the dice? What I tried- Let $A=$ sum of $3$; Let $B=$ sum of 5; then $P(A \mid \text{not}~B)=$ i.e probability of A given that B has not happened. $P(A \mid not B)= \dfrac{P(A~\text{and not}~B)}{P(\text{not}~B)}$; But using this approach I am not getting answer.,I am stuck at this problem- A pair of four-sided dice is rolled and the sum is determined.   What is the probability that a sum of 3 is rolled before a sum of 5 is rolled   in a sequence of rolls of the dice? What I tried- Let $A=$ sum of $3$; Let $B=$ sum of 5; then $P(A \mid \text{not}~B)=$ i.e probability of A given that B has not happened. $P(A \mid not B)= \dfrac{P(A~\text{and not}~B)}{P(\text{not}~B)}$; But using this approach I am not getting answer.,,"['probability', 'permutations', 'bayes-theorem']"
14,Moment generating function of a gamma distribution,Moment generating function of a gamma distribution,,"If I have a variable $X$ that has a gamma distribution with parameters $s$ and $\lambda$, what is its momment generating function. I know that it is $\int_0^\infty e^{tx}\frac{1}{\Gamma(s)}\lambda^sx^{s-1} e^{-x\lambda}dx$ and the final answer should be $(\frac{\lambda}{\lambda-t})^s$, but how can i compute this? P.S. I know that there are other questions on this site about the MGF of the gamma distibution, but none of those use this specific definition for the density function of a gamma distribution. And I would like to see it with this one. Thanks a lot!","If I have a variable $X$ that has a gamma distribution with parameters $s$ and $\lambda$, what is its momment generating function. I know that it is $\int_0^\infty e^{tx}\frac{1}{\Gamma(s)}\lambda^sx^{s-1} e^{-x\lambda}dx$ and the final answer should be $(\frac{\lambda}{\lambda-t})^s$, but how can i compute this? P.S. I know that there are other questions on this site about the MGF of the gamma distibution, but none of those use this specific definition for the density function of a gamma distribution. And I would like to see it with this one. Thanks a lot!",,"['probability', 'moment-generating-functions']"
15,Closed form equation for win percentage of two battling armies,Closed form equation for win percentage of two battling armies,,"I was pondering a battle mechanic for a board game that is similar to, but simpler than battling armies in Risk.  Consider one army of size X and a second army of size Y.  The battle occurs by creating pairs of one-on-one fights where the two combatants each have 50% probability of winning.  The pairs of fights continue until one army is defeated. For Example, a 2 vs 3 battle could have the following outcomes for the first army, when the first army wins: 1. W W W 2. L W W W 3. W L W W 4. W W L W Note that the final fight must be a win, all outcomes must have 3 wins total (the size of the second army, Y), and there cannot be more than 1 loss (the size of the first army, X, minus 1). I'm having trouble finding a closed form equation that gives the probability of the first army winning the battle where the sizes of the armies are X and Y. If that's easy, how about if the probability of winning the battle if an individual fight is not 50% but rather probability P? Edit: just wanted to add a 3 vs 2 example as well: 1. W W 2. L W W 3. W L W 4. L L W W 5. L W L W 6. W L L W Here's the 2 vs 2 case, which produces a 50% probability: 1. W W 2. L W W 3. W L W","I was pondering a battle mechanic for a board game that is similar to, but simpler than battling armies in Risk.  Consider one army of size X and a second army of size Y.  The battle occurs by creating pairs of one-on-one fights where the two combatants each have 50% probability of winning.  The pairs of fights continue until one army is defeated. For Example, a 2 vs 3 battle could have the following outcomes for the first army, when the first army wins: 1. W W W 2. L W W W 3. W L W W 4. W W L W Note that the final fight must be a win, all outcomes must have 3 wins total (the size of the second army, Y), and there cannot be more than 1 loss (the size of the first army, X, minus 1). I'm having trouble finding a closed form equation that gives the probability of the first army winning the battle where the sizes of the armies are X and Y. If that's easy, how about if the probability of winning the battle if an individual fight is not 50% but rather probability P? Edit: just wanted to add a 3 vs 2 example as well: 1. W W 2. L W W 3. W L W 4. L L W W 5. L W L W 6. W L L W Here's the 2 vs 2 case, which produces a 50% probability: 1. W W 2. L W W 3. W L W",,"['probability', 'statistics']"
16,What is the probability you guess the number I am thinking of?,What is the probability you guess the number I am thinking of?,,"Probability is defined as the likely number of outcomes over all total outcomes.  In this case, 1 over infinity; which would equate to zero. But, there is a chance you can guess the number I am thinking of. Furthermore, would it depend on the number of guesses you have? Let's say you have 2 guesses? 100 guesses? Infinity guesses? I'm looking for any insight as to the answer to this problem whatsoever.  Is there even a way to answer this question? Let me know. Thanks!","Probability is defined as the likely number of outcomes over all total outcomes.  In this case, 1 over infinity; which would equate to zero. But, there is a chance you can guess the number I am thinking of. Furthermore, would it depend on the number of guesses you have? Let's say you have 2 guesses? 100 guesses? Infinity guesses? I'm looking for any insight as to the answer to this problem whatsoever.  Is there even a way to answer this question? Let me know. Thanks!",,"['probability', 'measure-theory', 'probability-theory']"
17,Benford's law and voting in Georgia,Benford's law and voting in Georgia,,"With Benford's law ""the leading digits of the number found in real-world data sets"" should make sense.  But this video https://www.youtube.com/watch?v=DoF3WS42w3M&ab_channel=RobertA.Bonavito%2CCPA claims that by applying Benford's law they can prove electoral fraud. He claims that since Benford's law is ""broken"" in these graphs, it appears that there has been fraud committed, but I wonder if the artificiality of breaking things into counties and only having 156 of them violates the ""naturally occuring"" idea that is the foundation of Benford's Law. I am curious why Benford's law does not seem to apply here.","With Benford's law ""the leading digits of the number found in real-world data sets"" should make sense.  But this video https://www.youtube.com/watch?v=DoF3WS42w3M&ab_channel=RobertA.Bonavito%2CCPA claims that by applying Benford's law they can prove electoral fraud. He claims that since Benford's law is ""broken"" in these graphs, it appears that there has been fraud committed, but I wonder if the artificiality of breaking things into counties and only having 156 of them violates the ""naturally occuring"" idea that is the foundation of Benford's Law. I am curious why Benford's law does not seem to apply here.",,['probability']
18,Why use A|BC and not ABC?,Why use A|BC and not ABC?,,"Currently I'm reading Probability Theory The Logic of Science and there it's not really clear for me what exactly $A|BC$ means. So I have two questions: Is this a general notation? Is $A|BC$ equal to $ABC$? If it is — that means it's just for the sake of order/consecution, like $A(BC)$ (but according to the book it's not so)?","Currently I'm reading Probability Theory The Logic of Science and there it's not really clear for me what exactly $A|BC$ means. So I have two questions: Is this a general notation? Is $A|BC$ equal to $ABC$? If it is — that means it's just for the sake of order/consecution, like $A(BC)$ (but according to the book it's not so)?",,"['probability', 'probability-theory', 'notation']"
19,Expected value of the absolute value of the difference between two independent uniform random variables? [closed],Expected value of the absolute value of the difference between two independent uniform random variables? [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question I am trying to calculate the expected value of the absolute value of the difference between two independent uniform random variables. Let $X_1\sim\operatorname{Uniform}(0, 2)$ and $X_2\sim\operatorname{Uniform}(0, 2)$ and $X_1$ and $X_2$ are independent. I want to calculate $\operatorname E \left[|X_1 - X_2|\right]$. Can anyone please help?","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question I am trying to calculate the expected value of the absolute value of the difference between two independent uniform random variables. Let $X_1\sim\operatorname{Uniform}(0, 2)$ and $X_2\sim\operatorname{Uniform}(0, 2)$ and $X_1$ and $X_2$ are independent. I want to calculate $\operatorname E \left[|X_1 - X_2|\right]$. Can anyone please help?",,"['probability', 'expected-value', 'uniform-distribution']"
20,"$12$ Identical balls can be placed into $3$ identical boxes,","Identical balls can be placed into  identical boxes,",12 3,"$12$ Identical balls can be placed into $3$ identical boxes, Then find probability that one of the boxes contain exactly  $3$ balls. $\bf{My\; Try::}$ First we select $1$ bag out of $3$ and then put $3$ balls into that bag and then put remaining balls into $2$ bag. Which can be done by $\displaystyle \binom {3}{1}\times 1 \times \binom{1}{1}\times 1 = 3$ bcz here balls are identical . So we can arrange by only one ways. But my answer is wrong. plz help me , How can I get correct answer. Thanks","$12$ Identical balls can be placed into $3$ identical boxes, Then find probability that one of the boxes contain exactly  $3$ balls. $\bf{My\; Try::}$ First we select $1$ bag out of $3$ and then put $3$ balls into that bag and then put remaining balls into $2$ bag. Which can be done by $\displaystyle \binom {3}{1}\times 1 \times \binom{1}{1}\times 1 = 3$ bcz here balls are identical . So we can arrange by only one ways. But my answer is wrong. plz help me , How can I get correct answer. Thanks",,"['probability', 'combinatorics']"
21,Is it highly unusual to win a lottery with 10 tickets in 6 weeks out of 7? [closed],Is it highly unusual to win a lottery with 10 tickets in 6 weeks out of 7? [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question A woman in my local Rotary Club has won our weekly drawing 6 out of 7 weeks and I wanted to know the actual odds of this happening. On average 10 tickets are bought which I know makes her daily odds $1/10$. How to find the odds to win 6 out of 7?","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question A woman in my local Rotary Club has won our weekly drawing 6 out of 7 weeks and I wanted to know the actual odds of this happening. On average 10 tickets are bought which I know makes her daily odds $1/10$. How to find the odds to win 6 out of 7?",,['probability']
22,probability of picking a specific card from a deck,probability of picking a specific card from a deck,,"Question: What is the probability you draw Jack of Hearts in a hand of $5$ cards? Assume you have a deck with with $52$ cards ( $4$ suits of $13$ cards: numbers $1\ldots 9$ , and faces J, Q, K). My way of thinking is the following: $$\frac{\left(\dfrac{1\cdot51\cdot50\cdot49\cdot48}{4!}\right)}{ \left(\dfrac{52\cdot51\cdot50\cdot49\cdot48}{5!}\right)}$$ $1$ is for the Jack of Hearts being drawn, and then $51\ldots48$ for the rest of the $4$ cards","Question: What is the probability you draw Jack of Hearts in a hand of cards? Assume you have a deck with with cards ( suits of cards: numbers , and faces J, Q, K). My way of thinking is the following: is for the Jack of Hearts being drawn, and then for the rest of the cards","5 52 4 13 1\ldots 9 \frac{\left(\dfrac{1\cdot51\cdot50\cdot49\cdot48}{4!}\right)}{
\left(\dfrac{52\cdot51\cdot50\cdot49\cdot48}{5!}\right)} 1 51\ldots48 4",['probability']
23,Variance over IID a random number of times,Variance over IID a random number of times,,"Let $X_1, X_2,\dotsc$ be independent and identically distributed with mean $E[X]$ and variance $VAR[X]$. Let $N$ be a non-negative integer-valued random variable independent of the $X_i$'s. Show $$ VAR\left[ \sum_{i=1}^N X_i \right] = E[N]VAR[X]+(E[X])^2VAR[N] $$ I've tried expanding this in a number of different ways but I can't quite seem to get it to work out. I don't really understand how to condition on a random variable like this. Any help would be greatly appreciated.","Let $X_1, X_2,\dotsc$ be independent and identically distributed with mean $E[X]$ and variance $VAR[X]$. Let $N$ be a non-negative integer-valued random variable independent of the $X_i$'s. Show $$ VAR\left[ \sum_{i=1}^N X_i \right] = E[N]VAR[X]+(E[X])^2VAR[N] $$ I've tried expanding this in a number of different ways but I can't quite seem to get it to work out. I don't really understand how to condition on a random variable like this. Any help would be greatly appreciated.",,"['probability', 'independence']"
24,A combinatorial card problem,A combinatorial card problem,,"Suppose you have a standard bridge deck of 52 cards.  We will say you ""have a pair"" if you have two consecutive cards in the deck with the same rank (2,3,4,5,6,7,8,9,10,J,Q,K,A).  If a deck is randomly shuffled, what is the probability you have a pair in the deck? I have been able to estimate this nicely using a simulation, but finding an analytical solution remains elusive.","Suppose you have a standard bridge deck of 52 cards.  We will say you ""have a pair"" if you have two consecutive cards in the deck with the same rank (2,3,4,5,6,7,8,9,10,J,Q,K,A).  If a deck is randomly shuffled, what is the probability you have a pair in the deck? I have been able to estimate this nicely using a simulation, but finding an analytical solution remains elusive.",,"['probability', 'combinatorics', 'card-games']"
25,Turning over blue and pink cups until the gender of the baby is known.,Turning over blue and pink cups until the gender of the baby is known.,,"I'm trying to do the following problem, and want to know why my approach does not work. A “gender reveal” party is held to announce the gender of an expected newborn. 15 cups are filled in advance with colored beads and covered: if the baby is a boy, 8 are filled with blue beads and 7 with pink. If the baby is a girl, 7 are filled with blue and 8 with pink. When the audience arrives the cups are knocked over (revealing bead colors) in a uniformly random order until the audience has seen 8 cups of the same color (and thereby knows the gender). Let N be the number of cups turned over before the gender is known. Compute the probability that N = k for k ∈ {8, 9, 10, . . . , 15}. Is the probability that N = 15 (and one has to wait to the very end) more or less than 1/2? Let $E_i$ be the event that the gender of the baby is known after the $i^{\text{th}}$ cup is turned over, for $i \in \{ 8,9,10,...,15 \}$ . Let Boy be the event that the baby is a boy, and Girl the event that it is a girl. Then the desired probability is: $$P(E_i) = P(E_i| \text{Boy})P(\text{Boy}) + P(E_i| \text{Girl})P(\text{Girl}) $$ For a particular $i$ , we try to compute $P(E_i| \text{Boy})$ . Given that the baby is a boy, there would be 8 cups filled with blue beads and 7 cups filled with pink beads. If we place the cups in a line, then the outcomes we are interested in, i.e., the ones where we have to turn over the $i^{\text{th}}$ cup (from left to right) before the gender of the baby is known, are the cases where the $i^{\text{th}}$ cup is a cup filed with blue beads (denoted $B$ ), and all the cups to the right of it are filled with pink beads (denoted $P$ ), i.e., the situation in the following diagram: $${\underbrace{\_ \phantom{.} \_ \phantom{.} \_ \dots \underline{B} }_\text{i}} \phantom{.} {\underbrace{\underline{P} \phantom{.} \underline{P} \phantom{.} \underline{P} \dots \underline{P} } _\text{15-i}}$$ In the above diagram, there are $7 \choose {15-i}$ ways to choose the rightmost pink-beads cups, with $(15-i)!$ ways to permute each selection, 8 ways to choose the blue-beads cup at position $i$ , and $(i-1)!$ ways to arrange the remaining cups. So we'd have: $$P(E_i| \text{Boy}) = \frac{{7 \choose {15-i}} \cdot (15-i)! \cdot 8 \cdot (i-1)!}{15!}$$ Given that the situation is similar when the baby is a girl, and that $P(\text{Boy}) = P(\text{Girl}) = \frac{1}{2}$ , we'd have: $$P(E_i) = \frac{{7 \choose {15-i}} \cdot (15-i)! \cdot 8 \cdot (i-1)!}{15!}$$ But this is wrong, since, with $i = 15$ , for example, we'd have $P(E_{15}) \approx 3.73$ . Where did I go wrong with my analysis?","I'm trying to do the following problem, and want to know why my approach does not work. A “gender reveal” party is held to announce the gender of an expected newborn. 15 cups are filled in advance with colored beads and covered: if the baby is a boy, 8 are filled with blue beads and 7 with pink. If the baby is a girl, 7 are filled with blue and 8 with pink. When the audience arrives the cups are knocked over (revealing bead colors) in a uniformly random order until the audience has seen 8 cups of the same color (and thereby knows the gender). Let N be the number of cups turned over before the gender is known. Compute the probability that N = k for k ∈ {8, 9, 10, . . . , 15}. Is the probability that N = 15 (and one has to wait to the very end) more or less than 1/2? Let be the event that the gender of the baby is known after the cup is turned over, for . Let Boy be the event that the baby is a boy, and Girl the event that it is a girl. Then the desired probability is: For a particular , we try to compute . Given that the baby is a boy, there would be 8 cups filled with blue beads and 7 cups filled with pink beads. If we place the cups in a line, then the outcomes we are interested in, i.e., the ones where we have to turn over the cup (from left to right) before the gender of the baby is known, are the cases where the cup is a cup filed with blue beads (denoted ), and all the cups to the right of it are filled with pink beads (denoted ), i.e., the situation in the following diagram: In the above diagram, there are ways to choose the rightmost pink-beads cups, with ways to permute each selection, 8 ways to choose the blue-beads cup at position , and ways to arrange the remaining cups. So we'd have: Given that the situation is similar when the baby is a girl, and that , we'd have: But this is wrong, since, with , for example, we'd have . Where did I go wrong with my analysis?","E_i i^{\text{th}} i \in \{ 8,9,10,...,15 \} P(E_i) = P(E_i| \text{Boy})P(\text{Boy}) + P(E_i| \text{Girl})P(\text{Girl})  i P(E_i| \text{Boy}) i^{\text{th}} i^{\text{th}} B P {\underbrace{\_ \phantom{.} \_ \phantom{.} \_ \dots \underline{B} }_\text{i}} \phantom{.} {\underbrace{\underline{P} \phantom{.} \underline{P} \phantom{.} \underline{P} \dots \underline{P} } _\text{15-i}} 7 \choose {15-i} (15-i)! i (i-1)! P(E_i| \text{Boy}) = \frac{{7 \choose {15-i}} \cdot (15-i)! \cdot 8 \cdot (i-1)!}{15!} P(\text{Boy}) = P(\text{Girl}) = \frac{1}{2} P(E_i) = \frac{{7 \choose {15-i}} \cdot (15-i)! \cdot 8 \cdot (i-1)!}{15!} i = 15 P(E_{15}) \approx 3.73","['probability', 'conditional-probability', 'bayes-theorem']"
26,Durret 2.5.8: Question about probability of limsup,Durret 2.5.8: Question about probability of limsup,,"I am interested in this problem by Durret in Probability: Theory and Examples . Let $X_1,X_2, \dots$ be i.i.d. and not $\equiv0$ . If $E|X_1| < \infty$ , show that $$\limsup_{n \to \infty} |X_n|^{1/n} = 1$$ almost surely. One idea I had, was trying to show that $P(\limsup |X_n|^{1/n} > 1) = 0$ and $P(\limsup |X_n|^{1/n} < 1) = 0$ . This would give us the result. Now for the first one, we have $$P(\limsup |X_n|^{1/n} > 1) \leq P(|X_n|^{1/n} > 1 \text{ i.o.}).$$ I want to show that the last probability above is $0$ maybe by Borel-Cantelli and using $E|X_1| < \infty$ if and only if $\sum_nP(|X_1| \geq n) < \infty$ . I am not sure if this is the right directon. Please help.","I am interested in this problem by Durret in Probability: Theory and Examples . Let be i.i.d. and not . If , show that almost surely. One idea I had, was trying to show that and . This would give us the result. Now for the first one, we have I want to show that the last probability above is maybe by Borel-Cantelli and using if and only if . I am not sure if this is the right directon. Please help.","X_1,X_2, \dots \equiv0 E|X_1| < \infty \limsup_{n \to \infty} |X_n|^{1/n} = 1 P(\limsup |X_n|^{1/n} > 1) = 0 P(\limsup |X_n|^{1/n} < 1) = 0 P(\limsup |X_n|^{1/n} > 1) \leq P(|X_n|^{1/n} > 1 \text{ i.o.}). 0 E|X_1| < \infty \sum_nP(|X_1| \geq n) < \infty","['probability', 'probability-theory']"
27,combinatorics problem - sum of integers,combinatorics problem - sum of integers,,"I'm studying for my combinatorics exam and I'm not quite convinced about this problem: How many pairs of distinct integers from $1, 2, 3, ..., 60$ are there   whose  sum of integers is divisible by $3$? The way I solved it is, I divided the integers into $3$ groups: $0 \bmod 3, 1 \bmod 3, 2 \bmod 3$ (0m3,1m3,2m3 for future references). Each group includes $20$ integers, and from there I sorted out all the possible combinations. It's a sum of two integers, so possible combinations are: (0m3,0m3),(1m3,1m3),(2m3,2m3),(0m3,1m3),(0m3,2m3),(1m3,2m3). If two integers are from the same group, then it's $C(20,2)$, and if they are not it's $20^2$. Since there are 3 cases for each group, the answer would be: $3\cdot C(20,2) + 3\cdot (20^2)$ It turns out that was not the answer. What am I missing here?","I'm studying for my combinatorics exam and I'm not quite convinced about this problem: How many pairs of distinct integers from $1, 2, 3, ..., 60$ are there   whose  sum of integers is divisible by $3$? The way I solved it is, I divided the integers into $3$ groups: $0 \bmod 3, 1 \bmod 3, 2 \bmod 3$ (0m3,1m3,2m3 for future references). Each group includes $20$ integers, and from there I sorted out all the possible combinations. It's a sum of two integers, so possible combinations are: (0m3,0m3),(1m3,1m3),(2m3,2m3),(0m3,1m3),(0m3,2m3),(1m3,2m3). If two integers are from the same group, then it's $C(20,2)$, and if they are not it's $20^2$. Since there are 3 cases for each group, the answer would be: $3\cdot C(20,2) + 3\cdot (20^2)$ It turns out that was not the answer. What am I missing here?",,"['probability', 'combinatorics']"
28,How to calculate intersection and union of probabilities?,How to calculate intersection and union of probabilities?,,"lets say I have a switch A with 3 legs, each leg has 0.8 chance to be connected (and then electricity will flow), we need only 1 leg connected for A to transfer the electricity (so sorry I didn't explain it that well I'm having hard time to translate this problem) So I calculated the chance of A to transfer electricity by doing $1-(0.2)^3$  which is $124\over125$ which I think is true. The problem is I wanted to say that A will transfer elecricity only if 1 of his legs will be connected so its like saying $0.8 + 0.8 + 0.8$ which is obviously wrong(over $1$) so I used the weird formula that says to do like this: $0.8 + 0.8 + 0.8 - (0.8)^2 -(0.8)^2 - (0.8)^2 + (0.8)^3 = {124\over125}$ too. My only problem is that I didnt understand why I had to use that formula and why I could multiple probabilities for the intersection but couldn't just sum them for the union. Thanks in advance","lets say I have a switch A with 3 legs, each leg has 0.8 chance to be connected (and then electricity will flow), we need only 1 leg connected for A to transfer the electricity (so sorry I didn't explain it that well I'm having hard time to translate this problem) So I calculated the chance of A to transfer electricity by doing $1-(0.2)^3$  which is $124\over125$ which I think is true. The problem is I wanted to say that A will transfer elecricity only if 1 of his legs will be connected so its like saying $0.8 + 0.8 + 0.8$ which is obviously wrong(over $1$) so I used the weird formula that says to do like this: $0.8 + 0.8 + 0.8 - (0.8)^2 -(0.8)^2 - (0.8)^2 + (0.8)^3 = {124\over125}$ too. My only problem is that I didnt understand why I had to use that formula and why I could multiple probabilities for the intersection but couldn't just sum them for the union. Thanks in advance",,['probability']
29,Probability that each number obtained by throwing a die is no smaller than the preceding number,Probability that each number obtained by throwing a die is no smaller than the preceding number,,"A fair die is thrown 4 times. Find the probability that the each number obtained is no smaller than the preceding number. If all numbers obtained are same, number of such outcomes $$=\dbinom{6}{1}=6$$ If 3 numbers obtained are same, number of ways is equal  to the number of ways of choosing any two numbers $=\dbinom{6}{2}$. But these two number can be arranged as $x,y,y,y$ or $x,x,x,y$ where $x<y$. So $$2\times\dbinom{6}{2}$$ If 2 numbers are same, the cases are $a_1<a_2<a_3=a_4$, $a_1<a_2=a_3<a_4$, $a_1=a_2<a_3<a_4$, $a_1=a_2<a_3=a_4$. Number of ways $$=3\times\dbinom{6}{3}+\dbinom{6}{2}$$ if all 4 numbers are different, $$\dbinom{6}{4}$$ Total number of possibilities $=6^4$. Even though I got the correct answer, is there any shorter method?","A fair die is thrown 4 times. Find the probability that the each number obtained is no smaller than the preceding number. If all numbers obtained are same, number of such outcomes $$=\dbinom{6}{1}=6$$ If 3 numbers obtained are same, number of ways is equal  to the number of ways of choosing any two numbers $=\dbinom{6}{2}$. But these two number can be arranged as $x,y,y,y$ or $x,x,x,y$ where $x<y$. So $$2\times\dbinom{6}{2}$$ If 2 numbers are same, the cases are $a_1<a_2<a_3=a_4$, $a_1<a_2=a_3<a_4$, $a_1=a_2<a_3<a_4$, $a_1=a_2<a_3=a_4$. Number of ways $$=3\times\dbinom{6}{3}+\dbinom{6}{2}$$ if all 4 numbers are different, $$\dbinom{6}{4}$$ Total number of possibilities $=6^4$. Even though I got the correct answer, is there any shorter method?",,"['probability', 'combinatorics', 'dice']"
30,Example of an adapted but not progressively measurable process,Example of an adapted but not progressively measurable process,,"I'm looking for an example of a stochastic process $X$ that is $\mathbb{F}$-adapted, but not progressively measurable. One example I found is the following: $(\Omega, \mathfrak{A}) = (\mathbb{R^+}, \mathfrak{B}(\mathbb{R^+}))$, $\mathcal{F}_t = \sigma({x}:x \in \mathbb{R}^+)$ for all $t \geq 0$; $X(t,\omega) := \cases{0, \mbox{if}~  \omega \neq t,\\ 1, \mbox{if}~ \omega = t}$. I don't see why this process is adapted, but not progressively measurable. For $X_t$ we have $X_t (\omega) = \cases{0, \mbox{if}~ \omega \neq t,\\ 1, \mbox{if}~ \omega = t}.$ Then $X_t^{-1}(\{0\}) = \emptyset$ $X_t^{-1}(\{1\}) = \{t\}$ and since $\emptyset,\{t\} \in \mathcal{F}_t$ for all $t \geq 0$, $X_t$ is $\mathcal{F}_t$-measurable and therefore adapted. (correct so far?) But can someone please explain, how I can see, that this process is not progressively measurable? Or does someone have another easy understandable example?","I'm looking for an example of a stochastic process $X$ that is $\mathbb{F}$-adapted, but not progressively measurable. One example I found is the following: $(\Omega, \mathfrak{A}) = (\mathbb{R^+}, \mathfrak{B}(\mathbb{R^+}))$, $\mathcal{F}_t = \sigma({x}:x \in \mathbb{R}^+)$ for all $t \geq 0$; $X(t,\omega) := \cases{0, \mbox{if}~  \omega \neq t,\\ 1, \mbox{if}~ \omega = t}$. I don't see why this process is adapted, but not progressively measurable. For $X_t$ we have $X_t (\omega) = \cases{0, \mbox{if}~ \omega \neq t,\\ 1, \mbox{if}~ \omega = t}.$ Then $X_t^{-1}(\{0\}) = \emptyset$ $X_t^{-1}(\{1\}) = \{t\}$ and since $\emptyset,\{t\} \in \mathcal{F}_t$ for all $t \geq 0$, $X_t$ is $\mathcal{F}_t$-measurable and therefore adapted. (correct so far?) But can someone please explain, how I can see, that this process is not progressively measurable? Or does someone have another easy understandable example?",,"['probability', 'probability-theory', 'stochastic-processes', 'stochastic-calculus']"
31,Birthday Problem - Company Stats Strange or Average?,Birthday Problem - Company Stats Strange or Average?,,"I had a birthday problem question that I'm really interested in knowing the answer for: In a group of 2,000 people, what is the probability of one day during the year that no one has that particular day of birth?  What about the probability of having 10 days not having a birthday within them? For the real life story, I work for a company which we have just discovered that there are 10 particular days which no one has a birthday on.  We thought it strange, but we were wondering if this was actually an expected outcome.  I didn't know where else to turn.  Thanks in advance for your input!","I had a birthday problem question that I'm really interested in knowing the answer for: In a group of 2,000 people, what is the probability of one day during the year that no one has that particular day of birth?  What about the probability of having 10 days not having a birthday within them? For the real life story, I work for a company which we have just discovered that there are 10 particular days which no one has a birthday on.  We thought it strange, but we were wondering if this was actually an expected outcome.  I didn't know where else to turn.  Thanks in advance for your input!",,"['probability', 'coupon-collector', 'birthday']"
32,Expected value of two dependent variables is still a product of expectations,Expected value of two dependent variables is still a product of expectations,,"For independent variables we have $E[XY]=E[X]E[Y]$. Now, since I could not find a statement that the converse is also true, I suspect that there are examples of dependent variables where this relation still holds. Could anybody here give me an example?- I am somewhat interested in how this could look like.","For independent variables we have $E[XY]=E[X]E[Y]$. Now, since I could not find a statement that the converse is also true, I suspect that there are examples of dependent variables where this relation still holds. Could anybody here give me an example?- I am somewhat interested in how this could look like.",,"['probability', 'probability-distributions']"
33,Probability a die will come up 6 at least twice in twelve rolls,Probability a die will come up 6 at least twice in twelve rolls,,"What is the probability of rolling at least two 6's on twelve rolls of a fair 6-sided die. I am using the complement to solve the question $$1-\frac {5^{12}+(_{12}C_ 1)5^{11}}{6^{12}}$$ $5^{12}$ is the probability of not rolling a six $6^{12}$ is the sample space My question is why does the binomial coefficient have to be multiplied $5^{11}$ where the binomial coefficient is a ""6"" on the die. This method I find difficult but intriguing.","What is the probability of rolling at least two 6's on twelve rolls of a fair 6-sided die. I am using the complement to solve the question $$1-\frac {5^{12}+(_{12}C_ 1)5^{11}}{6^{12}}$$ $5^{12}$ is the probability of not rolling a six $6^{12}$ is the sample space My question is why does the binomial coefficient have to be multiplied $5^{11}$ where the binomial coefficient is a ""6"" on the die. This method I find difficult but intriguing.",,['probability']
34,How to calculate a fullhouse after dealing 5 cards?,How to calculate a fullhouse after dealing 5 cards?,,"In case you are not familiar with a fullhouse , it is when you have XXXYY (three of a kind + a pair). I am not that good calculating odds, but after time I manage to write all the possible combinations: However, I can't translate it to real odds, my questions: How can I translate it to odds? (Since my approach is time consuming, and will be impossible to apply on larger problems) what other alternatives do I have?","In case you are not familiar with a fullhouse , it is when you have XXXYY (three of a kind + a pair). I am not that good calculating odds, but after time I manage to write all the possible combinations: However, I can't translate it to real odds, my questions: How can I translate it to odds? (Since my approach is time consuming, and will be impossible to apply on larger problems) what other alternatives do I have?",,"['probability', 'card-games']"
35,Probability that ace of spades is at bottom of deck IF ace of hearts is NOT at top,Probability that ace of spades is at bottom of deck IF ace of hearts is NOT at top,,"What is the probability that the ace of spades is at the bottom of a standard deck of 52 cards given that the ace of hearts is not at the top? I asked my older brother, and he said it should be $\frac{50}{51} \cdot \frac{1}{51}$ because that's $$\mathbb{P}(A\heartsuit \text{ not at top}) \times \mathbb{P}(A\spadesuit \text{ at bottom}),$$ but I'm not sure if I agree. Shouldn't the $\frac{50}{51}$ be $\frac{50}{52}$? Thanks you!","What is the probability that the ace of spades is at the bottom of a standard deck of 52 cards given that the ace of hearts is not at the top? I asked my older brother, and he said it should be $\frac{50}{51} \cdot \frac{1}{51}$ because that's $$\mathbb{P}(A\heartsuit \text{ not at top}) \times \mathbb{P}(A\spadesuit \text{ at bottom}),$$ but I'm not sure if I agree. Shouldn't the $\frac{50}{51}$ be $\frac{50}{52}$? Thanks you!",,['probability']
36,Probability of rolling a die,Probability of rolling a die,,"I roll a die until it comes up $6$ and add up the numbers of spots I see. For example, I roll $4,1,3,5,6$ and record the number $4+1+3+5+6=19$. Call this sum $S$. Find the standard deviation of $S$. I have been looking for an easy way to do this because I know I can use the definitions here to calculate the variance of $S$ and then take the square root of it. But I am sure there is an easier way to do this.","I roll a die until it comes up $6$ and add up the numbers of spots I see. For example, I roll $4,1,3,5,6$ and record the number $4+1+3+5+6=19$. Call this sum $S$. Find the standard deviation of $S$. I have been looking for an easy way to do this because I know I can use the definitions here to calculate the variance of $S$ and then take the square root of it. But I am sure there is an easier way to do this.",,"['probability', 'combinatorics', 'dice']"
37,Convergence in probability versus convergence in distribution,Convergence in probability versus convergence in distribution,,Suppose $\bar{X}_n$ is the mean of a random sample of size ${n}$ from an exponential distribution with $\lambda$ > 0. Then what does the following statement about convergence mean (how does this converge)? $$\text{exp} \left(-\frac{1}{\bar{X}_n} \right) \xrightarrow{\rm{P}} \text{exp}(-\lambda) $$ More specifically what does the $\rm{P}$ on top of the arrow mean? I understand it's probability but what is the difference between some expression converging to some value in probability versus in distribution?,Suppose $\bar{X}_n$ is the mean of a random sample of size ${n}$ from an exponential distribution with $\lambda$ > 0. Then what does the following statement about convergence mean (how does this converge)? $$\text{exp} \left(-\frac{1}{\bar{X}_n} \right) \xrightarrow{\rm{P}} \text{exp}(-\lambda) $$ More specifically what does the $\rm{P}$ on top of the arrow mean? I understand it's probability but what is the difference between some expression converging to some value in probability versus in distribution?,,"['probability', 'probability-distributions']"
38,"If $X+Y$ is independent from $X$ and independent from $Y$, then $X+Y$ is deterministic","If  is independent from  and independent from , then  is deterministic",X+Y X Y X+Y,"Let $X,Y$ be two real random variables such that $X+Y$ is independent from $X$ and also independent from $Y$ . Show that $X+Y$ is deterministic If $X$ and $Y$ have a variance, then we can compute : $$\mathbb E[(X+Y)^2] = \mathbb E[ X (X+Y)] + \mathbb E[Y(X+Y)] =  \mathbb E[ X ]\mathbb E[X+Y] + \mathbb E[Y]\mathbb E[X+Y] = (\mathbb E[X+Y])^2$$ and therefore $\operatorname{Var}(X+Y) = 0$ and $X+Y$ is almost surely constant. In the general case however, I don't see how to prove this. Using the characteristic function $f_X(t) = \mathbb E[e^{itX}]$ , I can show that : $$\forall t,s\in\mathbb R,f_X(t) f_{X+Y}(s) = f_{X+Y}(s+t) f_Y(-t)$$ I am not sure if and how this helps, though.","Let be two real random variables such that is independent from and also independent from . Show that is deterministic If and have a variance, then we can compute : and therefore and is almost surely constant. In the general case however, I don't see how to prove this. Using the characteristic function , I can show that : I am not sure if and how this helps, though.","X,Y X+Y X Y X+Y X Y \mathbb E[(X+Y)^2] = \mathbb E[ X (X+Y)] + \mathbb E[Y(X+Y)] =  \mathbb E[ X ]\mathbb E[X+Y] + \mathbb E[Y]\mathbb E[X+Y] = (\mathbb E[X+Y])^2 \operatorname{Var}(X+Y) = 0 X+Y f_X(t) = \mathbb E[e^{itX}] \forall t,s\in\mathbb R,f_X(t) f_{X+Y}(s) = f_{X+Y}(s+t) f_Y(-t)","['probability', 'probability-theory', 'fourier-analysis']"
39,Why is the probability of getting a pair in a five-card poker hand so complicated?,Why is the probability of getting a pair in a five-card poker hand so complicated?,,"The working-out of this question has really confused me. I know the basics of probability but I don't get the calculations here. I think 13C2 * 4C2 determines the number of possible pairs, and the stuff in the brackets is the number of combinations possible with the cards remaining after a pair is obtained—but, in them, what does does each number specifically do? . Thanks in advance.","The working-out of this question has really confused me. I know the basics of probability but I don't get the calculations here. I think 13C2 * 4C2 determines the number of possible pairs, and the stuff in the brackets is the number of combinations possible with the cards remaining after a pair is obtained—but, in them, what does does each number specifically do? . Thanks in advance.",,"['probability', 'combinatorics', 'card-games', 'poker']"
40,"A deck of cards contains $26$ black and $13$ red cards, taking out the cards in a particular way, what is the probability the last card left is black","A deck of cards contains  black and  red cards, taking out the cards in a particular way, what is the probability the last card left is black",26 13,"You have a deck of cards containing 26 black and 13 red cards. You pull out 2 cards at the same time and check their color. If both cards are the same color, then a black card is added to the deck. However, if the cards are of diﬀerent colors, then a red card is used to replace them. Once the cards are taken out of the deck, they are not returned to the deck, and thus the number of cards in the deck keeps reducing. What is the probability the last card left in the deck is black? my attempt: for both cards are the same colors: (both black)+(both red) ((26/39) (25/38)) + ((13/39) (12/38))=0.5438 the cards are of diﬀerent colors: (black +red)+(red +black) ((26/39) (13/38))+((13/39) (26/38))=0.4561 please let me know how to continue for the answer for: What is the likelihood the last card left in the deck is black?","You have a deck of cards containing 26 black and 13 red cards. You pull out 2 cards at the same time and check their color. If both cards are the same color, then a black card is added to the deck. However, if the cards are of diﬀerent colors, then a red card is used to replace them. Once the cards are taken out of the deck, they are not returned to the deck, and thus the number of cards in the deck keeps reducing. What is the probability the last card left in the deck is black? my attempt: for both cards are the same colors: (both black)+(both red) ((26/39) (25/38)) + ((13/39) (12/38))=0.5438 the cards are of diﬀerent colors: (black +red)+(red +black) ((26/39) (13/38))+((13/39) (26/38))=0.4561 please let me know how to continue for the answer for: What is the likelihood the last card left in the deck is black?",,"['probability', 'probability-theory']"
41,"Is there a way to determine the summation of all ""even"" elements of an infinite geometric sequence?*","Is there a way to determine the summation of all ""even"" elements of an infinite geometric sequence?*",,"*Algebraically and not with by adding them for the first 100 or whatever and estimating This came up when I came across a question in my probability class where I was asked about a game where 2 players take turns to accomplish a task until one succeeds. Each attempt has a probability of $p = x$ for success (I'm using $x$ so it's general, but in my case, I got .35) This makes a geometric series of $x(1-x)^{(n-1)}$ for $n$ being a positive integer where $n$ equals nth attempt.  The question asked was what's the probability the first player wins, I wrote it as: $$\lim_{t\to \infty} \sum_{k=0}^{t}x*(x-1)^{2k}$$ Is there any way to solve this algebraically or something else or do I have to rely on computers for this task? Sorry for this awful formatting I'm asking this on a phone and I can't post images since I'm new and I can't write latex on mobile.","*Algebraically and not with by adding them for the first 100 or whatever and estimating This came up when I came across a question in my probability class where I was asked about a game where 2 players take turns to accomplish a task until one succeeds. Each attempt has a probability of $p = x$ for success (I'm using $x$ so it's general, but in my case, I got .35) This makes a geometric series of $x(1-x)^{(n-1)}$ for $n$ being a positive integer where $n$ equals nth attempt.  The question asked was what's the probability the first player wins, I wrote it as: $$\lim_{t\to \infty} \sum_{k=0}^{t}x*(x-1)^{2k}$$ Is there any way to solve this algebraically or something else or do I have to rely on computers for this task? Sorry for this awful formatting I'm asking this on a phone and I can't post images since I'm new and I can't write latex on mobile.",,"['probability', 'sequences-and-series', 'geometric-series']"
42,"Most Probable Sum by rolling $2$ dice in $[100,111]$.",Most Probable Sum by rolling  dice in .,"2 [100,111]","Given two dices, we roll them and add the result to a sum (initialised to 0) till sum is $\ge 100.$ The resultant sum can be any number in [100 111]. Which among them have the highest probability of being the resultant sum.","Given two dices, we roll them and add the result to a sum (initialised to 0) till sum is $\ge 100.$ The resultant sum can be any number in [100 111]. Which among them have the highest probability of being the resultant sum.",,"['probability', 'dice']"
43,"Must a Set's size be a natural number, and would the contrary invalidate a solution?","Must a Set's size be a natural number, and would the contrary invalidate a solution?",,"I came up with a way of solving this counting problem that's not in my textbook and I am wondering if it is still valid because in one of the intermediate steps I calculate the number of elements in a subset and I often get a non-integer answer like $9.5849\dots$ The questions is How many subsets of $S = \{1,2,....n\}$ contain at least one of the      elements $\{1,2\}$ and at least $2$ of the elements $\{3,4,5\}?$ First I got the number of subsets which have at least one of the elements $\{1,2\}$ by using the subtraction principle and by using powers of two. For each element in the set I ask 'is this in the set?' and there are two options, yes or no. So the total number of subsets is $2^{n}.$ And finally I use subtraction because the number of subsets with at least one element from $\{1,2\}$ is the same as the total minus the number of subsets with nothing from $\{1,2\}:$ $$m = 2^{n} - 2^{n-2}$$ Next, I tried something different. I tried to imagine that I was starting the problem all over again but this time the original set is smaller. Now $S = \{1,2....k\}$      where $k = log_{2}(m)$ I figured this was sound because if I had 10 element I would have $2^{10} = 1024$ possible subsets and $log_{2}(1024)$ gives me the number of elements in the set which is $10.$ Now I just have answer the simpler question: How many subsets of $S = \{1,2,....k\},$ where $k = log_{2}(m),$      contain at least $2$ of the elements $\{3,4,5\}?$ And the answer to this is $4 * 2^{k-3}$ I multiply by 4 because there are $3$ ways of of appending $2$ or more elements from $\{3,4,5\}$ back into to $S$ which has had $\{3,4,5\}$ taken away from it. They are $\{3,4\},\{3,5\},\{4,5\},\{3,4,5\}.$ What I find unusual about this approach is that the $log_{2}(m)$ is not always an integer. And I can't imagine going through each item in a set asking the question 'are you in the subset? if one of the elements is only a fraction of an element like $0.5849\dots$ For example, if $n = 10,$ then $m = 2^{10} - 2^{8}    = 768.$  Then $k = log_{2}(m)   = 9.584962\dots$ It feels wrong to ask how many subsets are in a set with $9.58\dots$ elements. And yet I get the correct answer: $4 * 2^{9.5849... - 3} = 384$ exactly!","I came up with a way of solving this counting problem that's not in my textbook and I am wondering if it is still valid because in one of the intermediate steps I calculate the number of elements in a subset and I often get a non-integer answer like $9.5849\dots$ The questions is How many subsets of $S = \{1,2,....n\}$ contain at least one of the      elements $\{1,2\}$ and at least $2$ of the elements $\{3,4,5\}?$ First I got the number of subsets which have at least one of the elements $\{1,2\}$ by using the subtraction principle and by using powers of two. For each element in the set I ask 'is this in the set?' and there are two options, yes or no. So the total number of subsets is $2^{n}.$ And finally I use subtraction because the number of subsets with at least one element from $\{1,2\}$ is the same as the total minus the number of subsets with nothing from $\{1,2\}:$ $$m = 2^{n} - 2^{n-2}$$ Next, I tried something different. I tried to imagine that I was starting the problem all over again but this time the original set is smaller. Now $S = \{1,2....k\}$      where $k = log_{2}(m)$ I figured this was sound because if I had 10 element I would have $2^{10} = 1024$ possible subsets and $log_{2}(1024)$ gives me the number of elements in the set which is $10.$ Now I just have answer the simpler question: How many subsets of $S = \{1,2,....k\},$ where $k = log_{2}(m),$      contain at least $2$ of the elements $\{3,4,5\}?$ And the answer to this is $4 * 2^{k-3}$ I multiply by 4 because there are $3$ ways of of appending $2$ or more elements from $\{3,4,5\}$ back into to $S$ which has had $\{3,4,5\}$ taken away from it. They are $\{3,4\},\{3,5\},\{4,5\},\{3,4,5\}.$ What I find unusual about this approach is that the $log_{2}(m)$ is not always an integer. And I can't imagine going through each item in a set asking the question 'are you in the subset? if one of the elements is only a fraction of an element like $0.5849\dots$ For example, if $n = 10,$ then $m = 2^{10} - 2^{8}    = 768.$  Then $k = log_{2}(m)   = 9.584962\dots$ It feels wrong to ask how many subsets are in a set with $9.58\dots$ elements. And yet I get the correct answer: $4 * 2^{9.5849... - 3} = 384$ exactly!",,"['probability', 'combinatorics', 'elementary-set-theory']"
44,"Single random variable, multiple probability distributions?","Single random variable, multiple probability distributions?",,"If we have two separate probability distributions P(x) and Q(x) over the same random variable x, we can measure how diﬀerent these two distributions are using the Kullback-Leibler (KL) divergence... The above statement is from Deep Learning by Ian Goodfellow and Yoshua Bengio and Aaron Courville and I have the following question: As far as I have understood, a random variable is defined considering a specific probability distribution in mind, it takes the value of a random outcome in that distribution. Perhaps I'm wrong in my understanding. My question is: How can you have two separate probability distributions on the same random variable? Kindly help me resolve this confusion. Thanks!","If we have two separate probability distributions P(x) and Q(x) over the same random variable x, we can measure how diﬀerent these two distributions are using the Kullback-Leibler (KL) divergence... The above statement is from Deep Learning by Ian Goodfellow and Yoshua Bengio and Aaron Courville and I have the following question: As far as I have understood, a random variable is defined considering a specific probability distribution in mind, it takes the value of a random outcome in that distribution. Perhaps I'm wrong in my understanding. My question is: How can you have two separate probability distributions on the same random variable? Kindly help me resolve this confusion. Thanks!",,"['probability', 'probability-theory', 'probability-distributions', 'random-variables']"
45,What is the probability that two numbers between 1 and 10 picked at random sum to a number greater than 5?,What is the probability that two numbers between 1 and 10 picked at random sum to a number greater than 5?,,"We have the numbers $1$ through $10$ in a box, we pick one at random, write it down and put it back in the box. We pick another of those numbers at random and write it down again. If we add the two numbers, what is the probability that it will be greater than $5$? At first I though that I could count the number of ways we could add two numbers to get six, i.e. $2+4$ and see what are the chances to get numbers bigger than those choices. Then adding all the probabilities that relate to each way. However, I get numbers greater than $1$ which is impossible. I also thought about the chance of getting a $1$ and then a number equal to or bigger to $5$, $P(x \ge 5) = \frac 12$ multiplying them together and repeating until all numbers run out. Again, wrong answer. My question is: how do we get to the correct answer? Is it possible to generalize? Say that the probability of $n$ numbers picked at random from $N$ choices add to something greater than $k$.","We have the numbers $1$ through $10$ in a box, we pick one at random, write it down and put it back in the box. We pick another of those numbers at random and write it down again. If we add the two numbers, what is the probability that it will be greater than $5$? At first I though that I could count the number of ways we could add two numbers to get six, i.e. $2+4$ and see what are the chances to get numbers bigger than those choices. Then adding all the probabilities that relate to each way. However, I get numbers greater than $1$ which is impossible. I also thought about the chance of getting a $1$ and then a number equal to or bigger to $5$, $P(x \ge 5) = \frac 12$ multiplying them together and repeating until all numbers run out. Again, wrong answer. My question is: how do we get to the correct answer? Is it possible to generalize? Say that the probability of $n$ numbers picked at random from $N$ choices add to something greater than $k$.",,"['probability', 'combinatorics']"
46,What is the expected number of coin tosses needed to obtain a head?,What is the expected number of coin tosses needed to obtain a head?,,"Due to my recent misunderstandings regarding the 'expected value' concept I decided to post this question. Although I have easily found the answer on the internet I haven't managed to fully understand it. I understood that the formula for the expected value is: $$E(x) = x_1p_1 +x_2*p_2 +...+x_np_n$$ The x's are the possible value that the random variable can take and the p's are the probabilites that this certain value is taken. So, if I get a head on the first try, then  $ p_1 = \frac{1}{2} , x_1 = 1 $ If I get a head on the second try, then $ p_2 = \frac{1}{4} , x_2 = 2 $ And then, I woudl have that: $$E(x) = \frac{1}{2}1+ \frac{1}{4}2 +...$$ So my reasoning led me to an inifnite sum which I don't think I can't evaluate it that easy. In the 'standard' solution of this problem, the expected value is found in a reccurisve manner. So the case in which the head doesn't appear in the first toss is treated reccursively. I haven't understood that step. My questions are: is my judgement correct? How about that reccursion step? Could somebody explain it to me?","Due to my recent misunderstandings regarding the 'expected value' concept I decided to post this question. Although I have easily found the answer on the internet I haven't managed to fully understand it. I understood that the formula for the expected value is: $$E(x) = x_1p_1 +x_2*p_2 +...+x_np_n$$ The x's are the possible value that the random variable can take and the p's are the probabilites that this certain value is taken. So, if I get a head on the first try, then  $ p_1 = \frac{1}{2} , x_1 = 1 $ If I get a head on the second try, then $ p_2 = \frac{1}{4} , x_2 = 2 $ And then, I woudl have that: $$E(x) = \frac{1}{2}1+ \frac{1}{4}2 +...$$ So my reasoning led me to an inifnite sum which I don't think I can't evaluate it that easy. In the 'standard' solution of this problem, the expected value is found in a reccurisve manner. So the case in which the head doesn't appear in the first toss is treated reccursively. I haven't understood that step. My questions are: is my judgement correct? How about that reccursion step? Could somebody explain it to me?",,"['probability', 'expectation']"
47,Probability and Expected Value of a guessing game,Probability and Expected Value of a guessing game,,Let's say I think of a number between one and six. I will tell you to guess the number and tell you when it's wrong until you guess the correct number. What is the expected number of guesses before the correct number?,Let's say I think of a number between one and six. I will tell you to guess the number and tell you when it's wrong until you guess the correct number. What is the expected number of guesses before the correct number?,,['probability']
48,Expected number of tosses before you see a repeat.,Expected number of tosses before you see a repeat.,,"Suppose we roll a fair die until some face has appeared twice. For instance, we might have a run of rolls 12545 or 636. How many rolls on average would we make? What if we roll until a face has appeared three times? I calculated the expected value for getting a repeat for a six-sided dice and I got 1223/324 (3.77 tosses). How would we generalize this to an $n$-sided dice? What about $k$-repeats?","Suppose we roll a fair die until some face has appeared twice. For instance, we might have a run of rolls 12545 or 636. How many rolls on average would we make? What if we roll until a face has appeared three times? I calculated the expected value for getting a repeat for a six-sided dice and I got 1223/324 (3.77 tosses). How would we generalize this to an $n$-sided dice? What about $k$-repeats?",,"['probability', 'dice']"
49,"Expectation of $ X(X - 1) \ldots (X - k + 1) $, where $ X $ has a Poisson distribution.","Expectation of , where  has a Poisson distribution.", X(X - 1) \ldots (X - k + 1)   X ,"I am trying to calculate $$ \text{E}[X(X - 1) \ldots (X - k + 1)], $$ where $ \text{E} $ denotes the expectation operator and $ k \in \mathbb{N} $ is fixed. I think I have to use the fact that the expectation of a sum of random variables is the sum of the expectations, but how can we apply it to this product?","I am trying to calculate $$ \text{E}[X(X - 1) \ldots (X - k + 1)], $$ where $ \text{E} $ denotes the expectation operator and $ k \in \mathbb{N} $ is fixed. I think I have to use the fact that the expectation of a sum of random variables is the sum of the expectations, but how can we apply it to this product?",,['probability']
50,a question related to two competing patterns in coin tossing,a question related to two competing patterns in coin tossing,,"If I have a two-sided coin with probability $p$ showing head. I repeatedly toss it until either HTHTH or HTHH appears. Can you calculate 1) the probability when I got HTHTH, and 2) the expected value of the number of tosses before I stop? Thanks.","If I have a two-sided coin with probability $p$ showing head. I repeatedly toss it until either HTHTH or HTHH appears. Can you calculate 1) the probability when I got HTHTH, and 2) the expected value of the number of tosses before I stop? Thanks.",,['probability']
51,What is the probability of a randomly chosen integer being even?,What is the probability of a randomly chosen integer being even?,,"There are a number of sets in math that have infinite cardinality but still have a superset. For example, the set of even integers has infinite cardinality, but it is a subset of all integers. The cardinality of the set of integers is infinity, but it has a superset, real numbers. These are just a few examples. So my question is if a random number was chosen from one of these supersets, what is the probability that it would be a part of one of its infinite subsets? There is an infinity of possibilities that are inside the subset, but also an infinity that is not.","There are a number of sets in math that have infinite cardinality but still have a superset. For example, the set of even integers has infinite cardinality, but it is a subset of all integers. The cardinality of the set of integers is infinity, but it has a superset, real numbers. These are just a few examples. So my question is if a random number was chosen from one of these supersets, what is the probability that it would be a part of one of its infinite subsets? There is an infinity of possibilities that are inside the subset, but also an infinity that is not.",,"['probability', 'infinity']"
52,Two cowboys A and B decide to solve a dispute with a duel. [duplicate],Two cowboys A and B decide to solve a dispute with a duel. [duplicate],,"This question already has an answer here : Two players shooting a target alternately (1 answer) Closed 3 years ago . Two cowboys $A$ and $B$ decide to solve a dispute with a duel. Cowboy $A$ hits his target $\frac13$ of the time. Cowboy $B$ hits the target $\frac23$ of the time. It is decided that $A$ will take the first shot, cowboy $B$ will take the second shot (if still alive). This will continue until there is only one left alive. Also, a cowboy can not shoot two times in a row. What are cowboy $A$ chances of winning the duel? My logic is to simulate the cases where $A$ wins: I Case: $A$ wins: $\frac13$ II Case: $A$ loses, $B$ loses, $A$ wins: $\frac23\cdot\frac13\cdot\frac13$ ... But I don't know what to do from here. Any help?","This question already has an answer here : Two players shooting a target alternately (1 answer) Closed 3 years ago . Two cowboys and decide to solve a dispute with a duel. Cowboy hits his target of the time. Cowboy hits the target of the time. It is decided that will take the first shot, cowboy will take the second shot (if still alive). This will continue until there is only one left alive. Also, a cowboy can not shoot two times in a row. What are cowboy chances of winning the duel? My logic is to simulate the cases where wins: I Case: wins: II Case: loses, loses, wins: ... But I don't know what to do from here. Any help?",A B A \frac13 B \frac23 A B A A A \frac13 A B A \frac23\cdot\frac13\cdot\frac13,"['probability', 'probability-theory', 'discrete-mathematics']"
53,What is the expectation of $X$ given $X$,What is the expectation of  given,X X,"Hi im trying to understand conditional expectation and conditional probability based on sigma algebras. Therefore an answer in that flavour would be most useful. So in a physical sense I can see what it means to condition on an event $A$ (i.e we know if this event happens or not). Then what does it mean to condition on a collection of events i.e a sigma algebra? and what is the meaning of asking for 1) $E[X|X]$ 2) to go further, $E[X|f(X)]$ p.s I know conditioning on a r.v is just conditioning of the sigma algebra generated by that r.v. So I guess im just asking what it means physically to condition on a collection of events (and why when you do so you get something random back, unless those events were just { $A,A^{c},\Omega$ ,empty set}","Hi im trying to understand conditional expectation and conditional probability based on sigma algebras. Therefore an answer in that flavour would be most useful. So in a physical sense I can see what it means to condition on an event (i.e we know if this event happens or not). Then what does it mean to condition on a collection of events i.e a sigma algebra? and what is the meaning of asking for 1) 2) to go further, p.s I know conditioning on a r.v is just conditioning of the sigma algebra generated by that r.v. So I guess im just asking what it means physically to condition on a collection of events (and why when you do so you get something random back, unless those events were just { ,empty set}","A E[X|X] E[X|f(X)] A,A^{c},\Omega","['probability', 'probability-theory', 'measure-theory', 'conditional-expectation']"
54,Question on coin tossing - probability,Question on coin tossing - probability,,"When considering an infinite sequence of tosses of a fair coin, how long will it take on an average until the pattern H T T H appears? I tried to break the problem into cases where ultimately the pattern HTTH appears, but that makes things complex. Any insight would be helpful.","When considering an infinite sequence of tosses of a fair coin, how long will it take on an average until the pattern H T T H appears? I tried to break the problem into cases where ultimately the pattern HTTH appears, but that makes things complex. Any insight would be helpful.",,"['probability', 'probability-theory', 'probability-distributions', 'random-variables', 'conditional-probability']"
55,"We lost two cards from a deck of $52$ cards. If we extract a card of this deck, what is the probability we get a diamond?","We lost two cards from a deck of  cards. If we extract a card of this deck, what is the probability we get a diamond?",52,"We lost two cards from a deck of $52$ cards. If we extract a card of this deck, what is the probability we get a diamond? I'm confused here. Suppose we lost two diamonds, then $$P(\text{we get a diamond})=\frac{11}{50}$$ but, if we lost two cards of the other suits, we have $$P(\text{we get a diamond})=\frac{13}{50}$$ if we lost one of the diamonds and one card from the other suits, we have: $$P(\text{we get a diamond})=\frac{12}{50}$$ but here I'm not sure, can someone help me?","We lost two cards from a deck of $52$ cards. If we extract a card of this deck, what is the probability we get a diamond? I'm confused here. Suppose we lost two diamonds, then $$P(\text{we get a diamond})=\frac{11}{50}$$ but, if we lost two cards of the other suits, we have $$P(\text{we get a diamond})=\frac{13}{50}$$ if we lost one of the diamonds and one card from the other suits, we have: $$P(\text{we get a diamond})=\frac{12}{50}$$ but here I'm not sure, can someone help me?",,['probability']
56,Conditional probability of gates.,Conditional probability of gates.,,"A hydraulic stucture has four gates which operate independently . The probability of failure of each gate is 0.1. Given that gate 1 has failed, what is the probability that gate 2 and gate 3 will fail ? I think the answer is $P(G_2 \cap G_3) / P(G_1) = (0.1*0.1)/0.1 = 0.1$ Am I correct?","A hydraulic stucture has four gates which operate independently . The probability of failure of each gate is 0.1. Given that gate 1 has failed, what is the probability that gate 2 and gate 3 will fail ? I think the answer is Am I correct?",P(G_2 \cap G_3) / P(G_1) = (0.1*0.1)/0.1 = 0.1,"['probability', 'combinatorics', 'permutations', 'combinations']"
57,Variance of Sample Variance,Variance of Sample Variance,,"Given $X_1,...,X_n$ iid to a certain distribution (not necessarily normal), with $\mathbb{E}(X_i)=\mu$ and $\mathbb{V}(X_i)=\sigma^2$ , I'm trying to deduce the standard and mean squared error of the estimator $\widehat{\sigma}^2=S_n^2$ , where $S_n^2$ is the sample variance, given by $$ S_n^2=\frac{1}{n-1}\sum_{i=1}^n(X_i-\overline{X}_n)^2. $$ To do so I need its variance, $\mathbb{V}(S_n^2)$ . Since I know the expectation $\mathbb{E}(S_n^2)=\sigma^2$ , I started by expanding $$ \mathbb{V}(S_n^2)=\mathbb{E}(S_n^4)-(\mathbb{E}(S_n^2))^2=\mathbb{E}(S_n^4)-\sigma^4 $$ but I'm stuck with the expansion of the term $\mathbb{E}(S_n^4)$ . Any ideas? P.S. - I saw user940 's answer on this question , but I was looking for a different approach, also not assuming normal distributed random variables.","Given iid to a certain distribution (not necessarily normal), with and , I'm trying to deduce the standard and mean squared error of the estimator , where is the sample variance, given by To do so I need its variance, . Since I know the expectation , I started by expanding but I'm stuck with the expansion of the term . Any ideas? P.S. - I saw user940 's answer on this question , but I was looking for a different approach, also not assuming normal distributed random variables.","X_1,...,X_n \mathbb{E}(X_i)=\mu \mathbb{V}(X_i)=\sigma^2 \widehat{\sigma}^2=S_n^2 S_n^2 
S_n^2=\frac{1}{n-1}\sum_{i=1}^n(X_i-\overline{X}_n)^2.
 \mathbb{V}(S_n^2) \mathbb{E}(S_n^2)=\sigma^2 
\mathbb{V}(S_n^2)=\mathbb{E}(S_n^4)-(\mathbb{E}(S_n^2))^2=\mathbb{E}(S_n^4)-\sigma^4
 \mathbb{E}(S_n^4)","['probability', 'statistics', 'statistical-inference']"
58,Expected number of items looked at,Expected number of items looked at,,"Currently failing at basic probability… Given a sequence of items, linear search means looking at each in turn and seeing if it's the one we're looking for. (I.e. in the worst case, it's the last item in the sequence or not in the sequence at all and we'll have to look at all items to find it/determine it's not there.) How many elements of the input sequence need to be checked on average, assuming that the element being searched for is equally likely to be any element in the array? Ok, we know two things: the element we're looking for is in the array P[the i-th item is the one we're looking for] = $\frac{1}{n}$ for all $i\in\{1,..,n\}$ And I think I'm supposed to get $\frac{n+1}{2}$ or $\frac{n}{2}$ or something thereabout. Let $X$ be the number of items the linear search algorithm is looking at. $$\begin{align} P[X=1] &= \frac{1}{n} \\ P[X=2] &= \left(1-\frac{1}{n}\right)\frac{1}{n} \\ P[X=3] &= \left(1-\frac{1}{n}\right)^2\frac{1}{n} \\ & \ \ \vdots \\ \end{align}$$ So $$\begin{align} \mathbb{E}(X) &= \sum_{i=1}^n i\left(1-\frac{1}{n}\right)^{i-1}\frac{1}{n} \\ &= \frac{1}{n}\sum_{i=1}^n i\left(1-\frac{1}{n}\right)^{i-1} \\ \end{align}$$ That's not something I want to solve myself, so I gave it to Wolfram Alpha and got $$\left(1-2\left(\frac{n-1}{n}\right)^n\right)n$$ This doesn't look particularly close. Where did I go wrong?","Currently failing at basic probability… Given a sequence of items, linear search means looking at each in turn and seeing if it's the one we're looking for. (I.e. in the worst case, it's the last item in the sequence or not in the sequence at all and we'll have to look at all items to find it/determine it's not there.) How many elements of the input sequence need to be checked on average, assuming that the element being searched for is equally likely to be any element in the array? Ok, we know two things: the element we're looking for is in the array P[the i-th item is the one we're looking for] = $\frac{1}{n}$ for all $i\in\{1,..,n\}$ And I think I'm supposed to get $\frac{n+1}{2}$ or $\frac{n}{2}$ or something thereabout. Let $X$ be the number of items the linear search algorithm is looking at. $$\begin{align} P[X=1] &= \frac{1}{n} \\ P[X=2] &= \left(1-\frac{1}{n}\right)\frac{1}{n} \\ P[X=3] &= \left(1-\frac{1}{n}\right)^2\frac{1}{n} \\ & \ \ \vdots \\ \end{align}$$ So $$\begin{align} \mathbb{E}(X) &= \sum_{i=1}^n i\left(1-\frac{1}{n}\right)^{i-1}\frac{1}{n} \\ &= \frac{1}{n}\sum_{i=1}^n i\left(1-\frac{1}{n}\right)^{i-1} \\ \end{align}$$ That's not something I want to solve myself, so I gave it to Wolfram Alpha and got $$\left(1-2\left(\frac{n-1}{n}\right)^n\right)n$$ This doesn't look particularly close. Where did I go wrong?",,"['probability', 'algorithms', 'sorting']"
59,Counting outcomes for coin tosses,Counting outcomes for coin tosses,,"Don't laugh, this is a dumb question, but my brain just doesn't work mathematically.  A question in my math class says A coin is tossed 4 times.  Compute the probability of at least 2 tails   occurring. OK, so I know I figure out how many total events are in the sample, then figure out how many possible ways at least 2 tails are occurring, and divide.  My problem is, I can NEVER seem to figure out how many total events there are!  I start with HHHH, HHHT, HHTH, HTHH, and so on, but I always get lost somewhere along the way, miss an event, and never get them all.  My book says there are 16 different possibilities.  Is there a better way of figuring out how many different events could happen??","Don't laugh, this is a dumb question, but my brain just doesn't work mathematically.  A question in my math class says A coin is tossed 4 times.  Compute the probability of at least 2 tails   occurring. OK, so I know I figure out how many total events are in the sample, then figure out how many possible ways at least 2 tails are occurring, and divide.  My problem is, I can NEVER seem to figure out how many total events there are!  I start with HHHH, HHHT, HHTH, HTHH, and so on, but I always get lost somewhere along the way, miss an event, and never get them all.  My book says there are 16 different possibilities.  Is there a better way of figuring out how many different events could happen??",,['probability']
60,How do I show a random variable converges in probability?,How do I show a random variable converges in probability?,,"I've been given the following problem: For $n \in \mathbb{N}^{*}$ , let $X_{n}$ be a random variable such that $\mathbb{P} \left[ X_{n} = \frac{1}{n} \right] = 1 - \frac{1}{n^{2}}$ and $\mathbb{P} \left[ X_{n} = n \right] = \frac{1}{n^{2}}$ . Does $X_{n}$ converge in probability? And the definition I've been given for convergence in probability of a random variable is: Let $\left( T_{n} \right)_{n \geq 1}$ be a sequence of r.v. and $T$ a r.v. ( $T$ may be deterministic). Then: $T_{n}\overset{\mathbb{P}}{\underset{n \rightarrow \infty}\rightarrow} T$ if and only if $\mathbb{P} \left[ \left| T_{n} - T \right| \geq \epsilon \right] {\underset{n \rightarrow \infty}\rightarrow} 0$ , for all $\epsilon > 0$ . But I don't understand how to apply this definition to the problem. I'm not even sure what I'm supposed to be seeing if $X_{n}$ is converging to. We have no $X$ as far as I can see. Can anyone give me some insight on this?","I've been given the following problem: For , let be a random variable such that and . Does converge in probability? And the definition I've been given for convergence in probability of a random variable is: Let be a sequence of r.v. and a r.v. ( may be deterministic). Then: if and only if , for all . But I don't understand how to apply this definition to the problem. I'm not even sure what I'm supposed to be seeing if is converging to. We have no as far as I can see. Can anyone give me some insight on this?",n \in \mathbb{N}^{*} X_{n} \mathbb{P} \left[ X_{n} = \frac{1}{n} \right] = 1 - \frac{1}{n^{2}} \mathbb{P} \left[ X_{n} = n \right] = \frac{1}{n^{2}} X_{n} \left( T_{n} \right)_{n \geq 1} T T T_{n}\overset{\mathbb{P}}{\underset{n \rightarrow \infty}\rightarrow} T \mathbb{P} \left[ \left| T_{n} - T \right| \geq \epsilon \right] {\underset{n \rightarrow \infty}\rightarrow} 0 \epsilon > 0 X_{n} X,"['probability', 'statistics', 'convergence-divergence']"
61,Can $Y$ and $\frac{X}{Y}$ be uncorrelated if neither $X$ or $Y$ is constant?,Can  and  be uncorrelated if neither  or  is constant?,Y \frac{X}{Y} X Y,"Suppose I have two variables $X$ and $Y$ with $Y>0$.  Can the random variables $Y$ and $\frac{X}{Y}$ ever be uncorrelated, i.e., $$\mathbb{E}(X)=\mathbb{E}(Y)\mathbb{E}\left(\frac{X}{Y}\right).$$  This seems counterintuitive since both are dependent on $Y$.  But I just want to make sure there is not some weird case I am not thinking of. Actually, I just realized as I type that this is true if $X$ or $Y$ is a constant.  How about in cases other than constant $X$ or $Y$ then? I guess this question simplifies to what are the conditions for  $$\mathbb{E}\left(\frac{X}{Y}\right)=\frac{\mathbb{E}(X)}{\mathbb{E}(Y)}?$$","Suppose I have two variables $X$ and $Y$ with $Y>0$.  Can the random variables $Y$ and $\frac{X}{Y}$ ever be uncorrelated, i.e., $$\mathbb{E}(X)=\mathbb{E}(Y)\mathbb{E}\left(\frac{X}{Y}\right).$$  This seems counterintuitive since both are dependent on $Y$.  But I just want to make sure there is not some weird case I am not thinking of. Actually, I just realized as I type that this is true if $X$ or $Y$ is a constant.  How about in cases other than constant $X$ or $Y$ then? I guess this question simplifies to what are the conditions for  $$\mathbb{E}\left(\frac{X}{Y}\right)=\frac{\mathbb{E}(X)}{\mathbb{E}(Y)}?$$",,"['probability', 'probability-theory', 'random-variables', 'expectation']"
62,Convergence in distribution then in probability,Convergence in distribution then in probability,,"If $X_n$ $\rightarrow$ $c$ in distribution, then $X_n$ $\rightarrow$ $c$ in probability. How do I show this? I thought convergence in probability implied convergence in distribution?","If $X_n$ $\rightarrow$ $c$ in distribution, then $X_n$ $\rightarrow$ $c$ in probability. How do I show this? I thought convergence in probability implied convergence in distribution?",,"['probability', 'convergence-divergence']"
63,Flipping fair coin -,Flipping fair coin -,,"Examining an event. Let's say we flip a fair coin many times. Let's say 1.000.000 times. We know that even though each flip is not connected, influenced by past or future flips, in the long run each side heads or tails will end up approximately around 500.000 ( 50/50 event - theory of equilibrium) My question is: What price ranges can the difference take between heads and tails throughout the 1.000.000 flips?  For example, if we could see the results at 1892 flips we may have witnessed a "" 70 "" difference ( 981 Heads over 911 Tails). Or maybe if we could see the results at 15250 flips we may have witnessed a "" 6 "" difference ( 7622 Heads over 7628 Tails) So... What could be considered a normal difference range? $\pm 70$? $\pm50$?  And what could be considered an EXTREME RARE difference range somewhere in the flips? $\pm500$ $\pm2000$? $\pm10.000$?","Examining an event. Let's say we flip a fair coin many times. Let's say 1.000.000 times. We know that even though each flip is not connected, influenced by past or future flips, in the long run each side heads or tails will end up approximately around 500.000 ( 50/50 event - theory of equilibrium) My question is: What price ranges can the difference take between heads and tails throughout the 1.000.000 flips?  For example, if we could see the results at 1892 flips we may have witnessed a "" 70 "" difference ( 981 Heads over 911 Tails). Or maybe if we could see the results at 15250 flips we may have witnessed a "" 6 "" difference ( 7622 Heads over 7628 Tails) So... What could be considered a normal difference range? $\pm 70$? $\pm50$?  And what could be considered an EXTREME RARE difference range somewhere in the flips? $\pm500$ $\pm2000$? $\pm10.000$?",,['probability']
64,How does conditional expectation allow us to condition on zero-probability events?,How does conditional expectation allow us to condition on zero-probability events?,,"Can someone explain and provide example(s) of where we need to appeal/use conditional expectation to determine a conditional probability given a zero-probability event has occurred? I've seen books describe something like $E[X|Y]$ as allowing us to derive such conditional probabilities, which are not amenable to the usual $P(A|B)=\frac{P(A\cap B)}{P(B)}$ since $P(B)=0$....","Can someone explain and provide example(s) of where we need to appeal/use conditional expectation to determine a conditional probability given a zero-probability event has occurred? I've seen books describe something like $E[X|Y]$ as allowing us to derive such conditional probabilities, which are not amenable to the usual $P(A|B)=\frac{P(A\cap B)}{P(B)}$ since $P(B)=0$....",,['probability']
65,What is the difference between a field and a sigma field? [closed],What is the difference between a field and a sigma field? [closed],,Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 9 years ago . Improve this question Can someone explain what is the smallest sigma field? I need to know this Thanks,Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 9 years ago . Improve this question Can someone explain what is the smallest sigma field? I need to know this Thanks,,['probability']
66,Choosing something of $0$ probability,Choosing something of  probability,0,"First of all, i am only a newbie and i am pretty sure that my thinking is faulty somewhere, so along the way as i explain things i will probably say something with an error and i hope you will help me find this error. This idea has been bogging me for some time already. Imagine picking a random real number. Without the loss of generality, let the picking interval be $(0,1)$ , or $<0,1>$ . Now, since there is an infinite amount of real numbers, the probability of choosing one specific number is $0$ . Yet, we have to pick one number when choosing randomly, let's say it's $0.5$ . We have now picked a number that had $0$ chance to be picked. How is this possible? Thank you for all the answers, i have had hard time deciding what to pick as ""correct"" answer as i came seeking answers. EDIT: Recently, i saw these Binomial Distributions video series and this video explains it pretty well","First of all, i am only a newbie and i am pretty sure that my thinking is faulty somewhere, so along the way as i explain things i will probably say something with an error and i hope you will help me find this error. This idea has been bogging me for some time already. Imagine picking a random real number. Without the loss of generality, let the picking interval be , or . Now, since there is an infinite amount of real numbers, the probability of choosing one specific number is . Yet, we have to pick one number when choosing randomly, let's say it's . We have now picked a number that had chance to be picked. How is this possible? Thank you for all the answers, i have had hard time deciding what to pick as ""correct"" answer as i came seeking answers. EDIT: Recently, i saw these Binomial Distributions video series and this video explains it pretty well","(0,1) <0,1> 0 0.5 0",['probability']
67,Intuition/Real-life Examples: Pairwise Independence vs (Mutual) Independence,Intuition/Real-life Examples: Pairwise Independence vs (Mutual) Independence,,"Would someone please advance/discuss some real-life situations falsities $1, 2$? I'd like to intuit why these are false. As a neophyte, since I still need to compute the probabilities for the examples in the two answers to apprehend them, I haven't naturalised these concepts yet. Thus, I beg leave to ask about other real-life examples which require less or no computations. I tried and would appreciate less numerical examples than http://notesofastatisticswatcher.wordpress.com/2012/01/02/pairwise-independence-does-not-imply-mutual-independence/ and http://econ.la.psu.edu/~hbierens/INDEPENDENCE.PDF , and  Examples 1.22 and 1.23 on P39 of Introduction to Pr by Bertsekas. $1.$ Pairwise Independence $\require{cancel} \cancel{\implies}$ (Mutual) Independence. $2.$ Pairwise Independence $\require{cancel} \cancel{\Longleftarrow}$ (Mutual) Independence. P38 defines (Mutual) Independence :    For all $S \subseteq \{1, ..., n - 1, n\} $ and events $A_i$, $Pr(\cap_{i \in S} A_i) = \Pi_{i \in S} A_i.$","Would someone please advance/discuss some real-life situations falsities $1, 2$? I'd like to intuit why these are false. As a neophyte, since I still need to compute the probabilities for the examples in the two answers to apprehend them, I haven't naturalised these concepts yet. Thus, I beg leave to ask about other real-life examples which require less or no computations. I tried and would appreciate less numerical examples than http://notesofastatisticswatcher.wordpress.com/2012/01/02/pairwise-independence-does-not-imply-mutual-independence/ and http://econ.la.psu.edu/~hbierens/INDEPENDENCE.PDF , and  Examples 1.22 and 1.23 on P39 of Introduction to Pr by Bertsekas. $1.$ Pairwise Independence $\require{cancel} \cancel{\implies}$ (Mutual) Independence. $2.$ Pairwise Independence $\require{cancel} \cancel{\Longleftarrow}$ (Mutual) Independence. P38 defines (Mutual) Independence :    For all $S \subseteq \{1, ..., n - 1, n\} $ and events $A_i$, $Pr(\cap_{i \in S} A_i) = \Pi_{i \in S} A_i.$",,['probability']
68,Expected number of steps in a random walk with a boundary,Expected number of steps in a random walk with a boundary,,"Let's say I am trying to climb a flight of $N$ stairs. Each time I want to take a step, I flip a fair coin. Heads means I take a step up; tails means I take a step down. If I'm at the bottom of the stairs, tails means I flip the coin again. How many total times do I flip the coin , on average, before I reach the top? This process is like a 1-D random walk except for the bottom-of-the-stairs condition, so I would expect the answer to involve $N^2$ somehow, but I don't know how to compute it exactly.","Let's say I am trying to climb a flight of $N$ stairs. Each time I want to take a step, I flip a fair coin. Heads means I take a step up; tails means I take a step down. If I'm at the bottom of the stairs, tails means I flip the coin again. How many total times do I flip the coin , on average, before I reach the top? This process is like a 1-D random walk except for the bottom-of-the-stairs condition, so I would expect the answer to involve $N^2$ somehow, but I don't know how to compute it exactly.",,"['probability', 'random-walk']"
69,Median for continuous distribution,Median for continuous distribution,,"Consider a continuous random variable X with probability density function given by $f(x)=cx$ for $1 \le x \le 5$ , zero otherwise.  Find the median. First I calculate the CDF: $F(x)=cx^2/2$ for $1 \le x \le 5$ , zero otherwise. Now we have to solve for constant c by using the definition of PDF, namely: $$\int\limits_{-\infty}^{\infty}f(x)dx=1 \implies \frac{c}{2}x^2\Big{|}_1^5=1 \implies c=\frac{1}{12} $$ Then to calculate the median, we set the CDF = 0.5: $$\frac{1}{2}=\frac{1}{12}\cdot \frac{1}{2} \cdot x^2 \implies x=\sqrt{12}$$ But the book solution is $\sqrt{13}$ .  Can someone tell me what I am doing wrong? Thank you.","Consider a continuous random variable X with probability density function given by for , zero otherwise.  Find the median. First I calculate the CDF: for , zero otherwise. Now we have to solve for constant c by using the definition of PDF, namely: Then to calculate the median, we set the CDF = 0.5: But the book solution is .  Can someone tell me what I am doing wrong? Thank you.",f(x)=cx 1 \le x \le 5 F(x)=cx^2/2 1 \le x \le 5 \int\limits_{-\infty}^{\infty}f(x)dx=1 \implies \frac{c}{2}x^2\Big{|}_1^5=1 \implies c=\frac{1}{12}  \frac{1}{2}=\frac{1}{12}\cdot \frac{1}{2} \cdot x^2 \implies x=\sqrt{12} \sqrt{13},"['probability', 'statistics']"
70,Proof that $\frac{(\bar X-\mu)}{\sigma}$ and $\sum_{i=1}^n\frac{(X_i-\bar X)^2}{\sigma^2}$ are independent,Proof that  and  are independent,\frac{(\bar X-\mu)}{\sigma} \sum_{i=1}^n\frac{(X_i-\bar X)^2}{\sigma^2},"Let $X_i\sim N(\mu,\sigma^2)$ ; where$[i=1,2,\ldots,n]$ $Z_i\sim N(0,1)$ ; where$[i=1,2,\ldots,n]$ Proof that $\bar Z=\frac{(\bar X-\mu)}{\sigma}$ and $\sum_{i=1}^{n}(Z_i-\bar Z)^2=\sum_{i=1}^n\frac{(X_i-\bar X)^2}{\sigma^2}$ are independent, which implies $\bar X$ and $\sum_{i=1}^n(X_i-\bar X)^2$ are independent. MY ATTEMPT: I considered $n=2$, and $$M_{X_1+X_2}(t_1)=M_{X_1}(t_1)M_{X_2}(t_1)$$ $\ast$I did so for the proof but does the statement $X_i\sim N(\mu,\sigma^2)$ ; where$[i=1,2,\ldots,n]$ imply that $X_i's$ are independent? Moment Generating Function of $X_1+X_2$ and $X_1-X_2$  are $$M_{X_1+X_2}(t_1)=e^{2\mu t_1+\sigma^2 t_1^2}$$ $$M_{X_1-X_2}(t_2)=e^{\sigma^2 t_2^2}$$ respectively. Also, $$M_{X_1+X_2,X_1-X_2}(t_1,t_2)=e^{2\mu t_1+\sigma^2 t_1^2}e^{\sigma^2 t_2^2}=M_{X_1+X_2}(t_1)M_{X_1-X_2}(t_2)$$ since the joint moment generating function factors into the product of the marginal moment generating functions, so $X_1+X_2$ and $X_1-X_2$  are independent which implies that: $\bullet$ Since $\bar Z=\frac{(\bar X-\mu)}{\sigma}$ is only a function of $X_1+X_2$ and $\sum_{i=1}^{2}(Z_i-\bar Z)^2=\sum_{i=1}^2\frac{(X_i-\bar X)^2}{\sigma^2}$ is only a function of $X_1-X_2$ ,so $\bar Z=\frac{(\bar X-\mu)}{\sigma}$ and $\sum_{i=1}^{n}(Z_i-\bar Z)^2=\sum_{i=1}^n\frac{(X_i-\bar X)^2}{\sigma^2}$ are independent. $\bullet$ Since $\bar X$ is only a function of $X_1+X_2$ and $S^2=\frac{1}{2-1}\sum_{i=1}^2(X_i-\bar X)^2$ is only a function of $X_1-X_2$ ,so Sample mean,$\bar X$ and sample variance,$S^2$ are independent. $\diamond\diamond\diamond$ We accept the above independence for any arbitrary $n$ . Is the procedure correct?","Let $X_i\sim N(\mu,\sigma^2)$ ; where$[i=1,2,\ldots,n]$ $Z_i\sim N(0,1)$ ; where$[i=1,2,\ldots,n]$ Proof that $\bar Z=\frac{(\bar X-\mu)}{\sigma}$ and $\sum_{i=1}^{n}(Z_i-\bar Z)^2=\sum_{i=1}^n\frac{(X_i-\bar X)^2}{\sigma^2}$ are independent, which implies $\bar X$ and $\sum_{i=1}^n(X_i-\bar X)^2$ are independent. MY ATTEMPT: I considered $n=2$, and $$M_{X_1+X_2}(t_1)=M_{X_1}(t_1)M_{X_2}(t_1)$$ $\ast$I did so for the proof but does the statement $X_i\sim N(\mu,\sigma^2)$ ; where$[i=1,2,\ldots,n]$ imply that $X_i's$ are independent? Moment Generating Function of $X_1+X_2$ and $X_1-X_2$  are $$M_{X_1+X_2}(t_1)=e^{2\mu t_1+\sigma^2 t_1^2}$$ $$M_{X_1-X_2}(t_2)=e^{\sigma^2 t_2^2}$$ respectively. Also, $$M_{X_1+X_2,X_1-X_2}(t_1,t_2)=e^{2\mu t_1+\sigma^2 t_1^2}e^{\sigma^2 t_2^2}=M_{X_1+X_2}(t_1)M_{X_1-X_2}(t_2)$$ since the joint moment generating function factors into the product of the marginal moment generating functions, so $X_1+X_2$ and $X_1-X_2$  are independent which implies that: $\bullet$ Since $\bar Z=\frac{(\bar X-\mu)}{\sigma}$ is only a function of $X_1+X_2$ and $\sum_{i=1}^{2}(Z_i-\bar Z)^2=\sum_{i=1}^2\frac{(X_i-\bar X)^2}{\sigma^2}$ is only a function of $X_1-X_2$ ,so $\bar Z=\frac{(\bar X-\mu)}{\sigma}$ and $\sum_{i=1}^{n}(Z_i-\bar Z)^2=\sum_{i=1}^n\frac{(X_i-\bar X)^2}{\sigma^2}$ are independent. $\bullet$ Since $\bar X$ is only a function of $X_1+X_2$ and $S^2=\frac{1}{2-1}\sum_{i=1}^2(X_i-\bar X)^2$ is only a function of $X_1-X_2$ ,so Sample mean,$\bar X$ and sample variance,$S^2$ are independent. $\diamond\diamond\diamond$ We accept the above independence for any arbitrary $n$ . Is the procedure correct?",,"['probability', 'statistics', 'generating-functions', 'statistical-inference', 'sampling']"
71,Conditional probabilities from a joint density function,Conditional probabilities from a joint density function,,"The joint density function of two continuos random variables $X$ and $Y$ is given by: $f(x,y) = 8xy$ if $0\le y\le x\le 1$ and $0$ otherwise. Calculate $P(X \le \frac{1}{2})$ Calculate $P(Y \le \frac{1}{4} \mid X = \frac{1}{2})$ Calculate the expected value of $Y^3$ if $X = \frac{1}{2}$ I would just like to check whether I am solving these questions in the right way. For question a), I think you first need to derive the marginal density function for $X$. However, I am unsure whether I obtain this by integrating over from $0$ to $x$ or from $0$ to $1$ (which one is correct and why?). Also, I wasnt entirely sure about how to do b, could anyone show me how that probability would be obtained?. I think I can do c, however, for it to be correct, I first need te correct answer to question a. Could anyone please help me out?","The joint density function of two continuos random variables $X$ and $Y$ is given by: $f(x,y) = 8xy$ if $0\le y\le x\le 1$ and $0$ otherwise. Calculate $P(X \le \frac{1}{2})$ Calculate $P(Y \le \frac{1}{4} \mid X = \frac{1}{2})$ Calculate the expected value of $Y^3$ if $X = \frac{1}{2}$ I would just like to check whether I am solving these questions in the right way. For question a), I think you first need to derive the marginal density function for $X$. However, I am unsure whether I obtain this by integrating over from $0$ to $x$ or from $0$ to $1$ (which one is correct and why?). Also, I wasnt entirely sure about how to do b, could anyone show me how that probability would be obtained?. I think I can do c, however, for it to be correct, I first need te correct answer to question a. Could anyone please help me out?",,['probability']
72,Expected length of arc in a randomly divided circle,Expected length of arc in a randomly divided circle,,"Choose, at random, three points on the unit circle. Interpret them as cuts that divide the circle into three arcs. Compute the expected length of the arc that contains the point (1, 0). Generalise for N points.","Choose, at random, three points on the unit circle. Interpret them as cuts that divide the circle into three arcs. Compute the expected length of the arc that contains the point (1, 0). Generalise for N points.",,['probability']
73,When is the sum of first $n$ numbers equal to the sum of the next $k$ numbers?,When is the sum of first  numbers equal to the sum of the next  numbers?,n k,"When is the sum $1+2+\cdots + n = (n+1) + (n+2) + \cdots +(n+k)$? The easiest solution $(n,k)$ is $(2,1)$. For example, $1+2 = 3$. Do any others exist? Roots of $(n+k)^2 + (n+k) = 2n^2 +2n$ give solutions (Is this solvable via a Pell equation?) If a complete graph has red($n$) and blue($k$) nodes, and I pick an edge at random; the probability of picking one that connects two red vertices is $1/2$, find the number of blue and red nodes. This may be trivial but I really have no clue so I ask the pros. A (sort of) variation on the first problem of ""Fifty Challenging problems in probability with solutions"" Frederick Mosteller.","When is the sum $1+2+\cdots + n = (n+1) + (n+2) + \cdots +(n+k)$? The easiest solution $(n,k)$ is $(2,1)$. For example, $1+2 = 3$. Do any others exist? Roots of $(n+k)^2 + (n+k) = 2n^2 +2n$ give solutions (Is this solvable via a Pell equation?) If a complete graph has red($n$) and blue($k$) nodes, and I pick an edge at random; the probability of picking one that connects two red vertices is $1/2$, find the number of blue and red nodes. This may be trivial but I really have no clue so I ask the pros. A (sort of) variation on the first problem of ""Fifty Challenging problems in probability with solutions"" Frederick Mosteller.",,"['probability', 'number-theory', 'diophantine-equations', 'graphing-functions', 'integer-partitions']"
74,Expected number of steps to transform a permutation to the identity,Expected number of steps to transform a permutation to the identity,,"Start from an identity permutation P=[1,2,3,4,5], each step  choose two random integers k and l in [1,5]. Then swap  P[k] and P[l]. Stop the process until P again becomes  identity. Observe that the expected number of steps  is 120. I can not prove it theoretically. Please guide me.","Start from an identity permutation P=[1,2,3,4,5], each step  choose two random integers k and l in [1,5]. Then swap  P[k] and P[l]. Stop the process until P again becomes  identity. Observe that the expected number of steps  is 120. I can not prove it theoretically. Please guide me.",,['probability']
75,Tossing a fair coin until two consecutive tosses are the same,Tossing a fair coin until two consecutive tosses are the same,,A fair coin is tossed repeatedly and independently until two consecutive heads or two consecutive tails appear. What is the PMF of the number of tosses ?,A fair coin is tossed repeatedly and independently until two consecutive heads or two consecutive tails appear. What is the PMF of the number of tosses ?,,"['probability', 'probability-distributions']"
76,"What's the probability of ""at least"" and ""exactly"" one event occurring?","What's the probability of ""at least"" and ""exactly"" one event occurring?",,"If I know the probability of event $A$ occurring and I also know the probability of $B$ occurring, how can I calculate the probability of "" at least one of them "" occurring? I was thinking that this is $P(A \text{ or } B) = P(A) + P(B) - P(A \text{ and }B)$. Is this correct? If it is, then how can I solve the following problem taken from DeGroot's Probability and Statistics : If $50$ percent of families in a certain city subscribe to the morning newspaper, $65$ percent of the families subscribe to the afternoon newspaper, and $85$ percent of the families subscribe to at least one of the two newspapers, what proportion of the families subscribe to both newspapers? In a more mathematical language, we are given $P(\text{morning})=.5$, $P(\text{afternoon})=.65$, $P(\text{morning or afternoon}) = .5 + .65 - P(\text{morning and afternoon}) = .85$, which implies that $P(\text{morning and afternoon}) = .3$, which should be the answer to the question. Is my reasoning correct? If it is correct, how can I calculate the following? If the probability that student $A$ will fail a certain statistics examination is $0.5$, the probability that student $B$ will fail the examination is $0.2$, and the probability that both student $A$ and student $B$ will fail the examination is $0.1$, what is the probability that exactly one of the two students will fail the examination? These problems and questions highlight the difference between ""at least one of them"" and ""exactly one of them"". Provided that ""at least one of them"" is equivalent to $P(A \text{ or } B)$, but how can I work out the probability of ""exactly one of them""?","If I know the probability of event $A$ occurring and I also know the probability of $B$ occurring, how can I calculate the probability of "" at least one of them "" occurring? I was thinking that this is $P(A \text{ or } B) = P(A) + P(B) - P(A \text{ and }B)$. Is this correct? If it is, then how can I solve the following problem taken from DeGroot's Probability and Statistics : If $50$ percent of families in a certain city subscribe to the morning newspaper, $65$ percent of the families subscribe to the afternoon newspaper, and $85$ percent of the families subscribe to at least one of the two newspapers, what proportion of the families subscribe to both newspapers? In a more mathematical language, we are given $P(\text{morning})=.5$, $P(\text{afternoon})=.65$, $P(\text{morning or afternoon}) = .5 + .65 - P(\text{morning and afternoon}) = .85$, which implies that $P(\text{morning and afternoon}) = .3$, which should be the answer to the question. Is my reasoning correct? If it is correct, how can I calculate the following? If the probability that student $A$ will fail a certain statistics examination is $0.5$, the probability that student $B$ will fail the examination is $0.2$, and the probability that both student $A$ and student $B$ will fail the examination is $0.1$, what is the probability that exactly one of the two students will fail the examination? These problems and questions highlight the difference between ""at least one of them"" and ""exactly one of them"". Provided that ""at least one of them"" is equivalent to $P(A \text{ or } B)$, but how can I work out the probability of ""exactly one of them""?",,['probability']
77,"Probability of ""clock patience"" going out","Probability of ""clock patience"" going out",,"Here is a question I've often wondered about, but have never figured out a satisfactory answer for. Here are the rules for the solitaire game ""clock patience."" Deal out 12 piles of 4 cards each with an extra 4 card draw pile. (From a standard 52 card deck.) Turn over the first card in the draw pile, and place it under the pile corresponding to that card's number 1-12 interpreted as Ace through Queen. Whenever you get a king you place that on the side and draw another card from the pile. The game goes out if you turn over every card in the 12 piles, and the game ends if you get four kings before this happens. My question is what is the probability that this game goes out? One thought I had is that the answer could be one in thirteen, the chances that the last card of a 52 card sequence is a king. Although this seems plausible, I doubt it's correct, mainly because I've played the game probably dozens of times since I was a kid, and have never gone out! Any light that people could shed on this problem would be appreciated!","Here is a question I've often wondered about, but have never figured out a satisfactory answer for. Here are the rules for the solitaire game ""clock patience."" Deal out 12 piles of 4 cards each with an extra 4 card draw pile. (From a standard 52 card deck.) Turn over the first card in the draw pile, and place it under the pile corresponding to that card's number 1-12 interpreted as Ace through Queen. Whenever you get a king you place that on the side and draw another card from the pile. The game goes out if you turn over every card in the 12 piles, and the game ends if you get four kings before this happens. My question is what is the probability that this game goes out? One thought I had is that the answer could be one in thirteen, the chances that the last card of a 52 card sequence is a king. Although this seems plausible, I doubt it's correct, mainly because I've played the game probably dozens of times since I was a kid, and have never gone out! Any light that people could shed on this problem would be appreciated!",,['probability']
78,Thought experiment for dice game,Thought experiment for dice game,,"Two players in a dice game to see who can roll a total of 60 first, taking turns each rolling 2 dice. For one player, one die is 4 sided and one is 6 sided. Therefore the average roll for this player will be a 6. The other player has two 6 sided dice. So this players average roll will be a 7. If they take turns, each rolling both dice, what % of the time will the first player (a 4-6 dice combo) get to 60 first and what % of the time will the second player (6-6 dice combo) get to 60 first. If they get to 60 on the same roll, the player who goes the furthest wins.","Two players in a dice game to see who can roll a total of 60 first, taking turns each rolling 2 dice. For one player, one die is 4 sided and one is 6 sided. Therefore the average roll for this player will be a 6. The other player has two 6 sided dice. So this players average roll will be a 7. If they take turns, each rolling both dice, what % of the time will the first player (a 4-6 dice combo) get to 60 first and what % of the time will the second player (6-6 dice combo) get to 60 first. If they get to 60 on the same roll, the player who goes the furthest wins.",,"['probability', 'probability-theory', 'dice']"
79,Maximum probability without the Optimal strategy,Maximum probability without the Optimal strategy,,"I've been stuck on this problem for a good 2 days now, I don't feel any closer to solving it. It reads: ""Pick a natural number between $0$ and $100$ inclusive; denote this number as $\mathit{n}$ . Define a process that terminates at either $0$ or $100+$ : For each iteration of this process, define $\mathit{l}$ to be a positive integer which is at most the current $\mathit{n}$ . Then, with probability $\frac{1}{5}$ , increment $\mathit{n}$ by the chosen $\mathit{l}$ instead. With probability $\frac{4}{5}$ , decrement $\mathit{n}$ by the chosen $\mathit{l}$ . Given that the strategy used to raise $\mathit{n}$ to $100+$ is optimal, find the probability that the process terminates at $100+$ rather than $0$ when you start at $\mathit{n}= 20$ ."" I believe I understand what this problem is asking, but I don't quite know where to begin! More specifically, I'm not sure about two things: What the optimal strategy might be, and how I would calculate probability from there. I would love to share what I've tried, but I've been so lost that I have next to nothing to share. If I let $p(\mathit{n})$ be the probability that I get to $100$ or more from $\mathit{n}$ , I've reasoned that it's related to $\frac{1}{5}p(n+l)+\frac{4}{5}p(n-l)$ . Considering that I don't know how they're related, you could say that I'm pretty stumped!","I've been stuck on this problem for a good 2 days now, I don't feel any closer to solving it. It reads: ""Pick a natural number between and inclusive; denote this number as . Define a process that terminates at either or : For each iteration of this process, define to be a positive integer which is at most the current . Then, with probability , increment by the chosen instead. With probability , decrement by the chosen . Given that the strategy used to raise to is optimal, find the probability that the process terminates at rather than when you start at ."" I believe I understand what this problem is asking, but I don't quite know where to begin! More specifically, I'm not sure about two things: What the optimal strategy might be, and how I would calculate probability from there. I would love to share what I've tried, but I've been so lost that I have next to nothing to share. If I let be the probability that I get to or more from , I've reasoned that it's related to . Considering that I don't know how they're related, you could say that I'm pretty stumped!",0 100 \mathit{n} 0 100+ \mathit{l} \mathit{n} \frac{1}{5} \mathit{n} \mathit{l} \frac{4}{5} \mathit{n} \mathit{l} \mathit{n} 100+ 100+ 0 \mathit{n}= 20 p(\mathit{n}) 100 \mathit{n} \frac{1}{5}p(n+l)+\frac{4}{5}p(n-l),['probability']
80,Heat Kernel on a compact manifold without boundary [closed],Heat Kernel on a compact manifold without boundary [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question I was wondering if the conservation of mass which is obvious for the heat equation in $\mathbb{R}^n$ holds also for the heat kernel in a general compact manifold without boundary. I mean I want to know if the heat kernel generally satisfies $$\int dx K(x,y,t)=1$$ If so, may I have some references to look at? Thanks in advance","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question I was wondering if the conservation of mass which is obvious for the heat equation in holds also for the heat kernel in a general compact manifold without boundary. I mean I want to know if the heat kernel generally satisfies If so, may I have some references to look at? Thanks in advance","\mathbb{R}^n \int dx K(x,y,t)=1","['probability', 'manifolds', 'heat-equation', 'regularization']"
81,8 Indistinguishable objects randomly sorted into six buckets - What is the probability of at least three buckets receiving the objects?,8 Indistinguishable objects randomly sorted into six buckets - What is the probability of at least three buckets receiving the objects?,,"Eight indistinguishable objects are to be randomly put into six buckets. What is the probability that at least three buckets will receive the objects? My approach was to let X= the number of buckets that receive objects, and then the required probability is $P(X≥3) = 1- P(X=1) - P(X=2)$ $= 1 - [(6C1)(1/6)^8 + (6C2)(2/6)^8]$ $= 0.99771$ My reasoning was that for all of the objects falling into one bucket, there are 6 possible buckets $(6C1)$ , and the probability for eight objects to fall into the same bucket in a row is $(1/6)^8 $ By the same logic, for all of the objects to be divided into two of the six buckets, there are $(6C2)$ possible ways to choose those two buckets...And the probability is $(2/6)^8 $ . Then, the probability that at least three buckets will receive objects is 1- (the probability of only one bucket receiving all the objects + two buckets receiving all the objects) However, the answer given to this question was 0.8904.  Where am I going wrong, and is there a better way to approach questions like this? Does it fall into any specific discrete distribution? Note : I also tried $1- [(6C1)(1/6)^8] - (6C2)[(1/6)^7(5/6) + (1/6)^6(5/6)^2 + (1/6)^5(5/6)^3 + (1/6)^4(5/6)^4 + (1/6)^3(5/6)^5 + (1/6)^2(5/6)^6 + (1/6)(5/6)^7]$ And got $0.8721$ . I am not sure if this approach is better.","Eight indistinguishable objects are to be randomly put into six buckets. What is the probability that at least three buckets will receive the objects? My approach was to let X= the number of buckets that receive objects, and then the required probability is My reasoning was that for all of the objects falling into one bucket, there are 6 possible buckets , and the probability for eight objects to fall into the same bucket in a row is By the same logic, for all of the objects to be divided into two of the six buckets, there are possible ways to choose those two buckets...And the probability is . Then, the probability that at least three buckets will receive objects is 1- (the probability of only one bucket receiving all the objects + two buckets receiving all the objects) However, the answer given to this question was 0.8904.  Where am I going wrong, and is there a better way to approach questions like this? Does it fall into any specific discrete distribution? Note : I also tried And got . I am not sure if this approach is better.",P(X≥3) = 1- P(X=1) - P(X=2) = 1 - [(6C1)(1/6)^8 + (6C2)(2/6)^8] = 0.99771 (6C1) (1/6)^8  (6C2) (2/6)^8  1- [(6C1)(1/6)^8] - (6C2)[(1/6)^7(5/6) + (1/6)^6(5/6)^2 + (1/6)^5(5/6)^3 + (1/6)^4(5/6)^4 + (1/6)^3(5/6)^5 + (1/6)^2(5/6)^6 + (1/6)(5/6)^7] 0.8721,"['probability', 'combinatorics', 'statistics', 'balls-in-bins']"
82,"Prove if $P(A \cup B) \le P(A \cap B)$, then $P(A) = P(B)$.","Prove if , then .",P(A \cup B) \le P(A \cap B) P(A) = P(B),"I am unsure if my thought process for proving this inequality is correct. This is what I have so far: $$ P(A \cup B) = P(A) + P(B) - P(A \cap B) ≤ P(A \cap B) $$ $$ P(A) + P(B) \le 2  P(A \cap B) $$ $$ P(A) + P(B) \le 2 P(A) P(B) $$ and in order for the last line to be possible, $P(A)$ and $P(B)$ have to be $0$ , thus $P(A) = P(B)$ . This doesn't seem right because I feel like there should be more cases than just $0$ for this inequality to be true and I was wondering if anyone could help guide me in the right direction.","I am unsure if my thought process for proving this inequality is correct. This is what I have so far: and in order for the last line to be possible, and have to be , thus . This doesn't seem right because I feel like there should be more cases than just for this inequality to be true and I was wondering if anyone could help guide me in the right direction.","
P(A \cup B) = P(A) + P(B) - P(A \cap B) ≤ P(A \cap B)
 
P(A) + P(B) \le 2  P(A \cap B)
 
P(A) + P(B) \le 2 P(A) P(B)
 P(A) P(B) 0 P(A) = P(B) 0","['probability', 'probability-theory']"
83,$E(X \mid X > x)$ is increasing in $x$. Why?,is increasing in . Why?,E(X \mid X > x) x,"For two points $x < x'$ and a random variable $X$ , we must have $E(X\mid X > x )\leq E(X\mid X > x' )$ . This is ""obviously"" true because the center of the truncated distribution shifts to the right. How do I prove that? I tried working with an iid copy $X^*$ of $X$ to show that the expectation of $X1(X>x)1(X^*>x')$ is smaller than the expectation of $X1(X>x')1(X^*>x)$ but I'm not having any luck with that. All results I can find either focus on normality or assume densities.","For two points and a random variable , we must have . This is ""obviously"" true because the center of the truncated distribution shifts to the right. How do I prove that? I tried working with an iid copy of to show that the expectation of is smaller than the expectation of but I'm not having any luck with that. All results I can find either focus on normality or assume densities.",x < x' X E(X\mid X > x )\leq E(X\mid X > x' ) X^* X X1(X>x)1(X^*>x') X1(X>x')1(X^*>x),"['probability', 'probability-theory', 'probability-distributions', 'conditional-expectation']"
84,Why is $P(a \text{ and } b)$ maximized when $P(a \text{ or } b)$ is minimized?,Why is  maximized when  is minimized?,P(a \text{ and } b) P(a \text{ or } b),"I can't seem to wrap my head around why $P(a \text{ and } b)$ is minimized when $P(a \text{ or } b)$ is maximized. This comes from PIE: $$P(a \text{ or } b) = P(A) + P(B) - P(a \text{ and } b).$$ Can someone please explain the intuition behind this? I'm even trying to picture the Venn diagram in my head, but this exact relationship doesn't make sense.","I can't seem to wrap my head around why is minimized when is maximized. This comes from PIE: Can someone please explain the intuition behind this? I'm even trying to picture the Venn diagram in my head, but this exact relationship doesn't make sense.",P(a \text{ and } b) P(a \text{ or } b) P(a \text{ or } b) = P(A) + P(B) - P(a \text{ and } b).,['probability']
85,Show that $\lim_{n\rightarrow \infty}\frac{\mathsf {Var}[Y_1 + \dots + Y_n]}{n^2} = 0.$,Show that,\lim_{n\rightarrow \infty}\frac{\mathsf {Var}[Y_1 + \dots + Y_n]}{n^2} = 0.,"Let $(X_n)_{n=1}^{\infty}$ be a sequence of pairwise independent, identically distributed random variables with finite mean. Let $Y_n = X_n\mathbf1\{{|X_n| \leq n\}}$ , then $$ \sum_{n=1}^{\infty} P(Y_n \neq X_n) = \sum_{n=1}^{\infty} P(|X_n| >n)  = \sum_{n=1}^{\infty} P(|X_1|>n) \leq \mathbb{E}[|X_1|] < \infty. $$ Hence from Borel-Cantelli lemma $\lim_{n\rightarrow \infty}\frac{X_1 + \dots + X_n}{n} = \mathbb{E}[X_1]~a.s$ if and only if $\lim_{n\rightarrow \infty}\frac{Y_1 + \dots + Y_n]}{n} = \mathbb{E}[X_1]~a.s.$ Now I have to show that $\lim_{n\rightarrow \infty}\frac{\mathsf {Var}[Y_1 + \dots + Y_n]}{n^2} = 0$ , unfortunately I don't know how. I would really appreciate any hints or tips.","Let be a sequence of pairwise independent, identically distributed random variables with finite mean. Let , then Hence from Borel-Cantelli lemma if and only if Now I have to show that , unfortunately I don't know how. I would really appreciate any hints or tips.",(X_n)_{n=1}^{\infty} Y_n = X_n\mathbf1\{{|X_n| \leq n\}}  \sum_{n=1}^{\infty} P(Y_n \neq X_n) = \sum_{n=1}^{\infty} P(|X_n| >n)  = \sum_{n=1}^{\infty} P(|X_1|>n) \leq \mathbb{E}[|X_1|] < \infty.  \lim_{n\rightarrow \infty}\frac{X_1 + \dots + X_n}{n} = \mathbb{E}[X_1]~a.s \lim_{n\rightarrow \infty}\frac{Y_1 + \dots + Y_n]}{n} = \mathbb{E}[X_1]~a.s. \lim_{n\rightarrow \infty}\frac{\mathsf {Var}[Y_1 + \dots + Y_n]}{n^2} = 0,"['probability', 'probability-theory']"
86,Find stationary distribution for infinite space Markov chain,Find stationary distribution for infinite space Markov chain,,"Let their be a Markov chain on state space $S = \{0,1,2,...\}$. Transition probabilities are given as: $p_{0,1} = 1$, $p_{i,i+1} = p$, $p_{i+1, i} = q$ where $0<p,q<1$ and $p+q=1$. For $p<q$ , I need to find the stationary distribution (say $\pi$) of this Markov chain. I got the balance equations: $$\pi_{0}  =q.\pi_{1}$$ $$\pi_{i} = p.\pi_{i-1}+ q.\pi_{i+1}$$ and normalization conditoin: $$\sum_{i=0}^{\infty}\pi_{i} = 1$$ Using these relations, how can I get the stationary distribution?","Let their be a Markov chain on state space $S = \{0,1,2,...\}$. Transition probabilities are given as: $p_{0,1} = 1$, $p_{i,i+1} = p$, $p_{i+1, i} = q$ where $0<p,q<1$ and $p+q=1$. For $p<q$ , I need to find the stationary distribution (say $\pi$) of this Markov chain. I got the balance equations: $$\pi_{0}  =q.\pi_{1}$$ $$\pi_{i} = p.\pi_{i-1}+ q.\pi_{i+1}$$ and normalization conditoin: $$\sum_{i=0}^{\infty}\pi_{i} = 1$$ Using these relations, how can I get the stationary distribution?",,"['probability', 'markov-chains']"
87,Probability Problem Solving,Probability Problem Solving,,"Red, yellow and blue counters are placed on a board as shown, and they ‘race’ to the finish (F) by moving up one square at a time. The moves are determined by picking a bead at random from a bag containing one red bead, two yellow beads and three blue beads. After the colour of the bead which has been drawn is noted, the bead is returned to the bag before the next bead is picked. The race is over as soon as one of the counters lands on the square marked F. Find the probability of winning for each of the counters. So far, I have only been able to figure out the basics of probability of red>probability of yellow>probability of blue. My estimate is that: Probability of red winning = 4/9 Probability of yellow winning 1/4 Probability of blue winning = 11/36 What do you guys think?","Red, yellow and blue counters are placed on a board as shown, and they ‘race’ to the finish (F) by moving up one square at a time. The moves are determined by picking a bead at random from a bag containing one red bead, two yellow beads and three blue beads. After the colour of the bead which has been drawn is noted, the bead is returned to the bag before the next bead is picked. The race is over as soon as one of the counters lands on the square marked F. Find the probability of winning for each of the counters. So far, I have only been able to figure out the basics of probability of red>probability of yellow>probability of blue. My estimate is that: Probability of red winning = 4/9 Probability of yellow winning 1/4 Probability of blue winning = 11/36 What do you guys think?",,"['probability', 'problem-solving']"
88,Probability that no three consecutive heads occur,Probability that no three consecutive heads occur,,"Suppose we flip a fair coin $n$ times, what is the probability that no three consecutive heads occur? I understand the proof for the case with no two consecutive heads, where we can consider the number of sequences that start with $H$ and $T$ and get the recurrence relations $$F(n+1) = F(n) + F(n-1) $$ where $F(n)$ is the number of sequences with no consecutive heads which leads to $$Q_n = \frac{1}{2}Q_{n-1} + \frac{1}{4}Q_{n-2}$$ However, I'm having trouble extending to the case of no three consecutive heads. What would the recurrence relations be for the number of sequences?","Suppose we flip a fair coin $n$ times, what is the probability that no three consecutive heads occur? I understand the proof for the case with no two consecutive heads, where we can consider the number of sequences that start with $H$ and $T$ and get the recurrence relations $$F(n+1) = F(n) + F(n-1) $$ where $F(n)$ is the number of sequences with no consecutive heads which leads to $$Q_n = \frac{1}{2}Q_{n-1} + \frac{1}{4}Q_{n-2}$$ However, I'm having trouble extending to the case of no three consecutive heads. What would the recurrence relations be for the number of sequences?",,[]
89,Confidence interval interpretation difficulty,Confidence interval interpretation difficulty,,"I have seen a lot of questions in this forum related to what my question is, but I didn't find any convincing answer. So I would to like to put this question: When we are dealing with 95% confidence interval we mean that if we repeat process of collecting samples of same size and calculate 95% intervals for those samples then 95% of those intervals will contain the true population parameter. Let the infinite number of intervals be represented by 100 for simplicity. Then 95 of these intervals will contain true population parameter. Suppose we got an interval at the starting of the above process (L,U).  Then if I ask what is the probability that this interval (L,U) contains the true population parameter then shouldn't it be 95/100 = 0.95? (Because this interval (L,U) can be anyone of 100 and it would contain true population parameter of its one of those 95). But this interpretation of confidence interval is considered incorrect. Can someone explain me why is this so?","I have seen a lot of questions in this forum related to what my question is, but I didn't find any convincing answer. So I would to like to put this question: When we are dealing with 95% confidence interval we mean that if we repeat process of collecting samples of same size and calculate 95% intervals for those samples then 95% of those intervals will contain the true population parameter. Let the infinite number of intervals be represented by 100 for simplicity. Then 95 of these intervals will contain true population parameter. Suppose we got an interval at the starting of the above process (L,U).  Then if I ask what is the probability that this interval (L,U) contains the true population parameter then shouldn't it be 95/100 = 0.95? (Because this interval (L,U) can be anyone of 100 and it would contain true population parameter of its one of those 95). But this interpretation of confidence interval is considered incorrect. Can someone explain me why is this so?",,"['probability', 'probability-theory', 'confidence-interval']"
90,Conditional Expectation of Gaussian Random Vector of length n,Conditional Expectation of Gaussian Random Vector of length n,,"I am trying to prove the following: Let $(X_1,\dots,X_n)$ be a Gaussian vector with mean 0 and covariance matrix B.  Find the distribution of $E(X_1\mid X_2,\dots,X_n).$ I know in general for two Gaussian r.v. $X_1$ and $X_2$ we can show that $f_{X_1|X_2} (x_1|x_2) = \frac{1}{\sigma_{X_1} \sqrt{2 \pi (1-\rho^2)}}\exp\frac{(-(x_{1}- \rho(\sigma_{X_1}/ \sigma_{X_2})x_2)^2)}{2 \sigma^{2}_{X_1}(1- \rho^{2})}$ where $\rho$ is the correlation and $E(X_{1}|X_{2})=\int x_{1} f_{X_1|X_2} (x_1|x_2)dx_{1}.  $ How can I generalize this for a gaussian random vector of size $n$?  Can I conclude on the distribution of $E(X_1|X_2,...X_n)$ based on the form of $f_{X_1|X_2,\dots,X_n} (x_1|x_2,\dots,x_n)$?  For example, in the case of 2 Gaussian r.v we produce a normal r.v with variance $2 \sigma^{2}_{X_1}(1- \rho^{2})$ and mean $\rho(\sigma_{X_1}/ \sigma_{X_2})x_2$.","I am trying to prove the following: Let $(X_1,\dots,X_n)$ be a Gaussian vector with mean 0 and covariance matrix B.  Find the distribution of $E(X_1\mid X_2,\dots,X_n).$ I know in general for two Gaussian r.v. $X_1$ and $X_2$ we can show that $f_{X_1|X_2} (x_1|x_2) = \frac{1}{\sigma_{X_1} \sqrt{2 \pi (1-\rho^2)}}\exp\frac{(-(x_{1}- \rho(\sigma_{X_1}/ \sigma_{X_2})x_2)^2)}{2 \sigma^{2}_{X_1}(1- \rho^{2})}$ where $\rho$ is the correlation and $E(X_{1}|X_{2})=\int x_{1} f_{X_1|X_2} (x_1|x_2)dx_{1}.  $ How can I generalize this for a gaussian random vector of size $n$?  Can I conclude on the distribution of $E(X_1|X_2,...X_n)$ based on the form of $f_{X_1|X_2,\dots,X_n} (x_1|x_2,\dots,x_n)$?  For example, in the case of 2 Gaussian r.v we produce a normal r.v with variance $2 \sigma^{2}_{X_1}(1- \rho^{2})$ and mean $\rho(\sigma_{X_1}/ \sigma_{X_2})x_2$.",,"['probability', 'probability-theory', 'random-variables']"
91,strange duel chances and my analysis,strange duel chances and my analysis,,"There is two guy, A and B they are shooting each other by turns, A shoot first, A has 30 percent chances to shoot and kill B and 70 percent to miss, B has 50 percent chances to kill A and 50 percent to miss.  A takes the first shot. So I first encounter this kind of questions, here is my analysis: first attempt: I think A has 30 percent to kill B, then if he succeed, then he will not die, so his prob of death is 0, but if he missed, next round B will take the gun, so A can see he might die at next round is 70 percent of miss multiply 50 percent of B's shot, which equas to 35 percent, then next round......... Don't laugh I realized this is an endless loop and you don't know when the game will over because it's a probability game, of course my statistics grade in my school is so bad... next attempt: So I try to understand this thing, normally if I am in this duel I would like to take first shot, I don't know why, cause if I am lucky and shoot that motherfucker to death at first round then I don't have to worry about dying, so I think the person first shoot has some advantage? I don't do any calculation at this attempt. last attempt: Okay I feel the person first shoot has some advantages somehow but I don't really know, so I choose to ignore it and some how I figured an equation like $$\dfrac{\dfrac1{0.3}}{\dfrac1{0.3}+\dfrac1{0.5}}$$ as B's chance of winning? I feel it's not right either... It's really some tough question, cuz I never encounter this thing before, and it seems easy but I can't find the direction to solve it, anyone can help a brother out? thx!","There is two guy, A and B they are shooting each other by turns, A shoot first, A has 30 percent chances to shoot and kill B and 70 percent to miss, B has 50 percent chances to kill A and 50 percent to miss.  A takes the first shot. So I first encounter this kind of questions, here is my analysis: first attempt: I think A has 30 percent to kill B, then if he succeed, then he will not die, so his prob of death is 0, but if he missed, next round B will take the gun, so A can see he might die at next round is 70 percent of miss multiply 50 percent of B's shot, which equas to 35 percent, then next round......... Don't laugh I realized this is an endless loop and you don't know when the game will over because it's a probability game, of course my statistics grade in my school is so bad... next attempt: So I try to understand this thing, normally if I am in this duel I would like to take first shot, I don't know why, cause if I am lucky and shoot that motherfucker to death at first round then I don't have to worry about dying, so I think the person first shoot has some advantage? I don't do any calculation at this attempt. last attempt: Okay I feel the person first shoot has some advantages somehow but I don't really know, so I choose to ignore it and some how I figured an equation like $$\dfrac{\dfrac1{0.3}}{\dfrac1{0.3}+\dfrac1{0.5}}$$ as B's chance of winning? I feel it's not right either... It's really some tough question, cuz I never encounter this thing before, and it seems easy but I can't find the direction to solve it, anyone can help a brother out? thx!",,"['probability', 'statistics', 'simulation']"
92,Maximizing expected value of coin reveal game,Maximizing expected value of coin reveal game,,"I was asked this question today in an interview and am still not sure of the answer. The question is as follows. Part one:  Say I have flipped 100 coins already and they are hidden to you. Now I reveal these coins one by one and you are to guess if it is heads or tails before I reveal the coin. If you get it correct, you get $\$1$. If you get it incorrect, you get $\$0$. I will allow you to ask me one yes or no question about the sequence for free. What will it be to maximize your profit? My approach for this part of the problem was to ask if there were more heads than tails. If they say yes, I will just guess all heads otherwise I just guess all tails. I know the expected value for this should be greater than 50 but is it possible to calculate the exact value for this? If so, how would you do it? Part two: Same scenario as before but now I will charge for a question. I will allow you to ask me any amount of yes or no questions as I go through this process for $\$1$. What is your strategy to maximize your profit? I was not sure about the answer to this part of the question. Would the best option be to guess randomly? I think the expected value of this should be 50. I am not sure about the expected value of part one but if it is greater than 51, I think I could also use that approach. Anyone have a good idea for this part?","I was asked this question today in an interview and am still not sure of the answer. The question is as follows. Part one:  Say I have flipped 100 coins already and they are hidden to you. Now I reveal these coins one by one and you are to guess if it is heads or tails before I reveal the coin. If you get it correct, you get $\$1$. If you get it incorrect, you get $\$0$. I will allow you to ask me one yes or no question about the sequence for free. What will it be to maximize your profit? My approach for this part of the problem was to ask if there were more heads than tails. If they say yes, I will just guess all heads otherwise I just guess all tails. I know the expected value for this should be greater than 50 but is it possible to calculate the exact value for this? If so, how would you do it? Part two: Same scenario as before but now I will charge for a question. I will allow you to ask me any amount of yes or no questions as I go through this process for $\$1$. What is your strategy to maximize your profit? I was not sure about the answer to this part of the question. Would the best option be to guess randomly? I think the expected value of this should be 50. I am not sure about the expected value of part one but if it is greater than 51, I think I could also use that approach. Anyone have a good idea for this part?",,"['probability', 'statistics']"
93,How many throws of a die until every possible result is obtained? [duplicate],How many throws of a die until every possible result is obtained? [duplicate],,"This question already has answers here : Expected time to roll all $1$ through $6$ on a die (3 answers) Closed 8 years ago . A die is thrown until every possible result (i.e., every integer from 1 to 6) is obtained. Find the expected value of the number of throws. How do I do that? I understand that probability for the single result is $\{1, 5/6, \ldots , 1/6\}$, but what about the expected value?","This question already has answers here : Expected time to roll all $1$ through $6$ on a die (3 answers) Closed 8 years ago . A die is thrown until every possible result (i.e., every integer from 1 to 6) is obtained. Find the expected value of the number of throws. How do I do that? I understand that probability for the single result is $\{1, 5/6, \ldots , 1/6\}$, but what about the expected value?",,"['probability', 'combinatorics', 'expectation']"
94,The 3rd raw moment of a binomial distribution,The 3rd raw moment of a binomial distribution,,"What is the 3rd raw moment (that is, $ E\{X^3\} $) of a Binomial distribution with parameters $n$ and $p$? I am getting $n(n-1)(n-2)p^3 + 3n(n-1)p^2 + np$. Is it correct?","What is the 3rd raw moment (that is, $ E\{X^3\} $) of a Binomial distribution with parameters $n$ and $p$? I am getting $n(n-1)(n-2)p^3 + 3n(n-1)p^2 + np$. Is it correct?",,"['probability', 'probability-distributions', 'binomial-distribution']"
95,Limit distribution of infinite sum of Bernoulli random variables,Limit distribution of infinite sum of Bernoulli random variables,,"I know that the finite sum of Bernoulli i.i.d. random variables is a binomial distribution, but what is the distribution of $$\lim_{n \to \infty}\sum_{k=1}^{n} \frac{x_k}{2^k}$$ where $x_k$ is a Bernoulli random variable with parameter $\frac12$?","I know that the finite sum of Bernoulli i.i.d. random variables is a binomial distribution, but what is the distribution of $$\lim_{n \to \infty}\sum_{k=1}^{n} \frac{x_k}{2^k}$$ where $x_k$ is a Bernoulli random variable with parameter $\frac12$?",,"['probability', 'probability-theory', 'probability-distributions']"
96,Linear combination of independent poisson random variables,Linear combination of independent poisson random variables,,"We know that if $X_1$  and $X_2$ are independent random variables such that  $ X_1 \sim \text{Poisson}(\lambda_1) $ and $X_2 \sim \text{Poisson}(\lambda_2)$ that $X_1+X_2 \sim \text{Poisson}(\lambda_1+\lambda_2)$ Is there any result about a linear combination of two independent poisson random variables $a_{1} X_1+a_2 X_2$ where $a_1, a_2 \in \mathcal{R}$?","We know that if $X_1$  and $X_2$ are independent random variables such that  $ X_1 \sim \text{Poisson}(\lambda_1) $ and $X_2 \sim \text{Poisson}(\lambda_2)$ that $X_1+X_2 \sim \text{Poisson}(\lambda_1+\lambda_2)$ Is there any result about a linear combination of two independent poisson random variables $a_{1} X_1+a_2 X_2$ where $a_1, a_2 \in \mathcal{R}$?",,"['probability', 'statistics', 'stochastic-processes', 'poisson-distribution']"
97,Suggestion: good book on probability theory with emphasis on applications to other areas of mathematics and physics,Suggestion: good book on probability theory with emphasis on applications to other areas of mathematics and physics,,"On this website, there are many questions about books on probability theory, but I would like to ask if you can suggest a book (or more than one if necessary) that is: rigorous and accurate according to modern standards; complete: from basic concepts and ideas to really advanced material; rich of useful applications of techniques and ideas of probability theory to other branches of mathematics and physics.","On this website, there are many questions about books on probability theory, but I would like to ask if you can suggest a book (or more than one if necessary) that is: rigorous and accurate according to modern standards; complete: from basic concepts and ideas to really advanced material; rich of useful applications of techniques and ideas of probability theory to other branches of mathematics and physics.",,"['probability', 'probability-theory', 'reference-request', 'soft-question', 'book-recommendation']"
98,What is the probability that $HH$ occurs before $TH$ in an infinte sequence of coin flips?,What is the probability that  occurs before  in an infinte sequence of coin flips?,HH TH,"This is one of the questions of a set of exam review questions that don't have solutions to them. I can't get my head around this but it seems so simple. By flipping a fair coin repeatedly and independently, we obtain a sequence of   H's and T's. We stop flipping the coin as soon as the sequence contains either HH or TH.   Two players play a game, in which Player 1 wins if the last two symbols in the sequence   are HH. Otherwise, the last two symbols in the sequence are TH, in which case Player 2   wins. A = ""Player 1 wins""   and   B = ""Player 2 wins."" Determine Pr(A) and Pr(B)","This is one of the questions of a set of exam review questions that don't have solutions to them. I can't get my head around this but it seems so simple. By flipping a fair coin repeatedly and independently, we obtain a sequence of   H's and T's. We stop flipping the coin as soon as the sequence contains either HH or TH.   Two players play a game, in which Player 1 wins if the last two symbols in the sequence   are HH. Otherwise, the last two symbols in the sequence are TH, in which case Player 2   wins. A = ""Player 1 wins""   and   B = ""Player 2 wins."" Determine Pr(A) and Pr(B)",,['probability']
99,What is the actual meaning of runs in terms of coin tossing?,What is the actual meaning of runs in terms of coin tossing?,,"I am not able to understand the concept of runs in terms of coin tossing. As per my question, suppose a coin is tossed x times, then we have to find the expected number of runs. But, what is a run? Can anybody give a detailed example? As per the question, the sequence of tosses HHHHTTHTTTHHHTHH has 7 runs. How? I am really not able to understand. I researched and found somewhere that a run is when the previous outcome is different from current, so for this case, how will it apply? Can somebody please explain in layman terms? Thanks","I am not able to understand the concept of runs in terms of coin tossing. As per my question, suppose a coin is tossed x times, then we have to find the expected number of runs. But, what is a run? Can anybody give a detailed example? As per the question, the sequence of tosses HHHHTTHTTTHHHTHH has 7 runs. How? I am really not able to understand. I researched and found somewhere that a run is when the previous outcome is different from current, so for this case, how will it apply? Can somebody please explain in layman terms? Thanks",,['probability']
