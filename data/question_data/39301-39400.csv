,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Involutions and Abelian Groups,Involutions and Abelian Groups,,"Suppose that $ G $ is a finite group where at least three-fourths of the elements are involutions, i.e., $$ |I(G)| \geq \frac{3}{4} |G|. $$ (Here, $ I(G) $ denotes the set of all involutions of $ G $, where an involution of $ G $ is defined as a group element of order $ 2 $.) (1) Suppose that $ A $ and $ B $ are subsets of a finite set $ S $. Show that $ |A \cap B| \geq |A| + |B| - |S| $. (2) Let $ x \in I(G) $. Show that $ |I(G) \cap x[I(G)]| \geq \dfrac{1}{2} |G| $. (3) Let $ x \in I(G) $. Show that $ \{ 1_{G} \} \cup \{ g \in I(G) ~|~ xg \in I(G) \} \subseteq {C_{G}}(x) $. (4) Use your answers to (1)-(3) to conclude that $ G $ is an abelian group.","Suppose that $ G $ is a finite group where at least three-fourths of the elements are involutions, i.e., $$ |I(G)| \geq \frac{3}{4} |G|. $$ (Here, $ I(G) $ denotes the set of all involutions of $ G $, where an involution of $ G $ is defined as a group element of order $ 2 $.) (1) Suppose that $ A $ and $ B $ are subsets of a finite set $ S $. Show that $ |A \cap B| \geq |A| + |B| - |S| $. (2) Let $ x \in I(G) $. Show that $ |I(G) \cap x[I(G)]| \geq \dfrac{1}{2} |G| $. (3) Let $ x \in I(G) $. Show that $ \{ 1_{G} \} \cup \{ g \in I(G) ~|~ xg \in I(G) \} \subseteq {C_{G}}(x) $. (4) Use your answers to (1)-(3) to conclude that $ G $ is an abelian group.",,"['abstract-algebra', 'combinatorics', 'group-theory']"
1,Every normal subgroup of a finite group is contained in some composition series,Every normal subgroup of a finite group is contained in some composition series,,"In this context composition series means the same thing as defined here. As the title says given a finite group $G$ and $H \unlhd G$ I would like to show there is a composition series containing $H.$ Following is my attempt at it. The main argument of the claim is showing the following. Lemma. If $H \unlhd G$ and $G/H$ is not simple then there exist a subgroup $I$ such that $H \unlhd I \unlhd G.$ The proof follows from the 4th isomorphism theorem since if $G/H$ is not simple then there is a normal subgroup $\overline{I} \unlhd G/H$ of the form $\overline{I} = H/I.$ Suppose now that $G/H$ is not simple. Using the above lemma we deduce that there exist a finite chain of groups (since $G$ is finite) such that $$H \unlhd I_1 \unlhd \cdots \unlhd I_k \unlhd G$$ and $G/I_k$ is simple. Now one has to repeat this process for all other pairs $I_{i+1}/I_{i}$ and for $I_1/H$ until the quotients are simple groups. This is all fine since all the subgroups are finite as well. Now if $H$ is simple we are done otherwise there is a group $J \unlhd H$ and we inductively construct the composition for $H.$ Is the above ""proof"" correct? If so, is there a way to make it less messy?","In this context composition series means the same thing as defined here. As the title says given a finite group and I would like to show there is a composition series containing Following is my attempt at it. The main argument of the claim is showing the following. Lemma. If and is not simple then there exist a subgroup such that The proof follows from the 4th isomorphism theorem since if is not simple then there is a normal subgroup of the form Suppose now that is not simple. Using the above lemma we deduce that there exist a finite chain of groups (since is finite) such that and is simple. Now one has to repeat this process for all other pairs and for until the quotients are simple groups. This is all fine since all the subgroups are finite as well. Now if is simple we are done otherwise there is a group and we inductively construct the composition for Is the above ""proof"" correct? If so, is there a way to make it less messy?",G H \unlhd G H. H \unlhd G G/H I H \unlhd I \unlhd G. G/H \overline{I} \unlhd G/H \overline{I} = H/I. G/H G H \unlhd I_1 \unlhd \cdots \unlhd I_k \unlhd G G/I_k I_{i+1}/I_{i} I_1/H H J \unlhd H H.,"['abstract-algebra', 'group-theory', 'finite-groups', 'simple-groups']"
2,Why does $\mathbb{C}$ have transcendence degree $\mathfrak{c}$ over $\mathbb{Q}$?,Why does  have transcendence degree  over ?,\mathbb{C} \mathfrak{c} \mathbb{Q},"It's pretty well known that $\text{trdeg}(\mathbb{C}/\mathbb{Q})=\mathfrak{c}=|\mathbb{C}|$. As a subset of $\mathbb{C}$, of course the degree cannot be any greater than $\mathfrak{c}$. I'm trying to understand the justification why it cannot be any smaller. The explanation in my book says that if $\mathbb{C}$ has an at most countable (i.e. finite or countable) transcendence basis $z_1,z_2,\dots$ over $\mathbb{Q}$, then $\mathbb{C}$ is algebraic over $\mathbb{Q}(z_1,z_2,\dots)$. Since a polynomial over $\mathbb{Q}$ can be identified as a finite sequence of rationals, it follows that $|\mathbb{C}|=|\mathbb{Q}|$, a contradiction. I don't see why the polynomial part comes in? I'm know things like a countable unions/products of countable sets is countable, but could someone please explain in more detail this part about the polynomial approach? Since $\mathbb{C}$ is algebraic over $\mathbb{Q}(z_1,z_2,\dots)$, does that just mean that any complex number can be written as a polynomial in the $z_i$ with coefficients in $\mathbb{Q}$? For example, $$ \alpha=q_1z_1^3z_4z_6^5+q_2z_{11}+q_3z^{12}_{19}+\cdots+q_nz_6z_8z^4_{51}? $$ Is the point just that the set of all such polynomials are countable? Thanks,","It's pretty well known that $\text{trdeg}(\mathbb{C}/\mathbb{Q})=\mathfrak{c}=|\mathbb{C}|$. As a subset of $\mathbb{C}$, of course the degree cannot be any greater than $\mathfrak{c}$. I'm trying to understand the justification why it cannot be any smaller. The explanation in my book says that if $\mathbb{C}$ has an at most countable (i.e. finite or countable) transcendence basis $z_1,z_2,\dots$ over $\mathbb{Q}$, then $\mathbb{C}$ is algebraic over $\mathbb{Q}(z_1,z_2,\dots)$. Since a polynomial over $\mathbb{Q}$ can be identified as a finite sequence of rationals, it follows that $|\mathbb{C}|=|\mathbb{Q}|$, a contradiction. I don't see why the polynomial part comes in? I'm know things like a countable unions/products of countable sets is countable, but could someone please explain in more detail this part about the polynomial approach? Since $\mathbb{C}$ is algebraic over $\mathbb{Q}(z_1,z_2,\dots)$, does that just mean that any complex number can be written as a polynomial in the $z_i$ with coefficients in $\mathbb{Q}$? For example, $$ \alpha=q_1z_1^3z_4z_6^5+q_2z_{11}+q_3z^{12}_{19}+\cdots+q_nz_6z_8z^4_{51}? $$ Is the point just that the set of all such polynomials are countable? Thanks,",,"['abstract-algebra', 'field-theory']"
3,What is the deal with the three isomorphism theorems?,What is the deal with the three isomorphism theorems?,,"I've been having lectures in group theory with Hungerford's book. We were presented with the following theorem: And then with: Previous to the lectures about them, I was understanding most of the stuff, that is: I kinda could figure out the motivation for things. But when I came into these theorems, things got pretty weird for me. I don't understand the motivation for them. I have the following guesses: Theorem 5.6 is used to prove Corollary 5.7 but I think it has a utility on its own: If given an homomorphism $f: G \to H$ with $N\lhd G$ , we have a unique homomorphism $\overline{f} : G/N\to H$ , then we could use this to know what homomorphisms could exist betwen $G$ and $H$ and this depends only on the normal subgroups of $G$ . Does that make sense? For the isomorphism theorems, I noticed they are corollaries so they must be very important. One of the reasons I conjectured for them is that we can construct very interesting isomorphisms. But why are those isomorphisms interesting? It's not clear to me what interesting stuff one could do with them. I know my guesses are maybe too obvious or wrong, but I can't figure out on my own the answer to that question. Can you help me?","I've been having lectures in group theory with Hungerford's book. We were presented with the following theorem: And then with: Previous to the lectures about them, I was understanding most of the stuff, that is: I kinda could figure out the motivation for things. But when I came into these theorems, things got pretty weird for me. I don't understand the motivation for them. I have the following guesses: Theorem 5.6 is used to prove Corollary 5.7 but I think it has a utility on its own: If given an homomorphism with , we have a unique homomorphism , then we could use this to know what homomorphisms could exist betwen and and this depends only on the normal subgroups of . Does that make sense? For the isomorphism theorems, I noticed they are corollaries so they must be very important. One of the reasons I conjectured for them is that we can construct very interesting isomorphisms. But why are those isomorphisms interesting? It's not clear to me what interesting stuff one could do with them. I know my guesses are maybe too obvious or wrong, but I can't figure out on my own the answer to that question. Can you help me?",f: G \to H N\lhd G \overline{f} : G/N\to H G H G,['abstract-algebra']
4,Localization commutes with arbitrary direct sums,Localization commutes with arbitrary direct sums,,"Let $M_i$ be a arbitrary colection of $A$ -modules and $S$ a multiplicative subset of $A$ . I want to show that $$S^{-1}\left(\bigoplus_i M_i\right)\cong \bigoplus_i S^{-1}M_i$$ as $A$ -modules and as $S^{-1}A$ -modules. I know how to explicitly write an isomorphism between them but I want to do it using the universal properties to understand better how they work. Here's what I've done: Let $M=\bigoplus_i M_i$ with the canonical injections $\iota_i:M_i\to M$ . Also let $\Phi:M\to S^{-1}M$ be the canonical morphism associated with the localization. Composing these morphisms we get $$\Phi\circ\iota_i:M_i\to S^{-1}M.$$ By the universal property of the localization, we obtain a unique morphism $$\overline{\Phi\circ\iota_i}:S^{-1}M_i\to S^{-1}M$$ such that $\overline{\Phi\circ\iota_i}\circ\Phi_i=\Phi\circ\iota_i$ , where $\Phi_i:M_i\to S^{-1}M_i$ is the localization morphism. Finally, by the universal property of the coproduct we obtain a morphism $$\bigoplus_i S^{-1}M_i\to S^{-1}M.$$ I think this morphism might be the desired isomorphism but I don't know how to prove it. (Maybe a good idea would be to find its inverse but for it I need some kind of morphism $M\to M_i$ , which is not available when the direct sum is infinite.) Also, I know there are a couple questions here about similar things but they do either the explicit isomorphism or the finite case. Edit: after @GreginGre commentaries, I have a morphism $S^{-1}M\to S^{-1}M_i$ but I don't know neither how to obtain a morphism $S^{-1}M\to\bigoplus S^{-1}M_i$ (since this is the wrong side for the universal property of coproducts) nor how to show that these two morphisms are inverses of each other.","Let be a arbitrary colection of -modules and a multiplicative subset of . I want to show that as -modules and as -modules. I know how to explicitly write an isomorphism between them but I want to do it using the universal properties to understand better how they work. Here's what I've done: Let with the canonical injections . Also let be the canonical morphism associated with the localization. Composing these morphisms we get By the universal property of the localization, we obtain a unique morphism such that , where is the localization morphism. Finally, by the universal property of the coproduct we obtain a morphism I think this morphism might be the desired isomorphism but I don't know how to prove it. (Maybe a good idea would be to find its inverse but for it I need some kind of morphism , which is not available when the direct sum is infinite.) Also, I know there are a couple questions here about similar things but they do either the explicit isomorphism or the finite case. Edit: after @GreginGre commentaries, I have a morphism but I don't know neither how to obtain a morphism (since this is the wrong side for the universal property of coproducts) nor how to show that these two morphisms are inverses of each other.",M_i A S A S^{-1}\left(\bigoplus_i M_i\right)\cong \bigoplus_i S^{-1}M_i A S^{-1}A M=\bigoplus_i M_i \iota_i:M_i\to M \Phi:M\to S^{-1}M \Phi\circ\iota_i:M_i\to S^{-1}M. \overline{\Phi\circ\iota_i}:S^{-1}M_i\to S^{-1}M \overline{\Phi\circ\iota_i}\circ\Phi_i=\Phi\circ\iota_i \Phi_i:M_i\to S^{-1}M_i \bigoplus_i S^{-1}M_i\to S^{-1}M. M\to M_i S^{-1}M\to S^{-1}M_i S^{-1}M\to\bigoplus S^{-1}M_i,"['abstract-algebra', 'modules', 'localization', 'direct-sum']"
5,Normal Groups and Quotient Groups,Normal Groups and Quotient Groups,,"These concepts are currently confusing me. My reading first defined a normal subgroup as one that is the kernel of a group homomorphism. Then it introduced the terms ""left coset"" and ""right coset,"" which seem straightforward enough. The next definition was that of the index of a subgroup $[G:H]$. Then, it gave another definition of a normal subgroup (?), namely, one invariant under conjugation ($gNg^{-1} = N \,\,\forall \, g \in G$). Finally, it gave the following tortuous definition of a quotient group: The set of all left cosets of a normal subgroup $N$ with the law of composition $(gN)(hN) = (gh)N$ and having order $[G:N]$. Why are those definitions equivalent? And what does that last horrendous definition mean? I'd really appreciate it if someone could provide an intuitive/simple explanation of these terms.","These concepts are currently confusing me. My reading first defined a normal subgroup as one that is the kernel of a group homomorphism. Then it introduced the terms ""left coset"" and ""right coset,"" which seem straightforward enough. The next definition was that of the index of a subgroup $[G:H]$. Then, it gave another definition of a normal subgroup (?), namely, one invariant under conjugation ($gNg^{-1} = N \,\,\forall \, g \in G$). Finally, it gave the following tortuous definition of a quotient group: The set of all left cosets of a normal subgroup $N$ with the law of composition $(gN)(hN) = (gh)N$ and having order $[G:N]$. Why are those definitions equivalent? And what does that last horrendous definition mean? I'd really appreciate it if someone could provide an intuitive/simple explanation of these terms.",,"['abstract-algebra', 'group-theory']"
6,"Find the center of the group $\operatorname{GL}(n,\mathbb R)$ of invertible $n \times n$ matrices. [duplicate]",Find the center of the group  of invertible  matrices. [duplicate],"\operatorname{GL}(n,\mathbb R) n \times n","This question already has answers here : The Center of $\operatorname{GL}(n,k)$ (3 answers) Closed 10 years ago . Find the center of the group $\operatorname{GL}(n,\mathbb R)$ of invertible $n \times n$ matrices. Please can someone please help me? I know that by definition the center $Z$ of a group $G$ is defined by $Z(G) = \{g \in G\ |\ ag = ga ,\, \forall a \in G\}$ . I know that the identity matrix commutes with any matrix. I also notice by computing several matrix products that if we have a matrix with a main diagonal and all other entries are zero, then the given matrix commutes. In addition, I know that the determinant cannot be zero since zero times another matrix will only be zero. Please I would really appreciate the help. Thank you.","This question already has answers here : The Center of $\operatorname{GL}(n,k)$ (3 answers) Closed 10 years ago . Find the center of the group of invertible matrices. Please can someone please help me? I know that by definition the center of a group is defined by . I know that the identity matrix commutes with any matrix. I also notice by computing several matrix products that if we have a matrix with a main diagonal and all other entries are zero, then the given matrix commutes. In addition, I know that the determinant cannot be zero since zero times another matrix will only be zero. Please I would really appreciate the help. Thank you.","\operatorname{GL}(n,\mathbb R) n \times n Z G Z(G) = \{g \in G\ |\ ag = ga ,\, \forall a \in G\}","['abstract-algebra', 'group-theory']"
7,Definition of a nilpotent group.,Definition of a nilpotent group.,,"I saw two different definitions of a nilpotent group, but I'm not really sure how these definitions are equivalent. The first one is from Basic Abstract Algebra (Robert Ash): A central series for $G$ is a normal series $1 = G_0 \trianglelefteq G_1 \trianglelefteq ... \trianglelefteq G_r = G$ such that $G_i/G_{i-1} \subseteq Z(G/G_{i-1})$ for every $i = 1, ... ,r$ . An arbitrary group $G$ is said to be nilpotent if it has a central series. The second one is from Advanced Modern Algebra (Rotman): The descending central series of a group $G$ is $$ G = \gamma_1(G) \supseteq \gamma_2(G) \supseteq ...,$$ where $\gamma_{i+1}(G) = [\gamma_i(G),G].$ A group $G$ is called nilpotent if the lower central series reaches $\{1\}$ ; that is, if $\gamma_n(G)=\{1\}$ for some $n$ . I can't really see how these definitions are equivalent, because they are defining it in very different ways... so I would appreciate it if anybody could clarify this for me. Thanks in advance","I saw two different definitions of a nilpotent group, but I'm not really sure how these definitions are equivalent. The first one is from Basic Abstract Algebra (Robert Ash): A central series for is a normal series such that for every . An arbitrary group is said to be nilpotent if it has a central series. The second one is from Advanced Modern Algebra (Rotman): The descending central series of a group is where A group is called nilpotent if the lower central series reaches ; that is, if for some . I can't really see how these definitions are equivalent, because they are defining it in very different ways... so I would appreciate it if anybody could clarify this for me. Thanks in advance","G 1 = G_0 \trianglelefteq G_1 \trianglelefteq ... \trianglelefteq G_r = G G_i/G_{i-1} \subseteq Z(G/G_{i-1}) i = 1, ... ,r G G  G = \gamma_1(G) \supseteq \gamma_2(G) \supseteq ..., \gamma_{i+1}(G) = [\gamma_i(G),G]. G \{1\} \gamma_n(G)=\{1\} n",['abstract-algebra']
8,"These two group theory statements are ""the same""?","These two group theory statements are ""the same""?",,"Let $G$ be a group and $G'$ its commutator subgroup. Let $\pi: G\to G/G'$ be the natural projection. Statement 1: $G/G'$ is the largest Abelian quotient of $G$ in the sense that if $H\unlhd G$ and $G/H$ is Abelian, then $G'\le H$. Conversely, if $G'\le H$, then $H\unlhd G$ and $G/H$ is Abelian. Statement 2: If $\varphi:G\to A$ is any homomorphism of $G$ into an Abelian group $A$, then $\varphi$ factors through $G'$; i.e., $G'\le \ker{\varphi}$ and there is a homomorphism $\hat{\varphi}:G/G'\to A$ such that $\varphi(g) = (\hat{\varphi}\circ \pi)(g)$. (That is, we have a fancy commutative diagram.) This is from Dummit and Foote, p.169, Proposition 7. The proof of (1) is very straightforward. However, the authors claim that (1) is a restatement of (2) in terms of homomorphisms. Can anyone explain this? Because it is not clear to me. Also, if I wanted to prove (2) outright, what should the map $\hat{\varphi}$ be? My first thought was defining it as $\hat{\varphi}(aG')= \varphi(a)$, but I don't think this works. Thanks!","Let $G$ be a group and $G'$ its commutator subgroup. Let $\pi: G\to G/G'$ be the natural projection. Statement 1: $G/G'$ is the largest Abelian quotient of $G$ in the sense that if $H\unlhd G$ and $G/H$ is Abelian, then $G'\le H$. Conversely, if $G'\le H$, then $H\unlhd G$ and $G/H$ is Abelian. Statement 2: If $\varphi:G\to A$ is any homomorphism of $G$ into an Abelian group $A$, then $\varphi$ factors through $G'$; i.e., $G'\le \ker{\varphi}$ and there is a homomorphism $\hat{\varphi}:G/G'\to A$ such that $\varphi(g) = (\hat{\varphi}\circ \pi)(g)$. (That is, we have a fancy commutative diagram.) This is from Dummit and Foote, p.169, Proposition 7. The proof of (1) is very straightforward. However, the authors claim that (1) is a restatement of (2) in terms of homomorphisms. Can anyone explain this? Because it is not clear to me. Also, if I wanted to prove (2) outright, what should the map $\hat{\varphi}$ be? My first thought was defining it as $\hat{\varphi}(aG')= \varphi(a)$, but I don't think this works. Thanks!",,"['abstract-algebra', 'group-theory']"
9,Is there a minimal generating set of reals which additively generate all the reals?,Is there a minimal generating set of reals which additively generate all the reals?,,"Is there a set $S$ of real numbers such that the submagma generated by $S$ under addition is the entire set of real numbers, but such that no proper subset of $S$ generates the entire set of real numbers?","Is there a set of real numbers such that the submagma generated by under addition is the entire set of real numbers, but such that no proper subset of generates the entire set of real numbers?",S S S,"['abstract-algebra', 'group-theory', 'real-numbers', 'semigroups']"
10,There does not exist group $G$ such that ${\rm Aut}(G)\cong \mathbb{Z}_n$ (for odd $n$),There does not exist group  such that  (for odd ),G {\rm Aut}(G)\cong \mathbb{Z}_n n,"I had this ""almost bonus"" question on the final in Group Theory recently: prove that there is no such group $G$ which would satisfy ${\rm Aut}(G)\cong \mathbb{Z}_n$ , where $n$ is an odd integer. I don't have much certainty if this proof is OK, and one's opinion would be appreciated. Here's my attempt: Suppose that there exists such a group $G$ that satisfies the above condition. Since $\mathbb{Z}_n$ is cyclic, ${\rm Aut}(G)$ is also cyclic and $G$ is abelian, which implies that ${\rm Inn}(G)\cong \{e\}$ . Thus ${\rm Aut}(G)={\rm Out}(G)$ . (I don't think this fact is important here though) . Now, since an automorphism sends a generator to a generator, and since each automorphism is completely determined by such mapping, $|{\rm Aut}(G)|$ must be of factorial order. But an integer factorial is always even. However, $|\mathbb{Z}_n|$ is odd, which is a contradiction. Therefore, no such $G$ exists. I'm afraid that my proof is not very nice, but at least a genuine attempt was made.","I had this ""almost bonus"" question on the final in Group Theory recently: prove that there is no such group which would satisfy , where is an odd integer. I don't have much certainty if this proof is OK, and one's opinion would be appreciated. Here's my attempt: Suppose that there exists such a group that satisfies the above condition. Since is cyclic, is also cyclic and is abelian, which implies that . Thus . (I don't think this fact is important here though) . Now, since an automorphism sends a generator to a generator, and since each automorphism is completely determined by such mapping, must be of factorial order. But an integer factorial is always even. However, is odd, which is a contradiction. Therefore, no such exists. I'm afraid that my proof is not very nice, but at least a genuine attempt was made.",G {\rm Aut}(G)\cong \mathbb{Z}_n n G \mathbb{Z}_n {\rm Aut}(G) G {\rm Inn}(G)\cong \{e\} {\rm Aut}(G)={\rm Out}(G) |{\rm Aut}(G)| |\mathbb{Z}_n| G,"['abstract-algebra', 'group-theory', 'cyclic-groups', 'group-isomorphism', 'automorphism-group']"
11,"What algebraic structure do date, temperature, and similar quantities belongs to?","What algebraic structure do date, temperature, and similar quantities belongs to?",,"I find that some quantities share serveral characteristics. For date: ""1st July"" + ""1 day"" = ""2nd July"" ""2nd July"" - ""1st July"" = ""1 day"" But ""20th August"" + ""29th August"" is nonsense. For temperature: An object can be heated up from 25 degree Celsius by 5 degree Celsius to 30 degree Celsius. The temperature of boiling water is 100 degree Celsius. The temperature of the surrounding is 25 degree Celsius. The difference is 75 degree Celsius. But we cannot add the temperature of a cup of tea to the temperature of a cup coffee. Also, we cannot do multiplication on date or temperature. Depending on context, their relative values are useful, but their absolute value are not relavent. E.g., we don't count date from the Big Bang; weather forecast does not involve absolute temperature. How does abstract algebra describe these quantities? Is there an algebraic structure captures their characteristics?","I find that some quantities share serveral characteristics. For date: ""1st July"" + ""1 day"" = ""2nd July"" ""2nd July"" - ""1st July"" = ""1 day"" But ""20th August"" + ""29th August"" is nonsense. For temperature: An object can be heated up from 25 degree Celsius by 5 degree Celsius to 30 degree Celsius. The temperature of boiling water is 100 degree Celsius. The temperature of the surrounding is 25 degree Celsius. The difference is 75 degree Celsius. But we cannot add the temperature of a cup of tea to the temperature of a cup coffee. Also, we cannot do multiplication on date or temperature. Depending on context, their relative values are useful, but their absolute value are not relavent. E.g., we don't count date from the Big Bang; weather forecast does not involve absolute temperature. How does abstract algebra describe these quantities? Is there an algebraic structure captures their characteristics?",,['abstract-algebra']
12,The degree of $\sqrt{2} + \sqrt[3]{5}$ over $\mathbb Q$,The degree of  over,\sqrt{2} + \sqrt[3]{5} \mathbb Q,"I know that the degree is at most $6$, since $\sqrt{2} + \sqrt[3]{5} \in \mathbb Q(\sqrt{2}, \sqrt[3]{5})$, which has degree $6$ over $\mathbb Q$. I'm trying to construct a polynomial with root $\sqrt{2} + \sqrt[3]{5}$ and coefficients in $\mathbb Q$ of degree $6$, and then show that it is irreducible over $\mathbb Q$. I managed to find that it is a root of the polynomial $x^6 - 6x^4 - 10x^3 +12x^2 - 60x +17$. This is where I run in to some problems. I don't know how to show that this is irreducible over $\mathbb Q$ (or $\mathbb Z$). The only criteria we have learned is Eisenstein's criteria, which clearly does not apply here. How else can I show that the degree of this number over $\mathbb Q$ is $6$?","I know that the degree is at most $6$, since $\sqrt{2} + \sqrt[3]{5} \in \mathbb Q(\sqrt{2}, \sqrt[3]{5})$, which has degree $6$ over $\mathbb Q$. I'm trying to construct a polynomial with root $\sqrt{2} + \sqrt[3]{5}$ and coefficients in $\mathbb Q$ of degree $6$, and then show that it is irreducible over $\mathbb Q$. I managed to find that it is a root of the polynomial $x^6 - 6x^4 - 10x^3 +12x^2 - 60x +17$. This is where I run in to some problems. I don't know how to show that this is irreducible over $\mathbb Q$ (or $\mathbb Z$). The only criteria we have learned is Eisenstein's criteria, which clearly does not apply here. How else can I show that the degree of this number over $\mathbb Q$ is $6$?",,"['abstract-algebra', 'field-theory', 'extension-field', 'irreducible-polynomials']"
13,Countable infinite direct product of $\mathbb{Z}$ modulo countable direct sum,Countable infinite direct product of  modulo countable direct sum,\mathbb{Z},"Let $M=\mathbb Z^{\mathbb N}$ be the product of a countable number of copies of the group $\mathbb{Z}$ and let $N=\mathbb Z^{(\mathbb N)}$ be the direct sum of a countable number of copies of $\mathbb{Z}$. Why is it true that $M$ is not isomorphic to $N \oplus M/N$? Thoughts I've had so far: I found out that $M$ is not a free or even projective $\mathbb{Z}$-module (note: projective modules are free over PIDs, as a commenter pointed out), but that fact doesn't preclude the possibility that the sequence $0 \to K \to M \to K \oplus M/K \to 0$ can still split some of the time for some $\mathbb{Z}$-submodule $K \subseteq M$. So the result does not follow directly from $M$ not being projective. I don't know much about $M/N$ besides that it consists of infinite sequences of integers, with sequences that only differ by a finite number of entries being identified. If $M/N$ is free or projective then the result follows from the fact that $M$ is not projective, but I don't have any intuition as to the freeness or projectiveness of $M/N$. I tried a proof considering $M$ as a ring with multiplication defined component-wise, and then consider $M$,$N$,$M/N$ as $M$-modules. But this didn't get me very far.","Let $M=\mathbb Z^{\mathbb N}$ be the product of a countable number of copies of the group $\mathbb{Z}$ and let $N=\mathbb Z^{(\mathbb N)}$ be the direct sum of a countable number of copies of $\mathbb{Z}$. Why is it true that $M$ is not isomorphic to $N \oplus M/N$? Thoughts I've had so far: I found out that $M$ is not a free or even projective $\mathbb{Z}$-module (note: projective modules are free over PIDs, as a commenter pointed out), but that fact doesn't preclude the possibility that the sequence $0 \to K \to M \to K \oplus M/K \to 0$ can still split some of the time for some $\mathbb{Z}$-submodule $K \subseteq M$. So the result does not follow directly from $M$ not being projective. I don't know much about $M/N$ besides that it consists of infinite sequences of integers, with sequences that only differ by a finite number of entries being identified. If $M/N$ is free or projective then the result follows from the fact that $M$ is not projective, but I don't have any intuition as to the freeness or projectiveness of $M/N$. I tried a proof considering $M$ as a ring with multiplication defined component-wise, and then consider $M$,$N$,$M/N$ as $M$-modules. But this didn't get me very far.",,"['abstract-algebra', 'group-theory', 'modules']"
14,Is the image of a tensor product equal to the tensor product of the images?,Is the image of a tensor product equal to the tensor product of the images?,,"Let $S$ be a commutative ring with unity, and let $A,B,A',B'$ be $S$-modules. If $\phi:A\rightarrow A'$ and $\psi:B\rightarrow B'$ are $S$-module homomorphisms, is it true that $$\operatorname{im}(\phi\otimes\psi)=\operatorname{im}(\phi)\otimes_S \operatorname{im} (\psi)?$$","Let $S$ be a commutative ring with unity, and let $A,B,A',B'$ be $S$-modules. If $\phi:A\rightarrow A'$ and $\psi:B\rightarrow B'$ are $S$-module homomorphisms, is it true that $$\operatorname{im}(\phi\otimes\psi)=\operatorname{im}(\phi)\otimes_S \operatorname{im} (\psi)?$$",,"['abstract-algebra', 'commutative-algebra', 'homological-algebra', 'tensor-products']"
15,Difference between a group normalizer and centralizer,Difference between a group normalizer and centralizer,,"If a group centralizer is defined as $C_G(A)=\{g \in G : gag^{-1} = a$ for all $a \in A\}$, and a group normalizer is defined as $N_G(A)=\{g\in G:gAg^{-1}=A\}$, where $gAg^{-1}=\{gag^{-1}:a\in A\}$ (definition taken from Abstract Algebra by Dummit and Foote), then what's the difference between $C_G(A)$ and $N_G(A)$?","If a group centralizer is defined as $C_G(A)=\{g \in G : gag^{-1} = a$ for all $a \in A\}$, and a group normalizer is defined as $N_G(A)=\{g\in G:gAg^{-1}=A\}$, where $gAg^{-1}=\{gag^{-1}:a\in A\}$ (definition taken from Abstract Algebra by Dummit and Foote), then what's the difference between $C_G(A)$ and $N_G(A)$?",,"['abstract-algebra', 'group-theory']"
16,Direct sum and direct product of infinitely many abelian groups are not isomorphic,Direct sum and direct product of infinitely many abelian groups are not isomorphic,,"Let $I$ be an infinite set, and for each $i$ let $A_i$ be an abelian group with order $o(A_i) \ge 2$.  Prove that the direct product $\prod A_i$ and the direct sum (coproduct) $\bigoplus A_i$ are not isomorphic. Here the product and coproduct are taken in the category of abelian groups.  So an element of the direct product is a ""list"" of one element from each group, and an element of the coproduct is such a list where all but finitely many terms are zero. This problem appeared on an algebra problem set a couple weeks ago and I haven't been able to solve it then or since then.  Any ideas? An initial observation is that the direct sum is of course a subgroup of the direct product.  But the direct product could be a subgroup of the direct sum as well!  For example let $I = \mathbb{N}$, and let $A_1 = B \times B \times B \times \cdots$ where $B = A_2 \times A_3 \times A_4 \times \cdots$.  Then $$ \prod A_i = A_1 \times B = (B \times B \times B \times \cdots) \times B = A_1 \subset \bigoplus A_i $$ This causes many of my ideas to fail; for instance I cannot rely on there existing a generating set of a certain cardinality, nor can I argue there are a certainly cardinality of subgroups, nor in general can I make any sort of argument regarding the size of the two groups. It also seems promising to appeal directly to the universal mapping properties satisfied by the product and coproduct.  The problem I ran into in this case was that the projections from the direct product to the individual $A_i$s and the inverse projections from the $A_i$s to the direct sum need not have anything to do with each other.  Also, this approach would somehow have to make use of the fact that $I$ is infinite...","Let $I$ be an infinite set, and for each $i$ let $A_i$ be an abelian group with order $o(A_i) \ge 2$.  Prove that the direct product $\prod A_i$ and the direct sum (coproduct) $\bigoplus A_i$ are not isomorphic. Here the product and coproduct are taken in the category of abelian groups.  So an element of the direct product is a ""list"" of one element from each group, and an element of the coproduct is such a list where all but finitely many terms are zero. This problem appeared on an algebra problem set a couple weeks ago and I haven't been able to solve it then or since then.  Any ideas? An initial observation is that the direct sum is of course a subgroup of the direct product.  But the direct product could be a subgroup of the direct sum as well!  For example let $I = \mathbb{N}$, and let $A_1 = B \times B \times B \times \cdots$ where $B = A_2 \times A_3 \times A_4 \times \cdots$.  Then $$ \prod A_i = A_1 \times B = (B \times B \times B \times \cdots) \times B = A_1 \subset \bigoplus A_i $$ This causes many of my ideas to fail; for instance I cannot rely on there existing a generating set of a certain cardinality, nor can I argue there are a certainly cardinality of subgroups, nor in general can I make any sort of argument regarding the size of the two groups. It also seems promising to appeal directly to the universal mapping properties satisfied by the product and coproduct.  The problem I ran into in this case was that the projections from the direct product to the individual $A_i$s and the inverse projections from the $A_i$s to the direct sum need not have anything to do with each other.  Also, this approach would somehow have to make use of the fact that $I$ is infinite...",,"['abstract-algebra', 'category-theory', 'abelian-groups', 'direct-sum', 'direct-product']"
17,"What is an example of two k-algebras that are isomorphic as rings, but not as k-algebras?","What is an example of two k-algebras that are isomorphic as rings, but not as k-algebras?",,"Let $k$ be a field. Let $A$ and $B$ be two $k$-algebras, ie. two rings that are also $k$-vector spaces and their multiplication is $k$-bilinear. Any isomorphism of $k$-algebras is also a ring isomorphism, so if $A$ and $B$ are isomorphic as $k$-algebras, they are isomorphic as rings. I would guess that the converse fails. Is there any example of $A$ and $B$ that are isomorphic as rings, but not as $k$-algebras? The reason I came up with this question is the following. Two affine varieties are isomorphic if and only if their coordinate rings are isomorphic as $k$-algebras. I am interested in finding an example where coordinate rings are isomorphic as rings, but the varieties are not isomorphic.","Let $k$ be a field. Let $A$ and $B$ be two $k$-algebras, ie. two rings that are also $k$-vector spaces and their multiplication is $k$-bilinear. Any isomorphism of $k$-algebras is also a ring isomorphism, so if $A$ and $B$ are isomorphic as $k$-algebras, they are isomorphic as rings. I would guess that the converse fails. Is there any example of $A$ and $B$ that are isomorphic as rings, but not as $k$-algebras? The reason I came up with this question is the following. Two affine varieties are isomorphic if and only if their coordinate rings are isomorphic as $k$-algebras. I am interested in finding an example where coordinate rings are isomorphic as rings, but the varieties are not isomorphic.",,"['abstract-algebra', 'algebraic-geometry', 'ring-theory', 'commutative-algebra']"
18,"If a and b are group elements and ab ≠ ba, prove that aba ≠ identity.","If a and b are group elements and ab ≠ ba, prove that aba ≠ identity.",,"Q: If a and b are group elements and ab ≠ ba, prove that aba ≠ identity. I began by stating my theorem, then assumed ab ≠ ba. Then I tried a few inverse law manipulations, which worked in a sense, however they brought me nowhere, as I couldn't conclude my proof concretely. Suggestions? Solutions?","Q: If a and b are group elements and ab ≠ ba, prove that aba ≠ identity. I began by stating my theorem, then assumed ab ≠ ba. Then I tried a few inverse law manipulations, which worked in a sense, however they brought me nowhere, as I couldn't conclude my proof concretely. Suggestions? Solutions?",,['abstract-algebra']
19,This tower of fields is being ridiculous,This tower of fields is being ridiculous,,"Suppose $K\subseteq F\subseteq L$ as fields. Then it is a fact that $[L:K]=[L:F][F:K]$. No other hypotheses are needed (I'm looking at you, Hungerford V.1.2). Now obviously $[\mathbf{C}:\mathbf{R}]=2$. But consider the fact that the algebraic closure of $\mathbf{R}(t)$ has cardinality $2^{\aleph_0}$---this implies that $\overline{\mathbf{R}(t)}\cong\mathbf{C}$, so in particular we can embed $\mathbf{R}(t)$ into $\mathbf{C}$. If we embed $\mathbf{R}$ into $\mathbf{R}(t)$ in the natural way, we get $$\mathbf{R}\subset\mathbf{R}(t)\subset\mathbf{C}.$$ So our good fact at the beginning would have us believe $$2=[\mathbf{C}:\mathbf{R}(t)][\mathbf{R}(t):\mathbf{R}].$$ What is the meaning of this? Either these two degrees really are both finite or (more likely) I've made a huge mistake. Perhaps it would all be clear if I were more precise about ""embedding"" $\mathbf{R}(t)$ in $\mathbf{C}$.","Suppose $K\subseteq F\subseteq L$ as fields. Then it is a fact that $[L:K]=[L:F][F:K]$. No other hypotheses are needed (I'm looking at you, Hungerford V.1.2). Now obviously $[\mathbf{C}:\mathbf{R}]=2$. But consider the fact that the algebraic closure of $\mathbf{R}(t)$ has cardinality $2^{\aleph_0}$---this implies that $\overline{\mathbf{R}(t)}\cong\mathbf{C}$, so in particular we can embed $\mathbf{R}(t)$ into $\mathbf{C}$. If we embed $\mathbf{R}$ into $\mathbf{R}(t)$ in the natural way, we get $$\mathbf{R}\subset\mathbf{R}(t)\subset\mathbf{C}.$$ So our good fact at the beginning would have us believe $$2=[\mathbf{C}:\mathbf{R}(t)][\mathbf{R}(t):\mathbf{R}].$$ What is the meaning of this? Either these two degrees really are both finite or (more likely) I've made a huge mistake. Perhaps it would all be clear if I were more precise about ""embedding"" $\mathbf{R}(t)$ in $\mathbf{C}$.",,"['abstract-algebra', 'field-theory', 'extension-field', 'fake-proofs']"
20,Some intuitive vision on abstract algebra,Some intuitive vision on abstract algebra,,"I'm currently on my second year of Mathematics and first one I'm learning abstract algebra. So far it's being the most interesting subject I've seen, but I have a problem with some intuitive visions about it that some teachers (out of experience I guess) have with this. Particularly, I heard one of them saying it was trivial that, under isomorphisms: $\mathbb{Z}/2\mathbb{Z}\times \mathbb{Z}/2\mathbb{Z} \subset A_4$ That meaning a subgroup of $A_4$ is isomorphic to the left side of the expression. I don't see that trivial at all until you do some study on $A_4$ (btw, it's the alternating group of order 12), and you find that there are elements of order 2 x,y, for which is true that $xy=yx$, you can deduce the next is a subgroup of $A_4$: $H=\{1,x,y,xy\}$. Once yo get here, the isomorphism between $H$ and $\mathbb{Z}_2\times \mathbb{Z}_2$ may look trivial, but I don't understand how, from just an alternating group, you can deduce that just by looking. Is there any intuitive vision on groups, either general or in this particular case, that I'm missing and could help me ""see"" these things? Also, would you recommend some book that makes a special effort explaining, not the formalism, which you can find in any book, but this more intuitive view? Thanks, in advance. EDIT: Ok, so my first question has been answered, thank you all guys. Now, my second, about the book, if anyone knows a book that's ""famous"" for begin great in group theory (elementary group theory), or that deals with the subject at an intuitive level (I won't give up the formal treatment), I would appreciate a name or author. EDIT2: @jspecter This was very usefull, thank you. A couple of questions, I don't understand the group $Stab_\Sigma(P)$: I'm not english an I don't know the meaning of ""tabalizes"", may be a typo... The second, I think I'm having some trouble thinking about the $\mathbb{Z}/m\times ... \times \mathbb{Z}/r$, I'm seeing them as ordered sets of as much integers as factors you have $(x_1,x_2,...,x_n)$, (I don't know the word for that in english either, we called them n-tuplas (spanish)). Maybe my difficulties are with seeing the isomorphism between these groups and the symmetry groups $A_n$.  With this particular example, if we take your subset $P$, which we can see as a triangle in a plane, and we create the group of symmetries of this figure we have the identity and 3 reflexions on the mediatrice of each vertex, this is what we identify with $\mathbb{Z}_2\times \mathbb{Z}_2=\{(0,0),(1,0),(0,1),(1,1)\}$.  Obviously we identify two reflexions with (1,0) and (0,1), and the other is a combination of the other two, plus it's abelian (just like any four element group), is that the way you're seeing it? I think I have difficulties identifying these members (i,j) with functions, in this case isometries for that triangle, any advice for this? Overall, you helped a lot and I'm starting to see the whole thing more clear. Thank you again. Still, if someone recommends a book, I would be gratefull.","I'm currently on my second year of Mathematics and first one I'm learning abstract algebra. So far it's being the most interesting subject I've seen, but I have a problem with some intuitive visions about it that some teachers (out of experience I guess) have with this. Particularly, I heard one of them saying it was trivial that, under isomorphisms: $\mathbb{Z}/2\mathbb{Z}\times \mathbb{Z}/2\mathbb{Z} \subset A_4$ That meaning a subgroup of $A_4$ is isomorphic to the left side of the expression. I don't see that trivial at all until you do some study on $A_4$ (btw, it's the alternating group of order 12), and you find that there are elements of order 2 x,y, for which is true that $xy=yx$, you can deduce the next is a subgroup of $A_4$: $H=\{1,x,y,xy\}$. Once yo get here, the isomorphism between $H$ and $\mathbb{Z}_2\times \mathbb{Z}_2$ may look trivial, but I don't understand how, from just an alternating group, you can deduce that just by looking. Is there any intuitive vision on groups, either general or in this particular case, that I'm missing and could help me ""see"" these things? Also, would you recommend some book that makes a special effort explaining, not the formalism, which you can find in any book, but this more intuitive view? Thanks, in advance. EDIT: Ok, so my first question has been answered, thank you all guys. Now, my second, about the book, if anyone knows a book that's ""famous"" for begin great in group theory (elementary group theory), or that deals with the subject at an intuitive level (I won't give up the formal treatment), I would appreciate a name or author. EDIT2: @jspecter This was very usefull, thank you. A couple of questions, I don't understand the group $Stab_\Sigma(P)$: I'm not english an I don't know the meaning of ""tabalizes"", may be a typo... The second, I think I'm having some trouble thinking about the $\mathbb{Z}/m\times ... \times \mathbb{Z}/r$, I'm seeing them as ordered sets of as much integers as factors you have $(x_1,x_2,...,x_n)$, (I don't know the word for that in english either, we called them n-tuplas (spanish)). Maybe my difficulties are with seeing the isomorphism between these groups and the symmetry groups $A_n$.  With this particular example, if we take your subset $P$, which we can see as a triangle in a plane, and we create the group of symmetries of this figure we have the identity and 3 reflexions on the mediatrice of each vertex, this is what we identify with $\mathbb{Z}_2\times \mathbb{Z}_2=\{(0,0),(1,0),(0,1),(1,1)\}$.  Obviously we identify two reflexions with (1,0) and (0,1), and the other is a combination of the other two, plus it's abelian (just like any four element group), is that the way you're seeing it? I think I have difficulties identifying these members (i,j) with functions, in this case isometries for that triangle, any advice for this? Overall, you helped a lot and I'm starting to see the whole thing more clear. Thank you again. Still, if someone recommends a book, I would be gratefull.",,"['abstract-algebra', 'group-theory', 'soft-question']"
21,Question about definition of Semi algebra,Question about definition of Semi algebra,,"I am wondering if someone could help me with basic properties of semi algebra. We say that $S$ is a semi algebra of subsets of X if $\emptyset \in S$ If $P_1$, $P_2 \in S$, then $P_1 \cap P_2 \in S$ If $P \in S$, then $X \backslash P$ can be written as a finite union of  sets from $S$. But I am finding that sometimes it is defined using the following 3' instead of 3. 3'. If $P \in S$, then $X \backslash P$ can be written as a disjoint finite union of  sets from $S$. My question is are these definitions equivalent? If so can someone please show me how we can obtain 3' from the first three conditions? Thank you.","I am wondering if someone could help me with basic properties of semi algebra. We say that $S$ is a semi algebra of subsets of X if $\emptyset \in S$ If $P_1$, $P_2 \in S$, then $P_1 \cap P_2 \in S$ If $P \in S$, then $X \backslash P$ can be written as a finite union of  sets from $S$. But I am finding that sometimes it is defined using the following 3' instead of 3. 3'. If $P \in S$, then $X \backslash P$ can be written as a disjoint finite union of  sets from $S$. My question is are these definitions equivalent? If so can someone please show me how we can obtain 3' from the first three conditions? Thank you.",,"['abstract-algebra', 'measure-theory']"
22,Computing the number of nonisomorphic finite abelian groups of order $n$,Computing the number of nonisomorphic finite abelian groups of order,n,"Let's say I'm given a number $n = p^{3}q^{4}r^{2}s$ and I want to find the number of (non-isomorphic) abelian groups of order $n$. How I'm computing the number is basically partitioning, that is, I'm just looking at it and saying that I have $\mathbb{Z}/p^{3}q^{4}r^{2}s\mathbb{Z}$, $\mathbb{Z}/p^{2}q^{4}r^{2}s\mathbb{Z} \times \mathbb{Z}/p\mathbb{Z}$, and so on. Then I count the number of groups I've written down. However, I've found that I'm quite prone to error when I do this. Is there a faster way of doing this? If not, is there a systematic trick/way I could use to make this easier?","Let's say I'm given a number $n = p^{3}q^{4}r^{2}s$ and I want to find the number of (non-isomorphic) abelian groups of order $n$. How I'm computing the number is basically partitioning, that is, I'm just looking at it and saying that I have $\mathbb{Z}/p^{3}q^{4}r^{2}s\mathbb{Z}$, $\mathbb{Z}/p^{2}q^{4}r^{2}s\mathbb{Z} \times \mathbb{Z}/p\mathbb{Z}$, and so on. Then I count the number of groups I've written down. However, I've found that I'm quite prone to error when I do this. Is there a faster way of doing this? If not, is there a systematic trick/way I could use to make this easier?",,"['abstract-algebra', 'group-theory']"
23,"How to show that $[\mathbb{Q}(\sqrt[3]{2},\sqrt[3]{3}):\mathbb{Q}]=9$?",How to show that ?,"[\mathbb{Q}(\sqrt[3]{2},\sqrt[3]{3}):\mathbb{Q}]=9","Fraleigh, Sec31, Ex9. Show that $[\mathbb{Q}(\sqrt[3]{2},\sqrt[3]{3}):\mathbb{Q}]=9$. Here is my trial: It is obvious that $\sqrt[3]2$ is algebraic of degree 3 over $\mathbb{Q}$, since $x^3-2$ is irreducible over $\mathbb{Q}$ by Eisenstein crieterion with $p=2$. Then we need to show that $\sqrt[3]3$ is algebraic of degree 3 over $\mathbb{Q}(\sqrt[3]2)$. Since $\sqrt[3]3$ is a zero of $x^3-3$, its degree is at most 3. To show that $\sqrt[3]3$ is not of degree 1, i.e. $\sqrt[3]3 \not\in \mathbb{Q}(\sqrt[3]2)$, suppose that $\sqrt[3]3=a+b\sqrt[3]2+c\sqrt[3]4$, where $a, b, c \in \mathbb{Q}$. (The usual degree argument is not available since $\deg(\sqrt[3]3,\mathbb{Q})=3$ divides $\deg(\sqrt[3]2,\mathbb{Q})=3$.) Cubing both sides, $3=p+q\sqrt[3]2+r\sqrt[3]4$ with some $p, q, r$ in $\mathbb{Q}$, so $\sqrt[3]2$ is a zero of $rx^2+qx+p-3$, which is a contradiction to $\deg(\sqrt[3]2,\mathbb{Q})=3$. Now to prove $\sqrt[3]3$ is not of degree 2, suppose that $\sqrt[3]3$ is a zero of quadratic polynomial. This means that $\sqrt[3]9=p\sqrt[3]3+q$ for some $p,q \in \mathbb{Q}(\sqrt[3]2)$. Cubing both sides, $9=3p^3+q^3+3p\sqrt[3]3q(\sqrt[3]3p+q)=3p^3+q^3+9pq:=a+b\sqrt[3]2+c\sqrt[3]4$ for some $a,b,c\in\mathbb{Q}$, which leads to the same contradiction. Actually I didn't know how to solve it but while writing out this question, it seems that I solved the problem. But is the above solution right? And is there any other way to solve it? At first, I tried to show that $x=\sqrt[3]{2}+\sqrt[3]{3}$ is algebraic of degree 9 over $\mathbb{Q}$. Cubing yields that $x^3=5+3 \sqrt[3]{6}x$, so $(x^3-5)^3=162x^3$, so $x^9-15x^6-87x^3-125=0$ has $\sqrt[3]{2}+\sqrt[3]{3}$ as a zero. But I couldn't show that it is irreducible (Eisenstein criterion with $p=5$ fails.) Edit: As Alex pointed out, it is sufficient to show that $x^3-3$ has no roots in $\mathbb{Q}(\sqrt[3]{2})$. And as Gerry pointed out, this process some more work than the above(check the nonzero condition). Suppose $(a+b\sqrt[3]2+c\sqrt[3]4)^3=3$. I did the heavy computation, $a^3+2b^3+4c^3+12abc+3\sqrt[3]2(a^2b+2b^2c+2c^2a)+3\sqrt[3]4(a^2c+b^2a+2c^2b)=3$, and stuck on here. How can I proceed here?","Fraleigh, Sec31, Ex9. Show that $[\mathbb{Q}(\sqrt[3]{2},\sqrt[3]{3}):\mathbb{Q}]=9$. Here is my trial: It is obvious that $\sqrt[3]2$ is algebraic of degree 3 over $\mathbb{Q}$, since $x^3-2$ is irreducible over $\mathbb{Q}$ by Eisenstein crieterion with $p=2$. Then we need to show that $\sqrt[3]3$ is algebraic of degree 3 over $\mathbb{Q}(\sqrt[3]2)$. Since $\sqrt[3]3$ is a zero of $x^3-3$, its degree is at most 3. To show that $\sqrt[3]3$ is not of degree 1, i.e. $\sqrt[3]3 \not\in \mathbb{Q}(\sqrt[3]2)$, suppose that $\sqrt[3]3=a+b\sqrt[3]2+c\sqrt[3]4$, where $a, b, c \in \mathbb{Q}$. (The usual degree argument is not available since $\deg(\sqrt[3]3,\mathbb{Q})=3$ divides $\deg(\sqrt[3]2,\mathbb{Q})=3$.) Cubing both sides, $3=p+q\sqrt[3]2+r\sqrt[3]4$ with some $p, q, r$ in $\mathbb{Q}$, so $\sqrt[3]2$ is a zero of $rx^2+qx+p-3$, which is a contradiction to $\deg(\sqrt[3]2,\mathbb{Q})=3$. Now to prove $\sqrt[3]3$ is not of degree 2, suppose that $\sqrt[3]3$ is a zero of quadratic polynomial. This means that $\sqrt[3]9=p\sqrt[3]3+q$ for some $p,q \in \mathbb{Q}(\sqrt[3]2)$. Cubing both sides, $9=3p^3+q^3+3p\sqrt[3]3q(\sqrt[3]3p+q)=3p^3+q^3+9pq:=a+b\sqrt[3]2+c\sqrt[3]4$ for some $a,b,c\in\mathbb{Q}$, which leads to the same contradiction. Actually I didn't know how to solve it but while writing out this question, it seems that I solved the problem. But is the above solution right? And is there any other way to solve it? At first, I tried to show that $x=\sqrt[3]{2}+\sqrt[3]{3}$ is algebraic of degree 9 over $\mathbb{Q}$. Cubing yields that $x^3=5+3 \sqrt[3]{6}x$, so $(x^3-5)^3=162x^3$, so $x^9-15x^6-87x^3-125=0$ has $\sqrt[3]{2}+\sqrt[3]{3}$ as a zero. But I couldn't show that it is irreducible (Eisenstein criterion with $p=5$ fails.) Edit: As Alex pointed out, it is sufficient to show that $x^3-3$ has no roots in $\mathbb{Q}(\sqrt[3]{2})$. And as Gerry pointed out, this process some more work than the above(check the nonzero condition). Suppose $(a+b\sqrt[3]2+c\sqrt[3]4)^3=3$. I did the heavy computation, $a^3+2b^3+4c^3+12abc+3\sqrt[3]2(a^2b+2b^2c+2c^2a)+3\sqrt[3]4(a^2c+b^2a+2c^2b)=3$, and stuck on here. How can I proceed here?",,"['abstract-algebra', 'field-theory']"
24,Is Aluffi's book a good second text for Algebra?,Is Aluffi's book a good second text for Algebra?,,"I have been trying to relearn parts of algebra (mostly module theory and (advanced)linear algebra) from Lang, which, frankly, is not going too well. Now, I have managed to get my hands on 'Aluffi - Algebra: Chapter 0'. And it (specifically the section called linear algebra reprise) seems pretty good. But, before I jump in and start studying from it, I want to make sure that I won't be repeating my experience with Lang. One indicator could be that it is a popular textbook. But, on searching, I found that it is not much used elsewhere. My question: Has anyone taken a formal/reading course using this book or studied it at length (not just leafed through it) and can thus recommend it and if it's possible (and not asking too much of their time) could they write briefly the course plan they followed? Added This is in response to KCd's comments What I am trying to do before next semester, is to take stock and make notes on some topics in Algebra generally taught in the first year of grad school (I am not in grad school. Will apply for Fall 2013). The notes will be (or on topics from) basic module theory, tensors, some exterior algebra, basic commutative algebra (an example of a topic would be Localization) (Some of these things I have learnt in courses such as Differential Geometry, etc.) For instance, in the note which will end with a proof of the structure theorem over PIDs (hopefully one that I am truly comfortable with), I began with defining free modules via universal property, instead of how I had learned it from Artin's book. Earlier, I thought I'll do this while relearning from Lang. But that's not serving me too well, for reasons I am not entirely clear about. Then I came upon Aluffi's book. [@KCd: Let me also add that when I was trying to write up a note on basic Galois Theory, I came across your expository notes. They are spectacular.]","I have been trying to relearn parts of algebra (mostly module theory and (advanced)linear algebra) from Lang, which, frankly, is not going too well. Now, I have managed to get my hands on 'Aluffi - Algebra: Chapter 0'. And it (specifically the section called linear algebra reprise) seems pretty good. But, before I jump in and start studying from it, I want to make sure that I won't be repeating my experience with Lang. One indicator could be that it is a popular textbook. But, on searching, I found that it is not much used elsewhere. My question: Has anyone taken a formal/reading course using this book or studied it at length (not just leafed through it) and can thus recommend it and if it's possible (and not asking too much of their time) could they write briefly the course plan they followed? Added This is in response to KCd's comments What I am trying to do before next semester, is to take stock and make notes on some topics in Algebra generally taught in the first year of grad school (I am not in grad school. Will apply for Fall 2013). The notes will be (or on topics from) basic module theory, tensors, some exterior algebra, basic commutative algebra (an example of a topic would be Localization) (Some of these things I have learnt in courses such as Differential Geometry, etc.) For instance, in the note which will end with a proof of the structure theorem over PIDs (hopefully one that I am truly comfortable with), I began with defining free modules via universal property, instead of how I had learned it from Artin's book. Earlier, I thought I'll do this while relearning from Lang. But that's not serving me too well, for reasons I am not entirely clear about. Then I came upon Aluffi's book. [@KCd: Let me also add that when I was trying to write up a note on basic Galois Theory, I came across your expository notes. They are spectacular.]",,"['abstract-algebra', 'self-learning']"
25,Exactness and obstruction in sheaf cohomology,Exactness and obstruction in sheaf cohomology,,"Given a topological space $X$ , sheaf cohomology 'measures' the lack of exactness of the global section functor $\Gamma(X, -) : \textbf{Sh}(X) \to \textbf{Ab}$ . From another viewpoint, sheaf cohomology should be measuring the 'obstruction to lifting local to global data'. I understand the notion of a sheaf as a local assignment to a topological space of algebraic structures that compatibly 'restrict' and 'glue'; and the global sections functor that maps $\mathcal{F} \mapsto \mathcal{F}(X)$ . Yet, I don't understand the connection between the exactness of $\Gamma(X, -)$ and the capability to 'lift local data to global'. How do these two viewpoints connect?","Given a topological space , sheaf cohomology 'measures' the lack of exactness of the global section functor . From another viewpoint, sheaf cohomology should be measuring the 'obstruction to lifting local to global data'. I understand the notion of a sheaf as a local assignment to a topological space of algebraic structures that compatibly 'restrict' and 'glue'; and the global sections functor that maps . Yet, I don't understand the connection between the exactness of and the capability to 'lift local data to global'. How do these two viewpoints connect?","X \Gamma(X, -) : \textbf{Sh}(X) \to \textbf{Ab} \mathcal{F} \mapsto \mathcal{F}(X) \Gamma(X, -)","['abstract-algebra', 'algebraic-topology', 'homology-cohomology', 'homological-algebra', 'sheaf-cohomology']"
26,Semigroup analogue to the classification of finite simple groups?,Semigroup analogue to the classification of finite simple groups?,,"Is there a semigroup analogue to the classification of finite simple groups? If so what are some of the major results? --Edit, reference links--- Classification of Finite Simple Groups Special Classes of Semigroups One of my semigroup equation sequences in OEIS, g(f(x)) = f(f(f(x)))","Is there a semigroup analogue to the classification of finite simple groups? If so what are some of the major results? --Edit, reference links--- Classification of Finite Simple Groups Special Classes of Semigroups One of my semigroup equation sequences in OEIS, g(f(x)) = f(f(f(x)))",,"['abstract-algebra', 'group-theory', 'semigroups']"
27,"Is $\Bbb Q(\sqrt 2, e)$ a simple extension of $\Bbb Q$?",Is  a simple extension of ?,"\Bbb Q(\sqrt 2, e) \Bbb Q","My general question is to find, if this is possible, two real numbers $a,b$ such that $K=\Bbb Q(a,b)$ is not a simple extension of $\Bbb Q$.   $\newcommand{\Q}{\Bbb Q}$ Of course $a$ and $b$  can't be both algebraic, otherwise $K$ would be a separable ($\Q$ has characteristic $0$) and finite extension, which has to be simple. So I tried with $\Q(\sqrt 2, e)$ but any other example would be accepted. The field $\Q(\sqrt 2, e)$ has transcendence degree $1$ over $\Q$, but I'm not sure if this imply that it is isomorphic to $\Q(a)$ for some transcendental number $a$ (the fact that two fields have the same transcendence degree over another field shouldn't imply that the fields are isomorphic). I'm not sure about the relation between the algebraic independence of $a$ and $b$, and the fact that $\Q(a,b)/\Q$ is a simple extension. Notice that $\Q(\pi, e)$ is probably unknown to be a simple extension of $\Q$. Thank you for your help!","My general question is to find, if this is possible, two real numbers $a,b$ such that $K=\Bbb Q(a,b)$ is not a simple extension of $\Bbb Q$.   $\newcommand{\Q}{\Bbb Q}$ Of course $a$ and $b$  can't be both algebraic, otherwise $K$ would be a separable ($\Q$ has characteristic $0$) and finite extension, which has to be simple. So I tried with $\Q(\sqrt 2, e)$ but any other example would be accepted. The field $\Q(\sqrt 2, e)$ has transcendence degree $1$ over $\Q$, but I'm not sure if this imply that it is isomorphic to $\Q(a)$ for some transcendental number $a$ (the fact that two fields have the same transcendence degree over another field shouldn't imply that the fields are isomorphic). I'm not sure about the relation between the algebraic independence of $a$ and $b$, and the fact that $\Q(a,b)/\Q$ is a simple extension. Notice that $\Q(\pi, e)$ is probably unknown to be a simple extension of $\Q$. Thank you for your help!",,"['abstract-algebra', 'field-theory', 'extension-field', 'transcendence-theory']"
28,Ring of real-valued convergent sequences,Ring of real-valued convergent sequences,,"Here is a fun and challenging problem: Let $R$ denote the ring of real-valued convergent sequences and let   $S$ denote the ring of real-valued sequences. Prove or disprove that   $S\cong R$. The cardinality of these two rings are the same (see Asaf's answer here ), but I somewhat doubt the existence of a bijection that would preserve the ring structure. I would appreciate some hints. Source: This is the last problem in this homework sheet (as you see, the deadline is long past).","Here is a fun and challenging problem: Let $R$ denote the ring of real-valued convergent sequences and let   $S$ denote the ring of real-valued sequences. Prove or disprove that   $S\cong R$. The cardinality of these two rings are the same (see Asaf's answer here ), but I somewhat doubt the existence of a bijection that would preserve the ring structure. I would appreciate some hints. Source: This is the last problem in this homework sheet (as you see, the deadline is long past).",,"['abstract-algebra', 'ring-theory']"
29,Is $a \circ b = \sqrt{a^2+b^2}$ ever a group?,Is  ever a group?,a \circ b = \sqrt{a^2+b^2},"I've been asked to ""Show that the operation $a ~ \circ ~ b = \sqrt{a^2+b^2}$ is associative, is commutative and has an identity but that the inverses do not always exist."" Wihch is easy enough to do if it is assumed that  $a,b \in \mathbb{R}$, except that the question does not stipulate over what field a and b exist, If however $a,b \in \mathbb{C}$ then all elements do have invereses in fact each element has two inverses, which I don't think is appropiate for a group, but this started me thinking maybe this operator might be classifable as a group operation if $a,b$ are chosen to exists over some specific field such as matrix, modular or finite or other field or ring ?. One possibility I have considered is complex upper half plane defined by $a,b \in \mathbb{H} = \{x + iy \mid y > 0 ; x,y \in \mathbb{R} \}$  but I am not sure if this would suffice to define the operation as a group operator or to prove the question incorrect. I believe the question is meant to be contradictory and stimulate discussion, but I am not knowledgable enough to determine if there are any situations in which this operator will suffice for a group ?, any help would be greatly appreciated. Michael","I've been asked to ""Show that the operation $a ~ \circ ~ b = \sqrt{a^2+b^2}$ is associative, is commutative and has an identity but that the inverses do not always exist."" Wihch is easy enough to do if it is assumed that  $a,b \in \mathbb{R}$, except that the question does not stipulate over what field a and b exist, If however $a,b \in \mathbb{C}$ then all elements do have invereses in fact each element has two inverses, which I don't think is appropiate for a group, but this started me thinking maybe this operator might be classifable as a group operation if $a,b$ are chosen to exists over some specific field such as matrix, modular or finite or other field or ring ?. One possibility I have considered is complex upper half plane defined by $a,b \in \mathbb{H} = \{x + iy \mid y > 0 ; x,y \in \mathbb{R} \}$  but I am not sure if this would suffice to define the operation as a group operator or to prove the question incorrect. I believe the question is meant to be contradictory and stimulate discussion, but I am not knowledgable enough to determine if there are any situations in which this operator will suffice for a group ?, any help would be greatly appreciated. Michael",,['abstract-algebra']
30,If $0$ is the zero-object $ \Longrightarrow F(0) $ is the zero object when $F$ additive,If  is the zero-object  is the zero object when  additive,0  \Longrightarrow F(0)  F,"Let $$ F : \text{A-Mod} \to \text{A-mod} $$ be an additive functor. Then if $0$ is the zero-object $F(0) $ is the zero object. Why this is true ? The definition of additive functor that I know is $\forall \ \ M , N \in $ A-Mod $$F : \hom_{A-Mod}(M,N ) \to \hom_{A-Mod}(FM,FN ) $$ is a morphism of abelian groups.","Let $$ F : \text{A-Mod} \to \text{A-mod} $$ be an additive functor. Then if $0$ is the zero-object $F(0) $ is the zero object. Why this is true ? The definition of additive functor that I know is $\forall \ \ M , N \in $ A-Mod $$F : \hom_{A-Mod}(M,N ) \to \hom_{A-Mod}(FM,FN ) $$ is a morphism of abelian groups.",,"['abstract-algebra', 'category-theory', 'modules']"
31,Example of a Subgroup That Is Not Normal,Example of a Subgroup That Is Not Normal,,"Can you kindly provide an example of a subgroup that is not normal?  I have been told many times that, for coset multiplication to be defined, the subgroup must be normal.  I have seen the proof and examples of quotient group multiplications.  Now, I am trying to find out where the process will break down if the subgroup is not normal. Suppose that $x \in a_1H = a_2H, y \in b_1H = b_2H$, where $H$ is not normal. So $x = a_1h_1 = a_2h_2$ for some $h_1, h_2 \in H$, and $y = b_1h_1^* = b_2h_2^*$ for some $h_1, h_2 \in H$. $xy = (a_1b_1)(h_1h_1^*) = (a_2b_2)(h_2h_2^*)$.  However, both $h_1h_1^*, h_2h_2^*$ are still elements of $H$. So I don't see how $a_1b_1H \neq a_2b_2H$.","Can you kindly provide an example of a subgroup that is not normal?  I have been told many times that, for coset multiplication to be defined, the subgroup must be normal.  I have seen the proof and examples of quotient group multiplications.  Now, I am trying to find out where the process will break down if the subgroup is not normal. Suppose that $x \in a_1H = a_2H, y \in b_1H = b_2H$, where $H$ is not normal. So $x = a_1h_1 = a_2h_2$ for some $h_1, h_2 \in H$, and $y = b_1h_1^* = b_2h_2^*$ for some $h_1, h_2 \in H$. $xy = (a_1b_1)(h_1h_1^*) = (a_2b_2)(h_2h_2^*)$.  However, both $h_1h_1^*, h_2h_2^*$ are still elements of $H$. So I don't see how $a_1b_1H \neq a_2b_2H$.",,"['abstract-algebra', 'group-theory', 'normal-subgroups']"
32,Group $\mathbb Q^*$ as direct product/sum,Group  as direct product/sum,\mathbb Q^*,"Is the group $\mathbb Q^*$ (rationals without $0$ under multiplication) a direct product or a direct sum of nontrivial subgroups? My thoughts: Consider subgroups $\langle p\rangle=\{p^k\mid k\in \mathbb Z\}$ generated by a positive prime $p$ and $\langle -1\rangle=\{-1,1\}$ . They are normal (because $\mathbb Q^*$ is abelian), intersects in $\{1\}$ and any $q\in \mathbb Q^*$ is uniquely written as quotient of primes' powers (finitely many). So, I think $\mathbb Q^*\cong \langle -1\rangle\times \bigoplus_p\langle p\rangle\,$ where $\bigoplus$ is the direct sum. And simply we can write $\mathbb Q^*\cong \Bbb Z_2\times \bigoplus_{i=1}^\infty \Bbb Z$ . Am I right?","Is the group (rationals without under multiplication) a direct product or a direct sum of nontrivial subgroups? My thoughts: Consider subgroups generated by a positive prime and . They are normal (because is abelian), intersects in and any is uniquely written as quotient of primes' powers (finitely many). So, I think where is the direct sum. And simply we can write . Am I right?","\mathbb Q^* 0 \langle p\rangle=\{p^k\mid k\in \mathbb Z\} p \langle -1\rangle=\{-1,1\} \mathbb Q^* \{1\} q\in \mathbb Q^* \mathbb Q^*\cong \langle -1\rangle\times \bigoplus_p\langle p\rangle\, \bigoplus \mathbb Q^*\cong \Bbb Z_2\times \bigoplus_{i=1}^\infty \Bbb Z","['abstract-algebra', 'group-theory', 'proof-verification', 'abelian-groups', 'rational-numbers']"
33,The necessary and sufficient condition for a unit element in Euclidean Domain,The necessary and sufficient condition for a unit element in Euclidean Domain,,"I am trying to prove that in Euclidean domain D with Euclidean function d , u in D is a unit if and only if d ( u )= d (1). Suppose u is a unit, then there exist v in D such that uv =1, this implies u \1 so d ( u )<= d (1), but obviously 1 divides u so d (1)<= d ( u ). Hence, d (u)= d (1). Conversely, suppose d (u)= d (1), since u is not zero, there exist q and r in D such that  1=uq+r with r=0 or d (r)< d (u). If r=0 then u is a unit. Else d (r)< d (u) = d (1), this implies d (r)< d (1). I stop here, because I failed to argue that r must be zero. Can anyone help me? Thanks.","I am trying to prove that in Euclidean domain D with Euclidean function d , u in D is a unit if and only if d ( u )= d (1). Suppose u is a unit, then there exist v in D such that uv =1, this implies u \1 so d ( u )<= d (1), but obviously 1 divides u so d (1)<= d ( u ). Hence, d (u)= d (1). Conversely, suppose d (u)= d (1), since u is not zero, there exist q and r in D such that  1=uq+r with r=0 or d (r)< d (u). If r=0 then u is a unit. Else d (r)< d (u) = d (1), this implies d (r)< d (1). I stop here, because I failed to argue that r must be zero. Can anyone help me? Thanks.",,"['abstract-algebra', 'ring-theory']"
34,The total ring of fractions of a reduced Noetherian ring is a direct product of fields,The total ring of fractions of a reduced Noetherian ring is a direct product of fields,,"This is question 6.5 in Matsumura's ""Commutative ring theory"": How can I prove that the total ring of fractions of a reduced Noetherian ring is a direct product of fields?","This is question 6.5 in Matsumura's ""Commutative ring theory"": How can I prove that the total ring of fractions of a reduced Noetherian ring is a direct product of fields?",,"['abstract-algebra', 'ring-theory', 'commutative-algebra', 'noetherian']"
35,Exercises to help a student become accustomed to Sweedler notation,Exercises to help a student become accustomed to Sweedler notation,,"For a coassociative coalgebra $A$, we have a comultiplication map $\Delta \colon A \to A \otimes A$. An element $c \in A$ is sent to a sum of simple tensors, which can be a mess of indices, so we can use Sweedler's notation to try to write down the comultiplication more cleanly: $$   \Delta(c) = \sum_i c_{{(1)}_i} \otimes c_{{(2)}_i}    = \sum_{(c)} c_{{(1)}} \otimes c_{{(2)}} $$ Sometimes even the sigma is omitted in the notation, and we simply write $\Delta(c) = c_{(1)} \otimes c_{(2)}$. Working with this sumless Sweedler notation takes some getting used to. What are some good introductory exercises to give a student practice working with Sweedler notation? I assume that there must be some canonical exercises like this one that only use the very basic properties of bialgebras or Hopf algebras.","For a coassociative coalgebra $A$, we have a comultiplication map $\Delta \colon A \to A \otimes A$. An element $c \in A$ is sent to a sum of simple tensors, which can be a mess of indices, so we can use Sweedler's notation to try to write down the comultiplication more cleanly: $$   \Delta(c) = \sum_i c_{{(1)}_i} \otimes c_{{(2)}_i}    = \sum_{(c)} c_{{(1)}} \otimes c_{{(2)}} $$ Sometimes even the sigma is omitted in the notation, and we simply write $\Delta(c) = c_{(1)} \otimes c_{(2)}$. Working with this sumless Sweedler notation takes some getting used to. What are some good introductory exercises to give a student practice working with Sweedler notation? I assume that there must be some canonical exercises like this one that only use the very basic properties of bialgebras or Hopf algebras.",,"['abstract-algebra', 'notation', 'tensor-products', 'hopf-algebras', 'coalgebras']"
36,Sum of elements of a finite field,Sum of elements of a finite field,,"Let $F$ be a finite field and $i$ an integer. Calculate the sum of all the elements of $F$, each raised to the $i$th power. My approach so far: Let $F=(0,1,\alpha,\alpha^2,...,\alpha^{p^n-1})$, where $p$ is a prime number and let $\sigma=1+\sum_{k=1}^{p^n-1}(α^k)^i$ be the desired sum. Since $F$ is a ring, each element has an additive inverse. Thus, the trivial case of $i=1$ results in $\sigma=1+[\alpha+(-\alpha)+\alpha^2+(-\alpha^2)+\cdots+\alpha^{p^n-1}+(-\alpha^{p^n-1})]=1$. We can also calculate the trivial case of $i=0$, where $\sigma=1+p^n-1=p^n$ In the general case, let $i=t (\text{mod } p^n)$. Then: $i=t+mp^n$, where $t,m$ are integers. We take into account the fact that the order of the multiplicative group of the finite field is $p^n$, so each element raised to the $p^n$ equals $1$. Thus $σ=1+α^t+α^{2t}+\cdots+α^{t(p^n-1)}$. This is the sum of a geometric progression, plus $1$. Thus, $σ=1+α(α^{p^n-1})/α-1$ = $ 1$+($α^{p^n}-α$)/${\alpha-1}$. But according to Lagrange's theorem, for every $\alpha\in F$, the polynomial $x^{p^n}-x$ is zero. It follows that $\sigma=1$. An important question is raised: Is it true that the characteristic of the finite field is $p$ if its order is $p^n$? If so, the case for $i=0$ leads to $σ=0≠1$ and all cases have been considered?","Let $F$ be a finite field and $i$ an integer. Calculate the sum of all the elements of $F$, each raised to the $i$th power. My approach so far: Let $F=(0,1,\alpha,\alpha^2,...,\alpha^{p^n-1})$, where $p$ is a prime number and let $\sigma=1+\sum_{k=1}^{p^n-1}(α^k)^i$ be the desired sum. Since $F$ is a ring, each element has an additive inverse. Thus, the trivial case of $i=1$ results in $\sigma=1+[\alpha+(-\alpha)+\alpha^2+(-\alpha^2)+\cdots+\alpha^{p^n-1}+(-\alpha^{p^n-1})]=1$. We can also calculate the trivial case of $i=0$, where $\sigma=1+p^n-1=p^n$ In the general case, let $i=t (\text{mod } p^n)$. Then: $i=t+mp^n$, where $t,m$ are integers. We take into account the fact that the order of the multiplicative group of the finite field is $p^n$, so each element raised to the $p^n$ equals $1$. Thus $σ=1+α^t+α^{2t}+\cdots+α^{t(p^n-1)}$. This is the sum of a geometric progression, plus $1$. Thus, $σ=1+α(α^{p^n-1})/α-1$ = $ 1$+($α^{p^n}-α$)/${\alpha-1}$. But according to Lagrange's theorem, for every $\alpha\in F$, the polynomial $x^{p^n}-x$ is zero. It follows that $\sigma=1$. An important question is raised: Is it true that the characteristic of the finite field is $p$ if its order is $p^n$? If so, the case for $i=0$ leads to $σ=0≠1$ and all cases have been considered?",,"['abstract-algebra', 'modular-arithmetic', 'finite-fields', 'abelian-groups']"
37,Are there nonisomorphic fields with isomorphic multiplicative groups?,Are there nonisomorphic fields with isomorphic multiplicative groups?,,"This is false for finite fields as the multiplicative groups of finite fields are cyclic, and different cardinalities yield cyclic groups of different cardinalities. But I'm unsure how to proceed for infinite fields.","This is false for finite fields as the multiplicative groups of finite fields are cyclic, and different cardinalities yield cyclic groups of different cardinalities. But I'm unsure how to proceed for infinite fields.",,['abstract-algebra']
38,Let $N$ be a normal subgroup of index $m$ in $G$. Prove that $a^m \in N$ for all $a \in G$.,Let  be a normal subgroup of index  in . Prove that  for all .,N m G a^m \in N a \in G,"I'm trying to understand this proof: Let $N$ be a normal subgroup of index $m$ in $G$. Prove that $a^m \in > N$ for all $a \in G$. Proof $\;\;$ Let $a\in G$. Since $[G:N]=m$, then $|G/N|=m$. From Lagrange's Theorem, it follows that $(aN)^m=a^mN=eN=N$. Hence $a^m  \in  N$. I don't understand why $a^mN=eN$. Can anybody help me out ?","I'm trying to understand this proof: Let $N$ be a normal subgroup of index $m$ in $G$. Prove that $a^m \in > N$ for all $a \in G$. Proof $\;\;$ Let $a\in G$. Since $[G:N]=m$, then $|G/N|=m$. From Lagrange's Theorem, it follows that $(aN)^m=a^mN=eN=N$. Hence $a^m  \in  N$. I don't understand why $a^mN=eN$. Can anybody help me out ?",,"['abstract-algebra', 'group-theory', 'finite-groups']"
39,On the spectrum of the sum of two commuting elements in a Banach algebra,On the spectrum of the sum of two commuting elements in a Banach algebra,,Original: Soit A une algèbre de Banach unitaire et a et b deux éléments tels que $a*b=b*a$ . Pourquoi $σ (a+b) \subset σ(a)+σ(b)$ . Et  qu’elle est la relation entre σ (a*b)  et σ(a) et σ(b)? Translation: Let $A$ be a unitary Banach algebra and the elements $a$ and $b$ such that $ab = ba$ . Why is the spectrum of $a + b$ contained in the sum of the spectra of $a$ and $b$ ? What relations do we have between the spectrum of $ab$ and the spectra of $a$ and $b$ ?,Original: Soit A une algèbre de Banach unitaire et a et b deux éléments tels que . Pourquoi . Et  qu’elle est la relation entre σ (a*b)  et σ(a) et σ(b)? Translation: Let be a unitary Banach algebra and the elements and such that . Why is the spectrum of contained in the sum of the spectra of and ? What relations do we have between the spectrum of and the spectra of and ?,a*b=b*a σ (a+b) \subset σ(a)+σ(b) A a b ab = ba a + b a b ab a b,"['abstract-algebra', 'functional-analysis', 'banach-algebras']"
40,What Are R-Modules Used For?,What Are R-Modules Used For?,,"Kind of a simple question, but what exactly are R-modules used for? Do they have any engineering applications? EDIT: If it helps, I'll give some more context to the question... I am a graduate student researcher in computer architecture, a subfield of computer engineering. Specifically, I do research on the best way to build future general purpose processors (stuff like the Intel i7). One thing I am looking into is if it is possible to apply mathematics to improve the design of CPUs. That is, can we use concepts from mathematics to improve the execution of general purpose programs on hardware. CPUs are a massive engineering design problem, and where exactly we could improve the design by applying math isn't entirely clear. What I don't have is a very deep mathematical background. I have taken an introductory abstract algebra course and one in coding theory. I've also read a number of coding theory papers... I know that other electrical engineering subfields like communications and compressed sensing have successfully applied elements of linear algebra and abstract algebra and have gotten very good results. The fact that this particular question spans both engineering and mathematics makes it both hard to formulate and to discuss with people. I'd be happy to talk about it in more detail, but I'm not entirely sure what the best forum would be for that. At least for now, I figured a good place to start would be to see if other people have successfully used some of the more abstract math concepts in engineering systems. One of the few I am aware of are R-modules, so I figured I'd ask if anyone knows of some engineering uses of them...","Kind of a simple question, but what exactly are R-modules used for? Do they have any engineering applications? EDIT: If it helps, I'll give some more context to the question... I am a graduate student researcher in computer architecture, a subfield of computer engineering. Specifically, I do research on the best way to build future general purpose processors (stuff like the Intel i7). One thing I am looking into is if it is possible to apply mathematics to improve the design of CPUs. That is, can we use concepts from mathematics to improve the execution of general purpose programs on hardware. CPUs are a massive engineering design problem, and where exactly we could improve the design by applying math isn't entirely clear. What I don't have is a very deep mathematical background. I have taken an introductory abstract algebra course and one in coding theory. I've also read a number of coding theory papers... I know that other electrical engineering subfields like communications and compressed sensing have successfully applied elements of linear algebra and abstract algebra and have gotten very good results. The fact that this particular question spans both engineering and mathematics makes it both hard to formulate and to discuss with people. I'd be happy to talk about it in more detail, but I'm not entirely sure what the best forum would be for that. At least for now, I figured a good place to start would be to see if other people have successfully used some of the more abstract math concepts in engineering systems. One of the few I am aware of are R-modules, so I figured I'd ask if anyone knows of some engineering uses of them...",,"['abstract-algebra', 'soft-question', 'modules']"
41,Is $f(\operatorname{rad}A)\subseteq\operatorname{rad}B$ for $f\colon A\to B$ not necessarily surjective?,Is  for  not necessarily surjective?,f(\operatorname{rad}A)\subseteq\operatorname{rad}B f\colon A\to B,"If I have two $K$-algebras $A$ and $B$ (associative, with identity) and an algebra homomorphism $f\colon A\to B$, is it true that $f(\operatorname{rad}A)\subseteq\operatorname{rad}B$, where $\operatorname{rad}$ denotes the Jacobsen radical, the intersection of all maximal right ideals? I can think of two proofs in the case that $f$ is surjective, but both depend on this surjectivity in a crucial way. The first uses the formulation of $\operatorname{rad}A$ as the set of $a\in A$ such that $1-ab$ is invertible for all $b\in A$, and the second treats an algebra as a module over itself, and uses the fact that the radical of $A$ as a module agrees with the radical of $A$ as an algebra, and is the intersection of kernels of maps onto simple modules; here the surjectivity is needed to make $B$ into an $A$-module in such a way that the radical of $B$ as an $A$-module is contained in the radical of $B$ as a $B$-module. If a counter example exists, $A$ will have to be infinite-dimensional, as in the finite dimensional case all elements of $\operatorname{rad}A$ are nilpotent, and (I think, although I don't remember a proof right now, so maybe I'm wrong) that the radical always contains every nilpotent element. This is my first question on here, so let me know if I should have done anything differently!","If I have two $K$-algebras $A$ and $B$ (associative, with identity) and an algebra homomorphism $f\colon A\to B$, is it true that $f(\operatorname{rad}A)\subseteq\operatorname{rad}B$, where $\operatorname{rad}$ denotes the Jacobsen radical, the intersection of all maximal right ideals? I can think of two proofs in the case that $f$ is surjective, but both depend on this surjectivity in a crucial way. The first uses the formulation of $\operatorname{rad}A$ as the set of $a\in A$ such that $1-ab$ is invertible for all $b\in A$, and the second treats an algebra as a module over itself, and uses the fact that the radical of $A$ as a module agrees with the radical of $A$ as an algebra, and is the intersection of kernels of maps onto simple modules; here the surjectivity is needed to make $B$ into an $A$-module in such a way that the radical of $B$ as an $A$-module is contained in the radical of $B$ as a $B$-module. If a counter example exists, $A$ will have to be infinite-dimensional, as in the finite dimensional case all elements of $\operatorname{rad}A$ are nilpotent, and (I think, although I don't remember a proof right now, so maybe I'm wrong) that the radical always contains every nilpotent element. This is my first question on here, so let me know if I should have done anything differently!",,"['abstract-algebra', 'representation-theory']"
42,Noetherian integral domain such that $m/m^2$ is a one-dimensional vector space over $A/m$,Noetherian integral domain such that  is a one-dimensional vector space over,m/m^2 A/m,"I am having trouble doing the following question (I'm studying for quals, it isn't homework) If $A$ is a noetherian integral domain such that for every maximal $m\subset A$, the quotient $m/m^2$ is a one-dimensional vector space over the field $A/m$ (a) Prove every nonzero prime ideal is maximal. (b) Prove $A$ is integrally closed. There is a hint which says that one should localize at maximal ideals. My problem is that I'm not really sure how to use the $m/m^2$ condition. A solution or hint in the right direction using a minimal amount of commutative algebra would be much appreciated (but clearly a decent amount should be used).","I am having trouble doing the following question (I'm studying for quals, it isn't homework) If $A$ is a noetherian integral domain such that for every maximal $m\subset A$, the quotient $m/m^2$ is a one-dimensional vector space over the field $A/m$ (a) Prove every nonzero prime ideal is maximal. (b) Prove $A$ is integrally closed. There is a hint which says that one should localize at maximal ideals. My problem is that I'm not really sure how to use the $m/m^2$ condition. A solution or hint in the right direction using a minimal amount of commutative algebra would be much appreciated (but clearly a decent amount should be used).",,"['abstract-algebra', 'commutative-algebra', 'ring-theory']"
43,Is there any relation of injective modules to free modules?,Is there any relation of injective modules to free modules?,,"Projective modules are direct summands of free modules. As I perceive it, projections and injections are dual notions. Based on that, I was looking whether there is a relation of injective modules to free modules (similar to the natural relation of projective modules  to free modules) or to another kind of module that has potentially ""dual"" properties to that of a free module. Any insights? Thank you :-)","Projective modules are direct summands of free modules. As I perceive it, projections and injections are dual notions. Based on that, I was looking whether there is a relation of injective modules to free modules (similar to the natural relation of projective modules  to free modules) or to another kind of module that has potentially ""dual"" properties to that of a free module. Any insights? Thank you :-)",,"['abstract-algebra', 'commutative-algebra', 'modules', 'injective-module', 'free-modules']"
44,How many homomorphism from $S_3$ to $S_4$?,How many homomorphism from  to ?,S_3 S_4,"How many homomorphism from  $S_3$ to $S_4$? Please find these using fundamental theorem. I think  if $f\colon G \rightarrow G'$ is a group homomorphism then $G/\ker f$ is isomorphic to a subgroup of  $G'$. For one choice of $\ker f$, the order of $G/\ker f$ is $k$ and $G'$ has $n$ subgroups of  order $k$ . Hence there are $n$ homomorphisms. But in case of $S_3$ to $S_4$,  if $S_3/\ker f$ is a subgroup of $S_4$ then we have three cases: $\ker f = \{\mathrm{id}\}$:  then $S_3$ is isomorphic to a subgroup of $S_4$. There are 4 subgroups in $S_4$ isomorphic to $S_3$ so in this case we have 4 homomorphisms. $\ker f = A_3$ then $S_3/A_3$ is a subgroup of order 2 in $S_4$. Again, 9 subgroups in $S_4$  so 9 homomorphisms. $\ker f = S_3$ which gives 0 homomorphism. So in total 14 homomorphisms. Am I right ?","How many homomorphism from  $S_3$ to $S_4$? Please find these using fundamental theorem. I think  if $f\colon G \rightarrow G'$ is a group homomorphism then $G/\ker f$ is isomorphic to a subgroup of  $G'$. For one choice of $\ker f$, the order of $G/\ker f$ is $k$ and $G'$ has $n$ subgroups of  order $k$ . Hence there are $n$ homomorphisms. But in case of $S_3$ to $S_4$,  if $S_3/\ker f$ is a subgroup of $S_4$ then we have three cases: $\ker f = \{\mathrm{id}\}$:  then $S_3$ is isomorphic to a subgroup of $S_4$. There are 4 subgroups in $S_4$ isomorphic to $S_3$ so in this case we have 4 homomorphisms. $\ker f = A_3$ then $S_3/A_3$ is a subgroup of order 2 in $S_4$. Again, 9 subgroups in $S_4$  so 9 homomorphisms. $\ker f = S_3$ which gives 0 homomorphism. So in total 14 homomorphisms. Am I right ?",,"['abstract-algebra', 'group-theory', 'finite-groups', 'group-homomorphism']"
45,Intuition behind definition of spinor,Intuition behind definition of spinor,,"Some time ago I searched for the definition of spinors and found the wikipedia page on the subject. Although highly detailed the page tries to talk about many different constructions and IMHO doesn't give the intuition behind any of them. As far as I know physicists prefer to define spinors based on transformation laws (as with vectors and tensors), but all due respect, I find these kind of definitions quite unpleasant. Vectors and tensors can be defined in much more intuitive ways and I believe the same happens with spinors. In that case, how does one really define spinors without resorting to transformation properties and what is the underlying intuition behind the definition? How the definition relates to the idea of spin from Quantum Mechanics? In Wikipedia's page we have two definitions. One based on spin groups and another based on Clifford Algebras. I couldn't understand the intuition behind neither of them, so I'd like really to get not just the definition but the intuition behind it.","Some time ago I searched for the definition of spinors and found the wikipedia page on the subject. Although highly detailed the page tries to talk about many different constructions and IMHO doesn't give the intuition behind any of them. As far as I know physicists prefer to define spinors based on transformation laws (as with vectors and tensors), but all due respect, I find these kind of definitions quite unpleasant. Vectors and tensors can be defined in much more intuitive ways and I believe the same happens with spinors. In that case, how does one really define spinors without resorting to transformation properties and what is the underlying intuition behind the definition? How the definition relates to the idea of spin from Quantum Mechanics? In Wikipedia's page we have two definitions. One based on spin groups and another based on Clifford Algebras. I couldn't understand the intuition behind neither of them, so I'd like really to get not just the definition but the intuition behind it.",,"['abstract-algebra', 'representation-theory', 'mathematical-physics', 'clifford-algebras', 'spin-geometry']"
46,Right module vs left module,Right module vs left module,,"I would like to have your help on this. Consider the following diagram summarizing the opposition left module-right module: Left module vs Right module (s an t represent scalars) Left module: $$s(x + y) = sx + sy$$ $$(s_1 + s_2)x = s_1x + s_2x$$  $$s(tx) = (s t)x$$ Right module $$(x + y)t = xt + yt$$ $$x(t_1 + t_2) = xt_1 + xt_2$$ $$(xs)t = x(s t)$$ Well, the thing is, I somewhere found this statement: "".....the distinction is not purely syntactical, since it implies two different associativity rules linking multiplication in a module with multiplication in a ring."" Could anyone be more specific on that and illustrate the diffence so that it becomes clear it is not simply a syntactic one. Would it be a semantic one or what exactly?","I would like to have your help on this. Consider the following diagram summarizing the opposition left module-right module: Left module vs Right module (s an t represent scalars) Left module: $$s(x + y) = sx + sy$$ $$(s_1 + s_2)x = s_1x + s_2x$$  $$s(tx) = (s t)x$$ Right module $$(x + y)t = xt + yt$$ $$x(t_1 + t_2) = xt_1 + xt_2$$ $$(xs)t = x(s t)$$ Well, the thing is, I somewhere found this statement: "".....the distinction is not purely syntactical, since it implies two different associativity rules linking multiplication in a module with multiplication in a ring."" Could anyone be more specific on that and illustrate the diffence so that it becomes clear it is not simply a syntactic one. Would it be a semantic one or what exactly?",,"['abstract-algebra', 'terminology', 'modules', 'ideals']"
47,"If $P$ is a prime ideal of $R$, then $P[x]$ is a prime ideal of $R[x]$, for $R$ a commutative ring.","If  is a prime ideal of , then  is a prime ideal of , for  a commutative ring.",P R P[x] R[x] R,"Prove that if $P$ is a prime ideal of $R$ then $P[x]$ is a prime ideal of $R[x]$ . This is homework. I have been trying to assume that there is an $fg$ in $P[x]$ such that neither $f$ nor $g$ is in $P[x]$ . Hence $f$ and $g$ have at least one coefficient not in $P$ . I was trying to show that $fg$ would then have a coefficient not in $P$ , obtaining a contradiction. But I don't see how to control the terms. If $f$ and $g$ had only one coefficient not in $P$ , then I think I could use the properties of the ideal to complete the proof. The problem is not being able to know for certain which if any of the coefficients of $f$ and $g$ are in $P$ . Perhaps my approach is wrong to begin. Please help. Even a hint in the right direction will much appreciated.","Prove that if is a prime ideal of then is a prime ideal of . This is homework. I have been trying to assume that there is an in such that neither nor is in . Hence and have at least one coefficient not in . I was trying to show that would then have a coefficient not in , obtaining a contradiction. But I don't see how to control the terms. If and had only one coefficient not in , then I think I could use the properties of the ideal to complete the proof. The problem is not being able to know for certain which if any of the coefficients of and are in . Perhaps my approach is wrong to begin. Please help. Even a hint in the right direction will much appreciated.",P R P[x] R[x] fg P[x] f g P[x] f g P fg P f g P f g P,"['abstract-algebra', 'polynomials', 'ring-theory', 'commutative-algebra']"
48,Example of a ring without Invariant Basis Property,Example of a ring without Invariant Basis Property,,"Let $A$ be a ring and consider the free modules $A^{\oplus n}$ , $A^{\oplus k}$ , with $n,k\in \mathbb{N}$ . Can $A^{\oplus n}$ be isomorphic to $A^{\oplus k}$ if $k\neq n$ ? Thanks in advance for the help.","Let be a ring and consider the free modules , , with . Can be isomorphic to if ? Thanks in advance for the help.","A A^{\oplus n} A^{\oplus k} n,k\in \mathbb{N} A^{\oplus n} A^{\oplus k} k\neq n","['abstract-algebra', 'modules']"
49,Algorithms for factoring multivariate polynomials,Algorithms for factoring multivariate polynomials,,"I am wondering if there are any algorithms to factor polynomials in multiple variables, when you know that the factors are other polynomials with rational or integer coefficients. I know you have the rational root theorem, which helps out a lot, but it isn't always obvious how to apply this. Suppose we have the expression $$ 2y^6 - 5x^6 + x^5y^5 - 10xy $$ (I deliberately choose factors with x and y in high powers, to avoid the solutions being solving by completing the square, Cardano's formula, or Ferrari's formula) This case might be doable: the powers in the terms suggest terms of $x^5$ and $y^5$ and $x$ and $y$, so with a little inspection one might expect the factorization to be of the form $(ax^5+by)(cy^5+dx)$. The term $x^5y^5$ suggests $a=c=1$ and from there it's almost trivial (you can use the rational root theorem, but I don't think that is even necessary). It seems to be doable in this case, which makes it plausible that there is an algorithm who does something like this. Also, I was wondering about another specific case, in just one variable: $$ (x - a)(x - b)(x - c) $$ With $a, b, c$ integers with a very large absolute value. You can't use Cardano for this (casus irreducibilis), and in order to use the rational root theorem, you need to factorize abc, a very large number (which is very slow). Besides, using the rational root theorem would not make use of the information that the values $a + b + c$ and $bc + ac + ab$ are also known (because they are coefficients in the polynomial). One trivial algorithm I can come up with is to enumerate all polynomials (we do this by enumerating their coefficients, and integers and rationals are countable, so we can do this) with powers equal to or lower than the powers in the original polynomial, and try if long division yields a rest term (if not, we found a factor). Of course, this is too slow to be practical, but this and the fact that Wolfram Alpha can usually find the factorization of complicated polynomials (though I haven't tried this thoroughly), suggests there is at least one algorithm to do this in a more or less practical way.","I am wondering if there are any algorithms to factor polynomials in multiple variables, when you know that the factors are other polynomials with rational or integer coefficients. I know you have the rational root theorem, which helps out a lot, but it isn't always obvious how to apply this. Suppose we have the expression $$ 2y^6 - 5x^6 + x^5y^5 - 10xy $$ (I deliberately choose factors with x and y in high powers, to avoid the solutions being solving by completing the square, Cardano's formula, or Ferrari's formula) This case might be doable: the powers in the terms suggest terms of $x^5$ and $y^5$ and $x$ and $y$, so with a little inspection one might expect the factorization to be of the form $(ax^5+by)(cy^5+dx)$. The term $x^5y^5$ suggests $a=c=1$ and from there it's almost trivial (you can use the rational root theorem, but I don't think that is even necessary). It seems to be doable in this case, which makes it plausible that there is an algorithm who does something like this. Also, I was wondering about another specific case, in just one variable: $$ (x - a)(x - b)(x - c) $$ With $a, b, c$ integers with a very large absolute value. You can't use Cardano for this (casus irreducibilis), and in order to use the rational root theorem, you need to factorize abc, a very large number (which is very slow). Besides, using the rational root theorem would not make use of the information that the values $a + b + c$ and $bc + ac + ab$ are also known (because they are coefficients in the polynomial). One trivial algorithm I can come up with is to enumerate all polynomials (we do this by enumerating their coefficients, and integers and rationals are countable, so we can do this) with powers equal to or lower than the powers in the original polynomial, and try if long division yields a rest term (if not, we found a factor). Of course, this is too slow to be practical, but this and the fact that Wolfram Alpha can usually find the factorization of complicated polynomials (though I haven't tried this thoroughly), suggests there is at least one algorithm to do this in a more or less practical way.",,"['abstract-algebra', 'algebra-precalculus', 'polynomials', 'nonlinear-system']"
50,Is a topological group action continuous if and only if all the stabilizers are open?,Is a topological group action continuous if and only if all the stabilizers are open?,,"Let $G$ be a topological group and $(X,\mu)$ be a $G$-set, i.e. $\mu$ defines an action $X \times G \rightarrow X$. Is it then true that $\mu$ is continuous if and only if for every $x \in X$ the stabilizer subgroup $G_x$ is open in $G$? If yes, how does one prove this?","Let $G$ be a topological group and $(X,\mu)$ be a $G$-set, i.e. $\mu$ defines an action $X \times G \rightarrow X$. Is it then true that $\mu$ is continuous if and only if for every $x \in X$ the stabilizer subgroup $G_x$ is open in $G$? If yes, how does one prove this?",,"['abstract-algebra', 'group-theory', 'general-topology', 'topological-groups']"
51,No group of order 400 is simple,No group of order 400 is simple,,"I've been given the question of showing that no group of order $400$ is simple. I've tried to attack it via the Sylow theorems for about a week now, but all the tricks and methods I know seem to be failing horribly. Things I've tried: Trying to produce a contradiction by giving a map into $S_n$ by elements acting by conjugation on Sylow 5-subgroups doesn't work, since there are 16 such Sylow 5-subgroups, and 400 divides $16!$, so it might very well be an injection and therefore we can't obviously find a nontrivial kernel. Trying element counting is messy and I can't get it to come out the way I want- for instance, we can show that each of the Sylow 5-subgroups is isomorphic to $\mathbb{Z}_5\times \mathbb{Z}_5$, so there should be at least 125 elements of order divisible by only 5, but I can't see this producing a contradiction with any of the  things I can find out about Sylow 2-subgroups. Anyways, I'm probably missing something fairly obvious, and I would appreciate any hints, solutions, or other help that you could give.","I've been given the question of showing that no group of order $400$ is simple. I've tried to attack it via the Sylow theorems for about a week now, but all the tricks and methods I know seem to be failing horribly. Things I've tried: Trying to produce a contradiction by giving a map into $S_n$ by elements acting by conjugation on Sylow 5-subgroups doesn't work, since there are 16 such Sylow 5-subgroups, and 400 divides $16!$, so it might very well be an injection and therefore we can't obviously find a nontrivial kernel. Trying element counting is messy and I can't get it to come out the way I want- for instance, we can show that each of the Sylow 5-subgroups is isomorphic to $\mathbb{Z}_5\times \mathbb{Z}_5$, so there should be at least 125 elements of order divisible by only 5, but I can't see this producing a contradiction with any of the  things I can find out about Sylow 2-subgroups. Anyways, I'm probably missing something fairly obvious, and I would appreciate any hints, solutions, or other help that you could give.",,"['abstract-algebra', 'group-theory', 'finite-groups']"
52,The p-adic numbers as an ordered group,The p-adic numbers as an ordered group,,"So I understand that there is no order on the field of $p$ -adic numbers $\mathbb{Q}_p$ that makes it into an ordered field (i.e.) compatible with both addition and multiplication. Now, from the responses to a couple of my previous questions, $\mathbb{Q}_p$ is a divisible abelian group under addition (being a field of characteristic $0$ ). $\mathbb{Q}_p$ is torsion-free. It admits an order compatible with the group operation (addition), since every torsion-free abelian group is orderable. My question is, can I write an explicit ordering of $\mathbb{Q}_p$ compatible with the group operation? By ""explicit"", I mean an ordering in which, given two $p$ -adic numbers, I can decide which is greater. P.S.: I was not sure how to classify this problem, so please feel free to change the tags.","So I understand that there is no order on the field of -adic numbers that makes it into an ordered field (i.e.) compatible with both addition and multiplication. Now, from the responses to a couple of my previous questions, is a divisible abelian group under addition (being a field of characteristic ). is torsion-free. It admits an order compatible with the group operation (addition), since every torsion-free abelian group is orderable. My question is, can I write an explicit ordering of compatible with the group operation? By ""explicit"", I mean an ordering in which, given two -adic numbers, I can decide which is greater. P.S.: I was not sure how to classify this problem, so please feel free to change the tags.",p \mathbb{Q}_p \mathbb{Q}_p 0 \mathbb{Q}_p \mathbb{Q}_p p,"['abstract-algebra', 'order-theory', 'p-adic-number-theory']"
53,"If A is noetherian, then Spec(A) is noetherian","If A is noetherian, then Spec(A) is noetherian",,"Let A be a noetherian ring. How can I show that Spec(A) is noetherian? Also, is there a way to show this by showing directly that the closed sets in Spec(A) satisfy the descending chain condition? (This is exercise 6.8 from Atiyah and Macdonald.)","Let A be a noetherian ring. How can I show that Spec(A) is noetherian? Also, is there a way to show this by showing directly that the closed sets in Spec(A) satisfy the descending chain condition? (This is exercise 6.8 from Atiyah and Macdonald.)",,"['abstract-algebra', 'ring-theory', 'commutative-algebra', 'noetherian']"
54,"Problem in the ""proof"" of Eisenstein's criterion on irreducibility.","Problem in the ""proof"" of Eisenstein's criterion on irreducibility.",,"I have a problem about a line inside the following proof which is actually from the book Abstract Algebra by Dummit & Foote Proposition (Eisenstein's Criterion) . Let $P$ be a prime ideal in the integral domain $R$ and let $~f(x)=x^n+a_{n-1}x^{n-1}+\dots +a_0$ be a polynomial in $R[x]$ $(n\ge1)$. Suppose $a_{n-1},\dots ,a_0$ are all elements of $P$ and $a_0$ is not an element of $P^2$. Then $f(x)$ is irreducible. Proof. Suppose $f(x)$ is reducible, say $f(x)=a(x)b(x)$ in $R[x]$, where $a(x),b(x)$ are non-constant polynomials. Reducing this equation modulo $P$ and using the assumptions on the coefficients of $f(x)$ we obtain the equation $x^n=\overline{a(x)b(x)}$ in $(R/P)[x]$, where bar denotes the polynomials with coefficients reduced mod $P$. Since $P$ is prime ideal, $R/P$ is an integral domain, and it follows that both of $\overline{a(x)}$ and $\overline{b(x)}$ have $0$ constant term , i.e, the constant term of both $a(x)$ and $b(x)$ are elements of $P$. But then constant term of $a_0$ of $~f(x)$ as the product of these two would be an element of $P^2$, a contradiction. This completes the proof. But I cannot understand the line which I have bold in the proof. What I understand is that since $x^n=\overline{a(x)b(x)}$, so comparing the coefficients on both sides we get the product of the constant terms of $~\overline{a(x)}$ and $~\overline{b(x)}$ is zero in $(R/P)[x]$, which is a Integral domain.....then either the constant term of $~\overline{a(x)}=0$ or constant term of $~\overline{b(x)}=0$...But how does both of them is zero? Please help.","I have a problem about a line inside the following proof which is actually from the book Abstract Algebra by Dummit & Foote Proposition (Eisenstein's Criterion) . Let $P$ be a prime ideal in the integral domain $R$ and let $~f(x)=x^n+a_{n-1}x^{n-1}+\dots +a_0$ be a polynomial in $R[x]$ $(n\ge1)$. Suppose $a_{n-1},\dots ,a_0$ are all elements of $P$ and $a_0$ is not an element of $P^2$. Then $f(x)$ is irreducible. Proof. Suppose $f(x)$ is reducible, say $f(x)=a(x)b(x)$ in $R[x]$, where $a(x),b(x)$ are non-constant polynomials. Reducing this equation modulo $P$ and using the assumptions on the coefficients of $f(x)$ we obtain the equation $x^n=\overline{a(x)b(x)}$ in $(R/P)[x]$, where bar denotes the polynomials with coefficients reduced mod $P$. Since $P$ is prime ideal, $R/P$ is an integral domain, and it follows that both of $\overline{a(x)}$ and $\overline{b(x)}$ have $0$ constant term , i.e, the constant term of both $a(x)$ and $b(x)$ are elements of $P$. But then constant term of $a_0$ of $~f(x)$ as the product of these two would be an element of $P^2$, a contradiction. This completes the proof. But I cannot understand the line which I have bold in the proof. What I understand is that since $x^n=\overline{a(x)b(x)}$, so comparing the coefficients on both sides we get the product of the constant terms of $~\overline{a(x)}$ and $~\overline{b(x)}$ is zero in $(R/P)[x]$, which is a Integral domain.....then either the constant term of $~\overline{a(x)}=0$ or constant term of $~\overline{b(x)}=0$...But how does both of them is zero? Please help.",,"['abstract-algebra', 'ring-theory', 'irreducible-polynomials']"
55,Show that left cosets partition the group,Show that left cosets partition the group,,"I know how to prove that it happens, by proving that the left coset definition actually is an equivalence relation. Then, it's proved that it partitions the set, since equivalence relations do it. However, this exercise asks me to prove it in a diferente way. First it asks me to show that: a) The union of the left cosets is equal to $G$ b) If $gH \cap g'H \neq \emptyset$ then $gH = g'H$ for $a)$ I'm  thinking about the following: $gH = \{gh, h\in H\}$ So if $G = \{g_1, g_2, \cdots g_n\}$ We would have the following left cosets: $$g_1H = \{g_1h, h\in H\}$$ $$g_2H = \{g_2h, h\in H\}$$ $$\cdots$$ $$g_nH = \{g_nh, h\in H\}$$ The union of all these sets will include all the $g's$, since for each set $$g_k = \{g_kh, h\in H\}$$ we have $$ge \in g_k = \{g_kh, h\in H\}$$ where $e$ is the identity. Then if we make the union of all these sets we'll have at least all the elements of $g$. The other elements are merely $gh$ for some $h$. But since $gh\in G$ they would be repeated elements in the union, doesn't matter. So, the union of all left cosets of $H$ in $G$ is $G$. Is my reasoning correct? Also, what could I do to prove $b)$?","I know how to prove that it happens, by proving that the left coset definition actually is an equivalence relation. Then, it's proved that it partitions the set, since equivalence relations do it. However, this exercise asks me to prove it in a diferente way. First it asks me to show that: a) The union of the left cosets is equal to $G$ b) If $gH \cap g'H \neq \emptyset$ then $gH = g'H$ for $a)$ I'm  thinking about the following: $gH = \{gh, h\in H\}$ So if $G = \{g_1, g_2, \cdots g_n\}$ We would have the following left cosets: $$g_1H = \{g_1h, h\in H\}$$ $$g_2H = \{g_2h, h\in H\}$$ $$\cdots$$ $$g_nH = \{g_nh, h\in H\}$$ The union of all these sets will include all the $g's$, since for each set $$g_k = \{g_kh, h\in H\}$$ we have $$ge \in g_k = \{g_kh, h\in H\}$$ where $e$ is the identity. Then if we make the union of all these sets we'll have at least all the elements of $g$. The other elements are merely $gh$ for some $h$. But since $gh\in G$ they would be repeated elements in the union, doesn't matter. So, the union of all left cosets of $H$ in $G$ is $G$. Is my reasoning correct? Also, what could I do to prove $b)$?",,"['abstract-algebra', 'group-theory', 'finite-groups']"
56,Cancellation problem: $R\not\cong S$ but $R[t]\cong S[t]$ (Danielewski surfaces),Cancellation problem:  but  (Danielewski surfaces),R\not\cong S R[t]\cong S[t],"I would like to understand why the two rings $$ R={\mathbb{C}[x,y,z]}/{(xy - (1 - z^2))} \\ S=\mathbb{C}[x,y,z]/{(x^2y - (1 - z^2))} $$ are not isomorphic, but $R[t]\cong S[t]$. This example is discussed in this document by Hochster. He references a paper by Danielewski, but it is a preprint from 1989, so I could not locate it anywhere. In fact, this example was also given by Timothy Wagner in this MSE thread , but no proof was supplied. Finally, this MSE thread seems to refer to this problem (though possibly with different formulation), but unfortunately it hasn't even received a single comment in the last 3.5 years. Can someone either find a precise reference (preferably online, or at least published in some book/journal) or supply a proof for this claim?","I would like to understand why the two rings $$ R={\mathbb{C}[x,y,z]}/{(xy - (1 - z^2))} \\ S=\mathbb{C}[x,y,z]/{(x^2y - (1 - z^2))} $$ are not isomorphic, but $R[t]\cong S[t]$. This example is discussed in this document by Hochster. He references a paper by Danielewski, but it is a preprint from 1989, so I could not locate it anywhere. In fact, this example was also given by Timothy Wagner in this MSE thread , but no proof was supplied. Finally, this MSE thread seems to refer to this problem (though possibly with different formulation), but unfortunately it hasn't even received a single comment in the last 3.5 years. Can someone either find a precise reference (preferably online, or at least published in some book/journal) or supply a proof for this claim?",,"['abstract-algebra', 'algebraic-geometry', 'reference-request', 'ring-theory', 'commutative-algebra']"
57,"For abelian groups: does knowing $\text{Hom}(X,Z)$ for all $Z$ suffice to determine $X$?",For abelian groups: does knowing  for all  suffice to determine ?,"\text{Hom}(X,Z) Z X","Let $X$ and $Y$ be abelian groups. Suppose $\text{Hom}(X,Z)\cong \text{Hom}(Y,Z)$ for all abelian groups $Z$. Does it follow that $X \cong Y$? It has been answered before that this is true if the bijection $\text{Hom}(X,Z)\to \text{Hom}(Y,Z)$ is natural in $Z$. My intuition says that this assumption shouldn't be necessary. Maybe if we choose an extremely large and suitably ""generic"" group $Z$, then the structure of $\text{Hom}(X,Z)$ will somehow reveal the structure of $X$? I'm also interested in the answer if ""abelian group"" is replaced by some other structure, in particular ""$R$-module"".","Let $X$ and $Y$ be abelian groups. Suppose $\text{Hom}(X,Z)\cong \text{Hom}(Y,Z)$ for all abelian groups $Z$. Does it follow that $X \cong Y$? It has been answered before that this is true if the bijection $\text{Hom}(X,Z)\to \text{Hom}(Y,Z)$ is natural in $Z$. My intuition says that this assumption shouldn't be necessary. Maybe if we choose an extremely large and suitably ""generic"" group $Z$, then the structure of $\text{Hom}(X,Z)$ will somehow reveal the structure of $X$? I'm also interested in the answer if ""abelian group"" is replaced by some other structure, in particular ""$R$-module"".",,"['abstract-algebra', 'group-theory', 'modules', 'abelian-groups']"
58,Pronunciation of `Rng` - the non-unital Ring,Pronunciation of `Rng` - the non-unital Ring,,"I chuckled the first time I heard that a Ring without a multiplicative identity (R i ng without the i ) is called a Rng (pronounced wrong ). According to Wikipedia , it's pronounced rung . How is Rng pronounced in research/academia?","I chuckled the first time I heard that a Ring without a multiplicative identity (R i ng without the i ) is called a Rng (pronounced wrong ). According to Wikipedia , it's pronounced rung . How is Rng pronounced in research/academia?",,"['abstract-algebra', 'ring-theory', 'rngs']"
59,"Structure of a group, $G$, of order $pq$ where $p, q$ are prime. [duplicate]","Structure of a group, , of order  where  are prime. [duplicate]","G pq p, q","This question already has an answer here : Question on groups of order $pq$ (1 answer) Closed 4 years ago . There is a proposition in Beachy and Blair's Abstract Algebra that I don't entirely follow. The proposition is the following: Let $G$ be a group of order $pq$, where $p > q$ are primes. a) If $q$ is not a divisor of $p-1$, the $G$ is cyclic. b) If $q$ is a divisor of $p-1$, then either $G$ is cyclic or else $G$ is generated by two elements $a$ and $b$ satisfying the following equations: $$a^p = e, \\ b^q = e,\\ ba = a^nb $$ where $n \not \equiv 1  \ (mod \ p)$ but $n^q \equiv 1 \ (mod \ p)$. Can one of you prove how this is true? I understand a similar proof for when $q=2$, but this one is more complicated.","This question already has an answer here : Question on groups of order $pq$ (1 answer) Closed 4 years ago . There is a proposition in Beachy and Blair's Abstract Algebra that I don't entirely follow. The proposition is the following: Let $G$ be a group of order $pq$, where $p > q$ are primes. a) If $q$ is not a divisor of $p-1$, the $G$ is cyclic. b) If $q$ is a divisor of $p-1$, then either $G$ is cyclic or else $G$ is generated by two elements $a$ and $b$ satisfying the following equations: $$a^p = e, \\ b^q = e,\\ ba = a^nb $$ where $n \not \equiv 1  \ (mod \ p)$ but $n^q \equiv 1 \ (mod \ p)$. Can one of you prove how this is true? I understand a similar proof for when $q=2$, but this one is more complicated.",,"['abstract-algebra', 'group-theory', 'finite-groups']"
60,"When is a local, reduced, (commutative) ring an integral domain?","When is a local, reduced, (commutative) ring an integral domain?",,"Question I am wondering whether or not it is true that if $A$ is a reduced ring, then  is it the case that the localization of $A$ at any of its prime ideals is an integral domain? Discussion Recall that $A$ is reduced if it contains no nonzero nilpotents, i.e. $Nil(A)=\{0\}$. I have already shown the following two facts: A ring $A$ being reduced is a local property, i.e. $A$ is reduced if and only if the localization of $A$ at any prime ideal is reduced. $A$ reduced does not imply $A$ is an integral domain (in general). The counter example I used to prove $2$ was $\mathbb{Z}/6\mathbb{Z}$. Unfortunately, in this case all the localizations at prime ideals are integral domains, and they seem to be in every example I can think of. More generally, one could ask the question (since localizations are local rings), when is a reduced local ring an integral domain? If anyone had a good idea for a counterexample to the original question (or a proof if it is true-although I doubt this since being an integral domain seems much stronger than being reduced), that would be much appreciated. This is one of 12 parts to a question which I had on my midterm a few weeks ago, and the only part I have not figured out of that question","Question I am wondering whether or not it is true that if $A$ is a reduced ring, then  is it the case that the localization of $A$ at any of its prime ideals is an integral domain? Discussion Recall that $A$ is reduced if it contains no nonzero nilpotents, i.e. $Nil(A)=\{0\}$. I have already shown the following two facts: A ring $A$ being reduced is a local property, i.e. $A$ is reduced if and only if the localization of $A$ at any prime ideal is reduced. $A$ reduced does not imply $A$ is an integral domain (in general). The counter example I used to prove $2$ was $\mathbb{Z}/6\mathbb{Z}$. Unfortunately, in this case all the localizations at prime ideals are integral domains, and they seem to be in every example I can think of. More generally, one could ask the question (since localizations are local rings), when is a reduced local ring an integral domain? If anyone had a good idea for a counterexample to the original question (or a proof if it is true-although I doubt this since being an integral domain seems much stronger than being reduced), that would be much appreciated. This is one of 12 parts to a question which I had on my midterm a few weeks ago, and the only part I have not figured out of that question",,"['abstract-algebra', 'commutative-algebra', 'ring-theory']"
61,"Unit, co-unit of adjunction","Unit, co-unit of adjunction",,Let us assume the following: (I) $F:Set\rightarrow Group$ is the free group functor and $f:Group\rightarrow Set$ is the natural forgetful functor. (ii) $F:Group\rightarrow Ab$ is the abelianization and $G:Ab\rightarrow Group$ is the forgetful functor. Could someone kindly explicitly compute the unit and co-unit of the adjunction in the above two cases please?,Let us assume the following: (I) $F:Set\rightarrow Group$ is the free group functor and $f:Group\rightarrow Set$ is the natural forgetful functor. (ii) $F:Group\rightarrow Ab$ is the abelianization and $G:Ab\rightarrow Group$ is the forgetful functor. Could someone kindly explicitly compute the unit and co-unit of the adjunction in the above two cases please?,,"['abstract-algebra', 'category-theory', 'adjoint-functors']"
62,A question about the relationship between submodule and ideal,A question about the relationship between submodule and ideal,,"It is stated in Wikipedia that if $I$ is an ideal of $R$, that is $I\triangleleft R$, then $_R I$ is a submodule of $_R R$. Here, I assume $R$ is commutative. Despite the notation, I mean ideal is the left and right ideal. But it can interpreted as left or right ideal only if necessary. The point of my question is not emphasising on left or right, I am just curious whether the statement works for the converse. Hopefully it is clear. But if there is something wrong in my interpretation, please kindly let me know. I would like to know whether the converse is true, but it is not stated in Wikipedia. That is for any submodule $_R N$ of $_R R$, then $N$ is an ideal of $R$? In other words, is it true that if $_R N\subseteq _R R$ then $N\triangleleft R$? If this is a well known useful property, then it should be stated, but I could not find in some books that I read and other sources. Is it something to proof or is it defined? If it is something to proof, could anyone give some ideas about the proof? Thanks!","It is stated in Wikipedia that if $I$ is an ideal of $R$, that is $I\triangleleft R$, then $_R I$ is a submodule of $_R R$. Here, I assume $R$ is commutative. Despite the notation, I mean ideal is the left and right ideal. But it can interpreted as left or right ideal only if necessary. The point of my question is not emphasising on left or right, I am just curious whether the statement works for the converse. Hopefully it is clear. But if there is something wrong in my interpretation, please kindly let me know. I would like to know whether the converse is true, but it is not stated in Wikipedia. That is for any submodule $_R N$ of $_R R$, then $N$ is an ideal of $R$? In other words, is it true that if $_R N\subseteq _R R$ then $N\triangleleft R$? If this is a well known useful property, then it should be stated, but I could not find in some books that I read and other sources. Is it something to proof or is it defined? If it is something to proof, could anyone give some ideas about the proof? Thanks!",,"['abstract-algebra', 'ring-theory', 'modules']"
63,What is true for a ring with exactly two right ideals,What is true for a ring with exactly two right ideals,,"This is question #66 from http://www.ets.org/s/gre/pdf/practice_book_math.pdf Let $R$ be a ring with a multiplicative identity. If $U$ is an additive subgroup of $R$ such that $ur \in U$ for all    $u \in U$ and for all $r \in R$ , then $U$ is said to be a right ideal of $R$. If $R$ has exactly two right ideals, which of    the following must be true? I. $R$ is commutative. II. $R$ is a division ring (that is, all elements except the additive identity have multiplicative inverses). III. $R$ is infinite. Here is my reasoning: Because $R$ is a ring, $R$ is also a additive group with some identity element $0$. We have a theorem that says $0r = 0 $ in any ring, so $\{0\}$ is a right ideal of $R$. Also, $R$ is a right ideal of $R$. Now I have found two different right ideals and there mustn't be any more. Edit: As mentioned in the comments, the example below is not a ring, so it is not applicable to the problem. I could not fix it by taking additive closure because that introduced more than two ideals. A possible candidate for $R$ could be the set of $2\times2$ matrices $\{0,I,-I,a,-a\}$ where $a = [[^1_0] ,[^0_0]]$. The only right ideals are $R$ and $\{0\}$. This ring satisfies only property I, but the answer key says that II is the correct answer.","This is question #66 from http://www.ets.org/s/gre/pdf/practice_book_math.pdf Let $R$ be a ring with a multiplicative identity. If $U$ is an additive subgroup of $R$ such that $ur \in U$ for all    $u \in U$ and for all $r \in R$ , then $U$ is said to be a right ideal of $R$. If $R$ has exactly two right ideals, which of    the following must be true? I. $R$ is commutative. II. $R$ is a division ring (that is, all elements except the additive identity have multiplicative inverses). III. $R$ is infinite. Here is my reasoning: Because $R$ is a ring, $R$ is also a additive group with some identity element $0$. We have a theorem that says $0r = 0 $ in any ring, so $\{0\}$ is a right ideal of $R$. Also, $R$ is a right ideal of $R$. Now I have found two different right ideals and there mustn't be any more. Edit: As mentioned in the comments, the example below is not a ring, so it is not applicable to the problem. I could not fix it by taking additive closure because that introduced more than two ideals. A possible candidate for $R$ could be the set of $2\times2$ matrices $\{0,I,-I,a,-a\}$ where $a = [[^1_0] ,[^0_0]]$. The only right ideals are $R$ and $\{0\}$. This ring satisfies only property I, but the answer key says that II is the correct answer.",,"['abstract-algebra', 'ring-theory']"
64,I am trying to understand Galois groups for a tower of fields,I am trying to understand Galois groups for a tower of fields,,"I have what is probably a very easy question, but it is something that I am finding hard to ""see"". Thanks to Jyrki's very helpful answer below then perhaps I can phrase my question better. Given a tower of fields $M / L / K$, we have the exact sequence $1 \rightarrow \operatorname{Gal}(M/L) \rightarrow \operatorname{Gal}(M/K) \rightarrow \operatorname{Gal}(L/K) \rightarrow 1$ If we know the groups $\operatorname{Gal}(M/L)$ and $\operatorname{Gal}(L/K)$, how can we recover the whole Galois group? I am particularly interested in when the exact sequence above is split, then the whole galois group is a semi-direct product $\operatorname{Gal}(M/K)  = \operatorname{Gal}(M/L) \rtimes \operatorname{Gal}(L/K)$ If we have an action of $\operatorname{Gal}(L/K)$ on $\operatorname{Gal}(M/L)$ by conjugation then we can recover the semidirect product. However, as the semi direct product can in general determine different groups, does this determine the group uniquely? Is there necessarily just one way of defining this action? In the general case (i.e. when the exact sequence does not split) what can we say about the whole Galois group? Is anyone able to point me in the right direction with this, I am sure that I am just forgetting something basic, and if anyone could give me a rough outline of what I am missing in my understanding I would very much appreciate it. Extra: I've found a similiar question here, Group actions in towers of Galois extensions but note that I am interested in non-abelian extensions as well as abelian. This question states that if $\sigma \in \operatorname{Gal}(L/K)$ then any two lifts of $\sigma$  are conjugate to each other by an element of $ \operatorname{Gal}(L/K)$ , which re-raises my initial question of why two lifts are conjugate.","I have what is probably a very easy question, but it is something that I am finding hard to ""see"". Thanks to Jyrki's very helpful answer below then perhaps I can phrase my question better. Given a tower of fields $M / L / K$, we have the exact sequence $1 \rightarrow \operatorname{Gal}(M/L) \rightarrow \operatorname{Gal}(M/K) \rightarrow \operatorname{Gal}(L/K) \rightarrow 1$ If we know the groups $\operatorname{Gal}(M/L)$ and $\operatorname{Gal}(L/K)$, how can we recover the whole Galois group? I am particularly interested in when the exact sequence above is split, then the whole galois group is a semi-direct product $\operatorname{Gal}(M/K)  = \operatorname{Gal}(M/L) \rtimes \operatorname{Gal}(L/K)$ If we have an action of $\operatorname{Gal}(L/K)$ on $\operatorname{Gal}(M/L)$ by conjugation then we can recover the semidirect product. However, as the semi direct product can in general determine different groups, does this determine the group uniquely? Is there necessarily just one way of defining this action? In the general case (i.e. when the exact sequence does not split) what can we say about the whole Galois group? Is anyone able to point me in the right direction with this, I am sure that I am just forgetting something basic, and if anyone could give me a rough outline of what I am missing in my understanding I would very much appreciate it. Extra: I've found a similiar question here, Group actions in towers of Galois extensions but note that I am interested in non-abelian extensions as well as abelian. This question states that if $\sigma \in \operatorname{Gal}(L/K)$ then any two lifts of $\sigma$  are conjugate to each other by an element of $ \operatorname{Gal}(L/K)$ , which re-raises my initial question of why two lifts are conjugate.",,"['abstract-algebra', 'galois-theory']"
65,What would happen if we created a vector space over an integral domain/ring.,What would happen if we created a vector space over an integral domain/ring.,,"I've always been curious about this, why do we use fields as the only algebraic structure to put vector spaces over? It seems a bit arbitrary to me, so I was wondering what would happen it we replaced the requirement with something less structured like a ring (with unity, we don't want to violate the axioms). Anyone have any idea what the consequences would be? Anyone have any ideas/reasons why we don't?","I've always been curious about this, why do we use fields as the only algebraic structure to put vector spaces over? It seems a bit arbitrary to me, so I was wondering what would happen it we replaced the requirement with something less structured like a ring (with unity, we don't want to violate the axioms). Anyone have any idea what the consequences would be? Anyone have any ideas/reasons why we don't?",,"['abstract-algebra', 'soft-question']"
66,What are applications of rings & groups?,What are applications of rings & groups?,,"I am following a course in basic algebra, and we have covered rings & groups in class, but I am having trouble visualising them. Are there applications of group &/or ring theory that can be more easily visualized than the abstract object? For instance, are there objects, or properties of objects, that behave as elements of a group in physics, chemistry, or other fields?","I am following a course in basic algebra, and we have covered rings & groups in class, but I am having trouble visualising them. Are there applications of group &/or ring theory that can be more easily visualized than the abstract object? For instance, are there objects, or properties of objects, that behave as elements of a group in physics, chemistry, or other fields?",,"['abstract-algebra', 'group-theory', 'ring-theory', 'applications']"
67,What are Free Objects?,What are Free Objects?,,"I've read the wikipedia article , but couldn't grasp the concept. Is there an informal definition? Are there examples of uses of free objects in calculus? Are free objects somehow connected to constructiveness? Maybe there are some computer program examples (in Haskell preferably). A reference to a short introductory text is welcome.","I've read the wikipedia article , but couldn't grasp the concept. Is there an informal definition? Are there examples of uses of free objects in calculus? Are free objects somehow connected to constructiveness? Maybe there are some computer program examples (in Haskell preferably). A reference to a short introductory text is welcome.",,"['abstract-algebra', 'reference-request', 'soft-question']"
68,Faithfully Flat Ring Homomorphism of Power Series,Faithfully Flat Ring Homomorphism of Power Series,,Let $R$ be a one-dimensional local ring and let $f:R[[x]][y] \rightarrow R[y][[x]]$ be the inclusion map. How can I show that $f$ is a faithfully flat ring homomorphism?  Or can you give me a reference? Thanks.,Let $R$ be a one-dimensional local ring and let $f:R[[x]][y] \rightarrow R[y][[x]]$ be the inclusion map. How can I show that $f$ is a faithfully flat ring homomorphism?  Or can you give me a reference? Thanks.,,"['abstract-algebra', 'commutative-algebra']"
69,Eigenvalues for matrices over general rings,Eigenvalues for matrices over general rings,,"I am aware of the theory of eigenvalues for matrices over fields. I was wondering to what extent this theory extends? Do we have a corresponding theory for matrices over integral domains, or at least over UFDs? H.C.Lee remarks here that there is no eigenvalue theory over general rings.","I am aware of the theory of eigenvalues for matrices over fields. I was wondering to what extent this theory extends? Do we have a corresponding theory for matrices over integral domains, or at least over UFDs? H.C.Lee remarks here that there is no eigenvalue theory over general rings.",,"['abstract-algebra', 'reference-request']"
70,Finitely generated modules over PID,Finitely generated modules over PID,,"Let $A$, $B$, $C$, and $D$ be finitely generated modules over a PID  such that $A\oplus B\cong C\oplus D$ and $A\oplus D\cong C\oplus B$. Prove that $A\cong C$ and $B\cong D$. The only tool I have is the theorem about finitely generated modules, but I don't quite see the connection. Please Help. Thanks.","Let $A$, $B$, $C$, and $D$ be finitely generated modules over a PID  such that $A\oplus B\cong C\oplus D$ and $A\oplus D\cong C\oplus B$. Prove that $A\cong C$ and $B\cong D$. The only tool I have is the theorem about finitely generated modules, but I don't quite see the connection. Please Help. Thanks.",,['abstract-algebra']
71,A different proof of the insolubility of the quintic?,A different proof of the insolubility of the quintic?,,"I'm familiar with the ""standard"" proof using Galois theory that there is no general formula for solving an equation of fifth (or higher) degree using radicals (i.e. arithmetic and root-taking). However, now I'm wondering if other proofs of different nature were found (in particular ones relying on analysis rather than algebra). What sparked my interest was seeing a description of the solution of the 2nd, 3rd and 4th degree equations via something that looked like discrete Fourier transform.","I'm familiar with the ""standard"" proof using Galois theory that there is no general formula for solving an equation of fifth (or higher) degree using radicals (i.e. arithmetic and root-taking). However, now I'm wondering if other proofs of different nature were found (in particular ones relying on analysis rather than algebra). What sparked my interest was seeing a description of the solution of the 2nd, 3rd and 4th degree equations via something that looked like discrete Fourier transform.",,"['abstract-algebra', 'galois-theory']"
72,Does a Galois group being $S_3$ correspond to the extension being the splitting field of a cubic?,Does a Galois group being  correspond to the extension being the splitting field of a cubic?,S_3,"If $f(x)$ is an irreducible cubic, then $\operatorname{Gal}(f(x))\cong S_3$ or $A_3$. But what about the converse? That is, if $\operatorname{Gal}(K/F)\cong S_3$, is it necessarily true that $K$ is the splitting field of some irreducible cubic in $F[x]$?","If $f(x)$ is an irreducible cubic, then $\operatorname{Gal}(f(x))\cong S_3$ or $A_3$. But what about the converse? That is, if $\operatorname{Gal}(K/F)\cong S_3$, is it necessarily true that $K$ is the splitting field of some irreducible cubic in $F[x]$?",,"['abstract-algebra', 'group-theory', 'galois-theory']"
73,Number of subfields of splitting fields of $x^5-5$ over $\mathbb{Q}$.,Number of subfields of splitting fields of  over .,x^5-5 \mathbb{Q},"I want to find the number of subfields of splitting fields of $x^5-5$ over $\mathbb{Q}$ . By Eisenstein Criterion, $x^5-5$ is irreducible over $\mathbb{Q}.$ Then splitting field $K$ of $x^5-5$ is Galois extension of $\mathbb{Q}$ . Let $\zeta$ be primitive 5th root. Then Roots of $x^5-5$ consist of exactly $\zeta \root5\of5$ , $\zeta^2 \root5\of5$ , $\zeta^3 \root5\of5$ , $\zeta^4 \root5\of5$ , $\root5\of5$ . So $$K=\mathbb{Q}(\zeta \root5\of5, \zeta^2 \root5\of5, \zeta^3 \root5\of5, \zeta^4 \root5\of5) = \mathbb{Q}(\zeta,\root5\of5)$$ Since $K=\mathbb{Q}(\zeta)\mathbb{Q}(\root5\of5)$ and $[\mathbb{Q}(\zeta):\mathbb{Q}] = 4 \mbox{ and } [\mathbb{Q}(\root5\of5):\mathbb{Q}]=5$ , $$|Gal(K/F)|=[K:F]=5\cdot 4=20.$$ Therefore $Gal(K/F)$ is group of order 20. So If I can find number of subgroups of $Gal(K/F)$ , then I can find number of subfields of the field. What shall I do?","I want to find the number of subfields of splitting fields of over . By Eisenstein Criterion, is irreducible over Then splitting field of is Galois extension of . Let be primitive 5th root. Then Roots of consist of exactly , , , , . So Since and , Therefore is group of order 20. So If I can find number of subgroups of , then I can find number of subfields of the field. What shall I do?","x^5-5 \mathbb{Q} x^5-5 \mathbb{Q}. K x^5-5 \mathbb{Q} \zeta x^5-5 \zeta \root5\of5 \zeta^2 \root5\of5 \zeta^3 \root5\of5 \zeta^4 \root5\of5 \root5\of5 K=\mathbb{Q}(\zeta \root5\of5, \zeta^2 \root5\of5, \zeta^3 \root5\of5, \zeta^4 \root5\of5) = \mathbb{Q}(\zeta,\root5\of5) K=\mathbb{Q}(\zeta)\mathbb{Q}(\root5\of5) [\mathbb{Q}(\zeta):\mathbb{Q}] = 4 \mbox{ and } [\mathbb{Q}(\root5\of5):\mathbb{Q}]=5 |Gal(K/F)|=[K:F]=5\cdot 4=20. Gal(K/F) Gal(K/F)","['abstract-algebra', 'galois-theory']"
74,Principal ideal rings that are not integral domains,Principal ideal rings that are not integral domains,,"In the usual definition, a principal ideal domain $R$ is also assumed to be an integral domain. However, the property that every ideal is generated by a single element does not seem to immediately imply that the ring is integral. Is this correct and if so: Do there exist rings where every ideal is generated by a single element and has zero divisors? I am most interested in the case where $R$ is commutative with unity, but don't mind examples where these properties don't hold. Also, assuming there are examples, is there any reason why we make this assumption?","In the usual definition, a principal ideal domain is also assumed to be an integral domain. However, the property that every ideal is generated by a single element does not seem to immediately imply that the ring is integral. Is this correct and if so: Do there exist rings where every ideal is generated by a single element and has zero divisors? I am most interested in the case where is commutative with unity, but don't mind examples where these properties don't hold. Also, assuming there are examples, is there any reason why we make this assumption?",R R,"['abstract-algebra', 'ring-theory', 'principal-ideal-domains', 'integral-domain']"
75,Every finite group is the Galois group of a field extension,Every finite group is the Galois group of a field extension,,How can I show that every finite group is the Galois group of an extension $K/F$ where $F$ is itself a finite extension of $\mathbb Q$? I know  the following: Every finite group is contained in $S_p$ for a large enough prime $p$. Every irreducible polynomial in $\mathbb Q[x]$ of degree $p$ having exactly $p-2$ real roots has a Galois group $S_p$ over $\mathbb Q$. For any $n$ there is an irreducible polynomial in $\mathbb Q[x]$ of degree $n$ having exactly $n-2$ real roots. Does this have something to do with the inverse Galois problem?,How can I show that every finite group is the Galois group of an extension $K/F$ where $F$ is itself a finite extension of $\mathbb Q$? I know  the following: Every finite group is contained in $S_p$ for a large enough prime $p$. Every irreducible polynomial in $\mathbb Q[x]$ of degree $p$ having exactly $p-2$ real roots has a Galois group $S_p$ over $\mathbb Q$. For any $n$ there is an irreducible polynomial in $\mathbb Q[x]$ of degree $n$ having exactly $n-2$ real roots. Does this have something to do with the inverse Galois problem?,,"['abstract-algebra', 'field-theory', 'finite-groups', 'galois-theory']"
76,2D Rubik's cube?,2D Rubik's cube?,,"There is a $3\times3$ matrix filled by numbers 1~9 that might look like this $$\begin{bmatrix}3 & 8 & 2 \\ 4 & 1 & 6 \\ 7 & 5 & 9\end{bmatrix}$$ All its rows and columns can be ""rolled forwards and backwards"" (like permutation acting on a single row/column) Roll the second column upwards: $$\begin{bmatrix}3 & 1 & 2 \\ 4 & 5 & 6 \\ 7 & 8 & 9\end{bmatrix}$$ And roll the first row to the left, we get $$A=\begin{bmatrix}1 & 2 & 3 \\ 4 & 5 & 6 \\ 7 & 8 & 9\end{bmatrix}$$ Now, if given an arbitrary matrix like this, how can I tell if it can be restored back to $A$? If it always could, why?","There is a $3\times3$ matrix filled by numbers 1~9 that might look like this $$\begin{bmatrix}3 & 8 & 2 \\ 4 & 1 & 6 \\ 7 & 5 & 9\end{bmatrix}$$ All its rows and columns can be ""rolled forwards and backwards"" (like permutation acting on a single row/column) Roll the second column upwards: $$\begin{bmatrix}3 & 1 & 2 \\ 4 & 5 & 6 \\ 7 & 8 & 9\end{bmatrix}$$ And roll the first row to the left, we get $$A=\begin{bmatrix}1 & 2 & 3 \\ 4 & 5 & 6 \\ 7 & 8 & 9\end{bmatrix}$$ Now, if given an arbitrary matrix like this, how can I tell if it can be restored back to $A$? If it always could, why?",,"['abstract-algebra', 'combinatorics', 'group-theory']"
77,Application of the Artin-Schreier Theorem,Application of the Artin-Schreier Theorem,,"This is exercise $6.29$ out of Lang's book: Let $K$ be a cyclic extension of a field $F$ , with Galois group $G$ generated by $\sigma$ . Assume that the characteristic is $p$ , and that $[K:F]=p^{m-1}$ for some $m\geq2$ . Let $\beta$ be an element of $K$ such that that Tr $^K_F(\beta)=1$ . (a) Show that there exists an element $\alpha\in K$ such that $\sigma(\alpha)-\alpha=\beta^p-\beta$ . (b) Prove that the polynomial $x^p-x-\alpha$ is irreducible in $K[x]$ . (c) If $\theta$ is a root of this polynomial, prove that $F(\theta)$ is a Galois, cyclic extension of degree $p^m$ of $F$ , and that its Galois group is generated by an extension $\sigma^*$ of $\sigma$ such that $\sigma^*(\theta)=\theta+\beta$ . I have been able to do letter $a$ using Hilbert's Theorem $90$ (Additive Form), since $$\text{Tr}(\beta)=1=1^p=(\text{Tr}(\beta))^p=\text{Tr}(\beta^p).$$ I'm at a loss for the second one, even though it seems to scream the Artin-Schreier theorem. For the third part, I certainly see that it is an extension of degree $p^m$ , although I'm not sure I can get much farther than that. How can I do the last two parts?","This is exercise out of Lang's book: Let be a cyclic extension of a field , with Galois group generated by . Assume that the characteristic is , and that for some . Let be an element of such that that Tr . (a) Show that there exists an element such that . (b) Prove that the polynomial is irreducible in . (c) If is a root of this polynomial, prove that is a Galois, cyclic extension of degree of , and that its Galois group is generated by an extension of such that . I have been able to do letter using Hilbert's Theorem (Additive Form), since I'm at a loss for the second one, even though it seems to scream the Artin-Schreier theorem. For the third part, I certainly see that it is an extension of degree , although I'm not sure I can get much farther than that. How can I do the last two parts?",6.29 K F G \sigma p [K:F]=p^{m-1} m\geq2 \beta K ^K_F(\beta)=1 \alpha\in K \sigma(\alpha)-\alpha=\beta^p-\beta x^p-x-\alpha K[x] \theta F(\theta) p^m F \sigma^* \sigma \sigma^*(\theta)=\theta+\beta a 90 \text{Tr}(\beta)=1=1^p=(\text{Tr}(\beta))^p=\text{Tr}(\beta^p). p^m,"['abstract-algebra', 'field-theory', 'galois-theory']"
78,Examples of Infinite Boolean Rings,Examples of Infinite Boolean Rings,,"I'm attempting to list examples of infinite boolean rings and I need some clarification. Firstly, is it possible to take an infinite direct product of the integers mod $2$ to get a boolean ring? (i.e. is $\mathbb{Z}/2\mathbb{Z} \times \mathbb{Z}/2\mathbb{Z} \times \mathbb{Z}/2\mathbb{Z}\times\cdots$ an infinite boolean ring?) The only other example of an infinite boolean ring that I can think of is the ring $\mathcal{P}(X)$, the set of all subsets of some set X, with addition defined to be symmetric difference and multiplication defined to be intersection. What are some other examples of infinite boolean rings?","I'm attempting to list examples of infinite boolean rings and I need some clarification. Firstly, is it possible to take an infinite direct product of the integers mod $2$ to get a boolean ring? (i.e. is $\mathbb{Z}/2\mathbb{Z} \times \mathbb{Z}/2\mathbb{Z} \times \mathbb{Z}/2\mathbb{Z}\times\cdots$ an infinite boolean ring?) The only other example of an infinite boolean ring that I can think of is the ring $\mathcal{P}(X)$, the set of all subsets of some set X, with addition defined to be symmetric difference and multiplication defined to be intersection. What are some other examples of infinite boolean rings?",,"['abstract-algebra', 'ring-theory']"
79,Specific proof that any finitely generated $R$-module over a Noetherian ring is Noetherian.,Specific proof that any finitely generated -module over a Noetherian ring is Noetherian.,R,"I have seen a handful of proofs that any finitely generated module over a Noetherian ring is again Noetherian. I'm specifically trying to understand the following proof idea. It goes as this: Observe that if $T\subseteq S$ are submodules of an $R$-module $M$ with $R$ Noetherian, and if $T$ is finitely generated (f.g.) and $S/T$ is f.g., then so is $S$. I get that. Proceed by induction. If $M$ is $1$-generated, say $M=Rv$, then if $\phi\colon R\to M$ defined by $r\mapsto rv$ is an epimorphism, and so $M\cong R/\ker(\phi)$, and is Noetherian as the quotient of a Noetherian ring. Suppose it holds for all $k$-generated $R$-modules, for $k\leq n$. Let $M=\langle v_1,\dots,v_{n+1}\rangle$. Let $M'=\langle v_1,\dots, v_n\rangle$. Then let $T=S\cap M'$. On second thought, I think $S$ is supposed to be an arbitrary submodule of $M$. Let $T=S\cap M'$. So $T$ is a submodule of $M'$, hence finitely generated. Then $$ S/T=S/(S\cap M')\cong (S+M')/M'. $$ How is $(S+M')/M'$ finitely generated? I suppose would give the conclusion.","I have seen a handful of proofs that any finitely generated module over a Noetherian ring is again Noetherian. I'm specifically trying to understand the following proof idea. It goes as this: Observe that if $T\subseteq S$ are submodules of an $R$-module $M$ with $R$ Noetherian, and if $T$ is finitely generated (f.g.) and $S/T$ is f.g., then so is $S$. I get that. Proceed by induction. If $M$ is $1$-generated, say $M=Rv$, then if $\phi\colon R\to M$ defined by $r\mapsto rv$ is an epimorphism, and so $M\cong R/\ker(\phi)$, and is Noetherian as the quotient of a Noetherian ring. Suppose it holds for all $k$-generated $R$-modules, for $k\leq n$. Let $M=\langle v_1,\dots,v_{n+1}\rangle$. Let $M'=\langle v_1,\dots, v_n\rangle$. Then let $T=S\cap M'$. On second thought, I think $S$ is supposed to be an arbitrary submodule of $M$. Let $T=S\cap M'$. So $T$ is a submodule of $M'$, hence finitely generated. Then $$ S/T=S/(S\cap M')\cong (S+M')/M'. $$ How is $(S+M')/M'$ finitely generated? I suppose would give the conclusion.",,"['abstract-algebra', 'ring-theory', 'modules']"
80,Can we extend the definition of a homomorphism to binary relations?,Can we extend the definition of a homomorphism to binary relations?,,"This is going to be quite a long post. The actual questions will be at the end of it in section ""Questions."" INTRODUCTION After receiving an answer to this question about extending the definition of a continuous function to binary relations, I started thinking about doing the same with homomorphisms in abstract algebra. It seems more difficult to me because there seems not to be a unique obvious way of doing it. I tried a modest task first: to do this for semigroups (so for groups too in particular). Ring or algebra homomorphisms seem more difficult to generalize. I have ended up with two definitions for semigroup homomorphisms, but I'm not sure if they're of any use. Both fail to satisfy a property I thought they should satisfy. I will explain this later. ATTEMPTED DEFINITIONS Let $S,T$ be semigroups. A function $\varphi:S\to T$ is a homomorphism if it satisfies $$\varphi(ab)=\varphi(a)\varphi(b).\tag1$$ If $\rho\subseteq S\times T$ is a binary relation, the following also makes sense: $$\rho(ab)=\rho(a)\rho(b),\tag2$$ but now $\rho(ab),\rho(a),\rho(b)$ are not elements of $T$, but of $2^T$. Yet $(2)$ makes sense, because $2^T$ also has a structure of a semigroup, with the operation defined by $$AB=\{ab\,|\,a\in A,\,b\in B\}.$$ This gives an idea for a definition. Definition 1. $\rho$ is element-wise homomorphic iff for any $a,b\in S,$ we have $$\rho(ab)=\rho(a)\rho(b).$$ But there's another idea. Every function $\varphi:S\to T$ can be extended to a function $\overline\varphi : 2^S\to 2^T$ as follows. $$\overline\varphi(A)=\varphi(A),$$ where $\varphi(A)$ denotes the image of $A$ under $\varphi.$ Obviously, $$\overline\varphi(\{a\})=\{\varphi(a)\}.$$ Now let $\varphi$ be a homomorphism. Fact 1. $\overline\varphi$ is a semigroup homomorphism from $2^S$ to $2^T$. Proof. Let $A,B\subseteq S.$ Then $$ \begin{eqnarray} \overline\varphi(AB)&=&\{\varphi(ab)\,|\, a\in A,\,b\in B\}\\ &=&\{\varphi(a)\varphi(b)\,|\,a\in A,\,b\in B\}\\ &=&\{xy\,|\,x\in\varphi(A),\,y\in\varphi(B)\}\\ &=&\{xy\,|\,x\in\overline\varphi(A),\,y\in\overline\varphi(B)\}\\ &=&\overline\varphi(A)\overline\varphi(B). \end{eqnarray} $$ Also, it is obvious that if $\overline\varphi$ is a homomorphism, then $\varphi$ is a homomorphism too, because it essentially a restriction of $\overline\varphi$ to the subsemigroup $S$ of the semigroup $2^S.$ This gives us Fact 2. $\varphi:S\to T$ is a homomorphism iff $\overline\varphi:2^S\to 2^T$ is a homomorphism. Now $\rho$ also induces a function $\overline\rho:2^S\to 2^T$ by $$\overline\rho(A)=\rho(A),$$ where $\rho(A)$ denotes the image of $A$ under $\rho.$ This gives another idea for a definition. Definition 2. $\rho$ is set-wise homomorphic iff $\overline\rho:2^S\to 2^T$ is a semigroup homomorphism. WHY I THINK IT DOESN'T WORK I think a good definition of a homomorphic relation $\rho$ should give that $\rho^{-1}$ is also homomorphic. This would be a generalization of the fact that a bijective homomorphism is an isomorphism. (That is, we don't need to check whether the inverse function is a homomorphism.) Both definitions fail here. Let $\varphi:\mathbb Z\to\mathbb Z$ be the trivial homomorphism. Then $$\overline{\left(\varphi^{-1}\right)}(\{1\}+\{-1\})=\overline{\left(\varphi^{-1}\right)}(\{0\})=\mathbb Z.$$ But $$\overline{\left(\varphi^{-1}\right)}(\{1\})=\varnothing$$ and $$\overline{\left(\varphi^{-1}\right)}(\{-1\})=\varnothing,$$ so $$\overline{\left(\varphi^{-1}\right)}(\{1\})\overline{\left(\varphi^{-1}\right)}(\{-1\})=\varnothing.$$ QUESTIONS (1) Is there a standard definition of a ""homomorphic binary relation"" for semigroups? other algebraic structures? (2) Has anything similar to the definitions I'm giving been tried in literature? (3) When defining a ""homomorphic binary relation"", what could make one defintion more sensible than another? (This is imprecise of course, but I want to ask it in case someone has a precise answer.)","This is going to be quite a long post. The actual questions will be at the end of it in section ""Questions."" INTRODUCTION After receiving an answer to this question about extending the definition of a continuous function to binary relations, I started thinking about doing the same with homomorphisms in abstract algebra. It seems more difficult to me because there seems not to be a unique obvious way of doing it. I tried a modest task first: to do this for semigroups (so for groups too in particular). Ring or algebra homomorphisms seem more difficult to generalize. I have ended up with two definitions for semigroup homomorphisms, but I'm not sure if they're of any use. Both fail to satisfy a property I thought they should satisfy. I will explain this later. ATTEMPTED DEFINITIONS Let $S,T$ be semigroups. A function $\varphi:S\to T$ is a homomorphism if it satisfies $$\varphi(ab)=\varphi(a)\varphi(b).\tag1$$ If $\rho\subseteq S\times T$ is a binary relation, the following also makes sense: $$\rho(ab)=\rho(a)\rho(b),\tag2$$ but now $\rho(ab),\rho(a),\rho(b)$ are not elements of $T$, but of $2^T$. Yet $(2)$ makes sense, because $2^T$ also has a structure of a semigroup, with the operation defined by $$AB=\{ab\,|\,a\in A,\,b\in B\}.$$ This gives an idea for a definition. Definition 1. $\rho$ is element-wise homomorphic iff for any $a,b\in S,$ we have $$\rho(ab)=\rho(a)\rho(b).$$ But there's another idea. Every function $\varphi:S\to T$ can be extended to a function $\overline\varphi : 2^S\to 2^T$ as follows. $$\overline\varphi(A)=\varphi(A),$$ where $\varphi(A)$ denotes the image of $A$ under $\varphi.$ Obviously, $$\overline\varphi(\{a\})=\{\varphi(a)\}.$$ Now let $\varphi$ be a homomorphism. Fact 1. $\overline\varphi$ is a semigroup homomorphism from $2^S$ to $2^T$. Proof. Let $A,B\subseteq S.$ Then $$ \begin{eqnarray} \overline\varphi(AB)&=&\{\varphi(ab)\,|\, a\in A,\,b\in B\}\\ &=&\{\varphi(a)\varphi(b)\,|\,a\in A,\,b\in B\}\\ &=&\{xy\,|\,x\in\varphi(A),\,y\in\varphi(B)\}\\ &=&\{xy\,|\,x\in\overline\varphi(A),\,y\in\overline\varphi(B)\}\\ &=&\overline\varphi(A)\overline\varphi(B). \end{eqnarray} $$ Also, it is obvious that if $\overline\varphi$ is a homomorphism, then $\varphi$ is a homomorphism too, because it essentially a restriction of $\overline\varphi$ to the subsemigroup $S$ of the semigroup $2^S.$ This gives us Fact 2. $\varphi:S\to T$ is a homomorphism iff $\overline\varphi:2^S\to 2^T$ is a homomorphism. Now $\rho$ also induces a function $\overline\rho:2^S\to 2^T$ by $$\overline\rho(A)=\rho(A),$$ where $\rho(A)$ denotes the image of $A$ under $\rho.$ This gives another idea for a definition. Definition 2. $\rho$ is set-wise homomorphic iff $\overline\rho:2^S\to 2^T$ is a semigroup homomorphism. WHY I THINK IT DOESN'T WORK I think a good definition of a homomorphic relation $\rho$ should give that $\rho^{-1}$ is also homomorphic. This would be a generalization of the fact that a bijective homomorphism is an isomorphism. (That is, we don't need to check whether the inverse function is a homomorphism.) Both definitions fail here. Let $\varphi:\mathbb Z\to\mathbb Z$ be the trivial homomorphism. Then $$\overline{\left(\varphi^{-1}\right)}(\{1\}+\{-1\})=\overline{\left(\varphi^{-1}\right)}(\{0\})=\mathbb Z.$$ But $$\overline{\left(\varphi^{-1}\right)}(\{1\})=\varnothing$$ and $$\overline{\left(\varphi^{-1}\right)}(\{-1\})=\varnothing,$$ so $$\overline{\left(\varphi^{-1}\right)}(\{1\})\overline{\left(\varphi^{-1}\right)}(\{-1\})=\varnothing.$$ QUESTIONS (1) Is there a standard definition of a ""homomorphic binary relation"" for semigroups? other algebraic structures? (2) Has anything similar to the definitions I'm giving been tried in literature? (3) When defining a ""homomorphic binary relation"", what could make one defintion more sensible than another? (This is imprecise of course, but I want to ask it in case someone has a precise answer.)",,['abstract-algebra']
81,"Prove that $\operatorname{Gal}(\mathbb{Q}(\sqrt[8]{2}, i)/\mathbb{Q}(\sqrt{-2})) \cong Q_8$",Prove that,"\operatorname{Gal}(\mathbb{Q}(\sqrt[8]{2}, i)/\mathbb{Q}(\sqrt{-2})) \cong Q_8","I seem to have reached a contradiction.  I am trying to prove that $\operatorname{Gal}(\mathbb{Q}(\sqrt[8]{2}, i)/\mathbb{Q}(\sqrt{-2})) \cong Q_8$. I could not think of a clever way to do this, so I decided to just list all the automorphisms of $\mathbb{Q}(\sqrt[8]{2}, i)$ that fix $\mathbb{Q}$ and hand-pick the ones that fix $i\sqrt{2}$.  By the Fundamental Theorem of Galois Theory, those automorphisms should be a subgroup of the ones that fix $\mathbb{Q}$.  I proved earlier that those automorphisms are given by $\sigma: \sqrt[8]{2} \mapsto \zeta^n\sqrt[8]{2}, i \mapsto \pm i$, where $n \in [0, 7]$ and $\zeta = e^\frac{2\pi i}{8}$. However, I am getting too many automorphisms.  One automorphism that fixes $i\sqrt{2}$ is $\sigma: \sqrt[8]{2} \mapsto \zeta\sqrt[8]{2}, i \mapsto -i$.  However, this means all powers of $\sigma$ fix $i\sqrt{2}$, and I know $Q_8$ does not contain a cyclic subgroup of order $8$.  What am I doing wrong? (Please do not give me the answer.  I have classmates for that.)","I seem to have reached a contradiction.  I am trying to prove that $\operatorname{Gal}(\mathbb{Q}(\sqrt[8]{2}, i)/\mathbb{Q}(\sqrt{-2})) \cong Q_8$. I could not think of a clever way to do this, so I decided to just list all the automorphisms of $\mathbb{Q}(\sqrt[8]{2}, i)$ that fix $\mathbb{Q}$ and hand-pick the ones that fix $i\sqrt{2}$.  By the Fundamental Theorem of Galois Theory, those automorphisms should be a subgroup of the ones that fix $\mathbb{Q}$.  I proved earlier that those automorphisms are given by $\sigma: \sqrt[8]{2} \mapsto \zeta^n\sqrt[8]{2}, i \mapsto \pm i$, where $n \in [0, 7]$ and $\zeta = e^\frac{2\pi i}{8}$. However, I am getting too many automorphisms.  One automorphism that fixes $i\sqrt{2}$ is $\sigma: \sqrt[8]{2} \mapsto \zeta\sqrt[8]{2}, i \mapsto -i$.  However, this means all powers of $\sigma$ fix $i\sqrt{2}$, and I know $Q_8$ does not contain a cyclic subgroup of order $8$.  What am I doing wrong? (Please do not give me the answer.  I have classmates for that.)",,"['abstract-algebra', 'galois-theory']"
82,Finding polynomial without constant term that commutes with $f(x)=x^3+3x$,Finding polynomial without constant term that commutes with,f(x)=x^3+3x,"Consider the polynomial $f(x)=x^3+3x$ over $\mathbb{Z}$ . I am trying to find a polynomial $g(x)$ $(\neq f^{\circ n})$ of any degree (or series) without constant term which commutes with $f$ (or any iteration $f^{\circ n}, ~n \geq 1)$ under composition. Trivially, any $g(x)=x$ , is another polynomial (or series) commutes with $f(x)$ . By hand it seems to be laborious. Suppose I start with an investigation if there are degree $2$ polynomial $g(x)=ax+bx^2$ such that $f \circ g=g\circ f$ . Then \begin{align} &f(g(x))=f(ax+bx^2)=3(ax+bx^2)+(ax+bx^2)^3=3ax+3bx^2+a^3x^3+3a^2bx^4+3ab^2x^5+b^3x^6, \\ &g(f(x))=g(x^3+3x)=a(x^3+3x)+b(x^3+3x)^2=3ax+ax^3+bx^6+6bx^4+9bx^2 \end{align} Comparing both equations, we get $b=0$ and $a=a^3 \Rightarrow a=\pm 1$ . In this case $g(x)=\pm 1$ , the trivial one. Suppose I start with an investigation if there are degree $3$ polynomial $g(x)=ax+bx^2+cx^3$ such that $f \circ g=g\circ f$ . Then \begin{align} &f(g(x))=f(ax+bx^2+cx^3)=3(ax+bx^2+cx^3)+(ax+bx^2+cx^3)^3=3ax+3bx^2+3cx^3+c^3x^9+3bc^2x^8 \hspace{3cm}+(3ac^2+3b^2c)x^7+(6abc + b^3)x^6 + (3a^2c + 3ab^2)x^5 + 3a^2bx^4 + a^3x^3, \\ &g(f(x))=g(x^3+3x)=a(x^3+3x)+b(x^3+3x)^2+c(x^3+3x)^3=3ax+ax^3+2bx^6+6bx^4+9bx^2+cx^9+9cx^7+27cx^5+27cx^3 \end{align} Comparing both sides we get $b=0$ and the following equations: \begin{align} a^3-a=24c, \\ a^2c=9c, \\ 3ac^2=9c,\\ c^3=c. \end{align} Solving these, we see $c^3=c$ and $3ac^2=a^2c$ . These two gives us $c=0$ or $c=\pm 1$ . If $c \neq 0$ , then $a=\pm 3$ . Thus $g(x)=\pm (3x+ x^3)$ , which is equivalent to $f(x)$ upto signs. Suppose I start with an investigation if there are degree $4$ polynomial $g(x)=ax+bx^2+cx^3+dx^4$ such that $f \circ g=g\circ f$ . Then it becomes laborious. Is there any way to find non-trivial $g$ with the help of PARI/GP or SAGE ? Edit 1: According to the hints given by @achille hui, I have found that $g(x)=-5x-5x^3-x^5$ commutes with $x^3+3x$ . However, I am looking for an polynomial whose first degree coefficient is $3$ or multiple of $3$ . I would appreciate one such example. Edit 2: But I need to find the polynomial with degree one coefficient, a multiple of $3$ and it is certainly possible as $f$ commutes with its iteration and each iteration has the degree one coefficient , a multiple of 3","Consider the polynomial over . I am trying to find a polynomial of any degree (or series) without constant term which commutes with (or any iteration under composition. Trivially, any , is another polynomial (or series) commutes with . By hand it seems to be laborious. Suppose I start with an investigation if there are degree polynomial such that . Then Comparing both equations, we get and . In this case , the trivial one. Suppose I start with an investigation if there are degree polynomial such that . Then Comparing both sides we get and the following equations: Solving these, we see and . These two gives us or . If , then . Thus , which is equivalent to upto signs. Suppose I start with an investigation if there are degree polynomial such that . Then it becomes laborious. Is there any way to find non-trivial with the help of PARI/GP or SAGE ? Edit 1: According to the hints given by @achille hui, I have found that commutes with . However, I am looking for an polynomial whose first degree coefficient is or multiple of . I would appreciate one such example. Edit 2: But I need to find the polynomial with degree one coefficient, a multiple of and it is certainly possible as commutes with its iteration and each iteration has the degree one coefficient , a multiple of 3","f(x)=x^3+3x \mathbb{Z} g(x) (\neq f^{\circ n}) f f^{\circ n}, ~n \geq 1) g(x)=x f(x) 2 g(x)=ax+bx^2 f \circ g=g\circ f \begin{align}
&f(g(x))=f(ax+bx^2)=3(ax+bx^2)+(ax+bx^2)^3=3ax+3bx^2+a^3x^3+3a^2bx^4+3ab^2x^5+b^3x^6, \\
&g(f(x))=g(x^3+3x)=a(x^3+3x)+b(x^3+3x)^2=3ax+ax^3+bx^6+6bx^4+9bx^2
\end{align} b=0 a=a^3 \Rightarrow a=\pm 1 g(x)=\pm 1 3 g(x)=ax+bx^2+cx^3 f \circ g=g\circ f \begin{align}
&f(g(x))=f(ax+bx^2+cx^3)=3(ax+bx^2+cx^3)+(ax+bx^2+cx^3)^3=3ax+3bx^2+3cx^3+c^3x^9+3bc^2x^8 \hspace{3cm}+(3ac^2+3b^2c)x^7+(6abc + b^3)x^6 + (3a^2c + 3ab^2)x^5 + 3a^2bx^4 + a^3x^3, \\
&g(f(x))=g(x^3+3x)=a(x^3+3x)+b(x^3+3x)^2+c(x^3+3x)^3=3ax+ax^3+2bx^6+6bx^4+9bx^2+cx^9+9cx^7+27cx^5+27cx^3
\end{align} b=0 \begin{align}
a^3-a=24c, \\
a^2c=9c, \\
3ac^2=9c,\\
c^3=c.
\end{align} c^3=c 3ac^2=a^2c c=0 c=\pm 1 c \neq 0 a=\pm 3 g(x)=\pm (3x+ x^3) f(x) 4 g(x)=ax+bx^2+cx^3+dx^4 f \circ g=g\circ f g g(x)=-5x-5x^3-x^5 x^3+3x 3 3 3 f","['abstract-algebra', 'elementary-number-theory', 'polynomials', 'ring-theory']"
83,Abelianization of free product is the direct sum of abelianizations [duplicate],Abelianization of free product is the direct sum of abelianizations [duplicate],,"This question already has answers here : Reference Request: Abelianization of free product is the direct sum of abelianizations (2 answers) Closed 3 years ago . I define $\text{Ab}(G)=G/[G,G]$ where $[G,G]$ is the commutator subgroup. I want to show that $$\text{Ab}(G_1*G_2)\cong \text{Ab}(G_1)\oplus\text{Ab}(G_2)$$ This page gives a categorical proof, but I don't know much category theory. Can someone give a purely group-theoretic proof of this (I know the universal property of abelianizations)? By the universal property, it would suffice to show that the RHS is an abelianization of $G_1*G_2$.","This question already has answers here : Reference Request: Abelianization of free product is the direct sum of abelianizations (2 answers) Closed 3 years ago . I define $\text{Ab}(G)=G/[G,G]$ where $[G,G]$ is the commutator subgroup. I want to show that $$\text{Ab}(G_1*G_2)\cong \text{Ab}(G_1)\oplus\text{Ab}(G_2)$$ This page gives a categorical proof, but I don't know much category theory. Can someone give a purely group-theoretic proof of this (I know the universal property of abelianizations)? By the universal property, it would suffice to show that the RHS is an abelianization of $G_1*G_2$.",,"['abstract-algebra', 'group-theory', 'algebraic-topology', 'free-groups', 'free-product']"
84,Semidirect product: general automorphism always results in a conjugation,Semidirect product: general automorphism always results in a conjugation,,"When $G$ is a group, $N$ is a normal subgroup of $G$ and $H$ is another subgroup of $G$ where $ N \cap H = \{1\} $, the normality of $N$ suggests that we can write, for $n_1, n_2 \in N$ and $h_1, h_2 \in H$, $$ n_1 h_1 n_2 h_2 = n_1 h_1 n_2 h_1^{-1} h_1 h_2 $$ and so motivates the definition of an 'external' semidirect product using $$ (n_1,h_1) (n_2,h_2) = (n_1 h_1 n_2 h_1^{-1}, h_1 h_2). $$ However, in general there is no reason to suppose $\textit{a priori}$ that $N$ and $H$ are subgroups of a larger group $G$, so that in general we say that to form the external product we need some groups $N$, $H$, and some homomorphism $\phi \colon H \to \textrm{Aut}(N)$ and define $$ (n_1,h_1) (n_2,h_2) = (n_1 \phi(h_1)(n_2), h_1 h_2). $$ I would expect that this would give something more general than the intuitive external product given above, since now we are using the result of a general automorphism $ \phi(h_1)(n_2) $ rather than the specific conjugation $ h_1 n_2 h_1^{-1} $. But it turns out that for any $\phi$ you come up with, this defines conjugation in the group $ N \rtimes H$. I am having difficulty seeing why this is intuitively. Is there any insight anyone can give? Why must the general automorphism in the external construction always correspond to an inner automorphism conjugation in the internal construction?","When $G$ is a group, $N$ is a normal subgroup of $G$ and $H$ is another subgroup of $G$ where $ N \cap H = \{1\} $, the normality of $N$ suggests that we can write, for $n_1, n_2 \in N$ and $h_1, h_2 \in H$, $$ n_1 h_1 n_2 h_2 = n_1 h_1 n_2 h_1^{-1} h_1 h_2 $$ and so motivates the definition of an 'external' semidirect product using $$ (n_1,h_1) (n_2,h_2) = (n_1 h_1 n_2 h_1^{-1}, h_1 h_2). $$ However, in general there is no reason to suppose $\textit{a priori}$ that $N$ and $H$ are subgroups of a larger group $G$, so that in general we say that to form the external product we need some groups $N$, $H$, and some homomorphism $\phi \colon H \to \textrm{Aut}(N)$ and define $$ (n_1,h_1) (n_2,h_2) = (n_1 \phi(h_1)(n_2), h_1 h_2). $$ I would expect that this would give something more general than the intuitive external product given above, since now we are using the result of a general automorphism $ \phi(h_1)(n_2) $ rather than the specific conjugation $ h_1 n_2 h_1^{-1} $. But it turns out that for any $\phi$ you come up with, this defines conjugation in the group $ N \rtimes H$. I am having difficulty seeing why this is intuitively. Is there any insight anyone can give? Why must the general automorphism in the external construction always correspond to an inner automorphism conjugation in the internal construction?",,"['abstract-algebra', 'group-theory', 'semidirect-product', 'group-extensions']"
85,Product of numbers $\pm\sqrt{1}\pm\sqrt{2}\pm\cdots\pm\sqrt{n}$ is integer,Product of numbers  is integer,\pm\sqrt{1}\pm\sqrt{2}\pm\cdots\pm\sqrt{n},"Prove that the product of the $2^n$ numbers $\pm\sqrt{1}\pm\sqrt{2}\pm\cdots\pm\sqrt{n}$ is an integer. I want to consider the polynomial $P(x)=(x-a_1)(x-a_2)\cdots(x-a_{2^n})$, where the $a_i$'s are the $2^n$ numbers. The desired product is the constant term of the polynomial. Can we show that this polynomial have some simple form?","Prove that the product of the $2^n$ numbers $\pm\sqrt{1}\pm\sqrt{2}\pm\cdots\pm\sqrt{n}$ is an integer. I want to consider the polynomial $P(x)=(x-a_1)(x-a_2)\cdots(x-a_{2^n})$, where the $a_i$'s are the $2^n$ numbers. The desired product is the constant term of the polynomial. Can we show that this polynomial have some simple form?",,"['abstract-algebra', 'polynomials']"
86,"$A\oplus C \cong B \oplus C$. Is $A \cong B$ when $C$ is finite, A and B infinite.",". Is  when  is finite, A and B infinite.",A\oplus C \cong B \oplus C A \cong B C,"So my question is simply that for groups $A, B, C,$ if C is finite, A and B infinite and $A\oplus C \cong B \oplus C$, is $A \cong B$?  My gut tells me this must be the case, and logically I can find no reason they shouldn't be, but I can not seem to derive a formal proof of this for the life of me. Note that I am well aware that this is not always true for infinite C.","So my question is simply that for groups $A, B, C,$ if C is finite, A and B infinite and $A\oplus C \cong B \oplus C$, is $A \cong B$?  My gut tells me this must be the case, and logically I can find no reason they shouldn't be, but I can not seem to derive a formal proof of this for the life of me. Note that I am well aware that this is not always true for infinite C.",,"['abstract-algebra', 'group-theory']"
87,Coprime elements in finite rings,Coprime elements in finite rings,,"Let $R$ be a finite commutative ring. Consider elements $a,b \in R$ such that $Ra+Rb=R$.  A paper I'm reading asserts that there exists some $x,y \in R$ such that $x(a+yb) = 1$. Of course, it is clear that we can find some $x,y \in R$ such that $xa+yb=1$, but it is not clear that we can get the above stronger statement. It is equivalent to saying that there exists some $y \in R$ such that $a+yb$ is a unit. Can anyone help me?","Let $R$ be a finite commutative ring. Consider elements $a,b \in R$ such that $Ra+Rb=R$.  A paper I'm reading asserts that there exists some $x,y \in R$ such that $x(a+yb) = 1$. Of course, it is clear that we can find some $x,y \in R$ such that $xa+yb=1$, but it is not clear that we can get the above stronger statement. It is equivalent to saying that there exists some $y \in R$ such that $a+yb$ is a unit. Can anyone help me?",,"['abstract-algebra', 'commutative-algebra', 'ring-theory', 'finite-rings']"
88,"When $\sin x, \cos x$ are $\mathbb{Q}$-linear combinations of square roots",When  are -linear combinations of square roots,"\sin x, \cos x \mathbb{Q}","Suppose $x\in\Bbb R$ is such that $$\sin x=\sum_{i=1}^m x_i\sqrt{r_i},\quad \cos x=\sum_{j=1}^n y_j\sqrt{s_j}$$ for some $x_i, r_i, y_j, s_j \in\Bbb Q \ , \  |x_i|=|y_j|=1$. Show that $x=\dfrac{k\pi}{12}$ for some $k\in\Bbb Z$.","Suppose $x\in\Bbb R$ is such that $$\sin x=\sum_{i=1}^m x_i\sqrt{r_i},\quad \cos x=\sum_{j=1}^n y_j\sqrt{s_j}$$ for some $x_i, r_i, y_j, s_j \in\Bbb Q \ , \  |x_i|=|y_j|=1$. Show that $x=\dfrac{k\pi}{12}$ for some $k\in\Bbb Z$.",,"['abstract-algebra', 'algebra-precalculus', 'trigonometry']"
89,"Universal Covering Group of $SO(1,3)^{\uparrow}$",Universal Covering Group of,"SO(1,3)^{\uparrow}","I'm trying to prove that $SL(2,\mathbb{C})$ is the universal covering group for the proper orthochronous Lorentz group $SO(1,3)^{\uparrow}$. The standard way goes as follows. (1) Exhibit a real vector space isomorphism between Minkowski space and the space of $2\times 2$ Hermitian matrices, $H$. (2) Let $SL(2,\mathbb{C})$ act on $H$ by $X\mapsto AXA^{\dagger}$ and prove this induces a surjective, 2:1 homomorphism from $SL(2,\mathbb{C})$ to $SO(1,3)^{\uparrow}$. I'm wondering whether there is a better way however. To prove that $SU(2)$ is the universal covering group of $SO(3)$ it suffices to go to the Lie algebra and demonstrate that the adjoint representation is an isomorphism of Lie algebras. Can I do something analogous here? Here's what I've tried. The Lie algebra of $SO(1,3)$ is $su(2)\oplus su(2)$ which naturally acts on a 4-dimensional complex vector space. The Lie algebra of $SL(2,\mathbb{C})$ is the space of traceless complex matrices, of dimension 6. I can't now see how to proceed. Maybe this approach doesn't work at all now. Is it just a special property of $SU(2)$ and $SO(3)$ that happens because $SU(2)$ happens to have dimension 3, exactly the right number for an $SO(3)$ action? Many thanks in advance!","I'm trying to prove that $SL(2,\mathbb{C})$ is the universal covering group for the proper orthochronous Lorentz group $SO(1,3)^{\uparrow}$. The standard way goes as follows. (1) Exhibit a real vector space isomorphism between Minkowski space and the space of $2\times 2$ Hermitian matrices, $H$. (2) Let $SL(2,\mathbb{C})$ act on $H$ by $X\mapsto AXA^{\dagger}$ and prove this induces a surjective, 2:1 homomorphism from $SL(2,\mathbb{C})$ to $SO(1,3)^{\uparrow}$. I'm wondering whether there is a better way however. To prove that $SU(2)$ is the universal covering group of $SO(3)$ it suffices to go to the Lie algebra and demonstrate that the adjoint representation is an isomorphism of Lie algebras. Can I do something analogous here? Here's what I've tried. The Lie algebra of $SO(1,3)$ is $su(2)\oplus su(2)$ which naturally acts on a 4-dimensional complex vector space. The Lie algebra of $SL(2,\mathbb{C})$ is the space of traceless complex matrices, of dimension 6. I can't now see how to proceed. Maybe this approach doesn't work at all now. Is it just a special property of $SU(2)$ and $SO(3)$ that happens because $SU(2)$ happens to have dimension 3, exactly the right number for an $SO(3)$ action? Many thanks in advance!",,"['abstract-algebra', 'group-theory', 'representation-theory', 'lie-groups', 'lie-algebras']"
90,Why is this isomorphism $M \otimes_K L \stackrel{\simeq}{\longrightarrow} M^{[L:K]}$ an isomorphism of $M$ - algebras?,Why is this isomorphism  an isomorphism of  - algebras?,M \otimes_K L \stackrel{\simeq}{\longrightarrow} M^{[L:K]} M,"Suppose that $L/K$ is a finite separable extension of fields and let $M$ denote the Galois closure of $L$. Let $\textrm{Hom}_K(L,M)$ denote the set of all $K$ - algebra homomorphisms from $L$ to $M$. Since $L/K$ is separable we know that the number of elements in $\textrm{Hom}_K(L,M)$ is equal to $[L:K]$. Now I want to prove that we have an isomorphism of $M$ - algebras $$\varphi : M \otimes_K L \stackrel{\simeq}{\longrightarrow} M^{[L:K]}$$ Proof that they are isomorphic as $K$ - modules : Write $L = K(a)$ for some $ a\in L$ (we can do this via the primitive element theorem). Then $$\begin{eqnarray*} M \otimes_K L &=& M \otimes_K K[a] \\ &\cong& M\otimes_K K[x]/(f) \hspace{3mm} \text{where $f$ is the minimal polynomial of $a$ over $K$} \\ &\cong& M[x]/(f)\\ &\cong& M[x]/(f_1\ldots f_{[L:K]}) \hspace{3mm} \text{where the $f_i$ are the distinct}\\ && \hspace{1.5in} \text{irreducible factors of $f$ since $M/L$ is Galois} \\ &\cong& M^{[L:K]}\end{eqnarray*}$$ where  the last step was using the Chinese remainder theorem. For the third last step, we consider the ses $$ 0 \to (f) \to K[x] \to K[x]/(f) \to 0$$ and tensor with the exact functor $-\otimes_K M$ to get $$0 \to (f) \otimes_K M \to K[x] \otimes_K M \to K[x]/(f) \otimes_K M \to 0$$ and so $$\begin{eqnarray*} M \otimes_K K[x]/(f) &\cong& K[x]/(f) \otimes_{K} M \\ &\cong& \frac{K[x] \otimes_{K} M}{f \otimes_K M}\\ & \cong& M[x]/(f) \end{eqnarray*}$$ where $(f)$ is now viewed as an ideal of $M[x]$. My question is: The tensor product $M \otimes_K L$ is a left $M$ - module, but why is it also an $M$ - algebra? Also why are the isomorphisms above isomorphisms of $M$ - algebras and not just $K$ - modules?","Suppose that $L/K$ is a finite separable extension of fields and let $M$ denote the Galois closure of $L$. Let $\textrm{Hom}_K(L,M)$ denote the set of all $K$ - algebra homomorphisms from $L$ to $M$. Since $L/K$ is separable we know that the number of elements in $\textrm{Hom}_K(L,M)$ is equal to $[L:K]$. Now I want to prove that we have an isomorphism of $M$ - algebras $$\varphi : M \otimes_K L \stackrel{\simeq}{\longrightarrow} M^{[L:K]}$$ Proof that they are isomorphic as $K$ - modules : Write $L = K(a)$ for some $ a\in L$ (we can do this via the primitive element theorem). Then $$\begin{eqnarray*} M \otimes_K L &=& M \otimes_K K[a] \\ &\cong& M\otimes_K K[x]/(f) \hspace{3mm} \text{where $f$ is the minimal polynomial of $a$ over $K$} \\ &\cong& M[x]/(f)\\ &\cong& M[x]/(f_1\ldots f_{[L:K]}) \hspace{3mm} \text{where the $f_i$ are the distinct}\\ && \hspace{1.5in} \text{irreducible factors of $f$ since $M/L$ is Galois} \\ &\cong& M^{[L:K]}\end{eqnarray*}$$ where  the last step was using the Chinese remainder theorem. For the third last step, we consider the ses $$ 0 \to (f) \to K[x] \to K[x]/(f) \to 0$$ and tensor with the exact functor $-\otimes_K M$ to get $$0 \to (f) \otimes_K M \to K[x] \otimes_K M \to K[x]/(f) \otimes_K M \to 0$$ and so $$\begin{eqnarray*} M \otimes_K K[x]/(f) &\cong& K[x]/(f) \otimes_{K} M \\ &\cong& \frac{K[x] \otimes_{K} M}{f \otimes_K M}\\ & \cong& M[x]/(f) \end{eqnarray*}$$ where $(f)$ is now viewed as an ideal of $M[x]$. My question is: The tensor product $M \otimes_K L$ is a left $M$ - module, but why is it also an $M$ - algebra? Also why are the isomorphisms above isomorphisms of $M$ - algebras and not just $K$ - modules?",,"['abstract-algebra', 'field-theory']"
91,Universal property of the completion of rings / modules,Universal property of the completion of rings / modules,,"If $A$ is a noetherian local ring and $M$ an $A$-module, then we define the completion $\hat{M}$ of $M$ with respect to the stable $\mathfrak{m}$-filtration $\{M_n\}$ by $$\hat{M}=\left\{(a_1,a_2,...)\in\prod_{i=1}^\infty M/M_i:a_j\equiv a_i\bmod{M_i}\,\,\forall j>i\right\}.$$ See also my previous question . Now in the book I use (A SINGULAR Introduction to Commutative Algebra by Greuel/Pfister), there is no universal property of this completion mentioned, but once it uses something that looks like one: We have a map from $K[x_1,...,x_n]_{\langle x_1,...,x_n\rangle}$ to some complete ring, hence we got a map from $K[[x_1,...,x_n]]$ to it. Is that the 'universal property of the completion of a ring / module', and if yes, is it somehow obvious from my definition of the completion, so that we could use it directly? How to prove this property with the above definition? (If it really works for modules; I don't know, at least for rings I guess it should be something like: If $A\to B$ is a ring homomorphism and $B$ is complete, then there is a unique map $\hat{A}\to B$ extending it). Well, I think I maybe got a clue right now, and you could perhaps tell me if this is the correct way (I'd still like to know if this is 'the' universal property of the completion): If $A\to B$ is a ring homomorphism ($A$ and $B$ noetherian local rings; does this homomorphism have to be local, too?), and $B$ is complete, then I get and induced map $\hat{A}\to\hat{B}=B$ as wanted.","If $A$ is a noetherian local ring and $M$ an $A$-module, then we define the completion $\hat{M}$ of $M$ with respect to the stable $\mathfrak{m}$-filtration $\{M_n\}$ by $$\hat{M}=\left\{(a_1,a_2,...)\in\prod_{i=1}^\infty M/M_i:a_j\equiv a_i\bmod{M_i}\,\,\forall j>i\right\}.$$ See also my previous question . Now in the book I use (A SINGULAR Introduction to Commutative Algebra by Greuel/Pfister), there is no universal property of this completion mentioned, but once it uses something that looks like one: We have a map from $K[x_1,...,x_n]_{\langle x_1,...,x_n\rangle}$ to some complete ring, hence we got a map from $K[[x_1,...,x_n]]$ to it. Is that the 'universal property of the completion of a ring / module', and if yes, is it somehow obvious from my definition of the completion, so that we could use it directly? How to prove this property with the above definition? (If it really works for modules; I don't know, at least for rings I guess it should be something like: If $A\to B$ is a ring homomorphism and $B$ is complete, then there is a unique map $\hat{A}\to B$ extending it). Well, I think I maybe got a clue right now, and you could perhaps tell me if this is the correct way (I'd still like to know if this is 'the' universal property of the completion): If $A\to B$ is a ring homomorphism ($A$ and $B$ noetherian local rings; does this homomorphism have to be local, too?), and $B$ is complete, then I get and induced map $\hat{A}\to\hat{B}=B$ as wanted.",,"['abstract-algebra', 'commutative-algebra']"
92,Group presentation of $A_5$ with two generators,Group presentation of  with two generators,A_5,"In [Huppert, Endliche Gruppen, p140] the author shows that the alternating group $A_5$ is isomorphic to $G := \langle x,y \mid x^5=y^2=(xy)^3=1 \rangle$ . The proof is elementary but long and complicated. Is there a simple way to prove the assertion by using some theory? Of course essentially we have to show that $|G| \leq 60$ . Here is a possible attempt: $A_5$ is generated by $(1,2,3,4,5)$ and $(12)(34)$ , and these elements satisfy the above relations. We can try to give a proof of $|A_5| \leq 60$ by using these generators (and the well known subgroup structure of $A_5$ ), and then to adapt the same proof for $G$ . This could be done as follows: Set $a := xy$ and $b := (xy)^{x^2} = x^{-1}y{x^2}$ . Both elements are of order three. The corresponding permutations are $(2,4,5)$ and $(1,2,4)$ so in principle we should be able to show that $U := \langle a,b \rangle$ (which is in fact isomorphic to $A_4$ ) has at most $12$ elements. For doing so we define $V := \langle ab, (ab)^b \rangle$ . $V$ has to be isomorphic to the Klein four group, so we have to show that $(ab)$ and $(ab)^b$ are commuting involutions (should be possible somehow...), and that $b$ normalizes $V$ (easy). Then it is clear that $U = V \langle b \rangle$ has at most $12$ elements. Finally, we have to show that the index $|G:U|$ is at most $5$ . This is the only part, where I have no idea how to proceed. Any ideas?","In [Huppert, Endliche Gruppen, p140] the author shows that the alternating group is isomorphic to . The proof is elementary but long and complicated. Is there a simple way to prove the assertion by using some theory? Of course essentially we have to show that . Here is a possible attempt: is generated by and , and these elements satisfy the above relations. We can try to give a proof of by using these generators (and the well known subgroup structure of ), and then to adapt the same proof for . This could be done as follows: Set and . Both elements are of order three. The corresponding permutations are and so in principle we should be able to show that (which is in fact isomorphic to ) has at most elements. For doing so we define . has to be isomorphic to the Klein four group, so we have to show that and are commuting involutions (should be possible somehow...), and that normalizes (easy). Then it is clear that has at most elements. Finally, we have to show that the index is at most . This is the only part, where I have no idea how to proceed. Any ideas?","A_5 G := \langle x,y \mid x^5=y^2=(xy)^3=1 \rangle |G| \leq 60 A_5 (1,2,3,4,5) (12)(34) |A_5| \leq 60 A_5 G a := xy b := (xy)^{x^2} = x^{-1}y{x^2} (2,4,5) (1,2,4) U := \langle a,b \rangle A_4 12 V := \langle ab, (ab)^b \rangle V (ab) (ab)^b b V U = V \langle b \rangle 12 |G:U| 5","['abstract-algebra', 'group-theory', 'alternative-proof', 'symmetric-groups', 'group-presentation']"
93,On the converse of Schur's Lemma,On the converse of Schur's Lemma,,"Let $G$ be a finite group and $F$ a field with $\mathrm{char}(F)=0$ or coprime to $|G|$. Let $V$ be a $FG$-module in a way that every $ FG$-homomorphism $ f : V \to V $ is given by $f(x)= \lambda x $. Then $V$ is irreducible. I already managed to proof this by contradiction, using Maschke's Theorem. We can  write $V$ as $U\oplus W$ and get a $FG$-homomorphism $\pi:U\oplus W \to U\oplus W$, $\pi (u+w)=u$, then $\pi(u+w)=\lambda (u+w)=u $ then either $U$ or $W$ are trivial and thus $V$ is irreducible. My question is if this statements still holds if the characterictic of $F$ divides the order of $G$, since I only used this fact in my proof to use Maschke's theorem.","Let $G$ be a finite group and $F$ a field with $\mathrm{char}(F)=0$ or coprime to $|G|$. Let $V$ be a $FG$-module in a way that every $ FG$-homomorphism $ f : V \to V $ is given by $f(x)= \lambda x $. Then $V$ is irreducible. I already managed to proof this by contradiction, using Maschke's Theorem. We can  write $V$ as $U\oplus W$ and get a $FG$-homomorphism $\pi:U\oplus W \to U\oplus W$, $\pi (u+w)=u$, then $\pi(u+w)=\lambda (u+w)=u $ then either $U$ or $W$ are trivial and thus $V$ is irreducible. My question is if this statements still holds if the characterictic of $F$ divides the order of $G$, since I only used this fact in my proof to use Maschke's theorem.",,"['abstract-algebra', 'group-theory', 'representation-theory']"
94,Show that a ring is commutative if it has the property that ab = ca implies b = c when $a\neq 0$,Show that a ring is commutative if it has the property that ab = ca implies b = c when,a\neq 0,"Show that a ring is commutative if it has the property that ab = ca implies b = c when $a\neq 0$. This is my proof to show that a ring is commutative if it has the property that ab = ca implies b = c. We need to show that if x, y ∈ R then xy = yx. Let a = x, b = yx and c = xy. Then ab = x(yx) = (xy)x = ca. Thus, by the hypothesis, b = c, or xy = yx. Thus, for x, y ∈ R we have xy = yx. How would I show when $a\neq 0$?","Show that a ring is commutative if it has the property that ab = ca implies b = c when $a\neq 0$. This is my proof to show that a ring is commutative if it has the property that ab = ca implies b = c. We need to show that if x, y ∈ R then xy = yx. Let a = x, b = yx and c = xy. Then ab = x(yx) = (xy)x = ca. Thus, by the hypothesis, b = c, or xy = yx. Thus, for x, y ∈ R we have xy = yx. How would I show when $a\neq 0$?",,"['abstract-algebra', 'ring-theory']"
95,When is a field a nontrivial field of fractions?,When is a field a nontrivial field of fractions?,,"If we take any integral domain, then we can define a field of fractions by taking equivalence classes of ordered pairs of elements, the same way that the rational numbers are constructed from the integers. My question is: What fields (of characteristic $0$) are isomorphic to the field of fractions of some integral domain (that's not a field)? For instance, is the field of constructible real numbers a nontrivial field of fractions? What about the algebraic real numbers?  What about arbitrarily real closed fields?  And what about if we restrict ourselves to integral domains which are models of Peano arithmetic, or models of Robinson arithmetic?  (EDIT:  for those less acquainted with logic and model theory, let me ask this: what if we restricted the integral domains to ones that are discretely ordered rings?)  I should mention that my motivation for asking these sorts of questions is my MathOverflow question . Any help would be greatly appreciated. Thank You in Advance.","If we take any integral domain, then we can define a field of fractions by taking equivalence classes of ordered pairs of elements, the same way that the rational numbers are constructed from the integers. My question is: What fields (of characteristic $0$) are isomorphic to the field of fractions of some integral domain (that's not a field)? For instance, is the field of constructible real numbers a nontrivial field of fractions? What about the algebraic real numbers?  What about arbitrarily real closed fields?  And what about if we restrict ourselves to integral domains which are models of Peano arithmetic, or models of Robinson arithmetic?  (EDIT:  for those less acquainted with logic and model theory, let me ask this: what if we restricted the integral domains to ones that are discretely ordered rings?)  I should mention that my motivation for asking these sorts of questions is my MathOverflow question . Any help would be greatly appreciated. Thank You in Advance.",,"['abstract-algebra', 'commutative-algebra', 'ring-theory', 'field-theory']"
96,Quaternion Rings,Quaternion Rings,,"Let $R$ be a commutative ring. Define the Hamilton quaternions $H(R)$ over $R$ to be the free $R$-module with basis $\{1, i, j, k\}$, that is, $$H(R)=\{a_0+a_1i+a_2j+a_3k\;\;:\;\;a_l\in R\}.$$ and multiplication is defined by: $i^2=j^2=k^2=ijk=-1$. Is well-known that over a field $F$ (with char $F\neq 2$) the ring $H(F)$ is a division ring or isomorphic to $M_2(F)$. What can we say  about the Hamilton quaternions over an arbitrary commutative ring $R$? Is still true that $H(R)$ is a division ring or isomorphic to $M_2(R)$? We must impose some conditions to the ring to make it happen?","Let $R$ be a commutative ring. Define the Hamilton quaternions $H(R)$ over $R$ to be the free $R$-module with basis $\{1, i, j, k\}$, that is, $$H(R)=\{a_0+a_1i+a_2j+a_3k\;\;:\;\;a_l\in R\}.$$ and multiplication is defined by: $i^2=j^2=k^2=ijk=-1$. Is well-known that over a field $F$ (with char $F\neq 2$) the ring $H(F)$ is a division ring or isomorphic to $M_2(F)$. What can we say  about the Hamilton quaternions over an arbitrary commutative ring $R$? Is still true that $H(R)$ is a division ring or isomorphic to $M_2(R)$? We must impose some conditions to the ring to make it happen?",,"['abstract-algebra', 'quaternions', 'division-algebras']"
97,"Isomorphism of direct sums $R/a \oplus R/b \cong R/{\rm lcm}(a,b)\oplus R/\gcd(a,b)$",Isomorphism of direct sums,"R/a \oplus R/b \cong R/{\rm lcm}(a,b)\oplus R/\gcd(a,b)","So I basically have to prove the following. If $a,b\in R$ non-zero, with $R$ a PID. Then we want to show $$R/aR\oplus R/bR\cong R/cR\oplus R/dR$$ Where $c$ is the least common multiple of $a$ and $b$ , and $d$ is the greatest common divisor of $a$ and $b$ . Here is my proof: Since $R$ is a PID it is also a UFD, so let $$a=u_1p_1^{\alpha_1}...p_n^{\alpha_n}$$ $$b=u_2p_1^{\beta_1}...p_n^{\beta_n}$$ where $u_i$ are units, and some of the $\alpha$ 's or $\beta$ 's might be zero, but it is written this way for a later convinience. By the chinese remainder theorem we have that $R/aR\cong R/p_1^{\alpha_1}R\oplus...\oplus R/p_n^{\alpha_n}R$ . I do the same with $R/bR$ , and then I have $$R/aR\oplus R/bR\cong  R/p_1^{\alpha_1}R\oplus...\oplus R/p_n^{\alpha_n}R\oplus R/p_1^{\beta_1}R\oplus...\oplus R/p_n^{\beta_n}R$$ Then for a given if $\alpha_i<\beta_i$ , then I interchange the summands of $R/p_i^{\alpha_i}R$ and $R/p_i^{\beta_i}R$ . I basically write the high exponents in the front and the low exponents in the back. The combination of the low exponents furnishes the gcd, and the combination of the high exponents yields the lcm. I was wondering if there is an easier way (which probably there is, I am somewhat tired) that gives an explicit map. Thanks.","So I basically have to prove the following. If non-zero, with a PID. Then we want to show Where is the least common multiple of and , and is the greatest common divisor of and . Here is my proof: Since is a PID it is also a UFD, so let where are units, and some of the 's or 's might be zero, but it is written this way for a later convinience. By the chinese remainder theorem we have that . I do the same with , and then I have Then for a given if , then I interchange the summands of and . I basically write the high exponents in the front and the low exponents in the back. The combination of the low exponents furnishes the gcd, and the combination of the high exponents yields the lcm. I was wondering if there is an easier way (which probably there is, I am somewhat tired) that gives an explicit map. Thanks.","a,b\in R R R/aR\oplus R/bR\cong R/cR\oplus R/dR c a b d a b R a=u_1p_1^{\alpha_1}...p_n^{\alpha_n} b=u_2p_1^{\beta_1}...p_n^{\beta_n} u_i \alpha \beta R/aR\cong R/p_1^{\alpha_1}R\oplus...\oplus R/p_n^{\alpha_n}R R/bR R/aR\oplus R/bR\cong  R/p_1^{\alpha_1}R\oplus...\oplus R/p_n^{\alpha_n}R\oplus R/p_1^{\beta_1}R\oplus...\oplus R/p_n^{\beta_n}R \alpha_i<\beta_i R/p_i^{\alpha_i}R R/p_i^{\beta_i}R","['abstract-algebra', 'principal-ideal-domains']"
98,Hochschild homology of Weyl algebra,Hochschild homology of Weyl algebra,,"Could someone explain to me how one can compute the Hochschild homology of the Weyl algebra $A_n$ (i.e., algebra of differential operators with polynomial coefficients in $n$ variables)?","Could someone explain to me how one can compute the Hochschild homology of the Weyl algebra (i.e., algebra of differential operators with polynomial coefficients in variables)?",A_n n,"['abstract-algebra', 'homological-algebra', 'hochschild-cohomology']"
99,Why do we call it trace?,Why do we call it trace?,,"For any module $P$, we define $\mathrm{tr}(P)=\sum \mathrm{im}(f)$, where $f$ ranges over all elements of $\mathrm{Hom}(P,R)$， and call it trace. Why does it have such a name? Does it have any relation to the trace of matrix？","For any module $P$, we define $\mathrm{tr}(P)=\sum \mathrm{im}(f)$, where $f$ ranges over all elements of $\mathrm{Hom}(P,R)$， and call it trace. Why does it have such a name? Does it have any relation to the trace of matrix？",,"['abstract-algebra', 'terminology', 'modules']"
