,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Are all Henstock-Kurzweil integrable functions expressible as the sum of a Lebesgue and an improper Riemann integrable function?,Are all Henstock-Kurzweil integrable functions expressible as the sum of a Lebesgue and an improper Riemann integrable function?,,"This question is based on this post , where in the comments, Toby Bartels conjectures that every Henstock-Kurzweil (gauge) integrable function $f\in\mathcal{HK}$ can be expressed as $f= g + h$ for a Lebesgue integrable function $g\in\mathcal{L}$ and improper Riemann integrable function $h\in\mathcal{R}^*$ Is this true? Intuitively to me this seems obviously false, since $\mathcal{HK}$ is strictly larger than $\mathcal{L}$ and $\mathcal{R}^*$ , but I can’t think of any counterexamples or a way to prove a counterexample exists. If a counterexample exists, I know from properties of the HK integral that it must not have compact support, $|f|$ must not be HK integrable, and $f$ is not non-negative, as any of these conditions would imply that it would be Lebesgue integrable. If this isn’t true, as I suspect, can we prove a more general statement, let’s say for $f=g\circ h$ . How would one go about proving this true or false?","This question is based on this post , where in the comments, Toby Bartels conjectures that every Henstock-Kurzweil (gauge) integrable function can be expressed as for a Lebesgue integrable function and improper Riemann integrable function Is this true? Intuitively to me this seems obviously false, since is strictly larger than and , but I can’t think of any counterexamples or a way to prove a counterexample exists. If a counterexample exists, I know from properties of the HK integral that it must not have compact support, must not be HK integrable, and is not non-negative, as any of these conditions would imply that it would be Lebesgue integrable. If this isn’t true, as I suspect, can we prove a more general statement, let’s say for . How would one go about proving this true or false?",f\in\mathcal{HK} f= g + h g\in\mathcal{L} h\in\mathcal{R}^* \mathcal{HK} \mathcal{L} \mathcal{R}^* |f| f f=g\circ h,"['real-analysis', 'measure-theory', 'lebesgue-integral', 'gauge-integral']"
1,Pre-Hilbert space and its completion,Pre-Hilbert space and its completion,,"I'm currently managing to understand how to find a completion of Pre-Hilbert space $\mathcal H_0$ in Stein's real analysis. The textbook says the completion $\mathcal H$ has three properties, and the proof of the second one (ii) $(f,g)_0 = (f,g)$ whenever $f,g \in \mathcal H_0$ is written on the red line as follows. This is where I'm stuck on. The following proof is what I've tried at most. $|(f_n-f, g_n-g)| \le ||f_n-f||_H ||g_n-g||_H$ , and since $||f_n-f||_H \to 0$ and $||g_n-g||_H \to 0$ as $n \to \infty$ , $|(f_n-f, g_n-g)| \to 0$ . Thus $lim_{n \to \infty}(f_n,g_n) = (f,g)$ . This is what I've interpreted the definition of $(f,g)$ written on the red line. If this is correct, what should I do to induce $(f,g)_0$ ? The above proof doesn't include no inner product of $\mathcal H_0$ , $(,)_0$ , so I have a difficulty associating my trial with $(,)_0$ . Any help would be appreciated. Thank you.","I'm currently managing to understand how to find a completion of Pre-Hilbert space in Stein's real analysis. The textbook says the completion has three properties, and the proof of the second one (ii) whenever is written on the red line as follows. This is where I'm stuck on. The following proof is what I've tried at most. , and since and as , . Thus . This is what I've interpreted the definition of written on the red line. If this is correct, what should I do to induce ? The above proof doesn't include no inner product of , , so I have a difficulty associating my trial with . Any help would be appreciated. Thank you.","\mathcal H_0 \mathcal H (f,g)_0 = (f,g) f,g \in \mathcal H_0 |(f_n-f, g_n-g)| \le ||f_n-f||_H ||g_n-g||_H ||f_n-f||_H \to 0 ||g_n-g||_H \to 0 n \to \infty |(f_n-f, g_n-g)| \to 0 lim_{n \to \infty}(f_n,g_n) = (f,g) (f,g) (f,g)_0 \mathcal H_0 (,)_0 (,)_0","['real-analysis', 'measure-theory', 'hilbert-spaces']"
2,"If $\mu_n \overset{\ast}{\rightharpoonup}\mu$, then $\mu^+_n \overset{\ast}{\rightharpoonup} \mu^+$ and $\mu^-_n \overset{\ast}{\rightharpoonup}\mu^-$","If , then  and",\mu_n \overset{\ast}{\rightharpoonup}\mu \mu^+_n \overset{\ast}{\rightharpoonup} \mu^+ \mu^-_n \overset{\ast}{\rightharpoonup}\mu^-,"Let $X$ be a Polish space and $\mu, \mu_n$ finite signed Borel measures on $X$ . Assume that $\mu_n \overset{\ast}{\rightharpoonup} \mu$ , i.e., $$ \int_X f \mathrm d \mu_n \to \int_X f \mathrm d \mu $$ for all bounded continuous functions $f:X \to \mathbb R$ . Let $\mu = \mu^+ - \mu^-$ and $\mu_n = \mu_n^+ - \mu_n^-$ be their Jordan decompositions. Is it true that $\mu^+_n \overset{\ast}{\rightharpoonup} \mu^+$ and $\mu^-_n \overset{\ast}{\rightharpoonup} \mu^-$ ?","Let be a Polish space and finite signed Borel measures on . Assume that , i.e., for all bounded continuous functions . Let and be their Jordan decompositions. Is it true that and ?","X \mu, \mu_n X \mu_n \overset{\ast}{\rightharpoonup} \mu 
\int_X f \mathrm d \mu_n \to \int_X f \mathrm d \mu
 f:X \to \mathbb R \mu = \mu^+ - \mu^- \mu_n = \mu_n^+ - \mu_n^- \mu^+_n \overset{\ast}{\rightharpoonup} \mu^+ \mu^-_n \overset{\ast}{\rightharpoonup} \mu^-","['measure-theory', 'weak-convergence', 'signed-measures']"
3,A step in a proof that a set is Lebesgue measurable if and only if its translation is,A step in a proof that a set is Lebesgue measurable if and only if its translation is,,"I'm trying to fill in the gaps in the following proof: In the above, $\mu^*$ refers to the Lebesgue outer measure , the Carathéodory definition of measurability states that a set $A$ is Carathéodory measurable if for any subset $E$ of $\mathbb{R}^n$ one has $$\mu^*(E)=\mu^*(E\cap A) + \mu^*(E\cap A^c),$$ and a set is defined as measurable if it belongs to the $\sigma$ -algebra formed by all the Carathédory measurable subsets of $\mathbb{R}^n$ (equivalently, if it is Carathéodory measurable). I understand why $\mu^*(A+h)=\mu^*(A)$ , but I fail to understand why a set $A$ is measurable if and only if so is $A+h$ . What we wish to prove is that, if $A$ is measurable, then for any subset $E$ of $\mathbb{R}^n$ we have that $$\mu^*(E)=\mu^*(E\cap (A+h)) + \mu^*(E\cap (A+h)^c),$$ but I do not see how the fact that $$(E+h)\cap (A+h) = (E\cap A) + h$$ is helpful here.","I'm trying to fill in the gaps in the following proof: In the above, refers to the Lebesgue outer measure , the Carathéodory definition of measurability states that a set is Carathéodory measurable if for any subset of one has and a set is defined as measurable if it belongs to the -algebra formed by all the Carathédory measurable subsets of (equivalently, if it is Carathéodory measurable). I understand why , but I fail to understand why a set is measurable if and only if so is . What we wish to prove is that, if is measurable, then for any subset of we have that but I do not see how the fact that is helpful here.","\mu^* A E \mathbb{R}^n \mu^*(E)=\mu^*(E\cap A) + \mu^*(E\cap A^c), \sigma \mathbb{R}^n \mu^*(A+h)=\mu^*(A) A A+h A E \mathbb{R}^n \mu^*(E)=\mu^*(E\cap (A+h)) + \mu^*(E\cap (A+h)^c), (E+h)\cap (A+h) = (E\cap A) + h","['measure-theory', 'lebesgue-measure', 'outer-measure', 'invariance']"
4,How to find an example for a measure which is not continuous from above?,How to find an example for a measure which is not continuous from above?,,"I need to give an example of a measure $\mu$ and subsets $A_n$ s.t. $$A_1\supset A_2\supset ...$$ and $$\mu(\cap_{n=1}^\infty A_n)\neq \lim_{n\rightarrow \infty} \mu(A_n)$$ I hat the following in mind. Take $\mu$ to be the counting measure and $A_1=\mathbb{N}, A_2=\mathbb{N}\setminus\{1\},...$ then $$\mu(\cap_{n=1}^\infty A_n)=\mu(\emptyset)=0$$ but now I have some strugles to show the other part with the limes. could someone help me please? It would be nice if we could procede with this example since this was my own idea without using any internet.",I need to give an example of a measure and subsets s.t. and I hat the following in mind. Take to be the counting measure and then but now I have some strugles to show the other part with the limes. could someone help me please? It would be nice if we could procede with this example since this was my own idea without using any internet.,"\mu A_n A_1\supset A_2\supset ... \mu(\cap_{n=1}^\infty A_n)\neq \lim_{n\rightarrow \infty} \mu(A_n) \mu A_1=\mathbb{N}, A_2=\mathbb{N}\setminus\{1\},... \mu(\cap_{n=1}^\infty A_n)=\mu(\emptyset)=0",['measure-theory']
5,Why do we need Fubini's theorem in this proof of Minkowski's inequality for integrals,Why do we need Fubini's theorem in this proof of Minkowski's inequality for integrals,,"I'm reading Theorem 6.19 in textbook Real Analysis: Modern Techniques and Their Applications by Gerald B. Folland. Suppose that $(X, \mathcal{M}, \mu)$ and $(Y, \mathcal{N}, \nu)$ are $\sigma$ -finite measure spaces, and let $f$ be an $(\mathcal{M} \otimes \mathcal{N})$ -measurable function on $X \times Y$ . a. If $f \geq 0$ and $1 \leq p<\infty$ , then $$ \left[\int\left(\int f(x, y) d \nu(y)\right)^{p} d \mu(x)\right]^{1 / p} \leq \int\left[\int f(x, y)^{p} d \mu(x)\right]^{1 / p} d \nu(y) $$ b. If $1 \leq p \leq \infty, f(\cdot, y) \in L^{p}(\mu)$ for a.e. $y$ , and the function $y \mapsto\|f(\cdot, y)\|_{p}$ is in $L^{1}(\nu)$ , then $f(x, \cdot) \in L^{1}(\nu)$ for a.e. $x$ , the function $x \mapsto \int f(x, y) d \nu(y)$ is in $L^{p}(\mu)$ , and $$ \left\|\int f(\cdot, y) d \nu(y)\right\|_{p} \leq \int\|f(\cdot, y)\|_{p} d \nu(y). $$ In the proof of (b), he said that Assertion (a) therefore follows from Theorem 6.14. When $p<\infty$ , (b) follows from (a) (with $f$ replaced by $|f|$ ) and Fubini's theorem; when $p=\infty$ , it is a simple consequence of the monotonicity of the integral. Could you please explain? Why do we need to use Fubini's theorem? I could not see the need of swapping differential operators here. How is the monotonicity of the integral used to obtain the result for $p = \infty$ here?","I'm reading Theorem 6.19 in textbook Real Analysis: Modern Techniques and Their Applications by Gerald B. Folland. Suppose that and are -finite measure spaces, and let be an -measurable function on . a. If and , then b. If for a.e. , and the function is in , then for a.e. , the function is in , and In the proof of (b), he said that Assertion (a) therefore follows from Theorem 6.14. When , (b) follows from (a) (with replaced by ) and Fubini's theorem; when , it is a simple consequence of the monotonicity of the integral. Could you please explain? Why do we need to use Fubini's theorem? I could not see the need of swapping differential operators here. How is the monotonicity of the integral used to obtain the result for here?","(X, \mathcal{M}, \mu) (Y, \mathcal{N}, \nu) \sigma f (\mathcal{M} \otimes \mathcal{N}) X \times Y f \geq 0 1 \leq p<\infty 
\left[\int\left(\int f(x, y) d \nu(y)\right)^{p} d \mu(x)\right]^{1 / p} \leq \int\left[\int f(x, y)^{p} d \mu(x)\right]^{1 / p} d \nu(y)
 1 \leq p \leq \infty, f(\cdot, y) \in L^{p}(\mu) y y \mapsto\|f(\cdot, y)\|_{p} L^{1}(\nu) f(x, \cdot) \in L^{1}(\nu) x x \mapsto \int f(x, y) d \nu(y) L^{p}(\mu) 
\left\|\int f(\cdot, y) d \nu(y)\right\|_{p} \leq \int\|f(\cdot, y)\|_{p} d \nu(y).
 p<\infty f |f| p=\infty p = \infty","['measure-theory', 'inequality', 'proof-explanation', 'fubini-tonelli-theorems']"
6,Additive but not $\sigma$-additive measure $\mathbb{Q} \cap I$,Additive but not -additive measure,\sigma \mathbb{Q} \cap I,"I read in an old book the following example of a measure: For the set $M=\mathbb{Q} \cap[0,1]$ denote with $S$ the set system of subsets of $M$ of the form $\mathbb{Q} \cap I$ , where $I$ is any interval in $[0,1]$ . Let us define the function $\mu: S \rightarrow \mathbb{R}$ as follows: for any set $A \in S$ of the form $A=\mathbb{Q} \cap I$ we set $\mu(A)=\ell(I)=b-a .$ Then it said without proof that $\mu$ is finitely additive, but not $\sigma$ -additive. As I did not get why I tried to prove it by myself and I tried to show that $S$ is a semi-ring, I guess that is important before I start with the other proof. We have $\emptyset \in \mathbb{Q}$ and furthermore $(\mathbb{Q} \cap I_1)\cap (\mathbb{Q} \cap I_2)=\mathbb{Q} \cap I_1 \cap I_2$ and the union of two closed intervals is either an interval or the disjoint union of two intervals. Then $(\mathbb{Q} \cap I_1)\setminus (\mathbb{Q} \cap I_2)$ is also an interval or the disjoint union of two intervals. Now the proof. I do not quite understand how it cannot be $\sigma$ -additive. Does it have something in common with Cantor sets? I don't know how to start the proof here. Any help or explanation (maybe an idea for the beginning of a proof) is appreciated. If there is a proof...","I read in an old book the following example of a measure: For the set denote with the set system of subsets of of the form , where is any interval in . Let us define the function as follows: for any set of the form we set Then it said without proof that is finitely additive, but not -additive. As I did not get why I tried to prove it by myself and I tried to show that is a semi-ring, I guess that is important before I start with the other proof. We have and furthermore and the union of two closed intervals is either an interval or the disjoint union of two intervals. Then is also an interval or the disjoint union of two intervals. Now the proof. I do not quite understand how it cannot be -additive. Does it have something in common with Cantor sets? I don't know how to start the proof here. Any help or explanation (maybe an idea for the beginning of a proof) is appreciated. If there is a proof...","M=\mathbb{Q} \cap[0,1] S M \mathbb{Q} \cap I I [0,1] \mu: S \rightarrow \mathbb{R} A \in S A=\mathbb{Q} \cap I \mu(A)=\ell(I)=b-a . \mu \sigma S \emptyset \in \mathbb{Q} (\mathbb{Q} \cap I_1)\cap (\mathbb{Q} \cap I_2)=\mathbb{Q} \cap I_1 \cap I_2 (\mathbb{Q} \cap I_1)\setminus (\mathbb{Q} \cap I_2) \sigma","['measure-theory', 'proof-writing']"
7,"If $f=g$ almost everywhere, then $\int_E f = \int_E g$.","If  almost everywhere, then .",f=g \int_E f = \int_E g,"One task in the book Analysis 2 by Tao is to prove the following Proposition 8.2.6: Let $(E,\mathcal{E},\mu)$ a measure space and $f,g \colon E \to [0,\infty]$ $\mathcal{E}$ -measurable functions on $E$ . If $f=g$ almost everywhere, then $\int_E f = \int_E g$ . My problem is not to prove the claim. For example let $A = \{f \neq g\} \in \mathcal{E}$ , then $f = \chi_A f + \chi_{A^c}f$ , $g = \chi_A g + \chi_{A^c}g$ and $\chi_{A^c}f = \chi_{A^c}g$ . So we have $\int_E f = \int_A f + \int_{A^c} f$ , when we know that interchanging sum and integral is possible. Then it's easy to show the rest. ( $\chi$ is indicator function) But the only properties I have available are: $\int_E f = \sup \left\{ \int_E g : g \text{ is simple, } 0 \leq g \leq f \right\}$ $f_E f = 0 \Leftrightarrow f=0$ almost everywhere $\int_E cf = c \int_E f$ , $c \in \mathbb{R}$ , $c \geq 0$ $f \leq g \Rightarrow \int_E f \leq \int_E g$","One task in the book Analysis 2 by Tao is to prove the following Proposition 8.2.6: Let a measure space and -measurable functions on . If almost everywhere, then . My problem is not to prove the claim. For example let , then , and . So we have , when we know that interchanging sum and integral is possible. Then it's easy to show the rest. ( is indicator function) But the only properties I have available are: almost everywhere , ,","(E,\mathcal{E},\mu) f,g \colon E \to [0,\infty] \mathcal{E} E f=g \int_E f = \int_E g A = \{f \neq g\} \in \mathcal{E} f = \chi_A f + \chi_{A^c}f g = \chi_A g + \chi_{A^c}g \chi_{A^c}f = \chi_{A^c}g \int_E f = \int_A f + \int_{A^c} f \chi \int_E f = \sup \left\{ \int_E g : g \text{ is simple, } 0 \leq g \leq f \right\} f_E f = 0 \Leftrightarrow f=0 \int_E cf = c \int_E f c \in \mathbb{R} c \geq 0 f \leq g \Rightarrow \int_E f \leq \int_E g","['real-analysis', 'measure-theory', 'lebesgue-integral', 'measurable-functions', 'almost-everywhere']"
8,"Show that $\lim_{n\to\infty}\int_0^1|f_n(x)-1|\,dx = 1$ if $\lVert f_n\rVert_{1} = 2$ and $\lim_{n\to\infty}f_n(x) = 1$",Show that  if  and,"\lim_{n\to\infty}\int_0^1|f_n(x)-1|\,dx = 1 \lVert f_n\rVert_{1} = 2 \lim_{n\to\infty}f_n(x) = 1","Suppose that $\{f_n\}_{n=1}^\infty$ , $f_{n}:[0,1]\to\mathbb{R}$ , is a sequence of measurable functions such that for every $x\in [0,1]$ $$\lim_{n\to\infty}f_n(x)=1$$ and for every $n$ : $$\int_{0}^{1}|f_{n}(x)|\,dx = 2.$$ Prove that $$\lim_{n\to\infty}\int_{0}^{1}|f_{n}(x) - 1|\,dx = 1$$ What I tried/have: Such a sequence is clearly possible since we can take $f_n = 1+n\chi_{(0,\frac{1} {n})}$ . The proposition is also trivial if $f_n\geq 1$ . I also managed to get, using the reverse triangle inequality that $$\liminf_n \int_0^1|f_n(x) - 1|\,dx\geq \liminf_n\int_0^1|f_n(x)|\,dx - 1 = 1$$ but I'm quite stuck on proving that the $\limsup$ is less than or equal to 1. Since it is not possible to find a dominating function (eg. consider the sequence I stated before) and there is no clear way to construct a monotone sequence, I feel like I need to use Fatou's Lemma somehow. Could someone please give me some tips on how I might show that the limit superior is at most $1$ ? Or maybe, if there is an easier approach, how I would directly compute the limit?","Suppose that , , is a sequence of measurable functions such that for every and for every : Prove that What I tried/have: Such a sequence is clearly possible since we can take . The proposition is also trivial if . I also managed to get, using the reverse triangle inequality that but I'm quite stuck on proving that the is less than or equal to 1. Since it is not possible to find a dominating function (eg. consider the sequence I stated before) and there is no clear way to construct a monotone sequence, I feel like I need to use Fatou's Lemma somehow. Could someone please give me some tips on how I might show that the limit superior is at most ? Or maybe, if there is an easier approach, how I would directly compute the limit?","\{f_n\}_{n=1}^\infty f_{n}:[0,1]\to\mathbb{R} x\in [0,1] \lim_{n\to\infty}f_n(x)=1 n \int_{0}^{1}|f_{n}(x)|\,dx = 2. \lim_{n\to\infty}\int_{0}^{1}|f_{n}(x) - 1|\,dx = 1 f_n = 1+n\chi_{(0,\frac{1} {n})} f_n\geq 1 \liminf_n \int_0^1|f_n(x) - 1|\,dx\geq \liminf_n\int_0^1|f_n(x)|\,dx - 1 = 1 \limsup 1","['measure-theory', 'convergence-divergence', 'lebesgue-integral']"
9,Finding the limit of the integral of some uniformly convergant sequence of functions,Finding the limit of the integral of some uniformly convergant sequence of functions,,"Let $\{f_n\}_{n\in \mathbb N}$ be a sequence of uniformly convergent functions on the interval [0,1]. Find the limit of the following integral: $$\lim_{n\to \infty} \int_0^1nf_n(t)e^{-nt}\,dt$$ Here is my thought process so far. In isolation l'hospital's rule would indicate that $\lim_{n\to \infty} \frac{n}{e^{nt}}$ would tend to zero, and so I expect that this exponential term will be more dominating. Normally Lebesgue's Dominated convergence theorem (or at the very least his monotone convergence theorem) would allow us to say that this uniformly convergent sequence of functions would converge to f...however I am guessing the surrounding terms sufficiently mess this up to the point where we no longer have convergence. My guess is the point of this question is to prove that this is the case. We know that $\lim_{n\to \infty}\{f_n\}_{n\in \mathbb N}$ is measurable, but If I can show that $g_n= \frac{n}{e^{nt}}$ is not measurable for $t\in[0,1]$ (because it tends to zero), then can I say this limit does not exist? I'm pretty confused, as is abundantly clear hahahaha.","Let be a sequence of uniformly convergent functions on the interval [0,1]. Find the limit of the following integral: Here is my thought process so far. In isolation l'hospital's rule would indicate that would tend to zero, and so I expect that this exponential term will be more dominating. Normally Lebesgue's Dominated convergence theorem (or at the very least his monotone convergence theorem) would allow us to say that this uniformly convergent sequence of functions would converge to f...however I am guessing the surrounding terms sufficiently mess this up to the point where we no longer have convergence. My guess is the point of this question is to prove that this is the case. We know that is measurable, but If I can show that is not measurable for (because it tends to zero), then can I say this limit does not exist? I'm pretty confused, as is abundantly clear hahahaha.","\{f_n\}_{n\in \mathbb N} \lim_{n\to \infty} \int_0^1nf_n(t)e^{-nt}\,dt \lim_{n\to \infty} \frac{n}{e^{nt}} \lim_{n\to \infty}\{f_n\}_{n\in \mathbb N} g_n= \frac{n}{e^{nt}} t\in[0,1]","['measure-theory', 'convergence-divergence', 'uniform-convergence', 'measurable-functions', 'sequence-of-function']"
10,"Decomposition of the variation of a signed measure as $|\mu|(A) = \int_A |\frac{d\mu_{1a}}{d\mu_2}-1|d\mu_2 + \mu_{1s}(A)$, where $\mu=\mu_1-\mu_2$","Decomposition of the variation of a signed measure as , where",|\mu|(A) = \int_A |\frac{d\mu_{1a}}{d\mu_2}-1|d\mu_2 + \mu_{1s}(A) \mu=\mu_1-\mu_2,"Let $\mu_1$ and $\mu_2$ be two finite measures on $(\Omega, \mathcal{F})$ . Let $\mu_1 = \mu_{1a}+\mu_{1s}$ be the Lebesgue decomposition of $\mu_1$ w.r.t. $\mu_2$ , that is, $\mu_{1a} \ll \mu_2$ and $\mu_{1s}\perp \mu_2$ . Let $\mu = \mu_1 - \mu_2$ . I'd like to show that for all $A\in \mathcal{F}$ , $$ |\mu|(A) = \int_A |h-1|d\mu_2 + \mu_{1s}(A) $$ where $h = \frac{d\mu_{1a}}{d\mu_2}$ is the Radon-Nikodym derivative of $\mu_{1a}$ w.r.t. $\mu_2$ . I know that we have the following decomposition: $$|\mu|=\mu_+ + \mu_- $$ Here, $\mu_+(A) = \mu(A \cap \Omega_+)$ and $\mu_-(A)=\mu_-(A \cap \Omega_-)$ , where $\Omega = \Omega_+ \cup \Omega_-$ is the Hahn decomposition of $\Omega$ w.r.t $\mu$ . Also, there exists a finite measure $\lambda$ such that $\mu_1 = \mu_+ + \lambda$ and $\mu_2 = \mu_-+\lambda$ with $\lambda = 0$ iff $\mu_1 \perp \mu_2$ . By the definition of Radon-Nikodym derivative, we have $\mu_{1a}(A) = \int_A h d\mu_2$ for all $A\in \mathcal{F}$ . I am unable to use these facts to prove the desired result. Any hint as to how I should proceed would be highly appreciated. Edit: This problem is exercise 4.13 from the book ""Measure theory and Probability Theory"" by Krishna B. Athreya and Soumendra N. Lahiri.","Let and be two finite measures on . Let be the Lebesgue decomposition of w.r.t. , that is, and . Let . I'd like to show that for all , where is the Radon-Nikodym derivative of w.r.t. . I know that we have the following decomposition: Here, and , where is the Hahn decomposition of w.r.t . Also, there exists a finite measure such that and with iff . By the definition of Radon-Nikodym derivative, we have for all . I am unable to use these facts to prove the desired result. Any hint as to how I should proceed would be highly appreciated. Edit: This problem is exercise 4.13 from the book ""Measure theory and Probability Theory"" by Krishna B. Athreya and Soumendra N. Lahiri.","\mu_1 \mu_2 (\Omega, \mathcal{F}) \mu_1 = \mu_{1a}+\mu_{1s} \mu_1 \mu_2 \mu_{1a} \ll \mu_2 \mu_{1s}\perp \mu_2 \mu = \mu_1 - \mu_2 A\in \mathcal{F}  |\mu|(A) = \int_A |h-1|d\mu_2 + \mu_{1s}(A)  h = \frac{d\mu_{1a}}{d\mu_2} \mu_{1a} \mu_2 |\mu|=\mu_+ + \mu_-  \mu_+(A) = \mu(A \cap \Omega_+) \mu_-(A)=\mu_-(A \cap \Omega_-) \Omega = \Omega_+ \cup \Omega_- \Omega \mu \lambda \mu_1 = \mu_+ + \lambda \mu_2 = \mu_-+\lambda \lambda = 0 \mu_1 \perp \mu_2 \mu_{1a}(A) = \int_A h d\mu_2 A\in \mathcal{F}","['real-analysis', 'measure-theory', 'radon-nikodym', 'signed-measures']"
11,How does $\sum_{i=1}^\infty \sum_{j=1}^\infty a_{ij} = \sum_{j=1}^\infty \sum_{i=1}^\infty a_{ij}$ follow from the monotone convergence theorem?,How does  follow from the monotone convergence theorem?,\sum_{i=1}^\infty \sum_{j=1}^\infty a_{ij} = \sum_{j=1}^\infty \sum_{i=1}^\infty a_{ij},"In Rudin's Real and Complex analysis, he says that the equality $$\sum_{i=1}^\infty \sum_{j=1}^\infty a_{ij} = \sum_{j=1}^\infty \sum_{i=1}^\infty a_{ij}$$ for $a_{i,j} \ge 0$ follows from this corollary of the monotone convergence theorem (via counting measure on a countable set): If $f_n: X \to [0, \infty]$ is measurable and $f = \sum f_n$ , then $$\int_X f =\sum_{n=1}^\infty \int_X fn $$ However, I'm having a hard time seeing this. I'm guessing you use indicator functions for each point in the countable set, but I don't see any obvious manipulations to make it true. Any help would be appreciated.","In Rudin's Real and Complex analysis, he says that the equality for follows from this corollary of the monotone convergence theorem (via counting measure on a countable set): If is measurable and , then However, I'm having a hard time seeing this. I'm guessing you use indicator functions for each point in the countable set, but I don't see any obvious manipulations to make it true. Any help would be appreciated.","\sum_{i=1}^\infty \sum_{j=1}^\infty a_{ij} = \sum_{j=1}^\infty \sum_{i=1}^\infty a_{ij} a_{i,j} \ge 0 f_n: X \to [0, \infty] f = \sum f_n \int_X f =\sum_{n=1}^\infty \int_X fn ","['real-analysis', 'measure-theory']"
12,Evaluate $\lim_{k \to \infty} \int_0^1 \frac{(1-x)^k \cos(k/x)}{\sqrt{x}}dx$,Evaluate,\lim_{k \to \infty} \int_0^1 \frac{(1-x)^k \cos(k/x)}{\sqrt{x}}dx,"I want to evaluate $$\lim_{k \to \infty} \int_{(0,1)}\frac{(1-x)^k \cos(k/x)}{\sqrt{x}}dx$$ where the integral is Lebesgue-integral. Attempt: Note first that for $x \in (0,1)$ , we have $\lim_k \frac{(1-x)^k \cos(k/x)}{\sqrt{x}} = 0$ . Also, $$\left|\frac{(1-x)^k \cos(k/x)}{\sqrt{x}}\right| \leq 1/\sqrt{x}$$ and by monotone convergence theorem $$\int_{(0,1)}1/\sqrt{x}dx = \lim_n \int_{(1/n,1)} x^{-1/2}dx = \lim_n (2-2\sqrt{1/n})=2$$ so the dominated convergence theorem allows us to interchange integral and limit and we conclude that $$\lim_{k \to \infty} \int_{(0,1)}\frac{(1-x)^k \cos(k/x)}{\sqrt{x}}dx = \int_{(0,1)}0 dx = 0$$ Is this correct?","I want to evaluate where the integral is Lebesgue-integral. Attempt: Note first that for , we have . Also, and by monotone convergence theorem so the dominated convergence theorem allows us to interchange integral and limit and we conclude that Is this correct?","\lim_{k \to \infty} \int_{(0,1)}\frac{(1-x)^k \cos(k/x)}{\sqrt{x}}dx x \in (0,1) \lim_k \frac{(1-x)^k \cos(k/x)}{\sqrt{x}} = 0 \left|\frac{(1-x)^k \cos(k/x)}{\sqrt{x}}\right| \leq 1/\sqrt{x} \int_{(0,1)}1/\sqrt{x}dx = \lim_n \int_{(1/n,1)} x^{-1/2}dx = \lim_n (2-2\sqrt{1/n})=2 \lim_{k \to \infty} \int_{(0,1)}\frac{(1-x)^k \cos(k/x)}{\sqrt{x}}dx = \int_{(0,1)}0 dx = 0","['real-analysis', 'calculus']"
13,If $f$ is Lebesgue integrable on an open set $U$ is it integrable over the surface of a submanifold contained in $U$?,If  is Lebesgue integrable on an open set  is it integrable over the surface of a submanifold contained in ?,f U U,"Let $d\in\mathbb N$ , $U\subseteq\mathbb R^d$ be open and $M\subseteq U$ be a $k$ -dimensional embedded $C^1$ -submanifold of $\mathbb R^d$ Let $f\in\mathcal L^1(U)$ and $\sigma_M$ denote the surface measure on $\mathcal B(M)$ . Are we able to show that $\left.f\right|_M\in\mathcal L^1(\sigma_M)$ ? Let $\lambda$ denote the Lebesgue measure on $\mathcal B(\mathbb R)$ . Maybe we can show $$\sigma_M(B)\le\lambda^{\otimes d}(B)\;\;\;\text{for all }B\in\mathcal B(M)\tag1$$ and use this to conclude the desired claim. In this regard, we may note that, trivially, $U$ is a $d$ -dimensional embedded $C^1$ -submanifold of $\mathbb R^d$ and $$\sigma_U=\left.\lambda^{\otimes d}\right|_U\tag2.$$ Remark : It might be useful to note that there is the following characterization of the surface measure: $\sigma_M$ is the unique measure on $\mathcal B(M)$ with $$\left.\sigma_M\right|_\Omega=\sigma_\Omega\tag3$$ for every open subset (in the subspace topology) $\Omega$ of $M$ .","Let , be open and be a -dimensional embedded -submanifold of Let and denote the surface measure on . Are we able to show that ? Let denote the Lebesgue measure on . Maybe we can show and use this to conclude the desired claim. In this regard, we may note that, trivially, is a -dimensional embedded -submanifold of and Remark : It might be useful to note that there is the following characterization of the surface measure: is the unique measure on with for every open subset (in the subspace topology) of .",d\in\mathbb N U\subseteq\mathbb R^d M\subseteq U k C^1 \mathbb R^d f\in\mathcal L^1(U) \sigma_M \mathcal B(M) \left.f\right|_M\in\mathcal L^1(\sigma_M) \lambda \mathcal B(\mathbb R) \sigma_M(B)\le\lambda^{\otimes d}(B)\;\;\;\text{for all }B\in\mathcal B(M)\tag1 U d C^1 \mathbb R^d \sigma_U=\left.\lambda^{\otimes d}\right|_U\tag2. \sigma_M \mathcal B(M) \left.\sigma_M\right|_\Omega=\sigma_\Omega\tag3 \Omega M,"['measure-theory', 'differential-geometry', 'differential-topology', 'smooth-manifolds', 'surface-integrals']"
14,Does $\int_1^\infty\frac{f_ng_n}{f_n^2+g_n}dx$ go to $0$ under these conditions of $f_n$ and $g_n$,Does  go to  under these conditions of  and,\int_1^\infty\frac{f_ng_n}{f_n^2+g_n}dx 0 f_n g_n,"Question: Let $f_n,g_n:[1,\infty)\rightarrow (0,\infty)$ be two sequences of measurable functions such that $|g_n(x)|\leq\frac{1}{x^3} \forall x\geq1$ and $f_n\rightarrow 0$ pointwise almost everywhere.  Is it always true that $\int_1^\infty\frac{f_ng_n}{f_n^2+g_n}dx\rightarrow0$ ? My thoughts: I was thinking that some sort of dominated convergence theorem will need to be used here since $|g_n(x)|$ is bounded by an integrable function $\frac{1}{x^3} \forall x\geq1$ .  The pointwise a.e. convergence of $f_n$ to $0$ seems like it would be easy to play with, but I'm just not sure how to deal with these functions as they are in the integrand.  Any help, suggestions, etc. are appreciated!  Thank you!","Question: Let be two sequences of measurable functions such that and pointwise almost everywhere.  Is it always true that ? My thoughts: I was thinking that some sort of dominated convergence theorem will need to be used here since is bounded by an integrable function .  The pointwise a.e. convergence of to seems like it would be easy to play with, but I'm just not sure how to deal with these functions as they are in the integrand.  Any help, suggestions, etc. are appreciated!  Thank you!","f_n,g_n:[1,\infty)\rightarrow (0,\infty) |g_n(x)|\leq\frac{1}{x^3} \forall x\geq1 f_n\rightarrow 0 \int_1^\infty\frac{f_ng_n}{f_n^2+g_n}dx\rightarrow0 |g_n(x)| \frac{1}{x^3} \forall x\geq1 f_n 0","['real-analysis', 'measure-theory', 'measurable-functions']"
15,"Will the set of algebraic polynomials be dense in space $L_{\infty}(0,1)$?",Will the set of algebraic polynomials be dense in space ?,"L_{\infty}(0,1)","I know that the set of algebraic polynomials is dense in space $L_{p}(a,b)$ , where $1 \leq p < \infty$ and $a,b \in \mathbb{R}$ . However, what about $L_{\infty}(0,1)$ ? Will the set of algebraic polynomials be dense in space $L_{\infty}(0,1)$ ? In my opinion it is not, but is there any example that prove this fact?","I know that the set of algebraic polynomials is dense in space , where and . However, what about ? Will the set of algebraic polynomials be dense in space ? In my opinion it is not, but is there any example that prove this fact?","L_{p}(a,b) 1 \leq p < \infty a,b \in \mathbb{R} L_{\infty}(0,1) L_{\infty}(0,1)","['real-analysis', 'measure-theory']"
16,Measure without sets of measure zero,Measure without sets of measure zero,,"Let $(X,\Sigma,\mu)$ be a finite $\sigma$ -additive measure space such that $$ E\in\Sigma,\quad\mu(E)=0\implies E=\varnothing $$ Is it true that $(X,\Sigma,\mu)$ is purely atomic? You may assume that $\mu$ is complete. I think I know how to prove this via Maharam theorem, but that looks like an overkill. I wonder if there is a simpler proof or maybe my guess is even wrong?","Let be a finite -additive measure space such that Is it true that is purely atomic? You may assume that is complete. I think I know how to prove this via Maharam theorem, but that looks like an overkill. I wonder if there is a simpler proof or maybe my guess is even wrong?","(X,\Sigma,\mu) \sigma 
E\in\Sigma,\quad\mu(E)=0\implies E=\varnothing
 (X,\Sigma,\mu) \mu",['measure-theory']
17,What is wrong with my proof of Vitali convergence theorem?,What is wrong with my proof of Vitali convergence theorem?,,"Below statement is in The Elements of Integration and Lebesgue Measure, BARTLE, 76p. Vitali Convergence Theorem. Let $\left\{ f_{n} \right\}$ ba a sequence in $\mathcal{L}_{p} ( X , \Sigma , \mu)$ and $1 \in [1, \infty)$ . Then the following three conditions are necessary and sufficient for the $\mathcal{L}_{p}$ convergence of $\left\{ f_{n} \right\}$ to $f$ : (i) $\left\{ f_{n} \right\}$ converges to $f$ in measure (ii) For each $\varepsilon > 0$ there is a set $E_{\varepsilon} \in \Sigma$ with $\mu(E_{\varepsilon}) < \infty$ such that if $F \in \Sigma$ and $F \cap E_{\varepsilon} = \emptyset$ , then $$\int_{F} |f_{n}|^{p} d \mu < \varepsilon^{p} \qquad \forall n \in \mathbb{N}$$ (iii) For each $\varepsilon > 0$ there is a $\delta(\varepsilon) > 0$ , such that if $E \in \Sigma$ and $\mu(E) < \delta(\varepsilon)$ , then $$\int_{E} |f_{n}|^{p} d \mu < \varepsilon^{p} \qquad \forall n \in \mathbb{N}$$ Textbook says that the fact that $\mathcal{L}_{p}$ convergence of the $\left\{ f_{n} \right\}$ implies (ii) and (iii) is not difficult and is left to reader. I seconded it in first glance, but i can't prove it at all. These are proved nowhere, just left 'easy' or 'trivial'. I wasted so much time to prove these. Please tell me what is wrong. Proof $(\Rightarrow)$ (ii). It's sufficient to prove that a case $F = E_{\varepsilon}^{c}$ . Take $E_{\varepsilon}:=\left\{ x \in X : | f_{n} (x) | \ge \varepsilon \right\}$ then $$\int_{E_{\varepsilon}^{c}} |f_{n}|^{p} d \mu < \int_{E_{\varepsilon}^{c}} \varepsilon^{p} d \mu = \varepsilon^{p} \mu (E_{\varepsilon}^{c}) $$ Proof $(\Rightarrow)$ (iii). For each $\varepsilon>0$ , take $E:=\left\{x \in X : |f_{n}(x)|^{p} < \varepsilon^{p-1} \right\}$ and $\delta(\varepsilon) := \varepsilon$ . If $E \in \Sigma$ and $\mu(E) < \delta(\varepsilon)$ , then $$\int_{E} |f_{n}|^{p} d \mu < \int_{E} \varepsilon^{p-1} d \mu = \varepsilon^{p-1} \mu(E) < \varepsilon^{p-1} \varepsilon = \varepsilon^{p} $$ for all $n \in \mathbb{N}$ . Questions (ii) We can't normalize just by putting $E_{\varepsilon} = \left\{ x \in X : | f_{n} (x) | \ge \varepsilon / \mu (E_{\varepsilon}^{c})^{1/p} \right\}$ , right? And there is no guarantee for $\mu (E_{\varepsilon}) < \infty$ . I approached $$\mu (E_{\varepsilon}) = \int_{E_{\varepsilon}} d \mu  = \int_{E_{\varepsilon} \cap ( 1 \le |f_{n}|) } d \mu + \int_{E_{\varepsilon} \cap ( 1 > |f_{n}|) } d \mu$$ then the first term can be finite since $f_{n} \in \mathcal{L}_{p}$ but second term  is not. I gave up. (iii) I didn't mention any hypothesis. What i missed? I have no idea how use the condition convergence in $\mathcal{L}_{p}$ .","Below statement is in The Elements of Integration and Lebesgue Measure, BARTLE, 76p. Vitali Convergence Theorem. Let ba a sequence in and . Then the following three conditions are necessary and sufficient for the convergence of to : (i) converges to in measure (ii) For each there is a set with such that if and , then (iii) For each there is a , such that if and , then Textbook says that the fact that convergence of the implies (ii) and (iii) is not difficult and is left to reader. I seconded it in first glance, but i can't prove it at all. These are proved nowhere, just left 'easy' or 'trivial'. I wasted so much time to prove these. Please tell me what is wrong. Proof (ii). It's sufficient to prove that a case . Take then Proof (iii). For each , take and . If and , then for all . Questions (ii) We can't normalize just by putting , right? And there is no guarantee for . I approached then the first term can be finite since but second term  is not. I gave up. (iii) I didn't mention any hypothesis. What i missed? I have no idea how use the condition convergence in .","\left\{ f_{n} \right\} \mathcal{L}_{p} ( X , \Sigma , \mu) 1 \in [1, \infty) \mathcal{L}_{p} \left\{ f_{n} \right\} f \left\{ f_{n} \right\} f \varepsilon > 0 E_{\varepsilon} \in \Sigma \mu(E_{\varepsilon}) < \infty F \in \Sigma F \cap E_{\varepsilon} = \emptyset \int_{F} |f_{n}|^{p} d \mu < \varepsilon^{p} \qquad \forall n \in \mathbb{N} \varepsilon > 0 \delta(\varepsilon) > 0 E \in \Sigma \mu(E) < \delta(\varepsilon) \int_{E} |f_{n}|^{p} d \mu < \varepsilon^{p} \qquad \forall n \in \mathbb{N} \mathcal{L}_{p} \left\{ f_{n} \right\} (\Rightarrow) F = E_{\varepsilon}^{c} E_{\varepsilon}:=\left\{ x \in X : | f_{n} (x) | \ge \varepsilon \right\} \int_{E_{\varepsilon}^{c}} |f_{n}|^{p} d \mu < \int_{E_{\varepsilon}^{c}} \varepsilon^{p} d \mu = \varepsilon^{p} \mu (E_{\varepsilon}^{c})  (\Rightarrow) \varepsilon>0 E:=\left\{x \in X : |f_{n}(x)|^{p} < \varepsilon^{p-1} \right\} \delta(\varepsilon) := \varepsilon E \in \Sigma \mu(E) < \delta(\varepsilon) \int_{E} |f_{n}|^{p} d \mu < \int_{E} \varepsilon^{p-1} d \mu = \varepsilon^{p-1} \mu(E) < \varepsilon^{p-1} \varepsilon = \varepsilon^{p}  n \in \mathbb{N} E_{\varepsilon} = \left\{ x \in X : | f_{n} (x) | \ge \varepsilon / \mu (E_{\varepsilon}^{c})^{1/p} \right\} \mu (E_{\varepsilon}) < \infty \mu (E_{\varepsilon}) = \int_{E_{\varepsilon}} d \mu  = \int_{E_{\varepsilon} \cap ( 1 \le |f_{n}|) } d \mu + \int_{E_{\varepsilon} \cap ( 1 > |f_{n}|) } d \mu f_{n} \in \mathcal{L}_{p} \mathcal{L}_{p}","['real-analysis', 'measure-theory', 'convergence-divergence']"
18,Difference between a Dynkin System and Sigma algebra,Difference between a Dynkin System and Sigma algebra,,"I am currently studying measure theory but there is one thing I simply cannot understand: The definitions of sigma algebras and dynkin systems are very much alike. However, they differ on the third property: Image 1 Image 2 So for a Dynkin system, the sets have to be pairwise disjoint to keep the third property correct, whereas for a sigma algebra this is not the case. However, a dynkin system is said to be a ""weaker form"" of a sigma algebra. How can this be if they are similar, but for a dynkin system the sets have to be pairwise disjoint and for a sigma algebra this doesn't matter? I can't just understand this, to me it seems like the pairwise disjoint is just an extra property it has to fulfill. What am I missing here? Thanks in advance!","I am currently studying measure theory but there is one thing I simply cannot understand: The definitions of sigma algebras and dynkin systems are very much alike. However, they differ on the third property: Image 1 Image 2 So for a Dynkin system, the sets have to be pairwise disjoint to keep the third property correct, whereas for a sigma algebra this is not the case. However, a dynkin system is said to be a ""weaker form"" of a sigma algebra. How can this be if they are similar, but for a dynkin system the sets have to be pairwise disjoint and for a sigma algebra this doesn't matter? I can't just understand this, to me it seems like the pairwise disjoint is just an extra property it has to fulfill. What am I missing here? Thanks in advance!",,['measure-theory']
19,"I want to study about F sigma and G delta sets,Can someone suggest a book for learning them?","I want to study about F sigma and G delta sets,Can someone suggest a book for learning them?",,I am an undergraduate student of mathematics and I know nothing about F sigma and G delta sets.I want to learn and understand these concepts along with their applications.Can anyone suggest me a good book that would be helpful for me?,I am an undergraduate student of mathematics and I know nothing about F sigma and G delta sets.I want to learn and understand these concepts along with their applications.Can anyone suggest me a good book that would be helpful for me?,,"['real-analysis', 'measure-theory']"
20,Why dont we only consider complete measure spaces?,Why dont we only consider complete measure spaces?,,"This question has been asked a few months ago , but in my opinion, it has not yet received a satisfying answer. So I ask again: Why should one consider non-complete measure spaces instead of requiring every measure space to be complete per definition? Most answers on similar questions are like: If $f$ is a measurable function, one wants its codomain to contain fewer measurable sets, so that one finds more measurable functions beside $f$ . Lebesgue-Lebesgue-measurable functions are pretty useless because not even continous functions have to be L-L-measurable (but diffeomorphisms are). If $\Omega$ is a probability space and $X:\Omega \to \mathbb{R}$ a random variable (where $\mathbb{R}$ is endowed with any $\sigma$ -Algebra), its distribution (pushforward measure) isnt necessarily a complete measure. But I see a mistake in those thoughts. The category of measurable spaces (set + $\sigma$ -Algebra) is confused with the category of measure spaces (set + $\sigma$ -Algebra + measure). Of course, Lebesgue-Borel-measurable functions are important, because they are the subject of separably-valued integration (on $\mathbb{R}^n$ ). But for a Bochner-measurable function (a.e. pointwise limit of simple functions) that one wants to integrate, it is irrelevant if there is a measure on its codomain. The $L_1$ -functor goes $$ L_1 : \mathsf{MeasureSpaces} \times \mathsf{BanachSpaces} \to \mathsf{BanachSpaces} \ ,\ (X,A,\mu) , E \mapsto L_1(X,\mu,E)$$ so it may be wrong to think of any sigma-Algebra on the codomain of an integrable function. Also, if $(X,A,\mu)$ is a measure space and $(X,\bar A,\bar \mu)$ is its canonical completion, a function $f:X \to E$ into a Banach space $E$ is Bochner-measurable with respect to $\mu$ , if and only if it is Bochner-measurable with respect to $\bar \mu$ . So, for Bochner integration theory, non-complete measure spaces are completely redundant. And concerning the distribution argument: If one has a random variable $X : \Omega \to \mathbb{R}$ , I see no reason to postulate a $\sigma$ -Algebra on $\mathbb{R}$ and the measurablitiy of $X$ . I think it to be more natural to view $\mathbb{R}$ as simply a set and consider every subset of $\mathbb{R}$ to be measurable, whose preimage is measurable. This yields a $\sigma$ -Algebra, bears no needless abandonment of per se measure-accessible subsets and if $\Omega$ is complete, the pushforward measure will be too.","This question has been asked a few months ago , but in my opinion, it has not yet received a satisfying answer. So I ask again: Why should one consider non-complete measure spaces instead of requiring every measure space to be complete per definition? Most answers on similar questions are like: If is a measurable function, one wants its codomain to contain fewer measurable sets, so that one finds more measurable functions beside . Lebesgue-Lebesgue-measurable functions are pretty useless because not even continous functions have to be L-L-measurable (but diffeomorphisms are). If is a probability space and a random variable (where is endowed with any -Algebra), its distribution (pushforward measure) isnt necessarily a complete measure. But I see a mistake in those thoughts. The category of measurable spaces (set + -Algebra) is confused with the category of measure spaces (set + -Algebra + measure). Of course, Lebesgue-Borel-measurable functions are important, because they are the subject of separably-valued integration (on ). But for a Bochner-measurable function (a.e. pointwise limit of simple functions) that one wants to integrate, it is irrelevant if there is a measure on its codomain. The -functor goes so it may be wrong to think of any sigma-Algebra on the codomain of an integrable function. Also, if is a measure space and is its canonical completion, a function into a Banach space is Bochner-measurable with respect to , if and only if it is Bochner-measurable with respect to . So, for Bochner integration theory, non-complete measure spaces are completely redundant. And concerning the distribution argument: If one has a random variable , I see no reason to postulate a -Algebra on and the measurablitiy of . I think it to be more natural to view as simply a set and consider every subset of to be measurable, whose preimage is measurable. This yields a -Algebra, bears no needless abandonment of per se measure-accessible subsets and if is complete, the pushforward measure will be too.","f f \Omega X:\Omega \to \mathbb{R} \mathbb{R} \sigma \sigma \sigma \mathbb{R}^n L_1  L_1 : \mathsf{MeasureSpaces} \times \mathsf{BanachSpaces} \to \mathsf{BanachSpaces} \ ,\ (X,A,\mu) , E \mapsto L_1(X,\mu,E) (X,A,\mu) (X,\bar A,\bar \mu) f:X \to E E \mu \bar \mu X : \Omega \to \mathbb{R} \sigma \mathbb{R} X \mathbb{R} \mathbb{R} \sigma \Omega","['measure-theory', 'random-variables', 'lebesgue-integral']"
21,Every quasi-invariant measures is in an invariant measure class (Zimmer),Every quasi-invariant measures is in an invariant measure class (Zimmer),,"I'm reading ""Ergodic Theory and Semisimple Groups"" by Zimmer and at the very beginning of Chapter $2$ (pp. $8$ ) the author claims that An action with quasi-invariant measure can be thought of as an action with an invariant measure class. I interpreted this vague statement in  the following way: Every quasi-invariant measure is in the same measure class with an invariant measure. Question1: is this statement true? I don't see how to prove this fact. Question2: If question1 has a negative answer, how should such a statement be understood? Here the author assumes the group $G$ be locally compact second countable, the action on a standard Borel space $S$ (i.e. Borel isomorphic to a Borel subset of a Polish space) be Borel (i.e. measurable). Moreover, a $\sigma$ -finite measure $\mu$ is said to be quasi-invariant under the action of $G$ iff for all $A\subseteq S$ , $g\in G$ we have $\mu(Ag)=0\iff\mu(A)=0$ . It is invariant iff $\mu(Ag)=\mu(A)$ for all $A$ , $g$ . Finally, two measures are said to be in the same measure class iff they have the same null sets. About my background: I have attended a basic measure theory course mostly focused on the real case. Whenever possible, a good reference that covers these topics is appreciated. Thank you in advance for your help.","I'm reading ""Ergodic Theory and Semisimple Groups"" by Zimmer and at the very beginning of Chapter (pp. ) the author claims that An action with quasi-invariant measure can be thought of as an action with an invariant measure class. I interpreted this vague statement in  the following way: Every quasi-invariant measure is in the same measure class with an invariant measure. Question1: is this statement true? I don't see how to prove this fact. Question2: If question1 has a negative answer, how should such a statement be understood? Here the author assumes the group be locally compact second countable, the action on a standard Borel space (i.e. Borel isomorphic to a Borel subset of a Polish space) be Borel (i.e. measurable). Moreover, a -finite measure is said to be quasi-invariant under the action of iff for all , we have . It is invariant iff for all , . Finally, two measures are said to be in the same measure class iff they have the same null sets. About my background: I have attended a basic measure theory course mostly focused on the real case. Whenever possible, a good reference that covers these topics is appreciated. Thank you in advance for your help.",2 8 G S \sigma \mu G A\subseteq S g\in G \mu(Ag)=0\iff\mu(A)=0 \mu(Ag)=\mu(A) A g,"['measure-theory', 'topological-groups', 'ergodic-theory', 'polish-spaces']"
22,Proof of $f\in L^1(\mathbb R)$ then $m\{x\mid |f|=\infty \}=0$. Is my proof correct.,Proof of  then . Is my proof correct.,f\in L^1(\mathbb R) m\{x\mid |f|=\infty \}=0,"Let $f\in L^1(\mathbb R)$ . Then $f$ is finite a.e. I did the following proof and my teacher gave me a mark of $0$ . What I did is : Let $E=\{x\mid |f(x)|=\infty \}$ . We have that $$ \int_E|f|\leq \int_{\mathbb R}|f|$$ If $m(E)>0$ then $$\int_E|f|=\infty \cdot m(E)=\infty,$$ and thus $\int_{\mathbb R}|f|=\infty $ which is a contradiction. He says that $a\cdot \infty =\infty $ for $a>0$ is more a convention than something formal. After he justify that if my proof is valid, then someone could make the proof $$\infty \cdot m(E)=\int_E|f|\leq \int_{\mathbb R}|f|<\infty ,$$ and thus $m(E)=0$ . Which is not completely wrong, but with rigor $\infty \cdot 0$ is undeterminated. So he didn't accepted my proof. I'm a bit confuse because for me it's a complete valid proof. What do you think ?","Let . Then is finite a.e. I did the following proof and my teacher gave me a mark of . What I did is : Let . We have that If then and thus which is a contradiction. He says that for is more a convention than something formal. After he justify that if my proof is valid, then someone could make the proof and thus . Which is not completely wrong, but with rigor is undeterminated. So he didn't accepted my proof. I'm a bit confuse because for me it's a complete valid proof. What do you think ?","f\in L^1(\mathbb R) f 0 E=\{x\mid |f(x)|=\infty \}  \int_E|f|\leq \int_{\mathbb R}|f| m(E)>0 \int_E|f|=\infty \cdot m(E)=\infty, \int_{\mathbb R}|f|=\infty  a\cdot \infty =\infty  a>0 \infty \cdot m(E)=\int_E|f|\leq \int_{\mathbb R}|f|<\infty , m(E)=0 \infty \cdot 0","['measure-theory', 'lebesgue-integral']"
23,Ergodic transformation on a atomless measure space,Ergodic transformation on a atomless measure space,,"I am currently reading Kakutani–Rokhlin lemma and faced a problem which is given below :--- Let $(X,\mathscr B,\mu,T)$ be an invertible measure preserving system such that $\mu(\{x\})=0,\forall x\in X$ . Suppose $T$ is ergodic we have to show, $$\mu\bigg(\bigcup_{k\in \Bbb Z,k\not=0}\{x\in X:T^k(x)=x\}\bigg)=0.$$ I don't how do I start with this problem. Any help will be appreciated.","I am currently reading Kakutani–Rokhlin lemma and faced a problem which is given below :--- Let be an invertible measure preserving system such that . Suppose is ergodic we have to show, I don't how do I start with this problem. Any help will be appreciated.","(X,\mathscr B,\mu,T) \mu(\{x\})=0,\forall x\in X T \mu\bigg(\bigcup_{k\in \Bbb Z,k\not=0}\{x\in X:T^k(x)=x\}\bigg)=0.","['measure-theory', 'ergodic-theory']"
24,When does Riemann-Lebesgue lemma hold in general?,When does Riemann-Lebesgue lemma hold in general?,,"Let's say for simplicity that I'm on the torus $\mathbb{T}=\mathbb{R}/\mathbb{Z}$ . In this setting, Riemann-Lebesgue lemma could be stated as: for any $f\in L^1(\mathbb{T})$ , $$ \lim_{\vert k\vert\to\infty}\int_\mathbb{T} f(x)e^{ikx}\, dx =0$$ which can be interpreted as: for any $f\in L^1(\mathbb{T})$ , $\widehat{f}\in c_0$ , where $\widehat{\cdot}$ denotes the discrete Fourier transform and $c_0$ the space of infinitesimal sequences. If I considered a Radon measure $\mu$ on $\mathbb{T}$ instead of $f$ , then it's easy to check that $\widehat{\mu}\in l^\infty$ and Riemann-Lebesgue lemma fails, take $\mu=\delta_x$ . The case $d\mu = f\,dx$ with $f\in L^1$ corresponds to measures which are absolutely continuous w.r.t. the Lebesgue measure. However the same technique of proof for $f\in L^1$ , i.e. showing the statement for smooth functions and then exploiting a density argument, shows that Riemann-Lebesgue lemma holds for any $\mu$ belonging to the closure of smooth functions in the total variation norm $\Vert\cdot\Vert_{TV}$ . So my question is: what is this space? Is it just the space of all absolutely continuous measures or it contains other objects (like the derivative of the Cantor function)? Does it have a proper characterization?","Let's say for simplicity that I'm on the torus . In this setting, Riemann-Lebesgue lemma could be stated as: for any , which can be interpreted as: for any , , where denotes the discrete Fourier transform and the space of infinitesimal sequences. If I considered a Radon measure on instead of , then it's easy to check that and Riemann-Lebesgue lemma fails, take . The case with corresponds to measures which are absolutely continuous w.r.t. the Lebesgue measure. However the same technique of proof for , i.e. showing the statement for smooth functions and then exploiting a density argument, shows that Riemann-Lebesgue lemma holds for any belonging to the closure of smooth functions in the total variation norm . So my question is: what is this space? Is it just the space of all absolutely continuous measures or it contains other objects (like the derivative of the Cantor function)? Does it have a proper characterization?","\mathbb{T}=\mathbb{R}/\mathbb{Z} f\in L^1(\mathbb{T})  \lim_{\vert k\vert\to\infty}\int_\mathbb{T} f(x)e^{ikx}\, dx =0 f\in L^1(\mathbb{T}) \widehat{f}\in c_0 \widehat{\cdot} c_0 \mu \mathbb{T} f \widehat{\mu}\in l^\infty \mu=\delta_x d\mu = f\,dx f\in L^1 f\in L^1 \mu \Vert\cdot\Vert_{TV}","['measure-theory', 'fourier-analysis', 'fourier-series', 'bounded-variation']"
25,The application $\mu^*$ is an outer measure. A proof without the Fubin's Theorem.,The application  is an outer measure. A proof without the Fubin's Theorem.,\mu^*,"Theorem. Let $\mathcal{K}\subseteq 2^{X}$ a set family such that $\emptyset \in\mathcal{K}$ and be given an application $\nu\colon\mathcal{K}\to[0,+\infty]$ such that $\nu(\emptyset)=0$ , we define $$\mu^*(E)=\inf\left\{\sum_{n\in\mathbb{N}}\nu(I_n)\;\middle|\;E\subseteq\bigcup_{n\in\mathbb{N}}I_n\;\text{and}\;\{I_n\}_{n\in\mathbb{N}}\subseteq\mathcal{K}\right\},$$ then $\mu^*$ is an outer measure. Proof. (With Fubini's Theorem ) We prove that $\mu^*$ is $\sigma$ -subadditive, the other properties are trivial. Let $\{E_n\}_{n\in\mathbb{N}}\subseteq 2^{X}$ a countable set family. We suppose that $\mu^*(E_n)<+\infty$ for all $n\in\mathbb{N}$ , that is for all $n\in\mathbb{N}$ exists $\{I_{n,k}\}_{k\in\mathbb{N}}\subseteq \mathcal{K}$ such that $E_n\subseteq\bigcup_{k\in\mathbb{N}}I_{n,k}$ . Be fixed $\varepsilon> 0$ . For what has been said above and for the properties of the infimum, for all $n\in\mathbb{N}$ exists $\{I_{n,k}\}\subseteq\mathcal{K}$ such that $$E_n\subseteq\bigcup_{k\in\mathbb{N}}I_{n,k}\quad\text{and}\quad\mu^*(E_n)+\frac{\varepsilon}{2^n}>\sum_{k\in\mathbb{N}}\nu(I_{n,k}).$$ We observe that $$\bigcup_{n\in\mathbb{N}}E_n\subseteq\bigcup_{n\in\mathbb{N}}\bigcup_{k\in\mathbb{N}}I_{n,k}=\bigcup_{(n,k)\in\mathbb{N}\times\mathbb{N}}I_{n,k}\quad\text{and}\quad\{I_{n,k}\}_{n,k\in\mathbb{N}}\subseteq\mathcal{K}.$$ At this point, in order to apply the definition of $\mu^*$ , it is necessary to specify that it is equivalent to $$\mu^*(E)=\inf\left\{\sum_{(n,k)\in\mathbb{N}\times\mathbb{N}}\nu(I_{n,k})\;\middle|\;E\subseteq\bigcup_{(n,k)\in\mathbb{N}\times\mathbb{N}}I_{n,k}\;\text{and}\;\{I_{n,k}\}_{(n,k)\in\mathbb{N}\times\mathbb{N}}\subseteq\mathcal{K}\right\}.$$ In general, what is important is that the set $E$ can be covered by a family $\{I_\gamma\}_{\gamma\in\Gamma}\subseteq\mathcal{K}$ , where $\Gamma$ is a countable set of indices. By definition of $\mu^*$ we have \begin{equation} \mu^*\bigg(\bigcup_{n\in\mathbb{N}}E_n\bigg)\le\sum_{(n,k)\in\mathbb{N}\times\mathbb{N}}\nu(I_{n,k})\color{BLUE}{=}\sum_{n\in\mathbb{N}}\sum_{k\in\mathbb{N}}\nu(I_{n,k})<\sum_{n\in\mathbb{N}}\bigg[\nu(I_{n,k})+\frac{\varepsilon}{2^n}\bigg]=\sum_{n\in\mathbb{N}}\mu^*(E_n)+\varepsilon, \end{equation} where the blue equal is the Fubini's Theorem. $\hspace{9cm}\square$ Proof. (Without Fubini's Theorem ) Let $\{E_n\}_{n\in\mathbb{N}}\subseteq 2^{X}$ a countable set family. We suppose that $\mu^*(E_n)<+\infty$ for all $n\in\mathbb{N}$ , that is for all $n\in\mathbb{N}$ exists $\{I_{nk}\}_{k\in\mathbb{N}}\subseteq \mathcal{K}$ such that $E_n\subseteq\bigcup_{k\in\mathbb{N}}I_{nk}$ . Be fixed $\varepsilon> 0$ . For what has been said above and for the properties of the infimum, for all $n\in\mathbb{N}$ exists $\{I_{nk}\}\subseteq\mathcal{K}$ such that $$E_n\subseteq\bigcup_{k\in\mathbb{N}}I_{nk}\quad\text{and}\quad\mu^*(E_n)+\frac{\varepsilon}{2^n}>\sum_{k\in\mathbb{N}}\nu(I_{nk}).$$ Let $f\colon\mathbb{N}\to\mathbb{N}\times\mathbb{N}$ be a bijection and we place $I_{n,k}:=I_{nk}$ for all $(n,k)\in\mathbb{N}\times\mathbb{N}$ . We consider the sequence $\{I_{f(r)}\}_{r\in\mathbb{N}}$ . We prove that $\{I_{f(r)}\}_{r\in\mathbb{N}}\subseteq\mathcal{K}$ and that is a covering of $\bigcup_{n\in\mathbb{N}} E_n$ .We observe that $$\bigcup_{r\in\mathbb{N}}I_{f(r)}= \bigcup_{(n,k)\in\mathbb{N}\times\mathbb{N}}I_{nk}=\bigcup_{n\in\mathbb{N}}\bigg[\bigcup_{k\in\mathbb{N}}I_{nk}\bigg]\supseteq\bigcup_{n\in\mathbb{N}}E_n.$$ By definition of $\mu^*$ we have $$\mu^*\bigg(\bigcup_{n\in\mathbb{N}}E_n\bigg)\le\sum_{r\in\mathbb{N}}\nu(I_{f(r)}).$$ Now we place $$f(r):=(n_r,k_r)\quad\text{and}\quad K_r=\max\{k_1,\dots, k_r\},$$ and we consider the partial sum s-th. Therefore \begin{equation} \begin{split} \sum_{r=1}^s \nu(I_{f(r)})=&\nu(I_{f(1)})+\cdots+\nu(I_{f(s)})\\ =&\nu(I_{n_1k_1})+\cdots+\nu(I_{n_sk_s})\quad\text{We remember that}\quad I_{nk}:=I_{n,k}\\ \color{RED}{\le}& \sum_{n=1}^{K_r}\color{BLUE}{\sum_{k\in\mathbb{N}}\nu(I_{nk})}\\ <&\sum_{n=1}^{K_r}\bigg[\mu^*(E_n)+\frac{\varepsilon}{2^n}\bigg]\\ <&\sum_{n\in\mathbb{N}}\bigg[\mu^*(E_n)+\frac{\varepsilon}{2^n}\bigg]\\ =&\sum_{n\in\mathbb{N}}\mu^*(E_n)+\varepsilon. \end{split} \end{equation} For $\varepsilon\to 0$ we have $$\sum_{r=1}^s \nu(I_{f(r)})\le\sum_{n\in\mathbb{N}}\mu^*(E_n).$$ Question 1. Why is the inequality in red true? $$$$ Question 2. Could it be that some blue series is divergent? $$$$ Therefore $$\sum_{r\in\mathbb{N}}\nu(I_{f(r)}):=\lim_{s\to+\infty}\sum_{r=1}^s \nu(I_{f(r)})\color{BLUE}{\le}\sum_{n\in\mathbb{N}}\mu^*(E_n)$$ Question 3. Why is the inequality in blue true? In general if $\{a_n\}$ and $\{b_n\}$ are two real number sequence such that $\lim a_n=a\in\mathbb{R}$ and $\lim b_n=b\in\mathbb{R}$ , then if $a_n\le b_n$ for all $n\in\mathbb{N}$ , then $a<b$ . Is this the case? That is, the series $\sum_{n\in\mathbb{N}}\mu^*(E_n)$ is convergent? Thanks for your patience!","Theorem. Let a set family such that and be given an application such that , we define then is an outer measure. Proof. (With Fubini's Theorem ) We prove that is -subadditive, the other properties are trivial. Let a countable set family. We suppose that for all , that is for all exists such that . Be fixed . For what has been said above and for the properties of the infimum, for all exists such that We observe that At this point, in order to apply the definition of , it is necessary to specify that it is equivalent to In general, what is important is that the set can be covered by a family , where is a countable set of indices. By definition of we have where the blue equal is the Fubini's Theorem. Proof. (Without Fubini's Theorem ) Let a countable set family. We suppose that for all , that is for all exists such that . Be fixed . For what has been said above and for the properties of the infimum, for all exists such that Let be a bijection and we place for all . We consider the sequence . We prove that and that is a covering of .We observe that By definition of we have Now we place and we consider the partial sum s-th. Therefore For we have Question 1. Why is the inequality in red true? Question 2. Could it be that some blue series is divergent? Therefore Question 3. Why is the inequality in blue true? In general if and are two real number sequence such that and , then if for all , then . Is this the case? That is, the series is convergent? Thanks for your patience!","\mathcal{K}\subseteq 2^{X} \emptyset \in\mathcal{K} \nu\colon\mathcal{K}\to[0,+\infty] \nu(\emptyset)=0 \mu^*(E)=\inf\left\{\sum_{n\in\mathbb{N}}\nu(I_n)\;\middle|\;E\subseteq\bigcup_{n\in\mathbb{N}}I_n\;\text{and}\;\{I_n\}_{n\in\mathbb{N}}\subseteq\mathcal{K}\right\}, \mu^* \mu^* \sigma \{E_n\}_{n\in\mathbb{N}}\subseteq 2^{X} \mu^*(E_n)<+\infty n\in\mathbb{N} n\in\mathbb{N} \{I_{n,k}\}_{k\in\mathbb{N}}\subseteq \mathcal{K} E_n\subseteq\bigcup_{k\in\mathbb{N}}I_{n,k} \varepsilon> 0 n\in\mathbb{N} \{I_{n,k}\}\subseteq\mathcal{K} E_n\subseteq\bigcup_{k\in\mathbb{N}}I_{n,k}\quad\text{and}\quad\mu^*(E_n)+\frac{\varepsilon}{2^n}>\sum_{k\in\mathbb{N}}\nu(I_{n,k}). \bigcup_{n\in\mathbb{N}}E_n\subseteq\bigcup_{n\in\mathbb{N}}\bigcup_{k\in\mathbb{N}}I_{n,k}=\bigcup_{(n,k)\in\mathbb{N}\times\mathbb{N}}I_{n,k}\quad\text{and}\quad\{I_{n,k}\}_{n,k\in\mathbb{N}}\subseteq\mathcal{K}. \mu^* \mu^*(E)=\inf\left\{\sum_{(n,k)\in\mathbb{N}\times\mathbb{N}}\nu(I_{n,k})\;\middle|\;E\subseteq\bigcup_{(n,k)\in\mathbb{N}\times\mathbb{N}}I_{n,k}\;\text{and}\;\{I_{n,k}\}_{(n,k)\in\mathbb{N}\times\mathbb{N}}\subseteq\mathcal{K}\right\}. E \{I_\gamma\}_{\gamma\in\Gamma}\subseteq\mathcal{K} \Gamma \mu^* \begin{equation}
\mu^*\bigg(\bigcup_{n\in\mathbb{N}}E_n\bigg)\le\sum_{(n,k)\in\mathbb{N}\times\mathbb{N}}\nu(I_{n,k})\color{BLUE}{=}\sum_{n\in\mathbb{N}}\sum_{k\in\mathbb{N}}\nu(I_{n,k})<\sum_{n\in\mathbb{N}}\bigg[\nu(I_{n,k})+\frac{\varepsilon}{2^n}\bigg]=\sum_{n\in\mathbb{N}}\mu^*(E_n)+\varepsilon,
\end{equation} \hspace{9cm}\square \{E_n\}_{n\in\mathbb{N}}\subseteq 2^{X} \mu^*(E_n)<+\infty n\in\mathbb{N} n\in\mathbb{N} \{I_{nk}\}_{k\in\mathbb{N}}\subseteq \mathcal{K} E_n\subseteq\bigcup_{k\in\mathbb{N}}I_{nk} \varepsilon> 0 n\in\mathbb{N} \{I_{nk}\}\subseteq\mathcal{K} E_n\subseteq\bigcup_{k\in\mathbb{N}}I_{nk}\quad\text{and}\quad\mu^*(E_n)+\frac{\varepsilon}{2^n}>\sum_{k\in\mathbb{N}}\nu(I_{nk}). f\colon\mathbb{N}\to\mathbb{N}\times\mathbb{N} I_{n,k}:=I_{nk} (n,k)\in\mathbb{N}\times\mathbb{N} \{I_{f(r)}\}_{r\in\mathbb{N}} \{I_{f(r)}\}_{r\in\mathbb{N}}\subseteq\mathcal{K} \bigcup_{n\in\mathbb{N}} E_n \bigcup_{r\in\mathbb{N}}I_{f(r)}= \bigcup_{(n,k)\in\mathbb{N}\times\mathbb{N}}I_{nk}=\bigcup_{n\in\mathbb{N}}\bigg[\bigcup_{k\in\mathbb{N}}I_{nk}\bigg]\supseteq\bigcup_{n\in\mathbb{N}}E_n. \mu^* \mu^*\bigg(\bigcup_{n\in\mathbb{N}}E_n\bigg)\le\sum_{r\in\mathbb{N}}\nu(I_{f(r)}). f(r):=(n_r,k_r)\quad\text{and}\quad K_r=\max\{k_1,\dots, k_r\}, \begin{equation}
\begin{split}
\sum_{r=1}^s \nu(I_{f(r)})=&\nu(I_{f(1)})+\cdots+\nu(I_{f(s)})\\
=&\nu(I_{n_1k_1})+\cdots+\nu(I_{n_sk_s})\quad\text{We remember that}\quad I_{nk}:=I_{n,k}\\
\color{RED}{\le}& \sum_{n=1}^{K_r}\color{BLUE}{\sum_{k\in\mathbb{N}}\nu(I_{nk})}\\
<&\sum_{n=1}^{K_r}\bigg[\mu^*(E_n)+\frac{\varepsilon}{2^n}\bigg]\\
<&\sum_{n\in\mathbb{N}}\bigg[\mu^*(E_n)+\frac{\varepsilon}{2^n}\bigg]\\
=&\sum_{n\in\mathbb{N}}\mu^*(E_n)+\varepsilon.
\end{split}
\end{equation} \varepsilon\to 0 \sum_{r=1}^s \nu(I_{f(r)})\le\sum_{n\in\mathbb{N}}\mu^*(E_n).   \sum_{r\in\mathbb{N}}\nu(I_{f(r)}):=\lim_{s\to+\infty}\sum_{r=1}^s \nu(I_{f(r)})\color{BLUE}{\le}\sum_{n\in\mathbb{N}}\mu^*(E_n) \{a_n\} \{b_n\} \lim a_n=a\in\mathbb{R} \lim b_n=b\in\mathbb{R} a_n\le b_n n\in\mathbb{N} a<b \sum_{n\in\mathbb{N}}\mu^*(E_n)","['measure-theory', 'proof-verification', 'proof-writing', 'proof-explanation']"
26,Prove that every open set is lebesgue-measurable,Prove that every open set is lebesgue-measurable,,"Let $\mathbb{R}^n\supset{I}=(a,b)=(a_1,b_1)\times...\times(a_n,b_n)$ with $a,b\in{\mathbb{R}^n}$ such that $a_i\lt b_i   $$\forall i$.    So that the outer measure is defined as: $$ \mu^*(A)=inf\{\sum_{i\in{J}}V(I_i)\mid A\subset\bigcup_{i\in{J}}(I_i)\} $$ Where:  $\{I_i\}_{i\in{J}}$ is a cover of A. I have already proven that every $I$ is a Lebesgue-measurable set. Now I want to  prove that every open set is Lebesgue-measurable. I have done this, is it correct? Let A be an open set. For every $x\in A$ with $x=(x_1,..,x_n)$ there exist an $r>0 $  such that $B(x;r)\subset A$. If we take $r$ small enough, there exists  $\alpha > 0$ such that: $$ B(x;r)\subset I_x=(x_1-\alpha,x_1+\alpha)\times...\times(x_n-\alpha,x_n+\alpha)\subset A $$ Then define $A$ with: $$   A=\bigcup_{x\in A} I_x $$ A is union of Lebesgue-measurable sets so A is Lebesgue-measurable.","Let $\mathbb{R}^n\supset{I}=(a,b)=(a_1,b_1)\times...\times(a_n,b_n)$ with $a,b\in{\mathbb{R}^n}$ such that $a_i\lt b_i   $$\forall i$.    So that the outer measure is defined as: $$ \mu^*(A)=inf\{\sum_{i\in{J}}V(I_i)\mid A\subset\bigcup_{i\in{J}}(I_i)\} $$ Where:  $\{I_i\}_{i\in{J}}$ is a cover of A. I have already proven that every $I$ is a Lebesgue-measurable set. Now I want to  prove that every open set is Lebesgue-measurable. I have done this, is it correct? Let A be an open set. For every $x\in A$ with $x=(x_1,..,x_n)$ there exist an $r>0 $  such that $B(x;r)\subset A$. If we take $r$ small enough, there exists  $\alpha > 0$ such that: $$ B(x;r)\subset I_x=(x_1-\alpha,x_1+\alpha)\times...\times(x_n-\alpha,x_n+\alpha)\subset A $$ Then define $A$ with: $$   A=\bigcup_{x\in A} I_x $$ A is union of Lebesgue-measurable sets so A is Lebesgue-measurable.",,['measure-theory']
27,Vitali Covering Lemma Proof,Vitali Covering Lemma Proof,,"Why may we assume that each interval in $\mathcal{F}$ is contained in $\mathcal{O}$? What warrants this reduction? Why is statement (4) true? If $x \in E - \bigcup_{k=1}^n I_k$, then $x \in E$ and $x \notin I_k$ for every $k=1,...,n$. Given some $\epsilon > 0$, there exists $I \in \mathcal{F}$ containing $x$ with $\ell (I) < \epsilon$. I tried choosing $\epsilon > 0$ small enough so that it $I$ wouldn't intersect any of the $I_k$, thereby showing $I \in \mathcal{F}_n$; but it wasn't clear to me how to do this. Indeed, it doesn't seem possible...[Note: the errata sheet for Royden-Fitpatrick's Real Analysis says that $\infty$ should be replaced by $n$] Where are we getting all of the disjoint collections? What guarantees they exist? E.g., ""Suppose $n$ is a natural number and the finite disjoint subcollection $\{I_k\}_{k=1}^n$ has been chosen."" How has this been chosen? It seems that we've chosen them out of thin air. I could keep going on. At this point I'm pretty lost given the sheer number of choices he has made and will make (e.g., why can we choose $\ell(I_{n+1}) > s_n/2$?). It isn't terribly clear how $\{I_k\}_{k=1}^n$ is obtained and how the rest are obtained. EDIT: I with the help of Tony S.F., I have been able to resolve the 1st and 2nd parts of my question. For the 1st, given $x \in E \subseteq \mathcal{O}$, there is some $r > 0$ such that $B(x,r) \subseteq \mathcal{O}$. Given $\frac{r}{2} > 0$, there is a compact interval $I = [a,b] \in \mathcal{F}$ with $\ell (I) < \frac{r}{2}$ such that $x \in I$. Hence $b-a < \frac{r}{2}$ or $b < \frac{r}{2} + a$, and $a \le x \le b$. From these we get $a \le x < a + \frac{r}{2}$ or $|x-a| < \frac{r}{2}$. Hence, if $y \in I = [a,b]$, then \begin{align} |x-y| &= |(x-a) + (a-y)| \\ &\le |x-a| + |y-a| \\  &< \frac{r}{2} + \frac{r}{2} = r, \\ \end{align} and therefore $y \in B(x,r)$, from which it follows $I \subseteq B(x,r) \subseteq \mathcal{O}$. Now for the second part. Let $\{I_k\}_{k=1}^n \subseteq \mathcal{F}$ and let $x \in E- \bigcup_{k=1}^n$. Then $x \notin I_k$ for every $k$, and, as the $I_k$ are closed, there exists $r_k > 0$ for which $B(x,r_k) \cap I_k = \emptyset$. Letting $r = \frac{1}{2} \min\{r_1,...,r_n\}$, there exists $I_r$ with $\ell(I_r) < r \le \frac{r_k}{2}$ for each $k$ such that $x \in I_r$. But, as we saw above, this means $I_r \subseteq B(x,r_k)$ for each $k$ and therefore $I_r \cap I_k = \emptyset$ for each $k$. Hence $x \in I_r \subseteq \bigcup_{I \in \mathcal{F}_n} I$. Point 3 is still giving me trouble. I still don't understand this: ""Suppose $n$ is a natural number and the finite disjoint subcollection $\{I_k\}_{k=1}^n$ has been chosen."" What justifies this supposition? Granting that for a moment, I think I now see how $I_{n+1}$ is chosen. Since $s_n := \sup \{\ell (I) \mid I \in \mathcal{F}_n\}$ is finite, given $s_n/2 > 0$, there exists $I \in \mathcal{F}_n$ for which $s_n < \ell(I) + s_n/2$ or $\ell(I) > s_n/2$. Let $I_{n+1}$ equal this particular $I \in \mathcal{F}_n$. The only thing I don't see is why $\ell (I_{n+1}) > \ell(I)/2$ for every $I \in \mathcal{F}$. Certainly $\ell (I_{n+1}) > \ell(I)/2$ for every $I \in \mathcal{F}_n$ is true, because by definition $\ell(I_{n+1}) > s_n/2 \ge \ell(I)/2$ for every $I \in \mathcal{F}_n$. The last thing giving me trouble is how $I \cap I_k = \emptyset$ for every $k$ implies $\ell(I_k) > \ell(I)/2$ for every $k$.","Why may we assume that each interval in $\mathcal{F}$ is contained in $\mathcal{O}$? What warrants this reduction? Why is statement (4) true? If $x \in E - \bigcup_{k=1}^n I_k$, then $x \in E$ and $x \notin I_k$ for every $k=1,...,n$. Given some $\epsilon > 0$, there exists $I \in \mathcal{F}$ containing $x$ with $\ell (I) < \epsilon$. I tried choosing $\epsilon > 0$ small enough so that it $I$ wouldn't intersect any of the $I_k$, thereby showing $I \in \mathcal{F}_n$; but it wasn't clear to me how to do this. Indeed, it doesn't seem possible...[Note: the errata sheet for Royden-Fitpatrick's Real Analysis says that $\infty$ should be replaced by $n$] Where are we getting all of the disjoint collections? What guarantees they exist? E.g., ""Suppose $n$ is a natural number and the finite disjoint subcollection $\{I_k\}_{k=1}^n$ has been chosen."" How has this been chosen? It seems that we've chosen them out of thin air. I could keep going on. At this point I'm pretty lost given the sheer number of choices he has made and will make (e.g., why can we choose $\ell(I_{n+1}) > s_n/2$?). It isn't terribly clear how $\{I_k\}_{k=1}^n$ is obtained and how the rest are obtained. EDIT: I with the help of Tony S.F., I have been able to resolve the 1st and 2nd parts of my question. For the 1st, given $x \in E \subseteq \mathcal{O}$, there is some $r > 0$ such that $B(x,r) \subseteq \mathcal{O}$. Given $\frac{r}{2} > 0$, there is a compact interval $I = [a,b] \in \mathcal{F}$ with $\ell (I) < \frac{r}{2}$ such that $x \in I$. Hence $b-a < \frac{r}{2}$ or $b < \frac{r}{2} + a$, and $a \le x \le b$. From these we get $a \le x < a + \frac{r}{2}$ or $|x-a| < \frac{r}{2}$. Hence, if $y \in I = [a,b]$, then \begin{align} |x-y| &= |(x-a) + (a-y)| \\ &\le |x-a| + |y-a| \\  &< \frac{r}{2} + \frac{r}{2} = r, \\ \end{align} and therefore $y \in B(x,r)$, from which it follows $I \subseteq B(x,r) \subseteq \mathcal{O}$. Now for the second part. Let $\{I_k\}_{k=1}^n \subseteq \mathcal{F}$ and let $x \in E- \bigcup_{k=1}^n$. Then $x \notin I_k$ for every $k$, and, as the $I_k$ are closed, there exists $r_k > 0$ for which $B(x,r_k) \cap I_k = \emptyset$. Letting $r = \frac{1}{2} \min\{r_1,...,r_n\}$, there exists $I_r$ with $\ell(I_r) < r \le \frac{r_k}{2}$ for each $k$ such that $x \in I_r$. But, as we saw above, this means $I_r \subseteq B(x,r_k)$ for each $k$ and therefore $I_r \cap I_k = \emptyset$ for each $k$. Hence $x \in I_r \subseteq \bigcup_{I \in \mathcal{F}_n} I$. Point 3 is still giving me trouble. I still don't understand this: ""Suppose $n$ is a natural number and the finite disjoint subcollection $\{I_k\}_{k=1}^n$ has been chosen."" What justifies this supposition? Granting that for a moment, I think I now see how $I_{n+1}$ is chosen. Since $s_n := \sup \{\ell (I) \mid I \in \mathcal{F}_n\}$ is finite, given $s_n/2 > 0$, there exists $I \in \mathcal{F}_n$ for which $s_n < \ell(I) + s_n/2$ or $\ell(I) > s_n/2$. Let $I_{n+1}$ equal this particular $I \in \mathcal{F}_n$. The only thing I don't see is why $\ell (I_{n+1}) > \ell(I)/2$ for every $I \in \mathcal{F}$. Certainly $\ell (I_{n+1}) > \ell(I)/2$ for every $I \in \mathcal{F}_n$ is true, because by definition $\ell(I_{n+1}) > s_n/2 \ge \ell(I)/2$ for every $I \in \mathcal{F}_n$. The last thing giving me trouble is how $I \cap I_k = \emptyset$ for every $k$ implies $\ell(I_k) > \ell(I)/2$ for every $k$.",,"['real-analysis', 'measure-theory', 'proof-explanation']"
28,Measurable function satisfying $| \int_{E} fdx | \leq 1 $ for every Lebesgue-measurable set $E$ with $m(E) \leq 1 $ satisfies certain condition,Measurable function satisfying  for every Lebesgue-measurable set  with  satisfies certain condition,| \int_{E} fdx | \leq 1  E m(E) \leq 1 ,"Let $f: \mathbb{R} \to \mathbb{R}$ be a measurable function satisfying $| \int_{E} fdx | \leq 1 $ for every Borel set $E$ with $m(E) \leq 1 $ . Prove that $$\lim_{n \to \infty} n m(\lbrace x \in \mathbb{R} : |f(x)| \geq n \rbrace) = 0.$$ $m$ is the standard Lebesgue measure. So this would be easy if the function were integrable, i.e. if $\int_{\mathbb{R}} fdx < +\infty$ , but this doesn't have to be the case, since for example $f(x) = \frac{1}{2}$ satisfies this condition. I've tried assuming the opposite, that there exists an $\varepsilon > 0$ and a subsequence $n_{k}$ such that $n_{k} m(\lbrace x \in \mathbb{R} : |f(x)| \geq n_{k} \rbrace) \geq \varepsilon$ for all $k \in \mathbb{N}$ . What I know is that this sequence of sets, $\{A_{k}\}_{k=1}^{\infty}$ , $A_{k} = n_{k} m(\lbrace x \in \mathbb{R} : |f(x)| \geq n_{k} \rbrace) \geq \varepsilon$ , is a decreasing (i.e. $A_{k+1} \subseteq A_{k}$ ) sequence, and that its limit is the empty set, so it would be nice if I could prove that $m(A_{k}) < +\infty$ for some $k$ so that I could apply continuity from below and conclude that $m(A_{k}) \to 0$ when $k \to \infty$ , but I can't even prove that. Also, I have no idea how to construct a contradiction using the given condition. Edit: Here's what I have so far: $$(\forall \alpha \in \mathbb{R})(\forall k \in \mathbb{N}) | \int_{\alpha}^{\alpha+k} fdx|<k;$$ From the opposite assumption, we have $$\int_{A_{k}} |f|dx \geq \varepsilon$$ for all $k \in \mathbb{N}$ .","Let be a measurable function satisfying for every Borel set with . Prove that is the standard Lebesgue measure. So this would be easy if the function were integrable, i.e. if , but this doesn't have to be the case, since for example satisfies this condition. I've tried assuming the opposite, that there exists an and a subsequence such that for all . What I know is that this sequence of sets, , , is a decreasing (i.e. ) sequence, and that its limit is the empty set, so it would be nice if I could prove that for some so that I could apply continuity from below and conclude that when , but I can't even prove that. Also, I have no idea how to construct a contradiction using the given condition. Edit: Here's what I have so far: From the opposite assumption, we have for all .",f: \mathbb{R} \to \mathbb{R} | \int_{E} fdx | \leq 1  E m(E) \leq 1  \lim_{n \to \infty} n m(\lbrace x \in \mathbb{R} : |f(x)| \geq n \rbrace) = 0. m \int_{\mathbb{R}} fdx < +\infty f(x) = \frac{1}{2} \varepsilon > 0 n_{k} n_{k} m(\lbrace x \in \mathbb{R} : |f(x)| \geq n_{k} \rbrace) \geq \varepsilon k \in \mathbb{N} \{A_{k}\}_{k=1}^{\infty} A_{k} = n_{k} m(\lbrace x \in \mathbb{R} : |f(x)| \geq n_{k} \rbrace) \geq \varepsilon A_{k+1} \subseteq A_{k} m(A_{k}) < +\infty k m(A_{k}) \to 0 k \to \infty (\forall \alpha \in \mathbb{R})(\forall k \in \mathbb{N}) | \int_{\alpha}^{\alpha+k} fdx|<k; \int_{A_{k}} |f|dx \geq \varepsilon k \in \mathbb{N},"['measure-theory', 'lebesgue-measure']"
29,Weak convergence and convergence in measure implies convergence in L^1?,Weak convergence and convergence in measure implies convergence in L^1?,,"This is a problem from S.J.Taylor Introduction to Measure and Integration p.182 Problem Let $(\Omega, \mathcal F, \mu)$ be a measure space. Let $f_n$ be a sequence of functions in $L^1(\mu)$ such that $f_n$  converge in measure to $f$ and $ \left(\int_E f_n \right)$  is a Cauchy sequence for every measurable set $E$, then we must prove that $f_n$ converge to $f$ in $L^1$. What I was trying to do is to proof that the measures $\nu_n $ induced by $f_n$ are equicontinous at $\emptyset$, this is, for all $\epsilon > 0$ and all decreasing sequence of sets $(B_k) \downarrow \emptyset$ there exists a $k_0$ such that $k\geq k_0$ implies $|\nu_n(B_k)|< \epsilon $. Because there is a result that convergence in measure and equicontinuity at $\emptyset$ implies $L^1$ convergence but the problem is that I don't know how to use effectively the condition that the measures converge for every set. One option was first consider the case where all the functions are positive or use contradiction and suppose that the sequence is not equicontinous.","This is a problem from S.J.Taylor Introduction to Measure and Integration p.182 Problem Let $(\Omega, \mathcal F, \mu)$ be a measure space. Let $f_n$ be a sequence of functions in $L^1(\mu)$ such that $f_n$  converge in measure to $f$ and $ \left(\int_E f_n \right)$  is a Cauchy sequence for every measurable set $E$, then we must prove that $f_n$ converge to $f$ in $L^1$. What I was trying to do is to proof that the measures $\nu_n $ induced by $f_n$ are equicontinous at $\emptyset$, this is, for all $\epsilon > 0$ and all decreasing sequence of sets $(B_k) \downarrow \emptyset$ there exists a $k_0$ such that $k\geq k_0$ implies $|\nu_n(B_k)|< \epsilon $. Because there is a result that convergence in measure and equicontinuity at $\emptyset$ implies $L^1$ convergence but the problem is that I don't know how to use effectively the condition that the measures converge for every set. One option was first consider the case where all the functions are positive or use contradiction and suppose that the sequence is not equicontinous.",,"['measure-theory', 'weak-convergence']"
30,Lusin’s Theorem and the connection between measurable and continuous functions,Lusin’s Theorem and the connection between measurable and continuous functions,,"I know questions similar to this have been asked on here, but I have yet to find an answer to my question. I’m trying to prove Lusin’s Theorem: Let $f$ be a measurable real-valued function on $[a,b]$. Given $\delta>0$, there exists a continuous function $\theta$ on$[a,b]$ such that $\mu(\{x;f(x)\neq\theta(x)\})<\delta$. And in the notes that I’m reading through, the first line of the proof goes: Let $f(x)$ be measurable on $[a,b]$ and let $\delta>0$. For each $n$, there exists a continuous function $h_n$ on $[a,b]$ such that   \begin{equation}\mu(\{x:|h_n(x)-f(x)|\geq\delta/2^{n+2}\}<\delta/2^{n+2}.\end{equation} How is this true? I am not seeing how we are able to make any assumptions about continuous functions just given that we have a measurable function.","I know questions similar to this have been asked on here, but I have yet to find an answer to my question. I’m trying to prove Lusin’s Theorem: Let $f$ be a measurable real-valued function on $[a,b]$. Given $\delta>0$, there exists a continuous function $\theta$ on$[a,b]$ such that $\mu(\{x;f(x)\neq\theta(x)\})<\delta$. And in the notes that I’m reading through, the first line of the proof goes: Let $f(x)$ be measurable on $[a,b]$ and let $\delta>0$. For each $n$, there exists a continuous function $h_n$ on $[a,b]$ such that   \begin{equation}\mu(\{x:|h_n(x)-f(x)|\geq\delta/2^{n+2}\}<\delta/2^{n+2}.\end{equation} How is this true? I am not seeing how we are able to make any assumptions about continuous functions just given that we have a measurable function.",,"['real-analysis', 'measure-theory']"
31,Prove that $L^{\infty}(\mathbb R)\cap C(\mathbb R)$ is not dense in $L^{\infty}(\mathbb R)$,Prove that  is not dense in,L^{\infty}(\mathbb R)\cap C(\mathbb R) L^{\infty}(\mathbb R),"Here $C(\mathbb R)$ is the set of all continuous functions in $\mathbb R$, so the problem asks me to prove that there exists $f \in L^\infty(\mathbb R)$ such that there is no sequence of functions in $\mathbb R$ converging under sup norm to $f$. Also, the continuous functions not necessarily have compact support. Does anyone have ideas? Thank you for your time.","Here $C(\mathbb R)$ is the set of all continuous functions in $\mathbb R$, so the problem asks me to prove that there exists $f \in L^\infty(\mathbb R)$ such that there is no sequence of functions in $\mathbb R$ converging under sup norm to $f$. Also, the continuous functions not necessarily have compact support. Does anyone have ideas? Thank you for your time.",,"['real-analysis', 'measure-theory', 'lebesgue-integral', 'lp-spaces']"
32,Prove that for any $\epsilon >0$ there exists a measurable set $E$ such that $m(E)<\infty$ and $\int_E f>(\int f)-\epsilon$.,Prove that for any  there exists a measurable set  such that  and .,\epsilon >0 E m(E)<\infty \int_E f>(\int f)-\epsilon,Let $f$ be a non-negative measurable function on $\mathbb{R}$ such that $\int f<\infty$. It is required to prove that for any $\epsilon >0$ there exists a measurable set $E$ such that $m(E)<\infty$ and $\int_E f>(\int f)-\epsilon$. The following is my attempt. Let $\epsilon >0$. Then there exists a simple function $\phi$ with $0\leq\phi\leq f$ such that $(\int f)-\epsilon<\int\phi$. Say $\sum_{k=1}^N a_k\ \chi_{E_k}$ is the canonical representation of $\phi$. Then $\int \phi=\sum_{k=1}^N a_k\ m(E_k)\leq\int f<\infty$. Define $E=\bigcup_{k=1}^N E_k$. Then $E$ is measurable and $m(E)<\infty$ and $\int \phi=\int_E\phi\leq\int_E f$. Hence the result. Is this proof correct? Someone please help. Thanks.,Let $f$ be a non-negative measurable function on $\mathbb{R}$ such that $\int f<\infty$. It is required to prove that for any $\epsilon >0$ there exists a measurable set $E$ such that $m(E)<\infty$ and $\int_E f>(\int f)-\epsilon$. The following is my attempt. Let $\epsilon >0$. Then there exists a simple function $\phi$ with $0\leq\phi\leq f$ such that $(\int f)-\epsilon<\int\phi$. Say $\sum_{k=1}^N a_k\ \chi_{E_k}$ is the canonical representation of $\phi$. Then $\int \phi=\sum_{k=1}^N a_k\ m(E_k)\leq\int f<\infty$. Define $E=\bigcup_{k=1}^N E_k$. Then $E$ is measurable and $m(E)<\infty$ and $\int \phi=\int_E\phi\leq\int_E f$. Hence the result. Is this proof correct? Someone please help. Thanks.,,"['measure-theory', 'proof-verification', 'lebesgue-integral', 'self-learning']"
33,Questions about Hausdorff measure and general metric outer measures.,Questions about Hausdorff measure and general metric outer measures.,,"The Hasudorff measure of a set $A\subset \mathbb R^n$ is defined as  $$ \mathcal H^s(A) = \lim_{\delta\downarrow 0} \mathcal H^s_\delta(A)$$  where  $$\mathcal H^s_\delta(A) = \inf\left\{\sum_{j=1}^\infty (\text{diam }S_j)^s : \{S_j\}_{j=1}^\infty \subset 2^{\mathbb R ^n} \text{ covers } A \text{ and } \text{diam } S_j < \delta  \right\} $$ It is easy to see that $\mathcal H^s_\delta(A)$ is non-increasing in $\delta$. However, I don't quite understand why $\mathcal H^s_\delta(A)$ is not actually constant in $\delta$ for each $A$; it would seem that the infimum should be achieved as the diameters of the sets $S_j$ get smaller and smaller, meaning that bounding the diameter of $S_j$ above by $\delta$ should do nothing at all to $\inf\sum_{j=1}^\infty (\text{diam }S_j)^s $. Moreover, suppose we approach Lebesgue measure analogously. Let $\mathscr{L^n}(A)$ be $n$-dimensional Lebesgue measure, and let  $$\mathscr{L_\delta^n}(A) := \inf\left\{\sum_{j=1}^\infty|B_j| : \{B_j\}_{j=1}^\infty \subset 2^{\mathbb R ^n} \text{ is a box cover of } A \text{ and } \text{diam } B_j < \delta  \right\} $$ we find that $\mathscr{L^n_\delta}(A)$ is constant in $\delta$, so that for any $\delta>0$  $$\mathscr{L^n}(A) = \mathscr{L^n_\delta}(A)= \lim_{\epsilon\rightarrow 0}\mathscr{L^n_\epsilon}(A)$$ So what about switching from volumes of boxes to diameters of arbitrary sets makes $\mathcal H^s_\delta(A)$ not necessarily constant in $\delta$? This question hints at a much more general question about the construction of outer measures via the Carathéodory method. A brief recap on this method (as I have learned it in class): Suppose $\mathcal F$ is a collection of subsets of some metric space $X$, let $A\subset X$, and consider the following set $$\mathcal C_{\delta, \mathcal F}(A) : = \left\{\{S_j\}^\infty\subset \mathcal F \mid \{S_j\}^\infty \text{ covers } A \text{ and } \text{diam }S_j< \delta\right\}$$ and consider any function $\zeta: \mathcal F \rightarrow [0,\infty]$. Then, the following functions are outer measures: $$\mu_{\delta, \mathcal F}(A) := \inf_{\{S_j\}^\infty \in \mathcal C_{\delta, \mathcal F}(A)} \sum^\infty_{j=1} \zeta(S_j)$$ $$\mu_{\mathcal F}(A) := \lim_{\delta \downarrow 0}\mu_{\delta, \mathcal F}(A)$$ Notice that the  Hausdorff measure $\mathcal H ^ s(A)$ is the special case where $\mathcal F = 2^X$ and $\zeta(S) = (\text{diam } S)^s$. Under what conditions is $\mu_{\delta,\mathcal F}(A)$ not constant in $\delta$ for every $A$, as is the case for $\mathcal H^s_{\delta}$?","The Hasudorff measure of a set $A\subset \mathbb R^n$ is defined as  $$ \mathcal H^s(A) = \lim_{\delta\downarrow 0} \mathcal H^s_\delta(A)$$  where  $$\mathcal H^s_\delta(A) = \inf\left\{\sum_{j=1}^\infty (\text{diam }S_j)^s : \{S_j\}_{j=1}^\infty \subset 2^{\mathbb R ^n} \text{ covers } A \text{ and } \text{diam } S_j < \delta  \right\} $$ It is easy to see that $\mathcal H^s_\delta(A)$ is non-increasing in $\delta$. However, I don't quite understand why $\mathcal H^s_\delta(A)$ is not actually constant in $\delta$ for each $A$; it would seem that the infimum should be achieved as the diameters of the sets $S_j$ get smaller and smaller, meaning that bounding the diameter of $S_j$ above by $\delta$ should do nothing at all to $\inf\sum_{j=1}^\infty (\text{diam }S_j)^s $. Moreover, suppose we approach Lebesgue measure analogously. Let $\mathscr{L^n}(A)$ be $n$-dimensional Lebesgue measure, and let  $$\mathscr{L_\delta^n}(A) := \inf\left\{\sum_{j=1}^\infty|B_j| : \{B_j\}_{j=1}^\infty \subset 2^{\mathbb R ^n} \text{ is a box cover of } A \text{ and } \text{diam } B_j < \delta  \right\} $$ we find that $\mathscr{L^n_\delta}(A)$ is constant in $\delta$, so that for any $\delta>0$  $$\mathscr{L^n}(A) = \mathscr{L^n_\delta}(A)= \lim_{\epsilon\rightarrow 0}\mathscr{L^n_\epsilon}(A)$$ So what about switching from volumes of boxes to diameters of arbitrary sets makes $\mathcal H^s_\delta(A)$ not necessarily constant in $\delta$? This question hints at a much more general question about the construction of outer measures via the Carathéodory method. A brief recap on this method (as I have learned it in class): Suppose $\mathcal F$ is a collection of subsets of some metric space $X$, let $A\subset X$, and consider the following set $$\mathcal C_{\delta, \mathcal F}(A) : = \left\{\{S_j\}^\infty\subset \mathcal F \mid \{S_j\}^\infty \text{ covers } A \text{ and } \text{diam }S_j< \delta\right\}$$ and consider any function $\zeta: \mathcal F \rightarrow [0,\infty]$. Then, the following functions are outer measures: $$\mu_{\delta, \mathcal F}(A) := \inf_{\{S_j\}^\infty \in \mathcal C_{\delta, \mathcal F}(A)} \sum^\infty_{j=1} \zeta(S_j)$$ $$\mu_{\mathcal F}(A) := \lim_{\delta \downarrow 0}\mu_{\delta, \mathcal F}(A)$$ Notice that the  Hausdorff measure $\mathcal H ^ s(A)$ is the special case where $\mathcal F = 2^X$ and $\zeta(S) = (\text{diam } S)^s$. Under what conditions is $\mu_{\delta,\mathcal F}(A)$ not constant in $\delta$ for every $A$, as is the case for $\mathcal H^s_{\delta}$?",,"['measure-theory', 'geometric-measure-theory', 'hausdorff-measure']"
34,"Rudin theorem 1.17, understanding the monotonicity of the function sequences defined.","Rudin theorem 1.17, understanding the monotonicity of the function sequences defined.",,"I'm going through the proof of theorem 1.17 of Rudin's Real and Complex Analysis . Theorem 1.17. Let $f: X \to [0,\infty]$ be measurable. There exist simple measurable functions $s_n$ on $X$ such that $0 \leq s_1 \leq s_2 \leq \dots \leq f$, $s_n(x) \to f(x)$ as $n \to \infty$, for every $x \in X$. The proof starts by defining $\delta_n = 2^{-n}$, for each $n$ and each real number $t$ there's an integer $k_n(t)$ such that $$ k_n(t)\delta_n \leq t < (k_n(t)+1)\delta_n, $$ this point is easily proved considering that the equation $$t = \mu \delta_n$$ has solution and taking $k_n(t) = \left\lfloor \mu \right\rfloor$ proves the statement above. Later the sequence $$\varphi_n(t) = \left\{ \begin{array}{lr} k_n(t)\delta_n & 0 \leq t < n \\ n & n \leq t \leq \infty \end{array} \right.$$ is defined. For each $n \;\;\varphi_n$ is a Borel function on $[0,\infty]$, but why? Is that because for each $n$ we have $\varphi_n$ is a simple function? Then it is stated that $$ t - \delta_n < \varphi_n(t) \leq t\;\; 0 \leq t \leq n $$ And this bit it is easy to prove by using the definition of $k_n(t)$. Almost finally it is stated that $$ 0 \leq \varphi_1 \leq \varphi_2 \leq \ldots \leq t $$ this bit puzzles me since $$ \begin{multline} \left\{ \begin{array}{l} t - \delta_n < \varphi_n(t) \leq t \\ t - \delta_{n-1} < \varphi_{n-1}(t) \leq t \end{array} \Rightarrow \right. \left\{ \begin{array}{l} t - \delta_n < \varphi_n(t) \leq t \\ - t \leq - \varphi_{n-1}(t) < - t + \delta_{n-1} \end{array}  \right. \Rightarrow \\ -\delta_n \leq \varphi_n(t) - \varphi_{n-1}(t) \leq \delta_{n-1} \end{multline} $$ and it doesn't tell me anything... And finally it is just stated that defining $s_n = \varphi_n \circ f$ has the required properties. My questions: Why is the sequence $\varphi_n$ measurable (borel function in this case)? Why is the sequence $\varphi_n$ monotonic? Why is the sequence $s_n$ monotonic? Update: Maybe I figured out 1 and 2, Since $\varphi_n$ is monotonic the counter image of any open set should be a Borelian set (union of open sets). Taking the difference $$ (\varphi_{n+1} - \varphi_n)(t) = \left\{ \begin{array}{lr} k_{n+1}(t) \delta_{n+1} - k_n(t) \delta_n & 0 \leq t < n \\ k_{n+1}(t) \delta_{n+1} - n & n \leq t < n + 1 \\ 1 & n + 1 \leq t < \infty \end{array} \right. $$ For $0 \leq t < n$ we have $$ \begin{multline} k_{n+1}(t) \delta_{n+1} - k_n(t) \delta_n = k_{n+1}(t) \delta_{n+1} - 2 k_n(t) \delta_{n + 1} = (k_{n+1}(t) - 2k_n(t))\delta_{n+1} = 0 \end{multline} $$ The equality to $0$ follows from the fact that it must be $k_{n+1}(t) = 2k_n(t)$ Given the uniqueness of the integer the multiplied by $\delta_j$ bound $t$. For $n \leq t < n + 1$ we have $$ (n\delta^{-1}_n) \delta_n = n \leq t < n + 1 = ((n+1)\delta^{-1}_n) \delta_n \Rightarrow k_{n}(t) = n2^n = n \delta^{-1}_n \Rightarrow k_{n}(t)\delta_n = n \Rightarrow k_{n+1}(t) \delta_{n+1} - n = n + 1 - n = 1 $$ I can then rewrite $$ (\varphi_{n+1} - \varphi_n)(t) = \left\{ \begin{array}{lr} 0 & 0 \leq t < n \\ 1 & n \leq t < \infty \end{array} \right. \Rightarrow 0 \leq (\varphi_{n+1} - \varphi_n)(t) \Rightarrow \varphi_n \leq \varphi_{n+1} $$ I keep trying to figure out why the sequence $s_n$ is monotonic.","I'm going through the proof of theorem 1.17 of Rudin's Real and Complex Analysis . Theorem 1.17. Let $f: X \to [0,\infty]$ be measurable. There exist simple measurable functions $s_n$ on $X$ such that $0 \leq s_1 \leq s_2 \leq \dots \leq f$, $s_n(x) \to f(x)$ as $n \to \infty$, for every $x \in X$. The proof starts by defining $\delta_n = 2^{-n}$, for each $n$ and each real number $t$ there's an integer $k_n(t)$ such that $$ k_n(t)\delta_n \leq t < (k_n(t)+1)\delta_n, $$ this point is easily proved considering that the equation $$t = \mu \delta_n$$ has solution and taking $k_n(t) = \left\lfloor \mu \right\rfloor$ proves the statement above. Later the sequence $$\varphi_n(t) = \left\{ \begin{array}{lr} k_n(t)\delta_n & 0 \leq t < n \\ n & n \leq t \leq \infty \end{array} \right.$$ is defined. For each $n \;\;\varphi_n$ is a Borel function on $[0,\infty]$, but why? Is that because for each $n$ we have $\varphi_n$ is a simple function? Then it is stated that $$ t - \delta_n < \varphi_n(t) \leq t\;\; 0 \leq t \leq n $$ And this bit it is easy to prove by using the definition of $k_n(t)$. Almost finally it is stated that $$ 0 \leq \varphi_1 \leq \varphi_2 \leq \ldots \leq t $$ this bit puzzles me since $$ \begin{multline} \left\{ \begin{array}{l} t - \delta_n < \varphi_n(t) \leq t \\ t - \delta_{n-1} < \varphi_{n-1}(t) \leq t \end{array} \Rightarrow \right. \left\{ \begin{array}{l} t - \delta_n < \varphi_n(t) \leq t \\ - t \leq - \varphi_{n-1}(t) < - t + \delta_{n-1} \end{array}  \right. \Rightarrow \\ -\delta_n \leq \varphi_n(t) - \varphi_{n-1}(t) \leq \delta_{n-1} \end{multline} $$ and it doesn't tell me anything... And finally it is just stated that defining $s_n = \varphi_n \circ f$ has the required properties. My questions: Why is the sequence $\varphi_n$ measurable (borel function in this case)? Why is the sequence $\varphi_n$ monotonic? Why is the sequence $s_n$ monotonic? Update: Maybe I figured out 1 and 2, Since $\varphi_n$ is monotonic the counter image of any open set should be a Borelian set (union of open sets). Taking the difference $$ (\varphi_{n+1} - \varphi_n)(t) = \left\{ \begin{array}{lr} k_{n+1}(t) \delta_{n+1} - k_n(t) \delta_n & 0 \leq t < n \\ k_{n+1}(t) \delta_{n+1} - n & n \leq t < n + 1 \\ 1 & n + 1 \leq t < \infty \end{array} \right. $$ For $0 \leq t < n$ we have $$ \begin{multline} k_{n+1}(t) \delta_{n+1} - k_n(t) \delta_n = k_{n+1}(t) \delta_{n+1} - 2 k_n(t) \delta_{n + 1} = (k_{n+1}(t) - 2k_n(t))\delta_{n+1} = 0 \end{multline} $$ The equality to $0$ follows from the fact that it must be $k_{n+1}(t) = 2k_n(t)$ Given the uniqueness of the integer the multiplied by $\delta_j$ bound $t$. For $n \leq t < n + 1$ we have $$ (n\delta^{-1}_n) \delta_n = n \leq t < n + 1 = ((n+1)\delta^{-1}_n) \delta_n \Rightarrow k_{n}(t) = n2^n = n \delta^{-1}_n \Rightarrow k_{n}(t)\delta_n = n \Rightarrow k_{n+1}(t) \delta_{n+1} - n = n + 1 - n = 1 $$ I can then rewrite $$ (\varphi_{n+1} - \varphi_n)(t) = \left\{ \begin{array}{lr} 0 & 0 \leq t < n \\ 1 & n \leq t < \infty \end{array} \right. \Rightarrow 0 \leq (\varphi_{n+1} - \varphi_n)(t) \Rightarrow \varphi_n \leq \varphi_{n+1} $$ I keep trying to figure out why the sequence $s_n$ is monotonic.",,"['real-analysis', 'measure-theory', 'proof-explanation']"
35,Understanding inequality in Keane's proof of the ergodic theorem,Understanding inequality in Keane's proof of the ergodic theorem,,"I know a few proofs of the ergodic theorem but I just cannot figure out this inequality. Let's take $(X, B_X, \mu, T)$ to be a measure preserving system and $B \in B_X$. Let $$S_n(x):= \left|\{i < n \ | \ T^ix \in B \}\right| = \sum_{i=0}^{n-1}\chi_B(T^ix)$$ $$A_n(x):= \frac{1}{n}S_n(x)\mbox{ and } \bar A(x) =\limsup_{n\to \infty}A_n(x)$$. The ergodic theorem is proved for indicators if $\int_X \bar A(x)d\mu \leq \mu (B)$ by replacing $B$ with $X - B$. Defining for a given $\varepsilon > 0$ $\tau (x):=\min \left\{ n \ | \ A_n(x) \geq \bar A(x) - \varepsilon \right\}$. Assuming that $\tau(x) \leq M$ for all $x$ he claims that $$S_n(x) \geq (n-M)\left(\bar A(x) - \varepsilon\right).$$ can someone please explain this inequality? Thanks in advance.","I know a few proofs of the ergodic theorem but I just cannot figure out this inequality. Let's take $(X, B_X, \mu, T)$ to be a measure preserving system and $B \in B_X$. Let $$S_n(x):= \left|\{i < n \ | \ T^ix \in B \}\right| = \sum_{i=0}^{n-1}\chi_B(T^ix)$$ $$A_n(x):= \frac{1}{n}S_n(x)\mbox{ and } \bar A(x) =\limsup_{n\to \infty}A_n(x)$$. The ergodic theorem is proved for indicators if $\int_X \bar A(x)d\mu \leq \mu (B)$ by replacing $B$ with $X - B$. Defining for a given $\varepsilon > 0$ $\tau (x):=\min \left\{ n \ | \ A_n(x) \geq \bar A(x) - \varepsilon \right\}$. Assuming that $\tau(x) \leq M$ for all $x$ he claims that $$S_n(x) \geq (n-M)\left(\bar A(x) - \varepsilon\right).$$ can someone please explain this inequality? Thanks in advance.",,"['real-analysis', 'measure-theory', 'ergodic-theory']"
36,"On rearrangement of level set: $\{f>t\}^* = \{f^*>t\}\,\,\text{?}$",On rearrangement of level set:,"\{f>t\}^* = \{f^*>t\}\,\,\text{?}","Let $A$ be a subset of $\mathbb{R}^n$ then the rearrangement of $A$ denoted by $A^*$ is the ball $B(0,r)$ having the same volume as $A$ i.e if  $|A| =|B(0,r)|$  with respect to Lebesgue measure then $$A^*= B(0,r)$$ Let $f$ be a function from $\mathbb{R}^n$ to $\mathbb{R}$. Then its symmetric decreasing rearrangement $f^*$ is the function defined for $x \in  \mathbb{R}^n$ by $$f^*(x) = \int_0^{\infty} 1_{\{f>t\}^*}(x) dt.$$ Where $1_{\{f>t\}^*}$ is the characteristic function of the set $\{f>t\}^*= B(0,r_t )$ on $\mathbb{R}^n$ for suitable $r_t >0$. The set $\{f>t\} := \{x \in \mathbb{R}^n: f(x)>t\}$ is called the $t$-level set of the function $f$. Question. How can I show that   $$\{f>t\}^* = \{f^*>t\}\,\,\text{?}$$ This is mentioned to be easy in the book of Elliott Lieb and Loss (Analysis second edition, Graduate Studies in Mathematical, vol 14, American mathematical Society, providence, RI 2001).","Let $A$ be a subset of $\mathbb{R}^n$ then the rearrangement of $A$ denoted by $A^*$ is the ball $B(0,r)$ having the same volume as $A$ i.e if  $|A| =|B(0,r)|$  with respect to Lebesgue measure then $$A^*= B(0,r)$$ Let $f$ be a function from $\mathbb{R}^n$ to $\mathbb{R}$. Then its symmetric decreasing rearrangement $f^*$ is the function defined for $x \in  \mathbb{R}^n$ by $$f^*(x) = \int_0^{\infty} 1_{\{f>t\}^*}(x) dt.$$ Where $1_{\{f>t\}^*}$ is the characteristic function of the set $\{f>t\}^*= B(0,r_t )$ on $\mathbb{R}^n$ for suitable $r_t >0$. The set $\{f>t\} := \{x \in \mathbb{R}^n: f(x)>t\}$ is called the $t$-level set of the function $f$. Question. How can I show that   $$\{f>t\}^* = \{f^*>t\}\,\,\text{?}$$ This is mentioned to be easy in the book of Elliott Lieb and Loss (Analysis second edition, Graduate Studies in Mathematical, vol 14, American mathematical Society, providence, RI 2001).",,"['measure-theory', 'harmonic-analysis', 'decreasing-rearrangements']"
37,Is $\mathcal {F}$ a sigma algebra?,Is  a sigma algebra?,\mathcal {F},"$(C[0,1],d)$ be metric space with usual 'sup-norm' metric. Let $(C[0,1],\mathcal {B})$ be a measurable space where $\mathcal {B}$ is Borel sigma algebra on $C[0,1]$.Let $\mathcal{F}_t=\sigma(W_s:s \in [0,t])$ where $W_s$ denotes the evaluation map.Let $\mathcal {F}= \bigcup_{ t \in [0,1)} \mathcal{F}_t$. Is $\mathcal {F}$ a $\sigma-$ algebra ? I am having trouble in showing that $\mathcal {F}$ is closed under countable union.I really dont have any intuition whether $\mathcal {F}$ is a $\sigma-$ algebra or not? Any idea to prove or disprove this?","$(C[0,1],d)$ be metric space with usual 'sup-norm' metric. Let $(C[0,1],\mathcal {B})$ be a measurable space where $\mathcal {B}$ is Borel sigma algebra on $C[0,1]$.Let $\mathcal{F}_t=\sigma(W_s:s \in [0,t])$ where $W_s$ denotes the evaluation map.Let $\mathcal {F}= \bigcup_{ t \in [0,1)} \mathcal{F}_t$. Is $\mathcal {F}$ a $\sigma-$ algebra ? I am having trouble in showing that $\mathcal {F}$ is closed under countable union.I really dont have any intuition whether $\mathcal {F}$ is a $\sigma-$ algebra or not? Any idea to prove or disprove this?",,['measure-theory']
38,Expectation of first-passage-time of a diffusion process with negative drift,Expectation of first-passage-time of a diffusion process with negative drift,,"Take  the stochastic process $X_0 = 0$ and $X_t = \nu t + \sigma W_t$  where $W_t$ is standard Brownian motion and $\nu$ is a drift which may be negative (this is the key complexity to the question) Let $\alpha > 0$ be a fixed level, then define the first passage time as the random variable: $T = \inf\{ 0 < t \mid X_t=\alpha \}$. Then, given some $r > 0$, what is the following expectation? $$ U \equiv \mathbb{E}\left(e^{-r T} \right) $$ A related question may be: what is the moment generating function for the $T$ stopping time?  Note that I do not care about the pdf or cdf of $T$, just the above expectation. Solving the $\nu \geq 0$ case: I believe this turns out to be easy as this follows the example in https://en.wikipedia.org/wiki/Inverse_Gaussian_distribution#Relationship_with_Brownian_motion .  Hence, $T$ is distributed as an Inverse Gaussian: $T\sim IG(\tfrac\alpha\nu, \tfrac {\alpha^2} {\sigma^2})$ in that notation. Moreover, the moment generating function for the $IG(\mu,\lambda)$ is $$M(t;\mu,\lambda) \equiv \exp\left[{\frac{\lambda}{\mu}\left(1-\sqrt{1-\frac{2\mu^2t}{\lambda}}\right)}\right]$$ Finally, note that the expectation I gave is exactly the definition of the MGF at $t=-r$, so we have our answer, $$ \mathbb{E}\left(e^{-r T} \right) = M\left(-r;\tfrac\alpha\nu, \tfrac {\alpha^2} {\sigma^2}\right) $$ Solving the $\nu < 0$ case: If you look carefully at theorems such as in Karlin  and Taylor ""A First Course in Stochastic Processes"" page 362 and theorem 5.3, or the wikipedia page above, they always assume that $\nu \geq 0$.  As Karlin and Taylor puts it: ""When $\nu < 0$, $T$ has a defective probability distribution, that is $T$ is infinite with positive probability"". However, to find $\mathbb{E}\left(e^{-r T}\right)$ we don't really need to find the probability distribution.  Is the moment generating function (and hence the direct solution for $U$) still defined?  Is the formula the same as above?","Take  the stochastic process $X_0 = 0$ and $X_t = \nu t + \sigma W_t$  where $W_t$ is standard Brownian motion and $\nu$ is a drift which may be negative (this is the key complexity to the question) Let $\alpha > 0$ be a fixed level, then define the first passage time as the random variable: $T = \inf\{ 0 < t \mid X_t=\alpha \}$. Then, given some $r > 0$, what is the following expectation? $$ U \equiv \mathbb{E}\left(e^{-r T} \right) $$ A related question may be: what is the moment generating function for the $T$ stopping time?  Note that I do not care about the pdf or cdf of $T$, just the above expectation. Solving the $\nu \geq 0$ case: I believe this turns out to be easy as this follows the example in https://en.wikipedia.org/wiki/Inverse_Gaussian_distribution#Relationship_with_Brownian_motion .  Hence, $T$ is distributed as an Inverse Gaussian: $T\sim IG(\tfrac\alpha\nu, \tfrac {\alpha^2} {\sigma^2})$ in that notation. Moreover, the moment generating function for the $IG(\mu,\lambda)$ is $$M(t;\mu,\lambda) \equiv \exp\left[{\frac{\lambda}{\mu}\left(1-\sqrt{1-\frac{2\mu^2t}{\lambda}}\right)}\right]$$ Finally, note that the expectation I gave is exactly the definition of the MGF at $t=-r$, so we have our answer, $$ \mathbb{E}\left(e^{-r T} \right) = M\left(-r;\tfrac\alpha\nu, \tfrac {\alpha^2} {\sigma^2}\right) $$ Solving the $\nu < 0$ case: If you look carefully at theorems such as in Karlin  and Taylor ""A First Course in Stochastic Processes"" page 362 and theorem 5.3, or the wikipedia page above, they always assume that $\nu \geq 0$.  As Karlin and Taylor puts it: ""When $\nu < 0$, $T$ has a defective probability distribution, that is $T$ is infinite with positive probability"". However, to find $\mathbb{E}\left(e^{-r T}\right)$ we don't really need to find the probability distribution.  Is the moment generating function (and hence the direct solution for $U$) still defined?  Is the formula the same as above?",,"['measure-theory', 'stochastic-processes', 'expectation', 'martingales']"
39,What is the relationship between the following set functions?,What is the relationship between the following set functions?,,"This problem is taken from Section 2.5 of Royden and Fitzpatrick's Real Analaysis, Fourth Edition text. For any open interval $I = (a,b)$, let $\ell(I) = b-a$ denote the length of $I$. For any set of real numbers $A$, define the following set functions: \begin{align} m^*(A) &= \inf\left\{\sum_{i=1}^\infty \ell(I_n): \bigcup_{n=1}^\infty I_n \supseteq A, I_n \text{ is an open, bounded interval for all $n$}\right\} \\ m^{**}(A)&= \inf\{m^*(\mathcal{O}): \mathcal{O} \supseteq A, \mathcal{O} \text{ open}\} \\ m^{***}(A)&= \sup\{m^*(F): F \subseteq A, F \text{ closed}\} \end{align} The text asks the reader to determine how these set functions are related. I think I can show that $m^* = m^{**}$ for all subsets of $\mathbf{R}$. However, I am only able to show $m^*(A) = m^{***}(A)$ if $m^{***}(A) = \infty$ or $A$ is measurable. Is this the correct answer? In particular, is it possible to find a set such that $m^{***}(A) < m^*(A)$?","This problem is taken from Section 2.5 of Royden and Fitzpatrick's Real Analaysis, Fourth Edition text. For any open interval $I = (a,b)$, let $\ell(I) = b-a$ denote the length of $I$. For any set of real numbers $A$, define the following set functions: \begin{align} m^*(A) &= \inf\left\{\sum_{i=1}^\infty \ell(I_n): \bigcup_{n=1}^\infty I_n \supseteq A, I_n \text{ is an open, bounded interval for all $n$}\right\} \\ m^{**}(A)&= \inf\{m^*(\mathcal{O}): \mathcal{O} \supseteq A, \mathcal{O} \text{ open}\} \\ m^{***}(A)&= \sup\{m^*(F): F \subseteq A, F \text{ closed}\} \end{align} The text asks the reader to determine how these set functions are related. I think I can show that $m^* = m^{**}$ for all subsets of $\mathbf{R}$. However, I am only able to show $m^*(A) = m^{***}(A)$ if $m^{***}(A) = \infty$ or $A$ is measurable. Is this the correct answer? In particular, is it possible to find a set such that $m^{***}(A) < m^*(A)$?",,"['real-analysis', 'measure-theory', 'lebesgue-measure']"
40,"Diffuse-like decomposition of the segment $[0,1]$ in accordance with Lebesgue measure",Diffuse-like decomposition of the segment  in accordance with Lebesgue measure,"[0,1]","Consider the segment $[0,1]\subset\mathbb{R}$ and the standard Lebesgue measure $\mu$ on $\mathbb{R}$. I wonder if we can find such decomposition $A\sqcup B=[0,1]$, that for any subsegment $[a,b]\subset[0,1]$ we'd have $\mu(A\cap [a,b])=\mu(B\cap [a,b])$? More particular case is that for any $x\in[0,1]$ we have $\mu(A\cap [0,x])=\mu(B\cap [0,x])$ and hence $\mu(A\cap [0,x])=\frac{x}{2}$. Metaphor. Such decomposition can be assosiated with mixture of liquids. Suppose we have two liquids of equal amount. We bottle them, shake them up and then pour some into the glass. No matter how much we pour, the glass will contain equal amount of both liquids. Ideas. We can decompose $[0,1]$ as $X\sqcup Y$ where $X=[0,1]\setminus\mathbb{Q}$ and $Y=[0,1]\cap\mathbb{Q}$. Here we have $\mu(X)=1$ and $\mu(Y)=0$. Maybe it's possible to describe a procedure of moving points from $X$ to $Y$ (i.e. excluding them from $X$ and including in $Y$) that will lead to desired decomposition. Another thought is to set $A_n=\bigsqcup_{k=0}^{2^{n-1}-1}[2k\cdot2^{-n},\ (2k+1)\cdot2^{-n})$ and $B_n=[0,1]\setminus A_n$ for all $n\in\mathbb{N}$. Then for any $n\in\mathbb{N}$ we'll have $A_n\sqcup B_n=[0,1]$ $\mu(A_n)=\mu(B_n)$ $|\mu(A\cap [a,b])-\mu(B\cap [a,b])|\leq 2^{-n}$ for any $[a,b]\subset[0,1]$ I wonder if we can take some kind of limit here raising $n\longrightarrow\infty$. Origin. This question arose after I read this post . It's interesting whether the condition of Riemann integrability is crucial there or we could weaken it with Lebesgue integrability. In attempts to find counterexample I thought of above mentioned decomposition. If it exists then we could define $f(x)=1$ if $x\in A$ and $f(x)=-1$ if $x\in B$. That would be our counterexample because $\int_I f\,d\mu$ would be zero for any interval $I\in[0,1]$. Generalization. Suppose $W\subset\mathbb{R}^n$ is a Lebesgue measurable set, and $\{r_i\}_{i=1}^k\subset\mathbb{R}_+$ such that $r_1+\ldots+r_k=\mu(W)$. Is it possible to choose such decomposition $A_1\sqcup\ldots\sqcup A_k=W$ that for any measurable $V\subset W$ we'd have $\mu(A_i \cap V)=r_i\cdot\frac{\mu(V)}{\mu(W)}$ for any $1\leq i\leq k$. In other words, can we uniformly ""blend"" measurable subsets of a measurable set in any proportions? It seems to me like a very interesting result, provided it's true.","Consider the segment $[0,1]\subset\mathbb{R}$ and the standard Lebesgue measure $\mu$ on $\mathbb{R}$. I wonder if we can find such decomposition $A\sqcup B=[0,1]$, that for any subsegment $[a,b]\subset[0,1]$ we'd have $\mu(A\cap [a,b])=\mu(B\cap [a,b])$? More particular case is that for any $x\in[0,1]$ we have $\mu(A\cap [0,x])=\mu(B\cap [0,x])$ and hence $\mu(A\cap [0,x])=\frac{x}{2}$. Metaphor. Such decomposition can be assosiated with mixture of liquids. Suppose we have two liquids of equal amount. We bottle them, shake them up and then pour some into the glass. No matter how much we pour, the glass will contain equal amount of both liquids. Ideas. We can decompose $[0,1]$ as $X\sqcup Y$ where $X=[0,1]\setminus\mathbb{Q}$ and $Y=[0,1]\cap\mathbb{Q}$. Here we have $\mu(X)=1$ and $\mu(Y)=0$. Maybe it's possible to describe a procedure of moving points from $X$ to $Y$ (i.e. excluding them from $X$ and including in $Y$) that will lead to desired decomposition. Another thought is to set $A_n=\bigsqcup_{k=0}^{2^{n-1}-1}[2k\cdot2^{-n},\ (2k+1)\cdot2^{-n})$ and $B_n=[0,1]\setminus A_n$ for all $n\in\mathbb{N}$. Then for any $n\in\mathbb{N}$ we'll have $A_n\sqcup B_n=[0,1]$ $\mu(A_n)=\mu(B_n)$ $|\mu(A\cap [a,b])-\mu(B\cap [a,b])|\leq 2^{-n}$ for any $[a,b]\subset[0,1]$ I wonder if we can take some kind of limit here raising $n\longrightarrow\infty$. Origin. This question arose after I read this post . It's interesting whether the condition of Riemann integrability is crucial there or we could weaken it with Lebesgue integrability. In attempts to find counterexample I thought of above mentioned decomposition. If it exists then we could define $f(x)=1$ if $x\in A$ and $f(x)=-1$ if $x\in B$. That would be our counterexample because $\int_I f\,d\mu$ would be zero for any interval $I\in[0,1]$. Generalization. Suppose $W\subset\mathbb{R}^n$ is a Lebesgue measurable set, and $\{r_i\}_{i=1}^k\subset\mathbb{R}_+$ such that $r_1+\ldots+r_k=\mu(W)$. Is it possible to choose such decomposition $A_1\sqcup\ldots\sqcup A_k=W$ that for any measurable $V\subset W$ we'd have $\mu(A_i \cap V)=r_i\cdot\frac{\mu(V)}{\mu(W)}$ for any $1\leq i\leq k$. In other words, can we uniformly ""blend"" measurable subsets of a measurable set in any proportions? It seems to me like a very interesting result, provided it's true.",,"['real-analysis', 'measure-theory', 'lebesgue-measure']"
41,Show that for any $1<p<\infty$ the set $\{ f \in L^p(\mathbb{R}) \cap L^1(\mathbb{R})\}$ where $ \int_{\mathbb{R}} f=0$ is dense in $L^p(\mathbb{R})$. [closed],Show that for any  the set  where  is dense in . [closed],1<p<\infty \{ f \in L^p(\mathbb{R}) \cap L^1(\mathbb{R})\}  \int_{\mathbb{R}} f=0 L^p(\mathbb{R}),"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Show that for any $1<p<\infty$ the set $\{ f \in L^p(\mathbb{R}) \cap L^1(\mathbb{R})\}$ where $ \int_{\mathbb{R}} f=0$ is dense in $L^p(\mathbb{R})$. Is the statement true if $\mathbb{R}$ is replaced by $[0,1]$? Also what can we say when $p=1$? Any clues? Thanks","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Show that for any $1<p<\infty$ the set $\{ f \in L^p(\mathbb{R}) \cap L^1(\mathbb{R})\}$ where $ \int_{\mathbb{R}} f=0$ is dense in $L^p(\mathbb{R})$. Is the statement true if $\mathbb{R}$ is replaced by $[0,1]$? Also what can we say when $p=1$? Any clues? Thanks",,"['real-analysis', 'measure-theory', 'lp-spaces']"
42,Prove that $\sigma(F)=\Omega$,Prove that,\sigma(F)=\Omega,"Let $F=\{A_1,...,A_n\}\subset P(X)$; $F_a=A_1^{a_1}\cap A_2^{a_2}\cap\cdots \cap A_n^{a_n}$ $ a=(a_1,...,a_n)\in \{0,1\}^n$ $$A^{a_i} = \begin{cases} A, & \text{if  } a_i=0 \\ A^c, & \text{if  } a_i=1 \end{cases}$$ Define $\Omega=\{\bigcup_{a\in D} F_a : D\subset \{0,1\}^n\}$ (by convention $\bigcup_{a\in \varnothing} F_a =\varnothing$) I need to prove that the sigma algebra generated by $F$, $\sigma(F)=\Omega$ what I have done so far: 1)$\Omega \subset \sigma(F)$: We know that $F\subset \sigma(F)$ then for all $a=(a_1,...,a_n)\in\{0,1\}^n$ $F_a\in \sigma(F)$, hence $\bigcup_{a\in D} F_a \in \sigma(F)$ 2)$\sigma(F)\subset \Omega$: for this part I wanted to prove that $\Omega$ is a sigma-algebra that contains $F$: $a) \varnothing \in \Omega$ $b)$ Since $\Omega$ is finite ($|\Omega|\le 2^{2^n}$) then we consider just finite unions: Let $A,B\in \Omega$: $$A\cup B= (\bigcup_{a\in D_1}F_a)\cup (\bigcup_{a\in D_2}F_a)=\bigcup_{a\in D_1\cup D_2}F_a\in \Omega$$ $c)$ I´m having trouble checking the complements: Let $A=\bigcup_{a\in D}F_a\in \Omega$; $A^c=(\bigcup_{a\in D}F_a)^c=\bigcap_{a\in D}F_a^c$ but from here how can I check that $A^c\in \Omega$? I would really appreciate if you can help me with this problem (I hope this question won't be marked as a duplicate)","Let $F=\{A_1,...,A_n\}\subset P(X)$; $F_a=A_1^{a_1}\cap A_2^{a_2}\cap\cdots \cap A_n^{a_n}$ $ a=(a_1,...,a_n)\in \{0,1\}^n$ $$A^{a_i} = \begin{cases} A, & \text{if  } a_i=0 \\ A^c, & \text{if  } a_i=1 \end{cases}$$ Define $\Omega=\{\bigcup_{a\in D} F_a : D\subset \{0,1\}^n\}$ (by convention $\bigcup_{a\in \varnothing} F_a =\varnothing$) I need to prove that the sigma algebra generated by $F$, $\sigma(F)=\Omega$ what I have done so far: 1)$\Omega \subset \sigma(F)$: We know that $F\subset \sigma(F)$ then for all $a=(a_1,...,a_n)\in\{0,1\}^n$ $F_a\in \sigma(F)$, hence $\bigcup_{a\in D} F_a \in \sigma(F)$ 2)$\sigma(F)\subset \Omega$: for this part I wanted to prove that $\Omega$ is a sigma-algebra that contains $F$: $a) \varnothing \in \Omega$ $b)$ Since $\Omega$ is finite ($|\Omega|\le 2^{2^n}$) then we consider just finite unions: Let $A,B\in \Omega$: $$A\cup B= (\bigcup_{a\in D_1}F_a)\cup (\bigcup_{a\in D_2}F_a)=\bigcup_{a\in D_1\cup D_2}F_a\in \Omega$$ $c)$ I´m having trouble checking the complements: Let $A=\bigcup_{a\in D}F_a\in \Omega$; $A^c=(\bigcup_{a\in D}F_a)^c=\bigcap_{a\in D}F_a^c$ but from here how can I check that $A^c\in \Omega$? I would really appreciate if you can help me with this problem (I hope this question won't be marked as a duplicate)",,"['measure-theory', 'elementary-set-theory']"
43,Uncertainty principle density argument,Uncertainty principle density argument,,"I proved the Heisenberg Uncertainty Principle for $f$ in the Schwartz space $ S(\mathbf R)$: $$ \int_{\mathbf R} |\xi \hat{f}(\xi)|^2 \int_{\mathbf R} |xf(x)|^2 dx \geq \frac{1}{(4\pi)^2} |f|_{L^2(\mathbf R)}^4. $$ Now I am having a lot of trouble extending it for $f\in L^2(\mathbf R)$. Of course we have to use density of $S(\mathbf R)$ in $L^2(\mathbf R)$ and use that $xf(x)$, $\xi\hat{f}(\xi) \in L^2(\mathbf R)$ (otherwise the inequality is trivial). But I can't think of a way of approximating everything at the same time. Any hints or suggestions? Thanks!","I proved the Heisenberg Uncertainty Principle for $f$ in the Schwartz space $ S(\mathbf R)$: $$ \int_{\mathbf R} |\xi \hat{f}(\xi)|^2 \int_{\mathbf R} |xf(x)|^2 dx \geq \frac{1}{(4\pi)^2} |f|_{L^2(\mathbf R)}^4. $$ Now I am having a lot of trouble extending it for $f\in L^2(\mathbf R)$. Of course we have to use density of $S(\mathbf R)$ in $L^2(\mathbf R)$ and use that $xf(x)$, $\xi\hat{f}(\xi) \in L^2(\mathbf R)$ (otherwise the inequality is trivial). But I can't think of a way of approximating everything at the same time. Any hints or suggestions? Thanks!",,"['real-analysis', 'measure-theory', 'fourier-analysis']"
44,Represent total variation of continuous function by integration of counting function,Represent total variation of continuous function by integration of counting function,,"$f : [a,b] \to \mathbb R$ is continuous, let $M(y)$ be the number of points $x$ in $[a,b]$ such that $f(x)=y$. prove that $M$ is Borel masurable and $\int M(y)dy$ equals the total variation of $f$ on $[a,b]$ This is an exercise in 'real analysis for graduate students'(Richard.F.Bass) At first time, I thought  $M(y)=\mu(\{x \mid f(x)=y\})$ where $\mu$ is counting measure. But I cannot find the relation between Borel measurability and $\mu(\{x \mid f(x)=y\})$ Is there anyone would help me?","$f : [a,b] \to \mathbb R$ is continuous, let $M(y)$ be the number of points $x$ in $[a,b]$ such that $f(x)=y$. prove that $M$ is Borel masurable and $\int M(y)dy$ equals the total variation of $f$ on $[a,b]$ This is an exercise in 'real analysis for graduate students'(Richard.F.Bass) At first time, I thought  $M(y)=\mu(\{x \mid f(x)=y\})$ where $\mu$ is counting measure. But I cannot find the relation between Borel measurability and $\mu(\{x \mid f(x)=y\})$ Is there anyone would help me?",,"['measure-theory', 'lebesgue-integral', 'lebesgue-measure']"
45,$n$ fold convolution tends to zero a.e. if $\|f\|_{L^1}<\infty$.,fold convolution tends to zero a.e. if .,n \|f\|_{L^1}<\infty,Let $f\geq 0$ satisfy $\int_\mathbb{R} f < 1$. Let $f_n$ be the $n$ time convolution of $f$ by itself.  Then I want to show  $f_n \rightarrow 0$ a.e. as $n\rightarrow \infty$. We can clearly obtain that $f_n \rightarrow 0$ in $L^1(\mathbb{R})$. But how to prove a.e. convergence?,Let $f\geq 0$ satisfy $\int_\mathbb{R} f < 1$. Let $f_n$ be the $n$ time convolution of $f$ by itself.  Then I want to show  $f_n \rightarrow 0$ a.e. as $n\rightarrow \infty$. We can clearly obtain that $f_n \rightarrow 0$ in $L^1(\mathbb{R})$. But how to prove a.e. convergence?,,"['real-analysis', 'measure-theory', 'lebesgue-measure', 'convolution']"
46,How to show density of 2^a 3^b,How to show density of 2^a 3^b,,"Sounds like a nice homework problem, but this actually came up in preparing a lecture for a Music class; I want to show that if you try to build a set of notes where you can go up and down octaves and perfect fifths from any note (that is, the set of notes is closed over multiplication and division by 2 & 3, essentially), you wind up with an infinite number of keys on your piano. Thinking about this, it seems ""obvious"" that this set--also describable as the rationals of the form $2^a 3^b$ where $a$ & $b$ can be positive or negative or zero--is dense in the reals. Proving it, though, is giving me fits. I feel like this should be easy. The best I've got is to think about multiplication & division by 3 as addition & subtraction in the log realm, and then to argue that if there was a neighborhood of a point that contained no other point in the set, then there would have to be a nonzero greatest common divisor of $\log2$ and $\log3$, but that no such thing can exist, because then it would be the case that $\exists$ (nonzero) $y,z . 2^y = 3^z$, which is impossible. Is there a simpler way to show this?","Sounds like a nice homework problem, but this actually came up in preparing a lecture for a Music class; I want to show that if you try to build a set of notes where you can go up and down octaves and perfect fifths from any note (that is, the set of notes is closed over multiplication and division by 2 & 3, essentially), you wind up with an infinite number of keys on your piano. Thinking about this, it seems ""obvious"" that this set--also describable as the rationals of the form $2^a 3^b$ where $a$ & $b$ can be positive or negative or zero--is dense in the reals. Proving it, though, is giving me fits. I feel like this should be easy. The best I've got is to think about multiplication & division by 3 as addition & subtraction in the log realm, and then to argue that if there was a neighborhood of a point that contained no other point in the set, then there would have to be a nonzero greatest common divisor of $\log2$ and $\log3$, but that no such thing can exist, because then it would be the case that $\exists$ (nonzero) $y,z . 2^y = 3^z$, which is impossible. Is there a simpler way to show this?",,['measure-theory']
47,Continuity of the Fourier transform of a measure,Continuity of the Fourier transform of a measure,,"If $\mu$ is a complex finite Borel measure on a separable real Hilbert space $H$ then $$x \mapsto \hat \mu (x) = \int \limits _H \Bbb e ^{\Bbb i \langle x, y \rangle } \Bbb d \mu _{(y)}$$ is continuous. This slightly reminds me of showing that the convolution of a function in $L^p$ and another one from $L^{\frac {p+1} p}$ is continuous. In this latter case, the proof was done in steps, showing things for step functions, then for linear combinations of them and finally taking a limit, but I do not know whether this approach can be mimicked here. Edit: An application of the Lebesgue dominated convergence theorem quickly proves the above. Question closed.","If $\mu$ is a complex finite Borel measure on a separable real Hilbert space $H$ then $$x \mapsto \hat \mu (x) = \int \limits _H \Bbb e ^{\Bbb i \langle x, y \rangle } \Bbb d \mu _{(y)}$$ is continuous. This slightly reminds me of showing that the convolution of a function in $L^p$ and another one from $L^{\frac {p+1} p}$ is continuous. In this latter case, the proof was done in steps, showing things for step functions, then for linear combinations of them and finally taking a limit, but I do not know whether this approach can be mimicked here. Edit: An application of the Lebesgue dominated convergence theorem quickly proves the above. Question closed.",,"['measure-theory', 'fourier-analysis', 'continuity', 'hilbert-spaces']"
48,Lebesgue-measurable function problem,Lebesgue-measurable function problem,,"I am trying to solve this exercise: Let $\phi: \mathbb R \to \mathbb R$ be a measurable function (Lebesgue-measurable) and $f:\mathbb R^2 \to \mathbb R$ defined as $f(x,y)=xy-\phi(y)$. Show the following: a) $f$ is measurable b) If $E \subset \mathbb R$ measurable, then $f^{-1}(E)$ is measurable. This is what I could do: a) If I define $h:\mathbb R^2 \to \mathbb R$ as the projection $h(x,y)=y$, then $h$ is continuous and $\phi(y)=\phi \circ h(x,y)$, if I could prove that $\phi \circ h$ is measurable, then, since $g(x,y)=xy$ is continuous and $f=g+ \phi \circ h$ is sum of measurable functions, $f$ is measurable. I couldn't show that $\phi \circ h$ is measurable, so I am not sure if my approach is the appropiate one. b) If $E$ is measurable, then $E$ can be written as $E=H \setminus Z$ with $H$ a $G_{\delta}$ set and $m(Z)=0$. The preimage is $f^{-1}(H \setminus Z)=f^{-1}(H) \setminus f^{-1}(Z)$. Since $H$ is a borel set, then it is easy to see that $f^{-1}(H)$ is measurable. I am having some difficulty trying to show that $f^{-1}(Z)$ is measurable. Since $m(Z)=0$, there exists $G$ a $G_{\delta}$ set with $Z \subset G$ and $m(G)=m(Z)=0$. The set $G$ can be written as $G=\bigcap_{k \in \mathbb N} G_k$ with $(G_k)_{k \in \mathbb N}$ decreasing, $m(G_k)<\infty$. We have $f^{-1}(Z) \subset f^{-1}(G) \subset f^{-1}(G_k)$ for all $k \in \mathbb N$. I didn't know what to do next. Any suggestions would be greatly appreciated. Thanks in advance.","I am trying to solve this exercise: Let $\phi: \mathbb R \to \mathbb R$ be a measurable function (Lebesgue-measurable) and $f:\mathbb R^2 \to \mathbb R$ defined as $f(x,y)=xy-\phi(y)$. Show the following: a) $f$ is measurable b) If $E \subset \mathbb R$ measurable, then $f^{-1}(E)$ is measurable. This is what I could do: a) If I define $h:\mathbb R^2 \to \mathbb R$ as the projection $h(x,y)=y$, then $h$ is continuous and $\phi(y)=\phi \circ h(x,y)$, if I could prove that $\phi \circ h$ is measurable, then, since $g(x,y)=xy$ is continuous and $f=g+ \phi \circ h$ is sum of measurable functions, $f$ is measurable. I couldn't show that $\phi \circ h$ is measurable, so I am not sure if my approach is the appropiate one. b) If $E$ is measurable, then $E$ can be written as $E=H \setminus Z$ with $H$ a $G_{\delta}$ set and $m(Z)=0$. The preimage is $f^{-1}(H \setminus Z)=f^{-1}(H) \setminus f^{-1}(Z)$. Since $H$ is a borel set, then it is easy to see that $f^{-1}(H)$ is measurable. I am having some difficulty trying to show that $f^{-1}(Z)$ is measurable. Since $m(Z)=0$, there exists $G$ a $G_{\delta}$ set with $Z \subset G$ and $m(G)=m(Z)=0$. The set $G$ can be written as $G=\bigcap_{k \in \mathbb N} G_k$ with $(G_k)_{k \in \mathbb N}$ decreasing, $m(G_k)<\infty$. We have $f^{-1}(Z) \subset f^{-1}(G) \subset f^{-1}(G_k)$ for all $k \in \mathbb N$. I didn't know what to do next. Any suggestions would be greatly appreciated. Thanks in advance.",,"['real-analysis', 'measure-theory', 'lebesgue-measure']"
49,"Difference between ""almost uniformly convergent"" and ""almost uniformly Cauchy""?","Difference between ""almost uniformly convergent"" and ""almost uniformly Cauchy""?",,"In Bartle's book ""The Elements of Integration"", the definitions of almost uniformly convergent and uniformly Cauchy are very similar, I can't tell the difference between them. Quote: A sequence $(f_n)$ of measurable functions is said to be almost uniformly convergent to a measurable function $f$ if for each $\delta>0$ there is a set $E_\delta$ in $\mathbf{X}$ with $\mu(E_\delta)<\delta$ such that $(f_n)$ converges uniformly to $f$ on $X\setminus E_\delta$. The sequence $(f_n)$ is said to be an almost uniformly Cauchy sequence if for every $\delta>0$ there exists a set $E_\delta$ in $\mathbf{X}$ with $\mu(E_\delta)<\delta$ such that $(f_n)$ is uniformly convergent on $X\setminus E_\delta$. What is the difference between the two definitions? Thanks!","In Bartle's book ""The Elements of Integration"", the definitions of almost uniformly convergent and uniformly Cauchy are very similar, I can't tell the difference between them. Quote: A sequence $(f_n)$ of measurable functions is said to be almost uniformly convergent to a measurable function $f$ if for each $\delta>0$ there is a set $E_\delta$ in $\mathbf{X}$ with $\mu(E_\delta)<\delta$ such that $(f_n)$ converges uniformly to $f$ on $X\setminus E_\delta$. The sequence $(f_n)$ is said to be an almost uniformly Cauchy sequence if for every $\delta>0$ there exists a set $E_\delta$ in $\mathbf{X}$ with $\mu(E_\delta)<\delta$ such that $(f_n)$ is uniformly convergent on $X\setminus E_\delta$. What is the difference between the two definitions? Thanks!",,['measure-theory']
50,A sufficient condition for almost everywhere equality,A sufficient condition for almost everywhere equality,,"Let $f,g:(0,\infty)\to \mathrm{R}$ be monotone decreasing functions. Show that if $m(\{x:f(x)>a\})=m(\{x;g(x)>a\}),\; \forall a\in \mathrm{R}$ where $m$ denotes Lebesgue measure, then $f=g~~~ a.e.$ in $(0,\infty)$. Here's how I tried to do: We need to show $m(\{x:f(x)\neq g(x)\})=0$. Since conditions for $f$ and $g$ are symmetric, it suffices to show $m(\{x:f(x)> g(x)\})=0$. To derive contradiction, assume $m(\{x:f(x)> g(x)\})>0$. Then there are $x_1, x_2$ with $x_1<x_2$ such that $[x_1,x_2]\subset \{x:f(x)> g(x)\} $. By the assumption, we have $f(x_1)\geq f(x)\geq f(x_2)$, $g(x_1)\geq g(x)\geq g(x_2)~~ {\rm and}~~ f(x)>g(x) ~~\forall x\in (x_1,x_2)$. If $f$ and $g$ were continuous and strictly decreasing, I can take a small neighborhood of a fixed $x^\star$ and argue that in that nighborhood, which is an open interval, $f(x)>f(x^\star)$ but $g(x)\leq f(x^\star)$, a contradiction. I can't think of how to prove it without these assumptions. Any comment or advise is greatly appreciated. Thank you for reading.","Let $f,g:(0,\infty)\to \mathrm{R}$ be monotone decreasing functions. Show that if $m(\{x:f(x)>a\})=m(\{x;g(x)>a\}),\; \forall a\in \mathrm{R}$ where $m$ denotes Lebesgue measure, then $f=g~~~ a.e.$ in $(0,\infty)$. Here's how I tried to do: We need to show $m(\{x:f(x)\neq g(x)\})=0$. Since conditions for $f$ and $g$ are symmetric, it suffices to show $m(\{x:f(x)> g(x)\})=0$. To derive contradiction, assume $m(\{x:f(x)> g(x)\})>0$. Then there are $x_1, x_2$ with $x_1<x_2$ such that $[x_1,x_2]\subset \{x:f(x)> g(x)\} $. By the assumption, we have $f(x_1)\geq f(x)\geq f(x_2)$, $g(x_1)\geq g(x)\geq g(x_2)~~ {\rm and}~~ f(x)>g(x) ~~\forall x\in (x_1,x_2)$. If $f$ and $g$ were continuous and strictly decreasing, I can take a small neighborhood of a fixed $x^\star$ and argue that in that nighborhood, which is an open interval, $f(x)>f(x^\star)$ but $g(x)\leq f(x^\star)$, a contradiction. I can't think of how to prove it without these assumptions. Any comment or advise is greatly appreciated. Thank you for reading.",,"['real-analysis', 'measure-theory']"
51,Product of outer measure equals outer measure of product,Product of outer measure equals outer measure of product,,"Define the outer measure $M^*$ on $\mathbb R$ by $ M^*(A) =inf\{\sum|I_k|: {I_k} $is an covering of A by open intervals $ \} $, Similarly the outer  measure $M^*$ on $\mathbb R^2$ is defined by $ M^*(A) =inf\{\sum|R_k|: {R_k} $is an covering of A by open rectangles $ \} $. Suppose $A \subset \mathbb R$,   $B \subset \mathbb R$, is it true that $ M^*(A \times B) = M^*(A)M^*(B)$? It is trivial that $ M^*(A \times B) \leq M^*(A)M^*(B)$, but I am not sure if  $ M^*(A \times B) \ge M^*(A)M^*(B)$ is ture.","Define the outer measure $M^*$ on $\mathbb R$ by $ M^*(A) =inf\{\sum|I_k|: {I_k} $is an covering of A by open intervals $ \} $, Similarly the outer  measure $M^*$ on $\mathbb R^2$ is defined by $ M^*(A) =inf\{\sum|R_k|: {R_k} $is an covering of A by open rectangles $ \} $. Suppose $A \subset \mathbb R$,   $B \subset \mathbb R$, is it true that $ M^*(A \times B) = M^*(A)M^*(B)$? It is trivial that $ M^*(A \times B) \leq M^*(A)M^*(B)$, but I am not sure if  $ M^*(A \times B) \ge M^*(A)M^*(B)$ is ture.",,"['measure-theory', 'lebesgue-measure']"
52,Outer measure of product of sets,Outer measure of product of sets,,"If  $A\subseteq R^n$ and $B\subseteq R^m$, such that $A \times B\subseteq R^{n+m}$ Prove that  $μ^{*}_{n+m}(A\times B)\leq μ^*_n(A)μ^*_m(B)$, where $μ^*_q$ is the outer measure of  $ \mathbb{R}^q $. My attempt $A⊆⋃_iA_i,B⊆⋃_jB_j $, and since  $A \times B \subseteq ⋃_{i,j}A_iB_j$ I have the inequality (because of the outer measure monotocity) that states $m^*_{n+m}(A \times B) \leq m^*_{n+m}(⋃_{i,j}A_iB_j)  $ But I don't think that is going to take me somewhere. Thanks!","If  $A\subseteq R^n$ and $B\subseteq R^m$, such that $A \times B\subseteq R^{n+m}$ Prove that  $μ^{*}_{n+m}(A\times B)\leq μ^*_n(A)μ^*_m(B)$, where $μ^*_q$ is the outer measure of  $ \mathbb{R}^q $. My attempt $A⊆⋃_iA_i,B⊆⋃_jB_j $, and since  $A \times B \subseteq ⋃_{i,j}A_iB_j$ I have the inequality (because of the outer measure monotocity) that states $m^*_{n+m}(A \times B) \leq m^*_{n+m}(⋃_{i,j}A_iB_j)  $ But I don't think that is going to take me somewhere. Thanks!",,"['measure-theory', 'inequality']"
53,a characterization of $L^p$ space,a characterization of  space,L^p,"The following question should be part of the questions I recently asked here Prove or disprove a claim related to $L^p$ space If $g \in L^p(\Omega, \lambda)$ where $\Omega$ is a bounded subset of $\mathbb{R^n}$, $p>1$ and $\lambda$ is the Lebesgue measure. By Holder's inequality, we know that for any measurable set $E \subset \Omega$, $$\int_E |g| d \lambda \le ||g||_p \lambda (E)^{\frac{p-1}{p}}$$. Now the question is, if there exits a constant C, such that for any measurable set $E \subset \Omega$, $$\int_E |g| d \lambda \le C \lambda (E)^{\frac{p-1}{p}}$$ Does this imply $g \in L^p(\Omega, \lambda)$? Here is my partial work. I tried to use the the duality of $L^q$ space by contradiction or the fact that simple functions are dense to prove this characterization, but I cannot control the constant. I think I need a powerful elementary inequality. Or maybe this characterization is not true. Any comments would be appreciated. Thanks!","The following question should be part of the questions I recently asked here Prove or disprove a claim related to $L^p$ space If $g \in L^p(\Omega, \lambda)$ where $\Omega$ is a bounded subset of $\mathbb{R^n}$, $p>1$ and $\lambda$ is the Lebesgue measure. By Holder's inequality, we know that for any measurable set $E \subset \Omega$, $$\int_E |g| d \lambda \le ||g||_p \lambda (E)^{\frac{p-1}{p}}$$. Now the question is, if there exits a constant C, such that for any measurable set $E \subset \Omega$, $$\int_E |g| d \lambda \le C \lambda (E)^{\frac{p-1}{p}}$$ Does this imply $g \in L^p(\Omega, \lambda)$? Here is my partial work. I tried to use the the duality of $L^q$ space by contradiction or the fact that simple functions are dense to prove this characterization, but I cannot control the constant. I think I need a powerful elementary inequality. Or maybe this characterization is not true. Any comments would be appreciated. Thanks!",,"['real-analysis', 'measure-theory', 'lebesgue-integral']"
54,Measure of the set of periodic points of a measure preserving map,Measure of the set of periodic points of a measure preserving map,,"Given a continuous (Lebesgue) measure preserving map $T$ from a compact convex region to itself that has an aperiodic point (i.e. a point $p$ such that $p \ne T^n(p)$ for any $n$), does the set of aperiodic points necessarily have positive measure? It can be arbitrarily small as can be seen by taking a rubber disk of radius 1 and gluing the disk of radius $1-\epsilon$ having the same center and turning the outer ring by a small irrational amount (so we are deforming only a small annulus), but can it be zero?","Given a continuous (Lebesgue) measure preserving map $T$ from a compact convex region to itself that has an aperiodic point (i.e. a point $p$ such that $p \ne T^n(p)$ for any $n$), does the set of aperiodic points necessarily have positive measure? It can be arbitrarily small as can be seen by taking a rubber disk of radius 1 and gluing the disk of radius $1-\epsilon$ having the same center and turning the outer ring by a small irrational amount (so we are deforming only a small annulus), but can it be zero?",,"['measure-theory', 'dynamical-systems']"
55,Can I use Lebesgue dominated convergence?,Can I use Lebesgue dominated convergence?,,"Calculate the following: $$\lim_{n \rightarrow \infty} \int_{0}^{\infty} \exp(−nx(\sin(x))^2)\,dx$$ my idea was using $f_n(x) = \exp(−nx(\sin(x))^2) < 1$ but $1$ is not integrable under $(0,\infty)$. I also think it is possible that dominated convergence theorem cannot be used for this particular problem. Can someone give me a hint on how to solve this? Thank you.","Calculate the following: $$\lim_{n \rightarrow \infty} \int_{0}^{\infty} \exp(−nx(\sin(x))^2)\,dx$$ my idea was using $f_n(x) = \exp(−nx(\sin(x))^2) < 1$ but $1$ is not integrable under $(0,\infty)$. I also think it is possible that dominated convergence theorem cannot be used for this particular problem. Can someone give me a hint on how to solve this? Thank you.",,"['real-analysis', 'measure-theory']"
56,Question on $L_p$ spaces involving $\lambda^n$-measure on $\mathbb{R}^n$,Question on  spaces involving -measure on,L_p \lambda^n \mathbb{R}^n,"Q/ Consider $L_p=L_p(\lambda^n)$ with the Lebesgue measure on $\mathbb{R}^n$ and $1\leq p<\infty$. Let $f_0=|x|^{-\alpha}$ for $|x|<1$ and $0$ otherwise. Show $f_0\in L_p$ iff $p\alpha < n$. Now first I have shown that $f_0$ is $\lambda^n$-measurable for all n so the question is equivalent to (by the definition of an $L_p$ space) showing $||f_0||_p=\big (\int_{\mathbb{R^n}}f_0\;d(\lambda^n)\big )^{\frac{1}{p}}<\infty$ iff $p\alpha < n$. I was thinking the way to proceed would be to look at the integral explicitly and try and evaluate it or potentially find some useful bounds; So $\big (\int_{\mathbb{R^n}}f_0\;d(\lambda^n)\big )^{\frac{1}{p}}=\big (\int_{\{x\;:\;|x|<1\}}|x|^{-\alpha}\;d(\lambda^n)\big )^{\frac{1}{p}}$ but then I am now stuck, I don't know how to compute this integral and can't find any meaningful bounds. Any help would be appreciated. Thanks","Q/ Consider $L_p=L_p(\lambda^n)$ with the Lebesgue measure on $\mathbb{R}^n$ and $1\leq p<\infty$. Let $f_0=|x|^{-\alpha}$ for $|x|<1$ and $0$ otherwise. Show $f_0\in L_p$ iff $p\alpha < n$. Now first I have shown that $f_0$ is $\lambda^n$-measurable for all n so the question is equivalent to (by the definition of an $L_p$ space) showing $||f_0||_p=\big (\int_{\mathbb{R^n}}f_0\;d(\lambda^n)\big )^{\frac{1}{p}}<\infty$ iff $p\alpha < n$. I was thinking the way to proceed would be to look at the integral explicitly and try and evaluate it or potentially find some useful bounds; So $\big (\int_{\mathbb{R^n}}f_0\;d(\lambda^n)\big )^{\frac{1}{p}}=\big (\int_{\{x\;:\;|x|<1\}}|x|^{-\alpha}\;d(\lambda^n)\big )^{\frac{1}{p}}$ but then I am now stuck, I don't know how to compute this integral and can't find any meaningful bounds. Any help would be appreciated. Thanks",,"['measure-theory', 'lebesgue-integral', 'lp-spaces', 'lebesgue-measure']"
57,Consistency strength of 0-1 valued Borel measures,Consistency strength of 0-1 valued Borel measures,,"The following is an overly fancy way of asking a question suggested in Borel Measures: Atoms vs. Point Masses Let $\phi$ be a property that topological spaces can have (such as ""compact"", ""$T_1$"", etc.) and let $M(\phi)$ be the statement ""There exists a topological space $X$ with property $\phi$, and a nontrivial, countably additive, 0-1 valued Borel measure on $X$ which is not a point mass.""  (For the purposes of this question, a measure $\mu$ is a point mass if there exists $a \in X$ such that $\mu(A) = 1$ iff $a \in A$.) For various values of $\phi$, what is the consistency strength of $M(\phi)$? A few examples: $M(\text{compact Hausdorff})$ is a theorem of ZFC (let $X = [0,\omega_1] = \omega_1+1$ with the order topology, and consider the Dieudonné measure .) $M(\text{finite discrete})$ is inconsistent with ZFC. $M(\text{separable metrizable})$ is also inconsistent with ZFC, as I show in this answer . $M(\text{discrete})$ is implied by ""there exists a measurable cardinal"", and if I understand the Wikipedia article correctly, they are actually equivalent.  It's known that this has greater consistency strength than ZFC but is not known to be inconsistent. I would be particularly interested in knowing about $M(\text{metrizable})$ and $M(\text{completely metrizable})$.","The following is an overly fancy way of asking a question suggested in Borel Measures: Atoms vs. Point Masses Let $\phi$ be a property that topological spaces can have (such as ""compact"", ""$T_1$"", etc.) and let $M(\phi)$ be the statement ""There exists a topological space $X$ with property $\phi$, and a nontrivial, countably additive, 0-1 valued Borel measure on $X$ which is not a point mass.""  (For the purposes of this question, a measure $\mu$ is a point mass if there exists $a \in X$ such that $\mu(A) = 1$ iff $a \in A$.) For various values of $\phi$, what is the consistency strength of $M(\phi)$? A few examples: $M(\text{compact Hausdorff})$ is a theorem of ZFC (let $X = [0,\omega_1] = \omega_1+1$ with the order topology, and consider the Dieudonné measure .) $M(\text{finite discrete})$ is inconsistent with ZFC. $M(\text{separable metrizable})$ is also inconsistent with ZFC, as I show in this answer . $M(\text{discrete})$ is implied by ""there exists a measurable cardinal"", and if I understand the Wikipedia article correctly, they are actually equivalent.  It's known that this has greater consistency strength than ZFC but is not known to be inconsistent. I would be particularly interested in knowing about $M(\text{metrizable})$ and $M(\text{completely metrizable})$.",,"['measure-theory', 'set-theory', 'large-cardinals']"
58,Measures which cannot be uniquely written as the sum of a purely atomic measure and a nonatomic measure,Measures which cannot be uniquely written as the sum of a purely atomic measure and a nonatomic measure,,"Maharam's theorem says that every complete measure can be written as the sum of a purely atomic measure and a nonatomic measure. According to the paper ""Atomic and Nonatomic Measures"" by R.A. Johnson, this decomposition becomes unique if we require the measure to be $\sigma$-finite. However, Johnson claims that uniqueness may not hold if we drop the $\sigma$-finite hypothesis. Is this obvious? If not, would someone please direct me to a counterexample?","Maharam's theorem says that every complete measure can be written as the sum of a purely atomic measure and a nonatomic measure. According to the paper ""Atomic and Nonatomic Measures"" by R.A. Johnson, this decomposition becomes unique if we require the measure to be $\sigma$-finite. However, Johnson claims that uniqueness may not hold if we drop the $\sigma$-finite hypothesis. Is this obvious? If not, would someone please direct me to a counterexample?",,['measure-theory']
59,Does Vitali set imply the axiom of choice,Does Vitali set imply the axiom of choice,,"I know that the construction of Vitali set needs the axiom of choice, but this only states that $AC \implies V$. Is it also true that $V \implies AC$? If $\neg AC \implies \neg V$, then what contradiction results from $\neg AC \wedge V$?","I know that the construction of Vitali set needs the axiom of choice, but this only states that $AC \implies V$. Is it also true that $V \implies AC$? If $\neg AC \implies \neg V$, then what contradiction results from $\neg AC \wedge V$?",,"['measure-theory', 'axiom-of-choice']"
60,"Exchange order of ""almost all"" quantifiers","Exchange order of ""almost all"" quantifiers",,"Is it always true that $$\forall^\star x\, \forall^\star y\,P(x,y) \Leftrightarrow \forall^\star y\, \forall^\star x\,P(x,y)$$ where $x,y$ are taken from (distinct) measure spaces, $P$ is a measurable predicate, and the $\forall^\star$ quantifier is ""almost all""? I am ok with assuming that both measure spaces are complete probability spaces. (I think it is true and follows from Tonelli's theorem, but not sure that I'm correct.)","Is it always true that $$\forall^\star x\, \forall^\star y\,P(x,y) \Leftrightarrow \forall^\star y\, \forall^\star x\,P(x,y)$$ where $x,y$ are taken from (distinct) measure spaces, $P$ is a measurable predicate, and the $\forall^\star$ quantifier is ""almost all""? I am ok with assuming that both measure spaces are complete probability spaces. (I think it is true and follows from Tonelli's theorem, but not sure that I'm correct.)",,['measure-theory']
61,"Does there exist a nowhere differentiable, everywhere continous, monotone somewhere function?","Does there exist a nowhere differentiable, everywhere continous, monotone somewhere function?",,Is there a nowhere differentiable but continuous everywhere function which is monotone in some small interval however small it is? Until now I have seen only the Weierstrass function and it seems to be oscillating everywhere.,Is there a nowhere differentiable but continuous everywhere function which is monotone in some small interval however small it is? Until now I have seen only the Weierstrass function and it seems to be oscillating everywhere.,,"['real-analysis', 'measure-theory', 'functions', 'examples-counterexamples']"
62,Composition of Borel relations,Composition of Borel relations,,"Let $X,Y,Z$ be Polish spaces, or standard Borel spaces, and let us consider two relations $A \subseteq X \times Y$ and $B \subseteq Y \times Z$ that are Borel sets. Define their composition as $$   C := \{(x,z): \; \exists y \text{ such that }(x,y)\in A \text{ and } (y,z)\in B\}. $$ Is $C$ a Borel subset of $X \times Z$? I can show that it is at least analytic.","Let $X,Y,Z$ be Polish spaces, or standard Borel spaces, and let us consider two relations $A \subseteq X \times Y$ and $B \subseteq Y \times Z$ that are Borel sets. Define their composition as $$   C := \{(x,z): \; \exists y \text{ such that }(x,y)\in A \text{ and } (y,z)\in B\}. $$ Is $C$ a Borel subset of $X \times Z$? I can show that it is at least analytic.",,"['measure-theory', 'descriptive-set-theory']"
63,Lebesgue integral of absolute value as difference goes to zero,Lebesgue integral of absolute value as difference goes to zero,,"Suppose $f\in L^1(\mathbb{R},\mu)$. Prove that $$\lim_{t\rightarrow 0}\int_\mathbb{R}|f(x)-f(x+t)|d\mu=0$$ When I see a limit like this, I want to move the limit inside the integral sign. Usually this can be done by the monotone convergence theorem or the dominated convergence theorem. But here the limit is $t\rightarrow 0$ instead of a sequence of functions with $n\rightarrow\infty$. What can we do?","Suppose $f\in L^1(\mathbb{R},\mu)$. Prove that $$\lim_{t\rightarrow 0}\int_\mathbb{R}|f(x)-f(x+t)|d\mu=0$$ When I see a limit like this, I want to move the limit inside the integral sign. Usually this can be done by the monotone convergence theorem or the dominated convergence theorem. But here the limit is $t\rightarrow 0$ instead of a sequence of functions with $n\rightarrow\infty$. What can we do?",,"['real-analysis', 'measure-theory', 'lebesgue-integral']"
64,measures on the family of locally measurable subsets,measures on the family of locally measurable subsets,,"I am contemplating over the exercise about the ways to extend a measure to a collection of locally measurable subsets. To be precise: Let $(X,\mathcal M,\mu)$ be a measure space. Assume that $\mu$ is semifinite (i.e. each measurable set of infinite measure contains measurable sets of arbitrarily large finite measure). Let $\mathcal C$ denote the collection of locally measurable subsets of $X$. (Recall that a subset $E\subseteq X$ is called locally measurable if for each $B\subseteq \mathcal M$ with $\mu(B)<\infty$, the intersection $E\cap B$ belongs to $\mathcal M$.) It can be shown that $\mathcal C$ is a $\sigma$-algebra, so one can extend measure $\mu$ from $\mathcal M$ to $\mathcal C$ in at least two different ways: for every $E\in\mathcal C$ define $\bar{\mu}(E)=\mu(E)$ if $E\in\mathcal M$ and $\bar{\mu}(E)=\infty$ if $E\notin\mathcal M$; $\underline{\mu}(E)=\sup\{\mu(B)\mid B\in\mathcal M,\, B\subseteq E\}$. One can show that each of these functions is indeed a measure on $\mathcal C$ making $(X,\mathcal C)$ a saturated measure space. The question is to give an example showing that $\bar\mu$ and $\underline\mu$ are different.","I am contemplating over the exercise about the ways to extend a measure to a collection of locally measurable subsets. To be precise: Let $(X,\mathcal M,\mu)$ be a measure space. Assume that $\mu$ is semifinite (i.e. each measurable set of infinite measure contains measurable sets of arbitrarily large finite measure). Let $\mathcal C$ denote the collection of locally measurable subsets of $X$. (Recall that a subset $E\subseteq X$ is called locally measurable if for each $B\subseteq \mathcal M$ with $\mu(B)<\infty$, the intersection $E\cap B$ belongs to $\mathcal M$.) It can be shown that $\mathcal C$ is a $\sigma$-algebra, so one can extend measure $\mu$ from $\mathcal M$ to $\mathcal C$ in at least two different ways: for every $E\in\mathcal C$ define $\bar{\mu}(E)=\mu(E)$ if $E\in\mathcal M$ and $\bar{\mu}(E)=\infty$ if $E\notin\mathcal M$; $\underline{\mu}(E)=\sup\{\mu(B)\mid B\in\mathcal M,\, B\subseteq E\}$. One can show that each of these functions is indeed a measure on $\mathcal C$ making $(X,\mathcal C)$ a saturated measure space. The question is to give an example showing that $\bar\mu$ and $\underline\mu$ are different.",,['measure-theory']
65,"Given $\mu$ the counting measure on an infinite set $\Omega$, $\lim \mu(A_n) \ne 0$","Given  the counting measure on an infinite set ,",\mu \Omega \lim \mu(A_n) \ne 0,"Problem: Let $\mu$ be the counting measure on an infinite set $\Omega$.  Prove that there is a sequence of sets $A_1 \supset A_2 \supset A_3 \dots$ such that $\bigcap A_n = \varnothing$, but $\lim_{n \to \infty} \mu(A_n) \ne 0$. Attempt :Choose a countably infinite set $\{x_i : i \in \mathbb{N} \}  = A_1 \subseteq \Omega$.   Define $A_n = \{x_i : i \ge n\}$  Then we have $A_1 \supseteq A_2 \dots$ with $\bigcap A_n = \varnothing$. However, $\mu(A_n) = \infty$ for all $n$. Does my proof look correct?","Problem: Let $\mu$ be the counting measure on an infinite set $\Omega$.  Prove that there is a sequence of sets $A_1 \supset A_2 \supset A_3 \dots$ such that $\bigcap A_n = \varnothing$, but $\lim_{n \to \infty} \mu(A_n) \ne 0$. Attempt :Choose a countably infinite set $\{x_i : i \in \mathbb{N} \}  = A_1 \subseteq \Omega$.   Define $A_n = \{x_i : i \ge n\}$  Then we have $A_1 \supseteq A_2 \dots$ with $\bigcap A_n = \varnothing$. However, $\mu(A_n) = \infty$ for all $n$. Does my proof look correct?",,"['real-analysis', 'measure-theory', 'proof-verification']"
66,Involution in $L^{1}(G)$ is isometric.,Involution in  is isometric.,L^{1}(G),"(Sorry for asking so many questions of the same type.  There is an underlying issue that I think once resolved will allow me to understand them all at once.) Let $G$ be a locally compact group, and $f\in L^{1}(G)$. I'm trying to verify that $\|f^{*}\|_{p} = \|f\|_{p}$, where the involution $*$ is defined by $f^{*}(x) = \delta(x)^{-1}\overline{f(x^{-1})}$. So my computations so far look like: \begin{eqnarray*} \int_{G}f^{*}(y)\mu(dy) &=& \int_{G}\left|\delta(y^{-1})\overline{f(y^{-1})}\right|^{p}\mu(dy)\\                         &=& \int_{G}\delta(y^{-1})^{p}\left|\overline{f(y^{-1})}\right|^{p}\mu(dy)\\ \end{eqnarray*} Here I am stuck at the central issue I am facing where the calculations stop making sense and I feel like I'm just throwing things around hoping it's true. How do I use the definition of the $\delta$ map: $$\text{the unique group homomorphism }\delta:G\to(0,\infty)\text{ such that }\\\delta(x)\mu(E) = \mu(Ex)\text{ for all Borel sets }E$$ when its argument is not independant of the variable of integration? Ted has already confirmed in his answer to: How to use the modular function of a locally compact group? that the definition of $\delta$ implies: $$\int_{G}\delta(x)f(y)\mu(dy) = \int_{G}f(y)\mu(dy\cdot x)$$ If I try to use that step in my current problem, I end up with \begin{eqnarray*} \int_{G}\delta(y^{-1})^{p}\left|\overline{f(y^{-1})}\right|^{p}\mu(dy) &=& \int_{G}\left|\overline{f(y^{-1})}\right|^{p}\mu(dy\cdot (y^{-1})^{p}) \end{eqnarray*} which I don't have any clue how to interpret, and I suspect is wrong.  What is the correct way to handle this function?  I dont know what measure to associate with the notation $\mu(dy\cdot (y^{-1})^{p})$. I think the answer to this question is what I really need to be able to finish the verifications I'm working on. Thanks to whoever can help me!","(Sorry for asking so many questions of the same type.  There is an underlying issue that I think once resolved will allow me to understand them all at once.) Let $G$ be a locally compact group, and $f\in L^{1}(G)$. I'm trying to verify that $\|f^{*}\|_{p} = \|f\|_{p}$, where the involution $*$ is defined by $f^{*}(x) = \delta(x)^{-1}\overline{f(x^{-1})}$. So my computations so far look like: \begin{eqnarray*} \int_{G}f^{*}(y)\mu(dy) &=& \int_{G}\left|\delta(y^{-1})\overline{f(y^{-1})}\right|^{p}\mu(dy)\\                         &=& \int_{G}\delta(y^{-1})^{p}\left|\overline{f(y^{-1})}\right|^{p}\mu(dy)\\ \end{eqnarray*} Here I am stuck at the central issue I am facing where the calculations stop making sense and I feel like I'm just throwing things around hoping it's true. How do I use the definition of the $\delta$ map: $$\text{the unique group homomorphism }\delta:G\to(0,\infty)\text{ such that }\\\delta(x)\mu(E) = \mu(Ex)\text{ for all Borel sets }E$$ when its argument is not independant of the variable of integration? Ted has already confirmed in his answer to: How to use the modular function of a locally compact group? that the definition of $\delta$ implies: $$\int_{G}\delta(x)f(y)\mu(dy) = \int_{G}f(y)\mu(dy\cdot x)$$ If I try to use that step in my current problem, I end up with \begin{eqnarray*} \int_{G}\delta(y^{-1})^{p}\left|\overline{f(y^{-1})}\right|^{p}\mu(dy) &=& \int_{G}\left|\overline{f(y^{-1})}\right|^{p}\mu(dy\cdot (y^{-1})^{p}) \end{eqnarray*} which I don't have any clue how to interpret, and I suspect is wrong.  What is the correct way to handle this function?  I dont know what measure to associate with the notation $\mu(dy\cdot (y^{-1})^{p})$. I think the answer to this question is what I really need to be able to finish the verifications I'm working on. Thanks to whoever can help me!",,"['measure-theory', 'harmonic-analysis']"
67,"Prove that if a particular function is measurable, then its image is a rect line [duplicate]","Prove that if a particular function is measurable, then its image is a rect line [duplicate]",,"This question already has answers here : Additivity + Measurability $\implies$ Continuity (2 answers) Closed 2 years ago . I´m really stuck with this problem of my homework. I don´t have any idea, how to begin. Let $f$ be a function, $f:\mathbb{R}\rightarrow \mathbb{R}$, such that $f(x+y)=f(x)+f(y)$ , $\forall x,y\in\mathbb{R}$. Prove that if f is Lebesgue-measurable, then there exists a $c\in\mathbb R$, such that $f(x)=cx$. I have the next idea, $\forall \alpha\in \mathbb R$, $f^{-1}((-\infty,\alpha))$, (where $f^{-1}$ denotes the preimage function) is measurable. And somehow I want to end with that the image of such set is $(-\infty,c\alpha)$. Any idea is welcome.","This question already has answers here : Additivity + Measurability $\implies$ Continuity (2 answers) Closed 2 years ago . I´m really stuck with this problem of my homework. I don´t have any idea, how to begin. Let $f$ be a function, $f:\mathbb{R}\rightarrow \mathbb{R}$, such that $f(x+y)=f(x)+f(y)$ , $\forall x,y\in\mathbb{R}$. Prove that if f is Lebesgue-measurable, then there exists a $c\in\mathbb R$, such that $f(x)=cx$. I have the next idea, $\forall \alpha\in \mathbb R$, $f^{-1}((-\infty,\alpha))$, (where $f^{-1}$ denotes the preimage function) is measurable. And somehow I want to end with that the image of such set is $(-\infty,c\alpha)$. Any idea is welcome.",,"['measure-theory', 'functional-equations']"
68,simple question from set theory/measure theory,simple question from set theory/measure theory,,"This is a simple question. On pages 5-6 of Measure Theory,Vol 1, Vladimir Bogachev he writes that: for $E=(A\cap S)\cup (B\cap (X-S))$ Now, he writes that: $X-E = ((X-A)\cap S) \cup ((X-B)\cap (X-S))$ But I don't get this expression, I get another term of $((X-B)\cap (X-A))$ i.e, $X-E =( ((X-A)\cap S) \cup ((X-B)\cap (X-S)))\cup ((X-B)\cap (X-A))$. I believe I did it correctly according to De-Morgan rules and distribution. I am puzzled...","This is a simple question. On pages 5-6 of Measure Theory,Vol 1, Vladimir Bogachev he writes that: for $E=(A\cap S)\cup (B\cap (X-S))$ Now, he writes that: $X-E = ((X-A)\cap S) \cup ((X-B)\cap (X-S))$ But I don't get this expression, I get another term of $((X-B)\cap (X-A))$ i.e, $X-E =( ((X-A)\cap S) \cup ((X-B)\cap (X-S)))\cup ((X-B)\cap (X-A))$. I believe I did it correctly according to De-Morgan rules and distribution. I am puzzled...",,"['measure-theory', 'elementary-set-theory']"
69,Derivative of $t \mapsto \Vert f+tg \Vert_p^p$,Derivative of,t \mapsto \Vert f+tg \Vert_p^p,"Suppose $(X,\mathcal A, \mu)$ is a measure space and let $f,g\in L^p(X)$ be real-valued functions, $p\in(1,+\infty)$. Let us define    $$ F:\mathbb{R} \ni t \mapsto \int_X \vert f(x)+tg(x) \vert^p d\mu = \Vert f+tg \Vert_p^p $$   Prove that $F$ is differentiable and compute $F'(0)$. Have you got any ideas? I've tried different things, quite unsuccessfully. I think that the derivability of $F$ is an application of dominated convergence theorem (but I can't see how exactly). What about $F'(0)$?  $$ \lim_{t \to 0}\frac{F(t)-F(0)}{t}=\lim_{t \to 0} \frac{\int_X \vert f+tg\vert^p-\vert f \vert^pd\mu}{t} $$ but I do not know how to go on.  Thanks in advance for your kind help.","Suppose $(X,\mathcal A, \mu)$ is a measure space and let $f,g\in L^p(X)$ be real-valued functions, $p\in(1,+\infty)$. Let us define    $$ F:\mathbb{R} \ni t \mapsto \int_X \vert f(x)+tg(x) \vert^p d\mu = \Vert f+tg \Vert_p^p $$   Prove that $F$ is differentiable and compute $F'(0)$. Have you got any ideas? I've tried different things, quite unsuccessfully. I think that the derivability of $F$ is an application of dominated convergence theorem (but I can't see how exactly). What about $F'(0)$?  $$ \lim_{t \to 0}\frac{F(t)-F(0)}{t}=\lim_{t \to 0} \frac{\int_X \vert f+tg\vert^p-\vert f \vert^pd\mu}{t} $$ but I do not know how to go on.  Thanks in advance for your kind help.",,"['measure-theory', 'lebesgue-integral']"
70,Foundations of measure theory,Foundations of measure theory,,"In measure theory one usually starts with a $\sigma$-algebra $A$ of sets and considers a measure $\mu:A\to [0,\infty]$. I'm interested in abstracting this definition to allow more general domains and codomains for the measure function. I'm aware of measures allowed to take values in $\mathbb {R}$ as well as in $\mathbb {C}$ and I'm also aware of vector valued measures. I'm not really familiar with measures having a domain that is anything but a $\sigma$-algebra of sets (except of course for finitely additive measures). So, any information or reference to work done along these lines would be greatly appreciated. Especially, for the most general case where the domain of $\mu$ is allowed to be any $\sigma$-complete lattice and the codomain is the most general kind of lattice (probably complete with some binary operation $+$) that will support a good theory. But also non so far-reaching generalizations would be great. Thanks.","In measure theory one usually starts with a $\sigma$-algebra $A$ of sets and considers a measure $\mu:A\to [0,\infty]$. I'm interested in abstracting this definition to allow more general domains and codomains for the measure function. I'm aware of measures allowed to take values in $\mathbb {R}$ as well as in $\mathbb {C}$ and I'm also aware of vector valued measures. I'm not really familiar with measures having a domain that is anything but a $\sigma$-algebra of sets (except of course for finitely additive measures). So, any information or reference to work done along these lines would be greatly appreciated. Especially, for the most general case where the domain of $\mu$ is allowed to be any $\sigma$-complete lattice and the codomain is the most general kind of lattice (probably complete with some binary operation $+$) that will support a good theory. But also non so far-reaching generalizations would be great. Thanks.",,"['reference-request', 'measure-theory', 'lattice-orders']"
71,Limit of a decreasing sequence of measurable sets.,Limit of a decreasing sequence of measurable sets.,,"Let $(X,\mathcal{A})$ be a measurable space, with measure $\mu$. Let $\{E_n\}_{n \in \mathbb{N}} \subseteq \mathcal{A}$ be a sequence of measurable sets, with $E_{n+1} \subseteq E_n, \ \forall n \in \mathbb{N}$, that is a decreasing sequence, and $\mu(E_n)=+ \infty, \ \forall n \in \mathbb{N}$. Let $E=\bigcap_{n \in \mathbb{N}} E_n$ the limit set of the sequence, $E$ is measurable for definition. Is true that $\mu(E)=+\infty$? If not in all cases, is true with $X=\mathbb{R}^{N}$, $\mathcal{A}$ the collection of Lebesgue-measurable sets, and $\mu$ the Lebesgue measure on $\mathbb{R}^N$?","Let $(X,\mathcal{A})$ be a measurable space, with measure $\mu$. Let $\{E_n\}_{n \in \mathbb{N}} \subseteq \mathcal{A}$ be a sequence of measurable sets, with $E_{n+1} \subseteq E_n, \ \forall n \in \mathbb{N}$, that is a decreasing sequence, and $\mu(E_n)=+ \infty, \ \forall n \in \mathbb{N}$. Let $E=\bigcap_{n \in \mathbb{N}} E_n$ the limit set of the sequence, $E$ is measurable for definition. Is true that $\mu(E)=+\infty$? If not in all cases, is true with $X=\mathbb{R}^{N}$, $\mathcal{A}$ the collection of Lebesgue-measurable sets, and $\mu$ the Lebesgue measure on $\mathbb{R}^N$?",,['measure-theory']
72,Positive part of the kernel,Positive part of the kernel,,"Let $(E,\mathscr E)$ be a measurable space and $Q:E\times \mathscr E\to\Bbb [-1,1]$ be a signed bounded kernel, i.e. $Q_x(\cdot)$ is a finite measure on $(E,\mathscr E)$ for any $x\in E$ and $x\mapsto Q_x(A)$ is a measurable function for any set $A\in \mathscr E$. For any fixed $x$, let the measure $Q^+_x$ be a positive part of the signed measure $Q_x$ as in Hahn-Jordan decomposition . Is it true that $Q^+$ is a kernel, i.e. is the function $x\mapsto Q_x^+(A)$ measurable for any $A\in \mathscr E$? It clearly holds if $Q$ is an integral kernel, but I am interested in the general case. Update: after three weeks and 1 bounty I decided to post this question also on MO","Let $(E,\mathscr E)$ be a measurable space and $Q:E\times \mathscr E\to\Bbb [-1,1]$ be a signed bounded kernel, i.e. $Q_x(\cdot)$ is a finite measure on $(E,\mathscr E)$ for any $x\in E$ and $x\mapsto Q_x(A)$ is a measurable function for any set $A\in \mathscr E$. For any fixed $x$, let the measure $Q^+_x$ be a positive part of the signed measure $Q_x$ as in Hahn-Jordan decomposition . Is it true that $Q^+$ is a kernel, i.e. is the function $x\mapsto Q_x^+(A)$ measurable for any $A\in \mathscr E$? It clearly holds if $Q$ is an integral kernel, but I am interested in the general case. Update: after three weeks and 1 bounty I decided to post this question also on MO",,['measure-theory']
73,Proof of An Integral Problem,Proof of An Integral Problem,,"Let $a_i >0$ for $1\le i \le n$, and let $J=(0,1) \times \dots \times (0,1)$. I want to prove : $$\int_J{1 \over x_1^{a_1}+x_2^{a_2}+ \dots+x_n^{a_n}}dx<\infty \Longleftrightarrow \sum^n_{i=1} {1 \over a_i}>1$$ It's not simple problem I think. How can I prove that? Should I use Fubini theorm?","Let $a_i >0$ for $1\le i \le n$, and let $J=(0,1) \times \dots \times (0,1)$. I want to prove : $$\int_J{1 \over x_1^{a_1}+x_2^{a_2}+ \dots+x_n^{a_n}}dx<\infty \Longleftrightarrow \sum^n_{i=1} {1 \over a_i}>1$$ It's not simple problem I think. How can I prove that? Should I use Fubini theorm?",,['measure-theory']
74,Unbounded measurable set with different inner and outer measures,Unbounded measurable set with different inner and outer measures,,"I'm working on providing a counterexample to the claim that A unbounded set $A \subset \mathbb{R}$ is Lebesgue measurable if and only if its inner and    outer measures are equal. Further, if $B$ is an unbounded measurable set that contains $A$,   then $A$ is measurable if and only if it divides $B$ cleanly. Let me clarify which definitions I'm using. Lebesgue outer measure is    $$m^*A = \inf\left\{ \sum_k |I_k| : \{I_k\} \text{ is a covering of $A$ by open intervals}\right\}$$ Lebesgue inner measure is   $$m_*A = \sup\left\{ m^*C : C\text{ is closed and }C \subset A\right\}$$ A set $E$ is Lebesgue measurable if the division $E|E^c$ of $\mathbb{R}$ is so ""clean""    that for each ""test set"" $X \subset \mathbb{R}$, we have   $$m^*X = m^*(X \cap E)+ m^*(X \cap E^c)$$ So far, I have thought that the best strategy to disprove the claim is to find an example of an unbounded measurable set that has unequal inner and outer measure. Does this seem like the right direction? Are there any example sets I should study?","I'm working on providing a counterexample to the claim that A unbounded set $A \subset \mathbb{R}$ is Lebesgue measurable if and only if its inner and    outer measures are equal. Further, if $B$ is an unbounded measurable set that contains $A$,   then $A$ is measurable if and only if it divides $B$ cleanly. Let me clarify which definitions I'm using. Lebesgue outer measure is    $$m^*A = \inf\left\{ \sum_k |I_k| : \{I_k\} \text{ is a covering of $A$ by open intervals}\right\}$$ Lebesgue inner measure is   $$m_*A = \sup\left\{ m^*C : C\text{ is closed and }C \subset A\right\}$$ A set $E$ is Lebesgue measurable if the division $E|E^c$ of $\mathbb{R}$ is so ""clean""    that for each ""test set"" $X \subset \mathbb{R}$, we have   $$m^*X = m^*(X \cap E)+ m^*(X \cap E^c)$$ So far, I have thought that the best strategy to disprove the claim is to find an example of an unbounded measurable set that has unequal inner and outer measure. Does this seem like the right direction? Are there any example sets I should study?",,"['real-analysis', 'measure-theory']"
75,Prove that this sequence does not converge pointwise almost everywhere.,Prove that this sequence does not converge pointwise almost everywhere.,,"Suppose that $f_n$ is a sequence of real measurable functions on a set $X$ of finite measure, and suppose that there is some $\epsilon$ such that for all $n\geq1$: $$m(\{x:|f_n(x)-f(x)|\}\geq\epsilon)\geq\epsilon$$ I want to show that this is false: $f_n(x)\rightarrow f(x)$ a.e. on $X$. I tried to prove the existence of a set $Y\subseteq X$ of positive measure such that $f_n(x)$ is far from $f(x)$ for all $x\in Y$. However, I only obtain sets $Y_n$ that depend on $n$ so I guess I need some stronger argument. Any help is appreciated!","Suppose that $f_n$ is a sequence of real measurable functions on a set $X$ of finite measure, and suppose that there is some $\epsilon$ such that for all $n\geq1$: $$m(\{x:|f_n(x)-f(x)|\}\geq\epsilon)\geq\epsilon$$ I want to show that this is false: $f_n(x)\rightarrow f(x)$ a.e. on $X$. I tried to prove the existence of a set $Y\subseteq X$ of positive measure such that $f_n(x)$ is far from $f(x)$ for all $x\in Y$. However, I only obtain sets $Y_n$ that depend on $n$ so I guess I need some stronger argument. Any help is appreciated!",,['measure-theory']
76,"""measurable with respect to completion"" vs ""equals a measurable function almost everywhere""?","""measurable with respect to completion"" vs ""equals a measurable function almost everywhere""?",,"Let $X$ and $Y$ be sets and let $\mathscr{M}$ (resp. $\mathscr{N}$) be a $\sigma$-algebra of subsets of $X$ (resp. $Y$). Let $f:X \to Y$ be some function. Even without any measures lying around, we can still make sense of what it means for $f$ to be measurable (ie. elements of $\mathscr{N}$ pull back to elements of $\mathscr{M}$). Now let us specify some not necessarily complete (countably additive) measure $\mu:\mathscr{M} \to [0,\infty]$. I will call a set $N \subset X$ $\mu$-null if there exists $N' \in \mathscr{M}$ such that $N \subset N'$ and $\mu(N') = 0$. Suppose I tell you that $f$ is ""$\mu$-measurable"". It seems to me there are two sensible ways to interpret this. I take the completion of the measure space $(X,\mathscr{M},\mu)$ and require that $f$ be measurable after replacing $\mathscr{M}$ with the resulting, possibly larger, $\sigma$-algebra. This is equivalent to requiring that, for all $B \in \mathscr{N}$, $f^{-1}(B) = A \cup N$ where $A \in \mathscr{M}$ and $N$ is $\mu$-null. I require that there exist some measurable function $g:X \to Y$ such that $f=g$, $\mu$-almost-everywhere (ie $\{x \in X: f(x) \neq g(x)\}$ is $\mu$-null). It isn't too hard to see that 2 implies 1. I sort of suspect the converse fails, but I can't think of a counterexample. Thoughts?","Let $X$ and $Y$ be sets and let $\mathscr{M}$ (resp. $\mathscr{N}$) be a $\sigma$-algebra of subsets of $X$ (resp. $Y$). Let $f:X \to Y$ be some function. Even without any measures lying around, we can still make sense of what it means for $f$ to be measurable (ie. elements of $\mathscr{N}$ pull back to elements of $\mathscr{M}$). Now let us specify some not necessarily complete (countably additive) measure $\mu:\mathscr{M} \to [0,\infty]$. I will call a set $N \subset X$ $\mu$-null if there exists $N' \in \mathscr{M}$ such that $N \subset N'$ and $\mu(N') = 0$. Suppose I tell you that $f$ is ""$\mu$-measurable"". It seems to me there are two sensible ways to interpret this. I take the completion of the measure space $(X,\mathscr{M},\mu)$ and require that $f$ be measurable after replacing $\mathscr{M}$ with the resulting, possibly larger, $\sigma$-algebra. This is equivalent to requiring that, for all $B \in \mathscr{N}$, $f^{-1}(B) = A \cup N$ where $A \in \mathscr{M}$ and $N$ is $\mu$-null. I require that there exist some measurable function $g:X \to Y$ such that $f=g$, $\mu$-almost-everywhere (ie $\{x \in X: f(x) \neq g(x)\}$ is $\mu$-null). It isn't too hard to see that 2 implies 1. I sort of suspect the converse fails, but I can't think of a counterexample. Thoughts?",,['measure-theory']
77,"Proving Theorem 1.16, Folland's Real Analysis","Proving Theorem 1.16, Folland's Real Analysis",,"I am confused about the proof of Theorem 1.16 in Folland's Real Analysis, in particular the two statements underlined below: In the part underlined in red, the book uses both continuity from above and from below, but in my proof I only used continuity from above. I probably make mistakes and please point it out: My attempt: Since $\mu$ is continuous from above, denote $E_n := (x, x+\frac{1}{n}]$ and $\mu(E_1) < \infty$ , then we have $\mu(\bigcap_1^{\infty} E_n) = \lim_{n\to\infty}\mu(E_n)$ , i.e., $\forall \epsilon > 0, \exists \delta > 0 $ s.t. $\mu((x, x+\delta]) < \epsilon$ . Therefore, when $x \geq 0$ : $$\mu((0, x+\delta]) - \mu((0, x]) = F(x+\delta) - F(x) < \epsilon$$ When $x<0$ : $$\mu((x, 0]) - \mu((x+\delta, 0]) = F(x+\delta) - F(x) < \epsilon$$ So $\mu$ is right-continuous. In the part underlined in blue, the book says it's evident on $\mathcal{A}$ , but I don't understand why it's only on $\mathcal{A}$ (why not evident on $\mathcal{B}_{\mathbb{R}}$ ): My attempt: $a=b$ : $$\mu((a,b]) = \mu(\emptyset) = 0 = \mu_F((a,a]) = F(a) - F(a)$$ $a<b\leq 0$ : $$\mu((a,b]) = \mu((a,0]) - \mu((b,0]) = F(b) - F(a) = \mu_F((a,b])$$ $0\leq a<b$ : $$\mu((a,b]) = \mu((0,b]) - \mu((0,a]) = F(b) - F(a) = \mu_F((a,b])$$ $a \leq 0 <b$ : $$\mu((a,b]) = \mu((a,0]) + \mu((0,b]) = F(b) - F(a) = \mu_F((a,b])$$ The above are probably my misunderstanding and please feel free to corret me. Thanks!","I am confused about the proof of Theorem 1.16 in Folland's Real Analysis, in particular the two statements underlined below: In the part underlined in red, the book uses both continuity from above and from below, but in my proof I only used continuity from above. I probably make mistakes and please point it out: My attempt: Since is continuous from above, denote and , then we have , i.e., s.t. . Therefore, when : When : So is right-continuous. In the part underlined in blue, the book says it's evident on , but I don't understand why it's only on (why not evident on ): My attempt: : : : : The above are probably my misunderstanding and please feel free to corret me. Thanks!","\mu E_n := (x, x+\frac{1}{n}] \mu(E_1) < \infty \mu(\bigcap_1^{\infty} E_n) = \lim_{n\to\infty}\mu(E_n) \forall \epsilon > 0, \exists \delta > 0  \mu((x, x+\delta]) < \epsilon x \geq 0 \mu((0, x+\delta]) - \mu((0, x]) = F(x+\delta) - F(x) < \epsilon x<0 \mu((x, 0]) - \mu((x+\delta, 0]) = F(x+\delta) - F(x) < \epsilon \mu \mathcal{A} \mathcal{A} \mathcal{B}_{\mathbb{R}} a=b \mu((a,b]) = \mu(\emptyset) = 0 = \mu_F((a,a]) = F(a) - F(a) a<b\leq 0 \mu((a,b]) = \mu((a,0]) - \mu((b,0]) = F(b) - F(a) = \mu_F((a,b]) 0\leq a<b \mu((a,b]) = \mu((0,b]) - \mu((0,a]) = F(b) - F(a) = \mu_F((a,b]) a \leq 0 <b \mu((a,b]) = \mu((a,0]) + \mu((0,b]) = F(b) - F(a) = \mu_F((a,b])",['real-analysis']
78,countable generated sigma-algebra is separable?,countable generated sigma-algebra is separable?,,"Let $X$ be a metric space and $\mathcal{B}(X)$ the Borel- $\sigma$ -algebra. Assume that $\mathcal{B}(X)$ is countably generated, i.e. there exists $\mathcal{C} \subset \mathcal{B}(X)$ countable such that $\sigma(\mathcal{C})=\mathcal{B}(X)$ . Does this imply that $X$ is second countable and therfore separable?","Let be a metric space and the Borel- -algebra. Assume that is countably generated, i.e. there exists countable such that . Does this imply that is second countable and therfore separable?",X \mathcal{B}(X) \sigma \mathcal{B}(X) \mathcal{C} \subset \mathcal{B}(X) \sigma(\mathcal{C})=\mathcal{B}(X) X,[]
79,$\phi \in L^1 \iff m(\{\phi \neq 0\})<\infty$,,\phi \in L^1 \iff m(\{\phi \neq 0\})<\infty,"Let $\phi$ be a positive, simple, function. Prove $\phi \in L^1 \iff m(\{\phi \neq 0\})<\infty$ . My attempt: $(\iff)$ $\{\phi \neq 0\}=\{\phi >0\}\cup \{\phi <0\}.$ Suppose $\phi :E\to [0,+\infty),$ then $\int_{E}\phi \:dμ =\int_{\{\phi >0\}\cup \{\phi <0\}\cup \{\phi = 0\}}\phi \:dμ= \int_{\{\phi >0\}}\phi \:dμ+\int_{\{\phi <0\}}\phi \:dμ+ \int_{\{\phi =0\}}\phi \:dμ.$ $\phi $ is integrable at $\{\phi =0\}$ , so in order to $\phi \in L^1(E)$ it must be that $\int_{\{\phi >0\}}\phi \:dμ< \infty$ and $\int_{\{\phi <0\}}\phi \:dμ<\infty,$ but because $\phi$ is simple ( $\int_{\{\phi >0\}}\phi \:dμ =\sum a_im(\{\phi >0\})$ that means $m(\{\phi <0\})<\infty $ , $m(\{\phi >0\})<\infty \Rightarrow m(\{\phi \neq 0\})<\infty$ .","Let be a positive, simple, function. Prove . My attempt: Suppose then is integrable at , so in order to it must be that and but because is simple ( that means , .","\phi \phi \in L^1 \iff m(\{\phi \neq 0\})<\infty (\iff) \{\phi \neq 0\}=\{\phi >0\}\cup \{\phi <0\}. \phi :E\to [0,+\infty), \int_{E}\phi \:dμ =\int_{\{\phi >0\}\cup \{\phi <0\}\cup \{\phi = 0\}}\phi \:dμ=
\int_{\{\phi >0\}}\phi \:dμ+\int_{\{\phi <0\}}\phi \:dμ+ \int_{\{\phi =0\}}\phi \:dμ. \phi  \{\phi =0\} \phi \in L^1(E) \int_{\{\phi >0\}}\phi \:dμ< \infty \int_{\{\phi <0\}}\phi \:dμ<\infty, \phi \int_{\{\phi >0\}}\phi \:dμ =\sum a_im(\{\phi >0\}) m(\{\phi <0\})<\infty  m(\{\phi >0\})<\infty \Rightarrow m(\{\phi \neq 0\})<\infty","['real-analysis', 'measure-theory', 'solution-verification']"
80,How can we prove $\int_a^bf\:{\rm d}g=\int_a^bf(s)g'(s)\:{\rm d}s$ if $g'$ is not continuous?,How can we prove  if  is not continuous?,\int_a^bf\:{\rm d}g=\int_a^bf(s)g'(s)\:{\rm d}s g',"Let $a,b\in\mathbb R$ with $a<b$ , $$\mathcal D_{[a,\:b]}:=\{(t_0,\ldots,t_k):k\in\mathbb N\text{ and }a=t_0<\cdots<t_k\}$$ and $$\mathcal T_\varsigma:=\{(\tau_1,\ldots,\tau_k):\tau_i\in[t_{i-1},t_i]\text{ for all }i\in\{1,\ldots,k\}\}\;\;\;\text{for }\varsigma=(t_0,\ldots,t_k)\in\mathcal D_{[a,\:b]}.$$ Moreover, let $f:[a,b]\to\mathbb R$ be continuous and $g:[a,b]\to\mathbb R$ be of bounded variation. We can show that $$\int_a^bf\:{\rm d}g:=\lim_{\substack{|\varsigma|\to0+\\\varsigma\in\mathcal D_{[a,\:b]}\\\tau\in\mathcal T_\varsigma}}S_{\varsigma,\:\tau}(f,g)$$ is well-defined, where $$|\varsigma|:=\max_{1\le i\le k}(t_i-t_{i-1})\;\;\;\text{for }\varsigma=(t_0,\ldots,t_k)\in\mathcal D_{[a,\:b]}$$ and $$S_{\varsigma,\:\tau}(f,g):=\sum_{i=1}^kf(\tau_i)(g(t_i)-g(t_{i-1}))\;\;\;\text{for }\varsigma=(t_0,\ldots,t_k)\in\mathcal D_{[a,\:b]}\text{ and }\tau\in\mathcal T_\varsigma.$$ Assuming that $g$ is differentiable (not necessarily continuously differentiable), are we able to show that $$\int_a^bf\:{\rm d}g=\int_a^bf(s)g'(s)\:{\rm d}s\tag1?$$ Let $\varsigma=(t_0,\ldots,t_k)\in\mathcal D_{[a,\:b]}$ . By the mean value theorem, there is a $\tau\in\mathcal T_\varsigma$ with $$S_{\varsigma,\:\tau}(f,g)=\sum_{i=1}^kf(\tau_i)g'(\tau_i)(t_i-t_{i-1})=S_{\varsigma,\:\tau}(fg',\operatorname{id}_{[a,\:b]})\tag2,$$ but does the right-hand side tend to the right-hand side of $(1)$ as $|\varsigma|\to0+$ ? This is clearly the case when $g'$ is continuous though ...","Let with , and Moreover, let be continuous and be of bounded variation. We can show that is well-defined, where and Assuming that is differentiable (not necessarily continuously differentiable), are we able to show that Let . By the mean value theorem, there is a with but does the right-hand side tend to the right-hand side of as ? This is clearly the case when is continuous though ...","a,b\in\mathbb R a<b \mathcal D_{[a,\:b]}:=\{(t_0,\ldots,t_k):k\in\mathbb N\text{ and }a=t_0<\cdots<t_k\} \mathcal T_\varsigma:=\{(\tau_1,\ldots,\tau_k):\tau_i\in[t_{i-1},t_i]\text{ for all }i\in\{1,\ldots,k\}\}\;\;\;\text{for }\varsigma=(t_0,\ldots,t_k)\in\mathcal D_{[a,\:b]}. f:[a,b]\to\mathbb R g:[a,b]\to\mathbb R \int_a^bf\:{\rm d}g:=\lim_{\substack{|\varsigma|\to0+\\\varsigma\in\mathcal D_{[a,\:b]}\\\tau\in\mathcal T_\varsigma}}S_{\varsigma,\:\tau}(f,g) |\varsigma|:=\max_{1\le i\le k}(t_i-t_{i-1})\;\;\;\text{for }\varsigma=(t_0,\ldots,t_k)\in\mathcal D_{[a,\:b]} S_{\varsigma,\:\tau}(f,g):=\sum_{i=1}^kf(\tau_i)(g(t_i)-g(t_{i-1}))\;\;\;\text{for }\varsigma=(t_0,\ldots,t_k)\in\mathcal D_{[a,\:b]}\text{ and }\tau\in\mathcal T_\varsigma. g \int_a^bf\:{\rm d}g=\int_a^bf(s)g'(s)\:{\rm d}s\tag1? \varsigma=(t_0,\ldots,t_k)\in\mathcal D_{[a,\:b]} \tau\in\mathcal T_\varsigma S_{\varsigma,\:\tau}(f,g)=\sum_{i=1}^kf(\tau_i)g'(\tau_i)(t_i-t_{i-1})=S_{\varsigma,\:\tau}(fg',\operatorname{id}_{[a,\:b]})\tag2, (1) |\varsigma|\to0+ g'","['real-analysis', 'measure-theory', 'riemann-integration', 'stieltjes-integral']"
81,Is the category of measurable spaces MONOIDAL closed? (fake-proof),Is the category of measurable spaces MONOIDAL closed? (fake-proof),,"As discussed on MathOverflow , there is a preprint on ArXiv that claims the category of measurable spaces is monoidal closed (in particular that exponential objects $Y^X$ always exist and have measurable evaluation maps $X \times Y^X \to Y$ ). Also as discussed in the same post , such a claim appears to contradict results by Robert Aumann that exponential objects do not always exist in the category of measurable spaces (i.e. there exists no $\sigma$ -algebra on $Y^X$ for which the evaluation map $X \times Y^X \to Y$ is measurable). So the claim is likely to be false. I have been scrutinizing the preprint and I think I may have identified the error in the argument. Am I correct? Or is the claim actually true? High-level overview of my argument: Because $\sigma$ -algebras are only closed under countable operations, rather than arbitrary ones, it is easier for $\sigma$ -algebras that make all members of a certain class of functions measurable to not exist? (And therefore easier for there to not be any initial or final $\sigma$ -algebras generated by those functions?) Cf. this comment on the MathOverflow post . I.e. in contrast to the situation with topologies, which are closed under arbitrary unions, which makes it easier to guarantee that there always exists some topology for which a collection of functions is measurable? (Thus allowing the existence of initial or final topologies.) Details of attempted disproof: The main issue seems to be that the preprint uses a non-standard definition for the $\sigma$ -algebra on the Cartesian product of two measurable spaces $X \times Y$ when defining the monoidal product $X \otimes Y$ : The coinduced (final) $\sigma$ -algebra [on $X \times Y$ ] such that all graph functions $$\begin{array}{rccl}  \Gamma_f: & X  &\to & X \times Y \\ & x & \mapsto & (x, f(x))  \end{array}$$ for $f: X \to Y$ measurable, as well as all the graph functions $$\begin{array}{rccl}  \Gamma_g: & Y  &\to & X \times Y \\ & y & \mapsto & (g(y), y)  \end{array}$$ for $g: Y \to X$ measurable, are measurable. Main question : The above $\sigma$ -algebra isn't even guaranteed to exist in general, correct? Asides/extra questions/comments: Normally the product $\sigma$ -algebra would be defined as the induced (initial) $\sigma$ -algebra such that the projections $(x,y) \mapsto x$ and $(x,y) \mapsto y$ are measurable, right? In particular the definition from the preprint, and the standard definition, are not always equivalent, correct? ( As an aside, are they ever equivalent? ) I can go into the details of how the preprint then defines the initial topology on $Y^X$ generated by the pointwise projections/evaluations, and from there the argument for why the evaluation map $X \otimes Y^X = X \times Y^X \to Y$ is measurable, but if the above topology isn't even guaranteed to exist, then the argument definitely seems to fail. (With Robert Aumann providing a counterexample in the case that $X = Y = [0,1]$ .) Terminology: By ""initial $\sigma$ -algebra"" on $X$ generated by functions $f_{\alpha}: X \to Y$ , with $Y$ a measurable space, I mean the ""coarsest"" or ""smallest"" possible $\sigma$ -algebra on $X$ such that all of the $\{f_{\alpha}\}$ are measurable. By ""final $\sigma$ -algebra on $Y$ generated by functions $f_{\alpha}: X \to Y$ , with $X$ a measurable space, I mean the ""finest"" or ""largest"" possible $\sigma$ -algebra on $Y$ such that all of the $\{f_{\alpha}\}$ are measurable. (I guess technically one could also require that $\{f_{\beta}\}$ for $f_{\beta}: X_2 \to Y$ are measurable for $X_2$ a measurable space, which is what the preprint appears to do.)","As discussed on MathOverflow , there is a preprint on ArXiv that claims the category of measurable spaces is monoidal closed (in particular that exponential objects always exist and have measurable evaluation maps ). Also as discussed in the same post , such a claim appears to contradict results by Robert Aumann that exponential objects do not always exist in the category of measurable spaces (i.e. there exists no -algebra on for which the evaluation map is measurable). So the claim is likely to be false. I have been scrutinizing the preprint and I think I may have identified the error in the argument. Am I correct? Or is the claim actually true? High-level overview of my argument: Because -algebras are only closed under countable operations, rather than arbitrary ones, it is easier for -algebras that make all members of a certain class of functions measurable to not exist? (And therefore easier for there to not be any initial or final -algebras generated by those functions?) Cf. this comment on the MathOverflow post . I.e. in contrast to the situation with topologies, which are closed under arbitrary unions, which makes it easier to guarantee that there always exists some topology for which a collection of functions is measurable? (Thus allowing the existence of initial or final topologies.) Details of attempted disproof: The main issue seems to be that the preprint uses a non-standard definition for the -algebra on the Cartesian product of two measurable spaces when defining the monoidal product : The coinduced (final) -algebra [on ] such that all graph functions for measurable, as well as all the graph functions for measurable, are measurable. Main question : The above -algebra isn't even guaranteed to exist in general, correct? Asides/extra questions/comments: Normally the product -algebra would be defined as the induced (initial) -algebra such that the projections and are measurable, right? In particular the definition from the preprint, and the standard definition, are not always equivalent, correct? ( As an aside, are they ever equivalent? ) I can go into the details of how the preprint then defines the initial topology on generated by the pointwise projections/evaluations, and from there the argument for why the evaluation map is measurable, but if the above topology isn't even guaranteed to exist, then the argument definitely seems to fail. (With Robert Aumann providing a counterexample in the case that .) Terminology: By ""initial -algebra"" on generated by functions , with a measurable space, I mean the ""coarsest"" or ""smallest"" possible -algebra on such that all of the are measurable. By ""final -algebra on generated by functions , with a measurable space, I mean the ""finest"" or ""largest"" possible -algebra on such that all of the are measurable. (I guess technically one could also require that for are measurable for a measurable space, which is what the preprint appears to do.)","Y^X X \times Y^X \to Y \sigma Y^X X \times Y^X \to Y \sigma \sigma \sigma \sigma X \times Y X \otimes Y \sigma X \times Y \begin{array}{rccl}
 \Gamma_f: & X  &\to & X \times Y \\
& x & \mapsto & (x, f(x))
 \end{array} f: X \to Y \begin{array}{rccl}
 \Gamma_g: & Y  &\to & X \times Y \\
& y & \mapsto & (g(y), y)
 \end{array} g: Y \to X \sigma \sigma \sigma (x,y) \mapsto x (x,y) \mapsto y Y^X X \otimes Y^X = X \times Y^X \to Y X = Y = [0,1] \sigma X f_{\alpha}: X \to Y Y \sigma X \{f_{\alpha}\} \sigma Y f_{\alpha}: X \to Y X \sigma Y \{f_{\alpha}\} \{f_{\beta}\} f_{\beta}: X_2 \to Y X_2","['measure-theory', 'solution-verification', 'category-theory', 'fake-proofs', 'measurable-functions']"
82,Fattened volume of a curve,Fattened volume of a curve,,"Let $\gamma:[0,1] \rightarrow \mathbb{R}^3$ be a smooth curve with nonvanishing velocity and let $C_\gamma = \gamma([0,1])$ be the image. Denote by $B_r = \{ x : \|x\| < r \}$ the open ball of radius $r$ centered at the origin. Then I expect the following to hold: $$\lim_{r \rightarrow 0} \frac1{r^2} \mathcal{H}^3 (C_\gamma + B_r) = \pi \cdot \mathcal{H}^1(C_\gamma)$$ where $A + B = \{ x+y : x \in A, y \in B \}$ is the Minkowski sum of two sets $A, B$ and $\mathcal{H}^d(A)$ is the $d$ -dimensional Hausdorff measure of $d$ . The above setup can be easily generalised by replacing a curve with a $d$ -dimensional embedded submanifold $M$ with boundary and by replacing $\mathbb R^3$ by $\mathbb R^D$ : $$\lim_{r \rightarrow 0} \frac1{r^{D-d}} \mathcal{H}^D (M + B_r) =  \omega_{D-d} \cdot \mathcal{H}^d(M)$$ with $\omega_k = \pi^{k/2}/\Gamma(\frac k2 + 1)$ being the volume of the $k$ -dimensional unit ball. Does anyone know if this type of result was proven elsewhere before?",Let be a smooth curve with nonvanishing velocity and let be the image. Denote by the open ball of radius centered at the origin. Then I expect the following to hold: where is the Minkowski sum of two sets and is the -dimensional Hausdorff measure of . The above setup can be easily generalised by replacing a curve with a -dimensional embedded submanifold with boundary and by replacing by : with being the volume of the -dimensional unit ball. Does anyone know if this type of result was proven elsewhere before?,"\gamma:[0,1] \rightarrow \mathbb{R}^3 C_\gamma = \gamma([0,1]) B_r = \{ x : \|x\| < r \} r \lim_{r \rightarrow 0} \frac1{r^2} \mathcal{H}^3 (C_\gamma + B_r) = \pi \cdot \mathcal{H}^1(C_\gamma) A + B = \{ x+y : x \in A, y \in B \} A, B \mathcal{H}^d(A) d d d M \mathbb R^3 \mathbb R^D \lim_{r \rightarrow 0} \frac1{r^{D-d}} \mathcal{H}^D (M + B_r) =  \omega_{D-d} \cdot \mathcal{H}^d(M) \omega_k = \pi^{k/2}/\Gamma(\frac k2 + 1) k","['measure-theory', 'differential-geometry', 'convex-geometry']"
83,"If $U_1,U_2,\dots$ are open subsets of $[0,1]$, then either prove or disprove the statements","If  are open subsets of , then either prove or disprove the statements","U_1,U_2,\dots [0,1]","Suppose $U_1,U_2,\dots$ are open subsets of $[0,1]$ . In each case, either prove the statement or disprove it. (a) If $m(\cap_{n=1}^\infty U_n)=0$ , then for some $n ≥ 1$ , we have $m(\overline{U_n})<1$ , where $m$ is Lebesgue measure and $\overline{U_n}$ is the closure of $U_n$ in the usual topology on $[0, 1]$ . (b) If $\cap_{n=1}^\infty U_n = \emptyset$ , then for some $n\geq 1$ , the set $[0,1] \setminus U_n$ contains a nonempty open interval. Thoughts . I think (a) is FALSE. i.e we can produce some open subsets $U_n$ such that $m(\cap_{n=1}^\infty U_n)=0$ and $m(\overline{U_n})=1$ For (b) I think it is TRUE. Suppose not. i.e. For each $n\geq 1$ if the closed set $[0,1]\setminus U_n$ does not contain a nonempty open interval then $m([0,1]\setminus U_n)=0$ , so $m(U_n)=m([0,1])=1$ for all $n\geq 1$ . So $\cap_{n=1}^\infty U_n\neq \emptyset$ , contradiction. I feel that I skip some details. Thanks for any comments/ideas/answers.","Suppose are open subsets of . In each case, either prove the statement or disprove it. (a) If , then for some , we have , where is Lebesgue measure and is the closure of in the usual topology on . (b) If , then for some , the set contains a nonempty open interval. Thoughts . I think (a) is FALSE. i.e we can produce some open subsets such that and For (b) I think it is TRUE. Suppose not. i.e. For each if the closed set does not contain a nonempty open interval then , so for all . So , contradiction. I feel that I skip some details. Thanks for any comments/ideas/answers.","U_1,U_2,\dots [0,1] m(\cap_{n=1}^\infty U_n)=0 n ≥ 1 m(\overline{U_n})<1 m \overline{U_n} U_n [0, 1] \cap_{n=1}^\infty U_n = \emptyset n\geq 1 [0,1] \setminus U_n U_n m(\cap_{n=1}^\infty U_n)=0 m(\overline{U_n})=1 n\geq 1 [0,1]\setminus U_n m([0,1]\setminus U_n)=0 m(U_n)=m([0,1])=1 n\geq 1 \cap_{n=1}^\infty U_n\neq \emptyset","['real-analysis', 'measure-theory']"
84,"Prove that if $A\subset S^{n-1}$ with $\mu(A) = \frac12$, then $\mu(A_\epsilon) \ge 1 - e^{-n\epsilon^2/2}$","Prove that if  with , then",A\subset S^{n-1} \mu(A) = \frac12 \mu(A_\epsilon) \ge 1 - e^{-n\epsilon^2/2},"Background : On Pg. $44$ of these notes , it is stated that: In the case of a sphere $\Omega = S^{n-1}$ , we have the following pair of properties. If $A\subset\Omega$ with $\mu(A) = \frac12$ , then $\mu(A_\epsilon) \ge 1 - e^{-n\epsilon^2/2}$ . If $f:\Omega\to\mathbb R$ is $1$ -Lipschitz there is a number $M$ for which $$\mu(|f-M| > \epsilon) \le 2e^{-n\epsilon^2/2}$$ We have seen how the second can be deduced from the first. The reverse implication also holds (apart from the precise constants involved). To see why, apply the second property to the function given by $f(x) = d(x,A)$ . Theme of this post: I need help deducing $(1)$ from $(2)$ . Notation: $S^{n-1}$ is the Euclidean sphere of unit radius in $\mathbb R^n$ . $\mu$ refers to the rotation invariant probability measure on the sphere $S^{n-1}$ . The measure of the entire sphere is $1$ , that of a hemisphere is $\frac12$ , etc. $d(x,A) = \inf\{\|x-y\|: y\in A\}$ where $A \subset\mathbb R^n$ is compact and $x \in \mathbb R^n$ . A function $f: S^{n-1}\to\mathbb R$ is $1$ -Lipschitz, if for any $x,y\in S^{n-1}$ , $$\|f(x) - f(y)\| \le \|x-y\|$$ $A_\epsilon$ is the $\epsilon$ -thickening (or neighborhood) of $A$ , that is $A_\epsilon = A + \epsilon B^n_2$ where $B^n_2 = \{x: \|x\| \le 1\}$ . My thoughts: The author suggests to put $f(x) = d(x,A)$ in $(2)$ . First we would have to check that this function is $1$ -Lipschitz. Consider $x,y\in S^{n-1}$ , i.e. $\|x\|=  \|y\| = 1$ and $A$ , a compact subset of $S^{n-1}$ . Thanks to @OliverDiaz's comment, I now see that $$|d(x,A) - d(y,A)| \le \|x- y\|$$ Consider $a\in A$ , then $d(x,A)\le \|x-a\| \le \|x-y\| + \|y-a\|$ . So, $d(x,A) - \|x-y\|\le \|y-a\|$ . Taking $\inf_{a\in A}$ , we have $d(x,A) - d(y,A) \le \|x-y\|$ . Interchanging $x$ and $y$ , we get $d(y,A) - d(x,A) \le \|x-y\|$ and hence the required inequality. Since $f = d(\cdot, A)$ is Lipschitz, there is some $M$ for which $$\mu(|d(\cdot, A)-M| > \epsilon) \le 2e^{-n\epsilon^2/2}$$ i.e. $$\mu(|d(\cdot, A)-M| \le  \epsilon) \ge 1 - 2e^{-n\epsilon^2/2}$$ It is easy to check that $A_\epsilon = \{x: d(x,A) \le \epsilon\}$ . Due to the similarity in expression of what I have arrived at, and what I need to prove - I think I'm pretty close, but don't know what to do next. Thank you!","Background : On Pg. of these notes , it is stated that: In the case of a sphere , we have the following pair of properties. If with , then . If is -Lipschitz there is a number for which We have seen how the second can be deduced from the first. The reverse implication also holds (apart from the precise constants involved). To see why, apply the second property to the function given by . Theme of this post: I need help deducing from . Notation: is the Euclidean sphere of unit radius in . refers to the rotation invariant probability measure on the sphere . The measure of the entire sphere is , that of a hemisphere is , etc. where is compact and . A function is -Lipschitz, if for any , is the -thickening (or neighborhood) of , that is where . My thoughts: The author suggests to put in . First we would have to check that this function is -Lipschitz. Consider , i.e. and , a compact subset of . Thanks to @OliverDiaz's comment, I now see that Consider , then . So, . Taking , we have . Interchanging and , we get and hence the required inequality. Since is Lipschitz, there is some for which i.e. It is easy to check that . Due to the similarity in expression of what I have arrived at, and what I need to prove - I think I'm pretty close, but don't know what to do next. Thank you!","44 \Omega = S^{n-1} A\subset\Omega \mu(A) = \frac12 \mu(A_\epsilon) \ge 1 - e^{-n\epsilon^2/2} f:\Omega\to\mathbb R 1 M \mu(|f-M| > \epsilon) \le 2e^{-n\epsilon^2/2} f(x) = d(x,A) (1) (2) S^{n-1} \mathbb R^n \mu S^{n-1} 1 \frac12 d(x,A) = \inf\{\|x-y\|: y\in A\} A \subset\mathbb R^n x \in \mathbb R^n f: S^{n-1}\to\mathbb R 1 x,y\in S^{n-1} \|f(x) - f(y)\| \le \|x-y\| A_\epsilon \epsilon A A_\epsilon = A + \epsilon B^n_2 B^n_2 = \{x: \|x\| \le 1\} f(x) = d(x,A) (2) 1 x,y\in S^{n-1} \|x\|=  \|y\| = 1 A S^{n-1} |d(x,A) - d(y,A)| \le \|x- y\| a\in A d(x,A)\le \|x-a\| \le \|x-y\| + \|y-a\| d(x,A) - \|x-y\|\le \|y-a\| \inf_{a\in A} d(x,A) - d(y,A) \le \|x-y\| x y d(y,A) - d(x,A) \le \|x-y\| f = d(\cdot, A) M \mu(|d(\cdot, A)-M| > \epsilon) \le 2e^{-n\epsilon^2/2} \mu(|d(\cdot, A)-M| \le  \epsilon) \ge 1 - 2e^{-n\epsilon^2/2} A_\epsilon = \{x: d(x,A) \le \epsilon\}","['real-analysis', 'measure-theory', 'convex-geometry']"
85,Folland Exercise 7.18 on Radon measure,Folland Exercise 7.18 on Radon measure,,"I'm trying to do the exercise below. 18. If $\mu$ is a $\sigma$ -finite Radon measure on $X$ and $\nu \in \mathcal{M}(X)$ , let $\nu=\nu_1+\nu_2$ be the Lebesgue decomposition of $\nu$ with respect to $\mu$ . Then $\nu_1$ and $\nu_2$ are Radon. (Use Exercise 8.) Also, can we say that $\| v\| = \|v_1\| + \| v_2\|$ ? Here $M(X)$ is the space of complex Radon measures on $X$ , and if $\mu \in M(X)$ , we define $\|\mu \| = |\mu|(X)$ , where $|\mu|$ is the total variation of $\mu$ . I know that by Lebesgue decomposition we have $v_1 \ll \mu$ and $v_2 \perp \mu$ . By the Radon- Nikodym theorem,  there exists some $f \in L^+$ such that $v_1(E) = \int_E f d\mu$ for $E \in B_X.$ By exercise 8, we have $v_1$ is Radon. But from here, I'm not sure how to proceed. Any help will be appreciated! Thank you.","I'm trying to do the exercise below. 18. If is a -finite Radon measure on and , let be the Lebesgue decomposition of with respect to . Then and are Radon. (Use Exercise 8.) Also, can we say that ? Here is the space of complex Radon measures on , and if , we define , where is the total variation of . I know that by Lebesgue decomposition we have and . By the Radon- Nikodym theorem,  there exists some such that for By exercise 8, we have is Radon. But from here, I'm not sure how to proceed. Any help will be appreciated! Thank you.",\mu \sigma X \nu \in \mathcal{M}(X) \nu=\nu_1+\nu_2 \nu \mu \nu_1 \nu_2 \| v\| = \|v_1\| + \| v_2\| M(X) X \mu \in M(X) \|\mu \| = |\mu|(X) |\mu| \mu v_1 \ll \mu v_2 \perp \mu f \in L^+ v_1(E) = \int_E f d\mu E \in B_X. v_1,"['measure-theory', 'radon-nikodym']"
86,Sets of infinite Hausdorff dimension in a second countable metric space,Sets of infinite Hausdorff dimension in a second countable metric space,,I am wondering if there exists an example of a second countable metric space $X$ containing a set $A$ with infinite Hausdorff dimension.,I am wondering if there exists an example of a second countable metric space containing a set with infinite Hausdorff dimension.,X A,"['measure-theory', 'metric-spaces', 'hausdorff-measure', 'dimension-theory-analysis']"
87,Proving $\lim\limits_{N\to\infty}\mu\Bigl(\bigcup\limits_{n=N}^\infty(E\setminus E_n)\Bigr)=0$,Proving,\lim\limits_{N\to\infty}\mu\Bigl(\bigcup\limits_{n=N}^\infty(E\setminus E_n)\Bigr)=0,"Let $E$ be a measurable set of $\mathbb{R}$ , and the characteristic function of a subset $A$ of $E$ is a function $$\mathbf1_A:X\to\{0,1\}$$ defined as $$\mathbf1_A(x):=\begin{cases}1&\text{ if }x\in A\\0&\text{ if }x\notin A\end{cases}.$$ Now let $\{E_{n}: n \in \mathbb{N}^+\} \subseteq E$ be a collection of subset of $E$ . Show that 1. The sequence $\{\mathbf{1}_{E_n}(x)\}$ uniformly converges to $\mathbf{1}_{E}(x)$ if and only if $\exists N \in \mathbb{N}^+$ , $\forall n \geq N$ such that $E=E_n$ . $\{\mathbf{1}_{E_n}(x)\}$ converges almost uniformly to $\mathbf{1}_{E}(x)$ if and only if $$\lim _{N \rightarrow \infty}\mu\left(\bigcup_{n=N}^\infty \left(E \backslash E_{n}\right)\right)=0,$$ where $\mu (⋅)$ denotes the Lebesgue measure. 3.The sequence $\{\mathbf{1}_{E_n}(x)\}$ converges to $\mathbf{1}_{E}(x)$ a.e.  iff $$\mu\left(\bigcap_{N=1}^\infty \bigcup_{n=N}^\infty \left(E \backslash E_{n}\right)\right)=0.$$ My attempt: 1: $\Longleftarrow$ it is quite obvious. $\Longrightarrow$ there exists a natural number $N$ such that $|\mathbf{1}_{E_n}(x)-\mathbf{1}_{E}(x)|<\epsilon$ for all $n \geq N$ and $x \in E$ , namely $|\mathbf{1}_{E_n}(x)-\mathbf{1}_{E}(x)|=0$ . Thus we obtain $E=E_n$ for all $n \geq N$ and $x \in E$ . 2: $\Longrightarrow$ By definition of almost uniformly, we have for every $\delta>0$ there exists a measurable set $E_{\delta}$ with measure less than $\delta$ such that $\{E_{n}: n \in \mathbb{N}^+\} $ converges to $\mathbf{1}_{E}(x)$ uniformly on $E \backslash E_{\delta}$ . I'm completely stuck on how to  proceed. Any help and comments  will be appreciated.","Let be a measurable set of , and the characteristic function of a subset of is a function defined as Now let be a collection of subset of . Show that 1. The sequence uniformly converges to if and only if , such that . converges almost uniformly to if and only if where denotes the Lebesgue measure. 3.The sequence converges to a.e.  iff My attempt: 1: it is quite obvious. there exists a natural number such that for all and , namely . Thus we obtain for all and . 2: By definition of almost uniformly, we have for every there exists a measurable set with measure less than such that converges to uniformly on . I'm completely stuck on how to  proceed. Any help and comments  will be appreciated.","E \mathbb{R} A E \mathbf1_A:X\to\{0,1\} \mathbf1_A(x):=\begin{cases}1&\text{ if }x\in A\\0&\text{ if }x\notin A\end{cases}. \{E_{n}: n \in \mathbb{N}^+\} \subseteq E E \{\mathbf{1}_{E_n}(x)\} \mathbf{1}_{E}(x) \exists N \in \mathbb{N}^+ \forall n \geq N E=E_n \{\mathbf{1}_{E_n}(x)\} \mathbf{1}_{E}(x) \lim _{N \rightarrow \infty}\mu\left(\bigcup_{n=N}^\infty \left(E \backslash E_{n}\right)\right)=0, \mu (⋅) \{\mathbf{1}_{E_n}(x)\} \mathbf{1}_{E}(x) \mu\left(\bigcap_{N=1}^\infty \bigcup_{n=N}^\infty \left(E \backslash E_{n}\right)\right)=0. \Longleftarrow \Longrightarrow N |\mathbf{1}_{E_n}(x)-\mathbf{1}_{E}(x)|<\epsilon n \geq N x \in E |\mathbf{1}_{E_n}(x)-\mathbf{1}_{E}(x)|=0 E=E_n n \geq N x \in E \Longrightarrow \delta>0 E_{\delta} \delta \{E_{n}: n \in \mathbb{N}^+\}  \mathbf{1}_{E}(x) E \backslash E_{\delta}","['real-analysis', 'measure-theory']"
88,Examples of nicely shrinking sets (Rudin),Examples of nicely shrinking sets (Rudin),,"In Rudin's Real and Complex Analysis, section 7.9, the definition of nicely shrinking sets is given as follows: Let $x\in \Bbb R^k$ . A sequence $\{E_n\}$ of Borel sets in $\Bbb R^k$ is said to shrink to $x$ nicely if there is a number $\alpha>0$ with the following property: There is a sequence of balls $B(x,r_n)$ , with $\lim r_n=0$ , such that $E_n\subset B(x,r_n)$ and $$ m(E_n) \geq \alpha \cdot m(B(x,r_n))$$ for $n=1,2,\cdots$ . (Here $m$ is the Lebesgue measure) Then Rudin says that (1) A nested sequence of $k$ -cells whose longest edge is at most 1,000 times as long as its shortest edge and whose diameter tends to $0$ shrinks nicely. (2) But a nested sequence of rectangles (in $\Bbb R^2$ ) whose edges have lengths $1/n$ and $1/n^2$ does not shrink nicely. But I can't see why. I think the biggest difference is there is a upper limit of the ratio between the edges in (1), while not in (2), but how can I prove these using the definitions?","In Rudin's Real and Complex Analysis, section 7.9, the definition of nicely shrinking sets is given as follows: Let . A sequence of Borel sets in is said to shrink to nicely if there is a number with the following property: There is a sequence of balls , with , such that and for . (Here is the Lebesgue measure) Then Rudin says that (1) A nested sequence of -cells whose longest edge is at most 1,000 times as long as its shortest edge and whose diameter tends to shrinks nicely. (2) But a nested sequence of rectangles (in ) whose edges have lengths and does not shrink nicely. But I can't see why. I think the biggest difference is there is a upper limit of the ratio between the edges in (1), while not in (2), but how can I prove these using the definitions?","x\in \Bbb R^k \{E_n\} \Bbb R^k x \alpha>0 B(x,r_n) \lim r_n=0 E_n\subset B(x,r_n)  m(E_n) \geq \alpha \cdot m(B(x,r_n)) n=1,2,\cdots m k 0 \Bbb R^2 1/n 1/n^2","['measure-theory', 'lebesgue-measure']"
89,Given $f$ integrable and $\int_E f\geq 0$ for every $E$ measurable set prove $f(x)\geq 0$ almost everywhere.,Given  integrable and  for every  measurable set prove  almost everywhere.,f \int_E f\geq 0 E f(x)\geq 0,"Prove that if $f$ is integrable on $\mathbb{R}^d$ and $\int_E f\geq 0$ for every $E$ measurable set prove $f(x)\geq 0$ almost everywhere. Defining $F=\{x:f(x)<0\}$ I have managed to show that $\int_Ff=0$ . However, there is a line a proof I am reading that follows on from $\int_Ff=0$ saying ""Since $f<0 \text{ for all }  x \in F$ , we conclude that $m(F)=0$ "" and that doesn't really make sense to me. Question: I know that $\int_Ff=0$ implies $f=0$ almost everywhere in $F$ . But how does one get from that to $m(F)=0$ ? Proof I am reading:","Prove that if is integrable on and for every measurable set prove almost everywhere. Defining I have managed to show that . However, there is a line a proof I am reading that follows on from saying ""Since , we conclude that "" and that doesn't really make sense to me. Question: I know that implies almost everywhere in . But how does one get from that to ? Proof I am reading:",f \mathbb{R}^d \int_E f\geq 0 E f(x)\geq 0 F=\{x:f(x)<0\} \int_Ff=0 \int_Ff=0 f<0 \text{ for all }  x \in F m(F)=0 \int_Ff=0 f=0 F m(F)=0,"['measure-theory', 'lebesgue-integral', 'lebesgue-measure', 'measurable-functions']"
90,Why is the set of continous paths of a browian motion not measurable?,Why is the set of continous paths of a browian motion not measurable?,,"Øksendal states in his book ""stochastic differential equations"" ( Defintion 2.2.1 iii), p.13 ) that the set $H = \{\ \omega \mid t → B_t (\omega)\ \text{is continuous}\ \}$ is not measurable with respect to the Borel $\sigma$ -algebra $\mathcal{B}$ on $(\mathbb{R}^n)^{[0,\infty)}$ (...) ( $H$ involves an uncountable number of $t$ 's), where $B_t$ is a brownian motion and we identify $\omega$ with the path of $B_t(\omega)$ . Unfortunately I don't know much about $\mathcal{B}((\mathbb{R}^n)^{[0,\infty)})$ aside its defintion. According to this question a set $A$ is measurable iff there exists $J\subseteq \mathbb{R}$ with $|J|≤\aleph_0$ and $B\in \mathcal{B}(\mathbb{R}^J)$ such that $A=B \times \mathbb{R}^{\mathbb{R}\setminus J}=\{f \in \mathbb{R}^\mathbb{R} \colon  \ (f(j) \colon \ t \in J) \in B\}$ . I would appreciate it, if someone could provide me a reference for the statement above. Edit: If I am not mistaken the product $\sigma$ -algebra $\mathcal{B}((\mathbb{R}^n))^{[0,\infty)}$ is a true subset of the Borel- $\sigma$ -algebra $\mathcal{B}((\mathbb{R}^n)^{[0,\infty)})$ and thus the statement above should be correct for the product, but not for the Borel algebra. Prior to the quote Øksendal writes ( after Definition 2.1.4, p. 10 ): $\mathcal{B}$ [the algebra generated by cylindrical sets] is the same as the Borel $\sigma$ -algebra on $\tilde{\Omega}$ [ $=(\mathbb{R}^n)^T$ ] ­ if $T = [0,\infty)$ and $\tilde{\Omega}$ ­ is given   the product topology This should be false or am I missing something?","Øksendal states in his book ""stochastic differential equations"" ( Defintion 2.2.1 iii), p.13 ) that the set is not measurable with respect to the Borel -algebra on (...) ( involves an uncountable number of 's), where is a brownian motion and we identify with the path of . Unfortunately I don't know much about aside its defintion. According to this question a set is measurable iff there exists with and such that . I would appreciate it, if someone could provide me a reference for the statement above. Edit: If I am not mistaken the product -algebra is a true subset of the Borel- -algebra and thus the statement above should be correct for the product, but not for the Borel algebra. Prior to the quote Øksendal writes ( after Definition 2.1.4, p. 10 ): [the algebra generated by cylindrical sets] is the same as the Borel -algebra on [ ] ­ if and ­ is given   the product topology This should be false or am I missing something?","H = \{\ \omega \mid t → B_t (\omega)\ \text{is continuous}\
\} \sigma \mathcal{B} (\mathbb{R}^n)^{[0,\infty)} H t B_t \omega B_t(\omega) \mathcal{B}((\mathbb{R}^n)^{[0,\infty)}) A J\subseteq \mathbb{R} |J|≤\aleph_0 B\in \mathcal{B}(\mathbb{R}^J) A=B \times \mathbb{R}^{\mathbb{R}\setminus J}=\{f \in \mathbb{R}^\mathbb{R} \colon  \ (f(j) \colon \ t \in J) \in B\} \sigma \mathcal{B}((\mathbb{R}^n))^{[0,\infty)} \sigma \mathcal{B}((\mathbb{R}^n)^{[0,\infty)}) \mathcal{B} \sigma \tilde{\Omega} =(\mathbb{R}^n)^T T = [0,\infty) \tilde{\Omega}","['measure-theory', 'stochastic-calculus', 'brownian-motion', 'stochastic-analysis', 'borel-sets']"
91,Uniform convergence of Lipschitz functions and convergence of their derivatives,Uniform convergence of Lipschitz functions and convergence of their derivatives,,"Suppose the following: $f$ and $f_m$ ( $m\in\mathbb N$ ) are real-valued functions on $[0,1]$ ; $f(0)=f_m(0)=0=f(1)=f_m(1)$ for each $m\in\mathbb N$ ; $f$ and $f_m$ ( $m\in\mathbb N$ ) all share the same Lipschitz constant $\kappa>0$ , meaning that $|f(y)-f(x)|\leq\kappa|y-x|$ and $|f_m(y)-f_m(x)|\leq\kappa|y-x|$ for each $x,y\in[0,1]$ and $m\in\mathbb N$ ; and $\lim_{m\to\infty}\sup_{x\in[0,1]}|f_m(x)-f(x)|=0$ (that is, we have uniform convergence). I am trying to either prove or disprove the following (the derivatives exist almost everywhere by Lipschitz and hence absolute continuity): $$\int_0^1|f'(t)|\,\mathrm dt\leq\liminf_{m\to\infty}\int_0^1|f'_m(t)|\,\mathrm dt.$$ It’s quite easy to come up with examples showing that the inequality can actually be strict, but I am wondering whether it always holds in the first place, or whether there is a neat counterexample. Any feedback is greatly appreciated.","Suppose the following: and ( ) are real-valued functions on ; for each ; and ( ) all share the same Lipschitz constant , meaning that and for each and ; and (that is, we have uniform convergence). I am trying to either prove or disprove the following (the derivatives exist almost everywhere by Lipschitz and hence absolute continuity): It’s quite easy to come up with examples showing that the inequality can actually be strict, but I am wondering whether it always holds in the first place, or whether there is a neat counterexample. Any feedback is greatly appreciated.","f f_m m\in\mathbb N [0,1] f(0)=f_m(0)=0=f(1)=f_m(1) m\in\mathbb N f f_m m\in\mathbb N \kappa>0 |f(y)-f(x)|\leq\kappa|y-x| |f_m(y)-f_m(x)|\leq\kappa|y-x| x,y\in[0,1] m\in\mathbb N \lim_{m\to\infty}\sup_{x\in[0,1]}|f_m(x)-f(x)|=0 \int_0^1|f'(t)|\,\mathrm dt\leq\liminf_{m\to\infty}\int_0^1|f'_m(t)|\,\mathrm dt.","['real-analysis', 'measure-theory', 'continuity']"
92,"Finding $\lim_{n \to \infty} \int_{(0,\infty)} \frac{n \sin (x/n)}{x(1+x^2)}dx$ via DCT",Finding  via DCT,"\lim_{n \to \infty} \int_{(0,\infty)} \frac{n \sin (x/n)}{x(1+x^2)}dx","I am trying to find $\lim_{n \to \infty} \int_{(0,\infty)} \frac{n \sin (x/n)}{x(1+x^2)}dx$ by applying the Dominated Convergence Theorem for Lebesgue Integrals. First, considering $(f_n): f_n=\frac{n \sin (x/n)}{x(1+x^2)}=\frac{\sin(x/n)}{(x/n)} \frac{1}{1+x^2},$ it then follows that $\lim_{n \to \infty}\frac{\sin(x/n)}{(x/n)}\frac{1}{1+x^2}=\frac{1}{1+x^2}\lim_{n \to \infty}\frac{\sin(x/n)}{(x/n)}$. And thus substituting with $u=\frac{x}{n}$, we get that as $n \to \infty$, $u \to 0$. Obviously, $\lim_{u \to 0} \frac{\sin u }{u}=1 \Rightarrow \lim_{n \to \infty} f_n = \frac{1}{1+x^2}=f(x).$ Hence $f_n$ converges pointwise to $f$. Then the requirement is that $(f_n)$ is in $L_1$. I go on to argue that since on $(0,\infty)$ both $\frac{\sin(x/n)}{(x/n)}$ and $\frac{1}{1+x^2}$ are continuous, then both functions are measurable. And because the measurable functions form an algebra, then $f_n$, their product, is also measurable. How do we argue however that they are Lebesgue integrable? I know, for example, that the Lebesgue integral $\int_{(0,\infty)}\frac{\sin x}{x}$ does not exist. Also, I reckon we are going to use $g(x)=\frac{1}{1+x^2} \in L_1$ to dominate $f_n$ such that $|f_n|\leq g$ for all $n$. I argue as follows: on $(0,\infty)$ we have $|\sin (x/n)|\leq|x/n|$ for any $n$. Hence $|f_n|=\left|\frac{\sin(x/n)}{(x/n)}\frac{1}{1+x^2} \right|\leq \frac{1}{1+x^2}$. So, once again we get to the question of the function being in $L_1$. Finally, it is straightforward to apply DCT and get $\lim_{n \to \infty}\int f_n= \int f=\left.\tan^{-1}(x)\right|^{\infty}_{0}=\frac{\pi}{2}$. However, application of the Riemann integral bothers me somewhat, as we know that for the bounded Riemann integrable function, the proper Riemann integral is equivalent to the Lebesgue version. Does this application hold?","I am trying to find $\lim_{n \to \infty} \int_{(0,\infty)} \frac{n \sin (x/n)}{x(1+x^2)}dx$ by applying the Dominated Convergence Theorem for Lebesgue Integrals. First, considering $(f_n): f_n=\frac{n \sin (x/n)}{x(1+x^2)}=\frac{\sin(x/n)}{(x/n)} \frac{1}{1+x^2},$ it then follows that $\lim_{n \to \infty}\frac{\sin(x/n)}{(x/n)}\frac{1}{1+x^2}=\frac{1}{1+x^2}\lim_{n \to \infty}\frac{\sin(x/n)}{(x/n)}$. And thus substituting with $u=\frac{x}{n}$, we get that as $n \to \infty$, $u \to 0$. Obviously, $\lim_{u \to 0} \frac{\sin u }{u}=1 \Rightarrow \lim_{n \to \infty} f_n = \frac{1}{1+x^2}=f(x).$ Hence $f_n$ converges pointwise to $f$. Then the requirement is that $(f_n)$ is in $L_1$. I go on to argue that since on $(0,\infty)$ both $\frac{\sin(x/n)}{(x/n)}$ and $\frac{1}{1+x^2}$ are continuous, then both functions are measurable. And because the measurable functions form an algebra, then $f_n$, their product, is also measurable. How do we argue however that they are Lebesgue integrable? I know, for example, that the Lebesgue integral $\int_{(0,\infty)}\frac{\sin x}{x}$ does not exist. Also, I reckon we are going to use $g(x)=\frac{1}{1+x^2} \in L_1$ to dominate $f_n$ such that $|f_n|\leq g$ for all $n$. I argue as follows: on $(0,\infty)$ we have $|\sin (x/n)|\leq|x/n|$ for any $n$. Hence $|f_n|=\left|\frac{\sin(x/n)}{(x/n)}\frac{1}{1+x^2} \right|\leq \frac{1}{1+x^2}$. So, once again we get to the question of the function being in $L_1$. Finally, it is straightforward to apply DCT and get $\lim_{n \to \infty}\int f_n= \int f=\left.\tan^{-1}(x)\right|^{\infty}_{0}=\frac{\pi}{2}$. However, application of the Riemann integral bothers me somewhat, as we know that for the bounded Riemann integrable function, the proper Riemann integral is equivalent to the Lebesgue version. Does this application hold?",,"['real-analysis', 'measure-theory']"
93,Showing that a discontinuous function is or is not borel measurable.,Showing that a discontinuous function is or is not borel measurable.,,"So my question is this. Please let me know if my answer is sufficient. Let $$  f(x) =       \begin{cases}       \sin(\frac{1}{x})  &\quad\text{if } x \neq 0,\\        \text{5} &\quad\text{if } x = 0\\      \end{cases}  $$ be defined on the whole real line. Is $f$ Borel measurable. My way of thinking is to use the definition of measurable function; Suppose we have a set X together with a sigma-algebra $\Sigma$. Function $f:X \rightarrow \mathbb{R}$ is measurable or $\Sigma$-measurable if the set $\{x:f(x)>a\}$ belongs to $\Sigma$ for all $a \in \mathbb{R}$. Therefore, from the question, I obtained the two following facts; If $a \geq 5$ then $\{x \in \mathbb{R}: f(x) > a\}=\emptyset$ Surely, this is all that is required to show that it is not Borel measurable as the empty set doesn't generate a sigma algebra.","So my question is this. Please let me know if my answer is sufficient. Let $$  f(x) =       \begin{cases}       \sin(\frac{1}{x})  &\quad\text{if } x \neq 0,\\        \text{5} &\quad\text{if } x = 0\\      \end{cases}  $$ be defined on the whole real line. Is $f$ Borel measurable. My way of thinking is to use the definition of measurable function; Suppose we have a set X together with a sigma-algebra $\Sigma$. Function $f:X \rightarrow \mathbb{R}$ is measurable or $\Sigma$-measurable if the set $\{x:f(x)>a\}$ belongs to $\Sigma$ for all $a \in \mathbb{R}$. Therefore, from the question, I obtained the two following facts; If $a \geq 5$ then $\{x \in \mathbb{R}: f(x) > a\}=\emptyset$ Surely, this is all that is required to show that it is not Borel measurable as the empty set doesn't generate a sigma algebra.",,"['measure-theory', 'lebesgue-measure', 'borel-sets']"
94,What can I get from measure $0$ set?,What can I get from measure  set?,0,"I'm having issues with this problem: Let $f:[0,1]\rightarrow[0,1]$ injective and continuous function. Let A=$\bigcup_i (a_i,b_i)$ $\forall x_1, x_2 \in (a_i,b_i)$, $|f(x_1)-f(x_2)|\leq |x_1-x_2|$ $f([0,1]\setminus A)$ has Lebesgue measure $0$ I have to show $\forall x_1, x_2 \in [0,1]$, $|f(x_1)-f(x_2)|\leq |x_1-x_2|$. What I know:  I noticed that $[0,1]\setminus A$ needs to have empty interior. Moreover, $f$ has to be increasing (because of continuity and injectivity). I also noticed that it has to work in the for $x_1,x_2\in [a_i,b_i]$. This leads me to believe that I can get more out of the $0$ measure, am I missing something?","I'm having issues with this problem: Let $f:[0,1]\rightarrow[0,1]$ injective and continuous function. Let A=$\bigcup_i (a_i,b_i)$ $\forall x_1, x_2 \in (a_i,b_i)$, $|f(x_1)-f(x_2)|\leq |x_1-x_2|$ $f([0,1]\setminus A)$ has Lebesgue measure $0$ I have to show $\forall x_1, x_2 \in [0,1]$, $|f(x_1)-f(x_2)|\leq |x_1-x_2|$. What I know:  I noticed that $[0,1]\setminus A$ needs to have empty interior. Moreover, $f$ has to be increasing (because of continuity and injectivity). I also noticed that it has to work in the for $x_1,x_2\in [a_i,b_i]$. This leads me to believe that I can get more out of the $0$ measure, am I missing something?",,"['real-analysis', 'measure-theory', 'lebesgue-measure']"
95,"If a set has positive measure, do its slices have positive measure?","If a set has positive measure, do its slices have positive measure?",,"Suppose $F \subset R^n$ and $|F|>0$. Let $F_x = \{ y \in R^{n-1} | (x, y) \in F\}$. Then is it true that for almost every $(x,y) \in F$, $F_x$ has positive $n-1$ dimensional measure? By Fubini's Theorem, we know that $|F| = \int_{R} |F_x| dx$, but I can't see why this implies the truth of the stated fact. All I can gather from this is that $|F_x|$ is positive on a subset of $R$ which has positive linear measure.","Suppose $F \subset R^n$ and $|F|>0$. Let $F_x = \{ y \in R^{n-1} | (x, y) \in F\}$. Then is it true that for almost every $(x,y) \in F$, $F_x$ has positive $n-1$ dimensional measure? By Fubini's Theorem, we know that $|F| = \int_{R} |F_x| dx$, but I can't see why this implies the truth of the stated fact. All I can gather from this is that $|F_x|$ is positive on a subset of $R$ which has positive linear measure.",,"['real-analysis', 'measure-theory', 'lebesgue-integral']"
96,On pointwise convergence of Lebesgue measurable sets and some properties,On pointwise convergence of Lebesgue measurable sets and some properties,,"Definition ( Pointwise convergence of sets ): We say that a sequence $E_n$ of sets in $\mathbb{R}^d$ converges pointwise to another set $E$ in $\mathbb{R}^d$ if the indicator functions $1_{E_n}$ converge pointwise to the indicator function $1_E$ . The problem is to show that if $E_n$ are all Lebesgue measurable, and converge pointwise to $E$ , then $E$ is also Lebesgue measurable. Further, I need to show that $m(E_n)$ converges to $m(E)$ [where $m(\cdot)$ denotes the Lebesgue measure], if $E_n$ are all contained in another Lebesgue measurable set $F$ of finite measure. Also, I've to produce a counter example to show that the convergence may not hold without the assumption. For the first part, I tried to write $E$ as some countable union/intersection of the $E_n$ 's. But I cannot exploit the definition of pointwise convergence of sets well enough to defend my point. For the second part, probably I need to incorporate the monotone convergence theorem, but I don't have a clear-cut attack on the problem. Any help would be greatly appreciated!","Definition ( Pointwise convergence of sets ): We say that a sequence of sets in converges pointwise to another set in if the indicator functions converge pointwise to the indicator function . The problem is to show that if are all Lebesgue measurable, and converge pointwise to , then is also Lebesgue measurable. Further, I need to show that converges to [where denotes the Lebesgue measure], if are all contained in another Lebesgue measurable set of finite measure. Also, I've to produce a counter example to show that the convergence may not hold without the assumption. For the first part, I tried to write as some countable union/intersection of the 's. But I cannot exploit the definition of pointwise convergence of sets well enough to defend my point. For the second part, probably I need to incorporate the monotone convergence theorem, but I don't have a clear-cut attack on the problem. Any help would be greatly appreciated!",E_n \mathbb{R}^d E \mathbb{R}^d 1_{E_n} 1_E E_n E E m(E_n) m(E) m(\cdot) E_n F E E_n,"['real-analysis', 'measure-theory']"
97,Product of a sequence of functions that converges in measure and a measurable function converges in measure.,Product of a sequence of functions that converges in measure and a measurable function converges in measure.,,"I'm working through the following problem in Royden (Chapter 5, exercise 7) and would like to understand the solution: Let $E$ have finite measure, $\{f_n\}\to f$ in measure on $E$, and $g$ be a measurable function on $E$ that is finite $a.e.$ on $E$. Prove that $\{f_n\cdot g\}\to f\cdot g$ in measure. $\newcommand{\N}{\mathbb{N}}$ Proof. Since $g$ is finite a.e. on $E$, $m(\bigcap_{n\in\N}\{x\in E\,\,|\,\,g(x)>n\})=0\implies \forall\epsilon>0\,\,\, \exists N_1\in\N$:$n\geq N_1 \implies m\{x\in E\,\,|\,\,|g(x)|>n\}<\epsilon$. So, let $\epsilon>0$ be given. Then there exists $M\in\N$ so that $m\{x\in E\,\,|\,\,|g(x)|>M\}<\frac{\epsilon}{2}$. Let $\eta>0$. Since $\{f_n\}\to f$ in measure on $E$, $\exists N\in\N :n\geq N\implies m\{x\in E\,\,|\,\,|f_n(x)-f(x)|>\frac{\eta}{2M}\}<\frac{\epsilon}{2}$. Letting $n\geq N$, notice that: \begin{align*} &\{x\in E\,\,|\,\,|(f_n\cdot g)(x)-(f\cdot g)(x)|>\frac{\eta}{2}\}\\ =&\{x\in E\,\,|\,\,|g(x)\cdot f_n(x)-g(x)\cdot f(x)|>\frac{\eta}{2}\}\\ =&\{x\in E\,\,|\,\,|g(x)|\cdot|f_n(x)-f(x)|>\frac{\eta}{2}\}\\ \subset &\{x\in E\,\,|\,\,|g(x)|>M_1\}\cup \{x\in E\,\,|\,\,|f_n(x)-f(x)|>\frac{\eta}{2M}\}.\\ \end{align*} We then infer that: \begin{align*} &m\{x\in E\,\,|\,\,|(f_n\cdot g)(x)-(f\cdot g)(x)|>\frac{\eta}{2}\}\\ \leq &m\{x\in E\,\,|\,\,|g(x)|>M_1\}+m\{x\in E\,\,|\,\,|f_n(x)-f(x)|>\frac{\eta}{2M}\}\\ < &\frac{\epsilon}{2}+\frac{\epsilon}{2}\\ =&\epsilon.\\ \end{align*}  $\blacksquare$ Specifically, I'm having some trouble understanding why: $\{x\in E\,\,|\,\,|g(x)|\cdot|f_n(x)-f(x)|>\frac{\eta}{2}\} \subset \{x\in E\,\,|\,\,|g(x)|>M_1\}\cup \{x\in E\,\,|\,\,|f_n(x)-f(x)|>\frac{\eta}{2M}\}$. Sorry if I'm being a bit handwavy. Any constructive feedback will be helpful!","I'm working through the following problem in Royden (Chapter 5, exercise 7) and would like to understand the solution: Let $E$ have finite measure, $\{f_n\}\to f$ in measure on $E$, and $g$ be a measurable function on $E$ that is finite $a.e.$ on $E$. Prove that $\{f_n\cdot g\}\to f\cdot g$ in measure. $\newcommand{\N}{\mathbb{N}}$ Proof. Since $g$ is finite a.e. on $E$, $m(\bigcap_{n\in\N}\{x\in E\,\,|\,\,g(x)>n\})=0\implies \forall\epsilon>0\,\,\, \exists N_1\in\N$:$n\geq N_1 \implies m\{x\in E\,\,|\,\,|g(x)|>n\}<\epsilon$. So, let $\epsilon>0$ be given. Then there exists $M\in\N$ so that $m\{x\in E\,\,|\,\,|g(x)|>M\}<\frac{\epsilon}{2}$. Let $\eta>0$. Since $\{f_n\}\to f$ in measure on $E$, $\exists N\in\N :n\geq N\implies m\{x\in E\,\,|\,\,|f_n(x)-f(x)|>\frac{\eta}{2M}\}<\frac{\epsilon}{2}$. Letting $n\geq N$, notice that: \begin{align*} &\{x\in E\,\,|\,\,|(f_n\cdot g)(x)-(f\cdot g)(x)|>\frac{\eta}{2}\}\\ =&\{x\in E\,\,|\,\,|g(x)\cdot f_n(x)-g(x)\cdot f(x)|>\frac{\eta}{2}\}\\ =&\{x\in E\,\,|\,\,|g(x)|\cdot|f_n(x)-f(x)|>\frac{\eta}{2}\}\\ \subset &\{x\in E\,\,|\,\,|g(x)|>M_1\}\cup \{x\in E\,\,|\,\,|f_n(x)-f(x)|>\frac{\eta}{2M}\}.\\ \end{align*} We then infer that: \begin{align*} &m\{x\in E\,\,|\,\,|(f_n\cdot g)(x)-(f\cdot g)(x)|>\frac{\eta}{2}\}\\ \leq &m\{x\in E\,\,|\,\,|g(x)|>M_1\}+m\{x\in E\,\,|\,\,|f_n(x)-f(x)|>\frac{\eta}{2M}\}\\ < &\frac{\epsilon}{2}+\frac{\epsilon}{2}\\ =&\epsilon.\\ \end{align*}  $\blacksquare$ Specifically, I'm having some trouble understanding why: $\{x\in E\,\,|\,\,|g(x)|\cdot|f_n(x)-f(x)|>\frac{\eta}{2}\} \subset \{x\in E\,\,|\,\,|g(x)|>M_1\}\cup \{x\in E\,\,|\,\,|f_n(x)-f(x)|>\frac{\eta}{2M}\}$. Sorry if I'm being a bit handwavy. Any constructive feedback will be helpful!",,"['real-analysis', 'measure-theory', 'convergence-divergence', 'lebesgue-measure']"
98,A lebesgue measurable set $E$ with $\mu(E)=1$ and $\mu_F(E) = 0$.,A lebesgue measurable set  with  and .,E \mu(E)=1 \mu_F(E) = 0,"I have to prove the following: suppose that $F : [0, 1] → \mathbb{R}_+$ is a right continuous increasing function and $F'  = 0$ almost everywhere. Let $\mu_F$ be such that $\mu_F((a, b]) = F(b) − F(a)$ for all $0 ≤ a < b ≤ 1$. Show there is a Lebesgue measurable set $E$ with $\mu(E)=1$ such that $\mu_F(E) = 0$. Following a hint, I have been trying to use Vitali’s covering lemma on the set $\{ F'=0\}$ to show that for any positive $\varepsilon>0$ and $\delta>0$ there is a set $G$ such that $\mu(G) ≥ 1 − \varepsilon$ and $\mu_F(G) ≤ \delta$, but I have not been able to go much further.","I have to prove the following: suppose that $F : [0, 1] → \mathbb{R}_+$ is a right continuous increasing function and $F'  = 0$ almost everywhere. Let $\mu_F$ be such that $\mu_F((a, b]) = F(b) − F(a)$ for all $0 ≤ a < b ≤ 1$. Show there is a Lebesgue measurable set $E$ with $\mu(E)=1$ such that $\mu_F(E) = 0$. Following a hint, I have been trying to use Vitali’s covering lemma on the set $\{ F'=0\}$ to show that for any positive $\varepsilon>0$ and $\delta>0$ there is a set $G$ such that $\mu(G) ≥ 1 − \varepsilon$ and $\mu_F(G) ≤ \delta$, but I have not been able to go much further.",,"['real-analysis', 'measure-theory', 'lebesgue-measure']"
99,Poincaré recurrence but infinite measure,Poincaré recurrence but infinite measure,,"I'm trying prove the following problem: Let $f : M → M$ be an invertible transformation and suppose that $µ$ is an invariant infinite measure. Let $B ⊂ M$ be a set with finite measure. Prove that, given any measurable set $A ⊂ M$ with positive measure, $µ$-almost every point $p ∈ A$ either returns to $A$ an infinite number of times or has only a finite number of iterates in $B$. Obs1: µ infinite measure means µ(M)=$\infty$; Obs2: f is a function preserving µ; Obs3: $f^{-1}$ isn't requered be measurable. Obs4: $µ(B)<\infty$, $µ(A)>0$ Obs5: $n$ iterates means $f^{n}(p)$ for a point $p$ What I tried: Separate the set A in 9 parts, combining iterates that never return to B, return a finite times to B, and never return to B with the analogous to A, where the iterates are done over points of the set A. But I didn't get success in prove that the appropriate intersections have null measures. I hope any suggestions to proceed ahead, thank you!","I'm trying prove the following problem: Let $f : M → M$ be an invertible transformation and suppose that $µ$ is an invariant infinite measure. Let $B ⊂ M$ be a set with finite measure. Prove that, given any measurable set $A ⊂ M$ with positive measure, $µ$-almost every point $p ∈ A$ either returns to $A$ an infinite number of times or has only a finite number of iterates in $B$. Obs1: µ infinite measure means µ(M)=$\infty$; Obs2: f is a function preserving µ; Obs3: $f^{-1}$ isn't requered be measurable. Obs4: $µ(B)<\infty$, $µ(A)>0$ Obs5: $n$ iterates means $f^{n}(p)$ for a point $p$ What I tried: Separate the set A in 9 parts, combining iterates that never return to B, return a finite times to B, and never return to B with the analogous to A, where the iterates are done over points of the set A. But I didn't get success in prove that the appropriate intersections have null measures. I hope any suggestions to proceed ahead, thank you!",,"['measure-theory', 'ergodic-theory']"
