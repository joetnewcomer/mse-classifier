,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Proving statement about approximation of functions in completed measure spaces by functions belonging to the noncompleted space,Proving statement about approximation of functions in completed measure spaces by functions belonging to the noncompleted space,,"Let $(X,\mathcal{A},\mu)$ be a measure space,   $(X,\mathcal{A}_\mu,\overline{\mu})$ be its completion and $f: X \to  [-\infty,\infty]$ $\mathcal{A}_\mu$-measurable. Then there   exist $\mathcal{A}$-measurable functions $g,h: X \to  [-\infty,\infty]$ with $g \leq f \leq h$ and $g = h$   $\mu$-a.e. Proof. First assume $f \in \Sigma^+$. Then $$f = \sum_{i = 1}^n a_i \chi_{A_i}$$ where $a_i \leq 0$ and $A_i \in \mathcal{A}_\mu$ for $i = 1,\dots,n$. Since $\mathcal{A}_\mu$ is the completion of $\mathcal{A}$, there exist $E_i,F_i \in \mathcal{A}$ such that $$E_i \subseteq A_i \subseteq F_i \qquad \text{and} \qquad \mu(F_i \setminus E_i) = 0$$ for $i = 1,\dots,n$. Then $$g := \sum_{i = 1}^n a_i \chi_{E_i} \qquad \text{and} \qquad h := \sum_{i = 1}^n a_i \chi_{F_i}$$  have the desired properties. Now let $f$ be a $\mathcal{A}_\mu$-measurable nonnegative function. Then we find a sequence $(\varphi_n)_{n \in \mathbb{N}}$ of $\mathcal{A}_\mu$-measurable simple functions $0 \leq \varphi_n$ such that $\varphi_n \nearrow f$. By the first part we find sequences $(g_n)_{n\in\mathbb{N}}$ and $(h_n)_{n \in \mathbb{N}}$ of $\mathcal{A}$-measurable functions such that $$g_n \leq \varphi_n \leq h_n \qquad \text{and} \qquad g_n = h_n \>\mu\text{-a.e.}$$ for any $n \in \mathbb{N}$. Now I am a bit unsure how to proceed. Intuitively, we just take $$g := \lim_{n \to \infty} g_n \qquad \text{and} \qquad h := \lim_{n \to \infty} h_n$$ but I am not sure if this works. I mean it is not clear that $g_n$ and $h_n$ converge pointwise. Any help? Edit. Maybe better would be $$g := \limsup_{n \to \infty} g_n \qquad \text{and} \qquad h := \liminf_{n \to \infty} h_n$$","Let $(X,\mathcal{A},\mu)$ be a measure space,   $(X,\mathcal{A}_\mu,\overline{\mu})$ be its completion and $f: X \to  [-\infty,\infty]$ $\mathcal{A}_\mu$-measurable. Then there   exist $\mathcal{A}$-measurable functions $g,h: X \to  [-\infty,\infty]$ with $g \leq f \leq h$ and $g = h$   $\mu$-a.e. Proof. First assume $f \in \Sigma^+$. Then $$f = \sum_{i = 1}^n a_i \chi_{A_i}$$ where $a_i \leq 0$ and $A_i \in \mathcal{A}_\mu$ for $i = 1,\dots,n$. Since $\mathcal{A}_\mu$ is the completion of $\mathcal{A}$, there exist $E_i,F_i \in \mathcal{A}$ such that $$E_i \subseteq A_i \subseteq F_i \qquad \text{and} \qquad \mu(F_i \setminus E_i) = 0$$ for $i = 1,\dots,n$. Then $$g := \sum_{i = 1}^n a_i \chi_{E_i} \qquad \text{and} \qquad h := \sum_{i = 1}^n a_i \chi_{F_i}$$  have the desired properties. Now let $f$ be a $\mathcal{A}_\mu$-measurable nonnegative function. Then we find a sequence $(\varphi_n)_{n \in \mathbb{N}}$ of $\mathcal{A}_\mu$-measurable simple functions $0 \leq \varphi_n$ such that $\varphi_n \nearrow f$. By the first part we find sequences $(g_n)_{n\in\mathbb{N}}$ and $(h_n)_{n \in \mathbb{N}}$ of $\mathcal{A}$-measurable functions such that $$g_n \leq \varphi_n \leq h_n \qquad \text{and} \qquad g_n = h_n \>\mu\text{-a.e.}$$ for any $n \in \mathbb{N}$. Now I am a bit unsure how to proceed. Intuitively, we just take $$g := \lim_{n \to \infty} g_n \qquad \text{and} \qquad h := \lim_{n \to \infty} h_n$$ but I am not sure if this works. I mean it is not clear that $g_n$ and $h_n$ converge pointwise. Any help? Edit. Maybe better would be $$g := \limsup_{n \to \infty} g_n \qquad \text{and} \qquad h := \liminf_{n \to \infty} h_n$$",,['measure-theory']
1,Proving that $m(\{f^{-1}(S) : S \in A\}) = \{f^{-1}(S) : S \in m(A)\}$ (monotone classes),Proving that  (monotone classes),m(\{f^{-1}(S) : S \in A\}) = \{f^{-1}(S) : S \in m(A)\},"Let $X,Y$ be sets, $A \subseteq \mathcal{P}(Y)$ and $f: X \to Y$. Then $$m(\{f^{-1}(S) : S \in A\}) = \{f^{-1}(S) : S \in  m(A)\}$$ Where $m(A)$ denotes the monotone class generated by $A$. For proving the inclusion $\subseteq$ it is enough to show that $$\{f^{-1}(S) : S \in  m(A)\}$$ is a monotone class. Hence we take an increaing sequence $(f^{-1}(S_n))_{n \in \mathbb{N}}$ where $S_n \in m(A)$ an look at its union. I mean trivially $$\bigcup_{n \in \mathbb{N}}f^{-1}(S_n) = f^{-1}\left( \bigcup_{n \in \mathbb{N}}S_n\right)$$ So if we could show $\bigcup_{n \in \mathbb{N}}S_n \in m(A)$ we are done. For this $(S_n)_{n \in \mathbb{N}}$ must be increasing, which is not per se the case, isn't it? I asked the one which wrote this exercise and he replied that it is the same as for $\sigma(A)$ ($\sigma$-algebra generated by $A$) no further assumptions on the nature of $f$ have to be made. But I mean, $\sigma$-algebras are a richer structure than monotone classes, hence it could be that we have to assert more in this case. My assumption would be that $f$ has to be surjective. So my question is: Is this assumption necessary or is it right that it is like in the case of $\sigma$-algebras? Does the proof work nevertheless and I do not see it?","Let $X,Y$ be sets, $A \subseteq \mathcal{P}(Y)$ and $f: X \to Y$. Then $$m(\{f^{-1}(S) : S \in A\}) = \{f^{-1}(S) : S \in  m(A)\}$$ Where $m(A)$ denotes the monotone class generated by $A$. For proving the inclusion $\subseteq$ it is enough to show that $$\{f^{-1}(S) : S \in  m(A)\}$$ is a monotone class. Hence we take an increaing sequence $(f^{-1}(S_n))_{n \in \mathbb{N}}$ where $S_n \in m(A)$ an look at its union. I mean trivially $$\bigcup_{n \in \mathbb{N}}f^{-1}(S_n) = f^{-1}\left( \bigcup_{n \in \mathbb{N}}S_n\right)$$ So if we could show $\bigcup_{n \in \mathbb{N}}S_n \in m(A)$ we are done. For this $(S_n)_{n \in \mathbb{N}}$ must be increasing, which is not per se the case, isn't it? I asked the one which wrote this exercise and he replied that it is the same as for $\sigma(A)$ ($\sigma$-algebra generated by $A$) no further assumptions on the nature of $f$ have to be made. But I mean, $\sigma$-algebras are a richer structure than monotone classes, hence it could be that we have to assert more in this case. My assumption would be that $f$ has to be surjective. So my question is: Is this assumption necessary or is it right that it is like in the case of $\sigma$-algebras? Does the proof work nevertheless and I do not see it?",,['measure-theory']
2,$L^p$ convergence follows from $L^2$ convergence plus $L^p$ boundedness?,convergence follows from  convergence plus  boundedness?,L^p L^2 L^p,"Suppose $f_n$ is sequence of functions such that $f_n\rightarrow f$ in $L^2(\mathbb{R})$. Also suppose $\|f_n\|_p\leqslant C \|f\|_p$, where constant $C$ is independent of $n$. From this data, can we conclude that $f_n\rightarrow f$ in $L^p(\mathbb{R})$? Assume $1<p<\infty$.","Suppose $f_n$ is sequence of functions such that $f_n\rightarrow f$ in $L^2(\mathbb{R})$. Also suppose $\|f_n\|_p\leqslant C \|f\|_p$, where constant $C$ is independent of $n$. From this data, can we conclude that $f_n\rightarrow f$ in $L^p(\mathbb{R})$? Assume $1<p<\infty$.",,"['functional-analysis', 'measure-theory']"
3,"Let $\mu,\ \nu$ be measures, $\mu\ll\nu$ and $\nu\ll \mu$. Show that $\frac{d\mu}{d\nu} = (\frac{d\nu}{d\mu})^{-1}$.","Let  be measures,  and . Show that .","\mu,\ \nu \mu\ll\nu \nu\ll \mu \frac{d\mu}{d\nu} = (\frac{d\nu}{d\mu})^{-1}","Let $\mu,\  \nu$ be measures, $\mu\ll\nu$ and $\nu\ll\mu$. Show that $\frac{d\mu}{d\nu} = (\frac{d\nu}{d\mu})^{-1}$. There are not any other assumptions, so is it necessary for $\mu, \nu$ to be $\sigma$-finite? Does  expression $\frac{d\mu}{d\nu}$ make sense without making such assumption? Any hints would be great!","Let $\mu,\  \nu$ be measures, $\mu\ll\nu$ and $\nu\ll\mu$. Show that $\frac{d\mu}{d\nu} = (\frac{d\nu}{d\mu})^{-1}$. There are not any other assumptions, so is it necessary for $\mu, \nu$ to be $\sigma$-finite? Does  expression $\frac{d\mu}{d\nu}$ make sense without making such assumption? Any hints would be great!",,['measure-theory']
4,On the proof that the total variation of a signed measure is itself a (positive) measure,On the proof that the total variation of a signed measure is itself a (positive) measure,,"Given a signed measure $\nu$ on $(X,\mathcal{M})$, define Here is the first half of the proof in Stein and Shakarchi's Real Analysis : Question: Could anyone elaborate the last sentence of the proof above? Why the inequality is immediate by taking the supremum? In Rudin's Real and Complex Analysis , similar argument is given. But I don't understand why it is so quick. It seems to me though one should instead let $$ a_j=|\nu|(E_j)-\frac{\varepsilon}{2^j} $$ which would give the desired result by taking the summation and using the last inequality in the proof.","Given a signed measure $\nu$ on $(X,\mathcal{M})$, define Here is the first half of the proof in Stein and Shakarchi's Real Analysis : Question: Could anyone elaborate the last sentence of the proof above? Why the inequality is immediate by taking the supremum? In Rudin's Real and Complex Analysis , similar argument is given. But I don't understand why it is so quick. It seems to me though one should instead let $$ a_j=|\nu|(E_j)-\frac{\varepsilon}{2^j} $$ which would give the desired result by taking the summation and using the last inequality in the proof.",,['real-analysis']
5,Outer measure equals length of cell - proof explanation,Outer measure equals length of cell - proof explanation,,"This is a proof from Bartle's Text - I summed up the definitions in the bottom. What I am confused are parts (1) (meaning of ""face"" and ""extending"") and (2) (the inequality) labelled below in the proof. May someone elaborate? Thank you so much. Theorem: If $I \subseteq \mathbb{R}^p$ is any cell then $m^{*}(I)= l(I)$. Proof: It is clear that $m^{*}(I) \le l(I)$. Now let $(I_k)$ be a covering of $I$ such that    $$\sum_{k=1}^{\infty}l(I_k) \le m^*(I) + \varepsilon.$$    Let $J$ be a closed cell such that $J \subseteq I$ and $l(I) - \varepsilon < l(J)$. By the Heine-Borel Theorem there is an $m \in \mathbb{N}$ such that $J \subseteq \bigcup_{k=1}^m I_k$. $\color{blue}{(1)} $We now divide the space $\mathbb{R}^p$ into a finite number closed intervals by extending the $(p-1)$ dimensional hyperplanes that contain a face of one of the cells $I_1, \ldots, I_m$ and of $J$. $\color{blue}{*}$ Let $K_1, \ldots, K_n$ be the distinct closed cells into which the cells (closures of the cells) $\bar{I_1}, \ldots, \bar{I_m}$ are divided by these hyperplanes; further let $J_1, \ldots, J_r$ be the closed cells which $J$ is divided. $\color{blue}{(2)}$  Therefore, we have,    $$ l(J) = \sum_{j=1}^{r} l(J_j) \le \sum_{k=1}^n l(K_k) \le \sum_{k=1}^m l(I_k) \le m^{*}(I) + \varepsilon. \color{blue}{*}$$    Hence, we are done. My thoughts: I attempted to visualize the problem in 3D. Suppose our cells are $I_1 = (0,1] \times (0,1/2] \times [0,1]$ and $I_2 = [1/2,3/2) \times [0,1] \times [0,1]$. And we suppose $I = (1/2,1) \times (0,1) \times (0,1)$. Let $J = [1/2 + 1/16, 1 - 1/16] \times [1/16 , 1 - 1/16] \times [1/16, 1 - 1/16]$ (used $1/16$ instead of $\epsilon$ for illustration). (1): $ \color{blue}{ \text {What exactly is happening by ""extending the hyperplanes..."", i.e. what are $K_1, \ldots, K_n$?} } $ My understanding is as follows. For $I_1$ in my example we generate six hyperplanes.  $$H_1 = [0,0] \times \mathbb{R} \times \mathbb{R}, \quad H_2 = [1,1] \times \mathbb{R} \times \mathbb{R}, \ldots, \quad H_6 = \mathbb{R} \times \mathbb{R} \times [1,1] $$ and similarly for the other cells. (2): $\color{blue}{ \text{ My problem here is how we got the line of inequalities. } } $ In regards to my interpretation of (1) , $J$ is divided into disjoint intervals. I see why $l(J)= \sum_{j=1}^r l(J_j) \le \sum_{k=1}^n l(K_n)$. But I don't see how we obtain $$ \sum_{k=1}^{n}l(K_k) \le \sum_{k=1}^m l(I_k) $$  Shouldn't this be an equality (or in fact $\ge$?) As the family $\{ K_k \}$ is just a distinct representation of $\{ \bar{I_k} \} $? If $E \subseteq \mathbb{R}^p$, then we define the outer measure of $E$ to be $$m^{*} (E) = \inf \sum_{k=1}^\infty l (I_k)  $$ where the infimum is taken over all family of cells $(I_k)$ of $\mathbb{R}^p$ such that $E \subseteq \bigcup_{k=1}^{\infty} I_k$. A cell in $\mathbb{R}^p$ is of the form $I = I_1 \times \cdots \times I_p$, where $I_k$ are bounded intervals in $\mathbb{R}$. We define $l(I) = \prod_{k=1}^p l(I_k)$, where $l(I_k)$ is length of interval in $\mathbb{R}$ (so $l((a,b))=l((a,b]) = b-a$ for example.) A closed cell (open cells) in $\mathbb{R}^p$ is one where $I_k$ are all closed (open) bounded intervals in $\mathbb{R}$. So my three hyperplanes which satisfies the condition are","This is a proof from Bartle's Text - I summed up the definitions in the bottom. What I am confused are parts (1) (meaning of ""face"" and ""extending"") and (2) (the inequality) labelled below in the proof. May someone elaborate? Thank you so much. Theorem: If $I \subseteq \mathbb{R}^p$ is any cell then $m^{*}(I)= l(I)$. Proof: It is clear that $m^{*}(I) \le l(I)$. Now let $(I_k)$ be a covering of $I$ such that    $$\sum_{k=1}^{\infty}l(I_k) \le m^*(I) + \varepsilon.$$    Let $J$ be a closed cell such that $J \subseteq I$ and $l(I) - \varepsilon < l(J)$. By the Heine-Borel Theorem there is an $m \in \mathbb{N}$ such that $J \subseteq \bigcup_{k=1}^m I_k$. $\color{blue}{(1)} $We now divide the space $\mathbb{R}^p$ into a finite number closed intervals by extending the $(p-1)$ dimensional hyperplanes that contain a face of one of the cells $I_1, \ldots, I_m$ and of $J$. $\color{blue}{*}$ Let $K_1, \ldots, K_n$ be the distinct closed cells into which the cells (closures of the cells) $\bar{I_1}, \ldots, \bar{I_m}$ are divided by these hyperplanes; further let $J_1, \ldots, J_r$ be the closed cells which $J$ is divided. $\color{blue}{(2)}$  Therefore, we have,    $$ l(J) = \sum_{j=1}^{r} l(J_j) \le \sum_{k=1}^n l(K_k) \le \sum_{k=1}^m l(I_k) \le m^{*}(I) + \varepsilon. \color{blue}{*}$$    Hence, we are done. My thoughts: I attempted to visualize the problem in 3D. Suppose our cells are $I_1 = (0,1] \times (0,1/2] \times [0,1]$ and $I_2 = [1/2,3/2) \times [0,1] \times [0,1]$. And we suppose $I = (1/2,1) \times (0,1) \times (0,1)$. Let $J = [1/2 + 1/16, 1 - 1/16] \times [1/16 , 1 - 1/16] \times [1/16, 1 - 1/16]$ (used $1/16$ instead of $\epsilon$ for illustration). (1): $ \color{blue}{ \text {What exactly is happening by ""extending the hyperplanes..."", i.e. what are $K_1, \ldots, K_n$?} } $ My understanding is as follows. For $I_1$ in my example we generate six hyperplanes.  $$H_1 = [0,0] \times \mathbb{R} \times \mathbb{R}, \quad H_2 = [1,1] \times \mathbb{R} \times \mathbb{R}, \ldots, \quad H_6 = \mathbb{R} \times \mathbb{R} \times [1,1] $$ and similarly for the other cells. (2): $\color{blue}{ \text{ My problem here is how we got the line of inequalities. } } $ In regards to my interpretation of (1) , $J$ is divided into disjoint intervals. I see why $l(J)= \sum_{j=1}^r l(J_j) \le \sum_{k=1}^n l(K_n)$. But I don't see how we obtain $$ \sum_{k=1}^{n}l(K_k) \le \sum_{k=1}^m l(I_k) $$  Shouldn't this be an equality (or in fact $\ge$?) As the family $\{ K_k \}$ is just a distinct representation of $\{ \bar{I_k} \} $? If $E \subseteq \mathbb{R}^p$, then we define the outer measure of $E$ to be $$m^{*} (E) = \inf \sum_{k=1}^\infty l (I_k)  $$ where the infimum is taken over all family of cells $(I_k)$ of $\mathbb{R}^p$ such that $E \subseteq \bigcup_{k=1}^{\infty} I_k$. A cell in $\mathbb{R}^p$ is of the form $I = I_1 \times \cdots \times I_p$, where $I_k$ are bounded intervals in $\mathbb{R}$. We define $l(I) = \prod_{k=1}^p l(I_k)$, where $l(I_k)$ is length of interval in $\mathbb{R}$ (so $l((a,b))=l((a,b]) = b-a$ for example.) A closed cell (open cells) in $\mathbb{R}^p$ is one where $I_k$ are all closed (open) bounded intervals in $\mathbb{R}$. So my three hyperplanes which satisfies the condition are",,"['measure-theory', 'inequality', 'lebesgue-measure', 'proof-explanation', 'outer-measure']"
6,Does convergence in the mean imply convergence in measure?,Does convergence in the mean imply convergence in measure?,,"There are a lot of types of convergences that imply other convergences, like almost uniform convergence implies convergence in measure, etc..., but this is the one that I cannot seem to find an answer for. Let me throw the definitions out there: A sequence $\{f_n\}$ of a.e. Real-valued, measurable functions is said to be $\underline{\text{convergent in measure}}$ if there is a measurable function $f$ such that for all $\epsilon >0$    \begin{equation} \lim_{n\rightarrow\infty} \mu[\{x; |f_n(x)-f(x)|\geq \epsilon\}=0\end{equation} A sequence $\{f_n\}$ of integrable functions $\underline{\text{converges in the mean}}$ to $f$ if for an integrable function $f$ it holds that $\int |f_n-f| d\mu \rightarrow 0$ as $n\rightarrow \infty$. My intuition says that convergence in mean does NOT imply convergence in measure, just because the first seems too weak to imply the second, but honestly I have no way of knowing if thats true or how to prove it. Thanks for any help!","There are a lot of types of convergences that imply other convergences, like almost uniform convergence implies convergence in measure, etc..., but this is the one that I cannot seem to find an answer for. Let me throw the definitions out there: A sequence $\{f_n\}$ of a.e. Real-valued, measurable functions is said to be $\underline{\text{convergent in measure}}$ if there is a measurable function $f$ such that for all $\epsilon >0$    \begin{equation} \lim_{n\rightarrow\infty} \mu[\{x; |f_n(x)-f(x)|\geq \epsilon\}=0\end{equation} A sequence $\{f_n\}$ of integrable functions $\underline{\text{converges in the mean}}$ to $f$ if for an integrable function $f$ it holds that $\int |f_n-f| d\mu \rightarrow 0$ as $n\rightarrow \infty$. My intuition says that convergence in mean does NOT imply convergence in measure, just because the first seems too weak to imply the second, but honestly I have no way of knowing if thats true or how to prove it. Thanks for any help!",,"['real-analysis', 'measure-theory', 'convergence-divergence', 'uniform-convergence']"
7,Let $f$ be a function with measurable domain $D$. show that$ f$ is mble iff the function $g$ is measurable,Let  be a function with measurable domain . show that is mble iff the function  is measurable,f D  f g,"I am working through some problems in Real Analysis (Royden) and I came across this one. Let $f$ be a function with  measurable domain $D$. Show that $f$ is measurable if and only if the function $g:\mathbb{R}\to \mathbb{R}$,  defined by $g(x)=f(x)$ for $x \in D$ and $g(x)=0, $ for $x\notin D$, is measurable. I realized that in one direction, if $g$ is measurable then $$\{x \in D : f(x)>c\}=\{x \in \mathbb{R}:g(x)>c \}\cap D$$ since  $g(x)=f(x)$ for $x \in D$.  Because the sets $D$ and $\{x \in \mathbb{R}:g(x)>c \}$ are measurable , $f$ is measurable. On the other hand if $f$ is measurable, then  $$\{x\in\mathbb{R}:g(x)>c\}= \begin{cases} \{x\in D:f(x)>c\}, &\mbox{ if }x\in D\\ D^c, &\mbox{ if }x\notin D \mbox{ and } c<0\\ \varnothing, &\mbox{ if }x\notin D \mbox{ and } c\geq0. \end{cases} $$ Because $\{x\in D:f(x)>c\}$, $D^c$, and $\varnothing$ are meas sets, it follows that $g$ is measurable. This illustration is almost clear to me except the part where we consider the cases where $c \ge $ 0 and $c<0$. I don't understand why we do that. Can someone explain to me or give me a similar one.","I am working through some problems in Real Analysis (Royden) and I came across this one. Let $f$ be a function with  measurable domain $D$. Show that $f$ is measurable if and only if the function $g:\mathbb{R}\to \mathbb{R}$,  defined by $g(x)=f(x)$ for $x \in D$ and $g(x)=0, $ for $x\notin D$, is measurable. I realized that in one direction, if $g$ is measurable then $$\{x \in D : f(x)>c\}=\{x \in \mathbb{R}:g(x)>c \}\cap D$$ since  $g(x)=f(x)$ for $x \in D$.  Because the sets $D$ and $\{x \in \mathbb{R}:g(x)>c \}$ are measurable , $f$ is measurable. On the other hand if $f$ is measurable, then  $$\{x\in\mathbb{R}:g(x)>c\}= \begin{cases} \{x\in D:f(x)>c\}, &\mbox{ if }x\in D\\ D^c, &\mbox{ if }x\notin D \mbox{ and } c<0\\ \varnothing, &\mbox{ if }x\notin D \mbox{ and } c\geq0. \end{cases} $$ Because $\{x\in D:f(x)>c\}$, $D^c$, and $\varnothing$ are meas sets, it follows that $g$ is measurable. This illustration is almost clear to me except the part where we consider the cases where $c \ge $ 0 and $c<0$. I don't understand why we do that. Can someone explain to me or give me a similar one.",,"['real-analysis', 'measure-theory']"
8,Question about sum of measure,Question about sum of measure,,"This could be very easy, but i don't get it. I have to state conditions for which, given a measurable extended real function $f$ on $X$ and two positive measure $m_1$ , $m_2$ on the same sigma algebra on $X$ it happens: $$\int_X f \, d(m_1 + m_2) = \int_X f \, dm_1 + \int_X f \, dm_2$$ I thought it is true for every measure. Because one can prove the risult for simple measurable and non negative functions. After that one can take $f$ to be non negative and take, thanks to simple aproximation theorem, a monotone sequence $s_n$ of simple measurable functions such that $s_n \rightarrow f$ . Thus by monotone convergence theorem, and what above we have: $$\int_X f \, d(m_1 + m_2) = \lim_n \int_X s_n \, d(m_1 + m_2) =\lim_n \left( \int_X s_n \, dm_1 + \int_X s_n \, dm_2 \right)$$ but by monotone convergence theorem $$ \lim_n \int_X s_n\, dm_1 =  \int_X f \, dm_1$$ and $$\lim_n \int_X s_n \,dm_2 =  \int_X f \, dm_2.$$ Thus the above limit is equal to the sum of the two. Thus the claim??","This could be very easy, but i don't get it. I have to state conditions for which, given a measurable extended real function on and two positive measure , on the same sigma algebra on it happens: I thought it is true for every measure. Because one can prove the risult for simple measurable and non negative functions. After that one can take to be non negative and take, thanks to simple aproximation theorem, a monotone sequence of simple measurable functions such that . Thus by monotone convergence theorem, and what above we have: but by monotone convergence theorem and Thus the above limit is equal to the sum of the two. Thus the claim??","f X m_1 m_2 X \int_X f \, d(m_1 + m_2) = \int_X f \, dm_1 + \int_X f \, dm_2 f s_n s_n \rightarrow f \int_X f \, d(m_1 + m_2) = \lim_n \int_X s_n \, d(m_1 + m_2) =\lim_n \left( \int_X s_n \, dm_1 + \int_X s_n \, dm_2 \right)  \lim_n \int_X s_n\, dm_1 =  \int_X f \, dm_1 \lim_n \int_X s_n \,dm_2 =  \int_X f \, dm_2.","['real-analysis', 'measure-theory']"
9,An application of Fatou's lemma,An application of Fatou's lemma,,"Let $\{f_k\}_{k \in \mathbb{N}}$ be a family of real positive measurable function on $D \subseteq \mathbb{R}$  such that $0 \leq f_0 \leq f_1 \leq \ldots $. If $\lim f_k = f$ on $D$ then $$\lim \int_D f_k(t)dt = \int_D \lim f_k(t) dt = \int_D f(t) dt.$$ Is this proof is right? And is there another way for the solution? Thank you! PROOF. Let $\{g_k\}_{k \in \mathbb{N}}$ be a sequence of non-negative measurable functions on $D$. If $\lim_{k \to +\infty} g_k = g$ then we have $$\int_D g = \int_D \lim g_k = \int_D \liminf_{k\to +\infty}( g_k )\leq \liminf_{k \to + \infty} \left(\int_D g_k \right) = \lim_{k \to + \infty} \int_D g_k.$$ And then  $$\int_D g \leq \lim_{k \to + \infty} \int_D g_k.$$ Note that $0 \leq f_0 \leq f_1 \leq \ldots \leq f$ on $D$. Then $\bullet$ Let us consider the family $\{f - f_k\}_{k \in \mathbb{N}}$. We have $\lim_{k \to +\infty } (f - f_k ) = 0$ and $f - f_k$ is a non-negative function for any $k \in \mathbb{N}$. Then $$ 0 \leq \lim_{k \to + \infty} \int_D (f - f_k)$$ or $$ \lim_{k \to + \infty} \int_D f_k \leq \int_D f.$$ $\bullet$ Let us consider the family $\{f_k\}_{k \in \mathbb{N}}$ then we have $$\int_D f \leq \lim_{k \to + \infty} \int_D f_k .$$ This implies that $$\lim_{k \to + \infty} \int_D f_k  = \int_D \, f \ .$$","Let $\{f_k\}_{k \in \mathbb{N}}$ be a family of real positive measurable function on $D \subseteq \mathbb{R}$  such that $0 \leq f_0 \leq f_1 \leq \ldots $. If $\lim f_k = f$ on $D$ then $$\lim \int_D f_k(t)dt = \int_D \lim f_k(t) dt = \int_D f(t) dt.$$ Is this proof is right? And is there another way for the solution? Thank you! PROOF. Let $\{g_k\}_{k \in \mathbb{N}}$ be a sequence of non-negative measurable functions on $D$. If $\lim_{k \to +\infty} g_k = g$ then we have $$\int_D g = \int_D \lim g_k = \int_D \liminf_{k\to +\infty}( g_k )\leq \liminf_{k \to + \infty} \left(\int_D g_k \right) = \lim_{k \to + \infty} \int_D g_k.$$ And then  $$\int_D g \leq \lim_{k \to + \infty} \int_D g_k.$$ Note that $0 \leq f_0 \leq f_1 \leq \ldots \leq f$ on $D$. Then $\bullet$ Let us consider the family $\{f - f_k\}_{k \in \mathbb{N}}$. We have $\lim_{k \to +\infty } (f - f_k ) = 0$ and $f - f_k$ is a non-negative function for any $k \in \mathbb{N}$. Then $$ 0 \leq \lim_{k \to + \infty} \int_D (f - f_k)$$ or $$ \lim_{k \to + \infty} \int_D f_k \leq \int_D f.$$ $\bullet$ Let us consider the family $\{f_k\}_{k \in \mathbb{N}}$ then we have $$\int_D f \leq \lim_{k \to + \infty} \int_D f_k .$$ This implies that $$\lim_{k \to + \infty} \int_D f_k  = \int_D \, f \ .$$",,"['integration', 'measure-theory', 'lebesgue-integral', 'lebesgue-measure']"
10,Equivalence of different criteria for Lebesgue measurability,Equivalence of different criteria for Lebesgue measurability,,"Let $E \subset \mathbb{R}^d$ be a set. Two different criteria for Lebesgue measurability of $E$ is given by: $(i)$ (Outer approximation by open) For every $\epsilon>0$, one can contain $E$ in an open set $U$ with $m^*(U \setminus E) \leq \epsilon$. $(ii)$ (Almost open) For every $\epsilon>0$, one can find an open set $U$ such that $m^*(U \Delta E) \leq \epsilon$. The problem is to show the equivalence of these two statements. Now, $(i) \Rightarrow (ii)$ is of course trivial. But I'm having some difficulty in showing $(ii) \Rightarrow (i)$. Given that, for every $\epsilon>0$, one can find an open set $U$ such that $m^*(U \Delta E) \leq \epsilon$, how can I find an open set $V$, containing $E$ with $m^*(V \setminus E) \leq \epsilon ~??$ Any help would be much appreciated!","Let $E \subset \mathbb{R}^d$ be a set. Two different criteria for Lebesgue measurability of $E$ is given by: $(i)$ (Outer approximation by open) For every $\epsilon>0$, one can contain $E$ in an open set $U$ with $m^*(U \setminus E) \leq \epsilon$. $(ii)$ (Almost open) For every $\epsilon>0$, one can find an open set $U$ such that $m^*(U \Delta E) \leq \epsilon$. The problem is to show the equivalence of these two statements. Now, $(i) \Rightarrow (ii)$ is of course trivial. But I'm having some difficulty in showing $(ii) \Rightarrow (i)$. Given that, for every $\epsilon>0$, one can find an open set $U$ such that $m^*(U \Delta E) \leq \epsilon$, how can I find an open set $V$, containing $E$ with $m^*(V \setminus E) \leq \epsilon ~??$ Any help would be much appreciated!",,"['measure-theory', 'lebesgue-measure']"
11,"Generated sigma fields, measurable functions","Generated sigma fields, measurable functions",,"Suppose that $X_{1}, X_{2}, \ldots, X_{n}$ are random variables with  $$X_{i}(\omega) : (\Omega, \mathcal{F})\to (\mathbb{R},\mathcal{R})$$ where $\Omega$ is the sample space, $\mathcal{F}$ is the $\sigma$-field, and $\mathcal{R}$ is the Borel $\sigma$-field. Now suppose that $f(X_{1}, X_{2}, \ldots, X_{n})$ is a measurable function, $f:(\mathbb{R}^{n}, \mathcal{R}^{n})\to (\mathbb{R},\mathcal{R})$, and consider the $\sigma$-fields generated by the random variables $X_{1}, X_{2}, \ldots, X_{n}$, which I will denote $\sigma(X_{1}), \sigma(X_{2}), \ldots, \sigma(X_{n})$. Finally, let $Y = f(X_{1}(\omega), X_{2}(\omega), \ldots, X_{n}(\omega))$ be a random variable with $Y: (\Omega, \mathcal{F}) \to (\mathbb{R},\mathcal{R})$. I want to show that  $$\sigma(Y) \subset \sigma\left(\bigcup_{i=1}^{n} \sigma(X_{i})\right)$$ I am having trouble with the exact formulation of the proof. Can anyone provide a rigorous proof of this? Motivation: In Durrett's Probability: Theory and Examples (fourth edition), the proof of theorem 2.1.6. basically says that if $\mathcal{G} = \sigma\left(\bigcup_{j} \sigma(X_{j})\right)$, then $f(X_{1}, X_{2}, \ldots, X_{n}) \in \mathcal{G}$ (I believe Durrett meant to put $f^{-1}(X_{1}, X_{2}, \ldots, X_{n}) \in \mathcal{G}$). I want to make sense of why this is true.","Suppose that $X_{1}, X_{2}, \ldots, X_{n}$ are random variables with  $$X_{i}(\omega) : (\Omega, \mathcal{F})\to (\mathbb{R},\mathcal{R})$$ where $\Omega$ is the sample space, $\mathcal{F}$ is the $\sigma$-field, and $\mathcal{R}$ is the Borel $\sigma$-field. Now suppose that $f(X_{1}, X_{2}, \ldots, X_{n})$ is a measurable function, $f:(\mathbb{R}^{n}, \mathcal{R}^{n})\to (\mathbb{R},\mathcal{R})$, and consider the $\sigma$-fields generated by the random variables $X_{1}, X_{2}, \ldots, X_{n}$, which I will denote $\sigma(X_{1}), \sigma(X_{2}), \ldots, \sigma(X_{n})$. Finally, let $Y = f(X_{1}(\omega), X_{2}(\omega), \ldots, X_{n}(\omega))$ be a random variable with $Y: (\Omega, \mathcal{F}) \to (\mathbb{R},\mathcal{R})$. I want to show that  $$\sigma(Y) \subset \sigma\left(\bigcup_{i=1}^{n} \sigma(X_{i})\right)$$ I am having trouble with the exact formulation of the proof. Can anyone provide a rigorous proof of this? Motivation: In Durrett's Probability: Theory and Examples (fourth edition), the proof of theorem 2.1.6. basically says that if $\mathcal{G} = \sigma\left(\bigcup_{j} \sigma(X_{j})\right)$, then $f(X_{1}, X_{2}, \ldots, X_{n}) \in \mathcal{G}$ (I believe Durrett meant to put $f^{-1}(X_{1}, X_{2}, \ldots, X_{n}) \in \mathcal{G}$). I want to make sense of why this is true.",,"['real-analysis', 'probability', 'measure-theory']"
12,The difference of closure of a set,The difference of closure of a set,,"Let $A$, $B\subset \mathbb R^N$ be given such that $A\subset B$. Assume that $\mathcal H^{N-1}(B\setminus A)<\epsilon$ where $\epsilon>0$ is a fixed constant and $\mathcal H^{N-1}$ is the $N-1$ dimensional Hausdorff measure (so we may think $A$ and $B$ are two curves embedded in $\mathbb R^N$). Moreover, we know that $\mathcal H^{N-1}(\overline {B}\setminus B)<\epsilon$ where $\overline{B}$ denotes the closure of set $B$, and $\mathcal H^{N-1}(\bar A\setminus A)=0$. My question: do we have  $$ \mathcal H^{N-1}(\overline {B\setminus A})<2\epsilon $$ hold? Update: I added an assumption on $A$ such that $A$ is compact, i.e.,  $$ \mathcal H^{N-1}(\overline {A}\setminus A^{\circ})=0 $$ where by $A^\circ$ we mean the interior of $A$. That is, I assume that $\mathcal H^{N-1}(\partial A)=0$. Hence, I may write \begin{align} \mathcal H^{N-1}(\overline {B\setminus A})\leq\mathcal H^{N-1}(\overline {\overline {B}\setminus A^\circ}) = \mathcal H^{N-1}( {\overline {B}\setminus A^\circ})\\ \leq\mathcal H^{N-1}( {\overline {B}\setminus B})+\mathcal H^{N-1}( {{B}\setminus A})+\mathcal H^{N-1}( {{A}\setminus A^\circ})\leq 2\epsilon. \end{align} PS: I understand that $A^\circ$ might be ill-defined... I am trying to work out a fix.","Let $A$, $B\subset \mathbb R^N$ be given such that $A\subset B$. Assume that $\mathcal H^{N-1}(B\setminus A)<\epsilon$ where $\epsilon>0$ is a fixed constant and $\mathcal H^{N-1}$ is the $N-1$ dimensional Hausdorff measure (so we may think $A$ and $B$ are two curves embedded in $\mathbb R^N$). Moreover, we know that $\mathcal H^{N-1}(\overline {B}\setminus B)<\epsilon$ where $\overline{B}$ denotes the closure of set $B$, and $\mathcal H^{N-1}(\bar A\setminus A)=0$. My question: do we have  $$ \mathcal H^{N-1}(\overline {B\setminus A})<2\epsilon $$ hold? Update: I added an assumption on $A$ such that $A$ is compact, i.e.,  $$ \mathcal H^{N-1}(\overline {A}\setminus A^{\circ})=0 $$ where by $A^\circ$ we mean the interior of $A$. That is, I assume that $\mathcal H^{N-1}(\partial A)=0$. Hence, I may write \begin{align} \mathcal H^{N-1}(\overline {B\setminus A})\leq\mathcal H^{N-1}(\overline {\overline {B}\setminus A^\circ}) = \mathcal H^{N-1}( {\overline {B}\setminus A^\circ})\\ \leq\mathcal H^{N-1}( {\overline {B}\setminus B})+\mathcal H^{N-1}( {{B}\setminus A})+\mathcal H^{N-1}( {{A}\setminus A^\circ})\leq 2\epsilon. \end{align} PS: I understand that $A^\circ$ might be ill-defined... I am trying to work out a fix.",,"['general-topology', 'measure-theory', 'lebesgue-measure']"
13,Measurable function which is not equivalent to real continuous function,Measurable function which is not equivalent to real continuous function,,"Hi Can anyone help with the following problem: Does there exist a measurable function $f:[0,1]\to \mathbb{R}$ which is not equivalent to any real continuous function on $[0,1]$? Does there exist a non-measurable function $f:\mathbb{R}\to\mathbb{R}$ such that $f^{-1}(y)$ is measurable for any $y\in\mathbb{R}$. Intuitively I believe that both of the answers are 'Yes, but I don't know how to prove? Can anyone help. It would be highly appreciated.","Hi Can anyone help with the following problem: Does there exist a measurable function $f:[0,1]\to \mathbb{R}$ which is not equivalent to any real continuous function on $[0,1]$? Does there exist a non-measurable function $f:\mathbb{R}\to\mathbb{R}$ such that $f^{-1}(y)$ is measurable for any $y\in\mathbb{R}$. Intuitively I believe that both of the answers are 'Yes, but I don't know how to prove? Can anyone help. It would be highly appreciated.",,"['measure-theory', 'lebesgue-measure']"
14,"Measures that coincide on every $(a,b)$ are equal",Measures that coincide on every  are equal,"(a,b)","From Bass, Real Analysis for Graduate Students : Suppose $X$ is the set of real numbers, $\mathcal B$ the Borel $\sigma$-algebra and $m$ and $n$ are two measures on $(X,\mathcal B)$ such that $m((a,b))=n((a,b))<\infty$ whenever $-\infty<a<b<\infty$. Prove that $m(A)=n(A)$ whenever $A\in \mathcal B$. I'm thinking the $\pi-\lambda$ theorem comes in handy in this situation. I'm therefore inclined to let $\mathcal C = \{(a,b), a<b\}$ and $\mathcal D = \{A\in \mathcal B, m(A)=n(A)\}$. $C$ is obviously a $\pi$-system, and I expect $\mathcal D$ to be a Dynkin system (also referred to as $\lambda$-system). It's easy to prove that $\mathbb R\in \mathcal D$ and $\mathcal D$ is closed under increasing union. Nonetheless, I'm running into some trouble when attempting to prove that $\mathcal D$ is stable under complement... Indeed, given $A,B$ in $\mathcal D$ such that $A\subset B$ , the following holds: $m(B) = m(B\setminus A) + m(A)$, hence $n(B) = m(B\setminus A)+n(A)$. But similarly, $n(B) = n(B\setminus A) + n(A)$. Hence $m(B\setminus A)+n(A) = n(B\setminus A) + n(A)$ The problem is, $1+\infty = 2+\infty $, yet $1\neq 2$. I cannot derive $m(B\setminus A) = n(B\setminus A)$ unless $n(A)<\infty$, which may not be true... Note that I haven't used finitess of $n$ and $m$ on $(a,b)$ yet ... Any help is much appreciated.","From Bass, Real Analysis for Graduate Students : Suppose $X$ is the set of real numbers, $\mathcal B$ the Borel $\sigma$-algebra and $m$ and $n$ are two measures on $(X,\mathcal B)$ such that $m((a,b))=n((a,b))<\infty$ whenever $-\infty<a<b<\infty$. Prove that $m(A)=n(A)$ whenever $A\in \mathcal B$. I'm thinking the $\pi-\lambda$ theorem comes in handy in this situation. I'm therefore inclined to let $\mathcal C = \{(a,b), a<b\}$ and $\mathcal D = \{A\in \mathcal B, m(A)=n(A)\}$. $C$ is obviously a $\pi$-system, and I expect $\mathcal D$ to be a Dynkin system (also referred to as $\lambda$-system). It's easy to prove that $\mathbb R\in \mathcal D$ and $\mathcal D$ is closed under increasing union. Nonetheless, I'm running into some trouble when attempting to prove that $\mathcal D$ is stable under complement... Indeed, given $A,B$ in $\mathcal D$ such that $A\subset B$ , the following holds: $m(B) = m(B\setminus A) + m(A)$, hence $n(B) = m(B\setminus A)+n(A)$. But similarly, $n(B) = n(B\setminus A) + n(A)$. Hence $m(B\setminus A)+n(A) = n(B\setminus A) + n(A)$ The problem is, $1+\infty = 2+\infty $, yet $1\neq 2$. I cannot derive $m(B\setminus A) = n(B\setminus A)$ unless $n(A)<\infty$, which may not be true... Note that I haven't used finitess of $n$ and $m$ on $(a,b)$ yet ... Any help is much appreciated.",,"['real-analysis', 'measure-theory']"
15,"How to prove the ""Average Lemma"" for integral functions?","How to prove the ""Average Lemma"" for integral functions?",,"I am having some troubles with the proof of this: let be $f\in\mathfrak{L}_1(X,S,\mu)$ such that exists $k\geq0$ that satisfies; for all $E\in S$ with $0<\mu(E)<\infty,$ $$\frac{|\int_{E}f \, d\mu|}{\mu(E)}\leq k$$ then $|f|\leq k$ almost everywhere. We can suppose that exists $E\in S$ with the condition. I have proved the trivial case $k=0,$ but when $k>0$ I tried (with any conlcution) to define $E:=\{x\in X: |f(x)|>k\}$ and prove $\mu(E)=0$ by contradiction, we can prove $\mu(E)<\infty$ using $\,\,f$ is integrable and then we can use the hypothesis.","I am having some troubles with the proof of this: let be $f\in\mathfrak{L}_1(X,S,\mu)$ such that exists $k\geq0$ that satisfies; for all $E\in S$ with $0<\mu(E)<\infty,$ $$\frac{|\int_{E}f \, d\mu|}{\mu(E)}\leq k$$ then $|f|\leq k$ almost everywhere. We can suppose that exists $E\in S$ with the condition. I have proved the trivial case $k=0,$ but when $k>0$ I tried (with any conlcution) to define $E:=\{x\in X: |f(x)|>k\}$ and prove $\mu(E)=0$ by contradiction, we can prove $\mu(E)<\infty$ using $\,\,f$ is integrable and then we can use the hypothesis.",,"['measure-theory', 'average']"
16,"Haar measure scalars, what am I doing wrong here?","Haar measure scalars, what am I doing wrong here?",,"Let $\mu$ be a Borel measure on a topological space $X$, and let $E \subseteq X$ be Borel.  Let $\phi$ be a homeomorphism of $X$, and let $\lambda$ be the measure given by $\lambda(A) = \mu(\phi(A))$.  If $f: E \rightarrow \mathbb{C}$ is measurable and integrable, then so is $f \circ \phi: \phi^{-1}E \rightarrow \mathbb{C}$, and $$\int\limits_E f \space d \mu= \int\limits_{\phi^{-1}E} f \circ \phi \space d\lambda$$ For example, if $f$ is a simple function, say $f = \sum\limits_{i=1}^m c_i \chi_{E_i}$ for $E_i \subseteq E$ disjoint and Borel, then $f \circ \phi: \phi^{-1}E \rightarrow \mathbb{C}$ is the function $\sum\limits_{i=1}^m c_i \chi_{\phi^{-1}E_i}$, and $$\int\limits_{\phi^{-1}E} f \circ \phi \space d \lambda = \sum\limits_{i=1}^m c_i \lambda(\phi^{-1}E_i) = \sum\limits_{i=1}^m c_i\mu(E_i) = \int\limits_E f \space d \mu$$ Now let $G$ be a locally compact topological group, $\mu$ a left Haar measure on $G$, and $\phi$ the topological group isomorphism $x \mapsto x_0xx_0^{-1}$ for a fixed $x_0 \in G$.  Define $\lambda = \mu \circ \phi$.  It is easy to see that $\lambda(E) = \mu(x_0Ex_0^{-1}) = \mu(Ex_0^{-1})$ for all Borel sets $E$, and that $\lambda$ is also a left Haar measure.  Therefore, there exists a constant $\Delta(x_0) = \Delta > 0$ such that $\lambda = \Delta \mu$, or in other words $$\mu(Ex_0^{-1}) = \Delta \mu(E)$$ for all $E$ Borel.  Now, for $f: G \rightarrow \mathbb{C}$ integrable, we should have $$\int\limits_G f d \mu = \int\limits_{\phi^{-1}G} f \circ \phi \space d \lambda = \int\limits_G f \circ \phi  \space d\lambda = \Delta \int\limits_G f \circ \phi \space d\mu$$ Or in other words, $$\int\limits_G f(x)dx = \Delta(x_0) \int\limits_G f(x_0xx_0^{-1}) dx$$ However, the notes I'm reading here ( http://www.math.toronto.edu/murnaghan/courses/mat1196/rnotes.pdf ) page 19, have $\Delta(x_0)$ on the other side of the equation.  Am I making a mistake somewhere?","Let $\mu$ be a Borel measure on a topological space $X$, and let $E \subseteq X$ be Borel.  Let $\phi$ be a homeomorphism of $X$, and let $\lambda$ be the measure given by $\lambda(A) = \mu(\phi(A))$.  If $f: E \rightarrow \mathbb{C}$ is measurable and integrable, then so is $f \circ \phi: \phi^{-1}E \rightarrow \mathbb{C}$, and $$\int\limits_E f \space d \mu= \int\limits_{\phi^{-1}E} f \circ \phi \space d\lambda$$ For example, if $f$ is a simple function, say $f = \sum\limits_{i=1}^m c_i \chi_{E_i}$ for $E_i \subseteq E$ disjoint and Borel, then $f \circ \phi: \phi^{-1}E \rightarrow \mathbb{C}$ is the function $\sum\limits_{i=1}^m c_i \chi_{\phi^{-1}E_i}$, and $$\int\limits_{\phi^{-1}E} f \circ \phi \space d \lambda = \sum\limits_{i=1}^m c_i \lambda(\phi^{-1}E_i) = \sum\limits_{i=1}^m c_i\mu(E_i) = \int\limits_E f \space d \mu$$ Now let $G$ be a locally compact topological group, $\mu$ a left Haar measure on $G$, and $\phi$ the topological group isomorphism $x \mapsto x_0xx_0^{-1}$ for a fixed $x_0 \in G$.  Define $\lambda = \mu \circ \phi$.  It is easy to see that $\lambda(E) = \mu(x_0Ex_0^{-1}) = \mu(Ex_0^{-1})$ for all Borel sets $E$, and that $\lambda$ is also a left Haar measure.  Therefore, there exists a constant $\Delta(x_0) = \Delta > 0$ such that $\lambda = \Delta \mu$, or in other words $$\mu(Ex_0^{-1}) = \Delta \mu(E)$$ for all $E$ Borel.  Now, for $f: G \rightarrow \mathbb{C}$ integrable, we should have $$\int\limits_G f d \mu = \int\limits_{\phi^{-1}G} f \circ \phi \space d \lambda = \int\limits_G f \circ \phi  \space d\lambda = \Delta \int\limits_G f \circ \phi \space d\mu$$ Or in other words, $$\int\limits_G f(x)dx = \Delta(x_0) \int\limits_G f(x_0xx_0^{-1}) dx$$ However, the notes I'm reading here ( http://www.math.toronto.edu/murnaghan/courses/mat1196/rnotes.pdf ) page 19, have $\Delta(x_0)$ on the other side of the equation.  Am I making a mistake somewhere?",,"['integration', 'measure-theory', 'harmonic-analysis', 'topological-groups']"
17,Cardinality function is measurable,Cardinality function is measurable,,"Let $f: [0,1] \rightarrow \mathbb{R}$ be a continuous function. Let also $g$ be a function, defined by the following condition:for each $a \in [0, + \infty]$ $$g(a)=\text{card} \{ x \in [0, 1] | f(x) = a \} \in [0, + \infty)$$ I would like to prove that $g$ is also a measurable function.  Are there any hints that might help? Probably, it is worth trying to prove it more or less directly, by checking that $\{ a \in [0, + \infty] | g(a) < c \}$ is measurable for any $c$, but this approach does not seem to be clear enough, since the preimage of $g$ would be some cardinal number.","Let $f: [0,1] \rightarrow \mathbb{R}$ be a continuous function. Let also $g$ be a function, defined by the following condition:for each $a \in [0, + \infty]$ $$g(a)=\text{card} \{ x \in [0, 1] | f(x) = a \} \in [0, + \infty)$$ I would like to prove that $g$ is also a measurable function.  Are there any hints that might help? Probably, it is worth trying to prove it more or less directly, by checking that $\{ a \in [0, + \infty] | g(a) < c \}$ is measurable for any $c$, but this approach does not seem to be clear enough, since the preimage of $g$ would be some cardinal number.",,"['real-analysis', 'measure-theory', 'lebesgue-integral', 'lebesgue-measure']"
18,Solving Cauchy's functional equation for Borel-measurable $f$,Solving Cauchy's functional equation for Borel-measurable,f,"Show that if $f$ is a continuous function on the real line such that for all $x$ and $y$, $f ((x + y)/2) = (f(x) + f (y)) /2$, then $f (x) = ax + b$ for some real $a$ and $b$. I have solved this problem, but there is a second part: If $f$ is Borel and satisfies the functional equation, show $f(x)=ax+b$ I'm not getting how to make use of the Borel-measurability property actually holds for all Borel $f$.","Show that if $f$ is a continuous function on the real line such that for all $x$ and $y$, $f ((x + y)/2) = (f(x) + f (y)) /2$, then $f (x) = ax + b$ for some real $a$ and $b$. I have solved this problem, but there is a second part: If $f$ is Borel and satisfies the functional equation, show $f(x)=ax+b$ I'm not getting how to make use of the Borel-measurability property actually holds for all Borel $f$.",,"['measure-theory', 'discrete-mathematics', 'functional-equations']"
19,how can I show that the translate of an open set is open and that the translate of a closed set is closed [closed],how can I show that the translate of an open set is open and that the translate of a closed set is closed [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question Let $P$ be an open set of real numbers and let $C$ be an closed set of real numbers.  Let $x$ be a real number.  How can I show that $P + x$ is open and that $C + x$ is closed? It's been a while since I worked with topology and I'm sort of stuck.","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question Let $P$ be an open set of real numbers and let $C$ be an closed set of real numbers.  Let $x$ be a real number.  How can I show that $P + x$ is open and that $C + x$ is closed? It's been a while since I worked with topology and I'm sort of stuck.",,"['real-analysis', 'measure-theory']"
20,"If $f\ge0$ and $ \int_{0}^{1} f(x)^kdx$ does not depend on $k\geq 1$ then $f=\mathbf 1_A$ almost everywhere, for some measurable subset $A$ of $[0,1]$","If  and  does not depend on  then  almost everywhere, for some measurable subset  of","f\ge0  \int_{0}^{1} f(x)^kdx k\geq 1 f=\mathbf 1_A A [0,1]","If $ \int_{0}^{1} (f(x))^k dx= C$ for all $k\geq 1$, then there exists a measurable subset A of [0,1] where $f(x)=1_{A}(x)$ for almost every x Note that $ f:[0,1] -> R^{+}$ I am stuck on this problem. Here is what I have done so far.. We know $\int_{0}^{1} f(x) dx = \int_{0}^{1} f^2(x) dx $ which implies $\int (f-f^2) dx= 0$ which implies $f(x)-f^2(x)= 0$ almost everywhere on [0,1], which implies $f(x)(1-f(x))=0$ a.e. on [0,1] hence f(x)= 0 or 1 for a.e. x on [0,1]. Where do I go from here? Is this correct so far? How do I know that the set of points where $f(x)=1$,call it A, will be measurable necessarily? Also how do I use the other powers of f? I feel I am missing something.","If $ \int_{0}^{1} (f(x))^k dx= C$ for all $k\geq 1$, then there exists a measurable subset A of [0,1] where $f(x)=1_{A}(x)$ for almost every x Note that $ f:[0,1] -> R^{+}$ I am stuck on this problem. Here is what I have done so far.. We know $\int_{0}^{1} f(x) dx = \int_{0}^{1} f^2(x) dx $ which implies $\int (f-f^2) dx= 0$ which implies $f(x)-f^2(x)= 0$ almost everywhere on [0,1], which implies $f(x)(1-f(x))=0$ a.e. on [0,1] hence f(x)= 0 or 1 for a.e. x on [0,1]. Where do I go from here? Is this correct so far? How do I know that the set of points where $f(x)=1$,call it A, will be measurable necessarily? Also how do I use the other powers of f? I feel I am missing something.",,"['real-analysis', 'measure-theory']"
21,orthogonal polynomial of the second kind,orthogonal polynomial of the second kind,,"Let $L:  \mathbb{R}[x] \rightarrow \mathbb{R}$ be a positive definite linear functional and let that $\{s_n\}$ be a positive semi-definite sequence such that $L(x^n)= s_n, n\ge 0.$ Given a positive definite sequence, I was able to use the Gram-Schimdt orthogonalization method to construct a sequence of orthogonal polynomials $\{p_n\}$ whose leading coefficient is positive due to the  positivity nature of the sequence given. It turns out that this sequence of orthogonal polynomials  $\{p_n\}$ satsifies a three term recurrence relation given below \begin{equation} xp_n(x) =b_np_{n+1}(x)+a_np_n(x)+b_{n-1}p_{n-1}(x) , \quad n\ge 0 \end{equation} We can see the sequence $p_n(x)$ as a solution to the three term recurrence relations stated above. Akhiezer http://www.maths.ed.ac.uk/~aar/papers/akhiezer.pdf as my reference introduced another solution to this three term recurrence relation by defining another solution by \begin{equation} q_n(x)= \displaystyle L\left(\frac{p_n(x)-p_n(y)}{x-y}\right) \end{equation} where the  quotient $\frac{p_n(x)-p_n(y)}{x-y}$  is a polynomial in $x$ and $y$ and $q_n(x)$ is a polynomial in variable $x$ and its degree is $n-1$ for any $x,y \in \mathbb{R}$ so that we have $ \displaystyle xq_n(x) =b_nq_{n+1}(x)+a_nq_n(x)+b_{n-1}q_{n-1}(x), n\ge 1$ with $q_0(x)=0$ and $q_1(x)= \frac{1}{b_0}$ My question is how can the  linear functional $L$ be defined on rational functions since its domain is $\mathbb{R}[x]$. I have troubles understanding  this definition even though I actually confirmed the definition is true by computing $q_1,q_2$.You can please check Akhiezer page 8 for more clarification. Details and explanation will be much appreciated.","Let $L:  \mathbb{R}[x] \rightarrow \mathbb{R}$ be a positive definite linear functional and let that $\{s_n\}$ be a positive semi-definite sequence such that $L(x^n)= s_n, n\ge 0.$ Given a positive definite sequence, I was able to use the Gram-Schimdt orthogonalization method to construct a sequence of orthogonal polynomials $\{p_n\}$ whose leading coefficient is positive due to the  positivity nature of the sequence given. It turns out that this sequence of orthogonal polynomials  $\{p_n\}$ satsifies a three term recurrence relation given below \begin{equation} xp_n(x) =b_np_{n+1}(x)+a_np_n(x)+b_{n-1}p_{n-1}(x) , \quad n\ge 0 \end{equation} We can see the sequence $p_n(x)$ as a solution to the three term recurrence relations stated above. Akhiezer http://www.maths.ed.ac.uk/~aar/papers/akhiezer.pdf as my reference introduced another solution to this three term recurrence relation by defining another solution by \begin{equation} q_n(x)= \displaystyle L\left(\frac{p_n(x)-p_n(y)}{x-y}\right) \end{equation} where the  quotient $\frac{p_n(x)-p_n(y)}{x-y}$  is a polynomial in $x$ and $y$ and $q_n(x)$ is a polynomial in variable $x$ and its degree is $n-1$ for any $x,y \in \mathbb{R}$ so that we have $ \displaystyle xq_n(x) =b_nq_{n+1}(x)+a_nq_n(x)+b_{n-1}q_{n-1}(x), n\ge 1$ with $q_0(x)=0$ and $q_1(x)= \frac{1}{b_0}$ My question is how can the  linear functional $L$ be defined on rational functions since its domain is $\mathbb{R}[x]$. I have troubles understanding  this definition even though I actually confirmed the definition is true by computing $q_1,q_2$.You can please check Akhiezer page 8 for more clarification. Details and explanation will be much appreciated.",,"['real-analysis', 'linear-algebra', 'measure-theory', 'recurrence-relations', 'orthogonal-polynomials']"
22,Show that $F$ is a field,Show that  is a field,F,"Suppose $F_0$ is the collection of finite unions of disjoint half-open half-closed subsets in $(0,1]$, i.e. $A=\cup_{j=1}^J (a_j,b_j]$ where $0\leq a_1\leq b_1 \leq a_2...\leq b_J\leq 1.$ How to show $F_0$ is a field (algebra)? I am able to prove two of the conditions needed, see below: 1, By definition, we can take $A=(a_1,b_1]$, where $0\leq a_1=b_1\leq 1$, so that $A$ is an empty set and is in $F_0$. 2, Suppose $A$ has the general form $A=\cup_{j=1}^J (a_j,b_j]$ where $0\leq a_1\leq b_1 \leq a_2...\leq b_J\leq 1.$ So $A^c=(0,a_1)\cup (b_1,a_2]\cup (b_3,a_3]...\cup (b_J,1]$ which is a finite union of disjoint half-open half-closed subsets in $(0,1]$. So $A^c\in F_0$. For the closure under finite unions since each $A_i$ can be overlapped, I have no ideas to show that. Can anyone help?","Suppose $F_0$ is the collection of finite unions of disjoint half-open half-closed subsets in $(0,1]$, i.e. $A=\cup_{j=1}^J (a_j,b_j]$ where $0\leq a_1\leq b_1 \leq a_2...\leq b_J\leq 1.$ How to show $F_0$ is a field (algebra)? I am able to prove two of the conditions needed, see below: 1, By definition, we can take $A=(a_1,b_1]$, where $0\leq a_1=b_1\leq 1$, so that $A$ is an empty set and is in $F_0$. 2, Suppose $A$ has the general form $A=\cup_{j=1}^J (a_j,b_j]$ where $0\leq a_1\leq b_1 \leq a_2...\leq b_J\leq 1.$ So $A^c=(0,a_1)\cup (b_1,a_2]\cup (b_3,a_3]...\cup (b_J,1]$ which is a finite union of disjoint half-open half-closed subsets in $(0,1]$. So $A^c\in F_0$. For the closure under finite unions since each $A_i$ can be overlapped, I have no ideas to show that. Can anyone help?",,"['real-analysis', 'measure-theory']"
23,Intermediate measure theorem?,Intermediate measure theorem?,,"Statement: Let $\lambda$ be the Lebesgue measure on the real line and $f$ be a continuous function. For every $0\le\epsilon \le 1$, there is a compact set $S\subseteq [0,1]$ with $\lambda(S) = \epsilon$ and \begin{align*} \int_0^1 f(x)\mathbf{1}_S(x)\, \lambda(\mathrm{d}x) = \epsilon\int_0^1 f(x)\,\lambda(\mathrm{d}x)\,\,. \end{align*} Is this statement true? If so, what would be the name of this principle? I only work with discrete mathematics in my day-to-day life and I apologize if this question is too naive.","Statement: Let $\lambda$ be the Lebesgue measure on the real line and $f$ be a continuous function. For every $0\le\epsilon \le 1$, there is a compact set $S\subseteq [0,1]$ with $\lambda(S) = \epsilon$ and \begin{align*} \int_0^1 f(x)\mathbf{1}_S(x)\, \lambda(\mathrm{d}x) = \epsilon\int_0^1 f(x)\,\lambda(\mathrm{d}x)\,\,. \end{align*} Is this statement true? If so, what would be the name of this principle? I only work with discrete mathematics in my day-to-day life and I apologize if this question is too naive.",,"['integration', 'measure-theory']"
24,Example when the tail $\sigma$-algebra is not generated by the even and odd tail $\sigma$-algebras,Example when the tail -algebra is not generated by the even and odd tail -algebras,\sigma \sigma,"The even tail $\sigma$-algebra $T^0$ and odd tail $\sigma$-algebra $T^1$ are always contained in the tail $\sigma$-algebra $T$.   Now I want to prove that it may happen that $T\neq\sigma(T^0,T^1)$. I have tried defining different families of $\sigma$-algebras (converging vs non converging sequences, starting with constant number of zeros or ones, ending with ones or zeros, etc.) but I can't find an example to demonstrate my claim that $T\neq\sigma(T^0,T^1)$. Here are the relevant definitions. Let $\Omega = \{0,1\}^{\mathbb N}$ the set of all binary sequences. If $\mathcal F_n$ is a family of $\sigma$-algebras, we define $$T_n=\sigma\left(\bigcup_{k\geq n}\mathcal F_k\right)\qquad T^0_n=\sigma\left(\bigcup_{k\geq n}\mathcal F_{2k}\right)\qquad T^1_n=\sigma\left(\bigcup_{k\geq n}\mathcal F_{2k-1}\right)$$ and $T=\bigcap\limits_nT_n$ the tail $\sigma- $algebra, $T^0=\bigcap\limits_nT^0_n$ the even tail $\sigma-$ algebra, $T^1=\bigcap\limits_nT^1_n$ the odd tail $\sigma-$ algebra.","The even tail $\sigma$-algebra $T^0$ and odd tail $\sigma$-algebra $T^1$ are always contained in the tail $\sigma$-algebra $T$.   Now I want to prove that it may happen that $T\neq\sigma(T^0,T^1)$. I have tried defining different families of $\sigma$-algebras (converging vs non converging sequences, starting with constant number of zeros or ones, ending with ones or zeros, etc.) but I can't find an example to demonstrate my claim that $T\neq\sigma(T^0,T^1)$. Here are the relevant definitions. Let $\Omega = \{0,1\}^{\mathbb N}$ the set of all binary sequences. If $\mathcal F_n$ is a family of $\sigma$-algebras, we define $$T_n=\sigma\left(\bigcup_{k\geq n}\mathcal F_k\right)\qquad T^0_n=\sigma\left(\bigcup_{k\geq n}\mathcal F_{2k}\right)\qquad T^1_n=\sigma\left(\bigcup_{k\geq n}\mathcal F_{2k-1}\right)$$ and $T=\bigcap\limits_nT_n$ the tail $\sigma- $algebra, $T^0=\bigcap\limits_nT^0_n$ the even tail $\sigma-$ algebra, $T^1=\bigcap\limits_nT^1_n$ the odd tail $\sigma-$ algebra.",,"['probability', 'measure-theory']"
25,Can we approximate an $L^1 $function pointwise almost everywhere by a continous function?,Can we approximate an function pointwise almost everywhere by a continous function?,L^1 ,Using this result Under what condition can converge in $L^1$ imply converge a.e.? . Can one infer that we can approximate an $L^1$ a.e by a continuous function on a finite measure space? I.e find $h$ cts s.t $\mid h-g \mid < \epsilon $ a.e Letting $=f_{n}=g-c_{n}$ where $c_{n}$ is a sequence of continuous approximating to $g$. Other suggestions which are simplier if this is true would be appreciated! I might have an alternative solution which is less messy; Since the measure is finite convergece in $L^1$ implies convergnce in measure which implies there is a subseq convering a.e we can pick/find some cts function from this subsequence that are arbitrarly close a.e to out $L^1$ function. Finite measure was added after Ian's comments!,Using this result Under what condition can converge in $L^1$ imply converge a.e.? . Can one infer that we can approximate an $L^1$ a.e by a continuous function on a finite measure space? I.e find $h$ cts s.t $\mid h-g \mid < \epsilon $ a.e Letting $=f_{n}=g-c_{n}$ where $c_{n}$ is a sequence of continuous approximating to $g$. Other suggestions which are simplier if this is true would be appreciated! I might have an alternative solution which is less messy; Since the measure is finite convergece in $L^1$ implies convergnce in measure which implies there is a subseq convering a.e we can pick/find some cts function from this subsequence that are arbitrarly close a.e to out $L^1$ function. Finite measure was added after Ian's comments!,,"['measure-theory', 'proof-verification', 'lp-spaces']"
26,Convex hull that ignores sets of measure zero,Convex hull that ignores sets of measure zero,,"In my research I use a definition of convex hull that is compatible with measure theory, in the sense that it ignores negligible sets. Are there any references to the following concept, or similar concepts, in the literature? (The name, obviously, need not be the same.) Suppose $A \subset \mathbb{R}^d$, $d \in \mathbb{Z}_+$. Define the closed essential convex hull of $A$ as the intersection of all half-spaces $H \subset \mathbb{R}^d$ that satisfy \begin{equation} m(A \setminus H) = 0, \end{equation} where $m$ is the $d$-dimensional Lebesgue measure.","In my research I use a definition of convex hull that is compatible with measure theory, in the sense that it ignores negligible sets. Are there any references to the following concept, or similar concepts, in the literature? (The name, obviously, need not be the same.) Suppose $A \subset \mathbb{R}^d$, $d \in \mathbb{Z}_+$. Define the closed essential convex hull of $A$ as the intersection of all half-spaces $H \subset \mathbb{R}^d$ that satisfy \begin{equation} m(A \setminus H) = 0, \end{equation} where $m$ is the $d$-dimensional Lebesgue measure.",,"['measure-theory', 'reference-request', 'convex-analysis', 'convex-hulls']"
27,Suppose that a measure on $X \times Y$ is given. In what situations can one define a measure on $\{x\} \times Y$ to imitate conditional probability?,Suppose that a measure on  is given. In what situations can one define a measure on  to imitate conditional probability?,X \times Y \{x\} \times Y,"Suppose that a measure on $X \times Y$ is given. In what situations can one define a measure on $\{x\} \times Y$ to imitate conditional probability? More generally, if a measure on $Z$ is given, and $C$ is a (nice, but maybe measure zero) subset of $Z$, then can one define the conditional probability measure, conditioned on lying in $C$. A reasonable litmus test for a general procedure should be: If $G$ is a compact group, and $\mu$ is the Haar measure, then if $H$ is a compact subgroup, the measure conditioned to being in $H$ should be the Haar measure of $H$. In ""geometric"" situations, like $\mathbb{R} \times \mathbb{R}$, one can imagine a procedure that takes the measure of tubular neighborhoods of subsets of $0 \times \mathbb{R}$ and renormalizes them appropriately. In the case of $G$ a topological group from before, assuming that $G$ has some metric structure, then given some $U \subset H$, one could define $\mu(U | H)$ as $\lim_{\epsilon \to 0} \frac{ \mu(U + B_{\epsilon}(e))} {\mu(B_{\epsilon(e)})}$, where $B_{\epsilon}(e)$ is an epsilon ball around the identity element of the group. Another test for the correct notion: In the case of $G$ and $H$ above, if $T$ is a (nice) set of transversals, then there ought to be a Fubini type theorem for integrating a function on $G$ in terms of integrating it over cosets of $H$ and then over $T$, using these kind of induced measures. (And something similarly for a bundles.) (Therefore, it should also be the case that this ""undoes"" the product measure construction.) Is there a general theory for this situation that someone can recommend or describe to me? -- Additional thoughts - given a family of measures $\rho_x$ on $Y$ parametrized by the measure space $(X, \Sigma, \mu)$, so that for an open $U$ in $X \times Y$, the function  $x \to \rho_x(U \cap \{x \} \times Y)$ is $\mu$-integrable, we can define a measure on $X \times Y$ by Fubini's theorem. Running over all such families, what is the image of this map into the space of all measures on $X \times Y$? (In particular, it should include the product measures, but should also be larger, since the measure on the fibers can vary in some fashion.)","Suppose that a measure on $X \times Y$ is given. In what situations can one define a measure on $\{x\} \times Y$ to imitate conditional probability? More generally, if a measure on $Z$ is given, and $C$ is a (nice, but maybe measure zero) subset of $Z$, then can one define the conditional probability measure, conditioned on lying in $C$. A reasonable litmus test for a general procedure should be: If $G$ is a compact group, and $\mu$ is the Haar measure, then if $H$ is a compact subgroup, the measure conditioned to being in $H$ should be the Haar measure of $H$. In ""geometric"" situations, like $\mathbb{R} \times \mathbb{R}$, one can imagine a procedure that takes the measure of tubular neighborhoods of subsets of $0 \times \mathbb{R}$ and renormalizes them appropriately. In the case of $G$ a topological group from before, assuming that $G$ has some metric structure, then given some $U \subset H$, one could define $\mu(U | H)$ as $\lim_{\epsilon \to 0} \frac{ \mu(U + B_{\epsilon}(e))} {\mu(B_{\epsilon(e)})}$, where $B_{\epsilon}(e)$ is an epsilon ball around the identity element of the group. Another test for the correct notion: In the case of $G$ and $H$ above, if $T$ is a (nice) set of transversals, then there ought to be a Fubini type theorem for integrating a function on $G$ in terms of integrating it over cosets of $H$ and then over $T$, using these kind of induced measures. (And something similarly for a bundles.) (Therefore, it should also be the case that this ""undoes"" the product measure construction.) Is there a general theory for this situation that someone can recommend or describe to me? -- Additional thoughts - given a family of measures $\rho_x$ on $Y$ parametrized by the measure space $(X, \Sigma, \mu)$, so that for an open $U$ in $X \times Y$, the function  $x \to \rho_x(U \cap \{x \} \times Y)$ is $\mu$-integrable, we can define a measure on $X \times Y$ by Fubini's theorem. Running over all such families, what is the image of this map into the space of all measures on $X \times Y$? (In particular, it should include the product measures, but should also be larger, since the measure on the fibers can vary in some fashion.)",,"['measure-theory', 'haar-measure']"
28,Trying to show the surjectivity of a map.,Trying to show the surjectivity of a map.,,"I am trying to solve the following exercise.I'm stuck in between,please help. Let $\Omega$ be a set with $n$ elements.Let $\mathcal A$ be the collection of all Boolean algebras of subsets of $\Omega$.A partition of $\Omega$ is a collection of nonempty disjoint subsets $A_1,A_2,...,A_k$ such that $\Omega = \cup_{j=1}^{k} A_j$.Let $\mathcal P$ be the collection of all possible partitions of $\Omega$.Given a subset $B$ of $\Omega$ we denote $B^1=B$ and $B^{-1} =B^c$.Show that the map $\Phi: \mathcal A \to \mathcal P$ given by $$\Phi(\sigma)= \{\sigma_{\epsilon} \mid \sigma_{\epsilon}= \cap_ { B \in \sigma} B^{(\epsilon_B)},\epsilon \in \{-1,1\}^{\vert  \sigma \vert }\}$$ is a bijection. I have shown that the $\Phi$ is injective.I think for showing surjective we have to take the sigma algebra generated by that partition for the preimage.Any hints/ideas to do this formally?","I am trying to solve the following exercise.I'm stuck in between,please help. Let $\Omega$ be a set with $n$ elements.Let $\mathcal A$ be the collection of all Boolean algebras of subsets of $\Omega$.A partition of $\Omega$ is a collection of nonempty disjoint subsets $A_1,A_2,...,A_k$ such that $\Omega = \cup_{j=1}^{k} A_j$.Let $\mathcal P$ be the collection of all possible partitions of $\Omega$.Given a subset $B$ of $\Omega$ we denote $B^1=B$ and $B^{-1} =B^c$.Show that the map $\Phi: \mathcal A \to \mathcal P$ given by $$\Phi(\sigma)= \{\sigma_{\epsilon} \mid \sigma_{\epsilon}= \cap_ { B \in \sigma} B^{(\epsilon_B)},\epsilon \in \{-1,1\}^{\vert  \sigma \vert }\}$$ is a bijection. I have shown that the $\Phi$ is injective.I think for showing surjective we have to take the sigma algebra generated by that partition for the preimage.Any hints/ideas to do this formally?",,['measure-theory']
29,Function/Measure Notation in Geometric Measure Theory,Function/Measure Notation in Geometric Measure Theory,,"I'm trying to understand a formula of this kind $$ ...=\phi_\sharp \left ( f \mathcal{H}^n    \right ) $$ where $\mathcal{H}^n$ is the n-dimensional Hausdorff measure on a measure space $X$, $\phi : X \to Y$ ($Y$ also a measure space) and $\phi_\sharp$ is the pushforward. Also $f:X \to \mathbb{R}$. Recall that the definition of pushforward requires ""$f \mathcal{H}^n$"" to be a measure (see for instance GMT of Mattila, definition 1.17). My question is: how do I actually read the notation ""$f \mathcal{H}^n$""? And where can I find references about it? By definition of pushforward, for $A \subseteq Y$, we have immediately $$ \left [ \phi_\sharp \left ( f \mathcal{H}^n    \right ) \right ](A) = \left [ f \mathcal{H}^n \right ] \left ( \phi^{-1}(A) \right ) $$ but that is as far as I go. PS$1$: I already read this but it didn't help much: Notation for the pushforward measure PS$2$: since this is a notational question, feel free to change some of the setting if it can help. Thanks!","I'm trying to understand a formula of this kind $$ ...=\phi_\sharp \left ( f \mathcal{H}^n    \right ) $$ where $\mathcal{H}^n$ is the n-dimensional Hausdorff measure on a measure space $X$, $\phi : X \to Y$ ($Y$ also a measure space) and $\phi_\sharp$ is the pushforward. Also $f:X \to \mathbb{R}$. Recall that the definition of pushforward requires ""$f \mathcal{H}^n$"" to be a measure (see for instance GMT of Mattila, definition 1.17). My question is: how do I actually read the notation ""$f \mathcal{H}^n$""? And where can I find references about it? By definition of pushforward, for $A \subseteq Y$, we have immediately $$ \left [ \phi_\sharp \left ( f \mathcal{H}^n    \right ) \right ](A) = \left [ f \mathcal{H}^n \right ] \left ( \phi^{-1}(A) \right ) $$ but that is as far as I go. PS$1$: I already read this but it didn't help much: Notation for the pushforward measure PS$2$: since this is a notational question, feel free to change some of the setting if it can help. Thanks!",,"['measure-theory', 'functions', 'notation', 'geometric-measure-theory']"
30,Change of Variable Proof in Folland,Change of Variable Proof in Folland,,"I am reviewing Folland's proof of the following standard result and I have a question on one part. Suppose $\Omega$ is an open set in $\mathbb R^{n}$; $G:\Omega \to \mathbb R^{n}$ is a diffeomorphism on $\Omega$; $f\in \mathcal L^{1}(G(\Omega))$. Then, $$\int _{G(\Omega)}f(x)dx=\int _{\Omega}f\circ G(x)\cdot\vert\det G'(x)\vert dx.$$ The main idea is to establish the inequality $$\tag1 m(G(Q))\leq \int _{Q}\vert\det G'(x)\vert dx$$ where $Q$ is a cube in $\Omega$. Folland does this by observing that for any $\epsilon>0$ we may choose $\delta>0$ so that, as soon as $Q$ is subdivided into $\left \{ Q_k \right \}^{n}_{k=1}$, where the $Q_k$ are cubes with disjoint interiors, of side length $<\delta$, with centers $x_k$, then the following holds: $$\tag 2m(G(Q))\leq (1+\epsilon)\sum_{k=1}^{n}\vert\det G'(x_k)\vert m(Q_k).$$ He then claims that $(1)$ follows from this, upon letting $\epsilon ,\delta\to 0$ and appealing to the uniform continuity of $\vert \det G'\vert $. This seems like a bit of handwaving to me. Or at least the claim deserves more rigor. Or am I missing something simple here? In any case, it seems easier just to note that $\vert \det G'\vert $ is Riemann integrable on $Q$, so we may write, with $P_k$ the partition of $Q$ determined by $Q_k$: $$\tag3 m(G(Q))\leq (1+\epsilon )\sum_{k=1}^{n}\vert\det G'(x_k)\vert m(Q_k)\leq (1+\epsilon )U(\vert \det G'\vert , P_k).$$ Then, given an an arbitrary partition of $Q$, there is a refinement to a partition determined by some $\left \{ Q_k \right \}^{N}_{k=1}$ where the side length of each $Q_k<\delta$, from which it follows immediately from $(3)$ that $$\tag4 m(G(Q))\leq (1+\epsilon )\overline \int _{Q}\vert\det G'(x)\vert dx=(1+\epsilon )\int _{Q}\vert\det G'(x)\vert dx,$$ which is what we want.","I am reviewing Folland's proof of the following standard result and I have a question on one part. Suppose $\Omega$ is an open set in $\mathbb R^{n}$; $G:\Omega \to \mathbb R^{n}$ is a diffeomorphism on $\Omega$; $f\in \mathcal L^{1}(G(\Omega))$. Then, $$\int _{G(\Omega)}f(x)dx=\int _{\Omega}f\circ G(x)\cdot\vert\det G'(x)\vert dx.$$ The main idea is to establish the inequality $$\tag1 m(G(Q))\leq \int _{Q}\vert\det G'(x)\vert dx$$ where $Q$ is a cube in $\Omega$. Folland does this by observing that for any $\epsilon>0$ we may choose $\delta>0$ so that, as soon as $Q$ is subdivided into $\left \{ Q_k \right \}^{n}_{k=1}$, where the $Q_k$ are cubes with disjoint interiors, of side length $<\delta$, with centers $x_k$, then the following holds: $$\tag 2m(G(Q))\leq (1+\epsilon)\sum_{k=1}^{n}\vert\det G'(x_k)\vert m(Q_k).$$ He then claims that $(1)$ follows from this, upon letting $\epsilon ,\delta\to 0$ and appealing to the uniform continuity of $\vert \det G'\vert $. This seems like a bit of handwaving to me. Or at least the claim deserves more rigor. Or am I missing something simple here? In any case, it seems easier just to note that $\vert \det G'\vert $ is Riemann integrable on $Q$, so we may write, with $P_k$ the partition of $Q$ determined by $Q_k$: $$\tag3 m(G(Q))\leq (1+\epsilon )\sum_{k=1}^{n}\vert\det G'(x_k)\vert m(Q_k)\leq (1+\epsilon )U(\vert \det G'\vert , P_k).$$ Then, given an an arbitrary partition of $Q$, there is a refinement to a partition determined by some $\left \{ Q_k \right \}^{N}_{k=1}$ where the side length of each $Q_k<\delta$, from which it follows immediately from $(3)$ that $$\tag4 m(G(Q))\leq (1+\epsilon )\overline \int _{Q}\vert\det G'(x)\vert dx=(1+\epsilon )\int _{Q}\vert\det G'(x)\vert dx,$$ which is what we want.",,"['real-analysis', 'measure-theory', 'lebesgue-measure']"
31,Another question about proving Lebesgue Decomposition,Another question about proving Lebesgue Decomposition,,"Note: This is my original question.  I have been kindly helped to turn this into a correct proof, which I have posted as an answer so this question won't show up as ""unanswered"". As an exercise, I am trying to provide a rigorous proof of uniqueness in the Lebesgue Decomposition Thm, assuming we already have existence.  I am following the outline provided here . Below is what I have so far Step 1 : Assume $\lambda$ is a finite measure ($\mu$ only needs to be $\sigma$-finite). Let $$\lambda=\lambda_1+\lambda_2 = \lambda_3 + \lambda_4, \text{where } \lambda_1, \lambda_3 \perp \mu \text{ and } \lambda_2,\lambda_4 \ll \mu \tag1$$ Let $\alpha:=\lambda_3 -\lambda_1 =\lambda_2-\lambda_4$ Extend defns of singular & abs cont to signed measures: (I just do the most intuitive thing here) $\alpha \perp \mu $ means $\exists$ a partition A,B of X s.t. $\alpha(A)= \mu(B)=0$.  $\alpha \ll \mu$ means $\mu(E)$=0 implies $\alpha(E)$=0. Show $\alpha \perp \mu$ and $\alpha \ll \mu$.  This is just checking defns. Conclude $\alpha$=0.  I'm stuck here.  By the previous pt, $\exists$ a partition A,B of X s.t. $\alpha(A)=\mu(B)$=0.  Further, $\mu(B)$=0 implies $\alpha(B)=0$.  So $\alpha(X)=\alpha(A)+\alpha(B)$=0.  But we may have a partition $X_1,X_2$ of X s.t. 0 $< \alpha(X_1)=-\alpha(X_2)$. Step 2 : (General case) $\lambda$ is $\sigma$-finite. Let $X_1 \subseteq X_2 \subseteq$..., $X=\cup_{n=1}^{\infty} X_n$, each $\lambda(X_n)< \infty$. $\forall n$, $E \in \textbf{X}$, put $\lambda_n(E):=\lambda(E \cap X_n)$, which is a finite measure, so $\exists$ a unique Lebesgue decomp $\lambda_n=\lambda_{1n}+\lambda_{2n}$ Assume (1) again.  Now I don't know how to show $\lambda_1=\lambda_3$.  I’m trying to use the previous bullet pt.  I think I can show $\lambda=(\lim_{n \to \infty} \lambda_{1n})+ (\lim_{n \to \infty} \lambda_{2n})$ is a Lebesgue Decomp, but how do I know there aren’t others?","Note: This is my original question.  I have been kindly helped to turn this into a correct proof, which I have posted as an answer so this question won't show up as ""unanswered"". As an exercise, I am trying to provide a rigorous proof of uniqueness in the Lebesgue Decomposition Thm, assuming we already have existence.  I am following the outline provided here . Below is what I have so far Step 1 : Assume $\lambda$ is a finite measure ($\mu$ only needs to be $\sigma$-finite). Let $$\lambda=\lambda_1+\lambda_2 = \lambda_3 + \lambda_4, \text{where } \lambda_1, \lambda_3 \perp \mu \text{ and } \lambda_2,\lambda_4 \ll \mu \tag1$$ Let $\alpha:=\lambda_3 -\lambda_1 =\lambda_2-\lambda_4$ Extend defns of singular & abs cont to signed measures: (I just do the most intuitive thing here) $\alpha \perp \mu $ means $\exists$ a partition A,B of X s.t. $\alpha(A)= \mu(B)=0$.  $\alpha \ll \mu$ means $\mu(E)$=0 implies $\alpha(E)$=0. Show $\alpha \perp \mu$ and $\alpha \ll \mu$.  This is just checking defns. Conclude $\alpha$=0.  I'm stuck here.  By the previous pt, $\exists$ a partition A,B of X s.t. $\alpha(A)=\mu(B)$=0.  Further, $\mu(B)$=0 implies $\alpha(B)=0$.  So $\alpha(X)=\alpha(A)+\alpha(B)$=0.  But we may have a partition $X_1,X_2$ of X s.t. 0 $< \alpha(X_1)=-\alpha(X_2)$. Step 2 : (General case) $\lambda$ is $\sigma$-finite. Let $X_1 \subseteq X_2 \subseteq$..., $X=\cup_{n=1}^{\infty} X_n$, each $\lambda(X_n)< \infty$. $\forall n$, $E \in \textbf{X}$, put $\lambda_n(E):=\lambda(E \cap X_n)$, which is a finite measure, so $\exists$ a unique Lebesgue decomp $\lambda_n=\lambda_{1n}+\lambda_{2n}$ Assume (1) again.  Now I don't know how to show $\lambda_1=\lambda_3$.  I’m trying to use the previous bullet pt.  I think I can show $\lambda=(\lim_{n \to \infty} \lambda_{1n})+ (\lim_{n \to \infty} \lambda_{2n})$ is a Lebesgue Decomp, but how do I know there aren’t others?",,"['real-analysis', 'measure-theory']"
32,Limit of integral with measure with parameter $\alpha$,Limit of integral with measure with parameter,\alpha,"Suppose $\mu$ is a positive masure on $X$, $f:X\to [0,\infty]$ is measurable, $\int \limits_{X}fd\mu=c$, where $0<c<\infty,$ and $\alpha$ is a constant. Prove that $$\lim \limits_{n\to \infty}\int \limits_{X}n\log [1+(f/n)^{\alpha}]d\mu= \begin{cases} \infty,  & \text{if} \quad0<\alpha<1, \\ c,  & \text{if} \quad\alpha=1, \\ 0, & \text{if} \quad 1<\alpha<\infty. \end{cases}$$ Remark: $[\cdot]$ is not integer part! Proof: $\color{blue}{Case \quad \alpha=1}$. Consider functions $f_n(x):X\to [0,\infty]$ defined by $f_n(x)=n\log \left[1+\dfrac{f(x)}{n}\right]$. It's easy to check  that $0\leqslant f_1\leqslant f_2\leqslant \dots \leqslant f$ on $X-S$ where $S=\{x\in X:f(x)=\infty\}$ and note that $\mu(S)=0$ (otherwise $\int \limits_{X}fd\mu=\infty$ which is contradiction). Also $f_n$ is measurable for each $n$ since it's a compostion of continuous and measurable functions. Using Monotone Convergence Theorem we get: $$\lim \limits_{n\to \infty}\int \limits_{X}f_nd\mu=\int \limits_{X}\lim \limits_{n\to \infty}f_nd\mu=\int \limits_{X}fd\mu=c.$$ $\color{blue}{Case \quad 0<\alpha<1}$. Using Fatou's lemma to functions $f_n=n\log[1+(f/n)^{\alpha}]$ which is measurable in $X-S$ for each $n$ we get the following inequality: $$\liminf \limits_{n\to \infty} \int \limits_{X}f_nd\mu\geqslant  \int \limits_{X}\liminf \limits_{n\to \infty} f_nd\mu$$ Since $\int \limits_{X}fd \mu=\int \limits_{X\setminus S}fd \mu=c$ then the set $E=\{x\in X-S: f(x)>0\}$ has positive measure.  And $$\int \limits_{X}\liminf \limits_{n\to \infty} f_nd\mu=\int \limits_{X\setminus S}\liminf \limits_{n\to \infty} f_nd\mu=\int \limits_{E}+\int \limits_{(X\setminus S)\setminus E}=$$ Since on $(X\setminus S)\setminus E$ we have that $f_n(x)=0$ $$=\int \limits_{E}\liminf \limits_{n\to \infty} f_nd\mu=+\infty$$ since $\liminf \limits_{n\to \infty} f_n=+\infty$ on $E$ and $\mu(E)>0.$ $\color{blue}{Case \quad \alpha>1}$. Our functions $f_n$ are measurable and non-negative on $X-S$ and $f_n(x)\to 0$ as $n\to \infty$ on $X-S$. Using derivative test we can show that $f_n\leqslant \alpha f$ for $n\in \mathbb{N}$ on $X-S$. Note that $\alpha f\in L^1(\mu)$. By Dominated Convergence theorem $$\lim \limits_{n\to \infty}\int \limits_{X}f_nd\mu=\int \limits_{X}\lim \limits_{n\to \infty}f_nd\mu=0.$$ Here we use that $\mu(S)=0$ because the measure of zero set in negligible in integration. Sorry if this topic is repeated but I would be thankful if anyone checks out my solution.","Suppose $\mu$ is a positive masure on $X$, $f:X\to [0,\infty]$ is measurable, $\int \limits_{X}fd\mu=c$, where $0<c<\infty,$ and $\alpha$ is a constant. Prove that $$\lim \limits_{n\to \infty}\int \limits_{X}n\log [1+(f/n)^{\alpha}]d\mu= \begin{cases} \infty,  & \text{if} \quad0<\alpha<1, \\ c,  & \text{if} \quad\alpha=1, \\ 0, & \text{if} \quad 1<\alpha<\infty. \end{cases}$$ Remark: $[\cdot]$ is not integer part! Proof: $\color{blue}{Case \quad \alpha=1}$. Consider functions $f_n(x):X\to [0,\infty]$ defined by $f_n(x)=n\log \left[1+\dfrac{f(x)}{n}\right]$. It's easy to check  that $0\leqslant f_1\leqslant f_2\leqslant \dots \leqslant f$ on $X-S$ where $S=\{x\in X:f(x)=\infty\}$ and note that $\mu(S)=0$ (otherwise $\int \limits_{X}fd\mu=\infty$ which is contradiction). Also $f_n$ is measurable for each $n$ since it's a compostion of continuous and measurable functions. Using Monotone Convergence Theorem we get: $$\lim \limits_{n\to \infty}\int \limits_{X}f_nd\mu=\int \limits_{X}\lim \limits_{n\to \infty}f_nd\mu=\int \limits_{X}fd\mu=c.$$ $\color{blue}{Case \quad 0<\alpha<1}$. Using Fatou's lemma to functions $f_n=n\log[1+(f/n)^{\alpha}]$ which is measurable in $X-S$ for each $n$ we get the following inequality: $$\liminf \limits_{n\to \infty} \int \limits_{X}f_nd\mu\geqslant  \int \limits_{X}\liminf \limits_{n\to \infty} f_nd\mu$$ Since $\int \limits_{X}fd \mu=\int \limits_{X\setminus S}fd \mu=c$ then the set $E=\{x\in X-S: f(x)>0\}$ has positive measure.  And $$\int \limits_{X}\liminf \limits_{n\to \infty} f_nd\mu=\int \limits_{X\setminus S}\liminf \limits_{n\to \infty} f_nd\mu=\int \limits_{E}+\int \limits_{(X\setminus S)\setminus E}=$$ Since on $(X\setminus S)\setminus E$ we have that $f_n(x)=0$ $$=\int \limits_{E}\liminf \limits_{n\to \infty} f_nd\mu=+\infty$$ since $\liminf \limits_{n\to \infty} f_n=+\infty$ on $E$ and $\mu(E)>0.$ $\color{blue}{Case \quad \alpha>1}$. Our functions $f_n$ are measurable and non-negative on $X-S$ and $f_n(x)\to 0$ as $n\to \infty$ on $X-S$. Using derivative test we can show that $f_n\leqslant \alpha f$ for $n\in \mathbb{N}$ on $X-S$. Note that $\alpha f\in L^1(\mu)$. By Dominated Convergence theorem $$\lim \limits_{n\to \infty}\int \limits_{X}f_nd\mu=\int \limits_{X}\lim \limits_{n\to \infty}f_nd\mu=0.$$ Here we use that $\mu(S)=0$ because the measure of zero set in negligible in integration. Sorry if this topic is repeated but I would be thankful if anyone checks out my solution.",,"['real-analysis', 'measure-theory']"
33,"Suppose $A,B\subseteq [0,1]$ are Lebesgue measurable with measure of at least $1/2$.",Suppose  are Lebesgue measurable with measure of at least .,"A,B\subseteq [0,1] 1/2","Suppose $A,B\subseteq [0,1]$ are Lebesgue measurable with measure of at least $1/2$. Prove there is some $x\in [-1,1]$ such that $\mu((A+x)\cap B)\geq 1/10$. This is a previous qual question. My thought is to define the function $f(x)=\mu((A+x)\cap B)$. Then we know that $f(-1)=f(1)=0$, $f$ is continuous and $f$ is non-negative. I was thinking of applying IVT in some way but I can't see how. Could someone provide a hint? (I would prefer hints only to a full answer)","Suppose $A,B\subseteq [0,1]$ are Lebesgue measurable with measure of at least $1/2$. Prove there is some $x\in [-1,1]$ such that $\mu((A+x)\cap B)\geq 1/10$. This is a previous qual question. My thought is to define the function $f(x)=\mu((A+x)\cap B)$. Then we know that $f(-1)=f(1)=0$, $f$ is continuous and $f$ is non-negative. I was thinking of applying IVT in some way but I can't see how. Could someone provide a hint? (I would prefer hints only to a full answer)",,[]
34,Doubt on proof of equivalance of conditions for uniform integrability in $L^1$,Doubt on proof of equivalance of conditions for uniform integrability in,L^1,"In a measure space with finite total measure, a family $A$ of r.v's is called U.I if $$ \lim_{N\to\infty}\sup_{X\in A} \int_{|X|>N} |X|\,d\mu=0 $$ I have some doubts on equivalance of this definition in $L^1$ space. The following is equivalent to U.I in $L^1$: A is bounded subset of $L^1$. For every $\epsilon>0$ there exists $\delta>0$ such that for any measurable $E$ if $\mu(E)\le \delta$ then $\int_E |X| d\mu\le \epsilon$ for any $X\in A$. The following proof is given: Proof: Suppose $A$ is U.I. Then for any measurable $E$, $$ \int_E |X| = \int_{E\cap \{|X|>N\}} |X| + \int_{E\cap \{|X|\le N\}} |X|:=B+C $$ Given $\epsilon>0$ we can choose $N$ such that $B<\epsilon /2$ and obviously $C\le N\mu (E)$. Thus we may choose $\delta = \frac{\epsilon}{2N(\mu(\Omega)+1)}$. And I'm not sure why we can't simply choose $\delta=\epsilon/2N$? And why do we need the condition that $\Omega$ is a finite measure space? I don't particularly see any necessity for it, unless I'm missing something about last line. Probably only place where it might matter is stating $C\le N\mu(E)$, since it might be that $\mu(E)=\infty$. But we are controlling size of $E$ anyway, aren't we? Edit : It seems for condition $1$ to hold, $E$ must be of finite measure so total measure must be finite, as we only control size of $E$ for proof of $2$.","In a measure space with finite total measure, a family $A$ of r.v's is called U.I if $$ \lim_{N\to\infty}\sup_{X\in A} \int_{|X|>N} |X|\,d\mu=0 $$ I have some doubts on equivalance of this definition in $L^1$ space. The following is equivalent to U.I in $L^1$: A is bounded subset of $L^1$. For every $\epsilon>0$ there exists $\delta>0$ such that for any measurable $E$ if $\mu(E)\le \delta$ then $\int_E |X| d\mu\le \epsilon$ for any $X\in A$. The following proof is given: Proof: Suppose $A$ is U.I. Then for any measurable $E$, $$ \int_E |X| = \int_{E\cap \{|X|>N\}} |X| + \int_{E\cap \{|X|\le N\}} |X|:=B+C $$ Given $\epsilon>0$ we can choose $N$ such that $B<\epsilon /2$ and obviously $C\le N\mu (E)$. Thus we may choose $\delta = \frac{\epsilon}{2N(\mu(\Omega)+1)}$. And I'm not sure why we can't simply choose $\delta=\epsilon/2N$? And why do we need the condition that $\Omega$ is a finite measure space? I don't particularly see any necessity for it, unless I'm missing something about last line. Probably only place where it might matter is stating $C\le N\mu(E)$, since it might be that $\mu(E)=\infty$. But we are controlling size of $E$ anyway, aren't we? Edit : It seems for condition $1$ to hold, $E$ must be of finite measure so total measure must be finite, as we only control size of $E$ for proof of $2$.",,"['real-analysis', 'measure-theory', 'uniform-integrability']"
35,A characterization of Borel measurability,A characterization of Borel measurability,,"I need help proving the following  fact.   Let $(X,\textbf{X})$ be a measurable space.  Then $f:X \to \mathbb{R}$ is X -measurable iff $f^{-1}(E) \in \textbf{X}$, $\forall E \in \textbf{B}$. Defns and notations: $X$ is a set, X is  a $\sigma$-algebra of subsets of $X$, $f^{-1}(E):=\{x \in X: f(x) \in E \}$, B is the $\sigma$-algebra of subsets of $\mathbb{R}$ generated by open intervals $(a,b)$. $f$ is X -measurable means $f^{-1}( \alpha, \infty) \in \textbf{X}$, $\forall \alpha \in \mathbb{R}$. What I have: ""$\leftarrow$"" is easy since $( \alpha, \infty) \in \textbf{B}$.   I'm struggling with the formal way to argue ""$\to$"".  Informally, I know the preimage $f^{-1}(E)$ is well-behaved wrt the operations of unions, intersections, complements, etc: $$f^{-1}(\cup_{i=1}^\infty E_i)=\cup_{i=1}^\infty f^{-1}(E_i), f^{-1}(E^c)=(f^{-1}(E))^c$$  Thus, since everything in B is generated by those operations starting from open intervals $(a,b)$, we should have that, starting from sets of the form $f^{-1}(a,b)$ and applying the same operations, we ""stay"" in X . Sorry I'm new to measure theory and still trying to pick up how proofs of this nature are done.","I need help proving the following  fact.   Let $(X,\textbf{X})$ be a measurable space.  Then $f:X \to \mathbb{R}$ is X -measurable iff $f^{-1}(E) \in \textbf{X}$, $\forall E \in \textbf{B}$. Defns and notations: $X$ is a set, X is  a $\sigma$-algebra of subsets of $X$, $f^{-1}(E):=\{x \in X: f(x) \in E \}$, B is the $\sigma$-algebra of subsets of $\mathbb{R}$ generated by open intervals $(a,b)$. $f$ is X -measurable means $f^{-1}( \alpha, \infty) \in \textbf{X}$, $\forall \alpha \in \mathbb{R}$. What I have: ""$\leftarrow$"" is easy since $( \alpha, \infty) \in \textbf{B}$.   I'm struggling with the formal way to argue ""$\to$"".  Informally, I know the preimage $f^{-1}(E)$ is well-behaved wrt the operations of unions, intersections, complements, etc: $$f^{-1}(\cup_{i=1}^\infty E_i)=\cup_{i=1}^\infty f^{-1}(E_i), f^{-1}(E^c)=(f^{-1}(E))^c$$  Thus, since everything in B is generated by those operations starting from open intervals $(a,b)$, we should have that, starting from sets of the form $f^{-1}(a,b)$ and applying the same operations, we ""stay"" in X . Sorry I'm new to measure theory and still trying to pick up how proofs of this nature are done.",,"['real-analysis', 'measure-theory']"
36,Definition of measurable space - sigma algebra,Definition of measurable space - sigma algebra,,"A measurable space is a set $S$, together with a nonempty collection,   $\mathcal{S}$, of subsets of $S$ satisfying the following two   conditions: For any $A$, $B$ in the collection of $\mathcal{S}$, the set $A-B$ is also in $\mathcal{S}$ For any $A_1, A_2, ... \in \mathcal{S}$, their union is in $\mathcal{S}$. Source Is $\mathcal{S}$ a sigma algebra? The definition of sigma algebra states it's a collection of subsets of $X$ closed under countable union, complementation, and that it contains the empty set. Point 1. guarantees it contains the empty set, point 2. states its closed under countable union. But how 1. and 2. imply that it's closed under complement? How to prove that $\mathcal{S}$ contains $S$ as well, as it should (because it contains the empty set), given it really is a sigma-algebra?","A measurable space is a set $S$, together with a nonempty collection,   $\mathcal{S}$, of subsets of $S$ satisfying the following two   conditions: For any $A$, $B$ in the collection of $\mathcal{S}$, the set $A-B$ is also in $\mathcal{S}$ For any $A_1, A_2, ... \in \mathcal{S}$, their union is in $\mathcal{S}$. Source Is $\mathcal{S}$ a sigma algebra? The definition of sigma algebra states it's a collection of subsets of $X$ closed under countable union, complementation, and that it contains the empty set. Point 1. guarantees it contains the empty set, point 2. states its closed under countable union. But how 1. and 2. imply that it's closed under complement? How to prove that $\mathcal{S}$ contains $S$ as well, as it should (because it contains the empty set), given it really is a sigma-algebra?",,['measure-theory']
37,Exercise 8.O in Bartle's The Elements of Integration,Exercise 8.O in Bartle's The Elements of Integration,,"I have a doubt about this exercise (8.O) in Bartle's book. Exercise 8.O I already answered the Exercise 8.N so I'm able to apply it, but, I just have no idea about how to do this. I'm working on it, but if you guys have any hint to me, would be great.","I have a doubt about this exercise (8.O) in Bartle's book. Exercise 8.O I already answered the Exercise 8.N so I'm able to apply it, but, I just have no idea about how to do this. I'm working on it, but if you guys have any hint to me, would be great.",,"['measure-theory', 'lebesgue-measure']"
38,regularity of a measure,regularity of a measure,,"Let $\mathcal{A}$ be a $\sigma$ -algebra containing the Borel algebra (everything is in a topological space). Let $m\colon\mathcal{A}\to[0,\infty]$ be a measure. The standard definition of regularity goes like this: $m$ is regular if, for any $A\in\mathcal{A}$ , the measure of $A$ equals the infimum of measures of open sets containing $A$ and also a supremum of measures of closed sets contained in $A$ . For Lebesgue measure in $\mathbb R^n$ , there is a known theorem that it is regular in the following way: for every L-measurable set $A$ , for every $\varepsilon>0$ there is a closed subset $K$ and open supset $U$ of $A$ such that $\lambda(U\setminus K)<\varepsilon$ . What about the general case - are these two properties equivalent?","Let be a -algebra containing the Borel algebra (everything is in a topological space). Let be a measure. The standard definition of regularity goes like this: is regular if, for any , the measure of equals the infimum of measures of open sets containing and also a supremum of measures of closed sets contained in . For Lebesgue measure in , there is a known theorem that it is regular in the following way: for every L-measurable set , for every there is a closed subset and open supset of such that . What about the general case - are these two properties equivalent?","\mathcal{A} \sigma m\colon\mathcal{A}\to[0,\infty] m A\in\mathcal{A} A A A \mathbb R^n A \varepsilon>0 K U A \lambda(U\setminus K)<\varepsilon","['real-analysis', 'measure-theory', 'lebesgue-measure']"
39,Why are the positive measure and negative measure induced by the Hahn Decomposition mutually singular?,Why are the positive measure and negative measure induced by the Hahn Decomposition mutually singular?,,"The following statement describes the Hahn decomposition and claims that the induced  positive measure and negative measure are mutually singular. Why is that the case? On a separate note, what are signed measure, Hahn decomposition and Jordan Decomposition good for? I am reading Royden's real analysis and feel a little bit lost. The Hahn Decomposition Theorem : Let $\nu$ be a signed measure on the measurable space   $(X, \mathcal{M})$. Then there is a positive set $A$ for $\nu$ and a negative set $B$ for $\nu$ for which   $$X=A\cup B,\quad A\cap B=\emptyset.$$ If $\{A, B\}$ is a Hahn decomposition for $\nu$, then we define two measures $\nu^+$ and $\nu^-$ with $\nu=\nu^+-\nu^-$ by setting    $$ \nu^+(E) =\nu(E\cap A),\quad  \nu^-(E) =-\nu(E \cap B). $$   Two measures $v_1$ and $v_2$ on $(X, \mathcal{M})$ are said to be mutually singular if there are disjoint measurable sets $A$ and $B$ with $X = A \cup B$ for which $v_1(A) = v_2(B) = 0$. The measures $\nu^+$ and $\nu^-$ defined above are mutually singular.","The following statement describes the Hahn decomposition and claims that the induced  positive measure and negative measure are mutually singular. Why is that the case? On a separate note, what are signed measure, Hahn decomposition and Jordan Decomposition good for? I am reading Royden's real analysis and feel a little bit lost. The Hahn Decomposition Theorem : Let $\nu$ be a signed measure on the measurable space   $(X, \mathcal{M})$. Then there is a positive set $A$ for $\nu$ and a negative set $B$ for $\nu$ for which   $$X=A\cup B,\quad A\cap B=\emptyset.$$ If $\{A, B\}$ is a Hahn decomposition for $\nu$, then we define two measures $\nu^+$ and $\nu^-$ with $\nu=\nu^+-\nu^-$ by setting    $$ \nu^+(E) =\nu(E\cap A),\quad  \nu^-(E) =-\nu(E \cap B). $$   Two measures $v_1$ and $v_2$ on $(X, \mathcal{M})$ are said to be mutually singular if there are disjoint measurable sets $A$ and $B$ with $X = A \cup B$ for which $v_1(A) = v_2(B) = 0$. The measures $\nu^+$ and $\nu^-$ defined above are mutually singular.",,"['real-analysis', 'measure-theory']"
40,How does the sum of the absolute values of the diagonal entries of a matrix change when the matrix is written in a random basis?,How does the sum of the absolute values of the diagonal entries of a matrix change when the matrix is written in a random basis?,,"The set-up is as follows: I have a complex, Hermitian matrix $H$ with $\mbox{Tr }H=0$, and such that the trace norm $\|H\|_1=1$ (i.e. the sum of the singular values $=1$). Let me define the functiona $\mbox{TrAbs}$ to ojcemp am the sum of the absolute values of the diagonal entries of a matrix (which is clearly dependent on the basis), i.e. $$ \mbox{TrAbs }H = \sum_{i=1}^n |(H)_{ii}| $$ where $n$ is the dimension of the matrix. My question is to understand the following: Given $\epsilon$, if I write $H$ in a randomly chosen orthonormal basis and call it $H^\prime$, what is the probability that $\mbox{TrAbs }H^\prime>\epsilon$? To clarify a couple of things: I'm looking for a lower bound on the probability---the exact value is not particularly relevant. ""randomly"" choosing a basis is quite vague. Perhaps this could be done by conjugating with a Haar random unitary, but if there are other ways of choosing a basis randomly that yield a more straightforward bound, I'm sure those would be fine too. What I know already: $\mbox{TrAbs }H^\prime \geq |\mbox{Tr }H|=0$. If $H^\prime$ is in its diagonal basis, then clearly $\mbox{TrAbs }H^\prime=\|H\|_1=1$. It is then easy to show that $0 \leq \mbox{TrAbs }H^\prime \leq 1$. I intuitively feel that the probability ought to approach $1$ as the dimension of $H$ tends to $\infty$ (because it seems like there would be so many more bases that give a $\mbox{TrAbs}$ value of $\frac{1}{2}$, say, than would give $0$), but can't show it. So I feel like there should be a way of giving a lower bound that only involves $\epsilon$, and not $n$. If I can provide any other information about this question, please let me know. I really appreciate any help you can provide.","The set-up is as follows: I have a complex, Hermitian matrix $H$ with $\mbox{Tr }H=0$, and such that the trace norm $\|H\|_1=1$ (i.e. the sum of the singular values $=1$). Let me define the functiona $\mbox{TrAbs}$ to ojcemp am the sum of the absolute values of the diagonal entries of a matrix (which is clearly dependent on the basis), i.e. $$ \mbox{TrAbs }H = \sum_{i=1}^n |(H)_{ii}| $$ where $n$ is the dimension of the matrix. My question is to understand the following: Given $\epsilon$, if I write $H$ in a randomly chosen orthonormal basis and call it $H^\prime$, what is the probability that $\mbox{TrAbs }H^\prime>\epsilon$? To clarify a couple of things: I'm looking for a lower bound on the probability---the exact value is not particularly relevant. ""randomly"" choosing a basis is quite vague. Perhaps this could be done by conjugating with a Haar random unitary, but if there are other ways of choosing a basis randomly that yield a more straightforward bound, I'm sure those would be fine too. What I know already: $\mbox{TrAbs }H^\prime \geq |\mbox{Tr }H|=0$. If $H^\prime$ is in its diagonal basis, then clearly $\mbox{TrAbs }H^\prime=\|H\|_1=1$. It is then easy to show that $0 \leq \mbox{TrAbs }H^\prime \leq 1$. I intuitively feel that the probability ought to approach $1$ as the dimension of $H$ tends to $\infty$ (because it seems like there would be so many more bases that give a $\mbox{TrAbs}$ value of $\frac{1}{2}$, say, than would give $0$), but can't show it. So I feel like there should be a way of giving a lower bound that only involves $\epsilon$, and not $n$. If I can provide any other information about this question, please let me know. I really appreciate any help you can provide.",,"['linear-algebra', 'matrices', 'measure-theory', 'representation-theory', 'random-matrices']"
41,Part of proof to show Lebesgue-lebesgue measurable,Part of proof to show Lebesgue-lebesgue measurable,,"I want to prove the following: Suppose $E$ is a subset of $\Bbb R$, let $\gamma(E)=\{ (x,y)\in \Bbb R \times \Bbb R :x-y\in E\}$. If $E\in \Bbb B$ (Borel/Lebesgue measurable set), show that $\gamma(E)\in \Bbb B \times \Bbb B$ . Here’s my idea: I want to first prove the following: Let $(X,\Bbb X)$ be a measurable space, $f$ be a measurable function on $X$ to $\Bbb R$, and let $\phi$ be a Borel measurable function, want to show that $\phi \circ f$ is measurable.  Then I will take $\phi=\chi_E$ and $f(x,y)=x-y$ to come up with the result. But I’m not sure how to prove $\phi \circ f$ is $X$-measurable. Could someone help to provide a proof please? I’m also not sure if I’m on the right track. Thanks.","I want to prove the following: Suppose $E$ is a subset of $\Bbb R$, let $\gamma(E)=\{ (x,y)\in \Bbb R \times \Bbb R :x-y\in E\}$. If $E\in \Bbb B$ (Borel/Lebesgue measurable set), show that $\gamma(E)\in \Bbb B \times \Bbb B$ . Here’s my idea: I want to first prove the following: Let $(X,\Bbb X)$ be a measurable space, $f$ be a measurable function on $X$ to $\Bbb R$, and let $\phi$ be a Borel measurable function, want to show that $\phi \circ f$ is measurable.  Then I will take $\phi=\chi_E$ and $f(x,y)=x-y$ to come up with the result. But I’m not sure how to prove $\phi \circ f$ is $X$-measurable. Could someone help to provide a proof please? I’m also not sure if I’m on the right track. Thanks.",,"['real-analysis', 'measure-theory', 'lebesgue-integral', 'lebesgue-measure']"
42,Integrating a probability density function that only depends on the norm,Integrating a probability density function that only depends on the norm,,"I have a probability density function $f$ on $\mathbb{R}^3$ which only depends on the norm of a vector (that is, it takes the same value for $x,y$ if their length is equal). Let me call a region of $\mathbb{R^3}$ a cone if it is closed under multiplying by a nonnegative number (the intersection of some half spaces through the origin for example). Now it seems intuitively obvious that for a cone $S$ the number $\int_Sf$ is equal to the relative area of its intersection with the unit sphere (compared to the surface area of the unit sphere). Is there an elegant way to show this?","I have a probability density function $f$ on $\mathbb{R}^3$ which only depends on the norm of a vector (that is, it takes the same value for $x,y$ if their length is equal). Let me call a region of $\mathbb{R^3}$ a cone if it is closed under multiplying by a nonnegative number (the intersection of some half spaces through the origin for example). Now it seems intuitively obvious that for a cone $S$ the number $\int_Sf$ is equal to the relative area of its intersection with the unit sphere (compared to the surface area of the unit sphere). Is there an elegant way to show this?",,"['probability', 'measure-theory']"
43,Pure states on $C(X)$ are exactly evaluations,Pure states on  are exactly evaluations,C(X),"Let $X$ be a compact Hausdorff space. I want to show that pure states are of the form $ \phi (f) =f(x)$. By Reisz Represenation Theorem states on $C(X)$ are of the form $\phi (f)= \int fd\mu$ where $\mu$ is a probability regular borel measure. I'm also familiar with the equivalent defenition: $\phi$ is pure iff for every positive functional $\psi$ satisfying $\psi \le \phi$ there exists $t \in [0,1]$ s.t. $\psi = t \phi$. $\Rightarrow$Suppose $\phi$ is an evaluation and show it's pure: write $\phi = t \psi_1 + (1-t) \psi_2$ for $t \in [0,1]$, and $\psi_1, \psi_2 \in S(A)$  so $\forall f\in C(X)$ we have $f(x)=\phi(f) = t \psi_1(f) + (1-t) \psi_2(f)=t\int fd\mu_1+ (1-t)\int fd\mu_2$ for some $\mu_1, \mu_2$ borel, regular probability measures. If I could take $f=\chi_{\{x\}}$ I think I can finish the argument. Maybe I should approximate this indicator by continuous functions in $L^1$, but I'm not sure it's the right direction. For the second direction I have nothing to present... I would like to get some hints. Thank you.","Let $X$ be a compact Hausdorff space. I want to show that pure states are of the form $ \phi (f) =f(x)$. By Reisz Represenation Theorem states on $C(X)$ are of the form $\phi (f)= \int fd\mu$ where $\mu$ is a probability regular borel measure. I'm also familiar with the equivalent defenition: $\phi$ is pure iff for every positive functional $\psi$ satisfying $\psi \le \phi$ there exists $t \in [0,1]$ s.t. $\psi = t \phi$. $\Rightarrow$Suppose $\phi$ is an evaluation and show it's pure: write $\phi = t \psi_1 + (1-t) \psi_2$ for $t \in [0,1]$, and $\psi_1, \psi_2 \in S(A)$  so $\forall f\in C(X)$ we have $f(x)=\phi(f) = t \psi_1(f) + (1-t) \psi_2(f)=t\int fd\mu_1+ (1-t)\int fd\mu_2$ for some $\mu_1, \mu_2$ borel, regular probability measures. If I could take $f=\chi_{\{x\}}$ I think I can finish the argument. Maybe I should approximate this indicator by continuous functions in $L^1$, but I'm not sure it's the right direction. For the second direction I have nothing to present... I would like to get some hints. Thank you.",,"['measure-theory', 'representation-theory', 'c-star-algebras']"
44,Any simpler form for $ \frac{\sum_{k=2}^{n-2}{k\left(\sum_{i=0}^{k}\frac{(-1)^i}{i!}\right)}}{n\sum_{i=0}^{n}\frac{(-1)^i}{i!}}$,Any simpler form for, \frac{\sum_{k=2}^{n-2}{k\left(\sum_{i=0}^{k}\frac{(-1)^i}{i!}\right)}}{n\sum_{i=0}^{n}\frac{(-1)^i}{i!}},"Is there any simpler form for the following expression: $$ \frac{\sum_{k=2}^{n-2}{k\left(\sum_{i=0}^{k}\frac{(-1)^i}{i!}\right)}}{n\sum_{i=0}^{n}\frac{(-1)^i}{i!}}$$ Because I have to compute this expression for $n=100$, and without using any computing packages, doing this would be really tedious and painful. A few days back, I posted a question: Any simpler expression for$\frac{\sum_{k=2}^{n-2}{k\big(\sum_{i=0}^{n-2}\frac{(-1)^i}{i!}\big)}}{n\sum_{i=0}^{n}\frac{(-1)^i}{i!}}$ . While the answers are amazing, when I was reading the answers, I was so confused and just realised that I actually typed in the wrong expression. Any help would be highly appreciated!","Is there any simpler form for the following expression: $$ \frac{\sum_{k=2}^{n-2}{k\left(\sum_{i=0}^{k}\frac{(-1)^i}{i!}\right)}}{n\sum_{i=0}^{n}\frac{(-1)^i}{i!}}$$ Because I have to compute this expression for $n=100$, and without using any computing packages, doing this would be really tedious and painful. A few days back, I posted a question: Any simpler expression for$\frac{\sum_{k=2}^{n-2}{k\big(\sum_{i=0}^{n-2}\frac{(-1)^i}{i!}\big)}}{n\sum_{i=0}^{n}\frac{(-1)^i}{i!}}$ . While the answers are amazing, when I was reading the answers, I was so confused and just realised that I actually typed in the wrong expression. Any help would be highly appreciated!",,"['calculus', 'real-analysis', 'probability', 'measure-theory', 'summation']"
45,Why does this function preserve measure of null sets?,Why does this function preserve measure of null sets?,,"In this question, one of the answers claimed that the function $f: \mathbb{R}^{2n} \to \mathbb{R}$ given by $f(x,y) = x-y$ pulls back Lebesgue null sets to null sets, that is, $f^{-1}(N)$ is a null set for any null set $N$ and mentions it can be proved using Fubini's theorem, but gives no proof of this. Could someone elaborate on why this must be true?","In this question, one of the answers claimed that the function $f: \mathbb{R}^{2n} \to \mathbb{R}$ given by $f(x,y) = x-y$ pulls back Lebesgue null sets to null sets, that is, $f^{-1}(N)$ is a null set for any null set $N$ and mentions it can be proved using Fubini's theorem, but gives no proof of this. Could someone elaborate on why this must be true?",,"['real-analysis', 'measure-theory', 'lebesgue-integral', 'lebesgue-measure']"
46,Corollary of Monotone Convergence Theorem,Corollary of Monotone Convergence Theorem,,"Let $(g_n)$ be a sequence in $M^+$, then $\int \left(\sum_{n=1}^\infty g_n\right)d\mu=\sum_{n=1}^\infty\left(\int g_nd\mu \right)$ proof: Let $f_n=g_1+\cdots+g_n$, then $f_n$ is a monotone increasing sequence of functions in $M^+$. I wan t use Monotone Convergence Theorem but I don't know how to guarantee that $f_n$ converges to $f=\lim_{n\to \infty}\sum_{i=1}^n g_n=\sum_{i=1}^{\infty}g_n$.","Let $(g_n)$ be a sequence in $M^+$, then $\int \left(\sum_{n=1}^\infty g_n\right)d\mu=\sum_{n=1}^\infty\left(\int g_nd\mu \right)$ proof: Let $f_n=g_1+\cdots+g_n$, then $f_n$ is a monotone increasing sequence of functions in $M^+$. I wan t use Monotone Convergence Theorem but I don't know how to guarantee that $f_n$ converges to $f=\lim_{n\to \infty}\sum_{i=1}^n g_n=\sum_{i=1}^{\infty}g_n$.",,['measure-theory']
47,Why is $\mathcal M(\mathcal C) \subset \sigma (\mathcal C)$?,Why is ?,\mathcal M(\mathcal C) \subset \sigma (\mathcal C),"There should be an error in my logical reasoning but I can't figure out. Every metric space is a topological space. So it can be understood that: metric space $\subset$ topological space. Every $\sigma$-algebra is a monotone class. The same spirit applies, it can be understood that: $\sigma$-algebra $\subset$ monotone class. But if we define monotone class generated by $\mathcal C$ by $\mathcal M(\mathcal C):=\bigcap\limits_{\mathcal M \text{ monotone class, } \mathcal C \subset \mathcal M} \mathcal M$ and $\sigma$-algebra generated by $\mathcal C$ by $\sigma(\mathcal C):=\bigcap\limits_{\mathcal T \sigma\text{-algebra, } \mathcal C \subset \mathcal T} \mathcal T$. Why is $\mathcal M(\mathcal C) \subset \sigma (\mathcal C)$?","There should be an error in my logical reasoning but I can't figure out. Every metric space is a topological space. So it can be understood that: metric space $\subset$ topological space. Every $\sigma$-algebra is a monotone class. The same spirit applies, it can be understood that: $\sigma$-algebra $\subset$ monotone class. But if we define monotone class generated by $\mathcal C$ by $\mathcal M(\mathcal C):=\bigcap\limits_{\mathcal M \text{ monotone class, } \mathcal C \subset \mathcal M} \mathcal M$ and $\sigma$-algebra generated by $\mathcal C$ by $\sigma(\mathcal C):=\bigcap\limits_{\mathcal T \sigma\text{-algebra, } \mathcal C \subset \mathcal T} \mathcal T$. Why is $\mathcal M(\mathcal C) \subset \sigma (\mathcal C)$?",,['measure-theory']
48,Norm vector spaces and Banach Space,Norm vector spaces and Banach Space,,"Suppose that $\{T_j\}_{1}^{\infty}$ is a sequence of bounded linear transformations from a normed vector space $X$ into a Banach space $Y$, suppose $\lVert T_j\rVert\leq M < \infty$ for all $j$ and suppose there is a dense set $E\subset X$ such that $\{T_k(x)\}_{1}^{\infty}$ converges for every $x\in E$. Prove that $\{T_j(x)\}_{1}^{\infty}$ converges for $x\in X$. Attempted proof: Let $x\in X$. We know $Y$ is complete, therefore if we show $\{T_j(x)\}_{1}^{\infty}$ is Cauchy then we are done. Let $\epsilon > 0$, choose an $N$ such that $$\lVert T_m(x) - T_n(x) \rVert < \epsilon \ \forall m,n\geq N$$ Since $E$ is dense in $X$ and $\{T_j(x')\}$ is convergent, we can choose an $x'\in E$ with $\lVert x - x'\rVert < \frac{\epsilon}{3M}$, and find an $N$ such that $$\lVert T_m(x') - T_n(x')\rVert < \frac{\epsilon}{3} \ \forall m,n\geq N$$ Then  \begin{align*} \lVert T_m(x) - T_n(x)\rVert &\leq \lVert T_m(x - x')\rVert + \lVert T_m(x') - T_n(x')\rVert + \lVert T_n(x' - x)\rVert\\ &< 2M\lVert x - x'\rVert + \frac{\epsilon}{3}\\ &< \frac{2\epsilon}{3} + \frac{\epsilon}{3}\\ &= \epsilon \end{align*}","Suppose that $\{T_j\}_{1}^{\infty}$ is a sequence of bounded linear transformations from a normed vector space $X$ into a Banach space $Y$, suppose $\lVert T_j\rVert\leq M < \infty$ for all $j$ and suppose there is a dense set $E\subset X$ such that $\{T_k(x)\}_{1}^{\infty}$ converges for every $x\in E$. Prove that $\{T_j(x)\}_{1}^{\infty}$ converges for $x\in X$. Attempted proof: Let $x\in X$. We know $Y$ is complete, therefore if we show $\{T_j(x)\}_{1}^{\infty}$ is Cauchy then we are done. Let $\epsilon > 0$, choose an $N$ such that $$\lVert T_m(x) - T_n(x) \rVert < \epsilon \ \forall m,n\geq N$$ Since $E$ is dense in $X$ and $\{T_j(x')\}$ is convergent, we can choose an $x'\in E$ with $\lVert x - x'\rVert < \frac{\epsilon}{3M}$, and find an $N$ such that $$\lVert T_m(x') - T_n(x')\rVert < \frac{\epsilon}{3} \ \forall m,n\geq N$$ Then  \begin{align*} \lVert T_m(x) - T_n(x)\rVert &\leq \lVert T_m(x - x')\rVert + \lVert T_m(x') - T_n(x')\rVert + \lVert T_n(x' - x)\rVert\\ &< 2M\lVert x - x'\rVert + \frac{\epsilon}{3}\\ &< \frac{2\epsilon}{3} + \frac{\epsilon}{3}\\ &= \epsilon \end{align*}",,"['real-analysis', 'measure-theory']"
49,absolute continuity and translation -invariant of $\mu$ measure,absolute continuity and translation -invariant of  measure,\mu,"if I have a measure $\mu$ on $(a,b]$ such that $\mu(a,b]=F(b)-F(a)$ where  $F$ is non-decreasing, continuous function from the right, I know that if $F$ is not absolutely continuous, then $μ(A) > 0$ for some set $A$ of Lebesgue measure $0$. How can I prove that almost all translates of $A$ must have $μ$-measure $0$ ? I'd like to prove that $\lambda(A)=0$ implies $\mu(A+x)=0$ for $x$ outside a set of Lebesgue measure zero. $\lambda$ is the Lebesgue measure and is invariant under translation and reflection through $0$) Thank you","if I have a measure $\mu$ on $(a,b]$ such that $\mu(a,b]=F(b)-F(a)$ where  $F$ is non-decreasing, continuous function from the right, I know that if $F$ is not absolutely continuous, then $μ(A) > 0$ for some set $A$ of Lebesgue measure $0$. How can I prove that almost all translates of $A$ must have $μ$-measure $0$ ? I'd like to prove that $\lambda(A)=0$ implies $\mu(A+x)=0$ for $x$ outside a set of Lebesgue measure zero. $\lambda$ is the Lebesgue measure and is invariant under translation and reflection through $0$) Thank you",,['measure-theory']
50,Measure multiplicative but not dirac,Measure multiplicative but not dirac,,"Let's call a measure $\mu$ on a measurable space $(X, \mathcal{A})$ multiplicative if $$\mu(A \cap B) = \mu(A) \mu(B) \tag{$*$}$$ for all $A,B \in \mathcal{A}$. Any dirac measure $\delta_x$ for some $x \in X$ is multiplicative. Do there exist nonzero multiplicative measures that are not dirac measures? If so, then can we make additional assumptions on the measurable space and the measure such that nonzero multiplicative implies dirac? The implication is true if $X$ is a compact Hausdorff space and $\mu$ is a regular Borel measure on $X$, but does it hold in more general circumstances? EDIT: As Jonas pointed out, $(*)$ becomes meaningless if $\mu(A) = 0$ and $\mu(B) = \infty$, so we should not require $(*)$ to hold for pairs of measurable sets where one has measure zero and the other has measure infinity. EDIT: Under no extra assumptions, $\mathcal{A} = \{\emptyset, X\}$ with $\mu(X) = \infty$ is a counter-example, though a rather uninteresting one. If we assume that at least one measurable set $A$ has finite positive measure then if $\mu(B)=\infty$ we get $\infty > \mu(A) \geq \mu(A \cap B) = \mu(A)\mu(B) = \infty$, a contradiction, so no sets can have infinite measure in this case. Let's therefore assume that the measure space is finite, i.e. all measurable sets have finite measure.","Let's call a measure $\mu$ on a measurable space $(X, \mathcal{A})$ multiplicative if $$\mu(A \cap B) = \mu(A) \mu(B) \tag{$*$}$$ for all $A,B \in \mathcal{A}$. Any dirac measure $\delta_x$ for some $x \in X$ is multiplicative. Do there exist nonzero multiplicative measures that are not dirac measures? If so, then can we make additional assumptions on the measurable space and the measure such that nonzero multiplicative implies dirac? The implication is true if $X$ is a compact Hausdorff space and $\mu$ is a regular Borel measure on $X$, but does it hold in more general circumstances? EDIT: As Jonas pointed out, $(*)$ becomes meaningless if $\mu(A) = 0$ and $\mu(B) = \infty$, so we should not require $(*)$ to hold for pairs of measurable sets where one has measure zero and the other has measure infinity. EDIT: Under no extra assumptions, $\mathcal{A} = \{\emptyset, X\}$ with $\mu(X) = \infty$ is a counter-example, though a rather uninteresting one. If we assume that at least one measurable set $A$ has finite positive measure then if $\mu(B)=\infty$ we get $\infty > \mu(A) \geq \mu(A \cap B) = \mu(A)\mu(B) = \infty$, a contradiction, so no sets can have infinite measure in this case. Let's therefore assume that the measure space is finite, i.e. all measurable sets have finite measure.",,['measure-theory']
51,How can I show that one of $m(A)$ or $m(\Bbb{R}\setminus A)$ is zero?,How can I show that one of  or  is zero?,m(A) m(\Bbb{R}\setminus A),"Let $A \subseteq \Bbb{R}$ be Borel measurable, and $T$ a dense subset of $\Bbb{R}$. Suppose for every $t \in T$ that  $$m((A+t)\setminus A)=0,$$ where $m$ is the Lebesgue measure. Then I want to show that $m(A)$ or $m(\Bbb{R}\setminus A) = 0$. Indeed suppose $m(A)$ is finite. Fix $t \in T$, then we see that $$\chi_A(x)= \tau_t \chi_A(x)$$ for a.e. $x$, where $\tau_t$ is translation. Then taking Fourier transforms we get  $$\hat{\chi_A}(\xi) = e^{it\xi} \hat{\chi_A}(\xi).$$ Since $t \in T$ was arbitrary, given any $\xi$ we can always choose $t\in T$ so that $e^{it\xi} \neq 1,$ and we get the result that we want. My question is: How can we reduce to the case where $m(A) < \infty$?","Let $A \subseteq \Bbb{R}$ be Borel measurable, and $T$ a dense subset of $\Bbb{R}$. Suppose for every $t \in T$ that  $$m((A+t)\setminus A)=0,$$ where $m$ is the Lebesgue measure. Then I want to show that $m(A)$ or $m(\Bbb{R}\setminus A) = 0$. Indeed suppose $m(A)$ is finite. Fix $t \in T$, then we see that $$\chi_A(x)= \tau_t \chi_A(x)$$ for a.e. $x$, where $\tau_t$ is translation. Then taking Fourier transforms we get  $$\hat{\chi_A}(\xi) = e^{it\xi} \hat{\chi_A}(\xi).$$ Since $t \in T$ was arbitrary, given any $\xi$ we can always choose $t\in T$ so that $e^{it\xi} \neq 1,$ and we get the result that we want. My question is: How can we reduce to the case where $m(A) < \infty$?",,"['real-analysis', 'measure-theory', 'fourier-analysis']"
52,Show that $f$ is summable on $A$ and $\lim_{n\rightarrow \infty} \int_A f_n dm=\int_A f dm$,Show that  is summable on  and,f A \lim_{n\rightarrow \infty} \int_A f_n dm=\int_A f dm,"Show that if $f_n$ is summable on a bounded measurable set $A$ for $n=1,2,\ldots$  and if $f_n$ converges uniformly to $f$ on $A$ then $f$ is summable on $A$ and $\lim_{n\rightarrow \infty} \int_A f_n dm=\int_A f dm$. Proof: It is enough to show that $\lim_{n\rightarrow \infty} \int_A (f_n-f) dm=0$. We have $$\Bigg| \int_A(f_n-f)dm\Bigg| \le \int_A|f_n-f|dm\le m(A)\sup_{x\in A} |f_n(x)-f(x)|$$ but $\sup_{x\in A} |f_n(x)-f(x)|$ goes to $0$ as $n\rightarrow\infty$ so $$\Bigg| \int_A(f_n-f)dm\Bigg| \rightarrow 0 \mbox{.}$$ Is this proof correct? I think I have not proved that $f$ is summable. How can I do it?","Show that if $f_n$ is summable on a bounded measurable set $A$ for $n=1,2,\ldots$  and if $f_n$ converges uniformly to $f$ on $A$ then $f$ is summable on $A$ and $\lim_{n\rightarrow \infty} \int_A f_n dm=\int_A f dm$. Proof: It is enough to show that $\lim_{n\rightarrow \infty} \int_A (f_n-f) dm=0$. We have $$\Bigg| \int_A(f_n-f)dm\Bigg| \le \int_A|f_n-f|dm\le m(A)\sup_{x\in A} |f_n(x)-f(x)|$$ but $\sup_{x\in A} |f_n(x)-f(x)|$ goes to $0$ as $n\rightarrow\infty$ so $$\Bigg| \int_A(f_n-f)dm\Bigg| \rightarrow 0 \mbox{.}$$ Is this proof correct? I think I have not proved that $f$ is summable. How can I do it?",,"['calculus', 'measure-theory', 'lebesgue-integral', 'lebesgue-measure']"
53,Show that Lebesgue outer measure is the infimum of Lebesgue measure,Show that Lebesgue outer measure is the infimum of Lebesgue measure,,"Let $$ \lambda^*(S) = \inf\left\{\sum_{j=0}^\infty (b_j - a_j)\mid a_j, b_j \in \mathbb{R},S \subseteq \bigcup_{j=0}^\infty [a_j,b_j[ \right\} $$ be the Lebesgue outer measure. Using Carathedory's method, the Lebesgue measure and $\lambda$ and Lebesgue measurable sets $\Sigma \subseteq \mathcal{P}(\mathbb{R})$ can be defined as $$ \Sigma = \{S\mid \forall U \subseteq \mathbb{R}, 				\lambda^*(U \cap S) + \lambda^*(U \setminus S) = \lambda^*(U)\}, \lambda = \lambda^*\restriction_\Sigma $$ Theorem: For every $S \subseteq \mathbb{R}$,   $$ \lambda^*(S) = \inf\{\lambda(U)\mid U \in \Sigma, S \subseteq U\}$$ How to prove this theorem? The question hints to consider sets of the form $$ U = \bigcup_{j=0}^\infty [a_j,b_j[ $$ They are certainly measurable, but how can the infimum be attained?","Let $$ \lambda^*(S) = \inf\left\{\sum_{j=0}^\infty (b_j - a_j)\mid a_j, b_j \in \mathbb{R},S \subseteq \bigcup_{j=0}^\infty [a_j,b_j[ \right\} $$ be the Lebesgue outer measure. Using Carathedory's method, the Lebesgue measure and $\lambda$ and Lebesgue measurable sets $\Sigma \subseteq \mathcal{P}(\mathbb{R})$ can be defined as $$ \Sigma = \{S\mid \forall U \subseteq \mathbb{R}, 				\lambda^*(U \cap S) + \lambda^*(U \setminus S) = \lambda^*(U)\}, \lambda = \lambda^*\restriction_\Sigma $$ Theorem: For every $S \subseteq \mathbb{R}$,   $$ \lambda^*(S) = \inf\{\lambda(U)\mid U \in \Sigma, S \subseteq U\}$$ How to prove this theorem? The question hints to consider sets of the form $$ U = \bigcup_{j=0}^\infty [a_j,b_j[ $$ They are certainly measurable, but how can the infimum be attained?",,"['measure-theory', 'lebesgue-measure']"
54,$\lim_ {n \to \infty} f_n$ is $\Sigma$-measurable,is -measurable,\lim_ {n \to \infty} f_n \Sigma,"Let $(X,\Sigma)$ be a measurable space and let $\{f_n\}_{n \in \mathbb{N}}$ be a sequence of $\Sigma$-measurable  real valued functions with domains included in $X$. What does it mean to say ""domains included in $X$""? Why is this significant? We define a function $\lim\limits_{n \to \infty} f_n$ by writing $$\lim\limits_{n \to \infty} (f_n)(x) = \lim\limits_{n \to \infty} f_n (x)$$ for $x \in \cup_{n \in \mathbb{N}} \cap_{m \geq n} \text{dom } f_m$ for which the limit exists in $\mathbb{R}$. Then $\lim\limits_{n \to \infty} f_n$  is $\Sigma$-measurable. What does $x \in \cup_{n \in \mathbb{N}} \cap_{m \geq n}\text{dom } f_m$ mean? How can it be interpreted?","Let $(X,\Sigma)$ be a measurable space and let $\{f_n\}_{n \in \mathbb{N}}$ be a sequence of $\Sigma$-measurable  real valued functions with domains included in $X$. What does it mean to say ""domains included in $X$""? Why is this significant? We define a function $\lim\limits_{n \to \infty} f_n$ by writing $$\lim\limits_{n \to \infty} (f_n)(x) = \lim\limits_{n \to \infty} f_n (x)$$ for $x \in \cup_{n \in \mathbb{N}} \cap_{m \geq n} \text{dom } f_m$ for which the limit exists in $\mathbb{R}$. Then $\lim\limits_{n \to \infty} f_n$  is $\Sigma$-measurable. What does $x \in \cup_{n \in \mathbb{N}} \cap_{m \geq n}\text{dom } f_m$ mean? How can it be interpreted?",,['measure-theory']
55,difference of characteristic function for measure and random variable,difference of characteristic function for measure and random variable,,Suppose random variable $X$ follow a certain (known) distribution. And I denote the probability measure $\mu$ as the distribution (pushforward measure) of $X$. Is there any difference between $\hat{\mu}(t)=\int_{\mathbb{R}}{e^{itx}\mu(dx)}$ (Fourier transformation of $\mu$) and $\phi_{X}(t)$ (the characteristic function of $X$),Suppose random variable $X$ follow a certain (known) distribution. And I denote the probability measure $\mu$ as the distribution (pushforward measure) of $X$. Is there any difference between $\hat{\mu}(t)=\int_{\mathbb{R}}{e^{itx}\mu(dx)}$ (Fourier transformation of $\mu$) and $\phi_{X}(t)$ (the characteristic function of $X$),,"['measure-theory', 'characteristic-functions']"
56,Proof step in Rademacher's Theorem,Proof step in Rademacher's Theorem,,"In the proof of Rademacher's theorem, we assume that $f: \Bbb R^n \to \Bbb R$ is a Lipschitz function and $v \in \Bbb R^n$ is a vector with $\Vert v \Vert = 1$. Our aim is to show, that  $$ \mathrm D_v f(x) = v \cdot \text{grad} f(x) \; ,$$ where $\mathrm D_v f(x)$ is the directional derivative of $f$ at the point $x$ in the direction $v$, and on the right sight of the equation we have the euclidean scalar product of $v$ and the gradient of $f$ at the point $x$. In the proof we have shown, that  $$ \int_{\Bbb R^n} \mathrm D_v f(x) \zeta(x) \; \mathrm dx = \int_{\Bbb R^n} [v \cdot \text{grad}f(x)] \zeta(x) \; \mathrm dx $$ for any $\zeta \in C_c^\infty(\Bbb R^n)$.  Why is this enough to know, that  $$ \mathrm D_v f(x) = v \cdot \text{grad} f(x) $$ holds?","In the proof of Rademacher's theorem, we assume that $f: \Bbb R^n \to \Bbb R$ is a Lipschitz function and $v \in \Bbb R^n$ is a vector with $\Vert v \Vert = 1$. Our aim is to show, that  $$ \mathrm D_v f(x) = v \cdot \text{grad} f(x) \; ,$$ where $\mathrm D_v f(x)$ is the directional derivative of $f$ at the point $x$ in the direction $v$, and on the right sight of the equation we have the euclidean scalar product of $v$ and the gradient of $f$ at the point $x$. In the proof we have shown, that  $$ \int_{\Bbb R^n} \mathrm D_v f(x) \zeta(x) \; \mathrm dx = \int_{\Bbb R^n} [v \cdot \text{grad}f(x)] \zeta(x) \; \mathrm dx $$ for any $\zeta \in C_c^\infty(\Bbb R^n)$.  Why is this enough to know, that  $$ \mathrm D_v f(x) = v \cdot \text{grad} f(x) $$ holds?",,"['real-analysis', 'measure-theory', 'geometric-measure-theory']"
57,"Prove set of points in $[0,1]$ with prime digits is measurable",Prove set of points in  with prime digits is measurable,"[0,1]","Let $A$ be the subset of $[0,1]$ consisting of all numbers such that every digit of $x$ after the decimal point is a prime number i.e. $x=0.p_1p_2p_3\ldots$, where $p_i\in\{2,3,5,7\}$. For example, $0.2$, $0.32$, $0.557$, $0.7532$, et cetera. I want to prove that $A$ is a Lebesgue measurable set and evaluate the Lebesgue measure $m(A)$. I notice that $A$ is an infinite set: $A = \{0.2, 0.22, 0.222,\ldots , 0.7777\ldots\}$. $A$ is bounded above by $0.777\ldots$, and bounded below by $0.2$ . Is that $A$ is compact and therefore measurable? I know that $m(X) = \text{length of }X=\lambda(X)$ when $X$ is an interval Also for $X \subseteq (0,1)$ and \lambda(X) = \lambda((0,1)) - \lambda((0,1)\X) I have not idea about how to evaluate $\lambda((0,1)\setminus A)$. Any ideas?","Let $A$ be the subset of $[0,1]$ consisting of all numbers such that every digit of $x$ after the decimal point is a prime number i.e. $x=0.p_1p_2p_3\ldots$, where $p_i\in\{2,3,5,7\}$. For example, $0.2$, $0.32$, $0.557$, $0.7532$, et cetera. I want to prove that $A$ is a Lebesgue measurable set and evaluate the Lebesgue measure $m(A)$. I notice that $A$ is an infinite set: $A = \{0.2, 0.22, 0.222,\ldots , 0.7777\ldots\}$. $A$ is bounded above by $0.777\ldots$, and bounded below by $0.2$ . Is that $A$ is compact and therefore measurable? I know that $m(X) = \text{length of }X=\lambda(X)$ when $X$ is an interval Also for $X \subseteq (0,1)$ and \lambda(X) = \lambda((0,1)) - \lambda((0,1)\X) I have not idea about how to evaluate $\lambda((0,1)\setminus A)$. Any ideas?",,"['measure-theory', 'lebesgue-measure', 'decimal-expansion']"
58,Checking Caratheodory-measurability condition on sets of the semiring,Checking Caratheodory-measurability condition on sets of the semiring,,"Let $\mathcal H$ be a semiring over the set $X$ and $\mu$ a pre-measure defined on $\mathcal H$. Then we associate an outer measure $\mu^\ast$ to $\mu$ (describe here: https://en.wikipedia.org/w/index.php?title=Outer_measure (method I)) A set $A$ is called Caratheodory-measurable by $\mu^\ast$ if $\mu^\ast(Q) = \mu^\ast(Q \cap A) + \mu^\ast(Q \cap A^c)$ for all sets $Q \subset X$. Now, would it be sufficient to check this condition against all sets $Q$ in the sigma-algebra generated by $\mathcal H$ or even only in the sets in the semiring $\mathcal H$?","Let $\mathcal H$ be a semiring over the set $X$ and $\mu$ a pre-measure defined on $\mathcal H$. Then we associate an outer measure $\mu^\ast$ to $\mu$ (describe here: https://en.wikipedia.org/w/index.php?title=Outer_measure (method I)) A set $A$ is called Caratheodory-measurable by $\mu^\ast$ if $\mu^\ast(Q) = \mu^\ast(Q \cap A) + \mu^\ast(Q \cap A^c)$ for all sets $Q \subset X$. Now, would it be sufficient to check this condition against all sets $Q$ in the sigma-algebra generated by $\mathcal H$ or even only in the sets in the semiring $\mathcal H$?",,['measure-theory']
59,Integral similar to Lebesgue point theorem,Integral similar to Lebesgue point theorem,,"Assume we are in $\mathbb R^N$ and $\Gamma$ is a ($N-1$)-rectifiable set with $\mathcal H^{N-1}(\Gamma)<\infty$ and $\mathcal H^{N-1}(\bar \Gamma\setminus \Gamma)=0$. Let $u\in C_c(\mathbb R^N)$ and $u\geq 0$. Define $\Gamma_\epsilon = \{x\in\mathbb R^N\mid \operatorname{dist}(x,\Gamma)<\epsilon\}$. I am trying to prove that  $$ \lim_{\epsilon\to 0}\frac{1}{2\epsilon}\int_{\Gamma_\epsilon}u(x)\,dx = \int_\Gamma u(x)\,d\mathcal H^{N-1}. $$ I feel like this is similar to Lebesgue point theorem, but instead of comprising to a point, it goes to a $N-1$ rectifiable set.","Assume we are in $\mathbb R^N$ and $\Gamma$ is a ($N-1$)-rectifiable set with $\mathcal H^{N-1}(\Gamma)<\infty$ and $\mathcal H^{N-1}(\bar \Gamma\setminus \Gamma)=0$. Let $u\in C_c(\mathbb R^N)$ and $u\geq 0$. Define $\Gamma_\epsilon = \{x\in\mathbb R^N\mid \operatorname{dist}(x,\Gamma)<\epsilon\}$. I am trying to prove that  $$ \lim_{\epsilon\to 0}\frac{1}{2\epsilon}\int_{\Gamma_\epsilon}u(x)\,dx = \int_\Gamma u(x)\,d\mathcal H^{N-1}. $$ I feel like this is similar to Lebesgue point theorem, but instead of comprising to a point, it goes to a $N-1$ rectifiable set.",,"['real-analysis', 'measure-theory', 'geometric-measure-theory']"
60,Why are Radon measures that agree on closed balls equal?,Why are Radon measures that agree on closed balls equal?,,"I have a task to prove that if two Radon measures $\mu$ and $\nu$ agree on closed balls in $\Bbb{R}^n$ then they are equal. It's given as a corollary of Vitali covering theorem, or to be precise, the corollary of this fact that for Radon measure $\mu$ for $\forall \epsilon>0$ we can find balls $\{B_i\}$, such that $\mu(A)\leq\sum_{i}\mu(B_i)\leq\mu(A)+\epsilon$. I understand how this fact above follows from Vitali covering theorem, but cannot get how to use it to prove that the measures are equal.","I have a task to prove that if two Radon measures $\mu$ and $\nu$ agree on closed balls in $\Bbb{R}^n$ then they are equal. It's given as a corollary of Vitali covering theorem, or to be precise, the corollary of this fact that for Radon measure $\mu$ for $\forall \epsilon>0$ we can find balls $\{B_i\}$, such that $\mu(A)\leq\sum_{i}\mu(B_i)\leq\mu(A)+\epsilon$. I understand how this fact above follows from Vitali covering theorem, but cannot get how to use it to prove that the measures are equal.",,['measure-theory']
61,Infinite Lebesgue integral over all infinite measure subsets?,Infinite Lebesgue integral over all infinite measure subsets?,,"This question is in particular for $\mathbb{R}^+$. What properties must a finite function $f$ have such that $\int_A f d\mu = \infty$ for all A with $\mu(A) = \infty$? As pointed out previously (when the question was not framed correctly), obviously any constant $f$ will have infinite integral.","This question is in particular for $\mathbb{R}^+$. What properties must a finite function $f$ have such that $\int_A f d\mu = \infty$ for all A with $\mu(A) = \infty$? As pointed out previously (when the question was not framed correctly), obviously any constant $f$ will have infinite integral.",,"['real-analysis', 'measure-theory']"
62,How to show that the closed unit ball is a measurable set for outer measure $m^*$?,How to show that the closed unit ball is a measurable set for outer measure ?,m^*,"How to show that $\{x \in \mathbb R^{n} : \|x\| \le 1 \}$ is an $m^* $-measurable set? I know that a set $E$ is said to be $m^*$-measurable (or Lebesgue measurable) if for any set $A \subset \Bbb R^{n}$ we have, $$m^*(A)=m^*(A \cap E)+m^*(A \cap E^C)$$ How should I use this definition? Is there any other method to show this?","How to show that $\{x \in \mathbb R^{n} : \|x\| \le 1 \}$ is an $m^* $-measurable set? I know that a set $E$ is said to be $m^*$-measurable (or Lebesgue measurable) if for any set $A \subset \Bbb R^{n}$ we have, $$m^*(A)=m^*(A \cap E)+m^*(A \cap E^C)$$ How should I use this definition? Is there any other method to show this?",,"['measure-theory', 'lebesgue-measure']"
63,Markov's inequality proof check,Markov's inequality proof check,,"Can anyone please check my proof? We are asked to show that if $f:\mathbb{R}^d \to \mathbb{R}_+$ is a measurable function then  $$\int f \ge a \times m(\{f>a\}).$$ I note that $$\int f = \int_{\mathbb{R}_+} m(\{f>t\}) dt \ge \int_{[0,a]} m(\{f>t\}) dt \ge \int_{[0,a]} m(\{f>a\}dt= a \times m(\{f>a\})$$ My first inequality is due to the fact that we have non-negative measure and the second one uses the fact that $\{f>a\} \subset \{f>t\}$ for $t \in [0,a]$ hence $m(\{f>t\}) \ge m(\{f>a\})$.","Can anyone please check my proof? We are asked to show that if $f:\mathbb{R}^d \to \mathbb{R}_+$ is a measurable function then  $$\int f \ge a \times m(\{f>a\}).$$ I note that $$\int f = \int_{\mathbb{R}_+} m(\{f>t\}) dt \ge \int_{[0,a]} m(\{f>t\}) dt \ge \int_{[0,a]} m(\{f>a\}dt= a \times m(\{f>a\})$$ My first inequality is due to the fact that we have non-negative measure and the second one uses the fact that $\{f>a\} \subset \{f>t\}$ for $t \in [0,a]$ hence $m(\{f>t\}) \ge m(\{f>a\})$.",,"['measure-theory', 'proof-verification', 'lebesgue-integral']"
64,Completeness of Probability Distribution as a Measure.,Completeness of Probability Distribution as a Measure.,,"Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a complete probability space and $X:\Omega \to \mathbb{R}^n$ be a $\mathcal{F}$-measurable function, i.e., it is a random variable. Then, in the book ""Bernt Øksendal, stochastic differential equations: an introduction with applications, Springer-Verlag, 2003,"" it is said that $X$ induces the probability space $(\mathbb{R}^n, \mathcal{B}, \mu_X)$, where $\mathcal{B}$ is the Borel $\sigma$-algebra on $\mathbb{R}^n$,  and $\mu_X: \mathcal{B} \to [0, 1]$ is the probability measure called the distribution given by \begin{equation}    \mu_X(B) \doteq \mathbb{P}(X^{-1}(B))  \end{equation} for any $B \in \mathcal{B}$. My question is that is $\mu_X$ a complete measure? Since $\mathbb{P}$ is assumed complete, I think $\mu_X$ would be also complete, but I stuck with its proof. Perhaps, one need to show that  \begin{equation}    \mu_X(B) = 0 \textrm{ and } C \subset B \;\; \Longrightarrow \;\;     C \in \mathcal{B}, \end{equation} which obviously implies $\mu_X(C) = 0$ by monotonicy.","Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a complete probability space and $X:\Omega \to \mathbb{R}^n$ be a $\mathcal{F}$-measurable function, i.e., it is a random variable. Then, in the book ""Bernt Øksendal, stochastic differential equations: an introduction with applications, Springer-Verlag, 2003,"" it is said that $X$ induces the probability space $(\mathbb{R}^n, \mathcal{B}, \mu_X)$, where $\mathcal{B}$ is the Borel $\sigma$-algebra on $\mathbb{R}^n$,  and $\mu_X: \mathcal{B} \to [0, 1]$ is the probability measure called the distribution given by \begin{equation}    \mu_X(B) \doteq \mathbb{P}(X^{-1}(B))  \end{equation} for any $B \in \mathcal{B}$. My question is that is $\mu_X$ a complete measure? Since $\mathbb{P}$ is assumed complete, I think $\mu_X$ would be also complete, but I stuck with its proof. Perhaps, one need to show that  \begin{equation}    \mu_X(B) = 0 \textrm{ and } C \subset B \;\; \Longrightarrow \;\;     C \in \mathcal{B}, \end{equation} which obviously implies $\mu_X(C) = 0$ by monotonicy.",,"['real-analysis', 'measure-theory', 'stochastic-calculus']"
65,Measure of Image of Linear Map between Different Dimensional Space,Measure of Image of Linear Map between Different Dimensional Space,,"If $L \in {\mathbb R}^{m \times n}$ ($m < n$) is a linear map from ${\mathbb R}^n$ onto ${\mathbb R}^m$ (onto means $L$ has full row rank). Given a compact set ${\mathcal A} \subset {\mathbb R}^n$ (compact set in Euclidean space is Lebesgue measurable), how to calculate the measure $\mu_{m}(L({\mathcal A}))$, where $\mu_{m}(\cdot)$ is the Lebesgue measure in ${\mathbb R}^m$?","If $L \in {\mathbb R}^{m \times n}$ ($m < n$) is a linear map from ${\mathbb R}^n$ onto ${\mathbb R}^m$ (onto means $L$ has full row rank). Given a compact set ${\mathcal A} \subset {\mathbb R}^n$ (compact set in Euclidean space is Lebesgue measurable), how to calculate the measure $\mu_{m}(L({\mathcal A}))$, where $\mu_{m}(\cdot)$ is the Lebesgue measure in ${\mathbb R}^m$?",,"['measure-theory', 'linear-transformations']"
66,"Show that $E=\{(x,\alpha)\mid 0\leq \alpha<|f(x)|\}$ is measurable if $f$ is measurable.",Show that  is measurable if  is measurable.,"E=\{(x,\alpha)\mid 0\leq \alpha<|f(x)|\} f","I have to show that $E=\{(x,\alpha)\mid  0\leq \alpha<|f(x)|\}$ is measurable if $f$ is measurable. My attempt : If $f=\boldsymbol 1_F$ where $f$ is measurable, then $$E=\big((\mathbb R\cap F)\times [0,1[\big)\cup \big((\mathbb R\cap F^c)\times \{0\}\big)$$ which is measurable since it's intersection, union and product of measurable set. If $f$ is simple (remark that $f$ simple $\iff$ $|f|$ simple) i.e. $$|f|=\sum_{i=1}^n a_i\boldsymbol 1_{F_i}$$ where $a_i>0$ and $F_i$ measurable, we obtain in the same way $$E=\bigcup_{i=1}^n\big((\mathbb R\cap F_i)\times [0,a_i[\big)\cup \bigcap_{i=1}^n \big((\mathbb R \cap F_i^c)\times \{0\}\big)$$ which is also measurable since it's finite union, intersection and product of measurable set. Finally, if $|f|\geq 0$ we have a sequence of simple function $\{\varphi_k\}_{k\in\mathbb N}$ s.t. $$\varphi_k(x)\nearrow |f(x)|\quad\text{ for all }x.$$ Let $$E_n=\{(x,\alpha)\mid 0\leq \alpha\leq \varphi_n(x)\}.$$ Therefore $E_n\subset E_{n+1}$ and thus $E_n\nearrow E$ i.e. $$E=\bigcup_{n=1}^\infty  E_n,$$ and since $E_n$ is measurable, the set $E$ is measurable. Is it correct ?","I have to show that $E=\{(x,\alpha)\mid  0\leq \alpha<|f(x)|\}$ is measurable if $f$ is measurable. My attempt : If $f=\boldsymbol 1_F$ where $f$ is measurable, then $$E=\big((\mathbb R\cap F)\times [0,1[\big)\cup \big((\mathbb R\cap F^c)\times \{0\}\big)$$ which is measurable since it's intersection, union and product of measurable set. If $f$ is simple (remark that $f$ simple $\iff$ $|f|$ simple) i.e. $$|f|=\sum_{i=1}^n a_i\boldsymbol 1_{F_i}$$ where $a_i>0$ and $F_i$ measurable, we obtain in the same way $$E=\bigcup_{i=1}^n\big((\mathbb R\cap F_i)\times [0,a_i[\big)\cup \bigcap_{i=1}^n \big((\mathbb R \cap F_i^c)\times \{0\}\big)$$ which is also measurable since it's finite union, intersection and product of measurable set. Finally, if $|f|\geq 0$ we have a sequence of simple function $\{\varphi_k\}_{k\in\mathbb N}$ s.t. $$\varphi_k(x)\nearrow |f(x)|\quad\text{ for all }x.$$ Let $$E_n=\{(x,\alpha)\mid 0\leq \alpha\leq \varphi_n(x)\}.$$ Therefore $E_n\subset E_{n+1}$ and thus $E_n\nearrow E$ i.e. $$E=\bigcup_{n=1}^\infty  E_n,$$ and since $E_n$ is measurable, the set $E$ is measurable. Is it correct ?",,"['measure-theory', 'proof-verification', 'lebesgue-measure']"
67,Measures which are not real-valued,Measures which are not real-valued,,"I'm currently starting to study measure theory and the definitions I've seem up to now are: A measurable space is a pair $(X,M)$ being $X$ a non empty set and $M$ a $\sigma$ -algebra of subsets of $X$ which are called measurable sets. A measure on the measurable space $(X,M)$ is a function $\mu : M\to [0,+\infty]$ satisfying: $\mu(\emptyset)=0$ , If $\{E_n \in M : n\in \mathbb{N}\}$ is a countable collection of pairwise disjoint measurable sets then $$\mu\left(\bigcup_{n\in \mathbb{N}}E_n\right)=\sum_{n=1}^\infty \mu(E_n).$$ This indeed make sense since the idea here is that $\mu$ is a generalized notion of the ""size"" of the measurable sets. The point is that I'm aware that there are measures which are not real valued like the one defined above. For example, I've already heard about complex measures. Another quite interesting example is the projector-valued measures which appear on the spectral theorem in Functional Analysis. Those projector-valued measures don't even take values on any set of numbers. They take value on a subset of the algebra of operators on a Hilbert space. Now, at first I find it quite intuitive the definition of measure given above, but I can't see how these other measures arise and how they are meaningful. So, how those measures which are not real-valued arise? How they relate to this definition? And I think more importantly, what is the intuition behind then? The measure defined above is meant to generalize the idea of size of a set, but those other measures what they intend to be? They can't be about sizes, since they can take values on sets which are not of numbers. So what is the point with them?","I'm currently starting to study measure theory and the definitions I've seem up to now are: A measurable space is a pair being a non empty set and a -algebra of subsets of which are called measurable sets. A measure on the measurable space is a function satisfying: , If is a countable collection of pairwise disjoint measurable sets then This indeed make sense since the idea here is that is a generalized notion of the ""size"" of the measurable sets. The point is that I'm aware that there are measures which are not real valued like the one defined above. For example, I've already heard about complex measures. Another quite interesting example is the projector-valued measures which appear on the spectral theorem in Functional Analysis. Those projector-valued measures don't even take values on any set of numbers. They take value on a subset of the algebra of operators on a Hilbert space. Now, at first I find it quite intuitive the definition of measure given above, but I can't see how these other measures arise and how they are meaningful. So, how those measures which are not real-valued arise? How they relate to this definition? And I think more importantly, what is the intuition behind then? The measure defined above is meant to generalize the idea of size of a set, but those other measures what they intend to be? They can't be about sizes, since they can take values on sets which are not of numbers. So what is the point with them?","(X,M) X M \sigma X (X,M) \mu : M\to [0,+\infty] \mu(\emptyset)=0 \{E_n \in M : n\in \mathbb{N}\} \mu\left(\bigcup_{n\in \mathbb{N}}E_n\right)=\sum_{n=1}^\infty \mu(E_n). \mu","['real-analysis', 'functional-analysis', 'measure-theory', 'definition']"
68,An example that the union of $\sigma$-algebras need not be a $\sigma$-algebra,An example that the union of -algebras need not be a -algebra,\sigma \sigma,"Does the following example show that the union of $\sigma$-algebras may fail to be a $\sigma$-algebra? Let $X=\{a,b,c,d\}$ and let $\mathscr{A}=\{\emptyset,X,\{a,b\},\{c,d\}\}$ and $\mathscr{B}=\{\emptyset,X,\{a,c\},\{b,d\}\}$. Then $\mathscr{A}$ and $\mathscr{B}$ are $\sigma$-algebras while $\mathscr{A}\cup \mathscr{B}=\{\emptyset,X,\{a,b\},\{c,d\},\{a,c\},\{b,d\}\}$ is not a $\sigma$-algebra since it is not closed under intersection.","Does the following example show that the union of $\sigma$-algebras may fail to be a $\sigma$-algebra? Let $X=\{a,b,c,d\}$ and let $\mathscr{A}=\{\emptyset,X,\{a,b\},\{c,d\}\}$ and $\mathscr{B}=\{\emptyset,X,\{a,c\},\{b,d\}\}$. Then $\mathscr{A}$ and $\mathscr{B}$ are $\sigma$-algebras while $\mathscr{A}\cup \mathscr{B}=\{\emptyset,X,\{a,b\},\{c,d\},\{a,c\},\{b,d\}\}$ is not a $\sigma$-algebra since it is not closed under intersection.",,['measure-theory']
69,Mathematical descriptions of physical space,Mathematical descriptions of physical space,,"Bear with me as I'm a philosophy (not math) student. First some philosophical background, and then the math question. One philosophical view is that physical space is composed of infinitely many points of zero volume. But the question arises, how can points of zero volume add up to a non-zero finite volume? Even with an infinite number of points this seems impossible--from nothing you get nothing, no matter how many times you add nothing. The response to this question is typically an appeal to measure theory in mathematics. While the Lebesgue measure of a set containing a single point, e.g. $[1,1]$ is $0$, the Lebesgue measure of the set of points $[0,1]$ is non-zero. Hence we have what is in some sense an addition of $0$'s equaling something nonzero. Thus if it is the case that measure theory correctly describes physical space, we have an answer to our original question. Now here is my question to you guys. Are there any alternatives to measure theory which yield different results? That is, are there any instances of mathematics where the sum of an actually infinite amount of zeros (this rules out limits and sums defined in terms of limits) is $0$? One candidate to me seemed to be the hyperreal numbers from non-standard analysis. While I do not know how to formalize an ""infinite sum"" in non-standard analysis (e.g. is there a sort of measure theory equivalent in non-standard analysis?) but I can do something similar--in non-standard analysis, $0$ times infinity is always zero (right?). Whether this calculation is a better analog to physical space than measure theory is something I am skeptical of, but nonetheless it would be interesting to hear from you mathematicians about sums of zeros in non-standard analysis or other alternative mathematical tools/theories.","Bear with me as I'm a philosophy (not math) student. First some philosophical background, and then the math question. One philosophical view is that physical space is composed of infinitely many points of zero volume. But the question arises, how can points of zero volume add up to a non-zero finite volume? Even with an infinite number of points this seems impossible--from nothing you get nothing, no matter how many times you add nothing. The response to this question is typically an appeal to measure theory in mathematics. While the Lebesgue measure of a set containing a single point, e.g. $[1,1]$ is $0$, the Lebesgue measure of the set of points $[0,1]$ is non-zero. Hence we have what is in some sense an addition of $0$'s equaling something nonzero. Thus if it is the case that measure theory correctly describes physical space, we have an answer to our original question. Now here is my question to you guys. Are there any alternatives to measure theory which yield different results? That is, are there any instances of mathematics where the sum of an actually infinite amount of zeros (this rules out limits and sums defined in terms of limits) is $0$? One candidate to me seemed to be the hyperreal numbers from non-standard analysis. While I do not know how to formalize an ""infinite sum"" in non-standard analysis (e.g. is there a sort of measure theory equivalent in non-standard analysis?) but I can do something similar--in non-standard analysis, $0$ times infinity is always zero (right?). Whether this calculation is a better analog to physical space than measure theory is something I am skeptical of, but nonetheless it would be interesting to hear from you mathematicians about sums of zeros in non-standard analysis or other alternative mathematical tools/theories.",,"['measure-theory', 'infinity', 'nonstandard-analysis']"
70,"If I show that an iterated integral is less than $\infty$, does it necessarily mean that the integral is finite?","If I show that an iterated integral is less than , does it necessarily mean that the integral is finite?",\infty,"I am currently trying to show that an function has a finite integral. I am trying to find the iterated integral of: $$ \frac{e^{\alpha + 0.3\beta}}{1+e^{\alpha + 0.3\beta}}\frac{1}{1+e^{\alpha + 0.3\beta}}\frac{e^{\alpha + 0.05\beta}}{1+e^{\alpha + 0.05\beta}}\frac{1}{1+e^{\alpha + 0.05\beta}} $$ over $-\infty < \alpha, \beta <\infty$. I am able to see that $\frac{e^{\alpha + 0.3\beta}}{1+e^{\alpha + 0.3\beta}}\frac{1}{1+e^{\alpha + 0.3\beta}} < e^{|\alpha + 0.3\beta|}$, and that $\frac{e^{\alpha + 0.05\beta}}{1+e^{\alpha + 0.05\beta}}\frac{1}{1+e^{\alpha + 0.05\beta}} < e^{|\alpha + 0.05\beta|}$. Hence, I have that: $$ \int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} \frac{e^{\alpha + 0.3\beta}}{1+e^{\alpha + 0.3\beta}}\frac{1}{1+e^{\alpha + 0.3\beta}}\frac{e^{\alpha + 0.05\beta}}{1+e^{\alpha + 0.05\beta}}\frac{1}{1+e^{\alpha + 0.05\beta}} d\alpha d\beta $$ $$ < \int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty}e^{|\alpha + 0.3\beta|} e^{|\alpha + 0.05\beta|}d\alpha d\beta = \infty $$ How I got the $\infty$ was by looking at the four cases, when $|\alpha + 0.3\beta|$ is greater than or less than 0, and when $|\alpha + 0.05\beta|$ is greater than or less than 0. However, if I look at alpha, it will either be $e^{-\alpha}e^{\alpha} = 1$, $e^{\alpha}e^{\alpha} = e^{2\alpha}$, or $e^{-\alpha}e^{-\alpha} = e^{-2\alpha}$. In any of these cases, the integral with $d\alpha$ will be infinity. Would this suffice to conclude that: $$ \int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} \frac{e^{\alpha + 0.3\beta}}{1+e^{\alpha + 0.3\beta}}\frac{1}{1+e^{\alpha + 0.3\beta}}\frac{e^{\alpha + 0.05\beta}}{1+e^{\alpha + 0.05\beta}}\frac{1}{1+e^{\alpha + 0.05\beta}} d\alpha d\beta < \infty $$ ? Thanks!","I am currently trying to show that an function has a finite integral. I am trying to find the iterated integral of: $$ \frac{e^{\alpha + 0.3\beta}}{1+e^{\alpha + 0.3\beta}}\frac{1}{1+e^{\alpha + 0.3\beta}}\frac{e^{\alpha + 0.05\beta}}{1+e^{\alpha + 0.05\beta}}\frac{1}{1+e^{\alpha + 0.05\beta}} $$ over $-\infty < \alpha, \beta <\infty$. I am able to see that $\frac{e^{\alpha + 0.3\beta}}{1+e^{\alpha + 0.3\beta}}\frac{1}{1+e^{\alpha + 0.3\beta}} < e^{|\alpha + 0.3\beta|}$, and that $\frac{e^{\alpha + 0.05\beta}}{1+e^{\alpha + 0.05\beta}}\frac{1}{1+e^{\alpha + 0.05\beta}} < e^{|\alpha + 0.05\beta|}$. Hence, I have that: $$ \int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} \frac{e^{\alpha + 0.3\beta}}{1+e^{\alpha + 0.3\beta}}\frac{1}{1+e^{\alpha + 0.3\beta}}\frac{e^{\alpha + 0.05\beta}}{1+e^{\alpha + 0.05\beta}}\frac{1}{1+e^{\alpha + 0.05\beta}} d\alpha d\beta $$ $$ < \int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty}e^{|\alpha + 0.3\beta|} e^{|\alpha + 0.05\beta|}d\alpha d\beta = \infty $$ How I got the $\infty$ was by looking at the four cases, when $|\alpha + 0.3\beta|$ is greater than or less than 0, and when $|\alpha + 0.05\beta|$ is greater than or less than 0. However, if I look at alpha, it will either be $e^{-\alpha}e^{\alpha} = 1$, $e^{\alpha}e^{\alpha} = e^{2\alpha}$, or $e^{-\alpha}e^{-\alpha} = e^{-2\alpha}$. In any of these cases, the integral with $d\alpha$ will be infinity. Would this suffice to conclude that: $$ \int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} \frac{e^{\alpha + 0.3\beta}}{1+e^{\alpha + 0.3\beta}}\frac{1}{1+e^{\alpha + 0.3\beta}}\frac{e^{\alpha + 0.05\beta}}{1+e^{\alpha + 0.05\beta}}\frac{1}{1+e^{\alpha + 0.05\beta}} d\alpha d\beta < \infty $$ ? Thanks!",,"['calculus', 'measure-theory', 'discrete-mathematics']"
71,Length of an interval is its outer measure,Length of an interval is its outer measure,,"To prove that the Lebesgue outer measure $m^*(I)$ of a closed interval $I$ is less or equal to its length $l(I)$  is easy enough. The converse however starts with a step that seems obvious but that I can not seem to prove: For an arbitrary $\epsilon>0$, and closed cover $\{I_n\}$ of $I$, it is said (Measure integral and probability, P.22) that $$\sum_{n=1}^{\infty}l(I_n)\leq m^*(I) + \frac{\epsilon}{2}$$ What I know from the outer measure being a infimum is that $$m^*(I)\leq \sum_{n=1}^{\infty}l(I_n)$$ so I could write $$m^*(I)\leq \sum_{n=1}^{\infty}l(I_n)\leq m^*(I)+2[\sum_{n=1}^{\infty}l(I_n)-m^*(I)]$$ $$\sum_{n=1}^{\infty}l(I_n)\leq m^*(I)+\frac{\epsilon}{2}$$ with $\epsilon :=4[\sum_{n=1}^{\infty}l(I_n)-m^*(I)]$, but that does not sound like an arbitrary $\epsilon$ to me... Any hints ? thanks. Following hints to exploit the infinum definition for $m^*$, I come to the following argument. Argue the opposite, namely that $$ m^*(I)+\frac{\epsilon}{2}<\sum_{n=1}^{\infty}l(I_n) \tag{1}$$ so $m^*(I)+\frac{\epsilon}{2}$ is a lower bound for $\sum_{n=1}^{\infty}l(I_n)$, also $m^*(I)+\frac{\epsilon}{2} > m^*(I)$ another lower bound for the sum. So it remains to find a cover of $I$ with length $m^*(I)+\frac{\epsilon}{2}$, and it would then be the greatest lower bound contradicting the definition of $m^*(I)$ as the g.l.b. Let $\{I_n^*\}$ with endpoints $a_n^*,b_n^*$ be the cover that achieves $m^*$, define the cover $\{I_n^{\epsilon}\}$ $$I_1^{\epsilon}:=(a_1-\frac{\epsilon}{4},b_1+\frac{\epsilon}{4})\\I_i^{\epsilon}=I_i^*,i>1$$ then $\sum_{n=1}^{\infty}l(I_n^{\epsilon})=\sum_{n=1}^{\infty}l(I_n^*)+\frac{\epsilon}{2} = m^*(I)+\frac{\epsilon}{2}$ So we found a cover that acheives l.h.s of $(1)$, contradicting the definition of $m^*(I)$ as the g.l.b. Is that correct ?","To prove that the Lebesgue outer measure $m^*(I)$ of a closed interval $I$ is less or equal to its length $l(I)$  is easy enough. The converse however starts with a step that seems obvious but that I can not seem to prove: For an arbitrary $\epsilon>0$, and closed cover $\{I_n\}$ of $I$, it is said (Measure integral and probability, P.22) that $$\sum_{n=1}^{\infty}l(I_n)\leq m^*(I) + \frac{\epsilon}{2}$$ What I know from the outer measure being a infimum is that $$m^*(I)\leq \sum_{n=1}^{\infty}l(I_n)$$ so I could write $$m^*(I)\leq \sum_{n=1}^{\infty}l(I_n)\leq m^*(I)+2[\sum_{n=1}^{\infty}l(I_n)-m^*(I)]$$ $$\sum_{n=1}^{\infty}l(I_n)\leq m^*(I)+\frac{\epsilon}{2}$$ with $\epsilon :=4[\sum_{n=1}^{\infty}l(I_n)-m^*(I)]$, but that does not sound like an arbitrary $\epsilon$ to me... Any hints ? thanks. Following hints to exploit the infinum definition for $m^*$, I come to the following argument. Argue the opposite, namely that $$ m^*(I)+\frac{\epsilon}{2}<\sum_{n=1}^{\infty}l(I_n) \tag{1}$$ so $m^*(I)+\frac{\epsilon}{2}$ is a lower bound for $\sum_{n=1}^{\infty}l(I_n)$, also $m^*(I)+\frac{\epsilon}{2} > m^*(I)$ another lower bound for the sum. So it remains to find a cover of $I$ with length $m^*(I)+\frac{\epsilon}{2}$, and it would then be the greatest lower bound contradicting the definition of $m^*(I)$ as the g.l.b. Let $\{I_n^*\}$ with endpoints $a_n^*,b_n^*$ be the cover that achieves $m^*$, define the cover $\{I_n^{\epsilon}\}$ $$I_1^{\epsilon}:=(a_1-\frac{\epsilon}{4},b_1+\frac{\epsilon}{4})\\I_i^{\epsilon}=I_i^*,i>1$$ then $\sum_{n=1}^{\infty}l(I_n^{\epsilon})=\sum_{n=1}^{\infty}l(I_n^*)+\frac{\epsilon}{2} = m^*(I)+\frac{\epsilon}{2}$ So we found a cover that acheives l.h.s of $(1)$, contradicting the definition of $m^*(I)$ as the g.l.b. Is that correct ?",,"['real-analysis', 'measure-theory']"
72,real-valued measurable function under a transformation.,real-valued measurable function under a transformation.,,"Here's the question:  ""Let $f \colon \mathbb{R} \to \mathbb{R}$ be measurable. Show that $f(ax)$ is measurable for all real $a$."" I know we can to look at sets of the form $\{f \geq \alpha\}$, where $\alpha$ is any real number. Yet, I'm not sure what this information gives us about the function $f(ax)$. Maybe I'm missing something obvious?  Any hints are very appreciated!","Here's the question:  ""Let $f \colon \mathbb{R} \to \mathbb{R}$ be measurable. Show that $f(ax)$ is measurable for all real $a$."" I know we can to look at sets of the form $\{f \geq \alpha\}$, where $\alpha$ is any real number. Yet, I'm not sure what this information gives us about the function $f(ax)$. Maybe I'm missing something obvious?  Any hints are very appreciated!",,"['real-analysis', 'measure-theory', 'lebesgue-measure']"
73,Cartesian product $\mathbb R^m \times E$ is measurable for $E \subset \mathbb R^n$ measurable,Cartesian product  is measurable for  measurable,\mathbb R^m \times E E \subset \mathbb R^n,"I am trying to show that given $E \subset \mathbb R^n$ measurable, then $\mathbb R^m \times E \subset \mathbb R^{m+n}$ is measurable but I don't have a clue how to show this. I could think of the following: If $E$ is a measurable set, then $E=H \setminus N$, with $H$ a $G_{\delta}$ set and $N$ a null set, so $H= \bigcap_{n \in \mathbb N} G_n$, with $G_n$ is open. So $$\mathbb R^m \times E= \mathbb R^m \times (H \setminus N)$$$$=(\mathbb R^m \times \bigcap_{n \in \mathbb N} G_n) \setminus (\mathbb R^m \times N)$$$$=\bigcap_{n \in \mathbb N} (\mathbb R^m \times G_n) \setminus (\mathbb R^m \times N)$$ So it is sufficient to prove the proposition for open and null sets. I would appreciate help to show the proposition for these two types of sets. Thanks in advance","I am trying to show that given $E \subset \mathbb R^n$ measurable, then $\mathbb R^m \times E \subset \mathbb R^{m+n}$ is measurable but I don't have a clue how to show this. I could think of the following: If $E$ is a measurable set, then $E=H \setminus N$, with $H$ a $G_{\delta}$ set and $N$ a null set, so $H= \bigcap_{n \in \mathbb N} G_n$, with $G_n$ is open. So $$\mathbb R^m \times E= \mathbb R^m \times (H \setminus N)$$$$=(\mathbb R^m \times \bigcap_{n \in \mathbb N} G_n) \setminus (\mathbb R^m \times N)$$$$=\bigcap_{n \in \mathbb N} (\mathbb R^m \times G_n) \setminus (\mathbb R^m \times N)$$ So it is sufficient to prove the proposition for open and null sets. I would appreciate help to show the proposition for these two types of sets. Thanks in advance",,"['real-analysis', 'measure-theory', 'lebesgue-measure']"
74,Explicit construction of a sigma algebra that makes a simple function measurable,Explicit construction of a sigma algebra that makes a simple function measurable,,"This is a question from an old exam. I'd like to see if my answer is correct. I'd appreciate any suggestion. Thanks :) Let $f: (\mathbb{R},\mathscr{S}) \to (\mathbb{R}, \mathscr{B}(\mathbb{R}))$ defined as follows $$f(x):=3\cdot \mathbb{1}_{[1,3]}(x)+2\cdot \mathbb{1}_{[2,4]}(x)$$ where $\mathscr{B}(\mathbb{R})$ is the Borel $\sigma$-algebra of the real numbers, and $\mathbb{1}_A(x)$ is the indicator function, i.e., if $x$ belongs to $A$, $\mathbb{1}_A(x)=1$ and it is zero otherwise. What is the minimum $\sigma$-algebra $\mathscr{S}$ that makes $f$ a measurable function (write explicitly the sigma algebra)? Answer : Let $B_1=[1,3]$ and $B_2=[2,4]$. Now let $\mathscr{D}$ be the collection of all the intersection $C_1\cap C_2$, where either $C_i=B_i$ or $C_i=B_i^c$ for $i\in \{1,2\}$. Then $$\mathscr{D}=\{\,[1,2),\,[2,3],\,(3,4],\,(-\infty,1)\cup (4,+\infty)\,\}$$ Now, we enumerate the elements in $\mathscr{D}$, i.e., $\mathscr{D}=\{D_j: \text{ for } j= 1,\ldots, 4 \}$, and define $\mathscr{A}$ as the collection of all the possible unions of the elements in $\mathscr{D}$, that is $$A\in \mathscr{A} \iff A=\bigcup\bigg\{D_j : j\in J \text{  where  } J \subset\{1,2,3,4\}\bigg\}$$ Thus, we have the follwing \begin{align*}\mathscr{A}= \bigg \{ &\varnothing,\,[1,2),\,[2,3],\,(3,4],\,(-\infty,1)\cup (4,+\infty),\,[1,3],\, [1,2)\cup (3,4],\,(-\infty,2)\cup (4,+\infty),\\ &[2,4],\,(-\infty,1)\cup [2,3]\cup (4,+\infty),\,(-\infty,1)\cup (3,+\infty), [1,4],\,(-\infty,3]\cup (4,+\infty),\\ & (-\infty,2)\cup (3,+\infty),\,(-\infty,1)\cup [2,+\infty),\, \mathbb{R} \bigg\} \end{align*} Now clearly $\mathscr{A}$ is a $\sigma$-algebra (it is closed under countable unions, complementation and also $\mathbb{R}$ belongs to it). On the other hand, the function $f$ can be written by elements in $\mathscr{D}$ (which are a partition of the reals) in the following way $$f(x)=3 \cdot \mathbb{1}_{[1,2)}(x)+5\cdot \mathbb{1}_{[2,3]}(x)+2 \cdot \mathbb{1}_{(3,4]} (x)$$ Therefore, in the above expression of $f$ it is clear that $\mathscr{A}$ makes $f$ measurable.The minimum sigma algebra $\mathscr{S}$ that makes $f$ measurable, must contain $[1,2),\,[2,3],\,(3,4]$. Then $\mathscr{D}$ belongs to $\mathscr{S}$, since $(-\infty,1)\cup (4,+\infty)=[1,4]^c$, and so $\mathscr{A}\subset \mathscr{S}$. The other inclusion is easy by minimality of $\mathscr{S}$. Then $\mathscr{S} =\mathscr{A}$ as desired.","This is a question from an old exam. I'd like to see if my answer is correct. I'd appreciate any suggestion. Thanks :) Let $f: (\mathbb{R},\mathscr{S}) \to (\mathbb{R}, \mathscr{B}(\mathbb{R}))$ defined as follows $$f(x):=3\cdot \mathbb{1}_{[1,3]}(x)+2\cdot \mathbb{1}_{[2,4]}(x)$$ where $\mathscr{B}(\mathbb{R})$ is the Borel $\sigma$-algebra of the real numbers, and $\mathbb{1}_A(x)$ is the indicator function, i.e., if $x$ belongs to $A$, $\mathbb{1}_A(x)=1$ and it is zero otherwise. What is the minimum $\sigma$-algebra $\mathscr{S}$ that makes $f$ a measurable function (write explicitly the sigma algebra)? Answer : Let $B_1=[1,3]$ and $B_2=[2,4]$. Now let $\mathscr{D}$ be the collection of all the intersection $C_1\cap C_2$, where either $C_i=B_i$ or $C_i=B_i^c$ for $i\in \{1,2\}$. Then $$\mathscr{D}=\{\,[1,2),\,[2,3],\,(3,4],\,(-\infty,1)\cup (4,+\infty)\,\}$$ Now, we enumerate the elements in $\mathscr{D}$, i.e., $\mathscr{D}=\{D_j: \text{ for } j= 1,\ldots, 4 \}$, and define $\mathscr{A}$ as the collection of all the possible unions of the elements in $\mathscr{D}$, that is $$A\in \mathscr{A} \iff A=\bigcup\bigg\{D_j : j\in J \text{  where  } J \subset\{1,2,3,4\}\bigg\}$$ Thus, we have the follwing \begin{align*}\mathscr{A}= \bigg \{ &\varnothing,\,[1,2),\,[2,3],\,(3,4],\,(-\infty,1)\cup (4,+\infty),\,[1,3],\, [1,2)\cup (3,4],\,(-\infty,2)\cup (4,+\infty),\\ &[2,4],\,(-\infty,1)\cup [2,3]\cup (4,+\infty),\,(-\infty,1)\cup (3,+\infty), [1,4],\,(-\infty,3]\cup (4,+\infty),\\ & (-\infty,2)\cup (3,+\infty),\,(-\infty,1)\cup [2,+\infty),\, \mathbb{R} \bigg\} \end{align*} Now clearly $\mathscr{A}$ is a $\sigma$-algebra (it is closed under countable unions, complementation and also $\mathbb{R}$ belongs to it). On the other hand, the function $f$ can be written by elements in $\mathscr{D}$ (which are a partition of the reals) in the following way $$f(x)=3 \cdot \mathbb{1}_{[1,2)}(x)+5\cdot \mathbb{1}_{[2,3]}(x)+2 \cdot \mathbb{1}_{(3,4]} (x)$$ Therefore, in the above expression of $f$ it is clear that $\mathscr{A}$ makes $f$ measurable.The minimum sigma algebra $\mathscr{S}$ that makes $f$ measurable, must contain $[1,2),\,[2,3],\,(3,4]$. Then $\mathscr{D}$ belongs to $\mathscr{S}$, since $(-\infty,1)\cup (4,+\infty)=[1,4]^c$, and so $\mathscr{A}\subset \mathscr{S}$. The other inclusion is easy by minimality of $\mathscr{S}$. Then $\mathscr{S} =\mathscr{A}$ as desired.",,"['measure-theory', 'self-learning']"
75,Can one complete a topological space induced by a family of pseudometrics?,Can one complete a topological space induced by a family of pseudometrics?,,"Suppose I have a set $X$ and a family $\{d_i\vert i \in I\}$ of pseudometrics on $X$. For each pseudometric $d_i$ you get a metric space by taking $X_i = X/\sim$ where $x\sim y \iff d_i(x,y)=0$. Let $\mathcal{T}$ be the initial topology induced by the projections $p_i : X \to X_i$. Let's further say that the family is definite, i.e. $d_i(x,y)=0 \, \forall i \implies x=y$. Can we always construct a completion of $X$ that completes all $X_i$? Is there a name for topological spaces that can be obtained this way or can every topological space be constructed by this?  What if every pseudometric is complete? This question came to my mind when trying to generalize this approach to Caratheodorys measurability criterion and theorem on non-$\sigma$-finite spaces by setting $d_A(X,Y) = m^*(A\cap (X\triangle Y))$ for every $A$ with $m^*(A)<\infty$.","Suppose I have a set $X$ and a family $\{d_i\vert i \in I\}$ of pseudometrics on $X$. For each pseudometric $d_i$ you get a metric space by taking $X_i = X/\sim$ where $x\sim y \iff d_i(x,y)=0$. Let $\mathcal{T}$ be the initial topology induced by the projections $p_i : X \to X_i$. Let's further say that the family is definite, i.e. $d_i(x,y)=0 \, \forall i \implies x=y$. Can we always construct a completion of $X$ that completes all $X_i$? Is there a name for topological spaces that can be obtained this way or can every topological space be constructed by this?  What if every pseudometric is complete? This question came to my mind when trying to generalize this approach to Caratheodorys measurability criterion and theorem on non-$\sigma$-finite spaces by setting $d_A(X,Y) = m^*(A\cap (X\triangle Y))$ for every $A$ with $m^*(A)<\infty$.",,"['general-topology', 'measure-theory']"
76,Show that for every $\epsilon > 0 $ there exists $h \in \mathcal{L}^1(X)$ non-negative and $\delta > 0$ such that:,Show that for every  there exists  non-negative and  such that:,\epsilon > 0  h \in \mathcal{L}^1(X) \delta > 0,"I am working through some practice questions, and I think I have gotten the first two parts, but I am having trouble deriving the third part: Let $(X,\mathcal{A},\mu)$ be a finite measure space. Suppose that   $(f_k)$ is a sequence of measurable functions $X \rightarrow \mathbb{R}$ such that for every $\epsilon > 0$ there exists $h \in \mathcal{L}^1(X)$ non-negative such that: $$ \int_{[|f_k|\ge h]} |f_k|d\mu< \epsilon$$ for all $k \in \mathbb{N}$. Where $[|f_k|\ge h] = \{ x \in X : |f_k(x)| \ge h(x) \} $ (1) Show that there exists $P>0$ such that: $$ \int_X |f_k|d\mu \le P$$ for all $k \in N$ (2) Show that for every $A \in \mathcal{A}$ and every $h \in > \mathcal{L}^1(X)$ non-negative: $$ \int_A |f_n|d\mu \le \int_{[|f_k|\ge h]} |f_k|d\mu + \int_A h d\mu$$   (3) Using part (2), show that for every $\epsilon > 0 $ there exists $h \in   \mathcal{L}^1(X)$ non-negative and $\delta > 0$ such that: $A \in \mathcal{A}$ and $\int_A h d\mu < \delta \implies \int_A |f_k|d  \mu < \epsilon $ for all $n \in \mathbb{N}$ For part (1), I have written the integral on the left hand side as disjoint integrals, namely $ [|f_k|\ge h]$ and $[|f_k| < h]$ then the second integral is smaller than $\int_{[|f_k| < h]} h $, since it is precisely over the x's which $h > |f_k|$. And since we know the integrals of $h$ are finite, this yields the result. For part (2), I have done a similar construction, splitting the problem into two cases, where $A$ and $[|f_k|\ge h]$ intersect and where they do not. I am able to derive the inequalities. Is this the right approach to this problem? Part(3) is where I am having the most trouble, by part(2) it seems that I can immediately derive that $\int_A |f_k|d\mu < \epsilon + \delta $, but how to show it is just $< \epsilon$? Any help would be very gratefully received!","I am working through some practice questions, and I think I have gotten the first two parts, but I am having trouble deriving the third part: Let $(X,\mathcal{A},\mu)$ be a finite measure space. Suppose that   $(f_k)$ is a sequence of measurable functions $X \rightarrow \mathbb{R}$ such that for every $\epsilon > 0$ there exists $h \in \mathcal{L}^1(X)$ non-negative such that: $$ \int_{[|f_k|\ge h]} |f_k|d\mu< \epsilon$$ for all $k \in \mathbb{N}$. Where $[|f_k|\ge h] = \{ x \in X : |f_k(x)| \ge h(x) \} $ (1) Show that there exists $P>0$ such that: $$ \int_X |f_k|d\mu \le P$$ for all $k \in N$ (2) Show that for every $A \in \mathcal{A}$ and every $h \in > \mathcal{L}^1(X)$ non-negative: $$ \int_A |f_n|d\mu \le \int_{[|f_k|\ge h]} |f_k|d\mu + \int_A h d\mu$$   (3) Using part (2), show that for every $\epsilon > 0 $ there exists $h \in   \mathcal{L}^1(X)$ non-negative and $\delta > 0$ such that: $A \in \mathcal{A}$ and $\int_A h d\mu < \delta \implies \int_A |f_k|d  \mu < \epsilon $ for all $n \in \mathbb{N}$ For part (1), I have written the integral on the left hand side as disjoint integrals, namely $ [|f_k|\ge h]$ and $[|f_k| < h]$ then the second integral is smaller than $\int_{[|f_k| < h]} h $, since it is precisely over the x's which $h > |f_k|$. And since we know the integrals of $h$ are finite, this yields the result. For part (2), I have done a similar construction, splitting the problem into two cases, where $A$ and $[|f_k|\ge h]$ intersect and where they do not. I am able to derive the inequalities. Is this the right approach to this problem? Part(3) is where I am having the most trouble, by part(2) it seems that I can immediately derive that $\int_A |f_k|d\mu < \epsilon + \delta $, but how to show it is just $< \epsilon$? Any help would be very gratefully received!",,"['measure-theory', 'lebesgue-integral']"
77,Is $\overline{D}_{\varepsilon}$ a connected Jordan region in $\mathbb{R}^{n}?$,Is  a connected Jordan region in,\overline{D}_{\varepsilon} \mathbb{R}^{n}?,"Definition . Let $E$ be a nonempty subset of $\mathbb{R}^{n}$.The distance from a point $\mathbb{x}\in\mathbb{R}^{n}$ to set $E$ is defined by  $$d(\mathbb{x},E)=\inf\{||\mathbb{x}-\mathbb{y}||:\mathbb{y}\in E\}.$$ $E^{\circ}$ (respectively,$\overline{E}, \partial{E}$) is the interior (respectively, closure,boundary ) of a set $E$; Vol$(E)$ is the jordan content of $E.$ We have a set $S\subset  \mathbb{R}^{n},$ such that $S=\overline{D}$ for some nonempty，open, connected jordan region $D$ in $\mathbb{R}^{n}.$ For each sufficiently small positive value of $\varepsilon $,let $$D_{\varepsilon}=\{\mathbb{x}\in D:d(\mathbb{x},\partial{D})\geq \varepsilon\}.$$   Whether $\overline{D}_{\varepsilon}$ is a connected Jordan region in $\mathbb{R}^{n}?$ The following is my effort: $$F_{1}=\{\mathbb{x}\in\mathbb{R}^{n}:d(\mathbb{x},\partial{D})\geq \varepsilon\}\text{ is closed},\quad F_{2}=\{\mathbb{x}\in\mathbb{R}^{n}:d(\mathbb{x},\partial{D})>\varepsilon\}\text{ is open}.$$ $$F^{\circ}_{1}=F_{2},D=D^{\circ},D^{\circ}_{\varepsilon}=F_{1}\cap D \Longrightarrow D^{\circ}_{\varepsilon}=(F_{1}\cap D)^{\circ}=F^{\circ}_{1}\cap D^{\circ}=F_{2}\cap D.$$ $$\partial F_{1}=\{\mathbb{x}\in\mathbb{R}^{n}:d(\mathbb{x},\partial{D})= \varepsilon\}.$$ Since $D$ is connected open set,it follows that $D^{\circ}_{\varepsilon}$ is connected open set. $$\overline{D^{\circ}_{\varepsilon}}=\overline{D}_{\varepsilon}=D^{\circ}_{\varepsilon}\cup \partial {D_{\varepsilon}},\quad\partial {D_{\varepsilon}}\subseteq \partial F_{1}\cup \partial{D},\quad\text{Vol}{(\partial{D})}=0.$$ If Vol$(\partial F_{1})=0 $ holds,then Vol$(\partial{D_{\varepsilon}})=0 $  holds. In my opinion ,If we can prove Vol$(\partial F_{1})=0 $,then $\overline{D}_{\varepsilon}$ is a connected Jordan region in $\mathbb{R}^{n}.$ But how can I prove Vol$(\partial F_{1})=0$? $$\overline{B}_{\varepsilon }(\mathbf{p})=\{\mathbf{x}\in\mathbb{R}^{n}:||\mathbf{x}-\mathbf{p}||\leq \varepsilon\} ,\\\overline{B}_{\varepsilon }(\mathbf{p})\cap \partial D=[\partial B_{\varepsilon }(\mathbf{p})\cup B^{\circ}_{\varepsilon }(\mathbf{p})]\cap\partial D=[\partial B_{\varepsilon }(\mathbf{p})\cap\partial D]\cup[ B^{\circ}_{\varepsilon }(\mathbf{p})\cap\partial D],\\ [\partial B_{\varepsilon }(\mathbf{p})\cap\partial D]\cap[ B^{\circ}_{\varepsilon }(\mathbf{p})\cap\partial D]=\emptyset.$$ $\mathbf{A}.$ $$S_{1}=\{\mathbf{p}\in D^{\circ}:\overline{B}_{\varepsilon }(\mathbf{p})\cap \partial D=\emptyset\}=\{\mathbf{p}\in D^{\circ}:d(\mathbf{p},\partial D)> \varepsilon\}=D_{\varepsilon}^{\circ}$$ $\mathbf{B}.$ $$S_{2}=\{\mathbf{p}\in D^{\circ}:\overline{B}_{\varepsilon }(\mathbf{p})\cap \partial D\ne\emptyset\}$$ $\mathbf(1).\partial B_{\varepsilon }(\mathbf{p})\cap\partial D\ne\emptyset\Longrightarrow \mathbf{p}\in \{\mathbf{p}\in D^{\circ}:d(\mathbf{p},\partial D)=\varepsilon\};$ $\mathbf(2).B^{\circ}_{\varepsilon }(\mathbf{p})\cap\partial D\ne\emptyset\Longrightarrow \mathbf{p}\in \{\mathbf{p}\in D^{\circ}:d(\mathbf{p},\partial D)<\varepsilon\}.$ $$\mathbf{A}+\mathbf{B}\Longrightarrow \partial D_{\varepsilon}=\{\mathbf{p}\in D^{\circ}:\partial B_{\varepsilon }(\mathbf{p})\cap\partial D\ne\emptyset \quad \wedge \quad B^{\circ}_{\varepsilon }(\mathbf{p})\cap\partial D=\emptyset \}.$$ Conversely,$\overline{D}_{\varepsilon}$ may not be  a connected Jordan region in $\mathbb{R}^{n}$.But how can I find a counterexample of that? If you have some good ideas about how to solve this question ,please give me some hints.Any help is going to be appreciated!","Definition . Let $E$ be a nonempty subset of $\mathbb{R}^{n}$.The distance from a point $\mathbb{x}\in\mathbb{R}^{n}$ to set $E$ is defined by  $$d(\mathbb{x},E)=\inf\{||\mathbb{x}-\mathbb{y}||:\mathbb{y}\in E\}.$$ $E^{\circ}$ (respectively,$\overline{E}, \partial{E}$) is the interior (respectively, closure,boundary ) of a set $E$; Vol$(E)$ is the jordan content of $E.$ We have a set $S\subset  \mathbb{R}^{n},$ such that $S=\overline{D}$ for some nonempty，open, connected jordan region $D$ in $\mathbb{R}^{n}.$ For each sufficiently small positive value of $\varepsilon $,let $$D_{\varepsilon}=\{\mathbb{x}\in D:d(\mathbb{x},\partial{D})\geq \varepsilon\}.$$   Whether $\overline{D}_{\varepsilon}$ is a connected Jordan region in $\mathbb{R}^{n}?$ The following is my effort: $$F_{1}=\{\mathbb{x}\in\mathbb{R}^{n}:d(\mathbb{x},\partial{D})\geq \varepsilon\}\text{ is closed},\quad F_{2}=\{\mathbb{x}\in\mathbb{R}^{n}:d(\mathbb{x},\partial{D})>\varepsilon\}\text{ is open}.$$ $$F^{\circ}_{1}=F_{2},D=D^{\circ},D^{\circ}_{\varepsilon}=F_{1}\cap D \Longrightarrow D^{\circ}_{\varepsilon}=(F_{1}\cap D)^{\circ}=F^{\circ}_{1}\cap D^{\circ}=F_{2}\cap D.$$ $$\partial F_{1}=\{\mathbb{x}\in\mathbb{R}^{n}:d(\mathbb{x},\partial{D})= \varepsilon\}.$$ Since $D$ is connected open set,it follows that $D^{\circ}_{\varepsilon}$ is connected open set. $$\overline{D^{\circ}_{\varepsilon}}=\overline{D}_{\varepsilon}=D^{\circ}_{\varepsilon}\cup \partial {D_{\varepsilon}},\quad\partial {D_{\varepsilon}}\subseteq \partial F_{1}\cup \partial{D},\quad\text{Vol}{(\partial{D})}=0.$$ If Vol$(\partial F_{1})=0 $ holds,then Vol$(\partial{D_{\varepsilon}})=0 $  holds. In my opinion ,If we can prove Vol$(\partial F_{1})=0 $,then $\overline{D}_{\varepsilon}$ is a connected Jordan region in $\mathbb{R}^{n}.$ But how can I prove Vol$(\partial F_{1})=0$? $$\overline{B}_{\varepsilon }(\mathbf{p})=\{\mathbf{x}\in\mathbb{R}^{n}:||\mathbf{x}-\mathbf{p}||\leq \varepsilon\} ,\\\overline{B}_{\varepsilon }(\mathbf{p})\cap \partial D=[\partial B_{\varepsilon }(\mathbf{p})\cup B^{\circ}_{\varepsilon }(\mathbf{p})]\cap\partial D=[\partial B_{\varepsilon }(\mathbf{p})\cap\partial D]\cup[ B^{\circ}_{\varepsilon }(\mathbf{p})\cap\partial D],\\ [\partial B_{\varepsilon }(\mathbf{p})\cap\partial D]\cap[ B^{\circ}_{\varepsilon }(\mathbf{p})\cap\partial D]=\emptyset.$$ $\mathbf{A}.$ $$S_{1}=\{\mathbf{p}\in D^{\circ}:\overline{B}_{\varepsilon }(\mathbf{p})\cap \partial D=\emptyset\}=\{\mathbf{p}\in D^{\circ}:d(\mathbf{p},\partial D)> \varepsilon\}=D_{\varepsilon}^{\circ}$$ $\mathbf{B}.$ $$S_{2}=\{\mathbf{p}\in D^{\circ}:\overline{B}_{\varepsilon }(\mathbf{p})\cap \partial D\ne\emptyset\}$$ $\mathbf(1).\partial B_{\varepsilon }(\mathbf{p})\cap\partial D\ne\emptyset\Longrightarrow \mathbf{p}\in \{\mathbf{p}\in D^{\circ}:d(\mathbf{p},\partial D)=\varepsilon\};$ $\mathbf(2).B^{\circ}_{\varepsilon }(\mathbf{p})\cap\partial D\ne\emptyset\Longrightarrow \mathbf{p}\in \{\mathbf{p}\in D^{\circ}:d(\mathbf{p},\partial D)<\varepsilon\}.$ $$\mathbf{A}+\mathbf{B}\Longrightarrow \partial D_{\varepsilon}=\{\mathbf{p}\in D^{\circ}:\partial B_{\varepsilon }(\mathbf{p})\cap\partial D\ne\emptyset \quad \wedge \quad B^{\circ}_{\varepsilon }(\mathbf{p})\cap\partial D=\emptyset \}.$$ Conversely,$\overline{D}_{\varepsilon}$ may not be  a connected Jordan region in $\mathbb{R}^{n}$.But how can I find a counterexample of that? If you have some good ideas about how to solve this question ,please give me some hints.Any help is going to be appreciated!",,"['real-analysis', 'general-topology']"
78,Existence of approximating simple function,Existence of approximating simple function,,"Let $(X,\mathcal F,\mu)$ be measurable space with $\mu(X)<\infty$. $\mathcal F$ is $\sigma$-algebra on X and $\mathcal F$ is generated by algebra $\mathcal F_0$. Prove that for every measurable function $f$ defined on $X$ and $\epsilon>0$, there exists a simple function $f_{\epsilon}=\sum_{k=1}^nc_k 1_{A_k}$ with $A_k\in \mathcal F_0$ such that $\mu\{x: |f(x)-f_{\epsilon}(x)|\geq \epsilon\}<\epsilon$, $c_k$ is constant. I have no idea to proceed the proof. Please give me some hints. Thanks","Let $(X,\mathcal F,\mu)$ be measurable space with $\mu(X)<\infty$. $\mathcal F$ is $\sigma$-algebra on X and $\mathcal F$ is generated by algebra $\mathcal F_0$. Prove that for every measurable function $f$ defined on $X$ and $\epsilon>0$, there exists a simple function $f_{\epsilon}=\sum_{k=1}^nc_k 1_{A_k}$ with $A_k\in \mathcal F_0$ such that $\mu\{x: |f(x)-f_{\epsilon}(x)|\geq \epsilon\}<\epsilon$, $c_k$ is constant. I have no idea to proceed the proof. Please give me some hints. Thanks",,['measure-theory']
79,Multiplication operators on $L^2$,Multiplication operators on,L^2,"Let $X$ be a $\sigma$-finite measure space, and let $g$ a measurable complex-valued function $X$, which lies in $L^\infty(X)$. I would like to determine sufficient and necessary properties for the operator $T:L^2(X)\rightarrow L^2(X)$ by $f\mapsto gf$ to be self-adjoint, an isometry (i.e. inner-product preserving), to be surjective, and to be injective. I feel that it is self-adjoint iff $g$ is real-valued, an isometry iff it takes values in the unit circle, surjective or injective iff it is constant. Is this true?","Let $X$ be a $\sigma$-finite measure space, and let $g$ a measurable complex-valued function $X$, which lies in $L^\infty(X)$. I would like to determine sufficient and necessary properties for the operator $T:L^2(X)\rightarrow L^2(X)$ by $f\mapsto gf$ to be self-adjoint, an isometry (i.e. inner-product preserving), to be surjective, and to be injective. I feel that it is self-adjoint iff $g$ is real-valued, an isometry iff it takes values in the unit circle, surjective or injective iff it is constant. Is this true?",,"['functional-analysis', 'measure-theory', 'lebesgue-integral']"
80,Showing that a Borel Measure $\mu\equiv 0$,Showing that a Borel Measure,\mu\equiv 0,"Problem. Let $\mu$ be a Borel measure on $[0,1]$. Assume that $\mu$ and Lebesgue measure $m$ are mutually singular. $\mu([0,t])$ depends continuously on $t$. $f\in L^{1}(\mu)$ for any function $f:[0,1]\rightarrow\mathbb{R}$, with $f\in L^{1}(m)$. (Note that $f$ has a finite value at every point.) Show that $\mu\equiv 0$. This question was asked before, but it did not receive a full answer--just a commented suggestion on how to proceed. My issue is that I don't see why $\mu=\delta_{0}$ (i.e. the Dirac mass at $x=0$) is not a counterexample to the problem statement. $\delta_{0}$ and Lebesgue measure are mutually singular. $\mu([0,t])\equiv 1$, which is trivially continuous. And for any function $f$ satisfying 3. $\int f\mathrm{d}\mu=f(0)$, which is finite by hypothesis. Am I missing something obvious? I believe I can show that under the hypotheses of the problem, we must have $\mu(\left\{0\right\})=\mu([0,1])$. Indeed, suppose that $\mu(\left\{0\right\})<\mu([0,1])$. Since $\mu$ and $m$ are mutually singular, there exist disjoint measure sets $A,B$ with $A\cup B=[0,1]$, $m(A)=0$, and $\mu(B)=0$. Since $F(t):=\mu([0,t])$ is continuous, the intermediate value theorem (IVT) applies. By repeated application of IVT, we can inductively find an increasing sequence $\left\{t_{n}\right\}$ with $$t_{0}:=0, \quad \alpha_{n+1}:=\mu([0,t_{n+1}])>\alpha_{n}:=\mu([0,t_{n}])$$ Note that it follows from the continuity of $F$ that $\mu(\left\{t\right\})=0$ for any $0<t\leq 1$. In particular, $\mu([t_{n},t_{n+1}))=\alpha_{n+1}-\alpha_{n}$. Now define a Borel measurable function $f:[0,1]\rightarrow\mathbb{R}$ by $$f(s):=\sum_{n=0}^{\infty}\dfrac{1}{\alpha_{n+1}-\alpha_{n}}\chi_{A\cap [t_{n},t_{n+1})}(s)$$ $f\in L^{1}(m)$, since $m(A)=0$, so $f\in L^{1}(\mu)$ by problem assumption. But then for any positive integer $N$, $$\int f(s)\mathrm{d}\mu(s)\geq\sum_{n=0}^{N}\dfrac{1}{\alpha_{n+1}-\alpha_{n}}\mu(A\cap [t_{n},t_{n+1}))=\sum_{n=0}^{N}\dfrac{1}{\alpha_{n+1}-\alpha_{n}}\mu([t_{n},t_{n+1}))=\sum_{n=0}^{N}1=N$$ Whence, we arrive at a contradiction.","Problem. Let $\mu$ be a Borel measure on $[0,1]$. Assume that $\mu$ and Lebesgue measure $m$ are mutually singular. $\mu([0,t])$ depends continuously on $t$. $f\in L^{1}(\mu)$ for any function $f:[0,1]\rightarrow\mathbb{R}$, with $f\in L^{1}(m)$. (Note that $f$ has a finite value at every point.) Show that $\mu\equiv 0$. This question was asked before, but it did not receive a full answer--just a commented suggestion on how to proceed. My issue is that I don't see why $\mu=\delta_{0}$ (i.e. the Dirac mass at $x=0$) is not a counterexample to the problem statement. $\delta_{0}$ and Lebesgue measure are mutually singular. $\mu([0,t])\equiv 1$, which is trivially continuous. And for any function $f$ satisfying 3. $\int f\mathrm{d}\mu=f(0)$, which is finite by hypothesis. Am I missing something obvious? I believe I can show that under the hypotheses of the problem, we must have $\mu(\left\{0\right\})=\mu([0,1])$. Indeed, suppose that $\mu(\left\{0\right\})<\mu([0,1])$. Since $\mu$ and $m$ are mutually singular, there exist disjoint measure sets $A,B$ with $A\cup B=[0,1]$, $m(A)=0$, and $\mu(B)=0$. Since $F(t):=\mu([0,t])$ is continuous, the intermediate value theorem (IVT) applies. By repeated application of IVT, we can inductively find an increasing sequence $\left\{t_{n}\right\}$ with $$t_{0}:=0, \quad \alpha_{n+1}:=\mu([0,t_{n+1}])>\alpha_{n}:=\mu([0,t_{n}])$$ Note that it follows from the continuity of $F$ that $\mu(\left\{t\right\})=0$ for any $0<t\leq 1$. In particular, $\mu([t_{n},t_{n+1}))=\alpha_{n+1}-\alpha_{n}$. Now define a Borel measurable function $f:[0,1]\rightarrow\mathbb{R}$ by $$f(s):=\sum_{n=0}^{\infty}\dfrac{1}{\alpha_{n+1}-\alpha_{n}}\chi_{A\cap [t_{n},t_{n+1})}(s)$$ $f\in L^{1}(m)$, since $m(A)=0$, so $f\in L^{1}(\mu)$ by problem assumption. But then for any positive integer $N$, $$\int f(s)\mathrm{d}\mu(s)\geq\sum_{n=0}^{N}\dfrac{1}{\alpha_{n+1}-\alpha_{n}}\mu(A\cap [t_{n},t_{n+1}))=\sum_{n=0}^{N}\dfrac{1}{\alpha_{n+1}-\alpha_{n}}\mu([t_{n},t_{n+1}))=\sum_{n=0}^{N}1=N$$ Whence, we arrive at a contradiction.",,"['real-analysis', 'measure-theory']"
81,Weak compactness of a set of translates in $C_0(\mathbb{R})$,Weak compactness of a set of translates in,C_0(\mathbb{R}),"Let $f \in C_0(\mathbb{R})$. Consider the set of translates of $f$ $$ A = \{ f_t : t \in \mathbb{R} \}$$  where $f_t(x)=f(x+t), x\in \mathbb{R}$. I want to show that $A$ is relatively compact in the weak topology on $C_0(\mathbb{R})$. I have shown that every sequence in $A$ has a weakly convergent subsequence, using the fact that the dual is the space of Radon measures. If the closed ball in $C_0(\mathbb{R})$ is metrizable in the weak topology (I'm not sure if it is), then my proof is complete.  [The problem is that $C_0(\mathbb{R})$ is not reflexive, and the dual is not separable either] Is there some result on the metrizability of the unit ball in $C_0(\mathbb{R})$?  Or is there some other way to show that $A$ is relatively weak-compact?","Let $f \in C_0(\mathbb{R})$. Consider the set of translates of $f$ $$ A = \{ f_t : t \in \mathbb{R} \}$$  where $f_t(x)=f(x+t), x\in \mathbb{R}$. I want to show that $A$ is relatively compact in the weak topology on $C_0(\mathbb{R})$. I have shown that every sequence in $A$ has a weakly convergent subsequence, using the fact that the dual is the space of Radon measures. If the closed ball in $C_0(\mathbb{R})$ is metrizable in the weak topology (I'm not sure if it is), then my proof is complete.  [The problem is that $C_0(\mathbb{R})$ is not reflexive, and the dual is not separable either] Is there some result on the metrizability of the unit ball in $C_0(\mathbb{R})$?  Or is there some other way to show that $A$ is relatively weak-compact?",,['functional-analysis']
82,Coincidence of two $\tau$-additive measures,Coincidence of two -additive measures,\tau,"I'm struggling to prove the following Lemma from V.I. Bogachev, Measure Theory 2: Let two $\tau$-additive measures $\mu$ and $\nu$ on a topological space $X$ coincide on all sets from some class $\mathcal{U}$ that contains a base $\mathcal{B}$ of the topology $\mathcal{T}$ in $X$ and is closed with respect to finite intersections. Then $\mu=\nu$. Recall that a Borel measure $\mu$ is called $\tau$-additive on a topological space $X$ if for every increasing net of open sets $(O_i)_{i\in I}$ in $X$ one has the equality $$|\mu|\bigg(\bigcup_{i\in I}O_i\bigg)=\lim_{i\in I}|\mu|(O_i)$$ The given proof is a little minimalistic: Every open set $O\in\mathcal{T}$ can be represented in the form of the union of a net of increasing open sets $O_i$ that are finite unions of sets in $\mathcal{U}$. It is easily seen that $\mu(O_i)=\nu(O_i)$ for all $i\in I$. By the $\tau$-additivity we obtain $\mu(O)=\nu(O)$. Since the two measures coincide an all open sets, they coincide on all Borel sets. With some help from Daniel Fischer I've constructed the net of increasing open sets $(O_i)_{i\in I}$ via the directed set $(I,\subseteq)$, where $$I:=\{\mathcal{B}_i\subseteq\mathcal{B}\,|\,\mathcal{B}_i\text{ is finite and }\forall B\in\mathcal{B}_i\,:\,B\subseteq O\}. $$ and $$O_i:=\bigcup_{B\in\mathcal{B}_i}B $$ This yields $O_i\subseteq O_j$ whenever $B_i\subseteq B_j$, $\bigcup_{\mathcal{B}_i\in I}O_i=O$ and every $O_i$ is a finite union of elements of the base $\mathcal{B}$. Now, I have troubles showing $\mu(O_i)=\nu(O_i)$ for all $\mathcal{B}_i\in I$. Also, I don't see where the assumption that $\mathcal{U}$ is closed with respect to finite intersections is needed. Any help would be highly appreciated and thank you very much in advance for your efforts! Greetings","I'm struggling to prove the following Lemma from V.I. Bogachev, Measure Theory 2: Let two $\tau$-additive measures $\mu$ and $\nu$ on a topological space $X$ coincide on all sets from some class $\mathcal{U}$ that contains a base $\mathcal{B}$ of the topology $\mathcal{T}$ in $X$ and is closed with respect to finite intersections. Then $\mu=\nu$. Recall that a Borel measure $\mu$ is called $\tau$-additive on a topological space $X$ if for every increasing net of open sets $(O_i)_{i\in I}$ in $X$ one has the equality $$|\mu|\bigg(\bigcup_{i\in I}O_i\bigg)=\lim_{i\in I}|\mu|(O_i)$$ The given proof is a little minimalistic: Every open set $O\in\mathcal{T}$ can be represented in the form of the union of a net of increasing open sets $O_i$ that are finite unions of sets in $\mathcal{U}$. It is easily seen that $\mu(O_i)=\nu(O_i)$ for all $i\in I$. By the $\tau$-additivity we obtain $\mu(O)=\nu(O)$. Since the two measures coincide an all open sets, they coincide on all Borel sets. With some help from Daniel Fischer I've constructed the net of increasing open sets $(O_i)_{i\in I}$ via the directed set $(I,\subseteq)$, where $$I:=\{\mathcal{B}_i\subseteq\mathcal{B}\,|\,\mathcal{B}_i\text{ is finite and }\forall B\in\mathcal{B}_i\,:\,B\subseteq O\}. $$ and $$O_i:=\bigcup_{B\in\mathcal{B}_i}B $$ This yields $O_i\subseteq O_j$ whenever $B_i\subseteq B_j$, $\bigcup_{\mathcal{B}_i\in I}O_i=O$ and every $O_i$ is a finite union of elements of the base $\mathcal{B}$. Now, I have troubles showing $\mu(O_i)=\nu(O_i)$ for all $\mathcal{B}_i\in I$. Also, I don't see where the assumption that $\mathcal{U}$ is closed with respect to finite intersections is needed. Any help would be highly appreciated and thank you very much in advance for your efforts! Greetings",,"['general-topology', 'measure-theory']"
83,A weaker form of Lebesgue's differentiation theorem in $\Bbb R ^n$,A weaker form of Lebesgue's differentiation theorem in,\Bbb R ^n,"If $f : \Bbb R ^n \to \Bbb C$ is locally-integrable then Lebesgue's differentiation theorem says that $$\lim \limits _{r \to 0} \frac 1 {\lambda \big( B(x, r) \big)} \int \limits _{B(x, r)} f \Bbb d \lambda = f(x) \tag{*}$$ almost everywhere. What happens if I want to study the set of those points $x$ where $\lim \limits _{r \to 0} \frac 1 {\lambda \big( B(x, r) \big)} \int \limits _{B(x, r)} f \Bbb d \lambda$ simply exists, without having to be equal to $f(x)$? Is it equal to the set of the points where $(*)$ holds, or can it be larger? Edit: The above question has been answered below, but I would like to complement it with the following closely related one: are there functions $f$ and points $x$ in which the above limit does not exist? I would like to understand whether in general this limit exists everywhere or only almost everywhere.","If $f : \Bbb R ^n \to \Bbb C$ is locally-integrable then Lebesgue's differentiation theorem says that $$\lim \limits _{r \to 0} \frac 1 {\lambda \big( B(x, r) \big)} \int \limits _{B(x, r)} f \Bbb d \lambda = f(x) \tag{*}$$ almost everywhere. What happens if I want to study the set of those points $x$ where $\lim \limits _{r \to 0} \frac 1 {\lambda \big( B(x, r) \big)} \int \limits _{B(x, r)} f \Bbb d \lambda$ simply exists, without having to be equal to $f(x)$? Is it equal to the set of the points where $(*)$ holds, or can it be larger? Edit: The above question has been answered below, but I would like to complement it with the following closely related one: are there functions $f$ and points $x$ in which the above limit does not exist? I would like to understand whether in general this limit exists everywhere or only almost everywhere.",,"['measure-theory', 'lebesgue-integral', 'lebesgue-measure']"
84,Prove that $\prod_1^{\infty}(1-a_i) > 0$ iff $\sum_1^{\infty}{a_i} < \infty$,Prove that  iff,\prod_1^{\infty}(1-a_i) > 0 \sum_1^{\infty}{a_i} < \infty,"Suppose $\{a_i\}_1^{\infty} \subset (0,1)$ a) $\prod_1^{\infty}(1-a_i) > 0$ iff $\sum_1^{\infty}{a_i} < \infty$ b) Given $\beta \in (0,1)$, exhibit a sequence $\{a_i\}$ such that $\prod_1^{\infty}(1-a_i) = \beta$ This is not my homework, but I'm learning measure theory from Real Analysis of Folland, and I get stuck on this problem. My idea is to prove that $\sum_1^{\infty}{\ln(1-a_i)} > -\infty$ (for sure this sum is smaller than 0). At the first glance, I try to prove that $\ln(1-x) + x > 0$, but finally, the inequality should be reversed. Using maclaurine expansion, I can expand: $$\ln(1-x) = -(x + x^2/2 + x^3/3 +...)$$ So seem like I can't find a function $f(x)$ such that $\ln(1-x) +f(x) > 0$. Can anyone give me some hint to solve this? For the second problem, I got no idea. Thanks so much. I really appreciate!","Suppose $\{a_i\}_1^{\infty} \subset (0,1)$ a) $\prod_1^{\infty}(1-a_i) > 0$ iff $\sum_1^{\infty}{a_i} < \infty$ b) Given $\beta \in (0,1)$, exhibit a sequence $\{a_i\}$ such that $\prod_1^{\infty}(1-a_i) = \beta$ This is not my homework, but I'm learning measure theory from Real Analysis of Folland, and I get stuck on this problem. My idea is to prove that $\sum_1^{\infty}{\ln(1-a_i)} > -\infty$ (for sure this sum is smaller than 0). At the first glance, I try to prove that $\ln(1-x) + x > 0$, but finally, the inequality should be reversed. Using maclaurine expansion, I can expand: $$\ln(1-x) = -(x + x^2/2 + x^3/3 +...)$$ So seem like I can't find a function $f(x)$ such that $\ln(1-x) +f(x) > 0$. Can anyone give me some hint to solve this? For the second problem, I got no idea. Thanks so much. I really appreciate!",,"['real-analysis', 'sequences-and-series', 'measure-theory', 'convergence-divergence']"
85,"Anywhere I integrate $f_n$, the integral approaches $f$. Is $\lim_n f_n = f$ a.e.?","Anywhere I integrate , the integral approaches . Is  a.e.?",f_n f \lim_n f_n = f,"Something tells me this is obvious... I have a bunch of functions: $f,f_n:\mathbb{R}^2\rightarrow \mathbb{R}$, all integrable. Also, $f$ is continuous. I also have a family of sets, $\mathcal{G}$ where $\sigma(\mathcal{G})=\mathcal{B}(\mathbb{R}^2).$ (the Borel sigma-algebra of $\mathbb{R}^2$, perhaps sans some sets of measure 0 wrt Lebesgue) Now the important part: we have that $\int_{S} f_n d\lambda \rightarrow \int_{S} f d\lambda$ for any $S\in \mathcal{G}$. Does $\lim_n f_n = f$ a.e.? Here is my thought: Think of this set: $S:=\{\lim_n f_n \neq f\}.$ What would happen if: $$\lambda(S)>\varepsilon > 0?$$ Then $\lim_n \int_S |f_n-f| = \lim_n \int_S (f_n-f)^+ +\int_S (f_n-f)^- > 0$. But both of these parts must go to 0 by assumption. So we have a contradiction.","Something tells me this is obvious... I have a bunch of functions: $f,f_n:\mathbb{R}^2\rightarrow \mathbb{R}$, all integrable. Also, $f$ is continuous. I also have a family of sets, $\mathcal{G}$ where $\sigma(\mathcal{G})=\mathcal{B}(\mathbb{R}^2).$ (the Borel sigma-algebra of $\mathbb{R}^2$, perhaps sans some sets of measure 0 wrt Lebesgue) Now the important part: we have that $\int_{S} f_n d\lambda \rightarrow \int_{S} f d\lambda$ for any $S\in \mathcal{G}$. Does $\lim_n f_n = f$ a.e.? Here is my thought: Think of this set: $S:=\{\lim_n f_n \neq f\}.$ What would happen if: $$\lambda(S)>\varepsilon > 0?$$ Then $\lim_n \int_S |f_n-f| = \lim_n \int_S (f_n-f)^+ +\int_S (f_n-f)^- > 0$. But both of these parts must go to 0 by assumption. So we have a contradiction.",,"['integration', 'functional-analysis', 'measure-theory', 'proof-verification', 'continuity']"
86,Consensus division of a cake,Consensus division of a cake,,"There is a pie and two people with different tastes. The goal is to cut a piece, using two radial cuts like this: such that both people agree that the piece has a value of exactly a fraction $p$ of the total, where $p\in[0,1]$ is a given constant. Formally, the pie is described as the interval $[0,1]$ whose two endpoints are identified (- a topological circle). There are two non-negative value measures over the interval, $V_A$ and $V_B$. They are absolutely continuous with respect to length (this means that they are non-atomic). Both measures assign the same value to the whole interval: $V_A([0,1])=V_B([0,1])=1$. The goal is to find an interval $[x,y]$ such that $V_A([x,y])=V_B([x,y])=p$. I found a solution for the special case in which the measure $V_A$ is equal to the length measure. Here it is. Hold two knives over the pie, such that the distance between them is exactly $p$. Move the knives a whole round around the pie, always keeping the distance between them at $p$. I claim that there is a point in which $V_B$ of the piece between the knives is exactly $p$. PROOF: At each time $t\in[0,1]$, the piece between the knives is $[t,t+p]$. Mark by $S$, the sum of the values of $V_B$ when the knives make a whole round: $$ S = \int_{t=0}^1 V_B([t,t+p]) dt $$ Since $V_B$ is continuous, it has a derivative $v_b$, such that $V_B([t,t+p])=\int_{x=t}^{t+p} v_b(x)dx$. So: $$ S = \int_{t=0}^1 \int_{x=t}^{t+p} v_b(x)dx dt = \int_{t=0}^1 \int_{x=0}^{p} v_b(t+x)dx dt $$ Substitute the order of integration and get: $$ S = \int_{x=0}^{p} \int_{t=0}^1 v_b(t+x) dt dx = \int_{x=0}^{p} 1 dx = p$$ The integral of $V_B([t,t+p])$ equals $p$ and the functions are continuous, so by the Mean Value Theorem there must be a  $t$ in which $V_B([t,t+p])=p$. $\square$ Is it possible to generalize this argument to arbitrary continuous value measures? EDIT: I just thought of an informal idea. Let $N$ be a large integer. Normalize the value measures such that the value of the entire cake for each person is $N^2$. Divide the cake to $N$ arcs such that, in each arc, $V_A+V_B=2N$. Additionally, round the values of $V_A$ and $V_B$ in each arc to the nearest integers. Now, we have a discrete problem. We can imagine that in each arc, there are $V_A$ Azure balls and $V_B$ Black balls. Move two knives around the cake in the following way. In each step $t$, knife #1 is just before Azure ball $t$, and knife #2 is just before Azure ball $t + p N^2$. Hence the number of Azure balls between the knives is always $p N^2$. Move the knives until the knives return to their original location. At each step, count the number of Black balls between the knives, and sum over the entire round-trip.  Each black ball is counted whenever there are between 1 and $p N^2$ azure balls before it. Hence, it is counted exactly $p N^2$ times. Hence, the sum of the counts over the entire trip is $p N^4$. This is a fraction $p$ of the product of the total number of balls. An interactive illustration is available here: http://tube.geogebra.org/m/1355529 There, $p N^2 = 5$. The green arc is the arc between the knives. You can increase $t$ and see that the green arc always covers exactly 5 azure balls, and each black ball is covered exactly 5 times. When $N$ is sufficiently large, the sum becomes an integral, and by continuity, the integral of the $V_B$ is $p$. Hence, by the Mean Value Theorem, there is a point in the trip in which $V_B=p$. Can this idea be made formal?","There is a pie and two people with different tastes. The goal is to cut a piece, using two radial cuts like this: such that both people agree that the piece has a value of exactly a fraction $p$ of the total, where $p\in[0,1]$ is a given constant. Formally, the pie is described as the interval $[0,1]$ whose two endpoints are identified (- a topological circle). There are two non-negative value measures over the interval, $V_A$ and $V_B$. They are absolutely continuous with respect to length (this means that they are non-atomic). Both measures assign the same value to the whole interval: $V_A([0,1])=V_B([0,1])=1$. The goal is to find an interval $[x,y]$ such that $V_A([x,y])=V_B([x,y])=p$. I found a solution for the special case in which the measure $V_A$ is equal to the length measure. Here it is. Hold two knives over the pie, such that the distance between them is exactly $p$. Move the knives a whole round around the pie, always keeping the distance between them at $p$. I claim that there is a point in which $V_B$ of the piece between the knives is exactly $p$. PROOF: At each time $t\in[0,1]$, the piece between the knives is $[t,t+p]$. Mark by $S$, the sum of the values of $V_B$ when the knives make a whole round: $$ S = \int_{t=0}^1 V_B([t,t+p]) dt $$ Since $V_B$ is continuous, it has a derivative $v_b$, such that $V_B([t,t+p])=\int_{x=t}^{t+p} v_b(x)dx$. So: $$ S = \int_{t=0}^1 \int_{x=t}^{t+p} v_b(x)dx dt = \int_{t=0}^1 \int_{x=0}^{p} v_b(t+x)dx dt $$ Substitute the order of integration and get: $$ S = \int_{x=0}^{p} \int_{t=0}^1 v_b(t+x) dt dx = \int_{x=0}^{p} 1 dx = p$$ The integral of $V_B([t,t+p])$ equals $p$ and the functions are continuous, so by the Mean Value Theorem there must be a  $t$ in which $V_B([t,t+p])=p$. $\square$ Is it possible to generalize this argument to arbitrary continuous value measures? EDIT: I just thought of an informal idea. Let $N$ be a large integer. Normalize the value measures such that the value of the entire cake for each person is $N^2$. Divide the cake to $N$ arcs such that, in each arc, $V_A+V_B=2N$. Additionally, round the values of $V_A$ and $V_B$ in each arc to the nearest integers. Now, we have a discrete problem. We can imagine that in each arc, there are $V_A$ Azure balls and $V_B$ Black balls. Move two knives around the cake in the following way. In each step $t$, knife #1 is just before Azure ball $t$, and knife #2 is just before Azure ball $t + p N^2$. Hence the number of Azure balls between the knives is always $p N^2$. Move the knives until the knives return to their original location. At each step, count the number of Black balls between the knives, and sum over the entire round-trip.  Each black ball is counted whenever there are between 1 and $p N^2$ azure balls before it. Hence, it is counted exactly $p N^2$ times. Hence, the sum of the counts over the entire trip is $p N^4$. This is a fraction $p$ of the product of the total number of balls. An interactive illustration is available here: http://tube.geogebra.org/m/1355529 There, $p N^2 = 5$. The green arc is the arc between the knives. You can increase $t$ and see that the green arc always covers exactly 5 azure balls, and each black ball is covered exactly 5 times. When $N$ is sufficiently large, the sum becomes an integral, and by continuity, the integral of the $V_B$ is $p$. Hence, by the Mean Value Theorem, there is a point in the trip in which $V_B=p$. Can this idea be made formal?",,"['real-analysis', 'measure-theory', 'fair-division']"
87,Lower Bound of Hausdorff Dimension of Cantor Set,Lower Bound of Hausdorff Dimension of Cantor Set,,"Consider a Cantor set $E$ where the intervals at every level of the construction maintain a minimum spacing and have a finite number of intervals on each level. I have two questions regarding finding the lower bound of the Hausdorff dimension on such a set. Assume we have a collection of sets $\{U_i\}$ such that $|U|<\epsilon$ and the union of these sets provide a cover of $C$. $\mathcal{H}^s(E)$ is the Hausdorff $s$-dimensional measure. 1) The mass distribution principle that says if we have a mass distribution on $E$ and $\mu(U)<c|U|^s$ then we can claim that $\mathcal{H}^s(E)>0$, and hence claim $s$ is a lower estimate on Hdim$E$. Is it possible to apply this method when the intervals from a given level have varying lengths? If yes, how do we assign masses to the intervals? If this method does not apply here, what other methods are there for this class of sets? 2) I attended a talk where professor claimed that when establishing a lower estimate on Hdim of a Cantor set it is sufficient to show that we can find a special collection of intervals in our construction such that $\sum|I_k|<c|U|^s$ for an arbitrary $U$.  Can anyone help me connect the dots between this claim and $\mathcal{H}(E)^s>0$?","Consider a Cantor set $E$ where the intervals at every level of the construction maintain a minimum spacing and have a finite number of intervals on each level. I have two questions regarding finding the lower bound of the Hausdorff dimension on such a set. Assume we have a collection of sets $\{U_i\}$ such that $|U|<\epsilon$ and the union of these sets provide a cover of $C$. $\mathcal{H}^s(E)$ is the Hausdorff $s$-dimensional measure. 1) The mass distribution principle that says if we have a mass distribution on $E$ and $\mu(U)<c|U|^s$ then we can claim that $\mathcal{H}^s(E)>0$, and hence claim $s$ is a lower estimate on Hdim$E$. Is it possible to apply this method when the intervals from a given level have varying lengths? If yes, how do we assign masses to the intervals? If this method does not apply here, what other methods are there for this class of sets? 2) I attended a talk where professor claimed that when establishing a lower estimate on Hdim of a Cantor set it is sufficient to show that we can find a special collection of intervals in our construction such that $\sum|I_k|<c|U|^s$ for an arbitrary $U$.  Can anyone help me connect the dots between this claim and $\mathcal{H}(E)^s>0$?",,"['measure-theory', 'fractals', 'dimension-theory-analysis']"
88,If $f(x) \le f(Tx)$ then $f(x)=f(Tx)$ almost everywhere ( $T$ is $\mu$-invariant ),If  then  almost everywhere (  is -invariant ),f(x) \le f(Tx) f(x)=f(Tx) T \mu,"Let $X$ be a probability space with probability $\mu$. Let $T:X\to X$ be a measurable and $\mu$-invariant transformation, i.e $\mu \left(T^{-1}A \right) =\mu A. $ for each measurable subset $A\subset X$. Let $f:X \to \mathbb R$ be a measurable and integrable function such that $f(x) \le f(Tx)$ for all $x\in X$. Prove that $f(x)$ and $f(Tx)$ are equal almost everywhere. This is what I did: For each $\alpha \in \mathbb R$ let $A_{\alpha}= \{x\in X : f(x) \le \alpha    \}$. Note that $T^{-1} A_{\alpha} \subset A_{\alpha}$. The $T$-invariance of $\mu$ implies that $\mu \left( A_{\alpha} \setminus T^{-1}A_{\alpha}  \right) = 0$. I want to show that the set $E=\{x\in X : f(x) < f(Tx)  \}$ has measure $0$. I wan't to write this set using the sets $A_{\alpha}$ and maybe a countable union of this sets but I don't know if it's possible. Please help =(","Let $X$ be a probability space with probability $\mu$. Let $T:X\to X$ be a measurable and $\mu$-invariant transformation, i.e $\mu \left(T^{-1}A \right) =\mu A. $ for each measurable subset $A\subset X$. Let $f:X \to \mathbb R$ be a measurable and integrable function such that $f(x) \le f(Tx)$ for all $x\in X$. Prove that $f(x)$ and $f(Tx)$ are equal almost everywhere. This is what I did: For each $\alpha \in \mathbb R$ let $A_{\alpha}= \{x\in X : f(x) \le \alpha    \}$. Note that $T^{-1} A_{\alpha} \subset A_{\alpha}$. The $T$-invariance of $\mu$ implies that $\mu \left( A_{\alpha} \setminus T^{-1}A_{\alpha}  \right) = 0$. I want to show that the set $E=\{x\in X : f(x) < f(Tx)  \}$ has measure $0$. I wan't to write this set using the sets $A_{\alpha}$ and maybe a countable union of this sets but I don't know if it's possible. Please help =(",,"['measure-theory', 'dynamical-systems', 'ergodic-theory']"
89,Convergence for every measurable set,Convergence for every measurable set,,Let $(f_n)$ non-negative measurable functions such that $f_n\to f$ and $\int f_n\to \int f<\infty$. We have to prove that $\int_E f_n\to \int_Ef$ for each $E$ measurable. I know that if $f_n\to f$ then $f_n\cdot \chi_E\to f\cdot \chi_E$. Maybe we can use that in order to prove $\int f_n\cdot\chi _E\to\int f\cdot\chi_E$. Could you give me any hint to do this? Thanks.,Let $(f_n)$ non-negative measurable functions such that $f_n\to f$ and $\int f_n\to \int f<\infty$. We have to prove that $\int_E f_n\to \int_Ef$ for each $E$ measurable. I know that if $f_n\to f$ then $f_n\cdot \chi_E\to f\cdot \chi_E$. Maybe we can use that in order to prove $\int f_n\cdot\chi _E\to\int f\cdot\chi_E$. Could you give me any hint to do this? Thanks.,,"['real-analysis', 'measure-theory']"
90,integral over a subset of interval in $\mathbb{R}$,integral over a subset of interval in,\mathbb{R},"Consider a finite interval  $[0,d]$, where $d$ is a positive real number. Let $K$ be a measurable subset of $[0,d]$ Then, how can I prove or disprove that $\int_Kx \,dx \geq \int^{m(K)}_0 x\,dx$, where $m(\cdot)$ denotes the Lebesgue measure?","Consider a finite interval  $[0,d]$, where $d$ is a positive real number. Let $K$ be a measurable subset of $[0,d]$ Then, how can I prove or disprove that $\int_Kx \,dx \geq \int^{m(K)}_0 x\,dx$, where $m(\cdot)$ denotes the Lebesgue measure?",,"['measure-theory', 'lebesgue-integral']"
91,Lebesgue measures defined on subspaces of $\Bbb R^n$,Lebesgue measures defined on subspaces of,\Bbb R^n,"For any subspace $V$ of $\Bbb R^n$, we have a special measure $\lambda_V$ which can be described in various ways: Haar measure on $V$, or the measure induced by the metric $V$ inherits from $\Bbb R^n$, or ""$k$-dimensional Lebesgue measure on $V$"" when $\dim V=k$. I want to be better able to calculate with this measure. For example, I might have linearly independent vectors $v_1,v_2\in \Bbb R^n$ and $V={}$span$\langle v_1,v_2 \rangle$. Suppose I have an integral of the form $$ \int_{\Bbb R} \int_{\Bbb R} F(tv_1+uv_2) g_1(t) g_2(u) \,du \,dt, $$ where $F\colon \Bbb R^n\to\Bbb R$ and $g_1,g_2\colon \Bbb R\to\Bbb R$. Can I say that this integral is equal to $$ \int_V F(v) h_1(v) h_2(v) \,d\lambda_V, $$ for some functions $h_1,h_2\colon V\to\Bbb R$? Perhaps each $h_j$ is $g_j$ composed with some canonical projection from $V$ onto the vectors it's made from. (And perhaps there needs to be some global constant corresponding to the determinant of something involving $\{v_1,v_2\}$.) I emphasize that I'm looking for a way to rigorously establish the connection between those two integrals; my formal ability with these Lebesgue measures on subspaces lags behind my intuition. Bonus points for an explanation that includes a reference to where these Lebesgue measures on subspaces are concretely defined and discussed. (This related question discusses a special case of the measure $\lambda_V$, but no answer was provided.)","For any subspace $V$ of $\Bbb R^n$, we have a special measure $\lambda_V$ which can be described in various ways: Haar measure on $V$, or the measure induced by the metric $V$ inherits from $\Bbb R^n$, or ""$k$-dimensional Lebesgue measure on $V$"" when $\dim V=k$. I want to be better able to calculate with this measure. For example, I might have linearly independent vectors $v_1,v_2\in \Bbb R^n$ and $V={}$span$\langle v_1,v_2 \rangle$. Suppose I have an integral of the form $$ \int_{\Bbb R} \int_{\Bbb R} F(tv_1+uv_2) g_1(t) g_2(u) \,du \,dt, $$ where $F\colon \Bbb R^n\to\Bbb R$ and $g_1,g_2\colon \Bbb R\to\Bbb R$. Can I say that this integral is equal to $$ \int_V F(v) h_1(v) h_2(v) \,d\lambda_V, $$ for some functions $h_1,h_2\colon V\to\Bbb R$? Perhaps each $h_j$ is $g_j$ composed with some canonical projection from $V$ onto the vectors it's made from. (And perhaps there needs to be some global constant corresponding to the determinant of something involving $\{v_1,v_2\}$.) I emphasize that I'm looking for a way to rigorously establish the connection between those two integrals; my formal ability with these Lebesgue measures on subspaces lags behind my intuition. Bonus points for an explanation that includes a reference to where these Lebesgue measures on subspaces are concretely defined and discussed. (This related question discusses a special case of the measure $\lambda_V$, but no answer was provided.)",,"['measure-theory', 'reference-request', 'lebesgue-measure']"
92,"Integrable function $f$ on $(\mathbb N, \mathcal P(\mathbb N),\mu)$ and series",Integrable function  on  and series,"f (\mathbb N, \mathcal P(\mathbb N),\mu)","Problem Let $(\mathbb N, \mathcal P(\mathbb N),\mu)$ where $\mu(A)=card(A)$. Show that $f \in L^1(\mathbb N,\mu)$ if and only if $\sum_{n=1}^{\infty} |f(n)|<\infty$, in which case $\int_X f d\mu=\sum_{k=1}^{\infty}f(k)$. I am stuck on one implication. Suppose $\sum_{n=1}^{\infty} |f(n)|<\infty$. If $A_n=\{n\}$, then $f=\sum_{n=1}^{\infty}f(n)\mathcal X_{A_n}$. If I define $g_n=\sum_{k=1}^nf_k\mathcal X_{A_k}$ then $\lim_n g_n=f$. I call $h=\sum_{n=1}^{\infty} |f(n)| \mathcal X_{A_n}$, then $$\int_X hd\mu=\sum_{n \geq 1}\int_X |f(n)| \mathcal X_{A_n}d\mu$$$$=\sum_{n \geq 1}|f(n)|\int_X \mathcal X_{A_n} d\mu$$$$=\sum_{n \geq 1}|f(n)|\mu(A_n)=\sum_{n \geq 1} |f(n)|<\infty$$ Note that $|g_n| \leq h \in L_1(\mathbb N, \mu)$ for all $n$, so $|f| \leq |h|$, which implies $f$ is integrable. By the dominated convergence theorem $$\int_X f d\mu=\lim_n \int_X \sum_{k=1}^n f(k)\mathcal X_{A_k}d\mu$$$$=\sum_{k\geq 1} f(k)\int_X \mathcal X_{A_k}d\mu$$$$=\sum_{k=1}^{\infty}f(k)$$ I don't know what to do to prove the other implication, if $g_n=\sum_{k=1}^n |f(k)| \mathcal X_{A_k}$, where $A_k$ is the set I've already defined, then $g_n \nearrow g=\sum_{n=1}^{\infty} |f(k)|X_{A_k}$, so by the monotone convergence theorem, $$\sum_{k=1}^{\infty}|f(k)|=\int_X g d\mu$$$$=\lim_n \int_X g_nd\mu$$ I would like to affirm $\lim_n \int_X g_nd\mu<\infty$, I would appreciate suggestions to prove this.","Problem Let $(\mathbb N, \mathcal P(\mathbb N),\mu)$ where $\mu(A)=card(A)$. Show that $f \in L^1(\mathbb N,\mu)$ if and only if $\sum_{n=1}^{\infty} |f(n)|<\infty$, in which case $\int_X f d\mu=\sum_{k=1}^{\infty}f(k)$. I am stuck on one implication. Suppose $\sum_{n=1}^{\infty} |f(n)|<\infty$. If $A_n=\{n\}$, then $f=\sum_{n=1}^{\infty}f(n)\mathcal X_{A_n}$. If I define $g_n=\sum_{k=1}^nf_k\mathcal X_{A_k}$ then $\lim_n g_n=f$. I call $h=\sum_{n=1}^{\infty} |f(n)| \mathcal X_{A_n}$, then $$\int_X hd\mu=\sum_{n \geq 1}\int_X |f(n)| \mathcal X_{A_n}d\mu$$$$=\sum_{n \geq 1}|f(n)|\int_X \mathcal X_{A_n} d\mu$$$$=\sum_{n \geq 1}|f(n)|\mu(A_n)=\sum_{n \geq 1} |f(n)|<\infty$$ Note that $|g_n| \leq h \in L_1(\mathbb N, \mu)$ for all $n$, so $|f| \leq |h|$, which implies $f$ is integrable. By the dominated convergence theorem $$\int_X f d\mu=\lim_n \int_X \sum_{k=1}^n f(k)\mathcal X_{A_k}d\mu$$$$=\sum_{k\geq 1} f(k)\int_X \mathcal X_{A_k}d\mu$$$$=\sum_{k=1}^{\infty}f(k)$$ I don't know what to do to prove the other implication, if $g_n=\sum_{k=1}^n |f(k)| \mathcal X_{A_k}$, where $A_k$ is the set I've already defined, then $g_n \nearrow g=\sum_{n=1}^{\infty} |f(k)|X_{A_k}$, so by the monotone convergence theorem, $$\sum_{k=1}^{\infty}|f(k)|=\int_X g d\mu$$$$=\lim_n \int_X g_nd\mu$$ I would like to affirm $\lim_n \int_X g_nd\mu<\infty$, I would appreciate suggestions to prove this.",,"['real-analysis', 'sequences-and-series', 'measure-theory']"
93,Application of Egorov's theorem,Application of Egorov's theorem,,"Problem Let $(E,\Sigma, \mu)$ be a $\sigma$-finite measurable space (i.e., $E=\bigcup_{k \in \mathbb N} A_k$ where $\mu(A_k) < \infty$ for each $k$). Let $(f_n)_{n \geq 1},f:E \to \overline{R}$ be a sequence of measurable, a.e. finite functions such that $f_n \to f$ a.e. on $E$. Show that there exists a sequence $(E_i)_{i \geq 1}$ of measurable sets on $E$ such that $$\mu(E \setminus \bigcup_{i \geq 1} E_i)=0, f_n \rightrightarrows f \space \text{on} \space E_i \space \text{for each i}$$ I've tried to show this result but I got stuck at one part, I'll write what I could do: In each $A_k$ I can apply Egorov's theorem, so for each $j \in \mathbb N$, there exists $B_{k,j}$ measurable subset of $A_k$ with $\mu(A_k \setminus B_{k,j})<\dfrac{1}{j}$ and $f_n \rightrightarrows f$ on $B_{k,j}$. Then $(B_{k,j})_{j}$ is a sequence of measurable subsets of $A_k$ with $$\mu(A_k \setminus \bigcup_{j \geq 1} B_{k,j})<\mu(A_k\setminus B_{k,j})<\dfrac{1}{j} \space \text{for each} j \in \mathbb N$$ But then $\mu(A_k \setminus \bigcup_{j \geq 1} B_{k,j})=0$ and $f_n$ converges uniformly to $f$ on each $B_{k,j}$. I defined $E_k=\bigcup_{j \geq 1} B_k,j$, then $$\mu(E \setminus \bigcup_{k \geq 1} E_k) \leq \mu(\bigcup_{k \geq 1} (A_k \setminus E_k)) \leq \sum_{k \geq 1} \mu(A_k \setminus E_k)=0$$ The problem here is that I cannot affirm $f_n \rightrightarrows f$ on $E_k$. Any suggestions to complete the solution would be greatly appreciated.","Problem Let $(E,\Sigma, \mu)$ be a $\sigma$-finite measurable space (i.e., $E=\bigcup_{k \in \mathbb N} A_k$ where $\mu(A_k) < \infty$ for each $k$). Let $(f_n)_{n \geq 1},f:E \to \overline{R}$ be a sequence of measurable, a.e. finite functions such that $f_n \to f$ a.e. on $E$. Show that there exists a sequence $(E_i)_{i \geq 1}$ of measurable sets on $E$ such that $$\mu(E \setminus \bigcup_{i \geq 1} E_i)=0, f_n \rightrightarrows f \space \text{on} \space E_i \space \text{for each i}$$ I've tried to show this result but I got stuck at one part, I'll write what I could do: In each $A_k$ I can apply Egorov's theorem, so for each $j \in \mathbb N$, there exists $B_{k,j}$ measurable subset of $A_k$ with $\mu(A_k \setminus B_{k,j})<\dfrac{1}{j}$ and $f_n \rightrightarrows f$ on $B_{k,j}$. Then $(B_{k,j})_{j}$ is a sequence of measurable subsets of $A_k$ with $$\mu(A_k \setminus \bigcup_{j \geq 1} B_{k,j})<\mu(A_k\setminus B_{k,j})<\dfrac{1}{j} \space \text{for each} j \in \mathbb N$$ But then $\mu(A_k \setminus \bigcup_{j \geq 1} B_{k,j})=0$ and $f_n$ converges uniformly to $f$ on each $B_{k,j}$. I defined $E_k=\bigcup_{j \geq 1} B_k,j$, then $$\mu(E \setminus \bigcup_{k \geq 1} E_k) \leq \mu(\bigcup_{k \geq 1} (A_k \setminus E_k)) \leq \sum_{k \geq 1} \mu(A_k \setminus E_k)=0$$ The problem here is that I cannot affirm $f_n \rightrightarrows f$ on $E_k$. Any suggestions to complete the solution would be greatly appreciated.",,"['real-analysis', 'measure-theory']"
94,"Measure space $(X,\mathcal{F},\mu)$ where $L^p(X,\mathcal{F},\mu) \neq L^q(X,\mathcal{F},\mu)$ if $p\neq q$",Measure space  where  if,"(X,\mathcal{F},\mu) L^p(X,\mathcal{F},\mu) \neq L^q(X,\mathcal{F},\mu) p\neq q","I was trying to solve this problem: Let $(X,\mathcal{F},\mu)$ be a measure space  where $L^p(X,\mathcal{F},\mu) \neq L^q(X,\mathcal{F},\mu)$ when $p\neq q$. Prove that there exist a sequence of sets  $(A_i)_{i \in \mathbb{N}} \subseteq \mathcal{F}$ such that $\mu(A_i)>0$ and $A_i \cap A_j = \emptyset$ when $i \neq j$. Any help will be appreciated.","I was trying to solve this problem: Let $(X,\mathcal{F},\mu)$ be a measure space  where $L^p(X,\mathcal{F},\mu) \neq L^q(X,\mathcal{F},\mu)$ when $p\neq q$. Prove that there exist a sequence of sets  $(A_i)_{i \in \mathbb{N}} \subseteq \mathcal{F}$ such that $\mu(A_i)>0$ and $A_i \cap A_j = \emptyset$ when $i \neq j$. Any help will be appreciated.",,['measure-theory']
95,If iterated integral is zero then function is zero,If iterated integral is zero then function is zero,,"We are in Measure & Integration class and were assigned this problem from a chapter on Product Measure & Fubini Theorem: Let $f$ be a real-valued function, integrable with regards to 2-dimensional Lebesgue measure on $[0, 1]^2$, and also for all $a, b \in [0, 1]$ it is further given that    $$\int_0^a \int_0^b f(x.y)\ dy \ dx = 0.$$   Show that $f = 0 $ almost everywhere. To me, the problem ""looks"" intuitive because if $f \neq 0,$ then in the first step the $\int_0^b f(x, y) \ dy \neq 0$ and in the second step $\int_0^a \int_0^b f(x.y)\ dy \ dx \neq 0$, contradicting the given hypothesis. But I do not know to write it down mathematically. Please help and thank you.","We are in Measure & Integration class and were assigned this problem from a chapter on Product Measure & Fubini Theorem: Let $f$ be a real-valued function, integrable with regards to 2-dimensional Lebesgue measure on $[0, 1]^2$, and also for all $a, b \in [0, 1]$ it is further given that    $$\int_0^a \int_0^b f(x.y)\ dy \ dx = 0.$$   Show that $f = 0 $ almost everywhere. To me, the problem ""looks"" intuitive because if $f \neq 0,$ then in the first step the $\int_0^b f(x, y) \ dy \neq 0$ and in the second step $\int_0^a \int_0^b f(x.y)\ dy \ dx \neq 0$, contradicting the given hypothesis. But I do not know to write it down mathematically. Please help and thank you.",,"['measure-theory', 'lebesgue-measure']"
96,A basic question regarding Lebesgue's density theorem,A basic question regarding Lebesgue's density theorem,,"Here is the question from Pugh's Real Mathematical Analysis: My answer to $b)$ is that for a closed square, points on corner has density $1/4$, while on the sides the density is $1/2$. But how to understand that ""almost every point has density 1"" by Lebesgue's density theorem? Is it because side of a square in $R^2$ has lower dimension and thus has zero measure (i.e. line in a plane has zero measure)? For $c)$, I want to use set of natural numbers (denote as $N$), which has measure $0$. So $m(B \cap N)=0$, while $mB$ is the length of interval. So  this imply that density of any natural number is $0$? I find a little bit confused because the denominator (length of interval) also tends to $0$. Still can someone show the density of points in the cantor set? By Lebesgue's density theorem, almost every point should have density of 1, but how to compute that, and are there points in cantor set with other values of density? What's more, the textbook does not require the ball $B$ to be centered at $x$, while many other materials require the ball to be centered at $x$ (and if B's centre is x, the textbook calls such density the balanced density as the picture shows). So what's the difference between those 2 versions of ""density""? Are they eventually the same definition? It is confused to compare limits where one come from balls centred at a point (balanced density), while others only require ball contain a point (density in this textbook). Thanks!","Here is the question from Pugh's Real Mathematical Analysis: My answer to $b)$ is that for a closed square, points on corner has density $1/4$, while on the sides the density is $1/2$. But how to understand that ""almost every point has density 1"" by Lebesgue's density theorem? Is it because side of a square in $R^2$ has lower dimension and thus has zero measure (i.e. line in a plane has zero measure)? For $c)$, I want to use set of natural numbers (denote as $N$), which has measure $0$. So $m(B \cap N)=0$, while $mB$ is the length of interval. So  this imply that density of any natural number is $0$? I find a little bit confused because the denominator (length of interval) also tends to $0$. Still can someone show the density of points in the cantor set? By Lebesgue's density theorem, almost every point should have density of 1, but how to compute that, and are there points in cantor set with other values of density? What's more, the textbook does not require the ball $B$ to be centered at $x$, while many other materials require the ball to be centered at $x$ (and if B's centre is x, the textbook calls such density the balanced density as the picture shows). So what's the difference between those 2 versions of ""density""? Are they eventually the same definition? It is confused to compare limits where one come from balls centred at a point (balanced density), while others only require ball contain a point (density in this textbook). Thanks!",,"['measure-theory', 'proof-verification', 'lebesgue-measure']"
97,Comparing limits of integrals,Comparing limits of integrals,,"If $$f_n:X\rightarrow [0,\infty]$$ is a sequence of measurable functions and we know that $$\lim_{n\rightarrow \infty }\int_X f_n \,d\mu=0,\qquad \qquad \tag{$\star$}$$ then can we conclude that for any measurable set $Y\subset X$ we have $$\lim_{n\rightarrow \infty }\int_Y f_n \,d\mu=0$$ because $0\leq\int_Y f_n \,d\mu\leq\int_X f_n \,d\mu$? Also, does the limit $(\star)$ imply that $\lim_{n\rightarrow \infty}f_n(x)=0$ almost everywhere?","If $$f_n:X\rightarrow [0,\infty]$$ is a sequence of measurable functions and we know that $$\lim_{n\rightarrow \infty }\int_X f_n \,d\mu=0,\qquad \qquad \tag{$\star$}$$ then can we conclude that for any measurable set $Y\subset X$ we have $$\lim_{n\rightarrow \infty }\int_Y f_n \,d\mu=0$$ because $0\leq\int_Y f_n \,d\mu\leq\int_X f_n \,d\mu$? Also, does the limit $(\star)$ imply that $\lim_{n\rightarrow \infty}f_n(x)=0$ almost everywhere?",,"['real-analysis', 'measure-theory', 'lebesgue-integral']"
98,Product $\sigma$-algebra on $\mathbb R^{\mathbb N}$,Product -algebra on,\sigma \mathbb R^{\mathbb N},"Let $\mathbb R^{\mathbb N}=\mathbb R\times\mathbb R\times\ldots$ be the space of all real sequences and endow it with product topology. Is the product $\sigma$-algebra generated by Borel subsets of $\mathbb R$ the same as the Borel $\sigma$-algebra generated by the product topology: $$\mathscr B(\mathbb R)\otimes\mathscr B(\mathbb R)\otimes\ldots=\mathscr B(\mathbb R\times\mathbb R\times\ldots)?$$ More generally, it is true if $\mathbb R$ is replaced by a second-countable topological space? If not, does at least $\subset$ or $\supset$ hold? What about uncountable products? It is quite well-known that the claim is true for finitely many products (even for general second-countable topological space), but I can't seem to find a proof or disproof for the (un)countably infinite case. Any input is appreciated.","Let $\mathbb R^{\mathbb N}=\mathbb R\times\mathbb R\times\ldots$ be the space of all real sequences and endow it with product topology. Is the product $\sigma$-algebra generated by Borel subsets of $\mathbb R$ the same as the Borel $\sigma$-algebra generated by the product topology: $$\mathscr B(\mathbb R)\otimes\mathscr B(\mathbb R)\otimes\ldots=\mathscr B(\mathbb R\times\mathbb R\times\ldots)?$$ More generally, it is true if $\mathbb R$ is replaced by a second-countable topological space? If not, does at least $\subset$ or $\supset$ hold? What about uncountable products? It is quite well-known that the claim is true for finitely many products (even for general second-countable topological space), but I can't seem to find a proof or disproof for the (un)countably infinite case. Any input is appreciated.",,"['general-topology', 'measure-theory']"
99,Measurable sets vs. unions of intervals.,Measurable sets vs. unions of intervals.,,"Let $E\subset\mathbb{R}$ be a Lebesgue measurable set.  Is it true that there exists a set $A$ which is a countable union of intervals such that  $\mu(E\Delta A) = 0$, where $\mu$ is the Lebesgue measure on $\mathbb{R}$ and $\Delta$ denotes the symmetric difference? If not, can you provide a counter example? What I do know is that $\mu$ is Borel-regular, which means there is a Borel set $B$ with $E\subset B$ and $\mu(B\setminus E) = 0$.  But the condition on $A$ (which is a countable union of intervals) is much stronger than the condition on $B$ (which is Borel).","Let $E\subset\mathbb{R}$ be a Lebesgue measurable set.  Is it true that there exists a set $A$ which is a countable union of intervals such that  $\mu(E\Delta A) = 0$, where $\mu$ is the Lebesgue measure on $\mathbb{R}$ and $\Delta$ denotes the symmetric difference? If not, can you provide a counter example? What I do know is that $\mu$ is Borel-regular, which means there is a Borel set $B$ with $E\subset B$ and $\mu(B\setminus E) = 0$.  But the condition on $A$ (which is a countable union of intervals) is much stronger than the condition on $B$ (which is Borel).",,"['measure-theory', 'lebesgue-measure']"
