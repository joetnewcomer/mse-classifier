,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Why is every conformal bijection between disks a linear fractional transformation?,Why is every conformal bijection between disks a linear fractional transformation?,,"Why is every conformal bijection between disks actually a linear fractional transformation? I thought I could justify this claim with the following idea. Suppose $f$ is a conformal bijection from a disk $A$ to a disk $B$. Let $z_0\in A$ be arbitrary. Now there is a LFT $g$ from the unit disk to $A$ mapping 0 to $z_0$. Also, there is a LFT $h$ from the unit disk to $B$ mapping $0$ to $f(z_0)$. So altogether, $F=h^{-1}\circ f\circ g$ is a bijection on the unit disk fixing $0$, so by Schwarz' lemma, $|F(z)|\leq |z|$. Since $F^{-1}$ shares the same property, we have $\vert F^{-1}(F(z))\vert=|z|\leq |F(z)|$, so $|F(z)|=|z|$, so by Schwarz' lemma, $F(z)=cz$ for some $c$. So $F$ is a LFT, and thus $f$ is as well. Is this valid? I was surprised to conclude $|F(z)|=|z|$ for all $z$, I wasn't expecting to find $F$ to be an isometry. Thanks all.","Why is every conformal bijection between disks actually a linear fractional transformation? I thought I could justify this claim with the following idea. Suppose $f$ is a conformal bijection from a disk $A$ to a disk $B$. Let $z_0\in A$ be arbitrary. Now there is a LFT $g$ from the unit disk to $A$ mapping 0 to $z_0$. Also, there is a LFT $h$ from the unit disk to $B$ mapping $0$ to $f(z_0)$. So altogether, $F=h^{-1}\circ f\circ g$ is a bijection on the unit disk fixing $0$, so by Schwarz' lemma, $|F(z)|\leq |z|$. Since $F^{-1}$ shares the same property, we have $\vert F^{-1}(F(z))\vert=|z|\leq |F(z)|$, so $|F(z)|=|z|$, so by Schwarz' lemma, $F(z)=cz$ for some $c$. So $F$ is a LFT, and thus $f$ is as well. Is this valid? I was surprised to conclude $|F(z)|=|z|$ for all $z$, I wasn't expecting to find $F$ to be an isometry. Thanks all.",,"['complex-analysis', 'conformal-geometry']"
1,Bounded spherical derivative implies finite order,Bounded spherical derivative implies finite order,,"Let $f$ be an entire function. The Spherical Derivative $\rho(f)$ is defined by $$\rho(f)(z):= \frac{|f'(z)|}{1+|f(z)|^2}.$$ A result from Clunie and Hayman states that if $\rho(f)$ is bounded, then $f$ is of exponential type. The proof uses the machinery of Nevanlinna's theory of value distribution. My question is the following : Is there an ""elementary"" proof that if $\rho(f)$ is bounded, then $f$ is of finite order ? (Note that this is a weaker result, since I'm only asking for finite order here). Finite order means that there exists constants $K$ and $\alpha$ such that $$|f(z)| \leq Ke^{|z|^\alpha}$$ for all $z$. Motivation : Motivation : I'm interested in this because it would lead to a quick proof of Picard's little theorem. Indeed, if there exists a non-constant entire function which omits $0$ and $1$, then it is possible to obtain (using normal families techniques) a non-constant entire function $f$ which omits $0$ and $1$ and that has bounded spherical derivative. Write $f=e^g$ for some entire function $g$. Since $f$ is of finite order, $g$ is a polynomial. But f does not take the value $1$, so g must be constant, a contradiction. Any reference is welcome, Malik NOTE: This is a duplicate of a question on MathOverflow . I'm posting it here too because I did not get any answer or comment.","Let $f$ be an entire function. The Spherical Derivative $\rho(f)$ is defined by $$\rho(f)(z):= \frac{|f'(z)|}{1+|f(z)|^2}.$$ A result from Clunie and Hayman states that if $\rho(f)$ is bounded, then $f$ is of exponential type. The proof uses the machinery of Nevanlinna's theory of value distribution. My question is the following : Is there an ""elementary"" proof that if $\rho(f)$ is bounded, then $f$ is of finite order ? (Note that this is a weaker result, since I'm only asking for finite order here). Finite order means that there exists constants $K$ and $\alpha$ such that $$|f(z)| \leq Ke^{|z|^\alpha}$$ for all $z$. Motivation : Motivation : I'm interested in this because it would lead to a quick proof of Picard's little theorem. Indeed, if there exists a non-constant entire function which omits $0$ and $1$, then it is possible to obtain (using normal families techniques) a non-constant entire function $f$ which omits $0$ and $1$ and that has bounded spherical derivative. Write $f=e^g$ for some entire function $g$. Since $f$ is of finite order, $g$ is a polynomial. But f does not take the value $1$, so g must be constant, a contradiction. Any reference is welcome, Malik NOTE: This is a duplicate of a question on MathOverflow . I'm posting it here too because I did not get any answer or comment.",,['complex-analysis']
2,Visualizing the domain of the square root,Visualizing the domain of the square root,,"I would like to show someone the domain of the complex square root function (the 2-sheeted riemann surface).  Is there a good interactive visualization software for this? I would like some sort of GeoGebra style app where there is a forbidden point or disk, but outside of that you can drag a point around.  As you drag around the pole, it changes from red to blue smoothly, so that on the bottom sheet it is red, and on the top sheet it is blue (or some reasonable periodic color scheme where 50% apart is always very distinct). It would be doubly nice if one could have simple geometric shapes do the same.  Basically I want a nice double covering of a plane symmetry group that is still very geometric. It would be n -tuply nice if one could handle n th roots and the n -sheeted Riemann surface, but n =2 suffices for me, I think. I've used other people's geogebra apps, but never made my own, and have no idea how to keep track of what sheet the point is on (or honestly how to animate the color, though I assume once I have a 0…4π valued argument function, I should be fine). Some pretty images from wikipedia :","I would like to show someone the domain of the complex square root function (the 2-sheeted riemann surface).  Is there a good interactive visualization software for this? I would like some sort of GeoGebra style app where there is a forbidden point or disk, but outside of that you can drag a point around.  As you drag around the pole, it changes from red to blue smoothly, so that on the bottom sheet it is red, and on the top sheet it is blue (or some reasonable periodic color scheme where 50% apart is always very distinct). It would be doubly nice if one could have simple geometric shapes do the same.  Basically I want a nice double covering of a plane symmetry group that is still very geometric. It would be n -tuply nice if one could handle n th roots and the n -sheeted Riemann surface, but n =2 suffices for me, I think. I've used other people's geogebra apps, but never made my own, and have no idea how to keep track of what sheet the point is on (or honestly how to animate the color, though I assume once I have a 0…4π valued argument function, I should be fine). Some pretty images from wikipedia :",,"['complex-analysis', 'riemann-surfaces', 'visualization']"
3,Show that the number of zeros of $e^{2z}-P(z)$ is not finite,Show that the number of zeros of  is not finite,e^{2z}-P(z),"I'm trying to solve the following problem: Let $P(z) \neq 0$ be a complex polynomial. Use Jensen's Formula to show that the set of zeros of $e^{2z}-P(z)$ is not finite. ATTEMPT Suppose that it were finite, say the zeros are $\alpha_1,\dots,\alpha_n$ , and they are inside of $D(0,R)$ . Then, by Jensen's Formula, \begin{align*} \log |f(0)|=-\sum_{k=1}^n \log \left(\frac{R}{\left|a_k\right|}\right)+\frac{1}{2 \pi} \int_0^{2 \pi} \log \left|f\left(R e^{i \theta}\right)\right| d \theta, \end{align*} where $f(z)= e^{2z}-P(z)$ . Now my idea was to show that $\int_0^{2 \pi} \log \left|f\left(R e^{i \theta}\right)\right| d \theta$ is divergent, and therefore the formula wasn't valid, I'm not sure how to compute $\log \left|e^{Re^{i\theta}} -P(Re^{i\theta})\right|$ . I'm also aware of the following inequality derived from Jensen's Formula: \begin{align*} n(R)\leq CR^{\rho}, \end{align*} where $\rho$ is the order of growth and $n(R)$ is the number of zeros inside $D(0,R)$ , but it doesn't seem relevant here since it's a $\leq$ -type inequality.","I'm trying to solve the following problem: Let be a complex polynomial. Use Jensen's Formula to show that the set of zeros of is not finite. ATTEMPT Suppose that it were finite, say the zeros are , and they are inside of . Then, by Jensen's Formula, where . Now my idea was to show that is divergent, and therefore the formula wasn't valid, I'm not sure how to compute . I'm also aware of the following inequality derived from Jensen's Formula: where is the order of growth and is the number of zeros inside , but it doesn't seem relevant here since it's a -type inequality.","P(z) \neq 0 e^{2z}-P(z) \alpha_1,\dots,\alpha_n D(0,R) \begin{align*}
\log |f(0)|=-\sum_{k=1}^n \log \left(\frac{R}{\left|a_k\right|}\right)+\frac{1}{2 \pi} \int_0^{2 \pi} \log \left|f\left(R e^{i \theta}\right)\right| d \theta,
\end{align*} f(z)= e^{2z}-P(z) \int_0^{2 \pi} \log \left|f\left(R e^{i \theta}\right)\right| d \theta \log \left|e^{Re^{i\theta}} -P(Re^{i\theta})\right| \begin{align*}
n(R)\leq CR^{\rho},
\end{align*} \rho n(R) D(0,R) \leq","['complex-analysis', 'polynomials', 'roots']"
4,Why can the exit distribution of a Brownian motion be found pretending it moves in a random straight line?,Why can the exit distribution of a Brownian motion be found pretending it moves in a random straight line?,,"Let $U$ be a domain in the plane and denote by $\mu_{x_0,U}$ the distribution of a Brownian motion starting at $x_0\in U$ by the time it hits the boundary of $U$ . Why is it that for $U=\mathbb{H}$ the upper half plane and any $x_0\in\mathbb{H}$ , the exit distribution $\mu_{x_0,\mathbb{H}}$ is a Cauchy distribution on the horizontal axis (centered at the first component of $x_0$ , and with scale parameter equal to the second component)? Note that the Cauchy distribution on the horizontal axis is the distribution of the intersections between the horizontal axis and random straight lines through the starting point with uniformly random angle. Obviously this uniform angle property also holds for the exiti distribution from $U=\mathbb{D}$ the unit disk when $x_0=0$ (in this case the exit distribution is just the Hausdorff measure on the circle). The question title was written in an attention gathering fashion though: I know this uniform-angle propery can't be true for all domains, but rather I'd like to ask what makes it true for the two special cases above and what makes it false for other domains. EDIT: In a lame sense, the answer is ""it's true for the half plane because the Cayley transform preserves BM up to time reparametrization and takes the horizontal axis to the circle and has derivative proportional to $1/(z+i)^2$ , the absolute value of which is the Cauchy distribution for real $z$ "". This isn't very revealing to what's going on though, at least to me. I still don't have a clear picture of whether the uniform angle property maybe is true for all, e.g., convex domains if only formulated well enough (e.g. first pick a random line, then simulate a one dimensional Brownian motion hitting the boundary intersected with that line)","Let be a domain in the plane and denote by the distribution of a Brownian motion starting at by the time it hits the boundary of . Why is it that for the upper half plane and any , the exit distribution is a Cauchy distribution on the horizontal axis (centered at the first component of , and with scale parameter equal to the second component)? Note that the Cauchy distribution on the horizontal axis is the distribution of the intersections between the horizontal axis and random straight lines through the starting point with uniformly random angle. Obviously this uniform angle property also holds for the exiti distribution from the unit disk when (in this case the exit distribution is just the Hausdorff measure on the circle). The question title was written in an attention gathering fashion though: I know this uniform-angle propery can't be true for all domains, but rather I'd like to ask what makes it true for the two special cases above and what makes it false for other domains. EDIT: In a lame sense, the answer is ""it's true for the half plane because the Cayley transform preserves BM up to time reparametrization and takes the horizontal axis to the circle and has derivative proportional to , the absolute value of which is the Cauchy distribution for real "". This isn't very revealing to what's going on though, at least to me. I still don't have a clear picture of whether the uniform angle property maybe is true for all, e.g., convex domains if only formulated well enough (e.g. first pick a random line, then simulate a one dimensional Brownian motion hitting the boundary intersected with that line)","U \mu_{x_0,U} x_0\in U U U=\mathbb{H} x_0\in\mathbb{H} \mu_{x_0,\mathbb{H}} x_0 U=\mathbb{D} x_0=0 1/(z+i)^2 z","['complex-analysis', 'brownian-motion', 'stochastic-analysis']"
5,Regarding definition of Linear Convexity in $\mathbb{C}^n$ and reference request,Regarding definition of Linear Convexity in  and reference request,\mathbb{C}^n,"In the book Notions of Convexity by Lars Hörmander page 290, section 4.6 Linear convexity is defined as follows. An open set $X\in \mathbb{C}^n$ is called linearly convex if for every $z\in \mathbb{C}^n\setminus X $ there exists an affine complex hyperplane $\Pi$ such that $z\in \Pi\subset \mathbb{C}^n\setminus X$ . Proposition 4.6.2 says. If $X$ is an open set in $\mathbb{C}^n$ , then the union $F$ Of all affine complex hyperplanes $\Pi\subset\mathbb{C}^n\setminus X$ is a closed set and $\hat{X}= \mathbb{C}^n\setminus F$ is linearly convex. If $V$ is a complex vector space we shall denote by $P(V)$ the projective space consisting of all complex lines through the origin in $V$ . And $V^*$ is the dual space of $V$ . I wanted to know that why did we need to go to the projective geometry set up to define $X^{**}$ ? Can we not define it in vector space set up itself? Do we have a similar definition of $X^{**}$ where we need not consider the projective space (something’s similar to the bipolar of a set in Banach space). I have no background in projective geometry, but have started learning and have understood the real projective plane. Since I am not very sure of my concepts in projective geometry, I wanted to know if we have similar definition of $X^{**}$ in vector space set up. Reference request: The most standard known books to study the different notions of convexity in several complex variables are Complex Convexity and Analytic Functionals by Mats Andersson and Notions of Convexity by Lars Hörmander. Are there any other references/texts with all equivalent definitions to study the same?","In the book Notions of Convexity by Lars Hörmander page 290, section 4.6 Linear convexity is defined as follows. An open set is called linearly convex if for every there exists an affine complex hyperplane such that . Proposition 4.6.2 says. If is an open set in , then the union Of all affine complex hyperplanes is a closed set and is linearly convex. If is a complex vector space we shall denote by the projective space consisting of all complex lines through the origin in . And is the dual space of . I wanted to know that why did we need to go to the projective geometry set up to define ? Can we not define it in vector space set up itself? Do we have a similar definition of where we need not consider the projective space (something’s similar to the bipolar of a set in Banach space). I have no background in projective geometry, but have started learning and have understood the real projective plane. Since I am not very sure of my concepts in projective geometry, I wanted to know if we have similar definition of in vector space set up. Reference request: The most standard known books to study the different notions of convexity in several complex variables are Complex Convexity and Analytic Functionals by Mats Andersson and Notions of Convexity by Lars Hörmander. Are there any other references/texts with all equivalent definitions to study the same?",X\in \mathbb{C}^n z\in \mathbb{C}^n\setminus X  \Pi z\in \Pi\subset \mathbb{C}^n\setminus X X \mathbb{C}^n F \Pi\subset\mathbb{C}^n\setminus X \hat{X}= \mathbb{C}^n\setminus F V P(V) V V^* V X^{**} X^{**} X^{**},"['complex-analysis', 'reference-request', 'convex-analysis', 'several-complex-variables']"
6,When do polynomial equations come from complexification?,When do polynomial equations come from complexification?,,"If $f(z) \in \mathbb{C}[z]$ is a polynomial of degree $d$ , then it has $d$ complex zeros. Writing the complexification $$f(x+iy)=u(x,y)+iv(x,y)$$ we observe that the real polynomial system $u(x,y)=v(x,y)=0$ has $d$ real solutions (corresponding to the $d$ complex zeros of $f$ ). Motivating question: if you are given $u(x,y),v(x,y)$ how could you recognize whether they came from a complexification $f(x+iy)$ ? The answer is to check the Cauchy Riemann equations. Actual (and more difficult) question: Suppose you are given new generators $g(x,y),h(x,y)$ for the ideal $\langle u(x,y),v(x,y) \rangle$ (where $u$ and $v$ are the real and imaginary parts of the complexification of a univariate polynomial).  Although the solutions $g=h=0$ are the same as $u=v=0$ , you can check that $g(x,y),h(x,y)$ (generically) do not satisfy the Cauchy-Riemann equations.  Now how can one tell when $g(x,y),h(x,y)$ came about in this fashion? and thus be able to tell immediately that they have real common solutions?","If is a polynomial of degree , then it has complex zeros. Writing the complexification we observe that the real polynomial system has real solutions (corresponding to the complex zeros of ). Motivating question: if you are given how could you recognize whether they came from a complexification ? The answer is to check the Cauchy Riemann equations. Actual (and more difficult) question: Suppose you are given new generators for the ideal (where and are the real and imaginary parts of the complexification of a univariate polynomial).  Although the solutions are the same as , you can check that (generically) do not satisfy the Cauchy-Riemann equations.  Now how can one tell when came about in this fashion? and thus be able to tell immediately that they have real common solutions?","f(z) \in \mathbb{C}[z] d d f(x+iy)=u(x,y)+iv(x,y) u(x,y)=v(x,y)=0 d d f u(x,y),v(x,y) f(x+iy) g(x,y),h(x,y) \langle u(x,y),v(x,y) \rangle u v g=h=0 u=v=0 g(x,y),h(x,y) g(x,y),h(x,y)","['complex-analysis', 'polynomials', 'real-algebraic-geometry']"
7,Definition of smooth curves in Stein and Shakarchi's Complex Analysis - why nonzero derivative?,Definition of smooth curves in Stein and Shakarchi's Complex Analysis - why nonzero derivative?,,"A parametrized curve is a function $z(t)$ which maps a closed interval $[a, b] \subset \mathbb{R}$ to the complex plane. We shall impose regularity conditions on the parametrization which are always verified in the situations that occur in this book. We say that the parametrized curve is smooth if $z'(t)$ exists and is continuous on $[a, b]$ , and $z'(t) \neq 0$ for $t \in[a, b]$ . Above is the definition of smooth parameterized curves given in Stein and Shakarchi's Complex Analysis . Questions : (i) Why do we require $z'(t) \not= 0$ ? I have not seen this condition used in any proofs. (ii) Where is the ""regularity condition"" imposed - I thought this meant $z(t) \in C^{\infty}[a,b]$ (?)","A parametrized curve is a function which maps a closed interval to the complex plane. We shall impose regularity conditions on the parametrization which are always verified in the situations that occur in this book. We say that the parametrized curve is smooth if exists and is continuous on , and for . Above is the definition of smooth parameterized curves given in Stein and Shakarchi's Complex Analysis . Questions : (i) Why do we require ? I have not seen this condition used in any proofs. (ii) Where is the ""regularity condition"" imposed - I thought this meant (?)","z(t) [a, b] \subset \mathbb{R} z'(t) [a, b] z'(t) \neq 0 t \in[a, b] z'(t) \not= 0 z(t) \in C^{\infty}[a,b]","['complex-analysis', 'terminology', 'definition', 'curves']"
8,Why are complex numbers so magical? [closed],Why are complex numbers so magical? [closed],,"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 7 years ago . Improve this question Both the real numbers and the complex numbers have a whole bunch of really nice properties: For reals, we have ordering, the intermediate value theorem, etc.  Complex numbers are algebraically closed, and we have nice calculus results like the Cauchy–Goursat theorem, holomorphicity implies analyticity, etc.  These results are to be contrasted with the case of e.g. higher dimensional spaces like $\mathbb{R}^n$ or other structures like the quaternions. My feeling is that all the nice properties of the reals can be traced to completeness and ordering.  However, I don't have a feeling for why the complex numbers have such miraculous analytical properties.  Since $\mathbb{C}$ is defined essentially as the algebraic closure of $\mathbb{R}$, I might naively suspect that closedness is the crucial property, but I don't see how that manifests itself in proving theorems like Cauchy-Goursat.  Perhaps Cauchy-Goursat is itself the essential property? So my question is: Are there one or two fundamental properties of the complex numbers which beget all the other miracles of complex analysis?  In other words, what makes complex analysis so different from real analysis or quaternionic analysis?","Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 7 years ago . Improve this question Both the real numbers and the complex numbers have a whole bunch of really nice properties: For reals, we have ordering, the intermediate value theorem, etc.  Complex numbers are algebraically closed, and we have nice calculus results like the Cauchy–Goursat theorem, holomorphicity implies analyticity, etc.  These results are to be contrasted with the case of e.g. higher dimensional spaces like $\mathbb{R}^n$ or other structures like the quaternions. My feeling is that all the nice properties of the reals can be traced to completeness and ordering.  However, I don't have a feeling for why the complex numbers have such miraculous analytical properties.  Since $\mathbb{C}$ is defined essentially as the algebraic closure of $\mathbb{R}$, I might naively suspect that closedness is the crucial property, but I don't see how that manifests itself in proving theorems like Cauchy-Goursat.  Perhaps Cauchy-Goursat is itself the essential property? So my question is: Are there one or two fundamental properties of the complex numbers which beget all the other miracles of complex analysis?  In other words, what makes complex analysis so different from real analysis or quaternionic analysis?",,"['complex-analysis', 'complex-numbers', 'soft-question']"
9,Tilings and meromorphic functions,Tilings and meromorphic functions,,"This question and its answer by ""J.M."" were quite informative and inspire other questions. If a function is meromorphic on $\mathbb C$ and doubly periodic then, as we all learned at our mother's knee, there is a fundamental domain that is a parallelogram.  So someone asked whether one could do the same with the standard tiling of the plane by regular hexagons, so that the restriction of the function to one hexagon is just a shift of its restriction to any of the other hexagons.  ""J.M."" 's answer was that that is exactly what happens with ""Dixon's elliptic functions"" .  This in no way conflicts with the existence of a fundamental domain that is a parallelogram --- indeed a rectangle (that's an exercise whose solution may take you five seconds). All this immediately inspires two other questions: What about other periodic tilings?  For example, there is a periodic tiling by hexagons, squares, and triangles.  Might the restriction of some doubly periodic meromorphic function to any of those be a shift or maybe a shift followed by a rotation, of the restriction to any of the others?  For that tiling, rotation as well as translation becomes relevant. What about aperiodic tilings?  We'd want a function meromorpic on the whole plane whose restriction to any tile is a shift-plus-rotation of its restriction to any of the infinitely many tiles of the same shape.  For which tilings does such a thing exist? [Aperiodic tilings won't work here. That follows immediately from some basic stuff from complex variables.]","This question and its answer by ""J.M."" were quite informative and inspire other questions. If a function is meromorphic on $\mathbb C$ and doubly periodic then, as we all learned at our mother's knee, there is a fundamental domain that is a parallelogram.  So someone asked whether one could do the same with the standard tiling of the plane by regular hexagons, so that the restriction of the function to one hexagon is just a shift of its restriction to any of the other hexagons.  ""J.M."" 's answer was that that is exactly what happens with ""Dixon's elliptic functions"" .  This in no way conflicts with the existence of a fundamental domain that is a parallelogram --- indeed a rectangle (that's an exercise whose solution may take you five seconds). All this immediately inspires two other questions: What about other periodic tilings?  For example, there is a periodic tiling by hexagons, squares, and triangles.  Might the restriction of some doubly periodic meromorphic function to any of those be a shift or maybe a shift followed by a rotation, of the restriction to any of the others?  For that tiling, rotation as well as translation becomes relevant. What about aperiodic tilings?  We'd want a function meromorpic on the whole plane whose restriction to any tile is a shift-plus-rotation of its restriction to any of the infinitely many tiles of the same shape.  For which tilings does such a thing exist? [Aperiodic tilings won't work here. That follows immediately from some basic stuff from complex variables.]",,"['complex-analysis', 'tiling', 'meromorphic-functions']"
10,Why do the Jacobi theta functions have a natural boundary?,Why do the Jacobi theta functions have a natural boundary?,,"The Jacobi theta functions, like $$ \theta_3(z,q)=1+2\sum_{n=0}^\infty q^{n^2}\!\cos(2nz) , $$ look relatively innocent in how they handle the 'nome' $q$, a complex parameter that shapes the dependence of $\theta_3$ on its argument $z$. At a first look, the series is definitely convergent if $|q|<1$, with some vague hopes of not-horrible behaviour at the edge of the unit disk. However, as it turns out, not only does the series in the definition above diverge for $|q|>1$, but the theta function simply cannot be analytically continued past the edge of the unit disk, where it has a natural boundary. I would like to understand exactly how the existence of this natural boundary, and the impossibility of analytical continuation beyond it, arises and how it can be rigorously proved. What is the cleanest, most flexible way of showing it's there? (In particular, I would like to decide whether a similar series, $\sum_{n=-\infty}^\infty\exp(i(an^3+bn^2+cn))$, has a similar behaviour with respect to the equivalent parameter $q=e^{ib}$, so I would appreciate results which can be extended in that sort of direction.)","The Jacobi theta functions, like $$ \theta_3(z,q)=1+2\sum_{n=0}^\infty q^{n^2}\!\cos(2nz) , $$ look relatively innocent in how they handle the 'nome' $q$, a complex parameter that shapes the dependence of $\theta_3$ on its argument $z$. At a first look, the series is definitely convergent if $|q|<1$, with some vague hopes of not-horrible behaviour at the edge of the unit disk. However, as it turns out, not only does the series in the definition above diverge for $|q|>1$, but the theta function simply cannot be analytically continued past the edge of the unit disk, where it has a natural boundary. I would like to understand exactly how the existence of this natural boundary, and the impossibility of analytical continuation beyond it, arises and how it can be rigorously proved. What is the cleanest, most flexible way of showing it's there? (In particular, I would like to decide whether a similar series, $\sum_{n=-\infty}^\infty\exp(i(an^3+bn^2+cn))$, has a similar behaviour with respect to the equivalent parameter $q=e^{ib}$, so I would appreciate results which can be extended in that sort of direction.)",,"['complex-analysis', 'special-functions', 'theta-functions', 'analytic-continuation']"
11,"There exists polynomial $(P_{n})_{n\in\mathbb{N}}$ such that $P_n(0)=1$, and $\lim_{n\rightarrow \infty}P_{n}(z)=0$..","There exists polynomial  such that , and ..",(P_{n})_{n\in\mathbb{N}} P_n(0)=1 \lim_{n\rightarrow \infty}P_{n}(z)=0,"Show that there exists a sequence of polynomial $(P_{n})_{n\in\mathbb{N}}$ such that $P_n(0)=1$ for each $n$, and $\lim_{n\rightarrow \infty}P_{n}(z)=0$  for all $z\in \mathbb{C}\setminus \left\{0\right\}$. Remark: There are proofs of this fact that use versions of the Runge's theorem, the problem is that those versions do not coincide with versions I was taught in my course. Runge's theorem on my course is: Runge's Theorem for compacts: Let $U\subseteq \mathbb{C}$ be an open set, $K\subseteq U$ compact set, $f:U\rightarrow \mathbb{C}$ holomorphic function. Let $\varepsilon >0 $  and let $A\subseteq \mathbb{C}\setminus K$ such that $A$ intersects any connected component of $\mathbb{C}\setminus K$. Then there is $g\in  \mathcal{R}_{A}$ such that $\left\|f-g\right\|_{K}<\varepsilon $. where  $$\mathcal{R}_{A}:=\left\{f \: \mbox{rational function with each pole in } A\right\}$$  In my attempt I use the following lemma: Lemma $\bigstar$: Let $K\subseteq \mathbb{C}$ be a compact set. Let $r>0$ such that $A:=\left\{z\in \mathbb{C}\: : \: |z|>r\right\}\subseteq \mathbb{C}\setminus K$ and $f\in \mathcal{R}_{A}$. Then $f$ can be approximated uniformly on $K$ by polynomials. My attempt: For each $n\in \mathbb{N}$ consider $C_{n}:=\left\{z\in \mathbb{C}\: : \: \frac{1}{n}\leq \mbox{Re}(z) \leq n \: \mbox{ and }\: \frac{-1}{4n}\leq \mbox{Im}(z) \leq \frac{1}{4n}\right\}$. We define $$K_{n}:=\left\{z\in\mathbb{C}\: : \: z\in \overline{B_{n}(0)  } \: \mbox{and} \: d(z,\mathbb{R}^{+})\geq \frac{1}{n}\right\}\cup \overline{B_{\frac{1}{4n}}(0)}\cup C_{n}.$$ Clearly $ K_ {n} $ is compact. Now, we consider the open set $V_{n}:=\left\{z\in \mathbb{C}\: : \: \frac{1}{n}\leq \mbox{Re}(z) \leq n \: \mbox{ and }\: \frac{-1}{3n}<\mbox{Im}(z) < \frac{1}{3n}\right\}\cup B_{\frac{1}{3n}}(\frac{1}{n})\cup B_{\frac{1}{3n}}(n)$. We define  $$U_{n}:=\left\{z\in\mathbb{C}\: : \: z\in B_{n+\frac{1}{3n}}(0)   \: \mbox{and} \: d(z,\mathbb{R}^{+})> \frac{2}{3n}\right\}\cup B_{\frac{1}{3n}}(0)\cup V_{n}.$$ Note that  $U_{n}$ is  open and also $K_{n}\subseteq U_{n}$.  All this is summarized in the following figure: Now, we consider $A_{n}:=\left\{z\in \mathbb{C} \: : \: |z|>n+\frac{1}{3n}\right\}$ and $f_{n}:U_{n}\rightarrow \mathbb{C}$ defined by: $$f_{n}(z):=\left\{\begin{array}{rl}1 & \mbox{If }z\in B_{\frac{1}{3n}}(0) \\ 0 & \mbox{If }z\in U_{n}\setminus B_{\frac{1}{3n}}(0)   \end{array}\right.$$ Note that $f_{n}$ is holomorphic in $U_{n}$. Therefore, by Runge's Theorem for compacts there is $g_{n}\in \mathcal{R}_{A_{n}}$ such that $\left\|f_{n}-g_{n}\right\|_{K_{n}}<\frac{1}{2n}$. But, by Lemma $\bigstar$ for $r_{n}=n+\frac{1}{3n}$, $g_{n}$ can be approximated uniformly on $K_{n}$ by polynomials. So, there exist a polynomial $P_{n}$ such that $\left\|g_{n}-P_{n}\right\|_{K_{n}}<\frac{1}{2n}$. Therefore, $$\left\|f_{n}-P_{n}\right\|_{K_{n}}<\frac{1}{n} \: \mbox{ for all } n=1,2,\ldots,n.$$ Therefore,  $(P_{n})_{n\in\mathbb{N}}$ is a sequence of polynomial such that $P_n(0)=1$ for each $n$, and $\lim_{n\rightarrow \infty}P_{n}(z)=0$  for all $z\in \mathbb{C}\setminus \left\{0\right\}$. Questions: I want to know if there is any mistake in my test. In addition, I want to know if I am correctly applying the theorems statements. If my proof has mistakes I would like you to give me some hint to complete the proof correctly.","Show that there exists a sequence of polynomial $(P_{n})_{n\in\mathbb{N}}$ such that $P_n(0)=1$ for each $n$, and $\lim_{n\rightarrow \infty}P_{n}(z)=0$  for all $z\in \mathbb{C}\setminus \left\{0\right\}$. Remark: There are proofs of this fact that use versions of the Runge's theorem, the problem is that those versions do not coincide with versions I was taught in my course. Runge's theorem on my course is: Runge's Theorem for compacts: Let $U\subseteq \mathbb{C}$ be an open set, $K\subseteq U$ compact set, $f:U\rightarrow \mathbb{C}$ holomorphic function. Let $\varepsilon >0 $  and let $A\subseteq \mathbb{C}\setminus K$ such that $A$ intersects any connected component of $\mathbb{C}\setminus K$. Then there is $g\in  \mathcal{R}_{A}$ such that $\left\|f-g\right\|_{K}<\varepsilon $. where  $$\mathcal{R}_{A}:=\left\{f \: \mbox{rational function with each pole in } A\right\}$$  In my attempt I use the following lemma: Lemma $\bigstar$: Let $K\subseteq \mathbb{C}$ be a compact set. Let $r>0$ such that $A:=\left\{z\in \mathbb{C}\: : \: |z|>r\right\}\subseteq \mathbb{C}\setminus K$ and $f\in \mathcal{R}_{A}$. Then $f$ can be approximated uniformly on $K$ by polynomials. My attempt: For each $n\in \mathbb{N}$ consider $C_{n}:=\left\{z\in \mathbb{C}\: : \: \frac{1}{n}\leq \mbox{Re}(z) \leq n \: \mbox{ and }\: \frac{-1}{4n}\leq \mbox{Im}(z) \leq \frac{1}{4n}\right\}$. We define $$K_{n}:=\left\{z\in\mathbb{C}\: : \: z\in \overline{B_{n}(0)  } \: \mbox{and} \: d(z,\mathbb{R}^{+})\geq \frac{1}{n}\right\}\cup \overline{B_{\frac{1}{4n}}(0)}\cup C_{n}.$$ Clearly $ K_ {n} $ is compact. Now, we consider the open set $V_{n}:=\left\{z\in \mathbb{C}\: : \: \frac{1}{n}\leq \mbox{Re}(z) \leq n \: \mbox{ and }\: \frac{-1}{3n}<\mbox{Im}(z) < \frac{1}{3n}\right\}\cup B_{\frac{1}{3n}}(\frac{1}{n})\cup B_{\frac{1}{3n}}(n)$. We define  $$U_{n}:=\left\{z\in\mathbb{C}\: : \: z\in B_{n+\frac{1}{3n}}(0)   \: \mbox{and} \: d(z,\mathbb{R}^{+})> \frac{2}{3n}\right\}\cup B_{\frac{1}{3n}}(0)\cup V_{n}.$$ Note that  $U_{n}$ is  open and also $K_{n}\subseteq U_{n}$.  All this is summarized in the following figure: Now, we consider $A_{n}:=\left\{z\in \mathbb{C} \: : \: |z|>n+\frac{1}{3n}\right\}$ and $f_{n}:U_{n}\rightarrow \mathbb{C}$ defined by: $$f_{n}(z):=\left\{\begin{array}{rl}1 & \mbox{If }z\in B_{\frac{1}{3n}}(0) \\ 0 & \mbox{If }z\in U_{n}\setminus B_{\frac{1}{3n}}(0)   \end{array}\right.$$ Note that $f_{n}$ is holomorphic in $U_{n}$. Therefore, by Runge's Theorem for compacts there is $g_{n}\in \mathcal{R}_{A_{n}}$ such that $\left\|f_{n}-g_{n}\right\|_{K_{n}}<\frac{1}{2n}$. But, by Lemma $\bigstar$ for $r_{n}=n+\frac{1}{3n}$, $g_{n}$ can be approximated uniformly on $K_{n}$ by polynomials. So, there exist a polynomial $P_{n}$ such that $\left\|g_{n}-P_{n}\right\|_{K_{n}}<\frac{1}{2n}$. Therefore, $$\left\|f_{n}-P_{n}\right\|_{K_{n}}<\frac{1}{n} \: \mbox{ for all } n=1,2,\ldots,n.$$ Therefore,  $(P_{n})_{n\in\mathbb{N}}$ is a sequence of polynomial such that $P_n(0)=1$ for each $n$, and $\lim_{n\rightarrow \infty}P_{n}(z)=0$  for all $z\in \mathbb{C}\setminus \left\{0\right\}$. Questions: I want to know if there is any mistake in my test. In addition, I want to know if I am correctly applying the theorems statements. If my proof has mistakes I would like you to give me some hint to complete the proof correctly.",,"['complex-analysis', 'proof-verification', 'alternative-proof']"
12,Riemann Surface Tennis [closed],Riemann Surface Tennis [closed],,"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 8 years ago . Improve this question So a few months ago I read Brave New World by Aldous Huxley and found the authors insights and style of humor remarkable. It describes a utopian society where people are conditioned to be enslaved by the pursuit of short term pleasure and happiness at the sacrifice of truth and beauty. Some of the games people play in the Brave New World include electromagnetic golf, and my personal favorite Riemann surface tennis. Huxley went to Oxford so he must have had tons of really brilliant friends, but I think he's just taking the piss out of mathematicians and their magical powers of abstraction. Still, what would playing tennis on a Riemann surface be like? Say for example, $f(z)=\log(z)$? What kinds of surfaces could you play Riemann surface tennis on? I'd imagine it'd be...challenging.","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 8 years ago . Improve this question So a few months ago I read Brave New World by Aldous Huxley and found the authors insights and style of humor remarkable. It describes a utopian society where people are conditioned to be enslaved by the pursuit of short term pleasure and happiness at the sacrifice of truth and beauty. Some of the games people play in the Brave New World include electromagnetic golf, and my personal favorite Riemann surface tennis. Huxley went to Oxford so he must have had tons of really brilliant friends, but I think he's just taking the piss out of mathematicians and their magical powers of abstraction. Still, what would playing tennis on a Riemann surface be like? Say for example, $f(z)=\log(z)$? What kinds of surfaces could you play Riemann surface tennis on? I'd imagine it'd be...challenging.",,['complex-analysis']
13,Complex 'mean-value-theorem'-like property implies quadratic,Complex 'mean-value-theorem'-like property implies quadratic,,"One of my friend asked me the following problem: Problem. Suppose that $f$ is a holomorphic function on a convex open set $U$ which satisfies the following property: For all distinct $z, w \in U$, there exists $\zeta$ on the line segment joining $z$ and $w$ such that   $$ \frac{f(w) - f(z)}{w - z} = f'(\zeta). $$   Then show that $f$ is a polynomial of degree at most 2. This problem was given in the lecture note right after some basic properties of complex differentiability are introduced. I was able to prove this problem, though my argument relies on heavy machinery (such as inverse function theorem) which is beyond the chapter containing it. Q. My question is, is there any elementary solution? For a reference, here is my heavy solution: Step 1. If $f'' \equiv 0$ on $U$, there is nothing to prove. So we may assume that $f''(z_0) \neq 0$ for some $z_0 \in U$. Our goal is to show that Claim. There exists a neighborhood $V \subseteq U$ of $z_0$ such that for any $z \in V$,   $$ \frac{f(z) - f(z_0)}{z - z_0} = f'(z_0 + \tfrac{1}{2}(z - z_0)).$$ Indeed, assuming that this claim is true, we obtain \begin{align*} \sum_{n=0}^{\infty} \frac{f^{(n+1)}(z_0)}{(n+1)!} (z - z_0)^n &= \frac{f(z) - f(z_0)}{z - z_0} \\ &= f'(z_0 + \tfrac{1}{2}(z - z_0)) = \sum_{n=0}^{\infty} \frac{f^{(n+1)}(z_0)}{n! 2^n} (z - z_0)^n. \end{align*} Comparing coefficients of both sides, we have $$f^{(3)}(z_0) = f^{(4)}(z_0) = \cdots = 0$$ and hence $f$ is a polynomial of degree at most 2 on $V$. Then by the principle of analytic continuation, this continues to hold on all of $U$ as desired. Step 2. So it remains to prove the claim. To this end, notice that $g(z) := (f(z) - f(z_0))/(z - z_0)$ has removable singularity at $z = z_0$, hence extends to a holomorphic function on $U$. By the inverse function theorem, there exists a neighborhood $V \subseteq U$ of $z_0$ on which $f'$ is invertible. By shrinking $V$ further, we may assume that $V$ is convex. From the assumption, we know that $g(V) \subseteq f'(V)$. Thus $$ \zeta(z) := (f')^{-1}(g(z)) $$ is a well-defined holomorphic function on $V$ such that $$ \frac{\zeta(z) - z_0}{z - z_0} \in [0, 1] \quad \text{for all } z \in V \setminus\{z_0\}. $$ This implies that $(\zeta(z) - z_0)/(z - z_0)$ is constant, and this value can be determined by $$ \frac{\zeta(z) - z_0}{z - z_0} = \lim_{w \to z_0} \frac{\zeta(w) - z_0}{w - z_0} = \zeta'(z_0) = \frac{g'(z_0)}{f''(z_0)} = \frac{1}{2}. $$ This completes the proof. ////","One of my friend asked me the following problem: Problem. Suppose that $f$ is a holomorphic function on a convex open set $U$ which satisfies the following property: For all distinct $z, w \in U$, there exists $\zeta$ on the line segment joining $z$ and $w$ such that   $$ \frac{f(w) - f(z)}{w - z} = f'(\zeta). $$   Then show that $f$ is a polynomial of degree at most 2. This problem was given in the lecture note right after some basic properties of complex differentiability are introduced. I was able to prove this problem, though my argument relies on heavy machinery (such as inverse function theorem) which is beyond the chapter containing it. Q. My question is, is there any elementary solution? For a reference, here is my heavy solution: Step 1. If $f'' \equiv 0$ on $U$, there is nothing to prove. So we may assume that $f''(z_0) \neq 0$ for some $z_0 \in U$. Our goal is to show that Claim. There exists a neighborhood $V \subseteq U$ of $z_0$ such that for any $z \in V$,   $$ \frac{f(z) - f(z_0)}{z - z_0} = f'(z_0 + \tfrac{1}{2}(z - z_0)).$$ Indeed, assuming that this claim is true, we obtain \begin{align*} \sum_{n=0}^{\infty} \frac{f^{(n+1)}(z_0)}{(n+1)!} (z - z_0)^n &= \frac{f(z) - f(z_0)}{z - z_0} \\ &= f'(z_0 + \tfrac{1}{2}(z - z_0)) = \sum_{n=0}^{\infty} \frac{f^{(n+1)}(z_0)}{n! 2^n} (z - z_0)^n. \end{align*} Comparing coefficients of both sides, we have $$f^{(3)}(z_0) = f^{(4)}(z_0) = \cdots = 0$$ and hence $f$ is a polynomial of degree at most 2 on $V$. Then by the principle of analytic continuation, this continues to hold on all of $U$ as desired. Step 2. So it remains to prove the claim. To this end, notice that $g(z) := (f(z) - f(z_0))/(z - z_0)$ has removable singularity at $z = z_0$, hence extends to a holomorphic function on $U$. By the inverse function theorem, there exists a neighborhood $V \subseteq U$ of $z_0$ on which $f'$ is invertible. By shrinking $V$ further, we may assume that $V$ is convex. From the assumption, we know that $g(V) \subseteq f'(V)$. Thus $$ \zeta(z) := (f')^{-1}(g(z)) $$ is a well-defined holomorphic function on $V$ such that $$ \frac{\zeta(z) - z_0}{z - z_0} \in [0, 1] \quad \text{for all } z \in V \setminus\{z_0\}. $$ This implies that $(\zeta(z) - z_0)/(z - z_0)$ is constant, and this value can be determined by $$ \frac{\zeta(z) - z_0}{z - z_0} = \lim_{w \to z_0} \frac{\zeta(w) - z_0}{w - z_0} = \zeta'(z_0) = \frac{g'(z_0)}{f''(z_0)} = \frac{1}{2}. $$ This completes the proof. ////",,"['complex-analysis', 'alternative-proof']"
14,Complex contour integral: How does the stationary point method used in this case?,Complex contour integral: How does the stationary point method used in this case?,,"I was reading a paper which has the following integral in order to do the inverse Laplace transformation: $$ I=\frac{1}{2\pi i}\int_{-i\infty+\gamma}^{i\infty+\gamma} e^{st}\frac{\Omega^2}{(s^2+4\Omega^2)\sqrt{s^2+4\Delta^2}\sinh^{-1}\frac{s}{2\Delta}}\mathrm{d}s  $$ To do this integral, we draw the following contour, in which we can see three poles and two branch points: The branch cut is defined as $$\mathcal{B}_{\pm}(\delta)=\{\pm 2i\Delta\pm ir e^{\pm i\delta}|r\in [0,+\infty)\}$$. My question is, how can I do the blue and red path in large $t$ limit , here is what the paper says: The asymptotic behavior of the integrals C± for t → ∞ is evaluated by   the saddle-point method. Finally we end up with long-time asymptotic   forms of the (integral) I have been working on this integral for two days and learn the very basic knowledge about the stationary point method(the steepest descent method), but still I cannot figure this out. Please help me with it, thanks in advance. The answer is as follows, the part with blue lines is the integral along branch cut which I am asking for help.","I was reading a paper which has the following integral in order to do the inverse Laplace transformation: $$ I=\frac{1}{2\pi i}\int_{-i\infty+\gamma}^{i\infty+\gamma} e^{st}\frac{\Omega^2}{(s^2+4\Omega^2)\sqrt{s^2+4\Delta^2}\sinh^{-1}\frac{s}{2\Delta}}\mathrm{d}s  $$ To do this integral, we draw the following contour, in which we can see three poles and two branch points: The branch cut is defined as $$\mathcal{B}_{\pm}(\delta)=\{\pm 2i\Delta\pm ir e^{\pm i\delta}|r\in [0,+\infty)\}$$. My question is, how can I do the blue and red path in large $t$ limit , here is what the paper says: The asymptotic behavior of the integrals C± for t → ∞ is evaluated by   the saddle-point method. Finally we end up with long-time asymptotic   forms of the (integral) I have been working on this integral for two days and learn the very basic knowledge about the stationary point method(the steepest descent method), but still I cannot figure this out. Please help me with it, thanks in advance. The answer is as follows, the part with blue lines is the integral along branch cut which I am asking for help.",,"['complex-analysis', 'laplace-transform', 'contour-integration', 'complex-integration']"
15,How to recognize when a function is secretely holomorphic,How to recognize when a function is secretely holomorphic,,"Let $f : M \rightarrow N$ be a holomorphic map between complex manifolds (I'd be interested even in the case $M=N=\mathbb{C}$ which should not be much different). Now take $K$ a compact subset of $M$, say with no isolated point for the question to be non trivial, and consider the restriction of $f$ to $M$. How can one recognize intrinsically (ie only looking at the values of $f$ on $K$) that $f_{|K}$ is secretely the restriction of a holomorphic map (in a neighborhood of $K$) ? Obviously such a restriction has to be locally lipschitz ; but it should also have some stronger, more constraining properties.","Let $f : M \rightarrow N$ be a holomorphic map between complex manifolds (I'd be interested even in the case $M=N=\mathbb{C}$ which should not be much different). Now take $K$ a compact subset of $M$, say with no isolated point for the question to be non trivial, and consider the restriction of $f$ to $M$. How can one recognize intrinsically (ie only looking at the values of $f$ on $K$) that $f_{|K}$ is secretely the restriction of a holomorphic map (in a neighborhood of $K$) ? Obviously such a restriction has to be locally lipschitz ; but it should also have some stronger, more constraining properties.",,['complex-analysis']
16,Interpretation of the Argument Principle,Interpretation of the Argument Principle,,"Recall that the argument principle states that given a meromorphic function $f$ and a compact region $K \subseteq \mathbb{C}$ whose boundary determines a simple contour and on which $f$ has no singularities, then: $$ \frac{1}{2\pi i}\int_{\partial K} \frac{f'(w)}{f(w)}dw = (N(Z) - N(P))$$ where $N(Z)$ and $N(P)$ refer to the number of zeroes and poles $f$ has in the interior of the compact region. I understand the statement and proof of the theorem, but I am a bit unclear as to why the contour integral of the logarithmic derivative is interpreted as the change in argument of $f$ along the simple contour $\partial K$. I realize that $\frac{d}{dz} \log{f(z)} = \frac{f'(z)}{f(z)}$, so I can certainly understand why we would consider the quantity $$\frac{1}{i} \int_{\partial K} \frac{f'(w)}{f(w)}dw$$ to measure the change in argument of $f$ along the contour if the contour is closed (since then the real part of the logarithm would vanish, so this quantity would indicate the change of argument). However, too many times I have encountered teachers/websites/authors refer to $$\int_{\gamma} \frac{f'(w)}{f(w)}dw$$ as the change of argument of $f$ even when $\gamma$ is not stated to be a closed contour. And this is precisely why I doubt my understanding of what's going on here. Is there something obvious that I'm overlooking?","Recall that the argument principle states that given a meromorphic function $f$ and a compact region $K \subseteq \mathbb{C}$ whose boundary determines a simple contour and on which $f$ has no singularities, then: $$ \frac{1}{2\pi i}\int_{\partial K} \frac{f'(w)}{f(w)}dw = (N(Z) - N(P))$$ where $N(Z)$ and $N(P)$ refer to the number of zeroes and poles $f$ has in the interior of the compact region. I understand the statement and proof of the theorem, but I am a bit unclear as to why the contour integral of the logarithmic derivative is interpreted as the change in argument of $f$ along the simple contour $\partial K$. I realize that $\frac{d}{dz} \log{f(z)} = \frac{f'(z)}{f(z)}$, so I can certainly understand why we would consider the quantity $$\frac{1}{i} \int_{\partial K} \frac{f'(w)}{f(w)}dw$$ to measure the change in argument of $f$ along the contour if the contour is closed (since then the real part of the logarithm would vanish, so this quantity would indicate the change of argument). However, too many times I have encountered teachers/websites/authors refer to $$\int_{\gamma} \frac{f'(w)}{f(w)}dw$$ as the change of argument of $f$ even when $\gamma$ is not stated to be a closed contour. And this is precisely why I doubt my understanding of what's going on here. Is there something obvious that I'm overlooking?",,['complex-analysis']
17,Set of derivatives of a normal family of analytic functions is itself a normal family.,Set of derivatives of a normal family of analytic functions is itself a normal family.,,"I'm working on a problem that is easily solvable if I can prove the statement in the title. Here's what I've done so far: Given $\mathscr{F}$ a normal family of analytic functions, let $\mathscr{F}'=\{f':f\in \mathscr{F}\}$. Let $\{f_n'\}$ be a sequence in $\mathscr{F}'$. Then the corresponding sequence $\{f_n\}$ (unique up to constants) contains a subsequence that converges to some analytic $f$. This implies that the subsequence of derivatives converges to $f'$, so every sequence in $\mathscr{F}'$ has a subsequence that converges and $\mathscr{F}'$ is normal. Am I missing something here? It seems like a very strong statement that I wouldn't necessarily expect to be true, but I can't think of a counterexample either.","I'm working on a problem that is easily solvable if I can prove the statement in the title. Here's what I've done so far: Given $\mathscr{F}$ a normal family of analytic functions, let $\mathscr{F}'=\{f':f\in \mathscr{F}\}$. Let $\{f_n'\}$ be a sequence in $\mathscr{F}'$. Then the corresponding sequence $\{f_n\}$ (unique up to constants) contains a subsequence that converges to some analytic $f$. This implies that the subsequence of derivatives converges to $f'$, so every sequence in $\mathscr{F}'$ has a subsequence that converges and $\mathscr{F}'$ is normal. Am I missing something here? It seems like a very strong statement that I wouldn't necessarily expect to be true, but I can't think of a counterexample either.",,['complex-analysis']
18,Fractal derivative of complex order and beyond,Fractal derivative of complex order and beyond,,"Is there some precise definition of ""complex (fractal) order derivative"" for all complex number? I am aware of the Riemann-Liouville fractional definition given here: Complex derivative but I would like to know if some mathematician has defined a complex order derivative valid without restrictions for all complex number z. I mean: Is a well-defined definition of such an object possible? I need some refereces about that topic. And related to this question would be the following question: What about a ""quaternionic order""/""octonionic order"" or maybe a ""matricial-order"" derivative? Can it be built somehow?Remark: I thought about this extended question when working with the ""matrix representation"" of complex numbers.","Is there some precise definition of ""complex (fractal) order derivative"" for all complex number? I am aware of the Riemann-Liouville fractional definition given here: Complex derivative but I would like to know if some mathematician has defined a complex order derivative valid without restrictions for all complex number z. I mean: Is a well-defined definition of such an object possible? I need some refereces about that topic. And related to this question would be the following question: What about a ""quaternionic order""/""octonionic order"" or maybe a ""matricial-order"" derivative? Can it be built somehow?Remark: I thought about this extended question when working with the ""matrix representation"" of complex numbers.",,"['complex-analysis', 'fractals', 'quaternions', 'fractional-calculus', 'octonions']"
19,What is the complex *algebraic* moduli of elliptic curves?,What is the complex *algebraic* moduli of elliptic curves?,,"It's well-known that $SL_2(\mathbb{Z}) \backslash \mathfrak{h}$ is a coarse moduli space for complex elliptic curves.  Thus, I would expect this to be related to the pullback of $\mathcal{M}_{ell} \rightarrow \mbox{Spec}(\mathbb{Z})$ along $\mbox{Spec}(\mathbb{C}) \rightarrow \mbox{Spec}(\mathbb{Z})$; for instance, I might expect this pullback to look something like $SL_2(\mathbb{Z}) \backslash \! \! \backslash \mathfrak{h}$.  However, I'm pretty sure that $\mathfrak{h}$ isn't actually a complex variety (basically by the Riemann mapping theorem), so at best this would admit a map from the analytification of the actual algebro-geometric pullback. The answer might be bound up in the $j$-invariant; over $\mathbb{C}$, this is a ""biholomorphism"" $SL_2(\mathbb{Z}) \backslash \mathfrak{h} \rightarrow \mathbb{C}$, i.e. it is a holomorphic bijection of complex orbifolds.  (Around the cone points $i \in \mathfrak{h}$ and $\omega=e^{2 \pi i /3}\in \mathfrak{h}$, the map is locally modeled by $z \mapsto z^2$ and by $z \mapsto z^3$, respectively.)  This has always been sort of mysterious to me, but I think the point is just that ""biholomorphism"" is the wrong notion of equivalence for complex orbifolds; it seems somehow besides the point to me that we happen to have such an equivalence.","It's well-known that $SL_2(\mathbb{Z}) \backslash \mathfrak{h}$ is a coarse moduli space for complex elliptic curves.  Thus, I would expect this to be related to the pullback of $\mathcal{M}_{ell} \rightarrow \mbox{Spec}(\mathbb{Z})$ along $\mbox{Spec}(\mathbb{C}) \rightarrow \mbox{Spec}(\mathbb{Z})$; for instance, I might expect this pullback to look something like $SL_2(\mathbb{Z}) \backslash \! \! \backslash \mathfrak{h}$.  However, I'm pretty sure that $\mathfrak{h}$ isn't actually a complex variety (basically by the Riemann mapping theorem), so at best this would admit a map from the analytification of the actual algebro-geometric pullback. The answer might be bound up in the $j$-invariant; over $\mathbb{C}$, this is a ""biholomorphism"" $SL_2(\mathbb{Z}) \backslash \mathfrak{h} \rightarrow \mathbb{C}$, i.e. it is a holomorphic bijection of complex orbifolds.  (Around the cone points $i \in \mathfrak{h}$ and $\omega=e^{2 \pi i /3}\in \mathfrak{h}$, the map is locally modeled by $z \mapsto z^2$ and by $z \mapsto z^3$, respectively.)  This has always been sort of mysterious to me, but I think the point is just that ""biholomorphism"" is the wrong notion of equivalence for complex orbifolds; it seems somehow besides the point to me that we happen to have such an equivalence.",,"['complex-analysis', 'algebraic-geometry', 'elliptic-curves']"
20,Bounded harmonic function is constant [closed],Bounded harmonic function is constant [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question Can you please help me to prove that bounded harmonic function is constant? Thanks a lot!","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question Can you please help me to prove that bounded harmonic function is constant? Thanks a lot!",,['complex-analysis']
21,How to define the exponential function without calculus? [duplicate],How to define the exponential function without calculus? [duplicate],,"This question already has answers here : An ""elementary"" approach to complex exponents? (3 answers) Closed 6 years ago . For fun, I would like to define the complex exponential function from these two properties: $\exp(0) = 1$ $\exp(z + w) = \exp(z) \exp(w)$ From here, I would like to find a way to compute values of $\exp(z)$, or at least to compute $\exp(1)$. So far, I found only two ways: Noting that $\exp'(z) = \exp(z)$ and solving the differential equation, which leads to $\int \frac{\exp'(z)}{\exp(z)} dz = \log(\exp(z)) + C = z$. Noting that $\exp'(z) = \exp(z)$, computing its Taylor series and checking that what I get is an entire function. The first approach is simply wrong because it involves logarithms, which I have not defined yet. The second approach looks much better. I haven't tried, but I guess I can find a way to manipulate the Taylor series to obtain the limit definition of $e$ and conclude that $\exp(1) = e$, which is my aim. However, I'm struggling to find another way that does not involve differentiation or limits in general. I would be happy to find a way to say $\exp(1) = e$ without calculus. I think that the irrational nature of $e$ forces me to use limits -- am I right?","This question already has answers here : An ""elementary"" approach to complex exponents? (3 answers) Closed 6 years ago . For fun, I would like to define the complex exponential function from these two properties: $\exp(0) = 1$ $\exp(z + w) = \exp(z) \exp(w)$ From here, I would like to find a way to compute values of $\exp(z)$, or at least to compute $\exp(1)$. So far, I found only two ways: Noting that $\exp'(z) = \exp(z)$ and solving the differential equation, which leads to $\int \frac{\exp'(z)}{\exp(z)} dz = \log(\exp(z)) + C = z$. Noting that $\exp'(z) = \exp(z)$, computing its Taylor series and checking that what I get is an entire function. The first approach is simply wrong because it involves logarithms, which I have not defined yet. The second approach looks much better. I haven't tried, but I guess I can find a way to manipulate the Taylor series to obtain the limit definition of $e$ and conclude that $\exp(1) = e$, which is my aim. However, I'm struggling to find another way that does not involve differentiation or limits in general. I would be happy to find a way to say $\exp(1) = e$ without calculus. I think that the irrational nature of $e$ forces me to use limits -- am I right?",,"['complex-analysis', 'exponential-function']"
22,Residue of high order pole,Residue of high order pole,,"I'm trying to compute the residue $\displaystyle\operatorname{Res}\left(\frac{1}{(z^2+1)^7},i\right)$. I know that there is the formula: $$\operatorname{Res}(f,z_0)=\frac{1}{(m-1)!}\lim_{z\rightarrow z_0 }[(z-z_0)^mf(z)]^{(m-1)}$$ for a pole with order $m$. But I'm pretty sure that I should not try to compute the 6th derivative of $\dfrac{1}{(z+i)^7}$. Is there another way to compute the residue beside this formula?","I'm trying to compute the residue $\displaystyle\operatorname{Res}\left(\frac{1}{(z^2+1)^7},i\right)$. I know that there is the formula: $$\operatorname{Res}(f,z_0)=\frac{1}{(m-1)!}\lim_{z\rightarrow z_0 }[(z-z_0)^mf(z)]^{(m-1)}$$ for a pole with order $m$. But I'm pretty sure that I should not try to compute the 6th derivative of $\dfrac{1}{(z+i)^7}$. Is there another way to compute the residue beside this formula?",,['complex-analysis']
23,When does a Möbius transformation map $\Im(z)>0$ to itself?,When does a Möbius transformation map  to itself?,\Im(z)>0,"Show Möbius transformation which maps $\Im(z)>0$ to itself iff $$ f(z)= \frac{az+b}{cz+d}\,,\,\,ad-bc>0$$ and $a,b,c,d$ are real.","Show Möbius transformation which maps $\Im(z)>0$ to itself iff $$ f(z)= \frac{az+b}{cz+d}\,,\,\,ad-bc>0$$ and $a,b,c,d$ are real.",,['complex-analysis']
24,Holomorphicity of the square of a function,Holomorphicity of the square of a function,,"I am trying to figure out whether the following statement is true. If $f$ is such that $f^2$ is holomorphic on an open set $\Omega \subset \mathbb{C}$ then $f$ itself is holomorphic on $\Omega$. My feeling would be that since the function mapping $z$ to $\sqrt{z}$ is multivalued that this should not be the case, but I am struggling to come up with a counterexample.","I am trying to figure out whether the following statement is true. If $f$ is such that $f^2$ is holomorphic on an open set $\Omega \subset \mathbb{C}$ then $f$ itself is holomorphic on $\Omega$. My feeling would be that since the function mapping $z$ to $\sqrt{z}$ is multivalued that this should not be the case, but I am struggling to come up with a counterexample.",,"['complex-analysis', 'examples-counterexamples', 'holomorphic-functions']"
25,how to show that power series is analytic inside the radius of convergence?,how to show that power series is analytic inside the radius of convergence?,,Let $f(z) = \sum a_n z^n$ be a power series with radius of convergence $R$. How do we show that $f$ is analytic in the circular region of radius $R$?,Let $f(z) = \sum a_n z^n$ be a power series with radius of convergence $R$. How do we show that $f$ is analytic in the circular region of radius $R$?,,"['complex-analysis', 'reference-request']"
26,Real integral by keyhole contour,Real integral by keyhole contour,,"Evaluate $$\int_0^\infty \frac{\log x \; dx}{x^{2} + 2x + 2}$$ by integrating a branch of $(\log z)^{2}/(z^{2} + 2z +2)$ along a keyhole contour. The thing I have trouble with is why I should be examining the square of the log - I guess it has something to do with ln x in fact NOT being the real part of log z, since log z is (or can be) defined on the entire negative real axis and ln x can't. But looking at the square would definitely not have been my first plan of attack :(","Evaluate $$\int_0^\infty \frac{\log x \; dx}{x^{2} + 2x + 2}$$ by integrating a branch of $(\log z)^{2}/(z^{2} + 2z +2)$ along a keyhole contour. The thing I have trouble with is why I should be examining the square of the log - I guess it has something to do with ln x in fact NOT being the real part of log z, since log z is (or can be) defined on the entire negative real axis and ln x can't. But looking at the square would definitely not have been my first plan of attack :(",,['complex-analysis']
27,Proving that $\left(1+\frac{z_{1}}{z_{2}}\right)\left(1+\frac{z_{2}}{z_{3}}\right)...\left(1+\frac{z_{n}}{z_{1}}\right)\in\mathbb R$,Proving that,\left(1+\frac{z_{1}}{z_{2}}\right)\left(1+\frac{z_{2}}{z_{3}}\right)...\left(1+\frac{z_{n}}{z_{1}}\right)\in\mathbb R,"I need to prove that $\left(1+\frac{z_{1}}{z_{2}}\right)\left(1+\frac{z_{2}}{z_{3}}\right)...\left(1+\frac{z_{n}}{z_{1}}\right)\in\mathbb R$ where $|z_{1}|=|z_{2}|=...=|z_{n}|=1$. This can be done relatively easily by induction, but I'm looking for  more elegant solution. Any ideas? Thanks!","I need to prove that $\left(1+\frac{z_{1}}{z_{2}}\right)\left(1+\frac{z_{2}}{z_{3}}\right)...\left(1+\frac{z_{n}}{z_{1}}\right)\in\mathbb R$ where $|z_{1}|=|z_{2}|=...=|z_{n}|=1$. This can be done relatively easily by induction, but I'm looking for  more elegant solution. Any ideas? Thanks!",,['complex-analysis']
28,The complex gamma function,The complex gamma function,,Show that $$\Gamma (z+1)=z\Gamma (z)$$ $\forall z\in \Bbb C$ except for $z=-n$ where $n\in \Bbb N$. I know that the gamma function is defined as $\Gamma (z)=\int_{0}^{\infty}e^{-t}t^{z-1}dt$  And I need to extend $\Gamma(z)$ to all of $\Bbb C-\{singular points\} $,Show that $$\Gamma (z+1)=z\Gamma (z)$$ $\forall z\in \Bbb C$ except for $z=-n$ where $n\in \Bbb N$. I know that the gamma function is defined as $\Gamma (z)=\int_{0}^{\infty}e^{-t}t^{z-1}dt$  And I need to extend $\Gamma(z)$ to all of $\Bbb C-\{singular points\} $,,"['complex-analysis', 'analysis', 'self-learning', 'gamma-function']"
29,Analytic functions close to $\bar{z}$,Analytic functions close to,\bar{z},Is there an analytic function $f\colon\Bbb{C}\longrightarrow \Bbb{C}$ such that for any $z$ on the unit circle $\lvert f(z) - \overline{z}\rvert < 1 $?,Is there an analytic function $f\colon\Bbb{C}\longrightarrow \Bbb{C}$ such that for any $z$ on the unit circle $\lvert f(z) - \overline{z}\rvert < 1 $?,,['complex-analysis']
30,How to show that the modulus of $\frac{z-w}{1-\bar{z}w}$ is always $1$?,How to show that the modulus of  is always ?,\frac{z-w}{1-\bar{z}w} 1,Let's suppose that $|z|<1$ and $|w|=1$. Show that the modulus of $\displaystyle \frac{z-w}{1-\bar{z}w}$ is always $1$. Some hint.,Let's suppose that $|z|<1$ and $|w|=1$. Show that the modulus of $\displaystyle \frac{z-w}{1-\bar{z}w}$ is always $1$. Some hint.,,[]
31,Relation between linearity and injectivity of an entire function [duplicate],Relation between linearity and injectivity of an entire function [duplicate],,This question already has answers here : Entire one-to-one functions are linear (8 answers) Closed 9 years ago . Given $f$ entire function on $\mathbb C$ and $f$ one-one. Is it true that $f$ is linear? At least among polynomials the only such functions are linear!,This question already has answers here : Entire one-to-one functions are linear (8 answers) Closed 9 years ago . Given $f$ entire function on $\mathbb C$ and $f$ one-one. Is it true that $f$ is linear? At least among polynomials the only such functions are linear!,,['complex-analysis']
32,If $f: \mathbb{C} \rightarrow \mathbb{C}$ is analytic and $\lim_{z \to \infty} f(z) = \infty$ show that $f$ is a polynomial,If  is analytic and  show that  is a polynomial,f: \mathbb{C} \rightarrow \mathbb{C} \lim_{z \to \infty} f(z) = \infty f,"I'm learning about complex analysis and need some help with this problem: If $f: \mathbb{C} \rightarrow \mathbb{C}$ is analytic and $\lim_{z \to \infty} f(z) = \infty$ show that $f$ is a polynomial (hint: consider the function $g(z) = f(1/z)$). Recall that poles are points where evaluating the function would entail dividing by zero. Therefore, since $\lim_{z \to \infty} f(z) = \infty$ this means that $\infty$ is a pole of $f$. How do I continue from here and make use of the hint? I should mention that this problem has already been asked by other members but I could not find any solution using the given hint.","I'm learning about complex analysis and need some help with this problem: If $f: \mathbb{C} \rightarrow \mathbb{C}$ is analytic and $\lim_{z \to \infty} f(z) = \infty$ show that $f$ is a polynomial (hint: consider the function $g(z) = f(1/z)$). Recall that poles are points where evaluating the function would entail dividing by zero. Therefore, since $\lim_{z \to \infty} f(z) = \infty$ this means that $\infty$ is a pole of $f$. How do I continue from here and make use of the hint? I should mention that this problem has already been asked by other members but I could not find any solution using the given hint.",,"['complex-analysis', 'analyticity', 'laurent-series']"
33,Complex Analysis Book with Good Exercises?,Complex Analysis Book with Good Exercises?,,"I have studied a bit of complex analysis in the past, but I realized that I couldn't really get into it because I didn't really see the motivation; I was spending a lot of time trying to understand proofs, and even though the theorems seemed pretty cool, I never really got to use them. Could you please recommend me some books with applications of Complex Analysis? I don't mean applications to science or engineering, I just mean applications of the theorems in first year Complex Analysis, aka a book with good, interesting problems, not necessarily a book with formal proofs of everything (though that's a bonus). Thank you very much.","I have studied a bit of complex analysis in the past, but I realized that I couldn't really get into it because I didn't really see the motivation; I was spending a lot of time trying to understand proofs, and even though the theorems seemed pretty cool, I never really got to use them. Could you please recommend me some books with applications of Complex Analysis? I don't mean applications to science or engineering, I just mean applications of the theorems in first year Complex Analysis, aka a book with good, interesting problems, not necessarily a book with formal proofs of everything (though that's a bonus). Thank you very much.",,"['complex-analysis', 'reference-request', 'book-recommendation']"
34,"If $f=u+iv$ is an entire function such that $u^2\geq v^2,$ then $f$ is constant",If  is an entire function such that  then  is constant,"f=u+iv u^2\geq v^2, f","Let $f=u+iv$ be an entire function such that $u^2(z) \geq v^2(z), \forall z \in  \mathbb{C}.$ Could anyone advise me how to prove $f \equiv$ constant $?$ Hints will suffice. Thank you.","Let $f=u+iv$ be an entire function such that $u^2(z) \geq v^2(z), \forall z \in  \mathbb{C}.$ Could anyone advise me how to prove $f \equiv$ constant $?$ Hints will suffice. Thank you.",,"['complex-analysis', 'analysis', 'analyticity']"
35,Complex roots of $z^6 + z^3 + 1 = 0$,Complex roots of,z^6 + z^3 + 1 = 0,"The equation I'm trying to solve is $f(z) = 0$ where $$f(z) = z^6 + z^3 + 1$$ I already tried the following: randomly throwing in complex numbers and real numbers, rational root theorem, banging my head on the table, and other painful things. Any ideas where I can start? EDIT: Answer Following Potato's hint, we have that if we set $y = z^3$ the resulting quadratic would be $y^2 + y + 1 = 0$, by which we can use the quadratic formula, so that $$y = \frac{-b \pm \sqrt{b^2 - 4ac}}{2a}$$ And then take the cube roots of the solutions. Thanks guys.","The equation I'm trying to solve is $f(z) = 0$ where $$f(z) = z^6 + z^3 + 1$$ I already tried the following: randomly throwing in complex numbers and real numbers, rational root theorem, banging my head on the table, and other painful things. Any ideas where I can start? EDIT: Answer Following Potato's hint, we have that if we set $y = z^3$ the resulting quadratic would be $y^2 + y + 1 = 0$, by which we can use the quadratic formula, so that $$y = \frac{-b \pm \sqrt{b^2 - 4ac}}{2a}$$ And then take the cube roots of the solutions. Thanks guys.",,"['complex-analysis', 'complex-numbers']"
36,"Complex Analysis, Entire functions","Complex Analysis, Entire functions",,"Prove if $f$ and $g$ are entire and $e^f+e^g=1$, then $f$ and $g$ are constant. I believe the simplest way would be to use Louiville's theorem by using Pick's theorem but I am not sure on how to go about this.","Prove if $f$ and $g$ are entire and $e^f+e^g=1$, then $f$ and $g$ are constant. I believe the simplest way would be to use Louiville's theorem by using Pick's theorem but I am not sure on how to go about this.",,['complex-analysis']
37,Derivatives of the Riemann zeta function at $s=0$,Derivatives of the Riemann zeta function at,s=0,"It's a curious fact that for $n>0$, $\zeta^{(n)}(0)\approx -n!$. Apostol gave a table for $\frac{\zeta^{(n)}(0)}{n!}$, among other results on $\zeta^{(n)}(0)$ . the sequence : $$\delta_{n}=\left | \zeta^{(n)}(0)+n! \right|$$ seems to be fast decreasing. What is the upper bound of $\delta_{n}$ ?? Edit: Following the logic in Apostol's paper, $\zeta(s)-\frac{1}{s-1}$ is holomorphic. Thus: $$\zeta(s)-\frac{1}{s-1}=:A(s)=\sum_{n=0}^{\infty}\frac{A^{(n)}(0)}{n!}s^{n}$$ where : $$\left|A^{(n)}(0)\right|=\delta_{n}=\left|\zeta^{(n)}(0)+n!\right|$$ the expansion converges everywhere. Therefore : $$\limsup_{n\rightarrow\infty}\left(\frac{\delta_{n}}{n!}\right)^{\frac{1}{n}}=0$$ To be exact, I am interested in the limit : $$\limsup_{n\rightarrow\infty}\left(\frac{\delta_{n}}{n}\right)^{\frac{1}{n}}$$ hence the question !!","It's a curious fact that for $n>0$, $\zeta^{(n)}(0)\approx -n!$. Apostol gave a table for $\frac{\zeta^{(n)}(0)}{n!}$, among other results on $\zeta^{(n)}(0)$ . the sequence : $$\delta_{n}=\left | \zeta^{(n)}(0)+n! \right|$$ seems to be fast decreasing. What is the upper bound of $\delta_{n}$ ?? Edit: Following the logic in Apostol's paper, $\zeta(s)-\frac{1}{s-1}$ is holomorphic. Thus: $$\zeta(s)-\frac{1}{s-1}=:A(s)=\sum_{n=0}^{\infty}\frac{A^{(n)}(0)}{n!}s^{n}$$ where : $$\left|A^{(n)}(0)\right|=\delta_{n}=\left|\zeta^{(n)}(0)+n!\right|$$ the expansion converges everywhere. Therefore : $$\limsup_{n\rightarrow\infty}\left(\frac{\delta_{n}}{n!}\right)^{\frac{1}{n}}=0$$ To be exact, I am interested in the limit : $$\limsup_{n\rightarrow\infty}\left(\frac{\delta_{n}}{n}\right)^{\frac{1}{n}}$$ hence the question !!",,"['complex-analysis', 'inequality', 'special-functions', 'riemann-zeta']"
38,Harmonic conjugate of $\ln|z|$ in $\mathbb C \setminus \{0\}$,Harmonic conjugate of  in,\ln|z| \mathbb C \setminus \{0\},"How I prove that $u(z)=\ln |z|$ has no harmonic conjugate in $\mathbb C \setminus \{0\}$ ? I found from C-R equation that $v(z)=\arctan(y/x)$ , which is defined in  $\mathbb C \setminus \{0\}$ . So why it is not a harmonic conjugate of $u$ ?","How I prove that $u(z)=\ln |z|$ has no harmonic conjugate in $\mathbb C \setminus \{0\}$ ? I found from C-R equation that $v(z)=\arctan(y/x)$ , which is defined in  $\mathbb C \setminus \{0\}$ . So why it is not a harmonic conjugate of $u$ ?",,"['complex-analysis', 'complex-numbers']"
39,Laurent series for $1/(e^z-1)$,Laurent series for,1/(e^z-1),Trying to compute the first five coefficients of the Laurent series for $$\frac{1}{e^z-1}$$ centered at the point $0$. I'm not seeing a way to use the geometric series due to the exponential. Any ideas?,Trying to compute the first five coefficients of the Laurent series for $$\frac{1}{e^z-1}$$ centered at the point $0$. I'm not seeing a way to use the geometric series due to the exponential. Any ideas?,,"['complex-analysis', 'laurent-series']"
40,Complex integral help involving $\sin^{2n}(x)$,Complex integral help involving,\sin^{2n}(x),Show that $$\int_0^\pi \sin^{2n} \theta d\theta=\dfrac{\pi(2n)!}{(2^n n!)^2} $$ So far I have came up with: $$\sin^{2n} \theta = \left(\dfrac {z-z^{-1}}{2i} \right)^{2n}$$ and I know I should be using: $$(a+b)^n=\sum_{k=0}^n \dfrac{n!}{(n-k)!k!}a^kb^{n-k}$$ but I'm not sure how to get the conclusion. Any help will be greatly appreciated.,Show that $$\int_0^\pi \sin^{2n} \theta d\theta=\dfrac{\pi(2n)!}{(2^n n!)^2} $$ So far I have came up with: $$\sin^{2n} \theta = \left(\dfrac {z-z^{-1}}{2i} \right)^{2n}$$ and I know I should be using: $$(a+b)^n=\sum_{k=0}^n \dfrac{n!}{(n-k)!k!}a^kb^{n-k}$$ but I'm not sure how to get the conclusion. Any help will be greatly appreciated.,,"['complex-analysis', 'definite-integrals']"
41,Fixed points of a holomorphic map on a simply connected domain,Fixed points of a holomorphic map on a simply connected domain,,"Given a holomorphic map $f: \Omega\to \Omega$, where $\Omega$ is a simply-connected domain in $\mathbb{C}$, is the number of fixed points at most $1$ if $f$ is not the identity map? How many could they be? By the Riemann Mapping Theorem, I am able to reduce the problem to finding a fixed point of a holomorphic map from the unit disc to itself. How should I proceed? Thanks.","Given a holomorphic map $f: \Omega\to \Omega$, where $\Omega$ is a simply-connected domain in $\mathbb{C}$, is the number of fixed points at most $1$ if $f$ is not the identity map? How many could they be? By the Riemann Mapping Theorem, I am able to reduce the problem to finding a fixed point of a holomorphic map from the unit disc to itself. How should I proceed? Thanks.",,['complex-analysis']
42,What is the radius of convergence of $\sum z^{n!}$?,What is the radius of convergence of ?,\sum z^{n!},"How to find the radius of convergence of $\sum z^{n!}$? I'm used to applying the ratio test to power series of the form $\sum a_{n}z^{n}$, but for a different power of $z$, I am a bit stumped. What about $\sum z^{2n+a}$ for another example? Where $a\in \mathbb{R}$.","How to find the radius of convergence of $\sum z^{n!}$? I'm used to applying the ratio test to power series of the form $\sum a_{n}z^{n}$, but for a different power of $z$, I am a bit stumped. What about $\sum z^{2n+a}$ for another example? Where $a\in \mathbb{R}$.",,"['complex-analysis', 'convergence-divergence', 'power-series']"
43,Does the complex exponential function $\exp(z)$ have an axiomatic definition?,Does the complex exponential function  have an axiomatic definition?,\exp(z),"It is known that the real exponential function $e^{(\cdot)}:\mathbb{R}\rightarrow\mathbb{R}$ can be characterized as the unique real function satisfying these three properties: $e^{1}=e$ , where $e=\lim\limits_{n\to\infty}\left(1+\frac{1}{n}\right)^n$ . $e^{x+y}=e^{x}e^{y}$ for all $x,y\in\mathbb{R}$ For some real number $x_0$ , $e^{(\cdot)}$ is continuous at $x_0$ , that is $\lim\limits_{x\to x_0}e^{x}=e^{x_0}$ The complex exponential function $e^{(\cdot)}:\mathbb{C}\rightarrow\mathbb{C}$ is usually defined by $e^{z}=\sum_{n=0}^{\infty}\frac{z^n}{n!}$ . I'm wondering if it can be characterized using axioms analogous to the ones above. Context : Lately, I've been wondering whether the identity $e^{i\pi}+1=0$ is as ""beautiful"" or ""remarkable"" as people often make it out to be. To me, it seems like it is not a fascinating result so much as a consequence of the definition $$e^{z}=\sum_{n=0}^{\infty}\frac{z^n}{n!}$$ and the series expansions of $\sin$ and $\cos$ . Nonetheless, I often hear people saying things like "" $e^{i\pi}+1=0$ relates the constants $e$ , $\pi$ , $i$ , $1$ and $0$ "", leading me to wonder if there's a deeper connection I have not discovered yet. Reflecting on these thoughts, I realized that $e^z$ having an axiomatic characterization lends credence to the idea that $e$ is special in relation to the identity $e^{i\pi}+1=0$ , precisely because it is the only number satisfying <insert property 1 analogue here>. I apologize if my context is unclear. If you need clarification or have useful edits, please feel free to leave a comment or edit my post.","It is known that the real exponential function can be characterized as the unique real function satisfying these three properties: , where . for all For some real number , is continuous at , that is The complex exponential function is usually defined by . I'm wondering if it can be characterized using axioms analogous to the ones above. Context : Lately, I've been wondering whether the identity is as ""beautiful"" or ""remarkable"" as people often make it out to be. To me, it seems like it is not a fascinating result so much as a consequence of the definition and the series expansions of and . Nonetheless, I often hear people saying things like "" relates the constants , , , and "", leading me to wonder if there's a deeper connection I have not discovered yet. Reflecting on these thoughts, I realized that having an axiomatic characterization lends credence to the idea that is special in relation to the identity , precisely because it is the only number satisfying <insert property 1 analogue here>. I apologize if my context is unclear. If you need clarification or have useful edits, please feel free to leave a comment or edit my post.","e^{(\cdot)}:\mathbb{R}\rightarrow\mathbb{R} e^{1}=e e=\lim\limits_{n\to\infty}\left(1+\frac{1}{n}\right)^n e^{x+y}=e^{x}e^{y} x,y\in\mathbb{R} x_0 e^{(\cdot)} x_0 \lim\limits_{x\to x_0}e^{x}=e^{x_0} e^{(\cdot)}:\mathbb{C}\rightarrow\mathbb{C} e^{z}=\sum_{n=0}^{\infty}\frac{z^n}{n!} e^{i\pi}+1=0 e^{z}=\sum_{n=0}^{\infty}\frac{z^n}{n!} \sin \cos e^{i\pi}+1=0 e \pi i 1 0 e^z e e^{i\pi}+1=0","['complex-analysis', 'exponential-function', 'eulers-number-e']"
44,What kind of singularity is possessed by $z^{-1/2}$?,What kind of singularity is possessed by ?,z^{-1/2},"I'm learning about singularities [Stein Sharkarchi Chapter 3], and this question popped up in my mind: What kind of singularity is $f(z):= z^{-\frac{1}{2}}$ at $0$ ? It doesn't seem to fall into either of these three categories: Removable singularity: It's clearly not a removable singularity as $\lim_{z \rightarrow 0} |f(z)| \rightarrow \infty$ Essential singularity: By Casorati-Weierstrass it's not essential singularity either since the image of the unit disc minus the origin is very clearly not dense (it completely misses a ball of radious $.9999$ centered at the origin) Pole : It's not a pole either since it contradicts this theorem because $z^nf(z)$ vanishes at $0$ for all positive integer $n$ : If $f$ has a pole at $0$ then for a neighbourhood of $0$ there's a positive unique  integer $n$ such that $f(z) = h(z) z^{-n}$ and $h(z)$ is holomorphic and nonvanishing in the neighbourhood So what's this singularity ? This is perplexing me. I feel this may have something to do with the nonuniqueness of $f(z)$ around $0$ but then I know nothing about branch cuts to add substance to my intuition.","I'm learning about singularities [Stein Sharkarchi Chapter 3], and this question popped up in my mind: What kind of singularity is at ? It doesn't seem to fall into either of these three categories: Removable singularity: It's clearly not a removable singularity as Essential singularity: By Casorati-Weierstrass it's not essential singularity either since the image of the unit disc minus the origin is very clearly not dense (it completely misses a ball of radious centered at the origin) Pole : It's not a pole either since it contradicts this theorem because vanishes at for all positive integer : If has a pole at then for a neighbourhood of there's a positive unique  integer such that and is holomorphic and nonvanishing in the neighbourhood So what's this singularity ? This is perplexing me. I feel this may have something to do with the nonuniqueness of around but then I know nothing about branch cuts to add substance to my intuition.",f(z):= z^{-\frac{1}{2}} 0 \lim_{z \rightarrow 0} |f(z)| \rightarrow \infty .9999 z^nf(z) 0 n f 0 0 n f(z) = h(z) z^{-n} h(z) f(z) 0,"['complex-analysis', 'singularity']"
45,How to remember Stolz Angle correctly,How to remember Stolz Angle correctly,,"The Stolz angle is a condition used in Abel's Theorem: $$|1-z|\leq M(1-|z|)$$ Q1) How do I intuitively remember (and understand this)? Q2) In particular, is there a quick way to see that $$(1-|z|)\leq M|1-z|$$ is the wrong condition? Thanks for any help.","The Stolz angle is a condition used in Abel's Theorem: $$|1-z|\leq M(1-|z|)$$ Q1) How do I intuitively remember (and understand this)? Q2) In particular, is there a quick way to see that $$(1-|z|)\leq M|1-z|$$ is the wrong condition? Thanks for any help.",,['complex-analysis']
46,Find the value of $(1-z)\left(1+\frac{z}{2}\right)\left(1-\frac{z}{3}\right)\left(1+\frac{z}{4}\right)\cdots$.,Find the value of .,(1-z)\left(1+\frac{z}{2}\right)\left(1-\frac{z}{3}\right)\left(1+\frac{z}{4}\right)\cdots,"Show that: $$(1-z)\left(1+\frac{z}{2}\right)\left(1-\frac{z}{3}\right)\left(1+\frac{z}{4}\right)\cdots = \dfrac{\sqrt{\pi}}{\Gamma\left(1+\dfrac{z}{2}\right)\Gamma\left(\dfrac{1}{2}-\dfrac{z}{2}\right)}.$$ By the duplication theorem and $\Gamma(z+1)=z\,\Gamma(z)$, we have: $$\dfrac{\sqrt{\pi}}{\Gamma\left(1+\dfrac{z}{2}\right)\Gamma\left(\dfrac{1}{2}-\dfrac{z}{2}\right)}=\dfrac{\Gamma\left(-\dfrac{z}{2}\right)}{z\,\Gamma\left(-z\right)\Gamma\left(\dfrac{z}{2}\right)} \cdot 2^{-z}.$$ Using the definition $\Gamma\left(z\right) = \dfrac{1}{z}\prod_{k=1}^\infty \left(1+\dfrac{1}{k}\right)^z \left(1+\dfrac{z}{k}\right)^{-1}$, and simplifying terms, we obtain:$$\dfrac{\sqrt{\pi}}{\Gamma\left(1+\dfrac{z}{2}\right)\Gamma\left(\dfrac{1}{2}-\dfrac{z}{2}\right)}=2^{-z}(1-z)\left(1+\frac{z}{2}\right)\left(1-\frac{z}{3}\right)\left(1+\frac{z}{4}\right)\cdots .$$ How can I get rid of the $2^{-z}$, and am I going about this the right way? Cheers!","Show that: $$(1-z)\left(1+\frac{z}{2}\right)\left(1-\frac{z}{3}\right)\left(1+\frac{z}{4}\right)\cdots = \dfrac{\sqrt{\pi}}{\Gamma\left(1+\dfrac{z}{2}\right)\Gamma\left(\dfrac{1}{2}-\dfrac{z}{2}\right)}.$$ By the duplication theorem and $\Gamma(z+1)=z\,\Gamma(z)$, we have: $$\dfrac{\sqrt{\pi}}{\Gamma\left(1+\dfrac{z}{2}\right)\Gamma\left(\dfrac{1}{2}-\dfrac{z}{2}\right)}=\dfrac{\Gamma\left(-\dfrac{z}{2}\right)}{z\,\Gamma\left(-z\right)\Gamma\left(\dfrac{z}{2}\right)} \cdot 2^{-z}.$$ Using the definition $\Gamma\left(z\right) = \dfrac{1}{z}\prod_{k=1}^\infty \left(1+\dfrac{1}{k}\right)^z \left(1+\dfrac{z}{k}\right)^{-1}$, and simplifying terms, we obtain:$$\dfrac{\sqrt{\pi}}{\Gamma\left(1+\dfrac{z}{2}\right)\Gamma\left(\dfrac{1}{2}-\dfrac{z}{2}\right)}=2^{-z}(1-z)\left(1+\frac{z}{2}\right)\left(1-\frac{z}{3}\right)\left(1+\frac{z}{4}\right)\cdots .$$ How can I get rid of the $2^{-z}$, and am I going about this the right way? Cheers!",,"['complex-analysis', 'infinite-product']"
47,integration of $\int_0^{2\pi} cos^{2n}(t)dt$,integration of,\int_0^{2\pi} cos^{2n}(t)dt,"Show that for any $n \in \mathbb{N}$,  $$\frac{1}{2\pi}\int_0^{2\pi}\cos^{2n}(t)dt = \frac{1 \cdot 3 \cdot 5 \cdots(2n-1)}{2 \cdot 4 \cdot 6 \cdots 2n}$$ To solve this problem, I was thinking that I would let $\cos(t)= \frac{e^{it} + e^{-it}}{2}$, then the integral will have the form:  $$\frac{1}{2\pi}\int_0^{2\pi} \left (\frac{e^{it} + e^{-it}}{2} \right)^{2n}dt$$ From this point, I was stuck. So, would anyone please help me to walk through this problem.","Show that for any $n \in \mathbb{N}$,  $$\frac{1}{2\pi}\int_0^{2\pi}\cos^{2n}(t)dt = \frac{1 \cdot 3 \cdot 5 \cdots(2n-1)}{2 \cdot 4 \cdot 6 \cdots 2n}$$ To solve this problem, I was thinking that I would let $\cos(t)= \frac{e^{it} + e^{-it}}{2}$, then the integral will have the form:  $$\frac{1}{2\pi}\int_0^{2\pi} \left (\frac{e^{it} + e^{-it}}{2} \right)^{2n}dt$$ From this point, I was stuck. So, would anyone please help me to walk through this problem.",,"['complex-analysis', 'analysis']"
48,Computing the Laurent series of $e^{z+\frac{1}{z}}$,Computing the Laurent series of,e^{z+\frac{1}{z}},"I'm really stuck on this, and I have no idea how to start. Writing it at $f(z)=e^z e^{\frac{1}{z}}$ and their expansions didn't really give any insight. I am aware it is possible to multiply the series of these functions, but this was not covered in this course. I am allowed to assume $f$ is holomorphic on $\mathbb{C}\setminus\{0\}$.","I'm really stuck on this, and I have no idea how to start. Writing it at $f(z)=e^z e^{\frac{1}{z}}$ and their expansions didn't really give any insight. I am aware it is possible to multiply the series of these functions, but this was not covered in this course. I am allowed to assume $f$ is holomorphic on $\mathbb{C}\setminus\{0\}$.",,"['complex-analysis', 'laurent-series']"
49,Showing Weierstrass elliptic function has periods,Showing Weierstrass elliptic function has periods,,"Let $$\wp(z)=\frac{1}{z^2}+\sum_{w \in \Lambda^*} \left[\frac{1}{(z+w)^2}-\frac{1}{w^2}\right] $$ be the Weierstrass elliptic function with $\Lambda=\Bbb{Z}+\Bbb{Z}\tau$, $\Lambda^*=\Lambda-0$. I want to show that $\wp(z+w)=\wp(z)$ whenever $w \in \Lambda$, without using differentiation. [Stein, Complex Analysis p.279] Suggested hint: For large $R$, $\wp(z)=\wp^R(z)+O(1/R)$ where   $$\wp^R(z)=\frac{1}{z^2}+\sum_{0<|w|<R}  \left[\frac{1}{(z+w)^2}-\frac{1}{w^2}\right]$$ Also observe that   $\wp^R(z+1)-\wp^R(z)$ and $\wp^R(z+\tau)-\wp^R(z)$ are   $O(\sum_{R-c<|w|<R+c} |w|^{-2})=O(1/R)$ But I can't understand the hint. I know that for $|z|<R$, $\sum_{|w|>2R}  \left[\frac{1}{(z+w)^2}-\frac{1}{w^2}\right]$ is $O(1/|w|^3)$ (uniformly) so defines a holomorphic function in $|z|<R$. But is the above hint also correct? $O(1/R)$ is ambiguous and restriction of $z$ seems to needed. So if I understood $\wp^R(z)$ as $$\wp^R(z)=\frac{1}{z^2}+\sum_{0<|w|<2R}  \left[\frac{1}{(z+w)^2}-\frac{1}{w^2}\right] \quad (|z|<R)$$ But still don't know how to compare $\wp^R(z+1)-\wp^R(z)$. What should I do?","Let $$\wp(z)=\frac{1}{z^2}+\sum_{w \in \Lambda^*} \left[\frac{1}{(z+w)^2}-\frac{1}{w^2}\right] $$ be the Weierstrass elliptic function with $\Lambda=\Bbb{Z}+\Bbb{Z}\tau$, $\Lambda^*=\Lambda-0$. I want to show that $\wp(z+w)=\wp(z)$ whenever $w \in \Lambda$, without using differentiation. [Stein, Complex Analysis p.279] Suggested hint: For large $R$, $\wp(z)=\wp^R(z)+O(1/R)$ where   $$\wp^R(z)=\frac{1}{z^2}+\sum_{0<|w|<R}  \left[\frac{1}{(z+w)^2}-\frac{1}{w^2}\right]$$ Also observe that   $\wp^R(z+1)-\wp^R(z)$ and $\wp^R(z+\tau)-\wp^R(z)$ are   $O(\sum_{R-c<|w|<R+c} |w|^{-2})=O(1/R)$ But I can't understand the hint. I know that for $|z|<R$, $\sum_{|w|>2R}  \left[\frac{1}{(z+w)^2}-\frac{1}{w^2}\right]$ is $O(1/|w|^3)$ (uniformly) so defines a holomorphic function in $|z|<R$. But is the above hint also correct? $O(1/R)$ is ambiguous and restriction of $z$ seems to needed. So if I understood $\wp^R(z)$ as $$\wp^R(z)=\frac{1}{z^2}+\sum_{0<|w|<2R}  \left[\frac{1}{(z+w)^2}-\frac{1}{w^2}\right] \quad (|z|<R)$$ But still don't know how to compare $\wp^R(z+1)-\wp^R(z)$. What should I do?",,"['complex-analysis', 'elliptic-functions']"
50,Conformal Map from Vertical Strip to Unit Disc,Conformal Map from Vertical Strip to Unit Disc,,"I haven't found a similar question on here, though I suspect the question may be rather well-covered. I want to find a conformal map from the vertical strip $\{z:-1<Re(z)<1\}$ onto the unit disc. Under the exponential map the region is taken to the annulus with radii $e$ and $e^{-1}$, but I'm not sure how useful this will be. Can anyone advise on what the conformal map may be? Thanks.","I haven't found a similar question on here, though I suspect the question may be rather well-covered. I want to find a conformal map from the vertical strip $\{z:-1<Re(z)<1\}$ onto the unit disc. Under the exponential map the region is taken to the annulus with radii $e$ and $e^{-1}$, but I'm not sure how useful this will be. Can anyone advise on what the conformal map may be? Thanks.",,"['geometry', 'complex-analysis', 'conformal-geometry']"
51,Evaluate $\int_{0}^{\pi} \frac{d\theta}{(2+\cos\theta)^2}$,Evaluate,\int_{0}^{\pi} \frac{d\theta}{(2+\cos\theta)^2},"How can one evaluate $\displaystyle\int_{0}^{\pi} \frac{d\theta}{(2+\cos\theta)^2}$? My attempt: $$\int_{0}^{\pi} \frac{d\theta}{(2+\cos\theta)^2} =  \frac{1}{2}\int_{0}^{2\pi} \frac{d\theta}{(2+\cos\theta)^2}$$ To find the singularity, I solve: $ (2+\cos\theta)^2 = 0 $ and therefore, $\cos\theta =  -2$. Substituting: $\cos z = \frac{e^{iz} + e^{-iz}}{2} = \frac{z + \frac{1}{z}}{2}$, I find that $z = -2 + \sqrt{3} $ is the singular point that lies in the unit circle $|z| = 1$. From this point, I have little idea how to go about solving this problem. I know I have to find the residue and then just sum them but to get the expression that would cancel out the pole is where I am currently stuck.","How can one evaluate $\displaystyle\int_{0}^{\pi} \frac{d\theta}{(2+\cos\theta)^2}$? My attempt: $$\int_{0}^{\pi} \frac{d\theta}{(2+\cos\theta)^2} =  \frac{1}{2}\int_{0}^{2\pi} \frac{d\theta}{(2+\cos\theta)^2}$$ To find the singularity, I solve: $ (2+\cos\theta)^2 = 0 $ and therefore, $\cos\theta =  -2$. Substituting: $\cos z = \frac{e^{iz} + e^{-iz}}{2} = \frac{z + \frac{1}{z}}{2}$, I find that $z = -2 + \sqrt{3} $ is the singular point that lies in the unit circle $|z| = 1$. From this point, I have little idea how to go about solving this problem. I know I have to find the residue and then just sum them but to get the expression that would cancel out the pole is where I am currently stuck.",,"['complex-analysis', 'contour-integration']"
52,Why does $\lim_{n\to\infty} z_n=A$ imply $\lim_{n\to\infty}\frac{1}{n}(z_1+\cdots+z_n)=A$?,Why does  imply ?,\lim_{n\to\infty} z_n=A \lim_{n\to\infty}\frac{1}{n}(z_1+\cdots+z_n)=A,"I'm self-studying a bit of complex analysis, and I'm attempting to figure out the following. Suppose $\lim_{n\to\infty}z_n=A$. How can I show that $$ \lim_{n\to\infty}\frac{1}{n}(z_1+\cdots+z_n)=A. $$ Is there a clever way to write the limit to make it more approachable? Thank you.","I'm self-studying a bit of complex analysis, and I'm attempting to figure out the following. Suppose $\lim_{n\to\infty}z_n=A$. How can I show that $$ \lim_{n\to\infty}\frac{1}{n}(z_1+\cdots+z_n)=A. $$ Is there a clever way to write the limit to make it more approachable? Thank you.",,['complex-analysis']
53,Doing Complex Analysis on the Riemann Sphere?,Doing Complex Analysis on the Riemann Sphere?,,"Everyone: This is my first post. Sorry if I break some protocol. I do know some complex analysis and how to tell when a function from $\mathbb C \rightarrow\mathbb C$ . But I am confused when I hear of analytic or meromorphic functions from (sorry, don't know the notation) Riemann Sphere to itself. I think this has something to see with Algebraic Geometry and Varieties, of which I know very little. Would someone please expand on how one determines if/when a function from the Riemann Sphere to itself is meromorphic or analytic? I have seen some Differential Geometry in which we compose functions with chart maps to determine if a function (from a real manifold to another real manifold) is differentiable, or $C^k$. Is that what we do for complex functions, and, if so, are there some theorems to avoid doing the chart composition? Thanks for any help.","Everyone: This is my first post. Sorry if I break some protocol. I do know some complex analysis and how to tell when a function from $\mathbb C \rightarrow\mathbb C$ . But I am confused when I hear of analytic or meromorphic functions from (sorry, don't know the notation) Riemann Sphere to itself. I think this has something to see with Algebraic Geometry and Varieties, of which I know very little. Would someone please expand on how one determines if/when a function from the Riemann Sphere to itself is meromorphic or analytic? I have seen some Differential Geometry in which we compose functions with chart maps to determine if a function (from a real manifold to another real manifold) is differentiable, or $C^k$. Is that what we do for complex functions, and, if so, are there some theorems to avoid doing the chart composition? Thanks for any help.",,"['complex-analysis', 'algebraic-geometry', 'complex-geometry']"
54,What object exactly is $\frac{d \bar{z}}{dz}$?,What object exactly is ?,\frac{d \bar{z}}{dz},"I know very basic differential geometry, that is i am aware of definitions of tangent spaces and differential forms, and I believe I know what is meant by $dz$ and $d \bar{z}$ . In a book I'm reading on complex dynamics i found the notation $\frac{d \bar{z}}{dz}$ , what kind of object is that? Differential forms are linear functionals, as far as i understand division of one by another does not make sense. EDIT: After getting a few replies, which were helpful in their own right, I realized i should have included some more context. The context for this question is the document ""Complex dynamics and renormalization"" by Curtis McMullen. On page 47 there is the sentence: ""A line field is the same as a Beltrami differential $\mu = \mu (z) d \bar{z} / dz$ "". I was curious about the notation i.e. what is $d \bar{z}/dz$ .","I know very basic differential geometry, that is i am aware of definitions of tangent spaces and differential forms, and I believe I know what is meant by and . In a book I'm reading on complex dynamics i found the notation , what kind of object is that? Differential forms are linear functionals, as far as i understand division of one by another does not make sense. EDIT: After getting a few replies, which were helpful in their own right, I realized i should have included some more context. The context for this question is the document ""Complex dynamics and renormalization"" by Curtis McMullen. On page 47 there is the sentence: ""A line field is the same as a Beltrami differential "". I was curious about the notation i.e. what is .",dz d \bar{z} \frac{d \bar{z}}{dz} \mu = \mu (z) d \bar{z} / dz d \bar{z}/dz,"['complex-analysis', 'differential-geometry', 'notation', 'differential-forms']"
55,Why does the criterion for convergence of a power series not imply every series with bounded terms converges?,Why does the criterion for convergence of a power series not imply every series with bounded terms converges?,,"I am reading Complex Made Simple by David C. Ullrich. There is a result from which I am deducing bogus conclusions, so I must be misunderstanding it somehow: Lemma 1.0. Suppose $(c_n)_{n = 0}^{\infty}$ is a sequence of complex numbers, and define $R \in [0, \infty]$ by $$R = \sup \{r \ge 0: \text{the sequence } (c_nr^n) \text{ is bounded}\}.$$ Then the power series $\sum_{n=0}^{\infty}c_n(z-z_0)^n$ converges absolutely and uniformly on every compact subset of the disk $D(z_0, R)$ and diverges at every point $z$ with $|z-z_0|>R$ . My bogus conclusion: Let $c_n$ be a sequence of complex numbers and suppose that $c_n r^n$ is bounded. Then $\sum_{n=0}^{\infty} c_n r^n$ converges. My reasoning: Let $c_n$ be any sequence of complex numbers. The series $\sum_{n=0}^{\infty}c_n(z-z_0)^n$ converges absolutely whenever $|z - z_0|<R$ , so $\sum_{n=0}^{\infty}c_nr^n$ converges whenever $r < R$ , so $\sum_{n=0}^{\infty}c_nr^n$ converges whenever $c_n r^n$ is bounded.","I am reading Complex Made Simple by David C. Ullrich. There is a result from which I am deducing bogus conclusions, so I must be misunderstanding it somehow: Lemma 1.0. Suppose is a sequence of complex numbers, and define by Then the power series converges absolutely and uniformly on every compact subset of the disk and diverges at every point with . My bogus conclusion: Let be a sequence of complex numbers and suppose that is bounded. Then converges. My reasoning: Let be any sequence of complex numbers. The series converges absolutely whenever , so converges whenever , so converges whenever is bounded.","(c_n)_{n = 0}^{\infty} R \in [0, \infty] R = \sup \{r \ge 0: \text{the sequence } (c_nr^n) \text{ is bounded}\}. \sum_{n=0}^{\infty}c_n(z-z_0)^n D(z_0, R) z |z-z_0|>R c_n c_n r^n \sum_{n=0}^{\infty} c_n r^n c_n \sum_{n=0}^{\infty}c_n(z-z_0)^n |z - z_0|<R \sum_{n=0}^{\infty}c_nr^n r < R \sum_{n=0}^{\infty}c_nr^n c_n r^n","['complex-analysis', 'convergence-divergence', 'power-series']"
56,How to prove Liouville's theorem for subharmonic functions,How to prove Liouville's theorem for subharmonic functions,,"I noticed this post and this paper , which gives a version of Liouville's theorem for subharmonic functions and the reference of its proof, but I think there must be an easier proof for the following version of Liouville's theorem with a stronger condition. A subharmonic function that is bounded above on the complex plane $\mathbb C$ must be constant I think we may need to use the fact that the maximum of a subharmonic function cannot be achieved in the interior of its domain unless the function is constant(MVP). But how do we prove that a bounded-above subharmonic function on the complex plane $\mathbb C$ can achieve its maximum at a certain point of $\mathbb C$?(Maybe we don't need to use MVP for proof) Thanks in advance!","I noticed this post and this paper , which gives a version of Liouville's theorem for subharmonic functions and the reference of its proof, but I think there must be an easier proof for the following version of Liouville's theorem with a stronger condition. A subharmonic function that is bounded above on the complex plane $\mathbb C$ must be constant I think we may need to use the fact that the maximum of a subharmonic function cannot be achieved in the interior of its domain unless the function is constant(MVP). But how do we prove that a bounded-above subharmonic function on the complex plane $\mathbb C$ can achieve its maximum at a certain point of $\mathbb C$?(Maybe we don't need to use MVP for proof) Thanks in advance!",,"['complex-analysis', 'harmonic-functions']"
57,Suppose that $f$ is analytic on a close curve γ. Prove or disprove $\int_\gamma \overline{f(z)}f'(z)dz$ is purely imaginary.,Suppose that  is analytic on a close curve γ. Prove or disprove  is purely imaginary.,f \int_\gamma \overline{f(z)}f'(z)dz,"Suppose that $f$ is analytic on a close curve γ. Prove or disprove $$\int_\gamma \overline{f(z)}f'(z)dz$$ is purely imagine. I know that $f$ is analytic on a close curve, then $$\int_\gamma f(z) dz=0$$ I tried an example with $\gamma =e^{it}$ with $0\leq t\leq 2\pi$, I often get the real part of the integral equal zero. I tried let $f=u+iv$ so $f'=u_x+iv_x$. Since $f=u+iv$, $\overline{f}=u-iv$ $$\overline{f(z)}f'(z)=uu_x+vv_x+i(uv_x-vu_x)$$ But this doesn't get me anywhere. Any help would be greatly appreciated.","Suppose that $f$ is analytic on a close curve γ. Prove or disprove $$\int_\gamma \overline{f(z)}f'(z)dz$$ is purely imagine. I know that $f$ is analytic on a close curve, then $$\int_\gamma f(z) dz=0$$ I tried an example with $\gamma =e^{it}$ with $0\leq t\leq 2\pi$, I often get the real part of the integral equal zero. I tried let $f=u+iv$ so $f'=u_x+iv_x$. Since $f=u+iv$, $\overline{f}=u-iv$ $$\overline{f(z)}f'(z)=uu_x+vv_x+i(uv_x-vu_x)$$ But this doesn't get me anywhere. Any help would be greatly appreciated.",,['complex-analysis']
58,$\int_0^\infty \frac{\log(1+x^2)}{x^2} dx $ using contour integration,using contour integration,\int_0^\infty \frac{\log(1+x^2)}{x^2} dx ,"I am trying to evaluate $$\int_0^\infty \frac{\log(1+x^2)}{x^2} dx $$ by using contour integration. It is possible to compute this integral using real techniques; integration by parts yields the result: $$\int_0^\infty \frac{\log(1+x^2)}{x^2} dx = \pi$$ I have been attempting to use the integrand $f(z)= \frac{\log(1+z^2)}{z^2}$ (with any suitable branch cut in the lower half plane), and have been trying to integrate around an indented semi-circle in the upper half plane, but I feel this is perhaps the wrong approach. Firstly, when summing the integrals along the real axis, the imaginary part seems to not converge. Furthermore, the indentation integral seems difficult to evaluate. Any help would be appreciated.","I am trying to evaluate $$\int_0^\infty \frac{\log(1+x^2)}{x^2} dx $$ by using contour integration. It is possible to compute this integral using real techniques; integration by parts yields the result: $$\int_0^\infty \frac{\log(1+x^2)}{x^2} dx = \pi$$ I have been attempting to use the integrand $f(z)= \frac{\log(1+z^2)}{z^2}$ (with any suitable branch cut in the lower half plane), and have been trying to integrate around an indented semi-circle in the upper half plane, but I feel this is perhaps the wrong approach. Firstly, when summing the integrals along the real axis, the imaginary part seems to not converge. Furthermore, the indentation integral seems difficult to evaluate. Any help would be appreciated.",,"['complex-analysis', 'contour-integration']"
59,The limit of complex sequence,The limit of complex sequence,,"$$\lim\limits_{n \rightarrow \infty} \left(\frac{i}{1+i}\right)^n$$ I think the limit is $0$; is it true that $\forall a,b\in \Bbb C$, if $|a|<|b|$ then $\lim\limits_{n\rightarrow \infty}\left(\frac{a}{b}\right)^n=0$? I would like to see a proof, if possible. Thank you","$$\lim\limits_{n \rightarrow \infty} \left(\frac{i}{1+i}\right)^n$$ I think the limit is $0$; is it true that $\forall a,b\in \Bbb C$, if $|a|<|b|$ then $\lim\limits_{n\rightarrow \infty}\left(\frac{a}{b}\right)^n=0$? I would like to see a proof, if possible. Thank you",,"['complex-analysis', 'complex-numbers']"
60,Expressing $\sum_{n=-\infty}^\infty\dfrac{1}{z^3-n^3}$ in closed form,Expressing  in closed form,\sum_{n=-\infty}^\infty\dfrac{1}{z^3-n^3},"I want to express $$\sum_{n=-\infty}^\infty\dfrac{1}{z^3-n^3}$$ in closed form. I know that $$\pi z\cot(\pi z)=1+2z^2\sum_{n=1}^\infty\dfrac{1}{z^2-n^2}$$ which looks close, but I don’t know how to use it.","I want to express $$\sum_{n=-\infty}^\infty\dfrac{1}{z^3-n^3}$$ in closed form. I know that $$\pi z\cot(\pi z)=1+2z^2\sum_{n=1}^\infty\dfrac{1}{z^2-n^2}$$ which looks close, but I don’t know how to use it.",,"['complex-analysis', 'partial-fractions']"
61,Riemann Zeta Function and Analytic Continuation,Riemann Zeta Function and Analytic Continuation,,"The Riemann Zeta Function is defined as $ \displaystyle \zeta(s) = \sum\limits_{n=1}^{\infty} \frac{1}{n^s}$. It is not absolutely convergent or conditionally convergent for $\text{Re}(s) \leq 1$. Using analytic continuation, one can derive the fact that $\displaystyle \zeta(-s) = -\frac{B_{s+1}}{s+1}$ where $B_{s+1}$ are the Bernoulli numbers. Can one obtain this result without resorting to analytic continuation?","The Riemann Zeta Function is defined as $ \displaystyle \zeta(s) = \sum\limits_{n=1}^{\infty} \frac{1}{n^s}$. It is not absolutely convergent or conditionally convergent for $\text{Re}(s) \leq 1$. Using analytic continuation, one can derive the fact that $\displaystyle \zeta(-s) = -\frac{B_{s+1}}{s+1}$ where $B_{s+1}$ are the Bernoulli numbers. Can one obtain this result without resorting to analytic continuation?",,"['complex-analysis', 'riemann-zeta']"
62,Where are the zeros of a slightly perturbed Riemann Zeta function?,Where are the zeros of a slightly perturbed Riemann Zeta function?,,"We seek to understand the locations of the zeros when we introduce a minor perturbation to the Riemann Zeta function: ${\displaystyle \zeta (s)=\sum _{n=1}^{\infty }{\frac {1}{n^{s}}}={\frac {1}{1^{s}}}+{\frac {1}{2^{s}}}+{\frac {1}{3^{s}}}+{\frac {1}{4^{s}}}+\cdots}$ For instance, consider the following slightly perturbed Zeta function: ${\displaystyle N(s)={\frac {1}{1^{s}}}+{\frac {2}{2^{s}}}+{\frac {1}{3^{s}}}+{\frac {1}{4^{s}}}+\cdots}$ Where are its zeros located on the complex plane? (We can assume the Riemann Hypothesis is true.)","We seek to understand the locations of the zeros when we introduce a minor perturbation to the Riemann Zeta function: For instance, consider the following slightly perturbed Zeta function: Where are its zeros located on the complex plane? (We can assume the Riemann Hypothesis is true.)",{\displaystyle \zeta (s)=\sum _{n=1}^{\infty }{\frac {1}{n^{s}}}={\frac {1}{1^{s}}}+{\frac {1}{2^{s}}}+{\frac {1}{3^{s}}}+{\frac {1}{4^{s}}}+\cdots} {\displaystyle N(s)={\frac {1}{1^{s}}}+{\frac {2}{2^{s}}}+{\frac {1}{3^{s}}}+{\frac {1}{4^{s}}}+\cdots},"['complex-analysis', 'number-theory', 'analytic-number-theory', 'riemann-zeta', 'riemann-hypothesis']"
63,Writing the Beta Function in terms of the Gamma Function,Writing the Beta Function in terms of the Gamma Function,,"I am studying the gamma and beta functions and I have seen an exercise which asks you to re-write the beta function in terms of the gamma function as follows: $B(\alpha,\beta)=\frac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha + \beta)}$ The only hint that the exercise gives is that you should start with a function of the form: $f(\alpha,\beta,t)=\int_0^tx^{\alpha-1}(t-x)^{\beta-1}dx$ The first thing I notice is that the right-hand side can be considered as a convolution of two functions, so: $L[f]=L[x^\alpha-1]L[(t-x)^{\beta-1}]$ However, this just ends up with the Laplace transform of f on the LHS and then a mess of transforms on the right.  The other thing is that if you set $t=1$, $f$ becomes the beta function: $f(\alpha,\beta,1)=B(\alpha,\beta)=\int_0^1x^{\alpha-1}(1-x)^{\beta-1}dx$ Hence I am hoping that if I convert $f$ to this form we have the beta function and then take the product of the Laplace transforms of the two functions in the convolution, it somehow comes out as a set of integrals which are equivalent to the given identity once I use the integral formula for the gamma function.  However, I have tried this and got a mess, could someone assist (if this is the right way of doing it)? Edit: I have looked on Wikipedia and seen that the identity can be proved just by taking the product of two gamma functions and then changing variables to show that this is $B(\alpha,\beta)\Gamma(\alpha+\beta)$: however, the exercise is in a section on Laplace transforms so I think it wants you to take the Laplace transform of the given function $f$ and work it out that way.","I am studying the gamma and beta functions and I have seen an exercise which asks you to re-write the beta function in terms of the gamma function as follows: $B(\alpha,\beta)=\frac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha + \beta)}$ The only hint that the exercise gives is that you should start with a function of the form: $f(\alpha,\beta,t)=\int_0^tx^{\alpha-1}(t-x)^{\beta-1}dx$ The first thing I notice is that the right-hand side can be considered as a convolution of two functions, so: $L[f]=L[x^\alpha-1]L[(t-x)^{\beta-1}]$ However, this just ends up with the Laplace transform of f on the LHS and then a mess of transforms on the right.  The other thing is that if you set $t=1$, $f$ becomes the beta function: $f(\alpha,\beta,1)=B(\alpha,\beta)=\int_0^1x^{\alpha-1}(1-x)^{\beta-1}dx$ Hence I am hoping that if I convert $f$ to this form we have the beta function and then take the product of the Laplace transforms of the two functions in the convolution, it somehow comes out as a set of integrals which are equivalent to the given identity once I use the integral formula for the gamma function.  However, I have tried this and got a mess, could someone assist (if this is the right way of doing it)? Edit: I have looked on Wikipedia and seen that the identity can be proved just by taking the product of two gamma functions and then changing variables to show that this is $B(\alpha,\beta)\Gamma(\alpha+\beta)$: however, the exercise is in a section on Laplace transforms so I think it wants you to take the Laplace transform of the given function $f$ and work it out that way.",,"['complex-analysis', 'laplace-transform', 'gamma-function', 'beta-function']"
64,Maximum of $|\sin(z)|$ as $\{z: |z| \leq 1 \} $,Maximum of  as,|\sin(z)| \{z: |z| \leq 1 \} ,"Maximum of $|\sin(z)|$ as $\{z: |z| \leq 1 \} $ So according to the Maximum Principle, the maximum is when $|z|=1$. I tried using the fact that $\sin z= \dfrac {e^{iz}-e^{-iz}}{2i}$, but didn't know how to continue from there. Setting $z=e^{it}$ doesn't help much. I saw this question was answered before, however the answer uses hyperbolic functions ($\sinh, \cosh$) which I haven't actually studied. Thanks in advance for any assistance!","Maximum of $|\sin(z)|$ as $\{z: |z| \leq 1 \} $ So according to the Maximum Principle, the maximum is when $|z|=1$. I tried using the fact that $\sin z= \dfrac {e^{iz}-e^{-iz}}{2i}$, but didn't know how to continue from there. Setting $z=e^{it}$ doesn't help much. I saw this question was answered before, however the answer uses hyperbolic functions ($\sinh, \cosh$) which I haven't actually studied. Thanks in advance for any assistance!",,['complex-analysis']
65,$|f|$ constant implies $f$ constant?,constant implies  constant?,|f| f,If $f$ is an analytic function on a domain $D$ and $|f|=C$ is constant on $D$ why does this imply that $f$ is constant on $D$? Why is the codomain of $f$ not the circle of radius $\sqrt{C}$?,If $f$ is an analytic function on a domain $D$ and $|f|=C$ is constant on $D$ why does this imply that $f$ is constant on $D$? Why is the codomain of $f$ not the circle of radius $\sqrt{C}$?,,"['complex-analysis', 'analyticity']"
66,Which holomorphic maps $f:\mathbb{H}\to\mathbb{H}$ satisfy $f(z+1)=f(z)-1$?,Which holomorphic maps  satisfy ?,f:\mathbb{H}\to\mathbb{H} f(z+1)=f(z)-1,"Let $\mathbb{H}$ denote the upper half-plane. Which holomorphic maps $f:\mathbb{H}\to\mathbb{H}$ satisfy $f(z+1)=f(z)-1$ for all $z\in\mathbb{H}$ ? My guess is that none exist. I think there might be orientation issues or something. One observation that I made is that $e^{2\pi i f}$ is $1$ -periodic. I was not able to get any use out of this though. I am quite stuck. Do such maps exist? And if not, then why not?","Let denote the upper half-plane. Which holomorphic maps satisfy for all ? My guess is that none exist. I think there might be orientation issues or something. One observation that I made is that is -periodic. I was not able to get any use out of this though. I am quite stuck. Do such maps exist? And if not, then why not?",\mathbb{H} f:\mathbb{H}\to\mathbb{H} f(z+1)=f(z)-1 z\in\mathbb{H} e^{2\pi i f} 1,"['complex-analysis', 'functional-equations']"
67,Fourier series expanding of holomorphic functions,Fourier series expanding of holomorphic functions,,"Let $f:\mathbb{C}\to \mathbb{C}$ be a holomorphic function with $f(z+1)=f(z)$. Then how to expand it into Fourier series $$f(z)=\sum\nolimits_{n\in \mathbb{Z}} a_n e^{2\pi inz}?$$ In another word, what is $a_n$? Thanks a lot!","Let $f:\mathbb{C}\to \mathbb{C}$ be a holomorphic function with $f(z+1)=f(z)$. Then how to expand it into Fourier series $$f(z)=\sum\nolimits_{n\in \mathbb{Z}} a_n e^{2\pi inz}?$$ In another word, what is $a_n$? Thanks a lot!",,"['complex-analysis', 'fourier-series']"
68,"Show that $f(z)=0$ for all $z$, where $f$ is an analytic function on the closed unit disc with additional conditions.","Show that  for all , where  is an analytic function on the closed unit disc with additional conditions.",f(z)=0 z f,"Let $D$ denote the open ball of unit radius about origin in the complex plane $\Bbb C$ . Let $f$ be a continuous complex-valued function on its closure $D$ which is analytic on $D$ . If $f(e^{it}) = 0$ for $0 < t  <\frac{\pi}{2}$ , show that $f(z) = 0 $ for all $z$ . Here is what I tried: $f$ is analytic on $D$ . If I can find a sequence $(z_n)_n$ in $D$ such that $f(z_n)=0\forall n$ and additionally $(z_n)_n$ has a limit point in $D$ then we are done. I think $f(e^{it}) = 0$ may help finding one sequence but I am not sure. Will you kindly help?","Let denote the open ball of unit radius about origin in the complex plane . Let be a continuous complex-valued function on its closure which is analytic on . If for , show that for all . Here is what I tried: is analytic on . If I can find a sequence in such that and additionally has a limit point in then we are done. I think may help finding one sequence but I am not sure. Will you kindly help?",D \Bbb C f D D f(e^{it}) = 0 0 < t  <\frac{\pi}{2} f(z) = 0  z f D (z_n)_n D f(z_n)=0\forall n (z_n)_n D f(e^{it}) = 0,['complex-analysis']
69,Is $z\cdot\sin(z)$ (function from $\mathbb{C} \to \mathbb{C}$) surjective?,Is  (function from ) surjective?,z\cdot\sin(z) \mathbb{C} \to \mathbb{C},"We know by Picard's theorem that any entire function is either constant, or surjective or misses only 1 point. It is easy to observe that $\sin{z}$, $\cos{z}$ are surjective. Is $f \cdot g$ surjective if $f$ and $g$ are entire and surjective? It is indeed true when $f$ and $g$ are polynomials. Does there a characterization of entire functions missing a point and surjective entire functions? Or any relation between them?","We know by Picard's theorem that any entire function is either constant, or surjective or misses only 1 point. It is easy to observe that $\sin{z}$, $\cos{z}$ are surjective. Is $f \cdot g$ surjective if $f$ and $g$ are entire and surjective? It is indeed true when $f$ and $g$ are polynomials. Does there a characterization of entire functions missing a point and surjective entire functions? Or any relation between them?",,['complex-analysis']
70,Holomorphic functions as sums,Holomorphic functions as sums,,Are there any holomorphic functions on a connected domain in $\mathbb C$ that can not be written as a sum of two univalent (holomorphic and injective) functions? What about as a sum of finitely many univalent functions? Or even infinitely many?,Are there any holomorphic functions on a connected domain in $\mathbb C$ that can not be written as a sum of two univalent (holomorphic and injective) functions? What about as a sum of finitely many univalent functions? Or even infinitely many?,,"['complex-analysis', 'analysis']"
71,Why does Fourier Transform use a negative exponent in its formula?,Why does Fourier Transform use a negative exponent in its formula?,,"I realize this question has been asked before but I don't understand the explanations. For example I have read this ( https://en.wikipedia.org/wiki/Negative_frequency ) as well as numerous other answers. I understand e^-jwt is simply a point going clockwise in the complex domain. What I don't understand is why you multiply a signal x(t) with a clockwise complex number. What would be the result of let's say Fourier Transform using the positive exponent? I guess one theory I had is they define shifted impulses using delta[t-to] and the Fourier transfform of that is going to be e^-jwto. We think of things shifted after time 0 rather than before, so is this why we have a negative exponent? If I'm wrong, please provide clear sequential steps.","I realize this question has been asked before but I don't understand the explanations. For example I have read this ( https://en.wikipedia.org/wiki/Negative_frequency ) as well as numerous other answers. I understand e^-jwt is simply a point going clockwise in the complex domain. What I don't understand is why you multiply a signal x(t) with a clockwise complex number. What would be the result of let's say Fourier Transform using the positive exponent? I guess one theory I had is they define shifted impulses using delta[t-to] and the Fourier transfform of that is going to be e^-jwto. We think of things shifted after time 0 rather than before, so is this why we have a negative exponent? If I'm wrong, please provide clear sequential steps.",,"['complex-analysis', 'fourier-analysis', 'fourier-transform', 'signal-processing']"
72,How to derive this Hankel's Contour integral formula with gamma function?,How to derive this Hankel's Contour integral formula with gamma function?,,"This relation was put up in The Art Of Computer Programming and no derivation was offered. Please help me understand this better. $$\frac{1}{\Gamma (z)} = \frac{1}{2i\pi} \oint\frac{e^t dt}{t^z}$$ It said that the path of the complex integration starts at $-\infty$ circles around the origin and returns to $-\infty$. If not a derivation, at least help me develop some intuition about this. How are we introducing complex analysis to a function that came up in the real numbers ?","This relation was put up in The Art Of Computer Programming and no derivation was offered. Please help me understand this better. $$\frac{1}{\Gamma (z)} = \frac{1}{2i\pi} \oint\frac{e^t dt}{t^z}$$ It said that the path of the complex integration starts at $-\infty$ circles around the origin and returns to $-\infty$. If not a derivation, at least help me develop some intuition about this. How are we introducing complex analysis to a function that came up in the real numbers ?",,"['complex-analysis', 'gamma-function']"
73,Determine the Integral $\int_{-\infty}^{\infty} e^{-x^2} \cos(2bx)dx$,Determine the Integral,\int_{-\infty}^{\infty} e^{-x^2} \cos(2bx)dx,"Please do not mark this question as a duplicate. I have to solve this with a different method that I don't believe has been discussed about this particular question (at least to my  knowledge). I am confronted with computing the integral below: $$\int_{-\infty}^{\infty} e^{-x^2} \cos(2bx)dx, b \in \mathbb R, b \gt0$$ I understand that this is a question in which Complex Analysis has applications to Real Analysis. Specifically, Cauchy's Theorem will be used. That being said, the hint I was given (and the method I am attempting to use) is the following: Integrate $e^{-z^2}$ over this curve: The curve is a rectangle such that its length is $2R$ and its width is $b$. Also, the length on the lower side of the rectangle lies on the x-axis. Lastly, the direction of curvature is counter-clockwise. My question is this: why integrate $e^{-z^2}$, and not $e^{-z^2}\cos(2bz)$? That is, the actual integral we're computing? I know that the former would be easier to integrate, but where did the $\cos(2bz)$ term go, and where will it come into play again? Also, it's important to say that $\int_{-\infty}^{\infty} e^{-t^2}dt = \sqrt\pi$ will be useful here as well. Lastly, I know that from the hint suggested, there will be four curves to evaluate: the two lengths and the two widths of the rectangle.","Please do not mark this question as a duplicate. I have to solve this with a different method that I don't believe has been discussed about this particular question (at least to my  knowledge). I am confronted with computing the integral below: $$\int_{-\infty}^{\infty} e^{-x^2} \cos(2bx)dx, b \in \mathbb R, b \gt0$$ I understand that this is a question in which Complex Analysis has applications to Real Analysis. Specifically, Cauchy's Theorem will be used. That being said, the hint I was given (and the method I am attempting to use) is the following: Integrate $e^{-z^2}$ over this curve: The curve is a rectangle such that its length is $2R$ and its width is $b$. Also, the length on the lower side of the rectangle lies on the x-axis. Lastly, the direction of curvature is counter-clockwise. My question is this: why integrate $e^{-z^2}$, and not $e^{-z^2}\cos(2bz)$? That is, the actual integral we're computing? I know that the former would be easier to integrate, but where did the $\cos(2bz)$ term go, and where will it come into play again? Also, it's important to say that $\int_{-\infty}^{\infty} e^{-t^2}dt = \sqrt\pi$ will be useful here as well. Lastly, I know that from the hint suggested, there will be four curves to evaluate: the two lengths and the two widths of the rectangle.",,"['complex-analysis', 'complex-integration']"
74,Is a meromorphic function satisfying $f(2z)=\frac{f(z)}{1+f(z)^2}$ constant?,Is a meromorphic function satisfying  constant?,f(2z)=\frac{f(z)}{1+f(z)^2},"Let $f(z)$ be a holomorphic function on the unit disk satisfying $f(0)=0$ and $$f(2z)=\frac{f(z)}{1+f(z)^2}.$$ Extend it to a meromorphic function on the entire complex plane using this recursion. Must $f(z)$ be constant? I think so, but I can't prove it. Substituting $g(z)=1/f(z)$ and rearranging yields $$g(2z)=g(z)+\frac{1}{g(z)},$$ which seems useful, but I'm not sure how to proceed after that.","Let $f(z)$ be a holomorphic function on the unit disk satisfying $f(0)=0$ and $$f(2z)=\frac{f(z)}{1+f(z)^2}.$$ Extend it to a meromorphic function on the entire complex plane using this recursion. Must $f(z)$ be constant? I think so, but I can't prove it. Substituting $g(z)=1/f(z)$ and rearranging yields $$g(2z)=g(z)+\frac{1}{g(z)},$$ which seems useful, but I'm not sure how to proceed after that.",,['complex-analysis']
75,Find the error in following reason $(-z)^2=z^2 \implies \log(-z)^2=\log(z)^2 \implies2\log(-z)=2\log(z)\implies \log(-z)=\log(z)$,Find the error in following reason,(-z)^2=z^2 \implies \log(-z)^2=\log(z)^2 \implies2\log(-z)=2\log(z)\implies \log(-z)=\log(z),"Find the error in following reason \begin{align*} (-z)^2=z^2 &\implies \log(-z)^2=\log(z)^2\\ &\implies2\log(-z)=2\log(z)\\ &\implies \log(-z)=\log(z) \end{align*} I think the error is $2\log(-z)=2\log(z)$ because for $z=1$, $2\log(1)=0$, but $2 \log(-1)$ is undefined. What's bugging me is this problem has a star on it, which mean it's a challenging problem. I don't think it is that easy. So I wonder if anyone could check if I missed or make mistake somewhere.","Find the error in following reason \begin{align*} (-z)^2=z^2 &\implies \log(-z)^2=\log(z)^2\\ &\implies2\log(-z)=2\log(z)\\ &\implies \log(-z)=\log(z) \end{align*} I think the error is $2\log(-z)=2\log(z)$ because for $z=1$, $2\log(1)=0$, but $2 \log(-1)$ is undefined. What's bugging me is this problem has a star on it, which mean it's a challenging problem. I don't think it is that easy. So I wonder if anyone could check if I missed or make mistake somewhere.",,['complex-analysis']
76,Why is this function a really good asymptotic for $\exp(x)\sqrt{x}$,Why is this function a really good asymptotic for,\exp(x)\sqrt{x},"$$f(x)=\sum_{n=0}^{\infty} a_n x^n\;\;\;\;\; a_n = \frac{1}{\Gamma(n+0.5)}$$ Why is this entire function a really good asymptotic for $\exp(x)\sqrt{x}$, where for large positive numbers, $f(x)\exp(-x) \approx \sqrt{x}$? As |x| gets larger, the error term is asymptotically $f(x)-\exp(x)\sqrt{x} \approx \frac{1}{x\cdot\Gamma(-0.5)}$, and the error term for $f(x)\exp(-x) - \sqrt{x} \approx \frac{\exp(-x)}{x\cdot \Gamma(-0.5)}$.  If we treat $f(x)$ as an infinite Laurent series, than it does not converge. I stumbled upon the result, using numerical approximations, so I can't really explain the equation for the $a_n$ coefficients, other than it appears to be the numerical limit of a pseudo Cauchy integral for the $a_n$ coefficients as the circle for the Cauchy integral path gets larger.  I suspect the formula has been seen before, and can be generated by some other technique.   By definition, for any entire function $f(x)$, we have for any value of real r: $$a_n = \oint x^{-n} f(x) = \int_{-\pi}^{\pi} \frac{1}{2\pi} (re^{-ix})^{-n} f(re^{ix}) )\; \mathrm{d}x\;\;$$  The conjecture is that this is an equivalent definition for $a_n$, where $f(x) \mapsto \exp(x)\sqrt{x}$ and $x \mapsto re^{ix}$. $$a_n =\lim_{r\to\infty} \int_{-\pi}^{\pi} \frac{1}{2\pi} (re^{-ix})^{-n}\exp(re^{ix})\sqrt{re^{ix}})\; \mathrm{d}x = \frac{1}{\Gamma(n+0.5)}   $$","$$f(x)=\sum_{n=0}^{\infty} a_n x^n\;\;\;\;\; a_n = \frac{1}{\Gamma(n+0.5)}$$ Why is this entire function a really good asymptotic for $\exp(x)\sqrt{x}$, where for large positive numbers, $f(x)\exp(-x) \approx \sqrt{x}$? As |x| gets larger, the error term is asymptotically $f(x)-\exp(x)\sqrt{x} \approx \frac{1}{x\cdot\Gamma(-0.5)}$, and the error term for $f(x)\exp(-x) - \sqrt{x} \approx \frac{\exp(-x)}{x\cdot \Gamma(-0.5)}$.  If we treat $f(x)$ as an infinite Laurent series, than it does not converge. I stumbled upon the result, using numerical approximations, so I can't really explain the equation for the $a_n$ coefficients, other than it appears to be the numerical limit of a pseudo Cauchy integral for the $a_n$ coefficients as the circle for the Cauchy integral path gets larger.  I suspect the formula has been seen before, and can be generated by some other technique.   By definition, for any entire function $f(x)$, we have for any value of real r: $$a_n = \oint x^{-n} f(x) = \int_{-\pi}^{\pi} \frac{1}{2\pi} (re^{-ix})^{-n} f(re^{ix}) )\; \mathrm{d}x\;\;$$  The conjecture is that this is an equivalent definition for $a_n$, where $f(x) \mapsto \exp(x)\sqrt{x}$ and $x \mapsto re^{ix}$. $$a_n =\lim_{r\to\infty} \int_{-\pi}^{\pi} \frac{1}{2\pi} (re^{-ix})^{-n}\exp(re^{ix})\sqrt{re^{ix}})\; \mathrm{d}x = \frac{1}{\Gamma(n+0.5)}   $$",,"['complex-analysis', 'logarithms', 'asymptotics', 'exponential-function', 'gamma-function']"
77,Cross ratio is real on image of real axis,Cross ratio is real on image of real axis,,"Theorem : The cross ratio $(z_1,z_2,z_3,z_4)$ is real if and only if the four points lie on a circle or on a straight line. We need only show that the image of the real axis under any linear transformation is either a circle or a straight line. Indeed, $Tz=(z,z_2,z_3,z_4)$ is real on the image of the real axis under the transformation $T^{-1}$ and nowhere else. I don't understand this paragraph. Why is it that $Tz$ is real on the image of the real axis under $T^{-1}$ , and why is it real nowhere else? And why is it enough to show only this?","Theorem : The cross ratio is real if and only if the four points lie on a circle or on a straight line. We need only show that the image of the real axis under any linear transformation is either a circle or a straight line. Indeed, is real on the image of the real axis under the transformation and nowhere else. I don't understand this paragraph. Why is it that is real on the image of the real axis under , and why is it real nowhere else? And why is it enough to show only this?","(z_1,z_2,z_3,z_4) Tz=(z,z_2,z_3,z_4) T^{-1} Tz T^{-1}","['complex-analysis', 'complex-numbers']"
78,Expand: $e^{\sin z}$ at $z = 0$,Expand:  at,e^{\sin z} z = 0,"I need hints to find the Laurent expansion of $\displaystyle e^{\sin z}$ at $z = 0$ in a simpler way. I am getting double series which I can't simplify. ADDED:: Can it be simpler that the below? I also need to find the radius of convergence. $$\Large e^{\sin z} = e^{\sum_{k = 0}^\infty \frac{(-1)^nz^{2n+1}}{(2n+1)!}} = \sum_{n = 0}^\infty \frac{\small{B(1, -1/3!, \dots , (-1)^n/(2n+1)!)} z^n}{n!}$$","I need hints to find the Laurent expansion of $\displaystyle e^{\sin z}$ at $z = 0$ in a simpler way. I am getting double series which I can't simplify. ADDED:: Can it be simpler that the below? I also need to find the radius of convergence. $$\Large e^{\sin z} = e^{\sum_{k = 0}^\infty \frac{(-1)^nz^{2n+1}}{(2n+1)!}} = \sum_{n = 0}^\infty \frac{\small{B(1, -1/3!, \dots , (-1)^n/(2n+1)!)} z^n}{n!}$$",,"['complex-analysis', 'laurent-series']"
79,Complex differentiability implies real differentiability,Complex differentiability implies real differentiability,,"First, we think of $\mathbb{R}^2$ as related to the complex plane by the following: $(x,y) \leftrightarrow x+iy$. Show that if $f(x,y)=(u(x,y),v(x,y))$ is complex differentiable at $z_0$, then $f$ is differentiable at $z_0$.  Also, at $z_0$ establish the Cauchy Riemann equations. I have not taken Complex analysis, but I am familiar with the definition of complex differentiable. Suppose $f$ is complex differentiable.  Then $\lim\limits_{z \to z_0}\frac{f(z)-f(z_0)}{z-z_0}=a+bi=\beta$.  Then $\lim\limits_{z \to z_0}|\frac{f(z)-f(z_0)-\beta(z-z_0)}{z-z_0}|=0$. At the above step, do I just sub in $z=x+yi$ and $z_0=x_0+iy_0$ to show real differentiability?","First, we think of $\mathbb{R}^2$ as related to the complex plane by the following: $(x,y) \leftrightarrow x+iy$. Show that if $f(x,y)=(u(x,y),v(x,y))$ is complex differentiable at $z_0$, then $f$ is differentiable at $z_0$.  Also, at $z_0$ establish the Cauchy Riemann equations. I have not taken Complex analysis, but I am familiar with the definition of complex differentiable. Suppose $f$ is complex differentiable.  Then $\lim\limits_{z \to z_0}\frac{f(z)-f(z_0)}{z-z_0}=a+bi=\beta$.  Then $\lim\limits_{z \to z_0}|\frac{f(z)-f(z_0)-\beta(z-z_0)}{z-z_0}|=0$. At the above step, do I just sub in $z=x+yi$ and $z_0=x_0+iy_0$ to show real differentiability?",,"['complex-analysis', 'analysis']"
80,Cauchy's Theorem vs. Fundamental Theorem of Contour Integration.,Cauchy's Theorem vs. Fundamental Theorem of Contour Integration.,,"The fundamental theorem of contour integration says if one has a function and its antiderivative, and integrates the function over a closed loop the result is zero. Cauchy's theorem (Goursat's Version) says the integral of a function in a holomorphic domain in a closed loop is zero. Cauchy's theorem is apparently much stronger, the proof is certainly more intricate. Can someone please give trivial and nontrivial examples of integrals that Cauchy's Theorem applies to that FTCI does not? Having proven Cauchy's Theorem, is the FTCI useful for anything, anymore?","The fundamental theorem of contour integration says if one has a function and its antiderivative, and integrates the function over a closed loop the result is zero. Cauchy's theorem (Goursat's Version) says the integral of a function in a holomorphic domain in a closed loop is zero. Cauchy's theorem is apparently much stronger, the proof is certainly more intricate. Can someone please give trivial and nontrivial examples of integrals that Cauchy's Theorem applies to that FTCI does not? Having proven Cauchy's Theorem, is the FTCI useful for anything, anymore?",,['complex-analysis']
81,Laurent Series  $\exp(1/z)/(1-z)$,Laurent Series,\exp(1/z)/(1-z),I need some help finding the Laurent expansion and residue of $$\dfrac{\exp \left(\frac1z \right)}{(1-z)}$$ So far I've done $$\sum_{j=0}^\infty \frac{z^{-j}}{j!} \sum_{k=0}^\infty z^k = \sum_{j=0}^\infty \sum_{k=0}^\infty \frac{z^{k-j}}{j!}$$ but don't know where to go from here. And is it also possible to use Cauchy product when one of the powers is $<0$ and the other is $>0$?,I need some help finding the Laurent expansion and residue of $$\dfrac{\exp \left(\frac1z \right)}{(1-z)}$$ So far I've done $$\sum_{j=0}^\infty \frac{z^{-j}}{j!} \sum_{k=0}^\infty z^k = \sum_{j=0}^\infty \sum_{k=0}^\infty \frac{z^{k-j}}{j!}$$ but don't know where to go from here. And is it also possible to use Cauchy product when one of the powers is $<0$ and the other is $>0$?,,['complex-analysis']
82,The winding number and index of curve,The winding number and index of curve,,"If $\gamma $ is a smooth closed curve in $\mathbb R^2-\{0\}$, I want to know whether the winding number of $\gamma $ about $0$, i.e., $\frac{1}{{2\pi i}}\int\limits_\gamma  {\frac{1}{z}} dz$ is equal to the index of $\gamma $ about $0$, that is, the degree of ${S^1} \to {S^1}$ through $t \to \frac{{\gamma (t)}}{{\left| {\gamma (t)} \right|}}$? If so, it gives us a convenient way to calculate the index of curve. Is there any analogy in higher dimension?","If $\gamma $ is a smooth closed curve in $\mathbb R^2-\{0\}$, I want to know whether the winding number of $\gamma $ about $0$, i.e., $\frac{1}{{2\pi i}}\int\limits_\gamma  {\frac{1}{z}} dz$ is equal to the index of $\gamma $ about $0$, that is, the degree of ${S^1} \to {S^1}$ through $t \to \frac{{\gamma (t)}}{{\left| {\gamma (t)} \right|}}$? If so, it gives us a convenient way to calculate the index of curve. Is there any analogy in higher dimension?",,"['complex-analysis', 'algebraic-topology', 'differential-geometry', 'differential-topology']"
83,the generalized Liouville theorem,the generalized Liouville theorem,,"The Liouville theorem state: Let $f$ be an entire function for which there exists a positive number M such that $|f(z)|\leq M$ for all z in $\mathbb{C}$, the $f$ must be a constant. more general form of this theorem is : Let $f$ be an entire function for which there exists a positive number M and a polynomial $P$ such that $|f(z)|\leq M |P(z)|$ for all z in $\mathbb{C}$ then $f(z)=k P(z)$ for $k$ a constant. who know a good proof of this generalized form ?","The Liouville theorem state: Let $f$ be an entire function for which there exists a positive number M such that $|f(z)|\leq M$ for all z in $\mathbb{C}$, the $f$ must be a constant. more general form of this theorem is : Let $f$ be an entire function for which there exists a positive number M and a polynomial $P$ such that $|f(z)|\leq M |P(z)|$ for all z in $\mathbb{C}$ then $f(z)=k P(z)$ for $k$ a constant. who know a good proof of this generalized form ?",,['complex-analysis']
84,Nomenclature in complex analysis,Nomenclature in complex analysis,,"I am having a little confusion on the naming of functions in complex analysis. If $f$ is a holomorphic function on the complex plane and its domain is the complex plane then it's called an entire function. If $g$ is holomorphic everywhere on the complex plane apart from its poles and its domain is the complex plane then it's a meromorphic function. But... If $g$'s domain is extended to the Riemann sphere (and it doesn't have a essential singularity at infinity) is it a ""meromorphic function with domain of Riemann sphere"" or ""holomorphic function with domain of Riemann sphere"" or a ""rational function""? Thanks!","I am having a little confusion on the naming of functions in complex analysis. If $f$ is a holomorphic function on the complex plane and its domain is the complex plane then it's called an entire function. If $g$ is holomorphic everywhere on the complex plane apart from its poles and its domain is the complex plane then it's a meromorphic function. But... If $g$'s domain is extended to the Riemann sphere (and it doesn't have a essential singularity at infinity) is it a ""meromorphic function with domain of Riemann sphere"" or ""holomorphic function with domain of Riemann sphere"" or a ""rational function""? Thanks!",,"['complex-analysis', 'terminology']"
85,"Understanding an integral from page 15 of Titchmarsh's book ""The theory of the Riemann Zeta function""","Understanding an integral from page 15 of Titchmarsh's book ""The theory of the Riemann Zeta function""",,"In Titchmarsh's book ""The theory of the Riemann Zeta function"" pg. 15 where the functional equation of the zeta function is being derived,  I couldn't understand this part: $$\frac{s}{\pi} \sum_{n=1}^{\infty} \frac{(2n\pi)^s}{n} \int_{0}^{\infty} \frac{\sin y}{y^{s+1}} dy = \frac{s}{\pi} (2\pi)^s \{-\Gamma(-s)\}\sin\frac{1}{2}s\pi\zeta(1-s)$$ I could not digest Titchmarsh's reasoning. Can anyone explain this please? Thanks,","In Titchmarsh's book ""The theory of the Riemann Zeta function"" pg. 15 where the functional equation of the zeta function is being derived,  I couldn't understand this part: $$\frac{s}{\pi} \sum_{n=1}^{\infty} \frac{(2n\pi)^s}{n} \int_{0}^{\infty} \frac{\sin y}{y^{s+1}} dy = \frac{s}{\pi} (2\pi)^s \{-\Gamma(-s)\}\sin\frac{1}{2}s\pi\zeta(1-s)$$ I could not digest Titchmarsh's reasoning. Can anyone explain this please? Thanks,",,"['complex-analysis', 'analytic-number-theory']"
86,How to plot a complex function?,How to plot a complex function?,,"We cannot plot graph of a complex function $f:\mathbb {C\to C}$ as it requires $4$ dimensions.But we can show how the mapping transforms the domain plane into image plane.We can draw grid lines parallel and perpendicular to $x$ -axis and see how the grid lines are modified.But often it becomes tedious task to plot these kind of diagrams.Is there any systematic procedure to draw such figures without help of any software? For example , $z^2,z^3,\sin(z),\log(z),\exp(z)$ etc. I want a method to visualize any given function.Is there a way out?","We cannot plot graph of a complex function as it requires dimensions.But we can show how the mapping transforms the domain plane into image plane.We can draw grid lines parallel and perpendicular to -axis and see how the grid lines are modified.But often it becomes tedious task to plot these kind of diagrams.Is there any systematic procedure to draw such figures without help of any software? For example , etc. I want a method to visualize any given function.Is there a way out?","f:\mathbb {C\to C} 4 x z^2,z^3,\sin(z),\log(z),\exp(z)","['complex-analysis', 'complex-numbers', 'graphing-functions', 'intuition', 'visualization']"
87,Find All Entire Functions that Satisfy Some Condition,Find All Entire Functions that Satisfy Some Condition,,"I am working on a problem stating that Find all entire functions $f$ that satisfy: $|zf(z)-\sin z|\leq 1+|z|^{4/3}$ for all $z\in\mathbb{C}$ . I am stuck in this problem but I had some attempts: (1): Since we are dealing with an  entire function, we want to apply Liouville’s theorem. However, the RHS is not a constant number. So we consider a disc $D(0, R)$ for $R$ large enough. Then for $z\in D(0,R)$ , we have $$|zf(z)-1|\leq |zf(z)-\sin z|\leq 1+|z|^{4/3}\leq 1+R^{4/3}.$$ Thus, by Liouville’s theorem, we know that the entire function $$g(z):=zf(z)-1$$ is constant. Thus, we have $$zf(z)-1=C,\ \text{for some constant}\ C.$$ However, here comes the problem. If we continue, we would have $$f(z)=\dfrac{c+1}{z},$$ but then $$\lim_{z\rightarrow 0}f(z)\neq 0$$ and thus $f(z)$ has a singularity at $z=0$ which is not removable, and thus $f(z)$ cannot be entire. So, such functions do not exist? I don't think my argument here is correct since $g(z)$ is only constant on a large disc, but not the whole complex plane. However, this is the only way I can think of to have some entire function being bounded. Other attempts could not yield me a constant on a side and an entire function on the other side. For instance (2): We can move $|z|^{4/3}$ to the LHS so that we have $$|zf(z)-\sin z|-|z|^{4/3}\leq 1,$$ but then I could not get a way to further shrink the LHS so that we have an entire function inside the complex norm. We can also move everything to the RHS, so that we can indeed have something like $$-1\leq |z|^{4/3}-|zf(z)-\sin z|\leq \Big||z|^{4/3}-|zf(z)-\sin z|\Big|\leq |z^{4/3}-zf(z)+\sin z|,$$ but this inequality does not tell us anything since the RHS must be positive, so it is absolutely larger than $-1$ . Any hints, ideas would be greatly appreciated! Thank you. Edit: The Whole Proof This proof follows exactly from what Martin R suggested. I am just adding more details. Define $$g(z):=zf(z)-\sin z.$$ As $f(z)$ is entire, $g(z)$ must also be entire. Thus, for any $R>0$ and $z_{0}\in\mathbb{C}$ , $g$ is holomorphic in an open set containing the closure of the disc $D(z_{0}, R)$ . Thus, by Cauchy's Inequalities, we have $$|g^{(n)}(z_{0})|\leq\dfrac{n!\sup_{z\in \partial D}|g(z)|}{R^{n}}.$$ On the other hand, as $|g(z)|\leq 1+|z|^{4/3}$ for all $z\in\mathbb{C}$ , we have $$\sup_{z\in \partial D}|g(z)|=1+R^{4/3},$$ so that $$|g^{(n)}(z_{0})|\leq\dfrac{n!(1+R^{4/3})}{R^{n}},\ \text{for all}\ z_{0}\in\mathbb{C}.$$ Taking $R\rightarrow 0$ , we can conclude that as long as $n>4/3>1$ , we have $|g^{n}(z_{0})|=0$ for $z_{0}\in\mathbb{C}$ . Thus, $g(z)$ is a polynomial of degree $1$ , i.e. we can write $g(z)$ as $$g(z)=az+b\ \text{for all}\ z\in\mathbb{C}.$$ Then, we have $$g(0)=0=b,$$ so that $$g(z)=az\ \text{for all}\ z\in\mathbb{C}.$$ Thus, $$|az|\leq 1+|z|^{4/3}\ \text{for all}\ z\in\mathbb{C}.$$ If $z=0$ , then $0\leq 1$ holds for all $a$ . For $z\in\mathbb{C}\setminus\{0\}$ , we can divide $|z|$ in both side so that $$|a|\leq |z|^{-1}+|z|^{1/3}.$$ For each $z\in\mathbb{C}\setminus\{0\}$ , we can find a disc with center at $0$ and radius $|z|:=r$ so that $z$ lives on the boundary. Thus, the above inequality can be rewritten into $$|a|\leq \dfrac{1}{r}+r^{1/3}\ \text{for all}\ r>0.$$ Since this inequality holds for all $r>0$ , we have $$|a|\leq\min\Big\{r>0:\dfrac{1}{r}+r^{1/3}\Big\}.$$ To find the minimum, define $$h(r):=\dfrac{1}{r}+r^{1/3},$$ so that $$h'(r)=-r^{-2}+\dfrac{1}{3}r^{-2/3}=r^{-2}\Big(-1+\dfrac{1}{3}r^{4/3}\Big),$$ and we have the critical point $r_{\min}=3^{3/4}$ . Also, for $r>r_{\min}$ , $h'(r)>0$ , and $r<r_{\min}$ , $h'(r)<0$ . Thus, $h(r)$ achieves local minimum for $r>0$ at $r_{\min}$ with the local minimum value $$h(r_{\min})=\dfrac{4}{3^{3/4}}.$$ Therefore, the entire function $f(z)$ also the form: $$f(z)=az,\ \text{where}\ |a|\leq \dfrac{4}{3^{3/4}}.$$ I'd like to express my appreciation to Martin R who always patiently answers my dumb questions. Please upvote his post, I own him too much. ^ ^","I am working on a problem stating that Find all entire functions that satisfy: for all . I am stuck in this problem but I had some attempts: (1): Since we are dealing with an  entire function, we want to apply Liouville’s theorem. However, the RHS is not a constant number. So we consider a disc for large enough. Then for , we have Thus, by Liouville’s theorem, we know that the entire function is constant. Thus, we have However, here comes the problem. If we continue, we would have but then and thus has a singularity at which is not removable, and thus cannot be entire. So, such functions do not exist? I don't think my argument here is correct since is only constant on a large disc, but not the whole complex plane. However, this is the only way I can think of to have some entire function being bounded. Other attempts could not yield me a constant on a side and an entire function on the other side. For instance (2): We can move to the LHS so that we have but then I could not get a way to further shrink the LHS so that we have an entire function inside the complex norm. We can also move everything to the RHS, so that we can indeed have something like but this inequality does not tell us anything since the RHS must be positive, so it is absolutely larger than . Any hints, ideas would be greatly appreciated! Thank you. Edit: The Whole Proof This proof follows exactly from what Martin R suggested. I am just adding more details. Define As is entire, must also be entire. Thus, for any and , is holomorphic in an open set containing the closure of the disc . Thus, by Cauchy's Inequalities, we have On the other hand, as for all , we have so that Taking , we can conclude that as long as , we have for . Thus, is a polynomial of degree , i.e. we can write as Then, we have so that Thus, If , then holds for all . For , we can divide in both side so that For each , we can find a disc with center at and radius so that lives on the boundary. Thus, the above inequality can be rewritten into Since this inequality holds for all , we have To find the minimum, define so that and we have the critical point . Also, for , , and , . Thus, achieves local minimum for at with the local minimum value Therefore, the entire function also the form: I'd like to express my appreciation to Martin R who always patiently answers my dumb questions. Please upvote his post, I own him too much. ^ ^","f |zf(z)-\sin z|\leq 1+|z|^{4/3} z\in\mathbb{C} D(0, R) R z\in D(0,R) |zf(z)-1|\leq |zf(z)-\sin z|\leq 1+|z|^{4/3}\leq 1+R^{4/3}. g(z):=zf(z)-1 zf(z)-1=C,\ \text{for some constant}\ C. f(z)=\dfrac{c+1}{z}, \lim_{z\rightarrow 0}f(z)\neq 0 f(z) z=0 f(z) g(z) |z|^{4/3} |zf(z)-\sin z|-|z|^{4/3}\leq 1, -1\leq |z|^{4/3}-|zf(z)-\sin z|\leq \Big||z|^{4/3}-|zf(z)-\sin z|\Big|\leq |z^{4/3}-zf(z)+\sin z|, -1 g(z):=zf(z)-\sin z. f(z) g(z) R>0 z_{0}\in\mathbb{C} g D(z_{0}, R) |g^{(n)}(z_{0})|\leq\dfrac{n!\sup_{z\in \partial D}|g(z)|}{R^{n}}. |g(z)|\leq 1+|z|^{4/3} z\in\mathbb{C} \sup_{z\in \partial D}|g(z)|=1+R^{4/3}, |g^{(n)}(z_{0})|\leq\dfrac{n!(1+R^{4/3})}{R^{n}},\ \text{for all}\ z_{0}\in\mathbb{C}. R\rightarrow 0 n>4/3>1 |g^{n}(z_{0})|=0 z_{0}\in\mathbb{C} g(z) 1 g(z) g(z)=az+b\ \text{for all}\ z\in\mathbb{C}. g(0)=0=b, g(z)=az\ \text{for all}\ z\in\mathbb{C}. |az|\leq 1+|z|^{4/3}\ \text{for all}\ z\in\mathbb{C}. z=0 0\leq 1 a z\in\mathbb{C}\setminus\{0\} |z| |a|\leq |z|^{-1}+|z|^{1/3}. z\in\mathbb{C}\setminus\{0\} 0 |z|:=r z |a|\leq \dfrac{1}{r}+r^{1/3}\ \text{for all}\ r>0. r>0 |a|\leq\min\Big\{r>0:\dfrac{1}{r}+r^{1/3}\Big\}. h(r):=\dfrac{1}{r}+r^{1/3}, h'(r)=-r^{-2}+\dfrac{1}{3}r^{-2/3}=r^{-2}\Big(-1+\dfrac{1}{3}r^{4/3}\Big), r_{\min}=3^{3/4} r>r_{\min} h'(r)>0 r<r_{\min} h'(r)<0 h(r) r>0 r_{\min} h(r_{\min})=\dfrac{4}{3^{3/4}}. f(z) f(z)=az,\ \text{where}\ |a|\leq \dfrac{4}{3^{3/4}}.",['complex-analysis']
88,Problem evaluating a contour integral using parametrization,Problem evaluating a contour integral using parametrization,,"I tried to solve the following contour integral: $$ \oint_\gamma  {\frac{{dz}}{{z - c}}} $$ Where $\gamma$ is a disk centered at the origin. In order to do so, I used the following parametrization:  $$ \begin{array}{l}  z &= Re^{i\varphi }, \qquad 0 < \left| R \right| \ne \left| c \right|  \\   dz &= iRe^{i\varphi } d\varphi   \end{array} $$ Replacing in the contour integral: $$ \begin{array}{l}  \oint_\gamma  {\frac{{dz}}{{z - c}}}  &= \int\limits_0^{2\pi } {\frac{{iRe^{i\varphi } }}{{Re^{i\varphi }  - c}}} d\varphi  \\    &= \left. {\ln \left( {Re^{i\varphi }  - c} \right)} \right|_0^{2\pi }  \\    &= \ln \left( {Re^{i2\pi }  - c} \right) - \ln \left( {Re^{i0}  - c} \right) \\    &= \ln \left( {R - c} \right) - \ln \left( {R - c} \right) \\    &= 0  \end{array} $$ However, by the residue theorem the contour integral must be equal to $2\pi i$ if $\left| R \right| > \left| c \right|$, whereas in the answer obtained by parametriztion the value is always $0$. My question is: What am I missing here? Where is my mistake? Thank you in advance.","I tried to solve the following contour integral: $$ \oint_\gamma  {\frac{{dz}}{{z - c}}} $$ Where $\gamma$ is a disk centered at the origin. In order to do so, I used the following parametrization:  $$ \begin{array}{l}  z &= Re^{i\varphi }, \qquad 0 < \left| R \right| \ne \left| c \right|  \\   dz &= iRe^{i\varphi } d\varphi   \end{array} $$ Replacing in the contour integral: $$ \begin{array}{l}  \oint_\gamma  {\frac{{dz}}{{z - c}}}  &= \int\limits_0^{2\pi } {\frac{{iRe^{i\varphi } }}{{Re^{i\varphi }  - c}}} d\varphi  \\    &= \left. {\ln \left( {Re^{i\varphi }  - c} \right)} \right|_0^{2\pi }  \\    &= \ln \left( {Re^{i2\pi }  - c} \right) - \ln \left( {Re^{i0}  - c} \right) \\    &= \ln \left( {R - c} \right) - \ln \left( {R - c} \right) \\    &= 0  \end{array} $$ However, by the residue theorem the contour integral must be equal to $2\pi i$ if $\left| R \right| > \left| c \right|$, whereas in the answer obtained by parametriztion the value is always $0$. My question is: What am I missing here? Where is my mistake? Thank you in advance.",,"['complex-analysis', 'logarithms', 'contour-integration', 'complex-integration']"
89,Understanding the Riemann Surface of the $\sqrt{z}$ [duplicate],Understanding the Riemann Surface of the  [duplicate],\sqrt{z},This question already has an answer here : Intuitively understanding Riemann surfaces (1 answer) Closed 6 years ago . I have been trying all the day to understand the Riemann Surface of the $\sqrt z$. I Can not understand . Can anyone help me to understand how this picture is Riemann Surface of $\sqrt z$. The other questioner did not ask this question. He already could visualize my question's answer. So I request you not to try to block this question. This is the only source from where I get help.   Please read that question. Intuitively understanding Riemann surfaces Explanation in simple words will be highly appreciated.,This question already has an answer here : Intuitively understanding Riemann surfaces (1 answer) Closed 6 years ago . I have been trying all the day to understand the Riemann Surface of the $\sqrt z$. I Can not understand . Can anyone help me to understand how this picture is Riemann Surface of $\sqrt z$. The other questioner did not ask this question. He already could visualize my question's answer. So I request you not to try to block this question. This is the only source from where I get help.   Please read that question. Intuitively understanding Riemann surfaces Explanation in simple words will be highly appreciated.,,"['complex-analysis', 'riemann-surfaces']"
90,How can it be shown that a Möbius transformation can have at most two fixed points unless it is $f(z) = z$?,How can it be shown that a Möbius transformation can have at most two fixed points unless it is ?,f(z) = z,"Obviously the identity fixes all points, but why do Möbius transformations fix at most two? I know that Möbius transformations map circles and lines to circles and lines, but how does that imply that no more than two points can be fixed?","Obviously the identity fixes all points, but why do Möbius transformations fix at most two? I know that Möbius transformations map circles and lines to circles and lines, but how does that imply that no more than two points can be fixed?",,"['complex-analysis', 'mobius-transformation', 'fixed-points']"
91,How to evaluate $ \int_0^\infty \frac{\log x}{(x^2+a^2)^2} dx $,How to evaluate, \int_0^\infty \frac{\log x}{(x^2+a^2)^2} dx ,"Evaluate $$  \int_0^\infty \frac{\log x}{(x^2+a^2)^2} dx $$ $$(a>0) $$ How can I use contour appropriately? What is the meaning of this integral? (additionally posted) I tried to solve this problem. First, I take a branch $$  \Omega=\mathbb C - \{z|\text{Re}(z)=0\; \text{and} \; \text{Im}(z)\le0\}  $$ Then ${\log_\Omega z}=\log r +i\theta (-\frac{\pi}{2}\lt\theta\lt\frac{3\pi}{2})$ Now, $\frac{\log z}{(z^2+a^2)^2}$ is holomorphic in $\Omega - \{ai\}$ with double poles at $ai$. Now I'll take the contour which forms an indented semicircle. For any $0\lt\epsilon\lt{a}$, where $\max (1,a)\lt R$, $\Gamma_{R,\epsilon}\subseteq\Omega - \{ai\}$ and in $\Omega$, $i=e^{i\pi/2}$. Now using the residue formula, $$2\pi{i}\operatorname*{Res}_{z=ai}\frac{\log_\Omega{z}}{(z^2+a^2)^2}=2\pi{i}\operatorname*{lim}_{z\to ai}\frac{d}{dz}(z-ai)^2\frac{\log_\Omega{z}}{(z^2+a^2)^2}=\frac{\pi}{2a^3}(\log_\Omega{ai}-1)$$ Now, the last part, take $i=e^{i\pi/2}$, then is equal to $\frac{\pi}{2a^3}(\log{a}-1+i\pi/2)$ So, I can split integrals by four parts, $$\int_{\epsilon}^R dz + \int_{\Gamma_R} dz + \int_{-R}^{-\epsilon} dz + \int_{\Gamma_\epsilon} dz$$ First, evaluate the second part, $$\left|\int_{\Gamma_R} dz\right|\le\int_0^{\pi}\left|\frac{\log_\Omega{Re^{i\theta}}}{(R^2e^{2i\theta}+a^2)^2}iRe^{i\theta}\right|d\theta$$ Note that $$\left|\log_\Omega{Re^{i\theta}}\right|=\left|\log R+i\theta\right|\le\left|\log R\right|+|\theta|$$ $$\left|R^2e^{2i\theta}+a^2\right|\ge R^2-a^2\quad (R\gt a)$$ Then, 2nd part $\le\frac{R(\pi R+\frac{\pi^2}{2})}{(R^2+a^2)^2}\to 0\; \text{as} \; R \to \infty\quad \left|\log R\right|\lt R\;\text{where}\;(R\gt 1)$ So, 4th part similarly, goes to $\;0$. Then 3rd part, substitute for $\;t=-z$, $$\int_\epsilon^{R}\frac{\log t}{(t^2+a^2)^2}dt + i\pi\int_\epsilon^{R}\frac{dt}{(t^2+a^2)^2}$$ And $\;i\pi\lim\limits_{{\epsilon \to 0},\;{R\to\infty}}\int_\epsilon^{R}\frac{dt}{(t^2+a^2)^2}=\frac{\pi}{4a^3}$ With tedious calculations, I got $\frac{\pi}{4a^3}(\log a -1)$.","Evaluate $$  \int_0^\infty \frac{\log x}{(x^2+a^2)^2} dx $$ $$(a>0) $$ How can I use contour appropriately? What is the meaning of this integral? (additionally posted) I tried to solve this problem. First, I take a branch $$  \Omega=\mathbb C - \{z|\text{Re}(z)=0\; \text{and} \; \text{Im}(z)\le0\}  $$ Then ${\log_\Omega z}=\log r +i\theta (-\frac{\pi}{2}\lt\theta\lt\frac{3\pi}{2})$ Now, $\frac{\log z}{(z^2+a^2)^2}$ is holomorphic in $\Omega - \{ai\}$ with double poles at $ai$. Now I'll take the contour which forms an indented semicircle. For any $0\lt\epsilon\lt{a}$, where $\max (1,a)\lt R$, $\Gamma_{R,\epsilon}\subseteq\Omega - \{ai\}$ and in $\Omega$, $i=e^{i\pi/2}$. Now using the residue formula, $$2\pi{i}\operatorname*{Res}_{z=ai}\frac{\log_\Omega{z}}{(z^2+a^2)^2}=2\pi{i}\operatorname*{lim}_{z\to ai}\frac{d}{dz}(z-ai)^2\frac{\log_\Omega{z}}{(z^2+a^2)^2}=\frac{\pi}{2a^3}(\log_\Omega{ai}-1)$$ Now, the last part, take $i=e^{i\pi/2}$, then is equal to $\frac{\pi}{2a^3}(\log{a}-1+i\pi/2)$ So, I can split integrals by four parts, $$\int_{\epsilon}^R dz + \int_{\Gamma_R} dz + \int_{-R}^{-\epsilon} dz + \int_{\Gamma_\epsilon} dz$$ First, evaluate the second part, $$\left|\int_{\Gamma_R} dz\right|\le\int_0^{\pi}\left|\frac{\log_\Omega{Re^{i\theta}}}{(R^2e^{2i\theta}+a^2)^2}iRe^{i\theta}\right|d\theta$$ Note that $$\left|\log_\Omega{Re^{i\theta}}\right|=\left|\log R+i\theta\right|\le\left|\log R\right|+|\theta|$$ $$\left|R^2e^{2i\theta}+a^2\right|\ge R^2-a^2\quad (R\gt a)$$ Then, 2nd part $\le\frac{R(\pi R+\frac{\pi^2}{2})}{(R^2+a^2)^2}\to 0\; \text{as} \; R \to \infty\quad \left|\log R\right|\lt R\;\text{where}\;(R\gt 1)$ So, 4th part similarly, goes to $\;0$. Then 3rd part, substitute for $\;t=-z$, $$\int_\epsilon^{R}\frac{\log t}{(t^2+a^2)^2}dt + i\pi\int_\epsilon^{R}\frac{dt}{(t^2+a^2)^2}$$ And $\;i\pi\lim\limits_{{\epsilon \to 0},\;{R\to\infty}}\int_\epsilon^{R}\frac{dt}{(t^2+a^2)^2}=\frac{\pi}{4a^3}$ With tedious calculations, I got $\frac{\pi}{4a^3}(\log a -1)$.",,"['complex-analysis', 'contour-integration']"
92,Are complex differentiable function in a point analytic?,Are complex differentiable function in a point analytic?,,"I know that if a function $f$ is complex differentiable in a neighborhood of $z_0$, then we say it's holomorphic in $z_0$ and it's also analytic in a neighborhood of $z_0$. But suppose that I know that $f'(z_0) = 0$ in the complex sense. I don't know what happens in a neighborhood of $z_0$; so can I say that the function $f$ is still analytic in $z_0$? I don't think we can conclude that there is a neighborhood of $z_0$ such that the function is analytics, but then again I'm not sure. Are there maybe additional condition to assume to ensure that the function is analytic? Thank you!","I know that if a function $f$ is complex differentiable in a neighborhood of $z_0$, then we say it's holomorphic in $z_0$ and it's also analytic in a neighborhood of $z_0$. But suppose that I know that $f'(z_0) = 0$ in the complex sense. I don't know what happens in a neighborhood of $z_0$; so can I say that the function $f$ is still analytic in $z_0$? I don't think we can conclude that there is a neighborhood of $z_0$ such that the function is analytics, but then again I'm not sure. Are there maybe additional condition to assume to ensure that the function is analytic? Thank you!",,"['complex-analysis', 'analysis', 'complex-numbers']"
93,Applications of Stein spaces in Algebraic Geometry,Applications of Stein spaces in Algebraic Geometry,,"I want to know where are essential applications of the theory of Stein spaces in algebraic geometry. I heard Cartan's theorem A & B were used in Serre's GAGA, but are there any other applications?","I want to know where are essential applications of the theory of Stein spaces in algebraic geometry. I heard Cartan's theorem A & B were used in Serre's GAGA, but are there any other applications?",,"['complex-analysis', 'algebraic-geometry', 'analytic-geometry']"
94,a sequence of polynomials converges to $0$,a sequence of polynomials converges to,0,"I am trying to show that there is a sequence $(P_{n})_{n}$ of polynomials such that $P'_{n}(0)=1$ for all $n$, $P'_{n}(z)\rightarrow0$ if $z \in \mathbb{C}^{\times}$ and $P_{n}(z)\rightarrow0$ if $z \in \mathbb{C}$ but I could not able to do that. I will appreciate for any help.","I am trying to show that there is a sequence $(P_{n})_{n}$ of polynomials such that $P'_{n}(0)=1$ for all $n$, $P'_{n}(z)\rightarrow0$ if $z \in \mathbb{C}^{\times}$ and $P_{n}(z)\rightarrow0$ if $z \in \mathbb{C}$ but I could not able to do that. I will appreciate for any help.",,['complex-analysis']
95,"If $p$ is a polynomial, then either $\,p(z)=z^n\,$ or $\,\max_{|z|=1}|p(z)|>1$.","If  is a polynomial, then either  or .","p \,p(z)=z^n\, \,\max_{|z|=1}|p(z)|>1",Let $p(z)=z^{n}+a_{n-1}z^{n-1}+...+a_{0}$ be a polynomial of degree $n\geq1$. How can you prove that either $p(z)=z^{n}$ or there exists $z'$ with $|z'|=1$ such that $|p(z')|>1$. Maybe we can use the maximum modulus principle and consider $q(z)=z^{n}p(1/z)$.,Let $p(z)=z^{n}+a_{n-1}z^{n-1}+...+a_{0}$ be a polynomial of degree $n\geq1$. How can you prove that either $p(z)=z^{n}$ or there exists $z'$ with $|z'|=1$ such that $|p(z')|>1$. Maybe we can use the maximum modulus principle and consider $q(z)=z^{n}p(1/z)$.,,"['complex-analysis', 'analysis', 'polynomials']"
96,How to plot complex functions on the paper by your hand?,How to plot complex functions on the paper by your hand?,,"I want to know the exact method of plotting complex function used by human, computer, and whatever who can do mathematics. For example how should I plot this : $w = u+iv$ , $z = x+iy$ , $w= f(z)= z^2$ I'm completely confused imagining the complex functions and I want to know how you would imagine such functions and do mathematics with it. Thanks in advance","I want to know the exact method of plotting complex function used by human, computer, and whatever who can do mathematics. For example how should I plot this : $w = u+iv$ , $z = x+iy$ , $w= f(z)= z^2$ I'm completely confused imagining the complex functions and I want to know how you would imagine such functions and do mathematics with it. Thanks in advance",,"['complex-analysis', 'graphing-functions']"
97,I am trying to show $\int^\infty_0\frac{\sin(x)}{x}dx=\frac{\pi}{2}$,I am trying to show,\int^\infty_0\frac{\sin(x)}{x}dx=\frac{\pi}{2},"I am trying to show $\int^\infty_0\frac{\sin(x)}{x}dx=\frac{\pi}{2}$ It was an exercise from a book about complex analysis, so I've gone through the complex plane to do it! Consider a semi-circle where |z|=R and $0<\arg(z)<\pi$. consider another, the exact same definition but swap R for $\epsilon$, I want to integrate from -R to $-\epsilon$ over the semi-circle that starts at $-\epsilon$ to $\epsilon$ then along the straight line to R, then from R anti-clockwise back to -R. I've been given the hint that the integral in the anticlockwise direction is zero, but the clockwise direction (for the $\epsilon$) is -j$\pi$ Here's the problem, my function is: $f(z)=\frac{e^{jz}}{z}$ I've established that f(z)dz = $je^{jz}$ but no amount of playing around has made this expression tolerable. Because I am considering the integral from 0 to infinity, if I can bound it above somehow by zero I can ""sandwich"" it between 0 and something that tends to zero. So far no luck.","I am trying to show $\int^\infty_0\frac{\sin(x)}{x}dx=\frac{\pi}{2}$ It was an exercise from a book about complex analysis, so I've gone through the complex plane to do it! Consider a semi-circle where |z|=R and $0<\arg(z)<\pi$. consider another, the exact same definition but swap R for $\epsilon$, I want to integrate from -R to $-\epsilon$ over the semi-circle that starts at $-\epsilon$ to $\epsilon$ then along the straight line to R, then from R anti-clockwise back to -R. I've been given the hint that the integral in the anticlockwise direction is zero, but the clockwise direction (for the $\epsilon$) is -j$\pi$ Here's the problem, my function is: $f(z)=\frac{e^{jz}}{z}$ I've established that f(z)dz = $je^{jz}$ but no amount of playing around has made this expression tolerable. Because I am considering the integral from 0 to infinity, if I can bound it above somehow by zero I can ""sandwich"" it between 0 and something that tends to zero. So far no luck.",,['complex-analysis']
98,Calculating $\int_{0}^{\infty} x^{a-1} \cos(x) \ \mathrm dx = \Gamma(a) \cos (\pi a/2)$ [duplicate],Calculating  [duplicate],\int_{0}^{\infty} x^{a-1} \cos(x) \ \mathrm dx = \Gamma(a) \cos (\pi a/2),"This question already has answers here : evaluate $\int_{0}^{\infty}\cos(t) t^{z-1}dt=\Gamma(z)\cos(\frac{\pi z}{2})$ (6 answers) Closed 6 years ago . My goal is to calculate the integral $\int_{0}^{\infty} x^{a-1} \cos(x) dx = \Gamma(a) \cos (\pi a/2)$, where $0<a<1$, and my textbook provides the hint: integrate $z^{a-1} e^{iz}$ around the boundary of a quarter disk. However, I couldn't figure out how to control the integral over the quarter arc. Any hints?","This question already has answers here : evaluate $\int_{0}^{\infty}\cos(t) t^{z-1}dt=\Gamma(z)\cos(\frac{\pi z}{2})$ (6 answers) Closed 6 years ago . My goal is to calculate the integral $\int_{0}^{\infty} x^{a-1} \cos(x) dx = \Gamma(a) \cos (\pi a/2)$, where $0<a<1$, and my textbook provides the hint: integrate $z^{a-1} e^{iz}$ around the boundary of a quarter disk. However, I couldn't figure out how to control the integral over the quarter arc. Any hints?",,"['complex-analysis', 'residue-calculus']"
99,$f$ is an entire function with Im $f\geq 0$,is an entire function with Im,f f\geq 0,$f$ is an entire function with $\operatorname{Im}f \geq 0$ . Then which of the followings are true: $f$ is constant. $\operatorname{Re}f$ is constant. $f = 0$ . $f'$ is a non-zero constant. That (3) & (4) are wrong can be shown by using $f(z) = i$ . But I'm clueless about the remaining two options.,is an entire function with . Then which of the followings are true: is constant. is constant. . is a non-zero constant. That (3) & (4) are wrong can be shown by using . But I'm clueless about the remaining two options.,f \operatorname{Im}f \geq 0 f \operatorname{Re}f f = 0 f' f(z) = i,['complex-analysis']
