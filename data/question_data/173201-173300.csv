,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Reference request: Asymptotic distribution of degenerate V-statistics,Reference request: Asymptotic distribution of degenerate V-statistics,,"I'm looking for references on the asymptotic distribution of V-statistics with 2nd order degenerate symmetric kernel $h:\mathcal{X}^k \to \mathbb{R}$ of degree $k\geq 2$. That is, we are considering the following V-statistic $$ V_n = \frac{1}{n^k}\sum_{i_1=1}^n\cdots \sum_{i_k=1}^n h(X_{i_1},...,X_{i_k}) $$ and the corresponding U-statistic $$ U_n = {n\choose k}^{-1}\sum_{1\leq i_1<\cdots <i_k \leq n} h(X_{i_1},...,X_{i_k}) $$ for some i.i.d. sequence $(X_n)_{n\in\mathbb{N}}$ of random elements in $\mathcal{X}$. If $h$ is 2nd order degenerate we know that  $ nU_n \Rightarrow \sum_{i=1}^\infty \lambda_i (Z_i^2-1), $ where $(Z_i)$ is an i.i.d. sequence of standard normal distributed random variables and $(\lambda_i)$ is the eigenvalues of a linear operator $S:L^2(\mathcal{X},P_X)\to L^2(\mathcal{X},P_X)$. The procedure used by Serfling(1980) to derive the asymptotic distribution of V-statistics from the asymptotic distribution of U-statistics in the non-degenerate case, can't be used when $h$ is degenerate. However I have seen some weak convergence results for V-statistics with degenerate kernels: Every monograph on U-statistics I have encountered ( ""Theory of U-statistics"" (1994) by Borovskich and Koroljuk p. 141 & ""Approximation Theorems of Mathematical Statistics"" (1980) by Serfling p. 227 ) only shows the degenerate V-statistic weak convergence for $k=2$, that is if $h$ is a 2nd order degenerate kernel of degree 2, then (under some conditions of course) $$ nV_n \Rightarrow \sum_{i=1}^\infty \lambda_i Z_i^2. $$ I need a similar result for a 2nd order degenerate kernel of degree $k>2$, can somebody provide me with a reference for such a result?","I'm looking for references on the asymptotic distribution of V-statistics with 2nd order degenerate symmetric kernel $h:\mathcal{X}^k \to \mathbb{R}$ of degree $k\geq 2$. That is, we are considering the following V-statistic $$ V_n = \frac{1}{n^k}\sum_{i_1=1}^n\cdots \sum_{i_k=1}^n h(X_{i_1},...,X_{i_k}) $$ and the corresponding U-statistic $$ U_n = {n\choose k}^{-1}\sum_{1\leq i_1<\cdots <i_k \leq n} h(X_{i_1},...,X_{i_k}) $$ for some i.i.d. sequence $(X_n)_{n\in\mathbb{N}}$ of random elements in $\mathcal{X}$. If $h$ is 2nd order degenerate we know that  $ nU_n \Rightarrow \sum_{i=1}^\infty \lambda_i (Z_i^2-1), $ where $(Z_i)$ is an i.i.d. sequence of standard normal distributed random variables and $(\lambda_i)$ is the eigenvalues of a linear operator $S:L^2(\mathcal{X},P_X)\to L^2(\mathcal{X},P_X)$. The procedure used by Serfling(1980) to derive the asymptotic distribution of V-statistics from the asymptotic distribution of U-statistics in the non-degenerate case, can't be used when $h$ is degenerate. However I have seen some weak convergence results for V-statistics with degenerate kernels: Every monograph on U-statistics I have encountered ( ""Theory of U-statistics"" (1994) by Borovskich and Koroljuk p. 141 & ""Approximation Theorems of Mathematical Statistics"" (1980) by Serfling p. 227 ) only shows the degenerate V-statistic weak convergence for $k=2$, that is if $h$ is a 2nd order degenerate kernel of degree 2, then (under some conditions of course) $$ nV_n \Rightarrow \sum_{i=1}^\infty \lambda_i Z_i^2. $$ I need a similar result for a 2nd order degenerate kernel of degree $k>2$, can somebody provide me with a reference for such a result?",,"['statistics', 'reference-request', 'weak-convergence', 'central-limit-theorem', 'probability-limit-theorems']"
1,How does Dr. Anderson's famous haystack example justify Bayesian statistics?,How does Dr. Anderson's famous haystack example justify Bayesian statistics?,,"I'm looking at Dr. Anderson's explanation of Bayesian statistics for a simple haystack model, from http://www.ar-tiste.com/pwa-on-bayes.html and reproduced below: There are two sources of hay, one with no needles at all and one with up to 9 needles per stack. Let's assign precisely probability 1/2, for the sake of argument, to the case where I'm buying from the needle-free source. (This represents the ""null hypothesis"" in this example.) If I'm dealing with the potentially needly hay, let's assume that p= (1/2)(1/10) for 0,1, . . . ,9 needles in anyone stack. I search for needles in one stack, and find none. What do I now know? I know that this outcome had p = 1/2 for needle-free hay, p = 1/20 for needly hay; hence the probability of this outcome is 10 times as great if the hay is needle free. The new ""a posteriori"" probability of the null hypothesis is therefore 10/11 = (1/2)(1/2+1/20 ) rather than 1/2. Clearly I should buy this hay if that is a good enough bet. Now suppose I was an ordinary statistician: I would simply say my expected number of needles per stack is now down to 0 +/- 2.5, and to get to 90% certainty I must search at least ten more haystacks, which is ten times as boring. I have difficulty following this logic: (1/2)(1/2+1/20) = 11/40 by my calculation. I think this is the probability of buying two haystacks from our source with no needles. I think the null hypothesis is that our source is the needle-free seller. I'm not sure where 10/11 comes from. how is 0 +/- 2.5 derived? What does 0-2.5 expected # of needles actually mean? He seems to be jumping a few, doubtless trivial, steps that I've missed. I'm not an ordinary or bayesian statistician but would like a basic understanding of the argument. If someone can help it would be appreciated. thanks","I'm looking at Dr. Anderson's explanation of Bayesian statistics for a simple haystack model, from http://www.ar-tiste.com/pwa-on-bayes.html and reproduced below: There are two sources of hay, one with no needles at all and one with up to 9 needles per stack. Let's assign precisely probability 1/2, for the sake of argument, to the case where I'm buying from the needle-free source. (This represents the ""null hypothesis"" in this example.) If I'm dealing with the potentially needly hay, let's assume that p= (1/2)(1/10) for 0,1, . . . ,9 needles in anyone stack. I search for needles in one stack, and find none. What do I now know? I know that this outcome had p = 1/2 for needle-free hay, p = 1/20 for needly hay; hence the probability of this outcome is 10 times as great if the hay is needle free. The new ""a posteriori"" probability of the null hypothesis is therefore 10/11 = (1/2)(1/2+1/20 ) rather than 1/2. Clearly I should buy this hay if that is a good enough bet. Now suppose I was an ordinary statistician: I would simply say my expected number of needles per stack is now down to 0 +/- 2.5, and to get to 90% certainty I must search at least ten more haystacks, which is ten times as boring. I have difficulty following this logic: (1/2)(1/2+1/20) = 11/40 by my calculation. I think this is the probability of buying two haystacks from our source with no needles. I think the null hypothesis is that our source is the needle-free seller. I'm not sure where 10/11 comes from. how is 0 +/- 2.5 derived? What does 0-2.5 expected # of needles actually mean? He seems to be jumping a few, doubtless trivial, steps that I've missed. I'm not an ordinary or bayesian statistician but would like a basic understanding of the argument. If someone can help it would be appreciated. thanks",,"['statistics', 'bayesian']"
2,expected value and variance of function,expected value and variance of function,,"I am confused about calculating the expected value of a function that is split, the question looks as follows: and my solution is: Which are incorrect.. can someone please help me to correct the answers. Or tell me what I'm doing wrong. Thank you","I am confused about calculating the expected value of a function that is split, the question looks as follows: and my solution is: Which are incorrect.. can someone please help me to correct the answers. Or tell me what I'm doing wrong. Thank you",,['statistics']
3,Convergence of sums of independent random variables,Convergence of sums of independent random variables,,"Hey I need some help with a problem: Let $X_{n1},X_{n2},...,X_{nn}$ be independent random variables with a common distribution as follows: $$P(X_{nk}=0)=1-\frac{1}{n}-\frac{1}{n^2}, P(X_{nk}=1)=\frac{1}{n}, P(X_{nk}=2)=\frac{1}{n^2}, $$ where k=1,2,.. and n=2,3,... $S_{n}=X_{n1}+X_{n2}+...+X_{nn}$, $n>=2$ Show that $S_{n}\stackrel{d}{\rightarrow}Po(1)$ as n $\rightarrow \infty$ I've started like this: $$E[e^{tS_{n}}]=E[e^{tX_{n1}+tX_{n2}+...+tX_{nn}}]=\prod_{k=1}^{n}E[e^{tX_{nk}}]=\prod_{n=2}^{\infty}(1-\frac{1}{n}-\frac{1}{n^2}+\frac{1}{n}e^{t}+\frac{1}{n^2}e^{2t})$$ but I'm not sure I'm going with the right approach. Does someone have any tips for me?","Hey I need some help with a problem: Let $X_{n1},X_{n2},...,X_{nn}$ be independent random variables with a common distribution as follows: $$P(X_{nk}=0)=1-\frac{1}{n}-\frac{1}{n^2}, P(X_{nk}=1)=\frac{1}{n}, P(X_{nk}=2)=\frac{1}{n^2}, $$ where k=1,2,.. and n=2,3,... $S_{n}=X_{n1}+X_{n2}+...+X_{nn}$, $n>=2$ Show that $S_{n}\stackrel{d}{\rightarrow}Po(1)$ as n $\rightarrow \infty$ I've started like this: $$E[e^{tS_{n}}]=E[e^{tX_{n1}+tX_{n2}+...+tX_{nn}}]=\prod_{k=1}^{n}E[e^{tX_{nk}}]=\prod_{n=2}^{\infty}(1-\frac{1}{n}-\frac{1}{n^2}+\frac{1}{n}e^{t}+\frac{1}{n^2}e^{2t})$$ but I'm not sure I'm going with the right approach. Does someone have any tips for me?",,"['probability-theory', 'statistics', 'expectation']"
4,Is $E[\frac{\alpha}{b+x}]$ decreasing in $\alpha$ when $x$ is Gamma distributed with parameters $\alpha$ and $\beta$,Is  decreasing in  when  is Gamma distributed with parameters  and,E[\frac{\alpha}{b+x}] \alpha x \alpha \beta,"My question is whether $E[\frac{\alpha}{b+x}]$ is decreasing in $\alpha$ when $x$ is Gamma distributed with parameters $\alpha$ and $\beta$ (under the shape/rate parameterization). It seems like it would hold intuitively, and numerically, but the actual derivative of the expectation is incredibly complicated, so I don't even know where to start.","My question is whether $E[\frac{\alpha}{b+x}]$ is decreasing in $\alpha$ when $x$ is Gamma distributed with parameters $\alpha$ and $\beta$ (under the shape/rate parameterization). It seems like it would hold intuitively, and numerically, but the actual derivative of the expectation is incredibly complicated, so I don't even know where to start.",,"['probability', 'statistics', 'probability-distributions']"
5,Proving $\phi$ is convex if and only if $\phi'(x) \leq \phi'(y)$ for all $a < x < y < b$,Proving  is convex if and only if  for all,\phi \phi'(x) \leq \phi'(y) a < x < y < b,"I'm an undergraduate student that find a problem for proofing theorem below. First it defined that: A function f defined on an interval (a,b), $-∞ ≤ a < b≤ ∞$, is said to be a convex function if for all x,y in (a,b) and for all $0 < γ < 1$, $$f[γx + (1 - γ)y] ≤ γf(x) + (1 - γ)f(y)$$  We say f is strictly convex if the above inequality is strict. The theorem said that, if f is differentiable on (a,b), then 1) f is convex if and only if $f' (x) ≤ f'(y)$, for all $a < x < y < b$, 2) f is strictly convex if and only if $f'(x) < f'(y)$, for all $a < x < y < b$. I try to proof the first part from the left to the right, in this way: a) Let f is differentiable on (a,b), and f is convex. Let $γ=\frac{(k-j)}{(k-x)}$. The value of γ is arbitrary value such that $0<γ<1$. Choosing x,j,k and y, such that $a < x <j<k< y < b$, and $j=\frac{(k-j)}{(k-x)} x+\frac{(j-x)}{(k-x)}k$,  so, by the  definiton of convex  $$f(j)=f\left(\frac{(k-j)}{(k-x)} x+\frac{(j-x)}{(k-x)} k\right)≤\frac{(k-j)}{(k-x)} f(x)+\frac{(j-x)}{(k-x)} f(k)$$ Then $(k-x)f(j)≤(k-j)f(x)+(j-x)f(k)$ $((k-j)+(j-x) )f(j)≤(k-j)f(x)+(j-x)f(k)$ $(k-j)f(j)+(j-x)f(j)≤(k-j)f(x)+(j-x)f(k)$ $(k-j)f(j)-(k-j)f(x)≤(j-x)f(k)-(j-x)f(j)$ $(k-j)[f(j)-f(x) ]≤(j-x)[f(k)-f(j) ]$ $$\frac{[f(j)-f(x) ]}{(j-x)}≤\frac{[f(k)-f(j) ]}{(k-j)}$$ Doing the same step for j,k and  y, yields $$\frac{[f(k)-f(j) ]}{(k-j)}≤\frac{[f(y)-f(k) ]}{(y-k)}$$ So, we get $$\frac{[f(j)-f(x) ]}{(j-x)}≤\frac{[f(k)-f(j) ]}{(k-j)}≤\frac{[f(y)-f(k) ]}{(y-k)}$$ $$\frac{[f(j)-f(x) ]}{(j-x)}≤\frac{[f(y)-f(k) ]}{(y-k)}$$ and the last step i was taking the limit j→x for the left side and k→y for the right one, yields $ f' (x)=lim_{j→x}⁡\left(\frac{[f(j)-f(x) ]}{(j-x)}\right)≤lim_{k→y}⁡\left(\frac{[f(y)-f(k) ]}{(y-k)}\right)=f' (y) $ is it reasonable to doing this? i have searching for the proof in some reference but i haven't find a clear explanation yet. ones said that the last step   you should take the limit $j→x^+$ and $k→y^-$, but i didn't understand what the reason. I find this problem in Robert V. Hogg math statistic book. The right reference should be analysis book from Hewitt-Stromberg but i didn't find it in my library.","I'm an undergraduate student that find a problem for proofing theorem below. First it defined that: A function f defined on an interval (a,b), $-∞ ≤ a < b≤ ∞$, is said to be a convex function if for all x,y in (a,b) and for all $0 < γ < 1$, $$f[γx + (1 - γ)y] ≤ γf(x) + (1 - γ)f(y)$$  We say f is strictly convex if the above inequality is strict. The theorem said that, if f is differentiable on (a,b), then 1) f is convex if and only if $f' (x) ≤ f'(y)$, for all $a < x < y < b$, 2) f is strictly convex if and only if $f'(x) < f'(y)$, for all $a < x < y < b$. I try to proof the first part from the left to the right, in this way: a) Let f is differentiable on (a,b), and f is convex. Let $γ=\frac{(k-j)}{(k-x)}$. The value of γ is arbitrary value such that $0<γ<1$. Choosing x,j,k and y, such that $a < x <j<k< y < b$, and $j=\frac{(k-j)}{(k-x)} x+\frac{(j-x)}{(k-x)}k$,  so, by the  definiton of convex  $$f(j)=f\left(\frac{(k-j)}{(k-x)} x+\frac{(j-x)}{(k-x)} k\right)≤\frac{(k-j)}{(k-x)} f(x)+\frac{(j-x)}{(k-x)} f(k)$$ Then $(k-x)f(j)≤(k-j)f(x)+(j-x)f(k)$ $((k-j)+(j-x) )f(j)≤(k-j)f(x)+(j-x)f(k)$ $(k-j)f(j)+(j-x)f(j)≤(k-j)f(x)+(j-x)f(k)$ $(k-j)f(j)-(k-j)f(x)≤(j-x)f(k)-(j-x)f(j)$ $(k-j)[f(j)-f(x) ]≤(j-x)[f(k)-f(j) ]$ $$\frac{[f(j)-f(x) ]}{(j-x)}≤\frac{[f(k)-f(j) ]}{(k-j)}$$ Doing the same step for j,k and  y, yields $$\frac{[f(k)-f(j) ]}{(k-j)}≤\frac{[f(y)-f(k) ]}{(y-k)}$$ So, we get $$\frac{[f(j)-f(x) ]}{(j-x)}≤\frac{[f(k)-f(j) ]}{(k-j)}≤\frac{[f(y)-f(k) ]}{(y-k)}$$ $$\frac{[f(j)-f(x) ]}{(j-x)}≤\frac{[f(y)-f(k) ]}{(y-k)}$$ and the last step i was taking the limit j→x for the left side and k→y for the right one, yields $ f' (x)=lim_{j→x}⁡\left(\frac{[f(j)-f(x) ]}{(j-x)}\right)≤lim_{k→y}⁡\left(\frac{[f(y)-f(k) ]}{(y-k)}\right)=f' (y) $ is it reasonable to doing this? i have searching for the proof in some reference but i haven't find a clear explanation yet. ones said that the last step   you should take the limit $j→x^+$ and $k→y^-$, but i didn't understand what the reason. I find this problem in Robert V. Hogg math statistic book. The right reference should be analysis book from Hewitt-Stromberg but i didn't find it in my library.",,"['statistics', 'convex-analysis']"
6,Intersection between $2$ sample sets of large lists,Intersection between  sample sets of large lists,2,"Say I have a List A of $1,000,000$ values, and List $B$ of $2,000,000$ values.  I want to know what percent of List $B$ is in list A without looking at all $2,000,000$ values and referencing List $A$. So, I want to only look at some of list $A$ and list $B$, rather than going through the entire list. Is there a way to reliably look at a percentage of the values of list $A$ and a percentage of the values of list $B$ (at random), compare those samples, and estimate the percent overlap for the entire lists $A$ and $B$?","Say I have a List A of $1,000,000$ values, and List $B$ of $2,000,000$ values.  I want to know what percent of List $B$ is in list A without looking at all $2,000,000$ values and referencing List $A$. So, I want to only look at some of list $A$ and list $B$, rather than going through the entire list. Is there a way to reliably look at a percentage of the values of list $A$ and a percentage of the values of list $B$ (at random), compare those samples, and estimate the percent overlap for the entire lists $A$ and $B$?",,['statistics']
7,Hoeffding's inequality for dependent random variables,Hoeffding's inequality for dependent random variables,,"suppose that I have $n$ independent sub-Gaussian random variables, $x_1,\ldots,x_n$. Let real-valued function $g(\cdot,\cdot)\in[-1,1]$ and $\mathbb{E}[g(\cdot,\cdot)]=0$. Set $S=\frac{2}{n(n-1)}\sum_{1\leq i< j\leq n}g(x_i,x_j)$ How can I bound the term $S$ with high probability? Hoeffding's inequality does not hold here since $g(\cdot,\cdot)$ are not independent. Nevertheless, can I get a similar bound as the Hoeffding's inequality? More specifically, I want a bound in the form of $\mathbb{P}(S>t)\leq e^{-ct^2}$ for any $t>0$.","suppose that I have $n$ independent sub-Gaussian random variables, $x_1,\ldots,x_n$. Let real-valued function $g(\cdot,\cdot)\in[-1,1]$ and $\mathbb{E}[g(\cdot,\cdot)]=0$. Set $S=\frac{2}{n(n-1)}\sum_{1\leq i< j\leq n}g(x_i,x_j)$ How can I bound the term $S$ with high probability? Hoeffding's inequality does not hold here since $g(\cdot,\cdot)$ are not independent. Nevertheless, can I get a similar bound as the Hoeffding's inequality? More specifically, I want a bound in the form of $\mathbb{P}(S>t)\leq e^{-ct^2}$ for any $t>0$.",,"['probability', 'statistics']"
8,"""Statistics"": How many of these begin and end with the letter ""S""?","""Statistics"": How many of these begin and end with the letter ""S""?",,"How many distinct permutations are there of the letters   in the word “ statistics”? How many of these begin   and end with the letter s? The first part of the question I do understand. You have to use permutation with identical items. This is based on the number of letters. $$\binom{10}{3,3,1,2,1} = 50400$$ Yet for the second part I am confused as to what the directions means. It says that how many letters begin and ends with letters s so does one eliminate $2$ s and calculate this problem normally? BONUS:  If so using a similar example how does one find out if how many of these begin and end with the letters m for the word ""mathematicsman"" ?","How many distinct permutations are there of the letters   in the word “ statistics”? How many of these begin   and end with the letter s? The first part of the question I do understand. You have to use permutation with identical items. This is based on the number of letters. $$\binom{10}{3,3,1,2,1} = 50400$$ Yet for the second part I am confused as to what the directions means. It says that how many letters begin and ends with letters s so does one eliminate $2$ s and calculate this problem normally? BONUS:  If so using a similar example how does one find out if how many of these begin and end with the letters m for the word ""mathematicsman"" ?",,"['statistics', 'permutations']"
9,Bivariate Normal Likelihood Ratio Statistic,Bivariate Normal Likelihood Ratio Statistic,,"Define $\Theta = \left\{\left(\mu_x,\mu_y,\sigma_x^2,\sigma_y^2,\sigma_{xy}\right)\in\mathbb{R}^5\right\}$ to be the set of possible parametrizations of (possibly) correlated bivariate normal distributions. Let $\Theta_0\subset\Theta$ be some subset of those parameters satisfying the property, $$ \Theta_0 = \left\{\left(\mu_x,\mu_y,\sigma_x^2,\sigma_y^2\right)\in\mathbb{R}^4 : \mu_x \leq 0, \sigma_{xy}=0\right\}, $$ that is to say, the set of uncorrelated bivariate normals with horizontal mean less than or equal to zero. I am developing a hypothesis test of the form, $$ H_0 : \theta \in \Theta_0 ~~~~~~~~~~~~~ H_1: \theta\not\in\Theta_0. $$ Let $\mathbf{X}^n$ be a set of $n$ i.i.d. data points drawn from a bivariate normal. Then usually I would use a likelihood ratio test statistic for the purposes of evaluating the test. In particular, $$ \Lambda\left(\mathbf{X}^n\right) = \frac{\sup_{\theta \in\Theta_0} \mathcal{L}\left(\mathbf{X}^n;\theta\right)}{\sup_{\theta \in\Theta} \mathcal{L}\left(\mathbf{X}^n;\theta\right)} $$ At this point a common question concerns the distribution of $\log \Lambda\left(\mathbf{X}^n\right)$. Let us suppose that the null hypothesis is true. Suppose furthermore that  $$ \theta^\star = \arg\sup_{\theta\in\Theta}\mathcal{L}\left(\mathbf{X}^n;\theta\right) $$ is an element of $\Theta_0$. That is to say, that the maximum likelihood parameter configuration is an element of the null hypothesis set. When this is true, it is fairly easy for me to verify that $-2\log\Lambda \sim\chi^2_1$. This is apparent because if the maximum likelihood estimate of $\mu_x$ is less than or equal to zero, then the full parameter space has an additional degree of freedom in $\sigma_{xy}$. But when $\theta^\star \not\in\Theta_0$, the distribution will be most messy and undesirable. What I would like to show is that the asymptotic distribution of $\log\Lambda\left(\mathbf{X}^n\right)$ is still $\chi^2_1$ under the null. My ""proof"" of this would be quite straightforward since, due to the consistency of the maximum likelihood estimate, $$ \mathbb{P}\left[\lim_{n\to\infty} \theta^\star = \theta\right] = 1, $$  and under the null we have that $\theta\in\Theta_0$ and hence almost surely $\theta^\star\in\Theta_0$. This brings us back to the case where the denominator in the likelihood ratio statistic has a single extra degree of freedom and therefore the statistic goes to a $\chi^2_1$. I would like to know if this reasoning regarding the asymptotic distribution of $\log\Lambda\left(\mathbf{X}^n\right)$ is correct.","Define $\Theta = \left\{\left(\mu_x,\mu_y,\sigma_x^2,\sigma_y^2,\sigma_{xy}\right)\in\mathbb{R}^5\right\}$ to be the set of possible parametrizations of (possibly) correlated bivariate normal distributions. Let $\Theta_0\subset\Theta$ be some subset of those parameters satisfying the property, $$ \Theta_0 = \left\{\left(\mu_x,\mu_y,\sigma_x^2,\sigma_y^2\right)\in\mathbb{R}^4 : \mu_x \leq 0, \sigma_{xy}=0\right\}, $$ that is to say, the set of uncorrelated bivariate normals with horizontal mean less than or equal to zero. I am developing a hypothesis test of the form, $$ H_0 : \theta \in \Theta_0 ~~~~~~~~~~~~~ H_1: \theta\not\in\Theta_0. $$ Let $\mathbf{X}^n$ be a set of $n$ i.i.d. data points drawn from a bivariate normal. Then usually I would use a likelihood ratio test statistic for the purposes of evaluating the test. In particular, $$ \Lambda\left(\mathbf{X}^n\right) = \frac{\sup_{\theta \in\Theta_0} \mathcal{L}\left(\mathbf{X}^n;\theta\right)}{\sup_{\theta \in\Theta} \mathcal{L}\left(\mathbf{X}^n;\theta\right)} $$ At this point a common question concerns the distribution of $\log \Lambda\left(\mathbf{X}^n\right)$. Let us suppose that the null hypothesis is true. Suppose furthermore that  $$ \theta^\star = \arg\sup_{\theta\in\Theta}\mathcal{L}\left(\mathbf{X}^n;\theta\right) $$ is an element of $\Theta_0$. That is to say, that the maximum likelihood parameter configuration is an element of the null hypothesis set. When this is true, it is fairly easy for me to verify that $-2\log\Lambda \sim\chi^2_1$. This is apparent because if the maximum likelihood estimate of $\mu_x$ is less than or equal to zero, then the full parameter space has an additional degree of freedom in $\sigma_{xy}$. But when $\theta^\star \not\in\Theta_0$, the distribution will be most messy and undesirable. What I would like to show is that the asymptotic distribution of $\log\Lambda\left(\mathbf{X}^n\right)$ is still $\chi^2_1$ under the null. My ""proof"" of this would be quite straightforward since, due to the consistency of the maximum likelihood estimate, $$ \mathbb{P}\left[\lim_{n\to\infty} \theta^\star = \theta\right] = 1, $$  and under the null we have that $\theta\in\Theta_0$ and hence almost surely $\theta^\star\in\Theta_0$. This brings us back to the case where the denominator in the likelihood ratio statistic has a single extra degree of freedom and therefore the statistic goes to a $\chi^2_1$. I would like to know if this reasoning regarding the asymptotic distribution of $\log\Lambda\left(\mathbf{X}^n\right)$ is correct.",,"['statistics', 'normal-distribution', 'maximum-likelihood', 'bivariate-distributions', 'log-likelihood']"
10,Autocovariance function at asymptotically large samples,Autocovariance function at asymptotically large samples,,"Periodicities are a common phenomena. A process generates a sinusoidal wave, which is observed with error, $$ y[k] = A \sin(2 \pi f_0k) + e[k]$$ where $e[k]$ is the usual zero-mean unit-variance White Noise sequence and A,$f_0$ are suitable constants. a. Prove that time-averaged ACVF of $y[k]$, $$R_{yy}[l] = \frac{1}{N} \sum_{k=l+1}^N (y[k] -\vec{y})(y[k-l]-\vec{y}) $$ where $\vec{y}$ is the sample mean, is asymptotically (large samples, $N\to\infty$) also a sinusoidal sequence with frequency $f_0$ b. Is there any advantage of detecting periodicity of the sine wave from its ACF rather than examining $y[k]$ directly?","Periodicities are a common phenomena. A process generates a sinusoidal wave, which is observed with error, $$ y[k] = A \sin(2 \pi f_0k) + e[k]$$ where $e[k]$ is the usual zero-mean unit-variance White Noise sequence and A,$f_0$ are suitable constants. a. Prove that time-averaged ACVF of $y[k]$, $$R_{yy}[l] = \frac{1}{N} \sum_{k=l+1}^N (y[k] -\vec{y})(y[k-l]-\vec{y}) $$ where $\vec{y}$ is the sample mean, is asymptotically (large samples, $N\to\infty$) also a sinusoidal sequence with frequency $f_0$ b. Is there any advantage of detecting periodicity of the sine wave from its ACF rather than examining $y[k]$ directly?",,"['probability', 'statistics', 'time-series']"
11,Finding the MLEs of the Odds Ratio and the Log-Odds Ratio,Finding the MLEs of the Odds Ratio and the Log-Odds Ratio,,"Take two random variables $Y$ and $Z$ with support $\{1,2\}$ each, and let $p_{i,j} = P(Z = i,Y = j).$ We define the odds ratio to be $$\psi = \frac{p_{1,1}p_{2,2}}{p_{1,2}p_{2,1}}$$ and the log-odds ratio to be $$\gamma = \log(\psi).$$ I want to show that the MLE for $\psi$ is $\hat{\psi} = \frac{X_{1,1}X_{2,2}}{X_{1,2}X_{2,1}}$ where $X_{i,j} = \#\{Z = i \wedge Y = j\},$ and I want to show that the MLE for $\gamma$ is $\hat{\gamma} = \log(\hat{\psi}).$ The MLE for $\gamma$ is trivial given the property of equivariance of estimators. I do see that $$\hat{\psi} = \frac{\hat{p}_{1,1}\hat{p}_{2,2}}{\hat{p}_{1,2}\hat{p}_{2,1}}.$$ Although this is again using equivariance of estimators. What I would like to consider is how to get the MLEs for $\hat{p}_{i,j}, (i,j) \in \{1,2\}^2$. However, I am having difficulty figuring out how to find the MLEs of my data, since it seems as though the only realized random variable is $X = (X_{1,1},X_{1,2},X_{2,1},X_{2,2}).$ How do I go about finding this MLE?","Take two random variables $Y$ and $Z$ with support $\{1,2\}$ each, and let $p_{i,j} = P(Z = i,Y = j).$ We define the odds ratio to be $$\psi = \frac{p_{1,1}p_{2,2}}{p_{1,2}p_{2,1}}$$ and the log-odds ratio to be $$\gamma = \log(\psi).$$ I want to show that the MLE for $\psi$ is $\hat{\psi} = \frac{X_{1,1}X_{2,2}}{X_{1,2}X_{2,1}}$ where $X_{i,j} = \#\{Z = i \wedge Y = j\},$ and I want to show that the MLE for $\gamma$ is $\hat{\gamma} = \log(\hat{\psi}).$ The MLE for $\gamma$ is trivial given the property of equivariance of estimators. I do see that $$\hat{\psi} = \frac{\hat{p}_{1,1}\hat{p}_{2,2}}{\hat{p}_{1,2}\hat{p}_{2,1}}.$$ Although this is again using equivariance of estimators. What I would like to consider is how to get the MLEs for $\hat{p}_{i,j}, (i,j) \in \{1,2\}^2$. However, I am having difficulty figuring out how to find the MLEs of my data, since it seems as though the only realized random variable is $X = (X_{1,1},X_{1,2},X_{2,1},X_{2,2}).$ How do I go about finding this MLE?",,"['probability', 'statistics']"
12,Probability that parents don't name their children with the same first initial as their own,Probability that parents don't name their children with the same first initial as their own,,"To test the hypothesis that parents name their children without bias towards their own initials we have data of one parent name and one of their children's names . There are 600 data points and it has been measured that roughly 7% of parents have names that start with the same first initial as their own. If there is no such tendency, what is the expected rate of parent-child first initial matches? Is it as simple as 1 in 26 (letters in the alphabet)? What would be the best way to go about it? Could you use distribution of children's names?","To test the hypothesis that parents name their children without bias towards their own initials we have data of one parent name and one of their children's names . There are 600 data points and it has been measured that roughly 7% of parents have names that start with the same first initial as their own. If there is no such tendency, what is the expected rate of parent-child first initial matches? Is it as simple as 1 in 26 (letters in the alphabet)? What would be the best way to go about it? Could you use distribution of children's names?",,['statistics']
13,Verify a distribution that is exponential family,Verify a distribution that is exponential family,,"Given the parametric class formed by the density functions defined as follows:   $$p(y;\theta)=\theta(\theta+1)y(1-y)^{\theta-1},\ y\in(0,1),\ \theta >0$$   Does this parametric class forms an exponential family like $$f(y, \theta)=q(y) exp\{\phi(\theta)t(y)-\tau(\theta)\}$$   ? I could write the density function in this way:$$p(y;\theta)=y\exp\{(\theta-1)ln(1-y)+ln(\theta(\theta+1))\}$$ so, if $$q(y)=y,\ \phi(\theta)=(\theta-1),\ t(y)=,\ \tau(\theta)=-ln(\theta(\theta+1))$$ then the answer should be yes. Is that correct? Is also correct the relationship $p(y;\theta)=Beta(2,\theta)$?","Given the parametric class formed by the density functions defined as follows:   $$p(y;\theta)=\theta(\theta+1)y(1-y)^{\theta-1},\ y\in(0,1),\ \theta >0$$   Does this parametric class forms an exponential family like $$f(y, \theta)=q(y) exp\{\phi(\theta)t(y)-\tau(\theta)\}$$   ? I could write the density function in this way:$$p(y;\theta)=y\exp\{(\theta-1)ln(1-y)+ln(\theta(\theta+1))\}$$ so, if $$q(y)=y,\ \phi(\theta)=(\theta-1),\ t(y)=,\ \tau(\theta)=-ln(\theta(\theta+1))$$ then the answer should be yes. Is that correct? Is also correct the relationship $p(y;\theta)=Beta(2,\theta)$?",,"['statistics', 'self-learning']"
14,Variance of a sum of identically distributed random variables that are not independent,Variance of a sum of identically distributed random variables that are not independent,,"I am ""new"" to probability/statistics and I was hoping someone could verify that this is correct. Let $Y_1,\ldots,Y_n$ be random variables that follow a common distribution with mean $\mu$ and variance $\sigma^2$. However, I am not assuming that the variables are independent. I want to compute the expected value and variance of $X=Y_1+\cdots+Y_n$. Then, $$\mathbb{E}(X) = \mathbb{E}\left(\sum_{i=1}^{n} Y_i \right) =  \sum_{i=1}^{n} \mathbb{E}\left( Y_i \right) = n \cdot \mu.$$ Moreover, \begin{eqnarray*} \operatorname{Var}(X) &=& \operatorname{Var}\left(\sum_{i=1}^{n} Y_i \right) \\ &=&  \sum_{i=1}^{n} \operatorname{Var}\left( Y_i \right) + 2\cdot\left(\sum_{1\leq i<j\leq n} \operatorname{Cov}(Y_i,Y_j) \right) \\ &=&  \sum_{i=1}^{n} \operatorname{Var}\left( Y_i \right) + 2\cdot\left(\frac{ n(n -1 )}{2}\right) \cdot C \\ &=& n \cdot \sigma^2 + n(n -1)\cdot C\\ &=& n\cdot ( \sigma^2 + (n-1)\cdot C), \end{eqnarray*} where we have used the properties of the variance, and the fact that for any $i\neq j$, the variables $Y_i,Y_j$ follow the same distribution,  and so $\operatorname{Cov}(Y_i,Y_j)=C$ for all $i\neq j$, for some constant $C$. Question 1: Is this right? I have an uneasy feeling about assuming that all the covariances equal a constant C. Is there some additional hypothesis on the original random variables $Y_1,\ldots,Y_n$ that one needs to assume so that the covariance   $\operatorname{Cov}(Y_i,Y_j)=C$ independent of the chosen $i\neq j$? Question 2: Also, is $C=\operatorname{Cov}(Y_i,Y_j)=\operatorname{Cov}(Y_i,Y_i)=\sigma^2$? Thanks!","I am ""new"" to probability/statistics and I was hoping someone could verify that this is correct. Let $Y_1,\ldots,Y_n$ be random variables that follow a common distribution with mean $\mu$ and variance $\sigma^2$. However, I am not assuming that the variables are independent. I want to compute the expected value and variance of $X=Y_1+\cdots+Y_n$. Then, $$\mathbb{E}(X) = \mathbb{E}\left(\sum_{i=1}^{n} Y_i \right) =  \sum_{i=1}^{n} \mathbb{E}\left( Y_i \right) = n \cdot \mu.$$ Moreover, \begin{eqnarray*} \operatorname{Var}(X) &=& \operatorname{Var}\left(\sum_{i=1}^{n} Y_i \right) \\ &=&  \sum_{i=1}^{n} \operatorname{Var}\left( Y_i \right) + 2\cdot\left(\sum_{1\leq i<j\leq n} \operatorname{Cov}(Y_i,Y_j) \right) \\ &=&  \sum_{i=1}^{n} \operatorname{Var}\left( Y_i \right) + 2\cdot\left(\frac{ n(n -1 )}{2}\right) \cdot C \\ &=& n \cdot \sigma^2 + n(n -1)\cdot C\\ &=& n\cdot ( \sigma^2 + (n-1)\cdot C), \end{eqnarray*} where we have used the properties of the variance, and the fact that for any $i\neq j$, the variables $Y_i,Y_j$ follow the same distribution,  and so $\operatorname{Cov}(Y_i,Y_j)=C$ for all $i\neq j$, for some constant $C$. Question 1: Is this right? I have an uneasy feeling about assuming that all the covariances equal a constant C. Is there some additional hypothesis on the original random variables $Y_1,\ldots,Y_n$ that one needs to assume so that the covariance   $\operatorname{Cov}(Y_i,Y_j)=C$ independent of the chosen $i\neq j$? Question 2: Also, is $C=\operatorname{Cov}(Y_i,Y_j)=\operatorname{Cov}(Y_i,Y_i)=\sigma^2$? Thanks!",,"['probability', 'statistics', 'covariance', 'variance']"
15,Calculating combined percentiles?,Calculating combined percentiles?,,"How to calculate combined percentile in the following case? Suppose some GMAT-like test result is expressed in two number, V (0-100) and Q (0-100). And to calculate the total score, a simple arithmetic mean is used (V+Q)/2. Now Alice has a score of V in the 75th percentile and Q score in the 60th percentile. Is/when is it possible to combine the two to get her total score's percentile?","How to calculate combined percentile in the following case? Suppose some GMAT-like test result is expressed in two number, V (0-100) and Q (0-100). And to calculate the total score, a simple arithmetic mean is used (V+Q)/2. Now Alice has a score of V in the 75th percentile and Q score in the 60th percentile. Is/when is it possible to combine the two to get her total score's percentile?",,['statistics']
16,Is there something special about the normal distribution in the context of the random vector being equally likely to point in any direction?,Is there something special about the normal distribution in the context of the random vector being equally likely to point in any direction?,,"In the context of the error vector $$\epsilon: \Omega \to \mathbb R^n$$ of a multivariable regression, I have heard roughly the following: The distribution of $\epsilon$ is uniform over the angle, so the random vector is equally likely to point in any direction. Distributions other than the Gaussian one don't give a spherically symmetrical distribution. As far as I can tell, it says that the multivariable normal distribution can be characterized in this way. It made me very curios. I was looking for a proof and saw this : Among spherically symmetric distributions are not only multivariate normal distributions with covariance matrices of form $σ^2I$ but also, for example, certain cases of standard multivariate t and logistic distributions. So the first quote is wrong and there is nothing special about normal distribution in this regard?","In the context of the error vector $$\epsilon: \Omega \to \mathbb R^n$$ of a multivariable regression, I have heard roughly the following: The distribution of $\epsilon$ is uniform over the angle, so the random vector is equally likely to point in any direction. Distributions other than the Gaussian one don't give a spherically symmetrical distribution. As far as I can tell, it says that the multivariable normal distribution can be characterized in this way. It made me very curios. I was looking for a proof and saw this : Among spherically symmetric distributions are not only multivariate normal distributions with covariance matrices of form $σ^2I$ but also, for example, certain cases of standard multivariate t and logistic distributions. So the first quote is wrong and there is nothing special about normal distribution in this regard?",,"['probability-theory', 'statistics', 'multivariable-calculus', 'normal-distribution', 'regression']"
17,Why does the central limit theorem work,Why does the central limit theorem work,,"Here is my understanding of the central limit theorem: The arithmetic sum/mean of a sufficiently large number of iterates of independent random variables approaches a normal distribution. These variables should be independent. I can visualize with a few examples how as a chance process (analogous to drawing from a box) is repeated, the probability histogram centered at the expected sum with standard error as a SD starts to resemble a normal curve, whether or not the contents of the box originally do resemble that. However, why is this so? I don't even know where to start.","Here is my understanding of the central limit theorem: The arithmetic sum/mean of a sufficiently large number of iterates of independent random variables approaches a normal distribution. These variables should be independent. I can visualize with a few examples how as a chance process (analogous to drawing from a box) is repeated, the probability histogram centered at the expected sum with standard error as a SD starts to resemble a normal curve, whether or not the contents of the box originally do resemble that. However, why is this so? I don't even know where to start.",,"['statistics', 'normal-distribution', 'central-limit-theorem']"
18,Limits on median given mean and sd,Limits on median given mean and sd,,"Given N, a mean, a standard deviation, and the range, what does that tell us about the median? Obviously and trivially it must be within the range, but can we get tighter limits? To give context, I'm trying to find a median by repeated search. I may not rearrange the data and I get charged for each pass through it. So the tighter the limits on the initial estimate the better, and I can obtain range, mean and standard deviation from one pass.","Given N, a mean, a standard deviation, and the range, what does that tell us about the median? Obviously and trivially it must be within the range, but can we get tighter limits? To give context, I'm trying to find a median by repeated search. I may not rearrange the data and I get charged for each pass through it. So the tighter the limits on the initial estimate the better, and I can obtain range, mean and standard deviation from one pass.",,['statistics']
19,Dirichlet-multinomial distribution,Dirichlet-multinomial distribution,,"I'm reading ""Microbiome, Metagenomics, and High-Dimensional Compositional Data Analysis"" by Li ( Annual Review of Statistics and Its Application , 2015). There is a part on using Dirichlet-multinomial to model joint-count data that I don't quite follow. In addition to scalar summary statistics, such as $\alpha$-and   $\beta$-diversity, one can directly model observed taxa count data   using Dirichlet multinomial regression (La Rosa et al. 2012, Chen & Li   2013b, Holmes et al. 2012). One advantage of this approach is that it   automatically accounts for measurement errors and other uncertainties   associated with the counts. Suppose we have $p$ bacterial taxa, and   their counts $ n = ( {n}_{1}, {n}_{2},..., {n}_{p} ) $ follow a   multinomial distribution with probability mass function    $$ 			{f}_{M}( {n}_{1}, \dots, {n}_{p}; \phi) = \binom{ {n}_{+} }{ n } \prod_{j=1}^{p}{ {\phi}_{j}^{ {n}_{j} } },   $$   where $ {n}_{+} = \sum_{ j=1 }^{ p }{ {n}_{j} } $ and $\phi = ({\phi}_{1}, {\phi}_{2}, \dots, {\phi}_{p} )$ are underlying species proportions for which $\sum_{ j=1 }^{ p }{ {\phi}_{j} } = 1$. Okay, here I don't get what is $n$ in the binomial coefficient. Moving further... For microbiome composition data, the observed variation is usually   larger than what would be predicted by the multinomial model. This   increased variation results from the heterogeneity of the microbiome   samples and from variation among samples in the underlying   proportions. To account for the extra variation or overdispersion, we   assume the underlying proportions are themselves positive random   variables $ ( {\Phi}_{1}, {\Phi}_{2}, \dots, {\Phi}_{p} ) $, subject   to the constraint $ \sum_{ j=1 }^{ p }{ {\Phi}_{j} } = 1$. This   assumption implies that the underlying proportions follow a Dirichlet   distribution $ Dir( {\gamma}_{1}, {\gamma}_{2}, \dots, {\gamma}_{p} ) $. The counts then marginally follow a Dirichlet-multinomial (DM)   distribution,    $$ 	{f}_{DM}( {n}_{1}, \dots, {n}_{p}; \gamma ) = \binom{ {n}_{+} }{ \mathbf{y} } \frac{ \Gamma( {n}_{+} + 1 ) \Gamma( {\gamma}_{+} ) }{ \Gamma( {n}_{+} + {\gamma}_{+} ) }  \prod_{ j=1 }^{ p }{ \frac{ \Gamma( {n}_{j} + {\gamma}_{j} ) }{ \Gamma( {\gamma}_{j} ) \Gamma( {n}_{j} + 1 ) } }  $$   To relate a $q$-dimensional covariate vector $ \mathbf{Z} = ( {z}_{1}, {z}_{2}, \dots, {z}_{q} ) $ to taxa composition, we assume that the parameters $ {\gamma}_{j} $ in the DM model depend on the covariates via a log-linear model   $$ {\gamma}_{j} (\mathbf{Z}) = \exp \left ( {\alpha}_{j} + \sum_{k=1}^{q}{ {\beta}_{jk} {z}_{k} } \right ), $$   where $ {\beta}_{jk} $ measures the effect on the $j$-th taxon of the $k$-th covariate. Here I don't get what is $ \mathbf{y} $. I suppose $ {\gamma}_{+} $ is the sum over $ \gamma $, though the author doesn't state it explicitly. The author says nothing about $\alpha$ either. In both cases I suppose that the author uses the notation for binomial coefficient to actually represent multidimensional slices of $p-1$-dimensional Pascal simplex. Am I right?","I'm reading ""Microbiome, Metagenomics, and High-Dimensional Compositional Data Analysis"" by Li ( Annual Review of Statistics and Its Application , 2015). There is a part on using Dirichlet-multinomial to model joint-count data that I don't quite follow. In addition to scalar summary statistics, such as $\alpha$-and   $\beta$-diversity, one can directly model observed taxa count data   using Dirichlet multinomial regression (La Rosa et al. 2012, Chen & Li   2013b, Holmes et al. 2012). One advantage of this approach is that it   automatically accounts for measurement errors and other uncertainties   associated with the counts. Suppose we have $p$ bacterial taxa, and   their counts $ n = ( {n}_{1}, {n}_{2},..., {n}_{p} ) $ follow a   multinomial distribution with probability mass function    $$ 			{f}_{M}( {n}_{1}, \dots, {n}_{p}; \phi) = \binom{ {n}_{+} }{ n } \prod_{j=1}^{p}{ {\phi}_{j}^{ {n}_{j} } },   $$   where $ {n}_{+} = \sum_{ j=1 }^{ p }{ {n}_{j} } $ and $\phi = ({\phi}_{1}, {\phi}_{2}, \dots, {\phi}_{p} )$ are underlying species proportions for which $\sum_{ j=1 }^{ p }{ {\phi}_{j} } = 1$. Okay, here I don't get what is $n$ in the binomial coefficient. Moving further... For microbiome composition data, the observed variation is usually   larger than what would be predicted by the multinomial model. This   increased variation results from the heterogeneity of the microbiome   samples and from variation among samples in the underlying   proportions. To account for the extra variation or overdispersion, we   assume the underlying proportions are themselves positive random   variables $ ( {\Phi}_{1}, {\Phi}_{2}, \dots, {\Phi}_{p} ) $, subject   to the constraint $ \sum_{ j=1 }^{ p }{ {\Phi}_{j} } = 1$. This   assumption implies that the underlying proportions follow a Dirichlet   distribution $ Dir( {\gamma}_{1}, {\gamma}_{2}, \dots, {\gamma}_{p} ) $. The counts then marginally follow a Dirichlet-multinomial (DM)   distribution,    $$ 	{f}_{DM}( {n}_{1}, \dots, {n}_{p}; \gamma ) = \binom{ {n}_{+} }{ \mathbf{y} } \frac{ \Gamma( {n}_{+} + 1 ) \Gamma( {\gamma}_{+} ) }{ \Gamma( {n}_{+} + {\gamma}_{+} ) }  \prod_{ j=1 }^{ p }{ \frac{ \Gamma( {n}_{j} + {\gamma}_{j} ) }{ \Gamma( {\gamma}_{j} ) \Gamma( {n}_{j} + 1 ) } }  $$   To relate a $q$-dimensional covariate vector $ \mathbf{Z} = ( {z}_{1}, {z}_{2}, \dots, {z}_{q} ) $ to taxa composition, we assume that the parameters $ {\gamma}_{j} $ in the DM model depend on the covariates via a log-linear model   $$ {\gamma}_{j} (\mathbf{Z}) = \exp \left ( {\alpha}_{j} + \sum_{k=1}^{q}{ {\beta}_{jk} {z}_{k} } \right ), $$   where $ {\beta}_{jk} $ measures the effect on the $j$-th taxon of the $k$-th covariate. Here I don't get what is $ \mathbf{y} $. I suppose $ {\gamma}_{+} $ is the sum over $ \gamma $, though the author doesn't state it explicitly. The author says nothing about $\alpha$ either. In both cases I suppose that the author uses the notation for binomial coefficient to actually represent multidimensional slices of $p-1$-dimensional Pascal simplex. Am I right?",,"['statistics', 'probability-distributions', 'mathematical-modeling', 'multinomial-coefficients']"
20,Variance of the Sample Variance of a normal distribution,Variance of the Sample Variance of a normal distribution,,"I'm trying to calculate the variance of the sample variance of a normal distribution. Let $Y_1,Y_2,...,Y_n$ be a sample of size $n$ from a normal distribution with mean $\mu$ and variance $\sigma^2$. Define the unbiased sample variance as $S^2=\frac1{n-1}\sum_{i=1}^{n}(\bar Y-Y_i)^2$ where $\bar Y$ is the sample mean. As we know, $\frac{(n-1)S^2}{\sigma^2}$ is $ \chi^2$ distributed with $n-1$ degrees of freedom, so $$Var(S^2)=\frac{\sigma^4}{(n-1)^2}Var(\frac{(n-1)S^2}{\sigma^2})=\frac{2\sigma^4}{n-1}$$However I am trying to calculate it in a different way. Notice that $\bar Y$ is normal with mean $\mu$ and variance $\frac {\sigma^2}n$. Each $Y_i$ is normal with mean $\mu$ and variance $\sigma^2$. It follows that $\bar Y-Y_i$ is normal with mean $0$ and variance $\frac {\sigma^2}n+\sigma^2=\frac{(n+1)\sigma^2}{n}$. Therefore $\frac{\bar Y-Y_i}{\sqrt{\frac{(n+1)\sigma^2}{n}}}$ is a standard normal variable. Using this and the fact that $Z^2=\chi^2$ I get that: $$Var(S^2)=\frac 1{(n-1)^2}Var(\sum_{i=1}^{n}(\bar Y-Y_i)^2)=\frac 1{(n-1)^2}Var(\sum_{i=1}^{n}(\frac{\bar Y-Y_i}{\sqrt{\frac{(n+1)\sigma^2}{n}}})^2\times\frac{(n+1)\sigma^2}{n})$$ $$=\frac {(n+1)^2\sigma^4}{n^2(n-1)^2}Var(\sum_{i=1}^{n}Z_i^2)=\frac {2n(n+1)^2\sigma^4}{n^2(n-1)^2}=\frac {2(n+1)^2\sigma^4}{n(n-1)^2}$$ since $\sum_{i=1}^{n}Z_i^2$ is $\chi^2$ distributed with $n$ degrees of freedom. My derivation of the variance seems correct to me but the answer is clearly not, where did I go wrong?","I'm trying to calculate the variance of the sample variance of a normal distribution. Let $Y_1,Y_2,...,Y_n$ be a sample of size $n$ from a normal distribution with mean $\mu$ and variance $\sigma^2$. Define the unbiased sample variance as $S^2=\frac1{n-1}\sum_{i=1}^{n}(\bar Y-Y_i)^2$ where $\bar Y$ is the sample mean. As we know, $\frac{(n-1)S^2}{\sigma^2}$ is $ \chi^2$ distributed with $n-1$ degrees of freedom, so $$Var(S^2)=\frac{\sigma^4}{(n-1)^2}Var(\frac{(n-1)S^2}{\sigma^2})=\frac{2\sigma^4}{n-1}$$However I am trying to calculate it in a different way. Notice that $\bar Y$ is normal with mean $\mu$ and variance $\frac {\sigma^2}n$. Each $Y_i$ is normal with mean $\mu$ and variance $\sigma^2$. It follows that $\bar Y-Y_i$ is normal with mean $0$ and variance $\frac {\sigma^2}n+\sigma^2=\frac{(n+1)\sigma^2}{n}$. Therefore $\frac{\bar Y-Y_i}{\sqrt{\frac{(n+1)\sigma^2}{n}}}$ is a standard normal variable. Using this and the fact that $Z^2=\chi^2$ I get that: $$Var(S^2)=\frac 1{(n-1)^2}Var(\sum_{i=1}^{n}(\bar Y-Y_i)^2)=\frac 1{(n-1)^2}Var(\sum_{i=1}^{n}(\frac{\bar Y-Y_i}{\sqrt{\frac{(n+1)\sigma^2}{n}}})^2\times\frac{(n+1)\sigma^2}{n})$$ $$=\frac {(n+1)^2\sigma^4}{n^2(n-1)^2}Var(\sum_{i=1}^{n}Z_i^2)=\frac {2n(n+1)^2\sigma^4}{n^2(n-1)^2}=\frac {2(n+1)^2\sigma^4}{n(n-1)^2}$$ since $\sum_{i=1}^{n}Z_i^2$ is $\chi^2$ distributed with $n$ degrees of freedom. My derivation of the variance seems correct to me but the answer is clearly not, where did I go wrong?",,"['statistics', 'random-variables', 'normal-distribution', 'variance']"
21,Why do we divide the kernel estimate function by h and also the entire equation by h?,Why do we divide the kernel estimate function by h and also the entire equation by h?,,"I believe the explanation is that the kernel estimate function would integrate to 1. But I do not quite understand the intuition behind it. How would dividing by h help to make the function integrate to 1. Also, what is the output of the kernel  k(.) if it were Uniform. EXPLANATION","I believe the explanation is that the kernel estimate function would integrate to 1. But I do not quite understand the intuition behind it. How would dividing by h help to make the function integrate to 1. Also, what is the output of the kernel  k(.) if it were Uniform. EXPLANATION",,"['statistics', 'functions', 'estimation']"
22,Likelihood function of $\sigma^2$ for two normal populations,Likelihood function of  for two normal populations,\sigma^2,"I'm working through problem 9.86 in Wackerly's ""Mathematical Statistics with applications, 7th ed."" The essence of the problem is: Given two samples: $X_1,X_2,\ldots,X_m$ from a normal population with mean $\mu_1$ and variance $\sigma^2$ and $Y_1,Y_2,\ldots,Y_n$ from a different normal population with mean $\mu_2$ but the same variance $\sigma^2$, find the maximum likelihood estimator for the common variance $\sigma^2$. Assume that $\mu_1$ and $\mu_2$ are unknown. The solution to this problem gives the likelihood function as $$L(\sigma^2)=(2\pi\sigma^2)^{\frac{-(m+n)}{2}}\exp\left(-\frac{1}{2\sigma^2}\left [\sum_{i=1}^m (x_i-\mu_1)^2-\sum_{i=1}^n (y_i-\mu_2)^2\right]\right)$$ However, I don't understand why there is a difference of sums in the exponential function. If I understand correctly, the likelihood function is obtained by taking the product of each sample density since they're independent, so $$L(\sigma^2)=\prod_{i=1}^m \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(\frac{-(x_i-\mu_1)^2}{2\sigma^2}\right) \prod_{i=1}^n \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left( \frac{-(y_i-\mu_2)^2}{2\sigma^2}\right)$$ which would simplify to $$L(\sigma^2) = (2\pi\sigma^2)^{\frac{-(m+n)}{2}} \exp\left(-\frac{1}{2\sigma^2}\left[\sum_{i=1}^m (x_i-\mu_1)^2+\sum_{i=1}^n (y_i-\mu_2)^2\right]\right)$$ where the two sums are added in the exponent. Did I go wrong somewhere or is it an error in the textbook?","I'm working through problem 9.86 in Wackerly's ""Mathematical Statistics with applications, 7th ed."" The essence of the problem is: Given two samples: $X_1,X_2,\ldots,X_m$ from a normal population with mean $\mu_1$ and variance $\sigma^2$ and $Y_1,Y_2,\ldots,Y_n$ from a different normal population with mean $\mu_2$ but the same variance $\sigma^2$, find the maximum likelihood estimator for the common variance $\sigma^2$. Assume that $\mu_1$ and $\mu_2$ are unknown. The solution to this problem gives the likelihood function as $$L(\sigma^2)=(2\pi\sigma^2)^{\frac{-(m+n)}{2}}\exp\left(-\frac{1}{2\sigma^2}\left [\sum_{i=1}^m (x_i-\mu_1)^2-\sum_{i=1}^n (y_i-\mu_2)^2\right]\right)$$ However, I don't understand why there is a difference of sums in the exponential function. If I understand correctly, the likelihood function is obtained by taking the product of each sample density since they're independent, so $$L(\sigma^2)=\prod_{i=1}^m \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(\frac{-(x_i-\mu_1)^2}{2\sigma^2}\right) \prod_{i=1}^n \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left( \frac{-(y_i-\mu_2)^2}{2\sigma^2}\right)$$ which would simplify to $$L(\sigma^2) = (2\pi\sigma^2)^{\frac{-(m+n)}{2}} \exp\left(-\frac{1}{2\sigma^2}\left[\sum_{i=1}^m (x_i-\mu_1)^2+\sum_{i=1}^n (y_i-\mu_2)^2\right]\right)$$ where the two sums are added in the exponent. Did I go wrong somewhere or is it an error in the textbook?",,"['statistics', 'probability-distributions', 'maximum-likelihood']"
23,Impact of spurious regressors on out of sample prediction error,Impact of spurious regressors on out of sample prediction error,,"The true DGP is  \begin{equation} y=\alpha_0 + \alpha_1 x_1 + \dots + \alpha_k x_k +\epsilon, \quad \epsilon\sim \mathcal{N}(0,1)\label{eq:1} \end{equation} but we instead estimate \begin{equation} y=\alpha_0 + \alpha_1 x_1 + \dots + \alpha_k x_k + \dots + \alpha_{k'} x_{k'} \epsilon, \quad \epsilon\sim \mathcal{N}(0,1)\label{eq:2} \end{equation} where $k'>k$. The observations are fixed design. Is it true that the standard error of the out of sample prediction of the estimated function (with spurious regressors) at some fixed $(x_1^*, \dots, x_{k'}^*)$ is (weakly) greater than the standard error of the out of sample prediction at $(x_1^*, \dots, x_k^*)$ using the correctly specified model? If so, how can I prove this?","The true DGP is  \begin{equation} y=\alpha_0 + \alpha_1 x_1 + \dots + \alpha_k x_k +\epsilon, \quad \epsilon\sim \mathcal{N}(0,1)\label{eq:1} \end{equation} but we instead estimate \begin{equation} y=\alpha_0 + \alpha_1 x_1 + \dots + \alpha_k x_k + \dots + \alpha_{k'} x_{k'} \epsilon, \quad \epsilon\sim \mathcal{N}(0,1)\label{eq:2} \end{equation} where $k'>k$. The observations are fixed design. Is it true that the standard error of the out of sample prediction of the estimated function (with spurious regressors) at some fixed $(x_1^*, \dots, x_{k'}^*)$ is (weakly) greater than the standard error of the out of sample prediction at $(x_1^*, \dots, x_k^*)$ using the correctly specified model? If so, how can I prove this?",,"['statistics', 'regression', 'linear-regression', 'mean-square-error']"
24,Statistics: Testing hypothesis,Statistics: Testing hypothesis,,"I'm not sure that I'm understanding this stuff fully so I would appreciate it if someone could check my work. QUESTION The percentage of children who leave foster care due to adoption is generally accepted to be 15%. A social worker claims that this percent is incorrect. After performing a hypothesis test on his claim using sample data from 2009, he fails to reject the null hypothesis. According to a report by the US department of Health and Human Services, the actual percentage of children who left foster care due to adoption was 20% in 2009. Was an error made? If so, what type? MY ANSWER Ho = p=15% Ha = p≠15% Ho is proven to be false, but it says that the service worker doesn't reject it. Since they think the Ho is true when it isn't, this is a type 1 error.","I'm not sure that I'm understanding this stuff fully so I would appreciate it if someone could check my work. QUESTION The percentage of children who leave foster care due to adoption is generally accepted to be 15%. A social worker claims that this percent is incorrect. After performing a hypothesis test on his claim using sample data from 2009, he fails to reject the null hypothesis. According to a report by the US department of Health and Human Services, the actual percentage of children who left foster care due to adoption was 20% in 2009. Was an error made? If so, what type? MY ANSWER Ho = p=15% Ha = p≠15% Ho is proven to be false, but it says that the service worker doesn't reject it. Since they think the Ho is true when it isn't, this is a type 1 error.",,['statistics']
25,Why aren't these two versions of a two-sample t-test the same?,Why aren't these two versions of a two-sample t-test the same?,,"I'm looking at two versions of a two-sample t-test that appear equivalent to me -- but when I crunch the numbers they don't seem to actually be equivalent. Consider the model $$\mathbf y = \beta_0 + \beta_1  \mathbf x$$ where $\mathbf x$ is a binary vector. So, for example, where $0$ indicates ""female"" and $1$ ""male"", we would have that $\beta_0$ is the mean response for females, and $\beta_1$ is the mean response for males minus that for females. We assume independent Gaussian errors. So, we can test whether males and females have different means as follows:  $$ \frac{\widehat\beta_1} {\mathrm{se}(\widehat\beta_1)} \sim t_{n-2} $$ Similary, we can consider the sample means of each of male and female: $\bar y_B$ and $\bar y_G$. These are normal random variables with sample variances respectively $\frac{s^2_B}{n_B}$ and $\frac{s^2_G}{n_G}$. Therefore  $$ \bar y_B-\bar y_G\sim N\left(\mu_B-\mu_G,\frac{s^2_B}{n_B}+\frac{s^2_G}{n_G}\right)$$ And so under the hypothesis that $\mu_B=\mu_G$, we can test whether males and females have the same mean as follows: $$ \frac{\bar y_B-\bar y_G}{\sqrt{\frac{s^2_B}{n_B}+\frac{s^2_G}{n_G} } } \sim t_{n-2} $$ This is testing the same thing as the earlier test, and should be equivalent. I have already proven the numerators are equivalent -- that is, $\widehat\beta_1 = \bar y_B-\bar y_G$. But I cannot prove the denominators equivalent, and in fact when I try calculating the denominators for some test cases in R, I do not get the same values. Is something about my above thinking incorrect? If not, any pointers for how to prove the denominators of these two t-statistics equivalent?","I'm looking at two versions of a two-sample t-test that appear equivalent to me -- but when I crunch the numbers they don't seem to actually be equivalent. Consider the model $$\mathbf y = \beta_0 + \beta_1  \mathbf x$$ where $\mathbf x$ is a binary vector. So, for example, where $0$ indicates ""female"" and $1$ ""male"", we would have that $\beta_0$ is the mean response for females, and $\beta_1$ is the mean response for males minus that for females. We assume independent Gaussian errors. So, we can test whether males and females have different means as follows:  $$ \frac{\widehat\beta_1} {\mathrm{se}(\widehat\beta_1)} \sim t_{n-2} $$ Similary, we can consider the sample means of each of male and female: $\bar y_B$ and $\bar y_G$. These are normal random variables with sample variances respectively $\frac{s^2_B}{n_B}$ and $\frac{s^2_G}{n_G}$. Therefore  $$ \bar y_B-\bar y_G\sim N\left(\mu_B-\mu_G,\frac{s^2_B}{n_B}+\frac{s^2_G}{n_G}\right)$$ And so under the hypothesis that $\mu_B=\mu_G$, we can test whether males and females have the same mean as follows: $$ \frac{\bar y_B-\bar y_G}{\sqrt{\frac{s^2_B}{n_B}+\frac{s^2_G}{n_G} } } \sim t_{n-2} $$ This is testing the same thing as the earlier test, and should be equivalent. I have already proven the numerators are equivalent -- that is, $\widehat\beta_1 = \bar y_B-\bar y_G$. But I cannot prove the denominators equivalent, and in fact when I try calculating the denominators for some test cases in R, I do not get the same values. Is something about my above thinking incorrect? If not, any pointers for how to prove the denominators of these two t-statistics equivalent?",,"['statistics', 'sampling']"
26,Estimating Distributed Cache Hits Based On Local Cache Hit Data,Estimating Distributed Cache Hits Based On Local Cache Hit Data,,"This needs a bit of an introduction. We have 6 servers with a local cache, in other words, we have 6 different systems of cache that do not speak to each other. A request that comes through our system is assigned a concrete server in a ""Round Robin"" fashion, e.g. Req1 -> Server1, Req2 -> Server2 ... Req7 -> Server 1 . You could think of it as Server assigned = Request number % number of servers . Our cache works as follows: if one request is identical to another received in that server in the last 30 minutes, we return the previously cached response for that request. We currently have a very low hit (i.e. statistically speaking, the chances of two identical request landing in the same sever is low). More specifically, the amount of repeated requests (based on real-world recollected data) ranges between 3% and 5%. That hit probability is very low, so low that it makes no sense to maintain the code necessary to configure the cache. We are thinking of using a distributed cached, i.e. one that is shared between all servers, so cache will be server-independent. The problem is that building that system is expensive. I will like to know what is the hit probability that could be expected in order to take that step or not. Now, to the maths I am guessing that the new distributed system will have a hit probability ranging from 5% to 30%. 30% being: average hit amongst server multiplied by number of servers . However, I am not very sure of that upper limit and my statistics knowledge is a bit rusty. Is there a way to calculate with proper confidence intervals what would the distributed cache hit be? TL;DR If the probability of a request being repeated on a given server in the last 30 minutes ranges between [0.03, 0.05] . Assuming that there are six servers and that a request is assigned to a server as follows: Server assigned = request number % number of servers (Round Robin). What would the probability be if we replace all that six servers by just one which manages all the requests.","This needs a bit of an introduction. We have 6 servers with a local cache, in other words, we have 6 different systems of cache that do not speak to each other. A request that comes through our system is assigned a concrete server in a ""Round Robin"" fashion, e.g. Req1 -> Server1, Req2 -> Server2 ... Req7 -> Server 1 . You could think of it as Server assigned = Request number % number of servers . Our cache works as follows: if one request is identical to another received in that server in the last 30 minutes, we return the previously cached response for that request. We currently have a very low hit (i.e. statistically speaking, the chances of two identical request landing in the same sever is low). More specifically, the amount of repeated requests (based on real-world recollected data) ranges between 3% and 5%. That hit probability is very low, so low that it makes no sense to maintain the code necessary to configure the cache. We are thinking of using a distributed cached, i.e. one that is shared between all servers, so cache will be server-independent. The problem is that building that system is expensive. I will like to know what is the hit probability that could be expected in order to take that step or not. Now, to the maths I am guessing that the new distributed system will have a hit probability ranging from 5% to 30%. 30% being: average hit amongst server multiplied by number of servers . However, I am not very sure of that upper limit and my statistics knowledge is a bit rusty. Is there a way to calculate with proper confidence intervals what would the distributed cache hit be? TL;DR If the probability of a request being repeated on a given server in the last 30 minutes ranges between [0.03, 0.05] . Assuming that there are six servers and that a request is assigned to a server as follows: Server assigned = request number % number of servers (Round Robin). What would the probability be if we replace all that six servers by just one which manages all the requests.",,"['statistics', 'statistical-inference']"
27,Why is the regression line an estimate of the average value of y for each value of x?,Why is the regression line an estimate of the average value of y for each value of x?,,"The regression line, passing through the point of averages with a slope equivalent to r, is said to be a good estimate of the average value of y for each value of x. I can see why this is the cases when r = 1,0 and -1. When r=1, all points lie on a line. SD increases in equal proportions. Likewise for -1, they have an inverse relationship. For r=0, there is no correlation, so on average, an increase in x will have no effect on y. But what about the values in between? I am using Freedman's Statistics textbook, and it mentions that while r is the correct factor to use, for values in between 1 and -1, a ""complicated mathematical argument is needed"". What is this argument?","The regression line, passing through the point of averages with a slope equivalent to r, is said to be a good estimate of the average value of y for each value of x. I can see why this is the cases when r = 1,0 and -1. When r=1, all points lie on a line. SD increases in equal proportions. Likewise for -1, they have an inverse relationship. For r=0, there is no correlation, so on average, an increase in x will have no effect on y. But what about the values in between? I am using Freedman's Statistics textbook, and it mentions that while r is the correct factor to use, for values in between 1 and -1, a ""complicated mathematical argument is needed"". What is this argument?",,"['statistics', 'regression', 'correlation']"
28,"Expectation of the fill distance of $N$ random points in $[0,1]^s$",Expectation of the fill distance of  random points in,"N [0,1]^s","Let $x_1,\ldots,x_N$ be uniformly distributed points in $[0,1]^s, s \in \mathbb{N}$. What can be said about $$ \mathbb{E} \left(\sup_{x \in [0,1]^s} \min_{i \in \{1,..N\}} \|x - x_i\|_2 \right) $$ where $\|y\|_2 = \sqrt{\sum_{i=1}^s y_i^2}$ denotes the Euclidian norm. In other words, what is the diameter of the largest empty ball I can expect to place in $[0,1]^s$.","Let $x_1,\ldots,x_N$ be uniformly distributed points in $[0,1]^s, s \in \mathbb{N}$. What can be said about $$ \mathbb{E} \left(\sup_{x \in [0,1]^s} \min_{i \in \{1,..N\}} \|x - x_i\|_2 \right) $$ where $\|y\|_2 = \sqrt{\sum_{i=1}^s y_i^2}$ denotes the Euclidian norm. In other words, what is the diameter of the largest empty ball I can expect to place in $[0,1]^s$.",,"['probability', 'statistics', 'geometric-probability']"
29,Is it possible to be a frequentist and a subjectivist at the same time?,Is it possible to be a frequentist and a subjectivist at the same time?,,"I'm trying to understand the differences between (1) Bayesian vs frequentist; and (2) subjectivist vs objectivist. So far my understanding (correct me if I'm wrong) is that: (1) Bayesian vs frequentist. Frequentist: A probability $p$ represents a long-run frequency. Bayesian: A probability $p$ simply reflects our tentative state of knowledge. Given new information, we may update $p$. (2) Subjectivist vs objectivist. Subjectivist: A probability is simply one's personal, subjective degree of belief about some particular matter. So two rational, intelligent people with the same information and knowledge can disagree about a probability $p$. Objectivist: It is impossible for two perfectly-rational people with the same information and knowledge to disagree about a probability $p$. My understanding is that Bayesians are typically subjectivist and frequentists are typically objectivist. However, it is possible for Bayesians to be objectivist. My question is this: Is it possible for frequentists to be subjectivist? And how would such a subjectivist-frequentist interpret probability?","I'm trying to understand the differences between (1) Bayesian vs frequentist; and (2) subjectivist vs objectivist. So far my understanding (correct me if I'm wrong) is that: (1) Bayesian vs frequentist. Frequentist: A probability $p$ represents a long-run frequency. Bayesian: A probability $p$ simply reflects our tentative state of knowledge. Given new information, we may update $p$. (2) Subjectivist vs objectivist. Subjectivist: A probability is simply one's personal, subjective degree of belief about some particular matter. So two rational, intelligent people with the same information and knowledge can disagree about a probability $p$. Objectivist: It is impossible for two perfectly-rational people with the same information and knowledge to disagree about a probability $p$. My understanding is that Bayesians are typically subjectivist and frequentists are typically objectivist. However, it is possible for Bayesians to be objectivist. My question is this: Is it possible for frequentists to be subjectivist? And how would such a subjectivist-frequentist interpret probability?",,['probability']
30,What is the relationship between the function $\mathbb{E}(Y \mid X = x)$ and linear regression?,What is the relationship between the function  and linear regression?,\mathbb{E}(Y \mid X = x),"Consider the  function $$ r(x) = \mathbb{E}(Y \mid X = x) $$ This has been called the regression function in a textbook I'm using. I'm trying to figure out the relationship between this function and the classical linear regression model. So, I know that it is a theorem* that we may write $$ Y = r(X) + \epsilon $$ for some random variable $\epsilon$ s.t. $\mathbb{E}(\epsilon) = 0$. Now suppose that we have $$ Y = \beta_0 + \beta_1 X + \epsilon $$ This is the classical 1-dimensional regression function (assuming the $\beta_0$ and $\beta_1$ minimize the residual sum of squares). Question: Is it then a mathematical theorem that if $Y$ is defined as above, that $$ r(X) = \mathbb{E}(Y \mid X) = (\beta_0 + \beta_1 X)? $$ And is this why the function $\mathbb{E}(Y \mid X)$ is called the ""regression function""? EDIT: The theorem that I am making use of is as follows (from All of Statistics pg. 89): Regression models are sometimes written as $$ Y = r(X) + \epsilon $$ where $\mathbb{E}(\epsilon) = 0$. We can always rewrite a regression model this way. To see this, define $\epsilon = Y - r(X)$ and hence $Y = Y + r(X) - r(X) = r(X) + \epsilon$. Moreover, $\mathbb{E}(\epsilon) = \mathbb{E}\mathbb{E}(\epsilon \mid X) = \mathbb{E}(\mathbb{E}(Y - r(X)) \mid X) = \mathbb{E}(\mathbb{E} ( Y \mid X) - r(X)) = \mathbb{E}(r(X) - r(X)) = 0$.","Consider the  function $$ r(x) = \mathbb{E}(Y \mid X = x) $$ This has been called the regression function in a textbook I'm using. I'm trying to figure out the relationship between this function and the classical linear regression model. So, I know that it is a theorem* that we may write $$ Y = r(X) + \epsilon $$ for some random variable $\epsilon$ s.t. $\mathbb{E}(\epsilon) = 0$. Now suppose that we have $$ Y = \beta_0 + \beta_1 X + \epsilon $$ This is the classical 1-dimensional regression function (assuming the $\beta_0$ and $\beta_1$ minimize the residual sum of squares). Question: Is it then a mathematical theorem that if $Y$ is defined as above, that $$ r(X) = \mathbb{E}(Y \mid X) = (\beta_0 + \beta_1 X)? $$ And is this why the function $\mathbb{E}(Y \mid X)$ is called the ""regression function""? EDIT: The theorem that I am making use of is as follows (from All of Statistics pg. 89): Regression models are sometimes written as $$ Y = r(X) + \epsilon $$ where $\mathbb{E}(\epsilon) = 0$. We can always rewrite a regression model this way. To see this, define $\epsilon = Y - r(X)$ and hence $Y = Y + r(X) - r(X) = r(X) + \epsilon$. Moreover, $\mathbb{E}(\epsilon) = \mathbb{E}\mathbb{E}(\epsilon \mid X) = \mathbb{E}(\mathbb{E}(Y - r(X)) \mid X) = \mathbb{E}(\mathbb{E} ( Y \mid X) - r(X)) = \mathbb{E}(r(X) - r(X)) = 0$.",,"['statistics', 'regression']"
31,Relation between these two series,Relation between these two series,,"Assume a constant $\alpha$ and $N$ positive integers $\{n_1,...,n_N\}$. What is the relation between $\frac{N\alpha}{\sum_i{n_{i}}}$ and $\sum_i{\frac{\alpha}{n_{i}}}$ when $N\rightarrow\infty$? $N$ is not necessarily infinite, I just want to compare these two series when $N$ becomes large enough. Note: statistically speaking, this represents the relation between $\mathbb{E}\{\frac{X}{Y}\}$ and $\frac{\mathbb{E}\{X\}}{\mathbb{E}\{Y\}}$.","Assume a constant $\alpha$ and $N$ positive integers $\{n_1,...,n_N\}$. What is the relation between $\frac{N\alpha}{\sum_i{n_{i}}}$ and $\sum_i{\frac{\alpha}{n_{i}}}$ when $N\rightarrow\infty$? $N$ is not necessarily infinite, I just want to compare these two series when $N$ becomes large enough. Note: statistically speaking, this represents the relation between $\mathbb{E}\{\frac{X}{Y}\}$ and $\frac{\mathbb{E}\{X\}}{\mathbb{E}\{Y\}}$.",,"['sequences-and-series', 'statistics']"
32,Expectation of absolute sum of squared normal distributions,Expectation of absolute sum of squared normal distributions,,"Let $u_i$ be a standard normal distribution for all $i$. All $u_i$'s are independent of each other. I want to compute the expectation of: $$| \sum_i u_i^2 \lambda_i |$$ Where $\lambda_i$ is real but can be negative. I found that the $u_i^2$ are Gamma distributions, and a sum of Gamma distributions is again a Gamma distribution (but I'm unsure since they are scaled). But how to deal with the absolute value? If this is untractable I'm wondering if we can compute this expectation if each $u_i$ has a symmetric uniform distribution. The expectation of $u_i^2 \lambda_i$ is straightforward to compute, but the sum and absolute value again seem tricky.","Let $u_i$ be a standard normal distribution for all $i$. All $u_i$'s are independent of each other. I want to compute the expectation of: $$| \sum_i u_i^2 \lambda_i |$$ Where $\lambda_i$ is real but can be negative. I found that the $u_i^2$ are Gamma distributions, and a sum of Gamma distributions is again a Gamma distribution (but I'm unsure since they are scaled). But how to deal with the absolute value? If this is untractable I'm wondering if we can compute this expectation if each $u_i$ has a symmetric uniform distribution. The expectation of $u_i^2 \lambda_i$ is straightforward to compute, but the sum and absolute value again seem tricky.",,"['probability', 'combinatorics', 'statistics']"
33,Find an estimator by using the method of moment,Find an estimator by using the method of moment,,"Let $X$ be a discrete random variable with density function:    $$p(x;\theta)=\left(\frac{\theta}{2}\right)^{\lvert x\rvert}(1-\theta)^{1-\lvert x\rvert}$$   where $x\in\{-1,0,1\}$ and $\theta \in[0,1]$. I have to find an estimator of $\theta$ by using the method of moment. Now, the first and second moments are: $\mathbb{E}(X)=0$ and $\mathbb{E}(X^2)=\theta$ Based on this , when a simple random sample of size $n$ is drawn: $\hat \mu_1=\dfrac{1}{n}\sum_{i=1}^nx_i$ and $\hat \mu_2=\dfrac{1}{n}\sum_{i=1}^nx_i^2$ So, the estimator $\hat \theta$ is  $$\hat \theta = \dfrac{1}{n}\sum_{i=1}^nx_i^2$$ Is that correct? :-) Edit I also have to prove that the estimator is unbiased and consistency. For first question: $$\mathbb{E}(\hat \theta)=\frac{1}{n}\mathbb{E}(X_1^2)+\frac{1}{n}\mathbb{E}(X_2^2)+\ldots+\frac{1}{n}\mathbb{E}(X_n^2)=\frac{1}{n}(\theta+\theta+\ldots+\theta)=\theta$$ thus the estimator is unbiased. For consistency we need that $\lim_{n \to \infty}\mathbb{E}(\hat \theta)=\theta$ and $\lim_{n \to \infty}\mathbb{Var}(\hat \theta)=0$. Any help?","Let $X$ be a discrete random variable with density function:    $$p(x;\theta)=\left(\frac{\theta}{2}\right)^{\lvert x\rvert}(1-\theta)^{1-\lvert x\rvert}$$   where $x\in\{-1,0,1\}$ and $\theta \in[0,1]$. I have to find an estimator of $\theta$ by using the method of moment. Now, the first and second moments are: $\mathbb{E}(X)=0$ and $\mathbb{E}(X^2)=\theta$ Based on this , when a simple random sample of size $n$ is drawn: $\hat \mu_1=\dfrac{1}{n}\sum_{i=1}^nx_i$ and $\hat \mu_2=\dfrac{1}{n}\sum_{i=1}^nx_i^2$ So, the estimator $\hat \theta$ is  $$\hat \theta = \dfrac{1}{n}\sum_{i=1}^nx_i^2$$ Is that correct? :-) Edit I also have to prove that the estimator is unbiased and consistency. For first question: $$\mathbb{E}(\hat \theta)=\frac{1}{n}\mathbb{E}(X_1^2)+\frac{1}{n}\mathbb{E}(X_2^2)+\ldots+\frac{1}{n}\mathbb{E}(X_n^2)=\frac{1}{n}(\theta+\theta+\ldots+\theta)=\theta$$ thus the estimator is unbiased. For consistency we need that $\lim_{n \to \infty}\mathbb{E}(\hat \theta)=\theta$ and $\lim_{n \to \infty}\mathbb{Var}(\hat \theta)=0$. Any help?",,"['statistics', 'parameter-estimation']"
34,Why is the CLT stated like it is?,Why is the CLT stated like it is?,,"The CLT says that given finite variance of iid RVs, we have  $$\sqrt{n}( \bar{X} - \mu) \rightarrow \mathcal{N}(0,\sigma^2),$$ but if this is true, then $\bar{X} - \mu$ should converge to $\mathcal{N}(0,\sigma^2 /n)$, right? And if this is true, then $\bar{X}$ should converge to $\mathcal{N}(\mu, \sigma^2/n)$, right? My questions are: are above two statements true (i.e, can we just multiply and subtract constants like we'd normally do with a normal distribution), and if so, why isn't the latter $\left( \bar{X} \rightarrow \mathcal{N}(\mu, \sigma^2/n) \right) $statement the way we state the CLT which seems much more intuitive, since it clearly says that the mean of our RVs are almost normally distributed with the proper mean and a diminishing variance, while it's not immediately obvious what the other statement is on about?","The CLT says that given finite variance of iid RVs, we have  $$\sqrt{n}( \bar{X} - \mu) \rightarrow \mathcal{N}(0,\sigma^2),$$ but if this is true, then $\bar{X} - \mu$ should converge to $\mathcal{N}(0,\sigma^2 /n)$, right? And if this is true, then $\bar{X}$ should converge to $\mathcal{N}(\mu, \sigma^2/n)$, right? My questions are: are above two statements true (i.e, can we just multiply and subtract constants like we'd normally do with a normal distribution), and if so, why isn't the latter $\left( \bar{X} \rightarrow \mathcal{N}(\mu, \sigma^2/n) \right) $statement the way we state the CLT which seems much more intuitive, since it clearly says that the mean of our RVs are almost normally distributed with the proper mean and a diminishing variance, while it's not immediately obvious what the other statement is on about?",,"['probability-theory', 'statistics', 'asymptotics']"
35,Find projection matrix using partitioned matrices,Find projection matrix using partitioned matrices,,"If X is a ($n$, $p+1$) design matrix, partition $X$ to be $X$=[$J$ $X$*]  where $J$ is a ($n$,$1$) vector of all $1$'s, and $X$* is a ($n$,$p$) matrix. Let $H_X$ be a projection matrix, where $H_X$ = $X{(X'X)}^{-1}X'$. I'm trying to prove: $H_X$ = $H_J$ + $H_X*$ And in doing so, I've been trying to deduce the above equation using: Suppose the design matrix $X$ can be decomposed by columns as $X$= [$A$ $B$].    Define the hat or projection operator as $P${$X$} = $X{(X'X)}^{-1}X'$. Similarly, define the residual operator as $M${$X$}=$I$-$P${$X$}.    Then the projection matrix can be decomposed as follows: $P${$X$} = $P${$A$} + $P${$M${$A$}$B$}. I found this formula (the ""Blockwise Formula"") on Wikipedia. The link is: https://en.wikipedia.org/wiki/Projection_matrix I've been trying to prove this formula, and from that deduce the equation I'm trying to solve. But I still haven't found a way to prove either. How can I prove the equation above? Will the formula I found on Wikipedia be helpful?","If X is a ($n$, $p+1$) design matrix, partition $X$ to be $X$=[$J$ $X$*]  where $J$ is a ($n$,$1$) vector of all $1$'s, and $X$* is a ($n$,$p$) matrix. Let $H_X$ be a projection matrix, where $H_X$ = $X{(X'X)}^{-1}X'$. I'm trying to prove: $H_X$ = $H_J$ + $H_X*$ And in doing so, I've been trying to deduce the above equation using: Suppose the design matrix $X$ can be decomposed by columns as $X$= [$A$ $B$].    Define the hat or projection operator as $P${$X$} = $X{(X'X)}^{-1}X'$. Similarly, define the residual operator as $M${$X$}=$I$-$P${$X$}.    Then the projection matrix can be decomposed as follows: $P${$X$} = $P${$A$} + $P${$M${$A$}$B$}. I found this formula (the ""Blockwise Formula"") on Wikipedia. The link is: https://en.wikipedia.org/wiki/Projection_matrix I've been trying to prove this formula, and from that deduce the equation I'm trying to solve. But I still haven't found a way to prove either. How can I prove the equation above? Will the formula I found on Wikipedia be helpful?",,"['linear-algebra', 'matrices', 'statistics', 'projection-matrices']"
36,What test would I use to analyze an applications' error rate?,What test would I use to analyze an applications' error rate?,,"I am a software engineer with a stats problem: I want to deploy a new version of a web application to a subset of users, measure the error rates, and if there is not an increase of error rates, direct it to all users. (We call this 'Canary Releasing' - including this term so the problem is searchable) I'm having trouble determining if the error rate has increased. My naive approach was to just calculate the error rate of each version: error rate A = # of errors in A / # requests in A error rate B = # of errors in B / # requests in B However this is a bit of a coin flip: the rates are never the same and it's possible that error rate B is higher but it is not significant. Is there a better test I can use?","I am a software engineer with a stats problem: I want to deploy a new version of a web application to a subset of users, measure the error rates, and if there is not an increase of error rates, direct it to all users. (We call this 'Canary Releasing' - including this term so the problem is searchable) I'm having trouble determining if the error rate has increased. My naive approach was to just calculate the error rate of each version: error rate A = # of errors in A / # requests in A error rate B = # of errors in B / # requests in B However this is a bit of a coin flip: the rates are never the same and it's possible that error rate B is higher but it is not significant. Is there a better test I can use?",,['statistics']
37,Cumulative bivariate normal,Cumulative bivariate normal,,"How do I calculate the cumulative probability distribution function for a bivariate normal distribution with conditions $P( x>a , y>b)$? Is there any method to solve $$P(x>a,y>b)\\\int_{b}^{\infty}\int_{a}^{\infty}\frac{1}{2\pi\sqrt{1-\rho^2}}\exp\left(-\frac12\frac{x^2-2\rho xy+y^2}{1-\rho^2}\right)\,dx\,dy$$","How do I calculate the cumulative probability distribution function for a bivariate normal distribution with conditions $P( x>a , y>b)$? Is there any method to solve $$P(x>a,y>b)\\\int_{b}^{\infty}\int_{a}^{\infty}\frac{1}{2\pi\sqrt{1-\rho^2}}\exp\left(-\frac12\frac{x^2-2\rho xy+y^2}{1-\rho^2}\right)\,dx\,dy$$",,"['integration', 'statistics', 'probability-distributions', 'normal-distribution']"
38,What do attendance figures tell me about regularity? What does the average tell me about individual attendance?,What do attendance figures tell me about regularity? What does the average tell me about individual attendance?,,"Suppose I have a group of $N$ people, attending a series of $M$ events, and (for simplicity) let's assume the overall attendance happens to be the same at each event, say $A$ people (ranging between 1 and $N$), or as a fraction $a = A/N$ (ranging between 0 and 1). However, it may not be the same people attending each event. What does knowing the attendance tell me about the individual attendance behaviour? In particular, can I draw any conclusions about the regularity of event attendance (i.e. the number of events an individual has been to)? For example, with fractional attendance $a$, it may be that (1) the same $a N$ people attended every event in the series ($M$ events), and the other $(1-a) N$ people never attended, giving an average of $a$. (2) Or it may mean that all $N$ people attended $a M$ events, also giving an average of $a$. My main question: Can you show that $a N$ people attended at least $a M$ events? More generally, given the average $a$ what is the minimum number of people $X$ (out of $N$), that attended at least $Y$ events (out of $M$)? I would have thought that this is relatively straight forward, but I couldn't find or come up with an answer. Extension 1: How would this change if the attendance at each event is variable? Would does the discrete distribution of attendance values $a_i=A_i/N$ ($i=1..M$), including the average $a = \sum_{i=1}^M a_i / M$, standard deviation, etc tell me about attendance pattern? Extension 2: I would also have thought that there are some combinatorial statements like: ""If I pick $a_1, a_2, a_3, ..., a_n$ out of $N$, the minimum overlap between $a_1, a_2, a_3, ..., a_n$ is such-and-such"".","Suppose I have a group of $N$ people, attending a series of $M$ events, and (for simplicity) let's assume the overall attendance happens to be the same at each event, say $A$ people (ranging between 1 and $N$), or as a fraction $a = A/N$ (ranging between 0 and 1). However, it may not be the same people attending each event. What does knowing the attendance tell me about the individual attendance behaviour? In particular, can I draw any conclusions about the regularity of event attendance (i.e. the number of events an individual has been to)? For example, with fractional attendance $a$, it may be that (1) the same $a N$ people attended every event in the series ($M$ events), and the other $(1-a) N$ people never attended, giving an average of $a$. (2) Or it may mean that all $N$ people attended $a M$ events, also giving an average of $a$. My main question: Can you show that $a N$ people attended at least $a M$ events? More generally, given the average $a$ what is the minimum number of people $X$ (out of $N$), that attended at least $Y$ events (out of $M$)? I would have thought that this is relatively straight forward, but I couldn't find or come up with an answer. Extension 1: How would this change if the attendance at each event is variable? Would does the discrete distribution of attendance values $a_i=A_i/N$ ($i=1..M$), including the average $a = \sum_{i=1}^M a_i / M$, standard deviation, etc tell me about attendance pattern? Extension 2: I would also have thought that there are some combinatorial statements like: ""If I pick $a_1, a_2, a_3, ..., a_n$ out of $N$, the minimum overlap between $a_1, a_2, a_3, ..., a_n$ is such-and-such"".",,"['probability', 'combinatorics', 'statistics', 'average']"
39,VC Dimension of star-shaped sets on $\mathbb{R}^2$,VC Dimension of star-shaped sets on,\mathbb{R}^2,"Consider a set $U \subset \mathbb{R}^2$ to be star-shaped with respect to a point $\epsilon \in \mathbb{R}^2$ if for every $x \in U$, the segment joining $\epsilon$ and $x$ is contained in $U$. Consider the $H = \{U \subset \mathbb{R}^2 | U \text{ is starshaped with respect to } \epsilon, \epsilon \in \mathbb{R}^2\}$ And take $H_{+}$ to be all the hypotheses in $H$ that assign $1$ if $x$ is within the starshaped set and $0$ otherwise. I am interested in finding the VC dimension of $H$. I have a feeling that this can account for an infinite number of points on $\mathbb{R}^2$, but I am having trouble formalizing this proof. Many of my friends said that these problems are best answered using ""matrix"" methods over all dichotomies of my observations. Is there a better method for handling this?","Consider a set $U \subset \mathbb{R}^2$ to be star-shaped with respect to a point $\epsilon \in \mathbb{R}^2$ if for every $x \in U$, the segment joining $\epsilon$ and $x$ is contained in $U$. Consider the $H = \{U \subset \mathbb{R}^2 | U \text{ is starshaped with respect to } \epsilon, \epsilon \in \mathbb{R}^2\}$ And take $H_{+}$ to be all the hypotheses in $H$ that assign $1$ if $x$ is within the starshaped set and $0$ otherwise. I am interested in finding the VC dimension of $H$. I have a feeling that this can account for an infinite number of points on $\mathbb{R}^2$, but I am having trouble formalizing this proof. Many of my friends said that these problems are best answered using ""matrix"" methods over all dichotomies of my observations. Is there a better method for handling this?",,['statistics']
40,Coin-toss game with \$1 entry fee and \$3 payout [closed],Coin-toss game with \3 payout [closed],1 entry fee and \,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Imagine a coin-tossing bet game. You pay \$1 to play the game (for one toss), and if you win you get a prize of \$3. The \$1 to play is not refunded. The probability of winning and losing is equal. If you play the game 100 times, what's the probability that you will have more money than when you started? I have worked out that the expected value after playing a game is \$1(gaining a dollar per game). Based on this, I couldn't quite figure out the answer to the probability question. Please explain your answer.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Imagine a coin-tossing bet game. You pay \$1 to play the game (for one toss), and if you win you get a prize of \$3. The \$1 to play is not refunded. The probability of winning and losing is equal. If you play the game 100 times, what's the probability that you will have more money than when you started? I have worked out that the expected value after playing a game is \$1(gaining a dollar per game). Based on this, I couldn't quite figure out the answer to the probability question. Please explain your answer.",,"['probability', 'statistics', 'random-variables', 'expectation']"
41,Determining if dice are fair using statistics,Determining if dice are fair using statistics,,"A casino must demonstrate to the state gaming commission that every die it uses is fair. a machine is used to roll each die 1200 times. a die is discarded if the following assumption it is fair is rejected at the 10% significance level. determine if the following results suggest a die is accepted or rejected by the casino. then it proceeds to show a picture of a die with the number 1 rolled 190 times, a die with the number 2 rolled 220 times and a die with the number 4 rolled 185 times.","A casino must demonstrate to the state gaming commission that every die it uses is fair. a machine is used to roll each die 1200 times. a die is discarded if the following assumption it is fair is rejected at the 10% significance level. determine if the following results suggest a die is accepted or rejected by the casino. then it proceeds to show a picture of a die with the number 1 rolled 190 times, a die with the number 2 rolled 220 times and a die with the number 4 rolled 185 times.",,['statistics']
42,Updating Bernoulli probability,Updating Bernoulli probability,,"I would like to show that the expression  $ \frac{E\,\left[\, p^{t+1}\left(1-p\right)^{\left(n-t\right)}\right]}{E\left[\, p^{t}\left(1-p\right)^{\left(n-t\right)}\right]} $ , where $p$ is random on $[0, 1] $ and $n$ and $t \leq n$ are positive integers, is increasing in $t$ (for any $n$). The background of this question is as follows. I'm currently starting to learn Bayesian statistics and I'm trying to understand some simple models. The above expression arises when there is a Bernoulli experiment with unknown probability $p$. Suppose that after $n$ trials we have drawn $t$ successes. It seems very intuitive that the larger $t$, the higher the posterior expectation of $p$ should be. However, the posterior expectation can be expressed as the expression above and I do not find a straightforward way to show that this expression is increasing in $t$. I assume that this is a simple textbook problem, but all I can find are treatments in which a specific prior distribution of $p$ is assumed. I however would like to see a solution which allows $p$ to have any distribution on $[0, 1]$, as long as the above expectations are defined.","I would like to show that the expression  $ \frac{E\,\left[\, p^{t+1}\left(1-p\right)^{\left(n-t\right)}\right]}{E\left[\, p^{t}\left(1-p\right)^{\left(n-t\right)}\right]} $ , where $p$ is random on $[0, 1] $ and $n$ and $t \leq n$ are positive integers, is increasing in $t$ (for any $n$). The background of this question is as follows. I'm currently starting to learn Bayesian statistics and I'm trying to understand some simple models. The above expression arises when there is a Bernoulli experiment with unknown probability $p$. Suppose that after $n$ trials we have drawn $t$ successes. It seems very intuitive that the larger $t$, the higher the posterior expectation of $p$ should be. However, the posterior expectation can be expressed as the expression above and I do not find a straightforward way to show that this expression is increasing in $t$. I assume that this is a simple textbook problem, but all I can find are treatments in which a specific prior distribution of $p$ is assumed. I however would like to see a solution which allows $p$ to have any distribution on $[0, 1]$, as long as the above expectations are defined.",,"['statistics', 'expectation', 'bayesian', 'binomial-distribution']"
43,Can we model this set of experiments as an stochastic process and estimate the sample size?,Can we model this set of experiments as an stochastic process and estimate the sample size?,,"I have an  image with the size 5575x9440 and I'm implementing a modified version of the algorithm used in this paper on it, but because the code performance is low right now, I have divided the image to 52628 submatrices of the size 25x40 (1000 pixels) and my first experiments show that some lines of code that are marked in the following picture as yellow are not needed at all (meaning that the 2 and 3 degree polynomials always have at least one real positive root) and so there's no need to check it. (Deleting these ten lines will make the code 3rd times faster and I have other plans to accelerate the code further) Because the code is slow right now, I cannot experiment all of these 52628 matrices and I have to choose a sample size and choose some random matrices to try. But how to calculate the sample size? What comes below is just to show my effort. And if you're not willing to read it, there's no necessity. I've already done as follows This is for lines 121 and 122. The approach for the other two lines (134 and 135) is the same. We want to test the following hypothesis. Hypothesis: the line 121, 122 will not be run even one time for the whole image. Hypothesis(scientifically): We can be 95% or 99% (confidence level) sure that those lines will be run just for 0.25% pixels (confidence interval) of the image. Up to know I have tried this way: First of all  we have a random variable X = two lines of code that can have just two values: they will run (1) or they will not run(0) . So the random variable  will have the Bernoulli distribution For each pixel, this experiment is done 62271 times and so in each submatrix, it will be done 62271000 times independently. So the random variable X = Number of times that the 2 lines are run that its value can be an integer number in the range $[0,62271000]$ is the sum of a huge number ( 62271000 ) of bernoulli distributed variables and so X will have a normal distribution according to the Central limit theorem so the random variable Z : $$Z=\frac{X-np}{\sqrt{npq}}$$ Edit: (Based on the discussion between me and @Wiley in the comments) I should say that from the theoretic concepts of my model, I know that $\Delta>0$ for 2d and 3d polynomials. So the roots are real but it is their sign that determines whether the highlighted cod is needed or not For 2D Polynomials: there are 4 cases if there's at least one positive root, the highlighted code is not needed ($p=\frac{3}{4}$) if all of the roots are negative, the highlighted code is needed. ($q=\frac{1}{4}$) For 3D Polynomials: there are 8 cases if there's at least one positive root, the highlighted code is not needed ($p=\frac{7}{8}$) if all of the roots are negative, the highlighted code is needed. ($q=\frac{1}{8}$) will have a Standard normal distribution So for the 3d polynomial we have: $p=\frac{7}{8}\;,q=\frac{1}{8}$ and also $n = 62271000$, so we will have: $$Z = \frac{X-54487125}{5219}\qquad 0\le X\le 62271000\Rightarrow -10440\le Z\le 1491$$ But from now on, I thinking I'm making some mistakes. Our confidence interval is 0.25% of pixels $$0.25\times 0.01\times 5575\times 9440 = 131570$$ meaning that the number of pixels that do not fit our hypothesis should be less than 131570 If we assume that these pixels are distributed homogeneously across the whole image, then the number of pixels in each submatrix that do not fit our hypothesis should be less than: $$\frac{131570}{52628}=2.5$$ so $0\le X\le 155677.5\Rightarrow -10440\le Z\le -10410$ so our confidence interval is $-10410-(-10440)=30$ and our confidence level is 95% or 99%, means that the probability that $Z$ lies in the above range should be 0.95 or 0.99 . $$p(Z)=N(0,1)=\frac{1}{\sqrt{2\pi}}\exp(-\frac{z^2}{2})$$ $$p(-10440\le Z\le -10410)=\frac{1}{\sqrt{2\pi}} \int_{-10440}^{-10410}\exp(-\frac{z^2}{2})\,dz = 0.95\; \text{or}\; 0.99$$ Then if we consider 52628 matrices as a stochastic process as a collection of 52628 (population) random variables with standard normal distribution , how many members of this process should be experimented (sample size)?","I have an  image with the size 5575x9440 and I'm implementing a modified version of the algorithm used in this paper on it, but because the code performance is low right now, I have divided the image to 52628 submatrices of the size 25x40 (1000 pixels) and my first experiments show that some lines of code that are marked in the following picture as yellow are not needed at all (meaning that the 2 and 3 degree polynomials always have at least one real positive root) and so there's no need to check it. (Deleting these ten lines will make the code 3rd times faster and I have other plans to accelerate the code further) Because the code is slow right now, I cannot experiment all of these 52628 matrices and I have to choose a sample size and choose some random matrices to try. But how to calculate the sample size? What comes below is just to show my effort. And if you're not willing to read it, there's no necessity. I've already done as follows This is for lines 121 and 122. The approach for the other two lines (134 and 135) is the same. We want to test the following hypothesis. Hypothesis: the line 121, 122 will not be run even one time for the whole image. Hypothesis(scientifically): We can be 95% or 99% (confidence level) sure that those lines will be run just for 0.25% pixels (confidence interval) of the image. Up to know I have tried this way: First of all  we have a random variable X = two lines of code that can have just two values: they will run (1) or they will not run(0) . So the random variable  will have the Bernoulli distribution For each pixel, this experiment is done 62271 times and so in each submatrix, it will be done 62271000 times independently. So the random variable X = Number of times that the 2 lines are run that its value can be an integer number in the range $[0,62271000]$ is the sum of a huge number ( 62271000 ) of bernoulli distributed variables and so X will have a normal distribution according to the Central limit theorem so the random variable Z : $$Z=\frac{X-np}{\sqrt{npq}}$$ Edit: (Based on the discussion between me and @Wiley in the comments) I should say that from the theoretic concepts of my model, I know that $\Delta>0$ for 2d and 3d polynomials. So the roots are real but it is their sign that determines whether the highlighted cod is needed or not For 2D Polynomials: there are 4 cases if there's at least one positive root, the highlighted code is not needed ($p=\frac{3}{4}$) if all of the roots are negative, the highlighted code is needed. ($q=\frac{1}{4}$) For 3D Polynomials: there are 8 cases if there's at least one positive root, the highlighted code is not needed ($p=\frac{7}{8}$) if all of the roots are negative, the highlighted code is needed. ($q=\frac{1}{8}$) will have a Standard normal distribution So for the 3d polynomial we have: $p=\frac{7}{8}\;,q=\frac{1}{8}$ and also $n = 62271000$, so we will have: $$Z = \frac{X-54487125}{5219}\qquad 0\le X\le 62271000\Rightarrow -10440\le Z\le 1491$$ But from now on, I thinking I'm making some mistakes. Our confidence interval is 0.25% of pixels $$0.25\times 0.01\times 5575\times 9440 = 131570$$ meaning that the number of pixels that do not fit our hypothesis should be less than 131570 If we assume that these pixels are distributed homogeneously across the whole image, then the number of pixels in each submatrix that do not fit our hypothesis should be less than: $$\frac{131570}{52628}=2.5$$ so $0\le X\le 155677.5\Rightarrow -10440\le Z\le -10410$ so our confidence interval is $-10410-(-10440)=30$ and our confidence level is 95% or 99%, means that the probability that $Z$ lies in the above range should be 0.95 or 0.99 . $$p(Z)=N(0,1)=\frac{1}{\sqrt{2\pi}}\exp(-\frac{z^2}{2})$$ $$p(-10440\le Z\le -10410)=\frac{1}{\sqrt{2\pi}} \int_{-10440}^{-10410}\exp(-\frac{z^2}{2})\,dz = 0.95\; \text{or}\; 0.99$$ Then if we consider 52628 matrices as a stochastic process as a collection of 52628 (population) random variables with standard normal distribution , how many members of this process should be experimented (sample size)?",,"['statistics', 'probability-distributions', 'stochastic-processes', 'random-variables', 'sampling']"
44,Probability of Detecting an Event Given No Previous Detections,Probability of Detecting an Event Given No Previous Detections,,"I'm trying to figure out: Given a probability distribution of how likely an event is to be detected at time $t=1,t=2,t=3,t=4$ etc, what is the probability that it will be detected at t=n+1 if it is not detected at t=n. To make sure I'm doing it correctly I've attempted to do this specifically for the example of exponential decay, since the probability of it being detected in any interval is constant, so it's easy to check whether or not I got the correct solution. To attempt this I've first calculate the cumulative distribution function, CDF. The probability of no detection at t=n is then simply $1-CDF(n)$. Then using Bayes rule(where Dt=n means detection at time t=n, and Nt=n means no detection at time t=n) $$P(Dt=n|Nt=n-1) = \frac{P(Nt=n-1|Dt=n)P(Dt=n)}{P(Nt=n-1)} $$ For something to of been detected at time t=n, it must of not been detected previously so $P(Nt=n-1|Dt=n)P(Dt=n)=1$ $$P(Dt=n|Nt=n-1) = \frac{P(Dt=n)}{P(Nt=n-1)} $$ Substiuting in $P(Nt=n-1) = 1-CDF(n-1)$ $$P(Dt=n|Nt=n-1) = \frac{P(Dt=n)}{1-CDF(n-1)} $$ However,this applied to an exponential decay does not result in $P(Dt=n|Nt=n-1)$ being constant. Could anyone point out what mistake I have made? Thank you for your time.","I'm trying to figure out: Given a probability distribution of how likely an event is to be detected at time $t=1,t=2,t=3,t=4$ etc, what is the probability that it will be detected at t=n+1 if it is not detected at t=n. To make sure I'm doing it correctly I've attempted to do this specifically for the example of exponential decay, since the probability of it being detected in any interval is constant, so it's easy to check whether or not I got the correct solution. To attempt this I've first calculate the cumulative distribution function, CDF. The probability of no detection at t=n is then simply $1-CDF(n)$. Then using Bayes rule(where Dt=n means detection at time t=n, and Nt=n means no detection at time t=n) $$P(Dt=n|Nt=n-1) = \frac{P(Nt=n-1|Dt=n)P(Dt=n)}{P(Nt=n-1)} $$ For something to of been detected at time t=n, it must of not been detected previously so $P(Nt=n-1|Dt=n)P(Dt=n)=1$ $$P(Dt=n|Nt=n-1) = \frac{P(Dt=n)}{P(Nt=n-1)} $$ Substiuting in $P(Nt=n-1) = 1-CDF(n-1)$ $$P(Dt=n|Nt=n-1) = \frac{P(Dt=n)}{1-CDF(n-1)} $$ However,this applied to an exponential decay does not result in $P(Dt=n|Nt=n-1)$ being constant. Could anyone point out what mistake I have made? Thank you for your time.",,"['probability', 'statistics']"
45,Coherent configurations (example and explanation),Coherent configurations (example and explanation),,"A coherent configuration is a pair $(X, S)$ consisting of a finite set $X $ of size $v$  and a set $S$ of binary relations on $X$ such that •$ S$ is a partition of $X × X$; • the diagonal relation $ ∆X$  is the union of some relations in $S$; • for each $R  \in  S$ it holds that $R^{T}  \in S$; • there exist integers $p^{R}_{ ST}$ such that |$\{z ∈ X|(x, z)  \in  S$  and  $(z, y) \in  T \}| = p^{R}_{ ST} \}$ whenever $(x, y) \in  R$, for each $R, S, T ∈ S$. I am new to this subject, so it is hard for me to understand. I request to explain above four axioms using an example. I have tried some notes, most of them have not included any example.","A coherent configuration is a pair $(X, S)$ consisting of a finite set $X $ of size $v$  and a set $S$ of binary relations on $X$ such that •$ S$ is a partition of $X × X$; • the diagonal relation $ ∆X$  is the union of some relations in $S$; • for each $R  \in  S$ it holds that $R^{T}  \in S$; • there exist integers $p^{R}_{ ST}$ such that |$\{z ∈ X|(x, z)  \in  S$  and  $(z, y) \in  T \}| = p^{R}_{ ST} \}$ whenever $(x, y) \in  R$, for each $R, S, T ∈ S$. I am new to this subject, so it is hard for me to understand. I request to explain above four axioms using an example. I have tried some notes, most of them have not included any example.",,"['abstract-algebra', 'combinatorics', 'statistics']"
46,Esscher Transform extended,Esscher Transform extended,,"This problem is almost solved, dont get scared by the massive text The Esscher-transform is a well know tool in the financial section. I posted this in statistics also, since it relates to continuous sampling. Im not sure if my approach is right, so it would be nice, if someone could check this. Given a Levy-process $(X_t)_{t\geq 0}$ under $P$ on $(\Omega,\mathcal{F})$ Let be $u$ be real such that the cumulant generating function of $X_t$ given by $\phi_{t}(u)=log(E[exp(uX_t)])$ is finite. We have with levy-properties $\phi_{t}(u)=t\phi_{1}(u)$. We know that the Esscher-transform $$ Z_{t}=e^{uX_t-t\phi_{1}(u)} \tag 1 $$ is a positive Martingale wrt to $\mathcal{F}_t=\sigma(X_s:s\leq t)$ and this density defines a measure $Q|\mathcal{F}_t$. We can define a measure $Q$ (by extension for $t\rightarrow \infty$) under which $(X_t)_{t\geq 0}$ is again a Levyprocess and its density on $\mathcal{F}_t$ is given by $$ \frac{dQ}{dP}|_{\mathcal{F}_t}=\frac{dQ}{dP}((X_{s})_{0\leq s \leq t})=Z_{t}  $$ Now however the restirction of $dQ/dP$ on $\mathcal{F}_t$ first says that $Z_t$ is an $\mathcal{F}_t$ measurable function and can thus be expressed almost surely as an function of the sample path $(X_s)_{s\leq t}$. Like in sequential statistics, we observe on $[0,t]$ and the induced likelihood-ratio $Z_t$ depends on the process observed on this interval. I want the understanding, why one says, that the induced measure $Z_t$ of the trajectory $(X_s)_{s\leq t}$ is only a function of the last $X_t$. So i want an understanding how we get this expression of $Z_t$. Typically in my understanding one has first to construct $Z_t$ in a common sense $$ Z_{t}=e^{\int_{0}^{t}udX_s-\int_{0}^{t}\phi_{1}(u)ds} \tag 2 $$ where you literally see, that the density is really a function of $(X_s)_{s\leq t}$, but which in the end really coincides with (1) then. This connects to my 2nd approach. There are possibly  approaches: Maybe since the cumulant generating function of $X_t$ $\phi_t$ is $t\cdot \phi_1$. So that the one dimensional distribution of $(X_t)_{t\geq 0}$ totally determine the law of the process, such that $X_t$ is enough to describe? First approach: This is not so clear for me. Maybe one can help me here. Maybe one can argue with the bayes forumla of conditional expectation, since the density process $Z_{t}$ is a Martingale wrt to $\mathcal{F}_t$ or general by the conditional expectation. Where for the second assertion we have for $s<t$ that $$ E_{Q}[Z_{t}|\mathcal{F}_s]=e^{uX_s-s\phi_1(u)}=Z_s $$ or for $A \in \mathcal{F}_s$ $$ Q_{|\mathcal{F}_t}(A)=E_{P}[L_t 1_{A}]=E_{P}[E_{P}[L_t 1_A|\mathcal{F_s}]=E_{P}[L_s 1_A]=Q_{|\mathcal{F}_s}(A) $$ which states, that the measures are consistent. Second approach: We construct (2). But i dont know if the way is correct. We know that the induced measure of a path $(X_s)_{s\leq t}$, is generated by its finite dimensional distributions. Basawa ""Statistical inference for Stochastic Processes"" p. 181 recommends to calculate the finite dimensional distributions  of $X=(X_{t_0},X_{t_1},\ldots X_{t_n})$ for $0=t_0<t_1<\ldots<t_n=t$ and let $\max_{1\leq i \leq n} t_i -t_{i-1}\rightarrow 0$ as $n\rightarrow \infty$ For a sequece $K_{i}$ of independent random variables on $(\Omega,\mathcal{F},P)$ with finite mean we have with $S_{n}=\sum_{i=1}^{n}K_{i}$ $$ Z_n=\frac{e^{uS_n}}{E[e^{uS_n}]} $$ Where $Z_{n}$ can be regarded as the density of the $n$-times product space wrt to $P^{\otimes n}$ and $Z_{n}=\prod_{i=1}^{n} e^{uK_{i}}/[Ee^{uK_{i}}]$ on $(\prod_{i=1}^{n} \Omega ,\otimes_{i=1}^{n} \mathcal{F})$. Lets $(K_{1},\ldots,K_{n})=(X_{t_1}-X_0(=0),X_{t_2}-X_{t_1},\ldots,X_{t_n}-X_{t_{n-1}})$ the increments of the increments of the levy process. Then $$ Z_n=e^{(uS_{n})-t_1\phi_{1}(u)-(t_2-t_1)\phi_{1}(u)-\ldots (t_n-t_{n-1})\phi_{1}(u)} $$ Letting $\max_{1\leq i \leq n} t_i -t_{i-1}\rightarrow \infty$ as $n\rightarrow \infty$ we can conclude (2). The law of $(X_s)_{s\leq t}$ is completely determined by the law of finite dimensional distributions. $Z_{t}$ is generated by sampling the increments on $[0,t]$. Since $X_t$ is Markov, the finite dimensional distribution is the product of the incremental densitys. This should show (2) i hope?","This problem is almost solved, dont get scared by the massive text The Esscher-transform is a well know tool in the financial section. I posted this in statistics also, since it relates to continuous sampling. Im not sure if my approach is right, so it would be nice, if someone could check this. Given a Levy-process $(X_t)_{t\geq 0}$ under $P$ on $(\Omega,\mathcal{F})$ Let be $u$ be real such that the cumulant generating function of $X_t$ given by $\phi_{t}(u)=log(E[exp(uX_t)])$ is finite. We have with levy-properties $\phi_{t}(u)=t\phi_{1}(u)$. We know that the Esscher-transform $$ Z_{t}=e^{uX_t-t\phi_{1}(u)} \tag 1 $$ is a positive Martingale wrt to $\mathcal{F}_t=\sigma(X_s:s\leq t)$ and this density defines a measure $Q|\mathcal{F}_t$. We can define a measure $Q$ (by extension for $t\rightarrow \infty$) under which $(X_t)_{t\geq 0}$ is again a Levyprocess and its density on $\mathcal{F}_t$ is given by $$ \frac{dQ}{dP}|_{\mathcal{F}_t}=\frac{dQ}{dP}((X_{s})_{0\leq s \leq t})=Z_{t}  $$ Now however the restirction of $dQ/dP$ on $\mathcal{F}_t$ first says that $Z_t$ is an $\mathcal{F}_t$ measurable function and can thus be expressed almost surely as an function of the sample path $(X_s)_{s\leq t}$. Like in sequential statistics, we observe on $[0,t]$ and the induced likelihood-ratio $Z_t$ depends on the process observed on this interval. I want the understanding, why one says, that the induced measure $Z_t$ of the trajectory $(X_s)_{s\leq t}$ is only a function of the last $X_t$. So i want an understanding how we get this expression of $Z_t$. Typically in my understanding one has first to construct $Z_t$ in a common sense $$ Z_{t}=e^{\int_{0}^{t}udX_s-\int_{0}^{t}\phi_{1}(u)ds} \tag 2 $$ where you literally see, that the density is really a function of $(X_s)_{s\leq t}$, but which in the end really coincides with (1) then. This connects to my 2nd approach. There are possibly  approaches: Maybe since the cumulant generating function of $X_t$ $\phi_t$ is $t\cdot \phi_1$. So that the one dimensional distribution of $(X_t)_{t\geq 0}$ totally determine the law of the process, such that $X_t$ is enough to describe? First approach: This is not so clear for me. Maybe one can help me here. Maybe one can argue with the bayes forumla of conditional expectation, since the density process $Z_{t}$ is a Martingale wrt to $\mathcal{F}_t$ or general by the conditional expectation. Where for the second assertion we have for $s<t$ that $$ E_{Q}[Z_{t}|\mathcal{F}_s]=e^{uX_s-s\phi_1(u)}=Z_s $$ or for $A \in \mathcal{F}_s$ $$ Q_{|\mathcal{F}_t}(A)=E_{P}[L_t 1_{A}]=E_{P}[E_{P}[L_t 1_A|\mathcal{F_s}]=E_{P}[L_s 1_A]=Q_{|\mathcal{F}_s}(A) $$ which states, that the measures are consistent. Second approach: We construct (2). But i dont know if the way is correct. We know that the induced measure of a path $(X_s)_{s\leq t}$, is generated by its finite dimensional distributions. Basawa ""Statistical inference for Stochastic Processes"" p. 181 recommends to calculate the finite dimensional distributions  of $X=(X_{t_0},X_{t_1},\ldots X_{t_n})$ for $0=t_0<t_1<\ldots<t_n=t$ and let $\max_{1\leq i \leq n} t_i -t_{i-1}\rightarrow 0$ as $n\rightarrow \infty$ For a sequece $K_{i}$ of independent random variables on $(\Omega,\mathcal{F},P)$ with finite mean we have with $S_{n}=\sum_{i=1}^{n}K_{i}$ $$ Z_n=\frac{e^{uS_n}}{E[e^{uS_n}]} $$ Where $Z_{n}$ can be regarded as the density of the $n$-times product space wrt to $P^{\otimes n}$ and $Z_{n}=\prod_{i=1}^{n} e^{uK_{i}}/[Ee^{uK_{i}}]$ on $(\prod_{i=1}^{n} \Omega ,\otimes_{i=1}^{n} \mathcal{F})$. Lets $(K_{1},\ldots,K_{n})=(X_{t_1}-X_0(=0),X_{t_2}-X_{t_1},\ldots,X_{t_n}-X_{t_{n-1}})$ the increments of the increments of the levy process. Then $$ Z_n=e^{(uS_{n})-t_1\phi_{1}(u)-(t_2-t_1)\phi_{1}(u)-\ldots (t_n-t_{n-1})\phi_{1}(u)} $$ Letting $\max_{1\leq i \leq n} t_i -t_{i-1}\rightarrow \infty$ as $n\rightarrow \infty$ we can conclude (2). The law of $(X_s)_{s\leq t}$ is completely determined by the law of finite dimensional distributions. $Z_{t}$ is generated by sampling the increments on $[0,t]$. Since $X_t$ is Markov, the finite dimensional distribution is the product of the incremental densitys. This should show (2) i hope?",,"['probability', 'probability-theory', 'measure-theory', 'statistics', 'stochastic-processes']"
47,Bayes' Theorem and Law of total propability for CDF,Bayes' Theorem and Law of total propability for CDF,,"The calculation of conditional probability is the same for conditional PDF and CDF(according to a number of questionable sources: first , second ) (I will use rough notation, with just $x$ and $y$): $$F(x \ | \ y) = \frac{F(x,y)}{F(y)}, \ \  f(x \ | \ y) = \frac{f(x,y)}{f(y)}  $$ The Bayes' Theorem for probability density functions looks like $$f(x \ | \ y) = \frac{f(y \ | \ x)f(x)}{f(y)}$$ and can be derived using second definition above. Looks like the same can be postulated for cumulative distribution function: $$F(x \ | \ y) = \frac{F(y \ | \ x)F(x)}{F(y)}$$ Really: $$\frac{F(x,y)}{F(y)} = F(x \ | \ y) = \frac{F(y \ | \ x)F(x)}{F(y)},$$ $$\frac{F(x , y)}{F(x)} = F(y \ | \ x).$$ Now the question - ""law of total probability"" for PDFs: $$f(x \ | \ y) = \frac{f(y \ | \ x)f(x)}{\int_{\Omega}f(y \ | \ x)f(x)dx}$$ Can it be expressed in terms of CDFs somehow (I don't have $F(y)$)? EDIT: maybe some computational approach. I know that I can set in joint CDF some very big $x$: $\lim_{x \rightarrow \infty} F(x,y) = F(y), \ F(x,y)=F(y\ | \ x)F(x)$, but I can't obtain joint CDF from my data. I know also that I can find find ""derivative"": $f(x) \approx \frac{F(x+\Delta)-F(x-\Delta)}{\Delta}$, but it will be poor estimate. I have: $F(y \ | \ x)$ and $F(x)$ estimated - both functions of $x$ ($y$ is actual observation data).","The calculation of conditional probability is the same for conditional PDF and CDF(according to a number of questionable sources: first , second ) (I will use rough notation, with just $x$ and $y$): $$F(x \ | \ y) = \frac{F(x,y)}{F(y)}, \ \  f(x \ | \ y) = \frac{f(x,y)}{f(y)}  $$ The Bayes' Theorem for probability density functions looks like $$f(x \ | \ y) = \frac{f(y \ | \ x)f(x)}{f(y)}$$ and can be derived using second definition above. Looks like the same can be postulated for cumulative distribution function: $$F(x \ | \ y) = \frac{F(y \ | \ x)F(x)}{F(y)}$$ Really: $$\frac{F(x,y)}{F(y)} = F(x \ | \ y) = \frac{F(y \ | \ x)F(x)}{F(y)},$$ $$\frac{F(x , y)}{F(x)} = F(y \ | \ x).$$ Now the question - ""law of total probability"" for PDFs: $$f(x \ | \ y) = \frac{f(y \ | \ x)f(x)}{\int_{\Omega}f(y \ | \ x)f(x)dx}$$ Can it be expressed in terms of CDFs somehow (I don't have $F(y)$)? EDIT: maybe some computational approach. I know that I can set in joint CDF some very big $x$: $\lim_{x \rightarrow \infty} F(x,y) = F(y), \ F(x,y)=F(y\ | \ x)F(x)$, but I can't obtain joint CDF from my data. I know also that I can find find ""derivative"": $f(x) \approx \frac{F(x+\Delta)-F(x-\Delta)}{\Delta}$, but it will be poor estimate. I have: $F(y \ | \ x)$ and $F(x)$ estimated - both functions of $x$ ($y$ is actual observation data).",,"['probability', 'probability-theory', 'statistics', 'bayes-theorem']"
48,statistical tolerance limits,statistical tolerance limits,,"My Question is: What statistical methods can be used to examine whether a selection of tolerance limits of data makes sense, i.e. validation of tolerance limits? My solution: I would analyse how many outliers exist (data greater than the tolerance limit), how they are distributed (>>tolerance limit oder low deviation from the tolerance limit), comparison of mean, quantiles, standard deviation of data (which allow statements about curtosis,skewness etc.). But I'm not sure in which cases one can say that a stated tolerance limit makes sense. There is no optimal tolerance limit. So my Questions summarized: (1) Which statistical methods exist to validate a stated tolerance limit? (2) What should be the ""desired goal/result"" of these statistical tests of validation?","My Question is: What statistical methods can be used to examine whether a selection of tolerance limits of data makes sense, i.e. validation of tolerance limits? My solution: I would analyse how many outliers exist (data greater than the tolerance limit), how they are distributed (>>tolerance limit oder low deviation from the tolerance limit), comparison of mean, quantiles, standard deviation of data (which allow statements about curtosis,skewness etc.). But I'm not sure in which cases one can say that a stated tolerance limit makes sense. There is no optimal tolerance limit. So my Questions summarized: (1) Which statistical methods exist to validate a stated tolerance limit? (2) What should be the ""desired goal/result"" of these statistical tests of validation?",,"['statistics', 'descriptive-statistics']"
49,How to Find Expected Value from a Joint Distribution?,How to Find Expected Value from a Joint Distribution?,,"I am trying to solve the following problem: Let $X$ be a random variable from a contaminated normal distribution.   That is, let $B ∼\text{Bernoulli}(p).$ Then $X|B = 0 ∼ N(µ, τ^2 )$ and $X|B = 1 ∼ N(µ, σ^2 )$. Calculate $\text{Cov}(X, B)$. Are $X$ and $B$ independent? Here we know $\operatorname{Cov}(X,B)=E(XB)-E(X)E(B)$ Here i found $$E(X)=\mu$$ and $E(B)=p,$. But how can I find E(XB)? even if i can find $E(XB)$, then how to take decision that $X and B$ are independent or not because $Cov(X,B)=0$ doesn't imply they are independent.","I am trying to solve the following problem: Let $X$ be a random variable from a contaminated normal distribution.   That is, let $B ∼\text{Bernoulli}(p).$ Then $X|B = 0 ∼ N(µ, τ^2 )$ and $X|B = 1 ∼ N(µ, σ^2 )$. Calculate $\text{Cov}(X, B)$. Are $X$ and $B$ independent? Here we know $\operatorname{Cov}(X,B)=E(XB)-E(X)E(B)$ Here i found $$E(X)=\mu$$ and $E(B)=p,$. But how can I find E(XB)? even if i can find $E(XB)$, then how to take decision that $X and B$ are independent or not because $Cov(X,B)=0$ doesn't imply they are independent.",,"['probability-theory', 'statistics', 'probability-distributions']"
50,Expectation or Integration of the normal cdf,Expectation or Integration of the normal cdf,,"Can any one help me how to solve this pronbelm? I have a random variable $W$, i.e., $$W=\Phi(X)^k\Phi(-X)^m=P(Z\le X)^kP(Z \ge X)^m,$$ $X$ is Normal($\mu$,1), $Z \text{ is Normal(0,1)}$, and $k$ and $m$ are two constant integers. I want to find the expectation of $W$, which is $EW$. In other words I want to find the integration of $$\int \Phi(x)^k\Phi(-x)^mf(x)dx$$ a) I tried to find first the density function of $W$ like the following way and then $EW$ but could not solve: $$P(W\le w)=P\left(\Phi(X)^k\Phi(Y)^m\le w\right)=\int P\left(X\le \Phi^{-1} \left( \left( \frac{w}{\Phi(y)^m} \right)^{1/k} \right)\right) f(y)\,dy$$ b) I also tried like $$W=\Phi(X)^k\Phi(-X)^m=P(Z\le X)^kP(Z \ge X)^m=P(Z-X\le 0)^kP(Z-X \ge 0)^m=\Phi \left(\frac{-\mu}{\sqrt(2-2\rho)}\right)^k\Phi \left(\frac{\mu}{\sqrt(2+2\rho)}\right)^m.$$ Since $Z-X \text{ is Normal(-$\mu,2-2\rho$) if correlation between Z and X is $\rho.$  }$  Therfore, $$EW=\Phi \left(\frac{-\mu}{\sqrt(2-2\rho)}\right)^k\Phi \left(\frac{\mu}{\sqrt(2+2\rho)}\right)^m.$$  Is the second procedure right? Thank you I highly appreciate it.","Can any one help me how to solve this pronbelm? I have a random variable $W$, i.e., $$W=\Phi(X)^k\Phi(-X)^m=P(Z\le X)^kP(Z \ge X)^m,$$ $X$ is Normal($\mu$,1), $Z \text{ is Normal(0,1)}$, and $k$ and $m$ are two constant integers. I want to find the expectation of $W$, which is $EW$. In other words I want to find the integration of $$\int \Phi(x)^k\Phi(-x)^mf(x)dx$$ a) I tried to find first the density function of $W$ like the following way and then $EW$ but could not solve: $$P(W\le w)=P\left(\Phi(X)^k\Phi(Y)^m\le w\right)=\int P\left(X\le \Phi^{-1} \left( \left( \frac{w}{\Phi(y)^m} \right)^{1/k} \right)\right) f(y)\,dy$$ b) I also tried like $$W=\Phi(X)^k\Phi(-X)^m=P(Z\le X)^kP(Z \ge X)^m=P(Z-X\le 0)^kP(Z-X \ge 0)^m=\Phi \left(\frac{-\mu}{\sqrt(2-2\rho)}\right)^k\Phi \left(\frac{\mu}{\sqrt(2+2\rho)}\right)^m.$$ Since $Z-X \text{ is Normal(-$\mu,2-2\rho$) if correlation between Z and X is $\rho.$  }$  Therfore, $$EW=\Phi \left(\frac{-\mu}{\sqrt(2-2\rho)}\right)^k\Phi \left(\frac{\mu}{\sqrt(2+2\rho)}\right)^m.$$  Is the second procedure right? Thank you I highly appreciate it.",,"['calculus', 'statistics', 'multivariable-calculus', 'discrete-mathematics', 'statistical-inference']"
51,How to compute $E[Xr / (Xr +1 - X)] $ where $X$ follows a Beta distibution?,How to compute  where  follows a Beta distibution?,E[Xr / (Xr +1 - X)]  X,"I would like to compute $E[Xr / (Xr +1 - X)] $ where $X$ follows a Beta distribution $\operatorname{Beta}(\alpha, \beta)$ with $\alpha, \beta > 1$, $\alpha < \beta$ and $r \in (0,1)$. This is the same as computing the integral: $$\int_0^1 \frac{xr}{xr +1 -x} \frac{x^{\alpha-1}  (1-x) ^ {\beta - 1}}{\operatorname{Beta}(\alpha,\beta)} \, dx$$ where $Beta$ is the beta function. I'm looking for a closed formula that would be a ""simple"" function of $r$ and known functions, such as the $Beta$ or $\Gamma$ functions. For instance, to solve $E[X] =\int_0^1 x \frac{x^{\alpha-1}  (1-x) ^ {\beta - 1}}{\operatorname{Beta}(\alpha,\beta)} \, dx$, noticing that: $\int_0^1 x^\alpha (1-x)^{\beta - 1} \, dx = \operatorname{Beta}(\alpha+1,\beta) = \operatorname{Beta}(\alpha,\beta) \frac{\alpha}{\alpha + \beta} $ (via the $\Gamma$ function) gives the answer. But I can't find such a trick or a nice change of variable for $E[Xr / (Xr +1 - X)] $. Thanks in advance","I would like to compute $E[Xr / (Xr +1 - X)] $ where $X$ follows a Beta distribution $\operatorname{Beta}(\alpha, \beta)$ with $\alpha, \beta > 1$, $\alpha < \beta$ and $r \in (0,1)$. This is the same as computing the integral: $$\int_0^1 \frac{xr}{xr +1 -x} \frac{x^{\alpha-1}  (1-x) ^ {\beta - 1}}{\operatorname{Beta}(\alpha,\beta)} \, dx$$ where $Beta$ is the beta function. I'm looking for a closed formula that would be a ""simple"" function of $r$ and known functions, such as the $Beta$ or $\Gamma$ functions. For instance, to solve $E[X] =\int_0^1 x \frac{x^{\alpha-1}  (1-x) ^ {\beta - 1}}{\operatorname{Beta}(\alpha,\beta)} \, dx$, noticing that: $\int_0^1 x^\alpha (1-x)^{\beta - 1} \, dx = \operatorname{Beta}(\alpha+1,\beta) = \operatorname{Beta}(\alpha,\beta) \frac{\alpha}{\alpha + \beta} $ (via the $\Gamma$ function) gives the answer. But I can't find such a trick or a nice change of variable for $E[Xr / (Xr +1 - X)] $. Thanks in advance",,"['probability', 'integration', 'statistics', 'expectation', 'beta-function']"
52,subaddivity of VaR,subaddivity of VaR,,"It is known that the VaR (Value at risk) doesn't fulfill subadditivity, i.e. $VaR(X)+VaR(Y) \le VaR(X+Y)$. But for elliptical distributions subadditivity is true.  Questions: (1) Which distributions are elliptical? I guess its the (multi)normal and t-distributions...Are stable and hyperbolic distributions elliptical,too? (2) Is subadditvity only fulfilled for elliptical distributions? Are there any other conditions (e.g. correlation) which have an impact on subadditivity of VaR.","It is known that the VaR (Value at risk) doesn't fulfill subadditivity, i.e. $VaR(X)+VaR(Y) \le VaR(X+Y)$. But for elliptical distributions subadditivity is true.  Questions: (1) Which distributions are elliptical? I guess its the (multi)normal and t-distributions...Are stable and hyperbolic distributions elliptical,too? (2) Is subadditvity only fulfilled for elliptical distributions? Are there any other conditions (e.g. correlation) which have an impact on subadditivity of VaR.",,"['probability', 'probability-theory', 'statistics', 'finance']"
53,Necessary to find an estimator's probability distribution before calculating its expectation?,Necessary to find an estimator's probability distribution before calculating its expectation?,,"Where $X_{1}, X_{2}, \dots X_{n}$ is an iid distribution with pdf given by: \begin{cases} \frac{1}{\theta}x^{1-\theta} \qquad &\text{If $0 \leq x \leq 1$} \\[5 pt] 0 \qquad &Otherwise \end{cases} It can be shown using the M.L.E for estimator inference that $\theta$ is given by: $$\theta = \frac{-1}{n} \sum_{i = 1}^{n} \ln(X_{i})$$ To take the expectation of this estimator, what's the next step? I believe that I need to find the underlying distribution for $\theta$, correct? I ask that question, only because a solution does not find this underlying distribution (or else is not explicit): And what if I find $\theta$ to be $(1 - \bar{X})/\bar{X}$? In that case, how would I find the underlying pmf of $\theta$?","Where $X_{1}, X_{2}, \dots X_{n}$ is an iid distribution with pdf given by: \begin{cases} \frac{1}{\theta}x^{1-\theta} \qquad &\text{If $0 \leq x \leq 1$} \\[5 pt] 0 \qquad &Otherwise \end{cases} It can be shown using the M.L.E for estimator inference that $\theta$ is given by: $$\theta = \frac{-1}{n} \sum_{i = 1}^{n} \ln(X_{i})$$ To take the expectation of this estimator, what's the next step? I believe that I need to find the underlying distribution for $\theta$, correct? I ask that question, only because a solution does not find this underlying distribution (or else is not explicit): And what if I find $\theta$ to be $(1 - \bar{X})/\bar{X}$? In that case, how would I find the underlying pmf of $\theta$?",,"['statistics', 'statistical-inference', 'parameter-estimation']"
54,Chi-square table,Chi-square table,,"I'm new to using chi-square table, and I assume that it should not be hard to use but yet I have some problems with it. I am due to find the following in a chi-square table: $P(Y>5)$ where $Y$ follows a chi-square distribution with $5$ degrees of freedom. We have not been given any significance level/alpha. How do I use the table to find the answer?","I'm new to using chi-square table, and I assume that it should not be hard to use but yet I have some problems with it. I am due to find the following in a chi-square table: $P(Y>5)$ where $Y$ follows a chi-square distribution with $5$ degrees of freedom. We have not been given any significance level/alpha. How do I use the table to find the answer?",,['statistics']
55,How to use Expectation Maximization (EM) in Item Response Theory (IRT)?,How to use Expectation Maximization (EM) in Item Response Theory (IRT)?,,Could you give a worked example on the steps of Expectation Maximization in Item Response Theory if we use the Two Parameter Rasch Model. The student abilities are unknown and the question parameters are unknown as well . How can we use Expectation Maximization (EM) to find these unknown parameters if we know what questions each student has got correct. (note: I have found a two sources online but I do not understand them. A worked example would be fantastic: http://www.openirt.com/b-a-h/papers/note9801.pdf and http://www.lsac.org/docs/default-source/research-(lsac-resources)/rr-11-01.pdf?sfvrsn=2 ),Could you give a worked example on the steps of Expectation Maximization in Item Response Theory if we use the Two Parameter Rasch Model. The student abilities are unknown and the question parameters are unknown as well . How can we use Expectation Maximization (EM) to find these unknown parameters if we know what questions each student has got correct. (note: I have found a two sources online but I do not understand them. A worked example would be fantastic: http://www.openirt.com/b-a-h/papers/note9801.pdf and http://www.lsac.org/docs/default-source/research-(lsac-resources)/rr-11-01.pdf?sfvrsn=2 ),,"['statistics', 'optimization', 'expectation', 'parameter-estimation']"
56,1-How my profesor reach this solution? 2-How can I use eigenvalues to compute betas?... if there is any way,1-How my profesor reach this solution? 2-How can I use eigenvalues to compute betas?... if there is any way,,"this time I quite don't undertand how the profesor avoid using matrix algebra to solve this exercise. Statement: Below you can see a scatter plot of the data with the three regression   lines corresponding to the three levels of the categorical predictor.   Using the same two dummy variables you dened in (a), write down the   tted regression model (read slope estimates o the graph). You do not   have to make a statement about the residuals. Note, that the general   regression model with interaction for this case is Graph: Questions: ** 1) What is the procedure the proffesor utilized? 2) How one can use quadratic form and eigenvalues to compuete the betas wich I belibe will be my eigeinvalues for each eigenvector. I hope I could explain my problem, thanks so much for your help.**","this time I quite don't undertand how the profesor avoid using matrix algebra to solve this exercise. Statement: Below you can see a scatter plot of the data with the three regression   lines corresponding to the three levels of the categorical predictor.   Using the same two dummy variables you dened in (a), write down the   tted regression model (read slope estimates o the graph). You do not   have to make a statement about the residuals. Note, that the general   regression model with interaction for this case is Graph: Questions: ** 1) What is the procedure the proffesor utilized? 2) How one can use quadratic form and eigenvalues to compuete the betas wich I belibe will be my eigeinvalues for each eigenvector. I hope I could explain my problem, thanks so much for your help.**",,"['linear-algebra', 'statistics', 'descriptive-statistics']"
57,Hypothesis test in Bayesian statistics,Hypothesis test in Bayesian statistics,,"Let $X\sim N(\theta,1)$ and 5 independent observations   $X=(4.9,5.6,5.1,4.6,3.6)$. The prior probability that $\theta=4.01$ is   $0.5$. The remain values of $\theta$ are given the density of   $g(\theta)$. a)Assume $g(\theta)\sim N(4.01,1)$ test the hypothesis   $$H_0:\theta=4.01\space vs\space H_1:\theta\neq 4.01$$ From what I learn to make a hypothesis test I need to find $$a_0=P(\theta\in\Theta_0|x)$$ such that $$a_0+a_1=1$$ and reject $H_0$ if $$a_0<a_1$$ in the cases where the null hypothesis is not a point I can make, but in this case I have a few doubts. From the notes that I take there is the theorem below Theorem: For any prior $$\pi(\theta)=\pi_0\space \text{if}\space \theta=\theta_0$$ $$\pi(\theta)=\pi_1 h(\theta)\space\text{if}\space  \theta\neq \theta_0$$ such that $$\int_{\theta\neq > \theta_0}g(\theta)d(\theta)=1$$ then $$a_0=f(\theta|x)\geq  [1+\frac{1-\pi_0}{\pi_0}\frac{r(x)}{f(x|\theta_0)}]^{-1}$$ where   $$r(x)=sup_{\theta\neq\theta_0}f(x|\theta)$$ usually   $$r(x)=f(x|\hat{\theta})$$ In this case $\hat{\theta}=\overline{X}$ but the distribution of $$f(x|\overline{X})$$ doesn't make sense to me, in one example that I look they take $$f(\overline{x}|\hat{\theta})$$ but I don't understood the logic. I need to use the distribution of the likelihood estimator supposing that $\theta=\hat{\theta}$? If someone can give me a explanation with details on how it works I really appreciate.","Let $X\sim N(\theta,1)$ and 5 independent observations   $X=(4.9,5.6,5.1,4.6,3.6)$. The prior probability that $\theta=4.01$ is   $0.5$. The remain values of $\theta$ are given the density of   $g(\theta)$. a)Assume $g(\theta)\sim N(4.01,1)$ test the hypothesis   $$H_0:\theta=4.01\space vs\space H_1:\theta\neq 4.01$$ From what I learn to make a hypothesis test I need to find $$a_0=P(\theta\in\Theta_0|x)$$ such that $$a_0+a_1=1$$ and reject $H_0$ if $$a_0<a_1$$ in the cases where the null hypothesis is not a point I can make, but in this case I have a few doubts. From the notes that I take there is the theorem below Theorem: For any prior $$\pi(\theta)=\pi_0\space \text{if}\space \theta=\theta_0$$ $$\pi(\theta)=\pi_1 h(\theta)\space\text{if}\space  \theta\neq \theta_0$$ such that $$\int_{\theta\neq > \theta_0}g(\theta)d(\theta)=1$$ then $$a_0=f(\theta|x)\geq  [1+\frac{1-\pi_0}{\pi_0}\frac{r(x)}{f(x|\theta_0)}]^{-1}$$ where   $$r(x)=sup_{\theta\neq\theta_0}f(x|\theta)$$ usually   $$r(x)=f(x|\hat{\theta})$$ In this case $\hat{\theta}=\overline{X}$ but the distribution of $$f(x|\overline{X})$$ doesn't make sense to me, in one example that I look they take $$f(\overline{x}|\hat{\theta})$$ but I don't understood the logic. I need to use the distribution of the likelihood estimator supposing that $\theta=\hat{\theta}$? If someone can give me a explanation with details on how it works I really appreciate.",,"['statistics', 'normal-distribution', 'bayesian', 'hypothesis-testing']"
58,Paired Observation Hypothesis Testing,Paired Observation Hypothesis Testing,,"I'm doing a project presentation for applied statistics about hypothesis testing. Me and my partner claimed that the average amount of money that people spend per month on groceries is less than or equal to the average amount spent on dining out. We've used survey monkey (a free online survey tool) to receive data from people and ended up receiving 34 responses. The survey asks the average amount of money per month that they spend on groceries and dining out. This is a paired observation therefore I used a paired t-test to draw conclusion from the data. I have two questions: 1.) The formula has d0, and d0 = u1 - u2. Now I'm not sure if the value that I gave  d0 = 0 is correct. d0 would definitely be equal to zero if my null hypothesis was u1 = u2, since the difference between the mews will be zero. 2.) Is it okay to assume that the population of the amount of money spent per month on groceries and dining out are normally distributed? Even though I don't know the real shape of the two population distributions? Any thoughts or comments about this? The image below contains my work and conclusion. The image contains my work and the conclusion. Also below is the data that we got from the survey. The green is the difference between the average money spent on groceries and dining out. Here is my updated work and conclusion","I'm doing a project presentation for applied statistics about hypothesis testing. Me and my partner claimed that the average amount of money that people spend per month on groceries is less than or equal to the average amount spent on dining out. We've used survey monkey (a free online survey tool) to receive data from people and ended up receiving 34 responses. The survey asks the average amount of money per month that they spend on groceries and dining out. This is a paired observation therefore I used a paired t-test to draw conclusion from the data. I have two questions: 1.) The formula has d0, and d0 = u1 - u2. Now I'm not sure if the value that I gave  d0 = 0 is correct. d0 would definitely be equal to zero if my null hypothesis was u1 = u2, since the difference between the mews will be zero. 2.) Is it okay to assume that the population of the amount of money spent per month on groceries and dining out are normally distributed? Even though I don't know the real shape of the two population distributions? Any thoughts or comments about this? The image below contains my work and conclusion. The image contains my work and the conclusion. Also below is the data that we got from the survey. The green is the difference between the average money spent on groceries and dining out. Here is my updated work and conclusion",,['statistics']
59,Sufficient sample size for 1 out of X sets,Sufficient sample size for 1 out of X sets,,"I want to create a ""game"" that aims at supporting the decision making. The user has to consecutively select one out of two random items. Each item belongs to one of X sets. My question is how many different choices are required to be sure which set is the preferred one. Example: 3 sets of food: ""German"", ""Italian"", ""Mexican"". First screen: potatoes (german) vs spaghetti (italian). User selects: potatoes Second screen: taco (mexican) vs bratwurst (german). User selects: bratwurst … How many selections are required to be sure that user selects the German food with a probability of 70% over Italian or Mexican food?","I want to create a ""game"" that aims at supporting the decision making. The user has to consecutively select one out of two random items. Each item belongs to one of X sets. My question is how many different choices are required to be sure which set is the preferred one. Example: 3 sets of food: ""German"", ""Italian"", ""Mexican"". First screen: potatoes (german) vs spaghetti (italian). User selects: potatoes Second screen: taco (mexican) vs bratwurst (german). User selects: bratwurst … How many selections are required to be sure that user selects the German food with a probability of 70% over Italian or Mexican food?",,['statistics']
60,Posterior Predictive Distribution for a coin toss,Posterior Predictive Distribution for a coin toss,,"In this question, i can work out that the posterior is supposed to be a Beta (r+1, n-r+1) distribution. However, what I am struggling with is how to compute f(X_n+1|theta). Is this the binomial distribution with r+1 replacing r, because it's the probability of achieving r+1 heads in X_n+1 flips? Or is it simply theta, because it's the probability of seeing an (r+1)th head in 1 extra flip, having observed r heads in n flips? Obviously depending on which is the correct f, the answers vary significantly. Any help would be greatly appreciated! Thanks a lot","In this question, i can work out that the posterior is supposed to be a Beta (r+1, n-r+1) distribution. However, what I am struggling with is how to compute f(X_n+1|theta). Is this the binomial distribution with r+1 replacing r, because it's the probability of achieving r+1 heads in X_n+1 flips? Or is it simply theta, because it's the probability of seeing an (r+1)th head in 1 extra flip, having observed r heads in n flips? Obviously depending on which is the correct f, the answers vary significantly. Any help would be greatly appreciated! Thanks a lot",,"['statistics', 'bayesian']"
61,Can You Help Me With This Statistics Question on Finding Estimators,Can You Help Me With This Statistics Question on Finding Estimators,,"The Question: The Attempt: I am not sure what they mean by ""random variables"". Am I finding an example, whether it is continuous or not, which satisfies these two inequalities? This question has to do with finding estimators for any types of random variables. Thank you very much!","The Question: The Attempt: I am not sure what they mean by ""random variables"". Am I finding an example, whether it is continuous or not, which satisfies these two inequalities? This question has to do with finding estimators for any types of random variables. Thank you very much!",,['statistics']
62,Is there a name for smoothed maximum value function?,Is there a name for smoothed maximum value function?,,"I have several arrays that look something like this: Spectrum Plot .  Think gaussian curves, but shorter and with lots of noise. I've been comparing values for the sake of peak detection .  Through experimentation, I've modified the comparison to be the average of x number of values around (and including) the maximum value. I'm really sorry I can't figure out the Math Jax thing, but here's a rough translation of my c# code: double[]     trace =      GetSpectrum(); double[]     baseline =   GetAverageOfAllTraces(); List<double> deviations = GetStandardDeviationOfEachTrace();  for (int i = 1; i < baseline.Length; i++)     baseline[i] = (baseline[i] + baseline[i - 1]) / 2) + deviations.Average();  int index = trace.IndexOf(trace.Max()); int x = 2; double maximum = trace.SubArray(index - x, index + x).Average(); if (maximum > baseline[index])     bool validPeak = true; If someone wants to translate, I'd be very grateful. $$ average(maxIndex-2, maxIndex+2) > average(all) + stddev(all) $$ I've started calling this a smoothed maximum , but is there a name for what I'm doing? Additionally, if there's some term for what I'm doing entirely and I'm just reinventing the wheel here, that would also be nice to know.","I have several arrays that look something like this: Spectrum Plot .  Think gaussian curves, but shorter and with lots of noise. I've been comparing values for the sake of peak detection .  Through experimentation, I've modified the comparison to be the average of x number of values around (and including) the maximum value. I'm really sorry I can't figure out the Math Jax thing, but here's a rough translation of my c# code: double[]     trace =      GetSpectrum(); double[]     baseline =   GetAverageOfAllTraces(); List<double> deviations = GetStandardDeviationOfEachTrace();  for (int i = 1; i < baseline.Length; i++)     baseline[i] = (baseline[i] + baseline[i - 1]) / 2) + deviations.Average();  int index = trace.IndexOf(trace.Max()); int x = 2; double maximum = trace.SubArray(index - x, index + x).Average(); if (maximum > baseline[index])     bool validPeak = true; If someone wants to translate, I'd be very grateful. $$ average(maxIndex-2, maxIndex+2) > average(all) + stddev(all) $$ I've started calling this a smoothed maximum , but is there a name for what I'm doing? Additionally, if there's some term for what I'm doing entirely and I'm just reinventing the wheel here, that would also be nice to know.",,"['statistics', 'optimization', 'terminology']"
63,Statistics Hypothesis test on a single sample,Statistics Hypothesis test on a single sample,,"I'm revising for my statistics exam that's coming up but I have a few questions without solutions in the book. I've worked out an answer however I'm not sure if it's correct. This question is: In order for a clothes washer to qualify for ENERGY STAR, it must have a Modified Energy Factor (MEF, a dimensionless quantity) of 1.42 or greater. Thirty-eight Speed Queen commercial washers were selected at random, and the MEF for each was measured. The sample mean was x = 1,228. Assume the distribution of MEF is normal and σ = 0.5. Conduct a hypothesis test to determine whether there is any evidence the mean MEF of this Speed Queen washer is less than 1.42. Use α = 0.01. So my first step was to declare the variables from the question: H0 = μ = 1.42 Ha = μ < 1.42 x̅ = 1.228 σ = 0.5 α = 0.01 Then I put that in the z score formula: z = x̅ - H0 / (σ/sqrt(n)) z = 1.228 - 1.42 / (0.5/sqrt(38)) z = -2.367 Now I can look up the z table for a p value of p = 0.0091 Then I conclude that I reject the null hypothesis because the p value is < than alpha the level of significance; 0.0091 < 0.01. Is this the correct answer/approach?","I'm revising for my statistics exam that's coming up but I have a few questions without solutions in the book. I've worked out an answer however I'm not sure if it's correct. This question is: In order for a clothes washer to qualify for ENERGY STAR, it must have a Modified Energy Factor (MEF, a dimensionless quantity) of 1.42 or greater. Thirty-eight Speed Queen commercial washers were selected at random, and the MEF for each was measured. The sample mean was x = 1,228. Assume the distribution of MEF is normal and σ = 0.5. Conduct a hypothesis test to determine whether there is any evidence the mean MEF of this Speed Queen washer is less than 1.42. Use α = 0.01. So my first step was to declare the variables from the question: H0 = μ = 1.42 Ha = μ < 1.42 x̅ = 1.228 σ = 0.5 α = 0.01 Then I put that in the z score formula: z = x̅ - H0 / (σ/sqrt(n)) z = 1.228 - 1.42 / (0.5/sqrt(38)) z = -2.367 Now I can look up the z table for a p value of p = 0.0091 Then I conclude that I reject the null hypothesis because the p value is < than alpha the level of significance; 0.0091 < 0.01. Is this the correct answer/approach?",,"['statistics', 'hypothesis-testing']"
64,Moment problem for order statistics,Moment problem for order statistics,,"Problem : Let $X_{1},\cdots,X_{n}$ be samples from $X$. If $E\left|X\right|^{a}<\infty$ for some $a>0,$ and $n,k,r$ satisfies $r\leq a\cdot\min\left(k,n-k+1\right),$ then $E\left|X_{\left(k\right)}\right|^{r}<\infty$. Attempted Solution Since $E\left|X\right|^{a}<\infty,$$E\left[X\right]^{r}<\infty$ for any $r\in\left[0,a\right].$ Note that  \begin{align*} +\infty>E\left|X\right|^{a}=\int_{\mathbb{R}}\left|t\right|^{r}dF\geq\int_{x}^{+\infty}\left|t\right|^{r}dF=\int_{\mathbb{R}}\left|t\right|^{r}1_{[x,+\infty)}\left(t\right)dF. \end{align*} Since $\left|t\right|^{r}1_{[x,+\infty)}\left(t\right)\rightarrow0$, it follows from DCT that $\int_{x}^{+\infty}\left|t\right|^{r}dF\rightarrow0.$ On the other hand, we have  \begin{align*} \int_{x}^{\infty}\left|t\right|^{r}dF & \geq\left|x\right|^{r}P\left(X>x\right)\geq0. \end{align*} Take the limit and we get  \begin{align*} 0=\lim_{x\rightarrow\infty}\int_{x}^{+\infty}\left|t\right|^{r}dF\geq\lim_{x}\left|x\right|^{r}P\left(X>x\right)\geq0, \end{align*} which implies  \begin{align*} \lim_{x}\left|x\right|^{r}P\left(X>x\right)=\lim_{x}\left|x\right|^{r}\left(1-F\left(x\right)\right)=0,\ \left|x\right|^{r}\left(1-F\left(x\right)\right)<\infty. \end{align*} Next by integration by parts we have ($G$ is the survival function) \begin{align*} \infty> & \int_{0}^{\infty}x^{a}dF=\int_{0}^{\infty}x^{a}dP\left(X\leq x\right)\\ = & \int_{0}^{\infty}x^{a}d\left[1-P\left(X>x\right)\right]\\ = & -\int_{0}^{\infty}x^{a}dP\left(X>x\right)\\ = & -\left[x^{a}P\left(X>x\right)\right]_{0}^{\infty}+a\int_{0}^{\infty}x^{a-1}P\left(X>x\right)dx\\ = & a\int_{0}^{\infty}x^{a-1}\left[1-F\left(x\right)\right]dx. \end{align*} Hence, we have $a\int_{0}^{+\infty}x^{a-1}\left[1-F\left(x\right)\right]dx<\infty.$ Next, let $G_{k}$ be the distribution function of $X_{\left(k\right)}.$ It is easy to see that  \begin{align*} G_{k}\left(x\right)= & P\left(X_{\left(k\right)}<x\right)=P\left(\left(X_{1},\cdots,X_{n}\right)\mbox{ has at least }k\mbox{ elements }\leq x\right)\\ = & \sum_{i=k}^{n}\binom{n}{i}\left[F\left(x\right)\right]^{i}\left(1-F\left(x\right)\right)^{n-i}. \end{align*} Note that we can write  \begin{align*} E\left|X_{\left(k\right)}\right|^{r}= & \int_{-\infty}^{0}\left|x\right|^{r}dG_{k}+\int_{0}^{+\infty}x^{r}dG_{k}. \end{align*} We talk about the second integral first. Note using similar method as before, we get  \begin{align*} \int_{0}^{+\infty}x^{r}dG_{k}= & -\int_{0}^{\infty}x^{r}dP\left(X_{\left(k\right)}>x\right)\\ = & -\left[x^{r}P\left(X_{\left(k\right)}>x\right)\right]_{0}^{+\infty}+r\int_{0}^{\infty}x^{r-1}P\left(X_{\left(k\right)}>x\right)dx. \end{align*} Since  \begin{align*} x^{r}P\left(X_{\left(k\right)}>x\right)= & x^{r}P\left(\left(X_{1},\cdots,X_{k}\right)\mbox{ has at most }\left(k-1\right)\ \leq x\right)\\ = & x^{r}\left(\sum_{i=0}^{k-1}\binom{n}{i}\left[F\left(x\right)\right]^{i}\left[1-F\left(x\right)\right]^{n-i}\right)\\ = & \sum_{i=1}^{k-1}\binom{n}{i}x^{r}\left[F\left(x\right)\right]^{i}\left[1-F\left(x\right)\right]^{n-i}\\ \leq & \sum_{i=1}^{k-1}\binom{n}{i}x^{r}\left[1-F\left(x\right)\right]\rightarrow0, \end{align*} where the last convergence results follows from previous argument, then it follows that  \begin{align*} \int_{0}^{+\infty}x^{r}dG_{k}= & r\int_{0}^{+\infty}x^{r-1}P\left(X_{\left(k\right)}>x\right)dx\\ = & r\int_{0}^{+\infty}x^{r-1}\left(\sum_{i=0}^{k-1}\binom{n}{i}\left[F\left(x\right)^{i}\right]\left[1-F\left(x\right)\right]^{n-i}\right)dx\\ = & r\sum_{i=0}^{k-1}\binom{n}{i}\int_{0}^{+\infty}\left\{ x^{a}\left[1-F\left(x\right)\right]\right\} ^{\frac{r-a}{a}}\left[1-F\left(x\right)\right]^{n-i-\frac{r}{a}}\left[F\left(x\right)\right]^{i}x^{a-1}\left[1-F\left(x\right)\right]dx.\tag{1} \end{align*} Note that (1)Since $x^{a}\left[1-F\left(x\right)\right]<\infty$ and $\lim_{x}x^{a}\left[1-F\left(x\right)\right]\rightarrow0,$ $\left\{ x^{a}\left[1-F\left(x\right)\right]\right\} ^{\frac{r-a}{a}}\leq M.$ (2) If $n-i-\frac{r}{a}\geq0,$ then $\left[1-F\left(x\right)\right]^{n-i-\frac{r}{a}}$ is bounded by 1. Since $i\in\{0,\cdots,k-1\},$ we have $r\leq a\left(n-i\right),\forall i\iff r\leq a\left(n-k+1\right).$ So if $r\leq a\left(n-k+1\right)$, then  \begin{align*} \left(1\right)\leq & M\int_{0}^{\infty}x^{a-1}\left[1-F\left(x\right)\right]dx<\infty, \end{align*} as desired. Question I am stuck at showing the another part of the integral. Namely, $\int_{-\infty}^0|x|^rdG_k<\infty$ if $r<ak$","Problem : Let $X_{1},\cdots,X_{n}$ be samples from $X$. If $E\left|X\right|^{a}<\infty$ for some $a>0,$ and $n,k,r$ satisfies $r\leq a\cdot\min\left(k,n-k+1\right),$ then $E\left|X_{\left(k\right)}\right|^{r}<\infty$. Attempted Solution Since $E\left|X\right|^{a}<\infty,$$E\left[X\right]^{r}<\infty$ for any $r\in\left[0,a\right].$ Note that  \begin{align*} +\infty>E\left|X\right|^{a}=\int_{\mathbb{R}}\left|t\right|^{r}dF\geq\int_{x}^{+\infty}\left|t\right|^{r}dF=\int_{\mathbb{R}}\left|t\right|^{r}1_{[x,+\infty)}\left(t\right)dF. \end{align*} Since $\left|t\right|^{r}1_{[x,+\infty)}\left(t\right)\rightarrow0$, it follows from DCT that $\int_{x}^{+\infty}\left|t\right|^{r}dF\rightarrow0.$ On the other hand, we have  \begin{align*} \int_{x}^{\infty}\left|t\right|^{r}dF & \geq\left|x\right|^{r}P\left(X>x\right)\geq0. \end{align*} Take the limit and we get  \begin{align*} 0=\lim_{x\rightarrow\infty}\int_{x}^{+\infty}\left|t\right|^{r}dF\geq\lim_{x}\left|x\right|^{r}P\left(X>x\right)\geq0, \end{align*} which implies  \begin{align*} \lim_{x}\left|x\right|^{r}P\left(X>x\right)=\lim_{x}\left|x\right|^{r}\left(1-F\left(x\right)\right)=0,\ \left|x\right|^{r}\left(1-F\left(x\right)\right)<\infty. \end{align*} Next by integration by parts we have ($G$ is the survival function) \begin{align*} \infty> & \int_{0}^{\infty}x^{a}dF=\int_{0}^{\infty}x^{a}dP\left(X\leq x\right)\\ = & \int_{0}^{\infty}x^{a}d\left[1-P\left(X>x\right)\right]\\ = & -\int_{0}^{\infty}x^{a}dP\left(X>x\right)\\ = & -\left[x^{a}P\left(X>x\right)\right]_{0}^{\infty}+a\int_{0}^{\infty}x^{a-1}P\left(X>x\right)dx\\ = & a\int_{0}^{\infty}x^{a-1}\left[1-F\left(x\right)\right]dx. \end{align*} Hence, we have $a\int_{0}^{+\infty}x^{a-1}\left[1-F\left(x\right)\right]dx<\infty.$ Next, let $G_{k}$ be the distribution function of $X_{\left(k\right)}.$ It is easy to see that  \begin{align*} G_{k}\left(x\right)= & P\left(X_{\left(k\right)}<x\right)=P\left(\left(X_{1},\cdots,X_{n}\right)\mbox{ has at least }k\mbox{ elements }\leq x\right)\\ = & \sum_{i=k}^{n}\binom{n}{i}\left[F\left(x\right)\right]^{i}\left(1-F\left(x\right)\right)^{n-i}. \end{align*} Note that we can write  \begin{align*} E\left|X_{\left(k\right)}\right|^{r}= & \int_{-\infty}^{0}\left|x\right|^{r}dG_{k}+\int_{0}^{+\infty}x^{r}dG_{k}. \end{align*} We talk about the second integral first. Note using similar method as before, we get  \begin{align*} \int_{0}^{+\infty}x^{r}dG_{k}= & -\int_{0}^{\infty}x^{r}dP\left(X_{\left(k\right)}>x\right)\\ = & -\left[x^{r}P\left(X_{\left(k\right)}>x\right)\right]_{0}^{+\infty}+r\int_{0}^{\infty}x^{r-1}P\left(X_{\left(k\right)}>x\right)dx. \end{align*} Since  \begin{align*} x^{r}P\left(X_{\left(k\right)}>x\right)= & x^{r}P\left(\left(X_{1},\cdots,X_{k}\right)\mbox{ has at most }\left(k-1\right)\ \leq x\right)\\ = & x^{r}\left(\sum_{i=0}^{k-1}\binom{n}{i}\left[F\left(x\right)\right]^{i}\left[1-F\left(x\right)\right]^{n-i}\right)\\ = & \sum_{i=1}^{k-1}\binom{n}{i}x^{r}\left[F\left(x\right)\right]^{i}\left[1-F\left(x\right)\right]^{n-i}\\ \leq & \sum_{i=1}^{k-1}\binom{n}{i}x^{r}\left[1-F\left(x\right)\right]\rightarrow0, \end{align*} where the last convergence results follows from previous argument, then it follows that  \begin{align*} \int_{0}^{+\infty}x^{r}dG_{k}= & r\int_{0}^{+\infty}x^{r-1}P\left(X_{\left(k\right)}>x\right)dx\\ = & r\int_{0}^{+\infty}x^{r-1}\left(\sum_{i=0}^{k-1}\binom{n}{i}\left[F\left(x\right)^{i}\right]\left[1-F\left(x\right)\right]^{n-i}\right)dx\\ = & r\sum_{i=0}^{k-1}\binom{n}{i}\int_{0}^{+\infty}\left\{ x^{a}\left[1-F\left(x\right)\right]\right\} ^{\frac{r-a}{a}}\left[1-F\left(x\right)\right]^{n-i-\frac{r}{a}}\left[F\left(x\right)\right]^{i}x^{a-1}\left[1-F\left(x\right)\right]dx.\tag{1} \end{align*} Note that (1)Since $x^{a}\left[1-F\left(x\right)\right]<\infty$ and $\lim_{x}x^{a}\left[1-F\left(x\right)\right]\rightarrow0,$ $\left\{ x^{a}\left[1-F\left(x\right)\right]\right\} ^{\frac{r-a}{a}}\leq M.$ (2) If $n-i-\frac{r}{a}\geq0,$ then $\left[1-F\left(x\right)\right]^{n-i-\frac{r}{a}}$ is bounded by 1. Since $i\in\{0,\cdots,k-1\},$ we have $r\leq a\left(n-i\right),\forall i\iff r\leq a\left(n-k+1\right).$ So if $r\leq a\left(n-k+1\right)$, then  \begin{align*} \left(1\right)\leq & M\int_{0}^{\infty}x^{a-1}\left[1-F\left(x\right)\right]dx<\infty, \end{align*} as desired. Question I am stuck at showing the another part of the integral. Namely, $\int_{-\infty}^0|x|^rdG_k<\infty$ if $r<ak$",,"['real-analysis', 'probability', 'statistics', 'lebesgue-integral']"
65,Generating continuous random variables from a set of Bernoullis,Generating continuous random variables from a set of Bernoullis,,"Given a set of $Bernoulli(p_i)$ variables with each having its own arbitrary $p_i$, is there an efficient way to generate continuous random variables sampled from an arbitrary distriubution?  To further specify, continuous in this context would refer to discrete N-bit numbers.  For example generating a 32-bit integer from the Normal distribution. The naive way seems to be generating a uniform() distribution using Bernoulli(.5), then using standard rv algorithms such as the Box-Muller transform.  However this seems rather bloated considering only a single probability ($p_i = .5$) is used. I was considering a solution in which each Bernoulli represents a bit of the number and $p_i = 1-CDF(x)$ where x is the bit's order of significance.  This would require calculating N expensive CDF functions though. Is there a better way to manipulate $p_i$ to generate samples more efficiently?","Given a set of $Bernoulli(p_i)$ variables with each having its own arbitrary $p_i$, is there an efficient way to generate continuous random variables sampled from an arbitrary distriubution?  To further specify, continuous in this context would refer to discrete N-bit numbers.  For example generating a 32-bit integer from the Normal distribution. The naive way seems to be generating a uniform() distribution using Bernoulli(.5), then using standard rv algorithms such as the Box-Muller transform.  However this seems rather bloated considering only a single probability ($p_i = .5$) is used. I was considering a solution in which each Bernoulli represents a bit of the number and $p_i = 1-CDF(x)$ where x is the bit's order of significance.  This would require calculating N expensive CDF functions though. Is there a better way to manipulate $p_i$ to generate samples more efficiently?",,"['probability', 'probability-theory', 'statistics', 'sampling']"
66,Probability and Statistics books for a prospective econometrician,Probability and Statistics books for a prospective econometrician,,"I've recently got accepted into a PhD Program in Economics and I'm looking for textbooks that can help me in my preparation.  I need a book (or books) that fit my needs and that take into account my background. Needs: -Mathematical rigor -Introductory -Suited to an Economics student -I'm especially interested in Econometrics, so I would not want a book which focus heavily on topics studied by Statisticians and not by Econometricians. Background: -I've taken one course on Real Analysis and some introductory lectures on Measure Theory. Topics: Probability: multivariate random variables, expectation, conditional expectation, limit theorems. Statistics: Estimation, properties of estimators, hypothesis testing, sample distributions, Asymptotic Theory Thanks!","I've recently got accepted into a PhD Program in Economics and I'm looking for textbooks that can help me in my preparation.  I need a book (or books) that fit my needs and that take into account my background. Needs: -Mathematical rigor -Introductory -Suited to an Economics student -I'm especially interested in Econometrics, so I would not want a book which focus heavily on topics studied by Statisticians and not by Econometricians. Background: -I've taken one course on Real Analysis and some introductory lectures on Measure Theory. Topics: Probability: multivariate random variables, expectation, conditional expectation, limit theorems. Statistics: Estimation, properties of estimators, hypothesis testing, sample distributions, Asymptotic Theory Thanks!",,"['probability', 'statistics', 'reference-request']"
67,How to solve an integratation involved an unknown function?,How to solve an integratation involved an unknown function?,,"Can anyone have any suggestions how to solve this equation for $w_i$, that is, what is the solution of $w_i$? $$ \int_0^\infty e^{\Phi^{-1}(w_i)ε_i}P(r_i│ε_i )f(ε_i )dε_i=δ $$ Where, $f(ε_i)$ is the probability density function of $ε_i$, $ε_i$ can be exponential random variable, $\Phi^{-1}(w_i)$ is the inverse of the normal CDF, $P(r_i│ε_i )$ is an unknown function, and all the remaining parameters are constant. I know it may not be possible to have an exact solution. However, there might have some approximation or clever trick, or possibility to get upper and lower limit of $w_i$. Thank you I appreciate your help :) Or, can we write the above equation as $$ \int_0^\infty e^{\Phi^{-1}(w_i)ε_i}P(r_i│ε_i )f(ε_i )dε_i=δ\int_0^\infty f(ε_i )dε_i $$ and hence by cancelling out the integrations from the both sides $$ e^{\Phi^{-1}(w_i)ε_i}P(r_i│ε_i )=δ $$  because $\int_0^\infty f(ε_i )dε_i=1$","Can anyone have any suggestions how to solve this equation for $w_i$, that is, what is the solution of $w_i$? $$ \int_0^\infty e^{\Phi^{-1}(w_i)ε_i}P(r_i│ε_i )f(ε_i )dε_i=δ $$ Where, $f(ε_i)$ is the probability density function of $ε_i$, $ε_i$ can be exponential random variable, $\Phi^{-1}(w_i)$ is the inverse of the normal CDF, $P(r_i│ε_i )$ is an unknown function, and all the remaining parameters are constant. I know it may not be possible to have an exact solution. However, there might have some approximation or clever trick, or possibility to get upper and lower limit of $w_i$. Thank you I appreciate your help :) Or, can we write the above equation as $$ \int_0^\infty e^{\Phi^{-1}(w_i)ε_i}P(r_i│ε_i )f(ε_i )dε_i=δ\int_0^\infty f(ε_i )dε_i $$ and hence by cancelling out the integrations from the both sides $$ e^{\Phi^{-1}(w_i)ε_i}P(r_i│ε_i )=δ $$  because $\int_0^\infty f(ε_i )dε_i=1$",,"['calculus', 'statistics', 'discrete-mathematics', 'statistical-inference']"
68,Parameter estimation - Holt's Two parameter Linear Exponential Smoothing,Parameter estimation - Holt's Two parameter Linear Exponential Smoothing,,"The reference for the below equations can be found in the Link . Note that $k$ is the timestamp and $i$ is the $i^{th}$ entry of a vector or $(i,i)^{th}$ entry of a matrix, $F$ in this case Equation 1 \begin{equation} \tilde{x}_{i}(k+1) = a_{i}(k) + b_{i}(k) \end{equation} where \begin{equation} \begin{aligned}  a_{i}(k) &= \alpha_{i}x_{i}(k) + (1-\alpha_{i})\tilde{x}_{i}(k) \\ b_{i}(k) &= \beta[a_{i}(k) - a_{i}(k-1)] + (1-\beta_{i})b_{i}(k-1) \\ \end{aligned} \end{equation} Equation 1 can also be written using the dynamic model as \begin{equation}  \begin{aligned} \tilde{x}_{i}(k+1) &= F_{i}(k)x_{i}(k)  + G_{i}(k)  \end{aligned} \end{equation} From the above equations we have \begin{equation} \begin{aligned} F_{i}(k) &= \alpha_{i}(1+\beta_{i}) \\   G_{i}(k) &= (1+\beta_{i})(1-\alpha_{i})\tilde{x}_{i}(k) - \beta_{i}a_{i}(k-1)+(1-\beta_{i})b_{i}(k-1) \end{aligned} \end{equation} I've the data, .i.e the x(k) which is time series data (k = 1,2,$\dots$,n) and I want to estimate the values of $\alpha$ and $\beta$. In my case the values of $\alpha$ and $\beta$ are assumed to be constant throughout the interval $n$. I looked online but couldn't find any suitable reference.  Please help.","The reference for the below equations can be found in the Link . Note that $k$ is the timestamp and $i$ is the $i^{th}$ entry of a vector or $(i,i)^{th}$ entry of a matrix, $F$ in this case Equation 1 \begin{equation} \tilde{x}_{i}(k+1) = a_{i}(k) + b_{i}(k) \end{equation} where \begin{equation} \begin{aligned}  a_{i}(k) &= \alpha_{i}x_{i}(k) + (1-\alpha_{i})\tilde{x}_{i}(k) \\ b_{i}(k) &= \beta[a_{i}(k) - a_{i}(k-1)] + (1-\beta_{i})b_{i}(k-1) \\ \end{aligned} \end{equation} Equation 1 can also be written using the dynamic model as \begin{equation}  \begin{aligned} \tilde{x}_{i}(k+1) &= F_{i}(k)x_{i}(k)  + G_{i}(k)  \end{aligned} \end{equation} From the above equations we have \begin{equation} \begin{aligned} F_{i}(k) &= \alpha_{i}(1+\beta_{i}) \\   G_{i}(k) &= (1+\beta_{i})(1-\alpha_{i})\tilde{x}_{i}(k) - \beta_{i}a_{i}(k-1)+(1-\beta_{i})b_{i}(k-1) \end{aligned} \end{equation} I've the data, .i.e the x(k) which is time series data (k = 1,2,$\dots$,n) and I want to estimate the values of $\alpha$ and $\beta$. In my case the values of $\alpha$ and $\beta$ are assumed to be constant throughout the interval $n$. I looked online but couldn't find any suitable reference.  Please help.",,"['statistics', 'dynamical-systems', 'estimation']"
69,ML estimator of generalized least squares,ML estimator of generalized least squares,,"I'm hung up on the following question, which I know how to do (part of) in concept, but the actual technique fails me. Show that the maximum likelihood of $\beta$ is $$ {\bf b}_{\mathrm GLS} = \left(\bf X^\top \Sigma_{\epsilon\epsilon}^{-1}X\right)^{-1} {\bf X^\top \Sigma_{\epsilon\epsilon}^{-1} y} $$ and that its sampling variance is $$ V({\bf b}_{\mathrm GLS}) = \left( {\bf X^\top \Sigma_{\epsilon\epsilon}^{-1} X}\right)^{-1} $$ I know that to solve the first part, I need to find the zero of the partial derivative with respect to $\beta$ of the generalized sum of squares, $\left( {\bf y^\top - X \beta)^\top \Sigma_{\epsilon\epsilon}^{-1} (y - X \beta} \right)$. The problem is, I'm not sure how to do this. It would be generous to say I have very little experience with matrix calculus. I know how to differentiate with respect to the flanking (?) elements of a quadratic form in y, but this is of little help here because I need only to differentiate with respect to $\beta$, and those flanking terms are the entire error. This would be $\frac{\partial {\mathrm GLS}}{\partial {\bf y - X \beta}} =  2 \Sigma_{\epsilon\epsilon}^{-1}\left( {\bf y - X \beta} \right))$ (I think). This appears to be pretty useless.  Rewriting GLS as  ${\bf y^\top \Sigma_{\epsilon\epsilon}^{-1} y -  (X\beta)^\top \Sigma_{\epsilon\epsilon}^{-1} (X\beta)}$ may be of some help; I'm not sure. As for the second part, I'm pretty dead in the water. This is one of those ""it is simple to show..."" type situations.","I'm hung up on the following question, which I know how to do (part of) in concept, but the actual technique fails me. Show that the maximum likelihood of $\beta$ is $$ {\bf b}_{\mathrm GLS} = \left(\bf X^\top \Sigma_{\epsilon\epsilon}^{-1}X\right)^{-1} {\bf X^\top \Sigma_{\epsilon\epsilon}^{-1} y} $$ and that its sampling variance is $$ V({\bf b}_{\mathrm GLS}) = \left( {\bf X^\top \Sigma_{\epsilon\epsilon}^{-1} X}\right)^{-1} $$ I know that to solve the first part, I need to find the zero of the partial derivative with respect to $\beta$ of the generalized sum of squares, $\left( {\bf y^\top - X \beta)^\top \Sigma_{\epsilon\epsilon}^{-1} (y - X \beta} \right)$. The problem is, I'm not sure how to do this. It would be generous to say I have very little experience with matrix calculus. I know how to differentiate with respect to the flanking (?) elements of a quadratic form in y, but this is of little help here because I need only to differentiate with respect to $\beta$, and those flanking terms are the entire error. This would be $\frac{\partial {\mathrm GLS}}{\partial {\bf y - X \beta}} =  2 \Sigma_{\epsilon\epsilon}^{-1}\left( {\bf y - X \beta} \right))$ (I think). This appears to be pretty useless.  Rewriting GLS as  ${\bf y^\top \Sigma_{\epsilon\epsilon}^{-1} y -  (X\beta)^\top \Sigma_{\epsilon\epsilon}^{-1} (X\beta)}$ may be of some help; I'm not sure. As for the second part, I'm pretty dead in the water. This is one of those ""it is simple to show..."" type situations.",,"['statistics', 'matrix-calculus', 'time-series']"
70,Multivariate distribution with the same kurtosis as normal distribution,Multivariate distribution with the same kurtosis as normal distribution,,"Good morning. I am writing a thesis about testing multivariate normality. I would like to do a comparison of power of some tests against given alternatives based on Monte Carlo simulations. I have a following problem: Some multivariate normality tests are based on multivariate skewness $\beta_{1,k}$ and multivariate kurtosis $\beta_{2,k}$ defined by Mardia this way: \begin{equation*} \beta_{1,k}(\mathbf{X}) := E [ \left\{ (\mathbf{X} - \boldsymbol \mu)^{T} \boldsymbol \Sigma^{-1} (\mathbf{Y} - \boldsymbol \mu) \right\}^{3} ],  \end{equation*} \begin{equation*} \beta_{2,k}(\mathbf{X}) := E [ \left\{ (\mathbf{X} - \boldsymbol \mu)^{T} \boldsymbol \Sigma^{-1} (\mathbf{X} - \boldsymbol \mu) \right\}^{2} ] \end{equation*} for iid. random vectors $\mathbf{X}$ and $\mathbf{Y}$. It is widely known that for $k$-dimensional normal distribution holds $\beta_{1,k} = 0$ and $\beta_{2,k} = k(k + 2)$. There are some studies that compare power of normality test against alternatives with $\beta_{1,k} = 0$ but $\beta_{2,k} \neq k(k + 2)$ (such as Students $t$ distribution). I would like to do it in the opposite direction and compare power of my normality tests against alternative with $\beta_{1,k} \neq 0$ but $\beta_{2,k} = k(k + 2)$. My problem is that I am unable to find such a distribution. Could anybody tell me, how to generate sample from multivariate distribution with $\beta_{1,k} \neq 0$ but $\beta_{2,k} = k(k + 2)$ in $R$ programme? I will be grateful for all useful ideas. I tried to solve my problem by using bivariate Skew-Normal Distribution from package $sn$ but it is probably not possible for this distribution (with parametrization from $sn$ package) to have $\beta_{1,k} \neq 0$ but $\beta_{2,k} = k(k + 2)$. Thank You!","Good morning. I am writing a thesis about testing multivariate normality. I would like to do a comparison of power of some tests against given alternatives based on Monte Carlo simulations. I have a following problem: Some multivariate normality tests are based on multivariate skewness $\beta_{1,k}$ and multivariate kurtosis $\beta_{2,k}$ defined by Mardia this way: \begin{equation*} \beta_{1,k}(\mathbf{X}) := E [ \left\{ (\mathbf{X} - \boldsymbol \mu)^{T} \boldsymbol \Sigma^{-1} (\mathbf{Y} - \boldsymbol \mu) \right\}^{3} ],  \end{equation*} \begin{equation*} \beta_{2,k}(\mathbf{X}) := E [ \left\{ (\mathbf{X} - \boldsymbol \mu)^{T} \boldsymbol \Sigma^{-1} (\mathbf{X} - \boldsymbol \mu) \right\}^{2} ] \end{equation*} for iid. random vectors $\mathbf{X}$ and $\mathbf{Y}$. It is widely known that for $k$-dimensional normal distribution holds $\beta_{1,k} = 0$ and $\beta_{2,k} = k(k + 2)$. There are some studies that compare power of normality test against alternatives with $\beta_{1,k} = 0$ but $\beta_{2,k} \neq k(k + 2)$ (such as Students $t$ distribution). I would like to do it in the opposite direction and compare power of my normality tests against alternative with $\beta_{1,k} \neq 0$ but $\beta_{2,k} = k(k + 2)$. My problem is that I am unable to find such a distribution. Could anybody tell me, how to generate sample from multivariate distribution with $\beta_{1,k} \neq 0$ but $\beta_{2,k} = k(k + 2)$ in $R$ programme? I will be grateful for all useful ideas. I tried to solve my problem by using bivariate Skew-Normal Distribution from package $sn$ but it is probably not possible for this distribution (with parametrization from $sn$ package) to have $\beta_{1,k} \neq 0$ but $\beta_{2,k} = k(k + 2)$. Thank You!",,"['probability', 'statistics', 'random-variables', 'normal-distribution']"
71,Why is $\mathrm E( x_i)= \mu$ where $\mu$ is the mean of the population when sampling is done without replacement?,Why is  where  is the mean of the population when sampling is done without replacement?,\mathrm E( x_i)= \mu \mu,"$\bullet$ Prove: $\mathrm E(\bar x)= \mu$ Answer: Let $x_1,x_2,x_3\ldots,x_n$ denote the sample observations. The sample mean is $$\bar x= \frac{(x_1+x_2+x_3+\ldots+x_n)}{n}= \frac{1}{n}\sum x_i$$ where $x_i$ is the $i$ -th member of of the sample. Note, in simple random sampling(with or without replacement), the sample members has the same probability distribution as in the variable $x$ in the population . Therefore, $\mathrm E( x_i)= \mu$ And $$\mathrm E(\bar x)= \frac{1}{n}[\mathrm E(x_1)+ \mathrm E(x_2)+\ldots+\mathrm E(x_n)]= \mu.$$ What I'm not getting is the blocked part that the author wanted to highlight. Can anyone tell me why actually $x_i$ has the same probability distribution as $x$ in the population especially even when the random sampling is done without replacement ? For $x_i$ and $x_j$ are not independent any-more when the sampling is done without replacement; so can then also the probability distribution of $x_i$ and $x_j$ remain the same as that of $x$ in the population? How can $\mathrm E(x_i)= \mu$ when the sampling is done without replacement? Can anyone please explain that?","Prove: Answer: Let denote the sample observations. The sample mean is where is the -th member of of the sample. Note, in simple random sampling(with or without replacement), the sample members has the same probability distribution as in the variable in the population . Therefore, And What I'm not getting is the blocked part that the author wanted to highlight. Can anyone tell me why actually has the same probability distribution as in the population especially even when the random sampling is done without replacement ? For and are not independent any-more when the sampling is done without replacement; so can then also the probability distribution of and remain the same as that of in the population? How can when the sampling is done without replacement? Can anyone please explain that?","\bullet \mathrm E(\bar x)= \mu x_1,x_2,x_3\ldots,x_n \bar x= \frac{(x_1+x_2+x_3+\ldots+x_n)}{n}= \frac{1}{n}\sum x_i x_i i x \mathrm E( x_i)= \mu \mathrm E(\bar x)= \frac{1}{n}[\mathrm E(x_1)+ \mathrm E(x_2)+\ldots+\mathrm E(x_n)]= \mu. x_i x x_i x_j x_i x_j x \mathrm E(x_i)= \mu",['statistics']
72,How to statistically beat this dice game?,How to statistically beat this dice game?,,"There is a dice game on this site where you can bet a video game's currency in games. I was wondering if any of the more statistically minded could come up with a way of beating the system? The game's rules are as follows: The player may bet a certain amount of chips on rolling above or below a    certain number on a 10,000 sided die, whereby the odds are the same, eg 45% chance of winning, above 55.00 or below 45.00. The player must make a MINIMUM bet of 2500. The player can set their own multiplier and odds. The relation is such that at a 2x multiplier of the bet, the chances of winning are 45% and at 5x it is 18% The maximum bet is such that the multipier*bet is equal to 1 billion. The player is every half hour given 100,000 chips to bet. Here is my strategy that I have been using: Roll the 100,000 chips to 1 million. Using a 5x multiplier, roll until lose 12 rolls on the lowest bet possible, then bet .2% of the cash stack, doing so two times if the first lost, then doubling the previous bet and so on until profit is made. The reason I bet double every two is that, because the odds of getting 13 losses is 0.82^13, eventually a win should turn out and the risk of loss only lowers. I have made it up to 3 billion chips, then lost them all when I got up to 200 million chip bets, which was max and kept on losing them. Assuming the system is not rigged, how would you go about beating this game consistently?","There is a dice game on this site where you can bet a video game's currency in games. I was wondering if any of the more statistically minded could come up with a way of beating the system? The game's rules are as follows: The player may bet a certain amount of chips on rolling above or below a    certain number on a 10,000 sided die, whereby the odds are the same, eg 45% chance of winning, above 55.00 or below 45.00. The player must make a MINIMUM bet of 2500. The player can set their own multiplier and odds. The relation is such that at a 2x multiplier of the bet, the chances of winning are 45% and at 5x it is 18% The maximum bet is such that the multipier*bet is equal to 1 billion. The player is every half hour given 100,000 chips to bet. Here is my strategy that I have been using: Roll the 100,000 chips to 1 million. Using a 5x multiplier, roll until lose 12 rolls on the lowest bet possible, then bet .2% of the cash stack, doing so two times if the first lost, then doubling the previous bet and so on until profit is made. The reason I bet double every two is that, because the odds of getting 13 losses is 0.82^13, eventually a win should turn out and the risk of loss only lowers. I have made it up to 3 billion chips, then lost them all when I got up to 200 million chip bets, which was max and kept on losing them. Assuming the system is not rigged, how would you go about beating this game consistently?",,"['probability', 'statistics', 'dice', 'gambling']"
73,Applying Markov's Inequality and Chebyshev to bound a r.v.,Applying Markov's Inequality and Chebyshev to bound a r.v.,,"Hi there, it's all nice and simple to work out the expectation of $X$ (which is $\mathbb{E}[X]=9$), of $X^2$ (which is $\mathbb{E}[X^2]=91$), and $\operatorname{Var}(X) = 10$. So we can apply Markov to the probability of X>50. However, if I try to apply Markov to the probability of $X^2>50$, I get a value that is greater than 1. Does this mean Markov cannot bound this r.v.? How do I apply Chebyshev to this, do I just take away the mean from $X^2$ and proceed like that? Thank you for any help!","Hi there, it's all nice and simple to work out the expectation of $X$ (which is $\mathbb{E}[X]=9$), of $X^2$ (which is $\mathbb{E}[X^2]=91$), and $\operatorname{Var}(X) = 10$. So we can apply Markov to the probability of X>50. However, if I try to apply Markov to the probability of $X^2>50$, I get a value that is greater than 1. Does this mean Markov cannot bound this r.v.? How do I apply Chebyshev to this, do I just take away the mean from $X^2$ and proceed like that? Thank you for any help!",,"['probability', 'statistics']"
74,How many ways can N objects be split into groups of 3?,How many ways can N objects be split into groups of 3?,,"I've found that if there are $N$ objects split up into two groups of $n_1$, and $n_2=N-n_1$ then this can be divided into $$\frac{N!}{n_1!(N-n_1)!}$$ groups. How can I extend this onto splitting $N$ objects split into three groups of $n_1, n_2, n_3$ if we assume that the objects are distinguishable, where $n_2=N-n_1$ and $n_3=N-n_1-n_2$?","I've found that if there are $N$ objects split up into two groups of $n_1$, and $n_2=N-n_1$ then this can be divided into $$\frac{N!}{n_1!(N-n_1)!}$$ groups. How can I extend this onto splitting $N$ objects split into three groups of $n_1, n_2, n_3$ if we assume that the objects are distinguishable, where $n_2=N-n_1$ and $n_3=N-n_1-n_2$?",,"['statistics', 'set-partition']"
75,Central limit theorem for distribution peak rather than mean,Central limit theorem for distribution peak rather than mean,,"The central limit theorem states that the arithmetic mean of a sufficiently large number of iterates of independent random variables, each with a well-defined expected value and well-defined variance, will be approximately normally distributed. i.e. $$ \lim_{n \to \infty}    \sqrt{n}\left(\frac{1}{n}\sum_i X_i - \mu\right)    = \mathcal{N}(0,\sigma^2). $$ My question is whether a similar result exists which allows for some combinations of samples to tend towards a normal distribution centred about the peak (i.e. mode) of the distribution of the $X_i$, this obviously corresponds to the mean for normal distributions but I am interested in non-symmetric distributions where this is not the case. So I am asking if there exists some function $H$ s.t. $$ \lim_{n \to \infty} \alpha(H(X_1,...,X_n) - \phi) = \mathcal{N}(0,\sigma^2), $$ where $\alpha$ is some number which might depend on $n$ and $\phi$ is the mode of the distribution from which the $X_i$ are drawn.","The central limit theorem states that the arithmetic mean of a sufficiently large number of iterates of independent random variables, each with a well-defined expected value and well-defined variance, will be approximately normally distributed. i.e. $$ \lim_{n \to \infty}    \sqrt{n}\left(\frac{1}{n}\sum_i X_i - \mu\right)    = \mathcal{N}(0,\sigma^2). $$ My question is whether a similar result exists which allows for some combinations of samples to tend towards a normal distribution centred about the peak (i.e. mode) of the distribution of the $X_i$, this obviously corresponds to the mean for normal distributions but I am interested in non-symmetric distributions where this is not the case. So I am asking if there exists some function $H$ s.t. $$ \lim_{n \to \infty} \alpha(H(X_1,...,X_n) - \phi) = \mathcal{N}(0,\sigma^2), $$ where $\alpha$ is some number which might depend on $n$ and $\phi$ is the mode of the distribution from which the $X_i$ are drawn.",,"['probability', 'statistics', 'central-limit-theorem']"
76,How do we take this expectation?,How do we take this expectation?,,"Suppose $X \sim \mathcal{N}\left(\mu, \Sigma\right)$ and $A$ is a symmetric matrix. How do I evaluate the following expectation: $$\mathbb{E}\left[e^{X'A'X}\right] $$?","Suppose $X \sim \mathcal{N}\left(\mu, \Sigma\right)$ and $A$ is a symmetric matrix. How do I evaluate the following expectation: $$\mathbb{E}\left[e^{X'A'X}\right] $$?",,"['probability', 'integration', 'statistics', 'multivariable-calculus', 'expectation']"
77,To what extent can the measures of the properties of data sets restrict the possibility of what they can be?,To what extent can the measures of the properties of data sets restrict the possibility of what they can be?,,"Despite the trivial cases, such as 1,1 and 1,1,1, can there be two different sets of data that have the same central tendency and dispersion?","Despite the trivial cases, such as 1,1 and 1,1,1, can there be two different sets of data that have the same central tendency and dispersion?",,[]
78,Basic MVUE Application,Basic MVUE Application,,"I am having some trouble with the following problem: Let $X = (X_{1}, . . . , X_{n})$ a random sample from $f_{\theta}$, where $\theta \in \Theta$. Suppose that $W$ is the MVUE for $\theta$. Let $Z$ be an unbiased estimator for the single point $0$; that is, for some function $u$ that does not depend on $\theta$, we have $Z = u(X)$ and $\mathbb{E} \theta Z = 0$ for all $\theta$. Show that $Cov_{\theta} (W,Z) = 0$. I know that this problem is related to completeness but I am not sure what do I need to do in order to prove it. Do I need to apply the Lehmann-Scheffe Theorem? Thanks for any help!","I am having some trouble with the following problem: Let $X = (X_{1}, . . . , X_{n})$ a random sample from $f_{\theta}$, where $\theta \in \Theta$. Suppose that $W$ is the MVUE for $\theta$. Let $Z$ be an unbiased estimator for the single point $0$; that is, for some function $u$ that does not depend on $\theta$, we have $Z = u(X)$ and $\mathbb{E} \theta Z = 0$ for all $\theta$. Show that $Cov_{\theta} (W,Z) = 0$. I know that this problem is related to completeness but I am not sure what do I need to do in order to prove it. Do I need to apply the Lehmann-Scheffe Theorem? Thanks for any help!",,"['probability-theory', 'statistics', 'covariance']"
79,Marginals/conditionals of a normalized Gaussian vector,Marginals/conditionals of a normalized Gaussian vector,,"It is well - known that if $x=(x_1,...,x_n)^T\sim{N(0, \sigma^2I)}$, then its normalized version is uniformly distributed on the unit $n-1$ - sphere: $$ y:=\frac{x}{||x||_2}\sim{\text{Uniform}}(S_{n-1}(1)). $$ From this it is easy to derive both the conditional and marginal distributions of $y$ as well. Now, the case that I'm interested in is the non-spherical case: $x\sim{N(0, D)}$, where $D$ can assumed to be diagonal. In this case it is again easy to derive by integration that $$ p_{\frac{x}{||x||_2}}(t)=|D|^{-1/2}(t^TD^{-1}t)^{-n/2} $$ with respect to the uniform measure on a unit $n-1$-sphere. However, I struggle with deriving marginal ($y_1$) and/or conditional ($(y_2,...,y_n)|y_1$) distributions of this vector since I quickly run into complicated integrals in spherical coordinates. I would highly appreciate any leads and/or even any available bounds/series expansions/approximations of these distributions. Thank you!","It is well - known that if $x=(x_1,...,x_n)^T\sim{N(0, \sigma^2I)}$, then its normalized version is uniformly distributed on the unit $n-1$ - sphere: $$ y:=\frac{x}{||x||_2}\sim{\text{Uniform}}(S_{n-1}(1)). $$ From this it is easy to derive both the conditional and marginal distributions of $y$ as well. Now, the case that I'm interested in is the non-spherical case: $x\sim{N(0, D)}$, where $D$ can assumed to be diagonal. In this case it is again easy to derive by integration that $$ p_{\frac{x}{||x||_2}}(t)=|D|^{-1/2}(t^TD^{-1}t)^{-n/2} $$ with respect to the uniform measure on a unit $n-1$-sphere. However, I struggle with deriving marginal ($y_1$) and/or conditional ($(y_2,...,y_n)|y_1$) distributions of this vector since I quickly run into complicated integrals in spherical coordinates. I would highly appreciate any leads and/or even any available bounds/series expansions/approximations of these distributions. Thank you!",,"['probability', 'statistics', 'probability-distributions', 'spherical-coordinates']"
80,one-step-ahead forecast in out-of-sample estimation,one-step-ahead forecast in out-of-sample estimation,,"Suppose I have a sample of $n+m$ observations of $\{x_i,y_i\}$ and i use the first $n$ observations to estimate the parameters in my model and save the last $m$ observations for forecasting. Let $\hat{f}_{n+h} $ be the one-step-ahead forecast of $y_{n+h+1}$ for $h=0,1,..m-1$. How do i estimate  $y_{n+h+2}$ ? Do I use the $n+1$ observations of both $x$ and $y$ to estimate $\hat{f}_{n+h+1} $ or use $n+1$ observations from $x$ and $n$ from $y$ and $\hat{f}_{n+h} $  to estimate $\hat{f}_{n+h+1} $? Thanks","Suppose I have a sample of $n+m$ observations of $\{x_i,y_i\}$ and i use the first $n$ observations to estimate the parameters in my model and save the last $m$ observations for forecasting. Let $\hat{f}_{n+h} $ be the one-step-ahead forecast of $y_{n+h+1}$ for $h=0,1,..m-1$. How do i estimate  $y_{n+h+2}$ ? Do I use the $n+1$ observations of both $x$ and $y$ to estimate $\hat{f}_{n+h+1} $ or use $n+1$ observations from $x$ and $n$ from $y$ and $\hat{f}_{n+h} $  to estimate $\hat{f}_{n+h+1} $? Thanks",,"['statistics', 'time-series']"
81,expectation of product of two independent normal random variables,expectation of product of two independent normal random variables,,"Say I have two normal independent random variables with nonzero means - X distributed as N(a,b) and Y as N(c,d). What is the mean of the product XY? I see that the distribution has been computed ( Is the product of two Gaussian random variables also a Gaussian? ) as a bessel function in an earlier question if it is 0 mean- but if the mean is not zero, is there a simple expression for E[XY] ?","Say I have two normal independent random variables with nonzero means - X distributed as N(a,b) and Y as N(c,d). What is the mean of the product XY? I see that the distribution has been computed ( Is the product of two Gaussian random variables also a Gaussian? ) as a bessel function in an earlier question if it is 0 mean- but if the mean is not zero, is there a simple expression for E[XY] ?",,"['probability', 'statistics', 'normal-distribution']"
82,PDF of sum of independent exponential r.v.s of different parameter values,PDF of sum of independent exponential r.v.s of different parameter values,,"If we have N independent exponential random variables of different parameter values: $x_1$ ~ exp($m_1$), $x_2$ ~ exp($m_2$), ..., $x_N$ ~ exp($m_N$) Is there a closed form (and SIMPLE) answer for the pdf of the sum of those random variables, i.e., the pdf of $\sum_{i=1}^{N} {x_i}$? If not, is there an approximation (with a reference if available) where this pdf is approximated using another known pdf? Thanks","If we have N independent exponential random variables of different parameter values: $x_1$ ~ exp($m_1$), $x_2$ ~ exp($m_2$), ..., $x_N$ ~ exp($m_N$) Is there a closed form (and SIMPLE) answer for the pdf of the sum of those random variables, i.e., the pdf of $\sum_{i=1}^{N} {x_i}$? If not, is there an approximation (with a reference if available) where this pdf is approximated using another known pdf? Thanks",,"['probability', 'statistics', 'probability-distributions']"
83,how to compute p-value when the confidence interval is given?,how to compute p-value when the confidence interval is given?,,"Please help on this problem...This is the statement: ""The immunological assay verified the presence of RuBisCO in non-treated (control) and Pb-induced leaves with average relative band intensities of 0.156 ± 0.012 and 0.128 ± 0.013 respectively"" My professor told me that the p-value is 0.0518. He have not seen the raw data but he gives me the p-value base on the interval i have given.While I do the computation using the excel I get 0.00114 only.. I s it possible to compute the p- value using the given interval only? Thank you..","Please help on this problem...This is the statement: ""The immunological assay verified the presence of RuBisCO in non-treated (control) and Pb-induced leaves with average relative band intensities of 0.156 ± 0.012 and 0.128 ± 0.013 respectively"" My professor told me that the p-value is 0.0518. He have not seen the raw data but he gives me the p-value base on the interval i have given.While I do the computation using the excel I get 0.00114 only.. I s it possible to compute the p- value using the given interval only? Thank you..",,"['statistics', 'statistical-inference', 'descriptive-statistics']"
84,question about correlation of variables,question about correlation of variables,,"Here is an interview question I had and  cannot figure out how to solve it. Any hint? Let $X$, $Y$, $Z$ be 3 random variables such that $\mathsf{Corr}(X, Y)=0.9$ and $\mathsf{Corr}(Y, Z)=0.8$. What is the minimum correlation between $X$ and $Z$? Thanks for your help!","Here is an interview question I had and  cannot figure out how to solve it. Any hint? Let $X$, $Y$, $Z$ be 3 random variables such that $\mathsf{Corr}(X, Y)=0.9$ and $\mathsf{Corr}(Y, Z)=0.8$. What is the minimum correlation between $X$ and $Z$? Thanks for your help!",,"['statistics', 'correlation']"
85,how to compare probability/ratios,how to compare probability/ratios,,"For one location, I have: Number of lollipops selling at morning time Number of lollipops selling at afternoon time Selling periods: Every 30 minutes is a period, which sells lollies either morning or afternoon Q1: I would like to calculate the probability of morning and afternoon lolly sold. My formula: Location                     Morning    Afternoon   Total Number of lollies 2        10            12 Selling periods 1         2            3 Ratio 2         5            4 P(Moring) = 2/4 = 0.5 P(Afternoon) = 5/4 = 1.25 If I take the ratio of: P(Afternoon)/P(Morning). Will it be called? Thanks,","For one location, I have: Number of lollipops selling at morning time Number of lollipops selling at afternoon time Selling periods: Every 30 minutes is a period, which sells lollies either morning or afternoon Q1: I would like to calculate the probability of morning and afternoon lolly sold. My formula: Location                     Morning    Afternoon   Total Number of lollies 2        10            12 Selling periods 1         2            3 Ratio 2         5            4 P(Moring) = 2/4 = 0.5 P(Afternoon) = 5/4 = 1.25 If I take the ratio of: P(Afternoon)/P(Morning). Will it be called? Thanks,",,"['probability', 'statistics', 'recreational-mathematics']"
86,When do you use indicator random variables?,When do you use indicator random variables?,,"One of the most difficult concepts that I can't seem to get my head around are indicator random variables. I understand what they are and I understand what to do. But when I am faced with a question, I never think to use them. When do you actually use indicator random variables in statistics questions such as estimation questions, questions about random variables and probability distributions etc Thanks!","One of the most difficult concepts that I can't seem to get my head around are indicator random variables. I understand what they are and I understand what to do. But when I am faced with a question, I never think to use them. When do you actually use indicator random variables in statistics questions such as estimation questions, questions about random variables and probability distributions etc Thanks!",,"['probability', 'statistics']"
87,What does it mean to regress out current features?,What does it mean to regress out current features?,,"First of all, I'd like to say that this is the intro to a homework problem.  Please do not post any answers, I am only looking for clarification on some terminology in the setup. I am trying to understand how this algorithm works and most of it makes sense except for the part where they ""update the residual by regressing out the currently selected features"".  What does that mean? and what is the least squares regression of $y$ onto $X_{S_t}$?","First of all, I'd like to say that this is the intro to a homework problem.  Please do not post any answers, I am only looking for clarification on some terminology in the setup. I am trying to understand how this algorithm works and most of it makes sense except for the part where they ""update the residual by regressing out the currently selected features"".  What does that mean? and what is the least squares regression of $y$ onto $X_{S_t}$?",,"['statistics', 'terminology', 'regression', 'regression-analysis']"
88,How do I calculate regression line using a data set with repeated values indicated as frequencies?,How do I calculate regression line using a data set with repeated values indicated as frequencies?,,"I have a data set that comprises of Independent Variable $(X)$ and Dependent Variable $(Y)$ values with a certain frequency $(F)$. I know that I have to find $x^2$ and $xy$ but how do I factor in the frequency? I am calculating regression using the least squares method ($Y = a + bX$). For clarity, this is the data set that I am working with. Frequency (F) Independent Variable (X) Dependent Variable (Y)       3                  4                       60       4                  4                       65       2                  5                       65       4                  5                       70       3                  6                       75       2                  6                       80       4                  7                       85       3                  8                       90","I have a data set that comprises of Independent Variable $(X)$ and Dependent Variable $(Y)$ values with a certain frequency $(F)$. I know that I have to find $x^2$ and $xy$ but how do I factor in the frequency? I am calculating regression using the least squares method ($Y = a + bX$). For clarity, this is the data set that I am working with. Frequency (F) Independent Variable (X) Dependent Variable (Y)       3                  4                       60       4                  4                       65       2                  5                       65       4                  5                       70       3                  6                       75       2                  6                       80       4                  7                       85       3                  8                       90",,"['statistics', 'regression']"
89,What do the eigenvalues of a correlation matrix represent?,What do the eigenvalues of a correlation matrix represent?,,"I was wondering if there was any special meaning to the eigenvalues/eigenvectors of a correlation matrix. I get what they mean in a covariance matrix, and how that relates to PCA, though. Can you do PCA with the eigenvalues of a correlation matrix instead? What would the PC's mean in that case?","I was wondering if there was any special meaning to the eigenvalues/eigenvectors of a correlation matrix. I get what they mean in a covariance matrix, and how that relates to PCA, though. Can you do PCA with the eigenvalues of a correlation matrix instead? What would the PC's mean in that case?",,"['linear-algebra', 'statistics', 'eigenvalues-eigenvectors', 'machine-learning', 'correlation']"
90,Distribution of order statistics,Distribution of order statistics,,"Let $X_1,X_2,\ldots,X_n$ be independently and identically distributed random variables with mean $1\over \lambda$ , find the distribution of the $1$ st and $n$ th order statistics using the joint density of the order statistics. I find that the joint distribution of the order statistics is $$f_{{X_{(1)}},\ldots,X{_{(n)}}}(y_1,\ldots,y_n)=n!\lambda^ne^{-\lambda(y_1+\cdots+y_2)} \text{ if } 0<y_1<y_2<\cdots<y_n$$ I want to know if this formula is correct and how to find the marginal distributions of $X_{(1)}$ and $X_{(n)}$ .","Let be independently and identically distributed random variables with mean , find the distribution of the st and th order statistics using the joint density of the order statistics. I find that the joint distribution of the order statistics is I want to know if this formula is correct and how to find the marginal distributions of and .","X_1,X_2,\ldots,X_n 1\over \lambda 1 n f_{{X_{(1)}},\ldots,X{_{(n)}}}(y_1,\ldots,y_n)=n!\lambda^ne^{-\lambda(y_1+\cdots+y_2)} \text{ if } 0<y_1<y_2<\cdots<y_n X_{(1)} X_{(n)}","['probability', 'statistics']"
91,Estimation of probability distribution for alternating renewal process,Estimation of probability distribution for alternating renewal process,,"I am studying so-called alternating renewal process, and I have a question concerning estimation of on-time/off-time distributions. Settings Let $\{(Z_0,Y_0),(Z_1,Y_1),(Z_2,Y_2),...\}$ be a sequence of pairs of positive random variables in $\mathbb{Z}_{>0}=\{1,2,3,\cdots\}$, and assume that $Y_i$ and $Z_i$ are independent and identically distributed random variables whose associated distributions are $f_Y(m)$ and $f_Z(m)$, respectively. Also, let $t\in \mathbb{Z}_{>0}$. Then, one can introduce $S_{Z;n},S_{Y;n}$ and $N_t$ by $$S_{Y;n}=\sum_{i=0}^{n}(Z_i+Y_i),\quad S_{Z;n}=S_{Y;n-1}+Z_n,\ where\ S_{Y;-1}:=0;$$$$N_t=\mathrm{card}(\{n|S_{Y;n}\in[0,t)\}).$$ Now, define two positive constant integers $t_0$ and $T$, and observe the process for $t\in[t_0,t_0+T]$. The observation procedure can be given as follows. (1) If $S_{Z;N_{t_0}}\le t_0$, define $Y_*$ by $Y_*=S_{Y;N_{t_0}}-t_0$, or otherwise, define $Z_*$ by $Z_*=S_{Z;N_{t_0}}-t_0$. (2) Similarly, if $S_{Z;N_{{t_0}+T}}< t_0+T$, define $Y_{**}$ by $Y_{**}=t_0+T-S_{Z;N_{{t_0}+T}}$, or otherwise define $Z_{**}$ by $Z_{**}=t_0+T-S_{Y;N_{t_0+T}-1}$. (3) We obtain a new sequence (hereafter ""subsequence"") $O=\{[(Z_*,Y_{N_{t_0}})\ or\ (0,Y_*)],(Z_{N_{t_0}+1},Y_{N_{t_0}+1}),(Z_{N_{t_0}+2},Y_{N_{t_0}+2}),\cdots,(Z_{N_{t_0+T}-1},Y_{N_{t_0+T}-1}),$$[(Z_{**},0)\ or\ (Z_{N_{t_0+T}},Y_{**})]\}$. Repeating this observation for independent $\{(Z_i,Y_i)\}$ sequences gives us ensemble of subsequences. Question Can we construct estimators of $f_Z(m)$ and $f_Y(m)$ (for $1\le m\le T$) from the subsequence $O$, or from the ensemble of subsequences? If yes, how can we do that? If no, what extra assumptions are needed (for example, what if we know $f_Z(m)\propto\exp(-m/\lambda)$, or how rapidly should $f_Z(m)$ and $f_Y(m)$ decay)? I appreciate that one can naively make a ""histogram"" of $Z_i$ and $Y_i$ by defining $p_Z(m)$ and $p_Y(m)$ as $$p_X(m):=\frac{\mathrm{card}\{n\in[N_{t_0},N_{t_0+T}-1]|X_n=m\}}{N_{t_0+T}-N_{t_0}}\ where\ X=Z,Y,$$ and that one can expect that $p_Z(m)$ and $p_Y(m)$ converge to $f_Z(m)$ and $f_Y(m)$ respectively in a limit of $T\rightarrow\infty$. However, if $T$ is finite, I suspect that the problem gets complicated for two reasons: (1) The process is censored by a window of finite length, and thus we have to compensate the missing intervals, (2) The denominator $N_{t_0+T}-N_t$ of $p_X(m)$ $(X=Z,Y)$ is also a random number and is sensitive to rare events of large $m$. Thus, I have no idea how I can appropriately estimate $f_Z(m),f_Y(m)$ so far. I would be grateful if you share your idea to tackle this problem, or you recommend me some literatures (if any) concerning this problem. Note My numerical experience with the case $f_Z(m)\propto m^{-6/5}\exp(m/\xi_{Z})$ and $f_Y(m)\propto \exp(m/\xi_{Y})$ with $\xi_{Y}\ll T$ tells me that the naive histogram over many realization, that is, estimating $p_X(m)$ from set of independent subsequences $\{O_i\}_{i=1}^M$ by $$p_X(m):=\frac{\sum_{i=1}^M\mathrm{card}\{n\in[N_{t_0;i},N_{t_0+T;i}-1]|X_n=m\}}{\sum_{i=1}^M(N_{t_0+T;i}-N_{t_0;i})}\ where\ X=Z,Y$$ underestimates $f_Z(t)$ (in particular $\xi_{Z}$) for $\xi_{Z}\sim T$. Meanwhile I have found that the two estimators shown below give us rather reasonable agreement with $f_Y(t)$: Calculating the sample probability for each realization $O_i(i=1,2,\cdots,M)$ and averaging over the ensemble; that is, $$q_X(m):=\sum_{i=1}^{M}\frac{\mathrm{card}\{n\in[N_{t_0;i},N_{t_0+T;i}-1]|X_n=m\}}{M(N_{t_0+T;i}-N_{t_0;i})}.$$ It should be noted that $q_X(m)$ itself does not satisfy normalization in general, that is, $\sum_{i=1}^{T-1}q_X(m)\ne 1$. Giving a correction to the forementioned histogram by multiplying $1/(1-m/T)$ for each $m$, considering that the interval of length $l$ is censored by the window (and therefore cannot be observed) with probability of approximately $m/T$, even if either of the edge of the interval is inside the window: $$r(m):=p_X(m):=\frac{\sum_{i=1}^M(\mathrm{card}\{n\in[N_{t_0;i},N_{t_0+T;i}-1]|X_n=m\}/(1-m/T))}{\sum_{i=1}^M\sum_{m=1}^T(\mathrm{card}\{n\in[N_{t_0;i},N_{t_0+T;i}-1]|X_n=m\}/(1-m/T))}.$$ Also, it seems to me that giving a rigorous estimation of the estimation is rather complicated task (e.g. E. E. Alvarez, Journal of Statistical Planning and Inference 131 , 209-229 (2005)), and thus I am wondering how we can evaluate the ""goodness"" of the heuristically constructed (approximate) estimators. Any suggestions or comments are gratefully appreciated.","I am studying so-called alternating renewal process, and I have a question concerning estimation of on-time/off-time distributions. Settings Let $\{(Z_0,Y_0),(Z_1,Y_1),(Z_2,Y_2),...\}$ be a sequence of pairs of positive random variables in $\mathbb{Z}_{>0}=\{1,2,3,\cdots\}$, and assume that $Y_i$ and $Z_i$ are independent and identically distributed random variables whose associated distributions are $f_Y(m)$ and $f_Z(m)$, respectively. Also, let $t\in \mathbb{Z}_{>0}$. Then, one can introduce $S_{Z;n},S_{Y;n}$ and $N_t$ by $$S_{Y;n}=\sum_{i=0}^{n}(Z_i+Y_i),\quad S_{Z;n}=S_{Y;n-1}+Z_n,\ where\ S_{Y;-1}:=0;$$$$N_t=\mathrm{card}(\{n|S_{Y;n}\in[0,t)\}).$$ Now, define two positive constant integers $t_0$ and $T$, and observe the process for $t\in[t_0,t_0+T]$. The observation procedure can be given as follows. (1) If $S_{Z;N_{t_0}}\le t_0$, define $Y_*$ by $Y_*=S_{Y;N_{t_0}}-t_0$, or otherwise, define $Z_*$ by $Z_*=S_{Z;N_{t_0}}-t_0$. (2) Similarly, if $S_{Z;N_{{t_0}+T}}< t_0+T$, define $Y_{**}$ by $Y_{**}=t_0+T-S_{Z;N_{{t_0}+T}}$, or otherwise define $Z_{**}$ by $Z_{**}=t_0+T-S_{Y;N_{t_0+T}-1}$. (3) We obtain a new sequence (hereafter ""subsequence"") $O=\{[(Z_*,Y_{N_{t_0}})\ or\ (0,Y_*)],(Z_{N_{t_0}+1},Y_{N_{t_0}+1}),(Z_{N_{t_0}+2},Y_{N_{t_0}+2}),\cdots,(Z_{N_{t_0+T}-1},Y_{N_{t_0+T}-1}),$$[(Z_{**},0)\ or\ (Z_{N_{t_0+T}},Y_{**})]\}$. Repeating this observation for independent $\{(Z_i,Y_i)\}$ sequences gives us ensemble of subsequences. Question Can we construct estimators of $f_Z(m)$ and $f_Y(m)$ (for $1\le m\le T$) from the subsequence $O$, or from the ensemble of subsequences? If yes, how can we do that? If no, what extra assumptions are needed (for example, what if we know $f_Z(m)\propto\exp(-m/\lambda)$, or how rapidly should $f_Z(m)$ and $f_Y(m)$ decay)? I appreciate that one can naively make a ""histogram"" of $Z_i$ and $Y_i$ by defining $p_Z(m)$ and $p_Y(m)$ as $$p_X(m):=\frac{\mathrm{card}\{n\in[N_{t_0},N_{t_0+T}-1]|X_n=m\}}{N_{t_0+T}-N_{t_0}}\ where\ X=Z,Y,$$ and that one can expect that $p_Z(m)$ and $p_Y(m)$ converge to $f_Z(m)$ and $f_Y(m)$ respectively in a limit of $T\rightarrow\infty$. However, if $T$ is finite, I suspect that the problem gets complicated for two reasons: (1) The process is censored by a window of finite length, and thus we have to compensate the missing intervals, (2) The denominator $N_{t_0+T}-N_t$ of $p_X(m)$ $(X=Z,Y)$ is also a random number and is sensitive to rare events of large $m$. Thus, I have no idea how I can appropriately estimate $f_Z(m),f_Y(m)$ so far. I would be grateful if you share your idea to tackle this problem, or you recommend me some literatures (if any) concerning this problem. Note My numerical experience with the case $f_Z(m)\propto m^{-6/5}\exp(m/\xi_{Z})$ and $f_Y(m)\propto \exp(m/\xi_{Y})$ with $\xi_{Y}\ll T$ tells me that the naive histogram over many realization, that is, estimating $p_X(m)$ from set of independent subsequences $\{O_i\}_{i=1}^M$ by $$p_X(m):=\frac{\sum_{i=1}^M\mathrm{card}\{n\in[N_{t_0;i},N_{t_0+T;i}-1]|X_n=m\}}{\sum_{i=1}^M(N_{t_0+T;i}-N_{t_0;i})}\ where\ X=Z,Y$$ underestimates $f_Z(t)$ (in particular $\xi_{Z}$) for $\xi_{Z}\sim T$. Meanwhile I have found that the two estimators shown below give us rather reasonable agreement with $f_Y(t)$: Calculating the sample probability for each realization $O_i(i=1,2,\cdots,M)$ and averaging over the ensemble; that is, $$q_X(m):=\sum_{i=1}^{M}\frac{\mathrm{card}\{n\in[N_{t_0;i},N_{t_0+T;i}-1]|X_n=m\}}{M(N_{t_0+T;i}-N_{t_0;i})}.$$ It should be noted that $q_X(m)$ itself does not satisfy normalization in general, that is, $\sum_{i=1}^{T-1}q_X(m)\ne 1$. Giving a correction to the forementioned histogram by multiplying $1/(1-m/T)$ for each $m$, considering that the interval of length $l$ is censored by the window (and therefore cannot be observed) with probability of approximately $m/T$, even if either of the edge of the interval is inside the window: $$r(m):=p_X(m):=\frac{\sum_{i=1}^M(\mathrm{card}\{n\in[N_{t_0;i},N_{t_0+T;i}-1]|X_n=m\}/(1-m/T))}{\sum_{i=1}^M\sum_{m=1}^T(\mathrm{card}\{n\in[N_{t_0;i},N_{t_0+T;i}-1]|X_n=m\}/(1-m/T))}.$$ Also, it seems to me that giving a rigorous estimation of the estimation is rather complicated task (e.g. E. E. Alvarez, Journal of Statistical Planning and Inference 131 , 209-229 (2005)), and thus I am wondering how we can evaluate the ""goodness"" of the heuristically constructed (approximate) estimators. Any suggestions or comments are gratefully appreciated.",,"['statistics', 'stochastic-processes', 'statistical-inference']"
92,Expectation of log likelihood ratio,Expectation of log likelihood ratio,,"Given that $X_{1},...,X_{n}$ are i.i.d random variables with joint distribution $f(x\mid \theta) $  with 1 dimensional parameter $\theta$ and let $\hat\theta$ be the maximum likelihood estimator of $\theta$. Based on the Wilks theorem,under null hypothesis that $H_{0}: \theta=\theta_{0}$ ,one have that $-2\log\left(f(x\mid \theta_{0})/f(x\mid \hat\theta)\right)\to \chi_{1}^{2}$ as $n\to\infty$. Since we know that $E\chi_{1}^{2}=1$, is there anyway I can find the value of the following integral (expectation of log likelihood ratio) or at least asymptotics $$-2\int f(x\mid \theta_{0})\log\left(\frac{f(x\mid \theta_{0})}{f(x\mid \hat\theta)}\right)\,dx=~?$$ My guess is that the integral should be around 1. Anyone please share some idea or references with the above integral.","Given that $X_{1},...,X_{n}$ are i.i.d random variables with joint distribution $f(x\mid \theta) $  with 1 dimensional parameter $\theta$ and let $\hat\theta$ be the maximum likelihood estimator of $\theta$. Based on the Wilks theorem,under null hypothesis that $H_{0}: \theta=\theta_{0}$ ,one have that $-2\log\left(f(x\mid \theta_{0})/f(x\mid \hat\theta)\right)\to \chi_{1}^{2}$ as $n\to\infty$. Since we know that $E\chi_{1}^{2}=1$, is there anyway I can find the value of the following integral (expectation of log likelihood ratio) or at least asymptotics $$-2\int f(x\mid \theta_{0})\log\left(\frac{f(x\mid \theta_{0})}{f(x\mid \hat\theta)}\right)\,dx=~?$$ My guess is that the integral should be around 1. Anyone please share some idea or references with the above integral.",,"['integration', 'statistics', 'expectation']"
93,Huffman Code Assuming Wrong Distribution,Huffman Code Assuming Wrong Distribution,,Assume the random variable X ∼ p(x). We design a Huffman code C for this X but unfortunately we assume an incorrect probability distribution p' for the random variable. What can you say about the expected code length L(C) per letter of our code? Your professor thought that it holds L(C) ≤ H(X) + D(p∥p') + 1. Prove him wrong; i.e. find a counterexample to this conjecture. So we design our tree from the p' distribution but calculate L(C) from the p distribution based on the lengths from p' call them l(x). That is $$L(C) = \sum_{x}^{}p(x)l(x)$$ So I know I can play around with a couple factors to find a distribution such that L(C) - 1 ≤ H(X) + D(p∥p') I can minimize the H(X) with a skewed distribution and I can minimize the relative entropy by making p and p' similar and I can try and maximize my code length but I am having trouble figuring out which combination of factors will achieve my result. I also know that the true bound on L(C) is 1 + 2H(X) + 2D(p∥p').,Assume the random variable X ∼ p(x). We design a Huffman code C for this X but unfortunately we assume an incorrect probability distribution p' for the random variable. What can you say about the expected code length L(C) per letter of our code? Your professor thought that it holds L(C) ≤ H(X) + D(p∥p') + 1. Prove him wrong; i.e. find a counterexample to this conjecture. So we design our tree from the p' distribution but calculate L(C) from the p distribution based on the lengths from p' call them l(x). That is $$L(C) = \sum_{x}^{}p(x)l(x)$$ So I know I can play around with a couple factors to find a distribution such that L(C) - 1 ≤ H(X) + D(p∥p') I can minimize the H(X) with a skewed distribution and I can minimize the relative entropy by making p and p' similar and I can try and maximize my code length but I am having trouble figuring out which combination of factors will achieve my result. I also know that the true bound on L(C) is 1 + 2H(X) + 2D(p∥p').,,"['statistics', 'information-theory']"
94,Neyman Pearson rule but not a Bayes rule,Neyman Pearson rule but not a Bayes rule,,"Consider a binary hypothesis testing problem of $P_0$ vs. $P_1$ under uniform costs. Let $r(\delta,\pi)$ denote the risk line for any decision rule $\delta$ and prior $\pi$, i.e, $r(\delta,\pi)=\pi R_0(\delta)+(1-\pi)R_1(\delta)$, where $R_0(\delta)=P_F(\delta)$ and $R_1(\delta)=P_M(\delta)$ are the false alarm and miss detection probabilities. The following is a question that I am trying to solve: If $V(\pi)=\min_{\delta} r(\delta,\pi)$ denotes the Bayes risk for prior $\pi$ and the significance level $\alpha$ is such that $V'(0) < \alpha <1$, then show that there exists Neyman Pearson decision rules that are not Bayes rules. Can anyone help me solve this? All I know is that we can always find Bayes rules from NP rules using randomized likelihood ratio test.","Consider a binary hypothesis testing problem of $P_0$ vs. $P_1$ under uniform costs. Let $r(\delta,\pi)$ denote the risk line for any decision rule $\delta$ and prior $\pi$, i.e, $r(\delta,\pi)=\pi R_0(\delta)+(1-\pi)R_1(\delta)$, where $R_0(\delta)=P_F(\delta)$ and $R_1(\delta)=P_M(\delta)$ are the false alarm and miss detection probabilities. The following is a question that I am trying to solve: If $V(\pi)=\min_{\delta} r(\delta,\pi)$ denotes the Bayes risk for prior $\pi$ and the significance level $\alpha$ is such that $V'(0) < \alpha <1$, then show that there exists Neyman Pearson decision rules that are not Bayes rules. Can anyone help me solve this? All I know is that we can always find Bayes rules from NP rules using randomized likelihood ratio test.",,"['statistics', 'parameter-estimation']"
95,Find the joint probability density given the support set,Find the joint probability density given the support set,,"Suppose that the support set of $(X,Y)$ is $$S_{X,Y}=\{(x,y)\in\mathbb{R}^2: x \geq 0 \text{ and } 0 \leq y \leq e^{-x/3}\}$$ $(X,Y)$ is uniformly distributed on $S_{X,Y}$ . a) Find the joint probability density function for $(X,Y)$ . b) Find the marginal PDFs for X and Y. c) Are X and Y independent? Explain. What I have tried a) Is the joint PDF $\int \int e^{-x/3}\text{d}x\text{d}y$ ?. If so, what are the bounds? b) Fix X, integrate over all Y and vice versa. c) Check if the joint PDF is the product of the marginals.","Suppose that the support set of is is uniformly distributed on . a) Find the joint probability density function for . b) Find the marginal PDFs for X and Y. c) Are X and Y independent? Explain. What I have tried a) Is the joint PDF ?. If so, what are the bounds? b) Fix X, integrate over all Y and vice versa. c) Check if the joint PDF is the product of the marginals.","(X,Y) S_{X,Y}=\{(x,y)\in\mathbb{R}^2: x \geq 0 \text{ and } 0 \leq y \leq e^{-x/3}\} (X,Y) S_{X,Y} (X,Y) \int \int e^{-x/3}\text{d}x\text{d}y","['probability', 'statistics', 'continuity', 'random-variables']"
96,Central limit theorem for uncorrelated identically distributed random variable,Central limit theorem for uncorrelated identically distributed random variable,,"I have a sum of random variables as bellow $$Y=\sum_n A_n=\sum_n B_n\times C_n$$ where $B_n$s are correlated Gaussian random variables with zero mean, variance $1$ and correlation $E\{B_nB^*_r\}=\frac{1}{N}\sum_{l-0}^{L-1}\sigma^2_le^{\frac{j2\pi l(n-r)}{N}}$ where $\sum_{l=0}^{L-1}\sigma^2_l=1$ and $L$ and $N$ are integers ($L<N$). $C_n$s are independent and identically distributed random variables with zero mean and variance $P$. Also $B_n$ is independent of $C_n$. My question is that can the distribution of $Y$ be approximated as Gaussian? I know that the central limit theorem is true for sum of iid random variables but $Y$ is sum of uncorrelated identically distributed random variable. I can't prove whether $A_n$s are independent or not. Does the central limit theorem hold for my case? Thanks in advance","I have a sum of random variables as bellow $$Y=\sum_n A_n=\sum_n B_n\times C_n$$ where $B_n$s are correlated Gaussian random variables with zero mean, variance $1$ and correlation $E\{B_nB^*_r\}=\frac{1}{N}\sum_{l-0}^{L-1}\sigma^2_le^{\frac{j2\pi l(n-r)}{N}}$ where $\sum_{l=0}^{L-1}\sigma^2_l=1$ and $L$ and $N$ are integers ($L<N$). $C_n$s are independent and identically distributed random variables with zero mean and variance $P$. Also $B_n$ is independent of $C_n$. My question is that can the distribution of $Y$ be approximated as Gaussian? I know that the central limit theorem is true for sum of iid random variables but $Y$ is sum of uncorrelated identically distributed random variable. I can't prove whether $A_n$s are independent or not. Does the central limit theorem hold for my case? Thanks in advance",,"['statistics', 'stochastic-processes', 'central-limit-theorem', 'law-of-large-numbers']"
97,"If a Stochastic Process has Variance linear with t, how to prove it is not Wide Sense Stationary?","If a Stochastic Process has Variance linear with t, how to prove it is not Wide Sense Stationary?",,"For my study, as a part of a Matlab exercise, the following question is asked: Using the results of the estimated standard deviations of the random   variable $x(k)$ for $k = 10^3; 10^4; 10^5$ conclude whether the random   process is wide sense stationary (WSS) or not. The process we are studying in this exercise is Brownian motion, using the following difference equation: $x(k)+\beta_1x(k-1)+\beta_2x(k-2)=\beta_3w(k)$ Where $w(k)$ is modeled using samples from the Normal distribution, normalised by the time step $dt$. Now, from theory, I know that the variance of the Brownian motion (a Wiener process) increases linearly with time: $Var(x)=at=\sigma_x^2$ So, $\sigma_x=b\sqrt(t)$ This is indeed what I observe, when I plot these values; the function looks like a square root. When I plot the squared values, I get something looking very nicely linear. I also know that a Wiener process is not WSS from literature (the internetz). Now, it is up to me to prove this from the gained relation between the standard deviation (Variance), and the time. According to my course reader, 3 criteria are needed for a stochastic process to be WSS: The mean should be constant (time-invariant) Autocorrelation $t1$,$t2$ should only be dependent on the difference between two time-intervals, $t2-t1$ $c_x(0)<\infty$, (with $c_x$ the autocovariance function). i.e. The variance is finite. I think the criterium that needs to be checked is the 3rd one. Maybe the second one can also be used. (The first one is already met, since for this process the mean is zero, and therefore constant in time.) I was thinking along the lines of: $\lim_{t\to\infty} at=\infty$ (Apologies if this is not the correct way to write that) However, I'm not sure if this a valid proof, or not. In a real physical system, t will never reach infity, and the Variance will be very large, but not infinite. Maybe I can relate the Variance in some way to the Autocorrelation, and this way prove that for a variance linear with t, it is not possible to satisfy condition 2? I appreciate nudges in the good direction more than final answers, if possible.","For my study, as a part of a Matlab exercise, the following question is asked: Using the results of the estimated standard deviations of the random   variable $x(k)$ for $k = 10^3; 10^4; 10^5$ conclude whether the random   process is wide sense stationary (WSS) or not. The process we are studying in this exercise is Brownian motion, using the following difference equation: $x(k)+\beta_1x(k-1)+\beta_2x(k-2)=\beta_3w(k)$ Where $w(k)$ is modeled using samples from the Normal distribution, normalised by the time step $dt$. Now, from theory, I know that the variance of the Brownian motion (a Wiener process) increases linearly with time: $Var(x)=at=\sigma_x^2$ So, $\sigma_x=b\sqrt(t)$ This is indeed what I observe, when I plot these values; the function looks like a square root. When I plot the squared values, I get something looking very nicely linear. I also know that a Wiener process is not WSS from literature (the internetz). Now, it is up to me to prove this from the gained relation between the standard deviation (Variance), and the time. According to my course reader, 3 criteria are needed for a stochastic process to be WSS: The mean should be constant (time-invariant) Autocorrelation $t1$,$t2$ should only be dependent on the difference between two time-intervals, $t2-t1$ $c_x(0)<\infty$, (with $c_x$ the autocovariance function). i.e. The variance is finite. I think the criterium that needs to be checked is the 3rd one. Maybe the second one can also be used. (The first one is already met, since for this process the mean is zero, and therefore constant in time.) I was thinking along the lines of: $\lim_{t\to\infty} at=\infty$ (Apologies if this is not the correct way to write that) However, I'm not sure if this a valid proof, or not. In a real physical system, t will never reach infity, and the Variance will be very large, but not infinite. Maybe I can relate the Variance in some way to the Autocorrelation, and this way prove that for a variance linear with t, it is not possible to satisfy condition 2? I appreciate nudges in the good direction more than final answers, if possible.",,"['statistics', 'brownian-motion', 'covariance', 'stationary-processes']"
98,Maximizing the probability of a poll prediction,Maximizing the probability of a poll prediction,,"Using the central limit theorem, I was able to find out the first part of this question. However, part b is eluding me. How do I, in general, find a value for $n$ such that we can ensure the probability a poll is correctly predictive (ie. 95% certainty a majority would vote for candidate A?)? I'm sure it has something to do with CTL or LLN, but it's been elusive. The equations at the bottom were my best guess as to finding some relationship between the probability and $n$, but I cannot solve the equation. Situation : In a large voting population, 56% of the voters prefer candidate A to candidate B. The true percentage is not known to either candidate, and candidate A commissions a poll of 100 voters to determine whether or not he will win. a) Using the Central Limit Theorem, determine the probability that the poll will correctly predict his winning the election. \ answer. Let $X_i$, $i = 1,...,100$ represent the outcome of the vote of the $i$-th person polled, where $X_i = 1$ if they prefer candidate A (with probability 0.56) and $X_i = 0$ otherwise. Let $S_n$  be the sum of all $X_i$. Then the probability that the poll will correctly predict candidate A winning the election is  \begin{align*} P(S_n > 50) &= 1 - P(S_n \leq 50) \end{align*} It can be shown that $E[S_n] = n\mu = 56$ and $SD(S_n) = \sigma\sqrt{n} = 7.48$. Using the central limit theorem, we can approximate $Z = \frac{S_n - n\mu}{\sigma\sqrt{n}}$ as the Standard Normal, so  \begin{align*} P(S_n \leq 50) &= P(Z \leq \frac{50 - n\mu}{\sigma\sqrt{n}}) \\  &= P(Z \leq \frac{50 - 56}{7.48}) \\  &= \Phi(-0.8021) \\  &= 0.2119 \end{align*} Finally, the probability that the poll will correctly predict candidate A winning the election is $P(S_n > 50) = 1 - P(S_n \leq 50) = 0.7881$. b) What sample size would be required to ensure at least a 95% chance of a correct prediction? answer. From part a, we can use the following inequality to solve for $n$:  \begin{align*} 0.95 &\leq 1 - P(S_n \leq 50) \\ 0.05 &\geq P(S_n \leq 50) \\ &\geq \Phi(\frac{50 - n(0.56)}{(0.784)\sqrt{n}}) \end{align*} Note: I  also attempted to use Markov's inequality to try to come up with a solution, but that proved just as difficult. EDIT: Thanks commenter Andre for pointing out that the last equation should use $P(S_n \leq n/2)$ instead of using 50. The equation is then  $$ 0.95 \leq 1 - P(S_n \leq n/2) $$","Using the central limit theorem, I was able to find out the first part of this question. However, part b is eluding me. How do I, in general, find a value for $n$ such that we can ensure the probability a poll is correctly predictive (ie. 95% certainty a majority would vote for candidate A?)? I'm sure it has something to do with CTL or LLN, but it's been elusive. The equations at the bottom were my best guess as to finding some relationship between the probability and $n$, but I cannot solve the equation. Situation : In a large voting population, 56% of the voters prefer candidate A to candidate B. The true percentage is not known to either candidate, and candidate A commissions a poll of 100 voters to determine whether or not he will win. a) Using the Central Limit Theorem, determine the probability that the poll will correctly predict his winning the election. \ answer. Let $X_i$, $i = 1,...,100$ represent the outcome of the vote of the $i$-th person polled, where $X_i = 1$ if they prefer candidate A (with probability 0.56) and $X_i = 0$ otherwise. Let $S_n$  be the sum of all $X_i$. Then the probability that the poll will correctly predict candidate A winning the election is  \begin{align*} P(S_n > 50) &= 1 - P(S_n \leq 50) \end{align*} It can be shown that $E[S_n] = n\mu = 56$ and $SD(S_n) = \sigma\sqrt{n} = 7.48$. Using the central limit theorem, we can approximate $Z = \frac{S_n - n\mu}{\sigma\sqrt{n}}$ as the Standard Normal, so  \begin{align*} P(S_n \leq 50) &= P(Z \leq \frac{50 - n\mu}{\sigma\sqrt{n}}) \\  &= P(Z \leq \frac{50 - 56}{7.48}) \\  &= \Phi(-0.8021) \\  &= 0.2119 \end{align*} Finally, the probability that the poll will correctly predict candidate A winning the election is $P(S_n > 50) = 1 - P(S_n \leq 50) = 0.7881$. b) What sample size would be required to ensure at least a 95% chance of a correct prediction? answer. From part a, we can use the following inequality to solve for $n$:  \begin{align*} 0.95 &\leq 1 - P(S_n \leq 50) \\ 0.05 &\geq P(S_n \leq 50) \\ &\geq \Phi(\frac{50 - n(0.56)}{(0.784)\sqrt{n}}) \end{align*} Note: I  also attempted to use Markov's inequality to try to come up with a solution, but that proved just as difficult. EDIT: Thanks commenter Andre for pointing out that the last equation should use $P(S_n \leq n/2)$ instead of using 50. The equation is then  $$ 0.95 \leq 1 - P(S_n \leq n/2) $$",,"['probability', 'statistics', 'normal-distribution', 'central-limit-theorem', 'law-of-large-numbers']"
99,"Is multiplication of a correlated random variable and a independent random variable, an independent random variable [closed]","Is multiplication of a correlated random variable and a independent random variable, an independent random variable [closed]",,Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 8 years ago . Improve this question I have a random variable that is a multiplication of two random variables as bellow: $$A_n=B_n\times C_n$$ $B_n$s are identically distributed with  zero mean and are correlated for different $n$s and $C_n$s are independent and identically distributed with  zero mean. My question is that are $A_n$s independent? By the way $B_n$ and $C_n$ are independent. Thanks in advance.,Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 8 years ago . Improve this question I have a random variable that is a multiplication of two random variables as bellow: $$A_n=B_n\times C_n$$ $B_n$s are identically distributed with  zero mean and are correlated for different $n$s and $C_n$s are independent and identically distributed with  zero mean. My question is that are $A_n$s independent? By the way $B_n$ and $C_n$ are independent. Thanks in advance.,,"['statistics', 'stochastic-processes']"
