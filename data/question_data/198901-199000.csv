,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Self-Linking Number on 3-Manifolds,Self-Linking Number on 3-Manifolds,,"We can assign a framing to a knot $K$ (in some nice enough space $M$) in order to calculate the self-linking number $lk(K,K)$. But of course it is not necessarily canonical, as added twists in your vector field can remove/add crossings. Two things are stated in Witten's QFT paper on the Jones polynomial, which I do not quite see: 1) On $S^3$ we do have a canonical framing of knots, by requesting that $lk(K,K)=0$. Why? I must be understanding this incorrectly, because if we decide the framing by requiring $lk(K,K)=0$, so that the framing has whatever twists it needs to accomplish this, then aren't we making a choice?? We could have simply required $lk(K,K)=n$ for any integer $n$. If $n> 0$ does there then exist multiple possible framings? 2) For general 3-manifolds, we can have $lk(K,K)$ ill-defined or it can be a fixed fraction (modulo $\mathbb{Z}$) so that any choice of framing won't make it $0$. What are some examples? When is it possible to set a fixed fraction? Is there a relation between the 3-manifold $M$ and the fractional value you can assign to $lk(K,K)$?","We can assign a framing to a knot $K$ (in some nice enough space $M$) in order to calculate the self-linking number $lk(K,K)$. But of course it is not necessarily canonical, as added twists in your vector field can remove/add crossings. Two things are stated in Witten's QFT paper on the Jones polynomial, which I do not quite see: 1) On $S^3$ we do have a canonical framing of knots, by requesting that $lk(K,K)=0$. Why? I must be understanding this incorrectly, because if we decide the framing by requiring $lk(K,K)=0$, so that the framing has whatever twists it needs to accomplish this, then aren't we making a choice?? We could have simply required $lk(K,K)=n$ for any integer $n$. If $n> 0$ does there then exist multiple possible framings? 2) For general 3-manifolds, we can have $lk(K,K)$ ill-defined or it can be a fixed fraction (modulo $\mathbb{Z}$) so that any choice of framing won't make it $0$. What are some examples? When is it possible to set a fixed fraction? Is there a relation between the 3-manifold $M$ and the fractional value you can assign to $lk(K,K)$?",,"['algebraic-topology', 'differential-geometry', 'knot-theory']"
1,Basis for the set of all covariant $k$-tensors on V,Basis for the set of all covariant -tensors on V,k,"Here's a proposition from Lee's Smooth Manifolds: Let $V$ be a real vector space of dimension $n$, let $(E^i)$ be any basis for $V$, and let $(\epsilon^i)$ be the dual basis. The set of all $k$-tensors of the form $\epsilon^{i_1}\otimes...\otimes\epsilon^{i_k}$ for $1 \leq i_1,...,i_k \leq n$ is a basis for the set of all covariant $k$-tensors on $V$, denoted by $T^k(V)$, which therefore has dimension $n^k$. I want to construct an example based on this proposition. Let $V=\mathbb{R}^3$, and let $e_1, e_2, e_3$ denote the usual basis for $\mathbb{R}^3$. Then the dual basis $(\epsilon^i)$ is $dx, dy$ and $dz$. Then $dx\otimes dy, dx\otimes dz, dy\otimes dz, dy\otimes dx, dz\otimes dy, dz\otimes dx, dx\otimes dx, dy\otimes dy$ and $dz\otimes dz$ form a basis for $T^2(\mathbb{R}^3)$. Is the example correct until this point? If so, which of them are the symmetric 2-tensors?","Here's a proposition from Lee's Smooth Manifolds: Let $V$ be a real vector space of dimension $n$, let $(E^i)$ be any basis for $V$, and let $(\epsilon^i)$ be the dual basis. The set of all $k$-tensors of the form $\epsilon^{i_1}\otimes...\otimes\epsilon^{i_k}$ for $1 \leq i_1,...,i_k \leq n$ is a basis for the set of all covariant $k$-tensors on $V$, denoted by $T^k(V)$, which therefore has dimension $n^k$. I want to construct an example based on this proposition. Let $V=\mathbb{R}^3$, and let $e_1, e_2, e_3$ denote the usual basis for $\mathbb{R}^3$. Then the dual basis $(\epsilon^i)$ is $dx, dy$ and $dz$. Then $dx\otimes dy, dx\otimes dz, dy\otimes dz, dy\otimes dx, dz\otimes dy, dz\otimes dx, dx\otimes dx, dy\otimes dy$ and $dz\otimes dz$ form a basis for $T^2(\mathbb{R}^3)$. Is the example correct until this point? If so, which of them are the symmetric 2-tensors?",,['differential-geometry']
2,Laplace-Beltrami Operator on Surfaces,Laplace-Beltrami Operator on Surfaces,,"I would like to know what is known about the spectrum of the Laplace-Beltrami operator on 2-dimensional negatively curved surfaces of constant curvature. For instance, What is the spectrum of the Hyperbolic plane? What is the Laplace-Beltrami operator and its spectrum for a compact surface of constant curvature $-1$ and genus $g\geq 2$? Can anyone point me to the right reference?","I would like to know what is known about the spectrum of the Laplace-Beltrami operator on 2-dimensional negatively curved surfaces of constant curvature. For instance, What is the spectrum of the Hyperbolic plane? What is the Laplace-Beltrami operator and its spectrum for a compact surface of constant curvature $-1$ and genus $g\geq 2$? Can anyone point me to the right reference?",,"['differential-geometry', 'riemannian-geometry', 'riemann-surfaces']"
3,Stokes' theorem in differential geometry vs measure theory [closed],Stokes' theorem in differential geometry vs measure theory [closed],,"Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 4 months ago . Improve this question For some context, I'm an undergraduate student in mathematics and have attended an introductory measure theory lecture. The lecture seemed to loosely follow some chapters of Real Analysis (Folland, 1999, 2nd edition) in scope if not in depth. In the next semester, I'll take what is called Analysis 3 in our curriculum. Now I've been comparing different lecture notes and there seem to be two different approaches to Stokes' theorem (as a widely applied theorem, I chose this especially for a cursory comparison). The one we will be learning is the differential geometry approach: Theorem (Stokes, 3.13, Analysis 3, Cap, 2023 ): Let $M \subset \mathbb{R}^n$ be a $k$ -dimensional oriented $C^1$ -submanifold with boundary $\partial M$ and let $W \subset \mathbb{R}^n$ be open with $M \subset W$ . Then for every continuously differentiable $(k-1)$ -form $\tau \in \Omega^{k-1}(W)$ with compact support on $M$ and with the induced orientation on $\partial M$ we have $$ \int_M d\tau = \int_{\partial M} \tau.$$ Other lecturers seem to prefer the measure theoretical approach: Theorem (Stokes, 15.9.2, Aufbau Analysis, Kaltenbäck, 2021 ): Let $p \gt 1$ and $G \subset \mathbb{R}^p$ be open and bounded. Let $f: \mathscr{cl}(G) \to \mathbb{R}$ be continuous such that $f{\big|}_G$ is continuously differentiable. Let $L \subset \partial G \setminus \partial^o G$ such that $$ \lim_{\delta \searrow 0} \frac{\lambda_p(K_{\delta}(L))}{\delta} = 0$$ and the support of $f$ be a subset of $G \cup \partial^o G \cup L.$ Then if $\partial_j f \in \mathscr{L}(G, \lambda_p)$ for all $j \in \{ 1, \dots, p \}$ and $f\big|_{\partial^o G} \in \mathscr{L}(\partial^o G, \mu)$ with the surface measure $\mu$ we have $$ \int_G D f(x) w \, d\lambda_p(x) = \int_{\partial^o G} f(y) \cdot \left(v(y)^T w\right) \, d\mu(y) $$ for any $w \in \mathbb{R}^p$ with the outward normal vector $v(y)$ at $y \in \partial^o G$ . What I've been wondering is how the two approaches differ in the long run and where it all leads to. I assume that they are equivalent up to a certain point but depending on your research area you eventually chose one, be it due to background, aesthetic preference or practicability?","Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 4 months ago . Improve this question For some context, I'm an undergraduate student in mathematics and have attended an introductory measure theory lecture. The lecture seemed to loosely follow some chapters of Real Analysis (Folland, 1999, 2nd edition) in scope if not in depth. In the next semester, I'll take what is called Analysis 3 in our curriculum. Now I've been comparing different lecture notes and there seem to be two different approaches to Stokes' theorem (as a widely applied theorem, I chose this especially for a cursory comparison). The one we will be learning is the differential geometry approach: Theorem (Stokes, 3.13, Analysis 3, Cap, 2023 ): Let be a -dimensional oriented -submanifold with boundary and let be open with . Then for every continuously differentiable -form with compact support on and with the induced orientation on we have Other lecturers seem to prefer the measure theoretical approach: Theorem (Stokes, 15.9.2, Aufbau Analysis, Kaltenbäck, 2021 ): Let and be open and bounded. Let be continuous such that is continuously differentiable. Let such that and the support of be a subset of Then if for all and with the surface measure we have for any with the outward normal vector at . What I've been wondering is how the two approaches differ in the long run and where it all leads to. I assume that they are equivalent up to a certain point but depending on your research area you eventually chose one, be it due to background, aesthetic preference or practicability?","M \subset \mathbb{R}^n k C^1 \partial M W \subset \mathbb{R}^n M \subset W (k-1) \tau \in \Omega^{k-1}(W) M \partial M  \int_M d\tau = \int_{\partial M} \tau. p \gt 1 G \subset \mathbb{R}^p f: \mathscr{cl}(G) \to \mathbb{R} f{\big|}_G L \subset \partial G \setminus \partial^o G  \lim_{\delta \searrow 0} \frac{\lambda_p(K_{\delta}(L))}{\delta} = 0 f G \cup \partial^o G \cup L. \partial_j f \in \mathscr{L}(G, \lambda_p) j \in \{ 1, \dots, p \} f\big|_{\partial^o G} \in \mathscr{L}(\partial^o G, \mu) \mu  \int_G D f(x) w \, d\lambda_p(x) = \int_{\partial^o G} f(y) \cdot \left(v(y)^T w\right) \, d\mu(y)  w \in \mathbb{R}^p v(y) y \in \partial^o G","['real-analysis', 'differential-geometry', 'geometric-measure-theory']"
4,"Vanishing of the second cohomology module of a pair $(M^*, \partial M^*)$",Vanishing of the second cohomology module of a pair,"(M^*, \partial M^*)","I am currently reading the paper $\textit{Classification of the actions of the circle on 3-manifolds}$ , by Frank Raymond. In the proof of Lemma 2, the author enunciates the following fact without a proof: If $M^*$ is a non-compact surface with boundary, and $U^*$ is a small enough closed collared neighborhood of $\partial M^*$ , then $$\text{H}^2(M^*, U^*;\mathbb{Z}) = 0.$$ The author seems to use the fact that $M^*\setminus U^*$ is non-compact and connected. I have unsuccessfully tried to use the usual tools from a basic Algebraic Topology course for a proof of the claim. Namely, the Long Exact Sequence in Cohomology for the given pair is $$0\rightarrow \text{H}^0(M^*, U^*)\rightarrow \text{H}^0(M^*)\rightarrow \text{H}^0(U^*)\rightarrow \text{H}^1(M^*, U^*)\rightarrow \text{H}^1(M^*)\xrightarrow{\phi} \text{H}^1(U^*)\xrightarrow{\delta}\text{H}^2(M^*, U^*)\rightarrow \text{H}^2(M^*)\rightarrow \text{H}^2(U^*)\rightarrow 0.$$ The two rightmost terms vanish, since $M^*$ is a non-compact surface and $U^*$ deformation retracts onto a 1-manifold. Thus, since $\delta$ is onto, $\text{H}^2(M^*, U^*) = 0 \iff \delta = 0 \iff \phi $ is onto. Hence, it would suffice to prove that the inclusion $U^*\hookrightarrow{} M^*$ induces a surjection in 1-dimensional cohomology. This seems to have a geometric interpretation in terms of cocycles, or even 1-forms if we consider the de Rham cohomology. The Excision Theorem is not very promising in my opinion, since there does not seem to be an appropriate way to excise a subspace from the pair $(M^*, U^*)$ so that it fundamentally simplifies. A colleague suggested to prove that the pair above has the homotopy type of a 1-dimensional CW pair, but this seems even harder to prove. By itself, this would be a very interesting fact to learn. Another reasonable approach could be to use the fact that $(M^*, U^*)$ is a $\textit{good pair}$ in the sense of Hatcher's book, so that the quotient map $$q:(M^*, U^*)\rightarrow (M^*/U^*, U^*/U^*)$$ induces isomorphisms in homology. However, the non-compact CW space $M^*/U^*\cong M^*/\partial M^*\cong M^*\cup_{\partial M^*} C(\partial M^*)$ can be a little wild if $\partial M^*$ has infinitely many components, where $CX$ denotes the cone over $X$ . I am very curious about the two main approaches I propose, but even the smallest hint towards a proof of the original question is greatly appreciated.","I am currently reading the paper , by Frank Raymond. In the proof of Lemma 2, the author enunciates the following fact without a proof: If is a non-compact surface with boundary, and is a small enough closed collared neighborhood of , then The author seems to use the fact that is non-compact and connected. I have unsuccessfully tried to use the usual tools from a basic Algebraic Topology course for a proof of the claim. Namely, the Long Exact Sequence in Cohomology for the given pair is The two rightmost terms vanish, since is a non-compact surface and deformation retracts onto a 1-manifold. Thus, since is onto, is onto. Hence, it would suffice to prove that the inclusion induces a surjection in 1-dimensional cohomology. This seems to have a geometric interpretation in terms of cocycles, or even 1-forms if we consider the de Rham cohomology. The Excision Theorem is not very promising in my opinion, since there does not seem to be an appropriate way to excise a subspace from the pair so that it fundamentally simplifies. A colleague suggested to prove that the pair above has the homotopy type of a 1-dimensional CW pair, but this seems even harder to prove. By itself, this would be a very interesting fact to learn. Another reasonable approach could be to use the fact that is a in the sense of Hatcher's book, so that the quotient map induces isomorphisms in homology. However, the non-compact CW space can be a little wild if has infinitely many components, where denotes the cone over . I am very curious about the two main approaches I propose, but even the smallest hint towards a proof of the original question is greatly appreciated.","\textit{Classification of the actions of the circle on 3-manifolds} M^* U^* \partial M^* \text{H}^2(M^*, U^*;\mathbb{Z}) = 0. M^*\setminus U^* 0\rightarrow \text{H}^0(M^*, U^*)\rightarrow \text{H}^0(M^*)\rightarrow \text{H}^0(U^*)\rightarrow \text{H}^1(M^*, U^*)\rightarrow \text{H}^1(M^*)\xrightarrow{\phi} \text{H}^1(U^*)\xrightarrow{\delta}\text{H}^2(M^*, U^*)\rightarrow \text{H}^2(M^*)\rightarrow \text{H}^2(U^*)\rightarrow 0. M^* U^* \delta \text{H}^2(M^*, U^*) = 0 \iff \delta = 0 \iff \phi  U^*\hookrightarrow{} M^* (M^*, U^*) (M^*, U^*) \textit{good pair} q:(M^*, U^*)\rightarrow (M^*/U^*, U^*/U^*) M^*/U^*\cong M^*/\partial M^*\cong M^*\cup_{\partial M^*} C(\partial M^*) \partial M^* CX X","['differential-geometry', 'algebraic-topology', 'differential-topology']"
5,"If $\alpha\wedge d\alpha$ is a volume form, there exists a vector field $X$ such that $i_X\alpha\equiv1$ and $i_X (d\alpha)\equiv0$.","If  is a volume form, there exists a vector field  such that  and .",\alpha\wedge d\alpha X i_X\alpha\equiv1 i_X (d\alpha)\equiv0,"I'm currently stuck on the following problem: Let $\alpha$ be a 1-form on a connected 3-manifold $M$ such that $\alpha\wedge d\alpha$ is a volume form. Show that there exists a vector field $X$ on $M$ such that $i_X\alpha\equiv1$ and $i_X(d\alpha)\equiv0$ . I believe there are a few routes to solve this problem, but I keep getting stuck at each step. Working locally, I first wrote $$\alpha=\alpha_1dx+\alpha_2dy+\alpha_3dz$$ and noticed that $\alpha$ is non-vanishing. Indeed, if not, there exists a point $p\in M$ such that $\alpha_i(p)=0$ for $i=1,2,3$ . Computing $\omega=\alpha\wedge d\alpha$ , it follows that $\omega_p=0$ , a contradiction. Thus, because $\alpha\neq0$ , we get (by a theorem about $\alpha\wedge d\alpha$ ) that $\ker\alpha$ is not involutive, but I'm really not sure what I can do from here. I suppose that if we choose appropriate vector fields $X,Y\in\ker\alpha$ , we do get that $$d \alpha(X, Y)=X(\alpha(Y))-Y(\alpha(X))-\alpha([X, Y])=-\alpha([X,Y])$$ is non-zero. Alternatively, there is the usual expansion $$i_X(\alpha\wedge d\alpha)=i_X\alpha\wedge d\alpha-\alpha\wedge i_Xd\alpha,$$ which connects both the conditions that $i_X\alpha\equiv1$ and $i_Xd\alpha\equiv0$ with the contraction of a volume form, but again I'm not able see where this leads me. I'd really appreciate any help towards a full solution. I'm reviewing my knowledge of smooth manifold theory, so this problem is not homework (although it's from an old exam at my university). Thank you!","I'm currently stuck on the following problem: Let be a 1-form on a connected 3-manifold such that is a volume form. Show that there exists a vector field on such that and . I believe there are a few routes to solve this problem, but I keep getting stuck at each step. Working locally, I first wrote and noticed that is non-vanishing. Indeed, if not, there exists a point such that for . Computing , it follows that , a contradiction. Thus, because , we get (by a theorem about ) that is not involutive, but I'm really not sure what I can do from here. I suppose that if we choose appropriate vector fields , we do get that is non-zero. Alternatively, there is the usual expansion which connects both the conditions that and with the contraction of a volume form, but again I'm not able see where this leads me. I'd really appreciate any help towards a full solution. I'm reviewing my knowledge of smooth manifold theory, so this problem is not homework (although it's from an old exam at my university). Thank you!","\alpha M \alpha\wedge d\alpha X M i_X\alpha\equiv1 i_X(d\alpha)\equiv0 \alpha=\alpha_1dx+\alpha_2dy+\alpha_3dz \alpha p\in M \alpha_i(p)=0 i=1,2,3 \omega=\alpha\wedge d\alpha \omega_p=0 \alpha\neq0 \alpha\wedge d\alpha \ker\alpha X,Y\in\ker\alpha d \alpha(X, Y)=X(\alpha(Y))-Y(\alpha(X))-\alpha([X, Y])=-\alpha([X,Y]) i_X(\alpha\wedge d\alpha)=i_X\alpha\wedge d\alpha-\alpha\wedge i_Xd\alpha, i_X\alpha\equiv1 i_Xd\alpha\equiv0","['differential-geometry', 'smooth-manifolds', 'differential-forms', 'vector-fields']"
6,"Let $(M, g) = (\mathbb{R}^n , ds^2 = dr^2 +f^2(r)d\theta^2)$. Determine the Riemannian volume form of $M$.",Let . Determine the Riemannian volume form of .,"(M, g) = (\mathbb{R}^n , ds^2 = dr^2 +f^2(r)d\theta^2) M","Let $(M, g) = (\mathbb{R}^n , ds^2 = dr^2 +f^2(r)d\theta^2)$ where $d\theta^2$ is the induced Riemannian metric from $\mathbb{S}^{n-1}$ . Determine the Riemannian volume form of $M$ . The volume form is in local coordinates given by $$\omega = \sqrt |g| dx^1 \wedge \dots \wedge dx^n$$ so the whole problem reduces to finding $\sqrt{|g|}$ where $|g|$ is the absolute value of the determinant of the metric tensor. Now in this case $g = ds^2$ so we are trying to find the matrix representation for $ds^2$ . This is where I'm stuck I think we should end up with a matrix $g_{ij}$ , but since this depends on $d\theta^2$ also I don't know how to find this matrix. Any help would be appreciated.","Let where is the induced Riemannian metric from . Determine the Riemannian volume form of . The volume form is in local coordinates given by so the whole problem reduces to finding where is the absolute value of the determinant of the metric tensor. Now in this case so we are trying to find the matrix representation for . This is where I'm stuck I think we should end up with a matrix , but since this depends on also I don't know how to find this matrix. Any help would be appreciated.","(M, g) = (\mathbb{R}^n , ds^2 = dr^2 +f^2(r)d\theta^2) d\theta^2 \mathbb{S}^{n-1} M \omega = \sqrt |g| dx^1 \wedge \dots \wedge dx^n \sqrt{|g|} |g| g = ds^2 ds^2 g_{ij} d\theta^2","['differential-geometry', 'riemannian-geometry']"
7,Proving $\mathbb{R}P^n$ is orientable if and only if $n$ is odd.,Proving  is orientable if and only if  is odd.,\mathbb{R}P^n n,"Prove that $\mathbb{R}P^n$ is orientable if and only if $n$ is odd. I know this question has been asked many times on this site, but all solutions consist of $n$ forms or homology groups which I can't use. The definition of orientability I can use is: a manifold is orientable if it admits an atlas $(V_\alpha,\phi_\alpha)$ such that the transition maps have a Jacobi matrix with positive determinant. I was able to prove that the map $\alpha: S^n\to S^n$ defined by $\alpha(x)=-x$ is orientation preserving iff $n$ is odd. Moreover, if $\pi:S^n\to\mathbb{R}P^n$ is the projection, then $\alpha\circ\pi=\pi$ . I thought mayble I can somehow use this fact (without using the fac that $\pi$ is a covering map, since it hasn't been taught yet). Moreover, I have constructed specific atlas for the projective plane: $$\{\varphi_i:U_i\to\mathbb{R}^{n}\},\,U_i=\{(x_0:\ldots:x_{n}):x_i\neq0\}$$ defined by: $$\varphi_i(x_0:\ldots:x_{n})=(\frac{x_0}{x_i},\ldots,\frac{x_{i-1}}{x_i},\frac{x_{i+1}}{x_i},\ldots,\frac{x_{n}}{x_i})$$ and was able to find the transition maps, but calculating the determinant in the general case seemed too hard, and will not disprove the existence of orientation in the even case (maybe this is the way to go). Is there an elementary approach that uses the fact that $\alpha$ is orientation preserving and that $S^n$ is orientable, or given the restriction to use ""elementary"" methods only I have to calculate the determinant of the Jacobi matrix? Any help would be appreciated.","Prove that is orientable if and only if is odd. I know this question has been asked many times on this site, but all solutions consist of forms or homology groups which I can't use. The definition of orientability I can use is: a manifold is orientable if it admits an atlas such that the transition maps have a Jacobi matrix with positive determinant. I was able to prove that the map defined by is orientation preserving iff is odd. Moreover, if is the projection, then . I thought mayble I can somehow use this fact (without using the fac that is a covering map, since it hasn't been taught yet). Moreover, I have constructed specific atlas for the projective plane: defined by: and was able to find the transition maps, but calculating the determinant in the general case seemed too hard, and will not disprove the existence of orientation in the even case (maybe this is the way to go). Is there an elementary approach that uses the fact that is orientation preserving and that is orientable, or given the restriction to use ""elementary"" methods only I have to calculate the determinant of the Jacobi matrix? Any help would be appreciated.","\mathbb{R}P^n n n (V_\alpha,\phi_\alpha) \alpha: S^n\to S^n \alpha(x)=-x n \pi:S^n\to\mathbb{R}P^n \alpha\circ\pi=\pi \pi \{\varphi_i:U_i\to\mathbb{R}^{n}\},\,U_i=\{(x_0:\ldots:x_{n}):x_i\neq0\} \varphi_i(x_0:\ldots:x_{n})=(\frac{x_0}{x_i},\ldots,\frac{x_{i-1}}{x_i},\frac{x_{i+1}}{x_i},\ldots,\frac{x_{n}}{x_i}) \alpha S^n","['differential-geometry', 'manifolds', 'projective-space', 'orientation', 'non-orientable-surfaces']"
8,Question about Riemannian metrics,Question about Riemannian metrics,,"I was reading a pdf about geodesics on Riemannian manifolds, and I've found this proposition $\textbf{Proposition :}$ Let $(M,g)$ be a Riemannian manifold. For every point, $p \in M$ , in normal coordinates at $p$ , $$g\left(\frac{\partial}{\partial x_i}, \frac{\partial}{\partial x_j}\right)_p = \delta_{ij} \quad \text{and} \quad \Gamma^k_{ij}(p)=0.$$ Before this proposition there is the following statement: The following proposition shows that Riemannian metrics do not admit any local invariants of order one. What does it mean that a Riemannian metric does not admit any local invariants of some order ?","I was reading a pdf about geodesics on Riemannian manifolds, and I've found this proposition Let be a Riemannian manifold. For every point, , in normal coordinates at , Before this proposition there is the following statement: The following proposition shows that Riemannian metrics do not admit any local invariants of order one. What does it mean that a Riemannian metric does not admit any local invariants of some order ?","\textbf{Proposition :} (M,g) p \in M p g\left(\frac{\partial}{\partial x_i}, \frac{\partial}{\partial x_j}\right)_p = \delta_{ij} \quad \text{and} \quad \Gamma^k_{ij}(p)=0.","['differential-geometry', 'smooth-manifolds']"
9,Why do the ideas in Sheaf theory seem analogous to concepts of Manifold theory?,Why do the ideas in Sheaf theory seem analogous to concepts of Manifold theory?,,"I had this thought when studying ""Sheaf Theory through Examples"" by Daniel Rosiak. In the introduction, there is the exploration of how one can fit together data of different sensors observing the same space. Here is a picture from page-11, This system of mutually compatible local data assignments or “measurements” of the happenings on the space—where the various data assignments are, piece by piece, constrained by one another, and thereby patched together to supply an assignment over the entire space covered by the individual regions—is, in essence, what constitutes our sheaf. Hmm this feels like the motif we have in Differential Geometry where we chart Manifolds. And now consider this section about the motivation behind the name of Sheaf: Here one thinks of various regions as the parcels of an overall space covered by those pieces, the collection of which then serves as a site where certain happenings are held to take place, and the abstract sensors capturing local snapshots or measurements of all that is going on in each parcel are then regarded as being collected together into “stalks” of data, regarded as sitting over (or growing out of) the various parts of the ground space to which they are attached. A selection of a particular snapshot made from each of the intersecting regions) and collation (along unions of regions) of these sections captures how the various stalks of data are bound together. pg-12,13 And this seems like the concept of a bundle in Differential Geometry! What exactly is going on here? Is there a deep connection between Sheaf Theory and manifold Theory?","I had this thought when studying ""Sheaf Theory through Examples"" by Daniel Rosiak. In the introduction, there is the exploration of how one can fit together data of different sensors observing the same space. Here is a picture from page-11, This system of mutually compatible local data assignments or “measurements” of the happenings on the space—where the various data assignments are, piece by piece, constrained by one another, and thereby patched together to supply an assignment over the entire space covered by the individual regions—is, in essence, what constitutes our sheaf. Hmm this feels like the motif we have in Differential Geometry where we chart Manifolds. And now consider this section about the motivation behind the name of Sheaf: Here one thinks of various regions as the parcels of an overall space covered by those pieces, the collection of which then serves as a site where certain happenings are held to take place, and the abstract sensors capturing local snapshots or measurements of all that is going on in each parcel are then regarded as being collected together into “stalks” of data, regarded as sitting over (or growing out of) the various parts of the ground space to which they are attached. A selection of a particular snapshot made from each of the intersecting regions) and collation (along unions of regions) of these sections captures how the various stalks of data are bound together. pg-12,13 And this seems like the concept of a bundle in Differential Geometry! What exactly is going on here? Is there a deep connection between Sheaf Theory and manifold Theory?",,"['differential-geometry', 'manifolds', 'sheaf-theory']"
10,Abstract Index Notation Inconsistency (Technical - Answer in the Question),Abstract Index Notation Inconsistency (Technical - Answer in the Question),,"I am reading this great work here and I am trying to make sense of a specific derivation around the middle of the page. In particular, it seems they are claiming that: $(\nabla_v w) (f) = (v^{\alpha} \nabla_{\alpha} w^{\beta})\nabla_{\beta}f$ where we work on a smooth manifold $M$ , $v, w$ are smooth vector fields (i.e. sections of the tangent bundle $\mathcal{T}(M)$ ), $f$ is a scalar function and $\nabla$ is the connection on $\mathcal{T}(M)$ . My understanding is that they are using abstract index notation. But when I consider, for simplicity, a local set of coordinates with a local basis $e_i := \frac{\partial}{\partial x^i}$ I get a seemingly different answer. Specifically, if we write $v = v^i e_i$ and $w = w^j e_j$ one gets: $(\nabla_v w) (f) = \left(\left(v^i \nabla_{e_i} w^k + v^iw^j \Gamma_{ij}^k \right)e_k\right)(f) =  \left(v^i \nabla_{e_i} w^k + v^iw^j \Gamma_{ij}^k \right)\nabla_{e_k} f :=(\nabla_v w)^k \nabla_{e_k} f$ where $(\nabla_v w)^k$ means the $k$ -th component of the vector $\nabla_v w$ in local coordinates. So my answer seems to be: $(\nabla_v w) (f) = \left(v^i \nabla_{e_i} w^k\right) \nabla_{e_k} f + \left(v^iw^j \Gamma_{ij}^k \right)\nabla_{e_k} f$ But if their derivation is correct and I am interpreting abstract notation properly, it seems like I should instead be getting: $ (\nabla_v w) (f) = \left(v^i \nabla_{e_i} w^k\right) \nabla_{e_k} f$ What am I missing? Edit: I wish I could accept multiple answers. Huge Credit to @peek-a-boo and @Jackozee Hakkiuz for adding incredible insight to the problem. If anyone is reading this in the future, I highly recommend going over both answers. Edit2: Also for those future readers, I highly suggest this high level debate here . One thing it illustrates clearly is that quantities like $\nabla_{\alpha} w^{\beta}$ are a priori ill-defined which can lead to understandable confusion. As a result, certain notational conventions are required, ones which are often author dependent. This makes it especially challenging for anyone who approaches the topic using different sources, since finding notational inconsistencies is almost inevitable. Edit3: For my own clarity I would also like to give a formal answer that bridges the gap between the two notations, so here it goes: $\underline{\textbf{(A posteriori) ANSWER:}}$ Let $\nabla_{\alpha} w^{\beta}:= (\nabla w)_{\alpha}^{\beta}$ be the placeholder (abstract) notation for the $(1,1)$ -tensor field $\nabla w$ (said differently, in local coordinates $(\nabla w)_{\alpha}^{\beta}$ corresponds to $(\nabla w)_{k}^{i} (e_i \otimes \epsilon^k)$ or $(\nabla w)_{k}^{i} e_i \epsilon^k$ for short). We will see that this notation is consistent with the numerical one (i.e. the one in local coordinates). The setup is the same as above but we also add a local co-basis $\epsilon^j := dx^j$ . We observe the following: $v = v^k e_k$ (as a $(1,0)$ -tensor field, aka a vector field) $\nabla w = (\nabla w)^i_j e_i \epsilon^j$ (as a $(1,1)$ -tensor field) $e_i (f) = \nabla_{e_i} f$ (by definition) $\nabla_v w = (\nabla w)(v)$ (by definition) One can then perform the following calculations: $$(\nabla_v w)(f) = ((\nabla w)(v))(f) = ((\nabla w)^i_j e_i \epsilon^j v^k e_k)(f) = (v^k(\nabla w)^i_k) e_i(f) = (v^k(\nabla w)^i_k) \nabla_{e_i}f$$ which is ""consistent"" with the abstract index notation of: $$(\nabla_v w)(f) = (v^{\alpha} \nabla_{\alpha} w^{\beta})\nabla_{\beta}f = (v^{\alpha} (\nabla w)_{\alpha}^{\beta}) \nabla_{\beta}f$$ $\underline{\textbf{The Subtleties:}}$ There are some subtleties here, I feel they need to be addressed: The first one is that in some sense we got ""lucky"" that the two expressions (abstract and numerical) seem to match each other one to one (symbol-wise). This is due to the fact that both results above, correspond to scalars so there are no implicit vectors/covectors ""leftover"" as implied from the abstract notation. To see this explicitly, observe the following correspondences between the two notations: $v^{\alpha} \leftrightarrow v^k e_k$ $(\nabla w)_{\alpha}^{\beta} \leftrightarrow (\nabla w)_{l}^{i}e_i \epsilon^l$ $\nabla_{\beta} f \leftrightarrow (\nabla_{e_m} f) \epsilon^m $ This means that when we put everything together we get: $$ (v^{\alpha} (\nabla w)_{\alpha}^{\beta}) \nabla_{\beta}f \leftrightarrow (v^k e_k (\nabla w)_{l}^{i}e_i \epsilon^l) ((\nabla_{e_m} f) \epsilon^m) = (v^k  (\nabla w)_{l}^{i} \nabla_{e_m} f) e_k e_i \epsilon^l \epsilon^m = (v^k  (\nabla w)_{k}^{i}) \nabla_{e_i} f $$ Thus, it is only because we have the perfect amount of contractions (i.e. the final result is a $(0,0)$ -tensor (aka. a scalar)) that the two notations ""match"" each other. In the general case, the two notations will not match one another as (in some sense) the abstract notation ""implies"" the basis vectors while the regular one does not . (For example, even though $v^{\alpha} \leftrightarrow v^k e_k$ , the two expressions are not in a ""perfect"" one to one notational correspondence, symbol-wise). Ambiguity can be eliminated . If one uses correspondences analogous to the ones seen above, ambiguities can be eliminated. This is best seen by performing calculations on different parentheses placements. For example, we know that in local coordinates: $$\nabla_v w = v^i \nabla_{e_i} (w^k e_k) = v^i (\nabla_{e_i} w)^k e_k $$ where $ \nabla_{e_i} w = \left(\frac{\partial w^k}{\partial x^i} + w^j \Gamma_{ij}^k \right) e_k$ so that $ (\nabla_{e_i} w)^k = \frac{\partial w^k}{\partial x^i} + w^j \Gamma_{ij}^k$ . But then, one can calculate $v^{\alpha}\nabla_{\alpha} w^{\beta}$ in three different ways: $$\boxed{v^{\alpha} (\nabla_{\alpha} w)^{\beta} \leftrightarrow v^i (\nabla_{e_i} w)^k e_k = \nabla_v w}$$ $$\boxed{ v^{\alpha} (\nabla w)_{\alpha}^{\beta} \leftrightarrow v^i (\nabla w)^k_i e_k = \nabla_v w }$$ $$\boxed{ v^{\alpha} (\nabla_{\alpha}w^{\beta}) \leftrightarrow v^i (\nabla_{e_i}( w^k e_k))= v^i(\nabla_{e_i} w)^k e_k = \nabla_v w }$$ This means that the notation $v^{\alpha}\nabla_{\alpha} w^{\beta}$ is (a posteriori) unambiguous . Some ambiguity can still arise (if one is not careful). For example, take the notation $\nabla_{\alpha} w^{\beta}$ with one covariant and one contravariant index. In local coordinates, does it correspond to $(\nabla_{e_i} (w^k e_k)) \epsilon^i$ or $(\nabla_{e_i} w^k) \epsilon^i e_k$ ? In other words, where should the ""implied"" basis vectors go? Unless we create some notion of priority of operation, we will have an unbridgeable ambiguity, since the two expressions above are different. However, loosely speaking, the operator $\nabla$ acts on the vector $w$ after it is made ""whole"" (i.e. after we make the correspondence $w^{\beta} \leftrightarrow w^k e_k$ ), so we need to put the implied basis vectors $e_k$ first: $$\nabla_{\alpha} w^{\beta} \leftrightarrow (\nabla_{e_i} (w^k e_k)) \epsilon^i = (\nabla_{e_i} w)^k e_k \epsilon^i$$ Similarly, the hessian of a smooth scalar function has a unique correspondence in local coordinates, given by: $$\color{red}{\nabla_{\alpha} \nabla_{\beta} f \leftrightarrow (\nabla_{e_i} [(\nabla_{e_j} f) \epsilon^j])\epsilon^i} = \dots = [(\partial_i \partial_j f)  - (\partial_k f)\Gamma_{ij}^k]\epsilon^j\epsilon^i  $$ From there, we can derive the expression of the Torsion (defined by $T(f) = (\nabla_{\alpha} \nabla_{\beta} - \nabla_{\beta} \nabla_{\alpha}) (f)$ ) when acting on the scalar : $$T(f) = [(\Gamma_{ij}^k - \Gamma_{ji}^k) - [e_i, e_j]^k](\partial_k f)\epsilon^i \epsilon^j $$ And also the expression for Torsion itself as a (1,2) vector field: $$\boxed{T = [(\Gamma_{ij}^k - \Gamma_{ji}^k) - [e_i, e_j]^k]\epsilon^i \epsilon^j e_k} $$","I am reading this great work here and I am trying to make sense of a specific derivation around the middle of the page. In particular, it seems they are claiming that: where we work on a smooth manifold , are smooth vector fields (i.e. sections of the tangent bundle ), is a scalar function and is the connection on . My understanding is that they are using abstract index notation. But when I consider, for simplicity, a local set of coordinates with a local basis I get a seemingly different answer. Specifically, if we write and one gets: where means the -th component of the vector in local coordinates. So my answer seems to be: But if their derivation is correct and I am interpreting abstract notation properly, it seems like I should instead be getting: What am I missing? Edit: I wish I could accept multiple answers. Huge Credit to @peek-a-boo and @Jackozee Hakkiuz for adding incredible insight to the problem. If anyone is reading this in the future, I highly recommend going over both answers. Edit2: Also for those future readers, I highly suggest this high level debate here . One thing it illustrates clearly is that quantities like are a priori ill-defined which can lead to understandable confusion. As a result, certain notational conventions are required, ones which are often author dependent. This makes it especially challenging for anyone who approaches the topic using different sources, since finding notational inconsistencies is almost inevitable. Edit3: For my own clarity I would also like to give a formal answer that bridges the gap between the two notations, so here it goes: Let be the placeholder (abstract) notation for the -tensor field (said differently, in local coordinates corresponds to or for short). We will see that this notation is consistent with the numerical one (i.e. the one in local coordinates). The setup is the same as above but we also add a local co-basis . We observe the following: (as a -tensor field, aka a vector field) (as a -tensor field) (by definition) (by definition) One can then perform the following calculations: which is ""consistent"" with the abstract index notation of: There are some subtleties here, I feel they need to be addressed: The first one is that in some sense we got ""lucky"" that the two expressions (abstract and numerical) seem to match each other one to one (symbol-wise). This is due to the fact that both results above, correspond to scalars so there are no implicit vectors/covectors ""leftover"" as implied from the abstract notation. To see this explicitly, observe the following correspondences between the two notations: This means that when we put everything together we get: Thus, it is only because we have the perfect amount of contractions (i.e. the final result is a -tensor (aka. a scalar)) that the two notations ""match"" each other. In the general case, the two notations will not match one another as (in some sense) the abstract notation ""implies"" the basis vectors while the regular one does not . (For example, even though , the two expressions are not in a ""perfect"" one to one notational correspondence, symbol-wise). Ambiguity can be eliminated . If one uses correspondences analogous to the ones seen above, ambiguities can be eliminated. This is best seen by performing calculations on different parentheses placements. For example, we know that in local coordinates: where so that . But then, one can calculate in three different ways: This means that the notation is (a posteriori) unambiguous . Some ambiguity can still arise (if one is not careful). For example, take the notation with one covariant and one contravariant index. In local coordinates, does it correspond to or ? In other words, where should the ""implied"" basis vectors go? Unless we create some notion of priority of operation, we will have an unbridgeable ambiguity, since the two expressions above are different. However, loosely speaking, the operator acts on the vector after it is made ""whole"" (i.e. after we make the correspondence ), so we need to put the implied basis vectors first: Similarly, the hessian of a smooth scalar function has a unique correspondence in local coordinates, given by: From there, we can derive the expression of the Torsion (defined by ) when acting on the scalar : And also the expression for Torsion itself as a (1,2) vector field:","(\nabla_v w) (f) = (v^{\alpha} \nabla_{\alpha} w^{\beta})\nabla_{\beta}f M v, w \mathcal{T}(M) f \nabla \mathcal{T}(M) e_i := \frac{\partial}{\partial x^i} v = v^i e_i w = w^j e_j (\nabla_v w) (f) = \left(\left(v^i \nabla_{e_i} w^k + v^iw^j \Gamma_{ij}^k \right)e_k\right)(f) =  \left(v^i \nabla_{e_i} w^k + v^iw^j \Gamma_{ij}^k \right)\nabla_{e_k} f :=(\nabla_v w)^k \nabla_{e_k} f (\nabla_v w)^k k \nabla_v w (\nabla_v w) (f) = \left(v^i \nabla_{e_i} w^k\right) \nabla_{e_k} f + \left(v^iw^j \Gamma_{ij}^k \right)\nabla_{e_k} f  (\nabla_v w) (f) = \left(v^i \nabla_{e_i} w^k\right) \nabla_{e_k} f \nabla_{\alpha} w^{\beta} \underline{\textbf{(A posteriori) ANSWER:}} \nabla_{\alpha} w^{\beta}:= (\nabla w)_{\alpha}^{\beta} (1,1) \nabla w (\nabla w)_{\alpha}^{\beta} (\nabla w)_{k}^{i} (e_i \otimes \epsilon^k) (\nabla w)_{k}^{i} e_i \epsilon^k \epsilon^j := dx^j v = v^k e_k (1,0) \nabla w = (\nabla w)^i_j e_i \epsilon^j (1,1) e_i (f) = \nabla_{e_i} f \nabla_v w = (\nabla w)(v) (\nabla_v w)(f) = ((\nabla w)(v))(f) = ((\nabla w)^i_j e_i \epsilon^j v^k e_k)(f) = (v^k(\nabla w)^i_k) e_i(f) = (v^k(\nabla w)^i_k) \nabla_{e_i}f (\nabla_v w)(f) = (v^{\alpha} \nabla_{\alpha} w^{\beta})\nabla_{\beta}f = (v^{\alpha} (\nabla w)_{\alpha}^{\beta}) \nabla_{\beta}f \underline{\textbf{The Subtleties:}} v^{\alpha} \leftrightarrow v^k e_k (\nabla w)_{\alpha}^{\beta} \leftrightarrow (\nabla w)_{l}^{i}e_i \epsilon^l \nabla_{\beta} f \leftrightarrow (\nabla_{e_m} f) \epsilon^m   (v^{\alpha} (\nabla w)_{\alpha}^{\beta}) \nabla_{\beta}f \leftrightarrow (v^k e_k (\nabla w)_{l}^{i}e_i \epsilon^l) ((\nabla_{e_m} f) \epsilon^m) = (v^k  (\nabla w)_{l}^{i} \nabla_{e_m} f) e_k e_i \epsilon^l \epsilon^m = (v^k  (\nabla w)_{k}^{i}) \nabla_{e_i} f  (0,0) v^{\alpha} \leftrightarrow v^k e_k \nabla_v w = v^i \nabla_{e_i} (w^k e_k) = v^i (\nabla_{e_i} w)^k e_k   \nabla_{e_i} w = \left(\frac{\partial w^k}{\partial x^i} + w^j \Gamma_{ij}^k \right) e_k  (\nabla_{e_i} w)^k = \frac{\partial w^k}{\partial x^i} + w^j \Gamma_{ij}^k v^{\alpha}\nabla_{\alpha} w^{\beta} \boxed{v^{\alpha} (\nabla_{\alpha} w)^{\beta} \leftrightarrow v^i (\nabla_{e_i} w)^k e_k = \nabla_v w} \boxed{ v^{\alpha} (\nabla w)_{\alpha}^{\beta} \leftrightarrow v^i (\nabla w)^k_i e_k = \nabla_v w } \boxed{ v^{\alpha} (\nabla_{\alpha}w^{\beta}) \leftrightarrow v^i (\nabla_{e_i}( w^k e_k))= v^i(\nabla_{e_i} w)^k e_k = \nabla_v w } v^{\alpha}\nabla_{\alpha} w^{\beta} \nabla_{\alpha} w^{\beta} (\nabla_{e_i} (w^k e_k)) \epsilon^i (\nabla_{e_i} w^k) \epsilon^i e_k \nabla w w^{\beta} \leftrightarrow w^k e_k e_k \nabla_{\alpha} w^{\beta} \leftrightarrow (\nabla_{e_i} (w^k e_k)) \epsilon^i = (\nabla_{e_i} w)^k e_k \epsilon^i \color{red}{\nabla_{\alpha} \nabla_{\beta} f \leftrightarrow (\nabla_{e_i} [(\nabla_{e_j} f) \epsilon^j])\epsilon^i} = \dots = [(\partial_i \partial_j f)  - (\partial_k f)\Gamma_{ij}^k]\epsilon^j\epsilon^i   T(f) = (\nabla_{\alpha} \nabla_{\beta} - \nabla_{\beta} \nabla_{\alpha}) (f) T(f) = [(\Gamma_{ij}^k - \Gamma_{ji}^k) - [e_i, e_j]^k](\partial_k f)\epsilon^i \epsilon^j  \boxed{T = [(\Gamma_{ij}^k - \Gamma_{ji}^k) - [e_i, e_j]^k]\epsilon^i \epsilon^j e_k} ","['differential-geometry', 'mathematical-physics', 'connections', 'index-notation', 'tangent-bundle']"
11,How much Differential Geometry do you need to do PDE?,How much Differential Geometry do you need to do PDE?,,"Ever since I took functional analysis and I read in Brezis's famous book how to apply this to PDE I have been extremely interested in PDE and I have kept reading more and more of the standard material on PDE. This is all, of course, in $\mathbb{R}^n$ , so you don't really need to know any differential geometry, but I saw that there are people doing PDE on Riemannian manifolds for instance. I for one am not a big differential geometry fan, I do know the basics, but I don't enjoy it much and I am not really eager to study it further. However, I can't help but wonder if I am going to enocunter differential geometry if I am going to further study PDE and whether it would be helpful to improve my background in differential geometry if PDE is what I am interested in. Disclaimer: I am well aware of the fact that PDE has many subfields and one of them is even called ""Geometric PDE"" (or Geometric analysis if you prefer) and is basically a field that deals precisely with what I am trying to ""run away"" from, but my question is more of the sort ""do all PDE involve differential geometry if you immerse yourself deep enough into their study?"".","Ever since I took functional analysis and I read in Brezis's famous book how to apply this to PDE I have been extremely interested in PDE and I have kept reading more and more of the standard material on PDE. This is all, of course, in , so you don't really need to know any differential geometry, but I saw that there are people doing PDE on Riemannian manifolds for instance. I for one am not a big differential geometry fan, I do know the basics, but I don't enjoy it much and I am not really eager to study it further. However, I can't help but wonder if I am going to enocunter differential geometry if I am going to further study PDE and whether it would be helpful to improve my background in differential geometry if PDE is what I am interested in. Disclaimer: I am well aware of the fact that PDE has many subfields and one of them is even called ""Geometric PDE"" (or Geometric analysis if you prefer) and is basically a field that deals precisely with what I am trying to ""run away"" from, but my question is more of the sort ""do all PDE involve differential geometry if you immerse yourself deep enough into their study?"".",\mathbb{R}^n,"['differential-geometry', 'partial-differential-equations', 'reference-request', 'self-learning']"
12,parallel transport $w$ along $\gamma$: Explicit computation,parallel transport  along : Explicit computation,w \gamma,"Let $S^2 = \{(x,y,z) \in \mathbb{R}^3 | x^2 + y^2 +z^2 =1\}$ . For fixed $t \in [0,1)$ consider the curve $\gamma(t) = (r\cos(t), r\sin(t), \sqrt{1-r^2})$ , $t\in [0,2\pi]$ . Take $w\in T_{\gamma(0)} S^2$ . I want to compute the parallel transport $w$ along $\gamma$ . Naively I know parallel transport $w$ along $\gamma$ as follow: Let $x(u,v) = \gamma(t)$ , then $w = ax_u + b x_v$ , then \begin{align}   \frac{Dw}{dt} &= \left(a' + \Gamma^1{}_{11} au' + \Gamma^1{}_{12} av' + \Gamma^{1}{}_{12} bu' + \Gamma^1{}_{22} bv' \right) x_u  \\   & \quad + \left( b'+ \Gamma^2{}_{11} au' + \Gamma^2{}_{12} a v' + \Gamma^2{}_{12} bu' + \Gamma^2{}_{22} bv' \right) x_v  \end{align} where $\Gamma^{i}{}_{jk}$ are Chritoffel symobl. So assuming my Riemannian metric as $ds^2=dx^2+dy^2+dz^2 = r^2dr^2+ r^2\sin^2(\theta) d\theta^2$ , I can compute $\Gamma$ . But I am having trouble computing $v$ and corresponding $a,b$ . Since $w \in T_{\gamma(0)} S^2$ , I guess $w$ should pass through the point $\gamma(0) = (r,0,\sqrt{1-r^2})$ From $x(u,v) = \gamma(t) = (r\cos(t),r\sin(t),\sqrt{1-r^2})$ , Can I idenitfy $(u,v) = (r,t)$ ? But in this case $u$ is independent of $t$ so my $u'$ all vanishes... Is my approach correct? (How to formulate $a,b$ out of $\gamma(t)$ ?) I am familiar with the covariant derivatives acting on tensors, $\nabla_{\mu} x^{\nu} = \partial_{\mu} x^{\nu} + \Gamma^{\nu}{}_{\mu \rho} x^{\rho}$ like in General relativity, but not familiar with these differential geometry notations so having trouble expliict computations.","Let . For fixed consider the curve , . Take . I want to compute the parallel transport along . Naively I know parallel transport along as follow: Let , then , then where are Chritoffel symobl. So assuming my Riemannian metric as , I can compute . But I am having trouble computing and corresponding . Since , I guess should pass through the point From , Can I idenitfy ? But in this case is independent of so my all vanishes... Is my approach correct? (How to formulate out of ?) I am familiar with the covariant derivatives acting on tensors, like in General relativity, but not familiar with these differential geometry notations so having trouble expliict computations.","S^2 = \{(x,y,z) \in \mathbb{R}^3 | x^2 + y^2 +z^2 =1\} t \in [0,1) \gamma(t) = (r\cos(t), r\sin(t), \sqrt{1-r^2}) t\in [0,2\pi] w\in T_{\gamma(0)} S^2 w \gamma w \gamma x(u,v) = \gamma(t) w = ax_u + b x_v \begin{align}
  \frac{Dw}{dt} &= \left(a' + \Gamma^1{}_{11} au' + \Gamma^1{}_{12} av' + \Gamma^{1}{}_{12} bu' + \Gamma^1{}_{22} bv' \right) x_u  \\
  & \quad + \left( b'+ \Gamma^2{}_{11} au' + \Gamma^2{}_{12} a v' + \Gamma^2{}_{12} bu' + \Gamma^2{}_{22} bv' \right) x_v 
\end{align} \Gamma^{i}{}_{jk} ds^2=dx^2+dy^2+dz^2 = r^2dr^2+ r^2\sin^2(\theta) d\theta^2 \Gamma v a,b w \in T_{\gamma(0)} S^2 w \gamma(0) = (r,0,\sqrt{1-r^2}) x(u,v) = \gamma(t) = (r\cos(t),r\sin(t),\sqrt{1-r^2}) (u,v) = (r,t) u t u' a,b \gamma(t) \nabla_{\mu} x^{\nu} = \partial_{\mu} x^{\nu} + \Gamma^{\nu}{}_{\mu \rho} x^{\rho}","['differential-geometry', 'riemannian-geometry', 'connections']"
13,Can a sphere with dimension $2$ admit locally negative curvature？,Can a sphere with dimension  admit locally negative curvature？,2,"I know that by the Cartan-Hadamard theorem the sphere cannot admit a global negative curvature, which can also be proved by the Gauss-Bonnet formula. But can we equip the sphere with a metric such that its curvature is negative at some point？","I know that by the Cartan-Hadamard theorem the sphere cannot admit a global negative curvature, which can also be proved by the Gauss-Bonnet formula. But can we equip the sphere with a metric such that its curvature is negative at some point？",,"['differential-geometry', 'riemannian-geometry']"
14,Is there a name for generalized manifolds?,Is there a name for generalized manifolds?,,"A topological manifold is a topological space which locally resembles real $n$ -dimensional Euclidean space. Here I consider removing `Euclidean' from manifold: Suppose that $X$ is a topological space, and $M$ is a topological space which locally resembles $X$ , i.e. for each $p\in M$ , there is an open neighborhood $U$ of $p$ in $M$ , an open set $V$ in $X$ , and a homeomorphism $\varphi: U\rightarrow V$ . Is there a name for $M$ ? And is there a book about orbifolds for beginners? I only know some basic concepts of differential manifolds.","A topological manifold is a topological space which locally resembles real -dimensional Euclidean space. Here I consider removing `Euclidean' from manifold: Suppose that is a topological space, and is a topological space which locally resembles , i.e. for each , there is an open neighborhood of in , an open set in , and a homeomorphism . Is there a name for ? And is there a book about orbifolds for beginners? I only know some basic concepts of differential manifolds.",n X M X p\in M U p M V X \varphi: U\rightarrow V M,"['differential-geometry', 'noneuclidean-geometry']"
15,Geodesic flow are generated by Hamiltonian vector field,Geodesic flow are generated by Hamiltonian vector field,,"Let $(M,g)$ be a Riemannian manifold and consider the Hamiltonian \begin{equation*}     \begin{array}{rcl}         H:T^*M & \rightarrow&\mathbb{R} \\         (q,p) & \mapsto&H(q,p):=\frac{1}{2}g^{ij}(q)p_ip_j.     \end{array} \end{equation*} We would like to show that the Hamiltonian vector field $X_H:T^*M\rightarrow TT^*M$ generates the geodesic flow. We can explicitely compute $X_H$ , since its components satisfies Hamilton's equations: \begin{equation*}     X_H=\dfrac{\partial H}{\partial p_j}\dfrac{\partial}{\partial q^j}-\dfrac{\partial H}{\partial q^j}\dfrac{\partial}{\partial p_k}=g^{ij}p_i\dfrac{\partial}{\partial q^j}-\frac{1}{2}\dfrac{\partial g^{ij}}{\partial q^k}p_ip_j\dfrac{\partial}{\partial p_k}. \end{equation*} We can see that the following vector field $Y:TM\rightarrow TTM$ , over $TM$ generates the geodesic flow: \begin{equation*}     Y(q,\dot{q}):=\dot{q}^i\dfrac{\partial}{\partial q^i}-\Gamma^j_{lk}\dot{q}^l\dot{q}^k\dfrac{\partial}{\partial\dot{q}^j}. \end{equation*} Indeed, we show that its integral curves are geodesics. Let $\gamma:\mathcal{I}\rightarrow TM$ , with $\gamma(t):=(\alpha(t),\beta(t))$ , then \begin{equation*}  \dot{\gamma}(t)=\dot{\alpha}^i(t)\dfrac{\partial}{\partial q^i}+\dot{\beta}^j(t)\dfrac{\partial}{\partial\dot{q}^j},    \end{equation*} so $Y(\gamma(t))=\dot{\gamma}(t)$ $\iff$ the following hold \begin{equation*}     \left\{\begin{array}{ll}          \dot{\alpha}^i(t)=\beta^i(t)&  \\          \dot{\beta}^j(t)=-\Gamma^j_{lk}\beta^l(t)\beta^k(t)&      \end{array}\right. \end{equation*} This is the geodesic equation and so this proves that the integral curves of $Y$ are geodesics. The problem is that $Y$ is a vector field over $TM$ , while in the Hamiltonian formalism, $X_H$ is a vector field over $T^*M$ . How are $X_H$ and $Y$ related? How can we show that $X_H$ generates the geodesic flow as $Y$ does? Thank you all. P.S. It is enough to show that the integral curves of $X_H$ satisfies the geodesic equation in the cotangent bundle? But then, what does it look like in the cotangent bundle?","Let be a Riemannian manifold and consider the Hamiltonian We would like to show that the Hamiltonian vector field generates the geodesic flow. We can explicitely compute , since its components satisfies Hamilton's equations: We can see that the following vector field , over generates the geodesic flow: Indeed, we show that its integral curves are geodesics. Let , with , then so the following hold This is the geodesic equation and so this proves that the integral curves of are geodesics. The problem is that is a vector field over , while in the Hamiltonian formalism, is a vector field over . How are and related? How can we show that generates the geodesic flow as does? Thank you all. P.S. It is enough to show that the integral curves of satisfies the geodesic equation in the cotangent bundle? But then, what does it look like in the cotangent bundle?","(M,g) \begin{equation*}
    \begin{array}{rcl}
        H:T^*M & \rightarrow&\mathbb{R} \\
        (q,p) & \mapsto&H(q,p):=\frac{1}{2}g^{ij}(q)p_ip_j.
    \end{array}
\end{equation*} X_H:T^*M\rightarrow TT^*M X_H \begin{equation*}
    X_H=\dfrac{\partial H}{\partial p_j}\dfrac{\partial}{\partial q^j}-\dfrac{\partial H}{\partial q^j}\dfrac{\partial}{\partial p_k}=g^{ij}p_i\dfrac{\partial}{\partial q^j}-\frac{1}{2}\dfrac{\partial g^{ij}}{\partial q^k}p_ip_j\dfrac{\partial}{\partial p_k}.
\end{equation*} Y:TM\rightarrow TTM TM \begin{equation*}
    Y(q,\dot{q}):=\dot{q}^i\dfrac{\partial}{\partial q^i}-\Gamma^j_{lk}\dot{q}^l\dot{q}^k\dfrac{\partial}{\partial\dot{q}^j}.
\end{equation*} \gamma:\mathcal{I}\rightarrow TM \gamma(t):=(\alpha(t),\beta(t)) \begin{equation*}
 \dot{\gamma}(t)=\dot{\alpha}^i(t)\dfrac{\partial}{\partial q^i}+\dot{\beta}^j(t)\dfrac{\partial}{\partial\dot{q}^j},   
\end{equation*} Y(\gamma(t))=\dot{\gamma}(t) \iff \begin{equation*}
    \left\{\begin{array}{ll}
         \dot{\alpha}^i(t)=\beta^i(t)&  \\
         \dot{\beta}^j(t)=-\Gamma^j_{lk}\beta^l(t)\beta^k(t)& 
    \end{array}\right.
\end{equation*} Y Y TM X_H T^*M X_H Y X_H Y X_H","['differential-geometry', 'riemannian-geometry', 'hamilton-equations']"
16,"Corollary 5.39, Lee - Introduction to Smooth Manifolds","Corollary 5.39, Lee - Introduction to Smooth Manifolds",,"I am struggling with understanding how to prove Corollary 5.39 in Lee - Introduction to Smooth Manifolds . I found an answer on this post: A characterization of tangent space to level set of a smooth submersion , but I do not understand the computation done there. Why do we have $d\Phi_p^i(v) = v\Phi^i$ ? By definition of the pushforward, for $f \in C^\infty(\mathbb{R})$ we have $d\Phi_p^i(v)f = v(f\circ\Phi^i).$ But by the linked answer, it seems we would also have $d\Phi_p^i(v)f = (v\Phi^i)f$ . But $(v\Phi^i)f \in C^\infty(\mathbb{R})$ , not $\mathbb{R}$ . What am I missing here?","I am struggling with understanding how to prove Corollary 5.39 in Lee - Introduction to Smooth Manifolds . I found an answer on this post: A characterization of tangent space to level set of a smooth submersion , but I do not understand the computation done there. Why do we have ? By definition of the pushforward, for we have But by the linked answer, it seems we would also have . But , not . What am I missing here?",d\Phi_p^i(v) = v\Phi^i f \in C^\infty(\mathbb{R}) d\Phi_p^i(v)f = v(f\circ\Phi^i). d\Phi_p^i(v)f = (v\Phi^i)f (v\Phi^i)f \in C^\infty(\mathbb{R}) \mathbb{R},"['differential-geometry', 'manifolds', 'differential-topology', 'smooth-manifolds']"
17,Existence of a vector field on a Riemannian manifold,Existence of a vector field on a Riemannian manifold,,"Let $(M,g,\nabla)$ be a Riemannian manifold with metric $g$ and Riemannian connection $\nabla$ . Let $f$ be a positive function on $M$ . Does there exist a vector field $Z$ such $$\frac{1}{f}\nabla_X\operatorname{grad} f=\nabla_XZ$$ I am looking for a complete existence result or non-existence result. I tried $Z=\operatorname{grad}\operatorname{log} f$ and I got $$\nabla_XZ=\nabla_X (\operatorname{grad}  \operatorname{log} f)=\nabla_X (\frac1f\operatorname{grad}  f)=\frac1f\nabla_X (\operatorname{grad}  f)-X(f) \frac1{f^2}(\operatorname{grad}  f)$$ Thanks in advance.",Let be a Riemannian manifold with metric and Riemannian connection . Let be a positive function on . Does there exist a vector field such I am looking for a complete existence result or non-existence result. I tried and I got Thanks in advance.,"(M,g,\nabla) g \nabla f M Z \frac{1}{f}\nabla_X\operatorname{grad} f=\nabla_XZ Z=\operatorname{grad}\operatorname{log} f \nabla_XZ=\nabla_X (\operatorname{grad}  \operatorname{log} f)=\nabla_X (\frac1f\operatorname{grad}  f)=\frac1f\nabla_X (\operatorname{grad}  f)-X(f) \frac1{f^2}(\operatorname{grad}  f)","['differential-geometry', 'riemannian-geometry']"
18,Is the kernel of a differential form a subset of $M$ or of $TM$?,Is the kernel of a differential form a subset of  or of ?,M TM,"What do we mean by the ""kernel of a differential 1-form""? In particular, if $\alpha$ is a 1-form on $M$ , then I understand that it takes points $p\in M$ to functionals $\alpha_p:T_pM\to\mathbb R$ . So is the kernel of $\alpha$ the set of points $p\in M$ such that $\alpha_p$ is the zero map, or is $\ker\alpha$ actually the set of vectors $v$ in $TM$ such that $\alpha_p(v)=0$ for the appropriate $p$ ? I ask this mostly because I would've expected $\ker\alpha$ to be the first one, but I also saw somewhere that the kernel of the 1-form is a 2-plane distribution (which doesn't make any sense if $\ker\alpha\subseteq M$ , of course). (Also, sorry if something like this has been posted before; I saw some similar-looking posts, but I'm still a bit shaky with differential forms, so I had a lot of trouble understanding them.)","What do we mean by the ""kernel of a differential 1-form""? In particular, if is a 1-form on , then I understand that it takes points to functionals . So is the kernel of the set of points such that is the zero map, or is actually the set of vectors in such that for the appropriate ? I ask this mostly because I would've expected to be the first one, but I also saw somewhere that the kernel of the 1-form is a 2-plane distribution (which doesn't make any sense if , of course). (Also, sorry if something like this has been posted before; I saw some similar-looking posts, but I'm still a bit shaky with differential forms, so I had a lot of trouble understanding them.)",\alpha M p\in M \alpha_p:T_pM\to\mathbb R \alpha p\in M \alpha_p \ker\alpha v TM \alpha_p(v)=0 p \ker\alpha \ker\alpha\subseteq M,"['differential-geometry', 'differential-forms']"
19,Definition of Poisson Bracket,Definition of Poisson Bracket,,"Context : Let $f,g :T^*M\rightarrow \mathbb{R}$ , the Poisson Bracket was defined classically as $$\{f,g\}=\sum\limits_{i=1}^n\frac{\partial f}{\partial q^i}\frac{\partial g}{\partial p_i}-\frac{\partial f}{\partial p_i}\frac{\partial g}{\partial q^i}$$ But this definition depends of a choice of canonical coordinates $(q,p)$ and that is my problem: Question : How can I prove this definition is actually well-defined? Thanks in advance for any help or any recommendation to read about.","Context : Let , the Poisson Bracket was defined classically as But this definition depends of a choice of canonical coordinates and that is my problem: Question : How can I prove this definition is actually well-defined? Thanks in advance for any help or any recommendation to read about.","f,g :T^*M\rightarrow \mathbb{R} \{f,g\}=\sum\limits_{i=1}^n\frac{\partial f}{\partial q^i}\frac{\partial g}{\partial p_i}-\frac{\partial f}{\partial p_i}\frac{\partial g}{\partial q^i} (q,p)","['differential-geometry', 'reference-request', 'smooth-manifolds', 'classical-mechanics', 'poisson-geometry']"
20,What is wrong with this proof of Cartan's second equation?,What is wrong with this proof of Cartan's second equation?,,"Let $(M,g)$ be a Riemannian manifold and $\nabla$ a metric compatible connection. Let $\{e_a\}$ be a local orthonormal basis of vector fields on some open set $U\subset M$ . We define the connection $1$ -forms $\omega^a_b$ by $$\nabla_X e_b = \omega^a_b(X)e_a.$$ Let $\operatorname{Rm}$ be the Riemann tensor defined by $$\operatorname{Rm}(X,Y)Z=\nabla_X\nabla_YZ-\nabla_Y\nabla_XZ-\nabla_{[X,Y]}Z.$$ One defines the curvature $2$ -forms $\Omega^a_b$ by $$\frac{1}{2}\operatorname{Rm}(X,Y)e_b=\Omega^a_b(X,Y)e_a.$$ I want to prove Cartan's second equation $$\Omega^a_b=d\omega^a_b-\omega_b^c\wedge \omega_c^a.$$ I just computed $\operatorname{Rm}(X,Y)e_b$ using the connecton $1$ -forms: $$\operatorname{Rm}(X,Y)e_b = \nabla_X\nabla_Y e_b - \nabla_Y \nabla_X e_b - \nabla_{[X,Y]}e_b\\ =\nabla_X\left[\omega^a_b(Y)e_a\right]-\nabla_Y\left[\omega^a_b(X)e_a\right]-\omega^a_b([X,Y])e_a\\ =X(\omega^a_b(Y))e_a+\omega^a_b(Y)\nabla_X e_a-Y(\omega^a_b(X))e_a-\omega^a_b(X)\nabla_Y e_a-\omega^a_b([X,Y])e_a.$$ Now we know that $$d\omega^a_b(X,Y)=X(\omega^a_b(Y))-Y(\omega^a_b(X))-\omega^a_b([X,Y]),$$ hence the above evaluates to $$\operatorname{Rm}(X,Y)e_b = d\omega^a_b(X,Y)e_a + \omega^a_b(Y)\omega^c_a(X)e_c-\omega^a_b(X)\omega^c_a(Y)e_c\\ =d\omega^a_b(X,Y)e_a-2 \omega^a_b\wedge \omega_a^c(X,Y) e_c.$$ Now this last equation gives, upon using the definition of the curvature $2$ -forms $$\Omega^a_b = \dfrac{1}{2}d\omega^a_b - \omega_b^c\wedge \omega_c^a.$$ So there is this $1/2$ factor wrong in front of $d\omega^a_b$ . I have already read my computations again a few times but did not spot what I'm doing wrong. So what is wrong with my approach? Why I'm getting this $1/2$ in front of $d\omega^a_b$ ?","Let be a Riemannian manifold and a metric compatible connection. Let be a local orthonormal basis of vector fields on some open set . We define the connection -forms by Let be the Riemann tensor defined by One defines the curvature -forms by I want to prove Cartan's second equation I just computed using the connecton -forms: Now we know that hence the above evaluates to Now this last equation gives, upon using the definition of the curvature -forms So there is this factor wrong in front of . I have already read my computations again a few times but did not spot what I'm doing wrong. So what is wrong with my approach? Why I'm getting this in front of ?","(M,g) \nabla \{e_a\} U\subset M 1 \omega^a_b \nabla_X e_b = \omega^a_b(X)e_a. \operatorname{Rm} \operatorname{Rm}(X,Y)Z=\nabla_X\nabla_YZ-\nabla_Y\nabla_XZ-\nabla_{[X,Y]}Z. 2 \Omega^a_b \frac{1}{2}\operatorname{Rm}(X,Y)e_b=\Omega^a_b(X,Y)e_a. \Omega^a_b=d\omega^a_b-\omega_b^c\wedge \omega_c^a. \operatorname{Rm}(X,Y)e_b 1 \operatorname{Rm}(X,Y)e_b = \nabla_X\nabla_Y e_b - \nabla_Y \nabla_X e_b - \nabla_{[X,Y]}e_b\\
=\nabla_X\left[\omega^a_b(Y)e_a\right]-\nabla_Y\left[\omega^a_b(X)e_a\right]-\omega^a_b([X,Y])e_a\\
=X(\omega^a_b(Y))e_a+\omega^a_b(Y)\nabla_X e_a-Y(\omega^a_b(X))e_a-\omega^a_b(X)\nabla_Y e_a-\omega^a_b([X,Y])e_a. d\omega^a_b(X,Y)=X(\omega^a_b(Y))-Y(\omega^a_b(X))-\omega^a_b([X,Y]), \operatorname{Rm}(X,Y)e_b = d\omega^a_b(X,Y)e_a + \omega^a_b(Y)\omega^c_a(X)e_c-\omega^a_b(X)\omega^c_a(Y)e_c\\
=d\omega^a_b(X,Y)e_a-2 \omega^a_b\wedge \omega_a^c(X,Y) e_c. 2 \Omega^a_b = \dfrac{1}{2}d\omega^a_b - \omega_b^c\wedge \omega_c^a. 1/2 d\omega^a_b 1/2 d\omega^a_b","['proof-verification', 'differential-geometry', 'riemannian-geometry', 'curvature']"
21,Differential forms on cartesian product,Differential forms on cartesian product,,"Let $M,N$ be smooth manifolds. Is it true, that any $k$ -form $\alpha$ on $M\times N$ is of the form $$\alpha = \sum_{p+q=k} p_M^* \beta_p \wedge p_N^* \gamma_q,$$ where $p_M, p_N$ are the projections and $\beta_p$ is a $p$ -form on $M$ and $\gamma_q$ is a $q$ -form on $N$ ? I know that it is true on the level of cohomology.","Let be smooth manifolds. Is it true, that any -form on is of the form where are the projections and is a -form on and is a -form on ? I know that it is true on the level of cohomology.","M,N k \alpha M\times N \alpha = \sum_{p+q=k} p_M^* \beta_p \wedge p_N^* \gamma_q, p_M, p_N \beta_p p M \gamma_q q N","['differential-geometry', 'algebraic-topology', 'differential-topology', 'differential-forms']"
22,Connection matrix for the Poincare disk,Connection matrix for the Poincare disk,,"This a problem from Loring Tu, 'Differential Geometry': Problem: The Poincare disk is the open unit disk $$ \mathbf{D} = \left\{ z = x + iy \in \mathbb{C} \mid | z| < 1 \right\} $$ in the complex plane with metric $$ \langle , \rangle_z = \frac{ 4 (dx \otimes dx + dy \otimes dy)}{ (1- |z|^2)^2}. $$ An orthonormal frame for $\mathbf{D}$ is $$e_1 = \frac{1}{2} (1 - |z|^2) \partial_x, \qquad e_2 = \frac{1}{2} (1 - |z|^2) \partial_y. $$ Find the connection matrix $ \omega = [\omega_j^{i}]$ relative to the orthonormal frame $e_1, e_2$ of the Riemannian connection $\nabla$ on the Poincare disk (Hint: first find the dual frame $\theta^{1}, \theta^{2}$ and then solve the first structural equation). Attempt: The dual frame satisfies $\theta^{i} (e_j ) = \delta_{j}^{i}$ . So that means $$ \theta^{1} = \frac{2}{ 1 - |z|^2} dx, \qquad \theta^{2} = \frac{2}{ 1 - |z|^2} dy. $$ We have zero torsion so the first structural equation reads $$ d \theta^{i} + \omega_j^{i} \wedge \theta^j = 0 $$ for $ i = 1, 2$ and summation is implied. I calculated $$ d \theta^1 = \partial_y \left( \frac{2}{ 1 - x^2 - y^2} \right) dy \wedge dx = \frac{ - 4y}{ (1 - x^2 - y^2)^2} dx \wedge dy $$ and $$ d \theta^2 = \frac{ 4 x}{ (1 - x^2 - y^2)^2} dx \wedge dy. $$ Since we have an orthonormal basis, I know that the connection matrix should be skew-symmetric. So this means $\omega^{1}_{1} = \omega_2^{2} = 0$ . Then I need to solve e.g. $$ d \theta^1 + \omega_2^{1} \wedge \theta^2 =0$$ for $\omega_2^{1}$ . Since I have a dual frame, I can always expand (right?) $$ \omega_2^{1} = a_1 \theta^1 + a_2 \theta^2 $$ for some coefficients $a_1$ and $a_2$ . So the above equation becomes $$ d\theta^1 + a_1 \theta^1 \wedge \theta^2 = 0. $$ In other words : $$ - \frac{4y}{ (1 - |z|^2)^2} dx \wedge dy + \frac{ 4 a_1}{ (1 - |z|^2)^2} dx \wedge dy = 0 $$ so that $a_1 = y$ . So $\omega_2^{1} = y \theta^1$ . Similarly, I found $$ \omega_1^{2} = x \theta^2. $$ But this doesn't seem correct to me since I should have $\omega_1^{2} = - \omega_2^{1}$ ? Where am I going wrong? Thanks for any help.","This a problem from Loring Tu, 'Differential Geometry': Problem: The Poincare disk is the open unit disk in the complex plane with metric An orthonormal frame for is Find the connection matrix relative to the orthonormal frame of the Riemannian connection on the Poincare disk (Hint: first find the dual frame and then solve the first structural equation). Attempt: The dual frame satisfies . So that means We have zero torsion so the first structural equation reads for and summation is implied. I calculated and Since we have an orthonormal basis, I know that the connection matrix should be skew-symmetric. So this means . Then I need to solve e.g. for . Since I have a dual frame, I can always expand (right?) for some coefficients and . So the above equation becomes In other words : so that . So . Similarly, I found But this doesn't seem correct to me since I should have ? Where am I going wrong? Thanks for any help."," \mathbf{D} = \left\{ z = x + iy \in \mathbb{C} \mid | z| < 1 \right\}   \langle , \rangle_z = \frac{ 4 (dx \otimes dx + dy \otimes dy)}{ (1- |z|^2)^2}.  \mathbf{D} e_1 = \frac{1}{2} (1 - |z|^2) \partial_x, \qquad e_2 = \frac{1}{2} (1 - |z|^2) \partial_y.   \omega = [\omega_j^{i}] e_1, e_2 \nabla \theta^{1}, \theta^{2} \theta^{i} (e_j ) = \delta_{j}^{i}  \theta^{1} = \frac{2}{ 1 - |z|^2} dx, \qquad \theta^{2} = \frac{2}{ 1 - |z|^2} dy.   d \theta^{i} + \omega_j^{i} \wedge \theta^j = 0   i = 1, 2  d \theta^1 = \partial_y \left( \frac{2}{ 1 - x^2 - y^2} \right) dy \wedge dx = \frac{ - 4y}{ (1 - x^2 - y^2)^2} dx \wedge dy   d \theta^2 = \frac{ 4 x}{ (1 - x^2 - y^2)^2} dx \wedge dy.  \omega^{1}_{1} = \omega_2^{2} = 0  d \theta^1 + \omega_2^{1} \wedge \theta^2 =0 \omega_2^{1}  \omega_2^{1} = a_1 \theta^1 + a_2 \theta^2  a_1 a_2  d\theta^1 + a_1 \theta^1 \wedge \theta^2 = 0.   - \frac{4y}{ (1 - |z|^2)^2} dx \wedge dy + \frac{ 4 a_1}{ (1 - |z|^2)^2} dx \wedge dy = 0  a_1 = y \omega_2^{1} = y \theta^1  \omega_1^{2} = x \theta^2.  \omega_1^{2} = - \omega_2^{1}","['differential-geometry', 'riemannian-geometry', 'connections']"
23,"$M$ differential manifold, $f:M\to \mathbb{R}$ with exactly two critical points $p,q$ such that $f(p)=f(q)$","differential manifold,  with exactly two critical points  such that","M f:M\to \mathbb{R} p,q f(p)=f(q)","Let $M$ be a differential manifold and let $f:M\to \mathbb{R}$ be a $C^{\infty}$ function such that there are exactly two points $x$ which satisfy $d_xf=0$. Let $p$ and $q$ those two points, and suppose that $f(p)=f(q)$. Prove that there is another $C^{\infty}$ function $g:M\to \mathbb{R}$ such that $p$ and $q$ are the only critical points but $g(p)\neq g(q)$. I have been trying to solve this problem but I cannot come up with a solution. Clearly we can suppose $f(p)\neq 0$, so I intended to separate (by the $T2$ property) $p$ and $q$ with two open subsets $U$ and $V$, and letting $W$ an open set such that $p\in W\subseteq \overline{W}\subset U$ and $\overline{W}$ compact. Then I intended to make use either of a bump function or partition of unity, but I could not succeed. How would you solve the problem?","Let $M$ be a differential manifold and let $f:M\to \mathbb{R}$ be a $C^{\infty}$ function such that there are exactly two points $x$ which satisfy $d_xf=0$. Let $p$ and $q$ those two points, and suppose that $f(p)=f(q)$. Prove that there is another $C^{\infty}$ function $g:M\to \mathbb{R}$ such that $p$ and $q$ are the only critical points but $g(p)\neq g(q)$. I have been trying to solve this problem but I cannot come up with a solution. Clearly we can suppose $f(p)\neq 0$, so I intended to separate (by the $T2$ property) $p$ and $q$ with two open subsets $U$ and $V$, and letting $W$ an open set such that $p\in W\subseteq \overline{W}\subset U$ and $\overline{W}$ compact. Then I intended to make use either of a bump function or partition of unity, but I could not succeed. How would you solve the problem?",,"['differential-geometry', 'smooth-manifolds']"
24,Lower bound of the injectivity radius,Lower bound of the injectivity radius,,"Suppose $F:M^n \rightarrow \mathbb{R}^m$ is an isometric immersion with bounded second fundamental form. This means the following: There exists a constant $C>0$ such that for any $p \in M^n$ and for any orthonormal basis $e_1,\ldots,e_n$ of $T_pM$ we have $$ |h(e_i,e_j)| \leq C$$ where $h$ is the second fundamental form defined by $$ h(X,Y) = \text{normal part of } D_{dF(X)} dF(Y) $$ for vector fields $X$ and $Y$ on $M$ and where $D$ is the regular derivative on $\mathbb{R}^m$. Does there exist a lower bound for the injectivity radius on $M$ (note we do not assume $M$ to be compact)? The injectivity radius is defined as the lowest radius for which the exponential map is a diffeomorphism.","Suppose $F:M^n \rightarrow \mathbb{R}^m$ is an isometric immersion with bounded second fundamental form. This means the following: There exists a constant $C>0$ such that for any $p \in M^n$ and for any orthonormal basis $e_1,\ldots,e_n$ of $T_pM$ we have $$ |h(e_i,e_j)| \leq C$$ where $h$ is the second fundamental form defined by $$ h(X,Y) = \text{normal part of } D_{dF(X)} dF(Y) $$ for vector fields $X$ and $Y$ on $M$ and where $D$ is the regular derivative on $\mathbb{R}^m$. Does there exist a lower bound for the injectivity radius on $M$ (note we do not assume $M$ to be compact)? The injectivity radius is defined as the lowest radius for which the exponential map is a diffeomorphism.",,"['differential-geometry', 'riemannian-geometry']"
25,Do Carmo Riemanniam Geometry Page 46 quesion 7,Do Carmo Riemanniam Geometry Page 46 quesion 7,,"In Do Carmo Riemannian Geometry, page 46 question 7, we show that if $G$ is a compact connected Lie group, it has a bi-invariant Riemannian metric. in the first part we are required to show that if $w$ is a left invariant differential n-form, it is also right invariant. I've shown that for any $a\in G$ we have $\textbf{R}^*_aw$ is left invariant. Do Carmo then says $\cdots$ it follows that $\textbf{R}^*_aw=f(a)w$. Is that an obvious relation which I'm missing, or is it something that requires proof?","In Do Carmo Riemannian Geometry, page 46 question 7, we show that if $G$ is a compact connected Lie group, it has a bi-invariant Riemannian metric. in the first part we are required to show that if $w$ is a left invariant differential n-form, it is also right invariant. I've shown that for any $a\in G$ we have $\textbf{R}^*_aw$ is left invariant. Do Carmo then says $\cdots$ it follows that $\textbf{R}^*_aw=f(a)w$. Is that an obvious relation which I'm missing, or is it something that requires proof?",,"['differential-geometry', 'lie-groups', 'riemannian-geometry', 'differential-forms']"
26,Do harmonic maps into spaces of negative curvature locally minimize energy?,Do harmonic maps into spaces of negative curvature locally minimize energy?,,"$\newcommand{\N}{\mathcal{N}}$ $\newcommand{\M}{\mathcal{M}}$ $\newcommand{\g}{\mathfrak{g}}$ $\newcommand{\g}{\mathfrak{h}}$ $\newcommand{\IP}[2]{\left\langle #1,#2 \right\rangle}$ $\newcommand{\Volg}{\operatorname{Vol}_\g}$ Let $\M,\N$ be oriented Riemannian manifolds, and suppose the sectional curvature of $\N$ is negative. (Suppose also $\M$ is compact and connected). Let $\phi:\M \to \N$ be harmonic map. Is it true that $\phi$ is a local minimizer for the Dirichlet energy? i.e let $\phi_t$ be a smooth variation of $\phi$. Is it true that $E(\phi) \le E(\phi_t) $ for sufficiently small $t>0$? (The sufficiently small interval $I$ of the ""good"" $t$'s can depend on the variation of course). Let us restrict the discussion for variations $\phi_t$ whose variation fields $\left. \frac{\partial\phi_t}{\partial t}  \right|_{t=0}$ are not identically zero. I proved that if the rank of $d\phi$ is everywhere $\ge 2$, then $\phi$ is a local minimizer. (See my proof below). Also, if $\text{rank }d\phi=0$ everywhere, i.e $\phi$ is constant, then $\phi$ is also a local minimizer (it's a global minimizer...). So, the question remains: Suppose $\phi$ is a non-constant harmonic map which has at least one point of degree less than $2$. Is $\phi$ a local minimizer? Proof that $\text{rank }d\phi \ge 2 \Rightarrow$ $\phi$ is locally minimizing: We first note that $$ \left. \frac{\partial^2}{\partial t^2}  E(\phi_{t}) \right|_{t=0}=H_{\phi}(V,V), $$ where $H_{\phi}$ is the hessian of the energy functional at $\phi$, and $V=\left. \frac{\partial\phi_t}{\partial t}  \right|_{t=0}$ is the corresponding variation field. From the second variation formula, we obtain $$ \begin{split} H(E)_{\phi}(V,V)&= \int_{\M} \IP{J_{\phi}(V)}{V}  \Volg \\ &=\int_{\M}  -\sum_i \IP{R^{T\N}(V,d\phi(e_i))d\phi(e_i)}{V}+\IP{d_{\nabla^{\phi^*(T\N)}}V}{d_{\nabla^{\phi^*(T\N)}}V} \Volg \\ & \ge -\sum_i \int_{\M} \IP{R^{T\N}(V,d\phi(e_i))d\phi(e_i)}{V}. \end{split} $$ By our assumption (non-zero variation field), there exist $p \in \M$ such that $V_p \neq 0$. If $V_p,d\phi_p(e_i(p))$ are linearly dependent, then since $V_p \neq 0$,  $ d\phi_p(e_i(p)) \in \text{span} \{V_p\}$. Since we assumed $\text{rank }(d\phi_p) \ge 2$, not all the $d\phi_p(e_i(p))$ are linearly dependent of $V_p$; Thus, there exist an $1 \le i \le d$ where they are independent, hence $\IP{R^{T\N}(V,d\phi(e_i))d\phi(e_i)}{V} < 0$ by the curvature assumption. Recall that the sectional curvature of the plane spanned by $x,y \in T_q\N$ is $$ K(x,y)=\frac{\IP{R^{T\N}(x,y)y}{x} }{|x \wedge y|^2}.$$","$\newcommand{\N}{\mathcal{N}}$ $\newcommand{\M}{\mathcal{M}}$ $\newcommand{\g}{\mathfrak{g}}$ $\newcommand{\g}{\mathfrak{h}}$ $\newcommand{\IP}[2]{\left\langle #1,#2 \right\rangle}$ $\newcommand{\Volg}{\operatorname{Vol}_\g}$ Let $\M,\N$ be oriented Riemannian manifolds, and suppose the sectional curvature of $\N$ is negative. (Suppose also $\M$ is compact and connected). Let $\phi:\M \to \N$ be harmonic map. Is it true that $\phi$ is a local minimizer for the Dirichlet energy? i.e let $\phi_t$ be a smooth variation of $\phi$. Is it true that $E(\phi) \le E(\phi_t) $ for sufficiently small $t>0$? (The sufficiently small interval $I$ of the ""good"" $t$'s can depend on the variation of course). Let us restrict the discussion for variations $\phi_t$ whose variation fields $\left. \frac{\partial\phi_t}{\partial t}  \right|_{t=0}$ are not identically zero. I proved that if the rank of $d\phi$ is everywhere $\ge 2$, then $\phi$ is a local minimizer. (See my proof below). Also, if $\text{rank }d\phi=0$ everywhere, i.e $\phi$ is constant, then $\phi$ is also a local minimizer (it's a global minimizer...). So, the question remains: Suppose $\phi$ is a non-constant harmonic map which has at least one point of degree less than $2$. Is $\phi$ a local minimizer? Proof that $\text{rank }d\phi \ge 2 \Rightarrow$ $\phi$ is locally minimizing: We first note that $$ \left. \frac{\partial^2}{\partial t^2}  E(\phi_{t}) \right|_{t=0}=H_{\phi}(V,V), $$ where $H_{\phi}$ is the hessian of the energy functional at $\phi$, and $V=\left. \frac{\partial\phi_t}{\partial t}  \right|_{t=0}$ is the corresponding variation field. From the second variation formula, we obtain $$ \begin{split} H(E)_{\phi}(V,V)&= \int_{\M} \IP{J_{\phi}(V)}{V}  \Volg \\ &=\int_{\M}  -\sum_i \IP{R^{T\N}(V,d\phi(e_i))d\phi(e_i)}{V}+\IP{d_{\nabla^{\phi^*(T\N)}}V}{d_{\nabla^{\phi^*(T\N)}}V} \Volg \\ & \ge -\sum_i \int_{\M} \IP{R^{T\N}(V,d\phi(e_i))d\phi(e_i)}{V}. \end{split} $$ By our assumption (non-zero variation field), there exist $p \in \M$ such that $V_p \neq 0$. If $V_p,d\phi_p(e_i(p))$ are linearly dependent, then since $V_p \neq 0$,  $ d\phi_p(e_i(p)) \in \text{span} \{V_p\}$. Since we assumed $\text{rank }(d\phi_p) \ge 2$, not all the $d\phi_p(e_i(p))$ are linearly dependent of $V_p$; Thus, there exist an $1 \le i \le d$ where they are independent, hence $\IP{R^{T\N}(V,d\phi(e_i))d\phi(e_i)}{V} < 0$ by the curvature assumption. Recall that the sectional curvature of the plane spanned by $x,y \in T_q\N$ is $$ K(x,y)=\frac{\IP{R^{T\N}(x,y)y}{x} }{|x \wedge y|^2}.$$",,"['differential-geometry', 'reference-request', 'riemannian-geometry', 'calculus-of-variations']"
27,Curves with Constant Curvature,Curves with Constant Curvature,,"Besides lines, circles and helices, are there any other curves that have a constant curvature $\kappa$? If there exist any, are there any that have an explicit formula in the form of r(t) = [x(t) , y(t) , z (t)] ?","Besides lines, circles and helices, are there any other curves that have a constant curvature $\kappa$? If there exist any, are there any that have an explicit formula in the form of r(t) = [x(t) , y(t) , z (t)] ?",,"['differential-geometry', 'curves']"
28,Express covariant derivative in terms of exterior derivative,Express covariant derivative in terms of exterior derivative,,"I know there is an intimate relation between covariant, Lie and exterior derivative. I know that the covariant derivative requires more structure than the exterior, so it would be possible. How do I express a covariant derivative $\nabla_{X} Y$ in terms of the exterior derivative, assuming the Levi-Civita connection?","I know there is an intimate relation between covariant, Lie and exterior derivative. I know that the covariant derivative requires more structure than the exterior, so it would be possible. How do I express a covariant derivative $\nabla_{X} Y$ in terms of the exterior derivative, assuming the Levi-Civita connection?",,"['differential-geometry', 'exterior-algebra', 'exterior-derivative']"
29,Lie derivative commutes with interior product,Lie derivative commutes with interior product,,"Let $i_X : \Omega^k M \to \Omega^{k-1} M$ be the interior product for a smooth manifold $M$ and a smooth vector field $X$ with flow $\Phi$ and  $$L_X : \Omega^k \to \Omega^k, \; \omega \mapsto L_X \omega := \frac{\text d}{\text d t} \Big| _{t=0} \Phi^*_t \omega$$ the Lie derivative of a $k$-form. Show that  $$i_X \circ L_X = L_X \circ i_X.$$ To be honest, I have no clue. What I have proven so far is that the Lie derivative commutes with the exterior derivative ($d \circ L_X = L_X \circ d$), and I have also proven Cartan's magic formula ($L_X = i_X \circ d + d \circ i_X$) by induction. Is there an easy way to use both of these to prove the upper statement?","Let $i_X : \Omega^k M \to \Omega^{k-1} M$ be the interior product for a smooth manifold $M$ and a smooth vector field $X$ with flow $\Phi$ and  $$L_X : \Omega^k \to \Omega^k, \; \omega \mapsto L_X \omega := \frac{\text d}{\text d t} \Big| _{t=0} \Phi^*_t \omega$$ the Lie derivative of a $k$-form. Show that  $$i_X \circ L_X = L_X \circ i_X.$$ To be honest, I have no clue. What I have proven so far is that the Lie derivative commutes with the exterior derivative ($d \circ L_X = L_X \circ d$), and I have also proven Cartan's magic formula ($L_X = i_X \circ d + d \circ i_X$) by induction. Is there an easy way to use both of these to prove the upper statement?",,['differential-geometry']
30,Is the pullback of a connection compatible with a bundle metric also compatible with the pullback metric?,Is the pullback of a connection compatible with a bundle metric also compatible with the pullback metric?,,"Let $M$ be a smooth manifold, and $E\to M$ a smooth vector bundle. Then if we have a smooth morphism $f:N\to M$ of smooth manifolds, then we obtain the following commutative diagram,  $$\require{AMScd} \begin{CD}f^*E @>>> E \\ @VVV @VVV \\ N @>f>> M \end{CD}$$ where $f^*E$ is the pullback of $E$. Therefore, if we have some bundle metric $g\in E^*\otimes E^*$, we can define the pullback bundle metric $\tilde g:=f^*g\in f^*E^*\otimes f^*E^*$ in the natural way, and for any connection $$\nabla:\Gamma(\mathrm TM)\otimes\Gamma(E)\to\Gamma(E)$$ we can define the pullback connection $$f^*\nabla:\Gamma(\mathrm TN)\otimes\Gamma(f^*E)\to\Gamma(f^*E)$$ as follows: Let $(x^i)$ be coordinates on $N$ mapping into coordinates $(y^j)$ on $M$, and let $E$ be locally trivial with basis $(e_k)$ on $M$, then if $\nabla_{\partial/\partial y^i}e_j=\Gamma_{ij}^k e_k$, then if we set $$\tilde\Gamma_{ij}^k=\frac{\partial f^l}{\partial x^i}\Gamma_{lj}^k\circ f$$ then we can define $\tilde\nabla$ by letting $\tilde\nabla_{\partial/\partial x^i} e_j=\tilde\Gamma_{ij}^k$. Now, suppose $\nabla$ is compatible with $g$, that is to say, for $a,b\in\Gamma(E)$ and $X\in\Gamma(\mathrm T M)$, $$X\langle a,b\rangle = \langle\nabla_Xa,b\rangle+\langle a,\nabla_Xb\rangle$$ then I wish to prove that for $a,b\in\Gamma(f^*E)$ and $X\in\Gamma(\mathrm T N)$, $$X\langle a,b\rangle = \langle\tilde\nabla_X a,b\rangle+\langle a,\tilde\nabla_Xb\rangle$$ but is this true? I've been having trouble proving this even for $X=\frac{\partial}{\partial x^i}$ and $a=e_j$, $b=e_k$. In this case, I obtain that $$\frac{\partial}{\partial x^i}\langle e_j,e_k\rangle = \frac{\partial g_{jk}}{\partial x^i} = \frac{\partial g_{jk}}{\partial y^l}\frac{\partial f^l}{\partial x^i}$$ and $$\langle\tilde\nabla_{\partial/\partial x^i}e_j,e_k\rangle + \langle e_j,\tilde\nabla_{\partial/\partial x^i}e_k\rangle =\tilde\Gamma_{ij}^l g_{lk} + \tilde\Gamma_{ik}^l g_{lj} = \Gamma_{mj}^l\frac{\partial f^m}{\partial x^i}g_{lk} + \Gamma_{mk}^l\frac{\partial f^m}{\partial x^i}g_{lj} $$ but I don't see why these two expressions should be equal.","Let $M$ be a smooth manifold, and $E\to M$ a smooth vector bundle. Then if we have a smooth morphism $f:N\to M$ of smooth manifolds, then we obtain the following commutative diagram,  $$\require{AMScd} \begin{CD}f^*E @>>> E \\ @VVV @VVV \\ N @>f>> M \end{CD}$$ where $f^*E$ is the pullback of $E$. Therefore, if we have some bundle metric $g\in E^*\otimes E^*$, we can define the pullback bundle metric $\tilde g:=f^*g\in f^*E^*\otimes f^*E^*$ in the natural way, and for any connection $$\nabla:\Gamma(\mathrm TM)\otimes\Gamma(E)\to\Gamma(E)$$ we can define the pullback connection $$f^*\nabla:\Gamma(\mathrm TN)\otimes\Gamma(f^*E)\to\Gamma(f^*E)$$ as follows: Let $(x^i)$ be coordinates on $N$ mapping into coordinates $(y^j)$ on $M$, and let $E$ be locally trivial with basis $(e_k)$ on $M$, then if $\nabla_{\partial/\partial y^i}e_j=\Gamma_{ij}^k e_k$, then if we set $$\tilde\Gamma_{ij}^k=\frac{\partial f^l}{\partial x^i}\Gamma_{lj}^k\circ f$$ then we can define $\tilde\nabla$ by letting $\tilde\nabla_{\partial/\partial x^i} e_j=\tilde\Gamma_{ij}^k$. Now, suppose $\nabla$ is compatible with $g$, that is to say, for $a,b\in\Gamma(E)$ and $X\in\Gamma(\mathrm T M)$, $$X\langle a,b\rangle = \langle\nabla_Xa,b\rangle+\langle a,\nabla_Xb\rangle$$ then I wish to prove that for $a,b\in\Gamma(f^*E)$ and $X\in\Gamma(\mathrm T N)$, $$X\langle a,b\rangle = \langle\tilde\nabla_X a,b\rangle+\langle a,\tilde\nabla_Xb\rangle$$ but is this true? I've been having trouble proving this even for $X=\frac{\partial}{\partial x^i}$ and $a=e_j$, $b=e_k$. In this case, I obtain that $$\frac{\partial}{\partial x^i}\langle e_j,e_k\rangle = \frac{\partial g_{jk}}{\partial x^i} = \frac{\partial g_{jk}}{\partial y^l}\frac{\partial f^l}{\partial x^i}$$ and $$\langle\tilde\nabla_{\partial/\partial x^i}e_j,e_k\rangle + \langle e_j,\tilde\nabla_{\partial/\partial x^i}e_k\rangle =\tilde\Gamma_{ij}^l g_{lk} + \tilde\Gamma_{ik}^l g_{lj} = \Gamma_{mj}^l\frac{\partial f^m}{\partial x^i}g_{lk} + \Gamma_{mk}^l\frac{\partial f^m}{\partial x^i}g_{lj} $$ but I don't see why these two expressions should be equal.",,"['differential-geometry', 'riemannian-geometry']"
31,Examples of compact negatively curved constant curvature manifold,Examples of compact negatively curved constant curvature manifold,,I am looking for concrete examples of negatively curved constant curvature manifold. The only example of negatively curved constant curvature manifold is the hyperbolic plane. Are there any easy examples of such manifolds which are compact.,I am looking for concrete examples of negatively curved constant curvature manifold. The only example of negatively curved constant curvature manifold is the hyperbolic plane. Are there any easy examples of such manifolds which are compact.,,['differential-geometry']
32,How to define a covariant derivative on a smooth vector bundle using only an Ehresmann connection?,How to define a covariant derivative on a smooth vector bundle using only an Ehresmann connection?,,"I'm trying to get a clear picture of covariant differentiation in my head. I'm looking for a definition of the covariant derivative using only the structure of an Ehresmann connection on a smooth vector bundle. The data of an Ehresmann connection on any submersion can be specified in the three usual equivalent ways of specifying a splitting of a short exact sequence: If $f:X\to Y$ is a submersion, there's the exact short sequence of Atiyah, of bundles over $X$ $$\mathrm VX\to \mathrm TX\to f^\ast \mathrm TY.$$ If we take a right splitting $\nabla:f^\ast \mathrm TY\to \mathrm TX$, the only new possibility seems to horizontally lift vector fields. How to define a covariant derivative on a smooth vector bundle $f:X\to Y$ using only an Ehresmann connection? Update following levap's great answer. If I understand correctly, here's the diagram describing the maps of levap's answer. $$\newcommand{\ra}[1]{\kern-1.5ex\xrightarrow{\ \ #1\ \ }\phantom{}\kern-1.5ex} \newcommand{\ras}[1]{\kern-1.5ex\xrightarrow{\ \ \smash{#1}\ \ }\phantom{}\kern-1.5ex} \newcommand{\da}[1]{\bigg\downarrow\raise.5ex\rlap{\scriptstyle#1}} \begin{array}{c} \mathrm T Y & \ra{\mathrm d s} & \mathrm T X & \ra{K} & \mathrm VX & \ra{\Phi} & X\times _YX & \ra{\pi_2} & X\\ \da{} & & \da{} & & \da{} & & \da{\pi_1} & & \da{f}\\ Y & \ras{s} & X & \ras{=} & X & \ras{=} & X & \ras{f} & Y \\ \end{array}$$ Here, $K$ is a section of the bundle map $\mathrm VX\to \mathrm TX$ over $X$, which fiberwise projects from a tangent space to its vertical subspace. $\Phi$ is fiberwise $\mathrm T_pf^{-1}(y)\cong f^{-1}(y)$ given by identifying the vector space $f^{-1}(y)$ with its tangent space at $p\in f^{-1}(y)$. I still don't feel I understand the geometry so I'll try to describe what I do. The bundle I'm visualizing is the ""infinite Möbius strip"" over the circle. The differential $\mathrm ds$ is by functoriality a section of $\mathrm df$, which means fiberwise $\mathrm d_ys$ a section of $\mathrm d_pf$. Now, the fiber $(\mathrm d_pf)^{-1}(v)$ consists of tangents upstairs. The fiber of a nonzero vector in $\mathrm T_yY$ consists of tangents with a horizontal component , since they're not in the kernel. At any rate, $\mathrm ds$ smoothly chooses a subbundle of $\mathrm TX\to X$. For the infinite Möbius strip this amounts to drawing a single arrow on each of the fibers in a smoothly varying way. $\pi_2\circ \Phi \circ K$ then projects this subbundle onto the vertical bundle. For the infinite Möbius strip we project each arrow on a fiber to the fiber itself, identified with its tangent space. The picture is then a smooth array of vertical (in the direction of the fiber) arrows, one on each fiber. Finally, given a vector field $\mathcal Y$ downstairs, $\nabla_\mathcal{Y}s$ is simply precomposition of $\nabla s$ with $\mathcal Y$. Why is the projection to the vertical bundle capturing the same as differentiating the parallel transport? It looks like we're ignoring variation between fibers by projecting onto the vertical bundle - exactly the opposite of parallel transport. I don't understand the intuition here... Here's the best I have: the fact we're parallel along fibers amounts to saying we're moving vectors ""without changing them w.r.t the horizontal direction"". This is somehow analogous to the projection on the vertical bundle, which also ignores horizontal changes. The vertical changes are the ones intrinsic to the manifold upstairs because the fibers of $f$ are ""straight"", as opposed to general tangents which may ""point outside of the surface"". So is the covariant derivative of a section of a vector bundle $f:X\to Y$ sort of like ""partial differentiation along the directions of the fibers of $f$?""","I'm trying to get a clear picture of covariant differentiation in my head. I'm looking for a definition of the covariant derivative using only the structure of an Ehresmann connection on a smooth vector bundle. The data of an Ehresmann connection on any submersion can be specified in the three usual equivalent ways of specifying a splitting of a short exact sequence: If $f:X\to Y$ is a submersion, there's the exact short sequence of Atiyah, of bundles over $X$ $$\mathrm VX\to \mathrm TX\to f^\ast \mathrm TY.$$ If we take a right splitting $\nabla:f^\ast \mathrm TY\to \mathrm TX$, the only new possibility seems to horizontally lift vector fields. How to define a covariant derivative on a smooth vector bundle $f:X\to Y$ using only an Ehresmann connection? Update following levap's great answer. If I understand correctly, here's the diagram describing the maps of levap's answer. $$\newcommand{\ra}[1]{\kern-1.5ex\xrightarrow{\ \ #1\ \ }\phantom{}\kern-1.5ex} \newcommand{\ras}[1]{\kern-1.5ex\xrightarrow{\ \ \smash{#1}\ \ }\phantom{}\kern-1.5ex} \newcommand{\da}[1]{\bigg\downarrow\raise.5ex\rlap{\scriptstyle#1}} \begin{array}{c} \mathrm T Y & \ra{\mathrm d s} & \mathrm T X & \ra{K} & \mathrm VX & \ra{\Phi} & X\times _YX & \ra{\pi_2} & X\\ \da{} & & \da{} & & \da{} & & \da{\pi_1} & & \da{f}\\ Y & \ras{s} & X & \ras{=} & X & \ras{=} & X & \ras{f} & Y \\ \end{array}$$ Here, $K$ is a section of the bundle map $\mathrm VX\to \mathrm TX$ over $X$, which fiberwise projects from a tangent space to its vertical subspace. $\Phi$ is fiberwise $\mathrm T_pf^{-1}(y)\cong f^{-1}(y)$ given by identifying the vector space $f^{-1}(y)$ with its tangent space at $p\in f^{-1}(y)$. I still don't feel I understand the geometry so I'll try to describe what I do. The bundle I'm visualizing is the ""infinite Möbius strip"" over the circle. The differential $\mathrm ds$ is by functoriality a section of $\mathrm df$, which means fiberwise $\mathrm d_ys$ a section of $\mathrm d_pf$. Now, the fiber $(\mathrm d_pf)^{-1}(v)$ consists of tangents upstairs. The fiber of a nonzero vector in $\mathrm T_yY$ consists of tangents with a horizontal component , since they're not in the kernel. At any rate, $\mathrm ds$ smoothly chooses a subbundle of $\mathrm TX\to X$. For the infinite Möbius strip this amounts to drawing a single arrow on each of the fibers in a smoothly varying way. $\pi_2\circ \Phi \circ K$ then projects this subbundle onto the vertical bundle. For the infinite Möbius strip we project each arrow on a fiber to the fiber itself, identified with its tangent space. The picture is then a smooth array of vertical (in the direction of the fiber) arrows, one on each fiber. Finally, given a vector field $\mathcal Y$ downstairs, $\nabla_\mathcal{Y}s$ is simply precomposition of $\nabla s$ with $\mathcal Y$. Why is the projection to the vertical bundle capturing the same as differentiating the parallel transport? It looks like we're ignoring variation between fibers by projecting onto the vertical bundle - exactly the opposite of parallel transport. I don't understand the intuition here... Here's the best I have: the fact we're parallel along fibers amounts to saying we're moving vectors ""without changing them w.r.t the horizontal direction"". This is somehow analogous to the projection on the vertical bundle, which also ignores horizontal changes. The vertical changes are the ones intrinsic to the manifold upstairs because the fibers of $f$ are ""straight"", as opposed to general tangents which may ""point outside of the surface"". So is the covariant derivative of a section of a vector bundle $f:X\to Y$ sort of like ""partial differentiation along the directions of the fibers of $f$?""",,"['differential-geometry', 'definition', 'smooth-manifolds', 'vector-bundles', 'connections']"
33,Deriving metric from Killing field.,Deriving metric from Killing field.,,Finding Killing fields from the metric in a Riemannian manifold is a standard procedure written in many relevant books.  My question is the reverse: How can I find a metric for a manifold whose Killing fields are known?,Finding Killing fields from the metric in a Riemannian manifold is a standard procedure written in many relevant books.  My question is the reverse: How can I find a metric for a manifold whose Killing fields are known?,,['differential-geometry']
34,$f$-related vector field,-related vector field,f,"Let $M$ and $N$ be smooth manifods and $f:M\to N$ a smooth submersion. Prove that for every vector field $X\in \mathfrak{X}(N)$ there is a vector field $Y\in \mathfrak{X}(M)$ such that $X$ and $Y$ are $f$ -related (i.e., $f_{*}Y=X\circ f $ ). Here is where I'm at: take $p\in M$ , then $X(f(p))\in T_{f(p)}N$ . Since $f$ is a submersion, $\exists v\in T_pM$ such that $f_{*_{p}}(v)=X(f(p))$ . In that fashion, we can define a function $Y:M\to TM$ with $Y(p)=v$ . I suppose this is the natural way to start. The problem is that this $v$ is not uniquely defined, which means $Y$ may well not be smooth depending on the choices for $v$ , so I'm stuck here. Any suggestions? Thanks!","Let and be smooth manifods and a smooth submersion. Prove that for every vector field there is a vector field such that and are -related (i.e., ). Here is where I'm at: take , then . Since is a submersion, such that . In that fashion, we can define a function with . I suppose this is the natural way to start. The problem is that this is not uniquely defined, which means may well not be smooth depending on the choices for , so I'm stuck here. Any suggestions? Thanks!",M N f:M\to N X\in \mathfrak{X}(N) Y\in \mathfrak{X}(M) X Y f f_{*}Y=X\circ f  p\in M X(f(p))\in T_{f(p)}N f \exists v\in T_pM f_{*_{p}}(v)=X(f(p)) Y:M\to TM Y(p)=v v Y v,"['differential-geometry', 'smooth-manifolds']"
35,A Riemannian metric which doesn't vary smoothly,A Riemannian metric which doesn't vary smoothly,,"A Riemannian metric $ds^2$ on a differential manifold $M$ of dimension $n\ge 2$ is written as $ds^2=\sum_{i=1}^n\sum_{j=1}^ng_{ij}(x_1,\dots,x_n)dx_idx_j$ where the functions $g_{ij}:M\rightarrow \mathbb{R}$ are twice continuously differentiable functions. The derivatives of the $g_{ij}$ are fundamental to define tools as Christoffel symbols, connection, curvature.. My question is: what happens if the $g_{ij}$ still admit derivatives of first and second order in every point of $M$, but these derivatives are not continuous? Is it still possible to define and use Christoffel symbols and curvature tensor (and other tool involving derivatives of $g_{ij}$) or should one expect something going wrong?","A Riemannian metric $ds^2$ on a differential manifold $M$ of dimension $n\ge 2$ is written as $ds^2=\sum_{i=1}^n\sum_{j=1}^ng_{ij}(x_1,\dots,x_n)dx_idx_j$ where the functions $g_{ij}:M\rightarrow \mathbb{R}$ are twice continuously differentiable functions. The derivatives of the $g_{ij}$ are fundamental to define tools as Christoffel symbols, connection, curvature.. My question is: what happens if the $g_{ij}$ still admit derivatives of first and second order in every point of $M$, but these derivatives are not continuous? Is it still possible to define and use Christoffel symbols and curvature tensor (and other tool involving derivatives of $g_{ij}$) or should one expect something going wrong?",,['differential-geometry']
36,"""Barred"" Tensor Indices in Complex Manifolds","""Barred"" Tensor Indices in Complex Manifolds",,"I'm having an embarrassingly hard time straightening out how to work with the ""barred"" indices that show up in tensors on complex manifolds.  For example, the Kahler form $\omega = \frac{i}{2}g_{i \bar{j}}dz^{i} \wedge d\bar{z}^{\bar{j}}$.  Is it correct to say that these barred indices only serve to denote an index that is contracted with either a $d\bar{z}$ or $\partial/\partial \bar{z}$ in some general tensor?  In other words, we could I think equivalently write the above Kahler form as $\omega = \frac{i}{2}g_{i j}dz^{i} \wedge d\bar{z}^{j}$, correct?  I suppose this barred notation is simply convenient when writing things out in coordinates, so we can read off the holomorphic and anti-holomorphic components. The precise problem in which this tripped me up, is arguing that the $g_{i \bar{j}}$ coming from the above Kahler form is actually a Hermitian matrix in local coordinates.  Clearly, without the barred notation, we would say a matrix is Hermitian if its entries satisfy $g_{ij}=(g_{ji})^{*}$.  Can someone perhaps help me reason through how the barred indices are affected by this complex conjugation?  I know the Kahler form is real, so it should equal its complex conjugate, but even for a non-real form there is a way to conjugate components, and the Hermitian condition I think is something extra.  I'd very much appreciate a little nudging here!","I'm having an embarrassingly hard time straightening out how to work with the ""barred"" indices that show up in tensors on complex manifolds.  For example, the Kahler form $\omega = \frac{i}{2}g_{i \bar{j}}dz^{i} \wedge d\bar{z}^{\bar{j}}$.  Is it correct to say that these barred indices only serve to denote an index that is contracted with either a $d\bar{z}$ or $\partial/\partial \bar{z}$ in some general tensor?  In other words, we could I think equivalently write the above Kahler form as $\omega = \frac{i}{2}g_{i j}dz^{i} \wedge d\bar{z}^{j}$, correct?  I suppose this barred notation is simply convenient when writing things out in coordinates, so we can read off the holomorphic and anti-holomorphic components. The precise problem in which this tripped me up, is arguing that the $g_{i \bar{j}}$ coming from the above Kahler form is actually a Hermitian matrix in local coordinates.  Clearly, without the barred notation, we would say a matrix is Hermitian if its entries satisfy $g_{ij}=(g_{ji})^{*}$.  Can someone perhaps help me reason through how the barred indices are affected by this complex conjugation?  I know the Kahler form is real, so it should equal its complex conjugate, but even for a non-real form there is a way to conjugate components, and the Hermitian condition I think is something extra.  I'd very much appreciate a little nudging here!",,"['differential-geometry', 'complex-geometry']"
37,Geometric quantization: not understanding the curvature form and Weil's theorem,Geometric quantization: not understanding the curvature form and Weil's theorem,,"I am reading a bit about geometric quantization. The texts that I am following are N.M.J. Woodhouse's ""Geometric Quantization"" and an article from arXiv . I am having troubles understanding the prequantization step. First, everybody cites 1958 Weil's theorem about the existence of Hermitian line bundles with prescribed curvature, but nobody provides its exact statement. Could anyone help me with it? In particular, do I prescribe just the curvature form, or a connection and its associated curvature form? Second, one tries to produce Hermitian line bundles $L$ over a symplectic manifold $(M, \omega)$ having $\omega$ as the curvature form $R$ of $L$. I'm lost: how can we relate these two forms? $R$ takes values in $\operatorname{End} _{\Bbb C} (L)$, which $\omega$ doesn't, so how can I identify them? Had $L$ been trivial, it would have been elementary, but how to do it in general? Or is this an abuse of terminology?","I am reading a bit about geometric quantization. The texts that I am following are N.M.J. Woodhouse's ""Geometric Quantization"" and an article from arXiv . I am having troubles understanding the prequantization step. First, everybody cites 1958 Weil's theorem about the existence of Hermitian line bundles with prescribed curvature, but nobody provides its exact statement. Could anyone help me with it? In particular, do I prescribe just the curvature form, or a connection and its associated curvature form? Second, one tries to produce Hermitian line bundles $L$ over a symplectic manifold $(M, \omega)$ having $\omega$ as the curvature form $R$ of $L$. I'm lost: how can we relate these two forms? $R$ takes values in $\operatorname{End} _{\Bbb C} (L)$, which $\omega$ doesn't, so how can I identify them? Had $L$ been trivial, it would have been elementary, but how to do it in general? Or is this an abuse of terminology?",,"['differential-geometry', 'vector-bundles', 'curvature', 'quantum-mechanics', 'symplectic-geometry']"
38,Gradient in terms of first fundamental form,Gradient in terms of first fundamental form,,"In Do Carmo's Differential Geometry of Curves and Surfaces , I'm having a quite hard time trying to solve Excersise 14 on pages 101-102. He defines the gradient of a differentiable function $f:S\to \Bbb{R}$ as a differentiable map $\text{grad}f:S\to\Bbb{R}^3$ which assigns to each point $p\in S$ a vector $f(p)\in T_p(S)\subset \Bbb{R}^3$ such that $$\qquad \langle \text{grad}f(p),v\rangle_p=df_p(v)\qquad\text{for all }v\in T_p(S)$$ The question is to express $\text{grad}f$ of $\phi(U)$ in terms of the coefficients $E,F,G$ of the first fundamental form in a parametrization $\phi:U\subset\Bbb{R}^2\to S$ . The solution is $$\qquad \text{grad}f=\frac{f_uG-f_vF}{EG-F^2}\phi_u\,+\,\frac{f_vE-f_uF}{EG-F^2}\phi_v$$ I'm not sure how to start. Sure that if $gradf$ sends points into vectors of the tangent plane, it must be a linear combination of $\phi_u$ and $\phi_v$ , but I don't know how to use the information that $\langle \text{grad}f(p),v\rangle_p=df_p(v)$ $\,$ for all $v\in T_p(S)$ to get the desired result. The $\dfrac{1}{EG-F^2}$ makes me think about the inverse matrix of the first fundamental form, but again, I don't see how can I relate one thing to the other. Any hints that can point me in the right direction would be appreciate. Thanks in advance!","In Do Carmo's Differential Geometry of Curves and Surfaces , I'm having a quite hard time trying to solve Excersise 14 on pages 101-102. He defines the gradient of a differentiable function as a differentiable map which assigns to each point a vector such that The question is to express of in terms of the coefficients of the first fundamental form in a parametrization . The solution is I'm not sure how to start. Sure that if sends points into vectors of the tangent plane, it must be a linear combination of and , but I don't know how to use the information that for all to get the desired result. The makes me think about the inverse matrix of the first fundamental form, but again, I don't see how can I relate one thing to the other. Any hints that can point me in the right direction would be appreciate. Thanks in advance!","f:S\to \Bbb{R} \text{grad}f:S\to\Bbb{R}^3 p\in S f(p)\in T_p(S)\subset \Bbb{R}^3 \qquad \langle \text{grad}f(p),v\rangle_p=df_p(v)\qquad\text{for all }v\in T_p(S) \text{grad}f \phi(U) E,F,G \phi:U\subset\Bbb{R}^2\to S \qquad \text{grad}f=\frac{f_uG-f_vF}{EG-F^2}\phi_u\,+\,\frac{f_vE-f_uF}{EG-F^2}\phi_v gradf \phi_u \phi_v \langle \text{grad}f(p),v\rangle_p=df_p(v) \, v\in T_p(S) \dfrac{1}{EG-F^2}",['differential-geometry']
39,Does the Morse homology depend on the orientation?,Does the Morse homology depend on the orientation?,,"Before asking my question I need to define some objects. I will follow the book ""M. Audin, M.Damian - Morse theory and Floer homology"", but the terminology is quite standard: Let $M$ be a smooth compact manifold and consider a Morse-Smale pair $(X,f)$ on $M$ ( $X$ is a gradient-like vector field and $f$ is an adapted Morse function). If $a,b$ are two critical points of $f$ , we indicate with $\mathcal L(a,b)$ the manifold such that every point is a trajectory of $X$ ''starting'' from $a$ and ''ending'' in $b$ . One can show that if $\text{ind}(a)=\text{ind}(b)+1$ then $\mathcal{L}(a,b)$ is a finite set. Moreover if we orient the stable manifold $W^s(a)$ , remember that it is a disk, we induce an orientation on $\mathcal L(a,b)$ , namely at each point we associate $\pm 1$ if $\text{ind}(a)=\text{ind}(b)+1$ . At this point one can define the Morse-Smale complex: $$C_k:=\sum_{a\in\text{Crit}_k(f)}\mathbb Za$$ where clearly $\text{Crit}_k(f)$ is the set of critical points of index $k$ . The map $d_k:C_k\longrightarrow C_{k-1}$ acts on the generators of $C_k$ in the following way: $$d_k(a)=\sum_{a\in\text{Crit}_{k-1}(f)}N(a,b)b$$ where $N(a,b)\in\mathbb Z$ is the sum of the $\pm 1$ (the orientations) attached to the points of $\mathcal L(a,b)$ . Question: From the above construction it is evident that the Morse-Smale complex (in particular the number $N(a,b)$ ) depends on the   orientation that we fix on the stable manifolds $W^s(a)$ . This sounds   very strange to me, indeed I'd expect a complex independent from the   orientation. Maybe by passing to the homology group one can recover   the independence but I can't see it. Many thanks.","Before asking my question I need to define some objects. I will follow the book ""M. Audin, M.Damian - Morse theory and Floer homology"", but the terminology is quite standard: Let be a smooth compact manifold and consider a Morse-Smale pair on ( is a gradient-like vector field and is an adapted Morse function). If are two critical points of , we indicate with the manifold such that every point is a trajectory of ''starting'' from and ''ending'' in . One can show that if then is a finite set. Moreover if we orient the stable manifold , remember that it is a disk, we induce an orientation on , namely at each point we associate if . At this point one can define the Morse-Smale complex: where clearly is the set of critical points of index . The map acts on the generators of in the following way: where is the sum of the (the orientations) attached to the points of . Question: From the above construction it is evident that the Morse-Smale complex (in particular the number ) depends on the   orientation that we fix on the stable manifolds . This sounds   very strange to me, indeed I'd expect a complex independent from the   orientation. Maybe by passing to the homology group one can recover   the independence but I can't see it. Many thanks.","M (X,f) M X f a,b f \mathcal L(a,b) X a b \text{ind}(a)=\text{ind}(b)+1 \mathcal{L}(a,b) W^s(a) \mathcal L(a,b) \pm 1 \text{ind}(a)=\text{ind}(b)+1 C_k:=\sum_{a\in\text{Crit}_k(f)}\mathbb Za \text{Crit}_k(f) k d_k:C_k\longrightarrow C_{k-1} C_k d_k(a)=\sum_{a\in\text{Crit}_{k-1}(f)}N(a,b)b N(a,b)\in\mathbb Z \pm 1 \mathcal L(a,b) N(a,b) W^s(a)","['differential-geometry', 'differential-topology', 'homology-cohomology', 'morse-theory']"
40,Practical drawing of geodesics,Practical drawing of geodesics,,"I want to use a computer to draw geodesics on a known parameterized surface of revolution, starting from a known point and at a known angle to the meridian. What would be the easiest way of doing this? Some methods I've considered: Using Clairaut's relation ($r \cos \theta = C$), and using small increments, but I'm afraid that this is not a general solution, as this will cause the geodesic to ""get stuck"" on parallels whenever the angle crosses zero. Use the relation that for a surface given by: $$\left(\varphi(v)\cos u, \varphi(v)\sin u, \psi(v)\right)$$ The geodesics are given by: $$\frac{du}{dv}=\frac{\sqrt{\varphi'^2+\psi'^2}}{\varphi\sqrt{\varphi^2-c^2}}\ \longrightarrow\ u(v_1) = u_0 + \int_{v_0}^{v_1} \frac{\sqrt{\varphi'^2+\psi'^2}}{\varphi\sqrt{\varphi^2-c^2}} dv$$ This presents the problem of finding the correct value of $c$ given the starting angle, and as user levap pointed out, has the same ""getting stuck"" problem, since $u(v)$ is no longer a function. Various numerical methods which work for any triangulated surface, but I feel it would be a shame to use these when I know the exact form of the surface. Are there any easier methods or modifications to the above?","I want to use a computer to draw geodesics on a known parameterized surface of revolution, starting from a known point and at a known angle to the meridian. What would be the easiest way of doing this? Some methods I've considered: Using Clairaut's relation ($r \cos \theta = C$), and using small increments, but I'm afraid that this is not a general solution, as this will cause the geodesic to ""get stuck"" on parallels whenever the angle crosses zero. Use the relation that for a surface given by: $$\left(\varphi(v)\cos u, \varphi(v)\sin u, \psi(v)\right)$$ The geodesics are given by: $$\frac{du}{dv}=\frac{\sqrt{\varphi'^2+\psi'^2}}{\varphi\sqrt{\varphi^2-c^2}}\ \longrightarrow\ u(v_1) = u_0 + \int_{v_0}^{v_1} \frac{\sqrt{\varphi'^2+\psi'^2}}{\varphi\sqrt{\varphi^2-c^2}} dv$$ This presents the problem of finding the correct value of $c$ given the starting angle, and as user levap pointed out, has the same ""getting stuck"" problem, since $u(v)$ is no longer a function. Various numerical methods which work for any triangulated surface, but I feel it would be a shame to use these when I know the exact form of the surface. Are there any easier methods or modifications to the above?",,"['differential-geometry', 'numerical-methods']"
41,Ricci identity in Lectures on Ricci Flow,Ricci identity in Lectures on Ricci Flow,,"So in the book, Lectures on Ricci flow , the identity is given as $$-\nabla^2_{X,Y}A(W,Z,\ldots)+\nabla_{Y,X}^2A(W,Z,\ldots)=-A(R(X,Y)W,Z,\ldots)-A(W,R(X,Y)Z,\ldots)$$ where  $$R(X,Y)=\nabla^2_{Y,X}-\nabla_{X,Y}^2$$ But the way how covariant derivatives distributes over a tensor field I think it should be $$-\nabla^2_{X,Y}A(W,Z,\ldots)+\nabla_{Y,X}^2A(W,Z,\ldots)=R(X,Y)(A(W,Z,\ldots))-A(R(X,Y)W,Z,\ldots)-A(W,R(X,Y)Z,\ldots)-\cdots$$ Is there something I am misunderstanding here?","So in the book, Lectures on Ricci flow , the identity is given as $$-\nabla^2_{X,Y}A(W,Z,\ldots)+\nabla_{Y,X}^2A(W,Z,\ldots)=-A(R(X,Y)W,Z,\ldots)-A(W,R(X,Y)Z,\ldots)$$ where  $$R(X,Y)=\nabla^2_{Y,X}-\nabla_{X,Y}^2$$ But the way how covariant derivatives distributes over a tensor field I think it should be $$-\nabla^2_{X,Y}A(W,Z,\ldots)+\nabla_{Y,X}^2A(W,Z,\ldots)=R(X,Y)(A(W,Z,\ldots))-A(R(X,Y)W,Z,\ldots)-A(W,R(X,Y)Z,\ldots)-\cdots$$ Is there something I am misunderstanding here?",,"['differential-geometry', 'riemannian-geometry', 'ricci-flow']"
42,Is any 2$m$-dimensional manifold almost complex?,Is any 2-dimensional manifold almost complex?,m,"In Nakahara's book ""Geometry, Topology and Physics"" (Ch. 8, about the almost complex structure) they write: Note that any 2$m$-dimensional manifold locally admits a tensor field $J$ [type (1,1)] which squares to $-id_{2m}$ [on $T_pM$]. Now, in view of the definition of almost complex manifold (some pages below in the book): $M$ is called an a.c.m.  if there exists a $(1,1)$-type tensor field $J$ (called the almost complex structure) such that $J_p^2 = -id_{T_pM}$ at each point $p \in M$ it seems to me that the first quoted sentence says something like ""every 2$m$-dimensional manifold is almost complex"". But, this cannot be true, since $S^4$ is the counterexample. Where am I wrong?","In Nakahara's book ""Geometry, Topology and Physics"" (Ch. 8, about the almost complex structure) they write: Note that any 2$m$-dimensional manifold locally admits a tensor field $J$ [type (1,1)] which squares to $-id_{2m}$ [on $T_pM$]. Now, in view of the definition of almost complex manifold (some pages below in the book): $M$ is called an a.c.m.  if there exists a $(1,1)$-type tensor field $J$ (called the almost complex structure) such that $J_p^2 = -id_{T_pM}$ at each point $p \in M$ it seems to me that the first quoted sentence says something like ""every 2$m$-dimensional manifold is almost complex"". But, this cannot be true, since $S^4$ is the counterexample. Where am I wrong?",,"['differential-geometry', 'differential-topology', 'complex-geometry', 'almost-complex']"
43,Parallelisable three dimensional orientable manifolds and Stiefel's theorem,Parallelisable three dimensional orientable manifolds and Stiefel's theorem,,"On Steenrod's book ""The topology of fibre bundles"" by the end of page 203 and beginning of page 204, Steenrod claims that any orientable three dimensional manifold is parallelisable, and he cites an article by Stielfel: ""Richtungsfelder und Fernparallelismus in n-dimensionalen Mannigfaltigkeiten"". I cannot read mathematics in German; thus my question is: Does Stielfel's theorem about the parallelisability of orientable three manifolds applies to noncompact ones, or his proof relies on the assumption that the manifold is compact? If his proof depends on the manifold being compact, Is it true that any noncompact and orientable three dimensional manifold is parallelisable? PVAL suggested a proof in his answer to this question: Elementary proof of the fact that any orientable 3-manifold is parallelizable . However, I should like to see a reference in the literature with more details than Steenrod's comments (in English, if it is the case that Stielfel's theorem holds for noncompact manifolds).","On Steenrod's book ""The topology of fibre bundles"" by the end of page 203 and beginning of page 204, Steenrod claims that any orientable three dimensional manifold is parallelisable, and he cites an article by Stielfel: ""Richtungsfelder und Fernparallelismus in n-dimensionalen Mannigfaltigkeiten"". I cannot read mathematics in German; thus my question is: Does Stielfel's theorem about the parallelisability of orientable three manifolds applies to noncompact ones, or his proof relies on the assumption that the manifold is compact? If his proof depends on the manifold being compact, Is it true that any noncompact and orientable three dimensional manifold is parallelisable? PVAL suggested a proof in his answer to this question: Elementary proof of the fact that any orientable 3-manifold is parallelizable . However, I should like to see a reference in the literature with more details than Steenrod's comments (in English, if it is the case that Stielfel's theorem holds for noncompact manifolds).",,"['differential-geometry', 'reference-request']"
44,"If two objects have the same gaussian curvature, are they the same up to isometries?","If two objects have the same gaussian curvature, are they the same up to isometries?",,"I was reading about Gauss Egregium Theorem but I'm not sure if I understand it well. Intuitively, what does it mean? It is true that if two objects have the same Gaussian curvature, then they are the same, OR is true that if two objects have an isometry, then they have the same curvature? The statement says that Gaussian curvature is preserved under isometries, but the trouble starts with the word preserves. Any hint would be appreciated.","I was reading about Gauss Egregium Theorem but I'm not sure if I understand it well. Intuitively, what does it mean? It is true that if two objects have the same Gaussian curvature, then they are the same, OR is true that if two objects have an isometry, then they have the same curvature? The statement says that Gaussian curvature is preserved under isometries, but the trouble starts with the word preserves. Any hint would be appreciated.",,"['differential-geometry', 'curvature']"
45,Why does it suffice to check the geodesic equation to leading order?,Why does it suffice to check the geodesic equation to leading order?,,"I am reading Taubes's book on differential geometry and am wondering about a proof. My apologies if this is simple, as I'm still grappling with the material. My question concerns material in chapter 8, page 83. Embed $S^n$ into $\mathbb R^{n+1}$ as the set of points with $|x|=1$. Pulling back the standard metric on $\mathbb R$ gives a metric on $S^n$ called the round metric. Taubes asserts the geodesic equation for a curve $\gamma: \mathbb R \rightarrow S^n \subset\mathbb R^{n+1}$ with coordinates $(x^i(t))$ is given by $$\ddot x^j + x^j|\dot x|^2=0.$$ To show this, he introduces the map $y\rightarrow (y, (1-|y|^2)^{1/2})$ from $\mathbb R^n$ to $\mathbb R^n \times \mathbb R$ that embeds the ball of radius $1$ into $S^n$. Pulling back the round metric gives  $$g_{ij} = \delta_{ij} + y_i y_j(1-|y|^2)^{-1}.$$ (This expression fixes a typo found in the book and pointed out here. ) Expanding in a power series and writing out the geodesic equation gives  $$\ddot y+y_j|\dot y|^2 +O(|y|^2)=0.$$ Taubes asserts that since this matches the original equation to leading order in $y$, the claim is proved. Why is this? That is, why does it suffices to check that the equations agree to leading order? His justification, which I do not understand, is: This agrees with what is written above to leading order in y. Since the metric and the sphere are invariant under rotations of   $S^n$, as is the equation for $x$ above, this verifies the equation at   all points. Presumably the second sentence is just referring to the face that, by symmetry, it suffices to verify the equation for the given coordinate patch, but perhaps there is more I am missing. I am also confused because the equation in $y$ is in $\mathbb R^n$, but the equation in $x$ is in $\mathbb R^{n+1}$. What is going on here?","I am reading Taubes's book on differential geometry and am wondering about a proof. My apologies if this is simple, as I'm still grappling with the material. My question concerns material in chapter 8, page 83. Embed $S^n$ into $\mathbb R^{n+1}$ as the set of points with $|x|=1$. Pulling back the standard metric on $\mathbb R$ gives a metric on $S^n$ called the round metric. Taubes asserts the geodesic equation for a curve $\gamma: \mathbb R \rightarrow S^n \subset\mathbb R^{n+1}$ with coordinates $(x^i(t))$ is given by $$\ddot x^j + x^j|\dot x|^2=0.$$ To show this, he introduces the map $y\rightarrow (y, (1-|y|^2)^{1/2})$ from $\mathbb R^n$ to $\mathbb R^n \times \mathbb R$ that embeds the ball of radius $1$ into $S^n$. Pulling back the round metric gives  $$g_{ij} = \delta_{ij} + y_i y_j(1-|y|^2)^{-1}.$$ (This expression fixes a typo found in the book and pointed out here. ) Expanding in a power series and writing out the geodesic equation gives  $$\ddot y+y_j|\dot y|^2 +O(|y|^2)=0.$$ Taubes asserts that since this matches the original equation to leading order in $y$, the claim is proved. Why is this? That is, why does it suffices to check that the equations agree to leading order? His justification, which I do not understand, is: This agrees with what is written above to leading order in y. Since the metric and the sphere are invariant under rotations of   $S^n$, as is the equation for $x$ above, this verifies the equation at   all points. Presumably the second sentence is just referring to the face that, by symmetry, it suffices to verify the equation for the given coordinate patch, but perhaps there is more I am missing. I am also confused because the equation in $y$ is in $\mathbb R^n$, but the equation in $x$ is in $\mathbb R^{n+1}$. What is going on here?",,"['differential-geometry', 'riemannian-geometry', 'geodesic']"
46,Easy example of unit speed plane curve?,Easy example of unit speed plane curve?,,"I was trying to find a non-trivial example of a unit speed plane curve. The reason is I want something to work with but if I start with a non-unit speed curve and then do the arc length parameterisation I end up with something impossible. The trivial example is of course the unit circle $(\cos t, \sin t)$ but this is indeed trivial as the curvature is $1$ and also, the circle is too obvious (can determine the curvature just by looking at it). Does anyone know a unit speed curve that is not the circle?","I was trying to find a non-trivial example of a unit speed plane curve. The reason is I want something to work with but if I start with a non-unit speed curve and then do the arc length parameterisation I end up with something impossible. The trivial example is of course the unit circle $(\cos t, \sin t)$ but this is indeed trivial as the curvature is $1$ and also, the circle is too obvious (can determine the curvature just by looking at it). Does anyone know a unit speed curve that is not the circle?",,['differential-geometry']
47,Different definitions of differential forms?,Different definitions of differential forms?,,"I am a physicist and was reading about differential forms in Classical Mechanics. Now, I thought that a two-form is a smooth map $\omega : M \rightarrow \Lambda(T^*M)$ so that a point $p$ on the manifold is mapped smoothly to a k-form in $T_p^*M \wedge ...\wedge T_p^*M.$ But now I found the notation $\omega(p,v)(q,w)$ in these notes (sorry they are not online) for $p,q \in M$ and $v \in T_pM$, $w \in T_qM$ respectively. This is of course something different than what I assumed, because here we are talking about two points of the manifold. Is this non-sense or am I understanding the definition not correctly?","I am a physicist and was reading about differential forms in Classical Mechanics. Now, I thought that a two-form is a smooth map $\omega : M \rightarrow \Lambda(T^*M)$ so that a point $p$ on the manifold is mapped smoothly to a k-form in $T_p^*M \wedge ...\wedge T_p^*M.$ But now I found the notation $\omega(p,v)(q,w)$ in these notes (sorry they are not online) for $p,q \in M$ and $v \in T_pM$, $w \in T_qM$ respectively. This is of course something different than what I assumed, because here we are talking about two points of the manifold. Is this non-sense or am I understanding the definition not correctly?",,"['real-analysis', 'differential-geometry', 'manifolds', 'differential-topology', 'differential-forms']"
48,Ricci curvature of the Grassmannian?,Ricci curvature of the Grassmannian?,,"Let $G(k, \mathbb{C}^n)$ be the Grassmannian of $k-$dimensional complex linear subspaces of $\mathbb{C}^n.$  We know that the Grassmannian can be embedded to the projective space $(\mathbb{P}^N,\omega_{FS})$ for some $N,$ via the Plucker embedding. What can we say about the Ricci curvature of the Grassmannian? or even the scalar curvature? (any bounds?)","Let $G(k, \mathbb{C}^n)$ be the Grassmannian of $k-$dimensional complex linear subspaces of $\mathbb{C}^n.$  We know that the Grassmannian can be embedded to the projective space $(\mathbb{P}^N,\omega_{FS})$ for some $N,$ via the Plucker embedding. What can we say about the Ricci curvature of the Grassmannian? or even the scalar curvature? (any bounds?)",,"['algebraic-geometry', 'differential-geometry', 'riemannian-geometry', 'complex-geometry', 'grassmannian']"
49,Lower bound on convexity radius in terms of injectivity radius (without using curvature),Lower bound on convexity radius in terms of injectivity radius (without using curvature),,"Let $M$ be a complete Riemannian manifold, and let $C$ be a subset of $M$. We will say $C$ is convex if for any points $p,q \in C$, there exists a unique normal minimal geodesic $\gamma$ joining $p$ and $q$, such that $\gamma \subset C$. We will define: the convexity radius of $M$ by ""the infimum of positive numbers $r$ such that the geodesic open ball $B(p,r)$ is convex for every $p \in M$"", the injectivity radius at $p$  by ""the infimum of the cut values of the various geodesics emanting from $p$"" (i.e. the radius of the largest geodesic ball on which $\exp$ is a diffeomorphism) the injectivity radius of $M$ as $\inf_{p \in M} \{\textrm{injectivity radius of } $p$\}$ (these definitions are taken from Berger's A Panoramic View of Riemannian Geometry , but appear to be standard across the field). Now, we have the following theorem, bounding the convexity radius from below in terms of the injectivity radius, and sectional curvature $K$: THM : If $M$ is compact, $\textrm{Convexity Radius}(M) \geq \min \{ \frac12  \pi/\sqrt{ \sup K}, \frac 12 \textrm{Injectivity Radius}(M)\}$ Where $\frac12 \sup \pi/\sqrt K$ is replaced by $\infty$ if $\sup K \leq 0$. (and if $M$ is not compact, a local version of the statement still holds) and Berger additionally notes: ""Apparently there is no example in the literature with the convexity radius smaller than half of the injectivity radius. A natural conjecture is that such a bound should not be too difficult to prove."" My question is essentially about a weaker form of this conjecture; in particular, if we can assume the injectivity radius is maximal, can we conclude something similar of the convexity radius (and without considering the curvature)? Or more precisely: Q : If the manifold is simple (meaning any two points are connected by a unique minimizing geodesic; equivalently the exponential is a global diffeomorphism at any point), is the geodesic ball $B(r,p)$ convex for any $r> 0$?","Let $M$ be a complete Riemannian manifold, and let $C$ be a subset of $M$. We will say $C$ is convex if for any points $p,q \in C$, there exists a unique normal minimal geodesic $\gamma$ joining $p$ and $q$, such that $\gamma \subset C$. We will define: the convexity radius of $M$ by ""the infimum of positive numbers $r$ such that the geodesic open ball $B(p,r)$ is convex for every $p \in M$"", the injectivity radius at $p$  by ""the infimum of the cut values of the various geodesics emanting from $p$"" (i.e. the radius of the largest geodesic ball on which $\exp$ is a diffeomorphism) the injectivity radius of $M$ as $\inf_{p \in M} \{\textrm{injectivity radius of } $p$\}$ (these definitions are taken from Berger's A Panoramic View of Riemannian Geometry , but appear to be standard across the field). Now, we have the following theorem, bounding the convexity radius from below in terms of the injectivity radius, and sectional curvature $K$: THM : If $M$ is compact, $\textrm{Convexity Radius}(M) \geq \min \{ \frac12  \pi/\sqrt{ \sup K}, \frac 12 \textrm{Injectivity Radius}(M)\}$ Where $\frac12 \sup \pi/\sqrt K$ is replaced by $\infty$ if $\sup K \leq 0$. (and if $M$ is not compact, a local version of the statement still holds) and Berger additionally notes: ""Apparently there is no example in the literature with the convexity radius smaller than half of the injectivity radius. A natural conjecture is that such a bound should not be too difficult to prove."" My question is essentially about a weaker form of this conjecture; in particular, if we can assume the injectivity radius is maximal, can we conclude something similar of the convexity radius (and without considering the curvature)? Or more precisely: Q : If the manifold is simple (meaning any two points are connected by a unique minimizing geodesic; equivalently the exponential is a global diffeomorphism at any point), is the geodesic ball $B(r,p)$ convex for any $r> 0$?",,"['differential-geometry', 'reference-request', 'partial-differential-equations', 'riemannian-geometry']"
50,Why is the Lagrangian a function on the tangent bundle?,Why is the Lagrangian a function on the tangent bundle?,,"I understand that empirically the state of a dynamical system (at a given instant in time) is determined by specifying it's position and velocity, but I'm slightly unsure as to why the Lagrangian is defined on the tangent bundle? Is the point that the Lagrangian of a system is defined independently of any path $q(t) $ that the system takes through configuration space.  Thus, at each instant in time we wish to have a function that encodes the dynamics of a system at that instant. This implies that such a function should be dependent on the point in configuration space, $q$ and also the possible velocities at that point (i.e. the tangent vectors at that point), $\dot {q} $,  in other words it should be a function on the tangent bundle $$\mathcal{L} :TM\rightarrow \mathbb {R} \;\;, \;\;\mathcal{L}= \mathcal{L}(q, \dot{q}) $$ By evaluating $\mathcal{L}$ on a particular curve through configuration space,  $q(t) $,  with corresponding velocity curve $\dot{q} (t) =\frac{dq} {dt} $ (i.e. $\mathcal{L}= \mathcal{L}(q(t), \dot{q} (t)) $) we obtain a description of the dynamics of the system if it followed that particular path through configuration space?! Sorry for the long-windedness of this post,  just really want to get this concept sorted it in my head.","I understand that empirically the state of a dynamical system (at a given instant in time) is determined by specifying it's position and velocity, but I'm slightly unsure as to why the Lagrangian is defined on the tangent bundle? Is the point that the Lagrangian of a system is defined independently of any path $q(t) $ that the system takes through configuration space.  Thus, at each instant in time we wish to have a function that encodes the dynamics of a system at that instant. This implies that such a function should be dependent on the point in configuration space, $q$ and also the possible velocities at that point (i.e. the tangent vectors at that point), $\dot {q} $,  in other words it should be a function on the tangent bundle $$\mathcal{L} :TM\rightarrow \mathbb {R} \;\;, \;\;\mathcal{L}= \mathcal{L}(q, \dot{q}) $$ By evaluating $\mathcal{L}$ on a particular curve through configuration space,  $q(t) $,  with corresponding velocity curve $\dot{q} (t) =\frac{dq} {dt} $ (i.e. $\mathcal{L}= \mathcal{L}(q(t), \dot{q} (t)) $) we obtain a description of the dynamics of the system if it followed that particular path through configuration space?! Sorry for the long-windedness of this post,  just really want to get this concept sorted it in my head.",,"['differential-geometry', 'calculus-of-variations']"
51,Proving Gaussian curvature $\leq 0$ on line,Proving Gaussian curvature  on line,\leq 0,"Given some regular surface $S$ that contains a line $L$, I need to prove that the Gaussian curvature $K\leq 0$ at all points of $L$. I am thinking that if I could show that no points on $L$ can be elliptical $K>0$ then I would be set. But how can I do that?","Given some regular surface $S$ that contains a line $L$, I need to prove that the Gaussian curvature $K\leq 0$ at all points of $L$. I am thinking that if I could show that no points on $L$ can be elliptical $K>0$ then I would be set. But how can I do that?",,['differential-geometry']
52,"Can't we consider the curve $t\to(\gamma(t),X(\gamma(t))$ instead of the covariant derivative $\nabla_{\gamma(t)}X$?",Can't we consider the curve  instead of the covariant derivative ?,"t\to(\gamma(t),X(\gamma(t)) \nabla_{\gamma(t)}X","Many text books on differential geometry motivate covariant derivative more or less by saying that if you have a vector field along a curve on a manifold (that is a curve $\gamma(t)$ and an assignment of a vector $X(\gamma(t))$ at each point) then you can not directly define its derivative because you can not subtract two vectors living at different spaces. Lie Derivative here does not also help since you would need to extend $\dot{\gamma(t)}$ to a vector field to define the Lie derivative along that vector field and then the Lie derivative will depend on the extension. So ok covariant derivative $\nabla_{\gamma(t)}X$ gives you a way to differentiate vector fields along curves by letting you compare two different tangent spaces through parallel transport along $\gamma(t)$ . But what I dont understand is what is the problem with constructing the curve $t \rightarrow (\gamma(t),X(\gamma(t)))$ which will be a curve inside the manifold TM and then derivative it whose coordinate expression would be $(\gamma(t),X(\gamma(t)),X(\gamma(t)),\beta(t))$ and call $\beta(t)$ the derivative of $X$ along $\gamma(t)$ . This derivative does not live on $TM$ but lives on $TTM$ that is true, but what is the problem with this? This also makes me think whether if one can define a connection on $M$ by defining some kind of projection $\pi: TTM \rightarrow TM$ so that first you find $\beta$ as above and then somehow send it back to $TM$ . In fact this is the way how you turn a second order ODE on $M$ to a first order ODE on $TM$ . Is there are more deeper way of understanding the necessity for covariant derivative?","Many text books on differential geometry motivate covariant derivative more or less by saying that if you have a vector field along a curve on a manifold (that is a curve and an assignment of a vector at each point) then you can not directly define its derivative because you can not subtract two vectors living at different spaces. Lie Derivative here does not also help since you would need to extend to a vector field to define the Lie derivative along that vector field and then the Lie derivative will depend on the extension. So ok covariant derivative gives you a way to differentiate vector fields along curves by letting you compare two different tangent spaces through parallel transport along . But what I dont understand is what is the problem with constructing the curve which will be a curve inside the manifold TM and then derivative it whose coordinate expression would be and call the derivative of along . This derivative does not live on but lives on that is true, but what is the problem with this? This also makes me think whether if one can define a connection on by defining some kind of projection so that first you find as above and then somehow send it back to . In fact this is the way how you turn a second order ODE on to a first order ODE on . Is there are more deeper way of understanding the necessity for covariant derivative?","\gamma(t) X(\gamma(t)) \dot{\gamma(t)} \nabla_{\gamma(t)}X \gamma(t) t \rightarrow (\gamma(t),X(\gamma(t))) (\gamma(t),X(\gamma(t)),X(\gamma(t)),\beta(t)) \beta(t) X \gamma(t) TM TTM M \pi: TTM \rightarrow TM \beta TM M TM","['differential-geometry', 'connections']"
53,"If $f\colon M^n\to N^n$ is proper, $N$ is connected, and $f_*$ preserves orientation at regular points, then $f$ is surjective?","If  is proper,  is connected, and  preserves orientation at regular points, then  is surjective?",f\colon M^n\to N^n N f_* f,"I'm attempting Exercise 8.21 from Spivak's Differential Geometry . It is not for homework or anything. The problem states Let $f\colon M^n\to N^n$ be a proper map between oriented $n$-manifolds such that $f_*\colon M_p\to N_{f(p)}$ ($f_*$ here is $df_p$ in other texts I think) is orientation preserving whenever $p$ is a regular point. If $N$ is connected, then either $f$ is onto $N$, or else all points are critical points of $f$. First, since $f$ is a proper map between manifolds, it is closed, and thus $\operatorname{im}(f)\subset N$ is closed. I want to show, assuming that there is a regular point of $f$ in $M$, then $\operatorname{im}(f)$ is open, hence all of $N$ since $N$ is connected. If $p$ is a regular point, so $f_*\colon M_p\to N_{f(p)}$ is surjective, so is also bijective since $M$ and $N$ are both $n$-dimensional. By the inverse function theorem, $f$ is a local diffeomorphism, so maps an open neighborhood of $p$ onto an open neighborhood of $f(p)$. If I could show arbitrary $q\in\operatorname{im}(f)$ is in one of these neighborhoods, then I would be done. If $q$ is not in the diffeomorphic image of any open neighborhood of a regular point of $f$, does this contradiction the orientation preserving property somehow?","I'm attempting Exercise 8.21 from Spivak's Differential Geometry . It is not for homework or anything. The problem states Let $f\colon M^n\to N^n$ be a proper map between oriented $n$-manifolds such that $f_*\colon M_p\to N_{f(p)}$ ($f_*$ here is $df_p$ in other texts I think) is orientation preserving whenever $p$ is a regular point. If $N$ is connected, then either $f$ is onto $N$, or else all points are critical points of $f$. First, since $f$ is a proper map between manifolds, it is closed, and thus $\operatorname{im}(f)\subset N$ is closed. I want to show, assuming that there is a regular point of $f$ in $M$, then $\operatorname{im}(f)$ is open, hence all of $N$ since $N$ is connected. If $p$ is a regular point, so $f_*\colon M_p\to N_{f(p)}$ is surjective, so is also bijective since $M$ and $N$ are both $n$-dimensional. By the inverse function theorem, $f$ is a local diffeomorphism, so maps an open neighborhood of $p$ onto an open neighborhood of $f(p)$. If I could show arbitrary $q\in\operatorname{im}(f)$ is in one of these neighborhoods, then I would be done. If $q$ is not in the diffeomorphic image of any open neighborhood of a regular point of $f$, does this contradiction the orientation preserving property somehow?",,"['differential-geometry', 'differential-topology']"
54,differential geometry : basic query about tensor notation and tensor products,differential geometry : basic query about tensor notation and tensor products,,"I have a few very basic queries. I've been studying differential geometry as part of a course on General Relativity, so I don't have a very well grounded understanding of the mathematical formalism; it's all kind of a blurry mess of index notations. The question are: 1) How do I formally interpret the product of two tensors/vectors? We often write products of the type $v^iw^j$ and just interpret them as a rank 2 tensor. Is this expression commutative? i.e. is it the same as  $w^jv^i$? I realize that this creature transforms like a rank 2 contra-variant tensor, but does it mean anything geometrically? Is there a meaningful notion of a product here? The same can be done for higher rank tensors, even products of mixed higher with lower rank tensors, etc. 2) Regarding the operation of lowering and raising indexes using the metric tensor. I realize that we define the co-variant vector $v_i$  as $g^{ij}v^j$. Can I write this as  $v^jg^{ij}$? This kind of relates to the previous question regarding commutation. Do I interpret the raising/lowering operation as a linear operator operating on a vector? If so the second notation seems wrong to me, but I've seen it used before... 3) We often encounter equations like the following one for a Christoffel symbol - $\Gamma_{\,\mu\nu}^{\rho}=g^{\rho\rho'}\Gamma_{\rho,\mu\nu}$. I have a problem interpreting this type of equation, as for it to make sense, I generally expect to see the same indexes on both sides. However on the right side $\rho$ is a summation index and doesn't actually appear there. I realize this is ""just"" raising the index, but when I look at what's actually written it seems like abuse of notation. Am I misunderstanding this? Thanks a lot in advance for any help","I have a few very basic queries. I've been studying differential geometry as part of a course on General Relativity, so I don't have a very well grounded understanding of the mathematical formalism; it's all kind of a blurry mess of index notations. The question are: 1) How do I formally interpret the product of two tensors/vectors? We often write products of the type $v^iw^j$ and just interpret them as a rank 2 tensor. Is this expression commutative? i.e. is it the same as  $w^jv^i$? I realize that this creature transforms like a rank 2 contra-variant tensor, but does it mean anything geometrically? Is there a meaningful notion of a product here? The same can be done for higher rank tensors, even products of mixed higher with lower rank tensors, etc. 2) Regarding the operation of lowering and raising indexes using the metric tensor. I realize that we define the co-variant vector $v_i$  as $g^{ij}v^j$. Can I write this as  $v^jg^{ij}$? This kind of relates to the previous question regarding commutation. Do I interpret the raising/lowering operation as a linear operator operating on a vector? If so the second notation seems wrong to me, but I've seen it used before... 3) We often encounter equations like the following one for a Christoffel symbol - $\Gamma_{\,\mu\nu}^{\rho}=g^{\rho\rho'}\Gamma_{\rho,\mu\nu}$. I have a problem interpreting this type of equation, as for it to make sense, I generally expect to see the same indexes on both sides. However on the right side $\rho$ is a summation index and doesn't actually appear there. I realize this is ""just"" raising the index, but when I look at what's actually written it seems like abuse of notation. Am I misunderstanding this? Thanks a lot in advance for any help",,"['differential-geometry', 'tensors']"
55,Formal adjoint of divergence,Formal adjoint of divergence,,"We define the so-called conformal Killing operator $K$ mapping (1,0) vectors to (0,2) tensors by $$K(X)_{ab} = \frac{1}{2}\nabla_aX_b+ \nabla_bX_a -\frac{2}{3}(\text{div}X) g_{ab}.$$ Here $g$ is the metric and $\nabla$ is the induced covariant derivative. I am told that the formal adjoint of $K$ is $-\text{div}.$  This is supposed to be easy, but I am not getting anywhere near the answer and I presume I must be doing something basic incorrectly. Could anyone point me in the correct direction? Attempt (WRONG): Let $h_{ab}$ be a $(0,2)$ tensor. We integrate by parts over a closed manifold: $$\int -\nabla^a h_{ab} X^b = \int \nabla^a (h_{ab} X^b) + \int h_{ab} \nabla^a X^b= 0 + \int h_{ab}\nabla^aX^b.$$ This would appear to mean that -div is the adjoint of $\nabla,$ which is wrong. [Edit: see answer below for explanation. The computation is in fact correct, as pointed out by Jack Lee.]","We define the so-called conformal Killing operator $K$ mapping (1,0) vectors to (0,2) tensors by $$K(X)_{ab} = \frac{1}{2}\nabla_aX_b+ \nabla_bX_a -\frac{2}{3}(\text{div}X) g_{ab}.$$ Here $g$ is the metric and $\nabla$ is the induced covariant derivative. I am told that the formal adjoint of $K$ is $-\text{div}.$  This is supposed to be easy, but I am not getting anywhere near the answer and I presume I must be doing something basic incorrectly. Could anyone point me in the correct direction? Attempt (WRONG): Let $h_{ab}$ be a $(0,2)$ tensor. We integrate by parts over a closed manifold: $$\int -\nabla^a h_{ab} X^b = \int \nabla^a (h_{ab} X^b) + \int h_{ab} \nabla^a X^b= 0 + \int h_{ab}\nabla^aX^b.$$ This would appear to mean that -div is the adjoint of $\nabla,$ which is wrong. [Edit: see answer below for explanation. The computation is in fact correct, as pointed out by Jack Lee.]",,"['differential-geometry', 'riemannian-geometry', 'tensors']"
56,Cheeger constant for $S^2$,Cheeger constant for,S^2,"I want to calculate explicitly Cheeger constant for $S^2$, but I haven't found any sources or examples. I'm using this definition  $$h(M)=\inf_A\{\frac{vol_{n-1}(\partial A)}{vol_n{(A)}}:vol_n(A)\leq \frac{1}{2} vol_n(M)\}$$ Here $M$ is manifold. The only thing I found in the Internet was estimation, but not explicit answer. Is there any ways to get it? I would appreciate any hints.","I want to calculate explicitly Cheeger constant for $S^2$, but I haven't found any sources or examples. I'm using this definition  $$h(M)=\inf_A\{\frac{vol_{n-1}(\partial A)}{vol_n{(A)}}:vol_n(A)\leq \frac{1}{2} vol_n(M)\}$$ Here $M$ is manifold. The only thing I found in the Internet was estimation, but not explicit answer. Is there any ways to get it? I would appreciate any hints.",,"['differential-geometry', 'spectral-theory']"
57,Canonical isomorphism between vector bundle and dual?,Canonical isomorphism between vector bundle and dual?,,"So, we've been asked to show, given a real vector bundle equipped with a metric, that there is a canonical isomorphism from the vector bundle and its dual. Now, there's a theorem that says two vector bundles are isomorphic iff their transition functions satisfy $\mu_i g_{ij} = f_{ij} \mu_j$, where $\mu_i$ is a map $U_i \rightarrow GL(r, \mathbb{R})$ and $g_{ij}$ and $f_{ij}$ are the two bundles transition functions. I was going to say the following:  Given a metric and Gram-Schmid one can always arrange for orthonormal frames, and hence orthogonal transition functions.  Therefore (since the dual bundle transition functions equal the inverse transpose of the bundles transition functions), the above is satisfied trivially. My question is:  Is this still 'canonical'?  I mean, the fact you can do this is a 'universal property' of vector bundles equipped with metrics, so it should be a canonical iso (according to wikipedia).  But, I'm confused by the meaning of 'canonical isomorphism' as meaning ""independent of a basis"".  In the above, I'm specifying a basis.","So, we've been asked to show, given a real vector bundle equipped with a metric, that there is a canonical isomorphism from the vector bundle and its dual. Now, there's a theorem that says two vector bundles are isomorphic iff their transition functions satisfy $\mu_i g_{ij} = f_{ij} \mu_j$, where $\mu_i$ is a map $U_i \rightarrow GL(r, \mathbb{R})$ and $g_{ij}$ and $f_{ij}$ are the two bundles transition functions. I was going to say the following:  Given a metric and Gram-Schmid one can always arrange for orthonormal frames, and hence orthogonal transition functions.  Therefore (since the dual bundle transition functions equal the inverse transpose of the bundles transition functions), the above is satisfied trivially. My question is:  Is this still 'canonical'?  I mean, the fact you can do this is a 'universal property' of vector bundles equipped with metrics, so it should be a canonical iso (according to wikipedia).  But, I'm confused by the meaning of 'canonical isomorphism' as meaning ""independent of a basis"".  In the above, I'm specifying a basis.",,"['differential-geometry', 'vector-spaces', 'vector-bundles']"
58,Manifold allowing function with two critical points is sphere,Manifold allowing function with two critical points is sphere,,"The only closed manifolds which allow a function with two (maybe degenerate) critical points are spheres. In dimension 2 it is quite easy to prove , but what is about higher dimensions?","The only closed manifolds which allow a function with two (maybe degenerate) critical points are spheres. In dimension 2 it is quite easy to prove , but what is about higher dimensions?",,"['differential-geometry', 'algebraic-topology', 'morse-theory']"
59,Is there an easy way to reason about expressions involving lots of indices?,Is there an easy way to reason about expressions involving lots of indices?,,"I have been reading some Riemannian geometry recently. So far, I think I am understanding the concepts well enough. However, I am finding it difficult to translate some of the notation into meaning. As an example, if $F$ and $G$ are in $T^k_l(T_pM)$, we can consider the sum $$    g^{i_1 r_1} \dots g^{i_k r_k} g_{j_1 s_1} \dots g_{j_l s_l} F^{j_1 \dots j_l}_{i_1 \dots i_k} G^{s_1 \dots s_l}_{r_1 \dots r_k} \tag{1})$$ In actuality, this is just the inner product $$\langle F, G \rangle \tag{2}$$ where $\langle \cdot , \cdot \rangle$ is the inner product determined by some metric $g$. Now, (I think) I understand what this inner product means and how it is defined in terms of lowering/raising indices, etc. When I read expression (2), everything is just fine. However, expression (1) does not impart this same immediate understanding of what is going on. This confusion prompts: The Question: What can I do to make reading and understanding some of the notation used in Riemannian geometry an easier/simpler/clearer task? In particular, how might I better reason about expressions involving a large number of indices?","I have been reading some Riemannian geometry recently. So far, I think I am understanding the concepts well enough. However, I am finding it difficult to translate some of the notation into meaning. As an example, if $F$ and $G$ are in $T^k_l(T_pM)$, we can consider the sum $$    g^{i_1 r_1} \dots g^{i_k r_k} g_{j_1 s_1} \dots g_{j_l s_l} F^{j_1 \dots j_l}_{i_1 \dots i_k} G^{s_1 \dots s_l}_{r_1 \dots r_k} \tag{1})$$ In actuality, this is just the inner product $$\langle F, G \rangle \tag{2}$$ where $\langle \cdot , \cdot \rangle$ is the inner product determined by some metric $g$. Now, (I think) I understand what this inner product means and how it is defined in terms of lowering/raising indices, etc. When I read expression (2), everything is just fine. However, expression (1) does not impart this same immediate understanding of what is going on. This confusion prompts: The Question: What can I do to make reading and understanding some of the notation used in Riemannian geometry an easier/simpler/clearer task? In particular, how might I better reason about expressions involving a large number of indices?",,"['differential-geometry', 'soft-question', 'riemannian-geometry', 'tensors']"
60,"Check that the parametrization x(u,v)is conformal if and only if E=G and F=0.","Check that the parametrization x(u,v)is conformal if and only if E=G and F=0.",,"Check that the parametrization x(u,v)is conformal if and only if E=G and F=0.  I am slightly confused with what this question is asking me. Could someone please walk me through this question. I believe that for --> we need to choose two convenient pairs of orthogonal directions. However, I am unsure of where to start and how to proceed with this question.  Thank yoU!","Check that the parametrization x(u,v)is conformal if and only if E=G and F=0.  I am slightly confused with what this question is asking me. Could someone please walk me through this question. I believe that for --> we need to choose two convenient pairs of orthogonal directions. However, I am unsure of where to start and how to proceed with this question.  Thank yoU!",,"['differential-geometry', 'conformal-geometry']"
61,Inverse Image of a Regular Value an Orientable Submanifold,Inverse Image of a Regular Value an Orientable Submanifold,,"Let $f:M^n \rightarrow \mathbb{R}$ be a smooth map, and let $c\in N$ be a regular value. When is $f^{-1}(c)$ an orientable manifold? Note: I know by regular value thm, $f^{-1}(c)$ is a smooth $n-1$ dimensional submanifold of $M$, w/o boundary, and I am aware that if $M$ is $\mathbb{R}^n$ then this is true.","Let $f:M^n \rightarrow \mathbb{R}$ be a smooth map, and let $c\in N$ be a regular value. When is $f^{-1}(c)$ an orientable manifold? Note: I know by regular value thm, $f^{-1}(c)$ is a smooth $n-1$ dimensional submanifold of $M$, w/o boundary, and I am aware that if $M$ is $\mathbb{R}^n$ then this is true.",,"['differential-geometry', 'manifolds', 'differential-topology', 'smooth-manifolds']"
62,The difference between a fiber and a section of a vector bundle,The difference between a fiber and a section of a vector bundle,,"If  $ E_x := \pi^{-1}(x) $ is the fiber over $x$ where $(E,\pi,M)$ is the vector bundle. And the section is $s: M \to E $ with $\pi \circ s = id_M $. This implies that $\pi^{-1} = s $ on $M$. So then whats the difference between a fiber over $x$ and the section restricted to $x$. Thanks.","If  $ E_x := \pi^{-1}(x) $ is the fiber over $x$ where $(E,\pi,M)$ is the vector bundle. And the section is $s: M \to E $ with $\pi \circ s = id_M $. This implies that $\pi^{-1} = s $ on $M$. So then whats the difference between a fiber over $x$ and the section restricted to $x$. Thanks.",,"['differential-geometry', 'definition', 'vector-bundles']"
63,parallel curvature imply constant Ricci and scalar curvature,parallel curvature imply constant Ricci and scalar curvature,,"$\text{Suppose we have} \nabla R = 0 $, where R represents curvature tensor, Prove that Ricci  curvature and scalar curvature are constant.","$\text{Suppose we have} \nabla R = 0 $, where R represents curvature tensor, Prove that Ricci  curvature and scalar curvature are constant.",,['differential-geometry']
64,Why do Zoll metrics exist only on $S^2$ and $RP^2$?,Why do Zoll metrics exist only on  and ?,S^2 RP^2,"Zoll metric on a Riemannian manifold is a metric for which all geodesics are closed and have the same period. For sure, a standart metric on the sphere $S^2$ has this property: all its geodesics are great circles of period $2 \pi$. Projective space $RP^2$ as a factor of $S^2$ provided with the canonical metric also has all geodesics closed and of the same lenght $\pi$. There was lots of work done (Tannery, Zoll, Funk, Guillemin and others) studying Zoll surfaces. For example, a theorem of Green shows that there are no nontrivial Zoll metrics on $RP^2$. On the contrary, there is an abundance of such metrics on the sphere $S^2$, even without nontrivial isometries. My question is why Zoll metrics exist only on the sphere and its factor $RP^2$? Of course, here I restrict myself to the $2$-dimensional case. The evidence that is true is mentioned in the book A.Besse ""Manifolds all of whose geodesics are closed"". The style of the book is very formal and the statement is proven in such a generality that it's impossible to understand.  There should be some easy topological argument but I do not find it.","Zoll metric on a Riemannian manifold is a metric for which all geodesics are closed and have the same period. For sure, a standart metric on the sphere $S^2$ has this property: all its geodesics are great circles of period $2 \pi$. Projective space $RP^2$ as a factor of $S^2$ provided with the canonical metric also has all geodesics closed and of the same lenght $\pi$. There was lots of work done (Tannery, Zoll, Funk, Guillemin and others) studying Zoll surfaces. For example, a theorem of Green shows that there are no nontrivial Zoll metrics on $RP^2$. On the contrary, there is an abundance of such metrics on the sphere $S^2$, even without nontrivial isometries. My question is why Zoll metrics exist only on the sphere and its factor $RP^2$? Of course, here I restrict myself to the $2$-dimensional case. The evidence that is true is mentioned in the book A.Besse ""Manifolds all of whose geodesics are closed"". The style of the book is very formal and the statement is proven in such a generality that it's impossible to understand.  There should be some easy topological argument but I do not find it.",,"['differential-geometry', 'differential-topology']"
65,How to obtain this Pohozaev identity for the Gross-Pitaevskii equation?,How to obtain this Pohozaev identity for the Gross-Pitaevskii equation?,,"The Gross-Pitaveskii equation (after plugging in the traveling wave ansatz and writing in moving frame coordinates) reads \begin{equation} ic\partial_1 v +\Delta v +v(1-\vert v \vert^2)=0.    \end{equation} Assume $v$ is a solution on $\Omega_n^N=[-n\pi,n\pi]^N$ and $v$ is $2\pi n$-periodic in every component. In [1,p.623] the authors give Pohozaev's formula for $v$ without any proof \begin{align} \frac{N-2}{2} \int_{\Omega_n^N} \vert \nabla v \vert^2+\frac{N}{4}\int_{\Omega_n^N} (1-\vert v \vert^2)^2 - c\frac{N-1}{v} \int_{\Omega_n^N} \langle Jv, \zeta_1 \rangle \\ = n\pi \int_{\partial \Omega_n^N} \left( \frac{\vert \nabla v \vert^2}{2} + \frac{(1-\vert v \vert^2)^2}{4} \right) - \int_{\partial \Omega_n^N} \partial_\nu v \left( \sum_{j=1}^N x_j \partial_j v \right). \end{align} Here the 2-form \begin{equation} Jv \equiv \sum_{1 \leq 1 < j \leq N} (\partial_i v \times \partial_j v) dx_i \wedge dx_j \end{equation} denotes the Jacobian of $v$ and $\zeta_1$ is the 2-form defined by \begin{equation} \zeta_1(x) \equiv - \frac{2}{N-1} \sum_{i=2}^N x_i dx_1 \wedge dx_i. \end{equation} Finally, $\langle \cdot, \cdot\rangle$ stands for the scalar product of 2-forms. My Question is : How do you obtain this ""Pohozaev's formula""? From what I have read on the internet already, it seems like you have to multiply the Gross-Pitaevskii equation by $(x|\nabla v(x))$ or similar and integrate by parts. But this doesn't help me too much. How do the 2-forms appear? I'm completly lost. Any hint would be much appreciated! [1] Béthuel, F., P. Gravejat und J. C. Saut: Travelling waves for the Gross- Pitaevskii equation. II. Comm. Math. Phys., 285(2):567–651, 2009.","The Gross-Pitaveskii equation (after plugging in the traveling wave ansatz and writing in moving frame coordinates) reads \begin{equation} ic\partial_1 v +\Delta v +v(1-\vert v \vert^2)=0.    \end{equation} Assume $v$ is a solution on $\Omega_n^N=[-n\pi,n\pi]^N$ and $v$ is $2\pi n$-periodic in every component. In [1,p.623] the authors give Pohozaev's formula for $v$ without any proof \begin{align} \frac{N-2}{2} \int_{\Omega_n^N} \vert \nabla v \vert^2+\frac{N}{4}\int_{\Omega_n^N} (1-\vert v \vert^2)^2 - c\frac{N-1}{v} \int_{\Omega_n^N} \langle Jv, \zeta_1 \rangle \\ = n\pi \int_{\partial \Omega_n^N} \left( \frac{\vert \nabla v \vert^2}{2} + \frac{(1-\vert v \vert^2)^2}{4} \right) - \int_{\partial \Omega_n^N} \partial_\nu v \left( \sum_{j=1}^N x_j \partial_j v \right). \end{align} Here the 2-form \begin{equation} Jv \equiv \sum_{1 \leq 1 < j \leq N} (\partial_i v \times \partial_j v) dx_i \wedge dx_j \end{equation} denotes the Jacobian of $v$ and $\zeta_1$ is the 2-form defined by \begin{equation} \zeta_1(x) \equiv - \frac{2}{N-1} \sum_{i=2}^N x_i dx_1 \wedge dx_i. \end{equation} Finally, $\langle \cdot, \cdot\rangle$ stands for the scalar product of 2-forms. My Question is : How do you obtain this ""Pohozaev's formula""? From what I have read on the internet already, it seems like you have to multiply the Gross-Pitaevskii equation by $(x|\nabla v(x))$ or similar and integrate by parts. But this doesn't help me too much. How do the 2-forms appear? I'm completly lost. Any hint would be much appreciated! [1] Béthuel, F., P. Gravejat und J. C. Saut: Travelling waves for the Gross- Pitaevskii equation. II. Comm. Math. Phys., 285(2):567–651, 2009.",,"['differential-geometry', 'partial-differential-equations']"
66,Differentiable manifolds $\mathscr C^k$ vs. $\mathscr C^\infty$,Differentiable manifolds  vs.,\mathscr C^k \mathscr C^\infty,"I noticed that there exists a (in some sense) better definition of the tangent space via the dual of a certain quotient algebra which is easier to work with in some cases. This however only works for smooth manifolds. My question is, is there a substantial loss of generality if I assume that a manifold is smooth rather than $\mathscr C^k$? What do I really lose by making such an assumtion? I noticed that most books simply work with smooth manifolds right from the start, barely mentioning the (not as nice) $\mathscr C^k$ manifolds. Thanks","I noticed that there exists a (in some sense) better definition of the tangent space via the dual of a certain quotient algebra which is easier to work with in some cases. This however only works for smooth manifolds. My question is, is there a substantial loss of generality if I assume that a manifold is smooth rather than $\mathscr C^k$? What do I really lose by making such an assumtion? I noticed that most books simply work with smooth manifolds right from the start, barely mentioning the (not as nice) $\mathscr C^k$ manifolds. Thanks",,"['differential-geometry', 'manifolds']"
67,A question about concept of pushforward,A question about concept of pushforward,,"In An Introduction to Smooth manifolds by Lee is written: for any smooth vector fields V and W on a manifold $M$, let $\theta$ be the flow of $V$, and define a vector $(\mathcal{L}_v W)_p$ at each $p\in M$, called the Lie derivative of $W$ with respect to $V$ at p, by $$(\mathcal{L}_v W)_p = -d/dt|_{t=0} (\theta_{-t})_{*} W_{\theta_{t}(p)}=\lim_{t\to 0}\frac{(\theta_{-t})_{*} W_{\theta_{t}(p)}-W_p}{t}$$ Now, my question is about pushforward. If the manifold is equipped with Levi Civita connection, then what is the difference between push $W_{\theta_{t}(p)}$ forward to the point $p$ by $(\theta_{-t})_{*}$ and parallel transport $W_{\theta_{t}(p)}$ to the point $p$ by Levi-Civita connectin? thanks!","In An Introduction to Smooth manifolds by Lee is written: for any smooth vector fields V and W on a manifold $M$, let $\theta$ be the flow of $V$, and define a vector $(\mathcal{L}_v W)_p$ at each $p\in M$, called the Lie derivative of $W$ with respect to $V$ at p, by $$(\mathcal{L}_v W)_p = -d/dt|_{t=0} (\theta_{-t})_{*} W_{\theta_{t}(p)}=\lim_{t\to 0}\frac{(\theta_{-t})_{*} W_{\theta_{t}(p)}-W_p}{t}$$ Now, my question is about pushforward. If the manifold is equipped with Levi Civita connection, then what is the difference between push $W_{\theta_{t}(p)}$ forward to the point $p$ by $(\theta_{-t})_{*}$ and parallel transport $W_{\theta_{t}(p)}$ to the point $p$ by Levi-Civita connectin? thanks!",,"['differential-geometry', 'manifolds', 'riemannian-geometry']"
68,Distinguished map that straightens a curve,Distinguished map that straightens a curve,,"Consider a smooth finite curve $\gamma$ without intersections in $\mathbb{R}^2$ . Consider the family of smooth maps $T:\mathbb{R}^2\rightarrow\mathbb{R}^2$ such that $T(\gamma)$ is a straight line. Which ways are there to distinguish one of these transformations as the one (straightening map of $\gamma$ ), e.g. the one closest to the identity transformation? How could this transformation be constructed from $\gamma$ ? Background Consider a straight line $PQ$ and all other curves $\gamma$ connecting $P$ and $Q$ , each of them approximating the straight line better or worse according to a given distance function $\delta$ between curves. Suppose there is one distinguished straightening map $T$ for one of those curves $\gamma_0$ with given distance $\delta(PQ,\gamma_0)$ . Then the question arises how the images of $PQ$ and $\gamma_0$ under $T$ behave, i.e. what can be said about $\delta(PQ,\gamma_0)$ vs. $\delta(T(PQ),T(\gamma_0))$ ?","Consider a smooth finite curve without intersections in . Consider the family of smooth maps such that is a straight line. Which ways are there to distinguish one of these transformations as the one (straightening map of ), e.g. the one closest to the identity transformation? How could this transformation be constructed from ? Background Consider a straight line and all other curves connecting and , each of them approximating the straight line better or worse according to a given distance function between curves. Suppose there is one distinguished straightening map for one of those curves with given distance . Then the question arises how the images of and under behave, i.e. what can be said about vs. ?","\gamma \mathbb{R}^2 T:\mathbb{R}^2\rightarrow\mathbb{R}^2 T(\gamma) \gamma \gamma PQ \gamma P Q \delta T \gamma_0 \delta(PQ,\gamma_0) PQ \gamma_0 T \delta(PQ,\gamma_0) \delta(T(PQ),T(\gamma_0))",['differential-geometry']
69,Does the $O(n)$ bundle of a manifold depend on the metric?,Does the  bundle of a manifold depend on the metric?,O(n),"Let $g_1$ and $g_2$ be two Riemannian metrics on a manifold $M$. These induce two $O(n)$ bundles on $M$, whose fibers over each point $x\in M$ are the groups of orthogonal transformations of $T_x M$ with respect to $g_1$ or $g_2$, respectively. Are these two $O(n)$ bundles necessarily isomorphic?","Let $g_1$ and $g_2$ be two Riemannian metrics on a manifold $M$. These induce two $O(n)$ bundles on $M$, whose fibers over each point $x\in M$ are the groups of orthogonal transformations of $T_x M$ with respect to $g_1$ or $g_2$, respectively. Are these two $O(n)$ bundles necessarily isomorphic?",,"['differential-geometry', 'lie-groups', 'riemannian-geometry']"
70,Is the tangent bundle the DISJOINT union of tangent spaces?,Is the tangent bundle the DISJOINT union of tangent spaces?,,"Let $M$ be a smooth manifold and consider the Lee's definition of the tangent space $T_pM$ (so $T_pM$ is the vector space of derivations at $p$). The canonical definition of tangent bundle (as set) of $M$ is:  $$TM=\bigcup_{p\in M}\{ p\}\times T_pM$$ so it is the disjoint union of all tangent spaces; but L.W.Tu in his ""Introduction to Manifolds"" says that the tangent spaces are already disjoint and for this reason he defines $$TM=\bigcup_{p\in M} T_pM$$ Why we can't find a common derivation between $T_pM$ and $T_qM$ if $q\neq p$? I think that Tu's statement  is not true.","Let $M$ be a smooth manifold and consider the Lee's definition of the tangent space $T_pM$ (so $T_pM$ is the vector space of derivations at $p$). The canonical definition of tangent bundle (as set) of $M$ is:  $$TM=\bigcup_{p\in M}\{ p\}\times T_pM$$ so it is the disjoint union of all tangent spaces; but L.W.Tu in his ""Introduction to Manifolds"" says that the tangent spaces are already disjoint and for this reason he defines $$TM=\bigcup_{p\in M} T_pM$$ Why we can't find a common derivation between $T_pM$ and $T_qM$ if $q\neq p$? I think that Tu's statement  is not true.",,"['differential-geometry', 'differential-topology']"
71,Christoffel symbols and fundamental forms,Christoffel symbols and fundamental forms,,"How can we prove that the christoffel symbol is \[ \Gamma^k_{ij} = \frac 12 \sum_{l=1}^2 g^{kl} \left(\frac{\partial g_{il}}{\partial u^j} + \frac{\partial g_{jl}}{\partial u^i} - \frac{\partial g_{ij}}{\partial u^l}\right) \] I can think of some substitution using the first and second fundamental forms, but can't see how to really fit it in. Thanks","How can we prove that the christoffel symbol is \[ \Gamma^k_{ij} = \frac 12 \sum_{l=1}^2 g^{kl} \left(\frac{\partial g_{il}}{\partial u^j} + \frac{\partial g_{jl}}{\partial u^i} - \frac{\partial g_{ij}}{\partial u^l}\right) \] I can think of some substitution using the first and second fundamental forms, but can't see how to really fit it in. Thanks",,['differential-geometry']
72,Pullback of differential form on the double covering,Pullback of differential form on the double covering,,"On a double covering there is a differential form $\omega$ arises by the pullback of a differential form under the projection iff it is the pullback of $\omega$ under the map $i$, where $i$ is the map induced from the involution of orientation, $\omega$ itself. Why is this the case? I ask this question because I am really stuck reading this document . The step is on page 148 last paragraph. Thanks in advance.","On a double covering there is a differential form $\omega$ arises by the pullback of a differential form under the projection iff it is the pullback of $\omega$ under the map $i$, where $i$ is the map induced from the involution of orientation, $\omega$ itself. Why is this the case? I ask this question because I am really stuck reading this document . The step is on page 148 last paragraph. Thanks in advance.",,"['differential-geometry', 'differential-topology', 'differential-forms', 'covering-spaces']"
73,How do I compute mean curvature in cylindrical coordinates?,How do I compute mean curvature in cylindrical coordinates?,,"If I have a surface defined by $ z=f(r, \theta) $, does anyone know the expression for the mean curvature? There is a previous post dealing with Gaussian instead of mean curvature, the answer I'm looking for is similar to that given by J.M. on that post. The mentioned post: How do I compute Gaussian curvature in cylindrical coordinates? Many thanks in advance for your help,","If I have a surface defined by $ z=f(r, \theta) $, does anyone know the expression for the mean curvature? There is a previous post dealing with Gaussian instead of mean curvature, the answer I'm looking for is similar to that given by J.M. on that post. The mentioned post: How do I compute Gaussian curvature in cylindrical coordinates? Many thanks in advance for your help,",,"['differential-geometry', 'curvature', 'cylindrical-coordinates']"
74,Real line bundle smoothly isomorphic to Möbius bundle,Real line bundle smoothly isomorphic to Möbius bundle,,"I am reading Lee's Introduction to Smooth Manifolds and got stuck on the problem 5.6. The question is written here, question 1. (There is a typo in the question. The last sentence should be ""Show that F is smoothly isomorphic..."") I do not know how to use the transition function in order to show that these bundles are isomorphic. I tried to find smooth trivializations of F, but I could not. Edit: This is how Lee defined the Möbius bundle in his book. (Lee, page 105, example 5.2)","I am reading Lee's Introduction to Smooth Manifolds and got stuck on the problem 5.6. The question is written here, question 1. (There is a typo in the question. The last sentence should be ""Show that F is smoothly isomorphic..."") I do not know how to use the transition function in order to show that these bundles are isomorphic. I tried to find smooth trivializations of F, but I could not. Edit: This is how Lee defined the Möbius bundle in his book. (Lee, page 105, example 5.2)",,"['differential-geometry', 'vector-bundles']"
75,Computing the restriction of a differential form,Computing the restriction of a differential form,,"Define $\omega$ on $\mathbb{R}^3$ by $\omega = x\,dy\wedge dz + y\,dz\wedge dx + z\,dx\wedge dy$. Thus far I have computed $\omega$ in spherical coordinates $(\rho,\phi,\theta)$, as well as computed $d\omega$ in both Cartesian and spherical coordinates. I found $\omega=\rho^3\sin\phi\,d\phi\wedge d\theta$. But now I'm asked to compute the restriction $\omega|_{S^2} = \iota^*\omega$, where $\iota:S^2\to\mathbb{R}^3$ is the inclusion map, using coordinates $(\phi,\theta)$ on the open subset where they are defined. So far, this is all I have: Fix $p\in S^2$ and consider the basis $\left(\frac{\partial}{\partial\phi},\frac{\partial}{\partial\theta}\right)$ on $T_pS^2$. Then $$(\iota^*\omega)_{(\phi,\theta)}\left(\frac{\partial}{\partial\phi},\frac{\partial}{\partial\theta}\right)=\omega_{\iota(\phi,\theta)}\left(\iota_*\left(\frac{\partial}{\partial\phi}\right),\iota_*\left(\frac{\partial}{\partial\theta}\right)\right)=\sin\phi\,d\phi\wedge d\theta\left(\iota_*\left(\frac{\partial}{\partial\phi}\right),\iota_*\left(\frac{\partial}{\partial\theta}\right)\right)\,.$$ And I suppose I also know that $-\frac{\pi}{2}<\phi<\frac{\pi}{2}$ and $0<\theta<2\pi$. I've done so few examples, though, that it's unclear to me where to go from here. Any help is appreciated","Define $\omega$ on $\mathbb{R}^3$ by $\omega = x\,dy\wedge dz + y\,dz\wedge dx + z\,dx\wedge dy$. Thus far I have computed $\omega$ in spherical coordinates $(\rho,\phi,\theta)$, as well as computed $d\omega$ in both Cartesian and spherical coordinates. I found $\omega=\rho^3\sin\phi\,d\phi\wedge d\theta$. But now I'm asked to compute the restriction $\omega|_{S^2} = \iota^*\omega$, where $\iota:S^2\to\mathbb{R}^3$ is the inclusion map, using coordinates $(\phi,\theta)$ on the open subset where they are defined. So far, this is all I have: Fix $p\in S^2$ and consider the basis $\left(\frac{\partial}{\partial\phi},\frac{\partial}{\partial\theta}\right)$ on $T_pS^2$. Then $$(\iota^*\omega)_{(\phi,\theta)}\left(\frac{\partial}{\partial\phi},\frac{\partial}{\partial\theta}\right)=\omega_{\iota(\phi,\theta)}\left(\iota_*\left(\frac{\partial}{\partial\phi}\right),\iota_*\left(\frac{\partial}{\partial\theta}\right)\right)=\sin\phi\,d\phi\wedge d\theta\left(\iota_*\left(\frac{\partial}{\partial\phi}\right),\iota_*\left(\frac{\partial}{\partial\theta}\right)\right)\,.$$ And I suppose I also know that $-\frac{\pi}{2}<\phi<\frac{\pi}{2}$ and $0<\theta<2\pi$. I've done so few examples, though, that it's unclear to me where to go from here. Any help is appreciated",,"['differential-geometry', 'differential-forms']"
76,Calabi-Yau Manifolds,Calabi-Yau Manifolds,,"In short, I'm hoping for some reading recommendations. I'm starting to do some work with Calabi-Yau manifolds, though my prerequisites are fairly minimal in differential geometry. I've taken a relaxed reading course on differential geometry, hopping around Spivak, and I'm taking a full course this semester. I've also taken a reading course on elliptic curves and a full course in algebraic geometry, building up to Riemann-Roch, in case there are some reads that build from that angle. So, does anyone have any recommendations for good reading material for my situation? Mostly I'm asking because I've been informed I have to read papers and present (relaxed) talks on the material, and I'd like to not fall flat on my face on the very first talk! Thanks! (Also, any recommendations on presenting material you very not familiar with is welcome.)","In short, I'm hoping for some reading recommendations. I'm starting to do some work with Calabi-Yau manifolds, though my prerequisites are fairly minimal in differential geometry. I've taken a relaxed reading course on differential geometry, hopping around Spivak, and I'm taking a full course this semester. I've also taken a reading course on elliptic curves and a full course in algebraic geometry, building up to Riemann-Roch, in case there are some reads that build from that angle. So, does anyone have any recommendations for good reading material for my situation? Mostly I'm asking because I've been informed I have to read papers and present (relaxed) talks on the material, and I'd like to not fall flat on my face on the very first talk! Thanks! (Also, any recommendations on presenting material you very not familiar with is welcome.)",,"['reference-request', 'differential-geometry', 'self-learning', 'complex-geometry']"
77,Defining a Submanifold of $\mathbb{R}^n$,Defining a Submanifold of,\mathbb{R}^n,"A submanifold (of $\mathbb{R}^n$), it appears, can be defined in several equivalent ways. One definition, paraphrased from Amann and Escher's Analysis II , is as follows: A subset $M$ of $\mathbb{R}^n$ is said to be a smooth $m$-dimensional submanifold of $\mathbb{R}^n$ if for every $x \in M$ there exists an open neighborhood $U$ of $x$, an open set $V$ in $\mathbb{R}^n$ and a smooth diffeomorphism $\phi:U \rightarrow V$ such that $\phi(U \cap M) = V \cap (\mathbb{R}^m \times \{0\})$ Everything about this definition makes sense to me except the intersection of $V$ with the Cartesian product of $\mathbb{R}^m$ and $\{0\}$ instead of just $\mathbb{R}^m$. Why not just require $\phi(U \cap M) = V \cap (\mathbb{R}^m)$?","A submanifold (of $\mathbb{R}^n$), it appears, can be defined in several equivalent ways. One definition, paraphrased from Amann and Escher's Analysis II , is as follows: A subset $M$ of $\mathbb{R}^n$ is said to be a smooth $m$-dimensional submanifold of $\mathbb{R}^n$ if for every $x \in M$ there exists an open neighborhood $U$ of $x$, an open set $V$ in $\mathbb{R}^n$ and a smooth diffeomorphism $\phi:U \rightarrow V$ such that $\phi(U \cap M) = V \cap (\mathbb{R}^m \times \{0\})$ Everything about this definition makes sense to me except the intersection of $V$ with the Cartesian product of $\mathbb{R}^m$ and $\{0\}$ instead of just $\mathbb{R}^m$. Why not just require $\phi(U \cap M) = V \cap (\mathbb{R}^m)$?",,"['real-analysis', 'differential-geometry']"
78,Explicit formula for space curves,Explicit formula for space curves,,"I've been looking a bit into differential geometry and have gotten stuck on a question: Given a function $f,$ is there a way to find the explicit space curve which has $f$ as both it's curvature and torsion? I've been able to find a formula for a plane curve with curvature $k(s),$ but extending to what seems to be the next simplest case (curvature = torsion) has been difficult. Any hints on how to proceed?",I've been looking a bit into differential geometry and have gotten stuck on a question: Given a function is there a way to find the explicit space curve which has as both it's curvature and torsion? I've been able to find a formula for a plane curve with curvature but extending to what seems to be the next simplest case (curvature = torsion) has been difficult. Any hints on how to proceed?,"f, f k(s),",['differential-geometry']
79,How does one characterize surfaces with constant nonzero Gaussian and mean curvature,How does one characterize surfaces with constant nonzero Gaussian and mean curvature,,"I know that for any surface, the Gaussian curvature $K$ and mean curvature $H$ satisfy the inequality $H^2 \geq K$ , and the sphere is a surface where that inequality becomes an equation. Thus, the sphere has both constant Gaussian and mean curvature. Are there other surfaces whose Gaussian and mean curvatures are constant and nonzero?","I know that for any surface, the Gaussian curvature $K$ and mean curvature $H$ satisfy the inequality $H^2 \geq K$ , and the sphere is a surface where that inequality becomes an equation. Thus, the sphere has both constant Gaussian and mean curvature. Are there other surfaces whose Gaussian and mean curvatures are constant and nonzero?",,[]
80,Precise statement of Poincaré duality,Precise statement of Poincaré duality,,"Let $(M,g)$ be a (not-necessarily compact) oriented, connected Riemannian manifold. Lets consider the pairing $$\Omega^{k}(M)\times\Omega^{d-k}_{c}(M)\to\mathbb{R}, (\alpha,\beta)\mapsto\int_{M}\alpha\wedge\beta$$ It is well-known that this pairing induces a well-defined pairing on cohomology $$H^{k}(M)\times H^{d-k}_{c}(M)\to\mathbb{R}, ([\alpha],[\beta])\mapsto\int_{M}\alpha\wedge\beta\quad\quad\quad (\ast)$$ Poincaré duality states that this pairing is non-degenerate (in both entries I suppose (?)). Now, my question is, what are the precise assumption for this to hold? In the book Manifolds and Differential Geometry by J. M. Lee, only non-degenaracy in the first entry is proven, i.e. that ( $\ast$ ) viewed as a map $H^{k}(M)\to (H^{d-k}_{c}(M))^{\ast}$ is an isomorphism provided $(M,g)$ admits a finite good cover . On the other hand, in Connections, Curvature, and Cohomology 1 by W. Grueb, it is mentioned that the finite good cover assumption is actually only needed for the other side, i.e. to show that ( $\ast$ ) viewed as a map $H^{d-k}_{c}(M)\to (H^{k}(M))^{\ast}$ is an isomorphism... Does anyone know the precise statement or has some idea where to find it?","Let be a (not-necessarily compact) oriented, connected Riemannian manifold. Lets consider the pairing It is well-known that this pairing induces a well-defined pairing on cohomology Poincaré duality states that this pairing is non-degenerate (in both entries I suppose (?)). Now, my question is, what are the precise assumption for this to hold? In the book Manifolds and Differential Geometry by J. M. Lee, only non-degenaracy in the first entry is proven, i.e. that ( ) viewed as a map is an isomorphism provided admits a finite good cover . On the other hand, in Connections, Curvature, and Cohomology 1 by W. Grueb, it is mentioned that the finite good cover assumption is actually only needed for the other side, i.e. to show that ( ) viewed as a map is an isomorphism... Does anyone know the precise statement or has some idea where to find it?","(M,g) \Omega^{k}(M)\times\Omega^{d-k}_{c}(M)\to\mathbb{R}, (\alpha,\beta)\mapsto\int_{M}\alpha\wedge\beta H^{k}(M)\times H^{d-k}_{c}(M)\to\mathbb{R}, ([\alpha],[\beta])\mapsto\int_{M}\alpha\wedge\beta\quad\quad\quad (\ast) \ast H^{k}(M)\to (H^{d-k}_{c}(M))^{\ast} (M,g) \ast H^{d-k}_{c}(M)\to (H^{k}(M))^{\ast}","['differential-geometry', 'algebraic-topology', 'reference-request', 'riemannian-geometry', 'duality-theorems']"
81,There is a diffeomorphism $f$ of $M$ such that $f(x_i) = y_i$ and $df_{x_i}(v_i) = w_i$,There is a diffeomorphism  of  such that  and,f M f(x_i) = y_i df_{x_i}(v_i) = w_i,"Let $x_1,...,x_k$ and $y_1,...,y_k$ be two sets of distinct points in a connected smooth manifold $M$ with $\dim M>1$ , and $v_1,...,v_k$ and $w_1,...,w_k$ be the corresponding two sets of nonzero tangent vectors at these points. Show that there is a diffeomorphism $f$ of $M$ such that $f(x_i) = y_i$ and $df_{x_i}(v_i)= w_i$ for $i =1,2,...,k$ . I think I can prove for the case $k=1$ . First suppose $x,y$ are close enough so that there is an open coordinate ball chart $(B,\varphi)$ containing $x$ and $y$ . Let $(x^i)$ a coordinate on $B$ and let $v_1 = v^i{\partial\over\partial x^i}\big|_x$ and $w_1 = w^i{\partial\over\partial x^i}\big|_y$ . Define a curve $\gamma:[0,1]\to B$ from $x$ to $y$ such that $\gamma'(0) = (v^1,...,v^n)$ and $\gamma'(1) = (w^1,...,w^n)$ in local coordinate. Then this gives a smooth vector field $X$ along $\gamma$ such that $X_x = v_1$ and $X_y =w_1$ . By the uniqueness of the flow, the corresponding flow of $X$ is $\gamma$ . Since the image of $\gamma$ is closed, we can extend $X$ onto $M$ with compact support (also denoted by $X$ ). Since $X$ has compact support, $X$ admits the global flow $\Phi$ . Then $\Phi_1:M\to M$ is a diffeomorphism such that $\Phi_1(x) =y$ and $\color{red}{d(\Phi_1)_x(v_1) =w_1}$ . The usual connectedness argument proves the statement. I'm not quite confident about my $k=1$ proof (the red part) but it should be like this (I guess). But for $k>1$ , I have no any idea. Please help. The vector field along the curve I have in mind:","Let and be two sets of distinct points in a connected smooth manifold with , and and be the corresponding two sets of nonzero tangent vectors at these points. Show that there is a diffeomorphism of such that and for . I think I can prove for the case . First suppose are close enough so that there is an open coordinate ball chart containing and . Let a coordinate on and let and . Define a curve from to such that and in local coordinate. Then this gives a smooth vector field along such that and . By the uniqueness of the flow, the corresponding flow of is . Since the image of is closed, we can extend onto with compact support (also denoted by ). Since has compact support, admits the global flow . Then is a diffeomorphism such that and . The usual connectedness argument proves the statement. I'm not quite confident about my proof (the red part) but it should be like this (I guess). But for , I have no any idea. Please help. The vector field along the curve I have in mind:","x_1,...,x_k y_1,...,y_k M \dim M>1 v_1,...,v_k w_1,...,w_k f M f(x_i) = y_i df_{x_i}(v_i)= w_i i =1,2,...,k k=1 x,y (B,\varphi) x y (x^i) B v_1 = v^i{\partial\over\partial x^i}\big|_x w_1 = w^i{\partial\over\partial x^i}\big|_y \gamma:[0,1]\to B x y \gamma'(0) = (v^1,...,v^n) \gamma'(1) = (w^1,...,w^n) X \gamma X_x = v_1 X_y =w_1 X \gamma \gamma X M X X X \Phi \Phi_1:M\to M \Phi_1(x) =y \color{red}{d(\Phi_1)_x(v_1) =w_1} k=1 k>1","['differential-geometry', 'smooth-manifolds']"
82,How many smooth vector space structures does $\mathbb R^n$ have?,How many smooth vector space structures does  have?,\mathbb R^n,"The title is a bit misleading. I am really asking about how many ways are there to equip $\mathbb R^n$ with a smooth addition $+:\mathbb R^n \times \mathbb R^n \to \mathbb R^n$ so that the (possibly non-standard) addition-map together with the standard scalar multiplication $\mathbb R \times \mathbb R^n \to \mathbb R^n$ give the smooth manifold $\mathbb R^n$ (with its standard smooth structure) the structure of a smooth vector space? A smooth vector space is like an ordinary vector space, only that all involved maps must be smooth. Background: I was learning a little bit of synthetic differential geometry, and while doing that I seemed to have proven that there is only one such smooth addition map on $\mathbb R^n$ once scalar multiplication is fixed. This seemed a bit extreme, so I thought it is time for a reality check. Here is my argument: There is a well adapted model of SDG which sends the smooth manifold $\mathbb R$ to the line object $R$ of the model and which sends $\mathbb R^n$ to the product $R^n$ . We may also choose a model such that each manifold becomes a microlinear space in it. In particular $R^n$ is microlinear (which is one of the axioms of synthetic differential geometry anyway), and it satisfies the Kock-Lawvere axiom. Such an $R$ -vector space is called Euclidean by Lavendhomme. Lavendhomme shows in their book that a map out of any $R$ -vector space $V$ into an Euclidean vector space is already linear if it is homogeneous. Now assume $+'$ is any addition map on $\mathbb R^n$ such that we get a smooth vector space together with standard scalar multiplication. Then we use the embedding of manifolds into the well adapted model to get an addition map on $R^n$ such that the resulting structure is a vector space internal to the model. Let us denote this vector space by $V$ . Since everything except the addition map is fixed, we have that the identity $V \to R^n$ is homogeneous. Since $R^n$ with its standard addition is an euclidean vector space (in the terminology of Lavendhomme, Basic Concepts of Synthetic Differential Geometry), we see that the identity $V\to R^n$ must be linear. But then we see that the two addition maps must agree, and using that the embedding of manifolds into the model is faithful we see that the abitrary addition $+'$ is in fact the standard one. What do you think? Did I make a mistake? I often do stupid stuff when I calculate alone, so reality check please!","The title is a bit misleading. I am really asking about how many ways are there to equip with a smooth addition so that the (possibly non-standard) addition-map together with the standard scalar multiplication give the smooth manifold (with its standard smooth structure) the structure of a smooth vector space? A smooth vector space is like an ordinary vector space, only that all involved maps must be smooth. Background: I was learning a little bit of synthetic differential geometry, and while doing that I seemed to have proven that there is only one such smooth addition map on once scalar multiplication is fixed. This seemed a bit extreme, so I thought it is time for a reality check. Here is my argument: There is a well adapted model of SDG which sends the smooth manifold to the line object of the model and which sends to the product . We may also choose a model such that each manifold becomes a microlinear space in it. In particular is microlinear (which is one of the axioms of synthetic differential geometry anyway), and it satisfies the Kock-Lawvere axiom. Such an -vector space is called Euclidean by Lavendhomme. Lavendhomme shows in their book that a map out of any -vector space into an Euclidean vector space is already linear if it is homogeneous. Now assume is any addition map on such that we get a smooth vector space together with standard scalar multiplication. Then we use the embedding of manifolds into the well adapted model to get an addition map on such that the resulting structure is a vector space internal to the model. Let us denote this vector space by . Since everything except the addition map is fixed, we have that the identity is homogeneous. Since with its standard addition is an euclidean vector space (in the terminology of Lavendhomme, Basic Concepts of Synthetic Differential Geometry), we see that the identity must be linear. But then we see that the two addition maps must agree, and using that the embedding of manifolds into the model is faithful we see that the abitrary addition is in fact the standard one. What do you think? Did I make a mistake? I often do stupid stuff when I calculate alone, so reality check please!",\mathbb R^n +:\mathbb R^n \times \mathbb R^n \to \mathbb R^n \mathbb R \times \mathbb R^n \to \mathbb R^n \mathbb R^n \mathbb R^n \mathbb R R \mathbb R^n R^n R^n R R V +' \mathbb R^n R^n V V \to R^n R^n V\to R^n +',"['differential-geometry', 'category-theory', 'smooth-manifolds', 'synthetic-differential-geometry']"
83,Existence of a non vanishng vector field on a manifold,Existence of a non vanishng vector field on a manifold,,"I have some doubts on a question related to the existence of a never vanishing smooth vector field on a manifold. First of all I have proved that $M=F^{-1}(1)$ is a regular submanifold of $\mathbb{R}^4$ where $F$ is defined as: \begin{equation} F(x,y,z,t)=x^2+y^2+z^2-t^2. \end{equation} Then I proved that $M$ is diffeomorphic to $S^2\times\mathbb{R}$ using the following map; since for $(x,y,z,t)\in M$ we have $\sqrt{x^2+y^2+z^2}\neq 0$ , for a fixed $t$ I can define: \begin{equation} F_t:S^2(\sqrt{1+t^2})\to S^2(1) \ \ \ F_t(x,y,z)=\bigg(\dfrac{x}{\sqrt{x^2+y^2+z^2}},\dfrac{y}{\sqrt{x^2+y^2+z^2}},\dfrac{z}{\sqrt{x^2+y^2+z^2}}\bigg). \end{equation} Then I simply notice that $F\colon M\to S^2\times\mathbb{R}$ defined as $F(x,y,z,t)=(F_t(x,y,z),t)$ is a diffeomorphism because both $F_t$ and the identity are diffeomorphism. Finally I have the problematic question: does there exist a never vanishing vector field on $M$ ? I know that to answer it, the Hairy ball theorem (telling us that on $n$ -spheres with $n$ even, there is no never vanishing vector field) should be useful; but how can I use this statement?","I have some doubts on a question related to the existence of a never vanishing smooth vector field on a manifold. First of all I have proved that is a regular submanifold of where is defined as: Then I proved that is diffeomorphic to using the following map; since for we have , for a fixed I can define: Then I simply notice that defined as is a diffeomorphism because both and the identity are diffeomorphism. Finally I have the problematic question: does there exist a never vanishing vector field on ? I know that to answer it, the Hairy ball theorem (telling us that on -spheres with even, there is no never vanishing vector field) should be useful; but how can I use this statement?","M=F^{-1}(1) \mathbb{R}^4 F \begin{equation}
F(x,y,z,t)=x^2+y^2+z^2-t^2.
\end{equation} M S^2\times\mathbb{R} (x,y,z,t)\in M \sqrt{x^2+y^2+z^2}\neq 0 t \begin{equation}
F_t:S^2(\sqrt{1+t^2})\to S^2(1) \ \ \ F_t(x,y,z)=\bigg(\dfrac{x}{\sqrt{x^2+y^2+z^2}},\dfrac{y}{\sqrt{x^2+y^2+z^2}},\dfrac{z}{\sqrt{x^2+y^2+z^2}}\bigg).
\end{equation} F\colon M\to S^2\times\mathbb{R} F(x,y,z,t)=(F_t(x,y,z),t) F_t M n n","['differential-geometry', 'manifolds', 'smooth-manifolds', 'vector-fields', 'submanifold']"
84,Is restriction of smooth functions to an open submanifold epimorphic?,Is restriction of smooth functions to an open submanifold epimorphic?,,"I learned recently that restricting smooth functions from a manifold $M$ to a closed submanifold $X$ is a surjective ring homomorphism, which is reminiscent of how (to my understanding) closed subschemes of $\operatorname{Spec} A$ are defined as quotient rings of $A$ , i.e surjections out of $A$ . Also for affine schemes, restricting regular functions from $\operatorname{Spec} A$ to an open subscheme is not a ring surjection but is always a localisation homomorphism, and hence an epimorphism. My question is, does a similar result hold for open submanifolds? That is, does restricting smooth functions from a manifold $M$ to some open $U$ give an epimorphism - either in general or for some class of manifolds? To be honest I'm not sure what the most appropriate category to use would be, e.g I can imagine the restriction being an epimorphism in $\mathbb{R}$ -Alg but not CRing or something. Any insight would be appreciated.","I learned recently that restricting smooth functions from a manifold to a closed submanifold is a surjective ring homomorphism, which is reminiscent of how (to my understanding) closed subschemes of are defined as quotient rings of , i.e surjections out of . Also for affine schemes, restricting regular functions from to an open subscheme is not a ring surjection but is always a localisation homomorphism, and hence an epimorphism. My question is, does a similar result hold for open submanifolds? That is, does restricting smooth functions from a manifold to some open give an epimorphism - either in general or for some class of manifolds? To be honest I'm not sure what the most appropriate category to use would be, e.g I can imagine the restriction being an epimorphism in -Alg but not CRing or something. Any insight would be appreciated.",M X \operatorname{Spec} A A A \operatorname{Spec} A M U \mathbb{R},"['differential-geometry', 'algebraic-geometry', 'manifolds', 'schemes']"
85,The pullback of a foliation,The pullback of a foliation,,"I would like to know how to prove that the pullback of a foliation is actually a well-defined concept. To be precise, if $M$ is an $n$ -dimensional smooth manifold, a $k$ -dimensional foliation $\mathcal F$ of $M$ is a set of nonempty, connected, mutally disjoint, immersed $k$ -dimensional submanifolds of $M$ called the leaves of the foliation, such that their union covers $M$ and for each $p\in M$ there exists a flat chart for $\mathcal F$ , that is, a chart $(U,\varphi)$ of $M$ such that $\varphi(U)$ is a cube in $\mathbb R^n$ and the intersection of $U$ with each element of $\mathcal F$ is either the empty set or a countable union of slices of the form $x^{k+1}=c^{k+1},\dots,x^n=c^n$ . Lets recall that if $\mathcal F$ is a foliation of a smooth manifold $M$ and $f:N\rightarrow M$ is a smooth map transversal to the leaves of the foliation, then there exists a unique foliation on $N$ , the pullback of $\mathcal F$ , denoted by $f^*\mathcal F$ , such that $f$ becomes a foliation-preserving map (it maps leaves of $f^*\mathcal F$ into leaves of $\mathcal F$ ). I have seen how to apply the transversality of $f$ in order to construct a flat chart for $f^*\mathcal F$ , but I don't know how to prove that the connected components of $f^{-1}(L)$ , where $L$ is a leaf of $\mathcal F$ , are actually immersed submanifolds of $N$ . For instance, I don't know hot to prove that such sets are Hausdorff, etc., and I have not seen a proof of this fact anywhere. It may be a technicality, but proving that there are flat charts does not suffice to conclude that the given set is a foliation. Thanks in advance for your answers.","I would like to know how to prove that the pullback of a foliation is actually a well-defined concept. To be precise, if is an -dimensional smooth manifold, a -dimensional foliation of is a set of nonempty, connected, mutally disjoint, immersed -dimensional submanifolds of called the leaves of the foliation, such that their union covers and for each there exists a flat chart for , that is, a chart of such that is a cube in and the intersection of with each element of is either the empty set or a countable union of slices of the form . Lets recall that if is a foliation of a smooth manifold and is a smooth map transversal to the leaves of the foliation, then there exists a unique foliation on , the pullback of , denoted by , such that becomes a foliation-preserving map (it maps leaves of into leaves of ). I have seen how to apply the transversality of in order to construct a flat chart for , but I don't know how to prove that the connected components of , where is a leaf of , are actually immersed submanifolds of . For instance, I don't know hot to prove that such sets are Hausdorff, etc., and I have not seen a proof of this fact anywhere. It may be a technicality, but proving that there are flat charts does not suffice to conclude that the given set is a foliation. Thanks in advance for your answers.","M n k \mathcal F M k M M p\in M \mathcal F (U,\varphi) M \varphi(U) \mathbb R^n U \mathcal F x^{k+1}=c^{k+1},\dots,x^n=c^n \mathcal F M f:N\rightarrow M N \mathcal F f^*\mathcal F f f^*\mathcal F \mathcal F f f^*\mathcal F f^{-1}(L) L \mathcal F N","['differential-geometry', 'manifolds', 'differential-topology', 'smooth-manifolds', 'foliations']"
86,Adjoint of a end-valued complex differential form,Adjoint of a end-valued complex differential form,,"Let $E\to X$ be a holomorphic Hermitian vector bundle over a complex manifold. Let $\xi\in \Omega^1(X,\operatorname{End}(E))$ be an end-valued form. We define its adjoint $\xi^*$ by the identity $$h(\xi v,w)=h(v,\xi^*w)\in \Omega^1(X).$$ for all $v,w\in E$ . (The Hermitian product is linear in $\Omega(X))$ Now we have that the 2-form $\xi\wedge \xi^*$ is anti-self-adjoint. To see that let us consider two simple 1-forms $a=\alpha\otimes f, b=\beta\otimes g\in \Omega^1(X,\operatorname{End}(E))$ , we have \begin{align*} (a\wedge b)^* &= (\alpha\wedge \beta\otimes f\circ g)^*\\               &= \overline{\alpha\wedge \beta}\otimes (f\circ g)^*\\               &= -\bar{\beta}\wedge \bar{\alpha}\otimes g^*\circ f^*\\               &= -b^*\wedge a^*. \end{align*} So in particular $$(\xi\wedge \xi^*)^*=-\xi\wedge \xi^*.$$ So a priori we should have that $$h(\xi\wedge \xi^* v,v)\in i\mathbb{R}$$ should be pure imaginary. The problem is that again a priori we have $$h(\xi\wedge \xi^* v,v)=h(\xi^*v,\xi^*v)=||\xi^*v||^2\in \mathbb{R}.$$ What did I get wrong?","Let be a holomorphic Hermitian vector bundle over a complex manifold. Let be an end-valued form. We define its adjoint by the identity for all . (The Hermitian product is linear in Now we have that the 2-form is anti-self-adjoint. To see that let us consider two simple 1-forms , we have So in particular So a priori we should have that should be pure imaginary. The problem is that again a priori we have What did I get wrong?","E\to X \xi\in \Omega^1(X,\operatorname{End}(E)) \xi^* h(\xi v,w)=h(v,\xi^*w)\in \Omega^1(X). v,w\in E \Omega(X)) \xi\wedge \xi^* a=\alpha\otimes f, b=\beta\otimes g\in \Omega^1(X,\operatorname{End}(E)) \begin{align*}
(a\wedge b)^* &= (\alpha\wedge \beta\otimes f\circ g)^*\\
              &= \overline{\alpha\wedge \beta}\otimes (f\circ g)^*\\
              &= -\bar{\beta}\wedge \bar{\alpha}\otimes g^*\circ f^*\\
              &= -b^*\wedge a^*.
\end{align*} (\xi\wedge \xi^*)^*=-\xi\wedge \xi^*. h(\xi\wedge \xi^* v,v)\in i\mathbb{R} h(\xi\wedge \xi^* v,v)=h(\xi^*v,\xi^*v)=||\xi^*v||^2\in \mathbb{R}.","['differential-geometry', 'complex-geometry', 'vector-bundles', 'complex-manifolds']"
87,Why can we use fundamental vector fields for vertical vector fields to prove the form of the curvature of a connection?,Why can we use fundamental vector fields for vertical vector fields to prove the form of the curvature of a connection?,,"There's a standard proof that roughly goes that, to prove the equivalence for a connection form $\omega$ on a $G$ -principal bundle $P$ ( $u, v \in \Gamma(TP)$ ): \begin{eqnarray} \Omega(u,v) &=& d\omega(\mathrm{Hor}(u), \mathrm{Hor}(v))\\ &=& d\omega(u,v) + \frac{1}{2} \left[ \omega(u), \omega(v) \right] \end{eqnarray} we can simply do it for horizontal and vertical vector fields, as any vector field can be decomposed thusly. This proof is in Kobayashi & Nomizu, it's here , it's here , etc. But for the vertical part, the proof assumes (""without loss of generality"", according to one source) that we can pick a fundamental vector field instead of a more general vertical vector field. The first part of the equality works without that choice, since $\mathrm{Hor}(u)$ is always zero for any vertical field, but for the second part, we are meant to pick $X, Y \in \mathfrak{g}$ and then use as vertical vectors $u = X^*$ , $v = Y^*$ , the fundamental vector fields based on the element $X$ and $Y$ . Part of the proof relies then on the derivative of the connection : \begin{eqnarray} d\omega(X^*,Y^*) &=& X^*(\omega(Y^*)) + Y^*(\omega(X^*)) - \omega([X^*, Y^*])\\ &=& X^*(Y) + Y^*(X) - [X, Y] \end{eqnarray} The term $X^*(Y) + Y^*(X)$ is then supposed to vanish, from what I have seen , due to $X, Y$ being a constant function $P \to \mathfrak{g}$ , and therefore zero when applied to a vector field as a differential operator. I can understand why it would make sense at a point to consider the value of a vertical vector field as the same as that of a fundamental vector field, but if there are derivatives involved, then the Lie algebra element associated to that field may be different at a nearby point, and the derivative may not vanish. From here , the set of fundamental vector fields very much do not cover the entire space of vertical vector fields. So what is the justification that there is no loss of generality in using fundamental vector fields here?","There's a standard proof that roughly goes that, to prove the equivalence for a connection form on a -principal bundle ( ): we can simply do it for horizontal and vertical vector fields, as any vector field can be decomposed thusly. This proof is in Kobayashi & Nomizu, it's here , it's here , etc. But for the vertical part, the proof assumes (""without loss of generality"", according to one source) that we can pick a fundamental vector field instead of a more general vertical vector field. The first part of the equality works without that choice, since is always zero for any vertical field, but for the second part, we are meant to pick and then use as vertical vectors , , the fundamental vector fields based on the element and . Part of the proof relies then on the derivative of the connection : The term is then supposed to vanish, from what I have seen , due to being a constant function , and therefore zero when applied to a vector field as a differential operator. I can understand why it would make sense at a point to consider the value of a vertical vector field as the same as that of a fundamental vector field, but if there are derivatives involved, then the Lie algebra element associated to that field may be different at a nearby point, and the derivative may not vanish. From here , the set of fundamental vector fields very much do not cover the entire space of vertical vector fields. So what is the justification that there is no loss of generality in using fundamental vector fields here?","\omega G P u, v \in \Gamma(TP) \begin{eqnarray}
\Omega(u,v) &=& d\omega(\mathrm{Hor}(u), \mathrm{Hor}(v))\\
&=& d\omega(u,v) + \frac{1}{2} \left[ \omega(u), \omega(v) \right]
\end{eqnarray} \mathrm{Hor}(u) X, Y \in \mathfrak{g} u = X^* v = Y^* X Y \begin{eqnarray}
d\omega(X^*,Y^*) &=& X^*(\omega(Y^*)) + Y^*(\omega(X^*)) - \omega([X^*, Y^*])\\
&=& X^*(Y) + Y^*(X) - [X, Y]
\end{eqnarray} X^*(Y) + Y^*(X) X, Y P \to \mathfrak{g}","['differential-geometry', 'lie-algebras', 'connections']"
88,Pullback of $n$-sphere volume form via Gauss map,Pullback of -sphere volume form via Gauss map,n,"Let $M \subset \mathbb{R}^{n+1}$ be a Riemannian hypersurface, and let $N$ be a smooth unit normal vector field along $M$ . Denote by $\nu : M \to \mathbb{S}^n$ the Gauss map associated to $N$ . Show that $$\nu^*\mathrm{vol}_{\mathbb{S}^n} = (-1)^n K \mathrm{vol}_M, $$ where $K$ is the Gaussian curvature of $M$ , $\mathrm{vol}_{\mathbb{S}^n}$ is the standard volume form of $\mathbb{S}^n$ , and $\mathrm{vol}_M$ is the volume form of $M$ . I am not particularly sure how to prove this statement. I tried proving this locally, in a coordinate chart, but the computations get messy. More precisely, I am not sure how to relate the volume form on $\mathbb{S}^n$ with the Gaussian curvature of $M$ and its volume form.","Let be a Riemannian hypersurface, and let be a smooth unit normal vector field along . Denote by the Gauss map associated to . Show that where is the Gaussian curvature of , is the standard volume form of , and is the volume form of . I am not particularly sure how to prove this statement. I tried proving this locally, in a coordinate chart, but the computations get messy. More precisely, I am not sure how to relate the volume form on with the Gaussian curvature of and its volume form.","M \subset \mathbb{R}^{n+1} N M \nu : M \to \mathbb{S}^n N \nu^*\mathrm{vol}_{\mathbb{S}^n} = (-1)^n K \mathrm{vol}_M,  K M \mathrm{vol}_{\mathbb{S}^n} \mathbb{S}^n \mathrm{vol}_M M \mathbb{S}^n M","['differential-geometry', 'riemannian-geometry', 'curvature']"
89,what actually is a manifold?,what actually is a manifold?,,"I am struggling with the term manifold. It's the first time, I am studying this. I have tried some sites and videos on youtube but I didn't really get the idea. Roughly speaking, Manifold is something that looks flat when we zoom it a lot or that is locally flat. It seems very easy but I am still confused. Why actually do we need to define the manifolds while every shape can be seen as flat except the corners part? Is there any easy way to understand the concept of the manifold? Or in any case, how to check practically if any space is manifold or not. here is a problem that I found somewhere. For $\lambda \in \mathbb R$ Let $M_{\lambda}=\{ (x,y,x)\in\mathbb R^3 : x^2+y^2-z^2=\lambda\}$ . Determine the paremters $\lambda$ for which $M_{\lambda}$ is a sub-manifold of $\mathbb R^3$ . for $\lambda = 0$ , we get something like the cone shape, and I feel like there is a problem at the origin because no matter how much we zoom at the origin, it will not homeomorphic to a flat thing. So Is that true $M_{\lambda}$ is not a manifold for $ \lambda = 0$ ? How to find all such $\lambda$ ? (Is it possibly Only by looking at the shapes in $\mathbb R^3$ or there is some other way. Like some particular mathematical conditions that the set does not satisfy) I am sorry if it seems a very easy question for you guys. Looking forward to hearing from you people. Many Thanks.","I am struggling with the term manifold. It's the first time, I am studying this. I have tried some sites and videos on youtube but I didn't really get the idea. Roughly speaking, Manifold is something that looks flat when we zoom it a lot or that is locally flat. It seems very easy but I am still confused. Why actually do we need to define the manifolds while every shape can be seen as flat except the corners part? Is there any easy way to understand the concept of the manifold? Or in any case, how to check practically if any space is manifold or not. here is a problem that I found somewhere. For Let . Determine the paremters for which is a sub-manifold of . for , we get something like the cone shape, and I feel like there is a problem at the origin because no matter how much we zoom at the origin, it will not homeomorphic to a flat thing. So Is that true is not a manifold for ? How to find all such ? (Is it possibly Only by looking at the shapes in or there is some other way. Like some particular mathematical conditions that the set does not satisfy) I am sorry if it seems a very easy question for you guys. Looking forward to hearing from you people. Many Thanks.","\lambda \in \mathbb R M_{\lambda}=\{ (x,y,x)\in\mathbb R^3 : x^2+y^2-z^2=\lambda\} \lambda M_{\lambda} \mathbb R^3 \lambda = 0 M_{\lambda}  \lambda = 0 \lambda \mathbb R^3","['differential-geometry', 'manifolds', 'submanifold']"
90,Question about the curved Laplace equation and an ambiguity in the metric.,Question about the curved Laplace equation and an ambiguity in the metric.,,"If we have a map from a Riemannian manifold $(M,g)$ let's call it $\phi$ to reals, with $x^i$ the local coordinates on $M$ . The curved Laplace equation (Laplace-Beltrami) looks like $$ g^{ij}\left(\phi_{ij}-\Gamma^k{}_{ij}\phi_{k}\right)=0 $$ Where $\Gamma^k_{ij}$ are Christoffel symbols of $g$ and I denote derivatives by subscripts. Looking at the structure we can notice that adding to $\Gamma^k_{ij}$ a tensor let's say $S^k_{ij}$ which has the property that the vector $g^{ij}S^k{}_{ij}=0$ , this change doesn't affect the equation. This would correspond to adding a metric $h$ to $g$ such that $S$ are Christoffel symbols of $h$ . This would for example mean there are more Riemannian spaces $(M,g)$ for which the Laplace equation looks the same, also there are Riemannian spaces $(M,g)$ for which the Laplace equation looks exactly like a flat one. First of all, I would like to ask if there is some mistake in my reasoning? Secondly, I would like to ask for some references where this is explored, I tried googling but I didn't quite know what to write and that what I tried didn't quite find any papers or something like that. Maybe this could be used to find the simplest metric to a particular solution. Thank you very much.","If we have a map from a Riemannian manifold let's call it to reals, with the local coordinates on . The curved Laplace equation (Laplace-Beltrami) looks like Where are Christoffel symbols of and I denote derivatives by subscripts. Looking at the structure we can notice that adding to a tensor let's say which has the property that the vector , this change doesn't affect the equation. This would correspond to adding a metric to such that are Christoffel symbols of . This would for example mean there are more Riemannian spaces for which the Laplace equation looks the same, also there are Riemannian spaces for which the Laplace equation looks exactly like a flat one. First of all, I would like to ask if there is some mistake in my reasoning? Secondly, I would like to ask for some references where this is explored, I tried googling but I didn't quite know what to write and that what I tried didn't quite find any papers or something like that. Maybe this could be used to find the simplest metric to a particular solution. Thank you very much.","(M,g) \phi x^i M 
g^{ij}\left(\phi_{ij}-\Gamma^k{}_{ij}\phi_{k}\right)=0
 \Gamma^k_{ij} g \Gamma^k_{ij} S^k_{ij} g^{ij}S^k{}_{ij}=0 h g S h (M,g) (M,g)","['differential-geometry', 'riemannian-geometry', 'harmonic-functions']"
91,Nowhere vanishing harmonic 1-forms on 3-manifolds,Nowhere vanishing harmonic 1-forms on 3-manifolds,,"Consider $(S^1 \times \Sigma^2, g)$ , where $g$ is any Riemannian metric on the compact and closed $3$ -manifold $S^1 \times \Sigma^2$ . Question: Does there always exist a nowhere vanishing harmonic $1$ -form on $S^1 \times \Sigma^2$ ? If the answer to this question is No, how about the generalisation to $k$ -parameter families of metrics? So far I tried to find an example of a harmonic $1$ -form on $T^3=S^1 \times S^1 \times S^1$ that does have a zero but did not succeed. I have cross-posted this question to: https://mathoverflow.net/questions/407340/nowhere-vanishing-harmonic-1-forms-on-3-manifolds .","Consider , where is any Riemannian metric on the compact and closed -manifold . Question: Does there always exist a nowhere vanishing harmonic -form on ? If the answer to this question is No, how about the generalisation to -parameter families of metrics? So far I tried to find an example of a harmonic -form on that does have a zero but did not succeed. I have cross-posted this question to: https://mathoverflow.net/questions/407340/nowhere-vanishing-harmonic-1-forms-on-3-manifolds .","(S^1 \times \Sigma^2, g) g 3 S^1 \times \Sigma^2 1 S^1 \times \Sigma^2 k 1 T^3=S^1 \times S^1 \times S^1","['differential-geometry', 'hodge-theory']"
92,Is an irreducible algebraic curve over $\mathbb{C}$ uniquely determined by a local parametrization?,Is an irreducible algebraic curve over  uniquely determined by a local parametrization?,\mathbb{C},"Let $F(X, Y)$ be an irreducible polynomial of $\mathbb{C}[X, Y]$ with $F(0, 0) = 0$ and non-singular there, and let $(X(t), Y(t))$ be a local analytical parametrization of the corresponding curve, that is, $F(X(t), Y(t)) = 0$ for $t$ in a neighborhood of $0$ , with $X(0) = Y(0) = 0$ and $X'(0) \neq 0$ . If, for some polynomial $G(X, Y)$ , we have $G(X(t), Y(t)) = 0$ for $t$ in the neighborhood in question, does then $G(X, Y)$ necessarily belong to the ideal generated by $F(X, Y)$ ? In other words, can the whole curve $F(X, Y) = 0$ be reconstructed from its local snippet? And for an arbitrary algebraically closed field, is there a well-known characterization for a subset of an irreducible algebraic curve to define the curve already ? Is it for instance enough for such a subset to be infinite ?","Let be an irreducible polynomial of with and non-singular there, and let be a local analytical parametrization of the corresponding curve, that is, for in a neighborhood of , with and . If, for some polynomial , we have for in the neighborhood in question, does then necessarily belong to the ideal generated by ? In other words, can the whole curve be reconstructed from its local snippet? And for an arbitrary algebraically closed field, is there a well-known characterization for a subset of an irreducible algebraic curve to define the curve already ? Is it for instance enough for such a subset to be infinite ?","F(X, Y) \mathbb{C}[X, Y] F(0, 0) = 0 (X(t), Y(t)) F(X(t), Y(t)) = 0 t 0 X(0) = Y(0) = 0 X'(0) \neq 0 G(X, Y) G(X(t), Y(t)) = 0 t G(X, Y) F(X, Y) F(X, Y) = 0","['differential-geometry', 'algebraic-geometry', 'algebraic-curves', 'parametrization', 'analytic-continuation']"
93,Is every differential 1-form a linear combination of closed forms?,Is every differential 1-form a linear combination of closed forms?,,"Let $M$ be a smooth manifold. We know that the $C^\infty (M)$ -module $\Omega^1 (M)$ is finitely generated, i.e. there exists $1$ -forms $\{\alpha_1, \ldots, \alpha_k \}$ such that for any $1$ -form $\omega$ , we can write $\omega = \sum_{i=1}^k f_i \alpha_i$ for some $f_i \in C^\infty (M)$ . I'm wondering if the $\alpha_i$ can be chosen to be closed, or, furthermore, exact. I'm guessing there must exist a counterexample, as I haven't seen this result in any of the standard textbooks or online sets of notes, and it might make computations a little too easy. I've been toying around with this idea for a while but haven't gotten any leads in either direction, except that this is trivially true in $\mathbb{R}^n$ . Have any of you seen this result or know a counterexample?","Let be a smooth manifold. We know that the -module is finitely generated, i.e. there exists -forms such that for any -form , we can write for some . I'm wondering if the can be chosen to be closed, or, furthermore, exact. I'm guessing there must exist a counterexample, as I haven't seen this result in any of the standard textbooks or online sets of notes, and it might make computations a little too easy. I've been toying around with this idea for a while but haven't gotten any leads in either direction, except that this is trivially true in . Have any of you seen this result or know a counterexample?","M C^\infty (M) \Omega^1 (M) 1 \{\alpha_1, \ldots, \alpha_k \} 1 \omega \omega = \sum_{i=1}^k f_i \alpha_i f_i \in C^\infty (M) \alpha_i \mathbb{R}^n","['differential-geometry', 'differential-forms']"
94,If a manifold admits a real analytic structure then the manifold is analytic?,If a manifold admits a real analytic structure then the manifold is analytic?,,I have been reading the notion of real analytic space in nLab and found a statement that puzzles me. That Whitney embedding theorem shows that every paracompact smooth manifold admits a real analytic structure. Whitney embedding theorem shows that a differentiable manifold $M$ can be embedded in $\mathbb{R}^n$ for a $n$ sufficient large. We know that $\mathbb{R}^n$ is an analytic manifold but it is not clear for me from this that $M$ admits an analytic structure. Does it mean that $M$ is an analytic manifold? If the answer to this question is true then there is a contradiction since there are smooth functions $f:\mathbb{R} \to \mathbb{R}$ whose graphs are embedded in $\mathbb{R}^2$ that are not analytic e.g. the bump function.,I have been reading the notion of real analytic space in nLab and found a statement that puzzles me. That Whitney embedding theorem shows that every paracompact smooth manifold admits a real analytic structure. Whitney embedding theorem shows that a differentiable manifold can be embedded in for a sufficient large. We know that is an analytic manifold but it is not clear for me from this that admits an analytic structure. Does it mean that is an analytic manifold? If the answer to this question is true then there is a contradiction since there are smooth functions whose graphs are embedded in that are not analytic e.g. the bump function.,M \mathbb{R}^n n \mathbb{R}^n M M f:\mathbb{R} \to \mathbb{R} \mathbb{R}^2,['differential-geometry']
95,Homeomorphic to a vector space but not itself a vector space,Homeomorphic to a vector space but not itself a vector space,,"In Nash & Sen p.162, they show that the space of all positive definite symmetric matrices $C$ , while not a vector space itself, is homeomorphic to the space of all symmetric matrices $S$ (which is a vector space), via the map $$ s \rightarrow e^s \in C, s \in  S $$ My question: can I not make $C$ into a vector space by defining addition of two elements as first adding the elements in $S$ and then exponentiating, i.e. $ e^a + e^b \equiv e^{a + b}$ ? Note this is not the usual multiplication of matrices. It seems to me that we then have an inverse ( $e^{-a}$ ) and an identity element ( $e^0$ ), that we inherit commutativity etc. from $S$ , and we can define scalar multiplication in the usual way. More generally, why is something homeomorphic to a vector space not itself a vector space? Can someone tell me where I'm going wrong?","In Nash & Sen p.162, they show that the space of all positive definite symmetric matrices , while not a vector space itself, is homeomorphic to the space of all symmetric matrices (which is a vector space), via the map My question: can I not make into a vector space by defining addition of two elements as first adding the elements in and then exponentiating, i.e. ? Note this is not the usual multiplication of matrices. It seems to me that we then have an inverse ( ) and an identity element ( ), that we inherit commutativity etc. from , and we can define scalar multiplication in the usual way. More generally, why is something homeomorphic to a vector space not itself a vector space? Can someone tell me where I'm going wrong?","C S  s \rightarrow e^s \in C, s \in  S  C S  e^a + e^b \equiv e^{a + b} e^{-a} e^0 S","['differential-geometry', 'vector-spaces']"
96,What really is $dr$ in differential forms?,What really is  in differential forms?,dr,"I am reading Arnold's Mathematical Methods of Classical Mechanics , and have arrived at differential forms. At this point in the chapter, there has been no discussion of the exterior derivative. There is discussion of the differential, however. One of the problems defines a differential form $$\omega=r\;dr\wedge d\varphi$$ where $x_1=r\cos\varphi$ and $x_2=r\sin\varphi$ ; $x_1$ and $x_2$ are the standard coordinates in $\mathbb{R}^2$ . So I can take differentials \begin{align*} dx_1\wedge dx_2 &=d(r\cos\varphi)\wedge d(r\sin\varphi)\\ &=(\cos\varphi\;dr-r\sin\varphi\;d\varphi)\wedge(\sin\varphi\;dr+r\cos\varphi\;d\varphi)\\ &=r\;dr\wedge d\varphi. \end{align*} But looking back, I realize that I don't really understand what I did at all. First of all, when we say $x_1=r\cos\varphi$ , for example, it seems like the $x_1$ we are talking about is the one that gives the coordinates on $\mathbb{R}^2$ , which is our manifold. On the other hand, $dx_1\wedge dx_2$ is a k-form on the tangent space at a particular point of $\mathbb{R}^2$ . So this substitution really doesn't even make sense to me at all; it feels like a type error. It seems perfectly plausible to me that our manifold can have polar coordinates while each tangent space has Cartesian coordinates. Second, what even is $dr$ ? The only interpretation I have is that it is the differential of the function $r$ . Intuitively it seems like it should be the function that, if the tangent space is parameterized using polar coordinates, retrieves the coordinate $r$ . So if I were to evaluate the differential form $dr$ at the point $(0,1)$ (in $\mathbb{R}^2$ ) on the vector $(1,1)$ in the tangent space, would the result be $\sqrt{2}$ ? I really seem to have confused a bunch of stuff here, so any help would be appreciated.","I am reading Arnold's Mathematical Methods of Classical Mechanics , and have arrived at differential forms. At this point in the chapter, there has been no discussion of the exterior derivative. There is discussion of the differential, however. One of the problems defines a differential form where and ; and are the standard coordinates in . So I can take differentials But looking back, I realize that I don't really understand what I did at all. First of all, when we say , for example, it seems like the we are talking about is the one that gives the coordinates on , which is our manifold. On the other hand, is a k-form on the tangent space at a particular point of . So this substitution really doesn't even make sense to me at all; it feels like a type error. It seems perfectly plausible to me that our manifold can have polar coordinates while each tangent space has Cartesian coordinates. Second, what even is ? The only interpretation I have is that it is the differential of the function . Intuitively it seems like it should be the function that, if the tangent space is parameterized using polar coordinates, retrieves the coordinate . So if I were to evaluate the differential form at the point (in ) on the vector in the tangent space, would the result be ? I really seem to have confused a bunch of stuff here, so any help would be appreciated.","\omega=r\;dr\wedge d\varphi x_1=r\cos\varphi x_2=r\sin\varphi x_1 x_2 \mathbb{R}^2 \begin{align*}
dx_1\wedge dx_2
&=d(r\cos\varphi)\wedge d(r\sin\varphi)\\
&=(\cos\varphi\;dr-r\sin\varphi\;d\varphi)\wedge(\sin\varphi\;dr+r\cos\varphi\;d\varphi)\\
&=r\;dr\wedge d\varphi.
\end{align*} x_1=r\cos\varphi x_1 \mathbb{R}^2 dx_1\wedge dx_2 \mathbb{R}^2 dr r r dr (0,1) \mathbb{R}^2 (1,1) \sqrt{2}","['differential-geometry', 'manifolds', 'differential-forms']"
97,Confusion about covariant derivatives,Confusion about covariant derivatives,,"I have the following confusion about covariant derivatives. Let $(M,g)$ be a Riemannian manifold with Levi-Civita connection $\nabla$ and let $f$ be a scalar function on $M$ . The Hessian of $f$ , denoted by $\nabla^2f$ , is by definition a rank 2 tensor. However, I'm wondering whether $\nabla_{X}\nabla_{Y}f$ is the same as $\nabla^2f(X,Y)$ for vector fields $X,Y$ on $M$ . If not, then what would be the interpretation of $\nabla_{X}\nabla_{Y}f$ ? Obviously, we are not evaluating $\nabla_{Y}f$ and $\nabla_{X}(\nabla_{Y}f)$ sequentially, since otherwise we would get the usual partial derivatives.","I have the following confusion about covariant derivatives. Let be a Riemannian manifold with Levi-Civita connection and let be a scalar function on . The Hessian of , denoted by , is by definition a rank 2 tensor. However, I'm wondering whether is the same as for vector fields on . If not, then what would be the interpretation of ? Obviously, we are not evaluating and sequentially, since otherwise we would get the usual partial derivatives.","(M,g) \nabla f M f \nabla^2f \nabla_{X}\nabla_{Y}f \nabla^2f(X,Y) X,Y M \nabla_{X}\nabla_{Y}f \nabla_{Y}f \nabla_{X}(\nabla_{Y}f)","['differential-geometry', 'riemannian-geometry']"
98,Relationship of a Simplex to a Symplectic Manifold,Relationship of a Simplex to a Symplectic Manifold,,"I have another short question regarding terminology. The phonetic similarity of simplex and symplectic manifold has little or nothing to do with any mathematical relationship, correct? I always considered a symplectic manifold to be a smooth manifold with an associated two form and a simplex to be a generalized tetrahedron. In conversation, someone asked me if any relationship existed between them, and I responded that there was none of which I was aware. I wanted to see if anyone could offer a potential connection or validate the absence of one. Thank you all.","I have another short question regarding terminology. The phonetic similarity of simplex and symplectic manifold has little or nothing to do with any mathematical relationship, correct? I always considered a symplectic manifold to be a smooth manifold with an associated two form and a simplex to be a generalized tetrahedron. In conversation, someone asked me if any relationship existed between them, and I responded that there was none of which I was aware. I wanted to see if anyone could offer a potential connection or validate the absence of one. Thank you all.",,"['differential-geometry', 'symplectic-geometry', 'simplex']"
99,Adjoint map $\text{Ad}:G\rightarrow \text{Aut}(\mathfrak{g})$ is smooth.,Adjoint map  is smooth.,\text{Ad}:G\rightarrow \text{Aut}(\mathfrak{g}),"Let $G$ be a lie group and let $\mathfrak{g}$ its lie algebra. Its not clear to me that $\text{Ad}:G\rightarrow \text{Aut}(\mathfrak{g})$ is smooth. It is clear to me that if we have a matrix group any $g\in G$ gives that $\text{Ad}(g)$ is smooth. Because $Ad(g)Y=gYg^{-1}$ consists of rational polynomials in each entry. However this does not tell us that $Ad$ is smooth,  only that it sends each $g$ to a smooth. How can we see that $Ad:G\rightarrow \text{Aut}(\mathfrak{g})$ is smooth? One approach might be to use that it is a group homomorphism between lie groups and then we need only show that it is continuous. I do not think this question is a duplicate of ( Adjoint action smooth (in Tapp's book)? ) because it seems to me that this question on explains why each $\text{Ad}(g)$ is smooth, not $\text{Ad}$","Let be a lie group and let its lie algebra. Its not clear to me that is smooth. It is clear to me that if we have a matrix group any gives that is smooth. Because consists of rational polynomials in each entry. However this does not tell us that is smooth,  only that it sends each to a smooth. How can we see that is smooth? One approach might be to use that it is a group homomorphism between lie groups and then we need only show that it is continuous. I do not think this question is a duplicate of ( Adjoint action smooth (in Tapp's book)? ) because it seems to me that this question on explains why each is smooth, not",G \mathfrak{g} \text{Ad}:G\rightarrow \text{Aut}(\mathfrak{g}) g\in G \text{Ad}(g) Ad(g)Y=gYg^{-1} Ad g Ad:G\rightarrow \text{Aut}(\mathfrak{g}) \text{Ad}(g) \text{Ad},"['differential-geometry', 'lie-groups', 'lie-algebras', 'smooth-manifolds']"
