,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Is the product of two monotone sequences monotone?,Is the product of two monotone sequences monotone?,,"Question: The product of monotone sequences is monotone, T or F? Uncompleted Solution: There are four cases from considering each of two monotone sequences, increasing or decreasing. CASE I: Suppose we have two monotonically decreasing sequences, say ${\{a_n}\}$ and ${\{b_n}\}$. Then, $a_{n+1}\leq a_n$ and $b_{n+1}\leq b_n$; if $b_n\geq 0$ and $b_{n+1}\geq 0$ then $a_{n+1}b_{n+1}\leq a_{n}b_{n+1}\leq a_{n}b_{n}$, but the l-h-s inequality, i.e., $a_{n}b_{n+1}\leq a_{n}b_{n}$, implies that must $a_{n}\geq 0$ since $b_{n+1}\leq b_n$ already has been supposed, but $a_{n}\geq 0$ has not been supposed. So does it mean that two monotonically decreasing sequences with requisites of $a_{n}\leq 0$ since $b_{n+1}\leq b_n$; is counterexample for ""the product of monotone sequences is monotone""? Under which circumstances the product of monotone sequences is monotone, even if it may not true for all cases? And, is there any short (general) proof without need to evaluate each single of sub-cases of the 4-cases? Thank you.","Question: The product of monotone sequences is monotone, T or F? Uncompleted Solution: There are four cases from considering each of two monotone sequences, increasing or decreasing. CASE I: Suppose we have two monotonically decreasing sequences, say ${\{a_n}\}$ and ${\{b_n}\}$. Then, $a_{n+1}\leq a_n$ and $b_{n+1}\leq b_n$; if $b_n\geq 0$ and $b_{n+1}\geq 0$ then $a_{n+1}b_{n+1}\leq a_{n}b_{n+1}\leq a_{n}b_{n}$, but the l-h-s inequality, i.e., $a_{n}b_{n+1}\leq a_{n}b_{n}$, implies that must $a_{n}\geq 0$ since $b_{n+1}\leq b_n$ already has been supposed, but $a_{n}\geq 0$ has not been supposed. So does it mean that two monotonically decreasing sequences with requisites of $a_{n}\leq 0$ since $b_{n+1}\leq b_n$; is counterexample for ""the product of monotone sequences is monotone""? Under which circumstances the product of monotone sequences is monotone, even if it may not true for all cases? And, is there any short (general) proof without need to evaluate each single of sub-cases of the 4-cases? Thank you.",,['real-analysis']
1,If $f^2$ is Riemann Integrable is $f$ always Riemann Integrable?,If  is Riemann Integrable is  always Riemann Integrable?,f^2 f,"Problem: Suppose that $f$ is a bounded, real-valued function on $[a,b]$ such that $f^2\in R$ (i.e. it is Riemann-Integrable). Must it be the case that $f\in R$ ? Thoughts: I think that this is not necessarily true, but I am having trouble refuting or even proving the above. Of course, the simplest way to prove that it is not necessarily true would be to give an example, but I am unable to think of one! I also have tried using $\phi(y)=\sqrt y$ and composing this with $f^2$ (to try show $f$ is continuous); however, the interval $[a,b]$ may contain negative numbers so I can't utilise $\phi$ in that case. Question: Does there exist a function $f$ such that $f^2\in R$ but $f$ $\not\in R$ ? Or conversely, if $f^2\in R$ does this always imply $f$ $\in R$ ? (If so, could you provide a way of proving this).","Problem: Suppose that $f$ is a bounded, real-valued function on $[a,b]$ such that $f^2\in R$ (i.e. it is Riemann-Integrable). Must it be the case that $f\in R$ ? Thoughts: I think that this is not necessarily true, but I am having trouble refuting or even proving the above. Of course, the simplest way to prove that it is not necessarily true would be to give an example, but I am unable to think of one! I also have tried using $\phi(y)=\sqrt y$ and composing this with $f^2$ (to try show $f$ is continuous); however, the interval $[a,b]$ may contain negative numbers so I can't utilise $\phi$ in that case. Question: Does there exist a function $f$ such that $f^2\in R$ but $f$ $\not\in R$ ? Or conversely, if $f^2\in R$ does this always imply $f$ $\in R$ ? (If so, could you provide a way of proving this).",,['real-analysis']
2,Countable subset of a uncountable set,Countable subset of a uncountable set,,"Is it true that for any uncountable subset T of $\mathbb R$, one can find a subset S of T such that S is countable. If yes, how can we prove it? Thanks! Edit: Is there a countable subset S of T such that for every element $t\in T$, there exists $s\in S$ such that $s\geq t$?","Is it true that for any uncountable subset T of $\mathbb R$, one can find a subset S of T such that S is countable. If yes, how can we prove it? Thanks! Edit: Is there a countable subset S of T such that for every element $t\in T$, there exists $s\in S$ such that $s\geq t$?",,"['real-analysis', 'elementary-set-theory']"
3,Dedekind Cut Proof,Dedekind Cut Proof,,"I am greatly confused with Dedekind cuts... I am trying to prove that this is a Dedekind cut: If $D$ and $E$ are in $\mathbb{Q}$ and are Dedekind cuts, then prove that    $$D*E=(-\infty, 0] \cup \{r_1r_2\mid  0 < r_1 \in D, 0 < r_2 \in E\}$$    is a Dedekind cut as well. My three propositions of a Dedekind cut are: 1.) If $r\in D$  and $s < r$, then $s \in D$. 2.) There is a number $x \in \mathbb{Q}$ so that $r\leq x$ for all $r \in D$. 3.) If $r \in D$, then there is a number $s \in D$ so that $r < s$. After looking at many sources, my concept of a Dedekind cut is falling short... and so this proof is. I would be greatly appreciative for a simple definition and example of a Dedekind cut, and/ or help on this proof. Thx!","I am greatly confused with Dedekind cuts... I am trying to prove that this is a Dedekind cut: If $D$ and $E$ are in $\mathbb{Q}$ and are Dedekind cuts, then prove that    $$D*E=(-\infty, 0] \cup \{r_1r_2\mid  0 < r_1 \in D, 0 < r_2 \in E\}$$    is a Dedekind cut as well. My three propositions of a Dedekind cut are: 1.) If $r\in D$  and $s < r$, then $s \in D$. 2.) There is a number $x \in \mathbb{Q}$ so that $r\leq x$ for all $r \in D$. 3.) If $r \in D$, then there is a number $s \in D$ so that $r < s$. After looking at many sources, my concept of a Dedekind cut is falling short... and so this proof is. I would be greatly appreciative for a simple definition and example of a Dedekind cut, and/ or help on this proof. Thx!",,"['real-analysis', 'rational-numbers']"
4,Convergence of $\left( \frac{1}{1} \right)^2+\left( \frac{1}{2}+\frac{1}{3} \right)^2+\cdots$,Convergence of,\left( \frac{1}{1} \right)^2+\left( \frac{1}{2}+\frac{1}{3} \right)^2+\cdots,"Does the following series converge? If yes, what is its value in simplest form? $$\left( \frac{1}{1} \right)^2+\left( \frac{1}{2}+\frac{1}{3} \right)^2+\left( \frac{1}{4}+\frac{1}{5}+\frac{1}{6} \right)^2+\left( \frac{1}{7}+\frac{1}{8}+\frac{1}{9}+\frac{1}{10} \right)^2+\,\dots$$ I have no idea how to start. Any hint would be really appreciated. THANKS!","Does the following series converge? If yes, what is its value in simplest form? I have no idea how to start. Any hint would be really appreciated. THANKS!","\left( \frac{1}{1} \right)^2+\left( \frac{1}{2}+\frac{1}{3} \right)^2+\left( \frac{1}{4}+\frac{1}{5}+\frac{1}{6} \right)^2+\left( \frac{1}{7}+\frac{1}{8}+\frac{1}{9}+\frac{1}{10} \right)^2+\,\dots","['real-analysis', 'calculus', 'sequences-and-series', 'limits', 'convergence-divergence']"
5,Show that $f'(x) = \lim\limits_{h \rightarrow 0} \dfrac{f(x+h)-f(x-h)}{2h}$,Show that,f'(x) = \lim\limits_{h \rightarrow 0} \dfrac{f(x+h)-f(x-h)}{2h},"I have to prove that if a function $f$ is differentiable on $(a,b)$, then \begin{align*} f'(x) = \lim\limits_{h \rightarrow 0} \dfrac{f(x+h)-f(x-h)}{2h} \end{align*} Using the fact that $f'(x) = \lim\limits_{h \rightarrow 0}\dfrac{f(x+h)-f(x)}{h}$, I wrote my proof in the following manner: \begin{align*} \lim\limits_{h \rightarrow 0}f(x+h) - 2f(x) = \lim\limits_{h \rightarrow 0} - f(x-h) \\ \lim\limits_{h \rightarrow 0} \dfrac{f(x+h)}{2h} - \dfrac{f(x)}{h} = \lim\limits_{h \rightarrow 0}\dfrac{-f(x-h)}{2h} \\ \lim\limits_{h \rightarrow 0}\dfrac{f(x+h)}{h} - \dfrac{f(x)}{h} = \lim\limits_{h \rightarrow 0} \dfrac{f(x+h)}{2h} - \dfrac{f(x-h)}{2h} \\ \lim\limits_{h \rightarrow 0} \dfrac{f(x+h) - f(x)}{h} = \lim\limits_{h \rightarrow 0} \dfrac{f(x+h)-f(x-h)}{2h} \end{align*} However, I believe that it is actually incorrect, because when I divide by $2h$ I am potentially making the limit undefined. How would I go about correcting my proof?","I have to prove that if a function $f$ is differentiable on $(a,b)$, then \begin{align*} f'(x) = \lim\limits_{h \rightarrow 0} \dfrac{f(x+h)-f(x-h)}{2h} \end{align*} Using the fact that $f'(x) = \lim\limits_{h \rightarrow 0}\dfrac{f(x+h)-f(x)}{h}$, I wrote my proof in the following manner: \begin{align*} \lim\limits_{h \rightarrow 0}f(x+h) - 2f(x) = \lim\limits_{h \rightarrow 0} - f(x-h) \\ \lim\limits_{h \rightarrow 0} \dfrac{f(x+h)}{2h} - \dfrac{f(x)}{h} = \lim\limits_{h \rightarrow 0}\dfrac{-f(x-h)}{2h} \\ \lim\limits_{h \rightarrow 0}\dfrac{f(x+h)}{h} - \dfrac{f(x)}{h} = \lim\limits_{h \rightarrow 0} \dfrac{f(x+h)}{2h} - \dfrac{f(x-h)}{2h} \\ \lim\limits_{h \rightarrow 0} \dfrac{f(x+h) - f(x)}{h} = \lim\limits_{h \rightarrow 0} \dfrac{f(x+h)-f(x-h)}{2h} \end{align*} However, I believe that it is actually incorrect, because when I divide by $2h$ I am potentially making the limit undefined. How would I go about correcting my proof?",,"['calculus', 'real-analysis', 'limits', 'derivatives']"
6,Proof that if $a_1=1$ and $a_{n+1}=1+\frac{1}{1+a_n}$,Proof that if  and,a_1=1 a_{n+1}=1+\frac{1}{1+a_n},"Question: Prove that if $$a_n=\left\{   \begin{array}{ll}     a_1=1\\     a_{n+1}=1+\frac{1}{1+a_n}   \end{array} \right.$$ then $a_n$ converges, and then find $\lim_{n \to \infty}a_n$ . I found that $\lim_{n \to \infty}a_n=\sqrt{2}$ , and that $1\leq a_n<2$ , but the convergence seems difficult. My idea is to show that $a_{2n}$ is decreasing, and $a_{2n-1}$ is increasing,  but I don’t see how. I’d be thankful for any hint.","Question: Prove that if then converges, and then find . I found that , and that , but the convergence seems difficult. My idea is to show that is decreasing, and is increasing,  but I don’t see how. I’d be thankful for any hint.","a_n=\left\{
  \begin{array}{ll}
    a_1=1\\
    a_{n+1}=1+\frac{1}{1+a_n}
  \end{array}
\right. a_n \lim_{n \to \infty}a_n \lim_{n \to \infty}a_n=\sqrt{2} 1\leq a_n<2 a_{2n} a_{2n-1}","['real-analysis', 'sequences-and-series', 'recurrence-relations']"
7,Uniqueness of hyperreals contructed via ultrapowers,Uniqueness of hyperreals contructed via ultrapowers,,"The construction I've seen of the field of hyperreal numbers considers a non-principal ultrafilter $\mathcal{U}$ on $\mathbb{N}$, then takes the quotient of $\mathbb{R}^{\mathbb{N}}$ by equivalence respect to $\mathcal{U}$, that is, $(a_{n})=(b_{n})$ if the set $S$ of indices $n$ for which $a_{n}=b_{n}$ is inside $\mathcal{U}$. Is it clear (or even true) that one obtains an isomorphic field with a different choice of ultrafilter?","The construction I've seen of the field of hyperreal numbers considers a non-principal ultrafilter $\mathcal{U}$ on $\mathbb{N}$, then takes the quotient of $\mathbb{R}^{\mathbb{N}}$ by equivalence respect to $\mathcal{U}$, that is, $(a_{n})=(b_{n})$ if the set $S$ of indices $n$ for which $a_{n}=b_{n}$ is inside $\mathcal{U}$. Is it clear (or even true) that one obtains an isomorphic field with a different choice of ultrafilter?",,"['real-analysis', 'model-theory', 'filters', 'nonstandard-analysis']"
8,"Function whose image of every open interval is $(-\infty,\infty)$ [duplicate]",Function whose image of every open interval is  [duplicate],"(-\infty,\infty)",This question already has answers here : Is there a function $f\colon\mathbb{R}\to\mathbb{R}$ such that every non-empty open interval is mapped onto $\mathbb{R}$? (5 answers) Closed 7 years ago . How to find a function from reals to reals such that the image of every open interval is the whole of R? Is there one which maps rationals to rationals?,This question already has answers here : Is there a function $f\colon\mathbb{R}\to\mathbb{R}$ such that every non-empty open interval is mapped onto $\mathbb{R}$? (5 answers) Closed 7 years ago . How to find a function from reals to reals such that the image of every open interval is the whole of R? Is there one which maps rationals to rationals?,,"['real-analysis', 'examples-counterexamples']"
9,What is value of this integral? $\int_{0}^{\infty}\frac{\log(1+4x^2)(1+9x^2)(9+x^2)+(9+x^2)\log(4+x^2)(10+10x^2)}{(9+x^2)^{2}(1+9x^{2})}dx$,What is value of this integral?,\int_{0}^{\infty}\frac{\log(1+4x^2)(1+9x^2)(9+x^2)+(9+x^2)\log(4+x^2)(10+10x^2)}{(9+x^2)^{2}(1+9x^{2})}dx,What is value of this integral $$I=\int_{0}^{\infty}\frac{\log(1+4x^2)(1+9x^2)(9+x^2)+(9+x^2)\log(4+x^2)(10+10x^2)}{(9+x^2)^{2}(1+9x^2)}dx$$ My work : \begin{align*}I&=\int_{0}^{\infty}\frac{\log(1+4x^2)}{9+x^2}dx+\int_{0}^{\infty}\frac{\log(4+x^2)(10+10x^2)}{(9+x^2)(1+9x^2)}dx\\ &=\int_{0}^{\infty}\frac{\log(1+4x^2)}{9+x^2}dx+\int_{0}^{\infty}\frac{\log(4+x^2)}{1+9x^2}dx+\int_{0}^{\infty}\frac{\log(4+x^2)}{9+x^2}dx\\ &=j_{1}+j_{2}+j_{3}\\ \end{align*} $$j_{1}=\int_{0}^{\infty}\frac{\log(1+4x^2)}{9+x^2}dx=\sum_{n=0}^{\infty}\frac{(-1)^n(2^{2(n+1)})}{n+1}\int_{0}^{\infty}\frac{x^{2(n+1)}}{9+x^2}dx$$ $$j_{2}=\log(4)\int_{0}^{\infty}\frac{1}{1+(3x)^2}dx+\sum_{n=0}^{\infty}\frac{(-1)^{n}}{(n+1)(2^{2(n+1)})}\int_{0}^{\infty}\frac{x^{2(n+1)}}{1+9x^2}dx=\frac{\log(4)\pi}{6}+\sum_{n=0}^{\infty}\frac{(-1)^n}{(n+1)2^{2(n+1)}}\int_{0}^{\infty}\frac{x^{2(n+1)}}{1+9x^2}dx$$ $$j_{3}=\int_{0}^{\infty}\frac{\log(4+x^2)}{9+x^2}dx=\frac{\log(4)\pi}{54}+\sum_{n=0}^{\infty}\frac{(-1)^n}{(n+1)2^{2(n+1)}}\int_{0}^{\infty}\frac{x^{2(n+1)}}{9+x^2}dx$$ Wait for a review to find solutions to this,What is value of this integral My work : Wait for a review to find solutions to this,"I=\int_{0}^{\infty}\frac{\log(1+4x^2)(1+9x^2)(9+x^2)+(9+x^2)\log(4+x^2)(10+10x^2)}{(9+x^2)^{2}(1+9x^2)}dx \begin{align*}I&=\int_{0}^{\infty}\frac{\log(1+4x^2)}{9+x^2}dx+\int_{0}^{\infty}\frac{\log(4+x^2)(10+10x^2)}{(9+x^2)(1+9x^2)}dx\\
&=\int_{0}^{\infty}\frac{\log(1+4x^2)}{9+x^2}dx+\int_{0}^{\infty}\frac{\log(4+x^2)}{1+9x^2}dx+\int_{0}^{\infty}\frac{\log(4+x^2)}{9+x^2}dx\\
&=j_{1}+j_{2}+j_{3}\\
\end{align*} j_{1}=\int_{0}^{\infty}\frac{\log(1+4x^2)}{9+x^2}dx=\sum_{n=0}^{\infty}\frac{(-1)^n(2^{2(n+1)})}{n+1}\int_{0}^{\infty}\frac{x^{2(n+1)}}{9+x^2}dx j_{2}=\log(4)\int_{0}^{\infty}\frac{1}{1+(3x)^2}dx+\sum_{n=0}^{\infty}\frac{(-1)^{n}}{(n+1)(2^{2(n+1)})}\int_{0}^{\infty}\frac{x^{2(n+1)}}{1+9x^2}dx=\frac{\log(4)\pi}{6}+\sum_{n=0}^{\infty}\frac{(-1)^n}{(n+1)2^{2(n+1)}}\int_{0}^{\infty}\frac{x^{2(n+1)}}{1+9x^2}dx j_{3}=\int_{0}^{\infty}\frac{\log(4+x^2)}{9+x^2}dx=\frac{\log(4)\pi}{54}+\sum_{n=0}^{\infty}\frac{(-1)^n}{(n+1)2^{2(n+1)}}\int_{0}^{\infty}\frac{x^{2(n+1)}}{9+x^2}dx","['real-analysis', 'calculus', 'integration', 'sequences-and-series', 'improper-integrals']"
10,Mistake in Kolmogorov's Elements of the theory of functions and functional analysis?,Mistake in Kolmogorov's Elements of the theory of functions and functional analysis?,,"I was reading the book Elements of the theory of functions and functional analysis (Volume 1) by Kolmogorov. More precisely, the part of compact sets in metric spaces: The underlined text is so confusig for me. First, we know that in $\mathbb{R}$ the compact sets are the closed and bounded sets (Heine-Borel), then, can be a set that is only bounded compact? I don't think so. I know that the definition that Kolomorov use is, really, the definition of sequentially compact, and I know that the compactness and the sequentially compactness are equivalent in metric spaces. Then, am I losing something of context in the book? Moreover, the book says that an arbitrary subset of a compact set is compact, but, is it true? I know that $[0,1]\subseteq\mathbb{R}$ is compact but $\left\{\displaystyle\frac{1}{n}:n\in\mathbb{N} \right\}\subseteq[0,1]$ is not compact. Again, Kolmogorov use some definition that I don't have? Am I misunderstanding? I will be really grateful if someone can explain me this. I really appreciate any help you can provide me.","I was reading the book Elements of the theory of functions and functional analysis (Volume 1) by Kolmogorov. More precisely, the part of compact sets in metric spaces: The underlined text is so confusig for me. First, we know that in $\mathbb{R}$ the compact sets are the closed and bounded sets (Heine-Borel), then, can be a set that is only bounded compact? I don't think so. I know that the definition that Kolomorov use is, really, the definition of sequentially compact, and I know that the compactness and the sequentially compactness are equivalent in metric spaces. Then, am I losing something of context in the book? Moreover, the book says that an arbitrary subset of a compact set is compact, but, is it true? I know that $[0,1]\subseteq\mathbb{R}$ is compact but $\left\{\displaystyle\frac{1}{n}:n\in\mathbb{N} \right\}\subseteq[0,1]$ is not compact. Again, Kolmogorov use some definition that I don't have? Am I misunderstanding? I will be really grateful if someone can explain me this. I really appreciate any help you can provide me.",,"['real-analysis', 'general-topology', 'functional-analysis', 'reference-request']"
11,"Prove that $\frac{\tan x}{x}>\frac{x}{\sin x}, x\in(0,\pi/2)$",Prove that,"\frac{\tan x}{x}>\frac{x}{\sin x}, x\in(0,\pi/2)","Prove that $$\frac{\tan x}{x}>\frac{x}{\sin x},\;\;\; x\in(0,\pi/2).$$ My work I formulated $$f(x)=\tan x \sin x - x^2$$ in hope that if $f'(x)>0$ i.e. monotonic then I can conclude for $x>0, f(x)>f(0)$ and hence, prove the statement. However, I got $$f'(x)=\sin x + \sec x \tan x -2x, $$ where I am unable to conclude if $f'(x)>0.$ I also found $$f''(x)=\cos x + 2\sec^3x-\sec x-2,$$ $$f'''(x)=-\sin x (1-6\sec^4x+\sec^2x).$$ But I am not able conclude the sign of any of the higher derivatives either. Am I doing something wrong? Or is there some other way?","Prove that $$\frac{\tan x}{x}>\frac{x}{\sin x},\;\;\; x\in(0,\pi/2).$$ My work I formulated $$f(x)=\tan x \sin x - x^2$$ in hope that if $f'(x)>0$ i.e. monotonic then I can conclude for $x>0, f(x)>f(0)$ and hence, prove the statement. However, I got $$f'(x)=\sin x + \sec x \tan x -2x, $$ where I am unable to conclude if $f'(x)>0.$ I also found $$f''(x)=\cos x + 2\sec^3x-\sec x-2,$$ $$f'''(x)=-\sin x (1-6\sec^4x+\sec^2x).$$ But I am not able conclude the sign of any of the higher derivatives either. Am I doing something wrong? Or is there some other way?",,"['calculus', 'real-analysis', 'trigonometry', 'derivatives', 'inequality']"
12,Is every Closed set a Perfect set?,Is every Closed set a Perfect set?,,"From 'baby' Rudin. I've seen that a set is closed iff it contains all of its limit points. In Rudin, $(d)$  says if every limit point of E is a point of E, then $E$ is closed. He also says $(h)$: $E$ is perfect if $E$ is closed and if every point of $E$ is a limit point of $E$. But Closed $\implies$ contains all of its limit points. So, is every closed set a perfect set?","From 'baby' Rudin. I've seen that a set is closed iff it contains all of its limit points. In Rudin, $(d)$  says if every limit point of E is a point of E, then $E$ is closed. He also says $(h)$: $E$ is perfect if $E$ is closed and if every point of $E$ is a limit point of $E$. But Closed $\implies$ contains all of its limit points. So, is every closed set a perfect set?",,"['real-analysis', 'general-topology', 'definition']"
13,Graph of a continuous function is closed,Graph of a continuous function is closed,,"Let $f: \mathbb{R} \to \mathbb{R}$ be continuous. Then $G = \{ (x, f(x) ) : x \in \mathbb{R} \} $ is a closed set. My try: Suppose $(z_n) =  (x_n, f(x_n) ) $ is sequence in $G$ with limit $(x,y)$. We must show $(x,y) \in G$. Since $x_n \to x$ and since $f$ is continuous, then we must have that $f(x_n) \to f(x) $. Since limits are unique. Then $y = f(x) $. Is this enough to conlude that $(x,y) \in G $ ? Hence showing $G$ is closed ? thanks","Let $f: \mathbb{R} \to \mathbb{R}$ be continuous. Then $G = \{ (x, f(x) ) : x \in \mathbb{R} \} $ is a closed set. My try: Suppose $(z_n) =  (x_n, f(x_n) ) $ is sequence in $G$ with limit $(x,y)$. We must show $(x,y) \in G$. Since $x_n \to x$ and since $f$ is continuous, then we must have that $f(x_n) \to f(x) $. Since limits are unique. Then $y = f(x) $. Is this enough to conlude that $(x,y) \in G $ ? Hence showing $G$ is closed ? thanks",,"['real-analysis', 'general-topology']"
14,"How to show that the monomials are not a Schauder basis for $C[0,1]$",How to show that the monomials are not a Schauder basis for,"C[0,1]","why the monomials are not a Schauder basis for $C[0,1]$? $p_n(x)=x^n$ such that $(p_n)$ does not form a Schauder basis for $C[0,1]$ span$\lbrace p_n : n\ge 0\rbrace$ is dense in $C[0,1]$ by Weierstrass approxmation theorem, but I cannot figure out why they are not a Schauder basis. Could you please explain","why the monomials are not a Schauder basis for $C[0,1]$? $p_n(x)=x^n$ such that $(p_n)$ does not form a Schauder basis for $C[0,1]$ span$\lbrace p_n : n\ge 0\rbrace$ is dense in $C[0,1]$ by Weierstrass approxmation theorem, but I cannot figure out why they are not a Schauder basis. Could you please explain",,"['real-analysis', 'analysis', 'functional-analysis']"
15,Compact sets of metric spaces are closed?,Compact sets of metric spaces are closed?,,"I am struggling with the idea that all compact subsets of a metric space are closed after reading chapter 2 of Rudin's Principles of Mathematical Analysis. The reason I am confused is that it seems unreasonable that a compact subset must be closed. If we were to take an open subset $K$ of a compact subset $Y$ in a metric space $X$, where $K$ is open relative to $X$, then every finite subcover of $Y$ would also be a finite subcover of $K$. But then, $K$ would be both compact and open in $X$, which contradicts the theorem that all compact subsets in $X$ are closed. Could someone please explain to me why my reasoning is incorrect and how it is  that compact subsets of metric spaces must be closed? Thank you, Evan","I am struggling with the idea that all compact subsets of a metric space are closed after reading chapter 2 of Rudin's Principles of Mathematical Analysis. The reason I am confused is that it seems unreasonable that a compact subset must be closed. If we were to take an open subset $K$ of a compact subset $Y$ in a metric space $X$, where $K$ is open relative to $X$, then every finite subcover of $Y$ would also be a finite subcover of $K$. But then, $K$ would be both compact and open in $X$, which contradicts the theorem that all compact subsets in $X$ are closed. Could someone please explain to me why my reasoning is incorrect and how it is  that compact subsets of metric spaces must be closed? Thank you, Evan",,"['real-analysis', 'general-topology', 'analysis']"
16,Show that $\sqrt{2+\sqrt{2+\sqrt{2...}}}$ converges to 2 [duplicate],Show that  converges to 2 [duplicate],\sqrt{2+\sqrt{2+\sqrt{2...}}},"This question already has answers here : Limit of the nested radical $x_{n+1} = \sqrt{c+x_n}$ (5 answers) The convergence of $\sqrt {2+\sqrt {2+\sqrt {2+\ldots}}}$ [duplicate] (5 answers) Closed 9 years ago . Consider the sequence defined by $a_1 = \sqrt{2}$, $a_2 = \sqrt{2 + \sqrt{2}}$, so that in general, $a_n = \sqrt{2 + a_{n - 1}}$ for $n > 1$. I know 2 is an upper bound of this sequence (I proved this by induction). Is there a way to show that this sequence converges to 2? What I think is that the key step is to prove 2 is the least upper bound of this sequence. But how?","This question already has answers here : Limit of the nested radical $x_{n+1} = \sqrt{c+x_n}$ (5 answers) The convergence of $\sqrt {2+\sqrt {2+\sqrt {2+\ldots}}}$ [duplicate] (5 answers) Closed 9 years ago . Consider the sequence defined by $a_1 = \sqrt{2}$, $a_2 = \sqrt{2 + \sqrt{2}}$, so that in general, $a_n = \sqrt{2 + a_{n - 1}}$ for $n > 1$. I know 2 is an upper bound of this sequence (I proved this by induction). Is there a way to show that this sequence converges to 2? What I think is that the key step is to prove 2 is the least upper bound of this sequence. But how?",,"['real-analysis', 'sequences-and-series', 'nested-radicals']"
17,Directional derivative in the direction of a sum of two vectors.,Directional derivative in the direction of a sum of two vectors.,,"Q. Let $f: \mathbb{R}^{n} \rightarrow \mathbb{R}$ be a map. For each vector $\mathbf{v} \in \mathbb{R}^{n}$ , we define $$ D_{\mathbf{v}} f(\mathbf{a})=\lim _{t \rightarrow 0} \frac{f(\mathbf{a}+t \mathbf{v})-f(\mathbf{a})}{t} $$ if the limit exists. $D_{\mathbf{v}} f(\mathbf{a})$ is the directional derivative of $f$ with respect to $v$ at $a$ . Show that for vectors $\mathbf{v}, \mathbf{w} \in \mathbb{R}^{n},$ one has $$ D_{\mathbf{v}+\mathbf{w}} f(\mathbf{a})=D_{\mathbf{v}} f(\mathbf{a})+D_{\mathbf{w}} f(\mathbf{a}) $$ My attempt: $$ \begin{array}{l}\lim _{t \rightarrow 0} \frac{f(a+t(\mathbf v+\mathbf w))-f(a)}{t} \\ =\operatorname{lim}_{t \rightarrow 0}\frac{ f(a+t\mathbf v+t\mathbf w)-f(a)}{t}\\ =\operatorname{lim}_{t \rightarrow 0}\frac{ f(a+t\mathbf v+t\mathbf w)-f(a+t\mathbf v)}{t}+\frac{ f(a+t\mathbf v)-f(a)}{t} \end{array} $$ Now, I have to prove that $$\operatorname{lim}_{t \rightarrow 0}\frac{ f(a+t\mathbf v+t\mathbf w)-f(a+t\mathbf v)}{t}=D_{\mathbf{w}} f(\mathbf{a}) $$ But how to?","Q. Let be a map. For each vector , we define if the limit exists. is the directional derivative of with respect to at . Show that for vectors one has My attempt: Now, I have to prove that But how to?","f: \mathbb{R}^{n} \rightarrow \mathbb{R} \mathbf{v} \in \mathbb{R}^{n} 
D_{\mathbf{v}} f(\mathbf{a})=\lim _{t \rightarrow 0} \frac{f(\mathbf{a}+t \mathbf{v})-f(\mathbf{a})}{t}
 D_{\mathbf{v}} f(\mathbf{a}) f v a \mathbf{v}, \mathbf{w} \in \mathbb{R}^{n}, 
D_{\mathbf{v}+\mathbf{w}} f(\mathbf{a})=D_{\mathbf{v}} f(\mathbf{a})+D_{\mathbf{w}} f(\mathbf{a})
 
\begin{array}{l}\lim _{t \rightarrow 0} \frac{f(a+t(\mathbf v+\mathbf w))-f(a)}{t} \\ =\operatorname{lim}_{t \rightarrow 0}\frac{ f(a+t\mathbf v+t\mathbf w)-f(a)}{t}\\
=\operatorname{lim}_{t \rightarrow 0}\frac{ f(a+t\mathbf v+t\mathbf w)-f(a+t\mathbf v)}{t}+\frac{ f(a+t\mathbf v)-f(a)}{t}
\end{array}
 \operatorname{lim}_{t \rightarrow 0}\frac{ f(a+t\mathbf v+t\mathbf w)-f(a+t\mathbf v)}{t}=D_{\mathbf{w}} f(\mathbf{a})
",['real-analysis']
18,Definition of Cauchy Sequence,Definition of Cauchy Sequence,,"I have a question regarding the definition of a Cauchy sequence of a sequence in a metric space. The definition I learned and that is consistent with Wikipedia defines a sequence $(x_n)_{n=1}^\infty$ as a Cauchy sequence if $$ \forall\, \varepsilon>0 \;\;\exists\, N\in\mathbb{N}\;\; \forall\, m,n \geq N : d(x_m,x_n)<\varepsilon $$ If I am not mistaken, there is a simpler, but equivalent definition: $$ \forall\, \varepsilon>0 \;\; \exists\, N\in\mathbb{N} \;\; \forall\, m \geq N: d(x_m,x_N)<\varepsilon $$ This is simpler, because it only has two natural numbers in it instead of three. This makes it easier to prove, that a given sequence is a Cauchy sequence. Note that the equivalence relies on the triangle inequality. Proof: $(\Rightarrow)$: we simply choose $n=N$. $(\Leftarrow)$: Let $\varepsilon>0$. Then $$ \exists\, N\in\mathbb{N}\;\; \forall\, m \geq N: d(x_m,x_N)<\frac12\varepsilon $$ This means that for $m,n\geq N$ we have $$ d(x_m,x_n) \leq d(x_m,x_N)+d(x_n,x_N) < \frac12\varepsilon +\frac12\varepsilon = \varepsilon $$ So here is my question: why did I never encounter the more simple definition before? Did I make a mistake somewhere? Are there advantages to the common definition, that I don't see? Edit: Often the shortest/simplest definition becomes the standard definition. Why not in this case?","I have a question regarding the definition of a Cauchy sequence of a sequence in a metric space. The definition I learned and that is consistent with Wikipedia defines a sequence $(x_n)_{n=1}^\infty$ as a Cauchy sequence if $$ \forall\, \varepsilon>0 \;\;\exists\, N\in\mathbb{N}\;\; \forall\, m,n \geq N : d(x_m,x_n)<\varepsilon $$ If I am not mistaken, there is a simpler, but equivalent definition: $$ \forall\, \varepsilon>0 \;\; \exists\, N\in\mathbb{N} \;\; \forall\, m \geq N: d(x_m,x_N)<\varepsilon $$ This is simpler, because it only has two natural numbers in it instead of three. This makes it easier to prove, that a given sequence is a Cauchy sequence. Note that the equivalence relies on the triangle inequality. Proof: $(\Rightarrow)$: we simply choose $n=N$. $(\Leftarrow)$: Let $\varepsilon>0$. Then $$ \exists\, N\in\mathbb{N}\;\; \forall\, m \geq N: d(x_m,x_N)<\frac12\varepsilon $$ This means that for $m,n\geq N$ we have $$ d(x_m,x_n) \leq d(x_m,x_N)+d(x_n,x_N) < \frac12\varepsilon +\frac12\varepsilon = \varepsilon $$ So here is my question: why did I never encounter the more simple definition before? Did I make a mistake somewhere? Are there advantages to the common definition, that I don't see? Edit: Often the shortest/simplest definition becomes the standard definition. Why not in this case?",,"['real-analysis', 'metric-spaces', 'cauchy-sequences']"
19,Every finite set contains its supremum: proof improvement.,Every finite set contains its supremum: proof improvement.,,"Every finite subset of $\mathbb R$ contains its supremum (and its infimum) Proof Let $A=\{a_1,...,a_n\}$ be a finite subset of $\mathbb{R}$. Since it is non-empty and it is bounded ($\max A$ is an upper bound), it has supremum, that is $\exists \sup A$ and by definition $\forall a \in A \;\, a \leq \sup A$. Let's suppose that $\sup A  \not\in A$ then, since $\max A \in A$ we have that $\max A < \sup A$. But considering that $\mathbb Q$ is dense in $\mathbb R$ we can conclude that $\exists r \in \mathbb Q$ s.t. $\max A < r < \sup A$, but this is absurd since $r$ is an upper bound of $A$ and it is lower than the supremum. Necessarily, $\sup A\in A$. Is there anything wrong? Is there any way to prove this without using density of $\mathbb Q$ or another property? Thanks in advance.","Every finite subset of $\mathbb R$ contains its supremum (and its infimum) Proof Let $A=\{a_1,...,a_n\}$ be a finite subset of $\mathbb{R}$. Since it is non-empty and it is bounded ($\max A$ is an upper bound), it has supremum, that is $\exists \sup A$ and by definition $\forall a \in A \;\, a \leq \sup A$. Let's suppose that $\sup A  \not\in A$ then, since $\max A \in A$ we have that $\max A < \sup A$. But considering that $\mathbb Q$ is dense in $\mathbb R$ we can conclude that $\exists r \in \mathbb Q$ s.t. $\max A < r < \sup A$, but this is absurd since $r$ is an upper bound of $A$ and it is lower than the supremum. Necessarily, $\sup A\in A$. Is there anything wrong? Is there any way to prove this without using density of $\mathbb Q$ or another property? Thanks in advance.",,"['real-analysis', 'proof-writing']"
20,"Closed form for the hypergeometic function $\,_{4}F_{3}\left(1,-k,k+\frac{3}{2},\frac{1}{2};\frac{1}{2}-k,k+2,\frac{3}{2};1\right)$",Closed form for the hypergeometic function,"\,_{4}F_{3}\left(1,-k,k+\frac{3}{2},\frac{1}{2};\frac{1}{2}-k,k+2,\frac{3}{2};1\right)","Let $K(x)$ be the complete elliptic integral of the first kind with the following convention $$K(x):=\int_{0}^{\pi/2}\frac{\mathrm{d}\theta}{\sqrt{1-x\sin^{2}(\theta)}}.$$ For a research work, I would like to compute the Fourier-Legendre coefficients of $K(x)^{2}$ , that is, integrals of the type $$\int_{0}^{1}K(x)^{2}P_{n}\left(2x-1\right)\mathrm{d}x$$ where $P_{n}(x)$ are the Legendre polynomials. For now, I'm only able to prove the following representation for odd $n$ $$\int_{0}^{1}K(x)^{2}P_{2k+1}(2x-1)\mathrm{d}x=\frac{1}{(2k+1)(k+1)}\,_{4}F_{3}\left(\left.{1,-k,k+\frac{3}{2},\frac{1}{2}\atop\frac{1}{2}-k,k+2,\frac{3}{2}}\right|1\right).$$ I tried to search some identities and to apply some classical results to this $_{4}F_{3}$ but I'm not able to find a closed form of such function (for closed form I intend some representation in terms of ratio of Gamma functions or in terms to functions strictly related to Gamma function). So my question is: does anyone know if this hypergeometric function admits a closed form? Bonus question : for even $n$ , for now, I have no idea to attack this problem, so any suggestions are welcome.","Let be the complete elliptic integral of the first kind with the following convention For a research work, I would like to compute the Fourier-Legendre coefficients of , that is, integrals of the type where are the Legendre polynomials. For now, I'm only able to prove the following representation for odd I tried to search some identities and to apply some classical results to this but I'm not able to find a closed form of such function (for closed form I intend some representation in terms of ratio of Gamma functions or in terms to functions strictly related to Gamma function). So my question is: does anyone know if this hypergeometric function admits a closed form? Bonus question : for even , for now, I have no idea to attack this problem, so any suggestions are welcome.","K(x) K(x):=\int_{0}^{\pi/2}\frac{\mathrm{d}\theta}{\sqrt{1-x\sin^{2}(\theta)}}. K(x)^{2} \int_{0}^{1}K(x)^{2}P_{n}\left(2x-1\right)\mathrm{d}x P_{n}(x) n \int_{0}^{1}K(x)^{2}P_{2k+1}(2x-1)\mathrm{d}x=\frac{1}{(2k+1)(k+1)}\,_{4}F_{3}\left(\left.{1,-k,k+\frac{3}{2},\frac{1}{2}\atop\frac{1}{2}-k,k+2,\frac{3}{2}}\right|1\right). _{4}F_{3} n","['real-analysis', 'integration', 'special-functions', 'closed-form', 'hypergeometric-function']"
21,Prove that $2-\cfrac{\pi^2}{6-\cfrac{\pi^2}{10-\cfrac{\pi^2}{14-\cfrac{\pi^2}{...}}}} = 0$,Prove that,2-\cfrac{\pi^2}{6-\cfrac{\pi^2}{10-\cfrac{\pi^2}{14-\cfrac{\pi^2}{...}}}} = 0,Prove that $$2 - \cfrac{\pi^2}{6-\cfrac{\pi^2}{10 - \cfrac{\pi^2}{14-\cfrac{\pi^2}{...}}}} = 0$$ My thoughts: One common approahch is setting $x = \text{LHS}$ and we express LHS as $x = \frac{\pi^2}{f(x)}$ . But it's hard to translate the denominator as a function of $x$ $\pi^2$ also reminds everybody of the basel problem $\sum_{n=1}^{\infty} \frac{1}{n^2} = \frac{\pi^2}{6}$ but what can we do about it?,Prove that My thoughts: One common approahch is setting and we express LHS as . But it's hard to translate the denominator as a function of also reminds everybody of the basel problem but what can we do about it?,2 - \cfrac{\pi^2}{6-\cfrac{\pi^2}{10 - \cfrac{\pi^2}{14-\cfrac{\pi^2}{...}}}} = 0 x = \text{LHS} x = \frac{\pi^2}{f(x)} x \pi^2 \sum_{n=1}^{\infty} \frac{1}{n^2} = \frac{\pi^2}{6},"['real-analysis', 'sequences-and-series']"
22,Why does the plot of $f(x)=|\cos x|-|\sin x|$ look almost piecewise linear?,Why does the plot of  look almost piecewise linear?,f(x)=|\cos x|-|\sin x|,I recently stumbled upon an interesting plot that I - even until today - could not quite explain: It's the plot of $f(x) = \lvert \cos(x) \rvert - \lvert \sin(x) \rvert$ . I mean this is almost piecewise linear... I tried to derive this shape from the Taylor series but I could not quite see it. Does anyone have some mathematical intuition for me concerning the shape of this plot?,I recently stumbled upon an interesting plot that I - even until today - could not quite explain: It's the plot of . I mean this is almost piecewise linear... I tried to derive this shape from the Taylor series but I could not quite see it. Does anyone have some mathematical intuition for me concerning the shape of this plot?,f(x) = \lvert \cos(x) \rvert - \lvert \sin(x) \rvert,"['real-analysis', 'calculus', 'algebra-precalculus', 'trigonometry']"
23,Evaluating $\sum_{k=0}^\infty \left(\frac{1}{5k+1} - \frac{1}{5k+2} - \frac{1}{5k+3} + \frac{1}{5k+4} \right)$,Evaluating,\sum_{k=0}^\infty \left(\frac{1}{5k+1} - \frac{1}{5k+2} - \frac{1}{5k+3} + \frac{1}{5k+4} \right),"I saw this problem somewhere recently and I was having some difficulty getting started on it. The problem is twofold. The first is to evaluate: $$\sum_{k=0}^\infty \left(\frac{1}{5k+1} - \frac{1}{5k+2} - \frac{1}{5k+3} + \frac{1}{5k+4} \right)$$ and once this is done, to explain what this has to do with the construction of a pentagon (maybe some other polygon?) using a compass and straight edge. In terms of evaluating the series, I tried writing each $n$ as $m \cdot 2^k$ and evaluating the summation there since $2^k$ will alternate between + and - mod 5. However, this leads to a divergent series and I think this is not a valid thing to do since the original series is not absolutely convergent so we can't rearrange terms like that.","I saw this problem somewhere recently and I was having some difficulty getting started on it. The problem is twofold. The first is to evaluate: $$\sum_{k=0}^\infty \left(\frac{1}{5k+1} - \frac{1}{5k+2} - \frac{1}{5k+3} + \frac{1}{5k+4} \right)$$ and once this is done, to explain what this has to do with the construction of a pentagon (maybe some other polygon?) using a compass and straight edge. In terms of evaluating the series, I tried writing each $n$ as $m \cdot 2^k$ and evaluating the summation there since $2^k$ will alternate between + and - mod 5. However, this leads to a divergent series and I think this is not a valid thing to do since the original series is not absolutely convergent so we can't rearrange terms like that.",,"['real-analysis', 'sequences-and-series', 'geometric-construction']"
24,"An example of a bounded, continuous function on $(0,1)$ that is not uniformly continuous","An example of a bounded, continuous function on  that is not uniformly continuous","(0,1)","I can not find the example of a continuous function on $(0,1)$ that is bounded on $(0,1)$, but not uniformly continuous on $(0,1)$. Is there any? Thank you.","I can not find the example of a continuous function on $(0,1)$ that is bounded on $(0,1)$, but not uniformly continuous on $(0,1)$. Is there any? Thank you.",,"['real-analysis', 'limits', 'continuity', 'examples-counterexamples', 'uniform-continuity']"
25,"If $f(A)\to A^{-1}$, prove that $f$ is continuous.","If , prove that  is continuous.",f(A)\to A^{-1} f,Let $f \colon GL_{n}(\mathbb{R})\to GL_{n}(\mathbb{R})$ be a function which maps $A\mapsto A^{-1}$. Prove that $f$ is continuous. $GL_{n}(\mathbb{R})=\det^{-1}(\mathbb{R}\setminus\{0\})$ is the set of invertible matrix of  order $n\times n$ with real coefficients. Should I do $A^{-1}=\dfrac{\operatorname{adj}(A)}{\det(A)}$ and use it like a rational polynomial? Are there a overkill way to prove this? Any hint? Thanks MSE!,Let $f \colon GL_{n}(\mathbb{R})\to GL_{n}(\mathbb{R})$ be a function which maps $A\mapsto A^{-1}$. Prove that $f$ is continuous. $GL_{n}(\mathbb{R})=\det^{-1}(\mathbb{R}\setminus\{0\})$ is the set of invertible matrix of  order $n\times n$ with real coefficients. Should I do $A^{-1}=\dfrac{\operatorname{adj}(A)}{\det(A)}$ and use it like a rational polynomial? Are there a overkill way to prove this? Any hint? Thanks MSE!,,"['real-analysis', 'continuity', 'matrix-calculus']"
26,Why does the definition of the functional limit involve a limit point?,Why does the definition of the functional limit involve a limit point?,,"This may be an odd question, and I'm not sure if these type of questions are at all appreciated in the maths community. But given the definition of the functional limit: Let $f: A \to \mathbb{R}$, and let $c$ be a limit point of the domain $A$. We say that $\lim_{x \to c} f(x)=L$ provided that, for all $\epsilon > 0$, there exists a $\delta > 0$ such that whenever $0<|x-c|< \delta$ (and $x \in A$) it follows that $|f(x)-L|< \epsilon$. why does $c$ have to be a limit point? I understand that the above is just a definition , and we can define anything we want to. But, after having gone through an entire chapter of functional limits and continuity, I have not yet figured out what would go wrong if $c$ was not a limit point.","This may be an odd question, and I'm not sure if these type of questions are at all appreciated in the maths community. But given the definition of the functional limit: Let $f: A \to \mathbb{R}$, and let $c$ be a limit point of the domain $A$. We say that $\lim_{x \to c} f(x)=L$ provided that, for all $\epsilon > 0$, there exists a $\delta > 0$ such that whenever $0<|x-c|< \delta$ (and $x \in A$) it follows that $|f(x)-L|< \epsilon$. why does $c$ have to be a limit point? I understand that the above is just a definition , and we can define anything we want to. But, after having gone through an entire chapter of functional limits and continuity, I have not yet figured out what would go wrong if $c$ was not a limit point.",,"['real-analysis', 'soft-question']"
27,A partition of the unit interval into uncountably many dense uncountable subsets,A partition of the unit interval into uncountably many dense uncountable subsets,,"The title says it all: Is there a partition of $[0,1]$ into uncountably many dense uncountable subsets ?","The title says it all: Is there a partition of $[0,1]$ into uncountably many dense uncountable subsets ?",,['real-analysis']
28,"how to prove, $f$ is onto if $f$ is continuous and satisfying $|f(x) - f(y)| ≥ |x - y|$ for all $x,y$ in $\mathbb{R}$","how to prove,  is onto if  is continuous and satisfying  for all  in","f f |f(x) - f(y)| ≥ |x - y| x,y \mathbb{R}","let $f:\mathbb{R}\rightarrow\mathbb{R}$ be a continuous function such that $|f(x) - f(y)| ≥ |x - y|$ for all $x,y$ in $\mathbb{R}$. then $f$ is onto.","let $f:\mathbb{R}\rightarrow\mathbb{R}$ be a continuous function such that $|f(x) - f(y)| ≥ |x - y|$ for all $x,y$ in $\mathbb{R}$. then $f$ is onto.",,['real-analysis']
29,"Is there a Partition of $[0,1]$ into closed, countably infinite sets?","Is there a Partition of  into closed, countably infinite sets?","[0,1]","I'm wondering whether it is possible to Partition the closed interval $[0,1]$ into closed, countably infinite sets. The only observations I could make were as follows: When we remove the endpoints, we effectively end up with $\mathbb R$, and can consider the image of $$\mathscr S :=\{r+\mathbb N\mid r\in [0,1)\}$$ Because every $S\in \mathscr S$ is bounded, it must contain at least one limit point. Because our partition itself must be uncountable, $\bigcup_{S\in \mathscr S} L(S)$ ist uncountable, and by second countability, has uncountably many limit points. A natural example for a partition into countably infinite sets is $\{r+\mathbb Q\}$, but these elements are not closed – on the contrary, every sets closure is $\mathbb R$ already. I'm not really sure where to go from there. My intuition says that this won't work, because it would get “too crowded” near the boundary points, but I'm not sure how to make this precise.","I'm wondering whether it is possible to Partition the closed interval $[0,1]$ into closed, countably infinite sets. The only observations I could make were as follows: When we remove the endpoints, we effectively end up with $\mathbb R$, and can consider the image of $$\mathscr S :=\{r+\mathbb N\mid r\in [0,1)\}$$ Because every $S\in \mathscr S$ is bounded, it must contain at least one limit point. Because our partition itself must be uncountable, $\bigcup_{S\in \mathscr S} L(S)$ ist uncountable, and by second countability, has uncountably many limit points. A natural example for a partition into countably infinite sets is $\{r+\mathbb Q\}$, but these elements are not closed – on the contrary, every sets closure is $\mathbb R$ already. I'm not really sure where to go from there. My intuition says that this won't work, because it would get “too crowded” near the boundary points, but I'm not sure how to make this precise.",,"['real-analysis', 'general-topology', 'cardinals']"
30,Can the integral of a function be larger than function itself?,Can the integral of a function be larger than function itself?,,"Are there any non zero(i.e not $f \equiv0  $) and non-negative continuous function $f$ defined on $[0,1]$, which satisfies $\int_0^x{f(t)}dt \geq f(x)~ \forall x$ in $[0,1]$?","Are there any non zero(i.e not $f \equiv0  $) and non-negative continuous function $f$ defined on $[0,1]$, which satisfies $\int_0^x{f(t)}dt \geq f(x)~ \forall x$ in $[0,1]$?",,"['real-analysis', 'convergence-divergence', 'definite-integrals']"
31,"If a linear operator has an adjoint operator, it is bounded","If a linear operator has an adjoint operator, it is bounded",,"This is a question I'm struggling with for a while: Let $H$ be a Hilber space. Let  $T,S: H\rightarrow H$ be linear operators (not neccessarily bounded) such that for every $x,y\in H$: $\langle Tx,y\rangle=\langle x,Sy \rangle$. Prove $T,S$ are bounded. What I did so far: First attempt: $||Tx||^2=\langle Tx,Tx\rangle=\langle x,STx\rangle\le||x||*||STx||\le||x||*||S||*||Tx||$ I'm not entirly sure I'm allowed to do the last inequallity, since $||S||$ might be $\infty$. It follows $||Tx||\le ||x||*||S||$ and analogly $||Sx||\le ||x||*||T||$ From the first I'd get $||T||\le ||S||$ and from the second $||S||\le||T||$. Therefore $||S||=||T||$. I don't know where to go from here. Second Attempt: assume  $T$ isn't bounded, therefore so is $S$, therefore there are series $(x_n),(y_n)\subset H$ such that $||x_n||=||y_n||=1$ and $\lim ||Tx_n||=\infty,\lim ||Sy_n||=\infty$. I'll keep it going soon, but it didn't go so well.. I'd love some guide. Not neccessarily the whole solution, but something that would tell me what i'm missing. Thanks :)","This is a question I'm struggling with for a while: Let $H$ be a Hilber space. Let  $T,S: H\rightarrow H$ be linear operators (not neccessarily bounded) such that for every $x,y\in H$: $\langle Tx,y\rangle=\langle x,Sy \rangle$. Prove $T,S$ are bounded. What I did so far: First attempt: $||Tx||^2=\langle Tx,Tx\rangle=\langle x,STx\rangle\le||x||*||STx||\le||x||*||S||*||Tx||$ I'm not entirly sure I'm allowed to do the last inequallity, since $||S||$ might be $\infty$. It follows $||Tx||\le ||x||*||S||$ and analogly $||Sx||\le ||x||*||T||$ From the first I'd get $||T||\le ||S||$ and from the second $||S||\le||T||$. Therefore $||S||=||T||$. I don't know where to go from here. Second Attempt: assume  $T$ isn't bounded, therefore so is $S$, therefore there are series $(x_n),(y_n)\subset H$ such that $||x_n||=||y_n||=1$ and $\lim ||Tx_n||=\infty,\lim ||Sy_n||=\infty$. I'll keep it going soon, but it didn't go so well.. I'd love some guide. Not neccessarily the whole solution, but something that would tell me what i'm missing. Thanks :)",,"['real-analysis', 'functional-analysis']"
32,Motivation for Topology study in Real Analysis,Motivation for Topology study in Real Analysis,,"I'm an engineering student trying to work out some Real Analysis to learn how to write proofs (Needed for my PhD thesis) and just to rekindle my Calculus fires. From what I see, Real Analysis is the study of the basics of Calculus and ""constructing"" Calculus ground up. Why is Topology needed in the endeavor? I can't grapple my Engineering brain around compact sets and finite subcovers and stuff. I just can't imagine what's happening without spending 2 hours and 4 coffees. The only ""use"" of this I've seen till now is for proving All Cauchy sequences are convergent in certain spaces. Can I skip topology? If yes, what is the bare minimum I need to do?","I'm an engineering student trying to work out some Real Analysis to learn how to write proofs (Needed for my PhD thesis) and just to rekindle my Calculus fires. From what I see, Real Analysis is the study of the basics of Calculus and ""constructing"" Calculus ground up. Why is Topology needed in the endeavor? I can't grapple my Engineering brain around compact sets and finite subcovers and stuff. I just can't imagine what's happening without spending 2 hours and 4 coffees. The only ""use"" of this I've seen till now is for proving All Cauchy sequences are convergent in certain spaces. Can I skip topology? If yes, what is the bare minimum I need to do?",,"['real-analysis', 'general-topology', 'soft-question']"
33,Terms that get closer and closer together [duplicate],Terms that get closer and closer together [duplicate],,"This question already has answers here : Closed 12 years ago . Possible Duplicate: Why doesn't $d(x_n,x_{n+1})\rightarrow 0$ as $n\rightarrow\infty$ imply ${x_n}$ is Cauchy? I was thinking about sequences where it appears the terms get closer and closer together, and wondered if they converge. Now let's first define a few things. When I say ""the terms get closer and closer together"", I mean ""the distance between any two consecutive terms approaches zero."" In other words, for a sequence $\left(x_n\right)$, $$|x_n-x_{n-1}| \to 0$$ consecutive terms become closer and closer together. Let's look at an example: $\left(\ln n\right)$. Clearly, $$\bigl|\ln (n) - \ln (n-1)\bigr|\to 0$$ and this can be verified by looking at a graph. At first, I saw this and thought $\left(x_n\right)$ and $\left(\ln n\right)$ looked like Cauchy sequences, and this was bugging me for the longest time, because I knew $\left(\ln n\right)$ was not supposed to be Cauchy! But I realize now that there is a subtle difference: for a Cauchy sequence $\left(y_n\right)$, $$|y_n-y_{m}| \to 0$$ So in the cases of $\left(x_n\right)$ and $\left(\ln n\right)$, it may be true that consecutive terms are closer together, but two arbitrary terms aren't necessarily close together. So $\left(\ln n\right)$ is definitely not Cauchy. What can we call sequences such as $\left(x_n\right)$ and $\left(\ln n\right)$, where consecutive terms become closer together? I'd like to propose a name: let's call them Cauchy-ish . An intuitive geometric view of a Cauchy-ish sequence $\left(x_n\right)$ might be that you have a bunch of points on a line, and as you move forward in the sequence, the points get closer and closer together. It seems to me that this sequence would converge, no? Obviously my intuitive side and my analytical side disagree, because $\left(\ln n\right)$ is Cauchy-ish but is not Cauchy. My question, finally, is, why don't ""Cauchy-ish"" sequences necessarily converge?","This question already has answers here : Closed 12 years ago . Possible Duplicate: Why doesn't $d(x_n,x_{n+1})\rightarrow 0$ as $n\rightarrow\infty$ imply ${x_n}$ is Cauchy? I was thinking about sequences where it appears the terms get closer and closer together, and wondered if they converge. Now let's first define a few things. When I say ""the terms get closer and closer together"", I mean ""the distance between any two consecutive terms approaches zero."" In other words, for a sequence $\left(x_n\right)$, $$|x_n-x_{n-1}| \to 0$$ consecutive terms become closer and closer together. Let's look at an example: $\left(\ln n\right)$. Clearly, $$\bigl|\ln (n) - \ln (n-1)\bigr|\to 0$$ and this can be verified by looking at a graph. At first, I saw this and thought $\left(x_n\right)$ and $\left(\ln n\right)$ looked like Cauchy sequences, and this was bugging me for the longest time, because I knew $\left(\ln n\right)$ was not supposed to be Cauchy! But I realize now that there is a subtle difference: for a Cauchy sequence $\left(y_n\right)$, $$|y_n-y_{m}| \to 0$$ So in the cases of $\left(x_n\right)$ and $\left(\ln n\right)$, it may be true that consecutive terms are closer together, but two arbitrary terms aren't necessarily close together. So $\left(\ln n\right)$ is definitely not Cauchy. What can we call sequences such as $\left(x_n\right)$ and $\left(\ln n\right)$, where consecutive terms become closer together? I'd like to propose a name: let's call them Cauchy-ish . An intuitive geometric view of a Cauchy-ish sequence $\left(x_n\right)$ might be that you have a bunch of points on a line, and as you move forward in the sequence, the points get closer and closer together. It seems to me that this sequence would converge, no? Obviously my intuitive side and my analytical side disagree, because $\left(\ln n\right)$ is Cauchy-ish but is not Cauchy. My question, finally, is, why don't ""Cauchy-ish"" sequences necessarily converge?",,"['real-analysis', 'sequences-and-series', 'convergence-divergence']"
34,"If $f(x)$ and $\frac{f(2x)-f(x)}{x}$ have limit $0$ as $x\to 0$, then $\frac{f(x)}{x}\to 0$","If  and  have limit  as , then",f(x) \frac{f(2x)-f(x)}{x} 0 x\to 0 \frac{f(x)}{x}\to 0,"Prove that if $\lim_{x\to 0} f(x) = 0$ and $\lim\limits_{x\to 0} \frac{f(2x)-f(x)}{x}= 0$ , then $\lim\limits_{x\to 0} \frac{f(x)}{x} = 0.$ I try to solve it in this way: $f(x)$ is infinitesimal because $\lim\limits_{x\to 0} f(x) = 0,$ $\lim\limits_{x\to 0} \frac{f(2x)-f(x)}{x}= 0,\Rightarrow {f(2x)-f(x)}=o({x})\Rightarrow  {f(2x)}=f(x)+o({x}).$ Well $$\lim_{x\to 0} \frac{f(2x)-f(x)}{x}= \lim_{x\to 0} \frac{f(x)+o({x})}{x}= \lim_{x\to 0} \frac{f(x)}{x}+\lim_{x\to 0}\frac{o({x})}{x}=0$$ $\lim_{x\to 0}\frac{o({x})}{x}=0$ , of course; then $$\lim_{x\to 0} \frac{f(x)}{x} = 0$$","Prove that if and , then I try to solve it in this way: is infinitesimal because Well , of course; then","\lim_{x\to 0} f(x) = 0 \lim\limits_{x\to 0} \frac{f(2x)-f(x)}{x}= 0 \lim\limits_{x\to 0} \frac{f(x)}{x} = 0. f(x) \lim\limits_{x\to 0} f(x) = 0, \lim\limits_{x\to 0} \frac{f(2x)-f(x)}{x}= 0,\Rightarrow {f(2x)-f(x)}=o({x})\Rightarrow  {f(2x)}=f(x)+o({x}). \lim_{x\to 0} \frac{f(2x)-f(x)}{x}= \lim_{x\to 0} \frac{f(x)+o({x})}{x}= \lim_{x\to 0} \frac{f(x)}{x}+\lim_{x\to 0}\frac{o({x})}{x}=0 \lim_{x\to 0}\frac{o({x})}{x}=0 \lim_{x\to 0} \frac{f(x)}{x} = 0","['calculus', 'real-analysis', 'sequences-and-series', 'limits']"
35,What is $\lim_{x \to \infty} \frac{\sin x}{\sin x}?$,What is,\lim_{x \to \infty} \frac{\sin x}{\sin x}?,"As the title suggests, I am interested in computing $$\lim_{x \to \infty} \frac{\sin x}{\sin x}.$$ Some of my friends say that the limit is $1$ because the domain of function is $\mathbb{R} \setminus \{n \pi : n \text{ is an integer}\},$ whereas others say that this limit is undefined. Which opinion is correct?","As the title suggests, I am interested in computing Some of my friends say that the limit is because the domain of function is whereas others say that this limit is undefined. Which opinion is correct?","\lim_{x \to \infty} \frac{\sin x}{\sin x}. 1 \mathbb{R} \setminus \{n \pi : n \text{ is an integer}\},","['real-analysis', 'calculus', 'limits']"
36,"Probabilistic techniques, methods, and ideas in (""undergraduate"") real analysis","Probabilistic techniques, methods, and ideas in (""undergraduate"") real analysis",,"As the book Probabilistic Techniques in Analysis by Richard F. Bass shows, nowadays techniques drawn from probability are used to tackle problems in analysis. The mentioned book presents a survey of these methods "" at the level of a beginning Ph.D. student "", but I would like to see some examples of ""more basic"" applications of probability to undergraduate (so to say) real analysis (in other words, I would like to see some applications of probabilistic reasoning to calculus problems).","As the book Probabilistic Techniques in Analysis by Richard F. Bass shows, nowadays techniques drawn from probability are used to tackle problems in analysis. The mentioned book presents a survey of these methods "" at the level of a beginning Ph.D. student "", but I would like to see some examples of ""more basic"" applications of probability to undergraduate (so to say) real analysis (in other words, I would like to see some applications of probabilistic reasoning to calculus problems).",,"['calculus', 'real-analysis', 'probability', 'soft-question', 'big-list']"
37,Calculus Question: Improper integral $\int_{0}^{\infty}\frac{\cos(2x+1)}{\sqrt[3]{x}}\text dx$,Calculus Question: Improper integral,\int_{0}^{\infty}\frac{\cos(2x+1)}{\sqrt[3]{x}}\text dx,How to evaluate integral $$\int_{0}^{\infty}\frac{\cos(2x+1)}{\sqrt[3]{x}}\text dx?$$ I tried substitution $x=u^3$ and I got $3\displaystyle\int_{0}^{\infty}u \cos(2u^3+1)\text du$ . After that I tried to use integration by parts but I don't know the integral $\displaystyle\int \cos(2u^3+1)\text du$ . Any idea? Thanks in advance.,How to evaluate integral I tried substitution and I got . After that I tried to use integration by parts but I don't know the integral . Any idea? Thanks in advance.,\int_{0}^{\infty}\frac{\cos(2x+1)}{\sqrt[3]{x}}\text dx? x=u^3 3\displaystyle\int_{0}^{\infty}u \cos(2u^3+1)\text du \displaystyle\int \cos(2u^3+1)\text du,"['calculus', 'real-analysis', 'integration', 'definite-integrals', 'improper-integrals']"
38,"Integral $\int_0^\infty \log \frac{1+x^3}{x^3} \frac{x \,dx}{1+x^3}=\frac{\pi}{\sqrt 3}\log 3-\frac{\pi^2}{9}$",Integral,"\int_0^\infty \log \frac{1+x^3}{x^3} \frac{x \,dx}{1+x^3}=\frac{\pi}{\sqrt 3}\log 3-\frac{\pi^2}{9}","I am trying to prove this interesting integral $$ I:=\int_0^\infty \log \frac{1+x^3}{x^3} \frac{x \,dx}{1+x^3}=\frac{\pi}{\sqrt 3}\log 3-\frac{\pi^2}{9}. $$ I tried using $y=1+x^3$ but that didn't help.   We can possibly try $$ I=\int_0^\infty \frac{\log(1+x^3) x}{1+x^3} \,dx-\int_0^\infty \frac{\log(x^3) x}{1+x^3}\,dx. $$ These integrals would be much easier had the bounds been from $0 $\ to $\infty$, however they are not.  Perhaps partial integration will work but I didn't find the way if we try $$ dv=\frac{x}{1+x^3}, \quad u= \log(1+x^3) $$ but I ran into a divergent integral. Thanks how can we prove I?","I am trying to prove this interesting integral $$ I:=\int_0^\infty \log \frac{1+x^3}{x^3} \frac{x \,dx}{1+x^3}=\frac{\pi}{\sqrt 3}\log 3-\frac{\pi^2}{9}. $$ I tried using $y=1+x^3$ but that didn't help.   We can possibly try $$ I=\int_0^\infty \frac{\log(1+x^3) x}{1+x^3} \,dx-\int_0^\infty \frac{\log(x^3) x}{1+x^3}\,dx. $$ These integrals would be much easier had the bounds been from $0 $\ to $\infty$, however they are not.  Perhaps partial integration will work but I didn't find the way if we try $$ dv=\frac{x}{1+x^3}, \quad u= \log(1+x^3) $$ but I ran into a divergent integral. Thanks how can we prove I?",,"['calculus', 'real-analysis', 'integration', 'complex-analysis', 'definite-integrals']"
39,Equivalent ideas of absolute continuity of measures,Equivalent ideas of absolute continuity of measures,,"Wikipedia says that $\mu$ is absolutely continuous with respect to $\nu$, if $\nu(A)=0 \Rightarrow \mu(A)=0$. Okay, then I found another notion of absolute continuous measures: Let $||f||_1=1$ and $\mu(A):= \int_A |f| d \nu$, then we also have absolute continuity in the sense that if $\nu(A)  < \delta \Rightarrow \mu(A) < \varepsilon$. My question is: How are these definitions related to each other? It is clear that the second notion implies the first one, but is the converse also true? Where does this $\varepsilon$, $\delta$ comes into play? Edit: Afais is the converse implication the result of a special case of the Radon-Nikodym theorem and a few lines of calculation that the $\varepsilon, \delta$ stuff actually holds, right?","Wikipedia says that $\mu$ is absolutely continuous with respect to $\nu$, if $\nu(A)=0 \Rightarrow \mu(A)=0$. Okay, then I found another notion of absolute continuous measures: Let $||f||_1=1$ and $\mu(A):= \int_A |f| d \nu$, then we also have absolute continuity in the sense that if $\nu(A)  < \delta \Rightarrow \mu(A) < \varepsilon$. My question is: How are these definitions related to each other? It is clear that the second notion implies the first one, but is the converse also true? Where does this $\varepsilon$, $\delta$ comes into play? Edit: Afais is the converse implication the result of a special case of the Radon-Nikodym theorem and a few lines of calculation that the $\varepsilon, \delta$ stuff actually holds, right?",,"['real-analysis', 'analysis']"
40,How to prove that Lebesgue outer measure is translation invariant?,How to prove that Lebesgue outer measure is translation invariant?,,"I am trying to prove that lesbegue outer measure is translation invariant, i.e., $m^\ast (E+y)=m^\ast E$. I proceed as follows. Let $E$ be a set. Let $\{I_n\}$ be a collection of open intervals that cover E. It follows that $\{I_n+y\}$ covers $E+y$. Then for any $\epsilon>0$, there is $\{I_n\}$ $$m^\ast E+\epsilon>\sum l(I_n)=\sum l(I_n+y)\geq m^\ast (E+y).$$ This implies that $$m^\ast E\geq m^\ast (E+y).$$ To finish the proof, I must get  $$m^\ast E\leq m^\ast (E+y),$$ by making use of $$E=(E+y)-y.$$ I am failing to figure this out.","I am trying to prove that lesbegue outer measure is translation invariant, i.e., $m^\ast (E+y)=m^\ast E$. I proceed as follows. Let $E$ be a set. Let $\{I_n\}$ be a collection of open intervals that cover E. It follows that $\{I_n+y\}$ covers $E+y$. Then for any $\epsilon>0$, there is $\{I_n\}$ $$m^\ast E+\epsilon>\sum l(I_n)=\sum l(I_n+y)\geq m^\ast (E+y).$$ This implies that $$m^\ast E\geq m^\ast (E+y).$$ To finish the proof, I must get  $$m^\ast E\leq m^\ast (E+y),$$ by making use of $$E=(E+y)-y.$$ I am failing to figure this out.",,"['real-analysis', 'measure-theory']"
41,Cardinality of the borel measurable functions?,Cardinality of the borel measurable functions?,,"Using Lebesgue measurable set which is uncountable, one can show that the cardinality of the set of all Lebesgue measurable functions is $2^\mathbb{R}$ I know that Borel $\sigma$-algebra on $\mathbb{R}$ is of cardinality $\mathbb{R}$ (even if I haven't read proof). Then how can I show that the cardinality of the set of all borel measurable functions is $\mathbb{R}$?","Using Lebesgue measurable set which is uncountable, one can show that the cardinality of the set of all Lebesgue measurable functions is $2^\mathbb{R}$ I know that Borel $\sigma$-algebra on $\mathbb{R}$ is of cardinality $\mathbb{R}$ (even if I haven't read proof). Then how can I show that the cardinality of the set of all borel measurable functions is $\mathbb{R}$?",,"['real-analysis', 'descriptive-set-theory']"
42,"If a function is continuously differentiable and bounded, is its derivative also bounded?","If a function is continuously differentiable and bounded, is its derivative also bounded?",,"Two questions: Suppose that $f:\mathbb{R}\rightarrow \mathbb{R}$ is continuously differentiable and bounded. Is its derivative $f'$ bounded as well? What about in the case of $f:\mathbb{R}^n\rightarrow \mathbb{R}^n$, where $f$ is continuously differentiable, and its total derivative $f'$? Thanks in advance.","Two questions: Suppose that $f:\mathbb{R}\rightarrow \mathbb{R}$ is continuously differentiable and bounded. Is its derivative $f'$ bounded as well? What about in the case of $f:\mathbb{R}^n\rightarrow \mathbb{R}^n$, where $f$ is continuously differentiable, and its total derivative $f'$? Thanks in advance.",,"['calculus', 'real-analysis', 'multivariable-calculus']"
43,A metric space in which every infinite set has a limit point is separable,A metric space in which every infinite set has a limit point is separable,,"I am struggling with one problem. I need to show that if $X$ is a metric space in which every infinite subset has a limit point then $X$ is separable (has countable dense subset in other words). I am trying to use the result I have proven prior to this problem, namely every separable metric space has a countable base (i.e. any open subset of the metric space can be expressed as a sub-collection of the countable collection of sets).  I am not sure this is the right way, can anyone outline the proof? Thanks a lot in advance!","I am struggling with one problem. I need to show that if $X$ is a metric space in which every infinite subset has a limit point then $X$ is separable (has countable dense subset in other words). I am trying to use the result I have proven prior to this problem, namely every separable metric space has a countable base (i.e. any open subset of the metric space can be expressed as a sub-collection of the countable collection of sets).  I am not sure this is the right way, can anyone outline the proof? Thanks a lot in advance!",,"['real-analysis', 'general-topology']"
44,Finding Taylor's series of the function: $\frac{e^{a \sin^{-1}x}}{\sqrt{1-x^2}}$,Finding Taylor's series of the function:,\frac{e^{a \sin^{-1}x}}{\sqrt{1-x^2}},"Show that $$\frac{e^{a \sin^{-1}x}}{\sqrt{1-x^2}}=1+\frac{ax}{1!}+\frac{(a^2+1^2)x^2}{2!}+\frac{a(a^2+2^2)x^3}{3!}+\frac{(a^2+1^2)(a^2+3^2)x^4}{4!}+\cdots$$ My attempt: I integrated the function and got $\frac{e^{a \sin^{-1}x}}{a}$ then I wrote the series of $e^{a \sin^{-1}x}$ but it contained terms like $(\sin^{-1}x)^2$ , $(\sin^{-1}x)^3$ and so on so I could not find the series. My idea was to find the series of the anti derivative of the function and then to derivate the obtained series. Any other way to do it?","Show that My attempt: I integrated the function and got then I wrote the series of but it contained terms like , and so on so I could not find the series. My idea was to find the series of the anti derivative of the function and then to derivate the obtained series. Any other way to do it?",\frac{e^{a \sin^{-1}x}}{\sqrt{1-x^2}}=1+\frac{ax}{1!}+\frac{(a^2+1^2)x^2}{2!}+\frac{a(a^2+2^2)x^3}{3!}+\frac{(a^2+1^2)(a^2+3^2)x^4}{4!}+\cdots \frac{e^{a \sin^{-1}x}}{a} e^{a \sin^{-1}x} (\sin^{-1}x)^2 (\sin^{-1}x)^3,"['real-analysis', 'sequences-and-series', 'power-series', 'taylor-expansion']"
45,A problem from the Shortlist of the Romanian Mathematics Olympiad,A problem from the Shortlist of the Romanian Mathematics Olympiad,,"Prove that $$\int_0^x \left(1+\frac{t}{1!}+\frac{t^2}{2!}+...+\frac{t^{2n+1}}{(2n+1)!} \right)\cdot \frac{1}{1+t^2} dt <\frac{\arctan x}{x} \int_0^x e^t dt$$ for all $x>0$ . (it is not stated in the question, but I suppose that $n$ is just a positive integer) I tried to use the fact that $e^t= \sum\limits_{k=0}^\infty \frac{t^k}{k !}$ . This gave me that $$1+\frac{t}{1!}+\frac{t^2}{2!}+...+\frac{t^{2n+1}}{(2n+1)!}< e^t, \forall t\in [0,x]$$ for some arbitrarily fixed $x$ . This lead to $$\int_0^x \left(1+\frac{t}{1!}+\frac{t^2}{2!}+...+\frac{t^{2n+1}}{(2n+1)!} \right)\cdot \frac{1}{1+t^2} dt < \int_0^x \frac{e^t}{1+t^2} dt.$$ From here I tried to apply IBP, but it doesn't seem to get closer to the required inequality.","Prove that for all . (it is not stated in the question, but I suppose that is just a positive integer) I tried to use the fact that . This gave me that for some arbitrarily fixed . This lead to From here I tried to apply IBP, but it doesn't seem to get closer to the required inequality.","\int_0^x \left(1+\frac{t}{1!}+\frac{t^2}{2!}+...+\frac{t^{2n+1}}{(2n+1)!} \right)\cdot \frac{1}{1+t^2} dt <\frac{\arctan x}{x} \int_0^x e^t dt x>0 n e^t= \sum\limits_{k=0}^\infty \frac{t^k}{k !} 1+\frac{t}{1!}+\frac{t^2}{2!}+...+\frac{t^{2n+1}}{(2n+1)!}< e^t, \forall t\in [0,x] x \int_0^x \left(1+\frac{t}{1!}+\frac{t^2}{2!}+...+\frac{t^{2n+1}}{(2n+1)!} \right)\cdot \frac{1}{1+t^2} dt < \int_0^x \frac{e^t}{1+t^2} dt.","['real-analysis', 'inequality', 'definite-integrals', 'contest-math', 'integral-inequality']"
46,How does changing metrics help to find solutions to a partial differential equation?,How does changing metrics help to find solutions to a partial differential equation?,,"I am taking a course in functional analysis and while reviewing the definition of a metric and various examples, my professor mentioned that one of the reason we care about swapping (possibly equivalent?) metrics is in pde, since a solution to a pde may be very difficult to find in one metric space, but easier in another. I was hoping the mathstack exchange community might be able to expand on this and maybe provide me with some examples hopefully that I can understand. Thanks!","I am taking a course in functional analysis and while reviewing the definition of a metric and various examples, my professor mentioned that one of the reason we care about swapping (possibly equivalent?) metrics is in pde, since a solution to a pde may be very difficult to find in one metric space, but easier in another. I was hoping the mathstack exchange community might be able to expand on this and maybe provide me with some examples hopefully that I can understand. Thanks!",,"['real-analysis', 'functional-analysis', 'partial-differential-equations', 'metric-spaces']"
47,Does there exist a function such that $\lim_{x \to a} f(x) = L$ for all $a \in \mathbb R$ but $f(x)$ is never $L$?,Does there exist a function such that  for all  but  is never ?,\lim_{x \to a} f(x) = L a \in \mathbb R f(x) L,"Does there exist a function $f:\mathbb R \to \mathbb R$ such that $\lim_{x \to a} f(x) = L$ for   all $a \in \mathbb R$ but $f(x) \neq L$ for all $x$? I found such a function in $\mathbb Q \to \mathbb Q$, where $f(\frac{p}{q})= \text{first p+q digits of }\pi$ satisfies the above condition. However, I have not been able to extend it to reals. So, is such a function possible, and if it is, is there any explicit example preferably related to the above function in rationals?","Does there exist a function $f:\mathbb R \to \mathbb R$ such that $\lim_{x \to a} f(x) = L$ for   all $a \in \mathbb R$ but $f(x) \neq L$ for all $x$? I found such a function in $\mathbb Q \to \mathbb Q$, where $f(\frac{p}{q})= \text{first p+q digits of }\pi$ satisfies the above condition. However, I have not been able to extend it to reals. So, is such a function possible, and if it is, is there any explicit example preferably related to the above function in rationals?",,"['calculus', 'real-analysis', 'limits']"
48,Is it always true that $\mathrm{int}(\ A \setminus \mathrm{int}(A)\ ) = \emptyset$?,Is it always true that ?,\mathrm{int}(\ A \setminus \mathrm{int}(A)\ ) = \emptyset,"Let $(X,d)$ be any arbitrary metric space? Let $A$ be some subset of $X$. Is it always true that $\mathrm{int}(\ A \setminus \mathrm{int}(A)\ ) = \emptyset$? I believe that this statement is false, and that for some wonky situation the above will not hold. I thought about letting $X=\mathbb{R}^{2}$ and letting $d$ be defined by $d(x,y)=\|x-y\|$ (Euclidean one). Then maybe taking $A$ to be some disconnected set? Like $A = B\big((0,0), 1\big)\cup \{ (21,9) \}$. Then I find that: $\mathrm{int}(A)=B\big((0,0), 1\big)$ $A \setminus \mathrm{int}(A) = A \setminus B\big((0,0), 1\big) = \{ (21,9) \}$ $\mathrm{int}(\ A \setminus \mathrm{int}(A)\ ) = \mathrm{int}(\ \{ (21,9) \}\ ) = \emptyset$ So my exmaple doesn't work unfortunately, but maybe it will work if I take $d$ to be the discrete distance or something like that? Can somebody give me a hint?","Let $(X,d)$ be any arbitrary metric space? Let $A$ be some subset of $X$. Is it always true that $\mathrm{int}(\ A \setminus \mathrm{int}(A)\ ) = \emptyset$? I believe that this statement is false, and that for some wonky situation the above will not hold. I thought about letting $X=\mathbb{R}^{2}$ and letting $d$ be defined by $d(x,y)=\|x-y\|$ (Euclidean one). Then maybe taking $A$ to be some disconnected set? Like $A = B\big((0,0), 1\big)\cup \{ (21,9) \}$. Then I find that: $\mathrm{int}(A)=B\big((0,0), 1\big)$ $A \setminus \mathrm{int}(A) = A \setminus B\big((0,0), 1\big) = \{ (21,9) \}$ $\mathrm{int}(\ A \setminus \mathrm{int}(A)\ ) = \mathrm{int}(\ \{ (21,9) \}\ ) = \emptyset$ So my exmaple doesn't work unfortunately, but maybe it will work if I take $d$ to be the discrete distance or something like that? Can somebody give me a hint?",,"['real-analysis', 'general-topology']"
49,"Can we find uncountably many disjoint dense measurable uncountable subsets of $[0,1]$?",Can we find uncountably many disjoint dense measurable uncountable subsets of ?,"[0,1]","Can we find uncountably many disjoint dense measurable uncountable subsets of $[0,1]$? Obviously we may as well assume all the subsets have measure $0$. If I didn't specify the subsets were uncountable, we could easily find uncountably many dense disjoint measurable subsets $X_\alpha$ (all countable) by taking a Hamel basis $H$ of $\mathbb{R}$ as a vector space over $\mathbb{Q}$, where $H$ contains a non-zero rational number, and then set $X_\alpha = (\mathbb{Q} + \alpha) \cap [0,1]$ for every $\alpha \in H$. But what about if we want uncountable measurable dense subsets? I think it should still be that there are uncountably many that can be found that are disjoint, according to my intuition, but I don't know an ""easy"" way to show it like I can in the case of countable dense subsets.","Can we find uncountably many disjoint dense measurable uncountable subsets of $[0,1]$? Obviously we may as well assume all the subsets have measure $0$. If I didn't specify the subsets were uncountable, we could easily find uncountably many dense disjoint measurable subsets $X_\alpha$ (all countable) by taking a Hamel basis $H$ of $\mathbb{R}$ as a vector space over $\mathbb{Q}$, where $H$ contains a non-zero rational number, and then set $X_\alpha = (\mathbb{Q} + \alpha) \cap [0,1]$ for every $\alpha \in H$. But what about if we want uncountable measurable dense subsets? I think it should still be that there are uncountably many that can be found that are disjoint, according to my intuition, but I don't know an ""easy"" way to show it like I can in the case of countable dense subsets.",,"['real-analysis', 'lebesgue-measure']"
50,Infinite Integral of Trigonometric Functions,Infinite Integral of Trigonometric Functions,,"I am interested in finding the Integral: $I = \int\limits_{0}^{\infty} \sin x \,dx$. Clearly going the conventional way $I = -\cos (\infty) + \cos(0)$ will not lead to a definite answer. However I have thought of the problem in a different way.  First, we already know from Fourier Transform that $ \int\limits_{-\infty}^{\infty}\exp \left(i \omega t\right) \, dt = 2 \pi \delta\left(\omega \right) $. Thus , upon setting $\omega = 1$, we have $ \int\limits_{-\infty}^{\infty}\cos \left(t\right) \, dt = 0$. But knowing that $\cos(t)$ is even in $t$ thus, $ 0 = \int\limits_{-\infty}^{\infty}\cos \left(t\right) \, dt = 2 \int\limits_{0}^{\infty}\cos \left(t\right) \, dt \Rightarrow \int\limits_{0}^{\infty}\cos \left(t\right) \, dt = 0$. Now consider the transformation $u = t + \frac{\pi}{2}$, we thus have $0 = \int\limits_{\frac{\pi}{2}}^{\infty}\cos \left(u - \frac{\pi}{2}\right) \, du = \int\limits_{\frac{\pi}{2}}^{\infty}\sin \left(u \right) \, du = \int\limits_{\frac{\pi}{2}}^{0}\sin \left(u \right) \, du + \int\limits_{0}^{\infty}\sin \left(u \right) \, du = \int\limits_{0}^{\infty}\sin \left(u \right) \, du -1 \Rightarrow \int\limits_{0}^{\infty}\sin \left(u \right) \, du = 1$. This solution is even sustained by the Laplace Transform results where we have $\mathcal{L} \lbrace \sin\left( t\right)\rbrace = \dfrac{1}{s^2 + 1}$. But $\mathcal{L} \lbrace \sin\left( t\right)\rbrace = \int\limits_{0}^{\infty}\exp \left(-st \right) \sin \left(t \right) \, dt $ Thus $\int\limits_{0}^{\infty}\sin \left(t \right) \, dt = \lim\limits_{s \rightarrow 0} \int\limits_{0}^{\infty}\exp \left(-st \right) \sin \left(t \right) \, dt = \lim\limits_{s \rightarrow 0}\dfrac{1}{s^2 + 1} = 1$. Hence $\int\limits_{0}^{\infty}\sin \left(t \right) \, dt = 1$. I am here getting exactly the same result for the integral by computing it in two different methods. Is my work correct? I definitely know that $\sin$ is not Reimann-integrable over the interval $[0,\infty)$. Is there a special name for this integral, or its evaluation in this method? Thanks very much for your suggestions!","I am interested in finding the Integral: $I = \int\limits_{0}^{\infty} \sin x \,dx$. Clearly going the conventional way $I = -\cos (\infty) + \cos(0)$ will not lead to a definite answer. However I have thought of the problem in a different way.  First, we already know from Fourier Transform that $ \int\limits_{-\infty}^{\infty}\exp \left(i \omega t\right) \, dt = 2 \pi \delta\left(\omega \right) $. Thus , upon setting $\omega = 1$, we have $ \int\limits_{-\infty}^{\infty}\cos \left(t\right) \, dt = 0$. But knowing that $\cos(t)$ is even in $t$ thus, $ 0 = \int\limits_{-\infty}^{\infty}\cos \left(t\right) \, dt = 2 \int\limits_{0}^{\infty}\cos \left(t\right) \, dt \Rightarrow \int\limits_{0}^{\infty}\cos \left(t\right) \, dt = 0$. Now consider the transformation $u = t + \frac{\pi}{2}$, we thus have $0 = \int\limits_{\frac{\pi}{2}}^{\infty}\cos \left(u - \frac{\pi}{2}\right) \, du = \int\limits_{\frac{\pi}{2}}^{\infty}\sin \left(u \right) \, du = \int\limits_{\frac{\pi}{2}}^{0}\sin \left(u \right) \, du + \int\limits_{0}^{\infty}\sin \left(u \right) \, du = \int\limits_{0}^{\infty}\sin \left(u \right) \, du -1 \Rightarrow \int\limits_{0}^{\infty}\sin \left(u \right) \, du = 1$. This solution is even sustained by the Laplace Transform results where we have $\mathcal{L} \lbrace \sin\left( t\right)\rbrace = \dfrac{1}{s^2 + 1}$. But $\mathcal{L} \lbrace \sin\left( t\right)\rbrace = \int\limits_{0}^{\infty}\exp \left(-st \right) \sin \left(t \right) \, dt $ Thus $\int\limits_{0}^{\infty}\sin \left(t \right) \, dt = \lim\limits_{s \rightarrow 0} \int\limits_{0}^{\infty}\exp \left(-st \right) \sin \left(t \right) \, dt = \lim\limits_{s \rightarrow 0}\dfrac{1}{s^2 + 1} = 1$. Hence $\int\limits_{0}^{\infty}\sin \left(t \right) \, dt = 1$. I am here getting exactly the same result for the integral by computing it in two different methods. Is my work correct? I definitely know that $\sin$ is not Reimann-integrable over the interval $[0,\infty)$. Is there a special name for this integral, or its evaluation in this method? Thanks very much for your suggestions!",,"['real-analysis', 'integration']"
51,"Proving that $\sum_{(m,n)\in \Bbb Z \times \Bbb Z}\frac{1}{m^2+n^2+1}$ diverges.",Proving that  diverges.,"\sum_{(m,n)\in \Bbb Z \times \Bbb Z}\frac{1}{m^2+n^2+1}","I must prove that $$\sum_{(m,n)\in \Bbb Z \times \Bbb Z}\frac{1}{m^2+n^2+1}$$ diverges. I understand that given $K > 0$, I must find a finite subset of $\Bbb Z \times \Bbb Z$, say, $F$, such that $\sum_{(m,n)\in F}\frac{1}{m^2+n^2+1} > K$. I know that I can't be lazy and just walk in diagonals, because $\sum 1/(2n^2+1) < +\infty$. Call $Q_n = ([-n,n]\times[-n,n])\cap (\Bbb Z \times \Bbb Z)$. Sure, $Q_n$ is finite for all $n$. Given $K > 0$, I want to find $n$ such that the sum over $Q_n$ goes over $K$. I can't think of a better choice of finite set to compute the sum over: I'm going in all directions, certainly it should blow up. For example, $Q_2$: Using and abusing of symmetry, I got so far (hopefully correct): $$ \sum_{(a,b)\in Q_n}\frac{1}{a^2+b^2+1} = 1+4\sum_{i=1}^n\frac{1}{i^2+1} +4\sum_{i=1}^n\frac{1}{2i^2+1} +8\sum_{1\leq i<j\leq n}\frac{1}{i^2+j^2+1}.$$ Needless to say, this is too complicated of an expression for me to find $n = n(K)$ to do the job - I don't know even how to find closed expressions for each term above. Maybe using $Q_n$ is overkill, and we can find a smaller set to compute the sum over. Hints, ideas, a magic solution? Thanks!","I must prove that $$\sum_{(m,n)\in \Bbb Z \times \Bbb Z}\frac{1}{m^2+n^2+1}$$ diverges. I understand that given $K > 0$, I must find a finite subset of $\Bbb Z \times \Bbb Z$, say, $F$, such that $\sum_{(m,n)\in F}\frac{1}{m^2+n^2+1} > K$. I know that I can't be lazy and just walk in diagonals, because $\sum 1/(2n^2+1) < +\infty$. Call $Q_n = ([-n,n]\times[-n,n])\cap (\Bbb Z \times \Bbb Z)$. Sure, $Q_n$ is finite for all $n$. Given $K > 0$, I want to find $n$ such that the sum over $Q_n$ goes over $K$. I can't think of a better choice of finite set to compute the sum over: I'm going in all directions, certainly it should blow up. For example, $Q_2$: Using and abusing of symmetry, I got so far (hopefully correct): $$ \sum_{(a,b)\in Q_n}\frac{1}{a^2+b^2+1} = 1+4\sum_{i=1}^n\frac{1}{i^2+1} +4\sum_{i=1}^n\frac{1}{2i^2+1} +8\sum_{1\leq i<j\leq n}\frac{1}{i^2+j^2+1}.$$ Needless to say, this is too complicated of an expression for me to find $n = n(K)$ to do the job - I don't know even how to find closed expressions for each term above. Maybe using $Q_n$ is overkill, and we can find a smaller set to compute the sum over. Hints, ideas, a magic solution? Thanks!",,"['real-analysis', 'sequences-and-series']"
52,The negation of an implication.,The negation of an implication.,,I have the following statement and I'm not sure what the negation is. The statement is: If $F:\mathbb{R}\to\mathbb{R}$ is a function satisfying some regularity assumptions $(R1)$ then we have $$\lim_{x\to\infty}F(x)\ge 0.$$ I think the negation should be: If $F:\mathbb{R}\to\mathbb{R}$ is a function satisfying some regularity assumptions $(R1)$ then we have $$\lim_{x\to\infty}F(x)< 0.$$ Is this correct?,I have the following statement and I'm not sure what the negation is. The statement is: If $F:\mathbb{R}\to\mathbb{R}$ is a function satisfying some regularity assumptions $(R1)$ then we have $$\lim_{x\to\infty}F(x)\ge 0.$$ I think the negation should be: If $F:\mathbb{R}\to\mathbb{R}$ is a function satisfying some regularity assumptions $(R1)$ then we have $$\lim_{x\to\infty}F(x)< 0.$$ Is this correct?,,['real-analysis']
53,Continuity of a convex function,Continuity of a convex function,,"I'm trying to solve the following problem: Let $f:K\rightarrow \mathbb{R} $, $f$ convex and $K \subseteq \mathbb{R}^n$ convex. Then $f$ is continuous on $K$. I have proved the only case $n=1$, but for an arbitrary $n$??","I'm trying to solve the following problem: Let $f:K\rightarrow \mathbb{R} $, $f$ convex and $K \subseteq \mathbb{R}^n$ convex. Then $f$ is continuous on $K$. I have proved the only case $n=1$, but for an arbitrary $n$??",,"['real-analysis', 'convex-analysis', 'continuity']"
54,A problem about Riemann-Lebesgue lemma,A problem about Riemann-Lebesgue lemma,,"Let $f$ be an integrable function over $[a,b]$. Prove that: $$\lim_{n \rightarrow \infty } \int _a ^b f(x)|\sin(nx)| dx= \frac {2}{\pi} \int _a^b f(x) dx.$$","Let $f$ be an integrable function over $[a,b]$. Prove that: $$\lim_{n \rightarrow \infty } \int _a ^b f(x)|\sin(nx)| dx= \frac {2}{\pi} \int _a^b f(x) dx.$$",,"['real-analysis', 'integration', 'limits']"
55,Proving that the given two integrals are equal,Proving that the given two integrals are equal,,"I am stuck up with this simple problem. If $\alpha \cdot \beta = \pi$, then show that $$\sqrt{\alpha}\int\limits_{0}^{\infty} \frac{e^{-x^{2}}}{\cosh{\alpha{x}}} \ \textrm{dx} = \sqrt{\beta} \int\limits_{0}^{\infty} \frac{e^{-x^{2}}}{\cosh{\beta{x}}} \ \textrm{dx}$$ I tried replacing $\cosh{x} = \frac{e^{x}+e^{-x}}{2}$ and tried doing some manipulations, but it's of no use. Seems to be a clever problem. Moreover since we have $\alpha \cdot \beta = \pi$, we get $\sqrt{\alpha} = \frac{\sqrt{\pi}}{\sqrt{\beta}}$, but the Beta factor is in the numerator, which bewilders me.","I am stuck up with this simple problem. If $\alpha \cdot \beta = \pi$, then show that $$\sqrt{\alpha}\int\limits_{0}^{\infty} \frac{e^{-x^{2}}}{\cosh{\alpha{x}}} \ \textrm{dx} = \sqrt{\beta} \int\limits_{0}^{\infty} \frac{e^{-x^{2}}}{\cosh{\beta{x}}} \ \textrm{dx}$$ I tried replacing $\cosh{x} = \frac{e^{x}+e^{-x}}{2}$ and tried doing some manipulations, but it's of no use. Seems to be a clever problem. Moreover since we have $\alpha \cdot \beta = \pi$, we get $\sqrt{\alpha} = \frac{\sqrt{\pi}}{\sqrt{\beta}}$, but the Beta factor is in the numerator, which bewilders me.",,"['calculus', 'real-analysis']"
56,Rationality of series $\sum \frac{1}{n!}$,Rationality of series,\sum \frac{1}{n!},"There is a famous literature on $\displaystyle e = \sum\limits_{n=0}^{\infty} \frac{1}{n!}$. We know that $e$ is irrational as well as transcendental. Question is: For each  $x_{n}$, sequence of $\pm{1}'s$, let $$f(x_{n}) = \sum\limits_{n=0}^{\infty} \frac{x_{n}}{n!}$$ for which sequences $(x_n)$ is $f(x_{n})$ rational? Also can we write $e$ as $\displaystyle e = \sum\limits_{n=1}^{\infty} \frac{x_{n}}{n}$ where $x_{n}$ is a sequence as above.","There is a famous literature on $\displaystyle e = \sum\limits_{n=0}^{\infty} \frac{1}{n!}$. We know that $e$ is irrational as well as transcendental. Question is: For each  $x_{n}$, sequence of $\pm{1}'s$, let $$f(x_{n}) = \sum\limits_{n=0}^{\infty} \frac{x_{n}}{n!}$$ for which sequences $(x_n)$ is $f(x_{n})$ rational? Also can we write $e$ as $\displaystyle e = \sum\limits_{n=1}^{\infty} \frac{x_{n}}{n}$ where $x_{n}$ is a sequence as above.",,['real-analysis']
57,"Find if $\sum\limits_{n=1}^{\infty} a^{1+\frac1{2}+\frac1{3}+\dots+\frac1{n}}$, $a > 0$ converges or not.","Find if ,  converges or not.",\sum\limits_{n=1}^{\infty} a^{1+\frac1{2}+\frac1{3}+\dots+\frac1{n}} a > 0,"Find if $\sum\limits_{n=1}^{\infty} a^{1+\frac1{2}+\frac1{3}+\dots+\frac1{n}}$ , $a >0$ converges or not. I used d'Alembert's criterion and I found $\lim_{n\to \infty} \frac{x_n}{x_{n+1}}=1$ Moving to Raabe–Duhamel's test, I found $$\lim_{n\to \infty} n(\frac{x_n}{x_{n+1}} -1) =  \lim_{n\to \infty} n(\frac{1}{\sqrt[n+1]{a}} - 1) $$ What can I do from there? Or is there a better way to find if $\sum\limits_{n=1}^{\infty} a^{1+\frac1{2}+\frac1{3}+\dots+\frac1{n}}$ , $a >0$ converges or not?","Find if , converges or not. I used d'Alembert's criterion and I found Moving to Raabe–Duhamel's test, I found What can I do from there? Or is there a better way to find if , converges or not?",\sum\limits_{n=1}^{\infty} a^{1+\frac1{2}+\frac1{3}+\dots+\frac1{n}} a >0 \lim_{n\to \infty} \frac{x_n}{x_{n+1}}=1 \lim_{n\to \infty} n(\frac{x_n}{x_{n+1}} -1) =  \lim_{n\to \infty} n(\frac{1}{\sqrt[n+1]{a}} - 1)  \sum\limits_{n=1}^{\infty} a^{1+\frac1{2}+\frac1{3}+\dots+\frac1{n}} a >0,"['real-analysis', 'sequences-and-series', 'convergence-divergence']"
58,If $L^1$ average of $f$ is smaller than $t^2$ then $f=0$ a.e.,If  average of  is smaller than  then  a.e.,L^1 f t^2 f=0,"Suppose $f\in L^1(\mathbb R)$ and there exits $\delta>0$ such that $$\|f(\cdot + t)-f\|_{L^1}\leq |t|^2$$ for all $|t|\leq \delta$ , where $f(\cdot + t)$ is the function $x\mapsto f(x+t)$ . Show that $f=0$ a.e. It is well known that $\lim_{t\to 0}\|f(\cdot+t)-f\|_{L^1}=0$ but this fact can't help here. Intuitively, the condition in the problem would deduce that $\int |f'|=0$ if the derivative is good enough so the conclusion must be right and $|t|^2$ can be improved to $|t|^{1+\epsilon}$ . I also tried to use the separability of $L^1$ , like when we prove the famous fact mentioned above, but it helps nothing. Any hints and thoughts are welcomed.","Suppose and there exits such that for all , where is the function . Show that a.e. It is well known that but this fact can't help here. Intuitively, the condition in the problem would deduce that if the derivative is good enough so the conclusion must be right and can be improved to . I also tried to use the separability of , like when we prove the famous fact mentioned above, but it helps nothing. Any hints and thoughts are welcomed.",f\in L^1(\mathbb R) \delta>0 \|f(\cdot + t)-f\|_{L^1}\leq |t|^2 |t|\leq \delta f(\cdot + t) x\mapsto f(x+t) f=0 \lim_{t\to 0}\|f(\cdot+t)-f\|_{L^1}=0 \int |f'|=0 |t|^2 |t|^{1+\epsilon} L^1,['real-analysis']
59,"Find $a$ and $b$ for which $\int_{0}^{1}( ax+b+\frac{1}{1+x^{2}} )^{2}\,dx$ takes its minimum possible value.",Find  and  for which  takes its minimum possible value.,"a b \int_{0}^{1}( ax+b+\frac{1}{1+x^{2}} )^{2}\,dx","Calculate for which values $a$ and $b$ the integral $$\int_{0}^{1} \left( ax+b+\frac{1}{1+x^{2}} \right)^{2}\,dx$$ takes its minimum  possible value? For being honest I'm not sure how to try this, but my idea is to calculate its derivative using fundamental calculus theorem as $\left(ax+b+\frac{1}{1+x^{2}} \right)^{2}$ is a continuous function over $[0,1]$ . And then, evaluate the integral over $0,1$ and the values where the derivative we calculate is zero and find which $a$ and $b$ does the work. Sorry but this is the first problem of this type I'm trying. Thanks","Calculate for which values and the integral takes its minimum  possible value? For being honest I'm not sure how to try this, but my idea is to calculate its derivative using fundamental calculus theorem as is a continuous function over . And then, evaluate the integral over and the values where the derivative we calculate is zero and find which and does the work. Sorry but this is the first problem of this type I'm trying. Thanks","a b \int_{0}^{1} \left( ax+b+\frac{1}{1+x^{2}} \right)^{2}\,dx \left(ax+b+\frac{1}{1+x^{2}} \right)^{2} [0,1] 0,1 a b","['real-analysis', 'calculus', 'integration', 'multivariable-calculus', 'optimization']"
60,Prove that $\int_0^\infty \frac{e^{\cos(ax)}\cos\left(\sin (ax)+bx\right)}{c^2+x^2}dx =\frac{\pi}{2c}\exp\left(e^{-ac}-bc\right)$,Prove that,\int_0^\infty \frac{e^{\cos(ax)}\cos\left(\sin (ax)+bx\right)}{c^2+x^2}dx =\frac{\pi}{2c}\exp\left(e^{-ac}-bc\right),"In my course, I have to prove formula below $$I=\int_0^\infty \frac{e^{\cos(ax)}\cos\left(\sin (ax)+bx\right)}{c^2+x^2}dx =\frac{\pi}{2c}\exp\left(e^{-ac}-bc\right)$$ for $a,b,c>0.$ I know that this integral can be easily solved with complex analysis using $$f(z)=\frac{1}{2} \ \mathbb{R} \left(\int_{-\infty}^\infty \frac{\exp\left(e^{iaz}+ibz\right)}{c^2+z^2}dz\right)$$ but right now I am in a course dealing with real analysis. I tried to use parametrization integral method $$I'(a)=-\int_0^\infty \frac{xe^{\cos(ax)}\sin(\sin(ax)+(a+b)x)}{c^2+x^2}dx $$ but it doesn't look easier to handle. I tried to differentiate it again, but I just got a horrible form. An idea came to mind to differentiate with respect to parameter $b$ and set a differential equation $$I''(b)+x^2I(b)=0$$ plugging this ODE to W|A, I got $$I(b)=c_1\cos(bx^2)+c_2\sin(bx^2)$$ It's definitely wrong! After seeing Samrat's answer, I tried to plug in again to W|A and I got $$I(b)=c_1 D_{-1/2}((i+1)b)+c_2 D_{-1/2}((i-1)b)$$ where $D_n(z)$ is the parabolic cylinder function but I have no idea what does that mean. Any idea? Thanks in advance.","In my course, I have to prove formula below $$I=\int_0^\infty \frac{e^{\cos(ax)}\cos\left(\sin (ax)+bx\right)}{c^2+x^2}dx =\frac{\pi}{2c}\exp\left(e^{-ac}-bc\right)$$ for $a,b,c>0.$ I know that this integral can be easily solved with complex analysis using $$f(z)=\frac{1}{2} \ \mathbb{R} \left(\int_{-\infty}^\infty \frac{\exp\left(e^{iaz}+ibz\right)}{c^2+z^2}dz\right)$$ but right now I am in a course dealing with real analysis. I tried to use parametrization integral method $$I'(a)=-\int_0^\infty \frac{xe^{\cos(ax)}\sin(\sin(ax)+(a+b)x)}{c^2+x^2}dx $$ but it doesn't look easier to handle. I tried to differentiate it again, but I just got a horrible form. An idea came to mind to differentiate with respect to parameter $b$ and set a differential equation $$I''(b)+x^2I(b)=0$$ plugging this ODE to W|A, I got $$I(b)=c_1\cos(bx^2)+c_2\sin(bx^2)$$ It's definitely wrong! After seeing Samrat's answer, I tried to plug in again to W|A and I got $$I(b)=c_1 D_{-1/2}((i+1)b)+c_2 D_{-1/2}((i-1)b)$$ where $D_n(z)$ is the parabolic cylinder function but I have no idea what does that mean. Any idea? Thanks in advance.",,"['calculus', 'real-analysis', 'integration', 'definite-integrals', 'improper-integrals']"
61,"Convergence of ""alternating"" harmonic series where sign is +, --, +++, ----, etc.","Convergence of ""alternating"" harmonic series where sign is +, --, +++, ----, etc.",,"Exercise 11 from section 9.3 of Introduction to Real Analysis (Bartle): Can Dirichlet’s Test be applied to establish the convergence of   $$ 1 - \dfrac12 - \dfrac13 + \dfrac14 + \dfrac15 + \dfrac16 - \cdots $$   $\qquad \qquad$    where the number of signs increases by one in each ‘‘block’’? If not, use another method to    establish the convergence of this series. Dirichlet's test cannot be used because the partial sums generated by (1, -1, -1, 1, 1, 1, ...) are not bounded. But we can group the terms of the series in the following way: $$ 1 - \left(\dfrac12 + \dfrac13\right) + \left(\dfrac14 + \dfrac15 + \dfrac16\right) - \left( \dfrac17 + \dfrac18 + \dfrac19 + \dfrac{1}{10} \right) + \cdots \\ = \sum _{n=1}^{\infty}(-1)^{n+1}a_n $$ where $$ (a_n) = \left(1, \left(\dfrac12 + \dfrac13\right), \left(\dfrac14 + \dfrac15 + \dfrac16\right), ... \right) $$ So by Leibniz's test, if the sequence $(a_n)$ is decreasing and $\lim{a_n} = 0$ then the grouped series is convergent. I've shown that since we are grouping terms of the same sign it is sufficient to show the convergence of the grouped series. I've shown that $\lim{a_n} = 0$, but how do I show that $(a_n)$ is decreasing?","Exercise 11 from section 9.3 of Introduction to Real Analysis (Bartle): Can Dirichlet’s Test be applied to establish the convergence of   $$ 1 - \dfrac12 - \dfrac13 + \dfrac14 + \dfrac15 + \dfrac16 - \cdots $$   $\qquad \qquad$    where the number of signs increases by one in each ‘‘block’’? If not, use another method to    establish the convergence of this series. Dirichlet's test cannot be used because the partial sums generated by (1, -1, -1, 1, 1, 1, ...) are not bounded. But we can group the terms of the series in the following way: $$ 1 - \left(\dfrac12 + \dfrac13\right) + \left(\dfrac14 + \dfrac15 + \dfrac16\right) - \left( \dfrac17 + \dfrac18 + \dfrac19 + \dfrac{1}{10} \right) + \cdots \\ = \sum _{n=1}^{\infty}(-1)^{n+1}a_n $$ where $$ (a_n) = \left(1, \left(\dfrac12 + \dfrac13\right), \left(\dfrac14 + \dfrac15 + \dfrac16\right), ... \right) $$ So by Leibniz's test, if the sequence $(a_n)$ is decreasing and $\lim{a_n} = 0$ then the grouped series is convergent. I've shown that since we are grouping terms of the same sign it is sufficient to show the convergence of the grouped series. I've shown that $\lim{a_n} = 0$, but how do I show that $(a_n)$ is decreasing?",,"['real-analysis', 'sequences-and-series']"
62,Motivation of Weierstrass-approximation Theorem?,Motivation of Weierstrass-approximation Theorem?,,"Weierstrass Theorem (Classical): If $f$ is a continuous real or complex function on $[a,b]$ , there exists a sequence of polynomials $P_n$ such thay $\lim_{n\to \infty} P_n(x)=f(x)$ . The proof i know (using Berstein Polynomials) is easy but really artificial. I don't see any motivation and how and where ideas come in. What are motivations for this proof? And is weierstrass' original proof not constructive?","Weierstrass Theorem (Classical): If is a continuous real or complex function on , there exists a sequence of polynomials such thay . The proof i know (using Berstein Polynomials) is easy but really artificial. I don't see any motivation and how and where ideas come in. What are motivations for this proof? And is weierstrass' original proof not constructive?","f [a,b] P_n \lim_{n\to \infty} P_n(x)=f(x)",['real-analysis']
63,Is there a mean value theorem for higher order differences?,Is there a mean value theorem for higher order differences?,,"The standard mean value theorem tells us $\frac{f(x+h)-f(x)}{h} = f'(c)$ for some $c$ between $x$ and $x+h$. Rewriting this, we may see it as $\frac 1h\Delta_h f(x) = f'(c)$. This makes me wonder if there is a similar formula for higher order differences. Here $$\Delta_h f(x) =f(x+h)-f(x)$$ Can I say something like $$\frac{1}{h^n}\Delta_h^nf(x) = f^{(n)}(c)$$ for some $c$ between $x$ and $x+nh$?","The standard mean value theorem tells us $\frac{f(x+h)-f(x)}{h} = f'(c)$ for some $c$ between $x$ and $x+h$. Rewriting this, we may see it as $\frac 1h\Delta_h f(x) = f'(c)$. This makes me wonder if there is a similar formula for higher order differences. Here $$\Delta_h f(x) =f(x+h)-f(x)$$ Can I say something like $$\frac{1}{h^n}\Delta_h^nf(x) = f^{(n)}(c)$$ for some $c$ between $x$ and $x+nh$?",,"['real-analysis', 'numerical-methods', 'finite-differences']"
64,"Characterization properties of number sets $\mathbb{N},\mathbb{ Z},\mathbb{Q},\mathbb{R},\mathbb{C}$",Characterization properties of number sets,"\mathbb{N},\mathbb{ Z},\mathbb{Q},\mathbb{R},\mathbb{C}","When people say that a structure is defined up to isomorphism means, accordingly, that they assume certain properties that make it completely determined under certain operations and relations. So, I'd like to know what the properties are that characterize the different systems of numbers ($\mathbb{N},\mathbb{Z},\mathbb{Q},\mathbb{R},\mathbb{C}$) up to isomorphism with the operations of $+,\cdot$, and $\leq$. To make my question clearer, for example I  guess the principle of induction would be part of characterizing $\mathbb{N}$, the least upper bound property would be part of characterizing $\mathbb{R}$, etc. The thing is that there are a lot of properties like these and it's not clear, at least for me, to decide what are the main ones and what of them can be deduced and are redundant, etc. In other words I'd like to ask which properties characterize each of the sets $\mathbb{N},\mathbb{ Z},\mathbb{Q},\mathbb{R},\mathbb{C}$ based on their operations and orderings.","When people say that a structure is defined up to isomorphism means, accordingly, that they assume certain properties that make it completely determined under certain operations and relations. So, I'd like to know what the properties are that characterize the different systems of numbers ($\mathbb{N},\mathbb{Z},\mathbb{Q},\mathbb{R},\mathbb{C}$) up to isomorphism with the operations of $+,\cdot$, and $\leq$. To make my question clearer, for example I  guess the principle of induction would be part of characterizing $\mathbb{N}$, the least upper bound property would be part of characterizing $\mathbb{R}$, etc. The thing is that there are a lot of properties like these and it's not clear, at least for me, to decide what are the main ones and what of them can be deduced and are redundant, etc. In other words I'd like to ask which properties characterize each of the sets $\mathbb{N},\mathbb{ Z},\mathbb{Q},\mathbb{R},\mathbb{C}$ based on their operations and orderings.",,"['real-analysis', 'abstract-algebra', 'elementary-set-theory']"
65,Proof That $\mathbb{R} \setminus \mathbb{Q}$ Is Not an $F_{\sigma}$ Set,Proof That  Is Not an  Set,\mathbb{R} \setminus \mathbb{Q} F_{\sigma},"I am trying to prove that the set of irrational numbers $\mathbb{R} \setminus \mathbb{Q}$ is not an $F_{\sigma}$ set. Here's my attempt: Assume that indeed $\mathbb{R} \setminus \mathbb{Q}$ is an $F_{\sigma}$ set. Then we may write it as a countable union of closed subsets $C_i$: $$ \mathbb{R} \setminus \mathbb{Q} = \bigcup_{i=1}^{\infty}  \ C_i $$ But $\text{int} ( \mathbb{R} \setminus \mathbb{Q}) = \emptyset$, so in fact each $C_i$ has empty interior as well. But then each $C_i$ is nowhere dense, hence $ \mathbb{R} \setminus \mathbb{Q} = \bigcup_{i=1}^{\infty}  \ C_i$ is thin. But we know $\mathbb{R} \setminus \mathbb{Q}$ is thick, a contradiction. This seems a bit too simple. I looked this up online, and although I haven't found the solution anywhere, many times there is a hint: Use Baire's Theorem. Have I skipped an important step I should explain further or is Baire's Theorem used implicitly in my proof? Or is my proof wrong? Thanks. EDIT: Thin and thick might not be the most standard terms so: Thin = meager = 1st Baire category","I am trying to prove that the set of irrational numbers $\mathbb{R} \setminus \mathbb{Q}$ is not an $F_{\sigma}$ set. Here's my attempt: Assume that indeed $\mathbb{R} \setminus \mathbb{Q}$ is an $F_{\sigma}$ set. Then we may write it as a countable union of closed subsets $C_i$: $$ \mathbb{R} \setminus \mathbb{Q} = \bigcup_{i=1}^{\infty}  \ C_i $$ But $\text{int} ( \mathbb{R} \setminus \mathbb{Q}) = \emptyset$, so in fact each $C_i$ has empty interior as well. But then each $C_i$ is nowhere dense, hence $ \mathbb{R} \setminus \mathbb{Q} = \bigcup_{i=1}^{\infty}  \ C_i$ is thin. But we know $\mathbb{R} \setminus \mathbb{Q}$ is thick, a contradiction. This seems a bit too simple. I looked this up online, and although I haven't found the solution anywhere, many times there is a hint: Use Baire's Theorem. Have I skipped an important step I should explain further or is Baire's Theorem used implicitly in my proof? Or is my proof wrong? Thanks. EDIT: Thin and thick might not be the most standard terms so: Thin = meager = 1st Baire category",,"['real-analysis', 'baire-category']"
66,Example of Hausdorff space $X$ s.t. $C_b(X)$ does not separate points?,Example of Hausdorff space  s.t.  does not separate points?,X C_b(X),"We know the Stone-Weierstrass theorem for locally compact Hausdorff spaces (LCH) which states the following: Theorem: Suppose $X$ is LCH. A subalgebra $\mathcal{A}$ of $C_0(X)$ is dense if and only if it separates points ($\forall x,y \in X : x\neq y \implies \exists f \in \mathcal{A}: f(x) \neq f(y)$) and vanishes nowhere $(\forall x \in X \exists f \in \mathcal{A} : f(x) \neq 0$) and is closed under complex conjugation 1 . It's also easy to show that $C_b(X)$, the continuous and bounded functions on a topological space $X$, is a Banach space 2 . It would be obvious to try and show a variant of Stone-Weierstrass for $C_b(X)$ where $X$ is merely Hausdorff, and since it's obviously dense in itself, for such a theorem to exist it would be required that $C_b(X)$ separates points (that it vanishes nowhere is clear: it contains the constant functions). I've tried to come up with an example of a Hausdorff space where $C_b(X)$ fails to separate points (this could for example be a space where every non-constant continuous function is unbounded), but to no avail. So does anyone happen to have an instructive example lying around? PS: It's an interesting exercise to prove that given a LCH space $X$ the continuous functions with compact support, $C_{00}(X)$, separates points and vanishes nowhere. You get to use many theorems from topology in the process of constructing a continuous function such that $f(x)=1$ and $f(y)=0$ given distinct points $x,y \in X$ [Hint: Find a good compact subset and use Urysohn's lemma]. [1]: In the case of real-valued functions this is essentially a no-op, so including it in the theorem statement doesn't hurt. [2]: [Car00] shows in Lemma 10.8 that $B(X)$, the set of bounded functions on a set $X$ is a Banach space, and it's an immediate corollary from Thm 10.4 that $C_b(X)$ is closed in $B(X)$ for $X$ a metric space. Of course this  generalises readily to the case of $X$ a topological space.","We know the Stone-Weierstrass theorem for locally compact Hausdorff spaces (LCH) which states the following: Theorem: Suppose $X$ is LCH. A subalgebra $\mathcal{A}$ of $C_0(X)$ is dense if and only if it separates points ($\forall x,y \in X : x\neq y \implies \exists f \in \mathcal{A}: f(x) \neq f(y)$) and vanishes nowhere $(\forall x \in X \exists f \in \mathcal{A} : f(x) \neq 0$) and is closed under complex conjugation 1 . It's also easy to show that $C_b(X)$, the continuous and bounded functions on a topological space $X$, is a Banach space 2 . It would be obvious to try and show a variant of Stone-Weierstrass for $C_b(X)$ where $X$ is merely Hausdorff, and since it's obviously dense in itself, for such a theorem to exist it would be required that $C_b(X)$ separates points (that it vanishes nowhere is clear: it contains the constant functions). I've tried to come up with an example of a Hausdorff space where $C_b(X)$ fails to separate points (this could for example be a space where every non-constant continuous function is unbounded), but to no avail. So does anyone happen to have an instructive example lying around? PS: It's an interesting exercise to prove that given a LCH space $X$ the continuous functions with compact support, $C_{00}(X)$, separates points and vanishes nowhere. You get to use many theorems from topology in the process of constructing a continuous function such that $f(x)=1$ and $f(y)=0$ given distinct points $x,y \in X$ [Hint: Find a good compact subset and use Urysohn's lemma]. [1]: In the case of real-valued functions this is essentially a no-op, so including it in the theorem statement doesn't hurt. [2]: [Car00] shows in Lemma 10.8 that $B(X)$, the set of bounded functions on a set $X$ is a Banach space, and it's an immediate corollary from Thm 10.4 that $C_b(X)$ is closed in $B(X)$ for $X$ a metric space. Of course this  generalises readily to the case of $X$ a topological space.",,"['real-analysis', 'general-topology', 'examples-counterexamples', 'separation-axioms']"
67,How to show that $\lim_{n\to \infty} \frac{a_1 +a_2 + \cdots + a_n}{n} = 0?$ [duplicate],How to show that  [duplicate],\lim_{n\to \infty} \frac{a_1 +a_2 + \cdots + a_n}{n} = 0?,"This question already has answers here : If $\sum_{n\geq 1}\frac{a_n}{n}$ converges, then $\lim_{n\rightarrow \infty}\frac{1}{n}\sum_{k=1}^na_k=0$ (2 answers) Closed 2 years ago . We are given that $\displaystyle\sum_{k=1}^\infty \frac{a_k}{k}$ converges, and we want to show that $$\lim_{n\to \infty} \frac{a_1 +a_2 + \cdots + a_n}{n} = 0.$$ Let $\epsilon>0.$ Then since $\displaystyle\sum_{k=1}^\infty \frac{a_k}{k}$ converges we have that there is some positive integer $N_\epsilon$ such that $\left|\sum_{k=N_\epsilon}^\infty \dfrac{a_k}{k}\right|<\dfrac{\epsilon}2$ . Let $\sum_{k=1}^{N_\epsilon} a_k =A$ and choose $N_1$ so that $\left|\frac{A}{n}\right|<\frac{\epsilon}{2}$ when $n\geq N_1$ . Now let $n\geq \max \left\{N_1, N_\epsilon \right\}$ so that $$\left|\frac{a_1 +a_2 + \cdots + a_n}{n}\right|\leq\left|\frac{A}{n}\right|+\left|\frac{\sum_{k=N_\epsilon+1}^n a_k}{n}\right|<\left|\frac{A}{n}\right|+ \left|\sum_{k=N_\epsilon+1}^\infty \frac{a_k}{k}\right|<\frac{\epsilon}{2}+\frac{\epsilon}{2} = \epsilon.$$ Again, I do not feel convinced of my own argument. Am I going the wrong direction? Is there perhaps a better route to showing my conclusion? Any help is appreciated. EDIT: Don’t know why this question got closed. I’m not solely wondering how to prove this statement, I’m also wondering if my proof is sufficient.","This question already has answers here : If $\sum_{n\geq 1}\frac{a_n}{n}$ converges, then $\lim_{n\rightarrow \infty}\frac{1}{n}\sum_{k=1}^na_k=0$ (2 answers) Closed 2 years ago . We are given that converges, and we want to show that Let Then since converges we have that there is some positive integer such that . Let and choose so that when . Now let so that Again, I do not feel convinced of my own argument. Am I going the wrong direction? Is there perhaps a better route to showing my conclusion? Any help is appreciated. EDIT: Don’t know why this question got closed. I’m not solely wondering how to prove this statement, I’m also wondering if my proof is sufficient.","\displaystyle\sum_{k=1}^\infty \frac{a_k}{k} \lim_{n\to \infty} \frac{a_1 +a_2 + \cdots + a_n}{n} = 0. \epsilon>0. \displaystyle\sum_{k=1}^\infty \frac{a_k}{k} N_\epsilon \left|\sum_{k=N_\epsilon}^\infty \dfrac{a_k}{k}\right|<\dfrac{\epsilon}2 \sum_{k=1}^{N_\epsilon} a_k =A N_1 \left|\frac{A}{n}\right|<\frac{\epsilon}{2} n\geq N_1 n\geq \max \left\{N_1, N_\epsilon \right\} \left|\frac{a_1 +a_2 + \cdots + a_n}{n}\right|\leq\left|\frac{A}{n}\right|+\left|\frac{\sum_{k=N_\epsilon+1}^n a_k}{n}\right|<\left|\frac{A}{n}\right|+ \left|\sum_{k=N_\epsilon+1}^\infty \frac{a_k}{k}\right|<\frac{\epsilon}{2}+\frac{\epsilon}{2} = \epsilon.","['real-analysis', 'sequences-and-series', 'limits', 'solution-verification', 'alternative-proof']"
68,Does parity matter for $\lim_{n\to \infty}\left(\ln 2 -\left(-\frac{1}{2}+\frac{1}{3}-\frac{1}{4}+\cdots -\frac{(-1)^n}{n}\right)\right)^n =\sqrt{e}$?,Does parity matter for ?,\lim_{n\to \infty}\left(\ln 2 -\left(-\frac{1}{2}+\frac{1}{3}-\frac{1}{4}+\cdots -\frac{(-1)^n}{n}\right)\right)^n =\sqrt{e},"Prove that $$\lim_{n\to \infty}\left(\ln 2 -\left(-\frac12+\frac13-\frac14+\cdots  -\frac{(-1)^n}n\right)\right)^n =\sqrt{e}$$ I happened to encounter this problem proposed  by Mohammed Bouras,Morocco in the facebook group of Romanian mathematical Magazine As per the  title,  I think the limit of the problem depends upon the parity of $n$ . That is,if $n$ is even, the limit is $\frac1{\sqrt e}$ otherwise as stated. My query is, Does the parity indeed matters for this problem ? And if it matters what should be  the conclusion for limit of the problem ? Here is my try we will show that the there exist two different limits  for above problem. For $0< x\leq 1$ , we define the functions $$f(x)=\ln(1+x),\; \displaystyle g(x)=\sum_{k=1}^n \frac{(-x)^k}{k+1}$$ and we note that $$\begin{aligned}f(x)-g(x) &= x-\sum_{k=2}^\infty(-1)^{k+n} \frac{x^{k+n}}{k+n}\\&=x+\sum_{k=2}^{\infty} (-1)^{k+n} \int_0^x t^{k+n-1}dt\\&=x+(-1)^n\int_0^x t^n\left(\sum_{k=1 }^\infty(-1)^k t^{k-1} \right)dx\\&=x-(-1)^n\int_0^x\frac{t^n}{1+t} dt\end{aligned}$$ hence for $x=1$ we have then $$f(1)-g(1)=\ln(2)-\sum_{k=1}^\infty\frac{(-1)^k}{k+1}=1-(-1)^n\int_0^1\frac{t^n}{1+t}dt$$ Note that latter integral is know result however,here we shall derive it and  we shall show that $$\displaystyle\lim_{n\to\infty}(f(1)-g(1))^n =\begin{cases}\sqrt{e}\; \text{if }  \, n\in 2n-1 \\  \frac1{\sqrt{e}} \; \text{otherwise}\end{cases}$$ We solve the following integral for any $n>0$ . By  polynomial long division it  is trivial to note that $$\int_0^1\frac{t^n}{t+1}dt=(-1)^n\int_0^1\left(\frac{1}{t+1}-\sum_{0\leq j\leq n}(-1)^j t^{j-1}\right)dt$$ and hence on integrating $\displaystyle \int_0^1\frac{t^n}{1+t}dt$ $$\begin{aligned}&=(-1)^n\left(\log(2) -\sum_{1\leq j\leq n} \frac{(-1)^{j+1}}{j}\right)\\&=2^{-1}\left(-\psi\left(\frac{n+1}2\right)+\psi\left(\frac{2n+1}2\right)\right)\\&=\frac12\left(H_{\frac{n}2}-H_{\frac{n-1}2}\right)\end{aligned}$$ Further we note that $H_n\approx \gamma +\ln n +\frac1{2n}-O(n^{-2})$ with which we deduce that $$H_{\frac{n}2} -H_{\frac{n-1}2} \approx  \frac1n-\ln\left(\frac{n-1}n\right)+\frac1{n-1}$$ for all $n>1$ and hence $H_{\frac{n}{2}} -H_{\frac{n-1}2} \to \frac1n$ as $n$ gets larger. Thus we have for $$\lim_{n\to\infty}(f(1)-g(1))^n= \lim_{n\to\infty} \left(1-\frac{(-1)^n}{2n}\right)^n=e^{-\frac{(-1)^n}2} =\sqrt{e^{-(-1)^n}}$$ therefore  if $n$ is even we have limit as $\displaystyle \frac1{\sqrt{e}}$ and if $n$ is odd we  have limit $ \displaystyle \sqrt{e}$ . Since we have two different limits. Does it have limit ? Thank you","Prove that I happened to encounter this problem proposed  by Mohammed Bouras,Morocco in the facebook group of Romanian mathematical Magazine As per the  title,  I think the limit of the problem depends upon the parity of . That is,if is even, the limit is otherwise as stated. My query is, Does the parity indeed matters for this problem ? And if it matters what should be  the conclusion for limit of the problem ? Here is my try we will show that the there exist two different limits  for above problem. For , we define the functions and we note that hence for we have then Note that latter integral is know result however,here we shall derive it and  we shall show that We solve the following integral for any . By  polynomial long division it  is trivial to note that and hence on integrating Further we note that with which we deduce that for all and hence as gets larger. Thus we have for therefore  if is even we have limit as and if is odd we  have limit . Since we have two different limits. Does it have limit ? Thank you","\lim_{n\to \infty}\left(\ln 2 -\left(-\frac12+\frac13-\frac14+\cdots  -\frac{(-1)^n}n\right)\right)^n =\sqrt{e} n n \frac1{\sqrt e} 0< x\leq 1 f(x)=\ln(1+x),\; \displaystyle g(x)=\sum_{k=1}^n \frac{(-x)^k}{k+1} \begin{aligned}f(x)-g(x) &= x-\sum_{k=2}^\infty(-1)^{k+n} \frac{x^{k+n}}{k+n}\\&=x+\sum_{k=2}^{\infty} (-1)^{k+n} \int_0^x t^{k+n-1}dt\\&=x+(-1)^n\int_0^x t^n\left(\sum_{k=1 }^\infty(-1)^k t^{k-1} \right)dx\\&=x-(-1)^n\int_0^x\frac{t^n}{1+t} dt\end{aligned} x=1 f(1)-g(1)=\ln(2)-\sum_{k=1}^\infty\frac{(-1)^k}{k+1}=1-(-1)^n\int_0^1\frac{t^n}{1+t}dt \displaystyle\lim_{n\to\infty}(f(1)-g(1))^n =\begin{cases}\sqrt{e}\; \text{if }  \, n\in 2n-1 \\  \frac1{\sqrt{e}} \; \text{otherwise}\end{cases} n>0 \int_0^1\frac{t^n}{t+1}dt=(-1)^n\int_0^1\left(\frac{1}{t+1}-\sum_{0\leq j\leq n}(-1)^j t^{j-1}\right)dt \displaystyle \int_0^1\frac{t^n}{1+t}dt \begin{aligned}&=(-1)^n\left(\log(2) -\sum_{1\leq j\leq n} \frac{(-1)^{j+1}}{j}\right)\\&=2^{-1}\left(-\psi\left(\frac{n+1}2\right)+\psi\left(\frac{2n+1}2\right)\right)\\&=\frac12\left(H_{\frac{n}2}-H_{\frac{n-1}2}\right)\end{aligned} H_n\approx \gamma +\ln n +\frac1{2n}-O(n^{-2}) H_{\frac{n}2} -H_{\frac{n-1}2} \approx  \frac1n-\ln\left(\frac{n-1}n\right)+\frac1{n-1} n>1 H_{\frac{n}{2}} -H_{\frac{n-1}2} \to \frac1n n \lim_{n\to\infty}(f(1)-g(1))^n= \lim_{n\to\infty} \left(1-\frac{(-1)^n}{2n}\right)^n=e^{-\frac{(-1)^n}2} =\sqrt{e^{-(-1)^n}} n \displaystyle \frac1{\sqrt{e}} n  \displaystyle \sqrt{e}","['real-analysis', 'integration', 'sequences-and-series', 'limits', 'summation']"
69,Proving that: $9.9998\lt \frac{\pi^9}{e^8}\lt 10$?,Proving that: ?,9.9998\lt \frac{\pi^9}{e^8}\lt 10,I would like to use mathematical tools to prove that      $$9.9998\lt \frac{\pi^9}{e^8}\lt 10$$ With an on-line calculator I got $$  \frac{\pi^9}{e^8}\approx 9.9998387978$$ But I do not know any good way to prove this. I failed to use Taylor expansion  $$e^8 =\sum_{n=0}^{\infty}\frac{8^n}{n!}$$ Any idea?,I would like to use mathematical tools to prove that      $$9.9998\lt \frac{\pi^9}{e^8}\lt 10$$ With an on-line calculator I got $$  \frac{\pi^9}{e^8}\approx 9.9998387978$$ But I do not know any good way to prove this. I failed to use Taylor expansion  $$e^8 =\sum_{n=0}^{\infty}\frac{8^n}{n!}$$ Any idea?,,"['calculus', 'real-analysis', 'approximation', 'approximation-theory', 'transcendental-numbers']"
70,Proof of uniform limit of Continuous Functions,Proof of uniform limit of Continuous Functions,,"The uniform limit of Continuous Functions is continuous. Proof Let $\varepsilon > 0$ . There exists $N$ in natural numbers such that $n>N$ implies $|f_n(x)-f(x)| < \frac{\varepsilon}{3}$ for all $x$ in $S$ . In particular $|f_{N+1}(x)-f(x)| < \frac{\varepsilon}{3}$ for all $x$ in $S$ . Since $f_{N+1}$ is continuous at $x_0$ there is a $\delta>0$ such that, $x$ in $S$ and $|x-x_0| < \delta$ imply $|f_{N+1}(x)-f_{N+1}(x_0)|< \frac{\varepsilon}{3}$ Now we conclude $x$ in $S$ and $|x-x_0| < \delta$ imply $|f(x)-f(x_0)|< 3 \cdot \frac{\varepsilon}{3} = \varepsilon$ . Can someone explain what is happening here? I don't follow it all.","The uniform limit of Continuous Functions is continuous. Proof Let . There exists in natural numbers such that implies for all in . In particular for all in . Since is continuous at there is a such that, in and imply Now we conclude in and imply . Can someone explain what is happening here? I don't follow it all.",\varepsilon > 0 N n>N |f_n(x)-f(x)| < \frac{\varepsilon}{3} x S |f_{N+1}(x)-f(x)| < \frac{\varepsilon}{3} x S f_{N+1} x_0 \delta>0 x S |x-x_0| < \delta |f_{N+1}(x)-f_{N+1}(x_0)|< \frac{\varepsilon}{3} x S |x-x_0| < \delta |f(x)-f(x_0)|< 3 \cdot \frac{\varepsilon}{3} = \varepsilon,"['real-analysis', 'continuity', 'uniform-convergence']"
71,Rudin's proof that the Cantor set has no segments,Rudin's proof that the Cantor set has no segments,,"In Principles of Mathematical Analysis , on page 42, Rudin proves that the Cantor set has no segments by stating that every segment $(\alpha,\beta)$ contains a segment of the form $(\frac{3k+1}{3^{n}},\frac{3k+2}{3^{n}})$ if $3^{-n}\lt\frac{\beta-\alpha}{6}$. I don't know how $\frac{\beta-\alpha}{6}$ is obtained.","In Principles of Mathematical Analysis , on page 42, Rudin proves that the Cantor set has no segments by stating that every segment $(\alpha,\beta)$ contains a segment of the form $(\frac{3k+1}{3^{n}},\frac{3k+2}{3^{n}})$ if $3^{-n}\lt\frac{\beta-\alpha}{6}$. I don't know how $\frac{\beta-\alpha}{6}$ is obtained.",,"['real-analysis', 'cantor-set']"
72,"Calculating $\int_0^1 \frac{\operatorname{arctanh}\left(\sqrt{1-\frac{u}{2}}\right)\sqrt{\frac{2 \pi \sqrt{1-u}}{u-2}+\pi } }{u\sqrt{1-u}} \, du$",Calculating,"\int_0^1 \frac{\operatorname{arctanh}\left(\sqrt{1-\frac{u}{2}}\right)\sqrt{\frac{2 \pi \sqrt{1-u}}{u-2}+\pi } }{u\sqrt{1-u}} \, du","What real tools would you employ for calculating the integral below? Some useful ideas I mean. $$\int_0^1 \frac{\operatorname{arctanh}\left(\sqrt{1-\frac{u}{2}}\right)\sqrt{\frac{2 \pi  \sqrt{1-u}}{u-2}+\pi } }{u\sqrt{1-u}} \, du$$","What real tools would you employ for calculating the integral below? Some useful ideas I mean. $$\int_0^1 \frac{\operatorname{arctanh}\left(\sqrt{1-\frac{u}{2}}\right)\sqrt{\frac{2 \pi  \sqrt{1-u}}{u-2}+\pi } }{u\sqrt{1-u}} \, du$$",,"['calculus', 'real-analysis', 'integration', 'definite-integrals']"
73,A function that is bounded and measurable but not Lebesgue integrable,A function that is bounded and measurable but not Lebesgue integrable,,"Could you give me concrete examples about ""a function that is bounded and measurable but not Lebesgue integrable"". Royden's textbook ""Real analysis"" says a bounded measurable function is said to be integrable if its lower Lebesgue integrale is equal to its upper Lebesgue integral. (I know if the domain is of finite measure, then a bounded function is Lebesgue integrable iff it is measurable , so my desired example need to be on a domain of infinite measure.)","Could you give me concrete examples about ""a function that is bounded and measurable but not Lebesgue integrable"". Royden's textbook ""Real analysis"" says a bounded measurable function is said to be integrable if its lower Lebesgue integrale is equal to its upper Lebesgue integral. (I know if the domain is of finite measure, then a bounded function is Lebesgue integrable iff it is measurable , so my desired example need to be on a domain of infinite measure.)",,"['real-analysis', 'integration', 'measure-theory', 'lebesgue-measure', 'examples-counterexamples']"
74,"If $f_n \geq 0$ and $f_n \to f$ in measure, then $\int f \leq \liminf \int f_n$","If  and  in measure, then",f_n \geq 0 f_n \to f \int f \leq \liminf \int f_n,"I am reading Folland's, Real Analysis and I am stuck at the following exercise (2.33). If $f_n \geq 0$ and $f_n \to f$ in measure, then $\int f \leq \liminf \int f_n$ It smells like Fatou's, however I couldn't see anything. Thanks in advance!","I am reading Folland's, Real Analysis and I am stuck at the following exercise (2.33). If $f_n \geq 0$ and $f_n \to f$ in measure, then $\int f \leq \liminf \int f_n$ It smells like Fatou's, however I couldn't see anything. Thanks in advance!",,['real-analysis']
75,"If $E$ has $\sigma$-finite measure, then $E$ is inner regular","If  has -finite measure, then  is inner regular",E \sigma E,"In Rudin's Real & Complex Analysis, page 47: It is easy to see that if $E \in \mathfrak{M}$ and E has $\sigma$-finite measure, then $E$ is inner regular. $\mathfrak{M}$ in this context is the $\sigma$-algebra constructed to prove the Riesz representation theorem. I can't for the life of me figure out how this is easy. Can anyone explain it to me?","In Rudin's Real & Complex Analysis, page 47: It is easy to see that if $E \in \mathfrak{M}$ and E has $\sigma$-finite measure, then $E$ is inner regular. $\mathfrak{M}$ in this context is the $\sigma$-algebra constructed to prove the Riesz representation theorem. I can't for the life of me figure out how this is easy. Can anyone explain it to me?",,"['real-analysis', 'measure-theory']"
76,Proving Cauchy's Generalized Mean Value Theorem,Proving Cauchy's Generalized Mean Value Theorem,,"This is an exercise from Stephen Abbott's Understanding Analysis . The hint it gives on how to solve it is not very clear, in my opinion, so I would like for a fresh set of eyes to go over it with me: pp 143 Exercise 5.3.4. (a) Supply the details for the proof of Cauchy's Generalized Mean Value Theorem (Theorem 5.3.5.). Theorem 5.3.5. (Generalized Mean Value Theorem). If $f$ and $g$ are continuous on the closed interval $[a,b]$ and differentiable on the open interval $(a,b)$, then there exists a point $c\in(a,b)$ where$$[f(b)-f(a)]g'(c)=[g(b)-g(a)]f'(c).$$If $g'$ is never zero on $(a,b)$, then the conclusion can be stated as$$\frac{f'(c)}{g'(c)}=\frac{f(b)-f(a)}{g(b)-g(a)}.$$ * Hint: This result follows by applying the Mean Value Theorem to the function *$$h(x)=[f(b)-f(a)]g(x)-[g(b)-g(a)]f(x)$$ First of all, I know that the Mean Value Theorem (MVT) states that if $f:[a,b]\to\mathbb{R}$ is continuous on $[a,b]$ and differentiable on $(a,b)$, then there exists a point $c\in(a,b)$ where$$f'(c)=\frac{f(b)-f(a)}{b-a}.$$ If we assume that $h$ has the above properties, then applying the MVT to it, for some $c\in(a,b)$, would yield$$h'(c)=\frac{h(b)-h(a)}{b-a}=$$ $$\frac{[f(b)-f(a)]g(b)-[g(b)-g(a)]f(b) \quad - \quad [f(b)-f(a)]g(a)+[g(b)-g(a)]f(a)}{b-a}=$$ $$[f(b)-f(a)]\left(\frac{g(b)-g(a)}{b-a}\right) \quad - \quad[g(b)-g(a)]\left(\frac{f(b)-f(a)}{b-a}\right)=$$ $$[f(b)-f(a)]g'(c) \quad - \quad [g(b)-g(a)]f'(c).$$This is the best I could achieve; I have no clue on how to reach the second equation in the above theorem. Do you guys have any ideas? Thanks in advance!","This is an exercise from Stephen Abbott's Understanding Analysis . The hint it gives on how to solve it is not very clear, in my opinion, so I would like for a fresh set of eyes to go over it with me: pp 143 Exercise 5.3.4. (a) Supply the details for the proof of Cauchy's Generalized Mean Value Theorem (Theorem 5.3.5.). Theorem 5.3.5. (Generalized Mean Value Theorem). If $f$ and $g$ are continuous on the closed interval $[a,b]$ and differentiable on the open interval $(a,b)$, then there exists a point $c\in(a,b)$ where$$[f(b)-f(a)]g'(c)=[g(b)-g(a)]f'(c).$$If $g'$ is never zero on $(a,b)$, then the conclusion can be stated as$$\frac{f'(c)}{g'(c)}=\frac{f(b)-f(a)}{g(b)-g(a)}.$$ * Hint: This result follows by applying the Mean Value Theorem to the function *$$h(x)=[f(b)-f(a)]g(x)-[g(b)-g(a)]f(x)$$ First of all, I know that the Mean Value Theorem (MVT) states that if $f:[a,b]\to\mathbb{R}$ is continuous on $[a,b]$ and differentiable on $(a,b)$, then there exists a point $c\in(a,b)$ where$$f'(c)=\frac{f(b)-f(a)}{b-a}.$$ If we assume that $h$ has the above properties, then applying the MVT to it, for some $c\in(a,b)$, would yield$$h'(c)=\frac{h(b)-h(a)}{b-a}=$$ $$\frac{[f(b)-f(a)]g(b)-[g(b)-g(a)]f(b) \quad - \quad [f(b)-f(a)]g(a)+[g(b)-g(a)]f(a)}{b-a}=$$ $$[f(b)-f(a)]\left(\frac{g(b)-g(a)}{b-a}\right) \quad - \quad[g(b)-g(a)]\left(\frac{f(b)-f(a)}{b-a}\right)=$$ $$[f(b)-f(a)]g'(c) \quad - \quad [g(b)-g(a)]f'(c).$$This is the best I could achieve; I have no clue on how to reach the second equation in the above theorem. Do you guys have any ideas? Thanks in advance!",,"['real-analysis', 'proof-verification']"
77,Derivative of a function is odd prove the function is even.,Derivative of a function is odd prove the function is even.,,$f:\mathbb{R} \rightarrow \mathbb{R}$ is such that $f'(x)$ exists $\forall x.$ And $f'(-x)=-f'(x)$ I would like to show $f(-x)=f(x)$ In other words a function with odd derivative is even. If I could apply the fundamental theorem of calculus $\int_{-x}^{x}f'(t)dt = f(x)-f(-x)$ but since the integrand is odd we have $f(x)-f(-x)=0 \Rightarrow f(x)=f(-x)$ but unfortunately I don't know that f' is integrable.,$f:\mathbb{R} \rightarrow \mathbb{R}$ is such that $f'(x)$ exists $\forall x.$ And $f'(-x)=-f'(x)$ I would like to show $f(-x)=f(x)$ In other words a function with odd derivative is even. If I could apply the fundamental theorem of calculus $\int_{-x}^{x}f'(t)dt = f(x)-f(-x)$ but since the integrand is odd we have $f(x)-f(-x)=0 \Rightarrow f(x)=f(-x)$ but unfortunately I don't know that f' is integrable.,,['real-analysis']
78,"Limit of $\int_0^1\left(\frac {2}{\sqrt {(1-t^2)(1-xt^2)}}-\frac{x}{1-xt}\right)\,dt$ as $x\to 1^{-}$",Limit of  as,"\int_0^1\left(\frac {2}{\sqrt {(1-t^2)(1-xt^2)}}-\frac{x}{1-xt}\right)\,dt x\to 1^{-}","While going through this question I was reminded of one of my earlier questions and I found that there is some unfinished business which needs some further exploration. Let $$F(x) =\int_0^1\left(\frac{2}{\sqrt{(1-t^2)(1-xt^2)}} -\frac{x}{1-xt}\right)\, dt=\int_0^1 f(x, t) \, dt\tag{1}$$ for $x\in[0,1]$ . Let's observe that $$\lim_{x\to 1^-}f(x,t)=\frac{1}{1+t}\tag{2}$$ and hence it is natural to expect that $\lim_{x\to 1^-}F(x)$ should equal $\int_0^1 dt/(1+t)=\log 2$ but numerical evidence as well as some amount of elliptic function theory tells (see one of my questions linked earlier for details) us that this particular limit is $4\log 2$ . This suggests that there is some weird behavior of integrand as $x\to 1^{-}$ (in particular the convergence is not uniform). I would like to have this limit evaluated using some analysis related to convergence of integrand as $x\to 1^-$ . Any help in this direction would be appreciated. Note : I have asked a new question instead of bumping an old one. The old question is more about solution verification and is related to elliptic integrals. I wanted to have a different perspective which involves general issues of uniform convergence to handle the limit of this integral.",While going through this question I was reminded of one of my earlier questions and I found that there is some unfinished business which needs some further exploration. Let for . Let's observe that and hence it is natural to expect that should equal but numerical evidence as well as some amount of elliptic function theory tells (see one of my questions linked earlier for details) us that this particular limit is . This suggests that there is some weird behavior of integrand as (in particular the convergence is not uniform). I would like to have this limit evaluated using some analysis related to convergence of integrand as . Any help in this direction would be appreciated. Note : I have asked a new question instead of bumping an old one. The old question is more about solution verification and is related to elliptic integrals. I wanted to have a different perspective which involves general issues of uniform convergence to handle the limit of this integral.,"F(x) =\int_0^1\left(\frac{2}{\sqrt{(1-t^2)(1-xt^2)}} -\frac{x}{1-xt}\right)\, dt=\int_0^1 f(x, t) \, dt\tag{1} x\in[0,1] \lim_{x\to 1^-}f(x,t)=\frac{1}{1+t}\tag{2} \lim_{x\to 1^-}F(x) \int_0^1 dt/(1+t)=\log 2 4\log 2 x\to 1^{-} x\to 1^-","['real-analysis', 'integration', 'limits']"
79,Prove $ \int_{5\pi/36}^{7\pi/36} \ln (\cot t )dt +\int_{\pi/36}^{3\pi/36} \ln (\cot t )dt = \frac49G $,Prove, \int_{5\pi/36}^{7\pi/36} \ln (\cot t )dt +\int_{\pi/36}^{3\pi/36} \ln (\cot t )dt = \frac49G ,"I have the conjecture for the integral $$ \int_{\frac{5\pi}{36}}^{\frac{7\pi}{36}} \ln (\cot t )\>dt +\int_{\frac{\pi}{36}}^{\frac{3\pi}{36}} \ln (\cot t )\>dt = \frac49G $$ where $G$ is the Catalan constant, following some heuristic effort. But, I am unable to derive it formally despite having tried for some time. The derivation seems tougher than the tools in my toolbox. I stick to real methods, though, trying to work it out mainly with elementary approaches. The standard procedures do not help that much. For instance, the substitution $u=\tan t $ is not viable given the inordinate limits; integration-by-parts coverts the integrand to $\frac t{\sin 2t}$ , which is not revealing either. The proof for a much simpler integral $$\int_0^\frac{\pi}{12}\ln(\cot x)=\frac23G $$ is known, yet perhaps with limited relevance. Maybe, there is no avoidance of resorting to infinite series, complex methods, etc. Edit: Taking the cue from the comments below, the integral can be equivalently expressed as $$\int_{\frac{\pi}{12}}^{\frac{5\pi}{36}} \ln\left( \cot (t+\frac\pi{36} )\cot (t-\frac\pi{36} )\right)=\frac49G$$ which may not reduce the difficulty, albeit appearing compact.","I have the conjecture for the integral where is the Catalan constant, following some heuristic effort. But, I am unable to derive it formally despite having tried for some time. The derivation seems tougher than the tools in my toolbox. I stick to real methods, though, trying to work it out mainly with elementary approaches. The standard procedures do not help that much. For instance, the substitution is not viable given the inordinate limits; integration-by-parts coverts the integrand to , which is not revealing either. The proof for a much simpler integral is known, yet perhaps with limited relevance. Maybe, there is no avoidance of resorting to infinite series, complex methods, etc. Edit: Taking the cue from the comments below, the integral can be equivalently expressed as which may not reduce the difficulty, albeit appearing compact."," \int_{\frac{5\pi}{36}}^{\frac{7\pi}{36}} \ln (\cot t )\>dt +\int_{\frac{\pi}{36}}^{\frac{3\pi}{36}} \ln (\cot t )\>dt = \frac49G  G u=\tan t  \frac t{\sin 2t} \int_0^\frac{\pi}{12}\ln(\cot x)=\frac23G
 \int_{\frac{\pi}{12}}^{\frac{5\pi}{36}} \ln\left( \cot (t+\frac\pi{36} )\cot (t-\frac\pi{36} )\right)=\frac49G","['real-analysis', 'calculus', 'integration', 'definite-integrals', 'catalans-constant']"
80,What is a continuous function on the rationals that hasn't a continuous extension on the reals? [duplicate],What is a continuous function on the rationals that hasn't a continuous extension on the reals? [duplicate],,"This question already has answers here : Does every continuous map from $\mathbb{Q}$ to $\mathbb{Q}$ extends continuously as a map from $\mathbb{R}$ to $\mathbb{R}$? (3 answers) Closed 4 years ago . In a review of H.R. Pitt's Integration, Measure and Probability , Sir John Kingman wrote, The author is often careless about details, asserting for instance (on page 105) that a function continuous on the rationals has a continuous extension to the reals. Using the properties of Cauchy sequences and completeness of $\mathbb R$ , I can prove that if $f:\mathbb Q\to\mathbb R$ is uniformly continuous, then there exists a continuous function $g:\mathbb R\to\mathbb R$ such that $f=g$ on $\mathbb Q$ . It follows that any inextensible $f$ cannot be uniformly continuous on $\mathbb Q$ . However, I am unable to come up with a concrete example.","This question already has answers here : Does every continuous map from $\mathbb{Q}$ to $\mathbb{Q}$ extends continuously as a map from $\mathbb{R}$ to $\mathbb{R}$? (3 answers) Closed 4 years ago . In a review of H.R. Pitt's Integration, Measure and Probability , Sir John Kingman wrote, The author is often careless about details, asserting for instance (on page 105) that a function continuous on the rationals has a continuous extension to the reals. Using the properties of Cauchy sequences and completeness of , I can prove that if is uniformly continuous, then there exists a continuous function such that on . It follows that any inextensible cannot be uniformly continuous on . However, I am unable to come up with a concrete example.",\mathbb R f:\mathbb Q\to\mathbb R g:\mathbb R\to\mathbb R f=g \mathbb Q f \mathbb Q,"['real-analysis', 'continuity']"
81,Existence of a pointwise convergent subsequence,Existence of a pointwise convergent subsequence,,"Let $X$ be a compact metric space and $f_m:X\to[0,1]$ a continuous function for each $m\in\mathbb N$ . Does there necessarily exist a $f:X\to[0,1]$ (not necessarily continuous) and a subsequence $(f_{m_k})$ such that $f_{m_k}(x)\to f(x)$ for each $x\in X$ pointwise? Note that the equicontinuity of $(f_m)_{m\in\mathbb N}$ is not assumed, so that the Arzelà–Ascoli theorem is of no use here. However, the desired conclusion is also weaker: the supposed limit function $f$ need not be continuous and only pointwise convergence is required. Any suggestion would be appreciated.","Let be a compact metric space and a continuous function for each . Does there necessarily exist a (not necessarily continuous) and a subsequence such that for each pointwise? Note that the equicontinuity of is not assumed, so that the Arzelà–Ascoli theorem is of no use here. However, the desired conclusion is also weaker: the supposed limit function need not be continuous and only pointwise convergence is required. Any suggestion would be appreciated.","X f_m:X\to[0,1] m\in\mathbb N f:X\to[0,1] (f_{m_k}) f_{m_k}(x)\to f(x) x\in X (f_m)_{m\in\mathbb N} f","['real-analysis', 'general-topology']"
82,"If $f : [a,b]\to\Bbb R$ is continuous, are there $x_1,x_2\in (a,b)$ such that $\tfrac{f(b)-f(a)}{b-a} = \tfrac{f(x_1)-f(x_2)}{x_1-x_2}$?","If  is continuous, are there  such that ?","f : [a,b]\to\Bbb R x_1,x_2\in (a,b) \tfrac{f(b)-f(a)}{b-a} = \tfrac{f(x_1)-f(x_2)}{x_1-x_2}","I just thought about the mean value theorem and wondered whether the following statement is true: If $f : [a,b]\to\Bbb R$ is continuous, then there are $x_1,x_2\in (a,b)$   such that $\tfrac{f(b)-f(a)}{b-a} = \tfrac{f(x_1)-f(x_2)}{x_1-x_2}$. One way to look at it is to consider the function $F : \{(x,y) : x,y\in[a,b],\,y>x\}\to\Bbb R$, defined by $F(x,y) = \tfrac{f(x)-f(y)}{x-y}$. If there don't exist such $x_1,x_2$, then $(a,b)$ is a maximum of a minimum of $F$. But I don't know what to conclude from that. Does anybody have an idea?","I just thought about the mean value theorem and wondered whether the following statement is true: If $f : [a,b]\to\Bbb R$ is continuous, then there are $x_1,x_2\in (a,b)$   such that $\tfrac{f(b)-f(a)}{b-a} = \tfrac{f(x_1)-f(x_2)}{x_1-x_2}$. One way to look at it is to consider the function $F : \{(x,y) : x,y\in[a,b],\,y>x\}\to\Bbb R$, defined by $F(x,y) = \tfrac{f(x)-f(y)}{x-y}$. If there don't exist such $x_1,x_2$, then $(a,b)$ is a maximum of a minimum of $F$. But I don't know what to conclude from that. Does anybody have an idea?",,"['real-analysis', 'continuity']"
83,"If $\ \sum_{k=1}^n m(E_k) > n-1,$ then prove that $\bigcap_{k=1}^n E_k$ has positive measure.",If  then prove that  has positive measure.,"\ \sum_{k=1}^n m(E_k) > n-1, \bigcap_{k=1}^n E_k","Question: Let $E_1,E_2,...,E_n$ be measurable subsets of $[0,1]$ with $$ \sum_{k=1}^n m(E_k)  > n-1.$$ Prove that $\bigcap_{k=1}^n E_k$ has positive measure. This is one of the questions in graduate analysis past year paper. I think we need to assume that the intersection $\bigcap_{k=1}^n E_k$ is nonempty. Otherwise, the question is false. Anyway, let's assume that $\bigcap_{k=1}^n E_k \neq \emptyset.$ If $n=2,$ by inclusion-exclusion principle and assumption, $$m(E_1\cup E_2) + m(E_1 \cap E_2) = m(E_1) + m(E_2) > 2.$$ Since $E_1,E_2 \subseteq [0,1],$ by monotonicity of Lebesgue measure, $$m(E_1) \leq 1, m(E_2) \leq 1.$$ By finite subadditivity of Lebesgue measure, $$m(E_1 \cup E_2) \leq m(E_1) + m(E_2) \leq 2.$$ Hence, $$m(E_1 \cap E_2) > 2 - m(E_1 \cup E_2) \geq 0$$ Therefore, the intersection $\bigcap_{k=1}^n E_k$ has positive measure for $n=2.$ I try prove the general $n$ using induction, but it seems a bit long. Does there exist an efficient method to solve the question? EDIT: Actually I am looking for a direct proof instead of indirect proof or inductive proof. If a direct proof is not possible, then I will accept Marios's answer.","Question: Let be measurable subsets of with Prove that has positive measure. This is one of the questions in graduate analysis past year paper. I think we need to assume that the intersection is nonempty. Otherwise, the question is false. Anyway, let's assume that If by inclusion-exclusion principle and assumption, Since by monotonicity of Lebesgue measure, By finite subadditivity of Lebesgue measure, Hence, Therefore, the intersection has positive measure for I try prove the general using induction, but it seems a bit long. Does there exist an efficient method to solve the question? EDIT: Actually I am looking for a direct proof instead of indirect proof or inductive proof. If a direct proof is not possible, then I will accept Marios's answer.","E_1,E_2,...,E_n [0,1]  \sum_{k=1}^n m(E_k)  > n-1. \bigcap_{k=1}^n E_k \bigcap_{k=1}^n E_k \bigcap_{k=1}^n E_k \neq \emptyset. n=2, m(E_1\cup E_2) + m(E_1 \cap E_2) = m(E_1) + m(E_2) > 2. E_1,E_2 \subseteq [0,1], m(E_1) \leq 1, m(E_2) \leq 1. m(E_1 \cup E_2) \leq m(E_1) + m(E_2) \leq 2. m(E_1 \cap E_2) > 2 - m(E_1 \cup E_2) \geq 0 \bigcap_{k=1}^n E_k n=2. n","['real-analysis', 'measure-theory', 'lebesgue-measure']"
84,Prove that $\int_a^bxf(x)dx\geq\frac{b+a}{2}\int_a^bf(x)dx$,Prove that,\int_a^bxf(x)dx\geq\frac{b+a}{2}\int_a^bf(x)dx,"Let $f:[a,b]\to\mathbb{R}$ be continuous and increasing, show that $$\int_a^bxf(x)dx\geq\frac{b+a}{2}\int_a^bf(x)dx$$ I am thinking of using integration by parts. First let $$F(x)=\int_a^xf(t)dt$$ Then $$\int_a^bxf(x)dx=bF(b)-\int_a^bF(x)dx=b\int_a^bf(x)dx-\int_a^b\int_a^xf(t)dtdx$$ So far I only have these in mind. Any one have any hints?","Let $f:[a,b]\to\mathbb{R}$ be continuous and increasing, show that $$\int_a^bxf(x)dx\geq\frac{b+a}{2}\int_a^bf(x)dx$$ I am thinking of using integration by parts. First let $$F(x)=\int_a^xf(t)dt$$ Then $$\int_a^bxf(x)dx=bF(b)-\int_a^bF(x)dx=b\int_a^bf(x)dx-\int_a^b\int_a^xf(t)dtdx$$ So far I only have these in mind. Any one have any hints?",,"['real-analysis', 'integration', 'integral-inequality']"
85,Show that $\sum\limits_{k=1}^\infty \frac{1}{k(k+1)(k+2)\cdots (k+p)}=\frac{1}{p!p} $ for every positive integer $p$,Show that  for every positive integer,\sum\limits_{k=1}^\infty \frac{1}{k(k+1)(k+2)\cdots (k+p)}=\frac{1}{p!p}  p,I have to prove that $$\sum_{k=1}^\infty \frac{1}{k(k+1)(k+2)\cdots (k+p)}=\dfrac{1}{p!p}$$ How can I do that?,I have to prove that How can I do that?,\sum_{k=1}^\infty \frac{1}{k(k+1)(k+2)\cdots (k+p)}=\dfrac{1}{p!p},"['real-analysis', 'sequences-and-series', 'analysis', 'convergence-divergence', 'summation']"
86,"$f$ a real, continuous function, is it measurable?","a real, continuous function, is it measurable?",f,"Let $f: \mathbb{R} \to \mathbb{R} $ be a continuous function. I need to show that is a measurable function. I tried working with the definition:  Let $f: X \to \mathbb{R}$ be a function. If $f^{-1}(O)$ is a measurable set for every open subset $O$ of $\mathbb{R}$ , then $f$ is called a measurable function. Since $f^{-1}(O)$ also lies in $\mathbb{R}$ , I think it is sufficient to show that every subset of $\mathbb{R}$ is measurable. But is this possible? So far I concluded that $\mathbb{R}$ itself is measurable, since $$\mu(A) = \mu(A \cap \mathbb{R}) + \mu(A \cap \mathbb{R}^c) = \mu(A) + \mu(\emptyset) = \mu(A).$$ How do I need to approach?","Let be a continuous function. I need to show that is a measurable function. I tried working with the definition:  Let be a function. If is a measurable set for every open subset of , then is called a measurable function. Since also lies in , I think it is sufficient to show that every subset of is measurable. But is this possible? So far I concluded that itself is measurable, since How do I need to approach?",f: \mathbb{R} \to \mathbb{R}  f: X \to \mathbb{R} f^{-1}(O) O \mathbb{R} f f^{-1}(O) \mathbb{R} \mathbb{R} \mathbb{R} \mu(A) = \mu(A \cap \mathbb{R}) + \mu(A \cap \mathbb{R}^c) = \mu(A) + \mu(\emptyset) = \mu(A).,"['real-analysis', 'measure-theory', 'lebesgue-measure', 'measurable-functions']"
87,Volume of $n$ dimensional ellipsoid,Volume of  dimensional ellipsoid,n,"Let $c_1,c_2,...,c_n$ be positive constants. Consider the $n$ dimensional ellipsoid given by $\{(x_1,...,x_n)|\sum_{k=1}^n\frac{x_k^2}{c_k^2}<1\}$. Prove that it's $n$ dimensional volume is $\frac{\pi^{n/2}}{\Gamma(n/2+1)}\prod_{k=1}^nc_k$ I'm know from http://en.wikipedia.org/wiki/Volume_of_an_n-ball that the volume of the $n$ ball is exactly the above formula with $c_1=c_2=...=c_n=r$, which at least confirms the formula in this special case. It seems we can argue by scaling in each coordinates, but how to make this rigorous?","Let $c_1,c_2,...,c_n$ be positive constants. Consider the $n$ dimensional ellipsoid given by $\{(x_1,...,x_n)|\sum_{k=1}^n\frac{x_k^2}{c_k^2}<1\}$. Prove that it's $n$ dimensional volume is $\frac{\pi^{n/2}}{\Gamma(n/2+1)}\prod_{k=1}^nc_k$ I'm know from http://en.wikipedia.org/wiki/Volume_of_an_n-ball that the volume of the $n$ ball is exactly the above formula with $c_1=c_2=...=c_n=r$, which at least confirms the formula in this special case. It seems we can argue by scaling in each coordinates, but how to make this rigorous?",,"['real-analysis', 'linear-algebra', 'integration', 'measure-theory']"
88,What determines if a function has a least positive period?,What determines if a function has a least positive period?,,"This question stems from this one, where if $f$ is continuous and $f(x) = f(x+1) = f(x+\pi)$, then $f$ must be constant. The above is shown using the density of $\mathbb{Z}+\pi\mathbb{Z}$ in $\mathbb{R}$ and the continuity of $f$. However, what jumps out at me from the question is the (seeming) incongruity of a period that is both rational and irrational. Specifically, if $f$ is non-constant and has a least positive period, $T$, then it cannot be that $f(x)=f(x+1)=f(x+\pi)$, since that would imply that $\pi$ is rational. But, as was pointed out to me, this cannot be used to prove the above because not every periodic function has a least positive period. So my question is, what determines if a function has a least positive period? Are there certain classes of functions that, if periodic, must have a least positive period? For instance, continuous periodic functions? Also, what other examples are there of non-constant periodic functions that do not have a least positive period? The example given to me (and the only one given on the Wikipedia page ) is the indicator function of rational numbers.","This question stems from this one, where if $f$ is continuous and $f(x) = f(x+1) = f(x+\pi)$, then $f$ must be constant. The above is shown using the density of $\mathbb{Z}+\pi\mathbb{Z}$ in $\mathbb{R}$ and the continuity of $f$. However, what jumps out at me from the question is the (seeming) incongruity of a period that is both rational and irrational. Specifically, if $f$ is non-constant and has a least positive period, $T$, then it cannot be that $f(x)=f(x+1)=f(x+\pi)$, since that would imply that $\pi$ is rational. But, as was pointed out to me, this cannot be used to prove the above because not every periodic function has a least positive period. So my question is, what determines if a function has a least positive period? Are there certain classes of functions that, if periodic, must have a least positive period? For instance, continuous periodic functions? Also, what other examples are there of non-constant periodic functions that do not have a least positive period? The example given to me (and the only one given on the Wikipedia page ) is the indicator function of rational numbers.",,"['real-analysis', 'periodic-functions']"
89,Let $f :\mathbb{R}→ \mathbb{R}$ be a function such that $f^2$ and $f^3$ are differentiable. Is $f$ differentiable?,Let  be a function such that  and  are differentiable. Is  differentiable?,f :\mathbb{R}→ \mathbb{R} f^2 f^3 f,"Let $f :\mathbb{R}→ \mathbb{R}$ be a function such that $f^2$ and $f^3$ are differentiable. Is $f$ differentiable? Similarly, let $f :\mathbb{C}→ \mathbb{C}$ be a function such that $f^2$ and $f^3$ are analytic. Is $f$ analytic?","Let $f :\mathbb{R}→ \mathbb{R}$ be a function such that $f^2$ and $f^3$ are differentiable. Is $f$ differentiable? Similarly, let $f :\mathbb{C}→ \mathbb{C}$ be a function such that $f^2$ and $f^3$ are analytic. Is $f$ analytic?",,"['real-analysis', 'complex-analysis', 'functions', 'derivatives']"
90,Supremum of an union of bounded sets,Supremum of an union of bounded sets,,"Given $A$, $B$ are bounded subsets of $\Bbb R$.  Prove $A\cup B$ is bounded. $\sup(A \cup B) =\sup\{\sup A, \sup B\}$. Can anyone help with this proof?","Given $A$, $B$ are bounded subsets of $\Bbb R$.  Prove $A\cup B$ is bounded. $\sup(A \cup B) =\sup\{\sup A, \sup B\}$. Can anyone help with this proof?",,"['real-analysis', 'analysis']"
91,Differentiable at a point,Differentiable at a point,,"My roommates and I have an argument you guys can help to settle (peace is at stake, don't let us down!) In undergrad calculus courses, one usually explains what it means for a function to be differentiable at a point x, and then differentiable in a domain. Then the focus is entirely on this latter notion. My question is: Has the notion of differentiability at a point any interest? That is, I'm looking for a theorem which is valid for a function regular at some point, but which needs significantly less regularity in a neighborhood of this point, or a good reason for which such a theorem doesn't exist. Of course, this question is very flexible, and any insight is welcome.","My roommates and I have an argument you guys can help to settle (peace is at stake, don't let us down!) In undergrad calculus courses, one usually explains what it means for a function to be differentiable at a point x, and then differentiable in a domain. Then the focus is entirely on this latter notion. My question is: Has the notion of differentiability at a point any interest? That is, I'm looking for a theorem which is valid for a function regular at some point, but which needs significantly less regularity in a neighborhood of this point, or a good reason for which such a theorem doesn't exist. Of course, this question is very flexible, and any insight is welcome.",,"['calculus', 'real-analysis', 'soft-question', 'definition']"
92,How is the discrete metric continuous?,How is the discrete metric continuous?,,"It is proven that any metric $d$ is continuous.  Consider the metric space $(\mathbb{R}, d)$ where: $$d:\mathbb{R}\times\mathbb{R}\rightarrow \mathbb{R}$$ $$d(x, y) =  \begin{cases}        0 & x=y \\       1 & x\neq y    \end{cases} $$ Let $x_n \rightarrow x=0$ and $y_n \rightarrow y=0$ . If you take $d(x_n, y_n)\rightarrow 1 \neq 0=d(x, y)$ . This shows that this metric is discontinuous. What is wrong with my reasoning?",It is proven that any metric is continuous.  Consider the metric space where: Let and . If you take . This shows that this metric is discontinuous. What is wrong with my reasoning?,"d (\mathbb{R}, d) d:\mathbb{R}\times\mathbb{R}\rightarrow \mathbb{R} d(x, y) =  \begin{cases} 
      0 & x=y \\
      1 & x\neq y
   \end{cases}
 x_n \rightarrow x=0 y_n \rightarrow y=0 d(x_n, y_n)\rightarrow 1 \neq 0=d(x, y)","['real-analysis', 'continuity', 'metric-spaces']"
93,The Hahn-Banach Theorem for Hilbert Space,The Hahn-Banach Theorem for Hilbert Space,,"The Hahn-Banach Theorem for Normed Space: Let $X$ be a real or complex normed space and let $W$ be a linear subspace of $X$ . If $f_W \in W'$ (the dual of $W$ ), then there exists an extension $f \in X'$ such that $\|f\|=\|f_w\|$ . How if I extend to a Hilbert Space?","The Hahn-Banach Theorem for Normed Space: Let be a real or complex normed space and let be a linear subspace of . If (the dual of ), then there exists an extension such that . How if I extend to a Hilbert Space?",X W X f_W \in W' W f \in X' \|f\|=\|f_w\|,"['real-analysis', 'functional-analysis']"
94,Compute the integral $\int_{-1}^1 \frac{|x-y|^{\alpha}}{(1 - x^2)^{\frac{1+\alpha}{2}}}dx = \frac{\pi}{\cos(\pi \alpha/2)}$,Compute the integral,\int_{-1}^1 \frac{|x-y|^{\alpha}}{(1 - x^2)^{\frac{1+\alpha}{2}}}dx = \frac{\pi}{\cos(\pi \alpha/2)},"$$ \mbox{How to prove that}\ \int_{-R}^{R}\frac{\left\vert x - y\right\vert^{\alpha}} {\left(R^{2} - x^{2}\right)^{\large\left(1+\alpha\right)/2}} \,\mathrm{d}x = \frac{\pi}{\cos\left(\pi \alpha/2\right)}\ {\Large ?}, $$ where $-1 < \alpha < 1$ , $-R \le y \le R$ . Since the right hand side does not depend on $y$ , I suppose, there must be some physical interpretation. I'll be grateful for any hints.","where , . Since the right hand side does not depend on , I suppose, there must be some physical interpretation. I'll be grateful for any hints.","
\mbox{How to prove that}\
\int_{-R}^{R}\frac{\left\vert x - y\right\vert^{\alpha}}
{\left(R^{2} - x^{2}\right)^{\large\left(1+\alpha\right)/2}}
\,\mathrm{d}x = \frac{\pi}{\cos\left(\pi \alpha/2\right)}\
{\Large ?},
 -1 < \alpha < 1 -R \le y \le R y","['real-analysis', 'integration', 'definite-integrals']"
95,(Somewhat) generalised mean value theorem,(Somewhat) generalised mean value theorem,,"Problem. Let $f:\Bbb R\to\Bbb R$ be a continuous map. Let $n$ be a non-negative integer. Then show that there is $0<t_0<1$ such that   $$\int_0^1(1-t)^nf(t)\ dt=\frac{f(t_0)}{n+1}$$ For $n=0$ this can be proved by the mean value theorem. We define $g:\Bbb R\to\Bbb R$ as $g(x)=\int_0^xf(t)\ dt$. Since $f$ is continuous, $g$ is a differentiable map. So there is $0<t_0<1$ such that $g'(t_0)=g(1)-g(0)$, which gives $f(t_0)=\int_0^1f(t)\ dt$. But I am unable to prove this for $n>0$.","Problem. Let $f:\Bbb R\to\Bbb R$ be a continuous map. Let $n$ be a non-negative integer. Then show that there is $0<t_0<1$ such that   $$\int_0^1(1-t)^nf(t)\ dt=\frac{f(t_0)}{n+1}$$ For $n=0$ this can be proved by the mean value theorem. We define $g:\Bbb R\to\Bbb R$ as $g(x)=\int_0^xf(t)\ dt$. Since $f$ is continuous, $g$ is a differentiable map. So there is $0<t_0<1$ such that $g'(t_0)=g(1)-g(0)$, which gives $f(t_0)=\int_0^1f(t)\ dt$. But I am unable to prove this for $n>0$.",,"['real-analysis', 'integration', 'derivatives']"
96,When is the Composite with Cube Root Smooth,When is the Composite with Cube Root Smooth,,"Let $f:\mathbf R\to \mathbf R$ be a smooth map and $g:\mathbf R\to \mathbf R$ be defined as $g(x)=f(x^{1/3})$ for all $x\in \mathbf R$. Problem. Then $g$ is smooth if and only if $f^{(n)}(0)$ is $0$ whenever $n$ is not an integral multiple of $3$. One direction is easy. Assume $g$ is smooth. Then we have $f(x)=g(x^3)$ for all $x$. Differentiating and using the chain rule gives that the required derivatives of $f$ vanish. I am struggling with the converse. Assume $f^{(n)}(0)=0$ whenever $n$ is not an integral multiple of $3$. We need to show that $g$ is smooth. Since $x^{1/3}$ is smooth at all points except $x=0$, we see that $g$ too is so. So the only problem is at $0$. I am only able to show that the first derivative of $g$ at $0$ exists. Here is what I have done. Let $x>0$ be arbitrary. By Taylor we know that $$f(x)= f(0)+f'(0)x+ \frac{f''(0)}{2}x^2+ \frac{f'''(\lambda_x x)}{6}x^3$$ for some $0<\lambda_x<1$. This gives by hypothesis that $$f(x) - f(0) = \frac{f'''(\lambda_x x)}{6}x^3$$ Thus $$g(x)-g(0)=\frac{f'''(\lambda_{x^{1/3}} x^{1/3})}{6} x$$ and therefore $$\frac{g(x)-g(0)}{x}=\frac{f'''(\lambda_{x^{1/3}} x^{1/3})}{6}$$ Since $\lim_{x\to 0}f'''(\lambda_{x^{1/3}} x^{1/3}))$ exists, we see that $g'(0)$ exists. But I am not able to extend this argument to show that $g''(0)$ etc. also exist.","Let $f:\mathbf R\to \mathbf R$ be a smooth map and $g:\mathbf R\to \mathbf R$ be defined as $g(x)=f(x^{1/3})$ for all $x\in \mathbf R$. Problem. Then $g$ is smooth if and only if $f^{(n)}(0)$ is $0$ whenever $n$ is not an integral multiple of $3$. One direction is easy. Assume $g$ is smooth. Then we have $f(x)=g(x^3)$ for all $x$. Differentiating and using the chain rule gives that the required derivatives of $f$ vanish. I am struggling with the converse. Assume $f^{(n)}(0)=0$ whenever $n$ is not an integral multiple of $3$. We need to show that $g$ is smooth. Since $x^{1/3}$ is smooth at all points except $x=0$, we see that $g$ too is so. So the only problem is at $0$. I am only able to show that the first derivative of $g$ at $0$ exists. Here is what I have done. Let $x>0$ be arbitrary. By Taylor we know that $$f(x)= f(0)+f'(0)x+ \frac{f''(0)}{2}x^2+ \frac{f'''(\lambda_x x)}{6}x^3$$ for some $0<\lambda_x<1$. This gives by hypothesis that $$f(x) - f(0) = \frac{f'''(\lambda_x x)}{6}x^3$$ Thus $$g(x)-g(0)=\frac{f'''(\lambda_{x^{1/3}} x^{1/3})}{6} x$$ and therefore $$\frac{g(x)-g(0)}{x}=\frac{f'''(\lambda_{x^{1/3}} x^{1/3})}{6}$$ Since $\lim_{x\to 0}f'''(\lambda_{x^{1/3}} x^{1/3}))$ exists, we see that $g'(0)$ exists. But I am not able to extend this argument to show that $g''(0)$ etc. also exist.",,"['calculus', 'real-analysis', 'derivatives', 'smooth-manifolds']"
97,"If $ \int_0^{\pi}f(x)\cos(nx)\,dx=0$ for all $n$ then prove that $f\equiv 0$",If  for all  then prove that," \int_0^{\pi}f(x)\cos(nx)\,dx=0 n f\equiv 0","If $f:[0,\pi]\to \mathbb R$ is continuous and $f(0)=0$ such that $\displaystyle \int_0^{\pi}f(x)\cos(nx)\,dx=0$ for all $n=0,1,2,\cdots$ then prove that $f\equiv 0$ in $[0,\pi]$. I want to apply Weierstrass approximation theorem. As $f$ is continuous so there exists a sequence of polynomials $\{p_n(x)\}$ such that $p_n(x)\to f$ uniformly. If I expand $\cos nx=1+\frac{n^2x^2}{2!}+\cdots$ then $$\int_0^{\pi}f(x)\,dx+\frac{n^2}{2!}\int_0^{\pi}x^2f(x)\,dx+\cdots=0.$$which implies  $\displaystyle \int_0^{\pi}x^{2n}f(x)\,dx=0$ for each $n=0,1,2,\cdots$. Is this step correct ? If yes then I can deduce from it that $f\equiv 0$. If I am Not correct then solve it please.","If $f:[0,\pi]\to \mathbb R$ is continuous and $f(0)=0$ such that $\displaystyle \int_0^{\pi}f(x)\cos(nx)\,dx=0$ for all $n=0,1,2,\cdots$ then prove that $f\equiv 0$ in $[0,\pi]$. I want to apply Weierstrass approximation theorem. As $f$ is continuous so there exists a sequence of polynomials $\{p_n(x)\}$ such that $p_n(x)\to f$ uniformly. If I expand $\cos nx=1+\frac{n^2x^2}{2!}+\cdots$ then $$\int_0^{\pi}f(x)\,dx+\frac{n^2}{2!}\int_0^{\pi}x^2f(x)\,dx+\cdots=0.$$which implies  $\displaystyle \int_0^{\pi}x^{2n}f(x)\,dx=0$ for each $n=0,1,2,\cdots$. Is this step correct ? If yes then I can deduce from it that $f\equiv 0$. If I am Not correct then solve it please.",,"['real-analysis', 'integration', 'analysis', 'definite-integrals']"
98,What star domain has a non-star-domain interior?,What star domain has a non-star-domain interior?,,"Definition: We call a subset $S$ of $\mathbb{R}^n$ a star domain (or star-shaped ) if there exists a point $x_0 \in S$ such that for every $x \in S$, the line segment $\overline{x_0x}$ is contained in $S$. The Wikipedia page on star domains claims that The closure of a star domain is a star domain, but the interior of a star domain is not necessarily a star domain. I must be particularly unimaginative, as I find myself unable to come up with an example of a star domain whose interior is not a star domain. What is such an example?","Definition: We call a subset $S$ of $\mathbb{R}^n$ a star domain (or star-shaped ) if there exists a point $x_0 \in S$ such that for every $x \in S$, the line segment $\overline{x_0x}$ is contained in $S$. The Wikipedia page on star domains claims that The closure of a star domain is a star domain, but the interior of a star domain is not necessarily a star domain. I must be particularly unimaginative, as I find myself unable to come up with an example of a star domain whose interior is not a star domain. What is such an example?",,"['real-analysis', 'general-topology']"
99,"Show that there are $ a,b \geq 0 $ so that $ |f(x)| \leq ax+b, \forall x \geq 0.$",Show that there are  so that," a,b \geq 0   |f(x)| \leq ax+b, \forall x \geq 0.","I have the following exercise: $$f:[0, +\infty) \rightarrow \mathbb{R} \text{ uniformly continuous  } .$$ $$\text{Show that there are } a,b \geq 0 \text{ so that } |f(x)| \leq ax+b, \forall x \geq 0.$$ $$$$ $f:[0, +\infty) \rightarrow \mathbb{R} \text{ uniformly continuous  } :$ $\forall \epsilon >0 \exists \delta >0 \text{ such that } \forall x,y \in [0, + \infty) \text{ with } |x-y|< \delta \Rightarrow |f(x)-f(y)|<\epsilon$ $$$$ How can I continue??","I have the following exercise: $$f:[0, +\infty) \rightarrow \mathbb{R} \text{ uniformly continuous  } .$$ $$\text{Show that there are } a,b \geq 0 \text{ so that } |f(x)| \leq ax+b, \forall x \geq 0.$$ $$$$ $f:[0, +\infty) \rightarrow \mathbb{R} \text{ uniformly continuous  } :$ $\forall \epsilon >0 \exists \delta >0 \text{ such that } \forall x,y \in [0, + \infty) \text{ with } |x-y|< \delta \Rightarrow |f(x)-f(y)|<\epsilon$ $$$$ How can I continue??",,"['real-analysis', 'analysis', 'continuity', 'uniform-continuity']"
