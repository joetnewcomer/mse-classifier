,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Is every Banach space densely embedded in a Hilbert space?,Is every Banach space densely embedded in a Hilbert space?,,"Can every Banach space be densely embedded in a Hilbert space? This is clear if the Banach space is actually a Hilbert space, but much can you relax this? If the embedding exists, is the target Hilbert space unique?","Can every Banach space be densely embedded in a Hilbert space? This is clear if the Banach space is actually a Hilbert space, but much can you relax this? If the embedding exists, is the target Hilbert space unique?",,"['functional-analysis', 'hilbert-spaces', 'banach-spaces']"
1,Fourier transform of even/odd function,Fourier transform of even/odd function,,How can I show that the Fourier transform of an even integrable function $f\colon \mathbb{R}\to\mathbb{R}$ is even real-valued function? And the Fourier transform of an odd integrable function $f\colon \mathbb{R}\to\mathbb{R}$ is odd and purely imaginary function?,How can I show that the Fourier transform of an even integrable function $f\colon \mathbb{R}\to\mathbb{R}$ is even real-valued function? And the Fourier transform of an odd integrable function $f\colon \mathbb{R}\to\mathbb{R}$ is odd and purely imaginary function?,,"['functional-analysis', 'analysis', 'fourier-analysis', 'fourier-transform']"
2,Does an unbounded operator $T$ with non-empty spectrum have an unbounded spectrum?,Does an unbounded operator  with non-empty spectrum have an unbounded spectrum?,T,"It's well known that the spectrum of a bounded operator on a Banach space is a closed bounded set (and non-empty)on the complex plane. And it's also not hard to find unbounded operators which their spectrum are empty or the whole complex plane. Conversely, suppose $T$ is an unbounded operator on a Banach space $E$,and has non-empty spectrum, does this imply that the $\sigma(T)$ is unbounded on $\mathbb{C}$ ? As far as I known, if  $\sigma(T)$ is bounded,then it implied that $\infty$ is the essential singular point of the resolvent $(\lambda-T)^{-1}$, but I don't know how to form a contradiction.","It's well known that the spectrum of a bounded operator on a Banach space is a closed bounded set (and non-empty)on the complex plane. And it's also not hard to find unbounded operators which their spectrum are empty or the whole complex plane. Conversely, suppose $T$ is an unbounded operator on a Banach space $E$,and has non-empty spectrum, does this imply that the $\sigma(T)$ is unbounded on $\mathbb{C}$ ? As far as I known, if  $\sigma(T)$ is bounded,then it implied that $\infty$ is the essential singular point of the resolvent $(\lambda-T)^{-1}$, but I don't know how to form a contradiction.",,"['functional-analysis', 'operator-theory', 'spectral-theory']"
3,"Can spectrum ""specify"" an operator?","Can spectrum ""specify"" an operator?",,"Given a bounded operator $A$ on a Banach space $X$, one may find the spectrum $\sigma(A)\subset{\bf C}$. Here are my questions : Given some set in the complex plane, say, $S\subset{\bf C}$, can one find an operator $A$ such that $\sigma(A)=S$? Is there a ""big picture"" for this kind of questions?","Given a bounded operator $A$ on a Banach space $X$, one may find the spectrum $\sigma(A)\subset{\bf C}$. Here are my questions : Given some set in the complex plane, say, $S\subset{\bf C}$, can one find an operator $A$ such that $\sigma(A)=S$? Is there a ""big picture"" for this kind of questions?",,['soft-question']
4,Is a convex function always continuous?,Is a convex function always continuous?,,"It is well known that a convex function defined on $\mathbb{R}$ is continuous (it is even left and right differentiable. We can define a convex function for any normed vector space $E$ : a function $f : E\mapsto \mathbb{R}$ is said to be  convex iff $$f\big(\lambda x + (1-\lambda)y\big) \le \lambda f(x)+(1-\lambda)f(y)$$ I know that such a function is not necessarily continuous if $E$ has infinite dimension: $f$ can be a discontinuous linear form. For instance, if $E = \ell^2(\mathbb{N})$ the space of square summable sequences (endowed with the supremum norm $||\cdot||_{\infty}$ instead of its natural norm), and $f(u) = \sum \limits_{i \ge 1} \frac{u_i}{i}$ , then $f$ is linear, thus convex, yet it is known that $f$ is not continuous. Now my question is: what about finite dimensions? Does there exist a convex function $f : \mathbb{R}^2 \to \mathbb{R}$ which is not continuous? I know that there are discontinuous functions from $\mathbb{R}^2$ to $\mathbb{R}$ that have derivatives in every direction (that's a good start since this is a necessary condition !) but I don't know any that is convex.","It is well known that a convex function defined on is continuous (it is even left and right differentiable. We can define a convex function for any normed vector space : a function is said to be  convex iff I know that such a function is not necessarily continuous if has infinite dimension: can be a discontinuous linear form. For instance, if the space of square summable sequences (endowed with the supremum norm instead of its natural norm), and , then is linear, thus convex, yet it is known that is not continuous. Now my question is: what about finite dimensions? Does there exist a convex function which is not continuous? I know that there are discontinuous functions from to that have derivatives in every direction (that's a good start since this is a necessary condition !) but I don't know any that is convex.",\mathbb{R} E f : E\mapsto \mathbb{R} f\big(\lambda x + (1-\lambda)y\big) \le \lambda f(x)+(1-\lambda)f(y) E f E = \ell^2(\mathbb{N}) ||\cdot||_{\infty} f(u) = \sum \limits_{i \ge 1} \frac{u_i}{i} f f f : \mathbb{R}^2 \to \mathbb{R} \mathbb{R}^2 \mathbb{R},"['functional-analysis', 'convex-analysis']"
5,Intuition for Fredholm operators?,Intuition for Fredholm operators?,,"Alot of the material I'm reading lately seems to mention Fredholm operators and the 'Fredholm alternative' and operators being 'Fredholm of index $0$'. Can someone give me a high level overview of what's the reason for caring whether an operator is Fredholm or not? What does it enable us to do with the operator? Is being Fredholm of index $0$ a good thing or a bad thing? Would be prefer an operator to be, say, Fredholm of index $2$ for example?","Alot of the material I'm reading lately seems to mention Fredholm operators and the 'Fredholm alternative' and operators being 'Fredholm of index $0$'. Can someone give me a high level overview of what's the reason for caring whether an operator is Fredholm or not? What does it enable us to do with the operator? Is being Fredholm of index $0$ a good thing or a bad thing? Would be prefer an operator to be, say, Fredholm of index $2$ for example?",,"['functional-analysis', 'partial-differential-equations', 'operator-theory', 'integral-equations']"
6,Why do we distinguish the continuous spectrum and the residual spectrum?,Why do we distinguish the continuous spectrum and the residual spectrum?,,"As we know, continuous spectrum and residual spectrum are two cases in the spectrum of an operator, which only appear in infinite dimension. If $T$ is a operator from Banach space $X$ to $X$, $aI-T$ is injective, and $R(aI-T)$ is not $X$. If $R(aI-T)$ is dense in $X$, then $a$ belongs to the continuous specturm, it not, $a$ belongs to the residual spectrum. I want to know why do we care about whether $R(aI-T)$ is dense, thanks.","As we know, continuous spectrum and residual spectrum are two cases in the spectrum of an operator, which only appear in infinite dimension. If $T$ is a operator from Banach space $X$ to $X$, $aI-T$ is injective, and $R(aI-T)$ is not $X$. If $R(aI-T)$ is dense in $X$, then $a$ belongs to the continuous specturm, it not, $a$ belongs to the residual spectrum. I want to know why do we care about whether $R(aI-T)$ is dense, thanks.",,"['functional-analysis', 'operator-theory', 'spectral-theory']"
7,How to develop an intuitive feel for spaces,How to develop an intuitive feel for spaces,,"I'm a physicist who's currently delving deeper into what I would call more 'hardcore' maths (e.g. FEM and control theory). Every now and then, I come across various spaces, such as vector spaces, Hilbert spaces, Hardy spaces, Banach spaces, topological spaces etc. I can read the definition, and sometimes I understand it, other times I don't (even the wikipedia articles can sometimes be very technical). But more importantly, I very rarely have an intuitive understanding of what these spaces really represent. Why are they important? What makes them different from another space? Should I really care? Are there any good (online) sources or tricks of the trade to wrap your head around the important things about a newly encountered space? I don't think I will ever delve deep enough into this to be really proficient with the underlying maths, but I would love to be able to distinguish the importance and meaning of these spaces... I've put some semi-sensical tags on this question, but anyone with more knowledge is welcome to change the tags to something more useful.","I'm a physicist who's currently delving deeper into what I would call more 'hardcore' maths (e.g. FEM and control theory). Every now and then, I come across various spaces, such as vector spaces, Hilbert spaces, Hardy spaces, Banach spaces, topological spaces etc. I can read the definition, and sometimes I understand it, other times I don't (even the wikipedia articles can sometimes be very technical). But more importantly, I very rarely have an intuitive understanding of what these spaces really represent. Why are they important? What makes them different from another space? Should I really care? Are there any good (online) sources or tricks of the trade to wrap your head around the important things about a newly encountered space? I don't think I will ever delve deep enough into this to be really proficient with the underlying maths, but I would love to be able to distinguish the importance and meaning of these spaces... I've put some semi-sensical tags on this question, but anyone with more knowledge is welcome to change the tags to something more useful.",,"['functional-analysis', 'vector-spaces', 'metric-spaces', 'normed-spaces', 'intuition']"
8,Is the convex hull of a compact set compact?,Is the convex hull of a compact set compact?,,"Let $V$ be a normed vector space and $K$ a compact subset of $V$ . Is the convex hull of $K$ given by $$\langle K \rangle = \left\{\sum_{i=1}^n t_i x_i\mid x_i\in K, t_i≥0\text{ s.t. }\sum_i t_i=1\right\}$$ again compact?",Let be a normed vector space and a compact subset of . Is the convex hull of given by again compact?,"V K V K \langle K \rangle = \left\{\sum_{i=1}^n t_i x_i\mid x_i\in K, t_i≥0\text{ s.t. }\sum_i t_i=1\right\}","['functional-analysis', 'representation-theory', 'convex-analysis', 'compactness', 'normed-spaces']"
9,Spectrum of shift-operator,Spectrum of shift-operator,,"Hoi, consider the Hilbertspace $l^2$ and the Left and Right-shift operator \begin{align*} L(x_1,x_2,\cdots) &= (x_2,x_3,\cdots)\\ R(x_1,x_2,\cdots) &= (0,x_1,x_2,\cdots ) \end{align*} I know that $L^*=R$ so these operators are Hilbert-space adjoints. The spectrum consists of 3 disjoint parts $\sigma(T) = \sigma_p(T)\cup \sigma_c(T)\cup \sigma_r(T)$. Assuming you are familiar with these notions: $\sigma_p(T)$ is point-spectrum, $\sigma_c(T)$ is continuous spectrum and $\sigma_r(T)$ the residual spectrum. I want to show that $$\sigma_p(L) = \sigma_r(R) = \{\lambda :|\lambda|<1\} $$ $$\sigma_c(L)=\sigma_c(R) = \{\lambda : |\lambda|=1\} $$ $$\sigma_r(L)=\sigma_p(R) =\emptyset. $$ I stumbled upon a few problems. I can see that $\rho(L),\rho(R)<1$ so that $\{\lambda: |\lambda|>1\}$ is contained in the resolvent-sets of both $L$, and $R$. I can calculate the point-spectrum for $L$, and $R$. So for $L$ i can calculate $\sigma_p(L)=\{\lambda : |\lambda|<1\} $ and since $\sigma(L)$ is closed, and $\{\lambda: |\lambda|>1\}$ is contained in the resolvent-set of $L$ we find that $\sigma(L) = \{\lambda: |\lambda| \leq 1\}$. Thus $$\sigma_c(L)\cup \sigma_r(L)= \{\lambda: |\lambda | =1\}. $$ Apparantly I can use the fact that $L$, and $R$ are eachothers adjoints, and reading the internet I found that $\sigma(T) = \sigma(T^*)$, or something like $\lambda \in \sigma(T) $implies $\overline{\lambda}\in \sigma(T^*)$ which is something i can't prove. I hoped to be able to use this fact by some Theorem in Rudin. (this excercise is also from Rudin CH. 12 excercise 18.c) Apparantly the fact that $\lambda \in \sigma_r(L)$ implies that $\overline{\lambda}\in \sigma_p(L^*) = \sigma_p(R) = \emptyset$, so that we can conclude that $\sigma_r(L)=\emptyset$. I dont understand this at all. Can someone explain this a little bit? How to go on from here?  Thanks in advance.","Hoi, consider the Hilbertspace $l^2$ and the Left and Right-shift operator \begin{align*} L(x_1,x_2,\cdots) &= (x_2,x_3,\cdots)\\ R(x_1,x_2,\cdots) &= (0,x_1,x_2,\cdots ) \end{align*} I know that $L^*=R$ so these operators are Hilbert-space adjoints. The spectrum consists of 3 disjoint parts $\sigma(T) = \sigma_p(T)\cup \sigma_c(T)\cup \sigma_r(T)$. Assuming you are familiar with these notions: $\sigma_p(T)$ is point-spectrum, $\sigma_c(T)$ is continuous spectrum and $\sigma_r(T)$ the residual spectrum. I want to show that $$\sigma_p(L) = \sigma_r(R) = \{\lambda :|\lambda|<1\} $$ $$\sigma_c(L)=\sigma_c(R) = \{\lambda : |\lambda|=1\} $$ $$\sigma_r(L)=\sigma_p(R) =\emptyset. $$ I stumbled upon a few problems. I can see that $\rho(L),\rho(R)<1$ so that $\{\lambda: |\lambda|>1\}$ is contained in the resolvent-sets of both $L$, and $R$. I can calculate the point-spectrum for $L$, and $R$. So for $L$ i can calculate $\sigma_p(L)=\{\lambda : |\lambda|<1\} $ and since $\sigma(L)$ is closed, and $\{\lambda: |\lambda|>1\}$ is contained in the resolvent-set of $L$ we find that $\sigma(L) = \{\lambda: |\lambda| \leq 1\}$. Thus $$\sigma_c(L)\cup \sigma_r(L)= \{\lambda: |\lambda | =1\}. $$ Apparantly I can use the fact that $L$, and $R$ are eachothers adjoints, and reading the internet I found that $\sigma(T) = \sigma(T^*)$, or something like $\lambda \in \sigma(T) $implies $\overline{\lambda}\in \sigma(T^*)$ which is something i can't prove. I hoped to be able to use this fact by some Theorem in Rudin. (this excercise is also from Rudin CH. 12 excercise 18.c) Apparantly the fact that $\lambda \in \sigma_r(L)$ implies that $\overline{\lambda}\in \sigma_p(L^*) = \sigma_p(R) = \emptyset$, so that we can conclude that $\sigma_r(L)=\emptyset$. I dont understand this at all. Can someone explain this a little bit? How to go on from here?  Thanks in advance.",,"['functional-analysis', 'operator-theory', 'spectral-theory']"
10,Existence theorem on weak solutions of ordinary differential equations,Existence theorem on weak solutions of ordinary differential equations,,"Consider an ordinary vector-valued differential equation of the form $$ \begin{align*} \dot y(t) &= f(t,y(t)), \\ y(0) &= y_0 \in \mathbb{R}^n. \end{align*} $$ It is well known that if $f$ is continuous and furthermore Lipschitz continuous in an appropriate sense, then there exists a unique solution $y \in C^1([0,T], \mathbb{R}^n)$ satisfying the differential equation at every point of the time interval $(0,T)$ (Picard–Lindelöf). The question: Which general assumptions on $f$ ensure solvability in a (Sobolev) weak sense ? In particular, I want the solution $y$ to be in $H^1 = W^{1,2}$, i.e. $y$ should be $L^2$, $y$ should be weakly differentiable, $y'$ should be $L^2$ and the weak derivative of $y$ should coincide with $f(t,y(t))$ almost everywhere. This should be an extremely basic question, but I do not know relevant literature. [I seem to have an existence proof in the case $f(t,y) = A(t) y$, where $A \in L^2([0,T], \mathbb{R}^{n \times n})$, by mimicking the usual proof of the Picard–Lindelöf theorem and simply considering the usual integral operator as an operator $L^2([0,T], \mathbb{R}^n) \to L^2([0,T], \mathbb{R}^n)$. This case is particularly important to me. Note that here, $f(t,y)$ is not continuous in $t$.]","Consider an ordinary vector-valued differential equation of the form $$ \begin{align*} \dot y(t) &= f(t,y(t)), \\ y(0) &= y_0 \in \mathbb{R}^n. \end{align*} $$ It is well known that if $f$ is continuous and furthermore Lipschitz continuous in an appropriate sense, then there exists a unique solution $y \in C^1([0,T], \mathbb{R}^n)$ satisfying the differential equation at every point of the time interval $(0,T)$ (Picard–Lindelöf). The question: Which general assumptions on $f$ ensure solvability in a (Sobolev) weak sense ? In particular, I want the solution $y$ to be in $H^1 = W^{1,2}$, i.e. $y$ should be $L^2$, $y$ should be weakly differentiable, $y'$ should be $L^2$ and the weak derivative of $y$ should coincide with $f(t,y(t))$ almost everywhere. This should be an extremely basic question, but I do not know relevant literature. [I seem to have an existence proof in the case $f(t,y) = A(t) y$, where $A \in L^2([0,T], \mathbb{R}^{n \times n})$, by mimicking the usual proof of the Picard–Lindelöf theorem and simply considering the usual integral operator as an operator $L^2([0,T], \mathbb{R}^n) \to L^2([0,T], \mathbb{R}^n)$. This case is particularly important to me. Note that here, $f(t,y)$ is not continuous in $t$.]",,"['functional-analysis', 'ordinary-differential-equations', 'sobolev-spaces']"
11,What is the square root of a Fourier transform?,What is the square root of a Fourier transform?,,Given the Fourier transform defined like $$ \mathcal F[f](\omega) = \frac{1}{\sqrt{2 \pi}} \int_{-\infty}^\infty f(t) e^{-iwt} \mathrm{d}t $$ how could one define a square root $\mathcal G$ of the operator $\mathcal F$ so that  $$ \mathcal G^2[f] = F[f] $$ My idea is to literally take the square root of $\mathcal F$ like $$ \mathcal G[f](\omega) = \sqrt{\mathcal F[f](\omega)} = \sqrt{\frac{1}{\sqrt{2 \pi}} \int_{-\infty}^\infty f(t) e^{-iwt} \mathrm{d}t} = \frac{1}{\sqrt{\sqrt{2 \pi}}} \int_{-\infty}^\infty \sqrt{f(t)} e^{-\frac{iwt}{2}} \mathrm{d}t $$ Then the square of $\mathcal G[f]$ would be $$ \mathcal G^2[f](\omega) = \frac{1}{\sqrt{\sqrt{2 \pi}}} \frac{1}{\sqrt{\sqrt{2 \pi}}} \int_{-\infty}^\infty \int_{-\infty}^\infty \sqrt{f(t)} \sqrt{f(t')} e^{-\frac{iwt}{2}} e^{-\frac{iw't'}{2}} dt' dt $$ But this doesn't quite equate to $\mathcal F[f]$ again. So I guess my approach of literally taking the square root is a bit too naive. How then could one define the square root of a Fourier transform?,Given the Fourier transform defined like $$ \mathcal F[f](\omega) = \frac{1}{\sqrt{2 \pi}} \int_{-\infty}^\infty f(t) e^{-iwt} \mathrm{d}t $$ how could one define a square root $\mathcal G$ of the operator $\mathcal F$ so that  $$ \mathcal G^2[f] = F[f] $$ My idea is to literally take the square root of $\mathcal F$ like $$ \mathcal G[f](\omega) = \sqrt{\mathcal F[f](\omega)} = \sqrt{\frac{1}{\sqrt{2 \pi}} \int_{-\infty}^\infty f(t) e^{-iwt} \mathrm{d}t} = \frac{1}{\sqrt{\sqrt{2 \pi}}} \int_{-\infty}^\infty \sqrt{f(t)} e^{-\frac{iwt}{2}} \mathrm{d}t $$ Then the square of $\mathcal G[f]$ would be $$ \mathcal G^2[f](\omega) = \frac{1}{\sqrt{\sqrt{2 \pi}}} \frac{1}{\sqrt{\sqrt{2 \pi}}} \int_{-\infty}^\infty \int_{-\infty}^\infty \sqrt{f(t)} \sqrt{f(t')} e^{-\frac{iwt}{2}} e^{-\frac{iw't'}{2}} dt' dt $$ But this doesn't quite equate to $\mathcal F[f]$ again. So I guess my approach of literally taking the square root is a bit too naive. How then could one define the square root of a Fourier transform?,,"['functional-analysis', 'fourier-analysis', 'fourier-transform']"
12,The direct sum of two closed subspace is closed? (Hilbert space),The direct sum of two closed subspace is closed? (Hilbert space),,"I know that if $X$ is a Banach space, then, the direct sum of two closed subspace $X_1$ and $X_2$ is not necessarily closed. But what if $X$ is Hilbert? I assume there is something to do with the orthonormal basis, since this is something you can ask for a Hilbert space but not a Banach space. Moreover, is the projection to $X_1$ bounded? Namely, $P$ is defined on $X_1\oplus X_2$: $$P(x)=x\quad \text{on $X_1$} \qquad P(x)=0\quad \text{on $X_2$}$$ is $P$ bounded?","I know that if $X$ is a Banach space, then, the direct sum of two closed subspace $X_1$ and $X_2$ is not necessarily closed. But what if $X$ is Hilbert? I assume there is something to do with the orthonormal basis, since this is something you can ask for a Hilbert space but not a Banach space. Moreover, is the projection to $X_1$ bounded? Namely, $P$ is defined on $X_1\oplus X_2$: $$P(x)=x\quad \text{on $X_1$} \qquad P(x)=0\quad \text{on $X_2$}$$ is $P$ bounded?",,"['functional-analysis', 'hilbert-spaces', 'examples-counterexamples']"
13,Direct approach to the Closed Graph Theorem,Direct approach to the Closed Graph Theorem,,"In the context of Banach spaces, the Closed Graph Theorem and the Open Mapping Theorem are equivalent. It seems that usually one proves the Open Mapping Theorem using the Baire Category Theorem , and then, from this theorem, proves the Closed Graph Theorem . I was wondering about a more direct approach to the Closed Graph Theorem. What I want to show, possibly using the Baire Category Theorem, but without the Closed Graph Theorem or any of its equivalent theorems, that if $T: X \to Y$ is not continuous, then, there is a convergent sequence $x_n \rightarrow x$ such that $T x_n \rightarrow y \neq Tx$. Of course, $X$ and $Y$ are Banach Spaces. Because $T$ is not bounded, I know that there is a sequence $a_n$ of unitary vectors such that $T a_n \rightarrow \infty$. Now, taking $b_n = \frac{a_n}{\|T a_n\|}$, we have that $b_n \rightarrow 0$, and $\|T b_n\| = 1$. I wonder, if there is a simple argument for constructing a $x_n \rightarrow x$, based on $a_n$ or $b_n$, such that $T x_n$ is a Cauchy Sequence , but such that $\|T x_n\|$ is ""far from"" $\|T x\|$. Of course, $x_n$'s construction would have to use the fact that $X$ is complete. For example, $x$ could be the limit of an absolutely convergent sequence, pretty much in the same fashion as the construction in the proof of the Open Mapping Theorem.","In the context of Banach spaces, the Closed Graph Theorem and the Open Mapping Theorem are equivalent. It seems that usually one proves the Open Mapping Theorem using the Baire Category Theorem , and then, from this theorem, proves the Closed Graph Theorem . I was wondering about a more direct approach to the Closed Graph Theorem. What I want to show, possibly using the Baire Category Theorem, but without the Closed Graph Theorem or any of its equivalent theorems, that if $T: X \to Y$ is not continuous, then, there is a convergent sequence $x_n \rightarrow x$ such that $T x_n \rightarrow y \neq Tx$. Of course, $X$ and $Y$ are Banach Spaces. Because $T$ is not bounded, I know that there is a sequence $a_n$ of unitary vectors such that $T a_n \rightarrow \infty$. Now, taking $b_n = \frac{a_n}{\|T a_n\|}$, we have that $b_n \rightarrow 0$, and $\|T b_n\| = 1$. I wonder, if there is a simple argument for constructing a $x_n \rightarrow x$, based on $a_n$ or $b_n$, such that $T x_n$ is a Cauchy Sequence , but such that $\|T x_n\|$ is ""far from"" $\|T x\|$. Of course, $x_n$'s construction would have to use the fact that $X$ is complete. For example, $x$ could be the limit of an absolutely convergent sequence, pretty much in the same fashion as the construction in the proof of the Open Mapping Theorem.",,"['functional-analysis', 'banach-spaces', 'alternative-proof']"
14,Hahn-Banach theorem: 2 versions,Hahn-Banach theorem: 2 versions,,"I have a question regarding the Hahn-Banach Theorem. Let the analytical version be defined as: Let $E$ be a vector space, $p: E \rightarrow \mathbb{R}$ be a sublinear function and $F$ be a subspace of E. Let $f: F\rightarrow \mathbb{R}$ be a linear function dominated by $p$ (by which I mean $\forall x \in F: f(x) \leq p(x)$). Then $f$ has a linear extension $g$ to $E$ with $g$ dominated by $p$. Let the geometric version of Hahn-Banach Theorem be defined as: Let $E$ be a topological vector space, $\emptyset \neq A \subset E$ be open and convex. Let $M = V + x$ with $V$ a subspace of $E$ and $x \in E$. Suppose that $A \cap M = \emptyset$. Then there exists a closed hyperplane $H$ such that $M \subset H$ and $H \cap A = \emptyset$. Now, I know that the analytical version is proved using Zorn's Lemma and that the geometric version can be derived from the analytical version. My question is: can the analytical version be derived from the geometric version ? I don't have a clue how to begin to prove this. (These versions hold for arbitrary vector spaces, not just finite dimensional ones). Any help will be appreciated.","I have a question regarding the Hahn-Banach Theorem. Let the analytical version be defined as: Let $E$ be a vector space, $p: E \rightarrow \mathbb{R}$ be a sublinear function and $F$ be a subspace of E. Let $f: F\rightarrow \mathbb{R}$ be a linear function dominated by $p$ (by which I mean $\forall x \in F: f(x) \leq p(x)$). Then $f$ has a linear extension $g$ to $E$ with $g$ dominated by $p$. Let the geometric version of Hahn-Banach Theorem be defined as: Let $E$ be a topological vector space, $\emptyset \neq A \subset E$ be open and convex. Let $M = V + x$ with $V$ a subspace of $E$ and $x \in E$. Suppose that $A \cap M = \emptyset$. Then there exists a closed hyperplane $H$ such that $M \subset H$ and $H \cap A = \emptyset$. Now, I know that the analytical version is proved using Zorn's Lemma and that the geometric version can be derived from the analytical version. My question is: can the analytical version be derived from the geometric version ? I don't have a clue how to begin to prove this. (These versions hold for arbitrary vector spaces, not just finite dimensional ones). Any help will be appreciated.",,"['functional-analysis', 'topological-vector-spaces', 'alternative-proof']"
15,A closed subspace of a reflexive Banach space is reflexive,A closed subspace of a reflexive Banach space is reflexive,,"Let $X$ be a reflexive Banach Space. Let $Y$ be a closed subspace of it.I need to show that $Y$ is reflexive as well. So as usual I consider the inclusion map $$J: Y \to Y'', J(y)=j_{y}, j_{y}(y')=y'(y)$$, where $Y''$ denotes the bidual space of $Y$. I need to show that the map is onto because everything else is guaranteed (one-one and isometry) I pick an element say $y^{**} \in Y''$, then define $\tilde{y} \in X''$ such that $\tilde{y}(x')=y^{**}(x'|_{Y})$. Then it is well-defined, linear, continuous. Since $X$ is reflexive there is $x \in X$ such that $j_{x}=\tilde{y}$. Suppose that $x \not \in Y$. Then since $Y$ is closed, by Hahn-Banach theorem, there is $f:X \to K$ such that $f(x)=1$ and $f|_{Y}=0$. Then $\tilde{y}(f)=f(x)=1=y^{**}(0)=0$ which can't happen. Thus $x=y \in Y$ I need to show that $j_{y}=y^{**}$.","Let $X$ be a reflexive Banach Space. Let $Y$ be a closed subspace of it.I need to show that $Y$ is reflexive as well. So as usual I consider the inclusion map $$J: Y \to Y'', J(y)=j_{y}, j_{y}(y')=y'(y)$$, where $Y''$ denotes the bidual space of $Y$. I need to show that the map is onto because everything else is guaranteed (one-one and isometry) I pick an element say $y^{**} \in Y''$, then define $\tilde{y} \in X''$ such that $\tilde{y}(x')=y^{**}(x'|_{Y})$. Then it is well-defined, linear, continuous. Since $X$ is reflexive there is $x \in X$ such that $j_{x}=\tilde{y}$. Suppose that $x \not \in Y$. Then since $Y$ is closed, by Hahn-Banach theorem, there is $f:X \to K$ such that $f(x)=1$ and $f|_{Y}=0$. Then $\tilde{y}(f)=f(x)=1=y^{**}(0)=0$ which can't happen. Thus $x=y \in Y$ I need to show that $j_{y}=y^{**}$.",,"['functional-analysis', 'weak-convergence', 'duality-theorems']"
16,"Compact Metric Spaces and Separability of $C(X,\mathbb{R})$ [duplicate]",Compact Metric Spaces and Separability of  [duplicate],"C(X,\mathbb{R})","This question already has an answer here : $C(X)$ is separable when $X$ is compact? (1 answer) Closed 5 years ago . Let $(X,d)$ be a compact metric space. Show that $C(X,\mathbb{R})$ is a separable metric space (space of continuous functions from $X$ to $\mathbb{R}$). I first showed that if $(X,d)$ is compact, then it must be separable, so we have a dense subset $\{x_{1},x_{2},...\}$ which is countable of $X$. Then, I'm not so sure on how to move forward. I was thinking of using the Stone Weierstrass Theorem for the set of functions: $F=\{1,f_{1},f_{2},...\}$ Where $f_{n}(x)=d(x,x_{n})$ for $x \in X$. Then, this implies that the above set is dense in $C(X,\mathbb{R})$ and countable, so $C(X,\mathbb{R})$ is separable if $F$ is a unital separating subalgebra. Clearly $F$ is unital, but I'm not sure on how to show it is separating and a subalgebra of $C(X,\mathbb{R})$ (it is a subset of the former set since the distance function is continuous). How would one proceed with this step? Thank you for your help.","This question already has an answer here : $C(X)$ is separable when $X$ is compact? (1 answer) Closed 5 years ago . Let $(X,d)$ be a compact metric space. Show that $C(X,\mathbb{R})$ is a separable metric space (space of continuous functions from $X$ to $\mathbb{R}$). I first showed that if $(X,d)$ is compact, then it must be separable, so we have a dense subset $\{x_{1},x_{2},...\}$ which is countable of $X$. Then, I'm not so sure on how to move forward. I was thinking of using the Stone Weierstrass Theorem for the set of functions: $F=\{1,f_{1},f_{2},...\}$ Where $f_{n}(x)=d(x,x_{n})$ for $x \in X$. Then, this implies that the above set is dense in $C(X,\mathbb{R})$ and countable, so $C(X,\mathbb{R})$ is separable if $F$ is a unital separating subalgebra. Clearly $F$ is unital, but I'm not sure on how to show it is separating and a subalgebra of $C(X,\mathbb{R})$ (it is a subset of the former set since the distance function is continuous). How would one proceed with this step? Thank you for your help.",,"['functional-analysis', 'metric-spaces', 'compactness']"
17,Fast convergence in $L^1$ implies convergence almost everywhere,Fast convergence in  implies convergence almost everywhere,L^1,"This is a proof-verification request. Claim: Let $(X,\mathscr M,\mu)$ be a measure space. Let $f_n$ ($n\in\mathbb N$) and $f$ be measurable, integrable, real-valued functions such that $(f_n)_{n\in\mathbb N}$ converges to $f$ in $L^1$ at a rate $O(1/n^p)$, where $p>1$. Then, $f_n\to f$ almost everywhere. Note: If no assumption is made on the rate of convergence, then the best one can establish is the existence of a $\textit{sub}$sequence $(f_{n_k})_{k\in\mathbb N}$ converging to $f$ almost everywhere (Corollary 2.32 in Folland, 1999 ). Proof of the Claim: Suppose there exists $M>0$ such that $\int|f_n-f|\,\mathrm d\mu\leq M/n^p$ for all $n\in\mathbb N$. For each $\varepsilon>0$ and $n\in\mathbb N$, let $$E(n,\varepsilon)\equiv \big\{x\in X\,\big|\,|f_n(x)-f(x)|\geq\varepsilon\big\}.$$ Then, $$\frac {M}{n^p}\geq\int|f_n-f|\,\mathrm d\mu\geq \int_{E(n,\varepsilon)}|f_n-f|\,\mathrm d\mu\geq\varepsilon\,\mu(E(n,\varepsilon))$$ for each $n\in\mathbb N$, so that $$\mu(E(n,\varepsilon))\leq\frac{M}{n^p\varepsilon}.$$ Defining $$E(\varepsilon)\equiv\bigcap_{m=1}^{\infty}\bigcup_{n=m}^{\infty}E(n,\varepsilon),$$ one has that $$\mu(E(\varepsilon))\underset{\forall m\in\mathbb N}{\leq}\mu\left(\bigcup_{n=m}^{\infty}E(n,\varepsilon)\right)\leq\sum_{n=m}^{\infty}\mu(E(n,\varepsilon))\leq\frac{M}{\varepsilon}\sum_{n=m}^{\infty}\frac{1}{n^p}\to0\quad\text{as $m\to\infty$},$$ since the series $\sum_{n=1}^{\infty}1/n^{p}=\zeta(p)$ converges. Therefore, $\mu(E(\varepsilon))=0$ for any $\varepsilon>0$, which implies also that $$\mu\left(\bigcup_{q\in\mathbb Q\cap(0,\infty)}E(q)\right)=0.$$ Now, if $x\in X$ is such that $f_n(x)\not\to f(x)$, then there exists some $q>0$ such that $q\in\mathbb Q$ and for each $m\in\mathbb N$, there exists some $n\geq m$ so that $|f_n(x)-f(x)|\geq q$. That is, $x\in E(q)$. Hence, the set where pointwise convergence fails is a subset of $\bigcup_{q\in\mathbb Q\cap(0,\infty)}E(q)$, completing the proof. $\quad\blacksquare$","This is a proof-verification request. Claim: Let $(X,\mathscr M,\mu)$ be a measure space. Let $f_n$ ($n\in\mathbb N$) and $f$ be measurable, integrable, real-valued functions such that $(f_n)_{n\in\mathbb N}$ converges to $f$ in $L^1$ at a rate $O(1/n^p)$, where $p>1$. Then, $f_n\to f$ almost everywhere. Note: If no assumption is made on the rate of convergence, then the best one can establish is the existence of a $\textit{sub}$sequence $(f_{n_k})_{k\in\mathbb N}$ converging to $f$ almost everywhere (Corollary 2.32 in Folland, 1999 ). Proof of the Claim: Suppose there exists $M>0$ such that $\int|f_n-f|\,\mathrm d\mu\leq M/n^p$ for all $n\in\mathbb N$. For each $\varepsilon>0$ and $n\in\mathbb N$, let $$E(n,\varepsilon)\equiv \big\{x\in X\,\big|\,|f_n(x)-f(x)|\geq\varepsilon\big\}.$$ Then, $$\frac {M}{n^p}\geq\int|f_n-f|\,\mathrm d\mu\geq \int_{E(n,\varepsilon)}|f_n-f|\,\mathrm d\mu\geq\varepsilon\,\mu(E(n,\varepsilon))$$ for each $n\in\mathbb N$, so that $$\mu(E(n,\varepsilon))\leq\frac{M}{n^p\varepsilon}.$$ Defining $$E(\varepsilon)\equiv\bigcap_{m=1}^{\infty}\bigcup_{n=m}^{\infty}E(n,\varepsilon),$$ one has that $$\mu(E(\varepsilon))\underset{\forall m\in\mathbb N}{\leq}\mu\left(\bigcup_{n=m}^{\infty}E(n,\varepsilon)\right)\leq\sum_{n=m}^{\infty}\mu(E(n,\varepsilon))\leq\frac{M}{\varepsilon}\sum_{n=m}^{\infty}\frac{1}{n^p}\to0\quad\text{as $m\to\infty$},$$ since the series $\sum_{n=1}^{\infty}1/n^{p}=\zeta(p)$ converges. Therefore, $\mu(E(\varepsilon))=0$ for any $\varepsilon>0$, which implies also that $$\mu\left(\bigcup_{q\in\mathbb Q\cap(0,\infty)}E(q)\right)=0.$$ Now, if $x\in X$ is such that $f_n(x)\not\to f(x)$, then there exists some $q>0$ such that $q\in\mathbb Q$ and for each $m\in\mathbb N$, there exists some $n\geq m$ so that $|f_n(x)-f(x)|\geq q$. That is, $x\in E(q)$. Hence, the set where pointwise convergence fails is a subset of $\bigcup_{q\in\mathbb Q\cap(0,\infty)}E(q)$, completing the proof. $\quad\blacksquare$",,"['functional-analysis', 'measure-theory', 'proof-verification']"
18,Gradient Estimate - Question about Inequality vs. Equality sign in one part,Gradient Estimate - Question about Inequality vs. Equality sign in one part,,"$\DeclareMathOperator{\diam}{diam}\newcommand{\norm}[1]{\lVert#1\rVert}\newcommand{\abs}[1]{\lvert#1\rvert}$For $u \in C^{1}(\overline{\Omega})$, for $\Omega\subset \subset \mathbb{R^{n}}$ a bounded convex set, and for any $1 \leq p \leq q$ such that $\frac{1}{p}-\frac{1}{q}<\frac{1}{n}$, I need to show that $$ \norm{u-\overline{u}_{\Omega}}_{L^{q}} \leq c_{n} \left[ \frac{1+\frac{1}{q} - \frac{1}{p}}{\frac{1}{n}+\frac{1}{q}-\frac{1}{p}}\right]^{1+\frac{1}{q}-\frac{1}{p}}  \cdot \frac{(\diam \Omega)^{n}}{\abs\Omega^{1-\frac{1}{n}+\frac{1}{p}-\frac{1}{q}}}\norm{Du}_{L^{p}(\Omega)}, $$ For context, this is a part (c) to a problem where in part (a), we were asked to show that $$ \abs{u(x)-\overline{u}_{\Omega}} \leq \frac{(\diam \Omega)^{n}}{n \abs{\Omega}}\int_{\Omega}\frac{\abs{Du(y)}}{\abs{x-y}^{n-1}}dy $$ for any function $u \in C^{1}(\overline{\Omega})$ and any point $x \in \Omega$, and in part (b), we were asked to show that if $u$ and $v$ were any two functions on $\Omega$ related as follows: $$\abs{u(x)}\leq \int_{\Omega}K(x,y) \abs{v(y)} \, dy, \quad x\in \Omega$$ for some kernel $K(x,y)$, then for any $1 \leq p \leq q \leq \infty$, we have $$\norm u_{L^{q}(\Omega)} \leq A \norm v_{L^{p}(\Omega)},$$ where $\displaystyle A = \max\left(\sup_{x}\norm{K(x,\cdot)}_{L^{\frac{pq}{pq+p-q}}}, \sup_{y}\norm{K(\cdot,y)}_{L^{\frac{pq}{pq+p-q}}}\right)$. We are told to assume the integral estimate that $$\int_{\Omega}\abs{x-y}^{-n\mu}dy \leq c_{n}\frac{1}{1-\mu}\abs{\Omega}^{1-\mu}$$ for any $0 \leq \mu < 1$, where $c_{n}$ is a constant dependent only on the dimension $n$. Here is how I did the problem: By part (a), we have that $\displaystyle \abs{u(x)-\overline{u}_{\Omega}}\leq \frac{(\diam \Omega)^{n}}{n\abs{\Omega}}\int_{\Omega}\frac{\abs{Du(y)}}{\abs{x-y}^{n-1}}dy$, so we have the relationship required in part (b) between $\tilde{u}(x) = u(x)-\overline{u}_{\Omega}$ and $v(y)$, with kernel $K(x,y) = \frac{1}{\abs{x-y}^{n-1}}$ and $\displaystyle \abs{v(y)} = \frac{(\diam \Omega)^{n}}{n\abs{\Omega}}\abs{Du(y)}$. Therefore, applying part (b), we obtain that $$\begin{align} \norm{\tilde{u}}_{L^{q}(\Omega)} &= \norm{u(x) - \overline{u}_{\Omega}}_{L^{q}(\Omega)}\\ &\leq A \norm{v}_{L^{p}(\Omega)} = A\left( \int_{\Omega}\abs{v(y)}^{p} dy\right)^{1/p} \\ &= A \left( \int \left\lvert \frac{(\diam \Omega)^{n}}{n\abs\Omega}Du(y)\right\rvert^{p}dy\right)^{1/p} \\ &= A \frac{(\diam \Omega)^{n}}{n\abs\Omega}\left( \int |Du(y)|^{p}dy\right)^{1/p} \\ &= A \frac{(\diam \Omega)^{n}}{n\abs\Omega}\norm{Du}_{L^{P}(\Omega)}. \end{align}$$ Now, since by part (b), we are told that $$A = \max\left(\sup_{x}\norm{K(x,\cdot)}_{L^{\frac{pq}{pq+p-q}}}, \sup_{y}\norm{K(\cdot,y)}_{L^{\frac{pq}{pq+p-q}}}\right),$$ we must show that $$\displaystyle \sup_{x}\norm{K(x,\cdot)}_{L^{\frac{pq}{pq+p-q}}(\Omega)} \leq C_{n}\left[ \frac{1+\frac{1}{q} - \frac{1}{p}}{\frac{1}{n}+\frac{1}{q}-\frac{1}{p}} \right]^{1 + \frac{1}{q} - \frac{1}{p}}\abs\Omega^{\frac{1}{n}+\frac{1}{q}-\frac{1}{p}},$$ which I did.  I'll spare you the gory details of this derivation, especially since it's not relevant to my question. My question comes in the putting of it all together : When we do put it all together, we have that $$\begin{align} \norm{u-\overline{u}_{\Omega}}_{L^{q}(\Omega)} &\leq A \norm v_{L^{p}(\Omega)} \\ &= A \frac{(\diam \Omega)^{n}}{n\abs\Omega}\left( \int_{\Omega} \abs{Du(y)}^{p}dy \right)^{1/p} \\ &\leq c_{n} \left[ \frac{1+\frac{1}{q}-\frac{1}{p}}{\frac{1}{n}+\frac{1}{q}-\frac{1}{p}} \right]^{1+\frac{1}{q}-\frac{1}{p}}\abs\Omega^{\frac{1}{n} + \frac{1}{q} - \frac{1}{p}}\frac{(\diam \Omega)^{n}}{n\abs\Omega} \norm{Du}_{L^{p}(\Omega)} \end{align}$$ and eventually, we get the desired result. From this point on, I was able to get the desired result just fine; however, my question is, in the last line of this last quoted formula, should I have a $\mathbf{\leq}$ sign as it is currently written, or should it be an $=$ sign, and why ? Thank you in advance. :)","$\DeclareMathOperator{\diam}{diam}\newcommand{\norm}[1]{\lVert#1\rVert}\newcommand{\abs}[1]{\lvert#1\rvert}$For $u \in C^{1}(\overline{\Omega})$, for $\Omega\subset \subset \mathbb{R^{n}}$ a bounded convex set, and for any $1 \leq p \leq q$ such that $\frac{1}{p}-\frac{1}{q}<\frac{1}{n}$, I need to show that $$ \norm{u-\overline{u}_{\Omega}}_{L^{q}} \leq c_{n} \left[ \frac{1+\frac{1}{q} - \frac{1}{p}}{\frac{1}{n}+\frac{1}{q}-\frac{1}{p}}\right]^{1+\frac{1}{q}-\frac{1}{p}}  \cdot \frac{(\diam \Omega)^{n}}{\abs\Omega^{1-\frac{1}{n}+\frac{1}{p}-\frac{1}{q}}}\norm{Du}_{L^{p}(\Omega)}, $$ For context, this is a part (c) to a problem where in part (a), we were asked to show that $$ \abs{u(x)-\overline{u}_{\Omega}} \leq \frac{(\diam \Omega)^{n}}{n \abs{\Omega}}\int_{\Omega}\frac{\abs{Du(y)}}{\abs{x-y}^{n-1}}dy $$ for any function $u \in C^{1}(\overline{\Omega})$ and any point $x \in \Omega$, and in part (b), we were asked to show that if $u$ and $v$ were any two functions on $\Omega$ related as follows: $$\abs{u(x)}\leq \int_{\Omega}K(x,y) \abs{v(y)} \, dy, \quad x\in \Omega$$ for some kernel $K(x,y)$, then for any $1 \leq p \leq q \leq \infty$, we have $$\norm u_{L^{q}(\Omega)} \leq A \norm v_{L^{p}(\Omega)},$$ where $\displaystyle A = \max\left(\sup_{x}\norm{K(x,\cdot)}_{L^{\frac{pq}{pq+p-q}}}, \sup_{y}\norm{K(\cdot,y)}_{L^{\frac{pq}{pq+p-q}}}\right)$. We are told to assume the integral estimate that $$\int_{\Omega}\abs{x-y}^{-n\mu}dy \leq c_{n}\frac{1}{1-\mu}\abs{\Omega}^{1-\mu}$$ for any $0 \leq \mu < 1$, where $c_{n}$ is a constant dependent only on the dimension $n$. Here is how I did the problem: By part (a), we have that $\displaystyle \abs{u(x)-\overline{u}_{\Omega}}\leq \frac{(\diam \Omega)^{n}}{n\abs{\Omega}}\int_{\Omega}\frac{\abs{Du(y)}}{\abs{x-y}^{n-1}}dy$, so we have the relationship required in part (b) between $\tilde{u}(x) = u(x)-\overline{u}_{\Omega}$ and $v(y)$, with kernel $K(x,y) = \frac{1}{\abs{x-y}^{n-1}}$ and $\displaystyle \abs{v(y)} = \frac{(\diam \Omega)^{n}}{n\abs{\Omega}}\abs{Du(y)}$. Therefore, applying part (b), we obtain that $$\begin{align} \norm{\tilde{u}}_{L^{q}(\Omega)} &= \norm{u(x) - \overline{u}_{\Omega}}_{L^{q}(\Omega)}\\ &\leq A \norm{v}_{L^{p}(\Omega)} = A\left( \int_{\Omega}\abs{v(y)}^{p} dy\right)^{1/p} \\ &= A \left( \int \left\lvert \frac{(\diam \Omega)^{n}}{n\abs\Omega}Du(y)\right\rvert^{p}dy\right)^{1/p} \\ &= A \frac{(\diam \Omega)^{n}}{n\abs\Omega}\left( \int |Du(y)|^{p}dy\right)^{1/p} \\ &= A \frac{(\diam \Omega)^{n}}{n\abs\Omega}\norm{Du}_{L^{P}(\Omega)}. \end{align}$$ Now, since by part (b), we are told that $$A = \max\left(\sup_{x}\norm{K(x,\cdot)}_{L^{\frac{pq}{pq+p-q}}}, \sup_{y}\norm{K(\cdot,y)}_{L^{\frac{pq}{pq+p-q}}}\right),$$ we must show that $$\displaystyle \sup_{x}\norm{K(x,\cdot)}_{L^{\frac{pq}{pq+p-q}}(\Omega)} \leq C_{n}\left[ \frac{1+\frac{1}{q} - \frac{1}{p}}{\frac{1}{n}+\frac{1}{q}-\frac{1}{p}} \right]^{1 + \frac{1}{q} - \frac{1}{p}}\abs\Omega^{\frac{1}{n}+\frac{1}{q}-\frac{1}{p}},$$ which I did.  I'll spare you the gory details of this derivation, especially since it's not relevant to my question. My question comes in the putting of it all together : When we do put it all together, we have that $$\begin{align} \norm{u-\overline{u}_{\Omega}}_{L^{q}(\Omega)} &\leq A \norm v_{L^{p}(\Omega)} \\ &= A \frac{(\diam \Omega)^{n}}{n\abs\Omega}\left( \int_{\Omega} \abs{Du(y)}^{p}dy \right)^{1/p} \\ &\leq c_{n} \left[ \frac{1+\frac{1}{q}-\frac{1}{p}}{\frac{1}{n}+\frac{1}{q}-\frac{1}{p}} \right]^{1+\frac{1}{q}-\frac{1}{p}}\abs\Omega^{\frac{1}{n} + \frac{1}{q} - \frac{1}{p}}\frac{(\diam \Omega)^{n}}{n\abs\Omega} \norm{Du}_{L^{p}(\Omega)} \end{align}$$ and eventually, we get the desired result. From this point on, I was able to get the desired result just fine; however, my question is, in the last line of this last quoted formula, should I have a $\mathbf{\leq}$ sign as it is currently written, or should it be an $=$ sign, and why ? Thank you in advance. :)",,"['analysis', 'functional-analysis']"
19,Prove that this integral operator is compact,Prove that this integral operator is compact,,"Let $X,Y=L^2(0,1)$, $k\in C^0([0,1]^2)$. Define $$ K:X\to Y,\,\,\,\,\,Kf(x):=\int_0^1k(x,y)f(y)dy\,\,\,\,\forall\, f\in L^2(0,1). $$ I have to show that $K$ is compact. My idea is to prove that $K$ is the limit of finite-rank operators. But I don't know exactly which kind of operators should I have to consider.","Let $X,Y=L^2(0,1)$, $k\in C^0([0,1]^2)$. Define $$ K:X\to Y,\,\,\,\,\,Kf(x):=\int_0^1k(x,y)f(y)dy\,\,\,\,\forall\, f\in L^2(0,1). $$ I have to show that $K$ is compact. My idea is to prove that $K$ is the limit of finite-rank operators. But I don't know exactly which kind of operators should I have to consider.",,"['functional-analysis', 'operator-theory', 'hilbert-spaces']"
20,Correct spaces for quantum mechanics,Correct spaces for quantum mechanics,,"The general formulation of quantum mechanics is done by describing quantum mechanical states by vectors $|\psi_t(x)\rangle$ in some Hilbert space $\mathcal{H}$ and describes their time evolution by the Schrödinger equation $$i\hbar\frac{\partial}{\partial t}|\psi_t\rangle = H|\psi_t\rangle$$ where $H$ is the Hamilton operator (for the free particle we have $H=-\frac{\hbar^2}{2m}\Delta$). Now I have often seen used spaces like $\mathcal{H}=L^2(\mathbb{R}^3)$ (in the case of a single particle), but I was wondering whether this is correct or not.  In fact shouldn't we require to be able to derivate $\left|\psi_t\right>$ twice in $x$ and thus choose something like $\mathcal{H} = H^2(\mathbb{R}^3)$? If we treat directly $\psi(t,x) := \psi_t(x)$, shouldn't we require them to be in something like $H^1(\mathbb{R};H^2(\mathbb{R}^3))$? i.e., functions in $H^1(\mathbb{R})$ with values in $H^2(\mathbb{R}^3)$, e.g. the function $t\mapsto\psi_t$.","The general formulation of quantum mechanics is done by describing quantum mechanical states by vectors $|\psi_t(x)\rangle$ in some Hilbert space $\mathcal{H}$ and describes their time evolution by the Schrödinger equation $$i\hbar\frac{\partial}{\partial t}|\psi_t\rangle = H|\psi_t\rangle$$ where $H$ is the Hamilton operator (for the free particle we have $H=-\frac{\hbar^2}{2m}\Delta$). Now I have often seen used spaces like $\mathcal{H}=L^2(\mathbb{R}^3)$ (in the case of a single particle), but I was wondering whether this is correct or not.  In fact shouldn't we require to be able to derivate $\left|\psi_t\right>$ twice in $x$ and thus choose something like $\mathcal{H} = H^2(\mathbb{R}^3)$? If we treat directly $\psi(t,x) := \psi_t(x)$, shouldn't we require them to be in something like $H^1(\mathbb{R};H^2(\mathbb{R}^3))$? i.e., functions in $H^1(\mathbb{R})$ with values in $H^2(\mathbb{R}^3)$, e.g. the function $t\mapsto\psi_t$.",,"['functional-analysis', 'partial-differential-equations', 'hilbert-spaces', 'mathematical-physics', 'quantum-mechanics']"
21,"If two norms are equivalent on a dense subspace of a normed space, are they equivalent?","If two norms are equivalent on a dense subspace of a normed space, are they equivalent?",,"Given a vector space $V$ equipped with two norms $|\cdot|$ and $\|\cdot\|$ which are equivalent on a subspace $W$ which is $\|\cdot\|$ -dense in $V$ , are the two norms necessarily equivalent? The statement seems like a relatively straightforward thing to show, but I can't manage it. Having played around with a few proof strategies and not getting anywhere, I'm starting to think that that the statement isn't true, but I'm not yet familiar with many normed spaces and can't think of a counter-example. Any help or hints would be much appreciated. EDIT: To clear things up, in the book that I took this question from (Linear Analysis by Béla Bollobás) a normed space is defined to be a real or complex vector space, so I think that the intention is for $V$ to be over $\mathbb{R}$ or $\mathbb{C}$ .","Given a vector space equipped with two norms and which are equivalent on a subspace which is -dense in , are the two norms necessarily equivalent? The statement seems like a relatively straightforward thing to show, but I can't manage it. Having played around with a few proof strategies and not getting anywhere, I'm starting to think that that the statement isn't true, but I'm not yet familiar with many normed spaces and can't think of a counter-example. Any help or hints would be much appreciated. EDIT: To clear things up, in the book that I took this question from (Linear Analysis by Béla Bollobás) a normed space is defined to be a real or complex vector space, so I think that the intention is for to be over or .",V |\cdot| \|\cdot\| W \|\cdot\| V V \mathbb{R} \mathbb{C},"['functional-analysis', 'normed-spaces']"
22,Compact sets as point spectrum of a bounded operator,Compact sets as point spectrum of a bounded operator,,"It is well known that if $K$ is any compact set in $\mathbb{C}$, then there exist a bounded linear operator $T:l_2\to l_2$ such that $\sigma(T)=K$. My questions are: Q1) Does there exist $T$, a bounded linear operator on $l_2$ such that the point spectrum $\sigma_p(T)$ is the given $K$? That is, the only eigenvalues are the complex numbers in $K$? Q2)  Does there exist $T$, a bounded linear operator on $l_2$ such that $\sigma(T)=\sigma_p(T)=K$. That is, there are no other points in the spectrum except the eigenvalues in $K$? Clearly a positive answer to Q2) implies a positive answer to Q1).","It is well known that if $K$ is any compact set in $\mathbb{C}$, then there exist a bounded linear operator $T:l_2\to l_2$ such that $\sigma(T)=K$. My questions are: Q1) Does there exist $T$, a bounded linear operator on $l_2$ such that the point spectrum $\sigma_p(T)$ is the given $K$? That is, the only eigenvalues are the complex numbers in $K$? Q2)  Does there exist $T$, a bounded linear operator on $l_2$ such that $\sigma(T)=\sigma_p(T)=K$. That is, there are no other points in the spectrum except the eigenvalues in $K$? Clearly a positive answer to Q2) implies a positive answer to Q1).",,"['functional-analysis', 'operator-theory']"
23,"Are there spaces ""smaller"" than $c_0$ whose dual is $\ell^1$?","Are there spaces ""smaller"" than  whose dual is ?",c_0 \ell^1,"It is well known that both the sequence spaces $c$ and $c_0$ have duals which are isometrically isomorphic to $\ell^1$. Now, $c_0$ is a subspace of $c$. My question - is there an even smaller subspace of $c$ whose dual is isometrically isomorphic to $\ell^1$? More generally, is there a characterization of preduals of $\ell^1$? References are most welcome.","It is well known that both the sequence spaces $c$ and $c_0$ have duals which are isometrically isomorphic to $\ell^1$. Now, $c_0$ is a subspace of $c$. My question - is there an even smaller subspace of $c$ whose dual is isometrically isomorphic to $\ell^1$? More generally, is there a characterization of preduals of $\ell^1$? References are most welcome.",,"['functional-analysis', 'banach-spaces', 'lp-spaces', 'dual-spaces']"
24,Proving that Tensor Product is Associative,Proving that Tensor Product is Associative,,"I want to show that $X\otimes(Y\otimes Z)$ is isomorphic to $(X\otimes Y)\otimes Z$. Intuitively I think I should just choose bases $\{e_{i}\}_{i\in I}, \{f_{j}\}_{j\in J}$, and $\{g_{k}\}_{k\in K}$ for $X,Y,Z$ and map $$e_{i}\otimes(f_{j}\otimes g_{k})\mapsto (e_{i}\otimes f_{j})\otimes g_{k}$$ This defines a bijective correspondence between basis elements and so should induce a vector space isomorphism. Is there a way to do this using the universal property of the tensor product? $\bf{\text{Context:}}$ I am working through Introduction to Tensor Products of Banach Spaces by Raymond Ryan, and am working on exercises at the end of the first chapter.  I'll try to summarize what I have available. We defined the space $X\otimes Y$ to be linear functionals on the space $B(X\times Y)$ of bilinear maps on $X\times Y$. That is, $x\otimes y:A\mapsto A(x,y)$ for $A\in B(X\times Y)$. We have stated and proved $\bf{\text{Universal Property of Tensor Products}}$:  Let $X,Y,Z$ be vector spaces.  For every bilinear $A:X\times Y\to Z$ there is a unique linear map $\hat{A}:X\otimes Y\to Z$ such that $\hat{A}(x\otimes y) = A(x,y)$. Next we proved that the Tensor product is unique up to isomorphism (in the sense of having this property). We did not define any higher tensor product structure such as $\otimes_{i\in I}X_{i}$.","I want to show that $X\otimes(Y\otimes Z)$ is isomorphic to $(X\otimes Y)\otimes Z$. Intuitively I think I should just choose bases $\{e_{i}\}_{i\in I}, \{f_{j}\}_{j\in J}$, and $\{g_{k}\}_{k\in K}$ for $X,Y,Z$ and map $$e_{i}\otimes(f_{j}\otimes g_{k})\mapsto (e_{i}\otimes f_{j})\otimes g_{k}$$ This defines a bijective correspondence between basis elements and so should induce a vector space isomorphism. Is there a way to do this using the universal property of the tensor product? $\bf{\text{Context:}}$ I am working through Introduction to Tensor Products of Banach Spaces by Raymond Ryan, and am working on exercises at the end of the first chapter.  I'll try to summarize what I have available. We defined the space $X\otimes Y$ to be linear functionals on the space $B(X\times Y)$ of bilinear maps on $X\times Y$. That is, $x\otimes y:A\mapsto A(x,y)$ for $A\in B(X\times Y)$. We have stated and proved $\bf{\text{Universal Property of Tensor Products}}$:  Let $X,Y,Z$ be vector spaces.  For every bilinear $A:X\times Y\to Z$ there is a unique linear map $\hat{A}:X\otimes Y\to Z$ such that $\hat{A}(x\otimes y) = A(x,y)$. Next we proved that the Tensor product is unique up to isomorphism (in the sense of having this property). We did not define any higher tensor product structure such as $\otimes_{i\in I}X_{i}$.",,"['functional-analysis', 'banach-spaces', 'tensor-products']"
25,Compactness of a bounded operator $T\colon c_0 \to \ell^1$,Compactness of a bounded operator,T\colon c_0 \to \ell^1,"Pitt Theorem says that any bounded linear operator $T\colon \ell^r \to \ell^p$, $1 \leq p < r < \infty$, or $T\colon c_0 \to \ell^p$ is compact. I know how to prove this in case $\ell^r \to \ell^p$, and $c_0 \to \ell^p$, where $p > 1$. Main idea in the first case is that $\ell^r$ is reflexive and hence closed ball $B_{\ell^r}$ is weakly compact. In the second case we could just use Schauder Theorem ($T$ is compact if and only if $T^*$ is compact). The only case left is $T\colon c_0 \to \ell^1$. I have tried something like this: By Schauder Theorem we need to prove that $T^*\colon \ell^\infty \to \ell^1$ is compact. By Banach-Alaoglu Theorem we know that $B_{\ell^\infty}$ is compact in the $weak^{*}$ topology on $\ell^\infty$. Moreover, we know, since $\ell^1$ is separable, that $B_{\ell^\infty}$ is metrizable. Hence, it is enough to prove that if $(x_n)$ is a $weak{}^{*}$ convergent (say, to $x$) sequence in $B_{\ell^\infty}$ then $(Tx_n)$ converges (to $Tx$, I think). Since Schur Theorem (weak and norm convergence is the same in $\ell^1$) we only need to show that $(Tx_n)$ converges weakly in $\ell^1$. And here I stuck. Could you give me any ideas or references? In every book I have looked so far this particular case was omitted. Edit (4.4.2011): I found in Diestel's Sequences and series in Banach spaces (chap. VII, Exercise 2(ii)) something like this: A bounded operator $T: c_0 \to X$ is compact if and only if every subseries of $\sum_{n=1}^\infty Te_n$ is convergent, where $(e_n)$ is canonical basis for $c_0$. I know how to prove this, but how we can show that operators $T: c_0 \to \ell^1$ possess the subseries property?","Pitt Theorem says that any bounded linear operator $T\colon \ell^r \to \ell^p$, $1 \leq p < r < \infty$, or $T\colon c_0 \to \ell^p$ is compact. I know how to prove this in case $\ell^r \to \ell^p$, and $c_0 \to \ell^p$, where $p > 1$. Main idea in the first case is that $\ell^r$ is reflexive and hence closed ball $B_{\ell^r}$ is weakly compact. In the second case we could just use Schauder Theorem ($T$ is compact if and only if $T^*$ is compact). The only case left is $T\colon c_0 \to \ell^1$. I have tried something like this: By Schauder Theorem we need to prove that $T^*\colon \ell^\infty \to \ell^1$ is compact. By Banach-Alaoglu Theorem we know that $B_{\ell^\infty}$ is compact in the $weak^{*}$ topology on $\ell^\infty$. Moreover, we know, since $\ell^1$ is separable, that $B_{\ell^\infty}$ is metrizable. Hence, it is enough to prove that if $(x_n)$ is a $weak{}^{*}$ convergent (say, to $x$) sequence in $B_{\ell^\infty}$ then $(Tx_n)$ converges (to $Tx$, I think). Since Schur Theorem (weak and norm convergence is the same in $\ell^1$) we only need to show that $(Tx_n)$ converges weakly in $\ell^1$. And here I stuck. Could you give me any ideas or references? In every book I have looked so far this particular case was omitted. Edit (4.4.2011): I found in Diestel's Sequences and series in Banach spaces (chap. VII, Exercise 2(ii)) something like this: A bounded operator $T: c_0 \to X$ is compact if and only if every subseries of $\sum_{n=1}^\infty Te_n$ is convergent, where $(e_n)$ is canonical basis for $c_0$. I know how to prove this, but how we can show that operators $T: c_0 \to \ell^1$ possess the subseries property?",,"['functional-analysis', 'banach-spaces', 'operator-theory', 'compact-operators']"
26,Is the closedness of the image of a Fredholm operator implied by the finiteness of the codimension of its image?,Is the closedness of the image of a Fredholm operator implied by the finiteness of the codimension of its image?,,"Let $X$ and $Y$ be Banach spaces. A bounded operator $T\colon X\to Y$ is called Fredholm iff The dimension of $\ker(T)$ is finite, The codimension of the image $\mathrm{im}(T)$ is finite, The image $\mathrm{im}(T)$ is closed in $Y$. Question: Is the third condition redundant? Some lecture notes I'm working through claim that the third condition follows from the second one together with the open mapping theorem . I've checked some books on functional-analysis without finding a proof of this.","Let $X$ and $Y$ be Banach spaces. A bounded operator $T\colon X\to Y$ is called Fredholm iff The dimension of $\ker(T)$ is finite, The codimension of the image $\mathrm{im}(T)$ is finite, The image $\mathrm{im}(T)$ is closed in $Y$. Question: Is the third condition redundant? Some lecture notes I'm working through claim that the third condition follows from the second one together with the open mapping theorem . I've checked some books on functional-analysis without finding a proof of this.",,['functional-analysis']
27,How are infinite-dimensional manifolds most commonly treated?,How are infinite-dimensional manifolds most commonly treated?,,"At a summer school I recently attended, infinite-dimensional manifolds popped up. I have never worked with them before (although I'm very familiar with finite-dimensional manifolds). The lecturer at the school did not give any details about the technical realization of infinite-dimensional manifolds, mentioning that there were issues (such as picking a topology) that he would leave out for the sake of clarity, since the relevant results were true independent of the exact technical details. An internet search reveals that ""Banach manifolds"" are one way of treating infinite-dimensional manifolds, but there are others. Are Banach manifolds the most common way of defining infinite-dimensional manifolds, or are there other notions commonly used?   Is there a more or less universal consensus about when to use which treatment? What are the most important (dis)advantages of each? Supposing I want to learn the basics of infinite-dimensional manifolds, are there any well-written introductory texts you would recommend?","At a summer school I recently attended, infinite-dimensional manifolds popped up. I have never worked with them before (although I'm very familiar with finite-dimensional manifolds). The lecturer at the school did not give any details about the technical realization of infinite-dimensional manifolds, mentioning that there were issues (such as picking a topology) that he would leave out for the sake of clarity, since the relevant results were true independent of the exact technical details. An internet search reveals that ""Banach manifolds"" are one way of treating infinite-dimensional manifolds, but there are others. Are Banach manifolds the most common way of defining infinite-dimensional manifolds, or are there other notions commonly used?   Is there a more or less universal consensus about when to use which treatment? What are the most important (dis)advantages of each? Supposing I want to learn the basics of infinite-dimensional manifolds, are there any well-written introductory texts you would recommend?",,"['functional-analysis', 'reference-request', 'differential-geometry']"
28,problem books in functional analysis,problem books in functional analysis,,There are many excellent problem books in real analysis. I'm looking for a problem book in functional analysis or a book which contains a lot of problems in functional analysis (Easy and hard problems) to which a complete solution manual is readily available .,There are many excellent problem books in real analysis. I'm looking for a problem book in functional analysis or a book which contains a lot of problems in functional analysis (Easy and hard problems) to which a complete solution manual is readily available .,,"['functional-analysis', 'reference-request', 'big-list', 'book-recommendation']"
29,Open Mapping Theorem: counterexample,Open Mapping Theorem: counterexample,,"The Open Mapping Theorem says that a linear continuous surjection between Banach spaces is an open mapping. I am writing some lecture notes on the Open Mapping Theorem. I guess it would be nice to have some counterexamples. After all, how can you appreciate it's meaning without a nice counterexample showing how the conclusion could fail and why the conclusion is not obvious at all. Let $\ell^1 \subset \mathbb{R}^\infty$ be the set of sequences $(a_1, a_2, \dotsc)$, such that $\sum |a_j| < \infty$. If we consider the $\ell^1$ norm $\|\cdot\|_1$ and the supremum norm $\|\cdot\|_s$, then, $(\ell^1, \|\cdot\|_1)$ is complete, while $(\ell^1, \|\cdot\|_s)$ is not complete. In this case, the identity $$   \begin{array}{rrcl}     \mathrm{id}:& (\ell^1, \|\cdot\|_1)& \to &(\ell^1, \|\cdot\|_s)     \\                 & x & \mapsto & x   \end{array} $$ is a continuous bijection but it is not open. I want a counterexample in the opposite direction. That is, I want a linear continuous bijection $T: E \to F$ between normed spaces $E$ and $F$ such that $F$ is Banach but $T$ is not open. This is equivalent to finding a vector space $E$ with non-equivalent norms $\|\cdot\|_c$ and $\|\cdot\|_n$, such that $E$ is complete when considered the norm $\|\cdot\|_c$, and such that $$   \|\cdot\|_c   \leq   \|\cdot\|_n. $$ The Open Mapping Theorem implies that $\|\cdot\|_n$ is not complete. So, is anyone aware of such a counterexample?","The Open Mapping Theorem says that a linear continuous surjection between Banach spaces is an open mapping. I am writing some lecture notes on the Open Mapping Theorem. I guess it would be nice to have some counterexamples. After all, how can you appreciate it's meaning without a nice counterexample showing how the conclusion could fail and why the conclusion is not obvious at all. Let $\ell^1 \subset \mathbb{R}^\infty$ be the set of sequences $(a_1, a_2, \dotsc)$, such that $\sum |a_j| < \infty$. If we consider the $\ell^1$ norm $\|\cdot\|_1$ and the supremum norm $\|\cdot\|_s$, then, $(\ell^1, \|\cdot\|_1)$ is complete, while $(\ell^1, \|\cdot\|_s)$ is not complete. In this case, the identity $$   \begin{array}{rrcl}     \mathrm{id}:& (\ell^1, \|\cdot\|_1)& \to &(\ell^1, \|\cdot\|_s)     \\                 & x & \mapsto & x   \end{array} $$ is a continuous bijection but it is not open. I want a counterexample in the opposite direction. That is, I want a linear continuous bijection $T: E \to F$ between normed spaces $E$ and $F$ such that $F$ is Banach but $T$ is not open. This is equivalent to finding a vector space $E$ with non-equivalent norms $\|\cdot\|_c$ and $\|\cdot\|_n$, such that $E$ is complete when considered the norm $\|\cdot\|_c$, and such that $$   \|\cdot\|_c   \leq   \|\cdot\|_n. $$ The Open Mapping Theorem implies that $\|\cdot\|_n$ is not complete. So, is anyone aware of such a counterexample?",,"['functional-analysis', 'examples-counterexamples', 'normed-spaces']"
30,Prove that $X^\ast$ separable implies $X$ separable,Prove that  separable implies  separable,X^\ast X,"Can someone tell me if I got the following right: Assume $X$ to be a normed vector space over $\mathbb{R}$. Prove that if the dual space $X^\ast$ is separable then $X$ is separable as well. I'm supposed to use the following hint: First show that for each $x_n^\ast$ we may choose a unit vector $x_n \in X$ such that $x_n^\ast (x_n) \geq \frac{\| x_n^\ast \|}{2}$. Then show that $\overline{Y} = \overline{span_\mathbb{Q} \{ x_n\}} = X$. My answer: (i) (by contradiction) Assume for all $x_n \in X$ with $\| x_n \|_X = 1$ that $$x_n^\ast (x_n) < \frac{\| x_n^\ast \|}{2} \iff 2 x_n^\ast (x_n) < \sup_{x_n; \| x_n \|_X = 1 } \{ | x_n^\ast(x_n) | \}$$ Claim: Then $\exists r \in \mathbb{R}: x_n^\ast(x_n) < r < \sup_{\dots}\{\dots \}$: (i) $x_n^\ast (x_n) \neq 0$: because $\| x_n \| = 1$ and $x_n^\ast$ linear (ii) if $x_n^\ast (x_n) < 0$ then  $2 x_n^\ast (x_n) < x_n^\ast (x_n) < x_n^\ast(- x_n) < 2 x_n^\ast(-x_n) < \sup_{\dots} \{ \dots \}$ (iii) $x_n^\ast(x_n) > 0$ then $\forall x_n: x_n^\ast (x_n) < 2 x_n^\ast (x_n) < \sup$ $\implies $ the $\sup$ is not the l.u.b., contradiction, so the claim $x_n^\ast (x_n) \geq \frac{\| x_n^\ast \|}{2}$ is true. (ii) Using: $ x \in \overline{Y} \iff \lnot \exists $ bounded linear functional $f^\ast$ such that $f^\ast (y ) = 0 \forall y \in Y$ and $f^\ast (x) \neq 0$ Let $f^\ast \in X^\ast$. Then $\{ x_n^\ast \}$ dense in $X^\ast \implies$ $$ \forall \varepsilon > 0 \exists x_n^\ast : \| x_n^\ast - f^\ast \| = \sup_{x \in X: \| x \| \leq 1} \{ |x_n^\ast (x) - f^\ast(x)| \} < \varepsilon$$ But for $x_n \in Y \subset X (\| x_n \| = 1)$ we know  $$| x_n^\ast (x_n)| \geq x_n^\ast (x_n) \geq \frac{\| x_n \|}{2} > 0$$ so if $f^\ast (y) = 0 \forall y \in Y$ then $$ 0 < \frac{\| x_n \|}{2} \leq |x_n^\ast (x_n)| = |x_n^\ast (x_n) - f^\ast(x_n)|$$ $$ \implies \exists \varepsilon: \sup |x_n^\ast (x_n) - f^\ast(x_n)| > \varepsilon$$ $$ \implies \lnot \exists f^\ast \in X^\ast : \forall y \in Y: f^\ast (y) = 0$$ $$ x \in \overline{Y}$$ Thanks for your help.","Can someone tell me if I got the following right: Assume $X$ to be a normed vector space over $\mathbb{R}$. Prove that if the dual space $X^\ast$ is separable then $X$ is separable as well. I'm supposed to use the following hint: First show that for each $x_n^\ast$ we may choose a unit vector $x_n \in X$ such that $x_n^\ast (x_n) \geq \frac{\| x_n^\ast \|}{2}$. Then show that $\overline{Y} = \overline{span_\mathbb{Q} \{ x_n\}} = X$. My answer: (i) (by contradiction) Assume for all $x_n \in X$ with $\| x_n \|_X = 1$ that $$x_n^\ast (x_n) < \frac{\| x_n^\ast \|}{2} \iff 2 x_n^\ast (x_n) < \sup_{x_n; \| x_n \|_X = 1 } \{ | x_n^\ast(x_n) | \}$$ Claim: Then $\exists r \in \mathbb{R}: x_n^\ast(x_n) < r < \sup_{\dots}\{\dots \}$: (i) $x_n^\ast (x_n) \neq 0$: because $\| x_n \| = 1$ and $x_n^\ast$ linear (ii) if $x_n^\ast (x_n) < 0$ then  $2 x_n^\ast (x_n) < x_n^\ast (x_n) < x_n^\ast(- x_n) < 2 x_n^\ast(-x_n) < \sup_{\dots} \{ \dots \}$ (iii) $x_n^\ast(x_n) > 0$ then $\forall x_n: x_n^\ast (x_n) < 2 x_n^\ast (x_n) < \sup$ $\implies $ the $\sup$ is not the l.u.b., contradiction, so the claim $x_n^\ast (x_n) \geq \frac{\| x_n^\ast \|}{2}$ is true. (ii) Using: $ x \in \overline{Y} \iff \lnot \exists $ bounded linear functional $f^\ast$ such that $f^\ast (y ) = 0 \forall y \in Y$ and $f^\ast (x) \neq 0$ Let $f^\ast \in X^\ast$. Then $\{ x_n^\ast \}$ dense in $X^\ast \implies$ $$ \forall \varepsilon > 0 \exists x_n^\ast : \| x_n^\ast - f^\ast \| = \sup_{x \in X: \| x \| \leq 1} \{ |x_n^\ast (x) - f^\ast(x)| \} < \varepsilon$$ But for $x_n \in Y \subset X (\| x_n \| = 1)$ we know  $$| x_n^\ast (x_n)| \geq x_n^\ast (x_n) \geq \frac{\| x_n \|}{2} > 0$$ so if $f^\ast (y) = 0 \forall y \in Y$ then $$ 0 < \frac{\| x_n \|}{2} \leq |x_n^\ast (x_n)| = |x_n^\ast (x_n) - f^\ast(x_n)|$$ $$ \implies \exists \varepsilon: \sup |x_n^\ast (x_n) - f^\ast(x_n)| > \varepsilon$$ $$ \implies \lnot \exists f^\ast \in X^\ast : \forall y \in Y: f^\ast (y) = 0$$ $$ x \in \overline{Y}$$ Thanks for your help.",,"['functional-analysis', 'banach-spaces', 'dual-spaces', 'separable-spaces']"
31,Sum of closed and compact set in a TVS,Sum of closed and compact set in a TVS,,"I am trying to prove: $A$ compact, $B$ closed $\Rightarrow A+B = \{a+b | a\in A, b\in B\}$ closed (exercise in Rudin's Functional Analysis), where $A$ and $B$ are subsets of a topological vector space $X$. In case $X=\mathbb{R}$ this is easy, using sequences. However, since I was told that using sequences in topology is ""dangerous"" (don't know why though), I am trying to prove this without using sequences (or nets, which I am not familiar with). Is this possible? My attempt was to show that if $x\notin A+B$, then $x \notin \overline{A+B}$. In some way, assuming $x\in\overline{A+B}$ should then contradict $A$ being compact. I'm not sure how to fill in the details here though. Any suggestions on this, or am I thinking in the wrong direction here?","I am trying to prove: $A$ compact, $B$ closed $\Rightarrow A+B = \{a+b | a\in A, b\in B\}$ closed (exercise in Rudin's Functional Analysis), where $A$ and $B$ are subsets of a topological vector space $X$. In case $X=\mathbb{R}$ this is easy, using sequences. However, since I was told that using sequences in topology is ""dangerous"" (don't know why though), I am trying to prove this without using sequences (or nets, which I am not familiar with). Is this possible? My attempt was to show that if $x\notin A+B$, then $x \notin \overline{A+B}$. In some way, assuming $x\in\overline{A+B}$ should then contradict $A$ being compact. I'm not sure how to fill in the details here though. Any suggestions on this, or am I thinking in the wrong direction here?",,"['functional-analysis', 'compactness', 'topological-vector-spaces', 'sumset']"
32,"Does every $\mathbb{R},\mathbb{C}$ vector space have a norm?",Does every  vector space have a norm?,"\mathbb{R},\mathbb{C}","Is there a canonical way to define on any vector space over $\mathbb{K}=\mathbb{R},\mathbb{C}$ a norm ? (Or, if there isn't, can someone give me an example of a vector space over $\mathbb{K}$ that is not normable ?) I have now looked through several books on the subject but nowhere is something like this mentioned and I also wasn't able to find a way to construct such norm (or to find a counterexample).","Is there a canonical way to define on any vector space over $\mathbb{K}=\mathbb{R},\mathbb{C}$ a norm ? (Or, if there isn't, can someone give me an example of a vector space over $\mathbb{K}$ that is not normable ?) I have now looked through several books on the subject but nowhere is something like this mentioned and I also wasn't able to find a way to construct such norm (or to find a counterexample).",,"['functional-analysis', 'topological-vector-spaces', 'normed-spaces']"
33,"How to show that $C=C[0,1]$ is a Banach space",How to show that  is a Banach space,"C=C[0,1]","Let $C=C[0,1]$ be the space of all continuous functions on $[0,1]$. Define $\|f \|=\max \ |f(x)|$. I want to show that $C$ is a Banach space. Below is my attempt and I was wondering if it's ok. I know I have to show that $C$ is a complete normed space. Clearly, $\|f\| \geqslant 0$ and $\|f\|=0 \Leftrightarrow f=0$. $\|cf \|=\max~|cf(x)|=|c|\max |f(x)|=|c| \cdot \|f\|$. $\|f+g\|=\max~|f(x)+g(x)|\leq \max~|f(x)|+\max~|g(x)|=\|f\|+ \|g\|$. So $C$ is a normed space. Next, I show that every Cauchy sequence in $C$ is convergent. Let $\{f_n\}$ be a Cauchy sequence in $C$. Let $\varepsilon \gt 0.$ Then $\exists$ an $N_1$ such that $$ \max~|f_n(x)-f_m(x)| \lt \frac{\varepsilon}{2}$$ for $n, m \gt N_1$ and $x\in[0,1]$. But there is a subsequence $f_{k_n} $, which converges to $f$. So $\exists$ an $N_2$ such that $$ \max~\left|f_{k_n} - f\right|\lt \frac{\varepsilon}{2}$$ for each $n\gt N_2$. Now Let $N = \max\{N_1, N_2\}$, if $n \gt N$ then $k_n \geqslant n\gt N$. So we have $$ \max~\left|f_n(x) - f(x)\right| \leqslant \max~\left|f_n - f_{k_n}\right| + \max~\left| f_{k_n} - f\right| \lt\frac{\varepsilon}{2} + \frac{\varepsilon}{2} = \varepsilon.$$  Thus, $\|f_n-f\| \to 0$ as $n\to \infty$. $\quad \square$ Thanks.","Let $C=C[0,1]$ be the space of all continuous functions on $[0,1]$. Define $\|f \|=\max \ |f(x)|$. I want to show that $C$ is a Banach space. Below is my attempt and I was wondering if it's ok. I know I have to show that $C$ is a complete normed space. Clearly, $\|f\| \geqslant 0$ and $\|f\|=0 \Leftrightarrow f=0$. $\|cf \|=\max~|cf(x)|=|c|\max |f(x)|=|c| \cdot \|f\|$. $\|f+g\|=\max~|f(x)+g(x)|\leq \max~|f(x)|+\max~|g(x)|=\|f\|+ \|g\|$. So $C$ is a normed space. Next, I show that every Cauchy sequence in $C$ is convergent. Let $\{f_n\}$ be a Cauchy sequence in $C$. Let $\varepsilon \gt 0.$ Then $\exists$ an $N_1$ such that $$ \max~|f_n(x)-f_m(x)| \lt \frac{\varepsilon}{2}$$ for $n, m \gt N_1$ and $x\in[0,1]$. But there is a subsequence $f_{k_n} $, which converges to $f$. So $\exists$ an $N_2$ such that $$ \max~\left|f_{k_n} - f\right|\lt \frac{\varepsilon}{2}$$ for each $n\gt N_2$. Now Let $N = \max\{N_1, N_2\}$, if $n \gt N$ then $k_n \geqslant n\gt N$. So we have $$ \max~\left|f_n(x) - f(x)\right| \leqslant \max~\left|f_n - f_{k_n}\right| + \max~\left| f_{k_n} - f\right| \lt\frac{\varepsilon}{2} + \frac{\varepsilon}{2} = \varepsilon.$$  Thus, $\|f_n-f\| \to 0$ as $n\to \infty$. $\quad \square$ Thanks.",,"['analysis', 'functional-analysis']"
34,"If $1\leq p < \infty$ then show that $L^p([0,1])$ and $\ell_p$ are not topologically isomorphic",If  then show that  and  are not topologically isomorphic,"1\leq p < \infty L^p([0,1]) \ell_p","If $1\leq p < \infty$ then show that $L^p([0,1])$ and $\ell_p$ are not topologically isomorphic unless $p=2$. Maybe I would have to use the Rademacher's functions.","If $1\leq p < \infty$ then show that $L^p([0,1])$ and $\ell_p$ are not topologically isomorphic unless $p=2$. Maybe I would have to use the Rademacher's functions.",,"['functional-analysis', 'banach-spaces', 'lp-spaces']"
35,"$C[0,1]$ is not Hilbert space",is not Hilbert space,"C[0,1]","Prove that the space $C[0,1]$ of continuous functions from $[0,1]$ to $\mathbb{R}$ with the inner product $ \langle f,g \rangle  =\int_{0}^{1} f(t)g(t)dt \quad $ is not Hilbert space. I know that I have to find a Cauchy sequence  $(f_n)_n$ which converges to a function $f$ which is not continuous, but I can't construct such a sequence $(f_n)_n$. Any help?","Prove that the space $C[0,1]$ of continuous functions from $[0,1]$ to $\mathbb{R}$ with the inner product $ \langle f,g \rangle  =\int_{0}^{1} f(t)g(t)dt \quad $ is not Hilbert space. I know that I have to find a Cauchy sequence  $(f_n)_n$ which converges to a function $f$ which is not continuous, but I can't construct such a sequence $(f_n)_n$. Any help?",,"['functional-analysis', 'hilbert-spaces']"
36,The kernel of a continuous linear operator is a closed subspace?,The kernel of a continuous linear operator is a closed subspace?,,If $V$ and $W$ are topological vector spaces (and $W$ is finite-dimensional) then a linear operator $L\colon V\to W$ is continuous if and only if the kernel of $L$ is a closed subspace of $V$. Why is this so?,If $V$ and $W$ are topological vector spaces (and $W$ is finite-dimensional) then a linear operator $L\colon V\to W$ is continuous if and only if the kernel of $L$ is a closed subspace of $V$. Why is this so?,,"['functional-analysis', 'topological-vector-spaces']"
37,"Eigenvalues and eigenfunctions for the Fredholm integral operator $K(g) = \int_0^1 e^{x t} g(t) \, dt$.",Eigenvalues and eigenfunctions for the Fredholm integral operator .,"K(g) = \int_0^1 e^{x t} g(t) \, dt","I would like to compute the eigenvalues and eigenfunctions for the Fredholm integral operator $$K(g) = \int_0^1 e^{xt} g(t) \,dt.$$ The sources I've checked* seem to say that the process is fairly involved.  Has anything been published on this kernel?  Or, if not, am I correct that it's going to be a hard thing to do? * See, e.g., equations (12) and on here: https://www.encyclopediaofmath.org/index.php/Fredholm_equation","I would like to compute the eigenvalues and eigenfunctions for the Fredholm integral operator $$K(g) = \int_0^1 e^{xt} g(t) \,dt.$$ The sources I've checked* seem to say that the process is fairly involved.  Has anything been published on this kernel?  Or, if not, am I correct that it's going to be a hard thing to do? * See, e.g., equations (12) and on here: https://www.encyclopediaofmath.org/index.php/Fredholm_equation",,"['analysis', 'functional-analysis', 'integral-equations']"
38,Is there such thing as an unnormed vector space?,Is there such thing as an unnormed vector space?,,"I learned about Banach spaces a few weeks ago. A Banach space is a complete normed vector space. This of course made me wonder: are there unnormed vector spaces? If there are, can anyone please provide any examples? Some thoughts: A complete space is where all Cauchy sequences converge. A normed vector space is a vector space (say, over $\mathbb{R})$ on some norm $N$ (which is a function that maps $N\to\mathbb{R}$), where the norm obeys the triangle inequality, the norm of a vector is non-negative, and if you have a scalar being multiplied by a vector, you can factor the scalar out, but it'll have absolute value braces. I'm not really sure what is needed in order to have an unnormed vector space (perhaps the vector space necessarily needs to be infinite dimensional?). Perhaps something really weird like the zero space? Thanks for any insight.","I learned about Banach spaces a few weeks ago. A Banach space is a complete normed vector space. This of course made me wonder: are there unnormed vector spaces? If there are, can anyone please provide any examples? Some thoughts: A complete space is where all Cauchy sequences converge. A normed vector space is a vector space (say, over $\mathbb{R})$ on some norm $N$ (which is a function that maps $N\to\mathbb{R}$), where the norm obeys the triangle inequality, the norm of a vector is non-negative, and if you have a scalar being multiplied by a vector, you can factor the scalar out, but it'll have absolute value braces. I'm not really sure what is needed in order to have an unnormed vector space (perhaps the vector space necessarily needs to be infinite dimensional?). Perhaps something really weird like the zero space? Thanks for any insight.",,"['functional-analysis', 'vector-spaces', 'normed-spaces', 'locally-convex-spaces']"
39,Linear functional on a Banach space is discontinuous then its nullspace is dense.,Linear functional on a Banach space is discontinuous then its nullspace is dense.,,"I need to prove that: If a nonzero linear functional $f$ on a Banach Space $X$ is discontinuous then the nullspace $N_f$ is dense in $X$. To prove that $N_f$ is dense, it suffices to show that $\overline N_f = X$ which is equivalent to $(X \setminus N_f)^o=\emptyset$. (the interior of complement of $N_f$ is null set.) Since $f$ is a linear functional and is discontinuous, it has to be unbounded. I don't know exactly how to utilize these observations. Also on a related topic, I'm a little confused about how to exploit the a Linear Functional $f:X \to R$ or a Linear Operator $T:X \to Y$ being unbounded. Can I say that if a linear operator is unbounded then exists a sequence $<x_n>$ in $X$ s.t.  $||Tx_n|| > n^2||x_n||$ for each $n$ or $||Tx_n|| > n||x_n||$ ?","I need to prove that: If a nonzero linear functional $f$ on a Banach Space $X$ is discontinuous then the nullspace $N_f$ is dense in $X$. To prove that $N_f$ is dense, it suffices to show that $\overline N_f = X$ which is equivalent to $(X \setminus N_f)^o=\emptyset$. (the interior of complement of $N_f$ is null set.) Since $f$ is a linear functional and is discontinuous, it has to be unbounded. I don't know exactly how to utilize these observations. Also on a related topic, I'm a little confused about how to exploit the a Linear Functional $f:X \to R$ or a Linear Operator $T:X \to Y$ being unbounded. Can I say that if a linear operator is unbounded then exists a sequence $<x_n>$ in $X$ s.t.  $||Tx_n|| > n^2||x_n||$ for each $n$ or $||Tx_n|| > n||x_n||$ ?",,"['functional-analysis', 'banach-spaces']"
40,Compactness in the weak* topology,Compactness in the weak* topology,,"Let $X$ be a Banach space, and let $X^*$ denote its continuous dual space. Under the weak* topology, do compactness and sequential compactness coincide? That is, is a subset of $X^*$ weakly* compact if and only if it is weakly* sequentially compact?  Does one imply the other? Perhaps I should make this next one a separate question, but I'd prefer to keep all of this in one place. Is the weak* topology on $X^*$ Hausdorff?  Is the weak topology on $X$ Hausdorff? Motivation: I would like to say that if a subset of $X^*$ is weakly* compact, then it is weakly* closed, and that if a subset of $X$ is weakly compact, then it is weakly closed.","Let $X$ be a Banach space, and let $X^*$ denote its continuous dual space. Under the weak* topology, do compactness and sequential compactness coincide? That is, is a subset of $X^*$ weakly* compact if and only if it is weakly* sequentially compact?  Does one imply the other? Perhaps I should make this next one a separate question, but I'd prefer to keep all of this in one place. Is the weak* topology on $X^*$ Hausdorff?  Is the weak topology on $X$ Hausdorff? Motivation: I would like to say that if a subset of $X^*$ is weakly* compact, then it is weakly* closed, and that if a subset of $X$ is weakly compact, then it is weakly closed.",,"['analysis', 'functional-analysis', 'compactness']"
41,Are polynomials dense in Gaussian Sobolev space?,Are polynomials dense in Gaussian Sobolev space?,,"Let $\mu$ be standard Gaussian measure on $\mathbb{R}^n$, i.e. $d\mu = (2\pi)^{-n/2} e^{-|x|^2/2} dx$, and define the Gaussian Sobolev space $H^1(\mu)$ to be the completion of $C_c^\infty(\mathbb{R}^n)$ under the inner product $$\langle f,g \rangle_{H^1(\mu)} := \int f g\, d\mu + \int \nabla f \cdot \nabla g\, d\mu.$$ It is easy to see that polynomials are in $H^1(\mu)$.  Do they form a dense set? I am quite sure the answer must be yes, but can't find or construct a proof in general.  I do have a proof for $n=1$, which I can post if anyone wants.  It may be useful to know that the polynomials are dense in $L^2(\mu)$. Edit : Here is a proof for $n=1$. It is sufficient to show that any $f \in C^\infty_c(\mathbb{R})$ can be approximated by polynomials.  We know polynomials are dense in $L^2(\mu)$, so choose a sequence of polynomials $q_n \to f'$ in $L^2(\mu)$.  Set $p_n(x) = \int_0^x q_n(y)\,dy + f(0)$; $p_n$ is also a polynomial.  By construction we have $p_n' \to f'$ in $L^2(\mu)$; it remains to show $p_n \to f$ in $L^2(\mu)$.  Now we have $$ \begin{align*} \int_0^\infty |p_n(x) - f(x)|^2 e^{-x^2/2} dx &= \int_0^\infty \left(\int_0^x (q_n(y) - f'(y)) dy \right)^2 e^{-x^2/2} dx \\ &\le \int_0^\infty \int_0^x (q_n(y) - f'(y))^2\,dy \,x e^{-x^2/2} dx \\ &= \int_0^\infty (q_n(x) - f'(x))^2 e^{-x^2/2} dx \to 0 \end{align*}$$ where we used Cauchy-Schwarz in the second line and integration by parts in the third.  The $\int_{-\infty}^0$ term can be handled the same with appropriate minus signs. The problem with $n > 1$ is I don't see how to use the fundamental theorem of calculus in the same way.","Let $\mu$ be standard Gaussian measure on $\mathbb{R}^n$, i.e. $d\mu = (2\pi)^{-n/2} e^{-|x|^2/2} dx$, and define the Gaussian Sobolev space $H^1(\mu)$ to be the completion of $C_c^\infty(\mathbb{R}^n)$ under the inner product $$\langle f,g \rangle_{H^1(\mu)} := \int f g\, d\mu + \int \nabla f \cdot \nabla g\, d\mu.$$ It is easy to see that polynomials are in $H^1(\mu)$.  Do they form a dense set? I am quite sure the answer must be yes, but can't find or construct a proof in general.  I do have a proof for $n=1$, which I can post if anyone wants.  It may be useful to know that the polynomials are dense in $L^2(\mu)$. Edit : Here is a proof for $n=1$. It is sufficient to show that any $f \in C^\infty_c(\mathbb{R})$ can be approximated by polynomials.  We know polynomials are dense in $L^2(\mu)$, so choose a sequence of polynomials $q_n \to f'$ in $L^2(\mu)$.  Set $p_n(x) = \int_0^x q_n(y)\,dy + f(0)$; $p_n$ is also a polynomial.  By construction we have $p_n' \to f'$ in $L^2(\mu)$; it remains to show $p_n \to f$ in $L^2(\mu)$.  Now we have $$ \begin{align*} \int_0^\infty |p_n(x) - f(x)|^2 e^{-x^2/2} dx &= \int_0^\infty \left(\int_0^x (q_n(y) - f'(y)) dy \right)^2 e^{-x^2/2} dx \\ &\le \int_0^\infty \int_0^x (q_n(y) - f'(y))^2\,dy \,x e^{-x^2/2} dx \\ &= \int_0^\infty (q_n(x) - f'(x))^2 e^{-x^2/2} dx \to 0 \end{align*}$$ where we used Cauchy-Schwarz in the second line and integration by parts in the third.  The $\int_{-\infty}^0$ term can be handled the same with appropriate minus signs. The problem with $n > 1$ is I don't see how to use the fundamental theorem of calculus in the same way.",,"['functional-analysis', 'probability-theory', 'probability-distributions', 'sobolev-spaces']"
42,Which functions are tempered distributions?,Which functions are tempered distributions?,,"Today's problem originates in this conversation with Willie Wong about the Fourier transform of a Gaussian function $$g_{\sigma}(x)=e^{-\sigma \lvert x \rvert^2},\quad x \in \mathbb{R}^n;$$ where $\sigma$ is a complex parameter. When $\Re (\sigma) \ge 0$, $g_\sigma$ is a tempered distribution$^{[1]}$ and so it is Fourier transformable. On the contrary, it appears obvious that if $\Re(\sigma) <0$ then $g_\sigma$ is not tempered. Question 1 . What is the fastest way to prove this? My guess is that one should exploit the fact that the pairing  $$\int_{\mathbb{R}^n} g_\sigma(x)\varphi(x)\, dx$$  makes no sense for some $\varphi \in \mathcal{S}(\mathbb{R}^n)$. But is it enough? I am afraid that this argument is incomplete. Question 2 . More generally, is there some characterization of tempered functions , that is, functions which belong to the space $L^1_{\text{loc}}(\mathbb{R})\cap \mathcal{S}'(\mathbb{R})$? The only tempered functions that I know are polynomially growing functions . By this I mean the functions of the form $Pu$, where $P$ is a polynomial and $u \in L^p(\mathbb{R}^n)$ for some $p\in[1, \infty]$. Question 3 . Is it true that all tempered functions are polynomially  growing functions? $^{[1]}$ The definition of tempered distribution I refer to is the following. A distribution $T \in \mathcal{D}'(\mathbb{R}^n)$ is called tempered if for every sequence $\varphi_n \in \mathcal{D}(\mathbb{R}^n)$ such that $\varphi_n \to 0$ in the Schwartz class sense, it happens that $\langle T, \varphi_n \rangle \to 0$. If this is the case then $T$ uniquely extends to a continuous linear functional on $\mathcal{S}(\mathbb{R}^n)$ and we write $T \in \mathcal{S}'(\mathbb{R}^n)$.","Today's problem originates in this conversation with Willie Wong about the Fourier transform of a Gaussian function $$g_{\sigma}(x)=e^{-\sigma \lvert x \rvert^2},\quad x \in \mathbb{R}^n;$$ where $\sigma$ is a complex parameter. When $\Re (\sigma) \ge 0$, $g_\sigma$ is a tempered distribution$^{[1]}$ and so it is Fourier transformable. On the contrary, it appears obvious that if $\Re(\sigma) <0$ then $g_\sigma$ is not tempered. Question 1 . What is the fastest way to prove this? My guess is that one should exploit the fact that the pairing  $$\int_{\mathbb{R}^n} g_\sigma(x)\varphi(x)\, dx$$  makes no sense for some $\varphi \in \mathcal{S}(\mathbb{R}^n)$. But is it enough? I am afraid that this argument is incomplete. Question 2 . More generally, is there some characterization of tempered functions , that is, functions which belong to the space $L^1_{\text{loc}}(\mathbb{R})\cap \mathcal{S}'(\mathbb{R})$? The only tempered functions that I know are polynomially growing functions . By this I mean the functions of the form $Pu$, where $P$ is a polynomial and $u \in L^p(\mathbb{R}^n)$ for some $p\in[1, \infty]$. Question 3 . Is it true that all tempered functions are polynomially  growing functions? $^{[1]}$ The definition of tempered distribution I refer to is the following. A distribution $T \in \mathcal{D}'(\mathbb{R}^n)$ is called tempered if for every sequence $\varphi_n \in \mathcal{D}(\mathbb{R}^n)$ such that $\varphi_n \to 0$ in the Schwartz class sense, it happens that $\langle T, \varphi_n \rangle \to 0$. If this is the case then $T$ uniquely extends to a continuous linear functional on $\mathcal{S}(\mathbb{R}^n)$ and we write $T \in \mathcal{S}'(\mathbb{R}^n)$.",,"['functional-analysis', 'fourier-analysis', 'distribution-theory', 'gaussian-integral']"
43,Why do we need the Hahn-Banach Theorem to extend a bounded linear functional?,Why do we need the Hahn-Banach Theorem to extend a bounded linear functional?,,"I'm beginning with functional analysis and I have a related question. It concerns the Hahn-Banach theorem. In particular, I cannot appreciate its value, most probably because I don't understand it. I mean the Hahn-Banach theorem in it's most common form, like it is stated in the relevant Wikipedia article . In particular, with the notation of the Wikipedia article, my (probably pretty dump) question is : why do we need the Hahn-Banach theorem to extend the bounded linear functional $\phi$ and don't we just consider its trivial extension , i.e., $\psi(x) = \phi(x), \forall x \in U$ and null everywhere else?","I'm beginning with functional analysis and I have a related question. It concerns the Hahn-Banach theorem. In particular, I cannot appreciate its value, most probably because I don't understand it. I mean the Hahn-Banach theorem in it's most common form, like it is stated in the relevant Wikipedia article . In particular, with the notation of the Wikipedia article, my (probably pretty dump) question is : why do we need the Hahn-Banach theorem to extend the bounded linear functional $\phi$ and don't we just consider its trivial extension , i.e., $\psi(x) = \phi(x), \forall x \in U$ and null everywhere else?",,['functional-analysis']
44,"What is the main purpose of learning about different spaces, like Hilbert, Banach, etc?","What is the main purpose of learning about different spaces, like Hilbert, Banach, etc?",,"I just started to learn about functional analysis and have started to learn about various spaces, like $L^{p}$, Banach, and Hilbert spaces. However, right now my understanding is rather mechanical . That is, my understanding of say the Hilbert space is that it is a vector space with an inner product such that the norm defined by it turns into a complete metric space. Additionally, that generally vector spaces will fulfill certain criteria. Hence, my understanding is rather unmotivated by why they are defined a certain way. Is there a reason why certain vector spaces are defined the way they are? What is it about vector spaces having certain properties that makes it appealing to study? Does it allow us to do certain things on the spaces that makes it so that we must use it? Sorry if my understanding is rather weak, I just started to learn more advanced spaces from a purely mathematical point of view and have had a hard time getting an answer from professors. In summary, right now it seems that someone just gave a bunch of random conditions to define certain vector spaces and I really have no idea why they defined it that way, and why it couldn't be defined with other conditions.","I just started to learn about functional analysis and have started to learn about various spaces, like $L^{p}$, Banach, and Hilbert spaces. However, right now my understanding is rather mechanical . That is, my understanding of say the Hilbert space is that it is a vector space with an inner product such that the norm defined by it turns into a complete metric space. Additionally, that generally vector spaces will fulfill certain criteria. Hence, my understanding is rather unmotivated by why they are defined a certain way. Is there a reason why certain vector spaces are defined the way they are? What is it about vector spaces having certain properties that makes it appealing to study? Does it allow us to do certain things on the spaces that makes it so that we must use it? Sorry if my understanding is rather weak, I just started to learn more advanced spaces from a purely mathematical point of view and have had a hard time getting an answer from professors. In summary, right now it seems that someone just gave a bunch of random conditions to define certain vector spaces and I really have no idea why they defined it that way, and why it couldn't be defined with other conditions.",,"['functional-analysis', 'soft-question']"
45,Why study operator spaces?,Why study operator spaces?,,"I'm currently enrolled in an operator spaces course and I'm finding it difficult to understand why we study them in the first place. Functional analysis is motivated well enough for me and even though I don't have a firm grasp on them, I guess I can see why $C^{\ast}$-algebras are studied as well (purely from a quantum mechanics point of view). However I fail to see what the motivation is for studying operator spaces or why they're useful/important. What is their motivation? What led people to be interested in them and what is so special about completely bounded/positive maps that we study them?","I'm currently enrolled in an operator spaces course and I'm finding it difficult to understand why we study them in the first place. Functional analysis is motivated well enough for me and even though I don't have a firm grasp on them, I guess I can see why $C^{\ast}$-algebras are studied as well (purely from a quantum mechanics point of view). However I fail to see what the motivation is for studying operator spaces or why they're useful/important. What is their motivation? What led people to be interested in them and what is so special about completely bounded/positive maps that we study them?",,"['functional-analysis', 'operator-algebras', 'operator-spaces']"
46,Operator norm and tensor norms,Operator norm and tensor norms,,"I have a linear operator $A\in\mathcal{L}(X,Y)$ where $X$ and $Y$ are some Banach spaces (or Hilbert spaces would also do, if that simplifies the answer.). The operator norm of $A$ is given by $$ \|A\|=\sup_{x\in X} \|Ax\|_Y/\|x\|_X. $$ Now, if the operator is of finite rank (makes things a little easier), I can view it as an element of the tensor product space $X^*\otimes Y$, where $X^*$ is the continuous dual of $X$, such that $$ A=\sum_{i=1}^n u_i^*\otimes v_i $$ with $u_i^*\in X^*$ and $v_i\in Y$. Now, there are quite a few tensor norms that I can define on $X^*\otimes Y$ in order to complete the space, e.g. the projective norm  $$ \epsilon(A)=\inf\left(\sum_{i=1}^n \|u_i^*\|_{X^*} \|v_i\|_Y\right) $$ where the infimum goes over all such decompositions, and (as I take from R. Ryan, Introduction to Tensor Products of Banach Spaces) 13 more norms you can sensibly define on a tensor product space. Now my question is: is there any of these tensor norms that coincides with the operator norm? The only thing I could show is, that the projective norm if always larger or equal to the operator norm. However, that doesn't help me much, I would need equality.","I have a linear operator $A\in\mathcal{L}(X,Y)$ where $X$ and $Y$ are some Banach spaces (or Hilbert spaces would also do, if that simplifies the answer.). The operator norm of $A$ is given by $$ \|A\|=\sup_{x\in X} \|Ax\|_Y/\|x\|_X. $$ Now, if the operator is of finite rank (makes things a little easier), I can view it as an element of the tensor product space $X^*\otimes Y$, where $X^*$ is the continuous dual of $X$, such that $$ A=\sum_{i=1}^n u_i^*\otimes v_i $$ with $u_i^*\in X^*$ and $v_i\in Y$. Now, there are quite a few tensor norms that I can define on $X^*\otimes Y$ in order to complete the space, e.g. the projective norm  $$ \epsilon(A)=\inf\left(\sum_{i=1}^n \|u_i^*\|_{X^*} \|v_i\|_Y\right) $$ where the infimum goes over all such decompositions, and (as I take from R. Ryan, Introduction to Tensor Products of Banach Spaces) 13 more norms you can sensibly define on a tensor product space. Now my question is: is there any of these tensor norms that coincides with the operator norm? The only thing I could show is, that the projective norm if always larger or equal to the operator norm. However, that doesn't help me much, I would need equality.",,"['functional-analysis', 'banach-spaces', 'hilbert-spaces', 'operator-theory', 'tensor-products']"
47,Are the coordinate functions of a Hamel basis for an infinite dimensional Banach space discontinuous?,Are the coordinate functions of a Hamel basis for an infinite dimensional Banach space discontinuous?,,"The question is in the title really, but I suppose I could at least fix some notation here. Let $X$ be an infinite dimensional Banach space - over the reals for the sake of concreteness. Use choice to produce a Hamel basis $(x_i)_{i \in I}$ for $X$. I have the impression that this basis should necessarily interact badly with the topology and, therefore, not be of much (any?) use for doing analysis on $X$, but I've never really thought about why this should be the case. Is there a rigorous sense in which we can say that this basis is ""useless""? One way to make this precise (although I'd be interested in other points of view) might be to consider the corresponding linear functionals $(f_i)_{i \in I}$ - uniquely determined by taking $f_i(x_j)$ equal to $1$ or $0$ according as $i=j$ or not. I would be very surprised if it were possible for any of these functionals to be continuous, but this conviction is based only on my vague notion that a Hamel basis for $X$ must be somehow ""pathological"" and not on any sound reasoning. Because I have no idea how to approach this question (admittedly also because I don't think this is a particularly constructive thing to be dwelling on at this time of year...) I thought I would appeal to the hard-earned wisdom of the good people of Mathematics Stack Exchange. Edit for clarity: I actually already know at most finitely many of the coordinate functions can be continuous (see comment below) which is, now that I think about it, a fairly critical failure in and of itself and probably enough to justify the word ""useless"" above. My question is whether they must all be discontinuous.","The question is in the title really, but I suppose I could at least fix some notation here. Let $X$ be an infinite dimensional Banach space - over the reals for the sake of concreteness. Use choice to produce a Hamel basis $(x_i)_{i \in I}$ for $X$. I have the impression that this basis should necessarily interact badly with the topology and, therefore, not be of much (any?) use for doing analysis on $X$, but I've never really thought about why this should be the case. Is there a rigorous sense in which we can say that this basis is ""useless""? One way to make this precise (although I'd be interested in other points of view) might be to consider the corresponding linear functionals $(f_i)_{i \in I}$ - uniquely determined by taking $f_i(x_j)$ equal to $1$ or $0$ according as $i=j$ or not. I would be very surprised if it were possible for any of these functionals to be continuous, but this conviction is based only on my vague notion that a Hamel basis for $X$ must be somehow ""pathological"" and not on any sound reasoning. Because I have no idea how to approach this question (admittedly also because I don't think this is a particularly constructive thing to be dwelling on at this time of year...) I thought I would appeal to the hard-earned wisdom of the good people of Mathematics Stack Exchange. Edit for clarity: I actually already know at most finitely many of the coordinate functions can be continuous (see comment below) which is, now that I think about it, a fairly critical failure in and of itself and probably enough to justify the word ""useless"" above. My question is whether they must all be discontinuous.",,"['functional-analysis', 'banach-spaces']"
48,Liouville's theorem for Banach spaces without the Hahn-Banach theorem?,Liouville's theorem for Banach spaces without the Hahn-Banach theorem?,,"Let $B$ be a (complex) Banach space. A function $f : \mathbb{C} \to B$ is holomorphic if $\lim_{w \to z} \frac{f(w) - f(z)}{w - z}$ exists for all $z$, just as in the ordinary case where $B = \mathbb{C}$. Liouville's theorem for Banach spaces says that if $f$ is holomorphic and $|f|$ is bounded, then $f$ is constant. The only way I know how to prove this uses the Hahn-Banach theorem: once we know that continuous linear functionals on $B$ separate points, we can apply the usual Liouville's theorem to $\lambda(f)$ for every such functional $\lambda : B \to \mathbb{C}$. Can we avoid using Hahn-Banach? What if $B$ is in addition a Banach algebra? Motivation: Liouville's theorem is useful in the elementary theory of Banach algebras, where it seems to me that we usually don't need the big theorems of Banach space theory (e.g. the closed graph theorem), and I would like to be able to develop this theory within ZF if possible. It would be very interesting if this were actually independent of ZF.","Let $B$ be a (complex) Banach space. A function $f : \mathbb{C} \to B$ is holomorphic if $\lim_{w \to z} \frac{f(w) - f(z)}{w - z}$ exists for all $z$, just as in the ordinary case where $B = \mathbb{C}$. Liouville's theorem for Banach spaces says that if $f$ is holomorphic and $|f|$ is bounded, then $f$ is constant. The only way I know how to prove this uses the Hahn-Banach theorem: once we know that continuous linear functionals on $B$ separate points, we can apply the usual Liouville's theorem to $\lambda(f)$ for every such functional $\lambda : B \to \mathbb{C}$. Can we avoid using Hahn-Banach? What if $B$ is in addition a Banach algebra? Motivation: Liouville's theorem is useful in the elementary theory of Banach algebras, where it seems to me that we usually don't need the big theorems of Banach space theory (e.g. the closed graph theorem), and I would like to be able to develop this theory within ZF if possible. It would be very interesting if this were actually independent of ZF.",,"['complex-analysis', 'functional-analysis', 'banach-spaces', 'banach-algebras']"
49,A property of exponential of operators,A property of exponential of operators,,"Let $X$ be a Banach space. $A\in B(X)$ is a bounded operator. we can define $e^{tA}$ by $$e^{tA}=\sum_{k=0}^{+\infty}\frac{t^kA^k}{k!}$$ I am interested in this property: If $x\in X$, such that the function $t\mapsto e^{tA}x$ is bounded on $\mathbb{R}$, then we have necessarily $$\inf_{t\in \mathbb{R}}|e^{tA}x|>0 \ \ \ \ \ or \ \ \ \ e^{tA}x=0 \ \ (i.e. \ \ x=0).$$ This property is clear in the scalar case $A=a\in \mathbb{C}$. Because $t\mapsto e^{ta}x$ is bounded on $\mathbb{R}$ if and only if $Re(a)=0$, and then $\inf_{t\in \mathbb{R}}|e^{ta}x|=|x|$. This property is also true if $X$ is finite dimensional i.e if $A$ is a matrix, and was answered here in math stack exchange. So my question is: "" Does this property hold if $X$ is infinite dimensional ? ""","Let $X$ be a Banach space. $A\in B(X)$ is a bounded operator. we can define $e^{tA}$ by $$e^{tA}=\sum_{k=0}^{+\infty}\frac{t^kA^k}{k!}$$ I am interested in this property: If $x\in X$, such that the function $t\mapsto e^{tA}x$ is bounded on $\mathbb{R}$, then we have necessarily $$\inf_{t\in \mathbb{R}}|e^{tA}x|>0 \ \ \ \ \ or \ \ \ \ e^{tA}x=0 \ \ (i.e. \ \ x=0).$$ This property is clear in the scalar case $A=a\in \mathbb{C}$. Because $t\mapsto e^{ta}x$ is bounded on $\mathbb{R}$ if and only if $Re(a)=0$, and then $\inf_{t\in \mathbb{R}}|e^{ta}x|=|x|$. This property is also true if $X$ is finite dimensional i.e if $A$ is a matrix, and was answered here in math stack exchange. So my question is: "" Does this property hold if $X$ is infinite dimensional ? """,,"['functional-analysis', 'operator-theory', 'banach-spaces', 'harmonic-analysis', 'functional-calculus']"
50,Weak topology on an infinite-dimensional normed vector space is not metrizable,Weak topology on an infinite-dimensional normed vector space is not metrizable,,"I've been pondering over this problem for a while now, but I can't come up with a proof or even a useful approach... Let $X$ be am infinite-dimensional normed vector space over $\mathbb{K}$ (that is either $\mathbb{R}$ or $\mathbb{C}$). Then the weak topology $\sigma(X,X^*)$ is not metrizable, i.e. there is no metric $d$ such that the induced topology of $d$ coincides with $\sigma(X,X^*)$. Can anyone help me with this?","I've been pondering over this problem for a while now, but I can't come up with a proof or even a useful approach... Let $X$ be am infinite-dimensional normed vector space over $\mathbb{K}$ (that is either $\mathbb{R}$ or $\mathbb{C}$). Then the weak topology $\sigma(X,X^*)$ is not metrizable, i.e. there is no metric $d$ such that the induced topology of $d$ coincides with $\sigma(X,X^*)$. Can anyone help me with this?",,"['functional-analysis', 'metric-spaces', 'normed-spaces', 'weak-topology']"
51,How to prove the spectrum of the Laplace operator?,How to prove the spectrum of the Laplace operator?,,"How can I prove that the spectrum of the Laplace operator $$\Delta: H^2(\mathbb{R}^N)\subset L^2(\mathbb{R}^N)\rightarrow L^2(\mathbb{R}^N)$$ is $\sigma(\Delta)=[-\infty,0]$?","How can I prove that the spectrum of the Laplace operator $$\Delta: H^2(\mathbb{R}^N)\subset L^2(\mathbb{R}^N)\rightarrow L^2(\mathbb{R}^N)$$ is $\sigma(\Delta)=[-\infty,0]$?",,"['functional-analysis', 'soft-question', 'sobolev-spaces', 'spectral-theory']"
52,A net version of dominated convergence?,A net version of dominated convergence?,,"Let $G$ be a locally compact Hausdorff Abelian topological group.  Let $\mu$ be a Haar measure on $G$, i.e. a regular translation invariant measure.  Let $f$ be fixed in $\mathcal{L}^1(G, \mu)$.  Define the function from $G$ to $\mathcal{L}^1(G)$ that assigns to each $y$ in $G$ the function that takes $x$ in $G$ to $f(xy^{-1})$.  I.e. it assigns the $y$-translate of $f$.  Is this a continuous function of $y$ into $\mathcal{L}^1$? On p.94 3.10 of these notes it is asserted that it is.  The usual proof of this sort of thing in cases where $G=\mathbb{R}$, say, is you use density of compactly supported continuous functions, and then dominated convergence.  The former survives, but dominated convergence does not work on nets.  In fact, a limit of a net of measurable functions need not be measurable.","Let $G$ be a locally compact Hausdorff Abelian topological group.  Let $\mu$ be a Haar measure on $G$, i.e. a regular translation invariant measure.  Let $f$ be fixed in $\mathcal{L}^1(G, \mu)$.  Define the function from $G$ to $\mathcal{L}^1(G)$ that assigns to each $y$ in $G$ the function that takes $x$ in $G$ to $f(xy^{-1})$.  I.e. it assigns the $y$-translate of $f$.  Is this a continuous function of $y$ into $\mathcal{L}^1$? On p.94 3.10 of these notes it is asserted that it is.  The usual proof of this sort of thing in cases where $G=\mathbb{R}$, say, is you use density of compactly supported continuous functions, and then dominated convergence.  The former survives, but dominated convergence does not work on nets.  In fact, a limit of a net of measurable functions need not be measurable.",,"['measure-theory', 'functional-analysis', 'topological-groups', 'harmonic-analysis', 'locally-compact-groups']"
53,Operator norm on product space,Operator norm on product space,,"I have a bilinear operator $B\colon X \times Y\to Z$ with $X,Y,Z$ normed spaces, and define a norm on $X \times Y$ by $\lVert(x,y)\rVert = \lVert x\rVert_X + \lVert y\rVert_Y$ (using the respective norms on $X,Y$). Does the definition of the operator norm then generalize to $\lVert B\rVert = \sup\{\lVert B(x,y)\rVert/\lVert(x,y)\rVert$, $(x,y) \neq 0\}$? Reason for asking: assuming this, $B(x,y) = xy$ does not seem to be a bounded operator (from i.e. $\mathbb{R}^2\to\mathbb{R}$) in this norm (or euclidean norm/ max norm for that matter), which contradicts the continuity (or at least until now I always thought the product operator was continuous!). edit: changed linear to bilinear","I have a bilinear operator $B\colon X \times Y\to Z$ with $X,Y,Z$ normed spaces, and define a norm on $X \times Y$ by $\lVert(x,y)\rVert = \lVert x\rVert_X + \lVert y\rVert_Y$ (using the respective norms on $X,Y$). Does the definition of the operator norm then generalize to $\lVert B\rVert = \sup\{\lVert B(x,y)\rVert/\lVert(x,y)\rVert$, $(x,y) \neq 0\}$? Reason for asking: assuming this, $B(x,y) = xy$ does not seem to be a bounded operator (from i.e. $\mathbb{R}^2\to\mathbb{R}$) in this norm (or euclidean norm/ max norm for that matter), which contradicts the continuity (or at least until now I always thought the product operator was continuous!). edit: changed linear to bilinear",,"['functional-analysis', 'banach-spaces', 'tensor-products', 'normed-spaces']"
54,Contraction mapping in an incomplete metric space,Contraction mapping in an incomplete metric space,,"Let us consider a contraction mapping $f$ acting on metric space $(X,~\rho)$ ( $f:X\to X$ and for any $x,y\in X:\rho(f(x),f(y))\leq k~\rho(x,y),~ 0 < k < 1$ ). If $X$ is complete, then there exists an unique fixed point. But is there an incomplete space for which this property holds as well? I think $X$ should be something like graph of $\text{sin}~{1\over x}$ , but I don't know how to prove it.","Let us consider a contraction mapping acting on metric space ( and for any ). If is complete, then there exists an unique fixed point. But is there an incomplete space for which this property holds as well? I think should be something like graph of , but I don't know how to prove it.","f (X,~\rho) f:X\to X x,y\in X:\rho(f(x),f(y))\leq k~\rho(x,y),~ 0 < k < 1 X X \text{sin}~{1\over x}","['functional-analysis', 'metric-spaces', 'fixed-point-theorems']"
55,Nonlinear function continuous but not bounded,Nonlinear function continuous but not bounded,,"I would like an example of a map $f:H\rightarrow R$, where $H$ is a (infinite dimensional) Hilbert space, and $R$ is the real numbers, such that $f$ is continuous, but $f$ is not bounded on the close unit ball $\{ x\in H : \|x\| \leq 1\}$. Actually, $H$ could be replaced by any Banach space (but not just a normed space-- that's too easy).  My motivation is that if $f$ is linear, this is impossible; but I have next to no intuition about non-linear functions. Edit: Here's an example for $c_0$ which is even differentiable (disclaimer: I found it here: http://www.ms.uky.edu/~larry/paper.dir/korea.ps ).  Define $f:c_0\rightarrow F$ (where F is your field, real or complex) by $$ f(x) = \sum_{n=1}^\infty x_n^n \qquad (x=(x_n)). $$  You can estimate the sum by a geometric progression, so it does converge.  A bit of checking shows that f is Frechet differentible (so certainly continuous).  But $f(1,1,\cdots,1,0,\cdots)=n$ (if there are $n$ ones) so $f$ is not bounded on the closed unit ball.  What I don't immediately see is how to adapt this to $\ell^2$, say.","I would like an example of a map $f:H\rightarrow R$, where $H$ is a (infinite dimensional) Hilbert space, and $R$ is the real numbers, such that $f$ is continuous, but $f$ is not bounded on the close unit ball $\{ x\in H : \|x\| \leq 1\}$. Actually, $H$ could be replaced by any Banach space (but not just a normed space-- that's too easy).  My motivation is that if $f$ is linear, this is impossible; but I have next to no intuition about non-linear functions. Edit: Here's an example for $c_0$ which is even differentiable (disclaimer: I found it here: http://www.ms.uky.edu/~larry/paper.dir/korea.ps ).  Define $f:c_0\rightarrow F$ (where F is your field, real or complex) by $$ f(x) = \sum_{n=1}^\infty x_n^n \qquad (x=(x_n)). $$  You can estimate the sum by a geometric progression, so it does converge.  A bit of checking shows that f is Frechet differentible (so certainly continuous).  But $f(1,1,\cdots,1,0,\cdots)=n$ (if there are $n$ ones) so $f$ is not bounded on the closed unit ball.  What I don't immediately see is how to adapt this to $\ell^2$, say.",,['functional-analysis']
56,Why do we study Cameron-Martin Space and what is the motivation behind it?,Why do we study Cameron-Martin Space and what is the motivation behind it?,,"I'm reading about Gaussian Measures and the chapters always define the Cameron-Martin space shortly after. Typically they'll define a covariance operator first.  Let $U$ be a separable Banach space, and $\mu$ be a centered Gaussian measure on $U$ . $U^*$ is the dual.  The Covariance operator $C:U^*\times U^*\to\mathbb{R}$ is first given by $$C_{\mu}(f)(g):= \int_Uf(x)g(x)\mu(dx)$$ First define $|x|_{H(\mu)} = \sup_{l\in U^*}\{ l(x) : C_{\mu}(l)(l)\leq 1\}.$ The Cameron-Martin space is then defined as $$H(\mu) := \{x \in U : |x|_{H(\mu)} < \infty \}.$$ (At least that's one of a couple definitions) Intuitively, I've also heard that the Cameron-Martin space is the set of all elements that make the null sets of $\mu$ translation-invariant (ie you can shift a null-set by that element and it will still be a null set). But I still feel like I'm missing a broader perspective.","I'm reading about Gaussian Measures and the chapters always define the Cameron-Martin space shortly after. Typically they'll define a covariance operator first.  Let be a separable Banach space, and be a centered Gaussian measure on . is the dual.  The Covariance operator is first given by First define The Cameron-Martin space is then defined as (At least that's one of a couple definitions) Intuitively, I've also heard that the Cameron-Martin space is the set of all elements that make the null sets of translation-invariant (ie you can shift a null-set by that element and it will still be a null set). But I still feel like I'm missing a broader perspective.",U \mu U U^* C:U^*\times U^*\to\mathbb{R} C_{\mu}(f)(g):= \int_Uf(x)g(x)\mu(dx) |x|_{H(\mu)} = \sup_{l\in U^*}\{ l(x) : C_{\mu}(l)(l)\leq 1\}. H(\mu) := \{x \in U : |x|_{H(\mu)} < \infty \}. \mu,"['functional-analysis', 'probability-theory', 'partial-differential-equations', 'stochastic-processes', 'stochastic-differential-equations']"
57,"Weak convergence, together with convergence of norms, implies strong convergence in a Hilbert space.","Weak convergence, together with convergence of norms, implies strong convergence in a Hilbert space.",,"Let $(x_n)$ be a weakly convergent sequence in a Hilbert space $H$ . If $\| x_n \| \to \| x \|$ , show that $x_n$ converges strongly to $x$ . Context This problem comes from a question in my exam paper; the original problem was incorrect.","Let be a weakly convergent sequence in a Hilbert space . If , show that converges strongly to . Context This problem comes from a question in my exam paper; the original problem was incorrect.",(x_n) H \| x_n \| \to \| x \| x_n x,"['functional-analysis', 'convergence-divergence', 'hilbert-spaces', 'weak-convergence']"
58,Geometric intepretation of Holder continuous functions?,Geometric intepretation of Holder continuous functions?,,"I've started working with Holder spaces recently and I'm wondering how I should think of them intuitively? I really have no idea what a function $f$ that is Holder continuous with exponent $\alpha$ is supposed to look like whereas I do have a good idea for other function spaces. $L^{\infty}$: Say we had a function $f$ such that $\Vert f \Vert_{L^\infty([0, 2])} \le 1$. Then I can visualize $f$ as being some function in the box $[0, 2] \times [-1, 1]$. Lipschitz: If we take another function $g$ and say it is Lipschitz continuous with some fixed constant $C$ I know that the slope of the $g$ will always be less than $C$ at any point in its domain which agrees with the vizualization stated on the Wikipedia page regarding a double cone that can be translated along the graph such that the graph always remains outside the cone. Holder: What is the best way to visualize a Holder continuous function with exponent $\alpha$ on a given domain such as, say, $[0, 5]$? Does such a function have a clear geometric interpretation like $L^{\infty}$ functions? What would be an example of such a function if the exponent was $\alpha = 0.2$ for example? Would a function with an exponent of $\alpha = 0.3$ be 'nicer' than one with $\alpha= 0.2$?","I've started working with Holder spaces recently and I'm wondering how I should think of them intuitively? I really have no idea what a function $f$ that is Holder continuous with exponent $\alpha$ is supposed to look like whereas I do have a good idea for other function spaces. $L^{\infty}$: Say we had a function $f$ such that $\Vert f \Vert_{L^\infty([0, 2])} \le 1$. Then I can visualize $f$ as being some function in the box $[0, 2] \times [-1, 1]$. Lipschitz: If we take another function $g$ and say it is Lipschitz continuous with some fixed constant $C$ I know that the slope of the $g$ will always be less than $C$ at any point in its domain which agrees with the vizualization stated on the Wikipedia page regarding a double cone that can be translated along the graph such that the graph always remains outside the cone. Holder: What is the best way to visualize a Holder continuous function with exponent $\alpha$ on a given domain such as, say, $[0, 5]$? Does such a function have a clear geometric interpretation like $L^{\infty}$ functions? What would be an example of such a function if the exponent was $\alpha = 0.2$ for example? Would a function with an exponent of $\alpha = 0.3$ be 'nicer' than one with $\alpha= 0.2$?",,"['functional-analysis', 'partial-differential-equations', 'continuity', 'holder-spaces']"
59,"A closed subspace of $C([0,1])$ with all functions of bounded variation has finite dimension",A closed subspace of  with all functions of bounded variation has finite dimension,"C([0,1])","In several papers on spaceability I found cited the following theorem of Levine and Milman (1940): Theorem: Let $E$ be a closed subspace of $C([0,1])$ (that is $C([0,1],\mathbb{R})$ endowed with the maximum norm $\|\cdot\|_\infty$ ) such that each $f \in E$ is of bounded variation. Then $\dim E < \infty$ . I woluld like to see a proof of this theorem but couldn't find one neither online nor offline. So, I tried to prove it myself, but I got stuck. Here's my attempt: Let $\|f\|_v := |f(0)| + Var_f([0,1])$ , and note that $\|f\|_\infty \le \|f\|_v$ for each $f \in C([0,1]) \cap BV([0,1])$ . Set $$  A_n:=\{f \in E: \|f\|_v \le n\}, \quad n \in \mathbb{N}.  $$ Each $A_n$ is a closed subset of $E$ (note that $E$ is endowed with $\|\cdot\|_\infty$ ) and $E= A_1\cup A_2 \cup A_3 \cup \dots$ . By Baire's Theorem some $A_n$ contains a closed ball of $E$ . Thus the closed unit ball $B_1(E)$ is contained in some $A_n$ . This implies that $\|\cdot\|_\infty$ and $\|\cdot\|_v$ are equivalent norms on $E$ . Now, I would like to prove that $B_1(E)$ is compact. If you replace for a moment ""of bounded variation"" by ""Lipschitz continuous"", then Arzela-Ascoli could be applied at this point and $\dim E < \infty$ would follow. But a closed and bounded subset $M$ of $C([0,1])$ with the property that $\|f\|_v \le c$ for a constant $c$ and each $f \in M$ is not compact, in general (e.g. $M=\{t \mapsto t^n: n \in \mathbb{N}\}$ ). Thus, in a proof of compactness of $B_1(E)$ the vector space structure of $E$ should play a central role. I can explain by an example what I mean by that: Consider the functions $f_n:[0,1] \to \mathbb{R}$ , $n \ge 2$ defined as $$ f_n(x)=nx ~ (x \in [0,1/n]), ~~ f_n(x)=2-nx ~ (x \in [1/n,2/n]), ~~ f_n(x)=0 ~ (x \in [2/n,1]). $$ There is a sequence $(n_k)$ such that $\|f_{n_1} + \dots +f_{n_k}\|_\infty$ is uniformly bounded in $k$ and $\|f_{n_1} + \dots + f_{n_k}\|_v \to \infty$ as $k \to \infty$ . Thus $f_n \in E$ $(n \ge 2)$ is impossible. So, I assumed that $\dim E = \infty$ and tried to construct functions in $E$ with $\|f\|_\infty$ small but $\|f\|_v$ big, but didn't succeed. A second idea leading to nowhere up to now was that Helly's First Theorem could help: It's known that each sequence in $B_1(E)$ has a pointwise convergent subsequence. So, three questions: Can somebody finish this proof? Is there a better (easier) proof? Is there an accessible reference with a proof of this theorem? Thanks for any support. Edit: The Lemma mentioned by daw in the comments would indeed finish the proof: Let $(f_n)$ be a sequence in $B_1(E)$ , w.l.o.g. pointwise convergent (Helly). Then it is a Cauchy sequence in $E$ : Otherwise there is some $\varepsilon_0 > 0$ such that $$ \forall n \exists k_n,l_n \ge n: ~ \|f_{k_n}-f_{l_n}\|_\infty \ge \varepsilon_0. $$ But $f_{k_n}-f_{l_n} \to 0$ pointwise as $n \to \infty$ , hence by the Lemma $\|f_{k_n}-f_{l_n}\|_\infty \to 0$ as $n \to \infty$ , a contradiction. Thus all is reduced to prove the following Lemma : If $(f_n)$ is a bounded sequence in $E$ with $f_n \to 0$ pointwise, then $\|f_n\|_\infty \to 0$ .","In several papers on spaceability I found cited the following theorem of Levine and Milman (1940): Theorem: Let be a closed subspace of (that is endowed with the maximum norm ) such that each is of bounded variation. Then . I woluld like to see a proof of this theorem but couldn't find one neither online nor offline. So, I tried to prove it myself, but I got stuck. Here's my attempt: Let , and note that for each . Set Each is a closed subset of (note that is endowed with ) and . By Baire's Theorem some contains a closed ball of . Thus the closed unit ball is contained in some . This implies that and are equivalent norms on . Now, I would like to prove that is compact. If you replace for a moment ""of bounded variation"" by ""Lipschitz continuous"", then Arzela-Ascoli could be applied at this point and would follow. But a closed and bounded subset of with the property that for a constant and each is not compact, in general (e.g. ). Thus, in a proof of compactness of the vector space structure of should play a central role. I can explain by an example what I mean by that: Consider the functions , defined as There is a sequence such that is uniformly bounded in and as . Thus is impossible. So, I assumed that and tried to construct functions in with small but big, but didn't succeed. A second idea leading to nowhere up to now was that Helly's First Theorem could help: It's known that each sequence in has a pointwise convergent subsequence. So, three questions: Can somebody finish this proof? Is there a better (easier) proof? Is there an accessible reference with a proof of this theorem? Thanks for any support. Edit: The Lemma mentioned by daw in the comments would indeed finish the proof: Let be a sequence in , w.l.o.g. pointwise convergent (Helly). Then it is a Cauchy sequence in : Otherwise there is some such that But pointwise as , hence by the Lemma as , a contradiction. Thus all is reduced to prove the following Lemma : If is a bounded sequence in with pointwise, then .","E C([0,1]) C([0,1],\mathbb{R}) \|\cdot\|_\infty f \in E \dim E < \infty \|f\|_v := |f(0)| + Var_f([0,1]) \|f\|_\infty \le \|f\|_v f \in C([0,1]) \cap BV([0,1]) 
 A_n:=\{f \in E: \|f\|_v \le n\}, \quad n \in \mathbb{N}.
  A_n E E \|\cdot\|_\infty E= A_1\cup A_2 \cup A_3 \cup \dots A_n E B_1(E) A_n \|\cdot\|_\infty \|\cdot\|_v E B_1(E) \dim E < \infty M C([0,1]) \|f\|_v \le c c f \in M M=\{t \mapsto t^n: n \in \mathbb{N}\} B_1(E) E f_n:[0,1] \to \mathbb{R} n \ge 2 
f_n(x)=nx ~ (x \in [0,1/n]), ~~ f_n(x)=2-nx ~ (x \in [1/n,2/n]), ~~ f_n(x)=0 ~ (x \in [2/n,1]).
 (n_k) \|f_{n_1} + \dots +f_{n_k}\|_\infty k \|f_{n_1} + \dots + f_{n_k}\|_v \to \infty k \to \infty f_n \in E (n \ge 2) \dim E = \infty E \|f\|_\infty \|f\|_v B_1(E) (f_n) B_1(E) E \varepsilon_0 > 0 
\forall n \exists k_n,l_n \ge n: ~ \|f_{k_n}-f_{l_n}\|_\infty \ge \varepsilon_0.
 f_{k_n}-f_{l_n} \to 0 n \to \infty \|f_{k_n}-f_{l_n}\|_\infty \to 0 n \to \infty (f_n) E f_n \to 0 \|f_n\|_\infty \to 0","['functional-analysis', 'bounded-variation']"
60,Hilbert space adjoint vs Banach space adjoint?,Hilbert space adjoint vs Banach space adjoint?,,"I have read that there are two 'options' for an adjoint when dealing with Hilbert spaces. Let $T : X \to Y$ be a bounded linear operator between the Hilbert spaces $X$ and $Y$. The Hilbert space adjoint: Define $T^* : Y \to X$ by $( T^*(y), x)_X = (y, T x)_Y$. The ""usual"" Banach space adjoint: Define $T^* : Y' \to X'$ by $\langle T^*(y^*), x \rangle_{X',X} = \langle y^*, T x\rangle_{Y',Y}$. Here, $(\cdot,\cdot)_X$ refers to the scalar product in $X$, whereas $\langle \cdot, \cdot \rangle_{X',X}$ refers to the duality product between $X'$ and $X$. It seems to me that these are both exactly the same, its just that we identify the duality product with the scalar product because we are in a Hilbert space and have an inner product at our disposal. Is this correct or are the adjoints in 1. and 2. fundamentally different?","I have read that there are two 'options' for an adjoint when dealing with Hilbert spaces. Let $T : X \to Y$ be a bounded linear operator between the Hilbert spaces $X$ and $Y$. The Hilbert space adjoint: Define $T^* : Y \to X$ by $( T^*(y), x)_X = (y, T x)_Y$. The ""usual"" Banach space adjoint: Define $T^* : Y' \to X'$ by $\langle T^*(y^*), x \rangle_{X',X} = \langle y^*, T x\rangle_{Y',Y}$. Here, $(\cdot,\cdot)_X$ refers to the scalar product in $X$, whereas $\langle \cdot, \cdot \rangle_{X',X}$ refers to the duality product between $X'$ and $X$. It seems to me that these are both exactly the same, its just that we identify the duality product with the scalar product because we are in a Hilbert space and have an inner product at our disposal. Is this correct or are the adjoints in 1. and 2. fundamentally different?",,"['functional-analysis', 'operator-theory', 'hilbert-spaces']"
61,$C^*$-algebra which is also a Hilbert space?,-algebra which is also a Hilbert space?,C^*,"Does there exist a nontrivial (i.e. other than $\mathbb{C}$) example of a $C^*$-algebra which is also a Hilbert space (in the same norm, of course)? For $\mathbb{C}^n$ with $n > 1$ the answer is no by uniqueness of norm in $C^*$-algebras, since $\mathbb{C}^n$ is a $C^*$-algebra in the $\ell^\infty$ norm, which is not given by an inner product.  What about more generally?","Does there exist a nontrivial (i.e. other than $\mathbb{C}$) example of a $C^*$-algebra which is also a Hilbert space (in the same norm, of course)? For $\mathbb{C}^n$ with $n > 1$ the answer is no by uniqueness of norm in $C^*$-algebras, since $\mathbb{C}^n$ is a $C^*$-algebra in the $\ell^\infty$ norm, which is not given by an inner product.  What about more generally?",,"['functional-analysis', 'operator-algebras', 'c-star-algebras']"
62,Why isometric isomorphic between Banach spaces means we can identify them?,Why isometric isomorphic between Banach spaces means we can identify them?,,"Is the ""isometric"" part really necessary? For what reason is that? Eg. we prove that there is an isometric isomorphism between $(L^p)'$ and $L^q$ ($(p,q)$ conjugate) and then we identify them together as the same space. If they were isomorphic but not necessarily isometric, could we not identify them?","Is the ""isometric"" part really necessary? For what reason is that? Eg. we prove that there is an isometric isomorphism between $(L^p)'$ and $L^q$ ($(p,q)$ conjugate) and then we identify them together as the same space. If they were isomorphic but not necessarily isometric, could we not identify them?",,"['functional-analysis', 'banach-spaces']"
63,Medial Limit of Mokobodzki (case of Banach Limit),Medial Limit of Mokobodzki (case of Banach Limit),,"A classical Banach limit is very useful concept for me, but there is a problem with the integration and even with the measurability, this means for a sequence $(f_n)_{n\in \mathbb{N}}$ of measurable (eg borel) and uniformly bounded functions, the function $x \mapsto L((f_n(x))_{n\in\mathbb{N}})$ , where $L$ is Banach limit, is not measurable in general. I heard about a stronger concept of Banach limit of Mokobodzki called ""medial limit"", that exists, assuming the continuum hypothesis. This functional apparently has the same properties like Banach limit and additionally, which is important for me, commutes with integration in appropriate settings, this means it would preserve the measurability and satisfied condition $M((\int f_n(x)\mu(dx))_{n\in\mathbb{N}}))=\int M((f_n(x))_{n\in\mathbb{N}})\mu(dx)$ , with appropriate assumptions. Unfortunately, I found only a brief mention of this notion in the available literature. Could somebody explain to me this idea more precisely or point me to available literature on this subject?","A classical Banach limit is very useful concept for me, but there is a problem with the integration and even with the measurability, this means for a sequence of measurable (eg borel) and uniformly bounded functions, the function , where is Banach limit, is not measurable in general. I heard about a stronger concept of Banach limit of Mokobodzki called ""medial limit"", that exists, assuming the continuum hypothesis. This functional apparently has the same properties like Banach limit and additionally, which is important for me, commutes with integration in appropriate settings, this means it would preserve the measurability and satisfied condition , with appropriate assumptions. Unfortunately, I found only a brief mention of this notion in the available literature. Could somebody explain to me this idea more precisely or point me to available literature on this subject?",(f_n)_{n\in \mathbb{N}} x \mapsto L((f_n(x))_{n\in\mathbb{N}}) L M((\int f_n(x)\mu(dx))_{n\in\mathbb{N}}))=\int M((f_n(x))_{n\in\mathbb{N}})\mu(dx),"['functional-analysis', 'measure-theory', 'set-theory', 'cardinals']"
64,Complement of $c_{0}$ in $\ell^{\infty}$,Complement of  in,c_{0} \ell^{\infty},How can I show that $c_{0}$ cannot be complemented in $\ell^{\infty}$? Complement in the following sense $$c_{0}+V = \ell^{\infty}$$ And the projections are continuous.,How can I show that $c_{0}$ cannot be complemented in $\ell^{\infty}$? Complement in the following sense $$c_{0}+V = \ell^{\infty}$$ And the projections are continuous.,,"['functional-analysis', 'banach-spaces']"
65,Question about proof that finite-dimensional subspaces of normed vector spaces are direct summands,Question about proof that finite-dimensional subspaces of normed vector spaces are direct summands,,"I am reading a proof that finite-dimensional subspaces of normed vector spaces have closed direct sum complements. This is the proof: Let $\{e_1, ..., e_n\}$ be a basis for $\mathcal M$. Every $x \in   \mathcal M$ has then a unique representation $$x = \alpha_1(x)e_1 +...+  \alpha_n(x)e_n.$$ Each $\alpha_i$ is a continuous linear functional on    $\mathcal M$ (a linear map from  finite dimensional space is always    continuous) which extends to a member of $\mathcal X^*$,  by the    Hahn-Banach theorem ($\mathcal X^*$ is the dual of $\mathcal X$). Let    $\mathcal N$ be the intersection of the null spaces of these exten­sions. Then $\mathcal X = \mathcal M\oplus \mathcal N$. I follow it until the last sentence. Clearly $\mathcal N$ is closed, as it is the intersection of closed sets (the inverse of $0$ under any continuous function, and in particular any linear functional on a vector space, is closed). Also it is easy to see that $\mathcal M \cap \mathcal N= \{0\}$, since if some $m\in\mathcal M$ is in every null space, it must have the zero coefficient for every basis vector, and so it must be zero. My question: Why do we have $\mathcal X =\mathcal M + \mathcal N$? This seems to only hold if the extension given by Hahn-Banach is zero off of $\mathcal M$, but I see no reason why this should be the case.","I am reading a proof that finite-dimensional subspaces of normed vector spaces have closed direct sum complements. This is the proof: Let $\{e_1, ..., e_n\}$ be a basis for $\mathcal M$. Every $x \in   \mathcal M$ has then a unique representation $$x = \alpha_1(x)e_1 +...+  \alpha_n(x)e_n.$$ Each $\alpha_i$ is a continuous linear functional on    $\mathcal M$ (a linear map from  finite dimensional space is always    continuous) which extends to a member of $\mathcal X^*$,  by the    Hahn-Banach theorem ($\mathcal X^*$ is the dual of $\mathcal X$). Let    $\mathcal N$ be the intersection of the null spaces of these exten­sions. Then $\mathcal X = \mathcal M\oplus \mathcal N$. I follow it until the last sentence. Clearly $\mathcal N$ is closed, as it is the intersection of closed sets (the inverse of $0$ under any continuous function, and in particular any linear functional on a vector space, is closed). Also it is easy to see that $\mathcal M \cap \mathcal N= \{0\}$, since if some $m\in\mathcal M$ is in every null space, it must have the zero coefficient for every basis vector, and so it must be zero. My question: Why do we have $\mathcal X =\mathcal M + \mathcal N$? This seems to only hold if the extension given by Hahn-Banach is zero off of $\mathcal M$, but I see no reason why this should be the case.",,"['functional-analysis', 'topological-vector-spaces']"
66,Motivation for test function topologies,Motivation for test function topologies,,"I'm a phisicist, who started looking just a little bit into distribution theory, so I can claim to know what I'm doing when throwing about dirac-deltas. Hence I only know two test function spaces: $\mathcal{D}=C^{\infty}_c(\Omega)$ (smooth functions with compact support) and $\mathcal{S}  (\Omega)$ (Schwartz-space) where $\Omega\subseteq\mathbb{R}^n$ open. Now I wonder what the motivation is for defining the topologies on these spaces as one does it. I'm reading ""Fundamental Solutions of Partial Differential Operators"" by Ortner and Wagner. They avoid actually defining the topologies on these spaces and only talk about convergence of sequences. I'm actually not sure what the exact relationship is between the sequence convergence and the topologies. For Schwarz space the question is irrelevant, since it its topology is metric. However $\mathcal{D}$ is not sequential. Question 1: Is there a way to characterize the topology of $\mathcal{D}$ with sequences, as in saying ""the coarsest topology having that convergence properties for sequences"" or something similar? What is the reason most people don't bother talking about the actual topology and seems satisfied with sequences, although the topology is not sequential? I've heared something about that being irrelevant for linear maps, but haven't seen a precise statement. As far as I know the definitions of sequence convergence are ""Uniform convergence of all derivatives on compact sets with supports contained in a compact set"" for $\mathcal{D}$ and ""uniform convergence of all derivatives"" for  $\mathcal{S}$ respectively. The rest of my question deals with motivating these definitions. For Schwarz space ""to some extent"" the motivation, as far as I know, is that almost everything one needs is continuous on this space and maps back into it. In particular all differential operators, and most particularly the Fourier transform. I'm fairly happy with this definition, although there is surely more to understand there. In particular I would like to know (Soft) Question 2: Is there a way to characterize Schwarz space as ""The subspace $X$ of $C^{\infty}(\Omega)$ where ??? can be defined $?:X\to X$"" and the topology (or sequential convergence) is motivated in some way by requiring all the ??? stuff to be continuous? In terms of the ??? stuff I'm thinking of usefull things like derivatives and fourier transforms, not artificial examples making it work out right. [I found a claim that one gets this starting from $L^1(\Omega)$ by taking differentiation and multiplication by polynomials as some kind of closure. Needs clarification and proof though] Let's turn to $\mathcal{D}$: I'm aware of Why does a convergent sequence of test functions have to be supported in a single compact set? , where the motivation of the convergence criteria of $\mathcal{D}$ is discussed to some extent. In particular it seems to me, that the notion of distribution depends on the topology on $\mathcal{D}$. Hence an answer saying something like ""that part doesn't matter for compactly supported distributions"" makes no sense to me. I don't really understand the answers and would like more detail. Can something similar to question 2 be answered for $\mathcal{D}$? (Soft) Question 3: What is the motivation behind the topology for  $\mathcal{D}$? Why all that talk about compact sets?  Certainly I would be also happy with a motivation for what the topological dual (distribution space) should look like and then looking for what spaces have that as their dual. In particular, the quoted question confused me on the following: The space $\mathcal{D}$ being locally convex, the topology is given by a family of semi-norms. That would mean we need to reabsorb the criterion ""all supports of functions in the sequence (when testing for convergence) lie inside some compact set"" into just a set of seminorms. Can this be done? I haven't seen that.","I'm a phisicist, who started looking just a little bit into distribution theory, so I can claim to know what I'm doing when throwing about dirac-deltas. Hence I only know two test function spaces: $\mathcal{D}=C^{\infty}_c(\Omega)$ (smooth functions with compact support) and $\mathcal{S}  (\Omega)$ (Schwartz-space) where $\Omega\subseteq\mathbb{R}^n$ open. Now I wonder what the motivation is for defining the topologies on these spaces as one does it. I'm reading ""Fundamental Solutions of Partial Differential Operators"" by Ortner and Wagner. They avoid actually defining the topologies on these spaces and only talk about convergence of sequences. I'm actually not sure what the exact relationship is between the sequence convergence and the topologies. For Schwarz space the question is irrelevant, since it its topology is metric. However $\mathcal{D}$ is not sequential. Question 1: Is there a way to characterize the topology of $\mathcal{D}$ with sequences, as in saying ""the coarsest topology having that convergence properties for sequences"" or something similar? What is the reason most people don't bother talking about the actual topology and seems satisfied with sequences, although the topology is not sequential? I've heared something about that being irrelevant for linear maps, but haven't seen a precise statement. As far as I know the definitions of sequence convergence are ""Uniform convergence of all derivatives on compact sets with supports contained in a compact set"" for $\mathcal{D}$ and ""uniform convergence of all derivatives"" for  $\mathcal{S}$ respectively. The rest of my question deals with motivating these definitions. For Schwarz space ""to some extent"" the motivation, as far as I know, is that almost everything one needs is continuous on this space and maps back into it. In particular all differential operators, and most particularly the Fourier transform. I'm fairly happy with this definition, although there is surely more to understand there. In particular I would like to know (Soft) Question 2: Is there a way to characterize Schwarz space as ""The subspace $X$ of $C^{\infty}(\Omega)$ where ??? can be defined $?:X\to X$"" and the topology (or sequential convergence) is motivated in some way by requiring all the ??? stuff to be continuous? In terms of the ??? stuff I'm thinking of usefull things like derivatives and fourier transforms, not artificial examples making it work out right. [I found a claim that one gets this starting from $L^1(\Omega)$ by taking differentiation and multiplication by polynomials as some kind of closure. Needs clarification and proof though] Let's turn to $\mathcal{D}$: I'm aware of Why does a convergent sequence of test functions have to be supported in a single compact set? , where the motivation of the convergence criteria of $\mathcal{D}$ is discussed to some extent. In particular it seems to me, that the notion of distribution depends on the topology on $\mathcal{D}$. Hence an answer saying something like ""that part doesn't matter for compactly supported distributions"" makes no sense to me. I don't really understand the answers and would like more detail. Can something similar to question 2 be answered for $\mathcal{D}$? (Soft) Question 3: What is the motivation behind the topology for  $\mathcal{D}$? Why all that talk about compact sets?  Certainly I would be also happy with a motivation for what the topological dual (distribution space) should look like and then looking for what spaces have that as their dual. In particular, the quoted question confused me on the following: The space $\mathcal{D}$ being locally convex, the topology is given by a family of semi-norms. That would mean we need to reabsorb the criterion ""all supports of functions in the sequence (when testing for convergence) lie inside some compact set"" into just a set of seminorms. Can this be done? I haven't seen that.",,"['functional-analysis', 'distribution-theory']"
67,"Chain rule in the Sobolev space $W^{1,p}$",Chain rule in the Sobolev space,"W^{1,p}","(Chain rule) Assume $F : \mathbb{R} \to \mathbb{R}$ is $C^1$, with $F'$ bounded. Suppose $U$ is bounded and $u \in W^{1,p}(U)$ for some $1 \le p \le \infty$. Show $$v :=F(u) \in W^{1,p}(U) \quad \text{and} \quad v_{x_i}=F'(u)u_{x_i}.$$ From PDE Evans, 2nd edition: Chapter 5, Exercise 17. Here is what I understand conceptually so far: Since $u \in W^{1,p}(U)$, it follows $Du=u'$ exists, with $$\int_U u \phi' dx = -\int_U Du \phi \, dx.$$ I need to show that $D(F(u))=F'(u)Du$ exists, with $$\int_U F(u) \phi' dx = -\int_U D(F(u)) \phi \, dx.$$ Then, I can conclude that $F(u) \in W^{1,p}(U)$. This is all I know so far; how can I go about making the connection?","(Chain rule) Assume $F : \mathbb{R} \to \mathbb{R}$ is $C^1$, with $F'$ bounded. Suppose $U$ is bounded and $u \in W^{1,p}(U)$ for some $1 \le p \le \infty$. Show $$v :=F(u) \in W^{1,p}(U) \quad \text{and} \quad v_{x_i}=F'(u)u_{x_i}.$$ From PDE Evans, 2nd edition: Chapter 5, Exercise 17. Here is what I understand conceptually so far: Since $u \in W^{1,p}(U)$, it follows $Du=u'$ exists, with $$\int_U u \phi' dx = -\int_U Du \phi \, dx.$$ I need to show that $D(F(u))=F'(u)Du$ exists, with $$\int_U F(u) \phi' dx = -\int_U D(F(u)) \phi \, dx.$$ Then, I can conclude that $F(u) \in W^{1,p}(U)$. This is all I know so far; how can I go about making the connection?",,"['functional-analysis', 'sobolev-spaces']"
68,Hilbert spaces and unique extensions of linear functions.,Hilbert spaces and unique extensions of linear functions.,,"So I'm pondering the statement: Show that a continuous linear functional $f$ on a subspace $V$ of a Hilbert space $H$ has a unique norm preserving extension $h$ on $H$ Here is my thought. Consider the closure of $V$, $\overline{V}$. Then since $V$ is dense in $\overline{V}$, there exists a unique extension $\overline{f}$ of $f$ to $\overline{V}$. Moreover since $\overline{V}$ is a closed subspace of $H$ then it is also a Hilbert space, so by the Frechet-Riesz theorem we have $\overline{f}(v)$ = $\langle v,y_{\space\overline{f}} \rangle$ for some unique element $y_{\space\overline{f}} \in \overline{V}$ Take $ h(x) = \langle x,y_{\space\overline{f}} \rangle$. How do I get uniqueness though?","So I'm pondering the statement: Show that a continuous linear functional $f$ on a subspace $V$ of a Hilbert space $H$ has a unique norm preserving extension $h$ on $H$ Here is my thought. Consider the closure of $V$, $\overline{V}$. Then since $V$ is dense in $\overline{V}$, there exists a unique extension $\overline{f}$ of $f$ to $\overline{V}$. Moreover since $\overline{V}$ is a closed subspace of $H$ then it is also a Hilbert space, so by the Frechet-Riesz theorem we have $\overline{f}(v)$ = $\langle v,y_{\space\overline{f}} \rangle$ for some unique element $y_{\space\overline{f}} \in \overline{V}$ Take $ h(x) = \langle x,y_{\space\overline{f}} \rangle$. How do I get uniqueness though?",,[]
69,Distributions on manifolds,Distributions on manifolds,,"Wikipedia entry on distributions contains a seemingly innocent sentence With minor modifications, one can also define complex-valued distributions, and one can replace $\mathbb{R}^n$ by any (paracompact) smooth manifold. without any reference cited. I went through Vladimirov, Demidov, Gel'fand & Shilov but could not find a single mention of the latter concept. Of course, I have an intuitive feeling of how to go about this, but I would need to use generalized functions on $S^1$ in my work and I don't want to inefficiently re-discover the whole theory if it exists anywhere already. Could anyone point me at a reference where I could learn more about distributions on smooth manifolds? NB this is not the same question as distributions supported , or concentrated , on a manifold embedded in $\mathbb{R}^n$. My space of test functions would also be defined on the same manifold so transverse derivatives are not defined.","Wikipedia entry on distributions contains a seemingly innocent sentence With minor modifications, one can also define complex-valued distributions, and one can replace $\mathbb{R}^n$ by any (paracompact) smooth manifold. without any reference cited. I went through Vladimirov, Demidov, Gel'fand & Shilov but could not find a single mention of the latter concept. Of course, I have an intuitive feeling of how to go about this, but I would need to use generalized functions on $S^1$ in my work and I don't want to inefficiently re-discover the whole theory if it exists anywhere already. Could anyone point me at a reference where I could learn more about distributions on smooth manifolds? NB this is not the same question as distributions supported , or concentrated , on a manifold embedded in $\mathbb{R}^n$. My space of test functions would also be defined on the same manifold so transverse derivatives are not defined.",,"['functional-analysis', 'distribution-theory']"
70,On every infinite-dimensional Banach space there exists a discontinuous linear functional.,On every infinite-dimensional Banach space there exists a discontinuous linear functional.,,"On every infinite-dimensional Banach space there exists a discontinuous linear functional. Assuming the axiom of choice, every vector space has a basis. With an infinite basis, I can define on a countable subset $\{e_n:n\in\mathbb{N}\}$ a function $f(e_n)=n\|e_n\|$ and let $f(x)=1$ for all other basis vectors. Then this determines an unbounded linear functional, which is therefore discontinuous. But this argument, a, applies to any infinite-dimensional normed spaces, b, relies on the assumption of the axiom of choice. Is there a smart answer that does make use of the condition that the space in question is a Banach space, and even better, avoids the use of axiom of choice?","On every infinite-dimensional Banach space there exists a discontinuous linear functional. Assuming the axiom of choice, every vector space has a basis. With an infinite basis, I can define on a countable subset $\{e_n:n\in\mathbb{N}\}$ a function $f(e_n)=n\|e_n\|$ and let $f(x)=1$ for all other basis vectors. Then this determines an unbounded linear functional, which is therefore discontinuous. But this argument, a, applies to any infinite-dimensional normed spaces, b, relies on the assumption of the axiom of choice. Is there a smart answer that does make use of the condition that the space in question is a Banach space, and even better, avoids the use of axiom of choice?",,"['functional-analysis', 'banach-spaces', 'axiom-of-choice']"
71,Does convexity of a 'norm' imply the triangle inequality?,Does convexity of a 'norm' imply the triangle inequality?,,"Given a vector space $V$ (for convenience, defined over $\mathbb{r}$), we call $d:V\rightarrow\mathbb{R}$ a norm for $V$ if $\forall \mathbf{u}, \mathbf{v} \in V$ and $\forall r \in \mathbb{R}$ we have: $d(r \mathbf{v}) = |r|d(\mathbf{v})$, $d(\mathbf{v})\ge 0$, with equality iff $\mathbf{v} = 0$, and $d(\mathbf{u})+d(\mathbf{v}) \ge d(\mathbf{u}+\mathbf{v})$ (triangle inequality) I've read in a few places that an important property of a norm is that it is convex; that is, given $\mathbf{u},\mathbf{v} \in V$, and $p \in (0,1)$, we have $d(p \mathbf{u} + (1-p) \mathbf{v}) \le p d(\mathbf{u}) + (1-p) d(\mathbf{v})$.  This clearly follows from the triangle inequality. My question is: Does the reverse also hold?  i.e. does a function satisfying (1) and (2) above which is convex necessarily satisfy the triangle inequality?  If not, what is an instructive counterexample? Thanks! (btw: please feel free to suggest better tags / improvements to the question; I'm new to this!)","Given a vector space $V$ (for convenience, defined over $\mathbb{r}$), we call $d:V\rightarrow\mathbb{R}$ a norm for $V$ if $\forall \mathbf{u}, \mathbf{v} \in V$ and $\forall r \in \mathbb{R}$ we have: $d(r \mathbf{v}) = |r|d(\mathbf{v})$, $d(\mathbf{v})\ge 0$, with equality iff $\mathbf{v} = 0$, and $d(\mathbf{u})+d(\mathbf{v}) \ge d(\mathbf{u}+\mathbf{v})$ (triangle inequality) I've read in a few places that an important property of a norm is that it is convex; that is, given $\mathbf{u},\mathbf{v} \in V$, and $p \in (0,1)$, we have $d(p \mathbf{u} + (1-p) \mathbf{v}) \le p d(\mathbf{u}) + (1-p) d(\mathbf{v})$.  This clearly follows from the triangle inequality. My question is: Does the reverse also hold?  i.e. does a function satisfying (1) and (2) above which is convex necessarily satisfy the triangle inequality?  If not, what is an instructive counterexample? Thanks! (btw: please feel free to suggest better tags / improvements to the question; I'm new to this!)",,"['functional-analysis', 'analysis', 'vector-spaces', 'convex-analysis', 'normed-spaces']"
72,Closure of the invertible operators on a Banach space,Closure of the invertible operators on a Banach space,,"Let $E$ be a Banach space, $\mathcal B(E)$ the Banach space of linear bounded operators and $\mathcal I$ the set of all invertible linear bounded operators from $E$ to $E$. We know that $\mathcal I$ is an open set, and if $E$ is finite dimensional then $\mathcal I$ is dense in $\mathcal B(E)$. It's not true that $\mathcal I$ is dense if we can find $T\in\mathcal B(E)$ injective, non surjective with $T(E)$ closed in $E$, since such an operator cannot be approximated in the norm on $\mathcal B(E)$ by elements of $\mathcal I$ (in particular $E$ has to be infinite dimensional). So the question is (maybe a little vague): is there a nice characterization of $\overline{\mathcal I}^{\mathcal B(E)}$ when $E$ is infinite dimensional? Is the case of Hilbert space simpler?","Let $E$ be a Banach space, $\mathcal B(E)$ the Banach space of linear bounded operators and $\mathcal I$ the set of all invertible linear bounded operators from $E$ to $E$. We know that $\mathcal I$ is an open set, and if $E$ is finite dimensional then $\mathcal I$ is dense in $\mathcal B(E)$. It's not true that $\mathcal I$ is dense if we can find $T\in\mathcal B(E)$ injective, non surjective with $T(E)$ closed in $E$, since such an operator cannot be approximated in the norm on $\mathcal B(E)$ by elements of $\mathcal I$ (in particular $E$ has to be infinite dimensional). So the question is (maybe a little vague): is there a nice characterization of $\overline{\mathcal I}^{\mathcal B(E)}$ when $E$ is infinite dimensional? Is the case of Hilbert space simpler?",,"['functional-analysis', 'banach-spaces', 'operator-theory', 'banach-algebras']"
73,"In $\ell^p$, if an operator commutes with left shift, it is continuous?","In , if an operator commutes with left shift, it is continuous?",\ell^p,"Our professor put this one in our exam, taking it out along the way though because it seemed too tricky. Still we wasted nearly an hour on it and can't stop thinking about a solution. What we have: The left shift $L : \ell^p \to \ell^p$ $$L(x_1,x_2,x_3,\ldots) = (x_2,x_3,\ldots)$$ and another operator $T$. We should prove that if $TL=LT$, then $T$ is continuous. We had defined subspaces $$ X_k = \{ (x_i) : x_i = 0 \text{ for } i>k \} $$ and seen that these are $T$-invariant and the restrictions $T : X_k \to X_k$ continuous (obvious). The hint was to use closed-graph-theorem to show that $T$ is continuous. Of course we can truncate any sequence to then lie in $X_k$, however I do not see how convergence of the truncated sequences relates to convergence of the images under $T$. Any help please?","Our professor put this one in our exam, taking it out along the way though because it seemed too tricky. Still we wasted nearly an hour on it and can't stop thinking about a solution. What we have: The left shift $L : \ell^p \to \ell^p$ $$L(x_1,x_2,x_3,\ldots) = (x_2,x_3,\ldots)$$ and another operator $T$. We should prove that if $TL=LT$, then $T$ is continuous. We had defined subspaces $$ X_k = \{ (x_i) : x_i = 0 \text{ for } i>k \} $$ and seen that these are $T$-invariant and the restrictions $T : X_k \to X_k$ continuous (obvious). The hint was to use closed-graph-theorem to show that $T$ is continuous. Of course we can truncate any sequence to then lie in $X_k$, however I do not see how convergence of the truncated sequences relates to convergence of the images under $T$. Any help please?",,"['functional-analysis', 'banach-spaces', 'lp-spaces']"
74,"Why is a function space considered to be a ""vector"" space when its elements are not vectors?","Why is a function space considered to be a ""vector"" space when its elements are not vectors?",,"I am confused by the notion of a function space. For example consider the basis $\{1, x, x^2\}$ which is the basis for the vector space of all polynomials of degree at most $2$. What is the notion of the ""vector"" here? I read somewhere (cannot recall the source), that the coefficients of the polynomials would essentially form vectors in this case, but the notion of the basis vectors is not Euclidean in the sense that each basis vector would be of the form $(a_1, a_2, ..., a_n)$ but functions! I cannot wrap my head around this, any ideas?","I am confused by the notion of a function space. For example consider the basis $\{1, x, x^2\}$ which is the basis for the vector space of all polynomials of degree at most $2$. What is the notion of the ""vector"" here? I read somewhere (cannot recall the source), that the coefficients of the polynomials would essentially form vectors in this case, but the notion of the basis vectors is not Euclidean in the sense that each basis vector would be of the form $(a_1, a_2, ..., a_n)$ but functions! I cannot wrap my head around this, any ideas?",,"['functional-analysis', 'vector-spaces']"
75,Dual of a dual cone,Dual of a dual cone,,"Any hint on how to prove the following please: Let $K$ be a convex cone, and $K^*$ its dual cone. Prove that $K^{**}$ is the closure of $K$. Thanks!","Any hint on how to prove the following please: Let $K$ be a convex cone, and $K^*$ its dual cone. Prove that $K^{**}$ is the closure of $K$. Thanks!",,"['functional-analysis', 'convex-analysis', 'topological-vector-spaces']"
76,Is there an algebraic homomorphism between two Banach algebras which is not continuous?,Is there an algebraic homomorphism between two Banach algebras which is not continuous?,,"According to wikipedia , you need the Axiom of Choice to find a discontinuous map between two Banach spaces. Does this procedure also apply for Banach algebras yielding a discontinuous multiplicative linear map? Or, is there some obstruction, ensuring that every algebraic homomorphism between two Banach algebras is continuous? (I know that this is true for $*$-homomorphisms between C*-algebras.)","According to wikipedia , you need the Axiom of Choice to find a discontinuous map between two Banach spaces. Does this procedure also apply for Banach algebras yielding a discontinuous multiplicative linear map? Or, is there some obstruction, ensuring that every algebraic homomorphism between two Banach algebras is continuous? (I know that this is true for $*$-homomorphisms between C*-algebras.)",,"['functional-analysis', 'set-theory', 'operator-algebras', 'banach-algebras']"
77,A Hamel basis for $\ell^p$?,A Hamel basis for ?,\ell^p,"I am looking for an explicit example for a Hamel basis for  $\ell^{p}$?. As we know that for a Banach space a Hamel basis has either finite or uncountably infinite cardinality and for such a basis one can express any element of the vector space as a finite linear combination of these. After some trying I could not write one explicitly. A quick google search did not reveal anything useful except for the proof of uncountability of a an infinite Hamel basis. Maybe I am being a bit silly but I don't think the answer is as obvious as for a Schauder basis for the same case. So, what is an explicit example for a Hamel basis for $\ell^{p}$??","I am looking for an explicit example for a Hamel basis for  $\ell^{p}$?. As we know that for a Banach space a Hamel basis has either finite or uncountably infinite cardinality and for such a basis one can express any element of the vector space as a finite linear combination of these. After some trying I could not write one explicitly. A quick google search did not reveal anything useful except for the proof of uncountability of a an infinite Hamel basis. Maybe I am being a bit silly but I don't think the answer is as obvious as for a Schauder basis for the same case. So, what is an explicit example for a Hamel basis for $\ell^{p}$??",,"['functional-analysis', 'banach-spaces', 'lp-spaces', 'axiom-of-choice', 'hamel-basis']"
78,"Is there a concept of a ""free Hilbert space on a set""?","Is there a concept of a ""free Hilbert space on a set""?",,"I am looking for a ""good"" definition of a Hilbert space with a distinct orthonormal basis (in the Hilbert space sense) such that each basis element corresponds to an element of a given set $X$. Before I explain my attempt for a definition of this, let me talk about something analogous. Analogy: There exists something analogous for vector spaces, namely the free vector space on the set $X$ . This is a vector space $V(X)$ with a distinct basis such that every basis element corresponds to an element of $X$. More precisely, a free vector space on $X$ is a vector space $V(X)$, together with a map $i: X \rightarrow V(X)$ such that the following universal property is satisfied: For every vector space $W$ (over the same field) and every map $\phi: X \rightarrow W$, there is a unique linear map $\psi: V(X) \rightarrow W$ such that $\phi = \psi \circ i$. For such a free vector space over $X$, the set $i(X) = \{i(x) \mid x \in X\}$ is a basis of $V(X)$ such that each element of the basis corresponds to an element of $X$. I heard that one calls $V(X)$ the free vector space because $V(X)$ free object on $X$ , but I don't fully understand this concept. Let's restrict to complex vector spaces. For a given set $X$, one can construct a free vector space on $X$ as follows: One takes the set $V(X)$ of functions $f: X \rightarrow \mathbb{C}$ with finite support, endowed with pointwise addition and scalar multiplication. This is a vector space with the Kronecker delta functions $\delta_x$ (which evaluate to 1 on $x$ and to zero elsewhere) as a basis. Then $V(X)$, together with the map $i: X \rightarrow V(X), \ x \mapsto \delta_x$ is a free vector space on $X$. My attempt: Inspired by the above construction of a free vector space on a set $X$, I want to define a free Hilbert space on $X$. Again, let's restrict to complex Hilbert spaces. For a given set $X$, let $\mathcal{H}(X)$ be the set of functions $f: X \rightarrow \mathbb{C}$ with countable support such that $\sum_{x \in \text{supp}(f)} \vert f(x) \vert^2 < \infty$, endowed with pointwise addition and scalar multiplication and the inner product $\langle f, g \rangle = \sum_{x \in \text{supp}(f) \cap \text{supp}(g)} f(x) \overline{g(x)}$. In other words, set $\mathcal{H}(X) := \ell^2(X)$. This is a Hilbert space where the Kronecker delta functions $\delta_x$ for $x \in X$ form an orthonormal basis. Let $i: X \rightarrow \mathcal{H}(X)$ be the map $x \mapsto \delta_x$. My question: Is this a ""good"" definition of a free Hilbert space on a set $X$? Does it satisfy a universal property analogous to the one for free vector spaces? Is this a ""Hilbert space with a distinct orthonormal basis such that each basis element corresponds to an element of $X$""? What makes me skeptical is the fact that I found a document on the functor $\ell^2$ in which it is said that ""The important $\ell^2$–construction is in many ways the closest thing there is to a free Hilbert space"" (page 1) but also ""Lemma 4.8 showed that $\ell^2(X)$ is not the free Hilbert space on X, at least not in the categorically accepted meaning."" What is this ""categorically accepted meaning"" and how does it relate to the universal property of the free vector space i mentioned above?","I am looking for a ""good"" definition of a Hilbert space with a distinct orthonormal basis (in the Hilbert space sense) such that each basis element corresponds to an element of a given set $X$. Before I explain my attempt for a definition of this, let me talk about something analogous. Analogy: There exists something analogous for vector spaces, namely the free vector space on the set $X$ . This is a vector space $V(X)$ with a distinct basis such that every basis element corresponds to an element of $X$. More precisely, a free vector space on $X$ is a vector space $V(X)$, together with a map $i: X \rightarrow V(X)$ such that the following universal property is satisfied: For every vector space $W$ (over the same field) and every map $\phi: X \rightarrow W$, there is a unique linear map $\psi: V(X) \rightarrow W$ such that $\phi = \psi \circ i$. For such a free vector space over $X$, the set $i(X) = \{i(x) \mid x \in X\}$ is a basis of $V(X)$ such that each element of the basis corresponds to an element of $X$. I heard that one calls $V(X)$ the free vector space because $V(X)$ free object on $X$ , but I don't fully understand this concept. Let's restrict to complex vector spaces. For a given set $X$, one can construct a free vector space on $X$ as follows: One takes the set $V(X)$ of functions $f: X \rightarrow \mathbb{C}$ with finite support, endowed with pointwise addition and scalar multiplication. This is a vector space with the Kronecker delta functions $\delta_x$ (which evaluate to 1 on $x$ and to zero elsewhere) as a basis. Then $V(X)$, together with the map $i: X \rightarrow V(X), \ x \mapsto \delta_x$ is a free vector space on $X$. My attempt: Inspired by the above construction of a free vector space on a set $X$, I want to define a free Hilbert space on $X$. Again, let's restrict to complex Hilbert spaces. For a given set $X$, let $\mathcal{H}(X)$ be the set of functions $f: X \rightarrow \mathbb{C}$ with countable support such that $\sum_{x \in \text{supp}(f)} \vert f(x) \vert^2 < \infty$, endowed with pointwise addition and scalar multiplication and the inner product $\langle f, g \rangle = \sum_{x \in \text{supp}(f) \cap \text{supp}(g)} f(x) \overline{g(x)}$. In other words, set $\mathcal{H}(X) := \ell^2(X)$. This is a Hilbert space where the Kronecker delta functions $\delta_x$ for $x \in X$ form an orthonormal basis. Let $i: X \rightarrow \mathcal{H}(X)$ be the map $x \mapsto \delta_x$. My question: Is this a ""good"" definition of a free Hilbert space on a set $X$? Does it satisfy a universal property analogous to the one for free vector spaces? Is this a ""Hilbert space with a distinct orthonormal basis such that each basis element corresponds to an element of $X$""? What makes me skeptical is the fact that I found a document on the functor $\ell^2$ in which it is said that ""The important $\ell^2$–construction is in many ways the closest thing there is to a free Hilbert space"" (page 1) but also ""Lemma 4.8 showed that $\ell^2(X)$ is not the free Hilbert space on X, at least not in the categorically accepted meaning."" What is this ""categorically accepted meaning"" and how does it relate to the universal property of the free vector space i mentioned above?",,"['functional-analysis', 'category-theory', 'hilbert-spaces', 'universal-algebra', 'universal-property']"
79,Differences between $L^p$ and $\ell^p$ spaces,Differences between  and  spaces,L^p \ell^p,Could someone explain some differences between the $L^p$ and $\ell^p$ spaces? Thanks a lot.,Could someone explain some differences between the $L^p$ and $\ell^p$ spaces? Thanks a lot.,,"['functional-analysis', 'banach-spaces', 'lp-spaces']"
80,Prove the dual space of $l^p$ is isomorphic to $l^q$ if $\frac{1}{q}+\frac{1}{p}=1$,Prove the dual space of  is isomorphic to  if,l^p l^q \frac{1}{q}+\frac{1}{p}=1,"Prove the dual space of $\ell^p$ is isomorphic to $\ell^q$ if $\frac{1}{q}+\frac{1}{p}=1$ ($1<p<\infty$) Define a map $J:\ell^q \to (\ell^p)'$ such that $Jy(x)=\sum_{k=1}^\infty x_ky_k,x\in \ell^p,y\in \ell^q$ I have verified that $Jy\in (\ell^p)'$, $J$ is linear and $\lVert Jy \rVert\leq \lVert y \rVert_q$. How to show $\lVert Jy \rVert \geq \lVert y \rVert_q$ and $J$ is surjective?","Prove the dual space of $\ell^p$ is isomorphic to $\ell^q$ if $\frac{1}{q}+\frac{1}{p}=1$ ($1<p<\infty$) Define a map $J:\ell^q \to (\ell^p)'$ such that $Jy(x)=\sum_{k=1}^\infty x_ky_k,x\in \ell^p,y\in \ell^q$ I have verified that $Jy\in (\ell^p)'$, $J$ is linear and $\lVert Jy \rVert\leq \lVert y \rVert_q$. How to show $\lVert Jy \rVert \geq \lVert y \rVert_q$ and $J$ is surjective?",,"['functional-analysis', 'banach-spaces', 'lp-spaces', 'dual-spaces']"
81,Functional analysis textbook (or course) with complete solutions to exercises,Functional analysis textbook (or course) with complete solutions to exercises,,"I am a Ph.D. student in economics and I plan to study functional analysis by myself either this winter or the next summer. I am currently looking for a textbook, and since I am studying it by myself, I would like the textbook to have complete solutions to all or at least many (say, all odd numbered) problems. I have taken a graduate real variables sequence, but have never studied functional analysis before. So preferably, this doesn't have to be a very advanced text. Is there any suggestions? Actually it doesn't have to be a book; well written online notes or course websites with complete solutions to exercise/homework problems would be great as well. Of course I will attempt the problems by my own effort first, but since I won't have anyone to discuss with, I hope that I can have some last resort whenever I cannot figure out a problem. Thank you very much!","I am a Ph.D. student in economics and I plan to study functional analysis by myself either this winter or the next summer. I am currently looking for a textbook, and since I am studying it by myself, I would like the textbook to have complete solutions to all or at least many (say, all odd numbered) problems. I have taken a graduate real variables sequence, but have never studied functional analysis before. So preferably, this doesn't have to be a very advanced text. Is there any suggestions? Actually it doesn't have to be a book; well written online notes or course websites with complete solutions to exercise/homework problems would be great as well. Of course I will attempt the problems by my own effort first, but since I won't have anyone to discuss with, I hope that I can have some last resort whenever I cannot figure out a problem. Thank you very much!",,"['analysis', 'functional-analysis', 'reference-request', 'self-learning', 'book-recommendation']"
82,Different versions of Riesz Theorems,Different versions of Riesz Theorems,,"In Wikipedia, there are three versions of Riesz theorems : 1 The Hilbert space representation theorem for the (continuous) dual space of a Hilbert space; 2 The representation theorem for positive linear functionals on $C_c(X)$ , where $X$ is a locally compact Hausdorff space; 3 The representation theorem for the dual of $C_0(X)$ , where $X$ is a locally compact Hausdorff space. I was wondering if none of the three versions is more general  than the others, in the sense that no one can be derived from another? when two or three of them can coincide? Thanks and regards!","In Wikipedia, there are three versions of Riesz theorems : 1 The Hilbert space representation theorem for the (continuous) dual space of a Hilbert space; 2 The representation theorem for positive linear functionals on , where is a locally compact Hausdorff space; 3 The representation theorem for the dual of , where is a locally compact Hausdorff space. I was wondering if none of the three versions is more general  than the others, in the sense that no one can be derived from another? when two or three of them can coincide? Thanks and regards!",C_c(X) X C_0(X) X,"['functional-analysis', 'hilbert-spaces', 'banach-spaces', 'riesz-representation-theorem']"
83,Dual space of the sobolev spaces.,Dual space of the sobolev spaces.,,"What is the dual space of $ H¹(\Omega) = W^{1,2}(\Omega) $? What is the dual space of $ W^{m,p}(\Omega) $? I know for example that the dual space of $ L^{p}(\Omega) $ for $ 1 \le p < \infty $ is $ L^{q}(\Omega) $ where $ \dfrac{1}{p} + \dfrac{1}{q} = 1 $.","What is the dual space of $ H¹(\Omega) = W^{1,2}(\Omega) $? What is the dual space of $ W^{m,p}(\Omega) $? I know for example that the dual space of $ L^{p}(\Omega) $ for $ 1 \le p < \infty $ is $ L^{q}(\Omega) $ where $ \dfrac{1}{p} + \dfrac{1}{q} = 1 $.",,"['functional-analysis', 'sobolev-spaces', 'riesz-representation-theorem']"
84,Nested sequences of balls in a Banach space,Nested sequences of balls in a Banach space,,"This seems to be a fairly easy question but I'm looking for new points of view on it and was wondering if anyone might be able to help. (By the way- this question does come from home-work, but I've already solved and handed it, and I'm posting this out of interest, so no HW tag.) Let $B_n=B(x_n,r_n)$ be a sequence of nested closed balls in a Banach space $X$. Prove that $\bigcap_{n=1}^\infty B_n\neq\varnothing$. As I said before, it should be rather simple. When the radii decrease to 0, it's just a matter of selecting any sequence of points in $B_n$, and it must be Cauchy- and the limit is in the intersection. My question is what to do when the radii do not decrease to 0? I got some tips about multiplying the balls by a sequence of decreasing scalars, or reducing the radii so that they decrease to 0, but found too many pathological cases for both methods. Finally- I used a geometric arguemnt (which i've shown to work in any normed space) that if $B(x_1,r_1)\subset B(x_2,r_2)$ then $\| x_1-x_2\|\leq|r_1-r_2|$. This turned out to be some kind of technical catastrophe, but it worked... Still, if anyone knows of a more elegant solution, I'd love to hear about it.","This seems to be a fairly easy question but I'm looking for new points of view on it and was wondering if anyone might be able to help. (By the way- this question does come from home-work, but I've already solved and handed it, and I'm posting this out of interest, so no HW tag.) Let $B_n=B(x_n,r_n)$ be a sequence of nested closed balls in a Banach space $X$. Prove that $\bigcap_{n=1}^\infty B_n\neq\varnothing$. As I said before, it should be rather simple. When the radii decrease to 0, it's just a matter of selecting any sequence of points in $B_n$, and it must be Cauchy- and the limit is in the intersection. My question is what to do when the radii do not decrease to 0? I got some tips about multiplying the balls by a sequence of decreasing scalars, or reducing the radii so that they decrease to 0, but found too many pathological cases for both methods. Finally- I used a geometric arguemnt (which i've shown to work in any normed space) that if $B(x_1,r_1)\subset B(x_2,r_2)$ then $\| x_1-x_2\|\leq|r_1-r_2|$. This turned out to be some kind of technical catastrophe, but it worked... Still, if anyone knows of a more elegant solution, I'd love to hear about it.",,"['geometry', 'functional-analysis', 'metric-spaces', 'banach-spaces']"
85,Mazur's Lemma (can't find a proof anywhere),Mazur's Lemma (can't find a proof anywhere),,"If we have a normed vector space $X$, and $x_n \to x$ weakly, then it's clear how to show there's a sequence $y_n \to x$ strongly (since the weak closure and strong closure of a convex set coincide, just consider the closure of the convex hull of the sequence). I'd like to know how to prove the second half of the lemma i.e. you can choose the $y_n$ to lie inside the convex hull of $\lbrace x_1,x_2,..,x_n \rbrace$. Why is this?","If we have a normed vector space $X$, and $x_n \to x$ weakly, then it's clear how to show there's a sequence $y_n \to x$ strongly (since the weak closure and strong closure of a convex set coincide, just consider the closure of the convex hull of the sequence). I'd like to know how to prove the second half of the lemma i.e. you can choose the $y_n$ to lie inside the convex hull of $\lbrace x_1,x_2,..,x_n \rbrace$. Why is this?",,['functional-analysis']
86,A reflexive space which does not have an equivalent uniformly convex norm,A reflexive space which does not have an equivalent uniformly convex norm,,"I found this beautiful theorem due to Milman and Pettis : Every uniformly convex Banach space is reflexive. I think it's a remarkable statement, since uniformly convexity is a geometric property of the norm and therefore need not to be true for an equivalent norm. While reflexivity is a topological statement and therefore a reflexive space remains reflexive for an equivalent norm. My first question is: Could someone give an example of a space with two equivalent norms such that the space is uniformly convex for just one of the two norms. And my second question is: Could someone give me an example of a reflexive space that admits no uniformly convex equivalent norm. Thank you in advance for answering my questions!","I found this beautiful theorem due to Milman and Pettis : Every uniformly convex Banach space is reflexive. I think it's a remarkable statement, since uniformly convexity is a geometric property of the norm and therefore need not to be true for an equivalent norm. While reflexivity is a topological statement and therefore a reflexive space remains reflexive for an equivalent norm. My first question is: Could someone give an example of a space with two equivalent norms such that the space is uniformly convex for just one of the two norms. And my second question is: Could someone give me an example of a reflexive space that admits no uniformly convex equivalent norm. Thank you in advance for answering my questions!",,"['functional-analysis', 'reference-request', 'banach-spaces', 'examples-counterexamples']"
87,Do eigenfunctions of elliptic operator form basis of $H^k(M)$?,Do eigenfunctions of elliptic operator form basis of ?,H^k(M),"We know that the eigenfunctions of the Laplacian on a compact manifold $M$ form a countable basis of $H^1(M)$. If $L$ is a $2k$-order elliptic operator, do the eigenfunctions of $L$ form a basis for $H^k(M)$? References/more detail would be appreciated. Thanks.","We know that the eigenfunctions of the Laplacian on a compact manifold $M$ form a countable basis of $H^1(M)$. If $L$ is a $2k$-order elliptic operator, do the eigenfunctions of $L$ form a basis for $H^k(M)$? References/more detail would be appreciated. Thanks.",,"['functional-analysis', 'partial-differential-equations', 'riemannian-geometry']"
88,When is $L^1 = (L^\infty)^\ast$?,When is ?,L^1 = (L^\infty)^\ast,"I found this exercise in Cohn's Measure Theory : Let $(X, \mathscr A, \mu)$ be a finite measure space. Show that the conditions the map $T: L^1(X, \mathscr A, \mu) \to (L^\infty(X, \mathscr A, \mu))^\ast$ given by $g\mapsto T_g(f) = \int fg \, d\mu$ is surjective $L^1(X, \mathscr A, \mu)$ is finite-dimensional $L^\infty(X, \mathscr A, \mu)$ is finite-dimensional there is a finite $\sigma$ -algebra $\mathscr A_0$ on $X$ such that $\mathscr A_0\subset \mathscr A$ and such that each set in $\mathscr A$ differs from a set in $\mathscr A_0$ by a $\mu$ -null set are equivalent. I figured out a way to show $2. \implies 4. \implies 3. \implies 2.$ and how these three conditions imply $1.$ What I'm having trouble with is how to get from 1. to either of the other three. If someone could provide a hint, I'd be grateful. Thank you.","I found this exercise in Cohn's Measure Theory : Let be a finite measure space. Show that the conditions the map given by is surjective is finite-dimensional is finite-dimensional there is a finite -algebra on such that and such that each set in differs from a set in by a -null set are equivalent. I figured out a way to show and how these three conditions imply What I'm having trouble with is how to get from 1. to either of the other three. If someone could provide a hint, I'd be grateful. Thank you.","(X, \mathscr A, \mu) T: L^1(X, \mathscr A, \mu) \to (L^\infty(X, \mathscr A, \mu))^\ast g\mapsto T_g(f) = \int fg \, d\mu L^1(X, \mathscr A, \mu) L^\infty(X, \mathscr A, \mu) \sigma \mathscr A_0 X \mathscr A_0\subset \mathscr A \mathscr A \mathscr A_0 \mu 2. \implies 4. \implies 3. \implies 2. 1.","['functional-analysis', 'measure-theory']"
89,"If a map between separable Banach spaces has closed graph, does it have a point of continuity?","If a map between separable Banach spaces has closed graph, does it have a point of continuity?",,"It is well known that the closed graph theorem does not directly extend to nonlinear maps: even for functions from $\mathbb{R}$ to $\mathbb{R}$ , having closed graph does not imply continuity. But let's consider the following reformulation of the closed graph theorem: If a linear map between Banach spaces has closed graph, it has a point of continuity. This does not essentially change the meaning, since a linear map is either everywhere continuous or everywhere discontinuous. But now there is a better chance of nonlinear generalization. Hence, my question : Suppose that a nonlinear map between separable Banach spaces has closed graph. Does it necessarily have a point of continuity? Nonseparable counterexample Since  the above seems too good to be true,   I tried to find a counterexample. So far, found it only in nonseparable setting. Let $X$ the space of all bounded functions $x:(0,1]\to\mathbb R$ with the supremum norm. Let $(q_n)_{n=1}^\infty$ be an enumeration of the rationals. Define the function $y=F(x)$ separately on each subinterval $(2^{-n},2^{1-n}]$, $n=1,2,\dots$ as $$ y(t) = \begin{cases} 1 \quad &\text{if   $f(2^nt-1)>q_n$} \\  0 \quad &\text{if  $f(2^n t-1)\le q_n$}  \end{cases}  $$ I claim that the map $F:X\to X$ satisfies $\|F(x_1)-F(x_2)\|=1$ whenever $x_1\ne x_2$. Hence, it is nowhere continuous and its graph is a discrete (in particular closed) set. Indeed, since $x_1\ne x_2$, there is a point $s\in (0,1]$ and a number $n\in\mathbb N$  such that $q_n$ is strictly between $x_1(s)$ and $x_2(s)$; according to the definition of $F$ this implies that the functions $F(x_1)$ and  $F(x_2)$ take on different values at the point $t=2^{-n}(s+1)$. Finite-dimensional case In finite dimensions, a map with a closed graph is continuous outside of a closed set with empty interior. The proof is not very interesting, so I link to it instead of adding it to the post.","It is well known that the closed graph theorem does not directly extend to nonlinear maps: even for functions from $\mathbb{R}$ to $\mathbb{R}$ , having closed graph does not imply continuity. But let's consider the following reformulation of the closed graph theorem: If a linear map between Banach spaces has closed graph, it has a point of continuity. This does not essentially change the meaning, since a linear map is either everywhere continuous or everywhere discontinuous. But now there is a better chance of nonlinear generalization. Hence, my question : Suppose that a nonlinear map between separable Banach spaces has closed graph. Does it necessarily have a point of continuity? Nonseparable counterexample Since  the above seems too good to be true,   I tried to find a counterexample. So far, found it only in nonseparable setting. Let $X$ the space of all bounded functions $x:(0,1]\to\mathbb R$ with the supremum norm. Let $(q_n)_{n=1}^\infty$ be an enumeration of the rationals. Define the function $y=F(x)$ separately on each subinterval $(2^{-n},2^{1-n}]$, $n=1,2,\dots$ as $$ y(t) = \begin{cases} 1 \quad &\text{if   $f(2^nt-1)>q_n$} \\  0 \quad &\text{if  $f(2^n t-1)\le q_n$}  \end{cases}  $$ I claim that the map $F:X\to X$ satisfies $\|F(x_1)-F(x_2)\|=1$ whenever $x_1\ne x_2$. Hence, it is nowhere continuous and its graph is a discrete (in particular closed) set. Indeed, since $x_1\ne x_2$, there is a point $s\in (0,1]$ and a number $n\in\mathbb N$  such that $q_n$ is strictly between $x_1(s)$ and $x_2(s)$; according to the definition of $F$ this implies that the functions $F(x_1)$ and  $F(x_2)$ take on different values at the point $t=2^{-n}(s+1)$. Finite-dimensional case In finite dimensions, a map with a closed graph is continuous outside of a closed set with empty interior. The proof is not very interesting, so I link to it instead of adding it to the post.",,['functional-analysis']
90,Necessity of completeness of the inner product space in Riesz representation theorem,Necessity of completeness of the inner product space in Riesz representation theorem,,"I wanted to find a counter example to show that the completeness of the inner product space is necessary in Riesz representation theorem . Please give an example of a bounded linear functional $T$ on an incomplete inner product space $X$ which do not have any inner product representation i.e. there does not exist any $z$ in $X$ s.t. $T(x)= \langle ,z\rangle$ for all $x$ in $X$.","I wanted to find a counter example to show that the completeness of the inner product space is necessary in Riesz representation theorem . Please give an example of a bounded linear functional $T$ on an incomplete inner product space $X$ which do not have any inner product representation i.e. there does not exist any $z$ in $X$ s.t. $T(x)= \langle ,z\rangle$ for all $x$ in $X$.",,"['functional-analysis', 'analysis', 'examples-counterexamples', 'inner-products', 'riesz-representation-theorem']"
91,Inclusion of $l^p$ space for sequences,Inclusion of  space for sequences,l^p,"Inclusion of $L^p$ spaces for functions has been discussed here . Does this apply to $l^p$ space of sequences similarly? I tried to show the following: For $1\leq p<q<\infty$, $l^q\subset l^p$ By using Hölder inequality but it doesn't seem to work. My question is that is this true? If yes, what's the right way to prove it and what's a good counter example for showing $l^p\subset l^q$ is not true? Thanks.","Inclusion of $L^p$ spaces for functions has been discussed here . Does this apply to $l^p$ space of sequences similarly? I tried to show the following: For $1\leq p<q<\infty$, $l^q\subset l^p$ By using Hölder inequality but it doesn't seem to work. My question is that is this true? If yes, what's the right way to prove it and what's a good counter example for showing $l^p\subset l^q$ is not true? Thanks.",,"['functional-analysis', 'lp-spaces']"
92,Why is $\ell^1(\mathbb{Z})$ not a $C^{*}$-algebra?,Why is  not a -algebra?,\ell^1(\mathbb{Z}) C^{*},"When $\ell^1(\mathbb Z)$ is equipped with the convolution as multiplication and $a^{*}_{n}=\bar{a}_{-n}$, I can prove it satisfies all conditions except $\|a^{*}a\|=\|a\|^2$, which I cannot prove nor find a counter example. I wonder whether anyone can give a hint on this. Thanks!","When $\ell^1(\mathbb Z)$ is equipped with the convolution as multiplication and $a^{*}_{n}=\bar{a}_{-n}$, I can prove it satisfies all conditions except $\|a^{*}a\|=\|a\|^2$, which I cannot prove nor find a counter example. I wonder whether anyone can give a hint on this. Thanks!",,"['functional-analysis', 'banach-spaces', 'c-star-algebras', 'banach-algebras']"
93,"Support of a distribution, what does it mean?","Support of a distribution, what does it mean?",,"In my course notes the support of a distribution (continous lineair functional) is defined as follows: Definitions First it defines something like open annihilation sets : An open annihilation set $\omega$ of a distribution $T$ is an open set where $\langle T, \phi\rangle = 0$ if the compact support of $\phi$ is a subset of $\omega$ . Then The support of a distribution $T$ is the complement of the open union of all open annihilation sets of $T$ . There are some examples provided: ( $\mathcal{D}$ is the function space of $\mathscr{C}^\infty$ functions with compact support) Choose a $\phi \in \mathcal{D}$ such that $0\not \in [\phi]$ . Then $\langle \delta , \phi \rangle = \phi(0) = 0$ . Which implies $[\delta]= \{0\}$ . Let $Y$ be the Heaviside distribution. Choose $\phi\in \mathcal{D}$ such that $[\phi]\subseteq ]-\infty, 0[$ , then $$\langle Y, \phi\rangle = \int_{-\infty}^{+\infty}Y(x)\phi(x)\operatorname d x = 0$$ Which implies $[Y] = [0,+\infty[$ What does it all mean? I find it hard to understand what support of a distribution really means. For example What does it mean for a distribution to have compact support ? If an ordinary function has compact support I can visualize this as some sort of bump function. But how should I look at the support of a distribution?","In my course notes the support of a distribution (continous lineair functional) is defined as follows: Definitions First it defines something like open annihilation sets : An open annihilation set of a distribution is an open set where if the compact support of is a subset of . Then The support of a distribution is the complement of the open union of all open annihilation sets of . There are some examples provided: ( is the function space of functions with compact support) Choose a such that . Then . Which implies . Let be the Heaviside distribution. Choose such that , then Which implies What does it all mean? I find it hard to understand what support of a distribution really means. For example What does it mean for a distribution to have compact support ? If an ordinary function has compact support I can visualize this as some sort of bump function. But how should I look at the support of a distribution?","\omega T \langle T, \phi\rangle = 0 \phi \omega T T \mathcal{D} \mathscr{C}^\infty \phi \in \mathcal{D} 0\not \in [\phi] \langle \delta , \phi \rangle = \phi(0) = 0 [\delta]= \{0\} Y \phi\in \mathcal{D} [\phi]\subseteq ]-\infty, 0[ \langle Y, \phi\rangle = \int_{-\infty}^{+\infty}Y(x)\phi(x)\operatorname d x = 0 [Y] = [0,+\infty[","['functional-analysis', 'definition', 'distribution-theory']"
94,Orthogonal complement of a Hilbert Space,Orthogonal complement of a Hilbert Space,,"I have this problem: Let $S$ be a subset of a Hilbert $H$ and let $M$ be the closed subspace generated by $S$. Show that $M^{\perp} = S^{\perp}$ $M = (S^{\perp})^{\perp}$ if $V$ is a subspace of $H$, then $H = \overline{V}\oplus V^{\perp}$. I have some doubts, because $H$ don't have finite dimension. For example, for 1. its clear that $S \subseteq M$ and then $M^{\perp} \subseteq S^{\perp}$. Later, if $x\in S^{\perp}$ then $\langle x, a\rangle = 0$, for all $a\in S$. Now in finite dimension I know how justify that $\langle x, b\rangle = 0$, for all $b\in M$, but in a Hilbert I really don't know. Thanks in advance for your help","I have this problem: Let $S$ be a subset of a Hilbert $H$ and let $M$ be the closed subspace generated by $S$. Show that $M^{\perp} = S^{\perp}$ $M = (S^{\perp})^{\perp}$ if $V$ is a subspace of $H$, then $H = \overline{V}\oplus V^{\perp}$. I have some doubts, because $H$ don't have finite dimension. For example, for 1. its clear that $S \subseteq M$ and then $M^{\perp} \subseteq S^{\perp}$. Later, if $x\in S^{\perp}$ then $\langle x, a\rangle = 0$, for all $a\in S$. Now in finite dimension I know how justify that $\langle x, b\rangle = 0$, for all $b\in M$, but in a Hilbert I really don't know. Thanks in advance for your help",,"['functional-analysis', 'hilbert-spaces']"
95,Are isometric normed linear spaces isomorphic?,Are isometric normed linear spaces isomorphic?,,"I should know the answer to this (and I did some time ago, but have forgotten): If the normed linear spaces $X$ and $Y$ are isometric (there is a bijective map from $X$ to $Y$ that preserves distances), are they linearly isomorphic (there is a continuous linear bijection from $X$ to $Y$ with a continuous inverse)?","I should know the answer to this (and I did some time ago, but have forgotten): If the normed linear spaces $X$ and $Y$ are isometric (there is a bijective map from $X$ to $Y$ that preserves distances), are they linearly isomorphic (there is a continuous linear bijection from $X$ to $Y$ with a continuous inverse)?",,"['functional-analysis', 'normed-spaces']"
96,Hahn-Banach Theorem for separable spaces without Zorn's Lemma,Hahn-Banach Theorem for separable spaces without Zorn's Lemma,,"I was reading about the Hahn-Banach Theorem, its many versions and their proofs. It's known that in the proofs we need Zorn's Lemma. But in the book that I'm reading, the author said if $X$ is a separable space then it's possible to prove the Hahn-Banach Theorem without the Zorn's Lemma. How can we show there is a suitable extension of a linear functional without Zorn's lemma?","I was reading about the Hahn-Banach Theorem, its many versions and their proofs. It's known that in the proofs we need Zorn's Lemma. But in the book that I'm reading, the author said if $X$ is a separable space then it's possible to prove the Hahn-Banach Theorem without the Zorn's Lemma. How can we show there is a suitable extension of a linear functional without Zorn's lemma?",,"['functional-analysis', 'vector-spaces', 'normed-spaces', 'axiom-of-choice', 'hahn-banach-theorem']"
97,Smooth functions with compact support are dense in $L^1$,Smooth functions with compact support are dense in,L^1,"Here is another homework question that I did and I'd be glad if you could tell me if it's right. We now strengthen the result of Question Two for $R$ where we have the notion of differentiability. Prove that for any open $Ω ⊂ R$ the set of smooth functions with compact support is dense in $L_1(Ω, λ)$ where $λ$ is the usual Lebesgue measure. a) Define $J(x) = ke^{\frac{-1}{1−x^2}}$ for $|x| < 1$ and equal to zero elsewhere. Here, the constant $k$ is chosen such that $\int_R J = 1$. Prove that the mollifier $J_ε(x) = \frac{1}{\varepsilon}J(\frac{x}{\varepsilon})$ vanishes for $|x| ≥ ε$ and $\int J_\varepsilon = 1$. For $f ∈ L_1$ define the regularization of f by convolving with $J_ε$: $$ f_ε(x) = J_ε \ast f(x) = \int_\Omega J_\varepsilon (x - y ) f(y) d \lambda(y)$$ b) Prove that $f_ε$ is integrable. c) Prove that $f_ε$ is smooth. d) Prove that if $f$ has compact support then so does $f_ε$. e) Finish the proof: For any $f ∈ L_1(Ω)$ there exists $g ∈ C_C^\infty(Ω)$ such that $|f − g| < ε$. Answer: a) $|x| > \varepsilon \implies |\frac{x}{e}| > 1$ by definition $J_\varepsilon = 0$. $$ \int J_\varepsilon = \frac{1}{\varepsilon} \int_R J(\frac{x}{\varepsilon}) = \frac{1}{\varepsilon} \int J(y) \varepsilon d \lambda = 1$$ doing a variable substitution b) $$ \int_R \int_\Omega J_\varepsilon (x - y) f(y) d \lambda(y) d\lambda(x) = \int_\Omega \int_R J_\varepsilon (x - y) dx f(y) dy = \int_\Omega f(y) dy \leq \int_R |f(y)| dy < \infty$$ using Fubini c) $$ \frac{d}{dx^{(n)}} f_\varepsilon (x) = \frac{d}{dx^{(n)}} \int_\Omega J_\varepsilon(x -y) f(y) dy = \int_\Omega \frac{d}{dx^{(n)}} J_\varepsilon (x -y ) f(y) dy$$ where $J_\varepsilon(x-y) = e^{g(x)}$ is smooth. d) $\int$ is linear $\implies $ continuous $\implies $ maps compact sets to compact sets $f$ has compact supp. $A$, $J_\varepsilon$ has compact support $B$ then $f J_\varepsilon$ has compact support $A \cap B$ e) take $g$ to be $f_\varepsilon$ Many thanks for your help.","Here is another homework question that I did and I'd be glad if you could tell me if it's right. We now strengthen the result of Question Two for $R$ where we have the notion of differentiability. Prove that for any open $Ω ⊂ R$ the set of smooth functions with compact support is dense in $L_1(Ω, λ)$ where $λ$ is the usual Lebesgue measure. a) Define $J(x) = ke^{\frac{-1}{1−x^2}}$ for $|x| < 1$ and equal to zero elsewhere. Here, the constant $k$ is chosen such that $\int_R J = 1$. Prove that the mollifier $J_ε(x) = \frac{1}{\varepsilon}J(\frac{x}{\varepsilon})$ vanishes for $|x| ≥ ε$ and $\int J_\varepsilon = 1$. For $f ∈ L_1$ define the regularization of f by convolving with $J_ε$: $$ f_ε(x) = J_ε \ast f(x) = \int_\Omega J_\varepsilon (x - y ) f(y) d \lambda(y)$$ b) Prove that $f_ε$ is integrable. c) Prove that $f_ε$ is smooth. d) Prove that if $f$ has compact support then so does $f_ε$. e) Finish the proof: For any $f ∈ L_1(Ω)$ there exists $g ∈ C_C^\infty(Ω)$ such that $|f − g| < ε$. Answer: a) $|x| > \varepsilon \implies |\frac{x}{e}| > 1$ by definition $J_\varepsilon = 0$. $$ \int J_\varepsilon = \frac{1}{\varepsilon} \int_R J(\frac{x}{\varepsilon}) = \frac{1}{\varepsilon} \int J(y) \varepsilon d \lambda = 1$$ doing a variable substitution b) $$ \int_R \int_\Omega J_\varepsilon (x - y) f(y) d \lambda(y) d\lambda(x) = \int_\Omega \int_R J_\varepsilon (x - y) dx f(y) dy = \int_\Omega f(y) dy \leq \int_R |f(y)| dy < \infty$$ using Fubini c) $$ \frac{d}{dx^{(n)}} f_\varepsilon (x) = \frac{d}{dx^{(n)}} \int_\Omega J_\varepsilon(x -y) f(y) dy = \int_\Omega \frac{d}{dx^{(n)}} J_\varepsilon (x -y ) f(y) dy$$ where $J_\varepsilon(x-y) = e^{g(x)}$ is smooth. d) $\int$ is linear $\implies $ continuous $\implies $ maps compact sets to compact sets $f$ has compact supp. $A$, $J_\varepsilon$ has compact support $B$ then $f J_\varepsilon$ has compact support $A \cap B$ e) take $g$ to be $f_\varepsilon$ Many thanks for your help.",,"['functional-analysis', 'measure-theory', 'lp-spaces']"
98,Every bounded sequence has a weakly convergent subsequence in a Hilbert space,Every bounded sequence has a weakly convergent subsequence in a Hilbert space,,"I tried to prove the following theorem and was wondering if someone could please tell me if my proof can be fixed somehow... Theorem: Let $H$ be a Hilbert space and $x_n\in H$ a bounded sequence. Then $x_n$ has a weakly convergent subsequence. My idea for a proof: The map $\phi: H \to H^\ast$ in the Riesz representation theorem is an isometry therefore $\varphi_n := \phi(x_n)$ is also bounded and therefore $\varphi_1(x_n)$ is a bounded sequencein $\mathbb R$. By Bolzano Weierstras it ha a convergent subsequence $\varphi_1(x_{n_{k_1}})$. (Say, $\varphi_1(x_{n_{k_1}})\to \varphi_1(x)$ for some $x$) Let $x_{n_1}$ be the argument of the first element in this sequence (apologies for the notation; the first element is also called $x_{n_1}$...). The sequence $\varphi_2(x_{n_1})$ has a convergent subsequence $x_{n_{k_2}}$. Let $x_{n_2}$ be the first element in that sequence. And so on. Then the resulting sequence $x_{n_k}$ has the property that for all $j$: $$ \varphi_j(x_{n_k}) \to \varphi_j(x)$$ My only problem is that I only showed this limit for $\varphi_n$ that is, not for all $\varphi \in H^\ast$. Can this argument be fixed somehow?","I tried to prove the following theorem and was wondering if someone could please tell me if my proof can be fixed somehow... Theorem: Let $H$ be a Hilbert space and $x_n\in H$ a bounded sequence. Then $x_n$ has a weakly convergent subsequence. My idea for a proof: The map $\phi: H \to H^\ast$ in the Riesz representation theorem is an isometry therefore $\varphi_n := \phi(x_n)$ is also bounded and therefore $\varphi_1(x_n)$ is a bounded sequencein $\mathbb R$. By Bolzano Weierstras it ha a convergent subsequence $\varphi_1(x_{n_{k_1}})$. (Say, $\varphi_1(x_{n_{k_1}})\to \varphi_1(x)$ for some $x$) Let $x_{n_1}$ be the argument of the first element in this sequence (apologies for the notation; the first element is also called $x_{n_1}$...). The sequence $\varphi_2(x_{n_1})$ has a convergent subsequence $x_{n_{k_2}}$. Let $x_{n_2}$ be the first element in that sequence. And so on. Then the resulting sequence $x_{n_k}$ has the property that for all $j$: $$ \varphi_j(x_{n_k}) \to \varphi_j(x)$$ My only problem is that I only showed this limit for $\varphi_n$ that is, not for all $\varphi \in H^\ast$. Can this argument be fixed somehow?",,['functional-analysis']
99,Invertibility of compact operators in infinite-dimensional Banach spaces,Invertibility of compact operators in infinite-dimensional Banach spaces,,"Let $X$ be an infinite-dimensional Banach space, and $T$ a compact operator from $X$ to $X$. Why must $0$ then be a spectral value for $T$? I believe this is equivalent to saying that $T$ is not bijective, but I am not sure how to show that injectivity implies the absence of surjectivity and the other way around (or if this is even the right way to approach the problem).","Let $X$ be an infinite-dimensional Banach space, and $T$ a compact operator from $X$ to $X$. Why must $0$ then be a spectral value for $T$? I believe this is equivalent to saying that $T$ is not bijective, but I am not sure how to show that injectivity implies the absence of surjectivity and the other way around (or if this is even the right way to approach the problem).",,['functional-analysis']
