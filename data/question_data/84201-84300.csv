,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Weakening the assumptions of the Hellinger-Toeplitz theorem,Weakening the assumptions of the Hellinger-Toeplitz theorem,,"The Hellinger-Toeplitz theorem states that if $T$ is a linear map from a Hilbert space $H$ to itself, satisfying $ \langle Tx,y\rangle=\langle x,Ty\rangle$ for all $ x,y \in H$ , then $T$ is bounded. But can we not instead have the assumption that there is a linear map $ T^*$ such that $ \langle Tx ,y \rangle = \langle x, T^* y \rangle$ for all $ x,y \in H$ ? Then we can take $ x_n \to x$ and set $ z = \lim_{n\to \infty} Tx_n $ , so that for all $ y \in H$ \begin{align} \langle z,y \rangle \leftarrow \langle Tx_n,y \rangle = \langle x_n, T^*y\rangle \to\langle x , T^*y\rangle = \langle Tx,y\rangle \end{align} so that $ z = Tx$ , and so the graph of $T$ is closed, so by closed graph theorem $T$ is bounded. It is the same proof as for the usual Hellinger-Toeplits, so I don't see why we need the operator to be symmetric?","The Hellinger-Toeplitz theorem states that if is a linear map from a Hilbert space to itself, satisfying for all , then is bounded. But can we not instead have the assumption that there is a linear map such that for all ? Then we can take and set , so that for all so that , and so the graph of is closed, so by closed graph theorem is bounded. It is the same proof as for the usual Hellinger-Toeplits, so I don't see why we need the operator to be symmetric?","T H  \langle Tx,y\rangle=\langle x,Ty\rangle  x,y \in H T  T^*  \langle Tx ,y \rangle = \langle x, T^* y \rangle  x,y \in H  x_n \to x  z = \lim_{n\to \infty} Tx_n   y \in H \begin{align}
\langle z,y \rangle \leftarrow \langle Tx_n,y \rangle = \langle x_n, T^*y\rangle \to\langle x , T^*y\rangle = \langle Tx,y\rangle
\end{align}  z = Tx T T","['functional-analysis', 'hilbert-spaces', 'closed-graph']"
1,Prove that $C_0(X)$ is separable given that X is locally compact metric space,Prove that  is separable given that X is locally compact metric space,C_0(X),"I'm struggling to prove the following fact: Suppose that $X$ is locally compact metric space. Let us denote with $C_0(X)$ the space of functions vanishing at infinity (i.e., $\forall f \in C_0(X)$ $\forall \varepsilon > 0$ $\exists  \, E\subset X$ s.t. $E$ is compact and $|f(x)|<\varepsilon$ for $x \in X\setminus E$ ). Then $C_0(X)$ is separable. I've proven that $C_0(X)$ equipped with a supremum norm is a Banach space, and that $C_c(X)$ (functions with compact support) are dense in $C_0(X)$ , so my guess would be to somehow use those facts to prove that $C_0(X)$ is separable. However, I can't exactly see how. I've seen the cases for compact spaces or using the assumption of $\sigma$ -compactness. Any help is highly appreciated.","I'm struggling to prove the following fact: Suppose that is locally compact metric space. Let us denote with the space of functions vanishing at infinity (i.e., s.t. is compact and for ). Then is separable. I've proven that equipped with a supremum norm is a Banach space, and that (functions with compact support) are dense in , so my guess would be to somehow use those facts to prove that is separable. However, I can't exactly see how. I've seen the cases for compact spaces or using the assumption of -compactness. Any help is highly appreciated.","X C_0(X) \forall f \in C_0(X) \forall \varepsilon > 0 \exists  \, E\subset X E |f(x)|<\varepsilon x \in X\setminus E C_0(X) C_0(X) C_c(X) C_0(X) C_0(X) \sigma","['functional-analysis', 'banach-spaces', 'separable-spaces', 'function-spaces']"
2,Subset of $\ell^2$ with distance property,Subset of  with distance property,\ell^2,"I'd been trying the following problem: Prove that exists an infinite set $A\subset B(0,1)$ such that $\|x-y\|_2>\sqrt{2}$ for all $x,y \in A$ . My ideas always end in points with distance at most $\sqrt{2}$ . I need hints, please.","I'd been trying the following problem: Prove that exists an infinite set such that for all . My ideas always end in points with distance at most . I need hints, please.","A\subset B(0,1) \|x-y\|_2>\sqrt{2} x,y \in A \sqrt{2}","['functional-analysis', 'hilbert-spaces', 'lp-spaces']"
3,Why this equality is true?,Why this equality is true?,,"Let $E$ be a complex Hilbert space. Let ${\bf S} = (S_1,...,S_d) \in \mathcal{L}(E)^d$. We recall that $\|{\bf S}\|$ is defined by \begin{eqnarray*} \|{\bf S}\| &:=&\sup\left\{\bigg(\displaystyle\sum_{k=1}^d\|S_kx\|^2\bigg)^{\frac{1}{2}},\;x\in E,\;\|x\|=1\;\right\}, \end{eqnarray*} If the operators $S_k$ are commuting, why we have $$\displaystyle\sup_{\|x\|=1}\displaystyle\sum_{|\alpha|=n}\frac{n!}{\alpha!}\|{\bf S}^{\alpha}x\|^2=||{\bf S}^n||^2\;?? \;,$$ with $n\in\mathbb{N}^*,\;$ $\alpha = (\alpha_1, \alpha_2,...,\alpha_d) \in \mathbb{N}^d;\;\alpha!: =\alpha_1!...\alpha_d!,\;|\alpha|:=\displaystyle\sum_{j=1}^d\alpha_j$;  ${\bf S}^\alpha:=S_1^{\alpha_1} \cdots S_d^{\alpha_d}$ and ${\bf S}^n:={\bf S}\diamond{\bf S}\diamond\cdots\diamond{\bf S}$. Note that ${\bf S}^2 :={\bf S}\diamond{\bf S}= (S_1 S_1,\cdots,S_1 S_d,S_2S_1,\cdots,S_2S_d,S_dS_1\cdots,S_d S_d)$. Thank you!!","Let $E$ be a complex Hilbert space. Let ${\bf S} = (S_1,...,S_d) \in \mathcal{L}(E)^d$. We recall that $\|{\bf S}\|$ is defined by \begin{eqnarray*} \|{\bf S}\| &:=&\sup\left\{\bigg(\displaystyle\sum_{k=1}^d\|S_kx\|^2\bigg)^{\frac{1}{2}},\;x\in E,\;\|x\|=1\;\right\}, \end{eqnarray*} If the operators $S_k$ are commuting, why we have $$\displaystyle\sup_{\|x\|=1}\displaystyle\sum_{|\alpha|=n}\frac{n!}{\alpha!}\|{\bf S}^{\alpha}x\|^2=||{\bf S}^n||^2\;?? \;,$$ with $n\in\mathbb{N}^*,\;$ $\alpha = (\alpha_1, \alpha_2,...,\alpha_d) \in \mathbb{N}^d;\;\alpha!: =\alpha_1!...\alpha_d!,\;|\alpha|:=\displaystyle\sum_{j=1}^d\alpha_j$;  ${\bf S}^\alpha:=S_1^{\alpha_1} \cdots S_d^{\alpha_d}$ and ${\bf S}^n:={\bf S}\diamond{\bf S}\diamond\cdots\diamond{\bf S}$. Note that ${\bf S}^2 :={\bf S}\diamond{\bf S}= (S_1 S_1,\cdots,S_1 S_d,S_2S_1,\cdots,S_2S_d,S_dS_1\cdots,S_d S_d)$. Thank you!!",,"['functional-analysis', 'multinomial-coefficients']"
4,Spectrum in functional-analysis and algebraic geometry,Spectrum in functional-analysis and algebraic geometry,,"Why do we use the notion ""spectrum"" both in functional-analysis and in algebraic geometry? Are there any analogies?","Why do we use the notion ""spectrum"" both in functional-analysis and in algebraic geometry? Are there any analogies?",,['functional-analysis']
5,Example of a topological vector space which is not locally convex,Example of a topological vector space which is not locally convex,,"I'm currently studying Functional Analysis and the professor gave an example for a TVS (which we have defined to be a vector-space $X$ in which addition $X \times X \rightarrow X, (x, y) \mapsto x + y$ and scalar-multiplication $\mathbf{R} \times X \rightarrow X, (\lambda, x) \mapsto \lambda x$ are continuous), which is not locally convex. The example was the following: Let $L^0([0, 1])$ denote the set of measurable functions $f : [0, 1] \rightarrow \mathbf{R}$ modulo equivalence almost-everywhere for some measure $\mu$. We make this a metric-space by defining: $$d(f, g) = \int \frac{\vert f - g \vert}{1 + \vert f - g \vert} d \mu$$ and the then claimed that this is a TVS with the topology induced by $d$. I wanted to check this, and addition is not too big an issue, but I got stuck on scalar-multiplication. I'd appreciate some help on this. He went on explaining that convergence in $d$ of a sequence $(f_n)_{n \in \mathbf{N}}$ is convergence in measure. The exercise he gave us then (and which would be my question) was: Any non-empty open convex set $A$ in $L^0([0, 1])$ is equal to the whole space. I have very little idea on how to do this. My idea would have been to pick an element $g \notin A$ and then choosing a sequence $(g_n)_{n \in \mathbf{N}} \subset X - A$ converging to $g$. This may give me some contradiction, but I really do not see how to use the convexity of $A$. Thanks for any help!","I'm currently studying Functional Analysis and the professor gave an example for a TVS (which we have defined to be a vector-space $X$ in which addition $X \times X \rightarrow X, (x, y) \mapsto x + y$ and scalar-multiplication $\mathbf{R} \times X \rightarrow X, (\lambda, x) \mapsto \lambda x$ are continuous), which is not locally convex. The example was the following: Let $L^0([0, 1])$ denote the set of measurable functions $f : [0, 1] \rightarrow \mathbf{R}$ modulo equivalence almost-everywhere for some measure $\mu$. We make this a metric-space by defining: $$d(f, g) = \int \frac{\vert f - g \vert}{1 + \vert f - g \vert} d \mu$$ and the then claimed that this is a TVS with the topology induced by $d$. I wanted to check this, and addition is not too big an issue, but I got stuck on scalar-multiplication. I'd appreciate some help on this. He went on explaining that convergence in $d$ of a sequence $(f_n)_{n \in \mathbf{N}}$ is convergence in measure. The exercise he gave us then (and which would be my question) was: Any non-empty open convex set $A$ in $L^0([0, 1])$ is equal to the whole space. I have very little idea on how to do this. My idea would have been to pick an element $g \notin A$ and then choosing a sequence $(g_n)_{n \in \mathbf{N}} \subset X - A$ converging to $g$. This may give me some contradiction, but I really do not see how to use the convexity of $A$. Thanks for any help!",,"['functional-analysis', 'topological-vector-spaces', 'locally-convex-spaces']"
6,Counterexample of polynomials in infinite dimensional Banach spaces,Counterexample of polynomials in infinite dimensional Banach spaces,,"I'm trying to prove exercise I.3.B in Mujica's ""Complex analysis in Banach spaces"". DEFINITIONS: A map $P$ is an m-homogeneous polynomial from $E$ to $F$ if there is a m-linear map $A$ from $E^m$ to $F$ such that $P(x)=A(x, \dots, x)$ . $P$ is a polynomial of degree at most $m$ if $P = P_0 + \dots + P_m$ where each $P_j$ is an j-homogeneous polynomial. I have to find a function $f: E \to \mathbb{K}$ (where $E$ is infinite dimensional) such that $f(a + \lambda b)$ is a polynomial in $\lambda$ for all $a,b \in E$ but $f$ is not a polynomial. $f$ clearly has to be discontinuous because there is a theorem implying that $f$ would be a polynomial in the continuous case. I thought about considering something like (where $\theta$ stands for the step function): $$f(a+\lambda b) = \theta (\| b\| -1) (a_1 + \lambda b_1)$$ But I don't know how to prove that $f$ wouldn't be a polynomial or even how to apply it to an arbitrary $x \in E$ . I also know that the restriction of $f$ to any finite dimensional subspace of $E$ is indeed a polynomial and that there is a sequence of homogeneous polynomials $P_k$ such that $f(x)=\sum_{k=0}^{\infty} P_k(x)$ where for each $x \in E$ $P_k(x)=0$ for all but finitely many indices. What function could act as a good example for this situation? I can provide any definition if you're not familiar with the terminology. Please ask for clarification in a comment if that is the case.","I'm trying to prove exercise I.3.B in Mujica's ""Complex analysis in Banach spaces"". DEFINITIONS: A map is an m-homogeneous polynomial from to if there is a m-linear map from to such that . is a polynomial of degree at most if where each is an j-homogeneous polynomial. I have to find a function (where is infinite dimensional) such that is a polynomial in for all but is not a polynomial. clearly has to be discontinuous because there is a theorem implying that would be a polynomial in the continuous case. I thought about considering something like (where stands for the step function): But I don't know how to prove that wouldn't be a polynomial or even how to apply it to an arbitrary . I also know that the restriction of to any finite dimensional subspace of is indeed a polynomial and that there is a sequence of homogeneous polynomials such that where for each for all but finitely many indices. What function could act as a good example for this situation? I can provide any definition if you're not familiar with the terminology. Please ask for clarification in a comment if that is the case.","P E F A E^m F P(x)=A(x, \dots, x) P m P = P_0 + \dots + P_m P_j f: E \to \mathbb{K} E f(a + \lambda b) \lambda a,b \in E f f f \theta f(a+\lambda b) = \theta (\| b\| -1) (a_1 + \lambda b_1) f x \in E f E P_k f(x)=\sum_{k=0}^{\infty} P_k(x) x \in E P_k(x)=0","['functional-analysis', 'polynomials', 'banach-spaces', 'examples-counterexamples']"
7,Equivalence of weak $L^p$ norms,Equivalence of weak  norms,L^p,"I'm kind of new to the subject of weak $L^p$ spaces. The definition of the (quasi-)norm in weak $L^p$ ($p\in(0; \infty)\,$) over $\sigma$-finite measure space $(X, \mu)$ I use is $||f||_{L^{p, \infty}} = \sup_{t\in\left(0, \infty\right)} t^{\frac{1}{p}}f^*\left(t\right)$, where $f^*(t)=\inf\{\lambda>0; \mu_f(\lambda)\leq t\}$ and $\mu_f(\lambda) = \mu(\{x\in X; |f(x)|>\lambda\})$. However, when studying another article regarding weak $L^p$ spaces, I came across this definition $||f||_{L^{p, \infty}} = \sup_{\lambda\in\left(0, \infty\right)} \lambda (\mu_f(\lambda))^\frac{1}{p}$. Somehow I forced myself to believe $\sup_{t\in\left(0, \infty\right)} t^{\frac{1}{p}}f^*\left(t\right) = \sup_{\lambda\in\left(0, \infty\right)}\lambda(\mu_f\left(\lambda\right))^\frac{1}{p}$. Today I decided to prove it rigorously. To my surprise, I've been struggling to prove it. I proved that $f^*(\mu_f(\lambda))\leq\lambda$ (if $\mu_f(\lambda)<\infty$) and $\mu_f(f^*(t))\leq t$ (if $f^*(t) < \infty)$ but I failed in using it to prove the equality. Does the equality really hold? I believe I must be missing some simple thing(s) but after spending hours trying to prove it I find myself really desperate. Thank you for any help!","I'm kind of new to the subject of weak $L^p$ spaces. The definition of the (quasi-)norm in weak $L^p$ ($p\in(0; \infty)\,$) over $\sigma$-finite measure space $(X, \mu)$ I use is $||f||_{L^{p, \infty}} = \sup_{t\in\left(0, \infty\right)} t^{\frac{1}{p}}f^*\left(t\right)$, where $f^*(t)=\inf\{\lambda>0; \mu_f(\lambda)\leq t\}$ and $\mu_f(\lambda) = \mu(\{x\in X; |f(x)|>\lambda\})$. However, when studying another article regarding weak $L^p$ spaces, I came across this definition $||f||_{L^{p, \infty}} = \sup_{\lambda\in\left(0, \infty\right)} \lambda (\mu_f(\lambda))^\frac{1}{p}$. Somehow I forced myself to believe $\sup_{t\in\left(0, \infty\right)} t^{\frac{1}{p}}f^*\left(t\right) = \sup_{\lambda\in\left(0, \infty\right)}\lambda(\mu_f\left(\lambda\right))^\frac{1}{p}$. Today I decided to prove it rigorously. To my surprise, I've been struggling to prove it. I proved that $f^*(\mu_f(\lambda))\leq\lambda$ (if $\mu_f(\lambda)<\infty$) and $\mu_f(f^*(t))\leq t$ (if $f^*(t) < \infty)$ but I failed in using it to prove the equality. Does the equality really hold? I believe I must be missing some simple thing(s) but after spending hours trying to prove it I find myself really desperate. Thank you for any help!",,"['functional-analysis', 'measure-theory', 'lp-spaces', 'supremum-and-infimum', 'weak-lp-spaces']"
8,Application of Schwartz Kernel Theorem to Quantum Mechanics,Application of Schwartz Kernel Theorem to Quantum Mechanics,,"I am currently reading Quantum Mechanics for Mathematicians and have a question about a statement made in the book: Remark. By the Schwartz kernel theorem, the operator B can be represented by an integral operator with distributional kernel $K(q,q')$. Then the commutativity $BQ = QB$ implies that, in the distributional sense, $$ (q-q')K(q,q') = 0, $$ so that $K$ is ""proportional"" to the Dirac delta-function, i .e.,  $$ K(q,q') = f(q)\delta(q-q').  $$ This argument is usually given in physics textbooks. $B$ and $Q$ are both operators in the coordinate representation. $Q$ is the position operator and $B$ is bounded. So, first of all, I can't find much about the kernel theorem online. I've been using this as a reference . According to this document, there is a relation between bilinear forms and distributions. However, I don't know how to view $B$ as a bilinear form and thus apply the theorem. Can someone elucidate how the kernel theorem is applicable to $B$? Secondly, what arguments/notation in physics is the author (of the QM book) referencing?","I am currently reading Quantum Mechanics for Mathematicians and have a question about a statement made in the book: Remark. By the Schwartz kernel theorem, the operator B can be represented by an integral operator with distributional kernel $K(q,q')$. Then the commutativity $BQ = QB$ implies that, in the distributional sense, $$ (q-q')K(q,q') = 0, $$ so that $K$ is ""proportional"" to the Dirac delta-function, i .e.,  $$ K(q,q') = f(q)\delta(q-q').  $$ This argument is usually given in physics textbooks. $B$ and $Q$ are both operators in the coordinate representation. $Q$ is the position operator and $B$ is bounded. So, first of all, I can't find much about the kernel theorem online. I've been using this as a reference . According to this document, there is a relation between bilinear forms and distributions. However, I don't know how to view $B$ as a bilinear form and thus apply the theorem. Can someone elucidate how the kernel theorem is applicable to $B$? Secondly, what arguments/notation in physics is the author (of the QM book) referencing?",,"['functional-analysis', 'operator-theory', 'mathematical-physics', 'quantum-mechanics']"
9,Conditions for a kernel of a bounded operator to be complemented,Conditions for a kernel of a bounded operator to be complemented,,"I am well aware of the problem of complementing subspaces in Banach spaces as it was discussed here and here . Nevertheless, I wonder whether there are conditions for existence of a complement $M$ to the kernel $N$ of a bounded linear operator $T:V\to Q$. That is, under which conditions there is a closed subspace $M\subset V$ such that $N \oplus M = V$? In my particular case, the operator $T\colon V \to Q$ fulfills these equivalent properties: $T'\colon Q' \to V'$ is an homeomorphism on its range $T'$ is injective and has a closed range $T$ is surjective $T$ has a bounded right inverse (I was wrong here, see comments below) Any ideas? Disclaimer: This relates to the problem I have posted the day before. EDIT: I additionally assume that $V$ and $Q$ are reflexive and separable. UPDATE: I have answered the questions, based on the comments.","I am well aware of the problem of complementing subspaces in Banach spaces as it was discussed here and here . Nevertheless, I wonder whether there are conditions for existence of a complement $M$ to the kernel $N$ of a bounded linear operator $T:V\to Q$. That is, under which conditions there is a closed subspace $M\subset V$ such that $N \oplus M = V$? In my particular case, the operator $T\colon V \to Q$ fulfills these equivalent properties: $T'\colon Q' \to V'$ is an homeomorphism on its range $T'$ is injective and has a closed range $T$ is surjective $T$ has a bounded right inverse (I was wrong here, see comments below) Any ideas? Disclaimer: This relates to the problem I have posted the day before. EDIT: I additionally assume that $V$ and $Q$ are reflexive and separable. UPDATE: I have answered the questions, based on the comments.",,"['functional-analysis', 'operator-theory', 'banach-spaces']"
10,Example of a sequence that converges to two different limits with respect to two complete norms,Example of a sequence that converges to two different limits with respect to two complete norms,,"I've wondered about the following question : Is there an (explicit?) example of a vector space $X$, two complete norms $\|\cdot\|_1$ and $\|\cdot\|_2$ on $X$, and a sequence $(x_n) \subseteq X$ such that $x_n$ converges to $x$ with respect to $\|\cdot\|_1$, $x_n$ converges to $y$ with respect to $\|\cdot\|_2$, but $x \neq y$? Obviously, this would imply that $\|\cdot\|_1$ and $\|\cdot\|_2$ are not equivalent. In fact, these two statements are equivalent, which is a consequence of the Open Mapping Theorem.","I've wondered about the following question : Is there an (explicit?) example of a vector space $X$, two complete norms $\|\cdot\|_1$ and $\|\cdot\|_2$ on $X$, and a sequence $(x_n) \subseteq X$ such that $x_n$ converges to $x$ with respect to $\|\cdot\|_1$, $x_n$ converges to $y$ with respect to $\|\cdot\|_2$, but $x \neq y$? Obviously, this would imply that $\|\cdot\|_1$ and $\|\cdot\|_2$ are not equivalent. In fact, these two statements are equivalent, which is a consequence of the Open Mapping Theorem.",,"['functional-analysis', 'limits', 'convergence-divergence', 'normed-spaces']"
11,Showing the sum of orthogonal projections with orthogonal ranges is also an orthogonal projection,Showing the sum of orthogonal projections with orthogonal ranges is also an orthogonal projection,,"Show that if $P$ and $Q$ are two orthogonal projections with orthogonal ranges, then $P+Q$ is also an orthogonal projection. First I need to show $(P+Q)^\ast = P+Q$. I am thinking that since \begin{align*} ((P+Q)^\ast f , g) & = (f,(P+Q)g) \\  & = (f,Pg) + (f,Qg) \\  & = (P^\ast f,g) + (Q^\ast f,g) \\  & = (Pf,g) + (Qf,g) \\  & = ((P+Q)f,g), \end{align*} we get $(P+Q)^\ast=P+Q$. I am not sure if what I am thinking is right since I assumed that $(P+Q)f=Pf+Qf$ is true  for any bounded linear operator $P$, $Q$. For $(P+Q)^2=P+Q$, I use $$(P+Q)^2= P^2 + Q^2 + PQ +QP,$$ but I cant show $PQ=0$ and $QP=0$. Anyone can help me? Thanks.","Show that if $P$ and $Q$ are two orthogonal projections with orthogonal ranges, then $P+Q$ is also an orthogonal projection. First I need to show $(P+Q)^\ast = P+Q$. I am thinking that since \begin{align*} ((P+Q)^\ast f , g) & = (f,(P+Q)g) \\  & = (f,Pg) + (f,Qg) \\  & = (P^\ast f,g) + (Q^\ast f,g) \\  & = (Pf,g) + (Qf,g) \\  & = ((P+Q)f,g), \end{align*} we get $(P+Q)^\ast=P+Q$. I am not sure if what I am thinking is right since I assumed that $(P+Q)f=Pf+Qf$ is true  for any bounded linear operator $P$, $Q$. For $(P+Q)^2=P+Q$, I use $$(P+Q)^2= P^2 + Q^2 + PQ +QP,$$ but I cant show $PQ=0$ and $QP=0$. Anyone can help me? Thanks.",,"['functional-analysis', 'hilbert-spaces']"
12,Set of all compact operators $K(H)$ is the unique ideal in $B(H)$?,Set of all compact operators  is the unique ideal in ?,K(H) B(H),I want to show that the set of all compact operators $K(H)$ is the unique ideal in $B(H)$. Is there any relation between invertibility and compactness of an operator?,I want to show that the set of all compact operators $K(H)$ is the unique ideal in $B(H)$. Is there any relation between invertibility and compactness of an operator?,,"['functional-analysis', 'operator-theory', 'hilbert-spaces', 'ideals', 'compact-operators']"
13,Reproducing kernel Hilbert spaces from Sobolev spaces with weight/density functions,Reproducing kernel Hilbert spaces from Sobolev spaces with weight/density functions,,"I would like to understand which of the statements about the Sobolev space $H^1(\mathbb{R})$ remain true if one introduces a density/weight function in the definition. Details The Sobolev space $H^1(\mathbb{R})$ are those square integrable functions whose first weak derivatives exist almost everywhere and are square integrable or briefly $f^2\in L^1$ and $(f')^2\in L^1.$ This space $H^1(\mathbb{R})$ has the following properties It is a reproducing kernel Hilbert space with inner product $$\langle f,g\rangle=\int_{\mathbb{R}} f(x)g(x)\,dx + \int_{\mathbb{R}} f'(x)g'(x)\,dx.$$ The functions in $H^1(\mathbb{R})$ are continuous. Let $w:\mathbb{R}\rightarrow\mathbb{R}$ be a weight function or density, which is a strictly positive function with $\int w(x)\,dx=1.$ Now define the weighted $L^1$ space as $L^1(w):=\left\{ f:\mathbb{R}\rightarrow\mathbb{R} \mid fw\in L^1\right\}$ with norm $\lVert f\rVert_w=\int_{\mathbb{R}} |f(x)| w(x)\,dx$ and the weighted Sobolev space $H^1_w(\mathbb{R})$ by replacing $L^1$ with $L^1(w)$ in the definition above. This means the inner product of $H^1_w(\mathbb{R})$ would be $$\langle f,g\rangle_w=\int_{\mathbb{R}} f(x)g(x)w(x)\,dx + \int_{\mathbb{R}} f'(x)g'(x)w(x)\,dx.$$ Question Does $H^1_w(\mathbb{R})$ still have the two properties? I.e. is it still a reproducing kernel Hilbert space consisting of continuous functions? EDIT: The literature for weighted Sobolev spaces seems to focus on weights which are of ""Muckenhoupt class"" (see this related question ) or "" doubling measures "". But finite measures are never doubling measures. EDIT2 I would like to use the weights in applications to control the asymptotic behaviour of the functions in the RKHS. E.g. I would like to have spaces containing constant functions, polynomials (up to a certain degree) or exponential functions. This means I am quite relaxed about the properties of $w$ . $w$ may be assumed to be continuous or even differentiable, if this helps. Typical examples for $w$ would be functions such as $\exp(-x^2)$ , $\frac{1}{\cosh x}$ or $\frac{1}{(1+x^2)^k}$ .","I would like to understand which of the statements about the Sobolev space remain true if one introduces a density/weight function in the definition. Details The Sobolev space are those square integrable functions whose first weak derivatives exist almost everywhere and are square integrable or briefly and This space has the following properties It is a reproducing kernel Hilbert space with inner product The functions in are continuous. Let be a weight function or density, which is a strictly positive function with Now define the weighted space as with norm and the weighted Sobolev space by replacing with in the definition above. This means the inner product of would be Question Does still have the two properties? I.e. is it still a reproducing kernel Hilbert space consisting of continuous functions? EDIT: The literature for weighted Sobolev spaces seems to focus on weights which are of ""Muckenhoupt class"" (see this related question ) or "" doubling measures "". But finite measures are never doubling measures. EDIT2 I would like to use the weights in applications to control the asymptotic behaviour of the functions in the RKHS. E.g. I would like to have spaces containing constant functions, polynomials (up to a certain degree) or exponential functions. This means I am quite relaxed about the properties of . may be assumed to be continuous or even differentiable, if this helps. Typical examples for would be functions such as , or .","H^1(\mathbb{R}) H^1(\mathbb{R}) f^2\in L^1 (f')^2\in L^1. H^1(\mathbb{R}) \langle f,g\rangle=\int_{\mathbb{R}} f(x)g(x)\,dx + \int_{\mathbb{R}} f'(x)g'(x)\,dx. H^1(\mathbb{R}) w:\mathbb{R}\rightarrow\mathbb{R} \int w(x)\,dx=1. L^1 L^1(w):=\left\{ f:\mathbb{R}\rightarrow\mathbb{R} \mid fw\in L^1\right\} \lVert f\rVert_w=\int_{\mathbb{R}} |f(x)| w(x)\,dx H^1_w(\mathbb{R}) L^1 L^1(w) H^1_w(\mathbb{R}) \langle f,g\rangle_w=\int_{\mathbb{R}} f(x)g(x)w(x)\,dx + \int_{\mathbb{R}} f'(x)g'(x)w(x)\,dx. H^1_w(\mathbb{R}) w w w \exp(-x^2) \frac{1}{\cosh x} \frac{1}{(1+x^2)^k}","['functional-analysis', 'partial-differential-equations', 'hilbert-spaces', 'sobolev-spaces', 'reproducing-kernel-hilbert-spaces']"
14,Are weakly compact sets bounded?,Are weakly compact sets bounded?,,"Let $X$ be a Hausdorff locally convex topological vector space, and let $X'$ denote its topological dual, that is, the vector space of all continuous linear functionals on $X$ . If $A$ is a weakly compact subset of $X$ , that is, if $A$ is $\sigma(X,X')$ -compact in $X$ , is it (always) true that $A$ is bounded in $X$ ? If not, can anybody give a counterexample for such a set?","Let be a Hausdorff locally convex topological vector space, and let denote its topological dual, that is, the vector space of all continuous linear functionals on . If is a weakly compact subset of , that is, if is -compact in , is it (always) true that is bounded in ? If not, can anybody give a counterexample for such a set?","X X' X A X A \sigma(X,X') X A X","['functional-analysis', 'topological-vector-spaces', 'locally-convex-spaces', 'weak-topology']"
15,Weak and Weak* convergences implying reflexivity,Weak and Weak* convergences implying reflexivity,,"Let $X$ be a Banach space. Suppose that for any sequence of functionals $(\phi_n) \subseteq X^*$ we have that $\phi_n$ converges weakly to some $\phi \in X^*$ if and only if $\phi_n$ converges weakly* to $\phi.$ We know that the weak and weak* topologies on $X^*$ coincide if and only if $X$ is reflexive. Since two topological spaces that have the same convergent sequences do not need to be equal, our $X$ above does not need the weak and weak* topologies to coincide. So what can we say about such an $X$ above? Is it still reflexive?","Let be a Banach space. Suppose that for any sequence of functionals we have that converges weakly to some if and only if converges weakly* to We know that the weak and weak* topologies on coincide if and only if is reflexive. Since two topological spaces that have the same convergent sequences do not need to be equal, our above does not need the weak and weak* topologies to coincide. So what can we say about such an above? Is it still reflexive?",X (\phi_n) \subseteq X^* \phi_n \phi \in X^* \phi_n \phi. X^* X X X,"['functional-analysis', 'banach-spaces', 'weak-convergence', 'reflexive-space']"
16,Defining interpolation spaces of Hilbert spaces using domains of unbounded operators,Defining interpolation spaces of Hilbert spaces using domains of unbounded operators,,"This comes from the book Non-Homogeneous Boundary Value Problems and Applications I by Lions and Magenes, section 2.1. Let $X\subset Y$ be a dense continuous injection of separable complex Hilbert spaces. We will define a strictly positive self-adjoint densely-defined unbounded operator $S$ in $Y$ as follows. Let $D(S)$ denote those $x\in X\subset Y$ such that $$X\to\Bbb C,\quad v\mapsto\langle u,v\rangle_X$$ is continuous w.r.t. the topology on $X$ induced by $Y$. Then we may define an operator $S:D(S)\to Y$ by setting $$\langle u,v\rangle_X=\langle Su,v\rangle_Y$$ for all $v\in X$, which uniquely defines $Su$ by density. Now, the authors state the following (without proof or explanation): Proposition For $S$ defined as such, $D(S)$ is dense in $Y$, and furthermore that $S$ is self-adjoint. Using the spectral theorem for unbounded self-adjoint operators, if we set $\Lambda=S^{1/2}$, then $D(\Lambda)=X$. However, I haven't managed to figure out the proof of any of these claims. For  general background, we have the following equivalence. We say that a densely-defined unbounded operator $S:D(S)\to Y$ on $Y$ is symmetric if it is closable and $\langle Su,v\rangle_Y=\langle u,Sv\rangle_Y$ for all $u,v\in D(S)$. Then for any symmetric operator $S$, the following are equivalent. The operator $S$ is self-adjoint. The operator $S$ is closed, and $\ker(S\pm i)=0$ as subspaces of $D(S)$. We have $\operatorname{im}(S\pm i)=Y$ where the image is of $D(S)$. Equivalently, we may replace $i,-i$ above with $\lambda,\bar\lambda$ for any strictly complex $\lambda$. Now, assuming that $D(S)\subset Y$ is dense and $S$ is closable, I see that $S$ is symmetric. Furthermore, for any $v\in D(S)$, we have that $$\langle Sv,v\rangle_Y=\lVert v\rVert_X\ge C\lVert v\rVert_Y$$ for some fixed $C>0$. This tells us that $S$ is injective, and furthermore that is $S$ if closed, then it is self-adjoint, since for any $\lambda\in\Bbb C\setminus\Bbb R$ with $|\lambda|<C$, if $Sv=\lambda v$ then $$0=|\langle Sv,v\rangle_Y-\langle\lambda v,v\rangle_Y|\ge C\lVert c\rVert_Y-|\lambda|\lVert v\rVert_Y$$ so that $v=0$. However, showing that $S$ is closed or even closable is beyond me. Any help with approaching a proof of the proposition would be greatly appreciated.","This comes from the book Non-Homogeneous Boundary Value Problems and Applications I by Lions and Magenes, section 2.1. Let $X\subset Y$ be a dense continuous injection of separable complex Hilbert spaces. We will define a strictly positive self-adjoint densely-defined unbounded operator $S$ in $Y$ as follows. Let $D(S)$ denote those $x\in X\subset Y$ such that $$X\to\Bbb C,\quad v\mapsto\langle u,v\rangle_X$$ is continuous w.r.t. the topology on $X$ induced by $Y$. Then we may define an operator $S:D(S)\to Y$ by setting $$\langle u,v\rangle_X=\langle Su,v\rangle_Y$$ for all $v\in X$, which uniquely defines $Su$ by density. Now, the authors state the following (without proof or explanation): Proposition For $S$ defined as such, $D(S)$ is dense in $Y$, and furthermore that $S$ is self-adjoint. Using the spectral theorem for unbounded self-adjoint operators, if we set $\Lambda=S^{1/2}$, then $D(\Lambda)=X$. However, I haven't managed to figure out the proof of any of these claims. For  general background, we have the following equivalence. We say that a densely-defined unbounded operator $S:D(S)\to Y$ on $Y$ is symmetric if it is closable and $\langle Su,v\rangle_Y=\langle u,Sv\rangle_Y$ for all $u,v\in D(S)$. Then for any symmetric operator $S$, the following are equivalent. The operator $S$ is self-adjoint. The operator $S$ is closed, and $\ker(S\pm i)=0$ as subspaces of $D(S)$. We have $\operatorname{im}(S\pm i)=Y$ where the image is of $D(S)$. Equivalently, we may replace $i,-i$ above with $\lambda,\bar\lambda$ for any strictly complex $\lambda$. Now, assuming that $D(S)\subset Y$ is dense and $S$ is closable, I see that $S$ is symmetric. Furthermore, for any $v\in D(S)$, we have that $$\langle Sv,v\rangle_Y=\lVert v\rVert_X\ge C\lVert v\rVert_Y$$ for some fixed $C>0$. This tells us that $S$ is injective, and furthermore that is $S$ if closed, then it is self-adjoint, since for any $\lambda\in\Bbb C\setminus\Bbb R$ with $|\lambda|<C$, if $Sv=\lambda v$ then $$0=|\langle Sv,v\rangle_Y-\langle\lambda v,v\rangle_Y|\ge C\lVert c\rVert_Y-|\lambda|\lVert v\rVert_Y$$ so that $v=0$. However, showing that $S$ is closed or even closable is beyond me. Any help with approaching a proof of the proposition would be greatly appreciated.",,"['functional-analysis', 'partial-differential-equations', 'operator-theory', 'hilbert-spaces', 'spectral-theory']"
17,A density proof not via Stone-Weierstrass,A density proof not via Stone-Weierstrass,,"Context: I have proved Weierstrass' theorem (polynomials are dense in $C[a,b]$) in two ways: one using Bernstein polynomials, and one using convolutions. You can also use Stone-Weierstrass theorem, however I do not quote that result since I have not proved it. My question, however, is of a different nature: I am not allowed to use Stone-Weierstrass, but am asked to prove the following: Given a continuous function $f \in C(\mathbb R)$ such that $\lim_{|x| \to \infty} f(x) = 0$, and given $\epsilon>0$, there exists a polynomial $p$ such that $|f(x) - p(x)e^{-|x|}| < \epsilon$ for all $x \in \mathbb R$. Which is to say, the set $\{ p(x)e^{-|x|} : p \in \mathscr P\}$ is dense in the set of continuous functions on $\mathbb R$ decaying to zero (in the supremum norm). You cannot try to approximate $f(x)e^{|x|}$ by polynomials, because that will give you a right side bound dependent on $x$, which is not the case in uniform convergence. Furthermore, working over $\mathbb R$, breaking it into compact intervals and applying Weierstrass is getting me nowhere. Hence, I need help on this question. I request an incomplete ""fill-in-the-blank"" answer, if that's possible!","Context: I have proved Weierstrass' theorem (polynomials are dense in $C[a,b]$) in two ways: one using Bernstein polynomials, and one using convolutions. You can also use Stone-Weierstrass theorem, however I do not quote that result since I have not proved it. My question, however, is of a different nature: I am not allowed to use Stone-Weierstrass, but am asked to prove the following: Given a continuous function $f \in C(\mathbb R)$ such that $\lim_{|x| \to \infty} f(x) = 0$, and given $\epsilon>0$, there exists a polynomial $p$ such that $|f(x) - p(x)e^{-|x|}| < \epsilon$ for all $x \in \mathbb R$. Which is to say, the set $\{ p(x)e^{-|x|} : p \in \mathscr P\}$ is dense in the set of continuous functions on $\mathbb R$ decaying to zero (in the supremum norm). You cannot try to approximate $f(x)e^{|x|}$ by polynomials, because that will give you a right side bound dependent on $x$, which is not the case in uniform convergence. Furthermore, working over $\mathbb R$, breaking it into compact intervals and applying Weierstrass is getting me nowhere. Hence, I need help on this question. I request an incomplete ""fill-in-the-blank"" answer, if that's possible!",,"['functional-analysis', 'polynomials', 'approximation', 'uniform-convergence', 'weierstrass-approximation']"
18,Bochner-Sobolev space vs. Sobolev space on product via Fubini-Tonelli?,Bochner-Sobolev space vs. Sobolev space on product via Fubini-Tonelli?,,"Let $\Omega \subset \mathbb{R}^n$ be a domain. There are two different types of Sobolev spaces on $\Omega \times \mathbb{R}$ that are used in PDE Theory: one is the Bochner-Sobolev space $W^{1,p}(\mathbb{R}, W^{1,q}(\Omega))$ of Banach-space valued functions; the other is the usual Sobolev space $W^{1,p}(\Omega \times \mathbb{R})$ on the product space. It seems to me that there should be some kind of simple relation between these two kinds of spaces coming from Fubini-Tonelli. However, none of the standard references that I've looked at seem to state any kind of result along these lines, which makes me somewhat concerned. Can someone give a reference for a theorem that relates these two? Background: I'm reading a PDE paper which states all of its results in terms of Bochner-Sobolev spaces and I'd like to understand how these results translate back into ordinary Sobolev spaces.","Let $\Omega \subset \mathbb{R}^n$ be a domain. There are two different types of Sobolev spaces on $\Omega \times \mathbb{R}$ that are used in PDE Theory: one is the Bochner-Sobolev space $W^{1,p}(\mathbb{R}, W^{1,q}(\Omega))$ of Banach-space valued functions; the other is the usual Sobolev space $W^{1,p}(\Omega \times \mathbb{R})$ on the product space. It seems to me that there should be some kind of simple relation between these two kinds of spaces coming from Fubini-Tonelli. However, none of the standard references that I've looked at seem to state any kind of result along these lines, which makes me somewhat concerned. Can someone give a reference for a theorem that relates these two? Background: I'm reading a PDE paper which states all of its results in terms of Bochner-Sobolev spaces and I'd like to understand how these results translate back into ordinary Sobolev spaces.",,"['functional-analysis', 'partial-differential-equations']"
19,Submultiplicative Hilbert space norm on $B(H)$,Submultiplicative Hilbert space norm on,B(H),"Let $H$ be a complex Hilbert space and let $B(H)$ denote the space of bounded linear operators $H \to H$ equipped with operator norm: $$ \lVert T \rVert = \sup\big\{ \lVert Tx \rVert \: : \: \lVert x \rVert \leq 1\big\}. $$ One easily shows that $B(H)$ is not a Hilbert space whenever $\dim(H) > 1$ holds, for it does not satisfy the parallelogram rule . Furthermore, an abstract argument shows that there exists a Hilbert space norm $\lVert\:\cdot\:\rVert_2$ on $B(H)$, but it does not provide us with a very concrete description of such a norm. In the finite-dimensional case one might take the Hilbert–Schmidt norm : this turns $B(H)$ into a Hilbert space and it is known to be submultiplicative. However, in the infinite-dimensional case this does not work, for now the space of Hilbert–Schmidt operators is a proper subspace of $B(H)$. This leads me to the following question: Question. Is there a submultiplicative Hilbert space norm on $B(H)$ if $H$ is infinite-dimensional, either by abstract reasoning or by concrete example? For the moment I do not care whether this new norm is equivalent to the operator norm. This is a strengthening of the question Is B(H) a Hilbert space? which did not ask for submultiplicativity.","Let $H$ be a complex Hilbert space and let $B(H)$ denote the space of bounded linear operators $H \to H$ equipped with operator norm: $$ \lVert T \rVert = \sup\big\{ \lVert Tx \rVert \: : \: \lVert x \rVert \leq 1\big\}. $$ One easily shows that $B(H)$ is not a Hilbert space whenever $\dim(H) > 1$ holds, for it does not satisfy the parallelogram rule . Furthermore, an abstract argument shows that there exists a Hilbert space norm $\lVert\:\cdot\:\rVert_2$ on $B(H)$, but it does not provide us with a very concrete description of such a norm. In the finite-dimensional case one might take the Hilbert–Schmidt norm : this turns $B(H)$ into a Hilbert space and it is known to be submultiplicative. However, in the infinite-dimensional case this does not work, for now the space of Hilbert–Schmidt operators is a proper subspace of $B(H)$. This leads me to the following question: Question. Is there a submultiplicative Hilbert space norm on $B(H)$ if $H$ is infinite-dimensional, either by abstract reasoning or by concrete example? For the moment I do not care whether this new norm is equivalent to the operator norm. This is a strengthening of the question Is B(H) a Hilbert space? which did not ask for submultiplicativity.",,"['functional-analysis', 'hilbert-spaces', 'banach-spaces', 'banach-algebras']"
20,"Subspaces of $C^\alpha [0,1]$ are finite dimensional if closed in $C[0,1]$",Subspaces of  are finite dimensional if closed in,"C^\alpha [0,1] C[0,1]","For $0 < \alpha < 1$, let $C^\alpha([0,1])$ be the subspace of $C[0,1]$ consisting of continuous functions with norm $$ \| f\|_\alpha = \|f\| + \sup_{x\neq y} \frac{|f(x) - f(y)|}{|x-y|^\alpha},$$ where $\|\cdot\|$ is the ordinary sup norm on $C[0,1]$. Problem: Let $X$ be a linear subspace of $C^\alpha[0,1]$. Suppose further $X$ is closed in $C[0,1]$. Then $X$ is finite dimensional. My strategy is to show that the unit ball $B \subseteq X$ is compact w.r.t. the $\| \cdot \|_\alpha$ norm. By the Arzela-Ascoli theorem, I can prove that $B$ is compact w.r.t. the $\| \cdot \|$ norm. It is clear to me that  $$\|\cdot\| \leq \|\cdot\|_{\alpha}.$$ However, how can I show that there is some constant $C$ so that  $$\|\cdot\|_\alpha \leq C\|\cdot\|?$$","For $0 < \alpha < 1$, let $C^\alpha([0,1])$ be the subspace of $C[0,1]$ consisting of continuous functions with norm $$ \| f\|_\alpha = \|f\| + \sup_{x\neq y} \frac{|f(x) - f(y)|}{|x-y|^\alpha},$$ where $\|\cdot\|$ is the ordinary sup norm on $C[0,1]$. Problem: Let $X$ be a linear subspace of $C^\alpha[0,1]$. Suppose further $X$ is closed in $C[0,1]$. Then $X$ is finite dimensional. My strategy is to show that the unit ball $B \subseteq X$ is compact w.r.t. the $\| \cdot \|_\alpha$ norm. By the Arzela-Ascoli theorem, I can prove that $B$ is compact w.r.t. the $\| \cdot \|$ norm. It is clear to me that  $$\|\cdot\| \leq \|\cdot\|_{\alpha}.$$ However, how can I show that there is some constant $C$ so that  $$\|\cdot\|_\alpha \leq C\|\cdot\|?$$",,"['functional-analysis', 'banach-spaces']"
21,Conditional expectation onto maximal abelian subalgebras,Conditional expectation onto maximal abelian subalgebras,,"If you take a von Neumann algebra $M$ and its maximal abelian subalgebra (masa) $D$ , then there is a norm-one projection from $M$ onto $D$ (conditional expectation). The same is true if you take the Cuntz algebra $O_2$ and its canonical masa $C(\Delta)$ . Is this true in general? Let $A$ be an arbitrary C*-algebra. Is there a masa $D$ of $A$ onto which there is a conditional expectation (norm-one projection from $A$ onto $D$ )?","If you take a von Neumann algebra and its maximal abelian subalgebra (masa) , then there is a norm-one projection from onto (conditional expectation). The same is true if you take the Cuntz algebra and its canonical masa . Is this true in general? Let be an arbitrary C*-algebra. Is there a masa of onto which there is a conditional expectation (norm-one projection from onto )?",M D M D O_2 C(\Delta) A D A A D,"['functional-analysis', 'banach-spaces', 'operator-algebras', 'conditional-expectation', 'c-star-algebras']"
22,In which cases the spectrum of an operator contains only eigenvalues?,In which cases the spectrum of an operator contains only eigenvalues?,,"Let $X\neq \{0\}$ be a complex normed spaces (not necessarily finite-dimensional) and $T:D(T)\subset X\to X$ a closed linear operator (not necessarily bounded). I would like to know under what conditions can we conclude that every spectral value $\lambda\neq 0$ of $T$ is, is fact, an eigenvalue of $T$. For example, a common condition is: $T$ compact and $D(T)=X$ (see Kreyszig , p. 420). Are there some other? Thanks.","Let $X\neq \{0\}$ be a complex normed spaces (not necessarily finite-dimensional) and $T:D(T)\subset X\to X$ a closed linear operator (not necessarily bounded). I would like to know under what conditions can we conclude that every spectral value $\lambda\neq 0$ of $T$ is, is fact, an eigenvalue of $T$. For example, a common condition is: $T$ compact and $D(T)=X$ (see Kreyszig , p. 420). Are there some other? Thanks.",,"['functional-analysis', 'operator-theory', 'spectral-theory']"
23,Rudin 13.3 zero operator as adjoint,Rudin 13.3 zero operator as adjoint,,"For an assignment I have to show that exists a densely defined operator on a infinite dimensional separable Hilbert space, such that its adjoint is the zero operator on the zero subspace. To show this there is a reference to exercise 13.3 in the book Functional Analysis of Rudin. The exercise is as follows By theorem 13.8, $\mathscr{D}(T^*) =\{0\}$ for a densely defined operator $T$ in $H$ if and only if $\mathscr{G}(T)$ is dense in $H\times H$. Show that this can actually happen. Suggestion: Let $\{e_n:n=1,2,3, \dots\}$ be an orthonormal basis of $H$; let $\{x_n\}$ be a dense subset of $H$; define $Te_n=x_n$; and extend $T$ linearly to $\mathscr{D}(T)$, the set of all finite linear combinations of the basis vector $e_n$. Show that the graph of   this $T$ is dense in $H \times H$. The exercise has been proved here . So now we know that $\mathscr{G}(T)$  is dense in $H \times H$. Then $V\,\mathscr{G}(T)$ is also dense, where $V$ is given by $V\{a,b\}=\{-b,a\}$. According to theorem 13.8 we have $ \mathscr{G}(T^*) = [V\,\mathscr{G}(T)]^{\perp}. $ Since $V\,\mathscr{G}(T)$ is dense we have that $\mathscr{G}(T^*)$ must be the zero vector. Since $ \mathscr{G}(T^*) = \{\,\{x,T^*x\} : x \in \mathscr{D}(T^*)\}, $ we can conclude that $\mathscr{D}(T^*) = 0$ and $T^*x=0$, so that $T^*$ is the zero operator. I thought that I'm done here, however the original assignment has the remark: Once you have the correct idea and also realize that $\lim_{n \rightarrow \infty}(x,e_n)=0$ for all $x\in H$, the solution is almost immediate. If $y \in \mathscr{D}(T^*)$ then there exists a $T^*y \in H$ s.t. $ (Tx,y) = (x,T^*y) \qquad [x \in \mathscr{D}(T)] $ and $x \rightarrow (Tx,y)$ must be continuous in $x$. Letting $x=e_n$ we get $ (x_n,y) = (e_n,T^*y) $ then using the remark above we see that $(x_n,y) \rightarrow 0$. Using the continuity condition it follows that $\mathscr{D}(T^*)=\{0\}$. If this is correct it is just another way of proving the assignment. Am I missing something here?","For an assignment I have to show that exists a densely defined operator on a infinite dimensional separable Hilbert space, such that its adjoint is the zero operator on the zero subspace. To show this there is a reference to exercise 13.3 in the book Functional Analysis of Rudin. The exercise is as follows By theorem 13.8, $\mathscr{D}(T^*) =\{0\}$ for a densely defined operator $T$ in $H$ if and only if $\mathscr{G}(T)$ is dense in $H\times H$. Show that this can actually happen. Suggestion: Let $\{e_n:n=1,2,3, \dots\}$ be an orthonormal basis of $H$; let $\{x_n\}$ be a dense subset of $H$; define $Te_n=x_n$; and extend $T$ linearly to $\mathscr{D}(T)$, the set of all finite linear combinations of the basis vector $e_n$. Show that the graph of   this $T$ is dense in $H \times H$. The exercise has been proved here . So now we know that $\mathscr{G}(T)$  is dense in $H \times H$. Then $V\,\mathscr{G}(T)$ is also dense, where $V$ is given by $V\{a,b\}=\{-b,a\}$. According to theorem 13.8 we have $ \mathscr{G}(T^*) = [V\,\mathscr{G}(T)]^{\perp}. $ Since $V\,\mathscr{G}(T)$ is dense we have that $\mathscr{G}(T^*)$ must be the zero vector. Since $ \mathscr{G}(T^*) = \{\,\{x,T^*x\} : x \in \mathscr{D}(T^*)\}, $ we can conclude that $\mathscr{D}(T^*) = 0$ and $T^*x=0$, so that $T^*$ is the zero operator. I thought that I'm done here, however the original assignment has the remark: Once you have the correct idea and also realize that $\lim_{n \rightarrow \infty}(x,e_n)=0$ for all $x\in H$, the solution is almost immediate. If $y \in \mathscr{D}(T^*)$ then there exists a $T^*y \in H$ s.t. $ (Tx,y) = (x,T^*y) \qquad [x \in \mathscr{D}(T)] $ and $x \rightarrow (Tx,y)$ must be continuous in $x$. Letting $x=e_n$ we get $ (x_n,y) = (e_n,T^*y) $ then using the remark above we see that $(x_n,y) \rightarrow 0$. Using the continuity condition it follows that $\mathscr{D}(T^*)=\{0\}$. If this is correct it is just another way of proving the assignment. Am I missing something here?",,['functional-analysis']
24,Maximum of measures over sets and functions,Maximum of measures over sets and functions,,"Let $(X,\mathcal A)$ be any measurable space and denote by $\mathrm b\mathcal A_1$ the set of all real-valued $\mathcal A$-measurable functions $f$ satisfying $\|f\|:=\sup_{x\in X}|f(x)|\leq 1$. Let $P$ and $Q$ be two arbitrary families of probability measures on $(X,\mathcal A)$ and denote  $$   P^*f := \sup_{p\in P} \int_X f\,\mathrm dp $$  for any $f\in\mathrm b\mathcal A_1$, and similarly denote $Q^*$. Let for simplicity write $P^*(A) = P^*1_A$ for any $A\in \mathcal A$ where $1_A:X\to \{0,1\}$ is the indicator function of the set $A$.  Is that true that $$   Q^*f\leq P^*f \quad \forall f\in \mathrm b\mathcal A_1 \iff Q^*(A)\leq P^*(A) \quad \forall A\in \mathcal A. $$ The direction $\implies$ is obvious, however I'm not sure what about the other direction. I'd be also happy if you can suggest the source where similar properties of $P^*$ are considered. For what I know now, it shall be a capacity, but that's pretty much it.","Let $(X,\mathcal A)$ be any measurable space and denote by $\mathrm b\mathcal A_1$ the set of all real-valued $\mathcal A$-measurable functions $f$ satisfying $\|f\|:=\sup_{x\in X}|f(x)|\leq 1$. Let $P$ and $Q$ be two arbitrary families of probability measures on $(X,\mathcal A)$ and denote  $$   P^*f := \sup_{p\in P} \int_X f\,\mathrm dp $$  for any $f\in\mathrm b\mathcal A_1$, and similarly denote $Q^*$. Let for simplicity write $P^*(A) = P^*1_A$ for any $A\in \mathcal A$ where $1_A:X\to \{0,1\}$ is the indicator function of the set $A$.  Is that true that $$   Q^*f\leq P^*f \quad \forall f\in \mathrm b\mathcal A_1 \iff Q^*(A)\leq P^*(A) \quad \forall A\in \mathcal A. $$ The direction $\implies$ is obvious, however I'm not sure what about the other direction. I'd be also happy if you can suggest the source where similar properties of $P^*$ are considered. For what I know now, it shall be a capacity, but that's pretty much it.",,"['functional-analysis', 'measure-theory', 'probability-theory']"
25,An alternate proof of Fuglede's theorem,An alternate proof of Fuglede's theorem,,"To prove Fuglede's Theorem for normal operators on a separable Hilbert space, why does it suffice to show that $E(S_1)T E(S_2)=0$ for all disjoint Borel sets $S_1$ and $S_2$ , where $E$ is the spectral measure associated to the given normal operator $N$ ? Further, why is this true for $S_1$ and $S_2$ at a positive distance from one another, and how can an approximation by compact sets be used to prove it in the general case?","To prove Fuglede's Theorem for normal operators on a separable Hilbert space, why does it suffice to show that for all disjoint Borel sets and , where is the spectral measure associated to the given normal operator ? Further, why is this true for and at a positive distance from one another, and how can an approximation by compact sets be used to prove it in the general case?",E(S_1)T E(S_2)=0 S_1 S_2 E N S_1 S_2,"['functional-analysis', 'operator-theory', 'hilbert-spaces', 'spectral-theory']"
26,Why are $C(K)$-spaces $\mathcal{L}^{\infty}$-spaces?,Why are -spaces -spaces?,C(K) \mathcal{L}^{\infty},"Let me first recall the definition of an $\mathcal{L}^{\infty}$-space: A Banach space $X$ is called an $\mathcal{L}^{\infty}$-space if there is a net $(X_{\lambda})_{\lambda \in \Lambda}$ (directed by inclusion) of finite-dimensional subspaces such that each one is $(1+\varepsilon)$-isomorphic to some $\ell_{\infty}^{n}$ and $X = \overline{\bigcup X_{\lambda}}$. I am asking for a proof or reference to a proof that $C(K)$-spaces enjoy this property. A natural idea for a proof would be to consider a net of finite open covers of $K$, directed by refinement, and for every such cover take a subspace spanned by subordinate partition of unity. However, I don't have a clue how to choose ""compatible"" partitions of unity, i.e. that the subspace spanned by the one coming from finer cover actually contains the other one. I would be glad if someone just opened my eyes to see some obvious argument.","Let me first recall the definition of an $\mathcal{L}^{\infty}$-space: A Banach space $X$ is called an $\mathcal{L}^{\infty}$-space if there is a net $(X_{\lambda})_{\lambda \in \Lambda}$ (directed by inclusion) of finite-dimensional subspaces such that each one is $(1+\varepsilon)$-isomorphic to some $\ell_{\infty}^{n}$ and $X = \overline{\bigcup X_{\lambda}}$. I am asking for a proof or reference to a proof that $C(K)$-spaces enjoy this property. A natural idea for a proof would be to consider a net of finite open covers of $K$, directed by refinement, and for every such cover take a subspace spanned by subordinate partition of unity. However, I don't have a clue how to choose ""compatible"" partitions of unity, i.e. that the subspace spanned by the one coming from finer cover actually contains the other one. I would be glad if someone just opened my eyes to see some obvious argument.",,"['functional-analysis', 'banach-spaces']"
27,Derivative of Convex Functional,Derivative of Convex Functional,,"Suppose that $H$ is a real Hilbert space and that $f:H  \to \mathbb{R}$ is differentiable in the Frechet sense. Then we can think of the derivative as a function $f': H \to H^* = H$. Suppose that this function also has a continuous Frechet derivative $f'': H \to B(H)$. My question is now: is it true that $f$ is convex if and only if $f''(x)$ is a positive operator for all $x \in H$, i.e., that $\langle f''(x)y, y \rangle \geq 0$ for all $x,y \in H$? The question is motivated by the analogous case for $C^2$ functions $f: \mathbb{R} \to \mathbb{R}$, in which case $f$ is convex if and only if $f''(x) \geq 0$ for all $x \in \mathbb{R}$. Thanks in advance.","Suppose that $H$ is a real Hilbert space and that $f:H  \to \mathbb{R}$ is differentiable in the Frechet sense. Then we can think of the derivative as a function $f': H \to H^* = H$. Suppose that this function also has a continuous Frechet derivative $f'': H \to B(H)$. My question is now: is it true that $f$ is convex if and only if $f''(x)$ is a positive operator for all $x \in H$, i.e., that $\langle f''(x)y, y \rangle \geq 0$ for all $x,y \in H$? The question is motivated by the analogous case for $C^2$ functions $f: \mathbb{R} \to \mathbb{R}$, in which case $f$ is convex if and only if $f''(x) \geq 0$ for all $x \in \mathbb{R}$. Thanks in advance.",,['functional-analysis']
28,Modulus of Continuity,Modulus of Continuity,,"Let $\rho(t)$ be a function on the set $\mathbb{R}^+$ of nonnegative real numbers such that: $\rho$ is nondecreasing (and continuous - thanks for the correction) $\rho(t) = 0$ if and only if $t = 0$ Let $X$ be a metric space and let $f$ be a real valued function on $X$.  Say that $f$ has modulus of continuity $\rho$ if $|f(x) - f(y)| \leq \rho(d(x,y))$ for every $x$ and $y$ in $X$.  For example, a function is Lipschitz if and only if it has modulus of continuity $Ct$ for some positive real number $C$.  Observe that a function with modulus of continuity $\rho$ is necessarily continuous. Question: If $X$ is a compact metric space without isolated points, is it true that the set of all functions with modulus of continuity $\rho$ is nowhere dense (meaning its closure contains no open set) in $C(X)$ equipped with the supremum norm? I am a TA in a class in which it was claimed that the answer is yes, but I don't completely believe the proof given and I can't seem to find a correct argument except in special cases.  For example, one can show that the set of all Lipschitz functions on $[0,1]$ with Lipschitz constant $C$ is nowhere dense in $C[0,1]$ using the existence of piecewise linear functions of arbitrarily small norm whose linear pieces all have slope larger than $C$ (or smaller than -C).  So the idea for general $X$ should be to construct continuous functions of arbitrarily small norm with arbitrarily rapid oscillation, but I don't see how to do this. Thanks!","Let $\rho(t)$ be a function on the set $\mathbb{R}^+$ of nonnegative real numbers such that: $\rho$ is nondecreasing (and continuous - thanks for the correction) $\rho(t) = 0$ if and only if $t = 0$ Let $X$ be a metric space and let $f$ be a real valued function on $X$.  Say that $f$ has modulus of continuity $\rho$ if $|f(x) - f(y)| \leq \rho(d(x,y))$ for every $x$ and $y$ in $X$.  For example, a function is Lipschitz if and only if it has modulus of continuity $Ct$ for some positive real number $C$.  Observe that a function with modulus of continuity $\rho$ is necessarily continuous. Question: If $X$ is a compact metric space without isolated points, is it true that the set of all functions with modulus of continuity $\rho$ is nowhere dense (meaning its closure contains no open set) in $C(X)$ equipped with the supremum norm? I am a TA in a class in which it was claimed that the answer is yes, but I don't completely believe the proof given and I can't seem to find a correct argument except in special cases.  For example, one can show that the set of all Lipschitz functions on $[0,1]$ with Lipschitz constant $C$ is nowhere dense in $C[0,1]$ using the existence of piecewise linear functions of arbitrarily small norm whose linear pieces all have slope larger than $C$ (or smaller than -C).  So the idea for general $X$ should be to construct continuous functions of arbitrarily small norm with arbitrarily rapid oscillation, but I don't see how to do this. Thanks!",,"['functional-analysis', 'metric-spaces']"
29,Abelian sub-C*-algebras,Abelian sub-C*-algebras,,"Given a non-abelian C*-algebra $A$. I am wondering what are the possible abelian sub-C*-algebras of $A$. Let $K$ be the spectrum of $A$. Does $A$ contain an isomorphic copy (as a Banach space) of the space $C(K)$? (if $A$ is abelian and unital, then thay are of course isometrically indistinguishable). If the answer for my question is negative, let $L$ be a compact metric space. Must $A$ contain $C(L)$?","Given a non-abelian C*-algebra $A$. I am wondering what are the possible abelian sub-C*-algebras of $A$. Let $K$ be the spectrum of $A$. Does $A$ contain an isomorphic copy (as a Banach space) of the space $C(K)$? (if $A$ is abelian and unital, then thay are of course isometrically indistinguishable). If the answer for my question is negative, let $L$ be a compact metric space. Must $A$ contain $C(L)$?",,"['functional-analysis', 'banach-spaces', 'banach-algebras', 'c-star-algebras']"
30,Schauder fixed point theorem,Schauder fixed point theorem,,I am teaching a course in functional analysis and I would like to illustrate the Schauder fixed point theorem (just for Banach spaces) with some nice applications. One that comes to  my mind is the existence of solutions of ordinary differential equations. Applications to nonlinear PDEs would require too much knowledge. Question What are the elementary and nice applications of the Schauder fixed point theorem?,I am teaching a course in functional analysis and I would like to illustrate the Schauder fixed point theorem (just for Banach spaces) with some nice applications. One that comes to  my mind is the existence of solutions of ordinary differential equations. Applications to nonlinear PDEs would require too much knowledge. Question What are the elementary and nice applications of the Schauder fixed point theorem?,,"['functional-analysis', 'fixed-point-theorems']"
31,Solving $f(x)-f(x+\alpha)=g(x)$,Solving,f(x)-f(x+\alpha)=g(x),"Problem: Suppose $g:\mathbb{R} \to \mathbb{R}$ has period $1$ and is $\mathcal{C}^{\infty}$ . Let $\alpha \in \mathbb{R}$ . Consider the following equation: \begin{equation} f(x)-f(x+\alpha)=g(x) \end{equation} I am asked to: $1$ . Let $\alpha \in \mathbb{Q}$ . Find necessary and sufficient condition on $g$ such that the equation has a solution $\mathcal{C}^{\infty}$ with period $1$ . $2$ . Let $\alpha \in \mathbb{R} \smallsetminus \mathbb{Q}$ such that exist $\gamma >0$ and $\tau >0$ with $|\alpha - \frac{p}{q}|>\gamma q^{-2-\tau}$ for all $\frac{p}{q} \in \mathbb{Q}$ , $q \geq 1$ . Find necessary and sufficient condition on $g$ such that the equation has a solution $\mathcal{C}^{\infty}$ with period $1$ $3$ . Prove that the set of $\alpha$ of the second point has to measure $0$ in $\mathbb{R}$ . Attempt: If we define $$\tau_{\alpha}f(x)=f(x-\alpha)   \space \text{for}\space f:\mathbb{R} \to \mathbb{R}$$ then we would study $(\mathbb{I}-\tau_{-\alpha})f=g$ and a necessary condition for the first point is that $$\sum_{j=0}^kg(x+j\alpha)=0$$ where $k$ is such that $k\alpha \in \mathbb{Z}$ .","Problem: Suppose has period and is . Let . Consider the following equation: I am asked to: . Let . Find necessary and sufficient condition on such that the equation has a solution with period . . Let such that exist and with for all , . Find necessary and sufficient condition on such that the equation has a solution with period . Prove that the set of of the second point has to measure in . Attempt: If we define then we would study and a necessary condition for the first point is that where is such that .","g:\mathbb{R} \to \mathbb{R} 1 \mathcal{C}^{\infty} \alpha \in \mathbb{R} \begin{equation}
f(x)-f(x+\alpha)=g(x)
\end{equation} 1 \alpha \in \mathbb{Q} g \mathcal{C}^{\infty} 1 2 \alpha \in \mathbb{R} \smallsetminus \mathbb{Q} \gamma >0 \tau >0 |\alpha - \frac{p}{q}|>\gamma q^{-2-\tau} \frac{p}{q} \in \mathbb{Q} q \geq 1 g \mathcal{C}^{\infty} 1 3 \alpha 0 \mathbb{R} \tau_{\alpha}f(x)=f(x-\alpha) 
 \space \text{for}\space f:\mathbb{R} \to \mathbb{R} (\mathbb{I}-\tau_{-\alpha})f=g \sum_{j=0}^kg(x+j\alpha)=0 k k\alpha \in \mathbb{Z}","['functional-analysis', 'analysis', 'functions']"
32,"Solving the wave equation, with boundary conditions, in the sense of distributions (Generalized functions)","Solving the wave equation, with boundary conditions, in the sense of distributions (Generalized functions)",,"After learning some distribution theory, I find that in my book, all PDEs given as examples are in free space (without any boundary conditions). I wonder if distribution theory can be used to tackle PDEs with boundary conditions. To be more specific, let's consider this problem. Let there be a string of length $\pi$ with both ends fixed. Transverse waves can be produced on the string, satisfying the classical wave equation $$ \partial^2_t u(x,t)=c^2\partial^2_x u(x,t). $$ The boundary conditions are $u(0)=u(\pi)=0$ . Now, let impose a wired initial condition: let's pluck the string in the middle, so initially, the string is at rest, in the position $$ u(x,0)=A(\pi/2-|x-\pi/2|), A\in \mathbb R. $$ As one can see, the initial condition is not everywhere differentiable. However, $u$ can be seen as an element of $\mathcal D'(\mathbb R)$ or $\mathcal S'(\mathbb R)$ , the space of (tempered) distributions. The differential equation therefore make sense in the sense of distributions. Using Fourier transform and convolution, we can manage to get a solution, IF there are no boundary conditions. However, in this situation, I do not know how to state the boundary condition in term of distributions. So, my question now is: can we make sense out of this problem, possibly in the sense of distributions, and solve the equation? Edit: we can use Fourier series expansion to solve this, but then I don't feel it really a way of ""understanding"" how it really works - after all, the original equation ceases to make sense when it is not differentiable. I want to somehow have some formalism in making sense of the derivative of a function which is not differentiable. Possibly weak derivative? Edit: Fourier transform over a bounded interval doesn't seem to be obvious to define; it appears that Fourier series are really easier.","After learning some distribution theory, I find that in my book, all PDEs given as examples are in free space (without any boundary conditions). I wonder if distribution theory can be used to tackle PDEs with boundary conditions. To be more specific, let's consider this problem. Let there be a string of length with both ends fixed. Transverse waves can be produced on the string, satisfying the classical wave equation The boundary conditions are . Now, let impose a wired initial condition: let's pluck the string in the middle, so initially, the string is at rest, in the position As one can see, the initial condition is not everywhere differentiable. However, can be seen as an element of or , the space of (tempered) distributions. The differential equation therefore make sense in the sense of distributions. Using Fourier transform and convolution, we can manage to get a solution, IF there are no boundary conditions. However, in this situation, I do not know how to state the boundary condition in term of distributions. So, my question now is: can we make sense out of this problem, possibly in the sense of distributions, and solve the equation? Edit: we can use Fourier series expansion to solve this, but then I don't feel it really a way of ""understanding"" how it really works - after all, the original equation ceases to make sense when it is not differentiable. I want to somehow have some formalism in making sense of the derivative of a function which is not differentiable. Possibly weak derivative? Edit: Fourier transform over a bounded interval doesn't seem to be obvious to define; it appears that Fourier series are really easier.","\pi 
\partial^2_t u(x,t)=c^2\partial^2_x u(x,t).
 u(0)=u(\pi)=0 
u(x,0)=A(\pi/2-|x-\pi/2|), A\in \mathbb R.
 u \mathcal D'(\mathbb R) \mathcal S'(\mathbb R)","['functional-analysis', 'partial-differential-equations', 'fourier-transform', 'distribution-theory', 'wave-equation']"
33,Heat semigroup norm between fractional Sobolev and $L^p$ spaces,Heat semigroup norm between fractional Sobolev and  spaces,L^p,"What is the actual inequality that holds for the heat semigroup between fractional Sobolev space $W^{2\alpha,p}$ and classical Lebesgue space $L^q$ ? I am trying to derive an inequality $$ \lvert\lvert e^{t\Delta}f  \rvert\rvert_{W^{2\alpha,p}} \leq \frac{C}{t^\beta}  \lvert\lvert f  \rvert\rvert_{L^q} $$ but i cannot manage to find the right value of $\beta$ . I am trying to write the heat semigroup as a convolution $$ e^{t\Delta}f = K_t*f $$ where $K_t$ is the heat kernel, and use Holder inequality for convolutions, but I am stuck when computing $$ \lvert\lvert (I-\Delta)^\alpha K_t  \rvert\rvert_{L^r}  $$ where $\frac{1}{q}+\frac{1}{r} = \frac{1}{p}+1$ . Any help is appreciated.","What is the actual inequality that holds for the heat semigroup between fractional Sobolev space and classical Lebesgue space ? I am trying to derive an inequality but i cannot manage to find the right value of . I am trying to write the heat semigroup as a convolution where is the heat kernel, and use Holder inequality for convolutions, but I am stuck when computing where . Any help is appreciated.","W^{2\alpha,p} L^q 
\lvert\lvert e^{t\Delta}f  \rvert\rvert_{W^{2\alpha,p}} \leq \frac{C}{t^\beta} 
\lvert\lvert f  \rvert\rvert_{L^q}  \beta  e^{t\Delta}f = K_t*f  K_t  \lvert\lvert (I-\Delta)^\alpha K_t  \rvert\rvert_{L^r}   \frac{1}{q}+\frac{1}{r} = \frac{1}{p}+1","['functional-analysis', 'semigroup-of-operators', 'fractional-sobolev-spaces']"
34,"Can $\{1, x^2, x^3, x^4, ...\}$ approximate $x$ on $[0,1]$?",Can  approximate  on ?,"\{1, x^2, x^3, x^4, ...\} x [0,1]","Can $\{1, x^2, x^3, x^4, ...\}$ approximate $x$ on $[0,1]$ ? Here is an attempt: Let $\mathcal{A}$ be the linear span of our set $\{x^0, x^2, x^3, x^4, ...\}$ . $\mathcal{A}$ is a vector subspace and separates points. It is also a subalgebra since $\sum_{i \neq 1}^{n} a_i x^i \times \sum_{i \neq 1}^{m} b_i x^i $ does not generate any $x^1$ term. $[0,1]$ is compact, and $x^0 = 1 \in \mathcal{A}$ . By the Stone-Weierstrass theorem, $\mathcal{A} = C([0,1])$ . Conclude that our initial set can approximate $x$ . This is my first time using the Stone-Weierstrass theorem and I think I made a mistake, since the same argument goes through for all sets of the form $\{1, x^k, x^{k+1}, x^{k+2}, ...\}$ or say polynomials with even powers. It also seems to contradict the fact that the $\{1, x, x^2, ... \}$ form a basis in $L^2([0,1])$ . Any help will be greatly appreciated!","Can approximate on ? Here is an attempt: Let be the linear span of our set . is a vector subspace and separates points. It is also a subalgebra since does not generate any term. is compact, and . By the Stone-Weierstrass theorem, . Conclude that our initial set can approximate . This is my first time using the Stone-Weierstrass theorem and I think I made a mistake, since the same argument goes through for all sets of the form or say polynomials with even powers. It also seems to contradict the fact that the form a basis in . Any help will be greatly appreciated!","\{1, x^2, x^3, x^4, ...\} x [0,1] \mathcal{A} \{x^0, x^2, x^3, x^4, ...\} \mathcal{A} \sum_{i \neq 1}^{n} a_i x^i \times \sum_{i \neq 1}^{m} b_i x^i  x^1 [0,1] x^0 = 1 \in \mathcal{A} \mathcal{A} = C([0,1]) x \{1, x^k, x^{k+1}, x^{k+2}, ...\} \{1, x, x^2, ... \} L^2([0,1])",['functional-analysis']
35,"If $X^{(n)},X$ are càdlàg and $X^{(n)}\to X$ in distribution, do the corresponding transition semigroups strongly converge?","If  are càdlàg and  in distribution, do the corresponding transition semigroups strongly converge?","X^{(n)},X X^{(n)}\to X","Let $\left(\kappa^{(n)}_t\right)_{t\ge0}$ and $(\kappa_t)_{t\ge0}$ be Markov semigroups on $(\mathbb R,\mathcal B(\mathbb R))$ for $n\in\mathbb N$ $(T_n(t))_{t\ge0}$ and $(T(t))_{t\ge0}$ be strongly continuous contraction semigroups on $C_0(\mathbb R)$ (continuous functions $\mathbb R\to\mathbb R$ vanishing at infinity equipped with the supremum norm) with $$T_n(t)f=\int\kappa^{(n)}_t(\;\cdot\;,{\rm d}y)f(y)\tag1$$ and $$T(t)f=\int\kappa_t(\;\cdot\;,{\rm d}y)f(y)\tag2$$ for all $f\in C_0(\mathbb R)$ and $t\ge0$ $X^{(n)}$ and $X$ be real-valued càdlàg Markov processes with transition semigroups $\left(\kappa^{(n)}_t\right)_{t\ge0}$ and $(\kappa_t)_{t\ge0}$ , respectively, for $n\in\mathbb N$ Assume $$X^{(n)}_0\xrightarrow{n\to\infty}X_0\tag3$$ in distribution and $$X^{(n)}\xrightarrow{n\to\infty}X\tag4$$ in distribution (with respect to the Skorohod topology). Are we able to conclude $$\left\|T_n(t)f-T(t)f\right\|_\infty\xrightarrow{n\to\infty}0\tag5$$ for all $f\in C_0(\mathbb R)$ and $t\ge0$ ? The desired claim is part of the following theorem in the book of Kallenberg, but I don't understand his proof: Relevant part of the proof: EDIT : What's bothering me most: Why are we allowed to assume $X_0=x$ and $X^n_0=x_n$ ? Can the general case somehow be reduced to that case? I don't know how he's arguing that $X$ is almost surely continuous at $t$ . Is this really true? In any case, if we assume that $X$ is almost surely continuous, it is at least clear to me that $(T_n(t)f)(x_n)\xrightarrow{n\to\infty}(T(t)f)(x)$ for all $(x_n)_{n\in\mathbb N}\subseteq\mathbb R$ and $x\in\mathbb R$ with $x_n\xrightarrow{n\to\infty}x$ and $t\ge0$ . But why is that sufficient for $(5)$ ?","Let and be Markov semigroups on for and be strongly continuous contraction semigroups on (continuous functions vanishing at infinity equipped with the supremum norm) with and for all and and be real-valued càdlàg Markov processes with transition semigroups and , respectively, for Assume in distribution and in distribution (with respect to the Skorohod topology). Are we able to conclude for all and ? The desired claim is part of the following theorem in the book of Kallenberg, but I don't understand his proof: Relevant part of the proof: EDIT : What's bothering me most: Why are we allowed to assume and ? Can the general case somehow be reduced to that case? I don't know how he's arguing that is almost surely continuous at . Is this really true? In any case, if we assume that is almost surely continuous, it is at least clear to me that for all and with and . But why is that sufficient for ?","\left(\kappa^{(n)}_t\right)_{t\ge0} (\kappa_t)_{t\ge0} (\mathbb R,\mathcal B(\mathbb R)) n\in\mathbb N (T_n(t))_{t\ge0} (T(t))_{t\ge0} C_0(\mathbb R) \mathbb R\to\mathbb R T_n(t)f=\int\kappa^{(n)}_t(\;\cdot\;,{\rm d}y)f(y)\tag1 T(t)f=\int\kappa_t(\;\cdot\;,{\rm d}y)f(y)\tag2 f\in C_0(\mathbb R) t\ge0 X^{(n)} X \left(\kappa^{(n)}_t\right)_{t\ge0} (\kappa_t)_{t\ge0} n\in\mathbb N X^{(n)}_0\xrightarrow{n\to\infty}X_0\tag3 X^{(n)}\xrightarrow{n\to\infty}X\tag4 \left\|T_n(t)f-T(t)f\right\|_\infty\xrightarrow{n\to\infty}0\tag5 f\in C_0(\mathbb R) t\ge0 X_0=x X^n_0=x_n X t X (T_n(t)f)(x_n)\xrightarrow{n\to\infty}(T(t)f)(x) (x_n)_{n\in\mathbb N}\subseteq\mathbb R x\in\mathbb R x_n\xrightarrow{n\to\infty}x t\ge0 (5)","['functional-analysis', 'probability-theory', 'operator-theory', 'markov-process', 'semigroup-of-operators']"
36,Compactness criterion for operator between reflexive Banach spaces,Compactness criterion for operator between reflexive Banach spaces,,"I found (without any proof) the following proposition: Let $T \in \mathcal{L}(X,Y)$ be a linear continuous operator between two reflexive Banach spaces $X,Y$, then $T$ is compact if and only if for every sequence $\left(x_n\right)_{n\in\mathbb{N}} \subseteq X$ weakly converging to $0$ and for every sequence $\left(y^*_n\right)_{n\in\mathbb{N}} \subseteq Y^*$ weakly-$*$ converging to $0$ it turns out that $\left< y^*_n,T x_n \right> \to 0$ I already know that: If $X$ is reflexive then $T$ is compact if and only if for every every sequence $\left(x_n\right)_{n\in\mathbb{N}} \subseteq X$ weakly converging to $0$ the sequence $\left(T x_n\right)_{n\in\mathbb{N}}$ converges strongly in $Y$. I tried to prove that given $\left( y_n \right) \subseteq Y$ (with $Y$ reflexive) that converges weakly to $0$ if for every $\left( y^*_n \right) \subseteq Y^*$ that converges weakly-$*$ to zero it turns out that $\left< y^*_n, y_n \right> \to 0$ then $y_n \to 0$ strongly, but without success. So I have a couple of questions: Q1: is my last proposition true? Can we infer strong convergence from the weak one and with this ""dual tests""? Q2: how can I prove the original proposition?","I found (without any proof) the following proposition: Let $T \in \mathcal{L}(X,Y)$ be a linear continuous operator between two reflexive Banach spaces $X,Y$, then $T$ is compact if and only if for every sequence $\left(x_n\right)_{n\in\mathbb{N}} \subseteq X$ weakly converging to $0$ and for every sequence $\left(y^*_n\right)_{n\in\mathbb{N}} \subseteq Y^*$ weakly-$*$ converging to $0$ it turns out that $\left< y^*_n,T x_n \right> \to 0$ I already know that: If $X$ is reflexive then $T$ is compact if and only if for every every sequence $\left(x_n\right)_{n\in\mathbb{N}} \subseteq X$ weakly converging to $0$ the sequence $\left(T x_n\right)_{n\in\mathbb{N}}$ converges strongly in $Y$. I tried to prove that given $\left( y_n \right) \subseteq Y$ (with $Y$ reflexive) that converges weakly to $0$ if for every $\left( y^*_n \right) \subseteq Y^*$ that converges weakly-$*$ to zero it turns out that $\left< y^*_n, y_n \right> \to 0$ then $y_n \to 0$ strongly, but without success. So I have a couple of questions: Q1: is my last proposition true? Can we infer strong convergence from the weak one and with this ""dual tests""? Q2: how can I prove the original proposition?",,"['functional-analysis', 'banach-spaces', 'compact-operators', 'reflexive-space']"
37,Proof that every bounded linear operator between hilbert spaces has an adjoint.,Proof that every bounded linear operator between hilbert spaces has an adjoint.,,"As a practice exercises(not an assignment question) for one of the papers I am doing currently at university we are asked to show the following; I $T:H \rightarrow K$ is a bounded linear operator from between two Hilbert spaces. Show that there exists a unique bounded linear operator $T^*:K\rightarrow H$ such that $$ \langle Th,k\rangle = \langle h,T^*k \rangle\ \ \ \ \forall h\in H,\ \ \forall k\in K. $$ Uniqueness is easy, for if there existed $S,P \in \mathcal{L}(K,H)$ satisfying this property then we would have $$ \langle h, Pk-Sk\rangle =0 \ \ \ \ \forall h \in H \ \ \ k\in K $$ in particular for $Pk -Sk \in H$ we would have $$ \langle Pk-Sk, Pk-Sk\rangle = 0 \ \ \ \forall k\in K $$ which means $Pk= Sk$ for all $k\in K$ so they are the same. Proof of existence We start by fixing $k \in K$. Now we define the linear functional $L_k : H \rightarrow \mathbb{F}$ by $$ L_k(h) := \langle Th,k \rangle, \ \ \ \  h \in H $$ ($L_k$ is linear by linearity of $T$ and linearity of inner products and bounded by Cauchy-Schwarz.) Now by the Riesz - Representation Theorem we know there exists a unique $v \in H$ such that $$ L_k(h) = \langle h,v \rangle , \ \ \ \ \  \forall h \in H. $$ Notice that the $k \in K$ that we fixed was arbitrary so for each $k \in K$ there exists a unique $v_k \in H$ such that $$ \langle Th,k\rangle = L_k(h) = \langle h,v_k \rangle , \ \ \ \ \  \forall h \in H. $$ Now we define the function $T^* :K \rightarrow H$ where $$ T^* (k) := v_k, \ \ \ \ k \in K. $$ Now we claim that $T^*$ is linear and bounded. We start by showing that $T^*$ is linear. So we fix $k,g \in K$ and $\lambda \in \mathbb{F}$, the case where $k = g = 0$ is trivial so we assume $k,g \neq 0$, then we need to show that $$ T^*(\lambda k +g) = \lambda T^*k +T^*g. $$ Or by the uniqueness of $T^*(k)$ for all $k \in H$ it is enough to show show that $$ \langle Th,\lambda k +g \rangle = \langle h, \lambda T^*k +T^*g \rangle, \ \ \ \ \forall h \in H $$ Now for arbitrary $h \in H$ we have $$ \langle Th, \lambda k +g \rangle = \bar{\lambda}\langle Th,k \rangle + \langle Th,g \rangle = \langle h, \lambda T^*k\rangle +\langle h, T^*g \rangle = \langle h, \lambda T^*k +T^*g \rangle $$ as needed for linearity. Now for boundedness we notice for $k \in K$, (the case where $k = 0$ is trivial so we may assume $ k \neq 0$) $$ ||T^*k||^2 = \langle T^*k,T^*k \rangle = \langle k , T(T^*k) \rangle \leq ||k||\ ||T(T^*k) || \leq ||k||\ ||T||_{\text{op}}\ || T^*k || $$ By simple rearranging it follows that $$ ||T^*k|| \leq ||T||_{\text{op}}\ ||k||. $$ As a bonus we also notice that the from infemum characterization of the operator it follows that $$ ||T^*||_{\text{op}}\leq ||T||_{\text{op}}. $$ QED","As a practice exercises(not an assignment question) for one of the papers I am doing currently at university we are asked to show the following; I $T:H \rightarrow K$ is a bounded linear operator from between two Hilbert spaces. Show that there exists a unique bounded linear operator $T^*:K\rightarrow H$ such that $$ \langle Th,k\rangle = \langle h,T^*k \rangle\ \ \ \ \forall h\in H,\ \ \forall k\in K. $$ Uniqueness is easy, for if there existed $S,P \in \mathcal{L}(K,H)$ satisfying this property then we would have $$ \langle h, Pk-Sk\rangle =0 \ \ \ \ \forall h \in H \ \ \ k\in K $$ in particular for $Pk -Sk \in H$ we would have $$ \langle Pk-Sk, Pk-Sk\rangle = 0 \ \ \ \forall k\in K $$ which means $Pk= Sk$ for all $k\in K$ so they are the same. Proof of existence We start by fixing $k \in K$. Now we define the linear functional $L_k : H \rightarrow \mathbb{F}$ by $$ L_k(h) := \langle Th,k \rangle, \ \ \ \  h \in H $$ ($L_k$ is linear by linearity of $T$ and linearity of inner products and bounded by Cauchy-Schwarz.) Now by the Riesz - Representation Theorem we know there exists a unique $v \in H$ such that $$ L_k(h) = \langle h,v \rangle , \ \ \ \ \  \forall h \in H. $$ Notice that the $k \in K$ that we fixed was arbitrary so for each $k \in K$ there exists a unique $v_k \in H$ such that $$ \langle Th,k\rangle = L_k(h) = \langle h,v_k \rangle , \ \ \ \ \  \forall h \in H. $$ Now we define the function $T^* :K \rightarrow H$ where $$ T^* (k) := v_k, \ \ \ \ k \in K. $$ Now we claim that $T^*$ is linear and bounded. We start by showing that $T^*$ is linear. So we fix $k,g \in K$ and $\lambda \in \mathbb{F}$, the case where $k = g = 0$ is trivial so we assume $k,g \neq 0$, then we need to show that $$ T^*(\lambda k +g) = \lambda T^*k +T^*g. $$ Or by the uniqueness of $T^*(k)$ for all $k \in H$ it is enough to show show that $$ \langle Th,\lambda k +g \rangle = \langle h, \lambda T^*k +T^*g \rangle, \ \ \ \ \forall h \in H $$ Now for arbitrary $h \in H$ we have $$ \langle Th, \lambda k +g \rangle = \bar{\lambda}\langle Th,k \rangle + \langle Th,g \rangle = \langle h, \lambda T^*k\rangle +\langle h, T^*g \rangle = \langle h, \lambda T^*k +T^*g \rangle $$ as needed for linearity. Now for boundedness we notice for $k \in K$, (the case where $k = 0$ is trivial so we may assume $ k \neq 0$) $$ ||T^*k||^2 = \langle T^*k,T^*k \rangle = \langle k , T(T^*k) \rangle \leq ||k||\ ||T(T^*k) || \leq ||k||\ ||T||_{\text{op}}\ || T^*k || $$ By simple rearranging it follows that $$ ||T^*k|| \leq ||T||_{\text{op}}\ ||k||. $$ As a bonus we also notice that the from infemum characterization of the operator it follows that $$ ||T^*||_{\text{op}}\leq ||T||_{\text{op}}. $$ QED",,"['functional-analysis', 'linear-transformations', 'hilbert-spaces', 'adjoint-operators']"
38,Manifold Galerkin method,Manifold Galerkin method,,"Standard Galerkin method reduces the problem Find $u\in V$ such that $a(u,v) = f(v)$ for all $v \in V$,     where $V$ is Hilbert space, $a$ is bilinear form and $f\in V^*$. to a finite dimensional problem by introducing a $n$-dimensional subspace $V_n\subset V$, then we look for an approximation $u_n$ of the solution $u$ such that Find $u_n \in V_n$ such that $a(u_n,v) = f(v)$ for all $v \in V_n$. I would like to replace $V_n$ by a $n$-dimensional manifold $\mathcal{M}_n$ in $V$. So the reduced problem would be Find $u_n\in \mathcal{M}_n$ such that $a(u_n,v)=f(v)$ for all $v\in T_{u_n}\mathcal{M}_n$, where $T_{u_n}\mathcal{M}_n$ is tangent space to the manifold $\mathcal{M}_n$ at the point $u_n$. What do we know about this problem? What are the conditions on $\mathcal{M}_n$ for existence of $u_n$? Does $u_n$ converge to $u$ as we make $\mathcal{M}_n$ bigger and bigger ($n\rightarrow \infty$)? What is this method called?(I called it Manifold Galerkin method ) Can you please point me to the literature where they discuss this problem?","Standard Galerkin method reduces the problem Find $u\in V$ such that $a(u,v) = f(v)$ for all $v \in V$,     where $V$ is Hilbert space, $a$ is bilinear form and $f\in V^*$. to a finite dimensional problem by introducing a $n$-dimensional subspace $V_n\subset V$, then we look for an approximation $u_n$ of the solution $u$ such that Find $u_n \in V_n$ such that $a(u_n,v) = f(v)$ for all $v \in V_n$. I would like to replace $V_n$ by a $n$-dimensional manifold $\mathcal{M}_n$ in $V$. So the reduced problem would be Find $u_n\in \mathcal{M}_n$ such that $a(u_n,v)=f(v)$ for all $v\in T_{u_n}\mathcal{M}_n$, where $T_{u_n}\mathcal{M}_n$ is tangent space to the manifold $\mathcal{M}_n$ at the point $u_n$. What do we know about this problem? What are the conditions on $\mathcal{M}_n$ for existence of $u_n$? Does $u_n$ converge to $u$ as we make $\mathcal{M}_n$ bigger and bigger ($n\rightarrow \infty$)? What is this method called?(I called it Manifold Galerkin method ) Can you please point me to the literature where they discuss this problem?",,"['functional-analysis', 'reference-request', 'partial-differential-equations', 'numerical-methods', 'galerkin-methods']"
39,$\sigma$-algebra generated by weak topology in Hilbert Space,-algebra generated by weak topology in Hilbert Space,\sigma,"In general, if we have $H$ Hilbert space, and equipped with the weak topology, say $\tau^\ast$, is $\sigma(\tau^*)=\mathcal{B}$?, where $\mathcal{B}$ is the usual Borel $\sigma$-algebra I suspect it is. By definition, $\tau^*$ is the minimum topology for which elements of $H^\prime(=H)$ are continuous. Then, $\sigma(\tau^*)\subseteq\mathcal{B}$. But for the other inclusion, do you have any hint?","In general, if we have $H$ Hilbert space, and equipped with the weak topology, say $\tau^\ast$, is $\sigma(\tau^*)=\mathcal{B}$?, where $\mathcal{B}$ is the usual Borel $\sigma$-algebra I suspect it is. By definition, $\tau^*$ is the minimum topology for which elements of $H^\prime(=H)$ are continuous. Then, $\sigma(\tau^*)\subseteq\mathcal{B}$. But for the other inclusion, do you have any hint?",,"['functional-analysis', 'measure-theory', 'hilbert-spaces']"
40,Prove that the norm of a linear transformation satisfies the inequality $\|Tx\| \leq M\|x\|$ for all $x$. [duplicate],Prove that the norm of a linear transformation satisfies the inequality  for all . [duplicate],\|Tx\| \leq M\|x\| x,"This question already has an answer here : Proof that $\|fx\| \leq \|f\|\cdot\|x\|$ (1 answer) Closed 6 years ago . Proof. Let $T$ be a bounded linear operator. Then $$\|T\|=\sup_{x\neq 0}\frac{\|Tx\|}{\|x\|}$$ So $\|T\| \geq \frac{\|Tx\|}{\|x\|}$, that is, $\|T\|\cdot\|x\|\geq \|Tx\|$. I'm not understand if I let $M=\|T\|$. Is this proof correct?","This question already has an answer here : Proof that $\|fx\| \leq \|f\|\cdot\|x\|$ (1 answer) Closed 6 years ago . Proof. Let $T$ be a bounded linear operator. Then $$\|T\|=\sup_{x\neq 0}\frac{\|Tx\|}{\|x\|}$$ So $\|T\| \geq \frac{\|Tx\|}{\|x\|}$, that is, $\|T\|\cdot\|x\|\geq \|Tx\|$. I'm not understand if I let $M=\|T\|$. Is this proof correct?",,"['functional-analysis', 'linear-transformations', 'normed-spaces']"
41,Does this sequence of operators converge in norm or strongly?,Does this sequence of operators converge in norm or strongly?,,"Let $H$ be a Hilbert space and $\mathcal{L}(H)$ the set of all bounded linear operators $L:H\to H$, equiped with the usual norm $\|\cdot\|_{\mathcal{L}}$. Let $T:D(T)\subset H\to H$ be a densely-defined linear operator and $(\lambda_n)$ a sequence in $\rho(T)$ (the resolvent set of $T$). Suppose that there exists $\lambda\in\rho(T)$ such that $\lambda_n\to \lambda$. What is it possible to conclude about the sequence $(S_n)$ of bounded linear operators given by $$S_n=(\lambda_nI-T)^{-1}?$$ Is it possible to prove that $\|S_n-(\lambda I-T)^{-1}\|_{\mathcal{L}}\to 0$? Is it possible to prove that $\|S_nx-(\lambda I-T)^{-1}x\|_H\to 0$ for all $x\in H$? Thanks.","Let $H$ be a Hilbert space and $\mathcal{L}(H)$ the set of all bounded linear operators $L:H\to H$, equiped with the usual norm $\|\cdot\|_{\mathcal{L}}$. Let $T:D(T)\subset H\to H$ be a densely-defined linear operator and $(\lambda_n)$ a sequence in $\rho(T)$ (the resolvent set of $T$). Suppose that there exists $\lambda\in\rho(T)$ such that $\lambda_n\to \lambda$. What is it possible to conclude about the sequence $(S_n)$ of bounded linear operators given by $$S_n=(\lambda_nI-T)^{-1}?$$ Is it possible to prove that $\|S_n-(\lambda I-T)^{-1}\|_{\mathcal{L}}\to 0$? Is it possible to prove that $\|S_nx-(\lambda I-T)^{-1}x\|_H\to 0$ for all $x\in H$? Thanks.",,"['functional-analysis', 'convergence-divergence', 'operator-theory', 'hilbert-spaces']"
42,"Problem 21 - Trotter theorem , Reed and Simon","Problem 21 - Trotter theorem , Reed and Simon",,"This problem if from Methods of modern mathematical physics I :Functional Analysis , by Reed and Simon: Problem 21: Let $\{A_n\}$ be a sequence of selfadjoint operators on a Hilbert space $H$, and let $A$ be a selfadjoint (not necessarily bounded) operator on $H$. Show that if $A_n \to A$ in the strong resolvent sense, then  $$ \mathrm{e}^{itA_n}x \to \mathrm{e}^{itA}x $$  uniformly for $t$ in any finite interval. I would be grateful for showing that this convergence is locally uniform in $t$.","This problem if from Methods of modern mathematical physics I :Functional Analysis , by Reed and Simon: Problem 21: Let $\{A_n\}$ be a sequence of selfadjoint operators on a Hilbert space $H$, and let $A$ be a selfadjoint (not necessarily bounded) operator on $H$. Show that if $A_n \to A$ in the strong resolvent sense, then  $$ \mathrm{e}^{itA_n}x \to \mathrm{e}^{itA}x $$  uniformly for $t$ in any finite interval. I would be grateful for showing that this convergence is locally uniform in $t$.",,"['functional-analysis', 'operator-theory', 'uniform-convergence', 'semigroup-of-operators']"
43,Physical interpretation of C* property,Physical interpretation of C* property,,"From a mathematical point of view, quantum mechanics can be formulated in the language of a non-commutative, unital C*-algebra $\mathcal A$ (of observables). In this context, what does the C*-property $$\vert\vert A^*A \vert\vert = \vert\vert A \vert\vert^2 \qquad \forall A \in  \mathcal A$$ mean from a physical point of view, i.e. which physical oberservation is modeled by requiring this property?","From a mathematical point of view, quantum mechanics can be formulated in the language of a non-commutative, unital C*-algebra $\mathcal A$ (of observables). In this context, what does the C*-property $$\vert\vert A^*A \vert\vert = \vert\vert A \vert\vert^2 \qquad \forall A \in  \mathcal A$$ mean from a physical point of view, i.e. which physical oberservation is modeled by requiring this property?",,"['functional-analysis', 'c-star-algebras']"
44,"If $X^*$ is isomorphic to $Y^*$, what do we know about $X$ and $Y$?","If  is isomorphic to , what do we know about  and ?",X^* Y^* X Y,"Suppose $X$ and $Y$ are Banach spaces with duals $X^*$ and $Y^*$. If we know $X^*$ and $Y^*$ are isomorphic, what can we say about $X$ and $Y$? One trivial thing is that they can be isometrically embedded into the same Banach space $X^{**}$. Another is that they can be isometrically embedded into the same $C(S)$, where $S$ is a compact Hausdorff space. But I am guessing much more can be implied about $X$ and $Y$? Am I right? Thanks!","Suppose $X$ and $Y$ are Banach spaces with duals $X^*$ and $Y^*$. If we know $X^*$ and $Y^*$ are isomorphic, what can we say about $X$ and $Y$? One trivial thing is that they can be isometrically embedded into the same Banach space $X^{**}$. Another is that they can be isometrically embedded into the same $C(S)$, where $S$ is a compact Hausdorff space. But I am guessing much more can be implied about $X$ and $Y$? Am I right? Thanks!",,"['functional-analysis', 'banach-spaces']"
45,Defining $A+B$ for self-adjoint operators $A$ and $B$?,Defining  for self-adjoint operators  and ?,A+B A B,"Consider the following observations: If $A$ and $B$ are bounded operators on a Banach space over $\mathbb{C}$ , then the Lie product formula implies that $$ e^{it(A+B)} = \lim_{n\to\infty} (e^{itA/n}e^{itB/n})^n. \tag{1} $$ This then allows to extract $A+B$ from the limit in the right-hand side: $$ A + B = \frac{1}{i}\left( \frac{\mathrm{d}}{\mathrm{d}t}\biggr|_{t=0} \right) \lim_{n\to\infty} (e^{itA/n}e^{itB/n})^n. \tag{2} $$ Now, let $A$ and $B$ be self-adjoint operators defined on dense subsets $\mathrm{Dom}(A)$ and $\mathrm{Dom}(B)$ of a Hilbert space $\mathcal{H}$ , respectively. Then a version of Trotter product formula tells that, if $\mathrm{Dom}(A) \cap \mathrm{Dom}(B)$ is dense and $A+B$ is essentially self-adjoint on $\mathrm{Dom}(A) \cap \mathrm{Dom}(B)$ , then the equality $\text{(1)}$ holds in the strong operator topology. These led me to the following question: Question. Is it possible that $A+B$ , as an operator defined on $\mathrm{Dom}(A) \cap \mathrm{Dom}(B)$ , is not essentially self-adjoint, but $A+B$ can still be defined as a self-adjoint operator via the formula $\text{(2)}$ ? If the answer is negative, does it mean that the RHS of $\text{(1)}$ diverges (or does not define a strongly continuous one-parameter unitary group) whenever $A+B$ is not essentially self-adjoint? The formula $\text{(1)}$ is less affected from the ""densely-definedness"" issue of self-adjoint operators. So I am curious whether this small advantage actually makes any differences and possibly opens up more rooms for defining $A+B$ or not. Unfortunately, I have only tangential knowledge on functional analysis and operator theory, which means that I don't have any good intuition regarding this question. I am fairly certain that this kind of question has been already examined by many people, so the fact that I can't seem to find any reference is likely because there are some serious obstructions in this approach (or I am too clumsy at googling 😔). Some Attempts. I tried this question with $\mathcal{H} = L^2[0, 1]$ , $A = -\frac{\mathrm{d}^2}{\mathrm{d}x^2}$ , and $B = -\frac{\mathrm{d}^2}{\mathrm{d}x^2}$ with the respective domains $$\mathrm{Dom}(A) = \{f \in H^2[0, 1] : f(0) = f(1) = 0\}$$ and $$\mathrm{Dom}(B) = \{f \in H^2[0, 1] : f'(0) = f'(1) = 0\}.$$ Then $A + B$ defined on the intersection of their respective domains is not essentially self-adjoint, since both $2A$ and $2B$ are self-adjoint extensions of $A+B$ . I tried simulating the RHS of $\text{(1)}$ numerically, and the results seem suggesting that the limit is convergent. However, I am not sure whether this is an artifact of the numerical scheme I adopted or not.","Consider the following observations: If and are bounded operators on a Banach space over , then the Lie product formula implies that This then allows to extract from the limit in the right-hand side: Now, let and be self-adjoint operators defined on dense subsets and of a Hilbert space , respectively. Then a version of Trotter product formula tells that, if is dense and is essentially self-adjoint on , then the equality holds in the strong operator topology. These led me to the following question: Question. Is it possible that , as an operator defined on , is not essentially self-adjoint, but can still be defined as a self-adjoint operator via the formula ? If the answer is negative, does it mean that the RHS of diverges (or does not define a strongly continuous one-parameter unitary group) whenever is not essentially self-adjoint? The formula is less affected from the ""densely-definedness"" issue of self-adjoint operators. So I am curious whether this small advantage actually makes any differences and possibly opens up more rooms for defining or not. Unfortunately, I have only tangential knowledge on functional analysis and operator theory, which means that I don't have any good intuition regarding this question. I am fairly certain that this kind of question has been already examined by many people, so the fact that I can't seem to find any reference is likely because there are some serious obstructions in this approach (or I am too clumsy at googling 😔). Some Attempts. I tried this question with , , and with the respective domains and Then defined on the intersection of their respective domains is not essentially self-adjoint, since both and are self-adjoint extensions of . I tried simulating the RHS of numerically, and the results seem suggesting that the limit is convergent. However, I am not sure whether this is an artifact of the numerical scheme I adopted or not.","A B \mathbb{C}  e^{it(A+B)} = \lim_{n\to\infty} (e^{itA/n}e^{itB/n})^n. \tag{1}  A+B  A + B = \frac{1}{i}\left( \frac{\mathrm{d}}{\mathrm{d}t}\biggr|_{t=0} \right) \lim_{n\to\infty} (e^{itA/n}e^{itB/n})^n. \tag{2}  A B \mathrm{Dom}(A) \mathrm{Dom}(B) \mathcal{H} \mathrm{Dom}(A) \cap \mathrm{Dom}(B) A+B \mathrm{Dom}(A) \cap \mathrm{Dom}(B) \text{(1)} A+B \mathrm{Dom}(A) \cap \mathrm{Dom}(B) A+B \text{(2)} \text{(1)} A+B \text{(1)} A+B \mathcal{H} = L^2[0, 1] A = -\frac{\mathrm{d}^2}{\mathrm{d}x^2} B = -\frac{\mathrm{d}^2}{\mathrm{d}x^2} \mathrm{Dom}(A) = \{f \in H^2[0, 1] : f(0) = f(1) = 0\} \mathrm{Dom}(B) = \{f \in H^2[0, 1] : f'(0) = f'(1) = 0\}. A + B 2A 2B A+B \text{(1)}","['functional-analysis', 'operator-theory', 'self-adjoint-operators']"
46,Dominated convergence theorem for Banach space,Dominated convergence theorem for Banach space,,"I'm trying to prove dominated convergence theorem for Banach space. Could you verify if my proof is fine or contains some subtle mistakes? Let $(f_n)$ be a sequence in $\mathcal L_0 (X, \mu, E)$ . Suppose that there exists $g \in \mathcal L_1 (X, \mu, E)$ such that $|f_n| \le |g|$ $\mu$ -a.e. for all $n$ . Suppose also that, for some $f \in E^X$ , $f_n \to f$ $\mu$ -a.e. Then $f_n,f \in \mathcal L_1 (X, \mu, E)$ for all $n$ , $f_n \to f$ in $\mathcal L_1 (X, \mu, E)$ , and $\int_X f_n \mathrm d \mu \to \int_X f \mathrm d \mu$ in $E$ . First, we recall related definitions. Let $(X, \mathcal A, \mu)$ be a $\sigma$ -finite measure space and $(E, | \cdot |)$ a Banach space. A function $f \in E^{X}$ is called $\mu$ - simple if $f = \sum_{k=1}^n e_k 1_{A_k}$ where $0 \neq e_k \in E$ and $(A_k)_{k=1}^n$ is a finite sequence of pairwise disjoint sets with finite measure in $\mathcal A$ . The integral of such $f$ w.r.t. $\mu$ is defined by $\int_{X} f \mathrm d \mu := \sum_{k=1}^n e_k \mu(A_k)$ . Let $\mathcal S (X, \mu, E)$ be the space of such $\mu$ -simple functions. We define $\| \cdot \|_1 : \mathcal S (X, \mu, E) \to \mathbb R$ by $f \mapsto \int_{X} |f| \mathrm d \mu$ . Then $\| \cdot \|_1$ is a semi-norm on $\mathcal S (X, \mu, E)$ . The notion of Cauchy sequence is thus applicable for $(\mathcal S (X, \mu, E), \| \cdot \|_1)$ . A function $f \in E^{X}$ is called $\mu$ - measurable if $f$ is a $\mu$ -a.e. limit of a sequence $(f_n)$ in $\mathcal S (X, \mu, E)$ .  Let $\mathcal L_0 (X, \mu, E)$ be the space of such $\mu$ -measurable functions. A function $f \in E^{X}$ is called $\mu$ - integrable if $f$ is $\mu$ -a.e. limit of a Cauchy sequence $(f_n)$ in $\mathcal S (X, \mu, E)$ . The integral of such $f$ w.r.t. $\mu$ is defined by $\int_{X} f \mathrm d \mu := \lim_n \int_{X} f_n \mathrm d \mu$ . We also define the semi-norm $\| f\|_1 :=  \int_{X} |f| \mathrm d \mu$ . Let $\mathcal L_1 (X, \mu, E)$ be the space of such $\mu$ -integrable functions. Then $\big (\mathcal L_1 (X, \mu, E), \| \cdot \|_1 \big )$ is complete. Also, $\mathcal S (X, \mu, E)$ is dense in $\mathcal L_1 (X, \mu, E)$ w.r.t. $\| \cdot \|_1$ . Proof: First, we assume $f_n \in \mathcal L_1 (X, \mu, E)$ for all $n$ . Let $0 \le g_n := \sup_{i,j \ge n} |f_i - f_j| \le 2 |g|$ . Then $(g_n)$ is a non-increasing sequence in $\mathcal L_0 (X, \mu, \mathbb R^+)$ that converges to $0$ $\mu$ -a.e. By ""reverse"" Fatou's lemma, $$0 \le \limsup_n \int_X g_n \mathrm d \mu \le \int_X \limsup_n g_n \mathrm d \mu = 0.$$ It follows that $\int_X g_n \mathrm d \mu \to 0$ in $\mathbb R^+$ . For all $i, j \ge n$ , $$\|f_i -f_j \|_1 = \int_X |f_i - f_j| \mathrm d \mu \le \int_X  g_{n} \mathrm d \mu.$$ Hence $(f_n)$ is a Cauchy sequence in $\mathcal L_1 (X, \mu, E)$ which is complete. Then $f_n$ converges to some $\hat f$ in $\mathcal L_1 (X, \mu, E)$ . Second, we will show that there is a subsequence $(f_{\varphi(\ell)})$ of $(f_n)$ such that $f_{\varphi(\ell)} \to \hat f$ $\mu$ -a.e as $\ell \to \infty$ . It suffices to assume $\hat f =0$ , because, if $\hat f \neq 0$ , we can consider the sequence $(f_n - \hat f)$ . There is a subsequence $\varphi$ of $(n)$ such that $\|f_i-f_j\|_1 \le 2^{-2\ell}$ for $i,j \ge \varphi(\ell)$ . Let $h_\ell :=f_{\varphi(\ell)}$ . Then $\|h_\ell - h_m\|_1 \le 2^{-2\ell}$ for $m \ge \ell$ . Take the limit $m \to \infty$ , we get $\|h_\ell\|_1 \le 2^{-2\ell}$ . Let $B_\ell := \{ x\in X \mid |h_\ell (x)| \ge 2^{-\ell} \}, A_n := \cup_{\ell \ge n} B_\ell$ , and $A := \cap A_n$ . Then $\mu(B_\ell) \le 2^{-\ell}$ for $\ell \in \mathbb N$ , $\mu(A_n) \le 2^{-n+1}$ for $n \in \mathbb N$ , and $\mu(A) =0$ . Then $(h_\ell)$ converges to $0$ uniformly on each $A_n^c$ and pointwise on $A^c$ . On the other hand, $f_n \to f$ $\mu$ -a.e., so does $(f_{\varphi(\ell)})$ . Hence $f = \hat f$ $\mu$ -a.e. and thus $f_n$ converges to $f$ in $\mathcal L_1 (X, \mu, E)$ . Next we have $$\left |\int_X f_n \mathrm d \mu - \int_X f \mathrm d \mu \right | = \left | \int_X (f_n - f) \mathrm d \mu \right | \le \int_X |f_n - f| \mathrm d \mu = \|f_n -f\|_1 \to 0.$$ Next we're going to prove $f_n \in \mathcal L_1 (X, \mu, E)$ . It suffices to prove for $n=0$ . Let $\left(\varphi_{n}\right)$ be a sequence in $\mathcal{S}(X, \mu, E)$ such that $\varphi_{n} \to f_0$ $\mu$ -a.e. Let $A_{n}:= \{x \in X \mid \left|\varphi_{n}(x)\right| \le |g(x)| \}$ and $g_{n} := 1_{A_{n}} \varphi_{n}$ for $n \in \mathbb N$ . Then $\left(g_{n}\right)$ is a sequence in $\mathcal{S}(X, \mu, E) \subseteq \mathcal{L}_1(X, \mu, E)$ that converges $\mu$ -a.e. to $f_0$ . Because $\left|g_{n}\right| \le g$ for $n \in \mathbb{N}$ , the claim follows from result proved above. This completes the proof. Update: I have found that the proof of $f_n \in \mathcal L_1 (X, \mu, E)$ is more subtle than I thought. Below is a proper treatment. Next we're going to prove $f_n \in \mathcal L_1 (X, \mu, E)$ . It suffices to prove for $n=0$ . Let $\left(\varphi_{n}\right)$ be a sequence in $\mathcal{S}(X, \mu, E)$ such that $\varphi_{n} \to f_0$ $\mu$ -a.e. Let $A_{n}:= \{x \in X \mid \left|\varphi_{n}(x)\right| \le 2 |g(x)| \}$ and $g_{n} := 1_{A_{n}} \varphi_{n}$ for $n \in \mathbb N$ . Then $\left(g_{n}\right)$ is a sequence in $\mathcal{S}(X, \mu, E) \subseteq \mathcal{L}_1(X, \mu, E)$ . Let's prove that $(g_n)$ converges $\mu$ -a.e. to $f_0$ . Let $A$ be a null set such that $\varphi_n (x) \to f_0 (x)$ for all $x \in A^c$ . Let $B$ be a null set such that $|f_0 (x)| \le |g(x)|$ for $x \in B^c$ . Also, $C := A \cup B$ and $D := \{x \in X | g (x) \neq 0 \}$ . Then $C$ is also a null set. For each $x \in C^c \cap D$ , there is $N \in \mathbb N$ such that $|\varphi_n(x) - f_0 (x)| \le |g(x)|$ and thus $|\varphi_n(x)| \le |f_0 (x)| + |g(x)| \le 2 |g(x)|$ and thus $x \in A_n$ for $n \ge N$ . This means $g_n (x) = \varphi_n (x) \to f_0(x)$ for $x \in C^c \cap D$ . For $x \in C^c \cap D^c$ , $g(x) = f_0(x) = 0$ and thus $|g_n (x) - f_0(x)| = |g_n(x)| = 1_{A_{n}} |\varphi_{n}| \le |\varphi_n(x)| \to 0$ and thus $g_n (x) \to f_0(x)$ . Hence $g_n \to f_0$ on $C^c$ . Because $\left|g_{n}\right| \le 2|g|$ for $n \in \mathbb{N}$ , the claim follows from result proved above. This completes the proof.","I'm trying to prove dominated convergence theorem for Banach space. Could you verify if my proof is fine or contains some subtle mistakes? Let be a sequence in . Suppose that there exists such that -a.e. for all . Suppose also that, for some , -a.e. Then for all , in , and in . First, we recall related definitions. Let be a -finite measure space and a Banach space. A function is called - simple if where and is a finite sequence of pairwise disjoint sets with finite measure in . The integral of such w.r.t. is defined by . Let be the space of such -simple functions. We define by . Then is a semi-norm on . The notion of Cauchy sequence is thus applicable for . A function is called - measurable if is a -a.e. limit of a sequence in .  Let be the space of such -measurable functions. A function is called - integrable if is -a.e. limit of a Cauchy sequence in . The integral of such w.r.t. is defined by . We also define the semi-norm . Let be the space of such -integrable functions. Then is complete. Also, is dense in w.r.t. . Proof: First, we assume for all . Let . Then is a non-increasing sequence in that converges to -a.e. By ""reverse"" Fatou's lemma, It follows that in . For all , Hence is a Cauchy sequence in which is complete. Then converges to some in . Second, we will show that there is a subsequence of such that -a.e as . It suffices to assume , because, if , we can consider the sequence . There is a subsequence of such that for . Let . Then for . Take the limit , we get . Let , and . Then for , for , and . Then converges to uniformly on each and pointwise on . On the other hand, -a.e., so does . Hence -a.e. and thus converges to in . Next we have Next we're going to prove . It suffices to prove for . Let be a sequence in such that -a.e. Let and for . Then is a sequence in that converges -a.e. to . Because for , the claim follows from result proved above. This completes the proof. Update: I have found that the proof of is more subtle than I thought. Below is a proper treatment. Next we're going to prove . It suffices to prove for . Let be a sequence in such that -a.e. Let and for . Then is a sequence in . Let's prove that converges -a.e. to . Let be a null set such that for all . Let be a null set such that for . Also, and . Then is also a null set. For each , there is such that and thus and thus for . This means for . For , and thus and thus . Hence on . Because for , the claim follows from result proved above. This completes the proof.","(f_n) \mathcal L_0 (X, \mu, E) g \in \mathcal L_1 (X, \mu, E) |f_n| \le |g| \mu n f \in E^X f_n \to f \mu f_n,f \in \mathcal L_1 (X, \mu, E) n f_n \to f \mathcal L_1 (X, \mu, E) \int_X f_n \mathrm d \mu \to \int_X f \mathrm d \mu E (X, \mathcal A, \mu) \sigma (E, | \cdot |) f \in E^{X} \mu f = \sum_{k=1}^n e_k 1_{A_k} 0 \neq e_k \in E (A_k)_{k=1}^n \mathcal A f \mu \int_{X} f \mathrm d \mu := \sum_{k=1}^n e_k \mu(A_k) \mathcal S (X, \mu, E) \mu \| \cdot \|_1 : \mathcal S (X, \mu, E) \to \mathbb R f \mapsto \int_{X} |f| \mathrm d \mu \| \cdot \|_1 \mathcal S (X, \mu, E) (\mathcal S (X, \mu, E), \| \cdot \|_1) f \in E^{X} \mu f \mu (f_n) \mathcal S (X, \mu, E) \mathcal L_0 (X, \mu, E) \mu f \in E^{X} \mu f \mu (f_n) \mathcal S (X, \mu, E) f \mu \int_{X} f \mathrm d \mu := \lim_n \int_{X} f_n \mathrm d \mu \| f\|_1 :=  \int_{X} |f| \mathrm d \mu \mathcal L_1 (X, \mu, E) \mu \big (\mathcal L_1 (X, \mu, E), \| \cdot \|_1 \big ) \mathcal S (X, \mu, E) \mathcal L_1 (X, \mu, E) \| \cdot \|_1 f_n \in \mathcal L_1 (X, \mu, E) n 0 \le g_n := \sup_{i,j \ge n} |f_i - f_j| \le 2 |g| (g_n) \mathcal L_0 (X, \mu, \mathbb R^+) 0 \mu 0 \le \limsup_n \int_X g_n \mathrm d \mu \le \int_X \limsup_n g_n \mathrm d \mu = 0. \int_X g_n \mathrm d \mu \to 0 \mathbb R^+ i, j \ge n \|f_i -f_j \|_1 = \int_X |f_i - f_j| \mathrm d \mu \le \int_X  g_{n} \mathrm d \mu. (f_n) \mathcal L_1 (X, \mu, E) f_n \hat f \mathcal L_1 (X, \mu, E) (f_{\varphi(\ell)}) (f_n) f_{\varphi(\ell)} \to \hat f \mu \ell \to \infty \hat f =0 \hat f \neq 0 (f_n - \hat f) \varphi (n) \|f_i-f_j\|_1 \le 2^{-2\ell} i,j \ge \varphi(\ell) h_\ell :=f_{\varphi(\ell)} \|h_\ell - h_m\|_1 \le 2^{-2\ell} m \ge \ell m \to \infty \|h_\ell\|_1 \le 2^{-2\ell} B_\ell := \{ x\in X \mid |h_\ell (x)| \ge 2^{-\ell} \}, A_n := \cup_{\ell \ge n} B_\ell A := \cap A_n \mu(B_\ell) \le 2^{-\ell} \ell \in \mathbb N \mu(A_n) \le 2^{-n+1} n \in \mathbb N \mu(A) =0 (h_\ell) 0 A_n^c A^c f_n \to f \mu (f_{\varphi(\ell)}) f = \hat f \mu f_n f \mathcal L_1 (X, \mu, E) \left |\int_X f_n \mathrm d \mu - \int_X f \mathrm d \mu \right | = \left | \int_X (f_n - f) \mathrm d \mu \right | \le \int_X |f_n - f| \mathrm d \mu = \|f_n -f\|_1 \to 0. f_n \in \mathcal L_1 (X, \mu, E) n=0 \left(\varphi_{n}\right) \mathcal{S}(X, \mu, E) \varphi_{n} \to f_0 \mu A_{n}:= \{x \in X \mid \left|\varphi_{n}(x)\right| \le |g(x)| \} g_{n} := 1_{A_{n}} \varphi_{n} n \in \mathbb N \left(g_{n}\right) \mathcal{S}(X, \mu, E) \subseteq \mathcal{L}_1(X, \mu, E) \mu f_0 \left|g_{n}\right| \le g n \in \mathbb{N} f_n \in \mathcal L_1 (X, \mu, E) f_n \in \mathcal L_1 (X, \mu, E) n=0 \left(\varphi_{n}\right) \mathcal{S}(X, \mu, E) \varphi_{n} \to f_0 \mu A_{n}:= \{x \in X \mid \left|\varphi_{n}(x)\right| \le 2 |g(x)| \} g_{n} := 1_{A_{n}} \varphi_{n} n \in \mathbb N \left(g_{n}\right) \mathcal{S}(X, \mu, E) \subseteq \mathcal{L}_1(X, \mu, E) (g_n) \mu f_0 A \varphi_n (x) \to f_0 (x) x \in A^c B |f_0 (x)| \le |g(x)| x \in B^c C := A \cup B D := \{x \in X | g (x) \neq 0 \} C x \in C^c \cap D N \in \mathbb N |\varphi_n(x) - f_0 (x)| \le |g(x)| |\varphi_n(x)| \le |f_0 (x)| + |g(x)| \le 2 |g(x)| x \in A_n n \ge N g_n (x) = \varphi_n (x) \to f_0(x) x \in C^c \cap D x \in C^c \cap D^c g(x) = f_0(x) = 0 |g_n (x) - f_0(x)| = |g_n(x)| = 1_{A_{n}} |\varphi_{n}| \le |\varphi_n(x)| \to 0 g_n (x) \to f_0(x) g_n \to f_0 C^c \left|g_{n}\right| \le 2|g| n \in \mathbb{N}","['functional-analysis', 'measure-theory', 'solution-verification', 'banach-spaces']"
47,Exactness of (full) group $C^*$-algebra,Exactness of (full) group -algebra,C^*,"Let $\Gamma$ be a discrete group. It is well known that if $\Gamma$ is amenable, then its full $C^*$ algebra $C^*(\Gamma)$ is exact. Moreover, if $\Gamma$ is residually finite then the converse also holds: if $C^*(\Gamma)$ is exact then $\Gamma$ is amenable (e.g. proposition 3.7.11. Brown-Ozawa "" $C^*$ -algebras and finite dimensional approximations""). Do we need to asumme that $\Gamma$ is residually finite? Or in other words, is there a discrete group $\Gamma$ which is not amenable but has exact full $C^*$ algebra $C^*(\Gamma)$ ?","Let be a discrete group. It is well known that if is amenable, then its full algebra is exact. Moreover, if is residually finite then the converse also holds: if is exact then is amenable (e.g. proposition 3.7.11. Brown-Ozawa "" -algebras and finite dimensional approximations""). Do we need to asumme that is residually finite? Or in other words, is there a discrete group which is not amenable but has exact full algebra ?",\Gamma \Gamma C^* C^*(\Gamma) \Gamma C^*(\Gamma) \Gamma C^* \Gamma \Gamma C^* C^*(\Gamma),"['functional-analysis', 'group-theory', 'operator-algebras', 'c-star-algebras']"
48,"$j(X)$ weak*-dense in $X^{**}$, $ j$ is the canonical embedding","weak*-dense in ,  is the canonical embedding",j(X) X^{**}  j,"Let $X$ be a Banach space and consider the canonical embedding in it's bidual $X^{**}$, namely $j:X\to X^{**}, \; x\mapsto j(x)$, where $j(x)(x^*)=x^*(x)$ for $x^*\in X^*$. My question: Why is $j(X)$ weak*-dense in $X^{**}$ for $X=l^1(G)$, where $G$ is a locally compact group (or is true for arbitrary Banach spaces $X$ as well)? (1) To prove this, for all $u\in X^{**}$ one has to find a sequence $(v_n)_n\subseteq j(X)$ such that $v_n(x^*)\to u(x^*)$ for all $x^*\in X^*$, and $v_n=j(x_n)$ for a $x_n\in X$ (since $(v_n)_n\subseteq j(X)$ ). I only know Goldstine ( https://en.wikipedia.org/wiki/Goldstine_theorem ):If $B\subseteq X$ is the closed unit ball, then $j(B)$ is weak*-dense in $B^{**}$, where $B^{**}$ is the closed unit ball in $X^{**}$. So, in the case $\|u\|_{op}>1$, is it possible to consider $\hat{u_n}:=\frac{1}{\|u\|_{op}}u_n$ and reduce to Goldstine, so that (1) is true? Or how to justify (1)?","Let $X$ be a Banach space and consider the canonical embedding in it's bidual $X^{**}$, namely $j:X\to X^{**}, \; x\mapsto j(x)$, where $j(x)(x^*)=x^*(x)$ for $x^*\in X^*$. My question: Why is $j(X)$ weak*-dense in $X^{**}$ for $X=l^1(G)$, where $G$ is a locally compact group (or is true for arbitrary Banach spaces $X$ as well)? (1) To prove this, for all $u\in X^{**}$ one has to find a sequence $(v_n)_n\subseteq j(X)$ such that $v_n(x^*)\to u(x^*)$ for all $x^*\in X^*$, and $v_n=j(x_n)$ for a $x_n\in X$ (since $(v_n)_n\subseteq j(X)$ ). I only know Goldstine ( https://en.wikipedia.org/wiki/Goldstine_theorem ):If $B\subseteq X$ is the closed unit ball, then $j(B)$ is weak*-dense in $B^{**}$, where $B^{**}$ is the closed unit ball in $X^{**}$. So, in the case $\|u\|_{op}>1$, is it possible to consider $\hat{u_n}:=\frac{1}{\|u\|_{op}}u_n$ and reduce to Goldstine, so that (1) is true? Or how to justify (1)?",,"['functional-analysis', 'banach-spaces', 'topological-vector-spaces']"
49,renorm a Banach space to make an operator have spectral radius equal to norm,renorm a Banach space to make an operator have spectral radius equal to norm,,"Let $X$ be an infinite-dimensional complex Banach space equipped with the norm $\lVert\cdot\rVert$, and let $T\in\mathcal{L}(X)$ a bounded linear operator on $X$.  Let $r(T)$ denote the spectral radius of $T$, and suppose $r(T)<\lVert T\rVert$.  I would like to renorm $X$ with an equivalent norm $|\cdot|$ so that $r(T)=|T|$, i.e. so that the spectral radius attains the operator norm. It is already known that we can equivalently renorm $X$ so that the spectral radius almost attains the norm.  Let $\epsilon>0$ be arbitrary and let $m$ be the smallest integer so that $\lVert T^m\rVert^{1/m}<r(T)+\epsilon$.  Then we can define the equivalent norm $|\cdot|_{T,\epsilon}$ on $X$ by $\displaystyle |x|_{T,\epsilon}:=\left[\lVert x\rVert^2+\left(\frac{\lVert Tx\rVert}{r(T)+\epsilon}\right)^2+\left(\frac{\lVert T^2x\rVert}{[r(T)+\epsilon]^2}\right)^2+\cdots+\left(\frac{\lVert T^mx\rVert}{[r(T)+\epsilon]^m}\right)^2\right]^{1/2}$ In this case, $|T|_{T,\epsilon}<r(T)+\epsilon$.  However, this is not good enough for my purposes.  We need equality, not almost-equality. In general, what I want need not be possible, for instance if $T$ is a nonzero quasinilpotent operator.  However, this problem arises in a context where I can make some powerful assumptions.  In particular, I have a situation where $0<r(T)$ with $\sigma(T)$ uncountable, $0\in\partial\sigma(T)$, and $\partial\sigma(T)\subseteq\sigma_p(T)$, where $\sigma(T)$ denotes the spectrum and $\sigma_p(T)$ the point spectrum, and $\partial$ denotes the topological boundary.  I can also assume that $\sigma_p(T^*)=\emptyset$, where $T^*\in\mathcal{L}(X^*)$ is the continuous dual of $T$. At least sometimes, what I want really is possible.  For instance let $(\delta_n)$ be a strictly decreasing sequence of positive reals with $\prod_{n=1}^\infty(1+\delta_n)<\infty$, and let $T\in\mathcal{L}(c_0)$ be the weighted left-shift operator defined by $Te_1=0$ and $Te_{n+1}=(1+\delta_n)e_n$, where $(e_n)$ is the unit vector basis for $c_0$, and $c_0$ (as usual) is the space of scalar sequences tending to zero equipped with the sup norm.  Then it's easy to see that $1=r(T)<1+\delta_1=\lVert T\rVert$.  Now, let $U\in\mathcal{L}(c_0)$ be the isomorphism $Ue_n=(1+\delta_n)e_n$, and define $|\cdot|$ by $|x|:=\lVert U^{-1}x\rVert$.  Then $|\cdot|$ is an equivalent norm with $r(T)=|T|=1$. Has this problem been studied at all? Please note, I am also free to ""adjust"" $X$ by modding out finite-dimensional subspaces.  More precisely, if $F$ is a finite-dimensional subspace of $X$ then I can replace $X$ with $W\cong X/F$, where $X=W\oplus F$ and $T$ with the corresponding induced operator $P_WT|_W$ (where $P_W$ is the continuous linear projection onto $W$ along $F$).","Let $X$ be an infinite-dimensional complex Banach space equipped with the norm $\lVert\cdot\rVert$, and let $T\in\mathcal{L}(X)$ a bounded linear operator on $X$.  Let $r(T)$ denote the spectral radius of $T$, and suppose $r(T)<\lVert T\rVert$.  I would like to renorm $X$ with an equivalent norm $|\cdot|$ so that $r(T)=|T|$, i.e. so that the spectral radius attains the operator norm. It is already known that we can equivalently renorm $X$ so that the spectral radius almost attains the norm.  Let $\epsilon>0$ be arbitrary and let $m$ be the smallest integer so that $\lVert T^m\rVert^{1/m}<r(T)+\epsilon$.  Then we can define the equivalent norm $|\cdot|_{T,\epsilon}$ on $X$ by $\displaystyle |x|_{T,\epsilon}:=\left[\lVert x\rVert^2+\left(\frac{\lVert Tx\rVert}{r(T)+\epsilon}\right)^2+\left(\frac{\lVert T^2x\rVert}{[r(T)+\epsilon]^2}\right)^2+\cdots+\left(\frac{\lVert T^mx\rVert}{[r(T)+\epsilon]^m}\right)^2\right]^{1/2}$ In this case, $|T|_{T,\epsilon}<r(T)+\epsilon$.  However, this is not good enough for my purposes.  We need equality, not almost-equality. In general, what I want need not be possible, for instance if $T$ is a nonzero quasinilpotent operator.  However, this problem arises in a context where I can make some powerful assumptions.  In particular, I have a situation where $0<r(T)$ with $\sigma(T)$ uncountable, $0\in\partial\sigma(T)$, and $\partial\sigma(T)\subseteq\sigma_p(T)$, where $\sigma(T)$ denotes the spectrum and $\sigma_p(T)$ the point spectrum, and $\partial$ denotes the topological boundary.  I can also assume that $\sigma_p(T^*)=\emptyset$, where $T^*\in\mathcal{L}(X^*)$ is the continuous dual of $T$. At least sometimes, what I want really is possible.  For instance let $(\delta_n)$ be a strictly decreasing sequence of positive reals with $\prod_{n=1}^\infty(1+\delta_n)<\infty$, and let $T\in\mathcal{L}(c_0)$ be the weighted left-shift operator defined by $Te_1=0$ and $Te_{n+1}=(1+\delta_n)e_n$, where $(e_n)$ is the unit vector basis for $c_0$, and $c_0$ (as usual) is the space of scalar sequences tending to zero equipped with the sup norm.  Then it's easy to see that $1=r(T)<1+\delta_1=\lVert T\rVert$.  Now, let $U\in\mathcal{L}(c_0)$ be the isomorphism $Ue_n=(1+\delta_n)e_n$, and define $|\cdot|$ by $|x|:=\lVert U^{-1}x\rVert$.  Then $|\cdot|$ is an equivalent norm with $r(T)=|T|=1$. Has this problem been studied at all? Please note, I am also free to ""adjust"" $X$ by modding out finite-dimensional subspaces.  More precisely, if $F$ is a finite-dimensional subspace of $X$ then I can replace $X$ with $W\cong X/F$, where $X=W\oplus F$ and $T$ with the corresponding induced operator $P_WT|_W$ (where $P_W$ is the continuous linear projection onto $W$ along $F$).",,"['functional-analysis', 'operator-theory', 'banach-spaces', 'normed-spaces', 'spectral-theory']"
50,Textbook for functional analysis in the style of Amann/Escher,Textbook for functional analysis in the style of Amann/Escher,,"Most textbooks I've seen so far are not concise enough for my taste and try to give way too much motivation. Or they're written with a too large focus on applications... Rudin wasn't bad contentwise, but the layout tells you it was 1991... An example for a perfect textbook in my eyes would be the Analysis series of Amann/Escher (I have the German editions and assume the English ones aren't essentially different). They go into depth, don't babble around and are yet as general as possible in their definitions and proofs, without having one lose focus. The structure is very clear, too and beautifully built up. Is there some textbook like this about functional analysis?","Most textbooks I've seen so far are not concise enough for my taste and try to give way too much motivation. Or they're written with a too large focus on applications... Rudin wasn't bad contentwise, but the layout tells you it was 1991... An example for a perfect textbook in my eyes would be the Analysis series of Amann/Escher (I have the German editions and assume the English ones aren't essentially different). They go into depth, don't babble around and are yet as general as possible in their definitions and proofs, without having one lose focus. The structure is very clear, too and beautifully built up. Is there some textbook like this about functional analysis?",,"['functional-analysis', 'reference-request', 'book-recommendation']"
51,Relations between spectrum and quadratic forms in the unbounded case,Relations between spectrum and quadratic forms in the unbounded case,,"Let $H$ be a complex Hilbert space. If $B$ is a bounded self-adjoint operator on $H$ then its spectrum is a closed and bounded subset of the real line and we can find its extremes in terms of the quadratic form $(B\psi, \psi)$ : $$\min (\sigma(B))=\inf_{\psi \in H} \frac{(B\psi, \psi)}{\lVert \psi\rVert^2}, \quad \max(\sigma(B))=\sup_{\psi \in H} \frac{(B\psi, \psi)}{\lVert \psi\rVert^2}$$ (cf. Brézis, Functional analysis, Sobolev spaces and PDE , §6.4, Proposition 6.9, p. 165 - link ) Question 1 . Does this extend to the unbounded case ? Specifically, I think it is true that, given a self-adjoint operator $A\colon D(A)\subset H \to H$ , we have $$\inf (\sigma(A))=\inf_{\psi \in D(A)} \frac{(A\psi, \psi)}{\lVert \psi\rVert^2}, \quad \sup(\sigma(A))=\sup_{\psi \in D(A)} \frac{(A\psi, \psi)}{\lVert \psi\rVert^2};$$ where of course we allow for infinite inf's and sup's. Question 2 . If the answer to 1. is affirmative, can we replace $$\inf_{\psi \in D(A)} \frac{(A\psi, \psi)}{\lVert \psi\rVert^2} \quad \text{and}\quad \sup_{\psi \in D(A)} \frac{(A\psi, \psi)}{\lVert \psi\rVert^2}$$ with $$\inf_{\psi \in D} \frac{(A\psi, \psi)}{\lVert \psi\rVert^2} \quad \text{and}\quad \sup_{\psi \in D} \frac{(A\psi, \psi)}{\lVert \psi\rVert^2}$$ where $D\subset D(A)$ is a dense subset? I guess that we cannot unless $D$ is a core for $A$ , that is a domain of essential self-adjointness. Thank you.","Let be a complex Hilbert space. If is a bounded self-adjoint operator on then its spectrum is a closed and bounded subset of the real line and we can find its extremes in terms of the quadratic form : (cf. Brézis, Functional analysis, Sobolev spaces and PDE , §6.4, Proposition 6.9, p. 165 - link ) Question 1 . Does this extend to the unbounded case ? Specifically, I think it is true that, given a self-adjoint operator , we have where of course we allow for infinite inf's and sup's. Question 2 . If the answer to 1. is affirmative, can we replace with where is a dense subset? I guess that we cannot unless is a core for , that is a domain of essential self-adjointness. Thank you.","H B H (B\psi, \psi) \min (\sigma(B))=\inf_{\psi \in H} \frac{(B\psi, \psi)}{\lVert \psi\rVert^2}, \quad \max(\sigma(B))=\sup_{\psi \in H} \frac{(B\psi, \psi)}{\lVert \psi\rVert^2} A\colon D(A)\subset H \to H \inf (\sigma(A))=\inf_{\psi \in D(A)} \frac{(A\psi, \psi)}{\lVert \psi\rVert^2}, \quad \sup(\sigma(A))=\sup_{\psi \in D(A)} \frac{(A\psi, \psi)}{\lVert \psi\rVert^2}; \inf_{\psi \in D(A)} \frac{(A\psi, \psi)}{\lVert \psi\rVert^2} \quad \text{and}\quad \sup_{\psi \in D(A)} \frac{(A\psi, \psi)}{\lVert \psi\rVert^2} \inf_{\psi \in D} \frac{(A\psi, \psi)}{\lVert \psi\rVert^2} \quad \text{and}\quad \sup_{\psi \in D} \frac{(A\psi, \psi)}{\lVert \psi\rVert^2} D\subset D(A) D A","['functional-analysis', 'hilbert-spaces', 'operator-theory', 'spectral-theory']"
52,Complemented Banach spaces.,Complemented Banach spaces.,,"Let $X$ be  Banach space and $Y$ a closed subspace of $X$. Assume that there exist a closed ""subset"" $Z$ of $X$ with the properties: $Z\cap Y=\{0\}$ and every $x\in X$  can be written in a unique form as $x=y+z$ with $y\in Y$ and $z\in Z$ Can we conclude that $Y$ is complemented in $X$? Edit: I'm not asking if $Z$ is a complement of $Y$ in $X$. Indeed, $Z$ does not need to be linear. What I am asking is if we can find a set closed linear $W\subset X$ such that $W$ is a complement of $Y$ in $X$.","Let $X$ be  Banach space and $Y$ a closed subspace of $X$. Assume that there exist a closed ""subset"" $Z$ of $X$ with the properties: $Z\cap Y=\{0\}$ and every $x\in X$  can be written in a unique form as $x=y+z$ with $y\in Y$ and $z\in Z$ Can we conclude that $Y$ is complemented in $X$? Edit: I'm not asking if $Z$ is a complement of $Y$ in $X$. Indeed, $Z$ does not need to be linear. What I am asking is if we can find a set closed linear $W\subset X$ such that $W$ is a complement of $Y$ in $X$.",,"['functional-analysis', 'banach-spaces']"
53,"How should I understand ""$A$ unless $B$""?","How should I understand "" unless ""?",A B,"The statement is from the book Linear Integral Equations by Rainer Kress: A compact operator cannot have a bounded inverse unless its range has finite dimension. Here are my questions : How should I understand the word ""unless"" here? If one interprets the statement in the form of $A\rightarrow B$, what should be $A$ and $B$ respectively? Is there an operator such that its range has finite dimension, but it does not have a bounded inverse? There can be two cases for ""not have a bounded inverse"": It does not have inverse. It has an inverse but the inverse is unbounded. For the first question, I think  we can translate a statement of the form ""$P$ unless $Q$"" as ""if not $Q$, then $P$"", or: $\neg Q → P$, according to this note for formal logic. But I'm not sure if the ""unless"" above is the same as the one here, which is the very reason why I ask the second question.","The statement is from the book Linear Integral Equations by Rainer Kress: A compact operator cannot have a bounded inverse unless its range has finite dimension. Here are my questions : How should I understand the word ""unless"" here? If one interprets the statement in the form of $A\rightarrow B$, what should be $A$ and $B$ respectively? Is there an operator such that its range has finite dimension, but it does not have a bounded inverse? There can be two cases for ""not have a bounded inverse"": It does not have inverse. It has an inverse but the inverse is unbounded. For the first question, I think  we can translate a statement of the form ""$P$ unless $Q$"" as ""if not $Q$, then $P$"", or: $\neg Q → P$, according to this note for formal logic. But I'm not sure if the ""unless"" above is the same as the one here, which is the very reason why I ask the second question.",,['functional-analysis']
54,"A weakly convergent sequence in a compact set, is strongly convegnet","A weakly convergent sequence in a compact set, is strongly convegnet",,"Let $E$ be a Banach space, and $K \subset E$ , compact set for the strong topology. And let $(x_n)_n$ converges for the weak topology $\sigma(E,E^*)$ to $x$ . Why $(x_n)_n$ converges for the strong topology ? My idea : Since $K$ is a compact set for the norm topology then $(x_n)_n$ has a convergent subsequence $(x_{n_k})_k$ for the norm topology to $x$ (Since $(x_{n_k})_k$ converges weakly to x). How to prove that the sequence $(x_n)_n$ converges strongly to $x$ ? I'm stuck in going from Since $(x_{n_k})_k$ converges weakly to x. then $(x_{n_k})_k$ to Since $(x_{n_k})_k$ converges weakly to x. then $(x_{n})_n$ .","Let be a Banach space, and , compact set for the strong topology. And let converges for the weak topology to . Why converges for the strong topology ? My idea : Since is a compact set for the norm topology then has a convergent subsequence for the norm topology to (Since converges weakly to x). How to prove that the sequence converges strongly to ? I'm stuck in going from Since converges weakly to x. then to Since converges weakly to x. then .","E K \subset E (x_n)_n \sigma(E,E^*) x (x_n)_n K (x_n)_n (x_{n_k})_k x (x_{n_k})_k (x_n)_n x (x_{n_k})_k (x_{n_k})_k (x_{n_k})_k (x_{n})_n","['functional-analysis', 'weak-convergence', 'weak-topology']"
55,Does there exists any non trivial linear metric space in which every open ball is not convex?,Does there exists any non trivial linear metric space in which every open ball is not convex?,,"$\Bbb{R^\omega}=\{(x_n)_{n\in \mathbb{N}}: x_n \in \Bbb{R}\}$ $d(x, y) =\sum_{j\in\mathbb{N}}{(a_j)} \frac{|x_j -y_j|}{1+|x_j -y_j|}$ Then $(\Bbb{R^\omega}, d) $ is a metric space. I know in a normed space any ball is convex. And it is easy to prove. The space $(\Bbb{R^\omega}, d) $ is not a normed space, I mean no norm on $\Bbb{R^\omega} $ can induce the metric $d$ . So, I guess in that space, It may be possible to find an open ball which is not convex. My question :1) Can I pick any open ball to test whether it is convex or not? If no, then is there any linear metric space in which every open ball is not convex? Can we get an example of a linear metric space (not a normed space) in which every open ball is convex? For the last question can I take $(X, \|•\|)$ be any  normed space and then define a metric $d(x, y) =\sqrt\|x-y\|$ . I think it works. Isn't it? Here $d$ is not scaling equivalent, hence not induced by any norm. $B_{d}(x_0, r) =\{x\in X : \|x-x_0\|<r^2 \}=B_{\|•\|} (x_0, r^2) $ Hence, every open ball is convex.","Then is a metric space. I know in a normed space any ball is convex. And it is easy to prove. The space is not a normed space, I mean no norm on can induce the metric . So, I guess in that space, It may be possible to find an open ball which is not convex. My question :1) Can I pick any open ball to test whether it is convex or not? If no, then is there any linear metric space in which every open ball is not convex? Can we get an example of a linear metric space (not a normed space) in which every open ball is convex? For the last question can I take be any  normed space and then define a metric . I think it works. Isn't it? Here is not scaling equivalent, hence not induced by any norm. Hence, every open ball is convex.","\Bbb{R^\omega}=\{(x_n)_{n\in \mathbb{N}}: x_n \in \Bbb{R}\} d(x, y) =\sum_{j\in\mathbb{N}}{(a_j)} \frac{|x_j -y_j|}{1+|x_j -y_j|} (\Bbb{R^\omega}, d)  (\Bbb{R^\omega}, d)  \Bbb{R^\omega}  d (X, \|•\|) d(x, y) =\sqrt\|x-y\| d B_{d}(x_0, r) =\{x\in X : \|x-x_0\|<r^2 \}=B_{\|•\|} (x_0, r^2) ","['functional-analysis', 'metric-spaces', 'convex-analysis']"
56,What distinguishes weak and strong convergence of bounded linear operator in Banach spaces?,What distinguishes weak and strong convergence of bounded linear operator in Banach spaces?,,"I'm self-studying using Applied Analysis by John Hunter and Bruno Nachtergaele. In chapter 5 on Banach space, the authors defined strong convergence and weak convergence as followed: A sequence ($T_{n}$) in $\mathcal{B}(X,Y)$ converges strongly if: $\lim_{n\to\infty} T_{n}x = Tx$ for every $x \in X$ We say that $T_{n}$ converges weakly to $T$ in $\mathcal{B}(X,Y)$ if the pointwise values $T_{n}x$ converge weakly to $Tx$ in Y. Then they say they will not consider the weak convergence of operators in this book..., but I'm confused between the two. They look quite identical to me. So, what is/are the difference(s) and why the difference(s) is/are important to keep in mind?","I'm self-studying using Applied Analysis by John Hunter and Bruno Nachtergaele. In chapter 5 on Banach space, the authors defined strong convergence and weak convergence as followed: A sequence ($T_{n}$) in $\mathcal{B}(X,Y)$ converges strongly if: $\lim_{n\to\infty} T_{n}x = Tx$ for every $x \in X$ We say that $T_{n}$ converges weakly to $T$ in $\mathcal{B}(X,Y)$ if the pointwise values $T_{n}x$ converge weakly to $Tx$ in Y. Then they say they will not consider the weak convergence of operators in this book..., but I'm confused between the two. They look quite identical to me. So, what is/are the difference(s) and why the difference(s) is/are important to keep in mind?",,"['functional-analysis', 'convergence-divergence', 'operator-theory', 'weak-convergence', 'strong-convergence']"
57,A closed subspace of a Banach space is a Banach space,A closed subspace of a Banach space is a Banach space,,How to prove that a closed subspace of a Banach space is a Banach space? A subspace is closed if it contains all of its limit points. But in the proof of the above question how can use this idea to get a Cauchy sequence and show that it is convergent in the subspace?,How to prove that a closed subspace of a Banach space is a Banach space? A subspace is closed if it contains all of its limit points. But in the proof of the above question how can use this idea to get a Cauchy sequence and show that it is convergent in the subspace?,,"['functional-analysis', 'banach-spaces']"
58,Reference request: Fourier and Fourier-Stieltjes algebras,Reference request: Fourier and Fourier-Stieltjes algebras,,"I would like to learn the basic theory of Fourier algebras and Fourier-Stieltjes algebras. In particular, I want to know how these two objects are defined in the case of not necessarily abelian locally compact groups and their relationship with the theory of amenable groups and operator algebras. Where is a good place to start?","I would like to learn the basic theory of Fourier algebras and Fourier-Stieltjes algebras. In particular, I want to know how these two objects are defined in the case of not necessarily abelian locally compact groups and their relationship with the theory of amenable groups and operator algebras. Where is a good place to start?",,"['reference-request', 'functional-analysis', 'harmonic-analysis', 'locally-compact-groups', 'banach-algebras']"
59,Can an inner product on a vector space be negative?,Can an inner product on a vector space be negative?,,This may be a noob question but I recently read a definition that an inner product on a complex vector space is said to be a positive-definite sesquilinear map. Doesn't positive definite mean that the inner product will only return positive values? (Just started studying Functional Analysis specifically Hilbert Spaces),This may be a noob question but I recently read a definition that an inner product on a complex vector space is said to be a positive-definite sesquilinear map. Doesn't positive definite mean that the inner product will only return positive values? (Just started studying Functional Analysis specifically Hilbert Spaces),,"['functional-analysis', 'hilbert-spaces']"
60,Why is the image of a compact operator separable?,Why is the image of a compact operator separable?,,"Let $A$ and $B$ be normed vector spaces and let $S\in \mathscr{K}(A,B)$ be a compact operator. Question: How does it follow that the image of $S$ is separable? Thanks for the help.","Let $A$ and $B$ be normed vector spaces and let $S\in \mathscr{K}(A,B)$ be a compact operator. Question: How does it follow that the image of $S$ is separable? Thanks for the help.",,"['functional-analysis', 'operator-theory', 'compactness', 'normed-spaces']"
61,An introductory textbook on functional analysis and operator theory,An introductory textbook on functional analysis and operator theory,,"I would like to ask for some recommendation of introductory texts on functional analysis. I am not a professional mathematician and I am totally new to the subject. However, I found out that some knowledge of functional analysis and operator theory would be quite helpful to my work... What I am searching for is some accessible and instructive text not necessarily covering the subject in great depth, but explaining the main ideas. I am not searching for a text for engineers, some amount of mathematical rigor would be fine. But I found myself unable of reading some standard textbooks covering in great depth a large amount of issues in theory of Banach spaces, etc. I am looking for something that proceeds to the most important topics (e.g., spectral theory) faster than the most of textbooks, but not at the expense of rigor. I.e., something that covers rigorously the main topics, but concentrates only on the main ideas. Simply an accessible introductory text for a fast orientation in the subject. Moreover, I would prefer a text that does not require any background in measure theory and similar disciplines. And another question: is there any functional analysis book that deals primarily with sequence spaces? It need not fulfill the description above. Thank you for your recommendations!","I would like to ask for some recommendation of introductory texts on functional analysis. I am not a professional mathematician and I am totally new to the subject. However, I found out that some knowledge of functional analysis and operator theory would be quite helpful to my work... What I am searching for is some accessible and instructive text not necessarily covering the subject in great depth, but explaining the main ideas. I am not searching for a text for engineers, some amount of mathematical rigor would be fine. But I found myself unable of reading some standard textbooks covering in great depth a large amount of issues in theory of Banach spaces, etc. I am looking for something that proceeds to the most important topics (e.g., spectral theory) faster than the most of textbooks, but not at the expense of rigor. I.e., something that covers rigorously the main topics, but concentrates only on the main ideas. Simply an accessible introductory text for a fast orientation in the subject. Moreover, I would prefer a text that does not require any background in measure theory and similar disciplines. And another question: is there any functional analysis book that deals primarily with sequence spaces? It need not fulfill the description above. Thank you for your recommendations!",,"['reference-request', 'functional-analysis', 'operator-theory']"
62,Compact support vs. vanishing at infinity?,Compact support vs. vanishing at infinity?,,Consider the two sets $$ C_0 = \{ f: \mathbb R \to \mathbb C \mid f \text{ is continuous and } \lim_{|x|\to \infty} f(x) = 0\}$$ $$ C_c = \{ f: \mathbb R \to \mathbb C \mid f \text{ is continuous and }  \operatorname{supp}{(f)} \text{ is bounded}\}$$ Aren't these two sets the same? What am I missing?,Consider the two sets $$ C_0 = \{ f: \mathbb R \to \mathbb C \mid f \text{ is continuous and } \lim_{|x|\to \infty} f(x) = 0\}$$ $$ C_c = \{ f: \mathbb R \to \mathbb C \mid f \text{ is continuous and }  \operatorname{supp}{(f)} \text{ is bounded}\}$$ Aren't these two sets the same? What am I missing?,,"['analysis', 'functional-analysis']"
63,What is the relationship between generalized functions and things like the Riesz representation theorem?,What is the relationship between generalized functions and things like the Riesz representation theorem?,,"I just watched this video of Prof. Osgood's lecture on Fourier Transforms, and it seems to me that there's some connection between his talk of distributions (generalized functions) and the usual linear algebra I'm familiar with. He mentions many times that the dirac delta function classically doesn't make any sense. I agree with him, but then he shows that one can represent the dirac delta function as a continuous linear functional. I'm a bit confused, because the Riesz representation theorem says that elements of a Hilbert space $H$ correspond bijectively with continuous linear functionals on $H$. So there must be some function that actually does everything we want out of the dirac delta function, right? I think the difference here is that the chosen measure is also part of the equation, but I haven't quite put my finger on it. So my question is: what part of the Riesz representation theorem fails for this?","I just watched this video of Prof. Osgood's lecture on Fourier Transforms, and it seems to me that there's some connection between his talk of distributions (generalized functions) and the usual linear algebra I'm familiar with. He mentions many times that the dirac delta function classically doesn't make any sense. I agree with him, but then he shows that one can represent the dirac delta function as a continuous linear functional. I'm a bit confused, because the Riesz representation theorem says that elements of a Hilbert space $H$ correspond bijectively with continuous linear functionals on $H$. So there must be some function that actually does everything we want out of the dirac delta function, right? I think the difference here is that the chosen measure is also part of the equation, but I haven't quite put my finger on it. So my question is: what part of the Riesz representation theorem fails for this?",,"['functional-analysis', 'fourier-analysis', 'distribution-theory', 'riesz-representation-theorem']"
64,Derivative of arcsin,Derivative of arcsin,,In my assignment I need to analyze the function $f(x)=\arcsin \frac{1-x^2}{1+x^2}$ And so I need to do the first derivative and my result is: $-\dfrac{4x}{\left(x^2+1\right)^2\sqrt{1-\frac{\left(1-x^2\right)^2}{\left(x^2+1\right)^2}}}$ But in the solution of this assignment it says $f'(x)=-\frac{2x}{|x|(1+x^2)}$ I don't understand how they get this. I checked my answer on online calculator and it is the same.,In my assignment I need to analyze the function $f(x)=\arcsin \frac{1-x^2}{1+x^2}$ And so I need to do the first derivative and my result is: $-\dfrac{4x}{\left(x^2+1\right)^2\sqrt{1-\frac{\left(1-x^2\right)^2}{\left(x^2+1\right)^2}}}$ But in the solution of this assignment it says $f'(x)=-\frac{2x}{|x|(1+x^2)}$ I don't understand how they get this. I checked my answer on online calculator and it is the same.,,"['functional-analysis', 'functions', 'derivatives']"
65,Sufficient condition for a *-homomorphism between C*-algebras being isometric,Sufficient condition for a *-homomorphism between C*-algebras being isometric,,"Let $\mathcal{A},\mathcal{B}$ be two unital C*-algebras and consider a *-homomorphism $\pi: \mathcal{A} \rightarrow \mathcal{B}$. I know that in general $\pi$ is contractive, i.e. $\vert\vert \pi(A) \vert\vert \leq \vert\vert A \vert\vert, \forall A\in \mathcal{A}$. I want to show that under the additional assumption that $\pi(A)>0, \forall A>0$ one has equality, i.e. $\pi$ is an isometry: $\vert\vert \pi(A) \vert\vert = \vert\vert A \vert\vert, \forall A\in \mathcal{A}$ The crucial step in establishing the previous inequality lies in the fact that $\forall A\in\mathcal{A}$ $$r(\pi(AA^*)) \leq r(AA^*),$$ where $r$ denotes the spectral radius, respectively. Since $AA^*$ is positive, I sense that the additional condition enters at this point, but I can't finish the proof. Am I on the wrong foot? Help is highly appreciated!","Let $\mathcal{A},\mathcal{B}$ be two unital C*-algebras and consider a *-homomorphism $\pi: \mathcal{A} \rightarrow \mathcal{B}$. I know that in general $\pi$ is contractive, i.e. $\vert\vert \pi(A) \vert\vert \leq \vert\vert A \vert\vert, \forall A\in \mathcal{A}$. I want to show that under the additional assumption that $\pi(A)>0, \forall A>0$ one has equality, i.e. $\pi$ is an isometry: $\vert\vert \pi(A) \vert\vert = \vert\vert A \vert\vert, \forall A\in \mathcal{A}$ The crucial step in establishing the previous inequality lies in the fact that $\forall A\in\mathcal{A}$ $$r(\pi(AA^*)) \leq r(AA^*),$$ where $r$ denotes the spectral radius, respectively. Since $AA^*$ is positive, I sense that the additional condition enters at this point, but I can't finish the proof. Am I on the wrong foot? Help is highly appreciated!",,"['functional-analysis', 'operator-algebras', 'c-star-algebras']"
66,Survey papers for PDE?,Survey papers for PDE?,,"I want to know if there is a good website which allows you to download survey papers on PDEs? The ""survey"" should include a summary of methods, skills, developments etc. I wish to get some basic (or common) conceptual ideas and methodology in the macroscopic view, as well as details. I think it can help me to understand the theory of PDEs and let me know how to do research in the field of PDEs? Any recommendation would be appreciated! ^_^","I want to know if there is a good website which allows you to download survey papers on PDEs? The ""survey"" should include a summary of methods, skills, developments etc. I wish to get some basic (or common) conceptual ideas and methodology in the macroscopic view, as well as details. I think it can help me to understand the theory of PDEs and let me know how to do research in the field of PDEs? Any recommendation would be appreciated! ^_^",,"['functional-analysis', 'partial-differential-equations', 'sobolev-spaces', 'holder-spaces']"
67,"Extreme points of unit ball of Banach spaces $\ell_1$, $c_0$, $\ell_\infty$","Extreme points of unit ball of Banach spaces , ,",\ell_1 c_0 \ell_\infty,"Find extreme points of the unit balls of each Banach space, $l^1  $,    $c_0$,   $    l^\infty$ Can you help me with this one? For the first space, $l^1$, I thought there was no extreme point, but apparently, this is not the answer :( And I don't know if the fact that $l^\infty$ contains $c_0$ matters in this problem. Thanks.","Find extreme points of the unit balls of each Banach space, $l^1  $,    $c_0$,   $    l^\infty$ Can you help me with this one? For the first space, $l^1$, I thought there was no extreme point, but apparently, this is not the answer :( And I don't know if the fact that $l^\infty$ contains $c_0$ matters in this problem. Thanks.",,"['functional-analysis', 'banach-spaces']"
68,Why topological spaces in Baire category theorem are required to be Hausdorff?,Why topological spaces in Baire category theorem are required to be Hausdorff?,,"In Baire category theorem it says  a locally compact Hausdorff space $S$ is second category. In the proof, it choose $V_1,V_2\cdots$ are dense open subset of $S$ . $B_0$ is an arbitrary nonempty open set in $S$ . Then we choose $B_n\not = \emptyset$ , $\bar B_n \subset V_n \cap B_{n-1}$ . We can choose $\bar B_n$ is compact. Put $K=\cap_{n=1}^\infty \bar B_n$ . Because in compact space, every family of closed subsets having the finite intersection property has non-empty intersection. So $K$ is nonempty. And $K\subset B_0,K\subset V_n$ . Hence $B_0$ intersects $\cap V_n$ So where the Hausdorffness is used. It seems that it should only be regular space. So where it use that it should be regular?","In Baire category theorem it says  a locally compact Hausdorff space is second category. In the proof, it choose are dense open subset of . is an arbitrary nonempty open set in . Then we choose , . We can choose is compact. Put . Because in compact space, every family of closed subsets having the finite intersection property has non-empty intersection. So is nonempty. And . Hence intersects So where the Hausdorffness is used. It seems that it should only be regular space. So where it use that it should be regular?","S V_1,V_2\cdots S B_0 S B_n\not = \emptyset \bar B_n \subset V_n \cap B_{n-1} \bar B_n K=\cap_{n=1}^\infty \bar B_n K K\subset B_0,K\subset V_n B_0 \cap V_n","['functional-analysis', 'baire-category']"
69,The dual $H'$ of a Hilbert Space $H$ is a Hilbert Space,The dual  of a Hilbert Space  is a Hilbert Space,H' H,"Let H be a Hilbert Space. Show that the dual space $H'$ of $H$ is a Hilbert Space with inner product $\langle \cdot, \cdot \rangle_1$ defined by $$ \langle f_z , f_v \rangle_1 = \overline{ \langle z,v\rangle}=\langle v,z\rangle,$$ where $f_z(x)=\langle x,z\rangle$ , with $\langle \cdot, \cdot\rangle$ is the inner product in $H$ . I have already shown that $\langle\cdot , \cdot\rangle_1$ is inner product. Now I need to prove that $H'$ is complete, so I started this way: we have that $H'$ is an inner product space and the metric $d:H'\times H'\rightarrow \mathbb{R}$ defined by $$d(f_z, f_v)= \sqrt{\langle f_z -f_v,f_z -f_v\rangle_1}.$$ Let $({f_z}_n)_{n\in\mathbb{N}}$ be a arbitrary Cauchy sequence in $H'$ , that is $$\forall \epsilon >0, \: \exists \: n_0 \in \mathbb{N} \:;\: m,n>n_0 \: \Rightarrow \: d({f_z}_n,{f_z}_m)<\epsilon.$$ I can write that ${f_z}_n=\langle x,z_n\rangle$ ? Where $(z_n)_{n\in\mathbb{N}}$ is a sequence in $H$ . How to continue to prove that such a sequence converges?","Let H be a Hilbert Space. Show that the dual space of is a Hilbert Space with inner product defined by where , with is the inner product in . I have already shown that is inner product. Now I need to prove that is complete, so I started this way: we have that is an inner product space and the metric defined by Let be a arbitrary Cauchy sequence in , that is I can write that ? Where is a sequence in . How to continue to prove that such a sequence converges?","H' H \langle \cdot, \cdot \rangle_1  \langle f_z , f_v \rangle_1 = \overline{ \langle z,v\rangle}=\langle v,z\rangle, f_z(x)=\langle x,z\rangle \langle \cdot, \cdot\rangle H \langle\cdot , \cdot\rangle_1 H' H' d:H'\times H'\rightarrow \mathbb{R} d(f_z, f_v)= \sqrt{\langle f_z -f_v,f_z -f_v\rangle_1}. ({f_z}_n)_{n\in\mathbb{N}} H' \forall \epsilon >0, \: \exists \: n_0 \in \mathbb{N} \:;\: m,n>n_0 \: \Rightarrow \: d({f_z}_n,{f_z}_m)<\epsilon. {f_z}_n=\langle x,z_n\rangle (z_n)_{n\in\mathbb{N}} H","['functional-analysis', 'hilbert-spaces']"
70,"If $H$ is a Hilbert space and $M$ is a closed subspace of $H$, then $H/M$ is a Hilbert space","If  is a Hilbert space and  is a closed subspace of , then  is a Hilbert space",H M H H/M,Can anyone give a brief proof or a reference of a proof for the following property of Hilbert spaces ? If $H$ is a Hilbert space and $M$ is a closed subspace of $H$ then $H/M$ is a Hilbert space. Definitions: A Hilbert space $H$ is a real or complex inner product space that is also a complete metric space with respect to the distance function induced by the inner product. A closed subspace of $H$ is a linear subspace of $H$ that is closed with respect to the topology induced by the norm (which is induced by the inner product). I know that $H/M$ denotes the quotient set . But I don't know how to prove the Hilbert space structure on this set.,Can anyone give a brief proof or a reference of a proof for the following property of Hilbert spaces ? If is a Hilbert space and is a closed subspace of then is a Hilbert space. Definitions: A Hilbert space is a real or complex inner product space that is also a complete metric space with respect to the distance function induced by the inner product. A closed subspace of is a linear subspace of that is closed with respect to the topology induced by the norm (which is induced by the inner product). I know that denotes the quotient set . But I don't know how to prove the Hilbert space structure on this set.,H M H H/M H H H H/M,"['functional-analysis', 'reference-request', 'hilbert-spaces', 'quotient-spaces']"
71,Is the number of dimensions in Hilbert Space countable infinity or uncountable infinity?,Is the number of dimensions in Hilbert Space countable infinity or uncountable infinity?,,"Hilbert Space is an ""infinity"" dimensional vector space. Does the ""infinity"" means $\aleph^0$ or $\aleph^1$ ? Or it does not matter at all? Math newbie thanks you. Could you please up vote for once so I could comment on others' posts?","Hilbert Space is an ""infinity"" dimensional vector space. Does the ""infinity"" means $\aleph^0$ or $\aleph^1$ ? Or it does not matter at all? Math newbie thanks you. Could you please up vote for once so I could comment on others' posts?",,"['functional-analysis', 'hilbert-spaces', 'infinity']"
72,"Show that $f \overset{T}{\rightarrow} \frac{1}{x} \int_0^x f(t) dt$ is Bounded, and is NOT Compact in $L^2(0, \infty)$","Show that  is Bounded, and is NOT Compact in","f \overset{T}{\rightarrow} \frac{1}{x} \int_0^x f(t) dt L^2(0, \infty)","Can someone help me with this question? Let $f \in X = L^2(0, \infty)$, and define \begin{equation} (Tf)(x) = \frac{1}{x} \int_0^x f(t) dt \ . \end{equation} Show that $T$ is Bounded, and is NOT Compact. Thanks in advance. Edit: For boundedness, I tried: \begin{eqnarray} \| f \| \leq 1 \Rightarrow \| Tf \|^2 &=& \int_0^{\infty} \lvert (Tf)(x) \rvert ^2 \ dx \\ &=& \int_0^{\infty} \lvert \frac{1}{x} \int_0^x f(t) \ dt \rvert ^2 \ dx \\ &\leq& \int_0^{\infty} \frac{1}{x^2} \int_0^x \lvert f(t) \rvert ^2 \ dt \ dx \\ &\leq& \int_0^{\infty} \frac{1}{x^2} \| f \| ^2 \ dx \\ &=& \| f \| ^2 \int_0^{\infty} \frac{1}{x^2} \ dx \\ \end{eqnarray} But the problem is that $\int_0^{\infty} \frac{1}{x^2} \ dx$ is NOT finite. To prove that $T$ is not compact, I think we should give a sequence of functions, $\{ f_n \}_{n=1}^{\infty}$, such that for every $n$, we have $\| f_n \| \leq 1$ and $\{ Tf_n \}$ has no Cauchy subsequence. But I can't find such sequence of functions.","Can someone help me with this question? Let $f \in X = L^2(0, \infty)$, and define \begin{equation} (Tf)(x) = \frac{1}{x} \int_0^x f(t) dt \ . \end{equation} Show that $T$ is Bounded, and is NOT Compact. Thanks in advance. Edit: For boundedness, I tried: \begin{eqnarray} \| f \| \leq 1 \Rightarrow \| Tf \|^2 &=& \int_0^{\infty} \lvert (Tf)(x) \rvert ^2 \ dx \\ &=& \int_0^{\infty} \lvert \frac{1}{x} \int_0^x f(t) \ dt \rvert ^2 \ dx \\ &\leq& \int_0^{\infty} \frac{1}{x^2} \int_0^x \lvert f(t) \rvert ^2 \ dt \ dx \\ &\leq& \int_0^{\infty} \frac{1}{x^2} \| f \| ^2 \ dx \\ &=& \| f \| ^2 \int_0^{\infty} \frac{1}{x^2} \ dx \\ \end{eqnarray} But the problem is that $\int_0^{\infty} \frac{1}{x^2} \ dx$ is NOT finite. To prove that $T$ is not compact, I think we should give a sequence of functions, $\{ f_n \}_{n=1}^{\infty}$, such that for every $n$, we have $\| f_n \| \leq 1$ and $\{ Tf_n \}$ has no Cauchy subsequence. But I can't find such sequence of functions.",,"['functional-analysis', 'compact-operators']"
73,Linear combinations of delta measures,Linear combinations of delta measures,,"Let us consider the space of Borel, regular, complex measures on the real line, endowed with the total variation norm. Inside this space, I would like to characterize the space of all the finite complex linear combinations of Delta measures. In particular, could we approximate a measure with compact support with linear combinations of that kind? Maybe it is possible only in the weak star topology... Thank you","Let us consider the space of Borel, regular, complex measures on the real line, endowed with the total variation norm. Inside this space, I would like to characterize the space of all the finite complex linear combinations of Delta measures. In particular, could we approximate a measure with compact support with linear combinations of that kind? Maybe it is possible only in the weak star topology... Thank you",,"['functional-analysis', 'measure-theory', 'banach-spaces']"
74,Does the derivative of a continuous function goes to zero if the function converges to it?,Does the derivative of a continuous function goes to zero if the function converges to it?,,"Physicist here. I am puzzled by a question: looking at a continuous function $g :\mathbb{R} \rightarrow \mathbb{R}$ that goes to zero at infinity, I am interested in the behavior of its derivative $\beta = g'$. Precisely, does it go to zero too? By writing on paper it looks like: $$ \beta(+ \infty)=\text{lim}_{x\rightarrow \infty}\text{lim}_{h\rightarrow 0} \frac{g(x+h)-g(x)}{h}$$ And if I can invert the two limits, I get what I expect: $\beta(+\infty)=0$, so I was curious about the hypothesis behind this permutation. Is the requirement of continuity enough? Thanks.","Physicist here. I am puzzled by a question: looking at a continuous function $g :\mathbb{R} \rightarrow \mathbb{R}$ that goes to zero at infinity, I am interested in the behavior of its derivative $\beta = g'$. Precisely, does it go to zero too? By writing on paper it looks like: $$ \beta(+ \infty)=\text{lim}_{x\rightarrow \infty}\text{lim}_{h\rightarrow 0} \frac{g(x+h)-g(x)}{h}$$ And if I can invert the two limits, I get what I expect: $\beta(+\infty)=0$, so I was curious about the hypothesis behind this permutation. Is the requirement of continuity enough? Thanks.",,"['functional-analysis', 'limits', 'derivatives']"
75,Why is Parseval's Equality and Bessel's Inequality Different?,Why is Parseval's Equality and Bessel's Inequality Different?,,"Bessel's Inequality:   $\sum_n |\langle x, e_n \rangle |^2 \leq \|x\|^2$ Parseval: $\;\;\;\;\;\;\;\;\;\;\;\;\;\;$ $\sum_n |\langle x, e_n \rangle |^2 = \|x\|^2$","Bessel's Inequality:   $\sum_n |\langle x, e_n \rangle |^2 \leq \|x\|^2$ Parseval: $\;\;\;\;\;\;\;\;\;\;\;\;\;\;$ $\sum_n |\langle x, e_n \rangle |^2 = \|x\|^2$",,"['functional-analysis', 'fourier-analysis', 'hilbert-spaces']"
76,Cesàro operator is bounded for $1<p<\infty$,Cesàro operator is bounded for,1<p<\infty,"The Cesàro operator $T\colon \ell_{p}\to\ell_{p}$ is defined by $(Tx)_{k}=\frac{1}{k}\sum_{j=1}^{k}x_{j},\: k\in\mathbb{N}$, where $x=(x_{k})_{k=1}^{\infty}$ Show that $T$ is bounded if $1<p<\infty$. I can do it for $p=\infty$, but not when it is between $1$ and $\infty$. Thank you.","The Cesàro operator $T\colon \ell_{p}\to\ell_{p}$ is defined by $(Tx)_{k}=\frac{1}{k}\sum_{j=1}^{k}x_{j},\: k\in\mathbb{N}$, where $x=(x_{k})_{k=1}^{\infty}$ Show that $T$ is bounded if $1<p<\infty$. I can do it for $p=\infty$, but not when it is between $1$ and $\infty$. Thank you.",,"['functional-analysis', 'banach-spaces', 'lp-spaces']"
77,Pointwise convergenve of mollified $f\in L^1_{loc}$,Pointwise convergenve of mollified,f\in L^1_{loc},"Let $\Omega\subseteq\mathbb{R}^n$ open, $f\in L^1_{loc}(\Omega)$, $\eta_\epsilon(x) = \dfrac{1}{\epsilon^n}\eta(\dfrac{x}{\epsilon})$ the usual scaled mollifier, i.e. $supp (\eta_\epsilon) \subseteq B_\epsilon(0), \int_{\mathbb{R}^n} \eta_\epsilon = 1, \eta_\epsilon \ge 0$. Then $f*\eta_\epsilon\to f$ almost everywhere as $\epsilon\to 0$. So, starting out I noticed that by definition $|f*\eta_\epsilon(x)-f(x)|\le \int_{B_\epsilon(x)}\eta_\epsilon(x-y)|f(y)-f(x)| dy \le C\int_{B_\epsilon(x)}|f(y)-f(x)|$ where $C=\sup\eta_\epsilon$ and I assume that $\epsilon$ is small enough that $f$ does not cause any problems, that is that the integral is well defined. Now intuitively it makes sense, that the ""average difference"" over a ball should go to 0 if the radius goes to 0, but I need help to formally justify this.","Let $\Omega\subseteq\mathbb{R}^n$ open, $f\in L^1_{loc}(\Omega)$, $\eta_\epsilon(x) = \dfrac{1}{\epsilon^n}\eta(\dfrac{x}{\epsilon})$ the usual scaled mollifier, i.e. $supp (\eta_\epsilon) \subseteq B_\epsilon(0), \int_{\mathbb{R}^n} \eta_\epsilon = 1, \eta_\epsilon \ge 0$. Then $f*\eta_\epsilon\to f$ almost everywhere as $\epsilon\to 0$. So, starting out I noticed that by definition $|f*\eta_\epsilon(x)-f(x)|\le \int_{B_\epsilon(x)}\eta_\epsilon(x-y)|f(y)-f(x)| dy \le C\int_{B_\epsilon(x)}|f(y)-f(x)|$ where $C=\sup\eta_\epsilon$ and I assume that $\epsilon$ is small enough that $f$ does not cause any problems, that is that the integral is well defined. Now intuitively it makes sense, that the ""average difference"" over a ball should go to 0 if the radius goes to 0, but I need help to formally justify this.",,"['functional-analysis', 'fourier-analysis', 'convolution']"
78,Does orthogonal decomposition characterize direct sums in Hilbert space?,Does orthogonal decomposition characterize direct sums in Hilbert space?,,"Let $H$ be a Hilbert space with inner product $(\cdot, \cdot)$. I know that if $M$ is a closed subspace of $H$, then $H$ can be written as the direct sum $M \oplus M^\perp$, where $M^\perp$ stands for the orthogonal complement of $M$. I would like to know if this decomposition above essentially describes all direct sums in Hilbert spaces: If $M,N$ are closed subspaces of $H$ with $H$ being the direct sum $M \oplus N$, then is it true that $N = M^\perp$. So far I've tried using a direct proof that's not really getting me anywhere: take $n \in N$ and show that $(n,m) = 0$ for $m \in M$ arbitrary. Without knowing any specific about $M$ and $N$, I am not able to move any further. Is there some basic fact about the inner product that makes this all work? Or is the question deeper? Hints or solutions are greatly appreciated.","Let $H$ be a Hilbert space with inner product $(\cdot, \cdot)$. I know that if $M$ is a closed subspace of $H$, then $H$ can be written as the direct sum $M \oplus M^\perp$, where $M^\perp$ stands for the orthogonal complement of $M$. I would like to know if this decomposition above essentially describes all direct sums in Hilbert spaces: If $M,N$ are closed subspaces of $H$ with $H$ being the direct sum $M \oplus N$, then is it true that $N = M^\perp$. So far I've tried using a direct proof that's not really getting me anywhere: take $n \in N$ and show that $(n,m) = 0$ for $m \in M$ arbitrary. Without knowing any specific about $M$ and $N$, I am not able to move any further. Is there some basic fact about the inner product that makes this all work? Or is the question deeper? Hints or solutions are greatly appreciated.",,"['functional-analysis', 'hilbert-spaces']"
79,Is every projection on a Hilbert space orthogonal?,Is every projection on a Hilbert space orthogonal?,,"I'm highly doubtful that the answer is ""yes,"" but I fail to see what's incorrect about this very basic proof I've thought of. If someone could point out my error, I'd appreciate it. My logic is as follows: Claim: Every projection on a Hilbert space is orthogonal. ""Proof"": 1. For any linear space $X$, it is true that given a projection $P: X \rightarrow X$ (where $P$ is a projection iff $P$ is linear and satisfies $P^2 = P$), we have $X = \text{ran}(P) \oplus \text{ker}(P)$. 2. Assume X is a Hilbert space (which is, by definition, linear). Since $\text{ker}(P)$ is a closed linear subspace of $X$, then by the projection theorem, $X = \text{ker}(P) \oplus \text{ker}(P)^\perp$ is an orthogonal direct sum. 3. Therefore, $\text{ker}(P)^\perp = \text{ran}(P)$, so $X = \text{ran}(P) \oplus \text{ker}(P)$ is an orthogonal direct sum. Thus, $P$ is an orthogonal projection.","I'm highly doubtful that the answer is ""yes,"" but I fail to see what's incorrect about this very basic proof I've thought of. If someone could point out my error, I'd appreciate it. My logic is as follows: Claim: Every projection on a Hilbert space is orthogonal. ""Proof"": 1. For any linear space $X$, it is true that given a projection $P: X \rightarrow X$ (where $P$ is a projection iff $P$ is linear and satisfies $P^2 = P$), we have $X = \text{ran}(P) \oplus \text{ker}(P)$. 2. Assume X is a Hilbert space (which is, by definition, linear). Since $\text{ker}(P)$ is a closed linear subspace of $X$, then by the projection theorem, $X = \text{ker}(P) \oplus \text{ker}(P)^\perp$ is an orthogonal direct sum. 3. Therefore, $\text{ker}(P)^\perp = \text{ran}(P)$, so $X = \text{ran}(P) \oplus \text{ker}(P)$ is an orthogonal direct sum. Thus, $P$ is an orthogonal projection.",,"['functional-analysis', 'hilbert-spaces']"
80,"Prove that a linear operator $T:E \rightarrow E'$ such that $\langle Tx,y \rangle=\langle Ty,x\rangle$ is bounded",Prove that a linear operator  such that  is bounded,"T:E \rightarrow E' \langle Tx,y \rangle=\langle Ty,x\rangle","Let E be a Banach space and $T:E\to E'$ a linear operator such that $\langle Tx,y\rangle=\langle x,Ty \rangle$ for all $x,y\in E$ . Here $E'$ is the dual space of $E$ . I have to prove that $T$ is a bounded operator. I tried to use the closed graph theorem, but I can't prove that the graph of T is closed. I would appreciate it if anyone could help me. Thank you.","Let E be a Banach space and a linear operator such that for all . Here is the dual space of . I have to prove that is a bounded operator. I tried to use the closed graph theorem, but I can't prove that the graph of T is closed. I would appreciate it if anyone could help me. Thank you.","T:E\to E' \langle Tx,y\rangle=\langle x,Ty \rangle x,y\in E E' E T","['functional-analysis', 'banach-spaces']"
81,Order of learning measure theory and functional analysis,Order of learning measure theory and functional analysis,,Guiding question :Should measure theory be learned before functional analysis or should it be the other way around? Perhaps there is no largely agreed upon answer to this so I'll ask: More specific question : What connections are there between the two subjects that might make a person choose to study one before the next? All feedback is appreciated.,Guiding question :Should measure theory be learned before functional analysis or should it be the other way around? Perhaps there is no largely agreed upon answer to this so I'll ask: More specific question : What connections are there between the two subjects that might make a person choose to study one before the next? All feedback is appreciated.,,"['functional-analysis', 'measure-theory', 'hilbert-spaces', 'lebesgue-measure', 'banach-spaces']"
82,Compactness of the open and closed unit intervals,Compactness of the open and closed unit intervals,,"In the article by Tao it's explained that the compactness can be formulated in the most general way as: (All open covers have finite subcovers) If $`V_\alpha:\alpha\in\mathcal{a}`$ is any collection of open sets which covers $X$, then there must exist a finite sub-collection $V_{\alpha_1},V_{\alpha_2}...V_{\alpha_k}$ of these sets which still cover $X$. Question: How is it possible to show (both intuitively and rigorously) that such coverage by a finite collection of open sets is possible for $X=[0,1]$ and not possible for $X=(0,1)$? Edit: a related question and another one on open covers.","In the article by Tao it's explained that the compactness can be formulated in the most general way as: (All open covers have finite subcovers) If $`V_\alpha:\alpha\in\mathcal{a}`$ is any collection of open sets which covers $X$, then there must exist a finite sub-collection $V_{\alpha_1},V_{\alpha_2}...V_{\alpha_k}$ of these sets which still cover $X$. Question: How is it possible to show (both intuitively and rigorously) that such coverage by a finite collection of open sets is possible for $X=[0,1]$ and not possible for $X=(0,1)$? Edit: a related question and another one on open covers.",,"['functional-analysis', 'compactness']"
83,Does every element of the weak-star closure of a set belong to the weak-star closure of a bounded subset?,Does every element of the weak-star closure of a set belong to the weak-star closure of a bounded subset?,,"I feel like this must be a monumentally stupid question. Say $X$ is a Banach space, $S\subset X^*$, and $x^*$ is in the weak* closure of $S$. Must $x^*$ lie in the weak* closure of some norm-bounded subset of $S$? (If $x^*$ is the weak* limit of a sequence of elements of $S$ then this is clear by Banach-Steinhaus. But a convergent net of scalars need not be bounded...)","I feel like this must be a monumentally stupid question. Say $X$ is a Banach space, $S\subset X^*$, and $x^*$ is in the weak* closure of $S$. Must $x^*$ lie in the weak* closure of some norm-bounded subset of $S$? (If $x^*$ is the weak* limit of a sequence of elements of $S$ then this is clear by Banach-Steinhaus. But a convergent net of scalars need not be bounded...)",,"['functional-analysis', 'banach-spaces']"
84,How does the general spectral theorem generalize the simpler versions?,How does the general spectral theorem generalize the simpler versions?,,"I read the following version of the spectral theorem in Banach Algebra Techniques in Operator Theory by Douglas: I'm trying to understand why this is a generalization of the following version, which is most common in an undergraduate functional analysis course: Theorem 1 . Suppose $A$ is a compact self-adjoint operator on a Hilbert space $V$. There is an orthonormal basis of $V$ consisting of eigenvectors of $A$. Each eigenvalue is real. or the version for normal matrix in undergraduate linear algebra: Theorem 2 An $n\times n$ complex matrix $A$ is normal if and only if there exists a unitary matrix $U$ such that   $$ A=U D U^*, $$   where $D$ is a diagonal matrix. It is pain in the neck to read the abstract version of the theorem without knowing how it generalize the simpler versions. Could anybody explain how is Theorem 4.30 a generalization? Especially, Where is the Gelfand transform in Theorem 1 and Theorem 2? How does the ""Gelfand map is a *-isometric isomorphism of $\mathfrak{C}_T$ onto $C(\sigma(T))$"" correspond to the eigenvector-eigenvalue statement in Theorem 1 and Theorem 2?","I read the following version of the spectral theorem in Banach Algebra Techniques in Operator Theory by Douglas: I'm trying to understand why this is a generalization of the following version, which is most common in an undergraduate functional analysis course: Theorem 1 . Suppose $A$ is a compact self-adjoint operator on a Hilbert space $V$. There is an orthonormal basis of $V$ consisting of eigenvectors of $A$. Each eigenvalue is real. or the version for normal matrix in undergraduate linear algebra: Theorem 2 An $n\times n$ complex matrix $A$ is normal if and only if there exists a unitary matrix $U$ such that   $$ A=U D U^*, $$   where $D$ is a diagonal matrix. It is pain in the neck to read the abstract version of the theorem without knowing how it generalize the simpler versions. Could anybody explain how is Theorem 4.30 a generalization? Especially, Where is the Gelfand transform in Theorem 1 and Theorem 2? How does the ""Gelfand map is a *-isometric isomorphism of $\mathfrak{C}_T$ onto $C(\sigma(T))$"" correspond to the eigenvector-eigenvalue statement in Theorem 1 and Theorem 2?",,"['functional-analysis', 'operator-theory']"
85,Spectrum of unbounded Operators + Spectral Theorem [duplicate],Spectrum of unbounded Operators + Spectral Theorem [duplicate],,"This question already has answers here : Resolvent: Definition (2 answers) Closed 10 years ago . I've seen a variaty of slightly different definitions for the spectrum and its division into pure point spectrum residual spectrum and so on. Thus I'm wondering what could be an appropriate definition. Moreover, when does the spectral theorem apply in principle? I have heard for normal operators and read once (I don't remember where) positive operators I guess...","This question already has answers here : Resolvent: Definition (2 answers) Closed 10 years ago . I've seen a variaty of slightly different definitions for the spectrum and its division into pure point spectrum residual spectrum and so on. Thus I'm wondering what could be an appropriate definition. Moreover, when does the spectral theorem apply in principle? I have heard for normal operators and read once (I don't remember where) positive operators I guess...",,['functional-analysis']
86,Are projections onto closed complemented subspaces of a topological vector space always continuous?,Are projections onto closed complemented subspaces of a topological vector space always continuous?,,"Suppose $X$ is a topological vector space and $X = V \oplus W$ is a decomposition of $X$ into closed subspaces. The decomposition gives rise to a projection $P$ onto $V$ (depending on the choice of complement $W$): \begin{equation} P:X \rightarrow X \\v+w \rightarrow v\end{equation} Is $P$ continuous? It seems like it ought to be (and ought to be easy to show!), but I haven't been able to prove it. I'm fairly sure that it's equivalent to show that the topology on $X$ is the same as the product topology on $V \oplus W$ (since in a preadditive category products=coproducts=biproducts) I'm interested in the result for an application to the space of test functions on a domain, which has a lot more structure than a general topological vector space (it's locally convex, locally bounded and has the Heine-Borel property but is not metrisable), so if anyone knows of/can think of a proof in that special case that would be great also.","Suppose $X$ is a topological vector space and $X = V \oplus W$ is a decomposition of $X$ into closed subspaces. The decomposition gives rise to a projection $P$ onto $V$ (depending on the choice of complement $W$): \begin{equation} P:X \rightarrow X \\v+w \rightarrow v\end{equation} Is $P$ continuous? It seems like it ought to be (and ought to be easy to show!), but I haven't been able to prove it. I'm fairly sure that it's equivalent to show that the topology on $X$ is the same as the product topology on $V \oplus W$ (since in a preadditive category products=coproducts=biproducts) I'm interested in the result for an application to the space of test functions on a domain, which has a lot more structure than a general topological vector space (it's locally convex, locally bounded and has the Heine-Borel property but is not metrisable), so if anyone knows of/can think of a proof in that special case that would be great also.",,"['functional-analysis', 'topological-vector-spaces']"
87,Difference between $u_t + \Delta u = f$ and $u_t - \Delta u = f$?,Difference between  and ?,u_t + \Delta u = f u_t - \Delta u = f,What is the difference between these 2 equations? Instead of $\Delta$ change it to some general elliptic operator. Do they have the same results? Which one is used for which?,What is the difference between these 2 equations? Instead of $\Delta$ change it to some general elliptic operator. Do they have the same results? Which one is used for which?,,"['functional-analysis', 'partial-differential-equations']"
88,On the definition of the Hausdorff distance,On the definition of the Hausdorff distance,,"$\newcommand{\dist}{\mathrm{dist}\,}$ Let $M$ be a metric space and $\emptyset\neq A,B\subset M$ bounded closed subsets. The Hausdorff distance is defined as $$h(A,B)=\max\{\dist(A,B),\dist(B,A)\},$$ where $$\dist(A,B)=\sup_{x\in A}\inf_{y\in B}d(x,y).$$ Why do we define $\dist(A,B)$ in this way? Is't it possible to replace the supremum by the infimum in the definition of $\dist\!$, that is, define $$\dist_{\mathrm{new}}(A,B)=\inf_{x\in A}\inf_{y\in B}d(x,y).$$ What is the impact of this 'new' definition on the 'Hausdorff distance' given by $$h_{\mathrm{new}}(A,B)=\max\{\dist_{\mathrm{new}}(A,B),\dist_{\mathrm{new}}(B,A)\}?$$","$\newcommand{\dist}{\mathrm{dist}\,}$ Let $M$ be a metric space and $\emptyset\neq A,B\subset M$ bounded closed subsets. The Hausdorff distance is defined as $$h(A,B)=\max\{\dist(A,B),\dist(B,A)\},$$ where $$\dist(A,B)=\sup_{x\in A}\inf_{y\in B}d(x,y).$$ Why do we define $\dist(A,B)$ in this way? Is't it possible to replace the supremum by the infimum in the definition of $\dist\!$, that is, define $$\dist_{\mathrm{new}}(A,B)=\inf_{x\in A}\inf_{y\in B}d(x,y).$$ What is the impact of this 'new' definition on the 'Hausdorff distance' given by $$h_{\mathrm{new}}(A,B)=\max\{\dist_{\mathrm{new}}(A,B),\dist_{\mathrm{new}}(B,A)\}?$$",,"['functional-analysis', 'metric-spaces', 'definition']"
89,How to prove that $C^k(\Omega)$ is not complete,How to prove that  is not complete,C^k(\Omega),"Let $\Omega \subset\mathbb{R}^n$ be some bounded domain. And Consider the set of all k-times differentiable functions $C^k(\Omega)$. I want to prove that this set is not complete with the inner product $\langle f,g\rangle=\int\limits_{\Omega}f\cdot g\text{ } dx$. First of all, is my hypothesis right? I'm not sure about this. Furthermore i need help in finding a nice Cauchy-Sequence, which has no limit. Maybe it is easy to consider the special case $\Omega =(0,1)$ and $k=1$. But couldn't find a good C-S. yet. I hope you can help me. Regards","Let $\Omega \subset\mathbb{R}^n$ be some bounded domain. And Consider the set of all k-times differentiable functions $C^k(\Omega)$. I want to prove that this set is not complete with the inner product $\langle f,g\rangle=\int\limits_{\Omega}f\cdot g\text{ } dx$. First of all, is my hypothesis right? I'm not sure about this. Furthermore i need help in finding a nice Cauchy-Sequence, which has no limit. Maybe it is easy to consider the special case $\Omega =(0,1)$ and $k=1$. But couldn't find a good C-S. yet. I hope you can help me. Regards",,['functional-analysis']
90,Weak convergence in Sobolev spaces,Weak convergence in Sobolev spaces,,"Consider the inner product by $\langle f,g \rangle_{H^1} = \langle f, g \rangle_{L^2} + \sum_{|\alpha|=1} \langle D^\alpha f, D^\alpha g \rangle_{L^2}$ where $\alpha$ is a multi-index and $D$ denotes the weak derivative. Define $H^1(\Omega)$ as the space of functions that are finite under the norm induced from this inner product. It can be shown that $H^1(\Omega)$ is a Hilbert space. Now, suppose there exists a sequence of functions $\{ f_n \} \subset H^1(\Omega)$ that converges weakly in $H^1$ to some limit $f \in H^1(\Omega)$. Can I then say that this sequence converges weakly to the same limit under the $L^2$ inner product? By an application of the Banach-Alaoglu Theorem, I know that weak convergence of this sequence in $H^1$ will imply strong convergence of a subsequence in $H^1$. And then I think strong convergence of this subsequence in $H^1$ will imply strong convergence in $L^2$ as well. However, I'm not sure if anything can be said about the entire sequence under the $L^2$ inner product and its weak/strong convergence properties.","Consider the inner product by $\langle f,g \rangle_{H^1} = \langle f, g \rangle_{L^2} + \sum_{|\alpha|=1} \langle D^\alpha f, D^\alpha g \rangle_{L^2}$ where $\alpha$ is a multi-index and $D$ denotes the weak derivative. Define $H^1(\Omega)$ as the space of functions that are finite under the norm induced from this inner product. It can be shown that $H^1(\Omega)$ is a Hilbert space. Now, suppose there exists a sequence of functions $\{ f_n \} \subset H^1(\Omega)$ that converges weakly in $H^1$ to some limit $f \in H^1(\Omega)$. Can I then say that this sequence converges weakly to the same limit under the $L^2$ inner product? By an application of the Banach-Alaoglu Theorem, I know that weak convergence of this sequence in $H^1$ will imply strong convergence of a subsequence in $H^1$. And then I think strong convergence of this subsequence in $H^1$ will imply strong convergence in $L^2$ as well. However, I'm not sure if anything can be said about the entire sequence under the $L^2$ inner product and its weak/strong convergence properties.",,"['functional-analysis', 'sobolev-spaces', 'weak-convergence']"
91,"Is there an explicit example of a complete norm on $C[0,1]$ that is not equivalent to $\|\cdot\|_\infty$?",Is there an explicit example of a complete norm on  that is not equivalent to ?,"C[0,1] \|\cdot\|_\infty","Does anyone have an constructive, explicit example for a norm $||.||$ on $C[0,1]$ , such that $(C[0,1], ||\cdot||)$ is a Banach space, but such that $||\cdot||$ is not equivalent to $||\cdot||_{\infty}$ ? I know that if convergence in $||\cdot||$ implies pointwise convergence then it is equivalent to $||\cdot||_{\infty}$ (see https://math.stackexchange.com/q/4471871 ). There is also this result Finding norm on $C[0,1]$ , which is not equivalent to the supremum norm, but which still makes $C[0,1]$ into a separable Banach space , but it uses some isomorphism which is based on the existence of a Hamel basis, which one cannot explicit construct.","Does anyone have an constructive, explicit example for a norm on , such that is a Banach space, but such that is not equivalent to ? I know that if convergence in implies pointwise convergence then it is equivalent to (see https://math.stackexchange.com/q/4471871 ). There is also this result Finding norm on $C[0,1]$ , which is not equivalent to the supremum norm, but which still makes $C[0,1]$ into a separable Banach space , but it uses some isomorphism which is based on the existence of a Hamel basis, which one cannot explicit construct.","||.|| C[0,1] (C[0,1], ||\cdot||) ||\cdot|| ||\cdot||_{\infty} ||\cdot|| ||\cdot||_{\infty}","['functional-analysis', 'metric-spaces', 'banach-spaces', 'axiom-of-choice']"
92,How to prove a space is not separable?,How to prove a space is not separable?,,I have a general question on how to prove a space is not separable. I read some posts on this site and it seems like it suffices to find an uncountable family of pairwise disjoint open sets to prove a space is not separable. (here: The space of bounded continuous functions are not separable ) Why an uncountable family of pairwise disjoint open sets is enough?,I have a general question on how to prove a space is not separable. I read some posts on this site and it seems like it suffices to find an uncountable family of pairwise disjoint open sets to prove a space is not separable. (here: The space of bounded continuous functions are not separable ) Why an uncountable family of pairwise disjoint open sets is enough?,,['functional-analysis']
93,Show the differential operator is bounded,Show the differential operator is bounded,,"I need to show the differential operator is bounded. I believe it is bounded on $C[0,1]$ with the sup norm by 1, but I am struggling to show this. What I have so far: NTS: $\|Tf\|\leq\|T\|\|f\|$ Where: \begin{equation} \|Tf\|=\sup_{\|f\|=1}\|Tf\|=\sup_{\|f\|=1} \sup_{x\in [0,1]} |f'(x)|=\sup_{\|f\|=1} \sup_{x\in [0,1]} \left|\frac{\lim_{h\rightarrow 0} f(a+h)-f(a)}{h}\right| \end{equation} Not entirely sure if I should have written the derivative like that in the last equality above. I need a hint to see where to go next. Thanks in advance!","I need to show the differential operator is bounded. I believe it is bounded on $C[0,1]$ with the sup norm by 1, but I am struggling to show this. What I have so far: NTS: $\|Tf\|\leq\|T\|\|f\|$ Where: \begin{equation} \|Tf\|=\sup_{\|f\|=1}\|Tf\|=\sup_{\|f\|=1} \sup_{x\in [0,1]} |f'(x)|=\sup_{\|f\|=1} \sup_{x\in [0,1]} \left|\frac{\lim_{h\rightarrow 0} f(a+h)-f(a)}{h}\right| \end{equation} Not entirely sure if I should have written the derivative like that in the last equality above. I need a hint to see where to go next. Thanks in advance!",,"['functional-analysis', 'normed-spaces', 'differential-operators']"
94,Let $C$ be a convex closed nonempty subset of a Hilbert space $H$. Show that there is a unique element in $C$ with the minimum norm.,Let  be a convex closed nonempty subset of a Hilbert space . Show that there is a unique element in  with the minimum norm.,C H C,"Let $H$ be a Hilbert space and $C \subset H $ be a convex, closed and nonempty subset of $H$. Prove that there exists a unique $x_0\in C$ with minimum norm among the elements of $C$. I don't know how to prove this. I tried to consider the set $\{y\in \mathbb{R}:y=||x||, x\in C\}$, and since this set is bounded below, there exists an infimum of the set, say $s$. Then we can find a sequence $x_n\in C$ such that $s\le ||x_n|| \le s+1/n$. By the continuity of the norm function and closedness of $C$, we can find the limit of $x_n$, say, $x$ to be in $C$. But I don't know how to show that this must be unique. How can I prove this? I would greatly appreciate any help. I've come up with a solution. By convexity $\frac{1}{2}(x_1+x_2)\in C$, and so $s\le ||\frac{1}{2}(x_1+x_2)||\le 1/2||x_1||+1/2||x_2||=s$. Hence we have $||x_1+x_2||=2s$. By Parallelogram law, $||x_1+x_2||^2+||x_1-x_2||^2=2||x_1||^2+2||x_2||^2$. And so $||x_1-x_2||^2=4s^2-4s^2=0.$ Thus $x_1=x_2$.","Let $H$ be a Hilbert space and $C \subset H $ be a convex, closed and nonempty subset of $H$. Prove that there exists a unique $x_0\in C$ with minimum norm among the elements of $C$. I don't know how to prove this. I tried to consider the set $\{y\in \mathbb{R}:y=||x||, x\in C\}$, and since this set is bounded below, there exists an infimum of the set, say $s$. Then we can find a sequence $x_n\in C$ such that $s\le ||x_n|| \le s+1/n$. By the continuity of the norm function and closedness of $C$, we can find the limit of $x_n$, say, $x$ to be in $C$. But I don't know how to show that this must be unique. How can I prove this? I would greatly appreciate any help. I've come up with a solution. By convexity $\frac{1}{2}(x_1+x_2)\in C$, and so $s\le ||\frac{1}{2}(x_1+x_2)||\le 1/2||x_1||+1/2||x_2||=s$. Hence we have $||x_1+x_2||=2s$. By Parallelogram law, $||x_1+x_2||^2+||x_1-x_2||^2=2||x_1||^2+2||x_2||^2$. And so $||x_1-x_2||^2=4s^2-4s^2=0.$ Thus $x_1=x_2$.",,"['functional-analysis', 'analysis', 'hilbert-spaces', 'normed-spaces']"
95,Fundamental theorem of calculus in Sobolev Space $H^1$,Fundamental theorem of calculus in Sobolev Space,H^1,"I would like to know whether the the Fundamental theorem of calculus (Part II) can be applied in the following setting. Let $(a,b)$ be an open interval in $R^1$. Let $u \in H^1((a,b))$ with $u(a)=0$ Then, I know by Sobolev Embedding Theorem that $u$ is in fact in $C([a,b])$ Now, what I am wondering is whether I can write $u(b)= u(a)+\int^b_au'(x)dx=\int^b_au'(x)dx$ It seems true to me, but how do I actually prove it?","I would like to know whether the the Fundamental theorem of calculus (Part II) can be applied in the following setting. Let $(a,b)$ be an open interval in $R^1$. Let $u \in H^1((a,b))$ with $u(a)=0$ Then, I know by Sobolev Embedding Theorem that $u$ is in fact in $C([a,b])$ Now, what I am wondering is whether I can write $u(b)= u(a)+\int^b_au'(x)dx=\int^b_au'(x)dx$ It seems true to me, but how do I actually prove it?",,"['functional-analysis', 'sobolev-spaces']"
96,Pointwise a.e. convergence and weak convergence in Lp,Pointwise a.e. convergence and weak convergence in Lp,,"I'm trying to prove the following Theorem: Let $\{f_n\}_{n\in\mathbb N}\subset L^p(\Omega)$ , $f_n \rightharpoonup f$ in $L^p(\Omega)$ ( $\Omega\subset\mathbb{R}^n$ is open and bounded, $1\leq p \leq \infty$ ) and $f_n \to \hat{f}$ almost everywhere. Then $f=\hat{f}$ almost everywhere. Ideas for the proof: We should prove that $$\int (f-\hat{f}) =0$$ We can write $$\int (f-\hat{f}) = \int (f-f_n)+\int (f_n-\hat{f})$$ Then, by weak convergence, the first integral tends to $0$ (because $1\in L^\infty\subseteq L^p$ ). The problem is the limit of the second integral. We can write $$ \int (f_n-\hat{f})=\int_{\Omega \cap E} (f_n-\hat{f}) + \int_{\Omega\cap E^c} (f_n-\hat{f})$$ where $E=\{x: f_n(x) \not \to \hat{f}(x)\}$ . Then $|E|=0$ and the first integral vanishes. My question is: What should I do with the second integral? Is it enough if I use the Lebesgue Dominated Convergence Theorem, since by Hölder inequality I can easily dominate $\{f_n\}$ in $L^1$ ?","I'm trying to prove the following Theorem: Let , in ( is open and bounded, ) and almost everywhere. Then almost everywhere. Ideas for the proof: We should prove that We can write Then, by weak convergence, the first integral tends to (because ). The problem is the limit of the second integral. We can write where . Then and the first integral vanishes. My question is: What should I do with the second integral? Is it enough if I use the Lebesgue Dominated Convergence Theorem, since by Hölder inequality I can easily dominate in ?",\{f_n\}_{n\in\mathbb N}\subset L^p(\Omega) f_n \rightharpoonup f L^p(\Omega) \Omega\subset\mathbb{R}^n 1\leq p \leq \infty f_n \to \hat{f} f=\hat{f} \int (f-\hat{f}) =0 \int (f-\hat{f}) = \int (f-f_n)+\int (f_n-\hat{f}) 0 1\in L^\infty\subseteq L^p  \int (f_n-\hat{f})=\int_{\Omega \cap E} (f_n-\hat{f}) + \int_{\Omega\cap E^c} (f_n-\hat{f}) E=\{x: f_n(x) \not \to \hat{f}(x)\} |E|=0 \{f_n\} L^1,"['functional-analysis', 'measure-theory', 'convergence-divergence', 'weak-convergence']"
97,Dirac delta of a function with zero derivative,Dirac delta of a function with zero derivative,,"It is known that: $$\int_{-\infty}^\infty f(x) \, \delta(g(x)) \, dx =  \sum_{i}\frac{f(x_i)}{|g'(x_i)|}$$ Where $x_i$ are the roots of $g(x)$. My question is, what happens when $g'(x_i)$ is zero, but $f(x_i)$ is not? It seems that the integral on the left shoul exist irrespective of the value of $g'(x)$, so: Is there a different formula for the integral one should use in this case, or conversely, is this indeed an indicator that the integral diverges? Bounty Edit As user88595 has explained this may be a consequence of $g(x)$ not having a simple root. I'm looking for a proof or a counterexample that for any $g(x)$ which does not have a simple root at $x_i$, the integral diverges. Edit : I thought I'd give a concrete example. Let's first look at: $$\int_{-\pi/2}^{\pi/2}e^x \delta\left(\sin(x)\right)dx$$ Since $\sin x$ only has one zero in the interval, and since the derivative at zero is one, the integral is equal to $e^0=1$. Now look at: $$\int_{-\pi/2}^{\pi/2}e^x \delta\left(\sin^3(x)\right)dx$$ Which leads to infinity by the above rule (since $g'(x) = 0$), and indeed diverges. Is this the case in general?","It is known that: $$\int_{-\infty}^\infty f(x) \, \delta(g(x)) \, dx =  \sum_{i}\frac{f(x_i)}{|g'(x_i)|}$$ Where $x_i$ are the roots of $g(x)$. My question is, what happens when $g'(x_i)$ is zero, but $f(x_i)$ is not? It seems that the integral on the left shoul exist irrespective of the value of $g'(x)$, so: Is there a different formula for the integral one should use in this case, or conversely, is this indeed an indicator that the integral diverges? Bounty Edit As user88595 has explained this may be a consequence of $g(x)$ not having a simple root. I'm looking for a proof or a counterexample that for any $g(x)$ which does not have a simple root at $x_i$, the integral diverges. Edit : I thought I'd give a concrete example. Let's first look at: $$\int_{-\pi/2}^{\pi/2}e^x \delta\left(\sin(x)\right)dx$$ Since $\sin x$ only has one zero in the interval, and since the derivative at zero is one, the integral is equal to $e^0=1$. Now look at: $$\int_{-\pi/2}^{\pi/2}e^x \delta\left(\sin^3(x)\right)dx$$ Which leads to infinity by the above rule (since $g'(x) = 0$), and indeed diverges. Is this the case in general?",,"['functional-analysis', 'measure-theory', 'dirac-delta']"
98,Commutant of bounded linear operators on a Hilbert space,Commutant of bounded linear operators on a Hilbert space,,"Given a Hilbert space $H$, denote by $\mathcal{A}=\mathcal{B}(H)$ the C*-algebra of bounded linear operators on $H$. Denote further by $$\mathcal{B}(H)' := \{A\in \mathcal{B}(H) : [A,B]=0 \;\forall B \in \mathcal{B}(H)\}$$ the commutant of $\mathcal{B}(H)$. I think $\mathcal{B}(H)' = \{\lambda \mathbb{1}:\lambda \in \mathbb{C}\}$, but how can proof this? Are the elements of $\mathcal{B}(H)'$ invertible in $\mathcal{B}(H)'$? (Then my claim would follow by the Gelfand-Mazur theorem...)","Given a Hilbert space $H$, denote by $\mathcal{A}=\mathcal{B}(H)$ the C*-algebra of bounded linear operators on $H$. Denote further by $$\mathcal{B}(H)' := \{A\in \mathcal{B}(H) : [A,B]=0 \;\forall B \in \mathcal{B}(H)\}$$ the commutant of $\mathcal{B}(H)$. I think $\mathcal{B}(H)' = \{\lambda \mathbb{1}:\lambda \in \mathbb{C}\}$, but how can proof this? Are the elements of $\mathcal{B}(H)'$ invertible in $\mathcal{B}(H)'$? (Then my claim would follow by the Gelfand-Mazur theorem...)",,"['functional-analysis', 'operator-algebras']"
99,Proof of Pitt's theorem,Proof of Pitt's theorem,,I'm reading the book Topics in Banach Space Theory by Albiac F. Kalton N. J. I got stuck at the proof of Pitt's theorem. In the second paragraphs authors tries to prove ad absurdum that for weakly nuul sequence $\lim\limits_{n\to\infty}\Vert T(x_n)\Vert=0$. They say that without loss of generality one may suppose that $\{x_n\}_{n=1}^\infty$ is a weakly null sequence with $\Vert x_n\Vert=1$ and $\Vert T(x_n)\Vert>\delta$ for all $n\in\mathbb{N}$. I think they normalized original sequence $\{x_n\}_{n=1}^\infty$ and claims that it is also weakly null. Why is weakly null sequence remains weakly null after normalization? Another place I got stuck is the place where authors claims that passing to subsequence in $\{T(x_n)\}_{n=1}^\infty$ gives subsequence equivalent to the natural basis of $\ell_p$. And they also assume that after passing to subsequence $\{x_n\}_{n=1}^\infty$ remains to be equivalent to natural basis of $\ell_p$. Why is $\{x_n\}_{n=1}^\infty$ remains to be equivalent to natural basis of $\ell_p$? Thank you.,I'm reading the book Topics in Banach Space Theory by Albiac F. Kalton N. J. I got stuck at the proof of Pitt's theorem. In the second paragraphs authors tries to prove ad absurdum that for weakly nuul sequence $\lim\limits_{n\to\infty}\Vert T(x_n)\Vert=0$. They say that without loss of generality one may suppose that $\{x_n\}_{n=1}^\infty$ is a weakly null sequence with $\Vert x_n\Vert=1$ and $\Vert T(x_n)\Vert>\delta$ for all $n\in\mathbb{N}$. I think they normalized original sequence $\{x_n\}_{n=1}^\infty$ and claims that it is also weakly null. Why is weakly null sequence remains weakly null after normalization? Another place I got stuck is the place where authors claims that passing to subsequence in $\{T(x_n)\}_{n=1}^\infty$ gives subsequence equivalent to the natural basis of $\ell_p$. And they also assume that after passing to subsequence $\{x_n\}_{n=1}^\infty$ remains to be equivalent to natural basis of $\ell_p$. Why is $\{x_n\}_{n=1}^\infty$ remains to be equivalent to natural basis of $\ell_p$? Thank you.,,"['functional-analysis', 'banach-spaces', 'lp-spaces', 'compact-operators']"
