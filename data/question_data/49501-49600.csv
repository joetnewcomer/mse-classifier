,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Gauge Integral: well defined?,Gauge Integral: well defined?,,"Given a compact space $\Omega$ and a Banach space $E$ Consider functions $f:\Omega\to E$. Regard neighborhood gauges: $$\delta:\Omega\to\mathcal{T}(\Omega):\quad\delta(\omega)\in\mathcal{N}(\omega)$$ and finite measurable tagged partitions: $$\mathcal{P}^*\subseteq\mathcal{B}(\Omega):\quad\#\mathcal{P}^*<\infty$$ (In fact, the tags are just surpressed.) Order gauges by inclusion: $$\delta\leq\delta':\iff\delta(\omega)\subseteq\delta'(\omega)\quad(\omega\in\Omega)$$ and collect gauge-fine partitions: $$\mathcal{P}^*\dashv\delta:\iff A_n\subseteq\delta(a_n)\quad(A_n\in\mathcal{P}^*)$$ Denote the partial sums by: $$\mathcal{S}(\mathcal{P}^*)=\sum_nF(a_n)\lambda(A_n)$$ and define the gauge integral to be the limit: $$\int_\Omega F\mathrm{d}\lambda:=\lim_\delta\{\mathcal{S}(\mathcal{P}^*)\}_{\mathcal{P}^*\dashv\delta}$$ Why is the value assigned to a gauge integral well defined (unique)?","Given a compact space $\Omega$ and a Banach space $E$ Consider functions $f:\Omega\to E$. Regard neighborhood gauges: $$\delta:\Omega\to\mathcal{T}(\Omega):\quad\delta(\omega)\in\mathcal{N}(\omega)$$ and finite measurable tagged partitions: $$\mathcal{P}^*\subseteq\mathcal{B}(\Omega):\quad\#\mathcal{P}^*<\infty$$ (In fact, the tags are just surpressed.) Order gauges by inclusion: $$\delta\leq\delta':\iff\delta(\omega)\subseteq\delta'(\omega)\quad(\omega\in\Omega)$$ and collect gauge-fine partitions: $$\mathcal{P}^*\dashv\delta:\iff A_n\subseteq\delta(a_n)\quad(A_n\in\mathcal{P}^*)$$ Denote the partial sums by: $$\mathcal{S}(\mathcal{P}^*)=\sum_nF(a_n)\lambda(A_n)$$ and define the gauge integral to be the limit: $$\int_\Omega F\mathrm{d}\lambda:=\lim_\delta\{\mathcal{S}(\mathcal{P}^*)\}_{\mathcal{P}^*\dashv\delta}$$ Why is the value assigned to a gauge integral well defined (unique)?",,"['integration', 'measure-theory', 'lebesgue-integral']"
1,Integral computation of $\int_0^\pi \mathrm d t \sin(a\cos t/2) \mathrm{sinh}(b\sin t/2)$,Integral computation of,\int_0^\pi \mathrm d t \sin(a\cos t/2) \mathrm{sinh}(b\sin t/2),"I'm having trouble computing an integral. $$ I=\int_0^1 \frac{\mathrm{d}x}{2x(1-x)}\left(x-\cosh\left(\frac{t\sqrt{1-x}}{\tau}\right)+\sqrt{1-x}\text{ }\mathrm{sinh}\left(\frac{t\sqrt{1-x}}{\tau}\right)\right)\left(1-\cos\left(\frac{y\sqrt{x}}{2u\tau}\right)\right) $$ I tried several changes of variable, such as $x=\cos^2(\frac{\theta}{2})$: $$ I=\int_0^\pi \frac{\mathrm{d}\theta}{\sin(\theta)} \left(     \underbrace{\cos^2(\theta)-1}_{A_1}+     \underbrace{1-\cosh\left(         \frac{t}{\tau}\sin(\theta/2)         \right)}_{A_2}+     \underbrace{\sin\frac{\theta}{2}     \text{ }\mathrm{sinh}\left(         \frac{t}{\tau}\sin(\theta/2)         \right)}_{A_3}     \right) \left(     1-     \cos\left(         \frac{y}{2u\tau}\cos(\theta/2)\right)         \right) $$ The first term $A_1$ is computable, result is something with cosintegral, and is not a problem. One can consider $\frac{\mathrm d A_3}{\mathrm d y}$ and one gets: $$ \frac{\mathrm d A_3}{\mathrm d y}=\frac{1}{4u\tau} \int_0^\pi\mathrm d \theta \text{ } \mathrm{sinh}\left(         \frac{t}{\tau}\sin(\theta/2)         \right) \sin\left(         \frac{y}{2u\tau}\cos(\theta/2)\right) $$ The $A_2$ term can be transform in something very similar: $$ \frac{\mathrm d^2 A_3}{\mathrm d t\mathrm d y}=- \frac{1}{4u\tau^2} \underline{\int_0^\pi\mathrm d \theta \text{ } \mathrm{sinh}\left(         \frac{t}{\tau}\sin(\theta/2)         \right) \sin\left(         \frac{y}{2u\tau}\cos(\theta/2)\right)}_{\Large\text{this one}} $$ Has anyone any idea how to compute such an integral ? I tried looking in the handbook for mathematical functions, and found that integral representation of Kelvin functions are almost the same as my integral. I am looking for any special (or not) function that may allow me to have an analytic expression of the latter integral.","I'm having trouble computing an integral. $$ I=\int_0^1 \frac{\mathrm{d}x}{2x(1-x)}\left(x-\cosh\left(\frac{t\sqrt{1-x}}{\tau}\right)+\sqrt{1-x}\text{ }\mathrm{sinh}\left(\frac{t\sqrt{1-x}}{\tau}\right)\right)\left(1-\cos\left(\frac{y\sqrt{x}}{2u\tau}\right)\right) $$ I tried several changes of variable, such as $x=\cos^2(\frac{\theta}{2})$: $$ I=\int_0^\pi \frac{\mathrm{d}\theta}{\sin(\theta)} \left(     \underbrace{\cos^2(\theta)-1}_{A_1}+     \underbrace{1-\cosh\left(         \frac{t}{\tau}\sin(\theta/2)         \right)}_{A_2}+     \underbrace{\sin\frac{\theta}{2}     \text{ }\mathrm{sinh}\left(         \frac{t}{\tau}\sin(\theta/2)         \right)}_{A_3}     \right) \left(     1-     \cos\left(         \frac{y}{2u\tau}\cos(\theta/2)\right)         \right) $$ The first term $A_1$ is computable, result is something with cosintegral, and is not a problem. One can consider $\frac{\mathrm d A_3}{\mathrm d y}$ and one gets: $$ \frac{\mathrm d A_3}{\mathrm d y}=\frac{1}{4u\tau} \int_0^\pi\mathrm d \theta \text{ } \mathrm{sinh}\left(         \frac{t}{\tau}\sin(\theta/2)         \right) \sin\left(         \frac{y}{2u\tau}\cos(\theta/2)\right) $$ The $A_2$ term can be transform in something very similar: $$ \frac{\mathrm d^2 A_3}{\mathrm d t\mathrm d y}=- \frac{1}{4u\tau^2} \underline{\int_0^\pi\mathrm d \theta \text{ } \mathrm{sinh}\left(         \frac{t}{\tau}\sin(\theta/2)         \right) \sin\left(         \frac{y}{2u\tau}\cos(\theta/2)\right)}_{\Large\text{this one}} $$ Has anyone any idea how to compute such an integral ? I tried looking in the handbook for mathematical functions, and found that integral representation of Kelvin functions are almost the same as my integral. I am looking for any special (or not) function that may allow me to have an analytic expression of the latter integral.",,"['integration', 'definite-integrals', 'special-functions']"
2,Are the $L^p$ norms ordered by $p$?,Are the  norms ordered by ?,L^p p,A question left over from this post is: Are the $L^p$ norms ordered by $p$ like the power means are?,A question left over from this post is: Are the $L^p$ norms ordered by $p$ like the power means are?,,"['integration', 'lp-spaces', 'average']"
3,Integration of progressively measurable process,Integration of progressively measurable process,,"Let $X=\{X_{t},\cal{F}_{t}; 0\leq t<\infty\}$ be a progressively measurable process and $f(t,x):[0,\infty)\times \mathbb{R}^{d}\rightarrow \mathbb{R}$ be a bounded, $\cal{B}([0,\infty))\otimes \cal{B}(\mathbb{R}^{d})$-measurable function. Show that the process $Y_{t} =\int_{0}^{t}f(s,X_{s})ds; t\geq0$ is progressively measurable with respect to $\{\cal{F}_{t}\}$","Let $X=\{X_{t},\cal{F}_{t}; 0\leq t<\infty\}$ be a progressively measurable process and $f(t,x):[0,\infty)\times \mathbb{R}^{d}\rightarrow \mathbb{R}$ be a bounded, $\cal{B}([0,\infty))\otimes \cal{B}(\mathbb{R}^{d})$-measurable function. Show that the process $Y_{t} =\int_{0}^{t}f(s,X_{s})ds; t\geq0$ is progressively measurable with respect to $\{\cal{F}_{t}\}$",,"['integration', 'measure-theory', 'stochastic-processes']"
4,Finding non-trivial functions $f(x)$ such that $\sum_{n=1}^{\infty}f(n)=\int_{0}^1f(x)dx$,Finding non-trivial functions  such that,f(x) \sum_{n=1}^{\infty}f(n)=\int_{0}^1f(x)dx,"It is known that Atle Selberg found the following expression when he was 14 years old : $$\sum_{n=1}^{\infty}n^{-n}=\int_{0}^1x^{-x}dx.$$ Then, here is my question. Question : Find the other non-trivial functions $f(x)$ such that $$\sum_{n=1}^{\infty}f(n)=\int_{0}^1f(x)dx.\ \ \ \cdots(\star)$$ Motivation : I found the followings: Let $m$ be a natural number. Let us define a function $f(x)$ for $a\gt0$ as $$f(x)=\frac1{(x+a)^m}-\frac1{(x+a+1)^m}\ \ \ (x\ge 0).$$ I'm going to prove that for any $m\in\mathbb N$ there exists only one $a\gt 0$ such that $f(x)$ satisfies $(\star)$. 1. The $m=1$ case. We get $$\sum_{n=1}^{\infty}f(n)=\sum_{n=1}^{\infty}\left(\frac1{n+a}-\frac1{n+a+1}\right)=\frac1{a+1},$$ $$\int_{0}^1f(x)dx=[\log(x+a)-\log(x+a+1)]_0^1=-\log\left(1-\left(\frac1{a+1}\right)^2\right).$$ Hence, if there exist $0\lt u_0\lt 1$ such that $$u_0=-\log(1-{u_0}^2),$$then $f(x)$ satisfies $(\star)$ when $a=a_0={u_0}^{-1}-1$. In fact, we find that there exists only one such $u_0$ by observing  $$G(u)=-\log(1-u^2)-u\ \ (0\lt u\lt 1).$$ 2. The $m\ge 2$ case. We get  $$\sum_{n=1}^{\infty}f(n)=\frac1{(a+1)^m},$$ $$\int_{0}^1f(x)dx=\frac1{m-1}\left\{\frac1{a^{m-1}}-\frac2{(a+1)^{m-1}}+\frac1{(a+2)^{m-1}}\right\}.$$ Hence, let's prove that there exist $a\gt0$ such that $$\frac1{(a+1)^m}=\frac1{m-1}\left\{\frac1{a^{m-1}}-\frac2{(a+1)^{m-1}}+\frac1{(a+2)^{m-1}}\right\}\ \ \ \ \cdots(\star\star)$$ Letting $$h_m(a)=\frac{(a+1)^m}{a^{m-1}}+\frac{(a+1)^{m}}{(a+2)^{m-1}}-2(a+1)-(m-1),$$ then we know that  $$(\star\star)\iff h_m(a)=0.$$ However, getting $$\begin{align} h_m(a) & = \frac{(a+1)^{m}}{a^{m-1}}+\frac{((a+2)-1)^m}{(a+2)^{m-1}}-2(a+1)-(m-1) \\  & = \frac1{a^{m-1}}\sum_{k=0}^m\binom{m}{k}a^{m-k}+\frac1{(a+2)^{m-1}}\sum_{k=0}^m\binom{m}{k}(-1)^k(a+2)^{m-k}-2(a+1)-(m-1) \\   & = -(m-1)+\sum_{k=2}^m\binom{m}{k}\left\{\frac1{a^{k-1}}+\frac{(-1)^k}{(a+2)^{k-1}}\right\} \end{align}$$ tells us $$\lim_{a\to +0}h_m(a)=+\infty, \lim_{a\to +\infty}h_m(a)=-(m-1)\lt 0,$$ $$h_m^{\prime}(a)=-\sum_{k=2}^m\binom{m}{k}(k-1)\left\{\frac1{a^k}+\frac{(-1)^k}{(a+2)^k}\right\}\lt0.$$ Here, note that  $$\frac1{a^k}+\frac{(-1)^k}{(a+2)^k}\gt 0.$$ Hence, we know that there exists only one $a\gt 0$ such that $h_m(a)=0.$ Now the proof is completed. By the way, we know $a=\sqrt2$ for $m=2$. I've been looking for the other functions, but I cannot find any other function. Can anyone help?","It is known that Atle Selberg found the following expression when he was 14 years old : $$\sum_{n=1}^{\infty}n^{-n}=\int_{0}^1x^{-x}dx.$$ Then, here is my question. Question : Find the other non-trivial functions $f(x)$ such that $$\sum_{n=1}^{\infty}f(n)=\int_{0}^1f(x)dx.\ \ \ \cdots(\star)$$ Motivation : I found the followings: Let $m$ be a natural number. Let us define a function $f(x)$ for $a\gt0$ as $$f(x)=\frac1{(x+a)^m}-\frac1{(x+a+1)^m}\ \ \ (x\ge 0).$$ I'm going to prove that for any $m\in\mathbb N$ there exists only one $a\gt 0$ such that $f(x)$ satisfies $(\star)$. 1. The $m=1$ case. We get $$\sum_{n=1}^{\infty}f(n)=\sum_{n=1}^{\infty}\left(\frac1{n+a}-\frac1{n+a+1}\right)=\frac1{a+1},$$ $$\int_{0}^1f(x)dx=[\log(x+a)-\log(x+a+1)]_0^1=-\log\left(1-\left(\frac1{a+1}\right)^2\right).$$ Hence, if there exist $0\lt u_0\lt 1$ such that $$u_0=-\log(1-{u_0}^2),$$then $f(x)$ satisfies $(\star)$ when $a=a_0={u_0}^{-1}-1$. In fact, we find that there exists only one such $u_0$ by observing  $$G(u)=-\log(1-u^2)-u\ \ (0\lt u\lt 1).$$ 2. The $m\ge 2$ case. We get  $$\sum_{n=1}^{\infty}f(n)=\frac1{(a+1)^m},$$ $$\int_{0}^1f(x)dx=\frac1{m-1}\left\{\frac1{a^{m-1}}-\frac2{(a+1)^{m-1}}+\frac1{(a+2)^{m-1}}\right\}.$$ Hence, let's prove that there exist $a\gt0$ such that $$\frac1{(a+1)^m}=\frac1{m-1}\left\{\frac1{a^{m-1}}-\frac2{(a+1)^{m-1}}+\frac1{(a+2)^{m-1}}\right\}\ \ \ \ \cdots(\star\star)$$ Letting $$h_m(a)=\frac{(a+1)^m}{a^{m-1}}+\frac{(a+1)^{m}}{(a+2)^{m-1}}-2(a+1)-(m-1),$$ then we know that  $$(\star\star)\iff h_m(a)=0.$$ However, getting $$\begin{align} h_m(a) & = \frac{(a+1)^{m}}{a^{m-1}}+\frac{((a+2)-1)^m}{(a+2)^{m-1}}-2(a+1)-(m-1) \\  & = \frac1{a^{m-1}}\sum_{k=0}^m\binom{m}{k}a^{m-k}+\frac1{(a+2)^{m-1}}\sum_{k=0}^m\binom{m}{k}(-1)^k(a+2)^{m-k}-2(a+1)-(m-1) \\   & = -(m-1)+\sum_{k=2}^m\binom{m}{k}\left\{\frac1{a^{k-1}}+\frac{(-1)^k}{(a+2)^{k-1}}\right\} \end{align}$$ tells us $$\lim_{a\to +0}h_m(a)=+\infty, \lim_{a\to +\infty}h_m(a)=-(m-1)\lt 0,$$ $$h_m^{\prime}(a)=-\sum_{k=2}^m\binom{m}{k}(k-1)\left\{\frac1{a^k}+\frac{(-1)^k}{(a+2)^k}\right\}\lt0.$$ Here, note that  $$\frac1{a^k}+\frac{(-1)^k}{(a+2)^k}\gt 0.$$ Hence, we know that there exists only one $a\gt 0$ such that $h_m(a)=0.$ Now the proof is completed. By the way, we know $a=\sqrt2$ for $m=2$. I've been looking for the other functions, but I cannot find any other function. Can anyone help?",,"['integration', 'summation']"
5,Absolute values in $\int \frac{dx}{(x+2)\sqrt{(x+1)(x+3)}}$,Absolute values in,\int \frac{dx}{(x+2)\sqrt{(x+1)(x+3)}},"in my math class we were given a list of indefinite integrals, and one of them was: $$\int \frac{dx}{(x+2)\sqrt{(x+1)(x+3)}}$$ My working: $$\int \frac{dx}{(x+2)\sqrt{(x+1)(x+3)}}=\int \frac{dx}{(x+2)\sqrt{(x+2)^2-1}}$$ Then I used the substitution $x+2=\sec t$ to get: $$\int \frac{\tan t}{\sqrt{\sec^2 t-1}}dt=\int \frac{\tan t}{|\tan t|}dt= t\,\text{sgn}\, (\tan t)+C...$$ Then I checked the answer sheet, and this is what they did: $$\int \frac{\tan t}{\sqrt{\sec^2 t-1}}dt=\int dt=t+C=\text{arcsec}(x+2)+C$$ What I don't understand is, why are they allowed to say $\sqrt{\sec^2 t-1}=\tan t?$ I tried to put some values in and I have found that: $$\int_{\sec \left(\frac{8}{5}\right)-2}^{\sec \left(\frac{9}{5}\right)-2} \frac{dx}{(x+2)\sqrt{(x+1)(x+3)}}<0$$ but according to the answer sheet I would get $\dfrac{1}{5}$ My answer looks wrong, I would be happy if someone could explain what the problem is, and also why we are allowed to simplify like they did.","in my math class we were given a list of indefinite integrals, and one of them was: $$\int \frac{dx}{(x+2)\sqrt{(x+1)(x+3)}}$$ My working: $$\int \frac{dx}{(x+2)\sqrt{(x+1)(x+3)}}=\int \frac{dx}{(x+2)\sqrt{(x+2)^2-1}}$$ Then I used the substitution $x+2=\sec t$ to get: $$\int \frac{\tan t}{\sqrt{\sec^2 t-1}}dt=\int \frac{\tan t}{|\tan t|}dt= t\,\text{sgn}\, (\tan t)+C...$$ Then I checked the answer sheet, and this is what they did: $$\int \frac{\tan t}{\sqrt{\sec^2 t-1}}dt=\int dt=t+C=\text{arcsec}(x+2)+C$$ What I don't understand is, why are they allowed to say $\sqrt{\sec^2 t-1}=\tan t?$ I tried to put some values in and I have found that: $$\int_{\sec \left(\frac{8}{5}\right)-2}^{\sec \left(\frac{9}{5}\right)-2} \frac{dx}{(x+2)\sqrt{(x+1)(x+3)}}<0$$ but according to the answer sheet I would get $\dfrac{1}{5}$ My answer looks wrong, I would be happy if someone could explain what the problem is, and also why we are allowed to simplify like they did.",,"['integration', 'absolute-value', 'indefinite-integrals']"
6,"Integral $ \int\limits_{-\infty}^\infty \exp \left[-\frac{(x-x_o)^2}{2 \sigma_x^2}-i (p - p_0) \frac{x}{\hbar}\right] \, dx $",Integral," \int\limits_{-\infty}^\infty \exp \left[-\frac{(x-x_o)^2}{2 \sigma_x^2}-i (p - p_0) \frac{x}{\hbar}\right] \, dx ","Can somebody show me how to calculate this integral? $$ \int\limits_{-\infty}^\infty \exp \left[-\frac{(x-x_o)^2}{2 \sigma_x^2}-i (p - p_0) \frac{x}{\hbar}\right] \,  dx $$ $x_0$, $p_0$, $\hbar$ are constants and $\sigma_x$ is a standard deviation of the Gaussian which we are integrating here. Somebody told me that i should complete the square. EDIT: Thank you @Michael Hardy for a superb explaination. I did continue your calculation and got this: $$ \begin{split} &\phantom{=}\int\limits_{-\infty}^\infty e^{-w^2} \cdot \underbrace{\exp \, -\left\{2x_o\dfrac{\sigma_x^2 i (p-p_0)}{\hbar} - \left( \frac{\sigma_x^2 i (p-p_0)}{\hbar} \right)^2 \right\}}_{constant}\, \mathrm{d} w =\\ &= \sqrt{\pi} \exp \, \left\{- 2x_o\dfrac{\sigma_x^2 i (p-p_0)}{\hbar} + \left( \frac{\sigma_x^2 \cdot i (p-p_0)}{\hbar} \right)^2 \right\} \end{split} $$ To get this result i used Gaussian integral . What i expected to get was the result in the below picture but my result is somewhat different. Why would that be? Was my integration wrong? In the picture there are some constants before the integral which do not play any signifficant role here. Could someone explain, how author of the integral in the picture gets the result he does?","Can somebody show me how to calculate this integral? $$ \int\limits_{-\infty}^\infty \exp \left[-\frac{(x-x_o)^2}{2 \sigma_x^2}-i (p - p_0) \frac{x}{\hbar}\right] \,  dx $$ $x_0$, $p_0$, $\hbar$ are constants and $\sigma_x$ is a standard deviation of the Gaussian which we are integrating here. Somebody told me that i should complete the square. EDIT: Thank you @Michael Hardy for a superb explaination. I did continue your calculation and got this: $$ \begin{split} &\phantom{=}\int\limits_{-\infty}^\infty e^{-w^2} \cdot \underbrace{\exp \, -\left\{2x_o\dfrac{\sigma_x^2 i (p-p_0)}{\hbar} - \left( \frac{\sigma_x^2 i (p-p_0)}{\hbar} \right)^2 \right\}}_{constant}\, \mathrm{d} w =\\ &= \sqrt{\pi} \exp \, \left\{- 2x_o\dfrac{\sigma_x^2 i (p-p_0)}{\hbar} + \left( \frac{\sigma_x^2 \cdot i (p-p_0)}{\hbar} \right)^2 \right\} \end{split} $$ To get this result i used Gaussian integral . What i expected to get was the result in the below picture but my result is somewhat different. Why would that be? Was my integration wrong? In the picture there are some constants before the integral which do not play any signifficant role here. Could someone explain, how author of the integral in the picture gets the result he does?",,['integration']
7,"Given $(x_n)$, does there exist a measure such that $x_n=\int_0^1t^n d\mu$?","Given , does there exist a measure such that ?",(x_n) x_n=\int_0^1t^n d\mu,"Let $(x_n)$ be a sequence of real numbers. Does there exist a measure $\mu$ on $[0,1]$ such that $x_n=\int\limits_0^1t^nd\mu$ ?","Let $(x_n)$ be a sequence of real numbers. Does there exist a measure $\mu$ on $[0,1]$ such that $x_n=\int\limits_0^1t^nd\mu$ ?",,"['measure-theory', 'integration']"
8,Math Courses involving clever integration techniques,Math Courses involving clever integration techniques,,"I am a third year undergraduate mathematics student. I learned some basic techniques for simplifying sums in high school algebra, but I have encountered some of the more interesting techniques in my combinatorics classes and math contests. Many of my favorite techniques involve showing some sort of bijection between things. However, I feel that I have learned almost no new cool integration technique since I took the AP Calculus exam in high school. The first combinatorics book I remember reading had a large chunk devoted to interesting techniques for evaluating summations, preferably with bijective techniques. I have yet to encounter a satisfying analog for integrals. There are two main things I have had difficulty finding out much about: What ""subject"" (perhaps a course I can take, or a book I can look up) might I look into for finding a plethora of interesting techniques for calculating integrals (e.g. for summations I might take a course in combinatorics or read ""Concrete Mathematics"" by Knuth et al)? I am particularly interested in analogs for ""bijective proofs"" for integrals. Perhaps there are techniques that look for geometric interpretation of integrals that makes this possible? I often love ""bijective proofs"" because there is often almost no error-prone calculi involved. In fact, I often colloquially define ""bijective proofs"" this way--as any method of proof in which the solution becomes obvious from interpreting the problem in more than one way. I don't know how useful it would be to calculate interesting (definite or indefinite) integrals, but I feel like it would be a fun endeavor to look into, and as a start I'd like to know what is considered ""commonly known"".","I am a third year undergraduate mathematics student. I learned some basic techniques for simplifying sums in high school algebra, but I have encountered some of the more interesting techniques in my combinatorics classes and math contests. Many of my favorite techniques involve showing some sort of bijection between things. However, I feel that I have learned almost no new cool integration technique since I took the AP Calculus exam in high school. The first combinatorics book I remember reading had a large chunk devoted to interesting techniques for evaluating summations, preferably with bijective techniques. I have yet to encounter a satisfying analog for integrals. There are two main things I have had difficulty finding out much about: What ""subject"" (perhaps a course I can take, or a book I can look up) might I look into for finding a plethora of interesting techniques for calculating integrals (e.g. for summations I might take a course in combinatorics or read ""Concrete Mathematics"" by Knuth et al)? I am particularly interested in analogs for ""bijective proofs"" for integrals. Perhaps there are techniques that look for geometric interpretation of integrals that makes this possible? I often love ""bijective proofs"" because there is often almost no error-prone calculi involved. In fact, I often colloquially define ""bijective proofs"" this way--as any method of proof in which the solution becomes obvious from interpreting the problem in more than one way. I don't know how useful it would be to calculate interesting (definite or indefinite) integrals, but I feel like it would be a fun endeavor to look into, and as a start I'd like to know what is considered ""commonly known"".",,"['integration', 'intuition', 'summation']"
9,Riemann integrable and continuous almost everywhere.,Riemann integrable and continuous almost everywhere.,,"I want a proof for this theorem: Let $f$ be a function on $[a,b]$. Then $f$ is Riemann integrable if and only if $f$ is bounded and continuous almost everywhere.","I want a proof for this theorem: Let $f$ be a function on $[a,b]$. Then $f$ is Riemann integrable if and only if $f$ is bounded and continuous almost everywhere.",,['integration']
10,Laplace integral and leading order behavior,Laplace integral and leading order behavior,,"Consider the integral: $$ \int_0^{\pi/2}\sqrt{\sin t}e^{-x\sin^4 t} \, dt $$ I'm trying to use Laplace's method to find its leading asymptotic behavior as $x\rightarrow\infty$, but I'm running into problems because the maximum of $\phi(t)$ (i.e. $-\sin^{4}t$) is $0$ and occurs at $0$ (call this $c$).  In my notes on the Laplace Method, it specifically demands that $f(c)$ (in this case $f(t)=\sqrt{\sin t}$) cannot equal zero--but it does. How do I get around this?","Consider the integral: $$ \int_0^{\pi/2}\sqrt{\sin t}e^{-x\sin^4 t} \, dt $$ I'm trying to use Laplace's method to find its leading asymptotic behavior as $x\rightarrow\infty$, but I'm running into problems because the maximum of $\phi(t)$ (i.e. $-\sin^{4}t$) is $0$ and occurs at $0$ (call this $c$).  In my notes on the Laplace Method, it specifically demands that $f(c)$ (in this case $f(t)=\sqrt{\sin t}$) cannot equal zero--but it does. How do I get around this?",,"['integration', 'asymptotics', 'laplace-method']"
11,"Verifying $\int_0^\pi  \sin(x) /2(\sin(x/(2n+1)) \,dx \leq \pi$",Verifying,"\int_0^\pi  \sin(x) /2(\sin(x/(2n+1)) \,dx \leq \pi","I'm having trouble verifying this inequality.  It goes like this (appears in Giaquinta, Mathematical analysis, linear and metric structures, page 445): $$ \int_{0}^{\pi} \cfrac{\sin(x)}{\sin\left(\frac{x}{2n+1}\right)} dx \leq\frac{ 2(n+1)\pi}{2n+1} \leq 2\pi $$ Of course, the last inequality is obvious.  The first one, however, I can't show.  I've tried bounding $\sin(x)$ by $1$, and then calculating the integral with mathematica, but it comes out unbounded.  When I put $n=1,2,3...$ or any finite number in mathematica, the result is numerically true, but I want to show this for any ""$n$"", and mathematica gives me a very complicated function (depending on $n$) with imaginary units and hypergeometric functions.  I guess I'm missing out a very simple argument here.  Any ideas? Edit: I have edited so that the formula is identical to the one of the book.","I'm having trouble verifying this inequality.  It goes like this (appears in Giaquinta, Mathematical analysis, linear and metric structures, page 445): $$ \int_{0}^{\pi} \cfrac{\sin(x)}{\sin\left(\frac{x}{2n+1}\right)} dx \leq\frac{ 2(n+1)\pi}{2n+1} \leq 2\pi $$ Of course, the last inequality is obvious.  The first one, however, I can't show.  I've tried bounding $\sin(x)$ by $1$, and then calculating the integral with mathematica, but it comes out unbounded.  When I put $n=1,2,3...$ or any finite number in mathematica, the result is numerically true, but I want to show this for any ""$n$"", and mathematica gives me a very complicated function (depending on $n$) with imaginary units and hypergeometric functions.  I guess I'm missing out a very simple argument here.  Any ideas? Edit: I have edited so that the formula is identical to the one of the book.",,"['trigonometry', 'inequality', 'integration']"
12,Is this a correct proof that all rational functions are integrable?,Is this a correct proof that all rational functions are integrable?,,"Is this a correct proof that all rational functions are integrable? I could be horribly wrong, but here goes: First, by trivial inspection, an $n$th degree polynomial is integrable: $$\begin{align} \int p(x) dx&=\int \sum_{i=0}^{n}\alpha_ix^i dx\\ &=\sum_{i=0}^{n}\alpha_i\int x^i dx\\ &=\sum_{i=0}^{n}\frac{\alpha_i}{i+1}x^{i+1}+C\\ \end{align} $$ Now, define: $$r(x)=\sum_{i=0}^{n}c_ix^i \text{ and } s(x)=\sum_{i=0}^{m}\gamma_ix^i$$ By the fundamental theorem of algebra, $$r(x)=c_n\prod_{i=1}^{n}(x-r_i) \text{ and } s(x)=\gamma_n\prod_{i=1}^{m}(x-\phi_i)$$ where $r_i$ and $\phi_i$ are the real (and complex, if they exist) roots of $r(x)$ and $s(x)$, respectively. Now, proving that a fraction of polynomials is integrable: $$\begin{align} \int \frac{r(x)}{s(x)} dx&=\int \frac{c_n(x-r_1)\cdots(x-r_n)}{\gamma_n(x-\phi_1)\cdots(x-\phi_m)}dx\\ &=\frac{c_n}{\gamma_n}\int\frac{(x-r_1)\cdots(x-r_n)}{(x-\phi_1)\cdots(x-\phi_m)} dx \end{align}$$ Suppose: $$ \frac{(x-r_1)\cdots(x-r_n)}{(x-\phi_1)\cdots(x-\phi_m)}=\frac{K_1}{x-\phi_1}+\frac{K_2}{x-\phi_2}+\dots+\frac{K_{m-1}}{x-\phi_{m-1}}+\frac{K_m}{x-\phi_m} \text{ where } K_i \in \mathbb{C} $$ Then: $$\begin{align} \int \frac{r(x)}{s(x)} dx&=\frac{c_n}{\gamma_n}\int \sum_{i=1}^{m}\frac{K_i}{x-\phi_i} dx\\ &=\frac{c_n}{\gamma_n}\sum_{i=1}^{m}K_i\int \frac{1}{x-\phi_i} dx\\ &=\frac{c_n}{\gamma_n}\sum_{i=1}^{m}K_i \log(x-\phi_i)+C \end{align}$$ I guess my issue here is: How do I know that the set of $K$'s exist? (By set of $K$'s, I mean exactly that elements of the set $\{K_1,K_2,\dots,K_{m-1},K_{m}\}$ exist.) And, how do I know that these elements are complex numbers rather than polynomials themselves? It has been clarified by Robert Israel that my use of terminology is incorrect. What I am proving is that rational functions are integrable in closed form, not that polynomials are integrable. It has also been clarified that this proof is valid if and only if $s(x)$ does not have repeated roots ($\phi_i=\phi_j \text{ for } i\neq j$) and that the degree of $s(x)$ is less than the degree of $r(x)$. An attempt at a general proof: Let $v(x)$ and $w(x)$ be two polynomials. ($\deg v>\deg w$) Now, define the following rational function: $$\mathfrak{J}(x)=\frac{v(x)}{w(x)}$$ \begin{align} \int \mathfrak{J}(x)\,dx&=\int \frac{v(x)}{w(x)}\,dx\\ \frac{v(x)}{w(x)}&=q(x)+\frac{r(x)}{w(x)} \quad \deg r<\deg w\\ &=\int q(x)+\frac{r(x)}{w(x)}\,dx\\ &=\int q(x)\,dx+\int\frac{r(x)}{w(x)}\,dx\\ &=\mathfrak{a}(x)+\int\frac{r(x)}{w(x)}\,dx\\ r(x)&=\sum_{i=1}^{n}c_ix^i\\ \int\frac{r(x)}{w(x)}&=\int \frac{c_nx^n}{w(x)}+\dots+\int \frac{c_0}{w(x)}\\ \int \frac{c_ix^i}{w(x)}&=\int \frac{k_{1,i}}{(x-r_1)^{\alpha_1}}+\dots+\int\frac{k_{m,i}}{(x-r_m)^{\alpha_m}}\\ &=k_{1,i}\int \frac{1}{(x-r_1)^{\alpha_1}}+\dots+k_{m,i}\int\frac{1}{(x-r_m)^{\alpha_m}}\\ &=k_{1,i}p_{1,i}(x)+\dots+k_{m,i}p_{m,i}(x)\\ &=\sum_{j=1}^{m}k_{j,i}p_{j,i}(x)\\ \int\frac{r(x)}{w(x)}&=\sum_{j=1}^{m}k_{j,n}p_{j,n}(x)+\dots+\sum_{q=1}^{m}k_{q,0}p_{q,0}(x)\\ &=\sum_{\alpha=0}^{n}\sum_{\beta=1}^{m}k_{\beta,\alpha}p_{\beta,\alpha}(x)\\ \mathfrak{b}(x)&=\sum_{\alpha=0}^{n}\sum_{\beta=1}^{m}k_{\beta,\alpha}p_{\beta,\alpha}(x) \end{align} $$\therefore \int\mathfrak{J}(x)\,dx=\mathfrak{a}(x)+\mathfrak{b}(x)$$ There is obviously a lot of details left out; but do I need them?","Is this a correct proof that all rational functions are integrable? I could be horribly wrong, but here goes: First, by trivial inspection, an $n$th degree polynomial is integrable: $$\begin{align} \int p(x) dx&=\int \sum_{i=0}^{n}\alpha_ix^i dx\\ &=\sum_{i=0}^{n}\alpha_i\int x^i dx\\ &=\sum_{i=0}^{n}\frac{\alpha_i}{i+1}x^{i+1}+C\\ \end{align} $$ Now, define: $$r(x)=\sum_{i=0}^{n}c_ix^i \text{ and } s(x)=\sum_{i=0}^{m}\gamma_ix^i$$ By the fundamental theorem of algebra, $$r(x)=c_n\prod_{i=1}^{n}(x-r_i) \text{ and } s(x)=\gamma_n\prod_{i=1}^{m}(x-\phi_i)$$ where $r_i$ and $\phi_i$ are the real (and complex, if they exist) roots of $r(x)$ and $s(x)$, respectively. Now, proving that a fraction of polynomials is integrable: $$\begin{align} \int \frac{r(x)}{s(x)} dx&=\int \frac{c_n(x-r_1)\cdots(x-r_n)}{\gamma_n(x-\phi_1)\cdots(x-\phi_m)}dx\\ &=\frac{c_n}{\gamma_n}\int\frac{(x-r_1)\cdots(x-r_n)}{(x-\phi_1)\cdots(x-\phi_m)} dx \end{align}$$ Suppose: $$ \frac{(x-r_1)\cdots(x-r_n)}{(x-\phi_1)\cdots(x-\phi_m)}=\frac{K_1}{x-\phi_1}+\frac{K_2}{x-\phi_2}+\dots+\frac{K_{m-1}}{x-\phi_{m-1}}+\frac{K_m}{x-\phi_m} \text{ where } K_i \in \mathbb{C} $$ Then: $$\begin{align} \int \frac{r(x)}{s(x)} dx&=\frac{c_n}{\gamma_n}\int \sum_{i=1}^{m}\frac{K_i}{x-\phi_i} dx\\ &=\frac{c_n}{\gamma_n}\sum_{i=1}^{m}K_i\int \frac{1}{x-\phi_i} dx\\ &=\frac{c_n}{\gamma_n}\sum_{i=1}^{m}K_i \log(x-\phi_i)+C \end{align}$$ I guess my issue here is: How do I know that the set of $K$'s exist? (By set of $K$'s, I mean exactly that elements of the set $\{K_1,K_2,\dots,K_{m-1},K_{m}\}$ exist.) And, how do I know that these elements are complex numbers rather than polynomials themselves? It has been clarified by Robert Israel that my use of terminology is incorrect. What I am proving is that rational functions are integrable in closed form, not that polynomials are integrable. It has also been clarified that this proof is valid if and only if $s(x)$ does not have repeated roots ($\phi_i=\phi_j \text{ for } i\neq j$) and that the degree of $s(x)$ is less than the degree of $r(x)$. An attempt at a general proof: Let $v(x)$ and $w(x)$ be two polynomials. ($\deg v>\deg w$) Now, define the following rational function: $$\mathfrak{J}(x)=\frac{v(x)}{w(x)}$$ \begin{align} \int \mathfrak{J}(x)\,dx&=\int \frac{v(x)}{w(x)}\,dx\\ \frac{v(x)}{w(x)}&=q(x)+\frac{r(x)}{w(x)} \quad \deg r<\deg w\\ &=\int q(x)+\frac{r(x)}{w(x)}\,dx\\ &=\int q(x)\,dx+\int\frac{r(x)}{w(x)}\,dx\\ &=\mathfrak{a}(x)+\int\frac{r(x)}{w(x)}\,dx\\ r(x)&=\sum_{i=1}^{n}c_ix^i\\ \int\frac{r(x)}{w(x)}&=\int \frac{c_nx^n}{w(x)}+\dots+\int \frac{c_0}{w(x)}\\ \int \frac{c_ix^i}{w(x)}&=\int \frac{k_{1,i}}{(x-r_1)^{\alpha_1}}+\dots+\int\frac{k_{m,i}}{(x-r_m)^{\alpha_m}}\\ &=k_{1,i}\int \frac{1}{(x-r_1)^{\alpha_1}}+\dots+k_{m,i}\int\frac{1}{(x-r_m)^{\alpha_m}}\\ &=k_{1,i}p_{1,i}(x)+\dots+k_{m,i}p_{m,i}(x)\\ &=\sum_{j=1}^{m}k_{j,i}p_{j,i}(x)\\ \int\frac{r(x)}{w(x)}&=\sum_{j=1}^{m}k_{j,n}p_{j,n}(x)+\dots+\sum_{q=1}^{m}k_{q,0}p_{q,0}(x)\\ &=\sum_{\alpha=0}^{n}\sum_{\beta=1}^{m}k_{\beta,\alpha}p_{\beta,\alpha}(x)\\ \mathfrak{b}(x)&=\sum_{\alpha=0}^{n}\sum_{\beta=1}^{m}k_{\beta,\alpha}p_{\beta,\alpha}(x) \end{align} $$\therefore \int\mathfrak{J}(x)\,dx=\mathfrak{a}(x)+\mathfrak{b}(x)$$ There is obviously a lot of details left out; but do I need them?",,"['polynomials', 'integration', 'rational-functions']"
13,Projection of Gaussian in Spherical Coordinates,Projection of Gaussian in Spherical Coordinates,,"Consider a point with spherical coordinates $\vec{r}_0=(r_0, \theta_0, 0)$. The spherical gaussian distribution centered at $\vec{r}_0$ is $f(\vec{r})=Ne^{|\vec{r}-\vec{r}_0|^2/A}$, where $N$ is the normalizing factor and $A$ is a measure of the spread. I am interested in the projection of $f$ onto the $\theta$ coordinate, $f_\theta(\theta)=\int_0^\infty\int_0^{2\pi} f(\vec{r})r\sin\theta\,d\phi\,dr$. Using the euclidean distance formula $\sqrt{(x-x_0)^2 + (y-y_0)^2+(z-z_0)^2}$ and substituting in the cartesian coordinates for $\vec{r}=(r,\theta,\phi)$ with  $$x=r\cos\phi\sin\theta\;;\;y=r\sin\phi\sin\theta\;;\;z=r\cos\theta$$ and similarly for $\vec{r}_0$ with $$x_0=r_0\sin\theta_0\; ; \; y_0=0\;;\;z_0=r\cos\theta.$$ Then $$f(\vec{r})=Ne^{(-r^2+2rr_0(\cos\phi\sin\theta\sin\theta_0+\cos\theta\cos\theta_0)-r_0^2)/A},$$ so  $$f_\theta(\theta)=\int_0^\infty\int_0^{2\pi} Ne^{(-r^2+2rr_0(\cos\phi\sin\theta\sin\theta_0+\cos\theta\cos\theta_0)-r_0^2)/A}r\sin\theta\,d\phi\,dr.$$ Using the fact that $\int_0^{2\pi}e^{x\cos\phi}=2\pi I_0(x)$, where $I_0(x)$ is the modified Bessel function of the first kind, I can simplify $f_\theta(\theta)$ to  $$f_\theta(\theta)=N\sin\theta2\pi e^{-r_0^2/A}\int_0^\infty e^{(-r^2+2rr_0\cos\theta\cos\theta_0)/A}I_0(2rr_0\sin\theta\sin\theta_0/A)r\,dr$$ Is there a way to evaluate this integral further? I will ultimately be using this as a kernel for kernel density estimation. If it is not possible to further evaluate the integral, I would be happy with an approximate evaluation as long as I will be able to implement it and it was not prohibitively inefficient to evaluate.","Consider a point with spherical coordinates $\vec{r}_0=(r_0, \theta_0, 0)$. The spherical gaussian distribution centered at $\vec{r}_0$ is $f(\vec{r})=Ne^{|\vec{r}-\vec{r}_0|^2/A}$, where $N$ is the normalizing factor and $A$ is a measure of the spread. I am interested in the projection of $f$ onto the $\theta$ coordinate, $f_\theta(\theta)=\int_0^\infty\int_0^{2\pi} f(\vec{r})r\sin\theta\,d\phi\,dr$. Using the euclidean distance formula $\sqrt{(x-x_0)^2 + (y-y_0)^2+(z-z_0)^2}$ and substituting in the cartesian coordinates for $\vec{r}=(r,\theta,\phi)$ with  $$x=r\cos\phi\sin\theta\;;\;y=r\sin\phi\sin\theta\;;\;z=r\cos\theta$$ and similarly for $\vec{r}_0$ with $$x_0=r_0\sin\theta_0\; ; \; y_0=0\;;\;z_0=r\cos\theta.$$ Then $$f(\vec{r})=Ne^{(-r^2+2rr_0(\cos\phi\sin\theta\sin\theta_0+\cos\theta\cos\theta_0)-r_0^2)/A},$$ so  $$f_\theta(\theta)=\int_0^\infty\int_0^{2\pi} Ne^{(-r^2+2rr_0(\cos\phi\sin\theta\sin\theta_0+\cos\theta\cos\theta_0)-r_0^2)/A}r\sin\theta\,d\phi\,dr.$$ Using the fact that $\int_0^{2\pi}e^{x\cos\phi}=2\pi I_0(x)$, where $I_0(x)$ is the modified Bessel function of the first kind, I can simplify $f_\theta(\theta)$ to  $$f_\theta(\theta)=N\sin\theta2\pi e^{-r_0^2/A}\int_0^\infty e^{(-r^2+2rr_0\cos\theta\cos\theta_0)/A}I_0(2rr_0\sin\theta\sin\theta_0/A)r\,dr$$ Is there a way to evaluate this integral further? I will ultimately be using this as a kernel for kernel density estimation. If it is not possible to further evaluate the integral, I would be happy with an approximate evaluation as long as I will be able to implement it and it was not prohibitively inefficient to evaluate.",,"['integration', 'special-functions', 'approximation', 'spherical-coordinates']"
14,What is the functional space of (general) Wavelet transform of squared-integrable functions?,What is the functional space of (general) Wavelet transform of squared-integrable functions?,,"Let $\psi(x) = \exp(-x^2)$ . The (general) Wavelet transform $W: L^2(\mathbb R) \rightarrow X$ is  defined by $$Wf(a, b) = b^{-1/2}\int_{x\in \mathbb R} f(x) \psi\left( \frac{x-a}{b}\right)dx$$ for $(a, b) \in \mathbb R_+ \times \mathbb R$ . My question is: What is the functional space $X$ ? NOTE: Note that the function $\psi$ above is a Gaussian-like function, which is not exactly a wavelet function. In general, a function $\psi$ is called a wavelet function if it satisfies 1) $\psi$ has compact support or at least fast decaying at infinity and 2) $\int_{x \in \mathbb R} \psi(x) dx=0$ . The given function $\psi$ however only satisfies the first requirement. We therefore refer it as a ""general"" Wavelet transformation. To have a clue for our question. Let's us consider a particular case, when $b=b_0$ is constant, then $Wf$ is just a function of $a$ . In this case $$Wf \in X = C_0(\mathbb R).$$ Indeed, in this case, one can see that $Wf = b_0^{-1/2} f\star \psi(\cdot/b_0)$ , i.e. $W$ is a simply a convolution operator. A (well-known?) fundamental result states that: The convolution operator of two $L^2$ functions is $C_0$ . Hence $ Wf\in C_0(\mathbb R)$ . For the original question, numerical simulations also suggest that $X=C_0(\mathbb R_+\times \mathbb R)$ . It it correct?","Let . The (general) Wavelet transform is  defined by for . My question is: What is the functional space ? NOTE: Note that the function above is a Gaussian-like function, which is not exactly a wavelet function. In general, a function is called a wavelet function if it satisfies 1) has compact support or at least fast decaying at infinity and 2) . The given function however only satisfies the first requirement. We therefore refer it as a ""general"" Wavelet transformation. To have a clue for our question. Let's us consider a particular case, when is constant, then is just a function of . In this case Indeed, in this case, one can see that , i.e. is a simply a convolution operator. A (well-known?) fundamental result states that: The convolution operator of two functions is . Hence . For the original question, numerical simulations also suggest that . It it correct?","\psi(x) = \exp(-x^2) W: L^2(\mathbb R) \rightarrow X Wf(a, b) = b^{-1/2}\int_{x\in \mathbb R} f(x) \psi\left( \frac{x-a}{b}\right)dx (a, b) \in \mathbb R_+ \times \mathbb R X \psi \psi \psi \int_{x \in \mathbb R} \psi(x) dx=0 \psi b=b_0 Wf a Wf \in X = C_0(\mathbb R). Wf = b_0^{-1/2} f\star \psi(\cdot/b_0) W L^2 C_0  Wf\in C_0(\mathbb R) X=C_0(\mathbb R_+\times \mathbb R)","['integration', 'functional-analysis', 'operator-theory', 'convolution', 'wavelets']"
15,Confused regarding Terence Tao's proof of Tonelli's Theorem,Confused regarding Terence Tao's proof of Tonelli's Theorem,,"I am struggling with Tao's proof of Tonelli's Theorem perhaps, admittedly, due to not having properly studied all the previous material regarding product measures in his book on the topic. I'd appreciate any help understanding any of the steps in the proof I am confused by. Theorem 1.7.15 (Tonelli’s theorem, incomplete version). Let $(X, B_X, \mu_X)$ and $(Y, B_Y , \mu_Y )$ be $\sigma$ -finite measure spaces, and let $f : X \times Y \to [0, +\infty]$ be measurable with respect to $B_X \times B_Y$ . Then: (i) The functions $x\mapsto \int_Y f(x,y)d\mu_Y$ and $y\mapsto \int _X f(x,y) d\mu_X$ are measurable with respect to $B_X$ and $B_Y$ respectively. (ii) We have $$\int_{X\times Y} f(x,y) \ d(\mu_X\times\mu_Y) = \int_Y\left(\int_X f(x,y) \ d\mu_X\right)d\mu_Y.$$ Proof: By writing the $\sigma$ -finite space $X$ as an increasing union $X = \cup_{n=1}^{\infty} X_n$ of finite measure sets, we see from several applications of the monotone convergence theorem (Theorem 1.4.44) that it suffices to prove the claims with $X$ replaced by $X_n$ . Thus we may assume without loss of generality that $X$ has finite measure. Similarly we may assume $Y$ has finite measure. Note from (1.36) that this implies that $X × Y$ has finite measure also. Q1: why does it suffice to show the result for $X$ replaced by $X_n$ ? I do not even understand how replacing $X$ with $X_n$ allows us to use the monotone convergence theorem. However, letting $X'_n=\cup_{i=1}^nX_i$ and, $Y'_n=\cup_{i=1}^nY_i$ we get $$f = \lim_{n\to \infty}f\ 1_{X'_n\times Y'n},$$ and the monotone convergence theorem can be applied, yet -if this is what Tao means- how may we use the monotone convergence theorem to conclude the result holds for $f$ given that it holds for any $f\ 1_{X'_n\times Y'n}$ ? Every unsigned measurable function is the increasing limit of unsigned simple functions. By several applications of the monotone convergence theorem (Theorem 1.4.44), we thus see that it suffices to verify the claim when $f$ is a simple function. By linearity, it then suffices to verify the claim when $f$ is an indicator function, thus $f = 1_S$ for some $S \in B_X × B_Y$ . Q2: why is every unsigned measurable function the increasing limit of simple unsigned measurable functions? Let $C$ be the set of all $S \in B_X × B_Y$ for which the claims hold. From the repeated applications of the monotone convergence theorem (Theorem 1.4.44) and the downward monotone convergence theorem (which is available in this finite measure setting) we see that C is a monotone class. Q3: Let $A_1\subseteq A_2 \subseteq \ldots $ all be members of $C$ , let $A'_n = \cup_{i=1}^nA_n$ and $A = \cup_{i=1}^{\infty}A_n$ . Since $$1_A = \lim_{n\to \infty}1_{A'_n}$$ we may apply the monotone convergence theorem to conclude that $C$ is closed under countable monotone unions. However, I do know how to show that $C$ is closed under countable monotone intersections. By direct computation (using (1.36)), we see that $C$ contains as an element any product $S = E × F$ with $E \in B_X$ and $F \in B_Y$ . By finite additivity, we conclude that $C$ also contains as an element any a disjoint finite union $S = E_1×F_1∪\ldots ∪E_k×F_k$ of such products. This implies that $C$ also contains the Boolean algebra $B_0$ in the proof of Proposition 1.7.11, as such sets can always be expressed as the disjoint finite union of Cartesian products of measurable sets. Applying the monotone class lemma, we conclude that $C$ contains $\langle B_0\rangle = B_X × B_Y$ , and the claim follows. Q4: The algebra $B_0$ is the collection of all finite unions $$E_1\times F_1 \cup \ldots \cup E_n\times F_n$$ of $B_X$ -measurable sets $E_k$ and $B_Y$ -measurable sets $F_k$ . How does one show $B_0$ is closed under complements and finite intersections?","I am struggling with Tao's proof of Tonelli's Theorem perhaps, admittedly, due to not having properly studied all the previous material regarding product measures in his book on the topic. I'd appreciate any help understanding any of the steps in the proof I am confused by. Theorem 1.7.15 (Tonelli’s theorem, incomplete version). Let and be -finite measure spaces, and let be measurable with respect to . Then: (i) The functions and are measurable with respect to and respectively. (ii) We have Proof: By writing the -finite space as an increasing union of finite measure sets, we see from several applications of the monotone convergence theorem (Theorem 1.4.44) that it suffices to prove the claims with replaced by . Thus we may assume without loss of generality that has finite measure. Similarly we may assume has finite measure. Note from (1.36) that this implies that has finite measure also. Q1: why does it suffice to show the result for replaced by ? I do not even understand how replacing with allows us to use the monotone convergence theorem. However, letting and, we get and the monotone convergence theorem can be applied, yet -if this is what Tao means- how may we use the monotone convergence theorem to conclude the result holds for given that it holds for any ? Every unsigned measurable function is the increasing limit of unsigned simple functions. By several applications of the monotone convergence theorem (Theorem 1.4.44), we thus see that it suffices to verify the claim when is a simple function. By linearity, it then suffices to verify the claim when is an indicator function, thus for some . Q2: why is every unsigned measurable function the increasing limit of simple unsigned measurable functions? Let be the set of all for which the claims hold. From the repeated applications of the monotone convergence theorem (Theorem 1.4.44) and the downward monotone convergence theorem (which is available in this finite measure setting) we see that C is a monotone class. Q3: Let all be members of , let and . Since we may apply the monotone convergence theorem to conclude that is closed under countable monotone unions. However, I do know how to show that is closed under countable monotone intersections. By direct computation (using (1.36)), we see that contains as an element any product with and . By finite additivity, we conclude that also contains as an element any a disjoint finite union of such products. This implies that also contains the Boolean algebra in the proof of Proposition 1.7.11, as such sets can always be expressed as the disjoint finite union of Cartesian products of measurable sets. Applying the monotone class lemma, we conclude that contains , and the claim follows. Q4: The algebra is the collection of all finite unions of -measurable sets and -measurable sets . How does one show is closed under complements and finite intersections?","(X, B_X, \mu_X) (Y, B_Y , \mu_Y ) \sigma f : X \times Y \to [0, +\infty] B_X \times B_Y x\mapsto \int_Y f(x,y)d\mu_Y y\mapsto \int _X f(x,y) d\mu_X B_X B_Y \int_{X\times Y} f(x,y) \ d(\mu_X\times\mu_Y) = \int_Y\left(\int_X f(x,y) \ d\mu_X\right)d\mu_Y. \sigma X X = \cup_{n=1}^{\infty} X_n X X_n X Y X × Y X X_n X X_n X'_n=\cup_{i=1}^nX_i Y'_n=\cup_{i=1}^nY_i f = \lim_{n\to \infty}f\ 1_{X'_n\times Y'n}, f f\ 1_{X'_n\times Y'n} f f f = 1_S S \in B_X × B_Y C S \in B_X × B_Y A_1\subseteq A_2 \subseteq \ldots  C A'_n = \cup_{i=1}^nA_n A = \cup_{i=1}^{\infty}A_n 1_A = \lim_{n\to \infty}1_{A'_n} C C C S = E × F E \in B_X F \in B_Y C S = E_1×F_1∪\ldots ∪E_k×F_k C B_0 C \langle B_0\rangle = B_X × B_Y B_0 E_1\times F_1 \cup \ldots \cup E_n\times F_n B_X E_k B_Y F_k B_0","['integration', 'lebesgue-integral', 'lebesgue-measure']"
16,Integrating product of Dirac deltas and step functions,Integrating product of Dirac deltas and step functions,,"I have the following integral $$\int d^4\boldsymbol{x}' \,\delta\big[(\boldsymbol{x}-\boldsymbol{x'})^2+\alpha^2\big]\,\Theta(-x_0+x'_0)\,\delta\big[(\boldsymbol{x'})^2+\alpha^2\big]\,\Theta(-x_0'),\tag{1}\label{1}$$ where $\boldsymbol{x}=\{x_0,x_1,x_2,x_3\}$ , the square is $(x')^2=x_\mu'\cdot x'^{\mu}$ , and the metric convention used is $\{-1,1,1,1\}.$ First I wanted to do it in the limit $\alpha\to0$ , where then I used the second dirac delta and theta function to impose $$x_0'=-\sqrt{(x_1')^2+(x_2')^2+(x_3')^2}.$$ Then performing the first integral over $dx_0'$ we would end up with $$\int d^3\boldsymbol{x}'\,\frac{\delta\big[\boldsymbol{x}^2-2x_0\sqrt{(x_1')^2+(x_2')^2+(x_3')^2}-2x^1  x_1'-2x^2  x_2'-2x^3  x_3'\big]}{2\sqrt{2}\sqrt{(x_1')^2+(x_2')^2+(x_3')^2}}\,\times\Theta\bigg(-x_0-\sqrt{(x_1')^2+(x_2')^2+(x_3')^2}\bigg),\tag{2}\label{2}$$ where the denominator came from the expansion of the second dirac delta via $$\int_{\mathbb{R}^n}f(x)\,\delta\big(g(x)\big)dx=\int_{g^{-1}(0)} \frac{f(x)}{|\nabla g|}d\sigma(x).\tag{3}\label{3}$$ This is not a very nice expression to work with so then I tried to go to spherical coordinates, however this ran into some issues. I tried $$\int dr'\int d\phi_1 d\phi_2\,\times\frac{(r')^2\,\text{sin}(\phi_1)}{2\sqrt{2}\,r'}\delta\big[\boldsymbol{x}^2-2r'\big(x_0+x_1 \text{sin}(\phi_1) \text{cos}(\phi_2)+x_2 \text{sin}(\phi_1) \text{sin}(\phi_2)+x_3 \text{cos}(\phi_1)\big)\big]\,\times\Theta\big(-x_0-r'\big),\tag{4}\label{4}$$ I don't think this factor of $r'$ should be there, as the final result should be proportional to ( updated 28/09 ) $\Theta\big(-x_0-\sqrt{x_1^2+x_2^2+x_3^2}\big)$ . Furthermore, since we normally have $$\delta(\boldsymbol{x}-\boldsymbol{x}_0)=\frac{1}{r^2\text{sin}(\phi_1)}\delta(r-r_0)\delta(\phi-\phi_0)\delta(\theta-\theta_0),\tag{6}\label{6}$$ I am not sure I am even expressing the Dirac delta correctly in \eqref{4}. I am also a bit lost in the difference between the usual coordinate change involving the Jacobian, and the relation \eqref{3}, obviously one is a coordinate change and one is not, but they seem to have very similar effects. So I my main questions are; what is the correct way to transform the expression \eqref{2} into polar coordinates, and am I using \eqref{3} correctly in tandem with the coordinate change?","I have the following integral where , the square is , and the metric convention used is First I wanted to do it in the limit , where then I used the second dirac delta and theta function to impose Then performing the first integral over we would end up with where the denominator came from the expansion of the second dirac delta via This is not a very nice expression to work with so then I tried to go to spherical coordinates, however this ran into some issues. I tried I don't think this factor of should be there, as the final result should be proportional to ( updated 28/09 ) . Furthermore, since we normally have I am not sure I am even expressing the Dirac delta correctly in \eqref{4}. I am also a bit lost in the difference between the usual coordinate change involving the Jacobian, and the relation \eqref{3}, obviously one is a coordinate change and one is not, but they seem to have very similar effects. So I my main questions are; what is the correct way to transform the expression \eqref{2} into polar coordinates, and am I using \eqref{3} correctly in tandem with the coordinate change?","\int d^4\boldsymbol{x}' \,\delta\big[(\boldsymbol{x}-\boldsymbol{x'})^2+\alpha^2\big]\,\Theta(-x_0+x'_0)\,\delta\big[(\boldsymbol{x'})^2+\alpha^2\big]\,\Theta(-x_0'),\tag{1}\label{1} \boldsymbol{x}=\{x_0,x_1,x_2,x_3\} (x')^2=x_\mu'\cdot x'^{\mu} \{-1,1,1,1\}. \alpha\to0 x_0'=-\sqrt{(x_1')^2+(x_2')^2+(x_3')^2}. dx_0' \int d^3\boldsymbol{x}'\,\frac{\delta\big[\boldsymbol{x}^2-2x_0\sqrt{(x_1')^2+(x_2')^2+(x_3')^2}-2x^1  x_1'-2x^2  x_2'-2x^3  x_3'\big]}{2\sqrt{2}\sqrt{(x_1')^2+(x_2')^2+(x_3')^2}}\,\times\Theta\bigg(-x_0-\sqrt{(x_1')^2+(x_2')^2+(x_3')^2}\bigg),\tag{2}\label{2} \int_{\mathbb{R}^n}f(x)\,\delta\big(g(x)\big)dx=\int_{g^{-1}(0)} \frac{f(x)}{|\nabla g|}d\sigma(x).\tag{3}\label{3} \int dr'\int d\phi_1 d\phi_2\,\times\frac{(r')^2\,\text{sin}(\phi_1)}{2\sqrt{2}\,r'}\delta\big[\boldsymbol{x}^2-2r'\big(x_0+x_1 \text{sin}(\phi_1) \text{cos}(\phi_2)+x_2 \text{sin}(\phi_1) \text{sin}(\phi_2)+x_3 \text{cos}(\phi_1)\big)\big]\,\times\Theta\big(-x_0-r'\big),\tag{4}\label{4} r' \Theta\big(-x_0-\sqrt{x_1^2+x_2^2+x_3^2}\big) \delta(\boldsymbol{x}-\boldsymbol{x}_0)=\frac{1}{r^2\text{sin}(\phi_1)}\delta(r-r_0)\delta(\phi-\phi_0)\delta(\theta-\theta_0),\tag{6}\label{6}","['quantum-field-theory', 'kinematics', 'integration']"
17,Substitute $x = \sec u$ to evaluate $\int\sqrt{x^2-1}\ dx$: but why $\tan u= \sqrt{x^2 - 1}$ rather than $\tan u= -\sqrt{x^2 - 1}$ is used?,Substitute  to evaluate : but why  rather than  is used?,x = \sec u \int\sqrt{x^2-1}\ dx \tan u= \sqrt{x^2 - 1} \tan u= -\sqrt{x^2 - 1},"I tried evaluating $\int\sqrt{x^2-1}\ dx$ using the substitution $x = \sec u$ I know my method gets to the same answer as WolframAlpha , namely: $$\int\sqrt{x^2-1}\ dx = \frac{1}{2} \left(\ x \sqrt{x^2-1} - \ln\left|x + \sqrt{x^2-1}\right|\ \right) + C,\quad (*)$$ but there is one step I can't justify. When I got to $$\int \tan^2(u)\sec(u)\ du = \frac{1}{2}\left(\ \tan(u)\sec(u) - \ln\left|\sec(u)+\tan(u)\right|\ \right) + C,$$ I then have to substitute stuff back in terms of $x$ . Now $$x=\sec(u) \implies \tan^2(u) = x^2 - 1,$$ but I don't see how this implies $\tan(u) = \sqrt{x^2 - 1}$ . Comparing the graphs of $\sec(u)$ and $\tan(u)$ , I don't see why not: $\ \tan(u) = -\sqrt{x^2 - 1}$ , which would give: $$\int\sqrt{x^2-1}\ dx = \frac{1}{2} \left(\ -x \sqrt{x^2-1} - \ln\left|x - \sqrt{x^2-1}\right|\ \right) + C,\quad (**)$$ which is a different answer than $(*)$ ? Now I noticed that $(*) = -(**)\ $ (ignoring the $C \to -C)$ . I can see from the graph of $\sqrt{x^2-1}$ that for $x>1$ , the definite integral $\int^x_1\sqrt{t^2-1}\ dt = (*),$ and for $x<-1,\ \int^{-1}_x\sqrt{t^2-1}\ dt = (**)$ So is the indefinite integral sort of poorly defined, or would you say it is: $$\int\sqrt{x^2-1}\ dx = \pm \frac{1}{2} \left(\ x \sqrt{x^2-1} - \ln\left|x + \sqrt{x^2-1}\right|\ \right) + C?$$","I tried evaluating using the substitution I know my method gets to the same answer as WolframAlpha , namely: but there is one step I can't justify. When I got to I then have to substitute stuff back in terms of . Now but I don't see how this implies . Comparing the graphs of and , I don't see why not: , which would give: which is a different answer than ? Now I noticed that (ignoring the . I can see from the graph of that for , the definite integral and for So is the indefinite integral sort of poorly defined, or would you say it is:","\int\sqrt{x^2-1}\ dx x = \sec u \int\sqrt{x^2-1}\ dx = \frac{1}{2} \left(\ x \sqrt{x^2-1} - \ln\left|x + \sqrt{x^2-1}\right|\ \right) + C,\quad (*) \int \tan^2(u)\sec(u)\ du = \frac{1}{2}\left(\ \tan(u)\sec(u) - \ln\left|\sec(u)+\tan(u)\right|\ \right) + C, x x=\sec(u) \implies \tan^2(u) = x^2 - 1, \tan(u) = \sqrt{x^2 - 1} \sec(u) \tan(u) \ \tan(u) = -\sqrt{x^2 - 1} \int\sqrt{x^2-1}\ dx = \frac{1}{2} \left(\ -x \sqrt{x^2-1} - \ln\left|x - \sqrt{x^2-1}\right|\ \right) + C,\quad (**) (*) (*) = -(**)\  C \to -C) \sqrt{x^2-1} x>1 \int^x_1\sqrt{t^2-1}\ dt = (*), x<-1,\ \int^{-1}_x\sqrt{t^2-1}\ dt = (**) \int\sqrt{x^2-1}\ dx = \pm \frac{1}{2} \left(\ x \sqrt{x^2-1} - \ln\left|x + \sqrt{x^2-1}\right|\ \right) + C?","['integration', 'indefinite-integrals', 'substitution']"
18,How can I evaluate $\int _0^1\frac{\text{Li}_2\left(-x\right)\ln \left(1-x\right)}{1+x}\:dx$,How can I evaluate,\int _0^1\frac{\text{Li}_2\left(-x\right)\ln \left(1-x\right)}{1+x}\:dx,I am trying to evaluate $\displaystyle \int _0^1\frac{\text{Li}_2\left(-x\right)\ln \left(1-x\right)}{1+x}\:dx$ I first tried using the series expansion for the dilogarithm like this $$\sum _{n=1}^{\infty }\frac{\left(-1\right)^n}{n^2}\int _0^1\frac{x^n\ln \left(1-x\right)}{1+x}\:dx$$ Then I used integration by parts but this lead to nothing useful.,I am trying to evaluate I first tried using the series expansion for the dilogarithm like this Then I used integration by parts but this lead to nothing useful.,\displaystyle \int _0^1\frac{\text{Li}_2\left(-x\right)\ln \left(1-x\right)}{1+x}\:dx \sum _{n=1}^{\infty }\frac{\left(-1\right)^n}{n^2}\int _0^1\frac{x^n\ln \left(1-x\right)}{1+x}\:dx,"['integration', 'definite-integrals']"
19,Fubini's theorem for integrable functions.,Fubini's theorem for integrable functions.,,"I have gone through the proof of Fubini's theorem for non-negative measurable functions from the book An Introduction to Measure and Integration by Inder K Rana. The satement of the theorem is as follows $:$ Theorem $1$ $:$ Let $(X \times Y, \mathcal A \otimes \mathcal B, \mu \times \nu)$ be the product measure space induced by the $\sigma$ -finite measure spaces $(X,\mathcal A, \mu)$ and $(Y,\mathcal B, \nu).$ Then for any non-negative $\mathcal A \otimes \mathcal B$ - measurable function $f,$ the following staements hold $:$ $($ i $)$ For any $x_0 \in X,y_0 \in Y$ the maps $x \longmapsto f(x,y_0)$ and $y \longmapsto f(x_0,y)$ are $\mathcal A$ -measurable and $\mathcal B$ -measurable respectively. $($ ii $)$ The map $x \longmapsto \displaystyle {\int_{Y}} f(x,y)\ d\nu(y)$ is $\mathcal A$ -measurable and the map $y \longmapsto \displaystyle {\int_{X}} f(x,y)\ d\mu(x)$ is $\mathcal B$ -measurable. $($ iii $)$ $\displaystyle {\int_{X}} \left ( \displaystyle {\int_{Y}} f(x,y)\ d\nu(y) \right ) d\mu(x) = \displaystyle {\int_{Y}} \left ( \displaystyle {\int_{X}} f(x,y)\ d\mu(x) \right ) d\nu(y) = \displaystyle {\int_{X \times Y}} f(x,y)\ d(\mu \times \nu) (x,y).$ The general version of the above theorem states as follows $:$ Theorem $2$ $:$ Let $(X \times Y, \mathcal A \otimes \mathcal B, \mu \times \nu)$ be the product measure space induced by the $\sigma$ -finite measure spaces $(X,\mathcal A, \mu)$ and $(Y,\mathcal B, \nu).$ Then for any $f \in L_1 (\mu \times \nu),$ the following staements hold $:$ $($ i $)$ The maps $x \longmapsto f(x,y)$ and $y \longmapsto f(x,y)$ are $\mu$ -integrable a.e. $y(\nu)$ and $\nu$ -integrable a.e. $x(\mu)$ respectively. $($ ii $)$ The map $x \longmapsto \displaystyle {\int_{Y}} f(x,y)\ d\nu(y)$ is $\mu$ -integrable a.e. $x(\mu)$ and the map $y \longmapsto \displaystyle {\int_{X}} f(x,y)\ d\mu(x)$ is $\nu$ -integrable a.e. $y(\nu).$ $($ iii $)$ $\displaystyle {\int_{X}} \left ( \displaystyle {\int_{Y}} f(x,y)\ d\nu(y) \right ) d\mu(x) = \displaystyle {\int_{Y}} \left ( \displaystyle {\int_{X}} f(x,y)\ d\mu(x) \right ) d\nu(y) = \displaystyle {\int_{X \times Y}} f(x,y)\ d(\mu \times \nu) (x,y).$ I tried to prove the above theorem with the help of Theorem $1.$ Here's what I did $:$ My attempt $:$ Let $f^+$ and $f^-$ be the positive and the negative part of the function $f$ respectively. Since $f \in L_1(\mu \times \nu),$ $f^+$ and $f^-$ are both non-negative $\mathcal A \otimes \mathcal B$ -measurable functions. Applying Theorem $1$ $($ iii $)$ to $f^+$ and $f^{-}$ we have \begin{align*}\displaystyle {\int_{X}} \left ( \displaystyle {\int_{Y}} f^+(x,y)\ d\nu(y) \right ) d\mu(x) = \displaystyle {\int_{Y}} \left ( \displaystyle {\int_{X}} f^+(x,y)\ d\mu(x) \right ) d\nu(y) & = \displaystyle {\int_{X \times Y}} f^+(x,y)\ d(\mu \times \nu) (x,y) \\ & \leq \displaystyle {\int_{X \times Y}} |f(x,y)|\ d(\mu \times \nu) < +\infty. \end{align*} \begin{align*}\displaystyle {\int_{X}} \left ( \displaystyle {\int_{Y}} f^-(x,y)\ d\nu(y) \right ) d\mu(x) = \displaystyle {\int_{Y}} \left ( \displaystyle {\int_{X}} f^-(x,y)\ d\mu(x) \right ) d\nu(y) & = \displaystyle {\int_{X \times Y}} f^-(x,y)\ d(\mu \times \nu) (x,y) \\ & \leq \displaystyle {\int_{X \times Y}} |f(x,y)|\ d(\mu \times \nu) < +\infty. \end{align*} This shows that the map $x \longmapsto \displaystyle {\int_Y} f^+(x,y)\ d\nu(y)$ is $\mu$ -integrable, the map $y \longmapsto \displaystyle {\int_X} f^+(x,y)\ d\mu(x)$ is $\nu$ -integrable, the map $x \longmapsto \displaystyle {\int_Y} f^-(x,y)\ d\nu(y)$ is $\mu$ -integrable and the map $y \longmapsto \displaystyle {\int_X} f^-(x,y)\ d\mu(x)$ is $\nu$ -integrable. So the map $y \longmapsto f^+(x,y)$ is $\nu$ -integrable a.e. $x(\mu)$ and the map $y \longmapsto f^-(x,y)$ is $\nu$ -integrable a.e. $x(\mu).$ Hence $y \longmapsto f(x,y)$ is $\nu$ -integrable a.e. $x(\mu).$ Similarly, the map $x \longmapsto f^+(x,y)$ is $\mu$ -integrable a.e. $y(\nu)$ and the map $x \longmapsto f^-(x,y)$ is $\mu$ -integrable a.e. $y(\nu).$ Hence $x \longmapsto f(x,y)$ is $\mu$ -integrable a.e. $y(\nu).$ This proves $($ i $).$ Since $f \in L_1(\mu \times \nu)$ it follows that \begin{align*} \int_{X \times Y} f(x,y)\ d(\mu \times \nu) (x,y) & = \int_{X \times Y} f^+(x,y)\ d(\mu \times \nu) (x,y) - \int_{X \times Y} f^-(x,y)\ d(\mu \times \nu) (x,y) \\ & = \int_X \left ( \int_{Y} f^+(x,y)\ d{\nu(y)} \right ) d{\mu}(x) - \int_X \left ( \int_{Y} f^-(x,y)\ d{\nu(y)} \right ) d{\mu}(x) \end{align*} Now how do I proceed? Any help will be highly appreciated. Thanks in advance.","I have gone through the proof of Fubini's theorem for non-negative measurable functions from the book An Introduction to Measure and Integration by Inder K Rana. The satement of the theorem is as follows Theorem Let be the product measure space induced by the -finite measure spaces and Then for any non-negative - measurable function the following staements hold i For any the maps and are -measurable and -measurable respectively. ii The map is -measurable and the map is -measurable. iii The general version of the above theorem states as follows Theorem Let be the product measure space induced by the -finite measure spaces and Then for any the following staements hold i The maps and are -integrable a.e. and -integrable a.e. respectively. ii The map is -integrable a.e. and the map is -integrable a.e. iii I tried to prove the above theorem with the help of Theorem Here's what I did My attempt Let and be the positive and the negative part of the function respectively. Since and are both non-negative -measurable functions. Applying Theorem iii to and we have This shows that the map is -integrable, the map is -integrable, the map is -integrable and the map is -integrable. So the map is -integrable a.e. and the map is -integrable a.e. Hence is -integrable a.e. Similarly, the map is -integrable a.e. and the map is -integrable a.e. Hence is -integrable a.e. This proves i Since it follows that Now how do I proceed? Any help will be highly appreciated. Thanks in advance.",": 1 : (X \times Y, \mathcal A \otimes \mathcal B, \mu \times \nu) \sigma (X,\mathcal A, \mu) (Y,\mathcal B, \nu). \mathcal A \otimes \mathcal B f, : ( ) x_0 \in X,y_0 \in Y x \longmapsto f(x,y_0) y \longmapsto f(x_0,y) \mathcal A \mathcal B ( ) x \longmapsto \displaystyle {\int_{Y}} f(x,y)\ d\nu(y) \mathcal A y \longmapsto \displaystyle {\int_{X}} f(x,y)\ d\mu(x) \mathcal B ( ) \displaystyle {\int_{X}} \left ( \displaystyle {\int_{Y}} f(x,y)\ d\nu(y) \right ) d\mu(x) = \displaystyle {\int_{Y}} \left ( \displaystyle {\int_{X}} f(x,y)\ d\mu(x) \right ) d\nu(y) = \displaystyle {\int_{X \times Y}} f(x,y)\ d(\mu \times \nu) (x,y). : 2 : (X \times Y, \mathcal A \otimes \mathcal B, \mu \times \nu) \sigma (X,\mathcal A, \mu) (Y,\mathcal B, \nu). f \in L_1 (\mu \times \nu), : ( ) x \longmapsto f(x,y) y \longmapsto f(x,y) \mu y(\nu) \nu x(\mu) ( ) x \longmapsto \displaystyle {\int_{Y}} f(x,y)\ d\nu(y) \mu x(\mu) y \longmapsto \displaystyle {\int_{X}} f(x,y)\ d\mu(x) \nu y(\nu). ( ) \displaystyle {\int_{X}} \left ( \displaystyle {\int_{Y}} f(x,y)\ d\nu(y) \right ) d\mu(x) = \displaystyle {\int_{Y}} \left ( \displaystyle {\int_{X}} f(x,y)\ d\mu(x) \right ) d\nu(y) = \displaystyle {\int_{X \times Y}} f(x,y)\ d(\mu \times \nu) (x,y). 1. : : f^+ f^- f f \in L_1(\mu \times \nu), f^+ f^- \mathcal A \otimes \mathcal B 1 ( ) f^+ f^{-} \begin{align*}\displaystyle {\int_{X}} \left ( \displaystyle {\int_{Y}} f^+(x,y)\ d\nu(y) \right ) d\mu(x) = \displaystyle {\int_{Y}} \left ( \displaystyle {\int_{X}} f^+(x,y)\ d\mu(x) \right ) d\nu(y) & = \displaystyle {\int_{X \times Y}} f^+(x,y)\ d(\mu \times \nu) (x,y) \\ & \leq \displaystyle {\int_{X \times Y}} |f(x,y)|\ d(\mu \times \nu) < +\infty. \end{align*} \begin{align*}\displaystyle {\int_{X}} \left ( \displaystyle {\int_{Y}} f^-(x,y)\ d\nu(y) \right ) d\mu(x) = \displaystyle {\int_{Y}} \left ( \displaystyle {\int_{X}} f^-(x,y)\ d\mu(x) \right ) d\nu(y) & = \displaystyle {\int_{X \times Y}} f^-(x,y)\ d(\mu \times \nu) (x,y) \\ & \leq \displaystyle {\int_{X \times Y}} |f(x,y)|\ d(\mu \times \nu) < +\infty. \end{align*} x \longmapsto \displaystyle {\int_Y} f^+(x,y)\ d\nu(y) \mu y \longmapsto \displaystyle {\int_X} f^+(x,y)\ d\mu(x) \nu x \longmapsto \displaystyle {\int_Y} f^-(x,y)\ d\nu(y) \mu y \longmapsto \displaystyle {\int_X} f^-(x,y)\ d\mu(x) \nu y \longmapsto f^+(x,y) \nu x(\mu) y \longmapsto f^-(x,y) \nu x(\mu). y \longmapsto f(x,y) \nu x(\mu). x \longmapsto f^+(x,y) \mu y(\nu) x \longmapsto f^-(x,y) \mu y(\nu). x \longmapsto f(x,y) \mu y(\nu). ( ). f \in L_1(\mu \times \nu) \begin{align*} \int_{X \times Y} f(x,y)\ d(\mu \times \nu) (x,y) & = \int_{X \times Y} f^+(x,y)\ d(\mu \times \nu) (x,y) - \int_{X \times Y} f^-(x,y)\ d(\mu \times \nu) (x,y) \\ & = \int_X \left ( \int_{Y} f^+(x,y)\ d{\nu(y)} \right ) d{\mu}(x) - \int_X \left ( \int_{Y} f^-(x,y)\ d{\nu(y)} \right ) d{\mu}(x) \end{align*}","['integration', 'measure-theory', 'proof-writing', 'product-space', 'fubini-tonelli-theorems']"
20,On $\int_0^1\frac{\ln(1-e^{\pi i/3}x)}{e^{-\pi i/3}-x}\ln^3xdx$ and its generalization,On  and its generalization,\int_0^1\frac{\ln(1-e^{\pi i/3}x)}{e^{-\pi i/3}-x}\ln^3xdx,"Motivation Consider $$I_n=\int_0^1\frac{\ln(1-\omega x)}{\bar\omega-x}\ln^nxdx=\int_0^1\frac{\omega\ln(1-\omega x)}{1-\omega x}\ln^nxdx$$ where $\omega=e^{i\pi/3}$ . It is known that $I_0=\frac1{18}\pi^2$ which can be deduced by integrating directly, and $$I_1=\frac23\zeta(3)-\frac\pi3\operatorname{Cl}_2\left(\frac\pi3\right)+i\cdot\frac1{324}\pi^3,$$ where $\text{Cl}$ is the Clausen Cl function. I evaluated $I_1$ by using known antiderivative of $\frac{\ln(x-a)\ln(x-b)}{x}$ . One thing I noticed why it is special for $\omega$ is that if we replace it with other complex numbers different from $\pm1$ and $0$ , the result of $I_2$ won't be very beautiful, such as $$\int_0^1\frac{\ln(1-zx)}{1-zx}\ln^2xdx,\text{ where $z=i$}$$ The result of the latter involves polylogarithm values that can not be simplified. It equals $$\tiny4 i\Re\operatorname{Li}_4\left(\frac{1}{2}+\frac{i}{2}\right)+\frac{35 \pi  \zeta (3)}{64}+\frac{35}{32} i \zeta (3) \log (2)-\frac{47 i \pi ^4}{1536}+\frac{1}{96} i \ln^4(2)-\frac{5}{192} i \pi ^2 \ln^2(2)+2\beta(4)$$ Also, a CAS knows how to handle $I_2$ . It gives the result $$I_2=\frac{23}{9720}\pi^4+i\left(\frac49\pi\zeta(3)-2\operatorname{Cl}_4\left(\frac\pi3\right)\right)$$ (CAS knows the antiderivative) So the following question comes out: For a general $n\in\mathbb N$ , does a closed form of $I_n$ exist? Higher to $n\ge3$ , the polylog-styled antiderivative no longer exists. The method  becomes invalid. But the numerically-verified closed form for the real part of $I_3$ still exist. $$\Re I_3=\frac{43}6\zeta(5)-\frac16\pi^2\zeta(3)-2\pi\operatorname{Cl}_4\left(\frac\pi3\right)$$ A failed attempt is trying to convert $I_n$ to series form: $$\sum_{k=1}^\infty H_k\omega^{k+1}\int_0^1x^k\ln^n\frac1xdx=n!\sum_{k=1}^\infty \frac{H_k\omega^{k+1}}{k^{n+1}}$$ and separating it into 6 series. No luck for continuing this method so far. Edit: I'm not looking for a proof of the result above. I'm looking for a closed form of $I_n$ .","Motivation Consider where . It is known that which can be deduced by integrating directly, and where is the Clausen Cl function. I evaluated by using known antiderivative of . One thing I noticed why it is special for is that if we replace it with other complex numbers different from and , the result of won't be very beautiful, such as The result of the latter involves polylogarithm values that can not be simplified. It equals Also, a CAS knows how to handle . It gives the result (CAS knows the antiderivative) So the following question comes out: For a general , does a closed form of exist? Higher to , the polylog-styled antiderivative no longer exists. The method  becomes invalid. But the numerically-verified closed form for the real part of still exist. A failed attempt is trying to convert to series form: and separating it into 6 series. No luck for continuing this method so far. Edit: I'm not looking for a proof of the result above. I'm looking for a closed form of .","I_n=\int_0^1\frac{\ln(1-\omega x)}{\bar\omega-x}\ln^nxdx=\int_0^1\frac{\omega\ln(1-\omega x)}{1-\omega x}\ln^nxdx \omega=e^{i\pi/3} I_0=\frac1{18}\pi^2 I_1=\frac23\zeta(3)-\frac\pi3\operatorname{Cl}_2\left(\frac\pi3\right)+i\cdot\frac1{324}\pi^3, \text{Cl} I_1 \frac{\ln(x-a)\ln(x-b)}{x} \omega \pm1 0 I_2 \int_0^1\frac{\ln(1-zx)}{1-zx}\ln^2xdx,\text{ where z=i} \tiny4 i\Re\operatorname{Li}_4\left(\frac{1}{2}+\frac{i}{2}\right)+\frac{35 \pi  \zeta (3)}{64}+\frac{35}{32} i \zeta (3) \log (2)-\frac{47 i \pi ^4}{1536}+\frac{1}{96} i \ln^4(2)-\frac{5}{192} i \pi ^2 \ln^2(2)+2\beta(4) I_2 I_2=\frac{23}{9720}\pi^4+i\left(\frac49\pi\zeta(3)-2\operatorname{Cl}_4\left(\frac\pi3\right)\right) n\in\mathbb N I_n n\ge3 I_3 \Re I_3=\frac{43}6\zeta(5)-\frac16\pi^2\zeta(3)-2\pi\operatorname{Cl}_4\left(\frac\pi3\right) I_n \sum_{k=1}^\infty H_k\omega^{k+1}\int_0^1x^k\ln^n\frac1xdx=n!\sum_{k=1}^\infty \frac{H_k\omega^{k+1}}{k^{n+1}} I_n","['integration', 'sequences-and-series', 'definite-integrals', 'euler-sums']"
21,Integrals Over Complex Domains,Integrals Over Complex Domains,,"In Complex Analysis texts, one often sees integrals of functions $f : A \subset \mathbb{C} \to \mathbb{C}$ along contours $\gamma : [0,1] \to \mathbb{C}$ . But I've never seen discussion of integrals of functions $f : A \subset \mathbb{C} \to \mathbb{C}$ over domains $D \subset A$ in any of these texts. It seems like it should be possible to define such integrals, so why aren't they discussed in most complex analysis textbooks? Are there any major results about them like, for example, Cauchy's integral formula for contour integrals? Are there any textbooks that do delve into these kinds of integrals? Examples By a contour integral, I mean something like the following: consider the contour $\gamma : [0,1] \to \mathbb{C}$ given by $\gamma(t)  = e^{2\pi i t}$ and the function $f : \mathbb{C} - \{0\} \to \mathbb{C}$ given by $f(z) = \frac{1}{z}$ . The integral of $f$ around the contour $\gamma$ is $$ \int_\gamma f = \int_0^1 f(\gamma(t))\gamma'(t) dt = \int_0^1 \frac{1}{e^{2\pi i t}} \frac{2\pi i e^{2\pi i t}}{1} dt = \int_0^1 2\pi i dt = 2\pi i $$ By an integral over a domain, I mean something like the following: consider the function $g : \mathbb{C} \to \mathbb{C}$ given by $g(z) = z^2$ and the domain $D = \{z \in \mathbb{C} : |z| \leq 1\}$ . The integral of $g$ over the domain $D$ is $$ \int_D g d\mu \stackrel{?}{=} $$ where, presumably, $d\mu$ is something like the Haar measure on $\mathbb{C}$ with $\mu([0,1]\times[0,1]) = 1$ .","In Complex Analysis texts, one often sees integrals of functions along contours . But I've never seen discussion of integrals of functions over domains in any of these texts. It seems like it should be possible to define such integrals, so why aren't they discussed in most complex analysis textbooks? Are there any major results about them like, for example, Cauchy's integral formula for contour integrals? Are there any textbooks that do delve into these kinds of integrals? Examples By a contour integral, I mean something like the following: consider the contour given by and the function given by . The integral of around the contour is By an integral over a domain, I mean something like the following: consider the function given by and the domain . The integral of over the domain is where, presumably, is something like the Haar measure on with .","f : A \subset \mathbb{C} \to \mathbb{C} \gamma : [0,1] \to \mathbb{C} f : A \subset \mathbb{C} \to \mathbb{C} D \subset A \gamma : [0,1] \to \mathbb{C} \gamma(t)  = e^{2\pi i t} f : \mathbb{C} - \{0\} \to \mathbb{C} f(z) = \frac{1}{z} f \gamma 
\int_\gamma f = \int_0^1 f(\gamma(t))\gamma'(t) dt = \int_0^1 \frac{1}{e^{2\pi i t}} \frac{2\pi i e^{2\pi i t}}{1} dt = \int_0^1 2\pi i dt = 2\pi i
 g : \mathbb{C} \to \mathbb{C} g(z) = z^2 D = \{z \in \mathbb{C} : |z| \leq 1\} g D 
\int_D g d\mu \stackrel{?}{=}
 d\mu \mathbb{C} \mu([0,1]\times[0,1]) = 1","['integration', 'complex-analysis', 'reference-request']"
22,Integral $\int_0^1\frac{\ln(1+x)}{1+x^2}\left(\frac{3\arctan x}{x}+2\ln x\right)dx$,Integral,\int_0^1\frac{\ln(1+x)}{1+x^2}\left(\frac{3\arctan x}{x}+2\ln x\right)dx,"I was playing around with PARI GP to generate a challenging integral. The method: The function lindep is intended to detect integer dependence. The constants used: $\text{G}\ln 2,\pi^3,\pi\ln^2 2,\ln^3 2,\pi^2\ln 2,\int_0^{\frac{\pi}{4}}\ln^2(\cos x)\,dx$ . All these numbers are of ""degree"" $3$ . To get a challenging integral you multiply, $\ln(1+x),\ln(1+x^2),\dfrac{1}{1+x^2},\arctan x,\dfrac{1}{1+x},\dfrac{1}{x}$ The idea is to sum up two integrals to cancel out the awful term $\int_0^{\frac{\pi}{4}}\ln^2(\cos x)\,dx$ After ten minutes, I have found: \begin{align}A&=\int_0^1 \frac{\ln x\ln(1+x)}{1+x^2}\,dx\\ &=-3\int_0^{\frac{\pi}{4}}\ln^2(\cos x)\,dx+...\\ B&=\int_0^1\frac{\ln(1+x)\arctan x}{x(1+x^2)}\,dx\\ &=2\int_0^{\frac{\pi}{4}}\ln^2(\cos x)\,dx+...\\ \end{align} Now, if you take $2A+3B$ you cancel out the term $\int_0^{\frac{\pi}{4}}\ln^2(\cos x)\,dx$ . The result is: \begin{align}\int_0^1\frac{\ln(1+x)}{1+x^2}\left(\frac{3\arctan x}{x}+2\ln x\right)dx=\frac{5}{128}\pi^3-\frac{7}{4}\text{G}\ln 2+\frac{3}{16}\pi \ln^2 2\end{align} The question is: How to prove this? Addendum : My first candidate for $B$ was: $\int_0^1\frac{\ln(1+x)\arctan x}{1+x^2}\,dx$ but it's not expressible as an integer linear combination of the chosen constants. Probably not related to constants of ""degree"" $3$ . To decrease the ""degree"" i have multiply by $\dfrac{1}{x}$ and voilà !","I was playing around with PARI GP to generate a challenging integral. The method: The function lindep is intended to detect integer dependence. The constants used: . All these numbers are of ""degree"" . To get a challenging integral you multiply, The idea is to sum up two integrals to cancel out the awful term After ten minutes, I have found: Now, if you take you cancel out the term . The result is: The question is: How to prove this? Addendum : My first candidate for was: but it's not expressible as an integer linear combination of the chosen constants. Probably not related to constants of ""degree"" . To decrease the ""degree"" i have multiply by and voilà !","\text{G}\ln 2,\pi^3,\pi\ln^2 2,\ln^3 2,\pi^2\ln 2,\int_0^{\frac{\pi}{4}}\ln^2(\cos x)\,dx 3 \ln(1+x),\ln(1+x^2),\dfrac{1}{1+x^2},\arctan x,\dfrac{1}{1+x},\dfrac{1}{x} \int_0^{\frac{\pi}{4}}\ln^2(\cos x)\,dx \begin{align}A&=\int_0^1 \frac{\ln x\ln(1+x)}{1+x^2}\,dx\\
&=-3\int_0^{\frac{\pi}{4}}\ln^2(\cos x)\,dx+...\\
B&=\int_0^1\frac{\ln(1+x)\arctan x}{x(1+x^2)}\,dx\\
&=2\int_0^{\frac{\pi}{4}}\ln^2(\cos x)\,dx+...\\
\end{align} 2A+3B \int_0^{\frac{\pi}{4}}\ln^2(\cos x)\,dx \begin{align}\int_0^1\frac{\ln(1+x)}{1+x^2}\left(\frac{3\arctan x}{x}+2\ln x\right)dx=\frac{5}{128}\pi^3-\frac{7}{4}\text{G}\ln 2+\frac{3}{16}\pi \ln^2 2\end{align} B \int_0^1\frac{\ln(1+x)\arctan x}{1+x^2}\,dx 3 \dfrac{1}{x}","['integration', 'definite-integrals']"
23,if the indefinite integral of $x^x$ was $f(x)$ what would the indefinite integral of $x^{1/x}$ be in terms of $x$ and $f(x)$?,if the indefinite integral of  was  what would the indefinite integral of  be in terms of  and ?,x^x f(x) x^{1/x} x f(x),so what this means is if $f(x)$ is the indefinite integral of $x^x dx$ then what would the indefinite integral of $x^{1/x}$ be in terms of $x$ and $f(x)$,so what this means is if is the indefinite integral of then what would the indefinite integral of be in terms of and,f(x) x^x dx x^{1/x} x f(x),['integration']
24,Finding $\int\frac{\sin^4 x+\cos^4 x}{\sin^3 x+\cos^3 x}dx$,Finding,\int\frac{\sin^4 x+\cos^4 x}{\sin^3 x+\cos^3 x}dx,"Find $$\int\frac{\sin^4 x+\cos^4 x}{\sin^3 x+\cos^3 x}dx$$ What I tried: $$\sin^4(x)+\cos^4(x)=(\sin^2 x+\cos^2 x)^2-2\sin^2 x\cos^2 x=1-2\sin^2 x\cos^2 x$$ and $$\sin^3 x+\cos^3 x=(\sin x+\cos x)(1-\sin x\cos x)$$ so $$\int\frac{1-\sin^2 x\cos^2 x}{(\sin x+\cos x)(1-\sin x\cos x)}dx-\int\frac{\sin^2 x\cos^2 x}{(\sin x+\cos x)(1-\sin x\cos x)}dx$$ How do I solve it? Help me, please.","Find What I tried: and so How do I solve it? Help me, please.",\int\frac{\sin^4 x+\cos^4 x}{\sin^3 x+\cos^3 x}dx \sin^4(x)+\cos^4(x)=(\sin^2 x+\cos^2 x)^2-2\sin^2 x\cos^2 x=1-2\sin^2 x\cos^2 x \sin^3 x+\cos^3 x=(\sin x+\cos x)(1-\sin x\cos x) \int\frac{1-\sin^2 x\cos^2 x}{(\sin x+\cos x)(1-\sin x\cos x)}dx-\int\frac{\sin^2 x\cos^2 x}{(\sin x+\cos x)(1-\sin x\cos x)}dx,['integration']
25,Evaluating an indefinite integral $\int \frac{dx}{\sqrt{x^3+2x+3}}$,Evaluating an indefinite integral,\int \frac{dx}{\sqrt{x^3+2x+3}},"Evaluate the following integral \begin{equation} J = \int \frac{dx}{\sqrt{x^3+2x+3}} \end{equation} I do not find suitable substitution to compute the above indefinite integral. Since $x^3+2x+3=(x+1)(x^2-x+3)$ , substituting $z=\sqrt{x+1}$ , we have $$J= 2\int \frac{dz}{\sqrt{z^4-3z^2+5}}.$$ I think this is not a good substitution. Any help is appreciated.","Evaluate the following integral I do not find suitable substitution to compute the above indefinite integral. Since , substituting , we have I think this is not a good substitution. Any help is appreciated.","\begin{equation}
J = \int \frac{dx}{\sqrt{x^3+2x+3}}
\end{equation} x^3+2x+3=(x+1)(x^2-x+3) z=\sqrt{x+1} J= 2\int \frac{dz}{\sqrt{z^4-3z^2+5}}.","['integration', 'indefinite-integrals']"
26,Notation for Higher Antiderivatives?,Notation for Higher Antiderivatives?,,"Higher derivative are blessed with many notations. For example $$ f',f'',...$$ or $$ \frac {dy}{dx}, \frac {d^2 y}{dx^2},...$$ I have not seen any notations for higher anti-derivatives. For example, the higher anti-derivatives of $$f(x)=2x+5$$ are $$x^2+5x+c_1, \frac {x^3}{3} +\frac {5}{2}  x^2 + c_1x +c_2,.....$$ Are there notations for higher anti-derivatives?","Higher derivative are blessed with many notations. For example or I have not seen any notations for higher anti-derivatives. For example, the higher anti-derivatives of are Are there notations for higher anti-derivatives?"," f',f'',...  \frac {dy}{dx}, \frac {d^2 y}{dx^2},... f(x)=2x+5 x^2+5x+c_1, \frac {x^3}{3} +\frac {5}{2}  x^2 + c_1x +c_2,.....",['integration']
27,Integral of $\int\frac{\sin x}{\sin x+\cos x}dx$,Integral of,\int\frac{\sin x}{\sin x+\cos x}dx,The questions defines $$I=\int\frac{\sin x}{\sin x +\cos x}dx\;\;J=\int\frac{\cos x}{\sin x +\cos x}dx$$ It asked me to find $I+J$ and $J-I$ which I have done and I will show below but now I need to find the integral shown below and I'm unsure on what to do. $$\int\frac{\sin x}{\sin x+\cos x}dx$$ I have found that: $$I+J = x+c$$ $$J-I=\ln{|\cos x +\sin x|} +c$$ But now i'm unsure on how to find just $I$,The questions defines It asked me to find and which I have done and I will show below but now I need to find the integral shown below and I'm unsure on what to do. I have found that: But now i'm unsure on how to find just,I=\int\frac{\sin x}{\sin x +\cos x}dx\;\;J=\int\frac{\cos x}{\sin x +\cos x}dx I+J J-I \int\frac{\sin x}{\sin x+\cos x}dx I+J = x+c J-I=\ln{|\cos x +\sin x|} +c I,"['integration', 'trigonometric-integrals']"
28,Integral over the hypersphere,Integral over the hypersphere,,"Assume I have a diagonal matrix $L$ of size $n$ . I want to compute the following integral: $$I_n(L) \equiv \int_{(\mathbb{S}^{n-1})^2} \mathrm{d}\sigma(x)  \mathrm{d}\sigma(x') \exp[n x^\top L \, x']$$ In which $\mathbb{S}^{n-1}$ is the unit sphere in $\mathbb{R}^n$ , and $ \mathrm{d}\sigma$ is the usual measure on $\mathbb{S}^{n-1}$ , with $\int_{\mathbb{S}^{n-1}} \mathrm{d}\sigma(x) = 2 \pi^{n/2}/\Gamma(n/2)$ . I am looking for either a general form of $I_n(L)$ or simply an asymptotic of $\frac{1}{n}\log I_n(L)$ as $n \to \infty$ . I tried but could not find such results. Any help would be appreciated. Thanks !","Assume I have a diagonal matrix of size . I want to compute the following integral: In which is the unit sphere in , and is the usual measure on , with . I am looking for either a general form of or simply an asymptotic of as . I tried but could not find such results. Any help would be appreciated. Thanks !","L n I_n(L) \equiv \int_{(\mathbb{S}^{n-1})^2} \mathrm{d}\sigma(x)  \mathrm{d}\sigma(x') \exp[n x^\top L \, x'] \mathbb{S}^{n-1} \mathbb{R}^n  \mathrm{d}\sigma \mathbb{S}^{n-1} \int_{\mathbb{S}^{n-1}} \mathrm{d}\sigma(x) = 2 \pi^{n/2}/\Gamma(n/2) I_n(L) \frac{1}{n}\log I_n(L) n \to \infty","['integration', 'gaussian-integral']"
29,Absolute convergence of f(nt) when f is integrable,Absolute convergence of f(nt) when f is integrable,,"I'm working on the following exercise: Let $f \in \mathcal L^1([0,\infty), \lambda)$ be a Lebesgue integrable function on $[0,\infty)$ . Show that for $\lambda$ -almost every $t \in (0,\infty)$ , the series $\sum_{n=1}^\infty f(nt)$ converges absolutely. Here $\lambda$ is Lebesgue measure. I'm not really sure how to go about this. I thought I could use monotone convergence on the functions $F_n = \sum_{k=1}^n f(kt)$ , but I have no reason to suspect these are integrable. I'm wondering if there's a Fatou argument I can make instead, but I'm having trouble seeing it. This exercise comes from Section 4.2 of Achim Klenke's book on probability theory (this section is on Fatou's lemma and monotone convergence). The series in question looks suspiciously similar to a limiting term in a Riemann integral, but this is discussed in the following section, so I'd like to avoid using Riemann integration arguments here. (Though the exercise could just be misplaced.)","I'm working on the following exercise: Let be a Lebesgue integrable function on . Show that for -almost every , the series converges absolutely. Here is Lebesgue measure. I'm not really sure how to go about this. I thought I could use monotone convergence on the functions , but I have no reason to suspect these are integrable. I'm wondering if there's a Fatou argument I can make instead, but I'm having trouble seeing it. This exercise comes from Section 4.2 of Achim Klenke's book on probability theory (this section is on Fatou's lemma and monotone convergence). The series in question looks suspiciously similar to a limiting term in a Riemann integral, but this is discussed in the following section, so I'd like to avoid using Riemann integration arguments here. (Though the exercise could just be misplaced.)","f \in \mathcal L^1([0,\infty), \lambda) [0,\infty) \lambda t \in (0,\infty) \sum_{n=1}^\infty f(nt) \lambda F_n = \sum_{k=1}^n f(kt)","['integration', 'measure-theory', 'lebesgue-integral', 'lebesgue-measure']"
30,Volume of cannoli,Volume of cannoli,,"Problem statement (see pic below): 1. Wrap unit circle over cylinder with radius $r=1/\pi$, edges of unit circle will just touch each other. 2. Remove cylinder, fill cannoli with cream)). 3. Scrape off the excess of cream with straight edge held perpendicular to the cannoli axis and touch symmetic points of the edges. Find volume of cannoli. This lead me to a difficult integral which I can't solve so far. Here are my steps: since figure is simmetrical we can integrate from 0 to R=1: $V=2\int_0^R S(h)dh$, where $S(h)$ is area at heigh $h$ $S(h)$ is a segment of circle with radius $r=1/\pi$ Length of this segment is: $l(h)=2\sqrt{R^2-h^2}$ (top pic) The angle of corresponding segment is $\phi={l(h)/ r}$ and it's area is: $S(h)={1\over 2}r^2(\phi-\sin\phi)=r\sqrt{R^2-h^2}-{1 \over 2}r^2 \sin{2\sqrt{R^2-h^2} \over r}$ (right picture) $V=2r\int_0^R \sqrt{R^2-h^2}dh-r^2\int_0^R\sin{2\sqrt{R^2-h^2} \over r}dh$ Am I being wrong somewhere? If 'no' then how to take 2nd integral?","Problem statement (see pic below): 1. Wrap unit circle over cylinder with radius $r=1/\pi$, edges of unit circle will just touch each other. 2. Remove cylinder, fill cannoli with cream)). 3. Scrape off the excess of cream with straight edge held perpendicular to the cannoli axis and touch symmetic points of the edges. Find volume of cannoli. This lead me to a difficult integral which I can't solve so far. Here are my steps: since figure is simmetrical we can integrate from 0 to R=1: $V=2\int_0^R S(h)dh$, where $S(h)$ is area at heigh $h$ $S(h)$ is a segment of circle with radius $r=1/\pi$ Length of this segment is: $l(h)=2\sqrt{R^2-h^2}$ (top pic) The angle of corresponding segment is $\phi={l(h)/ r}$ and it's area is: $S(h)={1\over 2}r^2(\phi-\sin\phi)=r\sqrt{R^2-h^2}-{1 \over 2}r^2 \sin{2\sqrt{R^2-h^2} \over r}$ (right picture) $V=2r\int_0^R \sqrt{R^2-h^2}dh-r^2\int_0^R\sin{2\sqrt{R^2-h^2} \over r}dh$ Am I being wrong somewhere? If 'no' then how to take 2nd integral?",,"['integration', '3d', 'volume']"
31,"Is there a closed form for this ""flowery"" integral?","Is there a closed form for this ""flowery"" integral?",,"I'm curious about shapes like this: I think of this as the trajectory of a particle where the acceleration is perpendicular to the velocity and oscillates sinusoidally in time. The functions I'm investigating, in the generic case, are of the form: $$f(x) = \int e^{ai(x + b\,sin\,x)}\ dx$$ The above image is generated with $a=0.75, b=-1$. I'm especially interested the relationship of $a$ and $b$ in the specific case: $$0 = \int_0^{2\pi} e^{ai(x + b\,sin\,x)}\ dx$$ This corresponds to shapes like this, where the ""lobes"" touch at the origin: This is generated with $a=0.75, b \approx -0.7364$. In trying to figure out $b = g(a)$ I've tried my usual method of graphing approximate values of $b$ against $a$ and comparing it with some common functions, but I couldn't find anything that matched. I also tried entering some values of $b$ into WolframAlpha to see if it could find a closed form, but no dice. Is there a closed form for the generic case? What is the equation relating $a$ and $b$ in the specific case, and does it have a closed form? To me, the numbers seem magically pulled out of thin air, with no relation to any known constants.","I'm curious about shapes like this: I think of this as the trajectory of a particle where the acceleration is perpendicular to the velocity and oscillates sinusoidally in time. The functions I'm investigating, in the generic case, are of the form: $$f(x) = \int e^{ai(x + b\,sin\,x)}\ dx$$ The above image is generated with $a=0.75, b=-1$. I'm especially interested the relationship of $a$ and $b$ in the specific case: $$0 = \int_0^{2\pi} e^{ai(x + b\,sin\,x)}\ dx$$ This corresponds to shapes like this, where the ""lobes"" touch at the origin: This is generated with $a=0.75, b \approx -0.7364$. In trying to figure out $b = g(a)$ I've tried my usual method of graphing approximate values of $b$ against $a$ and comparing it with some common functions, but I couldn't find anything that matched. I also tried entering some values of $b$ into WolframAlpha to see if it could find a closed form, but no dice. Is there a closed form for the generic case? What is the equation relating $a$ and $b$ in the specific case, and does it have a closed form? To me, the numbers seem magically pulled out of thin air, with no relation to any known constants.",,"['integration', 'definite-integrals', 'indefinite-integrals', 'graphing-functions', 'closed-form']"
32,A more general closed-form of an integral involving a square power of $\theta_4$ - function,A more general closed-form of an integral involving a square power of  - function,\theta_4,"$\textbf{Problem statement}$. Inspired by the computations at this nospoon we introduce the following integral: $$\int_{0}^{\infty }\frac{~\theta _{4}^{2}\left( \exp \left( -\pi \,y\,\beta \right) \right) }{1+y^{2}}dy\;  \tag{1}\label{1}$$ which is as far as I know only calculated for $\beta =1$. $$\int_{0}^{\infty }\frac{~\theta _{4}^{2}\left( \exp \left( -\pi \,y\right) \right) }{1+y^{2}}dx=1   \tag{2}\label{2} $$ My goal is to calculate the integral of \eqref{1} for any $\beta $. $\textbf{Ansatz}$.With the aid of the well-known representation of the square power of $ \theta_{4}$ Dieckmann $$\theta _{4}^{2}\left( \exp \left( -\pi \,y\right) \right) =1+2\sum_{k=1}^{\infty }(-1)^{k}~s{ech}(\pi k\,y)  \tag{3}\label{3}$$ and the transformation $y=\frac{x}{\beta }$, for \eqref{1} follows: $$\frac{\pi }{2}+2\sum_{k=1}^{\infty }(-1)^{k}\int_{0}^{\infty }\frac{~\beta ~s% {ech}(\pi k\,x)}{\beta ^{2}+x^{2}}\,dx  \tag{4}\label{4}$$ The integral in the sum: $$\int_{0}^{\infty }\frac{\beta ~s{ech}(\pi k\,x)}{\beta ^{2}+x^{2}}% \,dx=\int_{0}^{\infty }\frac{\beta ~}{\beta ^{2}+x^{2}}\frac{1\,}{\cosh \left( \pi k\,x\right) }dx  \tag{5}\label{5}$$ is done in Sangchul Lee and returns the solution of \eqref{1}: $$\mathcal{I}\left( \beta \right) =\frac{\pi }{2}+\sum_{k=1}^{\infty }(-1)^{k}\left( \psi \left( \frac{k\,\beta \ }{2}+\frac{3}{4}\right) -\psi \left( \frac{k\,\beta \ }{2}+\frac{1}{4}\right) \right) \;  \tag{6}\label{6}$$ Using nospoon returns $\mathcal {I} \left(1\right) = 1 $. A proof is upon request. For the readability, here some of the steps performed in Sangchul Lee . Transformation of \eqref{5} with $y=\frac{x}{% \beta }$ leads to: $$\int_{0}^{\infty }\frac{\beta ~}{\beta ^{2}+x^{2}}\frac{1\,}{\cosh \left( \pi k\,x\right) }dx=\int_{0}^{\infty }\frac{1~}{1+y^{2}}\frac{1\,}{\cosh \left( a\,y\right) }dy  \tag{7}\label{7}$$ with $a=k~\beta \,\pi $. Transformation with $z=$ $\frac{a\,y}{\pi }$ leads to: $$\int_{0}^{\infty }\frac{1~}{1+y^{2}}\frac{1\,}{\cosh \left( a\,y\right) }dy=% \frac{\pi a}{2}\int_{-\infty }^{\infty }\frac{dz}{\left( a^{2}+\pi ^{2}z^{2}\right) \cosh \left( \pi \,z\right) }  \tag{8}\label{8}$$ In the following, we need the Fourier transform of $f$ $$\widehat{f}\left( \xi \right) =\mathcal{F}\left[ f\left( z\right) \right] =\int_{\mathcal{R}}f\left( z\right) \exp \left( -2\pi i\xi z\right) ~dz \tag{9}\label{9}$$ Let $$f\left( z\right) =s{ech}(\pi \,z),\;g\left( z\right) =\frac{1}{a^{2}+\pi ^{2}z^{2}}  \tag{10}\label{10}$$ and $$\widehat{f}\left( \xi \right) =s{ech}(\pi \,\xi ),\;\widehat{g}\left( \xi \right) =\frac{1}{a}\exp \left( -2a\left\vert \xi \right\vert \right)  \tag{11}\label{11}$$ Also, if both $f$ and $g$ are in $L^{2}$, then $$\int_{\mathcal{R}}\widehat{f}~g=\int_{\mathcal{R}}f~\widehat{g} \tag{12}\label{12}$$ results to $$\frac{\pi }{2}+\pi a\sum_{k=1}^{\infty }(-1)^{k}\int_{-\infty }^{\infty }% \frac{dz}{\left( a^{2}+\pi ^{2}z^{2}\right) \cosh \left( \pi \,z\right) }=% \frac{\pi }{2}+2\pi \sum_{k=1}^{\infty }(-1)^{k}\int_{0}^{\infty }\frac{\exp \left( -2\pi k\beta ~z\right) }{\cosh \left( \pi \,z\right) }dz  \tag{13}\label{13}$$ Further transformations then leads finally to the solution \eqref{6}. Now, for an equivalent integral representation of \eqref{1}, we first perform the sum in \eqref{13}: $$\mathcal{I}\left( \beta \right) =\frac{\pi }{2}-2\pi \int_{0}^{\infty }\frac{% s{ech}(\pi \,z)}{1+\exp \left( 2\pi \beta ~z\right) }dz  \tag{14}\label{14}$$ For $\beta =1$, the known value $\mathcal{I}\left( 1\right) =1$ results. With the aid of Mathematica,  further analytical expressions for some fixed $\beta$-values can be calculated.  With \eqref{4} the following identity results: $$\sum_{k=1}^{\infty }(-1)^{k}\int_{0}^{\infty }\frac{s{ech}(k~\pi \,z)}{\beta ^{2}+z^{2}}dz=-\frac{\pi }{\beta }\int_{0}^{\infty }\frac{s{ech}(\pi \,z)}{% 1+\exp \left( 2\pi \beta ~z\right) }dz  \tag{15}\label{15}$$ The integral form \eqref{14} can be transformed into other interesting expressions.  Using the known identity Kim : $$\,_{2}F_{1}\left( a,a;a+1;\frac{1}{2}\right) =2^{a-1}a~\left( \psi \left(  \frac{a}{2}+\frac{1}{2}\right) -\psi \left( \frac{a}{2}\right) \right) \tag{16}\label{16}$$ and \eqref{6}, these expressions can be reproduced and further identities can be derived. For the readability, I omit lots of results, I've found so far. In case of interest, these results can be requested. $\textbf{1st Question}$ $\textit{Does anybody know how to approach this sum \eqref{6}?} $ $\textit{ Where can I find out more about dealing with the sum?}$ $\textit{Is it possible to derive a simpler expression?}$ $\textbf{2st Question}$ $\textit{Can we find a closed form expression for $\mathcal{I}\left( \beta\right)$, at least for $\beta $ $\in \mathbb{N}$?, distinguishing even/odd $\beta $ ?}$ $\textbf{Bonus Q}$ $\textit{How can I proof the identity \eqref{15} with the help of the Poisson Summation Formula?}$ $\textit{Are there any further results can be obtained by doing so?}$","$\textbf{Problem statement}$. Inspired by the computations at this nospoon we introduce the following integral: $$\int_{0}^{\infty }\frac{~\theta _{4}^{2}\left( \exp \left( -\pi \,y\,\beta \right) \right) }{1+y^{2}}dy\;  \tag{1}\label{1}$$ which is as far as I know only calculated for $\beta =1$. $$\int_{0}^{\infty }\frac{~\theta _{4}^{2}\left( \exp \left( -\pi \,y\right) \right) }{1+y^{2}}dx=1   \tag{2}\label{2} $$ My goal is to calculate the integral of \eqref{1} for any $\beta $. $\textbf{Ansatz}$.With the aid of the well-known representation of the square power of $ \theta_{4}$ Dieckmann $$\theta _{4}^{2}\left( \exp \left( -\pi \,y\right) \right) =1+2\sum_{k=1}^{\infty }(-1)^{k}~s{ech}(\pi k\,y)  \tag{3}\label{3}$$ and the transformation $y=\frac{x}{\beta }$, for \eqref{1} follows: $$\frac{\pi }{2}+2\sum_{k=1}^{\infty }(-1)^{k}\int_{0}^{\infty }\frac{~\beta ~s% {ech}(\pi k\,x)}{\beta ^{2}+x^{2}}\,dx  \tag{4}\label{4}$$ The integral in the sum: $$\int_{0}^{\infty }\frac{\beta ~s{ech}(\pi k\,x)}{\beta ^{2}+x^{2}}% \,dx=\int_{0}^{\infty }\frac{\beta ~}{\beta ^{2}+x^{2}}\frac{1\,}{\cosh \left( \pi k\,x\right) }dx  \tag{5}\label{5}$$ is done in Sangchul Lee and returns the solution of \eqref{1}: $$\mathcal{I}\left( \beta \right) =\frac{\pi }{2}+\sum_{k=1}^{\infty }(-1)^{k}\left( \psi \left( \frac{k\,\beta \ }{2}+\frac{3}{4}\right) -\psi \left( \frac{k\,\beta \ }{2}+\frac{1}{4}\right) \right) \;  \tag{6}\label{6}$$ Using nospoon returns $\mathcal {I} \left(1\right) = 1 $. A proof is upon request. For the readability, here some of the steps performed in Sangchul Lee . Transformation of \eqref{5} with $y=\frac{x}{% \beta }$ leads to: $$\int_{0}^{\infty }\frac{\beta ~}{\beta ^{2}+x^{2}}\frac{1\,}{\cosh \left( \pi k\,x\right) }dx=\int_{0}^{\infty }\frac{1~}{1+y^{2}}\frac{1\,}{\cosh \left( a\,y\right) }dy  \tag{7}\label{7}$$ with $a=k~\beta \,\pi $. Transformation with $z=$ $\frac{a\,y}{\pi }$ leads to: $$\int_{0}^{\infty }\frac{1~}{1+y^{2}}\frac{1\,}{\cosh \left( a\,y\right) }dy=% \frac{\pi a}{2}\int_{-\infty }^{\infty }\frac{dz}{\left( a^{2}+\pi ^{2}z^{2}\right) \cosh \left( \pi \,z\right) }  \tag{8}\label{8}$$ In the following, we need the Fourier transform of $f$ $$\widehat{f}\left( \xi \right) =\mathcal{F}\left[ f\left( z\right) \right] =\int_{\mathcal{R}}f\left( z\right) \exp \left( -2\pi i\xi z\right) ~dz \tag{9}\label{9}$$ Let $$f\left( z\right) =s{ech}(\pi \,z),\;g\left( z\right) =\frac{1}{a^{2}+\pi ^{2}z^{2}}  \tag{10}\label{10}$$ and $$\widehat{f}\left( \xi \right) =s{ech}(\pi \,\xi ),\;\widehat{g}\left( \xi \right) =\frac{1}{a}\exp \left( -2a\left\vert \xi \right\vert \right)  \tag{11}\label{11}$$ Also, if both $f$ and $g$ are in $L^{2}$, then $$\int_{\mathcal{R}}\widehat{f}~g=\int_{\mathcal{R}}f~\widehat{g} \tag{12}\label{12}$$ results to $$\frac{\pi }{2}+\pi a\sum_{k=1}^{\infty }(-1)^{k}\int_{-\infty }^{\infty }% \frac{dz}{\left( a^{2}+\pi ^{2}z^{2}\right) \cosh \left( \pi \,z\right) }=% \frac{\pi }{2}+2\pi \sum_{k=1}^{\infty }(-1)^{k}\int_{0}^{\infty }\frac{\exp \left( -2\pi k\beta ~z\right) }{\cosh \left( \pi \,z\right) }dz  \tag{13}\label{13}$$ Further transformations then leads finally to the solution \eqref{6}. Now, for an equivalent integral representation of \eqref{1}, we first perform the sum in \eqref{13}: $$\mathcal{I}\left( \beta \right) =\frac{\pi }{2}-2\pi \int_{0}^{\infty }\frac{% s{ech}(\pi \,z)}{1+\exp \left( 2\pi \beta ~z\right) }dz  \tag{14}\label{14}$$ For $\beta =1$, the known value $\mathcal{I}\left( 1\right) =1$ results. With the aid of Mathematica,  further analytical expressions for some fixed $\beta$-values can be calculated.  With \eqref{4} the following identity results: $$\sum_{k=1}^{\infty }(-1)^{k}\int_{0}^{\infty }\frac{s{ech}(k~\pi \,z)}{\beta ^{2}+z^{2}}dz=-\frac{\pi }{\beta }\int_{0}^{\infty }\frac{s{ech}(\pi \,z)}{% 1+\exp \left( 2\pi \beta ~z\right) }dz  \tag{15}\label{15}$$ The integral form \eqref{14} can be transformed into other interesting expressions.  Using the known identity Kim : $$\,_{2}F_{1}\left( a,a;a+1;\frac{1}{2}\right) =2^{a-1}a~\left( \psi \left(  \frac{a}{2}+\frac{1}{2}\right) -\psi \left( \frac{a}{2}\right) \right) \tag{16}\label{16}$$ and \eqref{6}, these expressions can be reproduced and further identities can be derived. For the readability, I omit lots of results, I've found so far. In case of interest, these results can be requested. $\textbf{1st Question}$ $\textit{Does anybody know how to approach this sum \eqref{6}?} $ $\textit{ Where can I find out more about dealing with the sum?}$ $\textit{Is it possible to derive a simpler expression?}$ $\textbf{2st Question}$ $\textit{Can we find a closed form expression for $\mathcal{I}\left( \beta\right)$, at least for $\beta $ $\in \mathbb{N}$?, distinguishing even/odd $\beta $ ?}$ $\textbf{Bonus Q}$ $\textit{How can I proof the identity \eqref{15} with the help of the Poisson Summation Formula?}$ $\textit{Are there any further results can be obtained by doing so?}$",,"['integration', 'sequences-and-series', 'definite-integrals', 'closed-form', 'theta-functions']"
33,Volume in zero dimensional space,Volume in zero dimensional space,,"Suppose $A\subset \mathbb{R}^n$ is a compact, convex and centrally symmetric set such that $(x_1,\ldots,x_n)\in A$ if $$ |x_1|+\ldots+|x_r|+2\left(\sqrt{x_{r+1}^2 + x_{r+2}^2} + \ldots + \sqrt{x_{n-1}^2 + x_{n}^2}\right) \leq n$$ If $n=r+2s$, I want to prove that (Lebesgue measure)   $$ \mathrm{vol}(A) = \frac{n^n}{n!}2^r \left(\frac{\pi}{2}\right)^s$$ To prove this, I assumed that $V_{r,s}(t)$ denote the volume of the subset $\mathbb{R}^{r+2s}$ defined by $$|x_1|+\ldots+|x_r|+2\left(\sqrt{x_{r+1}^2 + x_{r+2}^2} + \ldots + \sqrt{x_{r+2s-1}^2 + x_{r+2s}^2}\right) \leq t$$ Therefore, $$V_{r,s}(t) = t^{r+2s}V_{r,s}(1)$$ I have so far proved that ( following this ): $$V_{r,s}(1) =\frac{1}{n!}2^r \left(\frac{\pi}{2}\right)^sV_{0,0}(1)$$ But to conclude my proof I must show that $$V_{0,0}(1)=1$$ So, the question is : Why $V_{0,0}=1$?","Suppose $A\subset \mathbb{R}^n$ is a compact, convex and centrally symmetric set such that $(x_1,\ldots,x_n)\in A$ if $$ |x_1|+\ldots+|x_r|+2\left(\sqrt{x_{r+1}^2 + x_{r+2}^2} + \ldots + \sqrt{x_{n-1}^2 + x_{n}^2}\right) \leq n$$ If $n=r+2s$, I want to prove that (Lebesgue measure)   $$ \mathrm{vol}(A) = \frac{n^n}{n!}2^r \left(\frac{\pi}{2}\right)^s$$ To prove this, I assumed that $V_{r,s}(t)$ denote the volume of the subset $\mathbb{R}^{r+2s}$ defined by $$|x_1|+\ldots+|x_r|+2\left(\sqrt{x_{r+1}^2 + x_{r+2}^2} + \ldots + \sqrt{x_{r+2s-1}^2 + x_{r+2s}^2}\right) \leq t$$ Therefore, $$V_{r,s}(t) = t^{r+2s}V_{r,s}(1)$$ I have so far proved that ( following this ): $$V_{r,s}(1) =\frac{1}{n!}2^r \left(\frac{\pi}{2}\right)^sV_{0,0}(1)$$ But to conclude my proof I must show that $$V_{0,0}(1)=1$$ So, the question is : Why $V_{0,0}=1$?",,"['integration', 'multivariable-calculus', 'lebesgue-measure', 'volume']"
34,Closed-form for $\int_0^\infty {\frac{{\ln \left( {1 + x} \right)}}{{1 + ax}}{e^{ - bx}}{x^n}{\rm{d}}x} $,Closed-form for,\int_0^\infty {\frac{{\ln \left( {1 + x} \right)}}{{1 + ax}}{e^{ - bx}}{x^n}{\rm{d}}x} ,"I am trying to find the integration of the following $$\int_0^\infty  {\frac{{\ln \left( {1 + x} \right)}}{{1 + ax}}{e^{ - bx}}{x^n}{\rm{d}}x} $$ Here $a>0, b>0$, and $n$ is an integer. I think if we get the Meijer-G representation of $$\frac{{\ln \left( {1 + x} \right)}}{{1 + ax}}$$ we can use Laplace transform to get the closed-form expression. But I don't know how to express the above function as Meijer-G function. Thanks.","I am trying to find the integration of the following $$\int_0^\infty  {\frac{{\ln \left( {1 + x} \right)}}{{1 + ax}}{e^{ - bx}}{x^n}{\rm{d}}x} $$ Here $a>0, b>0$, and $n$ is an integer. I think if we get the Meijer-G representation of $$\frac{{\ln \left( {1 + x} \right)}}{{1 + ax}}$$ we can use Laplace transform to get the closed-form expression. But I don't know how to express the above function as Meijer-G function. Thanks.",,"['integration', 'definite-integrals', 'improper-integrals']"
35,"Prove that $\lim_n \int_{\Bbb R} \frac{\sin(n^2 x^5)}{n^2 x^4} \chi_{(0,n]} d\lambda(x) = 0$",Prove that,"\lim_n \int_{\Bbb R} \frac{\sin(n^2 x^5)}{n^2 x^4} \chi_{(0,n]} d\lambda(x) = 0","Prove that: $$\lim_n \int_{\Bbb R} \frac{\sin(n^2 x^5)}{n^2 x^4} \chi_{(0,n]} d\lambda(x) = 0$$ I am self-learning these stuff, and I would like to check whether I did things right. Here's my work: Call $f_n(x)$ the integrand. We have: $$\left| f_n(x) \right| = \left| \frac{\sin(n^2 x^5)}{n^2 x^4}\chi_{(0,1]} + \frac{\sin(n^2 x^5)}{n^2 x^4}\chi_{(1,n]}\right| \le \frac{n^2 x^5}{n^2x^4} \chi_{(0,1]} + \frac{1}{n^2 x^4} \chi_{(1,n]} \\ \le x \chi_{(0,1]} + \frac1{x^4} \chi_{(1,n]} \le x \chi_{[0,1]} + \frac{1}{x^4}\chi_{[1,\infty)} := g(x)$$ for all $n \ge 1$ and $x \in \Bbb R$ . Note that $(f_n)$ is a sequence of measurable functions, and it converges pointwise to $0$ . The function $x \mapsto x$ is Riemann-integrable on $[0,1]$ , hence it is Lebesgue-integrable and the integrals coincide. Also, $x \mapsto 1/x^4$ is Riemann-integrable on every compact $[1,a]$ , with $a > 1$ , and its $\int_1^{\infty}$ is absolutely convergent, hence it is Lebesgue integrable and the integrals coincide. Then, $$\int_{\Bbb R} g d\lambda = \int_0^1 x dx + \int_1^{\infty} \frac{dx}{x^4} < \infty$$ Hence $g \in L^1$ . Therefore, by LDCT, $$\lim_n \int_{\Bbb R} f_n d\lambda = \int_{\Bbb R} \lim_n f_n d\lambda = 0$$","Prove that: I am self-learning these stuff, and I would like to check whether I did things right. Here's my work: Call the integrand. We have: for all and . Note that is a sequence of measurable functions, and it converges pointwise to . The function is Riemann-integrable on , hence it is Lebesgue-integrable and the integrals coincide. Also, is Riemann-integrable on every compact , with , and its is absolutely convergent, hence it is Lebesgue integrable and the integrals coincide. Then, Hence . Therefore, by LDCT,","\lim_n \int_{\Bbb R} \frac{\sin(n^2 x^5)}{n^2 x^4} \chi_{(0,n]} d\lambda(x) = 0 f_n(x) \left| f_n(x) \right| = \left| \frac{\sin(n^2 x^5)}{n^2 x^4}\chi_{(0,1]} + \frac{\sin(n^2 x^5)}{n^2 x^4}\chi_{(1,n]}\right| \le \frac{n^2 x^5}{n^2x^4} \chi_{(0,1]} + \frac{1}{n^2 x^4} \chi_{(1,n]} \\ \le x \chi_{(0,1]} + \frac1{x^4} \chi_{(1,n]} \le x \chi_{[0,1]} + \frac{1}{x^4}\chi_{[1,\infty)} := g(x) n \ge 1 x \in \Bbb R (f_n) 0 x \mapsto x [0,1] x \mapsto 1/x^4 [1,a] a > 1 \int_1^{\infty} \int_{\Bbb R} g d\lambda = \int_0^1 x dx + \int_1^{\infty} \frac{dx}{x^4} < \infty g \in L^1 \lim_n \int_{\Bbb R} f_n d\lambda = \int_{\Bbb R} \lim_n f_n d\lambda = 0",['integration']
36,"How do I get $ \int_0^1 \frac{dz}{\sqrt{z(z - 1\,)(z+1\,)}} = \frac{\sqrt{\pi}}{2} \frac{\Gamma(\frac{3}{4})}{\Gamma(\frac{9}{4})}$?",How do I get ?," \int_0^1 \frac{dz}{\sqrt{z(z - 1\,)(z+1\,)}} = \frac{\sqrt{\pi}}{2} \frac{\Gamma(\frac{3}{4})}{\Gamma(\frac{9}{4})}","While reading physics papers I found a very interesting integral so I decided to write it down.  Let $p(z) = z^ 3 - 3\Lambda^ 2 z$ where $\Lambda$ could be any number.  If you want $\Lambda = 1$ and $p(z) = z^ 3 - 3z$.  Then $$ \int_0^{\sqrt{3}\Lambda} \frac{dz}{\sqrt{p(z)}} = \int_0^{\sqrt{3}\Lambda} \frac{dz}{\sqrt{z(z - \sqrt{3}\Lambda\,)(z+\sqrt{3}\Lambda\,)}} = \frac{\sqrt{\pi}}{2} \frac{\Gamma(\frac{3}{4})}{\Gamma(\frac{9}{4})} (\sqrt{3}\Lambda)^{5/2}$$ The physics paper at least tell us $\int \propto \Lambda^{5/2}$ so we know the growth rate. It could be that $\Lambda = \frac{1}{\sqrt{3}}$ is even simpler than $\Lambda = 1$. $$  \int_0^1 \frac{dz}{\sqrt{z(z - 1\,)(z+1\,)}} = \frac{\sqrt{\pi}}{2} \frac{\Gamma(\frac{3}{4})}{\Gamma(\frac{9}{4})}$$ This should be connected to the Riemann surface $y^ 2 = z(z^2 -1)$.  And we are computing a period of the Riemann surface. Contour integration is really important here.  Checking on Wolfram Alpha gives a different answer: $$ \int_0^1 \frac{dz}{x(x^2-1)} = - 2i\sqrt{\pi}\,\frac{ \Gamma(\frac{5}{4})}{\Gamma(\frac{3}{4})}$$ I am guessing this is either the same number or Mathematica is choosing a different contour. Physicists love contour integrals (taken from physics.stackexchange):","While reading physics papers I found a very interesting integral so I decided to write it down.  Let $p(z) = z^ 3 - 3\Lambda^ 2 z$ where $\Lambda$ could be any number.  If you want $\Lambda = 1$ and $p(z) = z^ 3 - 3z$.  Then $$ \int_0^{\sqrt{3}\Lambda} \frac{dz}{\sqrt{p(z)}} = \int_0^{\sqrt{3}\Lambda} \frac{dz}{\sqrt{z(z - \sqrt{3}\Lambda\,)(z+\sqrt{3}\Lambda\,)}} = \frac{\sqrt{\pi}}{2} \frac{\Gamma(\frac{3}{4})}{\Gamma(\frac{9}{4})} (\sqrt{3}\Lambda)^{5/2}$$ The physics paper at least tell us $\int \propto \Lambda^{5/2}$ so we know the growth rate. It could be that $\Lambda = \frac{1}{\sqrt{3}}$ is even simpler than $\Lambda = 1$. $$  \int_0^1 \frac{dz}{\sqrt{z(z - 1\,)(z+1\,)}} = \frac{\sqrt{\pi}}{2} \frac{\Gamma(\frac{3}{4})}{\Gamma(\frac{9}{4})}$$ This should be connected to the Riemann surface $y^ 2 = z(z^2 -1)$.  And we are computing a period of the Riemann surface. Contour integration is really important here.  Checking on Wolfram Alpha gives a different answer: $$ \int_0^1 \frac{dz}{x(x^2-1)} = - 2i\sqrt{\pi}\,\frac{ \Gamma(\frac{5}{4})}{\Gamma(\frac{3}{4})}$$ I am guessing this is either the same number or Mathematica is choosing a different contour. Physicists love contour integrals (taken from physics.stackexchange):",,"['integration', 'contour-integration', 'riemann-surfaces']"
37,Where did I mistake to integrate $I=\int\sqrt{\frac{\sin(x-\alpha)}{\sin(x+\alpha)}} \; dx\; ?$,Where did I mistake to integrate,I=\int\sqrt{\frac{\sin(x-\alpha)}{\sin(x+\alpha)}} \; dx\; ?,"It was given to integrate $$I=\int\sqrt{\frac{\sin(x-\alpha)}{\sin(x+\alpha)}} \; dx.$$ Attempt: \begin{align}I&= \int\sqrt{\frac{\sin((x+\alpha)-2\alpha)}{\sin(x+\alpha)}}\; dx\\&= \sqrt{\sin 2\alpha}\int\sqrt{\cot 2\alpha - \cot (x+\alpha)}\;dx\; .\end{align} Then I took \begin{align}\cot 2\alpha - \cot (x+\alpha)= z^2 \\ \implies [1 + \cot^2(x+\alpha)]\;dx= 2z\;dz\\ \implies [1+\{\cot 2\alpha - z^2\}^2]\; dx= 2z\;dz\; .\end{align} Now, \begin{align}\int\sqrt{\cot 2\alpha - \cot (x+\alpha)}\; dx\\ &= \int\frac{z\cdot 2z}{1+\{\cot 2\alpha - z^2\}^2}\;dz\\ &= \int\frac{2}{\dfrac{(1+ \cot^2 2\alpha)}{z^2} + z^2 -2\cot2\alpha}\; dz\\ &= \int \frac{\left(1+ \dfrac{\sqrt{(1+ \cot^2 2\alpha)}}{z^2}\right)+ \left(1- \dfrac{\sqrt{(1+ \cot^2 2\alpha)}}{z^2}\right)}{\dfrac{(1+ \cot^2 2\alpha)}{z^2} + z^2 -2\cot2\alpha}\; dz \; .\end{align} This makes me to break the integral to get \begin{align}\int\sqrt{\cot 2\alpha - \cot (x+\alpha)}\; dx\\ &= \int \frac{\left(1+ \dfrac{\sqrt{(1+ \cot^2 2\alpha)}}{z^2}\right)+ \left(1- \dfrac{\sqrt{(1+ \cot^2 2\alpha)}}{z^2}\right)}{\dfrac{(1+ \cot^2 2\alpha)}{z^2} + z^2 -2\cot2\alpha}\; dz\\ \\ &= \int\frac{\left(1+ \dfrac{\sqrt{(1+ \cot^2 2\alpha)}}{z^2}\right)}{\left(z-\dfrac{\sqrt{(1+ \cot^2 2\alpha)}}{z}\right) +\text{const.}}\; dz +\int\frac{\left(1- \dfrac{\sqrt{(1+ \cot^2 2\alpha)}}{z^2}\right)}{\left(z+\dfrac{\sqrt{(1+ \cot^2 2\alpha)}}{z}\right) +\text{const.}}\; dz \\ &=-\frac{1}{z- \dfrac{(1+ \cot^2 2\alpha)}{z}}-\frac{1}{z+ \dfrac{(1+ \cot^2 2\alpha)}{z}} .\end{align} So, $$I= -\sqrt{\sin 2\alpha}\left(\frac{1}{z- \dfrac{(1+ \cot^2 2\alpha)}{z}}+\frac{1}{z+ \dfrac{(1+ \cot^2 2\alpha)}{z}}\right)\; .$$ Unfortunately, my book gave the answer as $$I= \cos\alpha \cos^{-1} (\cos x\sec\alpha) - \sin\alpha\log\left(\sin x+ \sqrt{\sin^2 x - \sin^2\alpha}\right)\; .$$ This is not near to my solution; I've made somewhere a big plunder. So, could anyone please tell me where I did mistake? Is my attempted technique wrong?","It was given to integrate Attempt: Then I took Now, This makes me to break the integral to get So, Unfortunately, my book gave the answer as This is not near to my solution; I've made somewhere a big plunder. So, could anyone please tell me where I did mistake? Is my attempted technique wrong?",I=\int\sqrt{\frac{\sin(x-\alpha)}{\sin(x+\alpha)}} \; dx. \begin{align}I&= \int\sqrt{\frac{\sin((x+\alpha)-2\alpha)}{\sin(x+\alpha)}}\; dx\\&= \sqrt{\sin 2\alpha}\int\sqrt{\cot 2\alpha - \cot (x+\alpha)}\;dx\; .\end{align} \begin{align}\cot 2\alpha - \cot (x+\alpha)= z^2 \\ \implies [1 + \cot^2(x+\alpha)]\;dx= 2z\;dz\\ \implies [1+\{\cot 2\alpha - z^2\}^2]\; dx= 2z\;dz\; .\end{align} \begin{align}\int\sqrt{\cot 2\alpha - \cot (x+\alpha)}\; dx\\ &= \int\frac{z\cdot 2z}{1+\{\cot 2\alpha - z^2\}^2}\;dz\\ &= \int\frac{2}{\dfrac{(1+ \cot^2 2\alpha)}{z^2} + z^2 -2\cot2\alpha}\; dz\\ &= \int \frac{\left(1+ \dfrac{\sqrt{(1+ \cot^2 2\alpha)}}{z^2}\right)+ \left(1- \dfrac{\sqrt{(1+ \cot^2 2\alpha)}}{z^2}\right)}{\dfrac{(1+ \cot^2 2\alpha)}{z^2} + z^2 -2\cot2\alpha}\; dz \; .\end{align} \begin{align}\int\sqrt{\cot 2\alpha - \cot (x+\alpha)}\; dx\\ &= \int \frac{\left(1+ \dfrac{\sqrt{(1+ \cot^2 2\alpha)}}{z^2}\right)+ \left(1- \dfrac{\sqrt{(1+ \cot^2 2\alpha)}}{z^2}\right)}{\dfrac{(1+ \cot^2 2\alpha)}{z^2} + z^2 -2\cot2\alpha}\; dz\\ \\ &= \int\frac{\left(1+ \dfrac{\sqrt{(1+ \cot^2 2\alpha)}}{z^2}\right)}{\left(z-\dfrac{\sqrt{(1+ \cot^2 2\alpha)}}{z}\right) +\text{const.}}\; dz +\int\frac{\left(1- \dfrac{\sqrt{(1+ \cot^2 2\alpha)}}{z^2}\right)}{\left(z+\dfrac{\sqrt{(1+ \cot^2 2\alpha)}}{z}\right) +\text{const.}}\; dz \\ &=-\frac{1}{z- \dfrac{(1+ \cot^2 2\alpha)}{z}}-\frac{1}{z+ \dfrac{(1+ \cot^2 2\alpha)}{z}} .\end{align} I= -\sqrt{\sin 2\alpha}\left(\frac{1}{z- \dfrac{(1+ \cot^2 2\alpha)}{z}}+\frac{1}{z+ \dfrac{(1+ \cot^2 2\alpha)}{z}}\right)\; . I= \cos\alpha \cos^{-1} (\cos x\sec\alpha) - \sin\alpha\log\left(\sin x+ \sqrt{\sin^2 x - \sin^2\alpha}\right)\; .,[]
38,Relating Integration by Substitution to Change of Variables Theorem,Relating Integration by Substitution to Change of Variables Theorem,,"I'm having trouble relating the change of variables theorem from measure theory to the integration by substitution formula taught in Calculus.  I've always thought they were basically saying the same thing, but I can't quite see it.  Below I assume everything that needs to be integrable is integrable. Change of Variables Theorem : ( Wiki )  Let $(X_1, \Sigma_1, \mu)$ be a measure space and $(X_2, \Sigma_2)$ be   a measurable space.  Let $f: X_1 \to X_2$ be measurable and let $f_*[\mu]$ be the pushforward measure on $X_2$.  Finally let $g$ be a measurable function on $X_2$.  Then   $$ \int_{X_1} g \circ f \, \mathrm{d}\mu = \int_{X_2} g \, \mathrm{d}(f_*[\mu]). $$ Integration by substitution : ( Wiki ) Let $f: [a,b] \to I$ be continuously differentiable for some interval $I \subset \mathbb{R}$ and let $g: I \to \mathbb{R}$ be continuous.  Then   $$ \int_a^b (g \circ f)(t) \cdot f^\prime(t) \, \mathrm{d}t = \int_{f(a)}^{f(b)} g(x) \, \mathrm{d} x. $$ My attempt at relating the two, starting from change of variables theorem: Let $(X_1, \Sigma_1) = ([a,b], \mathcal{B}([a,b]))$ and $(X_2, \Sigma_2) = (I, \mathcal{B}(I))$.  Let $f$ be continuously differentiable and increasing and let $\mu = \mu_f$ be the Lebesgue-Stieltjes measure for $f$ on $[a,b]$.  Then $f^\prime = \frac{\mathrm{d} \mu_f}{\mathrm{d} \lambda_1}$, the Radon-Nikodym derivative of $\mu_f$ w.r.t. the Lebesgue measure $\lambda_1$ on $[a,b]$.  Finally, the pushforward measure $f_*[\mu_f] = \lambda_2$, the Lebesgue measure on $I$.  Hence \begin{align*} \int_a^b (g \circ f)(t) \cdot f^\prime(t) \, \mathrm{d}t & = \int_{[a,b]} (g \circ f) \cdot f^\prime \, \mathrm{d}\lambda_1 \\ & = \int_{[a,b]} g \circ f \, \mathrm{d} \mu_f \\ & = \int_I g \, \mathrm{d} (f_*[\mu_f]) \\ & = \int_I g \, \mathrm{d} \lambda_2 \\ & = \int_{f(a)}^{f(b)} g(x) \, \mathrm{d} x. \end{align*} The first line is because $(g \circ f) \cdot f^\prime$ is continuous and so the Riemann and Lebesgue integrals coincide, the second is because $f^\prime = \frac{\mathrm{d} \mu_f}{\mathrm{d} \lambda_1}$, the third is the change of variables theorem, the fourth is because $f_*[\mu_f] = \lambda_2$, and the last line is again because $g$ is continuous and so the Riemann and Lebesgue integrals coincide. So assuming the above is correct, I can relate the two for monotone increasing $f$, but not for more general continuous $f$.  How can I show this?","I'm having trouble relating the change of variables theorem from measure theory to the integration by substitution formula taught in Calculus.  I've always thought they were basically saying the same thing, but I can't quite see it.  Below I assume everything that needs to be integrable is integrable. Change of Variables Theorem : ( Wiki )  Let $(X_1, \Sigma_1, \mu)$ be a measure space and $(X_2, \Sigma_2)$ be   a measurable space.  Let $f: X_1 \to X_2$ be measurable and let $f_*[\mu]$ be the pushforward measure on $X_2$.  Finally let $g$ be a measurable function on $X_2$.  Then   $$ \int_{X_1} g \circ f \, \mathrm{d}\mu = \int_{X_2} g \, \mathrm{d}(f_*[\mu]). $$ Integration by substitution : ( Wiki ) Let $f: [a,b] \to I$ be continuously differentiable for some interval $I \subset \mathbb{R}$ and let $g: I \to \mathbb{R}$ be continuous.  Then   $$ \int_a^b (g \circ f)(t) \cdot f^\prime(t) \, \mathrm{d}t = \int_{f(a)}^{f(b)} g(x) \, \mathrm{d} x. $$ My attempt at relating the two, starting from change of variables theorem: Let $(X_1, \Sigma_1) = ([a,b], \mathcal{B}([a,b]))$ and $(X_2, \Sigma_2) = (I, \mathcal{B}(I))$.  Let $f$ be continuously differentiable and increasing and let $\mu = \mu_f$ be the Lebesgue-Stieltjes measure for $f$ on $[a,b]$.  Then $f^\prime = \frac{\mathrm{d} \mu_f}{\mathrm{d} \lambda_1}$, the Radon-Nikodym derivative of $\mu_f$ w.r.t. the Lebesgue measure $\lambda_1$ on $[a,b]$.  Finally, the pushforward measure $f_*[\mu_f] = \lambda_2$, the Lebesgue measure on $I$.  Hence \begin{align*} \int_a^b (g \circ f)(t) \cdot f^\prime(t) \, \mathrm{d}t & = \int_{[a,b]} (g \circ f) \cdot f^\prime \, \mathrm{d}\lambda_1 \\ & = \int_{[a,b]} g \circ f \, \mathrm{d} \mu_f \\ & = \int_I g \, \mathrm{d} (f_*[\mu_f]) \\ & = \int_I g \, \mathrm{d} \lambda_2 \\ & = \int_{f(a)}^{f(b)} g(x) \, \mathrm{d} x. \end{align*} The first line is because $(g \circ f) \cdot f^\prime$ is continuous and so the Riemann and Lebesgue integrals coincide, the second is because $f^\prime = \frac{\mathrm{d} \mu_f}{\mathrm{d} \lambda_1}$, the third is the change of variables theorem, the fourth is because $f_*[\mu_f] = \lambda_2$, and the last line is again because $g$ is continuous and so the Riemann and Lebesgue integrals coincide. So assuming the above is correct, I can relate the two for monotone increasing $f$, but not for more general continuous $f$.  How can I show this?",,"['integration', 'measure-theory', 'lebesgue-integral', 'lebesgue-measure']"
39,$\int_{-\pi/2}^{\pi/2} \cos(a \cos\theta) e^{im\theta} e^{-ib\sin\theta} \mathrm{d}\theta $ Integration,Integration,\int_{-\pi/2}^{\pi/2} \cos(a \cos\theta) e^{im\theta} e^{-ib\sin\theta} \mathrm{d}\theta ,"I am struggling to find the integration of the expression below, $$\int_{-\pi/2}^{\pi/2} \cos(a \cos\theta) e^{im\theta} e^{-ib\sin\theta} \mathrm{d}\theta $$ where $a$ and $b$ are arbitrary constant and $m$ is an integer. I have found the result for $m = 0$ which contains $J_0(\sqrt{a^2 + b^2})$ term. I think for this integration, it will involve the $m$-th order of Bessel function of the first kind.","I am struggling to find the integration of the expression below, $$\int_{-\pi/2}^{\pi/2} \cos(a \cos\theta) e^{im\theta} e^{-ib\sin\theta} \mathrm{d}\theta $$ where $a$ and $b$ are arbitrary constant and $m$ is an integer. I have found the result for $m = 0$ which contains $J_0(\sqrt{a^2 + b^2})$ term. I think for this integration, it will involve the $m$-th order of Bessel function of the first kind.",,"['integration', 'trigonometry', 'definite-integrals', 'bessel-functions']"
40,Integral with absolute value of the derivative,Integral with absolute value of the derivative,,"I'm trying to estimate this integral $\int_0^1 t |p'(t)|dt$ using this value $\int_0^1 |p(t)|dt$; here $p $ is a real polynomial. This means, I am looking for an $M>0$ such that $$\int_0^1 |t p'(t)|dt \le M \cdot \int_0^1 |p(t)|dt$$ I've been thinking about integration by parts but I don't know how to do that with an absolute value involved. Could you help me with that?","I'm trying to estimate this integral $\int_0^1 t |p'(t)|dt$ using this value $\int_0^1 |p(t)|dt$; here $p $ is a real polynomial. This means, I am looking for an $M>0$ such that $$\int_0^1 |t p'(t)|dt \le M \cdot \int_0^1 |p(t)|dt$$ I've been thinking about integration by parts but I don't know how to do that with an absolute value involved. Could you help me with that?",,"['integration', 'definite-integrals', 'normed-spaces']"
41,Why are some convergent Lebesgue integrals 'undefined'? [duplicate],Why are some convergent Lebesgue integrals 'undefined'? [duplicate],,"This question already has answers here : Why do we restrict the definition of Lebesgue Integrability? (8 answers) Closed 9 years ago . I sometimes read statements such as The integral $$\int_0^{\infty} dx \, \frac{\sin x}{x}  $$ does not exist as a Lebesgue integral, because it is not absolutely convergent. But according to my understanding, the integral $$\int_0^{R} dx \, \frac{\sin x}{x}  $$ exists as a Lebesgue integral for every $R>0$. Why can't we simply define $$ \int_0^{\infty} dx \, \frac{\sin x}{x}  = \lim\limits_{R \rightarrow \infty} \int_0^{R} dx \, \frac{\sin x}{x},   $$ and hence give meaning to the former integral as a Lebesgue integral? Isn't this also how one defines improper Riemann integrals, as a limit of proper integrals? Please point out any misunderstandings.","This question already has answers here : Why do we restrict the definition of Lebesgue Integrability? (8 answers) Closed 9 years ago . I sometimes read statements such as The integral $$\int_0^{\infty} dx \, \frac{\sin x}{x}  $$ does not exist as a Lebesgue integral, because it is not absolutely convergent. But according to my understanding, the integral $$\int_0^{R} dx \, \frac{\sin x}{x}  $$ exists as a Lebesgue integral for every $R>0$. Why can't we simply define $$ \int_0^{\infty} dx \, \frac{\sin x}{x}  = \lim\limits_{R \rightarrow \infty} \int_0^{R} dx \, \frac{\sin x}{x},   $$ and hence give meaning to the former integral as a Lebesgue integral? Isn't this also how one defines improper Riemann integrals, as a limit of proper integrals? Please point out any misunderstandings.",,"['integration', 'measure-theory', 'lebesgue-integral', 'lebesgue-measure']"
42,Changing order of integration limits,Changing order of integration limits,,"$$\int_{1}^{3} \int_{0}^y x+y-1 \, dx \, dy = 9$$ How would I change the order of integration here? Wouldn't this require two integrals? $$\int_{0}^{1} \int_{1}^3 x+y-1 \, dy \, dx + \int_{1}^{3} \int_{x}^3 x+y-1 \, dy \, dx = 9$$ Why does this integral below work? $$\int_{0}^{3} \int_{x}^3 x+y-1 \, dy \, dx = 9$$ Is this just a coincidence? I'm not sure how to plot this in 3D. Here's a graph of the xy plane and the boundaries of the region on it. This is how I visualized the region. Perhaps I did something wrong? I am finding the volume between the surface z = x + y and z = 1","$$\int_{1}^{3} \int_{0}^y x+y-1 \, dx \, dy = 9$$ How would I change the order of integration here? Wouldn't this require two integrals? $$\int_{0}^{1} \int_{1}^3 x+y-1 \, dy \, dx + \int_{1}^{3} \int_{x}^3 x+y-1 \, dy \, dx = 9$$ Why does this integral below work? $$\int_{0}^{3} \int_{x}^3 x+y-1 \, dy \, dx = 9$$ Is this just a coincidence? I'm not sure how to plot this in 3D. Here's a graph of the xy plane and the boundaries of the region on it. This is how I visualized the region. Perhaps I did something wrong? I am finding the volume between the surface z = x + y and z = 1",,['integration']
43,Definite integrals and möbius transformations,Definite integrals and möbius transformations,,"In examples I have seen for solving an infinite integral from $-\infty$ to $\infty$ using contour integration, the real axis becomes part of the contour of integration in the complex plane, and the residue method is used. Posted here is an example of transforming the real line to a unit circle at the complex origin using Möbius transformations. The residue method is used.  I have not seen this method before. Can someone point me to the literature on this method?","In examples I have seen for solving an infinite integral from $-\infty$ to $\infty$ using contour integration, the real axis becomes part of the contour of integration in the complex plane, and the residue method is used. Posted here is an example of transforming the real line to a unit circle at the complex origin using Möbius transformations. The residue method is used.  I have not seen this method before. Can someone point me to the literature on this method?",,"['integration', 'contour-integration']"
44,Area and Polar Coordinates,Area and Polar Coordinates,,Would anyone be able to help me with this problem? I think I know the area formula in polar coordinates that should be used: the antiderivative of ((1/2)r^2 dtheta) from alpha to beta but I'm not really sure how to get the area of the removed part. Thank you for any help that could be provided.,Would anyone be able to help me with this problem? I think I know the area formula in polar coordinates that should be used: the antiderivative of ((1/2)r^2 dtheta) from alpha to beta but I'm not really sure how to get the area of the removed part. Thank you for any help that could be provided.,,"['integration', 'polar-coordinates', 'area']"
45,Intuition for Integration of Differential Forms,Intuition for Integration of Differential Forms,,"In mathematics, we define $dx^i$ as linear functionals, when speaking of integration. However, in physics, we interpret $dx^i$ as very small quantities. There is nothing inherently small about a basis functional (covector). So why can we treat them as such? Is there any bridge between the two forms of intuition?","In mathematics, we define $dx^i$ as linear functionals, when speaking of integration. However, in physics, we interpret $dx^i$ as very small quantities. There is nothing inherently small about a basis functional (covector). So why can we treat them as such? Is there any bridge between the two forms of intuition?",,"['integration', 'differential-geometry', 'notation', 'physics']"
46,Multiple Fourier Integrals involving Heaviside Theta Function,Multiple Fourier Integrals involving Heaviside Theta Function,,"I want to evaluate the integral: $$I=\int_{-\infty}^{\infty}dx_1 \int_{-\infty}^{\infty}dx_2 \  \Theta(x_1-x_2) \ e^{i(ax_1+bx_2)}$$ where $\Theta(x)$ is the Heaviside function. What I was doing now was taking the relation for $\Theta$: $\Theta (x)=-\frac{1}{2\pi i}\int_{-\infty}^{\infty}d\tau \frac{1}{\tau + i\epsilon} e^{-ix\tau}$ and I got: $$I= -\frac{1}{2\pi i}\int_{-\infty}^{\infty}dx_1 \int_{-\infty}^{\infty}dx_2\int_{-\infty}^{\infty}d\tau \ \frac{1}{\tau + i\epsilon}e^{-i(\tau-a)x_1}e^{-i(\tau+b)x_2}\\=2\pi i\int_{-\infty}^{\infty}d\tau\ \frac{1}{\tau + i\epsilon}\delta(\tau-a)\delta(\tau+b) =2\pi i\frac{\delta(a+b)}{a + i\epsilon}$$ I didn't know if the integral was convergent and I could simply interchange the integrals, so I tried it in a different form with $X=x_1+x_2$ and $x=x_1-x_2$ : $$I=\frac{1}{2}\int_{-\infty}^{\infty}dX \int_{-\infty}^{\infty}dx \ \Theta(x) \ e^{ia\frac{x+X}{2}+ib\frac{X-x}{2}} \\ =\pi \int_{-\infty}^{\infty}dx \ \Theta(x) e^{-2\pi i\frac{b-a}{4\pi}}\delta(\frac{b+a}{2})$$ With the Fourier Transform of the Heaviside function $\int_{-\infty}^{\infty}dk\ \Theta(k)e^{-2\pi i kx}=\frac{1}{2}(\delta(x)-\frac{i}{\pi k}) $ I get $$I=\pi \left(2\pi\delta(b-a)-\frac{4 i}{b-a}\right)\delta(a+b)=2\pi^2\delta(a)\delta(b)+2\pi i\frac{\delta(a+b)}{a}$$ I don't know yet where the $\delta(a)\delta(b)$ should come from in the first method. When I want to check that now and integrate $I$ over $a$ and $b$ I get from the first line: $$\int_{-\infty}^{\infty}da \int_{-\infty}^{\infty}db \ I = \int_{-\infty}^{\infty}dx_1\int_{-\infty}^{\infty}dx_2 \Theta(x_1-x_2) \delta(x_1)\delta(x_2)  \\ = \Theta(0)=\frac{1}{2}$$ and from the second result: $$\int_{-\infty}^{\infty}da \int_{-\infty}^{\infty}db \ I=4\pi^2-\int_{-\infty}^{\infty}db \frac{1}{b}=-\infty$$ Where did it go wrong? Is the integral correct? EDIT: corrected mistake in derivation because of comment.","I want to evaluate the integral: $$I=\int_{-\infty}^{\infty}dx_1 \int_{-\infty}^{\infty}dx_2 \  \Theta(x_1-x_2) \ e^{i(ax_1+bx_2)}$$ where $\Theta(x)$ is the Heaviside function. What I was doing now was taking the relation for $\Theta$: $\Theta (x)=-\frac{1}{2\pi i}\int_{-\infty}^{\infty}d\tau \frac{1}{\tau + i\epsilon} e^{-ix\tau}$ and I got: $$I= -\frac{1}{2\pi i}\int_{-\infty}^{\infty}dx_1 \int_{-\infty}^{\infty}dx_2\int_{-\infty}^{\infty}d\tau \ \frac{1}{\tau + i\epsilon}e^{-i(\tau-a)x_1}e^{-i(\tau+b)x_2}\\=2\pi i\int_{-\infty}^{\infty}d\tau\ \frac{1}{\tau + i\epsilon}\delta(\tau-a)\delta(\tau+b) =2\pi i\frac{\delta(a+b)}{a + i\epsilon}$$ I didn't know if the integral was convergent and I could simply interchange the integrals, so I tried it in a different form with $X=x_1+x_2$ and $x=x_1-x_2$ : $$I=\frac{1}{2}\int_{-\infty}^{\infty}dX \int_{-\infty}^{\infty}dx \ \Theta(x) \ e^{ia\frac{x+X}{2}+ib\frac{X-x}{2}} \\ =\pi \int_{-\infty}^{\infty}dx \ \Theta(x) e^{-2\pi i\frac{b-a}{4\pi}}\delta(\frac{b+a}{2})$$ With the Fourier Transform of the Heaviside function $\int_{-\infty}^{\infty}dk\ \Theta(k)e^{-2\pi i kx}=\frac{1}{2}(\delta(x)-\frac{i}{\pi k}) $ I get $$I=\pi \left(2\pi\delta(b-a)-\frac{4 i}{b-a}\right)\delta(a+b)=2\pi^2\delta(a)\delta(b)+2\pi i\frac{\delta(a+b)}{a}$$ I don't know yet where the $\delta(a)\delta(b)$ should come from in the first method. When I want to check that now and integrate $I$ over $a$ and $b$ I get from the first line: $$\int_{-\infty}^{\infty}da \int_{-\infty}^{\infty}db \ I = \int_{-\infty}^{\infty}dx_1\int_{-\infty}^{\infty}dx_2 \Theta(x_1-x_2) \delta(x_1)\delta(x_2)  \\ = \Theta(0)=\frac{1}{2}$$ and from the second result: $$\int_{-\infty}^{\infty}da \int_{-\infty}^{\infty}db \ I=4\pi^2-\int_{-\infty}^{\infty}db \frac{1}{b}=-\infty$$ Where did it go wrong? Is the integral correct? EDIT: corrected mistake in derivation because of comment.",,"['integration', 'fourier-analysis', 'integral-transforms']"
47,"On integrating a ""gaussian-like"" integral","On integrating a ""gaussian-like"" integral",,"Let the following ""gaussian-like"" integral: $$ I = \int_{\Re^n} \! \frac{1}{(2\pi)^{n/2}|\Sigma|^{1/2}} \exp \left\{ -\frac{1}{2} (\mathbf{x}-\mathbf{\mu})^T\Sigma^{-1}(\mathbf{x}-\mathbf{\mu}) \right\} \mathbf{x} \,\mathbf{d}\mathbf{x}, $$ where $\mathbf{x}=(x_1,\dots,x_n)^T$, $\mathbf{\mu} = (\mu_1,\dots,\mu_n)^T\in\Re^n$, and $\Sigma\in\mathbb{S}_{++}^{n}$. Our main goal is to evaluate the above integral. To this end, let $\mathbf{x}-\mathbf{\mu}=S\mathbf{y}$, where $S$ is an $n \times n$ orthogonal matrix ($S^T=S^{-1}$) with determinant equal to $1$. Using this change of variable, the quadratic form shown in the integral written as: $$ -\frac{1}{2}(\mathbf{x}-\mathbf{\mu})^T\Sigma^{-1}(\mathbf{x}-\mathbf{\mu})= -\frac{1}{2}\mathbf{y}^T(S^T\Sigma^{-1}S)\mathbf{y}= -\frac{1}{2}\mathbf{y}^T(S^{-1}\Sigma^{-1}S)\mathbf{y}= -\frac{1}{2}\mathbf{y}^TD\mathbf{y}, $$ where $D=\operatorname{diag}\{d_1,\dots,d_n\}$. As a result it is rewritten as follows: $$ -\frac{1}{2}(\mathbf{x}-\mathbf{\mu})^T\Sigma^{-1}(\mathbf{x}-\mathbf{\mu})= -\frac{1}{2}\sum_{k=1}^{n} d_i y_i^2 $$ Moreover, $\mathbf{x}-\mathbf{\mu}=S\mathbf{y} \Rightarrow \mathbf{x}=S\mathbf{y}+\mathbf{\mu}=[\mathbf{s_1}\:\dots\:\mathbf{s_n}]\mathbf{y}+\mathbf{\mu}=(\mathbf{s_1}\cdot\mathbf{y}+\mu_1,\dots, \mathbf{s_n}\cdot\mathbf{y}+\mu_n)^T,$ where $\mathbf{s}_j$ is the $j$-th column of matrix $S$. Using the above results, the original integral can be rewritten as follows: $$ I = (I_1,\dots,I_n)^T, $$ where the $j$-th element of $I$ is given by: $$ I_j =  \int_{\Re^n} \! \frac{1}{(2\pi)^{n/2}|\Sigma|^{1/2}} \exp \left\{ -\frac{1}{2}\sum_{k=1}^{n} d_i y_i^2 \right\} (\mathbf{s}_j\cdot\mathbf{y}+\mu_j) \,\mathbf{d}\mathbf{y}\\ =  \int_{\Re^n} \! \frac{1}{(2\pi)^{n/2}|\Sigma|^{1/2}} \exp \left\{ -\frac{1}{2}\sum_{k=1}^{n} d_i y_i^2 \right\} \mathbf{s}_j\cdot\mathbf{y} \,\mathbf{d}\mathbf{y}\\ + \int_{\Re^n} \! \frac{1}{(2\pi)^{n/2}|\Sigma|^{1/2}} \exp \left\{ -\frac{1}{2}\sum_{k=1}^{n} d_i y_i^2 \right\} \mu_j \,\mathbf{d}\mathbf{y} \Rightarrow\\ I_j = \int_{\Re^n} \! \frac{1}{(2\pi)^{n/2}|\Sigma|^{1/2}} \exp \left\{ -\frac{1}{2}\sum_{k=1}^{n} d_i y_i^2 \right\} \mathbf{s}_j\cdot\mathbf{y} \,\mathbf{d}\mathbf{y} + \mu_j $$ If we write the dot product $\mathbf{s}_j\cdot\mathbf{y}$ as $$ \mathbf{s}_j\cdot\mathbf{y} = \sum_{r=1}^{n} s_{jr}y_r, $$ then the integral $I_j$ is given by: $$ I_j = \int_{\Re^n} \! \frac{1}{(2\pi)^{n/2}|\Sigma|^{1/2}} \left(\sum_{r=1}^{n} s_{jr}y_r\right) \exp \left\{ -\frac{1}{2}\sum_{k=1}^{n} d_i y_i^2 \right\} \,\mathbf{d}\mathbf{y} + \mu_j $$ I would like to ask, first, whether the whole approach above is correct or not(if so, please correct me), and, second, how could I evaluate the last integral, $I_j$. Does it converge, like the gaussian integral over $\Re^n$? Thanks in advance! Every useful comment will be extremely appretiated!","Let the following ""gaussian-like"" integral: $$ I = \int_{\Re^n} \! \frac{1}{(2\pi)^{n/2}|\Sigma|^{1/2}} \exp \left\{ -\frac{1}{2} (\mathbf{x}-\mathbf{\mu})^T\Sigma^{-1}(\mathbf{x}-\mathbf{\mu}) \right\} \mathbf{x} \,\mathbf{d}\mathbf{x}, $$ where $\mathbf{x}=(x_1,\dots,x_n)^T$, $\mathbf{\mu} = (\mu_1,\dots,\mu_n)^T\in\Re^n$, and $\Sigma\in\mathbb{S}_{++}^{n}$. Our main goal is to evaluate the above integral. To this end, let $\mathbf{x}-\mathbf{\mu}=S\mathbf{y}$, where $S$ is an $n \times n$ orthogonal matrix ($S^T=S^{-1}$) with determinant equal to $1$. Using this change of variable, the quadratic form shown in the integral written as: $$ -\frac{1}{2}(\mathbf{x}-\mathbf{\mu})^T\Sigma^{-1}(\mathbf{x}-\mathbf{\mu})= -\frac{1}{2}\mathbf{y}^T(S^T\Sigma^{-1}S)\mathbf{y}= -\frac{1}{2}\mathbf{y}^T(S^{-1}\Sigma^{-1}S)\mathbf{y}= -\frac{1}{2}\mathbf{y}^TD\mathbf{y}, $$ where $D=\operatorname{diag}\{d_1,\dots,d_n\}$. As a result it is rewritten as follows: $$ -\frac{1}{2}(\mathbf{x}-\mathbf{\mu})^T\Sigma^{-1}(\mathbf{x}-\mathbf{\mu})= -\frac{1}{2}\sum_{k=1}^{n} d_i y_i^2 $$ Moreover, $\mathbf{x}-\mathbf{\mu}=S\mathbf{y} \Rightarrow \mathbf{x}=S\mathbf{y}+\mathbf{\mu}=[\mathbf{s_1}\:\dots\:\mathbf{s_n}]\mathbf{y}+\mathbf{\mu}=(\mathbf{s_1}\cdot\mathbf{y}+\mu_1,\dots, \mathbf{s_n}\cdot\mathbf{y}+\mu_n)^T,$ where $\mathbf{s}_j$ is the $j$-th column of matrix $S$. Using the above results, the original integral can be rewritten as follows: $$ I = (I_1,\dots,I_n)^T, $$ where the $j$-th element of $I$ is given by: $$ I_j =  \int_{\Re^n} \! \frac{1}{(2\pi)^{n/2}|\Sigma|^{1/2}} \exp \left\{ -\frac{1}{2}\sum_{k=1}^{n} d_i y_i^2 \right\} (\mathbf{s}_j\cdot\mathbf{y}+\mu_j) \,\mathbf{d}\mathbf{y}\\ =  \int_{\Re^n} \! \frac{1}{(2\pi)^{n/2}|\Sigma|^{1/2}} \exp \left\{ -\frac{1}{2}\sum_{k=1}^{n} d_i y_i^2 \right\} \mathbf{s}_j\cdot\mathbf{y} \,\mathbf{d}\mathbf{y}\\ + \int_{\Re^n} \! \frac{1}{(2\pi)^{n/2}|\Sigma|^{1/2}} \exp \left\{ -\frac{1}{2}\sum_{k=1}^{n} d_i y_i^2 \right\} \mu_j \,\mathbf{d}\mathbf{y} \Rightarrow\\ I_j = \int_{\Re^n} \! \frac{1}{(2\pi)^{n/2}|\Sigma|^{1/2}} \exp \left\{ -\frac{1}{2}\sum_{k=1}^{n} d_i y_i^2 \right\} \mathbf{s}_j\cdot\mathbf{y} \,\mathbf{d}\mathbf{y} + \mu_j $$ If we write the dot product $\mathbf{s}_j\cdot\mathbf{y}$ as $$ \mathbf{s}_j\cdot\mathbf{y} = \sum_{r=1}^{n} s_{jr}y_r, $$ then the integral $I_j$ is given by: $$ I_j = \int_{\Re^n} \! \frac{1}{(2\pi)^{n/2}|\Sigma|^{1/2}} \left(\sum_{r=1}^{n} s_{jr}y_r\right) \exp \left\{ -\frac{1}{2}\sum_{k=1}^{n} d_i y_i^2 \right\} \,\mathbf{d}\mathbf{y} + \mu_j $$ I would like to ask, first, whether the whole approach above is correct or not(if so, please correct me), and, second, how could I evaluate the last integral, $I_j$. Does it converge, like the gaussian integral over $\Re^n$? Thanks in advance! Every useful comment will be extremely appretiated!",,['integration']
48,Proving a few things about $ L^{p} $-spaces,Proving a few things about -spaces, L^{p} ,"I am new to $ L^{p} $-spaces and am trying to prove a few things about them. Therefore, I would like to ask you whether I have gotten the following right. Prove that $ {L^{\infty}}(I) \subseteq {L^{p}}(I) $ for all $ p \in (0,\infty) $, where $ I = [a,b] $ is a closed bounded interval, by showing that $$ \text{$ \forall $ measurable functions $ f $ defined on $ [a,b] $}: \quad \| f \|_{L^{p}} \le (b - a)^{\frac{1}{p}} \| f \|_{L^{\infty}}. $$ My idea was to invoke the fact that $$                          \| f \|_{L^{p}} \stackrel{\text{def}}{=} \left( \int_{I} |f|^{p} \, d{\mu} \right)^{\frac{1}{p}} \le                      \| f \|_{\infty} \left( \int_{I} 1 \, d{\mu} \right)^{\frac{1}{p}} $$ for all measurable functions $ f $ defined on $ [a,b] $. Is this correct? Prove that $ \displaystyle {L^{\infty}}(I) \subsetneq \bigcap_{p \in (0,\infty)} {L^{p}}(I) $. Inclusion is clear from (1), and a function that illustrates why the inclusion is strict is $ f(x) \stackrel{\text{def}}{=} \dfrac{1}{x^{x}} $ on the interval $ [0,1] $ (its $ L^{p} $-norm exists for each $ p \le \infty $, but it is not bounded). Prove that $ {L^{p}}(\mathbb{R}) $ is not a subset of $ {L^{\infty}}(\mathbb{R}) $ and vice-versa. Take the function $ f(x) \stackrel{\text{def}}{\equiv} 3 $. It is not integrable over $ \mathbb{R} $, but it is bounded. For the reverse implication, take the function \begin{equation} f(x) \stackrel{\text{def}}{=} \left\{ \begin{array}{ll} \frac{1}{\sqrt{x}} & \text{if $ 0 \le x \le 1 $}; \\ 0                  & \text{if $ x \in (- \infty,0) \cup (1,\infty) $}. \end{array} \right. \end{equation} It is integrable over $ \mathbb{R} $, but it is not bounded. Maybe I have made some mistakes here or maybe I am missing something, so I appreciate any kind of help!!! P.S.: I have just noticed that my example $ \dfrac{1}{x^{x}} $ does not work, since this function is actually bounded on $ [0,1] $.","I am new to $ L^{p} $-spaces and am trying to prove a few things about them. Therefore, I would like to ask you whether I have gotten the following right. Prove that $ {L^{\infty}}(I) \subseteq {L^{p}}(I) $ for all $ p \in (0,\infty) $, where $ I = [a,b] $ is a closed bounded interval, by showing that $$ \text{$ \forall $ measurable functions $ f $ defined on $ [a,b] $}: \quad \| f \|_{L^{p}} \le (b - a)^{\frac{1}{p}} \| f \|_{L^{\infty}}. $$ My idea was to invoke the fact that $$                          \| f \|_{L^{p}} \stackrel{\text{def}}{=} \left( \int_{I} |f|^{p} \, d{\mu} \right)^{\frac{1}{p}} \le                      \| f \|_{\infty} \left( \int_{I} 1 \, d{\mu} \right)^{\frac{1}{p}} $$ for all measurable functions $ f $ defined on $ [a,b] $. Is this correct? Prove that $ \displaystyle {L^{\infty}}(I) \subsetneq \bigcap_{p \in (0,\infty)} {L^{p}}(I) $. Inclusion is clear from (1), and a function that illustrates why the inclusion is strict is $ f(x) \stackrel{\text{def}}{=} \dfrac{1}{x^{x}} $ on the interval $ [0,1] $ (its $ L^{p} $-norm exists for each $ p \le \infty $, but it is not bounded). Prove that $ {L^{p}}(\mathbb{R}) $ is not a subset of $ {L^{\infty}}(\mathbb{R}) $ and vice-versa. Take the function $ f(x) \stackrel{\text{def}}{\equiv} 3 $. It is not integrable over $ \mathbb{R} $, but it is bounded. For the reverse implication, take the function \begin{equation} f(x) \stackrel{\text{def}}{=} \left\{ \begin{array}{ll} \frac{1}{\sqrt{x}} & \text{if $ 0 \le x \le 1 $}; \\ 0                  & \text{if $ x \in (- \infty,0) \cup (1,\infty) $}. \end{array} \right. \end{equation} It is integrable over $ \mathbb{R} $, but it is not bounded. Maybe I have made some mistakes here or maybe I am missing something, so I appreciate any kind of help!!! P.S.: I have just noticed that my example $ \dfrac{1}{x^{x}} $ does not work, since this function is actually bounded on $ [0,1] $.",,"['integration', 'functional-analysis']"
49,Integration over regular simplex with Gaussian Function,Integration over regular simplex with Gaussian Function,,"Let $T_n$ be the regular n-dimensional simplex centered at the origin.  Please see the diefinition in http://en.wikipedia.org/wiki/Simplex#Cartesian_coordinates_for_regular_n-dimensional_simplex_in_Rn I want to integrate over $T_n$ with Gaussian function, i.e.,  \begin{align}  \int_{T_n} \exp \left( -\frac{x_1^2 + x_2^2 + \cdots + x_n^2}{2} \right) dx_1 dx_2 \cdots dx_n. \end{align} For example, if $n=2$, the regular simplex becomes a equilateral triangle centered at origin. I tried the above equation for $n=2$. But I failed to obtain the explicit value. What I tried is to divide two region into the distance from the origin is less(more) than $\sqrt{3}/6$. The first region does not hit the boundaries of the triangle, so the integral can be written as, \begin{align} 2 \pi  \int_0^{\frac{\sqrt{3}}{6}} r \exp \left(-\frac{r^2}{2}\right) \, dr = 2 \left(1-\frac{1}{\sqrt[24]{e}}\right) \pi \end{align} The second region, instead of considering all angle $2\pi$, only $6 \sin^{-1}(1/2\sqrt{3}r) - \pi$ radians should be covered. Therefore, \begin{align} \int_{\frac{1}{2 \sqrt{3}}}^{\frac{1}{\sqrt{3}}} e^{-\frac{r^2}{2}} r \left( 6\sin ^{-1}\left(\frac{1}{2 \sqrt{3} r}\right) - \pi \right)\, dr \end{align} should be evaluated. But I failed to perform the above integration. Furthermore, I want to generalize it to the arbitrary dimension $n$. This integration will be important in my research. Let me know anything related to the problem.  Thanks.","Let $T_n$ be the regular n-dimensional simplex centered at the origin.  Please see the diefinition in http://en.wikipedia.org/wiki/Simplex#Cartesian_coordinates_for_regular_n-dimensional_simplex_in_Rn I want to integrate over $T_n$ with Gaussian function, i.e.,  \begin{align}  \int_{T_n} \exp \left( -\frac{x_1^2 + x_2^2 + \cdots + x_n^2}{2} \right) dx_1 dx_2 \cdots dx_n. \end{align} For example, if $n=2$, the regular simplex becomes a equilateral triangle centered at origin. I tried the above equation for $n=2$. But I failed to obtain the explicit value. What I tried is to divide two region into the distance from the origin is less(more) than $\sqrt{3}/6$. The first region does not hit the boundaries of the triangle, so the integral can be written as, \begin{align} 2 \pi  \int_0^{\frac{\sqrt{3}}{6}} r \exp \left(-\frac{r^2}{2}\right) \, dr = 2 \left(1-\frac{1}{\sqrt[24]{e}}\right) \pi \end{align} The second region, instead of considering all angle $2\pi$, only $6 \sin^{-1}(1/2\sqrt{3}r) - \pi$ radians should be covered. Therefore, \begin{align} \int_{\frac{1}{2 \sqrt{3}}}^{\frac{1}{\sqrt{3}}} e^{-\frac{r^2}{2}} r \left( 6\sin ^{-1}\left(\frac{1}{2 \sqrt{3} r}\right) - \pi \right)\, dr \end{align} should be evaluated. But I failed to perform the above integration. Furthermore, I want to generalize it to the arbitrary dimension $n$. This integration will be important in my research. Let me know anything related to the problem.  Thanks.",,"['integration', 'simplex']"
50,Integral in Polar Co-ordinates: Can you help evaluate it?,Integral in Polar Co-ordinates: Can you help evaluate it?,,I have $$\int_{0}^{r_{0}}\int_{a}^{b}r_{1}e^{-\beta(r_{1}^{2}+r_{2}^{2}-2r_{1}r_{2}\cos(\theta))}d\theta dr_{1}$$ Can anyone help me break it down for general $a$ and $b$? Alex,I have $$\int_{0}^{r_{0}}\int_{a}^{b}r_{1}e^{-\beta(r_{1}^{2}+r_{2}^{2}-2r_{1}r_{2}\cos(\theta))}d\theta dr_{1}$$ Can anyone help me break it down for general $a$ and $b$? Alex,,"['integration', 'multivariable-calculus']"
51,The notion of a curve in the context of line integrals,The notion of a curve in the context of line integrals,,"For brevity I'm making the following assumption: I'm only talking about regular curves on $\left[a,b\right]$ with values in $\mathbb{R}^{n}$, and line integrals of scalar fields. [Since there are a lot of questions at the end and you have to dig through the text below to make sense of them, I'm willing to offer 150 bounty points for a complete and thorough answer by a knowledgeable person in either differential geometry or vector analysis (or related fields) of all the questions . There are three common ways to define curves: Here they are defined as mappings $\gamma:\left[a,b\right]\rightarrow\mathbb{R}^{n}$. Here a curve is used as a subset $C$ of $\mathbb{R}^{n}$ that's the image of a (regular) $\gamma:\left[a,b\right]\rightarrow\mathbb{R}^{n}$- which clearly doesn't work with the concept from 1. (although Wikipedia has linked to that - has no one spotted this so far ?) Here curves are equivalence classes of mappings $\left[a,b\right]\rightarrow\mathbb{R}^{n}$ (which are equivalent if they are obtained from reparametrisations of eachother). Now these definitions relate in different ways to the concept of a line integral over scalar field $f$ along $\gamma$. If I take 1. as my definition, I can define  $$ \int_{\gamma}fd s:=\int_{a}^{b}f\left(\gamma\left(t\right)\right)\left\Vert \dot{\gamma\left(t\right)}\right\Vert d t $$ without mathematical problems, but I have the ""psychological"" problem that I would like my line integral to not be dependent on all the information $\gamma$ contains (since, for example, different reparametrisations of $\gamma$ give me the same $\int_{\gamma}f$) - of course I can show that this holds in a separate theorem, but this just seems ugly). If I take 2. as my definition, I can define  $$ \int_{C}fds:=\int_{a}^{b}f\left(\gamma\left(t\right)\right)\left\Vert \dot{\gamma\left(t\right)}\right\Vert d t $$ where $\gamma$ is any parametrisation $\gamma:\left[a,b\right]\rightarrow\mathbb{R}^{n}$ that has image $C$. This has mathematical problems: There are (regular) curves that have the same image , but aren't equivalent, so have different lengths. For example  $$ t\mapsto\left(\begin{array}{c} \cos t\\ \sin t \end{array}\right)\ \text{and}\ t\mapsto\left(\begin{array}{c} \cos2t\\ \sin2t \end{array}\right) $$ where $t\in\left[0,2\pi\right]$. So $\int_{C}f s$ isn't well defined since it depends on the choice of the parametrisation of $C$. But from a ""psychological"" perspective I like this the most, since it only has a geometric content (since $C\subseteq\mathbb{R}^{n})$ and not a dynamic one (I don't know anything about the ""speed"" with which $C$ is traced) and my personal view is, that line integral (or arc lengths, since I could have discussed this issue in the same matter with arc lengths instead of line integrals) should be purely geometrical. If I take 3. as my definition, I can define  $$ \int_{\hat{\gamma}}fd s:=\int_{a}^{b}f\left(\gamma\left(t\right)\right)\left\Vert \dot{\gamma\left(t\right)}\right\Vert d t $$ where $\hat{\gamma}$ is the equivalance class of $\gamma:\left[a,b\right]\rightarrow\mathbb{R}^{n}$. This seems to me to be a compromise between 1. and 2.: The line integral is (from the start) independent of reparametrisations - but it isn't purely geometric, as the definitions from 2. But other weird issues arise in this case: Since a curve is a set of mappings (which makes up the equivalence class) I loose a comfortable way of speaking about curves by the following subtle point: I can't say anymore that a smooth curve is also a continuous curve, since for example the equivalence class of the identity on $[0,1]$ (taken as a curve in $\mathbb{R}$), viewed as a smooth curve (i.e. as the set $\{f\mid f:[0,1] \rightarrow \mathbb{R} \text{ is smooth and can be reparametrised to be the identity}\}$) does not contain $$t\mapsto\begin{cases} 2t, & 0\leq t\leq\frac{1}{2}\\ 1, & \frac{1}{2}<t\leq1 \end{cases}$$which is is in the equivalence class of the identity, viewed as a continuous curve (i.e. as the set $\{f\mid f:[0,1] \rightarrow \mathbb{R} \text{ is continuous and can be reparametrised to be the identity}\}$) . Questions: A. Is there a standart definition of what a curve (and thus a line integral) is ? If there isn't a definition that's valid for the whole of mathematics, is the definition at least separately standarised in subfields (like differential geometric, vector analysis etc.) ? B. Is my view that line integrals and arc lengths should only depend on a purely geometric object of a curve ""correct"" ? (You may understand what you wish by ""correct"".) C. Could I perhaps save the definition of $\int_{C}f ds$ from 2., by modifying its definition so that it says  $$ \int_{C}fds:=\int_{a}^{b}f\left(\gamma\left(t\right)\right)\left\Vert \dot{\gamma\left(t\right)}\right\Vert d t $$only for those $\gamma$ that are injective on $\left(a,b\right)$ ? (In this case I would need a proposition, that for every $\gamma:\left[a,b\right]\rightarrow\mathbb{R}^{n}$ there exists an injective $\gamma':\left[a,b\right]\rightarrow\mathbb{R}^{n}$, such that $\gamma$ and $\gamma'$ have the same image. Does such a proposition exist ?) Would I exclude important physical phenomena by this alternative definition of 2.? D. I've know that there also a fourth definition if a curve, namely as a topological space locally homeomorphic to a line. How does this definition reduce to each of the three definitions above (as Wikipedia says at the beginning of the article http://en.wikipedia.org/wiki/Curve about curves) and how do I define a line integral (or arc length) by this definition ? Note: I've already read this in case you wanted to direct me there.","For brevity I'm making the following assumption: I'm only talking about regular curves on $\left[a,b\right]$ with values in $\mathbb{R}^{n}$, and line integrals of scalar fields. [Since there are a lot of questions at the end and you have to dig through the text below to make sense of them, I'm willing to offer 150 bounty points for a complete and thorough answer by a knowledgeable person in either differential geometry or vector analysis (or related fields) of all the questions . There are three common ways to define curves: Here they are defined as mappings $\gamma:\left[a,b\right]\rightarrow\mathbb{R}^{n}$. Here a curve is used as a subset $C$ of $\mathbb{R}^{n}$ that's the image of a (regular) $\gamma:\left[a,b\right]\rightarrow\mathbb{R}^{n}$- which clearly doesn't work with the concept from 1. (although Wikipedia has linked to that - has no one spotted this so far ?) Here curves are equivalence classes of mappings $\left[a,b\right]\rightarrow\mathbb{R}^{n}$ (which are equivalent if they are obtained from reparametrisations of eachother). Now these definitions relate in different ways to the concept of a line integral over scalar field $f$ along $\gamma$. If I take 1. as my definition, I can define  $$ \int_{\gamma}fd s:=\int_{a}^{b}f\left(\gamma\left(t\right)\right)\left\Vert \dot{\gamma\left(t\right)}\right\Vert d t $$ without mathematical problems, but I have the ""psychological"" problem that I would like my line integral to not be dependent on all the information $\gamma$ contains (since, for example, different reparametrisations of $\gamma$ give me the same $\int_{\gamma}f$) - of course I can show that this holds in a separate theorem, but this just seems ugly). If I take 2. as my definition, I can define  $$ \int_{C}fds:=\int_{a}^{b}f\left(\gamma\left(t\right)\right)\left\Vert \dot{\gamma\left(t\right)}\right\Vert d t $$ where $\gamma$ is any parametrisation $\gamma:\left[a,b\right]\rightarrow\mathbb{R}^{n}$ that has image $C$. This has mathematical problems: There are (regular) curves that have the same image , but aren't equivalent, so have different lengths. For example  $$ t\mapsto\left(\begin{array}{c} \cos t\\ \sin t \end{array}\right)\ \text{and}\ t\mapsto\left(\begin{array}{c} \cos2t\\ \sin2t \end{array}\right) $$ where $t\in\left[0,2\pi\right]$. So $\int_{C}f s$ isn't well defined since it depends on the choice of the parametrisation of $C$. But from a ""psychological"" perspective I like this the most, since it only has a geometric content (since $C\subseteq\mathbb{R}^{n})$ and not a dynamic one (I don't know anything about the ""speed"" with which $C$ is traced) and my personal view is, that line integral (or arc lengths, since I could have discussed this issue in the same matter with arc lengths instead of line integrals) should be purely geometrical. If I take 3. as my definition, I can define  $$ \int_{\hat{\gamma}}fd s:=\int_{a}^{b}f\left(\gamma\left(t\right)\right)\left\Vert \dot{\gamma\left(t\right)}\right\Vert d t $$ where $\hat{\gamma}$ is the equivalance class of $\gamma:\left[a,b\right]\rightarrow\mathbb{R}^{n}$. This seems to me to be a compromise between 1. and 2.: The line integral is (from the start) independent of reparametrisations - but it isn't purely geometric, as the definitions from 2. But other weird issues arise in this case: Since a curve is a set of mappings (which makes up the equivalence class) I loose a comfortable way of speaking about curves by the following subtle point: I can't say anymore that a smooth curve is also a continuous curve, since for example the equivalence class of the identity on $[0,1]$ (taken as a curve in $\mathbb{R}$), viewed as a smooth curve (i.e. as the set $\{f\mid f:[0,1] \rightarrow \mathbb{R} \text{ is smooth and can be reparametrised to be the identity}\}$) does not contain $$t\mapsto\begin{cases} 2t, & 0\leq t\leq\frac{1}{2}\\ 1, & \frac{1}{2}<t\leq1 \end{cases}$$which is is in the equivalence class of the identity, viewed as a continuous curve (i.e. as the set $\{f\mid f:[0,1] \rightarrow \mathbb{R} \text{ is continuous and can be reparametrised to be the identity}\}$) . Questions: A. Is there a standart definition of what a curve (and thus a line integral) is ? If there isn't a definition that's valid for the whole of mathematics, is the definition at least separately standarised in subfields (like differential geometric, vector analysis etc.) ? B. Is my view that line integrals and arc lengths should only depend on a purely geometric object of a curve ""correct"" ? (You may understand what you wish by ""correct"".) C. Could I perhaps save the definition of $\int_{C}f ds$ from 2., by modifying its definition so that it says  $$ \int_{C}fds:=\int_{a}^{b}f\left(\gamma\left(t\right)\right)\left\Vert \dot{\gamma\left(t\right)}\right\Vert d t $$only for those $\gamma$ that are injective on $\left(a,b\right)$ ? (In this case I would need a proposition, that for every $\gamma:\left[a,b\right]\rightarrow\mathbb{R}^{n}$ there exists an injective $\gamma':\left[a,b\right]\rightarrow\mathbb{R}^{n}$, such that $\gamma$ and $\gamma'$ have the same image. Does such a proposition exist ?) Would I exclude important physical phenomena by this alternative definition of 2.? D. I've know that there also a fourth definition if a curve, namely as a topological space locally homeomorphic to a line. How does this definition reduce to each of the three definitions above (as Wikipedia says at the beginning of the article http://en.wikipedia.org/wiki/Curve about curves) and how do I define a line integral (or arc length) by this definition ? Note: I've already read this in case you wanted to direct me there.",,"['analysis', 'differential-geometry', 'multivariable-calculus', 'integration', 'vector-analysis']"
52,Describing/sketching region of integration of triple integral,Describing/sketching region of integration of triple integral,,"I'm having great difficulty with the following problem: This question concerns the integral $\int_{0}^{2}\int_{0}^{\sqrt{4-y^2}}\int_{\sqrt{x^2+y^2}}^{\sqrt{8-x^2-y^2}}\!z\ \mathrm{d}z\ \mathrm{d}x\ \mathrm{d}y$. Sketch or describe in words the domain of integration. Rewrite the integral in both cylindrical and spherical coordinates. Which is easier to evaluate? Below is what I believe I have established so far... The projection of this integral's domain onto the $xy$-plane is the portion of the circle $x^2+y^2=4$ on $0\le x\le2,\ y\ge0$. The bounds on $z$ correspond to $z^2=x^2+y^2$ (cone) and $x^2+y^2+z^2=8$ (sphere). These bounds intersect at $x^2+y^2=4$. Below $z=2$ (where the bounds on $z$ intersect), I believe that the cone and cylinder, $x^2+y^2=4$, are completely inside the sphere. Would it hence be correct to say that the region of integration is the solid lying between the cone and the cylinder, on $x\ge0$, $y\ge0$ and $0\le z\le2$? I'm struggling to visualize this problem. When I attempt to move on, and evaluate the integral in cylindrical/spherical coordinates, my solutions differ by a factor of 2. That is, I evaluated this integral as, $\int_{0}^{\frac{\pi}{2}}\int_{0}^{2}\int_{0}^{\sqrt{8-r^2}}\!z\ r\ \mathrm{d}z\ \mathrm{d}r\ \mathrm{d}\theta=2\pi$ And, $\int_{0}^{\frac{\pi}{2}}\int_{0}^{\frac{\pi}{2}}\int_{0}^{2\sqrt{2}}\!\rho\ \cos\phi\ \rho^2 \sin \phi\ \mathrm{d}\rho\ \mathrm{d}\theta\ \mathrm{d}\phi=4\pi$ Can you please help me to identify where I am going wrong? Thank you very much.","I'm having great difficulty with the following problem: This question concerns the integral $\int_{0}^{2}\int_{0}^{\sqrt{4-y^2}}\int_{\sqrt{x^2+y^2}}^{\sqrt{8-x^2-y^2}}\!z\ \mathrm{d}z\ \mathrm{d}x\ \mathrm{d}y$. Sketch or describe in words the domain of integration. Rewrite the integral in both cylindrical and spherical coordinates. Which is easier to evaluate? Below is what I believe I have established so far... The projection of this integral's domain onto the $xy$-plane is the portion of the circle $x^2+y^2=4$ on $0\le x\le2,\ y\ge0$. The bounds on $z$ correspond to $z^2=x^2+y^2$ (cone) and $x^2+y^2+z^2=8$ (sphere). These bounds intersect at $x^2+y^2=4$. Below $z=2$ (where the bounds on $z$ intersect), I believe that the cone and cylinder, $x^2+y^2=4$, are completely inside the sphere. Would it hence be correct to say that the region of integration is the solid lying between the cone and the cylinder, on $x\ge0$, $y\ge0$ and $0\le z\le2$? I'm struggling to visualize this problem. When I attempt to move on, and evaluate the integral in cylindrical/spherical coordinates, my solutions differ by a factor of 2. That is, I evaluated this integral as, $\int_{0}^{\frac{\pi}{2}}\int_{0}^{2}\int_{0}^{\sqrt{8-r^2}}\!z\ r\ \mathrm{d}z\ \mathrm{d}r\ \mathrm{d}\theta=2\pi$ And, $\int_{0}^{\frac{\pi}{2}}\int_{0}^{\frac{\pi}{2}}\int_{0}^{2\sqrt{2}}\!\rho\ \cos\phi\ \rho^2 \sin \phi\ \mathrm{d}\rho\ \mathrm{d}\theta\ \mathrm{d}\phi=4\pi$ Can you please help me to identify where I am going wrong? Thank you very much.",,"['integration', 'multivariable-calculus']"
53,Stokes' Theorem and Measure Zero Sets,Stokes' Theorem and Measure Zero Sets,,"This is probably a very naive question but I am trying to connect two pieces of information in my head regarding integration of differential forms and integration with respect to a measure. The first piece is that Stokes' theorem implies the fundamental theorem of calculus in the following way: $\int_{[a,b]}f(x)dx=\int_{[a,b]}dF(x)=\int_{\{a\}^-\cup\{b\}^+}F(x)=F(b)-F(a)$ Where $f(x)dx$ is the 1-form and $F(x)$ is the 0-form. The second piece is that (Lebesgue) integration on a measure zero set would be equal to zero. Since $\{a\}\cup\{b\}$ is a measure zero set, how would $\int_{\{a\}^-\cup\{b\}^+}F(x)$ being non-zero would fit into the Lebesgue framework? Thanks","This is probably a very naive question but I am trying to connect two pieces of information in my head regarding integration of differential forms and integration with respect to a measure. The first piece is that Stokes' theorem implies the fundamental theorem of calculus in the following way: $\int_{[a,b]}f(x)dx=\int_{[a,b]}dF(x)=\int_{\{a\}^-\cup\{b\}^+}F(x)=F(b)-F(a)$ Where $f(x)dx$ is the 1-form and $F(x)$ is the 0-form. The second piece is that (Lebesgue) integration on a measure zero set would be equal to zero. Since $\{a\}\cup\{b\}$ is a measure zero set, how would $\int_{\{a\}^-\cup\{b\}^+}F(x)$ being non-zero would fit into the Lebesgue framework? Thanks",,['integration']
54,"Proving $|\int_{C}f(z)\, dz|\leq10M$ when $|f(z)|\leq M$ on $D=\{|z|=50\}$",Proving  when  on,"|\int_{C}f(z)\, dz|\leq10M |f(z)|\leq M D=\{|z|=50\}","I am trying to solve a question from my complex analysis test that I didn't manage to do during the test in order to practice for the next exam. The problem is as follows: Let $f:\,\mathbb{C}\to\mathbb{C}$ be analytic function. Assume that   $|f(z)|\leq M$ for every $z$ s.t $|z|=50$. Consider the upper half of the ellipse $C=\{2x^{2}+y^{2}=50|\,  y\geq0\}$. Prove $|\int_{C}f(z)\, dz|\leq10M$ What I tried: Since $f$ is analytic, if $|C|\leq L$ then if $|f(z)|\leq M$ on $C$ we get that $|\int_{C}f(z)\, dz|\leq ML$. We also know that $$\max_{z\leq50}|f(z)|=\max_{z=50}|f(z)|\leq M$$ If $$2x^{2}+y^{2}=50$$ then $$x^{2}+y^{2}=50-x^{2}\leq50$$ hence for every $z$ on $C$ we have $|f(z)|\leq M$. From here I believe it only remains to show $|C|\leq10$ which I am unable to do. Can someone please help me out ? I guess that I am on the right track, but I couldn't bound $|C|$ from above by $10$","I am trying to solve a question from my complex analysis test that I didn't manage to do during the test in order to practice for the next exam. The problem is as follows: Let $f:\,\mathbb{C}\to\mathbb{C}$ be analytic function. Assume that   $|f(z)|\leq M$ for every $z$ s.t $|z|=50$. Consider the upper half of the ellipse $C=\{2x^{2}+y^{2}=50|\,  y\geq0\}$. Prove $|\int_{C}f(z)\, dz|\leq10M$ What I tried: Since $f$ is analytic, if $|C|\leq L$ then if $|f(z)|\leq M$ on $C$ we get that $|\int_{C}f(z)\, dz|\leq ML$. We also know that $$\max_{z\leq50}|f(z)|=\max_{z=50}|f(z)|\leq M$$ If $$2x^{2}+y^{2}=50$$ then $$x^{2}+y^{2}=50-x^{2}\leq50$$ hence for every $z$ on $C$ we have $|f(z)|\leq M$. From here I believe it only remains to show $|C|\leq10$ which I am unable to do. Can someone please help me out ? I guess that I am on the right track, but I couldn't bound $|C|$ from above by $10$",,"['complex-analysis', 'integration']"
55,Evaluate the integral by converting to polar coordinate,Evaluate the integral by converting to polar coordinate,,$$ \int^{\pi/2}_{\pi/4} \int^{\sqrt{2-y^2}}_y 3(x-y) dx dy$$ I attempted the following: $$ \int_{\pi/4}^{\pi/2} \int_{0}^{1} 3r^2 (\cos\theta - \sin\theta) dr d\theta $$ which is wrong apparently. I think I might have got the wrong drawing of the curve.,$$ \int^{\pi/2}_{\pi/4} \int^{\sqrt{2-y^2}}_y 3(x-y) dx dy$$ I attempted the following: $$ \int_{\pi/4}^{\pi/2} \int_{0}^{1} 3r^2 (\cos\theta - \sin\theta) dr d\theta $$ which is wrong apparently. I think I might have got the wrong drawing of the curve.,,"['integration', 'polar-coordinates']"
56,Cauchy transform,Cauchy transform,,"I'm trying to solve the problem:  If $\phi \colon S_1(0)\to \Bbb C$ is a continuous function on the unit circle, its Cauchy transform $$C\phi(z) =\frac 1{2\pi i}\int_{S_1(0)}\frac{\phi(w)}{w-z}dw$$ is analytic on $\Bbb C \setminus S_1(0)$. If $\phi$ is holomorphic on closure of $B_1(0)$ then it follows from Cauchy's formula that $$C\phi(z) = \begin{cases}\phi(z)& \mbox{if }z \in B_1(0);\\0&\mbox{if }z \in C\setminus B_1(0).\end{cases}$$ What happens if $\phi(z) =\bar z$? Hint: On the unit circle $\bar z = 1/z$. I tried to substitute in the integral by $\phi(w)=1/w$ and solve the integral by writing it as $(-1/zw + 1/z(w-z))$. I got the integral is $\log$, but I'm not sure at all of my solution. Can anyone please help me?  Also, I'm trying to read more in Cauchy transform but I couldn't find any resource with the same definition. The books that I found have other definition, can anyone please give me more information about this transformation to read with the same definition that I have here? Thank you in advance.","I'm trying to solve the problem:  If $\phi \colon S_1(0)\to \Bbb C$ is a continuous function on the unit circle, its Cauchy transform $$C\phi(z) =\frac 1{2\pi i}\int_{S_1(0)}\frac{\phi(w)}{w-z}dw$$ is analytic on $\Bbb C \setminus S_1(0)$. If $\phi$ is holomorphic on closure of $B_1(0)$ then it follows from Cauchy's formula that $$C\phi(z) = \begin{cases}\phi(z)& \mbox{if }z \in B_1(0);\\0&\mbox{if }z \in C\setminus B_1(0).\end{cases}$$ What happens if $\phi(z) =\bar z$? Hint: On the unit circle $\bar z = 1/z$. I tried to substitute in the integral by $\phi(w)=1/w$ and solve the integral by writing it as $(-1/zw + 1/z(w-z))$. I got the integral is $\log$, but I'm not sure at all of my solution. Can anyone please help me?  Also, I'm trying to read more in Cauchy transform but I couldn't find any resource with the same definition. The books that I found have other definition, can anyone please give me more information about this transformation to read with the same definition that I have here? Thank you in advance.",,"['complex-analysis', 'integration']"
57,Average sine of an angle between two rays in a cone,Average sine of an angle between two rays in a cone,,"I'm looking for an average value of sine of an angle between two rays, lying within a cone with a certain angle. Given a cone with an aperture of ${2\chi}$ and two rays lying within the cone. The rays can be represented as vectors in a spherical coordinate system: $$ {\vec{e_1}=\lbrace1,\phi_1,\theta_1 \rbrace},{\vec{e_2}=\lbrace1,\phi_2,\theta_2 \rbrace} $$ where ${\phi_1,\phi_2\in[0,2\pi], \theta_1,\theta_2\in[0,\chi]}$ (assuming the axis of the cone is aligned with the z axis). The distribution of every angle is uniform. It is needed to find the average value of the sine of the angle between the rays (vectors). We can get an answer by simply integrating the sine within a needed area: $$ {{\frac{1}{4\pi^2\chi^2}}\int\limits_{0}^{\chi}\int\limits_{0}^{\chi}\int\limits_{0}^{2\pi}\int\limits_{0}^{2\pi}\sin(\vec{e_1},\vec{e_2})d\phi_1\phi_2\theta_1d\theta_2} $$ We can get cosine of an angle between the vectors using the dot product: $${\cos(\vec{e_1},\vec{e_2})=\frac{(\vec{e_1},\vec{e_2})}{|\vec{e_1}||\vec{e_2}|}}=\sin\theta_{1}\sin\theta_{2}\cos\left(\phi_{1}-\phi_{2}\right)+\cos\theta_{1}\cos\theta_{2}$$ Using this an average value of cosine can be easily got: $$ {{\frac{1}{4\pi^2\chi^2}}\int\limits_{0}^{\chi}\int\limits_{0}^{\chi}\int\limits_{0}^{2\pi}\int\limits_{0}^{2\pi}\cos(\vec{e_1},\vec{e_2})d\phi_1\phi_2\theta_1d\theta_2=\frac{\sin^2\chi}{\chi^2}} $$ But I didn't have much luck trying to get the average value of sine. I can't solve this: $$ {{\frac{1}{4\pi^2\chi^2}}\int\limits_{0}^{\chi}\int\limits_{0}^{\chi}\int\limits_{0}^{2\pi}\int\limits_{0}^{2\pi}\sqrt{1-\left(\sin\theta_{1}\sin\theta_{2}\cos\left(\phi_{1}-\phi_{2}\right)+\cos\theta_{1}\cos\theta_{2}\right)^{2}}d\phi_1\phi_2\theta_1d\theta_2} $$ Using the Monte-Carlo simulation I got this curve: Any help would be appreciated!","I'm looking for an average value of sine of an angle between two rays, lying within a cone with a certain angle. Given a cone with an aperture of ${2\chi}$ and two rays lying within the cone. The rays can be represented as vectors in a spherical coordinate system: $$ {\vec{e_1}=\lbrace1,\phi_1,\theta_1 \rbrace},{\vec{e_2}=\lbrace1,\phi_2,\theta_2 \rbrace} $$ where ${\phi_1,\phi_2\in[0,2\pi], \theta_1,\theta_2\in[0,\chi]}$ (assuming the axis of the cone is aligned with the z axis). The distribution of every angle is uniform. It is needed to find the average value of the sine of the angle between the rays (vectors). We can get an answer by simply integrating the sine within a needed area: $$ {{\frac{1}{4\pi^2\chi^2}}\int\limits_{0}^{\chi}\int\limits_{0}^{\chi}\int\limits_{0}^{2\pi}\int\limits_{0}^{2\pi}\sin(\vec{e_1},\vec{e_2})d\phi_1\phi_2\theta_1d\theta_2} $$ We can get cosine of an angle between the vectors using the dot product: $${\cos(\vec{e_1},\vec{e_2})=\frac{(\vec{e_1},\vec{e_2})}{|\vec{e_1}||\vec{e_2}|}}=\sin\theta_{1}\sin\theta_{2}\cos\left(\phi_{1}-\phi_{2}\right)+\cos\theta_{1}\cos\theta_{2}$$ Using this an average value of cosine can be easily got: $$ {{\frac{1}{4\pi^2\chi^2}}\int\limits_{0}^{\chi}\int\limits_{0}^{\chi}\int\limits_{0}^{2\pi}\int\limits_{0}^{2\pi}\cos(\vec{e_1},\vec{e_2})d\phi_1\phi_2\theta_1d\theta_2=\frac{\sin^2\chi}{\chi^2}} $$ But I didn't have much luck trying to get the average value of sine. I can't solve this: $$ {{\frac{1}{4\pi^2\chi^2}}\int\limits_{0}^{\chi}\int\limits_{0}^{\chi}\int\limits_{0}^{2\pi}\int\limits_{0}^{2\pi}\sqrt{1-\left(\sin\theta_{1}\sin\theta_{2}\cos\left(\phi_{1}-\phi_{2}\right)+\cos\theta_{1}\cos\theta_{2}\right)^{2}}d\phi_1\phi_2\theta_1d\theta_2} $$ Using the Monte-Carlo simulation I got this curve: Any help would be appreciated!",,"['geometry', 'integration', 'trigonometry', 'average', 'uniform-distribution']"
58,How to find this integral?,How to find this integral?,,"I am trying to find the integral $$\oint_c Re(z)\;dz$$ where c is a circle $$|z|=2$$ I don't know what to do. I tried some things but I don't know if I am correct. $e^{i\theta} = \cos \theta +i \sin \theta$, so $Re(z) = \cos \theta$? And then $$\int_0^{2\pi} 2\cos \theta i e^{i\theta}\;d\theta$$ Can someone explain a little what's going on cause I am trying to understand it 2 hours now and I am getting nervous.","I am trying to find the integral $$\oint_c Re(z)\;dz$$ where c is a circle $$|z|=2$$ I don't know what to do. I tried some things but I don't know if I am correct. $e^{i\theta} = \cos \theta +i \sin \theta$, so $Re(z) = \cos \theta$? And then $$\int_0^{2\pi} 2\cos \theta i e^{i\theta}\;d\theta$$ Can someone explain a little what's going on cause I am trying to understand it 2 hours now and I am getting nervous.",,['integration']
59,Showing that $\int_0^1 x^{\lambda} [ \: \phi(x) - \phi(0)\: ] dx$ is convergent for $\lambda > -2$,Showing that  is convergent for,\int_0^1 x^{\lambda} [ \: \phi(x) - \phi(0)\: ] dx \lambda > -2,"Id' appreciate help understanding why the integral $$ \int_0^1 x^{\lambda} [ \: \phi(x) - \phi(0)\: ] dx $$ is convergent provided $\lambda > -2$, where $\phi \in \mathcal{D}(\mathbb{R})$. To provide some context: this integral arises in the regularization of the (divergent) integral of $x^{\lambda}_+$ ; i.e. $$ \langle x^{\lambda}_+ , \phi \rangle = \int_0^\infty x^{\lambda} \phi \: dx $$ By analytic continuation, this integral can be expressed as $$ \int_0^1 x^{\lambda} [ \: \phi(x) - \phi(0)\: ] dx + \int_1^\infty x^{\lambda} \: \phi(x) \: dx \: + \: \frac{\phi(0)}{\lambda + 1} $$ The following texts all state that the first integral is convergent provided $\lambda > -2$, but its not obvious to me how it does. Generalized Functions, Volume 1 by Gelfand and Shilov (1964) -- page 47 & 48 Theory of Distributions by M. A. Al-Gwaiz (1992), page 64 Asymptotic approximation of integrals by R. Wong (2001) -- page 258","Id' appreciate help understanding why the integral $$ \int_0^1 x^{\lambda} [ \: \phi(x) - \phi(0)\: ] dx $$ is convergent provided $\lambda > -2$, where $\phi \in \mathcal{D}(\mathbb{R})$. To provide some context: this integral arises in the regularization of the (divergent) integral of $x^{\lambda}_+$ ; i.e. $$ \langle x^{\lambda}_+ , \phi \rangle = \int_0^\infty x^{\lambda} \phi \: dx $$ By analytic continuation, this integral can be expressed as $$ \int_0^1 x^{\lambda} [ \: \phi(x) - \phi(0)\: ] dx + \int_1^\infty x^{\lambda} \: \phi(x) \: dx \: + \: \frac{\phi(0)}{\lambda + 1} $$ The following texts all state that the first integral is convergent provided $\lambda > -2$, but its not obvious to me how it does. Generalized Functions, Volume 1 by Gelfand and Shilov (1964) -- page 47 & 48 Theory of Distributions by M. A. Al-Gwaiz (1992), page 64 Asymptotic approximation of integrals by R. Wong (2001) -- page 258",,"['integration', 'asymptotics', 'distribution-theory']"
60,Exercise 2.5.8 Pedersen's Analysis Now,Exercise 2.5.8 Pedersen's Analysis Now,,"I'm trying to do the following problem, and I'm getting hung up on one part.  Here is the problem: Let $f: X \longrightarrow \mathfrak{X}$ be a continuous map from a compact Hausdorff space $X$ into a Banach space $\mathfrak{X}$ , with $\mu$ a Radon measure on $X$ .  Consider elements of the form: $$I_{\lambda}(f) = \sum_{k=1}^n f(s_k)\mu(E_k)$$ where the $E_k$ 's are Borel sets partitioning $X$ and $s_k \in E_k \subset \{s \in X \: | \: \lvert f(s)-f(s_k) \rVert \leq \epsilon \}$ for $\epsilon > 0$ .  With $\lambda = \{E_1,\dots,E_n,\epsilon\}$ , prove that $(I_{\lambda}(f))_{\lambda \in \Lambda}$ is a convergent net.  We denote the limit by: $$\int_{X} f(s) \: d\mu(s).$$ My main issue I'm having is what the ordering needs to be on the set $\Lambda$ .  I figured at first that I would want something like $\lambda \leq \mu$ if and only if $\mu$ contains a refinement of the partition in $\lambda$ , and $\epsilon_{\mu} \leq \epsilon_{\lambda}$ .  However, this doesn't seem to work, as the smaller the $\epsilon$ I stipulate, this seems to directly affect how many $E_k$ 's I would need in my partition since $E_k \subset \{s \in X \: | \: \lVert f(s)-f(s_k) \rVert \leq \epsilon\}$ .  Hence if $\epsilon > 0$ was really small, I should expect there to be many more $E_k$ 's as $\mu(\{s \in X \: | \: \lVert f(s)-f(s_k) \rVert \leq \epsilon\}) \longrightarrow 0$ as $\epsilon \rightarrow 0^{+}$ . Thus, my point is that I shouldn't be able to just change $\epsilon$ independently of changing the $E_1,\dots,E_n$ .  But this goes against what my ordering is supposedly okay with. Is there another ordering I'm supposed to be using?","I'm trying to do the following problem, and I'm getting hung up on one part.  Here is the problem: Let be a continuous map from a compact Hausdorff space into a Banach space , with a Radon measure on .  Consider elements of the form: where the 's are Borel sets partitioning and for .  With , prove that is a convergent net.  We denote the limit by: My main issue I'm having is what the ordering needs to be on the set .  I figured at first that I would want something like if and only if contains a refinement of the partition in , and .  However, this doesn't seem to work, as the smaller the I stipulate, this seems to directly affect how many 's I would need in my partition since .  Hence if was really small, I should expect there to be many more 's as as . Thus, my point is that I shouldn't be able to just change independently of changing the .  But this goes against what my ordering is supposedly okay with. Is there another ordering I'm supposed to be using?","f: X \longrightarrow \mathfrak{X} X \mathfrak{X} \mu X I_{\lambda}(f) = \sum_{k=1}^n f(s_k)\mu(E_k) E_k X s_k \in E_k \subset \{s \in X \: | \: \lvert f(s)-f(s_k) \rVert \leq \epsilon \} \epsilon > 0 \lambda = \{E_1,\dots,E_n,\epsilon\} (I_{\lambda}(f))_{\lambda \in \Lambda} \int_{X} f(s) \: d\mu(s). \Lambda \lambda \leq \mu \mu \lambda \epsilon_{\mu} \leq \epsilon_{\lambda} \epsilon E_k E_k \subset \{s \in X \: | \: \lVert f(s)-f(s_k) \rVert \leq \epsilon\} \epsilon > 0 E_k \mu(\{s \in X \: | \: \lVert f(s)-f(s_k) \rVert \leq \epsilon\}) \longrightarrow 0 \epsilon \rightarrow 0^{+} \epsilon E_1,\dots,E_n","['integration', 'functional-analysis', 'analysis', 'banach-spaces']"
61,Integrating a formula involving quantisation (floor function),Integrating a formula involving quantisation (floor function),,"I have a gamma correction function of the following form: $$f(x) = x^\gamma \text{ for } 0 \le x \le 1, \gamma \in \mathbb{R}^+$$ For example, a simplified approximation of the sRGB electro-optical transfer function (EOTF) is $f(x) = x^{2.2}$ , i.e. $\gamma=2.2$ . I'm trying to analyse the magnitude of deviation between this ""ideal"" gamma correction function, when calculated in a continuous manner, versus a variant where the space is quantised into an $n$ -bit value. The $n$ -bit quantised version of the gamma function can be represented as: $$f_Q(x) = \frac{\lfloor 2^n x^\gamma \rfloor}{2^n} \text{ for } 0 \le x \le 1, n \in \mathbb{N}^+, \gamma \in \mathbb{R}^+ $$ By subtracting $f_Q(x)$ from $f(x)$ we get a function that describes the magnitude of quantisation error across the input range: $$f_{Q\Delta}(x) = f(x) - f_Q(x)$$ To turn this into a single value representing the total magnitude of quantisation error, I'd like to calculate the definite integral: $$\int_0^1 f_{Q\Delta}(x) \text{ dx} = \int_0^1 x^\gamma - \frac{\lfloor 2^n x^\gamma \rfloor}{2^n} \text{ dx} \text{ for } 0 \le x \le 1, n \in \mathbb{N}^+, \gamma \in \mathbb{R}^+ $$ It's been 17 years since I last did definite integrals, so I'm more than a bit out of practice. My first thought was to tackle the initial step where $\lfloor 2^n x^\gamma \rfloor = 0$ . The upper bound of this first quantised step is the point where $\lfloor 2^n x^\gamma \rfloor > 0$ , which is $\left(\frac{1}{2^n}\right)^{1/\gamma}$ or $2^{-n/\gamma}$ . This simplifies the definite integral to: $$\int_0^{2^{-n/\gamma}} x^\gamma \text{ dx}$$ I'm pretty sure this is the solution of the integral for this first step: $$\int_0^{2^{-n/\gamma}} x^\gamma \text{ dx} = \frac{\left(2^{-n/\gamma}\right)^{\gamma+1}}{\gamma+1} $$ This seems to match up with the numbers I got when calculating the integral through the Desmos graphing calculator online. My next thought was to figure out the intervals for each quantised step. The end of each step should be: $$\left(\frac{k}{2^n}\right)^{1/\gamma} = k^{1/\gamma} \space 2^{-n/\gamma}$$ So, the start of each step should simply be: $$\left(\frac{k-1}{2^n}\right)^{1/\gamma} = \left(k-1\right)^{1/\gamma} \space 2^{-n/\gamma}$$ This lines up with the previous definite integral bounds: for $k=1$ we get $\left(\frac{1}{2^n}\right)^{1/\gamma}$ and $\left(\frac{0}{2^n}\right)^{1/\gamma} = 0$ . So this would mean that my original definite integral can be expressed as the following summation of definite integrals, each describing one quantised step: $$\int_0^1 x^\gamma - \frac{\lfloor 2^n x^\gamma \rfloor}{2^n} \text{ dx} = \sum_{k=1}^{2^n} \int_{\left(k-1\right)^{1/\gamma} \space 2^{-n/\gamma}}^{k^{1/\gamma} \space 2^{-n/\gamma}} x^\gamma \text{ dx}$$ However, this is where I got stuck. How do I rework these summed definite integrals to come up with a single formula for the whole definite integral? Or is there another approach I can use?","I have a gamma correction function of the following form: For example, a simplified approximation of the sRGB electro-optical transfer function (EOTF) is , i.e. . I'm trying to analyse the magnitude of deviation between this ""ideal"" gamma correction function, when calculated in a continuous manner, versus a variant where the space is quantised into an -bit value. The -bit quantised version of the gamma function can be represented as: By subtracting from we get a function that describes the magnitude of quantisation error across the input range: To turn this into a single value representing the total magnitude of quantisation error, I'd like to calculate the definite integral: It's been 17 years since I last did definite integrals, so I'm more than a bit out of practice. My first thought was to tackle the initial step where . The upper bound of this first quantised step is the point where , which is or . This simplifies the definite integral to: I'm pretty sure this is the solution of the integral for this first step: This seems to match up with the numbers I got when calculating the integral through the Desmos graphing calculator online. My next thought was to figure out the intervals for each quantised step. The end of each step should be: So, the start of each step should simply be: This lines up with the previous definite integral bounds: for we get and . So this would mean that my original definite integral can be expressed as the following summation of definite integrals, each describing one quantised step: However, this is where I got stuck. How do I rework these summed definite integrals to come up with a single formula for the whole definite integral? Or is there another approach I can use?","f(x) = x^\gamma \text{ for } 0 \le x \le 1, \gamma \in \mathbb{R}^+ f(x) = x^{2.2} \gamma=2.2 n n f_Q(x) = \frac{\lfloor 2^n x^\gamma \rfloor}{2^n} \text{ for } 0 \le x \le 1, n \in \mathbb{N}^+, \gamma \in \mathbb{R}^+  f_Q(x) f(x) f_{Q\Delta}(x) = f(x) - f_Q(x) \int_0^1 f_{Q\Delta}(x) \text{ dx} = \int_0^1 x^\gamma - \frac{\lfloor 2^n x^\gamma \rfloor}{2^n} \text{ dx} \text{ for } 0 \le x \le 1, n \in \mathbb{N}^+, \gamma \in \mathbb{R}^+  \lfloor 2^n x^\gamma \rfloor = 0 \lfloor 2^n x^\gamma \rfloor > 0 \left(\frac{1}{2^n}\right)^{1/\gamma} 2^{-n/\gamma} \int_0^{2^{-n/\gamma}} x^\gamma \text{ dx} \int_0^{2^{-n/\gamma}} x^\gamma \text{ dx} = \frac{\left(2^{-n/\gamma}\right)^{\gamma+1}}{\gamma+1}  \left(\frac{k}{2^n}\right)^{1/\gamma} = k^{1/\gamma} \space 2^{-n/\gamma} \left(\frac{k-1}{2^n}\right)^{1/\gamma} = \left(k-1\right)^{1/\gamma} \space 2^{-n/\gamma} k=1 \left(\frac{1}{2^n}\right)^{1/\gamma} \left(\frac{0}{2^n}\right)^{1/\gamma} = 0 \int_0^1 x^\gamma - \frac{\lfloor 2^n x^\gamma \rfloor}{2^n} \text{ dx} = \sum_{k=1}^{2^n} \int_{\left(k-1\right)^{1/\gamma} \space 2^{-n/\gamma}}^{k^{1/\gamma} \space 2^{-n/\gamma}} x^\gamma \text{ dx}","['integration', 'definite-integrals', 'ceiling-and-floor-functions']"
62,Using change of coordinates to find the exact value of an integral,Using change of coordinates to find the exact value of an integral,,"Use an appropriate change of coordinates to find the exact value of the integral $$\int_{-\sqrt{3}}^{\sqrt{3}}\int_{-\sqrt{3-x^2}}^{\sqrt{3-x^2}}\int_{-3+x^2+y^2}^{3-x^2-y^2}x^2dzdydx$$ My work so far: $-3+x^2+y^2\leq z\leq 3-x^2-y^2$ $-\sqrt{3-x^2}\leq y\leq \sqrt{3-x^2}$ $-\sqrt{3}\leq x \leq \sqrt{3}$ I can see that $y$ includes the entire circle, so that means $0 \leq \theta \leq 2\pi$ Similarly, graphing the circle centered at the origin with radius $\sqrt{3}$ , I can see that $0\leq r \leq \sqrt{3}$ I just need to change $z$ to polar now: $3-x^2-y^2=3-r^2$ $-3+x^2+y^2=-3+r^2$ So the integral becomes: $$\int_{0}^{2\pi}\int_{0}^{\sqrt{3}}\int_{-3+r^2}^{3-r^2} r(r\sin\theta)^2 dz dr d\theta$$ $$=\int_{0}^{2\pi}\int_{0}^{\sqrt{3}} r^3\sin^2\theta(3-r^2-(-3+r^2))drd\theta$$ $$=\int_{0}^{2\pi}\int_{0}^{\sqrt{3}} r^3\sin^2\theta(6-2r^2)drd\theta$$ $$=\int_{0}^{2\pi}\int_{0}^{\sqrt{3}} \sin^2\theta(6r^3-2r^5) drd\theta$$ $$=\int_{0}^{2\pi} \frac{9}{2}\sin^2\theta d\theta$$ $$=\frac{9\pi}{2}$$ Is my solution correct?","Use an appropriate change of coordinates to find the exact value of the integral My work so far: I can see that includes the entire circle, so that means Similarly, graphing the circle centered at the origin with radius , I can see that I just need to change to polar now: So the integral becomes: Is my solution correct?",\int_{-\sqrt{3}}^{\sqrt{3}}\int_{-\sqrt{3-x^2}}^{\sqrt{3-x^2}}\int_{-3+x^2+y^2}^{3-x^2-y^2}x^2dzdydx -3+x^2+y^2\leq z\leq 3-x^2-y^2 -\sqrt{3-x^2}\leq y\leq \sqrt{3-x^2} -\sqrt{3}\leq x \leq \sqrt{3} y 0 \leq \theta \leq 2\pi \sqrt{3} 0\leq r \leq \sqrt{3} z 3-x^2-y^2=3-r^2 -3+x^2+y^2=-3+r^2 \int_{0}^{2\pi}\int_{0}^{\sqrt{3}}\int_{-3+r^2}^{3-r^2} r(r\sin\theta)^2 dz dr d\theta =\int_{0}^{2\pi}\int_{0}^{\sqrt{3}} r^3\sin^2\theta(3-r^2-(-3+r^2))drd\theta =\int_{0}^{2\pi}\int_{0}^{\sqrt{3}} r^3\sin^2\theta(6-2r^2)drd\theta =\int_{0}^{2\pi}\int_{0}^{\sqrt{3}} \sin^2\theta(6r^3-2r^5) drd\theta =\int_{0}^{2\pi} \frac{9}{2}\sin^2\theta d\theta =\frac{9\pi}{2},"['integration', 'multivariable-calculus', 'cylindrical-coordinates']"
63,Double integral of a logarithm multiplied by an exponential,Double integral of a logarithm multiplied by an exponential,,"I would like to know the value of the following integral: $$ f(\alpha,\beta,\gamma)=\int_{0}^{1}\int_{0}^{1}\ln{(t+i\alpha t')}~e^{i(\beta t+\gamma t')}\,\mathrm{d}t\,\mathrm{d}t' $$ where $\alpha$ , $\beta$ and $\gamma$ are real-valued constants. The integral arises when considering surface currents on electrical conductors. Mathematica will calculate the integral analytically for individual integer values of the constants, in terms of the exponential integral, so I know an expression should be possible, but I'm not sure how to do this more generally. It is possible that the method in How to double integrate the product of a logarithm and an exponential may be helpful, but I don't see how to modify it to cover the difference in the argument of the logarithm here. Thanks in advance for any help.","I would like to know the value of the following integral: where , and are real-valued constants. The integral arises when considering surface currents on electrical conductors. Mathematica will calculate the integral analytically for individual integer values of the constants, in terms of the exponential integral, so I know an expression should be possible, but I'm not sure how to do this more generally. It is possible that the method in How to double integrate the product of a logarithm and an exponential may be helpful, but I don't see how to modify it to cover the difference in the argument of the logarithm here. Thanks in advance for any help.","
f(\alpha,\beta,\gamma)=\int_{0}^{1}\int_{0}^{1}\ln{(t+i\alpha t')}~e^{i(\beta t+\gamma t')}\,\mathrm{d}t\,\mathrm{d}t'
 \alpha \beta \gamma","['integration', 'definite-integrals', 'logarithms', 'exponential-function', 'multiple-integral']"
64,Quadratic-trigonometric integral -- part 2,Quadratic-trigonometric integral -- part 2,,"Problem I need to compute the following integral \begin{equation*}\int_{t_\text{s}}^{t_\text{e}} \cos(a+b\tau+c\tau^2)\text{ d}\tau\end{equation*} where $t_{\text{s}}<t_{\text{e}}$ and $a,b,c>0$ are given parameters. Remark Actually, thanks to the help of @egglog and @Bobby Laspy , I've got a clear solution expressed in terms of the so-called Fresnel integrals \begin{equation*}C(t)\triangleq \int_0^t \cos(\tau^2)\text{ d}\tau \qquad S(t)\triangleq \int_0^t \sin(\tau^2)\text{ d}\tau\end{equation*} Indeed this post is a continuation of this previous one . Questions From what I've understood, the Fresnel integrals are somewhat related to $\text{erf}(\cdot)$ function which, as an engineer, is more familiar to me. Wikipedia presents an expression of $C(\cdot)$ and an expression of $S(\cdot)$ in terms of the $\text{erf}(\cdot)$ function, which are \begin{equation*}\begin{aligned} S(z)&=\sqrt{\frac{\pi}{2}}\frac{1+i}{4}\left[\text{erf}\left(\frac{1+i}{\sqrt{2}}z\right)-i\,\text{erf}\left(\frac{1-i}{\sqrt{2}}z\right)\right]\\ C(z)&=\sqrt{\frac{\pi}{2}}\frac{1-i}{4}\left[\text{erf}\left(\frac{1+i}{\sqrt{2}}z\right)+i\,\text{erf}\left(\frac{1-i}{\sqrt{2}}z\right)\right] \end{aligned}\end{equation*} where, I believe, $i$ is the imaginary unit and the input $z$ is complex. A first question is the following: 1) what are the expressions of the (not complex) $C(\cdot)$ and $S(\cdot)$ in terms of $\text{erf}(\cdot)$ ? The answer to the first question can be obtained from the two expressions above by simply putting inside them $z=t$ real, but I would like to have an explanation (because I don't know if I have correctly understood the underlying theory) and so I'm trying to find a proof for the expressions above. Moreover, it is not clear if the output of the previous expressions is real if $z=t$ is real, so a second question is the following: 2) Why for $z=t$ real the expressions above give a real output? My attempt to prove the expressions, which is below, give rise to a third question: 3) In the derivations of the results are involved the square roots of $\text{j}$ (imaginary unit  expressed in my favorite notation) and $-\text{j}$ . Both $\text{j}$ and $-\text{j}$ have two square roots, so what roots I have to consider and why? Finally, I have also a fourth question about the utility of the $\text{erf}(\cdot)$ function. The expression above requires the computation of $\text{erf}(\cdot)$ with complex input. The $\text{erf}(\cdot)$ is not expressed in terms of elementary functions, so in a practical scenario one have to use some numerical approximation. But when the input is complex what happens? There are some numerical approximation for this more complicated case? It seems to me that the $\text{erf}(\cdot)$ function yields the computation of the Fresnel integrals more complicated because there are numerical approximations, that works with real inputs, of $C(\cdot)$ and $S(\cdot)$ . The question is thus the following: 4) What is the utility of expressing the Fresnel integrals in terms of the $\text{erf}(\cdot)$ function? Cosine integral derivation I consider the case of the cosine integral function (I believe that the sine case is analogous with some minor adjustments), so my objective is to express the integral \begin{equation*}C(t)\triangleq \int_0^t \text{cos}\left(\tau^2\right)\text{ d}\tau\end{equation*} in terms of the error function \begin{equation*}\text{erf}(t)\triangleq \frac{2}{\sqrt{\pi}}\int_0^t \exp\left(-\tau^2\right)\text{ d}\tau\end{equation*} So, in order to do that I'm tempted to express the cosine as the as the combination of two complex exponentials \begin{equation*}\begin{aligned} C(t)&= \int_0^t \frac{\text{exp}\left[\text{j}\left(\tau^2\right)\right]+\text{exp}\left[-\text{j}\left(\tau^2\right)\right]}{2}\text{ d}\tau \end{aligned}\end{equation*} where $\text{j}$ is the imaginary unit (I prefer this notation than $i$ ). Now I have the exponentials with quadratic arguments, but I'm still far from the result. Unfortunately it is not clear what to do, so I have to exploit my fantasy to find a way to rearrange the integral in a way such that the $\text{erf}(\cdot)$ function turns out somewhere. Firstly, I split the integrand, \begin{equation*}\begin{aligned} C(t)&= \frac{1}{2}\left[\underbrace{\int_0^t \text{exp}\left(\text{j}\tau^2\right)\text{ d}\tau}_{\triangleq I_1}+\underbrace{\int_0^t\text{exp}\left(-\text{j}\tau^2\right)\text{ d}\tau}_{\triangleq I_2}\right] \end{aligned}\end{equation*} so that I have to compute two independent integrals $I_1$ and $I_2$ . Second integral I start from the second integral because is easier. Thanks to the following dirty trick \begin{equation*}\begin{aligned} I_2&=    \frac{1}{\sqrt{\text{j}}}\int_0^t\text{exp}\left(-\text{j}\tau^2\right)\sqrt{\text{j}}\text{    d}\tau \end{aligned}\end{equation*} I can use the change of variable \begin{equation*} \alpha(\tau)\triangleq \sqrt{\text{j}}\,\tau    \end{equation*} which implies $\text{d}\alpha=\sqrt{\text{j}}\,\text{d}\tau$ ,  to write finally \begin{equation*}\begin{aligned} I_2&=    \frac{1}{\sqrt{\text{j}}}\int_0^{\sqrt{\text{j}}t}\text{exp}\left(-\alpha^2\right)\text{    d}\alpha=\frac{1}{\sqrt{\text{j}}}\frac{\sqrt{\pi}}{2}\text{erf}\left(\sqrt{\text{j}}t\right)    \end{aligned}\end{equation*} First integral For the first integral I use the same procedure, but starting from a different trick \begin{equation*}\begin{aligned} I_1&=    \frac{1}{\sqrt{-\text{j}}}\int_0^t\text{exp}\left(\text{j}\tau^2\right)\sqrt{-\text{j}}\text{    d}\tau \end{aligned}\end{equation*} so that the change of variable \begin{equation*} \beta(\tau)\triangleq \sqrt{-\text{j}}\,\tau    \end{equation*} allows to write \begin{equation*}\begin{aligned}    I_1&=    \frac{1}{\sqrt{-\text{j}}}\int_0^{\sqrt{-\text{j}}t}\text{exp}\left(-\beta^2\right)\text{    d}\beta=    \frac{1}{\sqrt{-\text{j}}}\frac{\sqrt{\pi}}{2}\text{erf}\left(\sqrt{-\text{j}}t\right)\\    \end{aligned}\end{equation*} In conclusion, the implicit result is \begin{equation*}C(t)=\frac{\sqrt{\pi}}{4}\left[\frac{1}{\sqrt{-\text{j}}}\text{erf}\left(\sqrt{-\text{j}}t\right)+\frac{1}{\sqrt{\text{j}}}\text{erf}\left(\sqrt{\text{j}}t\right)\right]\end{equation*} here I'm saying ""implicit"" because the square roots of $\text{j}$ and $-\text{j}$ are left implicit. This is a problem because both $\text{j}$ and $-\text{j}$ have not one square root, but two square roots! \begin{equation*}\begin{aligned} \sqrt{\text{j}}&=\sqrt{\exp\left(\text{j}\frac{\pi}{2}\right)}=\pm\exp\left(\text{j}\frac{\pi}{4}\right)=\pm\left(\frac{\sqrt{2}}{2}+\text{j}\frac{\sqrt{2}}{2}\right)\\ \sqrt{-\text{j}}&=\sqrt{\exp\left(-\text{j}\frac{\pi}{2}\right)}=\pm\exp\left(-\text{j}\frac{\pi}{4}\right)=\pm\left(\frac{\sqrt{2}}{2}-\text{j}\frac{\sqrt{2}}{2}\right)\\\end{aligned} \end{equation*} so, which one I have to consider? This is not so clear. It seems that Wikipedia consider the first roots (the one with the positive sign outside), but why? Final observation Such square roots are born from the change of variables $\alpha$ and $\beta$ , so in principle I can decide by myself what root to use because any root leads to the same integral in $\text{d}\alpha$ and the same integral in $\text{d}\beta$ . But this fact must imply that the ending result for $C(\cdot)$ is independent from the choice of the roots. This is actually true? I cannot see it clearly because the inputs of the $\text{erf}(\cdot)$ functions changes if the roots of $\sqrt{\text{j}}$ and $\sqrt{-\text{j}}$ change.","Problem I need to compute the following integral where and are given parameters. Remark Actually, thanks to the help of @egglog and @Bobby Laspy , I've got a clear solution expressed in terms of the so-called Fresnel integrals Indeed this post is a continuation of this previous one . Questions From what I've understood, the Fresnel integrals are somewhat related to function which, as an engineer, is more familiar to me. Wikipedia presents an expression of and an expression of in terms of the function, which are where, I believe, is the imaginary unit and the input is complex. A first question is the following: 1) what are the expressions of the (not complex) and in terms of ? The answer to the first question can be obtained from the two expressions above by simply putting inside them real, but I would like to have an explanation (because I don't know if I have correctly understood the underlying theory) and so I'm trying to find a proof for the expressions above. Moreover, it is not clear if the output of the previous expressions is real if is real, so a second question is the following: 2) Why for real the expressions above give a real output? My attempt to prove the expressions, which is below, give rise to a third question: 3) In the derivations of the results are involved the square roots of (imaginary unit  expressed in my favorite notation) and . Both and have two square roots, so what roots I have to consider and why? Finally, I have also a fourth question about the utility of the function. The expression above requires the computation of with complex input. The is not expressed in terms of elementary functions, so in a practical scenario one have to use some numerical approximation. But when the input is complex what happens? There are some numerical approximation for this more complicated case? It seems to me that the function yields the computation of the Fresnel integrals more complicated because there are numerical approximations, that works with real inputs, of and . The question is thus the following: 4) What is the utility of expressing the Fresnel integrals in terms of the function? Cosine integral derivation I consider the case of the cosine integral function (I believe that the sine case is analogous with some minor adjustments), so my objective is to express the integral in terms of the error function So, in order to do that I'm tempted to express the cosine as the as the combination of two complex exponentials where is the imaginary unit (I prefer this notation than ). Now I have the exponentials with quadratic arguments, but I'm still far from the result. Unfortunately it is not clear what to do, so I have to exploit my fantasy to find a way to rearrange the integral in a way such that the function turns out somewhere. Firstly, I split the integrand, so that I have to compute two independent integrals and . Second integral I start from the second integral because is easier. Thanks to the following dirty trick I can use the change of variable which implies ,  to write finally First integral For the first integral I use the same procedure, but starting from a different trick so that the change of variable allows to write In conclusion, the implicit result is here I'm saying ""implicit"" because the square roots of and are left implicit. This is a problem because both and have not one square root, but two square roots! so, which one I have to consider? This is not so clear. It seems that Wikipedia consider the first roots (the one with the positive sign outside), but why? Final observation Such square roots are born from the change of variables and , so in principle I can decide by myself what root to use because any root leads to the same integral in and the same integral in . But this fact must imply that the ending result for is independent from the choice of the roots. This is actually true? I cannot see it clearly because the inputs of the functions changes if the roots of and change.","\begin{equation*}\int_{t_\text{s}}^{t_\text{e}} \cos(a+b\tau+c\tau^2)\text{ d}\tau\end{equation*} t_{\text{s}}<t_{\text{e}} a,b,c>0 \begin{equation*}C(t)\triangleq \int_0^t \cos(\tau^2)\text{ d}\tau \qquad S(t)\triangleq \int_0^t \sin(\tau^2)\text{ d}\tau\end{equation*} \text{erf}(\cdot) C(\cdot) S(\cdot) \text{erf}(\cdot) \begin{equation*}\begin{aligned}
S(z)&=\sqrt{\frac{\pi}{2}}\frac{1+i}{4}\left[\text{erf}\left(\frac{1+i}{\sqrt{2}}z\right)-i\,\text{erf}\left(\frac{1-i}{\sqrt{2}}z\right)\right]\\
C(z)&=\sqrt{\frac{\pi}{2}}\frac{1-i}{4}\left[\text{erf}\left(\frac{1+i}{\sqrt{2}}z\right)+i\,\text{erf}\left(\frac{1-i}{\sqrt{2}}z\right)\right]
\end{aligned}\end{equation*} i z C(\cdot) S(\cdot) \text{erf}(\cdot) z=t z=t z=t \text{j} -\text{j} \text{j} -\text{j} \text{erf}(\cdot) \text{erf}(\cdot) \text{erf}(\cdot) \text{erf}(\cdot) C(\cdot) S(\cdot) \text{erf}(\cdot) \begin{equation*}C(t)\triangleq \int_0^t \text{cos}\left(\tau^2\right)\text{ d}\tau\end{equation*} \begin{equation*}\text{erf}(t)\triangleq \frac{2}{\sqrt{\pi}}\int_0^t \exp\left(-\tau^2\right)\text{ d}\tau\end{equation*} \begin{equation*}\begin{aligned}
C(t)&= \int_0^t \frac{\text{exp}\left[\text{j}\left(\tau^2\right)\right]+\text{exp}\left[-\text{j}\left(\tau^2\right)\right]}{2}\text{ d}\tau
\end{aligned}\end{equation*} \text{j} i \text{erf}(\cdot) \begin{equation*}\begin{aligned}
C(t)&= \frac{1}{2}\left[\underbrace{\int_0^t \text{exp}\left(\text{j}\tau^2\right)\text{ d}\tau}_{\triangleq I_1}+\underbrace{\int_0^t\text{exp}\left(-\text{j}\tau^2\right)\text{ d}\tau}_{\triangleq I_2}\right]
\end{aligned}\end{equation*} I_1 I_2 \begin{equation*}\begin{aligned} I_2&=
   \frac{1}{\sqrt{\text{j}}}\int_0^t\text{exp}\left(-\text{j}\tau^2\right)\sqrt{\text{j}}\text{
   d}\tau \end{aligned}\end{equation*} \begin{equation*} \alpha(\tau)\triangleq \sqrt{\text{j}}\,\tau
   \end{equation*} \text{d}\alpha=\sqrt{\text{j}}\,\text{d}\tau \begin{equation*}\begin{aligned} I_2&=
   \frac{1}{\sqrt{\text{j}}}\int_0^{\sqrt{\text{j}}t}\text{exp}\left(-\alpha^2\right)\text{
   d}\alpha=\frac{1}{\sqrt{\text{j}}}\frac{\sqrt{\pi}}{2}\text{erf}\left(\sqrt{\text{j}}t\right)
   \end{aligned}\end{equation*} \begin{equation*}\begin{aligned} I_1&=
   \frac{1}{\sqrt{-\text{j}}}\int_0^t\text{exp}\left(\text{j}\tau^2\right)\sqrt{-\text{j}}\text{
   d}\tau \end{aligned}\end{equation*} \begin{equation*} \beta(\tau)\triangleq \sqrt{-\text{j}}\,\tau
   \end{equation*} \begin{equation*}\begin{aligned}
   I_1&=
   \frac{1}{\sqrt{-\text{j}}}\int_0^{\sqrt{-\text{j}}t}\text{exp}\left(-\beta^2\right)\text{
   d}\beta=
   \frac{1}{\sqrt{-\text{j}}}\frac{\sqrt{\pi}}{2}\text{erf}\left(\sqrt{-\text{j}}t\right)\\
   \end{aligned}\end{equation*} \begin{equation*}C(t)=\frac{\sqrt{\pi}}{4}\left[\frac{1}{\sqrt{-\text{j}}}\text{erf}\left(\sqrt{-\text{j}}t\right)+\frac{1}{\sqrt{\text{j}}}\text{erf}\left(\sqrt{\text{j}}t\right)\right]\end{equation*} \text{j} -\text{j} \text{j} -\text{j} \begin{equation*}\begin{aligned}
\sqrt{\text{j}}&=\sqrt{\exp\left(\text{j}\frac{\pi}{2}\right)}=\pm\exp\left(\text{j}\frac{\pi}{4}\right)=\pm\left(\frac{\sqrt{2}}{2}+\text{j}\frac{\sqrt{2}}{2}\right)\\
\sqrt{-\text{j}}&=\sqrt{\exp\left(-\text{j}\frac{\pi}{2}\right)}=\pm\exp\left(-\text{j}\frac{\pi}{4}\right)=\pm\left(\frac{\sqrt{2}}{2}-\text{j}\frac{\sqrt{2}}{2}\right)\\\end{aligned}
\end{equation*} \alpha \beta \text{d}\alpha \text{d}\beta C(\cdot) \text{erf}(\cdot) \sqrt{\text{j}} \sqrt{-\text{j}}","['integration', 'complex-integration', 'trigonometric-integrals', 'error-function', 'fresnel-integrals']"
65,Integration in cylindrical coordinate system,Integration in cylindrical coordinate system,,"Context: I am trying to derive an equation given in a Journal of Fluid Mechanics paper (2.2). It deals with the analysis of an axisymmetric turbulent wake where cylindrical coordinate system has been used (which to me is a little hard to understand as I typically deals in Cartesian system). We start with what is called as a momentum equation (simplified version after certain assumptions): $$U_\infty \frac{\partial}{\partial x} (U - U_\infty) = - \frac{1}{r} \frac{\partial}{\partial r} (r \ \overline{uv})$$ Here, $r$ is the radial direction. The axial ( $x$ ) velocity is defined as $U$ and $U_\infty$ is a constant freestream velocity. The term $\overline{uv}$ is called as a turbulent stress which tends to zero if $r$ tends to infinity (i.e. restricted within a finite radial distance). The authors integrate this equation over a cross-section to yield: $$U_\infty \int_0^\infty (U_\infty - U) r \ dr \approx \theta^2U_\infty^2$$ where $\theta$ is the momentum thickness. I think I can tweak the variables to get the $\theta$ in the equation, but I am not able to understand how exactly would we take a cross-section and then integrate over it? Any leads would be appreciated. PS: Another equation that hasn't been mentioned is a continuity equation that is written as: $$\frac{\partial U}{\partial x} + \frac{1}{r} \frac{\partial}{\partial x} (r V) = 0$$","Context: I am trying to derive an equation given in a Journal of Fluid Mechanics paper (2.2). It deals with the analysis of an axisymmetric turbulent wake where cylindrical coordinate system has been used (which to me is a little hard to understand as I typically deals in Cartesian system). We start with what is called as a momentum equation (simplified version after certain assumptions): Here, is the radial direction. The axial ( ) velocity is defined as and is a constant freestream velocity. The term is called as a turbulent stress which tends to zero if tends to infinity (i.e. restricted within a finite radial distance). The authors integrate this equation over a cross-section to yield: where is the momentum thickness. I think I can tweak the variables to get the in the equation, but I am not able to understand how exactly would we take a cross-section and then integrate over it? Any leads would be appreciated. PS: Another equation that hasn't been mentioned is a continuity equation that is written as:",U_\infty \frac{\partial}{\partial x} (U - U_\infty) = - \frac{1}{r} \frac{\partial}{\partial r} (r \ \overline{uv}) r x U U_\infty \overline{uv} r U_\infty \int_0^\infty (U_\infty - U) r \ dr \approx \theta^2U_\infty^2 \theta \theta \frac{\partial U}{\partial x} + \frac{1}{r} \frac{\partial}{\partial x} (r V) = 0,"['integration', 'partial-differential-equations', 'fluid-dynamics', 'cylindrical-coordinates', 'boundary-layer']"
66,Maximizing An Integral Using Stokes' Theorem,Maximizing An Integral Using Stokes' Theorem,,"Here's a question I've been stuck on: Find a piecewise smooth, simple, closed, oriented curve $C$ which maximizes $$ \int\limits_{C} \vec{F} \,\mathrm{d}\vec{x},\quad \vec{F}(x,y,z)=\big(-y(z+1),x(z+1),0\big) $$ among all curves $C$ restricted to lie on the three-dimensional unit sphere. I began with computing $$\nabla \times F=\big(-x,-y,2(z+1)\big)$$ which doesn't really simplify the question a lot. Next, I restricted myself to deal with situations where $z$ is held constant. In this situation, by the Stokes' Theorem, and by using Polar Coordinates, I can write out, $$\int\limits_{C} \vec{F}\, \mathrm{d}\vec{x}=\iint\limits_S \big((\nabla \times \vec{F})\cdot \vec{n}\big) r\,\mathrm{d}r\,\mathrm{d}\theta \quad\vec{n}=(0,0,1), r\in(0,a],\theta\in(0,2\pi), z^2=1-a^2 $$ Upon solving this, I got that the integrand is maximized when, $$a=1 \implies z=0\implies x^2+y^2=1$$ I'm trying to generalize this approach to any curve which lies on the unit sphere. However, the primary issue I'm encountering is a lack of a neat expression for the unit normal (for any arbitrary surface satisfying the constraints) which appears in the Stokes' Theorem. I'm not really sure how to proceed any further. Update: 23rd August 2020 So, based on some comments and help from other forums, I got the following idea. The integrand, after the application of Stokes' Theorem, reduces to: $$\iint\limits_S 3z^2+2z-1 dA$$ If you consider the function in the integral on the domain $$z\in[-1,1]$$ , you'll see that the function is non-negative when $$\frac{1}{3}\leq z<1$$ , and non-positive otherwise. Therefore, in order to maximize the integral, we need to consider the surface on the sphere enclosed between the planes $$z=\frac{1}{3}, z=1$$ I used the following parameterization: $$(x,y,z)=(\cos(\theta)\sin(\phi), \sin(\theta)\sin(\phi), \cos(\phi)), 0\leq \theta \leq 2\pi, 0 \leq \phi \leq \frac{\pi}{2}-\arctan{\frac{1}{2\sqrt{2}}}$$ Then, $$\iint\limits_S 3z^2+2z-1 dA=\iint\limits_S (3\cos^2(\phi)+2\cos(\phi)-1)\sin(\phi)d\phi d\theta = \frac{64\pi}{27}$$ I believe this is the maximum...","Here's a question I've been stuck on: Find a piecewise smooth, simple, closed, oriented curve which maximizes among all curves restricted to lie on the three-dimensional unit sphere. I began with computing which doesn't really simplify the question a lot. Next, I restricted myself to deal with situations where is held constant. In this situation, by the Stokes' Theorem, and by using Polar Coordinates, I can write out, Upon solving this, I got that the integrand is maximized when, I'm trying to generalize this approach to any curve which lies on the unit sphere. However, the primary issue I'm encountering is a lack of a neat expression for the unit normal (for any arbitrary surface satisfying the constraints) which appears in the Stokes' Theorem. I'm not really sure how to proceed any further. Update: 23rd August 2020 So, based on some comments and help from other forums, I got the following idea. The integrand, after the application of Stokes' Theorem, reduces to: If you consider the function in the integral on the domain , you'll see that the function is non-negative when , and non-positive otherwise. Therefore, in order to maximize the integral, we need to consider the surface on the sphere enclosed between the planes I used the following parameterization: Then, I believe this is the maximum...","C 
\int\limits_{C} \vec{F} \,\mathrm{d}\vec{x},\quad \vec{F}(x,y,z)=\big(-y(z+1),x(z+1),0\big)
 C \nabla \times F=\big(-x,-y,2(z+1)\big) z \int\limits_{C} \vec{F}\, \mathrm{d}\vec{x}=\iint\limits_S \big((\nabla \times \vec{F})\cdot \vec{n}\big) r\,\mathrm{d}r\,\mathrm{d}\theta \quad\vec{n}=(0,0,1), r\in(0,a],\theta\in(0,2\pi), z^2=1-a^2  a=1 \implies z=0\implies x^2+y^2=1 \iint\limits_S 3z^2+2z-1 dA z\in[-1,1] \frac{1}{3}\leq z<1 z=\frac{1}{3}, z=1 (x,y,z)=(\cos(\theta)\sin(\phi), \sin(\theta)\sin(\phi), \cos(\phi)), 0\leq \theta \leq 2\pi, 0 \leq \phi \leq \frac{\pi}{2}-\arctan{\frac{1}{2\sqrt{2}}} \iint\limits_S 3z^2+2z-1 dA=\iint\limits_S (3\cos^2(\phi)+2\cos(\phi)-1)\sin(\phi)d\phi d\theta = \frac{64\pi}{27}","['integration', 'stokes-theorem']"
67,Second-Order In(exact) ODEs,Second-Order In(exact) ODEs,,"The second total derivative of $F(x,\ y(x))$ is $F_y y'' + F_{yy}(y')^2 + 2F_{xy}y' + F_{xx}$ .  Thus by analogy to first-order exact ODEs, if one notices a second-order ODE where this pattern equals some expression containing no $y$ 's, i.e., $\frac{1}{y}y'' - \frac{1}{y^2}(y')^2 - \frac{1}{x^2} = 0$ , the LHS can be condensed, in this case turning the ODE into $(ln|xy|)'' = 0$ , and both sides doubly integrated, in this case $ln|xy| = Ax + B \implies y = \frac{Be^{Ax}}{x}$ .  Of course, I had to reverse engineer this example from a chosen $F(x,\ y(x))$ ; otherwise it would have been likely prohibitively hard to spot. 1)  I assume a second-order ODE is exact if and only if the LHS can be condensed into $F(x,\ y(x))$ and integrated as shown above.  Is there an analogy here to the 2D-curl test for exactness? 2)  Is there a method here for finding integrating factors to make inexact equations exact, at least in certain cases? 3)  Is there a way to convert such ODEs into differential forms (analogous to how one ""sort of"" multiplies the first-order ODE through by $dx$ , even though that's not really what's going on but in practice it basically is)? 4)  There aren't many good resources on second-order exact ODEs, but the SE questions I found and this video spoken in a language I don't know never seem to involve $(y')^2$ .  Is this because it is only practical to consider the subset of cases where $F_{yy} = 0$ , as opposed to my contrived example where $F_{xy} = 0$ but $F_{yy} \neq 0$ , or are these second-order exact ODEs a different animal?  If the latter, are they related to my notion of second-order exact ODEs in any way?","The second total derivative of is .  Thus by analogy to first-order exact ODEs, if one notices a second-order ODE where this pattern equals some expression containing no 's, i.e., , the LHS can be condensed, in this case turning the ODE into , and both sides doubly integrated, in this case .  Of course, I had to reverse engineer this example from a chosen ; otherwise it would have been likely prohibitively hard to spot. 1)  I assume a second-order ODE is exact if and only if the LHS can be condensed into and integrated as shown above.  Is there an analogy here to the 2D-curl test for exactness? 2)  Is there a method here for finding integrating factors to make inexact equations exact, at least in certain cases? 3)  Is there a way to convert such ODEs into differential forms (analogous to how one ""sort of"" multiplies the first-order ODE through by , even though that's not really what's going on but in practice it basically is)? 4)  There aren't many good resources on second-order exact ODEs, but the SE questions I found and this video spoken in a language I don't know never seem to involve .  Is this because it is only practical to consider the subset of cases where , as opposed to my contrived example where but , or are these second-order exact ODEs a different animal?  If the latter, are they related to my notion of second-order exact ODEs in any way?","F(x,\ y(x)) F_y y'' + F_{yy}(y')^2 + 2F_{xy}y' + F_{xx} y \frac{1}{y}y'' - \frac{1}{y^2}(y')^2 - \frac{1}{x^2} = 0 (ln|xy|)'' = 0 ln|xy| = Ax + B \implies y = \frac{Be^{Ax}}{x} F(x,\ y(x)) F(x,\ y(x)) dx (y')^2 F_{yy} = 0 F_{xy} = 0 F_{yy} \neq 0","['integration', 'ordinary-differential-equations', 'partial-derivative', 'curl', 'integrating-factor']"
68,Evaluating the integral $\int_0^\infty \frac{\ln(x)}{e^x+1}$ [duplicate],Evaluating the integral  [duplicate],\int_0^\infty \frac{\ln(x)}{e^x+1},"This question already has answers here : $\int_0^{\infty } \frac{\log (x)}{e^x+1} \, dx = -\frac{1}{2} \log ^2(2)$ How to show? (2 answers) Closed 4 years ago . I'm interested in evaluating the integral of $$ \int_0^\infty \frac{\ln(x)}{e^x+1}\ $$ TLDR: How do you evaluate $ \eta'(1) $ ? I found and adapted this integral from this video , unfortunately, they didn't fully evaluate the integral and I'm interested in the result. This question is similar to this , but my question goes more in-depth on the way that I tried to evaluate this integral. This was solved by @J.G. in the answers, and by @Zacky in the comments. I'll run through what I did and what the video did to evaluate the integral $$ I =\int_0^\infty \frac{\ln(x)}{e^x+1}$$ Multiplying by $ \frac{e^{-x}}{e^{-x}}\ $ results in $$ = \int_0^\infty\frac{e^{-x}\ln(x)}{e^{-x}+1} $$ Expanding the denominator into a geometric sum results in $$ = \int_0^\infty\ e^{-x}\ln(x)\sum_{k\ge0}{-e^{-x^k}} $$ Interchanging our signs of integration of summation and simplifying results in $$ \sum_{k \ge 0}(-1)^k \int_0^\infty\ e^{-x(k+1)}\ln(x) $$ Substituting $ x(k+1) = t $ and $ dx = \frac{dt}{k+1} $ results in $$ \sum_{k \ge 0} (-1)^k \int_0^\infty e^{-t}\ln(\frac t{k+1})\frac{dt}{k+1} $$ Expanded and simplified you get $$ \sum_{k \ge 0} \frac{(-1)^k}{k+1} (\int_0^\infty \ln(t)e^{-t}dt - \ln(k+1)\int_0^\infty e^{-t}dt) $$ Once again simplified we can see that our first integral is the $ \mathcal L\{\ln(t)\} $ at $s = 1$ and our second integral is $\Gamma(1)$ in total this results in. Where $ \mathcal L $ is the Laplace transform and $\Gamma$ is the Gamma function. $$ \sum_{k \ge 0} \frac{(-1)^k}{k+1}(\mathcal L\{\ln(t)\}-\ln(k+1)\Gamma(1)) $$ This then simplifies to $$ \sum_{k \ge 0} \frac{(-1)^k}{k+1}(-\gamma-\ln(k+1)) $$ With $ \gamma $ being the euler-mascheroni constant Increasing our lower bound on our summation we get $$ \sum_{k \ge 1} \frac{(-1)^{k-1}}k(-\gamma-\ln(k)) $$ Realizing that the Dirichlet Eta function is defined as $$ \eta(s) = \sum_{k \ge 1} \frac{(-1)^{k-1}}{k^s} $$ We can then see that our equation is $$ \eta(1)(-\gamma-\ln(k)) $$ Knowing that $ \eta(1) = \ln(2) $ we can then distribute our eta to get $$ -\gamma\ln(2)-\ln(k)\eta(1) $$ Which is $$ -\gamma\ln(2) - \sum_{k \ge 1} \frac{(-1)^{k-1}}k\ln(k) $$ Taking the derivative of the eta function we can see that this is $$ -\gamma\ln(2)+\eta'(1) $$ According to Wikipedia $ \eta'(1) $ is equal to $ \gamma\ln(2)-\frac{\ln(2)^2}2$ Meaning that our integral $I$ will evaluate to $$ I = -\frac{\ln(2)^2}2$$ But how can we evaluate $ \eta'(1) $ without encountering the pole at $s = 1$ of the Zeta function? Are there any other interesting ways to evaluate this integral not using the eta function? Thank you for your time and patience!","This question already has answers here : $\int_0^{\infty } \frac{\log (x)}{e^x+1} \, dx = -\frac{1}{2} \log ^2(2)$ How to show? (2 answers) Closed 4 years ago . I'm interested in evaluating the integral of TLDR: How do you evaluate ? I found and adapted this integral from this video , unfortunately, they didn't fully evaluate the integral and I'm interested in the result. This question is similar to this , but my question goes more in-depth on the way that I tried to evaluate this integral. This was solved by @J.G. in the answers, and by @Zacky in the comments. I'll run through what I did and what the video did to evaluate the integral Multiplying by results in Expanding the denominator into a geometric sum results in Interchanging our signs of integration of summation and simplifying results in Substituting and results in Expanded and simplified you get Once again simplified we can see that our first integral is the at and our second integral is in total this results in. Where is the Laplace transform and is the Gamma function. This then simplifies to With being the euler-mascheroni constant Increasing our lower bound on our summation we get Realizing that the Dirichlet Eta function is defined as We can then see that our equation is Knowing that we can then distribute our eta to get Which is Taking the derivative of the eta function we can see that this is According to Wikipedia is equal to Meaning that our integral will evaluate to But how can we evaluate without encountering the pole at of the Zeta function? Are there any other interesting ways to evaluate this integral not using the eta function? Thank you for your time and patience!", \int_0^\infty \frac{\ln(x)}{e^x+1}\   \eta'(1)   I =\int_0^\infty \frac{\ln(x)}{e^x+1}  \frac{e^{-x}}{e^{-x}}\   = \int_0^\infty\frac{e^{-x}\ln(x)}{e^{-x}+1}   = \int_0^\infty\ e^{-x}\ln(x)\sum_{k\ge0}{-e^{-x^k}}   \sum_{k \ge 0}(-1)^k \int_0^\infty\ e^{-x(k+1)}\ln(x)   x(k+1) = t   dx = \frac{dt}{k+1}   \sum_{k \ge 0} (-1)^k \int_0^\infty e^{-t}\ln(\frac t{k+1})\frac{dt}{k+1}   \sum_{k \ge 0} \frac{(-1)^k}{k+1} (\int_0^\infty \ln(t)e^{-t}dt - \ln(k+1)\int_0^\infty e^{-t}dt)   \mathcal L\{\ln(t)\}  s = 1 \Gamma(1)  \mathcal L  \Gamma  \sum_{k \ge 0} \frac{(-1)^k}{k+1}(\mathcal L\{\ln(t)\}-\ln(k+1)\Gamma(1))   \sum_{k \ge 0} \frac{(-1)^k}{k+1}(-\gamma-\ln(k+1))   \gamma   \sum_{k \ge 1} \frac{(-1)^{k-1}}k(-\gamma-\ln(k))   \eta(s) = \sum_{k \ge 1} \frac{(-1)^{k-1}}{k^s}   \eta(1)(-\gamma-\ln(k))   \eta(1) = \ln(2)   -\gamma\ln(2)-\ln(k)\eta(1)   -\gamma\ln(2) - \sum_{k \ge 1} \frac{(-1)^{k-1}}k\ln(k)   -\gamma\ln(2)+\eta'(1)   \eta'(1)   \gamma\ln(2)-\frac{\ln(2)^2}2 I  I = -\frac{\ln(2)^2}2  \eta'(1)  s = 1,"['integration', 'number-theory', 'riemann-zeta']"
69,Different(?) measures on sphere,Different(?) measures on sphere,,"Let us consider the real sphere $S^{2n-1}:=\{x=(x_1,\ldots,x_{2n})\in\Bbb R^{2n}\mid\lVert x\rVert=1\}$ and the complex sphere $S_\Bbb C^{n-1}:=\{z=(z_1,\ldots,z_n)\in\Bbb C^n\mid\lVert z\rVert=1\}$ . Then we have an isomorphism \begin{align*} \Phi:S_\Bbb C^{n-1}\rightarrow S^{2n-1},\quad z\mapsto x \end{align*} where $z_1=x_1+ix_{n+1},z_2=x_2+ix_{n+2},\ldots,z_n=x_n+ix_{2n}$ . Now consider the inner product \begin{align*} \langle f,g\rangle_{L^2(S_\Bbb C^{n-1})}:=\int_{S_\Bbb C^{n-1}}f(z)\overline{g(z)}dz \end{align*} of functions $f,g$ on $S_\Bbb C^{n-1}$ where $dz$ is the $U(n)$ -invariant measure on $S_\Bbb C^{n-1}$ and let \begin{align*} \langle f,g\rangle_{L^2(S^{2n-1})}:=\int_{S^{2n-1}}f(x)\overline{g(x)}dx \end{align*} for two functions $f,g$ on $S^{2n-1}$ where $dx$ is the $O(2n)$ -invariant measure on $S^{2n-1}$ . My question is: Is it true that, after normalizing the measures, it holds for functions $f,g$ on $S^{2n-1}$ that \begin{align*} \langle f,g\rangle_{L^2(S^{2n-1})}=\langle f\circ\Phi, g\circ\Phi\rangle_{L^2(S_\Bbb C^{n-1})}? \end{align*} If not, is there any correlation like $\langle f,g\rangle_{L^2(S^{2n-1})}=0\Rightarrow \langle f\circ\Phi, g\circ\Phi\rangle_{L^2(S_\Bbb C^{n-1})}=0$ ? Thanks for any help in advance.","Let us consider the real sphere and the complex sphere . Then we have an isomorphism where . Now consider the inner product of functions on where is the -invariant measure on and let for two functions on where is the -invariant measure on . My question is: Is it true that, after normalizing the measures, it holds for functions on that If not, is there any correlation like ? Thanks for any help in advance.","S^{2n-1}:=\{x=(x_1,\ldots,x_{2n})\in\Bbb R^{2n}\mid\lVert x\rVert=1\} S_\Bbb C^{n-1}:=\{z=(z_1,\ldots,z_n)\in\Bbb C^n\mid\lVert z\rVert=1\} \begin{align*}
\Phi:S_\Bbb C^{n-1}\rightarrow S^{2n-1},\quad z\mapsto x
\end{align*} z_1=x_1+ix_{n+1},z_2=x_2+ix_{n+2},\ldots,z_n=x_n+ix_{2n} \begin{align*}
\langle f,g\rangle_{L^2(S_\Bbb C^{n-1})}:=\int_{S_\Bbb C^{n-1}}f(z)\overline{g(z)}dz
\end{align*} f,g S_\Bbb C^{n-1} dz U(n) S_\Bbb C^{n-1} \begin{align*}
\langle f,g\rangle_{L^2(S^{2n-1})}:=\int_{S^{2n-1}}f(x)\overline{g(x)}dx
\end{align*} f,g S^{2n-1} dx O(2n) S^{2n-1} f,g S^{2n-1} \begin{align*}
\langle f,g\rangle_{L^2(S^{2n-1})}=\langle f\circ\Phi, g\circ\Phi\rangle_{L^2(S_\Bbb C^{n-1})}?
\end{align*} \langle f,g\rangle_{L^2(S^{2n-1})}=0\Rightarrow \langle f\circ\Phi, g\circ\Phi\rangle_{L^2(S_\Bbb C^{n-1})}=0","['integration', 'measure-theory', 'haar-measure']"
70,Solving an integral equation with inverse Laplace transform,Solving an integral equation with inverse Laplace transform,,"Let $\alpha,\beta,\mu>0$ .  I am looking for a solution, i.e. a function $g(x)$ , that satisfies $$ \frac{\beta^{\alpha}}{\Gamma(\alpha)}\int_0^\infty g(x)x^{\alpha-1}e^{-\beta x}\,\mathrm dx=\left(\frac{\alpha}{\beta}-\mu\right)^{-1}, $$ where $\alpha/\beta>\mu$ .  Note that such a solution would yield an unbiased estimator for $\left(\frac{\alpha}{\beta}-\mu\right)^{-1}$ , i.e. if $X\sim\operatorname{Gamma}(\alpha,\beta)$ then $\operatorname Eg(X)=\left(\frac{\alpha}{\beta}-\mu\right)^{-1}$ . I tried solving this with an inverse Laplace transform by writing $$ \mathcal L\left\{x^{\alpha-1}g(x)\right\}(\beta)=\frac{\Gamma(\alpha)}{\beta^{\alpha}}\left(\frac{\alpha}{\beta}-\mu\right)^{-1}. $$ I recovered $g(x)$ by taking the inverse transform of both sides and then multiplying by $x^{1-\alpha}$ . $$ \begin{aligned} g(x)% &=x^{1-\alpha}\mathcal L^{-1}\left\{\Gamma(\alpha)s^{-\alpha}\left(\frac{\alpha}{s}-\mu\right)^{-1}\right\}(x)\\ &=-\frac{x^{1-\alpha}}{\mu}\mathcal L^{-1}\left\{\Gamma(\alpha)s^{-\alpha}\left(1-\frac{\alpha/\mu}{s}\right)^{-1}\right\}(x). \end{aligned} $$ Using Bateman's Tables of Integral transforms, volume 1, $5.4.(9)$ , this evaluates to $$ g(x)% =-\frac{1}{\mu}\Phi_2\left(1;\alpha;\frac{\alpha}{\mu}x\right), $$ where $$ \Phi_2(b_1,\dots,b_n;\gamma;z_1,\dots,z_n)=\sum_{m_1=0}^\infty \cdots\sum_{m_n=0}^\infty \frac{(b_1)_{m_1}\cdots (b_n)_{m_n}}{(\gamma)_{m_1+\cdots +m_n}m_1!\cdots m_n!}z_1^{m_1}\cdots z_n^{m_n} $$ is the hypergeometric function of $n$ variables.  In this case we have a hypergeomatric function of a single variable; thus, $$ g(x)% =-\frac{1}{\mu}{_1}F_1\left(1;\alpha;\frac{\alpha}{\mu}x\right). $$ Unfortunately, this solution only yields sensible results if $\alpha/\beta<\mu$ (I have tried using some example parameters in MATLAB which demonstrates this). That said, what I am interested in is the case where $\alpha/\beta>\mu$ . The formula in my table of integral transforms only has the restriction $\alpha>0$ .  Maybe there is an error?  How can I get the solution to work for positive $\mu$ ? We can check the solution which does seem to be correct.  Using G&R formula $7.522.9$ we find $$ \begin{aligned} \operatorname Eg(X)% &=-\frac{\beta^{\alpha}}{\mu\Gamma(\alpha)}\int_0^\infty x^{\alpha-1}e^{-\beta x}{_1}F_1\left(1;\alpha;\frac{\alpha}{\mu}x\right).\,\mathrm dx\\ &=-\frac{1}{\mu}{_2}F_1\left({1,\alpha\atop\alpha};\frac{\alpha}{\beta\mu}\right)\\ &=-\frac{1}{\mu}{_1}F_0\left({1\atop -};\frac{\alpha}{\beta\mu}\right)\\ &=-\frac{1}{\mu}\left(1-\frac{\alpha}{\beta\mu}\right)^{-1}\\ &=\left(\frac{\alpha}{\beta}-\mu\right)^{-1}. \end{aligned} $$ So I am puzzled as to why this solution does not work for $\alpha/\beta>\mu$ .  One thing worth noticing is that when $\alpha/\beta<\mu$ , the argument of the ${_1}F_0(1;-;\alpha/(\beta\mu))$ above is less than one and so the series defining it converges to $\left(1-\frac{\alpha}{\beta\mu}\right)^{-1}$ in the usual sense.  For $\alpha/\beta\geq\mu$ the aruguement is greater than or equal to unity and the series defining the ${_1}F_0$ diverges; thus analytic continutation is used.  Maybe this plays into the issue?  Here is a test in MATLAB showing disagreement when $\alpha/\beta<\mu$ : alpha = sym(10); beta = alpha/8; mu = sym(5);  syms x g(x) g(x) = -hypergeom(1,alpha,alpha*x/mu)/mu; for i = 1:512     X = gamrnd(double(alpha),double(1/beta));     est(i) = vpa(g(X)); end  mean(est) = -11979.51 (alpha/beta-mu)^(-1) = 1/3","Let .  I am looking for a solution, i.e. a function , that satisfies where .  Note that such a solution would yield an unbiased estimator for , i.e. if then . I tried solving this with an inverse Laplace transform by writing I recovered by taking the inverse transform of both sides and then multiplying by . Using Bateman's Tables of Integral transforms, volume 1, , this evaluates to where is the hypergeometric function of variables.  In this case we have a hypergeomatric function of a single variable; thus, Unfortunately, this solution only yields sensible results if (I have tried using some example parameters in MATLAB which demonstrates this). That said, what I am interested in is the case where . The formula in my table of integral transforms only has the restriction .  Maybe there is an error?  How can I get the solution to work for positive ? We can check the solution which does seem to be correct.  Using G&R formula we find So I am puzzled as to why this solution does not work for .  One thing worth noticing is that when , the argument of the above is less than one and so the series defining it converges to in the usual sense.  For the aruguement is greater than or equal to unity and the series defining the diverges; thus analytic continutation is used.  Maybe this plays into the issue?  Here is a test in MATLAB showing disagreement when : alpha = sym(10); beta = alpha/8; mu = sym(5);  syms x g(x) g(x) = -hypergeom(1,alpha,alpha*x/mu)/mu; for i = 1:512     X = gamrnd(double(alpha),double(1/beta));     est(i) = vpa(g(X)); end  mean(est) = -11979.51 (alpha/beta-mu)^(-1) = 1/3","\alpha,\beta,\mu>0 g(x) 
\frac{\beta^{\alpha}}{\Gamma(\alpha)}\int_0^\infty g(x)x^{\alpha-1}e^{-\beta x}\,\mathrm dx=\left(\frac{\alpha}{\beta}-\mu\right)^{-1},
 \alpha/\beta>\mu \left(\frac{\alpha}{\beta}-\mu\right)^{-1} X\sim\operatorname{Gamma}(\alpha,\beta) \operatorname Eg(X)=\left(\frac{\alpha}{\beta}-\mu\right)^{-1} 
\mathcal L\left\{x^{\alpha-1}g(x)\right\}(\beta)=\frac{\Gamma(\alpha)}{\beta^{\alpha}}\left(\frac{\alpha}{\beta}-\mu\right)^{-1}.
 g(x) x^{1-\alpha} 
\begin{aligned}
g(x)%
&=x^{1-\alpha}\mathcal L^{-1}\left\{\Gamma(\alpha)s^{-\alpha}\left(\frac{\alpha}{s}-\mu\right)^{-1}\right\}(x)\\
&=-\frac{x^{1-\alpha}}{\mu}\mathcal L^{-1}\left\{\Gamma(\alpha)s^{-\alpha}\left(1-\frac{\alpha/\mu}{s}\right)^{-1}\right\}(x).
\end{aligned}
 5.4.(9) 
g(x)%
=-\frac{1}{\mu}\Phi_2\left(1;\alpha;\frac{\alpha}{\mu}x\right),
 
\Phi_2(b_1,\dots,b_n;\gamma;z_1,\dots,z_n)=\sum_{m_1=0}^\infty \cdots\sum_{m_n=0}^\infty \frac{(b_1)_{m_1}\cdots (b_n)_{m_n}}{(\gamma)_{m_1+\cdots +m_n}m_1!\cdots m_n!}z_1^{m_1}\cdots z_n^{m_n}
 n 
g(x)%
=-\frac{1}{\mu}{_1}F_1\left(1;\alpha;\frac{\alpha}{\mu}x\right).
 \alpha/\beta<\mu \alpha/\beta>\mu \alpha>0 \mu 7.522.9 
\begin{aligned}
\operatorname Eg(X)%
&=-\frac{\beta^{\alpha}}{\mu\Gamma(\alpha)}\int_0^\infty x^{\alpha-1}e^{-\beta x}{_1}F_1\left(1;\alpha;\frac{\alpha}{\mu}x\right).\,\mathrm dx\\
&=-\frac{1}{\mu}{_2}F_1\left({1,\alpha\atop\alpha};\frac{\alpha}{\beta\mu}\right)\\
&=-\frac{1}{\mu}{_1}F_0\left({1\atop -};\frac{\alpha}{\beta\mu}\right)\\
&=-\frac{1}{\mu}\left(1-\frac{\alpha}{\beta\mu}\right)^{-1}\\
&=\left(\frac{\alpha}{\beta}-\mu\right)^{-1}.
\end{aligned}
 \alpha/\beta>\mu \alpha/\beta<\mu {_1}F_0(1;-;\alpha/(\beta\mu)) \left(1-\frac{\alpha}{\beta\mu}\right)^{-1} \alpha/\beta\geq\mu {_1}F_0 \alpha/\beta<\mu","['integration', 'laplace-transform', 'gamma-function', 'hypergeometric-function', 'gamma-distribution']"
71,Integrating a differential form,Integrating a differential form,,"I am currently going through Introduction to Smooth manifolds by John Lee and am a bit confused with the integration of differential forms. So given a smooth k-form $\omega = f dx^1 \wedge ... \wedge dx^k $ on some integral domain $D \subset \mathbb{R}^k$ we can integrate $\omega$ over $D$, which is given in the book by $$\int_D f dx^1 \wedge ... \wedge dx^k = \int_D f dx^1 ... dx^k \, \, \, \,  \, \, (\star)$$ What I am confused about is that if we interchange say the $dx^1$ and the $dx^2$ in both sides of the equation we get a negative side arising on the left as $dx^1 \wedge dx^2 = - dx^2 \wedge dx^1$, whilst on the right hand side there will be no sign factor as $dx^1 dx^2 =dx^2 dx^1$. Is the reason that the above is not a contradiction a result of the fact we have fixed an orientation $(x^1, ..., x^k)$, and so with this orientation  we get that $(\star)$ holds but  $$\int_D f dx^2 \wedge dx^1 \wedge ... \wedge dx^k \neq \int_D f dx^2 dx^1 dx^3 ... dx^k?$$ That is, we can only integrate once we have ordered the differential form into its chosen orientation?","I am currently going through Introduction to Smooth manifolds by John Lee and am a bit confused with the integration of differential forms. So given a smooth k-form $\omega = f dx^1 \wedge ... \wedge dx^k $ on some integral domain $D \subset \mathbb{R}^k$ we can integrate $\omega$ over $D$, which is given in the book by $$\int_D f dx^1 \wedge ... \wedge dx^k = \int_D f dx^1 ... dx^k \, \, \, \,  \, \, (\star)$$ What I am confused about is that if we interchange say the $dx^1$ and the $dx^2$ in both sides of the equation we get a negative side arising on the left as $dx^1 \wedge dx^2 = - dx^2 \wedge dx^1$, whilst on the right hand side there will be no sign factor as $dx^1 dx^2 =dx^2 dx^1$. Is the reason that the above is not a contradiction a result of the fact we have fixed an orientation $(x^1, ..., x^k)$, and so with this orientation  we get that $(\star)$ holds but  $$\int_D f dx^2 \wedge dx^1 \wedge ... \wedge dx^k \neq \int_D f dx^2 dx^1 dx^3 ... dx^k?$$ That is, we can only integrate once we have ordered the differential form into its chosen orientation?",,"['integration', 'differential-forms']"
72,Integral $\int_0^{\infty}\frac{1}{(1+x^2)(3-\cos x)}dx$,Integral,\int_0^{\infty}\frac{1}{(1+x^2)(3-\cos x)}dx,"Greetings I tried to evaluate $$I=\int_0^{\infty}\frac{1}{(1+x^2)(3-\cos x)}dx$$ Here is my try, it is abit longer, but I wrote it all so that I wont have a silly mistake. My main ideea was to expand into fourier series $$g(t)=\frac{1}{3-\cos t}$$ so I took(I am not sure if it's correct but that is how I learned) $$a_0=\frac{1}{\pi}\int_0^{2\pi}\frac{1}{3-\cos t}dt$$ $$a_n=\frac{1}{\pi}\int_0^{2\pi}\frac{\cos(nt)}{3-\cos t}dt$$$$b_n=\frac{1}{\pi}\int_0^{2\pi}\frac{\sin(nt)}{3-\cos t}dt$$ $$a_n+ib_n=\frac{1}{\pi}\int_0^{2\pi}\frac{e^{int} }{3-\cos t}dt$$ we let $$e^{it}=z \rightarrow dt=\frac{dz}{iz}\, ; |z|=1$$ And we can write $\cos t=\frac{z^2+1}{2z}$ $$a_n+ib_n=\frac{2}{i\pi}\int_{|z|=1} \frac{z^n}{-z^2+6z-1}dz$$our function $$g(z)= \frac{z^n}{-z^2+6z-1}$$ has in the interior of the circle $|z|=1$ simple poles at: $$-z^2+6z-1=0\rightarrow-(z-3)^2+8=0$$giving $$z_1=3-2\sqrt{2}$$ the other pole is not in the circle. So $$\frac{2}{i\pi}\int_{|z|=1} g(z)dz=2\pi i Res(g;z_1)$$ $$Res(g;3-2\sqrt 2)=\lim_{z\to 3-2\sqrt 2} \, \frac{z^n}{z-(3+2\sqrt 2)}=\frac{(3-2\sqrt 2)^n}{-4\sqrt 2}+i\cdot 0$$ Thus the $b_n$ term vanishes and $$a_n=\frac{(3-2\sqrt 2)^n}{-4\sqrt 2}\rightarrow a_0=-\frac{1}{4\sqrt 2}$$ so as a fourier series we have $$g(t)=-\frac{1}{8\sqrt 2}-\frac{1}{4\sqrt 2} \sum_{n=1}^{\infty}\frac{\cos(nt)}{(3+2\sqrt2)^n}$$ So we can rewrite the original integral as $$I=-\frac{1}{8\sqrt 2}\int_0^{\infty}\frac{1}{1+x^2}dx-\frac{1}{4\sqrt 2} \sum_{n=1}^{\infty}\frac{1}{(3+2\sqrt 2)^n}\int_0^{\infty}\frac{\cos(nx)}{1+x^2}dx$$ The first integral is simple, and the second one is well known around here to be $\frac{\pi}{2e^n}$ see for example: Integral evaluation $\int_{-\infty}^{\infty}\frac{\cos (ax)}{\pi (1+x^2)}dx$ so I get $$I=-\frac{\pi}{8\sqrt 2}\left(\frac{1}{2}+\sum_{n=1}^{\infty} \frac{1}{(e(3+2\sqrt 2))^n}\right)=-\frac{\pi}{16\sqrt 2}\left(\frac{3 e+2e\sqrt 2+ 1}{3e+2e\sqrt 2 - 1}\right) $$ Now since wolfram fails to compute this I am not sure, also for sure there is a sign mistake because the integral is positive... Could you please correct my answer?","Greetings I tried to evaluate $$I=\int_0^{\infty}\frac{1}{(1+x^2)(3-\cos x)}dx$$ Here is my try, it is abit longer, but I wrote it all so that I wont have a silly mistake. My main ideea was to expand into fourier series $$g(t)=\frac{1}{3-\cos t}$$ so I took(I am not sure if it's correct but that is how I learned) $$a_0=\frac{1}{\pi}\int_0^{2\pi}\frac{1}{3-\cos t}dt$$ $$a_n=\frac{1}{\pi}\int_0^{2\pi}\frac{\cos(nt)}{3-\cos t}dt$$$$b_n=\frac{1}{\pi}\int_0^{2\pi}\frac{\sin(nt)}{3-\cos t}dt$$ $$a_n+ib_n=\frac{1}{\pi}\int_0^{2\pi}\frac{e^{int} }{3-\cos t}dt$$ we let $$e^{it}=z \rightarrow dt=\frac{dz}{iz}\, ; |z|=1$$ And we can write $\cos t=\frac{z^2+1}{2z}$ $$a_n+ib_n=\frac{2}{i\pi}\int_{|z|=1} \frac{z^n}{-z^2+6z-1}dz$$our function $$g(z)= \frac{z^n}{-z^2+6z-1}$$ has in the interior of the circle $|z|=1$ simple poles at: $$-z^2+6z-1=0\rightarrow-(z-3)^2+8=0$$giving $$z_1=3-2\sqrt{2}$$ the other pole is not in the circle. So $$\frac{2}{i\pi}\int_{|z|=1} g(z)dz=2\pi i Res(g;z_1)$$ $$Res(g;3-2\sqrt 2)=\lim_{z\to 3-2\sqrt 2} \, \frac{z^n}{z-(3+2\sqrt 2)}=\frac{(3-2\sqrt 2)^n}{-4\sqrt 2}+i\cdot 0$$ Thus the $b_n$ term vanishes and $$a_n=\frac{(3-2\sqrt 2)^n}{-4\sqrt 2}\rightarrow a_0=-\frac{1}{4\sqrt 2}$$ so as a fourier series we have $$g(t)=-\frac{1}{8\sqrt 2}-\frac{1}{4\sqrt 2} \sum_{n=1}^{\infty}\frac{\cos(nt)}{(3+2\sqrt2)^n}$$ So we can rewrite the original integral as $$I=-\frac{1}{8\sqrt 2}\int_0^{\infty}\frac{1}{1+x^2}dx-\frac{1}{4\sqrt 2} \sum_{n=1}^{\infty}\frac{1}{(3+2\sqrt 2)^n}\int_0^{\infty}\frac{\cos(nx)}{1+x^2}dx$$ The first integral is simple, and the second one is well known around here to be $\frac{\pi}{2e^n}$ see for example: Integral evaluation $\int_{-\infty}^{\infty}\frac{\cos (ax)}{\pi (1+x^2)}dx$ so I get $$I=-\frac{\pi}{8\sqrt 2}\left(\frac{1}{2}+\sum_{n=1}^{\infty} \frac{1}{(e(3+2\sqrt 2))^n}\right)=-\frac{\pi}{16\sqrt 2}\left(\frac{3 e+2e\sqrt 2+ 1}{3e+2e\sqrt 2 - 1}\right) $$ Now since wolfram fails to compute this I am not sure, also for sure there is a sign mistake because the integral is positive... Could you please correct my answer?",,"['integration', 'proof-verification']"
73,How to reconcile these $L^p$ and $L^2$ (in)equalities?,How to reconcile these  and  (in)equalities?,L^p L^2,"Let $X,Y$ be iid random variables with mean $\mu$ and having finite moments of, say, all orders. It is an easy exercise to show that $$\operatorname{Var}(X) = E[|X-\mu|^2] = \frac{1}{2} E[|X-Y|^2].\tag{*}$$ If we want an $L^p$ version of this statement, $1 \le p < \infty$, we can write $$\begin{align*} E\left[|X-\mu|^p\right] &= E\left[\left|E[X-Y \mid X]\right|^p\right] \\ &\le E\left[E[|X-Y|^p \mid X]\right] &&\text{(conditional Jensen)} \\ &= E[|X-Y|^p].  \end{align*}$$ However, this does not reduce to (*) when $p=2$, because the factor of $1/2$ is missing.  Is there a ""better"" version of this $L^p$ inequality that contains the equality for $p=2$?","Let $X,Y$ be iid random variables with mean $\mu$ and having finite moments of, say, all orders. It is an easy exercise to show that $$\operatorname{Var}(X) = E[|X-\mu|^2] = \frac{1}{2} E[|X-Y|^2].\tag{*}$$ If we want an $L^p$ version of this statement, $1 \le p < \infty$, we can write $$\begin{align*} E\left[|X-\mu|^p\right] &= E\left[\left|E[X-Y \mid X]\right|^p\right] \\ &\le E\left[E[|X-Y|^p \mid X]\right] &&\text{(conditional Jensen)} \\ &= E[|X-Y|^p].  \end{align*}$$ However, this does not reduce to (*) when $p=2$, because the factor of $1/2$ is missing.  Is there a ""better"" version of this $L^p$ inequality that contains the equality for $p=2$?",,"['integration', 'probability-theory', 'measure-theory', 'inequality', 'lp-spaces']"
74,Mechanical Surface Integrator,Mechanical Surface Integrator,,"In an episode of ""Dirty Jobs"" Mike Rowe visited a tannery where they used an old mechanical device to calculate the surface area. Video shown [here] How is it calculating the surface area? Is it doing Riemann sum as it passes through with the width being the distances between the wheel, or is doing an operation similar to a planimeter [ link ] with an application of Green's Theorem? (Or some other mechanism?)","In an episode of ""Dirty Jobs"" Mike Rowe visited a tannery where they used an old mechanical device to calculate the surface area. Video shown [here] How is it calculating the surface area? Is it doing Riemann sum as it passes through with the width being the distances between the wheel, or is doing an operation similar to a planimeter [ link ] with an application of Green's Theorem? (Or some other mechanism?)",,['integration']
75,Differential equation $cos(x-t)=x'$,Differential equation,cos(x-t)=x',"So we have following equation to solve: $$\cos(x-t)=x'$$ This is the first time I use substitution, so I want to ensure that I'm doing it correctly, even though it is probably very easy example. We have: $$\cos(x-t)=\frac{dx}{dt}$$ We substitute $y=x-t$ $$\cos y=\frac{d(y+t)}{dt}=\frac{dy}{dt}+1$$ So: $$dt=\frac{dy}{\cos y-1}$$ And now I have to solve integrals: $$\int dt=\int\frac{dy}{\cos y-1}$$ Is it correct?","So we have following equation to solve: $$\cos(x-t)=x'$$ This is the first time I use substitution, so I want to ensure that I'm doing it correctly, even though it is probably very easy example. We have: $$\cos(x-t)=\frac{dx}{dt}$$ We substitute $y=x-t$ $$\cos y=\frac{d(y+t)}{dt}=\frac{dy}{dt}+1$$ So: $$dt=\frac{dy}{\cos y-1}$$ And now I have to solve integrals: $$\int dt=\int\frac{dy}{\cos y-1}$$ Is it correct?",,"['integration', 'ordinary-differential-equations']"
76,"The geometry behind the lemniscatic integral: $u' = \int^t_0(4t(1-t^2))^{-1/2}\,dt$",The geometry behind the lemniscatic integral:,"u' = \int^t_0(4t(1-t^2))^{-1/2}\,dt","From a translated version of this (page 111): One can easily recognise that in this case, the lemniscatic integral $$u' = \int^t_0\frac{dt}{\sqrt{4t(1-t^2)}}$$ represents the interior of each of the two half-planes in which the plane is divided by the real axis conformally on the interior of a square with sides $\int^1_0\frac{dt}{\sqrt{4t(1-t^2)}}$. I guess that it's saying that the integral conformally maps half-planes to a square with sides $\int^1_0\frac{dt}{\sqrt{4t(1-t^2)}}$, but I can't see the reason why.","From a translated version of this (page 111): One can easily recognise that in this case, the lemniscatic integral $$u' = \int^t_0\frac{dt}{\sqrt{4t(1-t^2)}}$$ represents the interior of each of the two half-planes in which the plane is divided by the real axis conformally on the interior of a square with sides $\int^1_0\frac{dt}{\sqrt{4t(1-t^2)}}$. I guess that it's saying that the integral conformally maps half-planes to a square with sides $\int^1_0\frac{dt}{\sqrt{4t(1-t^2)}}$, but I can't see the reason why.",,"['integration', 'geometry', 'definite-integrals', 'indefinite-integrals']"
77,What is the position of the maximal value of this bell-shaped function?,What is the position of the maximal value of this bell-shaped function?,,"Consider the following function : $$\tag{1} f(v) = v^{\frac{d}{2}} \int_v^{\infty} u^{\alpha \,-\, \smash{\frac{d}{2}} \,-\, 1} \; e^{-\, \alpha \, u} \; du, $$ where $d \le 6$ and $\alpha > 0$ are two positive constants (parameters).  Notice the lower limit of the integral : $v$ is a variable.  The plot of this function (for $0 \le v < \infty$) shows an almost bell-shaped curve, so it has a single maximal value. Now, I would like to find the position $v = v_0(\alpha, d)$ of the maximal value of this function.  I need an analytical expression for $v_0(\alpha, d)$, probably an approximation. $$\tag{2} v_0(\alpha, d) \approx \; ? $$ From the graph of $f(v)$, I know that $v_0 \propto d$ (maybe with some exponent). Take note that the derivative of function (1), set to 0, give this relation : $$\tag{3} f(v_0) \equiv f_{\text{max}} = \frac{2}{d} \; v_0^{\alpha} \; e^{-\, \alpha \, v_0}, $$ where $v_0 \equiv v_0(\alpha, d)$ is the position of the max value of (1). Someone knows a method to find the function (2) ? EDIT : Function (1) describes the ""deformation"" of a black body luminosity caused by the expansion of space in a cosmology model.  From Wien's and Planck's laws, $\alpha$ should be around 3 (depending on the presence of gaz and dust).  $d$ describes the kind of fluid contained in the cosmological model.  We have $d = 3$ for a dust filled universe, and $d = 4$ for a radiation universe.  $d = 0$ for an empty universe with a cosmological constant.  Since $\frac{d}{2} + 1$ gives 2.5 for dust and 3 for radiation, I suspect that $\alpha$ should be close to $\frac{d}{2} + 1$ (while it is an independant parameter).  In this special case, it is easy to explicitely evaluate the integral in (1) and we get the special case $$\tag{4} v_0(d) = \frac{d}{d + 2}, \quad \text{if $\alpha = \frac{d}{2} + 1$}. $$","Consider the following function : $$\tag{1} f(v) = v^{\frac{d}{2}} \int_v^{\infty} u^{\alpha \,-\, \smash{\frac{d}{2}} \,-\, 1} \; e^{-\, \alpha \, u} \; du, $$ where $d \le 6$ and $\alpha > 0$ are two positive constants (parameters).  Notice the lower limit of the integral : $v$ is a variable.  The plot of this function (for $0 \le v < \infty$) shows an almost bell-shaped curve, so it has a single maximal value. Now, I would like to find the position $v = v_0(\alpha, d)$ of the maximal value of this function.  I need an analytical expression for $v_0(\alpha, d)$, probably an approximation. $$\tag{2} v_0(\alpha, d) \approx \; ? $$ From the graph of $f(v)$, I know that $v_0 \propto d$ (maybe with some exponent). Take note that the derivative of function (1), set to 0, give this relation : $$\tag{3} f(v_0) \equiv f_{\text{max}} = \frac{2}{d} \; v_0^{\alpha} \; e^{-\, \alpha \, v_0}, $$ where $v_0 \equiv v_0(\alpha, d)$ is the position of the max value of (1). Someone knows a method to find the function (2) ? EDIT : Function (1) describes the ""deformation"" of a black body luminosity caused by the expansion of space in a cosmology model.  From Wien's and Planck's laws, $\alpha$ should be around 3 (depending on the presence of gaz and dust).  $d$ describes the kind of fluid contained in the cosmological model.  We have $d = 3$ for a dust filled universe, and $d = 4$ for a radiation universe.  $d = 0$ for an empty universe with a cosmological constant.  Since $\frac{d}{2} + 1$ gives 2.5 for dust and 3 for radiation, I suspect that $\alpha$ should be close to $\frac{d}{2} + 1$ (while it is an independant parameter).  In this special case, it is easy to explicitely evaluate the integral in (1) and we get the special case $$\tag{4} v_0(d) = \frac{d}{d + 2}, \quad \text{if $\alpha = \frac{d}{2} + 1$}. $$",,"['integration', 'functions', 'approximation', 'maxima-minima', 'approximate-integration']"
78,Integral representation of Bessel function $K_v(y) = \frac{1}{2} \int_{0}^{\infty} t^{v-1} \text{exp}(-\frac{1}{2}y(t+t^{-1}))\text{d}t$.,Integral representation of Bessel function .,K_v(y) = \frac{1}{2} \int_{0}^{\infty} t^{v-1} \text{exp}(-\frac{1}{2}y(t+t^{-1}))\text{d}t,"How does one find the following representation of the bessel function $K_v(y)$: $$K_v(y) = \frac{1}{2} \int_{0}^{\infty} t^{v-1} \exp \left(-\frac{1}{2}y\left(t+t^{-1}\right) \right)\,\mathrm{d}t.$$ I have seen many different integral presentations in different sources but couldn't find a proof for this one.","How does one find the following representation of the bessel function $K_v(y)$: $$K_v(y) = \frac{1}{2} \int_{0}^{\infty} t^{v-1} \exp \left(-\frac{1}{2}y\left(t+t^{-1}\right) \right)\,\mathrm{d}t.$$ I have seen many different integral presentations in different sources but couldn't find a proof for this one.",,"['integration', 'special-functions', 'bessel-functions']"
79,Evaluate integral with gaussian curvature,Evaluate integral with gaussian curvature,,"I thought evaluating it in the following way: $$\begin{align} \int_0^{2\pi}\int_0^{\pi}K(x,y)\sqrt{\det(g_{ij})} \, dy\,dx &= \int_0^{2\pi}\int_0^\pi \sqrt{\det L_{ij}}\cdot \sqrt{{\frac{\det L_{ij}}{\det{g_{ij}}}}} \, dy\,dx\\ &= \int_0^{2\pi}\int_0^\pi \sqrt{\det{L_{ij}}}\cdot \sqrt{\det (g^{ij}L_{ij})} \,dy\,dx \\ &=\int_0^{2\pi}\int_0^\pi\sqrt{\det L_{ij}}\cdot \sqrt {\det{L^i_{\space\space j}}} \, dy\, dx \end{align}$$ but from here I'm stuck. How can I continue evaluating the integral above?","I thought evaluating it in the following way: $$\begin{align} \int_0^{2\pi}\int_0^{\pi}K(x,y)\sqrt{\det(g_{ij})} \, dy\,dx &= \int_0^{2\pi}\int_0^\pi \sqrt{\det L_{ij}}\cdot \sqrt{{\frac{\det L_{ij}}{\det{g_{ij}}}}} \, dy\,dx\\ &= \int_0^{2\pi}\int_0^\pi \sqrt{\det{L_{ij}}}\cdot \sqrt{\det (g^{ij}L_{ij})} \,dy\,dx \\ &=\int_0^{2\pi}\int_0^\pi\sqrt{\det L_{ij}}\cdot \sqrt {\det{L^i_{\space\space j}}} \, dy\, dx \end{align}$$ but from here I'm stuck. How can I continue evaluating the integral above?",,"['integration', 'differential-geometry', 'coordinate-systems', 'curvature']"
80,Limit behavior of a definite integral that depends on a parameter.,Limit behavior of a definite integral that depends on a parameter.,,"Let $A>0$ and $0\le  \mu \le 2$. Consider a following integral. \begin{equation} {\mathcal I}(A,\mu) := \int\limits_0^\infty e^{-(k A)^\mu} \cdot \frac{\cos(k)-1}{k} dk \end{equation} By substituting for $k A$ and then by expanding the cosine in a Taylor series about zero I  have shown that: \begin{equation} {\mathcal I}(A,\mu) = \frac{1}{\mu} \sum\limits_{n=1}^\infty \frac{(1/A)^n}{n!} \cos\left(\frac{\pi}{2} n\right) \cdot \Gamma\left(\frac{n}{\mu}\right) \end{equation} Unfortunately the series on the right hand side above does not converge for small values of $A$. My question is therefore how do we find the small-$A$ behavior of ${\mathcal I}(A,\mu)$ ?","Let $A>0$ and $0\le  \mu \le 2$. Consider a following integral. \begin{equation} {\mathcal I}(A,\mu) := \int\limits_0^\infty e^{-(k A)^\mu} \cdot \frac{\cos(k)-1}{k} dk \end{equation} By substituting for $k A$ and then by expanding the cosine in a Taylor series about zero I  have shown that: \begin{equation} {\mathcal I}(A,\mu) = \frac{1}{\mu} \sum\limits_{n=1}^\infty \frac{(1/A)^n}{n!} \cos\left(\frac{\pi}{2} n\right) \cdot \Gamma\left(\frac{n}{\mu}\right) \end{equation} Unfortunately the series on the right hand side above does not converge for small values of $A$. My question is therefore how do we find the small-$A$ behavior of ${\mathcal I}(A,\mu)$ ?",,"['integration', 'limits']"
81,geometrical interpretation of a line integral issue,geometrical interpretation of a line integral issue,,"I was wondering : if the geometrical interpretation of a line integral is that the line integral gives the area under the function along a path, then why the line integral is equal to zero when the function is holomorphic inside a closed path, and why it is proportional to the residue if the function has a singularity inside the path? Hope that my quesion is clear :). Thanks in advance for all your feedbacks :).","I was wondering : if the geometrical interpretation of a line integral is that the line integral gives the area under the function along a path, then why the line integral is equal to zero when the function is holomorphic inside a closed path, and why it is proportional to the residue if the function has a singularity inside the path? Hope that my quesion is clear :). Thanks in advance for all your feedbacks :).",,"['integration', 'complex-analysis', 'complex-integration']"
82,Integration by parts: How to choose the constant which make calculations easier?,Integration by parts: How to choose the constant which make calculations easier?,,"The formula of integration by parts is: $$\int u(x)v(x) dx = u(x)V(x) - \int u'(x)V(x) dx$$ Which can be re-written  as: $$\int u(x)v(x) dx = u(x)[V(x)+C] - \int u'(x)[V(x)+C] dx$$ where C is a constant. It makes some integration calculations simpler, such as: $$\int x\tan^{-1}(x) dx$$ When we take $ u(x)=\tan^{-1}(x)$ and $v(x)=x .dx$, then $V(x)= \frac {x^2}2 + \frac 12$ instead of $V(x) = \frac {x^2}2$. It make steps calculations easier and simpler. The question is: How to know and choose this constant? is there some guide or it just experience ?","The formula of integration by parts is: $$\int u(x)v(x) dx = u(x)V(x) - \int u'(x)V(x) dx$$ Which can be re-written  as: $$\int u(x)v(x) dx = u(x)[V(x)+C] - \int u'(x)[V(x)+C] dx$$ where C is a constant. It makes some integration calculations simpler, such as: $$\int x\tan^{-1}(x) dx$$ When we take $ u(x)=\tan^{-1}(x)$ and $v(x)=x .dx$, then $V(x)= \frac {x^2}2 + \frac 12$ instead of $V(x) = \frac {x^2}2$. It make steps calculations easier and simpler. The question is: How to know and choose this constant? is there some guide or it just experience ?",,['integration']
83,Help with the integral $\int_{0}^{\infty}\log\left(1+\frac{s^{2}}{4\pi^{2}} \log(1+ix)\right ) e^{-2\pi nx}dx$,Help with the integral,\int_{0}^{\infty}\log\left(1+\frac{s^{2}}{4\pi^{2}} \log(1+ix)\right ) e^{-2\pi nx}dx,"We have the integral : $$\int_{0}^{\infty}\log\left(1+\frac{s^{2}}{4\pi^{2}} \log(1+ix)\right ) e^{-2\pi nx}dx$$ Where $s$ is a complex parameter, and $n$ is a positive integer. The integral converges by virtue of the exponential factor. I tried to deform the path of integration such that we avoid the branch cut(s) of the logarithm. But here is where i was stuck, the internal complex $\log$ makes it confusing to do so ! EDIT The integral is equivalent to : $$\frac{1}{2\pi n}\int_{0}^{\infty}\frac{e^{2\pi i nx}}{(1+x)\left(\frac{4\pi^{2}}{s^{2}}+\log(1+x) \right )}dx$$ Setting $y=\log(1+x)$, it's also equivalent to : $$\frac{1}{2\pi n}\int_{0}^{\infty}\frac{\exp[{2\pi i n \left(e^{y}-1 \right )]}}{\left(\frac{4\pi^{2}}{s^{2}}+y \right )}dy$$","We have the integral : $$\int_{0}^{\infty}\log\left(1+\frac{s^{2}}{4\pi^{2}} \log(1+ix)\right ) e^{-2\pi nx}dx$$ Where $s$ is a complex parameter, and $n$ is a positive integer. The integral converges by virtue of the exponential factor. I tried to deform the path of integration such that we avoid the branch cut(s) of the logarithm. But here is where i was stuck, the internal complex $\log$ makes it confusing to do so ! EDIT The integral is equivalent to : $$\frac{1}{2\pi n}\int_{0}^{\infty}\frac{e^{2\pi i nx}}{(1+x)\left(\frac{4\pi^{2}}{s^{2}}+\log(1+x) \right )}dx$$ Setting $y=\log(1+x)$, it's also equivalent to : $$\frac{1}{2\pi n}\int_{0}^{\infty}\frac{\exp[{2\pi i n \left(e^{y}-1 \right )]}}{\left(\frac{4\pi^{2}}{s^{2}}+y \right )}dy$$",,"['integration', 'complex-analysis', 'residue-calculus', 'branch-cuts']"
84,proving that the graph of a function is of Jordan measure zero,proving that the graph of a function is of Jordan measure zero,,"Let $f$ be an integrable function from $B$ to $[0,\inf]$ where $B$ is a sphere in $\mathbb{R^n}$. Exercise: For $f$ and $B$, the graph $$ \Gamma=\{(x,f(x)):x\in B\} \subset \mathbb{R}^{n+1} $$ is of volume zero. Prove it. I am having a hard time proving and understanding the whole notion of when a group is of Jordan measure zero and when it isn't; on the same note, what is the intuition behind proving that a group is Jordan Measurable? For instance, what about a sphere in $\mathbb{R^n}$? Thanks a lot!","Let $f$ be an integrable function from $B$ to $[0,\inf]$ where $B$ is a sphere in $\mathbb{R^n}$. Exercise: For $f$ and $B$, the graph $$ \Gamma=\{(x,f(x)):x\in B\} \subset \mathbb{R}^{n+1} $$ is of volume zero. Prove it. I am having a hard time proving and understanding the whole notion of when a group is of Jordan measure zero and when it isn't; on the same note, what is the intuition behind proving that a group is Jordan Measurable? For instance, what about a sphere in $\mathbb{R^n}$? Thanks a lot!",,"['integration', 'measure-theory']"
85,Integral involving a Meijer-G function,Integral involving a Meijer-G function,,"I am having trouble with calculating the following integral: $$ \int_{0}^{\infty} \ln{(1 + \alpha x)\, G^{k,0}_{k,k}\left[e^{-x}\left|^{(a_k)}_{(b_k)} \right.   \right]} \, dx,  $$ where $\alpha > 0$ and $G^{m,n}_{p,q}[\cdot | \cdot]$ is the Meijer-G function. Any ideas or references would be very helpful. Thank you!","I am having trouble with calculating the following integral: $$ \int_{0}^{\infty} \ln{(1 + \alpha x)\, G^{k,0}_{k,k}\left[e^{-x}\left|^{(a_k)}_{(b_k)} \right.   \right]} \, dx,  $$ where $\alpha > 0$ and $G^{m,n}_{p,q}[\cdot | \cdot]$ is the Meijer-G function. Any ideas or references would be very helpful. Thank you!",,"['integration', 'special-functions', 'improper-integrals']"
86,Bochner Integral vs. Riemann Integral,Bochner Integral vs. Riemann Integral,,"Disclaimer This thread is meant to record. See: Answer own Question Anyway, it is written as problem. Have fun! :) Reference This thread is directly related to: Bochner Integral: Axioms Bochner Integral: Integrability Riemann Integral: Bounded Nonexample Riemann Integral: Uniform Convergence Riemann Integral: Improper Version Riemann Integral vs. Uniform Integral and it is indirectly related to: Stone's Theorem Integral Nonmeasurable Functions Pointwise Limit vs. Uniform Limit Prologue This is the final comparison. All notions are up to null sets. Definitions Given a finite measure space $\mu(\Omega)<\infty$ and a Banach space $E$. Consider plain functions $F:\Omega\to E$. Denote the Bochner measurable functions by $\mathcal{B}$. Define the Bochner integral by: $$F\in\mathcal{B}:\quad\int F\mathrm{d}\mu:=\lim_n\int S_n\mathrm{d}\mu$$ for simple functions satisfying: $$\int\|F-S_n\|\mathrm{d}\mu\to0$$ Denote the Bochner integrable functions by $\mathcal{L}_\mathfrak{B}$. Define the generalized Riemann integral by: $$\int_\mathfrak{R}F\mathrm{d}\mu:=\lim_\mathcal{P}\{\sum_{a\in A\in\mathcal{P}}F(a)\mu(A)\}_\mathcal{P}$$ over finite measurable partitions: $$\mathcal{P}\subseteq\Sigma:\quad\Omega=\bigsqcup_{A\in\mathcal{P}}A\quad(\#\mathcal{P}<\infty)$$ being ordered by refinement: $$\mathcal{P}\leq\mathcal{P}':\iff\forall A'\in\mathcal{P}'\exists A\in\mathcal{P}:\quad A\supseteq A'$$ Denote Riemann integrable functions by $\mathcal{L}_\mathfrak{R}$. Problem Clearly, boundedness is a necessary condition for Riemann integrability: $$f:(0,1]\to\mathbb{R}:x\mapsto\frac{1}{\sqrt{x}}:\quad f\in\mathcal{L}_\mathfrak{B},\,f\notin\mathcal{L}_\mathfrak{R}$$ However, there are also bounded Riemann integrable functions that are not Bochner integrable: $$F:[0,1]\to\ell^2[0,1]:t\mapsto\chi_t:\quad F\notin\mathcal{L}_\mathfrak{B},\,F\in\mathcal{L}_\mathfrak{R}$$ Moreover, both strictly include the uniform integral: $$\mathcal{L}_\mathfrak{U}\subsetneq\mathcal{L}_\mathfrak{B}\land\mathcal{L}_\mathfrak{U}\subsetneq\mathcal{L}_\mathfrak{R}$$ So the remaining question is wether at least for the bounded case:   $$\|F\|_\infty<\infty:\quad F\in\mathcal{L}_\mathfrak{B}\implies F\in\mathcal{L}_\mathfrak{R}$$   and especially:   $$\int_\mathfrak{R}F\mathrm{d}\mu=\int_\mathfrak{B}F\mathrm{d}\mu$$ (Have a guess! ;))","Disclaimer This thread is meant to record. See: Answer own Question Anyway, it is written as problem. Have fun! :) Reference This thread is directly related to: Bochner Integral: Axioms Bochner Integral: Integrability Riemann Integral: Bounded Nonexample Riemann Integral: Uniform Convergence Riemann Integral: Improper Version Riemann Integral vs. Uniform Integral and it is indirectly related to: Stone's Theorem Integral Nonmeasurable Functions Pointwise Limit vs. Uniform Limit Prologue This is the final comparison. All notions are up to null sets. Definitions Given a finite measure space $\mu(\Omega)<\infty$ and a Banach space $E$. Consider plain functions $F:\Omega\to E$. Denote the Bochner measurable functions by $\mathcal{B}$. Define the Bochner integral by: $$F\in\mathcal{B}:\quad\int F\mathrm{d}\mu:=\lim_n\int S_n\mathrm{d}\mu$$ for simple functions satisfying: $$\int\|F-S_n\|\mathrm{d}\mu\to0$$ Denote the Bochner integrable functions by $\mathcal{L}_\mathfrak{B}$. Define the generalized Riemann integral by: $$\int_\mathfrak{R}F\mathrm{d}\mu:=\lim_\mathcal{P}\{\sum_{a\in A\in\mathcal{P}}F(a)\mu(A)\}_\mathcal{P}$$ over finite measurable partitions: $$\mathcal{P}\subseteq\Sigma:\quad\Omega=\bigsqcup_{A\in\mathcal{P}}A\quad(\#\mathcal{P}<\infty)$$ being ordered by refinement: $$\mathcal{P}\leq\mathcal{P}':\iff\forall A'\in\mathcal{P}'\exists A\in\mathcal{P}:\quad A\supseteq A'$$ Denote Riemann integrable functions by $\mathcal{L}_\mathfrak{R}$. Problem Clearly, boundedness is a necessary condition for Riemann integrability: $$f:(0,1]\to\mathbb{R}:x\mapsto\frac{1}{\sqrt{x}}:\quad f\in\mathcal{L}_\mathfrak{B},\,f\notin\mathcal{L}_\mathfrak{R}$$ However, there are also bounded Riemann integrable functions that are not Bochner integrable: $$F:[0,1]\to\ell^2[0,1]:t\mapsto\chi_t:\quad F\notin\mathcal{L}_\mathfrak{B},\,F\in\mathcal{L}_\mathfrak{R}$$ Moreover, both strictly include the uniform integral: $$\mathcal{L}_\mathfrak{U}\subsetneq\mathcal{L}_\mathfrak{B}\land\mathcal{L}_\mathfrak{U}\subsetneq\mathcal{L}_\mathfrak{R}$$ So the remaining question is wether at least for the bounded case:   $$\|F\|_\infty<\infty:\quad F\in\mathcal{L}_\mathfrak{B}\implies F\in\mathcal{L}_\mathfrak{R}$$   and especially:   $$\int_\mathfrak{R}F\mathrm{d}\mu=\int_\mathfrak{B}F\mathrm{d}\mu$$ (Have a guess! ;))",,"['integration', 'functional-analysis', 'banach-spaces']"
87,Inverting a Characteristic Function for half-cubic Student's T entailing a Modified Bessel of 2nd kind,Inverting a Characteristic Function for half-cubic Student's T entailing a Modified Bessel of 2nd kind,,"The Characteristic function of the Student's T with $\alpha$ degrees of freedom,  $C(t)=\frac{2^{1-\frac{\alpha }{2}} \alpha ^{\alpha /4} \left| t\right| ^{\alpha /2}    K_{\frac{\alpha }{2}}\left(\sqrt{\alpha } \left| t\right| \right)}{\Gamma    \left(\frac{\alpha }{2}\right)}$ entails a modified Bessel function of the second kind $K_{\alpha/2}\left(\sqrt{\alpha } \left| t\right| \right)$. To invert the Fourier to get the probability density of the $n$-summed variable when $\alpha$ is not an integer poses problem as the equation below seems integrable otherwise. Of particular interest is the distribution for $\alpha= 3/2$ (""halfcubic""). With $n$ an integer ( $n >2$):   $$f_n(x)= \left(\frac{3^{3/8}}{\sqrt[8]{2} \,\Gamma \left(\frac{3}{4}\right)}\right)^n \int_{-\infty }^{\infty } e^{-i\, t x}  \left| t\right| ^{\frac{3 n}{4}} K_{\frac{3}{4}}\left(\sqrt{\frac{3}{2}} \left| t\right| \right)^n \, dt$$    I tried all manner of expansions and reexpressions of the Bessel into other functions (Hypergeometric, Gamma) to no avail. One good news is that $n=2$ works on Mathematica because the Wolfram library has the square of a Bessel function. It would be great to get the solution for at least $n=3$.","The Characteristic function of the Student's T with $\alpha$ degrees of freedom,  $C(t)=\frac{2^{1-\frac{\alpha }{2}} \alpha ^{\alpha /4} \left| t\right| ^{\alpha /2}    K_{\frac{\alpha }{2}}\left(\sqrt{\alpha } \left| t\right| \right)}{\Gamma    \left(\frac{\alpha }{2}\right)}$ entails a modified Bessel function of the second kind $K_{\alpha/2}\left(\sqrt{\alpha } \left| t\right| \right)$. To invert the Fourier to get the probability density of the $n$-summed variable when $\alpha$ is not an integer poses problem as the equation below seems integrable otherwise. Of particular interest is the distribution for $\alpha= 3/2$ (""halfcubic""). With $n$ an integer ( $n >2$):   $$f_n(x)= \left(\frac{3^{3/8}}{\sqrt[8]{2} \,\Gamma \left(\frac{3}{4}\right)}\right)^n \int_{-\infty }^{\infty } e^{-i\, t x}  \left| t\right| ^{\frac{3 n}{4}} K_{\frac{3}{4}}\left(\sqrt{\frac{3}{2}} \left| t\right| \right)^n \, dt$$    I tried all manner of expansions and reexpressions of the Bessel into other functions (Hypergeometric, Gamma) to no avail. One good news is that $n=2$ works on Mathematica because the Wolfram library has the square of a Bessel function. It would be great to get the solution for at least $n=3$.",,"['integration', 'complex-analysis', 'analysis', 'probability-theory', 'probability-distributions']"
88,What is an example of a function that is measurable but not strongly measurable?,What is an example of a function that is measurable but not strongly measurable?,,"Let $(\Omega, \Sigma)$ be a measurable space and $X$ a Banach space. Let $f: \Omega \rightarrow X$. $f$ is called measurable if every the preimage of every Borel set in $X$ is an element of $\Sigma$. $f$ is called strongly measurable if $f$ is the pointwise limit of a sequence of simple functions. It is known that strongly measurable and measurable are equivalent when $X$ is separable. For this reason, the notion of strong measurability is only relevant when dealing with Bochner integration in full generality. What is an example of a function $f$ taking values in a non-separable Banach space $X$ such that $f$ is measurable but not strongly measurable?","Let $(\Omega, \Sigma)$ be a measurable space and $X$ a Banach space. Let $f: \Omega \rightarrow X$. $f$ is called measurable if every the preimage of every Borel set in $X$ is an element of $\Sigma$. $f$ is called strongly measurable if $f$ is the pointwise limit of a sequence of simple functions. It is known that strongly measurable and measurable are equivalent when $X$ is separable. For this reason, the notion of strong measurability is only relevant when dealing with Bochner integration in full generality. What is an example of a function $f$ taking values in a non-separable Banach space $X$ such that $f$ is measurable but not strongly measurable?",,"['integration', 'functional-analysis', 'measure-theory', 'examples-counterexamples']"
89,"How to find this integral $\int_{0}^{1}\ln\ln\bigl(1/x+\sqrt{(1/x^2)-1}\,\bigr)dx$ [duplicate]",How to find this integral  [duplicate],"\int_{0}^{1}\ln\ln\bigl(1/x+\sqrt{(1/x^2)-1}\,\bigr)dx",This question already has answers here : Closed form for $\int_0^1\log\log\left(\frac{1}{x}+\sqrt{\frac{1}{x^2}-1}\right)\mathrm dx$ (5 answers) Closed 9 years ago . How do I compute this integral ? $$I=\int_{0}^{1}\ln{\left(\ln{\left(\frac{1}{x}+\sqrt{\frac{1}{x^2}-1}\right)}\right)}dx$$ In the math chatroom someone suggests setting $x=\operatorname{sech}(t)$ and that the result immediately follows. I don't agree with it because $$\frac{1}{x}+\sqrt{\frac{1}{x^2}-1}=\frac{e^t+e^{-t}}{2}+\sqrt{\cosh^2{t}-1}=e^t$$ and $$dx=\frac{e^t}{(e^{2t}+1)^2}dt$$ so $$I=\int_{0}^{\infty}\ln(t)\frac{e^{t}}{(e^{2t}+1)^2}dt$$ Thanks for your help.,This question already has answers here : Closed form for $\int_0^1\log\log\left(\frac{1}{x}+\sqrt{\frac{1}{x^2}-1}\right)\mathrm dx$ (5 answers) Closed 9 years ago . How do I compute this integral ? In the math chatroom someone suggests setting and that the result immediately follows. I don't agree with it because and so Thanks for your help.,I=\int_{0}^{1}\ln{\left(\ln{\left(\frac{1}{x}+\sqrt{\frac{1}{x^2}-1}\right)}\right)}dx x=\operatorname{sech}(t) \frac{1}{x}+\sqrt{\frac{1}{x^2}-1}=\frac{e^t+e^{-t}}{2}+\sqrt{\cosh^2{t}-1}=e^t dx=\frac{e^t}{(e^{2t}+1)^2}dt I=\int_{0}^{\infty}\ln(t)\frac{e^{t}}{(e^{2t}+1)^2}dt,['integration']
90,"integral involving hypergeometric function $\int^1_0\frac{_2F_1(p,p;p+1;-\frac{1}{y})}{y}\,dy$",integral involving hypergeometric function,"\int^1_0\frac{_2F_1(p,p;p+1;-\frac{1}{y})}{y}\,dy","I arrived at the following result $$\tag{1}\int^\infty_0 z^{p-1} E^2(z)\,dz=\frac{\Gamma(p)}{p}\int^1_0\frac{_2F_1(p,p;p+1;-\frac{1}{z})}{z}\,dz$$ where the exponential integral $E(z)$ is defined as $$E(z)=\int^\infty_z \frac{e^{-t}}{t}\,dt$$ I have two questions [1] Does (1)  hold for all $p>0$ ? [2] Is there a way to simplify or solve the integral on the right ?","I arrived at the following result $$\tag{1}\int^\infty_0 z^{p-1} E^2(z)\,dz=\frac{\Gamma(p)}{p}\int^1_0\frac{_2F_1(p,p;p+1;-\frac{1}{z})}{z}\,dz$$ where the exponential integral $E(z)$ is defined as $$E(z)=\int^\infty_z \frac{e^{-t}}{t}\,dt$$ I have two questions [1] Does (1)  hold for all $p>0$ ? [2] Is there a way to simplify or solve the integral on the right ?",,"['integration', 'definite-integrals', 'special-functions', 'improper-integrals']"
91,"integrals of vector fields that yield vectors, not scalars","integrals of vector fields that yield vectors, not scalars",,"When I tried to think of how I'd answer this question , I realized that never in my undergraduate curriculum was I asked to compute the surface or line integral of a vector field. I don't mean I've never been asked to compute the flux or circulation of a field (meaning the field dotted with the surface normal, in the case of a surface integral, or the field dotted with a tangent vector, in the case of a line integral). I mean I've never been asked to compute things like $$\int_Sfd\mathbf{S}, \int_S \mathbf{f}dS, \int_c\mathbf{f}\times d\mathbf{r}$$ (where vectors are bolded and scalars aren't). I have two questions: In what contexts do such integrals -- integrals of vector fields that yield a vector rather than a scalar -- arise? Why are integrals like these pretty much never encountered in a standard course in undergraduate vector calculus? (I cannot think of a textbook where I could find them. If you can, please mention it.) NOTE: I'm not asking how to do these integrals; I realize you can just compute them component-wise.","When I tried to think of how I'd answer this question , I realized that never in my undergraduate curriculum was I asked to compute the surface or line integral of a vector field. I don't mean I've never been asked to compute the flux or circulation of a field (meaning the field dotted with the surface normal, in the case of a surface integral, or the field dotted with a tangent vector, in the case of a line integral). I mean I've never been asked to compute things like $$\int_Sfd\mathbf{S}, \int_S \mathbf{f}dS, \int_c\mathbf{f}\times d\mathbf{r}$$ (where vectors are bolded and scalars aren't). I have two questions: In what contexts do such integrals -- integrals of vector fields that yield a vector rather than a scalar -- arise? Why are integrals like these pretty much never encountered in a standard course in undergraduate vector calculus? (I cannot think of a textbook where I could find them. If you can, please mention it.) NOTE: I'm not asking how to do these integrals; I realize you can just compute them component-wise.",,"['integration', 'multivariable-calculus', 'vector-analysis']"
92,Calculus integration problem. [HW help],Calculus integration problem. [HW help],,Can someone please help me solve the following calculus problem for my homework?,Can someone please help me solve the following calculus problem for my homework?,,['integration']
93,Dirac Delta Constraint Question,Dirac Delta Constraint Question,,"Given an integral of the form \begin{equation}\int d\bar z\, dz\, \delta (\bar z \cdot A \cdot z-b)\,f(\bar z,z)\end{equation} Where $z$ is a complex $n$ dimensional vector, and $A$ is an arbitrary, possibly complex matrix, how would you sort out the delta function so that it provides a constraint over each variable $z_{i}$ and $\bar z_{i}$ rather than a general constraint on the inner product?  I guess it amounts to using a property analogous to $\delta(g(x))=\sum_{i}\frac{\delta (x-x_{i})}{|g'(x_{i})|}$ but I'm still unsure how to formalize that. Any thoughts?","Given an integral of the form \begin{equation}\int d\bar z\, dz\, \delta (\bar z \cdot A \cdot z-b)\,f(\bar z,z)\end{equation} Where $z$ is a complex $n$ dimensional vector, and $A$ is an arbitrary, possibly complex matrix, how would you sort out the delta function so that it provides a constraint over each variable $z_{i}$ and $\bar z_{i}$ rather than a general constraint on the inner product?  I guess it amounts to using a property analogous to $\delta(g(x))=\sum_{i}\frac{\delta (x-x_{i})}{|g'(x_{i})|}$ but I'm still unsure how to formalize that. Any thoughts?",,['integration']
94,"Why substitution method does not work for $\int (x-\frac{1}{2x} )^2\, \mathrm dx$?",Why substitution method does not work for ?,"\int (x-\frac{1}{2x} )^2\, \mathrm dx","Why $$\int \ \left(x-\frac{1}{2x} \right)^2 \, \mathrm  dx$$ is easy to integrate once $$\left(x-\frac{1}{2x} \right)^2$$ is expanded, but impossible using substitution method? (tried 5 different subs but of course that is not the proof that there is no suitable substitution) if mathematical results are independent of the logical methods used to derive them, why something so simple works one way but not the other?","Why $$\int \ \left(x-\frac{1}{2x} \right)^2 \, \mathrm  dx$$ is easy to integrate once $$\left(x-\frac{1}{2x} \right)^2$$ is expanded, but impossible using substitution method? (tried 5 different subs but of course that is not the proof that there is no suitable substitution) if mathematical results are independent of the logical methods used to derive them, why something so simple works one way but not the other?",,"['integration', 'problem-solving']"
95,Integrating the exponential $\exp\left(-{(x-a)^2\over 2a}\right)$,Integrating the exponential,\exp\left(-{(x-a)^2\over 2a}\right),"How can I show that  $$\int_0^\infty\exp\left(-{(x-a)^2\over 2a}\right)dx$$  can be approximated by $$\sqrt{2\pi a} \,\,\,e^{-a}$$ when $a\to \infty$? It looks suspiciously similar to $$e^{-a}\int_{-\infty}^\infty \exp\left(-{t^2\over 2a}\right)dt$$ (given the result) but I can't see how to convert the integral to this form, esp the limits seem a bit problematic... Please help, thanks.","How can I show that  $$\int_0^\infty\exp\left(-{(x-a)^2\over 2a}\right)dx$$  can be approximated by $$\sqrt{2\pi a} \,\,\,e^{-a}$$ when $a\to \infty$? It looks suspiciously similar to $$e^{-a}\int_{-\infty}^\infty \exp\left(-{t^2\over 2a}\right)dt$$ (given the result) but I can't see how to convert the integral to this form, esp the limits seem a bit problematic... Please help, thanks.",,"['integration', 'exponential-function']"
96,Simplifiying sum through integral? [duplicate],Simplifiying sum through integral? [duplicate],,"This question already has answers here : Sum with binomial coefficients: $\sum_{k=1}^m  \frac{1}{k}{m \choose k} $ (7 answers) Closed 4 years ago . I wanted to compute the sum $$\sum_{k=1}^{n}\frac{1}{k}\binom{n}{k}.$$ And I thought it would be easiest to do this by making it a function, differentiating it and integrating it then. So I did: $$f_n(a)=\sum_{k=1}^{n}\frac{1}{k}\binom{n}{k}a^k$$ $$f_n'(a)=\sum_{k=1}^{n}\binom{n}{k}a^{k-1}=\frac{(a+1)^n-1}{a}$$ And finally $$f_n(a)=\int\frac{(a+1)^n-1}{a}\mathrm{d}a+C(n)$$ where $C(n)$ is an unknown constant depending on $n$. The first problem is the integral of course, so here it stops. Can anyone help me calculating this integral or is there another way to calculate the sum? EDIT: another approach: I get, using Pascal's identity, $$S(n)=\sum_{k=1}^{n}\frac{1}{k}\binom{n}{k}=\frac{1}{n}+\sum_{k=1}^{n-1}\left(\frac{1}{k}\binom{n-1}{k-1}+\frac{1}{k}\binom{n-1}{k}\right)=\sum_{k=1}^{n}\frac{1}{n}\binom{n}{k}+\sum_{k=1}^{n-1}\frac{1}{k}\binom{n-1}{k}$$ So I have the recursion $S(n)=\frac{2^n-1}{n}+S(n-1)$, with $S(1)=\frac{2^1-1}{1}$. Thus $$\sum_{k=1}^{n}\frac{1}{k}\binom{n}{k}=\sum_{k=1}^{n}\frac{2^k-1}{k}$$ if that might help. Also, $f_n(a)=\displaystyle\sum_{k=1}^{n}\frac{(a+1)^k-1}{k}$ for the same reason.","This question already has answers here : Sum with binomial coefficients: $\sum_{k=1}^m  \frac{1}{k}{m \choose k} $ (7 answers) Closed 4 years ago . I wanted to compute the sum $$\sum_{k=1}^{n}\frac{1}{k}\binom{n}{k}.$$ And I thought it would be easiest to do this by making it a function, differentiating it and integrating it then. So I did: $$f_n(a)=\sum_{k=1}^{n}\frac{1}{k}\binom{n}{k}a^k$$ $$f_n'(a)=\sum_{k=1}^{n}\binom{n}{k}a^{k-1}=\frac{(a+1)^n-1}{a}$$ And finally $$f_n(a)=\int\frac{(a+1)^n-1}{a}\mathrm{d}a+C(n)$$ where $C(n)$ is an unknown constant depending on $n$. The first problem is the integral of course, so here it stops. Can anyone help me calculating this integral or is there another way to calculate the sum? EDIT: another approach: I get, using Pascal's identity, $$S(n)=\sum_{k=1}^{n}\frac{1}{k}\binom{n}{k}=\frac{1}{n}+\sum_{k=1}^{n-1}\left(\frac{1}{k}\binom{n-1}{k-1}+\frac{1}{k}\binom{n-1}{k}\right)=\sum_{k=1}^{n}\frac{1}{n}\binom{n}{k}+\sum_{k=1}^{n-1}\frac{1}{k}\binom{n-1}{k}$$ So I have the recursion $S(n)=\frac{2^n-1}{n}+S(n-1)$, with $S(1)=\frac{2^1-1}{1}$. Thus $$\sum_{k=1}^{n}\frac{1}{k}\binom{n}{k}=\sum_{k=1}^{n}\frac{2^k-1}{k}$$ if that might help. Also, $f_n(a)=\displaystyle\sum_{k=1}^{n}\frac{(a+1)^k-1}{k}$ for the same reason.",,"['integration', 'binomial-coefficients', 'summation']"
97,"How do I express $\int_0^t \frac{{\rm e}^{-a^2 z}}{\sqrt{z} (z+v)} \,dz$ in terms of named functions?",How do I express  in terms of named functions?,"\int_0^t \frac{{\rm e}^{-a^2 z}}{\sqrt{z} (z+v)} \,dz","Recently I derived an expression for a particular probability density function. The expression contains the integral $$ f(t,v,a) = \int_0^t \frac{{\rm e}^{-a^2 z}}{\sqrt{z} (z+v)} \,dz = 2a \int_0^{a\sqrt{t}} \frac{{\rm e}^{-x^2}}{x^2+a^2 v} \,dx \;, $$ where $t>0$, $v>0$ and $a \in \mathbb{R}$, and I would like to rewrite it in terms of named functions (such as error functions and exponential integrals). It seems innocuous but I've tried every integral substitution I can think of without success. The Wolfram Mathematica Online Integrator didn't help, nor did Abramowitz & Stegun's well-known book. I was about to give up when I stumbled upon the NIST Digital Library of Mathematical Functions, and in particular the page http://dlmf.nist.gov/7.7 where it is said ``Integrals of the type $\int {\rm e}^{-z^2} R(z) \,dz$, where $R(z)$ is an arbitrary rational function, can be written in closed form in terms of the error functions and elementary functions.'' Okay, how do I do this? Two final comments: Differentiation under the integral sign led me to $$ f(t,v,a) = \frac{\pi}{\sqrt{v}} {\rm e}^{a^2 v} {\rm erfc} \left( a \sqrt{v} \right) - \frac{4}{\sqrt{v}} {\rm e}^{a^2 v} \int_{a\sqrt{v}}^\infty \int_{\frac{\sqrt{t} q}{\sqrt{v}}}^\infty {\rm e}^{-p^2} {\rm e}^{-q^2} \,dp \,dq \;, $$ but this doesn't seem to be helpful. I can evaluate the integral in the special case $t=v$: $$ f(v,v,a) = \frac{\pi}{2 \sqrt{v}} {\rm e}^{a^2 v} \left( 1 - \left( {\rm erf} \left( a \sqrt{v} \right) \right)^2 \right) \;, $$ but this also doesn't seem helpful.","Recently I derived an expression for a particular probability density function. The expression contains the integral $$ f(t,v,a) = \int_0^t \frac{{\rm e}^{-a^2 z}}{\sqrt{z} (z+v)} \,dz = 2a \int_0^{a\sqrt{t}} \frac{{\rm e}^{-x^2}}{x^2+a^2 v} \,dx \;, $$ where $t>0$, $v>0$ and $a \in \mathbb{R}$, and I would like to rewrite it in terms of named functions (such as error functions and exponential integrals). It seems innocuous but I've tried every integral substitution I can think of without success. The Wolfram Mathematica Online Integrator didn't help, nor did Abramowitz & Stegun's well-known book. I was about to give up when I stumbled upon the NIST Digital Library of Mathematical Functions, and in particular the page http://dlmf.nist.gov/7.7 where it is said ``Integrals of the type $\int {\rm e}^{-z^2} R(z) \,dz$, where $R(z)$ is an arbitrary rational function, can be written in closed form in terms of the error functions and elementary functions.'' Okay, how do I do this? Two final comments: Differentiation under the integral sign led me to $$ f(t,v,a) = \frac{\pi}{\sqrt{v}} {\rm e}^{a^2 v} {\rm erfc} \left( a \sqrt{v} \right) - \frac{4}{\sqrt{v}} {\rm e}^{a^2 v} \int_{a\sqrt{v}}^\infty \int_{\frac{\sqrt{t} q}{\sqrt{v}}}^\infty {\rm e}^{-p^2} {\rm e}^{-q^2} \,dp \,dq \;, $$ but this doesn't seem to be helpful. I can evaluate the integral in the special case $t=v$: $$ f(v,v,a) = \frac{\pi}{2 \sqrt{v}} {\rm e}^{a^2 v} \left( 1 - \left( {\rm erf} \left( a \sqrt{v} \right) \right)^2 \right) \;, $$ but this also doesn't seem helpful.",,"['integration', 'definite-integrals', 'special-functions', 'improper-integrals']"
98,How would one integrate over $SO(n)$?,How would one integrate over ?,SO(n),"Suppose you want to find the average of an $n\times n$ diagonal matrix $A$ over all possible rotations, $$ \langle A\rangle = \int\limits_\text{SO($n$)} Q^T A Q \; dQ. $$ It's easy enough to do this for $n=2$ because you have only one degree of freedom. I suspect that $n=3$ would be ""simple"", but tedious. Using Monte-Carlo, I conjecture that $\langle A\rangle = \text{diag}\left[\text{tr}(A)/n \right]$ . But I'm curious if there's a way that you could derive this relation analytically for a general $n$ . I suspect that you could make some symmetry arguments to take the problem of an integral over $\text{SO}(n)$ to a sum over permutation matrices. Why take $A$ to be diagonal? Because really I'm interested in $A$ being positive-definite, and when that's the case, you can just diagonalize it and then rotate into the principal coordinate-frame.","Suppose you want to find the average of an diagonal matrix over all possible rotations, It's easy enough to do this for because you have only one degree of freedom. I suspect that would be ""simple"", but tedious. Using Monte-Carlo, I conjecture that . But I'm curious if there's a way that you could derive this relation analytically for a general . I suspect that you could make some symmetry arguments to take the problem of an integral over to a sum over permutation matrices. Why take to be diagonal? Because really I'm interested in being positive-definite, and when that's the case, you can just diagonalize it and then rotate into the principal coordinate-frame.","n\times n A 
\langle A\rangle = \int\limits_\text{SO(n)} Q^T A Q \; dQ.
 n=2 n=3 \langle A\rangle = \text{diag}\left[\text{tr}(A)/n \right] n \text{SO}(n) A A","['integration', 'group-theory', 'measure-theory', 'orthogonal-matrices', 'monte-carlo']"
99,Why is none trying to find the value of $\displaystyle\sum_{n=1}^\infty\frac1{n^n}$?,Why is none trying to find the value of ?,\displaystyle\sum_{n=1}^\infty\frac1{n^n},"I wish to know the exact value of $$\sum_{n=1}^\infty\frac1{n^n}.$$ I've found on the internet some mentions of the equality (the Sophomore's Dream , as I've learned) $$\sum_{n=1}^\infty\frac1{n^n} = \int_0^1\frac1{x^x}dx.$$ Wolfram Alpha's computations returns the value of $1.29128599706266\dots$ to the RHS integral. However, it says no result found in terms of standard mathematical functions for $$\int\frac1{x^x}dx$$ so the equality does not yield a definitive answer. I am aware there might be no better way to describe this constant value, and it could just be given its own name, such as the Euler–Mascheroni constant. Wondering if that was the case I've searched for its first few digits and was led to the Sophomore's Dream and then to this and this related questions, none of which relieved my curiosity. All I've learned was that it was not even known if this constant is a rational number. I apologize for the nature of my question, which is utterly meta, but I just cannot help myself to wonder: Is this problem uninteresting? Why were so many mathematicians mobilized to solve the Basel Problem but so little is talked about this (surely just as pretty) series? Is this somehow a much harder question? Why? Also, I'm guessing if this value had a name someone would have mentioned it by now, so I'm calling it Bernoulli's Constant (not Sophomore's Constant since there are two equations in the Sophomore's Dream). The digit sequence is A073009 on OEIS, as pointed out in a comment.","I wish to know the exact value of I've found on the internet some mentions of the equality (the Sophomore's Dream , as I've learned) Wolfram Alpha's computations returns the value of to the RHS integral. However, it says no result found in terms of standard mathematical functions for so the equality does not yield a definitive answer. I am aware there might be no better way to describe this constant value, and it could just be given its own name, such as the Euler–Mascheroni constant. Wondering if that was the case I've searched for its first few digits and was led to the Sophomore's Dream and then to this and this related questions, none of which relieved my curiosity. All I've learned was that it was not even known if this constant is a rational number. I apologize for the nature of my question, which is utterly meta, but I just cannot help myself to wonder: Is this problem uninteresting? Why were so many mathematicians mobilized to solve the Basel Problem but so little is talked about this (surely just as pretty) series? Is this somehow a much harder question? Why? Also, I'm guessing if this value had a name someone would have mentioned it by now, so I'm calling it Bernoulli's Constant (not Sophomore's Constant since there are two equations in the Sophomore's Dream). The digit sequence is A073009 on OEIS, as pointed out in a comment.",\sum_{n=1}^\infty\frac1{n^n}. \sum_{n=1}^\infty\frac1{n^n} = \int_0^1\frac1{x^x}dx. 1.29128599706266\dots \int\frac1{x^x}dx,"['integration', 'sequences-and-series', 'soft-question', 'closed-form', 'math-history']"
