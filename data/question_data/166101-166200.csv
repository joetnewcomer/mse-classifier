,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Deriving Moment Generating Function of the Negative Binomial?,Deriving Moment Generating Function of the Negative Binomial?,,"My textbook did the derivation for the binomial distribution, but omitted the derivations for the Negative Binomial Distribution. I know it is supposed to be similar to the Geometric, but it is not only limited to one success/failure. (i.e the way I understand it is that the negative binomial is the sum of independent geometric random variables). For example: $Y_1 +Y_2 +Y_3+\cdots $ where $Y_i$ is a geometric parameter. I can't seem to find online one for the negative binomial and am having trouble with even doing the geometric. Can anyone show me a derivation of the negative binomial? Edit: My book calls the negative binomial as the distribution of the number of trials needed to get a specified number r of successes.","My textbook did the derivation for the binomial distribution, but omitted the derivations for the Negative Binomial Distribution. I know it is supposed to be similar to the Geometric, but it is not only limited to one success/failure. (i.e the way I understand it is that the negative binomial is the sum of independent geometric random variables). For example: $Y_1 +Y_2 +Y_3+\cdots $ where $Y_i$ is a geometric parameter. I can't seem to find online one for the negative binomial and am having trouble with even doing the geometric. Can anyone show me a derivation of the negative binomial? Edit: My book calls the negative binomial as the distribution of the number of trials needed to get a specified number r of successes.",,"['statistics', 'probability-distributions', 'moment-generating-functions']"
1,"Maximum likelihood estimation of $a,b$ for a uniform distribution on $[a,b]$",Maximum likelihood estimation of  for a uniform distribution on,"a,b [a,b]","I'm supposed to calculate the MLE's for $a$ and $b$ from a random sample of $(X_1,...,X_n)$ drawn from a uniform distribution on $[a,b]$. But the likelihood function, $\mathcal{L}(a,b)=\frac{1}{(b-a)^n}$ is constant, how do I find a maximum? Would appreciate tips on how to proceed!","I'm supposed to calculate the MLE's for $a$ and $b$ from a random sample of $(X_1,...,X_n)$ drawn from a uniform distribution on $[a,b]$. But the likelihood function, $\mathcal{L}(a,b)=\frac{1}{(b-a)^n}$ is constant, how do I find a maximum? Would appreciate tips on how to proceed!",,"['statistics', 'uniform-distribution', 'maximum-likelihood', 'parameter-estimation']"
2,Coronavirus growth rate and its (possibly spurious) resemblance to the vapor pressure model,Coronavirus growth rate and its (possibly spurious) resemblance to the vapor pressure model,,"The objective is the model the growth rate of the Coronavirus using avaibale data. As opposed to the standard epidemiology models such as SIR and SEIR , I tried to model a direct relation between the number of infected or deaths as a function of time so as to capture the early days trends. I collected the latest data on the coronavirus from Johns Hopkins University as shown and fitted different curves to this data to model the relationship between the number of confirmed patients $P$ who are/were infected as function of time $T$ taking 20-Jan-20 as day 1. The curve fitting software I used has well known models form different branches of science as well as we could build our own custom models which I did as shown in the image below. The score against the name of a model gives how well a model fits this data. The higher the score, the better the fit and the maximum possible score is 1000. Although we have data only for 18 days (as of 7-Feb 2 AM GMT) one model always kept appearing at top as the best fit and this was the vapor pressure model. After checking for various boundary conditions, I rejected many of models but I could not find any immediately reason to reject the vapor pressure model. Similarly when I modeled the number of reported deaths against time, the vapor pressure model once again gave the best fit which for which I could not find any obvious reasons to reject. So I did some research on the vapor pressure model. Basic concept of vapor pressure Because the molecules of a liquid $L$ are in constant motion and possess kinetic energies, at any moment some fraction of them has enough energy to escape from the surface of the liquid to enter the gas phase. This process, called evaporation, generates a vapor pressure $P_L$ above the liquid. Molecules in the gas phase can collide with the liquid surface and reenter the liquid via condensation. Eventually, a steady state is reached in which the number of molecules evaporating and condensing per unit time is the same, and the system is in a state of dynamic equilibrium. Under these conditions, a liquid exhibits a characteristic equilibrium vapor pressure that depends only on the temperature $T_L$ . Volatile liquids are liquids with high vapor pressures, which tend to evaporate readily from an open container; nonvolatile liquids have low vapor pressures. When the vapor pressure equals the external pressure, bubbles of vapor form within the liquid, and it boils. We can express the nonlinear relationship between vapor pressure and temperature as an almost linear relationship using the Antoine equation . $$ P_L = exp\Big(a + \frac{b}{T_L} + c\log T_L\Big) $$ Next I did some research what is known about how the coronavirus spreads and if it is related to liquids. Here is what I found. How coronavirus spreads : When an infected person coughs or sneezes, they shed droplets of saliva, mucus, or other bodily fluids. If any of those droplets fall on you—or if you touch them and then, say, touch your face—you can become infected as well. Hospital for communicable diseases define exposure as being within six feet of an infected person for 10 minutes or longer. Time and distance matters. The coronavirus spreads when it escapes from an infected person through microscopic droplets of liquid carrying the virus through air. I wonder this has anything to do with why the vapor pressure model keeps coming on the top as the best fit even though there is no apparent pressure or temperature as in the vapor pressure equation and I cannot see how they could be elated. May be all this just a mere coincidence . As a bad scientist but a concerned human, I thought I must report this   observation in case there is anything worth in it. Question : My objective was mainly for reporting this given the seriousness of the situation. But since the community rules mandates a question, it I will ask one. Given this limited data what can we infer about the corona virus and how can we reject the vapor pressure model as a mere coincidence. Note 1 : I will be posting this in the Physics community where it is more relevant. But with 638 deaths in the last two weeks, I have posted it in MSE just in case someone else might find it useful. Note 2 : I am well aware of spurious correlation. But with only 3 weeks of data, we many not be able to detect a different trend this early. Hence I am reporting the best fit regardless.","The objective is the model the growth rate of the Coronavirus using avaibale data. As opposed to the standard epidemiology models such as SIR and SEIR , I tried to model a direct relation between the number of infected or deaths as a function of time so as to capture the early days trends. I collected the latest data on the coronavirus from Johns Hopkins University as shown and fitted different curves to this data to model the relationship between the number of confirmed patients who are/were infected as function of time taking 20-Jan-20 as day 1. The curve fitting software I used has well known models form different branches of science as well as we could build our own custom models which I did as shown in the image below. The score against the name of a model gives how well a model fits this data. The higher the score, the better the fit and the maximum possible score is 1000. Although we have data only for 18 days (as of 7-Feb 2 AM GMT) one model always kept appearing at top as the best fit and this was the vapor pressure model. After checking for various boundary conditions, I rejected many of models but I could not find any immediately reason to reject the vapor pressure model. Similarly when I modeled the number of reported deaths against time, the vapor pressure model once again gave the best fit which for which I could not find any obvious reasons to reject. So I did some research on the vapor pressure model. Basic concept of vapor pressure Because the molecules of a liquid are in constant motion and possess kinetic energies, at any moment some fraction of them has enough energy to escape from the surface of the liquid to enter the gas phase. This process, called evaporation, generates a vapor pressure above the liquid. Molecules in the gas phase can collide with the liquid surface and reenter the liquid via condensation. Eventually, a steady state is reached in which the number of molecules evaporating and condensing per unit time is the same, and the system is in a state of dynamic equilibrium. Under these conditions, a liquid exhibits a characteristic equilibrium vapor pressure that depends only on the temperature . Volatile liquids are liquids with high vapor pressures, which tend to evaporate readily from an open container; nonvolatile liquids have low vapor pressures. When the vapor pressure equals the external pressure, bubbles of vapor form within the liquid, and it boils. We can express the nonlinear relationship between vapor pressure and temperature as an almost linear relationship using the Antoine equation . Next I did some research what is known about how the coronavirus spreads and if it is related to liquids. Here is what I found. How coronavirus spreads : When an infected person coughs or sneezes, they shed droplets of saliva, mucus, or other bodily fluids. If any of those droplets fall on you—or if you touch them and then, say, touch your face—you can become infected as well. Hospital for communicable diseases define exposure as being within six feet of an infected person for 10 minutes or longer. Time and distance matters. The coronavirus spreads when it escapes from an infected person through microscopic droplets of liquid carrying the virus through air. I wonder this has anything to do with why the vapor pressure model keeps coming on the top as the best fit even though there is no apparent pressure or temperature as in the vapor pressure equation and I cannot see how they could be elated. May be all this just a mere coincidence . As a bad scientist but a concerned human, I thought I must report this   observation in case there is anything worth in it. Question : My objective was mainly for reporting this given the seriousness of the situation. But since the community rules mandates a question, it I will ask one. Given this limited data what can we infer about the corona virus and how can we reject the vapor pressure model as a mere coincidence. Note 1 : I will be posting this in the Physics community where it is more relevant. But with 638 deaths in the last two weeks, I have posted it in MSE just in case someone else might find it useful. Note 2 : I am well aware of spurious correlation. But with only 3 weeks of data, we many not be able to detect a different trend this early. Hence I am reporting the best fit regardless.","P T L P_L T_L 
P_L = exp\Big(a + \frac{b}{T_L} + c\log T_L\Big)
","['statistics', 'numerical-methods', 'physics', 'curves', 'mathematical-modeling']"
3,"MLE for Uniform $(0,\theta)$",MLE for Uniform,"(0,\theta)","I am a bit confused about the derivation of MLE of Uniform $(0,\theta)$ . I understand that $L(\theta)={\theta}^{-n}$ is a decreasing function and to find the MLE we want to maximize the likelihood function. What is confusing me is that if a function is decreasing, then wouldn't the function be maximized at the smallest input rather than the largest? Thank you in advance for your help.","I am a bit confused about the derivation of MLE of Uniform . I understand that is a decreasing function and to find the MLE we want to maximize the likelihood function. What is confusing me is that if a function is decreasing, then wouldn't the function be maximized at the smallest input rather than the largest? Thank you in advance for your help.","(0,\theta) L(\theta)={\theta}^{-n}","['statistics', 'uniform-distribution', 'maximum-likelihood', 'parameter-estimation']"
4,Deriving cost function using MLE :Why use log function?,Deriving cost function using MLE :Why use log function?,,"I am learning machine learning from Andrew Ng's open-class notes and coursera.org. I am trying to understand how the cost function for the logistic regression is derived. I will start with the cost function for linear regression and then get to my question with logistic regression. (Btw a similar question was asked here , which answers the question how the derivative of cost function was derived but not the cost function itself.) 1) Linear regression uses the following hypothesis: $$ h_\theta(x) = \theta_0 + \theta_1 x$$ Accordingly, the cost function is defined as: $$J(\theta) = \dfrac {1}{2m} \displaystyle \sum_{i=1}^m \left (h_\theta (x^{(i)}) - y^{(i)} \right)^2$$ - 2) The logistic regression uses a sigmoid/logistic function which is $ 0 \leq h_\theta (x) \leq 1 $. Defined as : $$ \begin{align*} & h_\theta (x) =  \dfrac{1}{1 + e^{-(\theta^T x)}} \newline \newline \end{align*} $$ Accordingly, our cost function has also changed. However, instead of plugging-in the new h(x) equation directly, we used logarithm. $$ \begin{align*} & J(\theta) = \dfrac{1}{m} \sum_{i=1}^m Cost(h_\theta(x^{(i)}),y^{(i)}) \newline & Cost(h_\theta(x),y) = -log(h_\theta(x)) \; & \text{if y = 1} \newline & Cost(h_\theta(x),y) = -log(1-h_\theta(x)) \; & \text{if y = 0} \end{align*} $$ And the new cost function is defined as: $$ J(\theta) = - \frac{1}{m} \sum_{i=1}^m [y^{(i)}\log (h_\theta (x^{(i)})) + (1 - y^{(i)})\log (1 - h_\theta(x^{(i)}))]$$ From class notes "".. the more hypothesis is off from y, the larger the cost function output. If our hypothesis is equal to y, then our cost is 0."" It's also mentioned in the class notes that  MLE (maximum-likelihood estimation) is used to derive the logs in the cost function. I can see how logs function and set penalty values until we find the right values, but I don't see how we came to choose them in the cost function.","I am learning machine learning from Andrew Ng's open-class notes and coursera.org. I am trying to understand how the cost function for the logistic regression is derived. I will start with the cost function for linear regression and then get to my question with logistic regression. (Btw a similar question was asked here , which answers the question how the derivative of cost function was derived but not the cost function itself.) 1) Linear regression uses the following hypothesis: $$ h_\theta(x) = \theta_0 + \theta_1 x$$ Accordingly, the cost function is defined as: $$J(\theta) = \dfrac {1}{2m} \displaystyle \sum_{i=1}^m \left (h_\theta (x^{(i)}) - y^{(i)} \right)^2$$ - 2) The logistic regression uses a sigmoid/logistic function which is $ 0 \leq h_\theta (x) \leq 1 $. Defined as : $$ \begin{align*} & h_\theta (x) =  \dfrac{1}{1 + e^{-(\theta^T x)}} \newline \newline \end{align*} $$ Accordingly, our cost function has also changed. However, instead of plugging-in the new h(x) equation directly, we used logarithm. $$ \begin{align*} & J(\theta) = \dfrac{1}{m} \sum_{i=1}^m Cost(h_\theta(x^{(i)}),y^{(i)}) \newline & Cost(h_\theta(x),y) = -log(h_\theta(x)) \; & \text{if y = 1} \newline & Cost(h_\theta(x),y) = -log(1-h_\theta(x)) \; & \text{if y = 0} \end{align*} $$ And the new cost function is defined as: $$ J(\theta) = - \frac{1}{m} \sum_{i=1}^m [y^{(i)}\log (h_\theta (x^{(i)})) + (1 - y^{(i)})\log (1 - h_\theta(x^{(i)}))]$$ From class notes "".. the more hypothesis is off from y, the larger the cost function output. If our hypothesis is equal to y, then our cost is 0."" It's also mentioned in the class notes that  MLE (maximum-likelihood estimation) is used to derive the logs in the cost function. I can see how logs function and set penalty values until we find the right values, but I don't see how we came to choose them in the cost function.",,"['statistics', 'logarithms', 'regression', 'machine-learning']"
5,What is continuity correction in statistics,What is continuity correction in statistics,,"Can someone please explain to me the idea behind continuity correction and when is it necessary to add or subtract $\dfrac{1}{2}$ from the desired number (how do we tell whether we need to add or subtract), how do we tell when we need to use continuity correction?","Can someone please explain to me the idea behind continuity correction and when is it necessary to add or subtract $\dfrac{1}{2}$ from the desired number (how do we tell whether we need to add or subtract), how do we tell when we need to use continuity correction?",,['statistics']
6,Finding the Moment Generating function of a Binomial Distribution,Finding the Moment Generating function of a Binomial Distribution,,"Suppose $X$ has a $\rm{Binomial}(n,p)$ distribution. Then its moment generating function is \begin{align} M(t) &= \sum_{x=0}^x e^{xt}{n \choose x}p^x(1-p)^{n-x} \\ &=\sum_{x=0}^{n} {n \choose x}(pe^t)^x(1-p)^{n-x} \\ &=(pe^t+1-p)^n \end{align} Can someone please explain how the sum is obtained from lines (2) to (3)?",Suppose has a distribution. Then its moment generating function is Can someone please explain how the sum is obtained from lines (2) to (3)?,"X \rm{Binomial}(n,p) \begin{align}
M(t)
&= \sum_{x=0}^x e^{xt}{n \choose x}p^x(1-p)^{n-x} \\
&=\sum_{x=0}^{n} {n \choose x}(pe^t)^x(1-p)^{n-x} \\
&=(pe^t+1-p)^n
\end{align}","['statistics', 'summation', 'generating-functions', 'binomial-theorem', 'moment-generating-functions']"
7,Derivation of formula for finding median for grouped data,Derivation of formula for finding median for grouped data,,I know the formula of formula for finding median for grouped data that is $$\mathrm{Median} = L_m + \left [ \frac { \frac{n}{2} - F_{m-1} }{f_m} \right ] \times c$$ and I know what all the letters stand for. But can anyone provide a derivation of this. Because I am very curious on how this comes.,I know the formula of formula for finding median for grouped data that is $$\mathrm{Median} = L_m + \left [ \frac { \frac{n}{2} - F_{m-1} }{f_m} \right ] \times c$$ and I know what all the letters stand for. But can anyone provide a derivation of this. Because I am very curious on how this comes.,,"['statistics', 'median']"
8,Proof variance of Geometric Distribution,Proof variance of Geometric Distribution,,"I have a Geometric Distribution, where the stochastic variable $X$ represents the number of failures before the first success. The distribution function is $P(X=x) = q^x p$ for $x=0,1,2,\ldots$ and $q = 1-p$. Now, I know the definition of the expected value is: $E[X] = \sum_{i}{x_i p_i}$ So, I proved the expected value of the Geometric Distribution like this: $E[X]=\sum _{ i=0 }^{ \infty  }{ iP(X=i) } = \sum _{i=0}^{\infty}{i q^i p} = p\sum _{i=0}^{\infty}{i q^i} = pq \sum _{i=0}^{\infty}{iq^{i-1}}$ $\qquad = pq \sum _{i=0}^{\infty}{\frac{d}{dq}q^i} = pq \frac{d}{dq}(\sum _{i=0}^{\infty}{q^i}) = pq \frac{d}{dq}(\frac{1}{1-q})$ $\qquad = pq \frac{1}{(1-q)^2} = \frac{pq}{p^2} = \frac{q}{p}$ So now, I would like to prove that $Var[X] = \frac{q}{p^2}$. I know I have to use a simular trick as above (with the derivation). $Var[X] = E[X^2] - E[X]^2 = \sum _{i=0}^{\infty}{i^2 q^i p} - (\frac{q}{p})^2 = p \sum _{i=0}^{\infty}{i^2 q^i} - (\frac{q}{p})^2 = pq \sum _{i=0}^{\infty}{i^2 q^{i-1}} - (\frac{q}{p})^2$ $\qquad = pq \sum _{i=0}^{\infty}{\frac{d}{dq}i q^i} - (\frac{q}{p})^2 = pq \frac{d}{dq} \sum _{i=0}^{\infty}{iq^i}-(\frac{q}{p})^2$ Then I'm stuck. How can I get another $q$ out of the sum? Won't it mess up the first derivation?","I have a Geometric Distribution, where the stochastic variable $X$ represents the number of failures before the first success. The distribution function is $P(X=x) = q^x p$ for $x=0,1,2,\ldots$ and $q = 1-p$. Now, I know the definition of the expected value is: $E[X] = \sum_{i}{x_i p_i}$ So, I proved the expected value of the Geometric Distribution like this: $E[X]=\sum _{ i=0 }^{ \infty  }{ iP(X=i) } = \sum _{i=0}^{\infty}{i q^i p} = p\sum _{i=0}^{\infty}{i q^i} = pq \sum _{i=0}^{\infty}{iq^{i-1}}$ $\qquad = pq \sum _{i=0}^{\infty}{\frac{d}{dq}q^i} = pq \frac{d}{dq}(\sum _{i=0}^{\infty}{q^i}) = pq \frac{d}{dq}(\frac{1}{1-q})$ $\qquad = pq \frac{1}{(1-q)^2} = \frac{pq}{p^2} = \frac{q}{p}$ So now, I would like to prove that $Var[X] = \frac{q}{p^2}$. I know I have to use a simular trick as above (with the derivation). $Var[X] = E[X^2] - E[X]^2 = \sum _{i=0}^{\infty}{i^2 q^i p} - (\frac{q}{p})^2 = p \sum _{i=0}^{\infty}{i^2 q^i} - (\frac{q}{p})^2 = pq \sum _{i=0}^{\infty}{i^2 q^{i-1}} - (\frac{q}{p})^2$ $\qquad = pq \sum _{i=0}^{\infty}{\frac{d}{dq}i q^i} - (\frac{q}{p})^2 = pq \frac{d}{dq} \sum _{i=0}^{\infty}{iq^i}-(\frac{q}{p})^2$ Then I'm stuck. How can I get another $q$ out of the sum? Won't it mess up the first derivation?",,"['statistics', 'proof-writing']"
9,Prove variance in Uniform distribution (continuous),Prove variance in Uniform distribution (continuous),,"I read in wikipedia article , variance is $\frac{1}{12}(b-a)^2$ , can anyone prove or show how can I derive this?","I read in wikipedia article , variance is $\frac{1}{12}(b-a)^2$ , can anyone prove or show how can I derive this?",,"['statistics', 'probability-distributions', 'random-variables']"
10,"Given a data set, how do you do a sinusoidal regression on paper? What are the equations, algorithms?","Given a data set, how do you do a sinusoidal regression on paper? What are the equations, algorithms?",,"Most regressions are easy. Trivial once you know how to do it.  Most of them involve substitutions which transform the data into a linear regression.  But I have yet to figure out how to do a sinusoidal regression.  I'm looking for the concept beyond the results. I don't need Excel, TI, or CAS answers. I would like to see equations, methods, so on. How would you do it on paper if you were actually willing to do it on paper. For clarification, I'm referring to the most general sinusoidal regression $$ y = A\sin(Bx+C) + D$$ Not some special case assuming the values of one of these constants.","Most regressions are easy. Trivial once you know how to do it.  Most of them involve substitutions which transform the data into a linear regression.  But I have yet to figure out how to do a sinusoidal regression.  I'm looking for the concept beyond the results. I don't need Excel, TI, or CAS answers. I would like to see equations, methods, so on. How would you do it on paper if you were actually willing to do it on paper. For clarification, I'm referring to the most general sinusoidal regression $$ y = A\sin(Bx+C) + D$$ Not some special case assuming the values of one of these constants.",,"['statistics', 'regression']"
11,Statistics: Could someone show why this exponential pdf integrates into this particular cdf,Statistics: Could someone show why this exponential pdf integrates into this particular cdf,,"I have the following exponential distribution: $$f(\lambda, x) = \begin{cases} \lambda e^{-\lambda x} &\text{if } x \geq 0 \\ 0 & \text{if } x&lt0. \end{cases}$$ I need to show that this expression integrates into $$F(\lambda, x) = \begin{cases} 1-e^{-\lambda x} &\text{if } x \geq 0 \\ 0 & \text{if } x&lt0. \end{cases}$$ I know that the integral of a pdf is equal to one but I'm not sure how it plays out when computing for the cdf. I computed the indefinite integral of $\lambda e^{-\lambda x}$ and got $-e^{-\lambda x} + C$","I have the following exponential distribution: $$f(\lambda, x) = \begin{cases} \lambda e^{-\lambda x} &\text{if } x \geq 0 \\ 0 & \text{if } x&lt0. \end{cases}$$ I need to show that this expression integrates into $$F(\lambda, x) = \begin{cases} 1-e^{-\lambda x} &\text{if } x \geq 0 \\ 0 & \text{if } x&lt0. \end{cases}$$ I know that the integral of a pdf is equal to one but I'm not sure how it plays out when computing for the cdf. I computed the indefinite integral of $\lambda e^{-\lambda x}$ and got $-e^{-\lambda x} + C$",,['statistics']
12,Intuition about the Central Limit Theorem,Intuition about the Central Limit Theorem,,"I'm studying statistics, and would like to better understand the Central Limit Theorem. The proof I found on Wikipedia requires some previous knowledge I do not currently possess. Is there a quick intuitive explanation you can give as to why this theorem is correct?","I'm studying statistics, and would like to better understand the Central Limit Theorem. The proof I found on Wikipedia requires some previous knowledge I do not currently possess. Is there a quick intuitive explanation you can give as to why this theorem is correct?",,['statistics']
13,Vague Gamma prior?,Vague Gamma prior?,,"I'm looking at a MCMC algorithm where the author takes a Gamma(shape = 0.001, rate = 0.001) prior distribution, which they refer to as a vague prior. For all my searching, I am struggling to see how this is vague. The density seems to spread probability almost uniformly when you get away from 0, but the overwhelming amount of probability sits around 0. Does anyone understand why this is considered vague, rather than almost constant at 0?","I'm looking at a MCMC algorithm where the author takes a Gamma(shape = 0.001, rate = 0.001) prior distribution, which they refer to as a vague prior. For all my searching, I am struggling to see how this is vague. The density seems to spread probability almost uniformly when you get away from 0, but the overwhelming amount of probability sits around 0. Does anyone understand why this is considered vague, rather than almost constant at 0?",,"['statistics', 'statistical-inference']"
14,Characteristic function of the normal distribution,Characteristic function of the normal distribution,,"The standard normal distribution $$f(x) = \frac{1}{\sqrt{2\pi}} e^{\frac{-x^2}{2}},$$ has the characteristic function $$\int_{-\infty}^\infty f(x) e^{itx} dx = e^{-\frac{t^2}{2}}$$ and this can be proved by obtaining the moments. However, is there a more direct method of proving that the standard normal has the stated characteristic function?  I got stuck on trying to show that $$\int_{-\infty}^\infty e^{-\frac{1}{2}(x-it)^2} dx= \sqrt{2\pi}.$$","The standard normal distribution $$f(x) = \frac{1}{\sqrt{2\pi}} e^{\frac{-x^2}{2}},$$ has the characteristic function $$\int_{-\infty}^\infty f(x) e^{itx} dx = e^{-\frac{t^2}{2}}$$ and this can be proved by obtaining the moments. However, is there a more direct method of proving that the standard normal has the stated characteristic function?  I got stuck on trying to show that $$\int_{-\infty}^\infty e^{-\frac{1}{2}(x-it)^2} dx= \sqrt{2\pi}.$$",,"['statistics', 'fourier-analysis', 'improper-integrals', 'normal-distribution']"
15,What's the difference between Rao-Blackwell Theorem and Lehmann-Scheffé Theorem?,What's the difference between Rao-Blackwell Theorem and Lehmann-Scheffé Theorem?,,"I know that the Rao-Blackwell theorem states that an unbiased estimator given a sufficient statistic will yield the best unbiased estimator. Is the only difference between Lehmann-Scheffé and Rao-Blackwell that in Lehmann-Scheffé, you need an unbiased estimator that is based on a complete sufficient statistic? I am also having a hard time conceptually understanding the definition of a complete statistic.","I know that the Rao-Blackwell theorem states that an unbiased estimator given a sufficient statistic will yield the best unbiased estimator. Is the only difference between Lehmann-Scheffé and Rao-Blackwell that in Lehmann-Scheffé, you need an unbiased estimator that is based on a complete sufficient statistic? I am also having a hard time conceptually understanding the definition of a complete statistic.",,['statistics']
16,What is the Difference between Frequency and Density in a Histogram?,What is the Difference between Frequency and Density in a Histogram?,,"I know count is simply the amount of times the observations occur in a single bin width, but what is density?","I know count is simply the amount of times the observations occur in a single bin width, but what is density?",,['statistics']
17,Prove $SST=SSE+SSR$,Prove,SST=SSE+SSR,Prove $$SST=SSE+SSR$$ I start with $$SST= \Sigma (y_i-\bar{y})^2=...=SSE+SSR+ \Sigma 2( y_i-y_i^*)(y_i^*-\bar{y} )$$ and I don't know how to prove that  $\Sigma 2( y_i-y_i^*)(y_i^*-\bar{y} )=0$ a note on notation: the residuals $e_i$ is $e_i=y_i-y_i^*$. A more common notation is $\hat{y}$.,Prove $$SST=SSE+SSR$$ I start with $$SST= \Sigma (y_i-\bar{y})^2=...=SSE+SSR+ \Sigma 2( y_i-y_i^*)(y_i^*-\bar{y} )$$ and I don't know how to prove that  $\Sigma 2( y_i-y_i^*)(y_i^*-\bar{y} )=0$ a note on notation: the residuals $e_i$ is $e_i=y_i-y_i^*$. A more common notation is $\hat{y}$.,,"['statistics', 'regression']"
18,"Linear regression: degrees of freedom of SST, SSR, and RSS","Linear regression: degrees of freedom of SST, SSR, and RSS",,"I'm trying to understand the concept of degrees of freedom in the specific case of the three quantities involved in a linear regression solution, i.e. $SST=SSR+SSE, $ i.e. Total sum of squares = sum of squares due to regression + sum of squared errors, i.e. $\sum(y_i-\bar y)^2=\sum(\hat y_i-\bar y)^2+\sum(y_i-\hat y_i)^2$. I tried Wikipedia and thought I had understood why the first (SST) and the third (SSE) have (n-1) and (n-2) degrees of freedom respectively, but I could not make out why (SSR) has 1 degree of freedom. So maybe I did not understand degrees of freedom after all. Can someone explain? Thank you! Sources: http://en.wikipedia.org/wiki/Degrees_of_freedom_%28statistics%29 http://www.cs.rice.edu/~johnmc/comp528/lecture-notes/Lecture9.pdf","I'm trying to understand the concept of degrees of freedom in the specific case of the three quantities involved in a linear regression solution, i.e. $SST=SSR+SSE, $ i.e. Total sum of squares = sum of squares due to regression + sum of squared errors, i.e. $\sum(y_i-\bar y)^2=\sum(\hat y_i-\bar y)^2+\sum(y_i-\hat y_i)^2$. I tried Wikipedia and thought I had understood why the first (SST) and the third (SSE) have (n-1) and (n-2) degrees of freedom respectively, but I could not make out why (SSR) has 1 degree of freedom. So maybe I did not understand degrees of freedom after all. Can someone explain? Thank you! Sources: http://en.wikipedia.org/wiki/Degrees_of_freedom_%28statistics%29 http://www.cs.rice.edu/~johnmc/comp528/lecture-notes/Lecture9.pdf",,"['statistics', 'regression']"
19,Math Intuition and Natural Motivation Behind t-Student Distribution,Math Intuition and Natural Motivation Behind t-Student Distribution,,"I am trying to understand with basic mathematical background how the $t$ -Student distribution is a ""natural"" pdf to define. A more accessible explanation than this post , or the daunting Biometrika paper by RA Fisher. Background: The central limit theorem states that if ${\textstyle X_{1},X_{2},...,X_{n}}$ are each a random sample of size ${\textstyle n},$ taken from a population with mean ${\textstyle \mu }$ and finite variance ${\textstyle \sigma ^{2}}$ and if ${\textstyle {\bar {X}}}$ is the sample mean, then the limiting form of the distribution of ${\textstyle Z=\left({\frac {{\bar {X}}_{n}-\mu }{\sigma /\surd n}}\right)}$ as ${\textstyle n\to \infty },$ is the standard normal distribution. If $X_1, \ldots, X_n$ are iid random variables $\sim N(\mu,\sigma^2)$ , $$\frac{\bar{X}\,-\,\mu}{\sigma/\sqrt{n}} \sim N(0,1)$$ This is the basis of the Z-test , $Z=\frac{\bar{X}\,-\,\mu}{\sigma/\sqrt{n}}$ [ Note that the preceding opening statement is now correct after reflecting @Ian and @Michael Hardy comments to the OP in reference to the CLT. ] If the standard deviation of the population, $\sigma$ , is unknown we can replace it by the estimation based on a sample, $S$ , but then the expression ( one-sample t-test statistic ) will follow a $t$ -distribution: $$ t=\frac{\bar{X}\,-\,\mu}{S/\sqrt{n}}\sim t_{n-1}$$ with $$s=\sqrt{\frac{\sum(X_i-\bar X)^2}{n-1}}.$$ Minimal manipulations of this equation for $T$ $$\begin{align} \frac{\bar{X}\,-\,\mu}{S/\sqrt{n}} &= \frac{\bar{X}\,-\,\mu}{\frac{\sigma}{\sqrt{n}}} \frac{1}{\frac{S}{\sigma}}\\[2ex] &= Z\,\frac{1}{\frac{S}{\sigma}}\\[2ex]  &= \frac{Z}{\sqrt{\frac{\color{blue}{\sum(X_i-\bar X)^2}}{(n-1)\,\color{blue}{\sigma^2}}}}\\[2ex] &\sim\frac{Z}{\sqrt{\frac{\color{blue}{\chi_{n-1}^2}}{n-1}}}\\[2ex] &\sim t_{n-1}\small \tag 1 \end{align}$$ will introduce the chi square distribution, $(\chi^2).$ The chi square is the distribution that models $X^2$ with $X\sim N(0,1)$ : Let's say that $X \sim N(0,1)$ and that $Y=X^2$ and find the density of $Y$ by using the $\text{cdf}$ method: $$\Pr(Y \leq y) = \Pr(X^2 \leq y)= \Pr(-\sqrt{y} \leq x \leq > \sqrt{y}).$$ We cannot integrate in close form the density of the normal distribution. But we can express it: $$ F_X(y) = F_X(\sqrt{y})- F_X(-\sqrt[]{y}).$$ Taking the derivative of the cdf: $$ f_X(y)= F_X'(\sqrt{y})\,\frac{1}{\sqrt{y}}+ > F_X'(\sqrt{-y})\,\frac{1}{\sqrt{y}}.$$ Since the values of the normal $\text{pdf}$ are symmetrical: $$ f_X(y)=  F_X'(\sqrt{y})\,\frac{1}{\sqrt{y}}.$$ Equating this to the $\text{pdf}$ of the normal (now the $x$ in the $\text{pdf}$ will be $\sqrt{y}$ to be plugged into the $e^{-\frac{x^2}{2}}$ part of the normal $\text{pdf}$ ); and remembering to in include $\frac{1}{\sqrt{y}}$ at the end: $$\begin{align} f_X(y) &=   F_X'\left(\sqrt{y}\right)\,\frac{1}{\sqrt[]{y}}\\[2ex]  &=\frac{1}{\sqrt{2\pi}}\,e^{-\frac{y}{2}}\,  \frac{1}{\sqrt[]{y}}\\[2ex]  &=\frac{1}{\sqrt{2\pi}}\,e^{-\frac{y}{2}}\, y^{\frac{1}{2}- 1}  \end{align}$$ Comparing to the pdf of the chi square: $$ f_X(x)= \frac{1}{2^{\nu/2}\Gamma(\frac{\nu}{2})}e^{\frac{-x}{2}}x^{\frac{\nu}{2}-1}$$ and, since $\Gamma(1/2)=\sqrt{\pi}$ , for $\nu=1$ df, we have derived exactly the $\text{pdf}$ of the chi square. In the case of the $t$ -distribution the chi-square is suitable to model the sum of squared normals, i.e $\displaystyle \sum(X_i-\bar X)^2 $ in the set of Eq $(1),$ a well known property derived here typically with $n$ degrees of freedom, but why is it $n\,-\,1$ here, i.e. $\color{blue}{\chi^2_{n-1}}$ in eq. $(1)$ ? I don't know how to explain $\sigma^2$ in $\frac{\sum(X_i-\bar X)^2}{\sigma^2}$ in equation $(1)$ becoming ""absorbed"" into the $\chi_{n-1}^2$ part of the $\text{t-Student's pdf}.$ So it boils down to understanding why $$\frac 1 {\sigma^2} \left((X_1-\bar X)^2 + \cdots + (X_n - \bar X)^2 \right) \sim \chi^2_{n-1}.$$ After that the derivation of the pdf is not that daunting . PS: The accepted answer below becomes clear after reading this Wikipedia entry. Also, a plot may be useful including the spherical cloud $(X_1,X_2,X_3)$ (in red) with the orthogonal projection, $(X_1-\bar X,\ldots,X_n-\bar X),$ on the $n-1$ subspace forming a plane (in blue) at the origin:","I am trying to understand with basic mathematical background how the -Student distribution is a ""natural"" pdf to define. A more accessible explanation than this post , or the daunting Biometrika paper by RA Fisher. Background: The central limit theorem states that if are each a random sample of size taken from a population with mean and finite variance and if is the sample mean, then the limiting form of the distribution of as is the standard normal distribution. If are iid random variables , This is the basis of the Z-test , [ Note that the preceding opening statement is now correct after reflecting @Ian and @Michael Hardy comments to the OP in reference to the CLT. ] If the standard deviation of the population, , is unknown we can replace it by the estimation based on a sample, , but then the expression ( one-sample t-test statistic ) will follow a -distribution: with Minimal manipulations of this equation for will introduce the chi square distribution, The chi square is the distribution that models with : Let's say that and that and find the density of by using the method: We cannot integrate in close form the density of the normal distribution. But we can express it: Taking the derivative of the cdf: Since the values of the normal are symmetrical: Equating this to the of the normal (now the in the will be to be plugged into the part of the normal ); and remembering to in include at the end: Comparing to the pdf of the chi square: and, since , for df, we have derived exactly the of the chi square. In the case of the -distribution the chi-square is suitable to model the sum of squared normals, i.e in the set of Eq a well known property derived here typically with degrees of freedom, but why is it here, i.e. in eq. ? I don't know how to explain in in equation becoming ""absorbed"" into the part of the So it boils down to understanding why After that the derivation of the pdf is not that daunting . PS: The accepted answer below becomes clear after reading this Wikipedia entry. Also, a plot may be useful including the spherical cloud (in red) with the orthogonal projection, on the subspace forming a plane (in blue) at the origin:","t {\textstyle X_{1},X_{2},...,X_{n}} {\textstyle n}, {\textstyle \mu } {\textstyle \sigma ^{2}} {\textstyle {\bar {X}}} {\textstyle Z=\left({\frac {{\bar {X}}_{n}-\mu }{\sigma /\surd n}}\right)} {\textstyle n\to \infty }, X_1, \ldots, X_n \sim N(\mu,\sigma^2) \frac{\bar{X}\,-\,\mu}{\sigma/\sqrt{n}} \sim N(0,1) Z=\frac{\bar{X}\,-\,\mu}{\sigma/\sqrt{n}} \sigma S t  t=\frac{\bar{X}\,-\,\mu}{S/\sqrt{n}}\sim t_{n-1} s=\sqrt{\frac{\sum(X_i-\bar X)^2}{n-1}}. T \begin{align} \frac{\bar{X}\,-\,\mu}{S/\sqrt{n}} &= \frac{\bar{X}\,-\,\mu}{\frac{\sigma}{\sqrt{n}}} \frac{1}{\frac{S}{\sigma}}\\[2ex]
&= Z\,\frac{1}{\frac{S}{\sigma}}\\[2ex] 
&= \frac{Z}{\sqrt{\frac{\color{blue}{\sum(X_i-\bar X)^2}}{(n-1)\,\color{blue}{\sigma^2}}}}\\[2ex]
&\sim\frac{Z}{\sqrt{\frac{\color{blue}{\chi_{n-1}^2}}{n-1}}}\\[2ex] &\sim t_{n-1}\small \tag 1
\end{align} (\chi^2). X^2 X\sim N(0,1) X \sim N(0,1) Y=X^2 Y \text{cdf} \Pr(Y \leq y) = \Pr(X^2 \leq y)= \Pr(-\sqrt{y} \leq x \leq
> \sqrt{y}).  F_X(y) = F_X(\sqrt{y})- F_X(-\sqrt[]{y}).  f_X(y)= F_X'(\sqrt{y})\,\frac{1}{\sqrt{y}}+
> F_X'(\sqrt{-y})\,\frac{1}{\sqrt{y}}. \text{pdf}  f_X(y)=  F_X'(\sqrt{y})\,\frac{1}{\sqrt{y}}. \text{pdf} x \text{pdf} \sqrt{y} e^{-\frac{x^2}{2}} \text{pdf} \frac{1}{\sqrt{y}} \begin{align} f_X(y) &= 
 F_X'\left(\sqrt{y}\right)\,\frac{1}{\sqrt[]{y}}\\[2ex]
 &=\frac{1}{\sqrt{2\pi}}\,e^{-\frac{y}{2}}\,
 \frac{1}{\sqrt[]{y}}\\[2ex]
 &=\frac{1}{\sqrt{2\pi}}\,e^{-\frac{y}{2}}\, y^{\frac{1}{2}- 1}
 \end{align}  f_X(x)= \frac{1}{2^{\nu/2}\Gamma(\frac{\nu}{2})}e^{\frac{-x}{2}}x^{\frac{\nu}{2}-1} \Gamma(1/2)=\sqrt{\pi} \nu=1 \text{pdf} t \displaystyle \sum(X_i-\bar X)^2  (1), n n\,-\,1 \color{blue}{\chi^2_{n-1}} (1) \sigma^2 \frac{\sum(X_i-\bar X)^2}{\sigma^2} (1) \chi_{n-1}^2 \text{t-Student's pdf}. \frac 1 {\sigma^2} \left((X_1-\bar X)^2 + \cdots + (X_n - \bar X)^2 \right) \sim \chi^2_{n-1}. (X_1,X_2,X_3) (X_1-\bar X,\ldots,X_n-\bar X), n-1","['statistics', 'probability-distributions']"
20,Arithmetic mean. Why does it work?,Arithmetic mean. Why does it work?,,"I've been using the formula for the arithmetic mean all my life, but I'm not sure why it works. My current intuition is this one: The arithmetic mean is a number that when multiplied by the number of elements, gives you the sum of all the elements. Because of this fact, it can't be more than the maximum nor less than the minimum, and it should be located somewhat around the center. But I was wondering if there are other intuitions out there? Why does this formula work? If in passing you could talk about the weighted average as well, that would be nice too. Thanks","I've been using the formula for the arithmetic mean all my life, but I'm not sure why it works. My current intuition is this one: The arithmetic mean is a number that when multiplied by the number of elements, gives you the sum of all the elements. Because of this fact, it can't be more than the maximum nor less than the minimum, and it should be located somewhat around the center. But I was wondering if there are other intuitions out there? Why does this formula work? If in passing you could talk about the weighted average as well, that would be nice too. Thanks",,"['statistics', 'arithmetic', 'means']"
21,Why can't we remove the sqrt from rms?,Why can't we remove the sqrt from rms?,,"In chemistry, we define the root-mean-square speed as $\sqrt{\bar{u^2}}$ = $\sqrt{\frac{3\text{RT}}{\text{M}}}$ A student asked me why we can't just remove the square root symbol. And aside from ""because this is how we define it"", I didn't actually have a reason. So, I'm hoping someone can shed some light on why the above equation is used and not: $\bar{u^2} = \frac{3\text{RT}}{\text{M}}$ In case it is important, we use this equation to determine the rms speed of a gas. It depends on the temperature (T) and the molecular mass of the gas (M). R is a constant value. I understand we don't just use the average because in a set of gases, they move in a random direction so the average is 0. But, by squaring isn't that issue resolved, without the square root?","In chemistry, we define the root-mean-square speed as $\sqrt{\bar{u^2}}$ = $\sqrt{\frac{3\text{RT}}{\text{M}}}$ A student asked me why we can't just remove the square root symbol. And aside from ""because this is how we define it"", I didn't actually have a reason. So, I'm hoping someone can shed some light on why the above equation is used and not: $\bar{u^2} = \frac{3\text{RT}}{\text{M}}$ In case it is important, we use this equation to determine the rms speed of a gas. It depends on the temperature (T) and the molecular mass of the gas (M). R is a constant value. I understand we don't just use the average because in a set of gases, they move in a random direction so the average is 0. But, by squaring isn't that issue resolved, without the square root?",,"['statistics', 'chemistry']"
22,Finding the maximum likelihood estimator,Finding the maximum likelihood estimator,,"Find the MLE of the unknown parameter $\theta$ when $X_1,X_2,...,X_n$ is a sample from the distribution whose density function is: $$f_X(x) = \frac12e^{-|x-\theta|}, -\infty<x<\infty$$ What I did so far: $$\text{maximize }(\frac12)^ne^{-|x_1-\theta|-|x_2-\theta|-...-|x_n-\theta|} \\ \text{thus we want to minimize }|x_1-\theta|+|x_2-\theta|+...+|x_n-\theta|$$ Since $|x_i-\theta|$ is positive for all $i$, we want to solve for $\theta$ so: $$|x_1-\theta|+|x_2-\theta|+...+|x_n-\theta|=0$$ What do I do from here?","Find the MLE of the unknown parameter $\theta$ when $X_1,X_2,...,X_n$ is a sample from the distribution whose density function is: $$f_X(x) = \frac12e^{-|x-\theta|}, -\infty<x<\infty$$ What I did so far: $$\text{maximize }(\frac12)^ne^{-|x_1-\theta|-|x_2-\theta|-...-|x_n-\theta|} \\ \text{thus we want to minimize }|x_1-\theta|+|x_2-\theta|+...+|x_n-\theta|$$ Since $|x_i-\theta|$ is positive for all $i$, we want to solve for $\theta$ so: $$|x_1-\theta|+|x_2-\theta|+...+|x_n-\theta|=0$$ What do I do from here?",,['statistics']
23,What is the relationship between the Boltzmann distribution and information theory?,What is the relationship between the Boltzmann distribution and information theory?,,"I'm reading a paper on Boltzmann machines (a type of neural network in Machine Learning), and it mentions that ""The Boltzmann distribution has some beautiful mathematical properties and it is intimately related to information theory."" What's the nature of this relationship (between the Boltzmann distribution and information theory), and what are these ""beautiful mathematical properties""? High-level answers are fine (perhaps even preferred, as I don't know much about statistical physics, though I do have some background in information theory; but if it's hard to give a high-level overview, technical explanations are also great).","I'm reading a paper on Boltzmann machines (a type of neural network in Machine Learning), and it mentions that ""The Boltzmann distribution has some beautiful mathematical properties and it is intimately related to information theory."" What's the nature of this relationship (between the Boltzmann distribution and information theory), and what are these ""beautiful mathematical properties""? High-level answers are fine (perhaps even preferred, as I don't know much about statistical physics, though I do have some background in information theory; but if it's hard to give a high-level overview, technical explanations are also great).",,"['statistics', 'physics', 'machine-learning', 'information-theory']"
24,Statistics : Where did this degree of freedom formula for the T distribution come from?,Statistics : Where did this degree of freedom formula for the T distribution come from?,,"I am on the hypothesis testing for two populations unit. I need some intuitive explanation as to why this formula is used. My statistics professor put this up on the board but he didn't explain why its true. For a T distribution, the formula for the degrees of freedom is: $$ \large \mathrm{df} = \frac{ \left(\frac{s_{1}^{2}}{n_1} + \frac{s_{2}^{2}}{n_2} \right)^{2} }{ \frac{\left(\frac{s_{1}^{2}}{n_1}\right)^2}{n_{1} - 1} + \frac{\left(\frac{s_{2}^{2}}{n_2}\right)^2}{n_{2}-1}}$$ Here $s_1, s_2$ are the sample standard deviations and $n_1,n_2$ are the sample sizes.","I am on the hypothesis testing for two populations unit. I need some intuitive explanation as to why this formula is used. My statistics professor put this up on the board but he didn't explain why its true. For a T distribution, the formula for the degrees of freedom is: $$ \large \mathrm{df} = \frac{ \left(\frac{s_{1}^{2}}{n_1} + \frac{s_{2}^{2}}{n_2} \right)^{2} }{ \frac{\left(\frac{s_{1}^{2}}{n_1}\right)^2}{n_{1} - 1} + \frac{\left(\frac{s_{2}^{2}}{n_2}\right)^2}{n_{2}-1}}$$ Here $s_1, s_2$ are the sample standard deviations and $n_1,n_2$ are the sample sizes.",,['statistics']
25,"More examples of Simpson's Paradox, barring the ones on Wikipedia, Titanic, and delayed flights.","More examples of Simpson's Paradox, barring the ones on Wikipedia, Titanic, and delayed flights.",,"I hope someone may know fresh examples of Simpson's paradox for use in my statistics courses.  The examples I've been using are fine, but I'd like to have some new ones. I'm familiar with the ones on the Wikipedia page: the gender bias lawsuit at Berkeley, batting averages, mortality rates among low birth babies, party voting on the Civil Rights Act, and success rates of kidney stone treatments.  I'm also familiar with the example of survival rates on the Titanic and the one about delayed flights at America West vs. Alaska Airlines.  These are all good ones, but, like I said, I'm looking for more. Does anybody know any others? For those who aren't familiar with it, Simpson's paradox is essentially a property of unreduced fractions: It's possible to have, simultaneously, $$\frac{a_1}{b_1} < \frac{c_1}{d_1} \text{ and } \frac{a_2}{b_2} < \frac{c_2}{d_2}, \text{ but } \frac{a_1 + a_2}{b_1+b_2} > \frac{c_1+c_2}{d_1+d_2}.$$ For example, $\frac{1}{3} < \frac{34}{100}$ and $\frac{66}{100} < \frac{2}{3}$, but $\frac{67}{103} > \frac{36}{103}$.  It can be hard to spot this happening in a given real-world scenario.","I hope someone may know fresh examples of Simpson's paradox for use in my statistics courses.  The examples I've been using are fine, but I'd like to have some new ones. I'm familiar with the ones on the Wikipedia page: the gender bias lawsuit at Berkeley, batting averages, mortality rates among low birth babies, party voting on the Civil Rights Act, and success rates of kidney stone treatments.  I'm also familiar with the example of survival rates on the Titanic and the one about delayed flights at America West vs. Alaska Airlines.  These are all good ones, but, like I said, I'm looking for more. Does anybody know any others? For those who aren't familiar with it, Simpson's paradox is essentially a property of unreduced fractions: It's possible to have, simultaneously, $$\frac{a_1}{b_1} < \frac{c_1}{d_1} \text{ and } \frac{a_2}{b_2} < \frac{c_2}{d_2}, \text{ but } \frac{a_1 + a_2}{b_1+b_2} > \frac{c_1+c_2}{d_1+d_2}.$$ For example, $\frac{1}{3} < \frac{34}{100}$ and $\frac{66}{100} < \frac{2}{3}$, but $\frac{67}{103} > \frac{36}{103}$.  It can be hard to spot this happening in a given real-world scenario.",,"['statistics', 'examples-counterexamples']"
26,Sxx in linear regression,Sxx in linear regression,,What is the meaning of the symbols $S_{xx}$ and $S_{xy}$ in simple linear regression? I know the formula but what is the meaning of those symbols?,What is the meaning of the symbols and in simple linear regression? I know the formula but what is the meaning of those symbols?,S_{xx} S_{xy},"['statistics', 'regression', 'regression-analysis']"
27,Given a 95% confidence interval why are we using 1.96 and not 1.64?,Given a 95% confidence interval why are we using 1.96 and not 1.64?,,"I'm studying for my test and am reviewing the solution to some example problems. The problem is: You are told that a new standardized test is given to 100 randomly selected third grade students in New Jersey. The sample average score is $\overline Y$ on the test is 58 and the sample standard deviation is $s_y$ = 8. The first part of the question asks you to construct a 95% confidence interval for the mean score of all New Jersey third graders. First I found $$\text{SE}_y = \frac{s_y}{\sqrt{n}} = \frac{8}{\sqrt{10}} = 0.8.$$ Then I did $$58 \pm (0.8)(1.64).$$ However, instead of using $1.64$ they used $1.96$ . Can someone explain why?","I'm studying for my test and am reviewing the solution to some example problems. The problem is: You are told that a new standardized test is given to 100 randomly selected third grade students in New Jersey. The sample average score is on the test is 58 and the sample standard deviation is = 8. The first part of the question asks you to construct a 95% confidence interval for the mean score of all New Jersey third graders. First I found Then I did However, instead of using they used . Can someone explain why?",\overline Y s_y \text{SE}_y = \frac{s_y}{\sqrt{n}} = \frac{8}{\sqrt{10}} = 0.8. 58 \pm (0.8)(1.64). 1.64 1.96,['statistics']
28,Complete Statistic: Uniform distribution,Complete Statistic: Uniform distribution,,"Take a random sample $X_1, X_2,\ldots X_n$ from the distribution $f(x;\theta)=1/\theta$ for $0\le x\le  \theta$. I need to show that $Y=\max(X_1,X_2,...,X_n)$ is complete. Now, I know I should multiply the sample distribution of $Y$ and multiply it with a function of $Y$, then integrate over the range of $\theta$ and equate them to zero. But how do I get the sampling distribution of $Y$?","Take a random sample $X_1, X_2,\ldots X_n$ from the distribution $f(x;\theta)=1/\theta$ for $0\le x\le  \theta$. I need to show that $Y=\max(X_1,X_2,...,X_n)$ is complete. Now, I know I should multiply the sample distribution of $Y$ and multiply it with a function of $Y$, then integrate over the range of $\theta$ and equate them to zero. But how do I get the sampling distribution of $Y$?",,"['statistics', 'uniform-distribution']"
29,Derivation of Mode of grouped data,Derivation of Mode of grouped data,,"A formula to calculate the mode for grouped data's is given in my text book: Mode = $l + \dfrac{(f_1 - f_0)h}{2f_1 - f_0 - f_2} $ Where, $l = $ lower limit of the modal class, $h = $ size of the class interval, $f_1 = $ frequency of the modal class, $f_0 = $ frequency of the class preceding the modal class, $f_2 =$ frequency of the class succeeding the modal class. Can you please explain the derivation of this formula, as it is not given in my T.B. Thanks .","A formula to calculate the mode for grouped data's is given in my text book: Mode = Where, lower limit of the modal class, size of the class interval, frequency of the modal class, frequency of the class preceding the modal class, frequency of the class succeeding the modal class. Can you please explain the derivation of this formula, as it is not given in my T.B. Thanks .",l + \dfrac{(f_1 - f_0)h}{2f_1 - f_0 - f_2}  l =  h =  f_1 =  f_0 =  f_2 =,['statistics']
30,Sum of two independent exponential distributions,Sum of two independent exponential distributions,,"Let $Y_1\sim \exp(\lambda_1)$ and $Y_2\sim \exp(\lambda_2)$ be two independent r.v.'s. Show that the pdf $p_V(x)$ for their sum $V=Y_1+Y_2$ has the following form $$p_V(x)=\frac{e^\frac{-v}{\lambda_1}-e^\frac{-v}{\lambda_2}}{\lambda_1-\lambda_2};\quad v\ge0$$ My attempt: distribution of $Y_i$ , $$p_{Y_i}(y_i)=\frac{1}{\lambda_i}e^\frac{-{y_i}}{\lambda_i};\quad x\ge0;\quad i=1,2$$ joint distribution of $Y_1$ and $Y_2$ , $$p_{Y_1,Y_2}(y_1,y_2)=\frac{1}{\lambda_1\lambda_2}e^{\frac{-{y_1}}{\lambda_1}-\frac{{y_2}}{\lambda_2}};\quad {y_1},{y_2}\ge0$$ Given, $V=Y_1+Y_2$ let $U=Y_2$ So the Jacobian of Transformation is $1$ and hence joint distribution of $V$ and $U$ , $$p_{V,U}(v,u)=\frac{1}{\lambda_1\lambda_2}e^{\frac{-{v-u}}{\lambda_1}-\frac{{u}}{\lambda_2}};\quad {v},{u}\ge0$$ so the distribution of $v$ $$p_{V}(v)=\int_0^\infty p_{V,U}(v,u)du=\frac{e^\frac{-v}{\lambda_1}}{\lambda_1-\lambda_2};\quad v\ge0$$ which doesn't match with the result.","Let and be two independent r.v.'s. Show that the pdf for their sum has the following form My attempt: distribution of , joint distribution of and , Given, let So the Jacobian of Transformation is and hence joint distribution of and , so the distribution of which doesn't match with the result.","Y_1\sim \exp(\lambda_1) Y_2\sim \exp(\lambda_2) p_V(x) V=Y_1+Y_2 p_V(x)=\frac{e^\frac{-v}{\lambda_1}-e^\frac{-v}{\lambda_2}}{\lambda_1-\lambda_2};\quad v\ge0 Y_i p_{Y_i}(y_i)=\frac{1}{\lambda_i}e^\frac{-{y_i}}{\lambda_i};\quad x\ge0;\quad i=1,2 Y_1 Y_2 p_{Y_1,Y_2}(y_1,y_2)=\frac{1}{\lambda_1\lambda_2}e^{\frac{-{y_1}}{\lambda_1}-\frac{{y_2}}{\lambda_2}};\quad {y_1},{y_2}\ge0 V=Y_1+Y_2 U=Y_2 1 V U p_{V,U}(v,u)=\frac{1}{\lambda_1\lambda_2}e^{\frac{-{v-u}}{\lambda_1}-\frac{{u}}{\lambda_2}};\quad {v},{u}\ge0 v p_{V}(v)=\int_0^\infty p_{V,U}(v,u)du=\frac{e^\frac{-v}{\lambda_1}}{\lambda_1-\lambda_2};\quad v\ge0","['statistics', 'probability-distributions']"
31,How to calculate relative error when true value is zero?,How to calculate relative error when true value is zero?,,How do I calculate relative error when the true value is zero? Say I have $x_{true} = 0$ and $x_{test}$. If I define relative error as: $\text{relative error} = \frac{x_{true}-x_{test}}{x_{true}}$ Then the relative error is always undefined. If instead I use the definition: $\text{relative error} = \frac{x_{true}-x_{test}}{x_{test}}$ Then the relative error is always 100%. Both methods seem useless. Is there another alternative?,How do I calculate relative error when the true value is zero? Say I have $x_{true} = 0$ and $x_{test}$. If I define relative error as: $\text{relative error} = \frac{x_{true}-x_{test}}{x_{true}}$ Then the relative error is always undefined. If instead I use the definition: $\text{relative error} = \frac{x_{true}-x_{test}}{x_{test}}$ Then the relative error is always 100%. Both methods seem useless. Is there another alternative?,,['statistics']
32,Non-zero Conditional Differential Entropy between a random variable and a function of it,Non-zero Conditional Differential Entropy between a random variable and a function of it,,"Let two continuous random variables, where the one is a function of the other: $X\,  $ and $\,  Y=g\left(X\right)$. Their mutual information is defined as $$I\left(X,Y\right)\,=\,h\left(X\right)\,-\,h\left(X|Y\right)=\,h\left(Y\right)\,-\,h\left(Y|X\right)$$ where lowercase h denotes differential entropy, the entropy concept for continuous rv's. It is a proven fact that the mutual information between two variables , for discrete as well as for continuous rv's, is non-negative, and becomes zero only when the two rv's are independent (clearly not our case). Using the fact that Y is a function of X we have $$I\left(X,g\left(X\right)\right)\,=\,h\left(g\left(X\right)\right)\,-\,h\left(g\left(X\right)|X\right) \gt\,0\,\Rightarrow \,h\left(g\left(X\right)\right)\,\gt \,h\left(g\left(X\right)|X\right)$$ Now, differential entropy (unlike entropy for discrete rv's) can take negative values. Assume that it so happens that $h\left(g\left(X\right)\right)\lt\,0$. Then from the positivity of mutual information we obtain $$0\,\gt \,h\left(g\left(X\right)\right)\,\gt \,h\left(g\left(X\right)|X\right) \Rightarrow\; h\left(g\left(X\right)|X\right)\neq\,0$$ And this is the counter-intuitive puzzle : for any discrete random variable Z we always have $h\left(g\left(Z\right)|Z\right)\,=\,0$. This is intuitive: if Z is known, then any function of Z is completely determined -no entropy, no uncertainty remains, and so the conditional entropy measure is zero. But we just saw that, when dealing with continuous rv's where the one is a function of the other, their conditional differential entropy may be non-zero (it doesn't matter whether it is positive or negative), which is not intuitive at all. Because, even in this strange world of continuous rv's, knowing X , completely determines Y=g(X) . I have searched high and low to find any discussion, comment or exposition of the matter, but I found nothing. Cover & Thomas book does not mention it, other books do not mention it, a myriad of scientific papers or web sites do not mention it. My motives: a) Scientific curiosity. b) I want to use the concept of mutual information for continuous rv's in an econometrics paper I am writing, and I feel very uncomfortable to just mention the ""non-zero conditional differential entropy"" case without being able to discuss it a bit. So any intuition, reference, suggestion, idea, or full answer of course, would be greatly appreciated. Thanks.","Let two continuous random variables, where the one is a function of the other: $X\,  $ and $\,  Y=g\left(X\right)$. Their mutual information is defined as $$I\left(X,Y\right)\,=\,h\left(X\right)\,-\,h\left(X|Y\right)=\,h\left(Y\right)\,-\,h\left(Y|X\right)$$ where lowercase h denotes differential entropy, the entropy concept for continuous rv's. It is a proven fact that the mutual information between two variables , for discrete as well as for continuous rv's, is non-negative, and becomes zero only when the two rv's are independent (clearly not our case). Using the fact that Y is a function of X we have $$I\left(X,g\left(X\right)\right)\,=\,h\left(g\left(X\right)\right)\,-\,h\left(g\left(X\right)|X\right) \gt\,0\,\Rightarrow \,h\left(g\left(X\right)\right)\,\gt \,h\left(g\left(X\right)|X\right)$$ Now, differential entropy (unlike entropy for discrete rv's) can take negative values. Assume that it so happens that $h\left(g\left(X\right)\right)\lt\,0$. Then from the positivity of mutual information we obtain $$0\,\gt \,h\left(g\left(X\right)\right)\,\gt \,h\left(g\left(X\right)|X\right) \Rightarrow\; h\left(g\left(X\right)|X\right)\neq\,0$$ And this is the counter-intuitive puzzle : for any discrete random variable Z we always have $h\left(g\left(Z\right)|Z\right)\,=\,0$. This is intuitive: if Z is known, then any function of Z is completely determined -no entropy, no uncertainty remains, and so the conditional entropy measure is zero. But we just saw that, when dealing with continuous rv's where the one is a function of the other, their conditional differential entropy may be non-zero (it doesn't matter whether it is positive or negative), which is not intuitive at all. Because, even in this strange world of continuous rv's, knowing X , completely determines Y=g(X) . I have searched high and low to find any discussion, comment or exposition of the matter, but I found nothing. Cover & Thomas book does not mention it, other books do not mention it, a myriad of scientific papers or web sites do not mention it. My motives: a) Scientific curiosity. b) I want to use the concept of mutual information for continuous rv's in an econometrics paper I am writing, and I feel very uncomfortable to just mention the ""non-zero conditional differential entropy"" case without being able to discuss it a bit. So any intuition, reference, suggestion, idea, or full answer of course, would be greatly appreciated. Thanks.",,"['statistics', 'information-theory', 'entropy']"
33,Fisher Information of a function of a parameter,Fisher Information of a function of a parameter,,"Suppose that $X$ is a random variable for which the p.d.f. or the p.f. is $f(x|\theta)$, where the value of the parameter $\theta$ is unknown but must lie in an open interval $\Omega$.  Let $I_0(\theta)$ denote the Fisher information in $X.$  Suppose now that the parameter $\theta$ is replaced by a new parameter $\mu$, where $\theta = \psi(\mu)$ and $\psi$ is a differentiable function.  Let $I_1(\mu)$ denote the Fisher information in $X$ when the parameter is regarded as $\mu.$  Show that $$I_1(\mu) = [\psi'(\mu)]^2 I_0[\psi(\mu)].$$ How would I do this?  Do I need to use a Taylor expansion?  Regardless, I would appreciate a written proof.  This isn't for class but the above statement has been mentioned in texts without any detail whatsoever. Thanks!","Suppose that $X$ is a random variable for which the p.d.f. or the p.f. is $f(x|\theta)$, where the value of the parameter $\theta$ is unknown but must lie in an open interval $\Omega$.  Let $I_0(\theta)$ denote the Fisher information in $X.$  Suppose now that the parameter $\theta$ is replaced by a new parameter $\mu$, where $\theta = \psi(\mu)$ and $\psi$ is a differentiable function.  Let $I_1(\mu)$ denote the Fisher information in $X$ when the parameter is regarded as $\mu.$  Show that $$I_1(\mu) = [\psi'(\mu)]^2 I_0[\psi(\mu)].$$ How would I do this?  Do I need to use a Taylor expansion?  Regardless, I would appreciate a written proof.  This isn't for class but the above statement has been mentioned in texts without any detail whatsoever. Thanks!",,['statistics']
34,Can the maximum likelihood estimator be unbiased and fail to achieve Cramer-Rao lower bound?,Can the maximum likelihood estimator be unbiased and fail to achieve Cramer-Rao lower bound?,,"If some maximum likelihood estimator (MLE) turns out to be unbiased (which does not necessarily holds), then does it achieve the Cramer-Rao lower bound (CRLB) even in finite sample? (It does when the parameter to estimate is the mean of some normal, or Poisson, or binomial distribution, for example.) I feel there should be some MLE which is unbiased but does not achieve CRLB, but I could not give an example. So I am wondering if the claim actually holds.","If some maximum likelihood estimator (MLE) turns out to be unbiased (which does not necessarily holds), then does it achieve the Cramer-Rao lower bound (CRLB) even in finite sample? (It does when the parameter to estimate is the mean of some normal, or Poisson, or binomial distribution, for example.) I feel there should be some MLE which is unbiased but does not achieve CRLB, but I could not give an example. So I am wondering if the claim actually holds.",,['statistics']
35,Intuition behind binomial variance,Intuition behind binomial variance,,"Suppose that I perform a stochastic task $n$ times (like tossing a coin) and that $p$ is the probability that one of the possible outcomes occurs. If $K$ is the stochastic variable that measures how many times this outcome occurred during the whole experiment, and if all the events are mutually independent, then the probability that $K$ is equal to a specific $k$ , with $0\leq k\leq n$ , is $$\mathrm{Pr}\{K=k\} = \binom n k p^k (1-p)^{n-k} =: b_n(k), $$ which makes intuitive sense to me. Now suppose that I want to know what the average , or expected , value of $K$ is going to be: the formulae tell me that $$\begin{split} \langle K\rangle &= \sum_{k=0}^n k b_n(k) = \sum_{k=0}^n k \binom n k p^k (1-p)^{n-k} \\ &= \sum_{k=0}^n k \frac{n(n-1)!}{k(k-1)!(n-k)!} p p^{k-1} (1-p)^{n-k} \\ &= np \sum_{\kappa=1}^\nu \frac{\nu!}{\kappa!(\nu-\kappa)!} p^\kappa (1-p)^{\nu-\kappa} = np(p + 1- p)^{\nu} \\ &= np, \end{split}$$ where I’ve made the substitutions $\kappa = k-1$ and $\nu = n-1$ . Notwithstanding the mathematical certainty of this derivation, it also makes perfect intuitive sense to me that $np$ should be the expected value of $K$ , since it is the product of the probability of the outcome times the number of trials performed: if there’s a $1/6$ chance that I roll a 5 on a fair dice, and I throw it $600$ times, then I expect to see a 5 about $100$ of those times. If instead I want to know how I should expect the outcomes to vary around the expected value, I may compute the variance of $K$ : with the same substitutions as before, $$\begin{split}  \mathrm{Var}[K] &= \langle K^2\rangle - \langle K \rangle^2 = \left(\sum_{k=0}^n k^2 b_n(k) \right) -n^2p^2 \\ &= \left( \sum_{k=1}^n k^2 \binom n k p^k (1-p)^{n-k}\right) -n^2p^2 \\ &= \left( np \sum_{\kappa = 0}^\nu (\kappa +1) \binom \nu \kappa p^\kappa (1-p)^{\nu-\kappa} \right)-n^2p^2 \\ &= \left(np \Big(\sum_{\kappa=0}^\nu \kappa b_\nu(\kappa) +(p + 1-p)^\nu \Big) \right) -n^2p^2 \\ &= np(\nu p + 1) - n^2 p^2 = np( np - p + 1 - np) \\ &= np(1-p). \end{split}$$ Again, the derivation is mathematically crystalline; but why should I expect that this be the formula for the variance of $K$ ? Why does multiplying the expected value of $K$ times the probability that my outcome doesn’t occur give me a measure of the dispersion of $K$ ? In other words, how can I justify this formula for variance intuitively in a similar way as I can with the formula for the mean? EDIT. Up until now, I’ve received answers that are just perfectly good explanations of how to derive the formula for the variance of $K$ in ways that differ from the one presented above. That’s not what I’m asking for. The ideal answer should contain as few formulae as possible, and use simple enough words to explain not why the formula is mathematically true, but why it’s reasonable and couldn’t possibly be otherwise – something like the intuitive explanation for $\langle K\rangle = np$ that I gave above.","Suppose that I perform a stochastic task times (like tossing a coin) and that is the probability that one of the possible outcomes occurs. If is the stochastic variable that measures how many times this outcome occurred during the whole experiment, and if all the events are mutually independent, then the probability that is equal to a specific , with , is which makes intuitive sense to me. Now suppose that I want to know what the average , or expected , value of is going to be: the formulae tell me that where I’ve made the substitutions and . Notwithstanding the mathematical certainty of this derivation, it also makes perfect intuitive sense to me that should be the expected value of , since it is the product of the probability of the outcome times the number of trials performed: if there’s a chance that I roll a 5 on a fair dice, and I throw it times, then I expect to see a 5 about of those times. If instead I want to know how I should expect the outcomes to vary around the expected value, I may compute the variance of : with the same substitutions as before, Again, the derivation is mathematically crystalline; but why should I expect that this be the formula for the variance of ? Why does multiplying the expected value of times the probability that my outcome doesn’t occur give me a measure of the dispersion of ? In other words, how can I justify this formula for variance intuitively in a similar way as I can with the formula for the mean? EDIT. Up until now, I’ve received answers that are just perfectly good explanations of how to derive the formula for the variance of in ways that differ from the one presented above. That’s not what I’m asking for. The ideal answer should contain as few formulae as possible, and use simple enough words to explain not why the formula is mathematically true, but why it’s reasonable and couldn’t possibly be otherwise – something like the intuitive explanation for that I gave above.","n p K K k 0\leq k\leq n \mathrm{Pr}\{K=k\} = \binom n k p^k (1-p)^{n-k} =: b_n(k),  K \begin{split}
\langle K\rangle &= \sum_{k=0}^n k b_n(k) = \sum_{k=0}^n k \binom n k p^k (1-p)^{n-k} \\
&= \sum_{k=0}^n k \frac{n(n-1)!}{k(k-1)!(n-k)!} p p^{k-1} (1-p)^{n-k} \\
&= np \sum_{\kappa=1}^\nu \frac{\nu!}{\kappa!(\nu-\kappa)!} p^\kappa (1-p)^{\nu-\kappa} = np(p + 1- p)^{\nu} \\ &= np,
\end{split} \kappa = k-1 \nu = n-1 np K 1/6 600 100 K \begin{split}
 \mathrm{Var}[K] &= \langle K^2\rangle - \langle K \rangle^2 = \left(\sum_{k=0}^n k^2 b_n(k) \right) -n^2p^2 \\
&= \left( \sum_{k=1}^n k^2 \binom n k p^k (1-p)^{n-k}\right) -n^2p^2 \\
&= \left( np \sum_{\kappa = 0}^\nu (\kappa +1) \binom \nu \kappa p^\kappa (1-p)^{\nu-\kappa} \right)-n^2p^2 \\
&= \left(np \Big(\sum_{\kappa=0}^\nu \kappa b_\nu(\kappa) +(p + 1-p)^\nu \Big) \right) -n^2p^2 \\
&= np(\nu p + 1) - n^2 p^2 = np( np - p + 1 - np) \\ &= np(1-p).
\end{split} K K K K \langle K\rangle = np","['statistics', 'probability-distributions', 'intuition', 'binomial-distribution', 'variance']"
36,"For the binomial distribution, why does no unbiased estimator exist for $1/p$?","For the binomial distribution, why does no unbiased estimator exist for ?",1/p,"Suppose that $X \sim \mathrm{Binomial}(n,p)$ for $0 < p < 1$ Why does no unbiased estimator exist for $1/p$? My approach: We try to find the structure of $E_p(U(x))$, where $U(x)$ is any estimator of $1/p$. Now, we will have: $$\sum{U(x)\binom{n}{x}\theta^x(1-\theta)^{n-x}}<\sum{U(x)\binom{n}{x}}<M(n)<\infty$$ so that the expectation is bounded above. So this is supposed to mean that if $\theta < 1/M(n)$, then the expectation cannot attain $1/\theta$ but I am not sure why the above argument even makes sense and what being bounded means for the expectation. Thanks!","Suppose that $X \sim \mathrm{Binomial}(n,p)$ for $0 < p < 1$ Why does no unbiased estimator exist for $1/p$? My approach: We try to find the structure of $E_p(U(x))$, where $U(x)$ is any estimator of $1/p$. Now, we will have: $$\sum{U(x)\binom{n}{x}\theta^x(1-\theta)^{n-x}}<\sum{U(x)\binom{n}{x}}<M(n)<\infty$$ so that the expectation is bounded above. So this is supposed to mean that if $\theta < 1/M(n)$, then the expectation cannot attain $1/\theta$ but I am not sure why the above argument even makes sense and what being bounded means for the expectation. Thanks!",,['statistics']
37,How to derive the likelihood and loglikelihood of the poisson distribution [closed],How to derive the likelihood and loglikelihood of the poisson distribution [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question As the title suggests, I'm really struggling to derive the likelihood function of the poisson distribution (mostly down to the fact I'm having a hard time understanding the concept of likelihood at all). I've watched a couple videos and understand that the likelihood function is the big product of the PMF or PDF of the distribution but can't get much further than that. The question is as follows: ""Random variables $X_1, \dots, X_n$ are independent and identically distributed (IID) from a $Poisson(θ)$ distribution. Suppose a random sample $x = (x_1, \dots, x_n)$ has been observed. (a) Write down the likelihood function $L(θ)$ based on the observed sample."" If anyone could help show me the process for deriving the likelihood function I would really appreciate it. Thanks!","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question As the title suggests, I'm really struggling to derive the likelihood function of the poisson distribution (mostly down to the fact I'm having a hard time understanding the concept of likelihood at all). I've watched a couple videos and understand that the likelihood function is the big product of the PMF or PDF of the distribution but can't get much further than that. The question is as follows: ""Random variables $X_1, \dots, X_n$ are independent and identically distributed (IID) from a $Poisson(θ)$ distribution. Suppose a random sample $x = (x_1, \dots, x_n)$ has been observed. (a) Write down the likelihood function $L(θ)$ based on the observed sample."" If anyone could help show me the process for deriving the likelihood function I would really appreciate it. Thanks!",,"['statistics', 'probability-distributions', 'poisson-distribution', 'log-likelihood']"
38,Covariance of two random vectors,Covariance of two random vectors,,"IF I have $X,Y_1,...,Y_n$ iid then how do I calculate: cov  $\left [\begin{pmatrix}X\\.\\.\\.\\X \end{pmatrix}, \begin{pmatrix}Y_1\\.\\.\\.\\Y_n \end{pmatrix}\right]$?","IF I have $X,Y_1,...,Y_n$ iid then how do I calculate: cov  $\left [\begin{pmatrix}X\\.\\.\\.\\X \end{pmatrix}, \begin{pmatrix}Y_1\\.\\.\\.\\Y_n \end{pmatrix}\right]$?",,['statistics']
39,What is CDF - Cumulative distribution function?,What is CDF - Cumulative distribution function?,,"Could someone please explain in layman's terms what CDF is? If someone could show a real-life example where this could be useful, it would be great.","Could someone please explain in layman's terms what CDF is? If someone could show a real-life example where this could be useful, it would be great.",,['statistics']
40,Distribution of Sum of Discrete Uniform Random Variables,Distribution of Sum of Discrete Uniform Random Variables,,I just had a quick question that I hope someone can answer.  Does anyone know what the distribution of the sum of discrete uniform random variables is?  Is it a normal distribution? Thanks!,I just had a quick question that I hope someone can answer.  Does anyone know what the distribution of the sum of discrete uniform random variables is?  Is it a normal distribution? Thanks!,,"['statistics', 'uniform-distribution', 'statistical-inference']"
41,metric in the Wasserstein space of gaussian measures,metric in the Wasserstein space of gaussian measures,,"I am reading the paper "" Wasserstein Geometry of Gaussian measures "" by Asuka Takatsu (section 3 is of interest to me) and I have difficulties understanding how the metric is used. In particular, I am wondering the following : if I take the square root of the covariance matrices of my gaussians, does the space become Euclidean ? I feel this should be the case as the metric $tr(XY)$ for $X$ and $Y$ two symmetric matrices allow to recover than $\frac{d}{dt}\langle\dot\gamma,\dot\gamma\rangle=0$ if $\gamma^2$ is a geodesic in the space of covariance matrices (if $\gamma^2(t)$ is a geodesic, it can be written $\gamma(t)=A+tT$, so differentiating by $T$ gives the tangent vector which is independant of the time). However, if this space was Euclidean, wouldn't it mean that an interpolation between a covariance matrix $V$ and another covariance matrix $U$ necessarily be given by $C(t) = (V^{\frac{1}{2}} + t (U^{\frac{1}{2}}-V^{\frac{1}{2}}))^2$ ? This is not the case as geodesics are given by $C(t) = (V^{\frac{1}{2}}+t(U^{\frac{1}{2}}(U^{\frac{1}{2}}VU^{\frac{1}{2}})^{-\frac{1}{2}}U^{\frac{1}{2}}V^{\frac{1}{2}} - V^{\frac{1}{2}}))^2$ (except in 1D where these are equivalent) In which space is the metric $g_V(X,Y)=tr(XVY)$ used ? I thought it was directly in the space of covariance matrices but this doesn't seem to be the case. For instance $\frac{d}{dt}g(\dot\gamma,\dot\gamma)\neq0$ : if $\gamma$ is a geodesic in the space of covariance matrices, then $\gamma(t) = (A+tT)^2$ and then $\dot\gamma = TA+AT+2tTT$ and $\frac{d}{dt}g(\dot\gamma,\dot\gamma)\neq 0$ Thanks!","I am reading the paper "" Wasserstein Geometry of Gaussian measures "" by Asuka Takatsu (section 3 is of interest to me) and I have difficulties understanding how the metric is used. In particular, I am wondering the following : if I take the square root of the covariance matrices of my gaussians, does the space become Euclidean ? I feel this should be the case as the metric $tr(XY)$ for $X$ and $Y$ two symmetric matrices allow to recover than $\frac{d}{dt}\langle\dot\gamma,\dot\gamma\rangle=0$ if $\gamma^2$ is a geodesic in the space of covariance matrices (if $\gamma^2(t)$ is a geodesic, it can be written $\gamma(t)=A+tT$, so differentiating by $T$ gives the tangent vector which is independant of the time). However, if this space was Euclidean, wouldn't it mean that an interpolation between a covariance matrix $V$ and another covariance matrix $U$ necessarily be given by $C(t) = (V^{\frac{1}{2}} + t (U^{\frac{1}{2}}-V^{\frac{1}{2}}))^2$ ? This is not the case as geodesics are given by $C(t) = (V^{\frac{1}{2}}+t(U^{\frac{1}{2}}(U^{\frac{1}{2}}VU^{\frac{1}{2}})^{-\frac{1}{2}}U^{\frac{1}{2}}V^{\frac{1}{2}} - V^{\frac{1}{2}}))^2$ (except in 1D where these are equivalent) In which space is the metric $g_V(X,Y)=tr(XVY)$ used ? I thought it was directly in the space of covariance matrices but this doesn't seem to be the case. For instance $\frac{d}{dt}g(\dot\gamma,\dot\gamma)\neq0$ : if $\gamma$ is a geodesic in the space of covariance matrices, then $\gamma(t) = (A+tT)^2$ and then $\dot\gamma = TA+AT+2tTT$ and $\frac{d}{dt}g(\dot\gamma,\dot\gamma)\neq 0$ Thanks!",,"['statistics', 'differential-geometry', 'riemannian-geometry', 'information-theory']"
42,"The Best Strategy and Highest Possible Score for the ""Threes!"" Game.","The Best Strategy and Highest Possible Score for the ""Threes!"" Game.",,"[There's still the strategy to go. A suitably robust argument that establishes what is statistically the best strategy will be accepted.] Here's my description of the game: There's a $4\times 4$ grid with some random, numbered cards on. The numbers are either one, two, or multiples of three. Using up, down, left, and right moves, you add the numbers on adjacent cards to make a new card like so: $$\begin{align}\color{blue}1+\color{red}2&=3\tag{1} \\ n+n&=2n\end{align}$$ for $n=2^k3\ge 3$ , where $k\in\{0, 1, . . . , 10\}$ , so the highest a card can be is $2^{11}3$ . But at each move the ""free"" cards move too and a random new card appears at a random point along the edge you slide away from. Everything is kept on the grid. The card for the next move is indicated by colour at the top of the screen: blue for $1$ , red for $2$ , and white for $n\ge 3$ (such that $n$ is attainable using the above process). The white $2^\ell 3$ -numbered cards are worth $3^{\ell+1}$ points; the rest give no points . Once there are no more available moves, the points on the remaining cards are summed to give your score for the game. Here's another description I've found; it's the least promotional. It has the following gif. So: What's the best strategy for the game? What's the highest possible score? Thoughts: We could model this using some operations on $4\times 4$ matrices over $\mathbb{N}$ . A new card would be the addition of $\alpha E_{ij}$ for some appropriate $\alpha$ and standard basis vector $E_{ij}$ . That's all I've got . . . NB: If this is a version of some other game, please let me know so I can avoid giving undue attention to this version :) The number on each card can be written $n=2^k3^{\varepsilon_k}$ , where $$\varepsilon_k=\cases{\color{blue}0\text{ or }1 &: $k=0$ \\ \color{red}0\text{ or }1 &: $k=1$ \\ 1 &: $k\ge 2$;}$$ that is, $\varepsilon_k=\cases{0 &:$n<3$ \\ 1 &:$n\ge 3$}$ . So we can write $(k, \varepsilon_k)$ instead under $$(k, \varepsilon_k)+(\ell, \varepsilon_\ell)\stackrel{(1)}{=}\cases{(k+1, 1)&: $\varepsilon_k, \varepsilon_\ell, k=\ell > 0$ \\ (0, 1)&: $\color{blue}k=\color{blue}{\varepsilon_k}=\color{red}{\varepsilon_\ell}=0, \color{red}\ell=1$ \\ (0, 1)&: $\color{blue}\ell=\color{red}{\varepsilon_k}=\color{blue}{\varepsilon_\ell}=0, \color{red}k=1$.}$$ Looking at a $2\times 2$ version might help: the moves from different starting positions show up if we work systematically. It fills up quickly. It'd help to be more precise about what a good strategy might look like. The best strategy might be one that, from an arbitrary $4\times 4$ grid $G_0$ and with the least number of moves, gives the highest score attainable with $G_0$ , subject to the random nature of the game. That's still a little vague though . . .","[There's still the strategy to go. A suitably robust argument that establishes what is statistically the best strategy will be accepted.] Here's my description of the game: There's a grid with some random, numbered cards on. The numbers are either one, two, or multiples of three. Using up, down, left, and right moves, you add the numbers on adjacent cards to make a new card like so: for , where , so the highest a card can be is . But at each move the ""free"" cards move too and a random new card appears at a random point along the edge you slide away from. Everything is kept on the grid. The card for the next move is indicated by colour at the top of the screen: blue for , red for , and white for (such that is attainable using the above process). The white -numbered cards are worth points; the rest give no points . Once there are no more available moves, the points on the remaining cards are summed to give your score for the game. Here's another description I've found; it's the least promotional. It has the following gif. So: What's the best strategy for the game? What's the highest possible score? Thoughts: We could model this using some operations on matrices over . A new card would be the addition of for some appropriate and standard basis vector . That's all I've got . . . NB: If this is a version of some other game, please let me know so I can avoid giving undue attention to this version :) The number on each card can be written , where that is, . So we can write instead under Looking at a version might help: the moves from different starting positions show up if we work systematically. It fills up quickly. It'd help to be more precise about what a good strategy might look like. The best strategy might be one that, from an arbitrary grid and with the least number of moves, gives the highest score attainable with , subject to the random nature of the game. That's still a little vague though . . .","4\times 4 \begin{align}\color{blue}1+\color{red}2&=3\tag{1} \\ n+n&=2n\end{align} n=2^k3\ge 3 k\in\{0, 1, . . . , 10\} 2^{11}3 1 2 n\ge 3 n 2^\ell 3 3^{\ell+1} 4\times 4 \mathbb{N} \alpha E_{ij} \alpha E_{ij} n=2^k3^{\varepsilon_k} \varepsilon_k=\cases{\color{blue}0\text{ or }1 &: k=0 \\
\color{red}0\text{ or }1 &: k=1 \\
1 &: k\ge 2;} \varepsilon_k=\cases{0 &:n<3 \\ 1 &:n\ge 3} (k, \varepsilon_k) (k, \varepsilon_k)+(\ell, \varepsilon_\ell)\stackrel{(1)}{=}\cases{(k+1, 1)&: \varepsilon_k, \varepsilon_\ell, k=\ell > 0 \\
(0, 1)&: \color{blue}k=\color{blue}{\varepsilon_k}=\color{red}{\varepsilon_\ell}=0, \color{red}\ell=1 \\
(0, 1)&: \color{blue}\ell=\color{red}{\varepsilon_k}=\color{blue}{\varepsilon_\ell}=0, \color{red}k=1.} 2\times 2 4\times 4 G_0 G_0","['statistics', 'graph-theory', 'soft-question', 'recreational-mathematics', 'game-theory']"
43,Why is polynomial regression considered a kind of linear regression?,Why is polynomial regression considered a kind of linear regression?,,"Why is polynomial regression considered a kind of linear regression? This is what I mean by polynomial regression. For example, the hypothesis function is $$h(x; t_0, t_1, t_2) = t_0 + t_1 x + t_2 x^2 ,$$ and the sample points are $$ (x_1, y_1), (x_2, y_2), \ldots$$","Why is polynomial regression considered a kind of linear regression? This is what I mean by polynomial regression. For example, the hypothesis function is $$h(x; t_0, t_1, t_2) = t_0 + t_1 x + t_2 x^2 ,$$ and the sample points are $$ (x_1, y_1), (x_2, y_2), \ldots$$",,"['statistics', 'regression']"
44,How does accuracy of a survey depend on sample size and population size?,How does accuracy of a survey depend on sample size and population size?,,"Which survey is more accurate? Assume the samples are taken perfectly randomly. A sample of 100 people out of a population of 1000   (sample is 10% of population) A sample of 1000 people out of a population of 1000000 (sample is 0.1% of population) I remember my lecturer saying something like ""when the sample size is small compared to the population, the accuracy depends almost all on the sample size , the population size is unimportant"" . Is there a name for that result? It's quite surprising at first. I'd love to see some graphs of these functions. If it helps, here's a concrete example (made up by me). An unknown proportion p of the population favour candidate Alice. The rest favour Bob. We take a random sample size k of the population (size n), and ask their preferences, to come up with an estimate p-hat. How does the expected error $\mathbb{E}|\hat{p} - p|$ depend on k and n? And in the limit $n\to\infty$ ?","Which survey is more accurate? Assume the samples are taken perfectly randomly. A sample of 100 people out of a population of 1000   (sample is 10% of population) A sample of 1000 people out of a population of 1000000 (sample is 0.1% of population) I remember my lecturer saying something like ""when the sample size is small compared to the population, the accuracy depends almost all on the sample size , the population size is unimportant"" . Is there a name for that result? It's quite surprising at first. I'd love to see some graphs of these functions. If it helps, here's a concrete example (made up by me). An unknown proportion p of the population favour candidate Alice. The rest favour Bob. We take a random sample size k of the population (size n), and ask their preferences, to come up with an estimate p-hat. How does the expected error depend on k and n? And in the limit ?",\mathbb{E}|\hat{p} - p| n\to\infty,"['statistics', 'sampling']"
45,Is there a name for numbers between 0 and 1?,Is there a name for numbers between 0 and 1?,,"In the world of competitive esports, players often discuss kill/death ratios, where higher is better. My friends sometimes call a poor ratio, like 1 kill to 4 deaths, as 'negative', but that's not quite right. Is there another word to describe values between 0.0 and 1.0, vs values larger than 1.0?","In the world of competitive esports, players often discuss kill/death ratios, where higher is better. My friends sometimes call a poor ratio, like 1 kill to 4 deaths, as 'negative', but that's not quite right. Is there another word to describe values between 0.0 and 1.0, vs values larger than 1.0?",,"['statistics', 'terminology']"
46,easy to implement method to fit a power function (regression),easy to implement method to fit a power function (regression),,"I want to fit to a dataset a power function ($y=Ax^B$). What is the best and easiest method to do this. I need the $A$ and $B$ parameters too. I'm using in general financial data in my project, which looks like this: 8553600 458.2 17193600    373.6 25833600    694.16 34646400    738.33 44064000    817.89 54259200    1040.67 67910400    1032.69 76291200    1222.1 84844800    1245.65 94089600    1217.44 102211200   1579.38 110592000   1859.24 118886400   1711.67 127612800   2303.62 136684800   2658.26 219196800   3669.23 225676800   3525.02 225763200   3749.27 I need to implement the algorithm in a Java similar language called ActionScript.","I want to fit to a dataset a power function ($y=Ax^B$). What is the best and easiest method to do this. I need the $A$ and $B$ parameters too. I'm using in general financial data in my project, which looks like this: 8553600 458.2 17193600    373.6 25833600    694.16 34646400    738.33 44064000    817.89 54259200    1040.67 67910400    1032.69 76291200    1222.1 84844800    1245.65 94089600    1217.44 102211200   1579.38 110592000   1859.24 118886400   1711.67 127612800   2303.62 136684800   2658.26 219196800   3669.23 225676800   3525.02 225763200   3749.27 I need to implement the algorithm in a Java similar language called ActionScript.",,"['statistics', 'algorithms', 'regression']"
47,How to find mean and median from histogram,How to find mean and median from histogram,,"Solution for finding   mean : The problem  faced  when i saw a  video to evaluate the mean https://www.youtube.com/watch?v=vMrc6dP8pCo According to the video, the lecturer said that, we can take the average of the measurement intervals. so according to him: we will get $$2.5 \times 15 +8.5\times 35+ ...$$ instead of $$1 \times 15 +6\times 35+ ...$$ Can we evaluate the mean and median precisely from the Histogram?","Solution for finding   mean : The problem  faced  when i saw a  video to evaluate the mean https://www.youtube.com/watch?v=vMrc6dP8pCo According to the video, the lecturer said that, we can take the average of the measurement intervals. so according to him: we will get $$2.5 \times 15 +8.5\times 35+ ...$$ instead of $$1 \times 15 +6\times 35+ ...$$ Can we evaluate the mean and median precisely from the Histogram?",,[]
48,Help with proof of expected value of gamma distribution,Help with proof of expected value of gamma distribution,,I am struggling with this proof of the expected value for the gamma distribution. I need help with the step indicated by the red arrow. Could someone please break it down for me. Thanks.,I am struggling with this proof of the expected value for the gamma distribution. I need help with the step indicated by the red arrow. Could someone please break it down for me. Thanks.,,['statistics']
49,Difference of order statistics in a sample of uniform random variables,Difference of order statistics in a sample of uniform random variables,,"Let $U_{1}, \, ... \, ,U_{n}$ be a random sample of uniform random variables $U_i \sim \mathrm{Uniform}(0,1)$. Let $U_{(1)}, \, ... \, , U_{(n)}$ be the order statistics of the sample. The goal is to prove that: $$ W = U_{(s)}-U_{(r)} \sim \textrm{Beta}(s-r, \, n - s + r +1) \qquad 1 \leq r < s \leq n $$ My ""proof"" The joint pdf of $U_{(r)}, U_{(s)}$ is: $$ f_{U_{(r)}, U_{(s)}} (u, v) = \frac{n!}{(r-1)!(s-1-r)!(n-s)!} u^{r-1} (v-u)^{s-1-r} (1 -v)^{n-s} \cdot \textbf{1}_{\{u < v\}}  $$ Consider the transformation: $$  \begin{Bmatrix} W = U_{(s)} - U{(r)}  & U_{(r)} = Z \\ Z = U_{(r)} & U_{(s)} = W + Z \\ \end{Bmatrix} $$ The absolute value of the Jacobian determinant is 1. Therefore, the joint pdf of the transformation is: $$ f_{W,Z}(w,z) = \frac{n!}{(r-1)!(s-1-r)!(n-s)!} z^{r-1} w^{s-1-r} (1 - w  - z)^{n-s}  $$ $$ f_W(w) = \int_{S} f_{W,Z}(w,z) \, \textrm{d}z $$ For fixed $w$, we have  $S = \{z  \, : \, 0 \leq z \leq 1 - w\}$. Thus: $$ f_W(w) = \frac{n!}{(r-1)!(s-1-r)!(n-s)!} w^{s-1-r} \int_{0}^{1-w} z^{r-1}(1-w-z)^{n-s} \, \textrm{d} z $$ The problem is that I do not know how to evaluate the integral, but Wolfram Alpha does: $$ \int_{0}^{1-w} z^{r-1}(1-w-z)^{n-s} \, \textrm{d} z= \frac{\Gamma(r)\Gamma(n-s+1)}{\Gamma(n+r-s+1)} (1- w)^{n+r-s} $$ Now it is really easy to figure out the distribution of $W$. Indeed, the only thing that has to be done is to rewrite the factorials using gamma functions. Initially I was going to ask how to evaluate the integral without the help of Wolfram Alpha, but then I realized that maybe there is a ""better"" proof that avoids it. I have tried to find an alternative proof by using multiple transformations which involved $W$ and another transformation, but it was useless. Edit I have corrected some mistakes I think I made: 1) The joint pdf I wrote was incorrect. 2) I wrote that I the pdf of $W$ could be found as a convolution, but $U_{(r)}, U_{(s)}$ are clearly dependent. What I actually did was an implicit change of variables.","Let $U_{1}, \, ... \, ,U_{n}$ be a random sample of uniform random variables $U_i \sim \mathrm{Uniform}(0,1)$. Let $U_{(1)}, \, ... \, , U_{(n)}$ be the order statistics of the sample. The goal is to prove that: $$ W = U_{(s)}-U_{(r)} \sim \textrm{Beta}(s-r, \, n - s + r +1) \qquad 1 \leq r < s \leq n $$ My ""proof"" The joint pdf of $U_{(r)}, U_{(s)}$ is: $$ f_{U_{(r)}, U_{(s)}} (u, v) = \frac{n!}{(r-1)!(s-1-r)!(n-s)!} u^{r-1} (v-u)^{s-1-r} (1 -v)^{n-s} \cdot \textbf{1}_{\{u < v\}}  $$ Consider the transformation: $$  \begin{Bmatrix} W = U_{(s)} - U{(r)}  & U_{(r)} = Z \\ Z = U_{(r)} & U_{(s)} = W + Z \\ \end{Bmatrix} $$ The absolute value of the Jacobian determinant is 1. Therefore, the joint pdf of the transformation is: $$ f_{W,Z}(w,z) = \frac{n!}{(r-1)!(s-1-r)!(n-s)!} z^{r-1} w^{s-1-r} (1 - w  - z)^{n-s}  $$ $$ f_W(w) = \int_{S} f_{W,Z}(w,z) \, \textrm{d}z $$ For fixed $w$, we have  $S = \{z  \, : \, 0 \leq z \leq 1 - w\}$. Thus: $$ f_W(w) = \frac{n!}{(r-1)!(s-1-r)!(n-s)!} w^{s-1-r} \int_{0}^{1-w} z^{r-1}(1-w-z)^{n-s} \, \textrm{d} z $$ The problem is that I do not know how to evaluate the integral, but Wolfram Alpha does: $$ \int_{0}^{1-w} z^{r-1}(1-w-z)^{n-s} \, \textrm{d} z= \frac{\Gamma(r)\Gamma(n-s+1)}{\Gamma(n+r-s+1)} (1- w)^{n+r-s} $$ Now it is really easy to figure out the distribution of $W$. Indeed, the only thing that has to be done is to rewrite the factorials using gamma functions. Initially I was going to ask how to evaluate the integral without the help of Wolfram Alpha, but then I realized that maybe there is a ""better"" proof that avoids it. I have tried to find an alternative proof by using multiple transformations which involved $W$ and another transformation, but it was useless. Edit I have corrected some mistakes I think I made: 1) The joint pdf I wrote was incorrect. 2) I wrote that I the pdf of $W$ could be found as a convolution, but $U_{(r)}, U_{(s)}$ are clearly dependent. What I actually did was an implicit change of variables.",,['statistics']
50,"How can I calculate ""most popular"" more accurately?","How can I calculate ""most popular"" more accurately?",,"I'm developing a website at the moment. The website allows users to ""rate"" a post from 0 to 5. Posts can then be displayed in order of popularity. At the moment, my method of calculation is pretty primitive: average_rating = total_rating/ratings the problem is that a story with 1 rating of 5 is more popular than a story with 99 ratings of 5 and 1 of 4. (5/1) > (499/100) Could someone suggest a more accurate way to calculate popularity both on the number of votes and the quality of each vote?","I'm developing a website at the moment. The website allows users to ""rate"" a post from 0 to 5. Posts can then be displayed in order of popularity. At the moment, my method of calculation is pretty primitive: average_rating = total_rating/ratings the problem is that a story with 1 rating of 5 is more popular than a story with 99 ratings of 5 and 1 of 4. (5/1) > (499/100) Could someone suggest a more accurate way to calculate popularity both on the number of votes and the quality of each vote?",,"['statistics', 'average', 'standard-deviation']"
51,"Distribution and moments of $\frac{X_iX_j}{\sum_{i=1}^n X_i^2}$ when $X_i$'s are i.i.d $N(0,\sigma^2)$",Distribution and moments of  when 's are i.i.d,"\frac{X_iX_j}{\sum_{i=1}^n X_i^2} X_i N(0,\sigma^2)","Suppose $X_1,X_2,\ldots,X_n$ are independent $N(0,\sigma^2)$ random variables. For $i,j\in \{1,2,\ldots,n\}$ , consider $$U=\frac{X_iX_j}{\sum_{i=1}^n X_i^2}$$ Provided $n>1$ , we know that $U$ has a Beta distribution when $i=j$ : $$U=\frac{X_i^2/\sigma^2}{\sum_{i=1}^n X_i^2/\sigma^2} \sim \text{Beta}\left(\frac12,\frac{n-1}2\right) \quad,\,i=1,2,\ldots,n$$ What can we say regarding the distribution of $U$ when $i\ne j$ ? What are the moments of $U$ in this case? For $n=2$ , if we transform $(X_1,X_2)$ to polar coordinates $(R,\Theta)$ , then $$U=\frac{X_1X_2}{X_1^2+X_2^2}=\frac{R^2\cos\Theta\sin\Theta}{R^2}=\frac{\sin(2\Theta)}{2}$$ Since $\Theta$ is uniformly distributed on $(0,2\pi)$ , it seems $\sin(2\Theta)$ has an $\text{Arcsine}(-1,1)$ distribution with pdf $$f(x)=\frac1{\pi \sqrt{1-x^2}}\mathbf 1_{(-1,1)}(x)$$ So that $U$ has pdf $$f_U(u)=2 f(2u)=\frac2{\pi\sqrt{1-4u^2}}\mathbf1_{\left(-\frac12,\frac12\right)}(u)$$ If $\boldsymbol X=(X_1,X_2,\ldots,X_n)^T$ , we can think of $U$ as the product of $i$ th and $j$ th components of the vector $\frac{\boldsymbol X}{\lVert \boldsymbol X \rVert}$ . And we know that $\frac{\boldsymbol X}{\lVert \boldsymbol X \rVert}$ is uniformly distributed on the surface of a unit sphere. I am not sure if this helps in any way.","Suppose are independent random variables. For , consider Provided , we know that has a Beta distribution when : What can we say regarding the distribution of when ? What are the moments of in this case? For , if we transform to polar coordinates , then Since is uniformly distributed on , it seems has an distribution with pdf So that has pdf If , we can think of as the product of th and th components of the vector . And we know that is uniformly distributed on the surface of a unit sphere. I am not sure if this helps in any way.","X_1,X_2,\ldots,X_n N(0,\sigma^2) i,j\in \{1,2,\ldots,n\} U=\frac{X_iX_j}{\sum_{i=1}^n X_i^2} n>1 U i=j U=\frac{X_i^2/\sigma^2}{\sum_{i=1}^n X_i^2/\sigma^2} \sim \text{Beta}\left(\frac12,\frac{n-1}2\right) \quad,\,i=1,2,\ldots,n U i\ne j U n=2 (X_1,X_2) (R,\Theta) U=\frac{X_1X_2}{X_1^2+X_2^2}=\frac{R^2\cos\Theta\sin\Theta}{R^2}=\frac{\sin(2\Theta)}{2} \Theta (0,2\pi) \sin(2\Theta) \text{Arcsine}(-1,1) f(x)=\frac1{\pi \sqrt{1-x^2}}\mathbf 1_{(-1,1)}(x) U f_U(u)=2 f(2u)=\frac2{\pi\sqrt{1-4u^2}}\mathbf1_{\left(-\frac12,\frac12\right)}(u) \boldsymbol X=(X_1,X_2,\ldots,X_n)^T U i j \frac{\boldsymbol X}{\lVert \boldsymbol X \rVert} \frac{\boldsymbol X}{\lVert \boldsymbol X \rVert}","['statistics', 'probability-distributions', 'normal-distribution', 'expected-value', 'variance']"
52,Prove there exists no uniform distribution on a countable and infinite set.,Prove there exists no uniform distribution on a countable and infinite set.,,"Can anyone help me with this problem, I can't figure out how to solve it... Let $X$ be a random variable which can take an infinite and countable   set of values. Prove that $X$ cannot be uniformly distributed among these values. Thanks!","Can anyone help me with this problem, I can't figure out how to solve it... Let $X$ be a random variable which can take an infinite and countable   set of values. Prove that $X$ cannot be uniformly distributed among these values. Thanks!",,['statistics']
53,How can the standard deviation be interpreted when the range is partially impossible?,How can the standard deviation be interpreted when the range is partially impossible?,,"After meassuring the answer time of a software system I calculated the standard deviation from the samples. The average time is about 200ms, the standard deviation $$\sigma = 300ms$$ According to the image below this should mean that 68.2% of all response times should be between -100ms and 500ms. Image: https://en.wikipedia.org/wiki/Standard_deviation A negative response time makes obviously no sense. How should the part of the normal distribution be interpreted that is enclosed in the red box? Sample data with similiar avg ~202 stddev ~337: 100 100 200 150 70 90 110 80 150 70 190 110 130 100 100 1500","After meassuring the answer time of a software system I calculated the standard deviation from the samples. The average time is about 200ms, the standard deviation $$\sigma = 300ms$$ According to the image below this should mean that 68.2% of all response times should be between -100ms and 500ms. Image: https://en.wikipedia.org/wiki/Standard_deviation A negative response time makes obviously no sense. How should the part of the normal distribution be interpreted that is enclosed in the red box? Sample data with similiar avg ~202 stddev ~337: 100 100 200 150 70 90 110 80 150 70 190 110 130 100 100 1500",,"['statistics', 'standard-deviation']"
54,How to get the standard deviation of a given histogram (image),How to get the standard deviation of a given histogram (image),,I have a doubt: How to get the standard deviation of a given histogram? I'm looking for it on the internet. But I got Nothing.  For example the case of this image below Thanks in advance!,I have a doubt: How to get the standard deviation of a given histogram? I'm looking for it on the internet. But I got Nothing.  For example the case of this image below Thanks in advance!,,['statistics']
55,How to determine if Standard Deviation is high/low,How to determine if Standard Deviation is high/low,,"I have derived the following response time data for a performance test I am running: Min - 8sec Max - 284sec Average - 28sec Standard Deviation - 27sec What does the standard deviation say about the response time data distribution? When you say low/high standard deviation, what does this actually mean? Is this in comparison to the Average/Min/Max? I know what standard deviation is and how it's computed. I'm just not sure how to tell if it is high or low.","I have derived the following response time data for a performance test I am running: Min - 8sec Max - 284sec Average - 28sec Standard Deviation - 27sec What does the standard deviation say about the response time data distribution? When you say low/high standard deviation, what does this actually mean? Is this in comparison to the Average/Min/Max? I know what standard deviation is and how it's computed. I'm just not sure how to tell if it is high or low.",,"['statistics', 'standard-deviation']"
56,Example of Sufficient and Insufficient Statistic?,Example of Sufficient and Insufficient Statistic?,,"I am having trouble understanding the concept of a sufficient statistic.  I have read What is a sufficient statistic? and Sufficient Statistic (Wikipedia) Can someone please give an example of: a simple (but non-trivial) statistical model a sufficient statistic of that model an insufficient statistic of that model how you identified 2 & 3 as having and lacking, respectively, the sufficiency property","I am having trouble understanding the concept of a sufficient statistic.  I have read What is a sufficient statistic? and Sufficient Statistic (Wikipedia) Can someone please give an example of: a simple (but non-trivial) statistical model a sufficient statistic of that model an insufficient statistic of that model how you identified 2 & 3 as having and lacking, respectively, the sufficiency property",,['statistics']
57,Intuition behind the Geometric Mean,Intuition behind the Geometric Mean,,"Our (awesome) statistics professor told us about the best intuition behind the definition of the Arithmetic Mean (he had heard of during his career). Here's what he said: Imagine a 10-yard-long wooden plank. Think of each data value in the data set as a stone that weighs 1 pound with its position on the plank determined by the data value the stone represents. Now, place a fulcrum under the plank. The AM is the number corresponding to the fulcrum's position when the plank with the stones on it is completely still and parallel to the ground. The Weighted AM is the same situation with some of the stones having the weight distinct from 1 pound. Of course, he then told us that this real-life physical example can easily be turned into a precise problem from physics and investigated formally using mathematics, arriving at the familiar nice properties the AM has. He said he'd never seen a rationele for the definition of the Geometric Mean (or other means, for that matter) even remotely close to the one described above for the AM. I thought I'd turn to the massive knowledgeable community of MSE for an answer. Side question: besides the physical intuition described above, what other rationales are there for why the AM is defined the way it is?","Our (awesome) statistics professor told us about the best intuition behind the definition of the Arithmetic Mean (he had heard of during his career). Here's what he said: Imagine a 10-yard-long wooden plank. Think of each data value in the data set as a stone that weighs 1 pound with its position on the plank determined by the data value the stone represents. Now, place a fulcrum under the plank. The AM is the number corresponding to the fulcrum's position when the plank with the stones on it is completely still and parallel to the ground. The Weighted AM is the same situation with some of the stones having the weight distinct from 1 pound. Of course, he then told us that this real-life physical example can easily be turned into a precise problem from physics and investigated formally using mathematics, arriving at the familiar nice properties the AM has. He said he'd never seen a rationele for the definition of the Geometric Mean (or other means, for that matter) even remotely close to the one described above for the AM. I thought I'd turn to the massive knowledgeable community of MSE for an answer. Side question: besides the physical intuition described above, what other rationales are there for why the AM is defined the way it is?",,"['statistics', 'intuition', 'means']"
58,Proof and precise formulation of Welch-Satterthwaite equation,Proof and precise formulation of Welch-Satterthwaite equation,,"In my statistics course notes the Welch-Satterthwaite equation, as used in the derivation of the Welch test, is formulated as follows: Suppose $S_1^2, \ldots, S_n^2$ are sample variances of $n$ samples, where the $k$-th sample is a sample of size $m_k$ from a population with distribution $N(\mu_k, \sigma_k^2)$. For any real numbers $a_1, \ldots, a_n$, the statistic   $$ L = \frac{\nu}{\sum_{k=1}^{n} a_k\sigma_k^2}\sum_{k=1}^n a_kS_k^2 $$   with   $$ \nu = \frac{\left(\sum_{k=1}^m a_kS_k^2\right)^2}{\sum_{k=1}^m \frac{(a_kS_k^2)^2}{N_k - 1}} $$   approximately (sic) follows a chi-squared distribution with $\nu$ degrees of freedom. Doing a quick Google search, most sources seem to follow a similar formulation.  There are a few questions I have though: How can the number of degrees of freedom of a chi-squared distribution depend on the statistics $S_i$? Shouldn't the number of degrees of freedom be a constant? What does 'approximately follow a distribution' mean? This is closely related to my third question: How can one justify this approximation? All 'proofs' I have seen on the internet seem to assume that $L$ follows a chi-squared distribution and then show that $\nu$ must have the stated value, using basic properties of expected value and variance. Even those arguments are confusing to mee, since they seem to ignore the fact that the $S_i$ are itself stochastic variables and not known constants. I found a link to the original papers by Welch and Satterthwaite , which I can't access freely. I wonder if there is a reasonably short answer to at least the first two of my questions. Us students are not expected to be able to prove the equation, so it's not that bad if there is no readily available proof, but I'd like to at least understand the statement itself.","In my statistics course notes the Welch-Satterthwaite equation, as used in the derivation of the Welch test, is formulated as follows: Suppose $S_1^2, \ldots, S_n^2$ are sample variances of $n$ samples, where the $k$-th sample is a sample of size $m_k$ from a population with distribution $N(\mu_k, \sigma_k^2)$. For any real numbers $a_1, \ldots, a_n$, the statistic   $$ L = \frac{\nu}{\sum_{k=1}^{n} a_k\sigma_k^2}\sum_{k=1}^n a_kS_k^2 $$   with   $$ \nu = \frac{\left(\sum_{k=1}^m a_kS_k^2\right)^2}{\sum_{k=1}^m \frac{(a_kS_k^2)^2}{N_k - 1}} $$   approximately (sic) follows a chi-squared distribution with $\nu$ degrees of freedom. Doing a quick Google search, most sources seem to follow a similar formulation.  There are a few questions I have though: How can the number of degrees of freedom of a chi-squared distribution depend on the statistics $S_i$? Shouldn't the number of degrees of freedom be a constant? What does 'approximately follow a distribution' mean? This is closely related to my third question: How can one justify this approximation? All 'proofs' I have seen on the internet seem to assume that $L$ follows a chi-squared distribution and then show that $\nu$ must have the stated value, using basic properties of expected value and variance. Even those arguments are confusing to mee, since they seem to ignore the fact that the $S_i$ are itself stochastic variables and not known constants. I found a link to the original papers by Welch and Satterthwaite , which I can't access freely. I wonder if there is a reasonably short answer to at least the first two of my questions. Us students are not expected to be able to prove the equation, so it's not that bad if there is no readily available proof, but I'd like to at least understand the statement itself.",,"['statistics', 'probability-distributions', 'approximation', 'hypothesis-testing', 'chi-squared']"
59,"What does it mean to ""marginalise out"" something?","What does it mean to ""marginalise out"" something?",,"Especially in machine learning one often reads the phrase ""to marginalise out"" something, and while I understand that this means to integrate over a property, I cannot quite grasp the larger significance. For example $z$ is unobserved, so its needs to be ""marginalised out"" to compute the likelihood of the parameters. I.e. $p_{\theta}(y) = \int p_{\theta}(y,z)dz$. Where $y$ is an observed variable, and $\theta$ parametrised the joint distribution. I suppose I am simply wondering why we need to marginalise out something at all, and why we call it marginalisation? Are we trying to change the dependency of the problem on as few variables as possible?","Especially in machine learning one often reads the phrase ""to marginalise out"" something, and while I understand that this means to integrate over a property, I cannot quite grasp the larger significance. For example $z$ is unobserved, so its needs to be ""marginalised out"" to compute the likelihood of the parameters. I.e. $p_{\theta}(y) = \int p_{\theta}(y,z)dz$. Where $y$ is an observed variable, and $\theta$ parametrised the joint distribution. I suppose I am simply wondering why we need to marginalise out something at all, and why we call it marginalisation? Are we trying to change the dependency of the problem on as few variables as possible?",,"['statistics', 'markov-chains', 'machine-learning']"
60,Chi-square or chi-squared?,Chi-square or chi-squared?,,"The $\chi^2$ test/distribution is referred to as either ""chi- square "" (more frequently) or else ""chi- squared "" (less frequently). What is the history behind the name? Footnote 2 in this paper by Peter Scott makes the following claim (without any corroboration): The notation of $\chi^2$ is traditional and possibly misleading. It is a single statistical variable, and not the square of some quantity. It is therefore not chi squared , but chi-square . The notation is merely suggestive of its construction as the sum of squares of terms. Perhaps it would have been better, historically, to have called it $\xi$ or $\zeta$. The Wikipedia article ""Pearson's chi-squared test"" states that it was first investigated by Karl Pearson in this paper from 1900 , in which he apparently just uses the notation $\chi^2$. More historical information can be found in Plackett's 1983 article, "" Karl Pearson and the Chi-squared Test "". Some evidence that suggests that it was first called ""chi-square"", and only later was ""chi-squared"" used, is the fact in MathSciNet the first paper with ""chi-squared"" in the title was published in 1958, whereas ""chi-square"" is used in the title of articles from 1940 onwards. Who first used the term ""chi-square"" in print? And why was ""chi-square"" not ""chi-squared"" used? And when was ""chi-squared"" first used in print?","The $\chi^2$ test/distribution is referred to as either ""chi- square "" (more frequently) or else ""chi- squared "" (less frequently). What is the history behind the name? Footnote 2 in this paper by Peter Scott makes the following claim (without any corroboration): The notation of $\chi^2$ is traditional and possibly misleading. It is a single statistical variable, and not the square of some quantity. It is therefore not chi squared , but chi-square . The notation is merely suggestive of its construction as the sum of squares of terms. Perhaps it would have been better, historically, to have called it $\xi$ or $\zeta$. The Wikipedia article ""Pearson's chi-squared test"" states that it was first investigated by Karl Pearson in this paper from 1900 , in which he apparently just uses the notation $\chi^2$. More historical information can be found in Plackett's 1983 article, "" Karl Pearson and the Chi-squared Test "". Some evidence that suggests that it was first called ""chi-square"", and only later was ""chi-squared"" used, is the fact in MathSciNet the first paper with ""chi-squared"" in the title was published in 1958, whereas ""chi-square"" is used in the title of articles from 1940 onwards. Who first used the term ""chi-square"" in print? And why was ""chi-square"" not ""chi-squared"" used? And when was ""chi-squared"" first used in print?",,"['statistics', 'probability-distributions', 'soft-question', 'math-history']"
61,Goldfish in a lake,Goldfish in a lake,,"It is known that many people dump their pet goldfish into lakes, when they want to get rid of them with no remorse! We wish to calculate the number of goldfish in a small lake, in which there are several other fish of various species. For this purpose we pick 20 goldfish and put them a permanent mark and then release them into the lake. After one day (and assuming there are no changes in the population of goldfish or other fish – the system is “closed”), we pick 30 goldfish, of which 5 are found marked. What is the probability that the total population of goldfish in the lake is from 115 to 125? I have found that this is done by using the “mark and recapture” method, by which we calculate the expected population to be $\frac{20*30}{5} = 120$ But how do we calculate the probability for it to be in the requested range? Of course by intuition, I guess it must be close to 100%!","It is known that many people dump their pet goldfish into lakes, when they want to get rid of them with no remorse! We wish to calculate the number of goldfish in a small lake, in which there are several other fish of various species. For this purpose we pick 20 goldfish and put them a permanent mark and then release them into the lake. After one day (and assuming there are no changes in the population of goldfish or other fish – the system is “closed”), we pick 30 goldfish, of which 5 are found marked. What is the probability that the total population of goldfish in the lake is from 115 to 125? I have found that this is done by using the “mark and recapture” method, by which we calculate the expected population to be But how do we calculate the probability for it to be in the requested range? Of course by intuition, I guess it must be close to 100%!",\frac{20*30}{5} = 120,['statistics']
62,Why is the partition function able to describe the whole system?,Why is the partition function able to describe the whole system?,,"No matter what the real system or subject is, if there is a partition function $Z$, then these kind of identities hold $$\langle X\rangle=\frac{\partial}{\partial Y}\left(-\log Z(Y)\right).$$ If one knows the partition function $Z$, than one essentially knows everything. Very much of the system is in this single expression. Now I see the technical details, the function contains the relevant weights and a sum/integral, which end up producing expectation values if you derive the thing with respect to conjugate parameters. But how can I really understand what's going on? Intuitively. Morally. What makes these kind of systems so that there is one special function, which does this?  ( Here and here two relevant examples I'm interested the most in.) What is the requirement for a system, to contain this conjugate variables business in the first place? They are usually related via an equation of motion or an equation of state...however, these model relations are then eventually also just derived. They are identities involving $Z$. Are there maybe statements about the functional dependencies a $Z$ of it's a priori free model parameters? A more direct formulation: For an initially microscopic system (fields, counting of states and so on) what are the requirements for it and its set of quantities/functions/observables like $X$, such that there is a single valued function/potential, which determines all the $\langle X\rangle$? The point being that you don't have to compute $\langle X\rangle$ like expectation values where $\langle\ \ \rangle$ denotes a complicated functional involving microscopic features. Also, is there a relationship with generating functions and are there reductionists views/mathematical generalizations of the partition function? I have to add that I really understand how phase transitions and renormalization work, maybe that gives an insight. I also know that there is an important ""macroscopic function"", which turns out to generate chern classes in algebraic topology, however I don't know if there are any conceptual relations to the quantity generating objects like partition functions.","No matter what the real system or subject is, if there is a partition function $Z$, then these kind of identities hold $$\langle X\rangle=\frac{\partial}{\partial Y}\left(-\log Z(Y)\right).$$ If one knows the partition function $Z$, than one essentially knows everything. Very much of the system is in this single expression. Now I see the technical details, the function contains the relevant weights and a sum/integral, which end up producing expectation values if you derive the thing with respect to conjugate parameters. But how can I really understand what's going on? Intuitively. Morally. What makes these kind of systems so that there is one special function, which does this?  ( Here and here two relevant examples I'm interested the most in.) What is the requirement for a system, to contain this conjugate variables business in the first place? They are usually related via an equation of motion or an equation of state...however, these model relations are then eventually also just derived. They are identities involving $Z$. Are there maybe statements about the functional dependencies a $Z$ of it's a priori free model parameters? A more direct formulation: For an initially microscopic system (fields, counting of states and so on) what are the requirements for it and its set of quantities/functions/observables like $X$, such that there is a single valued function/potential, which determines all the $\langle X\rangle$? The point being that you don't have to compute $\langle X\rangle$ like expectation values where $\langle\ \ \rangle$ denotes a complicated functional involving microscopic features. Also, is there a relationship with generating functions and are there reductionists views/mathematical generalizations of the partition function? I have to add that I really understand how phase transitions and renormalization work, maybe that gives an insight. I also know that there is an important ""macroscopic function"", which turns out to generate chern classes in algebraic topology, however I don't know if there are any conceptual relations to the quantity generating objects like partition functions.",,"['statistics', 'statistical-mechanics']"
63,"Why ""bother"" with a null hypothesis at all?","Why ""bother"" with a null hypothesis at all?",,"(note: this is a very basic probability question, so it is highly probable (heh) that it is a duplicate) Every time I am trying to get into statistics (again), I am always lost at hypothesis testing. My basic question is - why do we form a null hypothesis as a negation of what we want to prove in the first place, and only then do we prove or disprove the null hypothesis? Why do we do it at all, instead of just proving the original hypothesis?","(note: this is a very basic probability question, so it is highly probable (heh) that it is a duplicate) Every time I am trying to get into statistics (again), I am always lost at hypothesis testing. My basic question is - why do we form a null hypothesis as a negation of what we want to prove in the first place, and only then do we prove or disprove the null hypothesis? Why do we do it at all, instead of just proving the original hypothesis?",,['statistics']
64,Difference between time series and stochastic process?,Difference between time series and stochastic process?,,"What is the difference between a ""time series"" and a (discrete-time) stochastic process?","What is the difference between a ""time series"" and a (discrete-time) stochastic process?",,['statistics']
65,What's the kurtosis of exponential distribution?,What's the kurtosis of exponential distribution?,,"Original question (with confused terms): Wikipedia and Wolfram Math World claim that the kurtosis of exponential distribution is equal to $6$. Whenever I calculate the kurtosis in math software (or manually) I get $9$, so I am slightly confused. I calculate 4th central moment as: $$ D^4X = \int_0^\infty (x-\lambda^{-1})^4 \lambda e^{-\lambda x} \, dx\,. $$ And kurtosis as: $$ K = \frac{D^4X}{(D^2X)^2} $$ Is the approach and result correct (kurtosis equal to $9$)? I trust that the calculation of this very specific integral I shown is correct. Comment: I didn't know ' kurtosis ' and ' excess kurtosis ' are different terms. Thank you all for your help.","Original question (with confused terms): Wikipedia and Wolfram Math World claim that the kurtosis of exponential distribution is equal to $6$. Whenever I calculate the kurtosis in math software (or manually) I get $9$, so I am slightly confused. I calculate 4th central moment as: $$ D^4X = \int_0^\infty (x-\lambda^{-1})^4 \lambda e^{-\lambda x} \, dx\,. $$ And kurtosis as: $$ K = \frac{D^4X}{(D^2X)^2} $$ Is the approach and result correct (kurtosis equal to $9$)? I trust that the calculation of this very specific integral I shown is correct. Comment: I didn't know ' kurtosis ' and ' excess kurtosis ' are different terms. Thank you all for your help.",,"['statistics', 'probability-distributions', 'exponential-distribution']"
66,CDF of a ratio of exponential variables,CDF of a ratio of exponential variables,,"Let $X$ and $Y$ be independent exponential variables with rates $\alpha$ and $\beta$, respectively. Find the CDF of $X/Y$. I tried out the problem, and wanted to check to see if my answer of: $\frac{\alpha}{ \beta/t + \alpha}$ is correct, where $t$ is the time, which we need in our final answer since we need a cdf. Can someone verify if this is correct?","Let $X$ and $Y$ be independent exponential variables with rates $\alpha$ and $\beta$, respectively. Find the CDF of $X/Y$. I tried out the problem, and wanted to check to see if my answer of: $\frac{\alpha}{ \beta/t + \alpha}$ is correct, where $t$ is the time, which we need in our final answer since we need a cdf. Can someone verify if this is correct?",,"['statistics', 'probability-distributions']"
67,What is the difference between all types of Markov Chains?,What is the difference between all types of Markov Chains?,,"I have been looking for some good material covering Markov Chains but everything seems so difficult to me... After reading about the subject, I figured out that there is basically three kinds of processes: discrete-time, continuous-time and decision Markov Processes. I started reading Introduction to Probability Models, Tenth Edition, from Sheldon M. Ross, about discrete-time processes and then, after judging myself introduced to the subject tried to read about continuous-time processes and got confused. Could someone give me an explanation about the subject (like the other Markov Chains topic: What is a Markov Chain?), focusing on differences and at least one simple application ? I also would be glad if you could suggest books that don't use a very complicated language to explain the subject. The book I cited above seems cool (although I have lots of doubts over the formulas/proofs and the math notation) but there are too many people telling the book doesn't explain the subject properly. Thank you very much!","I have been looking for some good material covering Markov Chains but everything seems so difficult to me... After reading about the subject, I figured out that there is basically three kinds of processes: discrete-time, continuous-time and decision Markov Processes. I started reading Introduction to Probability Models, Tenth Edition, from Sheldon M. Ross, about discrete-time processes and then, after judging myself introduced to the subject tried to read about continuous-time processes and got confused. Could someone give me an explanation about the subject (like the other Markov Chains topic: What is a Markov Chain?), focusing on differences and at least one simple application ? I also would be glad if you could suggest books that don't use a very complicated language to explain the subject. The book I cited above seems cool (although I have lots of doubts over the formulas/proofs and the math notation) but there are too many people telling the book doesn't explain the subject properly. Thank you very much!",,"['statistics', 'stochastic-processes', 'markov-chains']"
68,Are squares of independent random variables independent?,Are squares of independent random variables independent?,,"If X and Y are independent random variables both with the same mean (0) and variance, how about $X^2$ and $Y^2$? I tried calculating E($X^2Y^2$)-E($X^2$)E($Y^2$) but haven't been able to get anywhere.","If X and Y are independent random variables both with the same mean (0) and variance, how about $X^2$ and $Y^2$? I tried calculating E($X^2Y^2$)-E($X^2$)E($Y^2$) but haven't been able to get anywhere.",,"['statistics', 'random']"
69,Calculating Fisher Information for Bernoulli rv,Calculating Fisher Information for Bernoulli rv,,"Let $X_1,...,X_n$ be Bernoulli distributed with unknown parameter $p$. My objective is to calculate the information contained in the first observation of the sample. I know that the pdf of $X$ is given by $$f(x\mid p)=p^x(1-p)^{1-x}$$, and my book defines the Fisher information about $p$ as $$I_X(p)=E_p\left[\left(\frac{d}{dp}\log\left(p^x(1-p)^{1-x}\right)\right)^2\right]$$ After some calculations, I arrive at $$I_X(p)=E_p\left[\frac{x^2}{p^2}\right]-2E_p\left[\frac{x(1-x)}{p(1-p)}\right]+E_p\left[\frac{(1-x)^2}{(1-p)^2}\right]$$ I know that the Fisher information about $p$ of a Bernoulli RV is $\frac{1}{p(1-p)}$, but I don't know how to get rid of the X-values, since I'm calculating an expectation with respect to $p$, not $X$. Any clues?","Let $X_1,...,X_n$ be Bernoulli distributed with unknown parameter $p$. My objective is to calculate the information contained in the first observation of the sample. I know that the pdf of $X$ is given by $$f(x\mid p)=p^x(1-p)^{1-x}$$, and my book defines the Fisher information about $p$ as $$I_X(p)=E_p\left[\left(\frac{d}{dp}\log\left(p^x(1-p)^{1-x}\right)\right)^2\right]$$ After some calculations, I arrive at $$I_X(p)=E_p\left[\frac{x^2}{p^2}\right]-2E_p\left[\frac{x(1-x)}{p(1-p)}\right]+E_p\left[\frac{(1-x)^2}{(1-p)^2}\right]$$ I know that the Fisher information about $p$ of a Bernoulli RV is $\frac{1}{p(1-p)}$, but I don't know how to get rid of the X-values, since I'm calculating an expectation with respect to $p$, not $X$. Any clues?",,['statistics']
70,Aggregating standard deviation to a summary point,Aggregating standard deviation to a summary point,,"I have a range of data (server performance statistics) is formatted as follows, for each server: Time            | Average |  Min  |  Max  | StdDev  | SampleCount | ------------------------------------------------------------------- Monday 1st      |    125  |   15  |  220  | 12.56   |     5       | Tuesday 2nd     |    118  |   11  |  221  | 13.21   |     4       | Wednesday 3rd   |    118  |   11  |  221  | 13.21   |     3       | ....            |    ...  |   ..  |  ...  | .....   |     .       | and so on... These data points are calculated from data that has a finer resolution (e.g. hourly data). I need to aggregate this data into a single summary point so the end result is a list of servers and an aggregate average, min, max, standard deviation. For average, I take the average of all the averages. For min, we take the minimum min. For max, we take the maximum max. However, I'm not sure what method I should be using to aggregate standard deviation? I've seen various answers including square roots and variance but I really need a concrete answer on this - can anyone help?","I have a range of data (server performance statistics) is formatted as follows, for each server: Time            | Average |  Min  |  Max  | StdDev  | SampleCount | ------------------------------------------------------------------- Monday 1st      |    125  |   15  |  220  | 12.56   |     5       | Tuesday 2nd     |    118  |   11  |  221  | 13.21   |     4       | Wednesday 3rd   |    118  |   11  |  221  | 13.21   |     3       | ....            |    ...  |   ..  |  ...  | .....   |     .       | and so on... These data points are calculated from data that has a finer resolution (e.g. hourly data). I need to aggregate this data into a single summary point so the end result is a list of servers and an aggregate average, min, max, standard deviation. For average, I take the average of all the averages. For min, we take the minimum min. For max, we take the maximum max. However, I'm not sure what method I should be using to aggregate standard deviation? I've seen various answers including square roots and variance but I really need a concrete answer on this - can anyone help?",,"['statistics', 'average', 'standard-deviation']"
71,Is There Something Called a Weighted Median?,Is There Something Called a Weighted Median?,,"I was given some data that represents the number of lines in a document as well as the line count per hour (which is the lines in the document divided by the number of hours that the document was worked on).  Considering the following data: lines LCPH 57    133 62    135 33    137 76    139 78    141 Typically, I would express the median LCPH as 137 as it is the 3rd of 5 figures.  However, the median is currently being reported as 139 because it is not until the fourth document that more than half the lines in all documents were seen. This figure is currently being referred to as the Weighted Median LCPH instead of Median LCPH. Is there a different term for this sort of figure?","I was given some data that represents the number of lines in a document as well as the line count per hour (which is the lines in the document divided by the number of hours that the document was worked on).  Considering the following data: lines LCPH 57    133 62    135 33    137 76    139 78    141 Typically, I would express the median LCPH as 137 as it is the 3rd of 5 figures.  However, the median is currently being reported as 139 because it is not until the fourth document that more than half the lines in all documents were seen. This figure is currently being referred to as the Weighted Median LCPH instead of Median LCPH. Is there a different term for this sort of figure?",,"['statistics', 'median']"
72,$n$ vs $n-1$ for the standard deviation,vs  for the standard deviation,n n-1,"Suppose that I went to Tasmania a few years before the ""Tazie Tiger"" (thylacine) became extinct. I sample say, $100$ thylacines and make some biometric measurements. To make the discussion concrete, let's make the data the skull widths at the widest point on the head. From this data I can calculate the sample mean, $\bar x$, and the standard deviation, sigma. I get confused by the use of $n-1$ in the denominator of $\sigma$. So, I go away, look at Wikipedia, find out about Bessel's correction, slowly work my way through the maths and eventually learn to accept that, since $\bar x$ is calculated from the data, I only have $99$ independent comparisons of $x-\bar x$. This makes a kind of sense. If I only have $1$ observation, there are no other data to compare it with. If I have $2$ observations, I have exactly $1$ estimate of the spread of the data, which is the spread of the data, and so on. I even understand that the sum of the absolute deviations must equal zero as the mean has been calculated from the data. Great! I go away, happy with my calculations. A week later, someone tells me that I was so thorough with my survey that   my ""sample"" was actually a census. I have taken measurements of absolutely every single living thylacine in the world. Suddenly, my sample average, $\bar x$ is actually the true population average $\mu$. Clearly, I now have to use the population standard deviation. I go back to my calculation. The number of data is still $100$. The population average has still been calculated from the data. The sum of the absolute deviations still adds up to zero. I still have $n-1$ independent estimates of $x-\bar x$. The data are identical. The algebra is identical. So when I calculate the standard deviation, why do I now divide by $n$, rather than by $n-1$? Where did the extra degree of freedom come from?","Suppose that I went to Tasmania a few years before the ""Tazie Tiger"" (thylacine) became extinct. I sample say, $100$ thylacines and make some biometric measurements. To make the discussion concrete, let's make the data the skull widths at the widest point on the head. From this data I can calculate the sample mean, $\bar x$, and the standard deviation, sigma. I get confused by the use of $n-1$ in the denominator of $\sigma$. So, I go away, look at Wikipedia, find out about Bessel's correction, slowly work my way through the maths and eventually learn to accept that, since $\bar x$ is calculated from the data, I only have $99$ independent comparisons of $x-\bar x$. This makes a kind of sense. If I only have $1$ observation, there are no other data to compare it with. If I have $2$ observations, I have exactly $1$ estimate of the spread of the data, which is the spread of the data, and so on. I even understand that the sum of the absolute deviations must equal zero as the mean has been calculated from the data. Great! I go away, happy with my calculations. A week later, someone tells me that I was so thorough with my survey that   my ""sample"" was actually a census. I have taken measurements of absolutely every single living thylacine in the world. Suddenly, my sample average, $\bar x$ is actually the true population average $\mu$. Clearly, I now have to use the population standard deviation. I go back to my calculation. The number of data is still $100$. The population average has still been calculated from the data. The sum of the absolute deviations still adds up to zero. I still have $n-1$ independent estimates of $x-\bar x$. The data are identical. The algebra is identical. So when I calculate the standard deviation, why do I now divide by $n$, rather than by $n-1$? Where did the extra degree of freedom come from?",,"['statistics', 'descriptive-statistics']"
73,What is the difference between a Savitzky-Golay filter and LOESS?,What is the difference between a Savitzky-Golay filter and LOESS?,,"I don't fully understand the difference between these two smoothing algorithms. It seems like they both take a window, fit a polynomial, sample from the fit, and move on. I would guess maybe the difference lies in the weighting function used by LOESS but not by the Savitzky-Golay filter, but I'm not sure exactly how this works or what the ultimate effects on the fit would be. I'm particularly interested in the differences and relative advantages/disadvantages to each for fitting data that is not evenly sampled. I understand there's a generalized Savitzky-Golay filter that works for non-evenly sampled data, albeit much less efficiently.","I don't fully understand the difference between these two smoothing algorithms. It seems like they both take a window, fit a polynomial, sample from the fit, and move on. I would guess maybe the difference lies in the weighting function used by LOESS but not by the Savitzky-Golay filter, but I'm not sure exactly how this works or what the ultimate effects on the fit would be. I'm particularly interested in the differences and relative advantages/disadvantages to each for fitting data that is not evenly sampled. I understand there's a generalized Savitzky-Golay filter that works for non-evenly sampled data, albeit much less efficiently.",,"['statistics', 'regression']"
74,Looking for references related to an inequality in order statistics,Looking for references related to an inequality in order statistics,,"I was reading the paper ""on the minimum of several random variables"" . In example 10 item (ii) it states: Let $1\leq k\leq n$. Let $g_i,i\leq n$, be independent $N(0,1)$ Gaussian random variables. Then for $k\leq n/2$: $$c\sqrt{\ln\frac{2n}{n+1-k}}\leq\mathbb{E}(k\text{-}\min_{i\leq n}|g_i|)\leq C\sqrt{\ln\frac{2n}{n+1-k}}$$ where $c,C$ are absolute constants. The author claimed that this is a well-known inequality so he didn't provide the proof. I am interested whether this inequality has a name and how this was proved. Especially I am interested in the proof techniques, since recently I was working on a project related to this topic, I would like to see whether or not similar result can be generalized to other distributions( e.g. sub-gaussian). Does anyone know any reference related to this? Thanks a lot. A clarification:  The notation $(k\text{-}\min_{i\leq n}|g_i|)$ is used to mean ""the $k$-th smallest value of $|g_i|$ over the set of $n$ variates."" (mf)","I was reading the paper ""on the minimum of several random variables"" . In example 10 item (ii) it states: Let $1\leq k\leq n$. Let $g_i,i\leq n$, be independent $N(0,1)$ Gaussian random variables. Then for $k\leq n/2$: $$c\sqrt{\ln\frac{2n}{n+1-k}}\leq\mathbb{E}(k\text{-}\min_{i\leq n}|g_i|)\leq C\sqrt{\ln\frac{2n}{n+1-k}}$$ where $c,C$ are absolute constants. The author claimed that this is a well-known inequality so he didn't provide the proof. I am interested whether this inequality has a name and how this was proved. Especially I am interested in the proof techniques, since recently I was working on a project related to this topic, I would like to see whether or not similar result can be generalized to other distributions( e.g. sub-gaussian). Does anyone know any reference related to this? Thanks a lot. A clarification:  The notation $(k\text{-}\min_{i\leq n}|g_i|)$ is used to mean ""the $k$-th smallest value of $|g_i|$ over the set of $n$ variates."" (mf)",,"['statistics', 'reference-request', 'normal-distribution', 'order-statistics']"
75,Why does Benford's Law (or Zipf's Law) hold?,Why does Benford's Law (or Zipf's Law) hold?,,"Both Benford's Law (if you take a list of values, the distribution of the most significant digit is rougly proportional to the logarithm of the digit) and Zipf's Law (given a corpus of natural language utterances, the frequency of any word is roughly inversely proportional to its rank in the frequency table) are not theorems in a mathematical sense, but they work quite good in the real life. Does anyone have an idea why this happens? (see also this question )","Both Benford's Law (if you take a list of values, the distribution of the most significant digit is rougly proportional to the logarithm of the digit) and Zipf's Law (given a corpus of natural language utterances, the frequency of any word is roughly inversely proportional to its rank in the frequency table) are not theorems in a mathematical sense, but they work quite good in the real life. Does anyone have an idea why this happens? (see also this question )",,"['statistics', 'soft-question', 'applications']"
76,Calculating uncertainty in standard deviation,Calculating uncertainty in standard deviation,,"I have a distribution with literally an infinite number of potential data points.  I need the standard deviation.  I generate about a hundred points and take the standard deviation of the points.  This gives a hopefully good approximation of the true standard deviation, but it won't, of course, be exact.  How do I estimate the uncertainty in the standard deviation?  This seems like a very basic question, but web searching hasn't provided any solution.  If I missed it somehow, my apologies.","I have a distribution with literally an infinite number of potential data points.  I need the standard deviation.  I generate about a hundred points and take the standard deviation of the points.  This gives a hopefully good approximation of the true standard deviation, but it won't, of course, be exact.  How do I estimate the uncertainty in the standard deviation?  This seems like a very basic question, but web searching hasn't provided any solution.  If I missed it somehow, my apologies.",,"['statistics', 'standard-deviation']"
77,How to know when to use t-value or z-value?,How to know when to use t-value or z-value?,,"I'm doing 2 statistics exercises: The 1st: An electrical firm manufactures light bulbs that have a length of life that is approximately normally distributed with a standard deviation of 40 hours. If a sample of 30 bulbs has an average life of 780 hours, find a 96% confidence interval for the population mean of all bulbs produced by this firm. The 2nd: A random sample of 10 chocolate energy bars of a certain brand has, on average, 230 calories per bar, with a standard deviation of 15 calories. Construct a 99% confidence interval for the true mean calorie content of this brand of energy bar. Assume that the distribution of the calorie content is approximately normal. I look at the solution my teacher provided. The 1st one use z-table and the 2nd use t-table. Could anyone tell me how to know (from questions) whether to use z or use t? And please show me the differences between 2 exercises here that make one use  z-value and the other use t-value. Thank you in advance for any help you can provide.","I'm doing 2 statistics exercises: The 1st: An electrical firm manufactures light bulbs that have a length of life that is approximately normally distributed with a standard deviation of 40 hours. If a sample of 30 bulbs has an average life of 780 hours, find a 96% confidence interval for the population mean of all bulbs produced by this firm. The 2nd: A random sample of 10 chocolate energy bars of a certain brand has, on average, 230 calories per bar, with a standard deviation of 15 calories. Construct a 99% confidence interval for the true mean calorie content of this brand of energy bar. Assume that the distribution of the calorie content is approximately normal. I look at the solution my teacher provided. The 1st one use z-table and the 2nd use t-table. Could anyone tell me how to know (from questions) whether to use z or use t? And please show me the differences between 2 exercises here that make one use  z-value and the other use t-value. Thank you in advance for any help you can provide.",,"['statistics', 'estimation']"
78,Recommend a statistics fundamentals book,Recommend a statistics fundamentals book,,"To give you some background, I have a grasp on the basics of statistics and probability theory and even remember touching Bayes theorem at the university data mining course. But being a few years away from the university made my math got extremely rusty (so much for last-minute pre-exam cramming). While I remember various random basic concepts, there are a lot of gaps in my understanding of them. What would be a good material (a book, a site, or otherwise equally accessible medium) to revise the fundamentals and go beyond basics? I'd like a book that can be actually read as a book (most statistics books are really dry and are close to being reference material, rather than a book).","To give you some background, I have a grasp on the basics of statistics and probability theory and even remember touching Bayes theorem at the university data mining course. But being a few years away from the university made my math got extremely rusty (so much for last-minute pre-exam cramming). While I remember various random basic concepts, there are a lot of gaps in my understanding of them. What would be a good material (a book, a site, or otherwise equally accessible medium) to revise the fundamentals and go beyond basics? I'd like a book that can be actually read as a book (most statistics books are really dry and are close to being reference material, rather than a book).",,"['statistics', 'reference-request']"
79,The pseudoness of pseudorandom number generators,The pseudoness of pseudorandom number generators,,"Is there a reasonable statistic test one can do to standard random number generators (say, one of those that come built in in Python libs) which shows they are not really random? (By reasonable I mean to exclude silly things like «generate a looong list and see that it is periodic») Later: Notice I am looking for a test that fails on standard generators.","Is there a reasonable statistic test one can do to standard random number generators (say, one of those that come built in in Python libs) which shows they are not really random? (By reasonable I mean to exclude silly things like «generate a looong list and see that it is periodic») Later: Notice I am looking for a test that fails on standard generators.",,"['statistics', 'random']"
80,What's the densitiy of the product of two independent Gaussian random variables?,What's the densitiy of the product of two independent Gaussian random variables?,,"Suppose that $X,Y$ are two scalar independent normal random variables, $X \sim N(\mu_X,\sigma_X^2)$, $Y \sim N(\mu_Y,\sigma_Y^2)$. I'm particularly interested about the case where we don't assume $\mu_X = \mu_Y = 0$. I'm interested in the random variable $XY$. What can be said about its PDF? There's an existing question where an answer explains that $XY$ is the difference of two chi-squared variables . For the zero-mean case, we know that the PDF is the normal product distribution . Is there a non-zero-mean generalization of this? I know that there's a 1970 SIAM paper by Springer and Thompson , but I don't have access to this. Is the part which is relevant for my question publicly available somewhere? To add to my confusion, I found a note by Bromiley , where it is argued that the product of two normal independent random variables is a normal variable again - which I thought was not the case. The argument in the linked document goes like this: Products of gaussian PDFs are gaussian. The PDF of a product of two independent RVs is their convolution. The Fourier transform of a convolution is the product of the fourier transforms. Gaussians are mapped to gaussians under the (inverse) Fourier transform. Am I misunderstanding something? Is there something wrong with the proof?","Suppose that $X,Y$ are two scalar independent normal random variables, $X \sim N(\mu_X,\sigma_X^2)$, $Y \sim N(\mu_Y,\sigma_Y^2)$. I'm particularly interested about the case where we don't assume $\mu_X = \mu_Y = 0$. I'm interested in the random variable $XY$. What can be said about its PDF? There's an existing question where an answer explains that $XY$ is the difference of two chi-squared variables . For the zero-mean case, we know that the PDF is the normal product distribution . Is there a non-zero-mean generalization of this? I know that there's a 1970 SIAM paper by Springer and Thompson , but I don't have access to this. Is the part which is relevant for my question publicly available somewhere? To add to my confusion, I found a note by Bromiley , where it is argued that the product of two normal independent random variables is a normal variable again - which I thought was not the case. The argument in the linked document goes like this: Products of gaussian PDFs are gaussian. The PDF of a product of two independent RVs is their convolution. The Fourier transform of a convolution is the product of the fourier transforms. Gaussians are mapped to gaussians under the (inverse) Fourier transform. Am I misunderstanding something? Is there something wrong with the proof?",,"['statistics', 'probability-distributions']"
81,Fisher information for exponential distribution,Fisher information for exponential distribution,,"Let $y_1, \dots,y_n$ be i.i.d. random variables from $Exp(\theta)$, where $\theta$ is scale parameter. I have to find Fisher information $i(\theta)$. The density function is  $$f(y)=\frac{1}{\theta}e^{-\frac{y}{\theta}}$$ and the likelihood function $$L(\theta)=\frac{1}{\theta^n}e^{-\frac{\sum^{n}_{i=1}y_i}{\theta}}$$ The log-likelihood is $$l(\theta)=-n\ln\theta-\frac{\sum^{n}_{i=1}y_i}{\theta}$$ Now, the score function $$l_*(\theta)=\frac{dl(\theta)}{d\theta}=-\frac{n}{\theta}+\frac{1}{\theta^2}\sum^{n}_{i=1}y_i$$ given the MLE $$\hat \theta=\frac{\sum^{n}_{i=1}y_i}{n}$$ I differentiate again to find the observed information $$j(\theta)=-\frac{dl_*(\theta)}{d\theta}=-(\frac{n}{\theta^2}-\frac{2}{\theta^3}\sum^{n}_{i=1}y_i)$$ and Finally fhe Fisher information is the expected value of the observed information, so $$i(\theta)=\mathbb{E}(j(\theta))=-\frac{n}{\theta^2}+\frac{2}{\theta^3}n\theta=\frac{n}{\theta^2}$$ Is everything correct?","Let $y_1, \dots,y_n$ be i.i.d. random variables from $Exp(\theta)$, where $\theta$ is scale parameter. I have to find Fisher information $i(\theta)$. The density function is  $$f(y)=\frac{1}{\theta}e^{-\frac{y}{\theta}}$$ and the likelihood function $$L(\theta)=\frac{1}{\theta^n}e^{-\frac{\sum^{n}_{i=1}y_i}{\theta}}$$ The log-likelihood is $$l(\theta)=-n\ln\theta-\frac{\sum^{n}_{i=1}y_i}{\theta}$$ Now, the score function $$l_*(\theta)=\frac{dl(\theta)}{d\theta}=-\frac{n}{\theta}+\frac{1}{\theta^2}\sum^{n}_{i=1}y_i$$ given the MLE $$\hat \theta=\frac{\sum^{n}_{i=1}y_i}{n}$$ I differentiate again to find the observed information $$j(\theta)=-\frac{dl_*(\theta)}{d\theta}=-(\frac{n}{\theta^2}-\frac{2}{\theta^3}\sum^{n}_{i=1}y_i)$$ and Finally fhe Fisher information is the expected value of the observed information, so $$i(\theta)=\mathbb{E}(j(\theta))=-\frac{n}{\theta^2}+\frac{2}{\theta^3}n\theta=\frac{n}{\theta^2}$$ Is everything correct?",,"['statistics', 'self-learning', 'fisher-information']"
82,comparing distribution of two data sets,comparing distribution of two data sets,,"I need to compare the distribution (unknown) of a set of data to the distribution of another one (unknown). In particular, I want to check for equality of the two distributions. What are some statistical tests for this?","I need to compare the distribution (unknown) of a set of data to the distribution of another one (unknown). In particular, I want to check for equality of the two distributions. What are some statistical tests for this?",,"['statistics', 'probability-distributions']"
83,"Minimal sufficient statistics for uniform distribution on $(-\theta, \theta)$",Minimal sufficient statistics for uniform distribution on,"(-\theta, \theta)","Let $X_1,\dots,X_n$ be a sample from uniform distribution on $(-\theta,\theta)$ with parameter $\theta>0$. It is easy to show that $T(X) = (X_{(1)},X_{(n)})$ is a sufficient statistic for $\theta$ where $X_{(1)}$ and $X_{(n)}$ stands for the minimum and the maximum from the sample $X_1,\dots,X_n$ respectively. I want to show that it is also minimal sufficient . To do so I look at the ratio of the densities $$ \frac{f(x_1,\dots,x_n;\theta)}{f(y_1,\dots,y_n;\theta)} = \frac{1_{[-\theta<x_{(1)}\leq x_{(n)}<\theta]}}{1_{[-\theta<y_{(1)}\leq y_{(n)}<\theta]}} $$ We want to show that this ratio is a constant as a function of $\theta$ iff $(x_{(1)},x_{(n)})=(y_{(1)},y_{(n)})$. 1. question: how should I understand the ratio if it is not defined (e.g. $\frac{0}{0}$)? It is easy to show that if $(x_{(1)},x_{(n)})=(y_{(1)},y_{(n)})$ than the ratio is constant as a function of $\theta$ (if I neglect the problem of understanding the $\frac{0}{0}$ case). But: 2. question: how to show that if the ratio is constant as a function of $\theta$ then $(x_{(1)},x_{(n)})=(y_{(1)},y_{(n)})$?","Let $X_1,\dots,X_n$ be a sample from uniform distribution on $(-\theta,\theta)$ with parameter $\theta>0$. It is easy to show that $T(X) = (X_{(1)},X_{(n)})$ is a sufficient statistic for $\theta$ where $X_{(1)}$ and $X_{(n)}$ stands for the minimum and the maximum from the sample $X_1,\dots,X_n$ respectively. I want to show that it is also minimal sufficient . To do so I look at the ratio of the densities $$ \frac{f(x_1,\dots,x_n;\theta)}{f(y_1,\dots,y_n;\theta)} = \frac{1_{[-\theta<x_{(1)}\leq x_{(n)}<\theta]}}{1_{[-\theta<y_{(1)}\leq y_{(n)}<\theta]}} $$ We want to show that this ratio is a constant as a function of $\theta$ iff $(x_{(1)},x_{(n)})=(y_{(1)},y_{(n)})$. 1. question: how should I understand the ratio if it is not defined (e.g. $\frac{0}{0}$)? It is easy to show that if $(x_{(1)},x_{(n)})=(y_{(1)},y_{(n)})$ than the ratio is constant as a function of $\theta$ (if I neglect the problem of understanding the $\frac{0}{0}$ case). But: 2. question: how to show that if the ratio is constant as a function of $\theta$ then $(x_{(1)},x_{(n)})=(y_{(1)},y_{(n)})$?",,"['statistics', 'statistical-inference', 'order-statistics', 'sufficient-statistics']"
84,Definition of mean as an integral over the CDF,Definition of mean as an integral over the CDF,,"I'm reading a statistics textbook which defines the mean of a random variable $X$ with CDF $F$ as a statistical function $t(\centerdot)$, where $$ t(F) = \int x \, dF(x).$$ Can someone explain this definition? I'm familiar with the definition of the mean as an integral over the PDF $f$: $$ \int x \, f(x) \, dx.$$ But what does it mean to have the function $F(x)$ in the variable of integration?","I'm reading a statistics textbook which defines the mean of a random variable $X$ with CDF $F$ as a statistical function $t(\centerdot)$, where $$ t(F) = \int x \, dF(x).$$ Can someone explain this definition? I'm familiar with the definition of the mean as an integral over the PDF $f$: $$ \int x \, f(x) \, dx.$$ But what does it mean to have the function $F(x)$ in the variable of integration?",,['statistics']
85,M.SE reputation distribution,M.SE reputation distribution,,What distribution does the reputation points per user follow on math.SE (or on entire stackexchange)? Is there a mathematical explanation/model of it?,What distribution does the reputation points per user follow on math.SE (or on entire stackexchange)? Is there a mathematical explanation/model of it?,,"['statistics', 'probability-distributions']"
86,Why are maximum likelihood estimators used?,Why are maximum likelihood estimators used?,,"Is there a motivating reason for using maximum likelihood estimators? As for as I can tell, there is no reason why they should be unbiased estimators (Can their expectation even be calculated in a general setting, given that they are defined by a global maximum?). So then why are they used?","Is there a motivating reason for using maximum likelihood estimators? As for as I can tell, there is no reason why they should be unbiased estimators (Can their expectation even be calculated in a general setting, given that they are defined by a global maximum?). So then why are they used?",,"['statistics', 'maximum-likelihood']"
87,What's the difference between MUTUALLY EXCLUSIVE and PAIRWISE DISJOINT?,What's the difference between MUTUALLY EXCLUSIVE and PAIRWISE DISJOINT?,,"When I study Statistical Theory, I find that these two concepts confuse me a lot. By definition, if we say two events are PAIRWISE DISJOINT, that means the intersection of these two event is empty set. If we say that two events are MUTUALLY EXCLUSIVE, that means if one of these two events happens, the other will not. But doesn't it means that these two events are PAIRWISE DISJOINT？ If we say two events are MUTUALLY EXCLUSIVE, then they are not INDEPENDENT. Can we say that two PAIRWISE DISJOINT events are not INDEPENDENT as well？ If these two concepts are different (actually my teacher told me they are), could you please give me an example that two events are MUTUALLY EXCLUSIVE but not PAIRWISE DISJOINT, or they are PAIRWISE DISJOINT but not MUTUALLY EXCLUSIVE. Thank you for your help.","When I study Statistical Theory, I find that these two concepts confuse me a lot. By definition, if we say two events are PAIRWISE DISJOINT, that means the intersection of these two event is empty set. If we say that two events are MUTUALLY EXCLUSIVE, that means if one of these two events happens, the other will not. But doesn't it means that these two events are PAIRWISE DISJOINT？ If we say two events are MUTUALLY EXCLUSIVE, then they are not INDEPENDENT. Can we say that two PAIRWISE DISJOINT events are not INDEPENDENT as well？ If these two concepts are different (actually my teacher told me they are), could you please give me an example that two events are MUTUALLY EXCLUSIVE but not PAIRWISE DISJOINT, or they are PAIRWISE DISJOINT but not MUTUALLY EXCLUSIVE. Thank you for your help.",,['statistics']
88,Assumption of a Random error term in a regression,Assumption of a Random error term in a regression,,"In one of my recent statistics courses, our teacher introduced the linear regression model. The typical $y=\alpha + \beta X + \epsilon$, where $\epsilon$ is a ""random"" error term. The teacher then proceeded to explain that this error term is normally distributed and has a mean zero. The error term is what is confusing me. What exactly does random mean? My back ground in statistics is very low level, but I understand that a random variable is defined as a mapping from a sample space to the real numbers. This definition makes sense, but the assumption of a zero mean is what I get tripped up on. How can we assume this fact? I've been trying to think about it intuitively, and can only think that in regards to the real numbers, zero is in a sense ""the middle ground"" and splits up the reals into 2 ""equal length"" parts. However, I know that the reals are uncountable so this may be a case where my intuition is incorrect. I apologize in advance if my question is confusing.","In one of my recent statistics courses, our teacher introduced the linear regression model. The typical $y=\alpha + \beta X + \epsilon$, where $\epsilon$ is a ""random"" error term. The teacher then proceeded to explain that this error term is normally distributed and has a mean zero. The error term is what is confusing me. What exactly does random mean? My back ground in statistics is very low level, but I understand that a random variable is defined as a mapping from a sample space to the real numbers. This definition makes sense, but the assumption of a zero mean is what I get tripped up on. How can we assume this fact? I've been trying to think about it intuitively, and can only think that in regards to the real numbers, zero is in a sense ""the middle ground"" and splits up the reals into 2 ""equal length"" parts. However, I know that the reals are uncountable so this may be a case where my intuition is incorrect. I apologize in advance if my question is confusing.",,"['statistics', 'probability-distributions', 'random-variables', 'normal-distribution', 'regression']"
89,A statistical approach to the prisoners problem,A statistical approach to the prisoners problem,,"Two days ago, I found this problem on reddit (I didn't have access to reddit when I did the math, so I did it with 24 instead of 23, and I decided the warden picked someone every day, not ""whenever he feels like it""): A prison warden tells 24 prisoners he has a ""game"" for them. Once per day, the warden chooses one prisoner at random and leads them to the Switch Room. The aptly named Switch Room has two switches, both at the Off position at first, that are connected to nothing. The called prisoner has to toggle exactly one switch. At any time, any prisoner can go to the warden and tell him that the 24 prisoners all went to the Switch Room at least once. If that's true, they're all freed. If not, they're going to be made into sausages for the other inmates or something. The prisoners can come up with a plan now but won't ever be able to communicate again until someone tells the warden. EDIT After some debating with @alex.jordan , I wanted to clarify my intent. My perspective is that this is a metaphor for ""how would you tell that N distinct events, uniformly and randomly happening, all happened at least once if you only had 2 bits to spare"", and has nothing to do with an actual warden (who could be biased in his random choices or use a different distribution model to screw up the prisoners), or actual prisoners. I am solely interested in an answer that assumes a prisoner is selected randomly and uniformly once every day (not ""from time to time"" as stated in the reddit riddle), so you can safely ignore any assumption that the warden is out there to grind the prisoners to sausages or selects people with a bias or just won't ever select anyone. The ""classical"" solution is that the prisoners designate one leader. When a prisoner enters the Switch Room (except the leader), if they've never been there and find the first switch in the Off position, they turn it on. Otherwise, they toggle the other switch. When the leader enters the Switch Room, if he sees the first switch in the On position, he knows that someone who's never been there before has been, so he counts one and turns off the switch. When he has counted to 23, he knows that everyone has been there at least one. The thing is, this solution sucks. Assuming 24 prisoners again, and knowing they're picked at random, we can represent the whole thing as a series of geometric distributions (this also assumes I'm doing it right, which I may not be): $$ X: \text{number of days before the Leader goes to the Switch Room}\\ X \sim Geom\left(\frac{1}{24}\right)\\ E(X) = 24, Var(X) = 552\\ $$ $$ Y_n: \text{number of days before one of the n remaining prisoner}\\ \text{goes to the Switch Room for the first time (n from 1 through 23)}\\ Y_n \sim Geom\left(\frac{n}{24}\right)\\ E(Y_n) = \frac{24}{n}, Var(Y_n) = \frac{24 (24-n)}{n^2} $$ Since expected values and variance can be linearly added, we can expect that the Leader will tell the warden after on average 642 days, with a standard deviation of 116, by assuming the leader will go $E(X)$ days after any given prisoner went for the first time as modeled by $E(Y_n)$: $$ Z: \text{Number of days before the Leader announces everyone's been to the Switch Room}\\ E(Z) = \sum_{n=1}^{23}E(X) + E(Y_n) = 552 + \sum_{n=1}^{23}E(Y_n) \approx 552 + 89.6229 \approx 641.6229\\ Var(Z) = \sum_{n=1}^{23}Var(X) + Var(Y_n) = 12696 + \sum_{n=1}^{23}Var(Y_n) \approx 12696 + 833.3521 \approx 13529.3521\\ \sigma = \sqrt{13529.3521} = 116.3157 $$ Very simple maths tell us that after 642 days, every prisoner's been on average 26 times to the Switch Room. This looks like a horrible waste of time. I'm pretty sure it's possible to calculate how many days you would need to wait before you have 99% chances (or higher) that each prisoner has been there. Problem is, I'm only halfway through my college stats class, and we've only seen easy distributions where successes are independent, so I'm not too sure how to tackle that. How would you calculate the chances that each prisoner has been to the Switch Room after $Z$ days? EDIT I just made a quick and dirty program to run ""simulations"", and it takes on average 90.6 days until every prisoner has visited the Switch Room, with a standard deviation of 28.5. Making that into a normal distribution, it should be around 157 days before we can say with 99% certainty that each prisoner has visited the Switch Room at least once, and 179 days for 99.9% certainty. Needless to say, you're pretty safe after 641 days... It's an empirical technique and it doesn't really feel mathematically satisfying, so the question is still open for better answers.","Two days ago, I found this problem on reddit (I didn't have access to reddit when I did the math, so I did it with 24 instead of 23, and I decided the warden picked someone every day, not ""whenever he feels like it""): A prison warden tells 24 prisoners he has a ""game"" for them. Once per day, the warden chooses one prisoner at random and leads them to the Switch Room. The aptly named Switch Room has two switches, both at the Off position at first, that are connected to nothing. The called prisoner has to toggle exactly one switch. At any time, any prisoner can go to the warden and tell him that the 24 prisoners all went to the Switch Room at least once. If that's true, they're all freed. If not, they're going to be made into sausages for the other inmates or something. The prisoners can come up with a plan now but won't ever be able to communicate again until someone tells the warden. EDIT After some debating with @alex.jordan , I wanted to clarify my intent. My perspective is that this is a metaphor for ""how would you tell that N distinct events, uniformly and randomly happening, all happened at least once if you only had 2 bits to spare"", and has nothing to do with an actual warden (who could be biased in his random choices or use a different distribution model to screw up the prisoners), or actual prisoners. I am solely interested in an answer that assumes a prisoner is selected randomly and uniformly once every day (not ""from time to time"" as stated in the reddit riddle), so you can safely ignore any assumption that the warden is out there to grind the prisoners to sausages or selects people with a bias or just won't ever select anyone. The ""classical"" solution is that the prisoners designate one leader. When a prisoner enters the Switch Room (except the leader), if they've never been there and find the first switch in the Off position, they turn it on. Otherwise, they toggle the other switch. When the leader enters the Switch Room, if he sees the first switch in the On position, he knows that someone who's never been there before has been, so he counts one and turns off the switch. When he has counted to 23, he knows that everyone has been there at least one. The thing is, this solution sucks. Assuming 24 prisoners again, and knowing they're picked at random, we can represent the whole thing as a series of geometric distributions (this also assumes I'm doing it right, which I may not be): $$ X: \text{number of days before the Leader goes to the Switch Room}\\ X \sim Geom\left(\frac{1}{24}\right)\\ E(X) = 24, Var(X) = 552\\ $$ $$ Y_n: \text{number of days before one of the n remaining prisoner}\\ \text{goes to the Switch Room for the first time (n from 1 through 23)}\\ Y_n \sim Geom\left(\frac{n}{24}\right)\\ E(Y_n) = \frac{24}{n}, Var(Y_n) = \frac{24 (24-n)}{n^2} $$ Since expected values and variance can be linearly added, we can expect that the Leader will tell the warden after on average 642 days, with a standard deviation of 116, by assuming the leader will go $E(X)$ days after any given prisoner went for the first time as modeled by $E(Y_n)$: $$ Z: \text{Number of days before the Leader announces everyone's been to the Switch Room}\\ E(Z) = \sum_{n=1}^{23}E(X) + E(Y_n) = 552 + \sum_{n=1}^{23}E(Y_n) \approx 552 + 89.6229 \approx 641.6229\\ Var(Z) = \sum_{n=1}^{23}Var(X) + Var(Y_n) = 12696 + \sum_{n=1}^{23}Var(Y_n) \approx 12696 + 833.3521 \approx 13529.3521\\ \sigma = \sqrt{13529.3521} = 116.3157 $$ Very simple maths tell us that after 642 days, every prisoner's been on average 26 times to the Switch Room. This looks like a horrible waste of time. I'm pretty sure it's possible to calculate how many days you would need to wait before you have 99% chances (or higher) that each prisoner has been there. Problem is, I'm only halfway through my college stats class, and we've only seen easy distributions where successes are independent, so I'm not too sure how to tackle that. How would you calculate the chances that each prisoner has been to the Switch Room after $Z$ days? EDIT I just made a quick and dirty program to run ""simulations"", and it takes on average 90.6 days until every prisoner has visited the Switch Room, with a standard deviation of 28.5. Making that into a normal distribution, it should be around 157 days before we can say with 99% certainty that each prisoner has visited the Switch Room at least once, and 179 days for 99.9% certainty. Needless to say, you're pretty safe after 641 days... It's an empirical technique and it doesn't really feel mathematically satisfying, so the question is still open for better answers.",,"['statistics', 'puzzle']"
90,How to generate sample from bimodal distribution?,How to generate sample from bimodal distribution?,,"Is there any ""classical"" distribution that is considered bimodal? For example, ""Normal"" is unimodal, ""Gamma"" is unimodal. If I have to generate a sample of 100 numbers from a univariate bimodal distribution, how should I proceed with that? I think that ""sticking"" two samples from unimodal distributions doesn't really work, or am I wrong? Will a sample created from sticking two random samples be considered independent?","Is there any ""classical"" distribution that is considered bimodal? For example, ""Normal"" is unimodal, ""Gamma"" is unimodal. If I have to generate a sample of 100 numbers from a univariate bimodal distribution, how should I proceed with that? I think that ""sticking"" two samples from unimodal distributions doesn't really work, or am I wrong? Will a sample created from sticking two random samples be considered independent?",,"['statistics', 'probability-distributions', 'simulation']"
91,Calculate the product of two Gaussian PDF's,Calculate the product of two Gaussian PDF's,,"I'm trying to understand the origin of the formulas for the $\mu$ and the $\sigma^2$ from this side (stanford): https://ccrma.stanford.edu/~jos/sasp/Product_Two_Gaussian_PDFs.html As I have understood actually the product of two Gaussian PDF's is not again a Gaussian PDF. But with the formula from the stanford website I again get a Gaussian PDF. Where I need help is: Understand the origin of the two formulas $(\mu, \sigma^2)$ Is the center of the product of two PDF's and the center of a PDF calculated via the two formulas in the same place?","I'm trying to understand the origin of the formulas for the $\mu$ and the $\sigma^2$ from this side (stanford): https://ccrma.stanford.edu/~jos/sasp/Product_Two_Gaussian_PDFs.html As I have understood actually the product of two Gaussian PDF's is not again a Gaussian PDF. But with the formula from the stanford website I again get a Gaussian PDF. Where I need help is: Understand the origin of the two formulas $(\mu, \sigma^2)$ Is the center of the product of two PDF's and the center of a PDF calculated via the two formulas in the same place?",,['statistics']
92,Distribution of the product of Cauchy IID random variables,Distribution of the product of Cauchy IID random variables,,"Can anyone tell me if the product distribution of (say $n$) IID Cauchy random variables has a tractable form? And if so, what's a good way to go about deriving it? Characteristic functions (ie. Fourier transforms) perhaps? Or is there a simplification of the polynomial form? Any thoughts are appreciated, thanks.","Can anyone tell me if the product distribution of (say $n$) IID Cauchy random variables has a tractable form? And if so, what's a good way to go about deriving it? Characteristic functions (ie. Fourier transforms) perhaps? Or is there a simplification of the polynomial form? Any thoughts are appreciated, thanks.",,"['statistics', 'probability-distributions', 'fourier-analysis', 'characteristic-functions']"
93,pairwise correlation of three random variables,pairwise correlation of three random variables,,"Assume three random variables have all equal pairwise correlation. What are the possible values of this correlation? Can all of these values be achieved? The solution says $\rho \in [-\frac 12,1]$, but without any explanation. Can someone give me a hint?","Assume three random variables have all equal pairwise correlation. What are the possible values of this correlation? Can all of these values be achieved? The solution says $\rho \in [-\frac 12,1]$, but without any explanation. Can someone give me a hint?",,['statistics']
94,Does randomness exist in computers and in nature?,Does randomness exist in computers and in nature?,,"In the programming language Python, you can import random and then with random.random() you can get a random number between $0$ and $1$. But is it truly random or are there constraints in how computers are built that makes them not truly random number generators? For instance, could there be a bias around the first value generated or value already in memory? How would one figure out the difference?","In the programming language Python, you can import random and then with random.random() you can get a random number between $0$ and $1$. But is it truly random or are there constraints in how computers are built that makes them not truly random number generators? For instance, could there be a bias around the first value generated or value already in memory? How would one figure out the difference?",,"['statistics', 'random', 'philosophy']"
95,How do actuaries calculate the premium of catastrophic insurance given the shortage of data?,How do actuaries calculate the premium of catastrophic insurance given the shortage of data?,,"Since catastrophes seldom happen, there aren't enough data points for meaningful statistical analysis. So, how do actuaries go about doing their calculation for the premium of these kinds of insurance given the lack of data points?","Since catastrophes seldom happen, there aren't enough data points for meaningful statistical analysis. So, how do actuaries go about doing their calculation for the premium of these kinds of insurance given the lack of data points?",,"['statistics', 'actuarial-science']"
96,How can you trust a bettor?,How can you trust a bettor?,,"Two friends of mine are trying to convince me that they are good at betting. They infact have a certain profit after n bets. They provided me with all the bets they have made so far: odds, outcome and amount bet. How can I check if their wins are statistically significant or it's just variance that brought them up? Pretend I want to invest some bucks, how can I deterimine how to divide this amount between them? Should I invest more in the one who has the higher ROI (return on investment)? Is there a way to suppose or prove that if they have been winning (if there is statistical significance) they will continue winning at the same rate? Is there a way to monitor their future performances?","Two friends of mine are trying to convince me that they are good at betting. They infact have a certain profit after n bets. They provided me with all the bets they have made so far: odds, outcome and amount bet. How can I check if their wins are statistically significant or it's just variance that brought them up? Pretend I want to invest some bucks, how can I deterimine how to divide this amount between them? Should I invest more in the one who has the higher ROI (return on investment)? Is there a way to suppose or prove that if they have been winning (if there is statistical significance) they will continue winning at the same rate? Is there a way to monitor their future performances?",,['statistics']
97,"What are the different types of ""averages"" and when to use each one?","What are the different types of ""averages"" and when to use each one?",,"So, the concept of an average truly is somewhat abstract. Most statisticians define it as a ""measure of central tendency."" Others say it is the ""center of gravity"" for a set of numbers. I personally prefer a slightly more concrete explanation: A statistic that describes the ""typical"", or better yet, ""representative"" value of a data set. We humans get to decide what ""representative"" actually means. Is it the most common number? The number that falls ""in the middle"" of a set of numbers? Etc. I am going to list a few types of averages and am wondering if someone could provide a data set where that particular average is the best choice for describing a ""typical"" or ""representative"" value for that data set. Types of averages: Arithmetic Mean: The number that you could use in place of each of the values of a data set, and still have the same sum. Formula: $$\overline{X}=\frac1N\sum\limits_{i=1}^{N} X_i$$ Mode: The most common value in a data set. No formula that I know of. Median: The literal middle number of a data set where the values are listed in ascending order. No formula that I know of. Root Mean Square: Don't really know how to describe this average in a physical sense. Maybe the average that gives larger numbers in the data set more ""weight"" or ""significance?"" Formula: $$X_{rms}=\sqrt{\frac1N\sum\limits_{i=1}^{N} X_i^2}$$ Mean Root Square: I just made this one up, but it seems to work well when I applied it to some random data sets. It seems to do the opposite of the RMS and gives smaller numbers in the data set more ""weight"" and ""significance."" Formula: $$X_{mrs}=\frac1N\sqrt{\sum\limits_{i=1}^{N} X_i^2}$$ EDIT: Turns out this should not be considered an average because it fails to describe a data set that consists of only one number, unlike all the other averages. Geometric mean: The number that you could use in place of each of the values of a data set, and still have the same product . Formula: $$GM=\sqrt[N]{\prod\limits_{i=1}^{N} X_i}$$ Feel free to add in any other popular or useful types of averages and when to use them!","So, the concept of an average truly is somewhat abstract. Most statisticians define it as a ""measure of central tendency."" Others say it is the ""center of gravity"" for a set of numbers. I personally prefer a slightly more concrete explanation: A statistic that describes the ""typical"", or better yet, ""representative"" value of a data set. We humans get to decide what ""representative"" actually means. Is it the most common number? The number that falls ""in the middle"" of a set of numbers? Etc. I am going to list a few types of averages and am wondering if someone could provide a data set where that particular average is the best choice for describing a ""typical"" or ""representative"" value for that data set. Types of averages: Arithmetic Mean: The number that you could use in place of each of the values of a data set, and still have the same sum. Formula: $$\overline{X}=\frac1N\sum\limits_{i=1}^{N} X_i$$ Mode: The most common value in a data set. No formula that I know of. Median: The literal middle number of a data set where the values are listed in ascending order. No formula that I know of. Root Mean Square: Don't really know how to describe this average in a physical sense. Maybe the average that gives larger numbers in the data set more ""weight"" or ""significance?"" Formula: $$X_{rms}=\sqrt{\frac1N\sum\limits_{i=1}^{N} X_i^2}$$ Mean Root Square: I just made this one up, but it seems to work well when I applied it to some random data sets. It seems to do the opposite of the RMS and gives smaller numbers in the data set more ""weight"" and ""significance."" Formula: $$X_{mrs}=\frac1N\sqrt{\sum\limits_{i=1}^{N} X_i^2}$$ EDIT: Turns out this should not be considered an average because it fails to describe a data set that consists of only one number, unlike all the other averages. Geometric mean: The number that you could use in place of each of the values of a data set, and still have the same product . Formula: $$GM=\sqrt[N]{\prod\limits_{i=1}^{N} X_i}$$ Feel free to add in any other popular or useful types of averages and when to use them!",,"['statistics', 'average', 'means']"
98,Average percent increase not equal to total percent increase?,Average percent increase not equal to total percent increase?,,"I tried searching around for this but it was difficult to boil down the search terms. Plus nothing seemed to be showing up anyway. What's an easy way to show that the average percentage increase of n numbers will not equal the total percentage increase of the before/after summed n numbers? Yes, one could work out an example but it still doesn't make it apparently clear. I worked out a small example to illustrate my intuition. Initial    %       Final 10         1       10.1 12         2.5     12.3 11         2       11.22  Inital Sum  = 33 Final Sum   = 33.62  Average %   = (% Sum)/ # of %'s             = (1+2.5+2)/3             = 1.833  Total %  Increase    = (Final Sum - Inital Sum) / (Initial Sum) * 100             = (33.62 - 33)/33 * 100             = 1.87879 These percentages are close but not the same. My intuition tells me this is correct but I would like to develope a proof to show this is actually true. Any help/guidance would be greatly appreciated. -- Edit 1 -- My question contains an incorrect premise. I shouldn't be using the average of the percentages. Rather, I should be using the weighted average. Using Excel and this example I was able to generate the total percent increase using the all the percentages. A proof would still be helpful in understanding the problem. -- Edit 2 -- Given initial values $a_k$ and percentages $p_k$, the weighted average for the percentages would be: $$  \frac{\sum_{k=1}^{n} a_k *p_k}{\sum_{k=1}^{n}p_k} $$ Hopefully that's the correct notation. Like I stated in Edit 1, that was pulled from How to calculate weighted averages in Excel .","I tried searching around for this but it was difficult to boil down the search terms. Plus nothing seemed to be showing up anyway. What's an easy way to show that the average percentage increase of n numbers will not equal the total percentage increase of the before/after summed n numbers? Yes, one could work out an example but it still doesn't make it apparently clear. I worked out a small example to illustrate my intuition. Initial    %       Final 10         1       10.1 12         2.5     12.3 11         2       11.22  Inital Sum  = 33 Final Sum   = 33.62  Average %   = (% Sum)/ # of %'s             = (1+2.5+2)/3             = 1.833  Total %  Increase    = (Final Sum - Inital Sum) / (Initial Sum) * 100             = (33.62 - 33)/33 * 100             = 1.87879 These percentages are close but not the same. My intuition tells me this is correct but I would like to develope a proof to show this is actually true. Any help/guidance would be greatly appreciated. -- Edit 1 -- My question contains an incorrect premise. I shouldn't be using the average of the percentages. Rather, I should be using the weighted average. Using Excel and this example I was able to generate the total percent increase using the all the percentages. A proof would still be helpful in understanding the problem. -- Edit 2 -- Given initial values $a_k$ and percentages $p_k$, the weighted average for the percentages would be: $$  \frac{\sum_{k=1}^{n} a_k *p_k}{\sum_{k=1}^{n}p_k} $$ Hopefully that's the correct notation. Like I stated in Edit 1, that was pulled from How to calculate weighted averages in Excel .",,"['statistics', 'finance', 'average']"
99,License Plate Statistics [duplicate],License Plate Statistics [duplicate],,"This question already has answers here : Why are these estimates to the German tank problem different? (2 answers) Closed 4 years ago . California issues license plates in numeric order (if we turn the letters into numbers).  I have fun noticing the latest plate I have seen.  I am interested in what you can derive from a series of these observations.  I understand that sampling from $\{1,2,3...n\}$ the only useful data is the highest value you have seen. Let's oversimplify the problem.  Assume the highest plate issued is $N_0+n*t$, $n$ in plates/day and $t$ in days.  Assume a similar number of low valued plates come off the road each day.  I don't observe a consistent number of plates each day, but it averages out.  Over a long time, the increase in highest plate seen should give a measure of $n$.  The only other data I have is how frequently I see a new highest plate.  Does that give some measure of how far my highest plate is from the highest issued? As we are asked to cite the source of a question, I made it up.  You probably guessed.","This question already has answers here : Why are these estimates to the German tank problem different? (2 answers) Closed 4 years ago . California issues license plates in numeric order (if we turn the letters into numbers).  I have fun noticing the latest plate I have seen.  I am interested in what you can derive from a series of these observations.  I understand that sampling from $\{1,2,3...n\}$ the only useful data is the highest value you have seen. Let's oversimplify the problem.  Assume the highest plate issued is $N_0+n*t$, $n$ in plates/day and $t$ in days.  Assume a similar number of low valued plates come off the road each day.  I don't observe a consistent number of plates each day, but it averages out.  Over a long time, the increase in highest plate seen should give a measure of $n$.  The only other data I have is how frequently I see a new highest plate.  Does that give some measure of how far my highest plate is from the highest issued? As we are asked to cite the source of a question, I made it up.  You probably guessed.",,"['statistics', 'puzzle', 'cryptography']"
