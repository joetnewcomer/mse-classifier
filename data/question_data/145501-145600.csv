,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,How to prove $P(x)=1-\frac{x^2}{2}$ is a good approximation of order $3$ for $f(x)=\cos x$ near $x=0$?,How to prove  is a good approximation of order  for  near ?,P(x)=1-\frac{x^2}{2} 3 f(x)=\cos x x=0,"Let $f$ be a function and we want to approximate $f$ using a different function $P$ near $x=0$. The error of approximation is $E(x)=f(x)-P(x)$. If the approximation is going to be any good, we want  $\lim\limits_{x\rightarrow 0}E(x)=0$. In fact, we want $E(x)$ approaches $0$ fast as $x\rightarrow 0$ Definition for $good \ approximation$: we say that $P$ is a good approximation of order $n$ for $f$ near $x=0$ when $E(x)$ approaches $0$ faster than $h_n(x)=x^n$. Definition for $approache\ 0\ faster$: Assume $\lim\limits_{x\rightarrow 0}f(x)=\lim\limits_{x\rightarrow 0}g(x)=0$. We say $\lim\limits_{x\rightarrow 0}f(x)$ approaches $0$ faster than $g(x)$, as $x\rightarrow 0$, when $\lim\limits_{x\rightarrow 0}\frac{f(x)}{g(x)}=0$. How to prove $P(x)=1-\frac{x^2}{2}$ is a good approximation of order $3$ for $f(x)=\cos x$ near $x=0$? Here is my try: We have $E(x)=f(x)-P(x)=\cos x -1+\frac{x^2}{2}$. Since $E(x)$ and $x^3$ are continuous and $E(0)=0^3=0$, then $\frac{E(x)}{x^3}=\frac{\cos x -1+\frac{x^2}{2}}{x^3}=\frac{\frac{\cos x}{x^2}-\frac{1}{x^2}+\frac{1}{2}}{x}$. Clearly $\lim\limits_{x\rightarrow 0}\frac{E(x)}{x^3}=0$. I think we can conclude that $P$ is a good approximation as $E(x)$ approaches $0$ faster than $x^3$. However I am sure the steps shouldn't be this simple. Could someone help?","Let $f$ be a function and we want to approximate $f$ using a different function $P$ near $x=0$. The error of approximation is $E(x)=f(x)-P(x)$. If the approximation is going to be any good, we want  $\lim\limits_{x\rightarrow 0}E(x)=0$. In fact, we want $E(x)$ approaches $0$ fast as $x\rightarrow 0$ Definition for $good \ approximation$: we say that $P$ is a good approximation of order $n$ for $f$ near $x=0$ when $E(x)$ approaches $0$ faster than $h_n(x)=x^n$. Definition for $approache\ 0\ faster$: Assume $\lim\limits_{x\rightarrow 0}f(x)=\lim\limits_{x\rightarrow 0}g(x)=0$. We say $\lim\limits_{x\rightarrow 0}f(x)$ approaches $0$ faster than $g(x)$, as $x\rightarrow 0$, when $\lim\limits_{x\rightarrow 0}\frac{f(x)}{g(x)}=0$. How to prove $P(x)=1-\frac{x^2}{2}$ is a good approximation of order $3$ for $f(x)=\cos x$ near $x=0$? Here is my try: We have $E(x)=f(x)-P(x)=\cos x -1+\frac{x^2}{2}$. Since $E(x)$ and $x^3$ are continuous and $E(0)=0^3=0$, then $\frac{E(x)}{x^3}=\frac{\cos x -1+\frac{x^2}{2}}{x^3}=\frac{\frac{\cos x}{x^2}-\frac{1}{x^2}+\frac{1}{2}}{x}$. Clearly $\lim\limits_{x\rightarrow 0}\frac{E(x)}{x^3}=0$. I think we can conclude that $P$ is a good approximation as $E(x)$ approaches $0$ faster than $x^3$. However I am sure the steps shouldn't be this simple. Could someone help?",,"['calculus', 'sequences-and-series', 'limits', 'functions', 'error-function']"
1,"""Sandwich"" or ""squeeze"" rule for function 2 variables","""Sandwich"" or ""squeeze"" rule for function 2 variables",,"So let's say I wanted to find $$ \displaystyle \lim_{(x,y) \to  (0,0)}\dfrac{xy^2} {x^2 +y^4} $$ Let's call the function above $f(x,y)$ then  $h(x,y) = 0$ would be a function smaller than $f$ that would work for the sandwich or squeeze rule. What's an easy way to find a function larger than $f(x,y)$ in order to complete the sandwich rule? Is there some specific method? Thanks in advance.","So let's say I wanted to find $$ \displaystyle \lim_{(x,y) \to  (0,0)}\dfrac{xy^2} {x^2 +y^4} $$ Let's call the function above $f(x,y)$ then  $h(x,y) = 0$ would be a function smaller than $f$ that would work for the sandwich or squeeze rule. What's an easy way to find a function larger than $f(x,y)$ in order to complete the sandwich rule? Is there some specific method? Thanks in advance.",,['limits']
2,How to prove $\{a_{n+k}\}^{\infty}_{n=1}$ is convergent and that $\lim\limits_{n\to \infty} a_n=\lim\limits_{n\to \infty} a_{n+k}$?,How to prove  is convergent and that ?,\{a_{n+k}\}^{\infty}_{n=1} \lim\limits_{n\to \infty} a_n=\lim\limits_{n\to \infty} a_{n+k},"Let $\{a_{n}\}^{\infty}_{n=1}$ be a sequence of real numbers and let $k$ be a fixed natural number. If $\{a_{n}\}^{\infty}_{n=1}$ is convergent, how to prove $\{a_{n+k}\}^{\infty}_{n=1}$ is convergent and that $\lim\limits_{n\to \infty} a_n=\lim\limits_{n\to \infty} a_{n+k}$. In my opinion, if $\{a_{n}\}^{\infty}_{n=1}$ is convergent, then $\forall\epsilon\gt 0, \exists N\in \Bbb{Z}^+$ such that if $N\le n$, then $|a_n-L|\lt \epsilon$. I think we can assume the condition to be true and say $\forall\epsilon_1\gt 0, \exists N_1\in \Bbb{Z}^+$ such that if $N_1-k\le n$ (since $k$ is natural number), then $N_1\le n+k$, then $|a_{n+k}-L_1|\lt \epsilon_1$. But I don't see it as a complete proof. Could someone give a clear one?","Let $\{a_{n}\}^{\infty}_{n=1}$ be a sequence of real numbers and let $k$ be a fixed natural number. If $\{a_{n}\}^{\infty}_{n=1}$ is convergent, how to prove $\{a_{n+k}\}^{\infty}_{n=1}$ is convergent and that $\lim\limits_{n\to \infty} a_n=\lim\limits_{n\to \infty} a_{n+k}$. In my opinion, if $\{a_{n}\}^{\infty}_{n=1}$ is convergent, then $\forall\epsilon\gt 0, \exists N\in \Bbb{Z}^+$ such that if $N\le n$, then $|a_n-L|\lt \epsilon$. I think we can assume the condition to be true and say $\forall\epsilon_1\gt 0, \exists N_1\in \Bbb{Z}^+$ such that if $N_1-k\le n$ (since $k$ is natural number), then $N_1\le n+k$, then $|a_{n+k}-L_1|\lt \epsilon_1$. But I don't see it as a complete proof. Could someone give a clear one?",,"['calculus', 'sequences-and-series', 'limits', 'elementary-number-theory', 'epsilon-delta']"
3,Is it legal to substitute the limit variable in a question like this?,Is it legal to substitute the limit variable in a question like this?,,"The question: Find the derivative of $f(x) = x^{-1}$ You can write down the derivative (Using limits) as $\lim_{h\to 0} \frac{f(x+h)-f(x)}{h}$ $\lim_{h\to 0} \frac{(x+h)^{-1}-x^{-1}}{h}$ $\lim_{(x+h)\to x} \frac{(x+h)^{-1}-x^{-1}}{(x+h) - (x)}$ As you can see, i switch the variable in the limit above. Is that legal? What is the formula behind the switch? What are the formal requirements for it to be legal?","The question: Find the derivative of $f(x) = x^{-1}$ You can write down the derivative (Using limits) as $\lim_{h\to 0} \frac{f(x+h)-f(x)}{h}$ $\lim_{h\to 0} \frac{(x+h)^{-1}-x^{-1}}{h}$ $\lim_{(x+h)\to x} \frac{(x+h)^{-1}-x^{-1}}{(x+h) - (x)}$ As you can see, i switch the variable in the limit above. Is that legal? What is the formula behind the switch? What are the formal requirements for it to be legal?",,"['limits', 'derivatives']"
4,"Find $\lim_{n \rightarrow \infty} \int_0^n (1+ \frac{x}{n})^{n+1} \exp(-2x) \, dx$",Find,"\lim_{n \rightarrow \infty} \int_0^n (1+ \frac{x}{n})^{n+1} \exp(-2x) \, dx","Find: $$\lim_{n \rightarrow \infty} \int_0^n \left(1+ \frac{x}{n}\right)^{n+1} \exp(-2x) \, dx$$ The sequence $\left(1+ \frac{x}{n}\right)^{n+1} \exp{(-2x)}$ converges pointwise to $\exp{(-x)}$. So if we could apply Lebesgue's monotone convergence theorem, we have: \begin{align} \lim_{n \rightarrow \infty} \int_0^n \left(1+ \frac{x}{n}\right)^{n+1} \exp(-2x) \, dx &=\lim_{n \rightarrow \infty} \int_{\mathbb{R}} I_{(0,n)(x)} \left(1+ \frac{x}{n}\right)^{n+1} \exp(-2x) \, dx \\[10pt] &= {} \int_{- \infty}^\infty \exp(-x) \, dx= +\infty \end{align} Can someone help me to prove that the sequence of integrands is monotone?","Find: $$\lim_{n \rightarrow \infty} \int_0^n \left(1+ \frac{x}{n}\right)^{n+1} \exp(-2x) \, dx$$ The sequence $\left(1+ \frac{x}{n}\right)^{n+1} \exp{(-2x)}$ converges pointwise to $\exp{(-x)}$. So if we could apply Lebesgue's monotone convergence theorem, we have: \begin{align} \lim_{n \rightarrow \infty} \int_0^n \left(1+ \frac{x}{n}\right)^{n+1} \exp(-2x) \, dx &=\lim_{n \rightarrow \infty} \int_{\mathbb{R}} I_{(0,n)(x)} \left(1+ \frac{x}{n}\right)^{n+1} \exp(-2x) \, dx \\[10pt] &= {} \int_{- \infty}^\infty \exp(-x) \, dx= +\infty \end{align} Can someone help me to prove that the sequence of integrands is monotone?",,"['integration', 'limits', 'lebesgue-integral']"
5,Calculate the limit of $\lim _{x\to 0}\left(\frac{1-\frac{\left(1+x\right)^{\frac{1}{x}}}{e}}{x}\right)$,Calculate the limit of,\lim _{x\to 0}\left(\frac{1-\frac{\left(1+x\right)^{\frac{1}{x}}}{e}}{x}\right),"I have to calcuate this limit: $$\lim _{x\to 0}\left(\frac{1-\frac{\left(1+x\right)^{\frac{1}{x}}}{e}}{x}\right)$$ I have no idea how to start, maybe taylor series? Thanks.","I have to calcuate this limit: $$\lim _{x\to 0}\left(\frac{1-\frac{\left(1+x\right)^{\frac{1}{x}}}{e}}{x}\right)$$ I have no idea how to start, maybe taylor series? Thanks.",,"['limits', 'taylor-expansion']"
6,Closed form for this $\text{I}=\int_{1}^{\infty}\frac{1}{\pi^{nx}-1}\space\text{d}x$ integral? (spot my mistake),Closed form for this  integral? (spot my mistake),\text{I}=\int_{1}^{\infty}\frac{1}{\pi^{nx}-1}\space\text{d}x,"Solving this question , I came up with this (but mathematica says, there isn't a closed form) can someone spot my mistake? My work: Assume that $m$ and $n$ are positive $\to m,n\in\mathbb{R^+}$: $$\text{I}=\int_{1}^{\infty}\frac{1}{\pi^{nx}-1}\space\text{d}x=$$ $$\lim_{m\to\infty}\int_{1}^{m}\frac{1}{\pi^{nx}-1}\space\text{d}x=$$ Substitute $u=nx$ and $\text{d}u=n\space\text{d}x$: This gives a new lower bound $u=n\cdot1=n$ and upper bound $u=n\cdot m=mn$: $$\lim_{m\to\infty}\frac{1}{n}\int_{n}^{mn}\frac{1}{\pi^{u}-1}\space\text{d}u=$$ Substitute $s=\pi^u$ and $\text{d}s=\pi^u\ln(\pi)\space\text{d}u$: This gives a new lower bound $s=\pi^{n}$ and upper bound $s=\pi^{mn}$: $$\lim_{m\to\infty}\frac{1}{n\ln(\pi)}\int_{\pi^{n}}^{\pi^{mn}}\frac{1}{s(s-1)}\space\text{d}s=$$ $$\lim_{m\to\infty}\frac{1}{n\ln(\pi)}\int_{\pi^{n}}^{\pi^{mn}}\left(\frac{1}{s-1}-\frac{1}{s}\right)\space\text{d}s=$$ $$\lim_{m\to\infty}\frac{1}{n\ln(\pi)}\left(\int_{\pi^{n}}^{\pi^{mn}}\frac{1}{s-1}\space\text{d}s-\int_{\pi^{n}}^{\pi^{mn}}\frac{1}{s}\space\text{d}s\right)=$$ $$\lim_{m\to\infty}\frac{1}{n\ln(\pi)}\left(\int_{\pi^{n}}^{\pi^{mn}}\frac{1}{s-1}\space\text{d}s-\left[\ln\left|s\right|\right]_{\pi^{n}}^{\pi^{mn}}\right)=$$ Substitute $p=s-1$ and $\text{d}p=\text{d}s$: This gives a new lower bound $p=\pi^{n}-1$ and upper bound $p=\pi^{mn}-1$: $$\lim_{m\to\infty}\frac{1}{n\ln(\pi)}\left(\int_{\pi^{n}-1}^{\pi^{mn}-1}\frac{1}{p}\space\text{d}p-\left[\ln\left|s\right|\right]_{\pi^{n}}^{\pi^{mn}}\right)=$$ $$\lim_{m\to\infty}\frac{1}{n\ln(\pi)}\left(\left[\ln\left|p\right|\right]_{\pi^{n}-1}^{\pi^{mn}-1}-\left[\ln\left|s\right|\right]_{\pi^{n}}^{\pi^{mn}}\right)=$$ $$\lim_{m\to\infty}\frac{\ln\left|\pi^{mn}-1\right|-\ln\left|\pi^{n}-1\right|-\ln\left|\pi^{mn}\right|+\ln\left|\pi^{n}\right|}{n\ln(\pi)}=$$ $$\frac{1}{n\ln(\pi)}\lim_{m\to\infty}\left(\ln\left|\pi^{mn}-1\right|-\ln\left|\pi^{n}-1\right|-\ln\left|\pi^{mn}\right|+\ln\left|\pi^{n}\right|\right)=$$ $$\frac{1}{n\ln(\pi)}\lim_{m\to\infty}\ln\left(\frac{\pi^n-\pi^{n-mn}}{\pi^n-1}\right)=\frac{\ln\left(1+\frac{1}{\pi^n-1}\right)}{n\ln(\pi)}$$","Solving this question , I came up with this (but mathematica says, there isn't a closed form) can someone spot my mistake? My work: Assume that $m$ and $n$ are positive $\to m,n\in\mathbb{R^+}$: $$\text{I}=\int_{1}^{\infty}\frac{1}{\pi^{nx}-1}\space\text{d}x=$$ $$\lim_{m\to\infty}\int_{1}^{m}\frac{1}{\pi^{nx}-1}\space\text{d}x=$$ Substitute $u=nx$ and $\text{d}u=n\space\text{d}x$: This gives a new lower bound $u=n\cdot1=n$ and upper bound $u=n\cdot m=mn$: $$\lim_{m\to\infty}\frac{1}{n}\int_{n}^{mn}\frac{1}{\pi^{u}-1}\space\text{d}u=$$ Substitute $s=\pi^u$ and $\text{d}s=\pi^u\ln(\pi)\space\text{d}u$: This gives a new lower bound $s=\pi^{n}$ and upper bound $s=\pi^{mn}$: $$\lim_{m\to\infty}\frac{1}{n\ln(\pi)}\int_{\pi^{n}}^{\pi^{mn}}\frac{1}{s(s-1)}\space\text{d}s=$$ $$\lim_{m\to\infty}\frac{1}{n\ln(\pi)}\int_{\pi^{n}}^{\pi^{mn}}\left(\frac{1}{s-1}-\frac{1}{s}\right)\space\text{d}s=$$ $$\lim_{m\to\infty}\frac{1}{n\ln(\pi)}\left(\int_{\pi^{n}}^{\pi^{mn}}\frac{1}{s-1}\space\text{d}s-\int_{\pi^{n}}^{\pi^{mn}}\frac{1}{s}\space\text{d}s\right)=$$ $$\lim_{m\to\infty}\frac{1}{n\ln(\pi)}\left(\int_{\pi^{n}}^{\pi^{mn}}\frac{1}{s-1}\space\text{d}s-\left[\ln\left|s\right|\right]_{\pi^{n}}^{\pi^{mn}}\right)=$$ Substitute $p=s-1$ and $\text{d}p=\text{d}s$: This gives a new lower bound $p=\pi^{n}-1$ and upper bound $p=\pi^{mn}-1$: $$\lim_{m\to\infty}\frac{1}{n\ln(\pi)}\left(\int_{\pi^{n}-1}^{\pi^{mn}-1}\frac{1}{p}\space\text{d}p-\left[\ln\left|s\right|\right]_{\pi^{n}}^{\pi^{mn}}\right)=$$ $$\lim_{m\to\infty}\frac{1}{n\ln(\pi)}\left(\left[\ln\left|p\right|\right]_{\pi^{n}-1}^{\pi^{mn}-1}-\left[\ln\left|s\right|\right]_{\pi^{n}}^{\pi^{mn}}\right)=$$ $$\lim_{m\to\infty}\frac{\ln\left|\pi^{mn}-1\right|-\ln\left|\pi^{n}-1\right|-\ln\left|\pi^{mn}\right|+\ln\left|\pi^{n}\right|}{n\ln(\pi)}=$$ $$\frac{1}{n\ln(\pi)}\lim_{m\to\infty}\left(\ln\left|\pi^{mn}-1\right|-\ln\left|\pi^{n}-1\right|-\ln\left|\pi^{mn}\right|+\ln\left|\pi^{n}\right|\right)=$$ $$\frac{1}{n\ln(\pi)}\lim_{m\to\infty}\ln\left(\frac{\pi^n-\pi^{n-mn}}{\pi^n-1}\right)=\frac{\ln\left(1+\frac{1}{\pi^n-1}\right)}{n\ln(\pi)}$$",,"['integration', 'limits']"
7,When does $\log(\lim_{x\to c} f(x)) = \lim_{x\to c} \log(f(x))$?,When does ?,\log(\lim_{x\to c} f(x)) = \lim_{x\to c} \log(f(x)),"When does $$\log(\lim_{x\to c} f(x)) = \lim_{x\to c} \log(f(x))$$ I have seen different things from different sources. For example, this and this . Does $f(x)$ have to be continuous at c, does $\log (f(x))$ have to be continuous at c, or something else?","When does $$\log(\lim_{x\to c} f(x)) = \lim_{x\to c} \log(f(x))$$ I have seen different things from different sources. For example, this and this . Does $f(x)$ have to be continuous at c, does $\log (f(x))$ have to be continuous at c, or something else?",,"['real-analysis', 'limits', 'continuity', 'logarithms']"
8,To prove the limit of $\frac{x^2+2\cos x-2}{x\sin^3 x}$ at zero is $1/12$,To prove the limit of  at zero is,\frac{x^2+2\cos x-2}{x\sin^3 x} 1/12,To Prove $$\lim_{x \to 0}\frac{x^2+2\cos x-2}{x\sin^3 x}=\frac{1}{12}$$ I tried with L'Hospital rule but in vain.,To Prove $$\lim_{x \to 0}\frac{x^2+2\cos x-2}{x\sin^3 x}=\frac{1}{12}$$ I tried with L'Hospital rule but in vain.,,['limits']
9,Evaluate $\lim_\limits{x \to 0} (1 +\sin^2 x)^{\frac{1}{\ln(\cos x)}}$,Evaluate,\lim_\limits{x \to 0} (1 +\sin^2 x)^{\frac{1}{\ln(\cos x)}},$$\lim_{x \to 0} (1 + \sin^2 x)^{\frac{1}{\ln(\cos x)}}$$ I evaluated $\sin$ and $\cos x$ but what can be done with $\ln\left(1-\frac{x^2}{2}\right)$ or $\ln\left(\frac{2 - x^2}{2}\right)$? Assume that L'Hopital is forbidden but you can use asymptotic simplifications like big and small $o$ notations and Taylor series.,$$\lim_{x \to 0} (1 + \sin^2 x)^{\frac{1}{\ln(\cos x)}}$$ I evaluated $\sin$ and $\cos x$ but what can be done with $\ln\left(1-\frac{x^2}{2}\right)$ or $\ln\left(\frac{2 - x^2}{2}\right)$? Assume that L'Hopital is forbidden but you can use asymptotic simplifications like big and small $o$ notations and Taylor series.,,"['calculus', 'limits', 'limits-without-lhopital']"
10,Evaluating $\lim_\limits{x\to 1 }\bigl( (2^x x + 1)/(3^x x)\bigr)^{\tan(\pi x/2)}$,Evaluating,\lim_\limits{x\to 1 }\bigl( (2^x x + 1)/(3^x x)\bigr)^{\tan(\pi x/2)},"I have to calculate limit  $$\lim_{x\to 1 } \left(\frac{2^x x + 1}{3^x x}\right)^{\tan(\frac{\pi x}{2})}.$$ I know $\tan(\frac{\pi x}{2})$ is undefined in $x = 1$, but can I just put $x = 1$ into $\frac{x\cdot 2^x + 1}{x\cdot3^x}$ and get  $$\lim_{x\to 1 } (1)^{\tan(\frac{\pi x}{2})} = 1.$$  Is the answer $1$ correct? It's forbidden to use L'Hôpital's rule.","I have to calculate limit  $$\lim_{x\to 1 } \left(\frac{2^x x + 1}{3^x x}\right)^{\tan(\frac{\pi x}{2})}.$$ I know $\tan(\frac{\pi x}{2})$ is undefined in $x = 1$, but can I just put $x = 1$ into $\frac{x\cdot 2^x + 1}{x\cdot3^x}$ and get  $$\lim_{x\to 1 } (1)^{\tan(\frac{\pi x}{2})} = 1.$$  Is the answer $1$ correct? It's forbidden to use L'Hôpital's rule.",,['limits']
11,Evaluate $\lim_{x\rightarrow\infty}\left(\Gamma\left(1/x\right)\right)^{-1}\int_{0}^{x}\frac{|\sin\left(t\right)|}{t}\:dt$,Evaluate,\lim_{x\rightarrow\infty}\left(\Gamma\left(1/x\right)\right)^{-1}\int_{0}^{x}\frac{|\sin\left(t\right)|}{t}\:dt,This is a problem from Widder's Advanced Calculus (p. 9 chapter 11 $\S$1.4) I'm having trouble evaluating. Could I have a hint? \begin{align}\lim_{x\rightarrow\infty}\left(\Gamma\left(1/x\right)\right)^{-1}\int_{0}^{x}\frac{|\sin\left(t\right)|}{t}\:dt&\overset{?}{=}\end{align} I don't exactly know where to start.,This is a problem from Widder's Advanced Calculus (p. 9 chapter 11 $\S$1.4) I'm having trouble evaluating. Could I have a hint? \begin{align}\lim_{x\rightarrow\infty}\left(\Gamma\left(1/x\right)\right)^{-1}\int_{0}^{x}\frac{|\sin\left(t\right)|}{t}\:dt&\overset{?}{=}\end{align} I don't exactly know where to start.,,"['limits', 'definite-integrals', 'gamma-function']"
12,Find these limits using l'Hopital's rule,Find these limits using l'Hopital's rule,,"I could use some help solving these 2 problems. I've finished the rest, I just need help on these two. I know I'm supposed to use natural log and l'hopitals rule. As the $x$ goes to $0$, find the limit of $\tan(x)^{\sin(x)}$. As the $x$ goes to infinity, find the limit of $(e^x+x)^{1/x}$ I tried to use natural log for both of these and got no where. What am I missing? I appreciate any input. It's very much needed.","I could use some help solving these 2 problems. I've finished the rest, I just need help on these two. I know I'm supposed to use natural log and l'hopitals rule. As the $x$ goes to $0$, find the limit of $\tan(x)^{\sin(x)}$. As the $x$ goes to infinity, find the limit of $(e^x+x)^{1/x}$ I tried to use natural log for both of these and got no where. What am I missing? I appreciate any input. It's very much needed.",,"['calculus', 'limits']"
13,Does $\lim \frac{f(x)}{g(x)}=1$ tell us anything about $\lim f(x)-g(x)$ or vice versa?,Does  tell us anything about  or vice versa?,\lim \frac{f(x)}{g(x)}=1 \lim f(x)-g(x),"This is not homework or anything, but I just had a random idea and I'm not really sure where to go with it. The equations: $$ \lim_{x \to \infty} \frac{f(x)}{g(x)}=1$$ $$ \lim_{x \to \infty} f(x)-g(x) = 0$$ Are both ways of roughly saying that as $x$ gets really large, $f(x)$ and $g(x)$ get really close to each other. My question is, do either of these statements imply the other? By taking logs of the first equation, we can see that it implies  $$\lim_{x \to \infty} \log(f(x))-\log(g(x))=0$$,  and by exponentiating the second equation, we get that $$\lim_{x \to \infty} \frac{e^{f(x)}}{e^{g(x)}}=1$$ Other than that, I haven't really noticed anything. Anybody have any insight?","This is not homework or anything, but I just had a random idea and I'm not really sure where to go with it. The equations: $$ \lim_{x \to \infty} \frac{f(x)}{g(x)}=1$$ $$ \lim_{x \to \infty} f(x)-g(x) = 0$$ Are both ways of roughly saying that as $x$ gets really large, $f(x)$ and $g(x)$ get really close to each other. My question is, do either of these statements imply the other? By taking logs of the first equation, we can see that it implies  $$\lim_{x \to \infty} \log(f(x))-\log(g(x))=0$$,  and by exponentiating the second equation, we get that $$\lim_{x \to \infty} \frac{e^{f(x)}}{e^{g(x)}}=1$$ Other than that, I haven't really noticed anything. Anybody have any insight?",,"['real-analysis', 'limits']"
14,How to show that $x_{n+1} = \frac{1}{3}(2 x_n + \frac{a}{x_n^2})$ has an upper bound?,How to show that  has an upper bound?,x_{n+1} = \frac{1}{3}(2 x_n + \frac{a}{x_n^2}),Let $x_n>0$ and $x_{n+1} = \frac{1}{3}(2 x_n + \frac{a}{x_n^2})$. We need to compute the $\lim_{n \to \infty} x_n $. My solution: suppose that the limit exists. Then we have $\lim_{n \to \infty} x_n = a^{1/3}$ by taking limits in both sides of $x_{n+1} = \frac{1}{3}(2 x_n + \frac{a}{x_n^2})$. Now we need to show that the limit exists. We have $x_{n+1} - x_n = \frac{1}{3}(-x_n + \frac{a}{x_n^2}) \geq 0$ if  $0 < x_n \leq a^{1/3}$. Therefore we only need to show that $0 < x_n \leq a^{1/3}$. But I have some difficulty in showing that $0 < x_n \leq a^{1/3}$. How to show that $0 < x_n \leq a^{1/3}$? Thank you very much.,Let $x_n>0$ and $x_{n+1} = \frac{1}{3}(2 x_n + \frac{a}{x_n^2})$. We need to compute the $\lim_{n \to \infty} x_n $. My solution: suppose that the limit exists. Then we have $\lim_{n \to \infty} x_n = a^{1/3}$ by taking limits in both sides of $x_{n+1} = \frac{1}{3}(2 x_n + \frac{a}{x_n^2})$. Now we need to show that the limit exists. We have $x_{n+1} - x_n = \frac{1}{3}(-x_n + \frac{a}{x_n^2}) \geq 0$ if  $0 < x_n \leq a^{1/3}$. Therefore we only need to show that $0 < x_n \leq a^{1/3}$. But I have some difficulty in showing that $0 < x_n \leq a^{1/3}$. How to show that $0 < x_n \leq a^{1/3}$? Thank you very much.,,"['calculus', 'limits']"
15,"Find $\lim\limits_{(x,y)\to(0,0)}\frac{e^{x^2+y^2}-x^2-y^2-1}{(x^2+y^2)^2}$",Find,"\lim\limits_{(x,y)\to(0,0)}\frac{e^{x^2+y^2}-x^2-y^2-1}{(x^2+y^2)^2}","We have to calculate this limit of the multivariable function: $$\lim\limits_{(x,y)\to(0,0)}\frac{e^{x^2+y^2}-x^2-y^2-1}{(x^2+y^2)^2}$$ By setting $z=x^2+y^2$ then $z\to 0$ when $(x,y)\to(0,0)$, so if we apply de l'Hopital's rule twice, we find that the limit is equal to $\frac{1}{2}$. Now, I'm trying to calculate it by using the Squeeze Theorem (I've tried by using the ε-δ definition, without a result). My thoughts so far: I have tried to use the inequality $(x^2+y^2)^2\geq 2x^2y^2$ in order to overcome the problem that the denominator=0 and after some algebraic manipulation I can't get a result. Another thing I've tried is to use polar coordinates, but it doesn't seem to give an inequality. What can I do? Thanks in advance!","We have to calculate this limit of the multivariable function: $$\lim\limits_{(x,y)\to(0,0)}\frac{e^{x^2+y^2}-x^2-y^2-1}{(x^2+y^2)^2}$$ By setting $z=x^2+y^2$ then $z\to 0$ when $(x,y)\to(0,0)$, so if we apply de l'Hopital's rule twice, we find that the limit is equal to $\frac{1}{2}$. Now, I'm trying to calculate it by using the Squeeze Theorem (I've tried by using the ε-δ definition, without a result). My thoughts so far: I have tried to use the inequality $(x^2+y^2)^2\geq 2x^2y^2$ in order to overcome the problem that the denominator=0 and after some algebraic manipulation I can't get a result. Another thing I've tried is to use polar coordinates, but it doesn't seem to give an inequality. What can I do? Thanks in advance!",,"['calculus', 'limits']"
16,Evaluate the limit without using the L'Hôpital's rule,Evaluate the limit without using the L'Hôpital's rule,,$$\lim_{x\to 0}\frac{\sqrt[5]{1+\sin(x)}-1}{\ln(1+\tan(x))}$$ How to evaluate the limit of this function without using L'Hôpital's rule?,$$\lim_{x\to 0}\frac{\sqrt[5]{1+\sin(x)}-1}{\ln(1+\tan(x))}$$ How to evaluate the limit of this function without using L'Hôpital's rule?,,['limits']
17,"What happens to $f(x,y) = \frac{|x|^{\alpha}y}{x^4 + y^2}$ as $(x,y) \rightarrow (0,0)$.",What happens to  as .,"f(x,y) = \frac{|x|^{\alpha}y}{x^4 + y^2} (x,y) \rightarrow (0,0)","As in the title I want to study what happens to $f(x,y)$ as $(x,y) \rightarrow (0,0)$. Where $f: R^2 \setminus \{(0,0) \} \rightarrow R$ $$f(x,y) = \frac{|x|^{\alpha}y}{x^4 + y^2} $$ A useful theorem I have been using is: Let $A \subset R^n, f:A\rightarrow R$ and let $x_0$ be an accumulation point of $A$. Then the limit $\lim_{x \rightarrow x_0} f(x) = l \in \bar{R}$ if and only if $\forall{B} \subset A$ s.t. $x_0$ is an accumulation point of $B$ we have $\lim_{x \rightarrow x_0} f|_B(x) = l$. So if I restrict the function domain to all $ x = y$ I get $$f(x,y) = \frac{|x|^{\alpha+1}}{x^{4} + x^2} = x^{\alpha -1}(1 + o(1))$$ this is 1 if $\alpha = 1$, $0$ if $\alpha> 1 $ and it goes to infinity if $\alpha <1$. So now I know that for $\alpha <1$ the function does not converge in $R^2$ correct? Then I notice that near $x = 0$ $$0 \le |f(x,y)| \le \frac{||(x,y)||^{1+\alpha}}{x^4+y^4} \le \frac{1}{c} ||(x,y)||^{\alpha -3}$$ by an euclidean distance inequality so the function converges for $\alpha>3$. But what happens for $1 \le \alpha \le 3 $?","As in the title I want to study what happens to $f(x,y)$ as $(x,y) \rightarrow (0,0)$. Where $f: R^2 \setminus \{(0,0) \} \rightarrow R$ $$f(x,y) = \frac{|x|^{\alpha}y}{x^4 + y^2} $$ A useful theorem I have been using is: Let $A \subset R^n, f:A\rightarrow R$ and let $x_0$ be an accumulation point of $A$. Then the limit $\lim_{x \rightarrow x_0} f(x) = l \in \bar{R}$ if and only if $\forall{B} \subset A$ s.t. $x_0$ is an accumulation point of $B$ we have $\lim_{x \rightarrow x_0} f|_B(x) = l$. So if I restrict the function domain to all $ x = y$ I get $$f(x,y) = \frac{|x|^{\alpha+1}}{x^{4} + x^2} = x^{\alpha -1}(1 + o(1))$$ this is 1 if $\alpha = 1$, $0$ if $\alpha> 1 $ and it goes to infinity if $\alpha <1$. So now I know that for $\alpha <1$ the function does not converge in $R^2$ correct? Then I notice that near $x = 0$ $$0 \le |f(x,y)| \le \frac{||(x,y)||^{1+\alpha}}{x^4+y^4} \le \frac{1}{c} ||(x,y)||^{\alpha -3}$$ by an euclidean distance inequality so the function converges for $\alpha>3$. But what happens for $1 \le \alpha \le 3 $?",,"['real-analysis', 'limits', 'multivariable-calculus']"
18,Prove $\lim_{a \to \infty} \frac{3a+2}{5a+4}= \frac35$ using definition of limit,Prove  using definition of limit,\lim_{a \to \infty} \frac{3a+2}{5a+4}= \frac35,Prove the limit using  definition of limit$$ \ \lim_{a \to \infty}\ \frac{3a+2}{5a+4}= \frac{3}{5} $$ Answer: Let $\varepsilon \ >0 $. We want to obtain the inequality $$\left|\frac{3a+2}{5a+4}- \frac{3}{5}\right|< {\varepsilon}$$ $$ \Rightarrow \left|\frac{3a+2}{5a+4} - \frac{3}{5}\right|\ =\left|\frac{5(3a+2)-3(5a+4)}{5(5a+4)}\right|\\= \left|\frac{-2}{5(5a+4)}\right|\le\frac{1}{a} $$  Therefore we choose $K \in N$ s.t $K> \frac{1}{\varepsilon} $  $$\Rightarrow\left|\frac{3a+2}{5a+4}- \frac{3}{5}\right| \le\frac{1}{a}\le\frac{1}{K} < \varepsilon $$ Is this correct?,Prove the limit using  definition of limit$$ \ \lim_{a \to \infty}\ \frac{3a+2}{5a+4}= \frac{3}{5} $$ Answer: Let $\varepsilon \ >0 $. We want to obtain the inequality $$\left|\frac{3a+2}{5a+4}- \frac{3}{5}\right|< {\varepsilon}$$ $$ \Rightarrow \left|\frac{3a+2}{5a+4} - \frac{3}{5}\right|\ =\left|\frac{5(3a+2)-3(5a+4)}{5(5a+4)}\right|\\= \left|\frac{-2}{5(5a+4)}\right|\le\frac{1}{a} $$  Therefore we choose $K \in N$ s.t $K> \frac{1}{\varepsilon} $  $$\Rightarrow\left|\frac{3a+2}{5a+4}- \frac{3}{5}\right| \le\frac{1}{a}\le\frac{1}{K} < \varepsilon $$ Is this correct?,,"['real-analysis', 'limits', 'proof-verification', 'epsilon-delta']"
19,Integrable slowly varying function,Integrable slowly varying function,,"We say a function $L$ is slowly varying if $$\lim_{t\to\infty} \frac{L(tx)}{L(t)} = 1$$ for every $x > 0$. Are there such $L$ that are integrable? Say $L$ is defined on $[0,\infty)$ and is continuous with $\lim\limits_{t\to\infty}L(t) = 0?$ I'm thinking of $L$ as the tail distribution of some non-negative random variable.","We say a function $L$ is slowly varying if $$\lim_{t\to\infty} \frac{L(tx)}{L(t)} = 1$$ for every $x > 0$. Are there such $L$ that are integrable? Say $L$ is defined on $[0,\infty)$ and is continuous with $\lim\limits_{t\to\infty}L(t) = 0?$ I'm thinking of $L$ as the tail distribution of some non-negative random variable.",,"['integration', 'limits', 'laplace-transform', 'limsup-and-liminf', 'distribution-tails']"
20,Integral $\int_1^2 \frac1x dx$ with a Riemann sum.,Integral  with a Riemann sum.,\int_1^2 \frac1x dx,"How do you find the $$ \int \dfrac{1}{x} dx$$ by using the idea of a limit of a Riemann sum on the interval [1,2]? I tried splitting the interval into a geometric progression and evaluating the Riemann sum, but i cant simplify the expression at this stage.","How do you find the $$ \int \dfrac{1}{x} dx$$ by using the idea of a limit of a Riemann sum on the interval [1,2]? I tried splitting the interval into a geometric progression and evaluating the Riemann sum, but i cant simplify the expression at this stage.",,"['calculus', 'integration', 'sequences-and-series', 'limits', 'definite-integrals']"
21,Limits at Infinity proof,Limits at Infinity proof,,"The problem is prove the limit using definition 6,  $$\lim_{x\rightarrow-3} \frac{1}{(x+3)^4} = \infty$$ The book gives definition 6 as: Let $f$ be a function defined on some open interval that contains $a$, except possibly at $a$ itself. Then $\lim_{x\rightarrow a} f(x) = \infty$ means that for every positive number $E$ there is a positive number $\delta$ such that $0 <|x-a| < \delta$ then $f(x) > E$. Can you please explain it step by step all the way to the answer? Thank you.","The problem is prove the limit using definition 6,  $$\lim_{x\rightarrow-3} \frac{1}{(x+3)^4} = \infty$$ The book gives definition 6 as: Let $f$ be a function defined on some open interval that contains $a$, except possibly at $a$ itself. Then $\lim_{x\rightarrow a} f(x) = \infty$ means that for every positive number $E$ there is a positive number $\delta$ such that $0 <|x-a| < \delta$ then $f(x) > E$. Can you please explain it step by step all the way to the answer? Thank you.",,"['calculus', 'limits', 'infinity']"
22,Find $\mathop {\lim }\limits_{x \to \infty } (\sqrt[3]{{{x^3} + 5{x^2}}} - \sqrt {{x^2} - 2x} ) $,Find,\mathop {\lim }\limits_{x \to \infty } (\sqrt[3]{{{x^3} + 5{x^2}}} - \sqrt {{x^2} - 2x} ) ,"$$\mathop {\lim }\limits_{x \to \infty } (\sqrt[3]{{{x^3} + 5{x^2}}} - \sqrt {{x^2} - 2x} ) $$ My try: $${a^3} - {b^3} = (a - b)({a^2} + ab + {b^2}) $$ $$\mathop {\lim }\limits_{x \to \infty } \frac{{(\sqrt[3]{{{x^3} + 5{x^2}}} - \sqrt {{x^2} - 2x} )(\sqrt[{\frac{3}{2}}]{{{x^3} + 5{x^2}}} + \sqrt[3]{{{x^3} + 5{x^2}}}\sqrt {{x^2} - 2x}  + {x^2} - 2x)}}{{(\sqrt[{\frac{3}{2}}]{{{x^3} + 5{x^2}}} + \sqrt[3]{{{x^3} + 5{x^2}}}\sqrt {{x^2} - 2x}  + {x^2} - 2x)}} =  $$ $$\mathop {\lim }\limits_{x \to \infty } \frac{{{x^3} + 5{x^2} - {x^2} - 2x}}{{(\sqrt[{\frac{3}{2}}]{{{x^3} + 5{x^2}}} + \sqrt[3]{{{x^3} + 5{x^2}}}\sqrt {{x^2} - 2x}  + {x^2} - 2x)}} $$ And what's next...? This task in first and second remarkable limits. I think i can replace variable, but how i will calculate it...","$$\mathop {\lim }\limits_{x \to \infty } (\sqrt[3]{{{x^3} + 5{x^2}}} - \sqrt {{x^2} - 2x} ) $$ My try: $${a^3} - {b^3} = (a - b)({a^2} + ab + {b^2}) $$ $$\mathop {\lim }\limits_{x \to \infty } \frac{{(\sqrt[3]{{{x^3} + 5{x^2}}} - \sqrt {{x^2} - 2x} )(\sqrt[{\frac{3}{2}}]{{{x^3} + 5{x^2}}} + \sqrt[3]{{{x^3} + 5{x^2}}}\sqrt {{x^2} - 2x}  + {x^2} - 2x)}}{{(\sqrt[{\frac{3}{2}}]{{{x^3} + 5{x^2}}} + \sqrt[3]{{{x^3} + 5{x^2}}}\sqrt {{x^2} - 2x}  + {x^2} - 2x)}} =  $$ $$\mathop {\lim }\limits_{x \to \infty } \frac{{{x^3} + 5{x^2} - {x^2} - 2x}}{{(\sqrt[{\frac{3}{2}}]{{{x^3} + 5{x^2}}} + \sqrt[3]{{{x^3} + 5{x^2}}}\sqrt {{x^2} - 2x}  + {x^2} - 2x)}} $$ And what's next...? This task in first and second remarkable limits. I think i can replace variable, but how i will calculate it...",,"['calculus', 'limits']"
23,A few intro questions about limits,A few intro questions about limits,,"I'm a first year university student and it is my first time posting on the forum so if I have posted incorrectly please let me know and I'll keep it in mind for next time! Although I've already finished my first calculus class, the course moved quite quickly and so I've been revising to clear up a few points I think could use some strengthening. While going over some $\delta-\varepsilon$ limit exercises, I realized there are few things about the $\delta-\varepsilon$ definition that either I don't understand, or would just like some confirmation about. Firstly, why is the definition not an equivalence statement? For any $\varepsilon$ value considered wouldn't there be a corresponding $\delta$ range for $x$? Also why is statement $0 < |x-a|< \delta$ , with $<$ rather than $\le$? With the $0<|x-a|$, is this simply to increase the strength of the statement by not requiring that the definition hold for the limit at $x=a$? But why then have $|x-a|< \delta$? Is there some issue with allowing $|x-a| \le \delta$? I realized this was a point I really didn't understand while reviewing the definition we were given for limits as $x \to \infty$. Here we were told that this has the limit $l$ when there exists an $N$ and $\varepsilon$ such that: $x \ge N \implies |f(x)-l|< \varepsilon$. So here the statement allows for a $\le$, while the finite statement doesn't, which seemed a little curious.","I'm a first year university student and it is my first time posting on the forum so if I have posted incorrectly please let me know and I'll keep it in mind for next time! Although I've already finished my first calculus class, the course moved quite quickly and so I've been revising to clear up a few points I think could use some strengthening. While going over some $\delta-\varepsilon$ limit exercises, I realized there are few things about the $\delta-\varepsilon$ definition that either I don't understand, or would just like some confirmation about. Firstly, why is the definition not an equivalence statement? For any $\varepsilon$ value considered wouldn't there be a corresponding $\delta$ range for $x$? Also why is statement $0 < |x-a|< \delta$ , with $<$ rather than $\le$? With the $0<|x-a|$, is this simply to increase the strength of the statement by not requiring that the definition hold for the limit at $x=a$? But why then have $|x-a|< \delta$? Is there some issue with allowing $|x-a| \le \delta$? I realized this was a point I really didn't understand while reviewing the definition we were given for limits as $x \to \infty$. Here we were told that this has the limit $l$ when there exists an $N$ and $\varepsilon$ such that: $x \ge N \implies |f(x)-l|< \varepsilon$. So here the statement allows for a $\le$, while the finite statement doesn't, which seemed a little curious.",,"['limits', 'epsilon-delta']"
24,Find $\lim_{n \rightarrow \infty } 2^{n} \sqrt{2-\sqrt{2+\sqrt{2+...+\sqrt{2}}}}$ [duplicate],Find  [duplicate],\lim_{n \rightarrow \infty } 2^{n} \sqrt{2-\sqrt{2+\sqrt{2+...+\sqrt{2}}}},This question already has an answer here : Find $\lim_{n\to\infty}2^n\underbrace{\sqrt{2-\sqrt{2+\sqrt{2+\dots+\sqrt2}}}}_{n \textrm{ square roots}}$. (1 answer) Closed 8 years ago . $\lim_{n \rightarrow  \infty } 2^{n} \sqrt{2-\sqrt{2+\sqrt{2+...+\sqrt{2}}}}$ where the 2 inside the roots appear n times. For example if n = 2 :  $2^{2} \sqrt{2-\sqrt{2}}$ I discovered this. Has this been already developed/made before?,This question already has an answer here : Find $\lim_{n\to\infty}2^n\underbrace{\sqrt{2-\sqrt{2+\sqrt{2+\dots+\sqrt2}}}}_{n \textrm{ square roots}}$. (1 answer) Closed 8 years ago . $\lim_{n \rightarrow  \infty } 2^{n} \sqrt{2-\sqrt{2+\sqrt{2+...+\sqrt{2}}}}$ where the 2 inside the roots appear n times. For example if n = 2 :  $2^{2} \sqrt{2-\sqrt{2}}$ I discovered this. Has this been already developed/made before?,,"['limits', 'pi']"
25,Show that $\frac{n}{n^2-3}$ converges,Show that  converges,\frac{n}{n^2-3},Hi I need help with this epsilon delta proof. The subtraction in the denominator as well as being left with $n$ in multiple places is causing problems.,Hi I need help with this epsilon delta proof. The subtraction in the denominator as well as being left with $n$ in multiple places is causing problems.,,"['calculus', 'sequences-and-series', 'analysis', 'limits', 'epsilon-delta']"
26,Limit of given expression,Limit of given expression,,"Let $\sum a_k=s$. I want to show that $$\lim\limits_{x\to 1^-}(1-x)\sum\limits_{k=1}^{\infty}\frac{ka_kx^k}{1-x^k}=s$$ where $x\in(0,1)$. Thanks for your helps.","Let $\sum a_k=s$. I want to show that $$\lim\limits_{x\to 1^-}(1-x)\sum\limits_{k=1}^{\infty}\frac{ka_kx^k}{1-x^k}=s$$ where $x\in(0,1)$. Thanks for your helps.",,"['sequences-and-series', 'limits', 'convergence-divergence', 'power-series']"
27,Proving that $\lim_{x {\to} \infty}f(x)=\infty $,Proving that,\lim_{x {\to} \infty}f(x)=\infty ,"Given $\ f(x)$ that is differential in $\ (x_0,\infty), f'(x)\ge a,$ for every $\ x> x_0$ and $\ a>0$, trying to show that $\lim_{x\to\infty}f(x)=\infty$. So far I've tried using Mean Value Theorem on $\ [b,b+1],$ so that $\ b>x_0$. From there I assumed in order to contradict, that $\ f(x)$ converges to a finite $\ L$. So  $$ \lim_{x\to\infty}f(x)=  \lim_{x\to\infty} f(b+1)-f(b)= L -L=0$$ This is against that (*)$\ f'(x) > 0$ so $\ f(x)$ does not converge to a finite value. Finally $\ f(x)$ is strictly increasing ($\ f'(x)\ge a>0$) so it tends to infinity.  $$$$ I think that * might be faulty, if the limit of a derivative is zero it doesn't mean that the actual derivative is affected so. Maybe there is a different direction to approach this. Any input? Maybe this should be solved in a different way?","Given $\ f(x)$ that is differential in $\ (x_0,\infty), f'(x)\ge a,$ for every $\ x> x_0$ and $\ a>0$, trying to show that $\lim_{x\to\infty}f(x)=\infty$. So far I've tried using Mean Value Theorem on $\ [b,b+1],$ so that $\ b>x_0$. From there I assumed in order to contradict, that $\ f(x)$ converges to a finite $\ L$. So  $$ \lim_{x\to\infty}f(x)=  \lim_{x\to\infty} f(b+1)-f(b)= L -L=0$$ This is against that (*)$\ f'(x) > 0$ so $\ f(x)$ does not converge to a finite value. Finally $\ f(x)$ is strictly increasing ($\ f'(x)\ge a>0$) so it tends to infinity.  $$$$ I think that * might be faulty, if the limit of a derivative is zero it doesn't mean that the actual derivative is affected so. Maybe there is a different direction to approach this. Any input? Maybe this should be solved in a different way?",,"['calculus', 'limits', 'derivatives']"
28,How to evaluate $\frac{2^{f(\tan x)}-2^{f(\sin x)}}{x^{2}f(\sin x)}$ as $x \to 0$?,How to evaluate  as ?,\frac{2^{f(\tan x)}-2^{f(\sin x)}}{x^{2}f(\sin x)} x \to 0,"If $f(x+y)=f(x)+f(y)$ for all real values of $x,y$. Given $f(1)=1$ How to evaluate $$\lim_{x \to 0} \frac{2^{f(\tan x)}-2^{f(\sin x)}}{x^{2}f(\sin x)}$$","If $f(x+y)=f(x)+f(y)$ for all real values of $x,y$. Given $f(1)=1$ How to evaluate $$\lim_{x \to 0} \frac{2^{f(\tan x)}-2^{f(\sin x)}}{x^{2}f(\sin x)}$$",,[]
29,Calculating limit of a particular product series,Calculating limit of a particular product series,,How to find  $$\lim\limits_{n\to\infty} \left(1+\frac{ 1 }{ a_{ 1 } }  \right) \left( 1+\frac { 1 }{ a_{ 2} }  \right)\cdots\left( 1+\frac { 1 }{ a_{ n } }  \right) $$  where  $$a_1=1$$  $$a_n=n(1+a_{n-1})$$  for all $n \geq 2$?,How to find  $$\lim\limits_{n\to\infty} \left(1+\frac{ 1 }{ a_{ 1 } }  \right) \left( 1+\frac { 1 }{ a_{ 2} }  \right)\cdots\left( 1+\frac { 1 }{ a_{ n } }  \right) $$  where  $$a_1=1$$  $$a_n=n(1+a_{n-1})$$  for all $n \geq 2$?,,[]
30,Proving a limit does not exist with epsilon delta,Proving a limit does not exist with epsilon delta,,I don't have an equation for this. I'm looking more for intuition rather than anything else. At what point in the epsilon-delta definition of a limit does this fail to hold up? I'm having trouble understanding the epsilon-delta definition of a limit and why it's defined the way it is.,I don't have an equation for this. I'm looking more for intuition rather than anything else. At what point in the epsilon-delta definition of a limit does this fail to hold up? I'm having trouble understanding the epsilon-delta definition of a limit and why it's defined the way it is.,,"['limits', 'epsilon-delta']"
31,How can I use a precise definition to find values of delta that correspond with given epsilon values,How can I use a precise definition to find values of delta that correspond with given epsilon values,,"I have been given this problem: For the limit $$\lim_{x\to 2}({x^3-3x+4})=6$$ illustrate ""Definition 2"" (I have included this below) by finding values of $\delta$ that correspond to $\varepsilon=0.2$ and $\varepsilon=0.1$ ""Definition 2:"" My textbook says to this definition ""Let $f$ be a function defined on some open interval that contains the number $a$, except possibly $a$ itself. Then we say that the limit of $f(x)$ as $x$ approaches $a$ is $L$, and we write $$\lim_{x\to a}f(x)=L$$ if for every number $\varepsilon>0$ such that $$if\;0<|x-a|<\delta\;\;\;then\;|f(x)-L|<\varepsilon$$ This has been a seriously frustrating problem, I've been working on it for two days, I just don't understand this concept at all. The only thing I think I understand is that the values of $\delta$ correspond to values on the x-axis, and $\varepsilon$ is related to the limit. How do I go about solving this problem?","I have been given this problem: For the limit $$\lim_{x\to 2}({x^3-3x+4})=6$$ illustrate ""Definition 2"" (I have included this below) by finding values of $\delta$ that correspond to $\varepsilon=0.2$ and $\varepsilon=0.1$ ""Definition 2:"" My textbook says to this definition ""Let $f$ be a function defined on some open interval that contains the number $a$, except possibly $a$ itself. Then we say that the limit of $f(x)$ as $x$ approaches $a$ is $L$, and we write $$\lim_{x\to a}f(x)=L$$ if for every number $\varepsilon>0$ such that $$if\;0<|x-a|<\delta\;\;\;then\;|f(x)-L|<\varepsilon$$ This has been a seriously frustrating problem, I've been working on it for two days, I just don't understand this concept at all. The only thing I think I understand is that the values of $\delta$ correspond to values on the x-axis, and $\varepsilon$ is related to the limit. How do I go about solving this problem?",,"['calculus', 'limits', 'definition']"
32,Computing the value of a series by telescoping cancellations vs. infinite limit of partial sums,Computing the value of a series by telescoping cancellations vs. infinite limit of partial sums,,"$$\sum_{m=5}^\infty \frac{3}{m^2+3m+2}$$ Given this problem my first approach was to take the limit of partial sums. To my surprise this didn't work. Many expletives later I realized it was a telescoping series. My question is why my first approach failed . My expectation is that both approaches would produce the same answer. Why didn't they? First approach: $$\sum_{m=5}^\infty \frac{3}{m^2+3m+2} = \lim \limits_{N \to \infty} \int_{m=5}^N \frac{3}{m^2+3m+2} = \lim \limits_{N \to \infty} 3 \left [ \ln \left ( \frac{N+1}{N+2} \right ) + \ln \left ( \frac{7}{6} \right ) \right ]$$$$ = 3 \ln(7/6) \approx 0.46245$$ An empirical check showed that the above approach is wrong. After I realized it was a telescoping series I was able to produce a sequence of partial sums: $$S_{m} = \left ( \frac{3}{6}-\frac{3}{m+2} \right ) $$ And the limit of this sequence gets to an answer that agrees with a crude empirical spreadsheet validation: $$\lim \limits_{m \to \infty} \left ( \frac{3}{6}-\frac{3}{m+2} \right ) = \frac{1}{2}$$ So clearly my initial intuition and understanding was wrong. But why was it wrong? I thought I could take the limit of an integral to calculate the value of a series. In what case do we apply the first approach I took? I've used it before, but I must have forgotten how to apply it correctly (and all my searches come up with references to computing convergence, not actual values).","$$\sum_{m=5}^\infty \frac{3}{m^2+3m+2}$$ Given this problem my first approach was to take the limit of partial sums. To my surprise this didn't work. Many expletives later I realized it was a telescoping series. My question is why my first approach failed . My expectation is that both approaches would produce the same answer. Why didn't they? First approach: $$\sum_{m=5}^\infty \frac{3}{m^2+3m+2} = \lim \limits_{N \to \infty} \int_{m=5}^N \frac{3}{m^2+3m+2} = \lim \limits_{N \to \infty} 3 \left [ \ln \left ( \frac{N+1}{N+2} \right ) + \ln \left ( \frac{7}{6} \right ) \right ]$$$$ = 3 \ln(7/6) \approx 0.46245$$ An empirical check showed that the above approach is wrong. After I realized it was a telescoping series I was able to produce a sequence of partial sums: $$S_{m} = \left ( \frac{3}{6}-\frac{3}{m+2} \right ) $$ And the limit of this sequence gets to an answer that agrees with a crude empirical spreadsheet validation: $$\lim \limits_{m \to \infty} \left ( \frac{3}{6}-\frac{3}{m+2} \right ) = \frac{1}{2}$$ So clearly my initial intuition and understanding was wrong. But why was it wrong? I thought I could take the limit of an integral to calculate the value of a series. In what case do we apply the first approach I took? I've used it before, but I must have forgotten how to apply it correctly (and all my searches come up with references to computing convergence, not actual values).",,"['calculus', 'sequences-and-series', 'limits']"
33,Evaluating a limit involving a definite integral,Evaluating a limit involving a definite integral,,"I want to prove the following limit evaluates to $0$ without using any techniques that involve complex numbers. I already solved it using residues and it's pretty straight forward, but it feels rather unpleasant using such a tool. $$\lim_{n\to\infty} \int_{0}^{2\pi} \frac{\cos(nx)}{x^2+4}\,dx$$ I also tried differentiation under the integral sign, but I got to a point where things got too messy to be handled gracefully so I came here to ask for help. Thanks!","I want to prove the following limit evaluates to $0$ without using any techniques that involve complex numbers. I already solved it using residues and it's pretty straight forward, but it feels rather unpleasant using such a tool. $$\lim_{n\to\infty} \int_{0}^{2\pi} \frac{\cos(nx)}{x^2+4}\,dx$$ I also tried differentiation under the integral sign, but I got to a point where things got too messy to be handled gracefully so I came here to ask for help. Thanks!",,"['limits', 'definite-integrals']"
34,Finding the limit of a function with 2 variables,Finding the limit of a function with 2 variables,,"Please help to solve the limit. $$\lim_{(x,y)\rightarrow(0,0)}\dfrac{x^3+y^3}{x^2+y^2}$$ I tried to solve it but... $$x:=0 \Rightarrow \dfrac{x^3+y^3}{x^2+y^2} = y$$ $$y:=0 \Rightarrow \dfrac{x^3+y^3}{x^2+y^2} = x$$","Please help to solve the limit. $$\lim_{(x,y)\rightarrow(0,0)}\dfrac{x^3+y^3}{x^2+y^2}$$ I tried to solve it but... $$x:=0 \Rightarrow \dfrac{x^3+y^3}{x^2+y^2} = y$$ $$y:=0 \Rightarrow \dfrac{x^3+y^3}{x^2+y^2} = x$$",,"['calculus', 'limits']"
35,Finding the Limit of the Ratio of a Recursive Sequence's Terms,Finding the Limit of the Ratio of a Recursive Sequence's Terms,,"Let {$f_n$} be defined recursively as $f_1 = f_2 = f_3 = 1$ and $f_n = f_{n-1} + f_{n-3}$ for all $n \gt 3$. Also, define {$a_n$} as the ratio of the terms of {$f_n$}. That is, $a_n = \frac{f_{n+1}}{f_n}$ for some $n \geq 1$. So, the terms of {$f_n$} are $$f_1 = 1,f_2 = 1,f_3 = 1,f_4 = 2,f_5 = 3,f_6 = 4,f_7 = 6,\ldots,$$ and the terms of {$a_n$} are $$a_1 = 1,a_2 = 1,a_3 = 2,a_4 = \frac{3}{2},a_5 = \frac{4}{3},a_6 = \frac{6}{4},\ldots$$ The question then becomes evaluating the limiting ratio of {$f_n$} or, in other words, Find $$\lim_{n \to \infty}{a_n} = \lim_{n \to \infty}\frac{f_{n+1}}{f_n}, \forall n \geq 1.$$ The way I approached this problem was to try to put bounds on $a_k = \frac{f_{k+1}}{f_k}$ for some $k$. It made the most sense to me that $1 \leq a_k \leq 2$ just based off of the first few terms of {$a_n$}. Then, I tried to rewrite $a_k = \frac{f_{k+1}}{f_k}$ in some way that would allow me to put bounds on $a_{k+1}$, since we want to show next that $1 \leq a_{k+1} \leq 2$. $$a_{k+1} = \frac{f_{k+2}}{f_{k+1}} = \frac{f_{k+1} + f_{k-1}}{f_{k+1}} = 1 + \frac{f_{k-1}}{f_{k+1}}.$$ Next, I thought it would be a good idea to invert the inequality $1 \leq a_k \leq 2$. That is, $1 \geq \frac{1}{a_k} = \frac{f_k}{f_{k+1}} \geq \frac{1}{2}$ and then add $1$ to get the inequality $2\geq 1 + \frac{f_k}{f_{k+1}} \geq \frac{3}{2}$. And while $1 + \frac{f_k}{f_{k+1}}$ looks like a pretty result, what I actually need to find in this case is $1 + \frac{f_{k-1}}{f_{k+1}}$. It seems that at this point more clever manipulation is required, but I don't know what else can be done once I've reached this dead end. Can someone please elaborate on how to proceed with the above method or provide an alternative approach altogether? I appreciate any and all advice! Thanks for reading, A","Let {$f_n$} be defined recursively as $f_1 = f_2 = f_3 = 1$ and $f_n = f_{n-1} + f_{n-3}$ for all $n \gt 3$. Also, define {$a_n$} as the ratio of the terms of {$f_n$}. That is, $a_n = \frac{f_{n+1}}{f_n}$ for some $n \geq 1$. So, the terms of {$f_n$} are $$f_1 = 1,f_2 = 1,f_3 = 1,f_4 = 2,f_5 = 3,f_6 = 4,f_7 = 6,\ldots,$$ and the terms of {$a_n$} are $$a_1 = 1,a_2 = 1,a_3 = 2,a_4 = \frac{3}{2},a_5 = \frac{4}{3},a_6 = \frac{6}{4},\ldots$$ The question then becomes evaluating the limiting ratio of {$f_n$} or, in other words, Find $$\lim_{n \to \infty}{a_n} = \lim_{n \to \infty}\frac{f_{n+1}}{f_n}, \forall n \geq 1.$$ The way I approached this problem was to try to put bounds on $a_k = \frac{f_{k+1}}{f_k}$ for some $k$. It made the most sense to me that $1 \leq a_k \leq 2$ just based off of the first few terms of {$a_n$}. Then, I tried to rewrite $a_k = \frac{f_{k+1}}{f_k}$ in some way that would allow me to put bounds on $a_{k+1}$, since we want to show next that $1 \leq a_{k+1} \leq 2$. $$a_{k+1} = \frac{f_{k+2}}{f_{k+1}} = \frac{f_{k+1} + f_{k-1}}{f_{k+1}} = 1 + \frac{f_{k-1}}{f_{k+1}}.$$ Next, I thought it would be a good idea to invert the inequality $1 \leq a_k \leq 2$. That is, $1 \geq \frac{1}{a_k} = \frac{f_k}{f_{k+1}} \geq \frac{1}{2}$ and then add $1$ to get the inequality $2\geq 1 + \frac{f_k}{f_{k+1}} \geq \frac{3}{2}$. And while $1 + \frac{f_k}{f_{k+1}}$ looks like a pretty result, what I actually need to find in this case is $1 + \frac{f_{k-1}}{f_{k+1}}$. It seems that at this point more clever manipulation is required, but I don't know what else can be done once I've reached this dead end. Can someone please elaborate on how to proceed with the above method or provide an alternative approach altogether? I appreciate any and all advice! Thanks for reading, A",,"['sequences-and-series', 'limits']"
36,unsure how to rearrange $f(x)$ into suitable $p(x)/q(x)$,unsure how to rearrange  into suitable,f(x) p(x)/q(x),"Consider the function $f(x)= (x^3 + 2x - 3) / (x^2 + 3x + 4)$ by dividing the numerator and denominator by the highest power of $x$ present, convert $f(x)$ into the form $P(x)/Q(x)$ where both $P(x)$ and $Q(x)$ have finite limits as '$x$ tends to infinity', not both $0$. I know I am supposed to divide the numerator and denominator separately, however when it says 'by the highest power of $x$ present', does this mean present in itself (ie numerator OR denominator) or the fuction $f(x)$ as a whole, (ie in this question $x^3$) I have assumed its the highest power of $x$ present in the whole function $f(x)$, and I have ended up with $$ (1 + 2x^{-2} - 3x^{-3}) / (x^{-1} + 3x^{-2} + 4x^{-3}) $$ and I do not know where to go from here. not entirely sure how to rearrange negative powers. ie, if theres a negative power can I just swap that term from the top to the bottom or vice versa?","Consider the function $f(x)= (x^3 + 2x - 3) / (x^2 + 3x + 4)$ by dividing the numerator and denominator by the highest power of $x$ present, convert $f(x)$ into the form $P(x)/Q(x)$ where both $P(x)$ and $Q(x)$ have finite limits as '$x$ tends to infinity', not both $0$. I know I am supposed to divide the numerator and denominator separately, however when it says 'by the highest power of $x$ present', does this mean present in itself (ie numerator OR denominator) or the fuction $f(x)$ as a whole, (ie in this question $x^3$) I have assumed its the highest power of $x$ present in the whole function $f(x)$, and I have ended up with $$ (1 + 2x^{-2} - 3x^{-3}) / (x^{-1} + 3x^{-2} + 4x^{-3}) $$ and I do not know where to go from here. not entirely sure how to rearrange negative powers. ie, if theres a negative power can I just swap that term from the top to the bottom or vice versa?",,"['calculus', 'limits', 'exponentiation']"
37,Convergence of the following sequence: $\lim_{n\to \infty} e^{-t\sqrt{n}}(1-\frac{t}{\sqrt{n}})^{-n}=e^{\frac{1}{2}t^2}$ [duplicate],Convergence of the following sequence:  [duplicate],\lim_{n\to \infty} e^{-t\sqrt{n}}(1-\frac{t}{\sqrt{n}})^{-n}=e^{\frac{1}{2}t^2},"This question already has an answer here : Evaluate $\lim\limits_{\alpha \to \infty} e^{-t\sqrt{\alpha}}(1-\frac{t}{\sqrt{\alpha}})^{-\alpha}$ [duplicate] (1 answer) Closed 3 months ago . It could be exhaustion from the amount of work that I've done today, but I'd like to prove for myself that $\lim_{n\to \infty} e^{-t\sqrt{n}}(1-\frac{t}{\sqrt{n}})^{-n}=e^{\frac{1}{2}t^2}$$ Here's what I've attempted: Take the log of our sequence. Then we have $\lim_{n\to \infty} n\cdot t\sqrt{n}\cdot \ln(1-\frac{t}{\sqrt{n}}) \implies \lim_{n\to \infty}  \ln((1-\frac{t}{\sqrt{n}})^{\sqrt{n}}) \implies \lim_{n\to \infty} \frac{\ln((1-\frac{t}{\sqrt{n}})^{\sqrt{n}})}{n^{-1}}$ To be frank, I'm not sure how to proceed from this step. I've applied L'Hopital's rule to this final step and it creates an utter mess. Every route I take seems to end in divergence, but I know this converges.","This question already has an answer here : Evaluate $\lim\limits_{\alpha \to \infty} e^{-t\sqrt{\alpha}}(1-\frac{t}{\sqrt{\alpha}})^{-\alpha}$ [duplicate] (1 answer) Closed 3 months ago . It could be exhaustion from the amount of work that I've done today, but I'd like to prove for myself that $\lim_{n\to \infty} e^{-t\sqrt{n}}(1-\frac{t}{\sqrt{n}})^{-n}=e^{\frac{1}{2}t^2}$$ Here's what I've attempted: Take the log of our sequence. Then we have To be frank, I'm not sure how to proceed from this step. I've applied L'Hopital's rule to this final step and it creates an utter mess. Every route I take seems to end in divergence, but I know this converges.","\lim_{n\to \infty} n\cdot t\sqrt{n}\cdot \ln(1-\frac{t}{\sqrt{n}})
\implies \lim_{n\to \infty}  \ln((1-\frac{t}{\sqrt{n}})^{\sqrt{n}})
\implies \lim_{n\to \infty} \frac{\ln((1-\frac{t}{\sqrt{n}})^{\sqrt{n}})}{n^{-1}}","['calculus', 'limits', 'convergence-divergence']"
38,"Prove that if a set H has only one limit point, then it is countable.","Prove that if a set H has only one limit point, then it is countable.",,Unfortunately i don't even know how to start with this problem. Edit: H is a subset of real numbers.,Unfortunately i don't even know how to start with this problem. Edit: H is a subset of real numbers.,,"['analysis', 'limits']"
39,Limit of $y \ln (x^2+y^2)$,Limit of,y \ln (x^2+y^2),"I want to calculate limit of $\lim_{(x,y) \rightarrow(0,0)}y \ln (x^2+y^2)$. How to do that? From iterated limits i know that limit exists for certain, but how to show that it is equal to zero then?","I want to calculate limit of $\lim_{(x,y) \rightarrow(0,0)}y \ln (x^2+y^2)$. How to do that? From iterated limits i know that limit exists for certain, but how to show that it is equal to zero then?",,"['limits', 'logarithms']"
40,Compute $\lim_{x \rightarrow +\infty} \frac{[\int^x_0 e^{y^{2}} dy]^2}{\int^x_0 e^{2y^{2}}dy}$,Compute,\lim_{x \rightarrow +\infty} \frac{[\int^x_0 e^{y^{2}} dy]^2}{\int^x_0 e^{2y^{2}}dy},"I've tried to apply L'hopitals rule on this one, as this get's $\frac{\infty}{\infty}$ $$\lim_{x \rightarrow +\infty} \frac{[\int^x_0 e^{y^2}\mathrm{d}y]^2}{\int^x_0 e^{2y^2}\mathrm{d}y}$$ $\frac{\mathrm{d} }{\mathrm{d} x}[\int^x_0 e^{y^2}\mathrm{d}y]^2 = 2[\int^x_0 e^{y^2}\mathrm{d}y] * [\frac{\mathrm{d} }{\mathrm{d} x}\int^x_0 e^{y^2}\mathrm{d}y]=2(e^{x^2}-1)(e^{x^2})$ and $\frac{\mathrm{d} }{\mathrm{d} x}[\int^x_0 e^{2y^2}\mathrm{d}y]=e^{2x^2}$ so $\lim_{x \rightarrow +\infty} \frac{[\int^x_0 e^{y^2}\mathrm{d}y]^2}{\int^x_0 e^{2y^2}\mathrm{d}y} = \lim_{x \rightarrow +\infty} \frac{2(e^{x^2}-1)(e^{x^2})}{e^{2x^2}} = 2\lim_{x \rightarrow +\infty} \frac{(e^{x^2}-1)}{e^{x^2}}=2\lim_{x \rightarrow +\infty} (1-\frac{1}{e^{x^2}})=2$ But the answer is $0$, so I think I've done a mistake somewhere I can't figure out where.","I've tried to apply L'hopitals rule on this one, as this get's $\frac{\infty}{\infty}$ $$\lim_{x \rightarrow +\infty} \frac{[\int^x_0 e^{y^2}\mathrm{d}y]^2}{\int^x_0 e^{2y^2}\mathrm{d}y}$$ $\frac{\mathrm{d} }{\mathrm{d} x}[\int^x_0 e^{y^2}\mathrm{d}y]^2 = 2[\int^x_0 e^{y^2}\mathrm{d}y] * [\frac{\mathrm{d} }{\mathrm{d} x}\int^x_0 e^{y^2}\mathrm{d}y]=2(e^{x^2}-1)(e^{x^2})$ and $\frac{\mathrm{d} }{\mathrm{d} x}[\int^x_0 e^{2y^2}\mathrm{d}y]=e^{2x^2}$ so $\lim_{x \rightarrow +\infty} \frac{[\int^x_0 e^{y^2}\mathrm{d}y]^2}{\int^x_0 e^{2y^2}\mathrm{d}y} = \lim_{x \rightarrow +\infty} \frac{2(e^{x^2}-1)(e^{x^2})}{e^{2x^2}} = 2\lim_{x \rightarrow +\infty} \frac{(e^{x^2}-1)}{e^{x^2}}=2\lim_{x \rightarrow +\infty} (1-\frac{1}{e^{x^2}})=2$ But the answer is $0$, so I think I've done a mistake somewhere I can't figure out where.",,"['limits', 'derivatives', 'definite-integrals']"
41,Derivative of sin(x)/x at $0$ by definition of derivative,Derivative of sin(x)/x at  by definition of derivative,0,"the question I am attempting is: Show $f '(0) = 0$ for: $$f(x) = \left\{ \begin{array}{lr} \frac{\sin(x)}{x} & : x \neq 0\\ 1 & : x=0 \end{array}  \right.$$ So I got stuck after the following working: $$ f'(0)  =  \lim_{h \to 0} \frac{f(0+h) - f(0)}{h} \\  = \lim_{h \to 0} \frac{\frac{\sin(h)}{h}-\frac{\sin(0)}{0}}{h}\\ = \lim_{h \to 0} \frac{\sin(h)}{h^2} $$ and the above limit does not exist. Am I not applying the derivative definition right? or am I going wrong somewhere else? EDIT:  I now see that f(0) = 1 from the definition of the function, however I still have: $$\lim_{h \to 0}\frac{\sin(h)-h}{h^2}$$ which I am struggling to evaluate. Splitting into two fractions the first fraction is still the one from above which does not exist. Also this must be from definition of derivative directly and not by L'Hopitals rule as it has not been taught yet.","the question I am attempting is: Show $f '(0) = 0$ for: $$f(x) = \left\{ \begin{array}{lr} \frac{\sin(x)}{x} & : x \neq 0\\ 1 & : x=0 \end{array}  \right.$$ So I got stuck after the following working: $$ f'(0)  =  \lim_{h \to 0} \frac{f(0+h) - f(0)}{h} \\  = \lim_{h \to 0} \frac{\frac{\sin(h)}{h}-\frac{\sin(0)}{0}}{h}\\ = \lim_{h \to 0} \frac{\sin(h)}{h^2} $$ and the above limit does not exist. Am I not applying the derivative definition right? or am I going wrong somewhere else? EDIT:  I now see that f(0) = 1 from the definition of the function, however I still have: $$\lim_{h \to 0}\frac{\sin(h)-h}{h^2}$$ which I am struggling to evaluate. Splitting into two fractions the first fraction is still the one from above which does not exist. Also this must be from definition of derivative directly and not by L'Hopitals rule as it has not been taught yet.",,"['real-analysis', 'analysis', 'limits', 'derivatives']"
42,Computing $\lim_{n\to\infty}\sqrt{\frac{2n}{n+1}}$,Computing,\lim_{n\to\infty}\sqrt{\frac{2n}{n+1}},"We are asked to find the limit of the recursively defined sequence, and to assume that the sequence converges. $a_1$=0 and $a_{n+1}$= $\sqrt{8+2a_n}$ I then solved for $a_n$ using algebra. $a_n$=${(a_{n+1})^2 - 8\over 2}$ I set the limits of each term equal to eachother. $\lim \limits_{n \to \infty}$$a_n$ = $\lim \limits_{n \to \infty}$${(a_{n+1})^2 - 8\over 2}$ So, from what I understand $\lim \limits_{n \to \infty}$$a_n$ = L And you can just set L = ${L^2 - 8\over 2}$ which after algebraic simplification equals: $L^2$ -2L -8 = 0 (L-4)(L+2) = 0 L = -2, 4 So I do not understand how there are two limits, if these are even correct? And why $(a_{n+1})^2$ can be substituted for $L^2$. I came to these answers after watching a video on a similar problem which is why I'm not really understanding the basic concepts of it. Thanks.","We are asked to find the limit of the recursively defined sequence, and to assume that the sequence converges. $a_1$=0 and $a_{n+1}$= $\sqrt{8+2a_n}$ I then solved for $a_n$ using algebra. $a_n$=${(a_{n+1})^2 - 8\over 2}$ I set the limits of each term equal to eachother. $\lim \limits_{n \to \infty}$$a_n$ = $\lim \limits_{n \to \infty}$${(a_{n+1})^2 - 8\over 2}$ So, from what I understand $\lim \limits_{n \to \infty}$$a_n$ = L And you can just set L = ${L^2 - 8\over 2}$ which after algebraic simplification equals: $L^2$ -2L -8 = 0 (L-4)(L+2) = 0 L = -2, 4 So I do not understand how there are two limits, if these are even correct? And why $(a_{n+1})^2$ can be substituted for $L^2$. I came to these answers after watching a video on a similar problem which is why I'm not really understanding the basic concepts of it. Thanks.",,"['sequences-and-series', 'limits', 'recursion']"
43,$\lim_{n\to\infty}\left(\frac{\log(p_{n+1})}{\log(p_n)}\right)^n = C?$,,\lim_{n\to\infty}\left(\frac{\log(p_{n+1})}{\log(p_n)}\right)^n = C?,"There is a conjecture (which is weaker) related conjecture to Firoozbakht's conjecture (see OEIS A182514 Commments) which states (and define $L_n$): $$L_n := \left(\frac{\log(p_{n+1})}{\log(p_n)}\right)^n < e,$$ where $p_n$ is the $n$-th prime. This implies there might be constant, $C$, because as the RHS is constant as $n\to\infty$, and every thing on the LHS increasing without bound. So does $C$ exist and what value does it approach? While I know that the $\lim_{n\to\infty}\left(\frac{\log(p_{n+1})}{\log(p_n)}\right) = 1$, and clearly $\left(\frac{\log(p_{n+1})}{\log(p_n)}\right) > 1$, it is the power, $n$, that is a curve-ball for me. Does the limit exist, and if it does, is the value $1,e$, or something   in between for: $$\lim_{n\to\infty} L_n = C?$$","There is a conjecture (which is weaker) related conjecture to Firoozbakht's conjecture (see OEIS A182514 Commments) which states (and define $L_n$): $$L_n := \left(\frac{\log(p_{n+1})}{\log(p_n)}\right)^n < e,$$ where $p_n$ is the $n$-th prime. This implies there might be constant, $C$, because as the RHS is constant as $n\to\infty$, and every thing on the LHS increasing without bound. So does $C$ exist and what value does it approach? While I know that the $\lim_{n\to\infty}\left(\frac{\log(p_{n+1})}{\log(p_n)}\right) = 1$, and clearly $\left(\frac{\log(p_{n+1})}{\log(p_n)}\right) > 1$, it is the power, $n$, that is a curve-ball for me. Does the limit exist, and if it does, is the value $1,e$, or something   in between for: $$\lim_{n\to\infty} L_n = C?$$",,"['limits', 'prime-numbers']"
44,Evaluate the following limit of finite sum,Evaluate the following limit of finite sum,,"Evaluate the limit $$\lim_{n\to \infty}\frac{1}{n}\sum_{k=0}^{[n/2]}\cos \left(\frac{k\pi}{n}\right)$$ I tried through considering two cases : (i) When $n$ is even (ii) when $n$ is odd. When $n$ is even then the limiting value is $\frac{1}{\pi}$. But when $n$ is odd then ?? Case 1 : $n$ is even.. Then , take $n=2p$ where $p$ is positive integer. Then $$\lim_{n\to \infty}\frac{1}{n}\sum_{k=0}^{[n/2]}\cos \left(\frac{k\pi}{n}\right)$$ $$=\lim_{p\to \infty}\frac{1}{2p}\sum_{k=0}^{p}\cos\left(\frac{k\pi}{2p}\right)$$ $$=\frac{1}{2}\int_0^1\cos(\pi x/2)\,dx$$ $$=\frac{1}{\pi}.$$ Case 2 : When $n$ is odd. Take, $n=2p+1$ , where $p$ is a positive integer. Then , $$\lim_{n\to \infty}\frac{1}{n}\sum_{k=0}^{[n/2]}\cos \left(\frac{k\pi}{n}\right)$$ $$=\lim_{p\to \infty}\frac{1}{2p+1}\sum_{k=0}^p\cos\left(\frac{k\pi}{2p+1}\right)$$ From here how I proceed ?","Evaluate the limit $$\lim_{n\to \infty}\frac{1}{n}\sum_{k=0}^{[n/2]}\cos \left(\frac{k\pi}{n}\right)$$ I tried through considering two cases : (i) When $n$ is even (ii) when $n$ is odd. When $n$ is even then the limiting value is $\frac{1}{\pi}$. But when $n$ is odd then ?? Case 1 : $n$ is even.. Then , take $n=2p$ where $p$ is positive integer. Then $$\lim_{n\to \infty}\frac{1}{n}\sum_{k=0}^{[n/2]}\cos \left(\frac{k\pi}{n}\right)$$ $$=\lim_{p\to \infty}\frac{1}{2p}\sum_{k=0}^{p}\cos\left(\frac{k\pi}{2p}\right)$$ $$=\frac{1}{2}\int_0^1\cos(\pi x/2)\,dx$$ $$=\frac{1}{\pi}.$$ Case 2 : When $n$ is odd. Take, $n=2p+1$ , where $p$ is a positive integer. Then , $$\lim_{n\to \infty}\frac{1}{n}\sum_{k=0}^{[n/2]}\cos \left(\frac{k\pi}{n}\right)$$ $$=\lim_{p\to \infty}\frac{1}{2p+1}\sum_{k=0}^p\cos\left(\frac{k\pi}{2p+1}\right)$$ From here how I proceed ?",,"['calculus', 'sequences-and-series', 'limits']"
45,"Determining existence of limit with multiple variables: $\lim_{(x,y)\to (0,0)} \frac{xy^2}{x^3+y^3}$",Determining existence of limit with multiple variables:,"\lim_{(x,y)\to (0,0)} \frac{xy^2}{x^3+y^3}","Given the following limit: $$ \lim_{(x,y)\to (0,0)} \frac{xy^2}{x^3+y^3} $$ And the instrucion to ""Determine whether the limit exists, give a complete argument"", would the following be a ""complete argument""? Approaching the limit from the line y=0, gives $ \lim_{(x,y)\to (0,0)} \frac{xy^2}{x^3+y^3} = \lim_{(x,y)\to (0,0)} \frac{0}{x^3+y^3} = 0 $ Approaching the limit from the line y=x, gives $ \lim_{(x,y)\to (0,0)} \frac{xy^2}{x^3+y^3} = \lim_{(x,y)\to (0,0)} \frac{x^3}{2x^3} = \frac{1}{2} $ These limits do not agree, thus the original limit $$ \lim_{(x,y)\to (0,0)} \frac{xy^2}{x^3+y^3} $$ does not exist. Or should another method besides approaching from different lines be used to give a ""complete argument"" whether this limit exists be given?","Given the following limit: And the instrucion to ""Determine whether the limit exists, give a complete argument"", would the following be a ""complete argument""? Approaching the limit from the line y=0, gives Approaching the limit from the line y=x, gives These limits do not agree, thus the original limit does not exist. Or should another method besides approaching from different lines be used to give a ""complete argument"" whether this limit exists be given?"," \lim_{(x,y)\to (0,0)} \frac{xy^2}{x^3+y^3}   \lim_{(x,y)\to (0,0)} \frac{xy^2}{x^3+y^3} = \lim_{(x,y)\to (0,0)} \frac{0}{x^3+y^3} = 0   \lim_{(x,y)\to (0,0)} \frac{xy^2}{x^3+y^3} = \lim_{(x,y)\to (0,0)} \frac{x^3}{2x^3} = \frac{1}{2}   \lim_{(x,y)\to (0,0)} \frac{xy^2}{x^3+y^3} ","['limits', 'multivariable-calculus']"
46,The limit $\lim_{n\to \infty}\frac{T_n(n)}{e^n}$ where $T_n(x)$ is the Taylor polynomial of $e^x$ [duplicate],The limit  where  is the Taylor polynomial of  [duplicate],\lim_{n\to \infty}\frac{T_n(n)}{e^n} T_n(x) e^x,This question already has answers here : Evaluating $\lim\limits_{n\to\infty} e^{-n} \sum\limits_{k=0}^{n} \frac{n^k}{k!}$ (9 answers) Closed 9 years ago . From working on a problem I was lead to consider the function $\frac{T_n(n)}{e^n}$ where $T_n(x)$ is the $n$'th order Taylor polynomial of $e^x$. Numerical evidence suggest that $$\lim_{n\to \infty} \frac{T_n(n)}{e^n} \equiv\lim_{n\to \infty} \frac{\sum_{k=0}^n\frac{n^k}{k!}}{\sum_{k=0}^\infty\frac{n^k}{k!}} = \frac{1}{2}$$ Is there a nice proof for this statement? More generally: is there a 'standard' approach for evaluating limits on the form $\lim_{n\to\infty}\frac{f_n(x_n)}{f(x_n)}$ where $f_n$ is a series converging (uniformly) to $f$ and where $x_n$ is an unbounded sequence? I would also apprechiate refs. to similar questions on this site or in the literature (I could only find this one ).,This question already has answers here : Evaluating $\lim\limits_{n\to\infty} e^{-n} \sum\limits_{k=0}^{n} \frac{n^k}{k!}$ (9 answers) Closed 9 years ago . From working on a problem I was lead to consider the function $\frac{T_n(n)}{e^n}$ where $T_n(x)$ is the $n$'th order Taylor polynomial of $e^x$. Numerical evidence suggest that $$\lim_{n\to \infty} \frac{T_n(n)}{e^n} \equiv\lim_{n\to \infty} \frac{\sum_{k=0}^n\frac{n^k}{k!}}{\sum_{k=0}^\infty\frac{n^k}{k!}} = \frac{1}{2}$$ Is there a nice proof for this statement? More generally: is there a 'standard' approach for evaluating limits on the form $\lim_{n\to\infty}\frac{f_n(x_n)}{f(x_n)}$ where $f_n$ is a series converging (uniformly) to $f$ and where $x_n$ is an unbounded sequence? I would also apprechiate refs. to similar questions on this site or in the literature (I could only find this one ).,,['limits']
47,proof : f continuous at a then |f| is continuous at a,proof : f continuous at a then |f| is continuous at a,,"Here's my proof, which I am not sure is correct : Assume f is continuous at a $=> \lim \limits_{x \to a} f(x) = f(a)$ $=> \lim \limits_{x \to a} f(x)$ exists $=> \lim \limits_{x \to a} |f(x)| = | \lim \limits_{x \to a} f(x) | = | f(a) |$ Hence, |f| is continuous at a Is there something wrong with it ?","Here's my proof, which I am not sure is correct : Assume f is continuous at a $=> \lim \limits_{x \to a} f(x) = f(a)$ $=> \lim \limits_{x \to a} f(x)$ exists $=> \lim \limits_{x \to a} |f(x)| = | \lim \limits_{x \to a} f(x) | = | f(a) |$ Hence, |f| is continuous at a Is there something wrong with it ?",,"['limits', 'continuity', 'solution-verification', 'absolute-value', 'epsilon-delta']"
48,What is the limit ${{\lim }_{x\to\infty}}x^\epsilon$ for an infinitesimal $\epsilon$?,What is the limit  for an infinitesimal ?,{{\lim }_{x\to\infty}}x^\epsilon \epsilon,"What is the limit $${{\lim }_{x\to\infty}}x^\epsilon$$ for an infinitesimal $\epsilon$? Does it give zero or infinity? Note that I'm considering the infinitesimals described in http://en.wikipedia.org/wiki/Smooth_infinitesimal_analysis EDIT: Since I was asked to show some of my own thoughts on the subject, I'd like to contribute the following: $$\lim_{x\to\infty} x^\epsilon = \lim_{x\to\infty} \exp(\log (x^\epsilon))= \lim_{x\to\infty} \exp(\epsilon\log(x))\\= \lim_{x\to\infty}(1+\epsilon\log(x))= \lim_{x\to\infty}(1+\epsilon)=1+\epsilon$$ Where we used a series expansion of $\exp(y)$ and the properties of infinitesimals $\epsilon^2=0$ and $a\epsilon=\epsilon$ for any number $a$. However, I am not sure if this is some sort of cheating my way around the limit at hand or not. Help would be appreciated!","What is the limit $${{\lim }_{x\to\infty}}x^\epsilon$$ for an infinitesimal $\epsilon$? Does it give zero or infinity? Note that I'm considering the infinitesimals described in http://en.wikipedia.org/wiki/Smooth_infinitesimal_analysis EDIT: Since I was asked to show some of my own thoughts on the subject, I'd like to contribute the following: $$\lim_{x\to\infty} x^\epsilon = \lim_{x\to\infty} \exp(\log (x^\epsilon))= \lim_{x\to\infty} \exp(\epsilon\log(x))\\= \lim_{x\to\infty}(1+\epsilon\log(x))= \lim_{x\to\infty}(1+\epsilon)=1+\epsilon$$ Where we used a series expansion of $\exp(y)$ and the properties of infinitesimals $\epsilon^2=0$ and $a\epsilon=\epsilon$ for any number $a$. However, I am not sure if this is some sort of cheating my way around the limit at hand or not. Help would be appreciated!",,"['limits', 'infinitesimals']"
49,Prove or disprove that $\lim_{x \to \infty}f(x) = 0$,Prove or disprove that,\lim_{x \to \infty}f(x) = 0,"Let f be a non-negative continuous function on $[0,\infty)$. If it's given that: $$\lim_{x \to \infty}\int_{x}^{x + 1}f(t)dt = 0$$ Does it follow that: $$(*) \ \lim_{x \to \infty}f(x) = 0 ?$$ Why or why not? I (thought) I had solved this problem , but it was pointed out that my argument was flawed. To prove $(*)$, I reasoned as follows: $f$ is continuous, so by MVT, there exists $C_x$ in $[x,x+1]$, such that: $$\int_{x}^{x + 1}f(t)dt = f(C_x)\int_{x}^{x + 1}dt = f(C_x)$$ So it follows that: $$\lim_{x \to \infty}f(x) = \lim_{x \to \infty}f(C_x) = \lim_{x \to \infty}\int_{x}^{x + 1}f(t)dt = 0 $$ What is missing in my work? Or where had I gone wrong? In case I'm mistaken and $(*)$ doesn't hold, in general, please present a counter-example and explain to me where had I gone wrong. Thanks a lot.","Let f be a non-negative continuous function on $[0,\infty)$. If it's given that: $$\lim_{x \to \infty}\int_{x}^{x + 1}f(t)dt = 0$$ Does it follow that: $$(*) \ \lim_{x \to \infty}f(x) = 0 ?$$ Why or why not? I (thought) I had solved this problem , but it was pointed out that my argument was flawed. To prove $(*)$, I reasoned as follows: $f$ is continuous, so by MVT, there exists $C_x$ in $[x,x+1]$, such that: $$\int_{x}^{x + 1}f(t)dt = f(C_x)\int_{x}^{x + 1}dt = f(C_x)$$ So it follows that: $$\lim_{x \to \infty}f(x) = \lim_{x \to \infty}f(C_x) = \lim_{x \to \infty}\int_{x}^{x + 1}f(t)dt = 0 $$ What is missing in my work? Or where had I gone wrong? In case I'm mistaken and $(*)$ doesn't hold, in general, please present a counter-example and explain to me where had I gone wrong. Thanks a lot.",,['real-analysis']
50,Question about a differentiable function at point $a$.,Question about a differentiable function at point .,a,"Let $f$ be differentiable at point $a$. Prove than if $\lim \limits_{n \to \infty}x_n =\ a^{+}$ and $\lim \limits_{n \to \infty}y_n = a^{-}$ then $$\lim \limits_{n \to \infty} \frac{ f(x_n) - f(y_n)}{x_n - y_n} = f'(a)$$ I thought about proving this by using lagrange's theorem, but I didn't know where to go with this because the question has limit and its talking about one point, not an interval. Is there any ideas how to solve this question?","Let $f$ be differentiable at point $a$. Prove than if $\lim \limits_{n \to \infty}x_n =\ a^{+}$ and $\lim \limits_{n \to \infty}y_n = a^{-}$ then $$\lim \limits_{n \to \infty} \frac{ f(x_n) - f(y_n)}{x_n - y_n} = f'(a)$$ I thought about proving this by using lagrange's theorem, but I didn't know where to go with this because the question has limit and its talking about one point, not an interval. Is there any ideas how to solve this question?",,"['calculus', 'analysis', 'limits', 'derivatives']"
51,"Why can you prove the continuity of $f(x) = \frac{x}{1+x²}$ with $\delta = \min \{ 2, \frac{\epsilon}{2} \} $?",Why can you prove the continuity of  with ?,"f(x) = \frac{x}{1+x²} \delta = \min \{ 2, \frac{\epsilon}{2} \} ","Let's take my question as an example. I just don't get it. What does $\delta = \min \{ 2, \frac{\epsilon}{2} \} $ mean ? (especially 'min{}')","Let's take my question as an example. I just don't get it. What does $\delta = \min \{ 2, \frac{\epsilon}{2} \} $ mean ? (especially 'min{}')",,"['real-analysis', 'limits', 'epsilon-delta']"
52,How do I prove the circumference of the Koch snowflake is divergent?,How do I prove the circumference of the Koch snowflake is divergent?,,"How do I prove that the circumference of the Koch snowflake is divergent? Let's say that the line in the first picture has a lenght of $3cm$. Since the middle part ($1cm$) gets replaced with a triangle with sidelenghts of $1cm$ each  we can assume that the circumference increases by the $\frac{4}{3}$-fold. I guess to calculate the circumference the following term should work, no? $\lim\limits_{n \rightarrow \infty}{3cm\cdot\frac{4}{3}^n}$ I know that the limit of the circumference is divergent ( $+\infty$). I also know that a divergent sequence is defined as : But how do I prove syntactically and mathematically correct that the sequence diverges to $+\infty$ ?","How do I prove that the circumference of the Koch snowflake is divergent? Let's say that the line in the first picture has a lenght of $3cm$. Since the middle part ($1cm$) gets replaced with a triangle with sidelenghts of $1cm$ each  we can assume that the circumference increases by the $\frac{4}{3}$-fold. I guess to calculate the circumference the following term should work, no? $\lim\limits_{n \rightarrow \infty}{3cm\cdot\frac{4}{3}^n}$ I know that the limit of the circumference is divergent ( $+\infty$). I also know that a divergent sequence is defined as : But how do I prove syntactically and mathematically correct that the sequence diverges to $+\infty$ ?",,"['limits', 'proof-writing', 'fractals']"
53,What are the limitations of the limit product rule?,What are the limitations of the limit product rule?,,"Consider the limit product rule: $$\lim_{x\rightarrow c} (f(x)⋅g(x))=[\lim _{x\rightarrow c} f(x)]⋅[\lim_{x\rightarrow c} g(x)]$$ Now consider, for the sake of the argument, $f(x) = x, g(x) = (e/x)$ Clearly, the limit is e. However, by the product it would be impossible to figure out. Does this mean that the product rule is only valid when the components don't have a limit of 0 or infinity? Will it always work for other cases?","Consider the limit product rule: $$\lim_{x\rightarrow c} (f(x)⋅g(x))=[\lim _{x\rightarrow c} f(x)]⋅[\lim_{x\rightarrow c} g(x)]$$ Now consider, for the sake of the argument, $f(x) = x, g(x) = (e/x)$ Clearly, the limit is e. However, by the product it would be impossible to figure out. Does this mean that the product rule is only valid when the components don't have a limit of 0 or infinity? Will it always work for other cases?",,['limits']
54,Is my proof that $\sum \frac{(-1)^n}{n+\frac{10100}{n}}$ is convergent valid?,Is my proof that  is convergent valid?,\sum \frac{(-1)^n}{n+\frac{10100}{n}},"I want to answer whether the following series is convergent or divergent: $$\sum_{n=1}^{\infty} \frac{(-1)^n}{n+\frac{10100}{n}}$$ Alternating series test seems like a good idea. So if I prove that $\frac{1}{n+\frac{10100}{n}}$ is monotone for large $n$ and converges to $0$ then I'm done. Convergence to $0$ is trivial so all I need to do is to prove that the sequence is monotone, for sufficiently large $n$. Here is what I've done: $\frac{1}{n+1+\frac{10100}{n+1}}-\frac{1}{n+\frac{10100}{n}}=\frac{n+\frac{10100}{n}-n-1-\frac{10100}{n+1}}{(n+1+\frac{10100}{n+1})(n+\frac{10100}{n})}$ The denominator is always positive so I'm only examining the numerator now. $n+\frac{10100}{n}-n-1-\frac{10100}{n+1}=\frac{10100(n+1)-10100n-n(n+1)}{n(n+1)}$ Again, the denominator is always positive, so let's examine the numerator. $10100(n+1)-10100n-n(n+1)=10100-n^2-n=10100-(n^2+n)$ which is less than zero for sufficiently large $n$. That means that for sufficiently large $n$ the sequence is monotonely decreasing so we can finish by saying our series is convergent by alternating series test. Is everything correct with my logic? Could this be done simpler?","I want to answer whether the following series is convergent or divergent: $$\sum_{n=1}^{\infty} \frac{(-1)^n}{n+\frac{10100}{n}}$$ Alternating series test seems like a good idea. So if I prove that $\frac{1}{n+\frac{10100}{n}}$ is monotone for large $n$ and converges to $0$ then I'm done. Convergence to $0$ is trivial so all I need to do is to prove that the sequence is monotone, for sufficiently large $n$. Here is what I've done: $\frac{1}{n+1+\frac{10100}{n+1}}-\frac{1}{n+\frac{10100}{n}}=\frac{n+\frac{10100}{n}-n-1-\frac{10100}{n+1}}{(n+1+\frac{10100}{n+1})(n+\frac{10100}{n})}$ The denominator is always positive so I'm only examining the numerator now. $n+\frac{10100}{n}-n-1-\frac{10100}{n+1}=\frac{10100(n+1)-10100n-n(n+1)}{n(n+1)}$ Again, the denominator is always positive, so let's examine the numerator. $10100(n+1)-10100n-n(n+1)=10100-n^2-n=10100-(n^2+n)$ which is less than zero for sufficiently large $n$. That means that for sufficiently large $n$ the sequence is monotonely decreasing so we can finish by saying our series is convergent by alternating series test. Is everything correct with my logic? Could this be done simpler?",,"['calculus', 'sequences-and-series', 'limits']"
55,"Limit, having trouble applying L'Hospital rule","Limit, having trouble applying L'Hospital rule",,I have been asked to solve for this limit: $$\lim_{x \to 0} \frac{\sin^2(3x)}{1-\cos(2x)}$$ I try to find the derivative of the numerator and denominator: $$\frac{6\sin(3x)\cos(3x)}{2\sin(2x)}$$ but that still gives me a $\frac{0}{0}$. How do I solve this,I have been asked to solve for this limit: $$\lim_{x \to 0} \frac{\sin^2(3x)}{1-\cos(2x)}$$ I try to find the derivative of the numerator and denominator: $$\frac{6\sin(3x)\cos(3x)}{2\sin(2x)}$$ but that still gives me a $\frac{0}{0}$. How do I solve this,,"['calculus', 'limits']"
56,Difference in treatment of Infinity and Undefined,Difference in treatment of Infinity and Undefined,,"I understand that $$1)\; \lim_{x\to0}\frac1{x} = +\infty$$ $$2)\; \frac1{0} is\,undefined $$ If both infinity and undefined are just abstract concepts and not a type of number, why I see this kind of expressions used $$ \lim_{x\to\infty}expression$$ but not these kind of expressions? $$ \lim_{x\to undefined}expression$$","I understand that $$1)\; \lim_{x\to0}\frac1{x} = +\infty$$ $$2)\; \frac1{0} is\,undefined $$ If both infinity and undefined are just abstract concepts and not a type of number, why I see this kind of expressions used $$ \lim_{x\to\infty}expression$$ but not these kind of expressions? $$ \lim_{x\to undefined}expression$$",,"['limits', 'infinity']"
57,Limit of square root function at $x \to 6$,Limit of square root function at,x \to 6,"I'm trying to find the limit of the following function at $x \to 6$: $$\frac{x^2-36}{\sqrt{x^2-12x+36}}$$ i've simplified it so that it becomes $\dfrac{(x+6)(x-6)}{\sqrt{(x-6)^2}}$, which simplifies to $x+6$. the problem is that i shouldn't be getting to $x+6$, because then id be able to plug in $6$, and say that the limit exists for the left hand side and the right hand side of $6$, when clearly i can tell from the graph that the limit does not exist. What am I doing wrong?","I'm trying to find the limit of the following function at $x \to 6$: $$\frac{x^2-36}{\sqrt{x^2-12x+36}}$$ i've simplified it so that it becomes $\dfrac{(x+6)(x-6)}{\sqrt{(x-6)^2}}$, which simplifies to $x+6$. the problem is that i shouldn't be getting to $x+6$, because then id be able to plug in $6$, and say that the limit exists for the left hand side and the right hand side of $6$, when clearly i can tell from the graph that the limit does not exist. What am I doing wrong?",,"['calculus', 'limits', 'factoring', 'radicals']"
58,How to show that limit of $(x^3+y^3)/(x-y)$ does not exist at origin?,How to show that limit of  does not exist at origin?,(x^3+y^3)/(x-y),"Show that the limit as $(x,y)\to (0,0)$ does not exist for the function   $$ f(x,t)=\begin{cases}\frac{x^3+y^3}{x-y},\quad & x\ne y \\ 0,\quad & x=y\end{cases} $$ My solution is below, but it appears to be inconsistent with the problem. What is wrong?","Show that the limit as $(x,y)\to (0,0)$ does not exist for the function   $$ f(x,t)=\begin{cases}\frac{x^3+y^3}{x-y},\quad & x\ne y \\ 0,\quad & x=y\end{cases} $$ My solution is below, but it appears to be inconsistent with the problem. What is wrong?",,"['limits', 'multivariable-calculus']"
59,How to prove that $0<e-(1+\frac{1}{n})^n<\frac{3}{n}$,How to prove that,0<e-(1+\frac{1}{n})^n<\frac{3}{n},I proved the first inequality $0<e-(1+\frac{1}{n})^n$ but now struggle with second part. I tried mathematical induction: For $n=1$  $e-2<\frac{3}{1}$ $e-(1+\frac{1}{n})^n<\frac{3}{n} \Rightarrow e-(1+\frac{1}{n+1})^{n+1}<\frac{3}{n+1}$,I proved the first inequality $0<e-(1+\frac{1}{n})^n$ but now struggle with second part. I tried mathematical induction: For $n=1$  $e-2<\frac{3}{1}$ $e-(1+\frac{1}{n})^n<\frac{3}{n} \Rightarrow e-(1+\frac{1}{n+1})^{n+1}<\frac{3}{n+1}$,,"['real-analysis', 'limits']"
60,Evaluating $\lim_{x \to e} \left ( \ln(x)\right )^{1/(x - e)}$ with substitutions,Evaluating  with substitutions,\lim_{x \to e} \left ( \ln(x)\right )^{1/(x - e)},"I evaluated the limit with two substitutions: $$\begin{align} L&:=\lim_{x \to e} \left ( \ln(x)\right )^{1/(x - e)}=\\ &=\begin{bmatrix} t = x - e\\  x = t + e \end{bmatrix}=\lim_{t \to 0} \left ( \ln(t + e)\right )^{1/t}=\\ &=e^{\displaystyle\lim_{t \to 0} \frac{\ln(\ln(t + e))}{t}}\\ \end{align}$$ Now the exponent becomes: $$\begin{align} \lim_{t \to 0} \frac{\ln(\ln(t + e))}{t} &= \begin{bmatrix} \ln(t + e) = 1 + \omega\\  t = e^{1 + \omega} - e \end{bmatrix} = \lim_{\omega \to 0} \frac{\ln(1+\omega)}{e(e^\omega - 1)} =\\ &=\lim_{\omega \to 0}\frac 1e \cdot \frac{\ln(1+\omega)}{\omega} \cdot \frac{\omega}{e^\omega - 1} = \frac 1e \end{align}$$ So we conclude that $L=e^{1/e}$. My question is: can we always substitute as needed or are there constraints that must be met? I'm asking this because in class the professor used five blackboards, so I thought that maybe there was something wrong with my approach.","I evaluated the limit with two substitutions: $$\begin{align} L&:=\lim_{x \to e} \left ( \ln(x)\right )^{1/(x - e)}=\\ &=\begin{bmatrix} t = x - e\\  x = t + e \end{bmatrix}=\lim_{t \to 0} \left ( \ln(t + e)\right )^{1/t}=\\ &=e^{\displaystyle\lim_{t \to 0} \frac{\ln(\ln(t + e))}{t}}\\ \end{align}$$ Now the exponent becomes: $$\begin{align} \lim_{t \to 0} \frac{\ln(\ln(t + e))}{t} &= \begin{bmatrix} \ln(t + e) = 1 + \omega\\  t = e^{1 + \omega} - e \end{bmatrix} = \lim_{\omega \to 0} \frac{\ln(1+\omega)}{e(e^\omega - 1)} =\\ &=\lim_{\omega \to 0}\frac 1e \cdot \frac{\ln(1+\omega)}{\omega} \cdot \frac{\omega}{e^\omega - 1} = \frac 1e \end{align}$$ So we conclude that $L=e^{1/e}$. My question is: can we always substitute as needed or are there constraints that must be met? I'm asking this because in class the professor used five blackboards, so I thought that maybe there was something wrong with my approach.",,"['calculus', 'limits']"
61,"Evaluate $\lim_{x\ \to\ \infty}\left(\,\sqrt{\,x^{4} + ax^{2} + 1\,}\, - \,\sqrt{\,x^{4} + bx^{2} +1\,}\,\right)$",Evaluate,"\lim_{x\ \to\ \infty}\left(\,\sqrt{\,x^{4} + ax^{2} + 1\,}\, - \,\sqrt{\,x^{4} + bx^{2} +1\,}\,\right)","I rewrote the function to the form   $$ x^{2}\left(\, \sqrt{\,1 + \dfrac{a}{x^{2}} + \dfrac{1}{x^{4}}\,}\,-\, \sqrt{\,1 + \dfrac{b}{x^{2}} + \dfrac{1}{x^{4}}\,}\,\right) $$   and figured that the answer would be $0$, but apparently this is wrong. The correct answer is $\displaystyle{{1 \over 2}\left(\,a - b\,\right)}$.","I rewrote the function to the form   $$ x^{2}\left(\, \sqrt{\,1 + \dfrac{a}{x^{2}} + \dfrac{1}{x^{4}}\,}\,-\, \sqrt{\,1 + \dfrac{b}{x^{2}} + \dfrac{1}{x^{4}}\,}\,\right) $$   and figured that the answer would be $0$, but apparently this is wrong. The correct answer is $\displaystyle{{1 \over 2}\left(\,a - b\,\right)}$.",,['limits']
62,Why does $x^{(1/\ln(x))} = e$?,Why does ?,x^{(1/\ln(x))} = e,"Why does $x^{(1/\ln(x))} = e$, espacially for a limit as it reaches infinity. I figured it would just be $0$ since $\frac{1}{\ln(\infty)}$ should equal $0$. I don't get the concept.","Why does $x^{(1/\ln(x))} = e$, espacially for a limit as it reaches infinity. I figured it would just be $0$ since $\frac{1}{\ln(\infty)}$ should equal $0$. I don't get the concept.",,['limits']
63,derive limit to make a function continuous,derive limit to make a function continuous,,"Here's the problem: Choose the value of k that makes the following  function continuous at $x = 1$: $f(x)=\begin{cases} \frac{-8x^2 + 48x - 40}{x - 1} &	x < 1\\ -2x + k &x \geq 1 \end{cases}$ My steps: $\lim_{x\uparrow 1} f(x) = \lim_{x\downarrow 1} f(x)$ $\frac{-8x^2 + 48x - 40}{x - 1} = -2x + k$ $\frac{-8(x^2 - 6x + 5)}{x - 1} = -2x + k$ $\frac{-8(x - 5)(x - 1)}{x - 1} = -2x + k$ $-8(x - 5) = -2x + k$ $-8x - (-8)\cdot5 = -2x + k$ $-8x + 40 = -2x + k$ $-8x + 2x + 40 = k$ (See note at bottom) $-6x + 40 = k$ $-6\cdot1 + 40 = k$ $-6 + 40 = k$ $36 = k$ The solution steps: For f to be continuous at $x = 1$ we need $\lim_{x\uparrow 1} f(x) = \lim_{x\downarrow1} f(x) = f(1)$ First lets evaluate lim x→1− f(x) . Since x < 1 as x approaches 1 from the left, f(x) = (−8x^2 + 48x − 40)/(x − 1) as x→1− So lim x→1− f(x) = lim x→1−  (−8x^2 + 48x − 40)/(x − 1) Start by factoring the numerator. In this case we find: lim x→1− (−8x^2 + 48x − 40)/(−3x^2 − 15x + 18) = lim x→1− (−8x + 40)(x − 1)/(x − 1) Aside: can anyone explain (−3x^2 − 15x + 18) in the denominator? Since we are taking the limit as x→1− , we may assume that x ≠ 1 . Canceling factors we see: \lim x→1− (−8x + 40)(x − 1)/(−3x − 18)(x − 1) = \lim x→1− (−8x + 40) We can evaluate this linear function at x = 1 . Hence, lim x→1− −8x^2 + 48x − 40)/(−3x^2 − 15x + 18) = −8(1) + 40 . Thus, lim x→1− f(x) = 32 . Thus lim x→1− f(x) = 32 lim x→1+ f(x) = lim x→ (−2x + k) , because x > 1 as x approaches 1 from the right. lim x→ (−2x + k) = −2⋅1 + k = −2 + k = f(1) because linear functions are continuous. For f to be continuous, these limits have to be equal. Thus 32 = −2 + k When k = 34 , f is continuous. NOTE: This is where I diverged from the solution by moving -2x to the left. My question is, assuming the given solution is correct, why is this nominally valid algebraic step not permitted?","Here's the problem: Choose the value of k that makes the following  function continuous at $x = 1$: $f(x)=\begin{cases} \frac{-8x^2 + 48x - 40}{x - 1} &	x < 1\\ -2x + k &x \geq 1 \end{cases}$ My steps: $\lim_{x\uparrow 1} f(x) = \lim_{x\downarrow 1} f(x)$ $\frac{-8x^2 + 48x - 40}{x - 1} = -2x + k$ $\frac{-8(x^2 - 6x + 5)}{x - 1} = -2x + k$ $\frac{-8(x - 5)(x - 1)}{x - 1} = -2x + k$ $-8(x - 5) = -2x + k$ $-8x - (-8)\cdot5 = -2x + k$ $-8x + 40 = -2x + k$ $-8x + 2x + 40 = k$ (See note at bottom) $-6x + 40 = k$ $-6\cdot1 + 40 = k$ $-6 + 40 = k$ $36 = k$ The solution steps: For f to be continuous at $x = 1$ we need $\lim_{x\uparrow 1} f(x) = \lim_{x\downarrow1} f(x) = f(1)$ First lets evaluate lim x→1− f(x) . Since x < 1 as x approaches 1 from the left, f(x) = (−8x^2 + 48x − 40)/(x − 1) as x→1− So lim x→1− f(x) = lim x→1−  (−8x^2 + 48x − 40)/(x − 1) Start by factoring the numerator. In this case we find: lim x→1− (−8x^2 + 48x − 40)/(−3x^2 − 15x + 18) = lim x→1− (−8x + 40)(x − 1)/(x − 1) Aside: can anyone explain (−3x^2 − 15x + 18) in the denominator? Since we are taking the limit as x→1− , we may assume that x ≠ 1 . Canceling factors we see: \lim x→1− (−8x + 40)(x − 1)/(−3x − 18)(x − 1) = \lim x→1− (−8x + 40) We can evaluate this linear function at x = 1 . Hence, lim x→1− −8x^2 + 48x − 40)/(−3x^2 − 15x + 18) = −8(1) + 40 . Thus, lim x→1− f(x) = 32 . Thus lim x→1− f(x) = 32 lim x→1+ f(x) = lim x→ (−2x + k) , because x > 1 as x approaches 1 from the right. lim x→ (−2x + k) = −2⋅1 + k = −2 + k = f(1) because linear functions are continuous. For f to be continuous, these limits have to be equal. Thus 32 = −2 + k When k = 34 , f is continuous. NOTE: This is where I diverged from the solution by moving -2x to the left. My question is, assuming the given solution is correct, why is this nominally valid algebraic step not permitted?",,['limits']
64,Behaviour of the function $\ln(1+ x^2)$,Behaviour of the function,\ln(1+ x^2),"Thus function has derivative equal to: $\frac{2x}{1+x^2}$. This indicates that it will flatten out while approaching infinity, ie, should have an asymptote. Yet, the function does not have any real limiting value at infinity. To imvestigate further, I plotted the graph, which showed the asymptote/limiting value as 14.25 (you may check youtself if this is right) What can the reason be for not getting a real limit from the function itself? Please explain keeping in mind that I am in the last year of high school.","Thus function has derivative equal to: $\frac{2x}{1+x^2}$. This indicates that it will flatten out while approaching infinity, ie, should have an asymptote. Yet, the function does not have any real limiting value at infinity. To imvestigate further, I plotted the graph, which showed the asymptote/limiting value as 14.25 (you may check youtself if this is right) What can the reason be for not getting a real limit from the function itself? Please explain keeping in mind that I am in the last year of high school.",,"['calculus', 'limits', 'functions', 'logarithms', 'graphing-functions']"
65,"Evaluating the limits $\lim_{(x,y)\to(\infty,\infty)}\frac{2x-y}{x^2-xy+y^2}$ and $\lim_{(x,y)\to(\infty,8)}(1+\frac{1}{3x})^\frac{x^2}{x+y}$",Evaluating the limits  and,"\lim_{(x,y)\to(\infty,\infty)}\frac{2x-y}{x^2-xy+y^2} \lim_{(x,y)\to(\infty,8)}(1+\frac{1}{3x})^\frac{x^2}{x+y}","I got the following problem: Evaluate the following limits or show that it does not exist: $$\lim_{(x,y)\to(\infty,\infty)}\frac{2x-y}{x^2-xy+y^2}$$ and $$\lim_{(x,y)\to(\infty,8)}\left(1+\frac{1}{3x}\right)^\frac{x^2}{x+y}$$ I tried for an hour and half evaluating each of those limits but I failed and I got nothing useful to share. Some hints will be appreciated. Thanks.","I got the following problem: Evaluate the following limits or show that it does not exist: $$\lim_{(x,y)\to(\infty,\infty)}\frac{2x-y}{x^2-xy+y^2}$$ and $$\lim_{(x,y)\to(\infty,8)}\left(1+\frac{1}{3x}\right)^\frac{x^2}{x+y}$$ I tried for an hour and half evaluating each of those limits but I failed and I got nothing useful to share. Some hints will be appreciated. Thanks.",,"['calculus', 'limits', 'multivariable-calculus']"
66,I need compute a rational limit that involves roots,I need compute a rational limit that involves roots,,"I need compute the result of this limit without l'hopital's rule, I tried different techniques but I did not get the limit, which is 1/32, I would appreciate if somebody help me. Thanks. $$\lim_{y\to32}\frac{\sqrt[5]{y^2} - 3\sqrt[5]{y} + 2}{y - 4\sqrt[5]{y^3}}$$","I need compute the result of this limit without l'hopital's rule, I tried different techniques but I did not get the limit, which is 1/32, I would appreciate if somebody help me. Thanks. $$\lim_{y\to32}\frac{\sqrt[5]{y^2} - 3\sqrt[5]{y} + 2}{y - 4\sqrt[5]{y^3}}$$",,"['calculus', 'limits']"
67,Proof that the limit of a sequence is $e=2.71828\ldots$,Proof that the limit of a sequence is,e=2.71828\ldots,"Consider the sequence $\{a_n\}$ defined as follows $$\{a_n\}_{n\ge{1}}=\left(1+\frac{1}{n}\right)^n\;,\; n\in\mathbb{N}$$ The question is to prove that $\{a_n\}$ has a limit as $n\to\infty$ and to find that limit. This is a well known sequence and everbody in our class knows that the limit is Euler's number (i.e $e=2.718\ldots$ ). Indeed in high-school 'e' was defined as the limit of this particular sequence. However none of us could come up with a rigrous proof that this is indeed true. Do note that since we have only touched upon limits so far in our calculus class, our teacher probably doesn't want a proof involving integrals.","Consider the sequence defined as follows The question is to prove that has a limit as and to find that limit. This is a well known sequence and everbody in our class knows that the limit is Euler's number (i.e ). Indeed in high-school 'e' was defined as the limit of this particular sequence. However none of us could come up with a rigrous proof that this is indeed true. Do note that since we have only touched upon limits so far in our calculus class, our teacher probably doesn't want a proof involving integrals.","\{a_n\} \{a_n\}_{n\ge{1}}=\left(1+\frac{1}{n}\right)^n\;,\; n\in\mathbb{N} \{a_n\} n\to\infty e=2.718\ldots","['calculus', 'sequences-and-series', 'limits']"
68,Finding multivariable limit,Finding multivariable limit,,"I would like to find the following limit $$\lim_{(x,y,z)\to(0,0,0)}\frac{x^3yz+xy^3z+xyz^3}{x^4+y^4+z^4}.$$ It looks like it would be zero since if we put $M=\max\{x,y,z\}$ and $m=\min\{x,y,z\}$, then $$\Big|\frac{x^3yz+xy^3z+xyz^3}{x^4+y^4+z^4}\Big| \leq \Big|\frac{M^5}{m^4}\Big|$$ so the exponent in the denominator is bigger than the exponent in the numerator. But how do I actually calculate this limit? Thank you.","I would like to find the following limit $$\lim_{(x,y,z)\to(0,0,0)}\frac{x^3yz+xy^3z+xyz^3}{x^4+y^4+z^4}.$$ It looks like it would be zero since if we put $M=\max\{x,y,z\}$ and $m=\min\{x,y,z\}$, then $$\Big|\frac{x^3yz+xy^3z+xyz^3}{x^4+y^4+z^4}\Big| \leq \Big|\frac{M^5}{m^4}\Big|$$ so the exponent in the denominator is bigger than the exponent in the numerator. But how do I actually calculate this limit? Thank you.",,"['calculus', 'limits', 'multivariable-calculus']"
69,Simple series divergence problem,Simple series divergence problem,,"I've got a problem here: $$\sum_{n=1}^{\infty} \frac{5^n}{n(3^{n+1})}$$ I've used the ratio test and essentially did this: $$\sum_{n=1}^{\infty} \left( \frac{5^{n + 1}}{n (3^{n+1+1})} / \frac{5^n}{n(3^{n+1})}\right) = \frac{5^n\,5}{9(n+1)3^n} \cdot \frac{n\,3^n}{5^n}$$ With a bunch of cancellations we get $\dfrac{5n}{9n+9}$, which means it converges, as $\frac{5}{9} < 1$. But the answer says it diverges! I even tried the root test and got the same result. Where am I going wrong?","I've got a problem here: $$\sum_{n=1}^{\infty} \frac{5^n}{n(3^{n+1})}$$ I've used the ratio test and essentially did this: $$\sum_{n=1}^{\infty} \left( \frac{5^{n + 1}}{n (3^{n+1+1})} / \frac{5^n}{n(3^{n+1})}\right) = \frac{5^n\,5}{9(n+1)3^n} \cdot \frac{n\,3^n}{5^n}$$ With a bunch of cancellations we get $\dfrac{5n}{9n+9}$, which means it converges, as $\frac{5}{9} < 1$. But the answer says it diverges! I even tried the root test and got the same result. Where am I going wrong?",,"['limits', 'divergent-series']"
70,$\lim_{n \rightarrow \infty} n ((n^5 +5n^4)^{1/5} - (n^2 +2n)^{1/2})$,,\lim_{n \rightarrow \infty} n ((n^5 +5n^4)^{1/5} - (n^2 +2n)^{1/2}),"$$\lim_{n \rightarrow \infty} n ((n^5 +5n^4)^{1/5} - (n^2 +2n)^{1/2})$$ Please, help me to find the limit.","$$\lim_{n \rightarrow \infty} n ((n^5 +5n^4)^{1/5} - (n^2 +2n)^{1/2})$$ Please, help me to find the limit.",,"['calculus', 'limits']"
71,limit of a sum of powers of integers [duplicate],limit of a sum of powers of integers [duplicate],,"This question already has answers here : What is the result of $ \lim_{n \to \infty} \frac{ \sum^n_{i=1} i^k}{n^{k+1}},\ k \in \mathbb{R} $ and why? (4 answers) Closed 9 years ago . I ran across the following problem in my Advanced Calculus class: For a fixed positive number $\beta$, find $$\lim_{n\to \infty} \left[\frac {1^\beta + 2^\beta + \cdots + n^\beta} {n^{\beta + 1}}\right]$$ I tried manipulating the expression inside the limit but didn't come up with anything useful. I also noted that the numerator can be rewritten as  $$\sum_{i=1}^{n}i^\beta$$ which is a well-known formula with a closed form (Faulhaber's formula) but I don't fully understand that formula and we haven't talked about the Bernoulli numbers at all, so I think the author intended for the problem to be solved a different way. Any suggestions on how to tackle this would be much appreciated.","This question already has answers here : What is the result of $ \lim_{n \to \infty} \frac{ \sum^n_{i=1} i^k}{n^{k+1}},\ k \in \mathbb{R} $ and why? (4 answers) Closed 9 years ago . I ran across the following problem in my Advanced Calculus class: For a fixed positive number $\beta$, find $$\lim_{n\to \infty} \left[\frac {1^\beta + 2^\beta + \cdots + n^\beta} {n^{\beta + 1}}\right]$$ I tried manipulating the expression inside the limit but didn't come up with anything useful. I also noted that the numerator can be rewritten as  $$\sum_{i=1}^{n}i^\beta$$ which is a well-known formula with a closed form (Faulhaber's formula) but I don't fully understand that formula and we haven't talked about the Bernoulli numbers at all, so I think the author intended for the problem to be solved a different way. Any suggestions on how to tackle this would be much appreciated.",,"['real-analysis', 'limits', 'summation']"
72,Proof that the limit of $\frac{1}{x}$ as $x$ approaches $0$ does not exist,Proof that the limit of  as  approaches  does not exist,\frac{1}{x} x 0,"Hello I was hoping that someone might be able to verify that the following proof that $\lim_{x\to 0} {1\over x}$ does not exist is correct. First assume that $\lim_{x\to 0} {1\over x} = L$. This means that for every $\epsilon > 0$ there is a $\delta > 0$ such that for all $x$ if $0 < \lvert x\rvert < \delta$ then $\lvert{1\over x} - L \rvert <\epsilon.$  Now let $\epsilon=1$ and choose $x < \min(1,\delta)$.  Therefore there is a $\delta>0$ such that if $0 < \lvert x\rvert < \delta$ then $\lvert{1\over x} - L \rvert <\epsilon$.  It follows that $\lvert{1\over x}\rvert < 1+ \lvert L\rvert$.  However clearly $\lvert{1\over x}\rvert>1$ and therefore a contradiction has been reached and there is no number $L$ such that $\lim_{x\to 0} {1\over x} = L$.","Hello I was hoping that someone might be able to verify that the following proof that $\lim_{x\to 0} {1\over x}$ does not exist is correct. First assume that $\lim_{x\to 0} {1\over x} = L$. This means that for every $\epsilon > 0$ there is a $\delta > 0$ such that for all $x$ if $0 < \lvert x\rvert < \delta$ then $\lvert{1\over x} - L \rvert <\epsilon.$  Now let $\epsilon=1$ and choose $x < \min(1,\delta)$.  Therefore there is a $\delta>0$ such that if $0 < \lvert x\rvert < \delta$ then $\lvert{1\over x} - L \rvert <\epsilon$.  It follows that $\lvert{1\over x}\rvert < 1+ \lvert L\rvert$.  However clearly $\lvert{1\over x}\rvert>1$ and therefore a contradiction has been reached and there is no number $L$ such that $\lim_{x\to 0} {1\over x} = L$.",,"['real-analysis', 'limits']"
73,Limit of the sequence $ x_{n+1}=x_n+\sqrt{a+x_n^2}$,Limit of the sequence, x_{n+1}=x_n+\sqrt{a+x_n^2},"Let $a$ be a real number and $x_1>0$. The sequence $\{x_n\}_{n \ge 1}$ is recursively given by the relation: $$ x_{n+1}=x_n+\sqrt{a+x_n^2}$$ for any natural number $n$. How to evaluate the limit $ \lim\limits_{n \to \infty} 2^{-n}x_n$ ? I think we have to consider the two cases $a>0$ and $a<0$ separately. The case $a<0$, I could manage by making the substitution $x_n = -a\cosh y_n$, and the limit came out to be $\dfrac{1}{2}$. I can't figure out how to deal with the case $a>0$. Any pointers, ideas or solution ?","Let $a$ be a real number and $x_1>0$. The sequence $\{x_n\}_{n \ge 1}$ is recursively given by the relation: $$ x_{n+1}=x_n+\sqrt{a+x_n^2}$$ for any natural number $n$. How to evaluate the limit $ \lim\limits_{n \to \infty} 2^{-n}x_n$ ? I think we have to consider the two cases $a>0$ and $a<0$ separately. The case $a<0$, I could manage by making the substitution $x_n = -a\cosh y_n$, and the limit came out to be $\dfrac{1}{2}$. I can't figure out how to deal with the case $a>0$. Any pointers, ideas or solution ?",,"['calculus', 'sequences-and-series', 'limits']"
74,Finding some counterexamples,Finding some counterexamples,,"The sequence of  $\begin{Bmatrix} {x}_{n} \end{Bmatrix}$ is strictly decreasing,$\quad \lim_{n\to\infty  }{x}_{n}=0 \quad $,and$\quad \lim_{n\to\infty  }{y}_{n}=0 .$ From the above conditions,whether we can get the following conclusion: If $\quad \lim_{n\to\infty  }\frac{{y}_{n+1}-{y}_{n}}{{x}_{n+1}-{x}_{n}}=\infty. then  \quad   \lim_{n\to\infty  }\frac{{y}_{n}}{{x}_{n}}=\infty $. If the conclusion is correct, please give the proof; or some ounterexamples.","The sequence of  $\begin{Bmatrix} {x}_{n} \end{Bmatrix}$ is strictly decreasing,$\quad \lim_{n\to\infty  }{x}_{n}=0 \quad $,and$\quad \lim_{n\to\infty  }{y}_{n}=0 .$ From the above conditions,whether we can get the following conclusion: If $\quad \lim_{n\to\infty  }\frac{{y}_{n+1}-{y}_{n}}{{x}_{n+1}-{x}_{n}}=\infty. then  \quad   \lim_{n\to\infty  }\frac{{y}_{n}}{{x}_{n}}=\infty $. If the conclusion is correct, please give the proof; or some ounterexamples.",,"['calculus', 'sequences-and-series', 'limits']"
75,A misconception about arbitary constant,A misconception about arbitary constant,,"Given a function $f(x)$ from $\mathbb R$ to $\mathbb R$, If $f'(x)=0$ $\text{ for all } x\in \mathbb R$. Then $f(x)=C$.(This is my understanding) Question: I think that $C$ has to remain constant for $\text{ for all } x\in\mathbb R$. But this is not valid for $f(x)= $$\arctan x+\arctan\frac{1}{x}$. clearly $f'(x)=0$ but $C$ doesn't remain constant. For all real positive numbers its$\frac{\pi}{2}$ while for -ve real numbers its $\frac{-\pi}{2}$. I just don't understand it. Can anyone help me?","Given a function $f(x)$ from $\mathbb R$ to $\mathbb R$, If $f'(x)=0$ $\text{ for all } x\in \mathbb R$. Then $f(x)=C$.(This is my understanding) Question: I think that $C$ has to remain constant for $\text{ for all } x\in\mathbb R$. But this is not valid for $f(x)= $$\arctan x+\arctan\frac{1}{x}$. clearly $f'(x)=0$ but $C$ doesn't remain constant. For all real positive numbers its$\frac{\pi}{2}$ while for -ve real numbers its $\frac{-\pi}{2}$. I just don't understand it. Can anyone help me?",,"['calculus', 'limits', 'constants']"
76,Solve multivariable limit,Solve multivariable limit,,"$$\lim_{(x,y) \to (0,0)} \frac{x^3 + y^4}{x^2 + y^2}$$ I am almost sure it is equal to $0$ but I can't prove it. Please give me some hint.","$$\lim_{(x,y) \to (0,0)} \frac{x^3 + y^4}{x^2 + y^2}$$ I am almost sure it is equal to $0$ but I can't prove it. Please give me some hint.",,"['calculus', 'limits', 'multivariable-calculus']"
77,How do you evaluate this limit? $\ln({x^3+2x^2+x})+ \frac{2}{x}$,How do you evaluate this limit?,\ln({x^3+2x^2+x})+ \frac{2}{x},"How do you evaluate the following? $$\lim_{x \to 0^+} \left [ \ln({x^3+2x^2+x})+ \frac{2}{x} \right ]$$ If I plug in $x$, I get $\infty-\infty$, which is undetermined, and I haven't been able to get the limit at a more manageable form. Can you please help me?","How do you evaluate the following? $$\lim_{x \to 0^+} \left [ \ln({x^3+2x^2+x})+ \frac{2}{x} \right ]$$ If I plug in $x$, I get $\infty-\infty$, which is undetermined, and I haven't been able to get the limit at a more manageable form. Can you please help me?",,"['real-analysis', 'limits']"
78,"Could somebody validate my proof regarding the limit of $\ln(x_n)$ when, $x_n$ tends to $a$?","Could somebody validate my proof regarding the limit of  when,  tends to ?",\ln(x_n) x_n a,"So, let me cearly state the problem: Let $(x_n)$ be a convergent sequence, with: $ x_n > 0 $, $\forall n$, n natural number, and $x_n \to a$, with $a>0$. Then $\ln{x_n} \to \ln{a}$. Here is my idea for a proof: Our goal is to proof that there $\forall\epsilon>0$ there is some $n_{\epsilon}$, such that $\forall n \ge n_{\epsilon} $, we have that $|\ln{x_n}-\ln{a}|<\epsilon$. So here is what I did. First: $|\ln{x_n}-\ln{a}| = |\ln{\frac{x_n}{a}}| $ Then, beacause $\ln{x} <x$, $\forall x>0$, it easily follows that $\ |\ln{x}| <x$, $\forall x>0$. Applying this, we have that: $$|\ln{x_n}-\ln{a}| = |\ln{\frac{x_n}{a}}| < \frac{x_n}{a} = \frac{x_n-a+a}{a}= \frac{x_n-a}{a} +1  $$ Now, we use the basic property of the absolute value: $x_n-a \le |x_n-a|$, that gives us: $$|\ln{x_n}-\ln{a}| <   \frac{x_n-a}{a} +1 \le   \frac{|x_n-a|}{a} +1 $$ Now, we use the fact that $ x_n \to a $. So, $\forall\epsilon>0$ there is some $n_{\epsilon}$, such that $\forall n \ge n_{\epsilon} $, we have that $|x_n-a|<\epsilon$. We choose an epsilon that takes the form $a(\epsilon_0-1)$. This choice is possible for any $\epsilon_0$. Now, we have managed to obtain that: $$|\ln{x_n}-\ln{a}| < \frac{a(\epsilon_0-1)}{a} +1 = \epsilon_0, \forall n \ge n_{\epsilon} $$ Since $\forall \epsilon_0 > 0$ we can find an $n_{\epsilon}$, such that $\forall n \ge n_{\epsilon}$, the above inequality is staisfied, our claim is proved. So, can you please tell me if my proof si correct? I've tried to find a proof, only for the limit of sequences! This problem has been on my nerves for s while. Also, probably there is some simpler way to do it, but I couldn't find it.","So, let me cearly state the problem: Let $(x_n)$ be a convergent sequence, with: $ x_n > 0 $, $\forall n$, n natural number, and $x_n \to a$, with $a>0$. Then $\ln{x_n} \to \ln{a}$. Here is my idea for a proof: Our goal is to proof that there $\forall\epsilon>0$ there is some $n_{\epsilon}$, such that $\forall n \ge n_{\epsilon} $, we have that $|\ln{x_n}-\ln{a}|<\epsilon$. So here is what I did. First: $|\ln{x_n}-\ln{a}| = |\ln{\frac{x_n}{a}}| $ Then, beacause $\ln{x} <x$, $\forall x>0$, it easily follows that $\ |\ln{x}| <x$, $\forall x>0$. Applying this, we have that: $$|\ln{x_n}-\ln{a}| = |\ln{\frac{x_n}{a}}| < \frac{x_n}{a} = \frac{x_n-a+a}{a}= \frac{x_n-a}{a} +1  $$ Now, we use the basic property of the absolute value: $x_n-a \le |x_n-a|$, that gives us: $$|\ln{x_n}-\ln{a}| <   \frac{x_n-a}{a} +1 \le   \frac{|x_n-a|}{a} +1 $$ Now, we use the fact that $ x_n \to a $. So, $\forall\epsilon>0$ there is some $n_{\epsilon}$, such that $\forall n \ge n_{\epsilon} $, we have that $|x_n-a|<\epsilon$. We choose an epsilon that takes the form $a(\epsilon_0-1)$. This choice is possible for any $\epsilon_0$. Now, we have managed to obtain that: $$|\ln{x_n}-\ln{a}| < \frac{a(\epsilon_0-1)}{a} +1 = \epsilon_0, \forall n \ge n_{\epsilon} $$ Since $\forall \epsilon_0 > 0$ we can find an $n_{\epsilon}$, such that $\forall n \ge n_{\epsilon}$, the above inequality is staisfied, our claim is proved. So, can you please tell me if my proof si correct? I've tried to find a proof, only for the limit of sequences! This problem has been on my nerves for s while. Also, probably there is some simpler way to do it, but I couldn't find it.",,"['real-analysis', 'limits', 'logarithms', 'probability-limit-theorems']"
79,Find the value of $\lim_{n\to \infty}\sum_{k=0}^n\frac{x^{2^k}}{1-x^{2^{k+1}}}$.,Find the value of .,\lim_{n\to \infty}\sum_{k=0}^n\frac{x^{2^k}}{1-x^{2^{k+1}}},If $0 \lt x \lt 1$ and $$A_n=\frac{x}{1-x^2}+\frac{x^2}{1-x^4}+.....+\frac{x^{2^n}}{1-x^{2^{n+1}}}$$ then Find $\lim\limits_{n\to \infty}A_n$.,If $0 \lt x \lt 1$ and $$A_n=\frac{x}{1-x^2}+\frac{x^2}{1-x^4}+.....+\frac{x^{2^n}}{1-x^{2^{n+1}}}$$ then Find $\lim\limits_{n\to \infty}A_n$.,,"['sequences-and-series', 'limits', 'summation']"
80,Determine if the following series is convergent.,Determine if the following series is convergent.,,Determine if the following series is convergent: $$\sum_n^{\infty} \frac{1}{n^2 + \cos \pi n}$$.,Determine if the following series is convergent: $$\sum_n^{\infty} \frac{1}{n^2 + \cos \pi n}$$.,,"['real-analysis', 'limits']"
81,Showing $\lim_{n\to\infty} \left( \frac{n}{n^2+1^2} + \frac{n}{n^2+2^2} + \cdots + \frac{n}{n^2+n^2} \right) = \frac{\pi}{4}$ [duplicate],Showing  [duplicate],\lim_{n\to\infty} \left( \frac{n}{n^2+1^2} + \frac{n}{n^2+2^2} + \cdots + \frac{n}{n^2+n^2} \right) = \frac{\pi}{4},This question already has an answer here : The limit of a sum $\sum_{k=1}^n \frac{n}{n^2+k^2}$ as $n\rightarrow\infty$ [closed] (1 answer) Closed 4 years ago . How could I go about proving the following limit: $$ \lim_{n\to\infty} \left( \frac{n}{n^2+1^2} + \frac{n}{n^2+2^2} + \cdots + \frac{n}{n^2+n^2} \right) = \frac{\pi}{4} $$,This question already has an answer here : The limit of a sum $\sum_{k=1}^n \frac{n}{n^2+k^2}$ as $n\rightarrow\infty$ [closed] (1 answer) Closed 4 years ago . How could I go about proving the following limit: $$ \lim_{n\to\infty} \left( \frac{n}{n^2+1^2} + \frac{n}{n^2+2^2} + \cdots + \frac{n}{n^2+n^2} \right) = \frac{\pi}{4} $$,,"['real-analysis', 'limits']"
82,"For $(x_n)$ increasing, $\sum_{n=1}^{\infty}\left(1-\frac{x_n}{x_{n+1}}\right)$ if $(x_n)$ is bounded and diverges if it is unbounded","For  increasing,  if  is bounded and diverges if it is unbounded",(x_n) \sum_{n=1}^{\infty}\left(1-\frac{x_n}{x_{n+1}}\right) (x_n),"Let $\{x_n\}$ be monotone increasing sequence of positive real numbers. Show that if $\{x_n\}$ is bounded, then $\sum_{n=1}^{\infty}\left(1-\frac{x_n}{x_{n+1}}\right)$ converges. On the other hand, if the sequence is unbounded, the series is divergent. The following is the proof given by my lecturer, but I do not understand the proof: Let $u_m = x_{m+1} -x_m$ and $d_m = \sum_{k=1}^m u_k = x_{m+1} - x_1$ and hence $x_{m+1} = d_m + x_1$ $$\sum_{n=1}^{\infty}\left(1-\frac{x_n}{x_{n+1}}\right) = \sum_{n=1}^{\infty}\frac{u_m}{d_m +x_1} $$ Then he says that if $d_m$ diverges, then the sum diverges. If $d_m$ converges, then then sum converges. He says that it has something to do with Gauss Test. Can someone explain the proof to me. Or does anyone has a better proof.","Let $\{x_n\}$ be monotone increasing sequence of positive real numbers. Show that if $\{x_n\}$ is bounded, then $\sum_{n=1}^{\infty}\left(1-\frac{x_n}{x_{n+1}}\right)$ converges. On the other hand, if the sequence is unbounded, the series is divergent. The following is the proof given by my lecturer, but I do not understand the proof: Let $u_m = x_{m+1} -x_m$ and $d_m = \sum_{k=1}^m u_k = x_{m+1} - x_1$ and hence $x_{m+1} = d_m + x_1$ $$\sum_{n=1}^{\infty}\left(1-\frac{x_n}{x_{n+1}}\right) = \sum_{n=1}^{\infty}\frac{u_m}{d_m +x_1} $$ Then he says that if $d_m$ diverges, then the sum diverges. If $d_m$ converges, then then sum converges. He says that it has something to do with Gauss Test. Can someone explain the proof to me. Or does anyone has a better proof.",,"['real-analysis', 'sequences-and-series', 'limits']"
83,Supremum of $\{\sqrt[n]{n}:$ $n \in \mathbb{N}\}$ and $ \{\sqrt[x]{x}:$ $x \in \mathbb{R}_{>0}\}$,Supremum of   and,\{\sqrt[n]{n}: n \in \mathbb{N}\}  \{\sqrt[x]{x}: x \in \mathbb{R}_{>0}\},"I would like to calculate the supremums of these sets: $\{\sqrt[n]{n}:$ $n \in \mathbb{N}\}$ and $ \{\sqrt[x]{x}:$ $x \in \mathbb{R}_{>0}\}$ I don't know how to start, any help is appreciated.","I would like to calculate the supremums of these sets: $\{\sqrt[n]{n}:$ $n \in \mathbb{N}\}$ and $ \{\sqrt[x]{x}:$ $x \in \mathbb{R}_{>0}\}$ I don't know how to start, any help is appreciated.",,"['calculus', 'limits']"
84,Limit at infinity for $e^{-\sin x}$,Limit at infinity for,e^{-\sin x},"Can you, please, confirm my assumption here.  $$\lim_{x\to ∞}e ^ {-\sin{x}}$$ does not exist . Due to $\lim_{x\to ∞}{\sin{x}}$ doesn't exist $\lim_{x\to a}f(x)=\lim_{x\to a}e^{\ln{f(x)}}=e^L$ if $\lim_{x\to a}{\ln{f(x)} = L}$","Can you, please, confirm my assumption here.  $$\lim_{x\to ∞}e ^ {-\sin{x}}$$ does not exist . Due to $\lim_{x\to ∞}{\sin{x}}$ doesn't exist $\lim_{x\to a}f(x)=\lim_{x\to a}e^{\ln{f(x)}}=e^L$ if $\lim_{x\to a}{\ln{f(x)} = L}$",,"['calculus', 'limits']"
85,Limit of the sequence $a_n = \frac{1+\sqrt2+\sqrt 3+ \cdots +\sqrt n}{n\sqrt n}$ [duplicate],Limit of the sequence  [duplicate],a_n = \frac{1+\sqrt2+\sqrt 3+ \cdots +\sqrt n}{n\sqrt n},"This question already has answers here : Find $\lim\limits_{n \to \infty} \frac{\sqrt 1 + \sqrt 2 + \dots + \sqrt{n}}{n\sqrt{n}}$. (3 answers) Closed 3 years ago . I have to solve this sequence: $$a_n = \frac{1+\sqrt2+\sqrt 3+ \cdots +\sqrt n}{n\sqrt n}$$ As a tip I've been told to use Stoltz-Cesaro for sequance of this form : $a_n = \dfrac{x_n}{y_n}$ So I did Stoltz-Cesaro $\dfrac{x_n - x_{n-1}}{y_n-y_{n-1}}$ and I end up with: $\dfrac{\sqrt{n}}{n\sqrt{n}-(n-1)\sqrt{n-1}}$. I am stuck at this point, can you please give me some tips on what to do next? Thank you.","This question already has answers here : Find $\lim\limits_{n \to \infty} \frac{\sqrt 1 + \sqrt 2 + \dots + \sqrt{n}}{n\sqrt{n}}$. (3 answers) Closed 3 years ago . I have to solve this sequence: $$a_n = \frac{1+\sqrt2+\sqrt 3+ \cdots +\sqrt n}{n\sqrt n}$$ As a tip I've been told to use Stoltz-Cesaro for sequance of this form : $a_n = \dfrac{x_n}{y_n}$ So I did Stoltz-Cesaro $\dfrac{x_n - x_{n-1}}{y_n-y_{n-1}}$ and I end up with: $\dfrac{\sqrt{n}}{n\sqrt{n}-(n-1)\sqrt{n-1}}$. I am stuck at this point, can you please give me some tips on what to do next? Thank you.",,"['calculus', 'sequences-and-series', 'limits']"
86,"Is $\lim\limits_{n \to \infty} n$ ""equal"" to $\mathbb{N}$?","Is  ""equal"" to ?",\lim\limits_{n \to \infty} n \mathbb{N},"In set theory, the natural numbers are defined by means of inductive sets and the successor operation $S(n+1) = n \cup \{n\}$ As such, we have $1 = \{0\}$, $2 = \{0, 1\}$, $3 = \{0, 1, 2\}$, etc. Thus, as the natural numbers $n$ get larger and larger, they get closer to approximating the set $\{0, 1, 2, 3, \ldots\}$, which of course, is $\mathbb{N}$. So while this seems a bit under-handed, since limits are really only defined for functions , it seems true in a sense that $$ \lim_{n \to \infty} n = \mathbb{N} $$ Is there any way in which this is rigorously true? Are there any consequences of this ""fact""?","In set theory, the natural numbers are defined by means of inductive sets and the successor operation $S(n+1) = n \cup \{n\}$ As such, we have $1 = \{0\}$, $2 = \{0, 1\}$, $3 = \{0, 1, 2\}$, etc. Thus, as the natural numbers $n$ get larger and larger, they get closer to approximating the set $\{0, 1, 2, 3, \ldots\}$, which of course, is $\mathbb{N}$. So while this seems a bit under-handed, since limits are really only defined for functions , it seems true in a sense that $$ \lim_{n \to \infty} n = \mathbb{N} $$ Is there any way in which this is rigorously true? Are there any consequences of this ""fact""?",,"['limits', 'elementary-set-theory', 'infinity', 'natural-numbers']"
87,How to show $\lim_{n\to \infty}\sqrt{n}^n (1 - (1 - 1/(\sqrt{n}^n))^{2^n})/2^n = 1$?,How to show ?,\lim_{n\to \infty}\sqrt{n}^n (1 - (1 - 1/(\sqrt{n}^n))^{2^n})/2^n = 1,How can you show the following? $$\lim_{n\to \infty}\frac{\sqrt{n}^n \left(1 - \left(1 - \frac{1}{\sqrt{n}^n}\right)^{2^n} \right)}{2^n} = 1$$ It certainly seems to be true numerically when I plot it.,How can you show the following? $$\lim_{n\to \infty}\frac{\sqrt{n}^n \left(1 - \left(1 - \frac{1}{\sqrt{n}^n}\right)^{2^n} \right)}{2^n} = 1$$ It certainly seems to be true numerically when I plot it.,,[]
88,Limits of Indeterminate Quotient: $\lim\limits_{x \to 0^+} \frac{\ln(e^x - 1)}{\ln(x)}$ and $\lim\limits_{x \to -1}(\frac1{x+1} - \frac3{x^3+1})$,Limits of Indeterminate Quotient:  and,\lim\limits_{x \to 0^+} \frac{\ln(e^x - 1)}{\ln(x)} \lim\limits_{x \to -1}(\frac1{x+1} - \frac3{x^3+1}),I was preparing for my exam and found myself struggling with finding limits of indeterminate quotient. $$\lim\limits_{x \to 0^+} \dfrac{\ln(e^x - 1)}{\ln(x)}$$ I have tried using L'Hopital's Rule to reduce it to: $\lim\limits_{x \to 0^+} \dfrac{xe^x}{e^x-1}$ but still does not solve the problem. Another problem that I've faced: $$\lim\limits_{x \to -1}(\frac{1}{x+1} - \frac{3}{x^3+1})$$ I have tried to combine it into 1 term: $\lim\limits_{x \to -1}(\dfrac{x^3-3x-2}{x^4+x^3+x+1})$ and applied L'Hopital's Rule but still got an Indeterminate Quotient. Any advice on the 2 above qns is really much appreciated!,I was preparing for my exam and found myself struggling with finding limits of indeterminate quotient. I have tried using L'Hopital's Rule to reduce it to: but still does not solve the problem. Another problem that I've faced: I have tried to combine it into 1 term: and applied L'Hopital's Rule but still got an Indeterminate Quotient. Any advice on the 2 above qns is really much appreciated!,\lim\limits_{x \to 0^+} \dfrac{\ln(e^x - 1)}{\ln(x)} \lim\limits_{x \to 0^+} \dfrac{xe^x}{e^x-1} \lim\limits_{x \to -1}(\frac{1}{x+1} - \frac{3}{x^3+1}) \lim\limits_{x \to -1}(\dfrac{x^3-3x-2}{x^4+x^3+x+1}),['limits']
89,Calculus: tangents and limits,Calculus: tangents and limits,,"For 1), I know the graph has a tangent but I don't know how to explain. For 2), is the answer 0? Would anyone mind giving me the steps? For 3) and 4),  I really have no idea.","For 1), I know the graph has a tangent but I don't know how to explain. For 2), is the answer 0? Would anyone mind giving me the steps? For 3) and 4),  I really have no idea.",,"['calculus', 'limits', 'graphing-functions']"
90,"Find the limit of a multivariable function $f(x,y)=\frac{\ln(1+x^2y^2)}{x^2}$",Find the limit of a multivariable function,"f(x,y)=\frac{\ln(1+x^2y^2)}{x^2}","The function is as follows: $f(x,y)=\frac{\ln(1+x^2y^2)}{x^2}$ and I want to calculate the following limit: $\lim_{(x,y)\to(0,y_0)}f(x,y)$ The reason I'm having trouble with this one is because the limit doesn't seem to be $0$ but $y_0^2$. Because of that, I need 2 functions to compare $f$ to, instead of one. The greater one I found like this: $\ln(1+x^2y^2)\leq x^2y^2$ $\frac{\ln(1+x^2y^2)}{x^2}\leq y^2$ so (if I'm correct) the limit is definitely lower or equal to $y_0^2$. But I can't find the function to be my upper bound that also converges to that value.","The function is as follows: $f(x,y)=\frac{\ln(1+x^2y^2)}{x^2}$ and I want to calculate the following limit: $\lim_{(x,y)\to(0,y_0)}f(x,y)$ The reason I'm having trouble with this one is because the limit doesn't seem to be $0$ but $y_0^2$. Because of that, I need 2 functions to compare $f$ to, instead of one. The greater one I found like this: $\ln(1+x^2y^2)\leq x^2y^2$ $\frac{\ln(1+x^2y^2)}{x^2}\leq y^2$ so (if I'm correct) the limit is definitely lower or equal to $y_0^2$. But I can't find the function to be my upper bound that also converges to that value.",,"['limits', 'multivariable-calculus']"
91,Limit as n approaches infinity of (log(n!) / nlog(n)) [duplicate],Limit as n approaches infinity of (log(n!) / nlog(n)) [duplicate],,This question already has answers here : Limit of $\frac{\log(n!)}{n\log(n)}$ as $n\to\infty$. (11 answers) Closed 10 years ago . I'm stumped with a limit. I know the answer (because I looked on wolframalpha) but I really want to know how to reach the correct answer. If you have any hints or tips on getting there I'd be most appreciative!,This question already has answers here : Limit of $\frac{\log(n!)}{n\log(n)}$ as $n\to\infty$. (11 answers) Closed 10 years ago . I'm stumped with a limit. I know the answer (because I looked on wolframalpha) but I really want to know how to reach the correct answer. If you have any hints or tips on getting there I'd be most appreciative!,,"['calculus', 'limits']"
92,Evaluate the limit $\lim_{x\to 0} \frac{(\tan(x+\pi/4))^{1/3}-1}{\sin(2x)}$,Evaluate the limit,\lim_{x\to 0} \frac{(\tan(x+\pi/4))^{1/3}-1}{\sin(2x)},"Evaluate the limit $$\lim_{x\to 0} \frac{(\tan(x+\pi/4))^{1/3}-1}{\sin(2x)}$$ I know the limit is $1\over3$ by looking at the graph of the function, but how can I algebraically show that that is the limit. using this limit: $$\lim_{x \rightarrow 0} \frac{(1+x)^c -1}{x} =c$$? (without L'Hopital Rule)","Evaluate the limit $$\lim_{x\to 0} \frac{(\tan(x+\pi/4))^{1/3}-1}{\sin(2x)}$$ I know the limit is $1\over3$ by looking at the graph of the function, but how can I algebraically show that that is the limit. using this limit: $$\lim_{x \rightarrow 0} \frac{(1+x)^c -1}{x} =c$$? (without L'Hopital Rule)",,"['calculus', 'limits']"
93,How to find the limit $\lim_{x \to 0}\sin(x)^{2\sin(x)}$,How to find the limit,\lim_{x \to 0}\sin(x)^{2\sin(x)},I can't find the following limit: $$\lim_{x \to 0}\sin(x)^{2\sin(x)}$$ My attempt : Let $y =\sin(x)^{2\sin(x)}$. Then we take the natural logarithm of this expression: $$y=\sin(x)^{2\sin(x)}$$ $$\ln(y) = 2\sin(x)\cdot \ln(\sin(x))$$ $$y=e^{2\sin(x)\cdot \ln(\sin(x))}$$ Then we put this in limit $$\lim_{x \to 0}\sin(x)^{2\sin(x)}= \lim_{x \to 0}(e^{2\sin(x)\cdot \ln(\sin(x))})=e^{0\cdot (-\infty)}=e^0=1$$ I want to know whether it is correct.,I can't find the following limit: $$\lim_{x \to 0}\sin(x)^{2\sin(x)}$$ My attempt : Let $y =\sin(x)^{2\sin(x)}$. Then we take the natural logarithm of this expression: $$y=\sin(x)^{2\sin(x)}$$ $$\ln(y) = 2\sin(x)\cdot \ln(\sin(x))$$ $$y=e^{2\sin(x)\cdot \ln(\sin(x))}$$ Then we put this in limit $$\lim_{x \to 0}\sin(x)^{2\sin(x)}= \lim_{x \to 0}(e^{2\sin(x)\cdot \ln(\sin(x))})=e^{0\cdot (-\infty)}=e^0=1$$ I want to know whether it is correct.,,"['real-analysis', 'limits']"
94,Limit with missing variables,Limit with missing variables,,Find the values for $a$ and $b$ such that    $$\lim_{x \to 0} \frac{\sqrt{a + bx} - \sqrt{3}}{x} = 3$$ Basically what I did so far was I started by multiplying by the conjugate. and obtained $$\frac{a+bx-3}{x(\sqrt{a+bx}+\sqrt 3)}$$ I don't know what to do after this.,Find the values for $a$ and $b$ such that    $$\lim_{x \to 0} \frac{\sqrt{a + bx} - \sqrt{3}}{x} = 3$$ Basically what I did so far was I started by multiplying by the conjugate. and obtained $$\frac{a+bx-3}{x(\sqrt{a+bx}+\sqrt 3)}$$ I don't know what to do after this.,,"['calculus', 'limits']"
95,Limit and sum question [closed],Limit and sum question [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 10 years ago . Improve this question Solve these limits. $$\lim_{n\to\infty}\left(\,\frac{1}{n}+\frac{1}{n+1}+\ldots+\frac{1}{2n}\,\right)=?$$ and $\lim_{n \to \infty}a_{n} = ?$ where $$a_{0}=1\,,\quad a_{n}=\frac{1}{2}\left(\,\frac{2}{a_{n-1}}+a_{n-1}\,\right)$$","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 10 years ago . Improve this question Solve these limits. $$\lim_{n\to\infty}\left(\,\frac{1}{n}+\frac{1}{n+1}+\ldots+\frac{1}{2n}\,\right)=?$$ and $\lim_{n \to \infty}a_{n} = ?$ where $$a_{0}=1\,,\quad a_{n}=\frac{1}{2}\left(\,\frac{2}{a_{n-1}}+a_{n-1}\,\right)$$",,"['calculus', 'sequences-and-series', 'analysis', 'limits', 'harmonic-numbers']"
96,"$f^{\prime}(x)\rightarrow 0$ as $x\rightarrow\infty$. $g(x)=f(x+1)-f(x)$, then $g(x)\rightarrow 0$ as $x\rightarrow\infty$","as . , then  as",f^{\prime}(x)\rightarrow 0 x\rightarrow\infty g(x)=f(x+1)-f(x) g(x)\rightarrow 0 x\rightarrow\infty,"If $f$ is a defined and $\forall x>0, f^{\prime}(x)\rightarrow 0$ as $x\rightarrow\infty$. $g(x)=f(x+1)-f(x)$, then $g(x)\rightarrow 0$ as $x\rightarrow\infty$. Note that  $$g(x)=\frac{f(x+1)-f(x)}{(x+1)-x}=\frac{f(x+1)-f(x)}{1}$$ $$\lim_{n\rightarrow\infty} f'(x)=0\implies \forall\varepsilon >0, \exists N>0 \space\space\text{s.t.}\space\space\space |f'(x)|<\varepsilon \space\space\forall x>N$$ $$\left| \lim_{h\rightarrow 0}\frac{f(x+h)-f(x)}{h}\right| < \varepsilon \space\space\forall x>N$$ How can I somehow link the $h$ and $1$ together so that $g(x)$ is bounded by $\varepsilon$?","If $f$ is a defined and $\forall x>0, f^{\prime}(x)\rightarrow 0$ as $x\rightarrow\infty$. $g(x)=f(x+1)-f(x)$, then $g(x)\rightarrow 0$ as $x\rightarrow\infty$. Note that  $$g(x)=\frac{f(x+1)-f(x)}{(x+1)-x}=\frac{f(x+1)-f(x)}{1}$$ $$\lim_{n\rightarrow\infty} f'(x)=0\implies \forall\varepsilon >0, \exists N>0 \space\space\text{s.t.}\space\space\space |f'(x)|<\varepsilon \space\space\forall x>N$$ $$\left| \lim_{h\rightarrow 0}\frac{f(x+h)-f(x)}{h}\right| < \varepsilon \space\space\forall x>N$$ How can I somehow link the $h$ and $1$ together so that $g(x)$ is bounded by $\varepsilon$?",,"['calculus', 'limits']"
97,Show that $\lim_{n \to \infty} \frac{k^n}{n!} =0$ for all $k$ in $\mathbb{R}$,Show that  for all  in,\lim_{n \to \infty} \frac{k^n}{n!} =0 k \mathbb{R},"$$\lim_{n\to\infty} \frac{k^n}{n!}=0 \, \forall\:k\in \mathbb{R}$$ I have tried to find an $N$ in term of epsilon in the definition of limit, but to no avail. I've tried log, but $\log (n!)=\log(1)+\log(2)+...+\log(n)$ does not seem to help here. Could you help me with this problem? Thanks.","$$\lim_{n\to\infty} \frac{k^n}{n!}=0 \, \forall\:k\in \mathbb{R}$$ I have tried to find an $N$ in term of epsilon in the definition of limit, but to no avail. I've tried log, but $\log (n!)=\log(1)+\log(2)+...+\log(n)$ does not seem to help here. Could you help me with this problem? Thanks.",,"['calculus', 'limits']"
98,Did I do this limit right? $\lim_{x \to 0} \frac{(\sqrt{x^2+2}-\sqrt{2})}{\sqrt{x^2+1}-1}$,Did I do this limit right?,\lim_{x \to 0} \frac{(\sqrt{x^2+2}-\sqrt{2})}{\sqrt{x^2+1}-1},This is how I did this limit: $$\lim_{x \to 0} \frac{(\sqrt{x^2+2}-\sqrt{2})}{\sqrt{x^2+1}-1} =\lim_{x \to 0}\frac{(\sqrt{x^2+2}-\sqrt{2})(\sqrt{x^2+1}+1)}{(\sqrt{x^2+1}-1)(\sqrt{x^2+1}+1)} = \lim_{x \to 0} \frac{(\sqrt{x^2+2}-\sqrt{2})(\sqrt{x^2+1}+1)(\sqrt{x^2+2}+\sqrt{2})}{(x^2+1-1)(\sqrt{x^2+2}+\sqrt{2})} = \lim_{x \to 0}\frac{({x^2+2}-2)(\sqrt{x^2+1}+1)}{(x^2+1-1)(\sqrt{x^2+2}+\sqrt{2})} =\frac{(\sqrt{0^2+1}+1)}{(\sqrt{0^2+2}+\sqrt{2})}=\frac{1}{2\sqrt{2}}$$ But Wolframalpha gave me another answer! So did I do it right?,This is how I did this limit: $$\lim_{x \to 0} \frac{(\sqrt{x^2+2}-\sqrt{2})}{\sqrt{x^2+1}-1} =\lim_{x \to 0}\frac{(\sqrt{x^2+2}-\sqrt{2})(\sqrt{x^2+1}+1)}{(\sqrt{x^2+1}-1)(\sqrt{x^2+1}+1)} = \lim_{x \to 0} \frac{(\sqrt{x^2+2}-\sqrt{2})(\sqrt{x^2+1}+1)(\sqrt{x^2+2}+\sqrt{2})}{(x^2+1-1)(\sqrt{x^2+2}+\sqrt{2})} = \lim_{x \to 0}\frac{({x^2+2}-2)(\sqrt{x^2+1}+1)}{(x^2+1-1)(\sqrt{x^2+2}+\sqrt{2})} =\frac{(\sqrt{0^2+1}+1)}{(\sqrt{0^2+2}+\sqrt{2})}=\frac{1}{2\sqrt{2}}$$ But Wolframalpha gave me another answer! So did I do it right?,,"['calculus', 'real-analysis', 'limits']"
99,Use L'Hôpital's rule to evaluate this limit,Use L'Hôpital's rule to evaluate this limit,,"$$\lim_{x\to0} \left(\frac{a^x + b^x}{2}\right)^{1/x}  = (ab)^{1/2}$$ I tried taking logarithm to both sides, but got stuck I got to e^ (lim (a^x loga + b^x logb)/(a^x + b^x)","$$\lim_{x\to0} \left(\frac{a^x + b^x}{2}\right)^{1/x}  = (ab)^{1/2}$$ I tried taking logarithm to both sides, but got stuck I got to e^ (lim (a^x loga + b^x logb)/(a^x + b^x)",,"['calculus', 'limits']"
