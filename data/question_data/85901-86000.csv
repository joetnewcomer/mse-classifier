,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Prove that in a Hilbert space, $\lim_{k \rightarrow \infty} \langle x_{n_k} , y\rangle =\langle x,y \rangle$ [closed]","Prove that in a Hilbert space,  [closed]","\lim_{k \rightarrow \infty} \langle x_{n_k} , y\rangle =\langle x,y \rangle","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question Let $\mathscr{H}$ be a Hilbert space and $(x_n)_n$ a bounded sequence in $\mathscr H$ . How can I show that there exists a subsequence $(x_{n_k})_k$ and an $x \in \mathscr{H}$ so that $$ \lim_{k \rightarrow \infty} \langle x_{n_k},y\rangle= \langle x,y\rangle $$ for all $ y \in \mathscr{H} $ ? I know some of such proofs, but I don't know how to show that for a Hilbert space ! As a hint I got : using the diagonal consequences argument. Appreciate any help of you !","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question Let be a Hilbert space and a bounded sequence in . How can I show that there exists a subsequence and an so that for all ? I know some of such proofs, but I don't know how to show that for a Hilbert space ! As a hint I got : using the diagonal consequences argument. Appreciate any help of you !","\mathscr{H} (x_n)_n \mathscr H (x_{n_k})_k x \in \mathscr{H}  \lim_{k \rightarrow \infty} \langle x_{n_k},y\rangle= \langle x,y\rangle   y \in \mathscr{H} ","['functional-analysis', 'hilbert-spaces']"
1,Minimizing a functional.,Minimizing a functional.,,"I am doing some work on Kernel based machine learning where I encountered the following functional - $$\frac{1}{m}\sum_{i=0}^m(y_i-f(x_i))^2+\gamma\lVert f\rVert^2$$ Here $\gamma$ is a positive real number, $x_i,y_i$ are given (these are the training data), and norm is of the function space(Reproducing Kernel Hilbert Space). Now I need to find a function that minimizes the given functional. This is what I came across - ""To minimize the given functional, we take the functional derivative with respect to $f$, apply it to an element $\bar{f}$ of the function space, and set it equal to $0$. We obtain $$\frac{1}{m}\sum_{i=0}^m(y_i-f(x_i))^2\bar{f}(x_i)-\gamma\left<f,\bar{f}\right> = 0$$ How do we arrive at this equation, or how do we take functional derivative? Reference - ""The Mathematics of Learning:Dealing with Data, Tomaso Poggio and Steve Smale""","I am doing some work on Kernel based machine learning where I encountered the following functional - $$\frac{1}{m}\sum_{i=0}^m(y_i-f(x_i))^2+\gamma\lVert f\rVert^2$$ Here $\gamma$ is a positive real number, $x_i,y_i$ are given (these are the training data), and norm is of the function space(Reproducing Kernel Hilbert Space). Now I need to find a function that minimizes the given functional. This is what I came across - ""To minimize the given functional, we take the functional derivative with respect to $f$, apply it to an element $\bar{f}$ of the function space, and set it equal to $0$. We obtain $$\frac{1}{m}\sum_{i=0}^m(y_i-f(x_i))^2\bar{f}(x_i)-\gamma\left<f,\bar{f}\right> = 0$$ How do we arrive at this equation, or how do we take functional derivative? Reference - ""The Mathematics of Learning:Dealing with Data, Tomaso Poggio and Steve Smale""",,"['functional-analysis', 'functional-calculus']"
2,A question about the spectral theorem for unbounded self-adjoint operators,A question about the spectral theorem for unbounded self-adjoint operators,,"The spectral theorem for unbounded operators says that if $A:D(A)\subset H\to H$ is a densely defined self-adjoint operator ($H$ Hilbert), and $f:\mathbb{R}\to \mathbb{R}$ is a Borel function bounded on $\sigma(A)$ then  $$f(A) = \int_{\mathbb{R}} f(\lambda) dP(\lambda)$$ where $dP(\lambda)$ is the spectral measure of $A$. I naively thought that the spectrum of $f(A)$ is given by $f(\sigma(A))$ but then I came across the following. Let $A = -\Delta: D(\Delta) \to L^2(\mathbb{R}^3)$, where $\Delta$ is the Laplacian. It  is well known that  $\sigma(A)= [0,+\infty)$. Let $\rho < 0$, then we can consider the self-adjoint operator $$ (A-\rho)^{-1} = \int_{0}^{+\infty} (\lambda-\rho)^{-1}dP(\lambda) $$ This operator is the inverse of $A-\rho$, and by our naive assumption its spectrum should be $\frac{1}{\sigma(A)-\rho}$. But from other theories we also know that the inverse $(A-\rho)^{-1}$ is a compact self-adjoint operator and thus its spectrum must be  a discrete set (contradiction). So, where have I made a mistake?","The spectral theorem for unbounded operators says that if $A:D(A)\subset H\to H$ is a densely defined self-adjoint operator ($H$ Hilbert), and $f:\mathbb{R}\to \mathbb{R}$ is a Borel function bounded on $\sigma(A)$ then  $$f(A) = \int_{\mathbb{R}} f(\lambda) dP(\lambda)$$ where $dP(\lambda)$ is the spectral measure of $A$. I naively thought that the spectrum of $f(A)$ is given by $f(\sigma(A))$ but then I came across the following. Let $A = -\Delta: D(\Delta) \to L^2(\mathbb{R}^3)$, where $\Delta$ is the Laplacian. It  is well known that  $\sigma(A)= [0,+\infty)$. Let $\rho < 0$, then we can consider the self-adjoint operator $$ (A-\rho)^{-1} = \int_{0}^{+\infty} (\lambda-\rho)^{-1}dP(\lambda) $$ This operator is the inverse of $A-\rho$, and by our naive assumption its spectrum should be $\frac{1}{\sigma(A)-\rho}$. But from other theories we also know that the inverse $(A-\rho)^{-1}$ is a compact self-adjoint operator and thus its spectrum must be  a discrete set (contradiction). So, where have I made a mistake?",,"['functional-analysis', 'operator-theory', 'spectral-theory']"
3,Which convex functions are characterized as the supremum of linear functions?,Which convex functions are characterized as the supremum of linear functions?,,A convex function $f$ can be represented as the supremum of all the affine functions that are dominated by $f$. Is there a simple characterization of those convex functions $g$ that can be represented as the supremum of all the linear functions that are dominated by $g$?,A convex function $f$ can be represented as the supremum of all the affine functions that are dominated by $f$. Is there a simple characterization of those convex functions $g$ that can be represented as the supremum of all the linear functions that are dominated by $g$?,,"['functional-analysis', 'convex-analysis']"
4,"kernel, range and adjoint of an operator in sequence space","kernel, range and adjoint of an operator in sequence space",,"I am working on an exercise in Brezis' functional analysis book (ex 2.23) and I'm having trouble with a certain step: Let $E=l^1$ and consider $T: E\to E$ with $Tu = (u_n/n)_{n\geq 1}$ . Determine $N(T), N(T)^\bot, T^*, R(T^*), \overline{R(T^*)}$ . I got that $N(T) = \{0\}$ , hence $N(T)^\bot = l^{\infty}$ , the adjoint looks identical to $T$ but operates on the dual space $E^* = l^\infty$ . The last two objects are interesting, though: $$R(T^*) = \{(v_n/n)_n, v\in l^\infty\} = \bigcap_{p>1}l^p$$ because $\|(v_n/n)_n\|_{l^p} < \infty$ for any $v\in l^\infty$ . Now I don't know what $$\overline{\bigcap_{p>1}l^p}^{l^\infty}$$ is. Is that just $l^\infty$ ?","I am working on an exercise in Brezis' functional analysis book (ex 2.23) and I'm having trouble with a certain step: Let and consider with . Determine . I got that , hence , the adjoint looks identical to but operates on the dual space . The last two objects are interesting, though: because for any . Now I don't know what is. Is that just ?","E=l^1 T: E\to E Tu = (u_n/n)_{n\geq 1} N(T), N(T)^\bot, T^*, R(T^*), \overline{R(T^*)} N(T) = \{0\} N(T)^\bot = l^{\infty} T E^* = l^\infty R(T^*) = \{(v_n/n)_n, v\in l^\infty\} = \bigcap_{p>1}l^p \|(v_n/n)_n\|_{l^p} < \infty v\in l^\infty \overline{\bigcap_{p>1}l^p}^{l^\infty} l^\infty","['functional-analysis', 'operator-theory']"
5,strong convergence of product of operators,strong convergence of product of operators,,"I'm trying to prove the next: Let $H$ be a Hilbert space. Consider $\{T_{n}\}$ and $\{S_{n}\}$ sequences of $\mathcal{B}(H)$ such that $S_{n}\xrightarrow{s} S$ and $T_{n}\xrightarrow{s}T;$ here $S_{n}\xrightarrow{s} S$ means that $S_{n}$ converges strongly to $S,$ i.e. for each $x\in H,$ $S_{n}x\rightarrow Sx.$ Then $S_{n}T_{n}\xrightarrow{s}ST.$ So, for $x\in H,$ We have $||(S_{n}T_{n}-ST)x||\leq||(S_{n}-S)T_{n}x||+||S||||(T_{n}-T)x||.$ The second term of right side of the inequality above converges to zero. My doubt comes from the other term. If $y_{n}=T_{n}x$ it would seem such term converges to zero too because of the strong convergence of $S_{n},$ but such $y_{n}$ depends of $n;$ I have doubts about it. Any kind of help is thanked in advanced.","I'm trying to prove the next: Let $H$ be a Hilbert space. Consider $\{T_{n}\}$ and $\{S_{n}\}$ sequences of $\mathcal{B}(H)$ such that $S_{n}\xrightarrow{s} S$ and $T_{n}\xrightarrow{s}T;$ here $S_{n}\xrightarrow{s} S$ means that $S_{n}$ converges strongly to $S,$ i.e. for each $x\in H,$ $S_{n}x\rightarrow Sx.$ Then $S_{n}T_{n}\xrightarrow{s}ST.$ So, for $x\in H,$ We have $||(S_{n}T_{n}-ST)x||\leq||(S_{n}-S)T_{n}x||+||S||||(T_{n}-T)x||.$ The second term of right side of the inequality above converges to zero. My doubt comes from the other term. If $y_{n}=T_{n}x$ it would seem such term converges to zero too because of the strong convergence of $S_{n},$ but such $y_{n}$ depends of $n;$ I have doubts about it. Any kind of help is thanked in advanced.",,"['functional-analysis', 'operator-theory']"
6,Weak formulation of Robin boundary condition problem,Weak formulation of Robin boundary condition problem,,"I have some issues with the following problem. Let ${\Omega \subset \Bbb{R}^n}$ be a bounded open set with smooth boundary $\Gamma$, and consider  the following problem $$(\text{R})\displaystyle \begin{cases} -\Delta u(x)+c(x)u(x) =f(x), &\text{  }x\in\Omega \\ \dfrac{\partial u}{\partial \nu}(x)+\alpha u(x) =g(x), & x\in\Gamma \end{cases}, $$ where ${\alpha>0}$ is a constant. This is a problem with Robin boundary conditions . If $f\in L^2(\Omega), g\in L^2(\Gamma)$ and $c\in L^\infty(\Omega)$ satisfy $c(x)\geq c_0>0$,   I must prove that (R) is a well posed problem which has a unique weak solution. As usual, one wants to use the Lax-Milgram theorem, so I must seek for a bilinear form $B\colon V\times V\to \mathbb R$ which is continuous and coercive. I don't have issues with proving that such $B$ is continous and coercive, but I get confused at the moment of proposing it (as well as chosing the appropiate space, I think that $V$ must be $H^1(\Omega )$). Is there some compatibility condition ? I'm thinking in proposing $B$ as $$B(u, v):=\int_\Omega  \nabla u\cdot \nabla v+\int_\Omega cuv+\alpha\int_{\Gamma }uv,$$  and so we want an unique $u\in V$ such that for all $v\in V$ $$B(u, v)=\int_\Omega  fv+\int_{\Gamma }gv.$$ Is this right? Can you help me in reasoning the formulation of this problem?   What is the appropiate choice of $V$? Thanks in advance, this is my first time solving these kind of problems","I have some issues with the following problem. Let ${\Omega \subset \Bbb{R}^n}$ be a bounded open set with smooth boundary $\Gamma$, and consider  the following problem $$(\text{R})\displaystyle \begin{cases} -\Delta u(x)+c(x)u(x) =f(x), &\text{  }x\in\Omega \\ \dfrac{\partial u}{\partial \nu}(x)+\alpha u(x) =g(x), & x\in\Gamma \end{cases}, $$ where ${\alpha>0}$ is a constant. This is a problem with Robin boundary conditions . If $f\in L^2(\Omega), g\in L^2(\Gamma)$ and $c\in L^\infty(\Omega)$ satisfy $c(x)\geq c_0>0$,   I must prove that (R) is a well posed problem which has a unique weak solution. As usual, one wants to use the Lax-Milgram theorem, so I must seek for a bilinear form $B\colon V\times V\to \mathbb R$ which is continuous and coercive. I don't have issues with proving that such $B$ is continous and coercive, but I get confused at the moment of proposing it (as well as chosing the appropiate space, I think that $V$ must be $H^1(\Omega )$). Is there some compatibility condition ? I'm thinking in proposing $B$ as $$B(u, v):=\int_\Omega  \nabla u\cdot \nabla v+\int_\Omega cuv+\alpha\int_{\Gamma }uv,$$  and so we want an unique $u\in V$ such that for all $v\in V$ $$B(u, v)=\int_\Omega  fv+\int_{\Gamma }gv.$$ Is this right? Can you help me in reasoning the formulation of this problem?   What is the appropiate choice of $V$? Thanks in advance, this is my first time solving these kind of problems",,"['functional-analysis', 'partial-differential-equations', 'sobolev-spaces', 'calculus-of-variations', 'elliptic-equations']"
7,Prove $L^p$ is reflexive for $1<p<\infty$ by using Riesz representation theorem,Prove  is reflexive for  by using Riesz representation theorem,L^p 1<p<\infty,"By definition, $X$ is reflexive if canonical injection $J:E \to E^{**}$ is surjective, where  $\langle Jx,f\rangle_{E^{**},E^*}=\langle f,x\rangle_{E^*,E},~\forall x \in E,~\forall f \in E^*.$ In order to show $E$ is reflexive, it is not enough to show the existence of linear surjective isometry from $E$ to $E^{**}$. I'd like to know if it is possible to show $L^p$ is reflexive for $1<p<\infty$ by using Riesz representation theorem.  By Riesz representation theorem, $(L^p)^* =L^{p'}$, where $1/p+1/p'=1.$ Usually people say ""since $(L^p)^{**} =(L^{p'})^*=L^p$, $L^p$ is reflexive "" It seems right, but I'd like to prove it in detail. Would you give me any comment for this question? Thanks in advance!","By definition, $X$ is reflexive if canonical injection $J:E \to E^{**}$ is surjective, where  $\langle Jx,f\rangle_{E^{**},E^*}=\langle f,x\rangle_{E^*,E},~\forall x \in E,~\forall f \in E^*.$ In order to show $E$ is reflexive, it is not enough to show the existence of linear surjective isometry from $E$ to $E^{**}$. I'd like to know if it is possible to show $L^p$ is reflexive for $1<p<\infty$ by using Riesz representation theorem.  By Riesz representation theorem, $(L^p)^* =L^{p'}$, where $1/p+1/p'=1.$ Usually people say ""since $(L^p)^{**} =(L^{p'})^*=L^p$, $L^p$ is reflexive "" It seems right, but I'd like to prove it in detail. Would you give me any comment for this question? Thanks in advance!",,"['functional-analysis', 'lp-spaces', 'reflexive-space']"
8,"$(Ax)(t)= \int_{0}^{1} \frac{\sin(ts)}{\mid t-s \mid^{\frac{1}{3}}} x(s) ds$ for $A : L_2[0,1] \to L_2[0,1] $ is compact.",for  is compact.,"(Ax)(t)= \int_{0}^{1} \frac{\sin(ts)}{\mid t-s \mid^{\frac{1}{3}}} x(s) ds A : L_2[0,1] \to L_2[0,1] ","The question is as follows: Show that the linear operator $(Ax)(t)= \int_{0}^{1} \frac{\sin(ts)}{\mid t-s \mid^{\frac{1}{3}}} x(s) ds$ for $A : L_2[0,1] \to L_2[0,1] $ is compact. $\textbf{An idea:}$ For to prove that $A$ is compact, it is enough to show that its kernel $k(t,s) = \frac{\sin(ts)}{\mid t-s \mid^{\frac{1}{3}}} $ is continuous and is in $L_2[0,1] \times L_2[0,1]$, i.e we have to show that $\int_{0}^{1} \int_{0}^{1} \left| \frac{\sin(ts)}{\mid t-s \mid^{\frac{1}{3}}} \right|^2 ds dt \leq +\infty $. For to show this, we have \begin{align} \int_{0}^{1} \int_{0}^{1} \left| \frac{\sin(ts)}{\mid t-s \mid^{\frac{1}{3}}} \right|^2 ds dt &\leq  \int_{0}^{1} \int_{0}^{1}  \frac{1}{\mid t-s \mid^{\frac{2}{3}}}   ds dt \\& =  \int_{0}^{1} \left( \int_{0}^{t} \frac{1}{( t-s )^{\frac{2}{3}}} + \int_{t}^{1} \frac{1}{(  s-t )^{\frac{2}{3}}} ds \right) dt \\&= \int_{0}^{1}  \left( -3(t-s)^{frac{1}{3}}\mid_{0}^{t} + 3(s-t)^{frac{1}{3}}\mid_{t}^{1} \right) dt \\& = \int_{0}^{1} \left( -3 t^{\frac{1}{3}} + 3(1 -t)^{\frac{1}{3}} \right) dt \\&= -\frac{9}{4} t^{\frac{4}{3}}\mid_{0}^{1} -  \frac{9}{4} (1-t)^{\frac{4}{3}}\mid_{0}^{1} = -  \frac{9}{4} +  \frac{9}{4} =0 < +\infty \end{align} This proves the claim. Please let me know if I am wrong or if we need to show something else for to ensure that the mentioned integral operator is compact? Thanks!","The question is as follows: Show that the linear operator $(Ax)(t)= \int_{0}^{1} \frac{\sin(ts)}{\mid t-s \mid^{\frac{1}{3}}} x(s) ds$ for $A : L_2[0,1] \to L_2[0,1] $ is compact. $\textbf{An idea:}$ For to prove that $A$ is compact, it is enough to show that its kernel $k(t,s) = \frac{\sin(ts)}{\mid t-s \mid^{\frac{1}{3}}} $ is continuous and is in $L_2[0,1] \times L_2[0,1]$, i.e we have to show that $\int_{0}^{1} \int_{0}^{1} \left| \frac{\sin(ts)}{\mid t-s \mid^{\frac{1}{3}}} \right|^2 ds dt \leq +\infty $. For to show this, we have \begin{align} \int_{0}^{1} \int_{0}^{1} \left| \frac{\sin(ts)}{\mid t-s \mid^{\frac{1}{3}}} \right|^2 ds dt &\leq  \int_{0}^{1} \int_{0}^{1}  \frac{1}{\mid t-s \mid^{\frac{2}{3}}}   ds dt \\& =  \int_{0}^{1} \left( \int_{0}^{t} \frac{1}{( t-s )^{\frac{2}{3}}} + \int_{t}^{1} \frac{1}{(  s-t )^{\frac{2}{3}}} ds \right) dt \\&= \int_{0}^{1}  \left( -3(t-s)^{frac{1}{3}}\mid_{0}^{t} + 3(s-t)^{frac{1}{3}}\mid_{t}^{1} \right) dt \\& = \int_{0}^{1} \left( -3 t^{\frac{1}{3}} + 3(1 -t)^{\frac{1}{3}} \right) dt \\&= -\frac{9}{4} t^{\frac{4}{3}}\mid_{0}^{1} -  \frac{9}{4} (1-t)^{\frac{4}{3}}\mid_{0}^{1} = -  \frac{9}{4} +  \frac{9}{4} =0 < +\infty \end{align} This proves the claim. Please let me know if I am wrong or if we need to show something else for to ensure that the mentioned integral operator is compact? Thanks!",,"['real-analysis', 'functional-analysis', 'operator-theory']"
9,"For $f$ in dual space, there exists $x$ with norm 1 and $f(x)=\|f\|$ if space is reflexive (and nontrivial)","For  in dual space, there exists  with norm 1 and  if space is reflexive (and nontrivial)",f x f(x)=\|f\|,"Let $X\ne\{0\}$ be a reflexive space and let $f\in X^*$, where $X^*$ is the dual of $X$. I want to know: in general, does there exist an $x\in X$ with $\|x\|=1$, and $f(x)=\|f\|$, where $\|f\|$ is defined as $\sup\{|f(x)|:x\in X,\|x\|=1\}$? I know this is true for $\mathbb{R}^n$ with the norm from the standard inner product, but I'm wondering if it is true in general.","Let $X\ne\{0\}$ be a reflexive space and let $f\in X^*$, where $X^*$ is the dual of $X$. I want to know: in general, does there exist an $x\in X$ with $\|x\|=1$, and $f(x)=\|f\|$, where $\|f\|$ is defined as $\sup\{|f(x)|:x\in X,\|x\|=1\}$? I know this is true for $\mathbb{R}^n$ with the norm from the standard inner product, but I'm wondering if it is true in general.",,"['functional-analysis', 'normed-spaces']"
10,How can i understand this contradiction of $H^{-s}(\Omega)$,How can i understand this contradiction of,H^{-s}(\Omega),"This makes me puzzled.Here $H^{k}(\Omega)$ is the sobolev space $W_p^k(\Omega)$ with $p=2$. We all know that $H^{k}(\Omega)$ is Hilbert space,This means that $(H^k(\Omega))^{*}=H^{-k}(\Omega)$ should be $H^{k}(\Omega)$ itself from Risez Representation theorem. However,we know that Dirac $\delta$-function $\delta\in W^{k}_p(\Omega)$ if $k<-n+n/p \  $ from Sobolev's Inequality.Clearly $\delta\notin H^{k}(\Omega),\forall k>0$.This will be a contradiction,cause there are some $k$ such that $\delta\in H^{-k}(\Omega)$ while $\delta\notin H^{k}(\Omega)$. What's wrong with my previous statement?","This makes me puzzled.Here $H^{k}(\Omega)$ is the sobolev space $W_p^k(\Omega)$ with $p=2$. We all know that $H^{k}(\Omega)$ is Hilbert space,This means that $(H^k(\Omega))^{*}=H^{-k}(\Omega)$ should be $H^{k}(\Omega)$ itself from Risez Representation theorem. However,we know that Dirac $\delta$-function $\delta\in W^{k}_p(\Omega)$ if $k<-n+n/p \  $ from Sobolev's Inequality.Clearly $\delta\notin H^{k}(\Omega),\forall k>0$.This will be a contradiction,cause there are some $k$ such that $\delta\in H^{-k}(\Omega)$ while $\delta\notin H^{k}(\Omega)$. What's wrong with my previous statement?",,"['functional-analysis', 'partial-differential-equations', 'sobolev-spaces', 'finite-element-method']"
11,What domains can we give the Laplacian on the sphere $\mathbb{S}^2$ as an unbounded closed operator?,What domains can we give the Laplacian on the sphere  as an unbounded closed operator?,\mathbb{S}^2,"Recall from the theory of spherical harmonics on the sphere $\mathbb{S}^2$ that $L^2(\mathbb{S}^2)$ has an orthonormal basis of smooth eigenfunctions $Y_\ell^m$ for integer $\ell,m$ such that $-\ell \le m\le\ell$, with $$\Delta Y_\ell^m + \ell(\ell+1)Y_\ell^m \;=\; 0$$ Now, if we denote by $D$ the span of the $Y_\ell^m$, then we know that $D$ is dense in $L^2(\mathbb{S}^2)$. But is the operator $\overline{\Delta|_D}$ self-adjoint, where by $\overline{\Delta|_D}$ we mean the closure of the operator $\Delta$ defined on $D$. If not, what precisely is the domain $\mathcal{D}(\overline{\Delta|_D})$?","Recall from the theory of spherical harmonics on the sphere $\mathbb{S}^2$ that $L^2(\mathbb{S}^2)$ has an orthonormal basis of smooth eigenfunctions $Y_\ell^m$ for integer $\ell,m$ such that $-\ell \le m\le\ell$, with $$\Delta Y_\ell^m + \ell(\ell+1)Y_\ell^m \;=\; 0$$ Now, if we denote by $D$ the span of the $Y_\ell^m$, then we know that $D$ is dense in $L^2(\mathbb{S}^2)$. But is the operator $\overline{\Delta|_D}$ self-adjoint, where by $\overline{\Delta|_D}$ we mean the closure of the operator $\Delta$ defined on $D$. If not, what precisely is the domain $\mathcal{D}(\overline{\Delta|_D})$?",,"['functional-analysis', 'differential-geometry', 'partial-differential-equations', 'harmonic-functions', 'potential-theory']"
12,Standard criterion for essential self-adjointness,Standard criterion for essential self-adjointness,,"Suppose $T:H\rightarrow H$ is a symmetric operator on a Hilbert space $H$. I want to show that $\text{Ran}(T\pm i)$ are dense in $H$ implies that $T$ is essentially self-adjoint, that is the closure of $T$ is self-adjoint. I already know that if $\text{Ran}(T\pm i)=H$ then $T$ is self-adjoint, and I feel that the above should follow from this in a simple way, but I don’t quite see it. Thanks.","Suppose $T:H\rightarrow H$ is a symmetric operator on a Hilbert space $H$. I want to show that $\text{Ran}(T\pm i)$ are dense in $H$ implies that $T$ is essentially self-adjoint, that is the closure of $T$ is self-adjoint. I already know that if $\text{Ran}(T\pm i)=H$ then $T$ is self-adjoint, and I feel that the above should follow from this in a simple way, but I don’t quite see it. Thanks.",,"['functional-analysis', 'operator-theory', 'hilbert-spaces']"
13,Isomorphism of normed vector spaces,Isomorphism of normed vector spaces,,"Let $(V,\|\cdot\|)$ and $(W,\|\cdot\|')$ be a normed vector spaces. We say $V$ and $W$ are isomorphic if there exists a map $L : V \to W$ such that $L$ is both a linear bijection and a homeomorphism on the norm topologies. Say $V$ and $W$ are algebraically isomorphic if there exists a linear bijection $T : V \to W$. ($T$ not necessarily a homeomorphism.) Suppose $V$ and $W$ are both algebraically isomorphic and homeomorphic in the norm topology. Are $V$ and $W$ isomorphic? In other words, if there exists a linear bijection $T : V \to W$ and a homeomorphism $H : V \to W$, does there necessarily exist a linear bijective homeomorphism $T : V \to W$?","Let $(V,\|\cdot\|)$ and $(W,\|\cdot\|')$ be a normed vector spaces. We say $V$ and $W$ are isomorphic if there exists a map $L : V \to W$ such that $L$ is both a linear bijection and a homeomorphism on the norm topologies. Say $V$ and $W$ are algebraically isomorphic if there exists a linear bijection $T : V \to W$. ($T$ not necessarily a homeomorphism.) Suppose $V$ and $W$ are both algebraically isomorphic and homeomorphic in the norm topology. Are $V$ and $W$ isomorphic? In other words, if there exists a linear bijection $T : V \to W$ and a homeomorphism $H : V \to W$, does there necessarily exist a linear bijective homeomorphism $T : V \to W$?",,"['functional-analysis', 'normed-spaces', 'vector-space-isomorphism']"
14,to prove an integral operator with a kernel is compact,to prove an integral operator with a kernel is compact,,"emphsisingly, I just need a hint not a whole solution please. Problem :   Consider the operator   $T:C([0,1])\to C([0,1])$defined by    $$ (Tf)(t):=\int_{0}^{1}k(s,t)f(s)ds $$    where    $k:[0,1]^{2}\to \mathbb{R}$   satisfies the following for all    $t\in [0,1],$   the function   $k_{t}(s)=k(t,s)$   is integrable in $s$:   $$ \int_{0}^{1}k(s,t)ds<\infty, $$ the function    $ t\mapsto k_{t}\in L^{1}([0,1]) $   is continuous. Show that $T$ is compact.","emphsisingly, I just need a hint not a whole solution please. Problem :   Consider the operator   $T:C([0,1])\to C([0,1])$defined by    $$ (Tf)(t):=\int_{0}^{1}k(s,t)f(s)ds $$    where    $k:[0,1]^{2}\to \mathbb{R}$   satisfies the following for all    $t\in [0,1],$   the function   $k_{t}(s)=k(t,s)$   is integrable in $s$:   $$ \int_{0}^{1}k(s,t)ds<\infty, $$ the function    $ t\mapsto k_{t}\in L^{1}([0,1]) $   is continuous. Show that $T$ is compact.",,"['real-analysis', 'functional-analysis', 'analysis', 'operator-theory', 'compact-operators']"
15,Derivations on the spaces of continuous functions form an infinite dimensional vector space(generalized tangent space),Derivations on the spaces of continuous functions form an infinite dimensional vector space(generalized tangent space),,"This question basically asks why the notion of tangent space can't be well-generalized to topological manifolds without coming across the issue of dimension. Let $X$ be a smooth manifold of finite dimension and $C(X)$ denote the space of continuous functions on $X$. Let $p\in X$. A linear derivation $v$ w.r.t.$p$ is a linear functional on $C(X)$ satisfying $v(fg)=f(p)v(g)+g(p)v(f), \forall f,g\in C(X)$. My question is, is the space of linear derivations an infinite dimensional space? I will be happy enough to see a proof for $X=\mathbb R, p=0$(or other special cases that could lead to infinite dimension), but general results will be great. As we know, if $C(X)$ is replaced by $C^\infty(X)$, then this space is the ordinary tangent space, which is finite dimensional.","This question basically asks why the notion of tangent space can't be well-generalized to topological manifolds without coming across the issue of dimension. Let $X$ be a smooth manifold of finite dimension and $C(X)$ denote the space of continuous functions on $X$. Let $p\in X$. A linear derivation $v$ w.r.t.$p$ is a linear functional on $C(X)$ satisfying $v(fg)=f(p)v(g)+g(p)v(f), \forall f,g\in C(X)$. My question is, is the space of linear derivations an infinite dimensional space? I will be happy enough to see a proof for $X=\mathbb R, p=0$(or other special cases that could lead to infinite dimension), but general results will be great. As we know, if $C(X)$ is replaced by $C^\infty(X)$, then this space is the ordinary tangent space, which is finite dimensional.",,"['functional-analysis', 'differential-geometry', 'smooth-manifolds']"
16,a problem about convergence in $L^{P}$ space,a problem about convergence in  space,L^{P},"I need a small certain hint for solving this problem please. Problem:  Let  $(f_{n})_{n} $ be a bounded sequence in  $ L^{3}(\mathbb{R}), $ such that  $ f_{n}\to f $ in $ L^{\frac{3}{2}}(\mathbb{R}). $ Prove that  $ f_{n}\to f $ in $ L^{2}(\mathbb{R}). $","I need a small certain hint for solving this problem please. Problem:  Let  $(f_{n})_{n} $ be a bounded sequence in  $ L^{3}(\mathbb{R}), $ such that  $ f_{n}\to f $ in $ L^{\frac{3}{2}}(\mathbb{R}). $ Prove that  $ f_{n}\to f $ in $ L^{2}(\mathbb{R}). $",,"['real-analysis', 'functional-analysis', 'analysis', 'lp-spaces']"
17,Baire Category Theorem without Completeness,Baire Category Theorem without Completeness,,"Let $(X,d)$ be a metric space. We say that $Y \subseteq X$ is dense in $X$ if for any non-empty open set $U\subseteq X,$ we have $U \cap Y \neq \emptyset.$ Baire Category Theorem states that If $(X,d)$ is a complete metric space with $(U_n)_{n \in \mathbb{N}}$ being a sequence of open dense sets in $X,$ then their intersection $\bigcap_{n \in \mathbb{N}}U_n$ is dense in $X.$ If we remove openness in the condition, then the theorem will not hold anymore, simply let $X = \mathbb{R},$ $U_1 = \mathbb{Q}$ and $\mathbb{R} \setminus \mathbb{Q}.$ Clearly $X$ is complete and $U_1$ and $U_2$ are dense in $X,$ but $U_1 \cap U_2 = \emptyset$ is not dense in $X.$ Question : Give an example such that $X$ is not complete with $(U_n)_{n \in \mathbb{N}}$ a sequence of open dense sets but their intersection $\bigcap_{n \in \mathbb{N}}U_n$ is not dense in $X.$ I have been trying to come out with an example that satisfies the question above. Since finite dimensional space is always complete, I have to let $X$ be infinite dimensional.  One example that comes to my mind is $C[0,1],$ the set of continuous functions on $[0,1].$ However, I do not know which set is dense in $C[0,1].$ Any hint would be appreciated.","Let $(X,d)$ be a metric space. We say that $Y \subseteq X$ is dense in $X$ if for any non-empty open set $U\subseteq X,$ we have $U \cap Y \neq \emptyset.$ Baire Category Theorem states that If $(X,d)$ is a complete metric space with $(U_n)_{n \in \mathbb{N}}$ being a sequence of open dense sets in $X,$ then their intersection $\bigcap_{n \in \mathbb{N}}U_n$ is dense in $X.$ If we remove openness in the condition, then the theorem will not hold anymore, simply let $X = \mathbb{R},$ $U_1 = \mathbb{Q}$ and $\mathbb{R} \setminus \mathbb{Q}.$ Clearly $X$ is complete and $U_1$ and $U_2$ are dense in $X,$ but $U_1 \cap U_2 = \emptyset$ is not dense in $X.$ Question : Give an example such that $X$ is not complete with $(U_n)_{n \in \mathbb{N}}$ a sequence of open dense sets but their intersection $\bigcap_{n \in \mathbb{N}}U_n$ is not dense in $X.$ I have been trying to come out with an example that satisfies the question above. Since finite dimensional space is always complete, I have to let $X$ be infinite dimensional.  One example that comes to my mind is $C[0,1],$ the set of continuous functions on $[0,1].$ However, I do not know which set is dense in $C[0,1].$ Any hint would be appreciated.",,"['real-analysis', 'functional-analysis', 'metric-spaces', 'examples-counterexamples', 'baire-category']"
18,"Tensor product $L^2([0,1],\mathbb R)\otimes L^2([0,1],\mathbb R)$",Tensor product,"L^2([0,1],\mathbb R)\otimes L^2([0,1],\mathbb R)","I am trying to get a good understanding of what a tensor product is and I am trying to understand one particular example. Suppose that $H=L^2([0,1],\mathbb R)$ and take the inner-product $$ \langle f,g\rangle=\int_0^1f(x)g(x)dx $$ defined for each $f,g\in H$ as a bilinear map from $H\times H$ to $\mathbb R$. I want to investigate the tensor product $H\otimes H$. First of all, as far as I understand, there exists a universal bilinear map $\varphi:H\times H\to H\otimes H$ and then there exists a linear map $l:H\otimes H\to\mathbb R$ such that $\langle\cdot,\cdot\rangle=l\circ \varphi$, i.e. $\langle f,g\rangle=l(\varphi(f,g))=l(f\otimes g)$ for each $f,g\in H$. My questions are as follow. As far as I understand (see also here ), a tensor $f\otimes g$ is defined as $(f\otimes g)(x,y)=f(x)g(y)$ for each $f,g\in H$ and $x,y\in[0,1]$ . How can we deduce that tensors $f\otimes g$ look like this? How can we come up with this expression? The bilinear map $\varphi$ is given by $\varphi(f,g)=f\otimes g$. $H\otimes H$ also contains elements that are finite linear combinations of the tensors $f\otimes g$. So the map $\varphi$ is not necessarily surjective, the image of $H\times H$ is smaller than $H\otimes H$, right? The tensor product $H\otimes H$ is actually isomorphic to the space $L^2([0,1]^2,\mathbb R)$, is that correct? How can we find the linear map $l$ that maps tensors $f\otimes g$ to $\langle f,g\rangle$ for each $f,g\in H$? Thanks a lot for your help!","I am trying to get a good understanding of what a tensor product is and I am trying to understand one particular example. Suppose that $H=L^2([0,1],\mathbb R)$ and take the inner-product $$ \langle f,g\rangle=\int_0^1f(x)g(x)dx $$ defined for each $f,g\in H$ as a bilinear map from $H\times H$ to $\mathbb R$. I want to investigate the tensor product $H\otimes H$. First of all, as far as I understand, there exists a universal bilinear map $\varphi:H\times H\to H\otimes H$ and then there exists a linear map $l:H\otimes H\to\mathbb R$ such that $\langle\cdot,\cdot\rangle=l\circ \varphi$, i.e. $\langle f,g\rangle=l(\varphi(f,g))=l(f\otimes g)$ for each $f,g\in H$. My questions are as follow. As far as I understand (see also here ), a tensor $f\otimes g$ is defined as $(f\otimes g)(x,y)=f(x)g(y)$ for each $f,g\in H$ and $x,y\in[0,1]$ . How can we deduce that tensors $f\otimes g$ look like this? How can we come up with this expression? The bilinear map $\varphi$ is given by $\varphi(f,g)=f\otimes g$. $H\otimes H$ also contains elements that are finite linear combinations of the tensors $f\otimes g$. So the map $\varphi$ is not necessarily surjective, the image of $H\times H$ is smaller than $H\otimes H$, right? The tensor product $H\otimes H$ is actually isomorphic to the space $L^2([0,1]^2,\mathbb R)$, is that correct? How can we find the linear map $l$ that maps tensors $f\otimes g$ to $\langle f,g\rangle$ for each $f,g\in H$? Thanks a lot for your help!",,"['functional-analysis', 'vector-spaces', 'hilbert-spaces', 'tensor-products', 'multilinear-algebra']"
19,Show that $\phi$ is an isometry,Show that  is an isometry,\phi,"The following Lemma can be obtained in ' Geometric Nonlinear Functional Analysis ' by Benyamini and Lindenstrauss, page $2.$ Lemma: Every metric space $X$ is isometric to a subset of $\ell_{\infty}(\Gamma)$ for some set $\Gamma.$ Proof: Fix any $x_0 \in X,$ and take $\Gamma$ to be the set $X$ itself. The embedding $\phi:X \rightarrow \ell_{\infty}(\Gamma)$ is defined by $$\phi(x)(y) = d(x,y) - d(x_0,y).$$ Question: How to show that $\phi$ is an isometry between $X$ and $\ell_{\infty}(\Gamma)?$ We want to show that $ d(\phi(x), \phi(z)) = d(x,z)$ for every $x,z \in X.$ Observe that for each $x \in X,$ $$\sup_{y \in X}|\phi(x)(y)| = \sup_{y \in X}|d(x,y)-d(x_0,y)| \leq \sup_{y \in X}|d(x,x_0)| = |d(x,x_0)|.$$ I do not know how to continue. Any hint is appreciated.","The following Lemma can be obtained in ' Geometric Nonlinear Functional Analysis ' by Benyamini and Lindenstrauss, page Lemma: Every metric space is isometric to a subset of for some set Proof: Fix any and take to be the set itself. The embedding is defined by Question: How to show that is an isometry between and We want to show that for every Observe that for each I do not know how to continue. Any hint is appreciated.","2. X \ell_{\infty}(\Gamma) \Gamma. x_0 \in X, \Gamma X \phi:X \rightarrow \ell_{\infty}(\Gamma) \phi(x)(y) = d(x,y) - d(x_0,y). \phi X \ell_{\infty}(\Gamma)?  d(\phi(x), \phi(z)) = d(x,z) x,z \in X. x \in X, \sup_{y \in X}|\phi(x)(y)| = \sup_{y \in X}|d(x,y)-d(x_0,y)| \leq \sup_{y \in X}|d(x,x_0)| = |d(x,x_0)|.","['real-analysis', 'functional-analysis', 'metric-spaces', 'lp-spaces', 'isometry']"
20,Natural quotient map,Natural quotient map,,Let  $X$ be a Banach space and let  $M $  be a closed subspace of  $X $. When is the quotient map $Q :X \to X/M $ closed? I got somewhere that it happens iff$ M=X$ or $M=(0) $. But I couldn't prove it. Please suggest.,Let  $X$ be a Banach space and let  $M $  be a closed subspace of  $X $. When is the quotient map $Q :X \to X/M $ closed? I got somewhere that it happens iff$ M=X$ or $M=(0) $. But I couldn't prove it. Please suggest.,,"['functional-analysis', 'banach-spaces', 'quotient-spaces', 'closed-map']"
21,"$X$ and $Y$ Banach Spaces, $T \in B(X,Y)$, $Y = \operatorname{im}T \oplus M$, for $M \subseteq Y$, then $\operatorname{im}T$ is closed in $Y$","and  Banach Spaces, , , for , then  is closed in","X Y T \in B(X,Y) Y = \operatorname{im}T \oplus M M \subseteq Y \operatorname{im}T Y","Let $X$ and $Y$ be Banach spaces. If $T \in B(X,Y)$, and $Y = \operatorname{im}T \oplus M$ for some closed linear subspace $M$ of $Y$, then $\operatorname{im}(T)$ is closed in $Y$. I am unsure if this statement is true or not. Nonetheless, I am having difficulty proving it, any suggestions or counterexample?","Let $X$ and $Y$ be Banach spaces. If $T \in B(X,Y)$, and $Y = \operatorname{im}T \oplus M$ for some closed linear subspace $M$ of $Y$, then $\operatorname{im}(T)$ is closed in $Y$. I am unsure if this statement is true or not. Nonetheless, I am having difficulty proving it, any suggestions or counterexample?",,['functional-analysis']
22,Prove $H^1(\Omega)$ is complete given that $L_2(\Omega)$ is complete,Prove  is complete given that  is complete,H^1(\Omega) L_2(\Omega),"Given that $L_2(\Omega)$ is complete, prove that $H^1(\Omega)$ is complete. Hint: Assume that $\|v_j-v_i\|\to 0$ as $i,j\to\infty$. Show that there are $v,w_k$ such that $\|v_j-v\|\to 0,\|\partial v_j/\partial x_k -w_k\|\to 0$ and that $w_k=\partial v/\partial x_k$ in the sense of weak derivative. So far I did, Since $L_2(\Omega)$ is complete we get $$\|v_j-v\|_{L_2}\to 0$$ where $v\in L_2(\Omega).$ Let $\{v_i\}$ be a Cauchy sequence in $H^1(\Omega)$, then  \begin{align*} &\|v_j-v_i\|_{H^1}\to 0\\ \implies\,&\|v_j-v_i\|_{L_2}+\|\nabla v_j-\nabla v_i\|_{L_2}\to 0. \end{align*} which gives us $$\|v_j-v_i\|_{L_2}\to 0$$ and $$\|\nabla v_j-\nabla v_i\|_{L_2}\to 0.$$ Now I am stuck, any help would be greatly appreciated. Thanks in advance.","Given that $L_2(\Omega)$ is complete, prove that $H^1(\Omega)$ is complete. Hint: Assume that $\|v_j-v_i\|\to 0$ as $i,j\to\infty$. Show that there are $v,w_k$ such that $\|v_j-v\|\to 0,\|\partial v_j/\partial x_k -w_k\|\to 0$ and that $w_k=\partial v/\partial x_k$ in the sense of weak derivative. So far I did, Since $L_2(\Omega)$ is complete we get $$\|v_j-v\|_{L_2}\to 0$$ where $v\in L_2(\Omega).$ Let $\{v_i\}$ be a Cauchy sequence in $H^1(\Omega)$, then  \begin{align*} &\|v_j-v_i\|_{H^1}\to 0\\ \implies\,&\|v_j-v_i\|_{L_2}+\|\nabla v_j-\nabla v_i\|_{L_2}\to 0. \end{align*} which gives us $$\|v_j-v_i\|_{L_2}\to 0$$ and $$\|\nabla v_j-\nabla v_i\|_{L_2}\to 0.$$ Now I am stuck, any help would be greatly appreciated. Thanks in advance.",,"['functional-analysis', 'partial-differential-equations', 'sobolev-spaces', 'lp-spaces', 'weak-derivatives']"
23,Limit of a sequence in an $L^{p}$ space.,Limit of a sequence in an  space.,L^{p},"Problem Statement: Suppose $f_{n}\in L^{p}(\mathbb{R}^{d})$ with $\lVert f_{n}\rVert_{p}\leq M$ ( $1\leq p<\infty$ ). Suppose $f_{n}(x)\rightarrow f(x)$ pointwise almost everywhere. Show that $f\in L^{p}(\mathbb{R}^{d})$ with $\lVert f\rVert_{p}\leq c_{p}M$ . ( $c_{p}=2^{p-1}$ , so $\lvert x+y\rvert^{p}\leq c_{p}(\lvert x\rvert^{p}+\lvert y\rvert^{p})$ , $p\geq 1$ ). I am trying to solve this problem but I am not completely clear about what exactly I need to show, and what I can assume. I was told to first assume that $f$ is bounded, and use Egorov's theorem to show that $\lVert f\rVert_{L^{p}(B_{R})}\leq c_{p}M$ for each $R>0$ . Egorov's Theorem $D\subset \mathbb{R}^{n}$ , $m(D)<\infty$ and $f_{n}, f$ are measurable functions over $D$ with $f_{n}(x)\rightarrow f(x)$ almost everywhere. Then $\forall \varepsilon >0$ $\exists E\subset D$ closed with $m(D\setminus E)<\varepsilon$ and $f_{n}\rightarrow f$ uniformly in $E$ . First, with the original assumption "" $f_{n}(x)\rightarrow f(x)$ pointwise almost everywhere"", does this mean with respect to the $L^{p}$ norm? That is, $\exists E\subset \mathbb{R}^{d}$ with $m(E)=0$ such that $\forall \varepsilon>0$ $\exists N=N(\varepsilon)>0$ such that $n\geq N$ and $x\in \mathbb{R}^{d}\setminus E$ (or $x\in B_{R}\setminus E$ ) implies $\lVert f_{n}(x)-f(x)\rVert_{p}<\varepsilon$ . Then to show that $f\in L^{P}(B_{R})$ . We must show that $\lVert f\rVert_{p}$ exists? That is, show that $\Big(\int_{B_{R}}\lvert f\rvert^{p}\Big)^{1/p}$ exists. Is it enough to say that because $f$ is measurable, then $\lvert f\rvert^{p}$ is measurable, and thus has an integral? But by Egorov's Theorem, $f_{n}\rightarrow f$ uniformly in $B_{R}$ , so is it enough to use the fact that $L^{p}$ is a Banach space to conclude that since $f_{n}\rightarrow f$ uniformly implies that $f\in L^{p}(B_{R})$ ? Then we have $$\lVert f\rVert_{p}\leq \lVert f_{n}-f\rVert_{p}+\lVert f_{n}\rVert_{p}<\varepsilon +M.$$ But we must show that $\lVert f\rVert_{p}\leq c_{p}M$ . Yet, I am not seeing where the $c_{p}$ comes into play, nor why the inequality $\lvert x+y\rvert^{p}\leq c_{p}(\lvert x\rvert^{p}+\lvert y\rvert^{p})$ is useful. I appreciate any hints to push me in the right direction.","Problem Statement: Suppose with ( ). Suppose pointwise almost everywhere. Show that with . ( , so , ). I am trying to solve this problem but I am not completely clear about what exactly I need to show, and what I can assume. I was told to first assume that is bounded, and use Egorov's theorem to show that for each . Egorov's Theorem , and are measurable functions over with almost everywhere. Then closed with and uniformly in . First, with the original assumption "" pointwise almost everywhere"", does this mean with respect to the norm? That is, with such that such that and (or ) implies . Then to show that . We must show that exists? That is, show that exists. Is it enough to say that because is measurable, then is measurable, and thus has an integral? But by Egorov's Theorem, uniformly in , so is it enough to use the fact that is a Banach space to conclude that since uniformly implies that ? Then we have But we must show that . Yet, I am not seeing where the comes into play, nor why the inequality is useful. I appreciate any hints to push me in the right direction.","f_{n}\in L^{p}(\mathbb{R}^{d}) \lVert f_{n}\rVert_{p}\leq M 1\leq p<\infty f_{n}(x)\rightarrow f(x) f\in L^{p}(\mathbb{R}^{d}) \lVert f\rVert_{p}\leq c_{p}M c_{p}=2^{p-1} \lvert x+y\rvert^{p}\leq c_{p}(\lvert x\rvert^{p}+\lvert y\rvert^{p}) p\geq 1 f \lVert f\rVert_{L^{p}(B_{R})}\leq c_{p}M R>0 D\subset \mathbb{R}^{n} m(D)<\infty f_{n}, f D f_{n}(x)\rightarrow f(x) \forall \varepsilon >0 \exists E\subset D m(D\setminus E)<\varepsilon f_{n}\rightarrow f E f_{n}(x)\rightarrow f(x) L^{p} \exists E\subset \mathbb{R}^{d} m(E)=0 \forall \varepsilon>0 \exists N=N(\varepsilon)>0 n\geq N x\in \mathbb{R}^{d}\setminus E x\in B_{R}\setminus E \lVert f_{n}(x)-f(x)\rVert_{p}<\varepsilon f\in L^{P}(B_{R}) \lVert f\rVert_{p} \Big(\int_{B_{R}}\lvert f\rvert^{p}\Big)^{1/p} f \lvert f\rvert^{p} f_{n}\rightarrow f B_{R} L^{p} f_{n}\rightarrow f f\in L^{p}(B_{R}) \lVert f\rVert_{p}\leq \lVert f_{n}-f\rVert_{p}+\lVert f_{n}\rVert_{p}<\varepsilon +M. \lVert f\rVert_{p}\leq c_{p}M c_{p} \lvert x+y\rvert^{p}\leq c_{p}(\lvert x\rvert^{p}+\lvert y\rvert^{p})","['real-analysis', 'functional-analysis', 'convergence-divergence', 'lp-spaces', 'proof-explanation']"
24,Lemma 2.5-2 and Theorem 2.5-3 in Kreyszig's Functional Analysis Book: Does compactness of every closed and bounded subset also imply ...?,Lemma 2.5-2 and Theorem 2.5-3 in Kreyszig's Functional Analysis Book: Does compactness of every closed and bounded subset also imply ...?,,"Here is Lemma 2.5-2 in the book Introductory Functional Analysis With Applications by Erwine Kreyszig: A compact subset $M$ of a metric space is closed and bounded. But the converse is not true, as is shown by the set $$M = \left\{ \ (1, 0, 0, \ldots), \ (0, 1, 0, 0, \ldots), \ (0, 0, 1, 0, 0, \ldots), \ \ldots \ \right\}$$ in $\ell^2$. But here is Theorem 2.5-3: In a finite dimensional normed space $X$, any subset $M \subset X$ is compact if and only if $M$ is closed and bounded. Now my question is as follows: Let $X$ be a metric space such that every closed and bounded subset of $X$ is (sequentially) compact. Does this imply that $X$ is a finite dimensional normed space? I have no idea of how to proceed, although I'm clear about the proofs in Kreyszig.","Here is Lemma 2.5-2 in the book Introductory Functional Analysis With Applications by Erwine Kreyszig: A compact subset $M$ of a metric space is closed and bounded. But the converse is not true, as is shown by the set $$M = \left\{ \ (1, 0, 0, \ldots), \ (0, 1, 0, 0, \ldots), \ (0, 0, 1, 0, 0, \ldots), \ \ldots \ \right\}$$ in $\ell^2$. But here is Theorem 2.5-3: In a finite dimensional normed space $X$, any subset $M \subset X$ is compact if and only if $M$ is closed and bounded. Now my question is as follows: Let $X$ be a metric space such that every closed and bounded subset of $X$ is (sequentially) compact. Does this imply that $X$ is a finite dimensional normed space? I have no idea of how to proceed, although I'm clear about the proofs in Kreyszig.",,"['real-analysis', 'functional-analysis', 'analysis', 'compactness', 'normed-spaces']"
25,Is there a category of spaces with multiple choices of topology?,Is there a category of spaces with multiple choices of topology?,,"If I remember my functional analysis correctly (hint: I probably don't), when considering Banach spaces we might want to work with up to 3 distinct choices of topology at a time: strong, weak, and weak-*. (Some of these coincide, I think, when the space is reflexive or Hilbert.) At least naively, it would seem like the category of topological spaces is insufficient to describe such objects, since each object carries insufficient ""data"" (i.e. only one choice of topology instead of 3). Is there a category-theoretic way to think about Banach spaces which is agnostic to which of the three topologies, strong, weak, weak-*, we might want to work with? My gut inclination is that the answer is no, because I can't think of appropriate morphisms for such a category -- they would have to be continuous with respect to all 3 different topologies, whereas I think one would be interested in a function which is continuous with respect to any one of them. That would lead to three different classes of morphisms, which would lead to an object related to a category (in particular which has categories as a special case) but nevertheless different. Note: I would have expected these questions (1) (2) to contain the answer, but they don't for whatever reason. Also nLab's page does seem to indicate that category theory applied to Banach spaces is less than simple (something about short versus bounded linear maps and unit balls) but doesn't seem to address my question about choice of topology (the phrase ""strong operator topology"" is found only once on the page, and the word ""weak"" has no hits at all).","If I remember my functional analysis correctly (hint: I probably don't), when considering Banach spaces we might want to work with up to 3 distinct choices of topology at a time: strong, weak, and weak-*. (Some of these coincide, I think, when the space is reflexive or Hilbert.) At least naively, it would seem like the category of topological spaces is insufficient to describe such objects, since each object carries insufficient ""data"" (i.e. only one choice of topology instead of 3). Is there a category-theoretic way to think about Banach spaces which is agnostic to which of the three topologies, strong, weak, weak-*, we might want to work with? My gut inclination is that the answer is no, because I can't think of appropriate morphisms for such a category -- they would have to be continuous with respect to all 3 different topologies, whereas I think one would be interested in a function which is continuous with respect to any one of them. That would lead to three different classes of morphisms, which would lead to an object related to a category (in particular which has categories as a special case) but nevertheless different. Note: I would have expected these questions (1) (2) to contain the answer, but they don't for whatever reason. Also nLab's page does seem to indicate that category theory applied to Banach spaces is less than simple (something about short versus bounded linear maps and unit balls) but doesn't seem to address my question about choice of topology (the phrase ""strong operator topology"" is found only once on the page, and the word ""weak"" has no hits at all).",,"['functional-analysis', 'soft-question', 'category-theory', 'banach-spaces']"
26,Why is a contractive algebra homomorphism between C*-algebras necessarily a C*-homomorphism?,Why is a contractive algebra homomorphism between C*-algebras necessarily a C*-homomorphism?,,"Suppose Φ is an algebra homomorphism from a unital C*-algebra into another unital C*-algebra. How to prove that if $\| \Phi(x)\| \le \|x\|$ for all $x$, then $\Phi$ is a C*-homomophism? In other words: How to prove that $\Phi$ preserves involutions? This is an exercise from Kehe Zhu's ""An introduction to operator algebras"".","Suppose Φ is an algebra homomorphism from a unital C*-algebra into another unital C*-algebra. How to prove that if $\| \Phi(x)\| \le \|x\|$ for all $x$, then $\Phi$ is a C*-homomophism? In other words: How to prove that $\Phi$ preserves involutions? This is an exercise from Kehe Zhu's ""An introduction to operator algebras"".",,"['functional-analysis', 'operator-algebras', 'banach-algebras']"
27,Compute the norm of an operator $T$,Compute the norm of an operator,T,"Let $X = Y = C([0,1], \mathbb{K})$ with $\|f \|_X = \| f \|_Y = \|f \|_1 = \int_{[0,1]} | f(t) |dt $ and let $(Tf)(x) = \int_0^x f(t) dt, \ x \in [0,1], \ f \in X$. Compute the norm of T. I have managed to show that $\|T \| \leq 1$. So I wish to show that $\| T \| \geq 1$. But I dont know how to do that, so I took a look at the solutions, where they introduce $f_n (x) = (2n - 2n^2x) \mathbb{1}_{[0,1/n]} (x) $ with this function they manage to show that $1 - 1/n \leq \| Tf_n \|_1 \leq 1$. How should I be able to ""guess"" such a function $f_n(x)$, to me it's seems that it's just coming from above or something, how could I come up with this function, like in a critical situation like an exam? The question itself is from a previous exam, so I guess I should be able to ""see"" this function $f_n$ without much effort.","Let $X = Y = C([0,1], \mathbb{K})$ with $\|f \|_X = \| f \|_Y = \|f \|_1 = \int_{[0,1]} | f(t) |dt $ and let $(Tf)(x) = \int_0^x f(t) dt, \ x \in [0,1], \ f \in X$. Compute the norm of T. I have managed to show that $\|T \| \leq 1$. So I wish to show that $\| T \| \geq 1$. But I dont know how to do that, so I took a look at the solutions, where they introduce $f_n (x) = (2n - 2n^2x) \mathbb{1}_{[0,1/n]} (x) $ with this function they manage to show that $1 - 1/n \leq \| Tf_n \|_1 \leq 1$. How should I be able to ""guess"" such a function $f_n(x)$, to me it's seems that it's just coming from above or something, how could I come up with this function, like in a critical situation like an exam? The question itself is from a previous exam, so I guess I should be able to ""see"" this function $f_n$ without much effort.",,"['real-analysis', 'functional-analysis', 'operator-theory', 'proof-explanation']"
28,Restriction of self-adjoint operator self-adjoint?,Restriction of self-adjoint operator self-adjoint?,,"Consider an unbounded self-adjoint operator $A$ on a Hilbert space $\mathcal{H}$. Let $\mathcal{J} \subset \mathcal{H}$ a closed subspace reducing $A$, i.e. such that $P A \subset A P$ where $P$ denotes orthogonal projection onto $J$. Equivalently, $P \mathcal{D}(A) \subset \mathcal{D}(A)$ and $P A \psi = A P \psi$ for all $\psi \in \mathcal{D}(A)$. Then the restriction $A|\mathcal{J}$ is a densely defined operator on $\mathcal{J}$ with domain $\mathcal{D}(A) \cap \mathcal{J}$. My question is this: is $A|\mathcal{J}$ again self-adjoint? The reason I am interested in this question is the following: Take $\mathcal{H} = L^2(\mathbb{R}^{3N})$, and $\mathcal{J} = \Lambda L^2(\mathbb{R}^{3N})$, where the $\Lambda$ denotes the totally antisymmetric subspace, i.e. those functions $\psi(\vec{x_1},...,\vec{x_N})$ with the property that for any permutation $\sigma \in S^N$, \begin{equation} \psi(\vec{x_{\sigma(1)}},...,\vec{x_{\sigma(N)}}) = sign(\sigma) \psi(\vec{x_1},...,\vec{x_N}) \end{equation} Then $\mathcal{H}$ is the phase space of an atom consisting of $N$ electrons, with the nucleus fixed at the origin, and $\mathcal{J}$ is the phase space for the same system, but respecting the Pauli principle. My operator on $\mathcal{H}$ is the self-adjoint operator given by \begin{equation} H^N = - \sum_{j=1}^{N} \Delta_j + \sum_{j = 1}^{N} V_{en}(x_j) + \sum_{i < j} V_{ee}(x_i - x_j) \end{equation} where the $V_{ee}$ terms denote electron-electron repulsion, and $V_{en}$ electron-nucleus attraction. In fact, in this case I know of a proof: since the Fourier transform maps antisymmetric functions to antisymmetric functions, one can first show that $H_0 = - \Delta$ is self-adjoint when restricted to $\mathcal{J}$. Then use the fact that the remaining terms are $H_0$-bounded with $H_0$-bound $0$, which remains true for the restriction. I am aware of the related question at Selfadjoint operators . However, the case I am interested in is very different, in the sense that the restricted operator $A|\mathcal{J}$ is considered an operator on $\mathcal{J}$ rather than on the full Hilbert space $\mathcal{H}$. Indeed, considering $A|\mathcal{J}$ to be an operator on $\mathcal{H}$, it is in general (and certainly in my case) not even densely defined.","Consider an unbounded self-adjoint operator $A$ on a Hilbert space $\mathcal{H}$. Let $\mathcal{J} \subset \mathcal{H}$ a closed subspace reducing $A$, i.e. such that $P A \subset A P$ where $P$ denotes orthogonal projection onto $J$. Equivalently, $P \mathcal{D}(A) \subset \mathcal{D}(A)$ and $P A \psi = A P \psi$ for all $\psi \in \mathcal{D}(A)$. Then the restriction $A|\mathcal{J}$ is a densely defined operator on $\mathcal{J}$ with domain $\mathcal{D}(A) \cap \mathcal{J}$. My question is this: is $A|\mathcal{J}$ again self-adjoint? The reason I am interested in this question is the following: Take $\mathcal{H} = L^2(\mathbb{R}^{3N})$, and $\mathcal{J} = \Lambda L^2(\mathbb{R}^{3N})$, where the $\Lambda$ denotes the totally antisymmetric subspace, i.e. those functions $\psi(\vec{x_1},...,\vec{x_N})$ with the property that for any permutation $\sigma \in S^N$, \begin{equation} \psi(\vec{x_{\sigma(1)}},...,\vec{x_{\sigma(N)}}) = sign(\sigma) \psi(\vec{x_1},...,\vec{x_N}) \end{equation} Then $\mathcal{H}$ is the phase space of an atom consisting of $N$ electrons, with the nucleus fixed at the origin, and $\mathcal{J}$ is the phase space for the same system, but respecting the Pauli principle. My operator on $\mathcal{H}$ is the self-adjoint operator given by \begin{equation} H^N = - \sum_{j=1}^{N} \Delta_j + \sum_{j = 1}^{N} V_{en}(x_j) + \sum_{i < j} V_{ee}(x_i - x_j) \end{equation} where the $V_{ee}$ terms denote electron-electron repulsion, and $V_{en}$ electron-nucleus attraction. In fact, in this case I know of a proof: since the Fourier transform maps antisymmetric functions to antisymmetric functions, one can first show that $H_0 = - \Delta$ is self-adjoint when restricted to $\mathcal{J}$. Then use the fact that the remaining terms are $H_0$-bounded with $H_0$-bound $0$, which remains true for the restriction. I am aware of the related question at Selfadjoint operators . However, the case I am interested in is very different, in the sense that the restricted operator $A|\mathcal{J}$ is considered an operator on $\mathcal{J}$ rather than on the full Hilbert space $\mathcal{H}$. Indeed, considering $A|\mathcal{J}$ to be an operator on $\mathcal{H}$, it is in general (and certainly in my case) not even densely defined.",,"['functional-analysis', 'quantum-mechanics', 'unbounded-operators']"
29,An inequality for convolution using Hölder inequality,An inequality for convolution using Hölder inequality,,"Let $p , q , r$ be three real numbers in $[1 , + \infty]$ such that $\frac{1}{p} + \frac{1}{q} = 1 + \frac{1}{r}$. If $f \in L^p({\mathbb{R}}^n)$, $g \in L^q({\mathbb{R}}^n)$ and $r < \infty$, I have to prove that $$ {|(f*g)(x)|}^r \leq {\|f\|}_p^{r - p} {\|g\|}_q^{r - q} \int_{{\mathbb{R}}^n} {|f(y)|}^p {|g(x - y)|}^q dy $$ and my indication is to use Hölder inequality for three functions; my intuition sais that $f$ and $g$ are two of that functions but I have to obtain the third. Can you help me with this problem please? Thank you very much.","Let $p , q , r$ be three real numbers in $[1 , + \infty]$ such that $\frac{1}{p} + \frac{1}{q} = 1 + \frac{1}{r}$. If $f \in L^p({\mathbb{R}}^n)$, $g \in L^q({\mathbb{R}}^n)$ and $r < \infty$, I have to prove that $$ {|(f*g)(x)|}^r \leq {\|f\|}_p^{r - p} {\|g\|}_q^{r - q} \int_{{\mathbb{R}}^n} {|f(y)|}^p {|g(x - y)|}^q dy $$ and my indication is to use Hölder inequality for three functions; my intuition sais that $f$ and $g$ are two of that functions but I have to obtain the third. Can you help me with this problem please? Thank you very much.",,"['real-analysis', 'functional-analysis', 'convolution']"
30,types of distances between points,types of distances between points,,"I was just finished working on a project where we had to allocate facilities in a $2$-dimensional plane in order to satisfy certain demand restrictions while keeping the cost at minimum. I do NOT have a degree in mathematics so my apologies if my question may seem a little dumb and uneducated. We worked with cartesian coordinates and a distance function $$d:\mathbb{R}^2 \times \mathbb{R}^2 \to \mathbb{R}$$ with the distance between $(x_1,y_1)$ and $(x_2,y_2)$ given by $\sqrt{(x_1-x_2)^2+(y_1-y_2)^2}$. In the assignment it was specifically stated that we used the euclidean distance that I started asking myself: what other types of distances measurements could we use, I mean, like absolute deviation? This brings my to my question: What other primary distance measure(s) exist(s) and what are possible applications of these? I am curious to seewhat you guys can bring me!","I was just finished working on a project where we had to allocate facilities in a $2$-dimensional plane in order to satisfy certain demand restrictions while keeping the cost at minimum. I do NOT have a degree in mathematics so my apologies if my question may seem a little dumb and uneducated. We worked with cartesian coordinates and a distance function $$d:\mathbb{R}^2 \times \mathbb{R}^2 \to \mathbb{R}$$ with the distance between $(x_1,y_1)$ and $(x_2,y_2)$ given by $\sqrt{(x_1-x_2)^2+(y_1-y_2)^2}$. In the assignment it was specifically stated that we used the euclidean distance that I started asking myself: what other types of distances measurements could we use, I mean, like absolute deviation? This brings my to my question: What other primary distance measure(s) exist(s) and what are possible applications of these? I am curious to seewhat you guys can bring me!",,"['geometry', 'functional-analysis']"
31,Can Evans's proof for the theorem regarding global approximation of Sobolev functions be significantly simplified?,Can Evans's proof for the theorem regarding global approximation of Sobolev functions be significantly simplified?,,"Here $U$ is an open subset of $\mathbb{R}^n$. Above is a theorem regarding approximation of Sobolev functions in Evans's Partial Differential Equations. When I tried to the recover the proof on my own, I found that the proof might be much shorter than the one in the book. But it looks too simple to be true and I'm wondering if there is a big gap there. Here is my argument. Suppose $u\in W^{k,p}(U)$. Then $u\in L^p(U)$ by definition and thus $u\in L^1(U)$ since $U$ is bounded. Now according to the answer and comments to the following questions: convolutions and mollification of functions in $L^1_{\text{loc}}(\Omega)$ Properties of mollification for integrable functions one can define the mollification $u^\epsilon=\eta_\epsilon*u$ on $U$ such that $u_\epsilon\in C^\infty(U)$. Moreover, since  $$ D^\alpha u^\epsilon=\eta_\epsilon*D^\alpha u \quad\textrm{in  } U,  $$ one has  $$ \|u^\epsilon-u\|_{W^{k,p}(U)}^p=\sum \|D^\alpha u^\epsilon-D^\alpha u\|_{L^p(U)}^p\to 0. $$ Could anyone identify if there is any serious mistake in the above argument? [ Added :]A possible naive analogy I make in the above argument is as the following. First of all, I have the following facts $D^\alpha u^\epsilon=\eta_\epsilon*D^\alpha$ in $\color{blue}{U_\epsilon}$, where the definition can be seen in the linked question. Also, $D^\alpha u^\epsilon\to D^\alpha u$ in $L^p(V)$ for any $V\Subset U$. Now that I can do mollification on the entire domain $U$ instead of just $U_\epsilon$, I just guess one might have $D^\alpha u^\epsilon=\eta_\epsilon*D^\alpha u$ in $\color{blue}{U}$. and $D^\alpha u^\epsilon\to D^\alpha u$ in $L^p(U)$. For the original ""long"" proof of THEOREM 2 by Evans, see this question .","Here $U$ is an open subset of $\mathbb{R}^n$. Above is a theorem regarding approximation of Sobolev functions in Evans's Partial Differential Equations. When I tried to the recover the proof on my own, I found that the proof might be much shorter than the one in the book. But it looks too simple to be true and I'm wondering if there is a big gap there. Here is my argument. Suppose $u\in W^{k,p}(U)$. Then $u\in L^p(U)$ by definition and thus $u\in L^1(U)$ since $U$ is bounded. Now according to the answer and comments to the following questions: convolutions and mollification of functions in $L^1_{\text{loc}}(\Omega)$ Properties of mollification for integrable functions one can define the mollification $u^\epsilon=\eta_\epsilon*u$ on $U$ such that $u_\epsilon\in C^\infty(U)$. Moreover, since  $$ D^\alpha u^\epsilon=\eta_\epsilon*D^\alpha u \quad\textrm{in  } U,  $$ one has  $$ \|u^\epsilon-u\|_{W^{k,p}(U)}^p=\sum \|D^\alpha u^\epsilon-D^\alpha u\|_{L^p(U)}^p\to 0. $$ Could anyone identify if there is any serious mistake in the above argument? [ Added :]A possible naive analogy I make in the above argument is as the following. First of all, I have the following facts $D^\alpha u^\epsilon=\eta_\epsilon*D^\alpha$ in $\color{blue}{U_\epsilon}$, where the definition can be seen in the linked question. Also, $D^\alpha u^\epsilon\to D^\alpha u$ in $L^p(V)$ for any $V\Subset U$. Now that I can do mollification on the entire domain $U$ instead of just $U_\epsilon$, I just guess one might have $D^\alpha u^\epsilon=\eta_\epsilon*D^\alpha u$ in $\color{blue}{U}$. and $D^\alpha u^\epsilon\to D^\alpha u$ in $L^p(U)$. For the original ""long"" proof of THEOREM 2 by Evans, see this question .",,['functional-analysis']
32,Proof that $\|fx\| \leq \|f\|\cdot\|x\|$,Proof that,\|fx\| \leq \|f\|\cdot\|x\|,"From the wiki article on the dual of a norm: $X$ and $Y$ are normed spaces, and we associate with each $f\in L(X,Y)$ (the space of bounded linear operators from $X$ to $Y$) the number $$\|f\| = \sup\{|f(x)|:x\in X, \|x\| \leq 1\}.$$ At some point in the proof that $L(X,Y)$ is bounded, it seems like they use the inequality $$\|fx\| \leq \|f\|\cdot\|x\|,$$ where $\|x\|\leq 1$. I can't see why this should holds. $\|f|\|$ is the supremum of what $|f(x)|$ can be, given that $\|x\|\leq 1$. So, given that $\|x\| \leq 1$, $|fx|$ should be bounded by $\|f\|$. But why should it be bounded by $\|f\|\cdot\|x\|$?","From the wiki article on the dual of a norm: $X$ and $Y$ are normed spaces, and we associate with each $f\in L(X,Y)$ (the space of bounded linear operators from $X$ to $Y$) the number $$\|f\| = \sup\{|f(x)|:x\in X, \|x\| \leq 1\}.$$ At some point in the proof that $L(X,Y)$ is bounded, it seems like they use the inequality $$\|fx\| \leq \|f\|\cdot\|x\|,$$ where $\|x\|\leq 1$. I can't see why this should holds. $\|f|\|$ is the supremum of what $|f(x)|$ can be, given that $\|x\|\leq 1$. So, given that $\|x\| \leq 1$, $|fx|$ should be bounded by $\|f\|$. But why should it be bounded by $\|f\|\cdot\|x\|$?",,"['functional-analysis', 'linear-transformations', 'normed-spaces']"
33,Convergence of Riemannian metric tensor implies convergence of induced distance functions,Convergence of Riemannian metric tensor implies convergence of induced distance functions,,"The general question is the following: Suppose one has on a smooth compact manifold $M$ a family of Riemannian metrics $g_t=(g_{ij}^t)$, with every function $g^t_{ij}\colon U\subset M \to \mathbb{R}$ converging uniformly to some function $g_{ij}$, so that $g = (g_{ij})$ is a Riemannian metric. Does the distance functions $d_t(x,y) = \inf\{\text{len}(\gamma)\mid \gamma \text{ curve that connects } x \text{ to } y\}$, induced by the metrics $g_t$,  converge pointwise to the distance function $d(x,y)$ induced by the metric $g$? In particular I am thinking of surfaces $S_t$ with metrics of the form $ds^2= dx^2+G_t(x)^2dy^2$.","The general question is the following: Suppose one has on a smooth compact manifold $M$ a family of Riemannian metrics $g_t=(g_{ij}^t)$, with every function $g^t_{ij}\colon U\subset M \to \mathbb{R}$ converging uniformly to some function $g_{ij}$, so that $g = (g_{ij})$ is a Riemannian metric. Does the distance functions $d_t(x,y) = \inf\{\text{len}(\gamma)\mid \gamma \text{ curve that connects } x \text{ to } y\}$, induced by the metrics $g_t$,  converge pointwise to the distance function $d(x,y)$ induced by the metric $g$? In particular I am thinking of surfaces $S_t$ with metrics of the form $ds^2= dx^2+G_t(x)^2dy^2$.",,"['functional-analysis', 'differential-geometry', 'metric-spaces']"
34,Interesting Open Questions In Wavelet Theory for UG Research?,Interesting Open Questions In Wavelet Theory for UG Research?,,"Just as background, I am going into my senior year of undergrad and I have a pretty light load this coming semester but I want to fill this time with something that will really make my grad school resume sparkle. As you might guess from my username, I am fascinated by wavelets (and harmonic analysis in general) and I have decided to try to at least attempt some research over the next year to close out my UG studies. I spoke with a professor about this and he said he'd be more than happy to help me as much as he can and get me credit for it but I'd need to come up with the topic and expect to do the vast majority of it on my own (I actually prefer working more independently). Anyways, I have been trying to find a problem that interests me enough that I can see myself working on 5-6 hours a day but I haven't had any luck. While I feel confident in my knowledge of wavelet theory, I don't really know which way is up when it comes to the actual research end of things. I know the major players like Daubechies, Mallat, Morlet, etc. but I am having a hard time figuring out what constitutes ""cutting edge"". Obviously, I expect that any research is going to be more on the applied end of things but I'd prefer it to be as ""pure"" (i.e. not computational) as possible just because I am limited in how much computing power I have access to (I've had my computer crash many many times from trying to do wavelet projects in MATLAB) and I am skeptical that the department will let me anywhere near the big guns. My knowledge base is sufficient that I can understand most of Mallat's ""A Wavelet Tour of Signal Processing: The Sparse Way"", though I find it to be quite a slog just because of the notation and lay out. I am particularly interested in some potential interplay between stochastic processes (sufficiently nice ones at least) and wavelet analysis. I do not have a great background in stochastic integration quite yet but I learn fast enough that I feel confident it wouldn't pose too much of barrier. I would be indebted to anyone who could point me in the right direction.","Just as background, I am going into my senior year of undergrad and I have a pretty light load this coming semester but I want to fill this time with something that will really make my grad school resume sparkle. As you might guess from my username, I am fascinated by wavelets (and harmonic analysis in general) and I have decided to try to at least attempt some research over the next year to close out my UG studies. I spoke with a professor about this and he said he'd be more than happy to help me as much as he can and get me credit for it but I'd need to come up with the topic and expect to do the vast majority of it on my own (I actually prefer working more independently). Anyways, I have been trying to find a problem that interests me enough that I can see myself working on 5-6 hours a day but I haven't had any luck. While I feel confident in my knowledge of wavelet theory, I don't really know which way is up when it comes to the actual research end of things. I know the major players like Daubechies, Mallat, Morlet, etc. but I am having a hard time figuring out what constitutes ""cutting edge"". Obviously, I expect that any research is going to be more on the applied end of things but I'd prefer it to be as ""pure"" (i.e. not computational) as possible just because I am limited in how much computing power I have access to (I've had my computer crash many many times from trying to do wavelet projects in MATLAB) and I am skeptical that the department will let me anywhere near the big guns. My knowledge base is sufficient that I can understand most of Mallat's ""A Wavelet Tour of Signal Processing: The Sparse Way"", though I find it to be quite a slog just because of the notation and lay out. I am particularly interested in some potential interplay between stochastic processes (sufficiently nice ones at least) and wavelet analysis. I do not have a great background in stochastic integration quite yet but I learn fast enough that I feel confident it wouldn't pose too much of barrier. I would be indebted to anyone who could point me in the right direction.",,"['functional-analysis', 'stochastic-processes', 'fourier-analysis', 'harmonic-analysis', 'wavelets']"
35,Fréchet Topology on $C^\infty(M)$,Fréchet Topology on,C^\infty(M),"In the Fréchet space wikipedia article , in the ""Examples"" section, it is stated that the space of smooth functions $C^\infty(M)$ on a compact smooth manifold $M$ can be made into a Fréchet space ""by using as seminorms the suprema of the norms of all partial derivatives"". However since of course $M$ need not admit a single coordinate chart, what is meant by ""partial derivatives""? I.e. what exactly is this countable family of seminorms on $C^{\infty}(M)$? I'm sorry if this is super standard (it seems like it should be!), but my preliminary Google searches were quite unsuccessful.","In the Fréchet space wikipedia article , in the ""Examples"" section, it is stated that the space of smooth functions $C^\infty(M)$ on a compact smooth manifold $M$ can be made into a Fréchet space ""by using as seminorms the suprema of the norms of all partial derivatives"". However since of course $M$ need not admit a single coordinate chart, what is meant by ""partial derivatives""? I.e. what exactly is this countable family of seminorms on $C^{\infty}(M)$? I'm sorry if this is super standard (it seems like it should be!), but my preliminary Google searches were quite unsuccessful.",,"['functional-analysis', 'differential-geometry', 'smooth-manifolds']"
36,infimum in inequalities,infimum in inequalities,,"I am just starting on analysis and I have a question about the concept of infimum: Consider this scenario: Theres is metric space (X,d) and a set $A \subseteq X$, hence for any $x,y \in X$ and $a\in A$ $ d(x,a) \leq d(x,y) +d(y,a) \; \forall a \in A$ .... this is true since d() is a valid metric. Now can I justify the following statement: $\inf_{a\in A} d(x,a) \leq d(x,y) + \inf_{a \in A} d(y,a)$ Basically $ d(x,A) \leq d(x,y) + d(y,A) $? Is is it OK to take the infimum on both sides of the inequality? How to argue that doing so is right? the '$a\in A$' which minimises (weakly speaking here) d(x,a) need not be the same '$a\in A$' which minimises d(y,a)? P.S: This question is in the backdrop of proving that the function d(x,A) is continuous","I am just starting on analysis and I have a question about the concept of infimum: Consider this scenario: Theres is metric space (X,d) and a set $A \subseteq X$, hence for any $x,y \in X$ and $a\in A$ $ d(x,a) \leq d(x,y) +d(y,a) \; \forall a \in A$ .... this is true since d() is a valid metric. Now can I justify the following statement: $\inf_{a\in A} d(x,a) \leq d(x,y) + \inf_{a \in A} d(y,a)$ Basically $ d(x,A) \leq d(x,y) + d(y,A) $? Is is it OK to take the infimum on both sides of the inequality? How to argue that doing so is right? the '$a\in A$' which minimises (weakly speaking here) d(x,a) need not be the same '$a\in A$' which minimises d(y,a)? P.S: This question is in the backdrop of proving that the function d(x,A) is continuous",,"['real-analysis', 'functional-analysis']"
37,Computing norms in quotient space $l_\infty/c_0$,Computing norms in quotient space,l_\infty/c_0,"Let $E$ be a Banach space and $F \subset E$ a closed subspace. We define $[x]=\{x+u: u \in F\}$ and $E/F = \{[x]: x \in E\}$ The norm on $E/F$ is given by: $$ \|[x]\| =\inf\limits_{u \in F} ||x+u||.$$ Now, let $E = l_\infty$ and $F = c_0$. I need to compute $\|[x]\|$ for $x = (1,1,1, \cdots )$ . My attempt: Let $(\xi_i)_{i \in \mathbb{N}}\in c_0$ and $n \in \mathbb{N}$. Since $\xi_i \rightarrow 0$, there exists $n_0$ such that $|\xi_i|<\frac{1}{n}$ ,$ \forall i \geq n_0.$ We have: $$||(1+\xi_1, 1+\xi_2, \cdots)||_\infty =\sup\limits_{i \in \mathbb{N}} |1+ \xi_i| \geq |1+ \xi_{n_0}|  \geq |1- |\xi_{n_0}|| = 1- |\xi_{n_0}| \geq 1-\frac{1}{n}$$ Since $n$ and $(\xi_i)_{i \in \mathbb{N}}\in c_0$ were arbitrary: $$||(1+\xi_1, 1+\xi_2, \cdots)||_\infty \geq 1, \forall (\xi_i)_{i \in \mathbb{N}}\in c_0$$ Thus: $$\|[x]\|=  \inf\limits_{(\xi_i) \in c_0} ||(1,1,\cdots) + (\xi_1, \xi_2, \cdots)||_\infty = \inf\limits_{(\xi_i) \in c_0} ||(1+\xi_1, 1+\xi_2, \cdots)||_\infty \geq 1$$ If $(\xi_i)_{i \in \mathbb{N}} = 0 \in c_0$, we have $||(1+\xi_1, 1+\xi_2, \cdots)||_\infty =1$. Hence $\|[x]\| = 1$. Am I right?","Let $E$ be a Banach space and $F \subset E$ a closed subspace. We define $[x]=\{x+u: u \in F\}$ and $E/F = \{[x]: x \in E\}$ The norm on $E/F$ is given by: $$ \|[x]\| =\inf\limits_{u \in F} ||x+u||.$$ Now, let $E = l_\infty$ and $F = c_0$. I need to compute $\|[x]\|$ for $x = (1,1,1, \cdots )$ . My attempt: Let $(\xi_i)_{i \in \mathbb{N}}\in c_0$ and $n \in \mathbb{N}$. Since $\xi_i \rightarrow 0$, there exists $n_0$ such that $|\xi_i|<\frac{1}{n}$ ,$ \forall i \geq n_0.$ We have: $$||(1+\xi_1, 1+\xi_2, \cdots)||_\infty =\sup\limits_{i \in \mathbb{N}} |1+ \xi_i| \geq |1+ \xi_{n_0}|  \geq |1- |\xi_{n_0}|| = 1- |\xi_{n_0}| \geq 1-\frac{1}{n}$$ Since $n$ and $(\xi_i)_{i \in \mathbb{N}}\in c_0$ were arbitrary: $$||(1+\xi_1, 1+\xi_2, \cdots)||_\infty \geq 1, \forall (\xi_i)_{i \in \mathbb{N}}\in c_0$$ Thus: $$\|[x]\|=  \inf\limits_{(\xi_i) \in c_0} ||(1,1,\cdots) + (\xi_1, \xi_2, \cdots)||_\infty = \inf\limits_{(\xi_i) \in c_0} ||(1+\xi_1, 1+\xi_2, \cdots)||_\infty \geq 1$$ If $(\xi_i)_{i \in \mathbb{N}} = 0 \in c_0$, we have $||(1+\xi_1, 1+\xi_2, \cdots)||_\infty =1$. Hence $\|[x]\| = 1$. Am I right?",,"['functional-analysis', 'proof-verification']"
38,Is the square root function norm continuous?,Is the square root function norm continuous?,,"Let $\{a_n\}$ be a  sequence of positive operators in $B(H)$. What about the following implication, True or false? $$||a_n-a||\to 0\Longrightarrow ||a_n^{\frac{1}{2}}-a^{\frac{1}{2}}||\to0$$","Let $\{a_n\}$ be a  sequence of positive operators in $B(H)$. What about the following implication, True or false? $$||a_n-a||\to 0\Longrightarrow ||a_n^{\frac{1}{2}}-a^{\frac{1}{2}}||\to0$$",,"['functional-analysis', 'c-star-algebras']"
39,Do projections preserve closed subspaces,Do projections preserve closed subspaces,,Let $H$ be a Hilbert space and let $\pi \colon H \to H$ be an orthogonal projection. Let $E \subset H$ be a closed subspace of $H$. My question: Is there any hope that one can conclude that $\pi(E)$ is closed?,Let $H$ be a Hilbert space and let $\pi \colon H \to H$ be an orthogonal projection. Let $E \subset H$ be a closed subspace of $H$. My question: Is there any hope that one can conclude that $\pi(E)$ is closed?,,['functional-analysis']
40,Is it possible to have $g\colon\Omega\to\Bbb C$ which defines an unbounded functional?,Is it possible to have  which defines an unbounded functional?,g\colon\Omega\to\Bbb C,"Let $\Omega$ be an infinite space with a nontrivial measure $\mu$. We define $L^p$ spaces as usual, then for $1<p<\infty$ if $\frac1p+\frac1q=1$, then $(L^p)^*=L^q$. This is all pretty much a classical theorem. Fix $1<p<\infty$ for the discussion. Suppose $g\colon\Omega\to\Bbb C$ is a function such that for every $f\in L^p$, the pointwise multiplication $gf\in L^1$. Is it necessarily the case that $g\in L^q$? It is not hard to show that $f\mapsto\int_\Omega fg\ d\mu$ is a linear functional. So $g\in L^q$ if and only if this functional is continuous. It is even not hard to show that if $g$ is measurable and $\mu$ is $\sigma$-finite then $g\in L^q$. Is it possible to have $g\notin L^q$ such that for every $f\in L^p$, $gf\in L^1$? Why is this difficult? It is consistent with $\sf ZF+DC$ that every linear functional on a Banach space is continuous. In such case $g$ has to be in $L^q$, since the functional is indeed continuous. This means that if there is a counterexample it has to involve the axiom of choice. We can even point further that such example has to involve sets without the Baire property since if every set of reals (equiv. complex numbers) has the Baire property, then every linear functional on a Banach space is continuous.","Let $\Omega$ be an infinite space with a nontrivial measure $\mu$. We define $L^p$ spaces as usual, then for $1<p<\infty$ if $\frac1p+\frac1q=1$, then $(L^p)^*=L^q$. This is all pretty much a classical theorem. Fix $1<p<\infty$ for the discussion. Suppose $g\colon\Omega\to\Bbb C$ is a function such that for every $f\in L^p$, the pointwise multiplication $gf\in L^1$. Is it necessarily the case that $g\in L^q$? It is not hard to show that $f\mapsto\int_\Omega fg\ d\mu$ is a linear functional. So $g\in L^q$ if and only if this functional is continuous. It is even not hard to show that if $g$ is measurable and $\mu$ is $\sigma$-finite then $g\in L^q$. Is it possible to have $g\notin L^q$ such that for every $f\in L^p$, $gf\in L^1$? Why is this difficult? It is consistent with $\sf ZF+DC$ that every linear functional on a Banach space is continuous. In such case $g$ has to be in $L^q$, since the functional is indeed continuous. This means that if there is a counterexample it has to involve the axiom of choice. We can even point further that such example has to involve sets without the Baire property since if every set of reals (equiv. complex numbers) has the Baire property, then every linear functional on a Banach space is continuous.",,"['functional-analysis', 'lp-spaces']"
41,Heat equation - regularity of solutions,Heat equation - regularity of solutions,,"Consider the heat equation on $\mathbb{R}$ $$ u_t=u_{xx} $$ with boundary conditions $u(0,x)=g(x)$. It is well-known that even if the function $g$ is ""very bad'' (say, only bounded but not continuous), the function $u(t,\cdot)$ would be from class $C^{\infty}$even for very small $t$. My question is whether it is possible to quantify this estimate. Namely, assuming that $g\in C^\gamma$ for $\gamma\in(0,1)$, I wonder whether one can prove something like this $$ \|u(t,\cdot)\|_{C^1}\le t^{-\lambda}\|g\|_{C^\gamma} $$  for some $\lambda>0$? Thanks!","Consider the heat equation on $\mathbb{R}$ $$ u_t=u_{xx} $$ with boundary conditions $u(0,x)=g(x)$. It is well-known that even if the function $g$ is ""very bad'' (say, only bounded but not continuous), the function $u(t,\cdot)$ would be from class $C^{\infty}$even for very small $t$. My question is whether it is possible to quantify this estimate. Namely, assuming that $g\in C^\gamma$ for $\gamma\in(0,1)$, I wonder whether one can prove something like this $$ \|u(t,\cdot)\|_{C^1}\le t^{-\lambda}\|g\|_{C^\gamma} $$  for some $\lambda>0$? Thanks!",,"['functional-analysis', 'partial-differential-equations', 'heat-equation']"
42,Geometric interpretation of monotone operators on a Hilbert space,Geometric interpretation of monotone operators on a Hilbert space,,"Recall that a monotone operator is defined by the relationship as follows: $$\langle y - x, F(y) - F(x)\rangle \geq 0, \quad \forall x,y \in X$$  ($X$ is a Hilbert space) What is a good geometric interpretation of this relationship? Obviously we could say that $y - x$ and $F(y) - F(x)$ maintains a less than $90$ deg angle, but can we say more about that? Does $\langle y - x, F(y) - F(x)\rangle \leq 0$ also define a monotone operator? Notice we cannot just pull out negative signs in the original inequality and reverse the sign this way.","Recall that a monotone operator is defined by the relationship as follows: $$\langle y - x, F(y) - F(x)\rangle \geq 0, \quad \forall x,y \in X$$  ($X$ is a Hilbert space) What is a good geometric interpretation of this relationship? Obviously we could say that $y - x$ and $F(y) - F(x)$ maintains a less than $90$ deg angle, but can we say more about that? Does $\langle y - x, F(y) - F(x)\rangle \leq 0$ also define a monotone operator? Notice we cannot just pull out negative signs in the original inequality and reverse the sign this way.",,"['functional-analysis', 'convex-analysis', 'hilbert-spaces', 'intuition', 'monotone-operator-theory']"
43,$L^{1}$ Boundedness of Hilbert Transform on $\left\{f\in L^{1}(\mathbb{R}) : \int_{\mathbb{R}}f=0\right\}$,Boundedness of Hilbert Transform on,L^{1} \left\{f\in L^{1}(\mathbb{R}) : \int_{\mathbb{R}}f=0\right\},"It is well-known that the Hilbert transform $H(f)$ of a bounded, compactly supported function $f:\mathbb{R}\rightarrow\mathbb{C}$ belongs to $L^{1}(\mathbb{R})$ precisely when $\int f=0$. One can relax the boundedness assumption to $f\in L^{p}$, for $p>1$, or even $L\log L$. More generally, we only have a hope that the Hilbert transform $H(f)$ of an integrable function $f$, not necessarily compactly supported, is itself integrable if $\int f=0$. Problem. I am quite confident that it is true that we have the proper containment $$H^{1}(\mathbb{R}):=\left\{f\in L^{1}(\mathbb{R}) : H(f)\in L^{1}(\mathbb{R})\right\}\subsetneq\left\{f\in L^{1}(\mathbb{R}) : \int_{\mathbb{R}}f=0\right\}$$ however, I am struggling to produce an example proving the properness   of the containment. Can someone help me with such an example? My motivation for this question is understanding how close the real Hardy space $\mathbb{R}^{n}$ is to integrable functions which have good cancellation (see also this question ). In one dimension, an equivalent characterization of the Hardy space $H^{1}(\mathbb{R})$ is $L^{1}$ functions with $L^{1}$ bounded Hilbert transforms and in fact, $\left\|f\right\|_{L^{1}}+\left\|Hf\right\|_{L^{1}}$ defines an equivalent norm. In higher dimensions, the analogue of this equivalence is $L^{1}$ boundedness of the Riesz transforms.","It is well-known that the Hilbert transform $H(f)$ of a bounded, compactly supported function $f:\mathbb{R}\rightarrow\mathbb{C}$ belongs to $L^{1}(\mathbb{R})$ precisely when $\int f=0$. One can relax the boundedness assumption to $f\in L^{p}$, for $p>1$, or even $L\log L$. More generally, we only have a hope that the Hilbert transform $H(f)$ of an integrable function $f$, not necessarily compactly supported, is itself integrable if $\int f=0$. Problem. I am quite confident that it is true that we have the proper containment $$H^{1}(\mathbb{R}):=\left\{f\in L^{1}(\mathbb{R}) : H(f)\in L^{1}(\mathbb{R})\right\}\subsetneq\left\{f\in L^{1}(\mathbb{R}) : \int_{\mathbb{R}}f=0\right\}$$ however, I am struggling to produce an example proving the properness   of the containment. Can someone help me with such an example? My motivation for this question is understanding how close the real Hardy space $\mathbb{R}^{n}$ is to integrable functions which have good cancellation (see also this question ). In one dimension, an equivalent characterization of the Hardy space $H^{1}(\mathbb{R})$ is $L^{1}$ functions with $L^{1}$ bounded Hilbert transforms and in fact, $\left\|f\right\|_{L^{1}}+\left\|Hf\right\|_{L^{1}}$ defines an equivalent norm. In higher dimensions, the analogue of this equivalence is $L^{1}$ boundedness of the Riesz transforms.",,"['real-analysis', 'functional-analysis', 'fourier-analysis', 'harmonic-analysis', 'hardy-spaces']"
44,Is the function characterized by $f(\alpha x+(1-\alpha) y) \le f^{\alpha}(x/\alpha)f^{1-\alpha}(y)$ convex?,Is the function characterized by  convex?,f(\alpha x+(1-\alpha) y) \le f^{\alpha}(x/\alpha)f^{1-\alpha}(y),"[Edit. The question lacks certain important conditions, as kindly pointed out by NeutralElement .  Below is the amended version.  I apologize for the omissions and many thanks to NeutralElement and user254665 for helpful comments. ] This is related to the question raised by Boby .  For a variant, consider the nonnegative function $f(x)$ satisfied by $$ f(\alpha\, x + (1 - \alpha) \, y) \le f^{\alpha}(x/\alpha) \, f^{1-\alpha}(y), \qquad (1) $$ for $\alpha \in (0, 1]$ and real $x$ and $y$. What can we say about his function?  Is it always convex? [Edit2.  In the original question by Boby, there is one additional condition that requires that $x \ge y$.  But unfortunately I missed this condition in the previous edit.  So I'll settle for the result for the above question.  I apologize for the many omissions.  However, if anyone can comment how this condition changes the result, it would be much appreciated.  Thank you.] Here are some observations that may or may not help. Observation 1 With $y = x$, we have $$ f(x) \le f(x/\alpha).  \qquad (2) $$ This means that $f(x)$ is increasing for $x \ge 0$, and decreasing for $x \le 0$.  A corollary is that $f(0)$ is the global minimum, i.e, $$ f(0) \le f(x). \qquad (3) $$ Observation 2 By Young's inequality or the weighted AM-GM inequality , we have $$ f^\alpha(x/\alpha) f^{1-\alpha}(y) \le \alpha f(x/\alpha) + (1 - \alpha) f(y). \qquad (4) $$ Thus, (4) and (1) require $$ f(y + \alpha (x - y)) \le \alpha \, f(x/\alpha) + (1 - \alpha) \, f(y). $$","[Edit. The question lacks certain important conditions, as kindly pointed out by NeutralElement .  Below is the amended version.  I apologize for the omissions and many thanks to NeutralElement and user254665 for helpful comments. ] This is related to the question raised by Boby .  For a variant, consider the nonnegative function $f(x)$ satisfied by $$ f(\alpha\, x + (1 - \alpha) \, y) \le f^{\alpha}(x/\alpha) \, f^{1-\alpha}(y), \qquad (1) $$ for $\alpha \in (0, 1]$ and real $x$ and $y$. What can we say about his function?  Is it always convex? [Edit2.  In the original question by Boby, there is one additional condition that requires that $x \ge y$.  But unfortunately I missed this condition in the previous edit.  So I'll settle for the result for the above question.  I apologize for the many omissions.  However, if anyone can comment how this condition changes the result, it would be much appreciated.  Thank you.] Here are some observations that may or may not help. Observation 1 With $y = x$, we have $$ f(x) \le f(x/\alpha).  \qquad (2) $$ This means that $f(x)$ is increasing for $x \ge 0$, and decreasing for $x \le 0$.  A corollary is that $f(0)$ is the global minimum, i.e, $$ f(0) \le f(x). \qquad (3) $$ Observation 2 By Young's inequality or the weighted AM-GM inequality , we have $$ f^\alpha(x/\alpha) f^{1-\alpha}(y) \le \alpha f(x/\alpha) + (1 - \alpha) f(y). \qquad (4) $$ Thus, (4) and (1) require $$ f(y + \alpha (x - y)) \le \alpha \, f(x/\alpha) + (1 - \alpha) \, f(y). $$",,"['functional-analysis', 'convex-analysis', 'functional-inequalities']"
45,Spectral theorem for momentum operator,Spectral theorem for momentum operator,,"I'm trying to apply the spectral theorem to the explicit example of the momentum operator: \begin{equation} p:= i\frac{d}{dx} \end{equation} on the domain $D=\{\psi\in H^1(0,2\pi)\ |\ \psi(0)=\psi(2\pi)\}$. Then p is self-adjoint, and its spectrum is given by the integers. Now, given a $\psi$ in the domain, it holds by the spectral theorem \begin{equation} <\psi\ |\ p[\psi]> = \int_{\mathbb Z}^{}n\ d\mu_\psi(n) \end{equation} In order to explicitly obtain $\mu_{\psi}$, one should apply Stieltjes' inversion formula to the function \begin{equation} \mathcal{F}_\psi:\ z \longmapsto <\psi,\ (p-z)^{-1}[\psi]>, \ z\in\mathbb C \end{equation} Namely, the task is to compute the following resolution of identity: \begin{equation} \mu_\psi(\lambda) = \lim_{\delta\to 0^+} \lim_{\varepsilon\to 0^+} \frac{1}{\pi} \int_{-\infty}^{\lambda + \delta}Im[\mathcal{F}_\psi (t+i\varepsilon)]dt \end{equation} The most natural thing to do would seem to be using Fourier Series. This has however proved unuseful. One gets: \begin{equation} \mathcal{F}_\psi(z) = \int_0^{2\pi}\sum_{k\in\mathbb Z}\frac{|c_k|^2}{k+z}\exp{[ikx]}dx \end{equation} where $\psi(x) = \sum_{k\in \mathbb Z}c_k\exp{[ikx]}$. I'm not getting anywhere with this: the series keeps hanging around, and there are integrals over the whole half-line of sines and cosines. Any hint would be greatly appreciated! Edit 1 : I tried digging deeper into the rabbit hole: switching series and integral in the last equation kills every k-term but $k=0$. The computation of $\mu_\psi(\lambda)$ is then doable, at the least with the help of Mathematica.\newline Unfortunately, the computation yields \begin{equation} \mu_\psi(\lambda) = \frac{\lambda + |{\lambda}|}{2\lambda}||{\psi}||^2 \end{equation} i.e. a delta measure centered at zero. This would mean \begin{equation} <\psi\ |\ p[\psi]> = \int_{\mathbb Z}^{}n\ d\delta_0(n) = 0 \end{equation} so that the problem is still not solved. By the way, I also realized that Fourier Series are really the answer to my question. ""Reverse engineering"" is then maybe possible. Edit 2 : I put some more thought into the problem, and I think I solved it. I'd still like to receive a confirm. Apparently, the equation \begin{equation} \mathcal{F}_\psi(z) = \int_0^{2\pi}\sum_{k\in\mathbb Z}\frac{|c_k|^2}{k+z}\exp{[ikx]}dx \end{equation} is wrong. The right computation implies a Kronecker Delta and yields just \begin{equation} \mathcal{F}_\psi(z) = \sum_{k\in\mathbb Z}\frac{|c_k|^2}{k+z} \end{equation} Now everything gets easier. One can compute $\mu_\psi(\lambda)$ explicitly, and the result is \begin{equation} \mu_\psi(\lambda) = \sum_{k\in\mathbb Z}|c_k|^2\frac{k+\lambda + |{k+\lambda}|}{2(k+\lambda)} = \sum_{k\in\mathbb Z}|c_k|^2\chi_{[-\lambda, +\infty)} \end{equation} The resulting measure is some kind of counting measure, characterized by \begin{equation} \mu_\psi(\{n\}) = \mu_\psi(n)-\mu_\psi(n-1) = |c_n|^2,\ \forall n\in\mathbb Z \end{equation} So that \begin{equation} <\psi\ |\ p[\psi]> = \int_{\mathbb Z}^{}n\ d\mu_\psi(n) = \sum_{n\in\mathbb Z}n|c_n|^2 \end{equation} Which is exactly the result one gets applying the Fourier Series theory. From here it's also possible to see \begin{equation} p[\cdot] = \sum_{n\in\mathbb Z}n\Big[\int_0^{2\pi}\cdot(x)e^{-inx}dx\Big]e^{inx} \end{equation} which also agrees with the FS theory. I hope this is at least useful for the internet wanderers...","I'm trying to apply the spectral theorem to the explicit example of the momentum operator: \begin{equation} p:= i\frac{d}{dx} \end{equation} on the domain $D=\{\psi\in H^1(0,2\pi)\ |\ \psi(0)=\psi(2\pi)\}$. Then p is self-adjoint, and its spectrum is given by the integers. Now, given a $\psi$ in the domain, it holds by the spectral theorem \begin{equation} <\psi\ |\ p[\psi]> = \int_{\mathbb Z}^{}n\ d\mu_\psi(n) \end{equation} In order to explicitly obtain $\mu_{\psi}$, one should apply Stieltjes' inversion formula to the function \begin{equation} \mathcal{F}_\psi:\ z \longmapsto <\psi,\ (p-z)^{-1}[\psi]>, \ z\in\mathbb C \end{equation} Namely, the task is to compute the following resolution of identity: \begin{equation} \mu_\psi(\lambda) = \lim_{\delta\to 0^+} \lim_{\varepsilon\to 0^+} \frac{1}{\pi} \int_{-\infty}^{\lambda + \delta}Im[\mathcal{F}_\psi (t+i\varepsilon)]dt \end{equation} The most natural thing to do would seem to be using Fourier Series. This has however proved unuseful. One gets: \begin{equation} \mathcal{F}_\psi(z) = \int_0^{2\pi}\sum_{k\in\mathbb Z}\frac{|c_k|^2}{k+z}\exp{[ikx]}dx \end{equation} where $\psi(x) = \sum_{k\in \mathbb Z}c_k\exp{[ikx]}$. I'm not getting anywhere with this: the series keeps hanging around, and there are integrals over the whole half-line of sines and cosines. Any hint would be greatly appreciated! Edit 1 : I tried digging deeper into the rabbit hole: switching series and integral in the last equation kills every k-term but $k=0$. The computation of $\mu_\psi(\lambda)$ is then doable, at the least with the help of Mathematica.\newline Unfortunately, the computation yields \begin{equation} \mu_\psi(\lambda) = \frac{\lambda + |{\lambda}|}{2\lambda}||{\psi}||^2 \end{equation} i.e. a delta measure centered at zero. This would mean \begin{equation} <\psi\ |\ p[\psi]> = \int_{\mathbb Z}^{}n\ d\delta_0(n) = 0 \end{equation} so that the problem is still not solved. By the way, I also realized that Fourier Series are really the answer to my question. ""Reverse engineering"" is then maybe possible. Edit 2 : I put some more thought into the problem, and I think I solved it. I'd still like to receive a confirm. Apparently, the equation \begin{equation} \mathcal{F}_\psi(z) = \int_0^{2\pi}\sum_{k\in\mathbb Z}\frac{|c_k|^2}{k+z}\exp{[ikx]}dx \end{equation} is wrong. The right computation implies a Kronecker Delta and yields just \begin{equation} \mathcal{F}_\psi(z) = \sum_{k\in\mathbb Z}\frac{|c_k|^2}{k+z} \end{equation} Now everything gets easier. One can compute $\mu_\psi(\lambda)$ explicitly, and the result is \begin{equation} \mu_\psi(\lambda) = \sum_{k\in\mathbb Z}|c_k|^2\frac{k+\lambda + |{k+\lambda}|}{2(k+\lambda)} = \sum_{k\in\mathbb Z}|c_k|^2\chi_{[-\lambda, +\infty)} \end{equation} The resulting measure is some kind of counting measure, characterized by \begin{equation} \mu_\psi(\{n\}) = \mu_\psi(n)-\mu_\psi(n-1) = |c_n|^2,\ \forall n\in\mathbb Z \end{equation} So that \begin{equation} <\psi\ |\ p[\psi]> = \int_{\mathbb Z}^{}n\ d\mu_\psi(n) = \sum_{n\in\mathbb Z}n|c_n|^2 \end{equation} Which is exactly the result one gets applying the Fourier Series theory. From here it's also possible to see \begin{equation} p[\cdot] = \sum_{n\in\mathbb Z}n\Big[\int_0^{2\pi}\cdot(x)e^{-inx}dx\Big]e^{inx} \end{equation} which also agrees with the FS theory. I hope this is at least useful for the internet wanderers...",,"['functional-analysis', 'spectral-theory', 'quantum-mechanics']"
46,A non trivial counterexample in three-space property,A non trivial counterexample in three-space property,,"We know that completeness is a three-space property: Let $M$ be a closed subspace of a normed space $X$. Then, $X$ is complete if and only if $M$ and $X/M$ are complete. I am looking for a non trivial counterexample: $X$ incomplete normed space but $X/M$ ($\neq \{M\}$) complete space with $M$ closed subspace of $X$.","We know that completeness is a three-space property: Let $M$ be a closed subspace of a normed space $X$. Then, $X$ is complete if and only if $M$ and $X/M$ are complete. I am looking for a non trivial counterexample: $X$ incomplete normed space but $X/M$ ($\neq \{M\}$) complete space with $M$ closed subspace of $X$.",,"['functional-analysis', 'normed-spaces', 'banach-spaces', 'examples-counterexamples']"
47,Example of Topological Vector Space,Example of Topological Vector Space,,"Is there a topological vector space such that, for every $x\in X$, there is a proper neighbourhood $V$ of $x$ in $X$ which is convex, but the whole space is not locally convex (i.e. $X$ has a local base consisting of convex sets in each of its point)?","Is there a topological vector space such that, for every $x\in X$, there is a proper neighbourhood $V$ of $x$ in $X$ which is convex, but the whole space is not locally convex (i.e. $X$ has a local base consisting of convex sets in each of its point)?",,"['functional-analysis', 'examples-counterexamples', 'topological-vector-spaces', 'locally-convex-spaces']"
48,What is the significance of the integral of the Hessian determinant?,What is the significance of the integral of the Hessian determinant?,,The integral of a function over some region measures the total value of the function in that region: $$T(u)=\int u\thinspace\mathrm{d}V$$ The integral of the squared norm of the gradient of the function measures its variability over some region and is known as the Dirichlet energy : $$E(u)=\int \lvert\nabla u\rvert^2\thinspace\mathrm{d}V$$ Is there a geometric significance to the integral of the determinant of the Hessian matrix (the square matrix of second-order partial derivatives) of a function over some region? $$\int\det H(u)\thinspace\mathrm{d}V$$ What other integral functionals of a similar form provide interesting information about the behavior of a function over some region?,The integral of a function over some region measures the total value of the function in that region: $$T(u)=\int u\thinspace\mathrm{d}V$$ The integral of the squared norm of the gradient of the function measures its variability over some region and is known as the Dirichlet energy : $$E(u)=\int \lvert\nabla u\rvert^2\thinspace\mathrm{d}V$$ Is there a geometric significance to the integral of the determinant of the Hessian matrix (the square matrix of second-order partial derivatives) of a function over some region? $$\int\det H(u)\thinspace\mathrm{d}V$$ What other integral functionals of a similar form provide interesting information about the behavior of a function over some region?,,"['functional-analysis', 'multivariable-calculus', 'calculus-of-variations', 'differential-operators', 'functional-calculus']"
49,Algebra with element having empty spectrum?,Algebra with element having empty spectrum?,,"The definition of the spectrum makes sense for any algebra. I guess we can go to the unitization to make sense of it even non-unital algebras. Recalling the well-known fact that for normed algebras, the spectrum of each element is always non-empty, I was wondering if there are examples of algebras having an element with empty spectrum. Maybe one might have some examples in mind where we actually have a topology on the algebra. Due to the useful comments, I make my setting more precise. I only consider complex algebras and define the spectrum as $$\sigma(x) := \{\lambda\in \mathbb{C}: \lambda 1 - x \text{ not invertible}\}.$$","The definition of the spectrum makes sense for any algebra. I guess we can go to the unitization to make sense of it even non-unital algebras. Recalling the well-known fact that for normed algebras, the spectrum of each element is always non-empty, I was wondering if there are examples of algebras having an element with empty spectrum. Maybe one might have some examples in mind where we actually have a topology on the algebra. Due to the useful comments, I make my setting more precise. I only consider complex algebras and define the spectrum as $$\sigma(x) := \{\lambda\in \mathbb{C}: \lambda 1 - x \text{ not invertible}\}.$$",,"['functional-analysis', 'spectral-theory', 'banach-algebras']"
50,Poincare-like inequality,Poincare-like inequality,,"I would like to prove that there exists $C>0$ such that $$\| u \|^2_{L^2(B(0,1))} \leq C \left ( \| \nabla u \|^2_{L^2(B(0,1))} + \| u \|^2_{L^2(\partial B(0,1))} \right )$$ for every $u \in C^\infty(\overline{B(0,1)})$, where $B(0,1)$ is the unit ball in $\mathbb{R}^2$. To me this looks similar to a Poincare inequality except that it compensates for the fact that $u$ may not be zero on the boundary. With this in mind, I tried manipulating the version of the Poincare inequality where we subtract off the average so that it would look like this situation. With that I get a $C>0$ such that $$\| u \|^2_{L^2(B(0,1))} \leq C \left ( \overline{u}^2 + \| \nabla u \|^2_{L^2(B(0,1))} \right )$$ where $\overline{u}$ is the average of $u$ over $B(0,1)$. Now I get stuck trying to relate $\overline{u}$ to $u$ on the boundary. From here I would want to show that $\overline{u}^2 \leq C \| u \|^2_{L^2(\partial B(0,1))}$. But that can't work, because we could have a nonzero function which is zero on the boundary yet strictly positive on the interior. Of course, in this case the result follows from the Poincare inequality for $H^1_0$. So this result seems to be somewhat like an interpolation between the Poincare inequality for $H^1_0$ and the Poincare inequality for $H^1$ functions with mean zero. Any suggestions?","I would like to prove that there exists $C>0$ such that $$\| u \|^2_{L^2(B(0,1))} \leq C \left ( \| \nabla u \|^2_{L^2(B(0,1))} + \| u \|^2_{L^2(\partial B(0,1))} \right )$$ for every $u \in C^\infty(\overline{B(0,1)})$, where $B(0,1)$ is the unit ball in $\mathbb{R}^2$. To me this looks similar to a Poincare inequality except that it compensates for the fact that $u$ may not be zero on the boundary. With this in mind, I tried manipulating the version of the Poincare inequality where we subtract off the average so that it would look like this situation. With that I get a $C>0$ such that $$\| u \|^2_{L^2(B(0,1))} \leq C \left ( \overline{u}^2 + \| \nabla u \|^2_{L^2(B(0,1))} \right )$$ where $\overline{u}$ is the average of $u$ over $B(0,1)$. Now I get stuck trying to relate $\overline{u}$ to $u$ on the boundary. From here I would want to show that $\overline{u}^2 \leq C \| u \|^2_{L^2(\partial B(0,1))}$. But that can't work, because we could have a nonzero function which is zero on the boundary yet strictly positive on the interior. Of course, in this case the result follows from the Poincare inequality for $H^1_0$. So this result seems to be somewhat like an interpolation between the Poincare inequality for $H^1_0$ and the Poincare inequality for $H^1$ functions with mean zero. Any suggestions?",,"['functional-analysis', 'partial-differential-equations', 'sobolev-spaces']"
51,"Let $X$ be a linear normed space, and $L$ a nontrivial linear functional on $X$. Prove the following are equivalent:","Let  be a linear normed space, and  a nontrivial linear functional on . Prove the following are equivalent:",X L X,"Let $X$ be a linear normed space, and $L$ a nontrivial linear functional on $X$. Prove the following are equivalent: $1) L$ is continuous $2)$ The null space of $L$ is proper, closed linear subspace of $X$ $3)$ The null space of $L$ is not dense in $X$. My Work: I proved that $1)\Rightarrow 2)$ and $ 2)\Rightarrow 3)$, but stuck in proving $3)\Rightarrow 1)$. Since ker $L$ is not dense, there is $x\in X$ which is not a limit point of ker $L$. How does it proceed towards $L$ is continuous? Can anybody please give me a hint?","Let $X$ be a linear normed space, and $L$ a nontrivial linear functional on $X$. Prove the following are equivalent: $1) L$ is continuous $2)$ The null space of $L$ is proper, closed linear subspace of $X$ $3)$ The null space of $L$ is not dense in $X$. My Work: I proved that $1)\Rightarrow 2)$ and $ 2)\Rightarrow 3)$, but stuck in proving $3)\Rightarrow 1)$. Since ker $L$ is not dense, there is $x\in X$ which is not a limit point of ker $L$. How does it proceed towards $L$ is continuous? Can anybody please give me a hint?",,['functional-analysis']
52,Can one find a stronger norm on a Banach space?,Can one find a stronger norm on a Banach space?,,"Given a Banach space $V$ of infinite dimension with norm $\|\cdot\|_1$, is that possible to find a norm $\|\cdot\|_2$ on $V$ such that the topology induced by $\|\cdot\|_2$ is strictly stronger than that of $\|\cdot\|_1$? I guess the answer is no, but I can only prove that $\|\cdot\|_2$ cannot be complete (simply  by open mapping theorem). Any idea will be appreciated.","Given a Banach space $V$ of infinite dimension with norm $\|\cdot\|_1$, is that possible to find a norm $\|\cdot\|_2$ on $V$ such that the topology induced by $\|\cdot\|_2$ is strictly stronger than that of $\|\cdot\|_1$? I guess the answer is no, but I can only prove that $\|\cdot\|_2$ cannot be complete (simply  by open mapping theorem). Any idea will be appreciated.",,"['functional-analysis', 'normed-spaces']"
53,Do $L^p$ spaces have the approximation property?,Do  spaces have the approximation property?,L^p,"A Banach space $X$ has the approximation property if every compact operator $T:X \to X$ is the norm-limit of a sequence of finite-rank operators. My question is if there is a simple proof that the approximation property holds for $L^p(\Sigma,\mu)$ spaces. It would be enough for me to prove this property in the case that $T$ is linear. I have found a proof of this in the case $\mu(\Sigma)<\infty$ in which the sequence is explicitely found but I am unable to adapt the proof for the general case. Any reference would be appreciated too. Thanks","A Banach space $X$ has the approximation property if every compact operator $T:X \to X$ is the norm-limit of a sequence of finite-rank operators. My question is if there is a simple proof that the approximation property holds for $L^p(\Sigma,\mu)$ spaces. It would be enough for me to prove this property in the case that $T$ is linear. I have found a proof of this in the case $\mu(\Sigma)<\infty$ in which the sequence is explicitely found but I am unable to adapt the proof for the general case. Any reference would be appreciated too. Thanks",,"['analysis', 'functional-analysis', 'lp-spaces', 'compact-operators']"
54,Exercise in Hahn-Banach Theorem; Finding linear functional $-p(-x)\leq f(x)\leq p(x)$,Exercise in Hahn-Banach Theorem; Finding linear functional,-p(-x)\leq f(x)\leq p(x),"(The following exercises are in Kreyszig's book 218 page; EXE 10) I want to solve the following exercise : If $X=l^\infty$ , let $p(x)=\lim\sup x_i $ , which is sublinear. Then find a linear functional $f(x)$ s.t. $$ -p(-x)\leq f(x) \leq p(x)$$ Background : If $p$ is a sublinear function on a real vector space, i.e., $$ p(x+y)\leq p(x) + p(y),\ p(cx)=cp(x),\ c\geq 0 $$ then there exists linear functional $f$ s.t. $$ -p(-x)\leq f(x) \leq p(x) $$ Proof : By Hahn-Banach theorem we have $f(x)\leq p(x) $ so that $$ f(-x)\leq p(-x)$$ That is $$ -p(-x)\leq f(x) \leq f(x)$$ Now, we return to original question : $X=l^\infty$ , let $p(x)=\limsup x_i $ . So $$-p(-x)=-\limsup (-x_i)=\liminf x_i$$ Hence if such functional $f$ exists, then $f(x)=\lim x_i$ when $\lim x_i$ exists. If $x_{2i+1}=2,\ x_{2i}=1$ then $v_{2i+1}=1,\ v_{2i}=2$ then $ f(x+v)=3 $ . That is, the problem is how determine $f$ on $x$ where $\lim x_i$ does not exist. Try : If we let $f(x)=\frac{\lim\inf x_i + \lim\sup x_i}{2} $ , then note that $f(x+v)\neq f(x)+f(v)$ . Thank you in advance.","(The following exercises are in Kreyszig's book 218 page; EXE 10) I want to solve the following exercise : If , let , which is sublinear. Then find a linear functional s.t. Background : If is a sublinear function on a real vector space, i.e., then there exists linear functional s.t. Proof : By Hahn-Banach theorem we have so that That is Now, we return to original question : , let . So Hence if such functional exists, then when exists. If then then . That is, the problem is how determine on where does not exist. Try : If we let , then note that . Thank you in advance.","X=l^\infty p(x)=\lim\sup x_i  f(x)  -p(-x)\leq
f(x) \leq p(x) p  p(x+y)\leq p(x) + p(y),\ p(cx)=cp(x),\ c\geq 0  f  -p(-x)\leq f(x) \leq
p(x)  f(x)\leq p(x)
  f(-x)\leq p(-x)  -p(-x)\leq f(x) \leq f(x) X=l^\infty p(x)=\limsup x_i  -p(-x)=-\limsup (-x_i)=\liminf x_i f f(x)=\lim x_i \lim x_i x_{2i+1}=2,\ x_{2i}=1 v_{2i+1}=1,\ v_{2i}=2  f(x+v)=3  f x \lim x_i f(x)=\frac{\lim\inf x_i + \lim\sup x_i}{2}  f(x+v)\neq f(x)+f(v)","['functional-analysis', 'normed-spaces']"
55,Orthogonal decomposition in Hilbert spaces,Orthogonal decomposition in Hilbert spaces,,"Corollary 2.76 (Orthogonal decomposition). Let H be a Hilbert space,   and let $Y \subset H$ be a closed subspace. Then $Y^\bot $ is a closed subspace with   $$H = Y \oplus Y^\bot$$,   meaning that every element $h \in H$ can be written in the form   $$h = y + z$$   with $y \in Y$ and $z \in Y^\bot$ and $y$ and $z$ are unique with these properties The uniqueness part is easily shown. But for the existance part it's said that we want to use the unique approximation within a closed convex set (i.e $\forall w\in V \exists ! v_o\in K \text{ s.t. } \|w-v_0\|=\inf_{k\in K}\|k-v_0\|$). The argumentation goes as follows: Fix $h \in H$, and   apply Theorem 2.73 with $K = Y$ to find a point $y \in Y$ that is closest to $h$.   Let $z := h − y$, so that for any $v \in Y$ and any scalar $t$ we have (noting that the first inequality holds because $(tv+y)\in Y$ and is strict for all $t\ne0$ by the lemma and the second equality holds for the properties of the inner product)    $$\|z\|^2\le\|h-(tv+y)\|^2=\|z-tv\|=\|z\|^2-2\Re(t\langle v,z\rangle)+|t|^2\|v\|^2$$ (And now the problematic part) However , this shows that   $$\Re(t\langle v,z\rangle)=0$$   for all scalars $t$ and $v \in Y$ , and so   $$\langle v,z\rangle=0$$ How should I interpret that ""However"" ? Where should I use the fact that this particular $y$ is the unique closest in $Y$? Many thanks in advance","Corollary 2.76 (Orthogonal decomposition). Let H be a Hilbert space,   and let $Y \subset H$ be a closed subspace. Then $Y^\bot $ is a closed subspace with   $$H = Y \oplus Y^\bot$$,   meaning that every element $h \in H$ can be written in the form   $$h = y + z$$   with $y \in Y$ and $z \in Y^\bot$ and $y$ and $z$ are unique with these properties The uniqueness part is easily shown. But for the existance part it's said that we want to use the unique approximation within a closed convex set (i.e $\forall w\in V \exists ! v_o\in K \text{ s.t. } \|w-v_0\|=\inf_{k\in K}\|k-v_0\|$). The argumentation goes as follows: Fix $h \in H$, and   apply Theorem 2.73 with $K = Y$ to find a point $y \in Y$ that is closest to $h$.   Let $z := h − y$, so that for any $v \in Y$ and any scalar $t$ we have (noting that the first inequality holds because $(tv+y)\in Y$ and is strict for all $t\ne0$ by the lemma and the second equality holds for the properties of the inner product)    $$\|z\|^2\le\|h-(tv+y)\|^2=\|z-tv\|=\|z\|^2-2\Re(t\langle v,z\rangle)+|t|^2\|v\|^2$$ (And now the problematic part) However , this shows that   $$\Re(t\langle v,z\rangle)=0$$   for all scalars $t$ and $v \in Y$ , and so   $$\langle v,z\rangle=0$$ How should I interpret that ""However"" ? Where should I use the fact that this particular $y$ is the unique closest in $Y$? Many thanks in advance",,"['functional-analysis', 'inequality']"
56,"On separable Hilbert space $H$, weak operator topology is metrizable on bounded parts of $B(H)$","On separable Hilbert space , weak operator topology is metrizable on bounded parts of",H B(H),"The following is a theorem of Takesaki's operator theory: In this proof, weak topology means weak operator topology. I'm wonder why the theorem holds just for bounded parts of $B(H)$ and also where does he  use of boundedness?  Thanks.","The following is a theorem of Takesaki's operator theory: In this proof, weak topology means weak operator topology. I'm wonder why the theorem holds just for bounded parts of $B(H)$ and also where does he  use of boundedness?  Thanks.",,"['functional-analysis', 'operator-theory', 'topological-vector-spaces']"
57,Why only densely defined operators can have an adjoint operator?,Why only densely defined operators can have an adjoint operator?,,Why is it impossible or making no sense to define an adjoint operator for a non-densely defined operator?,Why is it impossible or making no sense to define an adjoint operator for a non-densely defined operator?,,"['functional-analysis', 'hilbert-spaces']"
58,Ultraweakly closed left ideals of von Neumann algebras,Ultraweakly closed left ideals of von Neumann algebras,,"The following is a proposition of Takesaki's Operator Theory: My questions are: 1- He claims for two sided ideal $\cal m$, $e \in M\cap M'$. While I think for $\sigma -$ weakly closed two sided ideal we can conclude it. Also I think he uses of $\sigma-$ weakly closed ideal in the proof. Am I right? 2- He claims if $M$ is a factor, then every nonzero two-sided ideal is $\sigma-$weakly dense in it. I think in this situation, there is just a nonzero $\sigma-$ weak closed two sided ideal because the central projections are $1, -1$ and ${\cal m}_1=M(1) = M(-1) ={\cal m}_2$,  but there may be different two sided ideals with equal $\sigma- $ weak clusers. If this is true, I would like to see an emample about it. $\sigma- $weak means ultraweak topology. Thanks in advance.","The following is a proposition of Takesaki's Operator Theory: My questions are: 1- He claims for two sided ideal $\cal m$, $e \in M\cap M'$. While I think for $\sigma -$ weakly closed two sided ideal we can conclude it. Also I think he uses of $\sigma-$ weakly closed ideal in the proof. Am I right? 2- He claims if $M$ is a factor, then every nonzero two-sided ideal is $\sigma-$weakly dense in it. I think in this situation, there is just a nonzero $\sigma-$ weak closed two sided ideal because the central projections are $1, -1$ and ${\cal m}_1=M(1) = M(-1) ={\cal m}_2$,  but there may be different two sided ideals with equal $\sigma- $ weak clusers. If this is true, I would like to see an emample about it. $\sigma- $weak means ultraweak topology. Thanks in advance.",,"['functional-analysis', 'operator-algebras', 'c-star-algebras', 'weak-convergence', 'von-neumann-algebras']"
59,multiplicative semi-norms on $\mathbb{C}[x]$,multiplicative semi-norms on,\mathbb{C}[x],"A multiplicative semi-norm on a ring $A$ is a function $|\,|:A\to \mathbb{R}_{\ge 0}$ that is multiplicative and satisfies the semi-norm conditions: $|0|=0,|1|=1\\ |fg|=|f||g|,\\ |f+g|\le |f|+|g|.$ I want to see why the set of multiplicative semi-norms on $\mathbb{C}[x]$ that extend the absolute value norm on $\mathbb{C}$ is of the form $f\mapsto |f(x)|$ for some $x\in \mathbb{C}$. It is said here that this follows from Gelfand-Mazur's theorem but I do not see how. Can someone give a proof?","A multiplicative semi-norm on a ring $A$ is a function $|\,|:A\to \mathbb{R}_{\ge 0}$ that is multiplicative and satisfies the semi-norm conditions: $|0|=0,|1|=1\\ |fg|=|f||g|,\\ |f+g|\le |f|+|g|.$ I want to see why the set of multiplicative semi-norms on $\mathbb{C}[x]$ that extend the absolute value norm on $\mathbb{C}$ is of the form $f\mapsto |f(x)|$ for some $x\in \mathbb{C}$. It is said here that this follows from Gelfand-Mazur's theorem but I do not see how. Can someone give a proof?",,['functional-analysis']
60,Fubini's theorem for complete $\sigma$-algebras vs. non-complete $\sigma$-algebras,Fubini's theorem for complete -algebras vs. non-complete -algebras,\sigma \sigma,"Suppose $(X, \Sigma, \mu)$ and $(Y, \tau, \nu)$ are both complete measure spaces.  Consider the following two measure spaces: $(X \times Y, \overline{\Sigma \times \tau}, \mu \times \nu)$ and $(X \times Y, \Sigma \times \tau, \mu \times \nu)$. I know Fubini's theorem for the complete $\sigma$-algebra $\overline{\Sigma \times \tau}$: If $f \in L^{1}(d\mu \times d\nu)$, then: The maps $y \mapsto f(x,y)$ are in $L^{1}(d\nu)$ for almost all $x$ The map $x \mapsto \int \limits_{Y} f(x,y) \,d\nu$ is in $L^{1}(d\mu)$ $\int \limits_{X \times Y} f(x,y) \,d(\mu \times \nu) = \int \limits_{X} \left [ \int \limits_{Y} f(x,y) \,d\nu \right ] \,d\mu$ My first question: in statement 1, I believe we also have that the maps are measurable for almost all $x$.  Then the map in 2 can only exist almost everywhere, so shouldn't it equal an $L^{1}(d\mu)$ function almost everywhere, rather than being in $L^{1}(d\mu)$ itself? My second question: What is different between Fubini's theorem above for $\overline{\Sigma \times \tau}$ and Fubini's theorem applied to $\Sigma \times \tau$?  I know that when we are dealing with $\Sigma \times \tau$, we have that the maps $y \mapsto f(x,y)$ are measurable for all $x$, not just almost everywhere, but aside from this, I don't know what else is different.","Suppose $(X, \Sigma, \mu)$ and $(Y, \tau, \nu)$ are both complete measure spaces.  Consider the following two measure spaces: $(X \times Y, \overline{\Sigma \times \tau}, \mu \times \nu)$ and $(X \times Y, \Sigma \times \tau, \mu \times \nu)$. I know Fubini's theorem for the complete $\sigma$-algebra $\overline{\Sigma \times \tau}$: If $f \in L^{1}(d\mu \times d\nu)$, then: The maps $y \mapsto f(x,y)$ are in $L^{1}(d\nu)$ for almost all $x$ The map $x \mapsto \int \limits_{Y} f(x,y) \,d\nu$ is in $L^{1}(d\mu)$ $\int \limits_{X \times Y} f(x,y) \,d(\mu \times \nu) = \int \limits_{X} \left [ \int \limits_{Y} f(x,y) \,d\nu \right ] \,d\mu$ My first question: in statement 1, I believe we also have that the maps are measurable for almost all $x$.  Then the map in 2 can only exist almost everywhere, so shouldn't it equal an $L^{1}(d\mu)$ function almost everywhere, rather than being in $L^{1}(d\mu)$ itself? My second question: What is different between Fubini's theorem above for $\overline{\Sigma \times \tau}$ and Fubini's theorem applied to $\Sigma \times \tau$?  I know that when we are dealing with $\Sigma \times \tau$, we have that the maps $y \mapsto f(x,y)$ are measurable for all $x$, not just almost everywhere, but aside from this, I don't know what else is different.",,"['real-analysis', 'functional-analysis', 'measure-theory', 'lebesgue-integral']"
61,"The vector space of absolutely continuous functions on $[0,1]$ endowed with a special norm, then the space is complete.","The vector space of absolutely continuous functions on  endowed with a special norm, then the space is complete.","[0,1]","The vector space of absolutely continuous functions $V$ on $[0,1]$ endowed with a special norm $||\cdot ||$ as $||f||=\int_0^1 |f(t)|dt +\int_0^1 |f'(t)dt|=||f||_1+||f'||_1, \quad f\in V$.   Then the space is complete. Here is what I tried: we want to prove $V$ is complete, so it suffices to prove that $V$ is summable, i.e for any $\sum_{n=1}^\infty ||f_n||<\infty$, we can get $\sum_{n=1}^\infty f_n$ converges in $V$. Define $F:=\sum_{n=1}^\infty f_n, f:=\sum_{n=1}^\infty f'_n$,  then $||F||_1\leq \sum_{n=1}^\infty ||f_n||_1<\infty$ so that  $f\in L^1[0,1]$ and $||f||_1\leq \sum_{n=1}^\infty ||f'_n||_1<\infty$ so that  $f\in L^1[0,1]$. $\int_0^x f'=\int_0^x\sum_{n=1}^\infty f'_n=\sum_{n=1}^\infty \int_0^x f'_n=\sum_{n=1}^\infty (f_n(x)-f_n(0))=F(x)-F(0)$. So $F$ is absolutely continuous, i.e $F\in V$, we get $\sum_{n=1}^\infty f_n$ converges to $F$ in $V$. Is this process right? or there are other correct proof?","The vector space of absolutely continuous functions $V$ on $[0,1]$ endowed with a special norm $||\cdot ||$ as $||f||=\int_0^1 |f(t)|dt +\int_0^1 |f'(t)dt|=||f||_1+||f'||_1, \quad f\in V$.   Then the space is complete. Here is what I tried: we want to prove $V$ is complete, so it suffices to prove that $V$ is summable, i.e for any $\sum_{n=1}^\infty ||f_n||<\infty$, we can get $\sum_{n=1}^\infty f_n$ converges in $V$. Define $F:=\sum_{n=1}^\infty f_n, f:=\sum_{n=1}^\infty f'_n$,  then $||F||_1\leq \sum_{n=1}^\infty ||f_n||_1<\infty$ so that  $f\in L^1[0,1]$ and $||f||_1\leq \sum_{n=1}^\infty ||f'_n||_1<\infty$ so that  $f\in L^1[0,1]$. $\int_0^x f'=\int_0^x\sum_{n=1}^\infty f'_n=\sum_{n=1}^\infty \int_0^x f'_n=\sum_{n=1}^\infty (f_n(x)-f_n(0))=F(x)-F(0)$. So $F$ is absolutely continuous, i.e $F\in V$, we get $\sum_{n=1}^\infty f_n$ converges to $F$ in $V$. Is this process right? or there are other correct proof?",,"['functional-analysis', 'absolute-continuity']"
62,Show that a subspace of $\ell^2$ is not complete,Show that a subspace of  is not complete,\ell^2,"I would like to know if this exercise is correct. Let $\Bbb R^\infty=\{x:\Bbb N\rightarrow \Bbb R: \exists n \text{ such that}\quad x(k)=0 \quad \forall k\geq n\}$. Show that $(\Bbb R^\infty, \| \cdot\|_{l^2})$ is not complete. Let $x\in l^2$ be such that $x(k)= ({1\over 2})^k$. Let $(x_n)_n$ a sequence in $\Bbb R^\infty$ defined as: $$x_n(k)= \begin{cases} ({1\over 2})^k, & \mbox{if } k\leq n \\ 0 & \mbox{else }\end{cases}.$$ If we show that $x_n\rightarrow x$ in $l^2$ we've done, since $x\notin \Bbb R^\infty$. So, $$x(k)-x_n(k)= \begin{cases} 0, & \mbox{if } k\leq n \\({1\over 2})^k  & \mbox{if }k\geq n+1 \end{cases}$$ for each $n\in \Bbb N$. Now, $\|x-x_n\|_{l^2}^2=\sum_{k=1}^\infty|x(k)-x_n(k)|^2=\sum_{k=n+1}^\infty ({1\over 2})^{2k} $, for each $n\in \Bbb N$. Thus $\lim_{n\to \infty} \|x-x_n\|_{l^2}^2=\lim_{n \to \infty}\sum_{k=n+1}^\infty ({1\over 2})^{2k}=0.$ Since $x_n\rightarrow x$ in $l^2$, $(\Bbb R^\infty, \| \cdot\|_{l^2})$ is not complete.","I would like to know if this exercise is correct. Let $\Bbb R^\infty=\{x:\Bbb N\rightarrow \Bbb R: \exists n \text{ such that}\quad x(k)=0 \quad \forall k\geq n\}$. Show that $(\Bbb R^\infty, \| \cdot\|_{l^2})$ is not complete. Let $x\in l^2$ be such that $x(k)= ({1\over 2})^k$. Let $(x_n)_n$ a sequence in $\Bbb R^\infty$ defined as: $$x_n(k)= \begin{cases} ({1\over 2})^k, & \mbox{if } k\leq n \\ 0 & \mbox{else }\end{cases}.$$ If we show that $x_n\rightarrow x$ in $l^2$ we've done, since $x\notin \Bbb R^\infty$. So, $$x(k)-x_n(k)= \begin{cases} 0, & \mbox{if } k\leq n \\({1\over 2})^k  & \mbox{if }k\geq n+1 \end{cases}$$ for each $n\in \Bbb N$. Now, $\|x-x_n\|_{l^2}^2=\sum_{k=1}^\infty|x(k)-x_n(k)|^2=\sum_{k=n+1}^\infty ({1\over 2})^{2k} $, for each $n\in \Bbb N$. Thus $\lim_{n\to \infty} \|x-x_n\|_{l^2}^2=\lim_{n \to \infty}\sum_{k=n+1}^\infty ({1\over 2})^{2k}=0.$ Since $x_n\rightarrow x$ in $l^2$, $(\Bbb R^\infty, \| \cdot\|_{l^2})$ is not complete.",,"['real-analysis', 'functional-analysis', 'proof-verification', 'hilbert-spaces', 'banach-spaces']"
63,E is bounded if and only if every countable subset of it is bounded,E is bounded if and only if every countable subset of it is bounded,,"I'm trying to do an exercise from Rudin's ""Functional analysis, 2nd edition"". It is question 6 from the first chapter: ""Prove that a set E in a topological vector space is bounded if and only if every countable subset of E is bounded"" My efforts so far: If $E$ is bounded, then if $U$ is any neighbourhood containing $0$, $E\subset tU$ for all $t$ large enough and positive. $A\subset E$, and so for any $U$ a neighbourhood of $0$, $A\subset tU$ for $t$ large enough. I'm having trouble with the ""only if"" part. I cannot see where the ""countability"" of $A$ comes in: If $A$ is a bounded countable subset of $E$, then $A\subset tU$ for $t$ large enough, and $U$ is as before. Now, somehow I need to argue that $A\subset E \subset tU$. Any hints would be appreciated, thanks!","I'm trying to do an exercise from Rudin's ""Functional analysis, 2nd edition"". It is question 6 from the first chapter: ""Prove that a set E in a topological vector space is bounded if and only if every countable subset of E is bounded"" My efforts so far: If $E$ is bounded, then if $U$ is any neighbourhood containing $0$, $E\subset tU$ for all $t$ large enough and positive. $A\subset E$, and so for any $U$ a neighbourhood of $0$, $A\subset tU$ for $t$ large enough. I'm having trouble with the ""only if"" part. I cannot see where the ""countability"" of $A$ comes in: If $A$ is a bounded countable subset of $E$, then $A\subset tU$ for $t$ large enough, and $U$ is as before. Now, somehow I need to argue that $A\subset E \subset tU$. Any hints would be appreciated, thanks!",,['functional-analysis']
64,Dirac delta distribution and measure?,Dirac delta distribution and measure?,,"Of course the Dirac delta is not a function. Despite, I think the concept of a measure is much easier than that of a distribution. Therefore, I was wondering: In what sense is the concept of a Dirac distribution equivalent to the Dirac measure? Are you (in principle) able to prove all the properties of the distribution if you are using the concept of a measure? Or is the only thing that the Dirac delta measure is good for to say: $$\int_{\mathbb{R}} f(x)\delta(x-x_0) d\mu(x):= \int_{\mathbb{R}} f(x)d\delta_{x_0}=f(x_0)?$$ Or differently: Would this definition be an appropriate definition? Or do we have to refer to the theory of distributions to prove all the properties that the Dirac-delta has?","Of course the Dirac delta is not a function. Despite, I think the concept of a measure is much easier than that of a distribution. Therefore, I was wondering: In what sense is the concept of a Dirac distribution equivalent to the Dirac measure? Are you (in principle) able to prove all the properties of the distribution if you are using the concept of a measure? Or is the only thing that the Dirac delta measure is good for to say: $$\int_{\mathbb{R}} f(x)\delta(x-x_0) d\mu(x):= \int_{\mathbb{R}} f(x)d\delta_{x_0}=f(x_0)?$$ Or differently: Would this definition be an appropriate definition? Or do we have to refer to the theory of distributions to prove all the properties that the Dirac-delta has?",,"['real-analysis', 'functional-analysis']"
65,Non-existence Tracial states,Non-existence Tracial states,,We know that every non-zero finite dimensional C*-algebra has a tracial state. I am searching for an example of a simple C* algebra without tracial state with explaination. I think you have to look to the calkin algebra on a separable Hilbert space. Someone an idea? Thanks.,We know that every non-zero finite dimensional C*-algebra has a tracial state. I am searching for an example of a simple C* algebra without tracial state with explaination. I think you have to look to the calkin algebra on a separable Hilbert space. Someone an idea? Thanks.,,"['functional-analysis', 'c-star-algebras']"
66,Missing a necessary power in this proof - please help.,Missing a necessary power in this proof - please help.,,"This question is somewhat related to Gradient Estimate - Question about Inequality vs. Equality sign in one part . That question was related to part (c) of a problem I am working on, and this question is related to part (b). Specifically, I need to show the following: Let $u$ and $v$ be two functions on $\Omega$ related as follows:   $$ |u(x)| \leq \int_{\Omega}K(x,y)|v(y)|dy, \quad x \in \Omega, $$   for some kernel $K(x,y)$. Show that for any $1 \leq p \leq q \leq \infty$, we have   $$ ||u||_{L^{q}(\Omega)}\leq A||v||_{L^{p}(\Omega)} $$   where $A = \max \left( \sup_{x}||K(x,\cdot)||_{L^{\frac{pq}{pq+p-q}}(\Omega)},\sup_{y}||K(\cdot,y)||_{L^{\frac{pq}{pq+p-q}}(\Omega)} \right)$. So, starting with $u$, $v$ on $\Omega$ satisfying $$|u(x)| \leq \int_{\Omega}K(x,y)|v(y)|dy \quad (*)$$ I have that $$(*) \leq \int_{\Omega} |K(x,y) |v(y)|| dy \\ = \int_{\Omega}|K(x,y)v(y)| dy \\ = \int_{\Omega}|K(x,y)^{\alpha+1-\alpha}v(y)|dy\\ \leq \int_{\Omega}|K(x,y)|^{\alpha}|K(x,y)|^{1-\alpha}|v(y)|dy \\ = \int_{\Omega} |K(x,y)|^{\alpha} |K(x,y)|^{1-\alpha}|v(y)|^{1-\beta + \beta} dy\\ \leq \int_{\Omega}|K(x,y)|^{\alpha}(|K(x,y)|^{1-\alpha}|v(y)|^{1-\beta})|v(y)|dy \quad (1)$$ Aplying Holder's Inequality to $(1)$, we get that $$(1) \displaystyle \leq \left[ \int_{\Omega} |K(x,y)|^{\alpha a} dy\right]^{1/a} \cdot \left[ \int_{\Omega} |K(x,y)|^{(1-\alpha)c} |v(y)|^{(1-\beta)c}dy \right]^{1/c} \cdot \left[\int_{\Omega}|v(y)|^{\beta b}dy \right]^{1/b}, $$ where $\displaystyle 1 = \frac{1}{a} + \frac{1}{b} + \frac{1}{c}. \quad (1^{\prime})$ Since we want the $L^{p}$ norm of $v$ to appear in the RHS, choose $\beta b = p$. Thus, $\displaystyle b = \frac{p}{\beta}. \quad (2)$ Also, let $(1-\beta)c = p$, which implies that $\displaystyle \beta = 1 - \frac{p}{c}$. Raising (1) to the power of $q$ and taking the integral with respect to x, we obtain that $$ \int |u(x)|^{q} dx \leq \int \left( \left[ \int|K(x,y)|^{\alpha a}dy \right]^{q/a}\left[ \int|K(x,y)|^{(1-\alpha)c}|v(y)|^{(1-\beta)c}dy\right]^{q/c}||v||_{L^{p}}^{\beta q}\right) dx. $$ Now, in order for us to be able to switch the order of integration, we need $\displaystyle \frac{q}{c} = 1$, so $q = c. \quad (4)$ Therefore, $(3)$ becomes $\displaystyle \beta = 1 - \frac{p}{q} \quad (3^{\prime})$, and $(2)$ becomes $\displaystyle b = \frac{p}{\displaystyle \left( 1 - \frac{p}{q}\right)} = \frac{pq}{q-p} \quad (2^{\prime})$. Substituting $(4)$ and $(2^{\prime})$ into $(1^{\prime})$, we obtain an expression for $a$: $\displaystyle a = \frac{p}{p-1} \quad (5)$ Bounding everything, we obtain $$||u||_{L^{q}}^{q} \leq \sup_{x}\left( \int|K(x,y)|^{\alpha a}dy\right)^{q/a} \cdot \left[\sup_{y}\int |K(x,y)|^{(1-\alpha)c}dx \right] ||v||_{L^{p}}^{p+\beta q}. \quad (6)$$ Notice also that $\displaystyle \frac{q}{a} = 1$, so $$ (6) = \left[ \sup_{x}\int|K(x,y)^{\alpha a}dy\right] \cdot \left[ \sup_{y} \int |K(x,y)|^{(1-\alpha)c}dx \right] \cdot ||v||_{L^{p}}^{p+\beta q}. \quad (6^{\prime})$$ Now, we need $\sup_{x}$, $\sup_{y}$, and each of these kernels to be finite, so choose $\alpha$ so that $\alpha a = (1-\alpha)c$, which implies then that $\displaystyle \alpha = \frac{c}{a+c}$. Then, substituting our values for $a$ and $c$ [$(5)$ and $(4)$], respectively, we obtain that $\alpha = \frac{q}{\frac{p}{p-1}+q} = \frac{q(p-1)}{p+pq-q} \quad (7)$ and that $(1-\alpha) = \frac{p}{p+pq-q}. \quad (7^{\prime})$ So, $\alpha a = \frac{pq}{p+pq-q}$, and $(1-\alpha)c = \frac{pq}{p+pq-q}. \quad (7^{\prime\prime})$ Thus, $(6^{\prime})$ becomes $$ = \left[ \sup_{x}\int |K(x,y)|^{\frac{pq}{p+pq-q}}dy\right] \cdot \left[ \sup_{y} \int |K(x,y)|^{\frac{pq}{p+pq-q}}dx\right]||v||_{L^{p}}^{p+(1-\frac{p}{q})\cdot q}. \quad (8)$$ But, since $\displaystyle p + \left( 1-\frac{p}{q}\right)q = q$, $(8)$ becomes $$ = \left[\sup_{x}\int|K(x,y)|^{\frac{pq}{p+pq-q}}dy\right]\left[ \sup_{y} \int |K(x,y)|^{\frac{pq}{p+pq-q}} dx \right] ||v||_{L^{p}}^{q}$$. Which brings me to my question. Taking $q$th roots, you see that we have the following: $$ ||u||_{L^{q}(\Omega)} \leq \left[\sup_{x}\int|K(x,y)|^{\frac{pq}{p+pq-q}}dy\right]^{1/q}\left[\sup_{y}\int |K(x,y)|^{\frac{pq}{p+pq-q}}dx\right]^{1/q}||v||_{L^{p}}$$, but what I need is: $$ ||u||_{L^{q}(\Omega)} \leq \left[\sup_{x}\int|K(x,y)|^{\frac{pq}{p+pq-q}}dy\right]^{\frac{p+pq-q}{pq}}\left[\sup_{y}\int |K(x,y)|^{\frac{pq}{p+pq-q}}dx\right]^{\frac{p+pq-q}{pq}}||v||_{L^{p}}$$, so that I will have the $||K(x,y)||_{L^{\frac{pq}{pq+p-q}}}$ norms on the RHS that I need. So, what I am hoping someone will tell me is, where did I go wrong in ""misplacing"" these powers? How do I fix this so that I will get the correct norm in my final answer? Thank you in advance! I really would appreciate your help!!","This question is somewhat related to Gradient Estimate - Question about Inequality vs. Equality sign in one part . That question was related to part (c) of a problem I am working on, and this question is related to part (b). Specifically, I need to show the following: Let $u$ and $v$ be two functions on $\Omega$ related as follows:   $$ |u(x)| \leq \int_{\Omega}K(x,y)|v(y)|dy, \quad x \in \Omega, $$   for some kernel $K(x,y)$. Show that for any $1 \leq p \leq q \leq \infty$, we have   $$ ||u||_{L^{q}(\Omega)}\leq A||v||_{L^{p}(\Omega)} $$   where $A = \max \left( \sup_{x}||K(x,\cdot)||_{L^{\frac{pq}{pq+p-q}}(\Omega)},\sup_{y}||K(\cdot,y)||_{L^{\frac{pq}{pq+p-q}}(\Omega)} \right)$. So, starting with $u$, $v$ on $\Omega$ satisfying $$|u(x)| \leq \int_{\Omega}K(x,y)|v(y)|dy \quad (*)$$ I have that $$(*) \leq \int_{\Omega} |K(x,y) |v(y)|| dy \\ = \int_{\Omega}|K(x,y)v(y)| dy \\ = \int_{\Omega}|K(x,y)^{\alpha+1-\alpha}v(y)|dy\\ \leq \int_{\Omega}|K(x,y)|^{\alpha}|K(x,y)|^{1-\alpha}|v(y)|dy \\ = \int_{\Omega} |K(x,y)|^{\alpha} |K(x,y)|^{1-\alpha}|v(y)|^{1-\beta + \beta} dy\\ \leq \int_{\Omega}|K(x,y)|^{\alpha}(|K(x,y)|^{1-\alpha}|v(y)|^{1-\beta})|v(y)|dy \quad (1)$$ Aplying Holder's Inequality to $(1)$, we get that $$(1) \displaystyle \leq \left[ \int_{\Omega} |K(x,y)|^{\alpha a} dy\right]^{1/a} \cdot \left[ \int_{\Omega} |K(x,y)|^{(1-\alpha)c} |v(y)|^{(1-\beta)c}dy \right]^{1/c} \cdot \left[\int_{\Omega}|v(y)|^{\beta b}dy \right]^{1/b}, $$ where $\displaystyle 1 = \frac{1}{a} + \frac{1}{b} + \frac{1}{c}. \quad (1^{\prime})$ Since we want the $L^{p}$ norm of $v$ to appear in the RHS, choose $\beta b = p$. Thus, $\displaystyle b = \frac{p}{\beta}. \quad (2)$ Also, let $(1-\beta)c = p$, which implies that $\displaystyle \beta = 1 - \frac{p}{c}$. Raising (1) to the power of $q$ and taking the integral with respect to x, we obtain that $$ \int |u(x)|^{q} dx \leq \int \left( \left[ \int|K(x,y)|^{\alpha a}dy \right]^{q/a}\left[ \int|K(x,y)|^{(1-\alpha)c}|v(y)|^{(1-\beta)c}dy\right]^{q/c}||v||_{L^{p}}^{\beta q}\right) dx. $$ Now, in order for us to be able to switch the order of integration, we need $\displaystyle \frac{q}{c} = 1$, so $q = c. \quad (4)$ Therefore, $(3)$ becomes $\displaystyle \beta = 1 - \frac{p}{q} \quad (3^{\prime})$, and $(2)$ becomes $\displaystyle b = \frac{p}{\displaystyle \left( 1 - \frac{p}{q}\right)} = \frac{pq}{q-p} \quad (2^{\prime})$. Substituting $(4)$ and $(2^{\prime})$ into $(1^{\prime})$, we obtain an expression for $a$: $\displaystyle a = \frac{p}{p-1} \quad (5)$ Bounding everything, we obtain $$||u||_{L^{q}}^{q} \leq \sup_{x}\left( \int|K(x,y)|^{\alpha a}dy\right)^{q/a} \cdot \left[\sup_{y}\int |K(x,y)|^{(1-\alpha)c}dx \right] ||v||_{L^{p}}^{p+\beta q}. \quad (6)$$ Notice also that $\displaystyle \frac{q}{a} = 1$, so $$ (6) = \left[ \sup_{x}\int|K(x,y)^{\alpha a}dy\right] \cdot \left[ \sup_{y} \int |K(x,y)|^{(1-\alpha)c}dx \right] \cdot ||v||_{L^{p}}^{p+\beta q}. \quad (6^{\prime})$$ Now, we need $\sup_{x}$, $\sup_{y}$, and each of these kernels to be finite, so choose $\alpha$ so that $\alpha a = (1-\alpha)c$, which implies then that $\displaystyle \alpha = \frac{c}{a+c}$. Then, substituting our values for $a$ and $c$ [$(5)$ and $(4)$], respectively, we obtain that $\alpha = \frac{q}{\frac{p}{p-1}+q} = \frac{q(p-1)}{p+pq-q} \quad (7)$ and that $(1-\alpha) = \frac{p}{p+pq-q}. \quad (7^{\prime})$ So, $\alpha a = \frac{pq}{p+pq-q}$, and $(1-\alpha)c = \frac{pq}{p+pq-q}. \quad (7^{\prime\prime})$ Thus, $(6^{\prime})$ becomes $$ = \left[ \sup_{x}\int |K(x,y)|^{\frac{pq}{p+pq-q}}dy\right] \cdot \left[ \sup_{y} \int |K(x,y)|^{\frac{pq}{p+pq-q}}dx\right]||v||_{L^{p}}^{p+(1-\frac{p}{q})\cdot q}. \quad (8)$$ But, since $\displaystyle p + \left( 1-\frac{p}{q}\right)q = q$, $(8)$ becomes $$ = \left[\sup_{x}\int|K(x,y)|^{\frac{pq}{p+pq-q}}dy\right]\left[ \sup_{y} \int |K(x,y)|^{\frac{pq}{p+pq-q}} dx \right] ||v||_{L^{p}}^{q}$$. Which brings me to my question. Taking $q$th roots, you see that we have the following: $$ ||u||_{L^{q}(\Omega)} \leq \left[\sup_{x}\int|K(x,y)|^{\frac{pq}{p+pq-q}}dy\right]^{1/q}\left[\sup_{y}\int |K(x,y)|^{\frac{pq}{p+pq-q}}dx\right]^{1/q}||v||_{L^{p}}$$, but what I need is: $$ ||u||_{L^{q}(\Omega)} \leq \left[\sup_{x}\int|K(x,y)|^{\frac{pq}{p+pq-q}}dy\right]^{\frac{p+pq-q}{pq}}\left[\sup_{y}\int |K(x,y)|^{\frac{pq}{p+pq-q}}dx\right]^{\frac{p+pq-q}{pq}}||v||_{L^{p}}$$, so that I will have the $||K(x,y)||_{L^{\frac{pq}{pq+p-q}}}$ norms on the RHS that I need. So, what I am hoping someone will tell me is, where did I go wrong in ""misplacing"" these powers? How do I fix this so that I will get the correct norm in my final answer? Thank you in advance! I really would appreciate your help!!",,"['functional-analysis', 'partial-differential-equations']"
67,Proof of compactness of Lipschitz functions,Proof of compactness of Lipschitz functions,,"Consider the set $\mathcal{F}$ of continuous functions on $[0;1]$ with boundary values $$ f(0)=f(1)=0 \qquad \forall f \in \mathcal{F}. $$ Define the metric $d(f,g) = \lVert f-g \rVert_\infty = \sup_{0 \leq x \leq 1} |f(x)-g(x)|$ and the Lipschitz constant $$ L(f) = \sup_{0 \leq x_1 < x_2 \leq 1} \left|\frac{f(x_1)-f(x_2)}{x_1-x_2}\right|. $$ Define the subset of Lipschitz-continuous functions as $\mathcal{L}_M = \left\{ f \in \mathcal{F} \colon L(f) \leq M \right\}$. I want to show that the metric space $(\mathcal{L}_1,d)$ is a compact subset of $(\mathcal{F},d)$. What are the steps to do this? Here is my proof sketch: Prove that $(\mathcal{L}_1,d)$ is totally bounded (easy!) Prove that any sequence in $\mathcal{L}_1$ is equicontinuous. Infer from 1. and 2. by the Arzelà-Ascoli Theorem that $(\mathcal{L}_1,d)$ is relatively compact in the Banach space $(\mathcal{F},d)$ Prove that any Cauchy sequence in $(\mathcal{L}_1,d)$ converges to an element from $\mathcal{L}_1$, i.e., show that $(\mathcal{L}_1,d)$ is complete . Since $(\mathcal{L}_1,d)$ is relatively compact and complete, it is therefore compact. QED. Step 4. gives me headaches. That's because for any Cauchy sequence $(f_n)_n$, the sequence $(L(f_n))_n$ can be any sequence you like (in the unit interval). As a remedy, I could switch to a stronger metric $$ d(f,g) = \lVert f-g \rVert_\infty + \sup_{0 \leq x_1 < x_2 \leq 1} \left|\frac{f(x_1)-f(x_2)}{x_1-x_2}-\frac{g(x_1)-g(x_2)}{x_1-x_2}\right| $$ But then how do I eventually get back to my original metric?","Consider the set $\mathcal{F}$ of continuous functions on $[0;1]$ with boundary values $$ f(0)=f(1)=0 \qquad \forall f \in \mathcal{F}. $$ Define the metric $d(f,g) = \lVert f-g \rVert_\infty = \sup_{0 \leq x \leq 1} |f(x)-g(x)|$ and the Lipschitz constant $$ L(f) = \sup_{0 \leq x_1 < x_2 \leq 1} \left|\frac{f(x_1)-f(x_2)}{x_1-x_2}\right|. $$ Define the subset of Lipschitz-continuous functions as $\mathcal{L}_M = \left\{ f \in \mathcal{F} \colon L(f) \leq M \right\}$. I want to show that the metric space $(\mathcal{L}_1,d)$ is a compact subset of $(\mathcal{F},d)$. What are the steps to do this? Here is my proof sketch: Prove that $(\mathcal{L}_1,d)$ is totally bounded (easy!) Prove that any sequence in $\mathcal{L}_1$ is equicontinuous. Infer from 1. and 2. by the Arzelà-Ascoli Theorem that $(\mathcal{L}_1,d)$ is relatively compact in the Banach space $(\mathcal{F},d)$ Prove that any Cauchy sequence in $(\mathcal{L}_1,d)$ converges to an element from $\mathcal{L}_1$, i.e., show that $(\mathcal{L}_1,d)$ is complete . Since $(\mathcal{L}_1,d)$ is relatively compact and complete, it is therefore compact. QED. Step 4. gives me headaches. That's because for any Cauchy sequence $(f_n)_n$, the sequence $(L(f_n))_n$ can be any sequence you like (in the unit interval). As a remedy, I could switch to a stronger metric $$ d(f,g) = \lVert f-g \rVert_\infty + \sup_{0 \leq x_1 < x_2 \leq 1} \left|\frac{f(x_1)-f(x_2)}{x_1-x_2}-\frac{g(x_1)-g(x_2)}{x_1-x_2}\right| $$ But then how do I eventually get back to my original metric?",,"['functional-analysis', 'continuity', 'compactness']"
68,Question about Hahn-Banach theorem,Question about Hahn-Banach theorem,,"Let $(X,\|\cdot\|_1)$ and $(Y,\|\cdot\|_2)$ be normed spaces, and $X\subset Y$. If each $f\in (X,\|\cdot\|_1)^\ast$ extends to a bounded linear functional in $(Y,\|\cdot\|_2)^\ast$ with same norm, then $(X,\|\cdot\|_1)$ is a subspace of $(Y,\|\cdot\|_2)$, i.e., for all $x\in X$, $\|x\|_1=\|x\|_2$. I only proved that $\|x\|_1\leq\|x\|_2$ for all $x\in X$. I am in a difficult condition to prove $\|x\|_1\geq\|x\|_2$ for all $x\in X$. Thanks a lot.","Let $(X,\|\cdot\|_1)$ and $(Y,\|\cdot\|_2)$ be normed spaces, and $X\subset Y$. If each $f\in (X,\|\cdot\|_1)^\ast$ extends to a bounded linear functional in $(Y,\|\cdot\|_2)^\ast$ with same norm, then $(X,\|\cdot\|_1)$ is a subspace of $(Y,\|\cdot\|_2)$, i.e., for all $x\in X$, $\|x\|_1=\|x\|_2$. I only proved that $\|x\|_1\leq\|x\|_2$ for all $x\in X$. I am in a difficult condition to prove $\|x\|_1\geq\|x\|_2$ for all $x\in X$. Thanks a lot.",,"['functional-analysis', 'operator-theory', 'operator-algebras']"
69,An exercise of positive element in C*-algebra,An exercise of positive element in C*-algebra,,"Let $A$ be a unital C*-algebra and $\{b_{n}\}$ be a positive invertible sequence in $A$. If $||1_{A}-b_{n}||\rightarrow 0$, can we conclude $||1_{A}-b_{n}^{-\frac{1}{2}}||\rightarrow 0$ ?","Let $A$ be a unital C*-algebra and $\{b_{n}\}$ be a positive invertible sequence in $A$. If $||1_{A}-b_{n}||\rightarrow 0$, can we conclude $||1_{A}-b_{n}^{-\frac{1}{2}}||\rightarrow 0$ ?",,"['functional-analysis', 'operator-theory', 'operator-algebras', 'c-star-algebras']"
70,Arveson's Extension Theorem in C*-algebra,Arveson's Extension Theorem in C*-algebra,,"I am reading a book C*-algebra and finite-Dimensional Approximations. There are two conclusions (in the book) below. Corollary 1.5.16. Let $E\subset A$ be an operator subsystem and $\phi: E \rightarrow M_{n}(C)$ be a completely positive map. THen $\phi$ extends to a completely positive map $A \rightarrow B(H)$.   $~$($M_{n}(C)$ denotes the sets of all complex matrix.) Theorem 1.6.1 Let $A$ be a unital C*-algebra and $E\subset A$ be an operator subsystem. Then, every contractive completely positive map $\phi:E\rightarrow B(H)$ extends to a contractive completely positive map $\bar{\phi}: A\rightarrow B(H)$. Proof. Let $P_{i}\in B(H)$ be an increasing net of finite-rank projections which converge to the identity in the strong operator topology. For each $i$, we regard the contractive completely positive map $\phi_{i}: E \rightarrow P_{i}B(H)P_{i}$, $\phi_{i}(e)=P_{i}\phi(e)P_{ i}$ as taking values in a matrix algebra. Thus , by Corollary 1.5.16, we may assume that each $\phi_{i}$ is actually defined on all of $A$. Now we regard $\phi_{i}$ as taking values in $B(H)$ and apply compactness of the unit ball of $B(A,B(H))$ in the point-ultraweak topology to find a cluster point $\Phi:A:\rightarrow B(H)$. It is readily verified that $\Phi$ is completely positive and  extends to $\phi$. My question is how to explain take values of $\phi_{i}$ in a matrix algebra and, meanwhile, take values in $B(H)$ in the proof? ($B(H)$ denotes all the linear bounded operators on $H$)","I am reading a book C*-algebra and finite-Dimensional Approximations. There are two conclusions (in the book) below. Corollary 1.5.16. Let $E\subset A$ be an operator subsystem and $\phi: E \rightarrow M_{n}(C)$ be a completely positive map. THen $\phi$ extends to a completely positive map $A \rightarrow B(H)$.   $~$($M_{n}(C)$ denotes the sets of all complex matrix.) Theorem 1.6.1 Let $A$ be a unital C*-algebra and $E\subset A$ be an operator subsystem. Then, every contractive completely positive map $\phi:E\rightarrow B(H)$ extends to a contractive completely positive map $\bar{\phi}: A\rightarrow B(H)$. Proof. Let $P_{i}\in B(H)$ be an increasing net of finite-rank projections which converge to the identity in the strong operator topology. For each $i$, we regard the contractive completely positive map $\phi_{i}: E \rightarrow P_{i}B(H)P_{i}$, $\phi_{i}(e)=P_{i}\phi(e)P_{ i}$ as taking values in a matrix algebra. Thus , by Corollary 1.5.16, we may assume that each $\phi_{i}$ is actually defined on all of $A$. Now we regard $\phi_{i}$ as taking values in $B(H)$ and apply compactness of the unit ball of $B(A,B(H))$ in the point-ultraweak topology to find a cluster point $\Phi:A:\rightarrow B(H)$. It is readily verified that $\Phi$ is completely positive and  extends to $\phi$. My question is how to explain take values of $\phi_{i}$ in a matrix algebra and, meanwhile, take values in $B(H)$ in the proof? ($B(H)$ denotes all the linear bounded operators on $H$)",,"['functional-analysis', 'operator-algebras', 'c-star-algebras', 'von-neumann-algebras']"
71,Completeness and separability of $B(X)$ (bounded linear operators on $X$),Completeness and separability of  (bounded linear operators on ),B(X) X,"Assume $X$ is a separable Banach space with norm $|| \cdot||$. Consider $\{f_n\}_{n \in N}$ a countable dense subset of $X$ and equip $B(X)$ (bounded linear operators on $X$) with the following metric: \begin{align} & d(A,B)=\sum_{n=0}^\infty 2^{-n} (1+||f_n||)^{-1} || A f_n-B f_n || \end{align} Does this metric make $B(X)$ complete and separable? PS: completeness seems quite easy to prove. The interesting part is separability. PS2: below it is shown that $B_1(X)$ (the unit ball of $B(X)$ in the operator norm metric) is separable. What about the whole $B(X)$? http://thales.doa.fmph.uniba.sk/sleziak/texty/rozne/pozn/books/kechrisexercises.pdf","Assume $X$ is a separable Banach space with norm $|| \cdot||$. Consider $\{f_n\}_{n \in N}$ a countable dense subset of $X$ and equip $B(X)$ (bounded linear operators on $X$) with the following metric: \begin{align} & d(A,B)=\sum_{n=0}^\infty 2^{-n} (1+||f_n||)^{-1} || A f_n-B f_n || \end{align} Does this metric make $B(X)$ complete and separable? PS: completeness seems quite easy to prove. The interesting part is separability. PS2: below it is shown that $B_1(X)$ (the unit ball of $B(X)$ in the operator norm metric) is separable. What about the whole $B(X)$? http://thales.doa.fmph.uniba.sk/sleziak/texty/rozne/pozn/books/kechrisexercises.pdf",,"['functional-analysis', 'metric-spaces', 'operator-theory', 'banach-spaces']"
72,"The space of continuous functions $C([0,1])$ is not complete in the $L^2$ norm",The space of continuous functions  is not complete in the  norm,"C([0,1]) L^2","I am trying to prove that under the $L^2$ norm, $C([0,1])$ does not give rise to a  complete metric space. To do this I am trying to find a Cauchy Sequence which does not converge in $C([0,1])$ . As a template (on $C([a,b])$ ) I am led to believe the following is Cauchy: $$f_n (x) = \begin{cases}  1 &\mbox{if } 0 \leq x \leq \frac{1}{2} \\  1 - 2n(x-\frac{1}{2}) & \mbox{if } \frac{1}{2}\leq x \leq \frac{1}{2n} + \frac{1}{2}\\ 0 & \mbox{if } \frac{1}{2n} + \frac{1}{2} \leq x \leq 1  \end{cases} 	$$ But I am struggling to show this is Cauchy, I have tried integrating from 0 to 1 but this is giving a very nasty integral and I was wondering if anyone has a better method?","I am trying to prove that under the norm, does not give rise to a  complete metric space. To do this I am trying to find a Cauchy Sequence which does not converge in . As a template (on ) I am led to believe the following is Cauchy: But I am struggling to show this is Cauchy, I have tried integrating from 0 to 1 but this is giving a very nasty integral and I was wondering if anyone has a better method?","L^2 C([0,1]) C([0,1]) C([a,b]) f_n (x) = \begin{cases} 
1 &\mbox{if } 0 \leq x \leq \frac{1}{2} \\ 
1 - 2n(x-\frac{1}{2}) & \mbox{if } \frac{1}{2}\leq x \leq \frac{1}{2n} + \frac{1}{2}\\
0 & \mbox{if } \frac{1}{2n} + \frac{1}{2} \leq x \leq 1
 \end{cases} 	","['real-analysis', 'functional-analysis', 'inner-products', 'lp-spaces', 'cauchy-sequences']"
73,Automorphism of $W^*$ algebra,Automorphism of  algebra,W^*,"Let $\mathfrak{A}$ be von Neumann algebra. It is in particular $C^*$ algebra. Is it true that every $*$-isomorphism of $\mathfrak{A}$ is also $W^*-$isomorphism? (Note that every $*$-isomorphism of $C^*$ algebra is $C^*-$isomorphism). I'm especially interested in application to concrete von Neumann algebra (weakly closed subalgebra of $B(\mathcal{H})$ - the algebra of bounded operators on Hilbert space $\mathcal{H}$). Is it true that any isomorphism of this algebra is automatically continuous in weak, strong and ultraweak operator topologies on $\mathcal{H}$.","Let $\mathfrak{A}$ be von Neumann algebra. It is in particular $C^*$ algebra. Is it true that every $*$-isomorphism of $\mathfrak{A}$ is also $W^*-$isomorphism? (Note that every $*$-isomorphism of $C^*$ algebra is $C^*-$isomorphism). I'm especially interested in application to concrete von Neumann algebra (weakly closed subalgebra of $B(\mathcal{H})$ - the algebra of bounded operators on Hilbert space $\mathcal{H}$). Is it true that any isomorphism of this algebra is automatically continuous in weak, strong and ultraweak operator topologies on $\mathcal{H}$.",,"['functional-analysis', 'operator-theory', 'operator-algebras', 'c-star-algebras', 'von-neumann-algebras']"
74,If $T^2=TT^*$ then can i conclude that $T=T^*$?,If  then can i conclude that ?,T^2=TT^* T=T^*,let $B(H)$ be all bounded operator on Hilbert space H. If $T^2=TT^*$ then can i conclude that $T=T^*$? I think this is true if T is one to one. Can i construct an example that shows it is not true for any T?,let $B(H)$ be all bounded operator on Hilbert space H. If $T^2=TT^*$ then can i conclude that $T=T^*$? I think this is true if T is one to one. Can i construct an example that shows it is not true for any T?,,"['functional-analysis', 'operator-theory']"
75,"Given a Banach space $X$, are weak$^*$ bounded subsets of the dual space $X '$ also strongly bounded (with respect to the usual norm in $X '$)?","Given a Banach space , are weak bounded subsets of the dual space  also strongly bounded (with respect to the usual norm in )?",X ^* X ' X ',"Some related facts I already know: 1) In a Banach space $X$, weakly bounded sets are strongly bounded and vice-versa (Thm 3.18 - "" Functional Analysis "", Rudin); 2) From 1, it follows that my question is equivalent to proving that weak$^*$ bounded sets are bounded with respect to the weak topology of the dual $X'$. 3) If X is reflexive, then 2 is easy to show and then my question is true. But reflexiveness is really necessary?","Some related facts I already know: 1) In a Banach space $X$, weakly bounded sets are strongly bounded and vice-versa (Thm 3.18 - "" Functional Analysis "", Rudin); 2) From 1, it follows that my question is equivalent to proving that weak$^*$ bounded sets are bounded with respect to the weak topology of the dual $X'$. 3) If X is reflexive, then 2 is easy to show and then my question is true. But reflexiveness is really necessary?",,"['functional-analysis', 'banach-spaces', 'topological-vector-spaces']"
76,The importance of basis constant,The importance of basis constant,,"Let $X$ be a Banach space and let $(e_n)_{n=1}^{\infty}$ be a Schauder basis for $X$. Let us denote the natural projections associated with $(e_n)_{n=1}^{\infty}$ by $(S_n)_{n=1}^{\infty}$. Then by uniform boundedness principle one has $$\sup_n||S_n||<\infty.$$ The number $K=\sup_n||S_n||$ is called basis constant. At this point, I have a question. What is the importance of basis constant? What happens when $K=1$, i.e; what happens when the basis is monotone? Is there any condition on $K$ to observe an unconditional basis?","Let $X$ be a Banach space and let $(e_n)_{n=1}^{\infty}$ be a Schauder basis for $X$. Let us denote the natural projections associated with $(e_n)_{n=1}^{\infty}$ by $(S_n)_{n=1}^{\infty}$. Then by uniform boundedness principle one has $$\sup_n||S_n||<\infty.$$ The number $K=\sup_n||S_n||$ is called basis constant. At this point, I have a question. What is the importance of basis constant? What happens when $K=1$, i.e; what happens when the basis is monotone? Is there any condition on $K$ to observe an unconditional basis?",,"['functional-analysis', 'banach-spaces']"
77,find a weak solution in an intersection of Sobolev spaces,find a weak solution in an intersection of Sobolev spaces,,"In using lax-milgram to find a weak solution in an intersection of sobolev spaces the weak solution for  $$ -\Delta^2 u = f \in L^2(U)\\ \\ u|_{\partial U}=\Delta u|_{\partial U} = 0 $$ was discussed, I have a question about the week solution of  $$ \Delta^2 u + u = f \in L^2(U)\\ \\ u|_{\partial U}=\Delta u|_{\partial U} = 0 $$ I think I should use coupled elliptic PDE theory. Any hint or suggestion is helpful for me. In advanced thanks from anyone who tries to help me.","In using lax-milgram to find a weak solution in an intersection of sobolev spaces the weak solution for  $$ -\Delta^2 u = f \in L^2(U)\\ \\ u|_{\partial U}=\Delta u|_{\partial U} = 0 $$ was discussed, I have a question about the week solution of  $$ \Delta^2 u + u = f \in L^2(U)\\ \\ u|_{\partial U}=\Delta u|_{\partial U} = 0 $$ I think I should use coupled elliptic PDE theory. Any hint or suggestion is helpful for me. In advanced thanks from anyone who tries to help me.",,"['functional-analysis', 'partial-differential-equations', 'hilbert-spaces', 'sobolev-spaces']"
78,"Adjoint of resolvent of self-adjoint, densely-defined operator on a Hilbert space","Adjoint of resolvent of self-adjoint, densely-defined operator on a Hilbert space",,"Let $H$ be a Hilbert space, $T=T^*$ a densely-defined linear operator on $H$. Denote the resolvent set of $T$ as $\rho(T)=\{\lambda\in\mathbb{C}~|~T-\lambda$ has bounded, everywhere-defined inverse}, and define the resolvent of $T$ at $\lambda$ to be the bounded, everywhere-defined operator $R_\lambda=(T-\lambda)^{-1}$ $(\lambda\in\rho(T))$. How would I set about proving that $(R_\lambda)^* = R_{\smash{\overline{\lambda}}}$? I've been playing around with the inner product and the definition of $R_\lambda$ and I'm getting nowhere, so any hints of what sort of calculations to attempt would be greatly appreciated.","Let $H$ be a Hilbert space, $T=T^*$ a densely-defined linear operator on $H$. Denote the resolvent set of $T$ as $\rho(T)=\{\lambda\in\mathbb{C}~|~T-\lambda$ has bounded, everywhere-defined inverse}, and define the resolvent of $T$ at $\lambda$ to be the bounded, everywhere-defined operator $R_\lambda=(T-\lambda)^{-1}$ $(\lambda\in\rho(T))$. How would I set about proving that $(R_\lambda)^* = R_{\smash{\overline{\lambda}}}$? I've been playing around with the inner product and the definition of $R_\lambda$ and I'm getting nowhere, so any hints of what sort of calculations to attempt would be greatly appreciated.",,"['functional-analysis', 'operator-theory', 'hilbert-spaces', 'spectral-theory']"
79,non separable implies an uncountable set with lower bounded distances?,non separable implies an uncountable set with lower bounded distances?,,"Given a Banach space the only way i've seen to show that it is not separable is to show that there is a more than countable set $A$ and a costant $c>0$ such that $|a_1-a_2|>c, \forall a_1 \neq a_2 \in A$(in this way you show that $l^{\infty}$ is not separable). My question is: is it true the opposite implication? That is Question: Given X a non separable Banach space, is it true that there is $A$ more than countable such that there's $c>0$ so that  $|a_1-a_2|>c, \forall a_1 \neq a_2 \in A$? Thanks! Bye","Given a Banach space the only way i've seen to show that it is not separable is to show that there is a more than countable set $A$ and a costant $c>0$ such that $|a_1-a_2|>c, \forall a_1 \neq a_2 \in A$(in this way you show that $l^{\infty}$ is not separable). My question is: is it true the opposite implication? That is Question: Given X a non separable Banach space, is it true that there is $A$ more than countable such that there's $c>0$ so that  $|a_1-a_2|>c, \forall a_1 \neq a_2 \in A$? Thanks! Bye",,['functional-analysis']
80,Compactness with Ascoli-Arzelà?,Compactness with Ascoli-Arzelà?,,"Let    $$ K:= \{x: [0,T] \to \mathbb R: x^{\prime}(t)=x^2(t), \, 0\le x(T) \le 1\}. $$   Prove that $K$ is a compact subset of $C([0,T],\mathbb R)$. My idea is to use Ascoli-Arzelà thm. First of all, by some routine calculations I have found that  $$ K= \left\{x:[0,T] \to \mathbb R: x(t)=\frac{x(T)}{x(T)(T-t)+1}, \, 0\le x(T) \le 1\right\} $$ Then I have shown that $K$ is equibounded : $$ \vert x(t)\vert\le\left\vert \frac{x(T)}{(T-t)x(T)+1}\right\vert \le x(T) \le 1 $$ for every $t \in[0,T]$ and for every $x(\cdot) \in K$. $K$ is equicontinuous : indeed the following holds true $$ \vert x(t_1)-x(t_2) \vert \le \vert t_1 -t_2 \vert  $$ for every $t_1,t_2 \in[0,T]$ and for every $x(\cdot) \in K$. Finally I have to show that $K$ is closed: let us take $x_n \to x$ uniformly s.t. $x^{\prime}_n = x_n^2$ for every $n$. Then $x_n^2 \to x^2$ uniformly; to sum up we have $x_n \to x$ uniformly; $x^{\prime}_n = x_n^2 \to x^2$ uniformly. Hence $x$ is differentiable and $x^{\prime}=x^2$. Is my proof correct? Thanks in advance.","Let    $$ K:= \{x: [0,T] \to \mathbb R: x^{\prime}(t)=x^2(t), \, 0\le x(T) \le 1\}. $$   Prove that $K$ is a compact subset of $C([0,T],\mathbb R)$. My idea is to use Ascoli-Arzelà thm. First of all, by some routine calculations I have found that  $$ K= \left\{x:[0,T] \to \mathbb R: x(t)=\frac{x(T)}{x(T)(T-t)+1}, \, 0\le x(T) \le 1\right\} $$ Then I have shown that $K$ is equibounded : $$ \vert x(t)\vert\le\left\vert \frac{x(T)}{(T-t)x(T)+1}\right\vert \le x(T) \le 1 $$ for every $t \in[0,T]$ and for every $x(\cdot) \in K$. $K$ is equicontinuous : indeed the following holds true $$ \vert x(t_1)-x(t_2) \vert \le \vert t_1 -t_2 \vert  $$ for every $t_1,t_2 \in[0,T]$ and for every $x(\cdot) \in K$. Finally I have to show that $K$ is closed: let us take $x_n \to x$ uniformly s.t. $x^{\prime}_n = x_n^2$ for every $n$. Then $x_n^2 \to x^2$ uniformly; to sum up we have $x_n \to x$ uniformly; $x^{\prime}_n = x_n^2 \to x^2$ uniformly. Hence $x$ is differentiable and $x^{\prime}=x^2$. Is my proof correct? Thanks in advance.",,"['functional-analysis', 'ordinary-differential-equations', 'compactness', 'proof-verification']"
81,Intersection of Projections on Hilbert space,Intersection of Projections on Hilbert space,,"Let $H$ be a Hilbert space, on which $P,Q$ be projection operators. Let $S:=\mathcal{R}(P)\cap\mathcal{R}(Q)$ be the intersection of ranges, then it is easy to show the orthogonal complement $S^{\bot}$ is an invariant subspace of $PQP$. The question is how to show $||PQP|_{S^{\bot}}||<1$ , if $S^{\bot}$ is finite-dimensional? Sorry to have modified the problem. I made mistake and found out that if $PQ=QP$, which means $PQ$ is also projection on $H$, then $PQP$ shall vanish, but generally it does not, and should have the above norm estimate but I am not sure how to get it anyway.","Let $H$ be a Hilbert space, on which $P,Q$ be projection operators. Let $S:=\mathcal{R}(P)\cap\mathcal{R}(Q)$ be the intersection of ranges, then it is easy to show the orthogonal complement $S^{\bot}$ is an invariant subspace of $PQP$. The question is how to show $||PQP|_{S^{\bot}}||<1$ , if $S^{\bot}$ is finite-dimensional? Sorry to have modified the problem. I made mistake and found out that if $PQ=QP$, which means $PQ$ is also projection on $H$, then $PQP$ shall vanish, but generally it does not, and should have the above norm estimate but I am not sure how to get it anyway.",,['functional-analysis']
82,Algebraic and topological complements in a Hilbert space,Algebraic and topological complements in a Hilbert space,,"Every closed subspace of a Hilbert space has a topological complement, namely its orthogonal complement.  I'm wondering if every algebraic complement of a closed subspace of a Hilbert space is automatically a topological complement. In other words, if $C$ is closed, $V$ and $C$ have trivial intersection, and $V+C$ is the whole space, then is $V$ automatically closed? Thank you for your help!","Every closed subspace of a Hilbert space has a topological complement, namely its orthogonal complement.  I'm wondering if every algebraic complement of a closed subspace of a Hilbert space is automatically a topological complement. In other words, if $C$ is closed, $V$ and $C$ have trivial intersection, and $V+C$ is the whole space, then is $V$ automatically closed? Thank you for your help!",,"['functional-analysis', 'hilbert-spaces']"
83,Minimization problem as PDE,Minimization problem as PDE,,"In the article ""An Image Interpolation Scheme for Repetitive Structures"" Luong, Ledda and Philips propose the following approach to denoising digital image. They consider that regularized total variation minimization problem $$\hat I(x)=\arg\min_{I(x)}[f(\nabla I(x))+\lambda\cdot g(H*I(x)-I_0(x))] \tag{3}$$ can be transformed to the partial differential equation: $$\frac{\partial I(x, t)}{\partial t}=f_{I}' (\nabla I(x, t))+\lambda \cdot g_{I}'(H*I(x, t)-I(x, 0))) \tag{4}$$ I can't find foundation of such transformation and I can't agree with the equivalence of these two problems. Moreover the researchers believe appropriate to take $f(\cdot)=||\cdot||_{L^2}$ (or maybe $||\cdot||_{L^1}$) and $g(\cdot)=||\cdot||_{L^1}$. And I can't understand how they're going to find corresponding derivatives in such case. Could you help me understand these considerations?","In the article ""An Image Interpolation Scheme for Repetitive Structures"" Luong, Ledda and Philips propose the following approach to denoising digital image. They consider that regularized total variation minimization problem $$\hat I(x)=\arg\min_{I(x)}[f(\nabla I(x))+\lambda\cdot g(H*I(x)-I_0(x))] \tag{3}$$ can be transformed to the partial differential equation: $$\frac{\partial I(x, t)}{\partial t}=f_{I}' (\nabla I(x, t))+\lambda \cdot g_{I}'(H*I(x, t)-I(x, 0))) \tag{4}$$ I can't find foundation of such transformation and I can't agree with the equivalence of these two problems. Moreover the researchers believe appropriate to take $f(\cdot)=||\cdot||_{L^2}$ (or maybe $||\cdot||_{L^1}$) and $g(\cdot)=||\cdot||_{L^1}$. And I can't understand how they're going to find corresponding derivatives in such case. Could you help me understand these considerations?",,"['functional-analysis', 'partial-differential-equations', 'optimization', 'image-processing', 'gradient-flows']"
84,A basic question on Type and Cotype theory,A basic question on Type and Cotype theory,,"I'm studying basic theory of type and cotype of banach spaces, and I have a simple question. I'm using the definition using averages. All Banach spaces have type 1, that was easy to prove, using the triangle inequality. But I'm having a hard time trying to show that all Banach spaces have cotype $\infty$. What I'm trying to show is that there existsc $C>0$ such that, for every $x_1, \dotsc, x_n$  in a Banach space $X$, $$\left( \frac {{\displaystyle \sum\limits_{\varepsilon_i = \pm 1}} \lVert \sum^n_{i=1} \varepsilon_i x_i\rVert} {2^n} \right)  \ge  C \max_{1\le i \le n} \lVert x_i \rVert $$ How is it done ? This is supposed to be trivial, as the literature keeps telling me ""it's easy to see"". Thanks !","I'm studying basic theory of type and cotype of banach spaces, and I have a simple question. I'm using the definition using averages. All Banach spaces have type 1, that was easy to prove, using the triangle inequality. But I'm having a hard time trying to show that all Banach spaces have cotype $\infty$. What I'm trying to show is that there existsc $C>0$ such that, for every $x_1, \dotsc, x_n$  in a Banach space $X$, $$\left( \frac {{\displaystyle \sum\limits_{\varepsilon_i = \pm 1}} \lVert \sum^n_{i=1} \varepsilon_i x_i\rVert} {2^n} \right)  \ge  C \max_{1\le i \le n} \lVert x_i \rVert $$ How is it done ? This is supposed to be trivial, as the literature keeps telling me ""it's easy to see"". Thanks !",,"['analysis', 'functional-analysis', 'inequality', 'banach-spaces']"
85,"about weak convergence in $L^{2}(0,T;H)$",about weak convergence in,"L^{2}(0,T;H)","I am trying to do an exercise and if the  affirmation below is true, my exercise is done . This is the affirmation : Affirmation :  Let $H$ a Hilbert space and suppose $u_k$ converges weakly to $u$ in  $L^{2}(0,T;H)$. Suppose that $\operatorname{ess sup}_{ 0 \leq t \leq T} \ || u_k (t)|| \leq C$. Then $u_k(t) $ converges weakly to $u(t)$ for every $t$. I am trying  to do, but nothing...  . Someone can give me  a hint ? (please dont give me a complete answer , just a hint ^^ ) thanks in advance ^^","I am trying to do an exercise and if the  affirmation below is true, my exercise is done . This is the affirmation : Affirmation :  Let $H$ a Hilbert space and suppose $u_k$ converges weakly to $u$ in  $L^{2}(0,T;H)$. Suppose that $\operatorname{ess sup}_{ 0 \leq t \leq T} \ || u_k (t)|| \leq C$. Then $u_k(t) $ converges weakly to $u(t)$ for every $t$. I am trying  to do, but nothing...  . Someone can give me  a hint ? (please dont give me a complete answer , just a hint ^^ ) thanks in advance ^^",,"['functional-analysis', 'measure-theory', 'partial-differential-equations', 'hilbert-spaces', 'weak-convergence']"
86,An counterexample of Hahn-Banach theorem in a topological vector space,An counterexample of Hahn-Banach theorem in a topological vector space,,Problem : Give an example of a TVS $\mathcal{X}$ that is not locally convex and a subspace $\mathcal{Y}$ of $\mathcal{X}$ such that there is a continuous linear functional $f$ on $\mathcal{Y}$ with no continuous extension to $\mathcal{X}$ I think this problem means that Hahn-Banach theorem ( LCS version ) may not hold in a TVS. But I can't find a counterexample..,Problem : Give an example of a TVS $\mathcal{X}$ that is not locally convex and a subspace $\mathcal{Y}$ of $\mathcal{X}$ such that there is a continuous linear functional $f$ on $\mathcal{Y}$ with no continuous extension to $\mathcal{X}$ I think this problem means that Hahn-Banach theorem ( LCS version ) may not hold in a TVS. But I can't find a counterexample..,,"['functional-analysis', 'topological-vector-spaces', 'locally-convex-spaces']"
87,Definition of simple spectrum,Definition of simple spectrum,,"From the book ""Spinning Tops"" by Audin, given Lax equation $[A_{\lambda},B_{\lambda}]$ where $\lambda$ is a parameter (so called spectral parameter), she claims that we have spectral curve $P(\lambda,\nu)=0$ where $P(\lambda,\nu)$ is a characteristic polynomial of $A_{\lambda}$ . Then, she talks about when $A_{\lambda}$ has a simple spectrum. I tried to look for definition of it, but I couldn't find it. Can you please tell me what does it mean for a spectrum to be simple?","From the book ""Spinning Tops"" by Audin, given Lax equation where is a parameter (so called spectral parameter), she claims that we have spectral curve where is a characteristic polynomial of . Then, she talks about when has a simple spectrum. I tried to look for definition of it, but I couldn't find it. Can you please tell me what does it mean for a spectrum to be simple?","[A_{\lambda},B_{\lambda}] \lambda P(\lambda,\nu)=0 P(\lambda,\nu) A_{\lambda} A_{\lambda}","['functional-analysis', 'algebraic-curves', 'classical-mechanics']"
88,Generalized eigenspaces of a compact operator are finite dimensional,Generalized eigenspaces of a compact operator are finite dimensional,,"Let $T : H\rightarrow H$ be a compact operator on a Hilbert space $H$. Say that $\lambda \in \mathbb C$ is a generalized eigenvalue of $T$ if there is some $n \geq 1$ such that $(\lambda - T)^n$ is not injective. Define the generalized eigenspace corresponding to $\lambda$ to be the space $V$ of vectors $x\in H$ such that $(\lambda - T)^n x = 0$ for some $n$. I am trying to show that $V$ is necessarily finite dimensional if $\lambda\not=0$. I can show that the kernel of $(\lambda  - T)^n$ is finite dimensional for each $n$. But, I am having trouble extending this to the union of all of these kernels. Does anyone have any suggestions?","Let $T : H\rightarrow H$ be a compact operator on a Hilbert space $H$. Say that $\lambda \in \mathbb C$ is a generalized eigenvalue of $T$ if there is some $n \geq 1$ such that $(\lambda - T)^n$ is not injective. Define the generalized eigenspace corresponding to $\lambda$ to be the space $V$ of vectors $x\in H$ such that $(\lambda - T)^n x = 0$ for some $n$. I am trying to show that $V$ is necessarily finite dimensional if $\lambda\not=0$. I can show that the kernel of $(\lambda  - T)^n$ is finite dimensional for each $n$. But, I am having trouble extending this to the union of all of these kernels. Does anyone have any suggestions?",,"['functional-analysis', 'operator-theory', 'eigenvalues-eigenvectors']"
89,Can the $0$-norm represent determinism?,Can the -norm represent determinism?,0,"In Scott Aaronson's Quantum Computing since Democritus , he presents classical probability theory as based on the $1$-norm, and QM as based on the $2$-norm. Call $\{v_1,\ldots,v_N\}$ a unit vector in the $p$-norm if $|v_1|^{\ p}+\cdots+|v_N|^{\ p}=1$ The slide below is from a presentation of his. Now, he seems to claim that the $1$-norm and the $2$-norm are the only options here, although earlier in the book he allowed for three choices: (1) determinism, (2) classical probabilities, or (3) quantum mechanics. My question is: Would it be natural to let determinism be simply based on the $0$-norm? Is this problematic? Wouldn't the definition $0^0=0$ (for this purpose) and $p_i\in\{0,1\}$ suffice? If so, what would be the equivalent to ""probability vector"" and ""amplitude vector"" be called? (""Indicator vector""??)","In Scott Aaronson's Quantum Computing since Democritus , he presents classical probability theory as based on the $1$-norm, and QM as based on the $2$-norm. Call $\{v_1,\ldots,v_N\}$ a unit vector in the $p$-norm if $|v_1|^{\ p}+\cdots+|v_N|^{\ p}=1$ The slide below is from a presentation of his. Now, he seems to claim that the $1$-norm and the $2$-norm are the only options here, although earlier in the book he allowed for three choices: (1) determinism, (2) classical probabilities, or (3) quantum mechanics. My question is: Would it be natural to let determinism be simply based on the $0$-norm? Is this problematic? Wouldn't the definition $0^0=0$ (for this purpose) and $p_i\in\{0,1\}$ suffice? If so, what would be the equivalent to ""probability vector"" and ""amplitude vector"" be called? (""Indicator vector""??)",,"['functional-analysis', 'probability-theory', 'normed-spaces', 'quantum-mechanics']"
90,Proving Bishop's Theorem using Krein-Milman Theorem,Proving Bishop's Theorem using Krein-Milman Theorem,,"I am studying the proof of Bishop's theorem (generalization of Stone-Weierstrass) in Rudin's Functional Analysis 2nd edition.  He make the following statement on the bottom of page 122, ""Since $\mu \to \int g \, d\mu$ is a weak$^*$-continuous function on K, the Krein-Milman theorem implies that $\int g \, d\mu=0$ for every $\mu$ in $K$."" I do not understand why we know that is a weak$^*$-continuous function nor do I see why the Krein-Milman theorem implies that statement.  I think one or both these things might have to do with the fact that K is weak$^*$-compact. Thanks for the help!","I am studying the proof of Bishop's theorem (generalization of Stone-Weierstrass) in Rudin's Functional Analysis 2nd edition.  He make the following statement on the bottom of page 122, ""Since $\mu \to \int g \, d\mu$ is a weak$^*$-continuous function on K, the Krein-Milman theorem implies that $\int g \, d\mu=0$ for every $\mu$ in $K$."" I do not understand why we know that is a weak$^*$-continuous function nor do I see why the Krein-Milman theorem implies that statement.  I think one or both these things might have to do with the fact that K is weak$^*$-compact. Thanks for the help!",,"['analysis', 'functional-analysis']"
91,Weighted $L^2$ Estimates for Domains $\Omega\subseteq\mathbb{C}$,Weighted  Estimates for Domains,L^2 \Omega\subseteq\mathbb{C},"EDIT: After mrf 's comment below and some discussion with my instructor for the course it was decided that the below was not really an issue. Namely, I went into reading this lecture with the notion that we were going to solve the $\bar{\partial}$ equation--that this was our main goal. In other words, in the below we were mainly $f$ focused and not $\phi$ focused. In all actuality, it is the other way around. We were supposed to know that the $\bar{\partial}$ equation always has distributional solutions and that, in fact, we were really interested in finding solutions to $\bar{\partial}u=f$ with $u$ having controlled $\|\cdot\|_\phi$ norm. This begs two questions though that I would love if someone may be able to fill in: This is the one-dimensional case of Hormander's Theorem. Can someone give me intuition about why as an algebraic/differential geometer having Hormander's theorem is such a huge deal (as it is made out to be). mrf says that the below theorems actually show that $\bar{\partial}u=f$ is always solvable for any $f$ since we can always find (given a fixed $f$) a $C^2(\Omega,\mathbb{R})$ subharmonic function $\phi$ for which $\displaystyle \int_\Omega\frac{|f|^2}{\Delta\phi}e^{-\phi}$ is finite (we need finiteness to actually show a solution exists). Is there an easy way to see why such a function $\phi$ always exists for a given $f$? Thanks! I am currently reading the Park City lecture notes on Analytic and Algebraic Geometry ( this book) and am really confused by some implicit assumptions made in the first lecture of the first minicourse (Lecture 1 of Bo Berndtsson's ""An Introduction to Things $\overline{\partial}$""). Let me explain some of the background to the issue I am having. Let $\phi\in C^2(\Omega,\mathbb{R})$ be subharmonic and define the inner product: $$\langle f,g\rangle_\phi=\int_\Omega f\bar{g}e^{-\phi}$$ and the norm $\|\alpha\|_\phi^2=\langle \alpha,\alpha\rangle_\phi$. We then define $\bar{\partial}^\ast_\phi$ to be the adjoint of $\bar{\phi}$ with respect to $\langle,\rangle_\phi$. Explicitly one can show that $$\bar{\partial}^\ast_\phi\alpha=-e^{\phi}\frac{\partial}{\partial z}\left(e^{-\phi}\alpha\right)$$ So, now we are trying to follow the proof of Theorem 1.1.3 in the book which is stated as follows: Theorem 1.1.3 Let $\Omega\subseteq\mathbb{C}$ be a domain and suppose that $\phi\in C^2(\Omega,\mathbb{R})$ which is subharmonic. Then, for any $f\in L^2_{\text{loc}}(\Omega)$ there is a distributional solution $u$ to $\displaystyle \frac{\partial u}{\partial \bar{z}}=f$ subject to    $$\int_\Omega |u|^2 e^{-\phi}\leqslant \int_\Omega \frac{|f|^2}{\Delta \phi}e^{-\phi}$$ The author states that the theorem follows from the following three propositions: Proposition 1.1.1 Given $f$ there exists a distributional solution to $\displaystyle \frac{\partial u}{\partial\bar{z}}$ satisfying    $$\|u\|_\phi^2\leqslant C\quad \mathbf{(1.3)}$$   for some $C>0$ if and only if the estimate   $$\left\langle f,\alpha\right\rangle_\phi \leqslant C\|\bar{\partial}^\ast_\phi \alpha\|_\phi\quad\mathbf{(1.4)}$$   holds for every $\alpha\in C^2_c(\Omega)$. , Proposition 1.1.1(cont.) For any given $\mu:\Omega\to\mathbb{R}^+$ $\mathbf{(1.4)}$ holds for all $f$ satisfying   $$\int_\Omega \frac{|f|^2}{\mu}e^{-\phi}\, dz\leqslant C\quad\mathbf{(1.5)}$$   if and only if    $$\int_\Omega \mu|\alpha|^2 e^{-\phi}\, dz\leqslant \|\bar{\partial}^\ast_\phi\alpha\|\quad\mathbf{(1.6)}$$   holds for all $\alpha\in C^2_c(\Omega)$. and, Proposition 1.1.2 Let $\Omega\subseteq\mathbb{C}$ be a domain $\phi\in C^2(\Omega,\mathbb{R})$ and $\alpha\in C_c^2(\Omega)$. Then,   $$\int_\Omega \Delta\phi|\alpha|^2 e^{-\phi}+\int_\Omega\left|\frac{\partial \alpha}{\partial\bar{z}}\right|^2 e^{-\phi}=\|\bar{\partial}^\ast_\phi\alpha\|\quad\mathbf{(1.7)}$$ It seems by the ease to which he claims Theorem 1.1.3 follows from these three propositions that the easy answer should be the correct one. The easier answer is that Proposition 1.1.2 shows that (1.6) holds for $\mu=\Delta\phi$. Thus, Proposition 1.1.1(cont.) implies that for every $f$ satisfying (1.5) we have that $f$ satisfies (1.4) for all $\alpha$ and thus we have a distributional solution to $\displaystyle \frac{\partial u}{\partial\bar{z}}u=f$ satisfying (1.3). Ok, so everything seems hunky-dory, all of this goes through correctly to prove Theorem 1.1.3 if, given $f\in L^2_{\text{loc}}(\Omega)$, we could take $$C=\int_\Omega \frac{|f|^2}{\Delta\phi}e^{-\phi}$$ The only issue is that the apply the proof of Proposition 1.1.1 we apply Riesz-Fischer to a certain operator $L$, the boundedness of which follows because we obtain a bound $\|L\|_\text{op}\leqslant C$. Thus, everything breaks down if $C$ is infinite. So, all of this strongly seems to suggest that the integral $$\int_\Omega\frac{|f|^2}{\Delta\phi}e^{-\phi}$$ is finite for every $f\in L^2_\text{loc}(\Omega)$ and every subharmonic $\phi\in C^2(\Omega,\mathbb{R})$. But, I am fairly sure this is not true (just take $\Omega=\mathbb{C}$, $\phi=x^2+y^2$, and $f=\exp(2(x^2+y^2))$). Even if we require that $f\in L^2_{\text{loc}}(\Omega)$ and $fe^{\frac{-\phi}{2}}\in L^2(\Omega)$ (which may be a possible typo) there is still doubt that this integral always converges. If anyone could provide any insight into what I am missing/what the author may have meant I would be extremely grateful.","EDIT: After mrf 's comment below and some discussion with my instructor for the course it was decided that the below was not really an issue. Namely, I went into reading this lecture with the notion that we were going to solve the $\bar{\partial}$ equation--that this was our main goal. In other words, in the below we were mainly $f$ focused and not $\phi$ focused. In all actuality, it is the other way around. We were supposed to know that the $\bar{\partial}$ equation always has distributional solutions and that, in fact, we were really interested in finding solutions to $\bar{\partial}u=f$ with $u$ having controlled $\|\cdot\|_\phi$ norm. This begs two questions though that I would love if someone may be able to fill in: This is the one-dimensional case of Hormander's Theorem. Can someone give me intuition about why as an algebraic/differential geometer having Hormander's theorem is such a huge deal (as it is made out to be). mrf says that the below theorems actually show that $\bar{\partial}u=f$ is always solvable for any $f$ since we can always find (given a fixed $f$) a $C^2(\Omega,\mathbb{R})$ subharmonic function $\phi$ for which $\displaystyle \int_\Omega\frac{|f|^2}{\Delta\phi}e^{-\phi}$ is finite (we need finiteness to actually show a solution exists). Is there an easy way to see why such a function $\phi$ always exists for a given $f$? Thanks! I am currently reading the Park City lecture notes on Analytic and Algebraic Geometry ( this book) and am really confused by some implicit assumptions made in the first lecture of the first minicourse (Lecture 1 of Bo Berndtsson's ""An Introduction to Things $\overline{\partial}$""). Let me explain some of the background to the issue I am having. Let $\phi\in C^2(\Omega,\mathbb{R})$ be subharmonic and define the inner product: $$\langle f,g\rangle_\phi=\int_\Omega f\bar{g}e^{-\phi}$$ and the norm $\|\alpha\|_\phi^2=\langle \alpha,\alpha\rangle_\phi$. We then define $\bar{\partial}^\ast_\phi$ to be the adjoint of $\bar{\phi}$ with respect to $\langle,\rangle_\phi$. Explicitly one can show that $$\bar{\partial}^\ast_\phi\alpha=-e^{\phi}\frac{\partial}{\partial z}\left(e^{-\phi}\alpha\right)$$ So, now we are trying to follow the proof of Theorem 1.1.3 in the book which is stated as follows: Theorem 1.1.3 Let $\Omega\subseteq\mathbb{C}$ be a domain and suppose that $\phi\in C^2(\Omega,\mathbb{R})$ which is subharmonic. Then, for any $f\in L^2_{\text{loc}}(\Omega)$ there is a distributional solution $u$ to $\displaystyle \frac{\partial u}{\partial \bar{z}}=f$ subject to    $$\int_\Omega |u|^2 e^{-\phi}\leqslant \int_\Omega \frac{|f|^2}{\Delta \phi}e^{-\phi}$$ The author states that the theorem follows from the following three propositions: Proposition 1.1.1 Given $f$ there exists a distributional solution to $\displaystyle \frac{\partial u}{\partial\bar{z}}$ satisfying    $$\|u\|_\phi^2\leqslant C\quad \mathbf{(1.3)}$$   for some $C>0$ if and only if the estimate   $$\left\langle f,\alpha\right\rangle_\phi \leqslant C\|\bar{\partial}^\ast_\phi \alpha\|_\phi\quad\mathbf{(1.4)}$$   holds for every $\alpha\in C^2_c(\Omega)$. , Proposition 1.1.1(cont.) For any given $\mu:\Omega\to\mathbb{R}^+$ $\mathbf{(1.4)}$ holds for all $f$ satisfying   $$\int_\Omega \frac{|f|^2}{\mu}e^{-\phi}\, dz\leqslant C\quad\mathbf{(1.5)}$$   if and only if    $$\int_\Omega \mu|\alpha|^2 e^{-\phi}\, dz\leqslant \|\bar{\partial}^\ast_\phi\alpha\|\quad\mathbf{(1.6)}$$   holds for all $\alpha\in C^2_c(\Omega)$. and, Proposition 1.1.2 Let $\Omega\subseteq\mathbb{C}$ be a domain $\phi\in C^2(\Omega,\mathbb{R})$ and $\alpha\in C_c^2(\Omega)$. Then,   $$\int_\Omega \Delta\phi|\alpha|^2 e^{-\phi}+\int_\Omega\left|\frac{\partial \alpha}{\partial\bar{z}}\right|^2 e^{-\phi}=\|\bar{\partial}^\ast_\phi\alpha\|\quad\mathbf{(1.7)}$$ It seems by the ease to which he claims Theorem 1.1.3 follows from these three propositions that the easy answer should be the correct one. The easier answer is that Proposition 1.1.2 shows that (1.6) holds for $\mu=\Delta\phi$. Thus, Proposition 1.1.1(cont.) implies that for every $f$ satisfying (1.5) we have that $f$ satisfies (1.4) for all $\alpha$ and thus we have a distributional solution to $\displaystyle \frac{\partial u}{\partial\bar{z}}u=f$ satisfying (1.3). Ok, so everything seems hunky-dory, all of this goes through correctly to prove Theorem 1.1.3 if, given $f\in L^2_{\text{loc}}(\Omega)$, we could take $$C=\int_\Omega \frac{|f|^2}{\Delta\phi}e^{-\phi}$$ The only issue is that the apply the proof of Proposition 1.1.1 we apply Riesz-Fischer to a certain operator $L$, the boundedness of which follows because we obtain a bound $\|L\|_\text{op}\leqslant C$. Thus, everything breaks down if $C$ is infinite. So, all of this strongly seems to suggest that the integral $$\int_\Omega\frac{|f|^2}{\Delta\phi}e^{-\phi}$$ is finite for every $f\in L^2_\text{loc}(\Omega)$ and every subharmonic $\phi\in C^2(\Omega,\mathbb{R})$. But, I am fairly sure this is not true (just take $\Omega=\mathbb{C}$, $\phi=x^2+y^2$, and $f=\exp(2(x^2+y^2))$). Even if we require that $f\in L^2_{\text{loc}}(\Omega)$ and $fe^{\frac{-\phi}{2}}\in L^2(\Omega)$ (which may be a possible typo) there is still doubt that this integral always converges. If anyone could provide any insight into what I am missing/what the author may have meant I would be extremely grateful.",,"['complex-analysis', 'functional-analysis', 'partial-differential-equations', 'several-complex-variables']"
92,Generalizing the weak derivative,Generalizing the weak derivative,,"I am wondering about the weak derivative in time. We say f has a weak derivative f' if $$\int_0^T f\phi' = -\int_0^T f'\phi$$ for all $\phi \in C_0^\infty(0,T)$. This definition uses the $L^2$ inner product. Can I generalise this to some Hilbert space $H$? Is there such a notation of derivative? It would be something like $$(f, \phi')_H = -(f', \phi)_H$$ but how does define $\phi'$? What is the space it lies in? Because it makes no sense to consider a derivative of element of abstract Hilbert space. Any references to this area is appreciated.","I am wondering about the weak derivative in time. We say f has a weak derivative f' if $$\int_0^T f\phi' = -\int_0^T f'\phi$$ for all $\phi \in C_0^\infty(0,T)$. This definition uses the $L^2$ inner product. Can I generalise this to some Hilbert space $H$? Is there such a notation of derivative? It would be something like $$(f, \phi')_H = -(f', \phi)_H$$ but how does define $\phi'$? What is the space it lies in? Because it makes no sense to consider a derivative of element of abstract Hilbert space. Any references to this area is appreciated.",,"['functional-analysis', 'partial-differential-equations', 'distribution-theory']"
93,"Is $W_0^{1,p}$ weakly closed?",Is  weakly closed?,"W_0^{1,p}","Is $W_0^{1,p}(\Omega)$ weakly closed? $W_0^{1,p}(\Omega)$ is the closure of $C_0^{\infty}(\Omega)$ with respect to the norm of $W_0^{1,p}(\Omega)$ , and I've been trying to figure out if it is true that if we have a sequence $u_n\in W_0^{1,p}(\Omega)$ that converges weakly to $u\in W^{1,p}$ then $u\in W_0^{1,p}$ . (By weak convergence in $W^{1,p}$ I mean weak convergence in $L^p$ of both $u_n$ and $\nabla u_n$ ) The only thing I could think of was to approximate each $u_n$ with a sequence $(u_n^k)_k\in C_0^{\infty}$ . Then by the Sobolev embedding theorems we have that weak convergence of $\nabla u_n$ in $L^p$ implies strong convergence of $u_n$ in $L^p$ , so it should be possible to approximate $u$ with $C_0^{\infty}$ functions in the $L^p$ norm. But what about the derivatives? I hope I have not been too confusing. Thank you.","Is weakly closed? is the closure of with respect to the norm of , and I've been trying to figure out if it is true that if we have a sequence that converges weakly to then . (By weak convergence in I mean weak convergence in of both and ) The only thing I could think of was to approximate each with a sequence . Then by the Sobolev embedding theorems we have that weak convergence of in implies strong convergence of in , so it should be possible to approximate with functions in the norm. But what about the derivatives? I hope I have not been too confusing. Thank you.","W_0^{1,p}(\Omega) W_0^{1,p}(\Omega) C_0^{\infty}(\Omega) W_0^{1,p}(\Omega) u_n\in W_0^{1,p}(\Omega) u\in W^{1,p} u\in W_0^{1,p} W^{1,p} L^p u_n \nabla u_n u_n (u_n^k)_k\in C_0^{\infty} \nabla u_n L^p u_n L^p u C_0^{\infty} L^p","['real-analysis', 'functional-analysis', 'partial-differential-equations', 'sobolev-spaces']"
94,Show that norm of a functional is continuous,Show that norm of a functional is continuous,,"This question is based on Lemma 3.3, page 6 in this paper: http://arxiv.org/pdf/1106.0622v4.pdf I changed the notation quite a lot, but it should be a one-to-one correspondence. $S(x)$ is a compact manifold for each $x \in [0,T]$. Fix $s \in [0,T]$. Let $t \in [0,T]$. Suppose $f(t,s):H^{-1}(S(s)) \to H^{-1}(S(t))$ (linear functional),  with the property that $f(t,t)$ is the identity for any $t$, and suppose the following holds: $$\frac{1}{1+|s-t|}\lVert u\rVert_{H^{-1}(S(s))} \leq \lVert f(t,s)u \rVert_{H^{-1}(S(t))} \leq \frac{1}{1-|s-t|}\lVert u\rVert_{H^{-1}(S(s))}$$ It might be helpful to know the adjoint of $f(s,t)$, written $f(s,t)^*:H^1(S(s)) \to H^1(S(t))$ has the property that $\lVert f(s,t)^*v \rVert_{H^1(S(t))}$ is continuous as a function of $t$. The task is to show that $\lVert f(t,s)u \rVert_{H^{-1}(S(t))}$ is continuous as a function of $t$. Clearly we can see that it is continuous at $t=s$. But how about apart from $s$? How to see that it is continuous?","This question is based on Lemma 3.3, page 6 in this paper: http://arxiv.org/pdf/1106.0622v4.pdf I changed the notation quite a lot, but it should be a one-to-one correspondence. $S(x)$ is a compact manifold for each $x \in [0,T]$. Fix $s \in [0,T]$. Let $t \in [0,T]$. Suppose $f(t,s):H^{-1}(S(s)) \to H^{-1}(S(t))$ (linear functional),  with the property that $f(t,t)$ is the identity for any $t$, and suppose the following holds: $$\frac{1}{1+|s-t|}\lVert u\rVert_{H^{-1}(S(s))} \leq \lVert f(t,s)u \rVert_{H^{-1}(S(t))} \leq \frac{1}{1-|s-t|}\lVert u\rVert_{H^{-1}(S(s))}$$ It might be helpful to know the adjoint of $f(s,t)$, written $f(s,t)^*:H^1(S(s)) \to H^1(S(t))$ has the property that $\lVert f(s,t)^*v \rVert_{H^1(S(t))}$ is continuous as a function of $t$. The task is to show that $\lVert f(t,s)u \rVert_{H^{-1}(S(t))}$ is continuous as a function of $t$. Clearly we can see that it is continuous at $t=s$. But how about apart from $s$? How to see that it is continuous?",,"['functional-analysis', 'sobolev-spaces']"
95,Functional independence,Functional independence,,"Definition confusion: I wish to show that $$f(x,y)={-y\over x}$$ and $$g(x,y)=\log |x|$$ are functionally independent on some domain. What does that mean? What do I have to show? And how does one choose the domain? Thank you. This is related to question 2 on P. 84 in this book . In particular, the note in the square brackets. However, I don't know what exactly that is and why we would like to do that.","Definition confusion: I wish to show that $$f(x,y)={-y\over x}$$ and $$g(x,y)=\log |x|$$ are functionally independent on some domain. What does that mean? What do I have to show? And how does one choose the domain? Thank you. This is related to question 2 on P. 84 in this book . In particular, the note in the square brackets. However, I don't know what exactly that is and why we would like to do that.",,"['functional-analysis', 'functions', 'definition']"
96,Dual of $\ell_\infty(X)$,Dual of,\ell_\infty(X),"Given a Banach space $X$. Consider the space $\ell_\infty(X)$ which is the $\ell_\infty$-sum of countably many copies of $X$. Is there any accessible respresentation of the dual space $\ell_\infty(X)^*$? In particular, is this dual space isomorphic to the space of finitely additive $X^*$-valued measures on the powerset of $\mathbb N$ equipped with the semivariation norm? Any references will be appreciated.","Given a Banach space $X$. Consider the space $\ell_\infty(X)$ which is the $\ell_\infty$-sum of countably many copies of $X$. Is there any accessible respresentation of the dual space $\ell_\infty(X)^*$? In particular, is this dual space isomorphic to the space of finitely additive $X^*$-valued measures on the powerset of $\mathbb N$ equipped with the semivariation norm? Any references will be appreciated.",,"['functional-analysis', 'measure-theory', 'banach-spaces']"
97,What is the use of $H_s$ for non-integer $s$?,What is the use of  for non-integer ?,H_s s,"So we have the whole set of theory for Sobolev spaces \begin{equation} H_s(\mathbb{R}^d)=\{u\in D'(\mathbb{R}^d):(1+|y|^2)^{s/2}\hat{u}\in\mathcal{L}^2(\mathbb{R}^d)\}, \end{equation} and we know that they are the same as \begin{equation} W^{s,2}=\{u:D^{\alpha}u\in\mathcal{L}^2(\mathbb{R}^d)\text{ for all} |\alpha|\le s\} \end{equation} when $s\in\mathbb{N}$. We also know that $H_s$ is useful when $s$ is a negative integer since it can be identified as the dual space of $H_{-s}$. But what is the use of $H_s$ when $s$ is not an integer? Thanks!","So we have the whole set of theory for Sobolev spaces \begin{equation} H_s(\mathbb{R}^d)=\{u\in D'(\mathbb{R}^d):(1+|y|^2)^{s/2}\hat{u}\in\mathcal{L}^2(\mathbb{R}^d)\}, \end{equation} and we know that they are the same as \begin{equation} W^{s,2}=\{u:D^{\alpha}u\in\mathcal{L}^2(\mathbb{R}^d)\text{ for all} |\alpha|\le s\} \end{equation} when $s\in\mathbb{N}$. We also know that $H_s$ is useful when $s$ is a negative integer since it can be identified as the dual space of $H_{-s}$. But what is the use of $H_s$ when $s$ is not an integer? Thanks!",,"['functional-analysis', 'partial-differential-equations', 'intuition', 'sobolev-spaces', 'distribution-theory']"
98,Prove $\ell_1$ is first category in $\ell_2$,Prove  is first category in,\ell_1 \ell_2,"Prove that $\ell_1$ is first category in $\ell_2$. I tried to solve this, but had no idea about the approach. Any suggestions are helpful.  Thanks in advance.","Prove that $\ell_1$ is first category in $\ell_2$. I tried to solve this, but had no idea about the approach. Any suggestions are helpful.  Thanks in advance.",,"['analysis', 'functional-analysis', 'baire-category']"
99,how to show that $c_0$ is complete,how to show that  is complete,c_0,"I want to show that the metric space $(c_0,d_\infty)$ is complete, where $c_0$ is the collection of all sequences $x\colon \mathbb N\to\mathbb R$ which tend to $0$. I have already shown that the space $(X,d_\infty)$, which consists of all sequences with a limit in $\mathbb R$ is complete. How can I prove that $c_0$ is a closed subspace of of $X$?","I want to show that the metric space $(c_0,d_\infty)$ is complete, where $c_0$ is the collection of all sequences $x\colon \mathbb N\to\mathbb R$ which tend to $0$. I have already shown that the space $(X,d_\infty)$, which consists of all sequences with a limit in $\mathbb R$ is complete. How can I prove that $c_0$ is a closed subspace of of $X$?",,"['functional-analysis', 'metric-spaces', 'banach-spaces']"
