,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Differential Geometry or Functional Analysis? [closed],Differential Geometry or Functional Analysis? [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Questions about choosing a course, academic program, career path, etc. are off-topic. Such questions should be directed to those employed by the institution in question, or other qualified individuals who know your specific circumstances. Closed 5 years ago . Improve this question I am starting my Master's degree, and I have to chose between these two courses that I have not taken during my Bachelor's (I can only chose one!). I am interested in group theory and in particular geometric group theory. On the one hand, I'd like to do differential geometry to have a stronger basis for studying Lie groups. On the other hand, I know that the study of analytical properties of groups, such as everything around the notion of amenability, relies on some results of functional analysis. If any of you works in (geometric) group theory, what do you think is most important for a mathematician working in that field to master, and what is easier to learn by oneself? Thanks in advance.","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Questions about choosing a course, academic program, career path, etc. are off-topic. Such questions should be directed to those employed by the institution in question, or other qualified individuals who know your specific circumstances. Closed 5 years ago . Improve this question I am starting my Master's degree, and I have to chose between these two courses that I have not taken during my Bachelor's (I can only chose one!). I am interested in group theory and in particular geometric group theory. On the one hand, I'd like to do differential geometry to have a stronger basis for studying Lie groups. On the other hand, I know that the study of analytical properties of groups, such as everything around the notion of amenability, relies on some results of functional analysis. If any of you works in (geometric) group theory, what do you think is most important for a mathematician working in that field to master, and what is easier to learn by oneself? Thanks in advance.",,"['group-theory', 'functional-analysis', 'differential-geometry', 'education', 'geometric-group-theory']"
1,Rational rotational algebra (noncommutative torus) is not simple,Rational rotational algebra (noncommutative torus) is not simple,,"I would like to show that the rational rotational algebra $A_\theta$ is not simple where $A_\theta= C^{*}(u,v : u,v$ are unitaries and $uv=e^{i2\pi\theta}vu$) and $\theta$ is a rational number. The hint is given that I need to show the existence of unital $*$-homomorphisms $\phi : A_\theta → B $ and $\psi : A_\theta  → D $ such that $\phi (v^{q})=1$ and $\psi(v^{q})\neq 1$. And I do not know how to show the existences of such homomorphisms. Any help would be appreciated.","I would like to show that the rational rotational algebra $A_\theta$ is not simple where $A_\theta= C^{*}(u,v : u,v$ are unitaries and $uv=e^{i2\pi\theta}vu$) and $\theta$ is a rational number. The hint is given that I need to show the existence of unital $*$-homomorphisms $\phi : A_\theta → B $ and $\psi : A_\theta  → D $ such that $\phi (v^{q})=1$ and $\psi(v^{q})\neq 1$. And I do not know how to show the existences of such homomorphisms. Any help would be appreciated.",,"['functional-analysis', 'operator-algebras', 'c-star-algebras', 'universal-algebra']"
2,Characters and maximal ideals in $\ell^1(N)$,Characters and maximal ideals in,\ell^1(N),"Determine all the maximal ideals and all the characters in $\ell^1(N)$, if we know that it is a commutative Banach algebra with component-wise multiplication and addition. I know what are characters in $\ell^1(Z)$ but don't know how to determine them in $\ell^1(N)$. Any help would be appreciated.","Determine all the maximal ideals and all the characters in $\ell^1(N)$, if we know that it is a commutative Banach algebra with component-wise multiplication and addition. I know what are characters in $\ell^1(Z)$ but don't know how to determine them in $\ell^1(N)$. Any help would be appreciated.",,['functional-analysis']
3,Some functional analysis problem,Some functional analysis problem,,"In my undergraduate functional analysis course, there is this $1$ problem that I am stuck on, and it goes: For $n = 1, 2, 3,...,$ let the functions $f_n : [0, 1] → [0, 1]$ satisfy $|f_n(x)−f_n(y)|≤|x−y|$ whenever   $|x − y| ≥ \frac{1}{n}.$ Prove that the sequence ${f_n}$ has a uniformly convergent subsequence. How do I start this proof? Can anyone give me some leads? My Solution: If we let some function $\phi_n$ be continuous, which equates to $f_n$ at some $i/n$ for $i = 0,1,2,3,...,n.$ Denote the graph of $\phi_n$ be a line segment [(i-1)/n,i/n].Then it is not hard to see that $\phi_n \in [0,1]$ implies the $\phi_n$'s are bounded (uniformly).Using the assumption given in the problem regarding $f_n,$ we can calculate the absolute values of the slopes of $\phi_n$'s on the intervals: $$\bigg|\frac{\phi_n\big(\frac{i}{n}\big)-\phi_n\big(\frac{i-1}{n}\big)}{1/n}\bigg|=\bigg|\frac{f_n\big(\frac{i}{n}\big)-f_n\big(\frac{i-1}{n}\big)}{1/n}\bigg|\le 1$$ If $0 \le k/n \le x\le y \le (k+1)/n \le 1$, then it immediately follows that $|\phi_n(x)-\phi_n(y)|\le |x-y|.$ If on the other hand we consider the interval, $0\le x\le k/n \le m/n \le y \le 1,$ then we have the following computations:  $$|\phi_n(x)-\phi(y)| \le \bigg|\phi_n (x) -\phi_n\bigg(\frac{k}{n}\bigg)\bigg|+\sum^{m-1}_{p=k}\bigg|\phi_n \bigg(\frac{p}{n}\bigg) -\phi_n\bigg(\frac{p+1}{n}\bigg)\bigg|+\bigg|\phi_n \bigg(\frac{m}{n}\bigg)-\phi_n(y)\bigg|$$$$\le |x-y|$$ From here take the $\epsilon$ to be $\epsilon = \delta$, then $\{\phi_n\}$ is equicontinuous. From here we can apply the Arzela - Ascoli's theorem, some subsequence $\{\phi_{n_{j}}\}$ converges uniformly on $[0,1]$ to a limit function $\phi$. Now simply fix some $x\in [0,1]$ , then for each $j$, we let $x_j$ be a point in $[0,1]$ of the form $i/n_j$ for $i = 0,1,2,...,n_j$ such that $1/n_j\le |x-x_j|\le 2/n_j.$ Now we can conduct the final step:  $$|\phi(x)-f_{n_j}(x)|\le |\phi(x)-\phi_{n_j}(x)|+|\phi_{n_j}(x)-\phi_{n_j}(x_j)|+|f_{n_j}(x_j)-f_{n_j}(x)|\le ||\phi-\phi_{n_j}||_{\infty}+\frac{2}{n_j}+\frac{2}{n_j}\rightarrow 0$$ Hence clearly $\{f_{n_j}\}$ converges uniformly on $[0,1]$ to $\phi.$","In my undergraduate functional analysis course, there is this $1$ problem that I am stuck on, and it goes: For $n = 1, 2, 3,...,$ let the functions $f_n : [0, 1] → [0, 1]$ satisfy $|f_n(x)−f_n(y)|≤|x−y|$ whenever   $|x − y| ≥ \frac{1}{n}.$ Prove that the sequence ${f_n}$ has a uniformly convergent subsequence. How do I start this proof? Can anyone give me some leads? My Solution: If we let some function $\phi_n$ be continuous, which equates to $f_n$ at some $i/n$ for $i = 0,1,2,3,...,n.$ Denote the graph of $\phi_n$ be a line segment [(i-1)/n,i/n].Then it is not hard to see that $\phi_n \in [0,1]$ implies the $\phi_n$'s are bounded (uniformly).Using the assumption given in the problem regarding $f_n,$ we can calculate the absolute values of the slopes of $\phi_n$'s on the intervals: $$\bigg|\frac{\phi_n\big(\frac{i}{n}\big)-\phi_n\big(\frac{i-1}{n}\big)}{1/n}\bigg|=\bigg|\frac{f_n\big(\frac{i}{n}\big)-f_n\big(\frac{i-1}{n}\big)}{1/n}\bigg|\le 1$$ If $0 \le k/n \le x\le y \le (k+1)/n \le 1$, then it immediately follows that $|\phi_n(x)-\phi_n(y)|\le |x-y|.$ If on the other hand we consider the interval, $0\le x\le k/n \le m/n \le y \le 1,$ then we have the following computations:  $$|\phi_n(x)-\phi(y)| \le \bigg|\phi_n (x) -\phi_n\bigg(\frac{k}{n}\bigg)\bigg|+\sum^{m-1}_{p=k}\bigg|\phi_n \bigg(\frac{p}{n}\bigg) -\phi_n\bigg(\frac{p+1}{n}\bigg)\bigg|+\bigg|\phi_n \bigg(\frac{m}{n}\bigg)-\phi_n(y)\bigg|$$$$\le |x-y|$$ From here take the $\epsilon$ to be $\epsilon = \delta$, then $\{\phi_n\}$ is equicontinuous. From here we can apply the Arzela - Ascoli's theorem, some subsequence $\{\phi_{n_{j}}\}$ converges uniformly on $[0,1]$ to a limit function $\phi$. Now simply fix some $x\in [0,1]$ , then for each $j$, we let $x_j$ be a point in $[0,1]$ of the form $i/n_j$ for $i = 0,1,2,...,n_j$ such that $1/n_j\le |x-x_j|\le 2/n_j.$ Now we can conduct the final step:  $$|\phi(x)-f_{n_j}(x)|\le |\phi(x)-\phi_{n_j}(x)|+|\phi_{n_j}(x)-\phi_{n_j}(x_j)|+|f_{n_j}(x_j)-f_{n_j}(x)|\le ||\phi-\phi_{n_j}||_{\infty}+\frac{2}{n_j}+\frac{2}{n_j}\rightarrow 0$$ Hence clearly $\{f_{n_j}\}$ converges uniformly on $[0,1]$ to $\phi.$",,['functional-analysis']
4,"Spectral family of multiplication operator $T:L^{2}[0,1]\rightarrow L^{2}[0,1]$ defined by $Tx(t)=tx(t)$",Spectral family of multiplication operator  defined by,"T:L^{2}[0,1]\rightarrow L^{2}[0,1] Tx(t)=tx(t)","I'm trying to prove the next: Consider the multiplication operator $T:L^{2}[0,1]\rightarrow L^{2}[0,1]$ defined by $y(t)=Tx(t)=tx(t).$ Then $\sigma(T)=\sigma_{c}(T)=[0,1]$ and the corresponding spectral family is defined by $$E_{\lambda}x= \left\{ \begin{array}{lcc}              0 &   if  & \lambda<0 \\              \\ v_{\lambda} &  if & 0\leq\lambda\leq 1 \\              \\ x &  if  & \lambda \geq 1               \end{array}    \right.$$ where $$v_{\lambda}(t)= \left\{ \begin{array}{lcc}              x(t) &   if  & 0\leq t \leq \lambda \\              \\ 0 &  if  & \lambda<t\leq 1.               \end{array}    \right.$$ First, I've proved that operator multiplication $Tx(t)=tx(t)$ is linear, bounded and self-adjoint. Even more, such operator has no eigenvalues. Then residual spectrum $\sigma_{r}(T)=\emptyset$ and $\sigma_{c}(T)=\sigma(T).$ Computing $m=\displaystyle\inf_{||x||=1}\langle Tx,x\rangle=t=\displaystyle\sup_{||x||=1}\langle Tx,x\rangle=M$ and since $T$ is self-adjoint we can conclude $\sigma(T)=[0,1]$ because $t\in[0,1].$ I'm stuck proving that $\{E_{\lambda}\}_{\lambda}$ is the spectral family, defined as above, of such operator. I've seen in some cases this can be computed directly depending of the operator: if $T$ is the null operator or the identity such spectral family is easy to find, but in this case I can't see it. Any kind of help is thanked in advanced.","I'm trying to prove the next: Consider the multiplication operator $T:L^{2}[0,1]\rightarrow L^{2}[0,1]$ defined by $y(t)=Tx(t)=tx(t).$ Then $\sigma(T)=\sigma_{c}(T)=[0,1]$ and the corresponding spectral family is defined by $$E_{\lambda}x= \left\{ \begin{array}{lcc}              0 &   if  & \lambda<0 \\              \\ v_{\lambda} &  if & 0\leq\lambda\leq 1 \\              \\ x &  if  & \lambda \geq 1               \end{array}    \right.$$ where $$v_{\lambda}(t)= \left\{ \begin{array}{lcc}              x(t) &   if  & 0\leq t \leq \lambda \\              \\ 0 &  if  & \lambda<t\leq 1.               \end{array}    \right.$$ First, I've proved that operator multiplication $Tx(t)=tx(t)$ is linear, bounded and self-adjoint. Even more, such operator has no eigenvalues. Then residual spectrum $\sigma_{r}(T)=\emptyset$ and $\sigma_{c}(T)=\sigma(T).$ Computing $m=\displaystyle\inf_{||x||=1}\langle Tx,x\rangle=t=\displaystyle\sup_{||x||=1}\langle Tx,x\rangle=M$ and since $T$ is self-adjoint we can conclude $\sigma(T)=[0,1]$ because $t\in[0,1].$ I'm stuck proving that $\{E_{\lambda}\}_{\lambda}$ is the spectral family, defined as above, of such operator. I've seen in some cases this can be computed directly depending of the operator: if $T$ is the null operator or the identity such spectral family is easy to find, but in this case I can't see it. Any kind of help is thanked in advanced.",,"['functional-analysis', 'operator-theory', 'spectral-theory']"
5,First isomorphism theorem for Banach Spaces,First isomorphism theorem for Banach Spaces,,"I am dealing with the following exercise: Let $E$, $F$ be Banach Spaces and $T:E\to F$ a continuous and surjective linear function. Define $\widehat{T}:E/\ker T\to F$ as $\widehat{T}([x])=T(x)$. Prove that $\widehat{T}$ is an isomorphism such that $\left \|T\right \|=\left \|\widehat{T}\right \|$. First of all, since $T$ is continuous then $\ker T$ is closed, so $E/\ker T$ is a Banach space (because $E$ is a Banach Space). Take $Q:E\to E/\ker T$ the projection. Therefore $\widehat{T}\circ Q=T$, so $\widehat{T}$ is a continuous linear function which is bijective. By the open mapping theorem, it is also an homeomorphism. Moreover, $\left \|T\right \|=\left \|\widehat{T}\circ Q\right \|\leq \left \|\widehat{T}\right \|\left \|Q\right \|\leq\left \|\widehat{T}\right \|$ since $\left \|Q\right \|\leq 1$. The only thing I need to prove in order to finish the exercise is the other inequality: $\left \|\widehat{T}\right \|\leq \left \|T\right \|$. I do not know how to achieve it. How would you solve this last step?","I am dealing with the following exercise: Let $E$, $F$ be Banach Spaces and $T:E\to F$ a continuous and surjective linear function. Define $\widehat{T}:E/\ker T\to F$ as $\widehat{T}([x])=T(x)$. Prove that $\widehat{T}$ is an isomorphism such that $\left \|T\right \|=\left \|\widehat{T}\right \|$. First of all, since $T$ is continuous then $\ker T$ is closed, so $E/\ker T$ is a Banach space (because $E$ is a Banach Space). Take $Q:E\to E/\ker T$ the projection. Therefore $\widehat{T}\circ Q=T$, so $\widehat{T}$ is a continuous linear function which is bijective. By the open mapping theorem, it is also an homeomorphism. Moreover, $\left \|T\right \|=\left \|\widehat{T}\circ Q\right \|\leq \left \|\widehat{T}\right \|\left \|Q\right \|\leq\left \|\widehat{T}\right \|$ since $\left \|Q\right \|\leq 1$. The only thing I need to prove in order to finish the exercise is the other inequality: $\left \|\widehat{T}\right \|\leq \left \|T\right \|$. I do not know how to achieve it. How would you solve this last step?",,"['functional-analysis', 'continuity', 'banach-spaces', 'normed-spaces']"
6,Compact operator can be approximated by finite rank operator,Compact operator can be approximated by finite rank operator,,"I'm beginner of functional analysis and few days ago, I learned about compact operators. If $H$ is a Hilbert space, we know that the space of finite rank operators $F(H)$ is not closed in the space of continuous (or bounded) linear operators $L(H)$ in general, and its closure is same as the space of compact operators $K(H)$. I find a different proof of the direction $K(H)\subseteq \overline{F(H)}$ and I want to know whether this is right or wrong. Let $T\in K(H)$ be a compact operator. Then we can decompose $T$ as $$ T = \frac{1}{2}(T+T^{*}) + \frac{1}{2}(T-T^{*})=:T_{1}+T_{2}$$ where $T_{1}$ is self-adjoint and $T_{2}$ is anti-self-adjoint (I mean, $T_{2}^{*}=-T_{2}$), which follows from $T^{**}=T$. By the spectral theorem, $T_{1}$ can be written as $$ T_{1} = \sum_{n=1}^{\infty} \lambda_{n}P_{n} $$ where $\lambda_{n}$'s are eigenvalues of $T_{1}$ satisfying  $\lim_{n\to \infty} \lambda_{n}=0$, and $P_{n}$'s are orthogonal projections to the eigenspaces $E(\lambda_{n})$, which are all finite dimensional (so $P_{n}$'s are finite rank operators). Similarly, since $T_{2}^{*}=-T_{2}$, $(iT_{2})^{*} = -iT_{2}^{*}= iT_{2}$, $iT_{2}$ is a self-adjoint compact operator, so we can apply the spectral theorem again and we get  $$ T_{2} = -i(iT_{2}) = -i\sum_{n=1}^{\infty} \lambda_{n}'P_{n}' $$ where $\lambda_{n}'s$ are eigenvalues of $T_{2}$ with $\lim_{n\to\infty} \lambda_{n}'=0$ and $P_{n}'$'s are orthogonal projections to the eigenspaces $E(\lambda_{n}')$, which are finite dimensional spaces. Hence $$ \lim_{N\to\infty} ||T- \sum_{n=1}^{N}(\lambda_{n}P_{n}-i\lambda_{n}'P_{n}')||=0$$ and we get the result.","I'm beginner of functional analysis and few days ago, I learned about compact operators. If $H$ is a Hilbert space, we know that the space of finite rank operators $F(H)$ is not closed in the space of continuous (or bounded) linear operators $L(H)$ in general, and its closure is same as the space of compact operators $K(H)$. I find a different proof of the direction $K(H)\subseteq \overline{F(H)}$ and I want to know whether this is right or wrong. Let $T\in K(H)$ be a compact operator. Then we can decompose $T$ as $$ T = \frac{1}{2}(T+T^{*}) + \frac{1}{2}(T-T^{*})=:T_{1}+T_{2}$$ where $T_{1}$ is self-adjoint and $T_{2}$ is anti-self-adjoint (I mean, $T_{2}^{*}=-T_{2}$), which follows from $T^{**}=T$. By the spectral theorem, $T_{1}$ can be written as $$ T_{1} = \sum_{n=1}^{\infty} \lambda_{n}P_{n} $$ where $\lambda_{n}$'s are eigenvalues of $T_{1}$ satisfying  $\lim_{n\to \infty} \lambda_{n}=0$, and $P_{n}$'s are orthogonal projections to the eigenspaces $E(\lambda_{n})$, which are all finite dimensional (so $P_{n}$'s are finite rank operators). Similarly, since $T_{2}^{*}=-T_{2}$, $(iT_{2})^{*} = -iT_{2}^{*}= iT_{2}$, $iT_{2}$ is a self-adjoint compact operator, so we can apply the spectral theorem again and we get  $$ T_{2} = -i(iT_{2}) = -i\sum_{n=1}^{\infty} \lambda_{n}'P_{n}' $$ where $\lambda_{n}'s$ are eigenvalues of $T_{2}$ with $\lim_{n\to\infty} \lambda_{n}'=0$ and $P_{n}'$'s are orthogonal projections to the eigenspaces $E(\lambda_{n}')$, which are finite dimensional spaces. Hence $$ \lim_{N\to\infty} ||T- \sum_{n=1}^{N}(\lambda_{n}P_{n}-i\lambda_{n}'P_{n}')||=0$$ and we get the result.",,"['functional-analysis', 'proof-verification', 'operator-theory', 'compact-operators']"
7,Center of the group of invertible bounded linear operators with bounded inverse on Normed linear spaces,Center of the group of invertible bounded linear operators with bounded inverse on Normed linear spaces,,"Let $X$ be an Normed linear space. Let $Iso(X)$ be the set of all invertible bounded linear operators on $X$ with bounded inverse. If $T \in Iso(X)$ is such that $T \circ S=S \circ T, \forall S \in Iso (X)$, then is it true that $T=kI$ for some scalar $k$ ? If $X$ is Banach space, then the claim is true, which I can show as follows: Let $0\ne v \in X$. Pick $0\ne L_v \in X^*=\mathcal L(X,F)$ ($F$ is the underlying field) such that $||L_v||<\dfrac {1}{2||v||}$. Fix $a\in X$ with $L_v(a)\ne 0$. Define $S:X \to X$ as $S_v(x)=L_v(x)v,\forall x \in X$. Then $||S_v||\le ||L_v||||v||<1/2$. Then $I-S_v \in Iso(X)$ (this is where I need $X$ to be Banach). Let $T \in Iso(X)$ which commutes with every member of $Iso(X)$. Then we have in particular $T((I-S_v)(a))=(I-S_v)(T(a))$ i.e. $T(a-S_v(a))=T(a)-S_v(T(a))$ i.e. $T(a)-T(S_v(a))=T(a)-S_v(T(a))$ i.e. $T(L_v(a)v)=L_v(T(a))v$ i.e. $L_v(a)T(v)=L_v(T(a))v$ i.e. $T(v)=k_v v$ for some scalar $k_v \in F$. And now it can be easily shown that $k_v=k_w,\forall 0\ne v,w \in X$, hence $T$ is a scalar multiple of identity. I don't know what happens if $X$ is not Banach. Please help.","Let $X$ be an Normed linear space. Let $Iso(X)$ be the set of all invertible bounded linear operators on $X$ with bounded inverse. If $T \in Iso(X)$ is such that $T \circ S=S \circ T, \forall S \in Iso (X)$, then is it true that $T=kI$ for some scalar $k$ ? If $X$ is Banach space, then the claim is true, which I can show as follows: Let $0\ne v \in X$. Pick $0\ne L_v \in X^*=\mathcal L(X,F)$ ($F$ is the underlying field) such that $||L_v||<\dfrac {1}{2||v||}$. Fix $a\in X$ with $L_v(a)\ne 0$. Define $S:X \to X$ as $S_v(x)=L_v(x)v,\forall x \in X$. Then $||S_v||\le ||L_v||||v||<1/2$. Then $I-S_v \in Iso(X)$ (this is where I need $X$ to be Banach). Let $T \in Iso(X)$ which commutes with every member of $Iso(X)$. Then we have in particular $T((I-S_v)(a))=(I-S_v)(T(a))$ i.e. $T(a-S_v(a))=T(a)-S_v(T(a))$ i.e. $T(a)-T(S_v(a))=T(a)-S_v(T(a))$ i.e. $T(L_v(a)v)=L_v(T(a))v$ i.e. $L_v(a)T(v)=L_v(T(a))v$ i.e. $T(v)=k_v v$ for some scalar $k_v \in F$. And now it can be easily shown that $k_v=k_w,\forall 0\ne v,w \in X$, hence $T$ is a scalar multiple of identity. I don't know what happens if $X$ is not Banach. Please help.",,"['functional-analysis', 'linear-transformations', 'normed-spaces']"
8,Prove Brownian Bridge is Sampling Without Replacement,Prove Brownian Bridge is Sampling Without Replacement,,"Let's say we have a bowl containing $n$ many $+1$ 's and $n$ many $-1$ 's. You sample numbers from the bowl randomly without replacing. Let $k_1^{(n)}, k_2^{(n)}, ..., k_{2n}^{(n)}$ denote the random sequence of numbers from the process of sampling. Let the partial sum process: $$S_0=0 \; , \; S_a=\sum_{i=1}^a k_i^{(n)} \; , \; 1\leq a\leq 2n$$ We can define a sequence of continuous processes by scaling time and space via Donsker's theorem $$X_{\frac{a}{2n}}^{(n)} = \frac{S_a}{\sqrt{n}} \; , \; a=0,1,2,...,2n$$ by linearly interpolating we get $$X_{t}^{(n)} = X^{(n)}_{\frac{\lfloor 2nt\rfloor}{n}} + \frac{nt-\lfloor nt\rfloor}{\sqrt{n}} k_{\lfloor 2nt\rfloor+1}^{(n)} \; , \; 0 \leq t\leq1$$ How can we prove that the process $X^{(n)}$ converges weakly to a constant multiple of the standard Brownian bridge?",Let's say we have a bowl containing many 's and many 's. You sample numbers from the bowl randomly without replacing. Let denote the random sequence of numbers from the process of sampling. Let the partial sum process: We can define a sequence of continuous processes by scaling time and space via Donsker's theorem by linearly interpolating we get How can we prove that the process converges weakly to a constant multiple of the standard Brownian bridge?,"n +1 n -1 k_1^{(n)}, k_2^{(n)}, ..., k_{2n}^{(n)} S_0=0 \; , \; S_a=\sum_{i=1}^a k_i^{(n)} \; , \; 1\leq a\leq 2n X_{\frac{a}{2n}}^{(n)} = \frac{S_a}{\sqrt{n}} \; , \; a=0,1,2,...,2n X_{t}^{(n)} = X^{(n)}_{\frac{\lfloor 2nt\rfloor}{n}} + \frac{nt-\lfloor nt\rfloor}{\sqrt{n}} k_{\lfloor 2nt\rfloor+1}^{(n)} \; , \; 0 \leq t\leq1 X^{(n)}","['functional-analysis', 'probability-theory', 'measure-theory', 'brownian-motion', 'weak-convergence']"
9,Invertibility of one-to-one and onto linear operators on a Hilbert space,Invertibility of one-to-one and onto linear operators on a Hilbert space,,"$\mathcal{H}$ is a Hilbert space. $D$ is some dense subspace of $\mathcal{H}$. A linear operator $A:D\rightarrow \mathcal{H}$ is one-to-one (i.e., $Au=0$ implies $u=0$) and onto (i.e., $Range(A)=\mathcal{H}$). Do these conditions suffice to establish that $A$ has a bounded inverse?","$\mathcal{H}$ is a Hilbert space. $D$ is some dense subspace of $\mathcal{H}$. A linear operator $A:D\rightarrow \mathcal{H}$ is one-to-one (i.e., $Au=0$ implies $u=0$) and onto (i.e., $Range(A)=\mathcal{H}$). Do these conditions suffice to establish that $A$ has a bounded inverse?",,"['functional-analysis', 'operator-theory', 'hilbert-spaces']"
10,"If there is a bounded linear extension $W^{k,\:p}(Λ)\to W^{k,\:p}(ℝ^d)$, are we able to conclude the existence of such an extension for other $k,p$?","If there is a bounded linear extension , are we able to conclude the existence of such an extension for other ?","W^{k,\:p}(Λ)\to W^{k,\:p}(ℝ^d) k,p","Let $d\in\mathbb N$ $\Lambda\subseteq\mathbb R^d$ be open $k\in\mathbb N$ $p\in[1,\infty)$ We say that $\Lambda$ has the $(k,p)$-extension property $:\Leftrightarrow$ There is a bounded linear operator $W^{k,\:p}(\Lambda)\to W^{k,\:p}(\mathbb R^d)$ with $$\left.Eu\right|_\Lambda=u\;\;\;\text{for all }u\in W^{k,\:p}(\Lambda)\;.\tag1$$ My question is: If $\Lambda$ has the $(k,p)$-extension property, are we able to conclude that $\Lambda$ has the $(k',p')$-extension property for some $k'\in\mathbb N$ and $p'\in[1,\infty)$? In particular, if $\Lambda$ has the $(2,2)$-extension property, does it have the $(1,2)$-extension property too?","Let $d\in\mathbb N$ $\Lambda\subseteq\mathbb R^d$ be open $k\in\mathbb N$ $p\in[1,\infty)$ We say that $\Lambda$ has the $(k,p)$-extension property $:\Leftrightarrow$ There is a bounded linear operator $W^{k,\:p}(\Lambda)\to W^{k,\:p}(\mathbb R^d)$ with $$\left.Eu\right|_\Lambda=u\;\;\;\text{for all }u\in W^{k,\:p}(\Lambda)\;.\tag1$$ My question is: If $\Lambda$ has the $(k,p)$-extension property, are we able to conclude that $\Lambda$ has the $(k',p')$-extension property for some $k'\in\mathbb N$ and $p'\in[1,\infty)$? In particular, if $\Lambda$ has the $(2,2)$-extension property, does it have the $(1,2)$-extension property too?",,"['functional-analysis', 'sobolev-spaces']"
11,Definition of Cylindrical Brownian Motion and Spatial Correlation,Definition of Cylindrical Brownian Motion and Spatial Correlation,,"From Gawarecki and Mandrekar, Stochastic Differential Equations in Infinite Dimensions : We call a family $\{ W_t \}_{t\geq 0}$ defined on a filtered probability space $(\Omega, \mathcal{F}, \{\mathcal{F}_t\}_{t \geq 0}, P)$ a cylindrical Wiener process in a Hilbert space $K$ if: For an arbitrary $t\geq0$, the mapping $W_t:K \rightarrow L^2(\Omega, \mathcal{F}, P)$ is linear. For an arbitrary $k \in K$, $W_t(k)$ is an $\mathcal{F}_t$-Brownian motion. For arbitrary $k, k' \in K$ and $t \geq 0$, $E(W_t(k)W_t(k')) = t \langle k, k'\rangle_K$. Exercise 2.2 Show that $E(W_t(k)W_s(k')) = (t \wedge s) \langle k, k' \rangle_K$ and conclude that $W_t(f_j), j=1, 2, ...$, where $\{f_j\}_{j=1}^\infty$ is an orthonormal basis in $K$, are independent Brownian motions. I am new to functional analysis and don't see how to start this exercise. I can see that the third point is useful, but how does one begin? My thought was the following (assuming $t \leq s$: $$ \begin{align*} E(W_t(k)W_s(k')) &= E(E(W_t(k)W_s(k')|\mathcal{F}_t))\\ &= E(W_t(k)E(W_s(k')|\mathcal{F}))\\ &= E(W_t(k)W_t(k')\\ &= t\langle k, k' \rangle_K \end{align*} $$ by LIE, point two, and point three, respectively. The opposite holds for $s \leq t$. Is this the right approach? Then the independence follows from orthogonality.","From Gawarecki and Mandrekar, Stochastic Differential Equations in Infinite Dimensions : We call a family $\{ W_t \}_{t\geq 0}$ defined on a filtered probability space $(\Omega, \mathcal{F}, \{\mathcal{F}_t\}_{t \geq 0}, P)$ a cylindrical Wiener process in a Hilbert space $K$ if: For an arbitrary $t\geq0$, the mapping $W_t:K \rightarrow L^2(\Omega, \mathcal{F}, P)$ is linear. For an arbitrary $k \in K$, $W_t(k)$ is an $\mathcal{F}_t$-Brownian motion. For arbitrary $k, k' \in K$ and $t \geq 0$, $E(W_t(k)W_t(k')) = t \langle k, k'\rangle_K$. Exercise 2.2 Show that $E(W_t(k)W_s(k')) = (t \wedge s) \langle k, k' \rangle_K$ and conclude that $W_t(f_j), j=1, 2, ...$, where $\{f_j\}_{j=1}^\infty$ is an orthonormal basis in $K$, are independent Brownian motions. I am new to functional analysis and don't see how to start this exercise. I can see that the third point is useful, but how does one begin? My thought was the following (assuming $t \leq s$: $$ \begin{align*} E(W_t(k)W_s(k')) &= E(E(W_t(k)W_s(k')|\mathcal{F}_t))\\ &= E(W_t(k)E(W_s(k')|\mathcal{F}))\\ &= E(W_t(k)W_t(k')\\ &= t\langle k, k' \rangle_K \end{align*} $$ by LIE, point two, and point three, respectively. The opposite holds for $s \leq t$. Is this the right approach? Then the independence follows from orthogonality.",,"['functional-analysis', 'probability-theory', 'stochastic-processes', 'stochastic-calculus', 'brownian-motion']"
12,Proving linear operator is bounded,Proving linear operator is bounded,,"Prove that the formula $T(b_1,b_2,b_3,...,b_n,...) = (b_1, b_2/2 ,..., b_n/n ,...)$ deﬁnes a bounded linear operator $T : (ℓ^∞,∥·∥_∞)→(ℓ^∞,∥·∥_∞)$. Proving that it is linear is easy. Need help with the bounded part. But it seems obviously true: If it is bounded then $\exists C \ge 0$ such that $\|Tx\|_{\infty} \le C \|x\|_{\infty}$ for all $x \in X$. We can see that $\|Tx\|=\|b_n/n\|=\sup_{n \in \mathbb N}|b_n/n| \leq \|b_n\|=\sup_{n \in \mathbb N} |b_n|$ for all $n \ge 1$ so we can let $C=1$. Is this how we are meant to generally show boundedness of linear operators? Although I have heard of a theorem that says continuous $\iff$ bounded. But showing continuity would be long...","Prove that the formula $T(b_1,b_2,b_3,...,b_n,...) = (b_1, b_2/2 ,..., b_n/n ,...)$ deﬁnes a bounded linear operator $T : (ℓ^∞,∥·∥_∞)→(ℓ^∞,∥·∥_∞)$. Proving that it is linear is easy. Need help with the bounded part. But it seems obviously true: If it is bounded then $\exists C \ge 0$ such that $\|Tx\|_{\infty} \le C \|x\|_{\infty}$ for all $x \in X$. We can see that $\|Tx\|=\|b_n/n\|=\sup_{n \in \mathbb N}|b_n/n| \leq \|b_n\|=\sup_{n \in \mathbb N} |b_n|$ for all $n \ge 1$ so we can let $C=1$. Is this how we are meant to generally show boundedness of linear operators? Although I have heard of a theorem that says continuous $\iff$ bounded. But showing continuity would be long...",,"['functional-analysis', 'normed-spaces']"
13,Completeness of derivatives of Hilbert basis with respect to a parameter,Completeness of derivatives of Hilbert basis with respect to a parameter,,"Let us take a Hilbert basis $\left|x_\lambda\right >$ in a Hilbert space $\mathcal{H}$, i.e. the $\left|x_\lambda\right >$ are a complete, orthonormal set of vectors. The subscript indicates that they depend parametrically on a parameter $\lambda$. Consider now the new family of vectors $\left|\partial_\lambda x_\lambda\right >$ that is obtained by taking the derivative with respect to $\lambda$ of $\left|x_\lambda\right >$. The notation simply means $$\left|\partial_\lambda x_\lambda\right >=\sum_i \partial_\lambda\left<i, x_\lambda\right>\left |i \right>$$ with $\left|i\right>$ some fixed, i.e. parameter-independent, basis. My question: Under what conditions is this new family complete? To be clear, an example may be the following. The eigenfunctions of the harmonic oscillator hamiltonian are a basis for $L^2(\mathbb C)$, which depends parametrically on the frequency $\omega$ of the oscillator. Are derivatives with respect to $\omega$ of Hermite polynomials times Gaussian still a complete family?","Let us take a Hilbert basis $\left|x_\lambda\right >$ in a Hilbert space $\mathcal{H}$, i.e. the $\left|x_\lambda\right >$ are a complete, orthonormal set of vectors. The subscript indicates that they depend parametrically on a parameter $\lambda$. Consider now the new family of vectors $\left|\partial_\lambda x_\lambda\right >$ that is obtained by taking the derivative with respect to $\lambda$ of $\left|x_\lambda\right >$. The notation simply means $$\left|\partial_\lambda x_\lambda\right >=\sum_i \partial_\lambda\left<i, x_\lambda\right>\left |i \right>$$ with $\left|i\right>$ some fixed, i.e. parameter-independent, basis. My question: Under what conditions is this new family complete? To be clear, an example may be the following. The eigenfunctions of the harmonic oscillator hamiltonian are a basis for $L^2(\mathbb C)$, which depends parametrically on the frequency $\omega$ of the oscillator. Are derivatives with respect to $\omega$ of Hermite polynomials times Gaussian still a complete family?",,"['functional-analysis', 'hilbert-spaces']"
14,Weak convergence in different $L^p$ spaces,Weak convergence in different  spaces,L^p,"Consider $p \ge \alpha \ge 1.$ If a sequence converges weakly in $L^p,$ say $u_n \rightharpoonup u$, is it true that: $$u_n^{\alpha} \rightharpoonup u^{\alpha} \text{ in $L^{p/ \alpha}$}$$ This question came to me, while trying to solve the following: Composition of a weakly convergent sequence with a nonlinear function We can always argue that $u_n^{\alpha}$ has a converging subsequence, but I couldn't go anywhere with this.","Consider $p \ge \alpha \ge 1.$ If a sequence converges weakly in $L^p,$ say $u_n \rightharpoonup u$, is it true that: $$u_n^{\alpha} \rightharpoonup u^{\alpha} \text{ in $L^{p/ \alpha}$}$$ This question came to me, while trying to solve the following: Composition of a weakly convergent sequence with a nonlinear function We can always argue that $u_n^{\alpha}$ has a converging subsequence, but I couldn't go anywhere with this.",,"['functional-analysis', 'lp-spaces', 'weak-convergence']"
15,Critical Homogeneous Sobolev Embedding,Critical Homogeneous Sobolev Embedding,,"For $s\in\mathbb{R}$, $1<p<\infty$, define the homogeneous Sobolev space $\dot{W}^{s,p}(\mathbb{R}^{n})$ as follows: For $f\in\mathcal{S}_{0}(\mathbb{R}^{n})$ (Schwartz functions with Fourier transforms supported away from origin), we define the homogeneous Sobolev norm $\|f\|_{\dot{W}^{s,p}(\mathbb{R}^{n})}$ by     $$\|(2\pi|\xi|^{s}\widehat{f})^{\vee}\|_{L^{p}(\mathbb{R}^{n})}=\||\nabla|^{s}f\|_{L^{p}(\mathbb{R}^{n})}$$ We define $\dot{W}^{s,p}(\mathbb{R}^{n})$ as the closure of all $f$ under this norm. I am interested in the following critical Sobolev embedding: For $1<p<\infty$ and $s=n/p$, if $f\in\dot{W}^{s,p}(\mathbb{R}^{n})$,   then $f\in BMO(\mathbb{R}^{n})$ with    $$\|f\|_{BMO(\mathbb{R}^{n})}\lesssim_{n,p}\|f\|_{\dot{W}^{s,p}(\mathbb{R}^{n})}$$ One proof of this result is via Riesz potentials and goes something as follows. Using the fact that for $0<s<n$, the Fourier transform of the distribution $|x|^{-n+s}$ is a scalar multiple of $(2\pi|\xi|)^{-s}=\widehat{|\nabla|^{-s}}$, it suffices to show that the Riesz potential satisfies the inequality     $$\|I_{s}f\|_{BMO}\leq\|f\|_{L^{n/s}},\quad\forall f\in\mathcal{S}_{0}(\mathbb{R}^{n})$$ Indeed, if $f\in\mathcal{S}_{0}$, then $|\nabla|^{s}f\in\mathcal{S}_{0}$, whence     $$\|f\|_{BMO}=\|I_{s}|\nabla|^{s}f\|_{BMO}\lesssim_{n,s}\||\nabla|^{s}f\|_{L^{n/s}}=\|f\|_{\dot{W}^{s,n/s}}$$ By translation invariance, it suffices to show that there exists a constant $A>0$ such that for all cubes $Q$ centered at the origin, there exists a constant $c_{Q}\in\mathbb{C}$     $$\int_{Q}|I_{s}(f)(y)-c_{q}|dy\leq A|Q|$$ We then have that the infimum of all such $A$ is comparable to $\|I_{s}f\|_{BMO}$. To do this, we let $Q^{*}$ denote the enlargement of a cube $Q$ by a factor of $2\sqrt{n}$ (i.e. $l(Q^{*})=2\sqrt{n}l(Q)$). We write $f=f_{1}+f_{2}$, where $f_{1}=f\chi_{Q^{**}}$. Choose $1<p_{0}<p$ and let $q_{0}$ be such that $q_{0}^{-1}=p_{0}^{-1}-(s/n)$. By the Hardy-Littlewood-Sobolev inequality together with Holder's inequality, we have the estimate \begin{align*} \dfrac{1}{|Q|}\int_{Q}|I_{s}f_{1}|dx\leq\left(\dfrac{1}{|Q|}\int_{Q}|I_{s}f_{1}|^{q_{0}}dx\right)^{1/q_{0}}&\leq|Q|^{-1/q_{0}}\left(\int_{\mathbb{R}^{n}}|I_{s}f_{1}|^{q_{0}}dx\right)^{1/q_{0}}\\ &\lesssim_{n,p_{0},s}|Q|^{-1/q_{0}}\left(\int_{Q^{*}}|f_{1}(x)|^{p_{0}}dx\right)^{1/p_{0}}\\ 	&\lesssim_{n,p,s}|Q^{*}|^{\frac{1}{p_{0}}-\frac{1}{q_{0}}}\left(\dfrac{1}{|Q^{**}|}\int_{Q^{*}}|f(x)|^{p}dx\right)^{1/p}\\ 	&\lesssim_{n,p,s}|Q|^{\frac{1}{p_{0}}-\frac{1}{q_{0}}-\frac{1}{p}}\|f\|_{L^{p}} \end{align*} where we make use of Holder's inequality. Since $\frac{1}{p_{0}}-\frac{1}{q_{0}}-\frac{1}{p}=\frac{s}{n}-\frac{1}{p}=0$, we obtain the desired estimate. Now take $$c_{Q}:=I_{s}(f_{2})(0)=\int_{(Q^{*})^{c}}f(y)|y|^{-s}dy$$ Since for $x\in Q$ and $y\in (Q^{*})^{c}$, we have that $|x-y|\geq $, we obtain from the mean value theorem that \begin{align*} |I_{s}(f_{2})(x)-c_{Q}|&\leq\int_{(Q^{*})^{c}}|f(y)|\left|\dfrac{1}{|x-y|^{s}}-\dfrac{1}{|y|^{s}}\right|dy\\ &\lesssim_{s}\int_{(Q^{*})^{c}}|f(y)|\cdot\dfrac{|x|}{|y|^{n-s+1}}dy\\ &\leq l(Q)\left(\int_{(Q^{*})^{c}}|f(y)|^{\frac{n}{s}}dy\right)^{s/n}\left(\int_{(Q^{*})^{c}}|y|^{-p'(n-s+1)}dy\right)^{1/p'}\\ &\leq l(Q)\|f\|_{L^{n/s}}\cdot l(Q)^{\frac{n}{p'}}\cdot l(Q)^{-n+s-1}\left(\int_{|y|\geq 2\sqrt{n}}|y|^{-p'(n-s+1)}dy\right)^{1/p'}\\ &=C_{n,s}\|f\|_{L^{n/s}} \end{align*} where we use Holder's inequality and dilation invariance above. By the triangle inequality, we conclude that $$\dfrac{1}{|Q|}\int_{Q}|I_{s}(f)(x)-c_{Q}|dx\lesssim_{n,s}\dfrac{1}{|Q|}\int_{Q}|I_{s}(f_{1})(x)|dx+\dfrac{1}{|Q|}\int_{Q}|I_{s}(f_{2})(x)-c_{Q}|dx\lesssim_{n,s}\|f\|_{L^{n/s}},$$ which completes the proof. In some comments which can be found here , Terence Tao says that it's possible to prove this critical Sobolev embedding via Littlewood-Paley theory and references some notes of his which may be helpful. I took a look at them, and the only result which seemed to be useful was that if a Schwartz function has compactly supported Fourier transform, then $\|f\|_{L^{\infty}}\approx\|f\|_{BMO}$. One can apply this result to individual Littlewood-Paley projections $P_{k}f$, but I don't right now how to put this individual estimates together to obtain an estimate for $\|f\|_{BMO}$ in terms of $\|f\|_{L^{n/s}}$.","For $s\in\mathbb{R}$, $1<p<\infty$, define the homogeneous Sobolev space $\dot{W}^{s,p}(\mathbb{R}^{n})$ as follows: For $f\in\mathcal{S}_{0}(\mathbb{R}^{n})$ (Schwartz functions with Fourier transforms supported away from origin), we define the homogeneous Sobolev norm $\|f\|_{\dot{W}^{s,p}(\mathbb{R}^{n})}$ by     $$\|(2\pi|\xi|^{s}\widehat{f})^{\vee}\|_{L^{p}(\mathbb{R}^{n})}=\||\nabla|^{s}f\|_{L^{p}(\mathbb{R}^{n})}$$ We define $\dot{W}^{s,p}(\mathbb{R}^{n})$ as the closure of all $f$ under this norm. I am interested in the following critical Sobolev embedding: For $1<p<\infty$ and $s=n/p$, if $f\in\dot{W}^{s,p}(\mathbb{R}^{n})$,   then $f\in BMO(\mathbb{R}^{n})$ with    $$\|f\|_{BMO(\mathbb{R}^{n})}\lesssim_{n,p}\|f\|_{\dot{W}^{s,p}(\mathbb{R}^{n})}$$ One proof of this result is via Riesz potentials and goes something as follows. Using the fact that for $0<s<n$, the Fourier transform of the distribution $|x|^{-n+s}$ is a scalar multiple of $(2\pi|\xi|)^{-s}=\widehat{|\nabla|^{-s}}$, it suffices to show that the Riesz potential satisfies the inequality     $$\|I_{s}f\|_{BMO}\leq\|f\|_{L^{n/s}},\quad\forall f\in\mathcal{S}_{0}(\mathbb{R}^{n})$$ Indeed, if $f\in\mathcal{S}_{0}$, then $|\nabla|^{s}f\in\mathcal{S}_{0}$, whence     $$\|f\|_{BMO}=\|I_{s}|\nabla|^{s}f\|_{BMO}\lesssim_{n,s}\||\nabla|^{s}f\|_{L^{n/s}}=\|f\|_{\dot{W}^{s,n/s}}$$ By translation invariance, it suffices to show that there exists a constant $A>0$ such that for all cubes $Q$ centered at the origin, there exists a constant $c_{Q}\in\mathbb{C}$     $$\int_{Q}|I_{s}(f)(y)-c_{q}|dy\leq A|Q|$$ We then have that the infimum of all such $A$ is comparable to $\|I_{s}f\|_{BMO}$. To do this, we let $Q^{*}$ denote the enlargement of a cube $Q$ by a factor of $2\sqrt{n}$ (i.e. $l(Q^{*})=2\sqrt{n}l(Q)$). We write $f=f_{1}+f_{2}$, where $f_{1}=f\chi_{Q^{**}}$. Choose $1<p_{0}<p$ and let $q_{0}$ be such that $q_{0}^{-1}=p_{0}^{-1}-(s/n)$. By the Hardy-Littlewood-Sobolev inequality together with Holder's inequality, we have the estimate \begin{align*} \dfrac{1}{|Q|}\int_{Q}|I_{s}f_{1}|dx\leq\left(\dfrac{1}{|Q|}\int_{Q}|I_{s}f_{1}|^{q_{0}}dx\right)^{1/q_{0}}&\leq|Q|^{-1/q_{0}}\left(\int_{\mathbb{R}^{n}}|I_{s}f_{1}|^{q_{0}}dx\right)^{1/q_{0}}\\ &\lesssim_{n,p_{0},s}|Q|^{-1/q_{0}}\left(\int_{Q^{*}}|f_{1}(x)|^{p_{0}}dx\right)^{1/p_{0}}\\ 	&\lesssim_{n,p,s}|Q^{*}|^{\frac{1}{p_{0}}-\frac{1}{q_{0}}}\left(\dfrac{1}{|Q^{**}|}\int_{Q^{*}}|f(x)|^{p}dx\right)^{1/p}\\ 	&\lesssim_{n,p,s}|Q|^{\frac{1}{p_{0}}-\frac{1}{q_{0}}-\frac{1}{p}}\|f\|_{L^{p}} \end{align*} where we make use of Holder's inequality. Since $\frac{1}{p_{0}}-\frac{1}{q_{0}}-\frac{1}{p}=\frac{s}{n}-\frac{1}{p}=0$, we obtain the desired estimate. Now take $$c_{Q}:=I_{s}(f_{2})(0)=\int_{(Q^{*})^{c}}f(y)|y|^{-s}dy$$ Since for $x\in Q$ and $y\in (Q^{*})^{c}$, we have that $|x-y|\geq $, we obtain from the mean value theorem that \begin{align*} |I_{s}(f_{2})(x)-c_{Q}|&\leq\int_{(Q^{*})^{c}}|f(y)|\left|\dfrac{1}{|x-y|^{s}}-\dfrac{1}{|y|^{s}}\right|dy\\ &\lesssim_{s}\int_{(Q^{*})^{c}}|f(y)|\cdot\dfrac{|x|}{|y|^{n-s+1}}dy\\ &\leq l(Q)\left(\int_{(Q^{*})^{c}}|f(y)|^{\frac{n}{s}}dy\right)^{s/n}\left(\int_{(Q^{*})^{c}}|y|^{-p'(n-s+1)}dy\right)^{1/p'}\\ &\leq l(Q)\|f\|_{L^{n/s}}\cdot l(Q)^{\frac{n}{p'}}\cdot l(Q)^{-n+s-1}\left(\int_{|y|\geq 2\sqrt{n}}|y|^{-p'(n-s+1)}dy\right)^{1/p'}\\ &=C_{n,s}\|f\|_{L^{n/s}} \end{align*} where we use Holder's inequality and dilation invariance above. By the triangle inequality, we conclude that $$\dfrac{1}{|Q|}\int_{Q}|I_{s}(f)(x)-c_{Q}|dx\lesssim_{n,s}\dfrac{1}{|Q|}\int_{Q}|I_{s}(f_{1})(x)|dx+\dfrac{1}{|Q|}\int_{Q}|I_{s}(f_{2})(x)-c_{Q}|dx\lesssim_{n,s}\|f\|_{L^{n/s}},$$ which completes the proof. In some comments which can be found here , Terence Tao says that it's possible to prove this critical Sobolev embedding via Littlewood-Paley theory and references some notes of his which may be helpful. I took a look at them, and the only result which seemed to be useful was that if a Schwartz function has compactly supported Fourier transform, then $\|f\|_{L^{\infty}}\approx\|f\|_{BMO}$. One can apply this result to individual Littlewood-Paley projections $P_{k}f$, but I don't right now how to put this individual estimates together to obtain an estimate for $\|f\|_{BMO}$ in terms of $\|f\|_{L^{n/s}}$.",,"['functional-analysis', 'fourier-analysis', 'sobolev-spaces', 'harmonic-analysis', 'littlewood-paley-theory']"
16,The sum of subspace of finite dimension with a closed set is closed,The sum of subspace of finite dimension with a closed set is closed,,"In Banach-Hilbert Spaces, Vector Measures and Group Representations ,  P142 7-4.9 Corollary Let $M$ be a closed vector subspace of a normed space $E$. Then for every finite dimensional vector subspace $N$ of $E$, the sum $M+N$ is a closed vector subspace of $E$. This also can be found on Sum of closed subspaces of normed linear space However, my exercise is not the sum of two subspace, but the sum of subspace of finite dimension with a closed set. Let $M$ be a vector subspace of a normed space $E$, and $N$ be a finite dimensional vector subspace of $E$. Assume that $M\cap N=\{0\}$, let $K$ be a closed subset in $M$, and $K\cap N=\emptyset$. I would like to know whether $N+K$ is closed. I feel that it is closed. Is the following proof right? Let $\left\{  g_{n}\right\}  $ be the bases of $N$, and $\left\{ e_{m}\right\}  $ be the bases of $M$. For any $a_{i}g_{n}\in N$ and $b_{i}% e_{m}\in K$, then $c_{i}=a_{i}g_{n}+b_{i}e_{m}\in N+K$. If $c_{i}=a_{i}% g_{n}+b_{i}e_{m}\rightarrow c=ag_{n}+be_{m}+dh_{o}\in E$, where $h_{o}$ are the remains bases of $E$. We must have $d=0$, $a_{i}\rightarrow a$ and $b_{i}\rightarrow b$. and thus $c\in N+K$.","In Banach-Hilbert Spaces, Vector Measures and Group Representations ,  P142 7-4.9 Corollary Let $M$ be a closed vector subspace of a normed space $E$. Then for every finite dimensional vector subspace $N$ of $E$, the sum $M+N$ is a closed vector subspace of $E$. This also can be found on Sum of closed subspaces of normed linear space However, my exercise is not the sum of two subspace, but the sum of subspace of finite dimension with a closed set. Let $M$ be a vector subspace of a normed space $E$, and $N$ be a finite dimensional vector subspace of $E$. Assume that $M\cap N=\{0\}$, let $K$ be a closed subset in $M$, and $K\cap N=\emptyset$. I would like to know whether $N+K$ is closed. I feel that it is closed. Is the following proof right? Let $\left\{  g_{n}\right\}  $ be the bases of $N$, and $\left\{ e_{m}\right\}  $ be the bases of $M$. For any $a_{i}g_{n}\in N$ and $b_{i}% e_{m}\in K$, then $c_{i}=a_{i}g_{n}+b_{i}e_{m}\in N+K$. If $c_{i}=a_{i}% g_{n}+b_{i}e_{m}\rightarrow c=ag_{n}+be_{m}+dh_{o}\in E$, where $h_{o}$ are the remains bases of $E$. We must have $d=0$, $a_{i}\rightarrow a$ and $b_{i}\rightarrow b$. and thus $c\in N+K$.",,"['functional-analysis', 'vector-spaces', 'normed-spaces']"
17,Advantange of having a complete topology on test functions,Advantange of having a complete topology on test functions,,"Let's consider $\mathscr D(\Omega)$, the space of test functions on $\Omega \neq \emptyset \subseteq \mathbb R^n$ as usually defined. For the sake of clareness, $$\mathscr D(\Omega) = \cup_K \mathscr D_K,$$ $K \subset \Omega$ compact, $\mathscr D_k := \{ f \in C^\infty(\Omega) \mbox{ with support in } K\}$. There are serveral ways to topologize $\mathscr D(\Omega)$. Among them, one is defining the family of norms $$\| \phi \|_N := \max \{ | D^\alpha \phi(x) | : x \in \Omega, | \alpha | \leq N\},$$ for $\phi \in \mathscr D(\Omega)$ and $N = 0, 1, 2, \dots$. The restrictions of these norms to any fixed $\mathscr D_K \subset \mathscr D(\Omega)$ induce the same topology on $\mathscr D_K$ as do the seminorms $p_N$ defined below: $$p_N( \phi ) := \max \{ | D^\alpha \phi(x) | : x \in K_N, | \alpha | \leq N\}.$$ Let's denote this topology with $\tau_K$. It is well known that each $(\mathscr D_K, \tau_K)$ is Fréchet. One can use norms $\| \phi \|_N$ to define a locally convex metrizable topology on $\mathscr D(\Omega)$, but this topology is not complete . Now, suppose we topologize $\mathscr D(\Omega)$ as the inductive limit of $\mathscr D_K$ (see Rudin). Denote this topology with $\tau$. Then $\mathscr D(\Omega)$ is complete ($\tau$-Cauchy sequences do converge). One shows that $(\mathscr D(\Omega), \tau)$ is not metrizable (hence can't be Fréchet). Most important, one shows also that $\mathscr D_K$ inherits from $(\mathscr D(\Omega), \tau)$ the same topology as before, and Theorem 6.5 in Rudin holds. Rudin says that having an uncomplete topology is a disadvantage. This is taken as a motivation to substitute $\tau_K$ with $\tau$. Finally, look at continuous linear functionals on $\mathscr D(\Omega)$. Functional like these exist in both cases, because in each case $\mathscr D(\Omega)$ is locally convex. Of course, we would not obtain the same set of linear functionals in the two cases, so we have different sets of distributions. Looking at the above remarks, one could think that these distributions will share a lot of properties . So my question is Question. Which is the striking advatange to having a complete topology on $\mathscr D(\Omega)$, if our goal is constructing a distribution theory which have the usual well-known properties (cfr. Rudin, beginning Chapter 6)? Please, note that answers like ""completeness it's always better"", ""in order to apply Open Mapping theorem"" or similar will not be accepted, if unsupported by a specific example which shows a ""crash"" of uncompleteness. Thanks in advance. Rudin, Functional Analysis .","Let's consider $\mathscr D(\Omega)$, the space of test functions on $\Omega \neq \emptyset \subseteq \mathbb R^n$ as usually defined. For the sake of clareness, $$\mathscr D(\Omega) = \cup_K \mathscr D_K,$$ $K \subset \Omega$ compact, $\mathscr D_k := \{ f \in C^\infty(\Omega) \mbox{ with support in } K\}$. There are serveral ways to topologize $\mathscr D(\Omega)$. Among them, one is defining the family of norms $$\| \phi \|_N := \max \{ | D^\alpha \phi(x) | : x \in \Omega, | \alpha | \leq N\},$$ for $\phi \in \mathscr D(\Omega)$ and $N = 0, 1, 2, \dots$. The restrictions of these norms to any fixed $\mathscr D_K \subset \mathscr D(\Omega)$ induce the same topology on $\mathscr D_K$ as do the seminorms $p_N$ defined below: $$p_N( \phi ) := \max \{ | D^\alpha \phi(x) | : x \in K_N, | \alpha | \leq N\}.$$ Let's denote this topology with $\tau_K$. It is well known that each $(\mathscr D_K, \tau_K)$ is Fréchet. One can use norms $\| \phi \|_N$ to define a locally convex metrizable topology on $\mathscr D(\Omega)$, but this topology is not complete . Now, suppose we topologize $\mathscr D(\Omega)$ as the inductive limit of $\mathscr D_K$ (see Rudin). Denote this topology with $\tau$. Then $\mathscr D(\Omega)$ is complete ($\tau$-Cauchy sequences do converge). One shows that $(\mathscr D(\Omega), \tau)$ is not metrizable (hence can't be Fréchet). Most important, one shows also that $\mathscr D_K$ inherits from $(\mathscr D(\Omega), \tau)$ the same topology as before, and Theorem 6.5 in Rudin holds. Rudin says that having an uncomplete topology is a disadvantage. This is taken as a motivation to substitute $\tau_K$ with $\tau$. Finally, look at continuous linear functionals on $\mathscr D(\Omega)$. Functional like these exist in both cases, because in each case $\mathscr D(\Omega)$ is locally convex. Of course, we would not obtain the same set of linear functionals in the two cases, so we have different sets of distributions. Looking at the above remarks, one could think that these distributions will share a lot of properties . So my question is Question. Which is the striking advatange to having a complete topology on $\mathscr D(\Omega)$, if our goal is constructing a distribution theory which have the usual well-known properties (cfr. Rudin, beginning Chapter 6)? Please, note that answers like ""completeness it's always better"", ""in order to apply Open Mapping theorem"" or similar will not be accepted, if unsupported by a specific example which shows a ""crash"" of uncompleteness. Thanks in advance. Rudin, Functional Analysis .",,"['functional-analysis', 'distribution-theory', 'topological-vector-spaces']"
18,"Generating the borel $\sigma$-algebra of $C[0,\infty)$ by the cylinder sets",Generating the borel -algebra of  by the cylinder sets,"\sigma C[0,\infty)","This is related with this post: Set $M := \{f \colon [0,\infty) \to \mathbb{R} \ |\  f \text{ continuous }\}$ with the metric of the convergence in compact sets given by  $$d(f,g) = \sum_{n=1}^\infty \frac{\left(\max_{x\in [0,n]} |f(x)-g(x)|\right)\wedge 1}{2^n}$$ Then the Borel $\sigma$-algebra $B(M)$ is generated by the cylinder sets $C(A,t_1,\dots,t_n):=\{f\in M \colon (f(t_1),\dots,f(t_n)) \in A\}$ with $n \in \mathbb{N}$ and $A \in B(\mathbb{R}^n)$ I try to use the technique used in the post above but I could only prove that for $\varepsilon < 1$ $$B(f,\varepsilon) = \bigcup_{m\in \mathbb{N}} \bigcap_{n\in \mathbb{N}} \bigcap_{t \in [0,n]\cap \mathbb{Q}} \pi_t^{-1}\left(\left( f(t) -\left(\frac{1-2^{-m}}{2}\right)\varepsilon \ , \ f(t) +\left(\frac{1-2^{-m}}{2}\right)\varepsilon\right)\right)$$ The $ \varepsilon <1 $ condition comes from the fact that if $g \in B(f,\varepsilon)$ then $\left(\max_{x\in [0,n]} |f(x)-g(x)|\right)\wedge 1 \leq \varepsilon$ and this implies $\max_{x\in [0,n]} |f(x)-g(x)| < \varepsilon$ only if  $\epsilon < 1$. Any help will be appreciated. EDIT: the equation above is not true, I don't know how to extend the technique on the other post for this case.","This is related with this post: Set $M := \{f \colon [0,\infty) \to \mathbb{R} \ |\  f \text{ continuous }\}$ with the metric of the convergence in compact sets given by  $$d(f,g) = \sum_{n=1}^\infty \frac{\left(\max_{x\in [0,n]} |f(x)-g(x)|\right)\wedge 1}{2^n}$$ Then the Borel $\sigma$-algebra $B(M)$ is generated by the cylinder sets $C(A,t_1,\dots,t_n):=\{f\in M \colon (f(t_1),\dots,f(t_n)) \in A\}$ with $n \in \mathbb{N}$ and $A \in B(\mathbb{R}^n)$ I try to use the technique used in the post above but I could only prove that for $\varepsilon < 1$ $$B(f,\varepsilon) = \bigcup_{m\in \mathbb{N}} \bigcap_{n\in \mathbb{N}} \bigcap_{t \in [0,n]\cap \mathbb{Q}} \pi_t^{-1}\left(\left( f(t) -\left(\frac{1-2^{-m}}{2}\right)\varepsilon \ , \ f(t) +\left(\frac{1-2^{-m}}{2}\right)\varepsilon\right)\right)$$ The $ \varepsilon <1 $ condition comes from the fact that if $g \in B(f,\varepsilon)$ then $\left(\max_{x\in [0,n]} |f(x)-g(x)|\right)\wedge 1 \leq \varepsilon$ and this implies $\max_{x\in [0,n]} |f(x)-g(x)| < \varepsilon$ only if  $\epsilon < 1$. Any help will be appreciated. EDIT: the equation above is not true, I don't know how to extend the technique on the other post for this case.",,"['functional-analysis', 'measure-theory']"
19,"If every functional of $f$ is smooth, is $f$ smooth?","If every functional of  is smooth, is  smooth?",f f,"Let E be a (real or complex) Banach space and suppose $f: \mathbb{R}^n \rightarrow E$ has the property that $\lambda \circ f$ is $C^\infty$ for every bounded linear functional $\lambda \in E^\ast$.  Does it follow that $f$ is also $C^\infty$? I didn't really encounter this question anywhere; it occurred to me while reading about smooth, Banach space valued functions.  I remembered that all weakly holomorphic Banach space valued functions are holomorphic and I thought it would be nice to have a similar criterion for smooth functions.","Let E be a (real or complex) Banach space and suppose $f: \mathbb{R}^n \rightarrow E$ has the property that $\lambda \circ f$ is $C^\infty$ for every bounded linear functional $\lambda \in E^\ast$.  Does it follow that $f$ is also $C^\infty$? I didn't really encounter this question anywhere; it occurred to me while reading about smooth, Banach space valued functions.  I remembered that all weakly holomorphic Banach space valued functions are holomorphic and I thought it would be nice to have a similar criterion for smooth functions.",,"['analysis', 'functional-analysis']"
20,Corollary of Banach fixed-point theorem,Corollary of Banach fixed-point theorem,,"Let $(X, \left\lVert\cdot\right\rVert)$ be a Banach space. Let $A:X\to X$ be a linear map and $\nu\in \mathbb{N}$ such that $A^k:X\to X$ is a contraction for every $k>\nu$. Is it true that for every $y\in X$ the equation $(I-A)x=y$ has a unique solution? I have shown that $A$ has a unique fixed-point $I-A^k$ is invertible for every $k>\nu$ The proposition is true if $X\cong \mathbb{K}^n$ is finite, in fact $I-A$ is invertible using the result above and Binet theorem.","Let $(X, \left\lVert\cdot\right\rVert)$ be a Banach space. Let $A:X\to X$ be a linear map and $\nu\in \mathbb{N}$ such that $A^k:X\to X$ is a contraction for every $k>\nu$. Is it true that for every $y\in X$ the equation $(I-A)x=y$ has a unique solution? I have shown that $A$ has a unique fixed-point $I-A^k$ is invertible for every $k>\nu$ The proposition is true if $X\cong \mathbb{K}^n$ is finite, in fact $I-A$ is invertible using the result above and Binet theorem.",,"['functional-analysis', 'banach-spaces', 'fixed-point-theorems']"
21,Operator in fractional spaces,Operator in fractional spaces,,"I am no mathematician so please excuse me if I don't use the right terminology. Lets say I have a function $y=f(x): x \in \mathbb{R}^3$ and $y \in \mathbb{R}^1$. So this function ""projects"" points from a higher dimensional space into a lower dimensional space. I was wondering wether you can somehow divide this projection in smaller steps, i.e, interpret this function application as an equivalent composition of several ""shorter projections"": $\mathbb{R}^3 \Rightarrow \mathbb{R}^2 \Rightarrow \mathbb{R}^1$ or in general: $\mathbb{R}^m \Rightarrow \mathbb{R}^n = 	\mathbb{R}^{k_3} \circ \mathbb{R}^{k_2} \circ \mathbb{R}^{k_1} \circ ...$ where $\sum \Delta k_i = m-n$. Taking this to the continuum case may be there is an operator $G$ and an integral like operation(for function composition) such that: $\int^n_m G(k)dk = F(n) - F(m)$ This operator $G$ could be interpreted as an infinitesimal projection transformation from dimension $k$ to dimension $k+dk$. I have found that fractional spaces have something to do with this but I haven't seen anything similar to the G operator I am referring to here. Still I hope this has already been studied Question: What is the name of this branch of math? I would be very thankful if you could direct me to some resources to see what the main results in this field are. Edit: I know there are multiple ways to go from higher dimensional spaces into lower ones. I just want to impose conditions on the way this is done, (sort of a variational calculus where the functionals infinitesimally project between dimensions and we are trying to find some ""optimum way""(optimality criteria still to be defined) of going from $\mathbb{R}^m \Rightarrow \mathbb{R}^n$) and I was looking for a theoretical foundation to start with.","I am no mathematician so please excuse me if I don't use the right terminology. Lets say I have a function $y=f(x): x \in \mathbb{R}^3$ and $y \in \mathbb{R}^1$. So this function ""projects"" points from a higher dimensional space into a lower dimensional space. I was wondering wether you can somehow divide this projection in smaller steps, i.e, interpret this function application as an equivalent composition of several ""shorter projections"": $\mathbb{R}^3 \Rightarrow \mathbb{R}^2 \Rightarrow \mathbb{R}^1$ or in general: $\mathbb{R}^m \Rightarrow \mathbb{R}^n = 	\mathbb{R}^{k_3} \circ \mathbb{R}^{k_2} \circ \mathbb{R}^{k_1} \circ ...$ where $\sum \Delta k_i = m-n$. Taking this to the continuum case may be there is an operator $G$ and an integral like operation(for function composition) such that: $\int^n_m G(k)dk = F(n) - F(m)$ This operator $G$ could be interpreted as an infinitesimal projection transformation from dimension $k$ to dimension $k+dk$. I have found that fractional spaces have something to do with this but I haven't seen anything similar to the G operator I am referring to here. Still I hope this has already been studied Question: What is the name of this branch of math? I would be very thankful if you could direct me to some resources to see what the main results in this field are. Edit: I know there are multiple ways to go from higher dimensional spaces into lower ones. I just want to impose conditions on the way this is done, (sort of a variational calculus where the functionals infinitesimally project between dimensions and we are trying to find some ""optimum way""(optimality criteria still to be defined) of going from $\mathbb{R}^m \Rightarrow \mathbb{R}^n$) and I was looking for a theoretical foundation to start with.",,['functional-analysis']
22,Which normed space have Fatou's property?,Which normed space have Fatou's property?,,"There is tool in mathematics, more specifically  in Analysis, which has immense applications in handling delicates estimates, limiting arguments, etc... ; namely Fatou property. Let $E$ be a normed space, continuously embedded into $\mathcal{S'}(\mathbb R)$(= The space of tempered distributions). We say that $E$ has a Fatou property if there exists a constant $C>0$ such that the following is true: If $\{f_{j}\}_{j\geq 0}$ is any bounded sequence in $E,$ with limit $f\in \mathcal{S'}(\mathbb R),$ then $f$ belongs to $E$ and  $$\|f\|_{E}\leq C \sup_{j\geq 0} \|f_{j}\|_{E}.$$ My Question is : Is Fatou property true for general normed space(Or Banach Space) ? If not,which kind of normed space(Or Banch space) have Fatou property and which normed space (Banach) fails for Fatou property ?","There is tool in mathematics, more specifically  in Analysis, which has immense applications in handling delicates estimates, limiting arguments, etc... ; namely Fatou property. Let $E$ be a normed space, continuously embedded into $\mathcal{S'}(\mathbb R)$(= The space of tempered distributions). We say that $E$ has a Fatou property if there exists a constant $C>0$ such that the following is true: If $\{f_{j}\}_{j\geq 0}$ is any bounded sequence in $E,$ with limit $f\in \mathcal{S'}(\mathbb R),$ then $f$ belongs to $E$ and  $$\|f\|_{E}\leq C \sup_{j\geq 0} \|f_{j}\|_{E}.$$ My Question is : Is Fatou property true for general normed space(Or Banach Space) ? If not,which kind of normed space(Or Banch space) have Fatou property and which normed space (Banach) fails for Fatou property ?",,"['analysis', 'functional-analysis', 'lp-spaces', 'distribution-theory']"
23,Every unitary representation of a compact group is a direct sum of irreducible representations.,Every unitary representation of a compact group is a direct sum of irreducible representations.,,"I've read nice proofs of a few different variants of the Peter-Weyl theorem and its corollaries. For instance I know that for $G$ a compact group, $L^2(G)$ is a Hilbert space direct sum of the matrix coefficients of the irreducible representations of $G$, all of which are finite dimensional. However, there's one fact I'm not sure how to prove: If $G$ is a compact group and $\pi : G \rightarrow \mathcal{U}(H)$ is a unitary representation of $G$ on a Hilbert space $H$,  then $(\pi, H)$ is a Hilbert space direct sum of irreducible representations.","I've read nice proofs of a few different variants of the Peter-Weyl theorem and its corollaries. For instance I know that for $G$ a compact group, $L^2(G)$ is a Hilbert space direct sum of the matrix coefficients of the irreducible representations of $G$, all of which are finite dimensional. However, there's one fact I'm not sure how to prove: If $G$ is a compact group and $\pi : G \rightarrow \mathcal{U}(H)$ is a unitary representation of $G$ on a Hilbert space $H$,  then $(\pi, H)$ is a Hilbert space direct sum of irreducible representations.",,"['analysis', 'functional-analysis', 'representation-theory']"
24,Does the open mapping theorem have a local version?,Does the open mapping theorem have a local version?,,"Let $T:X\to Y$ be a linear continuous surjection between Banach spaces $X$ and $Y$. By the open mapping theorem, we have $T$ is open. Now let $C$ be a closed convex subset of $X$ satisfying that $T(C)$ is also closed. Does $T:C\to T(C)$ is open?","Let $T:X\to Y$ be a linear continuous surjection between Banach spaces $X$ and $Y$. By the open mapping theorem, we have $T$ is open. Now let $C$ be a closed convex subset of $X$ satisfying that $T(C)$ is also closed. Does $T:C\to T(C)$ is open?",,['functional-analysis']
25,An operator inequality,An operator inequality,,"I would be most thankful if you could help me prove the following operator inequality. Let $A$ be an arbitrary linear operator on a Hilbert space, satisfying $$\left\|AA^{\ast} - A^{\ast}A\right\|\leq 2a$$ where $A^{\ast}$ is the Hermitian adjoint and $a>0$ is a constant. Let $\varepsilon$ be equal to either $+1$ or $-1$. Then show that  $$2\sqrt{A^{\ast}A + aI} - \varepsilon\left(A + A^{\ast}\right) \geq 0$$  Thank you!","I would be most thankful if you could help me prove the following operator inequality. Let $A$ be an arbitrary linear operator on a Hilbert space, satisfying $$\left\|AA^{\ast} - A^{\ast}A\right\|\leq 2a$$ where $A^{\ast}$ is the Hermitian adjoint and $a>0$ is a constant. Let $\varepsilon$ be equal to either $+1$ or $-1$. Then show that  $$2\sqrt{A^{\ast}A + aI} - \varepsilon\left(A + A^{\ast}\right) \geq 0$$  Thank you!",,"['functional-analysis', 'inequality', 'operator-theory']"
26,"A space $X$ that contains a copy of $\ell_1$, does not contain a complemented copy of $\ell_1$, and whose dual is not weakly sequentially complete","A space  that contains a copy of , does not contain a complemented copy of , and whose dual is not weakly sequentially complete",X \ell_1 \ell_1,"I want to find an example of a Banach space $X$ which contains a copy of $\ell_1$, does not contain a complemented copy of $\ell_1$, and so that $X^*$ is not weakly sequentially complete.","I want to find an example of a Banach space $X$ which contains a copy of $\ell_1$, does not contain a complemented copy of $\ell_1$, and so that $X^*$ is not weakly sequentially complete.",,"['functional-analysis', 'banach-spaces']"
27,Uniqueness for 3-dimensional heat equation initial Robin boundary value problem (SOLVED),Uniqueness for 3-dimensional heat equation initial Robin boundary value problem (SOLVED),,"Let $\Omega \subset \mathbb{R}^3$ be a bounded domain. Using an energy argument, show that the IBVP \begin{align} u_t &= \Delta u ~~~~~~~~~~x \in \Omega, ~t>0\\ \frac{\partial u}{\partial \nu} + \alpha u &= h(x) ~~~~~~~~x \in \partial\Omega, ~t>0\\ u(x,0)&=g(x) ~~~~~~~~~x \in \Omega \end{align} where $\nu$ is the exterior unit normal and $\alpha$ is a constant has at most one solution. Treat the cases $\alpha \geq 0$ and $\alpha<0$ separately. Use logarithmic convexity for the second case. My attempted solution: By contradiction, suppose that there are two solutions $u_1$ and $u_2$ and define $v = u_1 - u_2$. Then $v$ satisfies  \begin{align} v_t &= \Delta v ~~~~~~~~~~x \in \Omega, ~t>0\\ \frac{\partial v}{\partial \nu} + \alpha v &= 0 ~~~~~~~~~~~~~x \in \partial\Omega, ~t>0\\ v(x,0)&=0 ~~~~~~~~~~~~~x \in \Omega \end{align} Define the energy functional to be $$E(t)= \frac{1}{2}\int_\Omega v^2 \,dx.$$  The case $\alpha \geq 0$ is trivial. I just showed that  $$\frac{dE}{dt}=\int_\Omega v \, v_t \,dx \leq 0$$  using Green's first identity and the conditions on $v$. Then since $E(0)=0$ we must have $E(t)=0$, and hence $v=0$. For the $\alpha<0$ case I want to show that  $$E\frac{d^2E}{d^2t} - \left( \frac{dE}{dt} \right)^2 \geq 0\,.$$ Since $E \geq 0$ then by logarithmic convexity we would have $E=0$. However, I'm running into some problems. I take \begin{align} \frac{d^2E}{dt^2}=\int_\Omega v_t^2 \,dx + \int_\Omega v \, v_{tt} \,dx\,. \end{align} Then, for the second term I write \begin{align} \int_\Omega v \, v_{tt} \,dx &=\int_\Omega v \, \Delta v_t \, dx\\ &= \int_\Omega v_t \, \Delta v \, dx \\ &= \int_\Omega (v_t)^2 \, dx \end{align} where I used Green's second identity and the boundary term vanished due to the boundary condition on $v$. Explicitly: \begin{align} \int_{\partial \Omega} v\frac{\partial v_t}{\partial \nu} - v_t \frac{\partial v}{\partial \nu} dS= \alpha \int_{\partial \Omega} -v v_t + v_t v \, dS = 0 \end{align} by the homogeneous Robin condition. So I get  $$E\frac{d^2E}{d^2t} - \left( \frac{dE}{dt} \right)^2 = \frac{1}{2}\int_\Omega v^2 dx \cdot 2 \int_\Omega v_t^2 dx - \left( \int_\Omega v v_t \, dx \right)^2 \geq 0$$ by the Cauchy-Schwarz inequality. So I did the proof without even using the assumption $\alpha < 0$, which seems very strange. Did I make a mistake somewhere? EDIT: Looks like my proof is actually correct. I guess the wording of the question just had me thinking there was an issue.","Let $\Omega \subset \mathbb{R}^3$ be a bounded domain. Using an energy argument, show that the IBVP \begin{align} u_t &= \Delta u ~~~~~~~~~~x \in \Omega, ~t>0\\ \frac{\partial u}{\partial \nu} + \alpha u &= h(x) ~~~~~~~~x \in \partial\Omega, ~t>0\\ u(x,0)&=g(x) ~~~~~~~~~x \in \Omega \end{align} where $\nu$ is the exterior unit normal and $\alpha$ is a constant has at most one solution. Treat the cases $\alpha \geq 0$ and $\alpha<0$ separately. Use logarithmic convexity for the second case. My attempted solution: By contradiction, suppose that there are two solutions $u_1$ and $u_2$ and define $v = u_1 - u_2$. Then $v$ satisfies  \begin{align} v_t &= \Delta v ~~~~~~~~~~x \in \Omega, ~t>0\\ \frac{\partial v}{\partial \nu} + \alpha v &= 0 ~~~~~~~~~~~~~x \in \partial\Omega, ~t>0\\ v(x,0)&=0 ~~~~~~~~~~~~~x \in \Omega \end{align} Define the energy functional to be $$E(t)= \frac{1}{2}\int_\Omega v^2 \,dx.$$  The case $\alpha \geq 0$ is trivial. I just showed that  $$\frac{dE}{dt}=\int_\Omega v \, v_t \,dx \leq 0$$  using Green's first identity and the conditions on $v$. Then since $E(0)=0$ we must have $E(t)=0$, and hence $v=0$. For the $\alpha<0$ case I want to show that  $$E\frac{d^2E}{d^2t} - \left( \frac{dE}{dt} \right)^2 \geq 0\,.$$ Since $E \geq 0$ then by logarithmic convexity we would have $E=0$. However, I'm running into some problems. I take \begin{align} \frac{d^2E}{dt^2}=\int_\Omega v_t^2 \,dx + \int_\Omega v \, v_{tt} \,dx\,. \end{align} Then, for the second term I write \begin{align} \int_\Omega v \, v_{tt} \,dx &=\int_\Omega v \, \Delta v_t \, dx\\ &= \int_\Omega v_t \, \Delta v \, dx \\ &= \int_\Omega (v_t)^2 \, dx \end{align} where I used Green's second identity and the boundary term vanished due to the boundary condition on $v$. Explicitly: \begin{align} \int_{\partial \Omega} v\frac{\partial v_t}{\partial \nu} - v_t \frac{\partial v}{\partial \nu} dS= \alpha \int_{\partial \Omega} -v v_t + v_t v \, dS = 0 \end{align} by the homogeneous Robin condition. So I get  $$E\frac{d^2E}{d^2t} - \left( \frac{dE}{dt} \right)^2 = \frac{1}{2}\int_\Omega v^2 dx \cdot 2 \int_\Omega v_t^2 dx - \left( \int_\Omega v v_t \, dx \right)^2 \geq 0$$ by the Cauchy-Schwarz inequality. So I did the proof without even using the assumption $\alpha < 0$, which seems very strange. Did I make a mistake somewhere? EDIT: Looks like my proof is actually correct. I guess the wording of the question just had me thinking there was an issue.",,"['functional-analysis', 'partial-differential-equations']"
28,Spectral theorem for unitary operators,Spectral theorem for unitary operators,,"I saw in several texts, as a part of the spectral theorem for unitary operators, that given a unitary operator $U$ on a Hilbert space $H$ (say it is separable), $H$ can be decomposed as an orthogonal direct sum (finite or countable) of cyclic sub-spaces (i.e. spaces of the form $\operatorname{cls}(\operatorname{span}\{U^nx/n\in\mathbb{Z}\})$ for some vector $x$). I couldn't find a proof for that, so if someone could give me a reference or a sketch of the proof it would be great.","I saw in several texts, as a part of the spectral theorem for unitary operators, that given a unitary operator $U$ on a Hilbert space $H$ (say it is separable), $H$ can be decomposed as an orthogonal direct sum (finite or countable) of cyclic sub-spaces (i.e. spaces of the form $\operatorname{cls}(\operatorname{span}\{U^nx/n\in\mathbb{Z}\})$ for some vector $x$). I couldn't find a proof for that, so if someone could give me a reference or a sketch of the proof it would be great.",,"['functional-analysis', 'operator-theory', 'hilbert-spaces', 'spectral-theory']"
29,Minimal projections vs maximal left ideals,Minimal projections vs maximal left ideals,,"I've seen in some papers a statement (which is referred to a very old book of Dixmier in French which I have no access to / can't read anyway) saying that maximal left ideals of a (unital) C*-algebra $A$ are in one-to-one correspondence with minimal projections in the algebra $zA^{**}$, where $z$ is the central projection being the supremum over all minimal projections in $A^{**}$. Could one please sketch how does this correspondence work? EDIT: One way: take a maximal left ideal $L$. Then its bipolar $L^{\circ\circ}$ is a $\sigma$-closed maximal left ideal of $A^{**}$. Consequently, there is a minimal projection $e$ in $A^{**}$ such that $L^{\circ\circ}=A^{**}(1-e)$. The other way round: Take a minimal projection $e$ in $zA^{**}$ and consider the left ideal $A^{**}(1-e)$. It seems that $A\cap A^{**}(1-e)$ is a maximal left ideal of $A$.","I've seen in some papers a statement (which is referred to a very old book of Dixmier in French which I have no access to / can't read anyway) saying that maximal left ideals of a (unital) C*-algebra $A$ are in one-to-one correspondence with minimal projections in the algebra $zA^{**}$, where $z$ is the central projection being the supremum over all minimal projections in $A^{**}$. Could one please sketch how does this correspondence work? EDIT: One way: take a maximal left ideal $L$. Then its bipolar $L^{\circ\circ}$ is a $\sigma$-closed maximal left ideal of $A^{**}$. Consequently, there is a minimal projection $e$ in $A^{**}$ such that $L^{\circ\circ}=A^{**}(1-e)$. The other way round: Take a minimal projection $e$ in $zA^{**}$ and consider the left ideal $A^{**}(1-e)$. It seems that $A\cap A^{**}(1-e)$ is a maximal left ideal of $A$.",,"['functional-analysis', 'operator-algebras', 'c-star-algebras', 'von-neumann-algebras']"
30,Natural question about weak convergence.,Natural question about weak convergence.,,"Let $u_k, u \in H^{1}(\Omega)$ such that $u_k \rightharpoonup u$ (weak convergence) in $H^{1}(\Omega)$. Is true that $u_{k}^{+}\rightharpoonup u^{+}$ in $\{u\geqslant 0\}$? You can do hypothesis on $\Omega$ if you need.","Let $u_k, u \in H^{1}(\Omega)$ such that $u_k \rightharpoonup u$ (weak convergence) in $H^{1}(\Omega)$. Is true that $u_{k}^{+}\rightharpoonup u^{+}$ in $\{u\geqslant 0\}$? You can do hypothesis on $\Omega$ if you need.",,"['analysis', 'functional-analysis', 'convergence-divergence', 'sobolev-spaces', 'weak-convergence']"
31,Lipschitz continuity of an integral,Lipschitz continuity of an integral,,"Let $(E,d)$ be a metric space, $\mathscr E$ be its Borel $\sigma$-algebra and $\mu$ be a $\sigma$-finite measure on $(E,\mathscr E)$. Let the function $p:E\times E\to\mathbb R_+$ be non-negative and jointly measurabe: $p\in\mathscr E\otimes \mathscr E$. Let's assume that for any compact set $A\subset E$ there is a constant $\lambda_A$  such that $$ |p(x'',y) - p(x',y)|\leq \lambda_A\cdot d(x',x'')\text{ for all }x',x''\in A,y\in E \tag{1} $$ and let us assume that $$ \int\limits_E p(x,y)\mu(\mathrm dy) = 1 \tag{2}\text{ for all }x\in E. $$ Clearly, if $A$ is compact, then $P(x,B):=\int\limits_B p(x,y)\mu(\mathrm dy)$ is Lipschitz on $A$ whenever $\mu(B)<\infty$: $$ |P(x'',B) - P(x',B)|\leq \lambda_A\cdot\mu(B)d(x'',x'). $$ Does the Lipschitz continuity of $P(x,B)$ also hold on $A$ if $\mu(B)=\infty$?","Let $(E,d)$ be a metric space, $\mathscr E$ be its Borel $\sigma$-algebra and $\mu$ be a $\sigma$-finite measure on $(E,\mathscr E)$. Let the function $p:E\times E\to\mathbb R_+$ be non-negative and jointly measurabe: $p\in\mathscr E\otimes \mathscr E$. Let's assume that for any compact set $A\subset E$ there is a constant $\lambda_A$  such that $$ |p(x'',y) - p(x',y)|\leq \lambda_A\cdot d(x',x'')\text{ for all }x',x''\in A,y\in E \tag{1} $$ and let us assume that $$ \int\limits_E p(x,y)\mu(\mathrm dy) = 1 \tag{2}\text{ for all }x\in E. $$ Clearly, if $A$ is compact, then $P(x,B):=\int\limits_B p(x,y)\mu(\mathrm dy)$ is Lipschitz on $A$ whenever $\mu(B)<\infty$: $$ |P(x'',B) - P(x',B)|\leq \lambda_A\cdot\mu(B)d(x'',x'). $$ Does the Lipschitz continuity of $P(x,B)$ also hold on $A$ if $\mu(B)=\infty$?",,"['measure-theory', 'functional-analysis', 'metric-spaces']"
32,Banach-Steinhaus theorem for nets?,Banach-Steinhaus theorem for nets?,,"Consider an uncountable set $I$ and let $A=\mbox{Fin}(I)$ be the family of finite subsets of $I$ ordered by inclusion. Let $E$ be a normed space and $F$ be a Banach space. Suppose moreover we have a net $(T_\alpha)_{\alpha\in A}$ of bounded operators between $E$ and $F$. I want to show that $(T_\alpha)_{\alpha\in A}$ is convergent to a certain operator $T$. Is there any version of Banach-Steinhaus theorem valid in this case? That is, what I can show is the fact that $(T_\alpha x)_{\alpha\in A}$ is convergent in $Y$ to $(Tx)_{\alpha\in A}$ for each $x\in X$. Can I conclude that $(T_\alpha)_{\alpha\in A}\to T$ ?","Consider an uncountable set $I$ and let $A=\mbox{Fin}(I)$ be the family of finite subsets of $I$ ordered by inclusion. Let $E$ be a normed space and $F$ be a Banach space. Suppose moreover we have a net $(T_\alpha)_{\alpha\in A}$ of bounded operators between $E$ and $F$. I want to show that $(T_\alpha)_{\alpha\in A}$ is convergent to a certain operator $T$. Is there any version of Banach-Steinhaus theorem valid in this case? That is, what I can show is the fact that $(T_\alpha x)_{\alpha\in A}$ is convergent in $Y$ to $(Tx)_{\alpha\in A}$ for each $x\in X$. Can I conclude that $(T_\alpha)_{\alpha\in A}\to T$ ?",,"['functional-analysis', 'banach-spaces']"
33,"Eigenvalues, kernel and rank of a compact operator: how to start?","Eigenvalues, kernel and rank of a compact operator: how to start?",,"I'm trying to solve the following exercise: Let $f\in\mathcal{C}([0,1])$ and let $T$ an operator such that $Tf(x)=\int_0^1(x-t)f(t)dt$. I have proved that $T$ is a bounded linear operator and, by means of Ascoli-Arzelà theorem, that it is a compact operator. Now I need to find its kernel, its rank (showing a basis) and its spectrum. I'm quite stucked, without an idea which could make me start. Thank you for any suggestion!","I'm trying to solve the following exercise: Let $f\in\mathcal{C}([0,1])$ and let $T$ an operator such that $Tf(x)=\int_0^1(x-t)f(t)dt$. I have proved that $T$ is a bounded linear operator and, by means of Ascoli-Arzelà theorem, that it is a compact operator. Now I need to find its kernel, its rank (showing a basis) and its spectrum. I'm quite stucked, without an idea which could make me start. Thank you for any suggestion!",,"['functional-analysis', 'eigenvalues-eigenvectors', 'operator-theory']"
34,Eigenvalues of likelihood ratio,Eigenvalues of likelihood ratio,,"Consider the following hypothesis testing problem: Under $H_0$ : $(X,Y) \sim N(0,1)\times N(0,1)$ , i.e. $X$ and $Y$ are independent standard normal. Under $H_1$ : $(X,Y) \sim N\left(\begin{pmatrix}  0\\0 \end{pmatrix},\begin{pmatrix}   1& \rho\\  \rho &1 \end{pmatrix}\right)$ , i.e. they are normal distribution with correlation coefficient $\rho$ . Let $Q$ denote the density of $N(0,1)$ , then the joint density of $(X,Y)$ under $H_0$ is $Q(x)Q(y)$ . Let $P(x,y)$ denote the joint density of $(X,Y)$ under $H_1$ . Then $L(x,y)= \frac{P(x,y)}{Q(x)Q(y)}$ is the likelihood ratio. For functions $f,g:\mathbb{R}\times \mathbb{R}\to \mathbb{R}$ , lets define inner product induced by $Q$ as $<f,g> = \mathbb{E}_{(X,Y)\sim N(0,1)\times N(0,1)} f(X,Y)g(X,Y)$ . Then we know that $L(x,y)$ is diagonalizable in this inner product space and can be written as $$L(x,y) = \sum_{k=0}^{\infty} \lambda_k \phi_k(x)\phi_k(y)$$ where $\lambda_k$ 's are the eigenvalues of $L$ (in this particular example $\lambda_k = \rho^k$ ) and $\phi_k$ 's is a set of orthonomal basis (in this particular example, $\phi_k$ is Hermite polynomial multiplied by constant). My question is if we conduct a transform on the distribution of $X$ and $Y$ , will the eigenvalues of likelihood ratio change or not? To be specific, Let $F$ denote the CDF of $N(0,1)$ . Then $F(X)$ follows $U(0,1)$ (uniform distribution on $(0,1)$ ). After this transformation, we have those two new hypotheses: Under $H_0$ : $(F(X),F(Y)) \sim U(0,1)\times U(0,1)$ . Here we use $\tilde Q(x) \tilde Q(y)$ denote the new joint density. Under $H_1$ : $(F(X),F(Y))$ follows a new distribution where we use $\tilde P(x,y)$ to denote the new density. Then $\tilde L(x,y) =\frac{\tilde P(x,y)}{\tilde Q(x)\tilde Q(y)}$ is the new likelihood ratio after transformation. For functions $f,g : (0,1)\times (0,1)\to \mathbb{R}$ , we define the new inner product as $\langle f,g \rangle = \mathbb{E}_{(X,Y)\sim U(0,1)\times U(0,1)} f(X,Y)g(X,Y)$ . Then $\tilde L$ also has an decomposition in this inner product space, as $$\tilde L(x,y) = \sum_{k=0}^{\infty} \tilde \lambda_k \tilde \phi_k(x)\tilde \phi_k(y)$$ . Here we must have $\phi_k \neq \tilde \phi_k$ becasue they are orthonormal basis on different spaces. But do we have $\lambda_k = \tilde \lambda_k$ ? Sorry about the long description. Let me know if there is any thing needs clarification.","Consider the following hypothesis testing problem: Under : , i.e. and are independent standard normal. Under : , i.e. they are normal distribution with correlation coefficient . Let denote the density of , then the joint density of under is . Let denote the joint density of under . Then is the likelihood ratio. For functions , lets define inner product induced by as . Then we know that is diagonalizable in this inner product space and can be written as where 's are the eigenvalues of (in this particular example ) and 's is a set of orthonomal basis (in this particular example, is Hermite polynomial multiplied by constant). My question is if we conduct a transform on the distribution of and , will the eigenvalues of likelihood ratio change or not? To be specific, Let denote the CDF of . Then follows (uniform distribution on ). After this transformation, we have those two new hypotheses: Under : . Here we use denote the new joint density. Under : follows a new distribution where we use to denote the new density. Then is the new likelihood ratio after transformation. For functions , we define the new inner product as . Then also has an decomposition in this inner product space, as . Here we must have becasue they are orthonormal basis on different spaces. But do we have ? Sorry about the long description. Let me know if there is any thing needs clarification.","H_0 (X,Y) \sim N(0,1)\times N(0,1) X Y H_1 (X,Y) \sim N\left(\begin{pmatrix}
 0\\0
\end{pmatrix},\begin{pmatrix}
  1& \rho\\
 \rho &1
\end{pmatrix}\right) \rho Q N(0,1) (X,Y) H_0 Q(x)Q(y) P(x,y) (X,Y) H_1 L(x,y)= \frac{P(x,y)}{Q(x)Q(y)} f,g:\mathbb{R}\times \mathbb{R}\to \mathbb{R} Q <f,g> = \mathbb{E}_{(X,Y)\sim N(0,1)\times N(0,1)} f(X,Y)g(X,Y) L(x,y) L(x,y) = \sum_{k=0}^{\infty} \lambda_k \phi_k(x)\phi_k(y) \lambda_k L \lambda_k = \rho^k \phi_k \phi_k X Y F N(0,1) F(X) U(0,1) (0,1) H_0 (F(X),F(Y)) \sim U(0,1)\times U(0,1) \tilde Q(x) \tilde Q(y) H_1 (F(X),F(Y)) \tilde P(x,y) \tilde L(x,y) =\frac{\tilde P(x,y)}{\tilde Q(x)\tilde Q(y)} f,g : (0,1)\times (0,1)\to \mathbb{R} \langle f,g \rangle = \mathbb{E}_{(X,Y)\sim U(0,1)\times U(0,1)} f(X,Y)g(X,Y) \tilde L \tilde L(x,y) = \sum_{k=0}^{\infty} \tilde \lambda_k \tilde \phi_k(x)\tilde \phi_k(y) \phi_k \neq \tilde \phi_k \lambda_k = \tilde \lambda_k","['functional-analysis', 'probability-theory', 'hypothesis-testing', 'eigenfunctions']"
35,Hadamard differentiability of function,Hadamard differentiability of function,,"Let $X$ and $Y$ be Banach spaces. Definition: A function $f:X\rightarrow Y$ is called Hadamard differentiable at $x\in X$ tangentially to $U\subseteq X$ iff $x\in U$ and there exists a continuous linear function $f'_x:U\rightarrow Y$ such that for all $u\in U$ it holds that $$\left\Vert\frac{f(x + \delta_nu_n)-f(x)}{\delta_n} - f'_x(u)\right\Vert_Y\rightarrow 0$$ as $n\rightarrow\infty$ for every sequence $(u_n)_{n\in\mathbb N}$ in $X$ converging to $u$ and every sequence $(\delta_n)_{n\in\mathbb N}$ in $\mathbb R$ converging to $0$ . Problem: In my case, $X = \textit{BV}([a,b])\times\textit{BV}([a,b])$ , where $\textit{BV}([a,b])$ is the set of all real-valued functions on $[a,b]$ that are of bounded variation, $Y = \mathbb R$ , and $$f(F,G) = \int_a^b F\,\mathrm dG.$$ Here the integral is the Lebesgue-Stieltjes integral; note that since real-valued functions on a compact set that are of bounded variation are also bounded and real-valued functions are measurable, $f$ is well-defined. Is $f$ Hadamard differentiable (maybe tangentially to some subset $U$ ) for each $(F,G)\in X$ ? I know that if $X = \big(\textit{BV}([a,b])\cap\textit{D}([a,b])\big)\times\big(\textit{BV}([a,b])\cap\textit{D}([a,b])\big)$ , where $D([a,b])$ is the space of real-valued cadlag functions on $[a,b]$ , then $f$ is Hadamard differentiable with derivative $$f_{(F,G)}'(A,B) = B(b)F(b) - B(a)F(a) - \int_a^b B_{-}\,\mathrm dF + \int_a^b A\,\mathrm dG,$$ where $B_{-}$ is the left-continuous version of the right-continuous function $B$ . <Edit: In an earlier version of this post, there was an error. I wrote $B(F(a))$ instead of $B(a)F(a)$ (and similar for $b$ ). The error is also in the comments. I hope this error didn't cause any confusion. > However, since I am operating on the larger space $\textit{BV}([a,b])\times\textit{BV}([a,b])$ , I suppose that this result no longer holds. Therefore my question: is there any hope that $f$ is still Hadamard differentiable on this larger space? Unfortunately, I have no idea how to tackle this problem. So any help is appreciated. The functions I want apply $f$ to are the of the form $\frac{L + R}2$ , where $L$ and $R$ are left- and right-continuous functions with the same points discontinuities (i.e., if $L$ is discontinuous at $t\in[a,b]$ , then so is $R$ ). So I have some form of continuity and an at most countable set of discontinuities. Maybe that's enough to have Hadamard differentiability tangentially to the set of these functions?","Let and be Banach spaces. Definition: A function is called Hadamard differentiable at tangentially to iff and there exists a continuous linear function such that for all it holds that as for every sequence in converging to and every sequence in converging to . Problem: In my case, , where is the set of all real-valued functions on that are of bounded variation, , and Here the integral is the Lebesgue-Stieltjes integral; note that since real-valued functions on a compact set that are of bounded variation are also bounded and real-valued functions are measurable, is well-defined. Is Hadamard differentiable (maybe tangentially to some subset ) for each ? I know that if , where is the space of real-valued cadlag functions on , then is Hadamard differentiable with derivative where is the left-continuous version of the right-continuous function . <Edit: In an earlier version of this post, there was an error. I wrote instead of (and similar for ). The error is also in the comments. I hope this error didn't cause any confusion. > However, since I am operating on the larger space , I suppose that this result no longer holds. Therefore my question: is there any hope that is still Hadamard differentiable on this larger space? Unfortunately, I have no idea how to tackle this problem. So any help is appreciated. The functions I want apply to are the of the form , where and are left- and right-continuous functions with the same points discontinuities (i.e., if is discontinuous at , then so is ). So I have some form of continuity and an at most countable set of discontinuities. Maybe that's enough to have Hadamard differentiability tangentially to the set of these functions?","X Y f:X\rightarrow Y x\in X U\subseteq X x\in U f'_x:U\rightarrow Y u\in U \left\Vert\frac{f(x + \delta_nu_n)-f(x)}{\delta_n} - f'_x(u)\right\Vert_Y\rightarrow 0 n\rightarrow\infty (u_n)_{n\in\mathbb N} X u (\delta_n)_{n\in\mathbb N} \mathbb R 0 X = \textit{BV}([a,b])\times\textit{BV}([a,b]) \textit{BV}([a,b]) [a,b] Y = \mathbb R f(F,G) = \int_a^b F\,\mathrm dG. f f U (F,G)\in X X = \big(\textit{BV}([a,b])\cap\textit{D}([a,b])\big)\times\big(\textit{BV}([a,b])\cap\textit{D}([a,b])\big) D([a,b]) [a,b] f f_{(F,G)}'(A,B) = B(b)F(b) - B(a)F(a) - \int_a^b B_{-}\,\mathrm dF + \int_a^b A\,\mathrm dG, B_{-} B B(F(a)) B(a)F(a) b \textit{BV}([a,b])\times\textit{BV}([a,b]) f f \frac{L + R}2 L R L t\in[a,b] R","['functional-analysis', 'banach-spaces', 'stieltjes-integral']"
36,Limit of a particular trace norm.,Limit of a particular trace norm.,,"I have the following problem. Let $\mathbf{\hat{\rho}}(t)$ and $\mathbf{\hat{\sigma}}(t)$ be two trace class positive operators acting on a Hilbert space of infinite dimension for all $t > 0$ . More precisely assume that $$ \mathbf{\hat{\rho}}(t):= \int p_{i}(x)e^{-ixt\mathbf{\hat{B}}}\big|\psi\big\rangle \big\langle \psi\big|e^{ixt\mathbf{\hat{B}}}dx $$ $$ \mathbf{\hat{\sigma}}(t):= \int p_{j}(x)e^{-ixt\mathbf{\hat{B}}}\big|\psi\big\rangle \big\langle \psi\big|e^{ixt\mathbf{\hat{B}}}dx $$ where $\mathbf{\hat{B}} $ is a self-adjoint operator with purely absolutely continuous spectrum and $\big|\psi\big\rangle$ is any vector in the Hilbert space in question, and $p_{i}$ and $p_{j}$ are probability distributions with compact support which is nonoverlapping. I am trying to prove that $$\lim_{t\rightarrow \infty}\big\|\sqrt{\mathbf{\hat{\rho}}(t)}\sqrt{\mathbf{\hat{\sigma}}(t)}\big\|_{1}= 0  \;\; (quantum\; fidelity)$$ However, this has proven to be quite a challenge since there are no good upper bounds for the quantum fidelity in the general case were both of the operators in question are not pure. I have tried using the following celebrated bound. $$ \big\|\sqrt{\mathbf{\hat{\rho}}(t)}\sqrt{\mathbf{\hat{\sigma}}(t)}\big\|_{1}\leq\sqrt{1-\big\|\mathbf{\hat{\rho}}(t)-\mathbf{\hat{\sigma}}(t)\big\|_{1}^{2}} $$ but this just replaces a very difficult problem with one of equal complexity. For the simpler version of this problem where $$\mathbf{\hat{\rho}}(t):=e^{-ix_{i}t\mathbf{\hat{B}}}\big|\psi\big\rangle \big\langle \psi\big|e^{ix_{i}t\mathbf{\hat{B}}} $$ and $$ \mathbf{\hat{\sigma}}(t):=e^{-ix_{j}t\mathbf{\hat{B}}}\big|\psi\big\rangle \big\langle \psi\big|e^{ix_{j}t\mathbf{\hat{B}}} $$ with $x_{i}\neq x_{j}$ and all of the other assumptions preserved I can easily show the analogous hypothesis. Here $$  \lim_{t\rightarrow \infty}\big\|\sqrt{\mathbf{\hat{\rho}}(t)}\sqrt{\mathbf{\hat{\sigma}}(t)}\big\|_{1} = \big|\langle \psi\big|e^{-t(x_{i}-x_{j})\mathbf{\hat{B}}}\big|\psi\big\rangle\big| = \int e^{-t(x_{i}-x_{j})\lambda}d\mu_{\psi}(\lambda) $$ where $d\mu_{\psi}(\lambda)$ is the absolutely continnuous spectral measure afforded by $\big|\psi\rangle$ . Owing to the Riemann Lebegues lemma indeed $\lim_{t\rightarrow \infty}\int e^{-t(x_{i}-x_{j})\lambda}d\mu_{\psi}(\lambda) = 0$ . Due to this result, I am led to believe that the more general case where $\mathbf{\hat{\rho}}(t)$ and $\mathbf{\hat{\sigma}}(t)$ are uncountable mixtures as presented above, we should have the same sort of behavior as $t\rightarrow \infty$ . However, the quantum fidelity is unwieldy. Any help tackling this problem would be greatly appreciated.","I have the following problem. Let and be two trace class positive operators acting on a Hilbert space of infinite dimension for all . More precisely assume that where is a self-adjoint operator with purely absolutely continuous spectrum and is any vector in the Hilbert space in question, and and are probability distributions with compact support which is nonoverlapping. I am trying to prove that However, this has proven to be quite a challenge since there are no good upper bounds for the quantum fidelity in the general case were both of the operators in question are not pure. I have tried using the following celebrated bound. but this just replaces a very difficult problem with one of equal complexity. For the simpler version of this problem where and with and all of the other assumptions preserved I can easily show the analogous hypothesis. Here where is the absolutely continnuous spectral measure afforded by . Owing to the Riemann Lebegues lemma indeed . Due to this result, I am led to believe that the more general case where and are uncountable mixtures as presented above, we should have the same sort of behavior as . However, the quantum fidelity is unwieldy. Any help tackling this problem would be greatly appreciated.","\mathbf{\hat{\rho}}(t) \mathbf{\hat{\sigma}}(t) t > 0 
\mathbf{\hat{\rho}}(t):= \int p_{i}(x)e^{-ixt\mathbf{\hat{B}}}\big|\psi\big\rangle \big\langle \psi\big|e^{ixt\mathbf{\hat{B}}}dx
 
\mathbf{\hat{\sigma}}(t):= \int p_{j}(x)e^{-ixt\mathbf{\hat{B}}}\big|\psi\big\rangle \big\langle \psi\big|e^{ixt\mathbf{\hat{B}}}dx
 \mathbf{\hat{B}}  \big|\psi\big\rangle p_{i} p_{j} \lim_{t\rightarrow \infty}\big\|\sqrt{\mathbf{\hat{\rho}}(t)}\sqrt{\mathbf{\hat{\sigma}}(t)}\big\|_{1}= 0  \;\; (quantum\; fidelity) 
\big\|\sqrt{\mathbf{\hat{\rho}}(t)}\sqrt{\mathbf{\hat{\sigma}}(t)}\big\|_{1}\leq\sqrt{1-\big\|\mathbf{\hat{\rho}}(t)-\mathbf{\hat{\sigma}}(t)\big\|_{1}^{2}}
 \mathbf{\hat{\rho}}(t):=e^{-ix_{i}t\mathbf{\hat{B}}}\big|\psi\big\rangle \big\langle \psi\big|e^{ix_{i}t\mathbf{\hat{B}}}
 
\mathbf{\hat{\sigma}}(t):=e^{-ix_{j}t\mathbf{\hat{B}}}\big|\psi\big\rangle \big\langle \psi\big|e^{ix_{j}t\mathbf{\hat{B}}}
 x_{i}\neq x_{j} 
 \lim_{t\rightarrow \infty}\big\|\sqrt{\mathbf{\hat{\rho}}(t)}\sqrt{\mathbf{\hat{\sigma}}(t)}\big\|_{1} = \big|\langle \psi\big|e^{-t(x_{i}-x_{j})\mathbf{\hat{B}}}\big|\psi\big\rangle\big| = \int e^{-t(x_{i}-x_{j})\lambda}d\mu_{\psi}(\lambda)
 d\mu_{\psi}(\lambda) \big|\psi\rangle \lim_{t\rightarrow \infty}\int e^{-t(x_{i}-x_{j})\lambda}d\mu_{\psi}(\lambda) = 0 \mathbf{\hat{\rho}}(t) \mathbf{\hat{\sigma}}(t) t\rightarrow \infty","['functional-analysis', 'measure-theory', 'operator-theory', 'trace', 'quantum-mechanics']"
37,The set of unitary operators on a complex separable Hilbert space is connected,The set of unitary operators on a complex separable Hilbert space is connected,,"In my functional analysis class I was given a problem: Let $H$ be complex separable Hilbert space. Prove that the set of unitary operators on $H$ is connected (as topological space with operator norm). I know the proof that unitary operators are path-connected , so they are connected. This proof is not short. And I wonder if it is possible to prove that unitary operators are connected without proving path-connectedness? It would give shorter proof of this problem. I do not have any ideas how to prove connectedness of unitary operators without proving path-connectedness, so any hints are appreciated. Thanks!","In my functional analysis class I was given a problem: Let be complex separable Hilbert space. Prove that the set of unitary operators on is connected (as topological space with operator norm). I know the proof that unitary operators are path-connected , so they are connected. This proof is not short. And I wonder if it is possible to prove that unitary operators are connected without proving path-connectedness? It would give shorter proof of this problem. I do not have any ideas how to prove connectedness of unitary operators without proving path-connectedness, so any hints are appreciated. Thanks!",H H,"['functional-analysis', 'operator-theory']"
38,On different types of convergence of Fourier Series.,On different types of convergence of Fourier Series.,,"I‘m currently going through my lecture notes and am a bit confused by the different convergence results and would be happy if someone could clarify:) In the following we always have $f \in L^2((-\pi, \pi), \mathbb{C})$ and $c_k(f):=\frac{1}{2\pi}\int_{-\pi}^{\pi} f(x) e^{-ikx} \ dx$ . We define the $N^{th}$ Fourier partial sum as: $S_N(f)(x):=\sum_{k=-N}^N c_k(f)e^{ikx}$ . Now my first result is that with $\mathcal{F}:=\{\frac{e^{ikx}}{\sqrt{s\pi}} | k \in \mathbb{Z}\}$ the span $\operatorname{Span}(\mathcal{F})$ , i.e. the Fourier partial sums, are dense in the space of continuous, $2\pi-$ periodic functions with respect to the $L^{\infty}$ norm, i.e. the sup norm (up to set of measure zero). Then it follows (since continuous and compactly supported functions are dense in $L^2((-\pi, \pi), \mathbb{C})$ ), that $\operatorname{Span}(\mathcal{F})$ is also dense in all of $L^2((-\pi, \pi), \mathbb{C})$ w.r.t. the $L^2$ norm. Thus $\mathcal{F}$ is a basis for the Hilbert space $L^2((-\pi, \pi), \mathbb{C})$ . Now my professor remarks that the preceding does not imply that the Fourier sequence of Fourier partial sums converges uniformly to any continuous, compactly supported (on $(-\pi, \pi)$ ) $f$ . I‘m not sure I get that, we have just stated that: $$ \forall \epsilon>0 \ \exists S_N(f) \in \operatorname{Span}(\mathcal{F}): ||f-S_N(f)||_{L^{\infty}}=\operatorname{ess} \sup |f-S_n|=\inf \{M \in \mathbb{R} | \mu(\{x:|f(x)-S_N(f)(x)|>M\})=0\} < \epsilon $$ Haven’t we? This is equivalent to uniform convergence almost everywhere, isn’t it? What’s the problem? Edit: The only problem I see here is that all coefficients in $S_N(f)$ are allowed to change as $\epsilon$ gets smaller, whereas if we consider uniform convergence „the coefficients with lower indices“ have to stay fixed as $\epsilon$ gets smaller (I hope this makes sense), could that be the issue? What about pointwise convergence almost everywhere, I know that if a sequence of functions converges in $L^p$ norm then there exists a subsequence that converges pointwise almost everywhere. Wouldn’t that suggest that for all $f \in L^2(-\pi, \pi)$ there is a sequence $(N_j)_{j \in \mathbb{N}}$ s.t.: $$ f(x)=\lim_{j \rightarrow \infty} \sum_{k=N_j}^{N_j}c_ke^{ikx} $$ for almost every $x \in (-\pi, \pi)$ . I fail to see why this doesn’t imply: $$ f(x)=\lim_{N \rightarrow \infty} S_N(f)(x) $$ Shouldn’t these limits be identical? Regarding this my professor remarks that we do indeed have pointwise convergence almost everywhere but that this isn’t a direct consequence from Hilbert space theory (only proved in 1966 by L. Carleson). So I‘d be happy if someone could clarify my confusion regarding uniform and pointwise convergence:)","I‘m currently going through my lecture notes and am a bit confused by the different convergence results and would be happy if someone could clarify:) In the following we always have and . We define the Fourier partial sum as: . Now my first result is that with the span , i.e. the Fourier partial sums, are dense in the space of continuous, periodic functions with respect to the norm, i.e. the sup norm (up to set of measure zero). Then it follows (since continuous and compactly supported functions are dense in ), that is also dense in all of w.r.t. the norm. Thus is a basis for the Hilbert space . Now my professor remarks that the preceding does not imply that the Fourier sequence of Fourier partial sums converges uniformly to any continuous, compactly supported (on ) . I‘m not sure I get that, we have just stated that: Haven’t we? This is equivalent to uniform convergence almost everywhere, isn’t it? What’s the problem? Edit: The only problem I see here is that all coefficients in are allowed to change as gets smaller, whereas if we consider uniform convergence „the coefficients with lower indices“ have to stay fixed as gets smaller (I hope this makes sense), could that be the issue? What about pointwise convergence almost everywhere, I know that if a sequence of functions converges in norm then there exists a subsequence that converges pointwise almost everywhere. Wouldn’t that suggest that for all there is a sequence s.t.: for almost every . I fail to see why this doesn’t imply: Shouldn’t these limits be identical? Regarding this my professor remarks that we do indeed have pointwise convergence almost everywhere but that this isn’t a direct consequence from Hilbert space theory (only proved in 1966 by L. Carleson). So I‘d be happy if someone could clarify my confusion regarding uniform and pointwise convergence:)","f \in L^2((-\pi, \pi), \mathbb{C}) c_k(f):=\frac{1}{2\pi}\int_{-\pi}^{\pi} f(x) e^{-ikx} \ dx N^{th} S_N(f)(x):=\sum_{k=-N}^N c_k(f)e^{ikx} \mathcal{F}:=\{\frac{e^{ikx}}{\sqrt{s\pi}} | k \in \mathbb{Z}\} \operatorname{Span}(\mathcal{F}) 2\pi- L^{\infty} L^2((-\pi, \pi), \mathbb{C}) \operatorname{Span}(\mathcal{F}) L^2((-\pi, \pi), \mathbb{C}) L^2 \mathcal{F} L^2((-\pi, \pi), \mathbb{C}) (-\pi, \pi) f 
\forall \epsilon>0 \ \exists S_N(f) \in \operatorname{Span}(\mathcal{F}): ||f-S_N(f)||_{L^{\infty}}=\operatorname{ess} \sup |f-S_n|=\inf \{M \in \mathbb{R} | \mu(\{x:|f(x)-S_N(f)(x)|>M\})=0\} < \epsilon
 S_N(f) \epsilon \epsilon L^p f \in L^2(-\pi, \pi) (N_j)_{j \in \mathbb{N}} 
f(x)=\lim_{j \rightarrow \infty} \sum_{k=N_j}^{N_j}c_ke^{ikx}
 x \in (-\pi, \pi) 
f(x)=\lim_{N \rightarrow \infty} S_N(f)(x)
","['functional-analysis', 'measure-theory', 'fourier-analysis', 'fourier-series', 'harmonic-analysis']"
39,"How can I prove that this subset $C$ is closed in $C[0,1]$?",How can I prove that this subset  is closed in ?,"C C[0,1]","Let $C=\{f\in C[0,1]: f(0)=f(1)\}$ . I need to show that $C$ is closed in $C[0,1]$ with respect to $||f||_{\infty}=\max(f)$ . I know that I can define $\phi(f)=f(0)-f(1)$ and then argue that $\phi$ is continuous and $C=\phi^{-1}(\{0\})$ . But I wanted to do it in another way: Proof Let $(f_n)_n$ be a sequence in $C$ s.t. $$f_n\stackrel{||\cdot||_\infty}{\longrightarrow}f\in C[0,1]$$ I want to show that $f\in C$ . But now consider $$\begin{align}|f_n(0)-f(0)|&\leq\max_x|f_n(x)-f(x)|\\&=||f_n-f||_\infty\rightarrow0\end{align}$$ Similarly for $f_n(1)$ . So we get $\lim_nf_n(0)=f(0)$ and $\lim_nf_n(1)=f(1)$ , but since the limit is unique and for all $n$ we have $f_n(0)=f_n(1)$ , we deduce that $f(0)=f(1)$ and therefore $f\in C$ . Now my question is does this work or am I wrong?","Let . I need to show that is closed in with respect to . I know that I can define and then argue that is continuous and . But I wanted to do it in another way: Proof Let be a sequence in s.t. I want to show that . But now consider Similarly for . So we get and , but since the limit is unique and for all we have , we deduce that and therefore . Now my question is does this work or am I wrong?","C=\{f\in C[0,1]: f(0)=f(1)\} C C[0,1] ||f||_{\infty}=\max(f) \phi(f)=f(0)-f(1) \phi C=\phi^{-1}(\{0\}) (f_n)_n C f_n\stackrel{||\cdot||_\infty}{\longrightarrow}f\in C[0,1] f\in C \begin{align}|f_n(0)-f(0)|&\leq\max_x|f_n(x)-f(x)|\\&=||f_n-f||_\infty\rightarrow0\end{align} f_n(1) \lim_nf_n(0)=f(0) \lim_nf_n(1)=f(1) n f_n(0)=f_n(1) f(0)=f(1) f\in C","['functional-analysis', 'analysis', 'solution-verification', 'uniform-convergence', 'pointwise-convergence']"
40,Banach space of a unitization non-unital $C^\ast$-algebra and norms as well,Banach space of a unitization non-unital -algebra and norms as well,C^\ast,"I've discussed a problem with good mathematicians here. We consider again a non-unital $C^\ast$ -algebra. Let's consider the following $C^\ast$ -algebra. That is, the $C^\ast$ -algebra $\mathcal{A}$ with norm $\|\cdot\|$ . Let $\tilde{\mathcal{A}}=\mathcal{A}\oplus \mathbb{C}$ as a vector space. We endow it with multiplication and involution, $$(a,\lambda)\cdot (b,\mu):=(ab+\lambda b+\mu a,\lambda \mu)$$ and $$(a,\lambda)^\ast:=(a^\ast,\bar{\lambda})$$ I already did some proofs including proof of homomorphism and norm etc. so we will take that for granted. Now take $x\in\tilde{\mathcal{A}}$ then we consider the linear map $\tilde{L}_x:\tilde{\mathcal{A}}\rightarrow \tilde{\mathcal{A}}$ by $y\mapsto xy$ restricts to a map, $L_x:\mathcal{A}\rightarrow \mathcal{A}$ which is bounded with $\|L_x\|_\infty \leq \|x\|_1$ . This is already proven. Notice that we know the one-norm is given by $x=(a,\lambda)\in \tilde{\mathcal{A}}$ by $\|x\|_1=\|a\|+|\lambda|$ and of course $\|\cdot\|_\infty$ denote the operator norm. Let's consider the following Banach space, call it $\mathscr{X}:=\mathcal{A}\oplus \mathbb{C}$ with the following norm. $$\|(a,\lambda)\|_{\max}=\max\{\|a\|,|\lambda|\}.$$ Set $x=(a,\lambda)$ and let $x\in \tilde{\mathcal{A}}$ , then I define the following: $p(x):\mathscr{X}\rightarrow \mathscr{X}$ by using a matrix given below, i.e. $$p(x)=\begin{pmatrix} L_x & 0 \\ 0 & \lambda \\ \end{pmatrix}$$ My questions: Can we verify that $p(x)\in\mathbb{B}(\mathscr{X})$ and further show $\|p(x)\|_\infty=\max\{\|L_x\|_\infty,|\lambda|\}$ ? Is $p$ a unital, injective homomorphism of algebras? Here $\mathbb{\mathscr{X}}$ is bounded operators on a Banach space $\mathscr{X}$ . For my second question I know the idea of homomorphism but now injective homomorphism ? Any suggestion would be helpful for me! If there are more conditions to show homomorphism, I would like to see how one of them can be done then I will do the other conditions. Further let's define a new norm on $\tilde{\mathcal{A}}$ by setting $\|(a,\lambda)\|_\sim=\|p(a,\lambda)\|_\infty$ . My third and last question. Is it possible to show the norm $\|\cdot \|_\infty$ restricts to the original $C^\ast$ -norm on $\mathcal{A}\subset\tilde{\mathcal{A}}$ ? I know that there is a lot of questions and I hope someone could help me to understand this way more better than I already do. I hope someone can give me an detailed answers/sketches so I can understand this and fill details. Thanks in advance. If I get a great answer I will mark it accepted.","I've discussed a problem with good mathematicians here. We consider again a non-unital -algebra. Let's consider the following -algebra. That is, the -algebra with norm . Let as a vector space. We endow it with multiplication and involution, and I already did some proofs including proof of homomorphism and norm etc. so we will take that for granted. Now take then we consider the linear map by restricts to a map, which is bounded with . This is already proven. Notice that we know the one-norm is given by by and of course denote the operator norm. Let's consider the following Banach space, call it with the following norm. Set and let , then I define the following: by using a matrix given below, i.e. My questions: Can we verify that and further show ? Is a unital, injective homomorphism of algebras? Here is bounded operators on a Banach space . For my second question I know the idea of homomorphism but now injective homomorphism ? Any suggestion would be helpful for me! If there are more conditions to show homomorphism, I would like to see how one of them can be done then I will do the other conditions. Further let's define a new norm on by setting . My third and last question. Is it possible to show the norm restricts to the original -norm on ? I know that there is a lot of questions and I hope someone could help me to understand this way more better than I already do. I hope someone can give me an detailed answers/sketches so I can understand this and fill details. Thanks in advance. If I get a great answer I will mark it accepted.","C^\ast C^\ast C^\ast \mathcal{A} \|\cdot\| \tilde{\mathcal{A}}=\mathcal{A}\oplus \mathbb{C} (a,\lambda)\cdot (b,\mu):=(ab+\lambda b+\mu a,\lambda \mu) (a,\lambda)^\ast:=(a^\ast,\bar{\lambda}) x\in\tilde{\mathcal{A}} \tilde{L}_x:\tilde{\mathcal{A}}\rightarrow \tilde{\mathcal{A}} y\mapsto xy L_x:\mathcal{A}\rightarrow \mathcal{A} \|L_x\|_\infty \leq \|x\|_1 x=(a,\lambda)\in \tilde{\mathcal{A}} \|x\|_1=\|a\|+|\lambda| \|\cdot\|_\infty \mathscr{X}:=\mathcal{A}\oplus \mathbb{C} \|(a,\lambda)\|_{\max}=\max\{\|a\|,|\lambda|\}. x=(a,\lambda) x\in \tilde{\mathcal{A}} p(x):\mathscr{X}\rightarrow \mathscr{X} p(x)=\begin{pmatrix}
L_x & 0 \\
0 & \lambda \\
\end{pmatrix} p(x)\in\mathbb{B}(\mathscr{X}) \|p(x)\|_\infty=\max\{\|L_x\|_\infty,|\lambda|\} p \mathbb{\mathscr{X}} \mathscr{X} \tilde{\mathcal{A}} \|(a,\lambda)\|_\sim=\|p(a,\lambda)\|_\infty \|\cdot \|_\infty C^\ast \mathcal{A}\subset\tilde{\mathcal{A}}","['functional-analysis', 'operator-theory', 'operator-algebras', 'c-star-algebras']"
41,Prove spectral convergence $\lim\limits_{n\to\infty} \sigma(P_n H P_n) = \sigma(H)$,Prove spectral convergence,\lim\limits_{n\to\infty} \sigma(P_n H P_n) = \sigma(H),"Suppose we want to numerically solve the following Schrodinger equation on a bounded open set $\Omega \subset \mathbb R^n$ : $$Hu = (-\Delta + V(x)) u = \lambda u, \qquad \left.u\right\vert_{\partial \Omega} = 0,\qquad V \in L^2(\Omega,\mathbb R), \not \equiv 0$$ I will discretize the Hamiltonian as a finite-dimensional operator $H_N$ acting on an orthonormal basis $(\phi_j)_{j=1}^N$ (where $\phi_j$ are Dirichlet eigenfunctions of $-\Delta$ on $\Omega$ with eigenvalues $\mu_j$ ). This is called the expansion method . Now I have: $$H_{N_{nm}} = \langle \phi_n, H \phi_m\rangle = \mu_n\delta_{nm} + \langle \phi_n, V \phi_m\rangle$$ Alternatively, we can write this as $$H_N = P_N H ,\qquad P_N = \text{projection onto }\operatorname{span}(\phi_j)_{j=1}^N$$ Note that both $H$ and $H_N$ are self-adjoint. Furthermore, by convention we can define $H_N$ as an operator acting in $H^1_0(\Omega)$ by defining: $$H_N := P_N H P_N$$ Now, referencing to Mathematical Methods in Quantum Mechanics by G. Teschl, I am able to prove $H_N$ converges to $H$ in the strong resolvent sense, which in turn gives us: $$\lim_{N\to \infty} \sigma(H_N) \supseteq \sigma(H)$$ I am, however, a bit confused why it's so hard to show either $H_N \to H$ in the norm resolvent sense (which would give us equality in the spectral limit above), or go from the above spectral containment then show it is indeed an equality (perhaps by contradiction). Do I have reason to believe that: $$\lim_{N\to\infty} \sigma(H_N) = \sigma(H)$$ isn't necessarily true? If so, could I put additional requirements on $V$ in order for this to be true? I suppose the proof might be similar to the analog for a finite-difference method, but I couldn't find any literature on that either.","Suppose we want to numerically solve the following Schrodinger equation on a bounded open set : I will discretize the Hamiltonian as a finite-dimensional operator acting on an orthonormal basis (where are Dirichlet eigenfunctions of on with eigenvalues ). This is called the expansion method . Now I have: Alternatively, we can write this as Note that both and are self-adjoint. Furthermore, by convention we can define as an operator acting in by defining: Now, referencing to Mathematical Methods in Quantum Mechanics by G. Teschl, I am able to prove converges to in the strong resolvent sense, which in turn gives us: I am, however, a bit confused why it's so hard to show either in the norm resolvent sense (which would give us equality in the spectral limit above), or go from the above spectral containment then show it is indeed an equality (perhaps by contradiction). Do I have reason to believe that: isn't necessarily true? If so, could I put additional requirements on in order for this to be true? I suppose the proof might be similar to the analog for a finite-difference method, but I couldn't find any literature on that either.","\Omega \subset \mathbb R^n Hu = (-\Delta + V(x)) u = \lambda u, \qquad \left.u\right\vert_{\partial \Omega} = 0,\qquad V \in L^2(\Omega,\mathbb R), \not \equiv 0 H_N (\phi_j)_{j=1}^N \phi_j -\Delta \Omega \mu_j H_{N_{nm}} = \langle \phi_n, H \phi_m\rangle = \mu_n\delta_{nm} + \langle \phi_n, V \phi_m\rangle H_N = P_N H ,\qquad P_N = \text{projection onto }\operatorname{span}(\phi_j)_{j=1}^N H H_N H_N H^1_0(\Omega) H_N := P_N H P_N H_N H \lim_{N\to \infty} \sigma(H_N) \supseteq \sigma(H) H_N \to H \lim_{N\to\infty} \sigma(H_N) = \sigma(H) V","['functional-analysis', 'partial-differential-equations', 'spectral-theory']"
42,"Existence of bases for $L^2(X,\mu )$ with special properties.",Existence of bases for  with special properties.,"L^2(X,\mu )","Let $X$ be a compact metric space and let $\mu $ be a Borel probability measure on $X$ .  The following questions regard the existence of orthonormal bases  for the complex  Hilbert space $L^2(X,\mu )$ with special properties. Does $L^2(X,\mu )$ admit a basis $\{f_i\}_i$ formed by continuous functions with $|f_i(x)|=1$ , for every $i$ and $x$ . Does $L^2(X,\mu )$ admit a basis $\{f_i\}_i$ with $|f_i(x)|=1$ , for every $i$ and almost every $x$ . Does $L^2(X,\mu )$ admit a basis $\{f_i\}_i$ formed by continuous functions with $\sup_{i, x}|f_i(x)|<\infty $ . Does $L^2(X,\mu )$ admit a basis $\{f_i\}_i$ with $\sup_i\|f_i\|_\infty <\infty $ . The inexistence of atoms for $\mu$ might be relevant, so you are welcome to assume this in case it helps. If you need motivation for this question, note that for every compact abelian group $G$ , with normalized Haar measure, the answer to (1) is affirmative, with the group characters forming a basis.","Let be a compact metric space and let be a Borel probability measure on .  The following questions regard the existence of orthonormal bases  for the complex  Hilbert space with special properties. Does admit a basis formed by continuous functions with , for every and . Does admit a basis with , for every and almost every . Does admit a basis formed by continuous functions with . Does admit a basis with . The inexistence of atoms for might be relevant, so you are welcome to assume this in case it helps. If you need motivation for this question, note that for every compact abelian group , with normalized Haar measure, the answer to (1) is affirmative, with the group characters forming a basis.","X \mu  X L^2(X,\mu ) L^2(X,\mu ) \{f_i\}_i |f_i(x)|=1 i x L^2(X,\mu ) \{f_i\}_i |f_i(x)|=1 i x L^2(X,\mu ) \{f_i\}_i \sup_{i, x}|f_i(x)|<\infty  L^2(X,\mu ) \{f_i\}_i \sup_i\|f_i\|_\infty <\infty  \mu G","['functional-analysis', 'measure-theory', 'hilbert-spaces']"
43,Proving that the quotient $\ell^\infty/c_0$ is not reflexive,Proving that the quotient  is not reflexive,\ell^\infty/c_0,"Let $\ell^\infty$ be the space of bounded sequences with the maximum norm and $c_0$ the space of sequences that have limit $0$ with the same norm. I use the notation $E^*$ for the dual of a normed space $E$ . I know that $c_0$ is a closed subspace of $\ell^\infty$ , that $c_0^{**}=\ell^\infty$ , and that both $c_0$ and $\ell^\infty$ are not reflexive. How can I prove that $\ell^\infty/c_0$ is not reflexive? My best guess has been using that a space is reflexive iff its dual is reflexive. The dual of the quotient is $(\ell^\infty/c_0)^*=c_0^\perp$ , the orthogonal of $c_0$ in the dual of $\ell^\infty$ (thanks to David for the correction). This is a closed subspace of $(\ell^\infty)^*$ and $(\ell^\infty)^*$ is also not reflexive, but I don't think this implies that $c_0^\perp$ is not reflexive. I also tried using the characterization ""A Banach space is reflexive iff the unit ball is weakly compact"" but I haven't been able to prove that the ball isn't weakly compact.","Let be the space of bounded sequences with the maximum norm and the space of sequences that have limit with the same norm. I use the notation for the dual of a normed space . I know that is a closed subspace of , that , and that both and are not reflexive. How can I prove that is not reflexive? My best guess has been using that a space is reflexive iff its dual is reflexive. The dual of the quotient is , the orthogonal of in the dual of (thanks to David for the correction). This is a closed subspace of and is also not reflexive, but I don't think this implies that is not reflexive. I also tried using the characterization ""A Banach space is reflexive iff the unit ball is weakly compact"" but I haven't been able to prove that the ball isn't weakly compact.",\ell^\infty c_0 0 E^* E c_0 \ell^\infty c_0^{**}=\ell^\infty c_0 \ell^\infty \ell^\infty/c_0 (\ell^\infty/c_0)^*=c_0^\perp c_0 \ell^\infty (\ell^\infty)^* (\ell^\infty)^* c_0^\perp,"['functional-analysis', 'reflexive-space']"
44,"Operator norm in Hilbert space, Schur criterion for infnite matrices","Operator norm in Hilbert space, Schur criterion for infnite matrices",,"Let H be Hilbert with an orthonormal basis $(e_n)_n$ . Consider $A,B>0$ and two sequence $a_n>0, b_n>0$ such that $$\sum_{i=1}^\infty b_i(T e_i, e_j)\leq Aa_j \quad\text{and}\quad \sum_{j=1}^\infty a_j(T e_i, e_j)\leq Bb_i.$$ Show that $T$ extends to continuous linear operator and that $\|T\|\leq \sqrt{AB}$ Assume that $(Te_i, e_j)=\frac{1}{j+i-1}$ prove that $\|T\|\leq \pi.$ If $(Te_i, e_j)=\frac{1}{2^{j+i-1}}$ then compute $\|T\|.$ As explained in this question it is possible to get that, $$\|T\|\leq \Big( \sum_{j=1}^\infty \sum_{i=1}^\infty (Te_i, e_j)^2\Big)^{1/2}. $$ How do I move from here?","Let H be Hilbert with an orthonormal basis . Consider and two sequence such that Show that extends to continuous linear operator and that Assume that prove that If then compute As explained in this question it is possible to get that, How do I move from here?","(e_n)_n A,B>0 a_n>0, b_n>0 \sum_{i=1}^\infty b_i(T e_i, e_j)\leq Aa_j \quad\text{and}\quad \sum_{j=1}^\infty a_j(T e_i, e_j)\leq Bb_i. T \|T\|\leq \sqrt{AB} (Te_i, e_j)=\frac{1}{j+i-1} \|T\|\leq \pi. (Te_i, e_j)=\frac{1}{2^{j+i-1}} \|T\|. \|T\|\leq \Big( \sum_{j=1}^\infty \sum_{i=1}^\infty (Te_i, e_j)^2\Big)^{1/2}. ","['functional-analysis', 'hilbert-spaces', 'normed-spaces', 'orthonormal']"
45,Incomplete inner product space has a subspace such that the direct sum with orthogonal isn't the whole space,Incomplete inner product space has a subspace such that the direct sum with orthogonal isn't the whole space,,"I would like to show that for any incomplete inner product space $H$ there exists a closed subspace $H_0$ such that $H_0 + H_0^{\bot}\neq H$ Here and there vere slightly relevant discussion. I saw an example for continuous functions (complex inner product inherited from $L_2$ ) and a subspace of functions such that $\int_0^1 f(t) dt = \int_{-1}^{0} f(t) dt$ which is closed and is not the whole subspace, but the orthogonal complement is zero. We could may be prove that there always exists a subspace such that the orthogonal complement to $H_0$ in the completion of the space $H$ doesn't lie in the image of $H$ under the standard isometric injection into the completion.","I would like to show that for any incomplete inner product space there exists a closed subspace such that Here and there vere slightly relevant discussion. I saw an example for continuous functions (complex inner product inherited from ) and a subspace of functions such that which is closed and is not the whole subspace, but the orthogonal complement is zero. We could may be prove that there always exists a subspace such that the orthogonal complement to in the completion of the space doesn't lie in the image of under the standard isometric injection into the completion.",H H_0 H_0 + H_0^{\bot}\neq H L_2 \int_0^1 f(t) dt = \int_{-1}^{0} f(t) dt H_0 H H,"['functional-analysis', 'inner-products']"
46,Separation of variables of 2nd order PDE yields 1st order ODEs,Separation of variables of 2nd order PDE yields 1st order ODEs,,"Consider the telegraph or Klein-Gordon equation on a rectangle*, $$ \begin{align} \left(\frac{\partial^2}{\partial x^2}-\frac{\partial^2}{\partial y^2}\right)\psi(x,y)=\gamma^2\psi(x,y), \end{align} $$ with $\gamma$ some arbitrary (maybe complex) constant . Suppose that the necessary initial conditions are given ( $\psi$ or its $x$ derivative at $x_1$ and $x_2$ if $x$ varies between $[x_1,x_2]$ , and $\psi(x,t_0)$ and $\partial\psi(x,t_0)/\partial t$ at some arbitrary $t_0$ ), then it is convenient to separate variables in the form $\psi=A(x)B(y)$ , which yields the ODEs $$ \begin{align} \frac{\mathrm{d}^2A}{\mathrm{d}x^2}=-\alpha^2A\;\;\;,\;\;\frac{\mathrm{d}^2B}{\mathrm{d}y^2}=-(\gamma^2+\alpha^2)B, \end{align} $$ for $\alpha$ some (maybe complex) constant. These are second order equations and then the problem is essentially solved thanks to Sturm-Liouville: along $x$ and $y$ lines we have complete bases that can span generic initial/boundary data. Now we rotate the coordinates: $$ \begin{align} u=x+y\;\;\;,\;\;v=x-y \end{align} $$ and observe that the equation becomes $$ \begin{align} \frac{\partial}{\partial v}\frac{\partial}{\partial u}\psi(u,v)=\frac{\gamma^2}{2}\psi(u,v), \end{align} $$ and after separating variables as $\psi=U(u)V(v)$ we have that $$ \begin{align} \frac{\mathrm{d}\log U}{\mathrm{d} u}\frac{\mathrm{d}\log V}{\mathrm{d} v}=\frac{\gamma^2}{2}. \end{align} $$ There are several ways to split the constants (e.g. $\frac{\mathrm{d}\log U}{\mathrm{d} u}=\beta,\;\frac{\mathrm{d}\log V}{\mathrm{d} v}=\frac{\gamma^2}{2\beta}$ , with $\beta$ an arbitrary constant), but the point is that Now we have 1st rather than 2nd order equations Then, is it true that the eigenfunctions form a basis that can span arbitrary initial/boundary data (specified on the $(u,v)$ plane)? I suspect the answer is no because the family of real exponentials are not complete. Moreover, is there any deep reason for the separated ODEs to become 1st order equations after the rotation ? *The rectangle is just to illustrate the problem, but something similar may happen on several different domains.","Consider the telegraph or Klein-Gordon equation on a rectangle*, with some arbitrary (maybe complex) constant . Suppose that the necessary initial conditions are given ( or its derivative at and if varies between , and and at some arbitrary ), then it is convenient to separate variables in the form , which yields the ODEs for some (maybe complex) constant. These are second order equations and then the problem is essentially solved thanks to Sturm-Liouville: along and lines we have complete bases that can span generic initial/boundary data. Now we rotate the coordinates: and observe that the equation becomes and after separating variables as we have that There are several ways to split the constants (e.g. , with an arbitrary constant), but the point is that Now we have 1st rather than 2nd order equations Then, is it true that the eigenfunctions form a basis that can span arbitrary initial/boundary data (specified on the plane)? I suspect the answer is no because the family of real exponentials are not complete. Moreover, is there any deep reason for the separated ODEs to become 1st order equations after the rotation ? *The rectangle is just to illustrate the problem, but something similar may happen on several different domains.","
\begin{align}
\left(\frac{\partial^2}{\partial x^2}-\frac{\partial^2}{\partial y^2}\right)\psi(x,y)=\gamma^2\psi(x,y),
\end{align}
 \gamma \psi x x_1 x_2 x [x_1,x_2] \psi(x,t_0) \partial\psi(x,t_0)/\partial t t_0 \psi=A(x)B(y) 
\begin{align}
\frac{\mathrm{d}^2A}{\mathrm{d}x^2}=-\alpha^2A\;\;\;,\;\;\frac{\mathrm{d}^2B}{\mathrm{d}y^2}=-(\gamma^2+\alpha^2)B,
\end{align}
 \alpha x y 
\begin{align}
u=x+y\;\;\;,\;\;v=x-y
\end{align}
 
\begin{align}
\frac{\partial}{\partial v}\frac{\partial}{\partial u}\psi(u,v)=\frac{\gamma^2}{2}\psi(u,v),
\end{align}
 \psi=U(u)V(v) 
\begin{align}
\frac{\mathrm{d}\log U}{\mathrm{d} u}\frac{\mathrm{d}\log V}{\mathrm{d} v}=\frac{\gamma^2}{2}.
\end{align}
 \frac{\mathrm{d}\log U}{\mathrm{d} u}=\beta,\;\frac{\mathrm{d}\log V}{\mathrm{d} v}=\frac{\gamma^2}{2\beta} \beta (u,v)","['functional-analysis', 'partial-differential-equations', 'mathematical-physics', 'sturm-liouville']"
47,Functional Analysis: Kernel-Based Approximation,Functional Analysis: Kernel-Based Approximation,,"First of all, let me give a basic definition and the problem that we want to solve [both taken from Armin Iske's Book ""Approximation Theory and Algorithms for Data Analysis""]: Problem 8.1. On given interpolation points $X = \{x_1, \dots, x_n\}\subset \Omega$ , where $\Omega\subset \mathbb R^{d}$ for $d>1$ , and function values $f_X\in \mathbb R^{n}$ find an interpolant $s\in \mathcal C(\Omega)$ satisfying $s_X = f_X$ , so that $s$ satisfies the interpolation conditions $$s(x_j) = f(x_j) \quad \text{for all $1\leq j\leq n$}.$$ Definition 8.2. [taken from Armin Iske's Book ""Approximation Theory and Algorithms for Data Analysis""]: A continuous and symmetric function $K: \mathbb R^{d}\times \mathbb R^{d} \rightarrow \mathbb R$ is said to be positive definite on $\mathbb R^{d}$ , $K\in \textbf{PD}_d$ , if for any set of pairwise distinct interpolation points $X = \left\{ x_1, \dots, x_n\right\} \subset \mathbb R^{d}$ , $n\in \mathbb N$ , the matrix $$A_{K, X} = \left( K\left(x_k, x_j\right) \right)_{1\leq j, k\leq n}\in\mathbb R^{n\times n}$$ is symmetric and positive definite. Now, here comes the problem that I want to solve: Let $\Phi\left(x-y\right) = K(x,y)$ be positive definite, $K\in \textbf{PD}_d$ , where $\Phi:\mathbb R^{d}\rightarrow \mathbb R$ is even and satisfies, for $\alpha > 0$ , the growth condition $$\left\vert \Phi\left(0\right) - \Phi\left( x\right) \right\vert \leq C \left\vert\left\vert  x\right\vert\right\vert_{2}^{\gamma} \quad \forall x\in B_{R}\left( 0\right)$$ on some ball $B_{R}\left( 0\right)$ around $0$ with radius $R > 0$ and constant $C > 0$ . Prove that no positive definite kernel $K\in \textbf{PD}_d$ satisfies the growth condition for $\gamma > 2$ . This is a homework we got in a class. EDIT : This is the definition of (total) differentiability I know: Let $U\subseteq \mathbb R^n$ be open and $F: U\rightarrow \mathbb R^m$ . (i) The function $F$ is called (totally) differentiable if there exists a linear map $A: \mathbb R^n\rightarrow\mathbb R^m$ such that $$\lim_{\xi\in\mathbb R^n\backslash\{0\},\ \xi\rightarrow 0}\frac{\|F(x+\xi)-F(x)-A(\xi)\|}{\|\xi\|} = 0$$ (ii) The function $F: U\rightarrow\mathbb R^m$ is called differentiable if $F$ is at all points $x\in U$ differentiable.","First of all, let me give a basic definition and the problem that we want to solve [both taken from Armin Iske's Book ""Approximation Theory and Algorithms for Data Analysis""]: Problem 8.1. On given interpolation points , where for , and function values find an interpolant satisfying , so that satisfies the interpolation conditions Definition 8.2. [taken from Armin Iske's Book ""Approximation Theory and Algorithms for Data Analysis""]: A continuous and symmetric function is said to be positive definite on , , if for any set of pairwise distinct interpolation points , , the matrix is symmetric and positive definite. Now, here comes the problem that I want to solve: Let be positive definite, , where is even and satisfies, for , the growth condition on some ball around with radius and constant . Prove that no positive definite kernel satisfies the growth condition for . This is a homework we got in a class. EDIT : This is the definition of (total) differentiability I know: Let be open and . (i) The function is called (totally) differentiable if there exists a linear map such that (ii) The function is called differentiable if is at all points differentiable.","X = \{x_1, \dots, x_n\}\subset \Omega \Omega\subset \mathbb R^{d} d>1 f_X\in \mathbb R^{n} s\in \mathcal C(\Omega) s_X = f_X s s(x_j) = f(x_j) \quad \text{for all 1\leq j\leq n}. K: \mathbb R^{d}\times \mathbb R^{d} \rightarrow \mathbb R \mathbb R^{d} K\in \textbf{PD}_d X = \left\{ x_1, \dots, x_n\right\} \subset \mathbb R^{d} n\in \mathbb N A_{K, X} = \left( K\left(x_k, x_j\right) \right)_{1\leq j, k\leq n}\in\mathbb R^{n\times n} \Phi\left(x-y\right) = K(x,y) K\in \textbf{PD}_d \Phi:\mathbb R^{d}\rightarrow \mathbb R \alpha > 0 \left\vert \Phi\left(0\right) - \Phi\left( x\right) \right\vert \leq C \left\vert\left\vert  x\right\vert\right\vert_{2}^{\gamma} \quad \forall x\in B_{R}\left( 0\right) B_{R}\left( 0\right) 0 R > 0 C > 0 K\in \textbf{PD}_d \gamma > 2 U\subseteq \mathbb R^n F: U\rightarrow \mathbb R^m F A: \mathbb R^n\rightarrow\mathbb R^m \lim_{\xi\in\mathbb R^n\backslash\{0\},\ \xi\rightarrow 0}\frac{\|F(x+\xi)-F(x)-A(\xi)\|}{\|\xi\|} = 0 F: U\rightarrow\mathbb R^m F x\in U","['functional-analysis', 'approximation', 'reproducing-kernel-hilbert-spaces']"
48,Improvement of Jensen inequality for random variables,Improvement of Jensen inequality for random variables,,"Jensen inequality implies that for every real random variable $X$ and every integer $n\in \mathbb N$ $$ (\mathbb E[X^2])^n \,\leq\, \mathbb E[X^{2n}]$$ by convexity of the function $x\mapsto x^n$ for $x\geq0$ . Now if we apply the previous inequality to a Gaussian random variable $X$ of mean $0$ and variance $\sigma^2$ we find: $$ \sigma^{2n} \,\leq\, \sigma^{2n}\, (2n-1)!!$$ which of course is not very good for large $n$ since $(n-1)!!$ grows faster than exponential. Is there an alternative / improvement of Jensen inequality that bounds $(\mathbb E)^n$ with a linear operator defined on a suitable space of random variables functions of $X^2$ and preserving exponential growth for large $n$ ? Edit. I would be happy enough if I could do that for all $X$ having a strong log-concave distribution on $\mathbb R$ , namely $$\mathbb E [\varphi(X)] \,=\, \int_{-\infty}^{\infty}\, \varphi(x)\,e^{-U(x)} \,dx $$ with $U''(x)\geq\lambda>0$ for all $x\in\mathbb R\,$ , for all $\varphi:\mathbb R\to\mathbb R$ having polynomial growth. Notice that the Gaussian case corresponds to $U(x)=(x-\mu)^2/(2\sigma^2) + \frac{1}{2}\log(2\pi\sigma^2)$ . Edit 2. A possible modification of this question could be: for which family of random variables it holds true $$ (\mathbb E[X^2])^n \,\leq\, \frac{c^n}{(2n-1)!!}\,\mathbb E[X^{2n}]$$ for some $c>0$ and all $n\in\mathbb N\,$ ? Centred Gaussian random variables for example satisfy the inequality with $c=1$ .","Jensen inequality implies that for every real random variable and every integer by convexity of the function for . Now if we apply the previous inequality to a Gaussian random variable of mean and variance we find: which of course is not very good for large since grows faster than exponential. Is there an alternative / improvement of Jensen inequality that bounds with a linear operator defined on a suitable space of random variables functions of and preserving exponential growth for large ? Edit. I would be happy enough if I could do that for all having a strong log-concave distribution on , namely with for all , for all having polynomial growth. Notice that the Gaussian case corresponds to . Edit 2. A possible modification of this question could be: for which family of random variables it holds true for some and all ? Centred Gaussian random variables for example satisfy the inequality with .","X n\in \mathbb N  (\mathbb E[X^2])^n \,\leq\, \mathbb E[X^{2n}] x\mapsto x^n x\geq0 X 0 \sigma^2  \sigma^{2n} \,\leq\, \sigma^{2n}\, (2n-1)!! n (n-1)!! (\mathbb E)^n X^2 n X \mathbb R \mathbb E [\varphi(X)] \,=\, \int_{-\infty}^{\infty}\, \varphi(x)\,e^{-U(x)} \,dx  U''(x)\geq\lambda>0 x\in\mathbb R\, \varphi:\mathbb R\to\mathbb R U(x)=(x-\mu)^2/(2\sigma^2) + \frac{1}{2}\log(2\pi\sigma^2)  (\mathbb E[X^2])^n \,\leq\, \frac{c^n}{(2n-1)!!}\,\mathbb E[X^{2n}] c>0 n\in\mathbb N\, c=1","['functional-analysis', 'probability-theory', 'measure-theory', 'convex-analysis', 'gaussian-integral']"
49,Bound in the Hille-Yosida Theorem,Bound in the Hille-Yosida Theorem,,"I saw the following version of the Hille-Yosida theorem in a book: However, from the proof that I have seen, they only proof the bound $$\left|\left|\frac{\partial Y}{\partial s}(s)\right|\right|=\left|\left|AY(s)\right|\right| \le \left|\left|AY_0\right|\right|$$ I know that the proof of the theorem follows from studying the Yosida approximations, but I am unable to prove $\left|\left|AY(s)\right|\right| \le \frac 1s\left|\left|Y_0\right|\right|$ from that.","I saw the following version of the Hille-Yosida theorem in a book: However, from the proof that I have seen, they only proof the bound I know that the proof of the theorem follows from studying the Yosida approximations, but I am unable to prove from that.",\left|\left|\frac{\partial Y}{\partial s}(s)\right|\right|=\left|\left|AY(s)\right|\right| \le \left|\left|AY_0\right|\right| \left|\left|AY(s)\right|\right| \le \frac 1s\left|\left|Y_0\right|\right|,"['functional-analysis', 'partial-differential-equations', 'unbounded-operators']"
50,"Density of polynomials in $L^2(\mathbb{R},d\mu)$",Density of polynomials in,"L^2(\mathbb{R},d\mu)","My question concerns a generalised version of the following fact from standard functional analysis books: The space $\mathbb{C}[x]$ of (complex-valued) polynomials on $[0,1]$ (or any other compact of $\mathbb{R}$ , of course) is dense in $L^2(0,1)$ , with the usual Lebesgue measure. The latter fact can be shown with a two-step argument: (1) the continuous functions $C([0,1])$ are dense in $L^2(0,1)$ , with $\|f\|_{L^2}\leq\|f\|_{L^\infty}$ ; (2) by Stone-Weierstrass $\mathbb{C}[x]$ is dense in $(C([0,1]),\|\cdot\|_{L^\infty})$ . Now, the new setting I'm wondering about is this. Let $\mu$ be a (positive regular Borel) measure on $\mathbb{R}$ such that all monomials $x^n$ , $n=0,1,2,\dots$ , are integrable. (For example: $d\mu(x)=e^{-x^2}dx$ .) In particular, $\mu$ is a finite measure. Thus, $\mathbb{C}[x]\subset L^2(\mathbb{R},d\mu)$ and its closure in the $L^2$ -norm is a closed Hilbert subspace of $L^2(\mathbb{R},d\mu)$ . I am to understand from indirect claims I found on various textbooks that in general such a closure subspace is not the whole $L^2(\mathbb{R},d\mu)$ , i.e., the polynomials are not necessarily dense in such $L^2(\mathbb{R},d\mu)$ . Is that true? Can anyone give me an example of lack of density? From the argument above on $[0,1]$ with Lebesgue measure at least I can save the inequality $\|f\|_{L^2}\leq \mathrm{const}\times\|f\|_{L^\infty}$ and also a standard density like the $C^\infty_0$ -functions into the $L^2$ -functions still holds true. So, where does the approximation mechanism break up? Thank you!","My question concerns a generalised version of the following fact from standard functional analysis books: The space of (complex-valued) polynomials on (or any other compact of , of course) is dense in , with the usual Lebesgue measure. The latter fact can be shown with a two-step argument: (1) the continuous functions are dense in , with ; (2) by Stone-Weierstrass is dense in . Now, the new setting I'm wondering about is this. Let be a (positive regular Borel) measure on such that all monomials , , are integrable. (For example: .) In particular, is a finite measure. Thus, and its closure in the -norm is a closed Hilbert subspace of . I am to understand from indirect claims I found on various textbooks that in general such a closure subspace is not the whole , i.e., the polynomials are not necessarily dense in such . Is that true? Can anyone give me an example of lack of density? From the argument above on with Lebesgue measure at least I can save the inequality and also a standard density like the -functions into the -functions still holds true. So, where does the approximation mechanism break up? Thank you!","\mathbb{C}[x] [0,1] \mathbb{R} L^2(0,1) C([0,1]) L^2(0,1) \|f\|_{L^2}\leq\|f\|_{L^\infty} \mathbb{C}[x] (C([0,1]),\|\cdot\|_{L^\infty}) \mu \mathbb{R} x^n n=0,1,2,\dots d\mu(x)=e^{-x^2}dx \mu \mathbb{C}[x]\subset L^2(\mathbb{R},d\mu) L^2 L^2(\mathbb{R},d\mu) L^2(\mathbb{R},d\mu) L^2(\mathbb{R},d\mu) [0,1] \|f\|_{L^2}\leq \mathrm{const}\times\|f\|_{L^\infty} C^\infty_0 L^2","['functional-analysis', 'measure-theory', 'polynomials']"
51,What kind of categorical construct is the tensor product of Hilbert spaces?,What kind of categorical construct is the tensor product of Hilbert spaces?,,"Let $H_1$ and $H_2$ be Hilbert spaces. We can form the algebraic tensor product $H_1 \odot H_2$ and complete it with respect to the inner product $$\langle \xi_1 \otimes \xi_2, \eta _1 \otimes  \eta_2 \rangle:= \langle \xi_1, \eta_1\rangle \langle \xi_2, \eta_2\rangle$$ In this way, we obtain the Hilbert space $H_1 \otimes H_2$ . Consider the category HILB of Hilbert spaces, say with contractive linear maps as morphisms. Can we view $H_1 \otimes H_2$ as some kind of limit in this category? Does it satisfy some useful universal property? Really, any answer can be as broad as you like. I am aware that $\otimes$ defines a bifunctor that gives us a monoidal structure on this category.","Let and be Hilbert spaces. We can form the algebraic tensor product and complete it with respect to the inner product In this way, we obtain the Hilbert space . Consider the category HILB of Hilbert spaces, say with contractive linear maps as morphisms. Can we view as some kind of limit in this category? Does it satisfy some useful universal property? Really, any answer can be as broad as you like. I am aware that defines a bifunctor that gives us a monoidal structure on this category.","H_1 H_2 H_1 \odot H_2 \langle \xi_1 \otimes \xi_2, \eta _1 \otimes  \eta_2 \rangle:= \langle \xi_1, \eta_1\rangle \langle \xi_2, \eta_2\rangle H_1 \otimes H_2 H_1 \otimes H_2 \otimes",['functional-analysis']
52,Prove that a parabolic problem is well posed (Lax-Milgram lemma appilication),Prove that a parabolic problem is well posed (Lax-Milgram lemma appilication),,"I need a check on the following problem, which is an application of the Lax-Milgram lemma. $$ \begin{cases} \dfrac{\partial u}{\partial t} -\dfrac{\partial }{\partial x} \Bigl( \alpha \dfrac{\partial u}{\partial x}\Bigr) - \beta u =0 \\ u(x,0)=u_0(x), & x \in [0,1] \\ u = \eta, & x=0,\; t>0 \\ \alpha \dfrac{\partial u}{\partial x} + \gamma u =0, & x=1,\; t>0 \end{cases} $$ where $\alpha(x), u_0(x)$ are given functions, $\beta >0$ and $\eta,\gamma \in \mathbb{R}$ . Question. Prove existence and uniqueness of the weak solution, giving some suitable assumptions on $\alpha(x)$ , $\gamma, \eta$ . Here's my attempt: As test functions, I choose $v \in V=H_{\Gamma_d}^1$ , where $\Gamma_d={0}$ ,i.e. I use tes functions which are $0$ where I have the Dirichlet data. By multiplying, with standard arguments one obtains the following bilinear form $$a(u,v)=\gamma u(1)v(1) + \int_0^1 \alpha u' v' dx - \beta \int_0^1 u v dx$$ To show existence and uniqueness, I need to show $a(v,v) + \lambda \geq \alpha \|v\|_V^2$ (weakly coercive) $a(u,v) \leq M \|u\|_V \|v\|_V$ Weakly coercive : Assume $0<\alpha_0 < \alpha(x) < \alpha_1$ $$a(v,v) + \beta \|v\|_V^2 \geq \frac{\alpha_0}{1+C_p^2} \|v\|_V^2 + \gamma v(1)^2$$ where $C_p$ is the Poincarè constant. If $\gamma >0$ , then: $$a(v,v) + \beta \|v\|_V^2 \geq \frac{\alpha_0}{1+C_p^2} \|v\|_V^2$$ i.e. $a(\cdot, \cdot)$ is weakly coercive. Continuity : $$|a(u,v)| \leq \alpha_1 \|u\|_V \|v\|_V + \beta \|u\|_V \|v\|_V + \gamma u(1)v(1)$$ Now, since I want a bound with the $H^1$ norm, I note that $$|u(1)| \leq \int_0^1 |u'(s)|ds + \eta$$ and therefore $$|u(1)| \leq \|u\|_V + \eta$$ Also, $v(1) = \int_0^1 v'(s)ds$ implies $|v(1)| \leq \|v\|_V$ Hence, $$|a(u,v)| \leq (\alpha_1 + \beta) \|u\|_V \|v\|_V+\gamma \|u\|_V \|v\|_V + \gamma \eta \|v\|_V $$ Now, if $\eta <0$ , then $$|a(u,v)| \leq (\alpha_1+\beta+\gamma)\|u\|_V \|v\|_V$$","I need a check on the following problem, which is an application of the Lax-Milgram lemma. where are given functions, and . Question. Prove existence and uniqueness of the weak solution, giving some suitable assumptions on , . Here's my attempt: As test functions, I choose , where ,i.e. I use tes functions which are where I have the Dirichlet data. By multiplying, with standard arguments one obtains the following bilinear form To show existence and uniqueness, I need to show (weakly coercive) Weakly coercive : Assume where is the Poincarè constant. If , then: i.e. is weakly coercive. Continuity : Now, since I want a bound with the norm, I note that and therefore Also, implies Hence, Now, if , then","
\begin{cases}
\dfrac{\partial u}{\partial t} -\dfrac{\partial }{\partial x} \Bigl( \alpha \dfrac{\partial u}{\partial x}\Bigr) - \beta u =0 \\
u(x,0)=u_0(x), & x \in [0,1] \\
u = \eta, & x=0,\; t>0 \\
\alpha \dfrac{\partial u}{\partial x} + \gamma u =0, & x=1,\; t>0
\end{cases}
 \alpha(x), u_0(x) \beta >0 \eta,\gamma \in \mathbb{R} \alpha(x) \gamma, \eta v \in V=H_{\Gamma_d}^1 \Gamma_d={0} 0 a(u,v)=\gamma u(1)v(1) + \int_0^1 \alpha u' v' dx - \beta \int_0^1 u v dx a(v,v) + \lambda \geq \alpha \|v\|_V^2 a(u,v) \leq M \|u\|_V \|v\|_V 0<\alpha_0 < \alpha(x) < \alpha_1 a(v,v) + \beta \|v\|_V^2 \geq \frac{\alpha_0}{1+C_p^2} \|v\|_V^2 + \gamma v(1)^2 C_p \gamma >0 a(v,v) + \beta \|v\|_V^2 \geq \frac{\alpha_0}{1+C_p^2} \|v\|_V^2 a(\cdot, \cdot) |a(u,v)| \leq \alpha_1 \|u\|_V \|v\|_V + \beta \|u\|_V \|v\|_V + \gamma u(1)v(1) H^1 |u(1)| \leq \int_0^1 |u'(s)|ds + \eta |u(1)| \leq \|u\|_V + \eta v(1) = \int_0^1 v'(s)ds |v(1)| \leq \|v\|_V |a(u,v)| \leq (\alpha_1 + \beta) \|u\|_V \|v\|_V+\gamma \|u\|_V \|v\|_V + \gamma \eta \|v\|_V  \eta <0 |a(u,v)| \leq (\alpha_1+\beta+\gamma)\|u\|_V \|v\|_V","['functional-analysis', 'partial-differential-equations', 'solution-verification', 'sobolev-spaces', 'weak-derivatives']"
53,An important corollary of Hahn - Banach Theorem,An important corollary of Hahn - Banach Theorem,,"Let $X$ a normed linear space. Denote with $\mathbb{F}=\mathbb{C}\;\text{or}\;\mathbb{R}$ Suppose that (1) $\;M$ is a closed subspace of $X$ ; (2) $\;x_0\in X\setminus M$ ; (3) $\;d=\text{dist}(x_0, M)=\inf\{\lVert x_0-m\rVert\;:\; m\in M\}$ . Then exists $\Lambda\in X^*$ such that $$\Lambda(x_0)=d,\quad \Lambda|_M=0\quad\text{and}\quad \lVert\Lambda\rVert_{X^*}=1.$$ $\textit{Proof}$ Observe that $d>0$ since $M$ is closed. Define $M_1=\text{span}\{M,x_0\}$ . Then each $x\in M_1$ can be written as $x=m_x+t_x x_0$ for same $m_x\in M$ e $t_x\in \mathbb{F}$ and since $x_0\notin M$ this representation is unique. Define $\lambda\colon M_1\to \mathbb{F}$ as $\lambda(x)=t_xd$ . Observe that $\lambda$ is linear, $\lambda|_M=0$ , and $\lambda(x_0)=d.$ If $x\in M_1$ e $t_x\ne 0$ , then we have that $-m_x/t_x\in M$ . Then, $$\lVert x\rVert_X=\Vert t_x x_0+m_x\rVert_X=\lvert t_x\rvert \bigg\lVert x_0-\bigg(\frac{-m_x}{t_x}\bigg)\bigg\rVert_X\ge\lvert t_x\rvert d.$$ If $t_x = 0$ (so $x\in M$ ), this is still true. Hence, $$\lvert\lambda(x)\rvert=\lvert{t_x}\rvert d \le\lVert x\rVert_X\quad\text{for all}\;x\in M_1.$$ Therefore $\lambda$ is continuous on $M_1$ and $\lVert\lambda\rVert_{M_1^*}\le1.$ On the other hand, exist vectors $m_n\in M$ such that $\lVert x_0-m_n\rVert_X\to d$ for $n\to \infty$ . Since $\lambda|_M=0$ , we have that $$d=\lambda(x_0)=\lambda(x_0-m_n)\le\lVert x_0-m_n \rVert_X\lVert\lambda\rVert_{M_1^*}\to d\lVert\lambda\rVert_{M_1^*}.$$ Therefore $\lVert\lambda\rVert_{M_1^*}\ge 1.$ Then we have $$\lVert\lambda\rVert_{M_1^*}=1.$$ For a Corollary of Hahn Banach Theorem, exists $\Lambda\in X^*$ such that $$\Lambda|_{M_1}=\lambda\quad\text{and} \quad\lVert\Lambda\rVert_{X^*}=\lVert\lambda\rVert_{M_1^*}=1.$$ Since $x_0\in M_1$ and $M\subseteq M_1$ we have $\Lambda(x_0)=\lambda(x_0)=d$ e $\Lambda|_M=\lambda|_M=0.$ Is everything formally correct?","Let a normed linear space. Denote with Suppose that (1) is a closed subspace of ; (2) ; (3) . Then exists such that Observe that since is closed. Define . Then each can be written as for same e and since this representation is unique. Define as . Observe that is linear, , and If e , then we have that . Then, If (so ), this is still true. Hence, Therefore is continuous on and On the other hand, exist vectors such that for . Since , we have that Therefore Then we have For a Corollary of Hahn Banach Theorem, exists such that Since and we have e Is everything formally correct?","X \mathbb{F}=\mathbb{C}\;\text{or}\;\mathbb{R} \;M X \;x_0\in X\setminus M \;d=\text{dist}(x_0, M)=\inf\{\lVert x_0-m\rVert\;:\; m\in M\} \Lambda\in X^* \Lambda(x_0)=d,\quad \Lambda|_M=0\quad\text{and}\quad \lVert\Lambda\rVert_{X^*}=1. \textit{Proof} d>0 M M_1=\text{span}\{M,x_0\} x\in M_1 x=m_x+t_x x_0 m_x\in M t_x\in \mathbb{F} x_0\notin M \lambda\colon M_1\to \mathbb{F} \lambda(x)=t_xd \lambda \lambda|_M=0 \lambda(x_0)=d. x\in M_1 t_x\ne 0 -m_x/t_x\in M \lVert x\rVert_X=\Vert t_x x_0+m_x\rVert_X=\lvert t_x\rvert \bigg\lVert x_0-\bigg(\frac{-m_x}{t_x}\bigg)\bigg\rVert_X\ge\lvert t_x\rvert d. t_x = 0 x\in M \lvert\lambda(x)\rvert=\lvert{t_x}\rvert d \le\lVert x\rVert_X\quad\text{for all}\;x\in M_1. \lambda M_1 \lVert\lambda\rVert_{M_1^*}\le1. m_n\in M \lVert x_0-m_n\rVert_X\to d n\to \infty \lambda|_M=0 d=\lambda(x_0)=\lambda(x_0-m_n)\le\lVert x_0-m_n \rVert_X\lVert\lambda\rVert_{M_1^*}\to d\lVert\lambda\rVert_{M_1^*}. \lVert\lambda\rVert_{M_1^*}\ge 1. \lVert\lambda\rVert_{M_1^*}=1. \Lambda\in X^* \Lambda|_{M_1}=\lambda\quad\text{and} \quad\lVert\Lambda\rVert_{X^*}=\lVert\lambda\rVert_{M_1^*}=1. x_0\in M_1 M\subseteq M_1 \Lambda(x_0)=\lambda(x_0)=d \Lambda|_M=\lambda|_M=0.","['functional-analysis', 'proof-writing', 'solution-verification']"
54,Showing linear isometry,Showing linear isometry,,"Define a norm on $\ell^1$ by $$\|x\|=(\|x\|_1^2+\|x\|_2^2)^{\frac{1}{2}},$$ where $\|.\|_p$ denotes the canonical norm on $\ell^p$ . Then $\|.\|$ is equivalent to $\|.\|_1$ . I want to show that a quotient space of $X=(\ell^1,\|.\|)$ is linearly isometric to $(\ell^1,\|.\|_1)$ . Let $D=\{x_n:n\in \mathbb{N}\}$ be a countable dense subset of $S_{\ell^1}$ . Let $M,m>0$ be such that $M\|x\|_1\leq \|x\|\leq m\|x\|_1$ for all $x\in \ell^1$ . Define $T:X\to (\ell^1,\|.\|_1)$ by $$T((\lambda_n))=\sum\limits_{n=1}^{\infty}M\lambda_n x_n \text{ for all }(\lambda_n)\in X.$$ Clearly, $T$ is linear. Also for all $(\lambda_n)\in X$ , $$\|T((\lambda_n))\|_1=\|\sum\limits_{n=1}^{\infty}M\lambda_n x_n\|\leq M\|(\lambda_n)\|_1\leq \|(\lambda_n)\|.$$ Thus $T$ is continuous. \ Let $x\in (\ell^1,\|.\|_1)$ . Choose $n_1\in \mathbb{N}$ such that $$\|x-\lambda_{n_1}x_{n_1}\|_1<\frac{\varepsilon}{2}, \text{ where }\lambda_{n_1}=\|x\|_1.$$ Choose $n_2\in \mathbb{N}$ with $n_2>n_1$ such that $$\|(x-\lambda_{n_1}x_{n_1})-\lambda_{n_2}x_{n_2}\|_1<\frac{\varepsilon}{2^2}, \text{ where }\lambda_{n_2}=\|x-\lambda_{n_1}x_{n_1}\|_1<\frac{\varepsilon}{2}.$$ Choose $n_3\in \mathbb{N}$ with $n_3>n_2>n_1$ such that $$\|(x-\lambda_{n_1}x_{n_1}-\lambda_{n_2}x_{n_2})-\lambda_{n_3}x_{n_3}\|_1<\frac{\varepsilon}{2^3}, \text{ where }\lambda_{n_3}=\|x-\lambda_{n_1}x_{n_1}-\lambda_{n_2}x_{n_2}\|_1<\frac{\varepsilon}{2^2}.$$ Proceeding in this way we get a sequence $(\lambda_{n_k})$ such that $$\lambda_{n_{k+1}}=\|x-(\lambda_{n_1}x_{n_1}+\ldots+\lambda_{n_k}x_{n_k})\|_1<\frac{\varepsilon}{2^k}.$$ It follows that $x=\sum\limits_{k=1}^{\infty}\lambda_{n_k}x_{n_k}$ . Let $\alpha_{n_k}=\frac{1}{M}\lambda_{n_k}$ for all $k\in \mathbb{N}$ and $\alpha_n=0$ for all $n\notin \{n_1,n_2,\ldots\}$ . Then $$\sum\limits_{n=1}^{\infty}|\alpha_n|\leq \frac{1}{M}(\|x\|+\sum\limits_{k=1}^{\infty}\frac{\varepsilon}{2^k})=\frac{1}{M}(\|x\|_1+\varepsilon)<\infty.$$ Consequently $(\alpha_n)\in X$ and $T((\alpha_n))=\sum\limits_{k=1}^{\infty}M\alpha_{n_k}x_{n_k}=\sum\limits_{k=1}^{\infty}\lambda_{n_k}x_{n_k}=x$ . Hence $T$ is onto. Since $T$ is continuous, $Y=\ker T$ is a closed subspace of $X$ and so $X/Y$ is a Banach space. Therefore by the first law of isomorphism of Banach spaces, $T$ induces a linear isomorphism $\tilde{T}$ from $X/Y$ onto $(\ell^1,\|.\|_1)$ given by $$\tilde{T}((\lambda_n)+Y)=T(\lambda_n)\text { for all }(\lambda_n)\in X.$$ We prove that $\tilde{T}$ is an isometry. For all $(y_n)\in Y$ , $$\|\tilde{T}((\lambda_n)+Y)\|_1=\|\tilde{T}((\lambda_n)+(y_n)+Y)\|_1=\|T((\lambda_n)+(y_n))\|_1 \leq \|(\lambda_n)+(y_n)\|.$$ Consequently $$\|\tilde{T}((\lambda_n)+Y)\|_1\leq \|(\lambda_n)+Y\|.$$ I got stuck here. How to show the reverse inequality? Any help will be appreciated.","Define a norm on by where denotes the canonical norm on . Then is equivalent to . I want to show that a quotient space of is linearly isometric to . Let be a countable dense subset of . Let be such that for all . Define by Clearly, is linear. Also for all , Thus is continuous. \ Let . Choose such that Choose with such that Choose with such that Proceeding in this way we get a sequence such that It follows that . Let for all and for all . Then Consequently and . Hence is onto. Since is continuous, is a closed subspace of and so is a Banach space. Therefore by the first law of isomorphism of Banach spaces, induces a linear isomorphism from onto given by We prove that is an isometry. For all , Consequently I got stuck here. How to show the reverse inequality? Any help will be appreciated.","\ell^1 \|x\|=(\|x\|_1^2+\|x\|_2^2)^{\frac{1}{2}}, \|.\|_p \ell^p \|.\| \|.\|_1 X=(\ell^1,\|.\|) (\ell^1,\|.\|_1) D=\{x_n:n\in \mathbb{N}\} S_{\ell^1} M,m>0 M\|x\|_1\leq \|x\|\leq m\|x\|_1 x\in \ell^1 T:X\to (\ell^1,\|.\|_1) T((\lambda_n))=\sum\limits_{n=1}^{\infty}M\lambda_n x_n \text{ for all }(\lambda_n)\in X. T (\lambda_n)\in X \|T((\lambda_n))\|_1=\|\sum\limits_{n=1}^{\infty}M\lambda_n x_n\|\leq M\|(\lambda_n)\|_1\leq \|(\lambda_n)\|. T x\in (\ell^1,\|.\|_1) n_1\in \mathbb{N} \|x-\lambda_{n_1}x_{n_1}\|_1<\frac{\varepsilon}{2}, \text{ where }\lambda_{n_1}=\|x\|_1. n_2\in \mathbb{N} n_2>n_1 \|(x-\lambda_{n_1}x_{n_1})-\lambda_{n_2}x_{n_2}\|_1<\frac{\varepsilon}{2^2}, \text{ where }\lambda_{n_2}=\|x-\lambda_{n_1}x_{n_1}\|_1<\frac{\varepsilon}{2}. n_3\in \mathbb{N} n_3>n_2>n_1 \|(x-\lambda_{n_1}x_{n_1}-\lambda_{n_2}x_{n_2})-\lambda_{n_3}x_{n_3}\|_1<\frac{\varepsilon}{2^3}, \text{ where }\lambda_{n_3}=\|x-\lambda_{n_1}x_{n_1}-\lambda_{n_2}x_{n_2}\|_1<\frac{\varepsilon}{2^2}. (\lambda_{n_k}) \lambda_{n_{k+1}}=\|x-(\lambda_{n_1}x_{n_1}+\ldots+\lambda_{n_k}x_{n_k})\|_1<\frac{\varepsilon}{2^k}. x=\sum\limits_{k=1}^{\infty}\lambda_{n_k}x_{n_k} \alpha_{n_k}=\frac{1}{M}\lambda_{n_k} k\in \mathbb{N} \alpha_n=0 n\notin \{n_1,n_2,\ldots\} \sum\limits_{n=1}^{\infty}|\alpha_n|\leq \frac{1}{M}(\|x\|+\sum\limits_{k=1}^{\infty}\frac{\varepsilon}{2^k})=\frac{1}{M}(\|x\|_1+\varepsilon)<\infty. (\alpha_n)\in X T((\alpha_n))=\sum\limits_{k=1}^{\infty}M\alpha_{n_k}x_{n_k}=\sum\limits_{k=1}^{\infty}\lambda_{n_k}x_{n_k}=x T T Y=\ker T X X/Y T \tilde{T} X/Y (\ell^1,\|.\|_1) \tilde{T}((\lambda_n)+Y)=T(\lambda_n)\text { for all }(\lambda_n)\in X. \tilde{T} (y_n)\in Y \|\tilde{T}((\lambda_n)+Y)\|_1=\|\tilde{T}((\lambda_n)+(y_n)+Y)\|_1=\|T((\lambda_n)+(y_n))\|_1 \leq \|(\lambda_n)+(y_n)\|. \|\tilde{T}((\lambda_n)+Y)\|_1\leq \|(\lambda_n)+Y\|.","['functional-analysis', 'linear-transformations', 'banach-spaces', 'isometry']"
55,Can two solutions of a PDE with different initial conditions coincide after finite time?,Can two solutions of a PDE with different initial conditions coincide after finite time?,,"Consider an ODE $$ \dot x=f(x),\quad x(0)=x_0, $$ where $f$ is a smooth function. It is well-known that if $y$ is another solution to this ODE with different initial condition $y_0\neq x_0$ , then the trajectories of $x(t)$ and $y(t)$ do not intersect - in particular, for any finite $t$ we have $x(t)\neq y(t)$ . I wonder if the same is true for PDEs. I'm interested in the following simple example: $$ \partial_t u=\partial_{xx} u+f(t,(u(t,x)), $$ with periodic boundary conditions. Here $x$ lives on a circle $[0,1]$ , $t\ge0$ and $f$ is a nice function. Is it true that if $u,v$ are two solutions of this PDE with $u(0)\neq v(0)$ , then $u(t)\neq v(t)$ for any $t$ ? (equivalent statement: if $u(1)=v(1)$ is it true that $u(0)=v(0)$ ?) How can we prove this? UPD: the case $f\equiv0$ can be found inn Evans' book and it involves taking second derivative of the energy. Is it possible to extend this technique to the case $f\neq0$ ?","Consider an ODE where is a smooth function. It is well-known that if is another solution to this ODE with different initial condition , then the trajectories of and do not intersect - in particular, for any finite we have . I wonder if the same is true for PDEs. I'm interested in the following simple example: with periodic boundary conditions. Here lives on a circle , and is a nice function. Is it true that if are two solutions of this PDE with , then for any ? (equivalent statement: if is it true that ?) How can we prove this? UPD: the case can be found inn Evans' book and it involves taking second derivative of the energy. Is it possible to extend this technique to the case ?","
\dot x=f(x),\quad x(0)=x_0,
 f y y_0\neq x_0 x(t) y(t) t x(t)\neq y(t) 
\partial_t u=\partial_{xx} u+f(t,(u(t,x)),
 x [0,1] t\ge0 f u,v u(0)\neq v(0) u(t)\neq v(t) t u(1)=v(1) u(0)=v(0) f\equiv0 f\neq0","['functional-analysis', 'ordinary-differential-equations', 'partial-differential-equations']"
56,On the closedness of KdV operator,On the closedness of KdV operator,,"Some papers that I am currently reading state that the classical KdV operator $Au=u'+u'''$ with $D(A)=\{u\in H^3(0,1)|u(0)=u(1)=u'(1)=0\}$ is a closed operator in $L^2(0,1)?$ However, no proof is given. How do I show this fact?","Some papers that I am currently reading state that the classical KdV operator with is a closed operator in However, no proof is given. How do I show this fact?","Au=u'+u''' D(A)=\{u\in H^3(0,1)|u(0)=u(1)=u'(1)=0\} L^2(0,1)?","['functional-analysis', 'operator-theory']"
57,Density of products of continuous bounded functions,Density of products of continuous bounded functions,,"Let $C_b(X)$ denote the space of continuous and bounded real functions in a topological space $X.$ $C_b(X)$ is a real Banach space with the $\infty$ -norm $$\|f\|_{\infty} = \sup_{x \in X} |f(x)|.$$ Let $C_b(X) \otimes C_b(X)$ be the space of functions in $C_b(X \times X)$ of the form $$f(x, y) = \sum_{i = 0}^{N} g_i(x) h_i(y) \,\text{ for some } N \in \mathbb{N}, \ \,g_i, h_i \in C_b(X) \,\,\, (i = 1, \cdots, N).$$ For the particular case $X = (0, 1]$ with the subspace topology of $\mathbb{R},$ is it true that $C_b(0,1] \otimes C_b(0,1]$ is dense in $C_b((0,1]\times(0,1])$ in the $\infty$ -norm?",Let denote the space of continuous and bounded real functions in a topological space is a real Banach space with the -norm Let be the space of functions in of the form For the particular case with the subspace topology of is it true that is dense in in the -norm?,"C_b(X) X. C_b(X) \infty \|f\|_{\infty} = \sup_{x \in X} |f(x)|. C_b(X) \otimes C_b(X) C_b(X \times X) f(x, y) = \sum_{i = 0}^{N} g_i(x) h_i(y) \,\text{ for some } N \in \mathbb{N}, \ \,g_i, h_i \in C_b(X) \,\,\, (i = 1, \cdots, N). X = (0, 1] \mathbb{R}, C_b(0,1] \otimes C_b(0,1] C_b((0,1]\times(0,1]) \infty","['functional-analysis', 'c-star-algebras']"
58,Luxemburg norm as argument of Young's function: $\Phi\left(\lVert f \rVert_{L^{\Phi}}\right)$,Luxemburg norm as argument of Young's function:,\Phi\left(\lVert f \rVert_{L^{\Phi}}\right),"Let $\Phi$ be a Youngs's function , i.e. $$ \Phi(t) = \int_0^t \varphi(s) \,\mathrm d s$$ for some $\varphi$ satifying $\varphi:[0,\infty)\to[0,\infty]$ is increasing $\varphi$ is lower semi continuous $\varphi(0) = 0$ $\varphi$ is neither identically zero nor identically infinite and define the Luxemburg norm of $f:\Omega\to\mathbb{R}$ as $$ \lVert f \rVert_{L^{\Phi}} := \inf \left\{\gamma\,\middle|\,\gamma>0,\,\int_{\Omega} \Phi\left(\frac {\lvert f(x)\rvert}{\gamma} \right)\,\mathrm{d}x\leq 1\right\}.$$ Question : What can we say about $\Phi\left(\lVert f \rVert_{L^{\Phi}}\right)$ ? In particular, I'd like to know, if $$\Phi\left(\lVert f \rVert_{L^{\Phi}}\right) \leq C \int_{\Omega}\Phi(\lvert f(x)\rvert) \,\mathrm d x$$ holds for some $C$ independent of $f$ . Any idea or hint for a reference is welcome! Notes : The above inequality trivially holds for $\Phi(t) = t^p$ , where $p>1$ Maybe it's appropriate to consider this question in the more general framework of Musielak-Orlicz spaces. However, e.g. in Lebesgue and Sobolev Spaces with Variable Exponents I was unable to find an appropriate result. Since there has been no response yet, I also asked the question on MathOverflow .","Let be a Youngs's function , i.e. for some satifying is increasing is lower semi continuous is neither identically zero nor identically infinite and define the Luxemburg norm of as Question : What can we say about ? In particular, I'd like to know, if holds for some independent of . Any idea or hint for a reference is welcome! Notes : The above inequality trivially holds for , where Maybe it's appropriate to consider this question in the more general framework of Musielak-Orlicz spaces. However, e.g. in Lebesgue and Sobolev Spaces with Variable Exponents I was unable to find an appropriate result. Since there has been no response yet, I also asked the question on MathOverflow .","\Phi  \Phi(t) = \int_0^t \varphi(s) \,\mathrm d s \varphi \varphi:[0,\infty)\to[0,\infty] \varphi \varphi(0) = 0 \varphi f:\Omega\to\mathbb{R}  \lVert f \rVert_{L^{\Phi}} := \inf \left\{\gamma\,\middle|\,\gamma>0,\,\int_{\Omega} \Phi\left(\frac {\lvert f(x)\rvert}{\gamma} \right)\,\mathrm{d}x\leq 1\right\}. \Phi\left(\lVert f \rVert_{L^{\Phi}}\right) \Phi\left(\lVert f \rVert_{L^{\Phi}}\right) \leq C \int_{\Omega}\Phi(\lvert f(x)\rvert) \,\mathrm d x C f \Phi(t) = t^p p>1","['functional-analysis', 'banach-spaces', 'orlicz-spaces']"
59,Orthonormal basis of the Schwartz space,Orthonormal basis of the Schwartz space,,"The Hermite functions $(h_n)_{n \ge 0}$ are the eigenfunctions of $T f = (x+\partial_x)(x-\partial_x) f$ , they are defined by their generating function $g(x,t)=\sum_{n=0}^\infty h_n(x) t^n = e^{-x^2/2+2xt-t^2}$ , looking at $\int_{-\infty}^\infty g(x,t)g(x,u)dx= \sqrt{\pi} e^{2tu}$ , $\|h_n\|_{L^2}^2 = \sqrt{\pi} \frac{2^n}{n!}$ , $\partial_x g,\partial_t g$ , $(x-\partial_x) h_n = (n+1)h_{n+1},(x+\partial_x) h_n = 2 h_{n-1}$ shows that $\left(\frac{h_n}{\|h_n\|_{L^2}}\right)_{n \ge 0}$ is an orthonormal basis of the Schwartz space, in the sense that it is an orthonormal basis of $L^2(\Bbb{R})$ and $f \in \mathscr{S}(\Bbb{R})$ if and only if $f = \sum_{n \ge 0} c_n \frac{h_n}{\|h_n\|_{L^2}}$ where $\forall k, \lim_{n \to \infty} c_n n^k=0$ . A similar behavior appears with $(e^{2i \pi nx})_{n \in \Bbb{Z}}$ the eigenfunctions of $f \mapsto {}{}{}{}{}{} i\partial_x f$ , they are an orthonormal basis of $C^\infty(\Bbb{R/Z})$ again in the sense that they are an orthonormal basis of $L^2(\Bbb{R/Z})$ and $f \in C^\infty(\Bbb{R/Z})$ iff $f = \sum_n c_n e^{2i \pi nx}$ where $\forall k, \lim_{n \to \pm\infty} c_n n^k=0$ . Question : What would be some other relevant examples of such basis ? For what kind of $\scriptstyle\text{(differential, normal, compact resolvent)}$ operator can we hope its eigenfunctions will be such an orthonormal basis of the Schwartz space ?","The Hermite functions are the eigenfunctions of , they are defined by their generating function , looking at , , , shows that is an orthonormal basis of the Schwartz space, in the sense that it is an orthonormal basis of and if and only if where . A similar behavior appears with the eigenfunctions of , they are an orthonormal basis of again in the sense that they are an orthonormal basis of and iff where . Question : What would be some other relevant examples of such basis ? For what kind of operator can we hope its eigenfunctions will be such an orthonormal basis of the Schwartz space ?","(h_n)_{n \ge 0} T f = (x+\partial_x)(x-\partial_x) f g(x,t)=\sum_{n=0}^\infty h_n(x) t^n = e^{-x^2/2+2xt-t^2} \int_{-\infty}^\infty g(x,t)g(x,u)dx= \sqrt{\pi} e^{2tu} \|h_n\|_{L^2}^2 = \sqrt{\pi} \frac{2^n}{n!} \partial_x g,\partial_t g (x-\partial_x) h_n = (n+1)h_{n+1},(x+\partial_x) h_n = 2 h_{n-1} \left(\frac{h_n}{\|h_n\|_{L^2}}\right)_{n \ge 0} L^2(\Bbb{R}) f \in \mathscr{S}(\Bbb{R}) f = \sum_{n \ge 0} c_n \frac{h_n}{\|h_n\|_{L^2}} \forall k, \lim_{n \to \infty} c_n n^k=0 (e^{2i \pi nx})_{n \in \Bbb{Z}} f \mapsto {}{}{}{}{}{} i\partial_x f C^\infty(\Bbb{R/Z}) L^2(\Bbb{R/Z}) f \in C^\infty(\Bbb{R/Z}) f = \sum_n c_n e^{2i \pi nx} \forall k, \lim_{n \to \pm\infty} c_n n^k=0 \scriptstyle\text{(differential, normal, compact resolvent)}","['functional-analysis', 'regularity-theory-of-pdes', 'schwartz-space']"
60,"Is the embedding of $W^{2,p}$ onto $C^1(\overline{I})$ compact?",Is the embedding of  onto  compact?,"W^{2,p} C^1(\overline{I})","We know that when $I$ is a bounded interval and $1<p\leq \infty$ that the injection $W^{1,p}\subset C(\overline{I})$ is compact. The proof of this fact uses the Arzela-Ascoli theorem on the unit ball $\mathcal{H}$ of $W^{1,p}(I)$ . Is it true that the embedding of $W^{2,p}$ onto $C^1(\overline{I})$ is also compact? Please Comment on This Part Suppose that $u\in W^{2,p}$ then $u'\in W^{1,p}$ and thus $u'\in C(\overline{I})$ and therefore $u\in C^1(\overline{I})$ . Now let $\mathcal{H}$ be the unit ball in $W^{2,p}$ . Then $\mathcal{H}$ is equicontinuous since for all $u\in \mathcal{H}$ , $$|u(x)-u(y)|=\left|\int_{y}^xu'(t)dt\right|\leq \|u'\|_p|x-y|^{1/p'}\leq  |x-y|^{1/p'}.$$ Hence by Ascoli-Arzela, $\mathcal{H}$ has compact closure in $C(\overline{I})$ . Since $\mathcal{H}\subset C^1(\overline{I})\subset C(\overline{I})$ then $\mathcal{H}$ has compact closure in $C^1(I).$ Is there anything wrong with the argument?","We know that when is a bounded interval and that the injection is compact. The proof of this fact uses the Arzela-Ascoli theorem on the unit ball of . Is it true that the embedding of onto is also compact? Please Comment on This Part Suppose that then and thus and therefore . Now let be the unit ball in . Then is equicontinuous since for all , Hence by Ascoli-Arzela, has compact closure in . Since then has compact closure in Is there anything wrong with the argument?","I 1<p\leq \infty W^{1,p}\subset C(\overline{I}) \mathcal{H} W^{1,p}(I) W^{2,p} C^1(\overline{I}) u\in W^{2,p} u'\in W^{1,p} u'\in C(\overline{I}) u\in C^1(\overline{I}) \mathcal{H} W^{2,p} \mathcal{H} u\in \mathcal{H} |u(x)-u(y)|=\left|\int_{y}^xu'(t)dt\right|\leq \|u'\|_p|x-y|^{1/p'}\leq 
|x-y|^{1/p'}. \mathcal{H} C(\overline{I}) \mathcal{H}\subset C^1(\overline{I})\subset C(\overline{I}) \mathcal{H} C^1(I).","['functional-analysis', 'sobolev-spaces']"
61,Is the Unitary Group of a Hilbert Space a Lie group?,Is the Unitary Group of a Hilbert Space a Lie group?,,"Let $H$ be an infinite-dimensional complex Hilbert space.  Then the set of unitary operators on $H$ forms a group, known as the unitary group or Hilbert group.  My question is, is this group a Lie group?  That is, is there a standard Lie group structure for this group? I ask because in quantum mechanics, at least subgroups of this group seem to be treated as Lie groups. EDIT: The second page of this paper off-handedly mentions ""the Frechet Lie group $U(H)$ consisting of all unitary operators on H, equipped with the strong operator topology"".  What that means is that the Lie group structure on $U(H)$ with the strong operator topology is a Frechet manifold, i.e. a manifold which is locally isomorphic to a Frechet space rather than a finite-dimensional Euclidean space.  But does anyone know the details of this Frechet manifold structure?","Let be an infinite-dimensional complex Hilbert space.  Then the set of unitary operators on forms a group, known as the unitary group or Hilbert group.  My question is, is this group a Lie group?  That is, is there a standard Lie group structure for this group? I ask because in quantum mechanics, at least subgroups of this group seem to be treated as Lie groups. EDIT: The second page of this paper off-handedly mentions ""the Frechet Lie group consisting of all unitary operators on H, equipped with the strong operator topology"".  What that means is that the Lie group structure on with the strong operator topology is a Frechet manifold, i.e. a manifold which is locally isomorphic to a Frechet space rather than a finite-dimensional Euclidean space.  But does anyone know the details of this Frechet manifold structure?",H H U(H) U(H),"['functional-analysis', 'representation-theory', 'hilbert-spaces', 'lie-groups', 'quantum-mechanics']"
62,Approximating orthonormal basis in Hilbert space by orthonormal basis from dense subset,Approximating orthonormal basis in Hilbert space by orthonormal basis from dense subset,,"Consider a Hilbert space $H_2$ with norm $\|\cdot\|_2$ . Consider a linear space $H_1 \subset H_2$ so that $H_1$ is dense in $H_2$ . Consider an orthonormal sequence $(h_k)_{k \in \mathbb{N}}$ in $H_2$ . Can I always find an orthogonal sequence $(g_k)_{k \in \mathbb{N}}$ in $H_2$ so that, for any $k \in \mathbb{N}$ , $$g_k\in H_1$$ and $$\|h_k - g_k\|_2 \leq \frac{1}{1+k^2}\; ?$$","Consider a Hilbert space with norm . Consider a linear space so that is dense in . Consider an orthonormal sequence in . Can I always find an orthogonal sequence in so that, for any , and",H_2 \|\cdot\|_2 H_1 \subset H_2 H_1 H_2 (h_k)_{k \in \mathbb{N}} H_2 (g_k)_{k \in \mathbb{N}} H_2 k \in \mathbb{N} g_k\in H_1 \|h_k - g_k\|_2 \leq \frac{1}{1+k^2}\; ?,"['functional-analysis', 'hilbert-spaces', 'orthonormal']"
63,Doubt in theorem from Conway's book on Functional Analysis,Doubt in theorem from Conway's book on Functional Analysis,,"I am reading John B. Conway. A Course in Functional Analysis. Springer, 1997 (second edition). Theorem X.4.10c states: If $(X,\Omega)$ is a measurable space, $H$ is a Hilbert space and $E$ is a spectral measure on $(X,\Omega,H)$ , let $\Phi(X,\Omega)$ be the algebra of all $\Omega$ -measurable functions $\phi:X\to\mathbb{C}$ and define $\rho:\Phi(X,\Omega)\to C(H)$ by $\rho(\phi)=\int\phi\mbox{d}E$ . Then for $\phi,\psi$ in $\Phi(X,\Omega)$ , if $\psi$ is bounded, $\rho(\phi)\rho(\psi)=\rho(\psi)\rho(\phi)=\rho(\phi\psi)$ . I doubt this claim. If $\psi=0$ and $\mbox{dom }\rho(\phi)\neq H$ , then $\mbox{dom }(\rho(\psi)\rho(\phi))\neq H$ , but $\mbox{dom }\rho(\phi\psi)=\mbox{dom }\rho(0)=H$ . Am I missing something?","I am reading John B. Conway. A Course in Functional Analysis. Springer, 1997 (second edition). Theorem X.4.10c states: If is a measurable space, is a Hilbert space and is a spectral measure on , let be the algebra of all -measurable functions and define by . Then for in , if is bounded, . I doubt this claim. If and , then , but . Am I missing something?","(X,\Omega) H E (X,\Omega,H) \Phi(X,\Omega) \Omega \phi:X\to\mathbb{C} \rho:\Phi(X,\Omega)\to C(H) \rho(\phi)=\int\phi\mbox{d}E \phi,\psi \Phi(X,\Omega) \psi \rho(\phi)\rho(\psi)=\rho(\psi)\rho(\phi)=\rho(\phi\psi) \psi=0 \mbox{dom }\rho(\phi)\neq H \mbox{dom }(\rho(\psi)\rho(\phi))\neq H \mbox{dom }\rho(\phi\psi)=\mbox{dom }\rho(0)=H","['functional-analysis', 'spectral-theory']"
64,"Functional Analysis by Rudin, Chapter $10$, Exercise $20$","Functional Analysis by Rudin, Chapter , Exercise",10 20,"This is the exercise: Suppose $x\in A$ , $x_n\in A$ , and $\lim x_n=x$ . Suppose $\Omega$ is   an open set in $\mathbb C$ that contains a component of $\sigma(x)$ .   Prove that $\sigma(x_n)$ intersects $\Omega$ for all sufficiently   large $n$ . (This strengthens Theorem 10.20.) Hint: If $\sigma(x)\subset\Omega\cup\Omega_0$ , where $\Omega_0$ is an open   set disjoint from $\Omega$ , consider the function $f$ that is $1$ in $\Omega$ , and $0$ in $\Omega_0$ . According to Rudin's hint, we can define $f\in H(\Omega\cup\Omega_0)$ as follows: $$ f(\lambda) = \left \{\begin{array}{lll}   1 &  \ \ \ \ \lambda\in \Omega\\   0  & \ \ \ \ \lambda\in \Omega_0\\   \end{array}\right. $$ And then by symbolic calculus we have $$ \tilde{f}(x) = \left \{\begin{array}{lll}   e &  \ \ \ \ \sigma(x)\subset \Omega\\   0  & \ \ \ \ \sigma(x)\subset \Omega_0\\   \end{array}\right. $$ For the $x\in A$ that $x_n\rightarrow x$ , we have $$\tilde{f}(x)=\tilde{f}(\lim_{n\to\infty}x_n)=\lim_{n\to\infty}\tilde{f}(x_n),$$ meaning $\{\tilde{f}(x_n)\}$ as a sequence in $A$ converges to $\tilde{f}(x)$ . So for a large enough $n$ ; $$\sigma\big(\tilde{f}(x_n)\big)\cap\sigma\big(\tilde{f}(x)\big)\neq\emptyset.$$ And by spectral mapping theorem; $$f\big(\sigma(x_n)\big)\cap f\big(\sigma(x)\big)\neq\emptyset,$$ $$f\big(\sigma(x_n)\big)\cap \{0,1\}\neq\emptyset.$$ So we are forced to have only one of these three possibilities; 1) $f\big(\sigma(x_n)\big)=\{0,1\}$ 2) $f\big(\sigma(x_n)\big)=\{1\}$ 3) $f\big(\sigma(x_n)\big)=\{0\}$ The third case never happens. Because if it happens by the definition of $f$ , we can conclude for any large $n$ that $$\sigma(x_n)\subset\Omega_0,$$ in which by tending $n$ to infinity, we get the following contradiction; $$\sigma(x)\subset\Omega_0.$$ In the first and second cases, there will be at least one $\lambda\in \sigma(x_n)$ such that $f(\lambda)=1$ which by definition simply means $\sigma(x_n)$ intersects $\Omega$ . Is this true? Thank you for your help.","This is the exercise: Suppose , , and . Suppose is   an open set in that contains a component of .   Prove that intersects for all sufficiently   large . (This strengthens Theorem 10.20.) Hint: If , where is an open   set disjoint from , consider the function that is in , and in . According to Rudin's hint, we can define as follows: And then by symbolic calculus we have For the that , we have meaning as a sequence in converges to . So for a large enough ; And by spectral mapping theorem; So we are forced to have only one of these three possibilities; 1) 2) 3) The third case never happens. Because if it happens by the definition of , we can conclude for any large that in which by tending to infinity, we get the following contradiction; In the first and second cases, there will be at least one such that which by definition simply means intersects . Is this true? Thank you for your help.","x\in A x_n\in A \lim x_n=x \Omega \mathbb C \sigma(x) \sigma(x_n) \Omega n \sigma(x)\subset\Omega\cup\Omega_0 \Omega_0 \Omega f 1 \Omega 0 \Omega_0 f\in
H(\Omega\cup\Omega_0) 
f(\lambda) = \left \{\begin{array}{lll}
  1 &  \ \ \ \ \lambda\in \Omega\\
  0  & \ \ \ \ \lambda\in \Omega_0\\
  \end{array}\right.
 
\tilde{f}(x) = \left \{\begin{array}{lll}
  e &  \ \ \ \ \sigma(x)\subset \Omega\\
  0  & \ \ \ \ \sigma(x)\subset \Omega_0\\
  \end{array}\right.
 x\in A x_n\rightarrow x \tilde{f}(x)=\tilde{f}(\lim_{n\to\infty}x_n)=\lim_{n\to\infty}\tilde{f}(x_n), \{\tilde{f}(x_n)\} A \tilde{f}(x) n \sigma\big(\tilde{f}(x_n)\big)\cap\sigma\big(\tilde{f}(x)\big)\neq\emptyset. f\big(\sigma(x_n)\big)\cap f\big(\sigma(x)\big)\neq\emptyset, f\big(\sigma(x_n)\big)\cap \{0,1\}\neq\emptyset. f\big(\sigma(x_n)\big)=\{0,1\} f\big(\sigma(x_n)\big)=\{1\} f\big(\sigma(x_n)\big)=\{0\} f n \sigma(x_n)\subset\Omega_0, n \sigma(x)\subset\Omega_0. \lambda\in \sigma(x_n) f(\lambda)=1 \sigma(x_n) \Omega","['functional-analysis', 'proof-verification', 'spectral-theory']"
65,Banach limit for Cesaro summable sequences,Banach limit for Cesaro summable sequences,,"I'm solving an exercise from Lax's Functional analysis. The section concerns generalized limits (more particularly, Banach limits), which are obtained by applying the Hahn-Banach theorem to the classical limit functional on $\ell^\infty$ . The exercise wants me to construct a Banach limit which agrees with the Cesaro limit of Cesaro summable sequences, that is, bounded sequences such that ""the arithmetic means of the partial sums converge."" If I understand this final sentence correctly (and wiki seems to confirm this), a sequence $(x_1,x_2,\ldots)$ is Cesaro summable if $$ \lim_{n\to\infty}\frac{1}{n}\sum_{k=1}^n s_k < \infty, \quad\text{where}\quad s_k = \sum_{j=1}^k x_j.  $$ On the other hand, in this post , another definition of Cesaro summability is used, namely there it is required that $$ \lim_{n\to\infty} \frac{1}{n}\sum_{k=1}^n x_k < \infty. $$ My problem is that I would like to dominate the Cesaro limit functional by the (subadditive and positive homogeneous) function $$ p(x) = \limsup_{n\to\infty} x_n, $$ which Lax uses to extend of the classical limit. This is easily done if we use the latter definition, but I'm not sure how to do it (or if it's even possible) if we use the former definition. My other idea was to use $$ p(x) = \limsup_{n\to\infty} |s_n|, $$ but this is not even well-defined since we are dealing with general bounded sequences. How would you interpret the problem, i.e. which definition of Cesaro summability am I supposed to use? What is a good candidate for $p$ if we use the former definition?","I'm solving an exercise from Lax's Functional analysis. The section concerns generalized limits (more particularly, Banach limits), which are obtained by applying the Hahn-Banach theorem to the classical limit functional on . The exercise wants me to construct a Banach limit which agrees with the Cesaro limit of Cesaro summable sequences, that is, bounded sequences such that ""the arithmetic means of the partial sums converge."" If I understand this final sentence correctly (and wiki seems to confirm this), a sequence is Cesaro summable if On the other hand, in this post , another definition of Cesaro summability is used, namely there it is required that My problem is that I would like to dominate the Cesaro limit functional by the (subadditive and positive homogeneous) function which Lax uses to extend of the classical limit. This is easily done if we use the latter definition, but I'm not sure how to do it (or if it's even possible) if we use the former definition. My other idea was to use but this is not even well-defined since we are dealing with general bounded sequences. How would you interpret the problem, i.e. which definition of Cesaro summability am I supposed to use? What is a good candidate for if we use the former definition?","\ell^\infty (x_1,x_2,\ldots)  \lim_{n\to\infty}\frac{1}{n}\sum_{k=1}^n s_k < \infty, \quad\text{where}\quad s_k = \sum_{j=1}^k x_j.    \lim_{n\to\infty} \frac{1}{n}\sum_{k=1}^n x_k < \infty.   p(x) = \limsup_{n\to\infty} x_n,   p(x) = \limsup_{n\to\infty} |s_n|,  p","['functional-analysis', 'cesaro-summable']"
66,Absolutely Continuous Spectrum of an operator $Af(x)=\sin x f(x)$,Absolutely Continuous Spectrum of an operator,Af(x)=\sin x f(x),"Let us consider the following operator  $$ Af(x)=\sin(x)f(x), $$ in $L^2(\mathbb R)$. This operator is self-adjoint, so $\sigma(A)\subset \mathbb R.$ Solving equation $(A-\lambda I)f=g,$ we obtain $(A-\lambda I)^{-1}g=\frac{g}{\sin x-\lambda}$, and this formula defines resolvent if $\lambda\in\mathbb R\setminus[-1,1].$ Let $\lambda \in [-1,1].$ From the fact, that $\parallel \frac{1}{\sin x- \lambda}\parallel=\infty$, we get, that $[-1,1]$ is continuous spectrum. Now I am trying  to check, if this continuous spectrum is (or is not)a absolutely continuous spectrum. I would by very grateful if anyone can give me a hint, how to do that.","Let us consider the following operator  $$ Af(x)=\sin(x)f(x), $$ in $L^2(\mathbb R)$. This operator is self-adjoint, so $\sigma(A)\subset \mathbb R.$ Solving equation $(A-\lambda I)f=g,$ we obtain $(A-\lambda I)^{-1}g=\frac{g}{\sin x-\lambda}$, and this formula defines resolvent if $\lambda\in\mathbb R\setminus[-1,1].$ Let $\lambda \in [-1,1].$ From the fact, that $\parallel \frac{1}{\sin x- \lambda}\parallel=\infty$, we get, that $[-1,1]$ is continuous spectrum. Now I am trying  to check, if this continuous spectrum is (or is not)a absolutely continuous spectrum. I would by very grateful if anyone can give me a hint, how to do that.",,"['functional-analysis', 'operator-theory', 'spectral-theory']"
67,Is being in the Sobolev space of power $\frac{d}{2}$ necessary for having well defined point evaluations?,Is being in the Sobolev space of power  necessary for having well defined point evaluations?,\frac{d}{2},"From the Sobolev embedding theorem we know that for $\alpha = \frac{d}{2}$,  $W^{\alpha, 2}(\mathbb{R}^d)$ is continuously embedded in $C^0(\mathbb{R}^d)$. Especially the point evaluations are in the dual of $W^{\alpha, 2}(\mathbb{R}^d)$ and thus well defined. But is it also necessary to be in $W^{\alpha, 2}(\mathbb{R}^d)$ to have well-defined point evaluations? Or is there maybe some $\beta < \alpha = \frac{d}{2}$ s.t. the point evaluations are well defined functions on $W^{\beta, 2}(\mathbb{R}^d)$ even if they aren't continuous anymore. Edit: By well-definedness I mean that if there is a $x \in \mathbb{R}^d$ s.t. $f(x) \not= g(x)$ for two representants of functions $f, g \in W^{\beta, 2}(\mathbb{R}^d)$ then $||f-g||_\beta \not= 0$ (they do not have the same equivalence class)","From the Sobolev embedding theorem we know that for $\alpha = \frac{d}{2}$,  $W^{\alpha, 2}(\mathbb{R}^d)$ is continuously embedded in $C^0(\mathbb{R}^d)$. Especially the point evaluations are in the dual of $W^{\alpha, 2}(\mathbb{R}^d)$ and thus well defined. But is it also necessary to be in $W^{\alpha, 2}(\mathbb{R}^d)$ to have well-defined point evaluations? Or is there maybe some $\beta < \alpha = \frac{d}{2}$ s.t. the point evaluations are well defined functions on $W^{\beta, 2}(\mathbb{R}^d)$ even if they aren't continuous anymore. Edit: By well-definedness I mean that if there is a $x \in \mathbb{R}^d$ s.t. $f(x) \not= g(x)$ for two representants of functions $f, g \in W^{\beta, 2}(\mathbb{R}^d)$ then $||f-g||_\beta \not= 0$ (they do not have the same equivalence class)",,"['functional-analysis', 'sobolev-spaces', 'regularity-theory-of-pdes', 'fractional-sobolev-spaces']"
68,Is there an axiomatic characterization of the Lebesgue integral?,Is there an axiomatic characterization of the Lebesgue integral?,,"Is there an axiomatic characterization of the Lebesgue integral w.r.t. some finite measure $\mu:\mathcal{F}\rightarrow[0,\infty)$, for instance as the function $I$ over the set of real-valued, $\mathcal{F}$-measurable functions that satisfies the following axioms: Linearity ($I(\alpha f + \beta g) = \alpha I(f) + \beta I(g)$) Positivity (for every $f \geq 0$, $I(f)\geq 0$) Continuity from below (for every $f, f_1, f_2, \dots$ such that $f_n\uparrow f$, $I(f) = \lim_{n\rightarrow\infty}I(f_n)$) Consistency with the measure (for every $A \in \mathcal{F}$, $I(\mathbb{1}_A) = \mu(A)$) I'm not asking whether the above axioms characterize the Lebesgue integral; I'm asking whether there is any set of axioms - be it the four above or another set - that characterizes the Lebesgue integral. For example, I've read here that there is an axiomatic characterization of the Lebesgue integral through linear functionals; I'd be interested in this characterization as well as in any other characterization, ideally 'simple' as in the four axioms above (which may or may not characterize the Lebesgue integral).","Is there an axiomatic characterization of the Lebesgue integral w.r.t. some finite measure $\mu:\mathcal{F}\rightarrow[0,\infty)$, for instance as the function $I$ over the set of real-valued, $\mathcal{F}$-measurable functions that satisfies the following axioms: Linearity ($I(\alpha f + \beta g) = \alpha I(f) + \beta I(g)$) Positivity (for every $f \geq 0$, $I(f)\geq 0$) Continuity from below (for every $f, f_1, f_2, \dots$ such that $f_n\uparrow f$, $I(f) = \lim_{n\rightarrow\infty}I(f_n)$) Consistency with the measure (for every $A \in \mathcal{F}$, $I(\mathbb{1}_A) = \mu(A)$) I'm not asking whether the above axioms characterize the Lebesgue integral; I'm asking whether there is any set of axioms - be it the four above or another set - that characterizes the Lebesgue integral. For example, I've read here that there is an axiomatic characterization of the Lebesgue integral through linear functionals; I'd be interested in this characterization as well as in any other characterization, ideally 'simple' as in the four axioms above (which may or may not characterize the Lebesgue integral).",,"['functional-analysis', 'measure-theory', 'lebesgue-integral', 'axioms']"
69,"Triebel-Lizorkin space $F_{p,q}^s(\mathbb{R}^d)$, $p=\infty$","Triebel-Lizorkin space ,","F_{p,q}^s(\mathbb{R}^d) p=\infty","One way to define the Triebel-Lizorkin space is using dyadic resolution of unity. Let $\psi$ be a Schwartz function which satisfies $\hat{\psi}(\xi)=1$ when $|\xi|\leq 1$ and $\hat{\psi}(\xi)=0$ when $|\xi|>\frac{3}{2}$. Define $\psi_0:=\psi$ and $\psi_j,j\in\mathbb{N}$ via $$\widehat{\psi_j}(\xi)=\hat{\psi}(2^{-j}\xi)-\hat{\psi}(2^{-j+1}\xi).$$ Then we can see that $\widehat{\psi_j}$ is supported in the set $$\{\xi\in\mathbb{R}^d: 2^{j-1}\leq|\xi|\leq 2^{j+1}\}.$$ Moreover: $$\sum_{j=0}^\infty\widehat{\psi_j}(\xi)=1,\quad\forall \xi\in\mathbb{R}^d.$$ In this case we call $\psi$ a generating function, and $(\psi_j)_{j=0}^\infty$ a dyadic resolution of unity. Note that in this case every tempered distribution $f$ has the following representation $$f=\sum_{j=0}^\infty\psi_j*f,$$ with the series converging in the space of tempered distributions. For $s\in\mathbb{R}$, $0<p<\infty$ and $0<q\leq\infty$, the Triebel-Lizorkin space $F_{p,q}^s(\mathbb{R}^d)$ is defined as the spaces of all tempered distribution $f$ such that $$\|f\|_{F_{p,q}^s}:=\left\|\left(\sum_{j=0}^\infty 2^{jsq}|\psi_j*f|^q\right)^{\frac{1}{q}}\right\|_{L^p}<\infty$$ for $0<q<\infty$, and $$\|f\|_{F_{p,\infty}^s}:=\left\|\sup_{j\in\mathbb{N}_0}2^{js}|\psi_j*f|\right\|_{L^p}<\infty.$$ By using technical arguments one can prove that dufferent dyadic resolutions of unity will give equivalent norms on the Triebel-Lizorking space. What I'm curious about is that, what happens if $p=\infty$? I've read several textbooks , e.g. ""Modern Fourier analysis"" by Loukas Grafakos, ""Theory of Funciton Spaces"" by Hans Triebel, in which $p=\infty$ is said to be a case where the above definition does not work. However the authors of those books didn't give more details on this issue. More specifically, my question is, why the above definition fails when $p=\infty$? Can anyone provide me some resources (links) which explains this issue in details? Or give me some key clues if possible? Thanks in advance.","One way to define the Triebel-Lizorkin space is using dyadic resolution of unity. Let $\psi$ be a Schwartz function which satisfies $\hat{\psi}(\xi)=1$ when $|\xi|\leq 1$ and $\hat{\psi}(\xi)=0$ when $|\xi|>\frac{3}{2}$. Define $\psi_0:=\psi$ and $\psi_j,j\in\mathbb{N}$ via $$\widehat{\psi_j}(\xi)=\hat{\psi}(2^{-j}\xi)-\hat{\psi}(2^{-j+1}\xi).$$ Then we can see that $\widehat{\psi_j}$ is supported in the set $$\{\xi\in\mathbb{R}^d: 2^{j-1}\leq|\xi|\leq 2^{j+1}\}.$$ Moreover: $$\sum_{j=0}^\infty\widehat{\psi_j}(\xi)=1,\quad\forall \xi\in\mathbb{R}^d.$$ In this case we call $\psi$ a generating function, and $(\psi_j)_{j=0}^\infty$ a dyadic resolution of unity. Note that in this case every tempered distribution $f$ has the following representation $$f=\sum_{j=0}^\infty\psi_j*f,$$ with the series converging in the space of tempered distributions. For $s\in\mathbb{R}$, $0<p<\infty$ and $0<q\leq\infty$, the Triebel-Lizorkin space $F_{p,q}^s(\mathbb{R}^d)$ is defined as the spaces of all tempered distribution $f$ such that $$\|f\|_{F_{p,q}^s}:=\left\|\left(\sum_{j=0}^\infty 2^{jsq}|\psi_j*f|^q\right)^{\frac{1}{q}}\right\|_{L^p}<\infty$$ for $0<q<\infty$, and $$\|f\|_{F_{p,\infty}^s}:=\left\|\sup_{j\in\mathbb{N}_0}2^{js}|\psi_j*f|\right\|_{L^p}<\infty.$$ By using technical arguments one can prove that dufferent dyadic resolutions of unity will give equivalent norms on the Triebel-Lizorking space. What I'm curious about is that, what happens if $p=\infty$? I've read several textbooks , e.g. ""Modern Fourier analysis"" by Loukas Grafakos, ""Theory of Funciton Spaces"" by Hans Triebel, in which $p=\infty$ is said to be a case where the above definition does not work. However the authors of those books didn't give more details on this issue. More specifically, my question is, why the above definition fails when $p=\infty$? Can anyone provide me some resources (links) which explains this issue in details? Or give me some key clues if possible? Thanks in advance.",,"['functional-analysis', 'fourier-analysis', 'normed-spaces', 'harmonic-analysis']"
70,"given the Heat kernel corresponding to $e^{-t\Delta_q}$, find the kernel of the smoothing operator $Fe^{-t\Delta_q}$","given the Heat kernel corresponding to , find the kernel of the smoothing operator",e^{-t\Delta_q} Fe^{-t\Delta_q},"In the proof of the Lefschetz formula for smooth maps $\phi\colon M \to M$ via the Heat Kernel (See Roe Elliptic Operators, Topology and asymptotic methods chapter 10) it's done the following observation: Let $\phi \colon M \to M$ a smooth map ($M$ closed smooth oriented), let $(S,d)$ be a Dirac complex, let $\zeta \colon \phi^*S \to S$ a smooth bundle map, together they define a geometric endomorpism $$ F:=\zeta\phi^* \colon C^{\infty}(S)\to C^{\infty}(S)$$ the smooth sections of my bundle $S$. Given now a smoothing operator $$P\colon L^2(S)\to C^{\infty}(S)$$ where $L^2(S)$ are the $L^2$-sections of $S$, it's claimed that $$FP\colon L^2(S)\to C^{\infty}(S)$$ is again a smoothing operator What I tried: let $k\ \colon M\times M \to S\boxtimes S^*$ be the smooth kernel of $P$ (think of $k(m_1,m_2)\in \hom(S_{m_2},S_{m_1})$), then for any section $s\in L^2(S)$, we have $$ FP(s)(m_1)=F\int_M k(m_1,m_2)s(m_2)vol(m_2)$$ Now upon carefully looking at what $F=\zeta\phi^*$ does on a section $s\colon M \to M$, We see that  $$ FP(s)(m_1)=\zeta P(s)(\phi(m_1))=\zeta\circ \int_M k(\phi(m_1),m_2)s(m_2)vol(m_2)$$ I would like to move my bundle map $\zeta$ inside the integral . If I'm allowed to do that I think I'm able to prove (following what's done by Roe at page $135$) that we still have a smooth kernel. Maybe using partition of unity (we can take a finite cover subordinate to the trivialising cover) we can reduce everything to (a finite sum of) integrals of vector valued functions over opens $U_i$, and then $\zeta$ would be a finite matrix whose entries depend on $m_1$) which should commute with the integral. Can someone provide some feedback or ideas on how to do that? (Roe ""does"" it for the heat kernel at page 135 without any justification) Some context (especially to understand more the notation) can be found here","In the proof of the Lefschetz formula for smooth maps $\phi\colon M \to M$ via the Heat Kernel (See Roe Elliptic Operators, Topology and asymptotic methods chapter 10) it's done the following observation: Let $\phi \colon M \to M$ a smooth map ($M$ closed smooth oriented), let $(S,d)$ be a Dirac complex, let $\zeta \colon \phi^*S \to S$ a smooth bundle map, together they define a geometric endomorpism $$ F:=\zeta\phi^* \colon C^{\infty}(S)\to C^{\infty}(S)$$ the smooth sections of my bundle $S$. Given now a smoothing operator $$P\colon L^2(S)\to C^{\infty}(S)$$ where $L^2(S)$ are the $L^2$-sections of $S$, it's claimed that $$FP\colon L^2(S)\to C^{\infty}(S)$$ is again a smoothing operator What I tried: let $k\ \colon M\times M \to S\boxtimes S^*$ be the smooth kernel of $P$ (think of $k(m_1,m_2)\in \hom(S_{m_2},S_{m_1})$), then for any section $s\in L^2(S)$, we have $$ FP(s)(m_1)=F\int_M k(m_1,m_2)s(m_2)vol(m_2)$$ Now upon carefully looking at what $F=\zeta\phi^*$ does on a section $s\colon M \to M$, We see that  $$ FP(s)(m_1)=\zeta P(s)(\phi(m_1))=\zeta\circ \int_M k(\phi(m_1),m_2)s(m_2)vol(m_2)$$ I would like to move my bundle map $\zeta$ inside the integral . If I'm allowed to do that I think I'm able to prove (following what's done by Roe at page $135$) that we still have a smooth kernel. Maybe using partition of unity (we can take a finite cover subordinate to the trivialising cover) we can reduce everything to (a finite sum of) integrals of vector valued functions over opens $U_i$, and then $\zeta$ would be a finite matrix whose entries depend on $m_1$) which should commute with the integral. Can someone provide some feedback or ideas on how to do that? (Roe ""does"" it for the heat kernel at page 135 without any justification) Some context (especially to understand more the notation) can be found here",,"['functional-analysis', 'differential-geometry', 'operator-theory', 'smooth-manifolds']"
71,Calculation involving complex numbers.,Calculation involving complex numbers.,,"We work in the space $\mathbb C^n$ and denote $v$ with $(v_1, \ldots, v_n)$ We also have $p,q > 1$ satisfying $p+q = pq$ Let $v_i = c_i|v_i|$ with every number complex, $|c_i| = 1$ Let $$w_i = \frac{\overline{c_i} |v_i|^{p/q}}{(\sum_j |v_j|^p)^{1/q})}$$ Show that  $\Vert w \Vert_q = 1$ ($q$-norm) and $\sum v_iw_i = \Vert v \Vert_p$ I tried to apply the definitions and just calculate it, but couldn't find the result. I think I'm overlooking something involving the complex conjugate.","We work in the space $\mathbb C^n$ and denote $v$ with $(v_1, \ldots, v_n)$ We also have $p,q > 1$ satisfying $p+q = pq$ Let $v_i = c_i|v_i|$ with every number complex, $|c_i| = 1$ Let $$w_i = \frac{\overline{c_i} |v_i|^{p/q}}{(\sum_j |v_j|^p)^{1/q})}$$ Show that  $\Vert w \Vert_q = 1$ ($q$-norm) and $\sum v_iw_i = \Vert v \Vert_p$ I tried to apply the definitions and just calculate it, but couldn't find the result. I think I'm overlooking something involving the complex conjugate.",,['functional-analysis']
72,Schauder basis $L^p(\mathbb{R})$,Schauder basis,L^p(\mathbb{R}),"Let $\{e_{n}(x)\}_{n=0}^{\infty}$ be orthonormal basis of Hilbert space $L^2(\mathbb{R})$. If $\{e_{n}(x)\}_{n=0}^{\infty} \subset L^p(\mathbb{R})$ for some $p\geq 1$, is the $\{e_{n}(x)\}_{n=0}^{\infty}$ Schauder basis for $L^p(\mathbb{R})$? Any reference?","Let $\{e_{n}(x)\}_{n=0}^{\infty}$ be orthonormal basis of Hilbert space $L^2(\mathbb{R})$. If $\{e_{n}(x)\}_{n=0}^{\infty} \subset L^p(\mathbb{R})$ for some $p\geq 1$, is the $\{e_{n}(x)\}_{n=0}^{\infty}$ Schauder basis for $L^p(\mathbb{R})$? Any reference?",,"['functional-analysis', 'reference-request', 'lp-spaces', 'orthogonality', 'schauder-basis']"
73,"Comparaison of two version of Fractional sobolev spaces: what do we have $W^{s,p}(\mathbb{R}^{n})=H^{s,p}(\mathbb{R}^{n})$?",Comparaison of two version of Fractional sobolev spaces: what do we have ?,"W^{s,p}(\mathbb{R}^{n})=H^{s,p}(\mathbb{R}^{n})","There are two version of Fractional sobolev spaces . Definition1: (Via Galiardo semi-norm) Let $1\leq p\leq +\infty$, $0<s<1$ and $\Omega\subseteq \mathbb{R}^n$ an open set. The fractional Sobolev space $W^{s,p}(\Omega)$ is defined to be $$ W^{s,p}(\Omega) = \left\{ u\in L^p(\Omega) : \frac{|u(x)-u(y)|}{|x-y|^{\frac{n}{p} + s}} \in L^p(\Omega\times\Omega) \right\} $$ equipped with the norm $$ \|u\|_{W^{s,p}(\Omega)} = \left( \int_\Omega |u|^p \; dx + \int_\Omega\int_\Omega \frac{|u(x)-u(y)|^p}{|x-y|^{n+ sp}} \; dx dy \right)^{1/p}. $$ Definition2:(Via Fourier Transform) For $s\in\mathbb{R}$, $1<p<\infty$, and $n\geq 1$, define the Sobolev space $H^{s,p}(\mathbb{R}^{n})$ by     $$H^{s,p}(\mathbb{R}^{n}):=\left\{f\in\mathcal{S}(\mathbb{R}^{n}) : \|(\langle{\xi}\rangle^{s}\widehat{f})^{\vee}\|_{L^{p}}<\infty\right\}$$, equipped with norm     $$\|f\|_{H^{s,p}}=\|(\langle{\xi}\rangle^{s}\widehat{f})^{\vee}\|_{L^{p}}$$ Where, $$\langle{\xi}\rangle^{s} =(1+|\xi|^2)^s$$ From these definitions I have a couples of questions 1) What are the value of $p\in[1,\infty)$ such that $W^{s,p}(\mathbb{R}^{n})$ and $H^{s,p}(\mathbb{R}^{n})$ coincide? I have found that this true for $p=2$ that is $$W^{s,2}(\mathbb{R}^{n})=H^{s,2}(\mathbb{R}^{n})$$ Do we still have equality or one side inclusion for some $p\neq 2$ if yes which one ? if no please provide me with some counter example or reference. 2) Next I would like to  know what are the advantage and disadvantage using one   the spaces  $W^{s,p}(\mathbb{R}^{n})$ and $H^{s,p}(\mathbb{R}^{n})$. I know that  the definition $W^{s,p}(\Omega)$ makes sense on any domain  which not the case for $H^{s,p}(\Omega)$ due to the lack of Fourier transforms.","There are two version of Fractional sobolev spaces . Definition1: (Via Galiardo semi-norm) Let $1\leq p\leq +\infty$, $0<s<1$ and $\Omega\subseteq \mathbb{R}^n$ an open set. The fractional Sobolev space $W^{s,p}(\Omega)$ is defined to be $$ W^{s,p}(\Omega) = \left\{ u\in L^p(\Omega) : \frac{|u(x)-u(y)|}{|x-y|^{\frac{n}{p} + s}} \in L^p(\Omega\times\Omega) \right\} $$ equipped with the norm $$ \|u\|_{W^{s,p}(\Omega)} = \left( \int_\Omega |u|^p \; dx + \int_\Omega\int_\Omega \frac{|u(x)-u(y)|^p}{|x-y|^{n+ sp}} \; dx dy \right)^{1/p}. $$ Definition2:(Via Fourier Transform) For $s\in\mathbb{R}$, $1<p<\infty$, and $n\geq 1$, define the Sobolev space $H^{s,p}(\mathbb{R}^{n})$ by     $$H^{s,p}(\mathbb{R}^{n}):=\left\{f\in\mathcal{S}(\mathbb{R}^{n}) : \|(\langle{\xi}\rangle^{s}\widehat{f})^{\vee}\|_{L^{p}}<\infty\right\}$$, equipped with norm     $$\|f\|_{H^{s,p}}=\|(\langle{\xi}\rangle^{s}\widehat{f})^{\vee}\|_{L^{p}}$$ Where, $$\langle{\xi}\rangle^{s} =(1+|\xi|^2)^s$$ From these definitions I have a couples of questions 1) What are the value of $p\in[1,\infty)$ such that $W^{s,p}(\mathbb{R}^{n})$ and $H^{s,p}(\mathbb{R}^{n})$ coincide? I have found that this true for $p=2$ that is $$W^{s,2}(\mathbb{R}^{n})=H^{s,2}(\mathbb{R}^{n})$$ Do we still have equality or one side inclusion for some $p\neq 2$ if yes which one ? if no please provide me with some counter example or reference. 2) Next I would like to  know what are the advantage and disadvantage using one   the spaces  $W^{s,p}(\mathbb{R}^{n})$ and $H^{s,p}(\mathbb{R}^{n})$. I know that  the definition $W^{s,p}(\Omega)$ makes sense on any domain  which not the case for $H^{s,p}(\Omega)$ due to the lack of Fourier transforms.",,"['functional-analysis', 'banach-spaces', 'sobolev-spaces', 'fractional-sobolev-spaces']"
74,Sanity check: self-adjoint operator on Sobolev space,Sanity check: self-adjoint operator on Sobolev space,,"I just wanted to check if the conclusion below is true, and whether the following reasoning works: Let $H^i$ be the Sobolev spaces on a compact manifold $M$ and $D$ a self-adjoint (in the $H^0$-inner product) first-order differential operator on $M$. $D$ is initially defined only on $C_c^\infty(M)$ but can be extended to a bounded operator  $$H^{i+1}\rightarrow H^i$$ for all $i\geq 0$. When viewed this way, $D$ is self-adjoint, in the sense of unbounded operators, in every $H^i$-inner product. That is, $$\langle Dx,y\rangle_i = \langle x,Dy\rangle_i,$$ for all $x,y\in H^{i+1}\subseteq H^i$. This follows from self-adjointness of $D:H^1\rightarrow H^0$. By the criterion for self-adjointness, we know that $D^2+1:H^2\rightarrow H^0$ is a bounded invertible operator. Conclusion: The bounded operator $$D^2+1:H^{i+2}\rightarrow H^{i}$$ is invertible for every $i\geq 0$. Thanks!","I just wanted to check if the conclusion below is true, and whether the following reasoning works: Let $H^i$ be the Sobolev spaces on a compact manifold $M$ and $D$ a self-adjoint (in the $H^0$-inner product) first-order differential operator on $M$. $D$ is initially defined only on $C_c^\infty(M)$ but can be extended to a bounded operator  $$H^{i+1}\rightarrow H^i$$ for all $i\geq 0$. When viewed this way, $D$ is self-adjoint, in the sense of unbounded operators, in every $H^i$-inner product. That is, $$\langle Dx,y\rangle_i = \langle x,Dy\rangle_i,$$ for all $x,y\in H^{i+1}\subseteq H^i$. This follows from self-adjointness of $D:H^1\rightarrow H^0$. By the criterion for self-adjointness, we know that $D^2+1:H^2\rightarrow H^0$ is a bounded invertible operator. Conclusion: The bounded operator $$D^2+1:H^{i+2}\rightarrow H^{i}$$ is invertible for every $i\geq 0$. Thanks!",,"['functional-analysis', 'analysis', 'differential-geometry', 'proof-verification', 'sobolev-spaces']"
75,Second Steklov operator and Dirichet-to-Neumann operator for a disk,Second Steklov operator and Dirichet-to-Neumann operator for a disk,,"Let $D: C^{\infty}(\partial K) \rightarrow C^{\infty}(\partial K)$ be the Steklov operator (or sometimes so-called Dirichlet-to-Neumann operator) defined via the relation: $\psi \mapsto u|_{\partial K}$. Here $u$ solves the following boundary value problem: $$ \Delta u = 0$$ $$ \frac{\partial u}{\partial \vec{n}}|_{\partial K} = \psi|_{\partial K}$$ Therefore, we can calculate the spectrum of the Steklov operator for a disk and thus obtain some general propetries of the spectrum via Riemann Mapping Theorem up to some conformal equivalence. Let also $u := u_{\psi}$, $w := v_{\varphi}$ be smooth functions that solve the boundary value problem in the preceding setting. Then we define so-called second Steklov operator $S_{2}$ as  $$\int_{\partial K}{(S_{2} \psi) \varphi dx } = \int_{K} {\langle \nabla^{2} u, \nabla^{2} w \rangle dx}$$ By differentiating the Bochner-Lichnerowicz-Weitzenbock formula, we get that $S_{2}$ can be expressed as $$S_{2}(f) = - \nabla_{\partial K}{Df} - D(\nabla_{\partial K}{f}) - H_{\partial K}{f} + D \nabla_{\partial K} \cdot II_{\partial K} \nabla_{\partial K} D(f)$$ Here $II_{\partial K}$ stands for the second fundamental form, $H_{\partial K}$ is the mean curvature, D is the Dirichlet-to-Neumann operator on $K$. My questions are: (1) Are there any implicitly stated relationships between the Dirichlet-to-Neumann operator and 2nd Steklov operator apart from those that can be directly derived from the definition? What can we say about some propetries that the spectrums of these two operators share? (2) Is it possible to treat the 2nd Steklov operator as a ""connecting"" operator for some mixed boundary value problem, perhaps, such as Dirichlet-to-Neumann is related to the Diriclet problem and, correspondingly, Neumann problem? Any piece of advice or references provided are much appreciated!","Let $D: C^{\infty}(\partial K) \rightarrow C^{\infty}(\partial K)$ be the Steklov operator (or sometimes so-called Dirichlet-to-Neumann operator) defined via the relation: $\psi \mapsto u|_{\partial K}$. Here $u$ solves the following boundary value problem: $$ \Delta u = 0$$ $$ \frac{\partial u}{\partial \vec{n}}|_{\partial K} = \psi|_{\partial K}$$ Therefore, we can calculate the spectrum of the Steklov operator for a disk and thus obtain some general propetries of the spectrum via Riemann Mapping Theorem up to some conformal equivalence. Let also $u := u_{\psi}$, $w := v_{\varphi}$ be smooth functions that solve the boundary value problem in the preceding setting. Then we define so-called second Steklov operator $S_{2}$ as  $$\int_{\partial K}{(S_{2} \psi) \varphi dx } = \int_{K} {\langle \nabla^{2} u, \nabla^{2} w \rangle dx}$$ By differentiating the Bochner-Lichnerowicz-Weitzenbock formula, we get that $S_{2}$ can be expressed as $$S_{2}(f) = - \nabla_{\partial K}{Df} - D(\nabla_{\partial K}{f}) - H_{\partial K}{f} + D \nabla_{\partial K} \cdot II_{\partial K} \nabla_{\partial K} D(f)$$ Here $II_{\partial K}$ stands for the second fundamental form, $H_{\partial K}$ is the mean curvature, D is the Dirichlet-to-Neumann operator on $K$. My questions are: (1) Are there any implicitly stated relationships between the Dirichlet-to-Neumann operator and 2nd Steklov operator apart from those that can be directly derived from the definition? What can we say about some propetries that the spectrums of these two operators share? (2) Is it possible to treat the 2nd Steklov operator as a ""connecting"" operator for some mixed boundary value problem, perhaps, such as Dirichlet-to-Neumann is related to the Diriclet problem and, correspondingly, Neumann problem? Any piece of advice or references provided are much appreciated!",,"['functional-analysis', 'partial-differential-equations', 'riemannian-geometry', 'spectral-theory']"
76,Understanding the working of creation and annihilation operators on Fock space,Understanding the working of creation and annihilation operators on Fock space,,"I have some problem in understanding how exactly the creation and annihilation operators work on a Fock space. We begin with a separable Hilbert space $\mathcal H$ with inner product $\langle,\rangle$ ( why is separable needed? ) and define the full Fock space on $\mathcal H$ by $\mathcal F(\mathcal H)=\huge\oplus\large_{n\geq0}\mathcal H^{\otimes n}$ where $\mathcal H^{\otimes0}=\mathbb C\Omega$, $\Omega$ being an element of $\mathcal H$ with unit norm. For $f\in\mathcal H$, define the left creation operator $l^\star(f)\in \mathcal B(\mathcal F(\mathcal H))$ by $l^*(f)(f_1\otimes...\otimes f_n)=f\otimes f_1\otimes...\otimes f_n$ and $l^*(f)(\Omega)=f$. Similarly define right creation operator. Define left annihilation operator $l(f)$ by $l(f)(f_1\otimes...\otimes f_n)=\langle f,f_1\rangle f_2\otimes...\otimes f_n$ with $l(f)(\Omega)=0$. Similarly define right annihilation operator. These are things I found in a standard text. I have some doubts with the notations mainly. Suppose I look at $x:=a\Omega\oplus b\oplus (c\otimes d)\in\mathcal F(\mathcal H)$. What is the result of $l^*(f)(x)$ and $l(f)(x)$? Here are my guesses: $l^*(f)(x)=0\oplus af\oplus (f\otimes x)\oplus (f\otimes c\otimes d)$, and $l(f)(x)=\langle f,b\rangle\Omega \oplus \langle f,c\rangle d$. Are these correct? Next we come to vacuum expectation: for any $g\in \mathcal B(\mathcal F(\mathcal H))$ define the function $\varphi(g)=\langle \Omega,g(\Omega)\rangle_{0,0}$. Now this $\Omega\in\mathcal H$, so how is the coordinatewise product of inner products defined? Shall we view $\Omega=\Omega\oplus 0\oplus 0\otimes 0\oplus...$ so that in effect, $\langle \Omega,g(\Omega)\rangle_{0,0}$ is the coefficient of $\Omega$ in $g(\Omega)$?","I have some problem in understanding how exactly the creation and annihilation operators work on a Fock space. We begin with a separable Hilbert space $\mathcal H$ with inner product $\langle,\rangle$ ( why is separable needed? ) and define the full Fock space on $\mathcal H$ by $\mathcal F(\mathcal H)=\huge\oplus\large_{n\geq0}\mathcal H^{\otimes n}$ where $\mathcal H^{\otimes0}=\mathbb C\Omega$, $\Omega$ being an element of $\mathcal H$ with unit norm. For $f\in\mathcal H$, define the left creation operator $l^\star(f)\in \mathcal B(\mathcal F(\mathcal H))$ by $l^*(f)(f_1\otimes...\otimes f_n)=f\otimes f_1\otimes...\otimes f_n$ and $l^*(f)(\Omega)=f$. Similarly define right creation operator. Define left annihilation operator $l(f)$ by $l(f)(f_1\otimes...\otimes f_n)=\langle f,f_1\rangle f_2\otimes...\otimes f_n$ with $l(f)(\Omega)=0$. Similarly define right annihilation operator. These are things I found in a standard text. I have some doubts with the notations mainly. Suppose I look at $x:=a\Omega\oplus b\oplus (c\otimes d)\in\mathcal F(\mathcal H)$. What is the result of $l^*(f)(x)$ and $l(f)(x)$? Here are my guesses: $l^*(f)(x)=0\oplus af\oplus (f\otimes x)\oplus (f\otimes c\otimes d)$, and $l(f)(x)=\langle f,b\rangle\Omega \oplus \langle f,c\rangle d$. Are these correct? Next we come to vacuum expectation: for any $g\in \mathcal B(\mathcal F(\mathcal H))$ define the function $\varphi(g)=\langle \Omega,g(\Omega)\rangle_{0,0}$. Now this $\Omega\in\mathcal H$, so how is the coordinatewise product of inner products defined? Shall we view $\Omega=\Omega\oplus 0\oplus 0\otimes 0\oplus...$ so that in effect, $\langle \Omega,g(\Omega)\rangle_{0,0}$ is the coefficient of $\Omega$ in $g(\Omega)$?",,"['functional-analysis', 'operator-theory']"
77,Does this the limit exist?,Does this the limit exist?,,"Assume that there exist constants $c_i>0, i=1,\dots,5$, $\beta>1\ge\gamma>0$, and $     \theta>0$ such that   \begin{eqnarray}    & &c_1 |x|^\beta\le V(x)\le c_2 |x|^\beta,\qquad c_4r^\theta\le \mu(B(x,r))\le c_5r^\theta,\\    && \frac{|V(x)-V(y)|}{|x-y|^\gamma}\le c_3\big(\max\{ |x|,|y|\}\big)^{\beta-\gamma}   \end{eqnarray}   for all $x,y\in \mathbb{R}$ and sufficently large $r>0$. Let $ V^\wedge $ (resp. $V^\vee $) be the piecewise constant function which takes the value $\sup_{x\in X_i} V(x)$ (resp. $\inf_{x\in X_i} V(x)$) on $X_i=[i,i+1]$ for $i\in \mathbb{Z}$. I want to know that whether the limit $$\lim_{\lambda\to \infty}\frac{\mu(\{x\in \mathbb{R}:V^\vee(x)\le \lambda\})}{\mu(\{x\in\mathbb{R}:V^\wedge(x)\le \lambda\})}$$  exists or not? It is easy to check that $$ \lim_{\lambda\to \infty}\frac{\mu(\{x\in \mathbb{R}:V^\vee(x)\le \lambda\})}{\mu(\{x\in\mathbb{R}:V^\wedge(x)\le \lambda\})}\ge 1.$$ Moreover, I have showed the folowing staements: For any $i\in \mathbb{Z}$ and any $x,y\in X_i$,   \begin{equation}\label{eq:Bohr_01}   \begin{aligned}     |V(x)-V(y)|&\le c_3|x-y|^\gamma\big(\max\{ |x|,|y|\}\big)^{\beta-\gamma}\\     &\le c_3|X_i|^\gamma\big(\max\{ |x|,|y|\}\big)^{\beta-\gamma}      \\     &=c_3\big(\max\{ |x|,|y|\}\big)^{\beta-\gamma}.   \end{aligned}   \end{equation}   By the definition of $V^b(x)$, $b\in \{\vee,\wedge\}$, there exist two sequences $\{x_{n,m}\}_{n=1}^\infty\subseteq X_i$, $m=1,2$, such that $V^\wedge(x)=\lim_{n\to \infty}V(x_{n,1})$ and $V^\vee(x)=\lim_{n\to \infty}V(x_{n,2})$ for any $i\in \mathbb{Z}$ and $x\in X_i$. It follows that, for any $x\in \mathbb{R}$ such that $|x|\ge 1$,   \begin{equation}\label{eq:V_-+}     \begin{aligned}       V^\wedge(x)-V^\vee(x)&=\lim_{n\to \infty}(V(x_{n,1})-V(x_{n,2}))\\       &\le c_4\big(\lim_{n\to \infty}\max\{ |x_{n,1}|,|x_{n,2}|\}\big)^{\beta-\gamma}\\       &\le c_4\big(  |x|+ 1\big)^{\beta-\gamma}\le c_5|x|^{\beta-\gamma}.     \end{aligned}   \end{equation} Thanks very much for you help.","Assume that there exist constants $c_i>0, i=1,\dots,5$, $\beta>1\ge\gamma>0$, and $     \theta>0$ such that   \begin{eqnarray}    & &c_1 |x|^\beta\le V(x)\le c_2 |x|^\beta,\qquad c_4r^\theta\le \mu(B(x,r))\le c_5r^\theta,\\    && \frac{|V(x)-V(y)|}{|x-y|^\gamma}\le c_3\big(\max\{ |x|,|y|\}\big)^{\beta-\gamma}   \end{eqnarray}   for all $x,y\in \mathbb{R}$ and sufficently large $r>0$. Let $ V^\wedge $ (resp. $V^\vee $) be the piecewise constant function which takes the value $\sup_{x\in X_i} V(x)$ (resp. $\inf_{x\in X_i} V(x)$) on $X_i=[i,i+1]$ for $i\in \mathbb{Z}$. I want to know that whether the limit $$\lim_{\lambda\to \infty}\frac{\mu(\{x\in \mathbb{R}:V^\vee(x)\le \lambda\})}{\mu(\{x\in\mathbb{R}:V^\wedge(x)\le \lambda\})}$$  exists or not? It is easy to check that $$ \lim_{\lambda\to \infty}\frac{\mu(\{x\in \mathbb{R}:V^\vee(x)\le \lambda\})}{\mu(\{x\in\mathbb{R}:V^\wedge(x)\le \lambda\})}\ge 1.$$ Moreover, I have showed the folowing staements: For any $i\in \mathbb{Z}$ and any $x,y\in X_i$,   \begin{equation}\label{eq:Bohr_01}   \begin{aligned}     |V(x)-V(y)|&\le c_3|x-y|^\gamma\big(\max\{ |x|,|y|\}\big)^{\beta-\gamma}\\     &\le c_3|X_i|^\gamma\big(\max\{ |x|,|y|\}\big)^{\beta-\gamma}      \\     &=c_3\big(\max\{ |x|,|y|\}\big)^{\beta-\gamma}.   \end{aligned}   \end{equation}   By the definition of $V^b(x)$, $b\in \{\vee,\wedge\}$, there exist two sequences $\{x_{n,m}\}_{n=1}^\infty\subseteq X_i$, $m=1,2$, such that $V^\wedge(x)=\lim_{n\to \infty}V(x_{n,1})$ and $V^\vee(x)=\lim_{n\to \infty}V(x_{n,2})$ for any $i\in \mathbb{Z}$ and $x\in X_i$. It follows that, for any $x\in \mathbb{R}$ such that $|x|\ge 1$,   \begin{equation}\label{eq:V_-+}     \begin{aligned}       V^\wedge(x)-V^\vee(x)&=\lim_{n\to \infty}(V(x_{n,1})-V(x_{n,2}))\\       &\le c_4\big(\lim_{n\to \infty}\max\{ |x_{n,1}|,|x_{n,2}|\}\big)^{\beta-\gamma}\\       &\le c_4\big(  |x|+ 1\big)^{\beta-\gamma}\le c_5|x|^{\beta-\gamma}.     \end{aligned}   \end{equation} Thanks very much for you help.",,"['real-analysis', 'functional-analysis', 'measure-theory']"
78,Density of test functions in Sobolev space in $\mathbb{R}^n \setminus \{ 0 \}$,Density of test functions in Sobolev space in,\mathbb{R}^n \setminus \{ 0 \},"Reading my professor's lecture notes on Sobolev spaces I came up with the following proposition: "" $\mathcal{D}(\mathbb{R}^n \setminus \{ 0 \})$ is dense in $W^{m,p}(\mathbb{R}^n \setminus \{ 0 \})$ whenever $p \neq \infty$ and $ mp \le n $ thanks to Sobolev-Morrey embeddings"". I basically have two issues: first of all, shouldn't Morrey's embedding of a Sobolev space into $C(\mathbb{R}^n)$ require something like $mp > n $ (which is exactly the contrary!)? Furthermore, suppose we have the Morrey embedding of $  W^{m,p}(\mathbb{R}^n \setminus \{ 0 \}) $ into $C(\mathbb{R}^n \setminus \{ 0\})$,  we should have by definition: $$ \text{cl}(\mathcal{D}(\mathbb{R}^n \setminus \{ 0 \})) = W^{m,p}_0(\mathbb{R}^n \setminus \{ 0 \}) $$ where the closure is taken with respect to the Sobolev space topology. If everything is consistent then we shall conclude: $$  W^{m,p}_0(\mathbb{R}^n \setminus \{ 0 \})=W^{m,p}(\mathbb{R}^n \setminus \{ 0 \})$$ which sounds a little strange to me. Now let's talk about norms. Fix $n=1$ for simplicity and suppose that we are able to approximate functions in $W^{m,p}(\mathbb{R} \setminus \{ 0 \})$ with test functions supported in $\mathbb{R} \setminus \{  0\}$. Take $u = H(x) \in W^{m,p}(\mathbb{R} \setminus \{ 0 \})  $ and $(u_n)_n \subset \mathcal{D}(\mathbb{R} \setminus \{ 0 \})$  such that $ \| u_n - u \|_{m,p} \rightarrow 0 $. Clearly such test functions must vanish near the origin forcing the derivatives, and hence their $(m,p)$ norms, to blow up. Am I missing something? Thanks in advance for any comment, suggestion or explanation.","Reading my professor's lecture notes on Sobolev spaces I came up with the following proposition: "" $\mathcal{D}(\mathbb{R}^n \setminus \{ 0 \})$ is dense in $W^{m,p}(\mathbb{R}^n \setminus \{ 0 \})$ whenever $p \neq \infty$ and $ mp \le n $ thanks to Sobolev-Morrey embeddings"". I basically have two issues: first of all, shouldn't Morrey's embedding of a Sobolev space into $C(\mathbb{R}^n)$ require something like $mp > n $ (which is exactly the contrary!)? Furthermore, suppose we have the Morrey embedding of $  W^{m,p}(\mathbb{R}^n \setminus \{ 0 \}) $ into $C(\mathbb{R}^n \setminus \{ 0\})$,  we should have by definition: $$ \text{cl}(\mathcal{D}(\mathbb{R}^n \setminus \{ 0 \})) = W^{m,p}_0(\mathbb{R}^n \setminus \{ 0 \}) $$ where the closure is taken with respect to the Sobolev space topology. If everything is consistent then we shall conclude: $$  W^{m,p}_0(\mathbb{R}^n \setminus \{ 0 \})=W^{m,p}(\mathbb{R}^n \setminus \{ 0 \})$$ which sounds a little strange to me. Now let's talk about norms. Fix $n=1$ for simplicity and suppose that we are able to approximate functions in $W^{m,p}(\mathbb{R} \setminus \{ 0 \})$ with test functions supported in $\mathbb{R} \setminus \{  0\}$. Take $u = H(x) \in W^{m,p}(\mathbb{R} \setminus \{ 0 \})  $ and $(u_n)_n \subset \mathcal{D}(\mathbb{R} \setminus \{ 0 \})$  such that $ \| u_n - u \|_{m,p} \rightarrow 0 $. Clearly such test functions must vanish near the origin forcing the derivatives, and hence their $(m,p)$ norms, to blow up. Am I missing something? Thanks in advance for any comment, suggestion or explanation.",,"['real-analysis', 'functional-analysis', 'sobolev-spaces']"
79,"Is this integral operator on $L_2(0, \infty)$ compact?",Is this integral operator on  compact?,"L_2(0, \infty)","Let's define $T:L_2(0,\infty) \to L_2(0,\infty)$ as $$(Tf)(x) = \int_0^\infty \frac{f(y)\sqrt{xy}}{x^2y^2+1}dy.$$ I'm interested, if this operator is compact. $T$ is integral operator with kernel $K = \frac{\sqrt{xy}}{x^2y^2+1}$. The Holder inequality, which gives the usual bound $\|Tf\|_{L_2}\leq \|K\|_{L_2}\cdot \|f\|_{L_2}$, is not working here, because $K \notin L^2((0,\infty)\times(0,\infty))$. But I tried to use Schur test, and succeed to find this bound: $||T|| \le {\pi}/{\sqrt2}$. Then I tried to prove that $T$ is not compact. Because $L_2(0,\infty)$ is reflexive space, $T$ is compact iff it's completely continuous. So I tried to prove that $T$ is not completely continuous, that is to find weakly convergent sequence $f_n$ for which $Tf_n$ is not norm-convergent. But I cannot find such a sequence.  Any suggestions? Maybe $T$ compact, but how to prove it then?","Let's define $T:L_2(0,\infty) \to L_2(0,\infty)$ as $$(Tf)(x) = \int_0^\infty \frac{f(y)\sqrt{xy}}{x^2y^2+1}dy.$$ I'm interested, if this operator is compact. $T$ is integral operator with kernel $K = \frac{\sqrt{xy}}{x^2y^2+1}$. The Holder inequality, which gives the usual bound $\|Tf\|_{L_2}\leq \|K\|_{L_2}\cdot \|f\|_{L_2}$, is not working here, because $K \notin L^2((0,\infty)\times(0,\infty))$. But I tried to use Schur test, and succeed to find this bound: $||T|| \le {\pi}/{\sqrt2}$. Then I tried to prove that $T$ is not compact. Because $L_2(0,\infty)$ is reflexive space, $T$ is compact iff it's completely continuous. So I tried to prove that $T$ is not completely continuous, that is to find weakly convergent sequence $f_n$ for which $Tf_n$ is not norm-convergent. But I cannot find such a sequence.  Any suggestions? Maybe $T$ compact, but how to prove it then?",,"['functional-analysis', 'operator-theory', 'compact-operators', 'integral-operators']"
80,Square-root for nonnegative (and not necessarily self-adjoint) operators,Square-root for nonnegative (and not necessarily self-adjoint) operators,,"Let $H$ be a $\mathbb R$-Hilbert space and $A$ be a bounded linear operator on $H$. If $A$ is nonnegative and self-adjoint, then there is a unique nonnegative and self-adjoint bounded linear operator $B$ on $H$ with $B^2=A$. This can be proved by an elementary version of the spectral theorem. Now, suppose that $A$ is only nonnegative (and not necessarily self-adjoint). I've read that we can still find a unique nonnegative bounded linear operator $B$ on $H$ with $B^2=A$. How can we prove this statement? My knowledge in operator theory is rather limited. So, I hope we can provide an elementary proof.","Let $H$ be a $\mathbb R$-Hilbert space and $A$ be a bounded linear operator on $H$. If $A$ is nonnegative and self-adjoint, then there is a unique nonnegative and self-adjoint bounded linear operator $B$ on $H$ with $B^2=A$. This can be proved by an elementary version of the spectral theorem. Now, suppose that $A$ is only nonnegative (and not necessarily self-adjoint). I've read that we can still find a unique nonnegative bounded linear operator $B$ on $H$ with $B^2=A$. How can we prove this statement? My knowledge in operator theory is rather limited. So, I hope we can provide an elementary proof.",,"['functional-analysis', 'operator-theory']"
81,Positive square root on a real Hilbert space?,Positive square root on a real Hilbert space?,,"I've found several references stating that when $T: H \to H$ is a positive, bounded linear operator on a complex Hilbert space, it has a unique positive square root, i.e. a positive, bounded linear operator $S$ such that $S^2=T$. What can we say when $H$ is a real Hilbert space? Does there always exist a positive square root, but which is non-unique? What kind of statements about the existence and uniqueness of a positive square root hold in this case?","I've found several references stating that when $T: H \to H$ is a positive, bounded linear operator on a complex Hilbert space, it has a unique positive square root, i.e. a positive, bounded linear operator $S$ such that $S^2=T$. What can we say when $H$ is a real Hilbert space? Does there always exist a positive square root, but which is non-unique? What kind of statements about the existence and uniqueness of a positive square root hold in this case?",,"['functional-analysis', 'operator-theory', 'hilbert-spaces']"
82,Square root of normal positive operators over real Hilbert spaces,Square root of normal positive operators over real Hilbert spaces,,"A bounded linear operator $A$ on a Hilbert space $H$ is called a positive operator if $\langle Ax, x\rangle \geq 0$ for all  $x$ in $H$. It is known that, if $A$ is a positive operator on a Hilbert space  $H$ over the complex field $\mathbb{C}$, then $A$ has unique positive square root. My question is the following:  Does a normal positive operator on an infinite dimensional Hilbert space over the real field $\mathbb{R}$ has a normal positive square root? If  exist, is it unique?","A bounded linear operator $A$ on a Hilbert space $H$ is called a positive operator if $\langle Ax, x\rangle \geq 0$ for all  $x$ in $H$. It is known that, if $A$ is a positive operator on a Hilbert space  $H$ over the complex field $\mathbb{C}$, then $A$ has unique positive square root. My question is the following:  Does a normal positive operator on an infinite dimensional Hilbert space over the real field $\mathbb{R}$ has a normal positive square root? If  exist, is it unique?",,"['functional-analysis', 'operator-theory', 'operator-algebras']"
83,Hypothesis in the Radon-Nikodym theorem.,Hypothesis in the Radon-Nikodym theorem.,,"I have a question concerning a proof of Radon-Nikodym theorem here . Why is the hypothesis ""$\nu$ is finite"" necessary? The author uses it to have the measure $\sigma=\mu+\nu$ finite and then, from $|Tu|\leq \Vert u\Vert_{L^2(X,\mathcal{F},\sigma)}\sqrt{\sigma(X)}$, conclude that $T$ is bounded. By I think that it is also true that $|Tu|\leq\Vert u\Vert_{L^2(X,\mathcal{F},\sigma)} \sqrt{\mu(X)}$ (applying first Hölder's inequality and then the fact that $\mu\leq\sigma$), so $T$ is bounded in any case . So for me, $\mu$ has to be finite, but $\nu$ not. However, this would contradict the example posted here . Any ideas?","I have a question concerning a proof of Radon-Nikodym theorem here . Why is the hypothesis ""$\nu$ is finite"" necessary? The author uses it to have the measure $\sigma=\mu+\nu$ finite and then, from $|Tu|\leq \Vert u\Vert_{L^2(X,\mathcal{F},\sigma)}\sqrt{\sigma(X)}$, conclude that $T$ is bounded. By I think that it is also true that $|Tu|\leq\Vert u\Vert_{L^2(X,\mathcal{F},\sigma)} \sqrt{\mu(X)}$ (applying first Hölder's inequality and then the fact that $\mu\leq\sigma$), so $T$ is bounded in any case . So for me, $\mu$ has to be finite, but $\nu$ not. However, this would contradict the example posted here . Any ideas?",,"['functional-analysis', 'probability-theory', 'measure-theory', 'lebesgue-integral', 'self-learning']"
84,"Is every $C_0(K,X)$ space isomorphic to $C(L,X)$, for some compact $L$?","Is every  space isomorphic to , for some compact ?","C_0(K,X) C(L,X) L","Let $K$ be a locally compact Hausdorff space and $X$ be a Banach space. Denote by $C_0(K,X)$ the Banach space of all continuous $X$-valued functions defined on $K$ that vanish at infinity, equipped with the supremum norm. ($f: K \to X$ vanishes at infinity if for every $\varepsilon > 0$ there exists a compact subset $K_\varepsilon$ of $K$ satisfying $\|f(k)\| < \varepsilon$ for all $k \in K \setminus K_\varepsilon$) For a compact Hausdorff space $L$, denote $C_0(L,X)$ simply by $C(L,X)$. Is it true that for every locally compact Hausdorff space $K$ and Banach space $X$ there exists a compact Hausdorff space $L$ such that the spaces $C_0(K,X)$ and $C(L,X)$ are isomorphic? I only know this is true for the special case when $K$ is an infinite set equipped with the discrete topology (it suffices to define $L$ as the Alexandroff compactification of $K$).","Let $K$ be a locally compact Hausdorff space and $X$ be a Banach space. Denote by $C_0(K,X)$ the Banach space of all continuous $X$-valued functions defined on $K$ that vanish at infinity, equipped with the supremum norm. ($f: K \to X$ vanishes at infinity if for every $\varepsilon > 0$ there exists a compact subset $K_\varepsilon$ of $K$ satisfying $\|f(k)\| < \varepsilon$ for all $k \in K \setminus K_\varepsilon$) For a compact Hausdorff space $L$, denote $C_0(L,X)$ simply by $C(L,X)$. Is it true that for every locally compact Hausdorff space $K$ and Banach space $X$ there exists a compact Hausdorff space $L$ such that the spaces $C_0(K,X)$ and $C(L,X)$ are isomorphic? I only know this is true for the special case when $K$ is an infinite set equipped with the discrete topology (it suffices to define $L$ as the Alexandroff compactification of $K$).",,"['functional-analysis', 'banach-spaces']"
85,Linear separation theorem for closed convex sets of measures,Linear separation theorem for closed convex sets of measures,,"Let $\mathcal P([0, 1])$ be the space of all probability measures on $[0, 1]$ endowed with the total variation metric. Let $P\subseteq \mathcal P([0, 1])$ be its closed convex subset, and $p'$ a measure that lies outside of it. Does there exist a bounded Borel-measurable function $f:[0,1]\to \Bbb R$ such that  $$   p'f > \sup\limits_{p\in P} pf. $$  It seems that Hahn–Banach separation theorem can be applied here, but I am not sure in which way exactly. Update: The answer to the original question is negative, unless we use a refined version of convexity that I had in mind initially, but did not put in the beginning, hoping that the usual definition of convexity would suffice. Unfortunately, it also means that Hahn-Banach separation theorem cannot be readily applied to my case. First, why the original question has negative answer. Let $P$ be the closure (in total variation) of all discrete measures on $[0, 1]$ with finite support. No absolutely continuous measure belongs to $P$ since they are mutually singular with discrete measures. Yet, for any measure $p'$ and any given function $f$ we cna always construct a sequence of discrete measures $p_n$ such that $\sup_n p_nf \geq p'f$. Second, instead of usual convexity I am working with barycentric convexity. A measurable set of measures $P\subseteq \mathcal P([0, 1])$ is said to be barycentrcially convex if for any measure $\nu \in \mathcal P(\mathcal P([0, 1]))$ such that $\nu(P) = 1$ it holds that $\int_P \mu \;\nu(\mathrm d\mu)\in P$. So, instead of only taking convex combinations with finite weights (like in usual convexity) we are allowed to take any possible linear combinations. So my question should read as: if $P$ is a barycentrically convex, closed (in TV) subset of $\mathcal P([0,1])$... In this formulation the previous counterexample does not apply: the set of all discrete measures is not barycentrically closed, in fact its barycentric closure consists of all measures.","Let $\mathcal P([0, 1])$ be the space of all probability measures on $[0, 1]$ endowed with the total variation metric. Let $P\subseteq \mathcal P([0, 1])$ be its closed convex subset, and $p'$ a measure that lies outside of it. Does there exist a bounded Borel-measurable function $f:[0,1]\to \Bbb R$ such that  $$   p'f > \sup\limits_{p\in P} pf. $$  It seems that Hahn–Banach separation theorem can be applied here, but I am not sure in which way exactly. Update: The answer to the original question is negative, unless we use a refined version of convexity that I had in mind initially, but did not put in the beginning, hoping that the usual definition of convexity would suffice. Unfortunately, it also means that Hahn-Banach separation theorem cannot be readily applied to my case. First, why the original question has negative answer. Let $P$ be the closure (in total variation) of all discrete measures on $[0, 1]$ with finite support. No absolutely continuous measure belongs to $P$ since they are mutually singular with discrete measures. Yet, for any measure $p'$ and any given function $f$ we cna always construct a sequence of discrete measures $p_n$ such that $\sup_n p_nf \geq p'f$. Second, instead of usual convexity I am working with barycentric convexity. A measurable set of measures $P\subseteq \mathcal P([0, 1])$ is said to be barycentrcially convex if for any measure $\nu \in \mathcal P(\mathcal P([0, 1]))$ such that $\nu(P) = 1$ it holds that $\int_P \mu \;\nu(\mathrm d\mu)\in P$. So, instead of only taking convex combinations with finite weights (like in usual convexity) we are allowed to take any possible linear combinations. So my question should read as: if $P$ is a barycentrically convex, closed (in TV) subset of $\mathcal P([0,1])$... In this formulation the previous counterexample does not apply: the set of all discrete measures is not barycentrically closed, in fact its barycentric closure consists of all measures.",,"['functional-analysis', 'probability-theory', 'measure-theory', 'convex-analysis']"
86,Relating primal and dual characterization of an (interpolation) norm on $\ell_1+\ell_2$,Relating primal and dual characterization of an (interpolation) norm on,\ell_1+\ell_2,"For any fixed $t> 0$, the $K$-functional defines a norm on the space $\ell_1+\ell_2$: $$ \lVert a\rVert_{K(t)} = \inf\{\lVert a'\rVert_1+ t\lVert a''\rVert_2 : a'\in\ell_1,\ a''\in\ell_2,\ a'+a''=a\}. \tag{1} $$ Now, one can show (Lemma 1, [1]) that, for $a\in\ell_2$ this is equal to the dual formulation $$ \lVert a\rVert_{K(t)} = \sup\left\{\sum_{n=1}^\infty a_nb_n : (b_n)_{n\in\mathbb{N}}\in\ell_2,\ \lVert b\rVert_\infty \leq 1,\ \lVert b\rVert_2 \leq t \right\}. \tag{2} $$ My question is: is there a way to relate (2) to (1)? More precisely, is there a correspondence between the $b\in\ell_2$ from (2) and the $(a',a'')\in\ell_1\times\ell_2$ from (1)? [1] Montgomery-Smith, S. J. (1990). The distribution of Rademacher sums . Proc. Amer. Math. Soc., 109(2), 517–517. doi:10.1090/s0002-9939-1990-1013975-0","For any fixed $t> 0$, the $K$-functional defines a norm on the space $\ell_1+\ell_2$: $$ \lVert a\rVert_{K(t)} = \inf\{\lVert a'\rVert_1+ t\lVert a''\rVert_2 : a'\in\ell_1,\ a''\in\ell_2,\ a'+a''=a\}. \tag{1} $$ Now, one can show (Lemma 1, [1]) that, for $a\in\ell_2$ this is equal to the dual formulation $$ \lVert a\rVert_{K(t)} = \sup\left\{\sum_{n=1}^\infty a_nb_n : (b_n)_{n\in\mathbb{N}}\in\ell_2,\ \lVert b\rVert_\infty \leq 1,\ \lVert b\rVert_2 \leq t \right\}. \tag{2} $$ My question is: is there a way to relate (2) to (1)? More precisely, is there a correspondence between the $b\in\ell_2$ from (2) and the $(a',a'')\in\ell_1\times\ell_2$ from (1)? [1] Montgomery-Smith, S. J. (1990). The distribution of Rademacher sums . Proc. Amer. Math. Soc., 109(2), 517–517. doi:10.1090/s0002-9939-1990-1013975-0",,"['functional-analysis', 'lp-spaces', 'interpolation-theory']"
87,Generalising Parseval's Identity using the Convolution Theorem,Generalising Parseval's Identity using the Convolution Theorem,,"Suppose that we have a $2\pi$-periodic, integrable function $f: \mathbb{R} \rightarrow \mathbb{R}$, whose Fourier coefficients are known. Parseval's identity tells us that: $$\displaystyle \frac{1}{2\pi}\int_{-\pi}^{\pi}|f(x)|^{2}dx =  \sum_{n = -\infty}^{\infty}|\widehat{f(n)}|^2,$$ where $\widehat{f(n)}$ are the Fourier coefficients of $f$. Suppose we instead want to replace $f(x)$ with $f(x)^{q}$, say: then it would suffice to determine the Fourier coefficients of the $q$-th power of $f$. Is repeated application of the convolution theorem the usual (or, most efficient) way of finding powers of the Fourier coefficients of functions, where the Fourier coefficients of the original function are already known? Moreover, can Parseval's identity be extended in this way, by replacing $f$ with a power of $f$ instead? For example, suppose that we are interested in the following integral: $$\displaystyle \int_{-\pi}^{\pi}|f(x)|^{4} dx.$$ I would like to know if it is valid to say the following: $$\displaystyle \frac{1}{2\pi}\int_{-\pi}^{\pi}|f(x)|^{4}dx = \frac{1}{2\pi}\int_{-\pi}^{\pi}|(f(x))^{2}|^{2}dx = \sum_{n = -\infty}^{\infty} |\widehat{f(n)^{2}}|^{2} = \sum_{n = -\infty}^{\infty} | (\hat{f} \ast \hat{f})(n)|^{2},$$ where $f \ast g$ denotes the convolution of $f$ and $g$, given by $(f \ast g)(t) := \int_{-\infty}^{\infty} f(\tau)g(t - \tau)d\tau,$ and $\widehat{f \ast g} = \hat{f} \cdot \hat{g}$ is the convolution theorem for the Fourier transforms of $f$ and $g$. Is this manipulation valid?","Suppose that we have a $2\pi$-periodic, integrable function $f: \mathbb{R} \rightarrow \mathbb{R}$, whose Fourier coefficients are known. Parseval's identity tells us that: $$\displaystyle \frac{1}{2\pi}\int_{-\pi}^{\pi}|f(x)|^{2}dx =  \sum_{n = -\infty}^{\infty}|\widehat{f(n)}|^2,$$ where $\widehat{f(n)}$ are the Fourier coefficients of $f$. Suppose we instead want to replace $f(x)$ with $f(x)^{q}$, say: then it would suffice to determine the Fourier coefficients of the $q$-th power of $f$. Is repeated application of the convolution theorem the usual (or, most efficient) way of finding powers of the Fourier coefficients of functions, where the Fourier coefficients of the original function are already known? Moreover, can Parseval's identity be extended in this way, by replacing $f$ with a power of $f$ instead? For example, suppose that we are interested in the following integral: $$\displaystyle \int_{-\pi}^{\pi}|f(x)|^{4} dx.$$ I would like to know if it is valid to say the following: $$\displaystyle \frac{1}{2\pi}\int_{-\pi}^{\pi}|f(x)|^{4}dx = \frac{1}{2\pi}\int_{-\pi}^{\pi}|(f(x))^{2}|^{2}dx = \sum_{n = -\infty}^{\infty} |\widehat{f(n)^{2}}|^{2} = \sum_{n = -\infty}^{\infty} | (\hat{f} \ast \hat{f})(n)|^{2},$$ where $f \ast g$ denotes the convolution of $f$ and $g$, given by $(f \ast g)(t) := \int_{-\infty}^{\infty} f(\tau)g(t - \tau)d\tau,$ and $\widehat{f \ast g} = \hat{f} \cdot \hat{g}$ is the convolution theorem for the Fourier transforms of $f$ and $g$. Is this manipulation valid?",,"['real-analysis', 'functional-analysis', 'fourier-analysis']"
88,"Proving Sobolev space on [0,1] is RKHS","Proving Sobolev space on [0,1] is RKHS",,"My aim is to prove that the space: $\mathcal{H}$ = {$f:[0,1] \to \mathbb{R}: f\;is\;absolutely\;continuous,\;f(0)=f(1)=0,\;f'\in L^2[0,1]$} is a reproducing kernel hilbert space. Now assuming an inner-product given by: $<f,g> = \int_0^1\;f'(t)g'(t)\;dt$, by writing $f(x) = \int_0^x f'(t)\;dt$ I am able to show using cauchy schwartz inequality that  $|f(x)|\leq ||f|| \sqrt{x}$  and hence show that the Point evaluation functional is bounded. However, for completing the proof I have to show that this space is complete (So that it becomes a hilbert space). How do I do this?","My aim is to prove that the space: $\mathcal{H}$ = {$f:[0,1] \to \mathbb{R}: f\;is\;absolutely\;continuous,\;f(0)=f(1)=0,\;f'\in L^2[0,1]$} is a reproducing kernel hilbert space. Now assuming an inner-product given by: $<f,g> = \int_0^1\;f'(t)g'(t)\;dt$, by writing $f(x) = \int_0^x f'(t)\;dt$ I am able to show using cauchy schwartz inequality that  $|f(x)|\leq ||f|| \sqrt{x}$  and hence show that the Point evaluation functional is bounded. However, for completing the proof I have to show that this space is complete (So that it becomes a hilbert space). How do I do this?",,"['real-analysis', 'functional-analysis', 'hilbert-spaces']"
89,Do chains of compacts with measure 1 w.r.t. a positive regular probability always have an upper bound when the ordering is the reverse inclusion?,Do chains of compacts with measure 1 w.r.t. a positive regular probability always have an upper bound when the ordering is the reverse inclusion?,,"In a course in Functional Analysis, I tried to prove the following. Theorem Let $X$ be an LCH (locally compact Hausdorff) space and $\mu$ a positive regular Borel probability measure such that $\mu(A)$ is 0 or 1 for any Borel set of $X$. Then $\mu$ is a Dirac delta. The professor gave a hint to use Zorn's lemma, so I tried considering $Y=\{K\subset\subset X:\mu(K)=1\}$, ordered by reverse inclusion. $Y$ is nonempty since otherwise $\mu(K)=0$ for all compacts of $X$, but then by regularity $\mu(X)=0$, and $\mu(X)=1$ by hypothesis. What I got stuck on is the upper bound for chains part. Let $\{K_\alpha\}$ be a chain in $Y$. I want, of course, to take the intersection as an upper bound. It is compact since it is closed (intersection of closed sets, since compact in H space implies closed) in a compact set, any of the $K_\alpha$ works. It is nonempty since by total ordering the elements of the chain have the FIP and they are compact. But what about the measure? I and the professor both failed to prove it is 1, no matter what we tried. The professor then opened a book to find another argument for what I wanted, which was of course a minimal compact set of measure 1. But the question remains: Can I prove that $Y$ satisfies Zorn? If I take a countable chain I have continuity from above of $\mu$, but what about the uncountable case? Are there examples of spaces where $Y$ does not satisty Zorn's hypotheses? If so, can you provide such an example? If not, can we prove that any chain has an upper bound, and how? Note I am NOT asking whether a positive regular Borel probability which assings either 0 or 1 to all Borel sets is a Dirac delta or not, as answered here . I was trying to prove this and stumbled on an intermediate step I wasn't able to prove valid. Then I found another way, but I want to know if that step could have been done somehow. Repeat: I am asking about the INTERMEDIATE STEP of proving the $Y$ above satisfies Zorn, NOT the theorem I was trying to prove when I bumped into this problematic step. I hope it is clear now. I mean, this got its title edited to asking for the theorem, and I changed the title in a very long but -- at least I thought, but evidently not -- clear title. It stayed up for ages, and now, two or three days after opening a bounty, I get a comment pointing me to the post linked above, which is, for the present question, at least AFAICT, PLAIN USELESS! So hopefully this note will clarify what I am asking and stop this misunderstanding.","In a course in Functional Analysis, I tried to prove the following. Theorem Let $X$ be an LCH (locally compact Hausdorff) space and $\mu$ a positive regular Borel probability measure such that $\mu(A)$ is 0 or 1 for any Borel set of $X$. Then $\mu$ is a Dirac delta. The professor gave a hint to use Zorn's lemma, so I tried considering $Y=\{K\subset\subset X:\mu(K)=1\}$, ordered by reverse inclusion. $Y$ is nonempty since otherwise $\mu(K)=0$ for all compacts of $X$, but then by regularity $\mu(X)=0$, and $\mu(X)=1$ by hypothesis. What I got stuck on is the upper bound for chains part. Let $\{K_\alpha\}$ be a chain in $Y$. I want, of course, to take the intersection as an upper bound. It is compact since it is closed (intersection of closed sets, since compact in H space implies closed) in a compact set, any of the $K_\alpha$ works. It is nonempty since by total ordering the elements of the chain have the FIP and they are compact. But what about the measure? I and the professor both failed to prove it is 1, no matter what we tried. The professor then opened a book to find another argument for what I wanted, which was of course a minimal compact set of measure 1. But the question remains: Can I prove that $Y$ satisfies Zorn? If I take a countable chain I have continuity from above of $\mu$, but what about the uncountable case? Are there examples of spaces where $Y$ does not satisty Zorn's hypotheses? If so, can you provide such an example? If not, can we prove that any chain has an upper bound, and how? Note I am NOT asking whether a positive regular Borel probability which assings either 0 or 1 to all Borel sets is a Dirac delta or not, as answered here . I was trying to prove this and stumbled on an intermediate step I wasn't able to prove valid. Then I found another way, but I want to know if that step could have been done somehow. Repeat: I am asking about the INTERMEDIATE STEP of proving the $Y$ above satisfies Zorn, NOT the theorem I was trying to prove when I bumped into this problematic step. I hope it is clear now. I mean, this got its title edited to asking for the theorem, and I changed the title in a very long but -- at least I thought, but evidently not -- clear title. It stayed up for ages, and now, two or three days after opening a bounty, I get a comment pointing me to the post linked above, which is, for the present question, at least AFAICT, PLAIN USELESS! So hopefully this note will clarify what I am asking and stop this misunderstanding.",,"['functional-analysis', 'measure-theory']"
90,Learning generalized functions,Learning generalized functions,,"What is the best book to learn generalized functions and what prerequisites are needed? I would like a book that helps build intuition but it rigorous enough and not overly complex.  My background is engineering and I am more or less familiar with real and complex analysis, algebra, differential equations, Fourier and Laplace transforms.","What is the best book to learn generalized functions and what prerequisites are needed? I would like a book that helps build intuition but it rigorous enough and not overly complex.  My background is engineering and I am more or less familiar with real and complex analysis, algebra, differential equations, Fourier and Laplace transforms.",,"['analysis', 'functional-analysis', 'reference-request', 'soft-question', 'book-recommendation']"
91,boundness of linear map,boundness of linear map,,"Let $X$ and $Y$ be Banach spaces, $T : X\rightarrow Y$ a linear map such that $f \circ T\in X^*$ for every $f\in Y^*$, then $T$ is bounded. I've tried to show that $T$ is closed, but I think that's something wrong with my proof: Suppose  $$\lim_{n\to \infty}(x_n,Tx_n)=(x,y),$$ given $f\in Y^*$, $f \circ T$ is continuous so $$\lim_{n\to \infty}f \circ T(x_n)=f \circ T(x).$$ Now, $\lim_{n\to \infty} T(x_n)=y$ and $f$ is continuous, so  $\lim_{n\to \infty}f(T(x_n))=f(y)$. Hence, $\forall f\in Y^*$, $f(y-Tx)=0$, then by Hann-Banach $y=Tx$.","Let $X$ and $Y$ be Banach spaces, $T : X\rightarrow Y$ a linear map such that $f \circ T\in X^*$ for every $f\in Y^*$, then $T$ is bounded. I've tried to show that $T$ is closed, but I think that's something wrong with my proof: Suppose  $$\lim_{n\to \infty}(x_n,Tx_n)=(x,y),$$ given $f\in Y^*$, $f \circ T$ is continuous so $$\lim_{n\to \infty}f \circ T(x_n)=f \circ T(x).$$ Now, $\lim_{n\to \infty} T(x_n)=y$ and $f$ is continuous, so  $\lim_{n\to \infty}f(T(x_n))=f(y)$. Hence, $\forall f\in Y^*$, $f(y-Tx)=0$, then by Hann-Banach $y=Tx$.",,"['real-analysis', 'functional-analysis']"
92,How to proof $C_0^\infty(\mathbb{R}^n)$ is dense in $H^s(\mathbb{R}^n)$ by using mollifier,How to proof  is dense in  by using mollifier,C_0^\infty(\mathbb{R}^n) H^s(\mathbb{R}^n),"Since the definition of $u\in H^s(\mathbb{R}^n)$ is $\left(1+|\lambda|^2\right)^{s/2}\hat{u}(\lambda)\in L^2(\mathbb{R}^n)$ I find it difficult to give an constructive prove that use mollifier. let $\rho_\delta$ be a mollifier (for example $\exp(\frac{1}{1-(x/\delta)^2}1_{B(0,\delta)})$ ), then how to say $(u\ 1_{B(0,R)})*\rho_\delta$ converge to $u$ in $H^s$ when $\delta\to 0^+,R\to+\infty$ The main purpose is to prove that $C_0^\infty(\mathbb{R}^n)$ is dense in $E=\{u\in H^s(\mathbb{R}^n):\partial_{x_1}u\in L^2(\mathbb{R}^n)\}$ where $||u||_E^2=||u||_{H^s}^2+||\partial_{x_1}u||_{L^2}^2$. Simply use the fact that $C_0^\infty(\mathbb{R}^n)$ is dense in $H^s(\mathbb{R}^n)$ does not work","Since the definition of $u\in H^s(\mathbb{R}^n)$ is $\left(1+|\lambda|^2\right)^{s/2}\hat{u}(\lambda)\in L^2(\mathbb{R}^n)$ I find it difficult to give an constructive prove that use mollifier. let $\rho_\delta$ be a mollifier (for example $\exp(\frac{1}{1-(x/\delta)^2}1_{B(0,\delta)})$ ), then how to say $(u\ 1_{B(0,R)})*\rho_\delta$ converge to $u$ in $H^s$ when $\delta\to 0^+,R\to+\infty$ The main purpose is to prove that $C_0^\infty(\mathbb{R}^n)$ is dense in $E=\{u\in H^s(\mathbb{R}^n):\partial_{x_1}u\in L^2(\mathbb{R}^n)\}$ where $||u||_E^2=||u||_{H^s}^2+||\partial_{x_1}u||_{L^2}^2$. Simply use the fact that $C_0^\infty(\mathbb{R}^n)$ is dense in $H^s(\mathbb{R}^n)$ does not work",,"['functional-analysis', 'sobolev-spaces']"
93,Adjoints in Banach spaces,Adjoints in Banach spaces,,"I been trying to figure out if the construction of the isomorphism between $g(W)$ and $f^{*}(W^{*})$ via  $$B_V(v, g(w)) = B_W(f(v),w) \quad \forall v \in V, w \in W $$ described (at least this is what I think they mean) in the wikipedia page , is meaningfull in a Banach space which is not Hilbert. One reason it wouldn't be the lack of existancee of non-degenrate bilinear forms but this is something which I can't manage to establish. Or maybe there is some other reason?","I been trying to figure out if the construction of the isomorphism between $g(W)$ and $f^{*}(W^{*})$ via  $$B_V(v, g(w)) = B_W(f(v),w) \quad \forall v \in V, w \in W $$ described (at least this is what I think they mean) in the wikipedia page , is meaningfull in a Banach space which is not Hilbert. One reason it wouldn't be the lack of existancee of non-degenrate bilinear forms but this is something which I can't manage to establish. Or maybe there is some other reason?",,['functional-analysis']
94,Intuition and slick proof that distributions are special cases of hyperfunctions?,Intuition and slick proof that distributions are special cases of hyperfunctions?,,"I am looking for some slick or simple proof that distributions are a special case of hyperfunctions. Furthermore, what is the intuition behind this fact? Why should one think of hyperfunctions as 'distributions of infinite order' as wikipedia says? I have not studied hyperfunctions, so I only think of them naively as the difference of two holomorphic functions (in one variable) on the real line. [ By the way, I think making a hyperfunctions tag may be worth considering .]","I am looking for some slick or simple proof that distributions are a special case of hyperfunctions. Furthermore, what is the intuition behind this fact? Why should one think of hyperfunctions as 'distributions of infinite order' as wikipedia says? I have not studied hyperfunctions, so I only think of them naively as the difference of two holomorphic functions (in one variable) on the real line. [ By the way, I think making a hyperfunctions tag may be worth considering .]",,"['functional-analysis', 'distribution-theory']"
95,$C^k$ one-parameter family of metrics,one-parameter family of metrics,C^k,"Consider a smooth Riemannian manifold $M$ and a $C^k$ one-parameter family of Riemannian metrics $g_t$ on $M$. Here $k$ could be any integer, $k$ could be infinity, when the one-parameter family $g_t$ is smooth in time, or $k = \omega$, when the one-parameter family $g_t$ is real analytic in time. Now, as the metric varies, the Laplacian associated to the metric varies, and hence its spectrum also varies in time. My question is, if $g_t$ is $C^k$ in time, are the eigenvalues of the Laplacian also $C^k$ in time for $k$ integer, $k = \infty$ or $k = \omega$? In case such results are well-known (which I am assuming they are), what is a good reference to learn about such results? Thanks for any guidance.","Consider a smooth Riemannian manifold $M$ and a $C^k$ one-parameter family of Riemannian metrics $g_t$ on $M$. Here $k$ could be any integer, $k$ could be infinity, when the one-parameter family $g_t$ is smooth in time, or $k = \omega$, when the one-parameter family $g_t$ is real analytic in time. Now, as the metric varies, the Laplacian associated to the metric varies, and hence its spectrum also varies in time. My question is, if $g_t$ is $C^k$ in time, are the eigenvalues of the Laplacian also $C^k$ in time for $k$ integer, $k = \infty$ or $k = \omega$? In case such results are well-known (which I am assuming they are), what is a good reference to learn about such results? Thanks for any guidance.",,"['functional-analysis', 'differential-geometry', 'reference-request', 'riemannian-geometry', 'spectral-theory']"
96,Me vs. Wikipedia (Lacunary function)?,Me vs. Wikipedia (Lacunary function)?,,"I was recently reading this wikipedia page: https://en.wikipedia.org/wiki/Lacunary_function and found atleast the example they are giving must be wrong because I have kind of managed to analytically get an asymptotic result: The example he gives seems to be a special version of this series: $$ S(n,x) = e^{n\ln(x)} + e^{n^2\ln(x)} + e^{n^3 ln(x)} + ... $$ However this series also satisfies the partial differential equation: $$ x \frac{\partial S}{\partial x} - n x^2 \frac{\partial^2 S}{\partial x^2} = nS $$ (This was found by me after alot of brute force) Dividing the PDE by $ x^2 $ $$ \frac{\partial S}{x \partial x} - n \frac{\partial^2 S}{\partial x^2} = \frac{nS}{x^2} $$ Taking limit $ x $ tends to infinity: $$ \lim_{x \to \infty} \frac{\partial S}{x \partial x} -\frac{nS}{x^2} = n \frac{\partial^2 S}{\partial x^2}  $$ Now, we have options depending on assuming $ \lim_{x \to \infty} S=\infty $ or $ \lim_{x \to \infty} S'=\infty $ With alot of guesswork we get (the other options when solved the assumption is not justified): $$ -\frac{nS}{x^2} = n \frac{\partial^2 S}{\partial x^2}  $$ We take the solution: $$ S \sim C \sqrt(x) \sin (\frac{\sqrt{3}}{2} \log(x)) $$ P.S: In general I find it hard to believe there can exist series which cannot be analytically continued. Questions Have I done something wrong? Is wikipedia wrong? Is this a known method of converting a function into a PDE and then taking limits to guess the asymptotic relationship known?","I was recently reading this wikipedia page: https://en.wikipedia.org/wiki/Lacunary_function and found atleast the example they are giving must be wrong because I have kind of managed to analytically get an asymptotic result: The example he gives seems to be a special version of this series: $$ S(n,x) = e^{n\ln(x)} + e^{n^2\ln(x)} + e^{n^3 ln(x)} + ... $$ However this series also satisfies the partial differential equation: $$ x \frac{\partial S}{\partial x} - n x^2 \frac{\partial^2 S}{\partial x^2} = nS $$ (This was found by me after alot of brute force) Dividing the PDE by $ x^2 $ $$ \frac{\partial S}{x \partial x} - n \frac{\partial^2 S}{\partial x^2} = \frac{nS}{x^2} $$ Taking limit $ x $ tends to infinity: $$ \lim_{x \to \infty} \frac{\partial S}{x \partial x} -\frac{nS}{x^2} = n \frac{\partial^2 S}{\partial x^2}  $$ Now, we have options depending on assuming $ \lim_{x \to \infty} S=\infty $ or $ \lim_{x \to \infty} S'=\infty $ With alot of guesswork we get (the other options when solved the assumption is not justified): $$ -\frac{nS}{x^2} = n \frac{\partial^2 S}{\partial x^2}  $$ We take the solution: $$ S \sim C \sqrt(x) \sin (\frac{\sqrt{3}}{2} \log(x)) $$ P.S: In general I find it hard to believe there can exist series which cannot be analytically continued. Questions Have I done something wrong? Is wikipedia wrong? Is this a known method of converting a function into a PDE and then taking limits to guess the asymptotic relationship known?",,"['analysis', 'functional-analysis', 'proof-verification']"
97,Regularity of a weak solution,Regularity of a weak solution,,"The problem is formulated as follows: Let $\Omega\subset\mathbb{R}^2$ a bounded Lipschitz domain. For $u\in L_2(\Omega)$ one can define the one dimensional weak dirivative $\partial_1 u$. Now define the space $M:=\{u\in L_2(\Omega):\partial_1 u\in L_2(\Omega)\}$. Then $M$ with the norm $\|u\|_{L_2}+\|\partial_1 u\|_{L_2}$ is a Hilbert space. It is also clear that $C_0^\infty(\Omega)\subset M$. Now debote by $M_0$ the closure of $C_0^\infty(\Omega)$ w.r.t. the special norm. Let's consider the following equation: Given some $f\in L_2(\Omega)$. Find $u\in M_0$ such that \begin{equation} \int_\Omega f\partial_1 vdx=\int_\Omega\partial_1u\partial_1vdx \end{equation} is valid for all $v\in M_0$. From Lax-Milgram and one dimensional Poincare's inequality one can deduce that such $u$ exists and is unique. Now the question is, if $f\in H_{loc}^1(\Omega)$, is $\partial_1 u$ in general also in $H_{loc}^1(\Omega)$? Update : So far I have proved that if $f\in H_0^1(\Omega)$, then $\partial_1\alpha$ has to be in $H^1_{loc}(\Omega)$. The trick is to use the discrete Fourier transform. Let me explain the trick I used (I am also not quite sure if I was mistaken, since I am not very familiar with the Fourier transform method). Since $f$ and $\alpha$ can be approximated by smooth functions with compact support, we can extend them to $\mathbb{R}^2$ by setting their value equal to zero outside of the region and they belong to $H^1(\mathbb{R}^2)$ and $M(\mathbb{R}^2)$. In particular, they and their derivatives can be written as the discrete Fourier sum (I will write also scalar components by $c$, since they don't essentially influence the result), for example, \begin{align} f(x)&=c\sum_{n\in\mathbb{Z}^2}Ff(n)e^{in\cdot x},\\ \partial_2f(x)&=c\sum_{n\in\mathbb{Z}^2}n_2Ff(n)e^{in\cdot x},\\ \partial_1\alpha(x)&=c\sum_{n\in\mathbb{Z}^2}n_1F\alpha(n)e^{in\cdot x} \end{align} and so on. In fact, using the standard differnce quotient method one derive \begin{equation} f(x)-\partial_1\alpha(x)=G(x_2) \end{equation} for some $G\in L_2(\Omega)$. Now for $g(x):=G(x_2)$ we also have its Fourier sum \begin{equation} G(x)=c\sum_{n_2\in\mathbb{Z}}Fg(n_2)e^{in_2\cdot x_2}. \end{equation} Sum up all, we have \begin{equation} \partial_2f(x)=c\sum_{n\in\mathbb{Z}^2}n_1n_2F\alpha(n)e^{in\cdot x}+c\sum_{n_2\in\mathbb{Z}}n_2Fg(n_2)e^{in_2x_2}. \end{equation} Since $\partial_2 f\in L_2$, we have \begin{equation} \sum_{n\in\mathbb{Z}^2}|n_1n_2F\alpha(n)|^2<\infty. \end{equation} Then define $v(x)=c\sum_{n\in\mathbb{Z}^2}n_1n_2F\alpha(n)e^{in\cdot x}$, and $v$ is in $L_2$ and using the definition of weak derivative, it is actually equal to $\partial_2\partial_1\alpha$.","The problem is formulated as follows: Let $\Omega\subset\mathbb{R}^2$ a bounded Lipschitz domain. For $u\in L_2(\Omega)$ one can define the one dimensional weak dirivative $\partial_1 u$. Now define the space $M:=\{u\in L_2(\Omega):\partial_1 u\in L_2(\Omega)\}$. Then $M$ with the norm $\|u\|_{L_2}+\|\partial_1 u\|_{L_2}$ is a Hilbert space. It is also clear that $C_0^\infty(\Omega)\subset M$. Now debote by $M_0$ the closure of $C_0^\infty(\Omega)$ w.r.t. the special norm. Let's consider the following equation: Given some $f\in L_2(\Omega)$. Find $u\in M_0$ such that \begin{equation} \int_\Omega f\partial_1 vdx=\int_\Omega\partial_1u\partial_1vdx \end{equation} is valid for all $v\in M_0$. From Lax-Milgram and one dimensional Poincare's inequality one can deduce that such $u$ exists and is unique. Now the question is, if $f\in H_{loc}^1(\Omega)$, is $\partial_1 u$ in general also in $H_{loc}^1(\Omega)$? Update : So far I have proved that if $f\in H_0^1(\Omega)$, then $\partial_1\alpha$ has to be in $H^1_{loc}(\Omega)$. The trick is to use the discrete Fourier transform. Let me explain the trick I used (I am also not quite sure if I was mistaken, since I am not very familiar with the Fourier transform method). Since $f$ and $\alpha$ can be approximated by smooth functions with compact support, we can extend them to $\mathbb{R}^2$ by setting their value equal to zero outside of the region and they belong to $H^1(\mathbb{R}^2)$ and $M(\mathbb{R}^2)$. In particular, they and their derivatives can be written as the discrete Fourier sum (I will write also scalar components by $c$, since they don't essentially influence the result), for example, \begin{align} f(x)&=c\sum_{n\in\mathbb{Z}^2}Ff(n)e^{in\cdot x},\\ \partial_2f(x)&=c\sum_{n\in\mathbb{Z}^2}n_2Ff(n)e^{in\cdot x},\\ \partial_1\alpha(x)&=c\sum_{n\in\mathbb{Z}^2}n_1F\alpha(n)e^{in\cdot x} \end{align} and so on. In fact, using the standard differnce quotient method one derive \begin{equation} f(x)-\partial_1\alpha(x)=G(x_2) \end{equation} for some $G\in L_2(\Omega)$. Now for $g(x):=G(x_2)$ we also have its Fourier sum \begin{equation} G(x)=c\sum_{n_2\in\mathbb{Z}}Fg(n_2)e^{in_2\cdot x_2}. \end{equation} Sum up all, we have \begin{equation} \partial_2f(x)=c\sum_{n\in\mathbb{Z}^2}n_1n_2F\alpha(n)e^{in\cdot x}+c\sum_{n_2\in\mathbb{Z}}n_2Fg(n_2)e^{in_2x_2}. \end{equation} Since $\partial_2 f\in L_2$, we have \begin{equation} \sum_{n\in\mathbb{Z}^2}|n_1n_2F\alpha(n)|^2<\infty. \end{equation} Then define $v(x)=c\sum_{n\in\mathbb{Z}^2}n_1n_2F\alpha(n)e^{in\cdot x}$, and $v$ is in $L_2$ and using the definition of weak derivative, it is actually equal to $\partial_2\partial_1\alpha$.",,"['functional-analysis', 'partial-differential-equations', 'sobolev-spaces', 'regularity-theory-of-pdes']"
98,The best constant in Poincare-liked inequality in BV space,The best constant in Poincare-liked inequality in BV space,,"Let $\Omega\subset \mathbb R^N$ be a open bounded set with smooth boundary. Then we can prove that for any $u\in BV(\Omega)$ and $\omega\in \operatorname{ker}\mathcal E $ , where $\mathcal E$ denotes the distributional symmetrize derivative $\mathcal E\omega = \frac{1}{2}(\nabla w+\nabla w^T)$ from $\mathbb R^N$ to $\mathbb R^N$ , there exists a constant $C>0$ independent of $u$ and $\omega$ such that $$ \|Du\|_{\mathcal M(\Omega)}\leq C(\|Du-w\|_{\mathcal M(\Omega)}+\|u\|_{L^1}) $$ The proof is not long and can be found here , Theorem 3.3, equation $(4)$ . It can also be shown that $\omega\in \operatorname{ker}\mathcal E$ iff $\omega = Ax+b$ where $A=-A^T$ , $A\in\mathbb R^{N\times N}$ and $b\in \mathbb R^N$ However, the proof I know is done by using contradiction, and while the argument is short and simple it cannot give any information on the constant $C$ . I am sure that this constant only depends on $\Omega$ but I really want to know its dependence explicitly. What is the best value for the constant $C$ and can we make it larger or smaller by changing $\Omega$ ? Also, if $\Omega:=[0,1]\times[0,1]$ in $\mathbb R^2$ , can we explicitly compute this constant? Thank you!","Let be a open bounded set with smooth boundary. Then we can prove that for any and , where denotes the distributional symmetrize derivative from to , there exists a constant independent of and such that The proof is not long and can be found here , Theorem 3.3, equation . It can also be shown that iff where , and However, the proof I know is done by using contradiction, and while the argument is short and simple it cannot give any information on the constant . I am sure that this constant only depends on but I really want to know its dependence explicitly. What is the best value for the constant and can we make it larger or smaller by changing ? Also, if in , can we explicitly compute this constant? Thank you!","\Omega\subset \mathbb R^N u\in BV(\Omega) \omega\in \operatorname{ker}\mathcal E  \mathcal E \mathcal E\omega = \frac{1}{2}(\nabla w+\nabla w^T) \mathbb R^N \mathbb R^N C>0 u \omega 
\|Du\|_{\mathcal M(\Omega)}\leq C(\|Du-w\|_{\mathcal M(\Omega)}+\|u\|_{L^1})
 (4) \omega\in \operatorname{ker}\mathcal E \omega = Ax+b A=-A^T A\in\mathbb R^{N\times N} b\in \mathbb R^N C \Omega C \Omega \Omega:=[0,1]\times[0,1] \mathbb R^2","['functional-analysis', 'partial-differential-equations', 'sobolev-spaces', 'bounded-variation']"
99,Compactum of Banach algebra,Compactum of Banach algebra,,"I need an example of Banach algebra $A$ and a left non-trivial closed ideal $I$ with all of following properties: There exists a bounded approximate identity in $I$ for $I$ i.e., a net $\{e_\alpha\}\subset I$ such that $$ae_\alpha\to a,\quad e_\alpha a\to a,\quad a\in I.$$ For all of the $a\in A$ with $Ia=\{0\}$ or $aI=\{0\}$ we get to $a=0$. There exists an element $x\in A$ with $x\not\in I$ and $xA_1x=\overline{\{xax:a\in A, \|a\|\leq1\}}^{\|.\|}$ is compact.","I need an example of Banach algebra $A$ and a left non-trivial closed ideal $I$ with all of following properties: There exists a bounded approximate identity in $I$ for $I$ i.e., a net $\{e_\alpha\}\subset I$ such that $$ae_\alpha\to a,\quad e_\alpha a\to a,\quad a\in I.$$ For all of the $a\in A$ with $Ia=\{0\}$ or $aI=\{0\}$ we get to $a=0$. There exists an element $x\in A$ with $x\not\in I$ and $xA_1x=\overline{\{xax:a\in A, \|a\|\leq1\}}^{\|.\|}$ is compact.",,"['functional-analysis', 'ideals', 'operator-algebras', 'harmonic-analysis', 'banach-algebras']"
