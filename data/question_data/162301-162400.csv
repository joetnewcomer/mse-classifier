,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Real Analysis, Folland Excercise 2.40","Real Analysis, Folland Excercise 2.40",,"Exercise 40 - Show in Egoroff's theorem, the hypothesis "" $\mu(X)<\infty$ "" can be replaced by "" $|f_n|\le g$ for all $n$ , where $g \in L^1(\mu)$ ."" Egoroff's Theorem - Suppose $\mu(X)<\infty$ , and $f_1, f_2, ...$ and $f$ are measurable complex-valued functions on $X$ such that $f_n \rightarrow f$ a.e. Then for every $\epsilon > 0$ there exists $E\subset X$ such that $\mu(E)<\epsilon$ and $f_n \rightarrow f$ uniformly on $E^c$ . The proof of the original Egoroff's theorem uses continuity from above, which requires the finiteness assumption. I tried to use the dominating $g$ to get some finiteness condition. When $\mu$ is $\sigma$ -finite, I showed the integral of $g$ is concentrated on some set of finite measure. But this does not seem to help proving the statement since the complement of this set still have infinite measure (if $X$ has). Can anyone give me some hint on the problem? Thank you","Exercise 40 - Show in Egoroff's theorem, the hypothesis "" "" can be replaced by "" for all , where ."" Egoroff's Theorem - Suppose , and and are measurable complex-valued functions on such that a.e. Then for every there exists such that and uniformly on . The proof of the original Egoroff's theorem uses continuity from above, which requires the finiteness assumption. I tried to use the dominating to get some finiteness condition. When is -finite, I showed the integral of is concentrated on some set of finite measure. But this does not seem to help proving the statement since the complement of this set still have infinite measure (if has). Can anyone give me some hint on the problem? Thank you","\mu(X)<\infty |f_n|\le g n g \in L^1(\mu) \mu(X)<\infty f_1, f_2, ... f X f_n \rightarrow f \epsilon > 0 E\subset X \mu(E)<\epsilon f_n \rightarrow f E^c g \mu \sigma g X","['real-analysis', 'measure-theory']"
1,"adapted process, translation between measurable and information?","adapted process, translation between measurable and information?",,"Although there are plenty of questions and answers on understanding the intuition for adapted process like this post and this post I am still unclear on how an adapted filtration 'captures the information of the process up to time $t$.' First some notation, let $(\Omega, \mathcal{F}, P)$ be a probability space. $X:T\times \Omega \to (S, \Sigma)$ be a stochastic process.  That is $X_t:= X(t,\cdot)$ is an $(\mathcal{F}, \Sigma)$-measurable function for all $t\in T.$ $\{\mathcal{F}_t\}$ such that $\mathcal{F}_s\subset \mathcal{F}_t$ for $s\leq t$ be a filtration of $\mathcal{F}.$ Definition: We say $X_t$ is adapted to the filtration $\{\mathcal{F}_t\}$ if $X_t$ is $\mathcal{F}_t$-measurable for all $t.$ The definition is clear as day but I am confused about the interpretation/intuition/motivation.  A classic example is the price of a stock, $S_t$ which is adapted to the natural filtration of the Brownian motion on which it is modeled $S_t = \exp(ut + \sigma B_t).$  The interpretation on the adapted filtration condition is that we only know the current price of the stock (and its history) but we don't know the future price of the stock. Question: (stock version): Why does the stock being adapted filtration have anything to do with knowing its current and historical prices? I don't see the connection mathematically. In real life we have a stock and we know its price and its history.  I can't see the connection between this and that condition that $S_t$ be $\mathcal{F}_t$-measurable.  A discrete example might help illustrate my confusion. Discrete Example Consider the example of flipping a coin 3 times. With $X_i$ being 1 if the $i$th flip is heads and $X_i$ is 0 if the $i$th flip is tails.  Let  $$\Omega = \{hhh, hht, hth, htt,ttt, tth, tht, thh\}$$ be the state space of the experiment and $\mathcal{F}$ all subsets of $\Omega.$  Then we define the stochastic process $X$ by $$X:\{1,2,3\}\times \Omega \to (S,\Sigma)$$ with $S=\{0,1\}$ and $\Sigma$ all subsets of $S.$ The smallest possible filtration to which $X$ is adapted is the natural filtration .  We compute $$\begin{align} \mathcal{F}_1 &= \sigma(\{X_1^{-1}(A)| A\in \Sigma\})\\               &= \sigma(\{X_1^{-1}(\emptyset), X_1^{-1}(0), X_1^{-1}(1), X_1^{-1}(\{0,1\})\}\\               &= \{\emptyset, \{ttt,tth,tht,thh\}, \{hhh,hht,hth,htt\}, \Omega\}               \end{align}$$ In this case adaptability translates to forcing $X_1$ to constant on the sets $\{ttt,tth,tht,thh\}$ and $\{hhh,hht,hth,htt\}.$  But how does this help us?  It certainly doesn't tell us which set happened and which didn't.  I can see that $X_2$ is not $\mathcal{F}_1$-measurable, but so what?  Knowing $\mathcal{F}_1$ doesn't give us any knowledge about the result of the first toss, other that it was either a heads or a tails, which we already knew.  So now I am ready to state my more general question Question Why does the $\sigma$-algebra $\mathcal{F}_t$  'contain information' about the process up to time $t$ and what does this mean?  How can we use it to say something concrete about what has actually happened up to time $t$ and how can we justify this mathematically?","Although there are plenty of questions and answers on understanding the intuition for adapted process like this post and this post I am still unclear on how an adapted filtration 'captures the information of the process up to time $t$.' First some notation, let $(\Omega, \mathcal{F}, P)$ be a probability space. $X:T\times \Omega \to (S, \Sigma)$ be a stochastic process.  That is $X_t:= X(t,\cdot)$ is an $(\mathcal{F}, \Sigma)$-measurable function for all $t\in T.$ $\{\mathcal{F}_t\}$ such that $\mathcal{F}_s\subset \mathcal{F}_t$ for $s\leq t$ be a filtration of $\mathcal{F}.$ Definition: We say $X_t$ is adapted to the filtration $\{\mathcal{F}_t\}$ if $X_t$ is $\mathcal{F}_t$-measurable for all $t.$ The definition is clear as day but I am confused about the interpretation/intuition/motivation.  A classic example is the price of a stock, $S_t$ which is adapted to the natural filtration of the Brownian motion on which it is modeled $S_t = \exp(ut + \sigma B_t).$  The interpretation on the adapted filtration condition is that we only know the current price of the stock (and its history) but we don't know the future price of the stock. Question: (stock version): Why does the stock being adapted filtration have anything to do with knowing its current and historical prices? I don't see the connection mathematically. In real life we have a stock and we know its price and its history.  I can't see the connection between this and that condition that $S_t$ be $\mathcal{F}_t$-measurable.  A discrete example might help illustrate my confusion. Discrete Example Consider the example of flipping a coin 3 times. With $X_i$ being 1 if the $i$th flip is heads and $X_i$ is 0 if the $i$th flip is tails.  Let  $$\Omega = \{hhh, hht, hth, htt,ttt, tth, tht, thh\}$$ be the state space of the experiment and $\mathcal{F}$ all subsets of $\Omega.$  Then we define the stochastic process $X$ by $$X:\{1,2,3\}\times \Omega \to (S,\Sigma)$$ with $S=\{0,1\}$ and $\Sigma$ all subsets of $S.$ The smallest possible filtration to which $X$ is adapted is the natural filtration .  We compute $$\begin{align} \mathcal{F}_1 &= \sigma(\{X_1^{-1}(A)| A\in \Sigma\})\\               &= \sigma(\{X_1^{-1}(\emptyset), X_1^{-1}(0), X_1^{-1}(1), X_1^{-1}(\{0,1\})\}\\               &= \{\emptyset, \{ttt,tth,tht,thh\}, \{hhh,hht,hth,htt\}, \Omega\}               \end{align}$$ In this case adaptability translates to forcing $X_1$ to constant on the sets $\{ttt,tth,tht,thh\}$ and $\{hhh,hht,hth,htt\}.$  But how does this help us?  It certainly doesn't tell us which set happened and which didn't.  I can see that $X_2$ is not $\mathcal{F}_1$-measurable, but so what?  Knowing $\mathcal{F}_1$ doesn't give us any knowledge about the result of the first toss, other that it was either a heads or a tails, which we already knew.  So now I am ready to state my more general question Question Why does the $\sigma$-algebra $\mathcal{F}_t$  'contain information' about the process up to time $t$ and what does this mean?  How can we use it to say something concrete about what has actually happened up to time $t$ and how can we justify this mathematically?",,"['measure-theory', 'stochastic-processes', 'finance', 'filtrations']"
2,Show that $\lim_{n\to \infty}\int_{0}^{1}g(x)f(nx)dx = \Big(\int_{0}^{1}g(x)dx\Big)\Big(\int_{0}^{1}f(x)dx\Big)$,Show that,\lim_{n\to \infty}\int_{0}^{1}g(x)f(nx)dx = \Big(\int_{0}^{1}g(x)dx\Big)\Big(\int_{0}^{1}f(x)dx\Big),"This is a question I've encountered in a homework sheet, and I do not even know where to begin: Let $f:[0, \infty) \rightarrow \mathbb R$ be a continuous real valued function such that $f(x+1)=f(x)$ for all $x\ge0$ . If $g:[0,1] \rightarrow \mathbb R$ is an arbitrary continuous function, show that $$\lim_{n\to \infty}\int_0^1g(x)f(nx)\,dx = \left(\int_0^1g(x)\,dx\right)\left(\int_0^1f(x)\,dx\right).$$ We were given a hint: $$\int_0^1 g(x)f(nx)\,dx = \frac{1}{n} \sum_{i=1}^n \int_{i-1}^i g\left(\frac{u}{n}\right)f(u)\,du,$$ and put $t = u - i + 1.$ I have absolutely no idea where to begin. My thoughts are that this question will involve the use of Lebesgue's convergence theorem, and perhaps the monotone convergence theorems. I have a very basic understanding of these theorems but still struggle when they need to be applied. My understanding is that: Function must be Riemann Integrable $f_n \rightarrow f$ almost everywhere $|f_n| \le g \in L^1$ I understand 1., and kind of understand 3. but I'm never able to prove 2. without any help. In fact, I only have a vague understanding of 2. and 3. I've attempted many questions, but just cannot finish one without help. My take is that I lack basic understanding on measure theory and I also lack practice, although I've been spending a large portion of time on this subject this semester. Everything is new and extremely difficult. I'd appreciate some books on the subjects, the lecture notes are really good, but I don't think it's enough at this point. I want something better than a mere pass (and if I aim for a pass, I will fail the subject) -- I want to actually understand it. Any help and recommendations are appreciated. Thanks!","This is a question I've encountered in a homework sheet, and I do not even know where to begin: Let be a continuous real valued function such that for all . If is an arbitrary continuous function, show that We were given a hint: and put I have absolutely no idea where to begin. My thoughts are that this question will involve the use of Lebesgue's convergence theorem, and perhaps the monotone convergence theorems. I have a very basic understanding of these theorems but still struggle when they need to be applied. My understanding is that: Function must be Riemann Integrable almost everywhere I understand 1., and kind of understand 3. but I'm never able to prove 2. without any help. In fact, I only have a vague understanding of 2. and 3. I've attempted many questions, but just cannot finish one without help. My take is that I lack basic understanding on measure theory and I also lack practice, although I've been spending a large portion of time on this subject this semester. Everything is new and extremely difficult. I'd appreciate some books on the subjects, the lecture notes are really good, but I don't think it's enough at this point. I want something better than a mere pass (and if I aim for a pass, I will fail the subject) -- I want to actually understand it. Any help and recommendations are appreciated. Thanks!","f:[0, \infty) \rightarrow \mathbb R f(x+1)=f(x) x\ge0 g:[0,1] \rightarrow \mathbb R \lim_{n\to \infty}\int_0^1g(x)f(nx)\,dx = \left(\int_0^1g(x)\,dx\right)\left(\int_0^1f(x)\,dx\right). \int_0^1 g(x)f(nx)\,dx = \frac{1}{n} \sum_{i=1}^n \int_{i-1}^i g\left(\frac{u}{n}\right)f(u)\,du, t = u - i + 1. f_n \rightarrow f |f_n| \le g \in L^1","['real-analysis', 'measure-theory', 'convergence-divergence', 'lebesgue-measure', 'riemann-integration']"
3,Implications of the Borel-Cantelli Lemma,Implications of the Borel-Cantelli Lemma,,"I'm looking back at my book for my Real Analysis course, and the book (Royden & Fitzpatrick's Real Analysis , 4 ed.) gives the following for the definition of ""almost everywhere"" and the statement of the Borel-Cantelli Lemma, respectively: (1) For a measurable set $E$, we say that a property holds almost everywhere on $E$, or it holds for almost all $x\in E$, provided there is a subset $E_0$ of $E$ for which $m(E_0)=0$ and the property holds for all $x\in E \setminus E_0$. (2) The Borel-Cantelli Lemma $\quad$ Let $\{E_k\}_{k=1}^\infty$ be a countable collection of measurable sets for which $\sum_{k=1}^\infty m(E_k) \lt \infty$.  Then almost all $x\in\mathbb{R}$ belong to at most finitely many of the $E_k$'s. Now, my question is this:  Does this imply that, for instance, almost all $x\in\mathbb{R}$ belong to the interval $[0,1]$? I have reasoned as follows: Take $E_1 = [0,1]$ and $\{E_k\}_{k\ge2} = \emptyset$. Then $\sum_{k=1}^\infty m(E_k) = 1 + 0 + 0 + \cdots = 1 \lt \infty$. Thus the hypotheses of the Lemma are satisfied and we can conclude that almost all $x\in\mathbb{R}$ belong to $[0,1]$. However, I struggle to find an $E_0$ that satisfies the definition of almost all .  I mean that the property "" belongs to $[0,1]$ "" holds for almost all $x\in\mathbb{R}$ by the above, so by definition, there is a subset $E_0 \subseteq \mathbb{R}$ such that $m(E_0)=0$ and "" belongs to $[0,1]$ "" holds for all $x\in\mathbb{R}\setminus E_0$.  I also find this confusing because it would seem that in order for this to be true we would have to remove at least the set $(-\infty,0)\cup(1,\infty)$ from $\mathbb{R}$ to obtain a set of numbers contained in $[0,1]$, right? But then this set doesn't have Lebesgue measure zero, right?  Please let me know what I am missing here or what I am getting wrong. It seems that there is either something I am not understanding correctly or I have made a false statement somewhere.","I'm looking back at my book for my Real Analysis course, and the book (Royden & Fitzpatrick's Real Analysis , 4 ed.) gives the following for the definition of ""almost everywhere"" and the statement of the Borel-Cantelli Lemma, respectively: (1) For a measurable set $E$, we say that a property holds almost everywhere on $E$, or it holds for almost all $x\in E$, provided there is a subset $E_0$ of $E$ for which $m(E_0)=0$ and the property holds for all $x\in E \setminus E_0$. (2) The Borel-Cantelli Lemma $\quad$ Let $\{E_k\}_{k=1}^\infty$ be a countable collection of measurable sets for which $\sum_{k=1}^\infty m(E_k) \lt \infty$.  Then almost all $x\in\mathbb{R}$ belong to at most finitely many of the $E_k$'s. Now, my question is this:  Does this imply that, for instance, almost all $x\in\mathbb{R}$ belong to the interval $[0,1]$? I have reasoned as follows: Take $E_1 = [0,1]$ and $\{E_k\}_{k\ge2} = \emptyset$. Then $\sum_{k=1}^\infty m(E_k) = 1 + 0 + 0 + \cdots = 1 \lt \infty$. Thus the hypotheses of the Lemma are satisfied and we can conclude that almost all $x\in\mathbb{R}$ belong to $[0,1]$. However, I struggle to find an $E_0$ that satisfies the definition of almost all .  I mean that the property "" belongs to $[0,1]$ "" holds for almost all $x\in\mathbb{R}$ by the above, so by definition, there is a subset $E_0 \subseteq \mathbb{R}$ such that $m(E_0)=0$ and "" belongs to $[0,1]$ "" holds for all $x\in\mathbb{R}\setminus E_0$.  I also find this confusing because it would seem that in order for this to be true we would have to remove at least the set $(-\infty,0)\cup(1,\infty)$ from $\mathbb{R}$ to obtain a set of numbers contained in $[0,1]$, right? But then this set doesn't have Lebesgue measure zero, right?  Please let me know what I am missing here or what I am getting wrong. It seems that there is either something I am not understanding correctly or I have made a false statement somewhere.",,"['real-analysis', 'measure-theory', 'lebesgue-measure', 'borel-cantelli-lemmas']"
4,Folland Exercise 3.8,Folland Exercise 3.8,,"Let $\nu$ is a signed measure and $\mu$ is a positive measure then $\nu \ll \mu$ iff ${\nu}^{+} \ll \mu$ and ${\nu}^{-} \ll \mu$. My try: Converse part is easy. For forward implication, let $\nu \ll \mu$ and $E \in \mathcal{M}$ such that $\mu(E)=0$ $\Rightarrow \nu(E)=0$ $\Rightarrow {\nu}^{+}(E)={\nu}^{-}(E)$ Since ${\nu}^{+}\perp {\nu}^{-}$ $\exists P,N \in \mathcal{M}$ such that P is ${\nu}^{-}$ null and N is $\nu^{+}$ null. $\Rightarrow$ $\nu^+(E)=\nu(E \cap P)$ But I am not able to proceed and show ${\nu}^{+}(E)=0$ Thanks for help!","Let $\nu$ is a signed measure and $\mu$ is a positive measure then $\nu \ll \mu$ iff ${\nu}^{+} \ll \mu$ and ${\nu}^{-} \ll \mu$. My try: Converse part is easy. For forward implication, let $\nu \ll \mu$ and $E \in \mathcal{M}$ such that $\mu(E)=0$ $\Rightarrow \nu(E)=0$ $\Rightarrow {\nu}^{+}(E)={\nu}^{-}(E)$ Since ${\nu}^{+}\perp {\nu}^{-}$ $\exists P,N \in \mathcal{M}$ such that P is ${\nu}^{-}$ null and N is $\nu^{+}$ null. $\Rightarrow$ $\nu^+(E)=\nu(E \cap P)$ But I am not able to proceed and show ${\nu}^{+}(E)=0$ Thanks for help!",,"['real-analysis', 'measure-theory']"
5,A question about dominated convergence theorem,A question about dominated convergence theorem,,"I have this question and I don't know how to proceed: Suppose that $(f_n)$ is a sequence of measurable functions on $[0,1]$ such that $\displaystyle \lim_{n \to \infty} \int_0^1 |f_n|\, =0$    and that there is an integrable function $g$ on [0,1] such that $|f_n|^2\leq g$ for all $n$. Show that $\displaystyle \lim_{n \to \infty} \int_0^1 |f_n|^2\, =0$. I think that I must show $\displaystyle \lim_{n \to \infty} \int_0^1 |f_n|\, = \displaystyle  \int_0^1 \lim_{n \to \infty}|f_n|$ , in other words I must show that we can take limit inside the integral.  What does $\displaystyle \lim_{n \to \infty} \int_0^1 |f_n|\, =0$ mean? Can you help me for this question? Thanks.","I have this question and I don't know how to proceed: Suppose that $(f_n)$ is a sequence of measurable functions on $[0,1]$ such that $\displaystyle \lim_{n \to \infty} \int_0^1 |f_n|\, =0$    and that there is an integrable function $g$ on [0,1] such that $|f_n|^2\leq g$ for all $n$. Show that $\displaystyle \lim_{n \to \infty} \int_0^1 |f_n|^2\, =0$. I think that I must show $\displaystyle \lim_{n \to \infty} \int_0^1 |f_n|\, = \displaystyle  \int_0^1 \lim_{n \to \infty}|f_n|$ , in other words I must show that we can take limit inside the integral.  What does $\displaystyle \lim_{n \to \infty} \int_0^1 |f_n|\, =0$ mean? Can you help me for this question? Thanks.",,['real-analysis']
6,Other references for Marstrand's density theorem,Other references for Marstrand's density theorem,,"I am currently working on topics closely correlated with Marstrand's density theorem (If the measure has a density, then the exponent of the density is an integer). I was reading together Preiss's article and De Lellis's notes but I realised that the proof of Mastrand theorem in De Lellis's note is wrong: The mistake is that at pg 27 the baricenter $b(r)$ cannot pass to blowup, since it has not been normalized properly. Does anyone know another (modern enough) reference which I can use to read the proof? Marstrand's paper uses quite an obsolete notation and it is very hard to follow. Thank you in advance","I am currently working on topics closely correlated with Marstrand's density theorem (If the measure has a density, then the exponent of the density is an integer). I was reading together Preiss's article and De Lellis's notes but I realised that the proof of Mastrand theorem in De Lellis's note is wrong: The mistake is that at pg 27 the baricenter $b(r)$ cannot pass to blowup, since it has not been normalized properly. Does anyone know another (modern enough) reference which I can use to read the proof? Marstrand's paper uses quite an obsolete notation and it is very hard to follow. Thank you in advance",,"['measure-theory', 'reference-request', 'geometric-measure-theory']"
7,Definition of Borel Measurable Sets,Definition of Borel Measurable Sets,,"My book defines a set $E \subseteq \Bbb{R}$ as Lebesgue measurable provided $m^*(A) = m^*(A \cap E) + m^*(A \cap E^C)$ for $A \subseteq \Bbb{R}$. What I am currently working on is trying to prove the equivalence of the following statemnets: (i) $\forall c \in \Bbb{R}$, $\{x \in E ~|~ f(x) > c \}$ is Borel measurable (ii) $\forall c \in \Bbb{R}$, $\{x \in E ~|~ f(x) \ge c \}$ is Borel measurable (iii) $\forall c \in \Bbb{R}$, $\{x \in E ~|~ f(x) < c \}$ is Borel measurable (iv) $\forall c \in \Bbb{R}$, $\{x \in E ~|~ f(x) \le c \}$ is Borel measurable My book defines what it means for a function to be Borel measurable (i.e., $f: E \to \Bbb{R}$ is Borel measurable provided $E$ is a Borel set, and $\{x \in E ~|~ f(x) > c \}$ is a Borel set for every $c \in \Bbb{R}$), but it furnishes no corresponding definition for what it means for a set to be Borel measurable. What does it mean for a set to be Borel measurable?","My book defines a set $E \subseteq \Bbb{R}$ as Lebesgue measurable provided $m^*(A) = m^*(A \cap E) + m^*(A \cap E^C)$ for $A \subseteq \Bbb{R}$. What I am currently working on is trying to prove the equivalence of the following statemnets: (i) $\forall c \in \Bbb{R}$, $\{x \in E ~|~ f(x) > c \}$ is Borel measurable (ii) $\forall c \in \Bbb{R}$, $\{x \in E ~|~ f(x) \ge c \}$ is Borel measurable (iii) $\forall c \in \Bbb{R}$, $\{x \in E ~|~ f(x) < c \}$ is Borel measurable (iv) $\forall c \in \Bbb{R}$, $\{x \in E ~|~ f(x) \le c \}$ is Borel measurable My book defines what it means for a function to be Borel measurable (i.e., $f: E \to \Bbb{R}$ is Borel measurable provided $E$ is a Borel set, and $\{x \in E ~|~ f(x) > c \}$ is a Borel set for every $c \in \Bbb{R}$), but it furnishes no corresponding definition for what it means for a set to be Borel measurable. What does it mean for a set to be Borel measurable?",,"['real-analysis', 'measure-theory', 'definition']"
8,Why isn't the approach of measurable functions (almost) duplicated in the approach to computable functions?,Why isn't the approach of measurable functions (almost) duplicated in the approach to computable functions?,,"Here are the definitions of computable .  There seems to be no direct analogy to measurable functions.  Why can't we make similar definitions to measurable (for computable )?  By that I mean, perhaps the set operations are exchanged for others or added to. For example.  Clearly any finite union of computable sets would also be computable, as well as the elementwise summation over the sets. I think computability should be about construction not decidability.  Then a set $A$ is computable in the traditional sense if $\chi_A$ is constructible.","Here are the definitions of computable .  There seems to be no direct analogy to measurable functions.  Why can't we make similar definitions to measurable (for computable )?  By that I mean, perhaps the set operations are exchanged for others or added to. For example.  Clearly any finite union of computable sets would also be computable, as well as the elementwise summation over the sets. I think computability should be about construction not decidability.  Then a set $A$ is computable in the traditional sense if $\chi_A$ is constructible.",,"['measure-theory', 'computer-science', 'computability', 'measurable-functions']"
9,Is Borel-field different from $\sigma$-field?,Is Borel-field different from -field?,\sigma,"My mathematical statistics book denotes $\sigma$-field as following: Let $\Bbb B$ be the collection of subsets of $\Bbb C$ where $\Bbb C$ denotes sample space which is the collection of all possible events. Then $\Bbb B$ is $\sigma$-field if (1) $\emptyset \in \Bbb B$ and $\exists b \in \Bbb B$ s.t. $\emptyset \subset b$ (2) $C \in \Bbb B \Rightarrow C^c\in \Bbb B $ where $C \in \Bbb C$ (3) $\{C_1, C_2, C_3..\} \in  \Bbb B \Rightarrow \cup_{i=1}^{\infty}C_i \in \Bbb B$ where $\{C_1, C_2, C_3..\}$ is countable collection of subsets of $\Bbb C$ Is this field a specific example of Borel Field? or this field is eqaully defined with Borel Field?","My mathematical statistics book denotes $\sigma$-field as following: Let $\Bbb B$ be the collection of subsets of $\Bbb C$ where $\Bbb C$ denotes sample space which is the collection of all possible events. Then $\Bbb B$ is $\sigma$-field if (1) $\emptyset \in \Bbb B$ and $\exists b \in \Bbb B$ s.t. $\emptyset \subset b$ (2) $C \in \Bbb B \Rightarrow C^c\in \Bbb B $ where $C \in \Bbb C$ (3) $\{C_1, C_2, C_3..\} \in  \Bbb B \Rightarrow \cup_{i=1}^{\infty}C_i \in \Bbb B$ where $\{C_1, C_2, C_3..\}$ is countable collection of subsets of $\Bbb C$ Is this field a specific example of Borel Field? or this field is eqaully defined with Borel Field?",,"['measure-theory', 'borel-sets']"
10,Why are pointwise measurable functions not measurable?,Why are pointwise measurable functions not measurable?,,"Let $(X,\mathcal{X})$, $(Y,\mathcal{Y})$ and $(Z,\mathcal{Z})$ be measurable spaces. Let $(X \times Y, \mathcal{X} \otimes \mathcal{Y})$ be the product of the two spaces, where $\mathcal{X} \otimes \mathcal{Y} := \sigma(\mathcal{X} \times \mathcal{Y})$. Let $f:X \times Y \to Z$ be a pointwise measurable function (my own term) in the sense that $\forall x \in X: f(x, \cdot):Y \to Z$ is measurable $\forall y \in Y: f(\cdot, y):X \to Z$ is measurable Sufficient conditions for separately measurable functions being jointly measurable. claims that $f:X \times Y \to Z$ is not necessarily measurable. Why? Is there a simple counter-example?","Let $(X,\mathcal{X})$, $(Y,\mathcal{Y})$ and $(Z,\mathcal{Z})$ be measurable spaces. Let $(X \times Y, \mathcal{X} \otimes \mathcal{Y})$ be the product of the two spaces, where $\mathcal{X} \otimes \mathcal{Y} := \sigma(\mathcal{X} \times \mathcal{Y})$. Let $f:X \times Y \to Z$ be a pointwise measurable function (my own term) in the sense that $\forall x \in X: f(x, \cdot):Y \to Z$ is measurable $\forall y \in Y: f(\cdot, y):X \to Z$ is measurable Sufficient conditions for separately measurable functions being jointly measurable. claims that $f:X \times Y \to Z$ is not necessarily measurable. Why? Is there a simple counter-example?",,"['measure-theory', 'measurable-functions']"
11,What the meaning of $\sigma$ (s) in $\sigma$-algebra?,What the meaning of  (s) in -algebra?,\sigma \sigma,"Why a mathematician write a ""s""/$\sigma$ in $\sigma$-algebra in place of another letter? Does it have anything to do with the word ""sum"", like $\Sigma$ or $\int$ for a sum?","Why a mathematician write a ""s""/$\sigma$ in $\sigma$-algebra in place of another letter? Does it have anything to do with the word ""sum"", like $\Sigma$ or $\int$ for a sum?",,"['measure-theory', 'math-history']"
12,"In Royden, a set $E$ is measurable iff $m(E \triangle U) < \epsilon$ where $U$ is a finite union of intervals","In Royden, a set  is measurable iff  where  is a finite union of intervals",E m(E \triangle U) < \epsilon U,"A set $E$ with $m(E) < \infty$ is measurable iff for all $\epsilon > 0$ there exists a finite union $U$ of intervals such that $m(E \triangle U) < \epsilon$. I am able to prove one way, i.e. $E$ measurable implies $m(E \triangle U) < \epsilon$, but have no insight on how to prove the other way.","A set $E$ with $m(E) < \infty$ is measurable iff for all $\epsilon > 0$ there exists a finite union $U$ of intervals such that $m(E \triangle U) < \epsilon$. I am able to prove one way, i.e. $E$ measurable implies $m(E \triangle U) < \epsilon$, but have no insight on how to prove the other way.",,"['measure-theory', 'lebesgue-measure']"
13,Measurability of a function with respect to the completion of a measure space,Measurability of a function with respect to the completion of a measure space,,"I would like some help with the following proof. Thanks for any help in advance. Let$(X,\mathscr M, \mu)$ be a measure space and $(X,\overline{\mathscr M}, \overline{\mu})$ its completion. Show, if $f:X\to \overline{\mathbb R}$ is a $\overline{\mathscr M}$-measurable function, then there is an $\mathscr M$-measurable function g such that $$\overline{\mu}\{x:f(x)\ne g(x)\}=0.$$ Edit: I have been given the following hint. I may wish to use the observation that, $f:X\to \overline{\mathbb R}$ is measurable if and only if $\{x : f(x) > q\}$ is measurable for every $q \in \mathbb{Q}$. Edit 2: As per Saz's request, here is a definition, If $(X,\mathscr M, \mu)$ has the property that F ∈$\mathscr M$ whenever $E \in \mathscr M$, ${\mu}(E) = 0$, and $F \subset E$, then $\mu$ is complete. Furthermore $\overline{\mathscr M}$ is defined to be the set $\{E\cup F \mid E \in \mathscr M, F \in N$ for some $N \in \mathscr N\}$ where $\mathscr N$ is defined to be the set $\{N \in \mathscr M \mid \bar{\mu}(E) =0\}$.","I would like some help with the following proof. Thanks for any help in advance. Let$(X,\mathscr M, \mu)$ be a measure space and $(X,\overline{\mathscr M}, \overline{\mu})$ its completion. Show, if $f:X\to \overline{\mathbb R}$ is a $\overline{\mathscr M}$-measurable function, then there is an $\mathscr M$-measurable function g such that $$\overline{\mu}\{x:f(x)\ne g(x)\}=0.$$ Edit: I have been given the following hint. I may wish to use the observation that, $f:X\to \overline{\mathbb R}$ is measurable if and only if $\{x : f(x) > q\}$ is measurable for every $q \in \mathbb{Q}$. Edit 2: As per Saz's request, here is a definition, If $(X,\mathscr M, \mu)$ has the property that F ∈$\mathscr M$ whenever $E \in \mathscr M$, ${\mu}(E) = 0$, and $F \subset E$, then $\mu$ is complete. Furthermore $\overline{\mathscr M}$ is defined to be the set $\{E\cup F \mid E \in \mathscr M, F \in N$ for some $N \in \mathscr N\}$ where $\mathscr N$ is defined to be the set $\{N \in \mathscr M \mid \bar{\mu}(E) =0\}$.",,['measure-theory']
14,Lebesgue differentiation theorem and surface measure,Lebesgue differentiation theorem and surface measure,,"I came across the following calculation ( Evans p.26 ) $$ \dots =  \lim_{t \to 0} \frac{1}{n \alpha(n)t^{n-1}} \int_{\partial B(x,t)}u(y) dS(y) \overset{\ast}{=} u(x), $$ for $u \in C^2(U)$, $U \subseteq R^n$ and $\alpha(n)$ the volume of the unit ball (i.e. $n\alpha(n)$ is the surface area of the unit sphere). I am trying to figure out the equality $\ast$. It looks like the Lebesgue differentiation theorem but Evans only mentions this for Balls $B(x,t)$ but not for spheres. When I try to write out the surface integral as an integral over an n-1-dimensional submanifold things get kind of confusing. Can you maybe share a reference or explain why the Lebesgue differentiation theorem holds for surface integrals? Based on the hints of  H. H. Rugh this could do the trick: $$  \frac{1}{n \alpha(n)t^{n-1}} \int_{\partial B(x,t)}u(y) dS(y)  = \left(\frac{1}{n \alpha(n)t^{n-1}} \int_{\partial B(x,t)} (u(y) - u(x))dS(y)\right)  + u(x) $$ Left to show is that $$\left(\frac{1}{n \alpha(n)t^{n-1}} \int_{\partial B(x,t)} (u(y) - u(x))dS(y)\right) \to 0 \quad\text{for}\quad t \to 0$$ which seems to be basically the same problem. Any suggestions?","I came across the following calculation ( Evans p.26 ) $$ \dots =  \lim_{t \to 0} \frac{1}{n \alpha(n)t^{n-1}} \int_{\partial B(x,t)}u(y) dS(y) \overset{\ast}{=} u(x), $$ for $u \in C^2(U)$, $U \subseteq R^n$ and $\alpha(n)$ the volume of the unit ball (i.e. $n\alpha(n)$ is the surface area of the unit sphere). I am trying to figure out the equality $\ast$. It looks like the Lebesgue differentiation theorem but Evans only mentions this for Balls $B(x,t)$ but not for spheres. When I try to write out the surface integral as an integral over an n-1-dimensional submanifold things get kind of confusing. Can you maybe share a reference or explain why the Lebesgue differentiation theorem holds for surface integrals? Based on the hints of  H. H. Rugh this could do the trick: $$  \frac{1}{n \alpha(n)t^{n-1}} \int_{\partial B(x,t)}u(y) dS(y)  = \left(\frac{1}{n \alpha(n)t^{n-1}} \int_{\partial B(x,t)} (u(y) - u(x))dS(y)\right)  + u(x) $$ Left to show is that $$\left(\frac{1}{n \alpha(n)t^{n-1}} \int_{\partial B(x,t)} (u(y) - u(x))dS(y)\right) \to 0 \quad\text{for}\quad t \to 0$$ which seems to be basically the same problem. Any suggestions?",,"['real-analysis', 'measure-theory', 'partial-differential-equations']"
15,An algebra (of sets) is a sigma algebra iff it is a monotone class,An algebra (of sets) is a sigma algebra iff it is a monotone class,,"Let $X$ be a set and $\mathcal{A}$ an algebra of sets of $X$. Show that $\mathcal{A}$ is a $\sigma$-algebra iff it is a monotone class. The fact that a $\sigma$-algebra is a monotone class is trivial; $\sigma$-algebras are closed under countable unions and intersections, so it is in particular closed under monotone limits. It is the converse that is troubling me. I would like to assume that any family of sets of $\mathcal{A}$ could be ordered under inclusion. Then this family can be written as an increasing chain of inclusions and the statement follows. But this seems like hand-waving, or simply false (since I do not particularly use the fact that $\mathcal{A}$ is an algebra). Any hints are appreciated.","Let $X$ be a set and $\mathcal{A}$ an algebra of sets of $X$. Show that $\mathcal{A}$ is a $\sigma$-algebra iff it is a monotone class. The fact that a $\sigma$-algebra is a monotone class is trivial; $\sigma$-algebras are closed under countable unions and intersections, so it is in particular closed under monotone limits. It is the converse that is troubling me. I would like to assume that any family of sets of $\mathcal{A}$ could be ordered under inclusion. Then this family can be written as an increasing chain of inclusions and the statement follows. But this seems like hand-waving, or simply false (since I do not particularly use the fact that $\mathcal{A}$ is an algebra). Any hints are appreciated.",,['real-analysis']
16,Interchanging of order summation in proposition 1.25 [Rudin RCA],Interchanging of order summation in proposition 1.25 [Rudin RCA],,"Hello! This proposition from Rudin's RCA book. One moment confuses me, namely how he interchanges the order of summation in that double infinite series? Can anyone give a rigorous explanation of it? EDIT: I know only that theorem from Rudin's PMA. Maybe we can apply it? I would be very grateful for comment/answer.","Hello! This proposition from Rudin's RCA book. One moment confuses me, namely how he interchanges the order of summation in that double infinite series? Can anyone give a rigorous explanation of it? EDIT: I know only that theorem from Rudin's PMA. Maybe we can apply it? I would be very grateful for comment/answer.",,"['real-analysis', 'measure-theory']"
17,Integral as a member of the closure of the convex hull of the integrand,Integral as a member of the closure of the convex hull of the integrand,,Suppose that $X$ is compact and metric and let $g:X\to\mathbb R$ be a Borel map. Let $\mu$ be a Borel probability measure on $X$. Then it seems that $\int_Xgd\mu$ is a member of the closure of the convex hull of $\{g(x):x\in X\}$ and I was wondering if anyone could provide a reference containing a proof of this result.,Suppose that $X$ is compact and metric and let $g:X\to\mathbb R$ be a Borel map. Let $\mu$ be a Borel probability measure on $X$. Then it seems that $\int_Xgd\mu$ is a member of the closure of the convex hull of $\{g(x):x\in X\}$ and I was wondering if anyone could provide a reference containing a proof of this result.,,"['integration', 'measure-theory', 'convex-analysis']"
18,Prove f is not measurable,Prove f is not measurable,,"Let $E$ be a non-measurable set contained in $(0,1)$. we will define $f(x) =x\textbf{1}_{E}(x) + x^3\textbf{1}_{E^C}(x)$ where $\textbf{1}_{E}(x)$ is the indicator function for the set $E$. Does $f$ is a measurable function? Answer: So I'm pretty sure the answer should be no, the function is not measurable. But I didn't succeed prove it formally, could anyone please help me prove it formally. Thanks.","Let $E$ be a non-measurable set contained in $(0,1)$. we will define $f(x) =x\textbf{1}_{E}(x) + x^3\textbf{1}_{E^C}(x)$ where $\textbf{1}_{E}(x)$ is the indicator function for the set $E$. Does $f$ is a measurable function? Answer: So I'm pretty sure the answer should be no, the function is not measurable. But I didn't succeed prove it formally, could anyone please help me prove it formally. Thanks.",,"['real-analysis', 'measure-theory']"
19,Lebesgue measure of numbers whose decimal representation contains at least one digit equal $9$,Lebesgue measure of numbers whose decimal representation contains at least one digit equal,9,"Let $A$ be the set of numbers on $[0, 1]$ whose decimal representation contains at least one digit equal $9$. What is its Lebesgue measure $\lambda(A)$?","Let $A$ be the set of numbers on $[0, 1]$ whose decimal representation contains at least one digit equal $9$. What is its Lebesgue measure $\lambda(A)$?",,"['measure-theory', 'lebesgue-measure', 'decimal-expansion']"
20,Measure theory qualifying exam questions,Measure theory qualifying exam questions,,"The following question is a qualifying exam question, though I don't see how these two parts are related. (a)Let $(X, \mathcal F, \mu)$ be a measure space with $\mu(X)=1$ and suppose $F_1 , F_2, ...F_7$ are 7 measurable sets with $\mu(F_j) \geq 1/2$. Show that there exist indices $i_1<i_2<i_3<i_4$ for which $F_{i_{1}} \cap F_{i_{2}} \cap F_{i_{3}} \cap F_{i_{4}} \neq \varnothing $. Thoughts: It seems this one is obvious I just suppose it's empty set then I can get a contradiction since the measure of the whole set is 1. I'm not sure whether it is the right track. (b) Let $m$ denote Lebesgue measure on $[0,1]$ and let $f_n \in L^1 (m)$ be nonnegative and measurable with $\int_{[0,1/n]} f_n dm \geq 1/2$ for all $n \geq 1$. Show that $\int_{[0,1/n]} [\sup_{n} f_n] m(dx)=\infty$. Thoughts: For this one, first I assume the integral of the sup is a finite number $M$ which is not infinity, then I can get the integral of the sup is going to zero,rather than $\geq 1/2$. I'm not sure about this idea either. Any comments would be appreciated. Edit: Thanks you guys. For (a), I'm wondering whether three sets also satifies the same result. I don't see why there always 4 such sets.","The following question is a qualifying exam question, though I don't see how these two parts are related. (a)Let $(X, \mathcal F, \mu)$ be a measure space with $\mu(X)=1$ and suppose $F_1 , F_2, ...F_7$ are 7 measurable sets with $\mu(F_j) \geq 1/2$. Show that there exist indices $i_1<i_2<i_3<i_4$ for which $F_{i_{1}} \cap F_{i_{2}} \cap F_{i_{3}} \cap F_{i_{4}} \neq \varnothing $. Thoughts: It seems this one is obvious I just suppose it's empty set then I can get a contradiction since the measure of the whole set is 1. I'm not sure whether it is the right track. (b) Let $m$ denote Lebesgue measure on $[0,1]$ and let $f_n \in L^1 (m)$ be nonnegative and measurable with $\int_{[0,1/n]} f_n dm \geq 1/2$ for all $n \geq 1$. Show that $\int_{[0,1/n]} [\sup_{n} f_n] m(dx)=\infty$. Thoughts: For this one, first I assume the integral of the sup is a finite number $M$ which is not infinity, then I can get the integral of the sup is going to zero,rather than $\geq 1/2$. I'm not sure about this idea either. Any comments would be appreciated. Edit: Thanks you guys. For (a), I'm wondering whether three sets also satifies the same result. I don't see why there always 4 such sets.",,"['real-analysis', 'measure-theory', 'lebesgue-integral', 'lebesgue-measure']"
21,Equivalence of definitions of measurable function: preimage of open set vs preimage of Borel set?,Equivalence of definitions of measurable function: preimage of open set vs preimage of Borel set?,,"Rudin defines a function from a measure space $X $ to a topological space $Y $ as measurable if the preimage of every open set in $Y $ is measurable in the measure space $X $. Now Wikipedia, and my books on probability, defines a function between two measure spaces $X $ and $Y $  as measurable if the preimage of every Borel set in $Y $ is measurable in $X $. Since the inverse image preserves set operations, one can easily see that the set of subsets of $Y $ such that $f^{-1 } $ is measurable in $X $ forms a $\sigma $ algebra $\Sigma  $ in $Y$. This implies $\Sigma \supset \mathcal B $, since $\Sigma $ contains all the opens sets. Can one show the opposite inclusion, so that the defintions are in fact equal? Thanks in advance!","Rudin defines a function from a measure space $X $ to a topological space $Y $ as measurable if the preimage of every open set in $Y $ is measurable in the measure space $X $. Now Wikipedia, and my books on probability, defines a function between two measure spaces $X $ and $Y $  as measurable if the preimage of every Borel set in $Y $ is measurable in $X $. Since the inverse image preserves set operations, one can easily see that the set of subsets of $Y $ such that $f^{-1 } $ is measurable in $X $ forms a $\sigma $ algebra $\Sigma  $ in $Y$. This implies $\Sigma \supset \mathcal B $, since $\Sigma $ contains all the opens sets. Can one show the opposite inclusion, so that the defintions are in fact equal? Thanks in advance!",,['measure-theory']
22,Inequalities like in Fatou's Lemma,Inequalities like in Fatou's Lemma,,"If $\{f_n\}$ is a sequence of non-negative Lebesgue measurable function on $\mathbb{R}$, $f_n\longrightarrow f$ a.e., then $\textbf{(1.) Fatous Lemma}: $ $\int \lim\inf f_n\leq \lim\inf \int f_n$. I want to see the importance of limit and infimum in the inequalities. Therefore, I would like to consider following natural questions: With the same hypothesis, do we have the following inequalities? $\textbf{(2.)}$ $\int \lim f_n \leq \lim\int f_n$ $\textbf{(3.)}$ $\int \inf f_n \leq \inf\int f_n$ Is the conclusion (1) stronger than (2) and (3)? If yes, how? (any example?)","If $\{f_n\}$ is a sequence of non-negative Lebesgue measurable function on $\mathbb{R}$, $f_n\longrightarrow f$ a.e., then $\textbf{(1.) Fatous Lemma}: $ $\int \lim\inf f_n\leq \lim\inf \int f_n$. I want to see the importance of limit and infimum in the inequalities. Therefore, I would like to consider following natural questions: With the same hypothesis, do we have the following inequalities? $\textbf{(2.)}$ $\int \lim f_n \leq \lim\int f_n$ $\textbf{(3.)}$ $\int \inf f_n \leq \inf\int f_n$ Is the conclusion (1) stronger than (2) and (3)? If yes, how? (any example?)",,['measure-theory']
23,How t show $f=g$ almost everywhere,How t show  almost everywhere,f=g,"How to show $f=g$ almost everywhere Let two real-valued measurable functions $f$ and $g$ be such that for any measurable set $E$ the integrals $\int_E f\,d\mu$  and  $\int_E g\,d\mu$ coincide. Could you please help. It seems obvious. we could define the integrals as charges. can we do sth from here. but I do not know how to approach.","How to show $f=g$ almost everywhere Let two real-valued measurable functions $f$ and $g$ be such that for any measurable set $E$ the integrals $\int_E f\,d\mu$  and  $\int_E g\,d\mu$ coincide. Could you please help. It seems obvious. we could define the integrals as charges. can we do sth from here. but I do not know how to approach.",,"['real-analysis', 'measure-theory', 'almost-everywhere']"
24,Proof that the predictable sigma algebra is also generated by continuous and adapted processes,Proof that the predictable sigma algebra is also generated by continuous and adapted processes,,"I'm reading George Lowther's blog and have a question about the proof of lemma 2. We want to verify that the predictable sigma algebra is also generated by the continuous and adapted processes. One direction is clear, for the other the idea is to write a left continuous process $X$ as the limit of a ccontinuous process. For this purpose he defines $$Y_t^n:=n\int_{t-\frac{1}{n}}^t\mathbf1_{|X_{s\vee 0}|\le n}X_{s\vee 0} ds$$ I've proved the following statement (see this question ). For $f:\mathbb{R}\to\mathbb{R}$ Borel, bounded the map $t\mapsto \int_{t-h}^tf(s)ds$ is lipschitz continuous. Assuming additionally left continuity of $f$ we have $$\lim_{h\downarrow 0}\frac{1}{h}\int_{t-h}^tf(s)ds=f(t)\tag{1}$$ $(1)$ implies the continuity of $Y^n_t$ and the convergence of $Y_t^n\to X_t$. This leads to the following two question: George Lowther writes $Y^n\to X$, what does this mean? I wonder why left-continuity is important comparing with right continuity. We can write $$\lim_{h\downarrow 0}\frac{1}{h}\int_{t}^{t+h}f(s)ds=f(t)\tag{1'}$$ if we assume $f$ to be right continuous. Hence we would conclude that the optional sigma algebra, which is generated by the right continuous and adapted processes is also generated by the continuous and adapted processes implying that the optional and predictable sigma algebra coincide. Therefore, I made a mistake in the right continuous case, but I can't see where. It would be appreciated if someone could explain what goes wrong in the right continuous case.","I'm reading George Lowther's blog and have a question about the proof of lemma 2. We want to verify that the predictable sigma algebra is also generated by the continuous and adapted processes. One direction is clear, for the other the idea is to write a left continuous process $X$ as the limit of a ccontinuous process. For this purpose he defines $$Y_t^n:=n\int_{t-\frac{1}{n}}^t\mathbf1_{|X_{s\vee 0}|\le n}X_{s\vee 0} ds$$ I've proved the following statement (see this question ). For $f:\mathbb{R}\to\mathbb{R}$ Borel, bounded the map $t\mapsto \int_{t-h}^tf(s)ds$ is lipschitz continuous. Assuming additionally left continuity of $f$ we have $$\lim_{h\downarrow 0}\frac{1}{h}\int_{t-h}^tf(s)ds=f(t)\tag{1}$$ $(1)$ implies the continuity of $Y^n_t$ and the convergence of $Y_t^n\to X_t$. This leads to the following two question: George Lowther writes $Y^n\to X$, what does this mean? I wonder why left-continuity is important comparing with right continuity. We can write $$\lim_{h\downarrow 0}\frac{1}{h}\int_{t}^{t+h}f(s)ds=f(t)\tag{1'}$$ if we assume $f$ to be right continuous. Hence we would conclude that the optional sigma algebra, which is generated by the right continuous and adapted processes is also generated by the continuous and adapted processes implying that the optional and predictable sigma algebra coincide. Therefore, I made a mistake in the right continuous case, but I can't see where. It would be appreciated if someone could explain what goes wrong in the right continuous case.",,"['measure-theory', 'stochastic-processes']"
25,a basic doubt on continuous image of a measurable set measurable,a basic doubt on continuous image of a measurable set measurable,,"Is continuous image (say the function is on $\Bbb R^n$) of a measurable set measurable ? Hint enough. Actually, $f: \Bbb R^n \to \Bbb R^n$ is given to be linear. I used some theorem to conclude that it is continuous.","Is continuous image (say the function is on $\Bbb R^n$) of a measurable set measurable ? Hint enough. Actually, $f: \Bbb R^n \to \Bbb R^n$ is given to be linear. I used some theorem to conclude that it is continuous.",,['measure-theory']
26,Beyond Calculus?? Integral Convergence using Measure Theory & Real Analysis,Beyond Calculus?? Integral Convergence using Measure Theory & Real Analysis,,$$ \mbox{Does}\quad \int_{\pi}^{\infty} {{\rm d}x \over x^{2}\sin^{2/3}\left(x\right)}\quad \mbox{diverge ?} $$ Is this problem suitable for a calculus class ?. I'm not sure exactly how to solve but I think it requires measure theory. Can someone lead me in the right direction ?.,$$ \mbox{Does}\quad \int_{\pi}^{\infty} {{\rm d}x \over x^{2}\sin^{2/3}\left(x\right)}\quad \mbox{diverge ?} $$ Is this problem suitable for a calculus class ?. I'm not sure exactly how to solve but I think it requires measure theory. Can someone lead me in the right direction ?.,,['real-analysis']
27,Prove that $f$ is constant almost everywhere.,Prove that  is constant almost everywhere.,f,"Let $f$ be a Lebesgue integrable function on $[0,1]$ such that for any $0 \leq a < b \leq 1$, $$\int^{\frac{a+b}{2}}_a f(x)dx = \int^b_{\frac{a+b}{2}} f(x)dx $$ Prove that $f$ is constant almost everywhere. Hints/ideas are appreciated, thanks","Let $f$ be a Lebesgue integrable function on $[0,1]$ such that for any $0 \leq a < b \leq 1$, $$\int^{\frac{a+b}{2}}_a f(x)dx = \int^b_{\frac{a+b}{2}} f(x)dx $$ Prove that $f$ is constant almost everywhere. Hints/ideas are appreciated, thanks",,"['real-analysis', 'measure-theory']"
28,Radon-Nikodym derivative vs standard derivative. Multivariable case,Radon-Nikodym derivative vs standard derivative. Multivariable case,,"For one dimensional case there is a nice connection of Radon-Nikodym derivative and ""classical"" derivative on real line. Is there some kind of analogy for higher dimensional cases?","For one dimensional case there is a nice connection of Radon-Nikodym derivative and ""classical"" derivative on real line. Is there some kind of analogy for higher dimensional cases?",,"['real-analysis', 'measure-theory']"
29,Convolution of functions with compact support,Convolution of functions with compact support,,"I have a question regarding convolution with compact support: Suppose $f \in L^1(\mathbb{R})$ and $g \in L^p(\mathbb{R})$, and both of them have compact support. Show that $f*g$ (convolution integral of $f$ and $g$) has compact support. Kindly advise in proceeding the working. Thank you.","I have a question regarding convolution with compact support: Suppose $f \in L^1(\mathbb{R})$ and $g \in L^p(\mathbb{R})$, and both of them have compact support. Show that $f*g$ (convolution integral of $f$ and $g$) has compact support. Kindly advise in proceeding the working. Thank you.",,"['measure-theory', 'convolution']"
30,Is the validity of measuring area by approximation an assumption of calculus?,Is the validity of measuring area by approximation an assumption of calculus?,,"The assumption that if you subdivide an area into more and more sub intervals, the approximation gets better and better. Has this been formally proved, or is it just intuition? Thanks!","The assumption that if you subdivide an area into more and more sub intervals, the approximation gets better and better. Has this been formally proved, or is it just intuition? Thanks!",,"['calculus', 'measure-theory', 'math-history', 'geometric-measure-theory']"
31,"$\mu(A) = 0 \;\;\; \Rightarrow \;\; \int_A f \,\, d\mu = 0$",,"\mu(A) = 0 \;\;\; \Rightarrow \;\; \int_A f \,\, d\mu = 0","I'm ashamed to have to ask this question... After poring over a few measure theory text books for the last couple of hours I still cannot figure out which theorem of ""standard"" measure theory, out of the bazillion theorems that these books give, justifies this stupefyingly obvious fact: $$\mu(A) = 0 \;\;\; \Rightarrow \;\; \int_A f \,\, d\mu = 0$$ Of course, I expect that some restrictions will need to be placed on the function $f$, and possibly on the measure $\mu$.  In fact, my interest in finding a formal statement of the theorem is to get some idea of how generally the above implication holds. (I figure that the above implication has to be true, at least for most functions $f$ one could care about, if for no other reason that any theory of measure for which this wasn't the case would be pretty worthless.  Therefore, I expect the above implication would lie very close to the basic definitions of the theory.  But the books on measure theory I have on hand use such elaborate apparatus to develop the theory, that it is impossible for me to discern through all the machinery the really fundamental facts like this one.)","I'm ashamed to have to ask this question... After poring over a few measure theory text books for the last couple of hours I still cannot figure out which theorem of ""standard"" measure theory, out of the bazillion theorems that these books give, justifies this stupefyingly obvious fact: $$\mu(A) = 0 \;\;\; \Rightarrow \;\; \int_A f \,\, d\mu = 0$$ Of course, I expect that some restrictions will need to be placed on the function $f$, and possibly on the measure $\mu$.  In fact, my interest in finding a formal statement of the theorem is to get some idea of how generally the above implication holds. (I figure that the above implication has to be true, at least for most functions $f$ one could care about, if for no other reason that any theory of measure for which this wasn't the case would be pretty worthless.  Therefore, I expect the above implication would lie very close to the basic definitions of the theory.  But the books on measure theory I have on hand use such elaborate apparatus to develop the theory, that it is impossible for me to discern through all the machinery the really fundamental facts like this one.)",,['measure-theory']
32,Prove that $m$ is ergodic.,Prove that  is ergodic.,m,"Let $X$ be a topological space, $f\colon X\rightarrow X$ be a function. Suppose that there exists a unique invariant Borel probability measure $m$. Prove that $m$ is ergodic. Thank you.","Let $X$ be a topological space, $f\colon X\rightarrow X$ be a function. Suppose that there exists a unique invariant Borel probability measure $m$. Prove that $m$ is ergodic. Thank you.",,"['measure-theory', 'ergodic-theory']"
33,Proof of Borel isomorphism theorem by Rao and Srivastava,Proof of Borel isomorphism theorem by Rao and Srivastava,,"Does someone know how Rao and Srivastava proved the Borel isomorphism theorem in their paper ""An elementary proof of the Borel isomorphism theorem"" published in 1995? I can't find anywhere this paper, neither a book or a pdf providing a proof, or even sketching it. Do you know a reference for that ? Thank you.","Does someone know how Rao and Srivastava proved the Borel isomorphism theorem in their paper ""An elementary proof of the Borel isomorphism theorem"" published in 1995? I can't find anywhere this paper, neither a book or a pdf providing a proof, or even sketching it. Do you know a reference for that ? Thank you.",,"['measure-theory', 'reference-request']"
34,The set of measurable subsets where two measures agree,The set of measurable subsets where two measures agree,,"From Nate Eldredge's reply Let $(\Omega, \mathcal{F})$ be a measurable space, and let $P,Q$ be two probability measures on $\mathcal{F}$.  It is a good exercise to verify that $$\mathcal{L} := \{ A \in \mathcal{F} : P(A) = Q(A) \}$$ is a $\lambda$-system.  (This is a common application of the $\pi$-$\lambda$ theorem : if one can show that $P$ and $Q$ agree on a $\pi$-system that generates $\mathcal{F}$, then $P$ and $Q$ must be the same.) I can't see and therefore was wondering how $L$ being a $\lambda$ system is an application of $\pi$-$\lambda$ theorem, i.e. $L$ being a $\lambda$ system can be proved from $\pi$-$\lambda$ theorem? In order for $L$ to be a $\lambda$ system, can $P$ and $Q$ be not necessarily probability measures, but $\sigma$-finite, or arbitrary? Thanks!","From Nate Eldredge's reply Let $(\Omega, \mathcal{F})$ be a measurable space, and let $P,Q$ be two probability measures on $\mathcal{F}$.  It is a good exercise to verify that $$\mathcal{L} := \{ A \in \mathcal{F} : P(A) = Q(A) \}$$ is a $\lambda$-system.  (This is a common application of the $\pi$-$\lambda$ theorem : if one can show that $P$ and $Q$ agree on a $\pi$-system that generates $\mathcal{F}$, then $P$ and $Q$ must be the same.) I can't see and therefore was wondering how $L$ being a $\lambda$ system is an application of $\pi$-$\lambda$ theorem, i.e. $L$ being a $\lambda$ system can be proved from $\pi$-$\lambda$ theorem? In order for $L$ to be a $\lambda$ system, can $P$ and $Q$ be not necessarily probability measures, but $\sigma$-finite, or arbitrary? Thanks!",,['measure-theory']
35,What can we tell about a sequence of measurable functions on a finite measure space such that $\sup_n \int_X |f_n(x)|^2 d\mu < \infty$?,What can we tell about a sequence of measurable functions on a finite measure space such that ?,\sup_n \int_X |f_n(x)|^2 d\mu < \infty,"I found this on a qualifier exam, and I think it will help me understand $L^p$ spaces better. Let $f_n$ be a sequence of measurable function on a finite measure space. Suppose that $$\sup_n \int_X |f_n(x)|^2 d\mu < \infty$$ and that $\lim_{n\to \infty}f_n(x) =: f(x)$ exists $\mu$-almost everywhere. Which of the following are true (proving or providing a counterexample): (1) $\int_X |f(x)|^2 d\mu < \infty$ (2) $ \int_X |f(x)| d\mu < \infty$ (3) $\lim_{n\to\infty} \int_X |f_n(x) - f(x)|^2 d\mu = 0$ (4) $\lim_{n\to\infty} \int_X |f_n(x) - f(x)| d\mu = 0$","I found this on a qualifier exam, and I think it will help me understand $L^p$ spaces better. Let $f_n$ be a sequence of measurable function on a finite measure space. Suppose that $$\sup_n \int_X |f_n(x)|^2 d\mu < \infty$$ and that $\lim_{n\to \infty}f_n(x) =: f(x)$ exists $\mu$-almost everywhere. Which of the following are true (proving or providing a counterexample): (1) $\int_X |f(x)|^2 d\mu < \infty$ (2) $ \int_X |f(x)| d\mu < \infty$ (3) $\lim_{n\to\infty} \int_X |f_n(x) - f(x)|^2 d\mu = 0$ (4) $\lim_{n\to\infty} \int_X |f_n(x) - f(x)| d\mu = 0$",,"['measure-theory', 'integration', 'convergence-divergence', 'lebesgue-integral']"
36,Prove convergence without Lebesgue theory,Prove convergence without Lebesgue theory,,"W. Rudin has the following exercise, ""to convince the reader of the power of Lebesgue integration"". Let $0 \leq f_n \leq 1$ be continuous functions from $[0,1]$ to $\mathbb R$, such that they converge pointwise to $0$. Prove that their integrals converge to $0$, without using any Lebesgue theory. How to do this?","W. Rudin has the following exercise, ""to convince the reader of the power of Lebesgue integration"". Let $0 \leq f_n \leq 1$ be continuous functions from $[0,1]$ to $\mathbb R$, such that they converge pointwise to $0$. Prove that their integrals converge to $0$, without using any Lebesgue theory. How to do this?",,['measure-theory']
37,On Lebesgue Outer Measure of an interval,On Lebesgue Outer Measure of an interval,,"We define the Lebesgue Outer Measure of an interval $[a,b]$ by $$\lambda([a,b])= \inf \left\{\sum_{j=1}^\infty |I_j|: [a,b]\subset \bigcup_{j=1}^{\infty} I_j\right\}$$ where $\{I_j\}$ is a sequence of open intervals that cover $[a,b]$, and we define the length of an open interval $|(a,b)|= b-a$. I want to show $\lambda([a,b])= b-a$ The proof of the book that I am using starts with the following: Let $\epsilon >0$. Because $$[a,b] \subset \left(a- \frac{\epsilon}{4}, b+ \frac{\epsilon}{4}\right) \cup \bigcup_{n=2}^\infty \left(- \frac{\epsilon}{2 \cdot 2^n},\frac{\epsilon}{2 \cdot 2^n}\right)$$, we obtain $\lambda([a,b]) < b-a +\epsilon$ which implies $\lambda([a,b])\le b-a$. I can understand $[a,b] \subset (a- \frac{\epsilon}{4}, b+ \frac{\epsilon}{4})$, but I do not get the part $\cup \bigcup_{n=2}^{\infty} (- \frac{\epsilon}{2 \cdot 2^n},\frac{\epsilon}{2 \cdot 2^n})$ Since $(a- \frac{\epsilon}{4}, b+ \frac{\epsilon}{4})$ already covers $[a,b]$, and I do not think that $\bigcup_{n=2}^{\infty} (- \frac{\epsilon}{2 \cdot 2^n},\frac{\epsilon}{2 \cdot 2^n})$ will necessarily cover an arbitrary closed interval $[a,b]$, so I do not really know why you need that union of arbitrary small intervals. (My guessing is that you add the countable union so that it coincides with the definition of Lebesgue outer measure) In addition, I do not know how can we arrive at the inequality $\lambda([a,b]) < b-a +\epsilon$. I do know that $b-a + \epsilon$ is essentially the length of $(a- \frac{\epsilon}{4}, b+ \frac{\epsilon}{4}) \cup \bigcup_{n=2}^{\infty} (- \frac{\epsilon}{2 \cdot 2^n},\frac{\epsilon}{2 \cdot 2^n})$ since I already computed it out. Taking the infimum of the length, we get $b-a$ and this is the outer measure (I think this statement should be wrong though) Sidenote: I have not officially encountered Lebesgue Measure yet. I encountered this outer measure thing when the book is trying to show function continuous a.e is Riemann-integrable. I really hope someone can shed some light since I have been puzzled by this the entire day.","We define the Lebesgue Outer Measure of an interval $[a,b]$ by $$\lambda([a,b])= \inf \left\{\sum_{j=1}^\infty |I_j|: [a,b]\subset \bigcup_{j=1}^{\infty} I_j\right\}$$ where $\{I_j\}$ is a sequence of open intervals that cover $[a,b]$, and we define the length of an open interval $|(a,b)|= b-a$. I want to show $\lambda([a,b])= b-a$ The proof of the book that I am using starts with the following: Let $\epsilon >0$. Because $$[a,b] \subset \left(a- \frac{\epsilon}{4}, b+ \frac{\epsilon}{4}\right) \cup \bigcup_{n=2}^\infty \left(- \frac{\epsilon}{2 \cdot 2^n},\frac{\epsilon}{2 \cdot 2^n}\right)$$, we obtain $\lambda([a,b]) < b-a +\epsilon$ which implies $\lambda([a,b])\le b-a$. I can understand $[a,b] \subset (a- \frac{\epsilon}{4}, b+ \frac{\epsilon}{4})$, but I do not get the part $\cup \bigcup_{n=2}^{\infty} (- \frac{\epsilon}{2 \cdot 2^n},\frac{\epsilon}{2 \cdot 2^n})$ Since $(a- \frac{\epsilon}{4}, b+ \frac{\epsilon}{4})$ already covers $[a,b]$, and I do not think that $\bigcup_{n=2}^{\infty} (- \frac{\epsilon}{2 \cdot 2^n},\frac{\epsilon}{2 \cdot 2^n})$ will necessarily cover an arbitrary closed interval $[a,b]$, so I do not really know why you need that union of arbitrary small intervals. (My guessing is that you add the countable union so that it coincides with the definition of Lebesgue outer measure) In addition, I do not know how can we arrive at the inequality $\lambda([a,b]) < b-a +\epsilon$. I do know that $b-a + \epsilon$ is essentially the length of $(a- \frac{\epsilon}{4}, b+ \frac{\epsilon}{4}) \cup \bigcup_{n=2}^{\infty} (- \frac{\epsilon}{2 \cdot 2^n},\frac{\epsilon}{2 \cdot 2^n})$ since I already computed it out. Taking the infimum of the length, we get $b-a$ and this is the outer measure (I think this statement should be wrong though) Sidenote: I have not officially encountered Lebesgue Measure yet. I encountered this outer measure thing when the book is trying to show function continuous a.e is Riemann-integrable. I really hope someone can shed some light since I have been puzzled by this the entire day.",,"['real-analysis', 'measure-theory']"
38,$p \leqslant q \leqslant r$. If $f \in L^p$ and $f \in L^r$ then $ f \in L^q$? [duplicate],. If  and  then ? [duplicate],p \leqslant q \leqslant r f \in L^p f \in L^r  f \in L^q,This question already has an answer here : Closed 11 years ago . Possible Duplicate: Proving an interpolation inequality Let $f \in L^p$ and $f \in L^r$ where $1 \leqslant p \leqslant r$ . Then can we say that $f \in L^q$ if $p \leqslant q \leqslant r$? ($f : \mathbb R^n \to \mathbb R$),This question already has an answer here : Closed 11 years ago . Possible Duplicate: Proving an interpolation inequality Let $f \in L^p$ and $f \in L^r$ where $1 \leqslant p \leqslant r$ . Then can we say that $f \in L^q$ if $p \leqslant q \leqslant r$? ($f : \mathbb R^n \to \mathbb R$),,"['real-analysis', 'measure-theory']"
39,Fatou's lemma and measurable sets,Fatou's lemma and measurable sets,,"I don't know how can I imply Fatou's lemma for any measurable sets $A_k$ , that is, $$\lambda(\liminf A_k)\le\liminf\lambda(A_k).$$ How can I prove it? And is there any example in $\mathbb R$ of sequence of measurable sets $A_k$ such that $A_k\subset[0,1]$ , $\lim\lambda(A_k)=1$ , but $\liminf A_k=\varnothing$ ? Thanks for your help!","I don't know how can I imply Fatou's lemma for any measurable sets , that is, How can I prove it? And is there any example in of sequence of measurable sets such that , , but ? Thanks for your help!","A_k \lambda(\liminf A_k)\le\liminf\lambda(A_k). \mathbb R A_k A_k\subset[0,1] \lim\lambda(A_k)=1 \liminf A_k=\varnothing","['real-analysis', 'measure-theory', 'measurable-sets']"
40,Tail sigma algebra and $\limsup$ of a sequence of subsets,Tail sigma algebra and  of a sequence of subsets,\limsup,"On a set $\Omega$, there is a sequence of sigma algebras $(\mathcal{F}_n)_{n \in \mathbb{N}}$. The tail sigma algebra of $(\mathcal{F}_n)$ is defined to be $\cap_{n=1}^{\infty} \sigma(\cup_{m=n}^\infty \mathcal{F}_m )$. I was wondering if the following two statements are true: $\forall B$ in the tail sigma algebra of $(\mathcal{F}_n)$, there exist $ A_n \in \mathcal{F}_n, \forall n \in \mathbb{N}$, such that $\limsup_n A_n = B$. $\forall A_n \in \mathcal{F}_n, \forall n \in \mathbb{N}$, $\limsup_n A_n$ is in the tail sigma algebra of $(\mathcal{F}_n)$. Actually @Did has somehow explained it in one earlier question of mine : The tail sigma-algebra is the sigma-algebra of sets $B$ such that, for   every integer $N$ one can build $B$ from the sets $A_n$ with $n\ge N$   only. For example the limsup/liminf of $(A_n)_n$ is also the   limsup/liminf of $(A_{n+N})_n$ hence the limsup/liminf is in the tail   sigma-algebra. But I don't quite understand it well in the hindsight: for any subset $B$ in the tail sigma algebra and any integer $N$,     how does one build $B$ from the sets $A_n \in \mathcal{F}_n$ with $n\ge N$? how does the above explain that $\limsup_n A_n$ is in the tail sigma    algebra of $(\mathcal{F}_n)$? Similar questions to the above two for relations: between $\sigma(\cup_{n=1}^{\infty} \cap_{m=n}^\infty \mathcal{F}_m )$ and $\liminf_n A_n$ for $A_n \in \mathcal{F}_n, \forall n \in \mathbb{N}$? between $\cap_{n=1}^{\infty} \sigma(\cup_{m=n}^\infty \mathcal{F}_m )$ and $\liminf_n A_n$ for $A_n \in \mathcal{F}_n, \forall n \in \mathbb{N}$? between $\sigma(\cup_{n=1}^{\infty} \cap_{m=n}^\infty \mathcal{F}_m )$ and $\limsup_n A_n$ for $A_n \in \mathcal{F}_n, \forall n \in \mathbb{N}$? Thanks and regards!","On a set $\Omega$, there is a sequence of sigma algebras $(\mathcal{F}_n)_{n \in \mathbb{N}}$. The tail sigma algebra of $(\mathcal{F}_n)$ is defined to be $\cap_{n=1}^{\infty} \sigma(\cup_{m=n}^\infty \mathcal{F}_m )$. I was wondering if the following two statements are true: $\forall B$ in the tail sigma algebra of $(\mathcal{F}_n)$, there exist $ A_n \in \mathcal{F}_n, \forall n \in \mathbb{N}$, such that $\limsup_n A_n = B$. $\forall A_n \in \mathcal{F}_n, \forall n \in \mathbb{N}$, $\limsup_n A_n$ is in the tail sigma algebra of $(\mathcal{F}_n)$. Actually @Did has somehow explained it in one earlier question of mine : The tail sigma-algebra is the sigma-algebra of sets $B$ such that, for   every integer $N$ one can build $B$ from the sets $A_n$ with $n\ge N$   only. For example the limsup/liminf of $(A_n)_n$ is also the   limsup/liminf of $(A_{n+N})_n$ hence the limsup/liminf is in the tail   sigma-algebra. But I don't quite understand it well in the hindsight: for any subset $B$ in the tail sigma algebra and any integer $N$,     how does one build $B$ from the sets $A_n \in \mathcal{F}_n$ with $n\ge N$? how does the above explain that $\limsup_n A_n$ is in the tail sigma    algebra of $(\mathcal{F}_n)$? Similar questions to the above two for relations: between $\sigma(\cup_{n=1}^{\infty} \cap_{m=n}^\infty \mathcal{F}_m )$ and $\liminf_n A_n$ for $A_n \in \mathcal{F}_n, \forall n \in \mathbb{N}$? between $\cap_{n=1}^{\infty} \sigma(\cup_{m=n}^\infty \mathcal{F}_m )$ and $\liminf_n A_n$ for $A_n \in \mathcal{F}_n, \forall n \in \mathbb{N}$? between $\sigma(\cup_{n=1}^{\infty} \cap_{m=n}^\infty \mathcal{F}_m )$ and $\limsup_n A_n$ for $A_n \in \mathcal{F}_n, \forall n \in \mathbb{N}$? Thanks and regards!",,"['measure-theory', 'limsup-and-liminf']"
41,About the smallest sigma field under certain conditions.,About the smallest sigma field under certain conditions.,,"Let $ (\Omega, \mathcal{F}) $ be a measurable space. Let $ A, B \in \mathcal {F} $ with $ A \cap B = \emptyset $.  Let $ \mathcal{A} \subset \mathcal{F} $ the smallest $ \sigma $-field containing $ A $ and not containing $ B $ and $ \mathcal {B} \subset \mathcal{F} $ the smallest $ \sigma $-field containing $ B $ and not containing $ A $. Is it true that $ \mathcal{F} $ is the smallest sigma algebra containing $ \mathcal {A} \cup \mathcal {B}$? And if $|\Omega|=\infty$ ? There is a counter example? Thank´s.","Let $ (\Omega, \mathcal{F}) $ be a measurable space. Let $ A, B \in \mathcal {F} $ with $ A \cap B = \emptyset $.  Let $ \mathcal{A} \subset \mathcal{F} $ the smallest $ \sigma $-field containing $ A $ and not containing $ B $ and $ \mathcal {B} \subset \mathcal{F} $ the smallest $ \sigma $-field containing $ B $ and not containing $ A $. Is it true that $ \mathcal{F} $ is the smallest sigma algebra containing $ \mathcal {A} \cup \mathcal {B}$? And if $|\Omega|=\infty$ ? There is a counter example? Thank´s.",,['measure-theory']
42,Necessary and sufficient conditions for $||f||_p = ||f||_q$ with $p \neq q$,Necessary and sufficient conditions for  with,||f||_p = ||f||_q p \neq q,"Let $0 < p < q \leq \infty$ and suppose $ E\subset \mathbb{R}^N$ with $m(E)=1$ (where $m$ is the Lebesgue measure). I am asked to find necessary and sufficient conditions for:  $$ ( \int_E{|f|}^pdx)^{1/p} = (\int_E{|f|}^qdx)^{1/q}$$  I know how to prove that that LHS $\leq$ RHS, this is done with Jensen's inequality in its measure-theoretic form, considering the function $\phi(t)=t^{q/p}$, which is convex, because $p<q$. This is how it works: $$(\int_E{|f|^pdx})^{q/p}=\phi(\int_E{|f|^p}dx) \leq \int_E{\phi(|f|^p)dx}= \int_E{|f|^qdx }$$ I was guessing that the necessary and sufficient condition required in the excercize is that $f(x) = 0$ almost everywhere (EDIT as observed in the comments, the condition is also satisfied if $f$ is such that $|f|$ is constant a.e.), but I'm stuck trying to prove it. I tried manipulating the exponents, but nothing seems to work; maybe some result on the inverse implication in Jensen's inequality could help, but I can't find any. I hope someone can point me in the right direction, thanks in advance!","Let $0 < p < q \leq \infty$ and suppose $ E\subset \mathbb{R}^N$ with $m(E)=1$ (where $m$ is the Lebesgue measure). I am asked to find necessary and sufficient conditions for:  $$ ( \int_E{|f|}^pdx)^{1/p} = (\int_E{|f|}^qdx)^{1/q}$$  I know how to prove that that LHS $\leq$ RHS, this is done with Jensen's inequality in its measure-theoretic form, considering the function $\phi(t)=t^{q/p}$, which is convex, because $p<q$. This is how it works: $$(\int_E{|f|^pdx})^{q/p}=\phi(\int_E{|f|^p}dx) \leq \int_E{\phi(|f|^p)dx}= \int_E{|f|^qdx }$$ I was guessing that the necessary and sufficient condition required in the excercize is that $f(x) = 0$ almost everywhere (EDIT as observed in the comments, the condition is also satisfied if $f$ is such that $|f|$ is constant a.e.), but I'm stuck trying to prove it. I tried manipulating the exponents, but nothing seems to work; maybe some result on the inverse implication in Jensen's inequality could help, but I can't find any. I hope someone can point me in the right direction, thanks in advance!",,"['real-analysis', 'measure-theory']"
43,"$f = 0$ outside a set of measure zero implies $\int_a^b f \, dx= 0$",outside a set of measure zero implies,"f = 0 \int_a^b f \, dx= 0","Let $f \colon [a,b] \to \mathbb R$ bounded, such that $f(x) = 0$ for every $x \in [a,b]$ except in a set $J$ of measure zero. When we say that a set $J$ has measure zero, if given any $\varepsilon  > 0$ there exist a countable collection of open intervals $( a_n ,b_n)$ such that $J \subset \bigcup\limits_{n \in \Bbb N} (a_n ,b_n)$ and $\sum \limits_{n \in {\Bbb N}} (b_n  - a_n) < \varepsilon$ . Prove that in the Riemann sense (I don't know any other sense of integrals) the integral exist and $$ \int_a^b f (x) \, dx = 0. $$ The existence is easy, but how can I prove the equality? Help me with this please. Don't use Lebesgue integrals, because I can't use it in this exercise. It's from a real analysis course. Thanks! I know that this result it's more general, Instead of putting $f(x) = 0$ , I can put any Riemann integrable function, but the general case, comes off as trivial corollary of this. So why try to prove this.","Let bounded, such that for every except in a set of measure zero. When we say that a set has measure zero, if given any there exist a countable collection of open intervals such that and . Prove that in the Riemann sense (I don't know any other sense of integrals) the integral exist and The existence is easy, but how can I prove the equality? Help me with this please. Don't use Lebesgue integrals, because I can't use it in this exercise. It's from a real analysis course. Thanks! I know that this result it's more general, Instead of putting , I can put any Riemann integrable function, but the general case, comes off as trivial corollary of this. So why try to prove this.","f \colon [a,b] \to \mathbb R f(x) = 0 x \in [a,b] J J \varepsilon  > 0 ( a_n ,b_n) J \subset \bigcup\limits_{n \in \Bbb N} (a_n ,b_n) \sum \limits_{n \in {\Bbb N}} (b_n  - a_n) < \varepsilon 
\int_a^b f (x) \, dx = 0.
 f(x) = 0","['real-analysis', 'measure-theory']"
44,$\sigma$-algebra for Lebesgue-Stieltjes Measure,-algebra for Lebesgue-Stieltjes Measure,\sigma,"If $f:\mathbb R \rightarrow \mathbb R$ is increasing and right continuous, one can define a measure $\mu_f$, the Lebesgue-Stieltjes measure induced by $f$, by setting $\mu_f(a,b] = f(b) - f(a)$ for half-open intervals $(a,b]$ then extending to a measure on the Borel $\sigma$-algebra by Caratheodory's theorem. In the special case where $f(x) = x$, one gets Lebesgue measure. In this case, the measure can be extended to the Lebesgue $\sigma$-algebra, which consists of unions of Borel sets and sets of Lebesgue measure zero. The same holds if $f$ is absolutely continuous. I am wondering whether the same holds for the Lebesgue-Stieltjes measure induced by functions $f$ which are not absolutely continuous. Can we always extend a Lebesgue-Stieltjes measure on $\mathbb R$ to the Lebesgue $\sigma$-algebra? To some $\sigma$-algebra which properly contains the Borel $\sigma$-algebra? I am particularly curious about singular continuous functions, like the Cantor-Lebesgue function.","If $f:\mathbb R \rightarrow \mathbb R$ is increasing and right continuous, one can define a measure $\mu_f$, the Lebesgue-Stieltjes measure induced by $f$, by setting $\mu_f(a,b] = f(b) - f(a)$ for half-open intervals $(a,b]$ then extending to a measure on the Borel $\sigma$-algebra by Caratheodory's theorem. In the special case where $f(x) = x$, one gets Lebesgue measure. In this case, the measure can be extended to the Lebesgue $\sigma$-algebra, which consists of unions of Borel sets and sets of Lebesgue measure zero. The same holds if $f$ is absolutely continuous. I am wondering whether the same holds for the Lebesgue-Stieltjes measure induced by functions $f$ which are not absolutely continuous. Can we always extend a Lebesgue-Stieltjes measure on $\mathbb R$ to the Lebesgue $\sigma$-algebra? To some $\sigma$-algebra which properly contains the Borel $\sigma$-algebra? I am particularly curious about singular continuous functions, like the Cantor-Lebesgue function.",,['measure-theory']
45,Integration by substitution explained from measure theory?,Integration by substitution explained from measure theory?,,"From Wikipedia : Let $U$ be a measurable subset of $\mathbb{R}^n$ and $\varphi : U \to  \mathbb{R}^n$ an injective function, and suppose for every $x$ in $U$   there exists $\varphi'(x)$ in $\mathbb{R}^{n,n}$ such that $\varphi(y) = \varphi(x) + \varphi'(x) (y − x) + o(||y − x||)$ as $y \to x$. Then $\varphi(U)$ is measurable, and for any real-valued function $f$   defined on $\varphi(U)$, $$      \int_{\varphi(U)} f(v)\, dv \;=\; \int_U f(\varphi(u)) \; \left|\det \varphi'(u)\right| \,du $$ in the sense that if either   integral exists (or is properly infinite), then so does the other one,   and they have the same value. Since I have learned the definition of Lebesgue integral, I have been trying to understand why  integration by substitution works from the view of measure theory. I admit that I still don't quite understand Jonas Meyer's excellent answer . But here is my current understanding (not sure if it is related to Jonas' answer), and hope it can be either finished in the same direction, or shown to be wrong: The integrals on both sides of the quoted equation are integrals wrt the Lebesgue measure $m$ on $\mathbb{R}^n$. Some extension $\varphi_e: \mathbb{R}^n \to \mathbb{R}^n$ extends $\varphi$ in such a way that it induces the Lebesgue measure $m$ on $\mathbb{R}^n$ from some measure $\mu$ on $\mathbb{R}^n$, i.e. $$m(A)=\mu(\varphi_e^{-1}(A)), \quad \forall A \in \mathcal{B}(\mathbb{R}^n).$$ So $$ \int_{\varphi(U)} f(v)\, dv \;=\; \int_U f(\varphi) \, d\mu $$ Then by some unknown proof , $\mu$ can be shown to be absolutely continuous wrt the Legesgue measure and its Radon-Nikodym derivative is $\left|\det \varphi'(u)\right|$ , i.e. $$\mu(A)=\int_A \left|\det \varphi'(u)\right| du, \quad \forall A \in \mathcal{B}(\mathbb{R}^n).$$ So $$ \int_{\varphi(U)} f(v)\, dv \;=\; \int_U f(\varphi) \, d\mu \;=\; \int_U f(\varphi(u)) \; \left|\det \varphi'(u)\right| \,du $$ I especially wonder if "" $\mu$ can be shown to be absolutely continuous wrt     the Legesgue measure and its Radon-Nikodym derivative is $\left|\det \varphi'(u)\right|$ "" can be justified not necessarily rigorously in more details? Or better, are there some texts that can help? Thanks and regards!","From Wikipedia : Let $U$ be a measurable subset of $\mathbb{R}^n$ and $\varphi : U \to  \mathbb{R}^n$ an injective function, and suppose for every $x$ in $U$   there exists $\varphi'(x)$ in $\mathbb{R}^{n,n}$ such that $\varphi(y) = \varphi(x) + \varphi'(x) (y − x) + o(||y − x||)$ as $y \to x$. Then $\varphi(U)$ is measurable, and for any real-valued function $f$   defined on $\varphi(U)$, $$      \int_{\varphi(U)} f(v)\, dv \;=\; \int_U f(\varphi(u)) \; \left|\det \varphi'(u)\right| \,du $$ in the sense that if either   integral exists (or is properly infinite), then so does the other one,   and they have the same value. Since I have learned the definition of Lebesgue integral, I have been trying to understand why  integration by substitution works from the view of measure theory. I admit that I still don't quite understand Jonas Meyer's excellent answer . But here is my current understanding (not sure if it is related to Jonas' answer), and hope it can be either finished in the same direction, or shown to be wrong: The integrals on both sides of the quoted equation are integrals wrt the Lebesgue measure $m$ on $\mathbb{R}^n$. Some extension $\varphi_e: \mathbb{R}^n \to \mathbb{R}^n$ extends $\varphi$ in such a way that it induces the Lebesgue measure $m$ on $\mathbb{R}^n$ from some measure $\mu$ on $\mathbb{R}^n$, i.e. $$m(A)=\mu(\varphi_e^{-1}(A)), \quad \forall A \in \mathcal{B}(\mathbb{R}^n).$$ So $$ \int_{\varphi(U)} f(v)\, dv \;=\; \int_U f(\varphi) \, d\mu $$ Then by some unknown proof , $\mu$ can be shown to be absolutely continuous wrt the Legesgue measure and its Radon-Nikodym derivative is $\left|\det \varphi'(u)\right|$ , i.e. $$\mu(A)=\int_A \left|\det \varphi'(u)\right| du, \quad \forall A \in \mathcal{B}(\mathbb{R}^n).$$ So $$ \int_{\varphi(U)} f(v)\, dv \;=\; \int_U f(\varphi) \, d\mu \;=\; \int_U f(\varphi(u)) \; \left|\det \varphi'(u)\right| \,du $$ I especially wonder if "" $\mu$ can be shown to be absolutely continuous wrt     the Legesgue measure and its Radon-Nikodym derivative is $\left|\det \varphi'(u)\right|$ "" can be justified not necessarily rigorously in more details? Or better, are there some texts that can help? Thanks and regards!",,"['real-analysis', 'integration', 'measure-theory']"
46,Can I build a finitely additive function on $\mathbb{Q}_p$?,Can I build a finitely additive function on ?,\mathbb{Q}_p,"This is partially motivated by a question I saw earlier here, Does such a finitely additive function exist? I've been reading about the topology of $\mathbb{Q}_p$ in Knapp's Advanced Algebra in Chapter 6, and I'm wondering if it's possible to impose a finitely additive function on $\mathbb{Q}_p$ in a natural way. By this I mean, suppose I take closed balls of form $$ B(x,r)=\{y\in\mathbb{Q}_p\mid|x-y|\leq p^{-r}\} $$ and let $\mathscr{B}$ be the set ring consisting of finite unions of such balls. I suspect there must also be a finitely additive function $\mu\colon\mathscr{B}\to\mathbb{R}^{+}$, the nonnegative reals, such that $\mu(B(x,r))=p^{-r}$, as one would expect naturally? In the case for $\mathbb{Q}$, such a function was constructed by first constructing a function which mapped a member of the set ring to its intersection with $\mathbb{Q}$. However, I view elements of $\mathbb{Q}_p$ as sequences in $\prod_{j=1}^\infty\mathbb{Q}$, so would their be some similar way of constructing such a function by first considering finite unions of such closed balls of sequences in $\prod_{j=1}^\infty\mathbb{R}$? And unlike the case in $\mathbb{Q}$, would it in fact be possible to extend $\mu$ to a unique measure on the generated $\sigma$-algebra of $\mathscr{B}$? Edit : Harry Altman's answer shows that the Haar measure is a measure which restricts back to this property. I guess I'm curious on how this would be built up. I mean, what would be the basic finitely additive function on $\mathscr{B}$ that could be uniquely extended to the Haar measure on the generated $\sigma$-algebra? Thank you for your considerations.","This is partially motivated by a question I saw earlier here, Does such a finitely additive function exist? I've been reading about the topology of $\mathbb{Q}_p$ in Knapp's Advanced Algebra in Chapter 6, and I'm wondering if it's possible to impose a finitely additive function on $\mathbb{Q}_p$ in a natural way. By this I mean, suppose I take closed balls of form $$ B(x,r)=\{y\in\mathbb{Q}_p\mid|x-y|\leq p^{-r}\} $$ and let $\mathscr{B}$ be the set ring consisting of finite unions of such balls. I suspect there must also be a finitely additive function $\mu\colon\mathscr{B}\to\mathbb{R}^{+}$, the nonnegative reals, such that $\mu(B(x,r))=p^{-r}$, as one would expect naturally? In the case for $\mathbb{Q}$, such a function was constructed by first constructing a function which mapped a member of the set ring to its intersection with $\mathbb{Q}$. However, I view elements of $\mathbb{Q}_p$ as sequences in $\prod_{j=1}^\infty\mathbb{Q}$, so would their be some similar way of constructing such a function by first considering finite unions of such closed balls of sequences in $\prod_{j=1}^\infty\mathbb{R}$? And unlike the case in $\mathbb{Q}$, would it in fact be possible to extend $\mu$ to a unique measure on the generated $\sigma$-algebra of $\mathscr{B}$? Edit : Harry Altman's answer shows that the Haar measure is a measure which restricts back to this property. I guess I'm curious on how this would be built up. I mean, what would be the basic finitely additive function on $\mathscr{B}$ that could be uniquely extended to the Haar measure on the generated $\sigma$-algebra? Thank you for your considerations.",,"['measure-theory', 'p-adic-number-theory']"
47,Number of distinct sets in a $\sigma$-algebra,Number of distinct sets in a -algebra,\sigma,"Let $F = \{E_1, E_2, ..., E_n\}$ be a collection of $n$ subsets of a set $X$, where $n$ is a positive integer. How many distinct sets could there be in $\sigma(F)$? Here are my thoughts: the largest that $\sigma(F)$ could be would be the power set of $F$, with $2^n$ elements. This doesn't satisfy me (and is probably wrong!) because a) our prof said that the answer is much larger than $2^n$, and b) this doesn't use the hypothesis about the sets $E_i$ in any way. How can I begin to wrap my head around this?","Let $F = \{E_1, E_2, ..., E_n\}$ be a collection of $n$ subsets of a set $X$, where $n$ is a positive integer. How many distinct sets could there be in $\sigma(F)$? Here are my thoughts: the largest that $\sigma(F)$ could be would be the power set of $F$, with $2^n$ elements. This doesn't satisfy me (and is probably wrong!) because a) our prof said that the answer is much larger than $2^n$, and b) this doesn't use the hypothesis about the sets $E_i$ in any way. How can I begin to wrap my head around this?",,['measure-theory']
48,"$\int_E f\, du= \int_E g\, du$ for all measurable $E$ implies $f=g$ a.e. and measurability of $E^+$ and $E^-$",for all measurable  implies  a.e. and measurability of  and,"\int_E f\, du= \int_E g\, du E f=g E^+ E^-","Hello I'm having trouble showing the following: Let $u$ be a positive measure. If $\int_E f\, du= \int_E g\, du$ for all measurable $E$ then $f=g$ a.e. I was trying to argue by contradiction: if $f\neq g$ a.e. then there must exist some set $E=\{x: f(x)\neq g(x)\}$ such that $u(E) \gt 0$. Then let $E^+=\{x: f(x)\gt g(x)\}$ and $E^-=\{x: f(x)\lt g(x)\}$. Now, if $E^+$ or $E^-$ is measurable and have positive measure then $\int_{E^+} f\, du \gt \int_{E^+} g\, du$ or $\int_{E^-} f\, du \lt \int_{E^-} g\, du$, contradiction. As you can see, the argument hinges on $E^+$ or $E^-$ being measurable. This is the part I'm having trouble with.","Hello I'm having trouble showing the following: Let $u$ be a positive measure. If $\int_E f\, du= \int_E g\, du$ for all measurable $E$ then $f=g$ a.e. I was trying to argue by contradiction: if $f\neq g$ a.e. then there must exist some set $E=\{x: f(x)\neq g(x)\}$ such that $u(E) \gt 0$. Then let $E^+=\{x: f(x)\gt g(x)\}$ and $E^-=\{x: f(x)\lt g(x)\}$. Now, if $E^+$ or $E^-$ is measurable and have positive measure then $\int_{E^+} f\, du \gt \int_{E^+} g\, du$ or $\int_{E^-} f\, du \lt \int_{E^-} g\, du$, contradiction. As you can see, the argument hinges on $E^+$ or $E^-$ being measurable. This is the part I'm having trouble with.",,"['integration', 'measure-theory']"
49,Measure from on product $\sigma$-algebra to on component $\sigma$-algebras,Measure from on product -algebra to on component -algebras,\sigma \sigma,"This is inspired by Carl Offner's reply to one of my previous questions and my previous question about marginal and joint measures . Given a measure $\mu$ on product $\sigma$-algebra $\prod_{i \in I} \mathbb{S}_i$ of a collection of measurable spaces $(X_i, \mathbb{S}_i), i \in I$, does there exist a measure $\mu_i$ on each component $\sigma$-algebra $\mathbb{S}_i$, s.t. their product $\prod_{i \in I} \mu_i$ is the given measure $\mu$ on the product $\sigma$-algebra? If no, what are some necessary and/or sufficient conditions for the given measure $\mu$ to have such a decomposition? When they exist, how to construct the component measures $\mu_i$ from $\mu$? For example, is this a viable way by defining  $$\mu_i(A_i):= \frac{\mu(A_i \times \prod_{j \in I, j\neq i} X_i)}{\prod_{j \in I, j\neq i} \mu_j(X_i)}, \forall A_i \in \mathbb{S}_i ?$$ If not, when will it become viable?  ADDED: I asked this question, because obviously, the product and the division may not make sense in some cases. Also I actually made a mistake of circular definition, where I define $\mu_i$ in terms of $\mu_j, j\neq i$ which have to be defined in similar ways. Thanks and regards!","This is inspired by Carl Offner's reply to one of my previous questions and my previous question about marginal and joint measures . Given a measure $\mu$ on product $\sigma$-algebra $\prod_{i \in I} \mathbb{S}_i$ of a collection of measurable spaces $(X_i, \mathbb{S}_i), i \in I$, does there exist a measure $\mu_i$ on each component $\sigma$-algebra $\mathbb{S}_i$, s.t. their product $\prod_{i \in I} \mu_i$ is the given measure $\mu$ on the product $\sigma$-algebra? If no, what are some necessary and/or sufficient conditions for the given measure $\mu$ to have such a decomposition? When they exist, how to construct the component measures $\mu_i$ from $\mu$? For example, is this a viable way by defining  $$\mu_i(A_i):= \frac{\mu(A_i \times \prod_{j \in I, j\neq i} X_i)}{\prod_{j \in I, j\neq i} \mu_j(X_i)}, \forall A_i \in \mathbb{S}_i ?$$ If not, when will it become viable?  ADDED: I asked this question, because obviously, the product and the division may not make sense in some cases. Also I actually made a mistake of circular definition, where I define $\mu_i$ in terms of $\mu_j, j\neq i$ which have to be defined in similar ways. Thanks and regards!",,['measure-theory']
50,Change the values of a measurable function on a negligible set,Change the values of a measurable function on a negligible set,,"If $f$ is a $\mu$-measurable function and I change its values on a $\mu$-negligible set, i.e. on $Y \subset Z$ with $\mu (Z) = 0$, why is $f$ still measurable?","If $f$ is a $\mu$-measurable function and I change its values on a $\mu$-negligible set, i.e. on $Y \subset Z$ with $\mu (Z) = 0$, why is $f$ still measurable?",,['measure-theory']
51,Typical applications of Fubini's theorem and Radon-Nikodym,Typical applications of Fubini's theorem and Radon-Nikodym,,"Can someone please share references (websites or books) where I can find problems related with Fubini's theorem and applications of Radon-Nikodym theorem? I have googled yes and don't find many problems. What are the ""typical"" problems (if there are any) related with these topics? [Yes, exam is coming soon so I don't know what to expect and don't have access to midterms from previous years]. Thank you","Can someone please share references (websites or books) where I can find problems related with Fubini's theorem and applications of Radon-Nikodym theorem? I have googled yes and don't find many problems. What are the ""typical"" problems (if there are any) related with these topics? [Yes, exam is coming soon so I don't know what to expect and don't have access to midterms from previous years]. Thank you",,['measure-theory']
52,Understanding proof of completeness of $L^{\infty}$ [closed],Understanding proof of completeness of  [closed],L^{\infty},"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 8 years ago . Improve this question I'm reading page number 4 here. In particular the section where it deals with the case $p=\infty$, that is , showing that $L^{\infty}$ is complete. http://www.core.org.cn/NR/rdonlyres/Mathematics/18-125Fall2003/5E3917E2-C212-463B-9EDB-671486133388/0/18125_lec15.pdf Two questions: 1) Why is the convergence uniform? where it says ""for $x \in N^{c}$ , $f_{n}$ is a Cauchy sequence of complex numbers. Thus $f_{n} \rightarrow f$ uniformly. Clearly we have pointwise convergence but why is it uniform? 2) I don't see why $||f_{n} - f||_{\infty} \rightarrow 0$. Can you please explain this step? Thanks. (3/2015) Edit: The original link appears to be broken. This document seems to provide a similar (maybe even identical) proof to the one the OP talks about with slight notational differences.","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 8 years ago . Improve this question I'm reading page number 4 here. In particular the section where it deals with the case $p=\infty$, that is , showing that $L^{\infty}$ is complete. http://www.core.org.cn/NR/rdonlyres/Mathematics/18-125Fall2003/5E3917E2-C212-463B-9EDB-671486133388/0/18125_lec15.pdf Two questions: 1) Why is the convergence uniform? where it says ""for $x \in N^{c}$ , $f_{n}$ is a Cauchy sequence of complex numbers. Thus $f_{n} \rightarrow f$ uniformly. Clearly we have pointwise convergence but why is it uniform? 2) I don't see why $||f_{n} - f||_{\infty} \rightarrow 0$. Can you please explain this step? Thanks. (3/2015) Edit: The original link appears to be broken. This document seems to provide a similar (maybe even identical) proof to the one the OP talks about with slight notational differences.",,['measure-theory']
53,Fatou's Lemma Counterexample,Fatou's Lemma Counterexample,,Give an example of sequence of Measurable functions defined on some measurable subset $E$ of $\mathbb{R}$  such that $f_{n} \to f$ pointwise almost everywhere on $E$ but $$\int\limits_{E} f \ dm \not\leq \lim_{n} \inf \int\limits_{E} f_{n} \ dm$$,Give an example of sequence of Measurable functions defined on some measurable subset $E$ of $\mathbb{R}$  such that $f_{n} \to f$ pointwise almost everywhere on $E$ but $$\int\limits_{E} f \ dm \not\leq \lim_{n} \inf \int\limits_{E} f_{n} \ dm$$,,[]
54,Measure of projection of a set is zero,Measure of projection of a set is zero,,"Suppose $S$ is measurable in $[0,1]^2$ and the orthogonal projection of $S$ onto the $x$ and $y$ axes has measure zero. Can the measure of the orthogonal projection of $S$ onto the line $y=x$ be positive? Each of these measures is the 1 dimensional Lebesgue measure. If we require just the $x$ axis projection to be zero, the answer is obviously ""no"" -- we can take the entire $y$ axis. The projection has measure $1/2$ .","Suppose is measurable in and the orthogonal projection of onto the and axes has measure zero. Can the measure of the orthogonal projection of onto the line be positive? Each of these measures is the 1 dimensional Lebesgue measure. If we require just the axis projection to be zero, the answer is obviously ""no"" -- we can take the entire axis. The projection has measure .","S [0,1]^2 S x y S y=x x y 1/2",['measure-theory']
55,"$\lim_{{n \to \infty}} \int_{{\frac{1}{n^2}}}^{{n}} (n^2x - 1)e^{-n^2x^2} \,dx$",,"\lim_{{n \to \infty}} \int_{{\frac{1}{n^2}}}^{{n}} (n^2x - 1)e^{-n^2x^2} \,dx","The limit of the integral is given $\lim_{{n \to \infty}} \int_{{\frac{1}{n^2}}}^{{n}} (n^2x - 1)e^{-n^2x^2} \,dx$ (a) Express the integral in the form $\int_0^\infty f_n(y) \, dy$ where $f_n(y)$ represents the general term of the sequence of functions. (b) Utilize the properties of the sequence of functions and apply either the Monotone Convergence Theorem or the Dominated Convergence Theorem to compute the given limit. Attempt: Introduce a new variable $t=nx$ : $\lim_{{n \to \infty}} \int_{{\frac{1}{n}}}^{{n^2}} (nt - 1)e^{-t^2} \,dt$ How do I continue? Can someone please share her/his solution :).",The limit of the integral is given (a) Express the integral in the form where represents the general term of the sequence of functions. (b) Utilize the properties of the sequence of functions and apply either the Monotone Convergence Theorem or the Dominated Convergence Theorem to compute the given limit. Attempt: Introduce a new variable : How do I continue? Can someone please share her/his solution :).,"\lim_{{n \to \infty}} \int_{{\frac{1}{n^2}}}^{{n}} (n^2x - 1)e^{-n^2x^2} \,dx \int_0^\infty f_n(y) \, dy f_n(y) t=nx \lim_{{n \to \infty}} \int_{{\frac{1}{n}}}^{{n^2}} (nt - 1)e^{-t^2} \,dt","['real-analysis', 'measure-theory', 'lebesgue-integral', 'lebesgue-measure']"
56,Continuum many reals with pairwise irrational difference,Continuum many reals with pairwise irrational difference,,"In ""Problems and Theorems in Classical Set Theory"" by Péter Komjáth and Vilmos Totik, in the Solutions to Chapter 30, they claim: ""It is easy to give continuum many reals with pairwise irrational difference"". However, I'm having a hard time constructing such a set. I've tried using an identification of $[0, 1]$ with $2^\omega$ and then constructing a subset of $2^\omega$ such that taking the bitwise difference results in a sequence that does not eventually repeat, meaning that the real number it corresponds to is not rational. However, I can't translate the bitwise difference operation on $2^\omega$ to the subtraction operation on $[0, 1]$ . Edit: I should note that in this chapter, the axiom of choice is explicitly not assumed","In ""Problems and Theorems in Classical Set Theory"" by Péter Komjáth and Vilmos Totik, in the Solutions to Chapter 30, they claim: ""It is easy to give continuum many reals with pairwise irrational difference"". However, I'm having a hard time constructing such a set. I've tried using an identification of with and then constructing a subset of such that taking the bitwise difference results in a sequence that does not eventually repeat, meaning that the real number it corresponds to is not rational. However, I can't translate the bitwise difference operation on to the subtraction operation on . Edit: I should note that in this chapter, the axiom of choice is explicitly not assumed","[0, 1] 2^\omega 2^\omega 2^\omega [0, 1]","['measure-theory', 'set-theory', 'real-numbers']"
57,The most explicit way of partitioning the reals into two dense subsets with positive measure,The most explicit way of partitioning the reals into two dense subsets with positive measure,,"In @UmbertoP's response to the question, "" Partition of real numbers into dense subsets of positive measure ,"" the answer is understandable to a advanced undergraduate; however, I have inadequate knowledge of measure and set theory. I tried to create a more explicit example here but it's too complicated. Question: Is there a more explicit version of Umberto P's answer that's understandable to an average undergraduate?","In @UmbertoP's response to the question, "" Partition of real numbers into dense subsets of positive measure ,"" the answer is understandable to a advanced undergraduate; however, I have inadequate knowledge of measure and set theory. I tried to create a more explicit example here but it's too complicated. Question: Is there a more explicit version of Umberto P's answer that's understandable to an average undergraduate?",,"['real-analysis', 'measure-theory', 'proof-explanation', 'real-numbers']"
58,"Almost uniform convergence, equivalent definition","Almost uniform convergence, equivalent definition",,"The definition of almost uniform convergence given by Bartle is this : $f_n$ is almost uniformly convergent if for each $\delta \gt 0 $ exist $E_{\delta}$ in $X$ with $\mu(E_{\delta}) \lt \delta$ such that $f_n$ converges uniformly to $f$ in $X$ \ $E_{\delta}$ Now, I am wondering if this definition is equivalent : $f_n$ is almost uniformly convergent iff $f_n$ converges uniformly to $f$ except for a set of measure zero. That is, the definition of almost everywhere convergence (but changing pointwise convergence for uniform convergence) Are these two definitions the same thing? Edit : Now, thinking a little more about this, what I am proposing is Egoroff Theorem, right? We need to add the hypothesis $\mu(X) \lt \infty$ , correct?","The definition of almost uniform convergence given by Bartle is this : is almost uniformly convergent if for each exist in with such that converges uniformly to in \ Now, I am wondering if this definition is equivalent : is almost uniformly convergent iff converges uniformly to except for a set of measure zero. That is, the definition of almost everywhere convergence (but changing pointwise convergence for uniform convergence) Are these two definitions the same thing? Edit : Now, thinking a little more about this, what I am proposing is Egoroff Theorem, right? We need to add the hypothesis , correct?",f_n \delta \gt 0  E_{\delta} X \mu(E_{\delta}) \lt \delta f_n f X E_{\delta} f_n f_n f \mu(X) \lt \infty,['measure-theory']
59,A question on properties of a limit function.,A question on properties of a limit function.,,"Suppose $f_n: A \rightarrow \mathbb{R^+}$ is an increasing sequence of measurable functions where $A \subseteq \mathbb{R}$ and suppose the sequence $ \left( \int_A f_n d \mu \right)_{n \in \mathbb{N}} $ is bounded. Let $ f : A \rightarrow [0 , \infty] $ be defined by $f(x) = \sup\{ f_n(x) \mid n \in \mathbb{N} \}$ . I want to show that $f_n \rightarrow f $ pointwise, and also I want to show that $f$ is finite almost everywhere. For the first bit, let $x \in A$ and let $\varepsilon > 0$ . If $f(x) = \infty$ then $\lim_{n \rightarrow \infty}f_n(x) = \infty$ . If not, then by definition of supremum there is $ n_0 \in \mathbb{N}$ such that $f(x) - \varepsilon < f_{n_0}(x).$ Since $f_n$ is increasing this gives $| f(x) - f_n(x) | < \varepsilon $ for all $n \geq n_0$ . Thus $f_n \rightarrow f$ pointwise. To show $f$ is finite almost everywhere, first I show that each $f_n$ is finite almost everywhere. Fix $n \in \mathbb{N}$ and for $j \in \mathbb{N}$ let $E_j = \{ x \in A \mid f_n(x) \geq j \}$ . Then from other results, we have that $\mu\left( E_j\right) \leq \frac{1}{j} \int_E f_n d \mu $ . By assumption $\int_A f_n d \mu $ is bounded and so $\lim_{j \rightarrow \infty}\mu(E_j) = 0$ . Note also that $f_n^{-1}\left( \{ \infty \} \right) = \bigcap_{j = 1}^\infty E_j$ . Since $(E_j)_{j \in \mathbb{N}}$ is decreasing and $\mu(E_1) < \infty$ , we have that $\mu\left( f_n^{-1}\left( \{ \infty \} \right) \right) = \mu\left( \bigcap_{j = 1}^\infty E_j \right) = \lim_{j \rightarrow \infty}\mu(E_j) = 0$ . Thus each $f_n$ is finite almost everywhere. And on this part I am stuck, not sure how to show that $f$ is also finite almost everywhere. I suspect I should have to use the fact the sequence $\left( \int_A f_n d \mu \right)_{n \in \mathbb{N}} $ is bounded.","Suppose is an increasing sequence of measurable functions where and suppose the sequence is bounded. Let be defined by . I want to show that pointwise, and also I want to show that is finite almost everywhere. For the first bit, let and let . If then . If not, then by definition of supremum there is such that Since is increasing this gives for all . Thus pointwise. To show is finite almost everywhere, first I show that each is finite almost everywhere. Fix and for let . Then from other results, we have that . By assumption is bounded and so . Note also that . Since is decreasing and , we have that . Thus each is finite almost everywhere. And on this part I am stuck, not sure how to show that is also finite almost everywhere. I suspect I should have to use the fact the sequence is bounded.","f_n: A \rightarrow \mathbb{R^+} A \subseteq \mathbb{R}  \left( \int_A f_n d \mu \right)_{n \in \mathbb{N}}   f : A \rightarrow [0 , \infty]  f(x) = \sup\{ f_n(x) \mid n \in \mathbb{N} \} f_n \rightarrow f  f x \in A \varepsilon > 0 f(x) = \infty \lim_{n \rightarrow \infty}f_n(x) = \infty  n_0 \in \mathbb{N} f(x) - \varepsilon < f_{n_0}(x). f_n | f(x) - f_n(x) | < \varepsilon  n \geq n_0 f_n \rightarrow f f f_n n \in \mathbb{N} j \in \mathbb{N} E_j = \{ x \in A \mid f_n(x) \geq j \} \mu\left( E_j\right) \leq \frac{1}{j} \int_E f_n d \mu  \int_A f_n d \mu  \lim_{j \rightarrow \infty}\mu(E_j) = 0 f_n^{-1}\left( \{ \infty \} \right) = \bigcap_{j = 1}^\infty E_j (E_j)_{j \in \mathbb{N}} \mu(E_1) < \infty \mu\left( f_n^{-1}\left( \{ \infty \} \right) \right) = \mu\left( \bigcap_{j = 1}^\infty E_j \right) = \lim_{j \rightarrow \infty}\mu(E_j) = 0 f_n f \left( \int_A f_n d \mu \right)_{n \in \mathbb{N}} ","['measure-theory', 'lebesgue-integral', 'lebesgue-measure']"
60,Weak Compactness Theorem for Borel Measures,Weak Compactness Theorem for Borel Measures,,"Weak convergence is defined as follows: The sequence $\{\mu_j\}$ of Borel measures on $\Bbb R^n$ converges weakly to a Borel measure $\mu$ if for all $f\in C_0(\Bbb R^n)$ , $$\int f d\mu_j \to \int f d\mu$$ After this, they state a certain weak compactness theorem , which is supposed to follow from the separability of $C_0(\Bbb R^n)$ . Theorem. Any sequence $\{\mu_j\}$ of Borel measures on $\Bbb R^n$ satisfying $$\sup_j \mu_j(\Bbb R^n) < \infty$$ has a weakly converging subsequence. I'm trying to prove the above theorem. Suppose $\{\mu_j\}$ is a sequence of Borel measures on $\Bbb R^n$ satisfying $\sup_j \mu_j(\Bbb R^n) < \infty$ . We must find a weakly convergent subsequence $\{\mu_{j_k}\}$ , i.e., $$\int fd\mu_{j_k} \xrightarrow{k\to\infty} \int f d\mu$$ for some Borel measure $\mu$ , and all $f\in C_0(\Bbb R^n)$ . I don't have much clue where to begin; could I please get any suggestions? Thanks a lot! Reference: Fourier Analysis and Hausdorff Dimension by Pertti Mattila.","Weak convergence is defined as follows: The sequence of Borel measures on converges weakly to a Borel measure if for all , After this, they state a certain weak compactness theorem , which is supposed to follow from the separability of . Theorem. Any sequence of Borel measures on satisfying has a weakly converging subsequence. I'm trying to prove the above theorem. Suppose is a sequence of Borel measures on satisfying . We must find a weakly convergent subsequence , i.e., for some Borel measure , and all . I don't have much clue where to begin; could I please get any suggestions? Thanks a lot! Reference: Fourier Analysis and Hausdorff Dimension by Pertti Mattila.",\{\mu_j\} \Bbb R^n \mu f\in C_0(\Bbb R^n) \int f d\mu_j \to \int f d\mu C_0(\Bbb R^n) \{\mu_j\} \Bbb R^n \sup_j \mu_j(\Bbb R^n) < \infty \{\mu_j\} \Bbb R^n \sup_j \mu_j(\Bbb R^n) < \infty \{\mu_{j_k}\} \int fd\mu_{j_k} \xrightarrow{k\to\infty} \int f d\mu \mu f\in C_0(\Bbb R^n),"['measure-theory', 'borel-sets', 'borel-measures']"
61,Radon-Nikodym derivative of pushforward of Lebesgue measure by differentiable function with respect to Lebesgue measure,Radon-Nikodym derivative of pushforward of Lebesgue measure by differentiable function with respect to Lebesgue measure,,"Here is the set up: $f:\mathbb{R}^n\to\mathbb{R}^m$ is a measurable function $\lambda^n$ is the $n$ -dimensional Lebesgue measure $f_*\lambda^n$ is the pushforward of $\lambda^n$ by $f$ $f_*\lambda^n \ll \lambda^m$ What do we know about the Radon-Nikodym derivative $$ \frac{d f_*\lambda^n}{d\lambda^m} $$ for different types of $f$ ? Notice this Radon-Nikodym derivative exists as long as $f_*\lambda^n$ and $\lambda^m$ are sigma-finite measures on the same space , which is true in this setup. Examples For instance, using the Change of Variables formula and Integration by Substitution when $f$ is a diffeomorphism , the Radon-Nikodym derivative is the absolute determinant Jacobian (see Billingsley ""Probability and Measure"", Theorem 17.2) $$ \frac{d f_*\lambda^n}{d\lambda^m} = |\det J_f|. $$ I have an intuition, based on this question, (but I have never seen it proven or mentioned anywhere) that when $f$ is simply differentiable , then the Radon-Nikodym derivative is the multidimensional Jacobian defined in Federer's ""Geometric Integration Theorem"" (Lemma 5.1.4) $$ \frac{d f_*\lambda^n}{d\lambda^m} = \begin{cases}     \mathcal{J}_n f(x) = |\det J_f(x)| && \text{ if } n = m \\     \mathcal{J}_n f(x) = \sqrt{\det J_f(x)^\top J_f(x)} && \text{ if } n \leq m \\     \mathcal{J}_m f(x) = \sqrt{\det J_f(x) J_f(x)^\top} && \text{ if } n \geq m \end{cases} $$ However I have no idea how to go about proving this.","Here is the set up: is a measurable function is the -dimensional Lebesgue measure is the pushforward of by What do we know about the Radon-Nikodym derivative for different types of ? Notice this Radon-Nikodym derivative exists as long as and are sigma-finite measures on the same space , which is true in this setup. Examples For instance, using the Change of Variables formula and Integration by Substitution when is a diffeomorphism , the Radon-Nikodym derivative is the absolute determinant Jacobian (see Billingsley ""Probability and Measure"", Theorem 17.2) I have an intuition, based on this question, (but I have never seen it proven or mentioned anywhere) that when is simply differentiable , then the Radon-Nikodym derivative is the multidimensional Jacobian defined in Federer's ""Geometric Integration Theorem"" (Lemma 5.1.4) However I have no idea how to go about proving this.","f:\mathbb{R}^n\to\mathbb{R}^m \lambda^n n f_*\lambda^n \lambda^n f f_*\lambda^n \ll \lambda^m 
\frac{d f_*\lambda^n}{d\lambda^m}
 f f_*\lambda^n \lambda^m f 
\frac{d f_*\lambda^n}{d\lambda^m} = |\det J_f|.
 f 
\frac{d f_*\lambda^n}{d\lambda^m} = \begin{cases}
    \mathcal{J}_n f(x) = |\det J_f(x)| && \text{ if } n = m \\
    \mathcal{J}_n f(x) = \sqrt{\det J_f(x)^\top J_f(x)} && \text{ if } n \leq m \\
    \mathcal{J}_m f(x) = \sqrt{\det J_f(x) J_f(x)^\top} && \text{ if } n \geq m
\end{cases}
","['measure-theory', 'multivariable-calculus', 'lebesgue-measure', 'jacobian', 'geometric-measure-theory']"
62,How do we use the dominated convergence theorem here? [duplicate],How do we use the dominated convergence theorem here? [duplicate],,"This question already has answers here : Royden's Lebesgue Integration 4.4 #34 (3 answers) Closed 2 years ago . Let $f$ be a nonegative measurable function on $\mathbb{R}$ . Show that \begin{equation} \boxed{\lim_{n \to \infty} \int_{-n}^{n} f=\int_{\mathbb{R}} f} \end{equation} This is from Royden 4th, chapter 4 #34. I know we can easily do this with the monotone convergence theorem, but what about the Dominated convergence theorem? The statement of the dominated convergence theorem states that the dominating function is integrable, and the obvious candidate for that function would just be $f$ since it clearly dominates $f\chi_{[-n,n]}$ . But we do not know that $\int_{\mathbb{R}}f$ has finite integral, so how can we use the theorem?","This question already has answers here : Royden's Lebesgue Integration 4.4 #34 (3 answers) Closed 2 years ago . Let be a nonegative measurable function on . Show that This is from Royden 4th, chapter 4 #34. I know we can easily do this with the monotone convergence theorem, but what about the Dominated convergence theorem? The statement of the dominated convergence theorem states that the dominating function is integrable, and the obvious candidate for that function would just be since it clearly dominates . But we do not know that has finite integral, so how can we use the theorem?","f \mathbb{R} \begin{equation}
\boxed{\lim_{n \to \infty} \int_{-n}^{n} f=\int_{\mathbb{R}} f}
\end{equation} f f\chi_{[-n,n]} \int_{\mathbb{R}}f",['measure-theory']
63,Measure given by $\nu(E)=\int_E gd\mu$. Want to prove $\int_\Omega fd\nu=\int_\Omega fgd\mu$,Measure given by . Want to prove,\nu(E)=\int_E gd\mu \int_\Omega fd\nu=\int_\Omega fgd\mu,"Define a measure $\nu$ given by $\nu(E)=\int_E gd\mu$ for all $E\subseteq\Omega$ measurable and for some measurable non-negative $g$ . Prove $\int_\Omega fd\nu=\int_\Omega fgd\mu$ . First step I proved this for simple functions, which was pretty straight-forward. Also, proving $\int_\Omega fgd\mu\geq\int_\Omega fd\nu$ for any measurable non-negative $f$ was easy too. It's the other inequality I'm having trouble with. Following definition, $\int_\Omega fgd\mu=\operatorname{Sup}\{\int_\Omega hd\nu:0\leq h\leq fg, \text{h simple}\}$ . Now, if I could say that $fg\geq h$ implies $f\geq \frac{h}{g}$ then solving it would be easy, but I can because it can be undefined. So I'm stuck. Any hint would be helpful.","Define a measure given by for all measurable and for some measurable non-negative . Prove . First step I proved this for simple functions, which was pretty straight-forward. Also, proving for any measurable non-negative was easy too. It's the other inequality I'm having trouble with. Following definition, . Now, if I could say that implies then solving it would be easy, but I can because it can be undefined. So I'm stuck. Any hint would be helpful.","\nu \nu(E)=\int_E gd\mu E\subseteq\Omega g \int_\Omega fd\nu=\int_\Omega fgd\mu \int_\Omega fgd\mu\geq\int_\Omega fd\nu f \int_\Omega fgd\mu=\operatorname{Sup}\{\int_\Omega hd\nu:0\leq h\leq fg, \text{h simple}\} fg\geq h f\geq \frac{h}{g}","['real-analysis', 'measure-theory', 'lebesgue-integral', 'lebesgue-measure', 'borel-measures']"
64,Frechet derivative of $\delta_{x(t)}$ is $\delta_{x'(t)}$?,Frechet derivative of  is ?,\delta_{x(t)} \delta_{x'(t)},"I don't really know anything about the Fréchet derivative but I was wondering if the Fréchet derivative of $\delta_{x(t)}$ was $\delta_{x'(t)}$ . More precisely, if we consider the Banach space $(\mathcal{M}(\mathbb{R}^d), \|\cdot\|_{\text{TV}})$ of signed measures with total variation norm, $t\mapsto x(t)$ is a smooth curve in $\mathbb{R}^d$ , and $\delta_{x(t)}$ the Dirac measure in the point $x(t)$ and consider the map \begin{align} \mathbb{R}\to&\mathcal{M}(\mathbb{R}^d)\\ t\mapsto& \delta_{x(t)} \end{align} I was wondering if this is Frechet differentiable and if like intuition suggest we have that it's Frechet derivative at point $t$ is $\delta_{x'(t)}$ . I think that what I have to verify is (is it?) that $$\frac{\|\delta_{x(t+h)}-\delta_{x(t)}-h\delta_{x'(t)}\|_{\text{TV}}}{|h|}\to0\text{ when }h\to 0$$","I don't really know anything about the Fréchet derivative but I was wondering if the Fréchet derivative of was . More precisely, if we consider the Banach space of signed measures with total variation norm, is a smooth curve in , and the Dirac measure in the point and consider the map I was wondering if this is Frechet differentiable and if like intuition suggest we have that it's Frechet derivative at point is . I think that what I have to verify is (is it?) that","\delta_{x(t)} \delta_{x'(t)} (\mathcal{M}(\mathbb{R}^d), \|\cdot\|_{\text{TV}}) t\mapsto x(t) \mathbb{R}^d \delta_{x(t)} x(t) \begin{align}
\mathbb{R}\to&\mathcal{M}(\mathbb{R}^d)\\
t\mapsto& \delta_{x(t)}
\end{align} t \delta_{x'(t)} \frac{\|\delta_{x(t+h)}-\delta_{x(t)}-h\delta_{x'(t)}\|_{\text{TV}}}{|h|}\to0\text{ when }h\to 0","['measure-theory', 'frechet-derivative']"
65,A real valued function defined on a Borel subset of $\mathbb{R}$ with a countable number of discontinuities is Borel measurable,A real valued function defined on a Borel subset of  with a countable number of discontinuities is Borel measurable,\mathbb{R},"I have proved the following statement and I would like to know if my proof is correct and/or/if/how it can be improved, thanks. ""Suppose $X$ is a Borel subset of $\mathbb{R}$ and $f:X\to\mathbb{R}$ is a function such that $\{x\in X: f\text{ is not continuous at }x\}$ is a countable set. Prove $f$ is a Borel measurable function."" My proof: ( EDIT: my proof is wrong in the case $\{x\in X: f\text{ is not continuous at }x\}$ is a countable set (a counterexample, as pointed out by Ramiro is the Thomae function) but it should work in the case $\{x\in X: f\text{ is not continuous at }x\}$ is finite ) Let $d_i, i\geq 1$ denote the points at which $f$ is discontinuous and fix $a\in\mathbb{R}$ ; if $x\in X$ and $f(x)>a$ then either $x=d_i$ for some $i\geq 1$ or $f$ is continuous at $x$ so if we set $\delta_x:=\frac{1}{2}\cdot\inf\{|x-d_i|:i\geq 1\}$ we have $f((x-\delta_x,x+\delta_x)\cap X)\subseteq (a,+\infty)$ (equivalently $(x-\delta_x,x+\delta_x)\cap X\subseteq f^{-1}((a,+\infty))$ being $f$ continuous in this whole set so $f^{-1}((a,+\infty))=\bigcup_{x\in f^{1}((a,+\infty)), x\neq d_i\forall i\geq 1} (x-\delta_x,x+\delta_x)\cap X\cup \{d_i:f(d_i)>a\}$ which being the union of two Borel sets ( $(x-\delta_x,x+\delta_x)$ is an open subset of $\mathbb{R}$ so it is Borel, $X$ is a Borel set by hypothesis so their intersection is Borel too and so is also their union and $\{d_i:f(d_i)>a\}$ is countable hence Borel too) is Borel. So, by LEMMA, we can conclude that $f$ is Borel-measurable, as desired. LEMMA. Suppose $(X,\mathcal{S})$ is a measurable space and $f:X\to\mathbb{R}$ is a function such that $f^{-1}((a,+\infty))\in\mathcal{S}$ for all $\in\mathbb{R}$ then $f$ is an $\mathcal{S}$ -measurable function. DEF. (measurable function) Suppose $(X,\mathcal{S})$ is a measurable space. A function $f:X\to\mathbb{R}$ is called $\mathcal{S}$ -measurable if $f^{-1}(B)\in\mathcal{S}$ for every Borel set $B\subset\mathbb{R}$ . DEF. (Borel-measurable function) Suppose $X\subset\mathbb{R}$ . A function $f:X\to\mathbb{R}$ is called Borel measurable if $f^{-1}(B)$ is a Borel set for every Borel set $B\subset\mathbb{R}$ .","I have proved the following statement and I would like to know if my proof is correct and/or/if/how it can be improved, thanks. ""Suppose is a Borel subset of and is a function such that is a countable set. Prove is a Borel measurable function."" My proof: ( EDIT: my proof is wrong in the case is a countable set (a counterexample, as pointed out by Ramiro is the Thomae function) but it should work in the case is finite ) Let denote the points at which is discontinuous and fix ; if and then either for some or is continuous at so if we set we have (equivalently being continuous in this whole set so which being the union of two Borel sets ( is an open subset of so it is Borel, is a Borel set by hypothesis so their intersection is Borel too and so is also their union and is countable hence Borel too) is Borel. So, by LEMMA, we can conclude that is Borel-measurable, as desired. LEMMA. Suppose is a measurable space and is a function such that for all then is an -measurable function. DEF. (measurable function) Suppose is a measurable space. A function is called -measurable if for every Borel set . DEF. (Borel-measurable function) Suppose . A function is called Borel measurable if is a Borel set for every Borel set .","X \mathbb{R} f:X\to\mathbb{R} \{x\in X: f\text{ is not continuous at }x\} f \{x\in X: f\text{ is not continuous at }x\} \{x\in X: f\text{ is not continuous at }x\} d_i, i\geq 1 f a\in\mathbb{R} x\in X f(x)>a x=d_i i\geq 1 f x \delta_x:=\frac{1}{2}\cdot\inf\{|x-d_i|:i\geq 1\} f((x-\delta_x,x+\delta_x)\cap X)\subseteq (a,+\infty) (x-\delta_x,x+\delta_x)\cap X\subseteq f^{-1}((a,+\infty)) f f^{-1}((a,+\infty))=\bigcup_{x\in f^{1}((a,+\infty)), x\neq d_i\forall i\geq 1} (x-\delta_x,x+\delta_x)\cap X\cup \{d_i:f(d_i)>a\} (x-\delta_x,x+\delta_x) \mathbb{R} X \{d_i:f(d_i)>a\} f (X,\mathcal{S}) f:X\to\mathbb{R} f^{-1}((a,+\infty))\in\mathcal{S} \in\mathbb{R} f \mathcal{S} (X,\mathcal{S}) f:X\to\mathbb{R} \mathcal{S} f^{-1}(B)\in\mathcal{S} B\subset\mathbb{R} X\subset\mathbb{R} f:X\to\mathbb{R} f^{-1}(B) B\subset\mathbb{R}","['real-analysis', 'measure-theory', 'solution-verification', 'measurable-functions', 'borel-sets']"
66,Finding $f$ s.t. the sequence of functions $f_n(x)=f (x − a_n )$ is not a.e. convergent to $f$,Finding  s.t. the sequence of functions  is not a.e. convergent to,f f_n(x)=f (x − a_n ) f,"The following is an exercise from Bruckner's Real Analysis : Let $a_n$ be any sequence of positive numbers converging to zero. If $f$ is continuous, then certainly $f (x − a_n)$ converges to $f (x)$ . Find a bounded measurable function on $[0, 1]$ such that the sequence of functions $f_n(x)=f (x − a_n )$ is not a.e. convergent to f [Hint: Take the characteristic function of a Cantor set of positive measure.] I don't understand how "" $f_n(x)=f (x − a_n )$ is not a.e. convergent to f"" can happen at all : $f (x − a_n )$ are 'moving' to become $f(x)$ as $n \to \infty$ and we only have a solution for not a.e. convergent to f when we consider any different $f$ that is not a.e. limit of $f_n$ ? So what is the use of fat Cantor sets here? Added - There should be an easy solution within the scope of Bruckner's book because when an exercise is hard and even still is at the book's level, it is always mentioned in a parenthesis ""This is hard"", but no notice for this exercise is.","The following is an exercise from Bruckner's Real Analysis : Let be any sequence of positive numbers converging to zero. If is continuous, then certainly converges to . Find a bounded measurable function on such that the sequence of functions is not a.e. convergent to f [Hint: Take the characteristic function of a Cantor set of positive measure.] I don't understand how "" is not a.e. convergent to f"" can happen at all : are 'moving' to become as and we only have a solution for not a.e. convergent to f when we consider any different that is not a.e. limit of ? So what is the use of fat Cantor sets here? Added - There should be an easy solution within the scope of Bruckner's book because when an exercise is hard and even still is at the book's level, it is always mentioned in a parenthesis ""This is hard"", but no notice for this exercise is.","a_n f f (x − a_n) f (x) [0, 1] f_n(x)=f (x − a_n ) f_n(x)=f (x − a_n ) f (x − a_n ) f(x) n \to \infty f f_n",['measure-theory']
67,"Measure, Integration & Real Analysis Sheldon Axler SEction 2B Exercise 12","Measure, Integration & Real Analysis Sheldon Axler SEction 2B Exercise 12",,"the question can be found here, but is also repeated below. Suppose $f:\mathbb{R}\rightarrow\mathbb{R}$ is a function. (a) For $k\in\mathbb{Z}^{+}$ , let $$G_k = \{a\in\mathbb{R}: \exists\delta>0 \text{ s.t. } \lvert f(b) - f(c)\rvert < \frac{1}{k}, \forall b,c\in(a-\delta, a+\delta\}.$$ Prove that $G_k$ is an open subset of $\mathbb{R}$ for each $k\in\mathbb{Z}^{+}$ . (b) Prove the set of points where $f$ is continuous equals $\cap_{k=1}^{\infty}G_{k}$ . (c) Conclude that the set of points at which $f$ is continuous is a Borel set. So, I'm really just looking for a help at where to start. I think that  I have an idea of where to set for (b) since the definition of $G_k$ is essentially just the definition of continuity using $\varepsilon_k = \frac{1}{k}$ , but I'm fairly lost on what to do for the other sections. Thank you!","the question can be found here, but is also repeated below. Suppose is a function. (a) For , let Prove that is an open subset of for each . (b) Prove the set of points where is continuous equals . (c) Conclude that the set of points at which is continuous is a Borel set. So, I'm really just looking for a help at where to start. I think that  I have an idea of where to set for (b) since the definition of is essentially just the definition of continuity using , but I'm fairly lost on what to do for the other sections. Thank you!","f:\mathbb{R}\rightarrow\mathbb{R} k\in\mathbb{Z}^{+} G_k = \{a\in\mathbb{R}: \exists\delta>0 \text{ s.t. } \lvert f(b) - f(c)\rvert < \frac{1}{k}, \forall b,c\in(a-\delta, a+\delta\}. G_k \mathbb{R} k\in\mathbb{Z}^{+} f \cap_{k=1}^{\infty}G_{k} f G_k \varepsilon_k = \frac{1}{k}","['real-analysis', 'measure-theory']"
68,Prove that $f$ is one-to-one on $B$ and $f^{-1}:Y\to B$ is Borel.,Prove that  is one-to-one on  and  is Borel.,f B f^{-1}:Y\to B,"Let $f: X\to Y$ be a continuous and surjective map between compact metric spaces. Prove that there is a Borel set $B\subset X$ such that $f(B)=Y$ , $f$ is one-to-one on $B$ and $f^{-1}:Y\to B$ is Borel. In other words, we can select from each of the sets $f^{-1}$ exactly one point in a way that the resulting inverse function is Borel. My attempt: For each $y \in Y$ we can pick one element $x_y \in f^{-1}(y)$ then have a collection $B'=\{x_y: y \in Y\}.$ Now $\{x_y\}$ is Borel. But we don't know $B'$ is Borel or not! Can we make it Borel? Even if we couldn't then we can take a finite or countable subcollection B or B' and that will be Borel and $f$ is 1-1 on $B$ but we are lacking $f(B)=Y$ . Please help me from here.","Let be a continuous and surjective map between compact metric spaces. Prove that there is a Borel set such that , is one-to-one on and is Borel. In other words, we can select from each of the sets exactly one point in a way that the resulting inverse function is Borel. My attempt: For each we can pick one element then have a collection Now is Borel. But we don't know is Borel or not! Can we make it Borel? Even if we couldn't then we can take a finite or countable subcollection B or B' and that will be Borel and is 1-1 on but we are lacking . Please help me from here.",f: X\to Y B\subset X f(B)=Y f B f^{-1}:Y\to B f^{-1} y \in Y x_y \in f^{-1}(y) B'=\{x_y: y \in Y\}. \{x_y\} B' f B f(B)=Y,"['real-analysis', 'measure-theory', 'lebesgue-measure', 'borel-sets', 'borel-measures']"
69,Doubts on application of continuity definition and Dominated Convergence theorem,Doubts on application of continuity definition and Dominated Convergence theorem,,"I quote Øksendal (2003) . Let $\mathcal{V}=\mathcal{V}(S,T)$ be the class of functions $f(t,\omega):[0,\infty)\times\Omega\to\mathbb{R}$ such that $(t,\omega)\to f(t,\omega)$ is $\mathcal{B}\times\mathcal{F}$ -measurable (where $\mathcal{B}$ denotes the Borel $\sigma$ -algebra on $[0,\infty)$ ), $f(t,\omega)$ is $\mathcal{F}_t$ -adapted and $\mathbb{E}\bigg[\int_{S}^T f(t,\omega)^2 dt\bigg]<\infty$ . [...] Recall that a function $\phi\in\mathcal{V}$ is called elementary if it has the form $$\phi(t,\omega)=\sum_j e_j(\omega)\cdot\chi_{[t_j, t_{j+1}]}(t)\tag{1}$$ [...] Statement Let $g\in\mathcal{V}$ be bounded and $g(\cdot,\omega)$ continuous for each $\omega$ . Then there exists elementary functions $\phi_n\in\mathcal{V}$ such that $$\mathbb{E}\left[\int_S^T\left(g-\phi_n\right)^2dt\right]\to 0\hspace{1.5cm}\text{as }n\to\infty\tag{2}$$ Proof Define $\phi_n(t,\omega)=\sum_j g(t_j,\omega)\cdot\chi_{[t_j,t_{j+1})}(t)$ . Then, $\phi_n$ is elementary since $g\in\mathcal{V}$ , and $$\int_S^T(g-\phi_n)^2dt\to0\hspace{1.5cm}\text{as }n\to\infty\text{ for each }\omega$$ since $g(\cdot,\omega)$ is continuous for each $\omega$ . Hence $\mathbb{E}\left[\int_S^T(g-\phi_n)^2dt\right]\to0$ as $n\to\infty$ by bounded convergence. My questions : Why does definition of continuity of $g(\cdot,\omega)$ imply that $$\displaystyle{\int_S^T(g-\phi_n)^2dt}\to0\hspace{1.5cm}\text{as }n\to\infty\text{ for each }\omega\hspace{3.5cm}\text{?}$$ My interpretation : I think I am allowed to conceive $\phi_n$ as a kind of step-function, whose value at time $t_n$ corresponds to the value of the continous and bounded function $g$ at time $t_n$ . Does that mean that if I shrink the differential of time $[t_j,t_{j+1})$ , continuity of $g$ implies that $|g-\phi_n|<\varepsilon\text{ for }|t_j-t_{j-1}|<\delta$ (which implies that $\displaystyle{\int_S^T(g-\phi_n)^2dt}\to0\hspace{0.5cm}\text{as }n\to\infty\text{ for each }\omega$ )? In the end, is Lebesgue's dominated convergence theorem applied? If so, why does it lead from $$\displaystyle{\int_S^T(g-\phi_n)^2dt}\to0\hspace{1cm}\text{as }n\to\infty\text{ for each }\omega$$ to $$\mathbb{E}\left[\displaystyle{\int_S^T(g-\phi_n)^2dt}\right]\to0\hspace{2.3cm}\text{as }n\to\infty\text{ for each }\omega\hspace{1.8cm}\text{ ?}$$ My interpretation : What I think is that one could set $X_n=(t_{j+1}-t_j)$ and $Y_n=\displaystyle{\int_S^T(g-\phi_n(t,\omega))^2}$ , which - as seen in my interpretation in point $1.$ - since $g$ is continuous, by definition of continuity, is such that for every $t$ , $|Y_n|<\epsilon$ whenever $|X_n|<\delta$ . In other words, $$g=\lim_{n\to\infty}\phi_n(t,\omega)\hspace{0.5cm}\text{ pointwise}\tag{3}$$ implies that $$0=\lim_{n\to\infty}\int_S^T(g-\phi_n(t,\omega))^2dt\hspace{0.5cm}\text{ pointwise}\tag{4}$$ Hence, given the immediately above explained conditions: $|Y_n|<\epsilon\text{ for every }t$ (namely, ""boundedness"" ), whenever $|X_n|<\delta$ ; $0=\lim\limits_{n\to\infty}\displaystyle{\int_S^T(g-\phi_n(t,\omega))^2dt}\hspace{0.5cm}\text{ pointwise}$ (namely, ""pointwise convergence"" ) one could apply Lebesgue's dominated convergence theorem : $$\lim_{n\to\infty}\mathbb{E}\left(Y_n\right)=\mathbb{E}\left(\lim_{n\to\infty}Y_n\right)=\mathbb{E}\left(0\right)=0$$ Are my interpretations of points $1.$ and $2.$ correct? If not, why?","I quote Øksendal (2003) . Let be the class of functions such that is -measurable (where denotes the Borel -algebra on ), is -adapted and . [...] Recall that a function is called elementary if it has the form [...] Statement Let be bounded and continuous for each . Then there exists elementary functions such that Proof Define . Then, is elementary since , and since is continuous for each . Hence as by bounded convergence. My questions : Why does definition of continuity of imply that My interpretation : I think I am allowed to conceive as a kind of step-function, whose value at time corresponds to the value of the continous and bounded function at time . Does that mean that if I shrink the differential of time , continuity of implies that (which implies that )? In the end, is Lebesgue's dominated convergence theorem applied? If so, why does it lead from to My interpretation : What I think is that one could set and , which - as seen in my interpretation in point - since is continuous, by definition of continuity, is such that for every , whenever . In other words, implies that Hence, given the immediately above explained conditions: (namely, ""boundedness"" ), whenever ; (namely, ""pointwise convergence"" ) one could apply Lebesgue's dominated convergence theorem : Are my interpretations of points and correct? If not, why?","\mathcal{V}=\mathcal{V}(S,T) f(t,\omega):[0,\infty)\times\Omega\to\mathbb{R} (t,\omega)\to f(t,\omega) \mathcal{B}\times\mathcal{F} \mathcal{B} \sigma [0,\infty) f(t,\omega) \mathcal{F}_t \mathbb{E}\bigg[\int_{S}^T f(t,\omega)^2 dt\bigg]<\infty \phi\in\mathcal{V} \phi(t,\omega)=\sum_j e_j(\omega)\cdot\chi_{[t_j, t_{j+1}]}(t)\tag{1} g\in\mathcal{V} g(\cdot,\omega) \omega \phi_n\in\mathcal{V} \mathbb{E}\left[\int_S^T\left(g-\phi_n\right)^2dt\right]\to 0\hspace{1.5cm}\text{as }n\to\infty\tag{2} \phi_n(t,\omega)=\sum_j g(t_j,\omega)\cdot\chi_{[t_j,t_{j+1})}(t) \phi_n g\in\mathcal{V} \int_S^T(g-\phi_n)^2dt\to0\hspace{1.5cm}\text{as }n\to\infty\text{ for each }\omega g(\cdot,\omega) \omega \mathbb{E}\left[\int_S^T(g-\phi_n)^2dt\right]\to0 n\to\infty g(\cdot,\omega) \displaystyle{\int_S^T(g-\phi_n)^2dt}\to0\hspace{1.5cm}\text{as }n\to\infty\text{ for each }\omega\hspace{3.5cm}\text{?} \phi_n t_n g t_n [t_j,t_{j+1}) g |g-\phi_n|<\varepsilon\text{ for }|t_j-t_{j-1}|<\delta \displaystyle{\int_S^T(g-\phi_n)^2dt}\to0\hspace{0.5cm}\text{as }n\to\infty\text{ for each }\omega \displaystyle{\int_S^T(g-\phi_n)^2dt}\to0\hspace{1cm}\text{as }n\to\infty\text{ for each }\omega \mathbb{E}\left[\displaystyle{\int_S^T(g-\phi_n)^2dt}\right]\to0\hspace{2.3cm}\text{as }n\to\infty\text{ for each }\omega\hspace{1.8cm}\text{ ?} X_n=(t_{j+1}-t_j) Y_n=\displaystyle{\int_S^T(g-\phi_n(t,\omega))^2} 1. g t |Y_n|<\epsilon |X_n|<\delta g=\lim_{n\to\infty}\phi_n(t,\omega)\hspace{0.5cm}\text{ pointwise}\tag{3} 0=\lim_{n\to\infty}\int_S^T(g-\phi_n(t,\omega))^2dt\hspace{0.5cm}\text{ pointwise}\tag{4} |Y_n|<\epsilon\text{ for every }t |X_n|<\delta 0=\lim\limits_{n\to\infty}\displaystyle{\int_S^T(g-\phi_n(t,\omega))^2dt}\hspace{0.5cm}\text{ pointwise} \lim_{n\to\infty}\mathbb{E}\left(Y_n\right)=\mathbb{E}\left(\lim_{n\to\infty}Y_n\right)=\mathbb{E}\left(0\right)=0 1. 2.","['measure-theory', 'convergence-divergence', 'continuity', 'proof-explanation', 'solution-verification']"
70,sigma-algebra generated by two-sigma algebras is generated by the intersection of sets from these two sigma-algebra,sigma-algebra generated by two-sigma algebras is generated by the intersection of sets from these two sigma-algebra,,"Let $\mathcal{G}$ and $\mathcal{H}$ be two $\sigma$ -algebras on a set $\Omega$ . Does it hold that $$\sigma(\mathcal{H},\mathcal{G}) = \sigma\{G\cap H: G\in\mathcal{G}, H\in \mathcal{H}\}?$$ How to prove it or disapprove it?",Let and be two -algebras on a set . Does it hold that How to prove it or disapprove it?,"\mathcal{G} \mathcal{H} \sigma \Omega \sigma(\mathcal{H},\mathcal{G}) = \sigma\{G\cap H: G\in\mathcal{G}, H\in \mathcal{H}\}?",['measure-theory']
71,why dominated convergence theorem is related to the superiority of Lebesgue integration (over Riemann integration)?,why dominated convergence theorem is related to the superiority of Lebesgue integration (over Riemann integration)?,,"I read the following paragraph from wikipedia: In measure theory, Lebesgue's dominated convergence theorem provides sufficient conditions under which almost everywhere convergence of a sequence of functions implies convergence in the $L^1$ norm. Its power and utility are two of the primary theoretical advantages of Lebesgue integration over Riemann integration. Can any one explain why the power of this theorem is the primary theoretical advantage of Lebesgue integration over Riemann? It would be great if you could illustrate with examples. Thanks!","I read the following paragraph from wikipedia: In measure theory, Lebesgue's dominated convergence theorem provides sufficient conditions under which almost everywhere convergence of a sequence of functions implies convergence in the norm. Its power and utility are two of the primary theoretical advantages of Lebesgue integration over Riemann integration. Can any one explain why the power of this theorem is the primary theoretical advantage of Lebesgue integration over Riemann? It would be great if you could illustrate with examples. Thanks!",L^1,"['measure-theory', 'lebesgue-integral', 'riemann-integration']"
72,Dominated convergence theorem for two integrals involving sine,Dominated convergence theorem for two integrals involving sine,,"I am stuck on some other problems in introductory measure theory on the convergence theorems (monotone convergence theorem and dominated convergence theorem). The exercise asks to compute the limit as $n\to\infty$ of the following integrals. $$(1)\quad\int_{(0,\infty)}\frac{\sin x}{x^2}\frac{x^{1/n}}{1+x^{1/n}}\,dx$$ $$(2)\quad \hspace{13pt}\int_{(0,\infty)} \frac{\sin (nx^n)}{nx^{n+\frac12}}\,dx$$ ( $1$ ) The monotone convergence theorem clearly doesn't apply since $\sin x$ changes sign on $(0,\infty)$ . My hope goes to the dominated convergence theorem. For all $x\in(0,\infty)$ , $\frac{x^{1/n}}{1+x^{1/n}}=\frac{1}{1+\frac{1}{x^{1/n}}}\xrightarrow{n\to\infty} \frac12$ , so by positivity it is bounded by $\frac12$ for all $x\in(0,\infty)$ and all $n$ . If I cut the integral into $\int_{0}^1$ and $\int_1^\infty$ , then the second part is easy. Indeed, for all $n$ and for all $x\in [1,\infty)$ , by the above remark $f_n(x)\xrightarrow{n\to\infty} \frac{\sin x}{2x^2}$ ; furthermore $|f_n(x)|\leqslant \frac{1}{2x^2}$ which is integrable, so this part follows by the dominated convergence theorem. However, I am stuck at what to do with $\int_0^1 f_n(x)\,dx$ , as I seem to keep the $x$ in the denominator which avoids integrability. I tried to use the inequality $\left\vert \frac{x^{1/n}}{1+x^{1/n}} \right\vert\leqslant \frac{1}{1+x}$ , but for the $\frac{\sin x}{x^2}$ term, the only inequality we can use is $\sin x\leqslant x$ and so we will always keep $x$ in the denominator. ( $2$ ) Here I have the same problem, $|\sin (nx^n)|\leqslant nx^{n}$ for all $x\in (0,\infty)$ and all $n$ , but then $\left\vert \frac{\sin (nx^n)}{nx^{n+\frac12}} \right\vert\leqslant \frac{nx^n}{nx^{n+\frac12}}=\frac{1}{x^{1/2}}$ , from where we have nowhere to go. I hope there is some slick trick I don't know about. Any help is welcome.","I am stuck on some other problems in introductory measure theory on the convergence theorems (monotone convergence theorem and dominated convergence theorem). The exercise asks to compute the limit as of the following integrals. ( ) The monotone convergence theorem clearly doesn't apply since changes sign on . My hope goes to the dominated convergence theorem. For all , , so by positivity it is bounded by for all and all . If I cut the integral into and , then the second part is easy. Indeed, for all and for all , by the above remark ; furthermore which is integrable, so this part follows by the dominated convergence theorem. However, I am stuck at what to do with , as I seem to keep the in the denominator which avoids integrability. I tried to use the inequality , but for the term, the only inequality we can use is and so we will always keep in the denominator. ( ) Here I have the same problem, for all and all , but then , from where we have nowhere to go. I hope there is some slick trick I don't know about. Any help is welcome.","n\to\infty (1)\quad\int_{(0,\infty)}\frac{\sin x}{x^2}\frac{x^{1/n}}{1+x^{1/n}}\,dx (2)\quad \hspace{13pt}\int_{(0,\infty)} \frac{\sin (nx^n)}{nx^{n+\frac12}}\,dx 1 \sin x (0,\infty) x\in(0,\infty) \frac{x^{1/n}}{1+x^{1/n}}=\frac{1}{1+\frac{1}{x^{1/n}}}\xrightarrow{n\to\infty} \frac12 \frac12 x\in(0,\infty) n \int_{0}^1 \int_1^\infty n x\in [1,\infty) f_n(x)\xrightarrow{n\to\infty} \frac{\sin x}{2x^2} |f_n(x)|\leqslant \frac{1}{2x^2} \int_0^1 f_n(x)\,dx x \left\vert \frac{x^{1/n}}{1+x^{1/n}} \right\vert\leqslant \frac{1}{1+x} \frac{\sin x}{x^2} \sin x\leqslant x x 2 |\sin (nx^n)|\leqslant nx^{n} x\in (0,\infty) n \left\vert \frac{\sin (nx^n)}{nx^{n+\frac12}} \right\vert\leqslant \frac{nx^n}{nx^{n+\frac12}}=\frac{1}{x^{1/2}}","['real-analysis', 'integration', 'measure-theory', 'definite-integrals']"
73,"If $G$ is a linear functional on $L^p$ given by $G(f)=\int fg \,d\mu$ for all $f \in L^p$, then $g \in L^q$","If  is a linear functional on  given by  for all , then","G L^p G(f)=\int fg \,d\mu f \in L^p g \in L^q","$\textbf{Problem.}$ Let $\frac{1}{p} +\frac{1}{q}=1 $ ,  and let $G$ be a linear functional on $L^p$ given by $$G(f)=\int fg \,d\mu $$ for all $f\in L^p$ . Show that $g\in L^q$ . I don't know that $g\in L^q$ holds for arbitrary measrue $\mu$ . If $\mu$ is $\sigma$ -finite and $fg\in L^1$ , I can prove that $g\in L^q$ . Also if $G$ is bounded, Riesz representation theorem implies that there exist such $g\in L^q$ . But I'm having a hard time to prove $G$ is bounded linear functional. My professor said that Use Hahn-Banach theorem. How can I use that theorem in this problem? Any help will be appreciated.","Let ,  and let be a linear functional on given by for all . Show that . I don't know that holds for arbitrary measrue . If is -finite and , I can prove that . Also if is bounded, Riesz representation theorem implies that there exist such . But I'm having a hard time to prove is bounded linear functional. My professor said that Use Hahn-Banach theorem. How can I use that theorem in this problem? Any help will be appreciated.","\textbf{Problem.} \frac{1}{p} +\frac{1}{q}=1  G L^p G(f)=\int fg \,d\mu  f\in L^p g\in L^q g\in L^q \mu \mu \sigma fg\in L^1 g\in L^q G g\in L^q G","['real-analysis', 'measure-theory']"
74,Does $\int\limits_\mathbb{R} f_n\ dm\to \int\limits_\mathbb{R} f\ dm$?,Does ?,\int\limits_\mathbb{R} f_n\ dm\to \int\limits_\mathbb{R} f\ dm,"Let $f_n$ be a sequence of measurable functions on $\mathbb{R}$ converging a.e. to $f$ . If $0\leq f_n\leq f$ a.e. Does it follow that $\displaystyle\int_\mathbb{R} f_n\ dm\to\displaystyle\int_\mathbb{R} f\ dm$ ? I think this is false but I can't think of any counterexample. Also, if I put another condition that $f_n$ is a sequence of integrable functions, does this imply that $f$ would also be integrable? Hence, the conclusion will hold by the Dominated Convergence Theorem? Thanks for any response.","Let be a sequence of measurable functions on converging a.e. to . If a.e. Does it follow that ? I think this is false but I can't think of any counterexample. Also, if I put another condition that is a sequence of integrable functions, does this imply that would also be integrable? Hence, the conclusion will hold by the Dominated Convergence Theorem? Thanks for any response.",f_n \mathbb{R} f 0\leq f_n\leq f \displaystyle\int_\mathbb{R} f_n\ dm\to\displaystyle\int_\mathbb{R} f\ dm f_n f,"['real-analysis', 'measure-theory', 'lebesgue-integral']"
75,Counterexample for the monotone convergence theorem,Counterexample for the monotone convergence theorem,,"Do you have a counterexample for the monotone convergence theorem when you omit the hypothesis that the sequence is increasing? I was thinking about the example where the sequence $f_n$ would approach $f$ as $\frac {\sin(x)} x$ do towards $0$ . It appears that the integrals are equal, isn't it? https://en.wikipedia.org/wiki/Monotone_convergence_theorem","Do you have a counterexample for the monotone convergence theorem when you omit the hypothesis that the sequence is increasing? I was thinking about the example where the sequence would approach as do towards . It appears that the integrals are equal, isn't it? https://en.wikipedia.org/wiki/Monotone_convergence_theorem",f_n f \frac {\sin(x)} x 0,"['real-analysis', 'integration', 'measure-theory', 'lebesgue-integral', 'lebesgue-measure']"
76,Wasserstein attains its infimum,Wasserstein attains its infimum,,"let $(\mathcal{X},d)$ be a Polish space. For $p\geq1$ let $\mathcal{P}_p(\mathcal{X})$ be the space of all Borel probability measures $\mu$ on $\mathcal{X}$ such that \begin{equation} \mathbb{E}_\mu\left[ d^p(X,x_0) \right]<\infty \end{equation} On this space we can define the Wasserstien distance (turns out to be a metric) as \begin{equation} W_{p}(\mu,\nu) =  \inf_{\pi \in \Pi(\mu,\nu)}\left(\int_{\mathcal{X}\times\mathcal{X}}d^p(x,y) \pi(dx,dy) \right)^{1/p}  \end{equation} where $\Pi(\mu,\nu)$ is the set of all probability measures on the space $\mathcal{X}\times \mathcal{X}$ with marginals $\mu$ and $\nu$ . Raginsky Sason 2014 Concentration of Measure Inequalities in Information Theory, Communications and coding, page 109, states that the inf is actually attained and therefore is a minimum. Does anyone know a proof for this? or point me in the direction of one? I cant seem to find it.","let be a Polish space. For let be the space of all Borel probability measures on such that On this space we can define the Wasserstien distance (turns out to be a metric) as where is the set of all probability measures on the space with marginals and . Raginsky Sason 2014 Concentration of Measure Inequalities in Information Theory, Communications and coding, page 109, states that the inf is actually attained and therefore is a minimum. Does anyone know a proof for this? or point me in the direction of one? I cant seem to find it.","(\mathcal{X},d) p\geq1 \mathcal{P}_p(\mathcal{X}) \mu \mathcal{X} \begin{equation}
\mathbb{E}_\mu\left[ d^p(X,x_0) \right]<\infty
\end{equation} \begin{equation}
W_{p}(\mu,\nu) =  \inf_{\pi \in \Pi(\mu,\nu)}\left(\int_{\mathcal{X}\times\mathcal{X}}d^p(x,y) \pi(dx,dy) \right)^{1/p} 
\end{equation} \Pi(\mu,\nu) \mathcal{X}\times \mathcal{X} \mu \nu","['measure-theory', 'optimization', 'concentration-of-measure', 'optimal-transport']"
77,Identifying a multiplicative measure,Identifying a multiplicative measure,,"I am trying to solve the next problem: Let $\mu:\mathcal{B}_{[0,1]}\rightarrow\mathbb{R}$ be a multiplicative measure, i.e. $$\int fg d\mu=\left(\int f d\mu\right)\left(\int g d\mu\right)$$ for all continuous $f,g:[0,1]\rightarrow\mathbb{R}.$ Identify $\mu.$ I was thinking in two possibly cases. One of them involves the Lebesgue measure and the other the trivial measure: If we consider the constant function $f=g=1$ we have $\mu([0,1])=\mu([0,1])^{2}$ so $\mu([0,1])=0$ or $\mu([0,1])=1.$ If $\mu([0,1])\neq 0,$ I'm not sure $\mu$ be the Lebesgue measure, because in general, for Lebesgue measure, doesn't satisfy the equality $\mu(A\cap B)=\mu(A)\mu(B).$ Also I was considering the case $f=g$ to get $\int f^2 d\mu=\left(\int f d\mu\right)^2$ but it seems a little useless. Any kind of help is thanked.","I am trying to solve the next problem: Let be a multiplicative measure, i.e. for all continuous Identify I was thinking in two possibly cases. One of them involves the Lebesgue measure and the other the trivial measure: If we consider the constant function we have so or If I'm not sure be the Lebesgue measure, because in general, for Lebesgue measure, doesn't satisfy the equality Also I was considering the case to get but it seems a little useless. Any kind of help is thanked.","\mu:\mathcal{B}_{[0,1]}\rightarrow\mathbb{R} \int fg d\mu=\left(\int f d\mu\right)\left(\int g d\mu\right) f,g:[0,1]\rightarrow\mathbb{R}. \mu. f=g=1 \mu([0,1])=\mu([0,1])^{2} \mu([0,1])=0 \mu([0,1])=1. \mu([0,1])\neq 0, \mu \mu(A\cap B)=\mu(A)\mu(B). f=g \int f^2 d\mu=\left(\int f d\mu\right)^2",['measure-theory']
78,"What to use for $\lim_{n\to \infty}\int_{[0,1]}\frac{n\sin{x}}{1+n^2\sqrt{x}}dx$",What to use for,"\lim_{n\to \infty}\int_{[0,1]}\frac{n\sin{x}}{1+n^2\sqrt{x}}dx","Determine $$\lim_{n\to \infty}\int_{[0,1]}\frac{n\sin{x}}{1+n^2\sqrt{x}}dx$$ I know the three convergence theorems, but to no avail: $1.$ Monotone Convergence: The series $f_{n}(x):=\frac{n\sin{x}}{1+n^2\sqrt{x}}$ is not monotonic increasing on $[0,1]$ , so the conditions are not met. $2.$ Fatou: Note: $\liminf_{n\to \infty}\int_{[0,1]}\frac{n\sin{x}}{1+n^2\sqrt{x}}dx\geq\int_{[0,1]}\liminf_{n\to \infty}\frac{n\sin{x}}{1+n^2\sqrt{x}}dx=0$ Which aids us no further. $3.$ Dominated Convergence Theorem: The only function $h$ to fulfill $|f_{n}|\leq h, \forall n \in \mathbb N$ that comes to mind is $|\frac{n\sin{x}}{1+n^2\sqrt{x}}|=\frac{n\sin{x}}{n^2\sqrt{x}}=\frac{\sin{x}}{n\sqrt{x}}\leq \frac{\sin{x}}{\sqrt{x}}=:h(x).$ But how do I show $h$ is $\in \mathcal{L}^1$ ? Is there anything I am missing? Any guidance is greatly appreciated.","Determine I know the three convergence theorems, but to no avail: Monotone Convergence: The series is not monotonic increasing on , so the conditions are not met. Fatou: Note: Which aids us no further. Dominated Convergence Theorem: The only function to fulfill that comes to mind is But how do I show is ? Is there anything I am missing? Any guidance is greatly appreciated.","\lim_{n\to \infty}\int_{[0,1]}\frac{n\sin{x}}{1+n^2\sqrt{x}}dx 1. f_{n}(x):=\frac{n\sin{x}}{1+n^2\sqrt{x}} [0,1] 2. \liminf_{n\to \infty}\int_{[0,1]}\frac{n\sin{x}}{1+n^2\sqrt{x}}dx\geq\int_{[0,1]}\liminf_{n\to \infty}\frac{n\sin{x}}{1+n^2\sqrt{x}}dx=0 3. h |f_{n}|\leq h, \forall n \in \mathbb N |\frac{n\sin{x}}{1+n^2\sqrt{x}}|=\frac{n\sin{x}}{n^2\sqrt{x}}=\frac{\sin{x}}{n\sqrt{x}}\leq \frac{\sin{x}}{\sqrt{x}}=:h(x). h \in \mathcal{L}^1","['real-analysis', 'measure-theory', 'convergence-divergence']"
79,How to find lower Riemann integral in given function?,How to find lower Riemann integral in given function?,,"$f(x)$ defined on $[0,1]$ as following - $$ \begin{align} f(x) = \begin{cases} 0 & \text{if $x=0$}\\ \frac{1}{n} & \text{if $1/(n+1)<x\le 1/n$} \end{cases} \end{align} $$ How to find lower Riemann integral of $f(x)$ from $0$ to $1$ . My question is different from How to find the Riemann integral of following function? Since we know $f(x)$ has countable number of discontinuities hence it is Riemann integrable and we can find it's upper integral for getting the answer .But how to find lower Riemann integral of this function ? EDIT -  I know since $f(x)$ is Riemann integrable hence it's lower Riemann integral is same as upper Riemann integral.But how to find it by partitioning the domain or in other words by using definition of lower Riemann integral.",defined on as following - How to find lower Riemann integral of from to . My question is different from How to find the Riemann integral of following function? Since we know has countable number of discontinuities hence it is Riemann integrable and we can find it's upper integral for getting the answer .But how to find lower Riemann integral of this function ? EDIT -  I know since is Riemann integrable hence it's lower Riemann integral is same as upper Riemann integral.But how to find it by partitioning the domain or in other words by using definition of lower Riemann integral.,"f(x) [0,1] 
\begin{align}
f(x) = \begin{cases}
0 & \text{if x=0}\\
\frac{1}{n} & \text{if 1/(n+1)<x\le 1/n}
\end{cases}
\end{align}
 f(x) 0 1 f(x) f(x)",['real-analysis']
80,Definition of measurability of $f:\Bbb R\to \Bbb R$,Definition of measurability of,f:\Bbb R\to \Bbb R,"Let $\cal B$ be the set of all Borel-measurable subsets of $\Bbb R$ and $\cal L$ be the set of all Lebesgue-measurable subsets of $\Bbb R$ . In measure theory texts, a function $f:\Bbb R\to \Bbb R$ is said to be measurable if for every $B\in \cal B$ , we have $f^{-1}(B)\in \cal L$ . Why is $\cal B$ used for range of the function. Why $\cal L$ is not used on both sides: a function $f:\Bbb R\to \Bbb R$ is said to be measurable if for every $L\in \cal L$ , we have $f^{-1}(L)\in \cal L$ ?","Let be the set of all Borel-measurable subsets of and be the set of all Lebesgue-measurable subsets of . In measure theory texts, a function is said to be measurable if for every , we have . Why is used for range of the function. Why is not used on both sides: a function is said to be measurable if for every , we have ?",\cal B \Bbb R \cal L \Bbb R f:\Bbb R\to \Bbb R B\in \cal B f^{-1}(B)\in \cal L \cal B \cal L f:\Bbb R\to \Bbb R L\in \cal L f^{-1}(L)\in \cal L,"['measure-theory', 'lebesgue-measure']"
81,The notion of limsup for sets,The notion of limsup for sets,,"I was working through The Borel-Cantelli lemma from Real Analysis problem book and ran into the following comment: Let $\{E_k\}_{k\geq1}$ is a countable family of measurable subsets of $\mathbb{R}^d$ and that $\sum \limits_{k=1}^{\infty}m(E_k)<\infty$. Let $$E=\{x\in \mathbb{R}^d: x\in E_k, \text{for  infinitely many} \ k\}=\limsup\limits_{k\to \infty}(E_k).$$ I know the notion of $\limsup$ and $\liminf$ for sequences from $[-\infty,+\infty]$. But here $E_k$ are sets (NOT numbers!). How did they get that $$\{x\in \mathbb{R}^d: x\in E_k, \text{for  infinitely many} \ k\}=\limsup\limits_{k\to \infty}(E_k)?$$ This equality seems to me quite weird. Would be very grateful for explanation! EDIT: Is there some essential difference between $\limsup$ of sequence of sets and reals?","I was working through The Borel-Cantelli lemma from Real Analysis problem book and ran into the following comment: Let $\{E_k\}_{k\geq1}$ is a countable family of measurable subsets of $\mathbb{R}^d$ and that $\sum \limits_{k=1}^{\infty}m(E_k)<\infty$. Let $$E=\{x\in \mathbb{R}^d: x\in E_k, \text{for  infinitely many} \ k\}=\limsup\limits_{k\to \infty}(E_k).$$ I know the notion of $\limsup$ and $\liminf$ for sequences from $[-\infty,+\infty]$. But here $E_k$ are sets (NOT numbers!). How did they get that $$\{x\in \mathbb{R}^d: x\in E_k, \text{for  infinitely many} \ k\}=\limsup\limits_{k\to \infty}(E_k)?$$ This equality seems to me quite weird. Would be very grateful for explanation! EDIT: Is there some essential difference between $\limsup$ of sequence of sets and reals?",,"['real-analysis', 'measure-theory', 'elementary-set-theory', 'limsup-and-liminf']"
82,Evaluating improper double integral with Lebesgue,Evaluating improper double integral with Lebesgue,,"Consider the improper double integral $$ I_{\text{Riemann}} = \int_0^1 \int_0^{\sqrt x} \frac{2xy}{1-y^4} \; dy \; dx = \lim_{B \to 1^-} \int_0^B \int_0^{\sqrt x} \frac{2xy}{1-y^4} \; dy \; dx .$$ The standard ""freshman calculus"" solution goes by swapping the order of integration to get $\int_0^1 \int_{y^2}^1 \frac{2xy}{1-y^4} \; dx \; dy$; then the inner integral is $\frac{y}{1-y^4} \int_{y^2}^1 2x \; dx = \frac{y}{1-y^4} \left[ x^2 \right]^1_{y^2} = y$ and the answer is $\int_0^1 y \; dy = \frac12$. I'm trying to make sense of this rigorously, particularly the bit about swapping the order of integration (which seems to require some sort of Tonelli/Fubini result). My idea is something like the following: define the double Lebesgue integral $$I_{\text{Lebesgue}} = \int_{x \in [0,1)} \int_{y \in [0,1)} \mathbf 1(x \ge y^2) \cdot \frac{2xy}{(1-y^4)} \; dy \; dx.$$ Then Tonelli's theorem lets us swap the order of summation to get $$I_{\text{Lebesgue}} = \int_{y \in [0,1)} \frac{y}{1-y^4} \int_{x \in [0,1)} \mathbf 1(x \ge y^2) \cdot 2x \; dx \; dy.$$ Thus the inner integral is the same as the Riemann one $\int_{y^2}^1 2x \; dx = 1 - y^4$, hence $$I_{\text{Lebesgue}} = \int_{y \in [0,1)} y \; dy = \frac12.$$ However, since the original Riemann integral was improper, I don't really know how to justify the first step (cue $x^{-1} \sin x$ example). So I have the following three questions: Is there some result/theorem that lets me quickly see that $I_{\text{Riemann}} = I_{\text{Lebesgue}}$? Bonus points for not using nonnegativity of $\frac{2xy}{1-y^4}$. Is the calculation of $I_{\text{Lebesgue}}$ correct as written? Are there other ways to justify the interchange of improper integrals? I'm fine appealing to Lebesgue since Lebesgue integrals are ""better-behaved"" anyways, but I'm wondering if I've missed something easier.","Consider the improper double integral $$ I_{\text{Riemann}} = \int_0^1 \int_0^{\sqrt x} \frac{2xy}{1-y^4} \; dy \; dx = \lim_{B \to 1^-} \int_0^B \int_0^{\sqrt x} \frac{2xy}{1-y^4} \; dy \; dx .$$ The standard ""freshman calculus"" solution goes by swapping the order of integration to get $\int_0^1 \int_{y^2}^1 \frac{2xy}{1-y^4} \; dx \; dy$; then the inner integral is $\frac{y}{1-y^4} \int_{y^2}^1 2x \; dx = \frac{y}{1-y^4} \left[ x^2 \right]^1_{y^2} = y$ and the answer is $\int_0^1 y \; dy = \frac12$. I'm trying to make sense of this rigorously, particularly the bit about swapping the order of integration (which seems to require some sort of Tonelli/Fubini result). My idea is something like the following: define the double Lebesgue integral $$I_{\text{Lebesgue}} = \int_{x \in [0,1)} \int_{y \in [0,1)} \mathbf 1(x \ge y^2) \cdot \frac{2xy}{(1-y^4)} \; dy \; dx.$$ Then Tonelli's theorem lets us swap the order of summation to get $$I_{\text{Lebesgue}} = \int_{y \in [0,1)} \frac{y}{1-y^4} \int_{x \in [0,1)} \mathbf 1(x \ge y^2) \cdot 2x \; dx \; dy.$$ Thus the inner integral is the same as the Riemann one $\int_{y^2}^1 2x \; dx = 1 - y^4$, hence $$I_{\text{Lebesgue}} = \int_{y \in [0,1)} y \; dy = \frac12.$$ However, since the original Riemann integral was improper, I don't really know how to justify the first step (cue $x^{-1} \sin x$ example). So I have the following three questions: Is there some result/theorem that lets me quickly see that $I_{\text{Riemann}} = I_{\text{Lebesgue}}$? Bonus points for not using nonnegativity of $\frac{2xy}{1-y^4}$. Is the calculation of $I_{\text{Lebesgue}}$ correct as written? Are there other ways to justify the interchange of improper integrals? I'm fine appealing to Lebesgue since Lebesgue integrals are ""better-behaved"" anyways, but I'm wondering if I've missed something easier.",,"['real-analysis', 'measure-theory', 'improper-integrals', 'lebesgue-integral']"
83,Vitali's Theorem for Convergence in Measure,Vitali's Theorem for Convergence in Measure,,"Show that Fatou's lemma, the Monotone Convergence Theorem, the Lebesgue Dominated Convergence Theorem, and the Vitali Convergence Theorem remain valid if ""pointwise convergence a.e."" is replaced by ""convergence in measure"" I have done every part except the part about Vitali's theorem. I tried a google search, but I couldn't find very much, so I am hoping the MSE community would be so kind as to critique my proof. For reference, here is the statement of Vitali's theorem with which I am working: Let $E$ be of finite measure. Suppose the sequence of functions $\{f_n\}$ is uniformly integrable over $E$. If $f_n \to f$ pointwise a.e. on $E$, then $f$ is integrable over $E$ and $$\lim_{n \to \infty} \int_E f_n = f$$. Here's my proof. First, I will show that $f$ is integrable. Given $\epsilon = 1$, by uniform integrability there exists $\delta > 0$ such that $A \subseteq E$ measurable with $m(A) < \delta$ implies $\int_A |f_n| < 1$ for every $n \in \Bbb{N}$. Given $\delta$, $E$ can be partitioned into measurable sets $E_1,...,E_k$ with $m(E_i) < \delta$. Hence $$\int_E |f_n| = \sum_{i=1}^k \int_{E_i} |f_n| < k,$$ for every $n \in \Bbb{N}$, and therefore $\liminf \int_{E} |f_n| \le \sup \int_E |f_n| \le k$. By Fatou's lemma for convergence in measure, $$\int_E |f| \le \liminf \int_{E} |f_n| \le k < \infty.$$ Now we prove the limit part. Again, by Fatou's lemma for convergence in measure, we get $\int_E f \le \liminf \int_E f_n$. Note that there exists a subsequence $\{f_{n_k}\}$ for which $$\lim_{k \to \infty} f_{n_k} = \limsup f_n.$$ Since $f_{n_k} \to f$ in measure, there exists a subsequence $\{f_{n_{k_m}}\}$ such that $f_{n_{k_m}} \to f$ pointwise a.e. on $E$. Since $\{f_n\}$ is UI, $\{f_{n_{k_m}}\}$ will also be UI. Hence by Vitali's theorem for pointwise covergence $$\lim_{m \to \infty} \int_E f_{n_{k_m}} = \int_E f .$$ Since $\{\int_E f_{n_{k_m}}\}$ is a subsequence of $\{\int_E f_{n_k}\}$, it must be the case that $$\lim_{m \to \infty} \int_E f_{n_{k_m}} = \limsup \int_E f_n,$$ and therefore $\limsup \int_E f_n = \int_E f \le \liminf \int_E f_n$ which implies $$\lim_{n \to \infty} \int_E f_n = \int_E f$$ $\blacksquare$ Does this sound right?","Show that Fatou's lemma, the Monotone Convergence Theorem, the Lebesgue Dominated Convergence Theorem, and the Vitali Convergence Theorem remain valid if ""pointwise convergence a.e."" is replaced by ""convergence in measure"" I have done every part except the part about Vitali's theorem. I tried a google search, but I couldn't find very much, so I am hoping the MSE community would be so kind as to critique my proof. For reference, here is the statement of Vitali's theorem with which I am working: Let $E$ be of finite measure. Suppose the sequence of functions $\{f_n\}$ is uniformly integrable over $E$. If $f_n \to f$ pointwise a.e. on $E$, then $f$ is integrable over $E$ and $$\lim_{n \to \infty} \int_E f_n = f$$. Here's my proof. First, I will show that $f$ is integrable. Given $\epsilon = 1$, by uniform integrability there exists $\delta > 0$ such that $A \subseteq E$ measurable with $m(A) < \delta$ implies $\int_A |f_n| < 1$ for every $n \in \Bbb{N}$. Given $\delta$, $E$ can be partitioned into measurable sets $E_1,...,E_k$ with $m(E_i) < \delta$. Hence $$\int_E |f_n| = \sum_{i=1}^k \int_{E_i} |f_n| < k,$$ for every $n \in \Bbb{N}$, and therefore $\liminf \int_{E} |f_n| \le \sup \int_E |f_n| \le k$. By Fatou's lemma for convergence in measure, $$\int_E |f| \le \liminf \int_{E} |f_n| \le k < \infty.$$ Now we prove the limit part. Again, by Fatou's lemma for convergence in measure, we get $\int_E f \le \liminf \int_E f_n$. Note that there exists a subsequence $\{f_{n_k}\}$ for which $$\lim_{k \to \infty} f_{n_k} = \limsup f_n.$$ Since $f_{n_k} \to f$ in measure, there exists a subsequence $\{f_{n_{k_m}}\}$ such that $f_{n_{k_m}} \to f$ pointwise a.e. on $E$. Since $\{f_n\}$ is UI, $\{f_{n_{k_m}}\}$ will also be UI. Hence by Vitali's theorem for pointwise covergence $$\lim_{m \to \infty} \int_E f_{n_{k_m}} = \int_E f .$$ Since $\{\int_E f_{n_{k_m}}\}$ is a subsequence of $\{\int_E f_{n_k}\}$, it must be the case that $$\lim_{m \to \infty} \int_E f_{n_{k_m}} = \limsup \int_E f_n,$$ and therefore $\limsup \int_E f_n = \int_E f \le \liminf \int_E f_n$ which implies $$\lim_{n \to \infty} \int_E f_n = \int_E f$$ $\blacksquare$ Does this sound right?",,"['real-analysis', 'measure-theory', 'proof-verification']"
84,Why is Hausdorff measure Borel regular?,Why is Hausdorff measure Borel regular?,,"Definition of Hausdorff measure: I already knew that all borel sets are measurable. So the problem is that given any subset $A$, how to find some borel set containing $A$ that has the same measure. I have read some text, but they only say that we can replace the definition with open sets or closed sets and get the same definition (and this part I can understand), but then they claim that Hausdorff measure is borel regular as a corollary without explanation. Can any one give a detailed proof? Thanks a lot. Explanation of the fact we can replace the definition with open/closed subsets:","Definition of Hausdorff measure: I already knew that all borel sets are measurable. So the problem is that given any subset $A$, how to find some borel set containing $A$ that has the same measure. I have read some text, but they only say that we can replace the definition with open sets or closed sets and get the same definition (and this part I can understand), but then they claim that Hausdorff measure is borel regular as a corollary without explanation. Can any one give a detailed proof? Thanks a lot. Explanation of the fact we can replace the definition with open/closed subsets:",,"['measure-theory', 'geometric-measure-theory', 'hausdorff-measure']"
85,"An integral of a positive function over a ""small"" set is ""small"".","An integral of a positive function over a ""small"" set is ""small"".",,"Consider a measure space $(X,\mathfrak{A},\mu)$, $f$ an integrable function and $f \geq 0$. Show that for every $\epsilon > 0$ there exists a $\delta > 0$ such that for every $A \in \mathfrak{A}$ if $\mu(A)<\delta$ then $\int_A f d\mu < \epsilon$. I am given a hint which is to consider $f_n(x) = \min\{n, f(x)\}$. I do this and given that $f_n \leq f_{n+1}$ I can use the Beppo-Levi theorem and conclude that $\displaystyle \int_A f d\mu = \lim_{n \to \infty} \int_A f_n d\mu$. If $f$ is bounded I can further conclude that there exists M such that $\displaystyle\lim_{n \to \infty} \int_A f_n d\mu \leq \int M d\mu = M\mu(A)$ and take $\delta = \frac{\epsilon}{M}$. I don't really know what to do if $f$ is not bounded.","Consider a measure space $(X,\mathfrak{A},\mu)$, $f$ an integrable function and $f \geq 0$. Show that for every $\epsilon > 0$ there exists a $\delta > 0$ such that for every $A \in \mathfrak{A}$ if $\mu(A)<\delta$ then $\int_A f d\mu < \epsilon$. I am given a hint which is to consider $f_n(x) = \min\{n, f(x)\}$. I do this and given that $f_n \leq f_{n+1}$ I can use the Beppo-Levi theorem and conclude that $\displaystyle \int_A f d\mu = \lim_{n \to \infty} \int_A f_n d\mu$. If $f$ is bounded I can further conclude that there exists M such that $\displaystyle\lim_{n \to \infty} \int_A f_n d\mu \leq \int M d\mu = M\mu(A)$ and take $\delta = \frac{\epsilon}{M}$. I don't really know what to do if $f$ is not bounded.",,"['integration', 'measure-theory']"
86,direct definition of the Radon-Nikodym derivative?,direct definition of the Radon-Nikodym derivative?,,"The Radon-Nikodym derivative $f$ for a measurable space $(X,F)$ and measures $\mu,\nu$ where $\nu$'s support contains $\mu$'s support, is defined as follows: $$\frac {d\mu}{d\nu}(x)=f(x) \text { s.t. }\quad \forall A\in F: \quad \mu(A)=\int_A fd\nu$$ My question is: Can we also define the Radon-Nikodym derivative ""directly""? i.e. as follows: $$f(x):=...$$ I am looking for something analogous to the classical derivative in real analysis which is defined as $$\frac {dF(x)}{dx}=f(x)=\lim_{d\to 0}\frac {F(x+d)-F(x)}{d}$$ Rather than: $$\frac {dF(x)}{dx}=f(x) \text { s.t. }\quad \forall a,b\in \mathbb R: \quad F(b)-F(a)=\int_a^b f(x)dx$$ EDIT: I came up with the following idea, but it only works for some measurable spaces: Take a sequence of sets $A_n$ that are both $\mu$ and $\nu$ measure positve for all $n$, such that $\lim_{n\to\infty}A_n=\{x \}$. Then $$f(x)=\lim_{n\to \infty}\frac {\mu(A_n)}{\nu(A_n)}$$ However, out of the examples I've checked, this only works for discrete measurable spaces (in which case the definition is useless anyway), and one-dimensional continuous measure spaces (not sure if it works for all of them, only the examples I picked). It already fails in the measure space $(\mathbb R^2, B)$ because the value you get depends on how you approach the limit.","The Radon-Nikodym derivative $f$ for a measurable space $(X,F)$ and measures $\mu,\nu$ where $\nu$'s support contains $\mu$'s support, is defined as follows: $$\frac {d\mu}{d\nu}(x)=f(x) \text { s.t. }\quad \forall A\in F: \quad \mu(A)=\int_A fd\nu$$ My question is: Can we also define the Radon-Nikodym derivative ""directly""? i.e. as follows: $$f(x):=...$$ I am looking for something analogous to the classical derivative in real analysis which is defined as $$\frac {dF(x)}{dx}=f(x)=\lim_{d\to 0}\frac {F(x+d)-F(x)}{d}$$ Rather than: $$\frac {dF(x)}{dx}=f(x) \text { s.t. }\quad \forall a,b\in \mathbb R: \quad F(b)-F(a)=\int_a^b f(x)dx$$ EDIT: I came up with the following idea, but it only works for some measurable spaces: Take a sequence of sets $A_n$ that are both $\mu$ and $\nu$ measure positve for all $n$, such that $\lim_{n\to\infty}A_n=\{x \}$. Then $$f(x)=\lim_{n\to \infty}\frac {\mu(A_n)}{\nu(A_n)}$$ However, out of the examples I've checked, this only works for discrete measurable spaces (in which case the definition is useless anyway), and one-dimensional continuous measure spaces (not sure if it works for all of them, only the examples I picked). It already fails in the measure space $(\mathbb R^2, B)$ because the value you get depends on how you approach the limit.",,"['measure-theory', 'derivatives', 'lebesgue-integral']"
87,Which counterexamples to keep in mind when studying (Lebesgue) integral convergence theorems,Which counterexamples to keep in mind when studying (Lebesgue) integral convergence theorems,,"When studying the classical theorems regarding the convergence of a sequence of integrals, to the integral of the limit function, e.g. Beppo Levi Dominated convergence Vitalli's theorem which counterexamples should one keep in mind?","When studying the classical theorems regarding the convergence of a sequence of integrals, to the integral of the limit function, e.g. Beppo Levi Dominated convergence Vitalli's theorem which counterexamples should one keep in mind?",,"['integration', 'measure-theory', 'examples-counterexamples']"
88,Absolutely Continuous function using sums.,Absolutely Continuous function using sums.,,"Below is an exercise from Iowa State's Qualifying Exams in analysis, and a solution I cooked up for it.  I showed it to a friend, and he seems very unhappy with the very end of the proof, though I see nothing wrong with it.  Would anyone mind pointing out whether there are any issues?  Any help is very appreciated! Suppose $\{E_n\}$ is a sequence of Lebesgue measurable subsets of $\mathbb{R}$ with  $$ \sum_{n=1}^\infty \mu(E_n)<\infty $$ Let $f(x)=\sum_{n=1}^\infty \mu(E_n\cap [0,x])$.  Prove that $f$ is absolutely continuous on $[0,\infty)$ We need to show the following:  given $\epsilon>0$, there exists some $\delta > 0$ so that      $$  \sum_{k=1}^{N} |f(b_k) - f(a_k) | < \epsilon \quad \text{ whenever } \sum_{k=1}^{N} (b_k-a_k) < \delta  $$      and the intervals $(a_k,b_k)$ form a partition of $[0,\infty)$ into pairwise disjoint intervals. By assumption, there exists an $n_0 \geq 1$ such that $\sum_{n \geq n_0} \mu(E_n) < \epsilon/2$. Let $x,y \in [0,\infty)$ be such that $x<y$. By monotonicity of the Lebesgue measure, we have that       $$  |f(y) - f(x)| = \left| \sum_{n=1}^{\infty} \mu(E_n \cap [0,y]) - \sum_{n=1}^{\infty} \mu(E_n \cap [0,x] )\right| \leq \sum_{n=1}^{\infty} |\mu(E_n \cap [0,y]) - \mu(E_n \cap [0,x])|  $$      For each $ n \geq 1$, $E_n \cap [0,x] \subset E_n \cap [0,y]$, each of which have finite measure, and so       $$  \mu(E_n \cap [0,y]) - \mu(E_n \cap [0,x]) = \mu ((E_n \cap [0,y]) \setminus (E_n \cap [0,x])) = \mu(E_n \cap [x,y]),  $$      for each $ n \geq 1$; consequently, we have that       $$  |f(y) - f(x)| \leq \sum_{n=1}^{\infty} \mu(E_n \cap [x,y]).  $$      Choose $\delta = \epsilon/2n_{0}$. By monotonicity of the Lebesgue measure, we see that       $$  |f(y) - f(x)| \leq \sum_{n=1}^{\infty} \mu(E_n \cap [x,y] \leq \sum_{n=1}^{n_0-1} \mu(E_n \cap [x,y] + \sum_{n \geq n_0} \mu(E_n) < \mu(E_n \cap [x,y] + \epsilon/2.   $$      Finally, given any partition $\{x_k,y_k)\}_{k=1^K}$ of $[0,\infty)$ into pairwise disjoint interval with $\sum_{k=1}^{K} (y_k-x_k )< \delta$. Then it follows that       $$  | f(y_k) - f(x_k)| < \sum_{n=1}^{n_0-1} \mu(E_n \cap [x_k,y_k]) + \epsilon/2 \leq \sum_{n=1}^{n_0-1}( y_k-x_k )< \epsilon.   $$      Hence,      $$  \sum_{k=1}^{K} |f(y_k) - f(x_k)| < K \cdot \epsilon,  $$ completing the proof.","Below is an exercise from Iowa State's Qualifying Exams in analysis, and a solution I cooked up for it.  I showed it to a friend, and he seems very unhappy with the very end of the proof, though I see nothing wrong with it.  Would anyone mind pointing out whether there are any issues?  Any help is very appreciated! Suppose $\{E_n\}$ is a sequence of Lebesgue measurable subsets of $\mathbb{R}$ with  $$ \sum_{n=1}^\infty \mu(E_n)<\infty $$ Let $f(x)=\sum_{n=1}^\infty \mu(E_n\cap [0,x])$.  Prove that $f$ is absolutely continuous on $[0,\infty)$ We need to show the following:  given $\epsilon>0$, there exists some $\delta > 0$ so that      $$  \sum_{k=1}^{N} |f(b_k) - f(a_k) | < \epsilon \quad \text{ whenever } \sum_{k=1}^{N} (b_k-a_k) < \delta  $$      and the intervals $(a_k,b_k)$ form a partition of $[0,\infty)$ into pairwise disjoint intervals. By assumption, there exists an $n_0 \geq 1$ such that $\sum_{n \geq n_0} \mu(E_n) < \epsilon/2$. Let $x,y \in [0,\infty)$ be such that $x<y$. By monotonicity of the Lebesgue measure, we have that       $$  |f(y) - f(x)| = \left| \sum_{n=1}^{\infty} \mu(E_n \cap [0,y]) - \sum_{n=1}^{\infty} \mu(E_n \cap [0,x] )\right| \leq \sum_{n=1}^{\infty} |\mu(E_n \cap [0,y]) - \mu(E_n \cap [0,x])|  $$      For each $ n \geq 1$, $E_n \cap [0,x] \subset E_n \cap [0,y]$, each of which have finite measure, and so       $$  \mu(E_n \cap [0,y]) - \mu(E_n \cap [0,x]) = \mu ((E_n \cap [0,y]) \setminus (E_n \cap [0,x])) = \mu(E_n \cap [x,y]),  $$      for each $ n \geq 1$; consequently, we have that       $$  |f(y) - f(x)| \leq \sum_{n=1}^{\infty} \mu(E_n \cap [x,y]).  $$      Choose $\delta = \epsilon/2n_{0}$. By monotonicity of the Lebesgue measure, we see that       $$  |f(y) - f(x)| \leq \sum_{n=1}^{\infty} \mu(E_n \cap [x,y] \leq \sum_{n=1}^{n_0-1} \mu(E_n \cap [x,y] + \sum_{n \geq n_0} \mu(E_n) < \mu(E_n \cap [x,y] + \epsilon/2.   $$      Finally, given any partition $\{x_k,y_k)\}_{k=1^K}$ of $[0,\infty)$ into pairwise disjoint interval with $\sum_{k=1}^{K} (y_k-x_k )< \delta$. Then it follows that       $$  | f(y_k) - f(x_k)| < \sum_{n=1}^{n_0-1} \mu(E_n \cap [x_k,y_k]) + \epsilon/2 \leq \sum_{n=1}^{n_0-1}( y_k-x_k )< \epsilon.   $$      Hence,      $$  \sum_{k=1}^{K} |f(y_k) - f(x_k)| < K \cdot \epsilon,  $$ completing the proof.",,"['real-analysis', 'measure-theory', 'lebesgue-measure', 'absolute-continuity']"
89,Properties of mutual singular measures,Properties of mutual singular measures,,"Let $\mu$ be a positive measure and $\nu_1, \nu_2$ arbitrary measures, all defined on the same measurable space $(S,\Sigma)$. We say that two arbitrary measure $\mu, \nu$ are mutually singular (notation $\nu \perp \mu$) if there exist disjoint sets $E$ and $F$ such that $\nu(A)=\nu(A \cap E)$ and $\mu(A) = \mu(A \cap F)$ for all $A \in \Sigma$. We say that $\nu$ is absolutely continuous w.r.t. $\mu$ (notation $\nu \ll \mu$), if $\nu(E) = 0$ for every $E \in \Sigma$ with $\mu(E)=0$. Now, I want to prove that If $\nu_1 \perp \mu$ and $\nu_2 \perp \mu$, then $\nu_1 + \nu_2 \perp \mu$. If $\nu_1 \ll \mu$ and $\mu_2 \perp \mu$, then $\nu_1 \perp \nu_2$. To start with 1.: $\exists E,F, G,H \in \Sigma$ such that \begin{align} \nu_1(A) = \nu_1(A \cap E)\  \text{ and }\  \mu(A) = \mu(A \cap F)\ \text{ for all $A \in \Sigma$}.\\ \nu_2(B) = \nu_2(B \cap G)\  \text{ and }\  \mu(B) = \mu(B \cap H)\ \text{ for all $B \in \Sigma$}.\\ \end{align} So, for which sets $C,I,J \in \Sigma$ do I have to show that $(\nu_1 + \nu_2)(C) = (\nu_1 + \nu_2)(C \cap I)$ and $\mu(C) = \mu(C \cap J)\ \text{ for all $C \in \Sigma$}$? Secondly, I do not have any suggestions for 2. Do you have any suggestions?","Let $\mu$ be a positive measure and $\nu_1, \nu_2$ arbitrary measures, all defined on the same measurable space $(S,\Sigma)$. We say that two arbitrary measure $\mu, \nu$ are mutually singular (notation $\nu \perp \mu$) if there exist disjoint sets $E$ and $F$ such that $\nu(A)=\nu(A \cap E)$ and $\mu(A) = \mu(A \cap F)$ for all $A \in \Sigma$. We say that $\nu$ is absolutely continuous w.r.t. $\mu$ (notation $\nu \ll \mu$), if $\nu(E) = 0$ for every $E \in \Sigma$ with $\mu(E)=0$. Now, I want to prove that If $\nu_1 \perp \mu$ and $\nu_2 \perp \mu$, then $\nu_1 + \nu_2 \perp \mu$. If $\nu_1 \ll \mu$ and $\mu_2 \perp \mu$, then $\nu_1 \perp \nu_2$. To start with 1.: $\exists E,F, G,H \in \Sigma$ such that \begin{align} \nu_1(A) = \nu_1(A \cap E)\  \text{ and }\  \mu(A) = \mu(A \cap F)\ \text{ for all $A \in \Sigma$}.\\ \nu_2(B) = \nu_2(B \cap G)\  \text{ and }\  \mu(B) = \mu(B \cap H)\ \text{ for all $B \in \Sigma$}.\\ \end{align} So, for which sets $C,I,J \in \Sigma$ do I have to show that $(\nu_1 + \nu_2)(C) = (\nu_1 + \nu_2)(C \cap I)$ and $\mu(C) = \mu(C \cap J)\ \text{ for all $C \in \Sigma$}$? Secondly, I do not have any suggestions for 2. Do you have any suggestions?",,"['real-analysis', 'measure-theory', 'singular-measures']"
90,integration - bartle theorem 5.3 - absolute integrability,integration - bartle theorem 5.3 - absolute integrability,,"Theorem 5.3: A measurable function $f$ belongs to  $L$ if and only if $|f| $ belongs to $L$. Definitions: $L = L(X,\mathbf{X}, \mu)$ of integrable functions consists of all real-valued $\mathbf{X}$-measurable functions $f$ defined on $X$, such that both the positive and negative parts $f^{+}, f^{-}$ of $f$ have finite integrals with respect to $\mu$. A function $f: X \rightarrow \mathbb{R}$ is $\mathbf{X}$-measurable if $f^{-1}((\alpha, \infty)) $ are measurable sets for all real $\alpha$. If $f: X \rightarrow \mathbb{R}^{+}$ is $\mathbf{X}$-measurable we define the integral with respect to $\mu$ to be the extended real number  $$ \int f \, d \mu = \sup \int \phi \, d \mu ,$$  where supremum is taken over all simple functions $\phi: X \rightarrow \mathbb{R}$ such that $ 0 \le \phi \le f $. (The integral of simple function is then the usual one with $\mu$.) What I don't see: $|f| \in L \Rightarrow f \in L$ We have $|f|^{+} = f^{+} + f^{-} , |f|^{-} = 0$ have finite integrals. But this does even not imply that $f^{+}$ and $f^{-}$ are $\mathbf{X}$- measurable. What am I missing? EDIT: As given in the counter example by the comments, I believe the theorem should be reformulated as, Let $f$ be a measurable function, then $f \in L \Leftrightarrow |f| \in L$ Is this correct?","Theorem 5.3: A measurable function $f$ belongs to  $L$ if and only if $|f| $ belongs to $L$. Definitions: $L = L(X,\mathbf{X}, \mu)$ of integrable functions consists of all real-valued $\mathbf{X}$-measurable functions $f$ defined on $X$, such that both the positive and negative parts $f^{+}, f^{-}$ of $f$ have finite integrals with respect to $\mu$. A function $f: X \rightarrow \mathbb{R}$ is $\mathbf{X}$-measurable if $f^{-1}((\alpha, \infty)) $ are measurable sets for all real $\alpha$. If $f: X \rightarrow \mathbb{R}^{+}$ is $\mathbf{X}$-measurable we define the integral with respect to $\mu$ to be the extended real number  $$ \int f \, d \mu = \sup \int \phi \, d \mu ,$$  where supremum is taken over all simple functions $\phi: X \rightarrow \mathbb{R}$ such that $ 0 \le \phi \le f $. (The integral of simple function is then the usual one with $\mu$.) What I don't see: $|f| \in L \Rightarrow f \in L$ We have $|f|^{+} = f^{+} + f^{-} , |f|^{-} = 0$ have finite integrals. But this does even not imply that $f^{+}$ and $f^{-}$ are $\mathbf{X}$- measurable. What am I missing? EDIT: As given in the counter example by the comments, I believe the theorem should be reformulated as, Let $f$ be a measurable function, then $f \in L \Leftrightarrow |f| \in L$ Is this correct?",,"['integration', 'measure-theory', 'proof-verification', 'indefinite-integrals', 'proof-explanation']"
91,"Show by definition that $f:[0,1]\to\mathbb R$ is measurable",Show by definition that  is measurable,"f:[0,1]\to\mathbb R","Show by definition that the function $f:[0,1]\to \mathbb R$ defined by $$f(x)=\begin{cases}\frac{1}{x} & 0<x<1\\3 & x=0\\5 & x=1\end{cases}$$is measurable. Let  $\alpha$ be any real number. Then $$\{f>\alpha\}=\begin{cases} [0,1] & \alpha<1 \\ [0,1/\alpha] &\alpha\ge 1 \end{cases}$$ Please check my calculation and detect if something wrong there. Also comment if there are no mistake.","Show by definition that the function $f:[0,1]\to \mathbb R$ defined by $$f(x)=\begin{cases}\frac{1}{x} & 0<x<1\\3 & x=0\\5 & x=1\end{cases}$$is measurable. Let  $\alpha$ be any real number. Then $$\{f>\alpha\}=\begin{cases} [0,1] & \alpha<1 \\ [0,1/\alpha] &\alpha\ge 1 \end{cases}$$ Please check my calculation and detect if something wrong there. Also comment if there are no mistake.",,['measure-theory']
92,Difference between line integral and Lebesgue integral over set containing the line in $\mathbb{R}^2$,Difference between line integral and Lebesgue integral over set containing the line in,\mathbb{R}^2,"It has been awhile since I last did any vector calculus, but this question got me thinking about line integrals and how they differ from Lebesgue integrals over sets containing the line. Considering the function given in the linked post, $$ f(x,y)=\begin{cases} xy \ \ \text{if}\ \  x=y\\ 0 \ \ \ \ \text{if}\ \ x\neq y\end{cases}$$  suppose we want to calculate the line integral of $f$ along the line $x=y$ from $(0,0)$ to $(1,1)$, call the curve $\Gamma$. We can use standard techniques to find that the answer is given by \begin{align*} \int_\Gamma f(x,y)ds & =\sqrt2\int_0^1t^2dt \\ & =\frac{\sqrt{2}}{3}. \end{align*} Now the Lebesgue integral in the linked post is $$\int_Afd\mu$$ where $A$ is the unit square $[0,1]\times[0,1]$ in $\mathbb{R}^2$. Now I understand that because the measure of the subset of $A$ on which is $f$ is non-zero is $0$ the integral is $0$, but in some way I can't help thinking that this is equivalent to integrating the function $f(x,y)=xy$ over the line $\Gamma$. Obviously this is not the case, but I don't really understand why as I'm quite a novice when it comes to measure theory. If someone could explain where my intuition is going wrong I'd be very appreciative. EDIT: Levap's brilliant answer aided me in coming up with an intuitive feeling for why the 2 are different. The line integral can intuitively thought to be the ""area"" of the function under the curve. If the curve is non-zero and not symmetric obviously the area will also be non-zero. The general integral (Riemann or Lebesgue) over a subset of $\mathbb{R}^2$ can intuitively thought to be the volume underneath the function over an area in $\mathbb{R^2}$. However, as function is only non-zero underneath a one-dimensional line the integral is actually giving the volume underneath a line, which is obviously $0$ because one of the values for the three ""dimensions"" used to calculate volume is $0$. This corresponds nicely with the standard Lebesgue measure in $\mathbb{R^2}$ of a line being $0$.","It has been awhile since I last did any vector calculus, but this question got me thinking about line integrals and how they differ from Lebesgue integrals over sets containing the line. Considering the function given in the linked post, $$ f(x,y)=\begin{cases} xy \ \ \text{if}\ \  x=y\\ 0 \ \ \ \ \text{if}\ \ x\neq y\end{cases}$$  suppose we want to calculate the line integral of $f$ along the line $x=y$ from $(0,0)$ to $(1,1)$, call the curve $\Gamma$. We can use standard techniques to find that the answer is given by \begin{align*} \int_\Gamma f(x,y)ds & =\sqrt2\int_0^1t^2dt \\ & =\frac{\sqrt{2}}{3}. \end{align*} Now the Lebesgue integral in the linked post is $$\int_Afd\mu$$ where $A$ is the unit square $[0,1]\times[0,1]$ in $\mathbb{R}^2$. Now I understand that because the measure of the subset of $A$ on which is $f$ is non-zero is $0$ the integral is $0$, but in some way I can't help thinking that this is equivalent to integrating the function $f(x,y)=xy$ over the line $\Gamma$. Obviously this is not the case, but I don't really understand why as I'm quite a novice when it comes to measure theory. If someone could explain where my intuition is going wrong I'd be very appreciative. EDIT: Levap's brilliant answer aided me in coming up with an intuitive feeling for why the 2 are different. The line integral can intuitively thought to be the ""area"" of the function under the curve. If the curve is non-zero and not symmetric obviously the area will also be non-zero. The general integral (Riemann or Lebesgue) over a subset of $\mathbb{R}^2$ can intuitively thought to be the volume underneath the function over an area in $\mathbb{R^2}$. However, as function is only non-zero underneath a one-dimensional line the integral is actually giving the volume underneath a line, which is obviously $0$ because one of the values for the three ""dimensions"" used to calculate volume is $0$. This corresponds nicely with the standard Lebesgue measure in $\mathbb{R^2}$ of a line being $0$.",,"['integration', 'measure-theory', 'lebesgue-integral', 'line-integrals']"
93,Lebesgue Dominated Convergence Theorem,Lebesgue Dominated Convergence Theorem,,"Good night or day or whatever time of the day you're living in.  I'm reading the book ""The Elements of Integration and Lebesgue Measure"" written by Robert G. Bartle. When he gives the proof to the Lebesgue Dominated Convergence Theorem, he sais: ""Be redefining the functions $f_n , f$ on a set of measure $0$ we may assume that the convergence takes place on all of $X$ "". Can someone help me to understand what does he means with this redefinition, please.","Good night or day or whatever time of the day you're living in.  I'm reading the book ""The Elements of Integration and Lebesgue Measure"" written by Robert G. Bartle. When he gives the proof to the Lebesgue Dominated Convergence Theorem, he sais: ""Be redefining the functions $f_n , f$ on a set of measure $0$ we may assume that the convergence takes place on all of $X$ "". Can someone help me to understand what does he means with this redefinition, please.",,"['measure-theory', 'lebesgue-integral']"
94,"If $A\cup B=\mathbb{R}$ and $A,B$ are closed, then either $A$ or $B$ contains an interval.","If  and  are closed, then either  or  contains an interval.","A\cup B=\mathbb{R} A,B A B","In this answer, the following fact is assumed: If $A$ and $B$ are closed subsets of $\mathbb{R}$ such that $A\cup B=\mathbb{R}$, then either $A$ or $B$ contains an interval. Why is that true? I first thought that we can use measure theory: either $m(A)>0$ and $m(B)>0$ and hence one contain an open interval. But this is false since there are sets of positive measure not containing any interval (e.g. $\mathbb{R}-\mathbb{Q}$). But $\mathbb{R}-\mathbb{Q}$ is not closed, so maybe closed sets with positive measure contain intervals?","In this answer, the following fact is assumed: If $A$ and $B$ are closed subsets of $\mathbb{R}$ such that $A\cup B=\mathbb{R}$, then either $A$ or $B$ contains an interval. Why is that true? I first thought that we can use measure theory: either $m(A)>0$ and $m(B)>0$ and hence one contain an open interval. But this is false since there are sets of positive measure not containing any interval (e.g. $\mathbb{R}-\mathbb{Q}$). But $\mathbb{R}-\mathbb{Q}$ is not closed, so maybe closed sets with positive measure contain intervals?",,"['real-analysis', 'measure-theory']"
95,Open set containing cantor set,Open set containing cantor set,,Is it possible to construct an open set of measure less than a given positive real and containing cantor set?,Is it possible to construct an open set of measure less than a given positive real and containing cantor set?,,['measure-theory']
96,"Real Analysis, Problem 3.2.14 The Radon Nikodym Theorem","Real Analysis, Problem 3.2.14 The Radon Nikodym Theorem",,"Problem 3.3.14 - If $\nu$ is an arbitrary signed measure and $\mu$ is a $\sigma$ -finite measure on $(X,M)$ such that $\nu\ll \mu$ , there exists an extended $\mu$ -integrable function $f:X\rightarrow [-\infty,\infty]$ such that $d\nu = fd\mu$ . Hints: a.) It suffices to assume that $\mu$ is finite and $\nu$ is positive. b.) With these assumptions, there exists an $E\in M$ that is $\sigma$ -finite for $\nu$ such that $\mu(E)\geq \mu(F)$ for all sets $F$ that are $\sigma$ -finite for $\nu$ . c.) The Radon-Nikodym theorem applies on $E$ . If $F\cap E = \emptyset$ , then either $\nu(F) = \mu(F) = 0$ or $\mu(F) > 0$ and $|\nu(F)| = \infty$ . Attempted proof - Consider $\mu(E)$ where $E$ is a $\sigma$ -finite set for $\nu$ . Since we have that $\mu$ is finite then clearly $\mu(E)$ must be bounded which implies it has a supremum. We will define the supremum as $$L = \sup\{F: F \ \text{is} \  \sigma-\text{finite for} \ \nu\}$$ Now lets take a sequence $\{E_n\}_{1}^{\infty}$ that are $\sigma$ -finite with respect to $\nu$ and $\mu(E_n)\rightarrow L$ as $n\rightarrow \infty$ . Now let $$E = \bigcup_{1}^{\infty}E_n$$ then $\mu(E) \leq L$ since it is taken to be a countable union of $\sigma$ -finite sets. On the other hand, $\mu(E)\geq \mu(E_n)$ for all $n$ and since $\mu(E_n)\rightarrow L$ then $\mu(E) = L$ . Now since $\mu(E) = L$ then clearly by definition of $L$ we have that $\mu(E) > \mu(F)$ for all sets $F$ that are $\sigma$ -finite for $\nu$ . Now we apply the Radon-Nikodym theorem: so, suppose that $F\cap E = \emptyset$ well since $\nu\ll\mu$ then by definition $\nu(F) = \mu(F) = 0$ . If $\mu(F) > 0$ then for sake of contradiction suppose $|\nu(F)|\neq \infty$ . Then since $\mu$ is finite $\mu(F\cup E) > \mu(E)$ then this implies that $E\cup F$ is not $\sigma$ -finite since a $\sigma$ -finite set with a union of a finite set is $\sigma$ -finite. Therefore $|\nu(F)| = \infty$ . Thus I believe we can refer to Radon-Nikidym theorem to conclude that there exists an extended $\mu$ -integrable function $f:X\rightarrow [-\infty,\infty]$ such that $d\nu = fd\mu$ . I am not sure if this is completely correct, any suggestions is greatly appreciated.","Problem 3.3.14 - If is an arbitrary signed measure and is a -finite measure on such that , there exists an extended -integrable function such that . Hints: a.) It suffices to assume that is finite and is positive. b.) With these assumptions, there exists an that is -finite for such that for all sets that are -finite for . c.) The Radon-Nikodym theorem applies on . If , then either or and . Attempted proof - Consider where is a -finite set for . Since we have that is finite then clearly must be bounded which implies it has a supremum. We will define the supremum as Now lets take a sequence that are -finite with respect to and as . Now let then since it is taken to be a countable union of -finite sets. On the other hand, for all and since then . Now since then clearly by definition of we have that for all sets that are -finite for . Now we apply the Radon-Nikodym theorem: so, suppose that well since then by definition . If then for sake of contradiction suppose . Then since is finite then this implies that is not -finite since a -finite set with a union of a finite set is -finite. Therefore . Thus I believe we can refer to Radon-Nikidym theorem to conclude that there exists an extended -integrable function such that . I am not sure if this is completely correct, any suggestions is greatly appreciated.","\nu \mu \sigma (X,M) \nu\ll \mu \mu f:X\rightarrow [-\infty,\infty] d\nu = fd\mu \mu \nu E\in M \sigma \nu \mu(E)\geq \mu(F) F \sigma \nu E F\cap E = \emptyset \nu(F) = \mu(F) = 0 \mu(F) > 0 |\nu(F)| = \infty \mu(E) E \sigma \nu \mu \mu(E) L = \sup\{F: F \ \text{is} \  \sigma-\text{finite for} \ \nu\} \{E_n\}_{1}^{\infty} \sigma \nu \mu(E_n)\rightarrow L n\rightarrow \infty E = \bigcup_{1}^{\infty}E_n \mu(E) \leq L \sigma \mu(E)\geq \mu(E_n) n \mu(E_n)\rightarrow L \mu(E) = L \mu(E) = L L \mu(E) > \mu(F) F \sigma \nu F\cap E = \emptyset \nu\ll\mu \nu(F) = \mu(F) = 0 \mu(F) > 0 |\nu(F)|\neq \infty \mu \mu(F\cup E) > \mu(E) E\cup F \sigma \sigma \sigma |\nu(F)| = \infty \mu f:X\rightarrow [-\infty,\infty] d\nu = fd\mu","['real-analysis', 'measure-theory', 'proof-verification']"
97,Conditions where $\mu$ is semifinite and where $\mu$ is $\sigma$-finite,Conditions where  is semifinite and where  is -finite,\mu \mu \sigma,"This comes out of the book Real Analysis by Folland: $\mu$ is semifinite if and only if $f(x) < \infty$ for every $x\in X$, and $\mu$ is $\sigma$-finite if and only if $\mu$ is semifinite and $\{x:f(x) > 0\}$ is countable. Attempted proof for first statement - Let $X$ be any nonempty set, $M = P(X)$, and $f$ be any function from $X$ to $[0,\infty]$. Then $f$ determines a measure $\mu$ on $M$ by the formula $$\mu(E) = \sum_{x\in E}f(x)$$ (note this is how Folland sets up the above problem that he states the reader can verify) Now suppose $\mu$ is semifinite then $E\in M$ with $\mu(E) = \infty$. So $$\mu(E) = \sum_{x\in E}f(x) = \infty$$ then $f(x) < \infty$ for every $x\in X$ (Not sure if this is true but seems to make sense to me). OTOH, suppose $f(x) < \infty$ for every $x\in X$... Not really sure where to go from here... any suggestions is greatly appreciated. Attempted proof for second statement - Let $\mu$ be $\sigma$-finite and let $\{E_j\}_{1}^{\infty}$ be a sequence of disjoint sets in $M$, and $\mu(E) = \infty$. Set $$F = \bigcup_{1}^{\infty} E_j \ \text{where} \ E_j\in M$$ Then there exists an $F\in M$ such that $F\subset E$ and $0 < \mu(F)\leq \mu(E) = \infty$ then $\mu$ is semifinite. Now define $$\sum_{x\in E'} f(x) := \sup\{\sum_{x\in E}f(x): E' \ \text{finite} \ , E' \subset E\}$$ Then observe that $\sum_{x\in E} f(x) < \infty$ which implies that $\{x\in E: f(x) > 0\}$ is countable. OTOH, suppose $\mu$ is semifinite and $\{x: f(x) > 0\}$ is countable then.... not really sure where to go from here... any suggestions is greatly appreciated. I would like to stick to how I set this proof up although if one would like to show me how they would prove it I would appreciate it.","This comes out of the book Real Analysis by Folland: $\mu$ is semifinite if and only if $f(x) < \infty$ for every $x\in X$, and $\mu$ is $\sigma$-finite if and only if $\mu$ is semifinite and $\{x:f(x) > 0\}$ is countable. Attempted proof for first statement - Let $X$ be any nonempty set, $M = P(X)$, and $f$ be any function from $X$ to $[0,\infty]$. Then $f$ determines a measure $\mu$ on $M$ by the formula $$\mu(E) = \sum_{x\in E}f(x)$$ (note this is how Folland sets up the above problem that he states the reader can verify) Now suppose $\mu$ is semifinite then $E\in M$ with $\mu(E) = \infty$. So $$\mu(E) = \sum_{x\in E}f(x) = \infty$$ then $f(x) < \infty$ for every $x\in X$ (Not sure if this is true but seems to make sense to me). OTOH, suppose $f(x) < \infty$ for every $x\in X$... Not really sure where to go from here... any suggestions is greatly appreciated. Attempted proof for second statement - Let $\mu$ be $\sigma$-finite and let $\{E_j\}_{1}^{\infty}$ be a sequence of disjoint sets in $M$, and $\mu(E) = \infty$. Set $$F = \bigcup_{1}^{\infty} E_j \ \text{where} \ E_j\in M$$ Then there exists an $F\in M$ such that $F\subset E$ and $0 < \mu(F)\leq \mu(E) = \infty$ then $\mu$ is semifinite. Now define $$\sum_{x\in E'} f(x) := \sup\{\sum_{x\in E}f(x): E' \ \text{finite} \ , E' \subset E\}$$ Then observe that $\sum_{x\in E} f(x) < \infty$ which implies that $\{x\in E: f(x) > 0\}$ is countable. OTOH, suppose $\mu$ is semifinite and $\{x: f(x) > 0\}$ is countable then.... not really sure where to go from here... any suggestions is greatly appreciated. I would like to stick to how I set this proof up although if one would like to show me how they would prove it I would appreciate it.",,"['real-analysis', 'measure-theory']"
98,A family of open sets of measure $<1$ such that the union of any two has measure $\ge 1$,A family of open sets of measure  such that the union of any two has measure,<1 \ge 1,"Can someone give me a few hints about how to solve this problem? Let  $m$ be the Lebesgue measure on the real line and $P$ the collection of all the open sets $U$ of $\mathbb{R}$ such that $m(U)<1$. Let $Q \subseteq P$ such that for each couple $V_1, V_2 \in Q$, with $V_1 \neq V_2$, we have $m(V_1 \cup V_2) \geq 1$.  Show that $Q$ is at most countable.","Can someone give me a few hints about how to solve this problem? Let  $m$ be the Lebesgue measure on the real line and $P$ the collection of all the open sets $U$ of $\mathbb{R}$ such that $m(U)<1$. Let $Q \subseteq P$ such that for each couple $V_1, V_2 \in Q$, with $V_1 \neq V_2$, we have $m(V_1 \cup V_2) \geq 1$.  Show that $Q$ is at most countable.",,"['real-analysis', 'measure-theory', 'lebesgue-measure']"
99,Constructing sets of certain measure from classes of bijections on the continuum,Constructing sets of certain measure from classes of bijections on the continuum,,"Suppose that for each $\alpha < 2^\omega$, $f_\alpha:2^\omega \rightarrow 2^\omega$ is a bijection. I want to know whether it's always possible to construct an $X\subseteq Y\subseteq 2^\omega$ such that: $X$ has measure 0. $Y$ has positive measure. $\{\alpha \mid \min f_\alpha(Y) = \min f_\alpha(X)\}$ has positive measure. (For $Z\subseteq 2^\omega$, $\min Z$ denotes the smallest element under the ordinal ordering.)","Suppose that for each $\alpha < 2^\omega$, $f_\alpha:2^\omega \rightarrow 2^\omega$ is a bijection. I want to know whether it's always possible to construct an $X\subseteq Y\subseteq 2^\omega$ such that: $X$ has measure 0. $Y$ has positive measure. $\{\alpha \mid \min f_\alpha(Y) = \min f_\alpha(X)\}$ has positive measure. (For $Z\subseteq 2^\omega$, $\min Z$ denotes the smallest element under the ordinal ordering.)",,"['measure-theory', 'set-theory']"
