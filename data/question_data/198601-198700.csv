,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Understanding complexified Levi-Civita connection in complex geometry,Understanding complexified Levi-Civita connection in complex geometry,,"Proposition $3.18$ From this note we have, Let $(X,J,g)$ be a Hermitian manifold. If we denote the complexified Levi-Civita connection by $\nabla$ . $\nabla$ is characterized as the only connection on $T^{\mathbb R}X$ that is both torsion free and compatible with $g$ . Then by definition we can assume, $$\nabla_{\partial_i}\partial_j=\Gamma^k_{ij}\partial_k+\Gamma^{\bar k}_{ij}\partial_{\bar k}\tag1$$ Since $\nabla$ is a real operator, we also have, $$\nabla_{\partial_{\bar i}}\partial_{\bar j}=\overline{\Gamma^k_{ij}}\partial_{\bar k}+\overline{\Gamma^{\bar k}_{ij}}\partial_{k},\nabla_{\partial_{i}}\partial_{\bar j}=\overline{\Gamma^k_{\bar ij}}\partial_{\bar k}+\overline{\Gamma^{\bar k}_{\bar ij}}\partial_{k}\tag2$$ Then using the torsion free and metric compatibility condition we have $\Gamma^k_{ij}=\Gamma^k_{ji}=\Gamma^{\bar k}_{ij}=\Gamma^{\bar k}_{ji}$ and $\Gamma^{\bar k}_{ij}=\Gamma^{\bar k}_{\bar ij}=\Gamma^{k}_{\bar ij}=0$ resp. $(1)$ make sense, as we decompose everything into holomorphic and anti-holomorphic coordinates. But $(2)$ doesn't make sense to me. Why we need the complex conjugate of Christoffel symbols here? what's the complex conjugates of the Christoffel symbols? And how to determine $\nabla_{\partial_{\bar i}}\partial_j=$ ? As it wasn't explicitly mentioned but I guess it should be $\nabla_{\partial_{\bar i}}\partial_j\stackrel{?}{=}\overline{\Gamma^k_{i\bar j}}\partial_{\bar k}+\overline{\Gamma^{\bar k}_{i\bar j}}\partial_{k}$ (without knowing why it should look like this! As I have a doubt about the \bar used in the formulas like I guess it should be $\nabla_{\partial_{\bar i}}\partial_{j}$ in $(2)$ ). On section $8.4$ , Geometry, Topology and Physics by Nakahara define covariant derivative differently, Let (M, g) be a Hermitian manifold. We define a connection which is compatible with the complex structure. $$\nabla_\mu \frac{\partial}{\partial z^\nu}=\Gamma^\lambda_{\mu\nu}(z)\frac{\partial}{\partial z^\lambda}\equiv\Gamma^\lambda_{\mu\nu}\partial_\lambda, \quad\nabla_{\bar \mu} \frac{\partial}{\partial \bar z^\nu}=\Gamma^{\bar \lambda}_{\bar\mu\bar\nu}(z)\frac{\partial}{\partial \bar z^\lambda}\equiv\Gamma^{\bar \lambda}_{\bar\mu\bar\nu}\partial_{\bar\lambda}\tag3$$ Why isn't decomposition considered here? As @TedShifrin mention in the comment, $\frac{\partial}{\partial z^\nu}$ are holomorphic sections of the tangent bundle, their covariant derivatives are of type $(1,0)$ only. That's why $\nabla_\mu \frac{\partial}{\partial z^\nu}=\Gamma^\lambda_{\mu\nu}\partial_\lambda$ make sense. The only thing which still confuse me is $(2)$ . Actually, I want to know, how to locally determine this connection intuitively . It will be a great help if anyone give me any reference/resource where I can have the motivation/derivation. TIA","Proposition From this note we have, Let be a Hermitian manifold. If we denote the complexified Levi-Civita connection by . is characterized as the only connection on that is both torsion free and compatible with . Then by definition we can assume, Since is a real operator, we also have, Then using the torsion free and metric compatibility condition we have and resp. make sense, as we decompose everything into holomorphic and anti-holomorphic coordinates. But doesn't make sense to me. Why we need the complex conjugate of Christoffel symbols here? what's the complex conjugates of the Christoffel symbols? And how to determine ? As it wasn't explicitly mentioned but I guess it should be (without knowing why it should look like this! As I have a doubt about the \bar used in the formulas like I guess it should be in ). On section , Geometry, Topology and Physics by Nakahara define covariant derivative differently, Let (M, g) be a Hermitian manifold. We define a connection which is compatible with the complex structure. Why isn't decomposition considered here? As @TedShifrin mention in the comment, are holomorphic sections of the tangent bundle, their covariant derivatives are of type only. That's why make sense. The only thing which still confuse me is . Actually, I want to know, how to locally determine this connection intuitively . It will be a great help if anyone give me any reference/resource where I can have the motivation/derivation. TIA","3.18 (X,J,g) \nabla \nabla T^{\mathbb R}X g \nabla_{\partial_i}\partial_j=\Gamma^k_{ij}\partial_k+\Gamma^{\bar k}_{ij}\partial_{\bar k}\tag1 \nabla \nabla_{\partial_{\bar i}}\partial_{\bar j}=\overline{\Gamma^k_{ij}}\partial_{\bar k}+\overline{\Gamma^{\bar k}_{ij}}\partial_{k},\nabla_{\partial_{i}}\partial_{\bar j}=\overline{\Gamma^k_{\bar ij}}\partial_{\bar k}+\overline{\Gamma^{\bar k}_{\bar ij}}\partial_{k}\tag2 \Gamma^k_{ij}=\Gamma^k_{ji}=\Gamma^{\bar k}_{ij}=\Gamma^{\bar k}_{ji} \Gamma^{\bar k}_{ij}=\Gamma^{\bar k}_{\bar ij}=\Gamma^{k}_{\bar ij}=0 (1) (2) \nabla_{\partial_{\bar i}}\partial_j= \nabla_{\partial_{\bar i}}\partial_j\stackrel{?}{=}\overline{\Gamma^k_{i\bar j}}\partial_{\bar k}+\overline{\Gamma^{\bar k}_{i\bar j}}\partial_{k} \nabla_{\partial_{\bar i}}\partial_{j} (2) 8.4 \nabla_\mu \frac{\partial}{\partial z^\nu}=\Gamma^\lambda_{\mu\nu}(z)\frac{\partial}{\partial z^\lambda}\equiv\Gamma^\lambda_{\mu\nu}\partial_\lambda, \quad\nabla_{\bar \mu} \frac{\partial}{\partial \bar z^\nu}=\Gamma^{\bar \lambda}_{\bar\mu\bar\nu}(z)\frac{\partial}{\partial \bar z^\lambda}\equiv\Gamma^{\bar \lambda}_{\bar\mu\bar\nu}\partial_{\bar\lambda}\tag3 \frac{\partial}{\partial z^\nu} (1,0) \nabla_\mu \frac{\partial}{\partial z^\nu}=\Gamma^\lambda_{\mu\nu}\partial_\lambda (2)","['differential-geometry', 'complex-geometry', 'connections']"
1,Why can the exterior derivative be interpreted as in this picture?,Why can the exterior derivative be interpreted as in this picture?,,"This paper provides a geometric intuition of differential forms. On page $5$ it reads: ""Consider the case $xdy$ . The number of horizontal lines is roughly proportional to $y$ . In other words the number of lines that 'come to an end' in any area is roughly the same wherever we look. This is just like the example $dx ∧ dy$ above. You may have guessed what is going on here: $d(xdy) = dx∧dy$ . In other words exterior derivative is none other than finding the boundary of the picture."" Why can the exterior derivative of a form $\omega$ , defined as $$d\omega = d\left(\sum_{i_1,\ldots,i_k}\omega_{i_1,\ldots,i_k}dx^{i_1}\wedge\ldots\wedge dx^{i_k}\right)\\ \ \ = \sum_{i_1,\ldots,i_k}d\omega_{i_1,\ldots,i_k}\wedge dx^{i_1}\wedge\ldots\wedge dx^{i_k}\\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ = \sum_{i_1,\ldots,i_k}\sum_{\alpha=1}^nD_{\alpha}(\omega_{i_1,\ldots,i_k})\ dx^{\alpha}\wedge dx^{i_1}\wedge\ldots\wedge dx^{i_k}\\ $$ be interpreted as the quantity of points at which the lines in the picture come to an end?","This paper provides a geometric intuition of differential forms. On page it reads: ""Consider the case . The number of horizontal lines is roughly proportional to . In other words the number of lines that 'come to an end' in any area is roughly the same wherever we look. This is just like the example above. You may have guessed what is going on here: . In other words exterior derivative is none other than finding the boundary of the picture."" Why can the exterior derivative of a form , defined as be interpreted as the quantity of points at which the lines in the picture come to an end?","5 xdy y dx ∧ dy d(xdy) = dx∧dy \omega d\omega = d\left(\sum_{i_1,\ldots,i_k}\omega_{i_1,\ldots,i_k}dx^{i_1}\wedge\ldots\wedge dx^{i_k}\right)\\
\ \ = \sum_{i_1,\ldots,i_k}d\omega_{i_1,\ldots,i_k}\wedge dx^{i_1}\wedge\ldots\wedge dx^{i_k}\\
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ = \sum_{i_1,\ldots,i_k}\sum_{\alpha=1}^nD_{\alpha}(\omega_{i_1,\ldots,i_k})\ dx^{\alpha}\wedge dx^{i_1}\wedge\ldots\wedge dx^{i_k}\\
","['differential-geometry', 'intuition', 'differential-forms', 'exterior-algebra', 'exterior-derivative']"
2,Using Godement's criterion to prove that leaf space of a foliation carries a smooth structure compatible with the quotient topology.,Using Godement's criterion to prove that leaf space of a foliation carries a smooth structure compatible with the quotient topology.,,"I am trying to prove the following from Differential Geometry by Rui Loja Fernandes: Let $\mathcal{F}$ be a foliation of a smooth manifold $M$ . The following statements are equivalent: There exists a smooth structure on $M/\mathcal{F}$ , compatible with the quotient topology, such that $π : M → M/\mathcal{F}$ is a submersion. The leaf space $M/\mathcal{F}$ is Hausdorff and there is a cover of $M$ by foliated charts with the property that each leaf of F intersects each chart at most once. The Book says to use Godement's criterion which says that: Let $M$ be a smooth manifold and let ∼ be an equivalence relation on $M$ . The following statements are equivalent: There exists a smooth structure on $M/ ∼$ , compatible with the quotient topology, such that $π : M → M/ ∼$ is a submersion. The graph $R$ of ∼ is a proper submanifold of $M ×M$ and the restriction of the projection $p_1 : M × M → M$ to $R$ is a submersion. Where $$ R= \{(x,y)\in M\times M; x∼y\}$$ I have shown that 1 implies 2. I am having trouble trying to show that 2 implies 1, in particular, that $R$ is a submanifold. I believe that having done that all of the rest follows straightforwardly from the criterion. Any tips/suggestions? (Also if you know of any other way to show this please let me know !)","I am trying to prove the following from Differential Geometry by Rui Loja Fernandes: Let be a foliation of a smooth manifold . The following statements are equivalent: There exists a smooth structure on , compatible with the quotient topology, such that is a submersion. The leaf space is Hausdorff and there is a cover of by foliated charts with the property that each leaf of F intersects each chart at most once. The Book says to use Godement's criterion which says that: Let be a smooth manifold and let ∼ be an equivalence relation on . The following statements are equivalent: There exists a smooth structure on , compatible with the quotient topology, such that is a submersion. The graph of ∼ is a proper submanifold of and the restriction of the projection to is a submersion. Where I have shown that 1 implies 2. I am having trouble trying to show that 2 implies 1, in particular, that is a submanifold. I believe that having done that all of the rest follows straightforwardly from the criterion. Any tips/suggestions? (Also if you know of any other way to show this please let me know !)","\mathcal{F} M M/\mathcal{F} π : M → M/\mathcal{F} M/\mathcal{F} M M M M/ ∼ π : M → M/ ∼ R M ×M p_1 : M × M → M R  R= \{(x,y)\in M\times M; x∼y\} R","['differential-geometry', 'quotient-spaces', 'foliations']"
3,Is the integral of the squared distance function smooth on a compact Riemannian manifold?,Is the integral of the squared distance function smooth on a compact Riemannian manifold?,,"Let $M$ be a compact Riemannian manifold and let $d$ be the natural distance on it. Is the function $$x \mapsto \int _M d(x,y) ^2 \, \mathrm d y$$ smooth? Had it not been for the integral, the map $x \mapsto d(x,y) ^2$ is smooth outside the cut locus of $y$ , for fixed $y$ . The problem is the integral, which makes $y$ vary, and I do not know how to investigate this. If the above function (let us call it $f$ ) is not smooth, is there any theoretical framework in which I could say that $$\Delta f = \int _M \Delta_x \, d(x,y)^2 \, \mathrm d y$$ where the lower index $x$ indicates the variable with respect to which the Laplacian acts? And what could be the meaning of the integrand? I have tried placing the problem in the context of distribution theory, but this did not allow me to slip the Laplacian inside the integral, which is what I am after.","Let be a compact Riemannian manifold and let be the natural distance on it. Is the function smooth? Had it not been for the integral, the map is smooth outside the cut locus of , for fixed . The problem is the integral, which makes vary, and I do not know how to investigate this. If the above function (let us call it ) is not smooth, is there any theoretical framework in which I could say that where the lower index indicates the variable with respect to which the Laplacian acts? And what could be the meaning of the integrand? I have tried placing the problem in the context of distribution theory, but this did not allow me to slip the Laplacian inside the integral, which is what I am after.","M d x \mapsto \int _M d(x,y) ^2 \, \mathrm d y x \mapsto d(x,y) ^2 y y y f \Delta f = \int _M \Delta_x \, d(x,y)^2 \, \mathrm d y x","['differential-geometry', 'metric-spaces', 'lebesgue-integral', 'riemannian-geometry', 'smooth-manifolds']"
4,How to show that if two vector fields $X$ and $Y$ are tangent to a submanifold then so is their Lie bracket?,How to show that if two vector fields  and  are tangent to a submanifold then so is their Lie bracket?,X Y,"Let $M$ be a smooth manifold and let $Q$ be a submanifold of $M$ . Consider two vector fields $X, Y \in \mathfrak{X}(M)$ such that $X_q, Y_q\in T_qQ$ for every $q\in Q$ . Prove that $[X, Y]_q\in T_qQ$ for every $q\in Q$ . So, I came across the following proposition in Lee's ""Introduction to Smooth Manifold"": Proposition 8.22. Let $M$ be a smooth manifold, $S\subseteq M$ be an embedded manifold with or without boundary, and $X$ be a smooth vector field on $M$ . Then $X$ is tangent to $S$ if and only if $(Xf)|_S=0$ for every $f\in C^\infty(M)$ such that $f|_S\equiv0$ . Thus, I thought that I have to show that, for $f\in C^\infty(M)$ such that $f|_Q=0$ , we have $[X, Y]_q(f)=0$ . But $[X, Y]_q(f)=X_q(Y(f))-Y_q(X(f))=0$ because $Y(f)$ and $X(f)$ are smooth functions on $M$ that vanish on $Q$ and $X_q$ and $Y_q$ are in $T_qQ$ . So, I thought that I was done, but my instructor said that this doesn't prove that $[X, Y]_q\in T_qQ$ . I don't really understand why, could anyone please explain this to me?","Let be a smooth manifold and let be a submanifold of . Consider two vector fields such that for every . Prove that for every . So, I came across the following proposition in Lee's ""Introduction to Smooth Manifold"": Proposition 8.22. Let be a smooth manifold, be an embedded manifold with or without boundary, and be a smooth vector field on . Then is tangent to if and only if for every such that . Thus, I thought that I have to show that, for such that , we have . But because and are smooth functions on that vanish on and and are in . So, I thought that I was done, but my instructor said that this doesn't prove that . I don't really understand why, could anyone please explain this to me?","M Q M X, Y \in \mathfrak{X}(M) X_q, Y_q\in T_qQ q\in Q [X, Y]_q\in T_qQ q\in Q M S\subseteq M X M X S (Xf)|_S=0 f\in C^\infty(M) f|_S\equiv0 f\in C^\infty(M) f|_Q=0 [X, Y]_q(f)=0 [X, Y]_q(f)=X_q(Y(f))-Y_q(X(f))=0 Y(f) X(f) M Q X_q Y_q T_qQ [X, Y]_q\in T_qQ","['differential-geometry', 'vector-fields', 'lie-derivative']"
5,'Tensor Calculus' by J.L. Synge and A. Schild (1979 Dover publication) . Exercise 12 page 110.,'Tensor Calculus' by J.L. Synge and A. Schild (1979 Dover publication) . Exercise 12 page 110.,,"I'm solving all the exercises  of 'Tensor Calculus' by J.L. Synge and A. Schild (1979 Dover publication) . Till now everything went smooth, but now I'm stuck at exercise 12. page 110 of the third chapter on 'Curvature'. The exercise is stated as Prove that the quantities $$G^{mn}+ \frac{1}{2a}\frac{\delta^2}{\delta x^x \delta x^s}\left[ a \left( a^{mn}a^{rs}-a^{mr}a^{ns} \right)\right]$$ can be expressed in terms of the metric tensor and its first derivatives. First, there must  be a typo error as $\delta x^x $ in $\frac{\delta^2}{\delta x^x \delta x^s}$ makes no sense. So I guess this must be $\frac{\delta^2}{\delta x^r \delta x^s}$ . Secondly, and that is my first question, it seems odd to me that the authors use  the absolute derivative symbol  in this expression. That does not make sense to me and I suppose they mean the covariant derivative instead. So the expression (sorry, I use the notational convention of the book and not the more modern one with $\nabla$ or $;$ ) should be $G^{mn}+ \frac{1}{2a}\left[ a \left( a^{mn}a^{rs}-a^{mr}a^{ns} \right)\right]_{|rs}$ . Am I right? Second question. Does someone know why the author chose this expression? Is it used somewhere in general relativity or physics in general? The pattern in the second term suggest remotely a connection with the Riemannian curvature ... Third question, does any one know the best approach to tackle the exercise? I made a lot of attempts but always get  stuck. Probably I got blind sighted and I'm turning around in the same wrong logic... For those interested, here's my best shot, which leads to ... nothing $$\blacklozenge$$ Let's define \begin{align} K^{mn} &\equiv \frac{1}{2a}\frac{\delta^2}{\delta x^r \delta x^s}\left[ a \left( a^{mn}a^{rs}-a^{mr}a^{ns} \right)\right]\\ T^{mn} &\equiv G^{mn}+ K^{mn} \end{align} The strategy to proof this, is to separate in both terms of the expression, the parts that can be expressed in $a_{ij}, a^{ij}, \partial_k a_{ij}, \partial_k a^{ij}$ and the parts of higher order differentiation. We begin with the second term. As the covariant derivatives of the metric tensor vanish, we get \begin{align} K^{mn} &=\frac{1}{2a}\left[ a \left( a^{mn}a^{rs}-a^{mr}a^{ns} \right)\right] _{|rs}\\ &= \frac{1}{2a}\left[ a_{|r} \left( a^{mn}a^{rs}-a^{mr}a^{ns} \right)+ a \underbrace{\left( a^{mn}a^{rs}-a^{mr}a^{ns} \right)_{|r}}_{=0}\right] _{|s}\\ &= \frac{1}{2a}\left[ a_{|r} \left( a^{mn}a^{rs}-a^{mr}a^{ns} \right)\right] _{|s}\\ &= \frac{1}{2a}\left[ \underbrace{a_{|rs}}_{=\partial^2_{rs} a} \left( a^{mn}a^{rs}-a^{mr}a^{ns} \right)+a_{|r} \underbrace{\left( a^{mn}a^{rs}-a^{mr}a^{ns} \right)_{|s}}_{=0} \right] \end{align} Considering, \begin{align} \partial^2_{rs} \ln a&= \partial_s \left(\frac{1}{a}\partial_r a\right)\\ &= \frac{1}{a}\partial^2_{rs}a-\frac{1}{a^2}\partial_r a\partial_s a\\ \Rightarrow\quad \frac{1}{a}\partial^2_{rs}a &= \partial^2_{rs} \ln a+ \frac{1}{a^2}\partial_r a\partial_s a \end{align} \begin{align} \Rightarrow \quad K^{mn} &= \frac{1}{2}\left( a^{mn}a^{rs}-a^{mr}a^{ns} \right)\partial^2_{rs}\ln a+\mathcal{E}^{mn}  \end{align} with $\mathcal{E}^{mn}$ being a function in $a_{ij}, a^{ij}, \partial_k a_{ij}, \partial_k a^{ij}$ only. Note that $\mathcal{E}^{mn}$ is a symmetrical object in $m,n$ . Indeed, \begin{align} \mathcal{E}^{mn} &= \frac{1}{2a^2}\left( a^{mn}a^{rs}-a^{mr}a^{ns} \right)\partial_r a\partial_s a\\ \Rightarrow\quad \mathcal{E}^{nm} &= \frac{1}{2a^2}\left( a^{nm}a^{rs}-a^{nr}a^{ms} \right)\partial_r a\partial_s a\\ &= \frac{1}{2a^2}\left( a^{mn}a^{sr}-a^{ns}a^{mr} \right)\partial_s a\partial_r a\\ &= \mathcal{E}^{mn} \end{align} We now rewrite $G^{mn}$ . We have: \begin{align} G^{mn} &= a^{nk}G^m_{. \ k}\\ G^m_{. \ k} &= R^m_{. \ k}-\frac{1}{2}\delta^m_k R\\ R^m_{. \ k} &= a^{mp} R_{pk}\\ R &= a^{pk}R_{pk} \end{align} And by $3.205.$ \begin{align} R_{pk} = \frac{1}{2} \partial^2_{pk} \ln a -  \partial_t \Gamma^t_{pk} + \mathcal{F}^{pk} \end{align} With $\mathcal{F}^{pk}$ a function in $a_{ij}, a^{ij}, \partial_k a_{ij}, \partial_k a^{ij}$ only. Note that $\mathcal{F}^{pk}$ is a symmetrical object in $p,k$ as $R_{pk}$ is a symmetrical tensor in $p,k$ . Hence by $(15)$ to $(19)$ : \begin{align} G^{mn} &= a^{nk} R^m_{. \ k}-\frac{1}{2} a^{nk}\delta^m_k R \\ &=  a^{nk} a^{mp} R_{pk}-\frac{1}{2} a^{nm}a^{pk}R_{pk} \\ &=  \left( a^{nk} a^{mp} -\frac{1}{2} a^{nm}a^{pk}\right)R_{pk} \\ &=  \left( a^{nk} a^{mp} -\frac{1}{2} a^{nm}a^{pk}\right)\left(\frac{1}{2} \partial^2_{pk} \ln a -  \partial_t \Gamma^t_{pk} + \mathcal{F}^{pk}\right) \\ &=  \left( a^{nk} a^{mp} -\frac{1}{2} a^{nm}a^{pk}\right)\left(\frac{1}{2} \partial^2_{pk} \ln a -  \partial_t \Gamma^t_{pk} \right)+ \mathcal{H}^{mn}\\ &= \left[ \frac{1}{2} a^{nk}a^{mp}\partial^2_{pk} \ln a -  a^{nk}a^{mp}\partial_t \Gamma^t_{pk} -\frac{1}{4} a^{nm} a^{pk} \partial^2_{pk} \ln a +\frac{1}{2} a^{nm} a^{pk}  \partial_t \Gamma^t_{pk} \right]+ \mathcal{H}^{mn} \end{align} with $\mathcal{H}^{mn}$ a function in $a_{ij}, a^{ij}, \partial_k a_{ij}, \partial_k a^{ij}$ only. Note that $\mathcal{H}^{mn}$ is a symmetrical object in $m,n$ . Indeed, \begin{align} \mathcal{H}^{mn} &= \left( a^{nk} a^{mp} -\frac{1}{2} a^{nm}a^{pk}\right)\mathcal{F}^{pk}\\ \Rightarrow\quad \mathcal{H}^{nm} &= \left( a^{mk} a^{np} -\frac{1}{2} a^{mn}a^{pk}\right)\mathcal{F}^{pk}\\ &= \left( a^{mp} a^{nk} -\frac{1}{2} a^{mn}a^{kp}\right)\mathcal{F}^{kp}\\ &= \mathcal{H}^{mn} \end{align} Putting $(10)$ and $(2)$ together with $\mathcal{L}^{mn}=\mathcal{E}^{mn}+ \mathcal{H}^{mn}$ we get, \begin{align} T^{mn} &= Q^{mn}+\mathcal{L}^{mn} \end{align} with $\mathcal{L}^{mn}$ a symmetrical object in $m,n$ and depending only on terms in $a_{ij}, a^{ij}, \partial_k a_{ij}, \partial_k a^{ij}$ and \begin{align}  Q^{mn} &\equiv \left\{ \begin{array}{l} \frac{1}{2} a^{nr}a^{ms}\partial^2_{rs} \ln a -  a^{nr}a^{ms}\partial_t \Gamma^t_{rs}\\\\ -\frac{1}{4} a^{nm} a^{rs} \partial^2_{rs} \ln a +\frac{1}{2} a^{nm} a^{rs}  \partial_t \Gamma^t_{rs}\\\\+\frac{1}{2} a^{mn}a^{rs}\partial^2_{rs}\ln a-\frac{1}{2} a^{mr}a^{ns} \partial^2_{rs}\ln a\\\\ \end{array} \right. \\ &= \frac{1}{4} a^{mn}a^{rs}\partial^2_{rs}\ln a + \left( \frac{1}{2} a^{mn}a^{rs}- a^{ms}a^{nr}\right)\partial_t \Gamma^t_{rs} \end{align} Note that \begin{align}  Q^{nm} &= \frac{1}{4} a^{nm}a^{rs}\partial^2_{rs}\ln a + \left( \frac{1}{2} a^{nm}a^{rs}- a^{ns}a^{mr}\right)\partial_t \Gamma^t_{rs} \\ &= \frac{1}{4} a^{mn}a^{rs}\partial^2_{rs}\ln a + \left( \frac{1}{2} a^{mn}a^{rs}- a^{nr}a^{ms}\right)\partial_t \Gamma^t_{sr} \\ &= Q^{mn}  \end{align} So $Q^{mn} $ is a symmetrical object in $m,n$ Given that by $(2.541.)$ , \begin{align} \partial^2_{rs} \ln a &= \partial_{s} \partial_r \ln a \\ &= \partial_{s} \left(a^{kt}\partial_r a_{kt}\right)\\ &= \partial_{s} a^{kt}\partial_{r} a_{kt}+a^{kt}\partial^2_{rs} a_{kt}  \end{align} $(32)$ can be written as \begin{align} Q^{mn} &= \mathcal{P}^{mn}+ \mathcal{Z}^{mn} \end{align} with $\mathcal{Z}^{mn} = \frac{1}{4} a^{mn}a^{rs}\partial_{s} a^{kt}\partial_{r} a_{kt}$ a symmetric object in $m,n$ and depending only on terms in $a_{ij}, a^{ij}, \partial_k a_{ij}, \partial_k a^{ij}$ and \begin{align} \mathcal{P}^{mn} = \frac{1}{4} a^{mn}a^{rs}a^{kt}\partial^2_{rs} a_{kt} + \left( \frac{1}{2} a^{mn}a^{rs}- a^{ms}a^{nr}\right)\partial_t \Gamma^t_{rs} \end{align} Expanding the Christoffel symbols and playing with the dummy indices, gives \begin{align} \mathcal{P}^{mn} &= \left\{\begin{array}{l}\frac{1}{4} a^{mn}a^{rs}a^{kt}\partial^2_{rs} a_{kt} \\\\ + \left( \frac{1}{2} a^{mn}a^{rs}- a^{ms}a^{nr}\right)\left( [rs,k]\partial_t a^{tk}+ a^{kt}\partial_t[rs,k]\right) \end{array}\right.\\ &= \frac{1}{2} \mathcal{V}^{mn}  +\mathcal{A}^{mn} \end{align} with \begin{align} \mathcal{A}^{mn} &= \left( \frac{1}{2} a^{mn}a^{rs}- a^{ms}a^{nr}\right) [rs,k]\partial_t a^{tk} \end{align} and \begin{align} \frac{1}{2} \mathcal{V}_{mn} &= \left\{\begin{array}{l} \frac{1}{4} a^{mn}a^{rs}a^{kt}\partial^2_{rs} a_{kt} \\\\ + \left( \frac{1}{4} a^{mn}a^{rs} a^{kt}- \frac{1}{2} a^{ms}a^{nr} a^{kt}\right)\left( \partial^2_{tr}a_{sk}+\partial^2_{ts}a_{rk}-\partial^2_{tk}a_{rs}\right) \end{array}\right.\\ &= \left\{\begin{array}{l} \underline{\frac{1}{4} a^{mn}a^{rs}a^{kt}\partial^2_{rs} a_{kt} } + \underbrace{\frac{1}{4} a^{mn}a^{rs} a^{kt} \partial^2_{tr}a_{sk}+ \frac{1}{4} a^{mn}a^{rs} a^{kt} \partial^2_{ts}a_{rk}}_{= \frac{1}{2} a^{mn}a^{rs} a^{kt} \partial^2_{tr}a_{sk}} - \underline{\frac{1}{4} a^{mn}a^{rs} a^{kt} \partial^2_{tk}a_{rs}}\\\\ - \frac{1}{2} a^{ms}a^{nr} a^{kt} \partial^2_{tr}a_{sk} - \frac{1}{2} a^{ms}a^{nr} a^{kt} \partial^2_{ts}a_{rk} + \frac{1}{2} a^{ms}a^{nr} a^{kt} \partial^2_{tk}a_{rs}\\ \end{array}\right. \end{align} giving \begin{align} \mathcal{V}_{mn} &=  a^{mn}a^{rs} a^{kt} \partial^2_{tr}a_{sk} -  a^{ms}a^{nr} a^{kt} \partial^2_{tr}a_{sk} -  a^{ms}a^{nr} a^{kt} \partial^2_{ts}a_{rk} +  a^{ms}a^{nr} a^{kt} \partial^2_{tk}a_{rs} \end{align} Playing with the dummy indices, gives \begin{align} \mathcal{V}_{mn} &=  \left(    a^{mn}a^{rs} a^{kt}  -  a^{mk}a^{nr} a^{st} -  a^{mt}a^{ns} a^{kr}  +  a^{ms}a^{nk} a^{rt} \right)\partial^2_{rt}a_{ks} \end{align} Does $\mathcal{V}_{mn}$ vanish ?! And here I'm stuck, ...","I'm solving all the exercises  of 'Tensor Calculus' by J.L. Synge and A. Schild (1979 Dover publication) . Till now everything went smooth, but now I'm stuck at exercise 12. page 110 of the third chapter on 'Curvature'. The exercise is stated as Prove that the quantities can be expressed in terms of the metric tensor and its first derivatives. First, there must  be a typo error as in makes no sense. So I guess this must be . Secondly, and that is my first question, it seems odd to me that the authors use  the absolute derivative symbol  in this expression. That does not make sense to me and I suppose they mean the covariant derivative instead. So the expression (sorry, I use the notational convention of the book and not the more modern one with or ) should be . Am I right? Second question. Does someone know why the author chose this expression? Is it used somewhere in general relativity or physics in general? The pattern in the second term suggest remotely a connection with the Riemannian curvature ... Third question, does any one know the best approach to tackle the exercise? I made a lot of attempts but always get  stuck. Probably I got blind sighted and I'm turning around in the same wrong logic... For those interested, here's my best shot, which leads to ... nothing Let's define The strategy to proof this, is to separate in both terms of the expression, the parts that can be expressed in and the parts of higher order differentiation. We begin with the second term. As the covariant derivatives of the metric tensor vanish, we get Considering, with being a function in only. Note that is a symmetrical object in . Indeed, We now rewrite . We have: And by With a function in only. Note that is a symmetrical object in as is a symmetrical tensor in . Hence by to : with a function in only. Note that is a symmetrical object in . Indeed, Putting and together with we get, with a symmetrical object in and depending only on terms in and Note that So is a symmetrical object in Given that by , can be written as with a symmetric object in and depending only on terms in and Expanding the Christoffel symbols and playing with the dummy indices, gives with and giving Playing with the dummy indices, gives Does vanish ?! And here I'm stuck, ...","G^{mn}+ \frac{1}{2a}\frac{\delta^2}{\delta x^x \delta x^s}\left[ a \left( a^{mn}a^{rs}-a^{mr}a^{ns} \right)\right] \delta x^x  \frac{\delta^2}{\delta x^x \delta x^s} \frac{\delta^2}{\delta x^r \delta x^s} \nabla ; G^{mn}+ \frac{1}{2a}\left[ a \left( a^{mn}a^{rs}-a^{mr}a^{ns} \right)\right]_{|rs} \blacklozenge \begin{align}
K^{mn} &\equiv \frac{1}{2a}\frac{\delta^2}{\delta x^r \delta x^s}\left[ a \left( a^{mn}a^{rs}-a^{mr}a^{ns} \right)\right]\\
T^{mn} &\equiv G^{mn}+ K^{mn}
\end{align} a_{ij}, a^{ij}, \partial_k a_{ij}, \partial_k a^{ij} \begin{align}
K^{mn} &=\frac{1}{2a}\left[ a \left( a^{mn}a^{rs}-a^{mr}a^{ns} \right)\right] _{|rs}\\
&= \frac{1}{2a}\left[ a_{|r} \left( a^{mn}a^{rs}-a^{mr}a^{ns} \right)+ a \underbrace{\left( a^{mn}a^{rs}-a^{mr}a^{ns} \right)_{|r}}_{=0}\right] _{|s}\\
&= \frac{1}{2a}\left[ a_{|r} \left( a^{mn}a^{rs}-a^{mr}a^{ns} \right)\right] _{|s}\\
&= \frac{1}{2a}\left[ \underbrace{a_{|rs}}_{=\partial^2_{rs} a} \left( a^{mn}a^{rs}-a^{mr}a^{ns} \right)+a_{|r} \underbrace{\left( a^{mn}a^{rs}-a^{mr}a^{ns} \right)_{|s}}_{=0} \right]
\end{align} \begin{align}
\partial^2_{rs} \ln a&= \partial_s \left(\frac{1}{a}\partial_r a\right)\\
&= \frac{1}{a}\partial^2_{rs}a-\frac{1}{a^2}\partial_r a\partial_s a\\
\Rightarrow\quad \frac{1}{a}\partial^2_{rs}a &= \partial^2_{rs} \ln a+ \frac{1}{a^2}\partial_r a\partial_s a
\end{align} \begin{align}
\Rightarrow \quad K^{mn} &= \frac{1}{2}\left( a^{mn}a^{rs}-a^{mr}a^{ns} \right)\partial^2_{rs}\ln a+\mathcal{E}^{mn} 
\end{align} \mathcal{E}^{mn} a_{ij}, a^{ij}, \partial_k a_{ij}, \partial_k a^{ij} \mathcal{E}^{mn} m,n \begin{align}
\mathcal{E}^{mn} &= \frac{1}{2a^2}\left( a^{mn}a^{rs}-a^{mr}a^{ns} \right)\partial_r a\partial_s a\\
\Rightarrow\quad \mathcal{E}^{nm} &= \frac{1}{2a^2}\left( a^{nm}a^{rs}-a^{nr}a^{ms} \right)\partial_r a\partial_s a\\
&= \frac{1}{2a^2}\left( a^{mn}a^{sr}-a^{ns}a^{mr} \right)\partial_s a\partial_r a\\
&= \mathcal{E}^{mn}
\end{align} G^{mn} \begin{align}
G^{mn} &= a^{nk}G^m_{. \ k}\\
G^m_{. \ k} &= R^m_{. \ k}-\frac{1}{2}\delta^m_k R\\
R^m_{. \ k} &= a^{mp} R_{pk}\\
R &= a^{pk}R_{pk}
\end{align} 3.205. \begin{align}
R_{pk} = \frac{1}{2} \partial^2_{pk} \ln a -  \partial_t \Gamma^t_{pk} + \mathcal{F}^{pk}
\end{align} \mathcal{F}^{pk} a_{ij}, a^{ij}, \partial_k a_{ij}, \partial_k a^{ij} \mathcal{F}^{pk} p,k R_{pk} p,k (15) (19) \begin{align}
G^{mn} &= a^{nk} R^m_{. \ k}-\frac{1}{2} a^{nk}\delta^m_k R \\
&=  a^{nk} a^{mp} R_{pk}-\frac{1}{2} a^{nm}a^{pk}R_{pk} \\
&=  \left( a^{nk} a^{mp} -\frac{1}{2} a^{nm}a^{pk}\right)R_{pk} \\
&=  \left( a^{nk} a^{mp} -\frac{1}{2} a^{nm}a^{pk}\right)\left(\frac{1}{2} \partial^2_{pk} \ln a -  \partial_t \Gamma^t_{pk} + \mathcal{F}^{pk}\right) \\
&=  \left( a^{nk} a^{mp} -\frac{1}{2} a^{nm}a^{pk}\right)\left(\frac{1}{2} \partial^2_{pk} \ln a -  \partial_t \Gamma^t_{pk} \right)+ \mathcal{H}^{mn}\\
&= \left[ \frac{1}{2} a^{nk}a^{mp}\partial^2_{pk} \ln a -  a^{nk}a^{mp}\partial_t \Gamma^t_{pk} -\frac{1}{4} a^{nm} a^{pk} \partial^2_{pk} \ln a +\frac{1}{2} a^{nm} a^{pk}  \partial_t \Gamma^t_{pk} \right]+ \mathcal{H}^{mn}
\end{align} \mathcal{H}^{mn} a_{ij}, a^{ij}, \partial_k a_{ij}, \partial_k a^{ij} \mathcal{H}^{mn} m,n \begin{align}
\mathcal{H}^{mn} &= \left( a^{nk} a^{mp} -\frac{1}{2} a^{nm}a^{pk}\right)\mathcal{F}^{pk}\\
\Rightarrow\quad \mathcal{H}^{nm} &= \left( a^{mk} a^{np} -\frac{1}{2} a^{mn}a^{pk}\right)\mathcal{F}^{pk}\\
&= \left( a^{mp} a^{nk} -\frac{1}{2} a^{mn}a^{kp}\right)\mathcal{F}^{kp}\\
&= \mathcal{H}^{mn}
\end{align} (10) (2) \mathcal{L}^{mn}=\mathcal{E}^{mn}+ \mathcal{H}^{mn} \begin{align}
T^{mn} &= Q^{mn}+\mathcal{L}^{mn}
\end{align} \mathcal{L}^{mn} m,n a_{ij}, a^{ij}, \partial_k a_{ij}, \partial_k a^{ij} \begin{align}
 Q^{mn} &\equiv \left\{ \begin{array}{l}
\frac{1}{2} a^{nr}a^{ms}\partial^2_{rs} \ln a -  a^{nr}a^{ms}\partial_t \Gamma^t_{rs}\\\\ -\frac{1}{4} a^{nm} a^{rs} \partial^2_{rs} \ln a
+\frac{1}{2} a^{nm} a^{rs}  \partial_t \Gamma^t_{rs}\\\\+\frac{1}{2} a^{mn}a^{rs}\partial^2_{rs}\ln a-\frac{1}{2} a^{mr}a^{ns} \partial^2_{rs}\ln a\\\\
\end{array} \right. \\
&= \frac{1}{4} a^{mn}a^{rs}\partial^2_{rs}\ln a + \left( \frac{1}{2} a^{mn}a^{rs}- a^{ms}a^{nr}\right)\partial_t \Gamma^t_{rs}
\end{align} \begin{align}
 Q^{nm} &= \frac{1}{4} a^{nm}a^{rs}\partial^2_{rs}\ln a + \left( \frac{1}{2} a^{nm}a^{rs}- a^{ns}a^{mr}\right)\partial_t \Gamma^t_{rs} \\
&= \frac{1}{4} a^{mn}a^{rs}\partial^2_{rs}\ln a + \left( \frac{1}{2} a^{mn}a^{rs}- a^{nr}a^{ms}\right)\partial_t \Gamma^t_{sr} \\
&= Q^{mn} 
\end{align} Q^{mn}  m,n (2.541.) \begin{align}
\partial^2_{rs} \ln a &= \partial_{s} \partial_r \ln a \\
&= \partial_{s} \left(a^{kt}\partial_r a_{kt}\right)\\
&= \partial_{s} a^{kt}\partial_{r} a_{kt}+a^{kt}\partial^2_{rs} a_{kt} 
\end{align} (32) \begin{align}
Q^{mn} &= \mathcal{P}^{mn}+ \mathcal{Z}^{mn}
\end{align} \mathcal{Z}^{mn} = \frac{1}{4} a^{mn}a^{rs}\partial_{s} a^{kt}\partial_{r} a_{kt} m,n a_{ij}, a^{ij}, \partial_k a_{ij}, \partial_k a^{ij} \begin{align}
\mathcal{P}^{mn} = \frac{1}{4} a^{mn}a^{rs}a^{kt}\partial^2_{rs} a_{kt} + \left( \frac{1}{2} a^{mn}a^{rs}- a^{ms}a^{nr}\right)\partial_t \Gamma^t_{rs}
\end{align} \begin{align}
\mathcal{P}^{mn} &= \left\{\begin{array}{l}\frac{1}{4} a^{mn}a^{rs}a^{kt}\partial^2_{rs} a_{kt} \\\\
+ \left( \frac{1}{2} a^{mn}a^{rs}- a^{ms}a^{nr}\right)\left( [rs,k]\partial_t a^{tk}+ a^{kt}\partial_t[rs,k]\right)
\end{array}\right.\\
&= \frac{1}{2} \mathcal{V}^{mn}  +\mathcal{A}^{mn}
\end{align} \begin{align}
\mathcal{A}^{mn} &= \left( \frac{1}{2} a^{mn}a^{rs}- a^{ms}a^{nr}\right) [rs,k]\partial_t a^{tk}
\end{align} \begin{align}
\frac{1}{2} \mathcal{V}_{mn} &= \left\{\begin{array}{l}
\frac{1}{4} a^{mn}a^{rs}a^{kt}\partial^2_{rs} a_{kt} \\\\
+ \left( \frac{1}{4} a^{mn}a^{rs} a^{kt}- \frac{1}{2} a^{ms}a^{nr} a^{kt}\right)\left( \partial^2_{tr}a_{sk}+\partial^2_{ts}a_{rk}-\partial^2_{tk}a_{rs}\right)
\end{array}\right.\\
&= \left\{\begin{array}{l}
\underline{\frac{1}{4} a^{mn}a^{rs}a^{kt}\partial^2_{rs} a_{kt} }
+ \underbrace{\frac{1}{4} a^{mn}a^{rs} a^{kt} \partial^2_{tr}a_{sk}+ \frac{1}{4} a^{mn}a^{rs} a^{kt} \partial^2_{ts}a_{rk}}_{= \frac{1}{2} a^{mn}a^{rs} a^{kt} \partial^2_{tr}a_{sk}}
- \underline{\frac{1}{4} a^{mn}a^{rs} a^{kt} \partial^2_{tk}a_{rs}}\\\\
- \frac{1}{2} a^{ms}a^{nr} a^{kt} \partial^2_{tr}a_{sk}
- \frac{1}{2} a^{ms}a^{nr} a^{kt} \partial^2_{ts}a_{rk}
+ \frac{1}{2} a^{ms}a^{nr} a^{kt} \partial^2_{tk}a_{rs}\\
\end{array}\right.
\end{align} \begin{align}
\mathcal{V}_{mn} &=
 a^{mn}a^{rs} a^{kt} \partial^2_{tr}a_{sk}
-  a^{ms}a^{nr} a^{kt} \partial^2_{tr}a_{sk}
-  a^{ms}a^{nr} a^{kt} \partial^2_{ts}a_{rk}
+  a^{ms}a^{nr} a^{kt} \partial^2_{tk}a_{rs}
\end{align} \begin{align}
\mathcal{V}_{mn} &=
 \left(
   a^{mn}a^{rs} a^{kt} 
-  a^{mk}a^{nr} a^{st}
-  a^{mt}a^{ns} a^{kr} 
+  a^{ms}a^{nk} a^{rt} \right)\partial^2_{rt}a_{ks}
\end{align} \mathcal{V}_{mn}","['differential-geometry', 'vector-analysis', 'tensors']"
6,Clifford algebra and Spin,Clifford algebra and Spin,,"I am reading Riemannian Geometry and Geometric Analysis by Jurgen Jost. Let me mention the notations and what I have learned from the book. In the book, the Clifford algebra $Cl(V)$ of a real vector field $V$ is defined to be the quotient of the tensor algebra $\bigoplus_{k\ge0} \bigotimes^k V$ by the two-sided ideal generated by elements of the form $v \otimes v + \langle v,v \rangle$ . The spin group $Spin(V)$ is defined as all elements of the form $$a = a_1...a_{2k} \text{ with } a_i \in V \text{, }\left\Vert a_i \right\Vert = 1 \text{ for } i = 1,...,2k $$ The chirality operator is $\Gamma = i^m e_1...e_n \in Cl^\mathbb{C}(V)$ where the upperscript $\mathbb{C}$ is the complexification, $m = \frac{n}{2} = \frac{dim_\mathbb{R}V}{2}$ and $e_i$ is an positive orthonormal basis (I am only interested in even dimensional case). Since $\Gamma^2 = 1$ , we may use $\Gamma$ to obtain a decomposition $Cl^\mathbb{C}(V)^\pm$ of $Cl^\mathbb{C}(V)$ into eigenspaces with eigenvalues $\pm 1$ under the multiplication of $\Gamma$ . Theorem 2.6.4 tells us that $Cl^\mathbb{C}(V)$ is isomorphic to the algebra of complex linear endomorphisms of the spinor space $S = \bigwedge W$ . Under the isomorphism, $\Gamma$ equals $(-1)^k$ on $\bigwedge^k W$ so that we have the decomposition $$ S^\pm = {\bigwedge}^\pm W $$ where the +(-) sign on the right denotes elements of even (odd) degree. I understand the material so far, but cannot see why this statement is true: Since $Spin(V)\subset Cl^+(V)$ , $Spin(V)$ leaves the space $S^+$ and $S^-$ invariant. I am thinking that for example, $e_1e_2\in Spin(V)$ , but $\Gamma (e_1e_2) = (e_2e_1)\Gamma = i^m e_3...e_n $ ; Then why do we have the containment $Spin(V)\subset Cl^+(V)$ ? Do I misunderstand something? Even if we have the containment, why the spin group leaves $S^\pm \subset S$ invariant? This is my first time seeing the Clifford algebra and representation, so I appreciate any relevant material for self-study.","I am reading Riemannian Geometry and Geometric Analysis by Jurgen Jost. Let me mention the notations and what I have learned from the book. In the book, the Clifford algebra of a real vector field is defined to be the quotient of the tensor algebra by the two-sided ideal generated by elements of the form . The spin group is defined as all elements of the form The chirality operator is where the upperscript is the complexification, and is an positive orthonormal basis (I am only interested in even dimensional case). Since , we may use to obtain a decomposition of into eigenspaces with eigenvalues under the multiplication of . Theorem 2.6.4 tells us that is isomorphic to the algebra of complex linear endomorphisms of the spinor space . Under the isomorphism, equals on so that we have the decomposition where the +(-) sign on the right denotes elements of even (odd) degree. I understand the material so far, but cannot see why this statement is true: Since , leaves the space and invariant. I am thinking that for example, , but ; Then why do we have the containment ? Do I misunderstand something? Even if we have the containment, why the spin group leaves invariant? This is my first time seeing the Clifford algebra and representation, so I appreciate any relevant material for self-study.","Cl(V) V \bigoplus_{k\ge0} \bigotimes^k V v \otimes v + \langle v,v \rangle Spin(V) a = a_1...a_{2k} \text{ with } a_i \in V \text{, }\left\Vert a_i \right\Vert = 1 \text{ for } i = 1,...,2k  \Gamma = i^m e_1...e_n \in Cl^\mathbb{C}(V) \mathbb{C} m = \frac{n}{2} = \frac{dim_\mathbb{R}V}{2} e_i \Gamma^2 = 1 \Gamma Cl^\mathbb{C}(V)^\pm Cl^\mathbb{C}(V) \pm 1 \Gamma Cl^\mathbb{C}(V) S = \bigwedge W \Gamma (-1)^k \bigwedge^k W  S^\pm = {\bigwedge}^\pm W  Spin(V)\subset Cl^+(V) Spin(V) S^+ S^- e_1e_2\in Spin(V) \Gamma (e_1e_2) = (e_2e_1)\Gamma = i^m e_3...e_n  Spin(V)\subset Cl^+(V) S^\pm \subset S","['differential-geometry', 'riemannian-geometry', 'clifford-algebras', 'spin-geometry']"
7,Any fibration of $S^3$ by simple closed curves must have base space $S^2$ and be equivalent to the Hopf-fibration.,Any fibration of  by simple closed curves must have base space  and be equivalent to the Hopf-fibration.,S^3 S^2,"I am currently reading Great Circle Fibrations of the Three-Sphere by Gluck and Warner since I am very interested in the Hopf-fibration. In particular I'm looking for properties which make it special, so this caught my eye. In the introduction, the authors remark that Any fibration of $S^3$ by simple closed curves must have base space a two-sphere and, as is well known [S], must be equivalent to the Hopf-fibration. Sadly, the reference, Steenrod's The Topology of Fibre Bundles , isn't available through my university library or any of its partners. Since this is ""well known"", I was hoping that someone could perhaps outline a proof, reference a theorem/construct which can be used to prove this fact, or another source in which a proof could be found.","I am currently reading Great Circle Fibrations of the Three-Sphere by Gluck and Warner since I am very interested in the Hopf-fibration. In particular I'm looking for properties which make it special, so this caught my eye. In the introduction, the authors remark that Any fibration of by simple closed curves must have base space a two-sphere and, as is well known [S], must be equivalent to the Hopf-fibration. Sadly, the reference, Steenrod's The Topology of Fibre Bundles , isn't available through my university library or any of its partners. Since this is ""well known"", I was hoping that someone could perhaps outline a proof, reference a theorem/construct which can be used to prove this fact, or another source in which a proof could be found.",S^3,"['differential-geometry', 'algebraic-topology', 'fiber-bundles']"
8,Sections of a polar action are totally geodesic,Sections of a polar action are totally geodesic,,"Suppose $G\curvearrowright M$ is an isometric action of a Lie group on a complete Riemannian manifold $M$ , and assume it is polar. This means that the action is proper and there exists a closed (hence complete) embedded submanifold $\Sigma\subseteq M$ (called a section) which meets all orbits orthogonally. It is well known that $\Sigma$ is totally geodesic, but I have not found a convincing proof of that fact. There is a special case where the last statement is easy to prove: the second fundamental form vanishes at regular (and exceptional) points. Indeed, given any $p\in \Sigma$ such that $G\cdot p$ has maximal dimension, $v\in T_{p}(\Sigma)=T_{p}(G\cdot p)$ and $\xi\in T_{p}(G\cdot p)$ , we can find an element $X$ in the Lie algebra $\mathfrak{g}$ of $G$ such that $$\xi=X^{*}(p), \quad X^{*}(q)=\dfrac{d}{dt}\bigg|_{t=0}\operatorname{Exp}(tX)\cdot q.$$ The vector field $X^{*}$ is Killing, so that its covariant derivative is antisymmetric. Let $\mathbb{II}$ be the second fundamental form of $\Sigma$ . Then $\mathbb{II}(v,v)$ is tangent to $G\cdot p$ and $\langle \mathbb{II}(v,v),\xi \rangle=-\langle v,\nabla_{v}X^{*} \rangle=0$ , so $\mathbb{II}(v,v)=0$ . Polarizing, we get $\mathbb{II}=0$ . The usual argument for proving that sections are totally geodesic at all points revolves around the fact that regular points are dense in $\Sigma$ . My problem is that all proofs that I found seem to lack crucial details for it. Here are some examples: In ""Lie Groups and Geometric Aspects of Isometric Actions"", by Alexandrino and Bettiol, it is stated in Exercise 4.9 that the density follows from Kleiner's Lemma (cf Lemma 3.70), but I can't get the connection between the lemma and this fact. In ""Critical Point Theory and Submanifold Geometry"", by Palais and Terng, the authors state that density follows from the theory of Riemannian submersions, without giving further details. In ""Polar Manifolds and Actions"", by Grove and Ziller, the authors state that singular points are isolated along any geodesic, because of the Slice Theorem. This is because if $\gamma$ is any geodesic of $\Sigma$ , and $t_{0}$ lies in the closure of $\{ t\in \mathbb{R}\colon \gamma(t)\in M_{R} \}$ , then $\gamma(t_{0}-\varepsilon)$ and $\gamma(t_{0}+\varepsilon)$ have the same isotropy for sufficiently small $\varepsilon>0$ (again, because of the Slice Theorem), but I don't understand why this is the case. Could somebody elaborate on any of the methods of proof proposed above (preferably the first or the last), or give a reference to a detailed proof of the fact that regular points are dense? Thank you in advance! EDIT I forgot to mention another method of proof, proposed in the book ""Submanifolds and Holonomy"", by Berndt, Console and Olmos. I have an (almost full) solution, which needs to prove the following crucial fact: if $p\in \Sigma$ and there is an open subset $\Omega\subseteq \Sigma$ such that all orbits of the points in $\Omega$ have the same (nonprincipal) type, then $T_{p}(\Sigma)$ is pointwise fixed by the slice representation. If somebody could give a proof of this last fact, I would also accept it as an answer. EDIT 2 I've decided to repost this question on MathOverflow. If anyone is interested in seeing it, you can find it on https://mathoverflow.net/questions/398008/sections-of-a-polar-action-are-totally-geodesic","Suppose is an isometric action of a Lie group on a complete Riemannian manifold , and assume it is polar. This means that the action is proper and there exists a closed (hence complete) embedded submanifold (called a section) which meets all orbits orthogonally. It is well known that is totally geodesic, but I have not found a convincing proof of that fact. There is a special case where the last statement is easy to prove: the second fundamental form vanishes at regular (and exceptional) points. Indeed, given any such that has maximal dimension, and , we can find an element in the Lie algebra of such that The vector field is Killing, so that its covariant derivative is antisymmetric. Let be the second fundamental form of . Then is tangent to and , so . Polarizing, we get . The usual argument for proving that sections are totally geodesic at all points revolves around the fact that regular points are dense in . My problem is that all proofs that I found seem to lack crucial details for it. Here are some examples: In ""Lie Groups and Geometric Aspects of Isometric Actions"", by Alexandrino and Bettiol, it is stated in Exercise 4.9 that the density follows from Kleiner's Lemma (cf Lemma 3.70), but I can't get the connection between the lemma and this fact. In ""Critical Point Theory and Submanifold Geometry"", by Palais and Terng, the authors state that density follows from the theory of Riemannian submersions, without giving further details. In ""Polar Manifolds and Actions"", by Grove and Ziller, the authors state that singular points are isolated along any geodesic, because of the Slice Theorem. This is because if is any geodesic of , and lies in the closure of , then and have the same isotropy for sufficiently small (again, because of the Slice Theorem), but I don't understand why this is the case. Could somebody elaborate on any of the methods of proof proposed above (preferably the first or the last), or give a reference to a detailed proof of the fact that regular points are dense? Thank you in advance! EDIT I forgot to mention another method of proof, proposed in the book ""Submanifolds and Holonomy"", by Berndt, Console and Olmos. I have an (almost full) solution, which needs to prove the following crucial fact: if and there is an open subset such that all orbits of the points in have the same (nonprincipal) type, then is pointwise fixed by the slice representation. If somebody could give a proof of this last fact, I would also accept it as an answer. EDIT 2 I've decided to repost this question on MathOverflow. If anyone is interested in seeing it, you can find it on https://mathoverflow.net/questions/398008/sections-of-a-polar-action-are-totally-geodesic","G\curvearrowright M M \Sigma\subseteq M \Sigma p\in \Sigma G\cdot p v\in T_{p}(\Sigma)=T_{p}(G\cdot p) \xi\in T_{p}(G\cdot p) X \mathfrak{g} G \xi=X^{*}(p), \quad X^{*}(q)=\dfrac{d}{dt}\bigg|_{t=0}\operatorname{Exp}(tX)\cdot q. X^{*} \mathbb{II} \Sigma \mathbb{II}(v,v) G\cdot p \langle \mathbb{II}(v,v),\xi \rangle=-\langle v,\nabla_{v}X^{*} \rangle=0 \mathbb{II}(v,v)=0 \mathbb{II}=0 \Sigma \gamma \Sigma t_{0} \{ t\in \mathbb{R}\colon \gamma(t)\in M_{R} \} \gamma(t_{0}-\varepsilon) \gamma(t_{0}+\varepsilon) \varepsilon>0 p\in \Sigma \Omega\subseteq \Sigma \Omega T_{p}(\Sigma)","['differential-geometry', 'group-actions', 'submanifold']"
9,"Uniqueness of geodesics between two points on surface, given metric","Uniqueness of geodesics between two points on surface, given metric",,"For concreteness, let us consider the surface described in this question: it is the graph of $$ z=\sin(x)+\sin(y) $$ The metric on the surface is $$ g=\left( \matrix{1+\cos^2(x) & \cos(x) \cos(y) \\ \cos(x) \cos(y) & 1+\cos^2(y)} \right) $$ I am more physicist than mathematician. I'm familar with GR, but not differential geometry. I'm quite happy finding the Christoffel symbols, curvature tensor, etc. I am aware of a theorem that guarantees unique geodesics at a point and in a given direction , (modulo certain niceties) but I'm interested in uniqueness between two points. In this answer, it seems that there exists a length minimizing geodesic, but not necessarily that it is unique. This answer mentions the Cartan-Hadamard theorem. It seems for a surface, 'sectional curvature'=scalar curvature. For the surface in question $$ R=\frac{8 \sin(x) \sin(y)}{(4+\cos(2x)+\cos(2y))^2} $$ Which oscillates between positive and negative over the surface. Can we apply the theorem to a region of the surface where $R<0$ , and say that for two points within that region, there is a unique length minimizing geodesic? Is there any way to tell if geodesics connecting two given points on  surface are unique? Can this be phrased in terms of: ""requirements for the metric such that there are unique geodesics""? Specifically, I'm asking about 'nice' surfaces like the one here: it doesn't have points removed, and it's smooth (you will undoubtedly shake your head and tell me the correct term to use).","For concreteness, let us consider the surface described in this question: it is the graph of The metric on the surface is I am more physicist than mathematician. I'm familar with GR, but not differential geometry. I'm quite happy finding the Christoffel symbols, curvature tensor, etc. I am aware of a theorem that guarantees unique geodesics at a point and in a given direction , (modulo certain niceties) but I'm interested in uniqueness between two points. In this answer, it seems that there exists a length minimizing geodesic, but not necessarily that it is unique. This answer mentions the Cartan-Hadamard theorem. It seems for a surface, 'sectional curvature'=scalar curvature. For the surface in question Which oscillates between positive and negative over the surface. Can we apply the theorem to a region of the surface where , and say that for two points within that region, there is a unique length minimizing geodesic? Is there any way to tell if geodesics connecting two given points on  surface are unique? Can this be phrased in terms of: ""requirements for the metric such that there are unique geodesics""? Specifically, I'm asking about 'nice' surfaces like the one here: it doesn't have points removed, and it's smooth (you will undoubtedly shake your head and tell me the correct term to use).","
z=\sin(x)+\sin(y)
 
g=\left( \matrix{1+\cos^2(x) & \cos(x) \cos(y) \\ \cos(x) \cos(y) & 1+\cos^2(y)} \right)
 
R=\frac{8 \sin(x) \sin(y)}{(4+\cos(2x)+\cos(2y))^2}
 R<0","['differential-geometry', 'metric-spaces', 'riemannian-geometry']"
10,De Rham Cohomology of Smooth $G$-manifolds,De Rham Cohomology of Smooth -manifolds,G,"Let $M$ be a smooth manifold and let $G$ be a compact, connected Lie Group that acts on $M$ by smoothly. Now suppose that the action of $G$ on $M$ is transitive. For some $m$ in $M$ , let $K$ be the stabiliser of $m$ . It should be clear that $K$ is a closed subgroup of $G$ , so we can associate $G/K$ with $M$ . Let $\mathfrak{g}$ denote Lie Algebra of $G$ and $\mathfrak{r}$ the Lie Algebra of $K$ . Because of compactness of $G$ , it is known that there exists some $Ad(G)$ -invariant and $ad(LG)$ invariant inner-product, say $\langle \ ,\  \rangle$ on $\mathfrak{g}$ , so as a $K$ - module, $\mathfrak{g} = \mathfrak{r} \oplus \mathfrak n $ where $\mathfrak{r}$ and $\mathfrak{n}$ orthogonal with respect to $\langle \ ,\  \rangle$ , and we regard $\mathfrak{n}$ as tangent space $T_m M$ . My question is towards calculating the cohomology of $M$ using exterior power of $\mathfrak{n}$ . Let $\omega$ be a $G$ - invariant differential $p$ - form on $M$ . So evaluating $\omega$ at point $m$ gives us an alternating, multi-linear function $\omega_m: \mathfrak{n}^p \rightarrow \mathbb{R}$ . It is mentioned that because $\omega$ is $G$ - invariant hence $\omega_m$ is $Ad(K)$ invariant, which I presume, means that for any $g \in K$ one has for left invariant vector fields $X_1,\dots, X_p$ : $$\omega_m(Ad(g^{-1})X_1(e),\dots, Ad(g^{-1})X_p(e)) = \omega_m(X_1(e),\dots, X_p(e))$$ I am having some trouble with the computation to convince myself to that this is indeed the case. What I have gotten so far is if we let $L_g$ denote left multiplication by $g$ and $R_g$ denotte multiplication of $g$ and $L{_g} _*$ to denote the pushforward maps, etc. then \begin{align*} \omega_m(Ad(g^{-1})X_1(e),\dots, Ad(g^{-1})X_p(e)) &= \omega_m(L_{g^-1}{_*}R_g{_*}X_1(e),\dots,L_{g^-1}{_*}R_g{_*}X_p(e))\\ &=\omega_{g^{-1}m} (R_g{_*}X_1(e),\dots, R_g{_*}X_p(e)) \end{align*} And I am unable to proceed. Same for the converse case as well i.e. obtaining a $G$ -invariant differential $p$ form from a $Ad(K)$ invariant alternating, multi-linear function $\omega_m: \mathfrak{n}^p \rightarrow \mathbb{R}$ . Do let me know if I have any misconception/misunderstanding. Thanks!","Let be a smooth manifold and let be a compact, connected Lie Group that acts on by smoothly. Now suppose that the action of on is transitive. For some in , let be the stabiliser of . It should be clear that is a closed subgroup of , so we can associate with . Let denote Lie Algebra of and the Lie Algebra of . Because of compactness of , it is known that there exists some -invariant and invariant inner-product, say on , so as a - module, where and orthogonal with respect to , and we regard as tangent space . My question is towards calculating the cohomology of using exterior power of . Let be a - invariant differential - form on . So evaluating at point gives us an alternating, multi-linear function . It is mentioned that because is - invariant hence is invariant, which I presume, means that for any one has for left invariant vector fields : I am having some trouble with the computation to convince myself to that this is indeed the case. What I have gotten so far is if we let denote left multiplication by and denotte multiplication of and to denote the pushforward maps, etc. then And I am unable to proceed. Same for the converse case as well i.e. obtaining a -invariant differential form from a invariant alternating, multi-linear function . Do let me know if I have any misconception/misunderstanding. Thanks!","M G M G M m M K m K G G/K M \mathfrak{g} G \mathfrak{r} K G Ad(G) ad(LG) \langle \ ,\  \rangle \mathfrak{g} K \mathfrak{g} = \mathfrak{r} \oplus \mathfrak n  \mathfrak{r} \mathfrak{n} \langle \ ,\  \rangle \mathfrak{n} T_m M M \mathfrak{n} \omega G p M \omega m \omega_m: \mathfrak{n}^p \rightarrow \mathbb{R} \omega G \omega_m Ad(K) g \in K X_1,\dots, X_p \omega_m(Ad(g^{-1})X_1(e),\dots, Ad(g^{-1})X_p(e)) = \omega_m(X_1(e),\dots, X_p(e)) L_g g R_g g L{_g} _* \begin{align*}
\omega_m(Ad(g^{-1})X_1(e),\dots, Ad(g^{-1})X_p(e)) &= \omega_m(L_{g^-1}{_*}R_g{_*}X_1(e),\dots,L_{g^-1}{_*}R_g{_*}X_p(e))\\
&=\omega_{g^{-1}m} (R_g{_*}X_1(e),\dots, R_g{_*}X_p(e))
\end{align*} G p Ad(K) \omega_m: \mathfrak{n}^p \rightarrow \mathbb{R}","['differential-geometry', 'algebraic-topology', 'lie-groups', 'lie-algebras', 'differential-forms']"
11,Algebraic Geometry as Generalized Calculus?,Algebraic Geometry as Generalized Calculus?,,"I've heard people say that (part of) algebraic geometry deals with generalizing results from differential geometry to fields other than $\mathbb{C}$ . Some searching has brought me to ""GAGA Theorems"", but I don't have anywhere near the background that it looks like I might need to understand those. It seems like this program was started in order to work on the Weil Conjectures, since the computational evidence seemed to point to ""continuous"" theorems (such as the Lefschetz fixed point theorem) being relevant in a ""discrete"" setting. Again, though, I don't have the background to understand even the wikipedia page . I have taken a class in ""classical"" algebraic geometry (using Shaferevich, Vol 1), but it is still unclear to me which aspects of differential geometry were able to be transported, and how. The only analogies that I can see for myself are the definition of an abstract variety (which we barely touched on at the end of my class) being clearly inspired by the definition of an abstract manifold the notion of ""singular"" and ""regular"" points on a curve, which are also clearly inspired by their analogues in differential geometry. I would appreciate it if someone can provide some insight into this program at a level I can understand. I am perfectly happy to see some hand-waving if that helps, but I would also like to see (relatively) concrete examples of ideas in differential geometry being moved to the world of arbitrary fields. Thanks!","I've heard people say that (part of) algebraic geometry deals with generalizing results from differential geometry to fields other than . Some searching has brought me to ""GAGA Theorems"", but I don't have anywhere near the background that it looks like I might need to understand those. It seems like this program was started in order to work on the Weil Conjectures, since the computational evidence seemed to point to ""continuous"" theorems (such as the Lefschetz fixed point theorem) being relevant in a ""discrete"" setting. Again, though, I don't have the background to understand even the wikipedia page . I have taken a class in ""classical"" algebraic geometry (using Shaferevich, Vol 1), but it is still unclear to me which aspects of differential geometry were able to be transported, and how. The only analogies that I can see for myself are the definition of an abstract variety (which we barely touched on at the end of my class) being clearly inspired by the definition of an abstract manifold the notion of ""singular"" and ""regular"" points on a curve, which are also clearly inspired by their analogues in differential geometry. I would appreciate it if someone can provide some insight into this program at a level I can understand. I am perfectly happy to see some hand-waving if that helps, but I would also like to see (relatively) concrete examples of ideas in differential geometry being moved to the world of arbitrary fields. Thanks!",\mathbb{C},['differential-geometry']
12,Product Sphere Curvature Computation,Product Sphere Curvature Computation,,"In Petersen's Riemannian geometry page 118 he computes the curvature operator on the product Riemannian manifold $S^n(1/a) \times S^m(1/b)$ . For my question the fact that it is a product of spheres does not seem relevant - it could be any product manifold. In his computation he lets $Y$ be a unit vector field on $S^n$ , $V$ a unit vector field on $S^n$ and $X$ be a unit vector field on either $S^n$ or $S^m$ that is perpendicular to $Y,V$ . He then computes that $g(\nabla_YX,V) = 0$ via the Koszul formula. This all seems fine to me. The part where I'm having trouble is he then claims that $g(\nabla_YX,V) = 0$ implies that $\nabla_YX = 0$ if $X$ is tangent to $S^m$ and $\nabla_YX$ is tangent to $S^n$ if $X$ is tangent to $S^n$ . I'm not exactly sure how this result follows from $g(\nabla_YX,V) = 0$ ? It seems like maybe he is using the fact that the Levi-Cevita connection for a product manifold is essentially the sum of the respective connections when acting on vectors fields tangent to the manifolds in the product, but if so, why the discussion on $g(\nabla_YX,V) = 0$ ?","In Petersen's Riemannian geometry page 118 he computes the curvature operator on the product Riemannian manifold . For my question the fact that it is a product of spheres does not seem relevant - it could be any product manifold. In his computation he lets be a unit vector field on , a unit vector field on and be a unit vector field on either or that is perpendicular to . He then computes that via the Koszul formula. This all seems fine to me. The part where I'm having trouble is he then claims that implies that if is tangent to and is tangent to if is tangent to . I'm not exactly sure how this result follows from ? It seems like maybe he is using the fact that the Levi-Cevita connection for a product manifold is essentially the sum of the respective connections when acting on vectors fields tangent to the manifolds in the product, but if so, why the discussion on ?","S^n(1/a) \times S^m(1/b) Y S^n V S^n X S^n S^m Y,V g(\nabla_YX,V) = 0 g(\nabla_YX,V) = 0 \nabla_YX = 0 X S^m \nabla_YX S^n X S^n g(\nabla_YX,V) = 0 g(\nabla_YX,V) = 0","['differential-geometry', 'riemannian-geometry']"
13,Chern classes and almost complex submanifolds,Chern classes and almost complex submanifolds,,"Suppose $M$ is a manifold endowes with an almost complex structure, such that the Chern classes $c_i(M)$ of $M$ are defined. Can we say that the Poincare dual to $c_i(M)$ can be represented by an almost complex submanifold of $M$ ?","Suppose is a manifold endowes with an almost complex structure, such that the Chern classes of are defined. Can we say that the Poincare dual to can be represented by an almost complex submanifold of ?",M c_i(M) M c_i(M) M,"['differential-geometry', 'algebraic-topology', 'differential-topology', 'almost-complex']"
14,Embedding whole flat 2-Torus in $\Bbb R^3$,Embedding whole flat 2-Torus in,\Bbb R^3,"I am trying to better understand an isometric embedding of a flat 2-Torus in $\Bbb R^3$ via a $C^1$ map. Here is a visualization involving $C^1$ fractals: This embedding is warped by an infinite sequence of waves called corrugations, according to the Hévéa Project (thanks to @dvitek for the reference). Due to this infinity, it is unclear how the points of this surface can be defined. My question is if this surface can be described as a function of the $x,y,z$ coordinates in $\Bbb R^3$ either in the explicit or parametric way.","I am trying to better understand an isometric embedding of a flat 2-Torus in via a map. Here is a visualization involving fractals: This embedding is warped by an infinite sequence of waves called corrugations, according to the Hévéa Project (thanks to @dvitek for the reference). Due to this infinity, it is unclear how the points of this surface can be defined. My question is if this surface can be described as a function of the coordinates in either in the explicit or parametric way.","\Bbb R^3 C^1 C^1 x,y,z \Bbb R^3","['differential-geometry', 'metric-spaces', 'riemannian-geometry']"
15,Is there a proof via Chern-Weil theory that the first Chern numbers of two $\mathbb R$-isomorphic complex vector bundles are equal mod 2?,Is there a proof via Chern-Weil theory that the first Chern numbers of two -isomorphic complex vector bundles are equal mod 2?,\mathbb R,"Let $M$ be a compact, oriented surface. If we have a complex vector bundle $E$ over $M$ , then we can define the first Chern number $c_1(E)$ via Chern-Weil theory. More precisely, if $\nabla$ is a connection on $E$ , then for a local frame $u_1,\ldots,u_k$ we can define the $1$ -forms $A_j^i$ by the formula $$\nabla u_j = \sum_i A_j^i u_i, $$ and then define the curvature by $$F := dA + A \wedge A,$$ where $A$ is the matrix $(A_j^i)$ of $1$ -forms. The first Chern number is defined by $$c_1(E) = \frac{1}{2\pi i}\int_M \mathrm{tr}(F),$$ and this number does not depend on the choice of connection $\nabla$ . Two complex vector bundles $E_1, E_2$ are $\mathbb C$ -isomorphic if there is a diffeomorphism $f:E_1 \to E_2$ such that the diagram commutes and $f$ restricted to the fibers is $\mathbb C$ -linear. Analogously, the complex vector bundles are $\mathbb R$ -isomorphic if the map $f$ restricted to the fibers is $\mathbb R$ -linear. If the $E_1$ and $E_2$ are $\mathbb C$ -isomorphic, then $c_1(E_1) = c_1(E_2)$ , and if they are $\mathbb R$ -isomorphic, then $c_1(E_1) = c_1(E_2) \mod 2$ . Nevertheless, I only know how to prove the second property via Stiefel–Whitney numbers: in short, we have $c_1(E_1) = w_2(E_1) \mod 2$ . Question: If $f:E_1 \to E_2$ is an $\mathbb R$ -isomorphism, how do I prove $c_1(E_1) = c_1(E_2) \mod 2$ direct from Chern-Weil approach, without using general characteristic classes? If $E_1$ and $E_2$ are line bundles, then the proof is actually simple, because in this case we have $$c_1(E) = \frac{1}{2\pi i}\int_M F,$$ that coincides it the Euler number, and it is easy to prove that $c_1(E_1) = c_1(E_2)$ if $f$ preserves orientation, and $c_1(E_1) = -c_1(E_2)$ if $f$ reverses the orientation. I would be satisfied with a proof for rank $2$ .","Let be a compact, oriented surface. If we have a complex vector bundle over , then we can define the first Chern number via Chern-Weil theory. More precisely, if is a connection on , then for a local frame we can define the -forms by the formula and then define the curvature by where is the matrix of -forms. The first Chern number is defined by and this number does not depend on the choice of connection . Two complex vector bundles are -isomorphic if there is a diffeomorphism such that the diagram commutes and restricted to the fibers is -linear. Analogously, the complex vector bundles are -isomorphic if the map restricted to the fibers is -linear. If the and are -isomorphic, then , and if they are -isomorphic, then . Nevertheless, I only know how to prove the second property via Stiefel–Whitney numbers: in short, we have . Question: If is an -isomorphism, how do I prove direct from Chern-Weil approach, without using general characteristic classes? If and are line bundles, then the proof is actually simple, because in this case we have that coincides it the Euler number, and it is easy to prove that if preserves orientation, and if reverses the orientation. I would be satisfied with a proof for rank .","M E M c_1(E) \nabla E u_1,\ldots,u_k 1 A_j^i \nabla u_j = \sum_i A_j^i u_i,
 F := dA + A \wedge A, A (A_j^i) 1 c_1(E) = \frac{1}{2\pi i}\int_M \mathrm{tr}(F), \nabla E_1, E_2 \mathbb C f:E_1 \to E_2 f \mathbb C \mathbb R f \mathbb R E_1 E_2 \mathbb C c_1(E_1) = c_1(E_2) \mathbb R c_1(E_1) = c_1(E_2) \mod 2 c_1(E_1) = w_2(E_1) \mod 2 f:E_1 \to E_2 \mathbb R c_1(E_1) = c_1(E_2) \mod 2 E_1 E_2 c_1(E) = \frac{1}{2\pi i}\int_M F, c_1(E_1) = c_1(E_2) f c_1(E_1) = -c_1(E_2) f 2","['differential-geometry', 'vector-bundles', 'connections', 'characteristic-classes']"
16,Fréchet manifold structure on space of sections,Fréchet manifold structure on space of sections,,"I know that the space $\mathsf{C}^\infty(M;N)$ of smooth maps from a closed (smooth) manifold $M$ to a (smooth) manifold $N$ is a Fréchet manifold. I have been looking for a more general version of this statement along the following lines: Let $p: E \to B$ be a smooth fiber bundle, where $E$ and $B$ are manifolds with corners (with some additional assumptions on $p:E \to B$ ?) . Then $\Gamma^\infty(B;E) := \{ s: B \to E \mid s $ smooth, $ p \circ s = \mathsf{id}_B \}$ is a Fréchet manifold (with corners?) but I can't seem to find a precise statement or proof of something like this anywhere. I've tried looking in ""A Convenient Setting for Global Analysis,"" but that book seems to work in a very large amount of generality that is a bit beyond what I would need. The only generalizations I am looking for are: instead of functions $f: M \to N$ , we consider sections $s: B \to E$ of a fiber bundle $p: E \to B$ , the manifolds in question can have boundary (or maybe even corners). Then the original result for $\mathsf{C}^\infty(M;N)$ would then be recovered by taking $M$ and $N$ without corners and considering the trivial bundle $M \times N \to M$ . I would really appreciate it if anyone could suggest a reference where a result like this is stated/proven, or if someone could explain how I could formulate/prove this (namely, what are the charts on $\Gamma^\infty(B;E)$ , what assumptions would we need on $p: E \to B$ , and do we need a notion of ""Fréchet manifold with corners""?). Thanks very much!","I know that the space of smooth maps from a closed (smooth) manifold to a (smooth) manifold is a Fréchet manifold. I have been looking for a more general version of this statement along the following lines: Let be a smooth fiber bundle, where and are manifolds with corners (with some additional assumptions on ?) . Then smooth, is a Fréchet manifold (with corners?) but I can't seem to find a precise statement or proof of something like this anywhere. I've tried looking in ""A Convenient Setting for Global Analysis,"" but that book seems to work in a very large amount of generality that is a bit beyond what I would need. The only generalizations I am looking for are: instead of functions , we consider sections of a fiber bundle , the manifolds in question can have boundary (or maybe even corners). Then the original result for would then be recovered by taking and without corners and considering the trivial bundle . I would really appreciate it if anyone could suggest a reference where a result like this is stated/proven, or if someone could explain how I could formulate/prove this (namely, what are the charts on , what assumptions would we need on , and do we need a notion of ""Fréchet manifold with corners""?). Thanks very much!",\mathsf{C}^\infty(M;N) M N p: E \to B E B p:E \to B \Gamma^\infty(B;E) := \{ s: B \to E \mid s   p \circ s = \mathsf{id}_B \} f: M \to N s: B \to E p: E \to B \mathsf{C}^\infty(M;N) M N M \times N \to M \Gamma^\infty(B;E) p: E \to B,"['differential-geometry', 'manifolds', 'fiber-bundles', 'manifolds-with-boundary', 'global-analysis']"
17,Geometric interpretation of Isotropic vector,Geometric interpretation of Isotropic vector,,"For real inner product space $(V,\langle.,.\rangle)$ there is a $\Bbb C$ -bilinear form $( , )$ on $V\otimes\Bbb C$ . This extension gives rise to a Hermitian inner product, again denoted by $( , )$ on $V^2\otimes\Bbb C$ . A vector $v\in V\otimes\Bbb C$ is isotropic if $(v, v) = 0$ . In physics a quantity is called isotropic if it has the same properties or characteristics along all axes. Q: what is the geometric interpretation of isotropic vector? Edit: There is a similar (maybe equal) concept known as Isotropic Vector Matrix . Is this related to isotropic vector?","For real inner product space there is a -bilinear form on . This extension gives rise to a Hermitian inner product, again denoted by on . A vector is isotropic if . In physics a quantity is called isotropic if it has the same properties or characteristics along all axes. Q: what is the geometric interpretation of isotropic vector? Edit: There is a similar (maybe equal) concept known as Isotropic Vector Matrix . Is this related to isotropic vector?","(V,\langle.,.\rangle) \Bbb C ( , ) V\otimes\Bbb C ( , ) V^2\otimes\Bbb C v\in V\otimes\Bbb C (v, v) = 0","['differential-geometry', 'riemannian-geometry', 'inner-products', 'vector-fields']"
18,Chern-Weil theory in the cohomological Atiyah-Singer theorem,Chern-Weil theory in the cohomological Atiyah-Singer theorem,,"I am interested in the following piece of data appearing in the cohomological Atiyah-Singer theorem. My reference is ""The index of elliptic operators. III"" by Atiyah and Singer. Let $D:\Gamma(E)\to\Gamma(F)$ be an elliptic operator where $E\to X$ and $F\to X$ are complex vector bundles over a closed manifold $X$ . The principal symbol of $D$ is a bundle isomorphism $\pi^\ast E\to\pi^\ast F$ , where $\pi$ is the restriction of the projection $T^\ast X\to X$ to the complement of the zero section. Given a Riemannian metric on $X$ , the Thom space $\operatorname{Th}_X$ of $T^\ast X\to X$ is the topological space arising as the one-point compactification of the unit ball subbundle of $T^\ast X$ . Using the above bundle isomorphism (and the obvious extension across the zero section), one extends $\pi^\ast E-\pi^\ast F$ to an element of $K(\operatorname{Th}_X)$ . The Chern character gives an element of cohomology on the Thom space, and the cohomological Thom isomorphism gives an element of cohomology on $X$ . Now, the de Rham theorem says that this final cohomology element can be represented by a smooth differential form. My question is: can such a smooth form be prescribed in differential-geometric terms from the principal symbol, the (choice of) Riemannian metric on $X$ , and perhaps a choice of hermitian bundle metrics and metric-compatible connections on $E\to X$ and $F\to X$ ? This seems non-obvious since the Thom space does not seem to have a natural smooth structure, and so the use of the Chern character in the above presentation doesn't seem immediately amenable to the Chern-Weil approach. But, given the context and the conclusion, it seems unnatural to be forced to reach into the theory of topological characteristic classes. If I understand correctly, the answer to my question is ""essentially yes"" according to Quillen's article ""Superconnections and the Chern character,"" which identifies such a differential form via a choice of ""superconnection"" on $\pi^\ast E\oplus\pi^\ast F.$ However, Quillen's article seems to be answering a more general question, and has nothing to do with, for instance, the Thom space. Can one make use of the more special situation above to give a simpler answer than Quillen's?","I am interested in the following piece of data appearing in the cohomological Atiyah-Singer theorem. My reference is ""The index of elliptic operators. III"" by Atiyah and Singer. Let be an elliptic operator where and are complex vector bundles over a closed manifold . The principal symbol of is a bundle isomorphism , where is the restriction of the projection to the complement of the zero section. Given a Riemannian metric on , the Thom space of is the topological space arising as the one-point compactification of the unit ball subbundle of . Using the above bundle isomorphism (and the obvious extension across the zero section), one extends to an element of . The Chern character gives an element of cohomology on the Thom space, and the cohomological Thom isomorphism gives an element of cohomology on . Now, the de Rham theorem says that this final cohomology element can be represented by a smooth differential form. My question is: can such a smooth form be prescribed in differential-geometric terms from the principal symbol, the (choice of) Riemannian metric on , and perhaps a choice of hermitian bundle metrics and metric-compatible connections on and ? This seems non-obvious since the Thom space does not seem to have a natural smooth structure, and so the use of the Chern character in the above presentation doesn't seem immediately amenable to the Chern-Weil approach. But, given the context and the conclusion, it seems unnatural to be forced to reach into the theory of topological characteristic classes. If I understand correctly, the answer to my question is ""essentially yes"" according to Quillen's article ""Superconnections and the Chern character,"" which identifies such a differential form via a choice of ""superconnection"" on However, Quillen's article seems to be answering a more general question, and has nothing to do with, for instance, the Thom space. Can one make use of the more special situation above to give a simpler answer than Quillen's?",D:\Gamma(E)\to\Gamma(F) E\to X F\to X X D \pi^\ast E\to\pi^\ast F \pi T^\ast X\to X X \operatorname{Th}_X T^\ast X\to X T^\ast X \pi^\ast E-\pi^\ast F K(\operatorname{Th}_X) X X E\to X F\to X \pi^\ast E\oplus\pi^\ast F.,"['differential-geometry', 'algebraic-topology', 'homology-cohomology', 'characteristic-classes', 'k-theory']"
19,Pursuit-evasion game with n pursuers and one evader,Pursuit-evasion game with n pursuers and one evader,,"Assume $n$ pursuers ( $P_i$ ) at the vertices of an $n$ sided regular polygon with   the evader ( $E$ ) at the centre. For what all $n$ can be the evader be caught?   Pursuers and evader have same speed For $n≥3$ , pursuers win. Consider the case with $3$ pursuers. Consider the equilateral triangle whose midpoints are given by the initial positions of the pursuers. Each pursuer simply moves along their side of this triangle as per the projection of the evader along that side. ( $P_i E$ is perpendicular to side and $P_i$ lies on side). Since there will be leftover scope for movement, shift one of the sides closer while maintaining it parallel. The triangle will no longer be equilateral but its angles will still be $60$ degrees. Repeat until triangle becomes point sized. In worst case this requires pursuers to move $2\Delta x + \epsilon$ for every $\Delta x$ of evader movement ( $2\Delta x$ to maintain the perpendicular condition for all three sides, and $\epsilon$ additionally to shift a side). What if we were restricted to $\Delta x$ movement? Assume $n$ pursuers on the vertices of an $n$ sided polygon and a single   evader at the centre. Pursuers must move such that the sum of their   speeds (absolute) does not exceed the evader's speed. For what all $n$ can the   evader be caught? A practical case where this situation might occur is where play is turn by turn. Consider the version discrete in time and space, where on each turn - exactly one pursuer can move one unit and the evader can move unit. How can this be solved? I tried writing a simulation for it using some intuitive strategies - in all cases the evader won. Is there any existing work where this problem has been solved? It seems like a useful base case to tackle before dealing with harder $n$ pursuer $m$ evader problems.","Assume pursuers ( ) at the vertices of an sided regular polygon with   the evader ( ) at the centre. For what all can be the evader be caught?   Pursuers and evader have same speed For , pursuers win. Consider the case with pursuers. Consider the equilateral triangle whose midpoints are given by the initial positions of the pursuers. Each pursuer simply moves along their side of this triangle as per the projection of the evader along that side. ( is perpendicular to side and lies on side). Since there will be leftover scope for movement, shift one of the sides closer while maintaining it parallel. The triangle will no longer be equilateral but its angles will still be degrees. Repeat until triangle becomes point sized. In worst case this requires pursuers to move for every of evader movement ( to maintain the perpendicular condition for all three sides, and additionally to shift a side). What if we were restricted to movement? Assume pursuers on the vertices of an sided polygon and a single   evader at the centre. Pursuers must move such that the sum of their   speeds (absolute) does not exceed the evader's speed. For what all can the   evader be caught? A practical case where this situation might occur is where play is turn by turn. Consider the version discrete in time and space, where on each turn - exactly one pursuer can move one unit and the evader can move unit. How can this be solved? I tried writing a simulation for it using some intuitive strategies - in all cases the evader won. Is there any existing work where this problem has been solved? It seems like a useful base case to tackle before dealing with harder pursuer evader problems.",n P_i n E n n≥3 3 P_i E P_i 60 2\Delta x + \epsilon \Delta x 2\Delta x \epsilon \Delta x n n n n m,"['differential-geometry', 'recreational-mathematics', 'game-theory', 'calculus-of-variations', 'differential-games']"
20,Product rule for codifferential on manifolds,Product rule for codifferential on manifolds,,"Let $(M^n,g)$ be a Riemannian manifold. It is well known that the following identity holds: $$ d(\alpha \wedge \beta) = (d\alpha) \wedge \beta + (-1)^p \alpha \wedge (d \beta) $$ where $\alpha$ is a $p$ -form on $M$ and $\beta$ is a $q$ -form on $M$ . Is there a formula for the codifferential of a wedge product? That is, can we express $\delta(\alpha \wedge \beta)$ in terms of $\delta \alpha$ and $\delta \beta$ (and possibly $d \alpha$ and $d \beta$ )? Just recalling: $\delta$ is defined as being equal to $(-1)^{n(k-1)+1}\ast d \ast$ acting on $k$ -forms.","Let be a Riemannian manifold. It is well known that the following identity holds: where is a -form on and is a -form on . Is there a formula for the codifferential of a wedge product? That is, can we express in terms of and (and possibly and )? Just recalling: is defined as being equal to acting on -forms.","(M^n,g)  d(\alpha \wedge \beta) = (d\alpha) \wedge \beta + (-1)^p \alpha \wedge (d \beta)  \alpha p M \beta q M \delta(\alpha \wedge \beta) \delta \alpha \delta \beta d \alpha d \beta \delta (-1)^{n(k-1)+1}\ast d \ast k","['differential-geometry', 'smooth-manifolds', 'differential-forms']"
21,Hopf submersion,Hopf submersion,,"Let's consider two maps: $H:\mathbb{S}^3\subset \mathbb{C}^2\to \mathbb{CP}^1$ with $H(z_0,z_1)=[z_0:z_1]$ and $h:\mathbb{S}^3\to \mathbb{S^2}$ with $h(x,y,z,t)=(x^2+y^2-z^2-t^2, 2(yz-xt), 2(xz+yt))$ . I have to prove that (1) $h$ and $H$ are smooth submersions. (2) $\mathbb{CP}^1$ is diffeomorphic to $\mathbb{S}^2$ . I have some problems solving both points because if I take some charts of $\mathbb{S}^2$ or $\mathbb{S}^3$ , then the calculations are extremely complicated. My attempt: (1) I can consider the natural extension of $h$ to $\mathbb{R}^4$ , $\widetilde{h}:\mathbb{R}^4\to \mathbb{R}^3$ , which has only one critical point 0. Then, since $h=\widetilde{h}\circ \iota\mid_{\mathbb{S}^3}$ , by chain rule we get, $(dh)_p=(d\widetilde{h})_p\circ (d\iota\mid_{\mathbb{S}^3})_p$ where $(d\widetilde{h})_p$ is surjective and $(d\iota\mid_{\mathbb{S}^3})_p$ . However, it's not trivial to conclude that $(df)_p$ is surjective. I don't know if it's the right way to do this. (2) Let's consider the map $\Phi: \mathbb{CP}^1\to \mathbb{S}^2$ such that $h=\Phi\circ H$ . $h$ is a surjective smooth submersion, then $\Phi$ is a surjective smooth submersion too. Moreover, since $\mathbb{CP}^1$ and $\mathbb{S}^2$ have the same dimension, i get that $\Phi$ is an immersion and therefore a local diffeomorphism. However, I still have to prove that $\Phi$ is injective. Any hint?","Let's consider two maps: with and with . I have to prove that (1) and are smooth submersions. (2) is diffeomorphic to . I have some problems solving both points because if I take some charts of or , then the calculations are extremely complicated. My attempt: (1) I can consider the natural extension of to , , which has only one critical point 0. Then, since , by chain rule we get, where is surjective and . However, it's not trivial to conclude that is surjective. I don't know if it's the right way to do this. (2) Let's consider the map such that . is a surjective smooth submersion, then is a surjective smooth submersion too. Moreover, since and have the same dimension, i get that is an immersion and therefore a local diffeomorphism. However, I still have to prove that is injective. Any hint?","H:\mathbb{S}^3\subset \mathbb{C}^2\to \mathbb{CP}^1 H(z_0,z_1)=[z_0:z_1] h:\mathbb{S}^3\to \mathbb{S^2} h(x,y,z,t)=(x^2+y^2-z^2-t^2, 2(yz-xt), 2(xz+yt)) h H \mathbb{CP}^1 \mathbb{S}^2 \mathbb{S}^2 \mathbb{S}^3 h \mathbb{R}^4 \widetilde{h}:\mathbb{R}^4\to \mathbb{R}^3 h=\widetilde{h}\circ \iota\mid_{\mathbb{S}^3} (dh)_p=(d\widetilde{h})_p\circ (d\iota\mid_{\mathbb{S}^3})_p (d\widetilde{h})_p (d\iota\mid_{\mathbb{S}^3})_p (df)_p \Phi: \mathbb{CP}^1\to \mathbb{S}^2 h=\Phi\circ H h \Phi \mathbb{CP}^1 \mathbb{S}^2 \Phi \Phi","['differential-geometry', 'differential-topology', 'smooth-manifolds', 'hopf-fibration']"
22,(History) Books About Geometry of Curves and Surfaces,(History) Books About Geometry of Curves and Surfaces,,"Are there any books regarding how curvature, torsion, etc., did born? When these math notions were used for the first time?","Are there any books regarding how curvature, torsion, etc., did born? When these math notions were used for the first time?",,"['differential-geometry', 'reference-request', 'book-recommendation', 'surfaces', 'curves']"
23,Integration by parts for covariant tensor fields,Integration by parts for covariant tensor fields,,"Let $(M,g)$ be a compact Riemannian manifold with boundary, and suppose $N$ is the outward unit normal vector field along $\partial M$ . I am trying to prove the following integration by parts formula: $$ \int_M \langle \nabla F, G \rangle \, dV_g = \int_{\partial M} \left\langle F \otimes N^\flat, G \right\rangle \, dV_{\widehat g} - \int_M \left\langle F, \mathrm{div}\,G\right\rangle \,dV_g $$ where $F$ is a covariant $k$ -tensor field, $G$ is a covariant $(k+1)$ -tensor field, and $\mathrm{div}\,G = \mathrm{tr}_g(\nabla G) = \mathrm{tr}\left(\left(\nabla G\right)^\sharp\right)$ . I'm trying to emulate the proof of the more traditional integration by parts formula $$ \int_M \left\langle \mathrm{grad}\,u, X \right\rangle \,dV_g = \int_{\partial M} u \left\langle X, N \right\rangle \,dV_{\widehat g} - \int_M u \,\mathrm{div}\,X \, dV_g $$ which is proven in the following steps: Prove $\iota_{\partial M}^*\left(X ^\big\lrcorner dV_g\right) = \langle X, N \rangle \, dV_{\widehat g}$ , where $\iota_{\partial M} : \partial M \hookrightarrow M$ is inclusion and $X^\big\lrcorner dV_g$ denotes interior multiplication; Use this result and Stokes' theorem to prove the divergence theorem: $$ \int_M(\mathrm{div}\,X)\,dV_g = \int_{\partial M} \langle X, N \rangle \, dV_{\widehat g} $$ where the divergence is defined in this case as $(\mathrm{div}\,X)\,dV_g = d\left(X^\big\lrcorner dV_g\right)$ ; Prove the product rule for the divergence operator: $\mathrm{div}(uX) = u\,\mathrm{div}\,X + \langle \mathrm{grad}\,u, X \rangle$ But I'm not sure what the parallel steps would be. And after taking a closer look, I'm not sure I'm going about this the right way at all, since Stokes' theorem requires the integrand to be a differential form, and I don't see at all how to express the divergence of an arbitrary covariant tensor field as an alternating covariant tensor field. Help on how to begin? EDIT: See comments below for an outline of a solution.","Let be a compact Riemannian manifold with boundary, and suppose is the outward unit normal vector field along . I am trying to prove the following integration by parts formula: where is a covariant -tensor field, is a covariant -tensor field, and . I'm trying to emulate the proof of the more traditional integration by parts formula which is proven in the following steps: Prove , where is inclusion and denotes interior multiplication; Use this result and Stokes' theorem to prove the divergence theorem: where the divergence is defined in this case as ; Prove the product rule for the divergence operator: But I'm not sure what the parallel steps would be. And after taking a closer look, I'm not sure I'm going about this the right way at all, since Stokes' theorem requires the integrand to be a differential form, and I don't see at all how to express the divergence of an arbitrary covariant tensor field as an alternating covariant tensor field. Help on how to begin? EDIT: See comments below for an outline of a solution.","(M,g) N \partial M 
\int_M \langle \nabla F, G \rangle \, dV_g = \int_{\partial M} \left\langle F \otimes N^\flat, G \right\rangle \, dV_{\widehat g} - \int_M \left\langle F, \mathrm{div}\,G\right\rangle \,dV_g
 F k G (k+1) \mathrm{div}\,G = \mathrm{tr}_g(\nabla G) = \mathrm{tr}\left(\left(\nabla G\right)^\sharp\right) 
\int_M \left\langle \mathrm{grad}\,u, X \right\rangle \,dV_g = \int_{\partial M} u \left\langle X, N \right\rangle \,dV_{\widehat g} - \int_M u \,\mathrm{div}\,X \, dV_g
 \iota_{\partial M}^*\left(X ^\big\lrcorner dV_g\right) = \langle X, N \rangle \, dV_{\widehat g} \iota_{\partial M} : \partial M \hookrightarrow M X^\big\lrcorner dV_g 
\int_M(\mathrm{div}\,X)\,dV_g = \int_{\partial M} \langle X, N \rangle \, dV_{\widehat g}
 (\mathrm{div}\,X)\,dV_g = d\left(X^\big\lrcorner dV_g\right) \mathrm{div}(uX) = u\,\mathrm{div}\,X + \langle \mathrm{grad}\,u, X \rangle","['differential-geometry', 'riemannian-geometry', 'tensors', 'divergence-operator']"
24,Stability on the number of connected components on a moduli space of smooth manifolds.,Stability on the number of connected components on a moduli space of smooth manifolds.,,"Let $g:\mathbb{R}^n \times \mathbb{R} \rightarrow \mathbb{R}^k$ be a function whose coordinates $g_i$ are homogeneous polynomials  and let $u \in \mathbb{R}^k$ and $c \in [0,1]$ and let $J_x(c)$ be the Jacobian matrix of $g(\cdot,c)$ at $x$ . Let $M(c)=\{x \in \mathbb{R}^n | g_i(x,c)=u_i, i=1\cdots,k\}$ be a space such that $J_x(c)$ is full rank at the interior of $M(c)$ for all $c \in [0,1]$ . Thus $M(c)$ is a collection of spaces whose interior are smooth manifolds. I try to investigate if the number of connected components of $M(c)$ is equal to $M(c')$ where $c' = c + \delta c$ and $\delta c$ is sufficient small. Some of you have an idea or which tools to use in order to investigate the above property? Thanks in advance.t",Let be a function whose coordinates are homogeneous polynomials  and let and and let be the Jacobian matrix of at . Let be a space such that is full rank at the interior of for all . Thus is a collection of spaces whose interior are smooth manifolds. I try to investigate if the number of connected components of is equal to where and is sufficient small. Some of you have an idea or which tools to use in order to investigate the above property? Thanks in advance.t,"g:\mathbb{R}^n \times \mathbb{R} \rightarrow \mathbb{R}^k g_i u \in \mathbb{R}^k c \in [0,1] J_x(c) g(\cdot,c) x M(c)=\{x \in \mathbb{R}^n | g_i(x,c)=u_i, i=1\cdots,k\} J_x(c) M(c) c \in [0,1] M(c) M(c) M(c') c' = c + \delta c \delta c","['differential-geometry', 'algebraic-geometry', 'algebraic-topology', 'differential-topology']"
25,references for algebraic topology of (complex) manifolds,references for algebraic topology of (complex) manifolds,,"Now I want to study some fundamental theorems of cohomology of (complex) manifolds. e.g., Poincare duality, Kunneth formula, weak and hard Lefschetz, cup product, cycle maps, ""de Rham cohomology = singular cohomology = derived sheaf cohomology = Cech cohomology"", and so on. I'm reading Bott-Tu's ""differential forms in algebraic topology"", so I know some of these for De Rham cohomology. I want to know these theorems for integers coefficient cohomology. Glancing through the table of contents, it seems that the chapter 0 of Griffiths-Harris contains all of these (for complex manifolds). But many people say that it is too brief for the people who study it first time. (I've read Hartshorne, so I think it may be readable for me...) So please suggest to me some references. Thank you very much.","Now I want to study some fundamental theorems of cohomology of (complex) manifolds. e.g., Poincare duality, Kunneth formula, weak and hard Lefschetz, cup product, cycle maps, ""de Rham cohomology = singular cohomology = derived sheaf cohomology = Cech cohomology"", and so on. I'm reading Bott-Tu's ""differential forms in algebraic topology"", so I know some of these for De Rham cohomology. I want to know these theorems for integers coefficient cohomology. Glancing through the table of contents, it seems that the chapter 0 of Griffiths-Harris contains all of these (for complex manifolds). But many people say that it is too brief for the people who study it first time. (I've read Hartshorne, so I think it may be readable for me...) So please suggest to me some references. Thank you very much.",,"['differential-geometry', 'algebraic-topology', 'complex-geometry']"
26,Minimizing elastic energy of shrinking balls,Minimizing elastic energy of shrinking balls,,"I am new to variational analysis and I am currently working in the following setup: We denote the $2$ -sphere with radius $r>0$ by $S_r^2$ and $S^2:=S_1^2$ . In coordinates $(\theta,\varphi)$ , we have a metric on $S_r^2$ given by $$g_r=r^2 d\varphi^2+r^2\sin^2\varphi d\theta^2$$ For $r>0,\, r\neq 1$ I want to find a minimizer of the following functional: \begin{align} E:C^\infty(S_r^2,S^2)&\longrightarrow\mathbb R_{\geq 0} \\ f&\longmapsto\frac{1}{\text{Vol}(S_r)}\int_{S_r^2}\operatorname{dist}^2(df(x),SO_x(g_r,g))dx \end{align} where $SO_x(g_r,g)$ is the set of orientation preserving isometries $T_x S_r^2\rightarrow T_{f(x)} S^2$ . An obvious candidate would be $f:x\mapsto\frac{1}{r}x$ . Then $df=\frac{1}{r}\operatorname{id}$ and therefore $$\operatorname{dist}^2(df(x),SO_x(g_r,g))=\left|\frac{1}{r}\operatorname{id}-\operatorname{id}\right|^2=\frac{(1-r)^2}{r^2}$$ for all $x$ . Hence $\inf E\leq\frac{(1-r)^2}{r^2}$ . I am suspecting that $\inf E=E(f)=\frac{(1-r)^2}{r^2}$ , so that $f$ is indeed a minimizer, but I am having trouble how I would go about proving this.","I am new to variational analysis and I am currently working in the following setup: We denote the -sphere with radius by and . In coordinates , we have a metric on given by For I want to find a minimizer of the following functional: where is the set of orientation preserving isometries . An obvious candidate would be . Then and therefore for all . Hence . I am suspecting that , so that is indeed a minimizer, but I am having trouble how I would go about proving this.","2 r>0 S_r^2 S^2:=S_1^2 (\theta,\varphi) S_r^2 g_r=r^2 d\varphi^2+r^2\sin^2\varphi d\theta^2 r>0,\, r\neq 1 \begin{align}
E:C^\infty(S_r^2,S^2)&\longrightarrow\mathbb R_{\geq 0} \\
f&\longmapsto\frac{1}{\text{Vol}(S_r)}\int_{S_r^2}\operatorname{dist}^2(df(x),SO_x(g_r,g))dx
\end{align} SO_x(g_r,g) T_x S_r^2\rightarrow T_{f(x)} S^2 f:x\mapsto\frac{1}{r}x df=\frac{1}{r}\operatorname{id} \operatorname{dist}^2(df(x),SO_x(g_r,g))=\left|\frac{1}{r}\operatorname{id}-\operatorname{id}\right|^2=\frac{(1-r)^2}{r^2} x \inf E\leq\frac{(1-r)^2}{r^2} \inf E=E(f)=\frac{(1-r)^2}{r^2} f","['differential-geometry', 'riemannian-geometry', 'calculus-of-variations', 'compact-manifolds', 'variational-analysis']"
27,Use of sprays in differential geometry?,Use of sprays in differential geometry?,,"I have been reading Fundamentals of Differential Geometry by Serge Lang. In his treatment, the notion of sprays plays a central role. However, I rarely see this term in other books on the subject. Although this is a soft question, I try to make clear my questions: Is spray a somewhat out-dated notion? What is the geometric meaning of sprays? (This name is suggestive but I don't have any intuition for it...) What are the advantages and disadvantages of using sprays? Can you suggest an alternative book whose treatment is similar to that of Lang's and which is modern and readable? Thanks in advance!","I have been reading Fundamentals of Differential Geometry by Serge Lang. In his treatment, the notion of sprays plays a central role. However, I rarely see this term in other books on the subject. Although this is a soft question, I try to make clear my questions: Is spray a somewhat out-dated notion? What is the geometric meaning of sprays? (This name is suggestive but I don't have any intuition for it...) What are the advantages and disadvantages of using sprays? Can you suggest an alternative book whose treatment is similar to that of Lang's and which is modern and readable? Thanks in advance!",,"['differential-geometry', 'soft-question', 'riemannian-geometry']"
28,Identification of the tangent space of a manifold and the tangent vectors to curves,Identification of the tangent space of a manifold and the tangent vectors to curves,,"I'm studying the different definitions of the tangent space for abstract manifolds, and I'm struggling to prove that these abstract concepts reduce to the classical ones when dealing with submanifolds of $\mathbb{R}^n$ . What I know: The tangent space $T_pM$ can be defined as the space of all equivalence classes of curves $\gamma:(-\epsilon, \epsilon)\to M$ with $\gamma(0)=p$ under the equivalence relation $$ \gamma \sim \beta \quad\iff\quad (\mathbf{x}^{-1}\circ\gamma)'(0) = (\mathbf{x}^{-1}\circ\beta)'(0), $$ where $\mathbf{x}$ is a local chart of $M$ at $p$ . This is easily shown to be independent of the chosen chart. The tangent space $T_pM$ can also be defined as the space or all derivations $D$ which are linear functionals obeying the Leibniz rule, which act on the space of smooth functions defined locally around $p$ . I know how to prove that the latter two are equivalent (in the sense that the spaces are isomorphic), and related by $$ [\gamma]\mapsto \left(f \mapsto (f\circ\gamma)'(0)\right), $$ where the latter map can be thought of as the directional derivative with respect to $[\gamma]$ I also know that they are both isomorphic to $\mathbb{R}^n$ . For the the differential of a smooth map $\varphi:M\to N$ , I use the definition using derivations derivations, i.e. $$\mathrm d\varphi_p(X)(f) = X(f\circ \varphi).$$ I know how to prove the chain rule and I also know that the differential $\mathrm d\varphi_p$ is an isomorphism whenever the map $\varphi$ is a diffeomorphism. What I don't know how to prove: If $M$ is a submanifold of $\mathbb{R}^n$ , the tangent space $T_pM$ is isomorphic to the space of all tangents $\dot\gamma(0)\in \mathbb{R}^n$ of curves $\gamma$ passing through $p$ ? I can intuitively see why this should be the case given the information that I have, but I don't know how to write a proper proof of it. One of the ideas is to show that two curves belong to the same equivalence class if and only if their tangent vectors at $p$ coincide, in which case I could do something as shown in this post . However, with my definition of the differential I do not directly see that $$ (\mathbf{x}^{-1}\circ\gamma)'(0) = \mathrm d\mathbf{x}^{-1}_p(\dot\gamma(0)). $$ That being said, I would guess that one can use the aforementioned isomorphisms to identify the differential with a map that operates in this way. Another idea would be to prove that the directional derivative with respect to $[\gamma]$ actually coincides with the tangent vector $\dot\gamma(0)$ , but I don't see how one can do this. Could you help me with this? EDIT: I have added a bounty. Let me know if my question is unclear or missing any of the details. EDIT 2: After thinking about this a bit more, I don't think it is possible to show what I'm trying to show without first defining the tangent space and the differential for submanifolds of $\mathbb{R}^n$ in the natural way (i.e. using tangents to curves) and showing that the differential of a chart is an isomorphism, and then using that fact to show that all of the new notions reduce to the classical ones. I would love to be wrong regarding this though.","I'm studying the different definitions of the tangent space for abstract manifolds, and I'm struggling to prove that these abstract concepts reduce to the classical ones when dealing with submanifolds of . What I know: The tangent space can be defined as the space of all equivalence classes of curves with under the equivalence relation where is a local chart of at . This is easily shown to be independent of the chosen chart. The tangent space can also be defined as the space or all derivations which are linear functionals obeying the Leibniz rule, which act on the space of smooth functions defined locally around . I know how to prove that the latter two are equivalent (in the sense that the spaces are isomorphic), and related by where the latter map can be thought of as the directional derivative with respect to I also know that they are both isomorphic to . For the the differential of a smooth map , I use the definition using derivations derivations, i.e. I know how to prove the chain rule and I also know that the differential is an isomorphism whenever the map is a diffeomorphism. What I don't know how to prove: If is a submanifold of , the tangent space is isomorphic to the space of all tangents of curves passing through ? I can intuitively see why this should be the case given the information that I have, but I don't know how to write a proper proof of it. One of the ideas is to show that two curves belong to the same equivalence class if and only if their tangent vectors at coincide, in which case I could do something as shown in this post . However, with my definition of the differential I do not directly see that That being said, I would guess that one can use the aforementioned isomorphisms to identify the differential with a map that operates in this way. Another idea would be to prove that the directional derivative with respect to actually coincides with the tangent vector , but I don't see how one can do this. Could you help me with this? EDIT: I have added a bounty. Let me know if my question is unclear or missing any of the details. EDIT 2: After thinking about this a bit more, I don't think it is possible to show what I'm trying to show without first defining the tangent space and the differential for submanifolds of in the natural way (i.e. using tangents to curves) and showing that the differential of a chart is an isomorphism, and then using that fact to show that all of the new notions reduce to the classical ones. I would love to be wrong regarding this though.","\mathbb{R}^n T_pM \gamma:(-\epsilon, \epsilon)\to M \gamma(0)=p  \gamma \sim \beta \quad\iff\quad (\mathbf{x}^{-1}\circ\gamma)'(0) = (\mathbf{x}^{-1}\circ\beta)'(0),  \mathbf{x} M p T_pM D p  [\gamma]\mapsto \left(f \mapsto (f\circ\gamma)'(0)\right),  [\gamma] \mathbb{R}^n \varphi:M\to N \mathrm d\varphi_p(X)(f) = X(f\circ \varphi). \mathrm d\varphi_p \varphi M \mathbb{R}^n T_pM \dot\gamma(0)\in \mathbb{R}^n \gamma p p  (\mathbf{x}^{-1}\circ\gamma)'(0) = \mathrm d\mathbf{x}^{-1}_p(\dot\gamma(0)).  [\gamma] \dot\gamma(0) \mathbb{R}^n","['differential-geometry', 'manifolds', 'tangent-spaces']"
29,Different forms of 2nd Bianchi's Identity,Different forms of 2nd Bianchi's Identity,,"I have been struggling with relating two different forms of Bianchi's 2nd Identity: $d\Omega = \Omega\wedge\omega-\omega\wedge\Omega$ and $\mathfrak{S}\left\{(\nabla_{Z}R)(X,Y,Z)+R(T(X,Y),Z)W)\right\}=0$ here $R$ and $T$ represent curvature and torsion tensor of a connection $\nabla$ $\Omega$ and $\omega$ represent curvature and connection form of $\nabla$ How do we relate the exterior derivative of curvature form to the covariant derivative of curvature and torsion tensors? I am able to prove them independently but I am not able to prove the equivalence. I am pretty new to differential geometry and I apologize if this question is very easy. Here are some of my thoughts: I started with curvature form. Suppose $X_1,X_2,X_3,...X_n$ represent the moving frames and $\theta^1, \theta^2,...,\theta_n$ represent the dual co frame. In the index notation the first form of bianchi's 2nd identity can be given as $d\Omega^{i}_{j} = \Omega^i_k\wedge\omega^k_j-\omega^i_k\wedge\Omega^k_j$ (using einstien's summation convention) Relation between cuvature tensor and curvature form can be given as $R(X_k,X_l)X_j = \Omega^i_j(X_k,X_l)X_i$ in the index notation curvature tensor can be given as $R(X_k,X_l)X_j = R^i_{jkl}X_i$ this gives us $R^i_{jkl}X_i = \Omega^i_j(X_k,X_l)X_i$ or $\Omega^i_{j} = \frac{1}{2}\sum_\limits{k,l}R^i_{jkl}\theta^k\wedge\theta^l$ this implies $d\Omega^{i}_{j} =\frac{1}{2}\sum_\limits{m,k,l} \frac{\partial{R^i_{j,k,l}}}{\partial{X_m}}\theta^m\wedge\theta^k\wedge\theta^l$ the covariant derivative of R in index notation can be given as: $\nabla R = \sum_\limits{h,j,k,l,i}R^i_{jkl;h}\theta^h\oplus\theta^j\oplus\theta^k\oplus\theta^l\oplus X_i$ where $R^i_{jkl;h}$ can be given as $R^i_{jkl;h} = \frac{\partial{R^i_{j,k,l}}}{\partial{X_h}} + \sum\limits_{v=1}^n R^v_{j,k,l}\Gamma_{hv}^{i}-\sum_\limits{v=1}^{n}(R^i_{vkl}\Gamma^{v}_{hj}+R^i_{kvl}\Gamma^{v}_{hk}+R^i_{jkv}\Gamma^{v}_{hl})$ where $\Gamma$ can be given as $\nabla_{X_i}{X_j} = \Gamma_{ij}^K X_k$ Also connection 1-form $\omega^i_{j}$ can be given as: $\omega^i_j = \Gamma^i_{kj}\theta^k$ on one hand I have tensor product and on the other hand I have wedge product. At this point I am stuck and wonder if there is an alternate approach which doesn't involve coordinate representations. I am also not sure about my use of $X_i$ 's as coordinate vector fields.",I have been struggling with relating two different forms of Bianchi's 2nd Identity: and here and represent curvature and torsion tensor of a connection and represent curvature and connection form of How do we relate the exterior derivative of curvature form to the covariant derivative of curvature and torsion tensors? I am able to prove them independently but I am not able to prove the equivalence. I am pretty new to differential geometry and I apologize if this question is very easy. Here are some of my thoughts: I started with curvature form. Suppose represent the moving frames and represent the dual co frame. In the index notation the first form of bianchi's 2nd identity can be given as (using einstien's summation convention) Relation between cuvature tensor and curvature form can be given as in the index notation curvature tensor can be given as this gives us or this implies the covariant derivative of R in index notation can be given as: where can be given as where can be given as Also connection 1-form can be given as: on one hand I have tensor product and on the other hand I have wedge product. At this point I am stuck and wonder if there is an alternate approach which doesn't involve coordinate representations. I am also not sure about my use of 's as coordinate vector fields.,"d\Omega = \Omega\wedge\omega-\omega\wedge\Omega \mathfrak{S}\left\{(\nabla_{Z}R)(X,Y,Z)+R(T(X,Y),Z)W)\right\}=0 R T \nabla \Omega \omega \nabla X_1,X_2,X_3,...X_n \theta^1, \theta^2,...,\theta_n d\Omega^{i}_{j} = \Omega^i_k\wedge\omega^k_j-\omega^i_k\wedge\Omega^k_j R(X_k,X_l)X_j = \Omega^i_j(X_k,X_l)X_i R(X_k,X_l)X_j = R^i_{jkl}X_i R^i_{jkl}X_i = \Omega^i_j(X_k,X_l)X_i \Omega^i_{j} = \frac{1}{2}\sum_\limits{k,l}R^i_{jkl}\theta^k\wedge\theta^l d\Omega^{i}_{j} =\frac{1}{2}\sum_\limits{m,k,l} \frac{\partial{R^i_{j,k,l}}}{\partial{X_m}}\theta^m\wedge\theta^k\wedge\theta^l \nabla R = \sum_\limits{h,j,k,l,i}R^i_{jkl;h}\theta^h\oplus\theta^j\oplus\theta^k\oplus\theta^l\oplus X_i R^i_{jkl;h} R^i_{jkl;h} = \frac{\partial{R^i_{j,k,l}}}{\partial{X_h}} + \sum\limits_{v=1}^n R^v_{j,k,l}\Gamma_{hv}^{i}-\sum_\limits{v=1}^{n}(R^i_{vkl}\Gamma^{v}_{hj}+R^i_{kvl}\Gamma^{v}_{hk}+R^i_{jkv}\Gamma^{v}_{hl}) \Gamma \nabla_{X_i}{X_j} = \Gamma_{ij}^K X_k \omega^i_{j} \omega^i_j = \Gamma^i_{kj}\theta^k X_i",['differential-geometry']
30,Is exterior calculus efficient for simple vector calculus problems?,Is exterior calculus efficient for simple vector calculus problems?,,"Exterior calculus and invariant formulations are important and lead to many breakthroughs and great insights in physics and mathematics. But for daily vector calculus tasks, I still struggle to apply the theory efficiently . Question: Is it possible to practice exterior calculus hard enough such that it becomes as fast as classical vector calculus? Or is there just an unavoidable trade-off we need to accept? Example: I want to validate a simple equation like $$\mathbf B = \operatorname{rot} \mathbf A$$ for a potential $\mathbf A$ defined by $\mathbf{A} := \frac 1 2( \mathbf{r} \times \mathbf{B}).$ ($\mathbf B$ is a given constant magnetic field.) Using classical vector calculus (with indices), this computation is easy. But using rules from differential geometry instead, there are always the same difficulties for me: Which kind of tensors do we have: differential forms, vector fields or tensor-fields? (Knowing this is in general interesting, but sometime I just don't have the time to get into these questions...) If the tensors don't match, I need to use general formulas which involve many isomorphisms (musicals, hodge-star ), that's complicated! For this example, I did the computations by applying all isomorphisms one after each other, i.e. $$\mathbf B = [*(\mathrm d ( * (\mathbf r^\flat \wedge \mathbf   B^\flat)))]^\sharp .$$  It took me more than 10 minutes to figure it out. And additionally, it does not use the idea that $\mathbf B$ is more naturally seen as a $2$-form. Therefore, I really hope that I am just a bit stupid and there is a smarter way to this. But this is not the first example where I could not find an efficient way to calculate. Books: I mainly use John M. Lee's 'Introduction to smooth manifolds' and Marsdens books 'Introduction to Mechanics and Symmetry' and 'Mathematical foundations of elasticity' to learn differential geometry. (To be honest, I was scared off but the old prints of Spivak's books.)","Exterior calculus and invariant formulations are important and lead to many breakthroughs and great insights in physics and mathematics. But for daily vector calculus tasks, I still struggle to apply the theory efficiently . Question: Is it possible to practice exterior calculus hard enough such that it becomes as fast as classical vector calculus? Or is there just an unavoidable trade-off we need to accept? Example: I want to validate a simple equation like $$\mathbf B = \operatorname{rot} \mathbf A$$ for a potential $\mathbf A$ defined by $\mathbf{A} := \frac 1 2( \mathbf{r} \times \mathbf{B}).$ ($\mathbf B$ is a given constant magnetic field.) Using classical vector calculus (with indices), this computation is easy. But using rules from differential geometry instead, there are always the same difficulties for me: Which kind of tensors do we have: differential forms, vector fields or tensor-fields? (Knowing this is in general interesting, but sometime I just don't have the time to get into these questions...) If the tensors don't match, I need to use general formulas which involve many isomorphisms (musicals, hodge-star ), that's complicated! For this example, I did the computations by applying all isomorphisms one after each other, i.e. $$\mathbf B = [*(\mathrm d ( * (\mathbf r^\flat \wedge \mathbf   B^\flat)))]^\sharp .$$  It took me more than 10 minutes to figure it out. And additionally, it does not use the idea that $\mathbf B$ is more naturally seen as a $2$-form. Therefore, I really hope that I am just a bit stupid and there is a smarter way to this. But this is not the first example where I could not find an efficient way to calculate. Books: I mainly use John M. Lee's 'Introduction to smooth manifolds' and Marsdens books 'Introduction to Mechanics and Symmetry' and 'Mathematical foundations of elasticity' to learn differential geometry. (To be honest, I was scared off but the old prints of Spivak's books.)",,"['differential-geometry', 'soft-question', 'vector-analysis', 'physics']"
31,Differences between homeomorphic and topologically conjugate dynamical systems.,Differences between homeomorphic and topologically conjugate dynamical systems.,,"I have begun studying homeomorphisms between dynamical systems. I have a few related questions about homeomorphic and topologically conjugate dynamical systems. Questions How can I determine if a homeomorphism is orientation presevering? If two dynamical systems are Topologically Conjugate (that is $f \circ h=h \circ g$), does this imply that $h$ is an orientation preserving homeomorphism? (Answered see comment below this post) What properties are preserved between two topologically conjugate dynamical systems, compared to two dynamical systems which are only homeomorphic to each other? Definitions $f:X \rightarrow X$, $g:Y \rightarrow Y$ and $h:Y \rightarrow X$ are continuous functions on smooth orientable manifolds, $X$ and $Y$. Topologically Conjugate: $f \circ h=h \circ g$ and $h$ is homeomorphsim. Homeomorphism What it means for a manifold to be orientable . Notes Partial answers are appreciated. If you need any clarification please ask.","I have begun studying homeomorphisms between dynamical systems. I have a few related questions about homeomorphic and topologically conjugate dynamical systems. Questions How can I determine if a homeomorphism is orientation presevering? If two dynamical systems are Topologically Conjugate (that is $f \circ h=h \circ g$), does this imply that $h$ is an orientation preserving homeomorphism? (Answered see comment below this post) What properties are preserved between two topologically conjugate dynamical systems, compared to two dynamical systems which are only homeomorphic to each other? Definitions $f:X \rightarrow X$, $g:Y \rightarrow Y$ and $h:Y \rightarrow X$ are continuous functions on smooth orientable manifolds, $X$ and $Y$. Topologically Conjugate: $f \circ h=h \circ g$ and $h$ is homeomorphsim. Homeomorphism What it means for a manifold to be orientable . Notes Partial answers are appreciated. If you need any clarification please ask.",,"['differential-geometry', 'differential-topology', 'dynamical-systems']"
32,Geodesic flow on Riemannian manifolds,Geodesic flow on Riemannian manifolds,,A naive question. I see many research papers on geodesic flows on Riemannian manifolds. Some of them try for instance to show that they are ergodic. It is probably a very broad question but could you give me some general ideas about why is the study of this flow important? And what does the fact that it is ergodic tells us?,A naive question. I see many research papers on geodesic flows on Riemannian manifolds. Some of them try for instance to show that they are ergodic. It is probably a very broad question but could you give me some general ideas about why is the study of this flow important? And what does the fact that it is ergodic tells us?,,"['differential-geometry', 'ergodic-theory', 'geodesic']"
33,Writing Laplacian in terms of tangential and normal derivatives in local coordinates,Writing Laplacian in terms of tangential and normal derivatives in local coordinates,,"I'm reading a text right now (in complex analysis -- hence the 2$n$ dimensions), and am struggling with a detail in a proof. Now in this proof we're doing a local argument near the boundary of a smoothly bounded domain $\Omega$, so we work in the coordinates of the lower half-space $(t_1,\ldots ,t_{2n-1},r)$ in $\mathbb{R}^{2n}\cong\mathbb{C}^{n}$ where $r<0$. Now in this the proof it's stated that, in terms of tangential and normal derivatives in these local coordinates, the Laplace operator can be written as $$ \Delta =\frac{\partial^2}{\partial\nu^2}+\frac{1}{2g}\frac{\partial g}{\partial\nu}\frac{\partial}{\partial\nu}+\frac{1}{\sqrt{g}}\sum_{j,k=1}^{2n-1}\frac{\partial}{\partial t_k}\left(g^{jk}\sqrt{g}\frac{\partial}{\partial t_j}\right), $$ where $\frac{\partial}{\partial \nu}=\frac{\partial}{\partial r}$ is the normal derivative, $(g_{jk})$ gives the Riemannian metric induced on the level sets of $r$ by the standard Euclidean metric, $(g^{jk})=(g_{jk})^{-1}$, and $g=\det(g_{jk})$. However, I don't immediately see this. I imagine it's a consequence of the representation $$ \Delta= \frac{1}{\sqrt{\tilde{g}}}\sum_{j,k=1}^{2n}\frac{\partial}{\partial t_k}\left({\tilde{g}}^{jk}\sqrt{\tilde{g}}\frac{\partial}{\partial t_j}\right) $$ (where now $\tilde{g}$ is the induced metric on the lower half-space and $t_{2n}:=r$ for simplicity). I've tried to separate all of the terms in the sum involving the normal derivative but there are these extra terms that I can't seem to get rid of; for example, when trying to pull the $\frac{\partial^2}{\partial\nu^2}$ term out of the sum I get $$ \frac{1}{\sqrt{\tilde{g}}}\frac{\partial}{\partial\nu}\left(\tilde{g}^{2n2n}\sqrt{\tilde{g}}\frac{\partial}{\partial\nu}\right)=\tilde{g}^{2n2n}\frac{\partial^2}{\partial\nu^2}+\frac{\partial\tilde{g}^{2n2n}}{\partial\nu}\frac{\partial}{\partial\nu}+\frac{\tilde{g}^{2n2n}}{2\tilde{g}}\frac{\partial\tilde{g}}{\partial\nu}\frac{\partial}{\partial\nu}. $$ So I suppose I believe the assertion if I can justify to myself that $\tilde{g}^{2n2n}\equiv 1$ and $\tilde{g}^{j2n}\equiv 0$, $1\leq j\leq 2n-1$, which sort of makes sense because of the way the coordinates are chosen, but I'm not fully convinced. I'll be happy to provide more context if necessary. Any help is greatly appreciated. Thanks.","I'm reading a text right now (in complex analysis -- hence the 2$n$ dimensions), and am struggling with a detail in a proof. Now in this proof we're doing a local argument near the boundary of a smoothly bounded domain $\Omega$, so we work in the coordinates of the lower half-space $(t_1,\ldots ,t_{2n-1},r)$ in $\mathbb{R}^{2n}\cong\mathbb{C}^{n}$ where $r<0$. Now in this the proof it's stated that, in terms of tangential and normal derivatives in these local coordinates, the Laplace operator can be written as $$ \Delta =\frac{\partial^2}{\partial\nu^2}+\frac{1}{2g}\frac{\partial g}{\partial\nu}\frac{\partial}{\partial\nu}+\frac{1}{\sqrt{g}}\sum_{j,k=1}^{2n-1}\frac{\partial}{\partial t_k}\left(g^{jk}\sqrt{g}\frac{\partial}{\partial t_j}\right), $$ where $\frac{\partial}{\partial \nu}=\frac{\partial}{\partial r}$ is the normal derivative, $(g_{jk})$ gives the Riemannian metric induced on the level sets of $r$ by the standard Euclidean metric, $(g^{jk})=(g_{jk})^{-1}$, and $g=\det(g_{jk})$. However, I don't immediately see this. I imagine it's a consequence of the representation $$ \Delta= \frac{1}{\sqrt{\tilde{g}}}\sum_{j,k=1}^{2n}\frac{\partial}{\partial t_k}\left({\tilde{g}}^{jk}\sqrt{\tilde{g}}\frac{\partial}{\partial t_j}\right) $$ (where now $\tilde{g}$ is the induced metric on the lower half-space and $t_{2n}:=r$ for simplicity). I've tried to separate all of the terms in the sum involving the normal derivative but there are these extra terms that I can't seem to get rid of; for example, when trying to pull the $\frac{\partial^2}{\partial\nu^2}$ term out of the sum I get $$ \frac{1}{\sqrt{\tilde{g}}}\frac{\partial}{\partial\nu}\left(\tilde{g}^{2n2n}\sqrt{\tilde{g}}\frac{\partial}{\partial\nu}\right)=\tilde{g}^{2n2n}\frac{\partial^2}{\partial\nu^2}+\frac{\partial\tilde{g}^{2n2n}}{\partial\nu}\frac{\partial}{\partial\nu}+\frac{\tilde{g}^{2n2n}}{2\tilde{g}}\frac{\partial\tilde{g}}{\partial\nu}\frac{\partial}{\partial\nu}. $$ So I suppose I believe the assertion if I can justify to myself that $\tilde{g}^{2n2n}\equiv 1$ and $\tilde{g}^{j2n}\equiv 0$, $1\leq j\leq 2n-1$, which sort of makes sense because of the way the coordinates are chosen, but I'm not fully convinced. I'll be happy to provide more context if necessary. Any help is greatly appreciated. Thanks.",,"['differential-geometry', 'riemannian-geometry']"
34,Moduli space of lines in $\mathbb{CP}^3$,Moduli space of lines in,\mathbb{CP}^3,"Let $J$ be an almost complex structure on $\mathbb{CP}^3$ whose Chern classes are the same as those of the standard complex structure. Let $A$ be the generator of $H_2(\mathbb{CP}^3;\mathbb{Z})$, i.e. the homology class of lines. I would like to show that the moduli space of $J$-holomorphic spheres representing the homology class $A$ is smooth . My guess is that every $J$-holomorphic $A$-sphere $u$ is immersed and has pullback bundle $$u^{\ast}T\mathbb{CP}^3=\mathcal{O}(2)\oplus\mathcal{O}(1)\oplus\mathcal{O}(1).$$ So if I could show that each summand is invariant under $D_u$, I could apply Lemma 3.3.2 from McDuff and Salamon to conclude that $D_u$ is surjective (i.e. the moduli space is smooth). The first summand is invariant by the definition of $D_u$. What about the other two summands? Is this reasoning correct? Note that if $J$ is the standard complex structure, then the moduli space is $\mathrm{Gr}_2(\mathbb{C}^4)$ (equivalently, the Klein quadric $Q_4\subset\mathbb{CP}^5$), as shown in the answer to this question .","Let $J$ be an almost complex structure on $\mathbb{CP}^3$ whose Chern classes are the same as those of the standard complex structure. Let $A$ be the generator of $H_2(\mathbb{CP}^3;\mathbb{Z})$, i.e. the homology class of lines. I would like to show that the moduli space of $J$-holomorphic spheres representing the homology class $A$ is smooth . My guess is that every $J$-holomorphic $A$-sphere $u$ is immersed and has pullback bundle $$u^{\ast}T\mathbb{CP}^3=\mathcal{O}(2)\oplus\mathcal{O}(1)\oplus\mathcal{O}(1).$$ So if I could show that each summand is invariant under $D_u$, I could apply Lemma 3.3.2 from McDuff and Salamon to conclude that $D_u$ is surjective (i.e. the moduli space is smooth). The first summand is invariant by the definition of $D_u$. What about the other two summands? Is this reasoning correct? Note that if $J$ is the standard complex structure, then the moduli space is $\mathrm{Gr}_2(\mathbb{C}^4)$ (equivalently, the Klein quadric $Q_4\subset\mathbb{CP}^5$), as shown in the answer to this question .",,"['differential-geometry', 'algebraic-geometry', 'symplectic-geometry']"
35,Defition of the Degree of a line bundle,Defition of the Degree of a line bundle,,"I was reading this notes , and there is some things that is unclear to me about the defition of the degree of a line bundle, page 16. First of all, here is the construction: Let $L$ be a complex line bundle on Riemann surface $C$. Consider a general section $\sigma : C \rightarrow L$. We can produce such a section by giving it locally and then gluing it together using a partition of unity. Locally, the line bundle $L$ is trivial, so it looks like $\mathbb{C}\times \Delta\rightarrow \Delta$, where $\Delta$ is the open unit disk. In this local picture, $\sigma$ is just a map $\Delta \rightarrow \mathbb{C}$.   By perturbing $\sigma$ we can insist that it is transverse to the zero section.Then locally, the inverse image of $0 \in \mathbb{C}$ under the map $\sigma: \Delta \rightarrow \mathbb{C}$ is a finite number of points. Each point $p \in \mathbb{C}$ where $\sigma$ intersects the zero section is called a zero of $\sigma$. Around each such point p the section $\sigma$ is a map $\sigma: \Delta \rightarrow \mathbb{C}$ where $p=0 \in \Delta$ and $\sigma(0)=0$. The differential $d\sigma:T_0\Delta \rightarrow T_0\mathbb{C}$ is nonsingular two-by-two matrix. Notice that there was an ambiguity since the map $\sigma: \Delta \rightarrow \mathbb{C}$ is defined up to post-multiplication by $\mathbb{C}^{*}$. Fortunately, multiplying by a complex number does not change the sing of $\mathrm{det}\mbox{ }d\sigma$. Definition: The degree of $L$ is $\mathrm{deg}(L)=\sum_{p}\mathrm{sgn}(p) \in \mathbb{Z}$, where the sum is over all points where a transverse section $\sigma$ is zero. My questions: Q1) In the construction is used that $\sigma$ is of a specific type, satisfying that in the trivialization, as a function of $\Delta \rightarrow \mathbb{C}$, $\sigma$ is differentiable. But, in the definition he doesn't mention it. Why is it not important? Q2) Why the definition doesn't depend on the section I take? Here's another question that is not about the definition, but an application of it: Q3) How can I show using this definition that the degree of the tangent bundle on a Riemann surface of genus $g$ is $2-2g$.","I was reading this notes , and there is some things that is unclear to me about the defition of the degree of a line bundle, page 16. First of all, here is the construction: Let $L$ be a complex line bundle on Riemann surface $C$. Consider a general section $\sigma : C \rightarrow L$. We can produce such a section by giving it locally and then gluing it together using a partition of unity. Locally, the line bundle $L$ is trivial, so it looks like $\mathbb{C}\times \Delta\rightarrow \Delta$, where $\Delta$ is the open unit disk. In this local picture, $\sigma$ is just a map $\Delta \rightarrow \mathbb{C}$.   By perturbing $\sigma$ we can insist that it is transverse to the zero section.Then locally, the inverse image of $0 \in \mathbb{C}$ under the map $\sigma: \Delta \rightarrow \mathbb{C}$ is a finite number of points. Each point $p \in \mathbb{C}$ where $\sigma$ intersects the zero section is called a zero of $\sigma$. Around each such point p the section $\sigma$ is a map $\sigma: \Delta \rightarrow \mathbb{C}$ where $p=0 \in \Delta$ and $\sigma(0)=0$. The differential $d\sigma:T_0\Delta \rightarrow T_0\mathbb{C}$ is nonsingular two-by-two matrix. Notice that there was an ambiguity since the map $\sigma: \Delta \rightarrow \mathbb{C}$ is defined up to post-multiplication by $\mathbb{C}^{*}$. Fortunately, multiplying by a complex number does not change the sing of $\mathrm{det}\mbox{ }d\sigma$. Definition: The degree of $L$ is $\mathrm{deg}(L)=\sum_{p}\mathrm{sgn}(p) \in \mathbb{Z}$, where the sum is over all points where a transverse section $\sigma$ is zero. My questions: Q1) In the construction is used that $\sigma$ is of a specific type, satisfying that in the trivialization, as a function of $\Delta \rightarrow \mathbb{C}$, $\sigma$ is differentiable. But, in the definition he doesn't mention it. Why is it not important? Q2) Why the definition doesn't depend on the section I take? Here's another question that is not about the definition, but an application of it: Q3) How can I show using this definition that the degree of the tangent bundle on a Riemann surface of genus $g$ is $2-2g$.",,"['differential-geometry', 'smooth-manifolds', 'vector-bundles', 'riemann-surfaces']"
36,Is a principal bundle of a principal bundle still principal?,Is a principal bundle of a principal bundle still principal?,,"Let $\left(P_1,\pi_1,M,G_1\right)$ and $\left(P_2,\pi_2,P_1,G_2\right)$ be two principal bundles, where $M$, $P_1$ and $P_2$ are differential manifolds, and $G_1$ and $G_2$ are Lie groups. With these settings, the chain $$ P_2\xrightarrow{\pi_2}P_1\xrightarrow{\pi_1}M $$ would induce $$ \pi_1\circ\pi_2:P_2\to M. $$ My questions are: (1) Is this $\pi_1\circ\pi_2$ always a principal bundle, and (2) In the case where $\pi_1\circ\pi_2$ is a principal bundle, is its structure group always $G_1\times G_2$? Motivation . That $\pi_1\circ\pi_2$ is always a fiber bundle seems straightforward, but I am curious as to whether this hierarchical system preserves the Lie group structure (especially if it does in the direct-product fashion). Thank you!","Let $\left(P_1,\pi_1,M,G_1\right)$ and $\left(P_2,\pi_2,P_1,G_2\right)$ be two principal bundles, where $M$, $P_1$ and $P_2$ are differential manifolds, and $G_1$ and $G_2$ are Lie groups. With these settings, the chain $$ P_2\xrightarrow{\pi_2}P_1\xrightarrow{\pi_1}M $$ would induce $$ \pi_1\circ\pi_2:P_2\to M. $$ My questions are: (1) Is this $\pi_1\circ\pi_2$ always a principal bundle, and (2) In the case where $\pi_1\circ\pi_2$ is a principal bundle, is its structure group always $G_1\times G_2$? Motivation . That $\pi_1\circ\pi_2$ is always a fiber bundle seems straightforward, but I am curious as to whether this hierarchical system preserves the Lie group structure (especially if it does in the direct-product fashion). Thank you!",,"['differential-geometry', 'lie-groups', 'fiber-bundles', 'principal-bundles']"
37,The Gauß map of a minimal surface: is it holomorphic or antiholomorphic?,The Gauß map of a minimal surface: is it holomorphic or antiholomorphic?,,"I'm reading A survey on classical minimal surface theory , by William H. Meeks and Joaquín Pérez. In the early beginning, they start giving eight definitions of minimal surfaces. The last of them is Definition 2.1.8 A surface $M\subset \Bbb R^3$ is minimal if and only if its stereographically projected Gauß map $g:M\to \Bbb{C}\cup \{\infty\}$ is meromorphic with respect to the underlying Riemann surface structure. The authors try to justify this definition as follows: a previous definition of minimal surfaces says that a surface $M\subset \Bbb R^3$ is minimal if it has indentically zero mean curvature. So, if $N:M\to \Bbb S^2\subset \Bbb R^3$ is the usual Gauß map, we know that $-dN_p:T_pM\to T_p\Bbb S^2\cong T_pM$ is a linear symmetric operator $\forall p\in M$ and, therefore, choosing an orthonormal basis for $T_pM$, $$-dN_p=\begin{pmatrix} a&b\\b&c\end{pmatrix},$$ a symmetric matrix. Since $$H=\text{arithmetic average of principal curvatures} = \frac{1}{2}\mathrm{trace} (-dN_p),$$ we must have $c=-a$, in order to get a minimal surface. Then they say that, identifying $\Bbb S^2$ with the Riemann sphere $\Bbb C\cup \{\infty\}$ together with the Cauchy-Riemann equations , this would show that the Gauß map $g:M\to \Bbb C\cup\{\infty\}$ must satisfy the definition above. My doubt is: the matrix $$-dN_p=\begin{pmatrix} a&b\\ b&-a\end{pmatrix}$$ does not satisfy Cauchy-Riemann equations. For this, it should have the form $$\begin{pmatrix} a&-b\\ b&a\end{pmatrix}.$$ However, if I invert the orientation of $\Bbb C\cup\{\infty\}$ and ""pretend"" I did nothing, the matrix gets that form and Cauchy-Riemann equations are indeed satisfied. Furthermore, other sources (like this Handbook of Differential Geometry ) says in page 228 that such Gauß maps of minimal surfaces are indeed anti -holomorphic. Which definition is correct?","I'm reading A survey on classical minimal surface theory , by William H. Meeks and Joaquín Pérez. In the early beginning, they start giving eight definitions of minimal surfaces. The last of them is Definition 2.1.8 A surface $M\subset \Bbb R^3$ is minimal if and only if its stereographically projected Gauß map $g:M\to \Bbb{C}\cup \{\infty\}$ is meromorphic with respect to the underlying Riemann surface structure. The authors try to justify this definition as follows: a previous definition of minimal surfaces says that a surface $M\subset \Bbb R^3$ is minimal if it has indentically zero mean curvature. So, if $N:M\to \Bbb S^2\subset \Bbb R^3$ is the usual Gauß map, we know that $-dN_p:T_pM\to T_p\Bbb S^2\cong T_pM$ is a linear symmetric operator $\forall p\in M$ and, therefore, choosing an orthonormal basis for $T_pM$, $$-dN_p=\begin{pmatrix} a&b\\b&c\end{pmatrix},$$ a symmetric matrix. Since $$H=\text{arithmetic average of principal curvatures} = \frac{1}{2}\mathrm{trace} (-dN_p),$$ we must have $c=-a$, in order to get a minimal surface. Then they say that, identifying $\Bbb S^2$ with the Riemann sphere $\Bbb C\cup \{\infty\}$ together with the Cauchy-Riemann equations , this would show that the Gauß map $g:M\to \Bbb C\cup\{\infty\}$ must satisfy the definition above. My doubt is: the matrix $$-dN_p=\begin{pmatrix} a&b\\ b&-a\end{pmatrix}$$ does not satisfy Cauchy-Riemann equations. For this, it should have the form $$\begin{pmatrix} a&-b\\ b&a\end{pmatrix}.$$ However, if I invert the orientation of $\Bbb C\cup\{\infty\}$ and ""pretend"" I did nothing, the matrix gets that form and Cauchy-Riemann equations are indeed satisfied. Furthermore, other sources (like this Handbook of Differential Geometry ) says in page 228 that such Gauß maps of minimal surfaces are indeed anti -holomorphic. Which definition is correct?",,"['differential-geometry', 'definition', 'riemannian-geometry', 'minimal-surfaces']"
38,How do I find a Gauss map and what should it look like?,How do I find a Gauss map and what should it look like?,,"So the problem says to compute the gauss map and it's derivative for the cone parametrized by  $$\mathbf x (u,v)=(v\cos u, v\sin u, v).$$ From what I understand, a Gauss map takes the unit normal vectors of this cone and maps them into the unit sphere in order to give geometric meaning to the equation by examining the shape traced on the sphere by the normal vectors of the cone. What I don't understand is what this should look like. It seems to me that the Gauss map should just be the equation for the unit normal vector, which I found like this: $$\begin{split} \mathbf x_u&= (-v\sin u, v\cos u, 0)\\ \mathbf x_v&= (\cos u, \sin u, 1)\\ U &= \frac{\mathbf x_u \times \mathbf x_v}{|\mathbf x_u \times \mathbf x_v|}\\ &= \frac{1}{\sqrt2}(\cos u,\sin u,-1). \end{split}$$ But I'm not sure how I should state my answer. Should it be $f(u,v)= \frac{1}{\sqrt2}(\cos u,\sin u,-1)$? And for finding the derivative of the Gauss map, also called the second fundamental form, I know this is equal to the negative of the shape operator. This I am also a bit confused about. Here is what I know about the shape operator: I think this should look like a matrix $S$ so that if: $$\begin{split} S(\mathbf x_u)&= a\mathbf x_u + b\mathbf x_v\\ S(\mathbf x_v)&=c\mathbf x_u + d\mathbf x_v. \end{split}$$ then $$S=  \left(     \begin{matrix}     a & c \\     b & d \\     \end{matrix}\right) $$ And using $$E=\mathbf x_u \cdot\mathbf x_u = v^2, \ \ F= \mathbf x_u \cdot\mathbf x_v = 0, \ \ \ G= \mathbf x_v\cdot\mathbf x_v = 2.$$ $$l= \mathbf x_{uu}\cdot U = -\frac{v}{\sqrt 2},\ \ m= \mathbf x_{uv}\cdot U =   \mathbf x_{vu}\cdot U  = 0,\ \ n= \mathbf  x_{vv}\cdot U = 0.$$ I can find $$ \begin{split}  a&=-\frac{ Fm - Gl }{ EG - F^2 } = -\frac{1}{v\sqrt2}\\ b&=-\frac{ Fl + Em }{ EG - F^2 } = 0 \\ c&= -\frac{ -mG + Fn }{ EG - F^2 } = 0\\ d&= \frac{ En - Fm }{ EG - F^2 } = 0. \end{split}$$ so the derivative of the gauss map is $$\left(     \begin{matrix}     -\frac{1}{v\sqrt2} & 0 \\     0 & 0 \\     \end{matrix}\right) $$ Am I on the right path? Any insight would be appreciated.","So the problem says to compute the gauss map and it's derivative for the cone parametrized by  $$\mathbf x (u,v)=(v\cos u, v\sin u, v).$$ From what I understand, a Gauss map takes the unit normal vectors of this cone and maps them into the unit sphere in order to give geometric meaning to the equation by examining the shape traced on the sphere by the normal vectors of the cone. What I don't understand is what this should look like. It seems to me that the Gauss map should just be the equation for the unit normal vector, which I found like this: $$\begin{split} \mathbf x_u&= (-v\sin u, v\cos u, 0)\\ \mathbf x_v&= (\cos u, \sin u, 1)\\ U &= \frac{\mathbf x_u \times \mathbf x_v}{|\mathbf x_u \times \mathbf x_v|}\\ &= \frac{1}{\sqrt2}(\cos u,\sin u,-1). \end{split}$$ But I'm not sure how I should state my answer. Should it be $f(u,v)= \frac{1}{\sqrt2}(\cos u,\sin u,-1)$? And for finding the derivative of the Gauss map, also called the second fundamental form, I know this is equal to the negative of the shape operator. This I am also a bit confused about. Here is what I know about the shape operator: I think this should look like a matrix $S$ so that if: $$\begin{split} S(\mathbf x_u)&= a\mathbf x_u + b\mathbf x_v\\ S(\mathbf x_v)&=c\mathbf x_u + d\mathbf x_v. \end{split}$$ then $$S=  \left(     \begin{matrix}     a & c \\     b & d \\     \end{matrix}\right) $$ And using $$E=\mathbf x_u \cdot\mathbf x_u = v^2, \ \ F= \mathbf x_u \cdot\mathbf x_v = 0, \ \ \ G= \mathbf x_v\cdot\mathbf x_v = 2.$$ $$l= \mathbf x_{uu}\cdot U = -\frac{v}{\sqrt 2},\ \ m= \mathbf x_{uv}\cdot U =   \mathbf x_{vu}\cdot U  = 0,\ \ n= \mathbf  x_{vv}\cdot U = 0.$$ I can find $$ \begin{split}  a&=-\frac{ Fm - Gl }{ EG - F^2 } = -\frac{1}{v\sqrt2}\\ b&=-\frac{ Fl + Em }{ EG - F^2 } = 0 \\ c&= -\frac{ -mG + Fn }{ EG - F^2 } = 0\\ d&= \frac{ En - Fm }{ EG - F^2 } = 0. \end{split}$$ so the derivative of the gauss map is $$\left(     \begin{matrix}     -\frac{1}{v\sqrt2} & 0 \\     0 & 0 \\     \end{matrix}\right) $$ Am I on the right path? Any insight would be appreciated.",,"['differential-geometry', 'riemannian-geometry', 'submanifold']"
39,Is the exterior/wedge product of differential forms injective?,Is the exterior/wedge product of differential forms injective?,,"Is the exterior wedge product of differential forms $$ \begin{align*} \Omega(X) \otimes_{\mathbb{R}} \Omega(Y) &\longrightarrow \Omega(X\times Y) \\ \alpha \otimes \beta &\longmapsto \pi_X^*\alpha \wedge \pi_Y^*\beta \end{align*} $$ injective? UPDATE 1: I think I got it locally: Suppose  $$\sum_{i=1}^n \alpha^i(x)\wedge \beta^i(y) = 0$$  for all $(x,y)\in X\times Y$. If $X=\mathbb{R}^N$, $Y=\mathbb{R}^M$ we write  $$ \alpha^i(x) = \sum_I \alpha^i_I(x) \mathrm{d}x^I,\quad \beta^i(y) = \sum_J \beta^i_J(y) \mathrm{d}y^J $$ for $i=1,\ldots,n$. The equation is equivalent to $$ \alpha_I(x) \cdot \beta_J(y) = 0 $$ for all $I$, $J$ and $x,y$, where we collected $\alpha^i_I$'s and $\beta^i_J$'s in vectors $\alpha_I(x), \beta_J(x) \in \mathbb{R}^n$ and used the dot product. It follows that there is an orthonormal basis $v_1, \ldots, v_{k}, w_1, \ldots, w_l\in \mathbb{R}^n$, $k + l =n$ and smooth coefficients $a_I^u(x)$, $b_J^v(y)$ such that $$ \begin{aligned} \alpha_I(x)&= a_I^1(x) v_1 + \ldots + a_I^k(x) v_k \\ \beta_J(y) &= b_J^1(y) w_1+\ldots + b_J^l(y) w_l \end{aligned} $$ for all $I, J$ and $x,y$. Now we have  $$ \sum_{i=1}^n \alpha^i \otimes \beta^i = \sum_{I,J,u,p} \bigl(\sum_{i=1}^n v^i_u w^i_p\bigr) (a^u_I (x) \mathrm{d}x^I)\otimes (b^v_J(y) \mathrm{d}x^J) = 0 $$ because $v_u \perp w_p$. UPDATE 2: For $X$, $Y$ compact we pick coordinate coverings $(U_1,x_1),\ldots,(U_A,x_A)$ of $X$ and $(V_1,y_1),\ldots,(V_B,y_B)$ of $Y$. We pick subordinate partitions of unity $(\lambda_a)$ and $(\mu_b)$ respectively. We do it in such a way that the collections $(\lambda_a\mathrm{d}x^I_a)_{a,I} \subset \Omega(X)$ and $(\mu_b \mathrm{d}y_b^J)_{b,J} \subset \Omega(Y)$ are $\mathbb{R}$-linearly independent. It follows that the collection $\bigl((\lambda_a\mathrm{d}x^I)\otimes(\mu_b \mathrm{d}y^J)\bigr)_{a,I,b,J}$ is linearly independent in $\Omega(X)\otimes_{\mathbb{R}}\Omega(Y)$. We write $\alpha^i$ and $\beta^i$ as linear combinations (with functions as coefficients) of $(\lambda_a\mathrm{d}x^I)$ and $(\mu_b \mathrm{d}y^J)$ respectively and apply exactly the same argument as above replacing $(\mathrm{d}x^I)_I$ by $(\lambda_a\mathrm{d}x^I)_{a,I}$ and $(\mathrm{d}y^J)_J$ by $(\lambda_b\mathrm{d}y^J)_{b,J}$. We see that the exterior wedge product for compact $X$, $Y$ is injective. UPDATE 3 (reaction to a comment): It is never an isomorphism since e.g. $e^{xy}$ is not equal to a finite sum of products $f(x)g(y)$. UPDATE 4: I think I got it for non compact $X$, $Y$ as well:  Let $U_i$, resp. $V_j$ be exhaustions of $X$, resp. $Y$ by relatively compact open sets. Each of these have a finite atlas, and hence, modifying the proof above, the exterior wedge product $\Omega(U_i)\otimes \Omega(V_j) \rightarrow \Omega(U_i\times V_j)$ is injective. For fixed $i$ the exterior wedge product induces an injection  $$\varprojlim_j \Omega(U_i)\otimes \Omega(V_j) \simeq \Omega(U_i) \otimes \varprojlim_j(\Omega(V_j)) \longrightarrow \varprojlim_j \Omega(U_i \times V_j)$$ where we used that the inverse limit commutes with tensor product and preserves exactness. Taking the inverse limit over $i$ we get similarly an injection $$ \varprojlim_i(\Omega(U_i))\otimes \varprojlim_j(\Omega(V_j)) \longrightarrow \varprojlim_i \varprojlim_j \Omega(U_i\times V_j) $$ It is easy to check that the restrictions from $X$ to $U_i$, resp. $Y$ to $V_j$, resp. $X\times Y$ to $U_i\times V_j$ induce embeddings of $\Omega(X)$, resp. $\Omega(Y)$, resp. $\Omega(X\times Y)$ into $\varprojlim_i(\Omega(U_i))$, resp. $\varprojlim_j(\Omega(V_j))$, resp. $\varprojlim_i \varprojlim_j \Omega(U_i\times V_j)$ and that the induced injection restricts to the exterior wedge product $\Omega(X)\otimes \Omega(Y) \rightarrow \Omega(X\times Y)$. Consequently it is injective. QUESTION LEFT: Is the above proof correct? Shall I close the question?","Is the exterior wedge product of differential forms $$ \begin{align*} \Omega(X) \otimes_{\mathbb{R}} \Omega(Y) &\longrightarrow \Omega(X\times Y) \\ \alpha \otimes \beta &\longmapsto \pi_X^*\alpha \wedge \pi_Y^*\beta \end{align*} $$ injective? UPDATE 1: I think I got it locally: Suppose  $$\sum_{i=1}^n \alpha^i(x)\wedge \beta^i(y) = 0$$  for all $(x,y)\in X\times Y$. If $X=\mathbb{R}^N$, $Y=\mathbb{R}^M$ we write  $$ \alpha^i(x) = \sum_I \alpha^i_I(x) \mathrm{d}x^I,\quad \beta^i(y) = \sum_J \beta^i_J(y) \mathrm{d}y^J $$ for $i=1,\ldots,n$. The equation is equivalent to $$ \alpha_I(x) \cdot \beta_J(y) = 0 $$ for all $I$, $J$ and $x,y$, where we collected $\alpha^i_I$'s and $\beta^i_J$'s in vectors $\alpha_I(x), \beta_J(x) \in \mathbb{R}^n$ and used the dot product. It follows that there is an orthonormal basis $v_1, \ldots, v_{k}, w_1, \ldots, w_l\in \mathbb{R}^n$, $k + l =n$ and smooth coefficients $a_I^u(x)$, $b_J^v(y)$ such that $$ \begin{aligned} \alpha_I(x)&= a_I^1(x) v_1 + \ldots + a_I^k(x) v_k \\ \beta_J(y) &= b_J^1(y) w_1+\ldots + b_J^l(y) w_l \end{aligned} $$ for all $I, J$ and $x,y$. Now we have  $$ \sum_{i=1}^n \alpha^i \otimes \beta^i = \sum_{I,J,u,p} \bigl(\sum_{i=1}^n v^i_u w^i_p\bigr) (a^u_I (x) \mathrm{d}x^I)\otimes (b^v_J(y) \mathrm{d}x^J) = 0 $$ because $v_u \perp w_p$. UPDATE 2: For $X$, $Y$ compact we pick coordinate coverings $(U_1,x_1),\ldots,(U_A,x_A)$ of $X$ and $(V_1,y_1),\ldots,(V_B,y_B)$ of $Y$. We pick subordinate partitions of unity $(\lambda_a)$ and $(\mu_b)$ respectively. We do it in such a way that the collections $(\lambda_a\mathrm{d}x^I_a)_{a,I} \subset \Omega(X)$ and $(\mu_b \mathrm{d}y_b^J)_{b,J} \subset \Omega(Y)$ are $\mathbb{R}$-linearly independent. It follows that the collection $\bigl((\lambda_a\mathrm{d}x^I)\otimes(\mu_b \mathrm{d}y^J)\bigr)_{a,I,b,J}$ is linearly independent in $\Omega(X)\otimes_{\mathbb{R}}\Omega(Y)$. We write $\alpha^i$ and $\beta^i$ as linear combinations (with functions as coefficients) of $(\lambda_a\mathrm{d}x^I)$ and $(\mu_b \mathrm{d}y^J)$ respectively and apply exactly the same argument as above replacing $(\mathrm{d}x^I)_I$ by $(\lambda_a\mathrm{d}x^I)_{a,I}$ and $(\mathrm{d}y^J)_J$ by $(\lambda_b\mathrm{d}y^J)_{b,J}$. We see that the exterior wedge product for compact $X$, $Y$ is injective. UPDATE 3 (reaction to a comment): It is never an isomorphism since e.g. $e^{xy}$ is not equal to a finite sum of products $f(x)g(y)$. UPDATE 4: I think I got it for non compact $X$, $Y$ as well:  Let $U_i$, resp. $V_j$ be exhaustions of $X$, resp. $Y$ by relatively compact open sets. Each of these have a finite atlas, and hence, modifying the proof above, the exterior wedge product $\Omega(U_i)\otimes \Omega(V_j) \rightarrow \Omega(U_i\times V_j)$ is injective. For fixed $i$ the exterior wedge product induces an injection  $$\varprojlim_j \Omega(U_i)\otimes \Omega(V_j) \simeq \Omega(U_i) \otimes \varprojlim_j(\Omega(V_j)) \longrightarrow \varprojlim_j \Omega(U_i \times V_j)$$ where we used that the inverse limit commutes with tensor product and preserves exactness. Taking the inverse limit over $i$ we get similarly an injection $$ \varprojlim_i(\Omega(U_i))\otimes \varprojlim_j(\Omega(V_j)) \longrightarrow \varprojlim_i \varprojlim_j \Omega(U_i\times V_j) $$ It is easy to check that the restrictions from $X$ to $U_i$, resp. $Y$ to $V_j$, resp. $X\times Y$ to $U_i\times V_j$ induce embeddings of $\Omega(X)$, resp. $\Omega(Y)$, resp. $\Omega(X\times Y)$ into $\varprojlim_i(\Omega(U_i))$, resp. $\varprojlim_j(\Omega(V_j))$, resp. $\varprojlim_i \varprojlim_j \Omega(U_i\times V_j)$ and that the induced injection restricts to the exterior wedge product $\Omega(X)\otimes \Omega(Y) \rightarrow \Omega(X\times Y)$. Consequently it is injective. QUESTION LEFT: Is the above proof correct? Shall I close the question?",,"['differential-geometry', 'exterior-algebra']"
40,Two definitions of holomorphic vector bundle,Two definitions of holomorphic vector bundle,,"I am stuck in the task of understanding of the following. I am trying to learn about holomorphic vector bundle. So far, I have found two definitions. Definition 1: One starts with the complex (smooth or topological, does not matter) vector bundle $\pi: E \rightarrow M$ over the complex manifold $M$ , assuming there is a local trivialization of $E$ whose transition maps are holomorphic maps. Definition 2: One again starts with complex vector bundle $\pi: E \rightarrow M$ over the complex manifold $M$ , only assuming that there is a complex structure on $E$ making $\pi: E \rightarrow M$ into a holomorphic map of complex manifolds. The implication D1 $\Rightarrow$ D2 is quite clear, as one can use the local trivialization together with holomorphic atlas on $M$ to define the holomorphic atlas on $E$ , such that $\pi$ is locally just a projection. The definition D1 is quite common. For example, I use the Lectures on Kähler Geometry . On the other hand, in lecture notes by Sean Pohorence, they use D2 . In the first reference, they give the equivalence D1 $\Leftrightarrow$ D2 as an excercise. I am completely stuck in the D2 $\Rightarrow$ D1 part. Excercise 2.0.7. in the second reference hints one to show that based on D2 , every local trivialization map $\phi: U \times \mathbb{C}^{k} \rightarrow \pi^{-1}(U)$ is automatically holomorphic. Clearly, this would prove D1 . Can someone hint me on this one? Some good reference (at least stating this precisely) would be fine. Interestingly, there is already some discussion in this topic here , where people suggest that this implication may not be true, which confuses me even more... With kind regards, Jan Vysoký","I am stuck in the task of understanding of the following. I am trying to learn about holomorphic vector bundle. So far, I have found two definitions. Definition 1: One starts with the complex (smooth or topological, does not matter) vector bundle over the complex manifold , assuming there is a local trivialization of whose transition maps are holomorphic maps. Definition 2: One again starts with complex vector bundle over the complex manifold , only assuming that there is a complex structure on making into a holomorphic map of complex manifolds. The implication D1 D2 is quite clear, as one can use the local trivialization together with holomorphic atlas on to define the holomorphic atlas on , such that is locally just a projection. The definition D1 is quite common. For example, I use the Lectures on Kähler Geometry . On the other hand, in lecture notes by Sean Pohorence, they use D2 . In the first reference, they give the equivalence D1 D2 as an excercise. I am completely stuck in the D2 D1 part. Excercise 2.0.7. in the second reference hints one to show that based on D2 , every local trivialization map is automatically holomorphic. Clearly, this would prove D1 . Can someone hint me on this one? Some good reference (at least stating this precisely) would be fine. Interestingly, there is already some discussion in this topic here , where people suggest that this implication may not be true, which confuses me even more... With kind regards, Jan Vysoký",\pi: E \rightarrow M M E \pi: E \rightarrow M M E \pi: E \rightarrow M \Rightarrow M E \pi \Leftrightarrow \Rightarrow \phi: U \times \mathbb{C}^{k} \rightarrow \pi^{-1}(U),"['differential-geometry', 'complex-geometry', 'vector-bundles']"
41,Connection on fiber bundle of generic fiber,Connection on fiber bundle of generic fiber,,"I am looking for references about connections on a generic fiber bundle.  A lot of books deal with connections on vector bundles, some books as the Kobayashi-Nomizu generalize the concept of connection to principal bundles. I know that exists also a more general notion of connection on fiber bundles (for example in Kolar-Michor-Slovak's book ""Natural Operators in Differential Geometry"" it is shown using horizontal and vertical bundles), but I have had some difficulties in finding other good references. Can someone suggest me a good book? This question is different from Reference Request for Fibre Bundle Theory from the Smooth Manifold Point of View as mine it is more specific on connections, among the books suggested there only the abovementioned K-M-S deals with  connections on general fiber bundles.","I am looking for references about connections on a generic fiber bundle.  A lot of books deal with connections on vector bundles, some books as the Kobayashi-Nomizu generalize the concept of connection to principal bundles. I know that exists also a more general notion of connection on fiber bundles (for example in Kolar-Michor-Slovak's book ""Natural Operators in Differential Geometry"" it is shown using horizontal and vertical bundles), but I have had some difficulties in finding other good references. Can someone suggest me a good book? This question is different from Reference Request for Fibre Bundle Theory from the Smooth Manifold Point of View as mine it is more specific on connections, among the books suggested there only the abovementioned K-M-S deals with  connections on general fiber bundles.",,"['differential-geometry', 'reference-request', 'fiber-bundles', 'connections']"
42,What is known about the space of geodesic vector fields on a surface?,What is known about the space of geodesic vector fields on a surface?,,"Let $M$ be a compact two-dimensional manifold. I'm interested in geodesic vector fields on $M$: smooth vector fields $v$ that have the property that every integral curve of the vector field is (locally) a geodesic. In other words $$\nabla_v v = \phi v$$ where $\phi$ is a function $M\to\mathbb{R}$. What is known about the space of such vector fields? Is there a way to characterize or parameterize them? For example, I imagine one possible construction is to pick a closed subset $S$ of $M$, construct the signed distance function $d_S$ to $S$, and set $v = \nabla d_S$. This vector field is undefined at the cut locus of $S$, but presumably that can be fixed by adjusting the magnitude of $v$ so that it vanishes near the cut locus.","Let $M$ be a compact two-dimensional manifold. I'm interested in geodesic vector fields on $M$: smooth vector fields $v$ that have the property that every integral curve of the vector field is (locally) a geodesic. In other words $$\nabla_v v = \phi v$$ where $\phi$ is a function $M\to\mathbb{R}$. What is known about the space of such vector fields? Is there a way to characterize or parameterize them? For example, I imagine one possible construction is to pick a closed subset $S$ of $M$, construct the signed distance function $d_S$ to $S$, and set $v = \nabla d_S$. This vector field is undefined at the cut locus of $S$, but presumably that can be fixed by adjusting the magnitude of $v$ so that it vanishes near the cut locus.",,"['differential-geometry', 'geodesic']"
43,Infinitesimals in an old Euler text (1778),Infinitesimals in an old Euler text (1778),,"I'm working through the text De curvis triangularibus of Leonard Euler. In this paper he defines orbiforms as some kind of curves with constant height. He uses these curves to find triangular curves (figure 1) as the evolute of these orbiforms. In the part where he starts working with these evolutes he uses infinitesimals in a formula which I have never seen before, can someone deduce his reasoning? Problem setting Consider the orbiform in figure 6 (drawn as a circle, but it doesn't need to be a circle) In the problem setting both $Ff$ and $Mm$ are normal to the curve (in each endpoint). Through a parameterization of the orbiform he deduced $$ FP = x = \frac{dS}{dp} \qquad   \qquad PM = y = \frac{pdS}{dp} - S $$ for a certain function $S$. Through further calculations he ends up with: $$ \sin \phi = \frac{1}{\sqrt{1+p^2}} \quad \& \quad \cos \phi = \frac{p}{\sqrt{1+p^2}} \qquad\Rightarrow \qquad d\phi =\frac{-dp}{1+p^2} $$ He then writes: Quod si iam brevitatis gratia ponamus $FN=v$, notum est, centrum circuli, curvam in $M$ osculantis, fore in puncto $U$, ita ut sit   $$ 			NU = \frac{d v\sin \phi}{d \phi}; $$ roughly translated as Let now for ease of use $FN=v$, it is known that the center of the osculationcircle in $M$ lies in the point $U$, then it is    $$ 			NU = \frac{d v\sin \phi}{d \phi}; $$ How did he deduce this last formula? In 1778 calculus was done using infinitesimals, and I guess $d v$ should be interpreted as a tiny increase of $v$, but how should I look at $d\phi$ and how did he derive this formula? Figures EDIT 16 november I've been looking trough other Euler and L'Hopital texts on curves, evolutes and involutes, but can't find any references. I did come up with an possible explanation though. Would it be reasonable that this was Euler's reasoning as well? Consider the picture below, of a zoomed in version of fig 6. Let $NU$ progress by $d\phi$, then since two normals which are but an infinitesimal apart have the same radius of curvature, $U$ is still the same point of the osculating circle. Now apply the law of sines to $\triangle NUU'$.  Also note how $|NU'| = d v$.  $$ \frac{NU'}{\sin d \phi} = \frac{NU}{\sin (\phi - d \phi)} $$ If we replace $\sin d\phi \stackrel{?}{\approx} d\phi$ and $\sin(\phi-d \phi) \stackrel{?}{\approx}  \sin \phi$ it follows $$ \frac{dv}{d \phi} = \frac{NU}{\sin \phi} \qquad \Rightarrow \qquad NU = \frac{d v\sin \phi}{d \phi} $$ Far fetched?","I'm working through the text De curvis triangularibus of Leonard Euler. In this paper he defines orbiforms as some kind of curves with constant height. He uses these curves to find triangular curves (figure 1) as the evolute of these orbiforms. In the part where he starts working with these evolutes he uses infinitesimals in a formula which I have never seen before, can someone deduce his reasoning? Problem setting Consider the orbiform in figure 6 (drawn as a circle, but it doesn't need to be a circle) In the problem setting both $Ff$ and $Mm$ are normal to the curve (in each endpoint). Through a parameterization of the orbiform he deduced $$ FP = x = \frac{dS}{dp} \qquad   \qquad PM = y = \frac{pdS}{dp} - S $$ for a certain function $S$. Through further calculations he ends up with: $$ \sin \phi = \frac{1}{\sqrt{1+p^2}} \quad \& \quad \cos \phi = \frac{p}{\sqrt{1+p^2}} \qquad\Rightarrow \qquad d\phi =\frac{-dp}{1+p^2} $$ He then writes: Quod si iam brevitatis gratia ponamus $FN=v$, notum est, centrum circuli, curvam in $M$ osculantis, fore in puncto $U$, ita ut sit   $$ 			NU = \frac{d v\sin \phi}{d \phi}; $$ roughly translated as Let now for ease of use $FN=v$, it is known that the center of the osculationcircle in $M$ lies in the point $U$, then it is    $$ 			NU = \frac{d v\sin \phi}{d \phi}; $$ How did he deduce this last formula? In 1778 calculus was done using infinitesimals, and I guess $d v$ should be interpreted as a tiny increase of $v$, but how should I look at $d\phi$ and how did he derive this formula? Figures EDIT 16 november I've been looking trough other Euler and L'Hopital texts on curves, evolutes and involutes, but can't find any references. I did come up with an possible explanation though. Would it be reasonable that this was Euler's reasoning as well? Consider the picture below, of a zoomed in version of fig 6. Let $NU$ progress by $d\phi$, then since two normals which are but an infinitesimal apart have the same radius of curvature, $U$ is still the same point of the osculating circle. Now apply the law of sines to $\triangle NUU'$.  Also note how $|NU'| = d v$.  $$ \frac{NU'}{\sin d \phi} = \frac{NU}{\sin (\phi - d \phi)} $$ If we replace $\sin d\phi \stackrel{?}{\approx} d\phi$ and $\sin(\phi-d \phi) \stackrel{?}{\approx}  \sin \phi$ it follows $$ \frac{dv}{d \phi} = \frac{NU}{\sin \phi} \qquad \Rightarrow \qquad NU = \frac{d v\sin \phi}{d \phi} $$ Far fetched?",,"['differential-geometry', 'math-history', 'infinitesimals']"
44,Explicit Connection on Frame bundle $F\mathbb{R}$,Explicit Connection on Frame bundle,F\mathbb{R},"I am trying to write down all the connections on the simple frame bundle $F\mathbb{R} \rightarrow \mathbb{R}$ as a choice of horizontal subspaces, but I get stuck. Please feel free to correct any of my statements, also I provide only results as I feel confident with the following derivations. Let $F\mathbb{R} \rightarrow \mathbb{R}$ be the frame bundle where $F\mathbb{R}\xrightarrow{\sim} \mathbb{R}\times\mathbb{R}_*$ and the projection map $\pi : \mathbb{R}\times\mathbb{R}_* \rightarrow \mathbb{R}$ the obvious projection onto the first factor. We consider the group $GL(1,\mathbb{R})$ acting on the left. We say that a tangent vector is in the vertical subspace if it is in $ker(\pi_*)$ where $\pi_*$ is the push forward map. Or similarly if the tangent vector is in the form $X^A_pf = \frac{\partial}{\partial t}\big|_0 f(p.exp(tA))$ where A is in the Lie algebra of the group. So : 1) I found that for $X_p = f(a,b)^i\frac{\partial}{\partial x^i}\big|_{(a,b)} \implies \pi_*(X_p) = f(p)^1\frac{\partial}{\partial t}\big|_a$ So we can conclude that $X_p$ is Vertical if and only if $f(p)^1 = 0$. To verify this result I tried to calculate $X^A_p$. For this I need to be able to compute $exp(tA)$ which is defined in my textbook as : $exp: T_eG \rightarrow T_pP$ which in my case is $exp: T_o\mathbb{R} \rightarrow T_{(a,b)}(\mathbb{R}\times \mathbb{R})$ and $exp(A) = \gamma^A(1)$ with $\gamma^A(1)$ the integral curve of the Left invariant vector field generated by A. So I started off by calculating the left invariant vector field : Let $A = a\frac{\partial}{\partial t}\big|_0$ be a vector in the Lie algebra. Define $L_g$ to be the left action : $L_g(a) = a + g$. I found out that $L_{g*}(A) = a\frac{\partial}{\partial t}\big|_g$. Now to calculate the integral curve we should have : $\gamma'(t) = a$ which leads me to having $\gamma(t) = at$ so that $\gamma(1) = exp(A) = a$ So we proceed with $X^A_{(b,c)}f = \frac{\partial}{\partial t}\big|_0 f((b,c).exp(tA)) = \frac{\partial}{\partial t}\big|_0 f((b,c).ta) = \frac{\partial}{\partial t}\big|_0 f((b,cta) = ca\partial_2\big|_{(b,c)}f $ which is indeed equivalent to $f(p)^1 = 0$ since only the second component is non-zero. So since the horizontal subspace is : \begin{align} T_{(a,b)}\mathbb{R}\times \mathbb{R}_* = Hor \oplus Ver\\ R_{g*}Hor_{(a,b)} = Hor_{(a,bg)}  \end{align} I set $X_{(a,b)} = f(a,b)^i\frac{\partial}{\partial x^i}\big|_{(a,b)} \in Hor \implies R_{g*}(X_{(a,b)}) = f(a,b)^1\frac{\partial}{\partial x^1}\big|_{(a,bg)} + gf(a,b)^2\frac{\partial}{\partial x^2}\big|_{(a,bg)}$ So we have the following constraints : $f(a,bg)^1 = f(a,b)^1 \implies f(a,b)^1 = f(a,1)^1$ $f(a,bg)^2 = gf(a,b)^2 \implies f(a,g)^2 = gf(a,1)^2$ From here I do not know what does it mean to : 1) Make a specific choice for Hor , for me Hor is completely determined bu the previous constraints. 2) How to project a tangent vector to Ver and Hor ? and How does that depend on the specific choice of Hor ? ( I need this to compute an explicit equation for the connection form $\omega_p = i^{-1}\circ Ver$. Thanks. EDIT : What is p in the third paragraph ? p is actually a point in the frame bundle $F\mathbb{R}$, so concretely $p\in \mathbb{R}\times \mathbb{R}_*$. p was a bad choice of notation. What is $exp(tA)$ This is a lie group element generated by the lie algebra element A. This is the Lie algebra of the Lie group $GL(1,\mathbb{R})$. We consider the left invariant vector field generated by A, then we find the integral curve $\gamma$ where the tangent vector of the curve at the identity is A, and then $exp(tA) = \gamma(t)$ What is $f(a,b)^i$ Yes this f is different from the f in the previous paragraph. It is the coordinates of the vector in the basis $\frac{\partial}{\partial x^i}\big|_{(a,b)}$. $(a,b)$ is point in the Frame bundle. And yes $p$ is a point in the frame bundle as well, I realize the notation is messy... But they are all point in the Frame bundle. $f(p)^1$ is the first coordinate.","I am trying to write down all the connections on the simple frame bundle $F\mathbb{R} \rightarrow \mathbb{R}$ as a choice of horizontal subspaces, but I get stuck. Please feel free to correct any of my statements, also I provide only results as I feel confident with the following derivations. Let $F\mathbb{R} \rightarrow \mathbb{R}$ be the frame bundle where $F\mathbb{R}\xrightarrow{\sim} \mathbb{R}\times\mathbb{R}_*$ and the projection map $\pi : \mathbb{R}\times\mathbb{R}_* \rightarrow \mathbb{R}$ the obvious projection onto the first factor. We consider the group $GL(1,\mathbb{R})$ acting on the left. We say that a tangent vector is in the vertical subspace if it is in $ker(\pi_*)$ where $\pi_*$ is the push forward map. Or similarly if the tangent vector is in the form $X^A_pf = \frac{\partial}{\partial t}\big|_0 f(p.exp(tA))$ where A is in the Lie algebra of the group. So : 1) I found that for $X_p = f(a,b)^i\frac{\partial}{\partial x^i}\big|_{(a,b)} \implies \pi_*(X_p) = f(p)^1\frac{\partial}{\partial t}\big|_a$ So we can conclude that $X_p$ is Vertical if and only if $f(p)^1 = 0$. To verify this result I tried to calculate $X^A_p$. For this I need to be able to compute $exp(tA)$ which is defined in my textbook as : $exp: T_eG \rightarrow T_pP$ which in my case is $exp: T_o\mathbb{R} \rightarrow T_{(a,b)}(\mathbb{R}\times \mathbb{R})$ and $exp(A) = \gamma^A(1)$ with $\gamma^A(1)$ the integral curve of the Left invariant vector field generated by A. So I started off by calculating the left invariant vector field : Let $A = a\frac{\partial}{\partial t}\big|_0$ be a vector in the Lie algebra. Define $L_g$ to be the left action : $L_g(a) = a + g$. I found out that $L_{g*}(A) = a\frac{\partial}{\partial t}\big|_g$. Now to calculate the integral curve we should have : $\gamma'(t) = a$ which leads me to having $\gamma(t) = at$ so that $\gamma(1) = exp(A) = a$ So we proceed with $X^A_{(b,c)}f = \frac{\partial}{\partial t}\big|_0 f((b,c).exp(tA)) = \frac{\partial}{\partial t}\big|_0 f((b,c).ta) = \frac{\partial}{\partial t}\big|_0 f((b,cta) = ca\partial_2\big|_{(b,c)}f $ which is indeed equivalent to $f(p)^1 = 0$ since only the second component is non-zero. So since the horizontal subspace is : \begin{align} T_{(a,b)}\mathbb{R}\times \mathbb{R}_* = Hor \oplus Ver\\ R_{g*}Hor_{(a,b)} = Hor_{(a,bg)}  \end{align} I set $X_{(a,b)} = f(a,b)^i\frac{\partial}{\partial x^i}\big|_{(a,b)} \in Hor \implies R_{g*}(X_{(a,b)}) = f(a,b)^1\frac{\partial}{\partial x^1}\big|_{(a,bg)} + gf(a,b)^2\frac{\partial}{\partial x^2}\big|_{(a,bg)}$ So we have the following constraints : $f(a,bg)^1 = f(a,b)^1 \implies f(a,b)^1 = f(a,1)^1$ $f(a,bg)^2 = gf(a,b)^2 \implies f(a,g)^2 = gf(a,1)^2$ From here I do not know what does it mean to : 1) Make a specific choice for Hor , for me Hor is completely determined bu the previous constraints. 2) How to project a tangent vector to Ver and Hor ? and How does that depend on the specific choice of Hor ? ( I need this to compute an explicit equation for the connection form $\omega_p = i^{-1}\circ Ver$. Thanks. EDIT : What is p in the third paragraph ? p is actually a point in the frame bundle $F\mathbb{R}$, so concretely $p\in \mathbb{R}\times \mathbb{R}_*$. p was a bad choice of notation. What is $exp(tA)$ This is a lie group element generated by the lie algebra element A. This is the Lie algebra of the Lie group $GL(1,\mathbb{R})$. We consider the left invariant vector field generated by A, then we find the integral curve $\gamma$ where the tangent vector of the curve at the identity is A, and then $exp(tA) = \gamma(t)$ What is $f(a,b)^i$ Yes this f is different from the f in the previous paragraph. It is the coordinates of the vector in the basis $\frac{\partial}{\partial x^i}\big|_{(a,b)}$. $(a,b)$ is point in the Frame bundle. And yes $p$ is a point in the frame bundle as well, I realize the notation is messy... But they are all point in the Frame bundle. $f(p)^1$ is the first coordinate.",,"['differential-geometry', 'connections']"
45,Generalized Jacobi Equation for Minimal Surface Deviation,Generalized Jacobi Equation for Minimal Surface Deviation,,"For background, recall that the Jacobi equation (also known as the equation of geodesic deviation) determines the evolution of the Jacobi field, interpreted as a deviation vector between two ""infinitesimally nearby"" geodesics.  Specifically, let $u^a$ be the tangent vector to a geodesic and let $\eta^a$ be a Jacobi field along it.  Then the Jacobi equation says that $$ u^a\nabla_a (u^b \nabla_b \eta^c) + R_{abd}^{\phantom{abd}c} u^a u^d \eta^b = 0, $$ where $R_{abcd}$ is the Riemann tensor of the ambient space. My question is the following: since a geodesic is just a special case of a minimal surface, is there some analogous equation for the deviation vector field between two ""infinitesimally nearby"" minimal (or more generally, extremal) surfaces?  That is, let $\Sigma$ be a minimal surface (of any dimension and codimension) and let $\eta^a$ be a deviation vector field on $\Sigma$ to some infinitesimally nearby minimal surface (more rigorously: let $\Sigma_t$ be a one-parameter family of minimal surfaces with $\Sigma = \Sigma_0$; then define $\eta^a = (\partial_t)^a$).  Is there an equation of the form $$ D^2 \eta^a + R_{bcd}^{\phantom{bcd}a} h^{bd} \eta^c = \mathrm{stuff}, $$ where $D^2$ is the Laplacian on $\Sigma$, $h^{ab}$ is the (inverse) induced metric on $\Sigma$, and the ""stuff"" terms are linear in $\eta^a$ and can contain things like the curvatures (intrinsic and extrinsic) of $\Sigma$? I've only been able to find partial answers to this question.  I think the equation I want may be related to the so-called Jacobi or stability operator of a minimal surface, related to the formula for the second variation of the area (as mentioned here ), but as far as I can tell that Jacobi operator is defined to act on functions (not vectors, as I want), and most references I see refer to embedded surfaces in Riemannian 3-manifolds (i.e. they don't seem to refer to completely general dimensions).  Moreover, the sources I've seen derive integral equations for the second derivative of the area under some perturbation, whereas I want a differential equation for the Jacobi field. I have also found this reference (specifically section 5.1) which does seem to do things in general dimensions, but runs into the same problem that it only obtains an integrated expression. (As you may be able to tell, I was trained in general relativity so I'm used to a different sort of notation than is usual in the math literature; it may be that I found what I wanted but couldn't translate it into familiar language!)","For background, recall that the Jacobi equation (also known as the equation of geodesic deviation) determines the evolution of the Jacobi field, interpreted as a deviation vector between two ""infinitesimally nearby"" geodesics.  Specifically, let $u^a$ be the tangent vector to a geodesic and let $\eta^a$ be a Jacobi field along it.  Then the Jacobi equation says that $$ u^a\nabla_a (u^b \nabla_b \eta^c) + R_{abd}^{\phantom{abd}c} u^a u^d \eta^b = 0, $$ where $R_{abcd}$ is the Riemann tensor of the ambient space. My question is the following: since a geodesic is just a special case of a minimal surface, is there some analogous equation for the deviation vector field between two ""infinitesimally nearby"" minimal (or more generally, extremal) surfaces?  That is, let $\Sigma$ be a minimal surface (of any dimension and codimension) and let $\eta^a$ be a deviation vector field on $\Sigma$ to some infinitesimally nearby minimal surface (more rigorously: let $\Sigma_t$ be a one-parameter family of minimal surfaces with $\Sigma = \Sigma_0$; then define $\eta^a = (\partial_t)^a$).  Is there an equation of the form $$ D^2 \eta^a + R_{bcd}^{\phantom{bcd}a} h^{bd} \eta^c = \mathrm{stuff}, $$ where $D^2$ is the Laplacian on $\Sigma$, $h^{ab}$ is the (inverse) induced metric on $\Sigma$, and the ""stuff"" terms are linear in $\eta^a$ and can contain things like the curvatures (intrinsic and extrinsic) of $\Sigma$? I've only been able to find partial answers to this question.  I think the equation I want may be related to the so-called Jacobi or stability operator of a minimal surface, related to the formula for the second variation of the area (as mentioned here ), but as far as I can tell that Jacobi operator is defined to act on functions (not vectors, as I want), and most references I see refer to embedded surfaces in Riemannian 3-manifolds (i.e. they don't seem to refer to completely general dimensions).  Moreover, the sources I've seen derive integral equations for the second derivative of the area under some perturbation, whereas I want a differential equation for the Jacobi field. I have also found this reference (specifically section 5.1) which does seem to do things in general dimensions, but runs into the same problem that it only obtains an integrated expression. (As you may be able to tell, I was trained in general relativity so I'm used to a different sort of notation than is usual in the math literature; it may be that I found what I wanted but couldn't translate it into familiar language!)",,"['differential-geometry', 'minimal-surfaces']"
46,How to pullback a gradient,How to pullback a gradient,,"In Guillemin and Pollack's ""Differential Topology"" on p. 134, there is a definition of the pullback of a vector field $v:X\rightarrow \mathbb{R}^k$, given as $\phi^*v(u):=d\phi^{-1}_u v(\phi(u))$ where $\phi:U\subset\mathbb{R}^k\rightarrow X$ is a diffeomorphic parameterisation of a subset of the $k$-dimensional manifold $X$ and $v(x)\in T_x(X)$. Later on p. 140, one is asked to derive that    \begin{equation} \phi^*\text{grad}(f)=\sum_{i,j=1}^k \frac{\partial(f\circ\phi)}{\partial x_i}g^{ij}e_j,\qquad g_{ij}(u):=\langle d\phi_u(e_i),d\phi_u(e_j)\rangle, \end{equation}   where $\langle \cdot,\cdot\rangle$ denotes the scalar product and $\text{grad}(f)$ is defined by the relation $df_x(w)=\langle\text{grad}(f)(x),w\rangle$, i.e. $df_x=\langle \text{grad}(f)(x),\cdot\rangle$.    ($\{e_1,\cdots,e_k\}$ denotes the standard basis of Euclidean space.) I hope to receive some support in doing that. What I thought about:     \begin{equation*}   \begin{split}     &\langle\phi^*\text{grad}(f)(u),e_j\rangle     =\langle d\phi^{-1}_{u} (\text{grad}(f)(\phi(u))),e_j\rangle   \end{split} \end{equation*} and     \begin{equation*}   \begin{split}     &\sum_{i,j=1}^k \frac{\partial(f\circ\phi)(u)}{\partial x_i}g_{ij}(u)e_j     =\sum_{i,j=1}^k d(f\circ\phi)_u(e_i)g_{ij}(u)e_j     =\sum_{i,j=1}^k df_{\phi(u)}d\phi_u(e_i)\langle d\phi_u(e_i),d\phi_u(e_j)\rangle e_j   \end{split} \end{equation*} but I just don't know how to get these expressions together. Help would be appreciated.","In Guillemin and Pollack's ""Differential Topology"" on p. 134, there is a definition of the pullback of a vector field $v:X\rightarrow \mathbb{R}^k$, given as $\phi^*v(u):=d\phi^{-1}_u v(\phi(u))$ where $\phi:U\subset\mathbb{R}^k\rightarrow X$ is a diffeomorphic parameterisation of a subset of the $k$-dimensional manifold $X$ and $v(x)\in T_x(X)$. Later on p. 140, one is asked to derive that    \begin{equation} \phi^*\text{grad}(f)=\sum_{i,j=1}^k \frac{\partial(f\circ\phi)}{\partial x_i}g^{ij}e_j,\qquad g_{ij}(u):=\langle d\phi_u(e_i),d\phi_u(e_j)\rangle, \end{equation}   where $\langle \cdot,\cdot\rangle$ denotes the scalar product and $\text{grad}(f)$ is defined by the relation $df_x(w)=\langle\text{grad}(f)(x),w\rangle$, i.e. $df_x=\langle \text{grad}(f)(x),\cdot\rangle$.    ($\{e_1,\cdots,e_k\}$ denotes the standard basis of Euclidean space.) I hope to receive some support in doing that. What I thought about:     \begin{equation*}   \begin{split}     &\langle\phi^*\text{grad}(f)(u),e_j\rangle     =\langle d\phi^{-1}_{u} (\text{grad}(f)(\phi(u))),e_j\rangle   \end{split} \end{equation*} and     \begin{equation*}   \begin{split}     &\sum_{i,j=1}^k \frac{\partial(f\circ\phi)(u)}{\partial x_i}g_{ij}(u)e_j     =\sum_{i,j=1}^k d(f\circ\phi)_u(e_i)g_{ij}(u)e_j     =\sum_{i,j=1}^k df_{\phi(u)}d\phi_u(e_i)\langle d\phi_u(e_i),d\phi_u(e_j)\rangle e_j   \end{split} \end{equation*} but I just don't know how to get these expressions together. Help would be appreciated.",,"['differential-geometry', 'differential-topology']"
47,Is every compact subset contained in a regular subset?,Is every compact subset contained in a regular subset?,,"Let $A$ be an open set in $\mathbb{R}^n$, $C \subset A$ a compact set. Does there always exist an open set $B \subset A$ such that $C \subset B$ and $\partial B \subset A$ is a $C^1$ regular surface? As possible partial results, first notice that by compactness there is a finite collection of balls contained in $A$ whose union contains $C$ (the border of course is not regular in the intersections). One can also try to regularize the characteristic function $\mathbb{1}_B$ of an open set $B$ that satisfies the inclusions, and consider a level set of the regularized function. However, it seems non trivial to show that one can choose the regularization and the level set in such a way that the gradient never vanish in the level set.","Let $A$ be an open set in $\mathbb{R}^n$, $C \subset A$ a compact set. Does there always exist an open set $B \subset A$ such that $C \subset B$ and $\partial B \subset A$ is a $C^1$ regular surface? As possible partial results, first notice that by compactness there is a finite collection of balls contained in $A$ whose union contains $C$ (the border of course is not regular in the intersections). One can also try to regularize the characteristic function $\mathbb{1}_B$ of an open set $B$ that satisfies the inclusions, and consider a level set of the regularized function. However, it seems non trivial to show that one can choose the regularization and the level set in such a way that the gradient never vanish in the level set.",,"['differential-geometry', 'geometric-topology']"
48,Gluing integral curves of two smooth vector fields,Gluing integral curves of two smooth vector fields,,"Let $X$ and $Y$ be two smooth vector fields defined in a smooth $n$-dimensional manifold $M$, with $X$ and $Y$ never vanishing simultaneously. Say $\gamma:[0,\varepsilon_1]\to M$ is an integral curve of $X$ and $\rho:[0,\varepsilon_2]\to M$ is an integral curve of $Y$, with $\gamma(\varepsilon_1)=\rho(0)$. Can I construct two smooth functions $\alpha,\beta \in C^{\infty}(M)$ such that the vector field $\alpha X+\beta Y$ has an integral curve that joins $\gamma(0)$ and $\rho(\varepsilon_2)$? The problem, of course, is with the point of intersection $\gamma(\varepsilon_1)=\rho(0)$. I tried putting a coordinate patch around that point and using the tubular flow theorem to glue the two curves, but couldn't make it work. Also, is it possible to do it without both functions ($\alpha$ and $\beta$) vanishing simultaneously? I appreciate any suggestions!","Let $X$ and $Y$ be two smooth vector fields defined in a smooth $n$-dimensional manifold $M$, with $X$ and $Y$ never vanishing simultaneously. Say $\gamma:[0,\varepsilon_1]\to M$ is an integral curve of $X$ and $\rho:[0,\varepsilon_2]\to M$ is an integral curve of $Y$, with $\gamma(\varepsilon_1)=\rho(0)$. Can I construct two smooth functions $\alpha,\beta \in C^{\infty}(M)$ such that the vector field $\alpha X+\beta Y$ has an integral curve that joins $\gamma(0)$ and $\rho(\varepsilon_2)$? The problem, of course, is with the point of intersection $\gamma(\varepsilon_1)=\rho(0)$. I tried putting a coordinate patch around that point and using the tubular flow theorem to glue the two curves, but couldn't make it work. Also, is it possible to do it without both functions ($\alpha$ and $\beta$) vanishing simultaneously? I appreciate any suggestions!",,"['differential-geometry', 'differential-topology', 'smooth-manifolds']"
49,Non conjugate points on a Riemannian manifold with two connecting minimizing geodesics,Non conjugate points on a Riemannian manifold with two connecting minimizing geodesics,,"We know that for a point $q$ in the cut locus of a point $p$ in a complete Riemannian manifold there are two possibilities: the point $q$ is conjugate to $p$ or they are connected by (at least) two minimizing geodesics. I have been told that there is an example of two conjugate points with a unique minimizing geodesic, and, conversely, of two non conjugate points connected by two minimizing geodesics. Can someone provide me some hints about the latter? I suspect that something on the torus can help me, but I can't say anything precise.","We know that for a point $q$ in the cut locus of a point $p$ in a complete Riemannian manifold there are two possibilities: the point $q$ is conjugate to $p$ or they are connected by (at least) two minimizing geodesics. I have been told that there is an example of two conjugate points with a unique minimizing geodesic, and, conversely, of two non conjugate points connected by two minimizing geodesics. Can someone provide me some hints about the latter? I suspect that something on the torus can help me, but I can't say anything precise.",,"['differential-geometry', 'riemannian-geometry']"
50,Why do faithful group actions yield faithful isotropy representations?,Why do faithful group actions yield faithful isotropy representations?,,"Let $M$ be a homogeneous space for a Lie group $G$. Then given any point $p \in M$, we have $M \cong G/H$ where $H$ is the isotropy group of $p$ ($H:= \{h \in G: hp = p\}$). It follows that there is a group homomorphism $\rho:H\to GL(T_pM)$ given by $\rho(h):= (h_*)_p$. I came across the following paraphrased statement without proof in ""Metric structures in differential geometry"" by Walschap: ""It is not difficult to show that if $M$ is connected and $G$ acts faithfully on $M$, then $\rho$ is injective and thus defines a faithful representation of $H$."" Question: Why is this true? I'm been stuck proving this. What I've tried: I know that if $M$ were a connected Riemannian homogeneous space ($G$ acts by isometries) with $G$ acting faithfully, then the isotropy representation is always faithful. This is because if $\exists p \in M$ and $h \in G$ with $hp = p$ and $(h_*)_p = id_{T_pM}$, then $(q \mapsto hq) = id_M$, and since the action is faithful then $h = e$. The proof is an open-closed argument using the fact that isometries map geodesics to geodesics. I'm not sure if it is possible to adapt this argument. I was hoping I could replace ""geodesics"" by ""integral curves of the infinitesimal generators of the group action"", but I haven't managed to get anywhere. Any hints/solutions would be greatly appreciated.","Let $M$ be a homogeneous space for a Lie group $G$. Then given any point $p \in M$, we have $M \cong G/H$ where $H$ is the isotropy group of $p$ ($H:= \{h \in G: hp = p\}$). It follows that there is a group homomorphism $\rho:H\to GL(T_pM)$ given by $\rho(h):= (h_*)_p$. I came across the following paraphrased statement without proof in ""Metric structures in differential geometry"" by Walschap: ""It is not difficult to show that if $M$ is connected and $G$ acts faithfully on $M$, then $\rho$ is injective and thus defines a faithful representation of $H$."" Question: Why is this true? I'm been stuck proving this. What I've tried: I know that if $M$ were a connected Riemannian homogeneous space ($G$ acts by isometries) with $G$ acting faithfully, then the isotropy representation is always faithful. This is because if $\exists p \in M$ and $h \in G$ with $hp = p$ and $(h_*)_p = id_{T_pM}$, then $(q \mapsto hq) = id_M$, and since the action is faithful then $h = e$. The proof is an open-closed argument using the fact that isometries map geodesics to geodesics. I'm not sure if it is possible to adapt this argument. I was hoping I could replace ""geodesics"" by ""integral curves of the infinitesimal generators of the group action"", but I haven't managed to get anywhere. Any hints/solutions would be greatly appreciated.",,"['differential-geometry', 'lie-groups', 'principal-bundles', 'homogeneous-spaces']"
51,Basic question regarding complexification of a vector bundle,Basic question regarding complexification of a vector bundle,,"Let $E\rightarrow M$ be a real vector bundle over a real manifold $M$. By complexification of this bundle we mean the complex vector bundle $E_{\mathbb{C}}$ whose fibers are given by complexifying the corresponding fibers in $E$, i.e. $(E_\mathbb {C})_x = E_x\otimes _{\mathbb {R}}\mathbb{C} \space\space \forall x\in M$. My question: Is the complexification same as the tensor product bundle of $E$ with the trivial bundle $M\times \mathbb{C}$? Intuitively, I think this is true since the fibers seem to be isomorphic, but not sure how to prove they are isomorphic as bundles over $M$. Any help would be appreciated.","Let $E\rightarrow M$ be a real vector bundle over a real manifold $M$. By complexification of this bundle we mean the complex vector bundle $E_{\mathbb{C}}$ whose fibers are given by complexifying the corresponding fibers in $E$, i.e. $(E_\mathbb {C})_x = E_x\otimes _{\mathbb {R}}\mathbb{C} \space\space \forall x\in M$. My question: Is the complexification same as the tensor product bundle of $E$ with the trivial bundle $M\times \mathbb{C}$? Intuitively, I think this is true since the fibers seem to be isomorphic, but not sure how to prove they are isomorphic as bundles over $M$. Any help would be appreciated.",,"['differential-geometry', 'complex-geometry', 'vector-bundles']"
52,Almost complex structure on $S^6$,Almost complex structure on,S^6,It is known that the sphere $ S^6$ admits an almost complex structure by identifying $S^6 $ with the space of unit purely imaginary Cayley numbers. I would like to show that this almost complex structure is not integrable using the Nijenhuis tensor. Can someone explain to me how vector fields look like in $S^6$ and how can we apply them in the Nijenhuis tensor? I found something in Ballmann's book (Kahler manifolds) but I didn't understand it.,It is known that the sphere $ S^6$ admits an almost complex structure by identifying $S^6 $ with the space of unit purely imaginary Cayley numbers. I would like to show that this almost complex structure is not integrable using the Nijenhuis tensor. Can someone explain to me how vector fields look like in $S^6$ and how can we apply them in the Nijenhuis tensor? I found something in Ballmann's book (Kahler manifolds) but I didn't understand it.,,"['differential-geometry', 'smooth-manifolds', 'almost-complex']"
53,Different notions of upper / lower indices,Different notions of upper / lower indices,,"In differential geometry and tensor analysis, lower and upper indices appear naturally through covariant and contravariant transformations. One uses the metric tensor and its inverse to lower and raise indices: $V_\mu=g_{\mu\nu}V^\nu$, and $R^{\mu\nu}=g^{\mu\lambda}R_\lambda^\nu$. In Anthony Zee's Group Theory in a Nutshell for Physicists on page 232, when talking about representations of $SU(N)$, Zee defines the lower index as simply a notation for the complex conjugate representation: $\psi_i={(\psi^i)}^*$ He calls these indices covariant and contravariant too, because if $\psi^i$ transforms like $\psi^i\mapsto {U^i}_j\psi^j$, then $\psi_i\mapsto{\psi_i}^{'} = \psi_j {(U^\dagger)^j}_i$. Then he says that these indices can be lowered or raised with the total antisymmetric symbol $\varepsilon^{ij\dots k}$ (the Levi-Civita symbol). For a tensor $\phi_k^{ij}$ in $SU(4)$ with two upper and two lower indices, the tensor $\phi_{kpq}:=\varepsilon_{ijpq}\phi^{ij}_k$ will have three lower indices (page 235). My question is: Applying the totally antisymmetric symbol $\varepsilon$ to a tensor representation looks like the Hodge star operator to me. Is it the same, or is there a difference? Zee does not write about the Hodge star operator, but it seems he avoids certain names to avoid confusion (which is the cause of much confusion for me - why not just say that it's known as the Hodge star?). Is there a connection between the index raising/lowering in differential geometry (using the metric) and the one of Zee (using $\varepsilon$)? The definition $\psi_i={(\psi^i)}^*$ is useful for complex representations, but for real (or pseudoreal) representations, it does not make much sense. However, the Hodge star operation is defined for all representations, complex and noncomplex. If Zee really talks about the Hodge star operation, why does he define it for complex reps only?","In differential geometry and tensor analysis, lower and upper indices appear naturally through covariant and contravariant transformations. One uses the metric tensor and its inverse to lower and raise indices: $V_\mu=g_{\mu\nu}V^\nu$, and $R^{\mu\nu}=g^{\mu\lambda}R_\lambda^\nu$. In Anthony Zee's Group Theory in a Nutshell for Physicists on page 232, when talking about representations of $SU(N)$, Zee defines the lower index as simply a notation for the complex conjugate representation: $\psi_i={(\psi^i)}^*$ He calls these indices covariant and contravariant too, because if $\psi^i$ transforms like $\psi^i\mapsto {U^i}_j\psi^j$, then $\psi_i\mapsto{\psi_i}^{'} = \psi_j {(U^\dagger)^j}_i$. Then he says that these indices can be lowered or raised with the total antisymmetric symbol $\varepsilon^{ij\dots k}$ (the Levi-Civita symbol). For a tensor $\phi_k^{ij}$ in $SU(4)$ with two upper and two lower indices, the tensor $\phi_{kpq}:=\varepsilon_{ijpq}\phi^{ij}_k$ will have three lower indices (page 235). My question is: Applying the totally antisymmetric symbol $\varepsilon$ to a tensor representation looks like the Hodge star operator to me. Is it the same, or is there a difference? Zee does not write about the Hodge star operator, but it seems he avoids certain names to avoid confusion (which is the cause of much confusion for me - why not just say that it's known as the Hodge star?). Is there a connection between the index raising/lowering in differential geometry (using the metric) and the one of Zee (using $\varepsilon$)? The definition $\psi_i={(\psi^i)}^*$ is useful for complex representations, but for real (or pseudoreal) representations, it does not make much sense. However, the Hodge star operation is defined for all representations, complex and noncomplex. If Zee really talks about the Hodge star operation, why does he define it for complex reps only?",,"['differential-geometry', 'representation-theory', 'lie-groups']"
54,What textbook/reference should I read in order to answer these questions?,What textbook/reference should I read in order to answer these questions?,,"Might be a strange question, but what textbook/reference should I read in order to be able to solve problems like the followings? I only took one class in classical differential geometry, and we covered chapter one through chapter five from this notes . But still I do not have sufficient knowledge to solve these problems. I have taken standard (?) undergraduate level classes in analysis (Apostol, but no measure theory), topology (Greene) and algebra (Hungerford, the introduction one). Example 1 : Let $S^2$ be the unit sphere in $\mathbb{R}^3$. Define map $f: S^2 \to \mathbb{R}^3$ by   $$f (x,y,z)\longrightarrow (yz-x,zx-y,xy-z)$$   Determine all the singular points of $f$. A point $p$ is singular if if the rank of the differential at $p$ is less than 2. Example 2 : Let $n \ge 1$ be an integer and $M \subset \mathbb{R}^{n+2}$ a smooth $n$-dimensional submanifold, which is a closed subset of $\mathbb{R}^{n+2}$. Prove that for any $x_0 \in M$, there exists a line $L$ in $\mathbb{R}^{n+2}$ satisfying the condition:   $$L\cap M = \{x_0\}$$ Example 3 : Let $V$ be an $n$-dimensional real vector space with $n \ge 2$. Prove that every element $v \in \wedge^{n−1}V$ can be written as   $$v = v_1 \wedge ... \wedge v_{n−1}$$   with some elements $v_1, ..., v_{n−1} \in V$ . Here $\wedge^{n−1}V$ denotes the $(n − 1)$-st exterior product of $V$ .","Might be a strange question, but what textbook/reference should I read in order to be able to solve problems like the followings? I only took one class in classical differential geometry, and we covered chapter one through chapter five from this notes . But still I do not have sufficient knowledge to solve these problems. I have taken standard (?) undergraduate level classes in analysis (Apostol, but no measure theory), topology (Greene) and algebra (Hungerford, the introduction one). Example 1 : Let $S^2$ be the unit sphere in $\mathbb{R}^3$. Define map $f: S^2 \to \mathbb{R}^3$ by   $$f (x,y,z)\longrightarrow (yz-x,zx-y,xy-z)$$   Determine all the singular points of $f$. A point $p$ is singular if if the rank of the differential at $p$ is less than 2. Example 2 : Let $n \ge 1$ be an integer and $M \subset \mathbb{R}^{n+2}$ a smooth $n$-dimensional submanifold, which is a closed subset of $\mathbb{R}^{n+2}$. Prove that for any $x_0 \in M$, there exists a line $L$ in $\mathbb{R}^{n+2}$ satisfying the condition:   $$L\cap M = \{x_0\}$$ Example 3 : Let $V$ be an $n$-dimensional real vector space with $n \ge 2$. Prove that every element $v \in \wedge^{n−1}V$ can be written as   $$v = v_1 \wedge ... \wedge v_{n−1}$$   with some elements $v_1, ..., v_{n−1} \in V$ . Here $\wedge^{n−1}V$ denotes the $(n − 1)$-st exterior product of $V$ .",,"['differential-geometry', 'reference-request', 'exterior-algebra']"
55,Why is the preimage orientation given by a transversal map smooth?,Why is the preimage orientation given by a transversal map smooth?,,"On page 100 of Differential Topology, Guillemin & Pollack define, given a smooth map $f: X \rightarrow Y$ between an orientedmanifold with boundary and an oriented boundaryless manifold and a submanifold $Z$ of $Y$ (also boundaryless and oriented) such that $f \pitchfork Z$ and $\partial f \pitchfork Z$, the preimage orientation for the manifold $S=f^{-1} (Z)$. What he does is first orient $df_{s}(N_s(S,X))$ (with $N_s(S,X)$ being the orthogonal complement in $T_s(X)$ of $T_s(S)$) so that $df_s(N_s(S,X)) \oplus T_{f(s)}(Z)=T_{f(s)}(Y)$, and then orient $N_s(S,X)$ and $S$ so that $df_s|_{N_s(S,X)}$ is an orientation preserving isomorphism and $N_s(S,X)  \oplus T_s(S) = T_s(X)$ My question is how can I show that this orientation is smooth (in the sense that around each $s \in S$ there is a smooth chart of S that preserves the orientation). I managed to do this in the case that $s \in \text{Int}(S)$ but my argument doesn't seem to translate at all to the case $s \in \partial S$.","On page 100 of Differential Topology, Guillemin & Pollack define, given a smooth map $f: X \rightarrow Y$ between an orientedmanifold with boundary and an oriented boundaryless manifold and a submanifold $Z$ of $Y$ (also boundaryless and oriented) such that $f \pitchfork Z$ and $\partial f \pitchfork Z$, the preimage orientation for the manifold $S=f^{-1} (Z)$. What he does is first orient $df_{s}(N_s(S,X))$ (with $N_s(S,X)$ being the orthogonal complement in $T_s(X)$ of $T_s(S)$) so that $df_s(N_s(S,X)) \oplus T_{f(s)}(Z)=T_{f(s)}(Y)$, and then orient $N_s(S,X)$ and $S$ so that $df_s|_{N_s(S,X)}$ is an orientation preserving isomorphism and $N_s(S,X)  \oplus T_s(S) = T_s(X)$ My question is how can I show that this orientation is smooth (in the sense that around each $s \in S$ there is a smooth chart of S that preserves the orientation). I managed to do this in the case that $s \in \text{Int}(S)$ but my argument doesn't seem to translate at all to the case $s \in \partial S$.",,"['differential-geometry', 'differential-topology', 'smooth-manifolds', 'orientation']"
56,On a particular solution of the Ricci flow,On a particular solution of the Ricci flow,,"Doing a little bit of calculations I found that the metric: $$g(t)=\frac{dx^2+dy^2}{e^{-4t}-x^2-y^2}$$ satisfies $\frac{dg(t)}{dt}=-2Ric(t)$ Where $$\frac{dg(t)}{dt}=\frac{4e^{-4t}(dx^2+dy^2)}{(e^{-4t}-x^2-y^2)^2}\ {\rm and} \ Ric(t)=\frac{-2e^{-4t}( dx^2+dy^2)}{(e^{-4t}-x^2-y^2)^2}$$ this should be a solution to the Ricci flow on $R^2$. Furthermore, with some other calculation, I found that this metric $g(t)$ is the only solution within the family: $g_{\lambda}(t)=\frac{dx^2+dy^2}{e^{-4\lambda t}-x^{2 \lambda}-y^{2 \lambda}}$, in fact, the only solution to the Ricci flow is only for $\lambda=1$. Said this, my analysis has been to see the behavior in time for $g(t)$ and $Ric(t)$, then $t$ tends to $\infty$ and $- \infty$, but I want that  the metric $g(t)$  remain positive. a) Then for $t \rightarrow \infty$, to ensure that $g(t)$ is positive, I fixed $x=0$ and $y=0$ and I get $g(t)$ tends to $\infty$ and $Ric(t)$ tends to $-2$ b) While for $t \rightarrow - \infty$  I get $g(t)$ tends to $0$ and $Ric(t)$ tends again to $-2$. For $t=0$, I get $g_0= \frac{dx^2+dy^2}{1-x^2-y^2}$ and with a simple calculations, I found that the 1-parameter family of diffeomorfism is $\phi_t=(e^{2t}x, e^{2t}y)$. Considering $r^2=(x^2+y^2)$, the Scalar curvature, for $t=0$, is $R=\frac{-4}{1-r^2}$. Now If I make an analysis of singularities (always for $(1-r^2)>0$), I found that if $r$ tends to $1-$, $g_0$ tends to $\infty$ and $R$ tends $- \infty$ My questions are: 1) (Admit that my calculations are correct) Is this a Steady Soliton? 2) Is this, for $t=0$, the Poincaré disk? 3) What else can I say? Which other analysis can I do? Thank you in advance! Alex","Doing a little bit of calculations I found that the metric: $$g(t)=\frac{dx^2+dy^2}{e^{-4t}-x^2-y^2}$$ satisfies $\frac{dg(t)}{dt}=-2Ric(t)$ Where $$\frac{dg(t)}{dt}=\frac{4e^{-4t}(dx^2+dy^2)}{(e^{-4t}-x^2-y^2)^2}\ {\rm and} \ Ric(t)=\frac{-2e^{-4t}( dx^2+dy^2)}{(e^{-4t}-x^2-y^2)^2}$$ this should be a solution to the Ricci flow on $R^2$. Furthermore, with some other calculation, I found that this metric $g(t)$ is the only solution within the family: $g_{\lambda}(t)=\frac{dx^2+dy^2}{e^{-4\lambda t}-x^{2 \lambda}-y^{2 \lambda}}$, in fact, the only solution to the Ricci flow is only for $\lambda=1$. Said this, my analysis has been to see the behavior in time for $g(t)$ and $Ric(t)$, then $t$ tends to $\infty$ and $- \infty$, but I want that  the metric $g(t)$  remain positive. a) Then for $t \rightarrow \infty$, to ensure that $g(t)$ is positive, I fixed $x=0$ and $y=0$ and I get $g(t)$ tends to $\infty$ and $Ric(t)$ tends to $-2$ b) While for $t \rightarrow - \infty$  I get $g(t)$ tends to $0$ and $Ric(t)$ tends again to $-2$. For $t=0$, I get $g_0= \frac{dx^2+dy^2}{1-x^2-y^2}$ and with a simple calculations, I found that the 1-parameter family of diffeomorfism is $\phi_t=(e^{2t}x, e^{2t}y)$. Considering $r^2=(x^2+y^2)$, the Scalar curvature, for $t=0$, is $R=\frac{-4}{1-r^2}$. Now If I make an analysis of singularities (always for $(1-r^2)>0$), I found that if $r$ tends to $1-$, $g_0$ tends to $\infty$ and $R$ tends $- \infty$ My questions are: 1) (Admit that my calculations are correct) Is this a Steady Soliton? 2) Is this, for $t=0$, the Poincaré disk? 3) What else can I say? Which other analysis can I do? Thank you in advance! Alex",,['differential-geometry']
57,Closed subset of a manifold is a submanifold if there exists a smooth retract.,Closed subset of a manifold is a submanifold if there exists a smooth retract.,,"My question is regarding a specific exercise that I'm not really sure how to approach. Suppose I have a smooth manifold $M$ and let $A$ be a closed subset. Now suppose that there exists a smooth function $f:M \to A$ such that $f|_A = id$ (smooth retract). I want to show that $A$ is a submanifold, i.e, it is Hausdorff, second countable and locally euclidean. Hausdorff and second countable are both hereditary properties, so only the latter is left. My attempt was to prove that if $(U, \varphi)$ is a chart around $x \in A \subset M$ for $M$, then $\left(f(U), \varphi|_{f(U)}\right)$ is the desired chart. However, I'm not sure if $f(U)$ is open. I probably should use that $A$ is closed and $f$ is a retract, but I couldn't connect both facts. There is no need for a solution, just a hint is enough. PS: John Lee suggested that I should ask a question instead of leaving the exercise for the community, so here it is. I rewrote my previous post here. :)","My question is regarding a specific exercise that I'm not really sure how to approach. Suppose I have a smooth manifold $M$ and let $A$ be a closed subset. Now suppose that there exists a smooth function $f:M \to A$ such that $f|_A = id$ (smooth retract). I want to show that $A$ is a submanifold, i.e, it is Hausdorff, second countable and locally euclidean. Hausdorff and second countable are both hereditary properties, so only the latter is left. My attempt was to prove that if $(U, \varphi)$ is a chart around $x \in A \subset M$ for $M$, then $\left(f(U), \varphi|_{f(U)}\right)$ is the desired chart. However, I'm not sure if $f(U)$ is open. I probably should use that $A$ is closed and $f$ is a retract, but I couldn't connect both facts. There is no need for a solution, just a hint is enough. PS: John Lee suggested that I should ask a question instead of leaving the exercise for the community, so here it is. I rewrote my previous post here. :)",,"['differential-geometry', 'manifolds', 'smooth-manifolds']"
58,are immersions of surfaces in $\mathbb R^3$ dense in all regular maps?,are immersions of surfaces in  dense in all regular maps?,\mathbb R^3,"Let $u\in C^\infty(\Omega,\mathbf R^3)$ with $\Omega$ open set in $\mathbf R^2$. Can we find $u_k\in C^\infty(\Omega,\mathbf R^3)$ with $\mathrm{rank}(Du_k(x))=2$ for all $x\in\Omega$ such that $u_k \to u$ uniformly? added. I actually have $\Omega$ bounded and $u\in C^\infty(\Omega)\cap C^0(\overline \Omega)$ with $u=0$ on $\partial \Omega$ and need to approximate uniformaly with functions $u_k$ with the same properties and full jacobian rank. Then I would like to apply Nash-Kuiper theorem to $u_k$ to obtain an isometric map approximating $u$.","Let $u\in C^\infty(\Omega,\mathbf R^3)$ with $\Omega$ open set in $\mathbf R^2$. Can we find $u_k\in C^\infty(\Omega,\mathbf R^3)$ with $\mathrm{rank}(Du_k(x))=2$ for all $x\in\Omega$ such that $u_k \to u$ uniformly? added. I actually have $\Omega$ bounded and $u\in C^\infty(\Omega)\cap C^0(\overline \Omega)$ with $u=0$ on $\partial \Omega$ and need to approximate uniformaly with functions $u_k$ with the same properties and full jacobian rank. Then I would like to apply Nash-Kuiper theorem to $u_k$ to obtain an isometric map approximating $u$.",,"['real-analysis', 'differential-geometry', 'differential-topology']"
59,Relearning differential geometry,Relearning differential geometry,,"I will shortly describe my situation and than formulate the problem. From around year I am working under supervision of my professor on master thesis in differential geometry (mainly discussion of different geometric structures on manifolds) I intend to stay in field of differential geometry during PhD. Yet I very often find myself unaware of some basic fact or have trouble to rebuild some part of theory from foundations so I have decided to relearn foundations of differential geometry. For that purpose I can spare 2-3 hours during my semester break and even longer if necessary in order to do that. I plan to workout one or two handbook covering foundations of diff. geometry (especially - here I find the biggest problems - connection theory in principal bundles) and Riemannian geometry (curvature, geodesics, normal coord., Jacobi fields etc - I know that these are basic themes yet here my gaps are quite big I presume). I have some propositions for that textbook yet I ask you for opinion or propositions if you know better one (list is partial based on: List of books I , List of books II ): Foundations of Differential Geometry I - S. Kobayashi, K. Nomizu (in my opinion great for connections yet lacks other material except for some Riemannian geometry) Introduction to Smooth Manifolds - John Lee's (It was mentioned in second list yet however it covers a lot of material seems to basic) Topics in differential geometry - P. Michor (It was not mentioned on neither of lists yest I am curious of you opinion) My second question is about post from second list, namely it was stated there that it is worthwhile to master/ be familiar (which one??) with theory of surfaces and curves. What is your opinion on it? If it is really necessary to master that themes for knowing what is going on which book will you recommend? I know there are many researchers here in our community and I would be very grateful for your responses. Formally I have taken two courses connected with differential geometry. Firs one rather connected with differential topology - definition of abstract manifold, construction of canonical bundles, differential forms, hodge decomposition and some facts about differential operators (I barely remember). Second one was about Riemannian geometry - Riemannian connection, geodesics, normal coordinates, Jacobi fields, curvature, Hopf-Rinow (without proof), harmonic maps (informations). Actually I have never had classes about classical diff. geometry of curves and surfaces. If it helps my current interest is in geometric structures (G-structures and pseudo-group structures) so feel free to take it into account.","I will shortly describe my situation and than formulate the problem. From around year I am working under supervision of my professor on master thesis in differential geometry (mainly discussion of different geometric structures on manifolds) I intend to stay in field of differential geometry during PhD. Yet I very often find myself unaware of some basic fact or have trouble to rebuild some part of theory from foundations so I have decided to relearn foundations of differential geometry. For that purpose I can spare 2-3 hours during my semester break and even longer if necessary in order to do that. I plan to workout one or two handbook covering foundations of diff. geometry (especially - here I find the biggest problems - connection theory in principal bundles) and Riemannian geometry (curvature, geodesics, normal coord., Jacobi fields etc - I know that these are basic themes yet here my gaps are quite big I presume). I have some propositions for that textbook yet I ask you for opinion or propositions if you know better one (list is partial based on: List of books I , List of books II ): Foundations of Differential Geometry I - S. Kobayashi, K. Nomizu (in my opinion great for connections yet lacks other material except for some Riemannian geometry) Introduction to Smooth Manifolds - John Lee's (It was mentioned in second list yet however it covers a lot of material seems to basic) Topics in differential geometry - P. Michor (It was not mentioned on neither of lists yest I am curious of you opinion) My second question is about post from second list, namely it was stated there that it is worthwhile to master/ be familiar (which one??) with theory of surfaces and curves. What is your opinion on it? If it is really necessary to master that themes for knowing what is going on which book will you recommend? I know there are many researchers here in our community and I would be very grateful for your responses. Formally I have taken two courses connected with differential geometry. Firs one rather connected with differential topology - definition of abstract manifold, construction of canonical bundles, differential forms, hodge decomposition and some facts about differential operators (I barely remember). Second one was about Riemannian geometry - Riemannian connection, geodesics, normal coordinates, Jacobi fields, curvature, Hopf-Rinow (without proof), harmonic maps (informations). Actually I have never had classes about classical diff. geometry of curves and surfaces. If it helps my current interest is in geometric structures (G-structures and pseudo-group structures) so feel free to take it into account.",,"['differential-geometry', 'reference-request', 'soft-question', 'riemannian-geometry']"
60,"Given a first fundamental form, showing a particular second form cannot exist","Given a first fundamental form, showing a particular second form cannot exist",,"If I have a first fundamental form $ \mathrm{d}u^2+\cos^2 u \mathrm{d}v^2$, I am trying to show that the second fundamental form cannot equal $f(u,v)\mathrm{d}v^2$ for a smooth function $f(u,v)$. I have calculated the Christoffel symbols and arrived at the following set of equations: $\sigma_{uu} = L \cdot \mathbf{N}$ $\sigma_{uv} = -\tan u \cdot \sigma_v + M \cdot \mathbf{N}$ $\sigma_{vv} = \tan u \cdot \sigma_u + N \cdot \mathbf{N}$ I suppose I was expecting to arrive at a contradiction, but I can't really see where any problem occurs with the fundamental form only having a coefficient for $N$ I know that both fundamental forms of a sphere are $\mathrm{d} u^2+ \cos^2 u \mathrm{d}v^2$ but does having such a first fundamental form necessarily imply that the surface is a sphere?","If I have a first fundamental form $ \mathrm{d}u^2+\cos^2 u \mathrm{d}v^2$, I am trying to show that the second fundamental form cannot equal $f(u,v)\mathrm{d}v^2$ for a smooth function $f(u,v)$. I have calculated the Christoffel symbols and arrived at the following set of equations: $\sigma_{uu} = L \cdot \mathbf{N}$ $\sigma_{uv} = -\tan u \cdot \sigma_v + M \cdot \mathbf{N}$ $\sigma_{vv} = \tan u \cdot \sigma_u + N \cdot \mathbf{N}$ I suppose I was expecting to arrive at a contradiction, but I can't really see where any problem occurs with the fundamental form only having a coefficient for $N$ I know that both fundamental forms of a sphere are $\mathrm{d} u^2+ \cos^2 u \mathrm{d}v^2$ but does having such a first fundamental form necessarily imply that the surface is a sphere?",,"['differential-geometry', 'surfaces', 'curvature']"
61,Calculation of extrinsic curvature,Calculation of extrinsic curvature,,"I asked this question first on physics.SE but I got no complete answer so I thought maybe someone here could help. I'm trying to understand how to derive the extrinsic curvature (in order to understand some calculation on fluid/gravity dynamics). But I hit a wall in my progress. I stuck at trying to verify the extrinsic curvature of a slowing-rotating Kerr solution ( page 94, E.Poisson: A relativistic Toolkit: The mathematics of black holes ): $$ds_+^2=g_{ab}\;dx^a dx^b=-f dt^2+f^{-1}dr^2+r^2 d\Omega^2-\frac{4Ma}{r}\;\sin^2(\theta)\;dr\;d\phi$$ where $f=1-2M/r$ and cut of $r=R$ which defines the hypersurface $\Sigma$ on which we'll work on. I derive the induced metric (with $\psi=\phi-\Omega t$ and $\Omega=\frac{2Ma}{R^3}$) : \begin{equation} h_{ab}\;dy^ady^b=-f dt^2+R^2(d\theta^2+\sin^2\theta d\psi^2) \end{equation} But from here on, I stuck. So my stucking points are: How can I derive the form of the unit normal vector $n_a$ here and in not so obvious metrics ?(The answer for this problem is $n_a=f^{-1/2}\partial_a\;r$, this means that $n_a=f^{-1/2}\delta^r_a$) ? The extrinsic curvature is defined as $$K_{AB}=n_{a;b}\frac{\partial x^a}{\partial y^A}\frac{\partial x^b}{\partial y^B} \;\;\;\;\;\;\; (1)$$ where $x^a=x^a(y^A)$. Edit : Until now I have compute the $n_a=f^{-1/2}\delta^{r}_{a}$ but if I try to compute the components of the extrinsic curvature, my answers are in complete disagreement with the answers from the book. I found for example $$K_{\theta\theta}=1/2$$ which is obviously wrong. The right answer is $$K_{\theta\theta}=f^{1/2}/R$$ Any suggestions? Thank you.","I asked this question first on physics.SE but I got no complete answer so I thought maybe someone here could help. I'm trying to understand how to derive the extrinsic curvature (in order to understand some calculation on fluid/gravity dynamics). But I hit a wall in my progress. I stuck at trying to verify the extrinsic curvature of a slowing-rotating Kerr solution ( page 94, E.Poisson: A relativistic Toolkit: The mathematics of black holes ): $$ds_+^2=g_{ab}\;dx^a dx^b=-f dt^2+f^{-1}dr^2+r^2 d\Omega^2-\frac{4Ma}{r}\;\sin^2(\theta)\;dr\;d\phi$$ where $f=1-2M/r$ and cut of $r=R$ which defines the hypersurface $\Sigma$ on which we'll work on. I derive the induced metric (with $\psi=\phi-\Omega t$ and $\Omega=\frac{2Ma}{R^3}$) : \begin{equation} h_{ab}\;dy^ady^b=-f dt^2+R^2(d\theta^2+\sin^2\theta d\psi^2) \end{equation} But from here on, I stuck. So my stucking points are: How can I derive the form of the unit normal vector $n_a$ here and in not so obvious metrics ?(The answer for this problem is $n_a=f^{-1/2}\partial_a\;r$, this means that $n_a=f^{-1/2}\delta^r_a$) ? The extrinsic curvature is defined as $$K_{AB}=n_{a;b}\frac{\partial x^a}{\partial y^A}\frac{\partial x^b}{\partial y^B} \;\;\;\;\;\;\; (1)$$ where $x^a=x^a(y^A)$. Edit : Until now I have compute the $n_a=f^{-1/2}\delta^{r}_{a}$ but if I try to compute the components of the extrinsic curvature, my answers are in complete disagreement with the answers from the book. I found for example $$K_{\theta\theta}=1/2$$ which is obviously wrong. The right answer is $$K_{\theta\theta}=f^{1/2}/R$$ Any suggestions? Thank you.",,"['differential-geometry', 'manifolds', 'riemannian-geometry', 'curvature', 'general-relativity']"
62,Poincaré duality for currents and non-closed forms,Poincaré duality for currents and non-closed forms,,"In page 8 of Quantization of Higher Abelian Gauge Theory in Generalized Differential Cohomology by Szabo, the author claims that Poincaré  duality holds for non-closed forms as long as the other form (pairing with the former one) is distributional, i.e., it's a de Rham current. Let me be more precise. Let $X$ be a manifold of dimension $n$. Given a de Rham current of compact support $j_e \in H^m_{dR, c} (X)$ that is exact in $H^m_{dR} (X)$ (I don't think this exactness part is relevant, anyway …), the author claims that there exists a homology class $[W_e] \in H_{m - n} (X, \mathbb{R})$ such that $$\int_X a \wedge j_e = \int_{W_e} a$$ for every $a \in \Omega^{n - m} (X)$. This fact is indeed need in the paper I mentioned since in page 6 he uses this property (without mentioning it previously) to deduce Dirac charge quantization condition from $\exp (-\int_X A\wedge j_e) = \exp (-\int_{W_e} A)$ for possibly non-closed $A$. I would like a proof or a reference for this fact about currents (mentioned above)","In page 8 of Quantization of Higher Abelian Gauge Theory in Generalized Differential Cohomology by Szabo, the author claims that Poincaré  duality holds for non-closed forms as long as the other form (pairing with the former one) is distributional, i.e., it's a de Rham current. Let me be more precise. Let $X$ be a manifold of dimension $n$. Given a de Rham current of compact support $j_e \in H^m_{dR, c} (X)$ that is exact in $H^m_{dR} (X)$ (I don't think this exactness part is relevant, anyway …), the author claims that there exists a homology class $[W_e] \in H_{m - n} (X, \mathbb{R})$ such that $$\int_X a \wedge j_e = \int_{W_e} a$$ for every $a \in \Omega^{n - m} (X)$. This fact is indeed need in the paper I mentioned since in page 6 he uses this property (without mentioning it previously) to deduce Dirac charge quantization condition from $\exp (-\int_X A\wedge j_e) = \exp (-\int_{W_e} A)$ for possibly non-closed $A$. I would like a proof or a reference for this fact about currents (mentioned above)",,"['differential-geometry', 'algebraic-topology', 'distribution-theory', 'gauge-theory']"
63,Projective Resolution of $C^{\infty}(V)$ by Connes,Projective Resolution of  by Connes,C^{\infty}(V),"In his article Noncommutative differential geometry (Inst. Hautes Études Sci. Publ. Math. No. 62 (1985), 257–360) A. Connes gives in Lemma 44 (p. 343f) a projective topological resolution of the module $C^{\infty}(V)$ over $C^{\infty}(V \times V)$ for a smooth compact manifold $V$. The basic construction is as follows: One considers the complex bundles $E_k$ on $V \times V$ given by the pull back of the projection $\mathrm{pr}_2\colon V \times V \to V$ onto the second coordinate of the exterior power $\bigwedge^k T_{\mathbb{C}}^* V$ of the complexified cotangent bundle of $V$.  Now, if the Euler characteristic of $V$ vanishes, one finds a section $X$ of $E_1^*$ which does not vanish outside the diagonal. Connes then states that a resolution is given by $$C^{\infty}(V) \xleftarrow{\Delta^*} C^{\infty}(V \times V) \xleftarrow{\iota_X} C^{\infty}(V^2, E_1) \xleftarrow{\iota_X} \cdots \leftarrow C^{\infty}(V^2, E_n) \leftarrow 0,$$ where $n$ is the dimension of $V$. For the proof Connes chooses smooth cut-offs $\chi$ and $\chi'$ in $C^{\infty}(V \times V)$ such that $X(a,b) = \exp_b^{-1}(a)$ for $(a,b)$ in the support of $\chi'$ and $\chi' = 1$ on the support of $\chi$ which itsself satisfies $\chi = 1$ in a neighbourhood of the diagonal $\Delta$. We do not understand a conclusion at the very end of the proof. Connes defines the section $$s(\omega) = \chi' \int_0^1 \varphi_t^*(d_b(\chi \omega)) \frac{dt}{t} + (1-\chi) \omega' \wedge \omega.$$ Then he proves that for every form $\omega_1 \in E_k$ vanishing off the support of $\chi$ and statisfying $\omega_1(a,a) = 0$ (i.e. $\omega_1$ vanishes on the diagonal) one has $$\int_0^1 \phi_t^* d(\iota_X \omega_1) + \iota_X \int_0^1 \varphi_t^* d\omega_1 \frac{dt}{t} = \omega_1.$$ Finally, he applies the above identiy to the form $\omega_1 = \chi \omega$, a smooth cut-off of an arbitray given form $\omega \in E_k$. But why does $\omega_1$ vanish on the diagonal and one can therefore apply the above identity? Can anyone clarify this step? Searching through the web, everyone seems to give more or less this proof due to Connes and therefore further literature was no help.","In his article Noncommutative differential geometry (Inst. Hautes Études Sci. Publ. Math. No. 62 (1985), 257–360) A. Connes gives in Lemma 44 (p. 343f) a projective topological resolution of the module $C^{\infty}(V)$ over $C^{\infty}(V \times V)$ for a smooth compact manifold $V$. The basic construction is as follows: One considers the complex bundles $E_k$ on $V \times V$ given by the pull back of the projection $\mathrm{pr}_2\colon V \times V \to V$ onto the second coordinate of the exterior power $\bigwedge^k T_{\mathbb{C}}^* V$ of the complexified cotangent bundle of $V$.  Now, if the Euler characteristic of $V$ vanishes, one finds a section $X$ of $E_1^*$ which does not vanish outside the diagonal. Connes then states that a resolution is given by $$C^{\infty}(V) \xleftarrow{\Delta^*} C^{\infty}(V \times V) \xleftarrow{\iota_X} C^{\infty}(V^2, E_1) \xleftarrow{\iota_X} \cdots \leftarrow C^{\infty}(V^2, E_n) \leftarrow 0,$$ where $n$ is the dimension of $V$. For the proof Connes chooses smooth cut-offs $\chi$ and $\chi'$ in $C^{\infty}(V \times V)$ such that $X(a,b) = \exp_b^{-1}(a)$ for $(a,b)$ in the support of $\chi'$ and $\chi' = 1$ on the support of $\chi$ which itsself satisfies $\chi = 1$ in a neighbourhood of the diagonal $\Delta$. We do not understand a conclusion at the very end of the proof. Connes defines the section $$s(\omega) = \chi' \int_0^1 \varphi_t^*(d_b(\chi \omega)) \frac{dt}{t} + (1-\chi) \omega' \wedge \omega.$$ Then he proves that for every form $\omega_1 \in E_k$ vanishing off the support of $\chi$ and statisfying $\omega_1(a,a) = 0$ (i.e. $\omega_1$ vanishes on the diagonal) one has $$\int_0^1 \phi_t^* d(\iota_X \omega_1) + \iota_X \int_0^1 \varphi_t^* d\omega_1 \frac{dt}{t} = \omega_1.$$ Finally, he applies the above identiy to the form $\omega_1 = \chi \omega$, a smooth cut-off of an arbitray given form $\omega \in E_k$. But why does $\omega_1$ vanish on the diagonal and one can therefore apply the above identity? Can anyone clarify this step? Searching through the web, everyone seems to give more or less this proof due to Connes and therefore further literature was no help.",,"['differential-geometry', 'commutative-algebra', 'noncommutative-geometry']"
64,Spin^c structure induced by a spin structure,Spin^c structure induced by a spin structure,,"I wondered how it works exactly to induce a $\mathrm{spin^c}$-structure if a spin structure is given. I wanted to use the following definitions as used in Friedrich`s ""Dirac operators in Riemannian Geometry"" Let $(Q,\pi_Q,M;\operatorname{SO}(n))$ be a $\operatorname{SO}(n)$-principle bundle on a manifold $M$. The maps $\lambda:\operatorname{Spin}(n)\to \operatorname{SO}(n)$ and $\lambda_\mathrm{c}:\mathrm{Spin^c}(n)\to \operatorname{SO}(n)$ below are the respective standard covering maps. The  horizontal arrows are the actions of the groups on the fibers. Definition A spin structure on $Q$ is a pair $(P,\varLambda)$ consisting of a $\operatorname{Spin}(n)$-principal bundle $(P,\pi_P,M;\operatorname{Spin}(n))$ such that $\varLambda:P\to Q$ is a $2$-fold covering bundle map for which the following diagram commutes Definition A $spin^c$ structure on $M$ is a pair $ (P^{\mathrm{c}},\varLambda_{\mathrm{c}})$ consisting of a $\mathrm{Spin^c}(n)$-principle bundle $(P^{\mathrm{c}},\pi_P,M;\mathrm{Spin^c}(n))$ over $M$ and a fiber map $\varLambda_{\mathrm{c}}:P\to Q$ such that the following diagram commutes: Now a typical assertion is that each spin structure induces a canonical $\mathrm{spin^c}$ structure. I tried to show that via connecting the commutative diagrams, and using the fact that there is a natural inclusion of the spin group in the $\mathrm{spin^c}$ group. That means I get a diagram, where the ""upper"" and ""big"" part commutes, but I do not know how to define $\varLambda_{\mathrm{c}}$:","I wondered how it works exactly to induce a $\mathrm{spin^c}$-structure if a spin structure is given. I wanted to use the following definitions as used in Friedrich`s ""Dirac operators in Riemannian Geometry"" Let $(Q,\pi_Q,M;\operatorname{SO}(n))$ be a $\operatorname{SO}(n)$-principle bundle on a manifold $M$. The maps $\lambda:\operatorname{Spin}(n)\to \operatorname{SO}(n)$ and $\lambda_\mathrm{c}:\mathrm{Spin^c}(n)\to \operatorname{SO}(n)$ below are the respective standard covering maps. The  horizontal arrows are the actions of the groups on the fibers. Definition A spin structure on $Q$ is a pair $(P,\varLambda)$ consisting of a $\operatorname{Spin}(n)$-principal bundle $(P,\pi_P,M;\operatorname{Spin}(n))$ such that $\varLambda:P\to Q$ is a $2$-fold covering bundle map for which the following diagram commutes Definition A $spin^c$ structure on $M$ is a pair $ (P^{\mathrm{c}},\varLambda_{\mathrm{c}})$ consisting of a $\mathrm{Spin^c}(n)$-principle bundle $(P^{\mathrm{c}},\pi_P,M;\mathrm{Spin^c}(n))$ over $M$ and a fiber map $\varLambda_{\mathrm{c}}:P\to Q$ such that the following diagram commutes: Now a typical assertion is that each spin structure induces a canonical $\mathrm{spin^c}$ structure. I tried to show that via connecting the commutative diagrams, and using the fact that there is a natural inclusion of the spin group in the $\mathrm{spin^c}$ group. That means I get a diagram, where the ""upper"" and ""big"" part commutes, but I do not know how to define $\varLambda_{\mathrm{c}}$:",,"['differential-geometry', 'principal-bundles', 'spin-geometry']"
65,Darboux's Theorem Alternate Proof,Darboux's Theorem Alternate Proof,,"I've been given the task of proving Darboux's theorem through non-standard means. Definitions Let $(M,\phi)$ be a symplectic manifold. $\mathcal{F}_{\text{SP}(V)}(M)$ is the bundle of frames $(\eta^1,\ldots ,\eta^{2m})$ such that $\phi=\eta^1\wedge\eta^{m+1}+\cdots +\eta^m\wedge\eta^{2m}$. $\eta$ is the column vector associated to a particular $(\eta^1,\ldots ,\eta^{2m})\in\mathcal{F}_{\text{SP}(V)}$, i.e. $\eta^i$ belongs to the $i^{\text{th}}$ row of $\eta$. $\theta$ is a $\mathfrak{sp}(V)$-valued 1-form such that $d\eta=-\theta\wedge\eta$. Problem Let $(M,\phi)$ be a symplectic manifold. Compute $d\theta+\theta\wedge\theta$. Use this to prove Darboux's theorem. I have an idea as how I might go about proving Darboux's theorem if I could compute $d\theta+\theta\wedge\theta$: I imagine (since $d\theta+\theta\wedge\theta$ is analogous to the Riemann curvature tensor) that it would be similar to showing that a Riemannian manifold is flat iff the Riemann curvature tensor is identically zero. But my progess halts at computing $d\theta+\theta\wedge\theta$. I cannot figure out anything besides breaking down $d\theta+\theta\wedge\theta$ into its component equations: If $\theta=(\theta^i_j)$ then solving $d\theta+\theta\wedge\theta$ is equivalent to solving $d\theta^i_j+\theta^i_k\wedge\theta^k_j$, but this doesn't get me anywhere. I've arrived a couple of equations using the fact that $d\phi=0$, but none of these have truly gotten me anywhere. Any help is greatly appreciated. Thanks in advance. Edit: I forgot to mention it before, but this is a homework problem so just hints please. Thanks again.","I've been given the task of proving Darboux's theorem through non-standard means. Definitions Let $(M,\phi)$ be a symplectic manifold. $\mathcal{F}_{\text{SP}(V)}(M)$ is the bundle of frames $(\eta^1,\ldots ,\eta^{2m})$ such that $\phi=\eta^1\wedge\eta^{m+1}+\cdots +\eta^m\wedge\eta^{2m}$. $\eta$ is the column vector associated to a particular $(\eta^1,\ldots ,\eta^{2m})\in\mathcal{F}_{\text{SP}(V)}$, i.e. $\eta^i$ belongs to the $i^{\text{th}}$ row of $\eta$. $\theta$ is a $\mathfrak{sp}(V)$-valued 1-form such that $d\eta=-\theta\wedge\eta$. Problem Let $(M,\phi)$ be a symplectic manifold. Compute $d\theta+\theta\wedge\theta$. Use this to prove Darboux's theorem. I have an idea as how I might go about proving Darboux's theorem if I could compute $d\theta+\theta\wedge\theta$: I imagine (since $d\theta+\theta\wedge\theta$ is analogous to the Riemann curvature tensor) that it would be similar to showing that a Riemannian manifold is flat iff the Riemann curvature tensor is identically zero. But my progess halts at computing $d\theta+\theta\wedge\theta$. I cannot figure out anything besides breaking down $d\theta+\theta\wedge\theta$ into its component equations: If $\theta=(\theta^i_j)$ then solving $d\theta+\theta\wedge\theta$ is equivalent to solving $d\theta^i_j+\theta^i_k\wedge\theta^k_j$, but this doesn't get me anywhere. I've arrived a couple of equations using the fact that $d\phi=0$, but none of these have truly gotten me anywhere. Any help is greatly appreciated. Thanks in advance. Edit: I forgot to mention it before, but this is a homework problem so just hints please. Thanks again.",,"['differential-geometry', 'symplectic-geometry']"
66,Equivalent condition for non-orientability of a manifold,Equivalent condition for non-orientability of a manifold,,"I've just came across this question , which gives us a great tool for showing that smooth manifold is non-orientable. Namely Thm. If $M$ is a smooth manifold and there are two charts $(U_a,\phi_a),(U_b,\phi_b),$ such that $U_a,U_b$ are connected, $U_a\cap U_b\neq\emptyset$ and transformation function $\phi_{ab}$ neither preserves nor reverses the orientation, then $M$ is non-orientable. Andrew D. Hwang gave an excellent answer. But still wonders me, if converse statement holds. I.e. Question. If $M$ is non-orientable, can we find two such charts $(U_a,\phi_a),(U_b,\phi_b)?$ Again Andrew D. Hwang suggested that it holds and gave me the following hint @Fallen: Yes, the converse is true. Intuitively, if M is non-orientable, there exists a loop (closed curve) around which ""the orientation reverses"". Thicken the loop into a tube and cover it with two ""solid cylinders"" Ua and Ub. There are details to check, and this sketch may not be the easiest strategy to make rigorous. (E.g., if no such charts exist, start with an arbitrary atlas and reverse chart orientations as needed to get an atlas of compatible charts. Again, though, there are details to check....). I only managed to do it assuming that $M$ is connected and second countable. Proof. Assume that for any two charts $(U_a,\phi_a),(U_b,\phi_b),$ such that $U_a,U_b$ are connected and $U_a\cap U_b\neq\emptyset$ transformation function $\phi_{ab}$ preserves or reverses orientation. We want to show that $M$ is orientable. Let $\{(V_i,\psi_i)\}_{i}$ be a countable atlas such that $V_i$ are connected. From that we want to construct a new atlas $\{(V_i,\overline{\psi}_i)\}_{i}$ which is oriented. Construction will be inductive. $\overline{\psi}_1:=\psi_1. \overline{\psi}_i:=\psi_i$ or $\overline{\psi}_i:=\psi^*_i$ (here if $\psi_i=(x^1,\dots,x^n),$ then $\psi^*_i=(x^1,\dots,-x^n)$) to satisfy condition $$\forall_{j<i}\overline{\psi}_{ji}\hspace{5pt}\text{preserves orientation,}$$ where $\overline{\psi}_{ji}$ is transformation function from $\overline{\psi}_j$ to $\overline{\psi}_i.$ But the obvious question is, if such procedure exists. Suppose it fails at some $i.$ Hence there are $j,k<i,$ such that transformation from $\overline{\psi_j}$ to $\psi_i$ preserves orientation and transformation from $\overline{\psi_k}$ to $\psi_i$ reverses. Consider a curve $\gamma$ starting in $V_i\cap V_j$ and ending in $V_i\cap V_k$ and its neighberhoud $U_a$ such that it sits in $V_p$ for $p\leqslant i$ and it meets $V_i$ only in $V_i\cap V_j$ and $V_i\cap V_k.$ Let additionaly $U_a$ be such that $(U_a,\phi_a)$ is a chart for $\phi_a$ ""glued"" from $\overline{\psi_p}$ for $p<i.$ Set $(U_b,\phi_b):=(V_i,\psi_i).$ As a result $\phi_{ab}$ preserves and reverses an orientation. Hence contradiction with the assumption from the beggining. Hence procedure cannot fail at $i.$ So $M$ is orientable. These reasoning can be captured in a picture I ask about some simplification of the proof. Now it is too constructive and descriptive for me, especially construction of $\phi_a.$ Do you have any ideas how to prove it simpler?","I've just came across this question , which gives us a great tool for showing that smooth manifold is non-orientable. Namely Thm. If $M$ is a smooth manifold and there are two charts $(U_a,\phi_a),(U_b,\phi_b),$ such that $U_a,U_b$ are connected, $U_a\cap U_b\neq\emptyset$ and transformation function $\phi_{ab}$ neither preserves nor reverses the orientation, then $M$ is non-orientable. Andrew D. Hwang gave an excellent answer. But still wonders me, if converse statement holds. I.e. Question. If $M$ is non-orientable, can we find two such charts $(U_a,\phi_a),(U_b,\phi_b)?$ Again Andrew D. Hwang suggested that it holds and gave me the following hint @Fallen: Yes, the converse is true. Intuitively, if M is non-orientable, there exists a loop (closed curve) around which ""the orientation reverses"". Thicken the loop into a tube and cover it with two ""solid cylinders"" Ua and Ub. There are details to check, and this sketch may not be the easiest strategy to make rigorous. (E.g., if no such charts exist, start with an arbitrary atlas and reverse chart orientations as needed to get an atlas of compatible charts. Again, though, there are details to check....). I only managed to do it assuming that $M$ is connected and second countable. Proof. Assume that for any two charts $(U_a,\phi_a),(U_b,\phi_b),$ such that $U_a,U_b$ are connected and $U_a\cap U_b\neq\emptyset$ transformation function $\phi_{ab}$ preserves or reverses orientation. We want to show that $M$ is orientable. Let $\{(V_i,\psi_i)\}_{i}$ be a countable atlas such that $V_i$ are connected. From that we want to construct a new atlas $\{(V_i,\overline{\psi}_i)\}_{i}$ which is oriented. Construction will be inductive. $\overline{\psi}_1:=\psi_1. \overline{\psi}_i:=\psi_i$ or $\overline{\psi}_i:=\psi^*_i$ (here if $\psi_i=(x^1,\dots,x^n),$ then $\psi^*_i=(x^1,\dots,-x^n)$) to satisfy condition $$\forall_{j<i}\overline{\psi}_{ji}\hspace{5pt}\text{preserves orientation,}$$ where $\overline{\psi}_{ji}$ is transformation function from $\overline{\psi}_j$ to $\overline{\psi}_i.$ But the obvious question is, if such procedure exists. Suppose it fails at some $i.$ Hence there are $j,k<i,$ such that transformation from $\overline{\psi_j}$ to $\psi_i$ preserves orientation and transformation from $\overline{\psi_k}$ to $\psi_i$ reverses. Consider a curve $\gamma$ starting in $V_i\cap V_j$ and ending in $V_i\cap V_k$ and its neighberhoud $U_a$ such that it sits in $V_p$ for $p\leqslant i$ and it meets $V_i$ only in $V_i\cap V_j$ and $V_i\cap V_k.$ Let additionaly $U_a$ be such that $(U_a,\phi_a)$ is a chart for $\phi_a$ ""glued"" from $\overline{\psi_p}$ for $p<i.$ Set $(U_b,\phi_b):=(V_i,\psi_i).$ As a result $\phi_{ab}$ preserves and reverses an orientation. Hence contradiction with the assumption from the beggining. Hence procedure cannot fail at $i.$ So $M$ is orientable. These reasoning can be captured in a picture I ask about some simplification of the proof. Now it is too constructive and descriptive for me, especially construction of $\phi_a.$ Do you have any ideas how to prove it simpler?",,"['differential-geometry', 'manifolds', 'differential-topology', 'smooth-manifolds']"
67,Formal adjoint of curvature (Yang Mills),Formal adjoint of curvature (Yang Mills),,"Currently reading a paper on finding solutions to the Yang Mills equation $D^*\Omega=0$, where $\Omega$ is the curvature and $D^*$ is the formal adjoint of the exterior covariant derivative $D$. The paper expresses the quantity $D^*\Omega$ locally as follows: For a local orthonormal frame field $(e_1,\dots,e_m)$ on a Riemannian manifold $(M,h)$, they define $(e_i^*)_{i=1}^m$ to be the horizontal lifts to the bundle $P$ relative to the connection $\omega$. Then \begin{align} D^*\Omega&=-\sum_{i,j}^m(\nabla_{e_i}\Omega)(e_i^*,e_j^*)\pi^*\omega_j \end{align} where $\{\omega_i\}$ is a system of 1-forms on $M$ dual to $\{e_i\}$ and $\nabla$ is the Levi Civita connection of $(M,h)$. I am just wondering if there is a quick way to verify that this is indeed the formula for the formal adjoint of the curvature and how would you go about doing so?","Currently reading a paper on finding solutions to the Yang Mills equation $D^*\Omega=0$, where $\Omega$ is the curvature and $D^*$ is the formal adjoint of the exterior covariant derivative $D$. The paper expresses the quantity $D^*\Omega$ locally as follows: For a local orthonormal frame field $(e_1,\dots,e_m)$ on a Riemannian manifold $(M,h)$, they define $(e_i^*)_{i=1}^m$ to be the horizontal lifts to the bundle $P$ relative to the connection $\omega$. Then \begin{align} D^*\Omega&=-\sum_{i,j}^m(\nabla_{e_i}\Omega)(e_i^*,e_j^*)\pi^*\omega_j \end{align} where $\{\omega_i\}$ is a system of 1-forms on $M$ dual to $\{e_i\}$ and $\nabla$ is the Levi Civita connection of $(M,h)$. I am just wondering if there is a quick way to verify that this is indeed the formula for the formal adjoint of the curvature and how would you go about doing so?",,"['differential-geometry', 'manifolds', 'lie-groups', 'vector-bundles', 'principal-bundles']"
68,Does a left group action on a principal bundle induce an action on associated vector bundles?,Does a left group action on a principal bundle induce an action on associated vector bundles?,,"Let $G\hookrightarrow P\xrightarrow{\pi}M$ be a principal $G$-bundle with right action $\cdot $ and suppose we are also given a left action $\rho: U\times P\rightarrow P$ of some group $U$  on $P$. Everything is smooth. Note that since left and right actions commute, for $u\in U$ the map $\rho_u=\rho(u, ):P\rightarrow P$ maps fibres to fibres and induces a map $\bar \rho_u$  on $M$. I am interested in the case where $\bar\rho_u$ is not the identity on $M$. If $V$ is a vector space, $\kappa$ a representation of $G$ on $V$ and $E=P\times_\kappa V$ is the associated vector bundle with projection $\pi_E$, does $\rho$ induce in any natural way an action $\hat \rho$ of $U$ on $E$ so that the map $\hat\rho_u:E\rightarrow E$ is a vector bundle map (that is $\hat\rho$ maps fibres to fibres and $\hat\rho:E|_{\pi_(p)}\rightarrow E|_{\pi_(\rho_u(p))} $ is linear) which covers $\bar\rho_u$? It seems to me that a suitable map $\hat\rho_u$ would be of the form \begin{equation} \hat\rho_u([p,v])=[\rho_u(p),L_u(p)v], \end{equation} with $L_u(p):V\rightarrow V$a linear map. In order for $\hat\rho_u$ to be well defined we need $L_u(p\cdot h)=\kappa(h)^{-1}L_u(p)\kappa(h)$. The action on the fibres of $E$ is linear and $\hat\rho_u$ maps fibres to fibres and covers $\bar\rho_u$ as \begin{equation} \pi_E(\hat\rho_u([p,v]))=\pi_E([\rho_u(p),v])=\pi(\rho_u(p))=\bar\rho_u(\pi(p))=\bar\rho_u(\pi_E([p,v])). \end{equation} In general it seems to me that the only ""preferred"" choice for $L_u$ is to take $L_u(p)=\mathrm{Id}_V$ (or a multiple thereof) for all $p$, so that \begin{equation} \hat\rho_u([p,v])=[\rho_u(p),v]. \end{equation} If $U$ is a subgroup of the centre of $G$ we can also take $L_u(p)=\kappa(u)$, still independent of $p$. First, am I saying anything stupid? And second, are there other natural ways of defining an induced action of $U$ on $E$ with the required properties? EDIT: I have found the following related, but not equivalent question Group actions and associated bundles asking about induced actions on sections of an associated bundle. Sadly it is without answers too...","Let $G\hookrightarrow P\xrightarrow{\pi}M$ be a principal $G$-bundle with right action $\cdot $ and suppose we are also given a left action $\rho: U\times P\rightarrow P$ of some group $U$  on $P$. Everything is smooth. Note that since left and right actions commute, for $u\in U$ the map $\rho_u=\rho(u, ):P\rightarrow P$ maps fibres to fibres and induces a map $\bar \rho_u$  on $M$. I am interested in the case where $\bar\rho_u$ is not the identity on $M$. If $V$ is a vector space, $\kappa$ a representation of $G$ on $V$ and $E=P\times_\kappa V$ is the associated vector bundle with projection $\pi_E$, does $\rho$ induce in any natural way an action $\hat \rho$ of $U$ on $E$ so that the map $\hat\rho_u:E\rightarrow E$ is a vector bundle map (that is $\hat\rho$ maps fibres to fibres and $\hat\rho:E|_{\pi_(p)}\rightarrow E|_{\pi_(\rho_u(p))} $ is linear) which covers $\bar\rho_u$? It seems to me that a suitable map $\hat\rho_u$ would be of the form \begin{equation} \hat\rho_u([p,v])=[\rho_u(p),L_u(p)v], \end{equation} with $L_u(p):V\rightarrow V$a linear map. In order for $\hat\rho_u$ to be well defined we need $L_u(p\cdot h)=\kappa(h)^{-1}L_u(p)\kappa(h)$. The action on the fibres of $E$ is linear and $\hat\rho_u$ maps fibres to fibres and covers $\bar\rho_u$ as \begin{equation} \pi_E(\hat\rho_u([p,v]))=\pi_E([\rho_u(p),v])=\pi(\rho_u(p))=\bar\rho_u(\pi(p))=\bar\rho_u(\pi_E([p,v])). \end{equation} In general it seems to me that the only ""preferred"" choice for $L_u$ is to take $L_u(p)=\mathrm{Id}_V$ (or a multiple thereof) for all $p$, so that \begin{equation} \hat\rho_u([p,v])=[\rho_u(p),v]. \end{equation} If $U$ is a subgroup of the centre of $G$ we can also take $L_u(p)=\kappa(u)$, still independent of $p$. First, am I saying anything stupid? And second, are there other natural ways of defining an induced action of $U$ on $E$ with the required properties? EDIT: I have found the following related, but not equivalent question Group actions and associated bundles asking about induced actions on sections of an associated bundle. Sadly it is without answers too...",,"['differential-geometry', 'vector-bundles', 'fiber-bundles', 'principal-bundles', 'gauge-theory']"
69,A Quotient of the Euclidean Group,A Quotient of the Euclidean Group,,"$\newcommand{\euc}{\mathscr I}\newcommand{\R}{\mathbf R}$ Let $\euc(n)$ denote the the Euclidean group $\R^n\rtimes O_n(\R)$. Recall that $\euc(n)$ acts on $\R^n$ as $(\mathbf x, T)\cdot \mathbf y=\mathbf x+T\mathbf y$ for all $(\mathbf x, T)\in \euc(n)$ and $\mathbf y\in \R^n$. Consider the action of $\euc(n)$ on $(\R^n)^v$ defined as follows: $$ A\cdot(\mathbf y_1, \ldots, \mathbf y_v)=(A\cdot\mathbf y_1,\ldots, A\cdot\mathbf y_v) $$ for all $A\in \euc(n)$ and $(\mathbf y_1,\ldots, \mathbf y_v)\in (\R^n)^v$. Fix a point $\mathbf p=(\mathbf p_1, \ldots, \mathbf p_v)\in (\R^n)^v$ and define a map $F:\euc(n)\to (\R^n)^v$ as $$ F(A)=(A\cdot\mathbf p_1,\ldots,A\cdot\mathbf p_v) $$ for all $A\in \euc(n)$. Since $F^{-1}(\mathbf p)$ is an isotropy subgroup of a Lie group action, we know that $F^{-1}(\mathbf p)$ is a Lie subgroup of $\euc(n)$. Now for some reason unknown to me, we can give a manifold structure to $\euc(n)/F^{-1}(\mathbf p)$ such that the natural projection map $\pi:\euc(n)\to \euc(n)/F^{-1}(\mathbf p)$ is a smooth submersion. For set theoretical reasons, we can get a map $\bar F:\euc(n)/F^{-1}(\mathbf p)\to (\R^{n})^v$ such that $F=\bar F\circ \pi$. Since $\pi$ is a smooth submersion, we infer that $\bar F$ is a smooth map. My Question: Now on pg. 283 of this paper (titled ' The Rigidity of Graphs ' and written by B. Roth and L. Asimow ), it is said that the map $\bar F:\euc(n)/F^{-1}(\mathbf p)\to \text{im}(\bar F)$ is a diffeomorphism. It is not clear to me why is this map a diffeomorphism. In fact, it is not even clear why is $\text{im}(\bar F)$ a smooth manifold.","$\newcommand{\euc}{\mathscr I}\newcommand{\R}{\mathbf R}$ Let $\euc(n)$ denote the the Euclidean group $\R^n\rtimes O_n(\R)$. Recall that $\euc(n)$ acts on $\R^n$ as $(\mathbf x, T)\cdot \mathbf y=\mathbf x+T\mathbf y$ for all $(\mathbf x, T)\in \euc(n)$ and $\mathbf y\in \R^n$. Consider the action of $\euc(n)$ on $(\R^n)^v$ defined as follows: $$ A\cdot(\mathbf y_1, \ldots, \mathbf y_v)=(A\cdot\mathbf y_1,\ldots, A\cdot\mathbf y_v) $$ for all $A\in \euc(n)$ and $(\mathbf y_1,\ldots, \mathbf y_v)\in (\R^n)^v$. Fix a point $\mathbf p=(\mathbf p_1, \ldots, \mathbf p_v)\in (\R^n)^v$ and define a map $F:\euc(n)\to (\R^n)^v$ as $$ F(A)=(A\cdot\mathbf p_1,\ldots,A\cdot\mathbf p_v) $$ for all $A\in \euc(n)$. Since $F^{-1}(\mathbf p)$ is an isotropy subgroup of a Lie group action, we know that $F^{-1}(\mathbf p)$ is a Lie subgroup of $\euc(n)$. Now for some reason unknown to me, we can give a manifold structure to $\euc(n)/F^{-1}(\mathbf p)$ such that the natural projection map $\pi:\euc(n)\to \euc(n)/F^{-1}(\mathbf p)$ is a smooth submersion. For set theoretical reasons, we can get a map $\bar F:\euc(n)/F^{-1}(\mathbf p)\to (\R^{n})^v$ such that $F=\bar F\circ \pi$. Since $\pi$ is a smooth submersion, we infer that $\bar F$ is a smooth map. My Question: Now on pg. 283 of this paper (titled ' The Rigidity of Graphs ' and written by B. Roth and L. Asimow ), it is said that the map $\bar F:\euc(n)/F^{-1}(\mathbf p)\to \text{im}(\bar F)$ is a diffeomorphism. It is not clear to me why is this map a diffeomorphism. In fact, it is not even clear why is $\text{im}(\bar F)$ a smooth manifold.",,"['differential-geometry', 'lie-groups']"
70,Divergence of a tensor with respect to the Levi-Civita connection,Divergence of a tensor with respect to the Levi-Civita connection,,"In a Riemannian manifold $\mathcal{S}$ with metric $\boldsymbol{g}$, given a chart $\{x^a\}$, it is fairly easy to prove that the divergence of a vector field $\boldsymbol{w} : \mathcal{S} \to T\mathcal{S}$ is given by $$ \mathrm{div}\boldsymbol{w} = w^a{}_{|a} = \frac{1}{\sqrt{\det[g_{mn}]}}  \frac{\partial}{\partial x^a} \left[ \sqrt{\det[g_{mn}]} \, w^a \right], $$ where $[g_{mn}]$ is the matrix representation of $\boldsymbol{g}$ in the chart $\{x^a\}$, and the vertical bar in ${}_{|a}$ denotes the covariant derivative with respect to the Levi-Civita connection induced by $\boldsymbol{g}$. I am wondering whether there is an equivalent expression for the divergence of a higher-order tensor, say, a second-order tensor $\boldsymbol{\sigma} : \mathcal{S} \to T\mathcal{S} \otimes T\mathcal{S}$, in which case the component form is $(\mathrm{div}\boldsymbol{\sigma})^a = \sigma^{ab}{}_{|b}$, with the divergence taken, e.g., on the last index. PS: In case you are curious, yes, I am looking for an expression of the divergence of the (fully contravariant) Cauchy stress.","In a Riemannian manifold $\mathcal{S}$ with metric $\boldsymbol{g}$, given a chart $\{x^a\}$, it is fairly easy to prove that the divergence of a vector field $\boldsymbol{w} : \mathcal{S} \to T\mathcal{S}$ is given by $$ \mathrm{div}\boldsymbol{w} = w^a{}_{|a} = \frac{1}{\sqrt{\det[g_{mn}]}}  \frac{\partial}{\partial x^a} \left[ \sqrt{\det[g_{mn}]} \, w^a \right], $$ where $[g_{mn}]$ is the matrix representation of $\boldsymbol{g}$ in the chart $\{x^a\}$, and the vertical bar in ${}_{|a}$ denotes the covariant derivative with respect to the Levi-Civita connection induced by $\boldsymbol{g}$. I am wondering whether there is an equivalent expression for the divergence of a higher-order tensor, say, a second-order tensor $\boldsymbol{\sigma} : \mathcal{S} \to T\mathcal{S} \otimes T\mathcal{S}$, in which case the component form is $(\mathrm{div}\boldsymbol{\sigma})^a = \sigma^{ab}{}_{|b}$, with the divergence taken, e.g., on the last index. PS: In case you are curious, yes, I am looking for an expression of the divergence of the (fully contravariant) Cauchy stress.",,"['differential-geometry', 'riemannian-geometry', 'curvature']"
71,Interior Derivative and Contraction: Kobayashi and Nomizu.,Interior Derivative and Contraction: Kobayashi and Nomizu.,,"In Kobayashi & Nomizu, the interior derivative of an r-form is defined as $\iota_X \omega = C(X \otimes \omega)$, where $C$ is the contraction associated with the pair $(1,1)$ and $\omega$ is interpreted as a tensor of type $(0,r)$. They then claim that \begin{equation*} (\iota_X)(Y_1, \dots, Y_{r-1}) = r \; \omega(X, Y_1, \dots, Y_{r-1}) \end{equation*} My question is: where does the factor of $r$ come from? This seems to be inconsistent with their previous conventions for forms. Since they define $\omega_1 \wedge \omega_2 = \frac{1}{2}(\omega_1 \otimes \omega_2  - \omega_2 \otimes \omega_1)$, we should have \begin{equation*} C(X \otimes (\omega_1 \wedge \omega_2))(Y) = \frac{1}{2}( \omega_1(X) \omega_2(Y) - \omega_2(X) \omega_1(Y)) \end{equation*} whereas, using the determinant convention in K&N, given by \begin{equation*} \omega_1 \wedge \dots \wedge \omega_n = \frac{1}{n!} \det(\omega_i(X_j)) \end{equation*} we have \begin{equation*} 2 (\omega_1 \wedge \omega_2)(X,Y) = 2 \frac{1}{2} (\omega_1(X) \omega_2(Y) - \omega_2(X) \omega_1(Y)) \end{equation*} and so the two expressions are not equal. Where does the problem arise?","In Kobayashi & Nomizu, the interior derivative of an r-form is defined as $\iota_X \omega = C(X \otimes \omega)$, where $C$ is the contraction associated with the pair $(1,1)$ and $\omega$ is interpreted as a tensor of type $(0,r)$. They then claim that \begin{equation*} (\iota_X)(Y_1, \dots, Y_{r-1}) = r \; \omega(X, Y_1, \dots, Y_{r-1}) \end{equation*} My question is: where does the factor of $r$ come from? This seems to be inconsistent with their previous conventions for forms. Since they define $\omega_1 \wedge \omega_2 = \frac{1}{2}(\omega_1 \otimes \omega_2  - \omega_2 \otimes \omega_1)$, we should have \begin{equation*} C(X \otimes (\omega_1 \wedge \omega_2))(Y) = \frac{1}{2}( \omega_1(X) \omega_2(Y) - \omega_2(X) \omega_1(Y)) \end{equation*} whereas, using the determinant convention in K&N, given by \begin{equation*} \omega_1 \wedge \dots \wedge \omega_n = \frac{1}{n!} \det(\omega_i(X_j)) \end{equation*} we have \begin{equation*} 2 (\omega_1 \wedge \omega_2)(X,Y) = 2 \frac{1}{2} (\omega_1(X) \omega_2(Y) - \omega_2(X) \omega_1(Y)) \end{equation*} and so the two expressions are not equal. Where does the problem arise?",,['differential-geometry']
72,Vectors that geodesically generate the same surface,Vectors that geodesically generate the same surface,,"Suppose that $\langle M,g \rangle$ is a complete, simply connected Riemannian symmetric space. The surface geodesically generated by a vector $\xi$ in $T_pM$ is the set of points lying on geodesics passing through $p$ that are orthogonal to $\xi$. Suppose that $\xi$ and $\xi^\prime$ are vectors in $T_pM$ and $T_{p^\prime}M$ respectively that geodesically generate the same surface. Does it follow that the vector obtained by parallel transporting $\xi$ along the geodesic connecting $p$ and $p^\prime$ is proportional to $\xi^\prime$?","Suppose that $\langle M,g \rangle$ is a complete, simply connected Riemannian symmetric space. The surface geodesically generated by a vector $\xi$ in $T_pM$ is the set of points lying on geodesics passing through $p$ that are orthogonal to $\xi$. Suppose that $\xi$ and $\xi^\prime$ are vectors in $T_pM$ and $T_{p^\prime}M$ respectively that geodesically generate the same surface. Does it follow that the vector obtained by parallel transporting $\xi$ along the geodesic connecting $p$ and $p^\prime$ is proportional to $\xi^\prime$?",,"['differential-geometry', 'riemannian-geometry', 'smooth-manifolds', 'general-relativity', 'semi-riemannian-geometry']"
73,Prerequsites for working through the 2nd half of Gradient flows in metric spaces and in the spaces of probability measures,Prerequsites for working through the 2nd half of Gradient flows in metric spaces and in the spaces of probability measures,,"I apologize in advance if this question is too general, that is, not a request for a specific reference, but more of a request for a road map, perhaps from someone that knows the material and, in retrospect, can see what knowledge was necessary for them in their development. I also apologize for the lack of brevity. I am asking from the perspective of someone with only an undergraduate mathematics degree and a small amount of slightly more advanced self-study in differential geometry and topology that would like to work toward an understanding of the second half of Gradient Flows In Metric Spaces and in the Space of Probability Measures by Ambrosio, Gigli and Savare. I am aware that this is an advanced area that relies on many others and thus the present question. I have read the post on mathoverflow: https://mathoverflow.net/questions/43083/textbooks-or-notes-on-gradient-flows-in-metric-spaces as well as the post: Gradient flows in metric spaces on stackexchange. Additionally, I have taken taken a look at the notes linked to in the above, some of which is accessible to me and some of which is not. I feel that I am sufficiently distant skill-wise from what is needed to read the material that textbooks are probably the first place that I want to head. It has been pointed out, for example, that Optimal Transport, old and new by Cédric Villani is useful and have begun to take a look at that. This is a good example however as, optimal transport itself touches a diversity of mathematical areas. Investigating the references (on Arxiv), I finds a wide array of core mathematics that are used by the authors in referenced material: analysis and ODEs, differential/Riemannian geometry, metric geometry, analysis of PDEs, probability... Related to these are other areas, e.g., geometric measure theory, which is itself a good example of the interdependance of material (differential geometry, measure theory, calculus of variations, analysis). This interdependence, while exciting to the uninitiated, does not allow for a quick understanding of what, exactly, the prerequisites are and what the ""prerequisites to the prerequisites"" may be in some limited cases. Finally, in related/referenced work, one also sees technical material accessible mainly to experts in say geometry, e.g., Gromov's Metric Structures for Riemannian and Non-Riemannian Spaces which I bring up as an example because in this case, it would be great for someone to provide a pointer to A Course in Metric Geometry by Burago^2 and Ivanov. Ideally, that is the kind of information I am looking for. For example responses along the lines of, ""Well, the book and related research rely heavily on results from metric geometry, some of which are available only in advanced monographs. A good introduction to the field is A Course in Metric Geometry ."" Or perhaps responses like, ""For the PDE-related material, a thorough understanding of Evan's book is sufficient."" Or, ""Check out Stroock's books on probability, analysis and PDE."" I have found the notes, blibiography and even the preliminary remarks and program from the course at https://www.math.leidenuniv.nl/~vangaans/topicsinanalysis2011.html to be helpful in beginning to situate myself. It seems there is material from analysis, measure theory, probability, optimal transport, ODE, PDE, stochastic processes and other fields that must be mastered in order to really engage with this material. As I am beginning this process as a self-study to hopefully be continued in graduate school, I am really just looking for a list of prerequisite math, good references to learning those areas, and tips on the knowledge that one must accumulate in order to understand the above book (especially the second half) at the level of applying it and reading related papers in the field. It would be very helpful if this advice came from those with direct experience learning these ideas. Thank you in advance for any help!","I apologize in advance if this question is too general, that is, not a request for a specific reference, but more of a request for a road map, perhaps from someone that knows the material and, in retrospect, can see what knowledge was necessary for them in their development. I also apologize for the lack of brevity. I am asking from the perspective of someone with only an undergraduate mathematics degree and a small amount of slightly more advanced self-study in differential geometry and topology that would like to work toward an understanding of the second half of Gradient Flows In Metric Spaces and in the Space of Probability Measures by Ambrosio, Gigli and Savare. I am aware that this is an advanced area that relies on many others and thus the present question. I have read the post on mathoverflow: https://mathoverflow.net/questions/43083/textbooks-or-notes-on-gradient-flows-in-metric-spaces as well as the post: Gradient flows in metric spaces on stackexchange. Additionally, I have taken taken a look at the notes linked to in the above, some of which is accessible to me and some of which is not. I feel that I am sufficiently distant skill-wise from what is needed to read the material that textbooks are probably the first place that I want to head. It has been pointed out, for example, that Optimal Transport, old and new by Cédric Villani is useful and have begun to take a look at that. This is a good example however as, optimal transport itself touches a diversity of mathematical areas. Investigating the references (on Arxiv), I finds a wide array of core mathematics that are used by the authors in referenced material: analysis and ODEs, differential/Riemannian geometry, metric geometry, analysis of PDEs, probability... Related to these are other areas, e.g., geometric measure theory, which is itself a good example of the interdependance of material (differential geometry, measure theory, calculus of variations, analysis). This interdependence, while exciting to the uninitiated, does not allow for a quick understanding of what, exactly, the prerequisites are and what the ""prerequisites to the prerequisites"" may be in some limited cases. Finally, in related/referenced work, one also sees technical material accessible mainly to experts in say geometry, e.g., Gromov's Metric Structures for Riemannian and Non-Riemannian Spaces which I bring up as an example because in this case, it would be great for someone to provide a pointer to A Course in Metric Geometry by Burago^2 and Ivanov. Ideally, that is the kind of information I am looking for. For example responses along the lines of, ""Well, the book and related research rely heavily on results from metric geometry, some of which are available only in advanced monographs. A good introduction to the field is A Course in Metric Geometry ."" Or perhaps responses like, ""For the PDE-related material, a thorough understanding of Evan's book is sufficient."" Or, ""Check out Stroock's books on probability, analysis and PDE."" I have found the notes, blibiography and even the preliminary remarks and program from the course at https://www.math.leidenuniv.nl/~vangaans/topicsinanalysis2011.html to be helpful in beginning to situate myself. It seems there is material from analysis, measure theory, probability, optimal transport, ODE, PDE, stochastic processes and other fields that must be mastered in order to really engage with this material. As I am beginning this process as a self-study to hopefully be continued in graduate school, I am really just looking for a list of prerequisite math, good references to learning those areas, and tips on the knowledge that one must accumulate in order to understand the above book (especially the second half) at the level of applying it and reading related papers in the field. It would be very helpful if this advice came from those with direct experience learning these ideas. Thank you in advance for any help!",,"['differential-geometry', 'reference-request', 'partial-differential-equations', 'soft-question', 'metric-geometry']"
74,Extending a function on a submanifold to the ambient manifold & proof of a property of a vector field.,Extending a function on a submanifold to the ambient manifold & proof of a property of a vector field.,,"$\newcommand{\wt}[1]{\widetilde{#1}}$ Hello, I just tried my hand at two exercises from John M Lee's book Riemannian Geometry and I would like to know whether my reasoning is sound or if I did something wrong. This is about exercise 2.3 (a) and (c) . Let $M^n\subset\widetilde{M}^m$ be an embedded submanifold. (a) If $f\in C^\infty(M)$ , show that $f$ can be extended to a smooth function on a neighborhood of $M$ in $\widetilde{M}$ . (c) Let $\widetilde{X}$ be a vector field on $\widetilde{M}$ , i.e. $\widetilde{X}\in\mathfrak{X}(\widetilde{M})$ . Show: $\widetilde{X}$ is tangent to $M$ $\iff$ If $f\in C^\infty(\widetilde{M})$ with $f_{|M}=0$ , then $(\wt{X}f)_{|M}=0$ Okay, so here's what I did for (a) . Choose open sets $\wt{U}_\alpha\subset\wt{M}$ s.t. $M\subseteq\bigcup_\alpha \wt{U}_\alpha$ and such that they imply slice coordinates  for the sets $U_\alpha=\wt{U}_\alpha\cap M$ , and both form open covers of $M$ . A note on the slice coordinates (abusing the notation a bit, but this is the way he does it in that particular book): If $\wt{U}_\alpha\leadsto x^1,...,x^m$ , then $U_\alpha\leadsto x^1,...,x^n$ . Define $\wt{f}_\alpha\in C^\infty(\wt{U}_\alpha)$ via $\wt{f}_\alpha(x^1,...,x^m)=f(x^1,...,x^n)$ . This definition is obviously independet of the last $m-n$ coordinates. Choose a partition of unity $p_\alpha$ subordinate to $\wt{U}_\alpha$ , and set $F=\sum_\alpha p_\alpha\wt{f}_\alpha$ . Then $F\in C^\infty\left(\bigcup_\alpha\wt{U}_\alpha\right)$ is an extension of $f$ in a neighborhood of $M$ . Now, for (c) : We again use the slice coordinates $x^i$ like above. Note first that if $f_{|M=0}$ , then $D f_{|\wt{U}_\alpha}=\partial_i f\mathrm{d}x^i_{|\wt{U}_\alpha}$ with $n<i\leq m$ , so let $f$ w.l.o.g. vanish on $M$ . $\wt{X}_{|M}$ is tangent to $M$ . $\iff$ In local coordinates of $\wt{U}_\alpha$ , $\wt{X}_{|\wt{U}_\alpha}={X^i\partial_i}_{|\wt{U}_\alpha}$ with $X^i(p)=0$ for all $p\in U_\alpha$ and $n<i\leq m$ . $\iff$ $\wt{X}f_{|\wt{U}_\alpha}=0$ , since-roughly spoken-there is no matching pair of indices in the $\partial_i$ and $\mathrm{d}x^j$ . But this holds for all $\wt{U}_\alpha$ , so for every point in $M$ . Personally, I can't think of any conflicts there, but that's why I'm asking here: I don't have too much experience. So - did I make a mistake somewhere, was I sloppy, etc? Thanks!","Hello, I just tried my hand at two exercises from John M Lee's book Riemannian Geometry and I would like to know whether my reasoning is sound or if I did something wrong. This is about exercise 2.3 (a) and (c) . Let be an embedded submanifold. (a) If , show that can be extended to a smooth function on a neighborhood of in . (c) Let be a vector field on , i.e. . Show: is tangent to If with , then Okay, so here's what I did for (a) . Choose open sets s.t. and such that they imply slice coordinates  for the sets , and both form open covers of . A note on the slice coordinates (abusing the notation a bit, but this is the way he does it in that particular book): If , then . Define via . This definition is obviously independet of the last coordinates. Choose a partition of unity subordinate to , and set . Then is an extension of in a neighborhood of . Now, for (c) : We again use the slice coordinates like above. Note first that if , then with , so let w.l.o.g. vanish on . is tangent to . In local coordinates of , with for all and . , since-roughly spoken-there is no matching pair of indices in the and . But this holds for all , so for every point in . Personally, I can't think of any conflicts there, but that's why I'm asking here: I don't have too much experience. So - did I make a mistake somewhere, was I sloppy, etc? Thanks!","\newcommand{\wt}[1]{\widetilde{#1}} M^n\subset\widetilde{M}^m f\in C^\infty(M) f M \widetilde{M} \widetilde{X} \widetilde{M} \widetilde{X}\in\mathfrak{X}(\widetilde{M}) \widetilde{X} M \iff f\in C^\infty(\widetilde{M}) f_{|M}=0 (\wt{X}f)_{|M}=0 \wt{U}_\alpha\subset\wt{M} M\subseteq\bigcup_\alpha \wt{U}_\alpha U_\alpha=\wt{U}_\alpha\cap M M \wt{U}_\alpha\leadsto x^1,...,x^m U_\alpha\leadsto x^1,...,x^n \wt{f}_\alpha\in C^\infty(\wt{U}_\alpha) \wt{f}_\alpha(x^1,...,x^m)=f(x^1,...,x^n) m-n p_\alpha \wt{U}_\alpha F=\sum_\alpha p_\alpha\wt{f}_\alpha F\in C^\infty\left(\bigcup_\alpha\wt{U}_\alpha\right) f M x^i f_{|M=0} D f_{|\wt{U}_\alpha}=\partial_i f\mathrm{d}x^i_{|\wt{U}_\alpha} n<i\leq m f M \wt{X}_{|M} M \iff \wt{U}_\alpha \wt{X}_{|\wt{U}_\alpha}={X^i\partial_i}_{|\wt{U}_\alpha} X^i(p)=0 p\in U_\alpha n<i\leq m \iff \wt{X}f_{|\wt{U}_\alpha}=0 \partial_i \mathrm{d}x^j \wt{U}_\alpha M","['differential-geometry', 'smooth-manifolds']"
75,Is There a de Rham Homology,Is There a de Rham Homology,,"For differential manifold category, we can introduce the differential form to make up a cochain, and then get the de Rham cohomology group. My question is that if we use $\text{Hom}$ functor to get the dual chain of the cochain, then does the new homology satisfies the Eilenberg-Steenrod axioms? If so, is there any reference to study it? Any advice is helpful. Thank you.","For differential manifold category, we can introduce the differential form to make up a cochain, and then get the de Rham cohomology group. My question is that if we use $\text{Hom}$ functor to get the dual chain of the cochain, then does the new homology satisfies the Eilenberg-Steenrod axioms? If so, is there any reference to study it? Any advice is helpful. Thank you.",,"['reference-request', 'differential-geometry', 'homology-cohomology']"
76,Hawking's and Ellis' derivation of the form of Einstein's field equations,Hawking's and Ellis' derivation of the form of Einstein's field equations,,"On pages 72-73 of the book ""The large scale structure of space-time"" Hawking and Ellis show while determining the form of the field equations of general relativity that there is a relation of the form $R_{ab} = K_{ab}$, where $K_{ab}$ is a tensorial function of the energy-momentum tensor $T_{ab}$ and the metric $g_{ab}$. They then state that $K_{ab}$ is of the form $$K_{ab} = \kappa \left(T_{ab}-\frac{1}{2} Tg_{ab} \right) + \Lambda g_{ab}$$ for some constants $\kappa$ und $\Lambda$. Here they use apart from the stated tensorial property the following facts. The contracted Bianchi identities ${K_{a}^{\,b}}_{;b} = \frac{1}{2} K_{;b}$ hold. The only first order identities satisfied by the energy-momentum tensor are the conservation equations ${T_{a}^{\,b}}_{;b} = 0$. Perhaps from Postulate (b) in the book the symmetry of the energy-momentum tensor $T_{ab}$. Maybe also some regularity assumptions on the function $K_{ab}$ are implicitly assumed. We have tried unsuccessfully to give a mathematically rigorous proof of this fact. In the vacuum case, i.e. the energy-momentum tensor vanishes and $K_{ab}$ therefore only depends on the metric, one can argue as follows: Writing $g = (g_{ab})$ and $K = (K_{ab})$ the tensorial property translates into the identity $K(SgS^T) = SK(g)S^T$ for all regular matrices $S$. It follows from Sylvester's law and the tensorial property that it suffices to determine the value of  $$A = K\left(\begin{pmatrix} -1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 \\ 0 & 0 &1 & 0 \\ 0 & 0 & 0 & 1 \end{pmatrix}\right) \begin{pmatrix} -1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 \\ 0 & 0 &1 & 0 \\ 0 & 0 & 0 & 1 \end{pmatrix}.$$ Now, from the tensorial property one obtains that $A$ commutes with every element of the Lorentz group and therefore must be a multiple of the identity, for example by Schur's lemma. Therefore one has  $$K(g) = K\left(S \begin{pmatrix} -1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 \\ 0 & 0 &1 & 0 \\ 0 & 0 & 0 & 1 \end{pmatrix} S^T \right) = S A \begin{pmatrix} -1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 \\ 0 & 0 &1 & 0 \\ 0 & 0 & 0 & 1 \end{pmatrix} S^T = \Lambda S \begin{pmatrix} -1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 \\ 0 & 0 &1 & 0 \\ 0 & 0 & 0 & 1 \end{pmatrix} S^T = \Lambda g.$$ So in this special case the assertion follows only from the tensorial property. However, we do not know how to deal with the general case. Can anyone give us a reference or a hint? Moreover, does one need property 3)?","On pages 72-73 of the book ""The large scale structure of space-time"" Hawking and Ellis show while determining the form of the field equations of general relativity that there is a relation of the form $R_{ab} = K_{ab}$, where $K_{ab}$ is a tensorial function of the energy-momentum tensor $T_{ab}$ and the metric $g_{ab}$. They then state that $K_{ab}$ is of the form $$K_{ab} = \kappa \left(T_{ab}-\frac{1}{2} Tg_{ab} \right) + \Lambda g_{ab}$$ for some constants $\kappa$ und $\Lambda$. Here they use apart from the stated tensorial property the following facts. The contracted Bianchi identities ${K_{a}^{\,b}}_{;b} = \frac{1}{2} K_{;b}$ hold. The only first order identities satisfied by the energy-momentum tensor are the conservation equations ${T_{a}^{\,b}}_{;b} = 0$. Perhaps from Postulate (b) in the book the symmetry of the energy-momentum tensor $T_{ab}$. Maybe also some regularity assumptions on the function $K_{ab}$ are implicitly assumed. We have tried unsuccessfully to give a mathematically rigorous proof of this fact. In the vacuum case, i.e. the energy-momentum tensor vanishes and $K_{ab}$ therefore only depends on the metric, one can argue as follows: Writing $g = (g_{ab})$ and $K = (K_{ab})$ the tensorial property translates into the identity $K(SgS^T) = SK(g)S^T$ for all regular matrices $S$. It follows from Sylvester's law and the tensorial property that it suffices to determine the value of  $$A = K\left(\begin{pmatrix} -1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 \\ 0 & 0 &1 & 0 \\ 0 & 0 & 0 & 1 \end{pmatrix}\right) \begin{pmatrix} -1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 \\ 0 & 0 &1 & 0 \\ 0 & 0 & 0 & 1 \end{pmatrix}.$$ Now, from the tensorial property one obtains that $A$ commutes with every element of the Lorentz group and therefore must be a multiple of the identity, for example by Schur's lemma. Therefore one has  $$K(g) = K\left(S \begin{pmatrix} -1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 \\ 0 & 0 &1 & 0 \\ 0 & 0 & 0 & 1 \end{pmatrix} S^T \right) = S A \begin{pmatrix} -1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 \\ 0 & 0 &1 & 0 \\ 0 & 0 & 0 & 1 \end{pmatrix} S^T = \Lambda S \begin{pmatrix} -1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 \\ 0 & 0 &1 & 0 \\ 0 & 0 & 0 & 1 \end{pmatrix} S^T = \Lambda g.$$ So in this special case the assertion follows only from the tensorial property. However, we do not know how to deal with the general case. Can anyone give us a reference or a hint? Moreover, does one need property 3)?",,"['differential-geometry', 'mathematical-physics', 'general-relativity']"
77,Existence of a holomorphic connection implies existence of a flat connection,Existence of a holomorphic connection implies existence of a flat connection,,"Let $E$ be a holomorphic vector bundle on a complex manifold $X$, and let $D: E \to E \otimes \Omega_X$ be a holomorphic connection on $E$ i.e. $$ D(fs) = s\otimes \partial(f)+ fD(s), $$ for any local holomorphic function $f$ and local section $s$. Locally such conections look like  $$ D = \partial + A, $$ where $A$ is a holomorphic section of $\operatorname{End}(E)\otimes \Omega_X$. If $D$ is a holomorphic connection on $E$ then $D+\bar{\partial}$ is an ""ordinary"" connection on $E$. How can one show that if $E$ admits a holomorphic connection then it admits a flat connection? In other words there is $B \in\operatorname{End}(E)\otimes \Omega_X$ s.t. $$ (\bar{\partial} +D+B)^2=0. $$","Let $E$ be a holomorphic vector bundle on a complex manifold $X$, and let $D: E \to E \otimes \Omega_X$ be a holomorphic connection on $E$ i.e. $$ D(fs) = s\otimes \partial(f)+ fD(s), $$ for any local holomorphic function $f$ and local section $s$. Locally such conections look like  $$ D = \partial + A, $$ where $A$ is a holomorphic section of $\operatorname{End}(E)\otimes \Omega_X$. If $D$ is a holomorphic connection on $E$ then $D+\bar{\partial}$ is an ""ordinary"" connection on $E$. How can one show that if $E$ admits a holomorphic connection then it admits a flat connection? In other words there is $B \in\operatorname{End}(E)\otimes \Omega_X$ s.t. $$ (\bar{\partial} +D+B)^2=0. $$",,"['differential-geometry', 'complex-geometry', 'vector-bundles', 'connections', 'holomorphic-bundles']"
78,When is a linear map of 1-forms a pullback?,When is a linear map of 1-forms a pullback?,,"Every diffeomorphism $\phi: M\to N$ between two-dimensional compact oriented Riemannian manifolds induces a linear map on one-forms $L:\Omega^1(M)\to\Omega^1(N)$ given by the pullback of $\phi^{-1}$. Is there a simple condition for when a linear map $L$ on the one-forms is the pullback by some diffeomorphism? In principle, if I know how $L$ acts on exact forms, I know how any such $\phi$ would have to act on the zero-forms of $M$; I could then choose appropriate bases for $\Omega^0(M)$ and $\Omega^0(N)$ and read off which points of $M$ must map to which on $N$. And then check that this $\phi^{-1}$ correctly pulls back all of the coexact forms...","Every diffeomorphism $\phi: M\to N$ between two-dimensional compact oriented Riemannian manifolds induces a linear map on one-forms $L:\Omega^1(M)\to\Omega^1(N)$ given by the pullback of $\phi^{-1}$. Is there a simple condition for when a linear map $L$ on the one-forms is the pullback by some diffeomorphism? In principle, if I know how $L$ acts on exact forms, I know how any such $\phi$ would have to act on the zero-forms of $M$; I could then choose appropriate bases for $\Omega^0(M)$ and $\Omega^0(N)$ and read off which points of $M$ must map to which on $N$. And then check that this $\phi^{-1}$ correctly pulls back all of the coexact forms...",,['differential-geometry']
79,Compact surfaces with boundary of constant negative curvature,Compact surfaces with boundary of constant negative curvature,,"Consider a surface (with boundary) diffeomorphic to $S^1 \times [0, 1]$ and with constant negative curvature, sitting inside $\mathbb{R}^3$. All the examples I know of such surfaces are ""part of"" (or ""cut out of"", if that makes better sense) a surface of revolution (examples are the catenoid, tractricoid, etc.; O'Neill's ""Elementary Differential Geometry"" has a comprehensive list on page 261, Exercise 7). I was wondering, are all constantly negatively curved $S^1 \times [0, 1]$ obtained this way (that is, cut out from a surface of revolution)?","Consider a surface (with boundary) diffeomorphic to $S^1 \times [0, 1]$ and with constant negative curvature, sitting inside $\mathbb{R}^3$. All the examples I know of such surfaces are ""part of"" (or ""cut out of"", if that makes better sense) a surface of revolution (examples are the catenoid, tractricoid, etc.; O'Neill's ""Elementary Differential Geometry"" has a comprehensive list on page 261, Exercise 7). I was wondering, are all constantly negatively curved $S^1 \times [0, 1]$ obtained this way (that is, cut out from a surface of revolution)?",,"['differential-geometry', 'surfaces', 'hyperbolic-geometry']"
80,Intuition for basic concepts in differential geometry,Intuition for basic concepts in differential geometry,,"Im studying a basic differential geometry course this semester. In the class, we defined the concept of covariant derivative (connection) as a function which takes 2 vectors fields into a vector field and satisfies some algebraic properties of derivative (linearity, additivity and product rule). From this definition we showed that the connection can be specified by the Christoffel symbols. The covariant derivative ""should be"" a way of differentiating vectors fields along vector fields. However, there are infinite covariant derivatives on any surface, so using a random one wont make sense. We proved the ""fundamental theorem of Riemmanian geometry"" - existence and uniqueness of Levi-Civita connection. Except for the nice properties of the Levi-Civita connection - why should I believe it is actually a good way to differentiate vector fields? An example from analytical mechanics could be great since Im familiar with the subject and didnt learn general relativity yet. Another concern resulting from the first one is ""Why (in what sense) is parallel transport parallel?"". Parallel transport along a curve is defined using covariant derivative along the velocity field of the curve. In the euclidean space, the definition makes perfect sense - parallel transport is actually parallel. In other surfaces, the covariant derivative is 0, and I didn't find any geometric intuition about ""what is actually parallel"". Thanks, Tsuf.","Im studying a basic differential geometry course this semester. In the class, we defined the concept of covariant derivative (connection) as a function which takes 2 vectors fields into a vector field and satisfies some algebraic properties of derivative (linearity, additivity and product rule). From this definition we showed that the connection can be specified by the Christoffel symbols. The covariant derivative ""should be"" a way of differentiating vectors fields along vector fields. However, there are infinite covariant derivatives on any surface, so using a random one wont make sense. We proved the ""fundamental theorem of Riemmanian geometry"" - existence and uniqueness of Levi-Civita connection. Except for the nice properties of the Levi-Civita connection - why should I believe it is actually a good way to differentiate vector fields? An example from analytical mechanics could be great since Im familiar with the subject and didnt learn general relativity yet. Another concern resulting from the first one is ""Why (in what sense) is parallel transport parallel?"". Parallel transport along a curve is defined using covariant derivative along the velocity field of the curve. In the euclidean space, the definition makes perfect sense - parallel transport is actually parallel. In other surfaces, the covariant derivative is 0, and I didn't find any geometric intuition about ""what is actually parallel"". Thanks, Tsuf.",,['differential-geometry']
81,"Unipotent representations of SL(2,R) by quantization","Unipotent representations of SL(2,R) by quantization",,"I'm a PhD student in mathematical physics and I happen to need some elements of Kirillov's ""orbit method"" for producing representations of Lie groups. I'm familiar with symplectic geometry, geometric quantization and coadjoint orbits. As regards the present question, I use the terminology of Witten, ""Coadjoint orbits of the Virasoro group"" . Specifically, my questions are the following: Are all unipotent representations of SL(2,R) known and classified? If yes, is it known how to reproduce these representations by geometric quantization of the ""cone-like"" coadjoint orbits of SL(2,R)? Same questions for any non-compact, semi-simple Lie group. I've tried to look for an answer by Googling ""unipotent representations SL(2,R)"" and similar keywords, but the only search results I got were research papers that were too advanced/obscure to me :-( In any case, sorry in advance if this question is trivial or if it is a duplicate of another math.SE question.","I'm a PhD student in mathematical physics and I happen to need some elements of Kirillov's ""orbit method"" for producing representations of Lie groups. I'm familiar with symplectic geometry, geometric quantization and coadjoint orbits. As regards the present question, I use the terminology of Witten, ""Coadjoint orbits of the Virasoro group"" . Specifically, my questions are the following: Are all unipotent representations of SL(2,R) known and classified? If yes, is it known how to reproduce these representations by geometric quantization of the ""cone-like"" coadjoint orbits of SL(2,R)? Same questions for any non-compact, semi-simple Lie group. I've tried to look for an answer by Googling ""unipotent representations SL(2,R)"" and similar keywords, but the only search results I got were research papers that were too advanced/obscure to me :-( In any case, sorry in advance if this question is trivial or if it is a duplicate of another math.SE question.",,"['differential-geometry', 'representation-theory']"
82,How to derive the cigar soliton solution to the Ricci flow equation?,How to derive the cigar soliton solution to the Ricci flow equation?,,"I am trying to derive the cigar soliton solution to the Ricci flow equation.  Such solution has the form $$ {\frac {{{\it dx}}^{2}+{{\it dy}}^{2}}{{{\rm e}^{4\,t}}+{x}^{2}+{y}^{2 }}}  $$ I am starting from a metric with he form $${\frac {{{\it dx}}^{2}+{{\it dy}}^{2}}{f \left( t,x,y \right) }}$$ and from the Ricci flow equations $dg_{ij}/dt = -2 R_{ij}$, I am obtaining $$-{\frac {\partial }{\partial t}}f \left( t,x,y \right) = \left( { \frac {\partial }{\partial y}}f \left( t,x,y \right)  \right) ^{2}-  \left( {\frac {\partial ^{2}}{\partial {y}^{2}}}f \left( t,x,y  \right)  \right) f \left( t,x,y \right) + \left( {\frac {\partial }{ \partial x}}f \left( t,x,y \right)  \right) ^{2}- \left( {\frac { \partial ^{2}}{\partial {x}^{2}}}f \left( t,x,y \right)  \right) f  \left( t,x,y \right) $$ I am looking for a solution of the form $f(t,x,y)=F(t)+g(x)+h(y)$.  Then I obtain $$f \left( t,x,y \right) ={\frac {{C_{{2}}}^{2}}{C_{{1}}}}+{{\rm e}^{2\, C_{{1}}t}}C_{{3}}+{\frac {1}{2}}C_{{1}}{x}^{2}+C_{{2}}x+{\frac {1}{2}}C_{{1}}{y}^{2}+C_{ {2}}y $$ Please let me know what other conditions it is necessary to apply with the aim to obtain the cigar soliton solution.  Many thanks.","I am trying to derive the cigar soliton solution to the Ricci flow equation.  Such solution has the form $$ {\frac {{{\it dx}}^{2}+{{\it dy}}^{2}}{{{\rm e}^{4\,t}}+{x}^{2}+{y}^{2 }}}  $$ I am starting from a metric with he form $${\frac {{{\it dx}}^{2}+{{\it dy}}^{2}}{f \left( t,x,y \right) }}$$ and from the Ricci flow equations $dg_{ij}/dt = -2 R_{ij}$, I am obtaining $$-{\frac {\partial }{\partial t}}f \left( t,x,y \right) = \left( { \frac {\partial }{\partial y}}f \left( t,x,y \right)  \right) ^{2}-  \left( {\frac {\partial ^{2}}{\partial {y}^{2}}}f \left( t,x,y  \right)  \right) f \left( t,x,y \right) + \left( {\frac {\partial }{ \partial x}}f \left( t,x,y \right)  \right) ^{2}- \left( {\frac { \partial ^{2}}{\partial {x}^{2}}}f \left( t,x,y \right)  \right) f  \left( t,x,y \right) $$ I am looking for a solution of the form $f(t,x,y)=F(t)+g(x)+h(y)$.  Then I obtain $$f \left( t,x,y \right) ={\frac {{C_{{2}}}^{2}}{C_{{1}}}}+{{\rm e}^{2\, C_{{1}}t}}C_{{3}}+{\frac {1}{2}}C_{{1}}{x}^{2}+C_{{2}}x+{\frac {1}{2}}C_{{1}}{y}^{2}+C_{ {2}}y $$ Please let me know what other conditions it is necessary to apply with the aim to obtain the cigar soliton solution.  Many thanks.",,"['differential-geometry', 'partial-differential-equations', 'ricci-flow']"
83,Decomposition of Laplacian into tangental and normal components w.r.t. submanifold,Decomposition of Laplacian into tangental and normal components w.r.t. submanifold,,"If I have the covariant Laplacian operator acting on a tensor e.g. $\nabla^2 h_{\mu\nu}$ on a (pseudo-Riemannian) manifold, and I have (say a codimension-2) submanifold, how can I ""decompose"" the Laplacian into normal and tangential components w.r.t the submanifold? I have found that section 14.2 of ""Fundamentals of Differential geometry"" by Serge Lang has material on decomposing the covariant Laplacian of a function $\nabla^2 f$ w.r.t. a submanifold, but I am wondering whether there is a more physicist-friendly reference, or one that explicitly extends the formalism to the Laplacian acting on tensors. Many thanks, A physicist","If I have the covariant Laplacian operator acting on a tensor e.g. $\nabla^2 h_{\mu\nu}$ on a (pseudo-Riemannian) manifold, and I have (say a codimension-2) submanifold, how can I ""decompose"" the Laplacian into normal and tangential components w.r.t the submanifold? I have found that section 14.2 of ""Fundamentals of Differential geometry"" by Serge Lang has material on decomposing the covariant Laplacian of a function $\nabla^2 f$ w.r.t. a submanifold, but I am wondering whether there is a more physicist-friendly reference, or one that explicitly extends the formalism to the Laplacian acting on tensors. Many thanks, A physicist",,"['reference-request', 'differential-geometry', 'manifolds', 'riemannian-geometry', 'differential-operators']"
84,Isometry group of a compact manifold,Isometry group of a compact manifold,,Is an isometry group of a compact manifold always a compact group?,Is an isometry group of a compact manifold always a compact group?,,"['differential-geometry', 'lie-groups', 'riemannian-geometry']"
85,Two definitions of real flag manifolds: do they coincide?,Two definitions of real flag manifolds: do they coincide?,,"Let $G$ be a real semisimple Lie group with finite center. Definition 1 A real flag manifold is a homogeneous space $G/Q$ where  $Q$ is a parabolic subgroup of $G$. Definition 2 Let $K$ be a maximal compact subgroup of $G$ and $\mathfrak g=\mathfrak k+\mathfrak p$ the Cartan decomposition. A real flag manifold is an adjoint orbit of $K$ in $\mathfrak p$. Question Do these definitions coincide? Since $K$ acts transitively on $G/Q$, we have $K/K\cap Q=G/Q$. Therefore I guess the problem amounts to showing that $K\cap Q$ is the centralizer in $K$ of a certain element $h_0$ in the Cartan subspace $\mathfrak a \subset\mathfrak p$ which defines $Q$. I can easily see that $\mathfrak k\cap \mathfrak q$ is the centralizer of $h_0$ in $\mathfrak k$, so this already shows that  $K/K\cap Q$ and $K/Z_K(h_0)$ coincide up to covering.","Let $G$ be a real semisimple Lie group with finite center. Definition 1 A real flag manifold is a homogeneous space $G/Q$ where  $Q$ is a parabolic subgroup of $G$. Definition 2 Let $K$ be a maximal compact subgroup of $G$ and $\mathfrak g=\mathfrak k+\mathfrak p$ the Cartan decomposition. A real flag manifold is an adjoint orbit of $K$ in $\mathfrak p$. Question Do these definitions coincide? Since $K$ acts transitively on $G/Q$, we have $K/K\cap Q=G/Q$. Therefore I guess the problem amounts to showing that $K\cap Q$ is the centralizer in $K$ of a certain element $h_0$ in the Cartan subspace $\mathfrak a \subset\mathfrak p$ which defines $Q$. I can easily see that $\mathfrak k\cap \mathfrak q$ is the centralizer of $h_0$ in $\mathfrak k$, so this already shows that  $K/K\cap Q$ and $K/Z_K(h_0)$ coincide up to covering.",,"['differential-geometry', 'lie-groups', 'homogeneous-spaces']"
86,How do Riemann and Ricci tensors represent curvature?,How do Riemann and Ricci tensors represent curvature?,,"I have started an attempt to self-study Riemannian Geometry. I well understand all the algebraic properties of the Riemann tensor (With a symmetric connection), and how it gradually becomes less and less frightening. However, I'm having trouble converting all the properties of this tensor into an explanation of how it represents curvature, and the same goes for the derived Ricci tensor. This is essentially what I'm aiming for in writing this question. I can decompose this question into a set of concrete questions, but I think it is too ""early"" to ask them with regards to my understanding of the subject. A Reference to relevant material would suffice.","I have started an attempt to self-study Riemannian Geometry. I well understand all the algebraic properties of the Riemann tensor (With a symmetric connection), and how it gradually becomes less and less frightening. However, I'm having trouble converting all the properties of this tensor into an explanation of how it represents curvature, and the same goes for the derived Ricci tensor. This is essentially what I'm aiming for in writing this question. I can decompose this question into a set of concrete questions, but I think it is too ""early"" to ask them with regards to my understanding of the subject. A Reference to relevant material would suffice.",,"['differential-geometry', 'riemannian-geometry', 'tensors', 'curvature']"
87,Top de Rham cohomology,Top de Rham cohomology,,"I just realized that I never really understood why $H_{dR}^n(M, \mathbb{R}) = \mathbb{R}$ if $M$ is compact  and $H_{dR}^n(M, \mathbb{R}) = \{0\}$ if $M$ is not compact (provided that's true?). I'm assuming here (in both cases) that $M$ is a connected orientable smooth $n$-manifold (without boundary). Is there an elementary way to explain this? By ""elementary"", I mean for instance that I'm okay with accepting ""technical lemmas"" such as : A compactly supported $n$-form $\alpha \in \Omega(\mathbb{R}^n)$ is exact iff $\int_{\mathbb{R}^n} \alpha = 0$ but I don't want to hear of singular homology, say.","I just realized that I never really understood why $H_{dR}^n(M, \mathbb{R}) = \mathbb{R}$ if $M$ is compact  and $H_{dR}^n(M, \mathbb{R}) = \{0\}$ if $M$ is not compact (provided that's true?). I'm assuming here (in both cases) that $M$ is a connected orientable smooth $n$-manifold (without boundary). Is there an elementary way to explain this? By ""elementary"", I mean for instance that I'm okay with accepting ""technical lemmas"" such as : A compactly supported $n$-form $\alpha \in \Omega(\mathbb{R}^n)$ is exact iff $\int_{\mathbb{R}^n} \alpha = 0$ but I don't want to hear of singular homology, say.",,"['differential-geometry', 'manifolds', 'homology-cohomology', 'differential-forms']"
88,Geodesics on pseudo-Riemannian manifolds,Geodesics on pseudo-Riemannian manifolds,,"Consider a Riemannian manifold $M$, with a metric $g$. We can find univocally the Levi Civita connection $\nabla$ on $M$, and so a covariant derivative $D_t$ (associated to $\nabla$) along curves. A geodesic is a curve $\gamma$ such that $D_t\gamma'=0$, where $\gamma'$ is the ""velocity vector field of $\gamma$ (along $\gamma$)"". There is also another approach to geodesic that involves the calculus of variation, so one proves that geodesics are  the lenght minimizing curves between two given points. On a pseudo-Riemannian Manifold $N$ with a pseudo-metric $h$, a geodesic can also be a lenght maximizing curve, so what is the physical importance of these kind of geodesics? For example in special relativity, being a geodesic, mean that the curve is crossed with the largest ""proper time"" (i.e. the time measured by a clock co-moving...). It means that a particle follows a geodesic if it has the lowest speed; this is a bit strange and seems to be the opposite of the naive concept of ""straightest path""!","Consider a Riemannian manifold $M$, with a metric $g$. We can find univocally the Levi Civita connection $\nabla$ on $M$, and so a covariant derivative $D_t$ (associated to $\nabla$) along curves. A geodesic is a curve $\gamma$ such that $D_t\gamma'=0$, where $\gamma'$ is the ""velocity vector field of $\gamma$ (along $\gamma$)"". There is also another approach to geodesic that involves the calculus of variation, so one proves that geodesics are  the lenght minimizing curves between two given points. On a pseudo-Riemannian Manifold $N$ with a pseudo-metric $h$, a geodesic can also be a lenght maximizing curve, so what is the physical importance of these kind of geodesics? For example in special relativity, being a geodesic, mean that the curve is crossed with the largest ""proper time"" (i.e. the time measured by a clock co-moving...). It means that a particle follows a geodesic if it has the lowest speed; this is a bit strange and seems to be the opposite of the naive concept of ""straightest path""!",,"['differential-geometry', 'riemannian-geometry', 'geodesic']"
89,Example of charts on $\mathbb{R}$ that are $\mathcal{C}^r$ compatible but not $\mathcal{C}^{r+1}$ compatible.,Example of charts on  that are  compatible but not  compatible.,\mathbb{R} \mathcal{C}^r \mathcal{C}^{r+1},Is there a simple example of two charts where this is the case? I'm struggling to think up one.,Is there a simple example of two charts where this is the case? I'm struggling to think up one.,,"['differential-geometry', 'manifolds', 'examples-counterexamples']"
90,Is $G$ a lie group if left multiplication is smooth and multiplication is smooth near $e$?,Is  a lie group if left multiplication is smooth and multiplication is smooth near ?,G e,"Suppose $G$ is a smooth manifold and also a topological group. Also suppose that left multiplication $L_g : G \rightarrow G$ is smooth for any $g \in G$. Finally suppose that the multiplication map is smooth in a neighborhood of the identity $e$.  By this i mean there exists open $U$ containing $e$ such that $\mu : U \times U \rightarrow M$ is smooth. Can we conclude that $\mu$ makes G into a Lie group (with the given smooth structure)? I know there are some strong theorems we could use here. Like the answer to one of hilbert's problems. I was hoping there was an elementary way to see it. I've tried writing the multiplication map near two different points as a composition of these maps, but I cant get things to work out. Thanks for your time.","Suppose $G$ is a smooth manifold and also a topological group. Also suppose that left multiplication $L_g : G \rightarrow G$ is smooth for any $g \in G$. Finally suppose that the multiplication map is smooth in a neighborhood of the identity $e$.  By this i mean there exists open $U$ containing $e$ such that $\mu : U \times U \rightarrow M$ is smooth. Can we conclude that $\mu$ makes G into a Lie group (with the given smooth structure)? I know there are some strong theorems we could use here. Like the answer to one of hilbert's problems. I was hoping there was an elementary way to see it. I've tried writing the multiplication map near two different points as a composition of these maps, but I cant get things to work out. Thanks for your time.",,"['differential-geometry', 'manifolds', 'lie-groups', 'topological-groups']"
91,What is the commutator of a horizontal and vector field for a connection on a Fiber bundle?,What is the commutator of a horizontal and vector field for a connection on a Fiber bundle?,,"I would be tempted to rephrase my question as : why do people seem to care only about the curvature of a connection on fiber bundles ? Indeed, the curvature gives the vertical part of the commutator of horizontal fields (the horizontal part is the lift of base commutator), while the commutator of vertical fields has nothing to do with the connection. So it remains, for me, aside from the curvature, to understand the commutator of a horizontal and a vertical field. In the case of principal bundles and principal (=invariant) connections, I understand it well, since we can use the action of the group. But what happens then in general for fiber bundles? Doesn't it give information on how the horizontal distribution vary in one fiber ? Thanks, Amin","I would be tempted to rephrase my question as : why do people seem to care only about the curvature of a connection on fiber bundles ? Indeed, the curvature gives the vertical part of the commutator of horizontal fields (the horizontal part is the lift of base commutator), while the commutator of vertical fields has nothing to do with the connection. So it remains, for me, aside from the curvature, to understand the commutator of a horizontal and a vertical field. In the case of principal bundles and principal (=invariant) connections, I understand it well, since we can use the action of the group. But what happens then in general for fiber bundles? Doesn't it give information on how the horizontal distribution vary in one fiber ? Thanks, Amin",,"['differential-geometry', 'curvature', 'fiber-bundles', 'principal-bundles']"
92,Why the connected sum is a differentiable manifold,Why the connected sum is a differentiable manifold,,"maybe this is a stupid question. I know how to prove that the connected sum $M\#N$ of two topological manifolds is a topological manifold, however I don´t know how to prove that the connected sum of two differentiable manifolds is , in fact, differentiable. Thanks in advance.","maybe this is a stupid question. I know how to prove that the connected sum $M\#N$ of two topological manifolds is a topological manifold, however I don´t know how to prove that the connected sum of two differentiable manifolds is , in fact, differentiable. Thanks in advance.",,['differential-geometry']
93,Isotopy preserving inverse image $f_t^{-1}(V)$ of a homotopy,Isotopy preserving inverse image  of a homotopy,f_t^{-1}(V),"During a lecture I was given a bunch of easy propositions entitled as ""observations"" by the lecturer. But one of them seems more difficult and I have absolutely no idea how to ""observe"" it... I'd be grateful for any (possibly online) reference, hint or hopefully a solution. The theorem states as follows: Assumptions: Let $f:(0-\varepsilon,1+\varepsilon)\times M \to N$ be a smooth homotopy between two manifolds $M,N$ . Fix $V$ - a submanifold of $N$ and assume that for all $t$ function $f_t$ is transversal to $V$ . Conclusion: There exists a smooth isotopy $\varphi$ (i.e. $\varphi_t$ is a diffeo $\forall t$ ) starting from $id_M$ such that $\varphi_t(f^{-1}_0(V)) = f_t^{-1}(V)$ . Update: The theorem is easy if $V$ is a point. Then we have that $f_t$ is locally a submersion and we can arrange a vector field $v_t$ (depending on $t$ ) with ""flow"" $\varphi$ such that ${d \over dt}f_t(\varphi_t(x))=0$ . But I don't know if proof in the general case can follow the same scheme. It should  also be ok if $f_t$ is locally a submersion [and $V$ is generic], but there is a problem if ${f_t}_*(x)({d\over dt})\nsubseteq {f_t}_*(x)(T_xM)$ .","During a lecture I was given a bunch of easy propositions entitled as ""observations"" by the lecturer. But one of them seems more difficult and I have absolutely no idea how to ""observe"" it... I'd be grateful for any (possibly online) reference, hint or hopefully a solution. The theorem states as follows: Assumptions: Let be a smooth homotopy between two manifolds . Fix - a submanifold of and assume that for all function is transversal to . Conclusion: There exists a smooth isotopy (i.e. is a diffeo ) starting from such that . Update: The theorem is easy if is a point. Then we have that is locally a submersion and we can arrange a vector field (depending on ) with ""flow"" such that . But I don't know if proof in the general case can follow the same scheme. It should  also be ok if is locally a submersion [and is generic], but there is a problem if .","f:(0-\varepsilon,1+\varepsilon)\times M \to N M,N V N t f_t V \varphi \varphi_t \forall t id_M \varphi_t(f^{-1}_0(V)) = f_t^{-1}(V) V f_t v_t t \varphi {d \over dt}f_t(\varphi_t(x))=0 f_t V {f_t}_*(x)({d\over dt})\nsubseteq {f_t}_*(x)(T_xM)","['reference-request', 'differential-geometry', 'differential-topology', 'manifolds']"
94,Asymptotic behaviour of the riemannian metric in polar coordinates,Asymptotic behaviour of the riemannian metric in polar coordinates,,"I'm studying the section 7 (""Local Geometry in Constant Curvature) of chapter 5 of ""Riemannian Geometry"" written by Petersen. At the beginning there is a Lemma which says how behaves the metric $g$ of a Riemannian manifold $M$ around a point $p$ in normal coordinates: $$ g_{ij} = \delta_{ij} + O(r^2). $$ where $r$ is the distance from $p$. Then the book says in polar coordinates around $p$ any Riemannian metric has the form: $$ g = dr^2 + g_r $$ where $g_r$ is a metric on $S^{n-1}$. We know also that the Euclidean metric looks like: $$ \delta_{ij} = dr^2 + r^2 ds^2_{n-1}, $$ where $ds^2_{n-1}$ is the canonical metric on $S^{n-1}$. Since these two metrics agrees up to the first order (thanks to the Lemma), we have that: $$ \lim_{r \rightarrow 0}g_r = \lim_{r \rightarrow 0}(r^2 ds^2_{n-1}) = 0 $$ and  $$ \lim_{r \rightarrow 0}\Big(\partial_rg_r - \frac{2}{r}g_r\Big) = \lim_{r \rightarrow 0}\Big(\partial_r(r^2 ds^2_{n-1})- \frac{2}{r}(r^2 ds^2_{n-1})\Big) = 0. $$ Everything is quite clear so far. But then the book says that since $$ \partial_rg_r = 2\text{Hess}r$$ then we get  $$ \lim_{r \rightarrow 0}\Big(\text{Hess}r - \frac{1}{r}g_{r}\Big) = 0. $$ I don't understand why $\partial_rg_r = 2\text{Hess}r$. Any help would be really appreciated. Another question: in the next theorem Petersen talks about space forms $S^n_k$. I know that they should be complete Riemannian manifold of dimnsion $n$ and constant sectional curvature $k$, but do you know where does he define them? What is $sn_k$?","I'm studying the section 7 (""Local Geometry in Constant Curvature) of chapter 5 of ""Riemannian Geometry"" written by Petersen. At the beginning there is a Lemma which says how behaves the metric $g$ of a Riemannian manifold $M$ around a point $p$ in normal coordinates: $$ g_{ij} = \delta_{ij} + O(r^2). $$ where $r$ is the distance from $p$. Then the book says in polar coordinates around $p$ any Riemannian metric has the form: $$ g = dr^2 + g_r $$ where $g_r$ is a metric on $S^{n-1}$. We know also that the Euclidean metric looks like: $$ \delta_{ij} = dr^2 + r^2 ds^2_{n-1}, $$ where $ds^2_{n-1}$ is the canonical metric on $S^{n-1}$. Since these two metrics agrees up to the first order (thanks to the Lemma), we have that: $$ \lim_{r \rightarrow 0}g_r = \lim_{r \rightarrow 0}(r^2 ds^2_{n-1}) = 0 $$ and  $$ \lim_{r \rightarrow 0}\Big(\partial_rg_r - \frac{2}{r}g_r\Big) = \lim_{r \rightarrow 0}\Big(\partial_r(r^2 ds^2_{n-1})- \frac{2}{r}(r^2 ds^2_{n-1})\Big) = 0. $$ Everything is quite clear so far. But then the book says that since $$ \partial_rg_r = 2\text{Hess}r$$ then we get  $$ \lim_{r \rightarrow 0}\Big(\text{Hess}r - \frac{1}{r}g_{r}\Big) = 0. $$ I don't understand why $\partial_rg_r = 2\text{Hess}r$. Any help would be really appreciated. Another question: in the next theorem Petersen talks about space forms $S^n_k$. I know that they should be complete Riemannian manifold of dimnsion $n$ and constant sectional curvature $k$, but do you know where does he define them? What is $sn_k$?",,"['riemannian-geometry', 'polar-coordinates', 'curvature']"
95,sheaf of differential forms - tangent sheaf [Hartshorne],sheaf of differential forms - tangent sheaf [Hartshorne],,"I'm reading section 8 Differentials of chapter 2 in Hartshorne. It's is extremely hard to me to understand the nature of the definitions: module of relative differential forms - sheaf of relative differential - tangent sheaf. It's said that ""the sheaf of differential forms is essentially the same as the dual of tangent bundle defined in differential geometry"". I want to understand very explicitly how these constructions come from Diff.Geometry?","I'm reading section 8 Differentials of chapter 2 in Hartshorne. It's is extremely hard to me to understand the nature of the definitions: module of relative differential forms - sheaf of relative differential - tangent sheaf. It's said that ""the sheaf of differential forms is essentially the same as the dual of tangent bundle defined in differential geometry"". I want to understand very explicitly how these constructions come from Diff.Geometry?",,"['algebraic-geometry', 'differential-geometry']"
96,A Simons' type inequality,A Simons' type inequality,,"I have a problem with the inequality (5) in the article 'Estimates for stable minimal surfaces in three dimensional manifolds' of R.Schoen. As the author suggests this inequality comes from 'well known' equations of the article 'Curvature estimates for minimal hypersurfaces' of Schoen-Simom-Yau. I use [S] to denote the first article and [SSY] for the second one. Now i think that the only usefull inequality in [SSY] for proving (5) of [S] is the inequality (1.27) that can be rewritten in the following form: $\Delta |A|^2 \geq 2|\nabla A|^2-c(1+|A|^2)^2 $ where $ c$ depends only on curvatures of $ N$. This inequality holds for every point in $ M $. In [SSY] the authors restict the study on points of $ M $ where the second fundamental form is non vanishing, but for the inequality above this restriction is clearly not necessary. All things made in [SSY] below (1.27) are restricted to $ |A| \neq 0 $, so they are not useful for proving (5) of [S] that it holds globally on $ M $. Thank you","I have a problem with the inequality (5) in the article 'Estimates for stable minimal surfaces in three dimensional manifolds' of R.Schoen. As the author suggests this inequality comes from 'well known' equations of the article 'Curvature estimates for minimal hypersurfaces' of Schoen-Simom-Yau. I use [S] to denote the first article and [SSY] for the second one. Now i think that the only usefull inequality in [SSY] for proving (5) of [S] is the inequality (1.27) that can be rewritten in the following form: $\Delta |A|^2 \geq 2|\nabla A|^2-c(1+|A|^2)^2 $ where $ c$ depends only on curvatures of $ N$. This inequality holds for every point in $ M $. In [SSY] the authors restict the study on points of $ M $ where the second fundamental form is non vanishing, but for the inequality above this restriction is clearly not necessary. All things made in [SSY] below (1.27) are restricted to $ |A| \neq 0 $, so they are not useful for proving (5) of [S] that it holds globally on $ M $. Thank you",,['differential-geometry']
97,De Rham cohomology of $\mathbb R^3$ without lines and a circumference,De Rham cohomology of  without lines and a circumference,\mathbb R^3,"I am trying to calculate De Rham cohomology of the following spaces: $X=\mathbb R^3\setminus r$ where $r$ is a line; $Y=\mathbb R^3\setminus (r \cup \gamma)$ where $r$ is a line and $\gamma$ is a circumference which concatenates the line; $Z=\mathbb R^3\setminus (r_1 \cup r_2 \cup \gamma )$ where $r_1,r_2$ are disjoint lines and $\gamma$ is a circumference which concatenates only $r_1$. Well, about (1) I do not have many doubts: we observe $X$ has $\mathbb R^2 \setminus \{0\}$ as deformation retract hence - by homotopy invariance - we have that $H^{\bullet}(X) \cong H^{\bullet}(\mathbb S^1)$. Is it correct? Now, what about $Y,Z$? I don't know how to start. Are there any ""nice"" deformation retracts? Perhaps, $Y$ retracts on $\mathbb R^2$ minus a point and a circumference, but how can I find the cohomology of this space? The only thing I know are homotopy invariance, Mayer-Vietoris long exact sequence and Kunneth theorem. Thanks in advance.","I am trying to calculate De Rham cohomology of the following spaces: $X=\mathbb R^3\setminus r$ where $r$ is a line; $Y=\mathbb R^3\setminus (r \cup \gamma)$ where $r$ is a line and $\gamma$ is a circumference which concatenates the line; $Z=\mathbb R^3\setminus (r_1 \cup r_2 \cup \gamma )$ where $r_1,r_2$ are disjoint lines and $\gamma$ is a circumference which concatenates only $r_1$. Well, about (1) I do not have many doubts: we observe $X$ has $\mathbb R^2 \setminus \{0\}$ as deformation retract hence - by homotopy invariance - we have that $H^{\bullet}(X) \cong H^{\bullet}(\mathbb S^1)$. Is it correct? Now, what about $Y,Z$? I don't know how to start. Are there any ""nice"" deformation retracts? Perhaps, $Y$ retracts on $\mathbb R^2$ minus a point and a circumference, but how can I find the cohomology of this space? The only thing I know are homotopy invariance, Mayer-Vietoris long exact sequence and Kunneth theorem. Thanks in advance.",,"['differential-geometry', 'homology-cohomology']"
98,Complex vector bundles with real transition functions,Complex vector bundles with real transition functions,,"After doing a bit of playing around (I think) I was able to show that the map $\operatorname{id}\otimes\ \psi : \Omega^{p,q}(X, E) \to \Omega^{p,q}(X, \bar{E})$, where $\psi $ is the conjugation map $E \to \bar{E}$, is well-defined for a complex vector bundle $E$ provided that $E$ has real transition functions. The trivial complex bundle has this property, but are there others? If so, what can we say about them? Added later: Alex has given some examples in the comments below so I am left with the following question. Can we classify complex vector bundles with real transition functions? Classify may be to strong a requirement. What I am after is either a name for this class of bundles or some properties which demonstrate how few there are. Compare this to the constant transition functions scenario in which case the bundles are flat and we can extend the exterior derivative to $\Omega^{\bullet}(X, E)$ by $d\otimes\operatorname{id}_E$.","After doing a bit of playing around (I think) I was able to show that the map $\operatorname{id}\otimes\ \psi : \Omega^{p,q}(X, E) \to \Omega^{p,q}(X, \bar{E})$, where $\psi $ is the conjugation map $E \to \bar{E}$, is well-defined for a complex vector bundle $E$ provided that $E$ has real transition functions. The trivial complex bundle has this property, but are there others? If so, what can we say about them? Added later: Alex has given some examples in the comments below so I am left with the following question. Can we classify complex vector bundles with real transition functions? Classify may be to strong a requirement. What I am after is either a name for this class of bundles or some properties which demonstrate how few there are. Compare this to the constant transition functions scenario in which case the bundles are flat and we can extend the exterior derivative to $\Omega^{\bullet}(X, E)$ by $d\otimes\operatorname{id}_E$.",,"['differential-geometry', 'vector-bundles']"
99,Extension of Riemannian Metric to Higher Forms,Extension of Riemannian Metric to Higher Forms,,"I've been reading about Riemannian manifolds, and have come across a comment that says that for a metric $g$ on an $N$-dimensional manifold $M$, considered as a bilinear map $$ g:\Omega^1(M) \times \Omega^1(M) \to C^{\infty}(M), $$ there exists a canonically induced bilinear map $$ g_k:\Omega^k(M) \times \Omega^k(M) \to C^{\infty}(M), $$ for all $2 \geq k \leq N$. What is this canonically induced $g_k$ defined?","I've been reading about Riemannian manifolds, and have come across a comment that says that for a metric $g$ on an $N$-dimensional manifold $M$, considered as a bilinear map $$ g:\Omega^1(M) \times \Omega^1(M) \to C^{\infty}(M), $$ there exists a canonically induced bilinear map $$ g_k:\Omega^k(M) \times \Omega^k(M) \to C^{\infty}(M), $$ for all $2 \geq k \leq N$. What is this canonically induced $g_k$ defined?",,"['differential-geometry', 'riemannian-geometry', 'multilinear-algebra']"
