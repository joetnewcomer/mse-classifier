,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Evaluate $\int_0^{1/\sqrt{3}}\sqrt{x+\sqrt{x^2+1}}\,dx$",Evaluate,"\int_0^{1/\sqrt{3}}\sqrt{x+\sqrt{x^2+1}}\,dx","I want to find a quick way of evaluating $$\int_0^{1/\sqrt{3}}\sqrt{x+\sqrt{x^2+1}}\,dx$$ This problem appeared on the qualifying round of MIT's 2014 Integration Bee , which leads me to think there should be a shortish way (no more than three minutes by hand) to solve it. Examining the indefinite integral (thanks to WolframAlpha) hasn't particularly helped me: $$\int\sqrt{x+\sqrt{x^2+1}}\,dx=-\frac{2}{3} \left(\sqrt{x^2+1}-2x\right) \sqrt{x+\sqrt{x^2+1}}+C$$ The bounds on the integral hint at trigonometric substitution, but I got nowhere by trying $x=\tan u$. I also noticed that we can transform the integral by multiplying $\dfrac{\sqrt{x^2+1}-x}{\sqrt{x^2+1}-x}$ in the first square root, but there didn't seem to be anything to do after that either.","I want to find a quick way of evaluating $$\int_0^{1/\sqrt{3}}\sqrt{x+\sqrt{x^2+1}}\,dx$$ This problem appeared on the qualifying round of MIT's 2014 Integration Bee , which leads me to think there should be a shortish way (no more than three minutes by hand) to solve it. Examining the indefinite integral (thanks to WolframAlpha) hasn't particularly helped me: $$\int\sqrt{x+\sqrt{x^2+1}}\,dx=-\frac{2}{3} \left(\sqrt{x^2+1}-2x\right) \sqrt{x+\sqrt{x^2+1}}+C$$ The bounds on the integral hint at trigonometric substitution, but I got nowhere by trying $x=\tan u$. I also noticed that we can transform the integral by multiplying $\dfrac{\sqrt{x^2+1}-x}{\sqrt{x^2+1}-x}$ in the first square root, but there didn't seem to be anything to do after that either.",,"['calculus', 'integration', 'definite-integrals']"
1,Why is the area of the circle $πr^2$? [duplicate],Why is the area of the circle ? [duplicate],πr^2,This question already has answers here : Why is $\pi r^2$ the surface of a circle (5 answers) Closed 9 years ago . I searched many times about the cause of the circle area formula but I did not know anything so ... Why is the area of the circle $\pi r^2$? Thanks for all here.,This question already has answers here : Why is $\pi r^2$ the surface of a circle (5 answers) Closed 9 years ago . I searched many times about the cause of the circle area formula but I did not know anything so ... Why is the area of the circle $\pi r^2$? Thanks for all here.,,"['calculus', 'geometry', 'circles', 'area']"
2,How to compute $\int_0^{\pi/2}\frac{\sin^3 t}{\sin^3 t+\cos^3 t}dt$?,How to compute ?,\int_0^{\pi/2}\frac{\sin^3 t}{\sin^3 t+\cos^3 t}dt,"Calculating with Mathematica, one can have $$\int_0^{\pi/2}\frac{\sin^3 t}{\sin^3 t+\cos^3 t}\,\mathrm dt=\frac{\pi}{4}.$$ How can I get this formula by hand? Is there any simpler idea than using $u = \sin t$ ? Is there a simple way to calculate $$ \int_0^{\pi/2}\frac{\sin^n t}{\sin^n t+\cos^n t}\,\mathrm dt $$ for $n>3$ ? Could anyone come up with a reference for this exercise?","Calculating with Mathematica, one can have How can I get this formula by hand? Is there any simpler idea than using ? Is there a simple way to calculate for ? Could anyone come up with a reference for this exercise?","\int_0^{\pi/2}\frac{\sin^3 t}{\sin^3 t+\cos^3 t}\,\mathrm dt=\frac{\pi}{4}. u = \sin t 
\int_0^{\pi/2}\frac{\sin^n t}{\sin^n t+\cos^n t}\,\mathrm dt
 n>3","['calculus', 'integration']"
3,Evaluating $\lim_{x\to 0}\left(\frac{1}{\sin x} - \frac{1}{\tan x}\right)$,Evaluating,\lim_{x\to 0}\left(\frac{1}{\sin x} - \frac{1}{\tan x}\right),How to solve this limit $$ \lim_{x\to 0}\left(\frac{1}{\sin x} - \frac{1}{\tan x}\right) $$ without using L'Hospital's rule?,How to solve this limit $$ \lim_{x\to 0}\left(\frac{1}{\sin x} - \frac{1}{\tan x}\right) $$ without using L'Hospital's rule?,,"['calculus', 'limits', 'limits-without-lhopital']"
4,Find bound for sum of square roots,Find bound for sum of square roots,,"Let $a_1,...,a_n$ be real numbers, such that $a_1+...+a_n=A$. What can we say about $\sqrt{a_1}+...+\sqrt{a_n}$? I would like to bound from above thus sum in terms of $A$.","Let $a_1,...,a_n$ be real numbers, such that $a_1+...+a_n=A$. What can we say about $\sqrt{a_1}+...+\sqrt{a_n}$? I would like to bound from above thus sum in terms of $A$.",,"['calculus', 'combinatorics', 'number-theory', 'approximation']"
5,"Closed form of $\int_0^\infty \frac{1}{\left(a+\cosh x\right)^{1/n}} \, dx$ for $a=0,1$",Closed form of  for,"\int_0^\infty \frac{1}{\left(a+\cosh x\right)^{1/n}} \, dx a=0,1","While I was working on this question by @Vladimir Reshetnikov, I've conjectured the following closed-forms: $$ I_0(n)=\int_0^\infty \frac{1}{\left(\cosh x\right)^{1/n}} \, dx \stackrel{?}{=} \frac{\sqrt{\pi}}{2} \frac{\Gamma\left(\tfrac{1}{2n}\right)}{\Gamma\left(\tfrac{1}{2}+\tfrac{1}{2n}\right)}, $$ for all $n\geq1$ real numbers. In another form: $$ {_2F_1}\left(\begin{array}c\tfrac{1}{2n},\tfrac1n\\1+\tfrac{1}{2n}\end{array}\middle|\,-1\right) \stackrel{?}{=} \frac{\sqrt{\pi}}{n\,2^{1+\frac1n}} \frac{\Gamma\left(\tfrac{1}{2n}\right)}{\Gamma\left(\tfrac{1}{2}+\tfrac{1}{2n}\right)}. $$ Another conjectured closed form is: $$ I_1(n)=\int_0^\infty \frac{1}{\left(1+\cosh x\right)^{1/n}} \, dx \stackrel{?}{=} \frac{\sqrt{\pi}}{2^{1/n}} \frac{\Gamma\left(\tfrac{1}{n}\right)}{\Gamma\left(\tfrac{1}{2}+\tfrac{1}{n}\right)}, $$ for all $n \geq 1$ real numbers. In another form: $$ {_2F_1}\left(\begin{array}c\tfrac1n,\tfrac2n\\1+\tfrac{1}{n}\end{array}\middle|\,-1\right) \stackrel{?}{=} \frac{\sqrt{\pi}}{n\,2^{\frac2n}} \frac{\Gamma\left(\tfrac{1}{n}\right)}{\Gamma\left(\tfrac{1}{2}+\tfrac{1}{n}\right)}. $$ Here $\cosh$ is the hyperbolic cosine function , $\Gamma$ is the gamma function , and ${_2F_1}$ is the hypergeometric function . Questions. $1^{\text{st}}$ question. How can we prove the conjectured closed form for $I_0$ and $I_1$ ? $2^{\text{nd}}$ question. How can we show the equivalent hypergeometric forms? $3^{\text{rd}}$ question. There is a closed form of $I_a(n) = \int_0^\infty \frac{1}{\left(a+\cosh x\right)^{1/n}} \, dx$ for $a\geq0,n\geq1$ real numbers in term of Appell $F_1$ function . Could we get a closed-form just in term of the gamma function?","While I was working on this question by @Vladimir Reshetnikov, I've conjectured the following closed-forms: for all real numbers. In another form: Another conjectured closed form is: for all real numbers. In another form: Here is the hyperbolic cosine function , is the gamma function , and is the hypergeometric function . Questions. question. How can we prove the conjectured closed form for and ? question. How can we show the equivalent hypergeometric forms? question. There is a closed form of for real numbers in term of Appell function . Could we get a closed-form just in term of the gamma function?","
I_0(n)=\int_0^\infty \frac{1}{\left(\cosh x\right)^{1/n}} \, dx \stackrel{?}{=} \frac{\sqrt{\pi}}{2} \frac{\Gamma\left(\tfrac{1}{2n}\right)}{\Gamma\left(\tfrac{1}{2}+\tfrac{1}{2n}\right)},
 n\geq1 
{_2F_1}\left(\begin{array}c\tfrac{1}{2n},\tfrac1n\\1+\tfrac{1}{2n}\end{array}\middle|\,-1\right) \stackrel{?}{=} \frac{\sqrt{\pi}}{n\,2^{1+\frac1n}} \frac{\Gamma\left(\tfrac{1}{2n}\right)}{\Gamma\left(\tfrac{1}{2}+\tfrac{1}{2n}\right)}.
 
I_1(n)=\int_0^\infty \frac{1}{\left(1+\cosh x\right)^{1/n}} \, dx \stackrel{?}{=} \frac{\sqrt{\pi}}{2^{1/n}} \frac{\Gamma\left(\tfrac{1}{n}\right)}{\Gamma\left(\tfrac{1}{2}+\tfrac{1}{n}\right)},
 n \geq 1 
{_2F_1}\left(\begin{array}c\tfrac1n,\tfrac2n\\1+\tfrac{1}{n}\end{array}\middle|\,-1\right) \stackrel{?}{=} \frac{\sqrt{\pi}}{n\,2^{\frac2n}} \frac{\Gamma\left(\tfrac{1}{n}\right)}{\Gamma\left(\tfrac{1}{2}+\tfrac{1}{n}\right)}.
 \cosh \Gamma {_2F_1} 1^{\text{st}} I_0 I_1 2^{\text{nd}} 3^{\text{rd}} I_a(n) = \int_0^\infty \frac{1}{\left(a+\cosh x\right)^{1/n}} \, dx a\geq0,n\geq1 F_1","['calculus', 'integration', 'definite-integrals', 'closed-form', 'hyperbolic-functions']"
6,Proving $|\sin x - \sin y| < |x - y|$,Proving,|\sin x - \sin y| < |x - y|,"From Spivak's Calculus: Prove that $|\sin x - \sin y| < |x - y|$ for all $x \neq y$. Hint: the same statement, with $<$ replaced by $\leq$, is a straightforward consequence of a well-known theorem. Now, I might even be able to prove this somehow (?), but I can't seem to figure out what ""well-known theorem"" the author is alluding to here... any hints?","From Spivak's Calculus: Prove that $|\sin x - \sin y| < |x - y|$ for all $x \neq y$. Hint: the same statement, with $<$ replaced by $\leq$, is a straightforward consequence of a well-known theorem. Now, I might even be able to prove this somehow (?), but I can't seem to figure out what ""well-known theorem"" the author is alluding to here... any hints?",,"['calculus', 'inequality']"
7,Proving the surprising limit: $\lim\limits_{n \to 0} \frac{x^{n}-y^{n}}{n}$ $=$ log$\frac{x}{y}$,Proving the surprising limit:   log,\lim\limits_{n \to 0} \frac{x^{n}-y^{n}}{n} = \frac{x}{y},"A few months ago, while at school, my classmate asked me this curious question: What does $\frac{x^{n}-y^{n}}{n}$ tend to as $n$ tends to $0$? I thought for a few minutes, became impatient, and asked ""What?"" His reply, log$\frac{x}{y}$, was surprising, but his purported 'proof' was more surprising: Consider $\lim\limits_{n \to 0}\,\int_y^x t^{n-1}\, dt$. ""Pushing the limit into the definite integral"", we have $$\int_y^x \lim\limits_{n \to 0}\,t^{n-1}\, dt \implies \int_y^x \frac{1}{t}\, dt \implies \mathsf{log} \frac{x}{y}$$ Leaving the fact that he had the inspiration to pull this integral out of thin air aside, is the limit allowed to pass into the definite integral? We hadn't learned Real Analysis (we were just taking a basic high school, hand-wavy single-variable calculus course), and I remember feeling very uneasy about the sorcery. I still am, hence, this question. I've since thought about approaching it using $\mathsf{L'Hospital}$, but I still feel uneasy, since it involves differentiating with respect to different variables, which is a little bit confusing. I'd also appreciate your help in this regard. If you have a better proof, I'll truly appreciate it.","A few months ago, while at school, my classmate asked me this curious question: What does $\frac{x^{n}-y^{n}}{n}$ tend to as $n$ tends to $0$? I thought for a few minutes, became impatient, and asked ""What?"" His reply, log$\frac{x}{y}$, was surprising, but his purported 'proof' was more surprising: Consider $\lim\limits_{n \to 0}\,\int_y^x t^{n-1}\, dt$. ""Pushing the limit into the definite integral"", we have $$\int_y^x \lim\limits_{n \to 0}\,t^{n-1}\, dt \implies \int_y^x \frac{1}{t}\, dt \implies \mathsf{log} \frac{x}{y}$$ Leaving the fact that he had the inspiration to pull this integral out of thin air aside, is the limit allowed to pass into the definite integral? We hadn't learned Real Analysis (we were just taking a basic high school, hand-wavy single-variable calculus course), and I remember feeling very uneasy about the sorcery. I still am, hence, this question. I've since thought about approaching it using $\mathsf{L'Hospital}$, but I still feel uneasy, since it involves differentiating with respect to different variables, which is a little bit confusing. I'd also appreciate your help in this regard. If you have a better proof, I'll truly appreciate it.",,"['calculus', 'limits', 'definite-integrals', 'limits-without-lhopital']"
8,"Is calculating the summation of derivatives ""mathematically sound""?","Is calculating the summation of derivatives ""mathematically sound""?",,"I have just discovered that if you take the following series: $$1 + x + x^2 + x^3 + x^4 + \cdot \cdot \cdot = \sum_{n = 0}^\infty x^n$$ and replace each term in the series with the derivative of them, you'll get: $$1 + 2x + 3x^2 + 4x^3 + 5x^4$$ Which I think could simplify to this: $$\sum_{n = 0}^\infty \frac {d}{dx}x^n$$ The question about this is: Is it [mathematically] sound to compute a summation of derivatives (or differentials)? I'm asking this because it looks like it is sound in this case because we are adding up all the derivatives of $x^n$ until $x = \infty$. So, is it sound to compute sums of derivatives? Reminders about Question I have seen a question related to this: infinite summation of derivatives of a  convergent function , but it didn't get me to where I am aiming for. I have also seen Calculus Summations and Help with derivative inside a summation , but they don't answer my question.","I have just discovered that if you take the following series: $$1 + x + x^2 + x^3 + x^4 + \cdot \cdot \cdot = \sum_{n = 0}^\infty x^n$$ and replace each term in the series with the derivative of them, you'll get: $$1 + 2x + 3x^2 + 4x^3 + 5x^4$$ Which I think could simplify to this: $$\sum_{n = 0}^\infty \frac {d}{dx}x^n$$ The question about this is: Is it [mathematically] sound to compute a summation of derivatives (or differentials)? I'm asking this because it looks like it is sound in this case because we are adding up all the derivatives of $x^n$ until $x = \infty$. So, is it sound to compute sums of derivatives? Reminders about Question I have seen a question related to this: infinite summation of derivatives of a  convergent function , but it didn't get me to where I am aiming for. I have also seen Calculus Summations and Help with derivative inside a summation , but they don't answer my question.",,"['calculus', 'derivatives', 'summation']"
9,Finding $\lim_{n \to \infty }\sqrt[n]{b^{2^{-n}}-1}$ without L'hopital,Finding  without L'hopital,\lim_{n \to \infty }\sqrt[n]{b^{2^{-n}}-1},"I found the limit $\lim_{n \to \infty }\sqrt[n]{b^{2^{-n}}-1}$ by first defining $f(x)=\sqrt[x]{b^{2^{-x}}-1}$ above $R$ and then finding the limit of $ln(f)$ (to cancel the nth root). This worked (the result is $1/2$), but I ended up having to find the derivative of rather complex functions when I used L'hopital (twice). My worry is that if I have to solve something like this in a test I'll easily make a technical error. I was wondering if there is a simpler way to find this limit? I know most basic techniques of finding limits in $R$ and a bit (Stoltz, Cantor's lemma, ...) about finding limits of sequences. Thank you for your help!","I found the limit $\lim_{n \to \infty }\sqrt[n]{b^{2^{-n}}-1}$ by first defining $f(x)=\sqrt[x]{b^{2^{-x}}-1}$ above $R$ and then finding the limit of $ln(f)$ (to cancel the nth root). This worked (the result is $1/2$), but I ended up having to find the derivative of rather complex functions when I used L'hopital (twice). My worry is that if I have to solve something like this in a test I'll easily make a technical error. I was wondering if there is a simpler way to find this limit? I know most basic techniques of finding limits in $R$ and a bit (Stoltz, Cantor's lemma, ...) about finding limits of sequences. Thank you for your help!",,"['calculus', 'limits', 'limits-without-lhopital']"
10,When is differentiating an equation valid?,When is differentiating an equation valid?,,"I wonder that Is it true to differentiate an equation side by side. Under which conditions can I differentiate both sides. For example, for the simple equality $x=3$, Is ıt valid to differentiate both sides with respect to x. I know that I am missing some basic point but I cant find it. Thanks for your helps.","I wonder that Is it true to differentiate an equation side by side. Under which conditions can I differentiate both sides. For example, for the simple equality $x=3$, Is ıt valid to differentiate both sides with respect to x. I know that I am missing some basic point but I cant find it. Thanks for your helps.",,"['calculus', 'derivatives']"
11,Prove that the sum of convex functions is again convex.,Prove that the sum of convex functions is again convex.,,"I have to prove that the sum of convex functions is again convex.  I know the definition of convex function: $f(tx_1+(1-t)x_2)\leq t f(x_1)+(1-t)f(x_2)$ - this the first convex function, then I have the second one $g(tx_1+(1-t)x_2)\leq t g(x_1)+(1-t)g(x_2)$ What should I do next? Thank you for your help and time.","I have to prove that the sum of convex functions is again convex.  I know the definition of convex function: $f(tx_1+(1-t)x_2)\leq t f(x_1)+(1-t)f(x_2)$ - this the first convex function, then I have the second one $g(tx_1+(1-t)x_2)\leq t g(x_1)+(1-t)g(x_2)$ What should I do next? Thank you for your help and time.",,"['calculus', 'convex-analysis']"
12,How to compute $\int_0^\infty \frac{x^4}{(x^4+ x^2 +1)^3} dx =\frac{\pi}{48\sqrt{3}}$?,How to compute ?,\int_0^\infty \frac{x^4}{(x^4+ x^2 +1)^3} dx =\frac{\pi}{48\sqrt{3}},$$\int_0^\infty \frac{x^4}{(x^4+ x^2 +1)^3} dx =\frac{\pi}{48\sqrt{3}}$$ I have difficulty to evaluating above integrals. First I try the substitution $x^4 =t$ or $x^4 +x^2+1 =t$ but it makes integral worse.  Using Mathematica I found the result $\dfrac{\pi}{48\sqrt{3}}$ I want to know the procedure of evaluating this integral.,$$\int_0^\infty \frac{x^4}{(x^4+ x^2 +1)^3} dx =\frac{\pi}{48\sqrt{3}}$$ I have difficulty to evaluating above integrals. First I try the substitution $x^4 =t$ or $x^4 +x^2+1 =t$ but it makes integral worse.  Using Mathematica I found the result $\dfrac{\pi}{48\sqrt{3}}$ I want to know the procedure of evaluating this integral.,,"['calculus', 'integration', 'definite-integrals', 'improper-integrals', 'closed-form']"
13,Limitations of approximating $\sin(x) = x$,Limitations of approximating,\sin(x) = x,"$$\lim _{x\rightarrow 0}{\frac {\cos \left( x \right) \sin \left( x  \right) -x}{ \left( \sin \left( x \right)  \right) ^{3}}}$$ I know that the real limit is $-2/3$ However, I've noticed that by approximating $\sin(x)$ as $x$ and $\cos(x)$ as $1-(x^2/2)$ I get the following: $(1-(x^2/2))x - x)/ x^3 = (1- (x^2/2) -1 )(1/x^2) = -x^2/(2x^2) = -1/2 $ also if I only partially approximate x like: $(x\cos(x) - x)/(x^3)$  = $(\cos(x)-1)/x^2$ and then use L'hospital's rule to chisel this down I get: (L'hospital) = $-\sin x / 2x $ = (L'hospital) = $-\cos(x) / 2 = -1/2 $ Why does this conflict with doing L'hospital the whole way through without approximating $\sin(x)$ as $x$ ?  Why is approximating $\sin(x)^3$ as $x^3$ wrong? Isn't this always approaching zero?","$$\lim _{x\rightarrow 0}{\frac {\cos \left( x \right) \sin \left( x  \right) -x}{ \left( \sin \left( x \right)  \right) ^{3}}}$$ I know that the real limit is $-2/3$ However, I've noticed that by approximating $\sin(x)$ as $x$ and $\cos(x)$ as $1-(x^2/2)$ I get the following: $(1-(x^2/2))x - x)/ x^3 = (1- (x^2/2) -1 )(1/x^2) = -x^2/(2x^2) = -1/2 $ also if I only partially approximate x like: $(x\cos(x) - x)/(x^3)$  = $(\cos(x)-1)/x^2$ and then use L'hospital's rule to chisel this down I get: (L'hospital) = $-\sin x / 2x $ = (L'hospital) = $-\cos(x) / 2 = -1/2 $ Why does this conflict with doing L'hospital the whole way through without approximating $\sin(x)$ as $x$ ?  Why is approximating $\sin(x)^3$ as $x^3$ wrong? Isn't this always approaching zero?",,"['calculus', 'limits']"
14,Spivak's proof of Inverse Function Theorem,Spivak's proof of Inverse Function Theorem,,"I am having trouble with Spivak's proof of the Inverse Function Theorem in his Calculus on Manifolds: 2-11 Theorem (Inverse Function Theorem) . Suppose that $f: \mathbb{R}^n\to\mathbb{R}^n$ is continuously differentiable in an open set containing $a$, and det $f'(a)\neq 0$. Then there is an open set $V$ containing $a$ and an open set $W$ containing $f(a)$ such that $f:V\to W$ has a continuous inverse $f^{-1}:W\to V$ which is differentiable and for all $y\in W$ satisfies $$(f^{-1})'(y) = [f'(f^{-1}(y))]^{-1}$$ Proof. Let $\lambda$ be the linear transformation $Df(a)$. Then $\lambda$ is non-singular, since det $f'(a)\neq 0$. Now $D(\lambda^{-1}\circ f)(a) = D(\lambda^{-1})(f(a))\circ Df(a) = \lambda^{-1}\circ Df(a)$ is the identity linear transformation. If the theorem is true for $\lambda^{-1}\circ f$, it is clearly true for $f$... How is the theorem true for $f$ if it is true for $\lambda^{-1}\circ f$?","I am having trouble with Spivak's proof of the Inverse Function Theorem in his Calculus on Manifolds: 2-11 Theorem (Inverse Function Theorem) . Suppose that $f: \mathbb{R}^n\to\mathbb{R}^n$ is continuously differentiable in an open set containing $a$, and det $f'(a)\neq 0$. Then there is an open set $V$ containing $a$ and an open set $W$ containing $f(a)$ such that $f:V\to W$ has a continuous inverse $f^{-1}:W\to V$ which is differentiable and for all $y\in W$ satisfies $$(f^{-1})'(y) = [f'(f^{-1}(y))]^{-1}$$ Proof. Let $\lambda$ be the linear transformation $Df(a)$. Then $\lambda$ is non-singular, since det $f'(a)\neq 0$. Now $D(\lambda^{-1}\circ f)(a) = D(\lambda^{-1})(f(a))\circ Df(a) = \lambda^{-1}\circ Df(a)$ is the identity linear transformation. If the theorem is true for $\lambda^{-1}\circ f$, it is clearly true for $f$... How is the theorem true for $f$ if it is true for $\lambda^{-1}\circ f$?",,"['calculus', 'analysis', 'multivariable-calculus', 'manifolds']"
15,"General form for $\sum_{n=1}^{\infty} (-1)^n \left(m n \, \text{arccoth} \, (m n) - 1\right)$",General form for,"\sum_{n=1}^{\infty} (-1)^n \left(m n \, \text{arccoth} \, (m n) - 1\right)","I'm wondering if there is a general form for the following sum: $$\sum_{n=1}^{\infty} (-1)^n \left(m n \, \text{arccoth} \, (m n) - 1\right)$$ for $m \in \mathbb{N}$ I have obtained the following closed-forms for these special cases: Where $G$ is Catalan's constant and $\text{Cl}_2$ is the Clausen function of order 2. $$\sum_{n=1}^{\infty}(-1)^n \left(2n \, \text{arccoth} \, (2n) - 1\right)  = \frac{1}{2} - \frac{2G}{\pi}$$ $$\sum_{n=1}^{\infty} (-1)^{n}\left( 3n \, \text{arccoth} \, (3n)-1\right)  = \frac{1}{2} - \frac{5}{2\pi} \, \text{Cl}_2 \, \left(\frac{\pi}{3}\right) + \frac{1}{4} \ln (3)$$ $$\sum_{n=1}^{\infty} (-1)^n \left(4n \, \text{arccoth} \, (4n) - 1\right) = \frac{1}{2}+ \frac{G}{\pi} - \frac{4}{\pi} \, \text{Cl}_2 \, \left(\frac{\pi}{4}\right) - \frac{1}{4} \ln \left(3- 2\sqrt{2}\right)$$ etc. Given that $G = \text{Cl}_2 \left(\frac{\pi}{2}\right)$ , I am curious to know if the general sum is expressible in terms of the Clausen function. These above sums were determined by using the Mittag-Leffler expansion of $\csc (z)$ , i.e $\csc(z) = \frac{1}{z} + 2z \sum_{n=1}^{\infty} (-1)^n \frac{1}{z^2 - \left(\pi n\right)^2}$ and substituting it into the integral $\int_{0}^{\pi/m} x \csc (x) \, dx$ If one uses the following other method, we can determine the odd and even terms of the sums $$\sum_{n=1}^{\infty} \left( 4n \, \text{arccoth} \, (4n)-1\right) = \frac{1}{2} - \frac{G}{\pi}- \frac{1}{4} \ln (2)$$ $$\sum_{n=1}^{\infty} \left( (4n-2) \, \text{arccoth} \, (4n-2) - 1\right) = \frac{G}{\pi} - \frac{1}{4} \ln (2)$$ $$\sum_{n=1}^{\infty} \left(6n \, \text{arccoth} \, (6n) - 1\right) = \frac{1}{2} - \frac{3}{2\pi} \, \text{Cl}_2 \left( \frac{\pi}{3}\right)$$ $$\sum_{n=1}^{\infty} \left( (6n-3) \, \text{arccoth} \, (6n-3) - 1\right) = \frac{1}{\pi} \, \text{Cl}_2 \, \left(\frac{\pi}{3}\right) - \frac{1}{4} \ln(3)$$ $$\sum_{n=1}^{\infty} \left( 8n \, \text{arccoth} \, (8n) - 1\right) = \frac{1}{2} - \frac{2}{\pi} \, \text{Cl}_2 \, \left(\frac{\pi}{4}\right) - \frac{1}{4} \ln (2-\sqrt{2})$$ $$\sum_{n=1}^{\infty} \left( (8n-4) \, \text{arccoth} \, (8n-4) - 1\right) = \frac{2}{\pi} \, \text{Cl}_2 \, \left(\frac{\pi}{4}\right) - \frac{G}{\pi} - \frac{1}{4} \ln(2+\sqrt{2})$$ EDIT I am now interested in $$\sum_{n=1}^{\infty} \left(m n \, \text{arccoth} \, (m n) - 1\right)$$ for $|m|>1$ as asked here. Here is how I originally proved it for the odd terms: For the first odd term sum, begin with the known result $$2G = \int_{0}^{\frac{\pi}{2}} x \csc (x) \, dx$$ then integrate by parts to get: $$2G = \int_{0}^{\frac{\pi}{2}} \ln \left(\cot (x) + \csc (x) \right) \, dx = \int_{0}^{\frac{\pi}{2}} \ln (\cos (x) + 1) \, dx - \int_{0}^{\frac{\pi}{2}} \ln (\sin (x)) \,dx$$ Then use the well-known result $\int_{0}^{\frac{\pi}{2}} \ln (\sin(x)) \,dx = - \frac{\pi}{2} \ln (2)$ and use the identity $\cos (x) + 1 = 2 \cos^2\left( \frac{x}{2}\right)$ and make the substitution $\frac{x}{2} = u$ . $$\implies 2G - \pi \ln (2) = 4 \int_{0}^{\frac{\pi}{4}} \ln (\cos (u)) \, du$$ Now use the Weierstrass product for $\cos (z)$ , namely $\cos(z) = \prod_{n=1}^{\infty} \left(1-\frac{4z^2}{\pi^2 (2n-1)^2}\right)$ to obtain: $$2G - \pi \ln (2) = 4 \sum_{n=1}^{\infty} \int_{0}^{\frac{\pi}{4}} \ln \left( 1-\frac{4u^2}{\pi^2 (2n-1)^2}\right) \, du$$ After integrating, obtain $\pi \sum_{n=1}^{\infty} \ln \left(1-\frac{1}{4(1-2n)^2}\right) = -\frac{\pi}{2} \ln (2)$ and the result quickly follows. The other odd sums are the same idea. The even sums just comes from combining the two results from the alternating sum and the odd term sum.","I'm wondering if there is a general form for the following sum: for I have obtained the following closed-forms for these special cases: Where is Catalan's constant and is the Clausen function of order 2. etc. Given that , I am curious to know if the general sum is expressible in terms of the Clausen function. These above sums were determined by using the Mittag-Leffler expansion of , i.e and substituting it into the integral If one uses the following other method, we can determine the odd and even terms of the sums EDIT I am now interested in for as asked here. Here is how I originally proved it for the odd terms: For the first odd term sum, begin with the known result then integrate by parts to get: Then use the well-known result and use the identity and make the substitution . Now use the Weierstrass product for , namely to obtain: After integrating, obtain and the result quickly follows. The other odd sums are the same idea. The even sums just comes from combining the two results from the alternating sum and the odd term sum.","\sum_{n=1}^{\infty} (-1)^n \left(m n \, \text{arccoth} \, (m n) - 1\right) m \in \mathbb{N} G \text{Cl}_2 \sum_{n=1}^{\infty}(-1)^n \left(2n \, \text{arccoth} \, (2n) - 1\right)  = \frac{1}{2} - \frac{2G}{\pi} \sum_{n=1}^{\infty} (-1)^{n}\left( 3n \, \text{arccoth} \, (3n)-1\right)  = \frac{1}{2} - \frac{5}{2\pi} \, \text{Cl}_2 \, \left(\frac{\pi}{3}\right) + \frac{1}{4} \ln (3) \sum_{n=1}^{\infty} (-1)^n \left(4n \, \text{arccoth} \, (4n) - 1\right) = \frac{1}{2}+ \frac{G}{\pi} - \frac{4}{\pi} \, \text{Cl}_2 \, \left(\frac{\pi}{4}\right) - \frac{1}{4} \ln \left(3- 2\sqrt{2}\right) G = \text{Cl}_2 \left(\frac{\pi}{2}\right) \csc (z) \csc(z) = \frac{1}{z} + 2z \sum_{n=1}^{\infty} (-1)^n \frac{1}{z^2 - \left(\pi n\right)^2} \int_{0}^{\pi/m} x \csc (x) \, dx \sum_{n=1}^{\infty} \left( 4n \, \text{arccoth} \, (4n)-1\right) = \frac{1}{2} - \frac{G}{\pi}- \frac{1}{4} \ln (2) \sum_{n=1}^{\infty} \left( (4n-2) \, \text{arccoth} \, (4n-2) - 1\right) = \frac{G}{\pi} - \frac{1}{4} \ln (2) \sum_{n=1}^{\infty} \left(6n \, \text{arccoth} \, (6n) - 1\right) = \frac{1}{2} - \frac{3}{2\pi} \, \text{Cl}_2 \left( \frac{\pi}{3}\right) \sum_{n=1}^{\infty} \left( (6n-3) \, \text{arccoth} \, (6n-3) - 1\right) = \frac{1}{\pi} \, \text{Cl}_2 \, \left(\frac{\pi}{3}\right) - \frac{1}{4} \ln(3) \sum_{n=1}^{\infty} \left( 8n \, \text{arccoth} \, (8n) - 1\right) = \frac{1}{2} - \frac{2}{\pi} \, \text{Cl}_2 \, \left(\frac{\pi}{4}\right) - \frac{1}{4} \ln (2-\sqrt{2}) \sum_{n=1}^{\infty} \left( (8n-4) \, \text{arccoth} \, (8n-4) - 1\right) = \frac{2}{\pi} \, \text{Cl}_2 \, \left(\frac{\pi}{4}\right) - \frac{G}{\pi} - \frac{1}{4} \ln(2+\sqrt{2}) \sum_{n=1}^{\infty} \left(m n \, \text{arccoth} \, (m n) - 1\right) |m|>1 2G = \int_{0}^{\frac{\pi}{2}} x \csc (x) \, dx 2G = \int_{0}^{\frac{\pi}{2}} \ln \left(\cot (x) + \csc (x) \right) \, dx = \int_{0}^{\frac{\pi}{2}} \ln (\cos (x) + 1) \, dx - \int_{0}^{\frac{\pi}{2}} \ln (\sin (x)) \,dx \int_{0}^{\frac{\pi}{2}} \ln (\sin(x)) \,dx = - \frac{\pi}{2} \ln (2) \cos (x) + 1 = 2 \cos^2\left( \frac{x}{2}\right) \frac{x}{2} = u \implies 2G - \pi \ln (2) = 4 \int_{0}^{\frac{\pi}{4}} \ln (\cos (u)) \, du \cos (z) \cos(z) = \prod_{n=1}^{\infty} \left(1-\frac{4z^2}{\pi^2 (2n-1)^2}\right) 2G - \pi \ln (2) = 4 \sum_{n=1}^{\infty} \int_{0}^{\frac{\pi}{4}} \ln \left( 1-\frac{4u^2}{\pi^2 (2n-1)^2}\right) \, du \pi \sum_{n=1}^{\infty} \ln \left(1-\frac{1}{4(1-2n)^2}\right) = -\frac{\pi}{2} \ln (2)","['calculus', 'integration', 'sequences-and-series', 'analysis']"
16,Integer part of a sum (floor),Integer part of a sum (floor),,"Let $\left(\, x_{n}\,\right)_{\,n\ \geq\ 1}$ be a sequence defined as follows: $$ x_{1}={1 \over 2014}\quad\mbox{and}\quad x_{n + 1}=x_{n} + x_{n}^{2}\,, \qquad\forall\ n\ \geq\ 1 $$ Compute the integer part of the sum: $$ S=\frac{x_1}{x_2} + \frac{x_2}{x_3} + \cdots +\frac{x_{2014}}{x_{2015}}\,,\qquad \left(\,\mbox{i. e.}\  \left\lfloor\, S\,\right\rfloor\,\right)$$ Any nice idea to approach this? How can one find a formula for $x_{n}$? Thank you!","Let $\left(\, x_{n}\,\right)_{\,n\ \geq\ 1}$ be a sequence defined as follows: $$ x_{1}={1 \over 2014}\quad\mbox{and}\quad x_{n + 1}=x_{n} + x_{n}^{2}\,, \qquad\forall\ n\ \geq\ 1 $$ Compute the integer part of the sum: $$ S=\frac{x_1}{x_2} + \frac{x_2}{x_3} + \cdots +\frac{x_{2014}}{x_{2015}}\,,\qquad \left(\,\mbox{i. e.}\  \left\lfloor\, S\,\right\rfloor\,\right)$$ Any nice idea to approach this? How can one find a formula for $x_{n}$? Thank you!",,['calculus']
17,Cauchy distribution characteristic function,Cauchy distribution characteristic function,,"I know that it's easy to calculate integral $\displaystyle\int_{-\infty}^\infty \frac{e^{itx}}{\pi(1+x^2)} \, dx$ using residue theorem. Is there any other way to calculate this integral (for someone who don't know how to use residue theorem)?","I know that it's easy to calculate integral $\displaystyle\int_{-\infty}^\infty \frac{e^{itx}}{\pi(1+x^2)} \, dx$ using residue theorem. Is there any other way to calculate this integral (for someone who don't know how to use residue theorem)?",,"['calculus', 'integration', 'complex-analysis', 'definite-integrals', 'improper-integrals']"
18,Easy way of memorizing or quickly deriving summation formulas,Easy way of memorizing or quickly deriving summation formulas,,"My math professor recently told us that she wants us to be familiar with summation notation. She says we have to have it mastered because we are starting integration next week. She gave us a bunch of formulas to memorize. I know I can simply memorize the list, but I am wondering if there is a quick intuitive way of deriving them on the fly . It has to be a really quick derivation because all of her test are timed . Otherwise is there an easy way, you guys remember these formulas . $\begin{align} \displaystyle &\sum_{k=1}^n k=\frac{n(n+1)}{2} \\ &\sum_{k=1}^n k^2=\frac{n(n+1)(2n+1)}{6} \\ &\sum_{k=1}^n k^3=\frac{n^2(n+1)^2}{4} \\ &\sum_{k=1}^n k(k+1)=\frac{n(n+1)(n+2)}{3} \\ &\sum_{k=1}^n \frac{1}{k(k+1)}=\frac{n}{n+1} \\ &\sum_{k=1}^n k(k+1)(k+2)=\frac{n(n+1)(n+2)(n+3)}{4} \\ &\sum_{k=1}^n \frac{1}{k(k+1)(k+2)}=\frac{n(n+3)}{4(n+1)(n+2)} \\ &\sum_{k=1}^n (2k-1)=n^2 \end{align}$ Note: Sorry if there is an easy and obvious answer to this question. Most of the students in my class already know these formulas from high school, but I only went up to Algebra 2 and Trig when I was in high school. PS: This is for a calculus class in college.","My math professor recently told us that she wants us to be familiar with summation notation. She says we have to have it mastered because we are starting integration next week. She gave us a bunch of formulas to memorize. I know I can simply memorize the list, but I am wondering if there is a quick intuitive way of deriving them on the fly . It has to be a really quick derivation because all of her test are timed . Otherwise is there an easy way, you guys remember these formulas . $\begin{align} \displaystyle &\sum_{k=1}^n k=\frac{n(n+1)}{2} \\ &\sum_{k=1}^n k^2=\frac{n(n+1)(2n+1)}{6} \\ &\sum_{k=1}^n k^3=\frac{n^2(n+1)^2}{4} \\ &\sum_{k=1}^n k(k+1)=\frac{n(n+1)(n+2)}{3} \\ &\sum_{k=1}^n \frac{1}{k(k+1)}=\frac{n}{n+1} \\ &\sum_{k=1}^n k(k+1)(k+2)=\frac{n(n+1)(n+2)(n+3)}{4} \\ &\sum_{k=1}^n \frac{1}{k(k+1)(k+2)}=\frac{n(n+3)}{4(n+1)(n+2)} \\ &\sum_{k=1}^n (2k-1)=n^2 \end{align}$ Note: Sorry if there is an easy and obvious answer to this question. Most of the students in my class already know these formulas from high school, but I only went up to Algebra 2 and Trig when I was in high school. PS: This is for a calculus class in college.",,"['calculus', 'integration', 'summation', 'mnemonic']"
19,Example of a function that is not twice differentiable,Example of a function that is not twice differentiable,,"Give an example of a function f that is defined in a neighborhood of a s.t. $\lim_{h\to 0}(f(a+h)+f(a-h)-2f(a))/h^2$ exists, but is not twice differentiable. Note: this follows a problem where I prove that the limit above $= f''(a)$ if $f$ is twice differentiable at $a$.","Give an example of a function f that is defined in a neighborhood of a s.t. $\lim_{h\to 0}(f(a+h)+f(a-h)-2f(a))/h^2$ exists, but is not twice differentiable. Note: this follows a problem where I prove that the limit above $= f''(a)$ if $f$ is twice differentiable at $a$.",,['calculus']
20,"How to prove $\int_{0}^{\infty} \frac{(1-x^2) \, \text{sech}^2\left(\frac{\pi x}{2} \right)}{(1+x^2)^2}\, dx = \frac{\zeta(3)}{\pi}$?",How to prove ?,"\int_{0}^{\infty} \frac{(1-x^2) \, \text{sech}^2\left(\frac{\pi x}{2} \right)}{(1+x^2)^2}\, dx = \frac{\zeta(3)}{\pi}","I was recently searching for interesting looking integrals. In my search, I came upon the following result: $$ \int_{0}^{\infty} \frac{(1-x^2) \, \text{sech}^2\left(\frac{\pi x}{2} \right)}{(1+x^2)^2}\, dx = \frac{\zeta(3)}{\pi}$$ and I wanted to try and prove it. Inspired by this answer by Jack D'Aurizio, I took the Weierstrass product for $\cosh(x)$ to obtain $$ \cosh\left(\frac{\pi x}{2} \right) = \prod_{n \ge 1}\left(1 + \frac{x^2}{(2n-1)^2} \right) $$ And by logarithmically differentiating twice we get $$ \frac{\pi^2}{4}\text{sech}^2\left(\frac{\pi x}{2} \right)  = \sum_{n \ge 1} \frac{4(2n-1)^2}{\left(x^2 + (2n-1)^2\right)^2} - \frac{2}{x^2 + (2n-1)^2} $$ Which means we get \begin{align*} \int_{0}^{\infty} \frac{(1-x^2) \, \text{sech}^2\left(\frac{\pi x}{2} \right)}{(1+x^2)^2}\, dx & =\frac{4}{\pi^2}\sum_{n\ge 1} \int_{0}^{\infty}  \frac{(1-x^2)}{(1+x^2)^2}\left( \frac{4(2n-1)^2}{\left(x^2 + (2n-1)^2\right)^2} - \frac{2}{x^2 + (2n-1)^2}\right)\, dx \end{align*} However, after this, I couldn't figure out how to evaluate the resulting integral. Does anyone know how I could continue this method? Or alternatively, does anyone know another way in which the result can be proven? Thank you very much!! Edit: Per jimjim's request, I'll add that I found this integral on the Wikipedia article for $\zeta(3)$ . I believe the reference is to this text where the following formula is given $$ (s-1) \zeta(s) = 2\pi \int_{\mathbb{R}}\frac{\left(\frac{1}{2} + xi \right)^{1-s}}{\left(e^{\pi x} +e^{-\pi x} \right)^2}\, dx $$ which for the case of $s=3$ reduces to the surprisingly concise $$ \int_{\mathbb{R}}\frac{\text{sech}^2(\pi x)}{(1+2xi)^2} \, dx = \frac{\zeta(3)}{\pi} $$ And I presume that one can modify the previous equation to get to the original integral from the question, but it is not apparent to me how this may be done. Edit 2: Random Variable has kindly posted in the comments how to go from $\int_{\mathbb{R}}\frac{\text{sech}^2(\pi x)}{(1+2xi)^2} \, dx$ to $ \int_{0}^{\infty} \frac{(1-x^2) \, \text{sech}^2\left(\frac{\pi x}{2} \right)}{(1+x^2)^2}\, dx$ . Thank you very much!","I was recently searching for interesting looking integrals. In my search, I came upon the following result: and I wanted to try and prove it. Inspired by this answer by Jack D'Aurizio, I took the Weierstrass product for to obtain And by logarithmically differentiating twice we get Which means we get However, after this, I couldn't figure out how to evaluate the resulting integral. Does anyone know how I could continue this method? Or alternatively, does anyone know another way in which the result can be proven? Thank you very much!! Edit: Per jimjim's request, I'll add that I found this integral on the Wikipedia article for . I believe the reference is to this text where the following formula is given which for the case of reduces to the surprisingly concise And I presume that one can modify the previous equation to get to the original integral from the question, but it is not apparent to me how this may be done. Edit 2: Random Variable has kindly posted in the comments how to go from to . Thank you very much!"," \int_{0}^{\infty} \frac{(1-x^2) \, \text{sech}^2\left(\frac{\pi x}{2} \right)}{(1+x^2)^2}\, dx = \frac{\zeta(3)}{\pi} \cosh(x) 
\cosh\left(\frac{\pi x}{2} \right) = \prod_{n \ge 1}\left(1 + \frac{x^2}{(2n-1)^2} \right)
 
\frac{\pi^2}{4}\text{sech}^2\left(\frac{\pi x}{2} \right)  = \sum_{n \ge 1} \frac{4(2n-1)^2}{\left(x^2 + (2n-1)^2\right)^2} - \frac{2}{x^2 + (2n-1)^2}
 \begin{align*}
\int_{0}^{\infty} \frac{(1-x^2) \, \text{sech}^2\left(\frac{\pi x}{2} \right)}{(1+x^2)^2}\, dx & =\frac{4}{\pi^2}\sum_{n\ge 1} \int_{0}^{\infty}  \frac{(1-x^2)}{(1+x^2)^2}\left( \frac{4(2n-1)^2}{\left(x^2 + (2n-1)^2\right)^2} - \frac{2}{x^2 + (2n-1)^2}\right)\, dx
\end{align*} \zeta(3) 
(s-1) \zeta(s) = 2\pi \int_{\mathbb{R}}\frac{\left(\frac{1}{2} + xi \right)^{1-s}}{\left(e^{\pi x} +e^{-\pi x} \right)^2}\, dx
 s=3 
\int_{\mathbb{R}}\frac{\text{sech}^2(\pi x)}{(1+2xi)^2} \, dx = \frac{\zeta(3)}{\pi}
 \int_{\mathbb{R}}\frac{\text{sech}^2(\pi x)}{(1+2xi)^2} \, dx  \int_{0}^{\infty} \frac{(1-x^2) \, \text{sech}^2\left(\frac{\pi x}{2} \right)}{(1+x^2)^2}\, dx","['calculus', 'integration', 'definite-integrals', 'riemann-zeta', 'hyperbolic-functions']"
21,Daunting series of integrals: $\sum_{n=2}^\infty\int_0^{\pi/2}\sqrt{\frac{(1-\sin x)^{n-2}}{(1+\sin x)^{n+2}}}\log(\frac{1-\sin x}{1+\sin x})dx$,Daunting series of integrals:,\sum_{n=2}^\infty\int_0^{\pi/2}\sqrt{\frac{(1-\sin x)^{n-2}}{(1+\sin x)^{n+2}}}\log(\frac{1-\sin x}{1+\sin x})dx,"My coleague showed me the following integral yesterday \begin{equation} I=\sum_{n=2}^{\infty}\int_0^{\pi/2}\sqrt{\frac{(1-\sin x)^{n-2}}{(1+\sin x)^{n+2}}}\log\left(\!\frac{1-\sin x}{1+\sin x}\!\right)\ dx=\frac{5}{4}-\frac{\pi^2}{3}\tag1 \end{equation} He also claimed the following closed-form: \begin{equation} J=\int_{2}^{\infty}\int_0^{\pi/2}\sqrt{\frac{(1-\sin x)^{y-2}}{(1+\sin x)^{y+2}}}\log\left(\!\frac{1-\sin x}{1+\sin x}\!\right)\ dx\ dy=-\frac{4}{3}\tag2 \end{equation} $(1)$ and $(2)$ seem difficult to deal with, but I believe there are some tricks that I can use but I'm not able to spot it yet. Using substitution $x\mapsto\frac\pi2-x$, one gets \begin{equation} I=\sum_{n=2}^{\infty}\int_0^{\pi/2}\sqrt{\frac{(1-\cos x)^{n-2}}{(1+\cos x)^{n+2}}}\log\left(\!\frac{1-\cos x}{1+\cos x}\!\right)\ dx\tag3 \end{equation} and \begin{equation} J=\int_{2}^{\infty}\int_0^{\pi/2}\sqrt{\frac{(1-\cos x)^{y-2}}{(1+\cos x)^{y+2}}}\log\left(\!\frac{1-\cos x}{1+\cos x}\!\right)\ dx\ dy\tag4 \end{equation} but I don't know how to use $(3)$ and $(4)$ to evaluate $(1)$ and $(2)$. I'm quite sure that the main problem here is to evaluate \begin{equation} K=\int_0^{\pi/2}\sqrt{\frac{(1-\sin x)^{n-2}}{(1+\sin x)^{n+2}}}\log\left(\!\frac{1-\sin x}{1+\sin x}\!\right)\ dx \end{equation} How does one prove $(1)$ and $(2)$?","My coleague showed me the following integral yesterday \begin{equation} I=\sum_{n=2}^{\infty}\int_0^{\pi/2}\sqrt{\frac{(1-\sin x)^{n-2}}{(1+\sin x)^{n+2}}}\log\left(\!\frac{1-\sin x}{1+\sin x}\!\right)\ dx=\frac{5}{4}-\frac{\pi^2}{3}\tag1 \end{equation} He also claimed the following closed-form: \begin{equation} J=\int_{2}^{\infty}\int_0^{\pi/2}\sqrt{\frac{(1-\sin x)^{y-2}}{(1+\sin x)^{y+2}}}\log\left(\!\frac{1-\sin x}{1+\sin x}\!\right)\ dx\ dy=-\frac{4}{3}\tag2 \end{equation} $(1)$ and $(2)$ seem difficult to deal with, but I believe there are some tricks that I can use but I'm not able to spot it yet. Using substitution $x\mapsto\frac\pi2-x$, one gets \begin{equation} I=\sum_{n=2}^{\infty}\int_0^{\pi/2}\sqrt{\frac{(1-\cos x)^{n-2}}{(1+\cos x)^{n+2}}}\log\left(\!\frac{1-\cos x}{1+\cos x}\!\right)\ dx\tag3 \end{equation} and \begin{equation} J=\int_{2}^{\infty}\int_0^{\pi/2}\sqrt{\frac{(1-\cos x)^{y-2}}{(1+\cos x)^{y+2}}}\log\left(\!\frac{1-\cos x}{1+\cos x}\!\right)\ dx\ dy\tag4 \end{equation} but I don't know how to use $(3)$ and $(4)$ to evaluate $(1)$ and $(2)$. I'm quite sure that the main problem here is to evaluate \begin{equation} K=\int_0^{\pi/2}\sqrt{\frac{(1-\sin x)^{n-2}}{(1+\sin x)^{n+2}}}\log\left(\!\frac{1-\sin x}{1+\sin x}\!\right)\ dx \end{equation} How does one prove $(1)$ and $(2)$?",,"['calculus', 'integration', 'sequences-and-series', 'multivariable-calculus', 'definite-integrals']"
22,Best way to integrate $ \int_0^\infty \frac{e^{-at} - e^{-bt}}{t} \text{d}t $,Best way to integrate, \int_0^\infty \frac{e^{-at} - e^{-bt}}{t} \text{d}t ,Today I had an exam and I mixed up the integration by parts formula.  The question was to integrate $$ \int\nolimits_0^\infty \frac{e^{-at} - e^{-bt}}{t} \text{d}t $$ I will try solve this again with the right formula when I arrive home. I would appreciate if somebody could tell me the solution so I can double check and maybe give a hint to another way of solving this instead of integration by parts (if possible).,Today I had an exam and I mixed up the integration by parts formula.  The question was to integrate $$ \int\nolimits_0^\infty \frac{e^{-at} - e^{-bt}}{t} \text{d}t $$ I will try solve this again with the right formula when I arrive home. I would appreciate if somebody could tell me the solution so I can double check and maybe give a hint to another way of solving this instead of integration by parts (if possible).,,"['calculus', 'integration']"
23,Prove $\int_0^{\infty}\frac{\ln (x)}{(x^2+1)(x^3+1)}\ dx=-\frac{37}{432}\pi^2$ with real method,Prove  with real method,\int_0^{\infty}\frac{\ln (x)}{(x^2+1)(x^3+1)}\ dx=-\frac{37}{432}\pi^2,"I came across the following integral: $$\large{\int_0^\infty \frac{\ln (x)}{(x^2+1)(x^3+1)}\ dx=-\frac{37}{432}\pi^2}$$ I know it could be solved with resuide method, and I want to know if there are some real methods can sove it? Meanwhile,I remember a similar integral: $$\large{\int_0^\infty \frac{1}{(x^2+1)(x^a+1)}\ dx=\frac{\pi}{4}}$$ And I want to know the following one: $${\color{red}{\large{\int_0^\infty \frac{\ln x}{(x^2+1)(x^a+1)}\ dx = \huge{?}}}}$$ Using the Mathematica I got the follow result. Could you suggest some ideas how to prove this?  Any hints will be appreciated.","I came across the following integral: $$\large{\int_0^\infty \frac{\ln (x)}{(x^2+1)(x^3+1)}\ dx=-\frac{37}{432}\pi^2}$$ I know it could be solved with resuide method, and I want to know if there are some real methods can sove it? Meanwhile,I remember a similar integral: $$\large{\int_0^\infty \frac{1}{(x^2+1)(x^a+1)}\ dx=\frac{\pi}{4}}$$ And I want to know the following one: $${\color{red}{\large{\int_0^\infty \frac{\ln x}{(x^2+1)(x^a+1)}\ dx = \huge{?}}}}$$ Using the Mathematica I got the follow result. Could you suggest some ideas how to prove this?  Any hints will be appreciated.",,"['calculus', 'integration', 'complex-analysis', 'improper-integrals', 'residue-calculus']"
24,If $f(x)f(y)=f(\sqrt{x^2+y^2})$ how to find $f(x)$,If  how to find,f(x)f(y)=f(\sqrt{x^2+y^2}) f(x),"As we know, for the $$f(x)f(y)=f(x+y)$$  $f(x)=\mathrm e^{\alpha x}$ is a solution. What about  $f(x)f(y)=f(\sqrt{x^2+y^2})$?  Does anybody know about the solution of the function equation? I tried to find $f(x)$. See my attempts below to find $f(x)$. $$f(x)=a_0+a_1x+\frac{a_2x^2}{2!}+\frac{a_3x^3}{3!}+\cdots$$ $$f(y)=a_0+a_1y+\frac{a_2y^2}{2!}+\frac{a_3y^3}{3!}+\cdots$$ $$f(x)f(y)=a_0f(y)+a_1f(y)x+\frac{a_2f(y)x^2}{2!}+\frac{a_3f(y)x^3}{3!}+\cdots$$ $$f(\sqrt{x^2+y^2})=a_0+a_1\sqrt{x^2+y^2}+\frac{a_2(x^2+y^2)}{2!}+\frac{a_3(x^2+y^2)^{3/2}}{3!}+\cdots=$$ $$f(\sqrt{x^2+y^2})=a_0+a_1y\sqrt{1+(x/y)^2}+\frac{a_2(x^2+y^2)}{2!}+\frac{a_3y^2(1+(x/y)^2)^{3/2}}{3!}+\cdots=f(x)f(y)=a_0f(y)+a_1f(y)x+\frac{a_2f(y)x^2}{2!}+\frac{a_3f(y)x^3}{3!}+\cdots$$ if we use binom expansion for $(1+(x/y)^2)^{m}$ $$(1+(x/y)^2)^{m}=1+\frac{mx^2}{y^2}+\frac{m(m-1)x^4}{2!y^4}+\frac{m(m-1)(m-2)x^6}{3!y^6}+\cdots$$ Let's put the expansion to the equation $f(\sqrt{x^2+y^2})$ $$ \begin{align} & f(\sqrt{x^2+y^2}) =a_0 + a_1 y \left( 1 + \frac{(1/2)x^2}{y^2} + \frac{(1/2)((1/2)-1)x^4}{2!y^4} \right. \\  \\ & \left. {} + \frac{(1/2)((1/2)-1)((1/2)-2)x^6}{3!y^6} + \cdots\right) + \frac{ a_2 (x^2+y^2)}{2!} \\  \\ &  + \frac{a_3y^2 \left(1+\frac{(3/2)x^2}{y^2}+\frac{(3/2)((3/2)-1)x^4}{2!y^4}+\frac{(3/2)((3/2)-1)((3/2)-2)x^6}{3!y^6}+\cdots\right)}{3!} +\cdots \\  \\ & = a_0f(y)+a_1f(y)x+\frac{a_2f(y)x^2}{2!}+\frac{a_3f(y)x^3}{3!}+\cdots \end{align} $$ If we equal for all $x^n$ terms in both sides we can see $a_{2n-1}=0$, but to find  $a_{2n}$  seems hard for me. Any idea to find $a_{2n}$ Thanks in advice.","As we know, for the $$f(x)f(y)=f(x+y)$$  $f(x)=\mathrm e^{\alpha x}$ is a solution. What about  $f(x)f(y)=f(\sqrt{x^2+y^2})$?  Does anybody know about the solution of the function equation? I tried to find $f(x)$. See my attempts below to find $f(x)$. $$f(x)=a_0+a_1x+\frac{a_2x^2}{2!}+\frac{a_3x^3}{3!}+\cdots$$ $$f(y)=a_0+a_1y+\frac{a_2y^2}{2!}+\frac{a_3y^3}{3!}+\cdots$$ $$f(x)f(y)=a_0f(y)+a_1f(y)x+\frac{a_2f(y)x^2}{2!}+\frac{a_3f(y)x^3}{3!}+\cdots$$ $$f(\sqrt{x^2+y^2})=a_0+a_1\sqrt{x^2+y^2}+\frac{a_2(x^2+y^2)}{2!}+\frac{a_3(x^2+y^2)^{3/2}}{3!}+\cdots=$$ $$f(\sqrt{x^2+y^2})=a_0+a_1y\sqrt{1+(x/y)^2}+\frac{a_2(x^2+y^2)}{2!}+\frac{a_3y^2(1+(x/y)^2)^{3/2}}{3!}+\cdots=f(x)f(y)=a_0f(y)+a_1f(y)x+\frac{a_2f(y)x^2}{2!}+\frac{a_3f(y)x^3}{3!}+\cdots$$ if we use binom expansion for $(1+(x/y)^2)^{m}$ $$(1+(x/y)^2)^{m}=1+\frac{mx^2}{y^2}+\frac{m(m-1)x^4}{2!y^4}+\frac{m(m-1)(m-2)x^6}{3!y^6}+\cdots$$ Let's put the expansion to the equation $f(\sqrt{x^2+y^2})$ $$ \begin{align} & f(\sqrt{x^2+y^2}) =a_0 + a_1 y \left( 1 + \frac{(1/2)x^2}{y^2} + \frac{(1/2)((1/2)-1)x^4}{2!y^4} \right. \\  \\ & \left. {} + \frac{(1/2)((1/2)-1)((1/2)-2)x^6}{3!y^6} + \cdots\right) + \frac{ a_2 (x^2+y^2)}{2!} \\  \\ &  + \frac{a_3y^2 \left(1+\frac{(3/2)x^2}{y^2}+\frac{(3/2)((3/2)-1)x^4}{2!y^4}+\frac{(3/2)((3/2)-1)((3/2)-2)x^6}{3!y^6}+\cdots\right)}{3!} +\cdots \\  \\ & = a_0f(y)+a_1f(y)x+\frac{a_2f(y)x^2}{2!}+\frac{a_3f(y)x^3}{3!}+\cdots \end{align} $$ If we equal for all $x^n$ terms in both sides we can see $a_{2n-1}=0$, but to find  $a_{2n}$  seems hard for me. Any idea to find $a_{2n}$ Thanks in advice.",,"['calculus', 'functions']"
25,"Is ""locally linear"" an appropriate description of a differentiable function?","Is ""locally linear"" an appropriate description of a differentiable function?",,"In this answer on meta , Pete L. Clark said: I think the question concerns the idea that a differentiable curve becomes more and more like a straight line segment the closer one zooms in on its graph. (And I must say that I regard part of this confusion as an artifact of badly written recent calculus books who describe this phenomenon as ""local linearity"". Ugh!) So, what's wrong with calling it ""local linearity""?  (Examples of the specific language from some relatively recent books follow.) From Finney, Demana, Waits, and Kennedy's Calculus: Graphical, Numerical, Algebraic , 1st ed, p107: A good way to think of differentiable functions is that they are locally linear; that is, a function that is differentiable at a closely resembles its own tangent line very close to a . From Hughes-Hallett, Gleason, et al's Calculus: Single Variable , 2nd ed, pp138-9: When we zoom in on the graph of a differentiable function, it looks like a straight line.  In fact, the graph is not exactly a straight line when we zoom in; however, its deviation from straightness is so small that it can't be detected by the naked eye. Following that, there is discussion of the tangent line approximation, then a theorem titled ""Differentiability and Local Linearity"" (the first time ""local linearity""/""locally linear"" appears) stating that if a function f is differentiable at a , then the limit as x goes to a of the quotient of the error in the tangent line approximation and the difference between x and a goes to 0. Ostebee and Zorn's Calculus from Graphical, Numerical, and Symbolic Points of View , 1st ed, p110: Remarkably, the just-illustrated strategy of zooming in to estimate slope almost always works.  Zooming in on the graph of almost any calculus function $f$, at almost any point $(a,f(a))$, eventually produces what looks like a straight line with slope $f'(a)$.  A function with this property is sometimes called locally linear (or locally straight ) at $x=a$. [Margin note: These aren't formal definitions, just descriptive phrases. ]  Local linearity says, in effect, that $f$ ""looks like a line"" near $x=a$ and therefore has a well-defined slope at $x=a$. (I did not find the term ""local linearity"" or ""locally linear"" at a quick glance in Stewart's Calculus: Concepts and Contexts , 2nd ed, or Leithold's The Calculus 7 ; the rest of the calculus books I have on hand predate the inclusion of graphing calculators/software in textbooks, so are not suitable for comparison.)","In this answer on meta , Pete L. Clark said: I think the question concerns the idea that a differentiable curve becomes more and more like a straight line segment the closer one zooms in on its graph. (And I must say that I regard part of this confusion as an artifact of badly written recent calculus books who describe this phenomenon as ""local linearity"". Ugh!) So, what's wrong with calling it ""local linearity""?  (Examples of the specific language from some relatively recent books follow.) From Finney, Demana, Waits, and Kennedy's Calculus: Graphical, Numerical, Algebraic , 1st ed, p107: A good way to think of differentiable functions is that they are locally linear; that is, a function that is differentiable at a closely resembles its own tangent line very close to a . From Hughes-Hallett, Gleason, et al's Calculus: Single Variable , 2nd ed, pp138-9: When we zoom in on the graph of a differentiable function, it looks like a straight line.  In fact, the graph is not exactly a straight line when we zoom in; however, its deviation from straightness is so small that it can't be detected by the naked eye. Following that, there is discussion of the tangent line approximation, then a theorem titled ""Differentiability and Local Linearity"" (the first time ""local linearity""/""locally linear"" appears) stating that if a function f is differentiable at a , then the limit as x goes to a of the quotient of the error in the tangent line approximation and the difference between x and a goes to 0. Ostebee and Zorn's Calculus from Graphical, Numerical, and Symbolic Points of View , 1st ed, p110: Remarkably, the just-illustrated strategy of zooming in to estimate slope almost always works.  Zooming in on the graph of almost any calculus function $f$, at almost any point $(a,f(a))$, eventually produces what looks like a straight line with slope $f'(a)$.  A function with this property is sometimes called locally linear (or locally straight ) at $x=a$. [Margin note: These aren't formal definitions, just descriptive phrases. ]  Local linearity says, in effect, that $f$ ""looks like a line"" near $x=a$ and therefore has a well-defined slope at $x=a$. (I did not find the term ""local linearity"" or ""locally linear"" at a quick glance in Stewart's Calculus: Concepts and Contexts , 2nd ed, or Leithold's The Calculus 7 ; the rest of the calculus books I have on hand predate the inclusion of graphing calculators/software in textbooks, so are not suitable for comparison.)",,"['calculus', 'education']"
26,Intuition for the derivative of the exponential function,Intuition for the derivative of the exponential function,,"1. THE PROBLEM Take the definition of the derivative: $$\frac{d}{dx}f(x)=\lim_{h\to 0}\frac{f(x+h)-f(x)}{h}$$ Using this definition to calculate the derivative of $e^x$ is not the most trivial thing to do, as one ends up with: $$\frac{d}{dx}e^x=e^x\lim_{h\to 0}\frac{e^h-1}{h}$$ We can finish this off by a change of variables $n=\frac1h$ . $$e^x\lim_{h\to 0}\frac{e^h-1}{h}=e^x\lim_{n\to\infty}n(e^{1/n}-1)=e^x\cdot\ln e=e^x$$ Note: the second to last equality holds because of a limit definition of the natural logarithm: $\ln x=\lim_{n\to\infty}n(x^{1/n}-1)$ . As we see, calculating the derivative of the exponential function is not easy with the usual limit definition of the derivative. It requires calculating a limit that is not obvious without knowing a special limit definition of $\ln x$ . One can wonder then, are there easier ways of proving that $\frac{d}{dx}e^x=e^x$ ? Indeed, there are easier ways to prove this. But all of the proofs I have ever seen either assume a taylor series or limit definition of the exponential function, or somehow use the derivative of $\ln x$ which itself has similar calculation problems. Finally, the proofs lack deep motivated intuition, and are raw algebraic manipulations for the most part. They prove things well, but they don't explain things well. Question: is there a way to find the derivative of the exponential function intuitively? 2. POSSIBLE SOLUTIONS I didn't ask this question without giving it a little thought. Path A I figured that one solution to this problem might be by intuituvely explaining how in the world $\ln x$ is equal to $\lim_{n\to\infty}n(x^{1/n}-1)$ . Euler observed, quite unrigorously, that if $\epsilon$ is an arbitrarily small number, then: $$\ln(1+\epsilon)=\epsilon$$ Similarly, if we let $n$ be an arbitrarily large number, we can observe that: $$x^{1/n}-1=\epsilon$$ Plugging this observation into the first one, we have: $$\ln(x^{1/n})=x^{1/n}-1$$ $$\frac1n\ln x=x^{1/n}-1$$ $$\ln x=n(x^{1/n}-1)$$ Thus: $$\ln x=\lim_{n\to\infty}n(x^{1/n}-1)$$ This would almost work as a solution, except for the fact that here we make observations that work for logarithms of all bases. The observation $\log_b(1+\epsilon)=\epsilon$ is valid for all bases $b$ . The second observation we made doesn't even relate specifically to logarithms. Thus, the ""intuition"" in this case assumes that the limit can be equal to a logarithm of any base. This is obviously false; computations evidently show that this limit holds only for $b=e$ . And it is not evident at all why it has to be $e$ and nothing else. This solution will be complete if it can be shown why base $e$ and none other work. Path B Another solution to this problem would be noting that the exponential function grows proportionally to its size. The problem with this intuition is that it is not at all evident why would this function follow such a behavior. The mystery is, how does one start with simple algebraic properties of exponents, which are trivially defined by multiplication, and arrive the conclusion that this function follows its unique growth behavior. It might help to note that exponentiation turns an arithmetic sequence into a geometric sequence. Id est , if: $$\alpha_n=a+\sum^n_1 d$$ $$\gamma_n=b\prod^n_1 r$$ Then: $$e^{\alpha_n}=e^{a+\sum^n_1 d}=e^a\prod^n_1 e^d=b\prod^n_1 r=\gamma_n$$ If there is a way to start with basic algebraic facts about exponents and end up (intuitively) with the fact that exponential growth is proportional to its size, we could then justify the fact that $e^x$ is the solution of $y'=y$ , $y(0)=1$ . From there, we could automatically say that the derivative of the natural exponential is itself. Caveat: While solving this ODE, there is still a problem because we need to compute the integral of $\frac1x$ . It turns out that we can intuitively solve this task. We can begin by splitting the area under the curve into n rectangles of equal area $A$ , situated between corresponding x coordinates: $\{x_0, x_1, ..., x_n\}$ . We will then note that: $$A=y_0(x_1-x_0)=y_1(x_2-x_1)$$ $$\frac{x_1-x_0}{x_0}=\frac{x_2-x_1}{x_1}$$ $$\frac{x_1}{x_0}-1=\frac{x_2}{x_1}-1$$ $$\frac{x_1}{x_0}=\frac{x_2}{x_1}$$ This will generalize to $\frac{x_n}{x_{n-1}}=\frac{x_{n+1}}{x_n}$ . What this means is that, if rectangles are the same area , if we increase the x coordinates geometrically (because the ratio between next and current x coordinate is constant), we increase the area arithmetically. This is precisely what logarithms do, they turn geometric sequences into arithmetic sequences (opposite of the exponentials). Thus, the integral of $\frac1x$ will be some kind of logarithm. The missing bit here, again, is...why is it base e , and not some another base? Other paths Those two paths are most likely not the only approaches. 3. MOTIVATION At this point, I overstressed the word ""intuition"", and I just wanted to explain myself. I just really love to explore things that are proven symbolically, in a natural way. I might be considered weird for trying to do that so deeply for such a simple derivative, but oh well. Thank you in advance for any good insights into this problem.","1. THE PROBLEM Take the definition of the derivative: Using this definition to calculate the derivative of is not the most trivial thing to do, as one ends up with: We can finish this off by a change of variables . Note: the second to last equality holds because of a limit definition of the natural logarithm: . As we see, calculating the derivative of the exponential function is not easy with the usual limit definition of the derivative. It requires calculating a limit that is not obvious without knowing a special limit definition of . One can wonder then, are there easier ways of proving that ? Indeed, there are easier ways to prove this. But all of the proofs I have ever seen either assume a taylor series or limit definition of the exponential function, or somehow use the derivative of which itself has similar calculation problems. Finally, the proofs lack deep motivated intuition, and are raw algebraic manipulations for the most part. They prove things well, but they don't explain things well. Question: is there a way to find the derivative of the exponential function intuitively? 2. POSSIBLE SOLUTIONS I didn't ask this question without giving it a little thought. Path A I figured that one solution to this problem might be by intuituvely explaining how in the world is equal to . Euler observed, quite unrigorously, that if is an arbitrarily small number, then: Similarly, if we let be an arbitrarily large number, we can observe that: Plugging this observation into the first one, we have: Thus: This would almost work as a solution, except for the fact that here we make observations that work for logarithms of all bases. The observation is valid for all bases . The second observation we made doesn't even relate specifically to logarithms. Thus, the ""intuition"" in this case assumes that the limit can be equal to a logarithm of any base. This is obviously false; computations evidently show that this limit holds only for . And it is not evident at all why it has to be and nothing else. This solution will be complete if it can be shown why base and none other work. Path B Another solution to this problem would be noting that the exponential function grows proportionally to its size. The problem with this intuition is that it is not at all evident why would this function follow such a behavior. The mystery is, how does one start with simple algebraic properties of exponents, which are trivially defined by multiplication, and arrive the conclusion that this function follows its unique growth behavior. It might help to note that exponentiation turns an arithmetic sequence into a geometric sequence. Id est , if: Then: If there is a way to start with basic algebraic facts about exponents and end up (intuitively) with the fact that exponential growth is proportional to its size, we could then justify the fact that is the solution of , . From there, we could automatically say that the derivative of the natural exponential is itself. Caveat: While solving this ODE, there is still a problem because we need to compute the integral of . It turns out that we can intuitively solve this task. We can begin by splitting the area under the curve into n rectangles of equal area , situated between corresponding x coordinates: . We will then note that: This will generalize to . What this means is that, if rectangles are the same area , if we increase the x coordinates geometrically (because the ratio between next and current x coordinate is constant), we increase the area arithmetically. This is precisely what logarithms do, they turn geometric sequences into arithmetic sequences (opposite of the exponentials). Thus, the integral of will be some kind of logarithm. The missing bit here, again, is...why is it base e , and not some another base? Other paths Those two paths are most likely not the only approaches. 3. MOTIVATION At this point, I overstressed the word ""intuition"", and I just wanted to explain myself. I just really love to explore things that are proven symbolically, in a natural way. I might be considered weird for trying to do that so deeply for such a simple derivative, but oh well. Thank you in advance for any good insights into this problem.","\frac{d}{dx}f(x)=\lim_{h\to 0}\frac{f(x+h)-f(x)}{h} e^x \frac{d}{dx}e^x=e^x\lim_{h\to 0}\frac{e^h-1}{h} n=\frac1h e^x\lim_{h\to 0}\frac{e^h-1}{h}=e^x\lim_{n\to\infty}n(e^{1/n}-1)=e^x\cdot\ln e=e^x \ln x=\lim_{n\to\infty}n(x^{1/n}-1) \ln x \frac{d}{dx}e^x=e^x \ln x \ln x \lim_{n\to\infty}n(x^{1/n}-1) \epsilon \ln(1+\epsilon)=\epsilon n x^{1/n}-1=\epsilon \ln(x^{1/n})=x^{1/n}-1 \frac1n\ln x=x^{1/n}-1 \ln x=n(x^{1/n}-1) \ln x=\lim_{n\to\infty}n(x^{1/n}-1) \log_b(1+\epsilon)=\epsilon b b=e e e \alpha_n=a+\sum^n_1 d \gamma_n=b\prod^n_1 r e^{\alpha_n}=e^{a+\sum^n_1 d}=e^a\prod^n_1 e^d=b\prod^n_1 r=\gamma_n e^x y'=y y(0)=1 \frac1x A \{x_0, x_1, ..., x_n\} A=y_0(x_1-x_0)=y_1(x_2-x_1) \frac{x_1-x_0}{x_0}=\frac{x_2-x_1}{x_1} \frac{x_1}{x_0}-1=\frac{x_2}{x_1}-1 \frac{x_1}{x_0}=\frac{x_2}{x_1} \frac{x_n}{x_{n-1}}=\frac{x_{n+1}}{x_n} \frac1x","['calculus', 'derivatives', 'exponential-function', 'intuition']"
27,"Closed form for ${\large\int}_0^\infty\frac{x\,\sqrt{e^x-1}}{1-2\cosh x}\,dx$",Closed form for,"{\large\int}_0^\infty\frac{x\,\sqrt{e^x-1}}{1-2\cosh x}\,dx","I was able to calculate $$\int_0^\infty\frac{\sqrt{e^x-1}}{1-2\cosh x}\,dx=-\frac\pi{\sqrt3}.$$ It turns out the integrand even has an elementary antiderivative ( see here ). Now I'm interested in a similar integral $$I=\int_0^\infty\frac{x\,\sqrt{e^x-1}}{1-2\cosh x}\,dx.$$ Numerically, it is $$I\approx4.0336314630136915863337257797951491097354689684433117747419802...$$ Is it possible to find a closed form for this integral?","I was able to calculate $$\int_0^\infty\frac{\sqrt{e^x-1}}{1-2\cosh x}\,dx=-\frac\pi{\sqrt3}.$$ It turns out the integrand even has an elementary antiderivative ( see here ). Now I'm interested in a similar integral $$I=\int_0^\infty\frac{x\,\sqrt{e^x-1}}{1-2\cosh x}\,dx.$$ Numerically, it is $$I\approx4.0336314630136915863337257797951491097354689684433117747419802...$$ Is it possible to find a closed form for this integral?",,"['calculus', 'integration', 'definite-integrals', 'closed-form', 'hyperbolic-functions']"
28,Infinite limits,Infinite limits,,"Does a limit that has the value of infinite exist or not? I've recently come across certain sources that say that if the value of a limit is infinite, then that limit does not exist. This contradicts what my calculus teachers and lecturers taught me however, that a limit doesn't exist if the right hand limit and left hand limit differ. So which one is it?","Does a limit that has the value of infinite exist or not? I've recently come across certain sources that say that if the value of a limit is infinite, then that limit does not exist. This contradicts what my calculus teachers and lecturers taught me however, that a limit doesn't exist if the right hand limit and left hand limit differ. So which one is it?",,"['calculus', 'definition', 'limits']"
29,Maximum value of a function. I am not able to check double derivative.,Maximum value of a function. I am not able to check double derivative.,,"Can someone explain me how $\sin^p x \cos^q x$ attains maximum at $\tan^2 x = \frac pq$. I am not able to check whether double derivative is positive or negative. Question Show that $$\sin^p\theta\cos^q\theta$$ attains a maximum when $$\theta=\tan^{-1}\sqrt{(p/q)}$$ Solution Ley $y=\sin^p\theta\cos^q\theta$. For a maximum or minimum of $y$, we have $\frac{\text dy}{\text dx}=0$ \begin{align}p\sin^{p-1}\theta\cos^{q+1}\theta-q\sin^{p+1}\theta\cos^{q-1}\theta&=0\\ \sin^{p-1}\theta\cos^{q-1}\theta(p\cos^2\theta-q\sin^2\theta)&=0\end{align} Therefore \begin{align}\sin\theta&=0\\ &\Downarrow\\ \theta&=0\\ \text{or } \cos\theta&=0\\ &\Downarrow\\ \theta&=\frac \pi 2\\ \text{or }\tan^2\theta&=\frac pq\\ &\Downarrow\\ \theta&=\tan^{-1}\sqrt{p/q}\end{align} Now $y=0$ at $\theta=0$ and also at $\theta=\frac\pi2$ When $0<\theta<\frac\pi2$, $y$ is positive Also, $\tan^{-1}\sqrt{p/q}$ is the only value of $\theta$ lying between $0$ and $\frac \pi2$ at which $\frac{\text d}{\text dx}=0$. Hence $y$ is maximum when $$\theta=\tan^{-1}\sqrt{p/q}$$ This can be seen from the graph of $y$","Can someone explain me how $\sin^p x \cos^q x$ attains maximum at $\tan^2 x = \frac pq$. I am not able to check whether double derivative is positive or negative. Question Show that $$\sin^p\theta\cos^q\theta$$ attains a maximum when $$\theta=\tan^{-1}\sqrt{(p/q)}$$ Solution Ley $y=\sin^p\theta\cos^q\theta$. For a maximum or minimum of $y$, we have $\frac{\text dy}{\text dx}=0$ \begin{align}p\sin^{p-1}\theta\cos^{q+1}\theta-q\sin^{p+1}\theta\cos^{q-1}\theta&=0\\ \sin^{p-1}\theta\cos^{q-1}\theta(p\cos^2\theta-q\sin^2\theta)&=0\end{align} Therefore \begin{align}\sin\theta&=0\\ &\Downarrow\\ \theta&=0\\ \text{or } \cos\theta&=0\\ &\Downarrow\\ \theta&=\frac \pi 2\\ \text{or }\tan^2\theta&=\frac pq\\ &\Downarrow\\ \theta&=\tan^{-1}\sqrt{p/q}\end{align} Now $y=0$ at $\theta=0$ and also at $\theta=\frac\pi2$ When $0<\theta<\frac\pi2$, $y$ is positive Also, $\tan^{-1}\sqrt{p/q}$ is the only value of $\theta$ lying between $0$ and $\frac \pi2$ at which $\frac{\text d}{\text dx}=0$. Hence $y$ is maximum when $$\theta=\tan^{-1}\sqrt{p/q}$$ This can be seen from the graph of $y$",,"['calculus', 'maxima-minima']"
30,Can't understand Second Fundamental Theorem of Calculus,Can't understand Second Fundamental Theorem of Calculus,,"sorry if this has been asked before, but I can't seem to find my question in particular. Anyway, in the Second FTM it says $$F(x)=\int_a^xf(x)dx$$ If I understand correctly is just the area under the curve. no problem there. Then it says that$$\int_a^bf(x)dx=F(b)-F(a)$$ if I'm thinking this correctly, it would make sense because in  $F(a)=\int_a^af(x)dx$  the area is $0$ so I'm just left with $F(b)$ which is the integral from a to b, this is where I think I have to be wrong, because in every example I see, they take the value of $a$ and plug it in $F(x)$. For example in $$\int_2^5x^2dx$$ with $F(x)=x^3/3$  they take $F(5)$ and $F(2)$, in particular $F(2)=2^3/3$, but shouldn't $F(2)$ always be $0$ because it's basically just $\int_2^2x^2dx$? p.s Sorry in advance for any mistake I made in formating or anything else.","sorry if this has been asked before, but I can't seem to find my question in particular. Anyway, in the Second FTM it says $$F(x)=\int_a^xf(x)dx$$ If I understand correctly is just the area under the curve. no problem there. Then it says that$$\int_a^bf(x)dx=F(b)-F(a)$$ if I'm thinking this correctly, it would make sense because in  $F(a)=\int_a^af(x)dx$  the area is $0$ so I'm just left with $F(b)$ which is the integral from a to b, this is where I think I have to be wrong, because in every example I see, they take the value of $a$ and plug it in $F(x)$. For example in $$\int_2^5x^2dx$$ with $F(x)=x^3/3$  they take $F(5)$ and $F(2)$, in particular $F(2)=2^3/3$, but shouldn't $F(2)$ always be $0$ because it's basically just $\int_2^2x^2dx$? p.s Sorry in advance for any mistake I made in formating or anything else.",,"['calculus', 'integration']"
31,Proving $\sum_{n=1}^{\infty }\frac{\cos(n)}{n^4}=\frac{\pi ^4}{90}-\frac{\pi ^2}{12}+\frac{\pi }{12}-\frac{1}{48}$,Proving,\sum_{n=1}^{\infty }\frac{\cos(n)}{n^4}=\frac{\pi ^4}{90}-\frac{\pi ^2}{12}+\frac{\pi }{12}-\frac{1}{48},Proving $$\sum_{n=1}^{\infty }\frac{\cos(n)}{n^4}=\frac{\pi ^4}{90}-\frac{\pi ^2}{12}+\frac{\pi }{12}-\frac{1}{48}$$ I tried with Wolfram but it couldn't give me any clear value as shown below The numerical value of Wolfram not different of my closed-form. Can anyone explain how the $.5(Li_4(e^{-i}+Li_4(e^{i}))$ equal the above closed-form,Proving $$\sum_{n=1}^{\infty }\frac{\cos(n)}{n^4}=\frac{\pi ^4}{90}-\frac{\pi ^2}{12}+\frac{\pi }{12}-\frac{1}{48}$$ I tried with Wolfram but it couldn't give me any clear value as shown below The numerical value of Wolfram not different of my closed-form. Can anyone explain how the $.5(Li_4(e^{-i}+Li_4(e^{i}))$ equal the above closed-form,,"['calculus', 'sequences-and-series']"
32,A curious limit for $-\frac{\pi}{2}$,A curious limit for,-\frac{\pi}{2},How to prove this ? $$-\frac\pi2 = \lim_{x\to\infty}\sum_{n=1}^{\infty}(-1)^n \frac{x^{2n-1}}{(2n)! \ln 2n}$$,How to prove this ? $$-\frac\pi2 = \lim_{x\to\infty}\sum_{n=1}^{\infty}(-1)^n \frac{x^{2n-1}}{(2n)! \ln 2n}$$,,"['calculus', 'pi']"
33,Limit of integration can't be the same as variable of integration?,Limit of integration can't be the same as variable of integration?,,"I am told that an expression like $$ \int_a^x f(x)dx $$ is not well formed, i.e. it should be $$ \int_a^xf(t)dt $$ or similar. Why is it that the limits of integration can't depend on the variable of integration?","I am told that an expression like $$ \int_a^x f(x)dx $$ is not well formed, i.e. it should be $$ \int_a^xf(t)dt $$ or similar. Why is it that the limits of integration can't depend on the variable of integration?",,"['calculus', 'notation']"
34,Puiseux Series?,Puiseux Series?,,WolframAlpha says that $$\sqrt{x^2-1}$$ expanded in Puiseux series near 1 is $\sqrt 2 \sqrt{x-1}$ . I don't know what a Puiseux series is; I have searched on the net but I haven't understood much... can you briefly explain it to me and how I can obtain this result?,WolframAlpha says that expanded in Puiseux series near 1 is . I don't know what a Puiseux series is; I have searched on the net but I haven't understood much... can you briefly explain it to me and how I can obtain this result?,\sqrt{x^2-1} \sqrt 2 \sqrt{x-1},"['calculus', 'derivatives', 'power-series']"
35,Derivative of ${x^{x^2}}$,Derivative of,{x^{x^2}},"Studying past exam problems for my exam in ~$4$ weeks, and I came across this derivative as one of the questions. I actually have no idea how to solve it. $$\frac{d}{dx} (x^{x^2})$$ Using the chain rule on it letting $x^2 = u$ led to me getting $2x^{x^2-2}$, which isn't right. The function acts like $e^x$ so I am thinking I have to convert it to this form. So I took it to be: $$\frac{d}{dx} (e^{{x^2}log(x)})$$ Not really sure where to go from here, or if I am going in the right direction.","Studying past exam problems for my exam in ~$4$ weeks, and I came across this derivative as one of the questions. I actually have no idea how to solve it. $$\frac{d}{dx} (x^{x^2})$$ Using the chain rule on it letting $x^2 = u$ led to me getting $2x^{x^2-2}$, which isn't right. The function acts like $e^x$ so I am thinking I have to convert it to this form. So I took it to be: $$\frac{d}{dx} (e^{{x^2}log(x)})$$ Not really sure where to go from here, or if I am going in the right direction.",,"['calculus', 'derivatives']"
36,"Need help with $\int_0^1\frac{\log(1+x)-\log(1-x)}{\left(1+\log^2x\right)x}\,dx$",Need help with,"\int_0^1\frac{\log(1+x)-\log(1-x)}{\left(1+\log^2x\right)x}\,dx","Please help me to evaluate this integral $$\int_0^1\frac{\log(1+x)-\log(1-x)}{\left(1+\log^2x\right)x}\,dx$$ I tried a change of variable $x=\tanh z$, that transforms it into the form $$\int_0^\infty\frac{4z}{\left(1+\log^2\tanh z\right)\sinh2z}\,dz,$$ but I do not know what to do next.","Please help me to evaluate this integral $$\int_0^1\frac{\log(1+x)-\log(1-x)}{\left(1+\log^2x\right)x}\,dx$$ I tried a change of variable $x=\tanh z$, that transforms it into the form $$\int_0^\infty\frac{4z}{\left(1+\log^2\tanh z\right)\sinh2z}\,dz,$$ but I do not know what to do next.",,"['calculus', 'integration', 'definite-integrals', 'hyperbolic-functions']"
37,How did the ancients view *infinitesimals*?,How did the ancients view *infinitesimals*?,,"With some category/topos theory we can now put infinitesimals on a rigorous ground, as in Bell's A Primer of Infinitesimal Analysis , where the author introduces $\epsilon$ satisfying \begin{equation} \epsilon\ne 0, \epsilon^2=0. \end{equation} However, he also points out that this version of infinitesimal is not compatible with the law of excluded middle . Meanwhile, the author seems convinced that this $\epsilon$ is the infinitesimal in the eyes of Newton and Leibniz among many others, when they were attacking problems like instantaneous speed and area under a curve. I wonder whether this is true. I know people like Newton and Leibniz did not use limiting argument. But this does not mean they think of infinitesimals as nilsquare elements as described by Bell, because there are still other models of infinitesimals available. Thanks very much.","With some category/topos theory we can now put infinitesimals on a rigorous ground, as in Bell's A Primer of Infinitesimal Analysis , where the author introduces $\epsilon$ satisfying \begin{equation} \epsilon\ne 0, \epsilon^2=0. \end{equation} However, he also points out that this version of infinitesimal is not compatible with the law of excluded middle . Meanwhile, the author seems convinced that this $\epsilon$ is the infinitesimal in the eyes of Newton and Leibniz among many others, when they were attacking problems like instantaneous speed and area under a curve. I wonder whether this is true. I know people like Newton and Leibniz did not use limiting argument. But this does not mean they think of infinitesimals as nilsquare elements as described by Bell, because there are still other models of infinitesimals available. Thanks very much.",,"['calculus', 'reference-request', 'logic', 'intuition', 'math-history']"
38,How to compute the monstrous $ \int_0^{\frac{e-1}{e}}{\frac{x(2-x)}{(1-x)}\frac{\log\left(\log\left(1+\frac{x^2}{2-2x}\right)\right)}{2-2x+x^2}dx} $,How to compute the monstrous, \int_0^{\frac{e-1}{e}}{\frac{x(2-x)}{(1-x)}\frac{\log\left(\log\left(1+\frac{x^2}{2-2x}\right)\right)}{2-2x+x^2}dx} ,"A friend told me, that he found a closed form for the following integral: $$ \int_0^{\frac{e-1}{e}}{\frac{x(2-x)}{(1-x)}\frac{\log\left(\log\left(1+\frac{x^2}{2-2x}\right)\right)}{\left(2-2x+x^2\right)}dx} $$ I don't know if he's just messing around with me, but I wonder if this integral admits a closed form. I tried to expand the $\log(\log)$ term into a power series, but things got worse. So any help will be appreciated!","A friend told me, that he found a closed form for the following integral: $$ \int_0^{\frac{e-1}{e}}{\frac{x(2-x)}{(1-x)}\frac{\log\left(\log\left(1+\frac{x^2}{2-2x}\right)\right)}{\left(2-2x+x^2\right)}dx} $$ I don't know if he's just messing around with me, but I wonder if this integral admits a closed form. I tried to expand the $\log(\log)$ term into a power series, but things got worse. So any help will be appreciated!",,"['calculus', 'integration', 'definite-integrals', 'closed-form']"
39,Calculate $\lim_{n \to \infty} \sqrt[n]{|\sin n|}$,Calculate,\lim_{n \to \infty} \sqrt[n]{|\sin n|},I am having trouble calculating the following limit:  $$\lim_{n \to \infty} \sqrt[n]{|\sin n|}\ .$$,I am having trouble calculating the following limit:  $$\lim_{n \to \infty} \sqrt[n]{|\sin n|}\ .$$,,"['calculus', 'limits', 'trigonometry', 'radicals', 'diophantine-approximation']"
40,"How can I ""see"" that calculus works for multidimensional problems?","How can I ""see"" that calculus works for multidimensional problems?",,"Let's say I have some function f(x) = x^2 + b . I can see what's going on, I can count the slope geometrically even without knowing the rules of derivatives. When I need to minimize some cost function for linear problem (linear regression with gradient descent), I just need to picture 3d, and I can ""see"", and be quite confident why and how it works. How can I ""see"" or get intuition that calculus works for multidimensional problems? Let's say I have a problem with many variables like: f(area_km, bedrooms, ...) = theta + theta1 * area_km + theta2 * bedrooms etc If I want to apply gradient descent, I know I need to calculate partial derivatives and multiply it with a learning rate etc. It works. But it's kinda magical that it works. I am sorry this is a silly question, I am just beginning.","Let's say I have some function f(x) = x^2 + b . I can see what's going on, I can count the slope geometrically even without knowing the rules of derivatives. When I need to minimize some cost function for linear problem (linear regression with gradient descent), I just need to picture 3d, and I can ""see"", and be quite confident why and how it works. How can I ""see"" or get intuition that calculus works for multidimensional problems? Let's say I have a problem with many variables like: f(area_km, bedrooms, ...) = theta + theta1 * area_km + theta2 * bedrooms etc If I want to apply gradient descent, I know I need to calculate partial derivatives and multiply it with a learning rate etc. It works. But it's kinda magical that it works. I am sorry this is a silly question, I am just beginning.",,"['calculus', 'multivariable-calculus', 'intuition', 'gradient-descent']"
41,How to Prove : $\frac{2}{(n+2)!}\sum_{k=0}^n(-1)^k\binom{n}{k}(n-k)^{n+2}=\frac{n(3n+1)}{12}$,How to Prove :,\frac{2}{(n+2)!}\sum_{k=0}^n(-1)^k\binom{n}{k}(n-k)^{n+2}=\frac{n(3n+1)}{12},"While I calculate an integral  $$ \int\limits_{[0,1]^n}\cdots\int(x_1+\cdots+x_n)^2\mathrm dx_1\cdots\mathrm dx_n $$ I used two different methods and got two answers. I am sure it's equivalent, but how can I prove it? $$\displaystyle\dfrac{2}{(n+2)!}\sum_{k=0}^n(-1)^k\binom{n}{k}(n-k)^{n+2}=\dfrac{n(3n+1)}{12}$$ Sincerely thanks!","While I calculate an integral  $$ \int\limits_{[0,1]^n}\cdots\int(x_1+\cdots+x_n)^2\mathrm dx_1\cdots\mathrm dx_n $$ I used two different methods and got two answers. I am sure it's equivalent, but how can I prove it? $$\displaystyle\dfrac{2}{(n+2)!}\sum_{k=0}^n(-1)^k\binom{n}{k}(n-k)^{n+2}=\dfrac{n(3n+1)}{12}$$ Sincerely thanks!",,"['calculus', 'integration', 'combinatorics', 'analysis']"
42,How to avoid stupid mistakes in calculus exams without checking the whole process?,How to avoid stupid mistakes in calculus exams without checking the whole process?,,"Few days ago I failed my Calculus exams. And again it was mostly due to simple mistakes such as forgetting about minus in front of fraction, switching y coordinates of two points etc. The assignments are pretty simple, for example calculating area defined by N curves or analyzing a function. But we have only ten minutes for each, so there is almost no time left to check the results. My question is: How to avoid such mistakes without checking everything?","Few days ago I failed my Calculus exams. And again it was mostly due to simple mistakes such as forgetting about minus in front of fraction, switching y coordinates of two points etc. The assignments are pretty simple, for example calculating area defined by N curves or analyzing a function. But we have only ten minutes for each, so there is almost no time left to check the results. My question is: How to avoid such mistakes without checking everything?",,"['calculus', 'soft-question', 'arithmetic']"
43,Limit of product with prime numbers,Limit of product with prime numbers,,"A friend found a calculus problem in an old box with a lot of math exercises, but we don't have the answer to one of them. If you could help us with a hint it would be nice! The question is:  what is the limit of the following infinite product? $$ \prod_{p \in \mathbb{P}} \frac{p^4+1}{p^4-1} $$ Here $\mathbb{P}$ is the set of prime numbers.","A friend found a calculus problem in an old box with a lot of math exercises, but we don't have the answer to one of them. If you could help us with a hint it would be nice! The question is:  what is the limit of the following infinite product? $$ \prod_{p \in \mathbb{P}} \frac{p^4+1}{p^4-1} $$ Here $\mathbb{P}$ is the set of prime numbers.",,"['calculus', 'infinite-product']"
44,Taylor series in two variables,Taylor series in two variables,,"Taylor series of a function $f(x,t)$ at $(a,b)$ is $$ f(x,t)=f(a,b) +(x-a)f_x(a,b)+(t-b)f_t(a,b) + \cdots .$$ But why $$df=\frac{\partial f}{\partial x}dx + \frac{\partial f}{\partial t}dt + \frac{\partial^2 f}{2\partial x^2}dx^2 + \cdots?$$ This formula is in the 6-th line below Informal derivation . I think that $$df=\frac{\partial f}{\partial x}dx + \frac{\partial f}{\partial t}dt.$$ Thank you very much.","Taylor series of a function $f(x,t)$ at $(a,b)$ is $$ f(x,t)=f(a,b) +(x-a)f_x(a,b)+(t-b)f_t(a,b) + \cdots .$$ But why $$df=\frac{\partial f}{\partial x}dx + \frac{\partial f}{\partial t}dt + \frac{\partial^2 f}{2\partial x^2}dx^2 + \cdots?$$ This formula is in the 6-th line below Informal derivation . I think that $$df=\frac{\partial f}{\partial x}dx + \frac{\partial f}{\partial t}dt.$$ Thank you very much.",,"['calculus', 'multivariable-calculus']"
45,Rare Integral $\int_0^1 \frac{\cosh \left( \alpha \cos ^{-1}x \right)\cos \left( \alpha \sinh ^{-1}x \right)}{\sqrt{1-x^{2}}} dx$,Rare Integral,\int_0^1 \frac{\cosh \left( \alpha \cos ^{-1}x \right)\cos \left( \alpha \sinh ^{-1}x \right)}{\sqrt{1-x^{2}}} dx,"I need to prove if this statement is true, some ideas? $$\int_0^1 \frac{\cosh\left(\alpha \cos ^{-1}x\right)\cos \left( \alpha \sinh^{-1} x \right)}{\sqrt{1-x^2}} \, dx = \frac \pi 4 + \frac 1 {2\alpha }\cdot \sinh \frac{\alpha \pi } 2$$","I need to prove if this statement is true, some ideas? $$\int_0^1 \frac{\cosh\left(\alpha \cos ^{-1}x\right)\cos \left( \alpha \sinh^{-1} x \right)}{\sqrt{1-x^2}} \, dx = \frac \pi 4 + \frac 1 {2\alpha }\cdot \sinh \frac{\alpha \pi } 2$$",,"['calculus', 'integration', 'definite-integrals']"
46,Using differentiation under integral sign to calculate $\int^{\pi/2}_0\frac{\log(1+a\sin\phi)}{\sin\phi}d\phi$,Using differentiation under integral sign to calculate,\int^{\pi/2}_0\frac{\log(1+a\sin\phi)}{\sin\phi}d\phi,I want to calculate the integral $$\int^{\pi/2}_0\frac{\log(1+\sin\phi)}{\sin\phi}d\phi$$ using differentiation with respect to parameter in the integral $$\int^{\pi/2}_0\frac{\log(1+a\sin\phi)}{\sin\phi}d\phi$$ I know that I have to solve from differentiate under the integral and I must use a suitable substitution for integrands involving trigonometric functions but I can't complete the solution. Could you help me?,I want to calculate the integral $$\int^{\pi/2}_0\frac{\log(1+\sin\phi)}{\sin\phi}d\phi$$ using differentiation with respect to parameter in the integral $$\int^{\pi/2}_0\frac{\log(1+a\sin\phi)}{\sin\phi}d\phi$$ I know that I have to solve from differentiate under the integral and I must use a suitable substitution for integrands involving trigonometric functions but I can't complete the solution. Could you help me?,,"['calculus', 'integration', 'definite-integrals', 'improper-integrals']"
47,"In Taylor series, what's the significance of choosing the point of expansion $x=a$?","In Taylor series, what's the significance of choosing the point of expansion ?",x=a,"So I read about the Taylor series and it said you can choose to expand the series around a given point ($x=a$). Does it matter which point you choose in calculating the value of the series? For example, if I wanted to calculate ""$e^x$"" at $x=1$ then would it matter if I'd expand the series around $a=1$ or $a=0$? Thanks in advance :)","So I read about the Taylor series and it said you can choose to expand the series around a given point ($x=a$). Does it matter which point you choose in calculating the value of the series? For example, if I wanted to calculate ""$e^x$"" at $x=1$ then would it matter if I'd expand the series around $a=1$ or $a=0$? Thanks in advance :)",,"['calculus', 'taylor-expansion']"
48,Leibniz rule derivation,Leibniz rule derivation,,"How is Leibniz Integral rule derived? $$\frac {\mathrm{d}}{\mathrm{d}x}\left(\int_{a(x)}^{b(x)}f(x, t) \,\mathrm{d}t\right)= f(x,b(x))\frac{\mathrm{d}}{\mathrm{d}x}b(x)- f(x, a(x))\dfrac{\mathrm{d}}{\mathrm{d}x}a(x)+ \displaystyle\int_{a(x)}^{b(x)}\dfrac{\partial f(x,t)}{\partial x} \,\mathrm{d}t.$$ Also, what is the intuition behind this formula?","How is Leibniz Integral rule derived? Also, what is the intuition behind this formula?","\frac {\mathrm{d}}{\mathrm{d}x}\left(\int_{a(x)}^{b(x)}f(x, t) \,\mathrm{d}t\right)= f(x,b(x))\frac{\mathrm{d}}{\mathrm{d}x}b(x)- f(x, a(x))\dfrac{\mathrm{d}}{\mathrm{d}x}a(x)+ \displaystyle\int_{a(x)}^{b(x)}\dfrac{\partial f(x,t)}{\partial x} \,\mathrm{d}t.",['calculus']
49,"Why is $-\log(x)$ integrable over the interval $[0, 1]$ but $\frac{1}{x}$ not integrable?",Why is  integrable over the interval  but  not integrable?,"-\log(x) [0, 1] \frac{1}{x}","I don't understand why some functions that contain a singularity in the domain of integration are integrable but others are not. For example, consider $f(x) = -\log(x)$ and $g(x) = \frac{1}{x}$ on the interval $[0, 1]$. These functions look very similar when they are plotted but only $f(x)$ can be integrated. What is the precise mathematical reason(s) that makes some functions with singularities integrable while others are not? Are $\log$ functions the only functions with singularities that can be integrated or are there other types of functions with singularities that can be integrated?","I don't understand why some functions that contain a singularity in the domain of integration are integrable but others are not. For example, consider $f(x) = -\log(x)$ and $g(x) = \frac{1}{x}$ on the interval $[0, 1]$. These functions look very similar when they are plotted but only $f(x)$ can be integrated. What is the precise mathematical reason(s) that makes some functions with singularities integrable while others are not? Are $\log$ functions the only functions with singularities that can be integrated or are there other types of functions with singularities that can be integrated?",,"['calculus', 'integration']"
50,Conjecture $\sum_{n=1}^\infty\frac{n^2}{(-1)^n \cosh(\pi n\sqrt{3})-1}=\frac{1}{12\pi^2}$,Conjecture,\sum_{n=1}^\infty\frac{n^2}{(-1)^n \cosh(\pi n\sqrt{3})-1}=\frac{1}{12\pi^2},Wolfram Alpha numerical calculation  shows that the quantity $$ \sum_{n=1}^\infty\frac{12\pi^2n^2}{(-1)^n \cosh(\pi n\sqrt{3})-1} $$ is 1 with high accuracy. Can anybody prove the resulting conjecture: $$ \sum_{n=1}^\infty\frac{n^2}{(-1)^n \cosh(\pi n\sqrt{3})-1}\overset{?}{=}\frac{1}{12\pi^2} $$,Wolfram Alpha numerical calculation  shows that the quantity $$ \sum_{n=1}^\infty\frac{12\pi^2n^2}{(-1)^n \cosh(\pi n\sqrt{3})-1} $$ is 1 with high accuracy. Can anybody prove the resulting conjecture: $$ \sum_{n=1}^\infty\frac{n^2}{(-1)^n \cosh(\pi n\sqrt{3})-1}\overset{?}{=}\frac{1}{12\pi^2} $$,,"['calculus', 'sequences-and-series', 'closed-form', 'conjectures']"
51,What are other methods to evaluate $\int_0^1 \sqrt{-\ln x} \ \mathrm dx$,What are other methods to evaluate,\int_0^1 \sqrt{-\ln x} \ \mathrm dx,"$$\int_0^1 \sqrt{-\ln x} dx$$ I'm looking for alternative methods  to what I already know (method I have used below) to evaluate this Integral. $$y=-\ln x$$ $$\bbox[8pt, border:1pt solid crimson]{e^y=e^{-\ln x}=e^{\ln\frac{1}{x}}=\frac{1}{x}}$$ $$\color{#008080}{dx= -\frac{dy}{e^y}}$$ $$\int_0^1  \sqrt{-\ln x} dx=\int_{\infty}^0 \sqrt{y} \left(-\frac{dy}{e^y}\right)=\int_0^{\infty} e^{-y} y^{\frac{1}{2}}dy=\left(\frac{1}{2}\right)!$$ $$\bbox[8pt, border:1pt solid crimson]{\left(\frac{1}{2}\right)!=\frac{1}{2} \sqrt{\pi}}$$ $$\Large{\color{crimson}{\int_0^1 \sqrt{-\ln x} dx=\frac{1}{2} \sqrt{\pi}}}$$","$$\int_0^1 \sqrt{-\ln x} dx$$ I'm looking for alternative methods  to what I already know (method I have used below) to evaluate this Integral. $$y=-\ln x$$ $$\bbox[8pt, border:1pt solid crimson]{e^y=e^{-\ln x}=e^{\ln\frac{1}{x}}=\frac{1}{x}}$$ $$\color{#008080}{dx= -\frac{dy}{e^y}}$$ $$\int_0^1  \sqrt{-\ln x} dx=\int_{\infty}^0 \sqrt{y} \left(-\frac{dy}{e^y}\right)=\int_0^{\infty} e^{-y} y^{\frac{1}{2}}dy=\left(\frac{1}{2}\right)!$$ $$\bbox[8pt, border:1pt solid crimson]{\left(\frac{1}{2}\right)!=\frac{1}{2} \sqrt{\pi}}$$ $$\Large{\color{crimson}{\int_0^1 \sqrt{-\ln x} dx=\frac{1}{2} \sqrt{\pi}}}$$",,"['calculus', 'integration', 'definite-integrals', 'improper-integrals']"
52,How to prove $\sqrt[\pi]{e} < \sqrt[\pi]{\pi}<\sqrt[e]{e}< \sqrt[e]{\pi}$,How to prove,\sqrt[\pi]{e} < \sqrt[\pi]{\pi}<\sqrt[e]{e}< \sqrt[e]{\pi},I was given a challenge of sorting the following numbers. $\Large\sqrt[\pi]{e} < \sqrt[\pi]{\pi}<\sqrt[e]{e}< \sqrt[e]{\pi}$. After some work I was able to figure out the order. How can one prove this by hand?,I was given a challenge of sorting the following numbers. $\Large\sqrt[\pi]{e} < \sqrt[\pi]{\pi}<\sqrt[e]{e}< \sqrt[e]{\pi}$. After some work I was able to figure out the order. How can one prove this by hand?,,"['calculus', 'algebra-precalculus', 'logarithms']"
53,"Show $\int_0^\infty \frac{e^{-x}-e^{-xt}}{x}dx = \ln(t),$ for $t \gt 0$",Show  for,"\int_0^\infty \frac{e^{-x}-e^{-xt}}{x}dx = \ln(t), t \gt 0","The problem is to show $$\int_0^\infty \frac{e^{-x}-e^{-xt}}{x}dx = \ln(t),$$ for $t \gt 0$. I'm pretty stuck. I thought about integration by parts and couldn't get anywhere with the integrand in its current form. I tried a substitution $u=e^{-x}$ and came to a new integral (hopefully after no mistakes) $$ \int_0^1 \frac{u^{t-1}-1}{\log(u)}du, $$ but this doesn't seem to help either. I hope I could have a hint in the right direction... I really want to solve most of it by myself. Thanks a lot!","The problem is to show $$\int_0^\infty \frac{e^{-x}-e^{-xt}}{x}dx = \ln(t),$$ for $t \gt 0$. I'm pretty stuck. I thought about integration by parts and couldn't get anywhere with the integrand in its current form. I tried a substitution $u=e^{-x}$ and came to a new integral (hopefully after no mistakes) $$ \int_0^1 \frac{u^{t-1}-1}{\log(u)}du, $$ but this doesn't seem to help either. I hope I could have a hint in the right direction... I really want to solve most of it by myself. Thanks a lot!",,"['calculus', 'integration', 'definite-integrals', 'improper-integrals']"
54,Intuitive reasoning behind the Chain Rule in multiple variables?,Intuitive reasoning behind the Chain Rule in multiple variables?,,"I've sort of gotten a grasp on the Chain rule with one variable.  If you hike up a mountain at 2 feet an hour, and the temperature decreases at 2 degrees per feet, the temperature would be decreasing for you at $2\times 2 = 4$ degrees per hour. But I'm having a bit more trouble understanding the Chain Rule as applied to multiple variables.  Even the case of 2 dimensions $$z = f(x,y),$$ where $x = g(t)$ and $y = h(t)$, so $$\frac{dz}{dt} = \frac{\partial z}{dx} \frac{dx}{dt} + \frac{\partial z}{dy} \frac{dy}{dt}.$$ Now, this is easy enough to ""calculate"" (and figure out what goes where).  My teacher taught me a neat tree-based graphical method for figuring out partial derivatives using chain rule.  All-in-all, it was rather hand-wavey.  However, I'm not sure exactly how this works, intuitively. Why, intuitively, is the equation above true?  Why addition ?  Why not multiplication, like the other chain rule?  Why are some multiplied and some added?","I've sort of gotten a grasp on the Chain rule with one variable.  If you hike up a mountain at 2 feet an hour, and the temperature decreases at 2 degrees per feet, the temperature would be decreasing for you at $2\times 2 = 4$ degrees per hour. But I'm having a bit more trouble understanding the Chain Rule as applied to multiple variables.  Even the case of 2 dimensions $$z = f(x,y),$$ where $x = g(t)$ and $y = h(t)$, so $$\frac{dz}{dt} = \frac{\partial z}{dx} \frac{dx}{dt} + \frac{\partial z}{dy} \frac{dy}{dt}.$$ Now, this is easy enough to ""calculate"" (and figure out what goes where).  My teacher taught me a neat tree-based graphical method for figuring out partial derivatives using chain rule.  All-in-all, it was rather hand-wavey.  However, I'm not sure exactly how this works, intuitively. Why, intuitively, is the equation above true?  Why addition ?  Why not multiplication, like the other chain rule?  Why are some multiplied and some added?",,"['calculus', 'linear-algebra']"
55,"If $u_{n+1}\le u_n+u_n^2$ and $\sum u_n$ converges, prove that $\lim\limits_{n\to +\infty}(n\cdot u_n)=0$","If  and  converges, prove that",u_{n+1}\le u_n+u_n^2 \sum u_n \lim\limits_{n\to +\infty}(n\cdot u_n)=0,"Given the positive sequence $\{u_n\},n\in \mathbb{N}$ that meets the conditions: $\boxed{1}$. $u_{n+1}\le u_n+u_n^2$ $\boxed{2}$. Exist the constant $\text{M} >0$ so that $\displaystyle\sum\limits_{k=1}^n u_k\le \text{M},\, \forall n\in \mathbb{N}$ Prove that $$\lim\limits_{n\to +\infty}(n\cdot u_n)=0$$ I think that we can use the Stolz-Cesaro Theorem, 0/0 Case , but I haven't found how.","Given the positive sequence $\{u_n\},n\in \mathbb{N}$ that meets the conditions: $\boxed{1}$. $u_{n+1}\le u_n+u_n^2$ $\boxed{2}$. Exist the constant $\text{M} >0$ so that $\displaystyle\sum\limits_{k=1}^n u_k\le \text{M},\, \forall n\in \mathbb{N}$ Prove that $$\lim\limits_{n\to +\infty}(n\cdot u_n)=0$$ I think that we can use the Stolz-Cesaro Theorem, 0/0 Case , but I haven't found how.",,"['calculus', 'sequences-and-series', 'limits']"
56,Average IQ of Mensa,Average IQ of Mensa,,"I was wondering, what the average IQ at Mensa is. Mensa is a group of people with an IQ of at least 130. And the IQ is normally distribed with $\mu = 100$ and $\sigma = 15$. My idea was this: To get the mean of a function in interval $[a,b]$ I have to calculate $$\bar{f}(x) = \frac{1}{b-a} \int_a^b f(x)\; dx$$ So the mean $p$ is $$p = \lim_{b \to \infty} \frac{1}{b-130} \int_{130}^{b} \frac{1}{2 \pi} e^{-\frac{1}{2} \left(\frac{x-100}{15}\right)^2}dx$$ And then I just have to calculate, which IQ corresponds to this $p$. Is my idea correct? How do I solve this integral and calculate the limit?","I was wondering, what the average IQ at Mensa is. Mensa is a group of people with an IQ of at least 130. And the IQ is normally distribed with $\mu = 100$ and $\sigma = 15$. My idea was this: To get the mean of a function in interval $[a,b]$ I have to calculate $$\bar{f}(x) = \frac{1}{b-a} \int_a^b f(x)\; dx$$ So the mean $p$ is $$p = \lim_{b \to \infty} \frac{1}{b-130} \int_{130}^{b} \frac{1}{2 \pi} e^{-\frac{1}{2} \left(\frac{x-100}{15}\right)^2}dx$$ And then I just have to calculate, which IQ corresponds to this $p$. Is my idea correct? How do I solve this integral and calculate the limit?",,"['calculus', 'integration', 'statistics']"
57,What are the higher derivatives of a multivariate function?,What are the higher derivatives of a multivariate function?,,I have recently realized that I am not sure what it means to consider $F''(x)$ and general higher derivatives for $F: \mathbb R ^n \rightarrow \mathbb R^m$. I am clear the at the first derivative is a matrix of partial derivatives $ \left( \begin{array}{ccc} \frac{\partial f_1}{\partial x_1}(x) & ... & \frac{\partial f_1}{\partial x_n}(x) \\ ... & ... & ... \\ \frac{\partial f_m}{\partial x_1}(x) & ... & \frac{\partial f_m}{\partial x_n}(x) \end{array} \right) $. But I am not sure how to differentiate this matrix. Do I want to treat it as a vector and then get the first derivative of the function $G: \mathbb R^n \rightarrow \mathbb R^{n \times m}$ which sends $x$ to the vector of partial derivatives?,I have recently realized that I am not sure what it means to consider $F''(x)$ and general higher derivatives for $F: \mathbb R ^n \rightarrow \mathbb R^m$. I am clear the at the first derivative is a matrix of partial derivatives $ \left( \begin{array}{ccc} \frac{\partial f_1}{\partial x_1}(x) & ... & \frac{\partial f_1}{\partial x_n}(x) \\ ... & ... & ... \\ \frac{\partial f_m}{\partial x_1}(x) & ... & \frac{\partial f_m}{\partial x_n}(x) \end{array} \right) $. But I am not sure how to differentiate this matrix. Do I want to treat it as a vector and then get the first derivative of the function $G: \mathbb R^n \rightarrow \mathbb R^{n \times m}$ which sends $x$ to the vector of partial derivatives?,,"['calculus', 'multivariable-calculus', 'derivatives']"
58,Evaluate $\int_0^\infty{\frac{\tan x}{x^n}dx}$,Evaluate,\int_0^\infty{\frac{\tan x}{x^n}dx},"For$$PV\int_0^\infty{\frac{\tan x}{x^n}dx}$$ I can prove that it converges when $0<n<2$. I know the ways to evaluate$$PV\int_0^\infty{\frac{\tan x}{x}dx}=\frac\pi2$$ but both of these 2 ways doesn't work. First, using contour integration: the path used in evaluating the second integral doesn't fit in with the first one and I can't find a suitable path to the integral. Second, seperating the integral: I had to calculate $$\sum_{k=0}^{\infty}{\int_0^{\pi /2}{\tan t\left( \frac{1}{\left( k\pi +t \right) ^n}-\frac{1}{\left( \left( k+1 \right) \pi -t \right) ^n} \right) dt}}$$ which is unable to be solved by Mathematica. I can't go further.","For$$PV\int_0^\infty{\frac{\tan x}{x^n}dx}$$ I can prove that it converges when $0<n<2$. I know the ways to evaluate$$PV\int_0^\infty{\frac{\tan x}{x}dx}=\frac\pi2$$ but both of these 2 ways doesn't work. First, using contour integration: the path used in evaluating the second integral doesn't fit in with the first one and I can't find a suitable path to the integral. Second, seperating the integral: I had to calculate $$\sum_{k=0}^{\infty}{\int_0^{\pi /2}{\tan t\left( \frac{1}{\left( k\pi +t \right) ^n}-\frac{1}{\left( \left( k+1 \right) \pi -t \right) ^n} \right) dt}}$$ which is unable to be solved by Mathematica. I can't go further.",,"['calculus', 'integration', 'definite-integrals']"
59,"On $\int_0^1\arctan\,_6F_5\left(\frac17,\frac27,\frac37,\frac47,\frac57,\frac67;\,\frac26,\frac36,\frac46,\frac56,\frac76;\frac{n}{6^6}\,x\right)\,dx$",On,"\int_0^1\arctan\,_6F_5\left(\frac17,\frac27,\frac37,\frac47,\frac57,\frac67;\,\frac26,\frac36,\frac46,\frac56,\frac76;\frac{n}{6^6}\,x\right)\,dx","Reshetnikov gave the remarkable evaluation , \begin{align} I&= \int_0^1\arctan{_4F_3}\left(\frac15,\frac25,\frac35,\frac45;\frac24,\frac34,\frac54;\frac{1}{64}\,x\right)\,dx \\ &=\frac{3125}{48}\left(5+3\pi+6\ln2-3\alpha^4+4\alpha^3+6\alpha^2-12\alpha\\-12\left(\alpha^5-\alpha^4+1\right)\arctan\frac1\alpha-6\ln\left(1+\alpha^2\right)\right)\\ &=0.7857194\dots \end{align} where $\alpha$ is a quartic root. However, it seems this can be simplified a bit and generalized. I. $p=5$: Given, $$I(n)=\int_0^1\arctan\,_4F_3\left(\frac15,\frac25,\frac35,\frac45;\,\frac24,\frac34,\frac54;\,\frac{n}{4^4}\,x\right)\,\mathrm dx$$ Is it true that, in general, $$\frac{12n}{5^5}\, I(n) = -12\Big(1\color{blue}-\frac{n}{5^5}\Big)\arctan\frac1\alpha+6\ln\Big(\frac{2}{1+\alpha^2}\Big)+3\pi+P(\alpha)$$ where $P(\alpha)=(1-\alpha)^3(5+3\alpha)$ and $\alpha$ is the largest positive root of the quintic , $$\alpha^5-\alpha^4+\frac{n}{5^5}=0$$ provided real number $n<4^4\,$? ( Note : By sheer coincidence, the choice of $n=4$ in the other post caused the quintic to factor.) II. $p=7$: Given, $$J(n)=\int_0^1\arctan\,_6F_5\left(\frac17,\frac27,\frac37,\frac47,\frac57,\frac67;\,\frac26,\frac36,\frac46,\frac56,\frac76;\,\frac{n}{6^6}\,x\right)\,\mathrm dx$$ is it true that, $$\frac{60n}{7^7}\, J(n) = 60\Big(1\color{blue}+\frac{n}{7^7}\Big)\arctan\frac1\alpha-30\ln\Big(\frac{2}{1+\alpha^2}\Big)-15\pi-P(\beta)$$ where $P(\beta) = (1-\beta)^2(27-6\beta-9\beta^2+8\beta^3+10\beta^4)$ and $\beta$ is the largest positive root of, $$\beta^7-\beta^6+\frac{n}{7^7}=0$$ provided real $n<6^6\,$? Questions: How do we prove the two conjectured equalities? What's the formula for $p=3$? ( Mathematica takes too long to evaluate the integral that I couldn't use an integer relations subroutine on it.)","Reshetnikov gave the remarkable evaluation , \begin{align} I&= \int_0^1\arctan{_4F_3}\left(\frac15,\frac25,\frac35,\frac45;\frac24,\frac34,\frac54;\frac{1}{64}\,x\right)\,dx \\ &=\frac{3125}{48}\left(5+3\pi+6\ln2-3\alpha^4+4\alpha^3+6\alpha^2-12\alpha\\-12\left(\alpha^5-\alpha^4+1\right)\arctan\frac1\alpha-6\ln\left(1+\alpha^2\right)\right)\\ &=0.7857194\dots \end{align} where $\alpha$ is a quartic root. However, it seems this can be simplified a bit and generalized. I. $p=5$: Given, $$I(n)=\int_0^1\arctan\,_4F_3\left(\frac15,\frac25,\frac35,\frac45;\,\frac24,\frac34,\frac54;\,\frac{n}{4^4}\,x\right)\,\mathrm dx$$ Is it true that, in general, $$\frac{12n}{5^5}\, I(n) = -12\Big(1\color{blue}-\frac{n}{5^5}\Big)\arctan\frac1\alpha+6\ln\Big(\frac{2}{1+\alpha^2}\Big)+3\pi+P(\alpha)$$ where $P(\alpha)=(1-\alpha)^3(5+3\alpha)$ and $\alpha$ is the largest positive root of the quintic , $$\alpha^5-\alpha^4+\frac{n}{5^5}=0$$ provided real number $n<4^4\,$? ( Note : By sheer coincidence, the choice of $n=4$ in the other post caused the quintic to factor.) II. $p=7$: Given, $$J(n)=\int_0^1\arctan\,_6F_5\left(\frac17,\frac27,\frac37,\frac47,\frac57,\frac67;\,\frac26,\frac36,\frac46,\frac56,\frac76;\,\frac{n}{6^6}\,x\right)\,\mathrm dx$$ is it true that, $$\frac{60n}{7^7}\, J(n) = 60\Big(1\color{blue}+\frac{n}{7^7}\Big)\arctan\frac1\alpha-30\ln\Big(\frac{2}{1+\alpha^2}\Big)-15\pi-P(\beta)$$ where $P(\beta) = (1-\beta)^2(27-6\beta-9\beta^2+8\beta^3+10\beta^4)$ and $\beta$ is the largest positive root of, $$\beta^7-\beta^6+\frac{n}{7^7}=0$$ provided real $n<6^6\,$? Questions: How do we prove the two conjectured equalities? What's the formula for $p=3$? ( Mathematica takes too long to evaluate the integral that I couldn't use an integer relations subroutine on it.)",,"['calculus', 'integration', 'closed-form', 'hypergeometric-function', 'conjectures']"
60,"Closed-form of $\int_0^1\left(\frac{\arctan x}{x}\right)^n\,dx$",Closed-form of,"\int_0^1\left(\frac{\arctan x}{x}\right)^n\,dx","Inspired by this question , is there a closed-form of $$\int_0^1\left(\frac{\arctan x}{x}\right)^n\,dx\,?$$ Here $n \in \mathbb{N_+}$. In the answers to the question above we could find proofs of cases $n=2,3$. I state here some specific cases. $$\begin{align} \int_0^1\frac{\arctan x}{x}\,dx & = G, \\ \int_0^1\left(\frac{\arctan x}{x}\right)^2\,dx & =G-\frac{\pi^2}{16}+\frac{\pi}{4}\ln2,\\ \int_0^1\left(\frac{\arctan x}{x}\right)^3\,dx & = \frac{3G}{2}-\frac{\pi^3}{64}-\frac{3\pi^2}{32}+\frac{3\pi}{8}\ln2.\\ \end{align}$$ Furtheremore I've evaluated $n=4,5$ cases. $$\int_{0}^{1}\left(\frac{\arctan(x)}{x}\right)^4dx$$ equals to $$2G-\frac{3\pi^4}{256}-\frac{\pi^3}{48}-\frac{\pi^2}{8}-\frac{\pi^2G}{8}+\frac{‌​3\pi}{64}\zeta(3)-\frac{\pi^3}{96} \ln2+\frac{\pi}{2} \ln2+\frac{1}{768}\psi_3\left(\frac{1}{4}\right),$$ and $$\int_{0}^{1}\left(\frac{\arctan(x)}{x}\right)^5dx$$ equals to $$\frac{5G}{2}-\frac{25\pi^4}{512}-\frac{5\pi^3}{192}-\frac{5\pi^2}{32}-\frac{5\pi^2 G}{8}+\frac{15\pi}{64}\zeta(3)-\frac{5\pi^3}{96}\ln 2+\frac{5\pi}{8}\ln 2 + \frac{5}{768}\psi_3\left(\frac{1}{4}\right).$$ Here $G$ is Catalan's constant , $\zeta$ is the Riemann zeta function , $\psi_3$ is the polygamma function of order $3$, and $\pi$ is also a famous constant . Note that the problem is related to Dirichlet beta function , since $$\begin{align} \beta(2) & = G \\ \beta(3) & = \frac{\pi^3}{32} \\ \beta(4) & = \frac{1}{768}\left(\psi_3\left(\frac{1}{4}\right)-8\pi^4\right). \end{align}$$","Inspired by this question , is there a closed-form of $$\int_0^1\left(\frac{\arctan x}{x}\right)^n\,dx\,?$$ Here $n \in \mathbb{N_+}$. In the answers to the question above we could find proofs of cases $n=2,3$. I state here some specific cases. $$\begin{align} \int_0^1\frac{\arctan x}{x}\,dx & = G, \\ \int_0^1\left(\frac{\arctan x}{x}\right)^2\,dx & =G-\frac{\pi^2}{16}+\frac{\pi}{4}\ln2,\\ \int_0^1\left(\frac{\arctan x}{x}\right)^3\,dx & = \frac{3G}{2}-\frac{\pi^3}{64}-\frac{3\pi^2}{32}+\frac{3\pi}{8}\ln2.\\ \end{align}$$ Furtheremore I've evaluated $n=4,5$ cases. $$\int_{0}^{1}\left(\frac{\arctan(x)}{x}\right)^4dx$$ equals to $$2G-\frac{3\pi^4}{256}-\frac{\pi^3}{48}-\frac{\pi^2}{8}-\frac{\pi^2G}{8}+\frac{‌​3\pi}{64}\zeta(3)-\frac{\pi^3}{96} \ln2+\frac{\pi}{2} \ln2+\frac{1}{768}\psi_3\left(\frac{1}{4}\right),$$ and $$\int_{0}^{1}\left(\frac{\arctan(x)}{x}\right)^5dx$$ equals to $$\frac{5G}{2}-\frac{25\pi^4}{512}-\frac{5\pi^3}{192}-\frac{5\pi^2}{32}-\frac{5\pi^2 G}{8}+\frac{15\pi}{64}\zeta(3)-\frac{5\pi^3}{96}\ln 2+\frac{5\pi}{8}\ln 2 + \frac{5}{768}\psi_3\left(\frac{1}{4}\right).$$ Here $G$ is Catalan's constant , $\zeta$ is the Riemann zeta function , $\psi_3$ is the polygamma function of order $3$, and $\pi$ is also a famous constant . Note that the problem is related to Dirichlet beta function , since $$\begin{align} \beta(2) & = G \\ \beta(3) & = \frac{\pi^3}{32} \\ \beta(4) & = \frac{1}{768}\left(\psi_3\left(\frac{1}{4}\right)-8\pi^4\right). \end{align}$$",,"['calculus', 'integration', 'definite-integrals', 'special-functions', 'closed-form']"
61,How to calclulate a derivate of a hypergeometric function w.r.t. one of its parameters?,How to calclulate a derivate of a hypergeometric function w.r.t. one of its parameters?,,"Is it possible to take a derivative of a hypergeometric function w.r.t. one of its parameters and express it in a closed form? I am particularly interested in this case: $$\large\left[\frac{d}{da}{_2F_1}\left(1/2,\,a;\,3/2;\,-1\right)\right]_{a=2}$$","Is it possible to take a derivative of a hypergeometric function w.r.t. one of its parameters and express it in a closed form? I am particularly interested in this case: $$\large\left[\frac{d}{da}{_2F_1}\left(1/2,\,a;\,3/2;\,-1\right)\right]_{a=2}$$",,"['calculus', 'derivatives', 'special-functions', 'closed-form', 'hypergeometric-function']"
62,Which Fourier series formula is correct,Which Fourier series formula is correct,,"I'm getting started on Fourier series but I'm confused over the formulae involved. My lecturers notes, including Wikipedia state that, for the interval $(-\pi \le x \le \pi)$ $$a_0 = \frac1\pi \int \cdots $$ whereas videos on Youtube and other tutorials I've found seem to be using: $$a_0 = \frac1{2\pi} \int \cdots $$ Which one am I supposed to use?","I'm getting started on Fourier series but I'm confused over the formulae involved. My lecturers notes, including Wikipedia state that, for the interval $(-\pi \le x \le \pi)$ $$a_0 = \frac1\pi \int \cdots $$ whereas videos on Youtube and other tutorials I've found seem to be using: $$a_0 = \frac1{2\pi} \int \cdots $$ Which one am I supposed to use?",,"['calculus', 'fourier-series']"
63,Book with novel approaches to analysis,Book with novel approaches to analysis,,"Now I'm studying Rudin's Principles of mathematical analysis , but I'm searching for a book that offers geometric, physical or otherwise non-standard approaches to topics in analysis. Also, I'm looking for some book (like Bell's), that describe calculus techniques from a novel perspective (possibly emphasizing their applications). Note : I'm not searching only for books that emphasize the application of analysisto physics, but also the other way round: a book that emphasizes the applications of physical arguments or geometry or any other non-standard approach to solve problems that should require a ""standard"" technique. For example, something like New Horizons in Geometry .","Now I'm studying Rudin's Principles of mathematical analysis , but I'm searching for a book that offers geometric, physical or otherwise non-standard approaches to topics in analysis. Also, I'm looking for some book (like Bell's), that describe calculus techniques from a novel perspective (possibly emphasizing their applications). Note : I'm not searching only for books that emphasize the application of analysisto physics, but also the other way round: a book that emphasizes the applications of physical arguments or geometry or any other non-standard approach to solve problems that should require a ""standard"" technique. For example, something like New Horizons in Geometry .",,"['calculus', 'geometry', 'reference-request', 'soft-question', 'book-recommendation']"
64,Evaluating $\int_{0}^{1} dx\frac{\log(1+x)}{1 + x^2}$ [duplicate],Evaluating  [duplicate],\int_{0}^{1} dx\frac{\log(1+x)}{1 + x^2},"This question already has answers here : Closed 11 years ago . Possible Duplicate: Evaluate the integral: $\int_{0}^{1} \frac{\ln(x+1)}{x^2+1} dx$ $$\int_{0}^{1} dx\frac{\log(1+x)}{1 + x^2}$$ I am having a hard time deriving the answer, $\frac{\pi}{8} \log(2) $.  I have tried Taylor expansion of both numerator and denominator, both seem too complicated and fruitless.","This question already has answers here : Closed 11 years ago . Possible Duplicate: Evaluate the integral: $\int_{0}^{1} \frac{\ln(x+1)}{x^2+1} dx$ $$\int_{0}^{1} dx\frac{\log(1+x)}{1 + x^2}$$ I am having a hard time deriving the answer, $\frac{\pi}{8} \log(2) $.  I have tried Taylor expansion of both numerator and denominator, both seem too complicated and fruitless.",,"['calculus', 'definite-integrals']"
65,challenging integral involving $\zeta(5)$,challenging integral involving,\zeta(5),"I ran across a curious integral that seems to be rather tough that some on the site may enjoy. Show that $$\displaystyle \int_{0}^{1}\frac{\sqrt{1-x^{2}}}{1-x^{2}\sin^{2}(x)}dx = \frac{5\sqrt[5]{{\pi}^{8}}}{32\sqrt[5]{{\zeta(5)}^{9}}}$$ How in the world can $\zeta(5)$ be incorporated into this?.  I tried series and several methods, but made no real progress. Any ideas?.  Thanks very much.","I ran across a curious integral that seems to be rather tough that some on the site may enjoy. Show that $$\displaystyle \int_{0}^{1}\frac{\sqrt{1-x^{2}}}{1-x^{2}\sin^{2}(x)}dx = \frac{5\sqrt[5]{{\pi}^{8}}}{32\sqrt[5]{{\zeta(5)}^{9}}}$$ How in the world can $\zeta(5)$ be incorporated into this?.  I tried series and several methods, but made no real progress. Any ideas?.  Thanks very much.",,"['calculus', 'integration', 'riemann-zeta']"
66,Simplify $\Gamma\left(\frac27\right) \Gamma\left(\frac{11}{42}\right)/\;\Gamma\left(\frac1{21}\right)$ to elementary terms,Simplify  to elementary terms,\Gamma\left(\frac27\right) \Gamma\left(\frac{11}{42}\right)/\;\Gamma\left(\frac1{21}\right),"How can we prove the following identity? $$\large \frac{\Gamma\left(\frac27\right) \Gamma\left(\frac{11}{42}\right)}{\Gamma\left(\frac1{21}\right)} = \frac{8 \sin\left(\frac\pi7\right) \sqrt{\pi \, \sin\left(\frac\pi{21}\right) \sin\left(\frac{4\pi}{21}\right) \sin\left(\frac{5\pi}{21}\right)}}{\sqrt[42]2 \; \sqrt[3]7 \; \sqrt[28]{19683}}$$ I guess we could use the Gauss multiplication formula , but how?","How can we prove the following identity? $$\large \frac{\Gamma\left(\frac27\right) \Gamma\left(\frac{11}{42}\right)}{\Gamma\left(\frac1{21}\right)} = \frac{8 \sin\left(\frac\pi7\right) \sqrt{\pi \, \sin\left(\frac\pi{21}\right) \sin\left(\frac{4\pi}{21}\right) \sin\left(\frac{5\pi}{21}\right)}}{\sqrt[42]2 \; \sqrt[3]7 \; \sqrt[28]{19683}}$$ I guess we could use the Gauss multiplication formula , but how?",,"['calculus', 'trigonometry', 'special-functions', 'gamma-function']"
67,"Can limits be thought of as linear functionals (or operators, depending on context)?","Can limits be thought of as linear functionals (or operators, depending on context)?",,"Ok so I just started Calc I this summer and since I already feel pretty comfortable with it from high school, I'm trying to gain a more rigorous perspective on it. I already know that limits behave linearly in the sense that $$ \lim_{x \to a}[f(x)+g(x)]=\lim_{x \to a}f(x)+\lim_{x \to a}g(x) $$ and  $$ \lim_{x \to a}[af(x)]=a \left(\lim_{x \to a}f(x)\right) $$ but I have never seen them formally described as a linear functional (or linear operator if the output is a function as in the case of the derivative) in the sense that they take an element of a suitable function space (for simplicity, take the continuous functions which form an infinite dimensional normed vector space, lets say $E$) such that $L:E \to \mathbb{R}$ where $L$ is defined by  $$ L=\lim_{x \to a} $$ My gut instinct on this is that it may have never been useful to formalize the notion of a limit as a linear functional or that the definition of the derivative operator $D:C^{k} \to C^{k-1}$ as  $$ Df=\lim_{h \to 0} \frac{f(x+h)+f(x)}{h} $$ makes this so obvious that no one talks about it explicitly. Another way to phrase my question would be: ""Limits belong to which class of mathematical objects?"" I tried asking my teacher but she didn't even understand what I was asking (she is a TA type who is well intentioned but clearly not comfortable enough with the material to teach) so any additional insights would be of great help here.","Ok so I just started Calc I this summer and since I already feel pretty comfortable with it from high school, I'm trying to gain a more rigorous perspective on it. I already know that limits behave linearly in the sense that $$ \lim_{x \to a}[f(x)+g(x)]=\lim_{x \to a}f(x)+\lim_{x \to a}g(x) $$ and  $$ \lim_{x \to a}[af(x)]=a \left(\lim_{x \to a}f(x)\right) $$ but I have never seen them formally described as a linear functional (or linear operator if the output is a function as in the case of the derivative) in the sense that they take an element of a suitable function space (for simplicity, take the continuous functions which form an infinite dimensional normed vector space, lets say $E$) such that $L:E \to \mathbb{R}$ where $L$ is defined by  $$ L=\lim_{x \to a} $$ My gut instinct on this is that it may have never been useful to formalize the notion of a limit as a linear functional or that the definition of the derivative operator $D:C^{k} \to C^{k-1}$ as  $$ Df=\lim_{h \to 0} \frac{f(x+h)+f(x)}{h} $$ makes this so obvious that no one talks about it explicitly. Another way to phrase my question would be: ""Limits belong to which class of mathematical objects?"" I tried asking my teacher but she didn't even understand what I was asking (she is a TA type who is well intentioned but clearly not comfortable enough with the material to teach) so any additional insights would be of great help here.",,"['calculus', 'functional-analysis']"
68,Integral $I=\int \frac{dx}{(x^2+1)\sqrt{x^2-4}} $,Integral,I=\int \frac{dx}{(x^2+1)\sqrt{x^2-4}} ,"Frankly, i don't have a solution to this, not even incorrect one, but, this integral looks a lot like that standard type of integral $I=\int\frac{Mx+N}{(x-\alpha)^n\sqrt{ax^2+bx+c}}$ which can be solved using substitution $x-\alpha=\frac{1}{t}$ so i tried to find such subtitution that will make this integral completely the same as this standard integral so i could use substitution i mentioned, so i tried two following substitutions $x^2-4=t^2 \Rightarrow x^2=t^2+4 \Rightarrow x=\sqrt{t^2+4}$ then i had to determine $dx$ $2xdx=2tdt \Rightarrow dx=\frac{tdt}{\sqrt{t^2+4}}$ from here i got: $\int\frac{dt}{(t^2+5)\sqrt{(t^2+4)}}$ but i have no idea what could i do with this, so i tried different substitution $x^2+1=t^2$ and then, by implementing the same pattern i used with the previous substitution i got this integral $\int\frac{dt}{t\sqrt{(t^2-1)(t^2-5)}}$  but again, i don't know what to do with this, so i could use some help.","Frankly, i don't have a solution to this, not even incorrect one, but, this integral looks a lot like that standard type of integral $I=\int\frac{Mx+N}{(x-\alpha)^n\sqrt{ax^2+bx+c}}$ which can be solved using substitution $x-\alpha=\frac{1}{t}$ so i tried to find such subtitution that will make this integral completely the same as this standard integral so i could use substitution i mentioned, so i tried two following substitutions $x^2-4=t^2 \Rightarrow x^2=t^2+4 \Rightarrow x=\sqrt{t^2+4}$ then i had to determine $dx$ $2xdx=2tdt \Rightarrow dx=\frac{tdt}{\sqrt{t^2+4}}$ from here i got: $\int\frac{dt}{(t^2+5)\sqrt{(t^2+4)}}$ but i have no idea what could i do with this, so i tried different substitution $x^2+1=t^2$ and then, by implementing the same pattern i used with the previous substitution i got this integral $\int\frac{dt}{t\sqrt{(t^2-1)(t^2-5)}}$  but again, i don't know what to do with this, so i could use some help.",,"['calculus', 'integration']"
69,Vardi's Integral: $\int_{\pi/4}^{\pi/2} \ln (\ln(\tan x))dx $,Vardi's Integral:,\int_{\pi/4}^{\pi/2} \ln (\ln(\tan x))dx ,Prove that: $\displaystyle\int_{\pi/4}^{\pi/2} \ln (\ln(\tan x))dx =\frac{\pi}{2}\ln \left( \frac{\sqrt{2\pi} \Gamma \left(\dfrac{3}{4} \right)}{\Gamma \left(\dfrac{1}{4} \right)}\right)$ I know that the Vardi's Integral can be evaluated in terms of derivatives of Hurwitz Zeta Function. I would like to see a method which uses differentiation under the integral sign.,Prove that: $\displaystyle\int_{\pi/4}^{\pi/2} \ln (\ln(\tan x))dx =\frac{\pi}{2}\ln \left( \frac{\sqrt{2\pi} \Gamma \left(\dfrac{3}{4} \right)}{\Gamma \left(\dfrac{1}{4} \right)}\right)$ I know that the Vardi's Integral can be evaluated in terms of derivatives of Hurwitz Zeta Function. I would like to see a method which uses differentiation under the integral sign.,,['calculus']
70,avoiding calculus,avoiding calculus,,"Some people may carelessly say that you need calculus to find such a thing as a local maximum of $f(x) = x^3 - 20x^2 + 96x$.  Certainly calculus is sufficient , but whether it's necessary is another question. There's a global maximum if you restrict the domain to $[0,8]$, and $f$ is $0$ at the endpoints and positive between them.  Say the maximum is at $x_0$.  One would have $$ \frac{f(x)-f(x_0)}{x-x_0}\begin{cases} >0 & \text{if }x<x_0, \\  <0 & \text{if }x>x_0. \end{cases} $$ This difference quotient is undefined when $x=x_0$, but mere algebra tells us that the numerator factors and we get $$ \frac{(x-x_0)g(x)}{x-x_0} = g(x) $$ where $g(x)$ is a polynomial whose coefficients depend on $x_0$.  Then of course one seeks its zeros since it should change signs at $x_0$. Have we tacitly used the intermediate value theorem, or the extreme value theorem?  To what extent can those be avoided?  Must one say that if there is a maximum point, then it is at a zero of $g(x)$?  And can we say that without the intermediate value theorem?  (At least in the case of this function, I think we stop short of needing the so-called fundamental theorem of algebra to tell us some zeros of $g$ exist!)","Some people may carelessly say that you need calculus to find such a thing as a local maximum of $f(x) = x^3 - 20x^2 + 96x$.  Certainly calculus is sufficient , but whether it's necessary is another question. There's a global maximum if you restrict the domain to $[0,8]$, and $f$ is $0$ at the endpoints and positive between them.  Say the maximum is at $x_0$.  One would have $$ \frac{f(x)-f(x_0)}{x-x_0}\begin{cases} >0 & \text{if }x<x_0, \\  <0 & \text{if }x>x_0. \end{cases} $$ This difference quotient is undefined when $x=x_0$, but mere algebra tells us that the numerator factors and we get $$ \frac{(x-x_0)g(x)}{x-x_0} = g(x) $$ where $g(x)$ is a polynomial whose coefficients depend on $x_0$.  Then of course one seeks its zeros since it should change signs at $x_0$. Have we tacitly used the intermediate value theorem, or the extreme value theorem?  To what extent can those be avoided?  Must one say that if there is a maximum point, then it is at a zero of $g(x)$?  And can we say that without the intermediate value theorem?  (At least in the case of this function, I think we stop short of needing the so-called fundamental theorem of algebra to tell us some zeros of $g$ exist!)",,['calculus']
71,What idea of integration were Newton and Leibniz using?,What idea of integration were Newton and Leibniz using?,,The integral that is taught in calculus courses is the Riemann Integral. Which presumably is named after Bernhard Riemann. But Riemann was born $99$ years after Newton died. So what kind of integration were Newton and Leibniz using? I ask this because we are told that Newtons advisor discovered the Fundamental Theorem of Calculus. But that would require knowledge of integration. So what idea did Newton and Leibniz have of integration if Newton's advisor managed to discover the Fundamental Theorem of Calculus.,The integral that is taught in calculus courses is the Riemann Integral. Which presumably is named after Bernhard Riemann. But Riemann was born years after Newton died. So what kind of integration were Newton and Leibniz using? I ask this because we are told that Newtons advisor discovered the Fundamental Theorem of Calculus. But that would require knowledge of integration. So what idea did Newton and Leibniz have of integration if Newton's advisor managed to discover the Fundamental Theorem of Calculus.,99,"['calculus', 'integration', 'math-history']"
72,Calculate integral $\int_0^{\pi/2} \frac{\cos^3x}{\sin^2x + \cos^3x}dx$.,Calculate integral .,\int_0^{\pi/2} \frac{\cos^3x}{\sin^2x + \cos^3x}dx,"Calculate integral $$\int_0^{\pi/2} \frac{\cos^3x}{\sin^2x + \cos^3x}dx.$$ My direction: Since this integral can't calculate normally, I tried to use the property following: $$\int_{a}^{b}f(x)dx = \int_{a}^{b}f(a+b-x)dx.$$ Then, I have $$I=\int_0^{\pi/2} \frac{\cos^3x}{\sin^2x + \cos^3x}dx = \int_0^{\pi/2} \frac{\sin^3x}{\cos^2x + \sin^3x}dx.$$ Therefore $$2I = \int_0^{\pi/2} \left(\frac{\cos^3x}{\sin^2x + \cos^3x} + \frac{\sin^3x}{\cos^2x + \sin^3x}\right) dx.$$ I stucked here.","Calculate integral My direction: Since this integral can't calculate normally, I tried to use the property following: Then, I have Therefore I stucked here.",\int_0^{\pi/2} \frac{\cos^3x}{\sin^2x + \cos^3x}dx. \int_{a}^{b}f(x)dx = \int_{a}^{b}f(a+b-x)dx. I=\int_0^{\pi/2} \frac{\cos^3x}{\sin^2x + \cos^3x}dx = \int_0^{\pi/2} \frac{\sin^3x}{\cos^2x + \sin^3x}dx. 2I = \int_0^{\pi/2} \left(\frac{\cos^3x}{\sin^2x + \cos^3x} + \frac{\sin^3x}{\cos^2x + \sin^3x}\right) dx.,"['calculus', 'integration', 'definite-integrals', 'trigonometric-integrals']"
73,Finding shortest distance between a point and a surface,Finding shortest distance between a point and a surface,,"Consider the surface $S$ (in $\mathbb R^3$) given by the equation $z=f(x,y)=\frac32(x^2+y^2)$. How can I find the shortest distance from a point $p=(a,b,c)$ on $S$ to the point $(0,0,1)$. This is what I have done: Define $d(a,b,c)=a^2+b^2+(c-1)^2$, for all points $p=(a,b,c)\in S$. Then $\sqrt d$ is the distance from $S$ to $(0,0,1)$. I think that the method of Lagrange multipliers is the easiest way to solve my question, but how can I find the Lagrangian function? Or is there an easier way to find the shortest distance?","Consider the surface $S$ (in $\mathbb R^3$) given by the equation $z=f(x,y)=\frac32(x^2+y^2)$. How can I find the shortest distance from a point $p=(a,b,c)$ on $S$ to the point $(0,0,1)$. This is what I have done: Define $d(a,b,c)=a^2+b^2+(c-1)^2$, for all points $p=(a,b,c)\in S$. Then $\sqrt d$ is the distance from $S$ to $(0,0,1)$. I think that the method of Lagrange multipliers is the easiest way to solve my question, but how can I find the Lagrangian function? Or is there an easier way to find the shortest distance?",,"['calculus', 'multivariable-calculus']"
74,Integration of some floor functions [closed],Integration of some floor functions [closed],,Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 6 months ago . Improve this question Can anyone please answer the following questions ? 1) $\int\left \lfloor{x}\right \rfloor dx$ 2) $\int$ $ \left \lfloor{\sin(x)}\right \rfloor $ $dx$ 3) $\int_0^2$ $\left \lfloor{x^2+x-1}\right \rfloor$ $dx$ 4) $\int_o^\pi$ $\left \lfloor{x(1+\sin(\pi x)}\right \rfloor$ Also can anyone please make me understand the way in which to proceed in these types of sums? $\left \lfloor{x}\right \rfloor$ is the floor function Thanks,Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 6 months ago . Improve this question Can anyone please answer the following questions ? 1) $\int\left \lfloor{x}\right \rfloor dx$ 2) $\int$ $ \left \lfloor{\sin(x)}\right \rfloor $ $dx$ 3) $\int_0^2$ $\left \lfloor{x^2+x-1}\right \rfloor$ $dx$ 4) $\int_o^\pi$ $\left \lfloor{x(1+\sin(\pi x)}\right \rfloor$ Also can anyone please make me understand the way in which to proceed in these types of sums? $\left \lfloor{x}\right \rfloor$ is the floor function Thanks,,"['calculus', 'integration', 'definite-integrals', 'indefinite-integrals', 'ceiling-and-floor-functions']"
75,Proof of $ f(x) = (e^x-1)/x = 1 \text{ as } x\to 0$ using epsilon-delta definition of a limit,Proof of  using epsilon-delta definition of a limit, f(x) = (e^x-1)/x = 1 \text{ as } x\to 0,"I am in calc 1 and we have just learned the epsilon-delta definition of a limit and I (on my own) wanted to try and use this methodology in order to prove $(e^x-1)/x = 1$ (one of the equivalencies), along with $\displaystyle \frac {\sin(x)}{x} = 1$, that the proof just told us ""was so."" I do not know how to put the happy little math symbols in this website so I'm going to upload a picture of my work. Now, I understand how to apply the epsilon-delta definition of the limit for some easy problems, even for some complex functions where the numbers simply ""fall out,"" but what do I do with the the $|f(x)-L|<\epsilon$ after I've made it be $|(e^x-1-x)/x| < \epsilon$? I understand that I basically need to get $|(e^x-1-x)/x|$ to become equivalent to $|x|$ but how do I do this? Is this factorable? And if this kind of easy problem is difficult for me, does this mean that I do have what it takes to become a math major? I really love this kind of problem-solving but sometimes I just don't get the answer. Thanks! http://tinypic.com/r/wiae6f/7 The above is my problem.","I am in calc 1 and we have just learned the epsilon-delta definition of a limit and I (on my own) wanted to try and use this methodology in order to prove $(e^x-1)/x = 1$ (one of the equivalencies), along with $\displaystyle \frac {\sin(x)}{x} = 1$, that the proof just told us ""was so."" I do not know how to put the happy little math symbols in this website so I'm going to upload a picture of my work. Now, I understand how to apply the epsilon-delta definition of the limit for some easy problems, even for some complex functions where the numbers simply ""fall out,"" but what do I do with the the $|f(x)-L|<\epsilon$ after I've made it be $|(e^x-1-x)/x| < \epsilon$? I understand that I basically need to get $|(e^x-1-x)/x|$ to become equivalent to $|x|$ but how do I do this? Is this factorable? And if this kind of easy problem is difficult for me, does this mean that I do have what it takes to become a math major? I really love this kind of problem-solving but sometimes I just don't get the answer. Thanks! http://tinypic.com/r/wiae6f/7 The above is my problem.",,['calculus']
76,"How to proof the following function is always constant which satisfies $f\left( x \right) + a\int_{x - 1}^x {f\left( t \right)\,dt} $?",How to proof the following function is always constant which satisfies ?,"f\left( x \right) + a\int_{x - 1}^x {f\left( t \right)\,dt} ","Suppose that $f(x)$ is a bounded continuous function on $\mathbb{R}$,and that there exists a positive number $a$ such that $$f\left( x \right) + a\int_{x - 1}^x {f\left( t \right)\,dt} $$ is constant. Can anybody show that  $f$ is necessarily constant ?","Suppose that $f(x)$ is a bounded continuous function on $\mathbb{R}$,and that there exists a positive number $a$ such that $$f\left( x \right) + a\int_{x - 1}^x {f\left( t \right)\,dt} $$ is constant. Can anybody show that  $f$ is necessarily constant ?",,"['calculus', 'integration', 'functions']"
77,Integrating $\int \sin^n{x} \ dx$,Integrating,\int \sin^n{x} \ dx,"I am working on trying to solve this problem: Prove: $\int \sin^n{x} \ dx = -\frac{1}{n} \cos{x} \cdot \sin^{n - 1}{x} + \frac{n - 1}{n} \int \sin^{n - 2}{x} \ dx$ Here are the steps that I follow in the example that I am reading: $u = \sin^{n - 1}{x}$ $du = (n - 1) \cdot \sin^{n - 2}{x} \cdot \cos{x} \ dx$ $v = -\cos{x}$ $dv = \sin{x} \ dx$ $\int \sin^n{x} \ dx =  \sin^{n - 1}{x} \cdot \sin{x} \ dx$ $\int \sin^n{x} \ dx = \underbrace{\sin^{n - 1}{x}}_{u} \cdot \underbrace{-\cos{x}}_{v} - \int \underbrace{-\cos{x}}_{v} \cdot \underbrace{(n - 1) \cdot \sin^{n - 2}{x} \cdot \cos{x} \ dx}_{du}$ $\int \sin^n{x} \ dx = -\cos{x} \cdot \sin^{n - 1}{x} + (n - 1)\int \sin^{n - 2}{x} \cdot \cos^{2}{x} \ dx$ $\int \sin^n{x} \ dx = -\cos{x} \cdot \sin^{n - 1}{x} + (n - 1)\int \sin^{n - 2}{x} \cdot \left(1 - \sin^{2}{x}\right) \ dx$ Here is where I get lost. How did we go from $\int \sin^{n - 2}{x} \cdot \left(1 - \sin^{2}{x}\right) \ dx$ to $\int \sin^{n - 2}{x} \ dx - (n - 1) \int \sin^{n}{x} \ dx$? Even more specifically, where did $\sin^{n}{x}$ come from? $\int \sin^n{x} \ dx = -\cos{x} \cdot \sin^{n - 1}{x} + (n - 1)\int \sin^{n - 2}{x} \ dx - (n - 1) \int \sin^{n}{x} \ dx$ I get this part. $n\int \sin^n{x} \ dx = -\cos{x} \cdot \sin^{n - 1}{x} + (n - 1)\int \sin^{n - 2}{x} \ dx$ $\int \sin^n{x} \ dx = -\frac{1}{n} \cos{x} \cdot x \ \sin^{n - 1}{x} + \frac{n - 1}{n} \int \sin^{n - 2}{x} \ dx$ Could someone please explain what I am missing? Thank you for your time.","I am working on trying to solve this problem: Prove: $\int \sin^n{x} \ dx = -\frac{1}{n} \cos{x} \cdot \sin^{n - 1}{x} + \frac{n - 1}{n} \int \sin^{n - 2}{x} \ dx$ Here are the steps that I follow in the example that I am reading: $u = \sin^{n - 1}{x}$ $du = (n - 1) \cdot \sin^{n - 2}{x} \cdot \cos{x} \ dx$ $v = -\cos{x}$ $dv = \sin{x} \ dx$ $\int \sin^n{x} \ dx =  \sin^{n - 1}{x} \cdot \sin{x} \ dx$ $\int \sin^n{x} \ dx = \underbrace{\sin^{n - 1}{x}}_{u} \cdot \underbrace{-\cos{x}}_{v} - \int \underbrace{-\cos{x}}_{v} \cdot \underbrace{(n - 1) \cdot \sin^{n - 2}{x} \cdot \cos{x} \ dx}_{du}$ $\int \sin^n{x} \ dx = -\cos{x} \cdot \sin^{n - 1}{x} + (n - 1)\int \sin^{n - 2}{x} \cdot \cos^{2}{x} \ dx$ $\int \sin^n{x} \ dx = -\cos{x} \cdot \sin^{n - 1}{x} + (n - 1)\int \sin^{n - 2}{x} \cdot \left(1 - \sin^{2}{x}\right) \ dx$ Here is where I get lost. How did we go from $\int \sin^{n - 2}{x} \cdot \left(1 - \sin^{2}{x}\right) \ dx$ to $\int \sin^{n - 2}{x} \ dx - (n - 1) \int \sin^{n}{x} \ dx$? Even more specifically, where did $\sin^{n}{x}$ come from? $\int \sin^n{x} \ dx = -\cos{x} \cdot \sin^{n - 1}{x} + (n - 1)\int \sin^{n - 2}{x} \ dx - (n - 1) \int \sin^{n}{x} \ dx$ I get this part. $n\int \sin^n{x} \ dx = -\cos{x} \cdot \sin^{n - 1}{x} + (n - 1)\int \sin^{n - 2}{x} \ dx$ $\int \sin^n{x} \ dx = -\frac{1}{n} \cos{x} \cdot x \ \sin^{n - 1}{x} + \frac{n - 1}{n} \int \sin^{n - 2}{x} \ dx$ Could someone please explain what I am missing? Thank you for your time.",,"['calculus', 'trigonometry', 'integration']"
78,"Tricky proof of a result of Michael Nielsen's book ""Neural Networks and Deep Learning"".","Tricky proof of a result of Michael Nielsen's book ""Neural Networks and Deep Learning"".",,"In his free online book, ""Neural Networks and Deep Learning"", Michael Nielsen proposes to prove the next result: If $C$ is a cost function which depends on $v_{1}, v_{2}, ..., v_{n}$, he states that we make a move in the $\Delta v$ direction to decrease $C$ as much as possible, and that's equivalent to minimizing $\Delta C \approx \nabla C \cdot \Delta v$. So if $\lvert\lvert\Delta v\rvert\rvert = \epsilon$ for a small $\epsilon$, it can be proved that the choice of $\Delta v$ that minimizes $\Delta C \approx \nabla C \cdot \Delta v$ is $\Delta v = -\eta \nabla C$ where $\eta = \epsilon / \lvert\lvert \nabla C \rvert\rvert$. And he suggests using the Cauchy-Schwarz inequality to prove this. Ok, so what I've done is to minimize with respect to $\Delta v$ an equivalent function $0 = min_{\Delta v} \lvert\lvert \nabla C \Delta v \rvert\rvert^{2} \leq min_{\Delta v}\lvert\lvert \nabla C \rvert\rvert^{2}\lvert\lvert \Delta v\rvert\rvert^{2}$ (using C-S inequality). I would say this is the correct path to prove the result but I'm stuck and can't arrive to the same result. Thanks.","In his free online book, ""Neural Networks and Deep Learning"", Michael Nielsen proposes to prove the next result: If $C$ is a cost function which depends on $v_{1}, v_{2}, ..., v_{n}$, he states that we make a move in the $\Delta v$ direction to decrease $C$ as much as possible, and that's equivalent to minimizing $\Delta C \approx \nabla C \cdot \Delta v$. So if $\lvert\lvert\Delta v\rvert\rvert = \epsilon$ for a small $\epsilon$, it can be proved that the choice of $\Delta v$ that minimizes $\Delta C \approx \nabla C \cdot \Delta v$ is $\Delta v = -\eta \nabla C$ where $\eta = \epsilon / \lvert\lvert \nabla C \rvert\rvert$. And he suggests using the Cauchy-Schwarz inequality to prove this. Ok, so what I've done is to minimize with respect to $\Delta v$ an equivalent function $0 = min_{\Delta v} \lvert\lvert \nabla C \Delta v \rvert\rvert^{2} \leq min_{\Delta v}\lvert\lvert \nabla C \rvert\rvert^{2}\lvert\lvert \Delta v\rvert\rvert^{2}$ (using C-S inequality). I would say this is the correct path to prove the result but I'm stuck and can't arrive to the same result. Thanks.",,"['calculus', 'multivariable-calculus', 'optimization', 'machine-learning', 'neural-networks']"
79,Show bounded and convex function on $\mathbb R$ is constant,Show bounded and convex function on  is constant,\mathbb R,"How can we show that a bounded and convex function on $\mathbb R$ is constant? Derivatives are of no use since the function does not have to differentiable. I saw an answer here I think a while ago but did not understand it at all. Since derivatives are useless, we would have to use the definition and somehow show that the function lies between two values which are equal to each other. But I am unable to progress any further.","How can we show that a bounded and convex function on $\mathbb R$ is constant? Derivatives are of no use since the function does not have to differentiable. I saw an answer here I think a while ago but did not understand it at all. Since derivatives are useless, we would have to use the definition and somehow show that the function lies between two values which are equal to each other. But I am unable to progress any further.",,['calculus']
80,Indefinite Integral $\int\sqrt[3]{\tan(x)}~dx$,Indefinite Integral,\int\sqrt[3]{\tan(x)}~dx,"For calculating $\int\sqrt{\tan(x)}~dx$ , I used this easy method $$\begin{align}\int\sqrt{\tan(x)}~dx&=\frac{1}{2}\int\left(\sqrt{\tan(x)}+\sqrt{\cot(x)}\right)dx+\frac{1}{2}\int\left(\sqrt{\tan(x)}-\sqrt{\cot(x)}\right)dx\\&=\frac{1}{2}\int\frac{\sin(x)+\cos(x)}{\sqrt{\sin(x)\cos(x)}}~dx-\frac{1}{2}\int\frac{\cos(x)-\sin(x)}{\sqrt{\sin(x)\cos(x)}}~dx\\&=\frac{\sqrt{2}}{2}\int\frac{du}{\sqrt{1-u^2}}-\frac{\sqrt{2}}{2}\int\frac{dv}{\sqrt{v^2-1}}.\end{align}$$ $$u=\sin(x)-\cos(x), v=\sin(x)+\cos(x)$$ Does there exist an easy method for $\int\sqrt[3]{\tan(x)}~dx$ ?","For calculating , I used this easy method Does there exist an easy method for ?","\int\sqrt{\tan(x)}~dx \begin{align}\int\sqrt{\tan(x)}~dx&=\frac{1}{2}\int\left(\sqrt{\tan(x)}+\sqrt{\cot(x)}\right)dx+\frac{1}{2}\int\left(\sqrt{\tan(x)}-\sqrt{\cot(x)}\right)dx\\&=\frac{1}{2}\int\frac{\sin(x)+\cos(x)}{\sqrt{\sin(x)\cos(x)}}~dx-\frac{1}{2}\int\frac{\cos(x)-\sin(x)}{\sqrt{\sin(x)\cos(x)}}~dx\\&=\frac{\sqrt{2}}{2}\int\frac{du}{\sqrt{1-u^2}}-\frac{\sqrt{2}}{2}\int\frac{dv}{\sqrt{v^2-1}}.\end{align} u=\sin(x)-\cos(x), v=\sin(x)+\cos(x) \int\sqrt[3]{\tan(x)}~dx","['calculus', 'integration', 'indefinite-integrals', 'substitution']"
81,"Difference between ""undefined"" and ""does not exist""","Difference between ""undefined"" and ""does not exist""",,"What is the difference between the terms ""undefined"" and ""does not exist"", especially in the context of differential calculus? Most calculus materials state, for example, that $\frac{d}{dx}{|x|}$ does not exist at $x = 0$.  Why don't we say that the derivative is undefined at $x = 0$?","What is the difference between the terms ""undefined"" and ""does not exist"", especially in the context of differential calculus? Most calculus materials state, for example, that $\frac{d}{dx}{|x|}$ does not exist at $x = 0$.  Why don't we say that the derivative is undefined at $x = 0$?",,"['calculus', 'terminology']"
82,"Is there a ""continuous product""?","Is there a ""continuous product""?",,"Is there a ""continuous product"" which is the limit of the discrete product $\Pi$ , just like the integral $\int$ is the limit of the summation operator $\sum$ ? Thanks!","Is there a ""continuous product"" which is the limit of the discrete product , just like the integral is the limit of the summation operator ? Thanks!",\Pi \int \sum,"['calculus', 'integration', 'products']"
83,How do I teach university level mathematics to myself? [closed],How do I teach university level mathematics to myself? [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Questions about choosing a course, academic program, career path, etc. are off-topic. Such questions should be directed to those employed by the institution in question, or other qualified individuals who know your specific circumstances. Closed 8 years ago . Improve this question So here I go, I have enrolled myself in maths major this year but due to less marks in SSC I couldn't secure admission in a good university so I have to take admission wherever I could get with my marks. The problems is that teachers here are not qualified enough to teach mathematics properly and they teach horrible. I feel like studying on my would be much better than that. What makes the situation much worse is that most of the students are not at all interested in learning. They abhor it.  But I'm interested in learning mathematics. In fact I love mathematics more than anything else in this world. But I don't know what is the best way to study higher level mathematics on my own. So here are my doubts: Is it possible to study university level mathematics on my own? If yes then how and what are resources that I will need? What are the best resources available on the web? Will I be as proficient in mathematics as the students from top universities who are taught by great teachers? What is the best piece of advice you will give me if I want to get into the field of coding/programming after completing my mathematics major? How do I develop myself overall during these three years in order to become a top notch mathematics student? I'm an average learner and love doing mathematics. The syllabus that I have to cover is : Calculus 2. Elementary Algebra 3. Analytical Geometry 4. Linear and abstract algebra 5. Differential calculus 6. Multivariate Calculus 7. Real and Numerical analysis 8. Probability and Statistics 8. Linear Programming 9. Discrete mathematics and 10. Mathematical modelling Answering this question rigorously will help many out there who are seeking answer to similar question.","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Questions about choosing a course, academic program, career path, etc. are off-topic. Such questions should be directed to those employed by the institution in question, or other qualified individuals who know your specific circumstances. Closed 8 years ago . Improve this question So here I go, I have enrolled myself in maths major this year but due to less marks in SSC I couldn't secure admission in a good university so I have to take admission wherever I could get with my marks. The problems is that teachers here are not qualified enough to teach mathematics properly and they teach horrible. I feel like studying on my would be much better than that. What makes the situation much worse is that most of the students are not at all interested in learning. They abhor it.  But I'm interested in learning mathematics. In fact I love mathematics more than anything else in this world. But I don't know what is the best way to study higher level mathematics on my own. So here are my doubts: Is it possible to study university level mathematics on my own? If yes then how and what are resources that I will need? What are the best resources available on the web? Will I be as proficient in mathematics as the students from top universities who are taught by great teachers? What is the best piece of advice you will give me if I want to get into the field of coding/programming after completing my mathematics major? How do I develop myself overall during these three years in order to become a top notch mathematics student? I'm an average learner and love doing mathematics. The syllabus that I have to cover is : Calculus 2. Elementary Algebra 3. Analytical Geometry 4. Linear and abstract algebra 5. Differential calculus 6. Multivariate Calculus 7. Real and Numerical analysis 8. Probability and Statistics 8. Linear Programming 9. Discrete mathematics and 10. Mathematical modelling Answering this question rigorously will help many out there who are seeking answer to similar question.",,"['calculus', 'linear-algebra', 'probability', 'algebraic-geometry', 'self-learning']"
84,"A Mathematical Coincidence, or more?","A Mathematical Coincidence, or more?",,"According to the paper ""Ten Problems in Experimental Mathematics"" , $$\int_0^\infty \cos(2x)\prod_{n=1}^\infty \cos\left(\frac{x}{n}\right)dx \quad =  \quad \frac{\pi}{8}\color{blue}{-7.407 \times 10^{-43}}$$ The article goes into some detail on how to compute the integral numerically in order to verify that the LHS is not strictly equal to $\pi/8$, but no theoretical explanation is given for why they are so close. The extremely high accuracy to which this relation holds leaves a strong feeling that it is more than a mere ""mathematical coincidence"", in the same sense that it is not a coincidence that $e^{\pi\sqrt{163}}$ is almost an integer . I am looking for an insight that can support that feeling.","According to the paper ""Ten Problems in Experimental Mathematics"" , $$\int_0^\infty \cos(2x)\prod_{n=1}^\infty \cos\left(\frac{x}{n}\right)dx \quad =  \quad \frac{\pi}{8}\color{blue}{-7.407 \times 10^{-43}}$$ The article goes into some detail on how to compute the integral numerically in order to verify that the LHS is not strictly equal to $\pi/8$, but no theoretical explanation is given for why they are so close. The extremely high accuracy to which this relation holds leaves a strong feeling that it is more than a mere ""mathematical coincidence"", in the same sense that it is not a coincidence that $e^{\pi\sqrt{163}}$ is almost an integer . I am looking for an insight that can support that feeling.",,"['calculus', 'improper-integrals']"
85,Who is buried in Weierstrass' tomb?,Who is buried in Weierstrass' tomb?,,"The tangent half-angle substitution often used to anti-differentiate rational functions of sine and cosine, and also sometimes used to find closed-form solutions of some differential equations, is \begin{align} y & = \tan\frac x2 \\[8pt] \dfrac{1-y^2}{1+y^2} & = \cos x \\[8pt] \dfrac{2y}{1+y^2} & = \sin x \\[8pt] \dfrac{2\,dy}{1+y^2} & = dx \end{align} Various books call this the Weierstrass substitution : http://books.google.com/books?id=JkwDOnDRAR8C&q=%22weierstrass+substitution%22&dq=%22weierstrass+substitution%22&hl=en&sa=X&ei=uDe7UbidGMONygHszIGQAw&ved=0CD0Q6AEwAw http://books.google.com/books?id=UG0RlFBqwrgC&pg=PA199&dq=%22weierstrass+substitution%22&hl=en&sa=X&ei=uDe7UbidGMONygHszIGQAw&ved=0CDIQ6AEwAQ#v=onepage&q=%22weierstrass%20substitution%22&f=false http://books.google.com/books?id=0IIsoRqw9hgC&pg=PA105&dq=%22weierstrass+substitution%22&hl=en&sa=X&ei=Bjq7UeOnFrOQyQGbtIGACw&ved=0CEYQ6AEwBA#v=onepage&q=%22weierstrass%20substitution%22&f=false http://books.google.com/books?id=EI4nAQAAIAAJ&q=%22weierstrass+substitution%22&dq=%22weierstrass+substitution%22&hl=en&sa=X&ei=Bjq7UeOnFrOQyQGbtIGACw&ved=0CEoQ6AEwBQ Is there historical evidence that this is due to Weierstrass, i.e. can it be found in something that he wrote?","The tangent half-angle substitution often used to anti-differentiate rational functions of sine and cosine, and also sometimes used to find closed-form solutions of some differential equations, is \begin{align} y & = \tan\frac x2 \\[8pt] \dfrac{1-y^2}{1+y^2} & = \cos x \\[8pt] \dfrac{2y}{1+y^2} & = \sin x \\[8pt] \dfrac{2\,dy}{1+y^2} & = dx \end{align} Various books call this the Weierstrass substitution : http://books.google.com/books?id=JkwDOnDRAR8C&q=%22weierstrass+substitution%22&dq=%22weierstrass+substitution%22&hl=en&sa=X&ei=uDe7UbidGMONygHszIGQAw&ved=0CD0Q6AEwAw http://books.google.com/books?id=UG0RlFBqwrgC&pg=PA199&dq=%22weierstrass+substitution%22&hl=en&sa=X&ei=uDe7UbidGMONygHszIGQAw&ved=0CDIQ6AEwAQ#v=onepage&q=%22weierstrass%20substitution%22&f=false http://books.google.com/books?id=0IIsoRqw9hgC&pg=PA105&dq=%22weierstrass+substitution%22&hl=en&sa=X&ei=Bjq7UeOnFrOQyQGbtIGACw&ved=0CEYQ6AEwBA#v=onepage&q=%22weierstrass%20substitution%22&f=false http://books.google.com/books?id=EI4nAQAAIAAJ&q=%22weierstrass+substitution%22&dq=%22weierstrass+substitution%22&hl=en&sa=X&ei=Bjq7UeOnFrOQyQGbtIGACw&ved=0CEoQ6AEwBQ Is there historical evidence that this is due to Weierstrass, i.e. can it be found in something that he wrote?",,"['calculus', 'math-history']"
86,Simple but difficult to prove inequality involving integrals,Simple but difficult to prove inequality involving integrals,,"Prove that for any smooth function $\phi:\mathbb{R}\rightarrow\mathbb{R}$ such that $\left|\frac{d\phi}{dx}\right|<1$ for all $x$ in $(0,\pi)$, $$\left(\int_0^\pi \cos(\phi(x)) \; dx\right)^2 + \left(\int_0^\pi \sin(\phi(x))\;dx\right)^2 > 4.$$","Prove that for any smooth function $\phi:\mathbb{R}\rightarrow\mathbb{R}$ such that $\left|\frac{d\phi}{dx}\right|<1$ for all $x$ in $(0,\pi)$, $$\left(\int_0^\pi \cos(\phi(x)) \; dx\right)^2 + \left(\int_0^\pi \sin(\phi(x))\;dx\right)^2 > 4.$$",,"['calculus', 'integration']"
87,$2^x - a$ touches $\log_2(x)$,touches,2^x - a \log_2(x),"I was playing around with the functions $2^x$ and $\log_2(x)$. As they are the inversions of each other, I thought there was a simple number $a$ for which $2^x - a$ touches $\log_2(x)$. Using trial-and-error, for $a = 2$ looked like the functions just touched each other, but on closer inspection they did cross each other: at $x = 1$ and at approximately $x = 1.04759$. Zoomed in: Is there an exact solution to $a$ for which $2^x - a$ touches $\log_2(x)$? With ""touches"" I mean that they just touch each other, like a tangent does to a function.","I was playing around with the functions $2^x$ and $\log_2(x)$. As they are the inversions of each other, I thought there was a simple number $a$ for which $2^x - a$ touches $\log_2(x)$. Using trial-and-error, for $a = 2$ looked like the functions just touched each other, but on closer inspection they did cross each other: at $x = 1$ and at approximately $x = 1.04759$. Zoomed in: Is there an exact solution to $a$ for which $2^x - a$ touches $\log_2(x)$? With ""touches"" I mean that they just touch each other, like a tangent does to a function.",,"['calculus', 'logarithms', 'exponentiation']"
88,Substitution Makes the Integral Bounds Equal,Substitution Makes the Integral Bounds Equal,,"This seems like a really basic calculus question, which is a tad embarrassing since I'm a graduate student, but what does it mean when a substitution in a definite integral makes the bounds the same? For example, if we have some function of $\sin(x)$: $$\int_0^{\pi} f(\sin(x)) \,\mathrm{d}x$$ If we make the substitution $u = \sin(x)$, then $du = \cos(x)\,\mathrm{d}x$, we find $$\int_{\sin(0)}^{\sin(\pi)} \frac{f(u)}{\cos(x)} \,\mathrm{d}u  = \int_0^0 \frac{f(u)}{\sqrt{1-u^2}} \,\mathrm{d}u$$ This would imply that the integral is zero. Is this always the case? For another example (more relevant to the problem I'm actually trying to solve) consider $$\int_{-b}^{b} \frac{1}{\sqrt{x^2 + a^2}}\,\mathrm{d}x$$ Clearly this can be solved using a trigonometric substitution to get $2\operatorname{arcsinh}(b)$, but what if I substituted $u = \sqrt{x^2 + a^2}$? Then $$\mathrm{d}u = \frac{x\,\mathrm{d}x}{\sqrt{x^2 + a^2}} \implies \mathrm{d}x = \frac{u\,\mathrm{d}u}{x} = \frac{u\, \mathrm{d}u}{\sqrt{u^2 - a^2}},$$ so the integral becomes $$\int_{\sqrt{b^2 + a^2}}^{\sqrt{b^2 + a^2}}  \frac{1}{\sqrt{u^2 - a^2}}\,\mathrm{d}u$$ This integral seems to be zero, which is not the case for the integral before the substitution. What's going on here? Does this just mean that these substitutions are not valid?","This seems like a really basic calculus question, which is a tad embarrassing since I'm a graduate student, but what does it mean when a substitution in a definite integral makes the bounds the same? For example, if we have some function of $\sin(x)$: $$\int_0^{\pi} f(\sin(x)) \,\mathrm{d}x$$ If we make the substitution $u = \sin(x)$, then $du = \cos(x)\,\mathrm{d}x$, we find $$\int_{\sin(0)}^{\sin(\pi)} \frac{f(u)}{\cos(x)} \,\mathrm{d}u  = \int_0^0 \frac{f(u)}{\sqrt{1-u^2}} \,\mathrm{d}u$$ This would imply that the integral is zero. Is this always the case? For another example (more relevant to the problem I'm actually trying to solve) consider $$\int_{-b}^{b} \frac{1}{\sqrt{x^2 + a^2}}\,\mathrm{d}x$$ Clearly this can be solved using a trigonometric substitution to get $2\operatorname{arcsinh}(b)$, but what if I substituted $u = \sqrt{x^2 + a^2}$? Then $$\mathrm{d}u = \frac{x\,\mathrm{d}x}{\sqrt{x^2 + a^2}} \implies \mathrm{d}x = \frac{u\,\mathrm{d}u}{x} = \frac{u\, \mathrm{d}u}{\sqrt{u^2 - a^2}},$$ so the integral becomes $$\int_{\sqrt{b^2 + a^2}}^{\sqrt{b^2 + a^2}}  \frac{1}{\sqrt{u^2 - a^2}}\,\mathrm{d}u$$ This integral seems to be zero, which is not the case for the integral before the substitution. What's going on here? Does this just mean that these substitutions are not valid?",,"['calculus', 'integration', 'substitution']"
89,Is $\lim\limits_{k \to \infty}\left[ \lim\limits_{p \to \infty} \frac{M}{1+3+5+\cdots+ [2^{p(k-1)}-2^{p(k-2)}-2^{p(k-3)}-\cdots-1]}\right]=1$?,Is ?,\lim\limits_{k \to \infty}\left[ \lim\limits_{p \to \infty} \frac{M}{1+3+5+\cdots+ [2^{p(k-1)}-2^{p(k-2)}-2^{p(k-3)}-\cdots-1]}\right]=1,"Firstly, my $\LaTeX$, Mathematics and English knowledge is very limited. It is extremely difficult for me to ask this question. Now I am improving myself.I hope you understand me... Look at this function: $$f(n) = \begin{cases} n/2 &\text{if } n \equiv 0 \pmod 2 \\ n+1 & \text{if } n\equiv 1 \pmod 2.\end{cases}$$ We know that for any positive number, there is a number $\text{“}k\text{''}$, which that $f^k(n)=1$ For function $f(n)$ go backward from number $1$. Let step number is $k$  $$[2^{\sum_{z=1}^{k-1} m_z}-2^{\sum_{z=2}^{k-1} m_z}-2^{\sum_{z=3}^{k-1} m_z}-\cdots-1]\stackrel{k\to \infty}{\longleftarrow}\mathbf{\cdots} \stackrel{k=5}{\longleftarrow} \mathbf{[2^{m_4+m_3+m_2+m_1}-2^{m_4+m_3+m_2}-2^{m_4+m_3}-2^{m_4}-1]}\stackrel{k=4}{\longleftarrow} \mathbf{[{2^{m_1+m_3+m_2}-2^{m_2+m_3}-2^{m_3}-1}]}\stackrel{k=3}{\longleftarrow} \mathbf{[{2^{m_1+m_2}-2^{m_2}-1}]}\stackrel{k=2}{\longleftarrow} \mathbf{[{2^{m_1}-1}]}\stackrel{k=1}{\longleftarrow} \mathbf1$$ Then, $2^{\sum_{z=1}^{k-1} m_z}-2^{\sum_{z=2}^{k-1} m_z}-2^{\sum_{z=3}^{k-1} m_z}-\cdots-1=F_{10}(m_1,m_2,\ldots,m_{k-1})$ and $2^{\sum_{z=1}^{k-i} m_z}-2^{\sum_{z=2}^{k-i} m_z}-2^{\sum_{z=3}^{k-i} m_z}-\cdots-1 =F_{ij}(m_1,m_2,\ldots,m_{k-i})$ Let, for $\max [F_{10}]$ , we can write $m_1=m_2=m_3=\cdots=m_{k-1}=p \Rightarrow \max[F_{10}]=2^{p(k-1)}-2^{p(k-2)}-2^{p(k-3)}-\cdots-1$ and for each $F_{ij}$ must be $\max [F_{ij}]<\max [F_{10}]$. Then, Let's write all possible sums: $$\sum_{m_{k-1}=1}^p \sum_{m_{k-2}=1}^p\cdots\sum_{m_{1}=1}^p F_{10}(m_1,m_2,\ldots,m_{k-1})+\sum \sum\cdots\sum F_{11}(m_1,m_2,\ldots,m_{k-1})+\sum\sum\cdots\sum F_{12}(m_1,m_2,\ldots,m_{k-1})+\sum\sum\cdots\sum F_{13}(m_1,m_2,\ldots,m_{k-1})+\cdots+\sum\sum\cdots\sum F_{20}(m_1,m_2,\ldots,m_{k-2})+\sum\sum\cdots\sum F_{21}(m_1,m_2,\ldots,m_{k-2})+\sum\sum\cdots\sum F_{22}(m_1,m_2,\ldots,m_{k-2})+\sum\sum\cdots\sum F_{23}(m_1,m_2,\ldots,m_{k-2})+\cdots+\sum\sum\cdots\sum F_{30}(m_1,m_2,\ldots,m_{k-3})+\sum\sum\cdots\sum F_{31}(m_1,m_2,\ldots,m_{k-3})+\sum\sum\cdots\sum F_{32}(m_1,m_2,\ldots,m_{k-3}) +\sum\sum\cdots\sum F_{33}(m_1,m_2,\ldots,m_{k-3}) + \dots + \cdots + \sum_{m_1=1}^{[log_2{(2^{p(k-1)}-2^{p(k-2)}-2^{p(k-3)}-\cdots-1+1)}]} (2^{m_1}-1) = M$$ What is $\sum\sum\cdots\sum F_{ij}(m_1,m_2,\ldots,m_{k-i})$ ? Example: Let,$\sum\sum\cdots\sum F_{11}(m_1,m_2,\ldots,m_{k-1}) = \sum_{m_1=1}^1 \sum_{m_2=1}^1 \cdots \sum_{m_{k-2}=1}^1 \sum_{m_{k-1}=p+1}^{p+1}F_{11}(m_1,m_2,\ldots,m_{k-1})$ which that, $\max [F_{10}]>\max [F_{11}]$ İf $k\to \infty$ and $p\to \infty$ I think $\text{“}M\text{''}$ must be sum of all odd numbers, which that the last number equal to $2^{p(k-1)}-2^{p(k-2)}-2^{p(k-3)}-\cdots-1.$ The Question: Is this limit equal to $1$ ? $$\lim_{k \to \infty}\left[ \lim_{p \to \infty} \frac{M}{1+3+5+7+\cdots+ [2^{p(k-1)} - 2^{p(k-2)}-2^{p(k-3)}-\cdots-1]}\right]=1$$","Firstly, my $\LaTeX$, Mathematics and English knowledge is very limited. It is extremely difficult for me to ask this question. Now I am improving myself.I hope you understand me... Look at this function: $$f(n) = \begin{cases} n/2 &\text{if } n \equiv 0 \pmod 2 \\ n+1 & \text{if } n\equiv 1 \pmod 2.\end{cases}$$ We know that for any positive number, there is a number $\text{“}k\text{''}$, which that $f^k(n)=1$ For function $f(n)$ go backward from number $1$. Let step number is $k$  $$[2^{\sum_{z=1}^{k-1} m_z}-2^{\sum_{z=2}^{k-1} m_z}-2^{\sum_{z=3}^{k-1} m_z}-\cdots-1]\stackrel{k\to \infty}{\longleftarrow}\mathbf{\cdots} \stackrel{k=5}{\longleftarrow} \mathbf{[2^{m_4+m_3+m_2+m_1}-2^{m_4+m_3+m_2}-2^{m_4+m_3}-2^{m_4}-1]}\stackrel{k=4}{\longleftarrow} \mathbf{[{2^{m_1+m_3+m_2}-2^{m_2+m_3}-2^{m_3}-1}]}\stackrel{k=3}{\longleftarrow} \mathbf{[{2^{m_1+m_2}-2^{m_2}-1}]}\stackrel{k=2}{\longleftarrow} \mathbf{[{2^{m_1}-1}]}\stackrel{k=1}{\longleftarrow} \mathbf1$$ Then, $2^{\sum_{z=1}^{k-1} m_z}-2^{\sum_{z=2}^{k-1} m_z}-2^{\sum_{z=3}^{k-1} m_z}-\cdots-1=F_{10}(m_1,m_2,\ldots,m_{k-1})$ and $2^{\sum_{z=1}^{k-i} m_z}-2^{\sum_{z=2}^{k-i} m_z}-2^{\sum_{z=3}^{k-i} m_z}-\cdots-1 =F_{ij}(m_1,m_2,\ldots,m_{k-i})$ Let, for $\max [F_{10}]$ , we can write $m_1=m_2=m_3=\cdots=m_{k-1}=p \Rightarrow \max[F_{10}]=2^{p(k-1)}-2^{p(k-2)}-2^{p(k-3)}-\cdots-1$ and for each $F_{ij}$ must be $\max [F_{ij}]<\max [F_{10}]$. Then, Let's write all possible sums: $$\sum_{m_{k-1}=1}^p \sum_{m_{k-2}=1}^p\cdots\sum_{m_{1}=1}^p F_{10}(m_1,m_2,\ldots,m_{k-1})+\sum \sum\cdots\sum F_{11}(m_1,m_2,\ldots,m_{k-1})+\sum\sum\cdots\sum F_{12}(m_1,m_2,\ldots,m_{k-1})+\sum\sum\cdots\sum F_{13}(m_1,m_2,\ldots,m_{k-1})+\cdots+\sum\sum\cdots\sum F_{20}(m_1,m_2,\ldots,m_{k-2})+\sum\sum\cdots\sum F_{21}(m_1,m_2,\ldots,m_{k-2})+\sum\sum\cdots\sum F_{22}(m_1,m_2,\ldots,m_{k-2})+\sum\sum\cdots\sum F_{23}(m_1,m_2,\ldots,m_{k-2})+\cdots+\sum\sum\cdots\sum F_{30}(m_1,m_2,\ldots,m_{k-3})+\sum\sum\cdots\sum F_{31}(m_1,m_2,\ldots,m_{k-3})+\sum\sum\cdots\sum F_{32}(m_1,m_2,\ldots,m_{k-3}) +\sum\sum\cdots\sum F_{33}(m_1,m_2,\ldots,m_{k-3}) + \dots + \cdots + \sum_{m_1=1}^{[log_2{(2^{p(k-1)}-2^{p(k-2)}-2^{p(k-3)}-\cdots-1+1)}]} (2^{m_1}-1) = M$$ What is $\sum\sum\cdots\sum F_{ij}(m_1,m_2,\ldots,m_{k-i})$ ? Example: Let,$\sum\sum\cdots\sum F_{11}(m_1,m_2,\ldots,m_{k-1}) = \sum_{m_1=1}^1 \sum_{m_2=1}^1 \cdots \sum_{m_{k-2}=1}^1 \sum_{m_{k-1}=p+1}^{p+1}F_{11}(m_1,m_2,\ldots,m_{k-1})$ which that, $\max [F_{10}]>\max [F_{11}]$ İf $k\to \infty$ and $p\to \infty$ I think $\text{“}M\text{''}$ must be sum of all odd numbers, which that the last number equal to $2^{p(k-1)}-2^{p(k-2)}-2^{p(k-3)}-\cdots-1.$ The Question: Is this limit equal to $1$ ? $$\lim_{k \to \infty}\left[ \lim_{p \to \infty} \frac{M}{1+3+5+7+\cdots+ [2^{p(k-1)} - 2^{p(k-2)}-2^{p(k-3)}-\cdots-1]}\right]=1$$",,"['calculus', 'number-theory', 'limits', 'functions', 'summation']"
90,"What are the inverse operations of the ""Partial derivative"" and the ""Total derivative""?","What are the inverse operations of the ""Partial derivative"" and the ""Total derivative""?",,"If a univariate function like $f(x)$ is differentiable, we denote its derivative by $\frac{\mathrm{d} }{\mathrm{d} x}f(x)$ and its integral by $\int f(x)\mathrm{d} x$. If the function happens to be multivariate we denote its ""Partial derivative"" by $\frac{\partial }{\partial x_i}f(x_1,\cdots ,x_i,\cdots ,x_n)$ and its total derivative by $\frac{\mathrm{d} }{\mathrm{d} x_i}f(x_1,\cdots ,x_i,\cdots ,x_n)$. Now this is my question: What are the inverse operations of ""Partial derivative"" and ""Total derivative"" of a multivariate function? Do we have such things as ""Partial Integral"" or ""Total integral"" of a multivariate function? And if this is true, what do we call such ""Partial Integral"" and ""Total integral"" of a multivariate function, and what are the agreed-upon notations for them?","If a univariate function like $f(x)$ is differentiable, we denote its derivative by $\frac{\mathrm{d} }{\mathrm{d} x}f(x)$ and its integral by $\int f(x)\mathrm{d} x$. If the function happens to be multivariate we denote its ""Partial derivative"" by $\frac{\partial }{\partial x_i}f(x_1,\cdots ,x_i,\cdots ,x_n)$ and its total derivative by $\frac{\mathrm{d} }{\mathrm{d} x_i}f(x_1,\cdots ,x_i,\cdots ,x_n)$. Now this is my question: What are the inverse operations of ""Partial derivative"" and ""Total derivative"" of a multivariate function? Do we have such things as ""Partial Integral"" or ""Total integral"" of a multivariate function? And if this is true, what do we call such ""Partial Integral"" and ""Total integral"" of a multivariate function, and what are the agreed-upon notations for them?",,"['calculus', 'multivariable-calculus', 'notation', 'definition', 'inverse']"
91,"Double integral $ \iint \limits_D \frac{y}{x^2+(y+1)^2}dxdy$, $D$=$\{(x,y): x^2+y^2 \le1 , y\ge0\}$","Double integral , ="," \iint \limits_D \frac{y}{x^2+(y+1)^2}dxdy D \{(x,y): x^2+y^2 \le1 , y\ge0\}","Solve $$ \iint \limits_D  \frac{y}{x^2+(y+1)^2}dxdy \ \ \ \ . . . \  (*)$$ where $D$=$\{$$(x,y): x^2+y^2 \le1 ,  y\ge0       $$\}$ $$ $$ Here is my attempt. $$\begin{align} &(1).\ \ \ (*)=\int_{-1}^1  \int_{0}^{\sqrt{1-x^2}}\frac{y}{x^2+(y+1)^2}dydx \\ &(2).\ \ \ (*)= \int_{0}^1  \int_{-\sqrt{1-y^2}}^{\sqrt{1-y^2}}\frac{y}{x^2+(y+1)^2}dxdy \\ &(3). \ \ \int\frac{y+1}{x^2+(y+1)^2}dx = \arctan\left(\frac{x}{y+1}\right) + C  \\ &(4). \ \  \ (*)=\int_{0}^{\pi}  \int_{0}^{1}\frac{r^2sin\theta}{r^2+2rsin\theta+1}drd\theta \\\\ \end{align}$$ I used $(1)$, $(4)$ and $(2)$ with $(3)$, but didn't solve yet. $$$$ Did I make a mistake? Could you give me some advice, please? How can I solve this integral... Thank you for your attention to this matter. $$$$ P.S. Here is result of wolframalpha $$$$ $$ $$ Additionally... I did like this.. maybe useless :-( $$\begin{align} (*)  &  = \int_{0}^1  \int_{-\sqrt{1-y^2}}^{\sqrt{1-y^2}}\frac{y}{x^2+(y+1)^2}dxdy \\\\ &=\int_{0}^1  \int_{-\sqrt{1-y^2}}^{\sqrt{1-y^2}}\frac{y+1}{x^2+(y+1)^2}dxdy + \int_{0}^1  \int_{-\sqrt{1-y^2}}^{\sqrt{1-y^2}}\frac{1}{x^2+(y+1)^2}dxdy \\\\ &=\int_{0}^1  \left(\arctan\left(\frac{\sqrt{1-y^2}}{y+1}\right) - \arctan\left(\frac{-\sqrt{1-y^2}}{y+1}\right)\right)dy \\  & \ \ \ \ + \int_{0}^1 \int_{-\sqrt{1-y^2}}^{\sqrt{1-y^2}}\frac{1}{x^2+(y+1)^2}dxdy  \\\\ &=\int_{0}^1  \left(\arctan\left(\sqrt\frac{1-y}{1+y} \ \right) - \arctan\left(-\sqrt\frac{1-y}{1+y} \ \right)\right)dy \\ & \ \ \ \ +\int_{0}^1 \int_{-\sqrt{1-y^2}}^{\sqrt{1-y^2}}\frac{1}{x^2+(y+1)^2}dxdy \\\\ &= terrible?!   \\ \end{align}$$ $$ $$ $$ $$ --------------------------------------------------------------------------- This picture is for asking to Christian Blatter (I am really sorry, if I bother you guys for this picture.)","Solve $$ \iint \limits_D  \frac{y}{x^2+(y+1)^2}dxdy \ \ \ \ . . . \  (*)$$ where $D$=$\{$$(x,y): x^2+y^2 \le1 ,  y\ge0       $$\}$ $$ $$ Here is my attempt. $$\begin{align} &(1).\ \ \ (*)=\int_{-1}^1  \int_{0}^{\sqrt{1-x^2}}\frac{y}{x^2+(y+1)^2}dydx \\ &(2).\ \ \ (*)= \int_{0}^1  \int_{-\sqrt{1-y^2}}^{\sqrt{1-y^2}}\frac{y}{x^2+(y+1)^2}dxdy \\ &(3). \ \ \int\frac{y+1}{x^2+(y+1)^2}dx = \arctan\left(\frac{x}{y+1}\right) + C  \\ &(4). \ \  \ (*)=\int_{0}^{\pi}  \int_{0}^{1}\frac{r^2sin\theta}{r^2+2rsin\theta+1}drd\theta \\\\ \end{align}$$ I used $(1)$, $(4)$ and $(2)$ with $(3)$, but didn't solve yet. $$$$ Did I make a mistake? Could you give me some advice, please? How can I solve this integral... Thank you for your attention to this matter. $$$$ P.S. Here is result of wolframalpha $$$$ $$ $$ Additionally... I did like this.. maybe useless :-( $$\begin{align} (*)  &  = \int_{0}^1  \int_{-\sqrt{1-y^2}}^{\sqrt{1-y^2}}\frac{y}{x^2+(y+1)^2}dxdy \\\\ &=\int_{0}^1  \int_{-\sqrt{1-y^2}}^{\sqrt{1-y^2}}\frac{y+1}{x^2+(y+1)^2}dxdy + \int_{0}^1  \int_{-\sqrt{1-y^2}}^{\sqrt{1-y^2}}\frac{1}{x^2+(y+1)^2}dxdy \\\\ &=\int_{0}^1  \left(\arctan\left(\frac{\sqrt{1-y^2}}{y+1}\right) - \arctan\left(\frac{-\sqrt{1-y^2}}{y+1}\right)\right)dy \\  & \ \ \ \ + \int_{0}^1 \int_{-\sqrt{1-y^2}}^{\sqrt{1-y^2}}\frac{1}{x^2+(y+1)^2}dxdy  \\\\ &=\int_{0}^1  \left(\arctan\left(\sqrt\frac{1-y}{1+y} \ \right) - \arctan\left(-\sqrt\frac{1-y}{1+y} \ \right)\right)dy \\ & \ \ \ \ +\int_{0}^1 \int_{-\sqrt{1-y^2}}^{\sqrt{1-y^2}}\frac{1}{x^2+(y+1)^2}dxdy \\\\ &= terrible?!   \\ \end{align}$$ $$ $$ $$ $$ --------------------------------------------------------------------------- This picture is for asking to Christian Blatter (I am really sorry, if I bother you guys for this picture.)",,"['calculus', 'integration', 'multivariable-calculus', 'definite-integrals']"
92,Converge or diverge? : $\sum_{n=1}^{\infty}\frac{\tan{n}}{2^{n}}$,Converge or diverge? :,\sum_{n=1}^{\infty}\frac{\tan{n}}{2^{n}},"Determine this series converge or diverge, and if it converges, find its value. $$\sum_{n=1}^{\infty}\frac{\tan{n}}{2^{n}}$$ This was too hard for me, as unboundedness of $\tan{x}$ at infinite number of poles make harder to guess the behavior of value of tangent function at positive integers. Thanks.","Determine this series converge or diverge, and if it converges, find its value. $$\sum_{n=1}^{\infty}\frac{\tan{n}}{2^{n}}$$ This was too hard for me, as unboundedness of $\tan{x}$ at infinite number of poles make harder to guess the behavior of value of tangent function at positive integers. Thanks.",,"['calculus', 'sequences-and-series']"
93,Showing that $ \int_{0}^{\pi/2}\frac{1}{\sqrt{\sin{x}}}\;{dx}=\int_{0}^{\pi/2}\frac{2}{\sqrt{2-\sin^2{x}}}\;{dx}?$,Showing that, \int_{0}^{\pi/2}\frac{1}{\sqrt{\sin{x}}}\;{dx}=\int_{0}^{\pi/2}\frac{2}{\sqrt{2-\sin^2{x}}}\;{dx}?,"How can we show that $ \displaystyle \int_{0}^{\pi/2}\frac{1}{\sqrt{\sin{x}}}\;{dx}=\int_{0}^{\pi/2}\frac{2}{\sqrt{2-\sin^2{x}}}\;{dx}? $ It feels like it should be simple, but I've tried many things and no luck.","How can we show that $ \displaystyle \int_{0}^{\pi/2}\frac{1}{\sqrt{\sin{x}}}\;{dx}=\int_{0}^{\pi/2}\frac{2}{\sqrt{2-\sin^2{x}}}\;{dx}? $ It feels like it should be simple, but I've tried many things and no luck.",,"['calculus', 'integration', 'definite-integrals']"
94,Solving $\int_0^1\log^2(1-x)\log^2(1+x)dx$,Solving,\int_0^1\log^2(1-x)\log^2(1+x)dx,"I came across this problem in the book (Almost) Impossible Integrals, Sums and Series Problem 1.8 $$\int_0^1\log^2(1-x)\log^2(1+x)dx=24-8\zeta(2)-8\zeta(3)-\zeta(4)+8\log2\zeta(2)-4\log^22\zeta(2)+8\log2\zeta(3)-24\log2+12\log^22-4\log^32+\log^42$$ In the book, this has been solved by using Beta Function. It is said that it can also be solved by the following method, although the solution is not provided. $A=\log(1-x)$ $B=\log(1+x)$ So, $A^2B^2=\dfrac{1}{12}\left[(A+B)^4+(A-B)^4-2A^4-2B^4\right]$ Hence, we can write the integral as $$\int_0^1\log^2(1-x)\log^2(1+x)dx=\dfrac{1}{12}\underbrace{\int_0^1\log^4(1-x^2)dx}_{I_1}+\dfrac{1}{12}\underbrace{\int_0^1\log^4\left(\dfrac{1-x}{1+x}\right)dx}_{I_2}-\dfrac{1}{6}\underbrace{\int_0^1\log^4(1-x)dx}_{I_3}-\dfrac{1}{6}\underbrace{\int_0^1\log^4(1+x)dx}_{I_4}$$ I am able to solve $I_3$ and $I_4$ but am stuck in the first two integrals. Can these be solved without using the beta function? Edit- The solutions found till now are $$I_2=42\zeta(4)$$ $$I_3=24$$ $$I_4=2\log^42-8\log^32+24\log^22-48\log2+24$$ A solution is provided in book, although I couldn't really get it.","I came across this problem in the book (Almost) Impossible Integrals, Sums and Series Problem 1.8 In the book, this has been solved by using Beta Function. It is said that it can also be solved by the following method, although the solution is not provided. So, Hence, we can write the integral as I am able to solve and but am stuck in the first two integrals. Can these be solved without using the beta function? Edit- The solutions found till now are A solution is provided in book, although I couldn't really get it.",\int_0^1\log^2(1-x)\log^2(1+x)dx=24-8\zeta(2)-8\zeta(3)-\zeta(4)+8\log2\zeta(2)-4\log^22\zeta(2)+8\log2\zeta(3)-24\log2+12\log^22-4\log^32+\log^42 A=\log(1-x) B=\log(1+x) A^2B^2=\dfrac{1}{12}\left[(A+B)^4+(A-B)^4-2A^4-2B^4\right] \int_0^1\log^2(1-x)\log^2(1+x)dx=\dfrac{1}{12}\underbrace{\int_0^1\log^4(1-x^2)dx}_{I_1}+\dfrac{1}{12}\underbrace{\int_0^1\log^4\left(\dfrac{1-x}{1+x}\right)dx}_{I_2}-\dfrac{1}{6}\underbrace{\int_0^1\log^4(1-x)dx}_{I_3}-\dfrac{1}{6}\underbrace{\int_0^1\log^4(1+x)dx}_{I_4} I_3 I_4 I_2=42\zeta(4) I_3=24 I_4=2\log^42-8\log^32+24\log^22-48\log2+24,"['calculus', 'integration', 'definite-integrals']"
95,"What algorithm is Newton using in the ""De analysi"" to extract the square root of a polynomial?","What algorithm is Newton using in the ""De analysi"" to extract the square root of a polynomial?",,"I'm reading a 1745 English translation of Newton's De analysi (apparently the most up-to-date there is, surprisingly). The Latin is here . In this tract he shows how to use the integral power rule for rational exponents (together with a sum rule: the area under a sum of curves being the sum of the areas) to find quadratures, and he gives examples in three types of how to deal with the case of integrating $y$ when it is not a polynomial: examples using long division e.g. $y=a^2/(b+x)$ , examples using the extraction of square roots e.g. $y=\sqrt{a^2+x^2}$ , and examples using ""the resolution of affected equations"" when $y$ is defined implicitly via a polynomial $f(x,y)=0$ . For the second example, $y=\sqrt{a^2+x^2}$ , he uses an algorithm to extract the root, but I don't recognize the algorithm. Here's an image: Note that Newton is not applying his binomial series: he is doing something else. I realize this is equivalent to the following procedure. Assume $y=\sum b_ix^i$ and we are given $y^2=\sum a_ix^i$ ; the goal is to solve for the $b_i$ . Using the Cauchy product, squaring the first equation gives $y^2=\sum c_ix^i$ where $c_i=\sum_{k=0}^ib_kb_{i-k}$ . Pattern matching the coefficients $c_i=a_i$ allows us to recursively solve for the $b_i$ , because $c_i$ is the first term to use $b_i$ . Thus $$c_0=b_0^2$$ $$c_1=2b_0b_1$$ $$c_2=2b_0b_2+b_1^2$$ $$c_3=2b_0b_3+2b_1b_2$$ $$c_4=2b_0b_4+2b_1b_3+b_2^2$$ etc. But Newton is clearly doing something else: drawing on some established algorithm with a visual representation. I don't think it's his algorithm. So: Three Questions How does the algorithm work? Does the algorithm have a name? Who first used the algorithm? EDITED After puzzling it out a little, I at least see the answer to my first question. Here is the procedure applied to $\sqrt{a^2+x^2}$ . Step 1: Guess $a$ . Store this as the latest estimate $S_0$ . Step 2: Square, giving $a^2$ , then subtract from the radicand: $x^2$ . Store this as the latest remainder $R_0$ . Step 3: Update $S_i$ to $S_{i+1}$ by adding a term $y_i$ to $S_i$ so that $2y_iS_0$ agrees with the lowest-degree term of $R_i$ . In this case, we want to add $y_0$ so that the lowest-degree term of $2y_0a$ agrees with $x^2$ . Hence $y_0=x^2/2a$ . The estimate $S_0$ is thus updated to $S_1=a+x^2/2a$ . Step 4: Multiply $y_i$ by $(2S_i+y_i)$ , then subtract from the last remainder and store the result as the latest remainder $R_{i+1}$ . In this case, we multiply $x^2/2a$ by $(2a+x^2/2a)$ , giving $x^2+x^4/4a^2$ . Subtracting from the last remainder gives $-x^4/4a^2$ . Step 5: Repeat steps 3/4. Just to illustrate for the next term, we want to add $y$ to that $2ya=-x^4/4a^2$ . Thus we add $y=-x^4/8a^3$ and the estimate is updated to $a+x^2/2a-x^4/8a^3$ . Now we multiply $$-\frac{x^4}{8a^3}\left(2\left(a+\frac{x^2}{2a}\right)-\frac{x^4}{8a^3}\right)=-\frac{x^4}{4a^2}-\frac{x^6}{8a^4}+\frac{x^8}{64a^6}$$ Subtracting from the previous remainder $-x^4/4a^2$ yields the new remainder $$\frac{x^6}{8a^4}-\frac{x^8}{64a^6}$$ and so on.","I'm reading a 1745 English translation of Newton's De analysi (apparently the most up-to-date there is, surprisingly). The Latin is here . In this tract he shows how to use the integral power rule for rational exponents (together with a sum rule: the area under a sum of curves being the sum of the areas) to find quadratures, and he gives examples in three types of how to deal with the case of integrating when it is not a polynomial: examples using long division e.g. , examples using the extraction of square roots e.g. , and examples using ""the resolution of affected equations"" when is defined implicitly via a polynomial . For the second example, , he uses an algorithm to extract the root, but I don't recognize the algorithm. Here's an image: Note that Newton is not applying his binomial series: he is doing something else. I realize this is equivalent to the following procedure. Assume and we are given ; the goal is to solve for the . Using the Cauchy product, squaring the first equation gives where . Pattern matching the coefficients allows us to recursively solve for the , because is the first term to use . Thus etc. But Newton is clearly doing something else: drawing on some established algorithm with a visual representation. I don't think it's his algorithm. So: Three Questions How does the algorithm work? Does the algorithm have a name? Who first used the algorithm? EDITED After puzzling it out a little, I at least see the answer to my first question. Here is the procedure applied to . Step 1: Guess . Store this as the latest estimate . Step 2: Square, giving , then subtract from the radicand: . Store this as the latest remainder . Step 3: Update to by adding a term to so that agrees with the lowest-degree term of . In this case, we want to add so that the lowest-degree term of agrees with . Hence . The estimate is thus updated to . Step 4: Multiply by , then subtract from the last remainder and store the result as the latest remainder . In this case, we multiply by , giving . Subtracting from the last remainder gives . Step 5: Repeat steps 3/4. Just to illustrate for the next term, we want to add to that . Thus we add and the estimate is updated to . Now we multiply Subtracting from the previous remainder yields the new remainder and so on.","y y=a^2/(b+x) y=\sqrt{a^2+x^2} y f(x,y)=0 y=\sqrt{a^2+x^2} y=\sum b_ix^i y^2=\sum a_ix^i b_i y^2=\sum c_ix^i c_i=\sum_{k=0}^ib_kb_{i-k} c_i=a_i b_i c_i b_i c_0=b_0^2 c_1=2b_0b_1 c_2=2b_0b_2+b_1^2 c_3=2b_0b_3+2b_1b_2 c_4=2b_0b_4+2b_1b_3+b_2^2 \sqrt{a^2+x^2} a S_0 a^2 x^2 R_0 S_i S_{i+1} y_i S_i 2y_iS_0 R_i y_0 2y_0a x^2 y_0=x^2/2a S_0 S_1=a+x^2/2a y_i (2S_i+y_i) R_{i+1} x^2/2a (2a+x^2/2a) x^2+x^4/4a^2 -x^4/4a^2 y 2ya=-x^4/4a^2 y=-x^4/8a^3 a+x^2/2a-x^4/8a^3 -\frac{x^4}{8a^3}\left(2\left(a+\frac{x^2}{2a}\right)-\frac{x^4}{8a^3}\right)=-\frac{x^4}{4a^2}-\frac{x^6}{8a^4}+\frac{x^8}{64a^6} -x^4/4a^2 \frac{x^6}{8a^4}-\frac{x^8}{64a^6}","['calculus', 'sequences-and-series', 'algorithms', 'radicals', 'math-history']"
96,Understanding the definition of a set with $C^k$ boundary and of the outward pointing normal vector field,Understanding the definition of a set with  boundary and of the outward pointing normal vector field,C^k,"Consider the following excerpt from Evans book. I don't understand these definitions. Can some please illustrate them on an example , so that I can figure out how to work with them. A negative example may be more illustrative, i.e. a set $U$ such that $\partial U$ isn't $ C^1$. Especially the second definition is unclear to me, since $\nu^i$ is nowhere actually defined.","Consider the following excerpt from Evans book. I don't understand these definitions. Can some please illustrate them on an example , so that I can figure out how to work with them. A negative example may be more illustrative, i.e. a set $U$ such that $\partial U$ isn't $ C^1$. Especially the second definition is unclear to me, since $\nu^i$ is nowhere actually defined.",,['calculus']
97,Convergence of power towers,Convergence of power towers,,"Let's define the sequence $\{s_n\}$ recursively as $$s_1=\sqrt2,\ \ \ s_{n+1}=\sqrt2^{\,s_n}.$$ Or, in other words, $$s_n=\underbrace{\sqrt2^{\sqrt2^{\ .^{\ .^{\ .^{\sqrt2}}}}}}_{n\ \text{levels}}.$$ The sequence is monotonically growing, and rapidly converges to a limit $$\lim\limits_{n\to\infty}s_n=2.$$ I'm interested in estimating its convergence speed. Based on numerical data, I conjectured that $$\ln\left(2-s_n\right)=n\ln\ln2+c_{\sqrt2}+O\big(\left(\ln2\right)^n\big)$$ for some constant $c_{\sqrt2}\approx-0.458709787761420587059021...$ Could you suggest possible approaches to prove (or refute) this conjecture? I am also interested in a possible closed form of the constant $c_{\sqrt2}$. Update: We can try to generalize this problem to other bases beyond $\sqrt2$. Let's use a usual notation for tetration $${^n}a=\underbrace{a^{a^{\ .^{\ .^{\ .^a}}}}}_{n\ \text{levels}}.$$ It's known that for all $1/e^e<a<e^{1/e}$ there exists a limit$${^\infty}a=\lim\limits_{n\to\infty}{^n}a=e^{-W\left(-\ln a\right)},$$ where $W(z)$ is the Lambert $W$ function , the inverse of the function $x\mapsto x\,e^x$. I conjecture that for all $1<a<e^{1/e}$ $$\ln\left({^\infty}a-{^n}a\right)=n \ln\ln\left({^\infty}a\right)+c_a+O\left(e^{n\ln\ln\left({^\infty}a\right)}\right),$$ where $c_a$ is some constant that depends on $a$ but not on $n$ (also note that $\ln\ln\left({^\infty}a\right)<0$, so the last term is exponentially small).","Let's define the sequence $\{s_n\}$ recursively as $$s_1=\sqrt2,\ \ \ s_{n+1}=\sqrt2^{\,s_n}.$$ Or, in other words, $$s_n=\underbrace{\sqrt2^{\sqrt2^{\ .^{\ .^{\ .^{\sqrt2}}}}}}_{n\ \text{levels}}.$$ The sequence is monotonically growing, and rapidly converges to a limit $$\lim\limits_{n\to\infty}s_n=2.$$ I'm interested in estimating its convergence speed. Based on numerical data, I conjectured that $$\ln\left(2-s_n\right)=n\ln\ln2+c_{\sqrt2}+O\big(\left(\ln2\right)^n\big)$$ for some constant $c_{\sqrt2}\approx-0.458709787761420587059021...$ Could you suggest possible approaches to prove (or refute) this conjecture? I am also interested in a possible closed form of the constant $c_{\sqrt2}$. Update: We can try to generalize this problem to other bases beyond $\sqrt2$. Let's use a usual notation for tetration $${^n}a=\underbrace{a^{a^{\ .^{\ .^{\ .^a}}}}}_{n\ \text{levels}}.$$ It's known that for all $1/e^e<a<e^{1/e}$ there exists a limit$${^\infty}a=\lim\limits_{n\to\infty}{^n}a=e^{-W\left(-\ln a\right)},$$ where $W(z)$ is the Lambert $W$ function , the inverse of the function $x\mapsto x\,e^x$. I conjecture that for all $1<a<e^{1/e}$ $$\ln\left({^\infty}a-{^n}a\right)=n \ln\ln\left({^\infty}a\right)+c_a+O\left(e^{n\ln\ln\left({^\infty}a\right)}\right),$$ where $c_a$ is some constant that depends on $a$ but not on $n$ (also note that $\ln\ln\left({^\infty}a\right)<0$, so the last term is exponentially small).",,"['calculus', 'sequences-and-series', 'convergence-divergence', 'asymptotics', 'power-towers']"
98,"Functions for which $\int f(g(x))\, \mathrm dx = f\left(\int g(x) \, dx\right)$",Functions for which,"\int f(g(x))\, \mathrm dx = f\left(\int g(x) \, dx\right)","I was playing around with some integrals, and this question popped into my head: What functions exist such that the following is true?   $$\int f(g(x))\;\mathrm dx = f\left(\int g(x)\;\mathrm dx\right)$$ There there's the obvious example of $f(x) = x, \;g(x)=e^x$, but I was wondering if others exist. EDIT 1: As pointed out in the comments, this is true for any $g$ if $f(x) = x$. But, this is sort of trivial--I'd really like to know about for other assignments of $f$... :) My question is twofold: Are there known functions that satisfy this equality? What sort of topic in math would this fall under?  (e.g. Abstract Algebra, Differential/Integral equations, etc.) EDIT 2: I'd also accept an answer to a similar, but slightly different question, as phrased in the comments by user1551; if it's easier/more feasible to answer: Find a pair of functions $f$ and $g$ such that $\int_a^b f(g(x))dx=f\left(\int_a^bg(x)dx\right)$ for any interval $[a,b]$","I was playing around with some integrals, and this question popped into my head: What functions exist such that the following is true?   $$\int f(g(x))\;\mathrm dx = f\left(\int g(x)\;\mathrm dx\right)$$ There there's the obvious example of $f(x) = x, \;g(x)=e^x$, but I was wondering if others exist. EDIT 1: As pointed out in the comments, this is true for any $g$ if $f(x) = x$. But, this is sort of trivial--I'd really like to know about for other assignments of $f$... :) My question is twofold: Are there known functions that satisfy this equality? What sort of topic in math would this fall under?  (e.g. Abstract Algebra, Differential/Integral equations, etc.) EDIT 2: I'd also accept an answer to a similar, but slightly different question, as phrased in the comments by user1551; if it's easier/more feasible to answer: Find a pair of functions $f$ and $g$ such that $\int_a^b f(g(x))dx=f\left(\int_a^bg(x)dx\right)$ for any interval $[a,b]$",,"['calculus', 'functions', 'integration']"
99,Need help with $\int_0^\infty\frac{e^{-x}}{\sqrt[3]2+\cos x}dx$,Need help with,\int_0^\infty\frac{e^{-x}}{\sqrt[3]2+\cos x}dx,Please help me to evaluate this integral: $$\int_0^\infty\frac{e^{-x}}{\sqrt[3]2+\cos x}dx$$,Please help me to evaluate this integral: $$\int_0^\infty\frac{e^{-x}}{\sqrt[3]2+\cos x}dx$$,,"['calculus', 'integration', 'definite-integrals', 'improper-integrals', 'closed-form']"
