,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,What are some neat ways to differentiate $\arctan(\frac yx)$?,What are some neat ways to differentiate ?,\arctan(\frac yx),"By choosing the branch cut to be the line $\gamma=\{it\in \Bbb C: t\le 0\}$ , we can write the complex logarithm as $$\text{Log}(z) = \log(|z|) + i\arg(z),$$ where $\arg(z) \in (-\pi,\pi].$ As a function of $x$ and $y$ (in $z=x+iy)$ , we write $$ \arg(z) = \arctan\left(\frac yx\right). $$ How do we rigorously justify the following equalities $$\begin{align} \partial_x \left(\arctan\left(\frac yx\right)\right) &= \frac{-y}{x^2+y^2}, \\ \partial_y \left(\arctan\left(\frac yx\right)\right) &= \frac{x}{x^2+y^2}? \end{align}$$ I usually see the above expressions come up when one want to show that the Cauchy-Riemann equations holds for $f(z) = \text{Log}(z)$ . We can blindly apply the chain rule the get the answer but that is not rigorous because for $x=0$ the fraction $\frac yx$ is undefined. To make it rigorous, we can rather write $\arg(z) = A(x,y)$ where $$ A(x,y) = \begin{cases} \arctan\left(\frac yx\right) &; x\ne 0 \\ \pi/2 &;x=0, y>0 \\ -\pi/2 &; x=0, y<0 \end{cases} $$ and compute the derivatives of this function carefully case by case instead but I find this method to be troublesome. Is there a neat way to get the result without having to consider $x=0$ as a separated case?","By choosing the branch cut to be the line , we can write the complex logarithm as where As a function of and (in , we write How do we rigorously justify the following equalities I usually see the above expressions come up when one want to show that the Cauchy-Riemann equations holds for . We can blindly apply the chain rule the get the answer but that is not rigorous because for the fraction is undefined. To make it rigorous, we can rather write where and compute the derivatives of this function carefully case by case instead but I find this method to be troublesome. Is there a neat way to get the result without having to consider as a separated case?","\gamma=\{it\in \Bbb C: t\le 0\} \text{Log}(z) = \log(|z|) + i\arg(z), \arg(z) \in (-\pi,\pi]. x y z=x+iy) 
\arg(z) = \arctan\left(\frac yx\right).
 \begin{align}
\partial_x \left(\arctan\left(\frac yx\right)\right) &= \frac{-y}{x^2+y^2}, \\
\partial_y \left(\arctan\left(\frac yx\right)\right) &= \frac{x}{x^2+y^2}?
\end{align} f(z) = \text{Log}(z) x=0 \frac yx \arg(z) = A(x,y) 
A(x,y) = \begin{cases} \arctan\left(\frac yx\right) &; x\ne 0 \\
\pi/2 &;x=0, y>0 \\
-\pi/2 &; x=0, y<0
\end{cases}
 x=0","['real-analysis', 'complex-analysis', 'multivariable-calculus', 'complex-numbers']"
1,Showing $\int_{-\infty}^{\infty}\frac{\sin^2(\omega)}{\omega^2}d\omega=\pi$,Showing,\int_{-\infty}^{\infty}\frac{\sin^2(\omega)}{\omega^2}d\omega=\pi,"Given the function $f$ with $f(t)=1$ for $|t|<1$ and $f(t)=0$ otherwise, I have to calculate its Fourier-transform, the convolution of $f$ with itself and from that I have to show that $$\int_{-\infty}^{\infty}\frac{\sin^2(\omega)}{\omega^2}d\omega=\pi$$ and $$\int_{-\infty}^{\infty}\frac{\sin^4(\omega)}{\omega^4}d\omega =\frac{2\pi}{3}$$ ( $\tilde{f}(\omega)=\frac{1}{\sqrt{2\pi}}$$\int_{-t}^{t}1\cdot  e^{-i\omega t}dt$ be the Fourier-transform of $f$ ) For the first two parts I have: $\tilde{f}(\omega)=\frac{2}{\sqrt{2\pi}}\frac{\sin(\omega t)}{\omega}$ and $(f*f)(\omega)=\frac{2}{\pi}\frac{\sin^2(\omega t)}{\omega^2}$ . But from here I dont know how to compute the integrals. My idea for the first one was using Fourier-Inversion of $(f*f)$ and then putting $t=1$ . But that gives me $0$ for the integral. Does someone has another idea? I would be grateful for any hint or advice! Thank you.","Given the function with for and otherwise, I have to calculate its Fourier-transform, the convolution of with itself and from that I have to show that and ( be the Fourier-transform of ) For the first two parts I have: and . But from here I dont know how to compute the integrals. My idea for the first one was using Fourier-Inversion of and then putting . But that gives me for the integral. Does someone has another idea? I would be grateful for any hint or advice! Thank you.","f f(t)=1 |t|<1 f(t)=0 f \int_{-\infty}^{\infty}\frac{\sin^2(\omega)}{\omega^2}d\omega=\pi \int_{-\infty}^{\infty}\frac{\sin^4(\omega)}{\omega^4}d\omega
=\frac{2\pi}{3} \tilde{f}(\omega)=\frac{1}{\sqrt{2\pi}}\int_{-t}^{t}1\cdot 
e^{-i\omega t}dt f \tilde{f}(\omega)=\frac{2}{\sqrt{2\pi}}\frac{\sin(\omega t)}{\omega} (f*f)(\omega)=\frac{2}{\pi}\frac{\sin^2(\omega t)}{\omega^2} (f*f) t=1 0","['real-analysis', 'complex-analysis', 'fourier-analysis', 'fourier-series', 'fourier-transform']"
2,How to represent $\sum\limits_{n=0}^\infty a_{kn}z^{kn}$ in terms of $f(z) = \sum\limits_{n=0}^\infty a_{n}z^{n}$,How to represent  in terms of,\sum\limits_{n=0}^\infty a_{kn}z^{kn} f(z) = \sum\limits_{n=0}^\infty a_{n}z^{n},"Given a power series $f(z) = \sum\limits_{n=0}^\infty a_nz^{n}$ where $z\in \mathbb{C}$ and radius of convergence $R.$ Then my goal is to find, $$\sum_{n=0}^\infty a_{kn}z^{kn}$$ for $|z|<R$ and $k\in \mathbb{N}.$ So I tried two examples and I think there is a connection with roots of unity. \begin{align*} \sum_{n=0}^\infty a_{2n}z^{2n} &=\frac{1}{2}(f(z)+f(i^2z))\\ \sum_{n=0}^\infty a_{3n}z^{3n} &=\frac{1}{2}(f(z)+f(iz) + f(i^2z)) \end{align*} My guess is that $$\sum_{n=0}^\infty a_{kn}z^{kn} =\frac{1}{2}(f(z)+f(iz) + f(i^2z)+ \cdots + f(i^{k-1}z))$$ if $k$ is odd. For $k$ even I am not sure. Any generalizations of this fact or proof ideas will be much appreciated.","Given a power series where and radius of convergence Then my goal is to find, for and So I tried two examples and I think there is a connection with roots of unity. My guess is that if is odd. For even I am not sure. Any generalizations of this fact or proof ideas will be much appreciated.","f(z) = \sum\limits_{n=0}^\infty a_nz^{n} z\in \mathbb{C} R. \sum_{n=0}^\infty a_{kn}z^{kn} |z|<R k\in \mathbb{N}. \begin{align*}
\sum_{n=0}^\infty a_{2n}z^{2n} &=\frac{1}{2}(f(z)+f(i^2z))\\
\sum_{n=0}^\infty a_{3n}z^{3n} &=\frac{1}{2}(f(z)+f(iz) + f(i^2z))
\end{align*} \sum_{n=0}^\infty a_{kn}z^{kn} =\frac{1}{2}(f(z)+f(iz) + f(i^2z)+ \cdots + f(i^{k-1}z)) k k","['complex-analysis', 'power-series']"
3,How can I minimize the real part of the roots of this function involving both $x$ and $e^x$ terms?,How can I minimize the real part of the roots of this function involving both  and  terms?,x e^x,"The question I have a function $D(s) = s^2 + c s + k + K_d s e^{-s} + K_p e^{-s}.$ The values of $c$ and $k$ are fixed, but I can choose $K_d$ and $K_p$ . How do I choose these two values in order to minimize $\max \{ \operatorname{Re}(s) : D(s) = 0 \}$ ? Motivation I'm writing an autopilot program for a flight simulation video game. Given information about the current state of the aircraft, it attempts to calculate flight control inputs which will put it into a desired state. I'm using PID controllers to accomplish this. However, it's difficult to make these work in practice. The main reason is that aircraft are inherently oscillatory in several ways, and poorly chosen PID parameters exacerbate these oscillations. Attempting to find PID parameters which control the aircraft effectively without producing oscillations is very tedious. In order to try to calculate parameters automatically, I've decided to examine a ""toy"" control problem whose behavior is similar to the aircraft in the video game. Problem In the ""toy"" problem, the system is a damped harmonic oscillator. The oscillator is driven by a PD controller which attempts to drive the position of the oscillator to $0$ . However, the controller suffers a delay of $1$ second. The differential equation describing this system is $$f''(t) = - c f'(t) - k f(t) - K_d f'(t - 1) - K_p f(t - 1).$$ Here, the $c$ term represents the damping force and the $k$ term represents the restoring force. The $K_d$ and $K_p$ terms form the driving force; the $K_d$ term attempts to slow the motion of the system, and the $K_p$ term attempts to push the position of the system towards $0$ . The constants $c$ and $k$ cannot be changed, but we are able to select $K_d$ and $K_p$ . We can find the Laplace transform of $f$ : $$s^2 F(s) - s f(0) - f'(0) = -c (s F(s) - f(0)) - k F(s) - K_d (s e^{-s} F(s) - f(-1)) - K_p e^{-s} F(s)$$ $$s^2 F(s) + c s F(s) + k F(s) + K_d s e^{-s} F(s) + K_p e^{-s} F(s) = s f(0) + f'(0) + c f(0) + K_d f(-1)$$ $$F(s) = \frac{s f(0) + f'(0) + c f(0) + K_d f(-1)}{s^2 + c s + k + K_d s e^{-s} + K_p e^{-s}}$$ If I understand the Laplace transform correctly, the system converges whenever all of the poles of $F(s)$ have a negative real part; and it suffers from divergent oscillations whenever at least one of the poles of $F(s)$ has at least one positive real part. So, the behavior is determined by the rightmost root of $s^2 + c s + k + K_d s e^{-s} + K_p e^{-s}$ . If the real part of this root is negative, then the system will converge. Furthermore, the closer the real part is to negative infinity, the more quickly the system will converge. So, we want to choose $K_d$ and $K_p$ so as to make the real part of the rightmost root as small as possible. Hence, the question at the top of this post. My thoughts The equation $s^2 + c s + k + K_d s e^{-s} + K_p e^{-s} = 0$ doesn't look like it admits an elementary solution. I could probably find its roots using some type of numerical search; is this the best way? Even if I had a fast way to calculate the solutions to this equation, I'd then have to perform another search in order to find the one which minimizes the maximum real part. If I had to perform nested searches, then the whole process could get very slow. Based on playing around with the function in graphing calculators, it looks like it usually has three roots near the origin (not necessarily distinct). Does this function always have exactly three roots near the origin when $K_d$ and $K_p$ are not both zero? If a numerical search is the best way to go for both parts of the problem (locating the roots and minimizing them), maybe the best approach is going to be to use gradient descent in the outer loop to minimize the roots, and Newton's method in the inner loop to locate the roots.","The question I have a function The values of and are fixed, but I can choose and . How do I choose these two values in order to minimize ? Motivation I'm writing an autopilot program for a flight simulation video game. Given information about the current state of the aircraft, it attempts to calculate flight control inputs which will put it into a desired state. I'm using PID controllers to accomplish this. However, it's difficult to make these work in practice. The main reason is that aircraft are inherently oscillatory in several ways, and poorly chosen PID parameters exacerbate these oscillations. Attempting to find PID parameters which control the aircraft effectively without producing oscillations is very tedious. In order to try to calculate parameters automatically, I've decided to examine a ""toy"" control problem whose behavior is similar to the aircraft in the video game. Problem In the ""toy"" problem, the system is a damped harmonic oscillator. The oscillator is driven by a PD controller which attempts to drive the position of the oscillator to . However, the controller suffers a delay of second. The differential equation describing this system is Here, the term represents the damping force and the term represents the restoring force. The and terms form the driving force; the term attempts to slow the motion of the system, and the term attempts to push the position of the system towards . The constants and cannot be changed, but we are able to select and . We can find the Laplace transform of : If I understand the Laplace transform correctly, the system converges whenever all of the poles of have a negative real part; and it suffers from divergent oscillations whenever at least one of the poles of has at least one positive real part. So, the behavior is determined by the rightmost root of . If the real part of this root is negative, then the system will converge. Furthermore, the closer the real part is to negative infinity, the more quickly the system will converge. So, we want to choose and so as to make the real part of the rightmost root as small as possible. Hence, the question at the top of this post. My thoughts The equation doesn't look like it admits an elementary solution. I could probably find its roots using some type of numerical search; is this the best way? Even if I had a fast way to calculate the solutions to this equation, I'd then have to perform another search in order to find the one which minimizes the maximum real part. If I had to perform nested searches, then the whole process could get very slow. Based on playing around with the function in graphing calculators, it looks like it usually has three roots near the origin (not necessarily distinct). Does this function always have exactly three roots near the origin when and are not both zero? If a numerical search is the best way to go for both parts of the problem (locating the roots and minimizing them), maybe the best approach is going to be to use gradient descent in the outer loop to minimize the roots, and Newton's method in the inner loop to locate the roots.",D(s) = s^2 + c s + k + K_d s e^{-s} + K_p e^{-s}. c k K_d K_p \max \{ \operatorname{Re}(s) : D(s) = 0 \} 0 1 f''(t) = - c f'(t) - k f(t) - K_d f'(t - 1) - K_p f(t - 1). c k K_d K_p K_d K_p 0 c k K_d K_p f s^2 F(s) - s f(0) - f'(0) = -c (s F(s) - f(0)) - k F(s) - K_d (s e^{-s} F(s) - f(-1)) - K_p e^{-s} F(s) s^2 F(s) + c s F(s) + k F(s) + K_d s e^{-s} F(s) + K_p e^{-s} F(s) = s f(0) + f'(0) + c f(0) + K_d f(-1) F(s) = \frac{s f(0) + f'(0) + c f(0) + K_d f(-1)}{s^2 + c s + k + K_d s e^{-s} + K_p e^{-s}} F(s) F(s) s^2 + c s + k + K_d s e^{-s} + K_p e^{-s} K_d K_p s^2 + c s + k + K_d s e^{-s} + K_p e^{-s} = 0 K_d K_p,"['complex-analysis', 'optimization', 'control-theory']"
4,Proving $f_n(z)=\frac{nz}{1+n^3z^2}$ converges uniformly,Proving  converges uniformly,f_n(z)=\frac{nz}{1+n^3z^2},"Show that the sequence of functions $f_n(z)=\frac{nz}{1+n^3z^2}$ converges uniformly on the set $E=[1,\infty]$ . $\lim_{n\to\infty}\frac{nz}{1+n^3z^2}=0$ so it converges pointwise to 0. So I am going to check if it converges uniformly to $0$ . $|\frac{nz}{1+n^3z^2}-0|\leqslant |\frac{nz}{n^3z^2}|=|\frac{1}{n^2z}|\leqslant\frac{1}{n^2}\to 0$ as $n\to\infty$ since $|\frac{nz}{1+n^3z^2}-0|$ is majored by $\frac{1}{n^2}$ that does not depend on $z$ . I conclude the function converges uniformly to $0$ . Questions: Is this proof right? If not why? Which are the alternatives? Thanks in advance!",Show that the sequence of functions converges uniformly on the set . so it converges pointwise to 0. So I am going to check if it converges uniformly to . as since is majored by that does not depend on . I conclude the function converges uniformly to . Questions: Is this proof right? If not why? Which are the alternatives? Thanks in advance!,"f_n(z)=\frac{nz}{1+n^3z^2} E=[1,\infty] \lim_{n\to\infty}\frac{nz}{1+n^3z^2}=0 0 |\frac{nz}{1+n^3z^2}-0|\leqslant |\frac{nz}{n^3z^2}|=|\frac{1}{n^2z}|\leqslant\frac{1}{n^2}\to 0 n\to\infty |\frac{nz}{1+n^3z^2}-0| \frac{1}{n^2} z 0","['sequences-and-series', 'complex-analysis']"
5,How is this not a proof of the Jacobian conjecture in the complex case?,How is this not a proof of the Jacobian conjecture in the complex case?,,"I've just been reading the Wikipedia entry regarding the Jacobian conjecture , and it said that either the conjecture is true for all fields of characteristic zero, or it is false for all such fields. Hence, I wonder, shouldn't this be an easy problem that yields to methods from real or complex analysis? After all, it involves only simple terms like determinant, inverse, constant, polynomial etc. Specifically, the determinant condition gives a relation between the derivatives, which one may then be able to integrate in order to possibly obtain polynomials. To make this more specific, say that we have a polynomial function $f: \mathbb K^n \to \mathbb K^n$ , where $\mathbb K = \mathbb R$ or $\mathbb C$ . Then $\det J_f$ is a polynomial in the derivatives of the components and hence itself a polynomial. By the inverse rule and Cramer's rule, the derivative of the (local) inverse has the form $$ \frac{1}{\det(J_f)} \operatorname{Cof}(J_f), $$ where by assumption $\det(J_f)$ is constant. Also, the cofactor matrix is a polynomial matrix. Thus, we integrate any of its entries for each component to obtain a local polynomial inverse, which is also global due to the identity theorem (at least in the complex case). What makes this approach fail? (This main part of my question makes it unique among other questions regarding the Jacobian conjecture, which have been completely falsely suggested to be a duplicate of this one.)","I've just been reading the Wikipedia entry regarding the Jacobian conjecture , and it said that either the conjecture is true for all fields of characteristic zero, or it is false for all such fields. Hence, I wonder, shouldn't this be an easy problem that yields to methods from real or complex analysis? After all, it involves only simple terms like determinant, inverse, constant, polynomial etc. Specifically, the determinant condition gives a relation between the derivatives, which one may then be able to integrate in order to possibly obtain polynomials. To make this more specific, say that we have a polynomial function , where or . Then is a polynomial in the derivatives of the components and hence itself a polynomial. By the inverse rule and Cramer's rule, the derivative of the (local) inverse has the form where by assumption is constant. Also, the cofactor matrix is a polynomial matrix. Thus, we integrate any of its entries for each component to obtain a local polynomial inverse, which is also global due to the identity theorem (at least in the complex case). What makes this approach fail? (This main part of my question makes it unique among other questions regarding the Jacobian conjecture, which have been completely falsely suggested to be a duplicate of this one.)","f: \mathbb K^n \to \mathbb K^n \mathbb K = \mathbb R \mathbb C \det J_f 
\frac{1}{\det(J_f)} \operatorname{Cof}(J_f),
 \det(J_f)","['real-analysis', 'linear-algebra', 'complex-analysis', 'proof-verification', 'open-problem']"
6,Complex integral help: $\oint_C \frac{\sin(z)}{z(z-\pi/4)} dz$,Complex integral help:,\oint_C \frac{\sin(z)}{z(z-\pi/4)} dz,"I'm attempting to evaluate the following complex integral: $$\oint_C  \frac{\sin(z)}{z(z-\pi/4)} dz, $$ where $C$ is a circle of radius $\pi$ centred on the origin. I have calculated the residues of this function at $z=0$ and $z=\pi/4$ , and then used Cauchy's Residue Theorem to evaluate the integral. However, this method gives the result as zero, which implies that the integrand in eq.(1) is analytic, which I don't think it is. Is my method (and/or answer) for solving this integral correct, or should I be using another method? Thanks","I'm attempting to evaluate the following complex integral: where is a circle of radius centred on the origin. I have calculated the residues of this function at and , and then used Cauchy's Residue Theorem to evaluate the integral. However, this method gives the result as zero, which implies that the integrand in eq.(1) is analytic, which I don't think it is. Is my method (and/or answer) for solving this integral correct, or should I be using another method? Thanks","\oint_C  \frac{\sin(z)}{z(z-\pi/4)} dz,  C \pi z=0 z=\pi/4","['complex-analysis', 'residue-calculus', 'complex-integration']"
7,Riemann Sphere Mapping,Riemann Sphere Mapping,,"this is my first post so sorry if my question is too vague. I didn't see a related question posted, hence why I'm asking. I can't find any resources on it, but there's supposed to be a bijective mapping from the complex plane to the reimann sphere, correct? The only mapping I've seen is by creating a line from a point in the complex plane to the top of the sphere and the intersection point with the sphere is the function value. How can this be expressed, and how is it injective? On a intuitive note, how can the complex plane be isomorphic to a sphere? I'd think you could 'unfold' the sphere which would create a finite plane hence not being injective.","this is my first post so sorry if my question is too vague. I didn't see a related question posted, hence why I'm asking. I can't find any resources on it, but there's supposed to be a bijective mapping from the complex plane to the reimann sphere, correct? The only mapping I've seen is by creating a line from a point in the complex plane to the top of the sphere and the intersection point with the sphere is the function value. How can this be expressed, and how is it injective? On a intuitive note, how can the complex plane be isomorphic to a sphere? I'd think you could 'unfold' the sphere which would create a finite plane hence not being injective.",,"['complex-analysis', 'complex-numbers']"
8,"What can be said about complex numbers $z_1, z_2, z_3$ if $\frac{z_1 - z_3}{z_2 - z_3}$ is real?",What can be said about complex numbers  if  is real?,"z_1, z_2, z_3 \frac{z_1 - z_3}{z_2 - z_3}","$z_1, z_2, z_3 \in \mathbb{C}$ $$\frac{z_1 - z_3}{z_2 - z_3} \in \mathbb{R}$$ The only idea I'm coming up with is that either $ \operatorname{Im}(z_1) =  \operatorname{Im}(z_2) =  \operatorname{Im}(z_3)$ or $ \operatorname{Re}(z_1) =  \operatorname{Re}(z_2) =  \operatorname{Re}(z_3)$ . If I were to do the division properly, i.e. express all complex numbers in the $( x+iy )$ format and multiply both the numerator and denominator by the conjugate of $z_2 - z_3$ , I'd end up with 6 variables, which seems very complicated. Do you have any ideas as to how to solve this? thanks!","The only idea I'm coming up with is that either or . If I were to do the division properly, i.e. express all complex numbers in the format and multiply both the numerator and denominator by the conjugate of , I'd end up with 6 variables, which seems very complicated. Do you have any ideas as to how to solve this? thanks!","z_1, z_2, z_3 \in \mathbb{C} \frac{z_1 - z_3}{z_2 - z_3} \in \mathbb{R}  \operatorname{Im}(z_1) =  \operatorname{Im}(z_2) =  \operatorname{Im}(z_3)  \operatorname{Re}(z_1) =  \operatorname{Re}(z_2) =  \operatorname{Re}(z_3) ( x+iy ) z_2 - z_3","['complex-analysis', 'complex-numbers']"
9,$f(z) = \frac{z-a}{1 - z\bar{a}}$ interpretation?,interpretation?,f(z) = \frac{z-a}{1 - z\bar{a}},"I recently started a complex-analysis course and our teacher proposed this exercise to us: Given $a, z \in \mathbb{C}$ , consider the complex function $$ f(z) = \frac{z-a}{1 - z\bar{a}}.$$ I've proved already that either $\vert{z}\vert = 1$ or $\vert{a}\vert = 1$ implies $$\left\vert{\frac{ z-a}{1 - z\bar{a}}}\right\vert = 1.$$ So, assume $\vert{a}\vert = 1$ . My teacher asked  ""What exception needs to be made if $\vert{z}\vert = \vert{a}\vert = 1$ ?"" I can tell that if e.g., $ z = \frac{1}{\bar{a}}$ , the function goes all the way to infinity, and that there is a $\frac{0}{0}$ type indetermination if $z = a$ , but: Is there any way to solve/understand the indetermination? Or a way to interpret the function geometrically? I've already tried plotting it on davidbau.com, but I can't really understand what's going on.  Or is it just because I'm not used to complex functions?","I recently started a complex-analysis course and our teacher proposed this exercise to us: Given , consider the complex function I've proved already that either or implies So, assume . My teacher asked  ""What exception needs to be made if ?"" I can tell that if e.g., , the function goes all the way to infinity, and that there is a type indetermination if , but: Is there any way to solve/understand the indetermination? Or a way to interpret the function geometrically? I've already tried plotting it on davidbau.com, but I can't really understand what's going on.  Or is it just because I'm not used to complex functions?","a, z \in \mathbb{C}  f(z) = \frac{z-a}{1 - z\bar{a}}. \vert{z}\vert = 1 \vert{a}\vert = 1 \left\vert{\frac{ z-a}{1 - z\bar{a}}}\right\vert = 1. \vert{a}\vert = 1 \vert{z}\vert = \vert{a}\vert = 1  z = \frac{1}{\bar{a}} \frac{0}{0} z = a","['complex-analysis', 'analysis', 'complex-numbers']"
10,Find sum $u_0 u_1 + u_1u_2+...+u_{n-2}u_{n-1} $,Find sum,u_0 u_1 + u_1u_2+...+u_{n-2}u_{n-1} ,I have $$ u_k = \cos\frac{2k\pi}{n} + i \sin\frac{2k\pi}{n}$$ And I should calculate: $$ u_0 u_1 + u_1u_2+...+u_{n-2}u_{n-1}+u_{n-1}u_0 $$ But I have stucked: Firstly I calculate $$u_0 u_1 + u_1u_2+...+u_{n-2}u_{n-1} $$ and put $$ \alpha_k = u_k \cdot u_{k+1} = ... = e^{\frac{i\pi(2k+1)}{n}} $$ and sum $$ \alpha_0 + ... + \alpha_{n-2} = ... = e^{\frac{i\pi}{n}} \cdot \frac{1-e^{\frac{2(n-1)i\pi}{n}}}{1-e^{\frac{2i\pi}{n}}}$$ and I don't know how ti finish that. If it comes to $$u_{n-1}u_0  =  e^{i\pi} = -1 $$,I have And I should calculate: But I have stucked: Firstly I calculate and put and sum and I don't know how ti finish that. If it comes to, u_k = \cos\frac{2k\pi}{n} + i \sin\frac{2k\pi}{n}  u_0 u_1 + u_1u_2+...+u_{n-2}u_{n-1}+u_{n-1}u_0  u_0 u_1 + u_1u_2+...+u_{n-2}u_{n-1}   \alpha_k = u_k \cdot u_{k+1} = ... = e^{\frac{i\pi(2k+1)}{n}}   \alpha_0 + ... + \alpha_{n-2} = ... = e^{\frac{i\pi}{n}} \cdot \frac{1-e^{\frac{2(n-1)i\pi}{n}}}{1-e^{\frac{2i\pi}{n}}} u_{n-1}u_0  =  e^{i\pi} = -1 ,['complex-analysis']
11,Understanding a proof concerning the loci of zeros of a polynomial curve,Understanding a proof concerning the loci of zeros of a polynomial curve,,"I am trying to understand following proof. One definition the author uses: The locus of zeros of a function $f(z, K)$ with respect to $K > 0$ is the set of all points $z$ such that for some $K_0$ , $f(z, K_0)=0$ . I can understand every sentence of the proof. But my confusion is: it seems to me it only proves necessity. Am I understanding wrong?","I am trying to understand following proof. One definition the author uses: The locus of zeros of a function with respect to is the set of all points such that for some , . I can understand every sentence of the proof. But my confusion is: it seems to me it only proves necessity. Am I understanding wrong?","f(z, K) K > 0 z K_0 f(z, K_0)=0","['abstract-algebra', 'complex-analysis', 'polynomials', 'locus']"
12,Is the textbook solution wrong by a sign? Laurent Series,Is the textbook solution wrong by a sign? Laurent Series,,"Find the Laurent series of $\frac{e^z}{z^2 -1}$ about $z = 1$ . Here is my solution: Factor denominator $\frac{e^z}{(z-1)(z+1)}$ let $w = z - 1$ , and so $z = w + 1$ , substitute in $\frac{e^{w+1}}{w(w+2)}$ Do partial fraction decomposition to get rid of the exponential in numerator $\frac{e^{w+1}}{w(w+2)}$ = $\frac{A}{w} + \frac{B}{w+2}$ $e^{w+1} = A(w+2) + Bw$ If $w=0$ , $e=2A$ , $A = e/2$ . If $w = -2$ , $\frac{1}{e} = -2B$ , $B = \frac{-1} {2e}$ Thus our new equation is $\frac{e}{2w} + \frac{-1}{2e(w+2)}$ Because the first term $\frac{e}{2w}$ is already in terms of $w = (z-1), we leave it be. The second term we can expand using geometric series expansion $\frac{-1}{4e} \cdot \frac{1}{1 - (\frac{-w}{2})}$ and so the Laurent series we get is $$\frac{e}{2w} - \frac{1}{4e} \cdot \{1 - \frac{w}{2} + \frac{w^2}{4} - \frac{w^3}{8} ... \} $$ However, the textbook solution has same terms, but no negative sign. Where did I go wrong?","Find the Laurent series of about . Here is my solution: Factor denominator let , and so , substitute in Do partial fraction decomposition to get rid of the exponential in numerator = If , , . If , , Thus our new equation is Because the first term is already in terms of $w = (z-1), we leave it be. The second term we can expand using geometric series expansion and so the Laurent series we get is However, the textbook solution has same terms, but no negative sign. Where did I go wrong?","\frac{e^z}{z^2 -1} z = 1 \frac{e^z}{(z-1)(z+1)} w = z - 1 z = w + 1 \frac{e^{w+1}}{w(w+2)} \frac{e^{w+1}}{w(w+2)} \frac{A}{w} + \frac{B}{w+2} e^{w+1} = A(w+2) + Bw w=0 e=2A A = e/2 w = -2 \frac{1}{e} = -2B B = \frac{-1}
{2e} \frac{e}{2w} + \frac{-1}{2e(w+2)} \frac{e}{2w} \frac{-1}{4e} \cdot \frac{1}{1 - (\frac{-w}{2})} \frac{e}{2w} - \frac{1}{4e} \cdot \{1 - \frac{w}{2} + \frac{w^2}{4} - \frac{w^3}{8} ... \} ","['complex-analysis', 'laurent-series']"
13,A weird value obtained by using Cauchy Principal Value on $\int_{-\infty}^{\infty}\frac{1}{x^2}dx$,A weird value obtained by using Cauchy Principal Value on,\int_{-\infty}^{\infty}\frac{1}{x^2}dx,"so I'm trying to evaluate the integral in the title, $$\int_{-\infty}^{\infty}\frac{1}{x^2}dx$$ by using complex plane integration. I've chosen my contour to be a infinte half circle with it's diameter on the real axis. (integration is preformed ccw). when R tends to infinity, the arch part of the contour yields zero, and so we are left with the part along the real axis, which is the one I'm trying to evalute. there are no other poles in my contour, only a second order pole at $z=0$ lying on it. the residue of this pole is $0$ so the integral sums up to be zero (by using Cauchy principal value.) However my function is always positive and greater than $0$ , so this doesn't make sense. Any help would be appreciated","so I'm trying to evaluate the integral in the title, by using complex plane integration. I've chosen my contour to be a infinte half circle with it's diameter on the real axis. (integration is preformed ccw). when R tends to infinity, the arch part of the contour yields zero, and so we are left with the part along the real axis, which is the one I'm trying to evalute. there are no other poles in my contour, only a second order pole at lying on it. the residue of this pole is so the integral sums up to be zero (by using Cauchy principal value.) However my function is always positive and greater than , so this doesn't make sense. Any help would be appreciated",\int_{-\infty}^{\infty}\frac{1}{x^2}dx z=0 0 0,"['complex-analysis', 'complex-integration']"
14,Evaluating $\int_{-\infty}^{\infty}\frac{e^{ax}}{\cosh{x}}dx $ using contour integration,Evaluating  using contour integration,\int_{-\infty}^{\infty}\frac{e^{ax}}{\cosh{x}}dx ,"Let $a \in \mathbb{C}$ with $-1 <$ Re $a < 1$ . By considering a rectangular contour with corners at $R, R + i\pi, -R+ i\pi, -R,$ show that $$\int_{-\infty}^{\infty}\frac{e^{ax}}{\cosh{x}}dx = \pi\sec\left( \frac{\pi a}{2}\right)$$ and hence evaluate, for real $n$ , $$\int_{-\infty}^{\infty}\frac{\cos nx}{\cosh{x}}dx$$ I can do everything in the question except showing that the integrals along the two sides of the rectangle vanish as $R$ tends to infinity. I have these two paths as $\gamma_1(t) = R +it$ for $t\in[0,\pi]$ and $\gamma_2(t) = -R + (\pi-t)i$ for $t\in[0,\pi]$ . I'm pretty sure these are right, but I really can't see how the integral of $\frac{e^{az}}{\cosh{z}}$ goes to zero when you integrate along these. I'd really appreciate whatever help you could offer.","Let with Re . By considering a rectangular contour with corners at show that and hence evaluate, for real , I can do everything in the question except showing that the integrals along the two sides of the rectangle vanish as tends to infinity. I have these two paths as for and for . I'm pretty sure these are right, but I really can't see how the integral of goes to zero when you integrate along these. I'd really appreciate whatever help you could offer.","a \in \mathbb{C} -1 < a < 1 R, R + i\pi, -R+ i\pi, -R, \int_{-\infty}^{\infty}\frac{e^{ax}}{\cosh{x}}dx = \pi\sec\left( \frac{\pi a}{2}\right) n \int_{-\infty}^{\infty}\frac{\cos nx}{\cosh{x}}dx R \gamma_1(t) = R +it t\in[0,\pi] \gamma_2(t) = -R + (\pi-t)i t\in[0,\pi] \frac{e^{az}}{\cosh{z}}","['integration', 'complex-analysis', 'analysis', 'contour-integration', 'residue-calculus']"
15,Is $\limsup_{n\rightarrow\infty}\sqrt[n]{|a_n|}=\frac{1}{R}=\limsup_{n\rightarrow\infty}|\frac{a_{n+1}}{a_n}|$?,Is ?,\limsup_{n\rightarrow\infty}\sqrt[n]{|a_n|}=\frac{1}{R}=\limsup_{n\rightarrow\infty}|\frac{a_{n+1}}{a_n}|,"$R$ is the radius of convergence for a powerseries I will write down my proof but I am not sure whether this is right because I thought $$\limsup_{n\rightarrow\infty}\sqrt[n]{|a_n|}\leq \limsup_{n\rightarrow\infty}|\frac{a_{n+1}}{a_n}|$$ If I would take a sequence $(a_n)_{n\in\mathbb{N}}$ for which $$\limsup_{n\rightarrow\infty}\sqrt[n]{|a_n|} < 1 <\limsup_{n\rightarrow\infty}|\frac{a_{n+1}}{a_n}|$$ wouldn't there be a contradiction for the respective power series. Because $$\limsup_{n\rightarrow\infty}\sqrt[n]{|a_n|} < \limsup_{n\rightarrow\infty}|\frac{a_{n+1}}{a_n}|$$ and the statement in my question would imply $\frac{1}{R}<\frac{1}{R}$ Please tell me where I made the mistake in my reasoning of the following proof: i) $\frac{1}{R}=\limsup_{n\rightarrow\infty}\sqrt[n]{|a_n|}=:t\neq 0,\infty$ Applying the root criteria for an arbitrary power series $\sum_{n=0}^{\infty}a_nz^n$ $$\limsup_{n\rightarrow\infty}\sqrt[n]{|a_nz^n|}=\limsup_{n\rightarrow\infty}\sqrt[n]{|a_n}||z|$$ Converges absolutely if $$\limsup_{n\rightarrow\infty}\sqrt[n]{|a_n}||z|<1\iff |z|<\frac{1}{\limsup_{n\rightarrow\infty}\sqrt[n]{|a_n}|}=\frac{1}{t}\tag{*}$$ Diverges if $$\limsup_{n\rightarrow\infty}\sqrt[n]{|a_n}||z|>1\iff |z|>\frac{1}{\limsup_{n\rightarrow\infty}\sqrt[n]{|a_n}|}=\frac{1}{t}\tag{**}$$ Suppose $\frac{1}{R}>t\iff R<\frac{1}{t}\Rightarrow R<\frac{R+\frac{1}{t}}{2}<\frac{1}{t}$ $(*) \Rightarrow \frac{R+\frac{1}{t}}{2}$ , converges absolutely. Contradiction Because $R:=\sup\{|z|:\sum_{n=0}^{\infty}a_nz^n$ , converges $\}$ Suppose $\frac{1}{R}<t$ , $(**) \Rightarrow$ The power series $\sum_{n=0}^{\infty}a_nz^n$ diverges for $z=\frac{R+\frac{1}{t}}{2}$ Contradiction Because $\forall z\in \mathbb{C}: |z|<R, \sum_{n=0}^{\infty}a_nz^n $ converges absolutely. ii) $\frac{1}{R}=\limsup_{n\rightarrow\infty}|\frac{a_{n+1}}{a_n}|=:t\neq 0,\infty$ Applying the quotient criteria for an arbitrary power series $\sum_{n=0}^{\infty}a_nz^n$ $$\limsup_{n\rightarrow\infty}|\frac{a_{n+1}z^{n+1}}{a_nz^n}|\iff \limsup_{n\rightarrow\infty}|\frac{a_{n+1}}{a_n}||z| $$ Converges absolutely if $$\limsup_{n\rightarrow\infty}|\frac{a_{n+1}}{a_n}||z|<1\iff|z|<\frac{1}{\limsup_{n\rightarrow\infty}|\frac{a_{n+1}}{a_n}|}= \frac{1}{t}\tag{***}$$ Diverges if $$\limsup_{n\rightarrow\infty}|\frac{a_{n+1}}{a_n}||z|>1\iff|z|>\frac{1}{\limsup_{n\rightarrow\infty}|\frac{a_{n+1}}{a_n}|}= \frac{1}{t}\tag{****}$$ Suppose $\frac{1}{R}>t\iff R<\frac{1}{t}\Rightarrow R<\frac{R+\frac{1}{t}}{2}<\frac{1}{t}$ $(***) \Rightarrow \frac{R+\frac{1}{t}}{2}$ , converges absolutely. Contradiction Because $R:=\sup\{|z|:\sum_{n=0}^{\infty}a_nz^n$ , converges $\}$ Suppose $\frac{1}{R}<t$ , $(****) \Rightarrow$ The powerseries $\sum_{n=0}^{\infty}a_nz^n$ diverges for $z=\frac{R+\frac{1}{t}}{2}$ Contradiction Because $\forall z\in \mathbb{C}: |z|<R, \sum_{n=0}^{\infty}a_nz^n $ converges absolutely. i) + ii) $\Rightarrow  \limsup_{n\rightarrow\infty}\sqrt[n]{|a_n|}=\frac{1}{R}=\limsup_{n\rightarrow\infty}|\frac{a_{n+1}}{a_n}|$ I am thinking about this for some time now please help me to solve the problem.","is the radius of convergence for a powerseries I will write down my proof but I am not sure whether this is right because I thought If I would take a sequence for which wouldn't there be a contradiction for the respective power series. Because and the statement in my question would imply Please tell me where I made the mistake in my reasoning of the following proof: i) Applying the root criteria for an arbitrary power series Converges absolutely if Diverges if Suppose , converges absolutely. Contradiction Because , converges Suppose , The power series diverges for Contradiction Because converges absolutely. ii) Applying the quotient criteria for an arbitrary power series Converges absolutely if Diverges if Suppose , converges absolutely. Contradiction Because , converges Suppose , The powerseries diverges for Contradiction Because converges absolutely. i) + ii) I am thinking about this for some time now please help me to solve the problem.","R \limsup_{n\rightarrow\infty}\sqrt[n]{|a_n|}\leq \limsup_{n\rightarrow\infty}|\frac{a_{n+1}}{a_n}| (a_n)_{n\in\mathbb{N}} \limsup_{n\rightarrow\infty}\sqrt[n]{|a_n|} < 1 <\limsup_{n\rightarrow\infty}|\frac{a_{n+1}}{a_n}| \limsup_{n\rightarrow\infty}\sqrt[n]{|a_n|} < \limsup_{n\rightarrow\infty}|\frac{a_{n+1}}{a_n}| \frac{1}{R}<\frac{1}{R} \frac{1}{R}=\limsup_{n\rightarrow\infty}\sqrt[n]{|a_n|}=:t\neq 0,\infty \sum_{n=0}^{\infty}a_nz^n \limsup_{n\rightarrow\infty}\sqrt[n]{|a_nz^n|}=\limsup_{n\rightarrow\infty}\sqrt[n]{|a_n}||z| \limsup_{n\rightarrow\infty}\sqrt[n]{|a_n}||z|<1\iff |z|<\frac{1}{\limsup_{n\rightarrow\infty}\sqrt[n]{|a_n}|}=\frac{1}{t}\tag{*} \limsup_{n\rightarrow\infty}\sqrt[n]{|a_n}||z|>1\iff |z|>\frac{1}{\limsup_{n\rightarrow\infty}\sqrt[n]{|a_n}|}=\frac{1}{t}\tag{**} \frac{1}{R}>t\iff R<\frac{1}{t}\Rightarrow R<\frac{R+\frac{1}{t}}{2}<\frac{1}{t} (*) \Rightarrow \frac{R+\frac{1}{t}}{2} R:=\sup\{|z|:\sum_{n=0}^{\infty}a_nz^n \} \frac{1}{R}<t (**) \Rightarrow \sum_{n=0}^{\infty}a_nz^n z=\frac{R+\frac{1}{t}}{2} \forall z\in \mathbb{C}: |z|<R, \sum_{n=0}^{\infty}a_nz^n  \frac{1}{R}=\limsup_{n\rightarrow\infty}|\frac{a_{n+1}}{a_n}|=:t\neq 0,\infty \sum_{n=0}^{\infty}a_nz^n \limsup_{n\rightarrow\infty}|\frac{a_{n+1}z^{n+1}}{a_nz^n}|\iff \limsup_{n\rightarrow\infty}|\frac{a_{n+1}}{a_n}||z|  \limsup_{n\rightarrow\infty}|\frac{a_{n+1}}{a_n}||z|<1\iff|z|<\frac{1}{\limsup_{n\rightarrow\infty}|\frac{a_{n+1}}{a_n}|}= \frac{1}{t}\tag{***} \limsup_{n\rightarrow\infty}|\frac{a_{n+1}}{a_n}||z|>1\iff|z|>\frac{1}{\limsup_{n\rightarrow\infty}|\frac{a_{n+1}}{a_n}|}= \frac{1}{t}\tag{****} \frac{1}{R}>t\iff R<\frac{1}{t}\Rightarrow R<\frac{R+\frac{1}{t}}{2}<\frac{1}{t} (***) \Rightarrow \frac{R+\frac{1}{t}}{2} R:=\sup\{|z|:\sum_{n=0}^{\infty}a_nz^n \} \frac{1}{R}<t (****) \Rightarrow \sum_{n=0}^{\infty}a_nz^n z=\frac{R+\frac{1}{t}}{2} \forall z\in \mathbb{C}: |z|<R, \sum_{n=0}^{\infty}a_nz^n  \Rightarrow  \limsup_{n\rightarrow\infty}\sqrt[n]{|a_n|}=\frac{1}{R}=\limsup_{n\rightarrow\infty}|\frac{a_{n+1}}{a_n}|","['sequences-and-series', 'complex-analysis', 'limsup-and-liminf']"
16,Weierstrass $\wp$-function defines a map from the torus to an elliptic curve. Why is it injective?,Weierstrass -function defines a map from the torus to an elliptic curve. Why is it injective?,\wp,"For $L$ a lattice in $\mathbb C$ , the Weierstrass $\wp$ -function is the meromorphic function $$\wp(z) = \frac{1}{z^2} + \sum\limits_{0 \neq \lambda \in L}\frac{1}{(z-\lambda)^2} - \frac{1}{\lambda^2}$$ It can be shown to satisfy the differential equation $\wp'(z) = 4\wp(z)^3 - g_2\wp(z) - g_3$ , where $$g_2 = 60 \sum\limits_{0 \neq \lambda \in L} \frac{1}{\lambda^4}$$ $$g_3 = 120 \sum\limits_{0 \neq \lambda \in L} \frac{1}{\lambda^6}$$ If $E$ is the elliptic curve in $\mathbb P^2$ defined by the homogeneous polynomial $y^2z = 4x^3 - g_2xz^2-g_3z^3$ , then $$F(z) = \begin{cases} (\wp(z);\wp'(z);1) & \textrm{if }z\not\in L \\ (0;1;0) & \textrm{if } z \in L \end{cases}$$ can be shown to define a holomorphic function $\mathbb C \rightarrow E$ .  Since $\mathscr P$ and $\mathscr P'$ are well defined on $\mathbb C/L$ , so is $F$ , and $F$ induces a holomorphic function $$\bar{F}: \mathbb C /L \rightarrow E$$ which is automatically surjective, because $F$ is an open map (being holomorphic and nonconstant), and $\mathbb C/L$ and $E$ are compact.  I want to say that $\bar{F}$ is a biholomorphism, which is equivalent to saying $\bar{F}$ is injective. How do we know that $\bar{F}$ is injective?","For a lattice in , the Weierstrass -function is the meromorphic function It can be shown to satisfy the differential equation , where If is the elliptic curve in defined by the homogeneous polynomial , then can be shown to define a holomorphic function .  Since and are well defined on , so is , and induces a holomorphic function which is automatically surjective, because is an open map (being holomorphic and nonconstant), and and are compact.  I want to say that is a biholomorphism, which is equivalent to saying is injective. How do we know that is injective?",L \mathbb C \wp \wp(z) = \frac{1}{z^2} + \sum\limits_{0 \neq \lambda \in L}\frac{1}{(z-\lambda)^2} - \frac{1}{\lambda^2} \wp'(z) = 4\wp(z)^3 - g_2\wp(z) - g_3 g_2 = 60 \sum\limits_{0 \neq \lambda \in L} \frac{1}{\lambda^4} g_3 = 120 \sum\limits_{0 \neq \lambda \in L} \frac{1}{\lambda^6} E \mathbb P^2 y^2z = 4x^3 - g_2xz^2-g_3z^3 F(z) = \begin{cases} (\wp(z);\wp'(z);1) & \textrm{if }z\not\in L \\ (0;1;0) & \textrm{if } z \in L \end{cases} \mathbb C \rightarrow E \mathscr P \mathscr P' \mathbb C/L F F \bar{F}: \mathbb C /L \rightarrow E F \mathbb C/L E \bar{F} \bar{F} \bar{F},"['complex-analysis', 'elliptic-curves', 'riemann-surfaces', 'complex-manifolds']"
17,Limitations of Bromwich integral for inverting Laplace transform,Limitations of Bromwich integral for inverting Laplace transform,,"Suppose: $$f(t)=e^{at}+e^{bt};\quad a>b>0$$ Its Laplace transform is: $$\mathbf{L}[e^{at}+e^{bt}]=\frac{1}{s-a}+\frac{1}{s-b}$$ for $Re(s)>a$ where $Re$ stands for the real part; for $Re(s)<a$ Laplace transform of $e^{at}+e^{bt}$ doesn't exist because the transform integral isn't finite. Now suppose we invert $$F(s)=\frac{1}{s-a}+\frac{1}{s-b}$$ using Bromwich integral. $F(s)$ has simple poles at $a,b$ , with corresponding residues equal to $1$ . Therefore the inverse transform using Bromwich integral would be: $$\mathbf{L}^{-1}[F(s)]=\frac{1}{2\pi i}\int_Cds~e^{st}(\frac{1}{s-a}+\frac{1}{s-b})\\ =Res_{s=a}[e^{st}(\frac{1}{s-a}+\frac{1}{s-b})]+Res_{s=b}[e^{st}(\frac{1}{s-a}+\frac{1}{s-b})]\\ =e^{at}+e^{bt}$$ Even though it matches with the $f(t)$ we began with, why is this procedure correct? $F(s)$ is not defined when $Re(s)<a$ and the pole at $b$ lies in the region where $F(s)$ isn't defined. But using the residue at that pole nevertheless gives me $f(t)$ correctly. My question: Does a transformed function $F(s)$ whose poles lie outside its domain of validity (in the sense that the Laplace transform of the inverted function $f(t)$ has a limited domain of validity in the complex $s$ -plane) always give the ""correct answer"" $f(t)$ when Bromwich integral is evaluated by summing residues? Since I am not a mathematician I don't how to better phrase my question, but I hope that my example above makes my question clear. Thanks in advance for your help.","Suppose: Its Laplace transform is: for where stands for the real part; for Laplace transform of doesn't exist because the transform integral isn't finite. Now suppose we invert using Bromwich integral. has simple poles at , with corresponding residues equal to . Therefore the inverse transform using Bromwich integral would be: Even though it matches with the we began with, why is this procedure correct? is not defined when and the pole at lies in the region where isn't defined. But using the residue at that pole nevertheless gives me correctly. My question: Does a transformed function whose poles lie outside its domain of validity (in the sense that the Laplace transform of the inverted function has a limited domain of validity in the complex -plane) always give the ""correct answer"" when Bromwich integral is evaluated by summing residues? Since I am not a mathematician I don't how to better phrase my question, but I hope that my example above makes my question clear. Thanks in advance for your help.","f(t)=e^{at}+e^{bt};\quad a>b>0 \mathbf{L}[e^{at}+e^{bt}]=\frac{1}{s-a}+\frac{1}{s-b} Re(s)>a Re Re(s)<a e^{at}+e^{bt} F(s)=\frac{1}{s-a}+\frac{1}{s-b} F(s) a,b 1 \mathbf{L}^{-1}[F(s)]=\frac{1}{2\pi i}\int_Cds~e^{st}(\frac{1}{s-a}+\frac{1}{s-b})\\
=Res_{s=a}[e^{st}(\frac{1}{s-a}+\frac{1}{s-b})]+Res_{s=b}[e^{st}(\frac{1}{s-a}+\frac{1}{s-b})]\\
=e^{at}+e^{bt} f(t) F(s) Re(s)<a b F(s) f(t) F(s) f(t) s f(t)","['complex-analysis', 'laplace-transform', 'residue-calculus', 'inverse-laplace']"
18,Find residues of $f(z)=\frac{1}{(e^{z}-1)^{2}}$,Find residues of,f(z)=\frac{1}{(e^{z}-1)^{2}},"How to find the residues of $f(z)=\dfrac{1}{(e^{z}-1)^{2}}$ I have found that the poles $z=2\pi i n$ . But when I apply the formula $\dfrac{1}{(m-1)!}\lim\limits_{z\rightarrow z_{0}}\dfrac{d^{m-1}}{dz^{m-1}}\left((z-z_{0})^{m}f(z)\right)$ , I got $\lim\limits_{z\rightarrow z_{0}}\dfrac{d}{dz}(z-z_{0})^{2}\dfrac{1}{(e^{z}-1)^{2}}$ , which is so complicated that I cannot get the limit value.","How to find the residues of I have found that the poles . But when I apply the formula , I got , which is so complicated that I cannot get the limit value.",f(z)=\dfrac{1}{(e^{z}-1)^{2}} z=2\pi i n \dfrac{1}{(m-1)!}\lim\limits_{z\rightarrow z_{0}}\dfrac{d^{m-1}}{dz^{m-1}}\left((z-z_{0})^{m}f(z)\right) \lim\limits_{z\rightarrow z_{0}}\dfrac{d}{dz}(z-z_{0})^{2}\dfrac{1}{(e^{z}-1)^{2}},"['complex-analysis', 'residue-calculus']"
19,Analytic function must be free from $\bar{z}.$,Analytic function must be free from,\bar{z}.,"How can i say that analytic function must be free from $\bar{z}?$ I verified it for many examples like $\bar{z}, z^2+\bar{z} $ etc and found that the results seems to be true according to me . I am thinking  like as if any complex function contains $\bar{z}$ term in any form(obviously in nontrivial form  unlike $\bar{z}-\bar{z}$ ) then that terms is never analytic and hence whole function is also never analytic. Please suggest . Thanks .",How can i say that analytic function must be free from I verified it for many examples like etc and found that the results seems to be true according to me . I am thinking  like as if any complex function contains term in any form(obviously in nontrivial form  unlike ) then that terms is never analytic and hence whole function is also never analytic. Please suggest . Thanks .,"\bar{z}? \bar{z}, z^2+\bar{z}  \bar{z} \bar{z}-\bar{z}",['complex-analysis']
20,Express $e^z$ as a Taylor series around the point $z_0 = 1$. Determine the set in $\mathbb{C}$ on which the series converges.,Express  as a Taylor series around the point . Determine the set in  on which the series converges.,e^z z_0 = 1 \mathbb{C},"I am a bit confused about how to approach this question / not sure if I'm on the right track. I know we can write $e^z = \sum_{n=0}^{\infty} \frac{z^n}{n!}$ . Further: $e^z$ $= e^{z_0}(e^{z-z_0})$ $= e^{z_0} \sum_{n=0}^{\infty} \frac{(z - z_0)^n}{n!}$ Replacing $z_0$ with $1$ we get: $e^z= e^{1} \sum_{n=0}^{\infty} \frac{(z - 1)^n}{n!}$ Is the above equation the correct Taylor Series for $e^z$ around $z_0 = 1$ ? Also: if $|z-1| < R$ for some fixed $R > 0$ then: $e^{1} \sum_{n=0}^{\infty} \frac{|(z - 1)^n|}{n!} \leq e \sum_{n=0}^{\infty} \frac{|R^n|}{n!}$ Using the ratio test: $L = \lim_{n \to \infty}|\frac{R^{n+1}}{(n+1)!}*\frac{n!}{R^n}| = \frac{R}{n+1}$ Since $L = 0$ for any fixed $R$ , does this mean that the Taylor Series converges everywhere? I'm a little confused on how to put everything together, so any insight is appreciated!","I am a bit confused about how to approach this question / not sure if I'm on the right track. I know we can write . Further: Replacing with we get: Is the above equation the correct Taylor Series for around ? Also: if for some fixed then: Using the ratio test: Since for any fixed , does this mean that the Taylor Series converges everywhere? I'm a little confused on how to put everything together, so any insight is appreciated!",e^z = \sum_{n=0}^{\infty} \frac{z^n}{n!} e^z = e^{z_0}(e^{z-z_0}) = e^{z_0} \sum_{n=0}^{\infty} \frac{(z - z_0)^n}{n!} z_0 1 e^z= e^{1} \sum_{n=0}^{\infty} \frac{(z - 1)^n}{n!} e^z z_0 = 1 |z-1| < R R > 0 e^{1} \sum_{n=0}^{\infty} \frac{|(z - 1)^n|}{n!} \leq e \sum_{n=0}^{\infty} \frac{|R^n|}{n!} L = \lim_{n \to \infty}|\frac{R^{n+1}}{(n+1)!}*\frac{n!}{R^n}| = \frac{R}{n+1} L = 0 R,"['complex-analysis', 'convergence-divergence', 'taylor-expansion']"
21,How to convert this complex number to exponential form?,How to convert this complex number to exponential form?,,"I have $Z = {\frac{2+i}{2-i}}$ . I need to write it in exponential form, i.e. $Z = r*e^{i{\phi}}$ . I simplified the given example to ${\frac{3 + 4i}{5}}$ , i.e. $a={\frac{3}{5}}, b={\frac{4}{5}}$ . Therefore, $r = 1$ . Then I calculate $cos({\phi}) = a / r = 3 / 5, sin({\phi})=b/r = 4/5$ . How do I calculate ${\phi}$ from here? The online Complex Number Exponential Form given ${\phi}=tan^{-1}({\frac{4}{3}})$ .","I have . I need to write it in exponential form, i.e. . I simplified the given example to , i.e. . Therefore, . Then I calculate . How do I calculate from here? The online Complex Number Exponential Form given .","Z = {\frac{2+i}{2-i}} Z = r*e^{i{\phi}} {\frac{3 + 4i}{5}} a={\frac{3}{5}}, b={\frac{4}{5}} r = 1 cos({\phi}) = a / r = 3 / 5, sin({\phi})=b/r = 4/5 {\phi} {\phi}=tan^{-1}({\frac{4}{3}})","['complex-analysis', 'complex-numbers']"
22,Are fractional linear transformations continuous?,Are fractional linear transformations continuous?,,"I was reading, some answers about fractional linear transformations and find this old question that was never answer and I think is a nice question. How do you prove it? We define a Möbius transformation through: $$z\rightarrow \frac{az+b}{cz+d}, ad-bc\neq0, a,b,c,d\in \mathbb{C}$$ and extend to the Riemann sphere as follows: if $c=0$ , $T(\infty)=\infty$ , and if $c\neq0$ , $T(\infty)=a/c$ and $T(-d/c)=\infty$ . Show that the Möbius transformations are continuous in that area with the chordal metric. We define the chordal metric thus: $$d_{c}(z_{1},z_{2})= \begin{cases} \frac{2|z_{1}-z_{2}|}{\sqrt{1+|z_{1}|^2}\sqrt{1+|z_{2}|^2}}& \text{if $z_{1},\,z_{2}\neq \infty$}\\ \frac{2}{\sqrt{1+|z_{1}|^2}} & \text{if $z_{2}= \infty$.} \end{cases}$$","I was reading, some answers about fractional linear transformations and find this old question that was never answer and I think is a nice question. How do you prove it? We define a Möbius transformation through: and extend to the Riemann sphere as follows: if , , and if , and . Show that the Möbius transformations are continuous in that area with the chordal metric. We define the chordal metric thus:","z\rightarrow \frac{az+b}{cz+d}, ad-bc\neq0, a,b,c,d\in \mathbb{C} c=0 T(\infty)=\infty c\neq0 T(\infty)=a/c T(-d/c)=\infty d_{c}(z_{1},z_{2})=
\begin{cases}
\frac{2|z_{1}-z_{2}|}{\sqrt{1+|z_{1}|^2}\sqrt{1+|z_{2}|^2}}& \text{if z_{1},\,z_{2}\neq \infty}\\
\frac{2}{\sqrt{1+|z_{1}|^2}} & \text{if z_{2}= \infty.}
\end{cases}","['complex-analysis', 'mobius-transformation']"
23,Simplification of complex conjugates,Simplification of complex conjugates,,"I was working through a limit problem and got stuck on the simplification. I have the answer key however I am not sure where I can simplify more. So the question is, $$f(z) = z \bar z$$ Differentiable at z=0. I know I can take the limit of this as it approaches zero to check for this. $$ f'(z) = \frac{f(z+h) - f(z)}{h}$$ Then the equation becomes: $$ f'(z) \lim z \Rightarrow 0 = \frac{(h+z)^2 (\bar h +\bar z) - z^2\bar z}{h}$$ $$ f'(z) \lim z \Rightarrow 0 = \frac{ (z^2 \bar h) + 2zh\bar h + h^2 \bar h + 2z \bar z h + h^2 \bar z}{h}$$ The professor has simplified then solution to: $$f'(z) \lim z \Rightarrow 0 = \frac{z^2 \bar h + 2z \bar z h }{h} $$ I think I must be missing some sort of an identity in my base knowledge. Any guidance would be greatly appreciated.","I was working through a limit problem and got stuck on the simplification. I have the answer key however I am not sure where I can simplify more. So the question is, Differentiable at z=0. I know I can take the limit of this as it approaches zero to check for this. Then the equation becomes: The professor has simplified then solution to: I think I must be missing some sort of an identity in my base knowledge. Any guidance would be greatly appreciated.",f(z) = z \bar z  f'(z) = \frac{f(z+h) - f(z)}{h}  f'(z) \lim z \Rightarrow 0 = \frac{(h+z)^2 (\bar h +\bar z) - z^2\bar z}{h}  f'(z) \lim z \Rightarrow 0 = \frac{ (z^2 \bar h) + 2zh\bar h + h^2 \bar h + 2z \bar z h + h^2 \bar z}{h} f'(z) \lim z \Rightarrow 0 = \frac{z^2 \bar h + 2z \bar z h }{h} ,"['complex-analysis', 'complex-numbers', 'complex-integration']"
24,Are concrete Riemann surfaces Riemann domains over $\mathbb C$?,Are concrete Riemann surfaces Riemann domains over ?,\mathbb C,"While reading about Riemann surfaces I stumbled upon the following two definitions. A Riemann surface of a complete analytic function is an example of both definitions while Abstract Riemann Surface is a generalisation of both definitions. So it seems like every (non singular, concrete) Riemann surface can be considered as Riemann domain over $\mathbb C$ or maybe vice versa. But I am unable figure it out. I am also curious about the historical origins of these definitions. Riemann surface: A subset $S \subseteq \mathbb C^2$ is called a (non-singular, concrete) Riemann surface if for each point $s \in S$ , there is a neighbourhood $U$ of $s$ and a holomorphic function $F$ on $U$ with non-zero gradient at $s$ such that $S \cap U$ is the zero set of $F$ . Riemann domain over $\mathbb C$ : A topological space (Hausdorff and connected) $G$ is called a Riemann domain over $\mathbb C$ if there exists a local homeomorphism map $\pi:G \to \mathbb C$ .","While reading about Riemann surfaces I stumbled upon the following two definitions. A Riemann surface of a complete analytic function is an example of both definitions while Abstract Riemann Surface is a generalisation of both definitions. So it seems like every (non singular, concrete) Riemann surface can be considered as Riemann domain over or maybe vice versa. But I am unable figure it out. I am also curious about the historical origins of these definitions. Riemann surface: A subset is called a (non-singular, concrete) Riemann surface if for each point , there is a neighbourhood of and a holomorphic function on with non-zero gradient at such that is the zero set of . Riemann domain over : A topological space (Hausdorff and connected) is called a Riemann domain over if there exists a local homeomorphism map .",\mathbb C S \subseteq \mathbb C^2 s \in S U s F U s S \cap U F \mathbb C G \mathbb C \pi:G \to \mathbb C,"['complex-analysis', 'algebraic-geometry', 'riemann-surfaces']"
25,On the functional equation of the theta function,On the functional equation of the theta function,,"Given $\tau$ in the upper half-plane, we define its theta function as $$ \theta(z) := \sum_{n \in \mathbb{Z}} e^{\pi i (n^2\tau + 2nz)}.$$ This is an entire function. It is well-known that the theta function satisfies the functional equation $$ \theta(z+\tau)=e^{-\pi i (\tau+2z)}\theta(z).$$ I am trying to show this, but I start from $$ \theta(z+\tau) = \sum_{n \in \mathbb{Z}} e^{\pi i (n^2\tau + 2nz)} e^{\pi i 2n\tau} $$ and then I have no idea how to proceed. Developing the exponential into a series doesn't look good, it only makes things messier. Any hint?","Given in the upper half-plane, we define its theta function as This is an entire function. It is well-known that the theta function satisfies the functional equation I am trying to show this, but I start from and then I have no idea how to proceed. Developing the exponential into a series doesn't look good, it only makes things messier. Any hint?",\tau  \theta(z) := \sum_{n \in \mathbb{Z}} e^{\pi i (n^2\tau + 2nz)}.  \theta(z+\tau)=e^{-\pi i (\tau+2z)}\theta(z).  \theta(z+\tau) = \sum_{n \in \mathbb{Z}} e^{\pi i (n^2\tau + 2nz)} e^{\pi i 2n\tau} ,['complex-analysis']
26,Alternate Way of Computing Complex Polynomial?,Alternate Way of Computing Complex Polynomial?,,I'm computing the value of this polynomial: $$\left(\frac{2}{z}+\frac{z}{2}\right)^2+2$$ Where $z = -1 + \sqrt{3}i$ I converted to polar $z = 4e^{i5\pi/6}$ to grind out the first term then converted back to cartesian so I could add. I was wondering if there was a faster way of simplifying this expression. I ask because its a question on an old timed exam.,I'm computing the value of this polynomial: Where I converted to polar to grind out the first term then converted back to cartesian so I could add. I was wondering if there was a faster way of simplifying this expression. I ask because its a question on an old timed exam.,\left(\frac{2}{z}+\frac{z}{2}\right)^2+2 z = -1 + \sqrt{3}i z = 4e^{i5\pi/6},['complex-analysis']
27,For given problem if we change the setting what will happen?,For given problem if we change the setting what will happen?,,"I encountered following problem and I solved it by using the hint provided. Thinking of it I noticed  that I am able to solve it even if I use the following function: $$ F(z)=1/f(1/z)),\quad |z|> 1$$ $$ =f(z) ,      \quad |z|\leq 1 $$ What is the problem if I use this function to solve the problem? I can extend it to the whole $\mathbb{C}$ as well: I know that analytic continuation of any function is unique, but I am thinking where is problem if I choose to use this function. Any Help will be appreciated.","I encountered following problem and I solved it by using the hint provided. Thinking of it I noticed  that I am able to solve it even if I use the following function: $$ F(z)=1/f(1/z)),\quad |z|> 1$$ $$ =f(z) ,      \quad |z|\leq 1 $$ What is the problem if I use this function to solve the problem? I can extend it to the whole $\mathbb{C}$ as well: I know that analytic continuation of any function is unique, but I am thinking where is problem if I choose to use this function. Any Help will be appreciated.",,"['complex-analysis', 'holomorphic-functions', 'analytic-continuation']"
28,Evaluate $\int_\gamma z \ \Im(z^2) \ dz$,Evaluate,\int_\gamma z \ \Im(z^2) \ dz,"I am trying to find $$\int_\gamma z\ \Im(z^2) \ dz,$$   where $\gamma$ is the unit circle traversed once, anticlockwise. My attempt: let $\gamma(t)=e^{it}\implies \gamma'(t)=ie^{it} \ \ \ \ t\in[0,2\pi]$. \begin{align} \int_\gamma z\ \Im(z^2) \ dx&=\int_{0}^{2\pi} e^{it}\sin(2t) \ ie^{it} \ dt\\ &=i\int_{0}^{2\pi} e^{2it}\sin(2t) \ dt\ \end{align} Now, I let  \begin{align} I&=i\int_{0}^{2\pi} e^{2it}\sin(2t) \ dt\ \\ &=i\left(\left[\frac{e^{2it}}{2i}\sin(2t)\right]_{0}^{2\pi}-\frac{1}{i}\int_{0}^{2\pi} e^{2it}\cos(2t) \ dt\right) \\ &=-\int_{0}^{2\pi} e^{2it}\cos(2t) \ dt \\ &=-\left(\left[\frac{e^{2it}}{2i}\cos(2t)\right]_{0}^{2\pi}+\frac{1}{i}\int_{0}^{2\pi} e^{2it}\sin(2t) \ dt\right) \\ &=i\int_{0}^{2\pi} e^{2it}\sin(2t) \ dt\ \end{align} Where am I going wrong? Wolfram says the answer is $-\pi$. edit I can see an alternative approach. We could express the integrand as, $$(\cos(2t)+i\sin(2t))\sin(2t)=\cos(2t)\sin(2t)+i\sin^2(2t).$$ But I prefer using integration by parts and would like to see the solution achieved via this approach.","I am trying to find $$\int_\gamma z\ \Im(z^2) \ dz,$$   where $\gamma$ is the unit circle traversed once, anticlockwise. My attempt: let $\gamma(t)=e^{it}\implies \gamma'(t)=ie^{it} \ \ \ \ t\in[0,2\pi]$. \begin{align} \int_\gamma z\ \Im(z^2) \ dx&=\int_{0}^{2\pi} e^{it}\sin(2t) \ ie^{it} \ dt\\ &=i\int_{0}^{2\pi} e^{2it}\sin(2t) \ dt\ \end{align} Now, I let  \begin{align} I&=i\int_{0}^{2\pi} e^{2it}\sin(2t) \ dt\ \\ &=i\left(\left[\frac{e^{2it}}{2i}\sin(2t)\right]_{0}^{2\pi}-\frac{1}{i}\int_{0}^{2\pi} e^{2it}\cos(2t) \ dt\right) \\ &=-\int_{0}^{2\pi} e^{2it}\cos(2t) \ dt \\ &=-\left(\left[\frac{e^{2it}}{2i}\cos(2t)\right]_{0}^{2\pi}+\frac{1}{i}\int_{0}^{2\pi} e^{2it}\sin(2t) \ dt\right) \\ &=i\int_{0}^{2\pi} e^{2it}\sin(2t) \ dt\ \end{align} Where am I going wrong? Wolfram says the answer is $-\pi$. edit I can see an alternative approach. We could express the integrand as, $$(\cos(2t)+i\sin(2t))\sin(2t)=\cos(2t)\sin(2t)+i\sin^2(2t).$$ But I prefer using integration by parts and would like to see the solution achieved via this approach.",,['complex-analysis']
29,Residue at infinity calculating integrals,Residue at infinity calculating integrals,,I have the following problem which I want to evaluate at infinity: $$\oint \dfrac{(z+2)}{(z^2+9)}dz$$ I approach this problem by saying that $z=\dfrac{1}{t}$ and $dz=\dfrac{-1}{t^2}dt$. And I plug them inside my integral and obtain: $$\oint \dfrac{-(2t+1)}{(t+9t^3)}dz=-2\pi i Res(0)=-2\pi i$$ Yet this result is not in accordance with the usual integration using residues which yield $2\pi i$. I was wondering where am I doing a mistake of minus.,I have the following problem which I want to evaluate at infinity: $$\oint \dfrac{(z+2)}{(z^2+9)}dz$$ I approach this problem by saying that $z=\dfrac{1}{t}$ and $dz=\dfrac{-1}{t^2}dt$. And I plug them inside my integral and obtain: $$\oint \dfrac{-(2t+1)}{(t+9t^3)}dz=-2\pi i Res(0)=-2\pi i$$ Yet this result is not in accordance with the usual integration using residues which yield $2\pi i$. I was wondering where am I doing a mistake of minus.,,"['complex-analysis', 'residue-calculus']"
30,Estimation of $f'(z)$ on the unit circle,Estimation of  on the unit circle,f'(z),"This is an old problem from Ph.D Qualifying Exam of Complex Analysis. Let $f$ be a holomorphic function in the open disc $D(0,2)$ of radius 2 centered at the origin and suppose that $|f(z)|=1$ whenever $|z|=1$, and $f(0)=0$. Prove that $|f'(z)|\ge 1$ if $|z|=1$. My attempt: By maximum modulus principle, $|f(z)|< 1$ when $|z|<1$. Therefore, by Schwarz lemma, $|f(z)|\le |z|$ if $|z|\le 1$. Since $|f(z)|=1$ when $|z|=1$, I guess something similar to the Mean Value Theorem would hold, but I have no idea how to figure it out. Does anyone have ideas? Thanks in advance!","This is an old problem from Ph.D Qualifying Exam of Complex Analysis. Let $f$ be a holomorphic function in the open disc $D(0,2)$ of radius 2 centered at the origin and suppose that $|f(z)|=1$ whenever $|z|=1$, and $f(0)=0$. Prove that $|f'(z)|\ge 1$ if $|z|=1$. My attempt: By maximum modulus principle, $|f(z)|< 1$ when $|z|<1$. Therefore, by Schwarz lemma, $|f(z)|\le |z|$ if $|z|\le 1$. Since $|f(z)|=1$ when $|z|=1$, I guess something similar to the Mean Value Theorem would hold, but I have no idea how to figure it out. Does anyone have ideas? Thanks in advance!",,"['complex-analysis', 'holomorphic-functions']"
31,Does a holomorphic function on the unit disk with continuous radial limits have a continuous extension to the closed disk?,Does a holomorphic function on the unit disk with continuous radial limits have a continuous extension to the closed disk?,,"Question: does there exist a holomorphic function $f$ defined on the unit disk $D$ such that $\forall t \in \mathbb{R}, \exists \lim _{r\rightarrow 1^-} f(re^{it})\in\mathbb{C}$; the periodic function $\tilde{f} :\mathbb{R} \rightarrow \mathbb{C}, t\mapsto\lim _{r\rightarrow 1^-} f(re^{it})\in\mathbb{C}$ is continuous; the function $\bar f : \bar{D}\rightarrow\mathbb{C}, z\mapsto \begin{cases}                f(z)\  \textrm{if} \ \ z\in D\\                \tilde{f}(t)\ \textrm{if} \ \ z=e^{it} \ \textrm{for some} \  t\in\mathbb{R}             \end{cases}$ is discontinuous ? I found an example that satisfies 1 and 3 but when it comes to 2, $\tilde{f}$ is just everywhere continuous except for a (periodic) point, i.e. the function $$f : D \rightarrow \mathbb{C}, z\mapsto \exp\left(-\frac{1}{1-z}\right) $$ and I start guessing that this is the best that  could be done. Edit: notice that if we were dealing with harmonic functions instead of holomorphic functions, actually such an $f$ exists, i.e. the derivative with respect to the angle of the Poisson's kernel: $$f :D\rightarrow \mathbb{R}, re^{i\vartheta}\mapsto\frac{\partial}{\partial\vartheta} \frac{1-r^2}{|1-re^{i\vartheta}|^2}.$$ However, the conjugate of $f$, say $g$, has a boundary that is discontinuous, so $f+ig$ fails to give us the example we were looking for.","Question: does there exist a holomorphic function $f$ defined on the unit disk $D$ such that $\forall t \in \mathbb{R}, \exists \lim _{r\rightarrow 1^-} f(re^{it})\in\mathbb{C}$; the periodic function $\tilde{f} :\mathbb{R} \rightarrow \mathbb{C}, t\mapsto\lim _{r\rightarrow 1^-} f(re^{it})\in\mathbb{C}$ is continuous; the function $\bar f : \bar{D}\rightarrow\mathbb{C}, z\mapsto \begin{cases}                f(z)\  \textrm{if} \ \ z\in D\\                \tilde{f}(t)\ \textrm{if} \ \ z=e^{it} \ \textrm{for some} \  t\in\mathbb{R}             \end{cases}$ is discontinuous ? I found an example that satisfies 1 and 3 but when it comes to 2, $\tilde{f}$ is just everywhere continuous except for a (periodic) point, i.e. the function $$f : D \rightarrow \mathbb{C}, z\mapsto \exp\left(-\frac{1}{1-z}\right) $$ and I start guessing that this is the best that  could be done. Edit: notice that if we were dealing with harmonic functions instead of holomorphic functions, actually such an $f$ exists, i.e. the derivative with respect to the angle of the Poisson's kernel: $$f :D\rightarrow \mathbb{R}, re^{i\vartheta}\mapsto\frac{\partial}{\partial\vartheta} \frac{1-r^2}{|1-re^{i\vartheta}|^2}.$$ However, the conjugate of $f$, say $g$, has a boundary that is discontinuous, so $f+ig$ fails to give us the example we were looking for.",,"['complex-analysis', 'examples-counterexamples', 'holomorphic-functions', 'hardy-spaces']"
32,Using complex method to evaluate $\int_0^\infty\frac{\ln(1+x)}{1+x^2}dx$,Using complex method to evaluate,\int_0^\infty\frac{\ln(1+x)}{1+x^2}dx,"Evaluate$$I=\int_0^\infty\frac{\ln(1+x)}{1+x^2}dx$$ I know the answer and other methods to solve this integral. I want to know what is wrong with my attempt. Let $f(z)=\frac{\ln(1+z)\ln z}{1+z^2}$, where $\Im\ln(1+z)\in(-\pi,\pi]$ and $\Im \ln z\in[0,2\pi)$. Take the ""keyhole contour"" $C=C_+\cup C_R\cup C_-\cup C_r$. Edit: $C_+$: the upside of the positive real axis, $C_-$: the downside of the positive real axis, $C_R$: big circle around the origin, $C_r$: small circle around the origin. $$\int_Cf(z)dz=2\pi i(\operatorname{Res}_{z=i}f(z)+\operatorname{Res}_{z=-i}f(z))=\frac12\pi^2 i(\ln(1+i)-3\ln(1-i))$$ As $r\to 0$ and $R\to\infty$, $\int_{C_R}f(z)dz$ and $\int_{C_r}f(z)dz$ vanish. $$(\int_{C_+}+\int_{C_-})f(z)dz=\int_0^\infty\frac{\ln(1+x)}{1+x^2}(\ln x+2\pi i-\ln x)dx$$ Hence I get $$I=\frac{1}{2\pi i}(\int_{C_+}+\int_{C_-})f(z)dz=\frac14\pi(\ln(1+i)-3\ln(1-i))$$ which is wrong.","Evaluate$$I=\int_0^\infty\frac{\ln(1+x)}{1+x^2}dx$$ I know the answer and other methods to solve this integral. I want to know what is wrong with my attempt. Let $f(z)=\frac{\ln(1+z)\ln z}{1+z^2}$, where $\Im\ln(1+z)\in(-\pi,\pi]$ and $\Im \ln z\in[0,2\pi)$. Take the ""keyhole contour"" $C=C_+\cup C_R\cup C_-\cup C_r$. Edit: $C_+$: the upside of the positive real axis, $C_-$: the downside of the positive real axis, $C_R$: big circle around the origin, $C_r$: small circle around the origin. $$\int_Cf(z)dz=2\pi i(\operatorname{Res}_{z=i}f(z)+\operatorname{Res}_{z=-i}f(z))=\frac12\pi^2 i(\ln(1+i)-3\ln(1-i))$$ As $r\to 0$ and $R\to\infty$, $\int_{C_R}f(z)dz$ and $\int_{C_r}f(z)dz$ vanish. $$(\int_{C_+}+\int_{C_-})f(z)dz=\int_0^\infty\frac{\ln(1+x)}{1+x^2}(\ln x+2\pi i-\ln x)dx$$ Hence I get $$I=\frac{1}{2\pi i}(\int_{C_+}+\int_{C_-})f(z)dz=\frac14\pi(\ln(1+i)-3\ln(1-i))$$ which is wrong.",,"['calculus', 'integration', 'complex-analysis', 'definite-integrals']"
33,Taylor coefficients of $\exp⁡(1/(1-z))$ [duplicate],Taylor coefficients of  [duplicate],\exp⁡(1/(1-z)),"This question already has an answer here : Coefficient growth in the power series $\sum u_n z^n = e^{1/(1-z)}$? (1 answer) Closed 5 years ago . I'm specifically interested in estimating the growth of the coefficients $(a_n)_{n\in\mathbb{N}}$ of the Taylor series of $$\exp⁡(1/(1-z))$$ centered in $0$: knowing that $\limsup_{n\rightarrow+\infty}|a_n|^{1/n}=1$, what I'm trying to figure out is whether the growth of $(a_n)_{n\in\mathbb{N}}$ is at most polynomial or super-polynomial... I tried to calculate explicitly the coefficients in order to find some regularity in the sequence of the coefficients, but I quickly got lost in the process. Thanks in advance for any answer or suggestion.","This question already has an answer here : Coefficient growth in the power series $\sum u_n z^n = e^{1/(1-z)}$? (1 answer) Closed 5 years ago . I'm specifically interested in estimating the growth of the coefficients $(a_n)_{n\in\mathbb{N}}$ of the Taylor series of $$\exp⁡(1/(1-z))$$ centered in $0$: knowing that $\limsup_{n\rightarrow+\infty}|a_n|^{1/n}=1$, what I'm trying to figure out is whether the growth of $(a_n)_{n\in\mathbb{N}}$ is at most polynomial or super-polynomial... I tried to calculate explicitly the coefficients in order to find some regularity in the sequence of the coefficients, but I quickly got lost in the process. Thanks in advance for any answer or suggestion.",,"['combinatorics', 'complex-analysis', 'taylor-expansion']"
34,Can a function be analytic if it does not satisfy the Cauchy-Riemann conditions,Can a function be analytic if it does not satisfy the Cauchy-Riemann conditions,,"I'm a student of electrical engineering, preparing for the theoretical exam covering complex analysis. I'm confused about the analyticity of a complex function, so I'm asking for clarification because our professor inadequately explained this concept. What I understand from my lecture notes: suppose there's a complex-valued function $f(z)$. Such function is analytic if the following conditions are satisfied: $f$ is differentiable at $z_0$, therefore $f'(z_0)$ exists $f$ is differential at every point of some $\epsilon$-spherical neighborhood of $z_0$ $f$ can be expanded as a Taylor series in the vicinity of $z_0$ At that point, Cauchy-Riemann equations are nowhere mentioned. However, I've found online that C-R equations are a necessary condition for a complex-valued function being holomorphic (or analytic, although terms are used interchangeably). And here's where I'm starting to get lost. If C-R equations are a necessary condition for holomorphicity, but they are not sufficient conditions for complex differentiability, then how can they ensure given function $f$ being holomorphic, if according to what I've read, such function must be differentiable at given point $z_0$ in order to be considered holomorphic? Can, therefore, a function be holomorphic (or analytic) if C-R conditions are not satisfied? What I've read thus far Are the Cauchy-Riemann equations a necessary and sufficient condition for a function to be analytic? Analyticity of a function in $x$ and $y$, without employing the Cauchy-Riemann eqns Complex analytic function and Cauchy-Riemann conditions question Reference request for undergraduate complex analysis. Prove a function is holomorphic https://www.quora.com/Complex-functions-satisfying-Cauchy-Riemann-conditions-are-analytic-and-there-is-proof-for-it-then-why-there-are-counter-examples","I'm a student of electrical engineering, preparing for the theoretical exam covering complex analysis. I'm confused about the analyticity of a complex function, so I'm asking for clarification because our professor inadequately explained this concept. What I understand from my lecture notes: suppose there's a complex-valued function $f(z)$. Such function is analytic if the following conditions are satisfied: $f$ is differentiable at $z_0$, therefore $f'(z_0)$ exists $f$ is differential at every point of some $\epsilon$-spherical neighborhood of $z_0$ $f$ can be expanded as a Taylor series in the vicinity of $z_0$ At that point, Cauchy-Riemann equations are nowhere mentioned. However, I've found online that C-R equations are a necessary condition for a complex-valued function being holomorphic (or analytic, although terms are used interchangeably). And here's where I'm starting to get lost. If C-R equations are a necessary condition for holomorphicity, but they are not sufficient conditions for complex differentiability, then how can they ensure given function $f$ being holomorphic, if according to what I've read, such function must be differentiable at given point $z_0$ in order to be considered holomorphic? Can, therefore, a function be holomorphic (or analytic) if C-R conditions are not satisfied? What I've read thus far Are the Cauchy-Riemann equations a necessary and sufficient condition for a function to be analytic? Analyticity of a function in $x$ and $y$, without employing the Cauchy-Riemann eqns Complex analytic function and Cauchy-Riemann conditions question Reference request for undergraduate complex analysis. Prove a function is holomorphic https://www.quora.com/Complex-functions-satisfying-Cauchy-Riemann-conditions-are-analytic-and-there-is-proof-for-it-then-why-there-are-counter-examples",,"['complex-analysis', 'derivatives', 'complex-numbers', 'holomorphic-functions', 'analytic-functions']"
35,Find the coefficient of $z$ in the Laurent series expansion of $\frac{e^z}{z-1}$ in ${|z| > 1}$,Find the coefficient of  in the Laurent series expansion of  in,z \frac{e^z}{z-1} {|z| > 1},"I've found this duplicate from '15: Find the coefficient of $z$ in the Laureant Series expansion of $\frac{e^z}{z-1}$ , but I think it's wrong, since it looks for the Laurent expansion in ${|z-1|>1}$. After developing it by myself, I've reached the following: $$f(z)=\frac{e^z}{z-1}=\frac{1}{z-1}\cdot e^z$$ Then, $e^z=\sum_{n\geq 0} \frac{z^n}{n!}$ and $$\frac{1}{z-1}=\sum_{n \geq 0} \frac{1}{z^{n+1}}$$. Here I thought of using the Cauchy Product, but I end up with $$f(z)=\sum_{n \geq 0} \sum_{k=0}^n \frac{z^{2k-n-1}}{k!}$$ (How can I make this font bigger? The exponent is too small. Sorry about that. The exponent would be $2k-n-1$). So I have to sum whenever $2k-n-1 = 1$ If I'm not getting it wrong, this means that I have to calculate $$\sum_{n \geq 0} \frac{1}{(1+2n)!}$$ (I'm not sure how to show it better, but I've put the first 3 terms and were $\frac{1}{1!}, \frac{1}{3!}$ and $\frac{1}{5!}$. I'm not sure how to calculate that. The nearest thing I thought was that $$\sum_{n \geq 0} \frac{1}{n!}=e $$. Maybe what I found before could be considered as an answer, but I think I can go one step further. Thanks","I've found this duplicate from '15: Find the coefficient of $z$ in the Laureant Series expansion of $\frac{e^z}{z-1}$ , but I think it's wrong, since it looks for the Laurent expansion in ${|z-1|>1}$. After developing it by myself, I've reached the following: $$f(z)=\frac{e^z}{z-1}=\frac{1}{z-1}\cdot e^z$$ Then, $e^z=\sum_{n\geq 0} \frac{z^n}{n!}$ and $$\frac{1}{z-1}=\sum_{n \geq 0} \frac{1}{z^{n+1}}$$. Here I thought of using the Cauchy Product, but I end up with $$f(z)=\sum_{n \geq 0} \sum_{k=0}^n \frac{z^{2k-n-1}}{k!}$$ (How can I make this font bigger? The exponent is too small. Sorry about that. The exponent would be $2k-n-1$). So I have to sum whenever $2k-n-1 = 1$ If I'm not getting it wrong, this means that I have to calculate $$\sum_{n \geq 0} \frac{1}{(1+2n)!}$$ (I'm not sure how to show it better, but I've put the first 3 terms and were $\frac{1}{1!}, \frac{1}{3!}$ and $\frac{1}{5!}$. I'm not sure how to calculate that. The nearest thing I thought was that $$\sum_{n \geq 0} \frac{1}{n!}=e $$. Maybe what I found before could be considered as an answer, but I think I can go one step further. Thanks",,"['complex-analysis', 'laurent-series']"
36,Evaluate $\oint_C \frac{3}{z + 1 + i}dz$ along the circle $|z| = 2$,Evaluate  along the circle,\oint_C \frac{3}{z + 1 + i}dz |z| = 2,"Evaluate $$\oint_C \frac{3}{z + 1 + i}dz$$ along the circle $|z| = 2$ The solution that I saw read as follows: The integrand is not holomorphic at $z = -1-i$ and this point $(-1, -1)$ lies within $C$. Put $z-z_0 = re^{it}$ where $z_0 = -1-i$ so $dz = ire^{it}$. So$$\oint \frac{3}{z+1+i}dz = \oint \frac{3}{re^{it}}ire^{it}dt = 3i\int_0^{2\pi}dt = 6\pi i$$ This was my lecturer's solution to the above problem. I can see that the lecturer ""set"" $z+1+i = re^{it}$ but how is this even possible? Because firstly $r$ is not even defined and secondly $2 \in C$ but $2+ 1 + i$ is certainly not in $C$. For example a parametrization of the circle $C = \{z \in \mathbb{C} \ | \ |z| = a\}$ is given by the holomorphic function $f : [0, 2\pi] \to C$ defined by $f(t) = ae^{it}$, then for any point $z \in C$ we have $z= f(t) = ae^{it}$ for some $t \in [0, 2\pi]$. What my lecturer did above does not seem correct. What would a correct solution look like for this? Taking the parameterizatin $z = 2e^{it}$ does not help in this case I think because we'd then end up with $$\frac{6ie^{it}}{2e^{it}+1+i}$$ as the integrand (which we'd be integrating from $t=0$ to $t=2\pi$","Evaluate $$\oint_C \frac{3}{z + 1 + i}dz$$ along the circle $|z| = 2$ The solution that I saw read as follows: The integrand is not holomorphic at $z = -1-i$ and this point $(-1, -1)$ lies within $C$. Put $z-z_0 = re^{it}$ where $z_0 = -1-i$ so $dz = ire^{it}$. So$$\oint \frac{3}{z+1+i}dz = \oint \frac{3}{re^{it}}ire^{it}dt = 3i\int_0^{2\pi}dt = 6\pi i$$ This was my lecturer's solution to the above problem. I can see that the lecturer ""set"" $z+1+i = re^{it}$ but how is this even possible? Because firstly $r$ is not even defined and secondly $2 \in C$ but $2+ 1 + i$ is certainly not in $C$. For example a parametrization of the circle $C = \{z \in \mathbb{C} \ | \ |z| = a\}$ is given by the holomorphic function $f : [0, 2\pi] \to C$ defined by $f(t) = ae^{it}$, then for any point $z \in C$ we have $z= f(t) = ae^{it}$ for some $t \in [0, 2\pi]$. What my lecturer did above does not seem correct. What would a correct solution look like for this? Taking the parameterizatin $z = 2e^{it}$ does not help in this case I think because we'd then end up with $$\frac{6ie^{it}}{2e^{it}+1+i}$$ as the integrand (which we'd be integrating from $t=0$ to $t=2\pi$",,['complex-analysis']
37,Quadratic Equations with Complex Roots [closed],Quadratic Equations with Complex Roots [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question I don't understand what is the geometric ( or intuitive ) meaning of complex roots of a quadratic polynomial : $ax^{2}+bx+c=0$ Can you help me ?","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question I don't understand what is the geometric ( or intuitive ) meaning of complex roots of a quadratic polynomial : $ax^{2}+bx+c=0$ Can you help me ?",,"['calculus', 'real-analysis', 'complex-analysis']"
38,Showing that $\sum\limits_{l=0}^\infty \frac{1}{(3l+2)!}=\frac{1}{3}(e-\frac{2}{\sqrt{e}} \cos(\frac{\pi}{3}-\frac{\sqrt{3}}{2}))$,Showing that,\sum\limits_{l=0}^\infty \frac{1}{(3l+2)!}=\frac{1}{3}(e-\frac{2}{\sqrt{e}} \cos(\frac{\pi}{3}-\frac{\sqrt{3}}{2})),"It is known that $\frac{1}{2\pi i} \int_C \frac{e^z}{z^3-1}dz=\sum\limits_{l=0}^\infty \frac{1}{(3l+2)!}$. Now I will like to evaluate $\frac{1}{2\pi i} \int_C \frac{e^z}{z^3-1}dz$ using Cauchy's Integral Formula, to show that $$\sum\limits_{l=0}^\infty \frac{1}{(3l+2)!}=\frac{1}{3}(e-\frac{2}{\sqrt{e}} \cos(\frac{\pi}{3}-\frac{\sqrt{3}}{2}))$$ There is a hint where we can assume the identity $$\prod\limits_{j=1,j\neq k}^m =(e^{2\pi ij/m}-e^{2\pi ik/m})=\frac{m}{e^{2\pi ik/m}}$$ I managed the following: $$\frac{1}{2\pi i} \int_C \frac{e^z}{z^3-1}dz=(\frac{e^z}{z+1})'|_{z=1}=\frac{e}{4}$$ by Cauchy's Integral Formula for higher derivatives, which is clearly not the desired solution. Where did I go wrong in my working? I feel like I may have a conceptual error of some sort..","It is known that $\frac{1}{2\pi i} \int_C \frac{e^z}{z^3-1}dz=\sum\limits_{l=0}^\infty \frac{1}{(3l+2)!}$. Now I will like to evaluate $\frac{1}{2\pi i} \int_C \frac{e^z}{z^3-1}dz$ using Cauchy's Integral Formula, to show that $$\sum\limits_{l=0}^\infty \frac{1}{(3l+2)!}=\frac{1}{3}(e-\frac{2}{\sqrt{e}} \cos(\frac{\pi}{3}-\frac{\sqrt{3}}{2}))$$ There is a hint where we can assume the identity $$\prod\limits_{j=1,j\neq k}^m =(e^{2\pi ij/m}-e^{2\pi ik/m})=\frac{m}{e^{2\pi ik/m}}$$ I managed the following: $$\frac{1}{2\pi i} \int_C \frac{e^z}{z^3-1}dz=(\frac{e^z}{z+1})'|_{z=1}=\frac{e}{4}$$ by Cauchy's Integral Formula for higher derivatives, which is clearly not the desired solution. Where did I go wrong in my working? I feel like I may have a conceptual error of some sort..",,"['complex-analysis', 'complex-integration', 'cauchy-integral-formula']"
39,Zeros of Holomorphic Functions,Zeros of Holomorphic Functions,,"I am studying theory on the zeros of a function; in particular the the zeros of some order $m$ of a holomorphic function. However I do not understand the following proof presented to me in proving that: A function $f(z)$ has a zero of order $m$ $\iff$ $f(z)=g(z)(z-z_0)^m$ where g(z) is holomorphic at $z_0$ and $g(z_0)\neq0$. I define a zero of a function of order $m$ at $z_0$ to mean that the first $0,\dots m-1$ derivatives evaluated at $z_0$ are zero and the $m$th derivative is non-zero at $z_0$. The only if part of the prove leaves me a little unsure as to why the function $g(z)$ as I shall show below is holomorphic. I have searched online but it has mostly been stated that this function is holomorphic so maybe I'm missing something obvious? The proof goes like this: The Taylor series for $f(z)$ is: \begin{align*} f(z)&=0+\dots+0+\frac{f^{(m)}(z_0)}{m!}(z-z_0)^m+\frac{f^{(m+1)}(z_0)}{(m+1)!}(z-z_0)^{m+1}+\dots \\&=(z-z_0)^m \Big\{ \frac{f^{(m)}(z_0)}{m!}+\frac{f^{(m+1)}(z_0)}{(m+1)!}(z-z_0)+\dots\Big\} \end{align*} and now the function in the curly parenthesis is denoted as $g(z)$, which is claimed to be the holomorphic function. It is clear $g(z_0)\neq0$ but could it be pointed out why the function is also a convergent power series ie analytic/holomorphic etc.","I am studying theory on the zeros of a function; in particular the the zeros of some order $m$ of a holomorphic function. However I do not understand the following proof presented to me in proving that: A function $f(z)$ has a zero of order $m$ $\iff$ $f(z)=g(z)(z-z_0)^m$ where g(z) is holomorphic at $z_0$ and $g(z_0)\neq0$. I define a zero of a function of order $m$ at $z_0$ to mean that the first $0,\dots m-1$ derivatives evaluated at $z_0$ are zero and the $m$th derivative is non-zero at $z_0$. The only if part of the prove leaves me a little unsure as to why the function $g(z)$ as I shall show below is holomorphic. I have searched online but it has mostly been stated that this function is holomorphic so maybe I'm missing something obvious? The proof goes like this: The Taylor series for $f(z)$ is: \begin{align*} f(z)&=0+\dots+0+\frac{f^{(m)}(z_0)}{m!}(z-z_0)^m+\frac{f^{(m+1)}(z_0)}{(m+1)!}(z-z_0)^{m+1}+\dots \\&=(z-z_0)^m \Big\{ \frac{f^{(m)}(z_0)}{m!}+\frac{f^{(m+1)}(z_0)}{(m+1)!}(z-z_0)+\dots\Big\} \end{align*} and now the function in the curly parenthesis is denoted as $g(z)$, which is claimed to be the holomorphic function. It is clear $g(z_0)\neq0$ but could it be pointed out why the function is also a convergent power series ie analytic/holomorphic etc.",,"['complex-analysis', 'power-series', 'proof-explanation', 'roots', 'analytic-functions']"
40,"Support of $f + g$ lies in the union of supports of $f, g$.",Support of  lies in the union of supports of .,"f + g f, g","Let $X$ be a topological space and $f, g : X \to \Bbb{C}$ be two continuous, compactly-supported, complex-valued functions on $X$. Support of $f$ is the closure of the set $\{x \in X : f(x) \neq 0\}$.  Similarly for $g$.  These are assumed to be compact sets. I'm trying to prove that $C_c(X)$ the space of continuous, complex-valued, compactly-supported functions on $X$ is a vector space. Rudin's ""Real & Complex Analysis"" book says that $\text{Support}(f + g) \subset \text{Support}(f) \cup \text{Support}(g) = $ union of two compact sets = compact set. $$ \text{Support}(f + g) = \overline{\{ x \in X : f(x) \neq - g(x)\}} $$ I'm not seeing how this lies in that union.","Let $X$ be a topological space and $f, g : X \to \Bbb{C}$ be two continuous, compactly-supported, complex-valued functions on $X$. Support of $f$ is the closure of the set $\{x \in X : f(x) \neq 0\}$.  Similarly for $g$.  These are assumed to be compact sets. I'm trying to prove that $C_c(X)$ the space of continuous, complex-valued, compactly-supported functions on $X$ is a vector space. Rudin's ""Real & Complex Analysis"" book says that $\text{Support}(f + g) \subset \text{Support}(f) \cup \text{Support}(g) = $ union of two compact sets = compact set. $$ \text{Support}(f + g) = \overline{\{ x \in X : f(x) \neq - g(x)\}} $$ I'm not seeing how this lies in that union.",,"['general-topology', 'complex-analysis', 'vector-spaces', 'compactness']"
41,Laurent series for $f(z)=\frac{1}{\sin z}$,Laurent series for,f(z)=\frac{1}{\sin z},"Since the isolated singularities are $z=k\pi, k \in \mathbb Z$, so we divided the complex plane into the disjoint annulus, i.e. $\{z: n\pi <|z|<(n+1)\pi\}, n \in \mathbb N \cup \{0\}$. On these annuli, $f$ is analytic, so has a unique Laurent series. First, let's consider $\{z: 0 < |z|<\pi\}$, then the solution says $$\begin{aligned} f(z)& =\frac{1}{\sin z}\\ & =\frac{1}{z-\frac{z^3}{3!}+\frac{z^5}{5!}-\cdots}\\ & =\frac{1}{z}\cdot \frac{1}{1-\left(\frac{z^2}{3!}-\frac{z^4}{5!}+\cdots\right)}\\ & =\frac{1}{z}\left[1+\left(\frac{z^2}{3!}-\frac{z^4}{5!}+\cdots\right)+\left(\frac{z^2}{3!}-\frac{z^4}{5!}+\cdots\right)^2+\cdots\right] \end{aligned}$$ My questions are: Do we need $\left|\frac{z^2}{3!}-\frac{z^4}{5!}+\cdots\right|<1$ to get the last step? If we do, then why it is less than 1? Thanks for any help!","Since the isolated singularities are $z=k\pi, k \in \mathbb Z$, so we divided the complex plane into the disjoint annulus, i.e. $\{z: n\pi <|z|<(n+1)\pi\}, n \in \mathbb N \cup \{0\}$. On these annuli, $f$ is analytic, so has a unique Laurent series. First, let's consider $\{z: 0 < |z|<\pi\}$, then the solution says $$\begin{aligned} f(z)& =\frac{1}{\sin z}\\ & =\frac{1}{z-\frac{z^3}{3!}+\frac{z^5}{5!}-\cdots}\\ & =\frac{1}{z}\cdot \frac{1}{1-\left(\frac{z^2}{3!}-\frac{z^4}{5!}+\cdots\right)}\\ & =\frac{1}{z}\left[1+\left(\frac{z^2}{3!}-\frac{z^4}{5!}+\cdots\right)+\left(\frac{z^2}{3!}-\frac{z^4}{5!}+\cdots\right)^2+\cdots\right] \end{aligned}$$ My questions are: Do we need $\left|\frac{z^2}{3!}-\frac{z^4}{5!}+\cdots\right|<1$ to get the last step? If we do, then why it is less than 1? Thanks for any help!",,"['complex-analysis', 'laurent-series']"
42,Is it always true that $Log(z^{-1})=-Log(z)$,Is it always true that,Log(z^{-1})=-Log(z),"Is it always true that $Log(z^{-1})=-Log(z)$? Can we just write $z=re^{i\theta}$ and then $$-Log(z)=-(\ln r+i\theta)=-\ln r-i\theta=\ln (r^{-1})+i(-\theta)=Log(r^{-1}e^{-i\theta})=Log(z^{-1})$$ it seems suspicious to me. Note: For $z\in\mathbb{C}\setminus (-\infty,0]:Log(z)=ln|z|+iArg(z)$ Clarification: I know that it is not always true that $Log(z^{2})=2Log(z)$. So, writing $z=re^{i\theta}$ and $$2Log(z)=2(\ln r+i\theta)=2\ln r+2i\theta=\ln (r^{2})+i(2\theta)=Log(r^{2}e^{2i\theta})=Log(z^{2})$$ is false. And to me it looks kind of the same (maybe false) ""technique"".","Is it always true that $Log(z^{-1})=-Log(z)$? Can we just write $z=re^{i\theta}$ and then $$-Log(z)=-(\ln r+i\theta)=-\ln r-i\theta=\ln (r^{-1})+i(-\theta)=Log(r^{-1}e^{-i\theta})=Log(z^{-1})$$ it seems suspicious to me. Note: For $z\in\mathbb{C}\setminus (-\infty,0]:Log(z)=ln|z|+iArg(z)$ Clarification: I know that it is not always true that $Log(z^{2})=2Log(z)$. So, writing $z=re^{i\theta}$ and $$2Log(z)=2(\ln r+i\theta)=2\ln r+2i\theta=\ln (r^{2})+i(2\theta)=Log(r^{2}e^{2i\theta})=Log(z^{2})$$ is false. And to me it looks kind of the same (maybe false) ""technique"".",,"['complex-analysis', 'logarithms']"
43,Proving that an analytic function $f$ on a region $\Omega$ has an analytic $n$-root,Proving that an analytic function  on a region  has an analytic -root,f \Omega n,"I'm interested in providing a non-topological (i.e no covering theory) proof of the following fact: Let $\Omega$ be an open connected  subset of $\Bbb C$. Prove that $f\colon \Omega \to \Bbb C\setminus 0$ analytic has an analytic $n$-th root (i.e. an analytic function $g\colon  \Omega \to \Bbb C\setminus 0$ s.t. $g^n=f$) if and only if $$ \dfrac{1}{2\pi i}\int_{\gamma} \dfrac{f'}{f}dz \in n\Bbb Z$$ for every loop $\gamma$ in $\Omega$. the only if part is trivial, and I can provide a covering theory proof of the if part (basically one prove that $f$ lifts to the $n$-fold cover $\Bbb C\setminus 0 \xrightarrow{(\cdot)^n} \Bbb C \setminus 0$). I would like to see a more ""complex analysis"" flavoured proof. I tried working with local $n$-th roots (on simply connected domains in $\Omega$ and try to prove  whether they patch together but I can't see how to use the hypothesis. Can someone give me any advice?","I'm interested in providing a non-topological (i.e no covering theory) proof of the following fact: Let $\Omega$ be an open connected  subset of $\Bbb C$. Prove that $f\colon \Omega \to \Bbb C\setminus 0$ analytic has an analytic $n$-th root (i.e. an analytic function $g\colon  \Omega \to \Bbb C\setminus 0$ s.t. $g^n=f$) if and only if $$ \dfrac{1}{2\pi i}\int_{\gamma} \dfrac{f'}{f}dz \in n\Bbb Z$$ for every loop $\gamma$ in $\Omega$. the only if part is trivial, and I can provide a covering theory proof of the if part (basically one prove that $f$ lifts to the $n$-fold cover $\Bbb C\setminus 0 \xrightarrow{(\cdot)^n} \Bbb C \setminus 0$). I would like to see a more ""complex analysis"" flavoured proof. I tried working with local $n$-th roots (on simply connected domains in $\Omega$ and try to prove  whether they patch together but I can't see how to use the hypothesis. Can someone give me any advice?",,['complex-analysis']
44,Open and connected subset in $\mathbb{R}^2$,Open and connected subset in,\mathbb{R}^2,"If $U$ is an open and connected subset in $\mathbb{R}^2$, then it is path connected. In further, we assume that $U$ is in a unit ball. If its complement $U^c$ is connected, then show that $U$ is simply connected. [Add] Definition : $X$ is simply connected if there is a continuous map $h: D^2\rightarrow X$ with $h|\partial D^2=c$ when $c: S^1\rightarrow X$ is continuous map.","If $U$ is an open and connected subset in $\mathbb{R}^2$, then it is path connected. In further, we assume that $U$ is in a unit ball. If its complement $U^c$ is connected, then show that $U$ is simply connected. [Add] Definition : $X$ is simply connected if there is a continuous map $h: D^2\rightarrow X$ with $h|\partial D^2=c$ when $c: S^1\rightarrow X$ is continuous map.",,"['general-topology', 'complex-analysis']"
45,How to find the image under a Möbius transformation.,How to find the image under a Möbius transformation.,,"Find the image of the set $D_1\cap D_2$, where $$D_1 = \{z : |z| < 1\}$$ and $$D_2 = \{z : |z + 1/2| > 1/2\}$$ under the transformation $$f(z) = \frac{z − i}{z + 1}$$ I have done the picture of $D_1\cap D_2$, but I don't know how to do it. If anybody could help me, please. Thanks!","Find the image of the set $D_1\cap D_2$, where $$D_1 = \{z : |z| < 1\}$$ and $$D_2 = \{z : |z + 1/2| > 1/2\}$$ under the transformation $$f(z) = \frac{z − i}{z + 1}$$ I have done the picture of $D_1\cap D_2$, but I don't know how to do it. If anybody could help me, please. Thanks!",,['complex-analysis']
46,Complex Analysis-Proof Verification,Complex Analysis-Proof Verification,,"Let $f$ and $g$ be two holomorphic functions on the disk $D$. If $f(z)g(z)$ $=$ $0$ for all z $\in$ $D$, show that either $f$ or $g$ in constantly zero in $D$. So this is what I have gotten: Suppose $f(z)g(z) = 0$ for all $z \in D$ Let $Z(fg) = \{z\in D: \, f(z)g(z)=0\}$ is the zero set of $(fg)$ Then $Z(fg)$ has a limit point in $D$ since $Z(fg) = D$, call the limit point as $\alpha$. Let $$Z(f) = z\in D \mid f(z)=0$$ $$Z(g) = z\in D \mid g(z)=0$$ Choose $r>0$ such that $B_r$($\alpha$)$\subset$$D$ If $f(z) = 0$ for all $z$ in $B_r$($\alpha$), then $B_r(\alpha)\subset Z(f)$ and since $B_r$($\alpha$) has a limit point in $D$, so does $Z(f)$ hence $f = 0$ Now, if $f\not\equiv0$ in $B_r$($\alpha$), there is some $z_0\in B_r(\alpha)$ such that $f(z_0) \neq 0$ but then $g(z_0) = 0$ Now, let $0<r_1<r$ such that $z_0 \notin Br_1 (\alpha)$ If $f\equiv0$ on $Br_1 (\alpha)$ then, we are done. If that is not the case, there is $z_1 \in Br_1 (\alpha)$ such that $f(z_1)\neq 0$. Then, $g(z_1)=0$ Either this process will terminate ($f\equiv 0$ on $Br_c(\alpha)$ for some $i$) (or) we will have a sequence $(z_c)_{c=0}^\infty$ converging to $\alpha$. But this sequence is entirely in $Z(g)$ So $Z(g)$ has a limit point in $0$. Hence by identity theorem, $g\equiv0$ in $D$.","Let $f$ and $g$ be two holomorphic functions on the disk $D$. If $f(z)g(z)$ $=$ $0$ for all z $\in$ $D$, show that either $f$ or $g$ in constantly zero in $D$. So this is what I have gotten: Suppose $f(z)g(z) = 0$ for all $z \in D$ Let $Z(fg) = \{z\in D: \, f(z)g(z)=0\}$ is the zero set of $(fg)$ Then $Z(fg)$ has a limit point in $D$ since $Z(fg) = D$, call the limit point as $\alpha$. Let $$Z(f) = z\in D \mid f(z)=0$$ $$Z(g) = z\in D \mid g(z)=0$$ Choose $r>0$ such that $B_r$($\alpha$)$\subset$$D$ If $f(z) = 0$ for all $z$ in $B_r$($\alpha$), then $B_r(\alpha)\subset Z(f)$ and since $B_r$($\alpha$) has a limit point in $D$, so does $Z(f)$ hence $f = 0$ Now, if $f\not\equiv0$ in $B_r$($\alpha$), there is some $z_0\in B_r(\alpha)$ such that $f(z_0) \neq 0$ but then $g(z_0) = 0$ Now, let $0<r_1<r$ such that $z_0 \notin Br_1 (\alpha)$ If $f\equiv0$ on $Br_1 (\alpha)$ then, we are done. If that is not the case, there is $z_1 \in Br_1 (\alpha)$ such that $f(z_1)\neq 0$. Then, $g(z_1)=0$ Either this process will terminate ($f\equiv 0$ on $Br_c(\alpha)$ for some $i$) (or) we will have a sequence $(z_c)_{c=0}^\infty$ converging to $\alpha$. But this sequence is entirely in $Z(g)$ So $Z(g)$ has a limit point in $0$. Hence by identity theorem, $g\equiv0$ in $D$.",,"['proof-verification', 'holomorphic-functions']"
47,prove that $\sum_{n=1}^{\infty} \frac{z^n}{n!}$ does not converge uniformly to $e^z$ on $\mathbb{C}$,prove that  does not converge uniformly to  on,\sum_{n=1}^{\infty} \frac{z^n}{n!} e^z \mathbb{C},"How can I prove that $\sum_{n=1}^{\infty} \frac{z^n}{n!}$ does not converge uniformly to $e^z$ on $\mathbb{C}$? My intuition is to assume, for a contraction, that a power series converges uniformly on $\mathbb{C}$. Then, let $$S_{m}(z) = \left(1+\frac{z}{1!}+\frac{z^{2}}{2!}+···+\frac{z^{m}}{m!}\right)−e^{z}.$$ Consider $$|S_{K+1}(z) − S_{K}(z)|$$ as $z \to \infty$ to get a contradiction. Can I get some help in formulating the details or any other more elegant approach in this?","How can I prove that $\sum_{n=1}^{\infty} \frac{z^n}{n!}$ does not converge uniformly to $e^z$ on $\mathbb{C}$? My intuition is to assume, for a contraction, that a power series converges uniformly on $\mathbb{C}$. Then, let $$S_{m}(z) = \left(1+\frac{z}{1!}+\frac{z^{2}}{2!}+···+\frac{z^{m}}{m!}\right)−e^{z}.$$ Consider $$|S_{K+1}(z) − S_{K}(z)|$$ as $z \to \infty$ to get a contradiction. Can I get some help in formulating the details or any other more elegant approach in this?",,['complex-analysis']
48,Evaluate using contour integration $\int_0^{\pi}\frac{\sin(2\theta)}{5-3\cos(\theta)}d\theta$,Evaluate using contour integration,\int_0^{\pi}\frac{\sin(2\theta)}{5-3\cos(\theta)}d\theta,"I had been given in my complex analysis examination the following problem. Evaluate the following integral by using contour integration: $$ \int_0^{\pi}\dfrac{\sin(2\theta)}{5-3\cos(\theta)}d\theta $$ The answer to which is: $$ \dfrac{2}{9}(log_e(1024)-6). $$ I tried to get this answer trying different ways but I just could not find a way to do it. A thing to notice is that there is no $\pi$ term occurring in the final answer which means whatever the contour is which will give the answer easily is such that by integrating along that contour the value which we will get will be proportional to $\dfrac{1}{i\pi }$. This is because the $2\pi i$ term multiplying the residue should be canceled out as the actual answer does not have $\pi$ dependence. The $pi$ in the denominator gives a hint to me that this going to be complicated as in complex analysis at least in introductory courses nowhere $\pi$ comes in the denominator unless the problem is intentionally set up that way. Another thing to notice is that if we have to use a contour that covers the angle from $0$ to $\pi$. Usually, the limits given in such problems is $0$ to $2\pi$ which is easy to do just by replacing $sine$ and $cosine$ term as follows: $$  sin(\theta) \rightarrow \dfrac{1}{2i}(z-\dfrac{1}{z}) $$ $$  cos(\theta) \rightarrow \dfrac{1}{2}(z+\dfrac{1}{z}) $$ $$ d\theta \rightarrow \dfrac{dz}{iz} $$ and then carrying out the contour integral along $|z|=1$ contour. The limits of the integral could be converted to $0$ to $2\pi$ by proper substitution and then the contour integral by above procedure could be carried out but that would not help as it will bring in fractional order poles (as $cos\dfrac{\theta}{2}$  term will appear) which residue theory can't deal with. So, what I need is a hint on how to do it.","I had been given in my complex analysis examination the following problem. Evaluate the following integral by using contour integration: $$ \int_0^{\pi}\dfrac{\sin(2\theta)}{5-3\cos(\theta)}d\theta $$ The answer to which is: $$ \dfrac{2}{9}(log_e(1024)-6). $$ I tried to get this answer trying different ways but I just could not find a way to do it. A thing to notice is that there is no $\pi$ term occurring in the final answer which means whatever the contour is which will give the answer easily is such that by integrating along that contour the value which we will get will be proportional to $\dfrac{1}{i\pi }$. This is because the $2\pi i$ term multiplying the residue should be canceled out as the actual answer does not have $\pi$ dependence. The $pi$ in the denominator gives a hint to me that this going to be complicated as in complex analysis at least in introductory courses nowhere $\pi$ comes in the denominator unless the problem is intentionally set up that way. Another thing to notice is that if we have to use a contour that covers the angle from $0$ to $\pi$. Usually, the limits given in such problems is $0$ to $2\pi$ which is easy to do just by replacing $sine$ and $cosine$ term as follows: $$  sin(\theta) \rightarrow \dfrac{1}{2i}(z-\dfrac{1}{z}) $$ $$  cos(\theta) \rightarrow \dfrac{1}{2}(z+\dfrac{1}{z}) $$ $$ d\theta \rightarrow \dfrac{dz}{iz} $$ and then carrying out the contour integral along $|z|=1$ contour. The limits of the integral could be converted to $0$ to $2\pi$ by proper substitution and then the contour integral by above procedure could be carried out but that would not help as it will bring in fractional order poles (as $cos\dfrac{\theta}{2}$  term will appear) which residue theory can't deal with. So, what I need is a hint on how to do it.",,"['integration', 'complex-analysis', 'definite-integrals', 'contour-integration', 'residue-calculus']"
49,Does a complex number have finitely many distinct powers?,Does a complex number have finitely many distinct powers?,,"Let's say I have a complex number, $z=a+bi$ such that $z$ is a root of unity. It's clear that $\mathrm {arg}(z)= \arctan\left(\frac{b}{a}\right)$. Can I conclude that $z$ has $\left|\frac{2\pi}{\mathrm {arg}(z)}\right|$ distinct integral powers? What can we say if I raise $z$ to real powers rather than integral? And lastly what about complex powers? Will there be finite distinct powers?","Let's say I have a complex number, $z=a+bi$ such that $z$ is a root of unity. It's clear that $\mathrm {arg}(z)= \arctan\left(\frac{b}{a}\right)$. Can I conclude that $z$ has $\left|\frac{2\pi}{\mathrm {arg}(z)}\right|$ distinct integral powers? What can we say if I raise $z$ to real powers rather than integral? And lastly what about complex powers? Will there be finite distinct powers?",,"['complex-analysis', 'complex-numbers']"
50,Deduce Poisson's integral formula from the mean value theorem,Deduce Poisson's integral formula from the mean value theorem,,"This question is from the book Complex Analysis by Stein: Let $u$ be a harmonic function in the unit disc that is continuous on it closure. Then, deduce Poisson's integral formula: $$u(z_{0}) = \frac{1}{2\pi}\int_{0}^{2\pi}\frac{1-\left\lvert z_{0}\right\rvert^{2}}{\left\lvert e^{i\theta}-z_{0}\right\rvert^{2}}\,u\!\left(e^{i\theta}\right)d\theta$$ for $\left\lvert z_{0}\right\rvert<1$ . Show that if $z_{0}=re^{i\phi}$ then, $$\frac{1-\left\lvert z_{0}\right\rvert^{2}}{\left\lvert e^{i\theta}-z_{0}\right\rvert^{2}}=\frac{1-r^{2}}{1-2r\cos(\theta -\phi)+r^{2}}$$ I have read some proofs posted here and they directly proved the general result, which is really good, such as the proof here: Deriving the Poisson Integral Formula from the Cauchy Integral Formula I understand those expert proofs, but the question in the book gives a hint which confuses me a lot. The hint: Set $u_{0}(z)=u(T(z))$ , where $T(z)=\frac{z_{0}-z}{1-\bar{z_{0}}z}$ . Prove that $u_{0}(z)$ is harmonic, the apply the mean value theorem to $u_{0}$ and make a change of variables in the integral. I am stuck in the first step, I don't really know how to show $u_{0}(z)$ is harmonic, since it is hard for me to calculate the Laplace. Is there any way out to do this question following the hint? Any explanations are really really appreciated!!! Edit 1: Okay. Thanks to the answer, I figured out how to prove $u_{0}(z)$ is harmonic, and then I proceed to next part. Now, since $u_{0}(z)$ is harmonic in the unit disc, we apply Mean-Value property for Harmonic function to $u_{0}(z)$ at $z_{0}=0$ . $u_{0}(0)=u\circ T(0)=u(z_{0})=\frac{1}{2\pi}\int_{0}^{2\pi}u_{0}(re^{i\theta})d\theta=\frac{1}{2\pi}\int_{0}^{2\pi}u\circ T(re^{i\theta})d\theta=\frac{1}{2\pi}\int_{0}^{2\pi}u(\frac{z_{0}-re^{i\theta}}{1-\bar{z_{0}}re^{i\theta}})d\theta$ , for all $0<r<1$ And I don't know how to do next. How can I get all other terms out of $u$ only learning $u(e^{i\theta})$ ? Also, why in the Poisson's integral formula, $r=1$ ? or I have to take limit $r\rightarrow 1^{-}$ ?","This question is from the book Complex Analysis by Stein: Let be a harmonic function in the unit disc that is continuous on it closure. Then, deduce Poisson's integral formula: for . Show that if then, I have read some proofs posted here and they directly proved the general result, which is really good, such as the proof here: Deriving the Poisson Integral Formula from the Cauchy Integral Formula I understand those expert proofs, but the question in the book gives a hint which confuses me a lot. The hint: Set , where . Prove that is harmonic, the apply the mean value theorem to and make a change of variables in the integral. I am stuck in the first step, I don't really know how to show is harmonic, since it is hard for me to calculate the Laplace. Is there any way out to do this question following the hint? Any explanations are really really appreciated!!! Edit 1: Okay. Thanks to the answer, I figured out how to prove is harmonic, and then I proceed to next part. Now, since is harmonic in the unit disc, we apply Mean-Value property for Harmonic function to at . , for all And I don't know how to do next. How can I get all other terms out of only learning ? Also, why in the Poisson's integral formula, ? or I have to take limit ?","u u(z_{0}) = \frac{1}{2\pi}\int_{0}^{2\pi}\frac{1-\left\lvert z_{0}\right\rvert^{2}}{\left\lvert e^{i\theta}-z_{0}\right\rvert^{2}}\,u\!\left(e^{i\theta}\right)d\theta \left\lvert z_{0}\right\rvert<1 z_{0}=re^{i\phi} \frac{1-\left\lvert z_{0}\right\rvert^{2}}{\left\lvert e^{i\theta}-z_{0}\right\rvert^{2}}=\frac{1-r^{2}}{1-2r\cos(\theta -\phi)+r^{2}} u_{0}(z)=u(T(z)) T(z)=\frac{z_{0}-z}{1-\bar{z_{0}}z} u_{0}(z) u_{0} u_{0}(z) u_{0}(z) u_{0}(z) u_{0}(z) z_{0}=0 u_{0}(0)=u\circ T(0)=u(z_{0})=\frac{1}{2\pi}\int_{0}^{2\pi}u_{0}(re^{i\theta})d\theta=\frac{1}{2\pi}\int_{0}^{2\pi}u\circ T(re^{i\theta})d\theta=\frac{1}{2\pi}\int_{0}^{2\pi}u(\frac{z_{0}-re^{i\theta}}{1-\bar{z_{0}}re^{i\theta}})d\theta 0<r<1 u u(e^{i\theta}) r=1 r\rightarrow 1^{-}","['complex-analysis', 'harmonic-analysis']"
51,"Given finite subset of $\mathbb C[[X]]$, does there exist a ring automorphism of $\mathbb C[[X]]$, fixing $A$, but not fixing $\mathbb C[X]$ set wise?","Given finite subset of , does there exist a ring automorphism of , fixing , but not fixing  set wise?",\mathbb C[[X]] \mathbb C[[X]] A \mathbb C[X],"For every  finite subset $A $ of $\mathbb C[[X]]$, does there exist a ring automorphism (bijective ring endomorphism ) $f$ of $\mathbb C[[X]]$ such that $f(a)=a, \forall a \in A$ but $f(\mathbb C[X]) \ne \mathbb C[X]$ ? Related Are $\mathbb C$ , $\mathbb C[X]$ definable in $\mathbb C[[X]]$? because if $D \subseteq M$ is definable by a set $A \subseteq M$  then $f(D)=D, \forall f \in Aut_A M$ , and in the related case we mean definable by some finite subset of $M$.","For every  finite subset $A $ of $\mathbb C[[X]]$, does there exist a ring automorphism (bijective ring endomorphism ) $f$ of $\mathbb C[[X]]$ such that $f(a)=a, \forall a \in A$ but $f(\mathbb C[X]) \ne \mathbb C[X]$ ? Related Are $\mathbb C$ , $\mathbb C[X]$ definable in $\mathbb C[[X]]$? because if $D \subseteq M$ is definable by a set $A \subseteq M$  then $f(D)=D, \forall f \in Aut_A M$ , and in the related case we mean definable by some finite subset of $M$.",,"['complex-analysis', 'polynomials', 'ring-theory', 'commutative-algebra', 'formal-power-series']"
52,Jump of dilogarithm,Jump of dilogarithm,,"I am reading about the dilogarithm function $$ \mathrm{Li}_2(z):= - \int_0^z \frac{\log(1-u)}{u}du, \quad z \in \mathbb{C} \backslash [1, \infty).$$ I found it stated that the ""jump"" of the dilogarithm across the axis where it is not defined is $2\pi i \log(r)$ for crossing at $r>1$. Why is that so? I can see that $\log(1-u)$ jumps by $2\pi i$ when $u$ crosses the axis, but I cannot see how to procede from there.","I am reading about the dilogarithm function $$ \mathrm{Li}_2(z):= - \int_0^z \frac{\log(1-u)}{u}du, \quad z \in \mathbb{C} \backslash [1, \infty).$$ I found it stated that the ""jump"" of the dilogarithm across the axis where it is not defined is $2\pi i \log(r)$ for crossing at $r>1$. Why is that so? I can see that $\log(1-u)$ jumps by $2\pi i$ when $u$ crosses the axis, but I cannot see how to procede from there.",,"['integration', 'complex-analysis', 'polylogarithm']"
53,Intuition with Complex Derivatives of a Complex Variable.,Intuition with Complex Derivatives of a Complex Variable.,,"I'm having some trouble wrapping my mind around derivatives of a complex function of a complex variable.This is a function of two real inputs and two real outputs, correct? What confuses me is that in multivariable calculus, the functions were of multivariable input, and had one real output.  So when calculating the derivative, you'd have to know what vector you're calculating it on. In the complex space however, with two inputs and two outputs, I feel like this would also be the case? But it seems like we can use all the standard rules from single variable calc. What am I misunderstanding? Thanks!","I'm having some trouble wrapping my mind around derivatives of a complex function of a complex variable.This is a function of two real inputs and two real outputs, correct? What confuses me is that in multivariable calculus, the functions were of multivariable input, and had one real output.  So when calculating the derivative, you'd have to know what vector you're calculating it on. In the complex space however, with two inputs and two outputs, I feel like this would also be the case? But it seems like we can use all the standard rules from single variable calc. What am I misunderstanding? Thanks!",,"['complex-analysis', 'intuition']"
54,"Setting up bounds for the integral $(\int_{U}|f(x,y)|^{2}dxdy)^{\frac{1}{2}}$?",Setting up bounds for the integral ?,"(\int_{U}|f(x,y)|^{2}dxdy)^{\frac{1}{2}}","In the text ""Functions of a Complex Variable"" by Robert E.Grenne and Steven G. Knartz I'm having the trouble with figuring out a method of attack for $\text{Proposition (1.1)}$ specifically getting the integral $(\int_{U}|f(x,y)|dxdy)^{\frac{1}{2}}$ into a more manageable form, may I have a hint to achieve this ? $\text{Proposition (1.1)}$ Let $U \subset \mathbb{C}$ be an open set and let $K$ be a compact subset $U$. Show that there is a constant $C$ $\text{(depending on U and K)}$ such that if $f$ is holomorphic on $U$, then in $(1.2)$ $(1.2)$ $$\sup_{K}|f| \leq C \cdot \big(\int_{U}|f(x,y)|^{2}dxdy \big)^{\frac{1}{2}}$$","In the text ""Functions of a Complex Variable"" by Robert E.Grenne and Steven G. Knartz I'm having the trouble with figuring out a method of attack for $\text{Proposition (1.1)}$ specifically getting the integral $(\int_{U}|f(x,y)|dxdy)^{\frac{1}{2}}$ into a more manageable form, may I have a hint to achieve this ? $\text{Proposition (1.1)}$ Let $U \subset \mathbb{C}$ be an open set and let $K$ be a compact subset $U$. Show that there is a constant $C$ $\text{(depending on U and K)}$ such that if $f$ is holomorphic on $U$, then in $(1.2)$ $(1.2)$ $$\sup_{K}|f| \leq C \cdot \big(\int_{U}|f(x,y)|^{2}dxdy \big)^{\frac{1}{2}}$$",,['complex-analysis']
55,modular form $q-$expansion not quite same as Laurent expansion to define the order of function at a point?,modular form expansion not quite same as Laurent expansion to define the order of function at a point?,q-,"Let $f$ be a modular form where $f:H\to \bar{C}$ is any meromorphic modular form. Say I want to study the singularity behaviour at $i\infty$ of $f$. I can consider $z\to \frac{1}{z}$ map. Then $f(\frac{1}{z})$ will give rise to laurent expansion $g(z)$ around $z=0$. The other thing to get is $q-$ expansion $h(q)$ for $f$ at $q=0$ where $q=e^{2\pi iz}$. Q1: Why order of $f$ at $i\infty$ is defined in terms of lowest degree of $q$ expansion here instead of laurent expansion $f(\frac{1}{z})$ at $z=0$'s degree? Q2: Should not they contain the same information? Q3: Say $f$ is weight $0$, then $f'$ is modular form of weight $2$.(This can be proven very easily.) Now I can consider either Laurent expansion's order at $i\infty$ and $q-$expansion's order of $f'$.($f'=\frac{df}{dz}$). They give me different order here for $f=j$ where $j$ is absolute modular invariant defined over the $H$ upper half plane. Was there anything wrong with my reasoning below? Q3 a) Since $j$ has simple pole at $i\infty$, $j(w)\sim\frac{1}{w}$ where $w=\frac{1}{z}$.(I am only concerned about the order the pole here.) So $j'(w)\sim-\frac{1}{w^2}$ by taking derivative. This gives me a second order pole from laurent expansion's derivative. So order of $j'(z)$ at $z=i\infty$ is $-2$. Q3 b) Consider $q=e^{2\pi iz}$ expansion and $j$ and one sees $j(q)\sim \frac{1}{q}$ as leading order. Take derivative to see $\frac{dj}{dz}=\frac{dj(q)}{dq}\frac{dq}{dz}\sim \frac{1}{q^2}\times -2\pi i q\sim\frac{1}{q}$. This says order of $j'$ at $i\infty$ is $-1$.","Let $f$ be a modular form where $f:H\to \bar{C}$ is any meromorphic modular form. Say I want to study the singularity behaviour at $i\infty$ of $f$. I can consider $z\to \frac{1}{z}$ map. Then $f(\frac{1}{z})$ will give rise to laurent expansion $g(z)$ around $z=0$. The other thing to get is $q-$ expansion $h(q)$ for $f$ at $q=0$ where $q=e^{2\pi iz}$. Q1: Why order of $f$ at $i\infty$ is defined in terms of lowest degree of $q$ expansion here instead of laurent expansion $f(\frac{1}{z})$ at $z=0$'s degree? Q2: Should not they contain the same information? Q3: Say $f$ is weight $0$, then $f'$ is modular form of weight $2$.(This can be proven very easily.) Now I can consider either Laurent expansion's order at $i\infty$ and $q-$expansion's order of $f'$.($f'=\frac{df}{dz}$). They give me different order here for $f=j$ where $j$ is absolute modular invariant defined over the $H$ upper half plane. Was there anything wrong with my reasoning below? Q3 a) Since $j$ has simple pole at $i\infty$, $j(w)\sim\frac{1}{w}$ where $w=\frac{1}{z}$.(I am only concerned about the order the pole here.) So $j'(w)\sim-\frac{1}{w^2}$ by taking derivative. This gives me a second order pole from laurent expansion's derivative. So order of $j'(z)$ at $z=i\infty$ is $-2$. Q3 b) Consider $q=e^{2\pi iz}$ expansion and $j$ and one sees $j(q)\sim \frac{1}{q}$ as leading order. Take derivative to see $\frac{dj}{dz}=\frac{dj(q)}{dq}\frac{dq}{dz}\sim \frac{1}{q^2}\times -2\pi i q\sim\frac{1}{q}$. This says order of $j'$ at $i\infty$ is $-1$.",,"['complex-analysis', 'number-theory', 'meromorphic-functions', 'modular-forms']"
56,"stein's complex analysis, functions of finite order.","stein's complex analysis, functions of finite order.",,"An entire function $f$ is said to be of finite order if there exists $\rho > 0$ and constants $A, B>0$ such that      \begin{equation}\label{eq:growth order} 		\lvert f(z)\rvert \leq Ae^{B\lvert z\rvert^\rho} \qquad \forall z\in\mathbb{C} 	\end{equation}     The growth order of $f$ is $\rho_f = \inf \rho$ where the infimum is taken over all $\rho > 0$ for which there exists constants $A, B$ such that the above equation holds. Let $n(r)$ denote the number of zeroes of a function $f$ in the disk of radius $r$ about the origin. Stein's theorem 2.1 states that if $f$ is entire and $\rho_f \leq \rho$, then there exists a constant $C>0$ such that $n(r) \leq Cr^\rho$ for all sufficiently large $r$. Here, $n(r)$ denotes the number of zeroes in a disk about the origin of radius $r$. PROOF.Suppose first that $f(0) \neq 0$ and note that since $n(r)$ is an increasing function,      $$ 		n(r) = \frac{n(r)}{\log(2)}\int_r^{2r}\frac{1}{x}\,\mathrm{d}{x} \leq \frac{1}{\log(2)}\int_r^{2r}\frac{n(x)}{x}\,\mathrm{d}{x} 	$$     By the previous lemma,     $$ 		\int_r^{2r}\frac{n(x)}{x}\,\mathrm{d}{x} \leq \frac{1}{2\pi}\int_0^{2\pi}\log\lvert f\left(2re^{it}\right)\rvert\,\mathrm{d}{t} - \lvert f(0)\rvert  	$$ Then for all sufficiently large $r$; $$ \int_0^{2\pi}\log\lvert f(2re^{it})\rvert dt\leq \int_0^{2\pi}\log\lvert A\exp\{B(2r)^\rho\} \rvert \,\mathrm{d}t \leq C r^\rho $$ for some constant $C$. Why do we need $r$ to be large? I am wondering if the assumption can be removed.","An entire function $f$ is said to be of finite order if there exists $\rho > 0$ and constants $A, B>0$ such that      \begin{equation}\label{eq:growth order} 		\lvert f(z)\rvert \leq Ae^{B\lvert z\rvert^\rho} \qquad \forall z\in\mathbb{C} 	\end{equation}     The growth order of $f$ is $\rho_f = \inf \rho$ where the infimum is taken over all $\rho > 0$ for which there exists constants $A, B$ such that the above equation holds. Let $n(r)$ denote the number of zeroes of a function $f$ in the disk of radius $r$ about the origin. Stein's theorem 2.1 states that if $f$ is entire and $\rho_f \leq \rho$, then there exists a constant $C>0$ such that $n(r) \leq Cr^\rho$ for all sufficiently large $r$. Here, $n(r)$ denotes the number of zeroes in a disk about the origin of radius $r$. PROOF.Suppose first that $f(0) \neq 0$ and note that since $n(r)$ is an increasing function,      $$ 		n(r) = \frac{n(r)}{\log(2)}\int_r^{2r}\frac{1}{x}\,\mathrm{d}{x} \leq \frac{1}{\log(2)}\int_r^{2r}\frac{n(x)}{x}\,\mathrm{d}{x} 	$$     By the previous lemma,     $$ 		\int_r^{2r}\frac{n(x)}{x}\,\mathrm{d}{x} \leq \frac{1}{2\pi}\int_0^{2\pi}\log\lvert f\left(2re^{it}\right)\rvert\,\mathrm{d}{t} - \lvert f(0)\rvert  	$$ Then for all sufficiently large $r$; $$ \int_0^{2\pi}\log\lvert f(2re^{it})\rvert dt\leq \int_0^{2\pi}\log\lvert A\exp\{B(2r)^\rho\} \rvert \,\mathrm{d}t \leq C r^\rho $$ for some constant $C$. Why do we need $r$ to be large? I am wondering if the assumption can be removed.",,"['complex-analysis', 'analysis', 'inequality']"
57,"Closed form solution for $\int_0^{\infty } \frac{\sin ({n}/{x})}{e^{2 \pi x}-1} \, dx$",Closed form solution for,"\int_0^{\infty } \frac{\sin ({n}/{x})}{e^{2 \pi x}-1} \, dx","Is there a closed form solution for the following  integral $$\int_0^{\infty } \frac{\sin \left(\frac{n}{x}\right)}{e^{2 \pi  x}-1} \, dx$$ for $n>0$",Is there a closed form solution for the following  integral for,"\int_0^{\infty } \frac{\sin \left(\frac{n}{x}\right)}{e^{2 \pi  x}-1} \, dx n>0","['calculus', 'integration', 'complex-analysis', 'improper-integrals', 'closed-form']"
58,"Find $\int_\gamma \frac{dz}{(z-\frac{1}{2}-i)(z-1-\frac{3i}{2})(z-1-\frac{i}{2})(z-\frac{3}{2}-i)}\, $",Find,"\int_\gamma \frac{dz}{(z-\frac{1}{2}-i)(z-1-\frac{3i}{2})(z-1-\frac{i}{2})(z-\frac{3}{2}-i)}\, ","Let $f(z)=\frac{1}{[(z-\frac{1}{2}-i)(z-1-\frac{3i}{2})(z-1-\frac{i}{2})(z-\frac{3}{2}-i)]}$ and let $\gamma$ be the polygon $[0,2,2+2i,2i,0]$. Find $\int_{\gamma}^{} f$ . I'm trying to use the partial fractions decomposition method, but it's getting too long and I'm lost in the accounts. I do not know if the author expects me to do so. Can anybody help me? Conway, pg. 96, prob., 7.","Let $f(z)=\frac{1}{[(z-\frac{1}{2}-i)(z-1-\frac{3i}{2})(z-1-\frac{i}{2})(z-\frac{3}{2}-i)]}$ and let $\gamma$ be the polygon $[0,2,2+2i,2i,0]$. Find $\int_{\gamma}^{} f$ . I'm trying to use the partial fractions decomposition method, but it's getting too long and I'm lost in the accounts. I do not know if the author expects me to do so. Can anybody help me? Conway, pg. 96, prob., 7.",,"['integration', 'complex-analysis', 'curves']"
59,laurent series of $\frac{z^2-2z+2}{(z-1)(z^2-2z-3)}$ around $z-1$ for $0<|z-1|<2$,laurent series of  around  for,\frac{z^2-2z+2}{(z-1)(z^2-2z-3)} z-1 0<|z-1|<2,"I want to find the Laurent series of $L=\frac{z^2-2z+2}{(z-1)(z^2-2z+3}$ around $(z-1)$ Here, I used the fact that  $L=\frac{5}{8(z-3)}+\frac{5}{8(z+1)}-\frac{1}{4(z-1)}$ When $|z-1|<2$, we have $L=\frac{-1}{4(z-1)}+\frac{5}{8} \frac{1}{(z-1)-2} +\frac{5}{8( (z-1)+2)}$ $=\frac{-1}{4(z-1)} +\frac{5}{-16}\frac{1}{1- \frac{(z-1)}{2}} + \frac{5}{16} \frac{1}{1+ \frac{(z-1)}{2}} =-\frac{1}{4(z-1)}+ \frac{5}{16} \sum_{k=0}^\infty \frac{(z-1)^k}{2^k}(-1+(-1)^k)=-\frac{1}{4(z-1)}+\frac{5}{16} \sum_{n=0}^\infty \frac{(z-1)^{2n+1}}{2^{2n+1}} (-2)$ However,in my book, Elements d'analyse complexe by Real Gelinas, the answer for 0<|z-1|<2 is $\frac{-1}{4} (z-1 + \frac{1}{z-1} )\sum_{n=0}^\infty (\frac{z-1}{2n})^{2n}.$ Hence, I am missing a term. Where is my mistake?","I want to find the Laurent series of $L=\frac{z^2-2z+2}{(z-1)(z^2-2z+3}$ around $(z-1)$ Here, I used the fact that  $L=\frac{5}{8(z-3)}+\frac{5}{8(z+1)}-\frac{1}{4(z-1)}$ When $|z-1|<2$, we have $L=\frac{-1}{4(z-1)}+\frac{5}{8} \frac{1}{(z-1)-2} +\frac{5}{8( (z-1)+2)}$ $=\frac{-1}{4(z-1)} +\frac{5}{-16}\frac{1}{1- \frac{(z-1)}{2}} + \frac{5}{16} \frac{1}{1+ \frac{(z-1)}{2}} =-\frac{1}{4(z-1)}+ \frac{5}{16} \sum_{k=0}^\infty \frac{(z-1)^k}{2^k}(-1+(-1)^k)=-\frac{1}{4(z-1)}+\frac{5}{16} \sum_{n=0}^\infty \frac{(z-1)^{2n+1}}{2^{2n+1}} (-2)$ However,in my book, Elements d'analyse complexe by Real Gelinas, the answer for 0<|z-1|<2 is $\frac{-1}{4} (z-1 + \frac{1}{z-1} )\sum_{n=0}^\infty (\frac{z-1}{2n})^{2n}.$ Hence, I am missing a term. Where is my mistake?",,['complex-analysis']
60,A complex-valued harmonic function of which the absolute value has a maximum point is constant,A complex-valued harmonic function of which the absolute value has a maximum point is constant,,"Let $\Omega \subseteq \mathbb R^n$ be an open, connected domain, and let $u: \Omega \to \mathbb C$ be (complex-)harmonic on $\Omega$. Furthermore, let $|u|$ have a (global) maximum in some point $x_0 \in \Omega$, i.e. we have $u(x_0) = \sup_\Omega u$. I now want to show that $u$ is constant on all of $\Omega$. Now my approach was to somehow apply the (strong) maximum principle which tells me that any subharmonic function $\Omega \to \mathbb R$ on a connected open set $\Omega \subseteq \mathbb R^n$ that has a maximum within $\Omega$ is constant. My problem is that in the above preliminaries, I have a harmonic function $\Omega \to \mathbb C$, so I think I have to apply the maximum principle for its absolute value $|u|: \Omega \to \mathbb R$ instead, but do I know in this given context that $|u|$ is subharmonic,  and if so, how could I see/deduce that?","Let $\Omega \subseteq \mathbb R^n$ be an open, connected domain, and let $u: \Omega \to \mathbb C$ be (complex-)harmonic on $\Omega$. Furthermore, let $|u|$ have a (global) maximum in some point $x_0 \in \Omega$, i.e. we have $u(x_0) = \sup_\Omega u$. I now want to show that $u$ is constant on all of $\Omega$. Now my approach was to somehow apply the (strong) maximum principle which tells me that any subharmonic function $\Omega \to \mathbb R$ on a connected open set $\Omega \subseteq \mathbb R^n$ that has a maximum within $\Omega$ is constant. My problem is that in the above preliminaries, I have a harmonic function $\Omega \to \mathbb C$, so I think I have to apply the maximum principle for its absolute value $|u|: \Omega \to \mathbb R$ instead, but do I know in this given context that $|u|$ is subharmonic,  and if so, how could I see/deduce that?",,"['complex-analysis', 'partial-differential-equations', 'harmonic-functions']"
61,The max of the modulus of difference of a continuous function,The max of the modulus of difference of a continuous function,,"Let $I=[a,b]$ be a closed real interval Let $f: I \to \mathbb{C}$ be a continuous function such that $|f(x)|$ is strictly decreasing I would like to know if is it true that $$ \max_{x,y \in I} |f(x)-f(y)| = |f(a)-f(b)| $$","Let $I=[a,b]$ be a closed real interval Let $f: I \to \mathbb{C}$ be a continuous function such that $|f(x)|$ is strictly decreasing I would like to know if is it true that $$ \max_{x,y \in I} |f(x)-f(y)| = |f(a)-f(b)| $$",,"['complex-analysis', 'supremum-and-infimum']"
62,Conformal map taking horizontal strip in second quadrant to the first quadrant,Conformal map taking horizontal strip in second quadrant to the first quadrant,,"I've been reading about confromal maps and fractional linear maps, and have the following problem: Find a conformal map taking the horizontal strip $\{z \in \mathbb{C}: \text{Re}(z) < 0 \space \text{ and } \space 0 < \text{Im}(z) < \pi \}$ to the first quadrant I've read some solutions to problems of this nature, but seem to generally have trouble with the intuition behind them. I've basically just been doing guess work, and am seeking a more intuitive explanation. If I could map the horizontal strip to a quadrant, then rotation solves the issue. If I could map the horizontal strip to a half-plane, then some combination of rotation and $\sqrt{z}$ will work. If I could map the horizontal strip to the full horizontal strip $0 < \text{Im}(z) < \pi$, then using $e^{z/2}$ should do the trick. However, I can't seem to figure out how to map the horizontal half-strip to any of these three cases.","I've been reading about confromal maps and fractional linear maps, and have the following problem: Find a conformal map taking the horizontal strip $\{z \in \mathbb{C}: \text{Re}(z) < 0 \space \text{ and } \space 0 < \text{Im}(z) < \pi \}$ to the first quadrant I've read some solutions to problems of this nature, but seem to generally have trouble with the intuition behind them. I've basically just been doing guess work, and am seeking a more intuitive explanation. If I could map the horizontal strip to a quadrant, then rotation solves the issue. If I could map the horizontal strip to a half-plane, then some combination of rotation and $\sqrt{z}$ will work. If I could map the horizontal strip to the full horizontal strip $0 < \text{Im}(z) < \pi$, then using $e^{z/2}$ should do the trick. However, I can't seem to figure out how to map the horizontal half-strip to any of these three cases.",,"['complex-analysis', 'conformal-geometry']"
63,Are the generalized zeroes of an analytic function necessarily isolated?,Are the generalized zeroes of an analytic function necessarily isolated?,,"The zeroes of any non-zero analytic function $\mathbb{R} \rightarrow \mathbb{R}$ are isolated. By a generalized zero of a smooth function $f:\mathbb{R} \rightarrow \mathbb{R}$, let us mean a zero of $f^{(n)}$ for some natural number $n \in \{0,1,2\ldots\}$. Are the generalized zeroes of a non-polynomial analytic function $\mathbb{R} \rightarrow \mathbb{R}$ necessarily isolated? My guess is 'no', but if the answer is yes, I'm also interested in the complex case where $\mathbb{R}$ is replaced by $\mathbb{C}$.","The zeroes of any non-zero analytic function $\mathbb{R} \rightarrow \mathbb{R}$ are isolated. By a generalized zero of a smooth function $f:\mathbb{R} \rightarrow \mathbb{R}$, let us mean a zero of $f^{(n)}$ for some natural number $n \in \{0,1,2\ldots\}$. Are the generalized zeroes of a non-polynomial analytic function $\mathbb{R} \rightarrow \mathbb{R}$ necessarily isolated? My guess is 'no', but if the answer is yes, I'm also interested in the complex case where $\mathbb{R}$ is replaced by $\mathbb{C}$.",,"['real-analysis', 'complex-analysis', 'power-series', 'examples-counterexamples']"
64,Conformal mapping from upper half plane to a triangle,Conformal mapping from upper half plane to a triangle,,"Let $T$ be the closed triangle with vertices at complex numbers $0, i, \dfrac12+\dfrac{i}2.$ How do we find explicit formula for the conformal mapping from upper half plane to $\Bbb{\overline C}\setminus T$? I know this is an application of Schwarz–Christoffel mappings, but do not know how to it works with these complex numbers.","Let $T$ be the closed triangle with vertices at complex numbers $0, i, \dfrac12+\dfrac{i}2.$ How do we find explicit formula for the conformal mapping from upper half plane to $\Bbb{\overline C}\setminus T$? I know this is an application of Schwarz–Christoffel mappings, but do not know how to it works with these complex numbers.",,"['complex-analysis', 'complex-numbers', 'triangles', 'conformal-geometry']"
65,Inverse Laplace transform of $\frac{1}{s^b-c}$.,Inverse Laplace transform of .,\frac{1}{s^b-c},"I am trying to find the inverse Laplace transform of $$F(s) = \frac{1}{(1+a\,s)^b-c}$$ where $a$ , $b$ , and $c$ are positive real numbers. For $c=0$ , we can use the following: $$\mathcal L^{-1}\left\{\frac1{s^b}\right\}=\frac{x^{b-1}}{\Gamma(b)}, \qquad for\quad b>0$$ Then we have $$\mathcal L^{-1}\left\{\frac1{(1+a s)^b}\right\} =\frac1{a^b}\mathcal L^{-1}\left\{\frac1{(\frac1{a}+s)^b}\right\} =\frac{e^{-\frac{x}{a}}}{a^b}\mathcal L^{-1}\left\{\frac1{s^b}\right\} =\frac{e^{-\frac{x}{a}}}{a^b}\frac{x^{b-1}}{\Gamma(b)}.$$ Now, what do I do with $c\neq 0\,$ ? This simplifies the question to: What is the inverse Laplace transform of $F(s)$ given by: $$\frac{1}{s^b-c}?$$","I am trying to find the inverse Laplace transform of where , , and are positive real numbers. For , we can use the following: Then we have Now, what do I do with ? This simplifies the question to: What is the inverse Laplace transform of given by:","F(s) = \frac{1}{(1+a\,s)^b-c} a b c c=0 \mathcal L^{-1}\left\{\frac1{s^b}\right\}=\frac{x^{b-1}}{\Gamma(b)}, \qquad for\quad b>0 \mathcal L^{-1}\left\{\frac1{(1+a s)^b}\right\}
=\frac1{a^b}\mathcal L^{-1}\left\{\frac1{(\frac1{a}+s)^b}\right\}
=\frac{e^{-\frac{x}{a}}}{a^b}\mathcal L^{-1}\left\{\frac1{s^b}\right\}
=\frac{e^{-\frac{x}{a}}}{a^b}\frac{x^{b-1}}{\Gamma(b)}. c\neq 0\, F(s) \frac{1}{s^b-c}?","['complex-analysis', 'special-functions', 'laplace-transform', 'contour-integration', 'signal-processing']"
66,"Why $\min_{a\in \Bbb C}\max \{|1-ax|,|1-ay|\}$ with given $x,y\in \Bbb C$ is attained at $a=\frac{2}{x+y}$",Why  with given  is attained at,"\min_{a\in \Bbb C}\max \{|1-ax|,|1-ay|\} x,y\in \Bbb C a=\frac{2}{x+y}","Consider complex numbers. Given $x,y \in \Bbb C$, how can we see the following $\min_{a\in \Bbb C}\max \{|1-ax|,|1-ay|\}$ is attained when $a=\frac{2}{x+y}$? The absolute value is the modulus of complex numbers. Many thanks! The previous post is not good (too many changes in the question), and there was no answer, so I open a new one.","Consider complex numbers. Given $x,y \in \Bbb C$, how can we see the following $\min_{a\in \Bbb C}\max \{|1-ax|,|1-ay|\}$ is attained when $a=\frac{2}{x+y}$? The absolute value is the modulus of complex numbers. Many thanks! The previous post is not good (too many changes in the question), and there was no answer, so I open a new one.",,"['calculus', 'complex-analysis', 'complex-numbers']"
67,How to prove the converse of Carathéodory's theorem,How to prove the converse of Carathéodory's theorem,,"The following problem is an assignment of my complex analysis course, which seems to be a converse of the Carathéodory's theorem that a biholomorphism between two Jordan regions can be extended to a homeomorphism between their closures. Suppose that $G$ and $\Omega$ are Jordan regions and $f$ is a continuous function on the closure $\overline G$ of $G$ such that $f$ is analytic on $G$ and $f(G)\subset\Omega$. If $f$ maps $\partial G$ onto $\partial\Omega$ homeomorphically, then $f(G)=\Omega$ and $f$ is univalent. To be honest it is a bit difficult to prove and I have worked on it for days. By Riemann mapping theorem and its extension to the boundary, we can take both $G$ and $\Omega$ in this problem as the unit disk $\Delta$ and $f(0)=0$. The image of $f$ is a region since $f$ here cannot be constant in $G$, and then we can consider a formally simpler but in fact equivalent problem as follows. Suppose that $f\colon\overline\Delta\to\overline\Delta$ is continuous. If $f\in\mathcal O(\Delta)$ and $f(0)=0$ and $f\colon\partial\Delta\to\partial\Delta$ is a homeomorphism, then $f\in\mathrm{Aut}\,(\Delta)$, namely $f(z)=e^{i\theta}z$ where $\theta\in\mathbb R$. For what happens next I completely have no idea. So may I ask how to prove such an $f$ is a bijection? Thanks in advance.. ps. I found it an exercise in J. B. Conway's Functions of One Complex Variable II , GTM159. It is the Excercise 10 of Section 14.5, while a preceding one (Excercise 8, for which a proof is here ) says that if $f$ is continuous over $\overline\Delta$ and $f\in\mathcal O(\Delta)$, then there is a sequence of polynomial $P_n(z)$ such that $P_n$ converges uniformly to $f$ on $\overline\Delta$. I think this may help since if we managed to prove the moduli of coefficients $a_n$ of $z$ in $P_n$ tend to $1$ then by Schwarz's lemma we can conclude that $f$ is biholomorphic. However, I don't know what the use of $f$ being homeomorphic on $S^1=\partial\Delta$ is and maybe it is the bottleneck of this proof. Now I would like to ask if I am in a right way, and what to do next...","The following problem is an assignment of my complex analysis course, which seems to be a converse of the Carathéodory's theorem that a biholomorphism between two Jordan regions can be extended to a homeomorphism between their closures. Suppose that $G$ and $\Omega$ are Jordan regions and $f$ is a continuous function on the closure $\overline G$ of $G$ such that $f$ is analytic on $G$ and $f(G)\subset\Omega$. If $f$ maps $\partial G$ onto $\partial\Omega$ homeomorphically, then $f(G)=\Omega$ and $f$ is univalent. To be honest it is a bit difficult to prove and I have worked on it for days. By Riemann mapping theorem and its extension to the boundary, we can take both $G$ and $\Omega$ in this problem as the unit disk $\Delta$ and $f(0)=0$. The image of $f$ is a region since $f$ here cannot be constant in $G$, and then we can consider a formally simpler but in fact equivalent problem as follows. Suppose that $f\colon\overline\Delta\to\overline\Delta$ is continuous. If $f\in\mathcal O(\Delta)$ and $f(0)=0$ and $f\colon\partial\Delta\to\partial\Delta$ is a homeomorphism, then $f\in\mathrm{Aut}\,(\Delta)$, namely $f(z)=e^{i\theta}z$ where $\theta\in\mathbb R$. For what happens next I completely have no idea. So may I ask how to prove such an $f$ is a bijection? Thanks in advance.. ps. I found it an exercise in J. B. Conway's Functions of One Complex Variable II , GTM159. It is the Excercise 10 of Section 14.5, while a preceding one (Excercise 8, for which a proof is here ) says that if $f$ is continuous over $\overline\Delta$ and $f\in\mathcal O(\Delta)$, then there is a sequence of polynomial $P_n(z)$ such that $P_n$ converges uniformly to $f$ on $\overline\Delta$. I think this may help since if we managed to prove the moduli of coefficients $a_n$ of $z$ in $P_n$ tend to $1$ then by Schwarz's lemma we can conclude that $f$ is biholomorphic. However, I don't know what the use of $f$ being homeomorphic on $S^1=\partial\Delta$ is and maybe it is the bottleneck of this proof. Now I would like to ask if I am in a right way, and what to do next...",,"['complex-analysis', 'inverse-function', 'holomorphic-functions', 'analytic-functions']"
68,To prove $\left|\frac{p_n(z)}{q_m(z)}\right|\leq \frac{M}{|z|^{m-n}}$ for some $M>0$,To prove  for some,\left|\frac{p_n(z)}{q_m(z)}\right|\leq \frac{M}{|z|^{m-n}} M>0,"To prove there exist $M>0$ and $a_0>0$ such that for $|z|>a_0$, $$\left|\frac{p_n(z)}{q_m(z)}\right|\leq \frac{M}{|z|^{m-n}}$$ where $p_n$ and $q_m$ are the polynomials of degree $n$ and $m$ respectively with $n<m$. I encountered this question in this post . According to the hint, it is enough to show that for large enough $R$ and for every $|z|>R$, we have $$\left|\frac{z-z_1}{z-z_2}\right|<M$$ In fact, $$\left|\frac{z-z_1}{z-z_2}\right|<\frac{|z-z_2|+|z_2-z_1|}{|z-z_2|}=1+\frac{|z_2-z_1|}{|z-z_2|}<M.$$","To prove there exist $M>0$ and $a_0>0$ such that for $|z|>a_0$, $$\left|\frac{p_n(z)}{q_m(z)}\right|\leq \frac{M}{|z|^{m-n}}$$ where $p_n$ and $q_m$ are the polynomials of degree $n$ and $m$ respectively with $n<m$. I encountered this question in this post . According to the hint, it is enough to show that for large enough $R$ and for every $|z|>R$, we have $$\left|\frac{z-z_1}{z-z_2}\right|<M$$ In fact, $$\left|\frac{z-z_1}{z-z_2}\right|<\frac{|z-z_2|+|z_2-z_1|}{|z-z_2|}=1+\frac{|z_2-z_1|}{|z-z_2|}<M.$$",,"['complex-analysis', 'inequality']"
69,What is the locus of the points satisfying $|z-\alpha|/|z+\alpha| = c$?,What is the locus of the points satisfying ?,|z-\alpha|/|z+\alpha| = c,"What is the locus of the points $z\in\mathbb{C}$ satisfying   $$\left|\frac{z-\alpha}{z+\alpha}\right| = c,$$ where $\alpha\in\mathbb{C}, c\in\mathbb{R}$? Plotting some examples by assigning values to $\alpha$ and $c$, I see that it is a conic section (it was a hyperbola in my example). But just writing $z = x+iy$ and $\alpha = a+ib$ the calculations get too long to carry and to organize in such a way that I could see what kind of curve it is in general. There is a ""less painful"" way to answer the question?","What is the locus of the points $z\in\mathbb{C}$ satisfying   $$\left|\frac{z-\alpha}{z+\alpha}\right| = c,$$ where $\alpha\in\mathbb{C}, c\in\mathbb{R}$? Plotting some examples by assigning values to $\alpha$ and $c$, I see that it is a conic section (it was a hyperbola in my example). But just writing $z = x+iy$ and $\alpha = a+ib$ the calculations get too long to carry and to organize in such a way that I could see what kind of curve it is in general. There is a ""less painful"" way to answer the question?",,"['complex-analysis', 'complex-numbers']"
70,There does not exist any holomorphic function $f$ in the open unit disc such that $f\left(\frac{1}{n}\right)=\frac{(-1)^n}{n^2}$,There does not exist any holomorphic function  in the open unit disc such that,f f\left(\frac{1}{n}\right)=\frac{(-1)^n}{n^2},"I want to show that There does not exist any holomorphic function $f$ in the open unit disc such that $$f\left(\frac{1}{n}\right)=\frac{(-1)^n}{n^2}, n=2,3,\ldots $$ My attempt: Suppose there exists such a holomorphic function. Now  $$f\left(\frac{1}{n}\right)=\begin{cases}\frac{1}{n^2}, & \text{if } n\ \text{is even.}\\ -\frac{1}{n^2}, & \text{if } n\ \text{is odd.} \end{cases}$$ Which says that $f(z)=z^2$ and $f(z)=-z^2$, which is not possible. Therefore, there does not exit any such holomorphic function. Is my argument fine? EDIT I used  the identity theorem to conclude that. Take $g(z)=z^2$. Since $$ f\left(\frac{1}{n}\right)=g\left(\frac{1}{n}\right)=\frac{1}{n^2} $$ As, $\frac{1}{n}\to 0\in \mathbb{D}(0,1)$ so using identity theorem I conclude that $f\equiv g$ on $\mathbb{D}$. Similar argument shows that $f(z)=-z^2$, and hence contradiction.","I want to show that There does not exist any holomorphic function $f$ in the open unit disc such that $$f\left(\frac{1}{n}\right)=\frac{(-1)^n}{n^2}, n=2,3,\ldots $$ My attempt: Suppose there exists such a holomorphic function. Now  $$f\left(\frac{1}{n}\right)=\begin{cases}\frac{1}{n^2}, & \text{if } n\ \text{is even.}\\ -\frac{1}{n^2}, & \text{if } n\ \text{is odd.} \end{cases}$$ Which says that $f(z)=z^2$ and $f(z)=-z^2$, which is not possible. Therefore, there does not exit any such holomorphic function. Is my argument fine? EDIT I used  the identity theorem to conclude that. Take $g(z)=z^2$. Since $$ f\left(\frac{1}{n}\right)=g\left(\frac{1}{n}\right)=\frac{1}{n^2} $$ As, $\frac{1}{n}\to 0\in \mathbb{D}(0,1)$ so using identity theorem I conclude that $f\equiv g$ on $\mathbb{D}$. Similar argument shows that $f(z)=-z^2$, and hence contradiction.",,"['complex-analysis', 'holomorphic-functions']"
71,Finding a closed rectifiable curve with prescribed winding numbers,Finding a closed rectifiable curve with prescribed winding numbers,,This is an exercise from the conway book. Here n(γ;a) is the winding number of γ around a. I have no idea how to find such a curve. To me this exercise seems to require a curve with arbitary winding numbers... Could anyone help me how to find such a curve?,This is an exercise from the conway book. Here n(γ;a) is the winding number of γ around a. I have no idea how to find such a curve. To me this exercise seems to require a curve with arbitary winding numbers... Could anyone help me how to find such a curve?,,"['complex-analysis', 'winding-number']"
72,"Prove that the map $z \mapsto \phi (z,w)$ is analytic for each fixed $w$ in a region $G$.",Prove that the map  is analytic for each fixed  in a region .,"z \mapsto \phi (z,w) w G","Suppose $f : G \longrightarrow \mathbb C$ is analytic and define $\phi : G \times G \longrightarrow \mathbb C$ by $\phi(z,w) = [f(z) - f(w)] (z-w)^{-1}$ if $z \neq w$ and $\phi(z,z) = f'(z)$. Prove that $\phi$ is continuous and for each fixed $w$, $z \mapsto \phi(z,w)$ is analytic. I have proved the continuity of $\phi$ in $G \times G$ which is pretty easy and analyticity of the map $z \mapsto \phi (z,w)$ in $G \setminus \{w\}$ for each fixed $w$ in $G$. At $w \in G$ I don't find any direct approach to prove that the map is analytic at $z=w$ for each fixed $w \in G$. I first show that $\int_{\partial T} f(z)\ dz =0$ for any closed triangle $T$ in $G$ (by using Goursat's theorem for the function analytic except at one point in a region) and then by Morera's theorem it has been concluded that the map is indeed analytic in $G$. However I don't like this process anyway. I think there is an elegant way to prove it directly though I have failed to find it inspite of my effort. Please help me by giving some suggestions. Thank you in advance.","Suppose $f : G \longrightarrow \mathbb C$ is analytic and define $\phi : G \times G \longrightarrow \mathbb C$ by $\phi(z,w) = [f(z) - f(w)] (z-w)^{-1}$ if $z \neq w$ and $\phi(z,z) = f'(z)$. Prove that $\phi$ is continuous and for each fixed $w$, $z \mapsto \phi(z,w)$ is analytic. I have proved the continuity of $\phi$ in $G \times G$ which is pretty easy and analyticity of the map $z \mapsto \phi (z,w)$ in $G \setminus \{w\}$ for each fixed $w$ in $G$. At $w \in G$ I don't find any direct approach to prove that the map is analytic at $z=w$ for each fixed $w \in G$. I first show that $\int_{\partial T} f(z)\ dz =0$ for any closed triangle $T$ in $G$ (by using Goursat's theorem for the function analytic except at one point in a region) and then by Morera's theorem it has been concluded that the map is indeed analytic in $G$. However I don't like this process anyway. I think there is an elegant way to prove it directly though I have failed to find it inspite of my effort. Please help me by giving some suggestions. Thank you in advance.",,"['complex-analysis', 'analyticity', 'analytic-functions']"
73,Tangent series representation,Tangent series representation,,"How to prove that for any complex number $z$ which is not equal to $\pi k + \frac{\pi}{2}$ ($k\in\mathbb Z$) : $$ \tan z = \sum_{n=0}^\infty \frac{8z}{(2n+1)^2\pi^2 - 4z^2} $$  Using complex analysis, I started with the contour intergal  $$ \oint_{C_N} \frac{\tan \frac{\pi s}{2}}{s^2-z^2}\,\mathrm ds = \sum_{n=-N}^N \frac{-4i}{(2n+1)^2 - z^2} + \frac{2\pi i \tan \frac{\pi z}{2}}{z}$$ where $C_N$ is the circle centered at 0 of radius $N+1/2$ ($N\in\mathbb N$). The complex number $z$ is chosen to be non zero & non odd integer. However, I don't know how proceed to show that the LHS goes to $0$ as $N\to \infty$ :( Thanks in advance for answers.","How to prove that for any complex number $z$ which is not equal to $\pi k + \frac{\pi}{2}$ ($k\in\mathbb Z$) : $$ \tan z = \sum_{n=0}^\infty \frac{8z}{(2n+1)^2\pi^2 - 4z^2} $$  Using complex analysis, I started with the contour intergal  $$ \oint_{C_N} \frac{\tan \frac{\pi s}{2}}{s^2-z^2}\,\mathrm ds = \sum_{n=-N}^N \frac{-4i}{(2n+1)^2 - z^2} + \frac{2\pi i \tan \frac{\pi z}{2}}{z}$$ where $C_N$ is the circle centered at 0 of radius $N+1/2$ ($N\in\mathbb N$). The complex number $z$ is chosen to be non zero & non odd integer. However, I don't know how proceed to show that the LHS goes to $0$ as $N\to \infty$ :( Thanks in advance for answers.",,"['sequences-and-series', 'complex-analysis', 'limits', 'contour-integration']"
74,What is Fourier transform of unilateral sinc function?,What is Fourier transform of unilateral sinc function?,,"$$\int_{0}^{+\infty} \frac{\sin(x)}{x} e^{itx} dx = ?$$ I know the Laplace transform of sinc is $\arctan(1/t)$. However, what if $t$ is a complex number?","$$\int_{0}^{+\infty} \frac{\sin(x)}{x} e^{itx} dx = ?$$ I know the Laplace transform of sinc is $\arctan(1/t)$. However, what if $t$ is a complex number?",,"['integration', 'complex-analysis', 'fourier-analysis', 'fourier-transform']"
75,Is a function analytic iff it has antiderivative?,Is a function analytic iff it has antiderivative?,,"Fundamental theorem of line integral states that for any function $f$ that has an antiderivative $F$, integrating $f$ from point $a$ to point $b$ yields $F(b) -  F(a)$, which would imply integration over a closed path yields $0$; However, Cauchy theorem requires the function to be analytic to guarantee $0$ on closed path integration. So does this mean any function that has primitive function $F$ will automatically be analytic and vice versa?","Fundamental theorem of line integral states that for any function $f$ that has an antiderivative $F$, integrating $f$ from point $a$ to point $b$ yields $F(b) -  F(a)$, which would imply integration over a closed path yields $0$; However, Cauchy theorem requires the function to be analytic to guarantee $0$ on closed path integration. So does this mean any function that has primitive function $F$ will automatically be analytic and vice versa?",,"['calculus', 'complex-analysis', 'analytic-functions']"
76,For which $z$ does $\sum_{n=1}^\infty \left[\frac {z(z+n)}{n}\right]^{n}$ converge?,For which  does  converge?,z \sum_{n=1}^\infty \left[\frac {z(z+n)}{n}\right]^{n},"Here is one of my olympiad problem, I have to find the radius of following series $$\sum_{n=1}^\infty \left[\frac {z(z+n)}{n}\right]^{n}$$ And here is my attempt $$U_{n}= \left[\frac {z(z+n)}{n}\right]^{n}$$ $$U_{n+1}=\left[\frac {z(z+n+1)}{n+1}\right]^{n+1}$$ but the problem is when I take $\lim_{n\to \infty} \left|\frac {U_{n+1}}{U_{n}}\right|$  But it will leave me ugy terms which i cant see any good way to see the center or radius of circle , could you give me some hint ?","Here is one of my olympiad problem, I have to find the radius of following series $$\sum_{n=1}^\infty \left[\frac {z(z+n)}{n}\right]^{n}$$ And here is my attempt $$U_{n}= \left[\frac {z(z+n)}{n}\right]^{n}$$ $$U_{n+1}=\left[\frac {z(z+n+1)}{n+1}\right]^{n+1}$$ but the problem is when I take $\lim_{n\to \infty} \left|\frac {U_{n+1}}{U_{n}}\right|$  But it will leave me ugy terms which i cant see any good way to see the center or radius of circle , could you give me some hint ?",,['complex-analysis']
77,Compute $\int\limits_{-\infty}^{\infty}\frac{1}{(1+x^2)^{n+1}}dx$ via residue calculus.,Compute  via residue calculus.,\int\limits_{-\infty}^{\infty}\frac{1}{(1+x^2)^{n+1}}dx,"Let $\Gamma_R$ be the semicircle of radius $R$ in the upper half plane. Then,  \begin{align} \int\limits_{-\infty}^{\infty}\frac{1}{(1+x^2)^{n+1}}dx  &= \lim_{R\to \infty}\int_{\Gamma_R}\frac{1}{(1+z^2)^{n+1}}dz \\ &= 2\pi i \operatorname{Res}\left(\frac{1}{(1+z^2)^{n+1}},i\right) \end{align} The pole of the function at $i$ is of order $n+1$, so the residue is computed by \begin{align} \operatorname{Res}\left(\frac{1}{(1+z^2)^{n+1}},i\right) &= \frac{1}{n!}\lim_{z\to i}\frac{d^n}{dz^n}\left(\frac{1}{(z+i)^{n+1}}\right) \\ &= \frac{1}{n!}\lim_{z\to i}(-1)^n\frac{(n+1)(n+2)\cdots(2n+1)}{(z+i)^{2n+1}} \\ &=\frac{(2n+1)!}{i2^{2n+1}(n!)^2} \end{align} Hence, $$\int_{-\infty}^{\infty}\frac{1}{(1+x^2)^{n+1}}dx = \pi\frac{(2n+1)!}{2^{2n}(n!)^2}$$ The answer provided is $\frac{1\cdot 3\cdot 5\cdots(2n-1)}{2\cdot 4\cdot 6\cdots (2n)}\pi$. How do I manipulate my answer to obtain this answer?","Let $\Gamma_R$ be the semicircle of radius $R$ in the upper half plane. Then,  \begin{align} \int\limits_{-\infty}^{\infty}\frac{1}{(1+x^2)^{n+1}}dx  &= \lim_{R\to \infty}\int_{\Gamma_R}\frac{1}{(1+z^2)^{n+1}}dz \\ &= 2\pi i \operatorname{Res}\left(\frac{1}{(1+z^2)^{n+1}},i\right) \end{align} The pole of the function at $i$ is of order $n+1$, so the residue is computed by \begin{align} \operatorname{Res}\left(\frac{1}{(1+z^2)^{n+1}},i\right) &= \frac{1}{n!}\lim_{z\to i}\frac{d^n}{dz^n}\left(\frac{1}{(z+i)^{n+1}}\right) \\ &= \frac{1}{n!}\lim_{z\to i}(-1)^n\frac{(n+1)(n+2)\cdots(2n+1)}{(z+i)^{2n+1}} \\ &=\frac{(2n+1)!}{i2^{2n+1}(n!)^2} \end{align} Hence, $$\int_{-\infty}^{\infty}\frac{1}{(1+x^2)^{n+1}}dx = \pi\frac{(2n+1)!}{2^{2n}(n!)^2}$$ The answer provided is $\frac{1\cdot 3\cdot 5\cdots(2n-1)}{2\cdot 4\cdot 6\cdots (2n)}\pi$. How do I manipulate my answer to obtain this answer?",,"['complex-analysis', 'residue-calculus', 'complex-integration']"
78,Complex analysis inequalities,Complex analysis inequalities,,"Show that if $z$ is real, then $$\left|\frac{e^{iz}}{z^2 + 1}\right| \leq \frac{1}{|z|^2 + 1}.$$ I don't see how this is true. The left hand side simplifies as: $\left|\frac{e^{iz}}{z^2 + 1}\right| = \frac{1}{|z^2 + 1|} \geq \frac{1}{|z|^2 + 1}$ by triangle inequality. Am I missing something? Edit: It seems that for any real $z$, both sides equal to each other.......??","Show that if $z$ is real, then $$\left|\frac{e^{iz}}{z^2 + 1}\right| \leq \frac{1}{|z|^2 + 1}.$$ I don't see how this is true. The left hand side simplifies as: $\left|\frac{e^{iz}}{z^2 + 1}\right| = \frac{1}{|z^2 + 1|} \geq \frac{1}{|z|^2 + 1}$ by triangle inequality. Am I missing something? Edit: It seems that for any real $z$, both sides equal to each other.......??",,['complex-analysis']
79,Show that a limit of the derivative of a complex function is $0$,Show that a limit of the derivative of a complex function is,0,"Question: For some $\alpha>0$, define $S=\{re^{i\theta}, r>0, 0<\theta<\alpha\}$. $f$ is bounded and holomorphic in $S$. Show that $\lim_{r\to\infty}f'(re^{i\theta})=0$ for each $0<\theta<\alpha$. Below $\Gamma$ is the counter-clockwise contour in S with only one loop around $z$ (here I choose $\Gamma$ to be a circle). My attempt is to represent $f'$ by Cauchy’s integral formula, i.e., I write $$ f'(z)=\frac{1}{2\pi i}\int_{\Gamma}\frac{f(w)}{(w-z)^2}dw.$$ Then $$ f'(re^{i\theta})=\frac{1}{2\pi i}\int_{\Gamma}\frac{f(w)}{(w-re^{i\theta})^2}dw.$$ Since $r\to\infty$, we can get $\frac{f(w)}{(w-re^{i\theta})^2}\to 0$, and then the integral goes to $0$ so that $f'(re^{i\theta})$ goes to $0$. But I begin to doubt myself since my attempt is too easy. So, is the method above correct? Is there any other ways to approch the problem.","Question: For some $\alpha>0$, define $S=\{re^{i\theta}, r>0, 0<\theta<\alpha\}$. $f$ is bounded and holomorphic in $S$. Show that $\lim_{r\to\infty}f'(re^{i\theta})=0$ for each $0<\theta<\alpha$. Below $\Gamma$ is the counter-clockwise contour in S with only one loop around $z$ (here I choose $\Gamma$ to be a circle). My attempt is to represent $f'$ by Cauchy’s integral formula, i.e., I write $$ f'(z)=\frac{1}{2\pi i}\int_{\Gamma}\frac{f(w)}{(w-z)^2}dw.$$ Then $$ f'(re^{i\theta})=\frac{1}{2\pi i}\int_{\Gamma}\frac{f(w)}{(w-re^{i\theta})^2}dw.$$ Since $r\to\infty$, we can get $\frac{f(w)}{(w-re^{i\theta})^2}\to 0$, and then the integral goes to $0$ so that $f'(re^{i\theta})$ goes to $0$. But I begin to doubt myself since my attempt is too easy. So, is the method above correct? Is there any other ways to approch the problem.",,"['complex-analysis', 'limits', 'cauchy-integral-formula']"
80,Determination of a Joukowski airfoil chord (demonstration),Determination of a Joukowski airfoil chord (demonstration),,"I'm currently studying Aerodynamics, and one thing that I noticed is that the maximum and minimum $x$ coordinate of the airfoils (which are necessary to compute the chord) on the transformed plane (let it be $z(x,y)$ ) correspond to the transformed intersection points of the circumference on the original plane  (let it be $\zeta(\xi,\eta)$ ) with the real axis. I don't find any proof of this statement, and so I tried to do it by myself. The problem is that it got too complicated to be solved analytically (too many different powers of trignometric functions). So I'm requesting someone to try demonstrate this too. I think that there's a simpler way to do it. There's my introduction to the problem: Consider the original circumference defined on the complex $\zeta$ plane: where $a$ is the circumference radius, and $b$ the intersection of the circumference with the real positive axis, $\xi$ . The parameter $\beta$ is the angle between the horizontal line and the line that links $\zeta_0$ to $b$ . The center of the circumference is: $$\zeta_0=-b\varepsilon+ia\sin(\beta)=-b\varepsilon+i(1+\varepsilon)b\tan(\beta)$$ So, this circumference is defined by: $$\zeta=-b\varepsilon+b\frac{1+\varepsilon}{\cos(\beta)}\left(e^{i\theta}+i\sin(\beta)\right),\hspace{15pt}\theta \in [0,2\pi]$$ Now I need to show that for the Joukowski transform $z=\zeta+\frac{b^2}{\zeta}$ the $x$ coordinate (real coordinate on the plane $z$ ) has a maximum on $\zeta=b$ (intersection of the circunference with the positive real axis) and a minimum on $\zeta=-b(1+2\varepsilon)$ , (intersection of the circunference with the negative real axis).","I'm currently studying Aerodynamics, and one thing that I noticed is that the maximum and minimum coordinate of the airfoils (which are necessary to compute the chord) on the transformed plane (let it be ) correspond to the transformed intersection points of the circumference on the original plane  (let it be ) with the real axis. I don't find any proof of this statement, and so I tried to do it by myself. The problem is that it got too complicated to be solved analytically (too many different powers of trignometric functions). So I'm requesting someone to try demonstrate this too. I think that there's a simpler way to do it. There's my introduction to the problem: Consider the original circumference defined on the complex plane: where is the circumference radius, and the intersection of the circumference with the real positive axis, . The parameter is the angle between the horizontal line and the line that links to . The center of the circumference is: So, this circumference is defined by: Now I need to show that for the Joukowski transform the coordinate (real coordinate on the plane ) has a maximum on (intersection of the circunference with the positive real axis) and a minimum on , (intersection of the circunference with the negative real axis).","x z(x,y) \zeta(\xi,\eta) \zeta a b \xi \beta \zeta_0 b \zeta_0=-b\varepsilon+ia\sin(\beta)=-b\varepsilon+i(1+\varepsilon)b\tan(\beta) \zeta=-b\varepsilon+b\frac{1+\varepsilon}{\cos(\beta)}\left(e^{i\theta}+i\sin(\beta)\right),\hspace{15pt}\theta \in [0,2\pi] z=\zeta+\frac{b^2}{\zeta} x z \zeta=b \zeta=-b(1+2\varepsilon)","['complex-analysis', 'optimization', 'physics', 'transformation']"
81,Range of the function $f(z)=\frac{z}{(1-z)^2}$ over the unit disk,Range of the function  over the unit disk,f(z)=\frac{z}{(1-z)^2},"Show that the range of the function $$f(z)=\frac{z}{(1-z)^2}$$ over the unit disk $\{z\in \mathbb{C};|z|<1\}$ is $\mathbb{C} \setminus \big(-\infty, -\frac{1}{4}\big]$. I was able to prove that the range of $f$ is a subset of $\mathbb{C} \setminus \big(-\infty, -\frac{1}{4}\big]$. I'm having issues with the other inclusion. I tried to solve $\frac{z}{(z-1)²} = w$ and impose that $|z|<1$ but it's not working, I can't get that $w$ should be in $\mathbb{C} \setminus \big(-\infty, -\frac{1}{4}\big]$. This question shows that if $|z|=1$ then $f(z) \in (-\infty, -\frac{1}{4}\big]$. I couldn't see if this  helps or not. Any ideas?","Show that the range of the function $$f(z)=\frac{z}{(1-z)^2}$$ over the unit disk $\{z\in \mathbb{C};|z|<1\}$ is $\mathbb{C} \setminus \big(-\infty, -\frac{1}{4}\big]$. I was able to prove that the range of $f$ is a subset of $\mathbb{C} \setminus \big(-\infty, -\frac{1}{4}\big]$. I'm having issues with the other inclusion. I tried to solve $\frac{z}{(z-1)²} = w$ and impose that $|z|<1$ but it's not working, I can't get that $w$ should be in $\mathbb{C} \setminus \big(-\infty, -\frac{1}{4}\big]$. This question shows that if $|z|=1$ then $f(z) \in (-\infty, -\frac{1}{4}\big]$. I couldn't see if this  helps or not. Any ideas?",,['complex-analysis']
82,Taylor series of $f(z)=\frac{\sin z}{z}$ at $z=1$,Taylor series of  at,f(z)=\frac{\sin z}{z} z=1,"My answer is: $$\sum_{n\geq 0} \frac{ (-1)^{n+1} z^{2n+1}(z-1)^{n}}{(2n+1)!}$$ I'm really confused, and I don't know if I'm correct, I mean, I have the term $z^{2n+1}$, is it okay?","My answer is: $$\sum_{n\geq 0} \frac{ (-1)^{n+1} z^{2n+1}(z-1)^{n}}{(2n+1)!}$$ I'm really confused, and I don't know if I'm correct, I mean, I have the term $z^{2n+1}$, is it okay?",,"['complex-analysis', 'taylor-expansion']"
83,"$\int_{\alpha}z^2 \log\left(\frac{z+1}{z-1}\right)\,dz$ where $\alpha$ is $|z-1|=1$",where  is,"\int_{\alpha}z^2 \log\left(\frac{z+1}{z-1}\right)\,dz \alpha |z-1|=1","Calculate $$\int_{\alpha}z^2 \log\left(\frac{z+1}{z-1}\right)\,dz$$ where $\alpha$ is $|z-1|=1$ and the initial point of integration $z_1=1+i$. The function isn't analytic at $1$ and $-1$. Is there a theorem to solve it? Transformation of the integral $z\to 1/z$ $$f(z)=\frac{\log\left(\frac{1+z}{1-z}\right)}{z^4}$$ How do I transform the circumference $1+e^{i\theta}$? Is there any other way?","Calculate $$\int_{\alpha}z^2 \log\left(\frac{z+1}{z-1}\right)\,dz$$ where $\alpha$ is $|z-1|=1$ and the initial point of integration $z_1=1+i$. The function isn't analytic at $1$ and $-1$. Is there a theorem to solve it? Transformation of the integral $z\to 1/z$ $$f(z)=\frac{\log\left(\frac{1+z}{1-z}\right)}{z^4}$$ How do I transform the circumference $1+e^{i\theta}$? Is there any other way?",,"['integration', 'complex-analysis']"
84,Proof the continuity of a function.,Proof the continuity of a function.,,"Let $X$ be a compact and perfect subset of $\mathbb C$. Consider a sequence of sets $F_n \subset X$ such that $F_n \neq \emptyset$ is a clopen set of $X$ and $F_n \cap F_m = \emptyset, \, \forall n \neq m.$ Hence, there is $z_n \in F_n$ and, since $X$ is compact, exists a subsequence $z_{n_k} \to z_0 \in X$. Since $F_{n_k}$ is open and $F_n \cap F_m = \emptyset, \, \forall n \neq m.$, we have that $z_0 \notin F_{n_k}, \, \forall k$. Define the following function: $$ f(z) = \left\{\begin{matrix} z_{n_k}, z \in F_{n_k} \\  z_0, z \in X\setminus \left ( \bigcup_{k \in \mathbb N} F_{n_k} \right ) \end{matrix}\right. $$ I'm trying to proof that $f$ is continuous in $X$. Take $z \in F_{n_k}$ for some $k$, as $F_{n_k}$ is an open set, exists an open neighborhood $V$ of $z$ such that $f_V = z_{n_k}$, hence $f$ is constant in $z$. Let's proof that $f$ is a continuous function in $z_0$. In fact, given $\epsilon > 0$, exists $k_0 \in \mathbb N$ s.t. $|z_{n_k} - z_0| < \epsilon, \, \forall k \geq k_0$. Since $V = B(z_0, \epsilon) \cup \left ( \bigcup_{k < k_0} X \setminus F_{n_k} \right )$ is an open set in $X$, exists $\delta > 0$ such that $B(z_0, \delta) \subset V$. Hence $$\forall z \in B(z_0, \delta), \, |f(z) - f(z_0)| \leq sup_{k \geq k_0} |z_{n_k} - z_0| < \epsilon$$ Then, we conclude that $f$ is continuous in $z_0$. However, I'm not getting to proof that $f$ is continuous in the other points of $\left ( \bigcup_{k \in \mathbb N} F_{n_k} \right )$. If I take $z$ in such set, we'd have $$ |f(w) - f(z)| \leq |f(w) - f(z_0)| + |f(z_0) - f(z)| = |f(w) - f(z_0)|, $$ since $f(z_0) = f(z) = z_0$. My problem is in define an neighborhood $V$ of $z$ that makes $|f(w) - z_0| < \epsilon$. Help?","Let $X$ be a compact and perfect subset of $\mathbb C$. Consider a sequence of sets $F_n \subset X$ such that $F_n \neq \emptyset$ is a clopen set of $X$ and $F_n \cap F_m = \emptyset, \, \forall n \neq m.$ Hence, there is $z_n \in F_n$ and, since $X$ is compact, exists a subsequence $z_{n_k} \to z_0 \in X$. Since $F_{n_k}$ is open and $F_n \cap F_m = \emptyset, \, \forall n \neq m.$, we have that $z_0 \notin F_{n_k}, \, \forall k$. Define the following function: $$ f(z) = \left\{\begin{matrix} z_{n_k}, z \in F_{n_k} \\  z_0, z \in X\setminus \left ( \bigcup_{k \in \mathbb N} F_{n_k} \right ) \end{matrix}\right. $$ I'm trying to proof that $f$ is continuous in $X$. Take $z \in F_{n_k}$ for some $k$, as $F_{n_k}$ is an open set, exists an open neighborhood $V$ of $z$ such that $f_V = z_{n_k}$, hence $f$ is constant in $z$. Let's proof that $f$ is a continuous function in $z_0$. In fact, given $\epsilon > 0$, exists $k_0 \in \mathbb N$ s.t. $|z_{n_k} - z_0| < \epsilon, \, \forall k \geq k_0$. Since $V = B(z_0, \epsilon) \cup \left ( \bigcup_{k < k_0} X \setminus F_{n_k} \right )$ is an open set in $X$, exists $\delta > 0$ such that $B(z_0, \delta) \subset V$. Hence $$\forall z \in B(z_0, \delta), \, |f(z) - f(z_0)| \leq sup_{k \geq k_0} |z_{n_k} - z_0| < \epsilon$$ Then, we conclude that $f$ is continuous in $z_0$. However, I'm not getting to proof that $f$ is continuous in the other points of $\left ( \bigcup_{k \in \mathbb N} F_{n_k} \right )$. If I take $z$ in such set, we'd have $$ |f(w) - f(z)| \leq |f(w) - f(z_0)| + |f(z_0) - f(z)| = |f(w) - f(z_0)|, $$ since $f(z_0) = f(z) = z_0$. My problem is in define an neighborhood $V$ of $z$ that makes $|f(w) - z_0| < \epsilon$. Help?",,"['complex-analysis', 'continuity']"
85,is partial derivative holomorphic?,is partial derivative holomorphic?,,"Let $f : \mathbb{C} \to \mathbb{C}$ be a holomorphic function. If $z = x + \Bbb i y$, are the partial derivatives $\dfrac {\partial ^{k+l} f} {\partial x^k \partial y ^l}$ holomorphic functions themselves? My idea: Proof by induction $k=1: \frac{\partial f}{\partial x}$ is real differentiable. But why is $\frac{\partial f}{\partial x}$ complex differentiable?","Let $f : \mathbb{C} \to \mathbb{C}$ be a holomorphic function. If $z = x + \Bbb i y$, are the partial derivatives $\dfrac {\partial ^{k+l} f} {\partial x^k \partial y ^l}$ holomorphic functions themselves? My idea: Proof by induction $k=1: \frac{\partial f}{\partial x}$ is real differentiable. But why is $\frac{\partial f}{\partial x}$ complex differentiable?",,"['complex-analysis', 'analysis', 'derivatives', 'partial-derivative', 'holomorphic-functions']"
86,Proof that a holomorphic square root of function exists,Proof that a holomorphic square root of function exists,,"Problem : Let $f(z)$ be a polynomial of even degree. We want to prove that it has a holomorphic square root in the annulus ouside all the zeros of the polynomial. I asked this question before and got this answer from Lord Shark The Unknown. To summarise the bit I want to understand better, I will write it out here. Firstly some definitions are given: $$f(z)=b_0 z^{2n}+b_{1}z^{2n-1}+\cdots+b_{2n} =b_0z^{2n}F(1/z)$$where$$F(z)=1+\frac{b_1}{b_0}z+\cdots+\frac{b_{2n}}{b_0}z^{2n} =\prod_{k=1}^{2n}(1-\alpha_k z).$$ Then the following concluding sentence is given: Now $F(z)$ will be nonzero for $|z|<1/a$ so each $|\alpha_k|<a$.   Each $(1-\alpha_kz)$ will have a holomorphic square root on the disc   $\{z:|z|<1/a\}$. I do not understand fully why such a conclusion can be made. Firstly, why must $F(1/z)$ be used? What is the problem with using $F(z)$ instead? Secondly, why can we say each $(1-\alpha_k z)$ has a holomorphi square root in that disc? Is there some theorem which allows us to make this conclusion?","Problem : Let $f(z)$ be a polynomial of even degree. We want to prove that it has a holomorphic square root in the annulus ouside all the zeros of the polynomial. I asked this question before and got this answer from Lord Shark The Unknown. To summarise the bit I want to understand better, I will write it out here. Firstly some definitions are given: $$f(z)=b_0 z^{2n}+b_{1}z^{2n-1}+\cdots+b_{2n} =b_0z^{2n}F(1/z)$$where$$F(z)=1+\frac{b_1}{b_0}z+\cdots+\frac{b_{2n}}{b_0}z^{2n} =\prod_{k=1}^{2n}(1-\alpha_k z).$$ Then the following concluding sentence is given: Now $F(z)$ will be nonzero for $|z|<1/a$ so each $|\alpha_k|<a$.   Each $(1-\alpha_kz)$ will have a holomorphic square root on the disc   $\{z:|z|<1/a\}$. I do not understand fully why such a conclusion can be made. Firstly, why must $F(1/z)$ be used? What is the problem with using $F(z)$ instead? Secondly, why can we say each $(1-\alpha_k z)$ has a holomorphi square root in that disc? Is there some theorem which allows us to make this conclusion?",,['complex-analysis']
87,"Given complex polynomial with roots within an annulus, there exists its ""square root"" which is analytic outside this annulus","Given complex polynomial with roots within an annulus, there exists its ""square root"" which is analytic outside this annulus",,"We are given a polynomial $f(z)$ of degree $2n$, which has all its roots within the annulus $|z|<a$. Now we must show that there is an analytic function $g(z)$ which is defined on $|z|>a$ which has the property that $g(z)^2=f(z)$. I have no idea what property I could use to show this is true (I don't even know why it is true). I think there could be some significance to the degree of the polynomial being even though - if it were odd, say degree $1$, then the square root can't possibly be a polynomial. I don't know how to formalise this, and more importantly I don't see the significance of the regions. Could someone please explain this to me?","We are given a polynomial $f(z)$ of degree $2n$, which has all its roots within the annulus $|z|<a$. Now we must show that there is an analytic function $g(z)$ which is defined on $|z|>a$ which has the property that $g(z)^2=f(z)$. I have no idea what property I could use to show this is true (I don't even know why it is true). I think there could be some significance to the degree of the polynomial being even though - if it were odd, say degree $1$, then the square root can't possibly be a polynomial. I don't know how to formalise this, and more importantly I don't see the significance of the regions. Could someone please explain this to me?",,['complex-analysis']
88,Differential of complex function,Differential of complex function,,"I understand how to find the derivative, but how should I find the differential of a complex function?","I understand how to find the derivative, but how should I find the differential of a complex function?",,['complex-analysis']
89,"If $e^f$ is holomorphic, then so is $f$?","If  is holomorphic, then so is ?",e^f f,"Let $f$ be defined on some open set. Is it true that if $e^f$ is holomorphic, then so is $f$? I believe this is true. But I do not know how to prove it. Please help.","Let $f$ be defined on some open set. Is it true that if $e^f$ is holomorphic, then so is $f$? I believe this is true. But I do not know how to prove it. Please help.",,['complex-analysis']
90,diffrentiation wrt to z bar operator,diffrentiation wrt to z bar operator,,I want to find $\partial_{\overline{z}}(\frac{z}{z-w})$ .I am getting two different answers. First I tried to do the product rule taking one of the function as $z$ and other as $z-w$ .The answer I got was $z\delta(z-w)$. Then I tried to rewrite the function as $ 1 + \frac{w}{z-w}$ and then did the diffrentiation .The answer I got was $w\delta(z-w)$. In both the cases I used the fact $\partial_{\overline{z}}(\frac{1}{z-w})=\delta(z-w)$. Am I doing something wrong?Please help me,I want to find $\partial_{\overline{z}}(\frac{z}{z-w})$ .I am getting two different answers. First I tried to do the product rule taking one of the function as $z$ and other as $z-w$ .The answer I got was $z\delta(z-w)$. Then I tried to rewrite the function as $ 1 + \frac{w}{z-w}$ and then did the diffrentiation .The answer I got was $w\delta(z-w)$. In both the cases I used the fact $\partial_{\overline{z}}(\frac{1}{z-w})=\delta(z-w)$. Am I doing something wrong?Please help me,,['complex-analysis']
91,Conformal Mapping #5,Conformal Mapping #5,,"I am studying for my final exam and am really struggling on this question #5.  I have attached both the question and the answer listed in the book.  I am really trying to get the ideas down so that I do well on the final. My attempt (Finding a conformal map of the part of the upper half-plane outside a circle of radius r onto the entire upper half plane): I want to use a known conformal map to map the domain to the first quadrant.  I then want to use w=z^2 to map to the first quadrant to entire half plane.  Finally I want to use a linear fractional transformation that maps the upper half-plane to itself.  The only thing is I don't know how to map the domain to the first quadrant and what the linear fractional transformation should be, but this is my general idea that I am thinking. Any help, suggestions, tips would be much welcomed, as I am struggling with these concepts.","I am studying for my final exam and am really struggling on this question #5.  I have attached both the question and the answer listed in the book.  I am really trying to get the ideas down so that I do well on the final. My attempt (Finding a conformal map of the part of the upper half-plane outside a circle of radius r onto the entire upper half plane): I want to use a known conformal map to map the domain to the first quadrant.  I then want to use w=z^2 to map to the first quadrant to entire half plane.  Finally I want to use a linear fractional transformation that maps the upper half-plane to itself.  The only thing is I don't know how to map the domain to the first quadrant and what the linear fractional transformation should be, but this is my general idea that I am thinking. Any help, suggestions, tips would be much welcomed, as I am struggling with these concepts.",,"['calculus', 'complex-analysis', 'analysis', 'complex-numbers', 'conformal-geometry']"
92,Let $f(z)$ be holomorphic in the punctured disk $0 < |z − z_0| < R$. What are the possible types of singularity that $f$ may have at $z_0$?,Let  be holomorphic in the punctured disk . What are the possible types of singularity that  may have at ?,f(z) 0 < |z − z_0| < R f z_0,"Let $f(z)$ be holomorphic in the punctured disk $0 < |z − z_0| < R$. What are the possible types of singularity that f may have at $z_0$? I am not sure how many there are but I think that one would be an isolated singularity is there any more for this function? Also, is there a method for working out what singularities apply to which function?","Let $f(z)$ be holomorphic in the punctured disk $0 < |z − z_0| < R$. What are the possible types of singularity that f may have at $z_0$? I am not sure how many there are but I think that one would be an isolated singularity is there any more for this function? Also, is there a method for working out what singularities apply to which function?",,"['complex-analysis', 'holomorphic-functions']"
93,Show that $f$ is constant. Liouville Thm [duplicate],Show that  is constant. Liouville Thm [duplicate],f,This question already has answers here : Liouvilles theorem question - show $f$ is constant (2 answers) Closed 7 years ago . Let $f$ : $\mathbb C \to \mathbb C$ be analytic such that $|Re(f(z)) Im(f(z))|$ $\le$ $1$ for every $z \in \mathbb C$. Show that $f$ is constant. I know the set is bounded hence I should be able to apply Liouville Thm. Other than this information I do not know how to approach this question. Any help will be appreciated.,This question already has answers here : Liouvilles theorem question - show $f$ is constant (2 answers) Closed 7 years ago . Let $f$ : $\mathbb C \to \mathbb C$ be analytic such that $|Re(f(z)) Im(f(z))|$ $\le$ $1$ for every $z \in \mathbb C$. Show that $f$ is constant. I know the set is bounded hence I should be able to apply Liouville Thm. Other than this information I do not know how to approach this question. Any help will be appreciated.,,"['complex-analysis', 'complex-numbers']"
94,Sum of series using complex numbers,Sum of series using complex numbers,,In this I just know $e^{im}=\cos m +i\sin m$ but in this none of the terms are cancelling . The answer of this question is 1008,In this I just know $e^{im}=\cos m +i\sin m$ but in this none of the terms are cancelling . The answer of this question is 1008,,"['complex-analysis', 'complex-numbers']"
95,Simple Connectedness of bounded region in $\mathbb{C}$ split by line,Simple Connectedness of bounded region in  split by line,\mathbb{C},"Note: This is one of the problems from Complex Analysis by Stein and Shakarchi. Let $\Omega \subset \mathbb{C}$ be a bounded region (open, connected), and let $L \subset \mathbb{C}$ be a line that intersects $\Omega$, you may assume that $\Omega \cap L = I$ is an interval. The line $L$ splits the complex plane in two halves, and since $\Omega$ is open, $\Omega$ will have a nonempty intersection with each half. Let's call these intersections $\Omega_l$ and $\Omega_r$. In particular, $\Omega$ will be the disjoint union $\Omega_l \cup I \cup \Omega_r$. To prove: If $\Omega_l$ and $\Omega_r$ are simply connected, then so is $\Omega$. Intuitively, this seems rather obvious: if $\Omega_l$ and $\Omega_r$ ""have no holes"", then $\Omega$ can't have any holes either. However, proving this rigorously has me stumped. There seem to be a few possible approaches here: Use the following theorem/lemma: A bounded region is simply connected if and only if its complement is connected. This gives us that $\Omega^c \cup I \cup \Omega_l$ and $\Omega^c \cup I \cup \Omega_r$ are both connected, and that it suffices to prove that $\Omega^c$ is connected. I don't see how any of these help, though. Use the definition of simple connectedness: An open set is simply connected if any two curves with the same initial and final points inside the set are homotopic. We could take two curves inside $\Omega$ and try to deform one into the other. Inside $\Omega_l$ and $\Omega_r$ we can deform curves easily, but when they intersect $I$ I can't figure out how to do it. Use the winding number: A bounded region $\Omega$ is simply connected if and only if $W_\gamma(z) = 0$ for any closed curve $\gamma$ in $\Omega$ and any point $z \notin \Omega$. Ideally, we would take any curve $\gamma$ in $\Omega$ and somehow split this into two curves $\gamma_l, \gamma_r$ in $\Omega_l$ and $\Omega_r$ respectively, then write the winding number $W_\gamma(z)$ in terms of the winding numbers of these new curves. But, once again, I can't figure out how to handle this when $\gamma$ and $I$ intersect. Any hints, suggestions or solutions are appreciated.","Note: This is one of the problems from Complex Analysis by Stein and Shakarchi. Let $\Omega \subset \mathbb{C}$ be a bounded region (open, connected), and let $L \subset \mathbb{C}$ be a line that intersects $\Omega$, you may assume that $\Omega \cap L = I$ is an interval. The line $L$ splits the complex plane in two halves, and since $\Omega$ is open, $\Omega$ will have a nonempty intersection with each half. Let's call these intersections $\Omega_l$ and $\Omega_r$. In particular, $\Omega$ will be the disjoint union $\Omega_l \cup I \cup \Omega_r$. To prove: If $\Omega_l$ and $\Omega_r$ are simply connected, then so is $\Omega$. Intuitively, this seems rather obvious: if $\Omega_l$ and $\Omega_r$ ""have no holes"", then $\Omega$ can't have any holes either. However, proving this rigorously has me stumped. There seem to be a few possible approaches here: Use the following theorem/lemma: A bounded region is simply connected if and only if its complement is connected. This gives us that $\Omega^c \cup I \cup \Omega_l$ and $\Omega^c \cup I \cup \Omega_r$ are both connected, and that it suffices to prove that $\Omega^c$ is connected. I don't see how any of these help, though. Use the definition of simple connectedness: An open set is simply connected if any two curves with the same initial and final points inside the set are homotopic. We could take two curves inside $\Omega$ and try to deform one into the other. Inside $\Omega_l$ and $\Omega_r$ we can deform curves easily, but when they intersect $I$ I can't figure out how to do it. Use the winding number: A bounded region $\Omega$ is simply connected if and only if $W_\gamma(z) = 0$ for any closed curve $\gamma$ in $\Omega$ and any point $z \notin \Omega$. Ideally, we would take any curve $\gamma$ in $\Omega$ and somehow split this into two curves $\gamma_l, \gamma_r$ in $\Omega_l$ and $\Omega_r$ respectively, then write the winding number $W_\gamma(z)$ in terms of the winding numbers of these new curves. But, once again, I can't figure out how to handle this when $\gamma$ and $I$ intersect. Any hints, suggestions or solutions are appreciated.",,"['general-topology', 'complex-analysis', 'homotopy-theory', 'connectedness', 'winding-number']"
96,Cauchy's Theorem and Contour Integrals,Cauchy's Theorem and Contour Integrals,,"Using Cauchy's Theorem and the function $f(z)=ze^{-ikz}e^{-z^2/{2a^2}}$ to evaluate $$\int_{0}^{\infty} x\sin(x)e^{-x^2/{2a^2}} $$ Thoughts: I am having trouble understanding the relationship between the complex function given, and the integrand. I have tried writing $sin(x)$ as $(e^{iz}-e^{-iz})/2$, but the function I get doesn't match. Also why is there a $k$ in the function they gave me?","Using Cauchy's Theorem and the function $f(z)=ze^{-ikz}e^{-z^2/{2a^2}}$ to evaluate $$\int_{0}^{\infty} x\sin(x)e^{-x^2/{2a^2}} $$ Thoughts: I am having trouble understanding the relationship between the complex function given, and the integrand. I have tried writing $sin(x)$ as $(e^{iz}-e^{-iz})/2$, but the function I get doesn't match. Also why is there a $k$ in the function they gave me?",,"['complex-analysis', 'complex-integration']"
97,Complex integral (Miscellaneous Problems),Complex integral (Miscellaneous Problems),,"Show that for $-1<p<1$,  $$ \int_0^{\infty} \frac{\cos(px)}{\cosh x} \,dx = \frac{\pi}{2\cosh(p\pi/2)}.$$ I make L.S to $$\frac{e^{ipx}+e^{-ipx}}{e^{x}+e^{-x}}$$ and I cannot approach next step.","Show that for $-1<p<1$,  $$ \int_0^{\infty} \frac{\cos(px)}{\cosh x} \,dx = \frac{\pi}{2\cosh(p\pi/2)}.$$ I make L.S to $$\frac{e^{ipx}+e^{-ipx}}{e^{x}+e^{-x}}$$ and I cannot approach next step.",,"['integration', 'complex-analysis']"
98,Integration -- can't figure out the substitution,Integration -- can't figure out the substitution,,"I need to evaluate the integral $$ \int_0^1 \frac{6\pi}{\lvert{2 - 3e^{2\pi i t}}\rvert^2} \,\mathrm{d}t.$$ The problem I am having is that I can't find a nice way to re-write the denominator to invoke a substitution. Perhaps I can view this as a contour integral in the complex plane? Any ideas appreciated.","I need to evaluate the integral $$ \int_0^1 \frac{6\pi}{\lvert{2 - 3e^{2\pi i t}}\rvert^2} \,\mathrm{d}t.$$ The problem I am having is that I can't find a nice way to re-write the denominator to invoke a substitution. Perhaps I can view this as a contour integral in the complex plane? Any ideas appreciated.",,"['integration', 'complex-analysis']"
99,Why aren't there complex solutions to $\sin(x) = 0$?,Why aren't there complex solutions to ?,\sin(x) = 0,Suppose that the addition formula works for $\sin(a+bi) = 0$ where $a$ and $b$ are real. Then $\tan(a) = \tanh(b)$ for any real $b$ and $a$ are valid solutions to the given equation. There are many solutions to $a$ and $b$. But why do none of them yield $\sin(a+bi) = 0$?,Suppose that the addition formula works for $\sin(a+bi) = 0$ where $a$ and $b$ are real. Then $\tan(a) = \tanh(b)$ for any real $b$ and $a$ are valid solutions to the given equation. There are many solutions to $a$ and $b$. But why do none of them yield $\sin(a+bi) = 0$?,,"['complex-analysis', 'trigonometry', 'proof-verification', 'complex-numbers']"
