,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Is there a finitely generated, algebraic $K$-algebra $A$ that is not a field?","Is there a finitely generated, algebraic -algebra  that is not a field?",K A,"There is a well-known theorem that states that if $A$ is a finitely generated $K$-algebra, an integral domain and algebraic over $K$, then $A$ is a field. Is the integral domain condition necesary? I mean, is there an example of an algebraic algebra over $K$, such that is not a field? It may be kind of simple, but I'm a bit confused. Thank you.","There is a well-known theorem that states that if $A$ is a finitely generated $K$-algebra, an integral domain and algebraic over $K$, then $A$ is a field. Is the integral domain condition necesary? I mean, is there an example of an algebraic algebra over $K$, such that is not a field? It may be kind of simple, but I'm a bit confused. Thank you.",,"['abstract-algebra', 'commutative-algebra']"
1,Alternative proof about the order of the alternating group?,Alternative proof about the order of the alternating group?,,"It is known that the order of the alternating group $A_n$ of order $n$ is $\frac{n!}{2}$. In Herstein's Abstract Algebra , it is proved by the First Homomorphism Theorem. I tried to find an alternative proof which needs not using the group homomorphism. I think the following rules may be helpful: The product of two even permutations is even. The product of two odd permutations is even. The product of an even permutation by an odd one (or of an odd one by an even one) is odd. Intuitively, since the product of an odd(resp. even) permutation and a 1-cycle is even(resp. odd), a half of all the permutations should be even. Then we get $\frac{n!}{2}$. What's more, the theorem mentioned in this question may be related. I don't know if one can turn the argument above into a proof. So here is my question: Does anybody know other proofs about the order of $A_n$?","It is known that the order of the alternating group $A_n$ of order $n$ is $\frac{n!}{2}$. In Herstein's Abstract Algebra , it is proved by the First Homomorphism Theorem. I tried to find an alternative proof which needs not using the group homomorphism. I think the following rules may be helpful: The product of two even permutations is even. The product of two odd permutations is even. The product of an even permutation by an odd one (or of an odd one by an even one) is odd. Intuitively, since the product of an odd(resp. even) permutation and a 1-cycle is even(resp. odd), a half of all the permutations should be even. Then we get $\frac{n!}{2}$. What's more, the theorem mentioned in this question may be related. I don't know if one can turn the argument above into a proof. So here is my question: Does anybody know other proofs about the order of $A_n$?",,['abstract-algebra']
2,"Why is ""working in $\mathbb {Z}_m$"" essentially the same as ""working with congruences modulo m""?","Why is ""working in "" essentially the same as ""working with congruences modulo m""?",\mathbb {Z}_m,"Due to my ignorance, I only superficially know the definition of congruence in number theory: For a given positive integer $n$, two integers $a$ and $b$ are called congruent modulo $n$, written $a\equiv b\pmod{n}$ if $a−b$ is divisible by $n$ (or equivalently if $a$ and $b$ have the same remainder when divided by $n$). Motivated by the comments and the answers to the question: solving $x^{12}-x^{10}=2$ in the field $\mathbb {Z}_{11}$ , I'd like the post the question here: Why is ""working in $\mathbb {Z}_m$"" essentially the same as ""working with congruences modulo $m$""? Edit: According to Qiaochu's comment, I added the definition of ${\mathbb Z}_n$ that I learned here. Let $n$ be an integer greater than or equal to $2$, and consider the set ${\mathbb Z}_n=\{0,1,2,\cdots,n-1\}$. For any two integers $a$ and $b$ in ${\mathbb Z}_n$, define $a\oplus b$ to be the remainder when the usual sum, $a+b$, is divided by $n$. Then for every $a$ and $b$ in ${\mathbb Z}_n$, $a\oplus b$ is unique interger in ${\mathbb Z}_n$ that's congruent to $a+b\pmod{n}$. With this operation, $({\mathbb Z}_n,\oplus)$ is a finite Abelian group of order $n$, called the additive group of integers modulo $n$.","Due to my ignorance, I only superficially know the definition of congruence in number theory: For a given positive integer $n$, two integers $a$ and $b$ are called congruent modulo $n$, written $a\equiv b\pmod{n}$ if $a−b$ is divisible by $n$ (or equivalently if $a$ and $b$ have the same remainder when divided by $n$). Motivated by the comments and the answers to the question: solving $x^{12}-x^{10}=2$ in the field $\mathbb {Z}_{11}$ , I'd like the post the question here: Why is ""working in $\mathbb {Z}_m$"" essentially the same as ""working with congruences modulo $m$""? Edit: According to Qiaochu's comment, I added the definition of ${\mathbb Z}_n$ that I learned here. Let $n$ be an integer greater than or equal to $2$, and consider the set ${\mathbb Z}_n=\{0,1,2,\cdots,n-1\}$. For any two integers $a$ and $b$ in ${\mathbb Z}_n$, define $a\oplus b$ to be the remainder when the usual sum, $a+b$, is divided by $n$. Then for every $a$ and $b$ in ${\mathbb Z}_n$, $a\oplus b$ is unique interger in ${\mathbb Z}_n$ that's congruent to $a+b\pmod{n}$. With this operation, $({\mathbb Z}_n,\oplus)$ is a finite Abelian group of order $n$, called the additive group of integers modulo $n$.",,['abstract-algebra']
3,Are there any other constructions of a finite field with characteristic $p$ except $\Bbb Z_p$?,Are there any other constructions of a finite field with characteristic  except ?,p \Bbb Z_p,"I mean, $\Bbb Z_p$ is an instance of $\Bbb F_p$, I wonder if there are other ways to construct a field with characteristic $p$? Thanks a lot!","I mean, $\Bbb Z_p$ is an instance of $\Bbb F_p$, I wonder if there are other ways to construct a field with characteristic $p$? Thanks a lot!",,"['abstract-algebra', 'finite-fields']"
4,Find all prime $p$ such that $x^2=-1$ has a solution in $\mathbb{Z}/p\mathbb{Z}$,Find all prime  such that  has a solution in,p x^2=-1 \mathbb{Z}/p\mathbb{Z},"I have found by a numerical experiment that first such primes are:  $2,5,13,17,29,37,41$. But I cannot work out the general formula for it. Please share any your ideas on the subject.","I have found by a numerical experiment that first such primes are:  $2,5,13,17,29,37,41$. But I cannot work out the general formula for it. Please share any your ideas on the subject.",,"['abstract-algebra', 'number-theory']"
5,Prove that $\mathbb Z^n$ is not isomorphic to $\mathbb Z^m$ for $m\neq n$ [duplicate],Prove that  is not isomorphic to  for  [duplicate],\mathbb Z^n \mathbb Z^m m\neq n,This question already has answers here : Prove that the group isomorphism $\mathbb{Z}^m \cong \mathbb{Z}^n$ implies that $m = n$ (6 answers) Closed 7 years ago . Prove that $\mathbb Z^n$ is not isomorphic to $\mathbb Z^m$ for $m\neq n$ . My try : Let $\mathbb Z^n\cong \mathbb Z^m $ . To show that $m=n$ . Case 1: Let $m>n$ . Now that $\mathbb Z^m$ has $m$ generators whereas $\mathbb Z^n$ has $n$ generators and an isomorphism takes a generator to generator ; that is the contradiction. Please correct me if I am wrong. The case $m<n$ also follows similarly.,This question already has answers here : Prove that the group isomorphism $\mathbb{Z}^m \cong \mathbb{Z}^n$ implies that $m = n$ (6 answers) Closed 7 years ago . Prove that is not isomorphic to for . My try : Let . To show that . Case 1: Let . Now that has generators whereas has generators and an isomorphism takes a generator to generator ; that is the contradiction. Please correct me if I am wrong. The case also follows similarly.,\mathbb Z^n \mathbb Z^m m\neq n \mathbb Z^n\cong \mathbb Z^m  m=n m>n \mathbb Z^m m \mathbb Z^n n m<n,"['abstract-algebra', 'abelian-groups', 'group-isomorphism', 'free-groups']"
6,Example Of a Proper noncyclic Subgroup of rationals,Example Of a Proper noncyclic Subgroup of rationals,,"We know the set of rational numbers forms a group under addition. My question is :does there exist a proper subgroup of rationals which is not cyclic? If yes, how can we construct it?","We know the set of rational numbers forms a group under addition. My question is :does there exist a proper subgroup of rationals which is not cyclic? If yes, how can we construct it?",,"['abstract-algebra', 'group-theory', 'examples-counterexamples', 'rational-numbers']"
7,Infinite cyclic group generated by every single element?,Infinite cyclic group generated by every single element?,,"This probably is a stupid question, but is there an infinite cyclic group generated by every single one of its nonidentity elements?","This probably is a stupid question, but is there an infinite cyclic group generated by every single one of its nonidentity elements?",,"['abstract-algebra', 'group-theory']"
8,"Show the power series $100+t\,$ is reducible in $\mathbb{Z}[[t]]$",Show the power series  is reducible in,"100+t\, \mathbb{Z}[[t]]","$\mathbb{Z}[[t]]$ is the ring of formal power series with integer coefficients, and the problem asks to show that $100+t$ is reducible. This means I need to find two power series, $\sum_{i=0}^\infty a_i t^i$ and $\sum_{j=0}^\infty b_j t^j$ with $a_i,b_j\in\mathbb{Z}$, that when multiplied give $100+t$. Since the integers are an integral domain, I know that neither of these power series may be finite, but I'm having a really hard time figuring out how to come up with two series that will telescope properly. Any suggestions?","$\mathbb{Z}[[t]]$ is the ring of formal power series with integer coefficients, and the problem asks to show that $100+t$ is reducible. This means I need to find two power series, $\sum_{i=0}^\infty a_i t^i$ and $\sum_{j=0}^\infty b_j t^j$ with $a_i,b_j\in\mathbb{Z}$, that when multiplied give $100+t$. Since the integers are an integral domain, I know that neither of these power series may be finite, but I'm having a really hard time figuring out how to come up with two series that will telescope properly. Any suggestions?",,"['abstract-algebra', 'ring-theory', 'commutative-algebra', 'power-series', 'divisibility']"
9,"Galois Theory by Rotman, Exercise 60, a field of four elements by using Kronecker's theorem and adjoining a root of $x^4-x$ to $\Bbb Z_2$","Galois Theory by Rotman, Exercise 60, a field of four elements by using Kronecker's theorem and adjoining a root of  to",x^4-x \Bbb Z_2,"I've been working through Rotman's Galois Theory and am stumped by exercise 60: Use Kronecker's theorem to construct a field with four elements by adjoining a suitable root of $x^4 - x$ to $\mathbb{Z}_2$ . I can split $x^4 - x$ in $\mathbb{C}[x]$ (which is not a field but which is contained in the field $\operatorname{Frac}(\mathbb{C[x]})$ ). The roots are $F = \{ 0, 1, \frac{-1 - i \sqrt{3}} {2}, \frac{-1 + i \sqrt{3}} {2} \}$ . So what does it mean to adjoin a suitable root to $\mathbb{Z}_2$ ? I have been unable to construct a four element field using either complex root. So I went and tried to use the proof of Thm 33 (Galois) which gives a construction. In this case, F is as above and has the required four elements with $p = 2$ , $n = 2$ , and $q = 4$ , and indeed $F \setminus \{0\}$ behaves as desired for multiplication. The problem is addition. How is addition defined? Normal addition is not closed, nor do I see how to define it to make it work. Further, given Kronecker's and Galois's theorems, I would assume that addition must be defined as it would be in the containing field.","I've been working through Rotman's Galois Theory and am stumped by exercise 60: Use Kronecker's theorem to construct a field with four elements by adjoining a suitable root of to . I can split in (which is not a field but which is contained in the field ). The roots are . So what does it mean to adjoin a suitable root to ? I have been unable to construct a four element field using either complex root. So I went and tried to use the proof of Thm 33 (Galois) which gives a construction. In this case, F is as above and has the required four elements with , , and , and indeed behaves as desired for multiplication. The problem is addition. How is addition defined? Normal addition is not closed, nor do I see how to define it to make it work. Further, given Kronecker's and Galois's theorems, I would assume that addition must be defined as it would be in the containing field.","x^4 - x \mathbb{Z}_2 x^4 - x \mathbb{C}[x] \operatorname{Frac}(\mathbb{C[x]}) F = \{ 0, 1, \frac{-1 - i \sqrt{3}} {2}, \frac{-1 + i \sqrt{3}} {2} \} \mathbb{Z}_2 p = 2 n = 2 q = 4 F \setminus \{0\}","['abstract-algebra', 'galois-theory', 'finite-fields', 'extension-field']"
10,Why is a unique Sylow p-subgroup normal?,Why is a unique Sylow p-subgroup normal?,,"I need to prove that a group $G$ with $|G| = pq$, where $p$, $q$ are primes, cannot be simple. I have already reduced this problem to showing that a unique Sylow $p$-subgroup is normal. The answers i have found so far are something along the line of ""the Sylow $p$-subgroup is normal because all $p$-Sylow subgroups are conjugate to each other"" which means diddly-squat to me. I need help understanding that last part.","I need to prove that a group $G$ with $|G| = pq$, where $p$, $q$ are primes, cannot be simple. I have already reduced this problem to showing that a unique Sylow $p$-subgroup is normal. The answers i have found so far are something along the line of ""the Sylow $p$-subgroup is normal because all $p$-Sylow subgroups are conjugate to each other"" which means diddly-squat to me. I need help understanding that last part.",,"['abstract-algebra', 'normal-subgroups', 'sylow-theory']"
11,Are kernels unique to homomorphisms?,Are kernels unique to homomorphisms?,,"I would like to ask if two different homomorphisms can share the same kernel. For instance for the kernel $n \mathbb{Z} $, is it possible to come up with homomorphisms other than the function mapping integers to residue classes modulo $n$? Thanks.","I would like to ask if two different homomorphisms can share the same kernel. For instance for the kernel $n \mathbb{Z} $, is it possible to come up with homomorphisms other than the function mapping integers to residue classes modulo $n$? Thanks.",,"['abstract-algebra', 'group-theory', 'group-homomorphism']"
12,Finite groups as subgroups of dihedral groups,Finite groups as subgroups of dihedral groups,,It is well-known that any finite group can be realised as a subgroup of a permutation group. But is it true that any finite group can be realised as a subgroup of a dihedral group?,It is well-known that any finite group can be realised as a subgroup of a permutation group. But is it true that any finite group can be realised as a subgroup of a dihedral group?,,"['abstract-algebra', 'group-theory', 'finite-groups']"
13,"Quotient rings of Gaussian integers $\,\Bbb Z[i]/(a+bi)\cong\Bbb Z/(a^2+b^2)\ $ if $\ (a,b)=1$ [duplicate]",Quotient rings of Gaussian integers  if  [duplicate],"\,\Bbb Z[i]/(a+bi)\cong\Bbb Z/(a^2+b^2)\  \ (a,b)=1","This question already has answers here : Quotient ring of Gaussian integers (7 answers) Closed 5 years ago . I used this isomorphism today but now I'm having trouble justifying it. The norm function isn't additive so I can't come up with a ring isomorphism to prove the following: For any $\,a+bi\in\Bbb Z[i],\,\gcd(a,b)=1$, we have a ring isomorphism   $$\Bbb Z[i]/\langle a+bi\rangle\,\cong\Bbb Z/(a^2+b^2)\Bbb Z=:\Bbb Z_{a^2+b^2}.$$ Could someone show me an isomorphism between these rings to prove this?","This question already has answers here : Quotient ring of Gaussian integers (7 answers) Closed 5 years ago . I used this isomorphism today but now I'm having trouble justifying it. The norm function isn't additive so I can't come up with a ring isomorphism to prove the following: For any $\,a+bi\in\Bbb Z[i],\,\gcd(a,b)=1$, we have a ring isomorphism   $$\Bbb Z[i]/\langle a+bi\rangle\,\cong\Bbb Z/(a^2+b^2)\Bbb Z=:\Bbb Z_{a^2+b^2}.$$ Could someone show me an isomorphism between these rings to prove this?",,"['abstract-algebra', 'number-theory', 'elementary-number-theory', 'ring-theory']"
14,How can the real numbers be a field if $0$ has no inverse?,How can the real numbers be a field if  has no inverse?,0,"I'm reading a linear algebra book (Linear Algebra by Georgi E. Shilov, Dover Books) and the very start of the book discusses fields. 9 field axioms discussing addition and multiplication are given then the author goes on to discuss common sets of numbers. The integers are identified as being a set of numbers which is not a field because there does not exist a reciprocal element for every integer (axiom # 8 in this book states the existence of a reciprocal element $B$ for a number $A$ such that $AB=1$). The author goes on to call the real numbers a field, and asserts that an axiomatic treatment can be had by supplementing the field axioms with the order axioms and the least upper bound axiom. My understanding consists of the following statements I believe are facts: zero is a member of the reals there exists no reciprocal element of zero that is a real number Given those two facts it seems to me that the reals fail the same test for being a field that the author states the integers fail. Yet the author is calling the real numbers a field. To my mind this is a contradiction. Is there a resolution to this apparent contradiction? I'm a total beginner at this sort of math (I'm an engineer by training, not a mathematician!) and would appreciate any assistance!","I'm reading a linear algebra book (Linear Algebra by Georgi E. Shilov, Dover Books) and the very start of the book discusses fields. 9 field axioms discussing addition and multiplication are given then the author goes on to discuss common sets of numbers. The integers are identified as being a set of numbers which is not a field because there does not exist a reciprocal element for every integer (axiom # 8 in this book states the existence of a reciprocal element $B$ for a number $A$ such that $AB=1$). The author goes on to call the real numbers a field, and asserts that an axiomatic treatment can be had by supplementing the field axioms with the order axioms and the least upper bound axiom. My understanding consists of the following statements I believe are facts: zero is a member of the reals there exists no reciprocal element of zero that is a real number Given those two facts it seems to me that the reals fail the same test for being a field that the author states the integers fail. Yet the author is calling the real numbers a field. To my mind this is a contradiction. Is there a resolution to this apparent contradiction? I'm a total beginner at this sort of math (I'm an engineer by training, not a mathematician!) and would appreciate any assistance!",,"['abstract-algebra', 'definition']"
15,Proving the quotient of a principal ideal domain by a prime ideal is again a principal ideal domain [closed],Proving the quotient of a principal ideal domain by a prime ideal is again a principal ideal domain [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question Please help me prove that the quotient of a principal ideal domain by a prime ideal is again a principal ideal domain. This was from Abstract Algebra","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question Please help me prove that the quotient of a principal ideal domain by a prime ideal is again a principal ideal domain. This was from Abstract Algebra",,"['abstract-algebra', 'principal-ideal-domains']"
16,"Basic understanding of quotients of ""things""?","Basic understanding of quotients of ""things""?",,"My modern algebra needs some work. Am I right in thinking that $\mathbb{Z}/2\mathbb{Z}$ refers to the two sets $$\{\pm0, \pm2, \pm4, \pm6, \ldots\}$$ and $$\{\pm1, \pm3, \pm5, \pm7\}~~?$$ What about $\mathbb{R}/2\mathbb{Z}$ if that makes sense to write? Would that mean $$\{,\ldots,[0,1),[2,3),[4,5),\ldots\}$$ and $$\{\ldots,[1,2),[3,4),[5,6),\ldots\}~~?$$ I haven't got round to looking at these ""quotients"" as I think they're called. It's on my list of things to do. I believe they're to do with equivalence classes? Are there some more ""exotic"" examples with concrete examples of the sets produced as above? Just asking to see if I'm thinking on the right track. So my original understanding of $\mathbb{R}/2\mathbb{Z}$ was incorrect (as pointed out in answer(s) below). EDIT Not sure if this is a good way to visualise what's going on with e.g. $\mathbb{R}/2\mathbb{Z}$, but imagine the Cartesian plane with $x$ and $y$ axes. For $\mathbb{R}/2\mathbb{Z}$ I can see the left hand side ($\mathbb{R}$) corresponding to the $y$-axis and the right hand side ($2\mathbb{Z}$) corresponding to the integers on the $x$-axis. If I imagine $2\mathbb{Z}$ on the $x$-axis slicing the plane vertically then what I'm left with is an infinite number of slices each of width $2$. The quotient kind of takes all these slices and stacks them on top of each other so that the only information available to me belongs to $[0,2)$. Positioning along the $x$-axis is lost.","My modern algebra needs some work. Am I right in thinking that $\mathbb{Z}/2\mathbb{Z}$ refers to the two sets $$\{\pm0, \pm2, \pm4, \pm6, \ldots\}$$ and $$\{\pm1, \pm3, \pm5, \pm7\}~~?$$ What about $\mathbb{R}/2\mathbb{Z}$ if that makes sense to write? Would that mean $$\{,\ldots,[0,1),[2,3),[4,5),\ldots\}$$ and $$\{\ldots,[1,2),[3,4),[5,6),\ldots\}~~?$$ I haven't got round to looking at these ""quotients"" as I think they're called. It's on my list of things to do. I believe they're to do with equivalence classes? Are there some more ""exotic"" examples with concrete examples of the sets produced as above? Just asking to see if I'm thinking on the right track. So my original understanding of $\mathbb{R}/2\mathbb{Z}$ was incorrect (as pointed out in answer(s) below). EDIT Not sure if this is a good way to visualise what's going on with e.g. $\mathbb{R}/2\mathbb{Z}$, but imagine the Cartesian plane with $x$ and $y$ axes. For $\mathbb{R}/2\mathbb{Z}$ I can see the left hand side ($\mathbb{R}$) corresponding to the $y$-axis and the right hand side ($2\mathbb{Z}$) corresponding to the integers on the $x$-axis. If I imagine $2\mathbb{Z}$ on the $x$-axis slicing the plane vertically then what I'm left with is an infinite number of slices each of width $2$. The quotient kind of takes all these slices and stacks them on top of each other so that the only information available to me belongs to $[0,2)$. Positioning along the $x$-axis is lost.",,"['abstract-algebra', 'quotient-spaces']"
17,"If $a^3=e$, then $a$ has a square root","If , then  has a square root",a^3=e a,"Assuming $a\in G$ where $G$ is a group. I'm not sure why this is hard for me. Essentially, the problem is just saying: If $a^3=e$, then there exists $x \in G$ such that $a=x^2$. Can somebody give me a hint or a direction to start in? (not full solution, please--I want to figure it out myself) Thank you.","Assuming $a\in G$ where $G$ is a group. I'm not sure why this is hard for me. Essentially, the problem is just saying: If $a^3=e$, then there exists $x \in G$ such that $a=x^2$. Can somebody give me a hint or a direction to start in? (not full solution, please--I want to figure it out myself) Thank you.",,"['abstract-algebra', 'group-theory']"
18,How do you prove that $\Bbb{Z}_p$ is an integral domain?,How do you prove that  is an integral domain?,\Bbb{Z}_p,Let $\Bbb{Z}_p$ be the $p$-adic integers given by formal series $\sum_{i\geq 0} a_i p^i$.  I'm having trouble proving that it's an integral domain.,Let $\Bbb{Z}_p$ be the $p$-adic integers given by formal series $\sum_{i\geq 0} a_i p^i$.  I'm having trouble proving that it's an integral domain.,,"['abstract-algebra', 'ring-theory', 'p-adic-number-theory']"
19,"Prove or disprove: $(\mathbb{Q}, +)$ is isomorphic to $(\mathbb{Z} \times \mathbb{Z}, +)$?",Prove or disprove:  is isomorphic to ?,"(\mathbb{Q}, +) (\mathbb{Z} \times \mathbb{Z}, +)","Prove or disprove: $\mathbb{Q}$ is isomorphic to $\mathbb{Z} \times \mathbb{Z}$. I mean the groups $(\mathbb Q, +)$ and $(\mathbb Z \times \mathbb Z,+).$ Is there an isomorphism?","Prove or disprove: $\mathbb{Q}$ is isomorphic to $\mathbb{Z} \times \mathbb{Z}$. I mean the groups $(\mathbb Q, +)$ and $(\mathbb Z \times \mathbb Z,+).$ Is there an isomorphism?",,"['abstract-algebra', 'group-theory']"
20,Showing that every field is an integral domain.,Showing that every field is an integral domain.,,"The proof I have starts of with $\;xy=0\;$ in a field. Then $x^{-1}$ exists because it is a field. Then $x^{-1} xy=x^{-1} 0$. Therefore $y=0$. But surely if an integral domain can not have any zero divisors, how can we end the proof by saying $y=0$? Surely then y is a zero divisor and hence the field is not an integral domain?","The proof I have starts of with $\;xy=0\;$ in a field. Then $x^{-1}$ exists because it is a field. Then $x^{-1} xy=x^{-1} 0$. Therefore $y=0$. But surely if an integral domain can not have any zero divisors, how can we end the proof by saying $y=0$? Surely then y is a zero divisor and hence the field is not an integral domain?",,[]
21,What is the quotient of a cyclic group of order $n$ by a cyclic subgroup of order $m$?,What is the quotient of a cyclic group of order  by a cyclic subgroup of order ?,n m,"Suppose that $H$ is a (cyclic) subgroup of order $m$ of a cyclic group   $G$ of order $n$. What is $G/H$? It's a very simple question but I am still struggling with getting accustomed to the notion of the quotient group. Now, I know that $m$ divides $n$ and that $G/H$ will be a group of cosets such that $\{gH:g\in G\}$. As a result, there will be $n/m$ of such cosets. I was wondering I can say anything more specific than just that?","Suppose that $H$ is a (cyclic) subgroup of order $m$ of a cyclic group   $G$ of order $n$. What is $G/H$? It's a very simple question but I am still struggling with getting accustomed to the notion of the quotient group. Now, I know that $m$ divides $n$ and that $G/H$ will be a group of cosets such that $\{gH:g\in G\}$. As a result, there will be $n/m$ of such cosets. I was wondering I can say anything more specific than just that?",,"['abstract-algebra', 'group-theory', 'finite-groups']"
22,Count the number group homomorphisms from $S_3$ to $\mathbb{Z}/6\mathbb{Z}$?,Count the number group homomorphisms from  to ?,S_3 \mathbb{Z}/6\mathbb{Z},"I have to count the number of group homomorphisms from $S_3$ to $\mathbb{Z}/6\mathbb{Z}$ ? 1 2 3 6 I aware of the formula for calculating group homomorphisms defined on cyclic groups, but here $S_3$ is not cyclic. Please suggest how to proceed. Thank you so much Egbert for the much detailed and patient reply.","I have to count the number of group homomorphisms from to ? 1 2 3 6 I aware of the formula for calculating group homomorphisms defined on cyclic groups, but here is not cyclic. Please suggest how to proceed. Thank you so much Egbert for the much detailed and patient reply.",S_3 \mathbb{Z}/6\mathbb{Z} S_3,"['abstract-algebra', 'group-theory']"
23,Isomorphic fields of finite degree have same dimension over base field,Isomorphic fields of finite degree have same dimension over base field,,"Let $K/F$ be a field extension and $L_1,L_2$ subfields of $K$ such that $L_1$ and $L_2$ have finite degree over $F$ . Does $L_1 \cong L_2$ imply $[L_1 : F ]=[L_2 : F]$ ? Obviously, if the isomorphism fixes $F$ (which isn't always necessarily true) the result holds. The result even holds if $F$ is of finite degree over its prime field. When trying the usual proof, we get that $[L_1 : F] = [L_1^{\theta} : F^{\theta} ]=[L_2 : F^{\theta}]$ when $\theta \,\colon L_1 \rightarrow L_2$ is the given isomorphism. But I don't see how to relate $F^{\theta}$ to $F$ in an easy way. Any help or counterexample? Many thanks in advance.","Let be a field extension and subfields of such that and have finite degree over . Does imply ? Obviously, if the isomorphism fixes (which isn't always necessarily true) the result holds. The result even holds if is of finite degree over its prime field. When trying the usual proof, we get that when is the given isomorphism. But I don't see how to relate to in an easy way. Any help or counterexample? Many thanks in advance.","K/F L_1,L_2 K L_1 L_2 F L_1 \cong L_2 [L_1 : F ]=[L_2 : F] F F [L_1 : F] = [L_1^{\theta} : F^{\theta} ]=[L_2 : F^{\theta}] \theta \,\colon L_1 \rightarrow L_2 F^{\theta} F","['abstract-algebra', 'field-theory', 'extension-field']"
24,Defining binomial coefficients over rings in general,Defining binomial coefficients over rings in general,,"I'm looking over my notes, and we proved that the binomial theorem $$(a + b)^n = \sum_{k = 0}^{n} {n \choose k}a^k b^{n-k}$$ holds on all commutative rings. However, I am confused on how we are defining  ${n \choose k}$, since the definition $ {n \choose k} = \frac{n!}{(n-k)!k!} $ is no longer well defined over rings in general, since $k!$ may equal $0$. For example, $p! = 0$ in $F_p$, the field of p elements. Any idea how to interpret the binomial coefficients in these cases?","I'm looking over my notes, and we proved that the binomial theorem $$(a + b)^n = \sum_{k = 0}^{n} {n \choose k}a^k b^{n-k}$$ holds on all commutative rings. However, I am confused on how we are defining  ${n \choose k}$, since the definition $ {n \choose k} = \frac{n!}{(n-k)!k!} $ is no longer well defined over rings in general, since $k!$ may equal $0$. For example, $p! = 0$ in $F_p$, the field of p elements. Any idea how to interpret the binomial coefficients in these cases?",,"['abstract-algebra', 'ring-theory', 'binomial-coefficients']"
25,An Infinite Cyclic Group has Exactly Two Generators: Is My Proof Correct?,An Infinite Cyclic Group has Exactly Two Generators: Is My Proof Correct?,,"I have completed a proof of this that I am inclined to believe is correct, or at least on the right track. I would like to ask if it is indeed correct, or if I need a nudge in the right direction. Perhaps there is a better way to go about this? My Proof : (1) I will show that the existence of a generator for an infinite cyclic group implies the existence of a second which is the inverse of the former. If $G$ is an infinite cyclic group, then every element of $G$ can be written as $a^n$ for $n\in\mathbb{Z}$ and $a$ some element of $G$. It is clear, then, that $a^{-1}$ and $a$ are both generators for $G$ since, given $n\in\mathbb{Z}$, we can choose $m\in\mathbb{Z}$ such that $(a^{-1})^n=(a)^m$ by taking $m=-n$. Moreover, we are guaranteed that $a^{-1}\ne a$ since this would imply $a=a^{-1}=e_G$ leaving us with $G$ the trivial group. So given one generator, there must be another, namely, the inverse of the given generator. (2) Now I will show that $G$ cannot have more than two generators. Now suppose for the sake of contradiction that $n>2$ and $G=\langle{a_1}\rangle=\ldots=\langle{a_n}\rangle$ (which is to say that any one of these $n$ elements and its inverses generate $G$), where $a_i=a_j\iff i=j$. Then, by invoking the pigeonhole principle, at least one of the members of $\{a_1,\ldots,a_n\}$ is not an inverse of one of the others. Let us call this element $a_i\ne a_1,a_{1}^{-1}$. Thus, if $a_1$ generates $G$, then there exists $b\in\mathbb{Z}$ for which $a_{1}^{b}=a_i$. Hence, if these both generate $G$, then $\forall{c\in\mathbb{Z}},\exists{j\in\mathbb{Z}}$ such that $a_{1}^{c}=a_{i}^{j}$, but $a_{i}=a_{1}^{b}$, so $a_{1}^{c}=a_{1}^{bj}$. But if $b\ne{\pm1}$, this is cannot be true, as this would state (for $c=b-1$) that $b-1=bj\implies j=1-\frac{1}{b}$ and then both $j$ and $\frac{1}{b}$ cannot be an integer for any value other than $b=\pm{1}$, which contradicts the assumption that $a_{i}$ is neither the inverse of $a_{1}$ nor equal to $a_1$. Combining statements (1) and (2),it follows that if $G$ has one generator and it is an infinite cyclic group, then this generator is not the identity element and $G$ must have two generators. Additionally, if $G$ is an infinite cyclic group, it cannot have $n>2$ generators. These two statements mean that $G$ must have precisely two generators.","I have completed a proof of this that I am inclined to believe is correct, or at least on the right track. I would like to ask if it is indeed correct, or if I need a nudge in the right direction. Perhaps there is a better way to go about this? My Proof : (1) I will show that the existence of a generator for an infinite cyclic group implies the existence of a second which is the inverse of the former. If $G$ is an infinite cyclic group, then every element of $G$ can be written as $a^n$ for $n\in\mathbb{Z}$ and $a$ some element of $G$. It is clear, then, that $a^{-1}$ and $a$ are both generators for $G$ since, given $n\in\mathbb{Z}$, we can choose $m\in\mathbb{Z}$ such that $(a^{-1})^n=(a)^m$ by taking $m=-n$. Moreover, we are guaranteed that $a^{-1}\ne a$ since this would imply $a=a^{-1}=e_G$ leaving us with $G$ the trivial group. So given one generator, there must be another, namely, the inverse of the given generator. (2) Now I will show that $G$ cannot have more than two generators. Now suppose for the sake of contradiction that $n>2$ and $G=\langle{a_1}\rangle=\ldots=\langle{a_n}\rangle$ (which is to say that any one of these $n$ elements and its inverses generate $G$), where $a_i=a_j\iff i=j$. Then, by invoking the pigeonhole principle, at least one of the members of $\{a_1,\ldots,a_n\}$ is not an inverse of one of the others. Let us call this element $a_i\ne a_1,a_{1}^{-1}$. Thus, if $a_1$ generates $G$, then there exists $b\in\mathbb{Z}$ for which $a_{1}^{b}=a_i$. Hence, if these both generate $G$, then $\forall{c\in\mathbb{Z}},\exists{j\in\mathbb{Z}}$ such that $a_{1}^{c}=a_{i}^{j}$, but $a_{i}=a_{1}^{b}$, so $a_{1}^{c}=a_{1}^{bj}$. But if $b\ne{\pm1}$, this is cannot be true, as this would state (for $c=b-1$) that $b-1=bj\implies j=1-\frac{1}{b}$ and then both $j$ and $\frac{1}{b}$ cannot be an integer for any value other than $b=\pm{1}$, which contradicts the assumption that $a_{i}$ is neither the inverse of $a_{1}$ nor equal to $a_1$. Combining statements (1) and (2),it follows that if $G$ has one generator and it is an infinite cyclic group, then this generator is not the identity element and $G$ must have two generators. Additionally, if $G$ is an infinite cyclic group, it cannot have $n>2$ generators. These two statements mean that $G$ must have precisely two generators.",,"['abstract-algebra', 'group-theory', 'cyclic-groups', 'infinite-groups']"
26,"Quotient rings of Gaussian integers $\mathbb{Z}[i]/(2)$, $\mathbb{Z}[i]/(3)$, $\mathbb{Z}[i]/(5)$,","Quotient rings of Gaussian integers , , ,",\mathbb{Z}[i]/(2) \mathbb{Z}[i]/(3) \mathbb{Z}[i]/(5),"I am studying for an algebra qualifying exam and came across the following problem. Let $R$ be the ring of Gaussian Integers. Of the three quotient rings   $$R/(2),\quad R/(3),\quad R/(5),$$   one is a field, one is isomorphic to a product of fields, and one is neither a field nor a product of fields. Which is which and why? I know that $2=(1+i)(1-i)$ and $5=(1+2i)(1-2i)$, so neither $(2)$ nor $(5)$ is a prime ideal of $R$. Then (I think) these same equations in $R/(2)$ and $R/(5)$, respectively, show that neither is an integral domain. Regardless, I can show that 3 is a Gaussian prime, hence $(3)$ is maximal in $R$ and $R/(3)$ is the field. But if I am correct about the others not being integral domains, I fail to see how either could be a product of fields. I hope that this can be answered easily and quickly. Thanks.","I am studying for an algebra qualifying exam and came across the following problem. Let $R$ be the ring of Gaussian Integers. Of the three quotient rings   $$R/(2),\quad R/(3),\quad R/(5),$$   one is a field, one is isomorphic to a product of fields, and one is neither a field nor a product of fields. Which is which and why? I know that $2=(1+i)(1-i)$ and $5=(1+2i)(1-2i)$, so neither $(2)$ nor $(5)$ is a prime ideal of $R$. Then (I think) these same equations in $R/(2)$ and $R/(5)$, respectively, show that neither is an integral domain. Regardless, I can show that 3 is a Gaussian prime, hence $(3)$ is maximal in $R$ and $R/(3)$ is the field. But if I am correct about the others not being integral domains, I fail to see how either could be a product of fields. I hope that this can be answered easily and quickly. Thanks.",,"['abstract-algebra', 'ring-theory']"
27,Can the square of a proper ideal be equal to the ideal?,Can the square of a proper ideal be equal to the ideal?,,"Let $R$ be a ring, commutative with $1$, let $\mathfrak{i}$ be an ideal, not the whole ring. In general $\mathfrak{i}^2\subseteq\mathfrak{i}$. Can this inclusion be an equality, or it is always a strict inclusion?","Let $R$ be a ring, commutative with $1$, let $\mathfrak{i}$ be an ideal, not the whole ring. In general $\mathfrak{i}^2\subseteq\mathfrak{i}$. Can this inclusion be an equality, or it is always a strict inclusion?",,"['abstract-algebra', 'ring-theory', 'ideals']"
28,"Why is $\mathbb{C}[x,y]$ not isomorphic to $\mathbb{C}[x] \otimes _{\mathbb{Z}} \mathbb{C}[y]$ as rings?",Why is  not isomorphic to  as rings?,"\mathbb{C}[x,y] \mathbb{C}[x] \otimes _{\mathbb{Z}} \mathbb{C}[y]","I would like to know why $\mathbb{C}[x,y]$ is not isomorphic to $\mathbb{C}[x] \otimes _{\mathbb{Z}} \mathbb{C}[y]$ as rings. Thank you! 1","I would like to know why $\mathbb{C}[x,y]$ is not isomorphic to $\mathbb{C}[x] \otimes _{\mathbb{Z}} \mathbb{C}[y]$ as rings. Thank you! 1",,"['abstract-algebra', 'algebraic-geometry', 'commutative-algebra']"
29,Multiplicity of root $1$ of $nX^{n+2}-(n+2)X^{n+1}+(n+2)X-n$?,Multiplicity of root  of ?,1 nX^{n+2}-(n+2)X^{n+1}+(n+2)X-n,"I'm solving this homework problem: Show that $1$ is a root of the polynomial $nX^{n+2}-(n+2)X^{n+1}+(n+2)X-n$ . Determine its multiplicity. I believe the answer is $n+2,$ and currently working on proving this. My intuition stems from the fact that when $n=1, P(x)=(x-1)^3, so$ 1 is a polynomial of multiplicity $3.$ I attempted this: calling the polynomial $P(x),$ we see that $P(1)=0,$ hence $1$ is a root for sure. To determine its multiplicity, I'm thinking about: Taking successive derivatives $P'(1), P''(1) \dots P^{(n+3)}(1) $ of the polynomial and showing that all but the last one $P^{(n+3)}(1)$ vanishes. But I'm a bit skeptical because the antiderivative of a polynomial doesn't always have multiplicity one more than the original polynomial, which forms the basis/idea of the method I'm thinking of. For example $Q(x):=2x$ has the root $0$ of multiplicity $1,$ but the antiderivative $x^2+1$ doesn't have any real root. So my question is: in order to answer the question in the image, what is the exact theorem should we use? Is it something like this? Proposed theorem: If $Q(x)$ has the real root $a$ of order $k,$ then its antiderivative with constant of integration $0$ has the real root $a$ of order $k+1.$ The above seems to be true, and if yes, can we use this to show that the successive derivatives $P'(1), P''(1) \dots P^{(n+2)}(1) $ of the polynomial vanish but $P^{(n+2)}(1) $ doesn't vanish, and this'll show that $1$ is a root of multiplicity $n+2.$ Is my idea correct? ADDENDUM/EDIT: Can we arrive at the proof that $1$ is a root of multiplicity $n+2$ by using induction? At $n=1,$ the multiplicity is $1+2=3,$ so the induction can start, and now we just need to show the induction step. Will this work? P.S. As per Dietrich's answer, the multiplicity seems to be $3$ irrespective of $n.$ So can we just prove this using the derivatives above or by induction?","I'm solving this homework problem: Show that is a root of the polynomial . Determine its multiplicity. I believe the answer is and currently working on proving this. My intuition stems from the fact that when 1 is a polynomial of multiplicity I attempted this: calling the polynomial we see that hence is a root for sure. To determine its multiplicity, I'm thinking about: Taking successive derivatives of the polynomial and showing that all but the last one vanishes. But I'm a bit skeptical because the antiderivative of a polynomial doesn't always have multiplicity one more than the original polynomial, which forms the basis/idea of the method I'm thinking of. For example has the root of multiplicity but the antiderivative doesn't have any real root. So my question is: in order to answer the question in the image, what is the exact theorem should we use? Is it something like this? Proposed theorem: If has the real root of order then its antiderivative with constant of integration has the real root of order The above seems to be true, and if yes, can we use this to show that the successive derivatives of the polynomial vanish but doesn't vanish, and this'll show that is a root of multiplicity Is my idea correct? ADDENDUM/EDIT: Can we arrive at the proof that is a root of multiplicity by using induction? At the multiplicity is so the induction can start, and now we just need to show the induction step. Will this work? P.S. As per Dietrich's answer, the multiplicity seems to be irrespective of So can we just prove this using the derivatives above or by induction?","1 nX^{n+2}-(n+2)X^{n+1}+(n+2)X-n n+2, n=1, P(x)=(x-1)^3, so 3. P(x), P(1)=0, 1 P'(1), P''(1) \dots P^{(n+3)}(1)  P^{(n+3)}(1) Q(x):=2x 0 1, x^2+1 Q(x) a k, 0 a k+1. P'(1), P''(1) \dots P^{(n+2)}(1)  P^{(n+2)}(1)  1 n+2. 1 n+2 n=1, 1+2=3, 3 n.","['abstract-algebra', 'derivatives', 'polynomials', 'roots']"
30,Does a group of order $400$ always have a subgroup of order $200$?,Does a group of order  always have a subgroup of order ?,400 200,"Does a group of order $400$ always have a subgroup of order $200$ ? I was considering some simple applications of Sylow theorems. I have made some questions. Among them, there was one which asks to prove that a group of order 200 always have a subgroup of order 100. This question has a simple solution since the Sylow group of order $25$ is unique and hence normal. After this, I became curious about the existence of normal subgroups of order $2^k p^l$ of groups of order $2^{k+1} p^l$ . The following two paragraphs are about my failed attempt which may not helpful. For a group of order $400$ , say $G$ , let $n_5$ be the number of Sylow group of order $25$ . If $n_5 =1$ , we are done. So suppose that $n_5 = 16$ . Let $A$ and $B$ be two Sylow subgroups of order $25$ . Analysing the number of elements in the set $AB$ , one can conclude that the order of $A \cap B$ to be $5$ . This forced $A \cap B$ to be normal subgroup in $A$ and $B$ . I was considered the normalizer $N(A \cap B)$ . For this should contain $A$ and $B$ , the order of $N(A \cap B)$ should be $200$ or $400$ . If it was $200$ , we are done. So suppose that for every pair of different Sylow groups of order $25$ $A$ and $B$ , $A \cap B$ is normal. If there occur two different intersections of order $5$ , we are done since the product of two such normal subgroups of order $5$ will provide a normal subgroup of order $25$ . The point I was stuck is there. Specifically, if a counterexample exists, it should have $16$ Sylow subgroups or order $25$ whose intersection is of order $5$ . The followings are just some consideration for generalization which may ""not even wrong"" Most generally, I'm curious about the condition of $n$ which forces to exist a subgroup of order $n$ of a group of order $2n$ . Note that as all of you know, there are some groups of even order without having subgroups of index $2$ . All simple groups of even order have this property since a subgroup of index $2$ is automatically normal. Anyway, let me just state the general question. Find a simple criterion for a positive integer $n$ to have the property that every group of order $2n$ has a subgroup of index $2$ . Finally, thank you for your attention.","Does a group of order always have a subgroup of order ? I was considering some simple applications of Sylow theorems. I have made some questions. Among them, there was one which asks to prove that a group of order 200 always have a subgroup of order 100. This question has a simple solution since the Sylow group of order is unique and hence normal. After this, I became curious about the existence of normal subgroups of order of groups of order . The following two paragraphs are about my failed attempt which may not helpful. For a group of order , say , let be the number of Sylow group of order . If , we are done. So suppose that . Let and be two Sylow subgroups of order . Analysing the number of elements in the set , one can conclude that the order of to be . This forced to be normal subgroup in and . I was considered the normalizer . For this should contain and , the order of should be or . If it was , we are done. So suppose that for every pair of different Sylow groups of order and , is normal. If there occur two different intersections of order , we are done since the product of two such normal subgroups of order will provide a normal subgroup of order . The point I was stuck is there. Specifically, if a counterexample exists, it should have Sylow subgroups or order whose intersection is of order . The followings are just some consideration for generalization which may ""not even wrong"" Most generally, I'm curious about the condition of which forces to exist a subgroup of order of a group of order . Note that as all of you know, there are some groups of even order without having subgroups of index . All simple groups of even order have this property since a subgroup of index is automatically normal. Anyway, let me just state the general question. Find a simple criterion for a positive integer to have the property that every group of order has a subgroup of index . Finally, thank you for your attention.",400 200 25 2^k p^l 2^{k+1} p^l 400 G n_5 25 n_5 =1 n_5 = 16 A B 25 AB A \cap B 5 A \cap B A B N(A \cap B) A B N(A \cap B) 200 400 200 25 A B A \cap B 5 5 25 16 25 5 n n 2n 2 2 n 2n 2,"['abstract-algebra', 'group-theory', 'finite-groups', 'normal-subgroups', 'sylow-theory']"
31,"Units in ring of integers are exactly those with norm {-1,1}","Units in ring of integers are exactly those with norm {-1,1}",,"Let $K$ be an algebraic number field and $R$ be the ring of the integers of $K$. Show that an element $u\in R$ is a unit of $R$ if and only if $N_{K/\mathbb{Q}}(u)\in \{-1,1\}$. It is easy to show units are of norm {-1,1}. But on the other hand, I have no idea.","Let $K$ be an algebraic number field and $R$ be the ring of the integers of $K$. Show that an element $u\in R$ is a unit of $R$ if and only if $N_{K/\mathbb{Q}}(u)\in \{-1,1\}$. It is easy to show units are of norm {-1,1}. But on the other hand, I have no idea.",,"['abstract-algebra', 'field-theory', 'algebraic-number-theory']"
32,Is a polynomial ring over a UFD in countably many variables a UFD?,Is a polynomial ring over a UFD in countably many variables a UFD?,,"Let $R$ be a UFD. It is well know that $R[x]$ is also a UFD, and so then is $R[x_1,x_2,\cdots,x_n]$ is a UFD for any finite number of variables. Is $R[x_1,x_2,\cdots,x_n,\cdots]$ in countably many variables also a UFD? If not, what about if we take $\tilde{R} = R[x_1,\cdots,x_n,\cdots]$ where each polynomial must be given in finitely many of the variables?","Let $R$ be a UFD. It is well know that $R[x]$ is also a UFD, and so then is $R[x_1,x_2,\cdots,x_n]$ is a UFD for any finite number of variables. Is $R[x_1,x_2,\cdots,x_n,\cdots]$ in countably many variables also a UFD? If not, what about if we take $\tilde{R} = R[x_1,\cdots,x_n,\cdots]$ where each polynomial must be given in finitely many of the variables?",,"['abstract-algebra', 'ring-theory', 'unique-factorization-domains']"
33,Prove $GL_2(\mathbb{Z}/2\mathbb{Z})$ is isomorphic to $S_3$,Prove  is isomorphic to,GL_2(\mathbb{Z}/2\mathbb{Z}) S_3,"I'm asked to show that $G=GL_2(\Bbb Z/2\Bbb Z)$ is isomorphic to $S_3$. I have few ideas but I don't manage to put them all together in order to obtain a satisying answer. I first tried using Cayley's theorem ($G$ is isomorphic to a subgroup of $S_6$), and I also noticed that $\operatorname{Card}(G)=\operatorname{Card}(S3)=6$ & that they're both non-abelian group. Is this enough to say that considering $S_3$ is a subgroup of $S_6$ with the same cardinality than $G$, it has to be isomorphic to it ?  Could anyone give me some elements to get a more rigorous proof or lead me to an other path to show this statement ?  Thanks in advance","I'm asked to show that $G=GL_2(\Bbb Z/2\Bbb Z)$ is isomorphic to $S_3$. I have few ideas but I don't manage to put them all together in order to obtain a satisying answer. I first tried using Cayley's theorem ($G$ is isomorphic to a subgroup of $S_6$), and I also noticed that $\operatorname{Card}(G)=\operatorname{Card}(S3)=6$ & that they're both non-abelian group. Is this enough to say that considering $S_3$ is a subgroup of $S_6$ with the same cardinality than $G$, it has to be isomorphic to it ?  Could anyone give me some elements to get a more rigorous proof or lead me to an other path to show this statement ?  Thanks in advance",,"['abstract-algebra', 'group-theory', 'proof-writing', 'group-isomorphism']"
34,Prove that the centralizer subgroup is normal in the normalizer subgroup,Prove that the centralizer subgroup is normal in the normalizer subgroup,,To my dear friends with gratitude. I want to get help proving centralizer of a nonempty subset of a group is a normal subgroup in the normalizer of that set in the mentioned group.symbolically: $C_G (S)\trianglelefteq N_G (S)$,To my dear friends with gratitude. I want to get help proving centralizer of a nonempty subset of a group is a normal subgroup in the normalizer of that set in the mentioned group.symbolically:,C_G (S)\trianglelefteq N_G (S),"['abstract-algebra', 'group-theory']"
35,Subgroups of finite solvable groups. Solvable?,Subgroups of finite solvable groups. Solvable?,,"I am attempting to prove that, given a non-trivial normal subgroup $N$ of a finite group $G$, we have that $G$ is solvable iff both $N$, $G/N$ are solvable. I was able to show that if $N,G/N$ are solvable, then $G$ is; also, that if $G$ is solvable, then $G/N$ is. I am stuck showing that $N$ must be solvable if $G$ is. It seems intuitive that any subgroup of a finite solvable group is necessarily solvable, as well. Is this true in general? For normal subgroups? How can I go about proving this result? Edit: By solvable, I mean we have a finite sequence $1=G_0\unlhd ... \unlhd G_k=G$ such that $G_{j+1}/G_j$ is abelian for each $1\leq j<k$.","I am attempting to prove that, given a non-trivial normal subgroup $N$ of a finite group $G$, we have that $G$ is solvable iff both $N$, $G/N$ are solvable. I was able to show that if $N,G/N$ are solvable, then $G$ is; also, that if $G$ is solvable, then $G/N$ is. I am stuck showing that $N$ must be solvable if $G$ is. It seems intuitive that any subgroup of a finite solvable group is necessarily solvable, as well. Is this true in general? For normal subgroups? How can I go about proving this result? Edit: By solvable, I mean we have a finite sequence $1=G_0\unlhd ... \unlhd G_k=G$ such that $G_{j+1}/G_j$ is abelian for each $1\leq j<k$.",,['abstract-algebra']
36,Matrix ring $\cong \Bbb F_2[x]/x^2 = $ dual numbers over $\Bbb Z/2$,Matrix ring  dual numbers over,\cong \Bbb F_2[x]/x^2 =  \Bbb Z/2,"For no real reason, I did a classification of (associative, with a 1) rings with less than 8 elements (they all happen to be commutative).  Most of the rings I got were of a type I knew - namely: cyclic, field, or Boolean - but one wasn't. $R \hspace{.04 in} := \hspace{.04 in} \Bigg\langle \bigg\{\begin{pmatrix} 0 & 0 \\ 0 & 0 \end{pmatrix},\begin{pmatrix} 1 & 0 \\ 0 & 1 \end{pmatrix},\begin{pmatrix} 0 & 1 \\ 0 & 0 \end{pmatrix},\begin{pmatrix} 1 & 1 \\ 0 & 1 \end{pmatrix}\bigg\} \text{ , matrix operations over the field } \mathbb{Z}/2\mathbb{Z} \Bigg\rangle$ Does $R$ arise in any remotely natural situations?","For no real reason, I did a classification of (associative, with a 1) rings with less than 8 elements (they all happen to be commutative).  Most of the rings I got were of a type I knew - namely: cyclic, field, or Boolean - but one wasn't. $R \hspace{.04 in} := \hspace{.04 in} \Bigg\langle \bigg\{\begin{pmatrix} 0 & 0 \\ 0 & 0 \end{pmatrix},\begin{pmatrix} 1 & 0 \\ 0 & 1 \end{pmatrix},\begin{pmatrix} 0 & 1 \\ 0 & 0 \end{pmatrix},\begin{pmatrix} 1 & 1 \\ 0 & 1 \end{pmatrix}\bigg\} \text{ , matrix operations over the field } \mathbb{Z}/2\mathbb{Z} \Bigg\rangle$ Does $R$ arise in any remotely natural situations?",,['abstract-algebra']
37,Transitive group action,Transitive group action,,"I am just trying to learn what transitive group action is. It seems I understand the definition, but I still have an issue. We read on Wikipedia that (emphasis added): ""The group action is transitive if and only if it has only one orbit, i.e. if there exists $x \in X$ with $G\cdot x = X$ . This is the case if and only if $G\cdot x = X$ for all $x \in X$ "". Direct implication of another definition I have (from the source I learn from) is that group action is transitive if for every $x \in X$ : $G\cdot x = X$ . According to Wikipedia (and later on in my source), it seems to be enough only for one x to have $G\cdot x = X$ to deduce transitivity. In short, I don't see how $G\cdot x = X$ for one $x \in X \implies G\cdot x = X$ , for every $x \in X$ . P.S: I have yet to learn what orbit is. So please avoid using orbits to explain the issue.","I am just trying to learn what transitive group action is. It seems I understand the definition, but I still have an issue. We read on Wikipedia that (emphasis added): ""The group action is transitive if and only if it has only one orbit, i.e. if there exists with . This is the case if and only if for all "". Direct implication of another definition I have (from the source I learn from) is that group action is transitive if for every : . According to Wikipedia (and later on in my source), it seems to be enough only for one x to have to deduce transitivity. In short, I don't see how for one , for every . P.S: I have yet to learn what orbit is. So please avoid using orbits to explain the issue.",x \in X G\cdot x = X G\cdot x = X x \in X x \in X G\cdot x = X G\cdot x = X G\cdot x = X x \in X \implies G\cdot x = X x \in X,"['abstract-algebra', 'group-theory']"
38,Difference between definitions of $p$-subgroup and Sylow $p$-subgroup,Difference between definitions of -subgroup and Sylow -subgroup,p p,"I'm reading Abstract Algebra by Dummit and Foote and the following definitions are made: $1$ . A group of order $p^{\alpha}$ for some $\alpha\geq1$ is called a $p$ -group. Subgroups of $G$ which are $p$ -groups are called $p$ -subgroups. $2$ . If $G$ is a group of order $p^{\alpha}m$ , where $p$ does not divide $m$ , then a subgroup of order $p^{\alpha}$ is called a Sylow $p$ -subgroup of G. As I see it the difference seems to be that if $H \leq G$ with $|H|=p^{\beta}$ for $\beta\geq1$ it is called a $p$ -subgroup if $|G|=p^{\alpha}$ and a sylow subgroup of $G$ if its order is not a power of $p$ . But in the wording of the Sylow's theorem in the book it reads that Let G be a group of order $p^{\alpha}m$ , where $p$ is a prime not dividing $m$ then...If $P$ is a Sylow $p$ -subgroup of $G$ and $Q$ is any $p$ -subgroup of G... I don't understand the difference between $P$ and $Q$ ..both are subgroups of $G$ with order of a power of $p$ and I thought that $Q$ can't be called a $p$ subgroup because the order of $G$ is not a power of $p$ . So it seems that I didn't understand the difference in definitions $(1)$ and $(2)$ after all. Can someone please clarify ?","I'm reading Abstract Algebra by Dummit and Foote and the following definitions are made: . A group of order for some is called a -group. Subgroups of which are -groups are called -subgroups. . If is a group of order , where does not divide , then a subgroup of order is called a Sylow -subgroup of G. As I see it the difference seems to be that if with for it is called a -subgroup if and a sylow subgroup of if its order is not a power of . But in the wording of the Sylow's theorem in the book it reads that Let G be a group of order , where is a prime not dividing then...If is a Sylow -subgroup of and is any -subgroup of G... I don't understand the difference between and ..both are subgroups of with order of a power of and I thought that can't be called a subgroup because the order of is not a power of . So it seems that I didn't understand the difference in definitions and after all. Can someone please clarify ?",1 p^{\alpha} \alpha\geq1 p G p p 2 G p^{\alpha}m p m p^{\alpha} p H \leq G |H|=p^{\beta} \beta\geq1 p |G|=p^{\alpha} G p p^{\alpha}m p m P p G Q p P Q G p Q p G p (1) (2),"['abstract-algebra', 'group-theory', 'finite-groups', 'sylow-theory', 'p-groups']"
39,Solvability of a group with order $p^n$,Solvability of a group with order,p^n,"If $G$ is a group whose order is $p^n$($p$ is prime), then $G$ is solvable. How am I going to show this? Any help is appreciated. Thank you.","If $G$ is a group whose order is $p^n$($p$ is prime), then $G$ is solvable. How am I going to show this? Any help is appreciated. Thank you.",,"['abstract-algebra', 'group-theory', 'finite-groups']"
40,Classify groups of order 27,Classify groups of order 27,,"Let $|G|=27$. Prove that all subgroups of index $3$ are normal. Classify all groups of order $27$. I can do the first one, but the classification is overwhelming. I don't even know where to start. Any help appreciated.","Let $|G|=27$. Prove that all subgroups of index $3$ are normal. Classify all groups of order $27$. I can do the first one, but the classification is overwhelming. I don't even know where to start. Any help appreciated.",,"['abstract-algebra', 'group-theory', 'finite-groups', 'p-groups', 'groups-enumeration']"
41,Term for a group where every element is its own inverse?,Term for a group where every element is its own inverse?,,"Several groups have the property that every element is its own inverse.  For example, the numbers $0$ and $1$ and the XOR operator form a group of this sort, and more generally the set of all bitstrings of length $n$ and XOR form a group with this property. These groups have the interesting property that they have to be commutative . Is there a special name associated with groups with this property?  Or are they just ""abelian groups where every element has order two?"" Thanks!","Several groups have the property that every element is its own inverse.  For example, the numbers and and the XOR operator form a group of this sort, and more generally the set of all bitstrings of length and XOR form a group with this property. These groups have the interesting property that they have to be commutative . Is there a special name associated with groups with this property?  Or are they just ""abelian groups where every element has order two?"" Thanks!",0 1 n,"['abstract-algebra', 'group-theory', 'terminology']"
42,Abelian groups: proving $\prod\limits_{g\in G}g=\prod\limits_{\substack{g\in G\\g^2=1}}g$,Abelian groups: proving,\prod\limits_{g\in G}g=\prod\limits_{\substack{g\in G\\g^2=1}}g,Let $G$ be a finite abelian group. Why is $$\prod_{g\in G}g=\prod_{\substack{g\in G\\g^2=1}} g \ ?$$ I've tried to consider an element with its inverse but I don't get why you can combine the elements - which are different of its inverse - and they annul themselves in the product. Any help?,Let be a finite abelian group. Why is I've tried to consider an element with its inverse but I don't get why you can combine the elements - which are different of its inverse - and they annul themselves in the product. Any help?,G \prod_{g\in G}g=\prod_{\substack{g\in G\\g^2=1}} g \ ?,['abstract-algebra']
43,Find the number of non-zero squares in the field $Zp$,Find the number of non-zero squares in the field,Zp,"Find the number of non-zero elements in the field $Z_p$, where $p$ is an odd prime number, which are squares, i.e. of the form $m^2$; $m \in Z_p$; $m \neq 0$. please help how can i solve this problem? the number of nonzero element is $p-1$ here","Find the number of non-zero elements in the field $Z_p$, where $p$ is an odd prime number, which are squares, i.e. of the form $m^2$; $m \in Z_p$; $m \neq 0$. please help how can i solve this problem? the number of nonzero element is $p-1$ here",,['abstract-algebra']
44,Does $R$ have to be a PID in order for all f.g. torsion-free $R$-modules to be free?,Does  have to be a PID in order for all f.g. torsion-free -modules to be free?,R R,"I was just going through a proof of the following fact from a textbook. Generally $M$ is an $R$ -module. $\textbf{Theorem.}$ A finitely generated torsion-free module over a PID is free. $\textbf{Proof.}$ The proof given in the book is as follows. Let $M$ be a torsion-free non-zero module, generated by $X=\{x_{1},\dots,x_{m}\}$ .  By reordering if necessary, we may assume that, $\mathscr{B} =\{x_{1},x_{2},\dots,x_{m}\}$ is a maximal linearly independent subset of $X$ . Let $F=\text{span}\:\mathscr{B}$ . Since $M$ is non-zero and torsion-free, we have $m \geq 1$ . For each $i$ , there are scalars, $a_{i},a_{ij}$ not all zero such that $$a_{i}x_{i} + \sum\limits_{j=1}^{m} a_{ij}x_{j}=0.\qquad\qquad\qquad\qquad (\star)$$ Since $\mathscr{B}$ is linearly independent, it is clear that $a_{i} \neq 0$ , for all $i$ . Let $a=a_{1}a_{2}\cdots a_{n}$ so that $a_{n} \neq 0$ .  For $(\star)$ , $a_{i}x_{i} \in F$ and so $ax_{i} \in F$ , for all $i$ , i.e. $aM \subseteq F$ . Now the map $\nu:M \to F$ , $x \to ax$ , is $R$ -linear and a monomorphism since $M$ is torsion-free. Hence $M \cong \nu(M)$ which is submodule of the free module $F$ and so $\nu(M)$ is free by $\textbf{Theorem A}$ (see below), i.e. $M$ is free as required. $\textbf{Theorem A.}$ Let $F$ be a free $R$ -module and $M$ a submodule of $F$ . Then $M$ is also free and $\dim_RM \leq \dim_RF$ . I would like to know in the proof of the above theorem, where have we assumed any facts about $\textbf{PID}$ . It seems as if this theorem is true for a torsion-free module over a general ring as well (which I know is not true).","I was just going through a proof of the following fact from a textbook. Generally is an -module. A finitely generated torsion-free module over a PID is free. The proof given in the book is as follows. Let be a torsion-free non-zero module, generated by .  By reordering if necessary, we may assume that, is a maximal linearly independent subset of . Let . Since is non-zero and torsion-free, we have . For each , there are scalars, not all zero such that Since is linearly independent, it is clear that , for all . Let so that .  For , and so , for all , i.e. . Now the map , , is -linear and a monomorphism since is torsion-free. Hence which is submodule of the free module and so is free by (see below), i.e. is free as required. Let be a free -module and a submodule of . Then is also free and . I would like to know in the proof of the above theorem, where have we assumed any facts about . It seems as if this theorem is true for a torsion-free module over a general ring as well (which I know is not true).","M R \textbf{Theorem.} \textbf{Proof.} M X=\{x_{1},\dots,x_{m}\} \mathscr{B} =\{x_{1},x_{2},\dots,x_{m}\} X F=\text{span}\:\mathscr{B} M m \geq 1 i a_{i},a_{ij} a_{i}x_{i} + \sum\limits_{j=1}^{m} a_{ij}x_{j}=0.\qquad\qquad\qquad\qquad (\star) \mathscr{B} a_{i} \neq 0 i a=a_{1}a_{2}\cdots a_{n} a_{n} \neq 0 (\star) a_{i}x_{i} \in F ax_{i} \in F i aM \subseteq F \nu:M \to F x \to ax R M M \cong \nu(M) F \nu(M) \textbf{Theorem A} M \textbf{Theorem A.} F R M F M \dim_RM \leq \dim_RF \textbf{PID}",['abstract-algebra']
45,"When can we ""switch"" isomorphic things","When can we ""switch"" isomorphic things",,"I'm finishing a course on basic abstract algebra, which covers groups, rings, modules, and finite group representations. However, up to this point, I am not very sure about the concept of isomorphism. I know there are examples where given a group $G$ and two normal subgroups, $H$ and $K$ , where $H \cong K$ , but $\frac{G}{H} \not \cong \frac{G}{K}$ . For instance, see here . However, for (external) direct sum, this does not seem to be a problem, for groups $A,B,C,D$ , if $A \cong B$ , $C \cong D$ , $A \oplus B \cong C \oplus D$ . I only know a little (if not nothing) about category theory. When learning general topology, we constructed product topology and quotient topology with universal product, and that's the most I know about these constructions. So my question is, when we create a new object based on two or more objects in the same category, does the isomorphism carry over? For instance if we make object $(AB)$ from $A$ and $B$ , and $(CD)$ from $C$ and $D$ , when can we conclude that $A \cong C$ , $B \cong D$ implies that $(AB) \cong (CD)$ , or vice versa?","I'm finishing a course on basic abstract algebra, which covers groups, rings, modules, and finite group representations. However, up to this point, I am not very sure about the concept of isomorphism. I know there are examples where given a group and two normal subgroups, and , where , but . For instance, see here . However, for (external) direct sum, this does not seem to be a problem, for groups , if , , . I only know a little (if not nothing) about category theory. When learning general topology, we constructed product topology and quotient topology with universal product, and that's the most I know about these constructions. So my question is, when we create a new object based on two or more objects in the same category, does the isomorphism carry over? For instance if we make object from and , and from and , when can we conclude that , implies that , or vice versa?","G H K H \cong K \frac{G}{H} \not \cong \frac{G}{K} A,B,C,D A \cong B C \cong D A \oplus B \cong C \oplus D (AB) A B (CD) C D A \cong C B \cong D (AB) \cong (CD)","['abstract-algebra', 'general-topology', 'category-theory', 'quotient-spaces', 'quotient-group']"
46,Constructing a field in which polynomial has root,Constructing a field in which polynomial has root,,"The problem Say we have a field $F$ and an irreducible polynomial $g \in F[x]$ of degree $\geq 1$. Let $(g)$ denote the (maximal) ideal generated by the $g$ in $F[x]$. Then define the field extension $F_1 = F[x]/(g)$ of $F$. Then $g$ has a root $\alpha$ in $F_1$, being $x + (g)$. My question(s) Why is $F_1$ a field extension of $F$? I don't see how the field $F$ can be contained in a quotient ring. I do know that $F_1$ is a field because $(g)$ is a maximal ideal in $F[x]$ so no need to explain this. Why is $\alpha$ a root of $g$? Perhaps because $\pi(g(x)) = g(\pi(x))$ with $\pi$ the surjection from $F[x]$ to $F_1$? This would only work in my eyes if $\pi$ 'fixes' constants but it doesn't to that or I don't understand why it should.","The problem Say we have a field $F$ and an irreducible polynomial $g \in F[x]$ of degree $\geq 1$. Let $(g)$ denote the (maximal) ideal generated by the $g$ in $F[x]$. Then define the field extension $F_1 = F[x]/(g)$ of $F$. Then $g$ has a root $\alpha$ in $F_1$, being $x + (g)$. My question(s) Why is $F_1$ a field extension of $F$? I don't see how the field $F$ can be contained in a quotient ring. I do know that $F_1$ is a field because $(g)$ is a maximal ideal in $F[x]$ so no need to explain this. Why is $\alpha$ a root of $g$? Perhaps because $\pi(g(x)) = g(\pi(x))$ with $\pi$ the surjection from $F[x]$ to $F_1$? This would only work in my eyes if $\pi$ 'fixes' constants but it doesn't to that or I don't understand why it should.",,"['abstract-algebra', 'field-theory', 'roots', 'extension-field']"
47,If $K$ be an algebraic extension of $E$ and $E$ be an algebraic extension of $F$ then $K$ is an algebraic extension of $F$.,If  be an algebraic extension of  and  be an algebraic extension of  then  is an algebraic extension of .,K E E F K F,"Let $K$ be an algebraic extension of $E$ and $E$ be an algebraic extension of $F$ then $K$ is an algebraic extension of $F$ Proof- Let $a \in K$,then since $a$ is algebraic over $E$, so there exist an irreducible polynomial in $E[x]$ say $p(x)$ such that $p(a) = 0$. Let $p(x) = b_{0} + b_{1}x +... +b_{n}x^n$ where $b_{0},b_{1},...,b_{n} \in E$ We need to show that $a$ is in some finite extension of $F$ How do we construct such a finite extension. In the remaining proof it adds element by element to the field $F$ but I am not sure why are we adding the elements $b_{i}$, $0 \leq i \leq n$ in order to show the existence of such a finite extension?. Any help is great!","Let $K$ be an algebraic extension of $E$ and $E$ be an algebraic extension of $F$ then $K$ is an algebraic extension of $F$ Proof- Let $a \in K$,then since $a$ is algebraic over $E$, so there exist an irreducible polynomial in $E[x]$ say $p(x)$ such that $p(a) = 0$. Let $p(x) = b_{0} + b_{1}x +... +b_{n}x^n$ where $b_{0},b_{1},...,b_{n} \in E$ We need to show that $a$ is in some finite extension of $F$ How do we construct such a finite extension. In the remaining proof it adds element by element to the field $F$ but I am not sure why are we adding the elements $b_{i}$, $0 \leq i \leq n$ in order to show the existence of such a finite extension?. Any help is great!",,"['abstract-algebra', 'extension-field']"
48,Ideal in a ring of continuous functions,Ideal in a ring of continuous functions,,"Let $R$ be the ring of all continuous real valued functions on the unit interval $[0,1]$ (with pointwise operations), and let $I$ be a proper ideal of $R$. Show that there exists $λ\in [0,1]$ such that   $$I\subseteq M_{λ}= \left\{f \in R\mid f(λ)=0\right\}.$$ Can't really get anywhere with this one. Appreciate the help.","Let $R$ be the ring of all continuous real valued functions on the unit interval $[0,1]$ (with pointwise operations), and let $I$ be a proper ideal of $R$. Show that there exists $λ\in [0,1]$ such that   $$I\subseteq M_{λ}= \left\{f \in R\mid f(λ)=0\right\}.$$ Can't really get anywhere with this one. Appreciate the help.",,"['abstract-algebra', 'ring-theory', 'continuity', 'ideals', 'maximal-and-prime-ideals']"
49,"If $p\in R[X_1,\dots,X_n]$ is irreducible, is it still irreducible in $R[X_1,\dots,X_n,\dots,X_N]$?","If  is irreducible, is it still irreducible in ?","p\in R[X_1,\dots,X_n] R[X_1,\dots,X_n,\dots,X_N]","It is a known fact that if $R$ is a UFD, then $R[X_1,X_2,\dots]$ is also a UFD, but there is a subtlety that is making me uncomfortable. The standard approach essentially goes something along the lines of...let $f$ be a polynomial, so it only involves finitely many variables, say up to $X_1,\dots,X_n$. Then since $R[X_1,\dots,X_n]$ is a UFD, $f$ has a factorization into irreducibles. Then $f$ cannot have a factorization involving indeterminates $X_N$ not in $R[X_1,\dots,X_n]$. If it did, then $f$ would have two factorizations in the UFD $R[X_1,\dots,X_n,\dots, X_N]$, a contradiction. This seems to assume that the prime factorization in $R[X_1,\dots,X_n]$ is still a prime factorization in $R[X_1,\dots,X_n,\dots,X_N]$. But how can you see that irreducibles in $R[X_1,\dots,X_n]$ are still irreducibles in $R[X_1,\dots,X_m]$ for $m>n$? This does not seem obvious. Let $R_k=R[X_1,\dots,X_k]$. The explanantion I found is this: Suppose $p\in R[X_1,\dots,X_n]$ is irreducible in $R_n$. Suppose $p=ab$ for $a,b\in R_m$. Evaluating $X_1,\dots,X_n$ at $1$, you get  $$ \bar{p}=\overline{ab}\in R[X_{n+1},\dots,X_m] $$ But $\bar{p}\in R$, which implies that $a$ and $b$ do not involve any variables $X_{n+1},\dots,X_m$. So $a,b\in R_n$, and thus one is a unit, hence a unit in $R_m$. The part I don't follow is how evaluation at $1$, implies $a$ and $b$ do not have indeterminates other than $X_1,\dots,X_n$. Isn't it possible that some of the higher indexed indeterminates disappear when you evaluate? Suppose for instance $p\in R_1$, and $a\in R_2$ is $a=-X_1X_2+X_2$. Then evaluting at $1$ gives $\bar{a}=0$ so we may not get the desired contradiction since $\overline{ab}=0\in R$?","It is a known fact that if $R$ is a UFD, then $R[X_1,X_2,\dots]$ is also a UFD, but there is a subtlety that is making me uncomfortable. The standard approach essentially goes something along the lines of...let $f$ be a polynomial, so it only involves finitely many variables, say up to $X_1,\dots,X_n$. Then since $R[X_1,\dots,X_n]$ is a UFD, $f$ has a factorization into irreducibles. Then $f$ cannot have a factorization involving indeterminates $X_N$ not in $R[X_1,\dots,X_n]$. If it did, then $f$ would have two factorizations in the UFD $R[X_1,\dots,X_n,\dots, X_N]$, a contradiction. This seems to assume that the prime factorization in $R[X_1,\dots,X_n]$ is still a prime factorization in $R[X_1,\dots,X_n,\dots,X_N]$. But how can you see that irreducibles in $R[X_1,\dots,X_n]$ are still irreducibles in $R[X_1,\dots,X_m]$ for $m>n$? This does not seem obvious. Let $R_k=R[X_1,\dots,X_k]$. The explanantion I found is this: Suppose $p\in R[X_1,\dots,X_n]$ is irreducible in $R_n$. Suppose $p=ab$ for $a,b\in R_m$. Evaluating $X_1,\dots,X_n$ at $1$, you get  $$ \bar{p}=\overline{ab}\in R[X_{n+1},\dots,X_m] $$ But $\bar{p}\in R$, which implies that $a$ and $b$ do not involve any variables $X_{n+1},\dots,X_m$. So $a,b\in R_n$, and thus one is a unit, hence a unit in $R_m$. The part I don't follow is how evaluation at $1$, implies $a$ and $b$ do not have indeterminates other than $X_1,\dots,X_n$. Isn't it possible that some of the higher indexed indeterminates disappear when you evaluate? Suppose for instance $p\in R_1$, and $a\in R_2$ is $a=-X_1X_2+X_2$. Then evaluting at $1$ gives $\bar{a}=0$ so we may not get the desired contradiction since $\overline{ab}=0\in R$?",,"['abstract-algebra', 'ring-theory', 'commutative-algebra', 'irreducible-polynomials']"
50,Set of homomorphisms form a group?,Set of homomorphisms form a group?,,"Given vector spaces $V, W$ over field $F$, the set of all linear maps $V \to W$ forms a vector space over $F$ under pointwise addition. Is there an analogue for groups?  Can the set of all homomorphisms from groups $G \to K$ be given a group structure?","Given vector spaces $V, W$ over field $F$, the set of all linear maps $V \to W$ forms a vector space over $F$ under pointwise addition. Is there an analogue for groups?  Can the set of all homomorphisms from groups $G \to K$ be given a group structure?",,"['abstract-algebra', 'group-theory']"
51,Why do mathematicians use this symbol $\mathbb R$ to represent the real numbers?,Why do mathematicians use this symbol  to represent the real numbers?,\mathbb R,"So, I'm wondering why mathematicians use the symbols like $\mathbb R$, $\mathbb Z$, etc... to represent the real and integers number for instance. I thought that's because these sets are a kind of special ones. The problem is I've already seen letters like $\mathbb K$ to represent a field in some books just to say an example. So, someone knows why we use these kind of symbols? Thanks","So, I'm wondering why mathematicians use the symbols like $\mathbb R$, $\mathbb Z$, etc... to represent the real and integers number for instance. I thought that's because these sets are a kind of special ones. The problem is I've already seen letters like $\mathbb K$ to represent a field in some books just to say an example. So, someone knows why we use these kind of symbols? Thanks",,"['abstract-algebra', 'soft-question', 'notation']"
52,"If $K$ is an extension field of $\mathbb{Q}$ such that $[K:\mathbb{Q}]=2$, prove that $K=\mathbb{Q}(\sqrt{d})$ for some square free integer $d$","If  is an extension field of  such that , prove that  for some square free integer",K \mathbb{Q} [K:\mathbb{Q}]=2 K=\mathbb{Q}(\sqrt{d}) d,"I think I have the later parts of this proof worked out pretty well but what's really stumping me is how to go from knowing $[K:\mathbb{Q}]=2$ to knowing that $K = \mathbb{Q}[x]/a_2x^2 + a_1x + a_0$. I mean all I know from $[K:\mathbb{Q}]=2$ is that every element of $K$ can be written in the form $bk_1 + ck_2$ for $b,c\in \mathbb{Q}$.  As far as I can tell I don't yet have any theorems at my disposal that say if $[K:\mathbb{Q}]$ is finite than $K$ must be algebraic over $\mathbb{Q}$, or anything like that.  How do I go from this premise about $K$ as a 2-dimensional vector space over $\mathbb{Q}$ to knowing something about elements of $K$ as roots of polynomials in $\mathbb{Q}[x]$?  Thanks.","I think I have the later parts of this proof worked out pretty well but what's really stumping me is how to go from knowing $[K:\mathbb{Q}]=2$ to knowing that $K = \mathbb{Q}[x]/a_2x^2 + a_1x + a_0$. I mean all I know from $[K:\mathbb{Q}]=2$ is that every element of $K$ can be written in the form $bk_1 + ck_2$ for $b,c\in \mathbb{Q}$.  As far as I can tell I don't yet have any theorems at my disposal that say if $[K:\mathbb{Q}]$ is finite than $K$ must be algebraic over $\mathbb{Q}$, or anything like that.  How do I go from this premise about $K$ as a 2-dimensional vector space over $\mathbb{Q}$ to knowing something about elements of $K$ as roots of polynomials in $\mathbb{Q}[x]$?  Thanks.",,"['abstract-algebra', 'field-theory']"
53,Group of Order 105 Having Normal Sylow 5/7 Subgroups,Group of Order 105 Having Normal Sylow 5/7 Subgroups,,"I am trying to prove that, given $|G|=105$, the G has a normal Sylow 5 subgroup and a normal Sylow 7 subgroup. I think the thing that is confusing me is the word ""and"".  It would seem that there can't be both a normal subgroup of order 5 and 7, i think.  If there were, since their intersection is just $e_G$, then this ties up the remaining 94 elements in a bunch of Sylow 3 subgroups.  Again, because they each contain $e_G$, there needs to be 47 Sylow 3 subgroups, which is impossible by the conditions on the Sylow theorems; So where is my thinking off?  Does it really mean ""or""? There has to be at least one normal 5 or 7, since if neither were normal, because $n_5=21$ and $n_7=15$, and since $4(21)+6(15)>105$, we have a contradiction with the number of elements.  So where is my logic flawed?","I am trying to prove that, given $|G|=105$, the G has a normal Sylow 5 subgroup and a normal Sylow 7 subgroup. I think the thing that is confusing me is the word ""and"".  It would seem that there can't be both a normal subgroup of order 5 and 7, i think.  If there were, since their intersection is just $e_G$, then this ties up the remaining 94 elements in a bunch of Sylow 3 subgroups.  Again, because they each contain $e_G$, there needs to be 47 Sylow 3 subgroups, which is impossible by the conditions on the Sylow theorems; So where is my thinking off?  Does it really mean ""or""? There has to be at least one normal 5 or 7, since if neither were normal, because $n_5=21$ and $n_7=15$, and since $4(21)+6(15)>105$, we have a contradiction with the number of elements.  So where is my logic flawed?",,"['abstract-algebra', 'group-theory', 'sylow-theory']"
54,"$\mathbb Z^n/\langle (a,...,a) \rangle \cong \mathbb Z^{n-1} \oplus \mathbb Z/\langle a \rangle$",,"\mathbb Z^n/\langle (a,...,a) \rangle \cong \mathbb Z^{n-1} \oplus \mathbb Z/\langle a \rangle","I am trying to show the isomorphism $$\mathbb Z^n/\langle (a,...,a) \rangle \cong \mathbb Z^{n-1} \oplus \mathbb Z/\langle a \rangle.$$ I've tried to define $\psi:\mathbb Z^n \to \mathbb Z^{n-1} \oplus \mathbb Z/\langle a \rangle$ an epimorphism with $\ker(\psi)=\langle (a,...,a) \rangle$ so to apply the first isomorphism theorem, but I couldn't come up with an appropiate morphism. Any hints or suggestions would be greatly appreciated.","I am trying to show the isomorphism $$\mathbb Z^n/\langle (a,...,a) \rangle \cong \mathbb Z^{n-1} \oplus \mathbb Z/\langle a \rangle.$$ I've tried to define $\psi:\mathbb Z^n \to \mathbb Z^{n-1} \oplus \mathbb Z/\langle a \rangle$ an epimorphism with $\ker(\psi)=\langle (a,...,a) \rangle$ so to apply the first isomorphism theorem, but I couldn't come up with an appropiate morphism. Any hints or suggestions would be greatly appreciated.",,"['abstract-algebra', 'group-theory']"
55,Group $G$ of order $p^2$: $\;G\cong \mathbb Z_{p^2}$ or $G\cong \mathbb Z_p \times \mathbb Z_p$ [closed],Group  of order :  or  [closed],G p^2 \;G\cong \mathbb Z_{p^2} G\cong \mathbb Z_p \times \mathbb Z_p,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question If the order of $G$ is $p^2$ then how do I show that $G$ is isomorphic to $\mathbb Z_{p^2}$ or $\mathbb Z_p\times\mathbb Z_p$.","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question If the order of $G$ is $p^2$ then how do I show that $G$ is isomorphic to $\mathbb Z_{p^2}$ or $\mathbb Z_p\times\mathbb Z_p$.",,"['abstract-algebra', 'group-theory', 'finite-groups']"
56,Let $K$ be a subfield of $\mathbb{C}$ not contained in $\mathbb{R}$. Show that $K$ is dense in $\mathbb{C}$.,Let  be a subfield of  not contained in . Show that  is dense in .,K \mathbb{C} \mathbb{R} K \mathbb{C},Let $K$ be a subfield of $\mathbb{C}$ not contained in $\mathbb{R}$. Show that $K$ is dense in $\mathbb{C}$. completely stuck on it. can I get some help please.,Let $K$ be a subfield of $\mathbb{C}$ not contained in $\mathbb{R}$. Show that $K$ is dense in $\mathbb{C}$. completely stuck on it. can I get some help please.,,"['abstract-algebra', 'general-topology', 'field-theory']"
57,The free group $F_2$ contains $F_k$,The free group  contains,F_2 F_k,"I want to prove the following: the free group $F_2$ contains the free group $F_k$ for every $k \geq 3$. I am wondering whether the following line of reasoning is correct or not: Suppose that $\lbrace a, b \rbrace$ is a free generating set of $F_2$. Define $S := \lbrace aba^{-1}, \cdots, ab^{k}a^{-1} \rbrace$ and let $F(S)$ be the free group with free generating set $S$. Then $F(S)$ is a free group on $k$ generators and since every reduced word of $F(S)$ collapses to a reduced word of $F(a, b)$ (for example $(aba^{-1})(ab^4a^{-1}) = ab^5a^{-1}$) it follows that $F(S) \subseteq F(a, b)$.","I want to prove the following: the free group $F_2$ contains the free group $F_k$ for every $k \geq 3$. I am wondering whether the following line of reasoning is correct or not: Suppose that $\lbrace a, b \rbrace$ is a free generating set of $F_2$. Define $S := \lbrace aba^{-1}, \cdots, ab^{k}a^{-1} \rbrace$ and let $F(S)$ be the free group with free generating set $S$. Then $F(S)$ is a free group on $k$ generators and since every reduced word of $F(S)$ collapses to a reduced word of $F(a, b)$ (for example $(aba^{-1})(ab^4a^{-1}) = ab^5a^{-1}$) it follows that $F(S) \subseteq F(a, b)$.",,"['abstract-algebra', 'group-theory', 'free-groups']"
58,Using Zorn's lemma show that $\mathbb R^+$ is the disjoint union of two sets closed under addition.,Using Zorn's lemma show that  is the disjoint union of two sets closed under addition.,\mathbb R^+,"Let $\Bbb R^+$ be the set of positive real numbers. Use Zorn's Lemma to show that $\Bbb R^+$ is the union of two disjoint, non-empty subsets, each closed under addition.","Let $\Bbb R^+$ be the set of positive real numbers. Use Zorn's Lemma to show that $\Bbb R^+$ is the union of two disjoint, non-empty subsets, each closed under addition.",,"['abstract-algebra', 'set-theory', 'axiom-of-choice', 'real-numbers']"
59,"If F is a field, then $F[x,y]$ is a Principal Ideal Domain?","If F is a field, then  is a Principal Ideal Domain?","F[x,y]","Let $F$ be a field, and $F[x,y]$ be a ring of polynomials in two variables. Is $F[x,y]$ a Principal Ideal Domain? Also show that $F[x,y]/(y^2-x)$ and $F[x,y]/(y^2-x^2)$ are not isomorphic for any field $F$.","Let $F$ be a field, and $F[x,y]$ be a ring of polynomials in two variables. Is $F[x,y]$ a Principal Ideal Domain? Also show that $F[x,y]/(y^2-x)$ and $F[x,y]/(y^2-x^2)$ are not isomorphic for any field $F$.",,"['abstract-algebra', 'principal-ideal-domains']"
60,How to rationalize the denominator $\frac{1}{1 + \sqrt[3]{5} - \sqrt[3]{25}}$,How to rationalize the denominator,\frac{1}{1 + \sqrt[3]{5} - \sqrt[3]{25}},"This is a review problem for an introductory Galois theory course. Rationalize the denominator $\frac{1}{1 + \sqrt[3]{5} - \sqrt[3]{25}}$ . There could be many ways to do this, but it's implicit that we use field theory for this problem. I tried looking at the solutions to this question , this question and this question , but they haven't helped me so far. What seems clear is to replace $x = \sqrt[3]{5}$ and then our expression becomes $\frac{1}{1+x-x^2}$ . Now, since $x^3-5$ is the minimal polynomial of $\sqrt[3]{5}$ in $\mathbb Q[x]$ , I think I want to find the inverse of $1+x-x^2$ in the quotient ring $\mathbb Q[x]/(x^3-5)$ , but I'm not sure how. Any hints or suggestions would be appreciated.","This is a review problem for an introductory Galois theory course. Rationalize the denominator . There could be many ways to do this, but it's implicit that we use field theory for this problem. I tried looking at the solutions to this question , this question and this question , but they haven't helped me so far. What seems clear is to replace and then our expression becomes . Now, since is the minimal polynomial of in , I think I want to find the inverse of in the quotient ring , but I'm not sure how. Any hints or suggestions would be appreciated.",\frac{1}{1 + \sqrt[3]{5} - \sqrt[3]{25}} x = \sqrt[3]{5} \frac{1}{1+x-x^2} x^3-5 \sqrt[3]{5} \mathbb Q[x] 1+x-x^2 \mathbb Q[x]/(x^3-5),"['abstract-algebra', 'polynomials', 'galois-theory', 'extension-field', 'radicals']"
61,"Why does a bijection from a set to itself deserve the name ""Permutation""?","Why does a bijection from a set to itself deserve the name ""Permutation""?",,"Sorry for the long text; this is a nebulous question that has always been in the back of my mind, and I've had trouble putting into a short form. ""Natural"" Definition If someone on the street hears the word ""permutation,"" I think they will naturally assume that a permutation: Involves rearranging objects The order in which the objects are written, before and after the permutation is performed, is of crucial importantce (it's really the essence of the permutation) I would naturally expect a permutation to be an instruction, or an action. For example, I would expect a permutation to look something like $$\sigma = \text{interchange the first two entries.}$$ Then, if we apply $\sigma$ to $(A, B, C)$ we get $(B, C, A);$ if we apply it to $(4, 6, 9)$ we get $(6, 4, 9).$ To me this is a very satisfying (informal) definition of a permutation, because it captures exactly what many people (or at least me) would think a permutation ""should be."" Another way to define ""permutation"" (to me, less satisfactory than the previous, but still more satisfactory than the official definition) could be to just say that ""the 3-tuple $(B, A, C)$ is a permutation of $(A, B, C).$ "" (In fact, I think this is the definition used in elementary Statistics books.) Percieved Weaknesses of the Official Definition It makes little sense to ""permute"" your set of objects. If you have a set of objects $\{4, 6, 8 \},$ and while you are not in the room someone applies a permutation to your set, you will never know; the output of your permutation is still $\{4, 6, 8 \}.$ Even if they only apply the permutation to a subset, you only might be able to tell. Permutations seem to have nothing to do with the order that your objects are in, either before or after doing the permutation. This, like I mentioned above, seems to violate the whole point of a permutation I call these weaknesses because they seem to violate the ""person on the street"" understanding of a permutation, and I know that generally mathematicians try really hard to not distort the meaning of common English words too much. My Question Is there really such a big disconnect between the ""Natural"" and Official definitions of permutations? Even if there is not, and there is a way to tediously link the natural definition with the official definition (which I'm sure there is), why does the Official definition deserve to be called a permutation more than the natural one? Is there a name for the Natural definition? Thanks.","Sorry for the long text; this is a nebulous question that has always been in the back of my mind, and I've had trouble putting into a short form. ""Natural"" Definition If someone on the street hears the word ""permutation,"" I think they will naturally assume that a permutation: Involves rearranging objects The order in which the objects are written, before and after the permutation is performed, is of crucial importantce (it's really the essence of the permutation) I would naturally expect a permutation to be an instruction, or an action. For example, I would expect a permutation to look something like Then, if we apply to we get if we apply it to we get To me this is a very satisfying (informal) definition of a permutation, because it captures exactly what many people (or at least me) would think a permutation ""should be."" Another way to define ""permutation"" (to me, less satisfactory than the previous, but still more satisfactory than the official definition) could be to just say that ""the 3-tuple is a permutation of "" (In fact, I think this is the definition used in elementary Statistics books.) Percieved Weaknesses of the Official Definition It makes little sense to ""permute"" your set of objects. If you have a set of objects and while you are not in the room someone applies a permutation to your set, you will never know; the output of your permutation is still Even if they only apply the permutation to a subset, you only might be able to tell. Permutations seem to have nothing to do with the order that your objects are in, either before or after doing the permutation. This, like I mentioned above, seems to violate the whole point of a permutation I call these weaknesses because they seem to violate the ""person on the street"" understanding of a permutation, and I know that generally mathematicians try really hard to not distort the meaning of common English words too much. My Question Is there really such a big disconnect between the ""Natural"" and Official definitions of permutations? Even if there is not, and there is a way to tediously link the natural definition with the official definition (which I'm sure there is), why does the Official definition deserve to be called a permutation more than the natural one? Is there a name for the Natural definition? Thanks.","\sigma = \text{interchange the first two entries.} \sigma (A, B, C) (B, C, A); (4, 6, 9) (6, 4, 9). (B, A, C) (A, B, C). \{4, 6, 8 \}, \{4, 6, 8 \}.","['abstract-algebra', 'combinatorics', 'group-theory', 'soft-question', 'math-history']"
62,Proving a group is Abelian,Proving a group is Abelian,,"Let $G$ be a group with the property that in every subset of 4 distinct elements, there exists at least a pair of commuting elements. Show that G is Abelian. I have thought so far that if G isn't abelian then if x,y dont commute and given subset of index 3 then the subset $\{x,y,xy\} \implies xy = yx$. Can I find something similar for the 4-element case?","Let $G$ be a group with the property that in every subset of 4 distinct elements, there exists at least a pair of commuting elements. Show that G is Abelian. I have thought so far that if G isn't abelian then if x,y dont commute and given subset of index 3 then the subset $\{x,y,xy\} \implies xy = yx$. Can I find something similar for the 4-element case?",,['abstract-algebra']
63,How do you square an ideal?,How do you square an ideal?,,"For some of you, this question is going to seem extremely basic. I think I understand what an ideal is. Such as $\langle 2, 1 + \sqrt{-5} \rangle$, it consists of all numbers in this ring of the form $2a + (1 + \sqrt{-5})b$. But then what is $\langle 2, 1 + \sqrt{-5} \rangle^2$? My first thought was $\langle 4, -4 + 2 \sqrt{-5} \rangle$, but that seems wrong somehow. I also had something in the back of my mind saying $\langle 2 \rangle$, but I'm not sure about that one either. Then I thought about trying to figure out $\langle 2, 1 + \sqrt{-5} \rangle \langle 2, 1 + \sqrt{-5} \rangle$ when I realized I don't actually understand how to multiply ideals to begin with. I'm only using $\langle 2, 1 + \sqrt{-5} \rangle$ as an example (though that does draw in one question identified as similar that looks much more relevant than all the questions identified as ""Questions that may already have your answer""). In a principal ideal domain, would it be correct to think that $\langle a \rangle \langle b \rangle = \langle ab \rangle$? Any help would be much appreciated.","For some of you, this question is going to seem extremely basic. I think I understand what an ideal is. Such as $\langle 2, 1 + \sqrt{-5} \rangle$, it consists of all numbers in this ring of the form $2a + (1 + \sqrt{-5})b$. But then what is $\langle 2, 1 + \sqrt{-5} \rangle^2$? My first thought was $\langle 4, -4 + 2 \sqrt{-5} \rangle$, but that seems wrong somehow. I also had something in the back of my mind saying $\langle 2 \rangle$, but I'm not sure about that one either. Then I thought about trying to figure out $\langle 2, 1 + \sqrt{-5} \rangle \langle 2, 1 + \sqrt{-5} \rangle$ when I realized I don't actually understand how to multiply ideals to begin with. I'm only using $\langle 2, 1 + \sqrt{-5} \rangle$ as an example (though that does draw in one question identified as similar that looks much more relevant than all the questions identified as ""Questions that may already have your answer""). In a principal ideal domain, would it be correct to think that $\langle a \rangle \langle b \rangle = \langle ab \rangle$? Any help would be much appreciated.",,"['abstract-algebra', 'ring-theory', 'ideals']"
64,Finding inverse in non-commutative ring,Finding inverse in non-commutative ring,,"Let $a,b,c,x$ be elements of a unital non-commutative ring. Assume $c$ is an inverse of $1-ab$: $$ c(1-ab) = 1$$ How can I find an inverse for $1-ba$? What I tried: Denote the unknown by $x$. Then $x (1-ba) = 1 = x - xba$. I tried to replace $1$ with $c(1-ab)$ but it didn't help because I cannot solve for $x$. I also tried to subtract $x (1-ba) $ from $ c(1-ab)$ but couldn't solve for $x$ either. Any suggestions?","Let $a,b,c,x$ be elements of a unital non-commutative ring. Assume $c$ is an inverse of $1-ab$: $$ c(1-ab) = 1$$ How can I find an inverse for $1-ba$? What I tried: Denote the unknown by $x$. Then $x (1-ba) = 1 = x - xba$. I tried to replace $1$ with $c(1-ab)$ but it didn't help because I cannot solve for $x$. I also tried to subtract $x (1-ba) $ from $ c(1-ab)$ but couldn't solve for $x$ either. Any suggestions?",,"['abstract-algebra', 'ring-theory']"
65,Proving that a ring is not a Principal Ideal Domain,Proving that a ring is not a Principal Ideal Domain,,"This is my first question on StackExchange. I'm taking a second semester course of Abstract Algebra. I have a general understanding of Principal Ideal Domains, but I am a bit confused on proving that a specific ring is a PID. Could I get an example of showing that a specific ring is a PID? Or possibly an example of a ring that is not a PID?","This is my first question on StackExchange. I'm taking a second semester course of Abstract Algebra. I have a general understanding of Principal Ideal Domains, but I am a bit confused on proving that a specific ring is a PID. Could I get an example of showing that a specific ring is a PID? Or possibly an example of a ring that is not a PID?",,"['abstract-algebra', 'ring-theory', 'examples-counterexamples', 'principal-ideal-domains', 'integral-domain']"
66,A nontrivial subgroup of $G$ contained in every other nontrivial subgroup.,A nontrivial subgroup of  contained in every other nontrivial subgroup.,G,"This question is from a collection of past master's exams. Let $G$ be a group with a subgroup $H$ as described in the title. I'd like to show that $H$ is in the center of $G$. My intuition is to choose some element $x\in H$ (and thus in every nontrivial subgroup $K$ of $G$) and then apply the counting formula; i.e. the order of $G$ is the product of the order of the centralizer of $x$ with that of its conjugacy class. I feel like this, together with the class equation, should tell me everything I need to know. It's been awhile since I've done a problem like this, so any help would be appreciated.","This question is from a collection of past master's exams. Let $G$ be a group with a subgroup $H$ as described in the title. I'd like to show that $H$ is in the center of $G$. My intuition is to choose some element $x\in H$ (and thus in every nontrivial subgroup $K$ of $G$) and then apply the counting formula; i.e. the order of $G$ is the product of the order of the centralizer of $x$ with that of its conjugacy class. I feel like this, together with the class equation, should tell me everything I need to know. It's been awhile since I've done a problem like this, so any help would be appreciated.",,['abstract-algebra']
67,Splitting field of an irreducible polynomial over $\mathbb{Q}$,Splitting field of an irreducible polynomial over,\mathbb{Q},"Let $P(x)$ be an irreducible polynomial over $\mathbb{Q}$ ; I am interested its splitting field. I know that $\mathbb{Q}[x]/\langle P(x)\rangle $ have one of the roots of $P(x)$ , and that regardless of what root $\xi$ we take the field $\mathbb{Q}(\xi)$ obtained by adjoining $\xi$ to $\mathbb{Q}$ is isomorphic to $\mathbb{Q}[x]/\langle P(x)\rangle$ I think think that if two field are isomorphic then a polynomial is irreducible over one of them implies it's irreducible over the second (is this true ? is it an iff claim ?) From here I think that adding one root implies we added them all and so we know the splitting field of $P(x)$ . Are some of my claims wrong ? (why ?)","Let be an irreducible polynomial over ; I am interested its splitting field. I know that have one of the roots of , and that regardless of what root we take the field obtained by adjoining to is isomorphic to I think think that if two field are isomorphic then a polynomial is irreducible over one of them implies it's irreducible over the second (is this true ? is it an iff claim ?) From here I think that adding one root implies we added them all and so we know the splitting field of . Are some of my claims wrong ? (why ?)",P(x) \mathbb{Q} \mathbb{Q}[x]/\langle P(x)\rangle  P(x) \xi \mathbb{Q}(\xi) \xi \mathbb{Q} \mathbb{Q}[x]/\langle P(x)\rangle P(x),"['abstract-algebra', 'field-theory']"
68,Can you construct a field over every set $M$?,Can you construct a field over every set ?,M,"I know there are finite fields like $\mathbb F_2$, $\mathbb F_4$ or the $\mathbb Z/n\mathbb Z$ for prime $n$ with modulo operations. For other special $n$, I've seen fields $\mathbb F_n$ with $n$ elements being constructed. And of course there are the usual infinite fields (take $\mathbb Q$ and so on). So I wonder: Let $M$ be an arbitrary set that contains at least two elements. Can you always find operations $+ : M\times M \to M$ and $\cdot : M \times M \to M$, such that $(M, +, \cdot)$ is a field?","I know there are finite fields like $\mathbb F_2$, $\mathbb F_4$ or the $\mathbb Z/n\mathbb Z$ for prime $n$ with modulo operations. For other special $n$, I've seen fields $\mathbb F_n$ with $n$ elements being constructed. And of course there are the usual infinite fields (take $\mathbb Q$ and so on). So I wonder: Let $M$ be an arbitrary set that contains at least two elements. Can you always find operations $+ : M\times M \to M$ and $\cdot : M \times M \to M$, such that $(M, +, \cdot)$ is a field?",,"['abstract-algebra', 'field-theory']"
69,Is a field (ring) an algebra over itself?,Is a field (ring) an algebra over itself?,,"I was wondering if a field is an algebra over itself ( http://en.wikipedia.org/wiki/Algebra_over_a_field )? Also is a ring an algebra over itself ( http://en.wikipedia.org/wiki/Algebra_(ring_theory )? If not, does the ring require to be commutative? Thanks and regards!","I was wondering if a field is an algebra over itself ( http://en.wikipedia.org/wiki/Algebra_over_a_field )? Also is a ring an algebra over itself ( http://en.wikipedia.org/wiki/Algebra_(ring_theory )? If not, does the ring require to be commutative? Thanks and regards!",,['abstract-algebra']
70,Prove every group of order less or equal to five is abelian [closed],Prove every group of order less or equal to five is abelian [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question Is it possible to prove that every group of order less or equal to five is abelian? We know that groups of prime order are cyclic and therefore commutative. As the number $4$ is the only composite number $\le5$, it basically remains to show this for groups of order four.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question Is it possible to prove that every group of order less or equal to five is abelian? We know that groups of prime order are cyclic and therefore commutative. As the number $4$ is the only composite number $\le5$, it basically remains to show this for groups of order four.",,"['abstract-algebra', 'group-theory', 'abelian-groups', 'normal-subgroups']"
71,General approach for finding how many group homomorphisms are there,General approach for finding how many group homomorphisms are there,,"So I've asked this type of questions for more than once, and still I don't get the method(s) I've been presented with. What's the general recommended method for finding how many homomorphisms are there, and finding them? I would probably understand better through an example: How many homomorphisms are there from $S_3$ to $\mathbb Z_2 \times \mathbb Z_2$. I would gladly appreciate full solutions. You have my full gratitude for any sort of assistance, comment, insight or info you can provide.","So I've asked this type of questions for more than once, and still I don't get the method(s) I've been presented with. What's the general recommended method for finding how many homomorphisms are there, and finding them? I would probably understand better through an example: How many homomorphisms are there from $S_3$ to $\mathbb Z_2 \times \mathbb Z_2$. I would gladly appreciate full solutions. You have my full gratitude for any sort of assistance, comment, insight or info you can provide.",,"['abstract-algebra', 'group-theory', 'finite-groups', 'permutations']"
72,Show $p(X)$ (over a field) is irreducible iff $p(X+a)$ is irreducible,Show  (over a field) is irreducible iff  is irreducible,p(X) p(X+a),"Let $A$ be a field and let $p(X)$ be a polynomial over $A$. Let $a\in A$. Want to show: $p(X)$ is irreducible if and only if $p(X+a)$ is irreducible. I suspect that I should use the substitution principle somehow , but that's as far as I've come. Completely stumped.","Let $A$ be a field and let $p(X)$ be a polynomial over $A$. Let $a\in A$. Want to show: $p(X)$ is irreducible if and only if $p(X+a)$ is irreducible. I suspect that I should use the substitution principle somehow , but that's as far as I've come. Completely stumped.",,"['abstract-algebra', 'irreducible-polynomials']"
73,Minimal polynomial of $\alpha^2$ given the minimal polynomial of $\alpha$,Minimal polynomial of  given the minimal polynomial of,\alpha^2 \alpha,"Given that $\alpha$ is a root (in the field extension) of the irreducible polynomial $X^4+X^3-X+2\in\mathbb{Q}[X]$, I have to find the minimal polynomial of $\alpha^2$. I am thinking about this for a while, but I can't find it. I need some hints. Thank you.","Given that $\alpha$ is a root (in the field extension) of the irreducible polynomial $X^4+X^3-X+2\in\mathbb{Q}[X]$, I have to find the minimal polynomial of $\alpha^2$. I am thinking about this for a while, but I can't find it. I need some hints. Thank you.",,"['abstract-algebra', 'polynomials', 'ring-theory', 'minimal-polynomials']"
74,Ring of all continuous functions from reals into reals is not integral domain,Ring of all continuous functions from reals into reals is not integral domain,,Let $R$ be the ring of all continuous functions from the real numbers into the real numbers. Prove that $R$ is not an integral domain. I need help with this. I do not understand this at all and my book really doesn't give that much information.,Let $R$ be the ring of all continuous functions from the real numbers into the real numbers. Prove that $R$ is not an integral domain. I need help with this. I do not understand this at all and my book really doesn't give that much information.,,"['abstract-algebra', 'ring-theory']"
75,How many elements in a ring can be invertible?,How many elements in a ring can be invertible?,,"If $R$ is a finite ring (with identity) but not a field, let $U(R)$ be its group of units. Is $\frac{|U(R)|}{|R|}$ bounded away from $1$ over all such rings? It's been a while since I cracked an algebra book (well, other than trying to solve this recently), so if someone can answer this, I'd prefer not to stray too far from first principles within reason.","If $R$ is a finite ring (with identity) but not a field, let $U(R)$ be its group of units. Is $\frac{|U(R)|}{|R|}$ bounded away from $1$ over all such rings? It's been a while since I cracked an algebra book (well, other than trying to solve this recently), so if someone can answer this, I'd prefer not to stray too far from first principles within reason.",,"['abstract-algebra', 'ring-theory', 'finite-rings']"
76,Is the zero map (between two arbitrary rings) a ring homomorphism?,Is the zero map (between two arbitrary rings) a ring homomorphism?,,"I was looking at the definition under Wikipedia , which states that for arbitrary rings $R,S$, a ring homomorphism $f:R\to S$ must satisfy $f(1)=1.$ Here, I assume they mean $1$ as the multiplicative identity. Certainly then, this implies the zero map is not a ring homomorphism? This seems somehow intuitionally false; that is, we would want the zero map to be a ring homomorphism, as it is a group homomorphism between groups, a continuous function between reals, a smooth function between manifolds, etc. Could someone help explain why the zero map in the category of rings seems to be an exception to this pattern?","I was looking at the definition under Wikipedia , which states that for arbitrary rings $R,S$, a ring homomorphism $f:R\to S$ must satisfy $f(1)=1.$ Here, I assume they mean $1$ as the multiplicative identity. Certainly then, this implies the zero map is not a ring homomorphism? This seems somehow intuitionally false; that is, we would want the zero map to be a ring homomorphism, as it is a group homomorphism between groups, a continuous function between reals, a smooth function between manifolds, etc. Could someone help explain why the zero map in the category of rings seems to be an exception to this pattern?",,"['abstract-algebra', 'ring-theory']"
77,Is there another name for Goursat's Lemma on subgroups of a direct product of groups?,Is there another name for Goursat's Lemma on subgroups of a direct product of groups?,,"I'm having trouble finding a textbook that discusses Goursat's Lemma on subgroups of a direct product of groups. I've looked in several standard Algebra textbooks and I've only seen it in Serge Lang's ""Algebra"" as an exercise. Is it more commonly known by another name, or perhaps subsumed by a more commonly-taught theorem? Bonus points, but not required: if not, why isn't it included in these texts? The direct product is one of the standard first constructions and it seems like one of the first questions one would ask is ""what is known about the subgroups of $G \times H$ ?""","I'm having trouble finding a textbook that discusses Goursat's Lemma on subgroups of a direct product of groups. I've looked in several standard Algebra textbooks and I've only seen it in Serge Lang's ""Algebra"" as an exercise. Is it more commonly known by another name, or perhaps subsumed by a more commonly-taught theorem? Bonus points, but not required: if not, why isn't it included in these texts? The direct product is one of the standard first constructions and it seems like one of the first questions one would ask is ""what is known about the subgroups of ?""",G \times H,"['abstract-algebra', 'group-theory', 'reference-request', 'direct-product']"
78,Cancellation Law for Direct Sums - What is wrong with this argument?,Cancellation Law for Direct Sums - What is wrong with this argument?,,"Let $G$, $H$, and $K$ be abelian groups. Assume $G \oplus H \cong G \oplus K$. If each are finitely generated, then the structure theorem easily gives us that $H \cong K$. However, there are counterexamples in the general case, namely $H=\mathbb{Z}$, $K=\mathbb{Z} \oplus \mathbb{Z}$, and $G=\bigoplus_{i=1}^\infty\mathbb{Z}$. I am wondering what goes wrong with the following argument: Form the split short exact sequence $$0 \to G \xrightarrow{i} G \oplus H \xrightarrow{\pi} H \to 0$$ where $i$ and $\pi$ are the inclusion and projection, respectively. Then don't we immediately get from the first isomorphism theorem that $H \cong (G \oplus H)/G$, which would contradict the counterexample above? If we run this for the counterexample given, we get the sequence $$0 \to \bigoplus_{i=1}^\infty\mathbb{Z} \to \bigoplus_{i=1}^\infty\mathbb{Z} \to \mathbb{Z} \to 0$$ which seems to still be short exact, even though here $G \cong G \oplus H$. But of course here we can see directly that $(G \oplus H)/G \cong G/G$, which is trivial. So what went wrong? It seems to me to be something along these lines: In this case, the kernel of the projection is not the same as the original group, it is just, say, $0 \oplus \mathbb{Z} \oplus \mathbb{Z} \oplus \dots$, i.e. nontrivial from the second coordinate on, which just happens to be isomorphic to the original group. So if we form the other short exact sequence with $K$ in place of $H$, then the difference seems to be that we have two different projection maps with different (but isomorphic) kernels. But I'm not really sure how to explain this in the general case, if my reasoning is correct to begin with. Thanks in advance for any help!","Let $G$, $H$, and $K$ be abelian groups. Assume $G \oplus H \cong G \oplus K$. If each are finitely generated, then the structure theorem easily gives us that $H \cong K$. However, there are counterexamples in the general case, namely $H=\mathbb{Z}$, $K=\mathbb{Z} \oplus \mathbb{Z}$, and $G=\bigoplus_{i=1}^\infty\mathbb{Z}$. I am wondering what goes wrong with the following argument: Form the split short exact sequence $$0 \to G \xrightarrow{i} G \oplus H \xrightarrow{\pi} H \to 0$$ where $i$ and $\pi$ are the inclusion and projection, respectively. Then don't we immediately get from the first isomorphism theorem that $H \cong (G \oplus H)/G$, which would contradict the counterexample above? If we run this for the counterexample given, we get the sequence $$0 \to \bigoplus_{i=1}^\infty\mathbb{Z} \to \bigoplus_{i=1}^\infty\mathbb{Z} \to \mathbb{Z} \to 0$$ which seems to still be short exact, even though here $G \cong G \oplus H$. But of course here we can see directly that $(G \oplus H)/G \cong G/G$, which is trivial. So what went wrong? It seems to me to be something along these lines: In this case, the kernel of the projection is not the same as the original group, it is just, say, $0 \oplus \mathbb{Z} \oplus \mathbb{Z} \oplus \dots$, i.e. nontrivial from the second coordinate on, which just happens to be isomorphic to the original group. So if we form the other short exact sequence with $K$ in place of $H$, then the difference seems to be that we have two different projection maps with different (but isomorphic) kernels. But I'm not really sure how to explain this in the general case, if my reasoning is correct to begin with. Thanks in advance for any help!",,"['abstract-algebra', 'group-theory', 'abelian-groups', 'direct-sum']"
79,"If the intersection of ideals $I_{1},\ldots,I_{n}$ is contained in a prime ideal $P$, then one of them is contained in $P$","If the intersection of ideals  is contained in a prime ideal , then one of them is contained in","I_{1},\ldots,I_{n} P P","Let $A$ be a commutative ring and $I_{1},\ldots, I_{n}$ and $P$ ideals in $A$ with $P$ prime so that $\cap_{i=1} ^{n} I_{i} \subset P $. Show that there's an $i_0 \in \{1,...,n \}$ so that $I_{i_0} \subset P$. My first idea was to try to do induction on $n$. The case $n=1$ is trivial of course, but then I couldn't go farther since removing one of the ideals to consider the intersection of $n-1$ ideals means I can't guarantee that the intersection is inside $P$. I'm trying to prove the straightforward way now but can't really accomplish much. I tried assuming that every ideal has an element that's not in the rest and trying to work from there but again, seems to not get me anywhere. I'm just not sure how to approach the problem. Any help would be greatly appreciated.","Let $A$ be a commutative ring and $I_{1},\ldots, I_{n}$ and $P$ ideals in $A$ with $P$ prime so that $\cap_{i=1} ^{n} I_{i} \subset P $. Show that there's an $i_0 \in \{1,...,n \}$ so that $I_{i_0} \subset P$. My first idea was to try to do induction on $n$. The case $n=1$ is trivial of course, but then I couldn't go farther since removing one of the ideals to consider the intersection of $n-1$ ideals means I can't guarantee that the intersection is inside $P$. I'm trying to prove the straightforward way now but can't really accomplish much. I tried assuming that every ideal has an element that's not in the rest and trying to work from there but again, seems to not get me anywhere. I'm just not sure how to approach the problem. Any help would be greatly appreciated.",,"['abstract-algebra', 'ring-theory', 'commutative-algebra', 'ideals', 'maximal-and-prime-ideals']"
80,"If $a+\sqrt{b}$ is a root of a polynomial equation with integer coefficients, so is $a-\sqrt{b}$","If  is a root of a polynomial equation with integer coefficients, so is",a+\sqrt{b} a-\sqrt{b},"I tried to use the Briot-Ruffini method but it didn't work. The question I need help is: ""Prove that, if a polynomial equation with integer coefficients has the irrational number $a+\sqrt{b}$ as a root, with $a,b \in \mathbb{Z} $, $b$ a prime number, so is $a-\sqrt{b}$.""","I tried to use the Briot-Ruffini method but it didn't work. The question I need help is: ""Prove that, if a polynomial equation with integer coefficients has the irrational number $a+\sqrt{b}$ as a root, with $a,b \in \mathbb{Z} $, $b$ a prime number, so is $a-\sqrt{b}$.""",,['abstract-algebra']
81,When is nilradical not a prime ideal,When is nilradical not a prime ideal,,Atiyah gives this criterion for nilradical to be a prime ideal.Nilradical is the intersection of prime ideals.Is nilradical prime iff there is only one prime ideal? ie Intersection of distinct prime ideals can never be a prime ideal?,Atiyah gives this criterion for nilradical to be a prime ideal.Nilradical is the intersection of prime ideals.Is nilradical prime iff there is only one prime ideal? ie Intersection of distinct prime ideals can never be a prime ideal?,,"['abstract-algebra', 'ring-theory', 'commutative-algebra', 'ideals']"
82,Every nonidentity element in a free group $F$ has infinite order,Every nonidentity element in a free group  has infinite order,F,"I'm trying to prove that every nonidentity element in a free group $F$ has infinite order. I'm really new on free groups and I found this subject really strange I couldn't understand it very well yet, I need a help or a hint to solve this question. I attached the definition of free groups: Thanks in advance","I'm trying to prove that every nonidentity element in a free group $F$ has infinite order. I'm really new on free groups and I found this subject really strange I couldn't understand it very well yet, I need a help or a hint to solve this question. I attached the definition of free groups: Thanks in advance",,"['abstract-algebra', 'group-theory', 'free-groups']"
83,understanding $\mathbb{R}$/$\mathbb{Z}$,understanding /,\mathbb{R} \mathbb{Z},"I am having trouble understanding the factor group, $\mathbb{R}$/$\mathbb{Z}$, or maybe i'm not.  Here's what I am thinking. Okay, so i have a group $G=(\mathbb{R},+)$, and I have a subgroup $N=(\mathbb{Z},+)$.  Then I form $G/N$.  So this thing identifies any real number $x$ with the integers that are exactly 1 unit step away.  So if $x=\frac{3}{4}$, then $[x]=({...,\frac{-5}{4},\frac{-1}{4},\frac{3}{4},\frac{7}{4},...})$ and i can do this for any real number.  So therefore, my cosets are unit intervals $[0,1)+k$, for integers $k$.  Herstein calls this thing a circle and I was not sure why, but here's my intuition.  The unit interval is essentially closed and since every real number plus an integer identifies with itself, these ""circles"" keep piling up on top of each other as if its one closed interval.  Since it's closed it is a circle.  Does that make sense? Now how do I extend this intuition to this? $G'=[(a,b)|a,b\in{\mathbb{R}}], N'=[(a,b)|a,b\in{\mathbb{Z}}].$  What is $G'/N'$?  How is this a torus?  I can't get an intuitive picture in my head... EDIT:  Actually, are the cosets just simply $[x]=[x\in{\mathbb{R}}|x+k,k\in{\mathbb{Z}}]?$","I am having trouble understanding the factor group, $\mathbb{R}$/$\mathbb{Z}$, or maybe i'm not.  Here's what I am thinking. Okay, so i have a group $G=(\mathbb{R},+)$, and I have a subgroup $N=(\mathbb{Z},+)$.  Then I form $G/N$.  So this thing identifies any real number $x$ with the integers that are exactly 1 unit step away.  So if $x=\frac{3}{4}$, then $[x]=({...,\frac{-5}{4},\frac{-1}{4},\frac{3}{4},\frac{7}{4},...})$ and i can do this for any real number.  So therefore, my cosets are unit intervals $[0,1)+k$, for integers $k$.  Herstein calls this thing a circle and I was not sure why, but here's my intuition.  The unit interval is essentially closed and since every real number plus an integer identifies with itself, these ""circles"" keep piling up on top of each other as if its one closed interval.  Since it's closed it is a circle.  Does that make sense? Now how do I extend this intuition to this? $G'=[(a,b)|a,b\in{\mathbb{R}}], N'=[(a,b)|a,b\in{\mathbb{Z}}].$  What is $G'/N'$?  How is this a torus?  I can't get an intuitive picture in my head... EDIT:  Actually, are the cosets just simply $[x]=[x\in{\mathbb{R}}|x+k,k\in{\mathbb{Z}}]?$",,"['abstract-algebra', 'group-theory']"
84,A group with no proper non-trivial subgroups,A group with no proper non-trivial subgroups,,"There is a lemma that says if a group $G$ has no proper nontrivial subgroups, then $G$ is cyclic. And here is the proof of the lemma: Suppose $G$ has no proper nontrivial subgroups. Take an element $a$ in $G$ for which $a$ is not  equal to $e$. Consider the cyclic subgroup $\langle a \rangle$. This subgroup contains at least $e$ and $a$, so it is not trivial. But $G$ has no proper subgroups, so it must be that $\langle a \rangle = G$. Thus $G$ is cyclic, by definition of a cyclic group. But here i do not understand the following: Why must $\langle a \rangle$ be a subgroup of $G$? For every single element $a$ in $G$, if $\langle a \rangle$ is a subgroup of $G$, then every group should have at least as many subgroups as the number of its elements. I would appreciate any help. Thanks","There is a lemma that says if a group $G$ has no proper nontrivial subgroups, then $G$ is cyclic. And here is the proof of the lemma: Suppose $G$ has no proper nontrivial subgroups. Take an element $a$ in $G$ for which $a$ is not  equal to $e$. Consider the cyclic subgroup $\langle a \rangle$. This subgroup contains at least $e$ and $a$, so it is not trivial. But $G$ has no proper subgroups, so it must be that $\langle a \rangle = G$. Thus $G$ is cyclic, by definition of a cyclic group. But here i do not understand the following: Why must $\langle a \rangle$ be a subgroup of $G$? For every single element $a$ in $G$, if $\langle a \rangle$ is a subgroup of $G$, then every group should have at least as many subgroups as the number of its elements. I would appreciate any help. Thanks",,"['abstract-algebra', 'group-theory', 'cyclic-groups']"
85,Number of ring homomorphisms from $\mathbb Z_{12}$ to $\mathbb Z_{28}$.,Number of ring homomorphisms from  to .,\mathbb Z_{12} \mathbb Z_{28},"Question: Find the number of non trivial ring homomorphisms from $\mathbb Z_{12}$ to $\mathbb Z_{28}$. ($f$ is not necessarily unitary, i.e., $f(1)$ need not be $1$.) Suppose $f$ is a ring homomorphism from $\mathbb Z_{12}$ to $\mathbb Z_{28}$. Consider $f$ as a additive group homomorphism.  Let $k= |\ker f|$ and  $ t = |\operatorname{im}(f)|$. Then $k\mid 12$ and $t\mid 24$ and $kt=12$, by first isomorphism  theorem of groups. There are two possibilities $k=3$, $t=4$   and $k=6$, $t=2$. For the first case $f$ should map $1$ to an element of the subgroup generated by $7$ as there is a unique subgroup of $\mathbb Z_{28}$ of order $4$ generated by $7$. For the second case $1$ has to map to $14$, for the same reasoning. So there are at most two ring homomorphisms from $\mathbb Z_{12}$ to $\mathbb Z_{28}$. Question is how to check the possible maps which are ring homomorphisms. Thanks.","Question: Find the number of non trivial ring homomorphisms from $\mathbb Z_{12}$ to $\mathbb Z_{28}$. ($f$ is not necessarily unitary, i.e., $f(1)$ need not be $1$.) Suppose $f$ is a ring homomorphism from $\mathbb Z_{12}$ to $\mathbb Z_{28}$. Consider $f$ as a additive group homomorphism.  Let $k= |\ker f|$ and  $ t = |\operatorname{im}(f)|$. Then $k\mid 12$ and $t\mid 24$ and $kt=12$, by first isomorphism  theorem of groups. There are two possibilities $k=3$, $t=4$   and $k=6$, $t=2$. For the first case $f$ should map $1$ to an element of the subgroup generated by $7$ as there is a unique subgroup of $\mathbb Z_{28}$ of order $4$ generated by $7$. For the second case $1$ has to map to $14$, for the same reasoning. So there are at most two ring homomorphisms from $\mathbb Z_{12}$ to $\mathbb Z_{28}$. Question is how to check the possible maps which are ring homomorphisms. Thanks.",,"['ring-theory', 'abstract-algebra']"
86,Intersection of two subfields of the Rational Function Field in characteristic $0$,Intersection of two subfields of the Rational Function Field in characteristic,0,"Let $K=F(x)$ be the rational function field over a field $F$ of characteristic $0$, let $L_1=F(x^2)$, and $L_2=F(x^2+x)$. How to show that $L_1\cap L_2 = F$?","Let $K=F(x)$ be the rational function field over a field $F$ of characteristic $0$, let $L_1=F(x^2)$, and $L_2=F(x^2+x)$. How to show that $L_1\cap L_2 = F$?",,"['abstract-algebra', 'field-theory', 'galois-theory']"
87,Group Multiplication Table,Group Multiplication Table,,"I'm currently trying to learn abstract algebra myself, and the following is a quote from the book I am using, ""A set of equations, involving only the generators and their inverses , is called a set of defining equations for $G$ if these equations completely determine the multiplication table of $G$."" Then the book proceeds to give an example: ""Let $G$ be the group $\{e, a, b, b^{2}, ab, ab^{2} \}$ whose generators $a$ and $b$ satisfy the equations $a^{2} = e$, $b^{3} = e$, and $ba = ab^{2}$."" And claims that the three equations determine the multiplication table of $G$. So I worked out the multiplication table and displayed it below. When they say, ""completely determine the multiplication table of $G$,"" does that mean the product of two elements can be simplified to another element? For example, $(ab^{2})(ab^{2}) = ab(ba)bb = ab(ab^{2})b^{2} = abab(b^{3}) = a(ba)b = a(ab^{2})b = aab^{3} = e.$ I also don't see how inverses are used in determining the multiplication table in this case. I've only used substitution in this case. Can someone explain why inverses might be important? How did the author know that only 3 equations were enough to determine the multiplication table? And why did he choose those equations? Also what is the significance of determining a multiplication table for elements of a group? Multiplication Table of G ___________________________________________           |  e      a      b      b^2    ab     ab^2  |   .-------+-------------------------------------------+   |  e    |  e      a      b      b^2    ab     ab^2  |   |  a    |  a      e      ab     ab^2   b      b^2   |   |  b    |  b      ab^2   b^2    e      a      ab    |   |  b^2  |  b^2    ab     e      b      ab^2   a     |   |  ab   |  ab     b^2    ab^2   a      e      b     |   |  ab^2 |  ab^2   b      a      ab     b^2    e     |   '-------+-------------------------------------------'","I'm currently trying to learn abstract algebra myself, and the following is a quote from the book I am using, ""A set of equations, involving only the generators and their inverses , is called a set of defining equations for $G$ if these equations completely determine the multiplication table of $G$."" Then the book proceeds to give an example: ""Let $G$ be the group $\{e, a, b, b^{2}, ab, ab^{2} \}$ whose generators $a$ and $b$ satisfy the equations $a^{2} = e$, $b^{3} = e$, and $ba = ab^{2}$."" And claims that the three equations determine the multiplication table of $G$. So I worked out the multiplication table and displayed it below. When they say, ""completely determine the multiplication table of $G$,"" does that mean the product of two elements can be simplified to another element? For example, $(ab^{2})(ab^{2}) = ab(ba)bb = ab(ab^{2})b^{2} = abab(b^{3}) = a(ba)b = a(ab^{2})b = aab^{3} = e.$ I also don't see how inverses are used in determining the multiplication table in this case. I've only used substitution in this case. Can someone explain why inverses might be important? How did the author know that only 3 equations were enough to determine the multiplication table? And why did he choose those equations? Also what is the significance of determining a multiplication table for elements of a group? Multiplication Table of G ___________________________________________           |  e      a      b      b^2    ab     ab^2  |   .-------+-------------------------------------------+   |  e    |  e      a      b      b^2    ab     ab^2  |   |  a    |  a      e      ab     ab^2   b      b^2   |   |  b    |  b      ab^2   b^2    e      a      ab    |   |  b^2  |  b^2    ab     e      b      ab^2   a     |   |  ab   |  ab     b^2    ab^2   a      e      b     |   |  ab^2 |  ab^2   b      a      ab     b^2    e     |   '-------+-------------------------------------------'",,"['abstract-algebra', 'group-theory']"
88,Partition of a group by proper subgroups with trivial intersection where no two subgroups are isomorphic to each other?,Partition of a group by proper subgroups with trivial intersection where no two subgroups are isomorphic to each other?,,"I was wondering if there exists a group $G$ and a partition of $G$ by proper subgroups $H_1,\cdots,H_n$ , meaning $G = \cup_{i=1}^{n} H_i$ and $H_i \cap H_j = \{1_G\}$ for every $i,j$ , such that $H_i \not\cong H_j$ for $i\neq j$ . I have already tried to check groups of small order and to use the sylow theorems with no success.","I was wondering if there exists a group and a partition of by proper subgroups , meaning and for every , such that for . I have already tried to check groups of small order and to use the sylow theorems with no success.","G G H_1,\cdots,H_n G = \cup_{i=1}^{n} H_i H_i \cap H_j = \{1_G\} i,j H_i \not\cong H_j i\neq j","['abstract-algebra', 'group-theory', 'group-isomorphism']"
89,Is $i$ well defined? [duplicate],Is  well defined? [duplicate],i,"This question already has an answer here : Why are $i$ and $-i$ ""more indistinguishable"" than $\sqrt{2}$ and $-\sqrt{2}$? (1 answer) Closed 3 years ago . I know, it may sound as nothing but a provocative question, and probably it is. However I've been thinking about it for a while, despite being aware that the question itself may not have much sense. Consider the field $\mathbb{R}$ . Each element can be defined univocally. First $0$ and $1$ , then the integers, so the rationals and then all the others (for instance as equivalence classes of Cauchy sequences on $\mathbb{Q}$ ). Now we can define the complex field $\mathbb{C}$ as $$\mathbb{C} = \mathbb{R}[X]/(X^2+1)$$ where $\mathbb{R}[X]$ is the ring of polynomials with real coefficient. However here it becomes impossible to univocally define a root of the polynomial $X^2+1$ since it has two roots (which we will eventually call $\pm i$ ) and they are totally indistinguishable. I know that in practice it's not a problem, we just decide to call one of the two roots $i$ and the other $-i$ . But what's going on exactly? Is it some kind of ""axiom"" the fact that we are allowed to choose one out of a set of two identical elements?","This question already has an answer here : Why are $i$ and $-i$ ""more indistinguishable"" than $\sqrt{2}$ and $-\sqrt{2}$? (1 answer) Closed 3 years ago . I know, it may sound as nothing but a provocative question, and probably it is. However I've been thinking about it for a while, despite being aware that the question itself may not have much sense. Consider the field . Each element can be defined univocally. First and , then the integers, so the rationals and then all the others (for instance as equivalence classes of Cauchy sequences on ). Now we can define the complex field as where is the ring of polynomials with real coefficient. However here it becomes impossible to univocally define a root of the polynomial since it has two roots (which we will eventually call ) and they are totally indistinguishable. I know that in practice it's not a problem, we just decide to call one of the two roots and the other . But what's going on exactly? Is it some kind of ""axiom"" the fact that we are allowed to choose one out of a set of two identical elements?",\mathbb{R} 0 1 \mathbb{Q} \mathbb{C} \mathbb{C} = \mathbb{R}[X]/(X^2+1) \mathbb{R}[X] X^2+1 \pm i i -i,"['abstract-algebra', 'complex-analysis', 'axioms']"
90,Intersection of any set of ideals is an ideal,Intersection of any set of ideals is an ideal,,"Prove that the intersection of any set of Ideals of a ring is an Ideal. I'm looking for hints . Let A, B both be Ideals of a ring R. Suppose $I \equiv A\cap B$ . Since A and B are both Ideals of a ring R, A and B are both Subrings of a ring R. In particular, we have that $\left ( A,+ \right ),\left ( A\setminus \left \{ 0 \right \} ,\cdot \right ),\left ( B,+ \right ),\left ( B\setminus \left \{ 0 \right \},\cdot  \right )$ are Abelian. Now, Suppose $x_{1},x_{2} \in I$ . I'm not entirely sure how I can justify $x_{1}+\left ( -x_{2} \right ) \in I.$ Might be overthinking this but I might have to use the fact that I is the intersection.","Prove that the intersection of any set of Ideals of a ring is an Ideal. I'm looking for hints . Let A, B both be Ideals of a ring R. Suppose . Since A and B are both Ideals of a ring R, A and B are both Subrings of a ring R. In particular, we have that are Abelian. Now, Suppose . I'm not entirely sure how I can justify Might be overthinking this but I might have to use the fact that I is the intersection.","I \equiv A\cap B \left ( A,+ \right ),\left ( A\setminus \left \{ 0 \right \} ,\cdot \right ),\left ( B,+ \right ),\left ( B\setminus \left \{ 0 \right \},\cdot  \right ) x_{1},x_{2} \in I x_{1}+\left ( -x_{2} \right ) \in I.","['abstract-algebra', 'ring-theory', 'ideals']"
91,Can we turn $\mathbb{R}^n$ into a field by changing the multiplication?,Can we turn  into a field by changing the multiplication?,\mathbb{R}^n,"Of course $\mathbb{R}$ is a field with usual addition and multiplication.  When we move up a dimension into $\mathbb{R}^2$, however, there is not a clear way to multiply two vectors together to get something useful.  In fact, if we define multiplication of two vectors component-wise (as is arguably the most natural way), we get something that isn't even an integral domain.  However, if we implement the multiplication $$ (a, b)(c, d) \mapsto (ac - bd, ad + bc), $$ then we obtain a copy of $\mathbb{C}$, which is again a field.  Can we do this for higher dimensions? That is, is there some clever multiplicative structure on $\mathbb{R}^3$ that produces a field? $\mathbb{R}^n$?","Of course $\mathbb{R}$ is a field with usual addition and multiplication.  When we move up a dimension into $\mathbb{R}^2$, however, there is not a clear way to multiply two vectors together to get something useful.  In fact, if we define multiplication of two vectors component-wise (as is arguably the most natural way), we get something that isn't even an integral domain.  However, if we implement the multiplication $$ (a, b)(c, d) \mapsto (ac - bd, ad + bc), $$ then we obtain a copy of $\mathbb{C}$, which is again a field.  Can we do this for higher dimensions? That is, is there some clever multiplicative structure on $\mathbb{R}^3$ that produces a field? $\mathbb{R}^n$?",,"['abstract-algebra', 'field-theory']"
92,Do Boolean rings always have a unit element?,Do Boolean rings always have a unit element?,,"Let $(B, +, \cdot)$ be a non-trivial ring with the property that every $x \in B$ satisfies $x \cdot x = x$. How does one prove that such a ring $(B, +, \cdot)$ must have a unit element $1_B$? (Or, in case this is not true in general, what is a counterexample?) BTW, I'm looking for an elementary proof, not requiring anything more than the definition of a ring, the definition of $(B, +, \cdot)$, and, if necessary, the easily shown facts that $x + x = 0$ and $x\cdot y = y\cdot x,\,\forall\, x,y \in B$.","Let $(B, +, \cdot)$ be a non-trivial ring with the property that every $x \in B$ satisfies $x \cdot x = x$. How does one prove that such a ring $(B, +, \cdot)$ must have a unit element $1_B$? (Or, in case this is not true in general, what is a counterexample?) BTW, I'm looking for an elementary proof, not requiring anything more than the definition of a ring, the definition of $(B, +, \cdot)$, and, if necessary, the easily shown facts that $x + x = 0$ and $x\cdot y = y\cdot x,\,\forall\, x,y \in B$.",,"['abstract-algebra', 'rngs']"
93,Prove $G/\ker \phi \times \ker \phi \cong G$,Prove,G/\ker \phi \times \ker \phi \cong G,"If $G, H$ are groups and $\phi : G \to H$ is a homomorphism, is it true that $G/\ker \phi \times \ker \phi \cong G$? I am pretty sure this is right, but I can't remember how to prove it. We can think of $\phi$ as a surjection of $G$ into $G/\ker \phi$, so I was thinking that for $\phi$ there ought to be a surjection $\psi : G \to \ker \phi$, such that $\psi$ maps an element of $G$ into its ""position"" in its coset of $\ker \phi$. Then then isomorphism between $G$ and $G/\ker \phi \times \ker \phi$ would be $f(g) = (\phi(g), \psi(g))$. To show $f$ is an isomorphim we only need to show it is injective since $\phi, \psi$ are both surjective. $f(g) = f(g')$ implies $\phi(g) = \phi(g')$ so they are in the same coset of $\ker\phi$ and $\psi(g) = \psi(g')$ so they are in the same ""position"" in that coset. Therefore $g = g'$. If my intuitive notion of position works, I am still not sure how I define $\psi$. Can anyone point me in the right direction?","If $G, H$ are groups and $\phi : G \to H$ is a homomorphism, is it true that $G/\ker \phi \times \ker \phi \cong G$? I am pretty sure this is right, but I can't remember how to prove it. We can think of $\phi$ as a surjection of $G$ into $G/\ker \phi$, so I was thinking that for $\phi$ there ought to be a surjection $\psi : G \to \ker \phi$, such that $\psi$ maps an element of $G$ into its ""position"" in its coset of $\ker \phi$. Then then isomorphism between $G$ and $G/\ker \phi \times \ker \phi$ would be $f(g) = (\phi(g), \psi(g))$. To show $f$ is an isomorphim we only need to show it is injective since $\phi, \psi$ are both surjective. $f(g) = f(g')$ implies $\phi(g) = \phi(g')$ so they are in the same coset of $\ker\phi$ and $\psi(g) = \psi(g')$ so they are in the same ""position"" in that coset. Therefore $g = g'$. If my intuitive notion of position works, I am still not sure how I define $\psi$. Can anyone point me in the right direction?",,"['abstract-algebra', 'group-theory']"
94,Clarification on proof: Order of left cosets equal,Clarification on proof: Order of left cosets equal,,There is a lemma that says that all left cosets $aH$ of a subgroup $H$ of a group $G$ have the same order. The proof given is as follows... The multiplication by $a \in G$ defines the map $H \rightarrow aH$ that sends $h\mapsto ah$. This map is bijective because its inverse is multiplication by $a^{-1}$. I don't quite understand the proof. Why does having a bijective map mean that all sets of left cosets have the same order? Thank you,There is a lemma that says that all left cosets $aH$ of a subgroup $H$ of a group $G$ have the same order. The proof given is as follows... The multiplication by $a \in G$ defines the map $H \rightarrow aH$ that sends $h\mapsto ah$. This map is bijective because its inverse is multiplication by $a^{-1}$. I don't quite understand the proof. Why does having a bijective map mean that all sets of left cosets have the same order? Thank you,,['abstract-algebra']
95,"If $H$ is a normal subgroup of $G$ and if both $H$ and $G/H$ are abelian, is $G$ abelian?","If  is a normal subgroup of  and if both  and  are abelian, is  abelian?",H G H G/H G,"Pretty straightforward: If $H$ is a normal subgroup of $G$ and if both $H$ and $G/H$ are abelian, is $G$ abelian?","Pretty straightforward: If $H$ is a normal subgroup of $G$ and if both $H$ and $G/H$ are abelian, is $G$ abelian?",,"['abstract-algebra', 'abelian-groups']"
96,A group of order $p^2$ has a subgroup of order $p$,A group of order  has a subgroup of order,p^2 p,"Let $G$ be a group of order $p^2$, where $p$ is prime. Show that $G$ must have a subgroup order of order $p$. What I have so far: $$G^{p^2} =e .$$ If $G$ has an element $g$ of order $p^2$, then $g^p$ is of order $p$.  $\langle g^p\rangle$ is a subgroup of order $p$. $G$ must have an element $a$ of order $p$ by Lagrange's Theorem.  $\langle a\rangle$ is a subgroup of order $p$. Is this sufficient?  Or am I missing some details?","Let $G$ be a group of order $p^2$, where $p$ is prime. Show that $G$ must have a subgroup order of order $p$. What I have so far: $$G^{p^2} =e .$$ If $G$ has an element $g$ of order $p^2$, then $g^p$ is of order $p$.  $\langle g^p\rangle$ is a subgroup of order $p$. $G$ must have an element $a$ of order $p$ by Lagrange's Theorem.  $\langle a\rangle$ is a subgroup of order $p$. Is this sufficient?  Or am I missing some details?",,"['abstract-algebra', 'group-theory']"
97,How to find all groups that have exactly 3 subgroups?,How to find all groups that have exactly 3 subgroups?,,"How to find all groups that have exactly 3 subgroups? Any group must have identity and itself as subgroups, so we just need to find all the groups that only have one proper subgroup. I think that for a prime $p$ the group $\mathbb Z/p^2\mathbb Z$ has only one proper subgroup (for example, $\mathbb Z/4\mathbb Z$, $\mathbb Z/9\mathbb Z$). Are there any other possibilities?","How to find all groups that have exactly 3 subgroups? Any group must have identity and itself as subgroups, so we just need to find all the groups that only have one proper subgroup. I think that for a prime $p$ the group $\mathbb Z/p^2\mathbb Z$ has only one proper subgroup (for example, $\mathbb Z/4\mathbb Z$, $\mathbb Z/9\mathbb Z$). Are there any other possibilities?",,"['abstract-algebra', 'group-theory', 'cyclic-groups']"
98,Are there any infinite dimensional division algebras?,Are there any infinite dimensional division algebras?,,"Appart from the finite dimensional division algebras like $\mathbb{R, C, H, O}$ Are there any infinite dimensional division algebras? (Especially any ""exceptional"" ones?) I was thinking maybe the ring over polynomials might be a division algebra if you include negative exponents and allow infinite series. But I'm not sure if every series gives a unique member of the algebra. You might have $(1+x)^{-1} = 1-x+x^2-...$ Well I guess the space of functions is a division algebra since you can add and divide them $f(x)g(x)$ and $f(x)/g(x)$ and has an identity element $1$ . What about the ring over polynomials with rational or irrational exponents? Or ones based on lattices?","Appart from the finite dimensional division algebras like Are there any infinite dimensional division algebras? (Especially any ""exceptional"" ones?) I was thinking maybe the ring over polynomials might be a division algebra if you include negative exponents and allow infinite series. But I'm not sure if every series gives a unique member of the algebra. You might have Well I guess the space of functions is a division algebra since you can add and divide them and and has an identity element . What about the ring over polynomials with rational or irrational exponents? Or ones based on lattices?","\mathbb{R, C, H, O} (1+x)^{-1} = 1-x+x^2-... f(x)g(x) f(x)/g(x) 1",['abstract-algebra']
99,"""In a finite commutative ring, prove every element is a unit or zero divisor."" What happens if we drop ""finite""?","""In a finite commutative ring, prove every element is a unit or zero divisor."" What happens if we drop ""finite""?",,"This was my ring theory exam question which states: Let $R$ be a finite commutative ring with unity.Prove that every non-zero element of $R$ is either a zero-divisor or a unit.What happens if we drop ""finite"" condition on $R$? I know I am wrong but I thought $R$ to be an integral domain.What should be correct way to solve it?","This was my ring theory exam question which states: Let $R$ be a finite commutative ring with unity.Prove that every non-zero element of $R$ is either a zero-divisor or a unit.What happens if we drop ""finite"" condition on $R$? I know I am wrong but I thought $R$ to be an integral domain.What should be correct way to solve it?",,"['abstract-algebra', 'ring-theory']"
