,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,How to solve this differential equation system?,How to solve this differential equation system?,,"The following system is given: $$ \dot{x} = y + z \\ \dot{y} = x + z \\ \dot{z} = x + y $$ The first thing I did was to find out the eigenvalues. I found out, that -1 is a doubled and 2 a single eigenvalue, so $$ \lambda_{1,2} = -1,\ \ \lambda_3 = 2 $$ In the excercises ago, the ideas were to determine $ y=e^{\lambda x} \underline{u} $. so I tried to do the following: $$ \begin{pmatrix} 0-\lambda & 1 & 1 \\ 1 & 0-\lambda & 1 \\ 1 & 1 & 0-\lambda \end{pmatrix} $$ Is this step right? I tried to find a scheme as in the excercises ago and in the line $ \dot{x} = y +z$ I don't have an x but one y and one z. When inserting  $ \lambda_1 = -1 $ I have $$ A-\lambda E = \underline{0} \rightarrow \begin{pmatrix} 1 & 1 & 1 \\ 1 & 1 & 1 \\ 1 & 1 & 1 \end{pmatrix} = \underline{0} $$ which means that $ x_i + y_i + z_i = 0\ for\ i ={1,2,3} $. Here is the point on which I don't know how to go on. One solution is the trivial one, so $x=y=z=0$. Can I use this solution? I think that I have to use something like $$ y = C_1 * \begin{pmatrix} u_1*e^{\lambda_1 x} \\ u_2*e^{\lambda_1 x}\\ u_3*e^{\lambda_1 x} \end{pmatrix} + C_2 \begin{pmatrix} ... \end{pmatrix} + C_3 \begin{pmatrix} ... \end{pmatrix}$$ in the case $ \lambda_1 = 1 $, but how to I get my u here exactly?","The following system is given: $$ \dot{x} = y + z \\ \dot{y} = x + z \\ \dot{z} = x + y $$ The first thing I did was to find out the eigenvalues. I found out, that -1 is a doubled and 2 a single eigenvalue, so $$ \lambda_{1,2} = -1,\ \ \lambda_3 = 2 $$ In the excercises ago, the ideas were to determine $ y=e^{\lambda x} \underline{u} $. so I tried to do the following: $$ \begin{pmatrix} 0-\lambda & 1 & 1 \\ 1 & 0-\lambda & 1 \\ 1 & 1 & 0-\lambda \end{pmatrix} $$ Is this step right? I tried to find a scheme as in the excercises ago and in the line $ \dot{x} = y +z$ I don't have an x but one y and one z. When inserting  $ \lambda_1 = -1 $ I have $$ A-\lambda E = \underline{0} \rightarrow \begin{pmatrix} 1 & 1 & 1 \\ 1 & 1 & 1 \\ 1 & 1 & 1 \end{pmatrix} = \underline{0} $$ which means that $ x_i + y_i + z_i = 0\ for\ i ={1,2,3} $. Here is the point on which I don't know how to go on. One solution is the trivial one, so $x=y=z=0$. Can I use this solution? I think that I have to use something like $$ y = C_1 * \begin{pmatrix} u_1*e^{\lambda_1 x} \\ u_2*e^{\lambda_1 x}\\ u_3*e^{\lambda_1 x} \end{pmatrix} + C_2 \begin{pmatrix} ... \end{pmatrix} + C_3 \begin{pmatrix} ... \end{pmatrix}$$ in the case $ \lambda_1 = 1 $, but how to I get my u here exactly?",,"['ordinary-differential-equations', 'eigenvalues-eigenvectors', 'systems-of-equations']"
1,Solve the following differential equation: $xy' - y = x^2$,Solve the following differential equation:,xy' - y = x^2,"I'm preparing to exam in Linear Algebra $2$ and I have problems with differential equations.. For example, the following exercise: Solve the following differential equation: $xy' - y = x^2$ . I started to solve: $$xy' - y = x^2$$ $$ \implies y' - \frac{y}{x} = x$$ I need to find some $u$ and multiply both sides by it: $$uy' - \frac{u}{x}y = ux$$ I need somehow to satisfy the product rule of derivative, by finding $u$ such that $u' = -\frac{u}{x}$ and by this get: $(uy)' = uy' + u'y$ . I need the help to find $u$ . I need to find $u$ such that $u' = -\frac{u}{x}$ . How would you find $u$ ? thanks in advance.","I'm preparing to exam in Linear Algebra and I have problems with differential equations.. For example, the following exercise: Solve the following differential equation: . I started to solve: I need to find some and multiply both sides by it: I need somehow to satisfy the product rule of derivative, by finding such that and by this get: . I need the help to find . I need to find such that . How would you find ? thanks in advance.",2 xy' - y = x^2 xy' - y = x^2  \implies y' - \frac{y}{x} = x u uy' - \frac{u}{x}y = ux u u' = -\frac{u}{x} (uy)' = uy' + u'y u u u' = -\frac{u}{x} u,"['calculus', 'linear-algebra', 'ordinary-differential-equations', 'derivatives']"
2,How do I solve $ \int \frac{t+1}{dt}=\int\frac{-y^2}{dy} $?,How do I solve ?, \int \frac{t+1}{dt}=\int\frac{-y^2}{dy} ,How can I integrate the following: $$ \int 	\frac{t+1}{dt}=\int\frac{-y^2}{dy} $$ would I integrate normally and inverse it? like: $$\int\frac{1}{dy} = \frac{1}{y} + c $$,How can I integrate the following: would I integrate normally and inverse it? like:,"
\int 	\frac{t+1}{dt}=\int\frac{-y^2}{dy}
 \int\frac{1}{dy} = \frac{1}{y} + c ","['integration', 'ordinary-differential-equations']"
3,Solve the following differential equation: $ty' + 2y = \sin(t)$,Solve the following differential equation:,ty' + 2y = \sin(t),"An exercise from the book: Solve the following differential equation: $ty' + 2y = \sin(t)$ This is the first time I approch a differential equation, and the book doesn't provide an example how to solve an differential equation, So I need your help to show me how to solve this differential equation. It's not a homework. Thanks in advance!","An exercise from the book: Solve the following differential equation: $ty' + 2y = \sin(t)$ This is the first time I approch a differential equation, and the book doesn't provide an example how to solve an differential equation, So I need your help to show me how to solve this differential equation. It's not a homework. Thanks in advance!",,['ordinary-differential-equations']
4,Regular and singular points in a second order differential equation.,Regular and singular points in a second order differential equation.,,"For a linear homogeneous second order differential equation $$y'' + p(x)y'+q(x)y=0$$ A point $x_0$ is regular point of the equation if the functions $p,q$ are analytic at $x_0$, and a singular point if they are not. If the functions $p,q$ satisfy: $$\lim_{x\to x_0} (x-x_0)p(x) <\infty$$ $$\lim_{x\to x_0} (x-x_0)^2 q(x)<\infty$$ then the singularity is said to be regular, otherwise it's irregular. Two questions: Firstly, what motives this particular bound on the order of growth (linear, quadratic) of the functions? Secondly, I am wondering how (or indeed, if) those definitions can be adapted to the general case, where we drop linearity and homogeneity, so the equation is of the form: $$y''=f(x,y,y')$$","For a linear homogeneous second order differential equation $$y'' + p(x)y'+q(x)y=0$$ A point $x_0$ is regular point of the equation if the functions $p,q$ are analytic at $x_0$, and a singular point if they are not. If the functions $p,q$ satisfy: $$\lim_{x\to x_0} (x-x_0)p(x) <\infty$$ $$\lim_{x\to x_0} (x-x_0)^2 q(x)<\infty$$ then the singularity is said to be regular, otherwise it's irregular. Two questions: Firstly, what motives this particular bound on the order of growth (linear, quadratic) of the functions? Secondly, I am wondering how (or indeed, if) those definitions can be adapted to the general case, where we drop linearity and homogeneity, so the equation is of the form: $$y''=f(x,y,y')$$",,['ordinary-differential-equations']
5,Solving a DE using substitution method. Please Help!,Solving a DE using substitution method. Please Help!,,"I'm attempting to solve the following DE: $$y^2\frac{dy}{dx} +\frac{y^3}{x}=\frac{2}{x^2}$$ with the substitution $u(x) = y^3$ I can somewhat picture what needs to be done, but I seem to come up short.  For instance, I know the following: $$u(x) = y^3$$ $$\frac{du}{dx}= 3y^2\frac{dy}{dx}$$ Therefore: $$\frac{dy}{dx}= \frac{1}{3y^2}\frac{du}{dx}$$ Furthermore: $$\frac{dy}{dx}=\frac{1}{3u^{\frac{2}{3}}}\frac{du}{dx}$$ Substituting this into the DE is where I'm getting stuck.  I can't seem to get it to ""work"" after that point. I would certainly appreciate any help!","I'm attempting to solve the following DE: $$y^2\frac{dy}{dx} +\frac{y^3}{x}=\frac{2}{x^2}$$ with the substitution $u(x) = y^3$ I can somewhat picture what needs to be done, but I seem to come up short.  For instance, I know the following: $$u(x) = y^3$$ $$\frac{du}{dx}= 3y^2\frac{dy}{dx}$$ Therefore: $$\frac{dy}{dx}= \frac{1}{3y^2}\frac{du}{dx}$$ Furthermore: $$\frac{dy}{dx}=\frac{1}{3u^{\frac{2}{3}}}\frac{du}{dx}$$ Substituting this into the DE is where I'm getting stuck.  I can't seem to get it to ""work"" after that point. I would certainly appreciate any help!",,"['ordinary-differential-equations', 'homogeneous-equation']"
6,A simple question about behavior of differential equation as it goes to infinity.,A simple question about behavior of differential equation as it goes to infinity.,,"Let $y^{\prime}=y+C$ where $C$ is any constant. The equilibrium value is $y=-C$ The behavior of y as $t\to \infty$ is what I am asking about. I think this is true: If $t > -C $ then it goes to infinity, if $t < -C$ then it goes to negative infinity, lastly if $t=C$ it doesn't change. If you have: $y^{\prime}=y^2-y-6$ which has two equilibrium solutions,$t=3,-2$ What exactly is the behavior as $t\to \infty$? is it: If $t > 3$ goes to infity If $t = 3$ no change If $2<t<3$ goes to 2 If $t = 2$ the no change If $t <2 $ goes to 2 Does this mean that 2 is more stable than 3?","Let $y^{\prime}=y+C$ where $C$ is any constant. The equilibrium value is $y=-C$ The behavior of y as $t\to \infty$ is what I am asking about. I think this is true: If $t > -C $ then it goes to infinity, if $t < -C$ then it goes to negative infinity, lastly if $t=C$ it doesn't change. If you have: $y^{\prime}=y^2-y-6$ which has two equilibrium solutions,$t=3,-2$ What exactly is the behavior as $t\to \infty$? is it: If $t > 3$ goes to infity If $t = 3$ no change If $2<t<3$ goes to 2 If $t = 2$ the no change If $t <2 $ goes to 2 Does this mean that 2 is more stable than 3?",,['ordinary-differential-equations']
7,Good ODE Books That Explain How Solution Methods Came To Be and Their Justifications,Good ODE Books That Explain How Solution Methods Came To Be and Their Justifications,,"As part of the mathematics program offered at my college, I took an introductory ODE course a few semesters back.  This was the one math course in my entire college career that I was totally lost in.  Even after pursuing additional information through my instructor and scouring countless other ODE books, I have no idea how the various methods of solutions for ODEs came to be.  They are all non-obvious to me--well, all except for separation of variables--and really seem quite contrived. What is a good book or online resource that conveys ODE solution methods in an easy to understand way?  The book I used for my course was ""Fundamentals of Ordinary Differential Equations"" by Nagle, Saff, and Snider and it was very much written for those people who really only wanted or needed an algorithmic way to find solutions.  What I am really looking for are some explanations for why certain methods work, how they work, and how they came to be from a theoretical standpoint, because right now they all seem like lucky guesses and don't seem interconnected at all. If you can suggest some books or online resources, that would be great.  Please provide some rationale for why you think the resource is good.  No modeling needs to be covered in the resource as that is rather simple.","As part of the mathematics program offered at my college, I took an introductory ODE course a few semesters back.  This was the one math course in my entire college career that I was totally lost in.  Even after pursuing additional information through my instructor and scouring countless other ODE books, I have no idea how the various methods of solutions for ODEs came to be.  They are all non-obvious to me--well, all except for separation of variables--and really seem quite contrived. What is a good book or online resource that conveys ODE solution methods in an easy to understand way?  The book I used for my course was ""Fundamentals of Ordinary Differential Equations"" by Nagle, Saff, and Snider and it was very much written for those people who really only wanted or needed an algorithmic way to find solutions.  What I am really looking for are some explanations for why certain methods work, how they work, and how they came to be from a theoretical standpoint, because right now they all seem like lucky guesses and don't seem interconnected at all. If you can suggest some books or online resources, that would be great.  Please provide some rationale for why you think the resource is good.  No modeling needs to be covered in the resource as that is rather simple.",,"['ordinary-differential-equations', 'reference-request', 'online-resources']"
8,By finding solutions as power series in $x$ solve $4xy''+2(1-x)y'-y=0 .$,By finding solutions as power series in  solve,x 4xy''+2(1-x)y'-y=0 .,"By finding solutions as power series in $x$ solve $$4xy''+2(1-x)y'-y=0  .$$ What I did is the following. First I let the solution $y$ be equal to  $$y =\sum_{i=0}^{\infty} b_ix^i =b_0 +b_1x+b_2x^2+\ldots$$ for undetermined $b_i$. Then I found the expression for $y'$ and $y''$, $$y' =\sum_{i=0}^{\infty} ib_ix^{i-1} =b_1 + 2b_2x+3b_3x^2+\ldots.$$ and $$y'' =\sum_{i=0}^{\infty} i(i-1)b_ix^{i-2} =2b_2+6b_3x+12b_4x^2\ldots.$$ Now I put these in the original DE to get $$4\sum   i(i-1)b_ix^{i-1}+2\sum ib_i(x^{i-1}-x^i) - \sum b_ix^i =0   $$ where all sums range from $0$ to infinity. Finally this becomes $$\sum \left\{    (4i(i-i)b_i+2ib_i )x^{i-1}+(-2ib_i-b_i)x^i \right\}=0.$$ At this point I am fairly certain I have already made a mistake somewhere, probably in working out the power series of $y'$ or $y''$. Who can help point it out to me, I am pretty sure in the last sum there should be terms like $b_{i+1}$ or $b_{i+2}$. Thanks for any help or tips! EDIT I have gotten further by realizing that $$y' =\sum_{i=0}^{\infty} ib_ix^{i-1} =\sum_{i=1}^{\infty} ib_ix^{i-1}=\sum_{i=0}^{\infty} (i+1)b_{i+1}x^{i}$$ and  $$y'' =\sum_{i=0}^{\infty} (i+2)(i+1)b_{i+2}x^{i}.$$ Putting these in the original DE I get $$\sum \left\{   [4(i+2)(i+1)b_{i+2}-2(i+1)b_{i+1}]x^{i+1} + [2(i+1)b_{i+1}-b_i]x^i  \right\}=0.$$  This must be true for all $x$ and thus we have  $$4(i+2)(i+1)b_{i+2}=2(i+1)b_{i+1}$$ and  $$2(i+1)b_{i+1} = b_i.$$ After simplyfying these two conditions are seen to be identical. Now I've set $b_0=1$ to obtain the solution  $$ y = 1 + \frac{x}{2}+ \frac{x^2}{8} +\frac{x^3}{48}+\ldots + \frac{x^i}{2^i(i!)}+\ldots.$$ Now I've arrived at the ackward position where in working out the question here I have actually managed to solve it. My last question is then, does anyone recognize this power series? Thanks!","By finding solutions as power series in $x$ solve $$4xy''+2(1-x)y'-y=0  .$$ What I did is the following. First I let the solution $y$ be equal to  $$y =\sum_{i=0}^{\infty} b_ix^i =b_0 +b_1x+b_2x^2+\ldots$$ for undetermined $b_i$. Then I found the expression for $y'$ and $y''$, $$y' =\sum_{i=0}^{\infty} ib_ix^{i-1} =b_1 + 2b_2x+3b_3x^2+\ldots.$$ and $$y'' =\sum_{i=0}^{\infty} i(i-1)b_ix^{i-2} =2b_2+6b_3x+12b_4x^2\ldots.$$ Now I put these in the original DE to get $$4\sum   i(i-1)b_ix^{i-1}+2\sum ib_i(x^{i-1}-x^i) - \sum b_ix^i =0   $$ where all sums range from $0$ to infinity. Finally this becomes $$\sum \left\{    (4i(i-i)b_i+2ib_i )x^{i-1}+(-2ib_i-b_i)x^i \right\}=0.$$ At this point I am fairly certain I have already made a mistake somewhere, probably in working out the power series of $y'$ or $y''$. Who can help point it out to me, I am pretty sure in the last sum there should be terms like $b_{i+1}$ or $b_{i+2}$. Thanks for any help or tips! EDIT I have gotten further by realizing that $$y' =\sum_{i=0}^{\infty} ib_ix^{i-1} =\sum_{i=1}^{\infty} ib_ix^{i-1}=\sum_{i=0}^{\infty} (i+1)b_{i+1}x^{i}$$ and  $$y'' =\sum_{i=0}^{\infty} (i+2)(i+1)b_{i+2}x^{i}.$$ Putting these in the original DE I get $$\sum \left\{   [4(i+2)(i+1)b_{i+2}-2(i+1)b_{i+1}]x^{i+1} + [2(i+1)b_{i+1}-b_i]x^i  \right\}=0.$$  This must be true for all $x$ and thus we have  $$4(i+2)(i+1)b_{i+2}=2(i+1)b_{i+1}$$ and  $$2(i+1)b_{i+1} = b_i.$$ After simplyfying these two conditions are seen to be identical. Now I've set $b_0=1$ to obtain the solution  $$ y = 1 + \frac{x}{2}+ \frac{x^2}{8} +\frac{x^3}{48}+\ldots + \frac{x^i}{2^i(i!)}+\ldots.$$ Now I've arrived at the ackward position where in working out the question here I have actually managed to solve it. My last question is then, does anyone recognize this power series? Thanks!",,['ordinary-differential-equations']
9,Show uniqueness of solution to $\dot{x}(t) = \frac{x}{2+2t}$,Show uniqueness of solution to,\dot{x}(t) = \frac{x}{2+2t},"In a homework problem, the diff EQ came up $$\dot{x}(t) = \frac{x(t)}{2+2t}$$ and $x(1) = 1$. I note that $x(t) = \frac1{\sqrt{2}}\sqrt{1+t}$ is a solution. How might I show uniqueness of the solution? I would say what I've tried, but I am inexperienced at diff EQ, and especially for equations which are functions of $x$ itself.","In a homework problem, the diff EQ came up $$\dot{x}(t) = \frac{x(t)}{2+2t}$$ and $x(1) = 1$. I note that $x(t) = \frac1{\sqrt{2}}\sqrt{1+t}$ is a solution. How might I show uniqueness of the solution? I would say what I've tried, but I am inexperienced at diff EQ, and especially for equations which are functions of $x$ itself.",,"['calculus', 'ordinary-differential-equations']"
10,Change of Variables in differential equation,Change of Variables in differential equation,,"Given the equation $zZ''(z) + Z'(z) + \alpha^2Z(z) = 0$ use the change of variables $x = \sqrt{\frac{z}{a}}$ where $a$ is a constant to map the problem to the differential equation $Z''(x) + \frac{1}{x}Z'(x) + \gamma^2 Z(x) = 0,$ where $\gamma = 2\alpha \sqrt{a}$ Attempt: I think I am struggling to get the chain rule correct for this particular case. Here is my attempt:  $$\frac{d}{dz} = \frac{d}{dx} \frac{dx}{dz} = \frac{1}{2\sqrt{za}}\frac{d}{dx} = \frac{1}{2xa} \frac{d}{dx}$$ This means by a similar argument $$\frac{d^2}{dz^2} = \frac{1}{4x^2a^2}\frac{d^2}{dx^2}$$ I am not really sure where to go from here. Thanks.","Given the equation $zZ''(z) + Z'(z) + \alpha^2Z(z) = 0$ use the change of variables $x = \sqrt{\frac{z}{a}}$ where $a$ is a constant to map the problem to the differential equation $Z''(x) + \frac{1}{x}Z'(x) + \gamma^2 Z(x) = 0,$ where $\gamma = 2\alpha \sqrt{a}$ Attempt: I think I am struggling to get the chain rule correct for this particular case. Here is my attempt:  $$\frac{d}{dz} = \frac{d}{dx} \frac{dx}{dz} = \frac{1}{2\sqrt{za}}\frac{d}{dx} = \frac{1}{2xa} \frac{d}{dx}$$ This means by a similar argument $$\frac{d^2}{dz^2} = \frac{1}{4x^2a^2}\frac{d^2}{dx^2}$$ I am not really sure where to go from here. Thanks.",,['ordinary-differential-equations']
11,Doubts related to a phase plane diagram.,Doubts related to a phase plane diagram.,,"I want to draw phase plane diagram of the following differential equation $$\frac{d^2y}{dx^2} - 2\frac{dy}{dx} + 10 y = 0.$$ Please check if my approach is correct. I have some doubts about it. They are in bold . First of all I am changing it to a system of differential equation by putting $y_1 = y$, $y_1' = y_2$, $y_2' = 2y_2 - 10 y_1$. So the system of differential equation will be $$\left[\begin{array}{c} y_1 \\ y_2\end{array}\right]' = \left[\begin{array}{c c} 0 & 1 \\ -10 & 2\end{array}\right]\left[\begin{array}{c} y_1 \\ y_2\end{array}\right]$$ Eigenvalues of the system will be $1 + 3i$ and $1 - 3i$. The eigenvector corresponding $1 + 3i$ is $(1, 1 + 3i)^t$. Computing a few steps we shall get the general solution $$\left[ \begin{array}{c} y_1 \\ y_2 \end{array} \right] = C_1 e^x \left(\begin{array}{c} \cos(3x) \\ \cos(3x) - 3\sin(3x) \end{array} \right) + C_2 e^x \left(\begin{array}{c} \sin(3x) \\ \sin(3x) + 3\cos(3x) \end{array} \right)$$ The system has only one critical point $(0,0)^t$. From the general solution we may say the critical point is a source, as $e^x \rightarrow \infty$ as $x \rightarrow 0$ so the trajectories will spiral out, I am predicting . How to prove from the general solution that the trajectories will spiral out? Let us transform the coordinate system. Transformation matrix will be $T = \left[ \begin{array}{c c} 1 & 0 \\ 1 & 3 \end{array} \right]$. New system of equation will be $$\left[\begin{array}{c} y_1 \\ y_2\end{array}\right]' = \left[\begin{array}{c c} 1 & 3 \\ -3 & 1\end{array}\right]\left[\begin{array}{c} y_1 \\ y_2\end{array}\right]$$ Corresponding general solution will be $$\left[ \begin{array}{c} y_1 \\ y_2 \end{array} \right] = C_1 e^x \left(\begin{array}{c} \cos(3x) \\ \sin(3x) \end{array} \right) + C_2 e^x \left(\begin{array}{c} \sin(3x) \\ \cos(3t) \end{array} \right)$$ Here it is easy to prove that the trajectories will spiral out. Will the trajectories will rotate clockwise or anticlockwise? How to determine? I know that if $a + bi$ be the eigenvalue then the trajectories will rotate clockwise if $b > 0$ and anticlockwise if $b < 0$. But $a - bi$ will also be an eigenvalue which can be written as $a + (-b)i$. I am confused. Why we are so much interested for the behavior of the system near the critical point? Thank you for reading the long question and your help. Is there any short method?","I want to draw phase plane diagram of the following differential equation $$\frac{d^2y}{dx^2} - 2\frac{dy}{dx} + 10 y = 0.$$ Please check if my approach is correct. I have some doubts about it. They are in bold . First of all I am changing it to a system of differential equation by putting $y_1 = y$, $y_1' = y_2$, $y_2' = 2y_2 - 10 y_1$. So the system of differential equation will be $$\left[\begin{array}{c} y_1 \\ y_2\end{array}\right]' = \left[\begin{array}{c c} 0 & 1 \\ -10 & 2\end{array}\right]\left[\begin{array}{c} y_1 \\ y_2\end{array}\right]$$ Eigenvalues of the system will be $1 + 3i$ and $1 - 3i$. The eigenvector corresponding $1 + 3i$ is $(1, 1 + 3i)^t$. Computing a few steps we shall get the general solution $$\left[ \begin{array}{c} y_1 \\ y_2 \end{array} \right] = C_1 e^x \left(\begin{array}{c} \cos(3x) \\ \cos(3x) - 3\sin(3x) \end{array} \right) + C_2 e^x \left(\begin{array}{c} \sin(3x) \\ \sin(3x) + 3\cos(3x) \end{array} \right)$$ The system has only one critical point $(0,0)^t$. From the general solution we may say the critical point is a source, as $e^x \rightarrow \infty$ as $x \rightarrow 0$ so the trajectories will spiral out, I am predicting . How to prove from the general solution that the trajectories will spiral out? Let us transform the coordinate system. Transformation matrix will be $T = \left[ \begin{array}{c c} 1 & 0 \\ 1 & 3 \end{array} \right]$. New system of equation will be $$\left[\begin{array}{c} y_1 \\ y_2\end{array}\right]' = \left[\begin{array}{c c} 1 & 3 \\ -3 & 1\end{array}\right]\left[\begin{array}{c} y_1 \\ y_2\end{array}\right]$$ Corresponding general solution will be $$\left[ \begin{array}{c} y_1 \\ y_2 \end{array} \right] = C_1 e^x \left(\begin{array}{c} \cos(3x) \\ \sin(3x) \end{array} \right) + C_2 e^x \left(\begin{array}{c} \sin(3x) \\ \cos(3t) \end{array} \right)$$ Here it is easy to prove that the trajectories will spiral out. Will the trajectories will rotate clockwise or anticlockwise? How to determine? I know that if $a + bi$ be the eigenvalue then the trajectories will rotate clockwise if $b > 0$ and anticlockwise if $b < 0$. But $a - bi$ will also be an eigenvalue which can be written as $a + (-b)i$. I am confused. Why we are so much interested for the behavior of the system near the critical point? Thank you for reading the long question and your help. Is there any short method?",,"['analysis', 'ordinary-differential-equations', 'dynamical-systems']"
12,How do I simulate a simple pendulum?,How do I simulate a simple pendulum?,,"I have the equation of motion of a simple pendulum as  $$\frac{d^2\theta}{dt^2} + \frac{g}{l}\sin \theta = 0$$ It's a second order equation. I am trying to simulate it using a SDL library in C++. I know how to solve first order differential equation using Runge-Kutta method. But I can't combine all these. Can anybody help me to solve the differential equation to get the correct simulation? Update BTW, I am not sure whether it should be posted here or in any stack-exchange forums. But If you could help me or redirect me to any other forums, that would be helpful. I have simulated it using Runge-Kutta method and I am adding my code below. //simplified equations 1 double thetadot(double u) {     return u; }  //simplified equations 2 double udot(double theta) {     return (-g / l) * sin(theta); }   int main(int argc, char *argv[]) {     double theta, thetanext, u, unext, ku1, ku2, ku3, ku4, kt1, kt2, kt3, kt4;     if (SDL_Init(SDL_INIT_VIDEO) != 0)         return 1;      atexit(SDL_Quit);     SDL_Surface *screen = SDL_SetVideoMode(width, height, 0, SDL_DOUBLEBUF);     if (screen == NULL)         return 2;     //putting inital values to the function     u = u0;     theta = theta0;      while(true)     {         SDL_Event event;         while(SDL_PollEvent(&event))         {             if(event.type == SDL_QUIT)                 return 0;         }          double x = xoffset + l * sin(theta);         double y = yoffset + l * cos(theta);          SDL_LockSurface(screen);          //string hanging position         draw_circle(screen, xoffset, yoffset, 10, 0x0000ff00);         fill_circle(screen, xoffset, yoffset, 10, 0x0000ff00);          //draw string         draw_line(screen, xoffset, yoffset, x, y, 0xff3366ff);          //draw bob's current position         fill_circle(screen, (int)x, (int)y, r, 0xff004400);         draw_circle(screen, (int)x, (int)y, r, 0xff3366ff);          SDL_Delay(300);         //SDL_FreeSurface(screen);         SDL_Flip(screen);          //Numerical integration of equation 1         kt1 = thetadot(u);         kt2 = thetadot(u) + 0.5 * h * kt1;         kt3 = thetadot(u) + 0.5 * h * kt2;         kt4 = thetadot(u) + h * kt3;         thetanext = thetadot(u) + (h / 6) * (kt1 + 2 * kt2 + 2 * kt3 + kt4);          //Numerical integration of equation 2         ku1 = udot(theta);         ku2 = udot(theta) + 0.5 * h * ku1;         ku3 = udot(theta) + 0.5 * h * ku2;         ku4 = udot(theta) + h * ku3;         unext = udot(theta) + (h / 6) * (ku1 + 2 * ku2 + 2 * ku3 + ku4);          //updating values         u = unext;         theta = thetanext;     }     return 0; } And the output is coming as follows Can anybody let me know where it went wrong?","I have the equation of motion of a simple pendulum as  $$\frac{d^2\theta}{dt^2} + \frac{g}{l}\sin \theta = 0$$ It's a second order equation. I am trying to simulate it using a SDL library in C++. I know how to solve first order differential equation using Runge-Kutta method. But I can't combine all these. Can anybody help me to solve the differential equation to get the correct simulation? Update BTW, I am not sure whether it should be posted here or in any stack-exchange forums. But If you could help me or redirect me to any other forums, that would be helpful. I have simulated it using Runge-Kutta method and I am adding my code below. //simplified equations 1 double thetadot(double u) {     return u; }  //simplified equations 2 double udot(double theta) {     return (-g / l) * sin(theta); }   int main(int argc, char *argv[]) {     double theta, thetanext, u, unext, ku1, ku2, ku3, ku4, kt1, kt2, kt3, kt4;     if (SDL_Init(SDL_INIT_VIDEO) != 0)         return 1;      atexit(SDL_Quit);     SDL_Surface *screen = SDL_SetVideoMode(width, height, 0, SDL_DOUBLEBUF);     if (screen == NULL)         return 2;     //putting inital values to the function     u = u0;     theta = theta0;      while(true)     {         SDL_Event event;         while(SDL_PollEvent(&event))         {             if(event.type == SDL_QUIT)                 return 0;         }          double x = xoffset + l * sin(theta);         double y = yoffset + l * cos(theta);          SDL_LockSurface(screen);          //string hanging position         draw_circle(screen, xoffset, yoffset, 10, 0x0000ff00);         fill_circle(screen, xoffset, yoffset, 10, 0x0000ff00);          //draw string         draw_line(screen, xoffset, yoffset, x, y, 0xff3366ff);          //draw bob's current position         fill_circle(screen, (int)x, (int)y, r, 0xff004400);         draw_circle(screen, (int)x, (int)y, r, 0xff3366ff);          SDL_Delay(300);         //SDL_FreeSurface(screen);         SDL_Flip(screen);          //Numerical integration of equation 1         kt1 = thetadot(u);         kt2 = thetadot(u) + 0.5 * h * kt1;         kt3 = thetadot(u) + 0.5 * h * kt2;         kt4 = thetadot(u) + h * kt3;         thetanext = thetadot(u) + (h / 6) * (kt1 + 2 * kt2 + 2 * kt3 + kt4);          //Numerical integration of equation 2         ku1 = udot(theta);         ku2 = udot(theta) + 0.5 * h * ku1;         ku3 = udot(theta) + 0.5 * h * ku2;         ku4 = udot(theta) + h * ku3;         unext = udot(theta) + (h / 6) * (ku1 + 2 * ku2 + 2 * ku3 + ku4);          //updating values         u = unext;         theta = thetanext;     }     return 0; } And the output is coming as follows Can anybody let me know where it went wrong?",,"['integration', 'ordinary-differential-equations', 'numerical-methods', 'simulation']"
13,Expressing an oscillator as a series of ODEs,Expressing an oscillator as a series of ODEs,,"Consider an oscillator satisfying the initial value problem $u''+w^2u=0$, where $u(0)=u_0$, $u'(0)=v_0$. Let $x_1 = u$, $x_2=u'$, and transform the equations given into the form $x' = Ax, x(0)$.  Then using $$\exp(At) = I + \sum_{n=1}^\infty {A^nt^n\over n!}$$ show that $$\exp(At)= I\cos(wt) + A({\sin(wt)\over w})$$ I've gotten as far as substituting $x_1$ and $x_2$ for $u$, but I am not sure what to do next.  I have $x_2'+ w^2x_1=0$.  Any help you can give will, as always, be greatly appreciated.","Consider an oscillator satisfying the initial value problem $u''+w^2u=0$, where $u(0)=u_0$, $u'(0)=v_0$. Let $x_1 = u$, $x_2=u'$, and transform the equations given into the form $x' = Ax, x(0)$.  Then using $$\exp(At) = I + \sum_{n=1}^\infty {A^nt^n\over n!}$$ show that $$\exp(At)= I\cos(wt) + A({\sin(wt)\over w})$$ I've gotten as far as substituting $x_1$ and $x_2$ for $u$, but I am not sure what to do next.  I have $x_2'+ w^2x_1=0$.  Any help you can give will, as always, be greatly appreciated.",,"['ordinary-differential-equations', 'dynamical-systems']"
14,Variation of parameters for a linear second order nonhomogeneous equation,Variation of parameters for a linear second order nonhomogeneous equation,,"I'm using variation of parameters for this problem, and I'm not sure if I'm on the right track. The question is Find a function $v_1$ and $v_2$ such that $v_1(x)e^x+v_2(x)e^{2x}$ is a solution of $y''-3y'+2y=4x+4$ and  $v_1(x)y_1(x)=v_2(x)y_2(x)$ $y''-3y'+2y=4x+4$ First we need to find the roots. $r^2-3r+2=0$ $(r-1)(r-2)=0$ $r=1$ $r=2$ So, the $Y_h$ = $c_1e^x+c_2e^{2x}$ Then we need to find the derivatives and the Wronskian. I am using Cramer's rule. $y_1$ = $e^x$ $y_2$ = $e^{2x}$ $y'_1$ = $e^x$ $y'_2$ = $2e^{2x}$ W[$e^x$ $e^{2x}$] W= $$ \left[   \begin{array}{ c c }      e^x & e^{2x} \\      e^x & 2e^{2x}   \end{array} \right] $$ $2e^{2x} e^x -e^xe^{2x}$ = $e^{3x}$ $W_1$= $$ \left[   \begin{array}{ c c }      0 & e^{2x} \\      4x-4 & 2e^{2x}   \end{array} \right] $$ $2e^{2x}(0)-(4x-4)e^{2x}$=$-(4x-4)e^{2x}$ $W_2$= $$ \left[   \begin{array}{ c c }      e^x & 0 \\      e^x & 4x-4   \end{array} \right]$$ $(4x-4)(e^x)-(0)(e^x)$=$(4x-4)e^{x}$ $\frac{W_1}{W}$  = $\frac{-(4x-4)e^{2x}}{e^{3x}}$ =  $\frac{-(4x-4)}{e^x}$ $\frac{W_2}{W}$  = $\frac{(4x-4)e^{x}}{e^{3x}}$ = $\frac{(4x-4)}{e^{2x}}$ After I calculated the Wronskian through Cramer's Rule I have to find the anti-derivative $\frac{W_1}{W}$ = $\frac{-(4x-4)}{e^x}$ $\int{-(4x-4)}{e^x}\,dx = 4xe^{-x} + C$ $\frac{W_2}{W}$  = $\frac{(4x-4)}{e^{2x}}$ $\int {(4x-4)}{e^{-2x}}\,dx =  (1-2x)e^{-2x} + C$ The result from the anti-derivative along with   $y_1$ = $e^x$ $y_2$ = $e^{2x}$ should be in a formula   $u_1y_1+u_2y_2 = 0$ $u_1y_1+u_2y_2 = 4x-4$ but I think I'm getting the letters confused. So, how do I find the values that equal to each other and satisfy this condition?  Do I solve using the method of undetermined coefficients? EDIT: I have one more piece to this problem. The Theorem states that If $y_1...y_n$ are linearly independent solutions of the reduced form of $y^{n}+P_{n+1}y^{n-1}+...+p_{1}y'+p_0y=q$ then there are functions  $v_1,...v_n$  which satisfy  $y_1v'_1+...+y_nv'_n=0$ I'm just a beginner at proofs. How do I tackle this problem?   I got it. It needed the derivatives of $v_1$ and $v_2$  Therefore,  $v_1(x)=4xe^{-x}$ $v'_1(x)=-4e^{-x}(x-1)$ $v_2(x)=4(-1/2x+1/4)e^{-2x}$ $v_2(x)=-(2x-1)e^{-2x}$ $v'_2(x)=4(x-1)e^{-2x}$ The problem for the theorem just needed the original $v_1(x)$ and $v_2(x)$ Something isn't right...  the answer is $v_1(x)$=$x$+$\frac{1}{2}e^{-x}$ because it needed to satisfy this situation $v_1(x)y_1(x)=v_2(x)y_2(x)$ since $v_1$ would normally represent a Wronskian in this problem, there must be something or some value...that would satisfy $v_1(x)y_1(x)=v_2(x)y_2(x)$ I've done this problem with a study buddy and we found the answer. We were supposed to take the derivatives of $Y_p$ twice and use the rules from linear equations. My study buddy's method:","I'm using variation of parameters for this problem, and I'm not sure if I'm on the right track. The question is Find a function $v_1$ and $v_2$ such that $v_1(x)e^x+v_2(x)e^{2x}$ is a solution of $y''-3y'+2y=4x+4$ and  $v_1(x)y_1(x)=v_2(x)y_2(x)$ $y''-3y'+2y=4x+4$ First we need to find the roots. $r^2-3r+2=0$ $(r-1)(r-2)=0$ $r=1$ $r=2$ So, the $Y_h$ = $c_1e^x+c_2e^{2x}$ Then we need to find the derivatives and the Wronskian. I am using Cramer's rule. $y_1$ = $e^x$ $y_2$ = $e^{2x}$ $y'_1$ = $e^x$ $y'_2$ = $2e^{2x}$ W[$e^x$ $e^{2x}$] W= $$ \left[   \begin{array}{ c c }      e^x & e^{2x} \\      e^x & 2e^{2x}   \end{array} \right] $$ $2e^{2x} e^x -e^xe^{2x}$ = $e^{3x}$ $W_1$= $$ \left[   \begin{array}{ c c }      0 & e^{2x} \\      4x-4 & 2e^{2x}   \end{array} \right] $$ $2e^{2x}(0)-(4x-4)e^{2x}$=$-(4x-4)e^{2x}$ $W_2$= $$ \left[   \begin{array}{ c c }      e^x & 0 \\      e^x & 4x-4   \end{array} \right]$$ $(4x-4)(e^x)-(0)(e^x)$=$(4x-4)e^{x}$ $\frac{W_1}{W}$  = $\frac{-(4x-4)e^{2x}}{e^{3x}}$ =  $\frac{-(4x-4)}{e^x}$ $\frac{W_2}{W}$  = $\frac{(4x-4)e^{x}}{e^{3x}}$ = $\frac{(4x-4)}{e^{2x}}$ After I calculated the Wronskian through Cramer's Rule I have to find the anti-derivative $\frac{W_1}{W}$ = $\frac{-(4x-4)}{e^x}$ $\int{-(4x-4)}{e^x}\,dx = 4xe^{-x} + C$ $\frac{W_2}{W}$  = $\frac{(4x-4)}{e^{2x}}$ $\int {(4x-4)}{e^{-2x}}\,dx =  (1-2x)e^{-2x} + C$ The result from the anti-derivative along with   $y_1$ = $e^x$ $y_2$ = $e^{2x}$ should be in a formula   $u_1y_1+u_2y_2 = 0$ $u_1y_1+u_2y_2 = 4x-4$ but I think I'm getting the letters confused. So, how do I find the values that equal to each other and satisfy this condition?  Do I solve using the method of undetermined coefficients? EDIT: I have one more piece to this problem. The Theorem states that If $y_1...y_n$ are linearly independent solutions of the reduced form of $y^{n}+P_{n+1}y^{n-1}+...+p_{1}y'+p_0y=q$ then there are functions  $v_1,...v_n$  which satisfy  $y_1v'_1+...+y_nv'_n=0$ I'm just a beginner at proofs. How do I tackle this problem?   I got it. It needed the derivatives of $v_1$ and $v_2$  Therefore,  $v_1(x)=4xe^{-x}$ $v'_1(x)=-4e^{-x}(x-1)$ $v_2(x)=4(-1/2x+1/4)e^{-2x}$ $v_2(x)=-(2x-1)e^{-2x}$ $v'_2(x)=4(x-1)e^{-2x}$ The problem for the theorem just needed the original $v_1(x)$ and $v_2(x)$ Something isn't right...  the answer is $v_1(x)$=$x$+$\frac{1}{2}e^{-x}$ because it needed to satisfy this situation $v_1(x)y_1(x)=v_2(x)y_2(x)$ since $v_1$ would normally represent a Wronskian in this problem, there must be something or some value...that would satisfy $v_1(x)y_1(x)=v_2(x)y_2(x)$ I've done this problem with a study buddy and we found the answer. We were supposed to take the derivatives of $Y_p$ twice and use the rules from linear equations. My study buddy's method:",,['ordinary-differential-equations']
15,Solving the differential equation $y'' + 2y' + 2y = 0$ given constraints,Solving the differential equation  given constraints,y'' + 2y' + 2y = 0,"How can I solve this initial value problem? $$ y'' + 2y' + 2y = 0,$$ given $y\,(\pi/4)=2$ and $y'(\pi/4)=0$. I've found $y(t)=e^{-t} \left(C_1\cos t + C_2\sin t \right)$ but I wasn't able to find $C_1$ and $C_2$. How can I find them?","How can I solve this initial value problem? $$ y'' + 2y' + 2y = 0,$$ given $y\,(\pi/4)=2$ and $y'(\pi/4)=0$. I've found $y(t)=e^{-t} \left(C_1\cos t + C_2\sin t \right)$ but I wasn't able to find $C_1$ and $C_2$. How can I find them?",,"['ordinary-differential-equations', 'complex-numbers']"
16,Equilibrium points of the ODE $y'=\sin y−\frac{y}{2}$.,Equilibrium points of the ODE .,y'=\sin y−\frac{y}{2},"Find the equilibrium points of the ODE, and investigate their stability: $$y'=\sin y−\frac{y}{2}.$$ I know the equilibrium points are about $1.9$, $-1.9$, and $0$.  Not sure how to get to that point though. I went ahead and tried to create a graph to find the stability of the problem.  I got this (forgive my poor artwork): https://i.sstatic.net/nG2Cd.png From this I'm inferring that at $+1.9$ and $-1.9$ the solution is stable, and at $0$ it's unstable because of the split.  Would be great if someone confirmed this. Thanks for the help.","Find the equilibrium points of the ODE, and investigate their stability: $$y'=\sin y−\frac{y}{2}.$$ I know the equilibrium points are about $1.9$, $-1.9$, and $0$.  Not sure how to get to that point though. I went ahead and tried to create a graph to find the stability of the problem.  I got this (forgive my poor artwork): https://i.sstatic.net/nG2Cd.png From this I'm inferring that at $+1.9$ and $-1.9$ the solution is stable, and at $0$ it's unstable because of the split.  Would be great if someone confirmed this. Thanks for the help.",,['ordinary-differential-equations']
17,Solving ODE $\frac{(1-2y)y'}{y-y^2}=(x+4)^3$,Solving ODE,\frac{(1-2y)y'}{y-y^2}=(x+4)^3,"Consider the ODE $$\frac{(1-2y)y'}{y-y^2}=(x+4)^3.$$ The answer is supposed to be $$\ln\Bigl(y(1-y)\Bigr)=\frac{(x+4)^4}{4}+C.$$ However, I'm not sure how to get to that answer. I can easily see how to get the right side of the answer, I know that's the integral of $(x+4)^3$.  I expanded the left side to get $$\frac{y'-2yy'}{y-y^2}.$$ I'm assuming I have to do the integral of that somewhere to get $\ln$, but this is where I got stuck.  How do I do the rest of the problem?  Thanks.","Consider the ODE $$\frac{(1-2y)y'}{y-y^2}=(x+4)^3.$$ The answer is supposed to be $$\ln\Bigl(y(1-y)\Bigr)=\frac{(x+4)^4}{4}+C.$$ However, I'm not sure how to get to that answer. I can easily see how to get the right side of the answer, I know that's the integral of $(x+4)^3$.  I expanded the left side to get $$\frac{y'-2yy'}{y-y^2}.$$ I'm assuming I have to do the integral of that somewhere to get $\ln$, but this is where I got stuck.  How do I do the rest of the problem?  Thanks.",,['ordinary-differential-equations']
18,Solve differential equation $ x^2 y''- 4y=0 $,Solve differential equation, x^2 y''- 4y=0 ,"Problem : $ x^2 y'' - 4y=0 $ with condition $y(0)=0,y(1)=1$ Solution :It is  homogeneous ordinary differential equation with variable cofficient Put $x=e^z$ Am I doing right ?",Problem : with condition Solution :It is  homogeneous ordinary differential equation with variable cofficient Put Am I doing right ?," x^2 y'' - 4y=0  y(0)=0,y(1)=1 x=e^z",['ordinary-differential-equations']
19,How fast is the water draining out after 5 min?,How fast is the water draining out after 5 min?,,"The volume $V$, in liters, of water in a water tank after $t$ min it   starts draining, is given by $$V(t)=260(60−t)^2$$ How fast is the   water draining out after 5 min? Do I calculate the volume at $t=0$ and $t=5$ and then take the answer minus each other and then divide the answer to $5$ or do I derive the function and then fill in $5$? Thank you for answers!","The volume $V$, in liters, of water in a water tank after $t$ min it   starts draining, is given by $$V(t)=260(60−t)^2$$ How fast is the   water draining out after 5 min? Do I calculate the volume at $t=0$ and $t=5$ and then take the answer minus each other and then divide the answer to $5$ or do I derive the function and then fill in $5$? Thank you for answers!",,['ordinary-differential-equations']
20,"Solution curves for the equation $y'=max(x,y)$, the larger of the two values $x$ and $y$","Solution curves for the equation , the larger of the two values  and","y'=max(x,y) x y","How do I find and sketch the solution curves for the equation $y'=max(x,y)$? I don't even know what is a closed function form of the expression max(x,y), let alone going about solving the differential equation?! Could someone provide a graphical output of the solution curves? Wolframalpha doesn't seem to be able to do it, and I don't have any mathematical software handy. Any ideas?","How do I find and sketch the solution curves for the equation $y'=max(x,y)$? I don't even know what is a closed function form of the expression max(x,y), let alone going about solving the differential equation?! Could someone provide a graphical output of the solution curves? Wolframalpha doesn't seem to be able to do it, and I don't have any mathematical software handy. Any ideas?",,[]
21,"Using Eigenvalues and Eigenvectors, Find the general solution of the following coupled differential equations. x'=x+y and y'=-x+3y.","Using Eigenvalues and Eigenvectors, Find the general solution of the following coupled differential equations. x'=x+y and y'=-x+3y.",,"Consider the matrix $A=\begin{bmatrix} 1 & 1 \\ -1 & 3 \end{bmatrix}$ I found the eigenvalue $\lambda=2$ with multiplicity $2$. However, the general solution I found degrees with the answer provided by the text. I found the solution $$\begin{bmatrix} x \\ y \end{bmatrix} = A\begin{bmatrix} 1 \\ 1 \end{bmatrix} e^{2t} + B\begin{bmatrix} t \\ t-1 \end{bmatrix}e^{2t}$$ whereas the book finds $$\begin{bmatrix} x \\ y \end{bmatrix} = A\begin{bmatrix} 1 \\ 1 \end{bmatrix}e^{2t} + B\begin{bmatrix} t-1 \\ t \end{bmatrix} e^{2t}$$ What have I done wrong?","Consider the matrix $A=\begin{bmatrix} 1 & 1 \\ -1 & 3 \end{bmatrix}$ I found the eigenvalue $\lambda=2$ with multiplicity $2$. However, the general solution I found degrees with the answer provided by the text. I found the solution $$\begin{bmatrix} x \\ y \end{bmatrix} = A\begin{bmatrix} 1 \\ 1 \end{bmatrix} e^{2t} + B\begin{bmatrix} t \\ t-1 \end{bmatrix}e^{2t}$$ whereas the book finds $$\begin{bmatrix} x \\ y \end{bmatrix} = A\begin{bmatrix} 1 \\ 1 \end{bmatrix}e^{2t} + B\begin{bmatrix} t-1 \\ t \end{bmatrix} e^{2t}$$ What have I done wrong?",,"['ordinary-differential-equations', 'eigenvalues-eigenvectors']"
22,Are all hyperbolic points/orbits unstable?,Are all hyperbolic points/orbits unstable?,,"My understanding of hyperbolic points (correct me if I'm wrong) is that there must be an unstable and stable manifold in the neighborhood of the hyperbolic point. So essentially the hyperbolic point is the saddle point of the manifolds intersecting. Does this mean that all hyperbolic points are unstable? Furthermore, are all hyperbolic orbits also unstable orbits? Thanks!","My understanding of hyperbolic points (correct me if I'm wrong) is that there must be an unstable and stable manifold in the neighborhood of the hyperbolic point. So essentially the hyperbolic point is the saddle point of the manifolds intersecting. Does this mean that all hyperbolic points are unstable? Furthermore, are all hyperbolic orbits also unstable orbits? Thanks!",,"['ordinary-differential-equations', 'dynamical-systems']"
23,Finding all bifurcations in a 2D system,Finding all bifurcations in a 2D system,,"I want to find all bifurcations for the system: \begin{align}                                                                                                                         x' =& -x+y\\                                                                                                                            y' =& \frac{x^2}{1+x^2}-\lambda y                                                                                                      \end{align} So far, I am using the idea that the intersection of the nullclines ($y'=0$ or $x'=0$) gives equilibrium points. So: \begin{align}                                                                                                                         x'=& 0 \implies x=y \\                                                                                                                y'=& 0 \implies y=\frac{x^2}{\lambda(1+x^2)}                                                                                          \end{align} Clearly $(0, 0)$ is an equilibrium point but there is also the possibility of two more equilibrium points when the parabola given by the above equation intersects the line $y=x$. To find the intersection I solved: \begin{align}                                                                                                                         x =& \frac{x^2}{\lambda(1+x^2)}\\                                                                                                     \lambda(1+x^2) =& x\\                                                                                                                 \lambda x^2-x+\lambda =& 0 \\                                                                                                         x =& \frac{1\pm \sqrt{1-4\lambda^2}}{2\lambda}                                                                                        \end{align} I have these two intersection points. Now I need to vary $\lambda$ to find where the curve passing through the intersection points becomes tangent to $y=x$ and hence we would expect one equilibrium point instead of these two at this particular value of $\lambda$. Then continuing the variation of $\lambda$ in the same direction we would expect no equilibrium points from these two. Hence we originally had $2$ equilibrium  points and then they coalesced and finally annihilated each other. This is a saddle-node bifucation. How do I show this for my variation of $\lambda$? Are there any other bifurcations? EDIT: Consider the discriminant of the equation: \begin{align}                                                                                                                           x = \frac{1\pm\sqrt{1-4\lambda^2}}{2\lambda}                                                                                        \end{align} \begin{align}                                                                                                                         1-4\lambda^2 =& 0 \\                                                                                                                  1 =& 4\lambda^2 \\                                                                                                                    1 =& \pm 2\lambda \\                                                                                                                  \pm\frac{1}{2} =& \lambda                                                                                                             \end{align} So, I plotted the system with $\lambda = \frac{1}{2}$: sage: P = plot(x^2/ .5*(1+x^2), 0, 2) + plot(x, 0, 2) We no longer have two bifurcations and instead have one. I was expecting the curves to be tangent. When does it happen that the curves are tangent? Actually I just realized that SAGE was not dividing the $1+x^2$ term, so I added the extra set of parens and everything works as expected!","I want to find all bifurcations for the system: \begin{align}                                                                                                                         x' =& -x+y\\                                                                                                                            y' =& \frac{x^2}{1+x^2}-\lambda y                                                                                                      \end{align} So far, I am using the idea that the intersection of the nullclines ($y'=0$ or $x'=0$) gives equilibrium points. So: \begin{align}                                                                                                                         x'=& 0 \implies x=y \\                                                                                                                y'=& 0 \implies y=\frac{x^2}{\lambda(1+x^2)}                                                                                          \end{align} Clearly $(0, 0)$ is an equilibrium point but there is also the possibility of two more equilibrium points when the parabola given by the above equation intersects the line $y=x$. To find the intersection I solved: \begin{align}                                                                                                                         x =& \frac{x^2}{\lambda(1+x^2)}\\                                                                                                     \lambda(1+x^2) =& x\\                                                                                                                 \lambda x^2-x+\lambda =& 0 \\                                                                                                         x =& \frac{1\pm \sqrt{1-4\lambda^2}}{2\lambda}                                                                                        \end{align} I have these two intersection points. Now I need to vary $\lambda$ to find where the curve passing through the intersection points becomes tangent to $y=x$ and hence we would expect one equilibrium point instead of these two at this particular value of $\lambda$. Then continuing the variation of $\lambda$ in the same direction we would expect no equilibrium points from these two. Hence we originally had $2$ equilibrium  points and then they coalesced and finally annihilated each other. This is a saddle-node bifucation. How do I show this for my variation of $\lambda$? Are there any other bifurcations? EDIT: Consider the discriminant of the equation: \begin{align}                                                                                                                           x = \frac{1\pm\sqrt{1-4\lambda^2}}{2\lambda}                                                                                        \end{align} \begin{align}                                                                                                                         1-4\lambda^2 =& 0 \\                                                                                                                  1 =& 4\lambda^2 \\                                                                                                                    1 =& \pm 2\lambda \\                                                                                                                  \pm\frac{1}{2} =& \lambda                                                                                                             \end{align} So, I plotted the system with $\lambda = \frac{1}{2}$: sage: P = plot(x^2/ .5*(1+x^2), 0, 2) + plot(x, 0, 2) We no longer have two bifurcations and instead have one. I was expecting the curves to be tangent. When does it happen that the curves are tangent? Actually I just realized that SAGE was not dividing the $1+x^2$ term, so I added the extra set of parens and everything works as expected!",,"['ordinary-differential-equations', 'bifurcation']"
24,Question about linear non-autonomous ode,Question about linear non-autonomous ode,,"I am currently learning about ode's and I am on the topic of linear non-autonomous ode's. The professor is deriving the solution to the following ode using some integrating factor $I$. $$\frac{dx}{dt} = A(t)x+B(t)$$ So these are the steps that he makes in finding $x$. $$\begin{align} I\left(\frac{dx}{dt} - Ax = B \right) \\ I\frac{dx}{dt} - AIx = IB \\ I\frac{dx}{dt} - \frac{dI}{dt} x = IB \\ d(Ix) = IB \\ \frac{dI}{dt} = -AI \end{align}$$ I understand all of those steps and now, since this a simple ode we can separate it and arrive at solution for $I$ as $$I = \exp (\int -Adt) = e^{-\int A}$$ Now, takes this solution of $I$ and uses it in $d(Ix) = IB$ by integrating both sides and subbing in $I$. $$\begin{align} Ix &= \int IB \\ x &= \frac{1}{I} \int IB \\ x &= e^{\int A} (\int B e^{-\int A}) & \text{?!} \\ \end{align}$$ That last bit is where my confusion is. How did he arrive at the last step because if we sub in $I$, should it not be $\frac{1}{e^{-\int A}}$? Where did the negative go and why is it reciprocal? Thanks!","I am currently learning about ode's and I am on the topic of linear non-autonomous ode's. The professor is deriving the solution to the following ode using some integrating factor $I$. $$\frac{dx}{dt} = A(t)x+B(t)$$ So these are the steps that he makes in finding $x$. $$\begin{align} I\left(\frac{dx}{dt} - Ax = B \right) \\ I\frac{dx}{dt} - AIx = IB \\ I\frac{dx}{dt} - \frac{dI}{dt} x = IB \\ d(Ix) = IB \\ \frac{dI}{dt} = -AI \end{align}$$ I understand all of those steps and now, since this a simple ode we can separate it and arrive at solution for $I$ as $$I = \exp (\int -Adt) = e^{-\int A}$$ Now, takes this solution of $I$ and uses it in $d(Ix) = IB$ by integrating both sides and subbing in $I$. $$\begin{align} Ix &= \int IB \\ x &= \frac{1}{I} \int IB \\ x &= e^{\int A} (\int B e^{-\int A}) & \text{?!} \\ \end{align}$$ That last bit is where my confusion is. How did he arrive at the last step because if we sub in $I$, should it not be $\frac{1}{e^{-\int A}}$? Where did the negative go and why is it reciprocal? Thanks!",,"['calculus', 'ordinary-differential-equations']"
25,How to solve $a \frac{d^2 y}{d x}+b \frac{d y}{d x} = f(y)$?,How to solve ?,a \frac{d^2 y}{d x}+b \frac{d y}{d x} = f(y),"Let $a,b$ be real numbers and $y$ is a function of $x$. $f$ is a given function. How to solve the ODE : $a \dfrac{d^2 y}{d x}+b \dfrac{d y}{d x} = f(y)$ ? Can it be done in closed form ?","Let $a,b$ be real numbers and $y$ is a function of $x$. $f$ is a given function. How to solve the ODE : $a \dfrac{d^2 y}{d x}+b \dfrac{d y}{d x} = f(y)$ ? Can it be done in closed form ?",,"['ordinary-differential-equations', 'closed-form']"
26,How to determine the starting values for linear multistep methods?,How to determine the starting values for linear multistep methods?,,"I am so confused with how to determine the starting values for linear multistep methods. I have searched the wiki page for linear multistep method . And it says that for Two-step Adams–Bashforth , the starting values are just got by Euler's method . I have also found this page . And the case is that the exact solution is already known. So my question is that: for common cases, how to determine the starting values?","I am so confused with how to determine the starting values for linear multistep methods. I have searched the wiki page for linear multistep method . And it says that for Two-step Adams–Bashforth , the starting values are just got by Euler's method . I have also found this page . And the case is that the exact solution is already known. So my question is that: for common cases, how to determine the starting values?",,"['ordinary-differential-equations', 'numerical-methods']"
27,Solve the second order differential equation.,Solve the second order differential equation.,,Find a general solution to the equation: $u''-e^tu'-e^tu=1$.,Find a general solution to the equation: $u''-e^tu'-e^tu=1$.,,['ordinary-differential-equations']
28,ODE's involving distributions or radon measures,ODE's involving distributions or radon measures,,"Well I would like to know an approach (method) to solve ""singular"" ODE's in a non-formal way. I seek for a method other (simpler) than   the parameters variation, Laplace transform. The equation would be  $$Ly=\delta$$ Suppose that we have solutions of the homogeneous problem.","Well I would like to know an approach (method) to solve ""singular"" ODE's in a non-formal way. I seek for a method other (simpler) than   the parameters variation, Laplace transform. The equation would be  $$Ly=\delta$$ Suppose that we have solutions of the homogeneous problem.",,['ordinary-differential-equations']
29,PDE initial value problem,PDE initial value problem,,"Show that the solution of the initial value problem for  $u_t+u_x=\cos ^2 u$ is given by $u(x,t)=\tan^{-1} \{ \tan [u_o(x-t)]+t\}$, where $u_0(x)$ is the initial condition. My attempts at a solution: I first tried directly taking the partial derivatives of $u(x,t)$ to plug them in and verify, but I got stuck on how I would do that with the $u_o(x-t)$ part of $u(x,t)$. I then tried separation of variables, but I couldn't successfully separate the variables $x$ and $t$. My most recent attempt involved Laplace transform. I got to this: $U_x(x,s)+sU(x,s)=\frac{2}{s(s^2+4)}+u_0(x)$ but didn't know how to proceed (I was trying to teach myself). Which method would you use? Also, could you please show the first few steps of your method, especially if it's one that I tried and got stuck on? Thanks!","Show that the solution of the initial value problem for  $u_t+u_x=\cos ^2 u$ is given by $u(x,t)=\tan^{-1} \{ \tan [u_o(x-t)]+t\}$, where $u_0(x)$ is the initial condition. My attempts at a solution: I first tried directly taking the partial derivatives of $u(x,t)$ to plug them in and verify, but I got stuck on how I would do that with the $u_o(x-t)$ part of $u(x,t)$. I then tried separation of variables, but I couldn't successfully separate the variables $x$ and $t$. My most recent attempt involved Laplace transform. I got to this: $U_x(x,s)+sU(x,s)=\frac{2}{s(s^2+4)}+u_0(x)$ but didn't know how to proceed (I was trying to teach myself). Which method would you use? Also, could you please show the first few steps of your method, especially if it's one that I tried and got stuck on? Thanks!",,"['ordinary-differential-equations', 'partial-differential-equations', 'laplace-transform']"
30,"Are there real numbers a and b such that $f(x,y,t) = x^a t^b$ satisfies the heat equation?",Are there real numbers a and b such that  satisfies the heat equation?,"f(x,y,t) = x^a t^b","The question is in the title. The heat equation is as follows: $$ \frac{\partial f}{\partial t} = k \left( \frac{\partial^2 f}{\partial x^2} +  \frac{\partial^2 f}{\partial y^2} \right),\quad k\in\mathbb{R} $$ Attempt at solution Plugging the requested form into the above equation yields: $$ \frac{\partial f}{\partial t} = b\ t^{b-1} x^a\\ \frac{\partial^2 f}{\partial x^2} = a (a-1)\ t^b x^{a-2}\\ \frac{\partial^2 f}{\partial y^2} = 0 $$ Which leads to showing that: $$ b\ x^2 = k\ a(a-1)\ t $$ I'm not sure how to proceed from this point. Is this the correct procedure to solve this problem? Thanks!","The question is in the title. The heat equation is as follows: $$ \frac{\partial f}{\partial t} = k \left( \frac{\partial^2 f}{\partial x^2} +  \frac{\partial^2 f}{\partial y^2} \right),\quad k\in\mathbb{R} $$ Attempt at solution Plugging the requested form into the above equation yields: $$ \frac{\partial f}{\partial t} = b\ t^{b-1} x^a\\ \frac{\partial^2 f}{\partial x^2} = a (a-1)\ t^b x^{a-2}\\ \frac{\partial^2 f}{\partial y^2} = 0 $$ Which leads to showing that: $$ b\ x^2 = k\ a(a-1)\ t $$ I'm not sure how to proceed from this point. Is this the correct procedure to solve this problem? Thanks!",,"['ordinary-differential-equations', 'multivariable-calculus', 'partial-derivative']"
31,Differential equations math help?,Differential equations math help?,,I have the equation $y' \sin x=y \ln y$. I told my teacher that we can solve if with separate variables method but he told me that we cant do that. He didn't explain why. Can you tell me why?,I have the equation $y' \sin x=y \ln y$. I told my teacher that we can solve if with separate variables method but he told me that we cant do that. He didn't explain why. Can you tell me why?,,['ordinary-differential-equations']
32,How do we know which component belongs to which part in a separable differential equation,How do we know which component belongs to which part in a separable differential equation,,"Take for instance dP/dt = kP We get after separating: dP/P = kdt, but why shouldn't it be dP/kP = dt instead, mathematically it doesn't make sense to say that k must belong absolutely to the right hand side of the equation.","Take for instance dP/dt = kP We get after separating: dP/P = kdt, but why shouldn't it be dP/kP = dt instead, mathematically it doesn't make sense to say that k must belong absolutely to the right hand side of the equation.",,['ordinary-differential-equations']
33,Equation of Motion,Equation of Motion,,So I have an equation of motion with an additional viscous force shown below: $ \frac{d^2x}{dt^2} = x^3 - x^5 - \frac{dx}{dt} $ And the question is Rewrite as a system for x(t) and v(t) . I don't even understand how to begin this problem. Any ideas?,So I have an equation of motion with an additional viscous force shown below: $ \frac{d^2x}{dt^2} = x^3 - x^5 - \frac{dx}{dt} $ And the question is Rewrite as a system for x(t) and v(t) . I don't even understand how to begin this problem. Any ideas?,,['ordinary-differential-equations']
34,Functions differentiable on {$z \in \mathbb{C}: 0 < |z| < 1$},Functions differentiable on {},z \in \mathbb{C}: 0 < |z| < 1,"This is a past exam question from a Complex Analysis exam paper.. Prove or disprove that there exists a function $f$ differentiable on {$z \in \mathbb{C}: 0 <|z|<1$} such that $(i) \displaystyle\lim_{z\rightarrow0}|f(z)|=\infty$ $(ii) \displaystyle\lim_{z\rightarrow0} zf(z)=0$ Im not really sure where to go with this type of question, any help would be greatly appreciated.","This is a past exam question from a Complex Analysis exam paper.. Prove or disprove that there exists a function $f$ differentiable on {$z \in \mathbb{C}: 0 <|z|<1$} such that $(i) \displaystyle\lim_{z\rightarrow0}|f(z)|=\infty$ $(ii) \displaystyle\lim_{z\rightarrow0} zf(z)=0$ Im not really sure where to go with this type of question, any help would be greatly appreciated.",,"['complex-analysis', 'ordinary-differential-equations']"
35,Differential Equation: Modifying Particular Solution,Differential Equation: Modifying Particular Solution,,"For a particular solution of $$ y^{(4)} - y''' - y'' + y' = t^2 + 4 + te^t$$ The solution to the homogeneous solution is represented by the characteristic equation: $$ r(r-1)^2 (r+1)$$ so the solutions of the homogeneous solution are:  $ 0,-1$ and $1$ with multiplicity 2. So the homogeneous solution will have the form: $$ y_h = Ae^t + Bte^t + Ce^{-t} + D$$ As for the particular solution, I think it will have the form of $$ y_p = A + Bt + Ct^2 + D + Ee^t + Ete^t$$ and then modify it so that it doesn't overlap with $y_h$. I am not sure how to go from here. (The question is merely looking for the ""form"" of the particular solution)","For a particular solution of $$ y^{(4)} - y''' - y'' + y' = t^2 + 4 + te^t$$ The solution to the homogeneous solution is represented by the characteristic equation: $$ r(r-1)^2 (r+1)$$ so the solutions of the homogeneous solution are:  $ 0,-1$ and $1$ with multiplicity 2. So the homogeneous solution will have the form: $$ y_h = Ae^t + Bte^t + Ce^{-t} + D$$ As for the particular solution, I think it will have the form of $$ y_p = A + Bt + Ct^2 + D + Ee^t + Ete^t$$ and then modify it so that it doesn't overlap with $y_h$. I am not sure how to go from here. (The question is merely looking for the ""form"" of the particular solution)",,['ordinary-differential-equations']
36,Solving a differential equation using guess and verify,Solving a differential equation using guess and verify,,"I need to solve for an explicit expression of $f(x)$ where $f$ satisfies $$f(x)=x-\frac{x}{n-1}f'(x),\tag{1}$$ where $n$ is a constant. The hint says that we can guess $$f(x)=ax^b,$$ so that $$f'(x)=abx^{b-1}.$$ Substituting the guessed form into $(1)$, we get $$ax^b=x-\frac{1}{n-1}abx^b.\tag{2}$$ I know that the final solution is $b=1$ and $a=\frac{n-1}{n}$. My questions are How to get from $(2)$ to the solution. In particular, how do we know that $b=1$ (I'm able to solve for $a$ from there)? Is there another way to get the solution directly from $(1)$ without guessing and verifying?","I need to solve for an explicit expression of $f(x)$ where $f$ satisfies $$f(x)=x-\frac{x}{n-1}f'(x),\tag{1}$$ where $n$ is a constant. The hint says that we can guess $$f(x)=ax^b,$$ so that $$f'(x)=abx^{b-1}.$$ Substituting the guessed form into $(1)$, we get $$ax^b=x-\frac{1}{n-1}abx^b.\tag{2}$$ I know that the final solution is $b=1$ and $a=\frac{n-1}{n}$. My questions are How to get from $(2)$ to the solution. In particular, how do we know that $b=1$ (I'm able to solve for $a$ from there)? Is there another way to get the solution directly from $(1)$ without guessing and verifying?",,['ordinary-differential-equations']
37,Solving a higher order differential equation,Solving a higher order differential equation,,"I am trying to learn how to solve higher order ODES, but not really getting it and getting really long answers which I don't think are correct. So i have been given $x'''-x''-x'+x=tcost$ and after lots of working out and finding the solution to the complementary and particular parts i have got the answer as $\displaystyle x(t)=x_c(t)+x_p(t)$ $=c_1/e^t+c_2e^t+c_3e^tt-\frac{\sin(t)}{2}-\frac{1}{4}t\sin(t)-\frac{\cos(t)}{4}+\frac{1}{4}t\cos(t)$ I assume this answer is too long and thus not correct? Any help much appreciated! $\frac{3ab^2}{12ab}$ Thank you","I am trying to learn how to solve higher order ODES, but not really getting it and getting really long answers which I don't think are correct. So i have been given $x'''-x''-x'+x=tcost$ and after lots of working out and finding the solution to the complementary and particular parts i have got the answer as $\displaystyle x(t)=x_c(t)+x_p(t)$ $=c_1/e^t+c_2e^t+c_3e^tt-\frac{\sin(t)}{2}-\frac{1}{4}t\sin(t)-\frac{\cos(t)}{4}+\frac{1}{4}t\cos(t)$ I assume this answer is too long and thus not correct? Any help much appreciated! $\frac{3ab^2}{12ab}$ Thank you",,['ordinary-differential-equations']
38,Non-degenerate solutions to constant Hamiltonian flow,Non-degenerate solutions to constant Hamiltonian flow,,"As I'm trying to work my way through Dietmar Salamon's ""Notes on Floer Homology"", I'm having trouble with the very first exercise. Let $(M, \omega)$ be a compact symplectic manifold. Let $H$ be a real function on $M$, let $X$ be the vector field associated to $dH$ under the isomorphism $TM \simeq T^{*}M$ induced by $\omega$. Let $x \in M$ be a critical point for $H$, ie. $dH(x) = 0$. If $\phi _{t}: M \times \mathbb{R} \rightarrow M$ is the flow associated to $X$ (that is, $\frac{\partial}{\partial t} \phi _{t} = X \circ \phi_{t}$), then $x$ is a fixed point of this flow. In particular $\phi_{1}(x) = x$. We will say that $x$ is non-degenerate if $det(id - d\phi_{1}(x)) \neq 0$. This happens exactly when $d\phi_{1}(x)$ has no fixed vectors. The problem is as follows. Show that under these assumptions $x$ is also a non-degenerate critical point for $H$. One possible way to state that is that in any local coordinate system $x_{i}$ around $x$, the matrix $(\frac{\partial^{2}}{\partial x_{i} \partial x_{j}} H) _{i, j}$ is non-singular. I tried to reason as follows. Since $X(x) = 0$, infinitesimally at time $0$ and around $x$ points are (up to first order) not moved by $\phi$ at all. However, as I let the flow run for one unit of time I perform some form of ""integration"" that makes the second order changes by $\phi$ ""go up an order"" and become visible in $d\phi_{1}$. Thus, I should interpret the condition that $d\phi_{1}$ has no fixed vectors as a sing that $X = dH$ moves all vectors around $x$ in a second-order change, ie. $dH$ is non-degenerate. I was trying to formalize the ""implication"" $(\frac{\partial}{\partial t} \phi_{t} = X \circ \phi_{t}) \  \Rightarrow  \ \phi_{1} = \int\limits_{0}^{1} X \circ \phi_{t} \ dt$ so that later I could differentiate both sides with respect to $x$, but I quickly run into trouble because I am not working in the euclidean space, where - up till now - I have always ""gotten by"" using coordinate-free descriptions, since the problem I worked on were rather simple-minded. I would be very interested in a coordinate-free and proof with coordinates, but it would be most useful if it was formal, because I think my problems stem from a large lack of experiance with these kinds of problems. Feel free to retag the question as needed.","As I'm trying to work my way through Dietmar Salamon's ""Notes on Floer Homology"", I'm having trouble with the very first exercise. Let $(M, \omega)$ be a compact symplectic manifold. Let $H$ be a real function on $M$, let $X$ be the vector field associated to $dH$ under the isomorphism $TM \simeq T^{*}M$ induced by $\omega$. Let $x \in M$ be a critical point for $H$, ie. $dH(x) = 0$. If $\phi _{t}: M \times \mathbb{R} \rightarrow M$ is the flow associated to $X$ (that is, $\frac{\partial}{\partial t} \phi _{t} = X \circ \phi_{t}$), then $x$ is a fixed point of this flow. In particular $\phi_{1}(x) = x$. We will say that $x$ is non-degenerate if $det(id - d\phi_{1}(x)) \neq 0$. This happens exactly when $d\phi_{1}(x)$ has no fixed vectors. The problem is as follows. Show that under these assumptions $x$ is also a non-degenerate critical point for $H$. One possible way to state that is that in any local coordinate system $x_{i}$ around $x$, the matrix $(\frac{\partial^{2}}{\partial x_{i} \partial x_{j}} H) _{i, j}$ is non-singular. I tried to reason as follows. Since $X(x) = 0$, infinitesimally at time $0$ and around $x$ points are (up to first order) not moved by $\phi$ at all. However, as I let the flow run for one unit of time I perform some form of ""integration"" that makes the second order changes by $\phi$ ""go up an order"" and become visible in $d\phi_{1}$. Thus, I should interpret the condition that $d\phi_{1}$ has no fixed vectors as a sing that $X = dH$ moves all vectors around $x$ in a second-order change, ie. $dH$ is non-degenerate. I was trying to formalize the ""implication"" $(\frac{\partial}{\partial t} \phi_{t} = X \circ \phi_{t}) \  \Rightarrow  \ \phi_{1} = \int\limits_{0}^{1} X \circ \phi_{t} \ dt$ so that later I could differentiate both sides with respect to $x$, but I quickly run into trouble because I am not working in the euclidean space, where - up till now - I have always ""gotten by"" using coordinate-free descriptions, since the problem I worked on were rather simple-minded. I would be very interested in a coordinate-free and proof with coordinates, but it would be most useful if it was formal, because I think my problems stem from a large lack of experiance with these kinds of problems. Feel free to retag the question as needed.",,"['ordinary-differential-equations', 'symplectic-geometry', 'gradient-flows']"
39,How to solve the differential equation of second order?,How to solve the differential equation of second order?,,How to solve the differential equation $y \dfrac {d^2y} {dx^2} -{(\dfrac {dy} {dx}} ) ^2=0$ . thank you for your time.,How to solve the differential equation $y \dfrac {d^2y} {dx^2} -{(\dfrac {dy} {dx}} ) ^2=0$ . thank you for your time.,,['ordinary-differential-equations']
40,Replacing large-dimensional ODE systems with one PDE,Replacing large-dimensional ODE systems with one PDE,,Is it possible to replace a large-dimensional system of differential equations with one partial differential equation?,Is it possible to replace a large-dimensional system of differential equations with one partial differential equation?,,[]
41,Legendre Polynomials: proofs $\int_{-1}^1P_n^2(x)dx=\frac{2}{(2n+1)}$,Legendre Polynomials: proofs,\int_{-1}^1P_n^2(x)dx=\frac{2}{(2n+1)},"Does any one know, how to compute any of those two things? The relationship between Legendre polynomials and Shifted Legendre Polynomials. $\displaystyle\int_{-1}^1P_n^2(x)dx=\dfrac{2}{(2n+1)}$ for $n\geq0$ . I tried to use Bonnet's equation: $(2n-1)xP_{n-1}(x)=nP_n(x)+(n-1)P_{n-2}(x)$ but I couldn't move. Thanks :) Edit: The second problem refers to regular Legendre Polynomials.","Does any one know, how to compute any of those two things? The relationship between Legendre polynomials and Shifted Legendre Polynomials. for . I tried to use Bonnet's equation: but I couldn't move. Thanks :) Edit: The second problem refers to regular Legendre Polynomials.",\displaystyle\int_{-1}^1P_n^2(x)dx=\dfrac{2}{(2n+1)} n\geq0 (2n-1)xP_{n-1}(x)=nP_n(x)+(n-1)P_{n-2}(x),"['ordinary-differential-equations', 'polynomials']"
42,Stability and Homogeneous Equations?,Stability and Homogeneous Equations?,,"I’m having some trouble understanding the concept of stability in the context of a homogenous system $x’ = Ax$. According to my textbook, a system is stable if it has a fundamental matrix whose entries all remain bounded as $t \rightarrow + \infty$. Can someone please explain what this actually means. Also why is it that if A has distinct real eigenvalues, then $x’(t) = Ax(t)$ is stable iff all eigenvalues are negative. This is a theorem that I don’t quite understand either. Please keep explanations simple if at all possible.","I’m having some trouble understanding the concept of stability in the context of a homogenous system $x’ = Ax$. According to my textbook, a system is stable if it has a fundamental matrix whose entries all remain bounded as $t \rightarrow + \infty$. Can someone please explain what this actually means. Also why is it that if A has distinct real eigenvalues, then $x’(t) = Ax(t)$ is stable iff all eigenvalues are negative. This is a theorem that I don’t quite understand either. Please keep explanations simple if at all possible.",,['ordinary-differential-equations']
43,Homogeneous equation,Homogeneous equation,,I am trying to solve the following homogeneous equation: Thanks for your tips $xy^3y′=2(y^4+x^4)$ I think this isHomogeneous of order4 => $xy^3dy/dx=2(y^4+x^4/1)$ => $xy^3dy=2(x^4+y^4)dx$ => $xy^3dy-2(x^4+y^4)dx=0$ I do not know how to continued,I am trying to solve the following homogeneous equation: Thanks for your tips $xy^3y′=2(y^4+x^4)$ I think this isHomogeneous of order4 => $xy^3dy/dx=2(y^4+x^4/1)$ => $xy^3dy=2(x^4+y^4)dx$ => $xy^3dy-2(x^4+y^4)dx=0$ I do not know how to continued,,['ordinary-differential-equations']
44,Is there a simple solution to this (ordinary) differential equation?,Is there a simple solution to this (ordinary) differential equation?,,"I'm trying to solve the following differential equation: $$ \frac{dy}{dx} = - \frac{3x + 2y}{2y}. $$ It looks pretty simple, yet it's not separable, linear, or exact.  It is of the form $$ \frac{dy}{dx} = f(y/x). $$ I could do the substitution $v = y/x$, and I know it would look pretty ugly, but is there a better or simpler method?","I'm trying to solve the following differential equation: $$ \frac{dy}{dx} = - \frac{3x + 2y}{2y}. $$ It looks pretty simple, yet it's not separable, linear, or exact.  It is of the form $$ \frac{dy}{dx} = f(y/x). $$ I could do the substitution $v = y/x$, and I know it would look pretty ugly, but is there a better or simpler method?",,['ordinary-differential-equations']
45,Identity of two differential equations,Identity of two differential equations,,"Today I've encountered this proof of Euler's Formula . The proof basically says that $e^{iz}$ and $(\cos z + i \sin z)$ are both solutions of the differential equation $f'(z) = i f(z)$ and do not differ by a constant. Everything is clear to me, however I have a doubt: isn't it necessary to demonstrate that if: $$ f'(x) = k f(x) \\ g'(x) = k g(x) $$ Then $f' = g'$? If so, how can I proceed to build a proof?","Today I've encountered this proof of Euler's Formula . The proof basically says that $e^{iz}$ and $(\cos z + i \sin z)$ are both solutions of the differential equation $f'(z) = i f(z)$ and do not differ by a constant. Everything is clear to me, however I have a doubt: isn't it necessary to demonstrate that if: $$ f'(x) = k f(x) \\ g'(x) = k g(x) $$ Then $f' = g'$? If so, how can I proceed to build a proof?",,"['ordinary-differential-equations', 'derivatives']"
46,Difference between a Hamilton and a gradient vector field,Difference between a Hamilton and a gradient vector field,,"I have been asked to consider a set of vector fields and determine whether these vectorfields are Hamilton or gradient and if possible to determine a Hamilton or potential function. I am a bit confused with the definitions of these concepts and can't find them clearly explained anywhere. For a system $x' = f(x,y)$ and $y' = g(x,y)$ I believe it is hamiltonian if $\partial_y f= -\partial_x g $, which is just some kind of exactness of the d.e.? But consider for example: $$ x' = y \\ y' =-x, $$ of course the solutions are cosines/sines but bare with me. A Hamiltonian $H = x^2 + y^2 = C$ satisfies $\partial H/\partial y = y $and $-\partial H/\partial x = -x $ but it also satisfies $x'' = -x = - \partial V /\partial x$ and $y'' = -y =- \partial V/\partial y$ for V the same function as the Hamilton above. I should know this rather easy concept, but I am utterly confused.","I have been asked to consider a set of vector fields and determine whether these vectorfields are Hamilton or gradient and if possible to determine a Hamilton or potential function. I am a bit confused with the definitions of these concepts and can't find them clearly explained anywhere. For a system $x' = f(x,y)$ and $y' = g(x,y)$ I believe it is hamiltonian if $\partial_y f= -\partial_x g $, which is just some kind of exactness of the d.e.? But consider for example: $$ x' = y \\ y' =-x, $$ of course the solutions are cosines/sines but bare with me. A Hamiltonian $H = x^2 + y^2 = C$ satisfies $\partial H/\partial y = y $and $-\partial H/\partial x = -x $ but it also satisfies $x'' = -x = - \partial V /\partial x$ and $y'' = -y =- \partial V/\partial y$ for V the same function as the Hamilton above. I should know this rather easy concept, but I am utterly confused.",,['ordinary-differential-equations']
47,Existence and Uniqueness Theorem,Existence and Uniqueness Theorem,,"I had a question about how to do one of these problems. So here's the question: Given this equation $y'=\frac{-\cos(t)y(t)}{(t+2)(t-1)}+t$, find if the initial conditions $y(0)=10, y(2)=-1, y(-10)=5$ exist. So I think the first step is just to take the partial derivative with respect to y which gives me: $$y''=\frac{-\cos(t)y'(t)}{(t+2)(t-1)}$$ So the 1'st equation doesn't exist at $t=-2,1$ and the partial derivative doesn't exist at $t=-2,1$ ....so do I conclude that all the initial values exists since none of them are $y(-2)$ or $y(1)$. Don't really know how to do this whole existence and uniqueness thing....so am I right or completely off track?","I had a question about how to do one of these problems. So here's the question: Given this equation $y'=\frac{-\cos(t)y(t)}{(t+2)(t-1)}+t$, find if the initial conditions $y(0)=10, y(2)=-1, y(-10)=5$ exist. So I think the first step is just to take the partial derivative with respect to y which gives me: $$y''=\frac{-\cos(t)y'(t)}{(t+2)(t-1)}$$ So the 1'st equation doesn't exist at $t=-2,1$ and the partial derivative doesn't exist at $t=-2,1$ ....so do I conclude that all the initial values exists since none of them are $y(-2)$ or $y(1)$. Don't really know how to do this whole existence and uniqueness thing....so am I right or completely off track?",,['ordinary-differential-equations']
48,$ y=y_1(t)+y_2(t)$ is solution of $y'+p(t)y=g(t)$ if $y=y_1(t)$ is one of $y'+p(t)y=0$ and $ y=y_2(t)$ is one of $y'+p(t)y=g(t)$,is solution of  if  is one of  and  is one of, y=y_1(t)+y_2(t) y'+p(t)y=g(t) y=y_1(t) y'+p(t)y=0  y=y_2(t) y'+p(t)y=g(t),Let $y=y_1(t)$ be a solution of $y'+p(t)y=0$ and let $ y=y_2(t)$ be a solution of $y'+p(t)y=g(t)$. How can we show that $ y=y_1(t)+y_2(t)$ is also a solution of $y'+p(t)y=g(t)$? I'm not really sure how to approach the problem. It's in the section dealing with differences between linear and nonlinear equations.,Let $y=y_1(t)$ be a solution of $y'+p(t)y=0$ and let $ y=y_2(t)$ be a solution of $y'+p(t)y=g(t)$. How can we show that $ y=y_1(t)+y_2(t)$ is also a solution of $y'+p(t)y=g(t)$? I'm not really sure how to approach the problem. It's in the section dealing with differences between linear and nonlinear equations.,,['ordinary-differential-equations']
49,non-linear ordinary differential equation,non-linear ordinary differential equation,,"Studying some Newtonian mechanics, I've encountered this differential equation : $y'+a y^2=b$ where $a,b$ are constants. how could we solve it ? (I trying to get an algebraic solution)","Studying some Newtonian mechanics, I've encountered this differential equation : $y'+a y^2=b$ where $a,b$ are constants. how could we solve it ? (I trying to get an algebraic solution)",,['ordinary-differential-equations']
50,"differential equation : non-homogeneous solution, finding YP","differential equation : non-homogeneous solution, finding YP",,"hi i have a problem for this Differential Equations : $$ \frac{d^{3}y}{dx^3} - 9\frac{dy}{dx} = 10 - 4x $$ i know first we must solve the homogeneous equation: and my result is : $C_1 + C_2e^{3x} + C_3e^{-3x}$ i'm really confused to find yp from $10 - 4x$,  my friend said it must : $(ax+b)x$ my question is : 1. why it's not $c - (ax + b)$, 2. if it same with $c1$ from yh(homogeneous solution ) why we not multiply $c$ with x?     so $yp = cx - (ax + b) $ 3. and why $(ax+b)$ must be multiplied with $x$?? can someone explain me? thanks for anyone helped me.","hi i have a problem for this Differential Equations : $$ \frac{d^{3}y}{dx^3} - 9\frac{dy}{dx} = 10 - 4x $$ i know first we must solve the homogeneous equation: and my result is : $C_1 + C_2e^{3x} + C_3e^{-3x}$ i'm really confused to find yp from $10 - 4x$,  my friend said it must : $(ax+b)x$ my question is : 1. why it's not $c - (ax + b)$, 2. if it same with $c1$ from yh(homogeneous solution ) why we not multiply $c$ with x?     so $yp = cx - (ax + b) $ 3. and why $(ax+b)$ must be multiplied with $x$?? can someone explain me? thanks for anyone helped me.",,"['calculus', 'ordinary-differential-equations']"
51,Differential Equations: Population Problem $dp/dt= 0.5p - 380$,Differential Equations: Population Problem,dp/dt= 0.5p - 380,"I just want to make sure this is right because I'm doing the homework online and I'm on my last attempt and I'm pretty sure I got the other two right yet the computer program said no. First at I have to find the time when the population becomes extinct when $p(0) = 710$. My answer was $2\ln\left(\frac{760}{50}\right)$ and its in months. Then I have to find the initial population if they become extinct after $1$ year. Now does that mean I use $t = 12$ since the first answer is in months? EDIT: When I edited it for the first time I deleted, unintentionally, some information of the title that I've already corrected, sorry.","I just want to make sure this is right because I'm doing the homework online and I'm on my last attempt and I'm pretty sure I got the other two right yet the computer program said no. First at I have to find the time when the population becomes extinct when $p(0) = 710$. My answer was $2\ln\left(\frac{760}{50}\right)$ and its in months. Then I have to find the initial population if they become extinct after $1$ year. Now does that mean I use $t = 12$ since the first answer is in months? EDIT: When I edited it for the first time I deleted, unintentionally, some information of the title that I've already corrected, sorry.",,['ordinary-differential-equations']
52,does it have unique fixed point?,does it have unique fixed point?,,"$p:C[0,1]\rightarrow C[0,1]$ defined by $p(f(x))=\int_{0}^{x} (x-t)f(t)dt$, well, I am getting all constant functions are fixed points, but the answer says that it has unique fixed point. I  got $p(f(x))=f(x)$ so $f'(x)=0$.","$p:C[0,1]\rightarrow C[0,1]$ defined by $p(f(x))=\int_{0}^{x} (x-t)f(t)dt$, well, I am getting all constant functions are fixed points, but the answer says that it has unique fixed point. I  got $p(f(x))=f(x)$ so $f'(x)=0$.",,"['real-analysis', 'ordinary-differential-equations', 'fixed-point-theorems']"
53,Second Order Cosine Differential Equation,Second Order Cosine Differential Equation,,"Can one think of a solution to: $$ \lambda f''(x)=f(x)\cos x$$ s.t. $f(0)=0$ and $f(\frac \pi 2)=0$, $\lambda>0$?","Can one think of a solution to: $$ \lambda f''(x)=f(x)\cos x$$ s.t. $f(0)=0$ and $f(\frac \pi 2)=0$, $\lambda>0$?",,['ordinary-differential-equations']
54,Inequality for boundedness solutions (in Euclidean space),Inequality for boundedness solutions (in Euclidean space),,"Suppose I have some smooth $t$-dependent function $x(t)$ in $\mathbb{R}^n$ for which I have the property \begin{equation} \langle x, \dot{x} \rangle  \; \; \leq C || x||^2  \end{equation} where $\dot{x}$ is the derivative of $x$ and $\langle \cdot, \cdot \rangle$ is the natural dot product. What kind of information does this property then give? I would say something like boundedness but I am worrying that in the kernel of $\langle \cdot, \dot{x} \rangle$ things get unbounded. Any help is welcome!","Suppose I have some smooth $t$-dependent function $x(t)$ in $\mathbb{R}^n$ for which I have the property \begin{equation} \langle x, \dot{x} \rangle  \; \; \leq C || x||^2  \end{equation} where $\dot{x}$ is the derivative of $x$ and $\langle \cdot, \cdot \rangle$ is the natural dot product. What kind of information does this property then give? I would say something like boundedness but I am worrying that in the kernel of $\langle \cdot, \dot{x} \rangle$ things get unbounded. Any help is welcome!",,"['functional-analysis', 'ordinary-differential-equations']"
55,$\frac{\mathrm{d} g(x)}{\mathrm{d}x}=h(x)$ and $\frac{\mathrm{d} h(x)}{\mathrm{d}x}=g(x)$ where $h(x)\neq g(x)$,and  where,\frac{\mathrm{d} g(x)}{\mathrm{d}x}=h(x) \frac{\mathrm{d} h(x)}{\mathrm{d}x}=g(x) h(x)\neq g(x),"Is there any other solution to : $$\frac{\mathrm{d} g(x)}{\mathrm{d}x}=h(x)$$ $$\frac{\mathrm{d} h(x)}{\mathrm{d}x}=g(x)$$ other than $h(x)=g(x)=e^x$? By varying $\alpha,\beta$ in $$\frac{\mathrm{d} g(x)}{\mathrm{d}x}=\alpha h(x)$$ $$\frac{\mathrm{d} h(x)}{\mathrm{d}x}=\beta g(x)$$ is it possible to obtain $(e^x,e^x) , (\sin (x),\cos(x))$ as solutions when $\alpha = 1, \beta=1$ and  $\alpha = 1, \beta=-1$ (without invoking complex analysis) is there any explanation for relationships between $\alpha,\beta$ yielding relationships between $e^x,\sin(x),\cos(x)$?","Is there any other solution to : $$\frac{\mathrm{d} g(x)}{\mathrm{d}x}=h(x)$$ $$\frac{\mathrm{d} h(x)}{\mathrm{d}x}=g(x)$$ other than $h(x)=g(x)=e^x$? By varying $\alpha,\beta$ in $$\frac{\mathrm{d} g(x)}{\mathrm{d}x}=\alpha h(x)$$ $$\frac{\mathrm{d} h(x)}{\mathrm{d}x}=\beta g(x)$$ is it possible to obtain $(e^x,e^x) , (\sin (x),\cos(x))$ as solutions when $\alpha = 1, \beta=1$ and  $\alpha = 1, \beta=-1$ (without invoking complex analysis) is there any explanation for relationships between $\alpha,\beta$ yielding relationships between $e^x,\sin(x),\cos(x)$?",,"['ordinary-differential-equations', 'special-functions']"
56,First order differential equation : $\frac{dy}{dt}+kty(t) = \frac{\sin(\pi t/10)}{\pi}$,First order differential equation :,\frac{dy}{dt}+kty(t) = \frac{\sin(\pi t/10)}{\pi},How to solve the following first order differential equation? $$\dfrac{dy}{dt}+kty(t) = \dfrac{\sin(\pi t/10)}{\pi}$$,How to solve the following first order differential equation? $$\dfrac{dy}{dt}+kty(t) = \dfrac{\sin(\pi t/10)}{\pi}$$,,['ordinary-differential-equations']
57,How can I solve this differential equation? [closed],How can I solve this differential equation? [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question How can I find a solution of the following differential equation: $$\frac{d^2y}{dx^2} =\exp(x^2+ x)$$ Thanks!","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question How can I find a solution of the following differential equation: $$\frac{d^2y}{dx^2} =\exp(x^2+ x)$$ Thanks!",,"['ordinary-differential-equations', 'integration']"
58,Kummer's Equation,Kummer's Equation,,"I'm trying to show that Kummer's equation can be solved by deriving $$xL_{n}^{''}(x)+(1-x)L_{n}^{'}(x)+nL_{n}(x)=0$$ from the Laguerre polynomials: $$g(x,t)=\frac{e^{-xt/(1-t)}}{1-t}=\sum_{n=0}^{\infty}L_{n}(x)\frac{t^n}{n!},$$ where $0<t<1.$ I'm having trouble working this one out.","I'm trying to show that Kummer's equation can be solved by deriving $$xL_{n}^{''}(x)+(1-x)L_{n}^{'}(x)+nL_{n}(x)=0$$ from the Laguerre polynomials: $$g(x,t)=\frac{e^{-xt/(1-t)}}{1-t}=\sum_{n=0}^{\infty}L_{n}(x)\frac{t^n}{n!},$$ where $0<t<1.$ I'm having trouble working this one out.",,['ordinary-differential-equations']
59,Is following system of nonlinear ODEs recognized?,Is following system of nonlinear ODEs recognized?,,"The following system of ODEs – is it recognized as distinct system, with meaningful background and uses? $$\frac{dx}{dt} = - [x(t)]^2 -  x(t)y(t)$$ $$\frac{dy}{dt} = - [y(t)]^2 -  x(t)y(t)$$ This is probably not needed, but initial conditions: $x(t=0) = x_0, \space y(t=0) = y_0$","The following system of ODEs – is it recognized as distinct system, with meaningful background and uses? $$\frac{dx}{dt} = - [x(t)]^2 -  x(t)y(t)$$ $$\frac{dy}{dt} = - [y(t)]^2 -  x(t)y(t)$$ This is probably not needed, but initial conditions: $x(t=0) = x_0, \space y(t=0) = y_0$",,"['reference-request', 'ordinary-differential-equations']"
60,Euler Lagrange equation of $J[y]=\int_0^1 (yy')^2dx$ subject to the constraint $\int_0^1 y^2 dx =3$ [duplicate],Euler Lagrange equation of  subject to the constraint  [duplicate],J[y]=\int_0^1 (yy')^2dx \int_0^1 y^2 dx =3,"This question already has an answer here : Extremising a functional with conditions (1 answer) Closed 3 years ago . Among all the admissible functions $y = y(x)$, find those that extremise the functional   $$J[y] = \int_0^1 (yy')^2dx$$    subject to the constraint $\int_0^1 y^2 dx =3$ and the boundary conditions $y(0)=1, y(1)=2$. Am I correct in saying denoting $F=(yy')^2 + \lambda y^2$. Thus the extrema corresponding to this problem are the extrema for the functional, $$J[y] =\int_0^1 F dx$$ and therefore they are solutions of the Euler-Lagrange equation $$\lambda y -y^2y''-(yy')^2=0.$$ Could some clarify whether my Euler-Lagrange equation is correct. I am pretty confused as to where to go from here. Any help would be grand.","This question already has an answer here : Extremising a functional with conditions (1 answer) Closed 3 years ago . Among all the admissible functions $y = y(x)$, find those that extremise the functional   $$J[y] = \int_0^1 (yy')^2dx$$    subject to the constraint $\int_0^1 y^2 dx =3$ and the boundary conditions $y(0)=1, y(1)=2$. Am I correct in saying denoting $F=(yy')^2 + \lambda y^2$. Thus the extrema corresponding to this problem are the extrema for the functional, $$J[y] =\int_0^1 F dx$$ and therefore they are solutions of the Euler-Lagrange equation $$\lambda y -y^2y''-(yy')^2=0.$$ Could some clarify whether my Euler-Lagrange equation is correct. I am pretty confused as to where to go from here. Any help would be grand.",,"['ordinary-differential-equations', 'calculus-of-variations']"
61,Find a particular solution for the differential equation $5y'' + 8y' + 8y = \cos^2(x)$,Find a particular solution for the differential equation,5y'' + 8y' + 8y = \cos^2(x),"I'm trying to use the method of undetermined coefficients, but I'm not sure what I should guess for $\cos^2(x)$.  I know that you generally want to take the first few derivatives, so: $f(x) = \cos^2(x)$ $f'(x) = -2\cos(x)\sin(x)$ $f''(x) = -2\cos(2x)$ $f^{(3)}(x) = 4\sin(2x)$ (now repeats between cosine and sine) Solving the characteristic equation $5r^2+8r+8 = 0$ gives complementary solution $y_g = c_1e^{-4x/5}\sin(\frac{2\sqrt{6}x}{5})+c_2e^{-4x/5}\cos(\frac{2\sqrt{6}x}{5})$. So a reasonable guess may be: $y_p = A\cos^2(x)+B\cos(x)\sin(x)+C\cos(2x)+D\sin(2x)$ Is this correct? If not, what am I doing wrong?","I'm trying to use the method of undetermined coefficients, but I'm not sure what I should guess for $\cos^2(x)$.  I know that you generally want to take the first few derivatives, so: $f(x) = \cos^2(x)$ $f'(x) = -2\cos(x)\sin(x)$ $f''(x) = -2\cos(2x)$ $f^{(3)}(x) = 4\sin(2x)$ (now repeats between cosine and sine) Solving the characteristic equation $5r^2+8r+8 = 0$ gives complementary solution $y_g = c_1e^{-4x/5}\sin(\frac{2\sqrt{6}x}{5})+c_2e^{-4x/5}\cos(\frac{2\sqrt{6}x}{5})$. So a reasonable guess may be: $y_p = A\cos^2(x)+B\cos(x)\sin(x)+C\cos(2x)+D\sin(2x)$ Is this correct? If not, what am I doing wrong?",,['ordinary-differential-equations']
62,How can I express such function as known functions or power series?,How can I express such function as known functions or power series?,,$$\int_0^x \cfrac{1}{1+\int_0^t \cfrac{1}{2+\int_0^{t_1} \cfrac{1}{3+\int_0^{t_2} \cfrac{1}{\cdots} dt_3} dt_2} dt_1} dt =f(x)$$ $$\int_{0}^{x} \frac{1}{n+h_{n+1}(t)}{d} t=h_n(x)$$ $$h'_n(x)(n+h_{n+1}(x))=1$$ $$h'_{n+1}(x)(n+1+h_{n+2}(x))=1$$ I need to find $ h_1(x)=f(x)$ Please help me how to express $f(x)$ as known functions or power series? Thanks a lot for answers,$$\int_0^x \cfrac{1}{1+\int_0^t \cfrac{1}{2+\int_0^{t_1} \cfrac{1}{3+\int_0^{t_2} \cfrac{1}{\cdots} dt_3} dt_2} dt_1} dt =f(x)$$ $$\int_{0}^{x} \frac{1}{n+h_{n+1}(t)}{d} t=h_n(x)$$ $$h'_n(x)(n+h_{n+1}(x))=1$$ $$h'_{n+1}(x)(n+1+h_{n+2}(x))=1$$ I need to find $ h_1(x)=f(x)$ Please help me how to express $f(x)$ as known functions or power series? Thanks a lot for answers,,"['ordinary-differential-equations', 'special-functions', 'recurrence-relations', 'power-series']"
63,How to solve this linear homogeneous diff equation when A is not constant,How to solve this linear homogeneous diff equation when A is not constant,,"I know how to solve the differential equation $\dot{x} = A x$ when $A$ is a constant $n\times n$ matrix. However, I cannot solve the problem when $A$ also depends on $t$. To be more specific, $A (t)=\left(\begin{array}{cc} 1 & -1/t\\ 1+t & -1 \end{array}\right)$, where $t>0$. I can verify that $x(t)=\left(\begin{array}{c} 1\\ t \end{array}\right)$ is a solution. However, in order to find the fundamental solution, I need another linearly independent solution. I tried to set the other solution to be $\left(\begin{array}{c} y_{1}(t)\\ y_{2}(t) \end{array}\right)$ and plugged it into the equation. Then I got the following: $y_{1}t-y_{2}=\dot{y}_{1}t$ and $y_{1}+y_{1}t-y_{2}=\dot{y}_{2}$. Then, I was stuck. I also tried $(\det\Phi)^{\prime}=trA\det\Phi$ and got nowhere.","I know how to solve the differential equation $\dot{x} = A x$ when $A$ is a constant $n\times n$ matrix. However, I cannot solve the problem when $A$ also depends on $t$. To be more specific, $A (t)=\left(\begin{array}{cc} 1 & -1/t\\ 1+t & -1 \end{array}\right)$, where $t>0$. I can verify that $x(t)=\left(\begin{array}{c} 1\\ t \end{array}\right)$ is a solution. However, in order to find the fundamental solution, I need another linearly independent solution. I tried to set the other solution to be $\left(\begin{array}{c} y_{1}(t)\\ y_{2}(t) \end{array}\right)$ and plugged it into the equation. Then I got the following: $y_{1}t-y_{2}=\dot{y}_{1}t$ and $y_{1}+y_{1}t-y_{2}=\dot{y}_{2}$. Then, I was stuck. I also tried $(\det\Phi)^{\prime}=trA\det\Phi$ and got nowhere.",,['ordinary-differential-equations']
64,Solving differential equations through integration?,Solving differential equations through integration?,,"In ordinary calculus, one can solve a function by taking its ""anti-derivative,"" in a form of integration. Likewise, in differential equations, one can look for solutions by integrating the equation in some way. Is this analogous to ""taking an anti-derivative?"" Does the process have a name, perhaps ""anti-differential?"" And is this made possible (as in the case of taking an anti-derivative) by the fundamental theorem of calculus?","In ordinary calculus, one can solve a function by taking its ""anti-derivative,"" in a form of integration. Likewise, in differential equations, one can look for solutions by integrating the equation in some way. Is this analogous to ""taking an anti-derivative?"" Does the process have a name, perhaps ""anti-differential?"" And is this made possible (as in the case of taking an anti-derivative) by the fundamental theorem of calculus?",,['ordinary-differential-equations']
65,Proving that these functions are proportional,Proving that these functions are proportional,,"This is a past exam question, that I don't have a solution to: Consider the equation: $$ \ddot{x} + p(t) \dot{x} + q(t)x = 0 $$ when $q$ and $p$ are continuous on $\mathbb{R}$, and there is $a \in \mathbb{R}$ such that  $$ \forall t \in \mathbb{R}, \space p(t) \leq -a < 0 $$ Let $x_1(t), x_2(t)$ two nontrivial solutions to the equations, such that: $$ \lim_{t \rightarrow +\infty }(x_1(t)^2 + x_2(t)^2 + \dot{x_1}(t)^2 +\dot{x_2}(t)^2) = 0 $$ Prove that $x_1$ and $x_2$ are proportional. I would love a hint where to start on this one. Thanks!","This is a past exam question, that I don't have a solution to: Consider the equation: $$ \ddot{x} + p(t) \dot{x} + q(t)x = 0 $$ when $q$ and $p$ are continuous on $\mathbb{R}$, and there is $a \in \mathbb{R}$ such that  $$ \forall t \in \mathbb{R}, \space p(t) \leq -a < 0 $$ Let $x_1(t), x_2(t)$ two nontrivial solutions to the equations, such that: $$ \lim_{t \rightarrow +\infty }(x_1(t)^2 + x_2(t)^2 + \dot{x_1}(t)^2 +\dot{x_2}(t)^2) = 0 $$ Prove that $x_1$ and $x_2$ are proportional. I would love a hint where to start on this one. Thanks!",,['ordinary-differential-equations']
66,Solve $x^2 (a - bx) {d^2y \over dx^2} - x (5a - 4bx) {dy \over dx} + 3(2a - bx)y = 6a^2$,Solve,x^2 (a - bx) {d^2y \over dx^2} - x (5a - 4bx) {dy \over dx} + 3(2a - bx)y = 6a^2,What do I substitute here $$ x^2 (a - bx) {d^2y \over dx^2}  - x (5a - 4bx) {dy \over dx} + 3(2a - bx)y = 6a^2 $$ to get it into this form? $$ u^2 {dv^2 \over du^2}  + P_1 u {dv \over du} + P_2 v = F(u) $$ The solution (according to answer sheet): $y(a-bx) = Ax^2 + Bx^3 + C$,What do I substitute here $$ x^2 (a - bx) {d^2y \over dx^2}  - x (5a - 4bx) {dy \over dx} + 3(2a - bx)y = 6a^2 $$ to get it into this form? $$ u^2 {dv^2 \over du^2}  + P_1 u {dv \over du} + P_2 v = F(u) $$ The solution (according to answer sheet): $y(a-bx) = Ax^2 + Bx^3 + C$,,['ordinary-differential-equations']
67,Second order derivatives of a function.,Second order derivatives of a function.,,"We have to use the Hessian to calculate the second order derivatives of a function. While that is okay if the function is mapped from $\mathbb{R}^n$ to $\mathbb{R}$, how does one proceed if it is mapped from $\mathbb{R}^n \longrightarrow \mathbb{R}^m$, where $m > 1$? How does one take the derivative of f with respect to each variable when f is itself in more than one dimension? For example, if there is a function f : $\mathbb{R}^2 \longrightarrow \mathbb{R}^3$ with $(x,y)$ mapped to $(x^2 + y, y^3, \cos(y))$, how does one calculate the Hessian? Thank you","We have to use the Hessian to calculate the second order derivatives of a function. While that is okay if the function is mapped from $\mathbb{R}^n$ to $\mathbb{R}$, how does one proceed if it is mapped from $\mathbb{R}^n \longrightarrow \mathbb{R}^m$, where $m > 1$? How does one take the derivative of f with respect to each variable when f is itself in more than one dimension? For example, if there is a function f : $\mathbb{R}^2 \longrightarrow \mathbb{R}^3$ with $(x,y)$ mapped to $(x^2 + y, y^3, \cos(y))$, how does one calculate the Hessian? Thank you",,"['ordinary-differential-equations', 'multivariable-calculus', 'derivatives']"
68,Exact DE with inital value,Exact DE with inital value,,"Solve the given initial value problem and determine at least approximately where the solution is valid  $(2x - y) dx + (2y- x) dy = 0, y(1) = 3 $. My Solution: Let $M=2x-y \Rightarrow M_y=-1$ and let $N=2y-x\Rightarrow N_x=-1$, therefore the given DE is exact.  Let $\Psi_x=M=2x-y\Rightarrow \Psi = x^2-xy+h(y)\Rightarrow \Psi_y=-x+h'(y)\Rightarrow h'(y)=\Psi_y+x=2y-x+x=2y \Rightarrow \Psi=x^2-xy+2y=C$, initial value condition given is $y(1)=3 \Rightarrow C=(1)^2-(1)(3)+2(3)=4 \Rightarrow x^2-xy+2y=4\Rightarrow y=\frac{4-x^2}{2-x}=2+x$, but the given answer is $y = [x+\sqrt{28-3x^2}]/2, |x|<\sqrt{28/3} $","Solve the given initial value problem and determine at least approximately where the solution is valid  $(2x - y) dx + (2y- x) dy = 0, y(1) = 3 $. My Solution: Let $M=2x-y \Rightarrow M_y=-1$ and let $N=2y-x\Rightarrow N_x=-1$, therefore the given DE is exact.  Let $\Psi_x=M=2x-y\Rightarrow \Psi = x^2-xy+h(y)\Rightarrow \Psi_y=-x+h'(y)\Rightarrow h'(y)=\Psi_y+x=2y-x+x=2y \Rightarrow \Psi=x^2-xy+2y=C$, initial value condition given is $y(1)=3 \Rightarrow C=(1)^2-(1)(3)+2(3)=4 \Rightarrow x^2-xy+2y=4\Rightarrow y=\frac{4-x^2}{2-x}=2+x$, but the given answer is $y = [x+\sqrt{28-3x^2}]/2, |x|<\sqrt{28/3} $",,['ordinary-differential-equations']
69,Solving $y'' - \frac{1}{x} y' + (1+\frac{\cot x}{x}) y = 0$ by rank reduction,Solving  by rank reduction,y'' - \frac{1}{x} y' + (1+\frac{\cot x}{x}) y = 0,"With the substitution $$y(x) = \sin x \int u(x) \, dx\tag{*}$$ I managed to get to$$u'(x) = \left(\frac{1}{x}-2\cot x\right)u(x)$$ Solving which gave me $$u(x) = C_1 \frac{x}{\sin^2 x}$$ Inserting that back into $(*)$ $$y(x) = (\sin x) C_1\int \frac{x}{\sin^2 x} \, dx = (\sin x) C_1 \left(\log(\sin x) - \frac{x}{\cot x} + C_2\right)$$ Which doesn't seem to be the correct solution(s). I don't know where I went wrong though.","With the substitution $$y(x) = \sin x \int u(x) \, dx\tag{*}$$ I managed to get to$$u'(x) = \left(\frac{1}{x}-2\cot x\right)u(x)$$ Solving which gave me $$u(x) = C_1 \frac{x}{\sin^2 x}$$ Inserting that back into $(*)$ $$y(x) = (\sin x) C_1\int \frac{x}{\sin^2 x} \, dx = (\sin x) C_1 \left(\log(\sin x) - \frac{x}{\cot x} + C_2\right)$$ Which doesn't seem to be the correct solution(s). I don't know where I went wrong though.",,"['analysis', 'ordinary-differential-equations']"
70,Finding $L^2$ norm of solution of ODE,Finding  norm of solution of ODE,L^2,"I have a linear differential equation with real constant coefficients $$ \sum\limits_{i=0}^3 a_i y^{(i)}(x)=0 $$ with initial conditions $y^{(i)}(0)=y_i\in\mathbb{R}$ where $i=0,1,2$. I need to find $L^2(\mathbb{R}_+)$ norm of $y(x)$ assuming that $\lim\limits_{x\to+\infty}y(x)=0$. How can I solve it? The chracteristic equation is of the third order with arbitrary coefficients!","I have a linear differential equation with real constant coefficients $$ \sum\limits_{i=0}^3 a_i y^{(i)}(x)=0 $$ with initial conditions $y^{(i)}(0)=y_i\in\mathbb{R}$ where $i=0,1,2$. I need to find $L^2(\mathbb{R}_+)$ norm of $y(x)$ assuming that $\lim\limits_{x\to+\infty}y(x)=0$. How can I solve it? The chracteristic equation is of the third order with arbitrary coefficients!",,['ordinary-differential-equations']
71,Solving a differential equation,Solving a differential equation,,I am trying to find the solution of the equation t $y''-(\cos x) y'+(\sin x )y = 0$. I need help urgently.Thanks,I am trying to find the solution of the equation t $y''-(\cos x) y'+(\sin x )y = 0$. I need help urgently.Thanks,,['ordinary-differential-equations']
72,The comparison theorem for matrices,The comparison theorem for matrices,,"Let matrix $X$ satisfy a differential equation $$   \dot X = f(t,X) $$ where right side is real and symmetric. Let $X(0) = M = M^{T} \succeq 0$ and matrix $Y$ satisfy differential inequality $$    \dot Y \succeq f(t,Y), \;\;\; Y(0) = M $$ where $A \succeq B$ means that for any vector $v$ we have $v^{T}Av \geq v^{T}Bv$. Is it true that $$   Y(t) \succeq X(t) $$ for $t> 0$? Function $f$ is sufficiently smooth.","Let matrix $X$ satisfy a differential equation $$   \dot X = f(t,X) $$ where right side is real and symmetric. Let $X(0) = M = M^{T} \succeq 0$ and matrix $Y$ satisfy differential inequality $$    \dot Y \succeq f(t,Y), \;\;\; Y(0) = M $$ where $A \succeq B$ means that for any vector $v$ we have $v^{T}Av \geq v^{T}Bv$. Is it true that $$   Y(t) \succeq X(t) $$ for $t> 0$? Function $f$ is sufficiently smooth.",,['ordinary-differential-equations']
73,"For $y'=x-y^2$, Compute: $\varphi_3(\frac{1}{2})=|y(\frac{1}{2})-y_3(\frac{1}{2})|$.","For , Compute: .",y'=x-y^2 \varphi_3(\frac{1}{2})=|y(\frac{1}{2})-y_3(\frac{1}{2})|,"I'd really love your help with the following Differential equations problem: Given $y'=x-y^2$, $y(0)=0$, I am ask to compute three Picard iterations and the value of the error: $\varphi_3(\frac{1}{2})=|y(\frac{1}{2})-y_3(\frac{1}{2})|$. I got that $$y_3(x)=\frac{x^2}{2}-\frac{x^5}{20}+\frac{x^8}{160}-\frac{x^{11}}{4400}.$$ I tried to find some pattern for a series, but I couldn't find one. How can I compute $\varphi_3$? Thank you very much!","I'd really love your help with the following Differential equations problem: Given $y'=x-y^2$, $y(0)=0$, I am ask to compute three Picard iterations and the value of the error: $\varphi_3(\frac{1}{2})=|y(\frac{1}{2})-y_3(\frac{1}{2})|$. I got that $$y_3(x)=\frac{x^2}{2}-\frac{x^5}{20}+\frac{x^8}{160}-\frac{x^{11}}{4400}.$$ I tried to find some pattern for a series, but I couldn't find one. How can I compute $\varphi_3$? Thank you very much!",,['ordinary-differential-equations']
74,One-to-one correspondence between the flow of an autonomous ODE an its solutions,One-to-one correspondence between the flow of an autonomous ODE an its solutions,,"I want to show the following that there is a bijective correspondence between a certain group action $g$ on $\mathbb{R}$ (I believe that that's called a flow - I don't know much about ODE's, so please keep the explanations at an accessible level) and global solutions of a certain type of differential equations (so talking about $g$ is the same as talking about solving certain ODE's), i.e. I want to show the following two theorems: ""1) Let $g:\mathbb{R}^{n}\times\mathbb{R}\rightarrow\mathbb{R}^{n}$ be a group action of the additive group $\mathbb{R}$ on $\mathbb{R}^{n}$ such that $\partial_{2}g$ exists on the whole domain. Then there exists the ODE  $$ x'=\partial_{2}g\,\left(x,0\right)\left(x\right), $$ such that for a solution $l:\mathbb{R}\rightarrow\mathbb{R}^{n}$ with initial value $x_{0}\in\mathbb{R}^{n}$of the above, we have: $l$ is unique and has the form $l\left(t\right):=g\left(x_{0},t\right)$. (Note, that $\partial_{2}g$  denotes the vector of the partial derivates with respect to the time/the $n+1$'th argument of $\phi$). 2) Conversely if an ODE $$ x'=f\left(x\right) $$ has unique global solutions, then there exists a mapping $g:\mathbb{R}^{n}\times\mathbb{R}\rightarrow\mathbb{R}^{n}$, such that $g$ is a group action ( like described above) and $\partial_{2}g\,\left(x,0\right)=f\left(x\right)$ holds."" My questions are: 1) Have I even stated this proposition correctly ? Is it true what I'm asking ? 2) How can I prove that ? For 1) for example it is easy to show (thanks to the properties of the group action) that if $l$ has the above form, that it is a solution. But taking an arbitrary solution and proving that $l$ has to be of the above form seems to be very difficult.","I want to show the following that there is a bijective correspondence between a certain group action $g$ on $\mathbb{R}$ (I believe that that's called a flow - I don't know much about ODE's, so please keep the explanations at an accessible level) and global solutions of a certain type of differential equations (so talking about $g$ is the same as talking about solving certain ODE's), i.e. I want to show the following two theorems: ""1) Let $g:\mathbb{R}^{n}\times\mathbb{R}\rightarrow\mathbb{R}^{n}$ be a group action of the additive group $\mathbb{R}$ on $\mathbb{R}^{n}$ such that $\partial_{2}g$ exists on the whole domain. Then there exists the ODE  $$ x'=\partial_{2}g\,\left(x,0\right)\left(x\right), $$ such that for a solution $l:\mathbb{R}\rightarrow\mathbb{R}^{n}$ with initial value $x_{0}\in\mathbb{R}^{n}$of the above, we have: $l$ is unique and has the form $l\left(t\right):=g\left(x_{0},t\right)$. (Note, that $\partial_{2}g$  denotes the vector of the partial derivates with respect to the time/the $n+1$'th argument of $\phi$). 2) Conversely if an ODE $$ x'=f\left(x\right) $$ has unique global solutions, then there exists a mapping $g:\mathbb{R}^{n}\times\mathbb{R}\rightarrow\mathbb{R}^{n}$, such that $g$ is a group action ( like described above) and $\partial_{2}g\,\left(x,0\right)=f\left(x\right)$ holds."" My questions are: 1) Have I even stated this proposition correctly ? Is it true what I'm asking ? 2) How can I prove that ? For 1) for example it is easy to show (thanks to the properties of the group action) that if $l$ has the above form, that it is a solution. But taking an arbitrary solution and proving that $l$ has to be of the above form seems to be very difficult.",,['ordinary-differential-equations']
75,construct a Lipschitz function,construct a Lipschitz function,,"Let $P_n$ be group of all permutations of the set $\{1,\dots,n\}$. I have trouble with construction a Lipschitz function $f:P_n \longrightarrow R$. Any help would be appreciate. Thank you.","Let $P_n$ be group of all permutations of the set $\{1,\dots,n\}$. I have trouble with construction a Lipschitz function $f:P_n \longrightarrow R$. Any help would be appreciate. Thank you.",,"['real-analysis', 'probability', 'combinatorics', 'group-theory', 'ordinary-differential-equations']"
76,Some double angle identity to solve $(2x^{2}+y^{2})\frac{dy}{dx}=2xy$?,Some double angle identity to solve ?,(2x^{2}+y^{2})\frac{dy}{dx}=2xy,"For some reason, I cannot see a clever way to solve this (I know the way of doing it like in Wolframalapha) but I am pretty sure there is a double angle identity to crack this puzzle. Could someone hint a bit to get this puzzle onwards? Firstly, I thought to use some rules such as $(x+y)^{2}=x^{2}+2xy+y^{2}$ or $(x-y)^{2}=x^{2}-2xy+y^{2}$ but I think some trigonometric substitution could solve this problem.","For some reason, I cannot see a clever way to solve this (I know the way of doing it like in Wolframalapha) but I am pretty sure there is a double angle identity to crack this puzzle. Could someone hint a bit to get this puzzle onwards? Firstly, I thought to use some rules such as $(x+y)^{2}=x^{2}+2xy+y^{2}$ or $(x-y)^{2}=x^{2}-2xy+y^{2}$ but I think some trigonometric substitution could solve this problem.",,"['ordinary-differential-equations', 'trigonometry']"
77,DAE with nonlinear constraints,DAE with nonlinear constraints,,I have a system of linear differential equation with an algebraic nonlinear constrain: $$\frac{d^2x(t)}{dt^2}+x(t)=y(t)$$ $$\frac{d^2y(t)}{dt^2}+y(t)=x(t)$$ $x(t)^2+y(t)^2=\alpha$ My question is: is it possible to find an analytical solution of this DAE system or the only way is to solve it numerically? Thanks in advance,I have a system of linear differential equation with an algebraic nonlinear constrain: $$\frac{d^2x(t)}{dt^2}+x(t)=y(t)$$ $$\frac{d^2y(t)}{dt^2}+y(t)=x(t)$$ $x(t)^2+y(t)^2=\alpha$ My question is: is it possible to find an analytical solution of this DAE system or the only way is to solve it numerically? Thanks in advance,,['ordinary-differential-equations']
78,Explicit differential equations,Explicit differential equations,,Can you help me to find all solutions of differential equation $y'^2-(x+y)y'+xy=0$? I wrote this equation as product of explicit equations: $$(y'-x)(y'-y)=0$$ Then I found zeroes: $y'-x=0 \Longrightarrow y'=x \Longrightarrow y=\frac{x^2}2+C_1$ $y'=0$ I don't know what to do here. Maybe to solve as equation 'without $x$'? Am I doing this right?,Can you help me to find all solutions of differential equation $y'^2-(x+y)y'+xy=0$? I wrote this equation as product of explicit equations: $$(y'-x)(y'-y)=0$$ Then I found zeroes: $y'-x=0 \Longrightarrow y'=x \Longrightarrow y=\frac{x^2}2+C_1$ $y'=0$ I don't know what to do here. Maybe to solve as equation 'without $x$'? Am I doing this right?,,['ordinary-differential-equations']
79,Must a weakly divergence-free vector function be continuous?,Must a weakly divergence-free vector function be continuous?,,"Let $F:{\mathbb R}^n \to {\mathbb R}^n$ have coordinate functions in $L^2$.  Suppose $F$ is weakly divergence-free, that is, $\int_{{\mathbb R}^n} F \cdot \nabla \varphi = 0$ for all $\varphi \in C_0^\infty({\mathbb R}^n)$.  Must $F$ be continuous?","Let $F:{\mathbb R}^n \to {\mathbb R}^n$ have coordinate functions in $L^2$.  Suppose $F$ is weakly divergence-free, that is, $\int_{{\mathbb R}^n} F \cdot \nabla \varphi = 0$ for all $\varphi \in C_0^\infty({\mathbb R}^n)$.  Must $F$ be continuous?",,['ordinary-differential-equations']
80,Weak lower semicontinuity of a functional on Hilbert space?,Weak lower semicontinuity of a functional on Hilbert space?,,"Let $H:=\left\{u\in L^2(R^N):\nabla u \in L^2(R^N)\right\}$ and a functional $$f(u)=\int_{R^N} |\nabla u|^2dx+\left(\int_{R^N} |\nabla u|^2dx\right)^2.$$ If $\{u_n\}\subset H$ is a sequence such that $u_n \rightharpoonup u$,   is it true that $$\liminf_{n\rightarrow +\infty}\left[\int_{R^N} |\nabla u_n|^2dx+\left(\int_{R^N} |\nabla u_n|^2dx\right)^2\right]\geq \int_{R^N} |\nabla u|^2dx+\left(\int_{R^N} |\nabla u|^2dx\right)^2 \;?$$","Let $H:=\left\{u\in L^2(R^N):\nabla u \in L^2(R^N)\right\}$ and a functional $$f(u)=\int_{R^N} |\nabla u|^2dx+\left(\int_{R^N} |\nabla u|^2dx\right)^2.$$ If $\{u_n\}\subset H$ is a sequence such that $u_n \rightharpoonup u$,   is it true that $$\liminf_{n\rightarrow +\infty}\left[\int_{R^N} |\nabla u_n|^2dx+\left(\int_{R^N} |\nabla u_n|^2dx\right)^2\right]\geq \int_{R^N} |\nabla u|^2dx+\left(\int_{R^N} |\nabla u|^2dx\right)^2 \;?$$",,"['ordinary-differential-equations', 'functional-analysis', 'calculus-of-variations', 'sobolev-spaces']"
81,"Given $\csc{x \text{ } \frac{dy}{dx}}=xy$, express $y$ in terms of $x$","Given , express  in terms of",\csc{x \text{ } \frac{dy}{dx}}=xy y x,"How do I do this? Given $\csc{x \text{ } \frac{dy}{dx}}=xy$, express $y$ in terms of $x$ https://i.sstatic.net/q1mH8.png I got $\frac{dy}{dx}=\frac{xy}{\csc{x}}$, then how can I remove the $y$? I am thinking maybe I need to use substitution or something? UPDATE: Correct Working? Is my working correct?","How do I do this? Given $\csc{x \text{ } \frac{dy}{dx}}=xy$, express $y$ in terms of $x$ https://i.sstatic.net/q1mH8.png I got $\frac{dy}{dx}=\frac{xy}{\csc{x}}$, then how can I remove the $y$? I am thinking maybe I need to use substitution or something? UPDATE: Correct Working? Is my working correct?",,['ordinary-differential-equations']
82,The equation $(x-2xy-y^2)\frac{dy}{dx}+y^2=0$,The equation,(x-2xy-y^2)\frac{dy}{dx}+y^2=0,Can one give a hint how to solve the following equation? $(x-2xy-y^2)\frac{dy}{dx}+y^2=0$ Thanks in advance.,Can one give a hint how to solve the following equation? $(x-2xy-y^2)\frac{dy}{dx}+y^2=0$ Thanks in advance.,,['ordinary-differential-equations']
83,Complex Numbers with the prey-predator equilibrium?,Complex Numbers with the prey-predator equilibrium?,,"Consider a model (very similar to Lotka-volterra prey-predator -model, exception $h$). $$ \frac{dx}{dt} = h+x(\alpha -\beta y)$$  $$ \frac{dy}{dt} = -y(\gamma - \rho x). $$ Let's write this  in matrix form: $$ \left(\begin{array}{c}\dot{x}  \\ \dot{y}  \end{array} \right) = \left( \begin{array}{cc} \alpha & -\beta x  \\ \rho y & -\gamma   \end{array} \right) \left(\begin{array}{c} x  \\ y  \end{array} \right) + \left(\begin{array}{c} h  \\ 0  \end{array} \right)  = \left(\begin{array}{c} 0  \\ 0  \end{array} \right) $$ where the final right hand-side is due to the definition of the equilibrium. So we have a system of the form $\bar{0} = A \bar{v} + \bar{h}$. The equation $\dot{f} = A \bar{v} + \bar{h}$ is non-linear ODE, more here , so I need to investigate the $J_{f} := \left[ \frac{\partial f_{i}}{\partial y_{j}} \right]$ where $f(\bar{x}, \bar{y}) = \frac{d \bar{v_{i}}}{d t}$ (read this link , clarifies things a lot!) So the Jacobian is needed for the stability more here . I am trying to solve the problem 5 here . Clarifications needed, Some Helper Questions Fix-points? Some material mention things called ""fixpoints"". $F(\bar{p}) =0$ and then checking some condition, thinking -- really, no need to check it like the history? linearization? Confused (see the history).","Consider a model (very similar to Lotka-volterra prey-predator -model, exception $h$). $$ \frac{dx}{dt} = h+x(\alpha -\beta y)$$  $$ \frac{dy}{dt} = -y(\gamma - \rho x). $$ Let's write this  in matrix form: $$ \left(\begin{array}{c}\dot{x}  \\ \dot{y}  \end{array} \right) = \left( \begin{array}{cc} \alpha & -\beta x  \\ \rho y & -\gamma   \end{array} \right) \left(\begin{array}{c} x  \\ y  \end{array} \right) + \left(\begin{array}{c} h  \\ 0  \end{array} \right)  = \left(\begin{array}{c} 0  \\ 0  \end{array} \right) $$ where the final right hand-side is due to the definition of the equilibrium. So we have a system of the form $\bar{0} = A \bar{v} + \bar{h}$. The equation $\dot{f} = A \bar{v} + \bar{h}$ is non-linear ODE, more here , so I need to investigate the $J_{f} := \left[ \frac{\partial f_{i}}{\partial y_{j}} \right]$ where $f(\bar{x}, \bar{y}) = \frac{d \bar{v_{i}}}{d t}$ (read this link , clarifies things a lot!) So the Jacobian is needed for the stability more here . I am trying to solve the problem 5 here . Clarifications needed, Some Helper Questions Fix-points? Some material mention things called ""fixpoints"". $F(\bar{p}) =0$ and then checking some condition, thinking -- really, no need to check it like the history? linearization? Confused (see the history).",,"['ordinary-differential-equations', 'complex-numbers']"
84,Finding Floquet Multipliers,Finding Floquet Multipliers,,"So I'm curious how to actually find Floquet multipliers given some differential equation $y'=A(t)y$. It's (usually) easy to find the fundamental matrix $\Phi(t)$ by other methods. And I feel like I'm missing something dumb, but what can I do from there to get the eigenvalues for the matrix $C$? For a more concrete example at hand, consider $y'=(a+b\cos t)y$. It is easy to see that $y=(C_0e^{at})e^{b\sin t}$ and the period of the periodic matrix is $p=2\pi$. So now I have: $$\Phi(t+p)C=\Phi(t)\implies(C_0e^{A(t+2\pi)})e^{B\sin{(t+2\pi)}}C=(C_0e^{At})e^{B\sin{t}}$$ How do I get $C$, or more specifically, the eigenvalues of C once I have this setup? I'm pretty sure I did something incorrectly. EDIT: Sorry, figured it out with anon's help. I completely mixed up my notions for computing the fundamental matrix.","So I'm curious how to actually find Floquet multipliers given some differential equation $y'=A(t)y$. It's (usually) easy to find the fundamental matrix $\Phi(t)$ by other methods. And I feel like I'm missing something dumb, but what can I do from there to get the eigenvalues for the matrix $C$? For a more concrete example at hand, consider $y'=(a+b\cos t)y$. It is easy to see that $y=(C_0e^{at})e^{b\sin t}$ and the period of the periodic matrix is $p=2\pi$. So now I have: $$\Phi(t+p)C=\Phi(t)\implies(C_0e^{A(t+2\pi)})e^{B\sin{(t+2\pi)}}C=(C_0e^{At})e^{B\sin{t}}$$ How do I get $C$, or more specifically, the eigenvalues of C once I have this setup? I'm pretty sure I did something incorrectly. EDIT: Sorry, figured it out with anon's help. I completely mixed up my notions for computing the fundamental matrix.",,['ordinary-differential-equations']
85,Diff Eq: Solving differential equations,Diff Eq: Solving differential equations,,"So I would just like to double check if my solutions are correct for the following two problems: Thanks in advance, really appreciate it.","So I would just like to double check if my solutions are correct for the following two problems: Thanks in advance, really appreciate it.",,[]
86,solving ordinary differential equations,solving ordinary differential equations,,"Sorry for asking such stupid things. But I have this simple question. In some books, instead of solving $dy / dx$ they just solve $dx / dy$ by  raising all to the power $-1$.  For example in this exercise in a directory they do this: instead of solving  $$\frac{dy}{dx}= \frac {1}{x\sin y + 2\sin 2y}$$ which is not linear, they solve this: $$\frac{dx}{dy}= x \sin y + 2 \sin 2y$$ which is linear in $x$. The question is, can we always do this? How is it justified?","Sorry for asking such stupid things. But I have this simple question. In some books, instead of solving $dy / dx$ they just solve $dx / dy$ by  raising all to the power $-1$.  For example in this exercise in a directory they do this: instead of solving  $$\frac{dy}{dx}= \frac {1}{x\sin y + 2\sin 2y}$$ which is not linear, they solve this: $$\frac{dx}{dy}= x \sin y + 2 \sin 2y$$ which is linear in $x$. The question is, can we always do this? How is it justified?",,['ordinary-differential-equations']
87,Substitution in ODE,Substitution in ODE,,"A tutorial (page 17) on ODE scaling takes the equation $m\ddot{u}+c\dot{u}+ku=F_0sin(\omega t)$, with $u$ a function of $t$, and substitutes $\eta=u/a$, $\tau=t/b$ to get: $$\frac{ma}{b^2}\ddot{\eta}+\frac{ca}{b}\dot{\eta}+ka\eta=F_0sin(\omega\tau)$$ Now, when I differentiate $\eta=u/a$, I get $\dot{\eta}=t\dot{u}/a=\tau b\dot{u}/a$. Substituting, the final result is: $$\frac{ma}{\tau^2b^2}\ddot{\eta}+\frac{ca}{\tau b}\dot{\eta}+ka\eta=F_0sin(\omega\tau b)$$ That's not the same. What am I missing?","A tutorial (page 17) on ODE scaling takes the equation $m\ddot{u}+c\dot{u}+ku=F_0sin(\omega t)$, with $u$ a function of $t$, and substitutes $\eta=u/a$, $\tau=t/b$ to get: $$\frac{ma}{b^2}\ddot{\eta}+\frac{ca}{b}\dot{\eta}+ka\eta=F_0sin(\omega\tau)$$ Now, when I differentiate $\eta=u/a$, I get $\dot{\eta}=t\dot{u}/a=\tau b\dot{u}/a$. Substituting, the final result is: $$\frac{ma}{\tau^2b^2}\ddot{\eta}+\frac{ca}{\tau b}\dot{\eta}+ka\eta=F_0sin(\omega\tau b)$$ That's not the same. What am I missing?",,['ordinary-differential-equations']
88,"Generalized ""Worm on the rubber band "" problem","Generalized ""Worm on the rubber band "" problem",,"I found this « Worm on the rubber band » problem in Concrete Mathematics book. A slow worm $W$ starts at one end of a meter-long rubber band and crawls one centimetre per minute toward the other end. At the end of each minute, a keeper of the band $K$ stretches it one meter. Does the worm ever reach the finish? The given solution is: $W$ reaches the finish if and when $H(n)$ ever surpasses 100, where $H(n)$ is the $n$th Harmonic number. How to solve this generalized problem with continuous data and with $W$ crawling with a velocity $u=f(t)$ and $K$ crawling with velocity $v=g(t)$  where $u(t)$ and $v(t)$ are both arbitrary functions of time. For example, I want to find if and when the worm will reach the end of a rubber band of length $L$ if (with $a$ and $b$ constants) $u(t)=a*t$ and $v(t)=b*(t)$ ?","I found this « Worm on the rubber band » problem in Concrete Mathematics book. A slow worm $W$ starts at one end of a meter-long rubber band and crawls one centimetre per minute toward the other end. At the end of each minute, a keeper of the band $K$ stretches it one meter. Does the worm ever reach the finish? The given solution is: $W$ reaches the finish if and when $H(n)$ ever surpasses 100, where $H(n)$ is the $n$th Harmonic number. How to solve this generalized problem with continuous data and with $W$ crawling with a velocity $u=f(t)$ and $K$ crawling with velocity $v=g(t)$  where $u(t)$ and $v(t)$ are both arbitrary functions of time. For example, I want to find if and when the worm will reach the end of a rubber band of length $L$ if (with $a$ and $b$ constants) $u(t)=a*t$ and $v(t)=b*(t)$ ?",,['ordinary-differential-equations']
89,Proving a property of homogeneous equation that is exact,Proving a property of homogeneous equation that is exact,,"The following question was given to us in an exam: If $0=M dx + N dy$ is an exact equation, in addition to the fact that $\frac{M}{N} = f\Big(\frac{y}{x}\Big)$ is homogeneous, then $xM_x + yM_y = (xN_x + yN_y)f$. Now I had absolutely no idea how to prove this question. I tried doing $M = Nf$ and taking derivatives and multiplying by $x$ or $y$, and you get the required R.H.S. but with the extra term $N(\frac{-f_x}{x} + \frac{f_y}{x})$ added. How does one approach a question like that?? I  have never encountered a question like that, not even when solving for different types of integrating factors to get an exact equation or when working with a homogeneous equation. Anyone got any ideas? Please don't post a complete solution. Thanks.","The following question was given to us in an exam: If $0=M dx + N dy$ is an exact equation, in addition to the fact that $\frac{M}{N} = f\Big(\frac{y}{x}\Big)$ is homogeneous, then $xM_x + yM_y = (xN_x + yN_y)f$. Now I had absolutely no idea how to prove this question. I tried doing $M = Nf$ and taking derivatives and multiplying by $x$ or $y$, and you get the required R.H.S. but with the extra term $N(\frac{-f_x}{x} + \frac{f_y}{x})$ added. How does one approach a question like that?? I  have never encountered a question like that, not even when solving for different types of integrating factors to get an exact equation or when working with a homogeneous equation. Anyone got any ideas? Please don't post a complete solution. Thanks.",,[]
90,A question related to a given differential equation?,A question related to a given differential equation?,,Given that    $$(xy^3+x^2y^7)y'=1$$   satisfies the initial condition $y(\frac{1}{4}) = 1$. Then the value of $y'$ when $y=-1$ is: (A) $\frac{4}{3}$. (B) $-\frac{4}{3}$. (C) $\frac{16}{5}$. (D) $-\frac{16}{5}$. I doubt if it necessary to solve for $y'$ in order to proceed.  Please help.,Given that    $$(xy^3+x^2y^7)y'=1$$   satisfies the initial condition $y(\frac{1}{4}) = 1$. Then the value of $y'$ when $y=-1$ is: (A) $\frac{4}{3}$. (B) $-\frac{4}{3}$. (C) $\frac{16}{5}$. (D) $-\frac{16}{5}$. I doubt if it necessary to solve for $y'$ in order to proceed.  Please help.,,['ordinary-differential-equations']
91,Differential Equation Help?,Differential Equation Help?,,"Q: Solve the separable differential equation: $3x - 2y\sqrt{x^2+1}\frac{dy}{dx} = 0$ and subject to the initial condition: $y(0) = 4$. What does $y$ equal, in relation to $x$? I am just really confused what I am suppose to do? Thanks.","Q: Solve the separable differential equation: $3x - 2y\sqrt{x^2+1}\frac{dy}{dx} = 0$ and subject to the initial condition: $y(0) = 4$. What does $y$ equal, in relation to $x$? I am just really confused what I am suppose to do? Thanks.",,['ordinary-differential-equations']
92,What is the differential equation expression for this question?,What is the differential equation expression for this question?,,Suppose that the population of cats in a has a rate of growth proportional to the population itself. Write down a differential equation for the population $P (t)$ at time $t$ ?,Suppose that the population of cats in a has a rate of growth proportional to the population itself. Write down a differential equation for the population $P (t)$ at time $t$ ?,,['ordinary-differential-equations']
93,A body falls through a medium,A body falls through a medium,,"I'm hating these variable resistance questions. A body of mass $m$ falls from rest in a medium that produces a resistance of magnitude $m\cdot k \cdot v$. where $k$ is a constant, where the speed of the particle is $v$. Show that when the body has reached a speed $V$ it will have fallen for a time $$\frac{1}{k} \ln \left(\frac{g}{g-k\cdot V}\right) \; .$$ Help much appreciated.","I'm hating these variable resistance questions. A body of mass $m$ falls from rest in a medium that produces a resistance of magnitude $m\cdot k \cdot v$. where $k$ is a constant, where the speed of the particle is $v$. Show that when the body has reached a speed $V$ it will have fallen for a time $$\frac{1}{k} \ln \left(\frac{g}{g-k\cdot V}\right) \; .$$ Help much appreciated.",,"['integration', 'ordinary-differential-equations', 'physics']"
94,What kind of vector space does the set of (complex/real) solutions of the following differential equation form?,What kind of vector space does the set of (complex/real) solutions of the following differential equation form?,,"I'm doing a multiple choice exercise and I'm stuck at a question, where there are two possible answers (may be both or none correct). Consider the differential equation $$y''+y'+y=0$$ for $y(x)$. Which of the following statements are true? The set of complex solutions forms a two-dimensional complex vector space. The set of real solutions forms a two-dimensional real vector space. I'm really not comfortable with vector spaces and the differentiation of real and complex vector space makes me even more unconfident. I solved the differential equation with the ansatz $y(x) = e^{\lambda x}$ and got to $\lambda^2 + \lambda + 1 = 0$, an equation which does not possess any real solutions. However, when I proceeded, I figured that I could rewrite the exponential function (with complex exponent) with the help of the sine and the cosine, so in the end I got a general solution with no complex coefficients. What kind of vector space is this?","I'm doing a multiple choice exercise and I'm stuck at a question, where there are two possible answers (may be both or none correct). Consider the differential equation $$y''+y'+y=0$$ for $y(x)$. Which of the following statements are true? The set of complex solutions forms a two-dimensional complex vector space. The set of real solutions forms a two-dimensional real vector space. I'm really not comfortable with vector spaces and the differentiation of real and complex vector space makes me even more unconfident. I solved the differential equation with the ansatz $y(x) = e^{\lambda x}$ and got to $\lambda^2 + \lambda + 1 = 0$, an equation which does not possess any real solutions. However, when I proceeded, I figured that I could rewrite the exponential function (with complex exponent) with the help of the sine and the cosine, so in the end I got a general solution with no complex coefficients. What kind of vector space is this?",,['ordinary-differential-equations']
95,Stability of Hamiltonian system on degenerate critical point.,Stability of Hamiltonian system on degenerate critical point.,,"I'm trying to find information on the stability of the following ODE: $$ x'' = x^4-x^2.$$ We know that it has a Hamiltonian $H(x,y) = \dfrac{y^2}{2} - (\dfrac{x^5}{5} - \dfrac{x^3}{3})$ . The orbits are given by the equation $$ y(x) = \pm \sqrt{\alpha(3x^5 - 5x^3 - \beta)}$$ for constants $\alpha = 2/15$ and $15\beta = H(x,y)$ . Now, we know that $3x^5 - 5x^3 - \beta$ is positive when the graph of $P(x) = 3x^5 - 5x^3$ is above the line $y=\beta$ . Looking at the graph we see that the domain of definition is disconnected when the line is in between the local extrema of $P(x)$ and only becomes connected when the line goes above or below the local extrema of $P(x)$ . From this information, we can conclude that the critical points $(-1,0)$ and $(1,0)$ obviously have to be a centre and a saddle point. However, we can't get any information on the critical point at $(0,0)$ . Looking at the direction field We kind of expect it to be a centre, but I really don´t know how to prove this. Geometrical reasoning aside, it easy to check that the Hessian has positive eigenvalues at $(-1,0)$ and that the Jacobian has a positive and a negative eigenvalue at $(1,0)$ and thus these points are a centre and a saddle point, but what do I do at zero?","I'm trying to find information on the stability of the following ODE: We know that it has a Hamiltonian . The orbits are given by the equation for constants and . Now, we know that is positive when the graph of is above the line . Looking at the graph we see that the domain of definition is disconnected when the line is in between the local extrema of and only becomes connected when the line goes above or below the local extrema of . From this information, we can conclude that the critical points and obviously have to be a centre and a saddle point. However, we can't get any information on the critical point at . Looking at the direction field We kind of expect it to be a centre, but I really don´t know how to prove this. Geometrical reasoning aside, it easy to check that the Hessian has positive eigenvalues at and that the Jacobian has a positive and a negative eigenvalue at and thus these points are a centre and a saddle point, but what do I do at zero?"," x'' = x^4-x^2. H(x,y) = \dfrac{y^2}{2} - (\dfrac{x^5}{5} - \dfrac{x^3}{3})  y(x) = \pm \sqrt{\alpha(3x^5 - 5x^3 - \beta)} \alpha = 2/15 15\beta = H(x,y) 3x^5 - 5x^3 - \beta P(x) = 3x^5 - 5x^3 y=\beta P(x) P(x) (-1,0) (1,0) (0,0) (-1,0) (1,0)","['ordinary-differential-equations', 'dynamical-systems', 'stability-theory', 'nonlinear-dynamics', 'hamilton-equations']"
96,$2$nd Order Nonlinear ODE with $y'^2$ Term,nd Order Nonlinear ODE with  Term,2 y'^2,"I am attempting to find a closed-form solution to the differential equation $5y'^2 - 4yy'' = 0$ . The substitution $y' = v$ does not appear to work here, due to the $y'^2$ term on the left hand side. How would I go about approaching this problem?","I am attempting to find a closed-form solution to the differential equation . The substitution does not appear to work here, due to the term on the left hand side. How would I go about approaching this problem?",5y'^2 - 4yy'' = 0 y' = v y'^2,['ordinary-differential-equations']
97,Prove stability of solution to a system of differential equations,Prove stability of solution to a system of differential equations,,"How to prove that the zero solution of the following system of differential equations is stable, but not asymptotically stable? \begin{cases}\dot{x} = y - y^2 \\\dot{y} = -x\end{cases} It is easy to see that its phase portraits are given by the equation $$x^2 + y^2 -\frac{2}{3}y^3 = C$$ If we plot this, we can see that for very small positive values of $C$ there are small cycles near the center of the coordinates. Which hints at the fact which we are trying to prove. However, it is not clear how to adequately plot them without a computer program and how to prove stability rigorously.","How to prove that the zero solution of the following system of differential equations is stable, but not asymptotically stable? It is easy to see that its phase portraits are given by the equation If we plot this, we can see that for very small positive values of there are small cycles near the center of the coordinates. Which hints at the fact which we are trying to prove. However, it is not clear how to adequately plot them without a computer program and how to prove stability rigorously.",\begin{cases}\dot{x} = y - y^2 \\\dot{y} = -x\end{cases} x^2 + y^2 -\frac{2}{3}y^3 = C C,"['ordinary-differential-equations', 'stability-theory']"
98,Differential equation with Fourier transform,Differential equation with Fourier transform,,"It is given the following differential equation: $$-\frac{d^2 x}{dt^2} + \frac{dx}{dt} = \theta(t) e^{-\varepsilon t}$$ where $\theta(t)$ is the Heaviside function (which equals $0$ for $t<0$ and equals $1$ for $t\ge 0$ ) and $\varepsilon$ is a real parameter which is always positive. Write the equation that the $\tilde{x}=\mathscr{F}[x]$ satisfies and find the most general solution (in the distribution sense). By anti-transforming, find a solution $x(t)$ to the differential equation, which must satisfy the contour condition of $\lim_{t\to -\infty} x(t) = 0$ . Find the most general solution $x(t)$ which satisfies the previous contour condition. Note: $\mathscr{F}$ represents the Fourier transform; $\tilde{x}(\omega)$ is the Fourier transform of $x(t)$ . Moreover, I will denote distribution associated to a certain function with the function itself. My solution: I started by Fourier-transforming the given differential equation to find the equation satisfied by $\tilde{x}(\omega)$ . Using the properties of the Fourier transform, I wrote that: $$- (-i\omega)^2 \tilde{x} (\omega) + (-i\omega)\tilde{x}(\omega) = \mathscr{F}[\theta(t) e^{-\varepsilon t}]$$ To evaluate the F-transform of the right-hand term, I calculated the integral directly: $$\mathscr{F}[\theta(t) e^{-\varepsilon t}] = \int_{-\infty}^{+\infty} \theta(t) e^{i\omega t} e^{-\varepsilon t} \ dt = \int_{0}^{+\infty} e^{t(i\omega - \varepsilon)}\ dt=\left[\frac{e^{t(i\omega-\varepsilon)}}{i\omega - \varepsilon}\right]_{0}^{+\infty}=-\frac{1}{i\omega - \varepsilon}$$ Hence: $$\tilde{x}(\omega) = -\frac{1}{(i\omega-1)(\omega^2-i\omega)}$$ This shouldn't be the most general solution; to obtain that, I either need to anti-transform this, which I don't know how to, or I need to solve the homogeneous differential equation $-x''(t) + x'(t) = 0$ and F-transform to add it to the $\tilde{x}(\omega)$ found above. By doing this, I should get $x(t) = A e^t + B$ , with $A$ and $B$ two real constants, but it isn't Fourier-transformable. What am I missing? If you could help me solving my doubts, I'll try to finish it by myself, but if you could provide the entire solution will be much more appreciated; I feel like I need to get more experience with this kind of exercise and, unfortunately, I don't have solutions to this. I'm sorry for having to ask you to solve this problem without even giving you a full solution to this, but I really don't know how to proceed. Thanks in advance for your help, I really appreciate it! EDIT 1: By using Jordan's lemma to calculate the anti-transform and obtain the particular solution of the differential equation, I get: $$x_P(t) = \left(\frac{e^{-\varepsilon t} }{\varepsilon (\varepsilon +1)} + \frac{1}{2 \varepsilon } \right) \theta (t) + \left(\frac{e^{t} }{1-i\varepsilon }+\frac{1}{2\varepsilon }\right) \theta (-t)$$ The problem with this is that the contour condition of the second point is never satisfied, which leads me to think that I did something wrong.","It is given the following differential equation: where is the Heaviside function (which equals for and equals for ) and is a real parameter which is always positive. Write the equation that the satisfies and find the most general solution (in the distribution sense). By anti-transforming, find a solution to the differential equation, which must satisfy the contour condition of . Find the most general solution which satisfies the previous contour condition. Note: represents the Fourier transform; is the Fourier transform of . Moreover, I will denote distribution associated to a certain function with the function itself. My solution: I started by Fourier-transforming the given differential equation to find the equation satisfied by . Using the properties of the Fourier transform, I wrote that: To evaluate the F-transform of the right-hand term, I calculated the integral directly: Hence: This shouldn't be the most general solution; to obtain that, I either need to anti-transform this, which I don't know how to, or I need to solve the homogeneous differential equation and F-transform to add it to the found above. By doing this, I should get , with and two real constants, but it isn't Fourier-transformable. What am I missing? If you could help me solving my doubts, I'll try to finish it by myself, but if you could provide the entire solution will be much more appreciated; I feel like I need to get more experience with this kind of exercise and, unfortunately, I don't have solutions to this. I'm sorry for having to ask you to solve this problem without even giving you a full solution to this, but I really don't know how to proceed. Thanks in advance for your help, I really appreciate it! EDIT 1: By using Jordan's lemma to calculate the anti-transform and obtain the particular solution of the differential equation, I get: The problem with this is that the contour condition of the second point is never satisfied, which leads me to think that I did something wrong.",-\frac{d^2 x}{dt^2} + \frac{dx}{dt} = \theta(t) e^{-\varepsilon t} \theta(t) 0 t<0 1 t\ge 0 \varepsilon \tilde{x}=\mathscr{F}[x] x(t) \lim_{t\to -\infty} x(t) = 0 x(t) \mathscr{F} \tilde{x}(\omega) x(t) \tilde{x}(\omega) - (-i\omega)^2 \tilde{x} (\omega) + (-i\omega)\tilde{x}(\omega) = \mathscr{F}[\theta(t) e^{-\varepsilon t}] \mathscr{F}[\theta(t) e^{-\varepsilon t}] = \int_{-\infty}^{+\infty} \theta(t) e^{i\omega t} e^{-\varepsilon t} \ dt = \int_{0}^{+\infty} e^{t(i\omega - \varepsilon)}\ dt=\left[\frac{e^{t(i\omega-\varepsilon)}}{i\omega - \varepsilon}\right]_{0}^{+\infty}=-\frac{1}{i\omega - \varepsilon} \tilde{x}(\omega) = -\frac{1}{(i\omega-1)(\omega^2-i\omega)} -x''(t) + x'(t) = 0 \tilde{x}(\omega) x(t) = A e^t + B A B x_P(t) = \left(\frac{e^{-\varepsilon t} }{\varepsilon (\varepsilon +1)} + \frac{1}{2 \varepsilon } \right) \theta (t) + \left(\frac{e^{t} }{1-i\varepsilon }+\frac{1}{2\varepsilon }\right) \theta (-t),"['ordinary-differential-equations', 'fourier-analysis', 'fourier-transform', 'distribution-theory']"
99,ODE and semi flow,ODE and semi flow,,"I am new to ODE and semi-flows. So, it is a beginner question. If an ODE $x^{\prime} = h(x)$ admits a unique solution, is it right to say that the flow generated by this equation, i.e. $\Phi_t(x) = x + \int_0^t h(s) \,\mathrm{d}s$ satisfies those properties : (a) $\Phi_0 = Id$ ; (b) $\Phi_t$ is continuous $\forall t$ ; (c) $\Phi_{t+s} = \Phi_t \circ \Phi_s$ $\forall s,t \geq 0$ . I can prove the first two points, but I fail to prove the third one. I try to prove this point in a particular case where $T$ is a contraction on $\mathbb{R}^d$ and $h = T - I_d$ . Thanks in advance","I am new to ODE and semi-flows. So, it is a beginner question. If an ODE admits a unique solution, is it right to say that the flow generated by this equation, i.e. satisfies those properties : (a) ; (b) is continuous ; (c) . I can prove the first two points, but I fail to prove the third one. I try to prove this point in a particular case where is a contraction on and . Thanks in advance","x^{\prime} = h(x) \Phi_t(x) = x + \int_0^t h(s) \,\mathrm{d}s \Phi_0 = Id \Phi_t \forall t \Phi_{t+s} = \Phi_t \circ \Phi_s \forall s,t \geq 0 T \mathbb{R}^d h = T - I_d",['ordinary-differential-equations']
