,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Given an array A of size n with elements from 1 to k and another Array B of size k with elements 1 to n. Show that they have a subarray of same sum.,Given an array A of size n with elements from 1 to k and another Array B of size k with elements 1 to n. Show that they have a subarray of same sum.,,"Given an array A of size n with elements from 1 to k and another Array B of size k with elements 1 to n.  Show that they have a subarray of the same sum where n,k >= 1. So far I have done this much analysis: Define d = P1- P2 where P1 and P2 are prefixes of array A and B. For some subarrays in A and B to have common sum d should be same for at least 2 pairs(P1, P2) and possible pairs are (n+1) (k+1) and d can have values from -n k to nk i.e. 2nk + 1 differences. How should I proceed further? or is there any another way(Induction or something different) of proving the same?","Given an array A of size n with elements from 1 to k and another Array B of size k with elements 1 to n.  Show that they have a subarray of the same sum where n,k >= 1. So far I have done this much analysis: Define d = P1- P2 where P1 and P2 are prefixes of array A and B. For some subarrays in A and B to have common sum d should be same for at least 2 pairs(P1, P2) and possible pairs are (n+1) (k+1) and d can have values from -n k to nk i.e. 2nk + 1 differences. How should I proceed further? or is there any another way(Induction or something different) of proving the same?",,"['abstract-algebra', 'number-theory', 'discrete-mathematics', 'induction', 'pigeonhole-principle']"
1,Abelianisation of a division ring,Abelianisation of a division ring,,"I was reading a paper recently concerning a non-commutative version of the matrix determinant. On the third page, it stated a fact without providing a proof or a reference: If $D$ is a division ring, let $D^\times$ be its multiplicative group, then the abelianisation of $D^\times$, $\frac{D^\times}{[D^\times,D^\times]}$, is isomorphic to $Z(D)^\times$ - the centre of $D^\times$. This result doesn't seem at all trivial, although of course it holds for any commutative field. I had considered that perhaps the natural map $Z(D)^\times\to \frac{D^\times}{[D^\times,D^\times]},c\mapsto c [D^\times,D^\times]$ could be proved to be an isomorphism. But I can see no reason why this should be be the case. Is this result really true? If so, does anyone have any idea why? Is the natural map an isomorphism, or is there some other non-canonical isomorphism? Otherwise, can anyone think of a counterexample?","I was reading a paper recently concerning a non-commutative version of the matrix determinant. On the third page, it stated a fact without providing a proof or a reference: If $D$ is a division ring, let $D^\times$ be its multiplicative group, then the abelianisation of $D^\times$, $\frac{D^\times}{[D^\times,D^\times]}$, is isomorphic to $Z(D)^\times$ - the centre of $D^\times$. This result doesn't seem at all trivial, although of course it holds for any commutative field. I had considered that perhaps the natural map $Z(D)^\times\to \frac{D^\times}{[D^\times,D^\times]},c\mapsto c [D^\times,D^\times]$ could be proved to be an isomorphism. But I can see no reason why this should be be the case. Is this result really true? If so, does anyone have any idea why? Is the natural map an isomorphism, or is there some other non-canonical isomorphism? Otherwise, can anyone think of a counterexample?",,"['abstract-algebra', 'group-theory', 'ring-theory', 'division-ring']"
2,"Is there a flaw on ""Galois for beginners""?","Is there a flaw on ""Galois for beginners""?",,"I guess that the following question is only for those who by any chance have read the text "" Galois for beginners "" by John Stillwell.  Although the text is short and there might be some remarkable people that might be able to read it and understand it fast enough. In any case, I'm thankful to anyone who answers. The aim of the text is to prove that there is no solution by radicals for polynomials of degree 5 or higher, and the issue I'm having is that the author seems to have made a mistake on a proof along the way. Reading this text -as brief as it is- is proving to be really hard for me, since I know little about abstract algebra, but it is the shortest 'proof' I've been able to find. What I wish to know, is if this mistake the author made will at the end ruin the whole proof (meaning that I would have lost my time) or if even with this flaw, the author is still able to prove Abel-Ruffini Theorem. The flaw: (For context, $x_1,...,x_n$ refer to the roots of a generic $n$th degree polynomial) Theorem (page $4$ of the pdf. ). ""for each radical extension $E$ of $ℚ(x_1,...,x_n)$ there is a radical extension $E′/E$ with automorphisms extending all permutations $σ$ of $x_1,...,x_n$."" Proof.  ""for each adjoined element, represented by the expression $e(x_1,...,x_n)$, and each permutation $σ$ of $x_1,...,x_n$ adjoin the element $e(σx_1,...,σx_n)$. Since there are only finitely many permutations of $σ$ then, the resulting field $E'⊇E$ is also a radical extension of $ℚ(x_1,...,x_n)$. This gives a bijection (also called $σ$ ) of $E'$ sending each $f(x_1,...,x_n)∈E'$ (a rational function of $x_1,...x_n$ and the adjoined elements) to $f(σx_1,...,σx_n)$, and this bijection is clearly an automorphism of $E′$, extending the permutation $σ$."" This theorem should hold for a generic polynomial $P$, but it doesn't, since something like this might happen: Let's say that $(x_1)^2+x_2^2=(x_3)^2$, yet $(σx_1)^3+(σx_2)^2≠(σx_3)^2$, meaning that $σ$ has mapped the same element into two different places, meaning that $σ$ can not be an automorphism. For a specific example let $x_1=i$, $x_2=3^{1/2}$ and $x_3=2^{1/2}$. So the theorem doesn't hold for all polynomials. Will this at the end ruin the proof? Or is just insignificant to consider the polynomials in which the flaw occurs? I will really appreciate any help/thoughts.","I guess that the following question is only for those who by any chance have read the text "" Galois for beginners "" by John Stillwell.  Although the text is short and there might be some remarkable people that might be able to read it and understand it fast enough. In any case, I'm thankful to anyone who answers. The aim of the text is to prove that there is no solution by radicals for polynomials of degree 5 or higher, and the issue I'm having is that the author seems to have made a mistake on a proof along the way. Reading this text -as brief as it is- is proving to be really hard for me, since I know little about abstract algebra, but it is the shortest 'proof' I've been able to find. What I wish to know, is if this mistake the author made will at the end ruin the whole proof (meaning that I would have lost my time) or if even with this flaw, the author is still able to prove Abel-Ruffini Theorem. The flaw: (For context, $x_1,...,x_n$ refer to the roots of a generic $n$th degree polynomial) Theorem (page $4$ of the pdf. ). ""for each radical extension $E$ of $ℚ(x_1,...,x_n)$ there is a radical extension $E′/E$ with automorphisms extending all permutations $σ$ of $x_1,...,x_n$."" Proof.  ""for each adjoined element, represented by the expression $e(x_1,...,x_n)$, and each permutation $σ$ of $x_1,...,x_n$ adjoin the element $e(σx_1,...,σx_n)$. Since there are only finitely many permutations of $σ$ then, the resulting field $E'⊇E$ is also a radical extension of $ℚ(x_1,...,x_n)$. This gives a bijection (also called $σ$ ) of $E'$ sending each $f(x_1,...,x_n)∈E'$ (a rational function of $x_1,...x_n$ and the adjoined elements) to $f(σx_1,...,σx_n)$, and this bijection is clearly an automorphism of $E′$, extending the permutation $σ$."" This theorem should hold for a generic polynomial $P$, but it doesn't, since something like this might happen: Let's say that $(x_1)^2+x_2^2=(x_3)^2$, yet $(σx_1)^3+(σx_2)^2≠(σx_3)^2$, meaning that $σ$ has mapped the same element into two different places, meaning that $σ$ can not be an automorphism. For a specific example let $x_1=i$, $x_2=3^{1/2}$ and $x_3=2^{1/2}$. So the theorem doesn't hold for all polynomials. Will this at the end ruin the proof? Or is just insignificant to consider the polynomials in which the flaw occurs? I will really appreciate any help/thoughts.",,"['abstract-algebra', 'group-theory', 'reference-request', 'field-theory', 'galois-theory']"
3,Is there an algebraic way to prove this relationship between the roots of a real polynomial and the roots of its derivative?,Is there an algebraic way to prove this relationship between the roots of a real polynomial and the roots of its derivative?,,"Let $$\sum_{0 \leq i\leq n} a_ix^i$$ be  a polynomial (real coefficients) with at least two real roots. Is there an algebraic way to show that for any two roots $k_1, k_2$ of this polynomial, the polynomial $$\sum_{1 \leq i\leq n} i \cdot a_ix^{i-1} $$ admits at least one root $c$ satisfying $k_1 <c < k_2$? Analytically, this is of course a consequence of Rolle's theorem. Edit: ""Algebra"" is as broad as you want it to be. Elementary or abstract. The completeness of $\mathbb{R}$ is essential, so it won't be purely algebraic. I was mainly hoping for something without derivatives.","Let $$\sum_{0 \leq i\leq n} a_ix^i$$ be  a polynomial (real coefficients) with at least two real roots. Is there an algebraic way to show that for any two roots $k_1, k_2$ of this polynomial, the polynomial $$\sum_{1 \leq i\leq n} i \cdot a_ix^{i-1} $$ admits at least one root $c$ satisfying $k_1 <c < k_2$? Analytically, this is of course a consequence of Rolle's theorem. Edit: ""Algebra"" is as broad as you want it to be. Elementary or abstract. The completeness of $\mathbb{R}$ is essential, so it won't be purely algebraic. I was mainly hoping for something without derivatives.",,"['abstract-algebra', 'polynomials', 'roots']"
4,"Given a solvable Galois group, to find a formula for the roots?","Given a solvable Galois group, to find a formula for the roots?",,"Rereading my old abstract algebra textbook, there's a mention that for every polynomial with a solvable Galois group, there's a formula for the roots comparable to the classical formulae for polynomials of order 2, 3, and 4, but it doesn't elaborate.  So I was wondering - let's say you know the Galois group, but only have a symbolic representation of the coefficients, how do you come up with such a formula?","Rereading my old abstract algebra textbook, there's a mention that for every polynomial with a solvable Galois group, there's a formula for the roots comparable to the classical formulae for polynomials of order 2, 3, and 4, but it doesn't elaborate.  So I was wondering - let's say you know the Galois group, but only have a symbolic representation of the coefficients, how do you come up with such a formula?",,"['abstract-algebra', 'polynomials', 'galois-theory']"
5,If $|G|=p^3q^2$ then $\Phi(G)$ is cyclic for primes $p\neq q$.,If  then  is cyclic for primes .,|G|=p^3q^2 \Phi(G) p\neq q,"I have conjectured this result for the Frattini subgroup by doing some calculations in GAP. I think this is even true if $|G|=p_1^{i_1}\cdots p_n^{i_n}$ for $i_j\leq 3$ holds, but I would like to stick with this example first. I know the following: If $p\mid |G|$, then $p\mid |G/\Phi(G)|$, thus the order of $\Phi(G)$ is at most $p^2q$. Since $\Phi(G)$ is nilpotent, it must be abelian, too. That's why I think that it suffices to show this result for only abelian $G$ (which is fairly easy), as considering all abelian groups with that order would lead to all possible abelian $\Phi(G)$. But I still need a valid argument for that. I also tried the assumption $\Phi(G)=C_p\times C_p$ or $\Phi(G)=C_p\times C_p\times C_q$ but I have not yet found a contradiction. I would be glad to see some ideas or approaches for this conjecture.","I have conjectured this result for the Frattini subgroup by doing some calculations in GAP. I think this is even true if $|G|=p_1^{i_1}\cdots p_n^{i_n}$ for $i_j\leq 3$ holds, but I would like to stick with this example first. I know the following: If $p\mid |G|$, then $p\mid |G/\Phi(G)|$, thus the order of $\Phi(G)$ is at most $p^2q$. Since $\Phi(G)$ is nilpotent, it must be abelian, too. That's why I think that it suffices to show this result for only abelian $G$ (which is fairly easy), as considering all abelian groups with that order would lead to all possible abelian $\Phi(G)$. But I still need a valid argument for that. I also tried the assumption $\Phi(G)=C_p\times C_p$ or $\Phi(G)=C_p\times C_p\times C_q$ but I have not yet found a contradiction. I would be glad to see some ideas or approaches for this conjecture.",,"['abstract-algebra', 'group-theory', 'finite-groups', 'conjectures', 'frattini-subgroup']"
6,Proof of every finite group is finitely presented.,Proof of every finite group is finitely presented.,,"I'm reading the proof that every finite group is finitely presented from Dummit's Abstract Algebra, but there's a part that I don't understand. In the proof below, what are the elements $\tilde{g_i}$? I think they are the cosets $g_iN$, but how do we know that they generate $\tilde{G}$? And why does $|\tilde{G}|=|G|$ lead to $N=\ker \pi$? And finally, how do we get the sufficient condition (ii) in the final sentence? I really do not understand these parts and I'd greatly appreciate any explanations.","I'm reading the proof that every finite group is finitely presented from Dummit's Abstract Algebra, but there's a part that I don't understand. In the proof below, what are the elements $\tilde{g_i}$? I think they are the cosets $g_iN$, but how do we know that they generate $\tilde{G}$? And why does $|\tilde{G}|=|G|$ lead to $N=\ker \pi$? And finally, how do we get the sufficient condition (ii) in the final sentence? I really do not understand these parts and I'd greatly appreciate any explanations.",,"['abstract-algebra', 'group-theory', 'finite-groups', 'group-presentation']"
7,Proving (without using complex numbers) that a real polynomial has a quadratic factor,Proving (without using complex numbers) that a real polynomial has a quadratic factor,,"The Fundamental Theorem of Algebra tells us that any polynomial with real coefficients can be written as a product of linear factors over $\mathbb{C}$. If we don't want to use $\mathbb{C}$, the best we can say is: If $p(x)$ is a polynomial with real coefficients, $\deg p > 2$, then   there exists some quadratic polynomial $q(x)$ such that $q(x)$ is a   factor of  $p(x)$.  (There are then two cases: either $q(x)$ is   irreducible over $\mathbb{R}$, or it can be further factored as a   product of linear factors.) This is easily proven as a corollary of the FTA:  If we work over $\mathbb{C}$, $p(x)$ can be written as a product of linear factors, and since a complex number $z$ is a root of $p(x)$ if and only if its conjugate $\bar{z}$ is, we can pair up linear factors so as to get a real quadratic. (In fact, the theorem above -- which seems at first glance like a weaker form of the FTA -- is equivalent to it, since every real quadratic can be factored over $\mathbb{C}$.) Is there a way to prove the above theorem without invoking complex numbers?  It seems to have a certain value on its own as a property of the reals.  For example, the fact that any even-degree real polynomial of $\deg 2n$ can be factored into $n$ (real) quadratics seems like something one should be able to prove without needing to change fields. A version of this question was asked at Factorize real polynomials to quadratic factors. Proof without fundamental theorem of algebra. , but the accepted (and only) answer there just concluded that such a proof would be equivalent to the FTA.  I already know that; I'm wondering how one could write such a proof without passing to the algebraic closure. Or, to put it another way:  The statement of the theorem would make sense (and would be true) even if complex numbers had never been invented (or discovered, if you are a Platonist).  So it seems like it ought to be provable without using complex numbers.  Is it?","The Fundamental Theorem of Algebra tells us that any polynomial with real coefficients can be written as a product of linear factors over $\mathbb{C}$. If we don't want to use $\mathbb{C}$, the best we can say is: If $p(x)$ is a polynomial with real coefficients, $\deg p > 2$, then   there exists some quadratic polynomial $q(x)$ such that $q(x)$ is a   factor of  $p(x)$.  (There are then two cases: either $q(x)$ is   irreducible over $\mathbb{R}$, or it can be further factored as a   product of linear factors.) This is easily proven as a corollary of the FTA:  If we work over $\mathbb{C}$, $p(x)$ can be written as a product of linear factors, and since a complex number $z$ is a root of $p(x)$ if and only if its conjugate $\bar{z}$ is, we can pair up linear factors so as to get a real quadratic. (In fact, the theorem above -- which seems at first glance like a weaker form of the FTA -- is equivalent to it, since every real quadratic can be factored over $\mathbb{C}$.) Is there a way to prove the above theorem without invoking complex numbers?  It seems to have a certain value on its own as a property of the reals.  For example, the fact that any even-degree real polynomial of $\deg 2n$ can be factored into $n$ (real) quadratics seems like something one should be able to prove without needing to change fields. A version of this question was asked at Factorize real polynomials to quadratic factors. Proof without fundamental theorem of algebra. , but the accepted (and only) answer there just concluded that such a proof would be equivalent to the FTA.  I already know that; I'm wondering how one could write such a proof without passing to the algebraic closure. Or, to put it another way:  The statement of the theorem would make sense (and would be true) even if complex numbers had never been invented (or discovered, if you are a Platonist).  So it seems like it ought to be provable without using complex numbers.  Is it?",,"['abstract-algebra', 'polynomials', 'real-numbers', 'alternative-proof']"
8,Separable field extensions *without* using embeddings or automorphisms,Separable field extensions *without* using embeddings or automorphisms,,"If $K\subseteq L$ is a field extension and $x\in L$ is algebraic, we say that $x$ is separable over $K$ iff its minimal polynomial $f$ over $K$ is separable (i.e., $f$ is relatively prime with its derivative).  We say that $L$ is a separable algebraic extension iff every element of $L$ is separable algebraic. These definitions, of course, are quite standard.  Now what I'd like to find is a proof of such standard facts as ""if $x$ is algebraic separable over $K$ then $K(x)$ is separable"" and ""if $L$ is algebraic separable over $K$ and $M$ is such over $L$ then $M$ is such over $K$"", or a definition of the separable degree of an extension, all without using field automorphisms or the trick of counting embeddings in an algebraic closure. (There can be a number of reasons to want this: for pedagogical purposesout of a desire to postpone a discussion of Galois theory at a later point, or because embeddings/automorphisms are computationally or logically more complex objects than field extensions, or simply because it seems that the point of view in the first paragraph above should be more natural, or to compare different points of view.) Now every textbook I could find on field extensions uses at some point a comparison between the number of embeddings of $L$ in the algebraic closure of $K$ and the degree $[L:K]$.  But surely this can be avoided (we can, instead, work explicitly with roots of polynomials and perhaps elementary symmetric functions). So, does someone know a place where separable field extensions are introduced without counting embeddings or similar objects, staying as close as possible to the definition I gave above? Edit : Maybe the nicest definition of an algebraic $x$ being separable over $K$ of characteristic $p$ is that $K(x) = K(x^p)$.","If $K\subseteq L$ is a field extension and $x\in L$ is algebraic, we say that $x$ is separable over $K$ iff its minimal polynomial $f$ over $K$ is separable (i.e., $f$ is relatively prime with its derivative).  We say that $L$ is a separable algebraic extension iff every element of $L$ is separable algebraic. These definitions, of course, are quite standard.  Now what I'd like to find is a proof of such standard facts as ""if $x$ is algebraic separable over $K$ then $K(x)$ is separable"" and ""if $L$ is algebraic separable over $K$ and $M$ is such over $L$ then $M$ is such over $K$"", or a definition of the separable degree of an extension, all without using field automorphisms or the trick of counting embeddings in an algebraic closure. (There can be a number of reasons to want this: for pedagogical purposesout of a desire to postpone a discussion of Galois theory at a later point, or because embeddings/automorphisms are computationally or logically more complex objects than field extensions, or simply because it seems that the point of view in the first paragraph above should be more natural, or to compare different points of view.) Now every textbook I could find on field extensions uses at some point a comparison between the number of embeddings of $L$ in the algebraic closure of $K$ and the degree $[L:K]$.  But surely this can be avoided (we can, instead, work explicitly with roots of polynomials and perhaps elementary symmetric functions). So, does someone know a place where separable field extensions are introduced without counting embeddings or similar objects, staying as close as possible to the definition I gave above? Edit : Maybe the nicest definition of an algebraic $x$ being separable over $K$ of characteristic $p$ is that $K(x) = K(x^p)$.",,"['abstract-algebra', 'reference-request', 'field-theory', 'extension-field']"
9,"If $P \in Syl_p(G)$ and $P$ is cyclic, then $N_G(P)=C_G(P)$","If  and  is cyclic, then",P \in Syl_p(G) P N_G(P)=C_G(P),"Let $G$ be a group such that $|G|=p^a m$ where $p$ is the smallest prime divisor of $|G|$.         If $P \in Syl_p(G)$ and $P$ is cyclic, then $N_G(P)=C_G(P)$ Proof First, note that $C_G(P) \leq N_G(P) \leq G$. Thus, we are done if $|N_G(P)|/|C_G(P)|=1$.         Since $P \leq G$, by Corollary 15, $N_G(P)/C_G(P)$ is isomorphic to a subgroup of $Aut(P)$.         Since $P$ is cyclic of order $p^a$, we have $P \cong \mathbb{Z}/p^a \mathbb{Z}$.         Thus, $|Aut(P)| = |Aut(\mathbb{Z}/ p^a \mathbb{Z})| = |(\mathbb{Z}/p^a \mathbb{Z})^{\times}|$ since         $Aut(\mathbb{Z}/ p^a \mathbb{Z})| \cong (\mathbb{Z}/p^a \mathbb{Z})^{\times}$.          Then, $|Aut(P)| = \phi(p^a) = p^{a-1}(p-1)$ where $\phi$ is Euler's totient function.         Thus, $N_G(P)/C_G(P)$ divides $p^{a-1}(p-1)$. Since $P$ is cyclic, $P$ in particular is abelian, and it follows that $P \leq C_G(P) \leq N_G(P)$. Since $P \leq N_G(P)$, there exists a positive integer $k_1, k_2$ such that $|N_G(P)|=k_1 p^a$ and $|C_G(P)|=k_2 p^a$. Since $k_1 p^a$ divides $p^a m$, $k_1$ must divide $m$. Since $|N_G(P)|/|C_G(P)|=k_1/k_2$, $|N_G(P)/C_G(P)|$ divides $m$. Since the prime divisors of $m$ are greater than $p$, it must be that $|N_G(P)/C_G(P)|=1$. This completes the proof. I don't really like the way argued the division of $m$. Is there a more succinct and better way to argue this? Thank you in advance!","Let $G$ be a group such that $|G|=p^a m$ where $p$ is the smallest prime divisor of $|G|$.         If $P \in Syl_p(G)$ and $P$ is cyclic, then $N_G(P)=C_G(P)$ Proof First, note that $C_G(P) \leq N_G(P) \leq G$. Thus, we are done if $|N_G(P)|/|C_G(P)|=1$.         Since $P \leq G$, by Corollary 15, $N_G(P)/C_G(P)$ is isomorphic to a subgroup of $Aut(P)$.         Since $P$ is cyclic of order $p^a$, we have $P \cong \mathbb{Z}/p^a \mathbb{Z}$.         Thus, $|Aut(P)| = |Aut(\mathbb{Z}/ p^a \mathbb{Z})| = |(\mathbb{Z}/p^a \mathbb{Z})^{\times}|$ since         $Aut(\mathbb{Z}/ p^a \mathbb{Z})| \cong (\mathbb{Z}/p^a \mathbb{Z})^{\times}$.          Then, $|Aut(P)| = \phi(p^a) = p^{a-1}(p-1)$ where $\phi$ is Euler's totient function.         Thus, $N_G(P)/C_G(P)$ divides $p^{a-1}(p-1)$. Since $P$ is cyclic, $P$ in particular is abelian, and it follows that $P \leq C_G(P) \leq N_G(P)$. Since $P \leq N_G(P)$, there exists a positive integer $k_1, k_2$ such that $|N_G(P)|=k_1 p^a$ and $|C_G(P)|=k_2 p^a$. Since $k_1 p^a$ divides $p^a m$, $k_1$ must divide $m$. Since $|N_G(P)|/|C_G(P)|=k_1/k_2$, $|N_G(P)/C_G(P)|$ divides $m$. Since the prime divisors of $m$ are greater than $p$, it must be that $|N_G(P)/C_G(P)|=1$. This completes the proof. I don't really like the way argued the division of $m$. Is there a more succinct and better way to argue this? Thank you in advance!",,"['abstract-algebra', 'group-theory', 'proof-verification', 'finite-groups', 'sylow-theory']"
10,Find roots or splitting field of a polynomial given its Galois group,Find roots or splitting field of a polynomial given its Galois group,,"A well known result from Galois theory is that the roots of a polynomial can be expressed by a formula using field operations and taking $k$-th roots if and only if the Galois group of the polynomial is solvable. How would you actually find such a formula given a solution of the Galois group? For example I tried to find a root of the polynomial $f(x) = x^3-x-1$ (I know that formulae exist for the roots of polynomials with degree $< 5$, but I am hoping for a more general approach). Observing that $f$ is irreducible, and that $f(x)$ has only one real root, it is not difficult to show that $Gal(E/\mathbb{Q}) \simeq S_3$ (where $E$ is the splitting field of $f$ ), because it is a subgroup of $S_3$ and it has at subgroup of order 2 (complex conjugation) and it acts transitively on the set of roots. Since $S_3$ is solvable we know that $E$ is contained in a radical extension of $\mathbb{Q}$. How would you go from here to find the roots? Is there a general approach or some tricks that can be used? I can't just follow the proof of the theorem that guarantees the existence of a radical extension, because i would need to know the automorphisms.","A well known result from Galois theory is that the roots of a polynomial can be expressed by a formula using field operations and taking $k$-th roots if and only if the Galois group of the polynomial is solvable. How would you actually find such a formula given a solution of the Galois group? For example I tried to find a root of the polynomial $f(x) = x^3-x-1$ (I know that formulae exist for the roots of polynomials with degree $< 5$, but I am hoping for a more general approach). Observing that $f$ is irreducible, and that $f(x)$ has only one real root, it is not difficult to show that $Gal(E/\mathbb{Q}) \simeq S_3$ (where $E$ is the splitting field of $f$ ), because it is a subgroup of $S_3$ and it has at subgroup of order 2 (complex conjugation) and it acts transitively on the set of roots. Since $S_3$ is solvable we know that $E$ is contained in a radical extension of $\mathbb{Q}$. How would you go from here to find the roots? Is there a general approach or some tricks that can be used? I can't just follow the proof of the theorem that guarantees the existence of a radical extension, because i would need to know the automorphisms.",,"['abstract-algebra', 'galois-theory']"
11,A familiar quasigroup - about independent axioms,A familiar quasigroup - about independent axioms,,"A quasigroup is a pair $(Q,/)$, where $/$ is a binary operation on $Q$, such that (1) for each $a,b\in Q$ there exists unique solutions to the equations $a/x=b$ and $y/a=b$. Now I want to extract a class of quasigroups that captures characteristics from $(Q_+,/)$, where $Q_+$ is the set of positive rational numbers and $/$ is division. So far I have chosen the three properties below and want to know if they are independent or if any of them can be derived from the other two plus (1): $a/(b/c)=c/(b/a)$, for all $a,b,c\in Q$ $(a/b)/c=(a/c)/b$, for all $a,b,c\in Q$ $(a/b)/(c/d)=(d/c)/(b/a)$, for all $a,b,c,d\in Q$","A quasigroup is a pair $(Q,/)$, where $/$ is a binary operation on $Q$, such that (1) for each $a,b\in Q$ there exists unique solutions to the equations $a/x=b$ and $y/a=b$. Now I want to extract a class of quasigroups that captures characteristics from $(Q_+,/)$, where $Q_+$ is the set of positive rational numbers and $/$ is division. So far I have chosen the three properties below and want to know if they are independent or if any of them can be derived from the other two plus (1): $a/(b/c)=c/(b/a)$, for all $a,b,c\in Q$ $(a/b)/c=(a/c)/b$, for all $a,b,c\in Q$ $(a/b)/(c/d)=(d/c)/(b/a)$, for all $a,b,c,d\in Q$",,"['abstract-algebra', 'axioms', 'quasigroups']"
12,Median order of an element in an additive group modulo $n$,Median order of an element in an additive group modulo,n,"I'm trying to gain some intuition here. Suppose we have the group $\mathbb{Z}_{n}$ (with the operation being addition modulo $n$). What is the median order of an element of this group when $n$ is a randomly chosen large number? I realize that when $n$ is prime, the median order will be $n$, because all elements other than the identity have order $n$. Also, are there any special values of $n$ that make the median order very small relative to $n$ (say $O(\log n)$)? If this sounds vague, here is a more concrete explanation of my question: Given a number $n$, let $\alpha(n)$ denote the median order of all elements of the group $\mathbb{Z}_n$. Are there any special values of $n$ (say, $m!$ or $p^m$ for a prime $p$, or something like that) for which $\alpha(n)$ is very small compared to $n$? What if $n$ is a randomly chosen large number? What would you expect the value of $\alpha(n)$ to be? Would it be of the order of $n$?","I'm trying to gain some intuition here. Suppose we have the group $\mathbb{Z}_{n}$ (with the operation being addition modulo $n$). What is the median order of an element of this group when $n$ is a randomly chosen large number? I realize that when $n$ is prime, the median order will be $n$, because all elements other than the identity have order $n$. Also, are there any special values of $n$ that make the median order very small relative to $n$ (say $O(\log n)$)? If this sounds vague, here is a more concrete explanation of my question: Given a number $n$, let $\alpha(n)$ denote the median order of all elements of the group $\mathbb{Z}_n$. Are there any special values of $n$ (say, $m!$ or $p^m$ for a prime $p$, or something like that) for which $\alpha(n)$ is very small compared to $n$? What if $n$ is a randomly chosen large number? What would you expect the value of $\alpha(n)$ to be? Would it be of the order of $n$?",,"['abstract-algebra', 'group-theory', 'number-theory', 'elementary-number-theory']"
13,"Let R be a ring. Prove that if $x^2=x$ for each $x \in R$, then R is a commutative ring. [duplicate]","Let R be a ring. Prove that if  for each , then R is a commutative ring. [duplicate]",x^2=x x \in R,"This question already has answers here : How to show that every Boolean ring is commutative? (14 answers) Closed 8 years ago . Let R be a ring. Prove that if $x^2=x$ for each $x \in R$, then R is a commutative ring. Ok, so I'm just looking for some confirmation that I'm doing this correctly. If we suppose $x,y \in R$ Let's consider $(x+y)^2$, Then $(x+y)^2 = x^2+xy+yx+y^2$ but $x^2=x$ and $y^2=y$ We can also see that for all $x \in R, x=-x$ So, $(x+y)^2= x+xy+yx+y$ Also, by our given  $(x+y)^2=(x+y)$ so $x+y =x+xy+yx+y$, Solving this algebraicly gives us $-yx=xy$ but since $(-yx)^2=(yx)$, We have, $yx=xy$, Therefore R is commutative. Does that about wrap it up?","This question already has answers here : How to show that every Boolean ring is commutative? (14 answers) Closed 8 years ago . Let R be a ring. Prove that if $x^2=x$ for each $x \in R$, then R is a commutative ring. Ok, so I'm just looking for some confirmation that I'm doing this correctly. If we suppose $x,y \in R$ Let's consider $(x+y)^2$, Then $(x+y)^2 = x^2+xy+yx+y^2$ but $x^2=x$ and $y^2=y$ We can also see that for all $x \in R, x=-x$ So, $(x+y)^2= x+xy+yx+y$ Also, by our given  $(x+y)^2=(x+y)$ so $x+y =x+xy+yx+y$, Solving this algebraicly gives us $-yx=xy$ but since $(-yx)^2=(yx)$, We have, $yx=xy$, Therefore R is commutative. Does that about wrap it up?",,"['abstract-algebra', 'group-theory', 'ring-theory', 'proof-verification']"
14,Galois group solvable but $f$ not solvable.,Galois group solvable but  not solvable.,f,"I know from a theorem that: Let $F$ be a field of characteristic $0$ and $f(x)\in F[x]$ . Then $f(x)$ is solvable by radicals if and only if the Galois group of $f(x)$ is solvable. But what if the field was not characteristic $0$ ? I've seen the result that if $F = \mathbb F_p(t)$ , then this theorem is completely false. If $f = x^p - x - t\in F[x]$ , the Galois group of $f$ is solvable, but $f$ is not solvable. But why is this true? I believe I can see why the Galois group is solvable because the Galois group is cyclic and hence isomorphic to $\mathbb{Z}/p\mathbb Z$ , but I cannot fully grasp why $f$ is not solvable. I tried do this by contradiction but got no result. Can anyone help me?","I know from a theorem that: Let be a field of characteristic and . Then is solvable by radicals if and only if the Galois group of is solvable. But what if the field was not characteristic ? I've seen the result that if , then this theorem is completely false. If , the Galois group of is solvable, but is not solvable. But why is this true? I believe I can see why the Galois group is solvable because the Galois group is cyclic and hence isomorphic to , but I cannot fully grasp why is not solvable. I tried do this by contradiction but got no result. Can anyone help me?",F 0 f(x)\in F[x] f(x) f(x) 0 F = \mathbb F_p(t) f = x^p - x - t\in F[x] f f \mathbb{Z}/p\mathbb Z f,"['abstract-algebra', 'galois-theory']"
15,Involutions of the second type in a division algebra,Involutions of the second type in a division algebra,,"I'm trying to figure out some details about involutions of division algebra, thought maybe someone here might have a better insight. Let $k$ be a $p$-adic or number field, and let $K=k[\sqrt{\delta}]$ be a non-trivial extension of degree $2$. For $x\in K$, let $\bar{x}$ denote the conjugate of $x$ under the non-trivial $K/k$ automorphism. Let $D$ be a division algebra of degree $\ell$ with $Z(D)=K$. For simplicity, we shall assume that $\ell$ is prime (or even $\ell=3$ is enough for the moment). An involution of the second type of $D$ is a $k$-linear anti-automorphism of $\tau:D\to D$ which coincides with $\bar{ }$ on $K$, and is of order two. That is to say that for any $t,s\in D$ and $\alpha,\beta\in $K$ $$(1)\:\tau(\alpha t+\beta s)=\bar{\alpha}\tau(t)+\bar{\beta}\tau(s),\quad(2)\: \tau(st)=\tau(t)\tau(s),\quad\text{and}\quad(2)\:\tau^2(t)=t.$$ Note that if $\tau,\eta$ are two involutions of type 2 of $D$, then $\tau\circ\mu$ is a $K$-automorphism of $D$. It follows easily (by the Skolem-Noether theorem) that there exists some $\gamma\in D$ such that $\tau(t)=\gamma^{-1}\mu(t)\gamma$ for all $t\in D$. In the case where $D$ is a quaternion algerbra over $K$ (i.e. a division algebra of degree $2$), one can construct a non-trivial involution of the second type on $D$ in the following way: Since the order of quaternion algebras in the Brauer group of a field is two, it follows that for any field $L$ and quaternion algebra $L$ has a non-trivial $L$-involution (i.e. an $L$-linear anti-automrophism of the algebra). This holds since the fact that $L$ has order two in the Brauer group is equivalent to $L$ being isomorphic to $L^{op}$, the opposite algebra, and hence existence of a non trivial map $L\to L^{op}$, which is the same thing as an anti-automorphism. Let $\mathbf{d}$ be a quaternion algebra over $k$, and let $\tau':\mathbf{d}\to\mathbf{d}$ be the non-trivial $k$ involution. One shows that $D\cong \mathbf{d}\otimes_K K$ as $K$-algebras, and that the map defined on generators by $\tau(t\otimes \alpha)=\tau(t)\otimes \bar{\alpha}$ is a field automorphism. The question is- what happens for higher degrees? In the book ""The Book of Involutions"", Knus presents an argument for the existence of a non-trivial involution of the second type on $D$. Namely, such an involution exists if and only if the norm $N_{K/k}(D)$ is a split $F$ algebra (see $\S 3$ of the book for the definition of the norm algebra, I  will add it here if someone here irequests it). My problem with Knus's proof is that it in not constructive, in the sense that it presents the reader with a bijection between the set of 2nd type involutions of $D$, and some specific set of left-sided ideals in $N_{K/k}(D)$, but shows that such ideals exists if the splitting condition holds. But it is terribly unclear to me, how to go back and construct such an involution once you've shown that it exists. So, after all this long introduction- here is my question Question : Does anybody here know of an example of a division algebra of degree 3 (or higher) over a $p$-adic or global field, which has a non-trivial and explicitly presented involution of the second type? I would be very thankful for any reference or example that anyone can offer. Thank you.","I'm trying to figure out some details about involutions of division algebra, thought maybe someone here might have a better insight. Let $k$ be a $p$-adic or number field, and let $K=k[\sqrt{\delta}]$ be a non-trivial extension of degree $2$. For $x\in K$, let $\bar{x}$ denote the conjugate of $x$ under the non-trivial $K/k$ automorphism. Let $D$ be a division algebra of degree $\ell$ with $Z(D)=K$. For simplicity, we shall assume that $\ell$ is prime (or even $\ell=3$ is enough for the moment). An involution of the second type of $D$ is a $k$-linear anti-automorphism of $\tau:D\to D$ which coincides with $\bar{ }$ on $K$, and is of order two. That is to say that for any $t,s\in D$ and $\alpha,\beta\in $K$ $$(1)\:\tau(\alpha t+\beta s)=\bar{\alpha}\tau(t)+\bar{\beta}\tau(s),\quad(2)\: \tau(st)=\tau(t)\tau(s),\quad\text{and}\quad(2)\:\tau^2(t)=t.$$ Note that if $\tau,\eta$ are two involutions of type 2 of $D$, then $\tau\circ\mu$ is a $K$-automorphism of $D$. It follows easily (by the Skolem-Noether theorem) that there exists some $\gamma\in D$ such that $\tau(t)=\gamma^{-1}\mu(t)\gamma$ for all $t\in D$. In the case where $D$ is a quaternion algerbra over $K$ (i.e. a division algebra of degree $2$), one can construct a non-trivial involution of the second type on $D$ in the following way: Since the order of quaternion algebras in the Brauer group of a field is two, it follows that for any field $L$ and quaternion algebra $L$ has a non-trivial $L$-involution (i.e. an $L$-linear anti-automrophism of the algebra). This holds since the fact that $L$ has order two in the Brauer group is equivalent to $L$ being isomorphic to $L^{op}$, the opposite algebra, and hence existence of a non trivial map $L\to L^{op}$, which is the same thing as an anti-automorphism. Let $\mathbf{d}$ be a quaternion algebra over $k$, and let $\tau':\mathbf{d}\to\mathbf{d}$ be the non-trivial $k$ involution. One shows that $D\cong \mathbf{d}\otimes_K K$ as $K$-algebras, and that the map defined on generators by $\tau(t\otimes \alpha)=\tau(t)\otimes \bar{\alpha}$ is a field automorphism. The question is- what happens for higher degrees? In the book ""The Book of Involutions"", Knus presents an argument for the existence of a non-trivial involution of the second type on $D$. Namely, such an involution exists if and only if the norm $N_{K/k}(D)$ is a split $F$ algebra (see $\S 3$ of the book for the definition of the norm algebra, I  will add it here if someone here irequests it). My problem with Knus's proof is that it in not constructive, in the sense that it presents the reader with a bijection between the set of 2nd type involutions of $D$, and some specific set of left-sided ideals in $N_{K/k}(D)$, but shows that such ideals exists if the splitting condition holds. But it is terribly unclear to me, how to go back and construct such an involution once you've shown that it exists. So, after all this long introduction- here is my question Question : Does anybody here know of an example of a division algebra of degree 3 (or higher) over a $p$-adic or global field, which has a non-trivial and explicitly presented involution of the second type? I would be very thankful for any reference or example that anyone can offer. Thank you.",,"['abstract-algebra', 'number-theory', 'division-algebras', 'involutions']"
16,Follow up to Pinter's abstract algebra,Follow up to Pinter's abstract algebra,,"I wanted to learn abstract algebra this summer so I bought Pinter's A book of Abstract Algebra . I was planning on reading it over the course of the summer, but just finished the last problem of its final chapter! I found the subject absolutely enthralling and now want to learn more, as such my question is: What algebra textbooks/topics would provide a good follow up to Pinter's text? Edit: Please note that my prerequsites are somewhat limited. As far as serious math classes, I've only taken ODEs, probability, and Analysis 1 (Rudin Ch 1-6).","I wanted to learn abstract algebra this summer so I bought Pinter's A book of Abstract Algebra . I was planning on reading it over the course of the summer, but just finished the last problem of its final chapter! I found the subject absolutely enthralling and now want to learn more, as such my question is: What algebra textbooks/topics would provide a good follow up to Pinter's text? Edit: Please note that my prerequsites are somewhat limited. As far as serious math classes, I've only taken ODEs, probability, and Analysis 1 (Rudin Ch 1-6).",,"['abstract-algebra', 'reference-request', 'soft-question', 'self-learning', 'advice']"
17,A module as an external direct product of the kernel and image of an idempotent function,A module as an external direct product of the kernel and image of an idempotent function,,"If $f:A\rightarrow A$ is an $R$ -module homomorphism such that $ff=f$ , show that $$A=\ker f\oplus{\rm im}~f$$ Here is a part of what I made as a proof. Let $a\in A$ . $f(a)\in{\rm im}~f$ , $f(a)\in A$ since $f$ is from $A$ to $A$ , $a-f(a) \in A$ since $A$ is a module. Consider $f(a-f(a))$ . Since $f$ is a module homomorphism, $$f(a-f(a))=f(a)-ff(a)=f(a)-f(a)=0,$$ therefore $a-f(a)\in\ker f$ . We have $a-f(a)\in\ker f$ and $f(a)\in{\rm im}~f$ . $$(a-f(a))+f(a)=a-f(a)+f(a)=a$$ So $a\in A$ can be written as the sum of an element in $\ker f$ and an element in ${\rm im}~f$ and since $\ker f$ and ${\rm im}~f$ are submodules of $A$ , we have $$A=\ker f+{\rm im}~f.$$ I was also able to show that the intersection of $\ker f$ and ${\rm im}~f$ is $\{0\}$ . I showed this proof to one of my senior and he said that what I actually did in my proof was show that $A$ is the Internal Direct Sum of $\ker f$ and ${\rm im}~f$ . Looking back at the problem, what is asked is to prove that $A$ is the External Direct Sum of $\ker f$ and ${\rm im}~f$ . I got the internal and external direct sum wrong but I understand them now. Now how would I go on proving the problem? Here are some of my questions/ideas: Since I'm trying to prove that $A$ is an external direct sum may I assume that $A=X\oplus Y$ where $X$ and $Y$ are modules? Then try to prove that that $\ker f=X$ and ${\rm im}~f=Y$ ? Also, if $A$ is the external direct product of $\ker f$ and ${\rm im}~f$ then that means that an element in $A$ is of the form $(x,y)$ where $x\in\ker f$ and $y\in{\rm im}~f$ right? Does that mean that I have to define $f$ in $X$ and $Y$ ? Is it possible to salvage my proof above? When does the internal direct sum equal to the external direct sum? I know that it is always the case that the two are isomorphic. If I remember correctly in groups it is possible for the internal direct product and the external direct product to be equal. I hope you guys could clarify some things to me and point me in the right direction. Thank you!","If is an -module homomorphism such that , show that Here is a part of what I made as a proof. Let . , since is from to , since is a module. Consider . Since is a module homomorphism, therefore . We have and . So can be written as the sum of an element in and an element in and since and are submodules of , we have I was also able to show that the intersection of and is . I showed this proof to one of my senior and he said that what I actually did in my proof was show that is the Internal Direct Sum of and . Looking back at the problem, what is asked is to prove that is the External Direct Sum of and . I got the internal and external direct sum wrong but I understand them now. Now how would I go on proving the problem? Here are some of my questions/ideas: Since I'm trying to prove that is an external direct sum may I assume that where and are modules? Then try to prove that that and ? Also, if is the external direct product of and then that means that an element in is of the form where and right? Does that mean that I have to define in and ? Is it possible to salvage my proof above? When does the internal direct sum equal to the external direct sum? I know that it is always the case that the two are isomorphic. If I remember correctly in groups it is possible for the internal direct product and the external direct product to be equal. I hope you guys could clarify some things to me and point me in the right direction. Thank you!","f:A\rightarrow A R ff=f A=\ker f\oplus{\rm im}~f a\in A f(a)\in{\rm im}~f f(a)\in A f A A a-f(a) \in A A f(a-f(a)) f f(a-f(a))=f(a)-ff(a)=f(a)-f(a)=0, a-f(a)\in\ker f a-f(a)\in\ker f f(a)\in{\rm im}~f (a-f(a))+f(a)=a-f(a)+f(a)=a a\in A \ker f {\rm im}~f \ker f {\rm im}~f A A=\ker f+{\rm im}~f. \ker f {\rm im}~f \{0\} A \ker f {\rm im}~f A \ker f {\rm im}~f A A=X\oplus Y X Y \ker f=X {\rm im}~f=Y A \ker f {\rm im}~f A (x,y) x\in\ker f y\in{\rm im}~f f X Y","['abstract-algebra', 'ring-theory', 'modules', 'terminology', 'direct-sum']"
18,When are infinite dimensional path algebras hereditary,When are infinite dimensional path algebras hereditary,,"The title says mostly everything. Suppose we  have a quiver, maybe with relations and cycles. Is it known when the path algebra modulo relations is hereditary? Especially in the case that the path algebra is infinite dimensional. I would appreciate any reference.","The title says mostly everything. Suppose we  have a quiver, maybe with relations and cycles. Is it known when the path algebra modulo relations is hereditary? Especially in the case that the path algebra is infinite dimensional. I would appreciate any reference.",,"['abstract-algebra', 'reference-request', 'ring-theory', 'quiver']"
19,Groups with only one element of order 2,Groups with only one element of order 2,,"I am doing some exercises in Algebra: Chapter 0 . In the second chapter, we are asked to prove the following: $G$ is a finite group with a unique element $f$ of order $2$. Then $\operatorname{\Pi_{g\in G}}g=f$. This result is highly plausible. If we multiply the elements in the order of \begin{equation}e\cdot f\cdot \text{elements of order 3}\cdot\text{elements of order 4}\cdots,\end{equation} and pair elements with their inverses, then we get $f$, since it is the only element that does not have a couple. However this is only one possible order of multiplication, and we know that in general different order give different results. So I wonder how we can do the general case. Thanks!","I am doing some exercises in Algebra: Chapter 0 . In the second chapter, we are asked to prove the following: $G$ is a finite group with a unique element $f$ of order $2$. Then $\operatorname{\Pi_{g\in G}}g=f$. This result is highly plausible. If we multiply the elements in the order of \begin{equation}e\cdot f\cdot \text{elements of order 3}\cdot\text{elements of order 4}\cdots,\end{equation} and pair elements with their inverses, then we get $f$, since it is the only element that does not have a couple. However this is only one possible order of multiplication, and we know that in general different order give different results. So I wonder how we can do the general case. Thanks!",,"['abstract-algebra', 'group-theory']"
20,Calculating the norm of an element in a field extension.,Calculating the norm of an element in a field extension.,,"Given a number field $\mathbb{Q}[\beta]$, where the minimal polynomial of $\beta$ in $\mathbb[Z][x]$ has degree $n$, I would like to calculate the norm of the general element $$a_0+a_1\beta+\cdots+a_{n-1}\beta^{n-1}.$$ In particular, here is my attempt when $\alpha=2^\frac{1}{3}$: Let $K=Q[2^\frac{1}{3}]$.  Using the definition of the norm , it is the determinant of the linear transformation.  Consider $\alpha =a+2^{\frac{1}{3}}b+2^{\frac{2}{3}}c$ acting by multiplication on the element $d+2^{\frac{1}{3}}e+2^{\frac{2}{3}}f$.  Since $$\left(a+2^{\frac{1}{3}}b+2^{\frac{2}{3}}c\right)\left(d+2^{\frac{1}{3}}e+2^{\frac{2}{3}}f\right)=ad+2bf+2ce+2^{\frac{1}{3}}\left(ae+bd+2cf\right)+2^{\frac{2}{3}}\left(af+dc+be\right) $$ in the basis $[1,2^{\frac{1}{3}},2^{\frac{2}{3}}$ we may view multiplication by $\alpha$ as a linear transform $$\alpha\left[\begin{array}{c} d\\ e\\ f \end{array}\right]=\left[\begin{array}{c} ad+2bf+2ce\\ ae+bd+2cf\\ af+dc+be \end{array}\right].$$  Using the above, we see that $$\alpha=\left[\begin{array}{ccc} a & 2c & 2b\\ b & a & 2c\\ c & b & a \end{array}\right] $$ in this basis.  Taking the determinant we find $$\det \left[\begin{array}{ccc} a & 2c & 2b\\ b & a & 2c\\ c & b & a \end{array}\right] =a\left(a^{2}-2bc\right)-2c\left(ba-2c^{2}\right)+2b(b^{2}-ac) $$ $$=a^{3}+2b^{3}+4c^{3}-6abc. $$ This means we have shown that $N_K(\alpha)=a^{3}+2b^{3}+4c^{3}-6abc$ for $\alpha=a+2^{\frac{1}{3}}b+2^{\frac{2}{3}}c$ Questions: (1) Was the above calculation correct?  Can we conclude that the norm of a general element in that space is $a^{3}+2b^{3}+4c^{3}-6abc$? (2) Is there a better way to do this computation?  What about if the extension is Galois?","Given a number field $\mathbb{Q}[\beta]$, where the minimal polynomial of $\beta$ in $\mathbb[Z][x]$ has degree $n$, I would like to calculate the norm of the general element $$a_0+a_1\beta+\cdots+a_{n-1}\beta^{n-1}.$$ In particular, here is my attempt when $\alpha=2^\frac{1}{3}$: Let $K=Q[2^\frac{1}{3}]$.  Using the definition of the norm , it is the determinant of the linear transformation.  Consider $\alpha =a+2^{\frac{1}{3}}b+2^{\frac{2}{3}}c$ acting by multiplication on the element $d+2^{\frac{1}{3}}e+2^{\frac{2}{3}}f$.  Since $$\left(a+2^{\frac{1}{3}}b+2^{\frac{2}{3}}c\right)\left(d+2^{\frac{1}{3}}e+2^{\frac{2}{3}}f\right)=ad+2bf+2ce+2^{\frac{1}{3}}\left(ae+bd+2cf\right)+2^{\frac{2}{3}}\left(af+dc+be\right) $$ in the basis $[1,2^{\frac{1}{3}},2^{\frac{2}{3}}$ we may view multiplication by $\alpha$ as a linear transform $$\alpha\left[\begin{array}{c} d\\ e\\ f \end{array}\right]=\left[\begin{array}{c} ad+2bf+2ce\\ ae+bd+2cf\\ af+dc+be \end{array}\right].$$  Using the above, we see that $$\alpha=\left[\begin{array}{ccc} a & 2c & 2b\\ b & a & 2c\\ c & b & a \end{array}\right] $$ in this basis.  Taking the determinant we find $$\det \left[\begin{array}{ccc} a & 2c & 2b\\ b & a & 2c\\ c & b & a \end{array}\right] =a\left(a^{2}-2bc\right)-2c\left(ba-2c^{2}\right)+2b(b^{2}-ac) $$ $$=a^{3}+2b^{3}+4c^{3}-6abc. $$ This means we have shown that $N_K(\alpha)=a^{3}+2b^{3}+4c^{3}-6abc$ for $\alpha=a+2^{\frac{1}{3}}b+2^{\frac{2}{3}}c$ Questions: (1) Was the above calculation correct?  Can we conclude that the norm of a general element in that space is $a^{3}+2b^{3}+4c^{3}-6abc$? (2) Is there a better way to do this computation?  What about if the extension is Galois?",,"['abstract-algebra', 'field-theory', 'galois-theory', 'normed-spaces']"
21,How to find irreducible polynomials over $\mathbb{Q}(i)$ with prescribed Galois group?,How to find irreducible polynomials over  with prescribed Galois group?,\mathbb{Q}(i),"Here is my recent homework question: For each of the following five fields $F$ and five groups $G$ , find an irreducible polynomial in $F[x]$ whose Galois group is isomorphic to $G$ . If no example exists, you must justify that. Fields $F$ : $\mathbb{C}$ , $\mathbb{R}$ , $\mathbb{F}_{11}$ , $\mathbb{Q}$ , $\mathbb{Q}(i)$ Groups $G$ : $C_2$ , $C_5$ , $C_2\times C_2$ , $S_3$ , $D_4$ I've found the polynomials for first 4 fields; however, I've got no idea about the $\mathbb{Q}(i)$ one. Can anyone here help me? Thanks, and regards. Now, I just found I made mistakes in looking for C2xC2 and C5 one . The polynomial I found are not irreducible ( in fact only with separable irreducible factors ).  Moreover, I don't know how to check the irreducibility of polynomial in F11. So I also can't do this part..","Here is my recent homework question: For each of the following five fields and five groups , find an irreducible polynomial in whose Galois group is isomorphic to . If no example exists, you must justify that. Fields : , , , , Groups : , , , , I've found the polynomials for first 4 fields; however, I've got no idea about the one. Can anyone here help me? Thanks, and regards. Now, I just found I made mistakes in looking for C2xC2 and C5 one . The polynomial I found are not irreducible ( in fact only with separable irreducible factors ).  Moreover, I don't know how to check the irreducibility of polynomial in F11. So I also can't do this part..",F G F[x] G F \mathbb{C} \mathbb{R} \mathbb{F}_{11} \mathbb{Q} \mathbb{Q}(i) G C_2 C_5 C_2\times C_2 S_3 D_4 \mathbb{Q}(i),"['abstract-algebra', 'field-theory', 'galois-theory']"
22,Problem about the definition of Euclidean domain,Problem about the definition of Euclidean domain,,"In the definition of domain, we first define a degree function $\vartheta: R^\times \rightarrow \mathbb{N}$ with such two constraints: (1) $\vartheta(f)\leq \vartheta(fg)$ for all $f,g\in R^\times$. (2) for all $f,g\in R$ with $f\in R^\times$, there exist $q,r\in R$ with $g=qf+r$ and either $r=0$ or $\vartheta(r)<\vartheta(f)$. I wonder why we need the first constraints? I think with only the second constraint, it is enough to prove the theorem: every Euclidean ring is a PID. Can anyone give me a example where the first constraint is used?","In the definition of domain, we first define a degree function $\vartheta: R^\times \rightarrow \mathbb{N}$ with such two constraints: (1) $\vartheta(f)\leq \vartheta(fg)$ for all $f,g\in R^\times$. (2) for all $f,g\in R$ with $f\in R^\times$, there exist $q,r\in R$ with $g=qf+r$ and either $r=0$ or $\vartheta(r)<\vartheta(f)$. I wonder why we need the first constraints? I think with only the second constraint, it is enough to prove the theorem: every Euclidean ring is a PID. Can anyone give me a example where the first constraint is used?",,['abstract-algebra']
23,$x^m-1 \nmid f(x)$ in $\mathbb{Z}/p\mathbb{Z}[x]$ where $f(x)=(x+1)((x+1)^{2m}+(x+1)^{m}+1)$,in  where,x^m-1 \nmid f(x) \mathbb{Z}/p\mathbb{Z}[x] f(x)=(x+1)((x+1)^{2m}+(x+1)^{m}+1),Problem: Suppose that $p$ is a prime. Suppose that there is $m \in \mathbb{N}$ such that $p=1+3m$ . Define: $$f(x)=(x+1)((x+1)^{2m}+(x+1)^{m}+1) \in \mathbb{Z}/p\mathbb{Z}[x]$$ I would like to prove that if $p \neq 7$ and $p \neq 13$ then $x^m-1 \nmid f(x)$ in $\mathbb{Z}/p\mathbb{Z}[x]$ . Attempt: I observed that $f(x-1)(x^m-1)=x^p-x$ . Then I observed that $x^p-x$ has all its roots in $\mathbb{Z}/p\mathbb{Z}$ and that its roots are all distinct. I would like to prove that for $m \geq 6$ then $x^m-1$ and $((x-1)^m-1)$ share at least a root. This is sufficient because then we would have that $x^p-x$ has at least one multiple roots (I mean that it is not simple).,Problem: Suppose that is a prime. Suppose that there is such that . Define: I would like to prove that if and then in . Attempt: I observed that . Then I observed that has all its roots in and that its roots are all distinct. I would like to prove that for then and share at least a root. This is sufficient because then we would have that has at least one multiple roots (I mean that it is not simple).,p m \in \mathbb{N} p=1+3m f(x)=(x+1)((x+1)^{2m}+(x+1)^{m}+1) \in \mathbb{Z}/p\mathbb{Z}[x] p \neq 7 p \neq 13 x^m-1 \nmid f(x) \mathbb{Z}/p\mathbb{Z}[x] f(x-1)(x^m-1)=x^p-x x^p-x \mathbb{Z}/p\mathbb{Z} m \geq 6 x^m-1 ((x-1)^m-1) x^p-x,"['abstract-algebra', 'number-theory', 'polynomials', 'finite-fields', 'sylow-theory']"
24,"If $N$ is large enough, then $x^5-Nx+1$ and $x^5-Nx^2+1$ are irreducible over $\mathbb{Q}$.","If  is large enough, then  and  are irreducible over .",N x^5-Nx+1 x^5-Nx^2+1 \mathbb{Q},"Show that if $N$ is large enough, then $x^5-Nx+1$ and $x^5-Nx^2+1$ are irreducible over $\mathbb{Q}$ . There is a hint for $x^5-Nx+1$ : prove first that four of the roots in $\Bbb{C}$ has absolute values larger than $1$ . I think that it follows from Rouche's theorem, but I don't know how to proceed. Update: I think that both problems can be solved by direct computations. For example for the second one,  we can write $$x^5-Nx^2+1=(x^3+ax^2+bx+u)(x^2+cx+v)$$ where $|u|=|v|=1$ and $a,b,c\in \Bbb{Z}$ . Multiply out, consider the coefficient of $x^4$ we get $a+c=0$ . Consider $x$ we get $uc=-bv$ . Next consider $x^3$ we have $b+v+ac=0$ . Note that $c=-a$ and $|b|=|a|$ , so we can actually solve $a$ . Then a contradiction is easily reached. I think that the same method also applies to the first one. However, the first one can be solved by using the fact that only one root is in the unit circle. I am still wondering if there is a nicer method for the second one. Update 2: I got a solution from my professor. A similar method can also be applied to $x^5-Nx^2+1$ . By Rouche's theorem, there are exactly two roots inside the unit circle, and the key point here is these two roots are complex conjugates. Hence they have to be the two roots of $x^2+cx+v$ . Then the other three roots for $x^3+ax^2+bx+u$ are absolutely greater than one. The contradiction follows by Vieta's theorem. (See rtybase's answer below)","Show that if is large enough, then and are irreducible over . There is a hint for : prove first that four of the roots in has absolute values larger than . I think that it follows from Rouche's theorem, but I don't know how to proceed. Update: I think that both problems can be solved by direct computations. For example for the second one,  we can write where and . Multiply out, consider the coefficient of we get . Consider we get . Next consider we have . Note that and , so we can actually solve . Then a contradiction is easily reached. I think that the same method also applies to the first one. However, the first one can be solved by using the fact that only one root is in the unit circle. I am still wondering if there is a nicer method for the second one. Update 2: I got a solution from my professor. A similar method can also be applied to . By Rouche's theorem, there are exactly two roots inside the unit circle, and the key point here is these two roots are complex conjugates. Hence they have to be the two roots of . Then the other three roots for are absolutely greater than one. The contradiction follows by Vieta's theorem. (See rtybase's answer below)","N x^5-Nx+1 x^5-Nx^2+1 \mathbb{Q} x^5-Nx+1 \Bbb{C} 1 x^5-Nx^2+1=(x^3+ax^2+bx+u)(x^2+cx+v) |u|=|v|=1 a,b,c\in \Bbb{Z} x^4 a+c=0 x uc=-bv x^3 b+v+ac=0 c=-a |b|=|a| a x^5-Nx^2+1 x^2+cx+v x^3+ax^2+bx+u","['abstract-algebra', 'polynomials', 'field-theory', 'irreducible-polynomials']"
25,What are the commutative rings $R$ for which $A \otimes _{\Bbb Z} B = A \otimes _R B$ as abelian groups?,What are the commutative rings  for which  as abelian groups?,R A \otimes _{\Bbb Z} B = A \otimes _R B,"This is a follow up . What are the commutative rings $R$ , for which given $R$ -modules $A$ and $B$ , $A \otimes _{\Bbb Z} B = A \otimes _R B$ as abelian groups? This is true when $R= \Bbb Q$ , or $\Bbb Z_m$ . We can give an $R$ -module structure $A \otimes _{\Bbb Z} B$ satisfying $r (a \otimes b) = ra \otimes b$ . When $R= \Bbb Q$ , we get the additional fact that $a \otimes rb=ra \otimes b$ . To see this,  note that when $r \in \Bbb N$ , we have $$ r a \otimes b = \sum a \otimes b = a \otimes rb $$ by bilinearity  - which extends $r$ to $\Bbb Z$ too. When $r=1/m$ , $m \in \Bbb Z$ , $$ \frac{1}{m}a \otimes b = \frac{1}{m} (a \otimes b) = \frac{1}{m} ( \sum (a \otimes \frac{1}{m} b)) = \frac{1}{m} (ma \otimes \frac{1}{m} b ) = a \otimes \frac{1}{m} b $$ Thus, we have equality for all $r \in \Bbb Q$ . I think generalizing to $\Bbb Q$ is as far as we can get for this naive strategy. I wonder if there exists better method for the classification.","This is a follow up . What are the commutative rings , for which given -modules and , as abelian groups? This is true when , or . We can give an -module structure satisfying . When , we get the additional fact that . To see this,  note that when , we have by bilinearity  - which extends to too. When , , Thus, we have equality for all . I think generalizing to is as far as we can get for this naive strategy. I wonder if there exists better method for the classification.",R R A B A \otimes _{\Bbb Z} B = A \otimes _R B R= \Bbb Q \Bbb Z_m R A \otimes _{\Bbb Z} B r (a \otimes b) = ra \otimes b R= \Bbb Q a \otimes rb=ra \otimes b r \in \Bbb N  r a \otimes b = \sum a \otimes b = a \otimes rb  r \Bbb Z r=1/m m \in \Bbb Z  \frac{1}{m}a \otimes b = \frac{1}{m} (a \otimes b) = \frac{1}{m} ( \sum (a \otimes \frac{1}{m} b)) = \frac{1}{m} (ma \otimes \frac{1}{m} b ) = a \otimes \frac{1}{m} b  r \in \Bbb Q \Bbb Q,"['abstract-algebra', 'tensor-products']"
26,Chasing down this lemma on infinite abelian locally finite groups,Chasing down this lemma on infinite abelian locally finite groups,,"I'm translating a paper from the 70's where the author cites László Fuchs' Abelian groups (the entire book, no page number). As you can imagine, given the size and differences in editions of Fuchs' book, I am having trouble connecting the dots. Here is the situation: $G$ is an infinite, abelian, and locally finite group. $H$ is an infinite subgroup of $G$ which is of finite index in $G$. From this, the step in a proof I am reading continues this way ... we deduce the socle of $G$ is of finite length and that $G$ is an Artinian group. The justification of the block above is what I am asking about. In the newest edition (2015) of Fuchs' Abelian groups , I feel think the relevant theorem is this: Theorem 5.3 (Prufer, Kurosh, Yahya) T.F.A.E: (i) $A$ is finitely cogenerated (ii) $A$ is an essential extension of a finite group (iii) $A$ is torsion of finite rank (iv) $A$ is a direct sum of a finite number of cocyclic groups (v) the subgroups of $A$ satisfy the minimum condition [later] Obeserve that (ii) is equivalent to the finiteness of the socle in a torsion group. This is the very first theorem in the section, preceded only by the definition of finite cogeneration. The local finiteness obviously makes $G$ torsion, so I can see why both conclusions are linked... but how do you use the fact that $|G:H|$ is finite to prove one of these conditions? I feel like I'm overlooking some connection between $G/H$ and $G$, possibly about the socles. In general module theory, there usually isn't a connection between the two, but perhaps since $G$ is locally finite there is a connection in my blind spot. I've decided the original source is in order: $A$ is a right self-injective ring, and $G$ is, as proven in an earlier step, at least a locally finite group. The $G_1$ and $H_1$ in this snippet are the $G$ and $H$ I was referring to in my original description. The citation (7) refers to Fuchs' Abelian groups . The theorem of Faith has to do with the injectivity of a free $A[H_1]$ module. Basically it allows you to conclude that $A[G_1]$ is a direct sum of finitely many copies of $A[H_1]$, and this means $|G_1:H_1|$ is finite. Perhaps the theorem that's needed (which did not come out in my description above) is that if $G$ is a locally finite, infinite abelian group whose infinite subgroups are all of finite index, $G$ is Artinian? If this is the case, then a reference to that result would be an acceptable solution to this problem. (Hopefully in Fuchs, but elsewhere would be fine.)","I'm translating a paper from the 70's where the author cites László Fuchs' Abelian groups (the entire book, no page number). As you can imagine, given the size and differences in editions of Fuchs' book, I am having trouble connecting the dots. Here is the situation: $G$ is an infinite, abelian, and locally finite group. $H$ is an infinite subgroup of $G$ which is of finite index in $G$. From this, the step in a proof I am reading continues this way ... we deduce the socle of $G$ is of finite length and that $G$ is an Artinian group. The justification of the block above is what I am asking about. In the newest edition (2015) of Fuchs' Abelian groups , I feel think the relevant theorem is this: Theorem 5.3 (Prufer, Kurosh, Yahya) T.F.A.E: (i) $A$ is finitely cogenerated (ii) $A$ is an essential extension of a finite group (iii) $A$ is torsion of finite rank (iv) $A$ is a direct sum of a finite number of cocyclic groups (v) the subgroups of $A$ satisfy the minimum condition [later] Obeserve that (ii) is equivalent to the finiteness of the socle in a torsion group. This is the very first theorem in the section, preceded only by the definition of finite cogeneration. The local finiteness obviously makes $G$ torsion, so I can see why both conclusions are linked... but how do you use the fact that $|G:H|$ is finite to prove one of these conditions? I feel like I'm overlooking some connection between $G/H$ and $G$, possibly about the socles. In general module theory, there usually isn't a connection between the two, but perhaps since $G$ is locally finite there is a connection in my blind spot. I've decided the original source is in order: $A$ is a right self-injective ring, and $G$ is, as proven in an earlier step, at least a locally finite group. The $G_1$ and $H_1$ in this snippet are the $G$ and $H$ I was referring to in my original description. The citation (7) refers to Fuchs' Abelian groups . The theorem of Faith has to do with the injectivity of a free $A[H_1]$ module. Basically it allows you to conclude that $A[G_1]$ is a direct sum of finitely many copies of $A[H_1]$, and this means $|G_1:H_1|$ is finite. Perhaps the theorem that's needed (which did not come out in my description above) is that if $G$ is a locally finite, infinite abelian group whose infinite subgroups are all of finite index, $G$ is Artinian? If this is the case, then a reference to that result would be an acceptable solution to this problem. (Hopefully in Fuchs, but elsewhere would be fine.)",,"['abstract-algebra', 'abelian-groups']"
27,Equalizers in CRing,Equalizers in CRing,,"This is a follow-up to this question of Martin Brandenburg. Let $B$ be a ring (in this post ""ring"" means ""commutative ring with $1$"") and $A$ a subring. We say that $A\subset B$ is an equalizer if there are two morphisms of rings from $B$ to $C$ which coincide precisely on $A$. (One also says that $A\subset B$ is a kernel , or that $A\to B$ is regular , but I find the phrase ""is an equalizer"" more descriptive.) As pointed out by Martin, this is equivalent to the condition that $b\in B$ and $b\otimes 1=1\otimes b$ in $B\otimes_AB$ imply $b\in A$. As also pointed out by Martin, $A\subset B$ is an equalizer if $B$ is faithfully flat over $A$. (This follows from Proposition 13, Chapter 1, Section 2, Subsection 11, and from Proposition 13, Chapter 1, Section 3, Subsection 6 in Nicolas Bourbaki, Algèbre commutative: Chapitres 1 à 4 , Masson, Paris 1985. Subquestion: are there better proofs?) The following question seems unavoidable: Is $A\subset B$ an equalizer if and only if the functor $B\otimes_A-\ $ reflects exactness? The phrase ""$B\otimes_A-\ $ reflects exactness"" means: If $M\to N\to P$ is a complex of $A$-modules and if $B\otimes_AM\to B\otimes_AN\to B\otimes_AP$ is exact, then $M\to N\to P$ is exact. Here is a nano-answer: Assume that all maximal ideals of $A$ are principal, that $B$ is flat over $A$ and that $A\subset B$ is an equalizer. Then $B$ is faithfully flat over $A$. Proof. If $B$ was not faithfully flat, by Tag 00HP in the Stacks Project, there would be a maximal ideal $(a)$ of $A$ such that $aB=B$, that is, $a$ is a unit of $B$. In $B\otimes_AB$ we would get  $$ 1\otimes a^{-1}=a^{-1}a\otimes a^{-1}=a^{-1}\otimes aa^{-1}=a^{-1}\otimes1. $$ (Subquestion: If all maximal ideals of $A$ are principal, does it follow that $A$ is a principal ideal ring?) To get an example of an equalizer $A\subset B$ where $B$ is not flat over $A$, consider the inclusion $\mathbb Z\subset\mathbb Z\times\mathbb Z/(2)$. It is clear that $(\mathbb Z\times\mathbb Z/(2))\otimes_{\mathbb Z}-\ $ reflects exactness. The co-equalizers in CRing are precisely the surjective epimorphisms. For instance $\mathbb Z\to\mathbb Q$ is a monomorphism and an epimorphism, but is neither an isomorphism, nor an equalizer, nor a surjection, nor a co-equalizer. Moreover $\mathbb Q$ is flat, but not faithfully flat, over $\mathbb Z$, and $\mathbb Q\otimes_{\mathbb Z}-\ $ does not reflect exactness. EDIT. Another question: Is the composition of two regular monomorphisms a regular monomorphism?","This is a follow-up to this question of Martin Brandenburg. Let $B$ be a ring (in this post ""ring"" means ""commutative ring with $1$"") and $A$ a subring. We say that $A\subset B$ is an equalizer if there are two morphisms of rings from $B$ to $C$ which coincide precisely on $A$. (One also says that $A\subset B$ is a kernel , or that $A\to B$ is regular , but I find the phrase ""is an equalizer"" more descriptive.) As pointed out by Martin, this is equivalent to the condition that $b\in B$ and $b\otimes 1=1\otimes b$ in $B\otimes_AB$ imply $b\in A$. As also pointed out by Martin, $A\subset B$ is an equalizer if $B$ is faithfully flat over $A$. (This follows from Proposition 13, Chapter 1, Section 2, Subsection 11, and from Proposition 13, Chapter 1, Section 3, Subsection 6 in Nicolas Bourbaki, Algèbre commutative: Chapitres 1 à 4 , Masson, Paris 1985. Subquestion: are there better proofs?) The following question seems unavoidable: Is $A\subset B$ an equalizer if and only if the functor $B\otimes_A-\ $ reflects exactness? The phrase ""$B\otimes_A-\ $ reflects exactness"" means: If $M\to N\to P$ is a complex of $A$-modules and if $B\otimes_AM\to B\otimes_AN\to B\otimes_AP$ is exact, then $M\to N\to P$ is exact. Here is a nano-answer: Assume that all maximal ideals of $A$ are principal, that $B$ is flat over $A$ and that $A\subset B$ is an equalizer. Then $B$ is faithfully flat over $A$. Proof. If $B$ was not faithfully flat, by Tag 00HP in the Stacks Project, there would be a maximal ideal $(a)$ of $A$ such that $aB=B$, that is, $a$ is a unit of $B$. In $B\otimes_AB$ we would get  $$ 1\otimes a^{-1}=a^{-1}a\otimes a^{-1}=a^{-1}\otimes aa^{-1}=a^{-1}\otimes1. $$ (Subquestion: If all maximal ideals of $A$ are principal, does it follow that $A$ is a principal ideal ring?) To get an example of an equalizer $A\subset B$ where $B$ is not flat over $A$, consider the inclusion $\mathbb Z\subset\mathbb Z\times\mathbb Z/(2)$. It is clear that $(\mathbb Z\times\mathbb Z/(2))\otimes_{\mathbb Z}-\ $ reflects exactness. The co-equalizers in CRing are precisely the surjective epimorphisms. For instance $\mathbb Z\to\mathbb Q$ is a monomorphism and an epimorphism, but is neither an isomorphism, nor an equalizer, nor a surjection, nor a co-equalizer. Moreover $\mathbb Q$ is flat, but not faithfully flat, over $\mathbb Z$, and $\mathbb Q\otimes_{\mathbb Z}-\ $ does not reflect exactness. EDIT. Another question: Is the composition of two regular monomorphisms a regular monomorphism?",,"['abstract-algebra', 'commutative-algebra', 'category-theory']"
28,"$f \in \mathbb C[x]$ monic polynomial of prime degree which is not co-prime with any of its derivative polynomials, then $f$ has only one root?","monic polynomial of prime degree which is not co-prime with any of its derivative polynomials, then  has only one root?",f \in \mathbb C[x] f,Let $f \in \mathbb C[x]$ be a monic polynomial of prime degree $p$ such that $f$ is not co-prime with any $f^{(k)}$ ($k$-th derivative) for $1\le k<p$. Then is it true that $\exists a\in \mathbb C$ such that $f(x)=(x-a)^p$ ?,Let $f \in \mathbb C[x]$ be a monic polynomial of prime degree $p$ such that $f$ is not co-prime with any $f^{(k)}$ ($k$-th derivative) for $1\le k<p$. Then is it true that $\exists a\in \mathbb C$ such that $f(x)=(x-a)^p$ ?,,['abstract-algebra']
29,Classify groups of order $pq^2$ using semidirect product,Classify groups of order  using semidirect product,pq^2,"I am struggling with semidirect products and how they can be used to classify groups of a certain order. In particular, I need help with the nonabelian case. This is the problem I am working with.. Classify all groups of order $pq^2$ with $p$,$q$ primes, $p<q$,   $p\nmid(q-1)$, and $p^2\nmid(q+1)$. Use can use the fact that $GL_2(\mathbb{Z}_q)$ has $(q^2-1)(q^2-q)$ elements. Ok. So here's my thought process. I first considered when $G$ was abelian and applied the Fundamental Theorem of Finitely Generated Abelian Groups (FTFGAG) to obtain all abelian groups of this order. My results were: $\mathbb{Z}_{pq^2}$ and $\mathbb{Z}_{pq}\times\mathbb{Z}_q$. Next considered when $G$ was nonabelian and applied Sylow's Theorem to determine how many Sylow $p$ and $q$ subgroups there were in $G$. I found the Sylow $q$-subgroups to be unique, and hence normal. I let the Sylow $q$-subgroup be called $H$. I let $K$ be any Sylow $p$-subgroup in $G$. Then by Lagrange, $H\cap K=1$. Next I showed that $G=HK$ and let $\varphi: K\rightarrow \text{Aut}(H)$ be a homomorphism. Then by applying theorem 12 from Dummit and Foote (sorry it didn't have a name :/), I got $G\cong H\rtimes_\varphi K$. Now I just need to consider all isomorphisms of $H$. They are $\mathbb{Z_{q^2}}$ and $\mathbb{Z}_q\times\mathbb{Z}_q$. Suppose $H=\mathbb{Z_{q^2}}$. Then $|\text{Aut}(H)|=q(q-1)$. Since $p\nmid q$ and $p\nmid q-1$, there does not exist an element of order $p$ in $\text{Aut}(H)$ by Lagrange. This means the only homomorphism is trivial. Therefore $H\rtimes_\varphi K\cong \mathbb{Z}_{q^2}\times \mathbb{Z}_p$. But this is abelian and contradicts my assumption that $G$ is nonabelian. Plus FTFGAG, already classified all abelian groups. Therefore $H=\mathbb{Z}_{q^2}$ does not result in a new group. And here is where I start to get lost... Suppose $H=\mathbb{Z_q}\times\mathbb{Z_q}$. Then $|\text{Aut}(H)|=(q^2-1)(q^2-q)$. I do not see how $p$ divides this... Help with this last part would be much appreciated. Thanks. Also here are some resources I have looked at: https://crazyproject.wordpress.com/2010/06/25/classify-the-groups-of-order-75/ http://www.math.purdue.edu/~lipman/5532011/order-p%5E2q.pdf","I am struggling with semidirect products and how they can be used to classify groups of a certain order. In particular, I need help with the nonabelian case. This is the problem I am working with.. Classify all groups of order $pq^2$ with $p$,$q$ primes, $p<q$,   $p\nmid(q-1)$, and $p^2\nmid(q+1)$. Use can use the fact that $GL_2(\mathbb{Z}_q)$ has $(q^2-1)(q^2-q)$ elements. Ok. So here's my thought process. I first considered when $G$ was abelian and applied the Fundamental Theorem of Finitely Generated Abelian Groups (FTFGAG) to obtain all abelian groups of this order. My results were: $\mathbb{Z}_{pq^2}$ and $\mathbb{Z}_{pq}\times\mathbb{Z}_q$. Next considered when $G$ was nonabelian and applied Sylow's Theorem to determine how many Sylow $p$ and $q$ subgroups there were in $G$. I found the Sylow $q$-subgroups to be unique, and hence normal. I let the Sylow $q$-subgroup be called $H$. I let $K$ be any Sylow $p$-subgroup in $G$. Then by Lagrange, $H\cap K=1$. Next I showed that $G=HK$ and let $\varphi: K\rightarrow \text{Aut}(H)$ be a homomorphism. Then by applying theorem 12 from Dummit and Foote (sorry it didn't have a name :/), I got $G\cong H\rtimes_\varphi K$. Now I just need to consider all isomorphisms of $H$. They are $\mathbb{Z_{q^2}}$ and $\mathbb{Z}_q\times\mathbb{Z}_q$. Suppose $H=\mathbb{Z_{q^2}}$. Then $|\text{Aut}(H)|=q(q-1)$. Since $p\nmid q$ and $p\nmid q-1$, there does not exist an element of order $p$ in $\text{Aut}(H)$ by Lagrange. This means the only homomorphism is trivial. Therefore $H\rtimes_\varphi K\cong \mathbb{Z}_{q^2}\times \mathbb{Z}_p$. But this is abelian and contradicts my assumption that $G$ is nonabelian. Plus FTFGAG, already classified all abelian groups. Therefore $H=\mathbb{Z}_{q^2}$ does not result in a new group. And here is where I start to get lost... Suppose $H=\mathbb{Z_q}\times\mathbb{Z_q}$. Then $|\text{Aut}(H)|=(q^2-1)(q^2-q)$. I do not see how $p$ divides this... Help with this last part would be much appreciated. Thanks. Also here are some resources I have looked at: https://crazyproject.wordpress.com/2010/06/25/classify-the-groups-of-order-75/ http://www.math.purdue.edu/~lipman/5532011/order-p%5E2q.pdf",,"['abstract-algebra', 'semidirect-product']"
30,Is there a subject in mathematics like topological Algebra?,Is there a subject in mathematics like topological Algebra?,,"I would consider myself an algebraic topologist and there is a lot of influence from algebra into topology and without this input from the algebraic site I would say that a lot of topological theorems wouldn't been proved today. On the other hand I only know of a few examples, where topology can prove an algebraic statement (for example that $\mathbb{Z}$ is the only discrete subgroup of $\mathbb{R}$ follows from the classification of $1$-dimensional manifolds; a lot of proofs of the fundamental theorem of algebra and so on) and I have never heard of an algebraic statement, where no purely algebraic proof exists, but a topological one. So my question is are there algebraic statements that so far have only been proven in topological ways or is there even a whole field of mathematics called ""topological algebra""?","I would consider myself an algebraic topologist and there is a lot of influence from algebra into topology and without this input from the algebraic site I would say that a lot of topological theorems wouldn't been proved today. On the other hand I only know of a few examples, where topology can prove an algebraic statement (for example that $\mathbb{Z}$ is the only discrete subgroup of $\mathbb{R}$ follows from the classification of $1$-dimensional manifolds; a lot of proofs of the fundamental theorem of algebra and so on) and I have never heard of an algebraic statement, where no purely algebraic proof exists, but a topological one. So my question is are there algebraic statements that so far have only been proven in topological ways or is there even a whole field of mathematics called ""topological algebra""?",,"['abstract-algebra', 'general-topology', 'algebraic-topology']"
31,"Computing (the ring structure of) $\mathrm{Ext}^\bullet_R(k,k)$ for $R=k[x]/(x^2)$",Computing (the ring structure of)  for,"\mathrm{Ext}^\bullet_R(k,k) R=k[x]/(x^2)","Let $k$ be some field (say of characteristic zero, if it matters) and define $$R=k[x]/(x^2).$$ I want to compute $$\mathrm{Ext}^\bullet_R(k,k)$$ and, in particular, the ring structure on it (though I think I can do this part if I can compute the Ext modules) . I know that we can think of elements of $\mathrm{Ext}^m_R(k,k)$ as length $m+2$ exact sequences of the form $$0\to k\to X_m\to\ldots\to X_1\to k\to0$$ modulo some sensible equivalence relation, and that we can also think of it as $$\mathrm{Ext}^m_R(k,k) = H^m(\mathrm{Hom}_{R\hbox{-}\mathsf{mod}}(P_\bullet,k)) = H^m(\mathrm{Hom}_{R\hbox{-}\mathsf{mod}}(k,I^\bullet))$$ for some projective (or injective) resolution $P_\bullet$ (or $I^\bullet$, respectively) of $k$. However, when it comes to the hands-on part of actually computing this, I hit a mental block. Since $R$ is a local ring (with maximal ideal $(x)$) we know that projective modules are exactly the free modules, and so computing a projective resolution will probably be easiest...? I would appreciate hints and partial answers over explicit answers (though it's likely I might have to ask for more hints if I still struggle...). At this stage I'll take whatever I can get. Edit: Here is a partial answer, all that remains is the question of the ring structure. Note that $k\cong R/(x)$ and so we have an epimorphism $\pi\colon R\twoheadrightarrow k$ given by $x\mapsto0$ (the quotient map). If we write $R=k[\varepsilon]$ where $\varepsilon$ is such that $\varepsilon^2=0$ then we obtain the following free resolution of $k$: $$\ldots\xrightarrow{\cdot\varepsilon}k[\varepsilon]\xrightarrow{\cdot\varepsilon}k[\varepsilon]\twoheadrightarrow k\to0.$$ Now any morphism $k[\varepsilon]\to k$ must send $\varepsilon$ to some element $\eta\in k$ such that $\eta^2=0$. But $k$ is a field, and so we are forced to choose $\eta=0$. This means that any such morphism is determined entirely by where it send $1\in k$, and it can send it to any $x\in k$. Thus $$\mathrm{Hom}_{R\hbox{-}\mathsf{mod}}(k[\varepsilon],k)\cong k.$$ So taking $\mathrm{Hom}_{R\hbox{-}\mathsf{mod}}(-,k)$ of the free resolution gives us the sequence $$0\to k\xrightarrow{\cdot0}k\xrightarrow{\cdot0}\ldots$$ which has homology $H_n=\ker d_n/\mathrm{im}\,d_{n+1}=k/0\cong k$ for all $n\geqslant0$. Thus $$\mathrm{Ext}^\bullet_R(k,k)\cong\bigoplus_{n\geqslant0}k$$ So my question now is about the ring structure of $\mathrm{Ext}^\bullet_R(k,k)$, and also about thinking of $\mathrm{Ext}$ as being extensions of $k$ by $k$. Unless I'm wrong, this means that we should be able to construct, taking $n=1$, short exact sequences $$0\to k\hookrightarrow X\twoheadrightarrow k\to0$$ and the collection of all such sequences should be isomorphic to $k$. The first thing that sprang to mind was to take $X=R$ and the epimorphism multiplication by $x\varepsilon$ for $x\in k$, but then I struggle to find a monomorphism into $R$ with the right kernel, and also taking $x=0$ means that the map fails to be an epimorphism. What is the correct choice of $\,\,\to X\to\,\,$? How can we compute explicitly the ring structure on $\mathrm{Ext}^\bullet_R(k,k)$ ? Edit 2: Following the ideas in the comments, I'm trying to explicitly spell out the following isomorphism, but I'm struggling to understand how the quotients are realised on both sides (i.e. the equivalence relations): I feel like the right-hand side should just be chain maps modulo homotopy equivalence, even though the $\mathrm{Hom}$ complex is just of maps of chains. I'm pretty certain that the lifts $\hat{f}_\bullet$ that we construct are in fact chain maps.","Let $k$ be some field (say of characteristic zero, if it matters) and define $$R=k[x]/(x^2).$$ I want to compute $$\mathrm{Ext}^\bullet_R(k,k)$$ and, in particular, the ring structure on it (though I think I can do this part if I can compute the Ext modules) . I know that we can think of elements of $\mathrm{Ext}^m_R(k,k)$ as length $m+2$ exact sequences of the form $$0\to k\to X_m\to\ldots\to X_1\to k\to0$$ modulo some sensible equivalence relation, and that we can also think of it as $$\mathrm{Ext}^m_R(k,k) = H^m(\mathrm{Hom}_{R\hbox{-}\mathsf{mod}}(P_\bullet,k)) = H^m(\mathrm{Hom}_{R\hbox{-}\mathsf{mod}}(k,I^\bullet))$$ for some projective (or injective) resolution $P_\bullet$ (or $I^\bullet$, respectively) of $k$. However, when it comes to the hands-on part of actually computing this, I hit a mental block. Since $R$ is a local ring (with maximal ideal $(x)$) we know that projective modules are exactly the free modules, and so computing a projective resolution will probably be easiest...? I would appreciate hints and partial answers over explicit answers (though it's likely I might have to ask for more hints if I still struggle...). At this stage I'll take whatever I can get. Edit: Here is a partial answer, all that remains is the question of the ring structure. Note that $k\cong R/(x)$ and so we have an epimorphism $\pi\colon R\twoheadrightarrow k$ given by $x\mapsto0$ (the quotient map). If we write $R=k[\varepsilon]$ where $\varepsilon$ is such that $\varepsilon^2=0$ then we obtain the following free resolution of $k$: $$\ldots\xrightarrow{\cdot\varepsilon}k[\varepsilon]\xrightarrow{\cdot\varepsilon}k[\varepsilon]\twoheadrightarrow k\to0.$$ Now any morphism $k[\varepsilon]\to k$ must send $\varepsilon$ to some element $\eta\in k$ such that $\eta^2=0$. But $k$ is a field, and so we are forced to choose $\eta=0$. This means that any such morphism is determined entirely by where it send $1\in k$, and it can send it to any $x\in k$. Thus $$\mathrm{Hom}_{R\hbox{-}\mathsf{mod}}(k[\varepsilon],k)\cong k.$$ So taking $\mathrm{Hom}_{R\hbox{-}\mathsf{mod}}(-,k)$ of the free resolution gives us the sequence $$0\to k\xrightarrow{\cdot0}k\xrightarrow{\cdot0}\ldots$$ which has homology $H_n=\ker d_n/\mathrm{im}\,d_{n+1}=k/0\cong k$ for all $n\geqslant0$. Thus $$\mathrm{Ext}^\bullet_R(k,k)\cong\bigoplus_{n\geqslant0}k$$ So my question now is about the ring structure of $\mathrm{Ext}^\bullet_R(k,k)$, and also about thinking of $\mathrm{Ext}$ as being extensions of $k$ by $k$. Unless I'm wrong, this means that we should be able to construct, taking $n=1$, short exact sequences $$0\to k\hookrightarrow X\twoheadrightarrow k\to0$$ and the collection of all such sequences should be isomorphic to $k$. The first thing that sprang to mind was to take $X=R$ and the epimorphism multiplication by $x\varepsilon$ for $x\in k$, but then I struggle to find a monomorphism into $R$ with the right kernel, and also taking $x=0$ means that the map fails to be an epimorphism. What is the correct choice of $\,\,\to X\to\,\,$? How can we compute explicitly the ring structure on $\mathrm{Ext}^\bullet_R(k,k)$ ? Edit 2: Following the ideas in the comments, I'm trying to explicitly spell out the following isomorphism, but I'm struggling to understand how the quotients are realised on both sides (i.e. the equivalence relations): I feel like the right-hand side should just be chain maps modulo homotopy equivalence, even though the $\mathrm{Hom}$ complex is just of maps of chains. I'm pretty certain that the lifts $\hat{f}_\bullet$ that we construct are in fact chain maps.",,"['abstract-algebra', 'modules', 'homological-algebra', 'projective-module', 'derived-functors']"
32,"Does there exist a prime number $p$ such that $p\mathcal{O}_{K}$ in $K=\mathbb{Q}(\sqrt{2},\sqrt{3})$ is a prime ideal?",Does there exist a prime number  such that  in  is a prime ideal?,"p p\mathcal{O}_{K} K=\mathbb{Q}(\sqrt{2},\sqrt{3})","Problem: Prove or disprove: there exists a prime number $p$ such that $p\mathcal{O}_{K}$ in $K=\mathbb{Q}(\sqrt{2},\sqrt{3})$ is a prime ideal, where $\mathcal{O}_K$ denotes the ring of algebraic integers in $K$. The following is my idea: Suppose $p\mathcal{O}_K=p$ is a prime ideal. Then we know that $g=1$, $e=1$, and $f=4$ from $4=efg$. Now, denote by $D$ and $I$ the decomposition group and the inertia group for $p$. Then, $|D|=ef=4$ and $|I|=e=1$. On the other hand, $K/\mathbb{Q}$ is Galois with $G=\mathbb{Z}_2 \times \mathbb{Z}_2$, and I can find all intermediate fields: $$K_1=\mathbb{Q}(\sqrt{2}),\qquad K_2=\mathbb Q(\sqrt 3),\qquad K_3=\mathbb Q(\sqrt 6).$$ For a given $p$, I try to determine whether or not $p$ is inert in $K_i$  ($i=1,2,3$). But I guess this cannot work. That's all I try. Please help me! Thank you very much!","Problem: Prove or disprove: there exists a prime number $p$ such that $p\mathcal{O}_{K}$ in $K=\mathbb{Q}(\sqrt{2},\sqrt{3})$ is a prime ideal, where $\mathcal{O}_K$ denotes the ring of algebraic integers in $K$. The following is my idea: Suppose $p\mathcal{O}_K=p$ is a prime ideal. Then we know that $g=1$, $e=1$, and $f=4$ from $4=efg$. Now, denote by $D$ and $I$ the decomposition group and the inertia group for $p$. Then, $|D|=ef=4$ and $|I|=e=1$. On the other hand, $K/\mathbb{Q}$ is Galois with $G=\mathbb{Z}_2 \times \mathbb{Z}_2$, and I can find all intermediate fields: $$K_1=\mathbb{Q}(\sqrt{2}),\qquad K_2=\mathbb Q(\sqrt 3),\qquad K_3=\mathbb Q(\sqrt 6).$$ For a given $p$, I try to determine whether or not $p$ is inert in $K_i$  ($i=1,2,3$). But I guess this cannot work. That's all I try. Please help me! Thank you very much!",,"['abstract-algebra', 'number-theory', 'algebraic-number-theory']"
33,Explaining the difference between the number theoretic Langlands program and geometric Langlands program to a graduate student.,Explaining the difference between the number theoretic Langlands program and geometric Langlands program to a graduate student.,,"I am a graduate student who just took a course introducing some notions in algebraic number theory and algebraic geometry (officially, it was a course on an introduction to the Langlands program). Almost every lecture, the professor spoke about some geometric analog of some field-theoretic object / algebraic object. Can anyone provide a general description of the relationship between the classical Langlands program and the geometric Langlands program? If the difference is very technical and out of the reach of a novice, could you direct me to a resource? Thanks.","I am a graduate student who just took a course introducing some notions in algebraic number theory and algebraic geometry (officially, it was a course on an introduction to the Langlands program). Almost every lecture, the professor spoke about some geometric analog of some field-theoretic object / algebraic object. Can anyone provide a general description of the relationship between the classical Langlands program and the geometric Langlands program? If the difference is very technical and out of the reach of a novice, could you direct me to a resource? Thanks.",,"['abstract-algebra', 'number-theory', 'algebraic-geometry']"
34,If $n\mid m$ prove that the canonical surjection $\pi: \mathbb Z_m \rightarrow \mathbb Z_n$ is also surjective on units,If  prove that the canonical surjection  is also surjective on units,n\mid m \pi: \mathbb Z_m \rightarrow \mathbb Z_n,"Not sure if this is the right proof (i found it online): Since $n\mid m$, if we factor $m = p_1^{\alpha_1}p_2^{\alpha_2}\cdots p_k^{\alpha_k}$, then $n = p_1^{\beta_1}p_2^{\beta_2}\cdots p_k^{\beta_k} $ with $\beta_i \leq \alpha_i$. On the other hand, by the Chinese Remainder Theorem: $$(\mathbb Z_m)^\times \cong (\mathbb Z_{p_1^{\alpha_1}})^\times \times (\mathbb Z_{p_2^{\alpha_2}})^\times \times\dots \times (\mathbb Z_{p_k^{\alpha_k}})^ \times $$  $$(\mathbb Z_n)^\times \cong (\mathbb Z_{p_1^{\beta_1}})^\times \times (\mathbb Z_{p_2^{\beta_2}})^\times \times \dots \times(\mathbb Z_{p_k^{\beta_k}})^\times$$ Now, if we define: $$\pi: \mathbb Z_m \longrightarrow \mathbb Z_n,\,\,\, a+(m) \mapsto a+(n)$$ then: $$\pi: \mathbb Z_{p_1^{\alpha_1}} \times \mathbb Z_{p_2^{\alpha_2}} \times \dots \times\mathbb Z_{p_k^{\alpha_k}} \longrightarrow \mathbb Z_{p_1^{\beta_1}} \times \mathbb Z_{p_2^{\beta_2}} \times \dots \times\mathbb Z_{p_k^{\beta_k}}$$ has map: $(a+p_1^{\alpha_1},a+p_2^{\alpha_2}, \dots, a+p_k^{\alpha_k}) \mapsto (a+p_1^{\beta_1},a+p_2^{\beta_2}, \dots, a+p_r^{\beta_k})$ It suffices to show that the statement holds for $n =p^{\beta}$ and $m = p^{\alpha}$ with $\beta \leq \alpha.$ First, we notice that $(a,p^{\alpha})=1 \Leftrightarrow (a, p^{\beta}) =1$, both means that $p \nmid a$. Now, the projection: $$\pi: \mathbb Z/p^{\alpha}\mathbb Z \longrightarrow \mathbb Z/p^{\beta}\mathbb Z$$ maps $(\mathbb Z/p^{\alpha}\mathbb Z)^ \times$ to $(\mathbb Z/p^{\beta}\mathbb Z)^\times$, but $a+(p^{\alpha}) \in (\mathbb Z/p^{\alpha}\mathbb Z)^ \times$ iff $(a,p^{\alpha})=1 \Rightarrow (a, p^{\beta}) =1 $, that is $a+(p^{\beta}) \in (\mathbb Z/p^{\beta}\mathbb Z)^ \times$. Now it is onto since if $\pi(a+(p^{\alpha})) = a+(p^{\beta}) \in (\mathbb Z/p^{\beta}\mathbb Z)^ \times$, then $(a, p^{\beta}) =1$ and this implies that $(a,p^{\alpha})=1$, so $a+(p^{\alpha}) \in (\mathbb Z/p^{\alpha}\mathbb Z)^ \times$ Then the natural surjective ring projection is also surjective on the units.","Not sure if this is the right proof (i found it online): Since $n\mid m$, if we factor $m = p_1^{\alpha_1}p_2^{\alpha_2}\cdots p_k^{\alpha_k}$, then $n = p_1^{\beta_1}p_2^{\beta_2}\cdots p_k^{\beta_k} $ with $\beta_i \leq \alpha_i$. On the other hand, by the Chinese Remainder Theorem: $$(\mathbb Z_m)^\times \cong (\mathbb Z_{p_1^{\alpha_1}})^\times \times (\mathbb Z_{p_2^{\alpha_2}})^\times \times\dots \times (\mathbb Z_{p_k^{\alpha_k}})^ \times $$  $$(\mathbb Z_n)^\times \cong (\mathbb Z_{p_1^{\beta_1}})^\times \times (\mathbb Z_{p_2^{\beta_2}})^\times \times \dots \times(\mathbb Z_{p_k^{\beta_k}})^\times$$ Now, if we define: $$\pi: \mathbb Z_m \longrightarrow \mathbb Z_n,\,\,\, a+(m) \mapsto a+(n)$$ then: $$\pi: \mathbb Z_{p_1^{\alpha_1}} \times \mathbb Z_{p_2^{\alpha_2}} \times \dots \times\mathbb Z_{p_k^{\alpha_k}} \longrightarrow \mathbb Z_{p_1^{\beta_1}} \times \mathbb Z_{p_2^{\beta_2}} \times \dots \times\mathbb Z_{p_k^{\beta_k}}$$ has map: $(a+p_1^{\alpha_1},a+p_2^{\alpha_2}, \dots, a+p_k^{\alpha_k}) \mapsto (a+p_1^{\beta_1},a+p_2^{\beta_2}, \dots, a+p_r^{\beta_k})$ It suffices to show that the statement holds for $n =p^{\beta}$ and $m = p^{\alpha}$ with $\beta \leq \alpha.$ First, we notice that $(a,p^{\alpha})=1 \Leftrightarrow (a, p^{\beta}) =1$, both means that $p \nmid a$. Now, the projection: $$\pi: \mathbb Z/p^{\alpha}\mathbb Z \longrightarrow \mathbb Z/p^{\beta}\mathbb Z$$ maps $(\mathbb Z/p^{\alpha}\mathbb Z)^ \times$ to $(\mathbb Z/p^{\beta}\mathbb Z)^\times$, but $a+(p^{\alpha}) \in (\mathbb Z/p^{\alpha}\mathbb Z)^ \times$ iff $(a,p^{\alpha})=1 \Rightarrow (a, p^{\beta}) =1 $, that is $a+(p^{\beta}) \in (\mathbb Z/p^{\beta}\mathbb Z)^ \times$. Now it is onto since if $\pi(a+(p^{\alpha})) = a+(p^{\beta}) \in (\mathbb Z/p^{\beta}\mathbb Z)^ \times$, then $(a, p^{\beta}) =1$ and this implies that $(a,p^{\alpha})=1$, so $a+(p^{\alpha}) \in (\mathbb Z/p^{\alpha}\mathbb Z)^ \times$ Then the natural surjective ring projection is also surjective on the units.",,"['abstract-algebra', 'ring-theory', 'proof-verification', 'chinese-remainder-theorem']"
35,"Let $G$ be a group, and $H$ a subgroup of $G$. Let $a, b \in G$. Prove $Ha=Hb$ iff $ab^{-1} \in H$.","Let  be a group, and  a subgroup of . Let . Prove  iff .","G H G a, b \in G Ha=Hb ab^{-1} \in H","Let $G$ be a group, and $H$ a subgroup of $G$. Let $a, b \in G$. Prove $Ha=Hb$ iff $ab^{-1} \in H$. $\rightarrow$ If $Ha=Hb$, then $h_1a=h_2b$ for some $h_1, h_2 \in H$. So, $ab^{-1} = h_1^{-1}h_2$. Therefore, $ab^{-1} \in H$. $\leftarrow$ If $ab^{-1} \in H$, then $ab^{-1} = h_3$ for some $h_3 \in H$. So, $a=h_3b$, and thus $a \in Hb$. Therefore, $a \in Hb$ implies $Ha=Hb$. Is this proof correct? I am unsure about the first step (If $Ha=Hb$, then $h_1a=h_2b$ for some $h_1, h_2 \in H$.).","Let $G$ be a group, and $H$ a subgroup of $G$. Let $a, b \in G$. Prove $Ha=Hb$ iff $ab^{-1} \in H$. $\rightarrow$ If $Ha=Hb$, then $h_1a=h_2b$ for some $h_1, h_2 \in H$. So, $ab^{-1} = h_1^{-1}h_2$. Therefore, $ab^{-1} \in H$. $\leftarrow$ If $ab^{-1} \in H$, then $ab^{-1} = h_3$ for some $h_3 \in H$. So, $a=h_3b$, and thus $a \in Hb$. Therefore, $a \in Hb$ implies $Ha=Hb$. Is this proof correct? I am unsure about the first step (If $Ha=Hb$, then $h_1a=h_2b$ for some $h_1, h_2 \in H$.).",,"['abstract-algebra', 'group-theory', 'proof-verification', 'proof-writing']"
36,Is there any group $H\times K$ where $H\times 1$ and $1\times K$ are the only subgroups of order $n$?,Is there any group  where  and  are the only subgroups of order ?,H\times K H\times 1 1\times K n,"$G=H\times K$ where $H$ and $K$ are non-isomorphic groups of order $n$. I am looking for an example such that $G$ has no subgroup of order $n$ except $H\times 1$ and $1\times K$. If anyone can find such a group, I would be thankful. Edit: Let $G$ be such an example, then $H\times 1$ and $1\times K$ must be characteristic group in $G$ which means $\operatorname{Aut}(G)\cong \operatorname{Aut}(H)\times \operatorname{Aut}(K)$ and clearly $(|H|,|K|)\neq 1$. This may make question easy.(to reach contradiction)","$G=H\times K$ where $H$ and $K$ are non-isomorphic groups of order $n$. I am looking for an example such that $G$ has no subgroup of order $n$ except $H\times 1$ and $1\times K$. If anyone can find such a group, I would be thankful. Edit: Let $G$ be such an example, then $H\times 1$ and $1\times K$ must be characteristic group in $G$ which means $\operatorname{Aut}(G)\cong \operatorname{Aut}(H)\times \operatorname{Aut}(K)$ and clearly $(|H|,|K|)\neq 1$. This may make question easy.(to reach contradiction)",,"['abstract-algebra', 'group-theory', 'finite-groups']"
37,When are all ring homomorphisms also algebra homomorphisms?,When are all ring homomorphisms also algebra homomorphisms?,,"Let $k$ be an algebraically closed field, and let $A,B$ be two unitary $k$-algebras. In general, there are more ring homomorphisms $A\to B$ than there are $k$-algebra homomorphisms. More precisely, the forgetful functor from $k$-algebras to rings induces an injective map of sets $$j:\hom_{k\textrm{-Alg}}(A,B)\to \hom_{\textrm{Ring}}(A,B).$$ Question . Under what conditions on $k,A,B$ is $j$ a bijection? There is a particular case I am looking at. I have a finite dimensional $k$-vector space $V$ and the ring $A=k[x,y,z]$. If $B=\textrm{End}_k(V)$ is the ring of $k$-linear endomorphisms of $V$, does $$\hom_{\textrm{Ring}}(A,B)\cong\hom_{k\textrm{-Alg}}(A,B)$$ hold in this case? Thank you!","Let $k$ be an algebraically closed field, and let $A,B$ be two unitary $k$-algebras. In general, there are more ring homomorphisms $A\to B$ than there are $k$-algebra homomorphisms. More precisely, the forgetful functor from $k$-algebras to rings induces an injective map of sets $$j:\hom_{k\textrm{-Alg}}(A,B)\to \hom_{\textrm{Ring}}(A,B).$$ Question . Under what conditions on $k,A,B$ is $j$ a bijection? There is a particular case I am looking at. I have a finite dimensional $k$-vector space $V$ and the ring $A=k[x,y,z]$. If $B=\textrm{End}_k(V)$ is the ring of $k$-linear endomorphisms of $V$, does $$\hom_{\textrm{Ring}}(A,B)\cong\hom_{k\textrm{-Alg}}(A,B)$$ hold in this case? Thank you!",,"['abstract-algebra', 'ring-theory', 'vector-spaces', 'category-theory']"
38,Example of a Non-Abelian Infinite Group,Example of a Non-Abelian Infinite Group,,"I was hunting an example of a non-trivial infinite group in which 1) All non-trivial normal subgroup are non-abelian. 2) There exists a nontrivial subnormal abelian subgroup. Is there any hope to find this out? Note In the finite case such an example is not possible (see here ). Notation A subgroup H of a given group G is a subnormal subgroup of G if there is a finite chain of subgroups of the group, each one normal in the next, beginning at H and ending at G.","I was hunting an example of a non-trivial infinite group in which 1) All non-trivial normal subgroup are non-abelian. 2) There exists a nontrivial subnormal abelian subgroup. Is there any hope to find this out? Note In the finite case such an example is not possible (see here ). Notation A subgroup H of a given group G is a subnormal subgroup of G if there is a finite chain of subgroups of the group, each one normal in the next, beginning at H and ending at G.",,"['abstract-algebra', 'group-theory']"
39,Understanding what an action is?,Understanding what an action is?,,"This is a very simple question, and I am quite embarrassed to ask it! I'm trying to understand what an action is in general, and perhaps the best place to start is to try and outline my current understanding. I understand what a group action on a set is, a map $G \times X \rightarrow X$, where $(g,x) \mapsto g\cdot x$. such that $e \cdot x = x, \forall x \in X $, and  $(gh)\cdot x = g\cdot(h\cdot x)$ By the properties above each element of $G$ gives us a bijection of elements in $X$, and we have a homomorphism $G \rightarrow \textrm{Sym}(X)$ As I understand it we can also have a group acting on other objects, namely we say a group $G$ acts on an object $A$ if we have a group homomorphism $G \rightarrow \textrm{End}(A)$ E.g. in Galois theory, if we have a Galois extension $E / F$ with Galois group $G$, then $G$ acts on $E$, as we have a map $G \times E \rightarrow E$, where $(g,a) \mapsto g(a)$. By its definition $g$ is an automorphism of $E$, and the group operation is composition of functions so $(g, (h , a)) = (gh ,a)$.  From my understanding, this action is not just on the underlying set of the field, we actually mean that the action respects the field structure. So in general if we want to show that a group $G$ acts on an object $A$ we have to: (1) associate an element $g \in G$ with a map $\phi_g: A \rightarrow A$ (2) Show that this map is a homomorphism $\phi_g \in \textrm{Hom} (A,A)$, i.e. that it respects all the operations of $A$, and (3) show that for $g_1, g_2 \in G$ we have $\phi_{g_1g_2} = \phi_{g_1} (\phi_{g_2})$. Hopefully I am right so far, please correct me if not. Where I am having trouble is twofold. Firstly, I am worried that my understanding is a little off. When $X$ is a set, the action of an element of $G$ is a bijection of the set, so it seems to me that if an object $A$  has an underlying set $X$ then should we instead expect a homomorphism $G \rightarrow \textrm{Aut}(A)$? In fact, regardless of the underlying set, using an element of $G$ and its inverse then the composition property implies that the homomorphism associated with any element $g \in G$ has an inverse, namely the homomorphism associated to $g^{-1}$. Secondly, I don't have an understanding or appreciation of the significance of group actions in a wider setting, for example if we have a Galois extension $E / F$ with Galois group $G$, and let $N$ be the fixed field of a normal subgroup $H \trianglelefteq G$, then $G$ acts on $H$ by conjugation. But I am struggling to see the interpretation of this i.e. what meaning the action has in terms of the field extension, or the group. Thanks in advance for any pointers.","This is a very simple question, and I am quite embarrassed to ask it! I'm trying to understand what an action is in general, and perhaps the best place to start is to try and outline my current understanding. I understand what a group action on a set is, a map $G \times X \rightarrow X$, where $(g,x) \mapsto g\cdot x$. such that $e \cdot x = x, \forall x \in X $, and  $(gh)\cdot x = g\cdot(h\cdot x)$ By the properties above each element of $G$ gives us a bijection of elements in $X$, and we have a homomorphism $G \rightarrow \textrm{Sym}(X)$ As I understand it we can also have a group acting on other objects, namely we say a group $G$ acts on an object $A$ if we have a group homomorphism $G \rightarrow \textrm{End}(A)$ E.g. in Galois theory, if we have a Galois extension $E / F$ with Galois group $G$, then $G$ acts on $E$, as we have a map $G \times E \rightarrow E$, where $(g,a) \mapsto g(a)$. By its definition $g$ is an automorphism of $E$, and the group operation is composition of functions so $(g, (h , a)) = (gh ,a)$.  From my understanding, this action is not just on the underlying set of the field, we actually mean that the action respects the field structure. So in general if we want to show that a group $G$ acts on an object $A$ we have to: (1) associate an element $g \in G$ with a map $\phi_g: A \rightarrow A$ (2) Show that this map is a homomorphism $\phi_g \in \textrm{Hom} (A,A)$, i.e. that it respects all the operations of $A$, and (3) show that for $g_1, g_2 \in G$ we have $\phi_{g_1g_2} = \phi_{g_1} (\phi_{g_2})$. Hopefully I am right so far, please correct me if not. Where I am having trouble is twofold. Firstly, I am worried that my understanding is a little off. When $X$ is a set, the action of an element of $G$ is a bijection of the set, so it seems to me that if an object $A$  has an underlying set $X$ then should we instead expect a homomorphism $G \rightarrow \textrm{Aut}(A)$? In fact, regardless of the underlying set, using an element of $G$ and its inverse then the composition property implies that the homomorphism associated with any element $g \in G$ has an inverse, namely the homomorphism associated to $g^{-1}$. Secondly, I don't have an understanding or appreciation of the significance of group actions in a wider setting, for example if we have a Galois extension $E / F$ with Galois group $G$, and let $N$ be the fixed field of a normal subgroup $H \trianglelefteq G$, then $G$ acts on $H$ by conjugation. But I am struggling to see the interpretation of this i.e. what meaning the action has in terms of the field extension, or the group. Thanks in advance for any pointers.",,"['abstract-algebra', 'group-theory', 'group-actions']"
40,Is there some sort of correspondence between groups and partitions of a set?,Is there some sort of correspondence between groups and partitions of a set?,,"Every group action on a set $S$ partitions the set into orbits.  Conversely, for every partition of $S$ is there a group action such that the set of orbits of the group action equals the partition? My attempt.  Let $P = \{S_1,\dots, S_k\}$  be a partition of a finite set $S$ of order $n$.  Then there are elements of $G = Perm(S)$, the set of permutations of $S$, that leave each subset fixed, i.e. $g\in G$ such that $g\cdot S_i = \{gs : s\in S_i\} = S_i, \forall i$.  Think of the permutations that fix all of $S$ except permutes $S_i$ possibly in some nontrivial way.  If $g, h$ are such elements then $gS_i = S_i, \forall i$, so $g^{-1} S_i = S_i$, the action also being an action on the subsets.  Similarly $g\cdot h S_i = g S_i = S_i$.  Thus, the set of all $P$-stabilizing elements is a subgroup of $G$. Groups are known in correspondence with subgroups of $G$.  Please comment. Motivation: is there a group-theoretical way to count partitions of a set of size $n$?  So that maybe it can help prove formulas about the latter. According to m_l in a comment, there's no application here to counting partitions here that doesn't lead to having to count the partitions the known ways. I was thinking, we haven't considered yet, at least I haven't, the set of partitions of $S$ itself, call it $P(S)$, and the group $G = Perm(S)$ acting on it.  The nice thing about $G = Perm(S)$ is that every finite group is isomorphic to a subgroup of it.  So if $H \leqslant G$, and $H'$ is the group presented in some other way, then almost anything we say about $H$ can be applied to $H'$ regarding group actions on $S$ or $P(S)$.  Hopefully, so let's keep that in the back of our minds.  In other words, every partition corresponds to a partition of the set of subgroups of $G$.  But we should say more about it than that.  I'm moving off track here, so continuing on... Define the action of $G$ on $P(S), $ to be $g \cdot P = \cup_{i=|P|} \{ g\cdot S_i \}$, where $g\cdot S_i$ is the element $g$ acting on the block $S_i$ suing simple coset multpilcation.  Relatedly there's an obvious way to make $G$ act on the set of all subsets of $S$. Anyway.  As you can tell the action on $P(S)$ defines a group action.  Proof: The identity permutation obviously fixes a partition.  And $g(h P) = g\cdot\cup_{i=1..|P|} \{ h\cdot S_i \}$.  Note that since $g$ acts on the set of subsets of $S$, $g(hP) = (gh)P. \ $  The rest of the proof is left to the reader. Let's switch notation a bit.  $P\in P(S)$ will now be called $p$, and $P(S)$ will be called $P$. An orbit is simply $O_p = G\cdot p \subset P(S)$.  We have the class equation $|P(S)| = \sum_{orbits} |O_p|$ Burnside's Lemma: # orbits $ = 1/|G| \sum_{g\in G}|P^g|, \ $ where $P^g$ is the set of all partitions fixed by $g$. and the index counting formula $|G| = |H_p||O_p| = |H_p|[G:H_p], \ $ where $H_p = Stab(p)$ is the stabilizer of the partition $p$.","Every group action on a set $S$ partitions the set into orbits.  Conversely, for every partition of $S$ is there a group action such that the set of orbits of the group action equals the partition? My attempt.  Let $P = \{S_1,\dots, S_k\}$  be a partition of a finite set $S$ of order $n$.  Then there are elements of $G = Perm(S)$, the set of permutations of $S$, that leave each subset fixed, i.e. $g\in G$ such that $g\cdot S_i = \{gs : s\in S_i\} = S_i, \forall i$.  Think of the permutations that fix all of $S$ except permutes $S_i$ possibly in some nontrivial way.  If $g, h$ are such elements then $gS_i = S_i, \forall i$, so $g^{-1} S_i = S_i$, the action also being an action on the subsets.  Similarly $g\cdot h S_i = g S_i = S_i$.  Thus, the set of all $P$-stabilizing elements is a subgroup of $G$. Groups are known in correspondence with subgroups of $G$.  Please comment. Motivation: is there a group-theoretical way to count partitions of a set of size $n$?  So that maybe it can help prove formulas about the latter. According to m_l in a comment, there's no application here to counting partitions here that doesn't lead to having to count the partitions the known ways. I was thinking, we haven't considered yet, at least I haven't, the set of partitions of $S$ itself, call it $P(S)$, and the group $G = Perm(S)$ acting on it.  The nice thing about $G = Perm(S)$ is that every finite group is isomorphic to a subgroup of it.  So if $H \leqslant G$, and $H'$ is the group presented in some other way, then almost anything we say about $H$ can be applied to $H'$ regarding group actions on $S$ or $P(S)$.  Hopefully, so let's keep that in the back of our minds.  In other words, every partition corresponds to a partition of the set of subgroups of $G$.  But we should say more about it than that.  I'm moving off track here, so continuing on... Define the action of $G$ on $P(S), $ to be $g \cdot P = \cup_{i=|P|} \{ g\cdot S_i \}$, where $g\cdot S_i$ is the element $g$ acting on the block $S_i$ suing simple coset multpilcation.  Relatedly there's an obvious way to make $G$ act on the set of all subsets of $S$. Anyway.  As you can tell the action on $P(S)$ defines a group action.  Proof: The identity permutation obviously fixes a partition.  And $g(h P) = g\cdot\cup_{i=1..|P|} \{ h\cdot S_i \}$.  Note that since $g$ acts on the set of subsets of $S$, $g(hP) = (gh)P. \ $  The rest of the proof is left to the reader. Let's switch notation a bit.  $P\in P(S)$ will now be called $p$, and $P(S)$ will be called $P$. An orbit is simply $O_p = G\cdot p \subset P(S)$.  We have the class equation $|P(S)| = \sum_{orbits} |O_p|$ Burnside's Lemma: # orbits $ = 1/|G| \sum_{g\in G}|P^g|, \ $ where $P^g$ is the set of all partitions fixed by $g$. and the index counting formula $|G| = |H_p||O_p| = |H_p|[G:H_p], \ $ where $H_p = Stab(p)$ is the stabilizer of the partition $p$.",,"['abstract-algebra', 'group-theory', 'set-partition']"
41,Specific projective dimension of a module over bound quiver,Specific projective dimension of a module over bound quiver,,"Suppose $K$ is an algebraically closed field, and $A$ is the algebra presented by the quiver $$\require{AMScd} \begin{CD} 1 @>>> 2\\ @V{}VV @V{}VV \\ 3 @>>> 4 @>>> 5 \end{CD} $$ bound by $1\to 2\to 4 = 1\to3\to 4$ and $3\to4\to5 = 0$. What is the projective dimension of the simple $A$-module $S(1)$? Here is my work: the projective indecomposables have submodule lattices indicated by the following Alperin diagrams: $$\begin{array}{c@{}c@{}c@{}c@{}c} \newcommand{\kem}{\kern-1ex} \kem&\kem&\kem\kem1\kem&\kem&\kem \\ \kem&\kem\nearrow\kem&\kem&\kem\nwarrow\kem&\kem \\ 2\kem&\kem&\kem&\kem&\kem3 \\ \kem&\kem\nwarrow\kem&\kem&\kem\nearrow\kem&\kem \\ \kem&\kem&\kem\kem4\kem&\kem&\kem \end{array} \qquad \begin{array}{c} 2 \\ \uparrow \\ 4 \\ \uparrow \\ 5 \end{array} \qquad \begin{array}{c} 3 \\ \uparrow \\ 4 \\ \phantom{\uparrow} \\ \phantom{5}\end{array} \qquad \begin{array}{c} 4 \\ \uparrow \\ 5 \\ \phantom{\uparrow} \\ \phantom{5}\end{array} \qquad \begin{array}{c} 5 \\ \phantom{\uparrow} \\ \phantom{4} \\ \phantom{\uparrow} \\ \phantom{5}\end{array} $$ The projective cover of $S(1)$ is $P(1)$ and the kernel is the Heller operator of $S(1)$, namely $$\begin{array}{c@{}c@{}c@{}c@{}c} \newcommand{\kem}{\kern-1ex} 2\kem&\kem&\kem&\kem&\kem3 \\ &\kem\nwarrow\kem&\kem&\kem\nearrow\kem&\\ &\kem&\kem\kem4\kem&\kem& \end{array} $$ with $P(2) \oplus P(3)$ its projective cover. Now the problem is to find the second Heller operator $\Omega^2(S(1))$. Its composition factors are clear: $S(4)$ and $S(5)$, but how do we know if it is $S(4) \oplus S(5)$ versus $P(4) = \begin{array}{c} 4 \\ \uparrow \\ 5 \end{array}$? In the former case, the next projective cover is $P(5) = S(5)$ and the resolution terminates with projective dimension 3, but in the latter case the resolution terminates immediately with projective dimension 2. The former case “uses” the 4 from $P(2)$ leaving $S(5)$ from $P(2)$ and $S(4)$ from $P(3)$. The latter case “uses” the 4 from $P(3)$ leaving the trailing $P(4)$ from $P(3)$. Neither of these is really the kernel, since it is some sort of “diagonal” submodule, but how do we know if the diagonal submodule is split or not? Does the answer depend on the field?","Suppose $K$ is an algebraically closed field, and $A$ is the algebra presented by the quiver $$\require{AMScd} \begin{CD} 1 @>>> 2\\ @V{}VV @V{}VV \\ 3 @>>> 4 @>>> 5 \end{CD} $$ bound by $1\to 2\to 4 = 1\to3\to 4$ and $3\to4\to5 = 0$. What is the projective dimension of the simple $A$-module $S(1)$? Here is my work: the projective indecomposables have submodule lattices indicated by the following Alperin diagrams: $$\begin{array}{c@{}c@{}c@{}c@{}c} \newcommand{\kem}{\kern-1ex} \kem&\kem&\kem\kem1\kem&\kem&\kem \\ \kem&\kem\nearrow\kem&\kem&\kem\nwarrow\kem&\kem \\ 2\kem&\kem&\kem&\kem&\kem3 \\ \kem&\kem\nwarrow\kem&\kem&\kem\nearrow\kem&\kem \\ \kem&\kem&\kem\kem4\kem&\kem&\kem \end{array} \qquad \begin{array}{c} 2 \\ \uparrow \\ 4 \\ \uparrow \\ 5 \end{array} \qquad \begin{array}{c} 3 \\ \uparrow \\ 4 \\ \phantom{\uparrow} \\ \phantom{5}\end{array} \qquad \begin{array}{c} 4 \\ \uparrow \\ 5 \\ \phantom{\uparrow} \\ \phantom{5}\end{array} \qquad \begin{array}{c} 5 \\ \phantom{\uparrow} \\ \phantom{4} \\ \phantom{\uparrow} \\ \phantom{5}\end{array} $$ The projective cover of $S(1)$ is $P(1)$ and the kernel is the Heller operator of $S(1)$, namely $$\begin{array}{c@{}c@{}c@{}c@{}c} \newcommand{\kem}{\kern-1ex} 2\kem&\kem&\kem&\kem&\kem3 \\ &\kem\nwarrow\kem&\kem&\kem\nearrow\kem&\\ &\kem&\kem\kem4\kem&\kem& \end{array} $$ with $P(2) \oplus P(3)$ its projective cover. Now the problem is to find the second Heller operator $\Omega^2(S(1))$. Its composition factors are clear: $S(4)$ and $S(5)$, but how do we know if it is $S(4) \oplus S(5)$ versus $P(4) = \begin{array}{c} 4 \\ \uparrow \\ 5 \end{array}$? In the former case, the next projective cover is $P(5) = S(5)$ and the resolution terminates with projective dimension 3, but in the latter case the resolution terminates immediately with projective dimension 2. The former case “uses” the 4 from $P(2)$ leaving $S(5)$ from $P(2)$ and $S(4)$ from $P(3)$. The latter case “uses” the 4 from $P(3)$ leaving the trailing $P(4)$ from $P(3)$. Neither of these is really the kernel, since it is some sort of “diagonal” submodule, but how do we know if the diagonal submodule is split or not? Does the answer depend on the field?",,"['abstract-algebra', 'modules', 'representation-theory', 'projective-module', 'quiver']"
42,Vandermonde identity in a ring,Vandermonde identity in a ring,,"Let $R$ be a commutative $\mathbb{Q}$-algebra. For $r \in R$ and $n \in \mathbb{N}$ we can define the binomial coefficient $\binom{r}{n}$ as usual by $\binom{r}{0}=1$ and $\binom{r}{n+1}=\frac{r-n}{n+1} \cdot \binom{r}{n}$. I would like to prove the following identity for $r,s \in R$ and $n \in \mathbb{N}$: $$\binom{r+s}{n}=\sum_{p+q=n} \binom{r}{p} \cdot \binom{s}{q}$$ For $r,s \in \mathbb{N}$ this is known as the Vandermonde identity . For $R=\mathbb{C}$ it is known as the Chu–Vandermonde identity. In general, let's just call it the Vandermonde identity in $R$. One can prove the identity for general $R$ by observing that both sides are polynomials in $r,s$, so that it suffices to consider $R=\mathbb{Q}[x,y]$ with $r=x$, $s=y$. Then the polynomials agree on $\mathbb{N} \times \mathbb{N}$ by the usual Vandermonde identity. Hence they are equal (using that $\mathbb{N} \times \mathbb{N} \subseteq \mathbb{A}^2$ is Zariski dense). See also Darij Grinberg's notes on $\lambda$-rings , Theorem 3.2. Question. Is there a more direct and algebraic proof of the Vandermonde identity in a given commutative $\mathbb{Q}$-algebra $R$? I am looking for a proof which works directly for $R$, without any reduction arguments. There should be some proof which just consists of simple algebraic manipulations. I have tried induction on $n$, but didn't succeed. Note that the claim is equivalent to $$\prod_{k=0}^{n-1} (r+s-k)=\sum_{p=0}^{n} \binom{n}{p} \cdot \prod_{i=0}^{p-1} (r-i) \cdot \prod_{j=0}^{n-p-1} (s-j).$$ I would also be very happy with a proof following the principle of categorification: For $r,n$ try to find some $R$-module (or some complex of $R$-modules?) $\Lambda^n(r)$, construct (via universal properties?) an isomorphism $\Lambda^n(r+s) \cong \oplus_{p+q=n} \Lambda^p(r) \otimes \Lambda^q(s)$ and evaluate this using some rank function. I have no idea what $\Lambda^n(r)$ should be, but for $r \in \mathbb{N}$ it should be the usual exterior power $\Lambda^n(R^r)$.","Let $R$ be a commutative $\mathbb{Q}$-algebra. For $r \in R$ and $n \in \mathbb{N}$ we can define the binomial coefficient $\binom{r}{n}$ as usual by $\binom{r}{0}=1$ and $\binom{r}{n+1}=\frac{r-n}{n+1} \cdot \binom{r}{n}$. I would like to prove the following identity for $r,s \in R$ and $n \in \mathbb{N}$: $$\binom{r+s}{n}=\sum_{p+q=n} \binom{r}{p} \cdot \binom{s}{q}$$ For $r,s \in \mathbb{N}$ this is known as the Vandermonde identity . For $R=\mathbb{C}$ it is known as the Chu–Vandermonde identity. In general, let's just call it the Vandermonde identity in $R$. One can prove the identity for general $R$ by observing that both sides are polynomials in $r,s$, so that it suffices to consider $R=\mathbb{Q}[x,y]$ with $r=x$, $s=y$. Then the polynomials agree on $\mathbb{N} \times \mathbb{N}$ by the usual Vandermonde identity. Hence they are equal (using that $\mathbb{N} \times \mathbb{N} \subseteq \mathbb{A}^2$ is Zariski dense). See also Darij Grinberg's notes on $\lambda$-rings , Theorem 3.2. Question. Is there a more direct and algebraic proof of the Vandermonde identity in a given commutative $\mathbb{Q}$-algebra $R$? I am looking for a proof which works directly for $R$, without any reduction arguments. There should be some proof which just consists of simple algebraic manipulations. I have tried induction on $n$, but didn't succeed. Note that the claim is equivalent to $$\prod_{k=0}^{n-1} (r+s-k)=\sum_{p=0}^{n} \binom{n}{p} \cdot \prod_{i=0}^{p-1} (r-i) \cdot \prod_{j=0}^{n-p-1} (s-j).$$ I would also be very happy with a proof following the principle of categorification: For $r,n$ try to find some $R$-module (or some complex of $R$-modules?) $\Lambda^n(r)$, construct (via universal properties?) an isomorphism $\Lambda^n(r+s) \cong \oplus_{p+q=n} \Lambda^p(r) \otimes \Lambda^q(s)$ and evaluate this using some rank function. I have no idea what $\Lambda^n(r)$ should be, but for $r \in \mathbb{N}$ it should be the usual exterior power $\Lambda^n(R^r)$.",,"['abstract-algebra', 'commutative-algebra', 'polynomials', 'ring-theory', 'binomial-coefficients']"
43,Why is this statement about generators of groups true?,Why is this statement about generators of groups true?,,"Let $G$ be free abelian of rank $n$ and $H \subseteq G$ a subgroup also of rank $n$. It is known that $G/H$ is finite, in fact a direct sum of at most $n$ cyclic groups. Thus we can write $$G/H = \langle x_1,\ldots,x_n | d_1x_1 = \cdots =d_nx_n = 0\rangle,$$ where the $d_i$'s are the orders of those cyclic groups. From here why does it follow that there is a basis $\beta_1,\ldots,\beta_n$ of $G$ such that $d_1\beta_1,\ldots ,d_n\beta_n$ is a basis for $H$? Thanks!","Let $G$ be free abelian of rank $n$ and $H \subseteq G$ a subgroup also of rank $n$. It is known that $G/H$ is finite, in fact a direct sum of at most $n$ cyclic groups. Thus we can write $$G/H = \langle x_1,\ldots,x_n | d_1x_1 = \cdots =d_nx_n = 0\rangle,$$ where the $d_i$'s are the orders of those cyclic groups. From here why does it follow that there is a basis $\beta_1,\ldots,\beta_n$ of $G$ such that $d_1\beta_1,\ldots ,d_n\beta_n$ is a basis for $H$? Thanks!",,"['abstract-algebra', 'group-theory']"
44,Question about a property certain algebraic extensions $E/K$ (not necessarily separable) have.,Question about a property certain algebraic extensions  (not necessarily separable) have.,E/K,"A few days ago I found this question here on math.stackexchange, which gave a sufficient criterion for a separable, algebraic extension $E/K$ to be an algebraic closure of $K$. However it was claimed by KCd, in a comment below the question I'm referring to, that we can drop the separability condition on the extension and still get the same result My question is: how does the proof work in the non-separable case? Put precisely: Let $E/K$ be an algebraic extension such that every non-constant polynomial in $K[X]$ has a root in $E$, then $E$ is the (up to isomorphism) algebraic closure of $K$. It is pretty clear to me that Makotos proof in the separable case (which can be found on the page the link above is leading to) won't work for the case of a non-separable extension (e.g. because the primitive element theorem may fail). I had some ideas of working with the separable closure but didn't try much, because I didn't see a real perspective in my approach. In other words, I'm stuck. Lastly an apology: I refrained from asking KCd this question directly because it might be of common interest. Regards","A few days ago I found this question here on math.stackexchange, which gave a sufficient criterion for a separable, algebraic extension $E/K$ to be an algebraic closure of $K$. However it was claimed by KCd, in a comment below the question I'm referring to, that we can drop the separability condition on the extension and still get the same result My question is: how does the proof work in the non-separable case? Put precisely: Let $E/K$ be an algebraic extension such that every non-constant polynomial in $K[X]$ has a root in $E$, then $E$ is the (up to isomorphism) algebraic closure of $K$. It is pretty clear to me that Makotos proof in the separable case (which can be found on the page the link above is leading to) won't work for the case of a non-separable extension (e.g. because the primitive element theorem may fail). I had some ideas of working with the separable closure but didn't try much, because I didn't see a real perspective in my approach. In other words, I'm stuck. Lastly an apology: I refrained from asking KCd this question directly because it might be of common interest. Regards",,"['abstract-algebra', 'field-theory']"
45,Prime ideals of the ring of rational functions,Prime ideals of the ring of rational functions,,"Let $A$ be a commutative ring with identity. If $f = a_0 + a_1 x + \cdots + a_n x^n \in A[x]$ is a polynomial, define $c(f) = A a_0 + A a_1 + \cdots + A a_n$ the ideal of $A$ generated by the coefficients of $f$. Consider $S$ the subset of $A[x]$ made up of primitive polynomials, i.e. polynomials $f \in A[x]$ such that $c(f) = A$. It is not difficult to prove that $S$ is a multiplicative subset of $A[x]$. Consider the ring $$ A(x) = S^{-1} (A[x]). $$ It is easy to show that $S$ does not contain zero-divisors of $A[x]$, hence $A \subseteq A[x] \subseteq A(x)$. If $I$ is an ideal of $A$ then $(I \cdot A(x)) \cap A = I$. If $\mathfrak{p}$ is a prime ideal of $A$ then $\mathfrak{p} \cdot A(x)$ is a prime ideal of $A(x)$. The map $\phi \colon \mathrm{Spec} A(x) \to \mathrm{Spec} A$ defined by $\phi(P) = P \cap A$ is surjective, because a right-inverse is $\mathfrak{p} \mapsto \mathfrak{p} \cdot A(x)$. It is clear that $\dim A \leq \dim A(x) \leq \dim A[x]$. If $M$ is a maximal ideal of $A(x)$, then does there exist a maximal ideal $\mathfrak{m}$ of $A$ such that $M = \mathfrak{m} \cdot A(x)$? Is the map $\phi \colon \mathrm{Spec} A(x) \to \mathrm{Spec} A$ injective? If $A$ is noetherian, then $\dim A(x) = \dim A$? If $A$ is a normal domain, then is $A(x)$ a normal domain?","Let $A$ be a commutative ring with identity. If $f = a_0 + a_1 x + \cdots + a_n x^n \in A[x]$ is a polynomial, define $c(f) = A a_0 + A a_1 + \cdots + A a_n$ the ideal of $A$ generated by the coefficients of $f$. Consider $S$ the subset of $A[x]$ made up of primitive polynomials, i.e. polynomials $f \in A[x]$ such that $c(f) = A$. It is not difficult to prove that $S$ is a multiplicative subset of $A[x]$. Consider the ring $$ A(x) = S^{-1} (A[x]). $$ It is easy to show that $S$ does not contain zero-divisors of $A[x]$, hence $A \subseteq A[x] \subseteq A(x)$. If $I$ is an ideal of $A$ then $(I \cdot A(x)) \cap A = I$. If $\mathfrak{p}$ is a prime ideal of $A$ then $\mathfrak{p} \cdot A(x)$ is a prime ideal of $A(x)$. The map $\phi \colon \mathrm{Spec} A(x) \to \mathrm{Spec} A$ defined by $\phi(P) = P \cap A$ is surjective, because a right-inverse is $\mathfrak{p} \mapsto \mathfrak{p} \cdot A(x)$. It is clear that $\dim A \leq \dim A(x) \leq \dim A[x]$. If $M$ is a maximal ideal of $A(x)$, then does there exist a maximal ideal $\mathfrak{m}$ of $A$ such that $M = \mathfrak{m} \cdot A(x)$? Is the map $\phi \colon \mathrm{Spec} A(x) \to \mathrm{Spec} A$ injective? If $A$ is noetherian, then $\dim A(x) = \dim A$? If $A$ is a normal domain, then is $A(x)$ a normal domain?",,"['abstract-algebra', 'commutative-algebra', 'polynomials', 'ring-theory']"
46,Why are local rings called local?,Why are local rings called local?,,"I gather that rings of germs of functions at a point $p$ on a manifold/variety/etc. are local with the maximal ideal containing exactly the germs of functions which vanish at $p$ . So in some sense, these rings, which happen to be local, describe the local behavior of functions. But what about other local rings? $\mathbb Z/p^n\mathbb Z$ is local for primes $p$ and $n\geq1$ . Can we interpret it as a ring of germs of functions on some space? I found a way to do so for fields $F$ , at least. They can be seen as the ring of functions (or germs thereof, makes no difference in this case) on a one-element topological space $\{p\}$ , where $x(p):=x$ for all $x\in F$ . Which seems like it would make sense in a context where local rings actually are rings of germs: local rings with trivial maximal ideal (fields) are germs of functions on a trivial space. But how to generalize this?","I gather that rings of germs of functions at a point on a manifold/variety/etc. are local with the maximal ideal containing exactly the germs of functions which vanish at . So in some sense, these rings, which happen to be local, describe the local behavior of functions. But what about other local rings? is local for primes and . Can we interpret it as a ring of germs of functions on some space? I found a way to do so for fields , at least. They can be seen as the ring of functions (or germs thereof, makes no difference in this case) on a one-element topological space , where for all . Which seems like it would make sense in a context where local rings actually are rings of germs: local rings with trivial maximal ideal (fields) are germs of functions on a trivial space. But how to generalize this?",p p \mathbb Z/p^n\mathbb Z p n\geq1 F \{p\} x(p):=x x\in F,"['abstract-algebra', 'ring-theory', 'local-rings', 'germs']"
47,Ideal topology on commutative ring,Ideal topology on commutative ring,,"One small question on the book 'Real and Functional Analysis' by S. Lang: Example 6 on page 21: Let $R$ be a commutative ring. We define a subset $U$ of $R$ to be open if for each $x\in U$ there exists an ideal $J$ in $R$ such that $x+J\subseteq U$ . This is called the ideal topology. It seems to me that this definition is useless: All sets will be open because we can always pick $J=0$ . Unfortunately I couldn't find anything related to this 'ideal topology' via a Google search, so I don't know what is meant in the book. Perhaps requiring $J\ne0$ ?","One small question on the book 'Real and Functional Analysis' by S. Lang: Example 6 on page 21: Let be a commutative ring. We define a subset of to be open if for each there exists an ideal in such that . This is called the ideal topology. It seems to me that this definition is useless: All sets will be open because we can always pick . Unfortunately I couldn't find anything related to this 'ideal topology' via a Google search, so I don't know what is meant in the book. Perhaps requiring ?",R U R x\in U J R x+J\subseteq U J=0 J\ne0,['abstract-algebra']
48,Hasse-Minkowski for cubic forms,Hasse-Minkowski for cubic forms,,"We know that an analogue of the Hasse-Minkowski theorem does not hold for all cubic forms, e.g. because Selmer's cubic: $$ 3x^3 + 4y^3 + 5z^3 = 0 $$ has solutions over $\mathbb{R}$ and $\mathbb{Q}_p$ for all $p$ , but no solutions over $\mathbb{Q}$ . My questions are: Can we find a (non-trivial) class of cubic forms where an analogue of the Hasse-Minkowski theorem does hold? Is there any intuition for why the local-global principle holds for quadratic but fails for cubic forms? Are there higher degree forms where the local-global principle holds again? Are questions like these addressed anywhere in the literature? Many thanks.","We know that an analogue of the Hasse-Minkowski theorem does not hold for all cubic forms, e.g. because Selmer's cubic: has solutions over and for all , but no solutions over . My questions are: Can we find a (non-trivial) class of cubic forms where an analogue of the Hasse-Minkowski theorem does hold? Is there any intuition for why the local-global principle holds for quadratic but fails for cubic forms? Are there higher degree forms where the local-global principle holds again? Are questions like these addressed anywhere in the literature? Many thanks.","
3x^3 + 4y^3 + 5z^3 = 0
 \mathbb{R} \mathbb{Q}_p p \mathbb{Q}","['abstract-algebra', 'number-theory', 'elementary-number-theory', 'diophantine-equations', 'p-adic-number-theory']"
49,Maps between short exact sequences,Maps between short exact sequences,,"Suppose I have a short exact sequence of modules $0 \to A \to B \to C \to 0$ . Let $A' \subseteq A$ and $C' \subseteq C$ be submodules and suppose I have a short exact sequence $0 \to A'\to B'\to C'\to 0$ . Then I have the following diagram: $$   \require{AMScd}   \begin{CD}     0 @>>> A'   @>>> B'   @>>>C' @>>> 0  \\     @.     @VVV      @.   @VVV        @. \\     0 @>>> A    @>>> B    @>>>C  @>>> 0   \end{CD} $$ I know in general there is no map $B' \to B$ that would make the diagram commute, but are there sufficient conditions for such a map to exist?","Suppose I have a short exact sequence of modules . Let and be submodules and suppose I have a short exact sequence . Then I have the following diagram: I know in general there is no map that would make the diagram commute, but are there sufficient conditions for such a map to exist?","0 \to A \to B \to C \to 0 A' \subseteq A C' \subseteq C 0 \to A'\to B'\to C'\to 0 
  \require{AMScd}
  \begin{CD}
    0 @>>> A'   @>>> B'   @>>>C' @>>> 0  \\
    @.     @VVV      @.   @VVV        @. \\
    0 @>>> A    @>>> B    @>>>C  @>>> 0
  \end{CD}
 B' \to B","['abstract-algebra', 'commutative-algebra', 'modules', 'representation-theory']"
50,Proof of Jordan-Hölder for Modules carries over for Groups?,Proof of Jordan-Hölder for Modules carries over for Groups?,,"The Book [Auslander, Reiten - Representation theory of Artin algebras] begins with the Jordan-Hölder theorem for modules of finite length over arbitrary rings. The proof is probably quite standard - here is the idea: Define the length of a module $M$ and the multiplicities of its composition factors as minimal length and minimal multiplicities over all (generalized) composition series. Then show that these functions are additive with respect to short exact sequences. The Jordan-Hölder theorem now follows easily by induction on the length of $M$: For $l(M) \leq 1$ the statement holds clearly. If $l(M) \geq 2$ there is a submodule $0 \lneq U \lneq M$. Any (generalized) composition series of $M$ splits into a (generalized) composition series of $U$ and of $M/U$. By induction hypothesis, those sequences satisfy the claim, i.e. they have length $l(U)$ and $l(M/U)$, respectively, and certain factor multiplicities defined by $U$ and $M/U$. By additivity of the length function and the multiplicity functions shown before, the claim also holds for the chosen composition series of $M$. I wonder whether this proof can be adopted verbatim to prove the Jordan-Hölder theorem for groups. At first sight, I see no reason why this cannot be done. However, I haven't seen this proof in any source concerning groups (usually, the Zassenhaus lemma is used instead).","The Book [Auslander, Reiten - Representation theory of Artin algebras] begins with the Jordan-Hölder theorem for modules of finite length over arbitrary rings. The proof is probably quite standard - here is the idea: Define the length of a module $M$ and the multiplicities of its composition factors as minimal length and minimal multiplicities over all (generalized) composition series. Then show that these functions are additive with respect to short exact sequences. The Jordan-Hölder theorem now follows easily by induction on the length of $M$: For $l(M) \leq 1$ the statement holds clearly. If $l(M) \geq 2$ there is a submodule $0 \lneq U \lneq M$. Any (generalized) composition series of $M$ splits into a (generalized) composition series of $U$ and of $M/U$. By induction hypothesis, those sequences satisfy the claim, i.e. they have length $l(U)$ and $l(M/U)$, respectively, and certain factor multiplicities defined by $U$ and $M/U$. By additivity of the length function and the multiplicity functions shown before, the claim also holds for the chosen composition series of $M$. I wonder whether this proof can be adopted verbatim to prove the Jordan-Hölder theorem for groups. At first sight, I see no reason why this cannot be done. However, I haven't seen this proof in any source concerning groups (usually, the Zassenhaus lemma is used instead).",,"['abstract-algebra', 'group-theory', 'ring-theory', 'modules', 'noncommutative-algebra']"
51,Which isomorphism of coordinate rings corresponds to isomorphisms of affine varieties?,Which isomorphism of coordinate rings corresponds to isomorphisms of affine varieties?,,"Consider the following claim: Let $X \subset k[x_1,\dots,x_n]$ and $Y\subset k[y_1,\dots,y_m]$ be algebraic sets and suppose that we have a ring isomorphism $\varphi: \mathcal{O}_Y \to \mathcal{O}_X$ . Show that the algebraic sets $X$ and $Y$ are isomorphic. Now, I know that if $\varphi$ is an isomorphism of $k$ -algebras, then $X$ and $Y$ are isomorphic. And I know that any isomorphism of $k$ -algebras is also an isomorphism of the underlying rings. Question: However, isn't it the case that not every ring homomorphism $\varphi: \mathcal{O}_Y \to \mathcal{O}_X$ is a $k$ -algebra homomorphism $\mathcal{O}_Y \to \mathcal{O}_X$ , and that only $k$ -algebra homomorphisms $ \mathcal{O}_Y \to \mathcal{O}_X$ correspond to morphisms $X \to Y$ , not arbitrary ring homomorphsims $\mathcal{O}_Y \to \mathcal{O}_X$ ? In other words, which of the following two statements are correct? Are they even mutually exclusive? Or are they equivalent? If they are equivalent, why? Two algebraic sets are isomorphic if and only if their coordinate rings are isomorphic as rings. OR Two algebraic sets are isomorphic if and only if their coordinate rings are isomorphic as $k$ -algebras. Context: My book , in sections 4.18 and 4.19, as well as this question on Math.SE implies that the first statement is true. However, section 4.8 of the same book , and every other source I have found (e.g. here or here ), implies only that the second statement is true. Moreover, I was only able to prove the second statement, not the first. Which is correct? This is a follow-up to my previous question , an attempt to show that the two statements are mutually exclusive and not equivalent. It was unanswered though, so I don't know if my attempt was successful -- for all I know, the two statements could be equivalent. If so, why? EDIT: What I showed in my notes, and was agreed to be true in the comments is that: There is a one-one correspondence between morphisms $X \to Y$ and ring homomorphisms $\mathcal{O}_Y \to \mathcal{O}_X$ . ( FALSE ) There is a one-one correspondence between morphisms $X \to Y$ and $k$ -algebra homomorphisms $\mathcal{O}_Y \to \mathcal{O}_X$ . ( TRUE )","Consider the following claim: Let and be algebraic sets and suppose that we have a ring isomorphism . Show that the algebraic sets and are isomorphic. Now, I know that if is an isomorphism of -algebras, then and are isomorphic. And I know that any isomorphism of -algebras is also an isomorphism of the underlying rings. Question: However, isn't it the case that not every ring homomorphism is a -algebra homomorphism , and that only -algebra homomorphisms correspond to morphisms , not arbitrary ring homomorphsims ? In other words, which of the following two statements are correct? Are they even mutually exclusive? Or are they equivalent? If they are equivalent, why? Two algebraic sets are isomorphic if and only if their coordinate rings are isomorphic as rings. OR Two algebraic sets are isomorphic if and only if their coordinate rings are isomorphic as -algebras. Context: My book , in sections 4.18 and 4.19, as well as this question on Math.SE implies that the first statement is true. However, section 4.8 of the same book , and every other source I have found (e.g. here or here ), implies only that the second statement is true. Moreover, I was only able to prove the second statement, not the first. Which is correct? This is a follow-up to my previous question , an attempt to show that the two statements are mutually exclusive and not equivalent. It was unanswered though, so I don't know if my attempt was successful -- for all I know, the two statements could be equivalent. If so, why? EDIT: What I showed in my notes, and was agreed to be true in the comments is that: There is a one-one correspondence between morphisms and ring homomorphisms . ( FALSE ) There is a one-one correspondence between morphisms and -algebra homomorphisms . ( TRUE )","X \subset k[x_1,\dots,x_n] Y\subset k[y_1,\dots,y_m] \varphi: \mathcal{O}_Y \to \mathcal{O}_X X Y \varphi k X Y k \varphi: \mathcal{O}_Y \to \mathcal{O}_X k \mathcal{O}_Y \to \mathcal{O}_X k  \mathcal{O}_Y \to \mathcal{O}_X X \to Y \mathcal{O}_Y \to \mathcal{O}_X k X \to Y \mathcal{O}_Y \to \mathcal{O}_X X \to Y k \mathcal{O}_Y \to \mathcal{O}_X","['abstract-algebra', 'algebraic-geometry', 'reference-request', 'ring-theory', 'commutative-algebra']"
52,Equivalent characterizations of discrete valuation rings,Equivalent characterizations of discrete valuation rings,,"Let $R$ be a commutative ring with identiy, then the following are equivalent: $R$ is a DVR $R$ is a local Euclidean domain that is not a field. $R$ is a local PID that is not a field. $R$ is a local Dedekind domain that is not a field. $R$ is a UFD with a unique irreducible element up to a unit. There is a non-nilpotent non-unit element $\pi \in R$ such that every $a \in R \setminus\{0\}$ has a unique expression $a = u \pi^n$ , where $u \in R^\times$ and $n\in \mathbb{N}$ . $R$ is a Noetherian valuation ring and not a field. $R$ is a Noetherian local ring with a principal maximal ideal generated by a non-nilpotent element. $R$ is a regular local Noetherian ring of dimension $1$ . $R$ is a local Noetherian domain that is not a field such that every non-zero ideal is a power of the maximal ideal. Here is what I tried so far: $(1.) \Rightarrow (2.)$ Every valuation ring is local . Suppose $v$ is a discrete valuation on the fraction field of $R$ such that $v^{-1}(\mathbb{N}) \cup \{0\} = R$ . We claim that $v$ is actually also a Euclidean function for $R$ . Let $x,y \in R$ , $y \neq 0$ , if $\frac{x}{y} \in R$ , we have $x = y \frac{x}{y} + 0$ , so we are done. If $\frac{x}{y} \notin R$ , then $0 > v(\frac{x}{y}) = v(x)- v(y)$ , so $v(y) > v(x)$ . Now we have $v(x) = v(y + (x - y)) \geq \min(v(y), v(x - y))$ , but as $v(y) > v(x)$ , it must be the case that $v(x) \geq v(x-y)$ . Now we write $x = 1\cdot y + (x - y)$ and $v(y) > v(x) \geq v(x-y)$ . $(2.) \Rightarrow (3.)$ Every Euclidean domain is a PID . $(3.) \Rightarrow (4.)$ Every PID is a Dedekind domain . $(3.) \Rightarrow (5)$ Every PID is a UFD and every irreducible element generates a maximal ideal in a PID and every maximao ideal is generated by an irreducible element (As $R$ is not a field, the maximal ideals are non-zero). As all these maximal ideals must coincide, there is exactly one irreducible element up to a unit. $(5.) \Rightarrow (6.)$ A domain does not contain nontrivial nilpotents. So we can take $\pi$ to be the unique irreducible element. $(1.) \land (3.) \Rightarrow (7.)$ Every PID is Noetherian . $(7.) \Rightarrow (3.)$ Every valuation ring is a local Bezout domain. Noetherian Bezout domains are PIDs. $(4.) \Rightarrow (10.)$ Let $R$ be a local Dedekind domain that is not a field. Then $R$ is one-dimensional, so every nonzero prime ideal is maximal, but there is only one maximal ideal as $R$ is local, so there is only one non-zero prime ideal. As $R$ is Dedekind, every non-zero ideal is a product of prime ideals, thus every non-zero ideal is a power of the maximal ideal. $(8.) \Rightarrow (9.)$ Let the maximal ideal $m$ be generated by $x$ , then the image of $x$ generates $m/m^2$ . If $m/m^2 = 0$ , $m = m^2$ , but then $m  = 0$ by Nakayama's lemma , so $m/m^2 \neq 0$ , thus $\operatorname{dim}_{R/m}m/m^2 = 1$ . It follows from Krull's principal ideal theorem that $\operatorname{dim}R= 1$ . $(9.) \Rightarrow (8.)$ Let $m$ be the maximal ideal and $\bar{x}$ be a generator of $m/m^2$ and let $x$ be a preimage of $\bar{x}$ under the natural quotient map. We then have $m = m^2 + (x)$ , so $m = (x)$ by a corollary to Nakayama's lemma. Now we need to show that $x$ is not nilpotent. As $\operatorname{dim}R = 1$ , $m$ properly contains a minimal prime ideal $p$ . If $x$ was nilpotent, then $x \in p$ , but this implies $m \subset p$ , which is impossible. $(10.) \Rightarrow (8.)$ Let $m$ be the maximal ideal. Note that we cannot have $m^2 = m$ or else $m = 0$ by Nakayama's lemma, but $R$ is not a field. Choose $x \in m \setminus m^2$ , then $(x)$ is a power of $m$ , but by our choice of $x$ the only possibility is that $m = (x)$ . As $R$ is a domain, $(x)$ is not nilpotent. $(8.) \Rightarrow (6.)$ Let $m = (\pi)$ be the maximal ideal. We first show that every nonzero $x_0 \in R$ has an expression of the required form. First, if $x_0$ is a unit, then we are done. If $x_0$ is not a unit, then $x_0 \in m$ , so $x_0 = x_1 \cdot \pi$ . Then, do the same for $x_1$ . If $x_1$ is a unit, then we are done, if $x_1$ is not a unit $x_1 \in m$ , so we can write $x_1 = x_2 \cdot \pi$ etc. To see that this process must terminate, we note that if it doesn't, we have $x \in m^n$ for all $n\in \mathbb{N}$ which contradicts Krull's intersection theorem . Now that every nonzero element is of the form $u\pi^n$ we have to show uniqueness. If we take two non-zero elements write them as $u_{1}\pi^n$ and $u_{2}\pi^k$ , then their product $u_{1}u_{2}\pi^{n+k}$ is non-zero, as $\pi$ is not nilpotent. This shows that $R$ is an integral domain, thus the multiplicative monoid is cancellative, from this, the uniqueness follows easily, if we have $u_1 \pi^n = u_2 \pi^k$ Assume wlog that $n \geq k$ , then we have $u_1 = u_2 \pi^{n-k}$ . Now if $n > k$ , the LHS is a unit while the RHS is not, which is absurd. Thus $n = k$ and $u_1 = u_2$ . $(6.) \Rightarrow (1.)$ $R$ is an integral domain by the same argument as in $(8.) \Rightarrow(6.)$ Now define a valuation on $R$ via $v(u\pi^n)=n$ We have $v(u_1\pi^n\cdot u_2 \pi^k) = n+k = v(u_1\pi^n)+v(u_2\pi^k)$ Assume wlog that $k \leq n$ , then $v(u_1\pi^k+u_2\pi^n)=v( (u_1+u_2\pi^{n-k})\pi^k) \geq k = \min(v(u_1\pi^k),v(u_2\pi^n))$ . Extend $v$ to the fraction field of $R$ by setting $v(\frac{a}{b})=v(a)-v(b)$ , then it is obvious that $R$ is the valuation ring of $v$ . My question is, is this all correct? Do you know any other characterization of DVRs? If so, why is it equivalent? For example, wikipedia has the following $R$ is a (edit: Noetherian) domain that is not a field, and every nonzero fractional ideal of $R$ is irreducible in the sense that it cannot be written as finite intersection of fractional ideals properly containing it. But I have no idea how to show that it is equivalent.","Let be a commutative ring with identiy, then the following are equivalent: is a DVR is a local Euclidean domain that is not a field. is a local PID that is not a field. is a local Dedekind domain that is not a field. is a UFD with a unique irreducible element up to a unit. There is a non-nilpotent non-unit element such that every has a unique expression , where and . is a Noetherian valuation ring and not a field. is a Noetherian local ring with a principal maximal ideal generated by a non-nilpotent element. is a regular local Noetherian ring of dimension . is a local Noetherian domain that is not a field such that every non-zero ideal is a power of the maximal ideal. Here is what I tried so far: Every valuation ring is local . Suppose is a discrete valuation on the fraction field of such that . We claim that is actually also a Euclidean function for . Let , , if , we have , so we are done. If , then , so . Now we have , but as , it must be the case that . Now we write and . Every Euclidean domain is a PID . Every PID is a Dedekind domain . Every PID is a UFD and every irreducible element generates a maximal ideal in a PID and every maximao ideal is generated by an irreducible element (As is not a field, the maximal ideals are non-zero). As all these maximal ideals must coincide, there is exactly one irreducible element up to a unit. A domain does not contain nontrivial nilpotents. So we can take to be the unique irreducible element. Every PID is Noetherian . Every valuation ring is a local Bezout domain. Noetherian Bezout domains are PIDs. Let be a local Dedekind domain that is not a field. Then is one-dimensional, so every nonzero prime ideal is maximal, but there is only one maximal ideal as is local, so there is only one non-zero prime ideal. As is Dedekind, every non-zero ideal is a product of prime ideals, thus every non-zero ideal is a power of the maximal ideal. Let the maximal ideal be generated by , then the image of generates . If , , but then by Nakayama's lemma , so , thus . It follows from Krull's principal ideal theorem that . Let be the maximal ideal and be a generator of and let be a preimage of under the natural quotient map. We then have , so by a corollary to Nakayama's lemma. Now we need to show that is not nilpotent. As , properly contains a minimal prime ideal . If was nilpotent, then , but this implies , which is impossible. Let be the maximal ideal. Note that we cannot have or else by Nakayama's lemma, but is not a field. Choose , then is a power of , but by our choice of the only possibility is that . As is a domain, is not nilpotent. Let be the maximal ideal. We first show that every nonzero has an expression of the required form. First, if is a unit, then we are done. If is not a unit, then , so . Then, do the same for . If is a unit, then we are done, if is not a unit , so we can write etc. To see that this process must terminate, we note that if it doesn't, we have for all which contradicts Krull's intersection theorem . Now that every nonzero element is of the form we have to show uniqueness. If we take two non-zero elements write them as and , then their product is non-zero, as is not nilpotent. This shows that is an integral domain, thus the multiplicative monoid is cancellative, from this, the uniqueness follows easily, if we have Assume wlog that , then we have . Now if , the LHS is a unit while the RHS is not, which is absurd. Thus and . is an integral domain by the same argument as in Now define a valuation on via We have Assume wlog that , then . Extend to the fraction field of by setting , then it is obvious that is the valuation ring of . My question is, is this all correct? Do you know any other characterization of DVRs? If so, why is it equivalent? For example, wikipedia has the following is a (edit: Noetherian) domain that is not a field, and every nonzero fractional ideal of is irreducible in the sense that it cannot be written as finite intersection of fractional ideals properly containing it. But I have no idea how to show that it is equivalent.","R R R R R R \pi \in R a \in R \setminus\{0\} a = u \pi^n u \in R^\times n\in \mathbb{N} R R R 1 R (1.) \Rightarrow (2.) v R v^{-1}(\mathbb{N}) \cup \{0\} = R v R x,y \in R y \neq 0 \frac{x}{y} \in R x = y \frac{x}{y} + 0 \frac{x}{y} \notin R 0 > v(\frac{x}{y}) = v(x)- v(y) v(y) > v(x) v(x) = v(y + (x - y)) \geq \min(v(y), v(x - y)) v(y) > v(x) v(x) \geq v(x-y) x = 1\cdot y + (x - y) v(y) > v(x) \geq v(x-y) (2.) \Rightarrow (3.) (3.) \Rightarrow (4.) (3.) \Rightarrow (5) R (5.) \Rightarrow (6.) \pi (1.) \land (3.) \Rightarrow (7.) (7.) \Rightarrow (3.) (4.) \Rightarrow (10.) R R R R (8.) \Rightarrow (9.) m x x m/m^2 m/m^2 = 0 m = m^2 m 
= 0 m/m^2 \neq 0 \operatorname{dim}_{R/m}m/m^2 = 1 \operatorname{dim}R= 1 (9.) \Rightarrow (8.) m \bar{x} m/m^2 x \bar{x} m = m^2 + (x) m = (x) x \operatorname{dim}R = 1 m p x x \in p m \subset p (10.) \Rightarrow (8.) m m^2 = m m = 0 R x \in m \setminus m^2 (x) m x m = (x) R (x) (8.) \Rightarrow (6.) m = (\pi) x_0 \in R x_0 x_0 x_0 \in m x_0 = x_1 \cdot \pi x_1 x_1 x_1 x_1 \in m x_1 = x_2 \cdot \pi x \in m^n n\in \mathbb{N} u\pi^n u_{1}\pi^n u_{2}\pi^k u_{1}u_{2}\pi^{n+k} \pi R u_1 \pi^n = u_2 \pi^k n \geq k u_1 = u_2 \pi^{n-k} n > k n = k u_1 = u_2 (6.) \Rightarrow (1.) R (8.) \Rightarrow(6.) R v(u\pi^n)=n v(u_1\pi^n\cdot u_2 \pi^k) = n+k = v(u_1\pi^n)+v(u_2\pi^k) k \leq n v(u_1\pi^k+u_2\pi^n)=v( (u_1+u_2\pi^{n-k})\pi^k) \geq k = \min(v(u_1\pi^k),v(u_2\pi^n)) v R v(\frac{a}{b})=v(a)-v(b) R v R R","['abstract-algebra', 'ring-theory', 'solution-verification', 'commutative-algebra', 'valuation-theory']"
53,Unramified primes of splitting field,Unramified primes of splitting field,,"I would like to show the following: Theorem : Let $K$ be a number field and and $L$ be the splitting field of a polynomial $f$ over $K$. If $f$ is separable modulo a prime $\lambda$ of $K$, then $L$ is unramified above $\lambda$. This should follow from the following theorem: Theorem : Let $L / K$ be a finite extension of number fields, and $B$ resp. $A$ the ring of integers of $L$ resp. $K$. Let $\mathfrak{p}$ be a prime of $K$ and $p$ the prime number lying under $\mathfrak{p}$. Let $\alpha \in B$. Let $f$ be the minimal polynomial of $\alpha$ over $K$, and let $\overline{f} = \overline{g_1}^{e_1} \cdots \overline{g_r}^{e_r}$ be the distinct irreducible factors of $f$ modulo $\mathfrak{p}$. If $p$ does not divide the order of $B / A[\alpha]$, then $\mathfrak{p}B = \mathfrak{P}_1^{e_1} \cdots \mathfrak{P_r}^{e_r}$. How can I do this? Thanks a lot!","I would like to show the following: Theorem : Let $K$ be a number field and and $L$ be the splitting field of a polynomial $f$ over $K$. If $f$ is separable modulo a prime $\lambda$ of $K$, then $L$ is unramified above $\lambda$. This should follow from the following theorem: Theorem : Let $L / K$ be a finite extension of number fields, and $B$ resp. $A$ the ring of integers of $L$ resp. $K$. Let $\mathfrak{p}$ be a prime of $K$ and $p$ the prime number lying under $\mathfrak{p}$. Let $\alpha \in B$. Let $f$ be the minimal polynomial of $\alpha$ over $K$, and let $\overline{f} = \overline{g_1}^{e_1} \cdots \overline{g_r}^{e_r}$ be the distinct irreducible factors of $f$ modulo $\mathfrak{p}$. If $p$ does not divide the order of $B / A[\alpha]$, then $\mathfrak{p}B = \mathfrak{P}_1^{e_1} \cdots \mathfrak{P_r}^{e_r}$. How can I do this? Thanks a lot!",,"['abstract-algebra', 'polynomials', 'commutative-algebra', 'field-theory', 'algebraic-number-theory']"
54,Cosemisimple Hopf algebra and Krull-Schmidt,Cosemisimple Hopf algebra and Krull-Schmidt,,"A cosemisimple Hopf algebra is one which is the sum of its cosimple sub-cobalgebras. Is it clear that a comodule of a cosemisimple Hopf algebra always decomposes into irreducible parts? Moreover, will this decomposition obey Krull-Schmidt , by which I mean will the type and multiplicity of the irreducible comodules appearing be the same in any decomposition. I am sure that this should be the case but I can't see how to prove it. One thing that confuses me is the prospect of infinite multiplicity in the case of an infinite dimensional comodule.","A cosemisimple Hopf algebra is one which is the sum of its cosimple sub-cobalgebras. Is it clear that a comodule of a cosemisimple Hopf algebra always decomposes into irreducible parts? Moreover, will this decomposition obey Krull-Schmidt , by which I mean will the type and multiplicity of the irreducible comodules appearing be the same in any decomposition. I am sure that this should be the case but I can't see how to prove it. One thing that confuses me is the prospect of infinite multiplicity in the case of an infinite dimensional comodule.",,"['abstract-algebra', 'hopf-algebras', 'quantum-groups', 'coalgebras']"
55,On finite commutative rings with the number of ideals equal to the number of elements of the ring,On finite commutative rings with the number of ideals equal to the number of elements of the ring,,Let $R$ be a finite commutative ring with identity. Under what conditions the number of ideals of $R$ is equal to the number of elements of $R$? The only class of rings with this property that I know is the class of finite boolean rings. I do not know if the converse is true. So any suggestion would be helpful.,Let $R$ be a finite commutative ring with identity. Under what conditions the number of ideals of $R$ is equal to the number of elements of $R$? The only class of rings with this property that I know is the class of finite boolean rings. I do not know if the converse is true. So any suggestion would be helpful.,,"['abstract-algebra', 'ring-theory']"
56,"What does it mean ""unique"" for this author?","What does it mean ""unique"" for this author?",,"I'm studying Hungerford's Abstract Algebra book. I would like to know what the author means by ""unique"" in this theorem: The orders count? I mean the element $g\in G$ such that $g=a_{i_1}a_{i_2}=a_{i_2}a_{i_1}$ is considered unique? I'm asking that because we know that if $G$ is an internal weak direct product of the family $\{N_i\mid i\in I\}$, we have $a_{i_k}a_{i_l}=a_{i_l}a_{i_k}$ for every $a_{i_k}\in N_{i_k}$ and $a_{i_l}\in N_{i_l}$. Thanks in advance","I'm studying Hungerford's Abstract Algebra book. I would like to know what the author means by ""unique"" in this theorem: The orders count? I mean the element $g\in G$ such that $g=a_{i_1}a_{i_2}=a_{i_2}a_{i_1}$ is considered unique? I'm asking that because we know that if $G$ is an internal weak direct product of the family $\{N_i\mid i\in I\}$, we have $a_{i_k}a_{i_l}=a_{i_l}a_{i_k}$ for every $a_{i_k}\in N_{i_k}$ and $a_{i_l}\in N_{i_l}$. Thanks in advance",,['abstract-algebra']
57,Proof of Conjugate Subgroup Isomorphism,Proof of Conjugate Subgroup Isomorphism,,"Let $G$ be a group, and let $H$ be a subgroup of $G$. Prove that if $a$ is an element of $G$, then the subset $aHa^{-1} = \{g ∈ G | g = aha^{-1} \text{ for some } h \in H\}$ is a subgroup of $G$ that is isomorphic to $H$. Proof: Let $G$ be a group and $H$ is a subgroup of $G$. Suppose $a$ is any element of $G$. Now $ϕ: H \rightarrow aHa^{-1}$ be defined by $ϕ(h) = aha^{-1}.$  So $$ϕ(h_1 h_2) = ah_1h_2a^{-1} = ah_1a^{-1} ah_2a^{-1} = ϕ(h_1) ϕ(h_2)  $$ Thus, ϕ is a homomorphism. (one-to-one) Now $$\begin{eqnarray*}h \in \operatorname{ker}(ϕ) &\text{if and only if}&ϕ(h) = 0\\ &\text{if and only if}&aha^{-1} = 0\\ &\text{if and only if}&h = 0\\ \end{eqnarray*} $$ Hence, $\operatorname{ker}(ϕ) = \{0\}$. Thus $ϕ$ is one-to-one. (onto) Let $y \in aHa^{-1}$. Then $y = aha^{-1}$ for some $h \in H$.  As $h \in H$, $ϕ(h) = aha^{-1} = y$.  Thus $ϕ$ is onto. Hence, $ϕ$ is an isomorphism. How do I show that $aHa^{-1}$ is a subgroup of $G$?","Let $G$ be a group, and let $H$ be a subgroup of $G$. Prove that if $a$ is an element of $G$, then the subset $aHa^{-1} = \{g ∈ G | g = aha^{-1} \text{ for some } h \in H\}$ is a subgroup of $G$ that is isomorphic to $H$. Proof: Let $G$ be a group and $H$ is a subgroup of $G$. Suppose $a$ is any element of $G$. Now $ϕ: H \rightarrow aHa^{-1}$ be defined by $ϕ(h) = aha^{-1}.$  So $$ϕ(h_1 h_2) = ah_1h_2a^{-1} = ah_1a^{-1} ah_2a^{-1} = ϕ(h_1) ϕ(h_2)  $$ Thus, ϕ is a homomorphism. (one-to-one) Now $$\begin{eqnarray*}h \in \operatorname{ker}(ϕ) &\text{if and only if}&ϕ(h) = 0\\ &\text{if and only if}&aha^{-1} = 0\\ &\text{if and only if}&h = 0\\ \end{eqnarray*} $$ Hence, $\operatorname{ker}(ϕ) = \{0\}$. Thus $ϕ$ is one-to-one. (onto) Let $y \in aHa^{-1}$. Then $y = aha^{-1}$ for some $h \in H$.  As $h \in H$, $ϕ(h) = aha^{-1} = y$.  Thus $ϕ$ is onto. Hence, $ϕ$ is an isomorphism. How do I show that $aHa^{-1}$ is a subgroup of $G$?",,"['abstract-algebra', 'group-theory', 'proof-verification']"
58,Show that $(\mathbb{Z}[x]/(x^{n+1}))^{\times}\cong \mathbb{Z}/2\mathbb{Z}\times\Pi_{i=1}^n\mathbb{Z}$,Show that,(\mathbb{Z}[x]/(x^{n+1}))^{\times}\cong \mathbb{Z}/2\mathbb{Z}\times\Pi_{i=1}^n\mathbb{Z},Show that $(\mathbb{Z}[x]/(x^{n+1}))^{\times}\cong \mathbb{Z}/2\mathbb{Z}\times\Pi_{i=1}^n\mathbb{Z}$. Anyway how and what method is used to prove this. I still have no idea now. really thanks for your help,Show that $(\mathbb{Z}[x]/(x^{n+1}))^{\times}\cong \mathbb{Z}/2\mathbb{Z}\times\Pi_{i=1}^n\mathbb{Z}$. Anyway how and what method is used to prove this. I still have no idea now. really thanks for your help,,"['abstract-algebra', 'ring-theory']"
59,Understanding the three isomorphism theorems,Understanding the three isomorphism theorems,,"I have learnt the following three isomorphisms for a while but without true understanding: A group homomorphism $\phi:G\to G'$ can be decomposed into \begin{equation}G\xrightarrow{\text{quotient}}G/\operatorname{ker}(\phi)\simeq \operatorname{Im}(\phi)\hookrightarrow G'. \end{equation} and $H$ is a normal subgroup of $G$ and $K$ is another subgroup. Then $H\cap K$ is normal in $K$, $HK$ is a subgroup inside which $H$ is normal, and \begin{equation}\frac{K}{H\cap K}\simeq \frac{HK}{H}. \end{equation} and $H$ is a subgroup $G$ and $K\supset H$ is another subgroup. Then $K/H$ is normal in $G/H$ if and only if $K$ is normal in $G$. If $K$ is normal then \begin{equation}\frac{G}{K}\simeq \frac{G/H}{K/H}. \end{equation} The proofs for these three theorems are rather straightforward, and after teaching myself some category theory I am more comfortable with the first one. But I do not feel them. (Like in this post by Gowers he explains Orbit-Stablizer by moving a cube and with this picture you get the feeling that such a theorem has to be right.) I wonder whether someone can share similar insights on the three isomorphisms maybe by using intuitive-but-nontrivial examples like Gowers. Thanks!","I have learnt the following three isomorphisms for a while but without true understanding: A group homomorphism $\phi:G\to G'$ can be decomposed into \begin{equation}G\xrightarrow{\text{quotient}}G/\operatorname{ker}(\phi)\simeq \operatorname{Im}(\phi)\hookrightarrow G'. \end{equation} and $H$ is a normal subgroup of $G$ and $K$ is another subgroup. Then $H\cap K$ is normal in $K$, $HK$ is a subgroup inside which $H$ is normal, and \begin{equation}\frac{K}{H\cap K}\simeq \frac{HK}{H}. \end{equation} and $H$ is a subgroup $G$ and $K\supset H$ is another subgroup. Then $K/H$ is normal in $G/H$ if and only if $K$ is normal in $G$. If $K$ is normal then \begin{equation}\frac{G}{K}\simeq \frac{G/H}{K/H}. \end{equation} The proofs for these three theorems are rather straightforward, and after teaching myself some category theory I am more comfortable with the first one. But I do not feel them. (Like in this post by Gowers he explains Orbit-Stablizer by moving a cube and with this picture you get the feeling that such a theorem has to be right.) I wonder whether someone can share similar insights on the three isomorphisms maybe by using intuitive-but-nontrivial examples like Gowers. Thanks!",,"['abstract-algebra', 'group-theory', 'category-theory', 'intuition']"
60,Spinors in Spin Geometry,Spinors in Spin Geometry,,"First of all I am a physicist with a decent knowledge of graduate-level geometry. I'm studying Spin Geometry from Bär Lecture Notes and I have some trouble understanding what spinors are from his definition. I'll recap some information here to avoid the needing of reading the lecture notes. Given a vector space $V$ and a symmetric bilinear form $\beta$ we build the Clifford algebra $Cl(V,\beta)$ with Clifford product $\cdot_C$ Given an algebra homomorphism $\phi: Cl(V,\beta) \rightarrow Cl(V,\beta)$ This splits the algebra as: $Cl(V,\beta) = Cl^0(V,\beta) \oplus Cl^1(V,\beta)$ With $Cl^0(V,\beta)$ the +1 eigenspace of $\phi$ and $Cl^1(V,\beta)$ the -1 eigenspace of $\phi$ Now i will choose $V = \mathbb{R}^n$ because it's the most straight forward vector space to work with. Then he defines the Pin and Spin groups as: $$Pin(n) = \{v_1 \cdot_C ... \cdot_C \; v_m \in Cl(\mathbb{R}^n) | v_i \in S^{n-1} \; , \; m\in \mathbb{N}_0 \}$$ And $$Spin(n) = Pin(n)\cap Cl^0(\mathbb{R}^n,\beta) $$ So to my understanding, $Pin(n)$ is the group built multiplying a number $m$ of unitary elements of $\mathbb{R}^n$ while $Spin(n)$ is built only with an even amount of multiplications. For $n=2m$ he defines 2 quantities: $$z_j = (e_{2j-1}-ie_{2j})/2 $$ $$\bar{z}_j = (e_{2j-1}+ie_{2j})/2 $$ To me this seems the basis, split into right-handed and left-handed, for the complexified version of $\mathbb{R}^n$ but I'm not sure if it is the case. Now the questions. Question 1 He defines: $$z(j_1, ..., j_k) = z_{j_1} \cdot_C \; ... \cdot_C\; z_{j_k} \cdot_C\; \bar{z}_1 \cdot_C\;...\cdot_C\;\bar{z}_m$$ What does this quantity represent? What is it? An explanation in geometrical terms would be awesome Question 2 He defines: $$\Sigma_n^\pm = span\{z(j_1, ..., j_k) | k=0, ..., m \; j_i \; ordered\}$$ With $+$ for even $m$ and $-$ for odd $m$ He calls elements of such a space spinors, left and right-handed. How do these elements relate to the ""complex vector-type"" of spinors usually encountered in physics and to the $Spin(n)$ group above? Those should be the mathematical counterpart of the physics Weyl spinors, but I can't see how it is possible to recover them.","First of all I am a physicist with a decent knowledge of graduate-level geometry. I'm studying Spin Geometry from Bär Lecture Notes and I have some trouble understanding what spinors are from his definition. I'll recap some information here to avoid the needing of reading the lecture notes. Given a vector space and a symmetric bilinear form we build the Clifford algebra with Clifford product Given an algebra homomorphism This splits the algebra as: With the +1 eigenspace of and the -1 eigenspace of Now i will choose because it's the most straight forward vector space to work with. Then he defines the Pin and Spin groups as: And So to my understanding, is the group built multiplying a number of unitary elements of while is built only with an even amount of multiplications. For he defines 2 quantities: To me this seems the basis, split into right-handed and left-handed, for the complexified version of but I'm not sure if it is the case. Now the questions. Question 1 He defines: What does this quantity represent? What is it? An explanation in geometrical terms would be awesome Question 2 He defines: With for even and for odd He calls elements of such a space spinors, left and right-handed. How do these elements relate to the ""complex vector-type"" of spinors usually encountered in physics and to the group above? Those should be the mathematical counterpart of the physics Weyl spinors, but I can't see how it is possible to recover them.","V \beta Cl(V,\beta) \cdot_C \phi: Cl(V,\beta) \rightarrow Cl(V,\beta) Cl(V,\beta) = Cl^0(V,\beta) \oplus Cl^1(V,\beta) Cl^0(V,\beta) \phi Cl^1(V,\beta) \phi V = \mathbb{R}^n Pin(n) = \{v_1 \cdot_C ... \cdot_C \; v_m \in Cl(\mathbb{R}^n) | v_i \in S^{n-1} \; , \; m\in \mathbb{N}_0 \} Spin(n) = Pin(n)\cap Cl^0(\mathbb{R}^n,\beta)  Pin(n) m \mathbb{R}^n Spin(n) n=2m z_j = (e_{2j-1}-ie_{2j})/2  \bar{z}_j = (e_{2j-1}+ie_{2j})/2  \mathbb{R}^n z(j_1, ..., j_k) = z_{j_1} \cdot_C \; ... \cdot_C\; z_{j_k} \cdot_C\; \bar{z}_1 \cdot_C\;...\cdot_C\;\bar{z}_m \Sigma_n^\pm = span\{z(j_1, ..., j_k) | k=0, ..., m \; j_i \; ordered\} + m - m Spin(n)","['abstract-algebra', 'mathematical-physics', 'clifford-algebras', 'spin-geometry']"
61,Finite rings $R$ in which $x^{25}=x$ holds,Finite rings  in which  holds,R x^{25}=x,"I want to classify finite rings $R$ in which $x^{25}=x$ for all $x\in R$ . I know Jacobson's Theorem that if $x^n=x$ for all $x\in$ then $R$ is commutative. I don't know how to show the Theorem for the special case $n=25$ by elementary methods. Furthermore, after showing that $R$ is commutative, is there any Theorem similar to Wedderburn's Theorem to conclude that $R$ is a field?","I want to classify finite rings in which for all . I know Jacobson's Theorem that if for all then is commutative. I don't know how to show the Theorem for the special case by elementary methods. Furthermore, after showing that is commutative, is there any Theorem similar to Wedderburn's Theorem to conclude that is a field?",R x^{25}=x x\in R x^n=x x\in R n=25 R R,"['abstract-algebra', 'ring-theory', 'field-theory', 'noncommutative-algebra']"
62,"For general $n \in \Bbb N$ , how to determine all groups (both finite and infinite) having exactly $n$ conjugacy classes?","For general  , how to determine all groups (both finite and infinite) having exactly  conjugacy classes?",n \in \Bbb N n,"I was trying to solve the following problem : Determine all the finite groups having exactly 3 conjugacy classes. My attempt: Among all abelian groups $(\Bbb Z_3,+)$ only satisfies the property , because all other abelian groups of order $n$ , ($n \neq 3$) are having $n$ elements in the center of the group and hence there are exactly $n$ conjugacy classes. In case of non-abelian groups, if we look at the permutation groups it is again clear that $S_3$ is the only permuatation group having the property because collection of conjugacy classes in permutation groups have one-to-one correspondence with the collection of distinct cycle types. And in case of Dihedral groups it clearly follows that $D_3$ has the above property and in fact $D_3 \cong S_3$ . The Quarternion group also does not have the property. So my precise questions are : $(i)$ Now by considering semi-direct products of these non-abelian groups can the argument be extended? $(ii)$ Apart from the Permutation groups, about all other non-abelian groups my attempts are mere observations, so how to give a rigorous argument. I would like to mention that I've gone through this question . It deals with infinte periodic group , but my question is for all infinite groups : $(iii)$ Is there any infinite group having exactly 3 conjugacy classes . I have also seen this question and this one as well. They only discussed about finite groups and I was not quite clear with the answers over there. Hence, trying to generalize the problem : $(iv)$ For general $n \in \Bbb N$ , how to determine all groups (both finite and infinite) having exactly $n$ conjugacy classes ? And about the last question I only can state echoing the arguments for $n=3$ , there is exactly one finite abelian group having the property. Thanks in advance for help.","I was trying to solve the following problem : Determine all the finite groups having exactly 3 conjugacy classes. My attempt: Among all abelian groups $(\Bbb Z_3,+)$ only satisfies the property , because all other abelian groups of order $n$ , ($n \neq 3$) are having $n$ elements in the center of the group and hence there are exactly $n$ conjugacy classes. In case of non-abelian groups, if we look at the permutation groups it is again clear that $S_3$ is the only permuatation group having the property because collection of conjugacy classes in permutation groups have one-to-one correspondence with the collection of distinct cycle types. And in case of Dihedral groups it clearly follows that $D_3$ has the above property and in fact $D_3 \cong S_3$ . The Quarternion group also does not have the property. So my precise questions are : $(i)$ Now by considering semi-direct products of these non-abelian groups can the argument be extended? $(ii)$ Apart from the Permutation groups, about all other non-abelian groups my attempts are mere observations, so how to give a rigorous argument. I would like to mention that I've gone through this question . It deals with infinte periodic group , but my question is for all infinite groups : $(iii)$ Is there any infinite group having exactly 3 conjugacy classes . I have also seen this question and this one as well. They only discussed about finite groups and I was not quite clear with the answers over there. Hence, trying to generalize the problem : $(iv)$ For general $n \in \Bbb N$ , how to determine all groups (both finite and infinite) having exactly $n$ conjugacy classes ? And about the last question I only can state echoing the arguments for $n=3$ , there is exactly one finite abelian group having the property. Thanks in advance for help.",,['abstract-algebra']
63,Thinking about the group algebra $k[G]$ as functions on $G$,Thinking about the group algebra  as functions on,k[G] G,"Given a group $G$ and field $k$ one can define the group algebra $k[G]$ in two ways: The underlying vector space of $k[G]$ is the free $k$-vector space on $G$, and the multiplication on $k[G]$ is the unique bilinear extension $k[G] \times k[G] \to k[G]$ of the group multiplication $G \times G \to G$. The elements of $k[G]$ are the functions $f \colon G \to k$ with finite support and the vector space operations are defined pointwise. The multiplication is given by the convolution product $$      (f_1 f_2)(g)   := \sum_{h \in G} f_1(h) f_2(h^{-1} g)   \qquad   \text{for all $g \in G$}. $$ Since I first encountered the second definition I have always found it somewhat inferior to the first one. I assumed that it exists only to define $k[G]$ without requiring the notion of a free vector space, made possible by hiding the free vector space on a set $X$ behinds its technical construction as functions $X \to k$ with finite support. But by now I have seen the second definition often enough to begin wondering if there is some benefit to taking it more seriously. While thinking about this, I began to wonder if there is some deeper connection between the two definition than I have given it credit for. Question: What do we gain from thinking about the group algebra $k[G]$ as an algebra of functions on $G$, and how does this view point relate to the other definition? (I realize that it could turn out be more appropriate to ask two separate questions instead. But I’m currently not sure how related the two are, and thus refrained from doing so.) So far my thoughts on this have been the following: According to the first definition, $G$ is a basis of $k[G]$. Functions $G \to k$ are then “the same” as elements of $k[G]^*$; the functions of finite support correspond to the image of the basis-dependent embedding $k[G] \hookrightarrow k[G]^*$, $g \mapsto \delta_g$. This seems to suggest some kind of duality between the two definitions, coming from the usual duality pairing of $k[G]$ and $k[G]^*$. (I know that for finite $G$ the Hopf algebra $k[G]$ is dual to the Hopf algebra of functions $G \to k$. But I don’t know if this is of use here.) If $k[G]$ consists of functions on $G$, then I would strongly expect it to be contravariant in $G$. That this is not the case seem to be thanks to the convolution product. But I don’t really understand where the convolution product comes from when one doesn’t already have the first definition in mind. The requirement of finite support is needed to assure that the sum $\sum_{h \in G} f_1(h) f_2(h^{-1} g)$ is well-defined even for infinite groups. It should be possible to lift this restriction if we have some notion of convergence for this sum. While this seems to be a thing , I don’t know if this sheds any light on a possible deeper relation between the two definitions in the algebraic setting. Help is appreciated.","Given a group $G$ and field $k$ one can define the group algebra $k[G]$ in two ways: The underlying vector space of $k[G]$ is the free $k$-vector space on $G$, and the multiplication on $k[G]$ is the unique bilinear extension $k[G] \times k[G] \to k[G]$ of the group multiplication $G \times G \to G$. The elements of $k[G]$ are the functions $f \colon G \to k$ with finite support and the vector space operations are defined pointwise. The multiplication is given by the convolution product $$      (f_1 f_2)(g)   := \sum_{h \in G} f_1(h) f_2(h^{-1} g)   \qquad   \text{for all $g \in G$}. $$ Since I first encountered the second definition I have always found it somewhat inferior to the first one. I assumed that it exists only to define $k[G]$ without requiring the notion of a free vector space, made possible by hiding the free vector space on a set $X$ behinds its technical construction as functions $X \to k$ with finite support. But by now I have seen the second definition often enough to begin wondering if there is some benefit to taking it more seriously. While thinking about this, I began to wonder if there is some deeper connection between the two definition than I have given it credit for. Question: What do we gain from thinking about the group algebra $k[G]$ as an algebra of functions on $G$, and how does this view point relate to the other definition? (I realize that it could turn out be more appropriate to ask two separate questions instead. But I’m currently not sure how related the two are, and thus refrained from doing so.) So far my thoughts on this have been the following: According to the first definition, $G$ is a basis of $k[G]$. Functions $G \to k$ are then “the same” as elements of $k[G]^*$; the functions of finite support correspond to the image of the basis-dependent embedding $k[G] \hookrightarrow k[G]^*$, $g \mapsto \delta_g$. This seems to suggest some kind of duality between the two definitions, coming from the usual duality pairing of $k[G]$ and $k[G]^*$. (I know that for finite $G$ the Hopf algebra $k[G]$ is dual to the Hopf algebra of functions $G \to k$. But I don’t know if this is of use here.) If $k[G]$ consists of functions on $G$, then I would strongly expect it to be contravariant in $G$. That this is not the case seem to be thanks to the convolution product. But I don’t really understand where the convolution product comes from when one doesn’t already have the first definition in mind. The requirement of finite support is needed to assure that the sum $\sum_{h \in G} f_1(h) f_2(h^{-1} g)$ is well-defined even for infinite groups. It should be possible to lift this restriction if we have some notion of convergence for this sum. While this seems to be a thing , I don’t know if this sheds any light on a possible deeper relation between the two definitions in the algebraic setting. Help is appreciated.",,"['abstract-algebra', 'intuition', 'group-rings']"
64,"If $I^n = 0$ and $M$ is a simple module, then $IM = 0.$","If  and  is a simple module, then",I^n = 0 M IM = 0.,"Let $A$ be a ring with unity, and let $I$ be a two sided ideal of $A$ such that $I^n = 0.$ Let $M$ be a simple $A$-module. I want to show that $IM = 0.$ We know that $IM$ is a submodule of $M$. Suppose $IM = M.$ Then $I^2M = I(IM) = IM = M,$ and so $I^nM = M.$ But $I^nM = \{0\}M = 0,$ but $M$ cannot be $0$ as it is simple, hence nontrivial, a contradiction. So $IM = 0.$ This seems too simple to me (this question was on a past paper, and my solution seems much shorter than the number of marks), so I was wondering if it was correct. Particularly, I was wondering if $I^2M = I(IM)$ actually works? I can't see how it shouldn't work from the definitions, but I can never be too sure about products of ideals and modules.","Let $A$ be a ring with unity, and let $I$ be a two sided ideal of $A$ such that $I^n = 0.$ Let $M$ be a simple $A$-module. I want to show that $IM = 0.$ We know that $IM$ is a submodule of $M$. Suppose $IM = M.$ Then $I^2M = I(IM) = IM = M,$ and so $I^nM = M.$ But $I^nM = \{0\}M = 0,$ but $M$ cannot be $0$ as it is simple, hence nontrivial, a contradiction. So $IM = 0.$ This seems too simple to me (this question was on a past paper, and my solution seems much shorter than the number of marks), so I was wondering if it was correct. Particularly, I was wondering if $I^2M = I(IM)$ actually works? I can't see how it shouldn't work from the definitions, but I can never be too sure about products of ideals and modules.",,"['abstract-algebra', 'ring-theory', 'modules', 'noncommutative-algebra']"
65,"Kernel of $GL(n, \mathbb{Z}) \to GL(n, \mathbb{Z}_{m})$",Kernel of,"GL(n, \mathbb{Z}) \to GL(n, \mathbb{Z}_{m})","I need to describe the kernel of the canonical group homomorphism $GL(n, \mathbb{Z}) \to GL(n, \mathbb{Z}_{m})$. Generally speaking, the kernel would be the set of all matrices in $GL(n,\mathbb{Z})$ whose entries along the main diagonal modulo $m$ would equal 1, with all other entries modulo $m$ equaling zero. For example, in the case where $n = 2$, the kernel of this homomorphism would be the set of all $A = \begin{pmatrix} a_{11} & a_{12} \\ a_{21} & a_{22} \end{pmatrix}$ such that $\begin{pmatrix} a_{11} \mod m = 1 && a_{12} \mod m = 0 \\  a_{21} \mod m = 0 & &a_{22}\mod m = 1 \end{pmatrix}$. Is this all there is to this problem? Or is there something additional that I need to prove? It is an exercise in a section on Ideals and Isomorphism Theorems for Rings, so I thought it was kind of weird that I was able to come up with a solution to this problem that has nothing to do with ideals or ring isomorphisms. Therefore, I feel like I'm missing something...","I need to describe the kernel of the canonical group homomorphism $GL(n, \mathbb{Z}) \to GL(n, \mathbb{Z}_{m})$. Generally speaking, the kernel would be the set of all matrices in $GL(n,\mathbb{Z})$ whose entries along the main diagonal modulo $m$ would equal 1, with all other entries modulo $m$ equaling zero. For example, in the case where $n = 2$, the kernel of this homomorphism would be the set of all $A = \begin{pmatrix} a_{11} & a_{12} \\ a_{21} & a_{22} \end{pmatrix}$ such that $\begin{pmatrix} a_{11} \mod m = 1 && a_{12} \mod m = 0 \\  a_{21} \mod m = 0 & &a_{22}\mod m = 1 \end{pmatrix}$. Is this all there is to this problem? Or is there something additional that I need to prove? It is an exercise in a section on Ideals and Isomorphism Theorems for Rings, so I thought it was kind of weird that I was able to come up with a solution to this problem that has nothing to do with ideals or ring isomorphisms. Therefore, I feel like I'm missing something...",,['abstract-algebra']
66,"Sufficient Conditions for $(R,+,.)$ to be a commutative ring",Sufficient Conditions for  to be a commutative ring,"(R,+,.)","Today, in class, my algebra professor stated this particular general result. Theorem. Let $R$ be a ring of order $pq$ where $p,q$ are two primes with $p\gt q$ and $q\not\mid (p-1)$. Then, $R$ is a commutative ring. My question is: Do we require the condition $q\not\mid (p-1)$ ? Here's a proof attempt where we don't consider the above condition: Proof. Since $(R,+,.)$ is a ring, we know that $(R,+)$ is an abelian group. Now, since $p,q$ are primes and $(R,+)$ is a group, we know by Cauchy's theorem that there exists two elements $a,b\in R$ such that $|a|=p$ and $|b|=q$. Now, since $p\gt q$, we know that they are distinct primes and hence $\gcd(p,q)=1$. So, we have, $$|a+b|=|a||b|=pq=|R|\implies (R,+)=\langle a+b\rangle$$ Denote $a+b$ by $g$. Then, since $(R,+)$ is cyclic, we have, $$\forall x,y\in R~\exists m,n\in\Bbb Z\mid x=mg~,~y=ng\\~\\ xy=(mg)(ng)=mn(gg)=nm(gg)=(ng)(mg)=yx$$ using the distributive laws. Hence, $(R,+,.)$ is a commutative ring. So, does my proof work and the additional condition is not required? Or is there any error in my thinking?","Today, in class, my algebra professor stated this particular general result. Theorem. Let $R$ be a ring of order $pq$ where $p,q$ are two primes with $p\gt q$ and $q\not\mid (p-1)$. Then, $R$ is a commutative ring. My question is: Do we require the condition $q\not\mid (p-1)$ ? Here's a proof attempt where we don't consider the above condition: Proof. Since $(R,+,.)$ is a ring, we know that $(R,+)$ is an abelian group. Now, since $p,q$ are primes and $(R,+)$ is a group, we know by Cauchy's theorem that there exists two elements $a,b\in R$ such that $|a|=p$ and $|b|=q$. Now, since $p\gt q$, we know that they are distinct primes and hence $\gcd(p,q)=1$. So, we have, $$|a+b|=|a||b|=pq=|R|\implies (R,+)=\langle a+b\rangle$$ Denote $a+b$ by $g$. Then, since $(R,+)$ is cyclic, we have, $$\forall x,y\in R~\exists m,n\in\Bbb Z\mid x=mg~,~y=ng\\~\\ xy=(mg)(ng)=mn(gg)=nm(gg)=(ng)(mg)=yx$$ using the distributive laws. Hence, $(R,+,.)$ is a commutative ring. So, does my proof work and the additional condition is not required? Or is there any error in my thinking?",,"['abstract-algebra', 'group-theory', 'ring-theory', 'cyclic-groups']"
67,Ideals of Polynomial Rings and Field Extensions,Ideals of Polynomial Rings and Field Extensions,,"Let $F \subseteq K$ be fields, and suppose $f_1, ... , f_t \in F[X_1, ... , X_n]$.  Let $R = F[X_1, ... , X_n]$, and let $S = K[X_1, ... , X_n]$.  Is it always true that $(f_1S + \cdots + f_t S) \cap R = f_1R + \cdots + f_t R$? This seems like a natural thing to conclude, and I think I can prove this in the case $t = 1$, but I also know that intersections don't always distribute over sums.","Let $F \subseteq K$ be fields, and suppose $f_1, ... , f_t \in F[X_1, ... , X_n]$.  Let $R = F[X_1, ... , X_n]$, and let $S = K[X_1, ... , X_n]$.  Is it always true that $(f_1S + \cdots + f_t S) \cap R = f_1R + \cdots + f_t R$? This seems like a natural thing to conclude, and I think I can prove this in the case $t = 1$, but I also know that intersections don't always distribute over sums.",,"['abstract-algebra', 'polynomials', 'commutative-algebra', 'ideals']"
68,"Based space, commuting in diagram up to homotopy, dual Barratt-Puppe sequence.","Based space, commuting in diagram up to homotopy, dual Barratt-Puppe sequence.",,"For a based map $f : X \to Y$, define the ""homotopy fiber"" $Ff$ to be$$Fd = X \times_f PY = \{(x, \chi) : f(x) = \chi(1)\} \subset X \times PY.$$Equivalently, $Ff$ is the pullback displayed in the diagram where $\pi(x, \chi) = x$. As a pullback of a fibration, $\pi$ is a fibration. If $\rho: Nf \to f$ is defined by $\rho(x, \chi) = \chi(0)$, then $f = \rho \circ \nu$, where $\nu(x) = (x, c_{f(x)})$, and $Ff$ is the fiber $\rho^{-1}(*)$. Thus the homotopy fiber $Ff$ is constructed by first replacing $f$ by the fibration $\rho$ and then taking the actual fiber. Let $\iota: \Omega Y \to Ff$ be the inclusion specified by $\iota(\chi) = (*, \chi)$. The sequence$$\dots \to \Omega^2 X \overset{\Omega^2 f}{\longrightarrow} \Omega^2Y \overset{-\Omega\iota}{\longrightarrow} \Omega Ff \overset{-\Omega\pi}{\longrightarrow} \Omega X \overset{-\Omega f}{\longrightarrow} \Omega Y \overset{\iota}{\to} Ff \overset{\pi}{\to} X \overset{f}{\to} Y$$is called the fiber sequence generated by the map $f$; here$$(-\Omega f)(\zeta)(t) = (f \circ \zeta)(1 - t) \text{ for }\zeta \in \Omega X.$$These ""long exact sequences of based spaces"" also give rise to long exact sequences of pointed sets, covariantly. Theorem. For any based space $Z$, the induced sequence$$\dots \to [Z, \Omega F f] \to [Z,\Omega X] \to [Z, \Omega Y] \to [Z, Ff] \to [Z, X] \to [Z, Y]$$is an exact sequence of pointed sets, or of groups to the left of $[Z, \Omega Y]$, or of Abelian groups to the left of $[Z, \Omega^2Y]$. Exactness is clear at the first stage. To see this, consider the diagram Here $h: c_* \simeq f \circ g$, and we view $h$ as a map $Z \to PY$. Thus we check exactness by using any given homotopy to lift $g$ to the fiber. I claim that, up to homotopy equivalence, each consecutive pair of maps in my fiber sequence is the composite of a map and the projection from its fiber onto its source. This will imply the source. I observe that, that for any map $f$, interchange of coordinates gives a homeomorphism$$\Omega F f \cong F(\Omega f)$$such that the following diagram commutes: Here $\tau$ is obtained by interchanging the loop coordinates and is homotopic to − \text{id}. We have $\iota(f)$, $\pi(f)$, etc., to indicate the maps to which the generic constructions $\iota$ and $\pi$ are applied. Using this inductively, we see that we need only verify our claim for the two pairs of maps $(\iota(f), \pi(f))$ and $(-\Omega f, \iota(f))$. Anyways, one key step in finishing the proof: I need that the right triangle commutes and the left triangle commutes up to homotopy in the following diagram. My question is, what is the easiest way to see that the two triangles commute up to homotopy? Thanks in advance.","For a based map $f : X \to Y$, define the ""homotopy fiber"" $Ff$ to be$$Fd = X \times_f PY = \{(x, \chi) : f(x) = \chi(1)\} \subset X \times PY.$$Equivalently, $Ff$ is the pullback displayed in the diagram where $\pi(x, \chi) = x$. As a pullback of a fibration, $\pi$ is a fibration. If $\rho: Nf \to f$ is defined by $\rho(x, \chi) = \chi(0)$, then $f = \rho \circ \nu$, where $\nu(x) = (x, c_{f(x)})$, and $Ff$ is the fiber $\rho^{-1}(*)$. Thus the homotopy fiber $Ff$ is constructed by first replacing $f$ by the fibration $\rho$ and then taking the actual fiber. Let $\iota: \Omega Y \to Ff$ be the inclusion specified by $\iota(\chi) = (*, \chi)$. The sequence$$\dots \to \Omega^2 X \overset{\Omega^2 f}{\longrightarrow} \Omega^2Y \overset{-\Omega\iota}{\longrightarrow} \Omega Ff \overset{-\Omega\pi}{\longrightarrow} \Omega X \overset{-\Omega f}{\longrightarrow} \Omega Y \overset{\iota}{\to} Ff \overset{\pi}{\to} X \overset{f}{\to} Y$$is called the fiber sequence generated by the map $f$; here$$(-\Omega f)(\zeta)(t) = (f \circ \zeta)(1 - t) \text{ for }\zeta \in \Omega X.$$These ""long exact sequences of based spaces"" also give rise to long exact sequences of pointed sets, covariantly. Theorem. For any based space $Z$, the induced sequence$$\dots \to [Z, \Omega F f] \to [Z,\Omega X] \to [Z, \Omega Y] \to [Z, Ff] \to [Z, X] \to [Z, Y]$$is an exact sequence of pointed sets, or of groups to the left of $[Z, \Omega Y]$, or of Abelian groups to the left of $[Z, \Omega^2Y]$. Exactness is clear at the first stage. To see this, consider the diagram Here $h: c_* \simeq f \circ g$, and we view $h$ as a map $Z \to PY$. Thus we check exactness by using any given homotopy to lift $g$ to the fiber. I claim that, up to homotopy equivalence, each consecutive pair of maps in my fiber sequence is the composite of a map and the projection from its fiber onto its source. This will imply the source. I observe that, that for any map $f$, interchange of coordinates gives a homeomorphism$$\Omega F f \cong F(\Omega f)$$such that the following diagram commutes: Here $\tau$ is obtained by interchanging the loop coordinates and is homotopic to − \text{id}. We have $\iota(f)$, $\pi(f)$, etc., to indicate the maps to which the generic constructions $\iota$ and $\pi$ are applied. Using this inductively, we see that we need only verify our claim for the two pairs of maps $(\iota(f), \pi(f))$ and $(-\Omega f, \iota(f))$. Anyways, one key step in finishing the proof: I need that the right triangle commutes and the left triangle commutes up to homotopy in the following diagram. My question is, what is the easiest way to see that the two triangles commute up to homotopy? Thanks in advance.",,"['abstract-algebra', 'general-topology']"
69,Should this be viewed as a serious issue with the meadow-theoretic approach?,Should this be viewed as a serious issue with the meadow-theoretic approach?,,"Meadow theory (see here ) allows us to apply the results and concepts of universal algebra to the study of fields. Obviously, this is very, very nice. However, I have the following issue with the meadow-theoretic approach: since every meadow satisfies $0^{-1}=0,$ and since this makes reciprocation in both $\mathbb{R}$ and $\mathbb{C}$ discontinuous (at $0$), thus these number systems cannot be viewed as models of the theory of meadows in the category $\mathrm{Top}$ unless we endow them with a non-standard topology. Questions. Should this be viewed as a serious issue with the meadow-theoretic approach? Does anyone know of a good solution?","Meadow theory (see here ) allows us to apply the results and concepts of universal algebra to the study of fields. Obviously, this is very, very nice. However, I have the following issue with the meadow-theoretic approach: since every meadow satisfies $0^{-1}=0,$ and since this makes reciprocation in both $\mathbb{R}$ and $\mathbb{C}$ discontinuous (at $0$), thus these number systems cannot be viewed as models of the theory of meadows in the category $\mathrm{Top}$ unless we endow them with a non-standard topology. Questions. Should this be viewed as a serious issue with the meadow-theoretic approach? Does anyone know of a good solution?",,"['abstract-algebra', 'category-theory', 'field-theory']"
70,Elementary proof of irreducibility criterion,Elementary proof of irreducibility criterion,,"From ``Problems from the Book'' by Andreescu and Dospinescu, the following irreducibility criterion is presented: Let $f$ be a monic polynomial with integer coefficients and let $p$ be a prime.  If $f$ is irreducible over the integers, and $\sqrt[p]{(-1)^{\deg(f)} f(0)}$ is irrational, then $f(x^p)$ is also irreducible over the integers. I've reproduced the proof here.  I'd like to see an elementary proof that does not rely on field theory, if possible.","From ``Problems from the Book'' by Andreescu and Dospinescu, the following irreducibility criterion is presented: Let $f$ be a monic polynomial with integer coefficients and let $p$ be a prime.  If $f$ is irreducible over the integers, and $\sqrt[p]{(-1)^{\deg(f)} f(0)}$ is irrational, then $f(x^p)$ is also irreducible over the integers. I've reproduced the proof here.  I'd like to see an elementary proof that does not rely on field theory, if possible.",,"['abstract-algebra', 'polynomials', 'alternative-proof', 'irreducible-polynomials']"
71,Degrees of the real and imaginary parts of an algebraic number,Degrees of the real and imaginary parts of an algebraic number,,"I am working on a theory of generalized geometric constructions, which involves generating new numbers as real roots of polynomials whose coefficients are existing numbers satisfying certain relationships. The following general questions arise, and I am wondering if anyone already knows the answers or can link to a source that would have them: (1) If $x = a + b i$ is a root of an irreducible polynomial over the rationals of degree $n$, what is the maximum possible degree of the irreducible polynomials over the rationals for the real numbers $a$ and $b$? (2) If $\operatorname{Alg}_n$ is the field generated by all roots of polynomials over the rationals of degree $\leq n$, and $\operatorname{RAlg}_n$ is the field generated by all REAL roots of polynomials over the rationals of degree $\leq n$, for which $n$ does $\operatorname{Alg}_n=\operatorname{RAlg}_n[i]$? (3)  The inverse function of f(x)=x^5+x is uniquely defined for all real numbers; the inverse function of f(x)=x^5-x is uniquely defined for |x|>sqrt(sqrt(0.08192)) and has two or three real values otherwise. Can either of these functions be obtained from the other (assuming one has access to all three real roots when they exist), using only operations of degree <5 and complex 5th roots (that is, real 5th roots and angle 5-sections)?","I am working on a theory of generalized geometric constructions, which involves generating new numbers as real roots of polynomials whose coefficients are existing numbers satisfying certain relationships. The following general questions arise, and I am wondering if anyone already knows the answers or can link to a source that would have them: (1) If $x = a + b i$ is a root of an irreducible polynomial over the rationals of degree $n$, what is the maximum possible degree of the irreducible polynomials over the rationals for the real numbers $a$ and $b$? (2) If $\operatorname{Alg}_n$ is the field generated by all roots of polynomials over the rationals of degree $\leq n$, and $\operatorname{RAlg}_n$ is the field generated by all REAL roots of polynomials over the rationals of degree $\leq n$, for which $n$ does $\operatorname{Alg}_n=\operatorname{RAlg}_n[i]$? (3)  The inverse function of f(x)=x^5+x is uniquely defined for all real numbers; the inverse function of f(x)=x^5-x is uniquely defined for |x|>sqrt(sqrt(0.08192)) and has two or three real values otherwise. Can either of these functions be obtained from the other (assuming one has access to all three real roots when they exist), using only operations of degree <5 and complex 5th roots (that is, real 5th roots and angle 5-sections)?",,"['abstract-algebra', 'algebraic-number-theory', 'galois-theory']"
72,What is a simple axiomatisation of groups using division?,What is a simple axiomatisation of groups using division?,,"I recall from an old exercise I did as an undergrad that groups can be axiomatised using division rather than multiplication: A group is a non-empty set equipped with a binary division operator / satisfying some equational axioms. I don't remember the axioms, but I do remember that $x/y = x\cdot y^{-1}$. Because $x/x = 1$ and $1/x = x^{-1}$ we can recover the group structure by setting $x\cdot y = x/(1/y)$ and so such an axiomatisation should exist. However, I am interested in a simple , preferably natural , axiomatisation. Does anyone know one? Also, if you know a classic reference for this result/exercise, I will be grateful.","I recall from an old exercise I did as an undergrad that groups can be axiomatised using division rather than multiplication: A group is a non-empty set equipped with a binary division operator / satisfying some equational axioms. I don't remember the axioms, but I do remember that $x/y = x\cdot y^{-1}$. Because $x/x = 1$ and $1/x = x^{-1}$ we can recover the group structure by setting $x\cdot y = x/(1/y)$ and so such an axiomatisation should exist. However, I am interested in a simple , preferably natural , axiomatisation. Does anyone know one? Also, if you know a classic reference for this result/exercise, I will be grateful.",,"['abstract-algebra', 'group-theory', 'universal-algebra']"
73,Question about comultiplication,Question about comultiplication,,"I have a question about comultiplication for coalgebras: Suppose $C$ is a coalgebra over the field $k$. How does one show that the comultiplication map $\Delta:C\to C\otimes C$ is a coalgebra map if and only if $C$ is cocommutative? The main problem that I encounter is that when I tried to do it by definition, I was struggling to find a relation between $c_{(1)(2)}$ and $c_{(2)(1)}$. In that case, is there any other way for which I could tackle this question?","I have a question about comultiplication for coalgebras: Suppose $C$ is a coalgebra over the field $k$. How does one show that the comultiplication map $\Delta:C\to C\otimes C$ is a coalgebra map if and only if $C$ is cocommutative? The main problem that I encounter is that when I tried to do it by definition, I was struggling to find a relation between $c_{(1)(2)}$ and $c_{(2)(1)}$. In that case, is there any other way for which I could tackle this question?",,"['abstract-algebra', 'hopf-algebras', 'coalgebras']"
74,Trivial summand of a representation's symmetric power,Trivial summand of a representation's symmetric power,,"The following comes from Exercise 13.17 of Fulton and Harris's book, Representation Theory: A First Course . Let $V$ denote the standard representation of $\mathfrak{sl}_3\mathbb{C}$, with weights $L_1,L_2$, and $L_3$. I would like to show that the only symmetric powers $\operatorname{Sym}^n(\operatorname{Sym}^2V)$ that contains trivial summands (e.g. $\mathbb{C}$ appears when decomposed into irreducible representations) are when $n=3k$ ($n$ is divisible by $3$), and that the trivial summand here is just the $k$-th power of the original trivial summand. So, for example, $$\operatorname{Sym}^3(\operatorname{Sym}^2V)=\operatorname{Sym}^6V\oplus \Gamma_{2,2}\oplus \mathbb{C},$$ where $\Gamma_{2,2}$ is the irreducible rep. with highest weight $2L_1-2L_3$. The goal is to say something about the appearance of $\mathbb{C}$'s for $n=3k$. I have been hitting my head against the wall trying to do this with weight diagrams (finding $n$-wise sums of the weights of $\operatorname{Sym}^2V$ given by $\{L_i+L_j,2L_i\}$), and am having trouble finding a general pattern to the decomposition of $\operatorname{Sym}^n(\operatorname{Sym}^2V)$. I also know that the dimension of $\operatorname{Sym}^n(\operatorname{Sym}^2V)$ is ${n+5}\choose n$ and the dimension of each irreducible rep. with highest weight $aL_1-bL_3$ is $\dim(\Gamma_{a,b})=(a+1)(b+1)(\frac{a+b+2}{2})$, but I do not think this helps much. If you look at this from an algebraic geometric standpoint, apparently the existence of this trivial summand in the decomposition above tells us that there exists a cubic hypersurface $X$ in $\mathbb{P}^5$ preserved under all automorphisms of $\mathbb{P}^5$ carrying the Veronese surface to itself. But my background here is lacking, and this is all Greek to me. If anyone could possibly recommend a better way to approach this problem, I would greatly, greatly appreciate it.","The following comes from Exercise 13.17 of Fulton and Harris's book, Representation Theory: A First Course . Let $V$ denote the standard representation of $\mathfrak{sl}_3\mathbb{C}$, with weights $L_1,L_2$, and $L_3$. I would like to show that the only symmetric powers $\operatorname{Sym}^n(\operatorname{Sym}^2V)$ that contains trivial summands (e.g. $\mathbb{C}$ appears when decomposed into irreducible representations) are when $n=3k$ ($n$ is divisible by $3$), and that the trivial summand here is just the $k$-th power of the original trivial summand. So, for example, $$\operatorname{Sym}^3(\operatorname{Sym}^2V)=\operatorname{Sym}^6V\oplus \Gamma_{2,2}\oplus \mathbb{C},$$ where $\Gamma_{2,2}$ is the irreducible rep. with highest weight $2L_1-2L_3$. The goal is to say something about the appearance of $\mathbb{C}$'s for $n=3k$. I have been hitting my head against the wall trying to do this with weight diagrams (finding $n$-wise sums of the weights of $\operatorname{Sym}^2V$ given by $\{L_i+L_j,2L_i\}$), and am having trouble finding a general pattern to the decomposition of $\operatorname{Sym}^n(\operatorname{Sym}^2V)$. I also know that the dimension of $\operatorname{Sym}^n(\operatorname{Sym}^2V)$ is ${n+5}\choose n$ and the dimension of each irreducible rep. with highest weight $aL_1-bL_3$ is $\dim(\Gamma_{a,b})=(a+1)(b+1)(\frac{a+b+2}{2})$, but I do not think this helps much. If you look at this from an algebraic geometric standpoint, apparently the existence of this trivial summand in the decomposition above tells us that there exists a cubic hypersurface $X$ in $\mathbb{P}^5$ preserved under all automorphisms of $\mathbb{P}^5$ carrying the Veronese surface to itself. But my background here is lacking, and this is all Greek to me. If anyone could possibly recommend a better way to approach this problem, I would greatly, greatly appreciate it.",,"['abstract-algebra', 'algebraic-geometry', 'representation-theory', 'lie-groups', 'lie-algebras']"
75,Cancellation conditions on finitely generated projectives over a commutative ring,Cancellation conditions on finitely generated projectives over a commutative ring,,"A class $\mathcal{C}$ of $R$-modules is called -separative if $A \oplus A \simeq A \oplus B \simeq B \oplus B$ implies $A \simeq B$ for each $A,B \in \mathcal{C}$ -cancellative if $A \oplus C \simeq B \oplus C$ implies $A \simeq B$ for all $A,B,C \in \mathcal{C}$. According to literature, if $R$ is commutative then the class of finitely generated projectives over $R$ is separative iff it is cancelative. Even though I keep finding it as 'easy to see' in literature I seem unable to prove separative => cancelative. I would be grateful for any hint.","A class $\mathcal{C}$ of $R$-modules is called -separative if $A \oplus A \simeq A \oplus B \simeq B \oplus B$ implies $A \simeq B$ for each $A,B \in \mathcal{C}$ -cancellative if $A \oplus C \simeq B \oplus C$ implies $A \simeq B$ for all $A,B,C \in \mathcal{C}$. According to literature, if $R$ is commutative then the class of finitely generated projectives over $R$ is separative iff it is cancelative. Even though I keep finding it as 'easy to see' in literature I seem unable to prove separative => cancelative. I would be grateful for any hint.",,"['abstract-algebra', 'commutative-algebra', 'modules', 'projective-module']"
76,Alexander-Whitney map gives a coalgebra?,Alexander-Whitney map gives a coalgebra?,,"Let $R$ be a unital ring with multiplication $\mu\colon R\otimes R \rightarrow R$ . Consider the category $\mathcal{Ch}(R-\text{mod})$ of chain complexes of $R$ -modules. This category becomes a monoidal category with the tensor product of chain complexes as monoidal product and the chain complex $R[0]$ (concentrated in degree $0$ on $R$ ) as the monoidal unit. This monoidal category is braided via $x\otimes y\mapsto(-1)^{\vert x\vert \vert y \vert}y\otimes x$ . Let $X$ be a topological space. Consider $S_\ast(X):=S_\ast(X,R)$ , its singular chain complex with coefficients in $R$ . This is an object in $\mathcal{Ch}(R-\text{mod})$ . There is a special morphism in $\mathcal{Ch}(R-\text{mod})$ , aka a chain map $$AW(X)\colon S_\ast(X)\rightarrow S_\ast(X)\otimes S_\ast(X).$$ This map is sometimes called Alexander-Whitney diagonal map and defined on a chain $c\in S_n(X)$ as $AW(X)_n(c):=\sum_{p+q=n}F^p(c)\otimes R^q(c)$ , where $F^p(c)=c\circ \iota$ and $R^q(c)=c\circ \tilde{\iota}$ for the inclusions $\iota\colon \Delta^p\rightarrow \Delta^n, (t_0,\ldots, t_p)\mapsto (t_0,t_1,\ldots,t_p,0,\ldots,0)$ and $\tilde{\iota}\colon \Delta^q\rightarrow \Delta^n, (t_0,\ldots, t_q)\mapsto (0,\ldots,0,t_0,t_1,\ldots,t_q)$ . Define the chain map $\epsilon(X)\colon S_\ast(X)\rightarrow R[0]$ by letting $\epsilon(X)_{i}=0$ for all $i \neq 0$ and $\epsilon(X)_{0}$ be the $R$ -module map that sends each singular $0$ -simplex in $X$ to $1_R$ . This makes the triple $(S_{\ast}(X),AW(X), \epsilon(X))$ into a coassociative, and counital coalgebra in $\mathcal{Ch}(R-\text{mod})$ , I think. This coalgebra is not cocommutative. Is what I have said so far correct? (When) can $(S_{\ast}(X),AW(X), \epsilon(X))$ be made into a bialgebra or even a Hopf algebra? Additionally, the cup product $\cup \colon S^p(X)\otimes S^q(X)\rightarrow S^{p+q}(X)$ is defined as $\alpha\otimes \beta \mapsto \mu \circ (\alpha \otimes \beta) \circ \pi_{p,q} \circ AW(X)_{p+q}$ , where $\pi_{p,q}\colon \oplus_{k+l=p+q}S_k(X)\otimes S_l(X)\rightarrow S_{p}(X)\otimes S_q(X)$ is the projection map. This definition somehow looks like a convolution product in a bialgebra. Can this be made precise?","Let be a unital ring with multiplication . Consider the category of chain complexes of -modules. This category becomes a monoidal category with the tensor product of chain complexes as monoidal product and the chain complex (concentrated in degree on ) as the monoidal unit. This monoidal category is braided via . Let be a topological space. Consider , its singular chain complex with coefficients in . This is an object in . There is a special morphism in , aka a chain map This map is sometimes called Alexander-Whitney diagonal map and defined on a chain as , where and for the inclusions and . Define the chain map by letting for all and be the -module map that sends each singular -simplex in to . This makes the triple into a coassociative, and counital coalgebra in , I think. This coalgebra is not cocommutative. Is what I have said so far correct? (When) can be made into a bialgebra or even a Hopf algebra? Additionally, the cup product is defined as , where is the projection map. This definition somehow looks like a convolution product in a bialgebra. Can this be made precise?","R \mu\colon R\otimes R \rightarrow R \mathcal{Ch}(R-\text{mod}) R R[0] 0 R x\otimes y\mapsto(-1)^{\vert x\vert \vert y \vert}y\otimes x X S_\ast(X):=S_\ast(X,R) R \mathcal{Ch}(R-\text{mod}) \mathcal{Ch}(R-\text{mod}) AW(X)\colon S_\ast(X)\rightarrow S_\ast(X)\otimes S_\ast(X). c\in S_n(X) AW(X)_n(c):=\sum_{p+q=n}F^p(c)\otimes R^q(c) F^p(c)=c\circ \iota R^q(c)=c\circ \tilde{\iota} \iota\colon \Delta^p\rightarrow \Delta^n, (t_0,\ldots, t_p)\mapsto (t_0,t_1,\ldots,t_p,0,\ldots,0) \tilde{\iota}\colon \Delta^q\rightarrow \Delta^n, (t_0,\ldots, t_q)\mapsto (0,\ldots,0,t_0,t_1,\ldots,t_q) \epsilon(X)\colon S_\ast(X)\rightarrow R[0] \epsilon(X)_{i}=0 i \neq 0 \epsilon(X)_{0} R 0 X 1_R (S_{\ast}(X),AW(X), \epsilon(X)) \mathcal{Ch}(R-\text{mod}) (S_{\ast}(X),AW(X), \epsilon(X)) \cup \colon S^p(X)\otimes S^q(X)\rightarrow S^{p+q}(X) \alpha\otimes \beta \mapsto \mu \circ (\alpha \otimes \beta) \circ \pi_{p,q} \circ AW(X)_{p+q} \pi_{p,q}\colon \oplus_{k+l=p+q}S_k(X)\otimes S_l(X)\rightarrow S_{p}(X)\otimes S_q(X)","['abstract-algebra', 'algebraic-topology', 'homology-cohomology', 'homological-algebra', 'coalgebras']"
77,"Finding a dominant root $\alpha$ for a semisimple, irreducible Lie-algebra $\mathfrak{g}$.","Finding a dominant root  for a semisimple, irreducible Lie-algebra .",\alpha \mathfrak{g},"I´m working myself right now through this article and have trouble understanding a part of the proof of Proposition 6.4, case II) on page 345-346. I try to give a short outline of the situation: Suppose $V$ is an irreducible $\mathfrak{g}$ module, with highest weight $\lambda$ . And $\mathfrak{g}$ being a semisimple Lie-algebra, with a subalgebra $\mathfrak{s} \simeq \mathfrak{sl}(2,\mathbb{C})$ . Also let $V$ be a complex vector space [Edit] that as an $\mathfrak{s}$ -module is the direct sum $V=V(1)\oplus V_0$ , where $V(1)$ is the usual 2-dimensional (irreducible) representation of $\mathfrak{s}$ , and $V_0$ is a direct sum of trivial 1-dimensional representations of $\mathfrak{s}$ [/Edit, JL]. Then the statement i want to verify goes as follows: Then there exists a dominant root $\alpha$ for $\mathfrak{g}$ , s.th. $(\lambda, \alpha^{\lor})=1, (w_0 \lambda, \alpha^{\lor})=-1, (\mu, \alpha^{\lor})=0$ for all weights $\mu$ with $w_0 \lambda < \mu < \lambda$ . Here $w_0$ is the longest element in the Weyl group $\mathfrak{W}$ , and $<$ the usual ordering. My thoughts so far: By the theorem of the highest weight there exists a highest weight $\lambda$ satisfying $$2\frac{(\lambda, \alpha)}{(\alpha,\alpha)} \in \mathbb{Z},$$ which coincides with $(\lambda, \alpha^{\lor})$ , using the definition of the coroot of a semisimple Lie-algebra. Using the Properties of the longest element $w_0$ in the Weyl-group of a semisimple Lie-algebra $\mathfrak{g}$ and concidering that $\mathfrak{sl}(n,\mathbb{C})$ has root system $A_{n-1}$ , $w_0$ satisfies $w_0\lambda = - \lambda$ . So in particular we have $$(w_0 \lambda, \alpha^{\lor}) = - (\lambda, \alpha^{\lor}).$$ The trivial representation of $\mathfrak{s}$ has a single weight, $0$ . Let $V(1)=\mathbb{C}^2$ be the standard representation. Write $e_1,e_2$ for the standard basis. Note that $$H=\begin{pmatrix} 1 & 0\\ 0 & -1\\ \end{pmatrix}.$$ Then $He_1 = e_1$ and $He_2 = -e_2$ . Thus the set of weights of $V(1)$ is $\{\pm1\}$ .","I´m working myself right now through this article and have trouble understanding a part of the proof of Proposition 6.4, case II) on page 345-346. I try to give a short outline of the situation: Suppose is an irreducible module, with highest weight . And being a semisimple Lie-algebra, with a subalgebra . Also let be a complex vector space [Edit] that as an -module is the direct sum , where is the usual 2-dimensional (irreducible) representation of , and is a direct sum of trivial 1-dimensional representations of [/Edit, JL]. Then the statement i want to verify goes as follows: Then there exists a dominant root for , s.th. for all weights with . Here is the longest element in the Weyl group , and the usual ordering. My thoughts so far: By the theorem of the highest weight there exists a highest weight satisfying which coincides with , using the definition of the coroot of a semisimple Lie-algebra. Using the Properties of the longest element in the Weyl-group of a semisimple Lie-algebra and concidering that has root system , satisfies . So in particular we have The trivial representation of has a single weight, . Let be the standard representation. Write for the standard basis. Note that Then and . Thus the set of weights of is .","V \mathfrak{g} \lambda \mathfrak{g} \mathfrak{s} \simeq \mathfrak{sl}(2,\mathbb{C}) V \mathfrak{s} V=V(1)\oplus V_0 V(1) \mathfrak{s} V_0 \mathfrak{s} \alpha \mathfrak{g} (\lambda, \alpha^{\lor})=1, (w_0 \lambda, \alpha^{\lor})=-1, (\mu, \alpha^{\lor})=0 \mu w_0 \lambda < \mu < \lambda w_0 \mathfrak{W} < \lambda 2\frac{(\lambda, \alpha)}{(\alpha,\alpha)} \in \mathbb{Z}, (\lambda, \alpha^{\lor}) w_0 \mathfrak{g} \mathfrak{sl}(n,\mathbb{C}) A_{n-1} w_0 w_0\lambda = - \lambda (w_0 \lambda, \alpha^{\lor}) = - (\lambda, \alpha^{\lor}). \mathfrak{s} 0 V(1)=\mathbb{C}^2 e_1,e_2 H=\begin{pmatrix}
1 & 0\\
0 & -1\\
\end{pmatrix}. He_1 = e_1 He_2 = -e_2 V(1) \{\pm1\}","['abstract-algebra', 'group-theory', 'representation-theory', 'lie-algebras', 'root-systems']"
78,What is the point of (Lie) derivations?,What is the point of (Lie) derivations?,,"Probably some very naive questions, but ... Definition Let $A$ be a vector space together with a bilinear map $\mu: A \times A \rightarrow A$ . We call a map $D: A \rightarrow A$ a derivation if it satisfies the Leibniz rule $D(\mu (a,b))=\mu(D(a), b) + \mu(a, D(b))$ for all $a,b \in A$ . There are many examples of derivations, differential operators on a suitable associative algebra being one of them. Lie derivations One can look at derivations of Lie algebras (where $\mu$ is the Lie bracket). Given a Lie algebra $\mathfrak g$ (in fact any vector space with bilinear product) one can show that the derivations on $\mathfrak g$ form a Lie subalgebra of $End(\mathfrak g)$ with respect to the commutator. Furthermore, the Jacobi identity is precisely the statement that $ad_x$ is a derivation with respect to the Lie bracket for any $x \in\mathfrak g$ . Question(s) Why should we care? What is the relevance of Lie derivations? Why study them? What do they tell us about a Lie algebra? Are they somehow a generalization of differential operators? Are they related to the Lie algebra-Lie group correspondence? Is there any category theoretic perspective on them?","Probably some very naive questions, but ... Definition Let be a vector space together with a bilinear map . We call a map a derivation if it satisfies the Leibniz rule for all . There are many examples of derivations, differential operators on a suitable associative algebra being one of them. Lie derivations One can look at derivations of Lie algebras (where is the Lie bracket). Given a Lie algebra (in fact any vector space with bilinear product) one can show that the derivations on form a Lie subalgebra of with respect to the commutator. Furthermore, the Jacobi identity is precisely the statement that is a derivation with respect to the Lie bracket for any . Question(s) Why should we care? What is the relevance of Lie derivations? Why study them? What do they tell us about a Lie algebra? Are they somehow a generalization of differential operators? Are they related to the Lie algebra-Lie group correspondence? Is there any category theoretic perspective on them?","A \mu: A \times A \rightarrow A D: A \rightarrow A D(\mu (a,b))=\mu(D(a), b) + \mu(a, D(b)) a,b \in A \mu \mathfrak g \mathfrak g End(\mathfrak g) ad_x x \in\mathfrak g","['abstract-algebra', 'category-theory', 'lie-groups', 'lie-algebras', 'intuition']"
79,Fermat's Last Theorem ($n=4$) using the Gaussian integers,Fermat's Last Theorem () using the Gaussian integers,n=4,"I'm doing the second part of the following exercise in Miles Reid's Undergraduate Commutative Algebra : Exercise 0.18 : Prove the cases $n=3$ and $n=4$ of Fermat's last theorem. I would like to know: Is my proof correct? Is there a simpler way to prove the result using the Gaussian integers? (I'm aware of the proof that uses infinite descent, over the integers, so I would like to know if there is a very short proof using the power of the Gaussian integers) Here is my attempt: Let $$x^4+y^4=z^4$$ with $x,y,z\in\Bbb N$ . We can assume that $x,y,z$ has no common factor, otherwise we could divide through by that factor. If $z$ is even, then $x^4+y^4\equiv_4 0$ , which is only possible if $x^4,y^4\equiv_4 0$ , but then $x,y,z$ all have a common factor. So assume that $x$ is even. Write $$(x^2+iy^2)(x^2-iy^2)=z^4$$ Let $\pi\in\Bbb Z[i]$ be a prime such that $\pi\mid x^2+iy^2, x^2-iy^2$ . Then, $\pi\mid 2x^2,2y^2$ . If $\pi=1-i$ then $N(\pi)=2\mid z$ . Contradiction. Therefore $x^2+iy^2,x^2-iy^2$ are relatively prime. We can write $x^2+iy^2=i^k\alpha^4=i^k(a+bi)^4$ , and we get $$x^2+y^2i=i^k(a^4-6a^2b^2+b^4+i4ab(a^2-b^2))$$ $k=0,2$ is impossible, since this implies that $y$ is even, so $k=1,3$ . Therefore $$\begin{align}x^2&=\pm 4ab(a^2-b^2)\\y^2&=\mp (a^4-6a^2b^2+b^4)\end{align}$$ Since $y$ is odd, we must have that $a,b$ have different parities. If $k=3$ we get a contradiction no matter which of $a,b$ we assume to be even, since then $y^2\equiv_4 -a^4$ or $y^2\equiv_4 -b^4$ , which is impossible. Therefore $k=1$ , and so $$\begin{align}x^2&=4ab(b^2-a^2)\\y^2&=a^4-6a^2b^2+b^4=(b^2-2ab-a^2)(b^2+2ab-a^2)\end{align}$$ The factors of $b^2-2ab-a^2,b^2+2ab-a^2$ are relatively prime so they must both be odd squares. To see this, let $d\mid b^2-2ab-a^2,b^2+2ab-a^2$ . Then $d\mid b^2-a^2, ab$ , in particular $d\mid a^2b^2-a^2,b^4-a^2b^2$ . Let therefore $$C^2=b^2-2ab-a^2$$ solving for $b$ yields $$b=1\pm\sqrt{2+\frac{C^2}{a^2}}$$ which implies that $a\mid C\Rightarrow a\mid y$ . Hence both $x,y$ have an even factor of $a$ . This is only possible if $a=0$ .","I'm doing the second part of the following exercise in Miles Reid's Undergraduate Commutative Algebra : Exercise 0.18 : Prove the cases and of Fermat's last theorem. I would like to know: Is my proof correct? Is there a simpler way to prove the result using the Gaussian integers? (I'm aware of the proof that uses infinite descent, over the integers, so I would like to know if there is a very short proof using the power of the Gaussian integers) Here is my attempt: Let with . We can assume that has no common factor, otherwise we could divide through by that factor. If is even, then , which is only possible if , but then all have a common factor. So assume that is even. Write Let be a prime such that . Then, . If then . Contradiction. Therefore are relatively prime. We can write , and we get is impossible, since this implies that is even, so . Therefore Since is odd, we must have that have different parities. If we get a contradiction no matter which of we assume to be even, since then or , which is impossible. Therefore , and so The factors of are relatively prime so they must both be odd squares. To see this, let . Then , in particular . Let therefore solving for yields which implies that . Hence both have an even factor of . This is only possible if .","n=3 n=4 x^4+y^4=z^4 x,y,z\in\Bbb N x,y,z z x^4+y^4\equiv_4 0 x^4,y^4\equiv_4 0 x,y,z x (x^2+iy^2)(x^2-iy^2)=z^4 \pi\in\Bbb Z[i] \pi\mid x^2+iy^2, x^2-iy^2 \pi\mid 2x^2,2y^2 \pi=1-i N(\pi)=2\mid z x^2+iy^2,x^2-iy^2 x^2+iy^2=i^k\alpha^4=i^k(a+bi)^4 x^2+y^2i=i^k(a^4-6a^2b^2+b^4+i4ab(a^2-b^2)) k=0,2 y k=1,3 \begin{align}x^2&=\pm 4ab(a^2-b^2)\\y^2&=\mp (a^4-6a^2b^2+b^4)\end{align} y a,b k=3 a,b y^2\equiv_4 -a^4 y^2\equiv_4 -b^4 k=1 \begin{align}x^2&=4ab(b^2-a^2)\\y^2&=a^4-6a^2b^2+b^4=(b^2-2ab-a^2)(b^2+2ab-a^2)\end{align} b^2-2ab-a^2,b^2+2ab-a^2 d\mid b^2-2ab-a^2,b^2+2ab-a^2 d\mid b^2-a^2, ab d\mid a^2b^2-a^2,b^4-a^2b^2 C^2=b^2-2ab-a^2 b b=1\pm\sqrt{2+\frac{C^2}{a^2}} a\mid C\Rightarrow a\mid y x,y a a=0","['abstract-algebra', 'commutative-algebra', 'solution-verification', 'gaussian-integers']"
80,"Subfields of $\mathbb{Q}(x,y)$ of the form $\mathbb{Q}(p,q,r)$",Subfields of  of the form,"\mathbb{Q}(x,y) \mathbb{Q}(p,q,r)","Let $\mathbb{Q}(x,y)$ be the field of rational functions in the variables $x, y$ with rational coefficients. Choose $p, q, r \in \mathbb{Q}(x,y)$ and consider the subfield $K=\mathbb{Q}(p,q,r)$ . Is it generally true that there exist $s, t \in K$ such that $K=\mathbb{Q}(s,t)$ ? Any help is welcome. NOTE. This question is a particular, but very interesting case of question (II) of my previous post Subextensions of Finitely Generated Fields . In his answer to my other post Can $\mathbb{Q}(x^3,y^3,x+y)$ be generated by only two elements? professor René Schoof proved that the answer is positive for the particular choice $p=x^3, q=y^3, r=x+y$ , which I had thought to give rise to a counterexample.","Let be the field of rational functions in the variables with rational coefficients. Choose and consider the subfield . Is it generally true that there exist such that ? Any help is welcome. NOTE. This question is a particular, but very interesting case of question (II) of my previous post Subextensions of Finitely Generated Fields . In his answer to my other post Can be generated by only two elements? professor René Schoof proved that the answer is positive for the particular choice , which I had thought to give rise to a counterexample.","\mathbb{Q}(x,y) x, y p, q, r \in \mathbb{Q}(x,y) K=\mathbb{Q}(p,q,r) s, t \in K K=\mathbb{Q}(s,t) \mathbb{Q}(x^3,y^3,x+y) p=x^3, q=y^3, r=x+y","['abstract-algebra', 'algebraic-geometry', 'field-theory']"
81,Monodromy element: Why that name?,Monodromy element: Why that name?,,"Let $(H,R)$ be a quasitriangular Hopf algebra, i.e. $R$ is a choice of an universal $R$ -matrix for the Hopf algebra H. (You can find a definition of the term quasitriangular Hopf algebra on wikipedia .). One calls the element $Q:=R_{21}\cdot R_{12} \in H \otimes H$ the monodromy element of the quasitriangular Hopf algebra $(H,R)$ . Questions Why is $Q$ called that way? Is it related to the monodromy group? Or to any other concept presented on here ?","Let be a quasitriangular Hopf algebra, i.e. is a choice of an universal -matrix for the Hopf algebra H. (You can find a definition of the term quasitriangular Hopf algebra on wikipedia .). One calls the element the monodromy element of the quasitriangular Hopf algebra . Questions Why is called that way? Is it related to the monodromy group? Or to any other concept presented on here ?","(H,R) R R Q:=R_{21}\cdot R_{12} \in H \otimes H (H,R) Q","['abstract-algebra', 'algebraic-topology', 'terminology', 'singularity', 'hopf-algebras']"
82,Is there an example of a Baer ring $R$ for which $R/J(R)$ is not Baer?,Is there an example of a Baer ring  for which  is not Baer?,R R/J(R),"As the title suggests, I'm curious if there is an example of a Baer ring $R$ such that the quotient ring of $R$ by its Jacobson radical, i.e. $R/J(R)$ , is not Baer. By ""Baer ring"" I mean a ring $R$ with identity such that the right annihilator of any nonempty subset $X\subseteq R$ is generated by an idempotent of $R$ . That is, for any nonempty $X\subseteq R$ there exists $e=e^2\in R$ such that $\{a\in R\mid Xa=0\}=eR$ .","As the title suggests, I'm curious if there is an example of a Baer ring such that the quotient ring of by its Jacobson radical, i.e. , is not Baer. By ""Baer ring"" I mean a ring with identity such that the right annihilator of any nonempty subset is generated by an idempotent of . That is, for any nonempty there exists such that .",R R R/J(R) R X\subseteq R R X\subseteq R e=e^2\in R \{a\in R\mid Xa=0\}=eR,"['abstract-algebra', 'ring-theory']"
83,Isomorphism of $\mathbb{Z}\ltimes_A \mathbb{Z}^m$ and $\mathbb{Z}\ltimes_B \mathbb{Z}^m$,Isomorphism of  and,\mathbb{Z}\ltimes_A \mathbb{Z}^m \mathbb{Z}\ltimes_B \mathbb{Z}^m,"Let $A$ and $B$ be matrices of finite order with integer coefficients. Let $n\in\mathbb{N}$ and let $G_A=\mathbb{Z}\ltimes_A \mathbb{Z}^n$ be the semidirect product, where the action is $\varphi(n)\cdot (m_1,\ldots,m_n)=A^n (m_1,\ldots,m_n)$ , and similarly with $B$ . It is easy to construct an isomorphism between $G_A$ and $G_B$ if $A$ is conjugate in $GL(n,\mathbb{Z})$ to $B$ or $B^{-1}$ . But, this is also a necessary condition? I mean, does $G_A\cong G_B$ implies $A\cong B$ or $A\cong B^{-1}$ in $GL(n,\mathbb{Z})$ or is there a counterexample? I've seen in A necessary condition for two semi-direct products to be isomorphic. that it is true if A and B are hyperbolic, i.e none of their eigenvalues have module 1, but it isn't the case. Thank you!","Let and be matrices of finite order with integer coefficients. Let and let be the semidirect product, where the action is , and similarly with . It is easy to construct an isomorphism between and if is conjugate in to or . But, this is also a necessary condition? I mean, does implies or in or is there a counterexample? I've seen in A necessary condition for two semi-direct products to be isomorphic. that it is true if A and B are hyperbolic, i.e none of their eigenvalues have module 1, but it isn't the case. Thank you!","A B n\in\mathbb{N} G_A=\mathbb{Z}\ltimes_A \mathbb{Z}^n \varphi(n)\cdot (m_1,\ldots,m_n)=A^n (m_1,\ldots,m_n) B G_A G_B A GL(n,\mathbb{Z}) B B^{-1} G_A\cong G_B A\cong B A\cong B^{-1} GL(n,\mathbb{Z})","['abstract-algebra', 'group-theory', 'group-isomorphism', 'semidirect-product', 'group-extensions']"
84,"Is there a characterization of groups with the property $\forall N\unlhd G,\:\exists H\leq G\text{ s.t. }H\cong G/N$?",Is there a characterization of groups with the property ?,"\forall N\unlhd G,\:\exists H\leq G\text{ s.t. }H\cong G/N","A common mistake for beginning group theory students is the belief that a quotient of a group $G$ is necessarily isomorphic to a subgroup of $G$ .  Is there a characterization of the groups in which this property holds? If this question is too broad, I might ask if such a characterization exists for $p$ -groups. History : I originally posed the opposite question, regarding groups for which $\exists N\unlhd G\,:\, \not\exists H \unlhd G\, \text{  s.t. } H \cong G/N$ , and crossposted this to MO .  I received an answer there to the (now omitted) peripheral question about probability, which shows that most finite groups probably have this property.  After this, I changed the question to its current state, as this smaller collection of groups is more likely to be characterizable.","A common mistake for beginning group theory students is the belief that a quotient of a group is necessarily isomorphic to a subgroup of .  Is there a characterization of the groups in which this property holds? If this question is too broad, I might ask if such a characterization exists for -groups. History : I originally posed the opposite question, regarding groups for which , and crossposted this to MO .  I received an answer there to the (now omitted) peripheral question about probability, which shows that most finite groups probably have this property.  After this, I changed the question to its current state, as this smaller collection of groups is more likely to be characterizable.","G G p \exists N\unlhd G\,:\, \not\exists H \unlhd G\, \text{  s.t. } H \cong G/N","['combinatorics', 'group-theory', 'finite-groups', 'group-cohomology', 'p-groups']"
85,"The ""semi-symmetric"" algebra of a vector space","The ""semi-symmetric"" algebra of a vector space",,"If $V$ is a vector space over a field $K$ then the symmetric algebra $S(V)$ is defined as the tensor algebra $T(V)$ factorized by the two-sided ideal generated by $x\otimes y-y\otimes x$ , with $x,y\in V$ . The homogeneous component of degree $n$ of $S(V)$ is $S^n(V)=T^n(V)/I_n$ , where $I_n$ is the subspace of $T^n(V)$ generated by $x_1\otimes\cdots\otimes x_n-x_{\sigma (1)}\otimes\cdots\otimes x_{\sigma (n)}$ , where $x_1,\ldots,x_n\in V$ and $\sigma\in S_n$ . What I'm interested are the spaces $S'^n(V):=T^n(V)/I'_n$ , where $I'_n$ is generated only by expressions $x_1\otimes\cdots\otimes x_n-x_{\sigma (1)}\otimes\cdots\otimes x_{\sigma (n)}$ with $\sigma\in A_n$ . Alternatively, we may regard $S'^n(V)$ as the homogeneous component of degree $n$ of the algebra $S'(V)=T(V)/I'$ , where $I'$ is the two-sided ideal of $T(V)$ generated by $x\otimes y\otimes z-y\otimes z\otimes x$ , with $x,y,z\in V$ . (It is because $A_n$ is generated by the cyclic permutations $(i,i+1,i+2)$ with $1\leq i\leq n-2$ .) We may call $S'(V)$ the ""semi-symmetric algebra of $V$ "". My question is, is this object already known? Maybe it was introduced by somebody else under other name or other notation. I need it in a paper I'm writing and, if possible, I'd rather quote the definition and the properties of $S'^n(V)$ than write them myself.","If is a vector space over a field then the symmetric algebra is defined as the tensor algebra factorized by the two-sided ideal generated by , with . The homogeneous component of degree of is , where is the subspace of generated by , where and . What I'm interested are the spaces , where is generated only by expressions with . Alternatively, we may regard as the homogeneous component of degree of the algebra , where is the two-sided ideal of generated by , with . (It is because is generated by the cyclic permutations with .) We may call the ""semi-symmetric algebra of "". My question is, is this object already known? Maybe it was introduced by somebody else under other name or other notation. I need it in a paper I'm writing and, if possible, I'd rather quote the definition and the properties of than write them myself.","V K S(V) T(V) x\otimes y-y\otimes x x,y\in V n S(V) S^n(V)=T^n(V)/I_n I_n T^n(V) x_1\otimes\cdots\otimes x_n-x_{\sigma (1)}\otimes\cdots\otimes x_{\sigma (n)} x_1,\ldots,x_n\in V \sigma\in S_n S'^n(V):=T^n(V)/I'_n I'_n x_1\otimes\cdots\otimes x_n-x_{\sigma (1)}\otimes\cdots\otimes x_{\sigma (n)} \sigma\in A_n S'^n(V) n S'(V)=T(V)/I' I' T(V) x\otimes y\otimes z-y\otimes z\otimes x x,y,z\in V A_n (i,i+1,i+2) 1\leq i\leq n-2 S'(V) V S'^n(V)","['abstract-algebra', 'reference-request', 'vector-spaces', 'tensor-products']"
86,Method of showing maximal number of intermediate field extensions of a Galois extension with given degree,Method of showing maximal number of intermediate field extensions of a Galois extension with given degree,,"The task is the following: Show that a Galois extension $L/K$ of degree $45$ has got at most $12$ intermediate field extensions. Below I present a proof. I seek a more general method for this kind of problems. Using Galois correspondence, each intermediate field extension corresponds to a subgroup of $Gal(L/K)$ and $|Gal(L/K)|=45$ . Using Sylow theorems, we show that there are one of each Sylow subgroups for $3,5$ and conclude that they are normal subgroups and thus their product generates the whole group. The Sylow- $5$ group must be isomorphic to $\Bbb{Z}_5$ and the Sylow- $3$ group must be isomorphic to either $\Bbb{Z}_9$ or $\Bbb{Z}_3 \times \Bbb{Z}_3$ . $\Bbb{Z}_5 \times \Bbb{Z}_9 \cong\Bbb{Z}_{45}$ is cyclic so every divisor of $45$ gives exactly one subgroup, total of $6$ . $\Bbb{Z}_5 \times \Bbb{Z}_3 \times \Bbb{Z}_3$ has the subgroups: Order $1$ : $\langle 1 \rangle$ Order $3$ : $\langle (010) \rangle$ , $\langle (001) \rangle$ , $\langle (011) \rangle$ , $\langle (012) \rangle$ Order $5$ : $\langle (100) \rangle$ Order $9$ : $\langle (010),(001) \rangle$ Order $15$ : $\langle (100), \sigma \rangle$ for each $\sigma$ of order $3$ , total of $4$ Order $45$ : whole group Which gives exactly $12$ subgroups. However the last part seemed like a proof by exhaustion and it seemed ""lucky"", the group was pretty small and I could just write out the subgroups. Are there more elegant methods for this problem? General ones or in the case that the group is a product of normal subgroups? Thanks in advance.","The task is the following: Show that a Galois extension of degree has got at most intermediate field extensions. Below I present a proof. I seek a more general method for this kind of problems. Using Galois correspondence, each intermediate field extension corresponds to a subgroup of and . Using Sylow theorems, we show that there are one of each Sylow subgroups for and conclude that they are normal subgroups and thus their product generates the whole group. The Sylow- group must be isomorphic to and the Sylow- group must be isomorphic to either or . is cyclic so every divisor of gives exactly one subgroup, total of . has the subgroups: Order : Order : , , , Order : Order : Order : for each of order , total of Order : whole group Which gives exactly subgroups. However the last part seemed like a proof by exhaustion and it seemed ""lucky"", the group was pretty small and I could just write out the subgroups. Are there more elegant methods for this problem? General ones or in the case that the group is a product of normal subgroups? Thanks in advance.","L/K 45 12 Gal(L/K) |Gal(L/K)|=45 3,5 5 \Bbb{Z}_5 3 \Bbb{Z}_9 \Bbb{Z}_3 \times \Bbb{Z}_3 \Bbb{Z}_5 \times \Bbb{Z}_9 \cong\Bbb{Z}_{45} 45 6 \Bbb{Z}_5 \times \Bbb{Z}_3 \times \Bbb{Z}_3 1 \langle 1 \rangle 3 \langle (010) \rangle \langle (001) \rangle \langle (011) \rangle \langle (012) \rangle 5 \langle (100) \rangle 9 \langle (010),(001) \rangle 15 \langle (100), \sigma \rangle \sigma 3 4 45 12","['abstract-algebra', 'galois-theory', 'galois-extensions']"
87,Is $[G_p \cap G_q:G_{pq}]$ always finite? v2.0,Is  always finite? v2.0,[G_p \cap G_q:G_{pq}],"Suppose $G$ is a finitely generated group. $G_n = \langle\{g^n| g \in G\}\rangle$. Suppose $p$ and $q$ are coprime integers. Is the index of $G_{pq}$ in $G_p \cap G_q$ always finite? I have recently asked a similar question about arbitrary groups and received an infinitely generated counterexample: Is $[G_p \cap G_q:G_{pq}]$ always finite? However, the question, whether the statement is true under this additional condition, or is there a finitely generated counterexample, seems to be quite interesting and still remains unanswered.","Suppose $G$ is a finitely generated group. $G_n = \langle\{g^n| g \in G\}\rangle$. Suppose $p$ and $q$ are coprime integers. Is the index of $G_{pq}$ in $G_p \cap G_q$ always finite? I have recently asked a similar question about arbitrary groups and received an infinitely generated counterexample: Is $[G_p \cap G_q:G_{pq}]$ always finite? However, the question, whether the statement is true under this additional condition, or is there a finitely generated counterexample, seems to be quite interesting and still remains unanswered.",,"['abstract-algebra', 'group-theory', 'finitely-generated']"
88,Correspondence theorem for prime and maximal ideals,Correspondence theorem for prime and maximal ideals,,"Here is a version of the Correspondence Theorem: I need to generalize it for prime and maximal ideals. That is, under the bijection mentioned in the statement of the theorem, I need to show that prime ideals correspond to prime ideals and maximal ideals correspond to maximal ideals. This seems obvious so I have some doubts. I would prove it like this. If $I\subset R$ is prime (maximal) then $R/I$ is a domain (field). Let $\mathcal I=\varphi(I)$. Since $R/I\simeq \mathcal R/\mathcal I$ and $R/I$ is a domain (field), $\mathcal R/\mathcal I$ is also a domain (field). Hence $\mathcal I$ is prime (maximal) in $\mathcal R$. The converse is similar. Is that correct?","Here is a version of the Correspondence Theorem: I need to generalize it for prime and maximal ideals. That is, under the bijection mentioned in the statement of the theorem, I need to show that prime ideals correspond to prime ideals and maximal ideals correspond to maximal ideals. This seems obvious so I have some doubts. I would prove it like this. If $I\subset R$ is prime (maximal) then $R/I$ is a domain (field). Let $\mathcal I=\varphi(I)$. Since $R/I\simeq \mathcal R/\mathcal I$ and $R/I$ is a domain (field), $\mathcal R/\mathcal I$ is also a domain (field). Hence $\mathcal I$ is prime (maximal) in $\mathcal R$. The converse is similar. Is that correct?",,['abstract-algebra']
89,How to effectively compute fundamental units in rings?,How to effectively compute fundamental units in rings?,,"Consider the ring of integers of $K=\mathbb{Q}(\sqrt 2,\sqrt 3)$. By Dirichlet's unit theorem the units of $\mathcal O_K$ have rank 3, so they are expressible as $\pm u_1^au_2^bu_3^c$ for suitable units $u_1,u_2,u_3$ and $a,b,c\in\mathbb Z$. I found three units which are not expressible as powers of each other: $1+\sqrt 2$, $2+\sqrt 3$ and $\sqrt 3+\sqrt 2$ but how do I guarantee that none of these units is a power of another unit i.e $u^n=1+\sqrt 2$ or the same for the other two? For fields of the form $\mathbb Q(\sqrt m, \sqrt n)$ for coprime squarefree positive integers $m,n$ is it always sufficient to examine the minimal nontrivial solutions to $x^2-my^2=\pm 1$, $x^2-ny^2=\pm 1$ and $x^2-mny^2=\pm 1$?","Consider the ring of integers of $K=\mathbb{Q}(\sqrt 2,\sqrt 3)$. By Dirichlet's unit theorem the units of $\mathcal O_K$ have rank 3, so they are expressible as $\pm u_1^au_2^bu_3^c$ for suitable units $u_1,u_2,u_3$ and $a,b,c\in\mathbb Z$. I found three units which are not expressible as powers of each other: $1+\sqrt 2$, $2+\sqrt 3$ and $\sqrt 3+\sqrt 2$ but how do I guarantee that none of these units is a power of another unit i.e $u^n=1+\sqrt 2$ or the same for the other two? For fields of the form $\mathbb Q(\sqrt m, \sqrt n)$ for coprime squarefree positive integers $m,n$ is it always sufficient to examine the minimal nontrivial solutions to $x^2-my^2=\pm 1$, $x^2-ny^2=\pm 1$ and $x^2-mny^2=\pm 1$?",,"['abstract-algebra', 'ring-theory', 'algebraic-number-theory']"
90,A Ramanujan-type trigonometric identity,A Ramanujan-type trigonometric identity,,"At the end of the following article: http://www.ijpam.eu/contents/2013-85-1/15/15.pdf It is asserted that the russian mathematician, Sergey Markelov, in private communication, told them that he discovered the following trigonometric identity $\sqrt[3]{\sin \frac{2\pi}{7}} + \sqrt[3]{\sin \frac{4\pi}{7}} + \sqrt[3]{\sin \frac{8\pi}{7}} = \sqrt[3]{\frac{\sqrt[3]{7}}{3} - 2 +\sqrt[3]{3\sqrt[3]{7} - 4}+\sqrt[3]{3\sqrt[3]{7} - 5}}\sqrt[3]{\frac{3}{2}\sqrt[6]{7}}$ However, there isn't further reference about this remarkable identity. How to prove it?","At the end of the following article: http://www.ijpam.eu/contents/2013-85-1/15/15.pdf It is asserted that the russian mathematician, Sergey Markelov, in private communication, told them that he discovered the following trigonometric identity $\sqrt[3]{\sin \frac{2\pi}{7}} + \sqrt[3]{\sin \frac{4\pi}{7}} + \sqrt[3]{\sin \frac{8\pi}{7}} = \sqrt[3]{\frac{\sqrt[3]{7}}{3} - 2 +\sqrt[3]{3\sqrt[3]{7} - 4}+\sqrt[3]{3\sqrt[3]{7} - 5}}\sqrt[3]{\frac{3}{2}\sqrt[6]{7}}$ However, there isn't further reference about this remarkable identity. How to prove it?",,"['abstract-algebra', 'functions']"
91,Every polynomial's image contains $0$ or $1$ in a field $\Bbb F$,Every polynomial's image contains  or  in a field,0 1 \Bbb F,"This question talks about fields in which every polynomials are almost surjective, while I am interested in the following case: $\Bbb F$ is a field such that for every non-constant polynomial $f$ over $\Bbb F$, $f$ or $f-1$ has a root in $\Bbb F$. If $\Bbb F$ is not the field with two elements, must $\Bbb F$ be algebraically closed?","This question talks about fields in which every polynomials are almost surjective, while I am interested in the following case: $\Bbb F$ is a field such that for every non-constant polynomial $f$ over $\Bbb F$, $f$ or $f-1$ has a root in $\Bbb F$. If $\Bbb F$ is not the field with two elements, must $\Bbb F$ be algebraically closed?",,['abstract-algebra']
92,"$\mathrm{Ext}^1( \mathbb{Q},B)$ for torsion-free group $B$",for torsion-free group,"\mathrm{Ext}^1( \mathbb{Q},B) B","The following is exercise 3.5.3 from Weibel's Introduction to Homological Algebra : Show that $\mathrm{Ext}^1(\mathbb{Z}[\frac{1}{p}],\mathbb{Z})= \hat{\mathbb{Z}}_p/\mathbb{Z}$ using $\mathbb{Z}[\frac{1}{p}]=\cup p^{-i} \mathbb{Z}$ . Then show that $\mathrm{Ext}^1(\mathbb{Q},B)=(\Pi_p \hat{B}_p)/B$ for torsion-free $B$ . (Here $\hat{B}_p=\varprojlim (B/p^iB)$ is the $p$ -adic completion of $B$ ). I can show the first statement using the short exact sequence $$0 \to {\varprojlim}^1 \mathrm{Ext}^{q-1} (A_i,B) \to \mathrm{Ext}^q(\cup A_i, B) \to \varprojlim \mathrm{Ext}^q(A_i,B) \to 0$$ Ideally the second statement would follow from the observation that $\mathbb{Q}$ is the union of $\mathbb{Z}[\frac{1}{2}] \subset \mathbb{Z}[\frac{1}{6}] \subset \mathbb{Z}[\frac{1}{30}] \subset\cdots$ , and the computation $$\mathrm{Ext}^1(\mathbb{Q},B)=\mathrm{Ext}^1(\varinjlim \mathbb{Z}[\frac{1}{p_1\cdots p_r}],B)=\varprojlim \mathrm{Ext}^1(\mathbb{Z}[\frac{1}{p_1...p_r}],B)$$ $$= \varprojlim \hat{B}_{p_1\cdots p_r}/B=\varprojlim (\Pi \hat{B}_{p_i})/B=(\Pi_p \hat{B}_p)/B.$$ However the step where I take the $\varinjlim$ out of $\mathrm{Ext}^1$ is problematic, since to justify this would require that the category $Ab$ satisfy axiom (AB5*), i.e. filtered limits are exact, which is not the case. I am unable to find another way to do this exercise, so I suspect there should be a reasoning showing that the passing of the (co)limit outside $\mathrm{Ext}^1$ is legitimate in this particular case. It would be appreciated if someone can point out how to patch this step, or even point out another way to do this exercise. Thank you in advance.","The following is exercise 3.5.3 from Weibel's Introduction to Homological Algebra : Show that using . Then show that for torsion-free . (Here is the -adic completion of ). I can show the first statement using the short exact sequence Ideally the second statement would follow from the observation that is the union of , and the computation However the step where I take the out of is problematic, since to justify this would require that the category satisfy axiom (AB5*), i.e. filtered limits are exact, which is not the case. I am unable to find another way to do this exercise, so I suspect there should be a reasoning showing that the passing of the (co)limit outside is legitimate in this particular case. It would be appreciated if someone can point out how to patch this step, or even point out another way to do this exercise. Thank you in advance.","\mathrm{Ext}^1(\mathbb{Z}[\frac{1}{p}],\mathbb{Z})= \hat{\mathbb{Z}}_p/\mathbb{Z} \mathbb{Z}[\frac{1}{p}]=\cup p^{-i} \mathbb{Z} \mathrm{Ext}^1(\mathbb{Q},B)=(\Pi_p \hat{B}_p)/B B \hat{B}_p=\varprojlim (B/p^iB) p B 0 \to {\varprojlim}^1 \mathrm{Ext}^{q-1} (A_i,B) \to \mathrm{Ext}^q(\cup A_i, B) \to \varprojlim \mathrm{Ext}^q(A_i,B) \to 0 \mathbb{Q} \mathbb{Z}[\frac{1}{2}] \subset \mathbb{Z}[\frac{1}{6}] \subset \mathbb{Z}[\frac{1}{30}] \subset\cdots \mathrm{Ext}^1(\mathbb{Q},B)=\mathrm{Ext}^1(\varinjlim \mathbb{Z}[\frac{1}{p_1\cdots p_r}],B)=\varprojlim \mathrm{Ext}^1(\mathbb{Z}[\frac{1}{p_1...p_r}],B) = \varprojlim \hat{B}_{p_1\cdots p_r}/B=\varprojlim (\Pi \hat{B}_{p_i})/B=(\Pi_p \hat{B}_p)/B. \varinjlim \mathrm{Ext}^1 Ab \mathrm{Ext}^1","['abstract-algebra', 'category-theory', 'homological-algebra']"
93,Intuition on the external Zappa–Szép product,Intuition on the external Zappa–Szép product,,"$\newcommand{\Aut}{\operatorname{Aut}}$A classmate of mine recently posted an interesting question on Facebook. It didn't get an answer, and I couldn't get anywhere myself, so I'm hoping that someone here will be able to help out. Here's a paraphrase of the question: The Zappa–Szép product generalizes the semi-direct product, which   itself is a generalization of the direct product. They've all got   roughly the same conditions for the ""internal"" product: $H$ and $K$ are subgroups of some parent group $G$ $H \cap K = \{ e \}$ $HK = G$ Normality: Direct: $H$ and $K$ are normal in $G$ Semidirect: $K$ is normal in $G$ Zappa-Szép: no further assumptions But usually, people use this products in their ""external"" forms. For   these three, we need different amounts of additional data describing how the   groups commute. For the direct product $H \times K$, we need no further information. For   a semidirect product $H \rtimes_\varphi K$, we also need a homomorphism   $\varphi : H \to \Aut(K)$. So for the Zappa-Szép product, one might expect to have two   homomorphisms: $\alpha : K \to \Aut(H)$ and $\beta : H \to \Aut(K)$.   But as the Wikipedia article explains, one of the conditions we need is that   $$ \alpha(k, h_1 h_2) = \alpha(k, h_1) \cdot \alpha(\beta(h_1, k), h_2) $$ But if $\alpha(k)$ were an automorphism of $H$, then the condition would   just be   $$ \alpha(k, h_1 h_2) = \alpha(k, h_1) \cdot \alpha(k, h_2) $$ This makes sense from a multiplication perspective, because as we pull   the $k$ to the right of $h_1$, it will become a different element of   $K$. But it's rather unappetizing from a morphism perspective. Is there a way to phrase this additional data more elegantly? Here's my thoughts so far: $\alpha$ might not be a homomorphism into $\Aut(H)$, but it's still a left group action of $K$ on $H$. Same for $\beta$, except it's a right group action. So that takes care of the first five conditions from the wiki page. So now we just need to rephrase the last two conditions in a group-action-friendly way. But I can't seem to do so. Alternatively, maybe we should think of this as a single map $\psi : K \times H \to H \times K$. But I can't think of any natural, morphism-ish qualities that this map must have.","$\newcommand{\Aut}{\operatorname{Aut}}$A classmate of mine recently posted an interesting question on Facebook. It didn't get an answer, and I couldn't get anywhere myself, so I'm hoping that someone here will be able to help out. Here's a paraphrase of the question: The Zappa–Szép product generalizes the semi-direct product, which   itself is a generalization of the direct product. They've all got   roughly the same conditions for the ""internal"" product: $H$ and $K$ are subgroups of some parent group $G$ $H \cap K = \{ e \}$ $HK = G$ Normality: Direct: $H$ and $K$ are normal in $G$ Semidirect: $K$ is normal in $G$ Zappa-Szép: no further assumptions But usually, people use this products in their ""external"" forms. For   these three, we need different amounts of additional data describing how the   groups commute. For the direct product $H \times K$, we need no further information. For   a semidirect product $H \rtimes_\varphi K$, we also need a homomorphism   $\varphi : H \to \Aut(K)$. So for the Zappa-Szép product, one might expect to have two   homomorphisms: $\alpha : K \to \Aut(H)$ and $\beta : H \to \Aut(K)$.   But as the Wikipedia article explains, one of the conditions we need is that   $$ \alpha(k, h_1 h_2) = \alpha(k, h_1) \cdot \alpha(\beta(h_1, k), h_2) $$ But if $\alpha(k)$ were an automorphism of $H$, then the condition would   just be   $$ \alpha(k, h_1 h_2) = \alpha(k, h_1) \cdot \alpha(k, h_2) $$ This makes sense from a multiplication perspective, because as we pull   the $k$ to the right of $h_1$, it will become a different element of   $K$. But it's rather unappetizing from a morphism perspective. Is there a way to phrase this additional data more elegantly? Here's my thoughts so far: $\alpha$ might not be a homomorphism into $\Aut(H)$, but it's still a left group action of $K$ on $H$. Same for $\beta$, except it's a right group action. So that takes care of the first five conditions from the wiki page. So now we just need to rephrase the last two conditions in a group-action-friendly way. But I can't seem to do so. Alternatively, maybe we should think of this as a single map $\psi : K \times H \to H \times K$. But I can't think of any natural, morphism-ish qualities that this map must have.",,"['abstract-algebra', 'soft-question', 'intuition', 'semidirect-product']"
94,What is $\Bbb Z[X]/(aX+b)$ isomorphic to?,What is  isomorphic to?,\Bbb Z[X]/(aX+b),"Let $a,b$ be integers. I would to know what other ring is $R=\Bbb Z[X]/(aX+b)$ isomorphic to? If $a$ is a unit of $\Bbb Z$, then $R \cong \Bbb Z$. If $a=0$, then $R \cong (\Bbb Z/b\Bbb Z)[X]$. If $a=2,b=0$, then $R \cong \Bbb Z \oplus \Bbb F_2[X]$ as abelian groups at least, but I'm not sure as rings. If $b$ is a multiple of $a$, we could use the Chinese remainder theorem, I think. But in general, for instance $\Bbb Z[X]/(2X+3)$ or $\Bbb Z[X]/(6X+4)$ I don't know how to manage. It would also be interesting to know what happens if we replace $\Bbb Z$ by any other commutative ring (and $a,b$ elements of that ring)... Thank you!","Let $a,b$ be integers. I would to know what other ring is $R=\Bbb Z[X]/(aX+b)$ isomorphic to? If $a$ is a unit of $\Bbb Z$, then $R \cong \Bbb Z$. If $a=0$, then $R \cong (\Bbb Z/b\Bbb Z)[X]$. If $a=2,b=0$, then $R \cong \Bbb Z \oplus \Bbb F_2[X]$ as abelian groups at least, but I'm not sure as rings. If $b$ is a multiple of $a$, we could use the Chinese remainder theorem, I think. But in general, for instance $\Bbb Z[X]/(2X+3)$ or $\Bbb Z[X]/(6X+4)$ I don't know how to manage. It would also be interesting to know what happens if we replace $\Bbb Z$ by any other commutative ring (and $a,b$ elements of that ring)... Thank you!",,"['abstract-algebra', 'ring-theory', 'quotient-spaces']"
95,Under what conditions is the homology of a dg coalgebra a graded coalgebra?,Under what conditions is the homology of a dg coalgebra a graded coalgebra?,,"I'm trying to get a feel for some differential graded (dg) structures. Suppose $C$ is a differential graded coalgebra over a commutative ring $k$ , i.e. a graded $k$ -module equipped with a coproduct $\Delta : C \to C \otimes C$ and a counit $\varepsilon : C \to k$ satisfying the usual axioms. I'm interested in some sufficient conditions for the coalgebra structure on $C$ to induce coalgebra structure on the homology $H(C)$ (which is a graded $k$ -module). I guess if $k$ is a field (or a ring for which the relevant $\operatorname{Tor}$ 's in the Künneth sequence vanish) then the map $H(C)\otimes H(C) \to H(C \otimes C)$ is an isomorphism, so the inverse can be used to define a coalgebra structure on $H(C)$ . What if $k$ is a more complicated ring? What about conditions ""about $C$ "" instead of conditions ""about $k$ ""? Is it correct that when dealing with a product-type structure (e.g. a dg algebra or a dg Lie algebra) then no use of the Künneth formula is needed to induce the product-type structure on homology? Many thanks!","I'm trying to get a feel for some differential graded (dg) structures. Suppose is a differential graded coalgebra over a commutative ring , i.e. a graded -module equipped with a coproduct and a counit satisfying the usual axioms. I'm interested in some sufficient conditions for the coalgebra structure on to induce coalgebra structure on the homology (which is a graded -module). I guess if is a field (or a ring for which the relevant 's in the Künneth sequence vanish) then the map is an isomorphism, so the inverse can be used to define a coalgebra structure on . What if is a more complicated ring? What about conditions ""about "" instead of conditions ""about ""? Is it correct that when dealing with a product-type structure (e.g. a dg algebra or a dg Lie algebra) then no use of the Künneth formula is needed to induce the product-type structure on homology? Many thanks!",C k k \Delta : C \to C \otimes C \varepsilon : C \to k C H(C) k k \operatorname{Tor} H(C)\otimes H(C) \to H(C \otimes C) H(C) k C k,"['abstract-algebra', 'algebraic-topology', 'homological-algebra', 'coalgebras']"
96,Classification of all subrings,Classification of all subrings,,"Let $R$ be an integral domain whose underlying additive group is finitely generated free and whose field of fractions $K$ is a finite Galois extension of $\mathbb{Q}$. Is there a method of classifiying all subrings of $R$? Is there perhaps a variant of Galois theory? (Notice that I don't want to restrict to étale subrings!) For example, the subrings of $\mathbb{Z}[\sqrt{2}]$ should be $\mathbb{Z}[z \cdot \sqrt{2}]$ for $z \in \mathbb{Z}$, right? Here we also see that the subring structure is more complicated than the subgroup structure of the automorphism group.","Let $R$ be an integral domain whose underlying additive group is finitely generated free and whose field of fractions $K$ is a finite Galois extension of $\mathbb{Q}$. Is there a method of classifiying all subrings of $R$? Is there perhaps a variant of Galois theory? (Notice that I don't want to restrict to étale subrings!) For example, the subrings of $\mathbb{Z}[\sqrt{2}]$ should be $\mathbb{Z}[z \cdot \sqrt{2}]$ for $z \in \mathbb{Z}$, right? Here we also see that the subring structure is more complicated than the subgroup structure of the automorphism group.",,"['abstract-algebra', 'reference-request', 'ring-theory', 'algebraic-number-theory', 'galois-theory']"
97,A More Advanced Version Of Aluffi,A More Advanced Version Of Aluffi,,"Paulo Aluffi's Book, Algebra, Chapter 0 aims to teach basic algebra from a categorical viewpoint. The first chapters of the book, however, introduce groups and rings using very basic categorical concepts (no general limits or adjoints). Is there a book which teaches a basic course in group theory, and in commutative algebra, from a more advanced categorical point of view, in particular using adjoints, limits, and basic higher categories? Is there, for instance, a nice categorical viewpoint of localization and prime ideals?","Paulo Aluffi's Book, Algebra, Chapter 0 aims to teach basic algebra from a categorical viewpoint. The first chapters of the book, however, introduce groups and rings using very basic categorical concepts (no general limits or adjoints). Is there a book which teaches a basic course in group theory, and in commutative algebra, from a more advanced categorical point of view, in particular using adjoints, limits, and basic higher categories? Is there, for instance, a nice categorical viewpoint of localization and prime ideals?",,"['abstract-algebra', 'reference-request']"
98,The number of orbits of a (normal) subgroup,The number of orbits of a (normal) subgroup,,"I want to solve the following problem from Dummit & Foote's Abstract Algebra text: Assume $G$ acts transitively on the finite set $A$ and let $H$ be a normal subgroup of $G$. Let $\mathcal{O}_1,\mathcal{O}_2,\dots, \mathcal{O}_r$ be the distinct orbits of $H$ on $A$. (a) Prove that $G$ permutes the sets $\mathcal{O}_1,\mathcal{O}_2,\dots,\mathcal{O}_r$ in the sense that for each $g \in G$ and each $i \in \{1,\dots,r\}$ there is a $j$ such that $g \mathcal{O}_i=\mathcal{O}_j$, where $g \mathcal{O}=\{g \cdot a \, | \, a \in \mathcal{O}\}$ (i.e., in the notation of Exercise 7 the sets $\mathcal{O}_1,\dots,\mathcal{O}_r$ are blocks). Prove that $G$ is transitive on $\{\mathcal{O}_1,\dots,\mathcal{O}_r\}$. Deduce that all orbits of $H$ on $A$ have the same cardinality. (b) Prove that if $a \in \mathcal{O}_1$ then $|\mathcal{O}_1|=|H: H \cap G_a|$ and prove that $r=|G:HG_a|$. [Draw the sublattice describing the Second Isomorphism Theorem for the subgroups $H$ and $G_a$ of $G$. Note that $H \cap G_a=H_a$.] Here is my attempt: (a) Fix some $g \in G$ and  $i \in \{1,2,\dots,r\}$. Let $\{a_k\}$ be representatives of the orbits $\{\mathcal{O}_k\}$ (so that $\forall k$ $\mathcal{O}_k=H \cdot a_k$) ,and let us denote $g \cdot a_i$ by $a_j$. We have by normality $g \mathcal{O}_i=g H a_i=H g a_i=H a_j=\mathcal{O}_j$. Since $G$ acts transitively on $A$, given any $a_i,a_j \in A$ we may find an element $g \in G$ with $g \cdot a_i=a_j$, so that $g \mathcal{O}_i=\mathcal{O}_j$. Since the map $\sigma_g:A \to A$ defined by $\sigma_g(a)=g \cdot a$ is a bijection, restricting it to $\mathcal{O}_i \subseteq A$ gives a bijection $\mathcal{O}_i \to \mathcal{O}_j$, where $\mathcal{O}_j$ is the image $g \mathcal{O_i}$. By transitivity it follows that all orbits have the same cardinality. (b) Since $G$ acts transitively on the set of orbits $\{\mathcal{O}_k\}_{k=1}^r$ we have $r=|G:G_{\mathcal{O}_1}|$. Observe that (where in the following $h$ stands for some element of $H$) $g \mathcal{O}_1=\mathcal{O}_1 \Leftrightarrow g \cdot a=h \cdot a \Leftrightarrow h^{-1} g \cdot a=a \Leftrightarrow h^{-1}g \in G_a \Leftrightarrow g \in HG_a$. Thus the proof is complete. My questions regarding this are: Is this proof correct? How is it possible to prove (b) using the Second Isomorphism Theorem as described in the hint? I tried to do it but it only worked out if $G$ is finite, in which case I could rewrite indices as quotients of orders. Thank you!","I want to solve the following problem from Dummit & Foote's Abstract Algebra text: Assume $G$ acts transitively on the finite set $A$ and let $H$ be a normal subgroup of $G$. Let $\mathcal{O}_1,\mathcal{O}_2,\dots, \mathcal{O}_r$ be the distinct orbits of $H$ on $A$. (a) Prove that $G$ permutes the sets $\mathcal{O}_1,\mathcal{O}_2,\dots,\mathcal{O}_r$ in the sense that for each $g \in G$ and each $i \in \{1,\dots,r\}$ there is a $j$ such that $g \mathcal{O}_i=\mathcal{O}_j$, where $g \mathcal{O}=\{g \cdot a \, | \, a \in \mathcal{O}\}$ (i.e., in the notation of Exercise 7 the sets $\mathcal{O}_1,\dots,\mathcal{O}_r$ are blocks). Prove that $G$ is transitive on $\{\mathcal{O}_1,\dots,\mathcal{O}_r\}$. Deduce that all orbits of $H$ on $A$ have the same cardinality. (b) Prove that if $a \in \mathcal{O}_1$ then $|\mathcal{O}_1|=|H: H \cap G_a|$ and prove that $r=|G:HG_a|$. [Draw the sublattice describing the Second Isomorphism Theorem for the subgroups $H$ and $G_a$ of $G$. Note that $H \cap G_a=H_a$.] Here is my attempt: (a) Fix some $g \in G$ and  $i \in \{1,2,\dots,r\}$. Let $\{a_k\}$ be representatives of the orbits $\{\mathcal{O}_k\}$ (so that $\forall k$ $\mathcal{O}_k=H \cdot a_k$) ,and let us denote $g \cdot a_i$ by $a_j$. We have by normality $g \mathcal{O}_i=g H a_i=H g a_i=H a_j=\mathcal{O}_j$. Since $G$ acts transitively on $A$, given any $a_i,a_j \in A$ we may find an element $g \in G$ with $g \cdot a_i=a_j$, so that $g \mathcal{O}_i=\mathcal{O}_j$. Since the map $\sigma_g:A \to A$ defined by $\sigma_g(a)=g \cdot a$ is a bijection, restricting it to $\mathcal{O}_i \subseteq A$ gives a bijection $\mathcal{O}_i \to \mathcal{O}_j$, where $\mathcal{O}_j$ is the image $g \mathcal{O_i}$. By transitivity it follows that all orbits have the same cardinality. (b) Since $G$ acts transitively on the set of orbits $\{\mathcal{O}_k\}_{k=1}^r$ we have $r=|G:G_{\mathcal{O}_1}|$. Observe that (where in the following $h$ stands for some element of $H$) $g \mathcal{O}_1=\mathcal{O}_1 \Leftrightarrow g \cdot a=h \cdot a \Leftrightarrow h^{-1} g \cdot a=a \Leftrightarrow h^{-1}g \in G_a \Leftrightarrow g \in HG_a$. Thus the proof is complete. My questions regarding this are: Is this proof correct? How is it possible to prove (b) using the Second Isomorphism Theorem as described in the hint? I tried to do it but it only worked out if $G$ is finite, in which case I could rewrite indices as quotients of orders. Thank you!",,"['abstract-algebra', 'group-theory']"
99,Any non-trivial finitely-generated group admits maximal subgroups,Any non-trivial finitely-generated group admits maximal subgroups,,"I want to solve the following problem from Dummit & Foote's Abstract Algebra: This is exercise involving Zorn's Lemma (see Appendix I) to prove that every nontrivial finitely generated group possesses maximal subgroups. Let $G$ be a finitely generated group, say $G=\langle g_1,g_2,\dots,g_n \rangle$ , and let $\mathcal{S}$ be the set of all proper subgroups $G$ . Then $\mathcal{S}$ is partially ordered by inclusion. Let $\mathcal{C}$ be a chain in $\mathcal{S}$ . (a) Prove that the union, $H$ , of all the subgroups in $\mathcal{C}$ is a subgroup of $G$ . (b) Prove that $H$ is a proper subgroup. [If not, each $g_i$ must lie in $H$ and so must lie in some element of the chain $\mathcal{C}$ . Use the definition of a chain to arrive at a contradiction.] (c) Use Zorn's Lemma to show that $\mathcal{S}$ has a maximal element (which is, by definition, a maximal subgroup). Here is my attempt at a solution: REMARK: The goal of this exercise is to prove that any chain has an upper bound in $\mathcal{S}$ . It seems that the case of an empty chain needs to be handled separately: The empty chain $\mathcal{C}=\emptyset$ , has any element of $\mathcal{S}$ as an upper bound. From now on, we assume all chains are nonempty. (a) Let $\mathcal{C}$ be a nonempty chain in $\mathcal{S}$ , and let $H=\cup_{K \in \mathcal{C}} K$ . Since $\mathcal{C}$ is nonempty, it contains some subgroup $K_0$ , which has the identity element. Thus $1 \in H$ , so $H \neq \emptyset$ . Suppose $x,y \in H$ then there are subgroups $K_1,K_2 < G$ in $\mathcal{C}$ , such that $x \in K_1,y \in K_2$ . Since $\mathcal{C}$ is a chain we must have either $K_1 \subseteq K_2$ or $K_2 \subseteq K_1$ . Suppose WLOG that $K_1 \subseteq K_2$ . Then both $x,y$ are elements of $K_2$ , and since it's a subgroup we have $xy^{-1} \in K_2 \subseteq H$ . Thus $H$ is a subgroup of $G$ . (b) Suppose, by way of contradiction that $H$ is not a proper subgroup. Then there exist subgroups $K_1,\dots,K_n \in \mathcal{C}$ such that $g_i \in K_i$ for $1 \leq i \leq n$ . As before, it follows from the definition of the chain that one of the subgroups $K_1,K_2$ contains both of $g_1$ and $g_2$ . Similarly one of the subgroups $K_1, \dots, K_n$ must contain all generators $g_1,\dots,g_n$ of $G$ . Suppose WLOG that $K_n$ is that subgroup, we arrive at a contradiction since any element of $G$ may be constructed from the generators, so $K_n=G$ (This is a contradiction, because the elements in the chain are proper subgroups). (c) Combining the previous two parts, we have shown that any (nonempty) chain in $\mathcal{S}$ has an upper bound in $\mathcal{S}$ (the empty case was taken care of in the remark). Thus Zorn's lemma furnishes the existence of a maximal element in $\mathcal{S}$ . By definition this is a proper subgroup $M <G $ , such that if $M \subseteq K$ for any other proper subgroup $K \in \mathcal{S}$ , then $M=K$ . Thus there cannot be any subgroup $K<G$ which is a proper supergroup of $M$ . In other words, $M$ is a maximal subgroup of $G$ . Is my proof correct? Must the case of an empty chain be handled separately? Thank you!","I want to solve the following problem from Dummit & Foote's Abstract Algebra: This is exercise involving Zorn's Lemma (see Appendix I) to prove that every nontrivial finitely generated group possesses maximal subgroups. Let be a finitely generated group, say , and let be the set of all proper subgroups . Then is partially ordered by inclusion. Let be a chain in . (a) Prove that the union, , of all the subgroups in is a subgroup of . (b) Prove that is a proper subgroup. [If not, each must lie in and so must lie in some element of the chain . Use the definition of a chain to arrive at a contradiction.] (c) Use Zorn's Lemma to show that has a maximal element (which is, by definition, a maximal subgroup). Here is my attempt at a solution: REMARK: The goal of this exercise is to prove that any chain has an upper bound in . It seems that the case of an empty chain needs to be handled separately: The empty chain , has any element of as an upper bound. From now on, we assume all chains are nonempty. (a) Let be a nonempty chain in , and let . Since is nonempty, it contains some subgroup , which has the identity element. Thus , so . Suppose then there are subgroups in , such that . Since is a chain we must have either or . Suppose WLOG that . Then both are elements of , and since it's a subgroup we have . Thus is a subgroup of . (b) Suppose, by way of contradiction that is not a proper subgroup. Then there exist subgroups such that for . As before, it follows from the definition of the chain that one of the subgroups contains both of and . Similarly one of the subgroups must contain all generators of . Suppose WLOG that is that subgroup, we arrive at a contradiction since any element of may be constructed from the generators, so (This is a contradiction, because the elements in the chain are proper subgroups). (c) Combining the previous two parts, we have shown that any (nonempty) chain in has an upper bound in (the empty case was taken care of in the remark). Thus Zorn's lemma furnishes the existence of a maximal element in . By definition this is a proper subgroup , such that if for any other proper subgroup , then . Thus there cannot be any subgroup which is a proper supergroup of . In other words, is a maximal subgroup of . Is my proof correct? Must the case of an empty chain be handled separately? Thank you!","G G=\langle g_1,g_2,\dots,g_n \rangle \mathcal{S} G \mathcal{S} \mathcal{C} \mathcal{S} H \mathcal{C} G H g_i H \mathcal{C} \mathcal{S} \mathcal{S} \mathcal{C}=\emptyset \mathcal{S} \mathcal{C} \mathcal{S} H=\cup_{K \in \mathcal{C}} K \mathcal{C} K_0 1 \in H H \neq \emptyset x,y \in H K_1,K_2 < G \mathcal{C} x \in K_1,y \in K_2 \mathcal{C} K_1 \subseteq K_2 K_2 \subseteq K_1 K_1 \subseteq K_2 x,y K_2 xy^{-1} \in K_2 \subseteq H H G H K_1,\dots,K_n \in \mathcal{C} g_i \in K_i 1 \leq i \leq n K_1,K_2 g_1 g_2 K_1, \dots, K_n g_1,\dots,g_n G K_n G K_n=G \mathcal{S} \mathcal{S} \mathcal{S} M <G  M \subseteq K K \in \mathcal{S} M=K K<G M M G","['abstract-algebra', 'group-theory', 'solution-verification', 'finitely-generated', 'maximal-subgroup']"
