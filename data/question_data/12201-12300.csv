,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Calculate $\int_{-\infty}^{+\infty}\frac{x}{1+x^2}dx$, what is wrong with this?","Calculate , what is wrong with this?",\int_{-\infty}^{+\infty}\frac{x}{1+x^2}dx,"Evaluate the integral   $$\int_{-\infty}^{+\infty}\dfrac{x}{1+x^2}dx .$$ Intuitive approach As you see, it's an odd function,and we can say that value of the integral is $0$, because its symetric point is $0$ in opposite sign each other, and I think $0$ is mid point of $(-\infty,\infty)$. Solution (wrong) It's a improper integral and let's change its form: $$\displaystyle\int_{-\infty}^{+\infty}\dfrac{x}{1+x^2}dx=\displaystyle\int_{-a}^{+a}\dfrac{x}{1+x^2}dx=\lim_\limits{a\rightarrow \infty}\left[\dfrac{1}{2}\ln|x^2+1|\right]^{^{a}}_{_{-a}}=\lim\limits_{a\rightarrow \infty}\dfrac{1}{2}[0]=0$$ I've checked in Wolfram, but it says that this integral is not defined. Why can't we just calculate simply? There are no improper points, and it is a very simple function. What is the big deal? What I miss?","Evaluate the integral   $$\int_{-\infty}^{+\infty}\dfrac{x}{1+x^2}dx .$$ Intuitive approach As you see, it's an odd function,and we can say that value of the integral is $0$, because its symetric point is $0$ in opposite sign each other, and I think $0$ is mid point of $(-\infty,\infty)$. Solution (wrong) It's a improper integral and let's change its form: $$\displaystyle\int_{-\infty}^{+\infty}\dfrac{x}{1+x^2}dx=\displaystyle\int_{-a}^{+a}\dfrac{x}{1+x^2}dx=\lim_\limits{a\rightarrow \infty}\left[\dfrac{1}{2}\ln|x^2+1|\right]^{^{a}}_{_{-a}}=\lim\limits_{a\rightarrow \infty}\dfrac{1}{2}[0]=0$$ I've checked in Wolfram, but it says that this integral is not defined. Why can't we just calculate simply? There are no improper points, and it is a very simple function. What is the big deal? What I miss?",,"['calculus', 'integration', 'improper-integrals']"
1,Integral $\int_{-\infty}^{\infty} \frac{\sin^2x}{x^2} e^{ix}dx$,Integral,\int_{-\infty}^{\infty} \frac{\sin^2x}{x^2} e^{ix}dx,"How do I determine the value of this integral? $$\int_{-\infty}^{\infty} \frac{\sin^2x}{x^2} e^{ix}dx$$ Plugging in Euler's identity gives $$\int_{-\infty}^{\infty} \frac{i\sin^3x}{x^2}dx + \int_{-\infty}^{\infty} \frac{\sin^2x \cos x}{x^2}dx$$ and since $\dfrac{i\sin^3x}{x^2}$ is an odd function, all that is left is $$\int_{-\infty}^{\infty} \frac{\sin^2x \cos x}{x^2}dx$$ at which point I am stuck. I feel I am not even going the right direction, anybody willing to help? Thanks in advance.","How do I determine the value of this integral? $$\int_{-\infty}^{\infty} \frac{\sin^2x}{x^2} e^{ix}dx$$ Plugging in Euler's identity gives $$\int_{-\infty}^{\infty} \frac{i\sin^3x}{x^2}dx + \int_{-\infty}^{\infty} \frac{\sin^2x \cos x}{x^2}dx$$ and since $\dfrac{i\sin^3x}{x^2}$ is an odd function, all that is left is $$\int_{-\infty}^{\infty} \frac{\sin^2x \cos x}{x^2}dx$$ at which point I am stuck. I feel I am not even going the right direction, anybody willing to help? Thanks in advance.",,"['calculus', 'integration', 'definite-integrals']"
2,Derivative of the sine function when the argument is measured in degrees,Derivative of the sine function when the argument is measured in degrees,,"I'm trying to show that the derivative of $\sin\theta$ is equal to $\pi/180 \cos\theta$ if $\theta$ is measured in degrees. The main idea is that we need to convert $\theta$ to radians to be able to apply the identity $d/dx \sin x = \cos x $. So we need to express $ \sin \theta$  as  $$ \sin_{deg} \theta = \sin(\pi \theta /180), $$ where $\sin_{deg}$ is the $\sin$ function that takes degrees as input. Then applying the chain rule yields  $$ d/d\theta [ \sin(\pi\theta/180)] = \cos(\pi \theta/180) \pi/180 = \frac{\pi}{180}\cos_{deg}\theta. $$ Is this derivation formally correct?","I'm trying to show that the derivative of $\sin\theta$ is equal to $\pi/180 \cos\theta$ if $\theta$ is measured in degrees. The main idea is that we need to convert $\theta$ to radians to be able to apply the identity $d/dx \sin x = \cos x $. So we need to express $ \sin \theta$  as  $$ \sin_{deg} \theta = \sin(\pi \theta /180), $$ where $\sin_{deg}$ is the $\sin$ function that takes degrees as input. Then applying the chain rule yields  $$ d/d\theta [ \sin(\pi\theta/180)] = \cos(\pi \theta/180) \pi/180 = \frac{\pi}{180}\cos_{deg}\theta. $$ Is this derivation formally correct?",,['calculus']
3,"Understanding the definition of ""Indefinite integral"".","Understanding the definition of ""Indefinite integral"".",,"Everywhere I have looked up, see here , the indefinite integral is defined as: $$F'(x)= f(x) \iff \int f(x) \, dx= F(x) + C $$ From what I understand if $f$ has an antiderivative $F$ then the set $$\{F(x) + C : C \in \mathbb{R}\}$$ is called ""indefinite integral"" of $f$ . But I don't understand the definition, $F'(x) =f(x)$ ... okay, where? What values of $x$ ? For every $x$ in the domain of $f$ ? Oh then I think we have a problem. Let $f(x)= 0$ for $x \in (0,1)\cup(1,2)= \text{Domain}(f)$ , we then go on to say $\displaystyle\int f(x)\, dx =\int 0 \ dx = C = \{ F(x) = C, \forall x \in \text{Domain}(f): C \in \mathbb{R}\}$ , a set of constant functions ... Sure but what if $F:(0,1)\cup(1,2)\to \mathbb{R}$ given by, $$ F(x)= \begin{cases}1, \ x \in (0,1) \\ \\ 2, \ x \in (1,2) \end{cases}$$ then $$F'(x)= 0 = f(x)\, , \ \forall x \in \text{Domain}(f)$$ but $F(x)$ is not a constant function on $\text{Domain}(f)$ and so $F(x)\notin \displaystyle\int f(x) \, dx$ and yet $F'(x)=f(x), \forall x $ . What gives? Surely, that definition is incomplete? NOTE: I have not mentioned $f$ is Riemann integrable or not so writing $F(x)=\int_a^x f(t) \, dt$ is already a no-go.","Everywhere I have looked up, see here , the indefinite integral is defined as: From what I understand if has an antiderivative then the set is called ""indefinite integral"" of . But I don't understand the definition, ... okay, where? What values of ? For every in the domain of ? Oh then I think we have a problem. Let for , we then go on to say , a set of constant functions ... Sure but what if given by, then but is not a constant function on and so and yet . What gives? Surely, that definition is incomplete? NOTE: I have not mentioned is Riemann integrable or not so writing is already a no-go.","F'(x)= f(x) \iff \int f(x) \, dx= F(x) + C  f F \{F(x) + C : C \in \mathbb{R}\} f F'(x) =f(x) x x f f(x)= 0 x \in (0,1)\cup(1,2)= \text{Domain}(f) \displaystyle\int f(x)\, dx =\int 0 \ dx = C = \{ F(x) = C, \forall x \in \text{Domain}(f): C \in \mathbb{R}\} F:(0,1)\cup(1,2)\to \mathbb{R}  F(x)= \begin{cases}1, \ x \in (0,1) \\ \\ 2, \ x \in (1,2) \end{cases} F'(x)= 0 = f(x)\, , \ \forall x \in \text{Domain}(f) F(x) \text{Domain}(f) F(x)\notin \displaystyle\int f(x) \, dx F'(x)=f(x), \forall x  f F(x)=\int_a^x f(t) \, dt","['calculus', 'integration', 'derivatives', 'definition', 'indefinite-integrals']"
4,Why do mean value theorems have open interval for differentiablity while closed for continuity? [duplicate],Why do mean value theorems have open interval for differentiablity while closed for continuity? [duplicate],,"This question already has answers here : Why does the Mean Value Theorem require a closed interval for continuity and an open interval for differentiability? (2 answers) Closed 4 years ago . For mean value theorems like Lagrange's and Rolle's, we have the following conditions: For applying mean value theorem to any function $f(x)$ for the domain $[a,b]$ , it should be (1) continuous in $[a,b]$ (2) differentiable in $(a,b)$ So why is it that for the criteria of differentiablity, we have the open interval ?? Is it possible for a function differentiable in $(a,b)$ and continuous in $[a,b]$ to be non- differentiable at the end points? Also why is the first statement needed ?? Doesn't the second statement of differentiablity also mean that the function is continuous ?? I'm not very experienced in calculus and still in high-school,  so it might be something too obvious I'm missing , please help :)","This question already has answers here : Why does the Mean Value Theorem require a closed interval for continuity and an open interval for differentiability? (2 answers) Closed 4 years ago . For mean value theorems like Lagrange's and Rolle's, we have the following conditions: For applying mean value theorem to any function for the domain , it should be (1) continuous in (2) differentiable in So why is it that for the criteria of differentiablity, we have the open interval ?? Is it possible for a function differentiable in and continuous in to be non- differentiable at the end points? Also why is the first statement needed ?? Doesn't the second statement of differentiablity also mean that the function is continuous ?? I'm not very experienced in calculus and still in high-school,  so it might be something too obvious I'm missing , please help :)","f(x) [a,b] [a,b] (a,b) (a,b) [a,b]","['calculus', 'derivatives']"
5,Proof verification for $\lim_{n\to\infty}\frac{1}{n}(1+\sqrt2+\dots + \sqrt{n}) = +\infty$,Proof verification for,\lim_{n\to\infty}\frac{1}{n}(1+\sqrt2+\dots + \sqrt{n}) = +\infty,"Show that: $$ \lim_{n\to\infty}\frac{1}{n}(1+\sqrt2+\dots + \sqrt{n}) = +\infty $$ I've tried the following way. Consider the following sum: $$ \sqrt n + \sqrt{n-1} + \dots + \sqrt{n-\frac{n}{2}} + \dots + \sqrt{2} + 1 $$ Now if we take only $n\over 2$ terms of the sum we obtain that: $$ \sqrt n + \sqrt{n-1} + \dots > {n \over 2} \sqrt{n\over 2} $$ Let: $$ x_n = {1 \over n}(1 + \sqrt{2} + \dots + \sqrt{n}),\ \ n\in \Bbb N $$ Using the above we have that: $$ x_n > {1\over n} {n\over 2}\sqrt{n\over 2} = {1\over 2} \sqrt{n \over 2} $$ Now taking the limit for RHS its obvious that: $$\lim_{n\to\infty}{1\over2}\sqrt{n\over2} = +\infty $$ Which implies: $$ \lim_{n\to \infty}x_n = + \infty $$ Have I done it the right way? Also i would appreciate alternative ways of showing  that limit. Thanks!",Show that: I've tried the following way. Consider the following sum: Now if we take only terms of the sum we obtain that: Let: Using the above we have that: Now taking the limit for RHS its obvious that: Which implies: Have I done it the right way? Also i would appreciate alternative ways of showing  that limit. Thanks!,"
\lim_{n\to\infty}\frac{1}{n}(1+\sqrt2+\dots + \sqrt{n}) = +\infty
 
\sqrt n + \sqrt{n-1} + \dots + \sqrt{n-\frac{n}{2}} + \dots + \sqrt{2} + 1
 n\over 2 
\sqrt n + \sqrt{n-1} + \dots > {n \over 2} \sqrt{n\over 2}
 
x_n = {1 \over n}(1 + \sqrt{2} + \dots + \sqrt{n}),\ \ n\in \Bbb N
 
x_n > {1\over n} {n\over 2}\sqrt{n\over 2} = {1\over 2}
\sqrt{n \over 2}
 \lim_{n\to\infty}{1\over2}\sqrt{n\over2} = +\infty
 
\lim_{n\to \infty}x_n = + \infty
","['calculus', 'sequences-and-series', 'limits', 'proof-verification']"
6,Prove that $ f(x) = e^x + \ln x $ attains every real number as its value exactly once,Prove that  attains every real number as its value exactly once, f(x) = e^x + \ln x ,"Prove that the function $$ f(x) = e^x + \ln x $$ attains every real number as its value exactly once. First, I thought to prove that this function is a monotonic continuous function. But then I wasn't sure if that is how to prove the result, and if it is, I wasn't sure of how exactly to prove it that way.","Prove that the function $$ f(x) = e^x + \ln x $$ attains every real number as its value exactly once. First, I thought to prove that this function is a monotonic continuous function. But then I wasn't sure if that is how to prove the result, and if it is, I wasn't sure of how exactly to prove it that way.",,['calculus']
7,Derivative of Lambert W function.,Derivative of Lambert W function.,,I'm trying to find the derivative of the Lambert W function which is defined such that: $$W(x)e^{W(x)}=x$$ Through implicit differentiation I get: $$W(x)e^{W(x)}W'(x)+W'(x)e^{W(x)}=1$$ $$W'(x)(W(x)e^{W(x)}+e^{W(x)})=1$$ And using $W(x)e^{W(x)}=x$ I get: $$W'(x)=\frac{1}{x+e^{W(x)}}$$ However the answer should be: $$W'(x)=\frac{W(x)}{x(1+W(x))}$$ Where did I go wrong?,I'm trying to find the derivative of the Lambert W function which is defined such that: Through implicit differentiation I get: And using I get: However the answer should be: Where did I go wrong?,W(x)e^{W(x)}=x W(x)e^{W(x)}W'(x)+W'(x)e^{W(x)}=1 W'(x)(W(x)e^{W(x)}+e^{W(x)})=1 W(x)e^{W(x)}=x W'(x)=\frac{1}{x+e^{W(x)}} W'(x)=\frac{W(x)}{x(1+W(x))},['calculus']
8,"Limit of an Integral, Then taking Sum","Limit of an Integral, Then taking Sum",,"I am given that $I_n=\int^1_0x^ne^x\,dx$ Now, how can I find the value of the following limit: $$\lim_{n\to\infty}\left(\sum_{k=1}^{n}\frac{I_{k+1}}{k}\right)$$ I suppose solving for $I_n$ is that necessary first here?","I am given that $I_n=\int^1_0x^ne^x\,dx$ Now, how can I find the value of the following limit: $$\lim_{n\to\infty}\left(\sum_{k=1}^{n}\frac{I_{k+1}}{k}\right)$$ I suppose solving for $I_n$ is that necessary first here?",,"['calculus', 'integration', 'limits', 'summation']"
9,Deriving Mean and Variance of Laplace Distribution,Deriving Mean and Variance of Laplace Distribution,,"It has been a long time since I have used calculus, and I am trying to understand how the mean and variance of the Laplace distribution with pdf $$f(x|\mu,\sigma) = \dfrac{1}{2 \sigma}\,e^{-\Large\frac{|x-\mu |}\sigma}$$ are derived. I know that E$[X] = \mu$ and Var$[X] = 2\sigma^2$, but I don't understand how that happens. Many thanks.","It has been a long time since I have used calculus, and I am trying to understand how the mean and variance of the Laplace distribution with pdf $$f(x|\mu,\sigma) = \dfrac{1}{2 \sigma}\,e^{-\Large\frac{|x-\mu |}\sigma}$$ are derived. I know that E$[X] = \mu$ and Var$[X] = 2\sigma^2$, but I don't understand how that happens. Many thanks.",,"['calculus', 'integration', 'statistics', 'probability-distributions', 'improper-integrals']"
10,A conjecture $\int_{-\infty}^\infty\frac{\arctan e^x}{\cosh x}\cdot\frac{\tanh\frac{x}2}{x}dx\stackrel?=\frac\pi2\ln2$,A conjecture,\int_{-\infty}^\infty\frac{\arctan e^x}{\cosh x}\cdot\frac{\tanh\frac{x}2}{x}dx\stackrel?=\frac\pi2\ln2,"I need to find a closed form for this integral: $$\mathcal{I}=\int_{-\infty}^\infty\frac{\arctan e^x}{\cosh x}\cdot\frac{\tanh\frac{x}2}{x}dx.$$ A numerical integration results in an approximation $\mathcal{I}\approx1.0887930451518...$, and WolframAlpha suggests a possible closed form for this number: $$\mathcal{I}\stackrel?=\frac\pi2\ln2$$ Is it the correct value of this integral? If so, how to prove it?","I need to find a closed form for this integral: $$\mathcal{I}=\int_{-\infty}^\infty\frac{\arctan e^x}{\cosh x}\cdot\frac{\tanh\frac{x}2}{x}dx.$$ A numerical integration results in an approximation $\mathcal{I}\approx1.0887930451518...$, and WolframAlpha suggests a possible closed form for this number: $$\mathcal{I}\stackrel?=\frac\pi2\ln2$$ Is it the correct value of this integral? If so, how to prove it?",,"['calculus', 'integration', 'closed-form', 'conjectures', 'hyperbolic-functions']"
11,"Is there something to the ""let $\varepsilon < 0$"" joke that I'm missing?","Is there something to the ""let "" joke that I'm missing?",\varepsilon < 0,"Sorry if this is the wrong place to ask this, but I feel it's a question of vital importance to the future of math education. I hear this listed as a ""math joke"" all the time and I've never got it.  I've always thought that it was just dumb, but have started to wonder if I'm missing something.  Is the joke literally that it's just unexpected to take $\varepsilon < 0$ since we usually let $\varepsilon$ represent a small positive number, or is there something else to it?","Sorry if this is the wrong place to ask this, but I feel it's a question of vital importance to the future of math education. I hear this listed as a ""math joke"" all the time and I've never got it.  I've always thought that it was just dumb, but have started to wonder if I'm missing something.  Is the joke literally that it's just unexpected to take $\varepsilon < 0$ since we usually let $\varepsilon$ represent a small positive number, or is there something else to it?",,"['calculus', 'soft-question', 'popular-math']"
12,Definition for Covariant Derivative,Definition for Covariant Derivative,,"What is simple definition of the covariant derivative that looks like the definition of the derivative of a function in calculus? definition of the derivative of a function in calculus is: $$\frac {df(x)}{dx}=\lim_{\Delta x\to o}\frac {f(x+\Delta x)-f(x)}{\Delta x}$$ what about Covariant derivative, what is definition of the Covariant derivative of a function in calculus? $$\frac {{\mathcal D}f(x)}{dx}$$ Remark: ok lets say that: $$\frac {{\mathcal D}f(x)}{dx}=\frac {df(x)} {dx} +\delta f(x)$$ where the covariant derivative is broken into two parts, the extrinsic normal component and the intrinsic covariant derivative component . Now, how do we define a simple definition for the intrinsic covariant derivative component $\delta f(x)$ (this small addition is the result of parallel translation)","What is simple definition of the covariant derivative that looks like the definition of the derivative of a function in calculus? definition of the derivative of a function in calculus is: $$\frac {df(x)}{dx}=\lim_{\Delta x\to o}\frac {f(x+\Delta x)-f(x)}{\Delta x}$$ what about Covariant derivative, what is definition of the Covariant derivative of a function in calculus? $$\frac {{\mathcal D}f(x)}{dx}$$ Remark: ok lets say that: $$\frac {{\mathcal D}f(x)}{dx}=\frac {df(x)} {dx} +\delta f(x)$$ where the covariant derivative is broken into two parts, the extrinsic normal component and the intrinsic covariant derivative component . Now, how do we define a simple definition for the intrinsic covariant derivative component $\delta f(x)$ (this small addition is the result of parallel translation)",,"['calculus', 'differential-geometry', 'definition']"
13,How is Leibniz's rule for the derivative of a product related to the binomial formula? [duplicate],How is Leibniz's rule for the derivative of a product related to the binomial formula? [duplicate],,"This question already has answers here : Closed 12 years ago . Possible Duplicate: “Binomial theorem”-like identities The binomial formula describes the expansion of the $n$th power of the sum $(a+b)$: $$(a+b)^n = \sum_{k = 0}^n {n\choose k}a^kb^{n-k}$$ In calculus, there is a generalization of the product rule called Leibniz's rule , which describes the expansion of the $n$th derivative of the product of two functions $f$ and $g$: $$(fg)^{(n)} = \sum_{k = 0}^n {n\choose k}f^{(k)}g^{(n-k)}$$ It's not difficult to prove using the product rule and induction, what I'm really trying understand here is why the formula is true. Is there a way to prove it using the binomial formula? How are these two formulas related? Is there a combinatorial proof for Leibniz's rule like there is for the binomial formula ? I understand this question is a bit vague, but I hope you'll agree that these two formulas look so similar it just feels like there should be some relation between the two. Of course this is not necessarily true, but I'm hoping it's not just a crazy coincidence.","This question already has answers here : Closed 12 years ago . Possible Duplicate: “Binomial theorem”-like identities The binomial formula describes the expansion of the $n$th power of the sum $(a+b)$: $$(a+b)^n = \sum_{k = 0}^n {n\choose k}a^kb^{n-k}$$ In calculus, there is a generalization of the product rule called Leibniz's rule , which describes the expansion of the $n$th derivative of the product of two functions $f$ and $g$: $$(fg)^{(n)} = \sum_{k = 0}^n {n\choose k}f^{(k)}g^{(n-k)}$$ It's not difficult to prove using the product rule and induction, what I'm really trying understand here is why the formula is true. Is there a way to prove it using the binomial formula? How are these two formulas related? Is there a combinatorial proof for Leibniz's rule like there is for the binomial formula ? I understand this question is a bit vague, but I hope you'll agree that these two formulas look so similar it just feels like there should be some relation between the two. Of course this is not necessarily true, but I'm hoping it's not just a crazy coincidence.",,"['calculus', 'combinatorics', 'intuition', 'alternative-proof']"
14,Finding $\int_0^{\frac{\pi}{2}} \frac{x}{\sin x} dx $,Finding,\int_0^{\frac{\pi}{2}} \frac{x}{\sin x} dx ,"Is there a way to show $$\int_0^{\frac{\pi}{2}} \frac{x}{\sin x} dx = 2C$$ where $C=\sum_{n=0}^{\infty} \frac{(-1)^n}{(2n+1)^2} $ is Catalan’s constant, preferably without using complex analysis? The following is an attempt to expand it as as a series: \begin{align*} \int_0^{\frac{\pi}{2}} \frac{x}{\sin x} dx &= \int_0^{\frac{\pi}{2}} \frac{x}{1-\cos^2 x}\sin x\  dx \\ &= \sum_{n=0}^{\infty} \int_0^{\frac{\pi}{2}} x\sin x \ \cos^{2n}x \ dx \\ &= \sum_{n=0}^{\infty}\frac{1}{2n+1} \int_0^{\frac{\pi}{2}} \cos^{2n+1}x \ dx \\ &= \sum_{n=0}^{\infty} \frac{4^n}{\binom{2n}{n}(2n+1)^2} \end{align*} which is close but not quite there.","Is there a way to show where is Catalan’s constant, preferably without using complex analysis? The following is an attempt to expand it as as a series: which is close but not quite there.","\int_0^{\frac{\pi}{2}} \frac{x}{\sin x} dx = 2C C=\sum_{n=0}^{\infty} \frac{(-1)^n}{(2n+1)^2}  \begin{align*}
\int_0^{\frac{\pi}{2}} \frac{x}{\sin x} dx
&= \int_0^{\frac{\pi}{2}} \frac{x}{1-\cos^2 x}\sin x\  dx \\
&= \sum_{n=0}^{\infty} \int_0^{\frac{\pi}{2}} x\sin x \ \cos^{2n}x \ dx \\
&= \sum_{n=0}^{\infty}\frac{1}{2n+1} \int_0^{\frac{\pi}{2}} \cos^{2n+1}x \ dx \\
&= \sum_{n=0}^{\infty} \frac{4^n}{\binom{2n}{n}(2n+1)^2}
\end{align*}","['calculus', 'integration', 'definite-integrals', 'catalans-constant']"
15,Definite integration $\int _{-\infty}^\infty \frac{\tan^{-1}(2x-2)}{\cosh(\pi x)}dx$,Definite integration,\int _{-\infty}^\infty \frac{\tan^{-1}(2x-2)}{\cosh(\pi x)}dx,"How do I integrate $$\int _{-\infty}^\infty \frac{\tan^{-1}(2x-2)}{\cosh(\pi x)}dx\quad ?$$ The actual integral that I encountered is: $$\int_{-\infty}^\infty dx \left(\frac{N}{\cosh(\frac{\pi }{c}(x-1))}+\frac{1}{\cosh(\frac{\pi}{c}x)} \right) 2 \tan^{-1}\left(\frac{2x-2}{c} \right)$$ where c is a constant with $$\Re c>0$$ Not sure if these two terms makes it easier. I was trying to solve just the last term, but I couldn't make any progress. Numerical integration gives $\int _{-\infty}^\infty \frac{\tan^{-1}(2x-2)}{\cosh(\pi x)}dx= -1.01334 $ . Any hint on how to do it analytically?","How do I integrate The actual integral that I encountered is: where c is a constant with Not sure if these two terms makes it easier. I was trying to solve just the last term, but I couldn't make any progress. Numerical integration gives . Any hint on how to do it analytically?",\int _{-\infty}^\infty \frac{\tan^{-1}(2x-2)}{\cosh(\pi x)}dx\quad ? \int_{-\infty}^\infty dx \left(\frac{N}{\cosh(\frac{\pi }{c}(x-1))}+\frac{1}{\cosh(\frac{\pi}{c}x)} \right) 2 \tan^{-1}\left(\frac{2x-2}{c} \right) \Re c>0 \int _{-\infty}^\infty \frac{\tan^{-1}(2x-2)}{\cosh(\pi x)}dx= -1.01334 ,"['calculus', 'integration', 'definite-integrals']"
16,Misunderstanding the Taylor Remainder Theorem,Misunderstanding the Taylor Remainder Theorem,,"I believe I am misinterpreting the Taylor Remainder theorem somehow. The Taylor Remainder theorem is (taken from Briggs 3rd ed Calculus: Early Transcendentals) Let $f$ have continuous derivatives up to $f^{(n+1)}$ on an open interval $I$ containing $a$ . For all $x$ in $I$ , $$f(x) = p_n(x) + R_n(x)$$ where $p_n$ is the $n$ th-order Taylor polynomial for $f$ centered at $a$ and the remainder is $$R_n(x) = \frac{f^{(n+1)}(c)}{(n+1)!}(x-a)^{n+1}$$ for some point $c$ between $x$ and $a$ . Suppose that my function is $f(x)=e^x$ , $a$ is set to $0$ , and that I'm considering the 2nd-order Taylor polynomial for $e^x$ . Namely, $$p_2(x) = 1+x +\frac{x^2}{2}$$ Then the remainder will be $$R_2(x) = \frac{e^c}{3!}x^3$$ Here's where I think I might be messing up. If I consider the interval $(-5,5)$ , which is an open interval containing $0$ , where $f(x)$ is $(n+1)$ -times differentiable, I am unable to come up with a $c$ where the function $e^x$ is identical to $1+x +\frac{x^2}{2}+\frac{e^c}{3!}x^3$ in the interval $(-5,5)$ . Here is a link to a Desmos page where I tried to find such a $c$ . So I guess the main question here is this: Am I supposed to specify the interval $I$ from the beginning, or is the theorem stating that there is some interval $I$ containing $a$ where $f(x)=p_n(x)+R_n(x)$ for all $x\in I$ ? Or perhaps there's some other key idea that I'm missing here. Please let me know where I'm going wrong.","I believe I am misinterpreting the Taylor Remainder theorem somehow. The Taylor Remainder theorem is (taken from Briggs 3rd ed Calculus: Early Transcendentals) Let have continuous derivatives up to on an open interval containing . For all in , where is the th-order Taylor polynomial for centered at and the remainder is for some point between and . Suppose that my function is , is set to , and that I'm considering the 2nd-order Taylor polynomial for . Namely, Then the remainder will be Here's where I think I might be messing up. If I consider the interval , which is an open interval containing , where is -times differentiable, I am unable to come up with a where the function is identical to in the interval . Here is a link to a Desmos page where I tried to find such a . So I guess the main question here is this: Am I supposed to specify the interval from the beginning, or is the theorem stating that there is some interval containing where for all ? Or perhaps there's some other key idea that I'm missing here. Please let me know where I'm going wrong.","f f^{(n+1)} I a x I f(x) = p_n(x) + R_n(x) p_n n f a R_n(x) = \frac{f^{(n+1)}(c)}{(n+1)!}(x-a)^{n+1} c x a f(x)=e^x a 0 e^x p_2(x) = 1+x +\frac{x^2}{2} R_2(x) = \frac{e^c}{3!}x^3 (-5,5) 0 f(x) (n+1) c e^x 1+x +\frac{x^2}{2}+\frac{e^c}{3!}x^3 (-5,5) c I I a f(x)=p_n(x)+R_n(x) x\in I","['calculus', 'taylor-expansion']"
17,Is this matrix always orthogonal?,Is this matrix always orthogonal?,,"I was reading about orthogonal matricies and noticed that the $2 \times 2$ matrix  $$\begin{pmatrix} \cos(\theta) & \sin(\theta) \\ -\sin(\theta) & \cos(\theta) \end{pmatrix} $$ is orthogonal for every value of $\theta$ and that every $2\times 2$ orthogonal matrix can be expressed in this form. I then wondered if this can be generalized to any smooth paramtrization of the unit circle. More precisely, let $x(t)$ and $y(t)$ be a smooth parametrization of the unit circle for all $t$ in some interval $I \subseteq \Bbb R$ such that $|\langle x(t),y(t) \rangle| = 1$ for all $t \in I$. Is the matrix $$A= \begin{pmatrix}x(t)&y(t)\\x'(t) & y'(t) \end{pmatrix} $$ necessarily orthogonal? At first I thought yes, but I'm having trouble proving it. Letting $v = \langle x(t), y(t) \rangle$, it suffices to show three things: 1) $|v| = 1$, 2) $v \cdot v' = 0$, and 3) $|v'| = 1$. (1) follows straight from how $x(t)$ and $y(t)$ were defined. (2) can be obtained by differentiating the equation $x(t)^2 + y(t)^2 = 1$: \begin{align*} &\frac{d}{dt} \Big[ x(t)^2 + y(t)^2 \Big]= 0 \\ &\implies 2x(t)x'(t) + 2y(t)y'(t)= 0 \\ &\implies v \cdot v' = 0. \end{align*} But I couldn't find a way to prove (3). Now I am unsure whether (3) is true at all. Is $A$ even orthogonal in the first place? Any hints would be much appreciated.","I was reading about orthogonal matricies and noticed that the $2 \times 2$ matrix  $$\begin{pmatrix} \cos(\theta) & \sin(\theta) \\ -\sin(\theta) & \cos(\theta) \end{pmatrix} $$ is orthogonal for every value of $\theta$ and that every $2\times 2$ orthogonal matrix can be expressed in this form. I then wondered if this can be generalized to any smooth paramtrization of the unit circle. More precisely, let $x(t)$ and $y(t)$ be a smooth parametrization of the unit circle for all $t$ in some interval $I \subseteq \Bbb R$ such that $|\langle x(t),y(t) \rangle| = 1$ for all $t \in I$. Is the matrix $$A= \begin{pmatrix}x(t)&y(t)\\x'(t) & y'(t) \end{pmatrix} $$ necessarily orthogonal? At first I thought yes, but I'm having trouble proving it. Letting $v = \langle x(t), y(t) \rangle$, it suffices to show three things: 1) $|v| = 1$, 2) $v \cdot v' = 0$, and 3) $|v'| = 1$. (1) follows straight from how $x(t)$ and $y(t)$ were defined. (2) can be obtained by differentiating the equation $x(t)^2 + y(t)^2 = 1$: \begin{align*} &\frac{d}{dt} \Big[ x(t)^2 + y(t)^2 \Big]= 0 \\ &\implies 2x(t)x'(t) + 2y(t)y'(t)= 0 \\ &\implies v \cdot v' = 0. \end{align*} But I couldn't find a way to prove (3). Now I am unsure whether (3) is true at all. Is $A$ even orthogonal in the first place? Any hints would be much appreciated.",,"['calculus', 'linear-algebra']"
18,Should $f(x) \equiv 0$ if $0\le f'(x)\le f(x)$ and $f(0)=0$?,Should  if  and ?,f(x) \equiv 0 0\le f'(x)\le f(x) f(0)=0,"Assume $f(x)$ is a real-function defined on $[0,+\infty)$ and satisfies the followings: $f'(x) \geq 0$ $f(0)=0$ $f'(x) \leq f(x)$ Should we always have $f(x) \equiv 0$ ? Thanks for any solution.","Assume $f(x)$ is a real-function defined on $[0,+\infty)$ and satisfies the followings: $f'(x) \geq 0$ $f(0)=0$ $f'(x) \leq f(x)$ Should we always have $f(x) \equiv 0$ ? Thanks for any solution.",,['calculus']
19,Differentiating both sides of a non-differential equation,Differentiating both sides of a non-differential equation,,"I'm working on solving for $t$ in the expression $$\ln t=3\left(1-\frac{1}{t}\right)$$ and although I can easily tell by inspection and by graphing that $t=1$, I'd like to prove it more rigorously. I got stuck trying to solve this algebraically, so I tried to take the derivative of each side with respect to $t$ to get $$\frac{1}{t}=3\left(\frac{1}{t^{2}}\right).$$ However, this implies that $t=3$, which is incorrect. Why can't I take the derivative of each side like this? What am I doing wrong or misunderstanding?","I'm working on solving for $t$ in the expression $$\ln t=3\left(1-\frac{1}{t}\right)$$ and although I can easily tell by inspection and by graphing that $t=1$, I'd like to prove it more rigorously. I got stuck trying to solve this algebraically, so I tried to take the derivative of each side with respect to $t$ to get $$\frac{1}{t}=3\left(\frac{1}{t^{2}}\right).$$ However, this implies that $t=3$, which is incorrect. Why can't I take the derivative of each side like this? What am I doing wrong or misunderstanding?",,"['calculus', 'derivatives', 'transcendental-equations']"
20,"Can I learn Calculus on the web, for free, using simple tutorials? [closed]","Can I learn Calculus on the web, for free, using simple tutorials? [closed]",,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Questions about choosing a course, academic program, career path, etc. are off-topic. Such questions should be directed to those employed by the institution in question, or other qualified individuals who know your specific circumstances. Closed 8 years ago . Improve this question I'm a lazy type of person. I love experimenting with things before learning the theory. I like to practice, and learn from my mistakes. In 3-4 months I have a basic University exam on Calculus, and I'd like to learn it in a fun way. I have found these videos to be quite entertaining: http://www.calculus-help.com/tutorials However they are not exhaustive enough for my needs. Any references you would like to share? I'm not sure if it's a valid type of question for this group, so I'm sorry in advanced if it's off-topic.","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Questions about choosing a course, academic program, career path, etc. are off-topic. Such questions should be directed to those employed by the institution in question, or other qualified individuals who know your specific circumstances. Closed 8 years ago . Improve this question I'm a lazy type of person. I love experimenting with things before learning the theory. I like to practice, and learn from my mistakes. In 3-4 months I have a basic University exam on Calculus, and I'd like to learn it in a fun way. I have found these videos to be quite entertaining: http://www.calculus-help.com/tutorials However they are not exhaustive enough for my needs. Any references you would like to share? I'm not sure if it's a valid type of question for this group, so I'm sorry in advanced if it's off-topic.",,"['calculus', 'learning', 'online-resources']"
21,Prove $\int_0^1\frac{x^{2n}}{1+x}dx=\ln2+H_n-H_{2n}$,Prove,\int_0^1\frac{x^{2n}}{1+x}dx=\ln2+H_n-H_{2n},"How to prove $$\int_0^1\frac{x^{2n}}{1+x}dx=\ln2+H_n-H_{2n}$$ I used this identity to solve some advanced harmonic series but I didn't provide a proof so I see that it's worth a post so that we can use it as a reference for future solutions if needed. Here is my approach and would like to see alternative ones . \begin{align} \int_0^1\frac{x^{2n}}{1+x}dx&=\ln2-2n\int_0^1x^{2n-1}\ln(1+x)dx\tag1\\ &=\ln2-2n\sum_{k=1}^\infty\frac{(-1)^{k-1}}{k}\int_0^1 x^{2n+k-1}dx\tag2\\ &=\ln2+2n\sum_{k=1}^\infty\frac{(-1)^{k}}{k(k+2n)}\tag3\\ &=\ln2+4n\sum_{k=1}^\infty\frac{1}{2k(2k+2n)}-2n\sum_{k=1}^\infty\frac{1}{k(k+2n)}\tag4\\ &=\ln2+\sum_{k=1}^\infty\frac{n}{k(k+n)}-\sum_{k=1}^\infty\frac{2n}{k(k+2n)}\tag5\\ &=\ln2+H_n-H_{2n}\tag6 \end{align} Explanation: 1) Apply integration by parts 2) Write $\ln(1+x)=\sum_{k=1}^\infty \frac{(-1)^{k-1}}{k}x^{k}$ 3) Use the rule $\int_0^1 x^ndx=\frac1{n+1}$ 4) $\sum_{k=1}^\infty (-1)^k f(k)=2\sum_{k=1}^\infty f(2k)-\sum_{k=1}^\infty f(k)$ 5) Simplify 6) Use $H_n=\sum_{k=1}^n \frac1k=\sum_{k=1}^\infty\frac{n}{k(k+n)}$ A good application for this identity is the following problem proposed by Cornel: $$\zeta(3)=\frac43\sum_{n=1}^\infty\frac{(2H_{2n}-H_n)(H_n-H_{2n}+\ln2)}{n}$$ If we multiply both sides of our identity by $\frac{2H_{2n}-H_n}{n}$ then sum up from $n= 1$ to $\infty$ we get $$\sum_{n=1}^\infty\frac{(2H_{2n}-H_n)(H_n-H_{2n}+\ln2)}{n}=\int_0^1\frac1{1+x}\sum_{n=1}^\infty\frac{x^{2n}}{n}(2H_{2n}-H_n)dx\\=\frac12\int_0^1\frac{1}{1+x}\ln^2\left(\frac{1-x}{1+x}\right)dx=\frac12\int_0^1\frac{\ln^2x}{1+x}dx=\frac34\zeta(3)$$ where the identity $\ln^2\left(\frac{1-x}{1+x}\right)=2\sum_{n=1}^\infty \frac{x^{2n}}{n}(2H_{2n}-H_n)$ was used in our calculations. Another application is calculating $\sum_{n=1}^\infty \frac{(-1)^nH_{n/2}}{n^3}$ : From our proof above, we can see that $$\int_0^1 x^{2n-1}\ln(1+x)dx=\frac{H_{2n}-H_n}{2n}$$ Replace $2n$ by $n$ then multiply both sides by $\frac{(-1)^n}{n^2}$ and sum up we get $$\sum_{n=1}^\infty \frac{(-1)^nH_n}{n^3}-\sum_{n=1}^\infty \frac{(-1)^nH_{n/2}}{n^3}=\int_0^1\frac{\ln(1+x)}{x}\sum_{n=1}^\infty \frac{(-x)^n}{n^2}dx\\=\int_0^1\frac{\ln(1+x)\operatorname{Li}_2(-x)}{x}dx=-\frac12\operatorname{Li}_2^2(-1)=-\frac12\left(-\frac12\zeta(2)\right)^2=-\frac5{16}\zeta(4)$$ I managed here to prove $$\sum_{n=1}^\infty \frac{(-1)^nH_n}{n^3}=2\operatorname{Li_4}\left(\frac12\right)-\frac{11}4\zeta(4)+\frac74\ln2\zeta(3)-\frac12\ln^22\zeta(2)+\frac{1}{12}\ln^42$$ Thus $$\sum_{n=1}^\infty \frac{(-1)^nH_{n/2}}{n^3}=2\operatorname{Li_4}\left(\frac12\right)-\frac{39}{16}\zeta(4)+\frac74\ln2\zeta(3)-\frac12\ln^22\zeta(2)+\frac{1}{12}\ln^42$$","How to prove I used this identity to solve some advanced harmonic series but I didn't provide a proof so I see that it's worth a post so that we can use it as a reference for future solutions if needed. Here is my approach and would like to see alternative ones . Explanation: 1) Apply integration by parts 2) Write 3) Use the rule 4) 5) Simplify 6) Use A good application for this identity is the following problem proposed by Cornel: If we multiply both sides of our identity by then sum up from to we get where the identity was used in our calculations. Another application is calculating : From our proof above, we can see that Replace by then multiply both sides by and sum up we get I managed here to prove Thus","\int_0^1\frac{x^{2n}}{1+x}dx=\ln2+H_n-H_{2n} \begin{align}
\int_0^1\frac{x^{2n}}{1+x}dx&=\ln2-2n\int_0^1x^{2n-1}\ln(1+x)dx\tag1\\
&=\ln2-2n\sum_{k=1}^\infty\frac{(-1)^{k-1}}{k}\int_0^1 x^{2n+k-1}dx\tag2\\
&=\ln2+2n\sum_{k=1}^\infty\frac{(-1)^{k}}{k(k+2n)}\tag3\\
&=\ln2+4n\sum_{k=1}^\infty\frac{1}{2k(2k+2n)}-2n\sum_{k=1}^\infty\frac{1}{k(k+2n)}\tag4\\
&=\ln2+\sum_{k=1}^\infty\frac{n}{k(k+n)}-\sum_{k=1}^\infty\frac{2n}{k(k+2n)}\tag5\\
&=\ln2+H_n-H_{2n}\tag6
\end{align} \ln(1+x)=\sum_{k=1}^\infty \frac{(-1)^{k-1}}{k}x^{k} \int_0^1 x^ndx=\frac1{n+1} \sum_{k=1}^\infty (-1)^k f(k)=2\sum_{k=1}^\infty f(2k)-\sum_{k=1}^\infty f(k) H_n=\sum_{k=1}^n \frac1k=\sum_{k=1}^\infty\frac{n}{k(k+n)} \zeta(3)=\frac43\sum_{n=1}^\infty\frac{(2H_{2n}-H_n)(H_n-H_{2n}+\ln2)}{n} \frac{2H_{2n}-H_n}{n} n= 1 \infty \sum_{n=1}^\infty\frac{(2H_{2n}-H_n)(H_n-H_{2n}+\ln2)}{n}=\int_0^1\frac1{1+x}\sum_{n=1}^\infty\frac{x^{2n}}{n}(2H_{2n}-H_n)dx\\=\frac12\int_0^1\frac{1}{1+x}\ln^2\left(\frac{1-x}{1+x}\right)dx=\frac12\int_0^1\frac{\ln^2x}{1+x}dx=\frac34\zeta(3) \ln^2\left(\frac{1-x}{1+x}\right)=2\sum_{n=1}^\infty \frac{x^{2n}}{n}(2H_{2n}-H_n) \sum_{n=1}^\infty \frac{(-1)^nH_{n/2}}{n^3} \int_0^1 x^{2n-1}\ln(1+x)dx=\frac{H_{2n}-H_n}{2n} 2n n \frac{(-1)^n}{n^2} \sum_{n=1}^\infty \frac{(-1)^nH_n}{n^3}-\sum_{n=1}^\infty \frac{(-1)^nH_{n/2}}{n^3}=\int_0^1\frac{\ln(1+x)}{x}\sum_{n=1}^\infty \frac{(-x)^n}{n^2}dx\\=\int_0^1\frac{\ln(1+x)\operatorname{Li}_2(-x)}{x}dx=-\frac12\operatorname{Li}_2^2(-1)=-\frac12\left(-\frac12\zeta(2)\right)^2=-\frac5{16}\zeta(4) \sum_{n=1}^\infty \frac{(-1)^nH_n}{n^3}=2\operatorname{Li_4}\left(\frac12\right)-\frac{11}4\zeta(4)+\frac74\ln2\zeta(3)-\frac12\ln^22\zeta(2)+\frac{1}{12}\ln^42 \sum_{n=1}^\infty \frac{(-1)^nH_{n/2}}{n^3}=2\operatorname{Li_4}\left(\frac12\right)-\frac{39}{16}\zeta(4)+\frac74\ln2\zeta(3)-\frac12\ln^22\zeta(2)+\frac{1}{12}\ln^42","['calculus', 'integration', 'sequences-and-series', 'alternative-proof', 'harmonic-numbers']"
22,"Calculus Books, preferably Soviet.","Calculus Books, preferably Soviet.",,"I would like some book recommendations on calculus books for novices. I love old Russian texts and if you you suggest such books(no issue if they are rigorous), I would be very grateful. If the text is quite challenging, I have no problem. But it should be interesting with proper exposition of topics. The book should be good for self-study, preferably a textbook(again, for beginners). And it's not necessary for it to be Soviet. Just anything good. I merely like Soviet/Slavic books and so, the title. Thanks to you all. Edit again:Please try to abstain from suggesting analysis books. All I want is a nice, rigorous Book on Integral and Differential Calculus. Doesn't matter which origin(at this point), but should be translated into English. Thanks.","I would like some book recommendations on calculus books for novices. I love old Russian texts and if you you suggest such books(no issue if they are rigorous), I would be very grateful. If the text is quite challenging, I have no problem. But it should be interesting with proper exposition of topics. The book should be good for self-study, preferably a textbook(again, for beginners). And it's not necessary for it to be Soviet. Just anything good. I merely like Soviet/Slavic books and so, the title. Thanks to you all. Edit again:Please try to abstain from suggesting analysis books. All I want is a nice, rigorous Book on Integral and Differential Calculus. Doesn't matter which origin(at this point), but should be translated into English. Thanks.",,"['calculus', 'soft-question', 'book-recommendation']"
23,Is the differential forms perspective on $dx$ incompatible with the technique of implicit differentiation?,Is the differential forms perspective on  incompatible with the technique of implicit differentiation?,dx,"Suppose $$x^2 + y^2 = 5^2.$$ We're trying to find $dy/dx$ at $(3,4).$ Applying $d$ to both sides: $$2x dx + 2y dy = 0$$ Or in other words: $$2x dx + 2y dy = 0dx + 0dy$$ Since the covectors $dx_p$ and $dy_p$ form a basis for the cotangent space at any $p \in \mathbb{R}^2$ , hence $2x = 0$ and $2y = 0.$ Hence $x = 0$ and $y = 0$ . Ergo $0^2 + 0^2 = 5^2$ , a contradiction. Question. Does this mean that the differential forms perspective on $dx$ is incompatible with the technique of implicit differentiation? If not, why not? If so, what definition of $dx$ can be used to avoid this issue?","Suppose We're trying to find at Applying to both sides: Or in other words: Since the covectors and form a basis for the cotangent space at any , hence and Hence and . Ergo , a contradiction. Question. Does this mean that the differential forms perspective on is incompatible with the technique of implicit differentiation? If not, why not? If so, what definition of can be used to avoid this issue?","x^2 + y^2 = 5^2. dy/dx (3,4). d 2x dx + 2y dy = 0 2x dx + 2y dy = 0dx + 0dy dx_p dy_p p \in \mathbb{R}^2 2x = 0 2y = 0. x = 0 y = 0 0^2 + 0^2 = 5^2 dx dx","['calculus', 'differential-geometry', 'differential-topology', 'differential-forms', 'implicit-differentiation']"
24,Prove that a function is equal to a constant.,Prove that a function is equal to a constant.,,"Assume that $f(x)$ is continuous on $[a,b]$. And for any continuous function $g$  if $\int_a^bg(x)dx=0$ then $\int_a^bf(x)g(x)dx=0$,  show that $f(x)$ is a constant. I tried to convert this question to show$f'(x)\equiv0$ but this seems impossible by using the mean value theorem or the Rolle theorem.  Any ideas?","Assume that $f(x)$ is continuous on $[a,b]$. And for any continuous function $g$  if $\int_a^bg(x)dx=0$ then $\int_a^bf(x)g(x)dx=0$,  show that $f(x)$ is a constant. I tried to convert this question to show$f'(x)\equiv0$ but this seems impossible by using the mean value theorem or the Rolle theorem.  Any ideas?",,"['calculus', 'integration']"
25,Different Ways of Integrating $3\sin x\cos x$,Different Ways of Integrating,3\sin x\cos x,"I am asking this question for my son who is in (equivalent) twelfth grade and I failed to answer his query. When he tries to integrate $3\sin x\cos x$, he finds that this can be done in at least following three ways. And these three ways do not produce equivalent results. ONE Let us assume, $\sin x = z$. This gives, \begin{align*}   \cos x &= \frac{dz}{dx}\\   \cos x dx &= dz \end{align*} So, we can write, \begin{align*}   \int 3\sin x\cos x dx  &=3 \int zdz\\   &=3 \frac{z^2}{2}\\   &=\frac{3}{2} \sin^2 x\\   &=\frac{3}{4}\times 2\sin^2 x\\   &=\frac{3}{4} (1 -\cos 2x)\\ \end{align*} TWO Let us assume, $\cos x = z$. This gives, \begin{align*}   -\sin x &= \frac{dz}{dx}\\   \sin x dx &= -dz \end{align*} So, we can write, \begin{align*}   \int 3\sin x\cos x dx  &=-3 \int zdz\\   &=-3 \frac{z^2}{2}\\   &=-\frac{3}{2} \cos^2 x\\   &=-\frac{3}{4}\times 2\cos^2 x\\   &=-\frac{3}{4} (1 +\cos 2x)\\ \end{align*} THREE \begin{align*}   \int 3\sin x\cos x dx  &=\frac{3}{2}\int 2\sin x\cos x dx\\   &=\frac{3}{2}\int \sin 2x dx\\   &=-\frac{3}{2}\times\frac{1}{2} \cos 2x\\   &=-\frac{3}{4} \cos 2x\\ \end{align*} The results found in above three methods are not the same. If we try a simple approach of evaluating the integration results at, $x = \frac{\pi}{6}$, we get as follows. From the first one, $\frac{3}{4} (1 -\cos 2x) = \frac{3}{4} (1 -\cos \frac{2\pi}{6}) = \frac{3}{4} (1 -\cos \frac{\pi}{3}) = \frac{3}{4} (1 - \frac{1}{2}) = \frac{3}{4}\times\frac{1}{2} = \frac{3}{8}$ From the second one, $-\frac{3}{4} (1 +\cos 2x) = -\frac{3}{4} (1 +\cos \frac{2\pi}{6}) = -\frac{3}{4} (1 +\cos \frac{\pi}{3}) = -\frac{3}{4} (1 + \frac{1}{2}) = -\frac{3}{4}\times\frac{3}{2} = -\frac{9}{8}$ From the third one, $-\frac{3}{4} \cos 2x=-\frac{3}{4} \cos \frac{2\pi}{6} = -\frac{3}{4} \cos \frac{\pi}{3} = -\frac{3}{4} \times \frac{1}{2} = -\frac{3}{8} $ Clearly, we are getting some nonequivalent results. We have failed to find the mistakes or explanations behind this. Your help will be appreciated.","I am asking this question for my son who is in (equivalent) twelfth grade and I failed to answer his query. When he tries to integrate $3\sin x\cos x$, he finds that this can be done in at least following three ways. And these three ways do not produce equivalent results. ONE Let us assume, $\sin x = z$. This gives, \begin{align*}   \cos x &= \frac{dz}{dx}\\   \cos x dx &= dz \end{align*} So, we can write, \begin{align*}   \int 3\sin x\cos x dx  &=3 \int zdz\\   &=3 \frac{z^2}{2}\\   &=\frac{3}{2} \sin^2 x\\   &=\frac{3}{4}\times 2\sin^2 x\\   &=\frac{3}{4} (1 -\cos 2x)\\ \end{align*} TWO Let us assume, $\cos x = z$. This gives, \begin{align*}   -\sin x &= \frac{dz}{dx}\\   \sin x dx &= -dz \end{align*} So, we can write, \begin{align*}   \int 3\sin x\cos x dx  &=-3 \int zdz\\   &=-3 \frac{z^2}{2}\\   &=-\frac{3}{2} \cos^2 x\\   &=-\frac{3}{4}\times 2\cos^2 x\\   &=-\frac{3}{4} (1 +\cos 2x)\\ \end{align*} THREE \begin{align*}   \int 3\sin x\cos x dx  &=\frac{3}{2}\int 2\sin x\cos x dx\\   &=\frac{3}{2}\int \sin 2x dx\\   &=-\frac{3}{2}\times\frac{1}{2} \cos 2x\\   &=-\frac{3}{4} \cos 2x\\ \end{align*} The results found in above three methods are not the same. If we try a simple approach of evaluating the integration results at, $x = \frac{\pi}{6}$, we get as follows. From the first one, $\frac{3}{4} (1 -\cos 2x) = \frac{3}{4} (1 -\cos \frac{2\pi}{6}) = \frac{3}{4} (1 -\cos \frac{\pi}{3}) = \frac{3}{4} (1 - \frac{1}{2}) = \frac{3}{4}\times\frac{1}{2} = \frac{3}{8}$ From the second one, $-\frac{3}{4} (1 +\cos 2x) = -\frac{3}{4} (1 +\cos \frac{2\pi}{6}) = -\frac{3}{4} (1 +\cos \frac{\pi}{3}) = -\frac{3}{4} (1 + \frac{1}{2}) = -\frac{3}{4}\times\frac{3}{2} = -\frac{9}{8}$ From the third one, $-\frac{3}{4} \cos 2x=-\frac{3}{4} \cos \frac{2\pi}{6} = -\frac{3}{4} \cos \frac{\pi}{3} = -\frac{3}{4} \times \frac{1}{2} = -\frac{3}{8} $ Clearly, we are getting some nonequivalent results. We have failed to find the mistakes or explanations behind this. Your help will be appreciated.",,"['calculus', 'integration']"
26,Find a continuous function $f$ that satisfies...,Find a continuous function  that satisfies...,f,Find a continuous function $f$ that satisfies $$ f(x) = 1 + \frac{1}{x}\int_1^x f(t) \ dt $$ Note: I tried differentiating with respect to $x$ to get an ODE but you get one that contains integrals - likely difficult to solve.,Find a continuous function $f$ that satisfies $$ f(x) = 1 + \frac{1}{x}\int_1^x f(t) \ dt $$ Note: I tried differentiating with respect to $x$ to get an ODE but you get one that contains integrals - likely difficult to solve.,,"['calculus', 'integration', 'ordinary-differential-equations', 'integral-equations']"
27,Evaluate $\int _{ 0 }^{ 1 }{ \left( { x }^{ 5 }+{ x }^{ 4 }+{ x }^{ 2 } \right) \sqrt { 4{ x }^{ 3 }+5{ x }^{ 2 }+10 } \; dx } $,Evaluate,\int _{ 0 }^{ 1 }{ \left( { x }^{ 5 }+{ x }^{ 4 }+{ x }^{ 2 } \right) \sqrt { 4{ x }^{ 3 }+5{ x }^{ 2 }+10 } \; dx } ,"Evaluate    $$\int _{ 0 }^{ 1 }{ \left( { x }^{ 5 }+{ x }^{ 4 }+{ x }^{ 2  } \right) \sqrt { 4{ x }^{ 3 }+5{ x }^{ 2 }+10 } \; dx } $$ The question look's like there is a nice method to do it, but I can't figure out. Can someone provide some hint or answer?.","Evaluate    $$\int _{ 0 }^{ 1 }{ \left( { x }^{ 5 }+{ x }^{ 4 }+{ x }^{ 2  } \right) \sqrt { 4{ x }^{ 3 }+5{ x }^{ 2 }+10 } \; dx } $$ The question look's like there is a nice method to do it, but I can't figure out. Can someone provide some hint or answer?.",,"['calculus', 'integration', 'definite-integrals']"
28,Evaluating $\int_1^3\frac{\ln(x+2)}{x^2+2x+15} \ dx$,Evaluating,\int_1^3\frac{\ln(x+2)}{x^2+2x+15} \ dx,Could you please give me a hint on how to compute: $$ \int_1^3\frac{\ln(x+2)}{x^2+2x+15}dx $$ Thank you for your help,Could you please give me a hint on how to compute: $$ \int_1^3\frac{\ln(x+2)}{x^2+2x+15}dx $$ Thank you for your help,,"['calculus', 'integration', 'definite-integrals']"
29,Can the fundamental theorem of calculus be proved without an appeal to mean value or Rolle's theorem or its immediate consequences?,Can the fundamental theorem of calculus be proved without an appeal to mean value or Rolle's theorem or its immediate consequences?,,"I think the answer is in the negative. Here are two of the ways I know. Both of them use the Mean Value Theorem. The first one use in an indirect way, and the second uses it more forthrightly. The first proof goes something like this. Prove that $F(x) = \int_a^x f(t) dt, a \le x \le b$ is a particular anti derivative and if $G$ is an anti derivative that is $G^\prime =(x) = f(x)$. Then apply the Mean Value Theorem to $F-G$ on any interval $(c,d) \subset (a,b)$ to conclude that $F(c) - G(d) = 0$. Now keep $c$ fixed and move $d$ in the interval $[a, b]$. Use $F(b) - G(b) = F(a)-G(a)$ to conclude $G(b) - G(a) = F(b) - F(a) = F(b) = \int_a^b f(x)dx$. The second proof, which I prefer, goes something like this: $G(b) - G(a) = \int dG = (G(b) - G(x_{n-1})) + (G(x_{n-1}-G(x_{n-2}) )+ \ldots (G(x_1) - G(a))$ for any partition $\{a, x_1, x_2,\ldots, x_{n-1}, b \}$ of $[a, b] $. Now you use the Mean Value Theorem to write replace each term $G(x_k) - G(x_{k-1})$ by $G^\prime(c_k)(x_k - x_{k-1})$ to get a Riemann sum which converges to $\int_a^b f(x)dx $. I think one has to use some sort of theorem like mvt which gives you global information $f(b) - f(a)$ of $f$ using the derivative which can only provide local information on $f$.","I think the answer is in the negative. Here are two of the ways I know. Both of them use the Mean Value Theorem. The first one use in an indirect way, and the second uses it more forthrightly. The first proof goes something like this. Prove that $F(x) = \int_a^x f(t) dt, a \le x \le b$ is a particular anti derivative and if $G$ is an anti derivative that is $G^\prime =(x) = f(x)$. Then apply the Mean Value Theorem to $F-G$ on any interval $(c,d) \subset (a,b)$ to conclude that $F(c) - G(d) = 0$. Now keep $c$ fixed and move $d$ in the interval $[a, b]$. Use $F(b) - G(b) = F(a)-G(a)$ to conclude $G(b) - G(a) = F(b) - F(a) = F(b) = \int_a^b f(x)dx$. The second proof, which I prefer, goes something like this: $G(b) - G(a) = \int dG = (G(b) - G(x_{n-1})) + (G(x_{n-1}-G(x_{n-2}) )+ \ldots (G(x_1) - G(a))$ for any partition $\{a, x_1, x_2,\ldots, x_{n-1}, b \}$ of $[a, b] $. Now you use the Mean Value Theorem to write replace each term $G(x_k) - G(x_{k-1})$ by $G^\prime(c_k)(x_k - x_{k-1})$ to get a Riemann sum which converges to $\int_a^b f(x)dx $. I think one has to use some sort of theorem like mvt which gives you global information $f(b) - f(a)$ of $f$ using the derivative which can only provide local information on $f$.",,['calculus']
30,Evaluating $\sum_{n=k}^{\infty} \frac{1}{ \binom{n}{k}}$,Evaluating,\sum_{n=k}^{\infty} \frac{1}{ \binom{n}{k}},"I've looked into WolframAlpha and deduced from some examples that: $$ \sum_{n=k}^{\infty} \frac{1}{ \binom{n}{k}}  = \frac{k}{k-1} ~~~~ \text{where} ~~~ k \in \mathbb{N} \setminus \{1\}$$ But why is that? The only thing I could pull of is this: $$ \sum_{n=k}^{\infty} \frac{1}{ \binom{n}{k}} = \sum_{n=k}^{\infty} \frac{k! (n-k)!}{n!} = k! \sum_{n=k}^{\infty} \frac{ (n-k)!}{n!} = k! \sum_{n=k}^{\infty} \frac{1}{(n-k+1) \cdot (n-k+2)\dots \cdot n}$$ Which then got me into a dead-end (for my knowledge) ... I am curious as why is that and but this actually mean ""combinatorically"" / ""statistically"" and how to actually evaluate this. Thanks!","I've looked into WolframAlpha and deduced from some examples that: But why is that? The only thing I could pull of is this: Which then got me into a dead-end (for my knowledge) ... I am curious as why is that and but this actually mean ""combinatorically"" / ""statistically"" and how to actually evaluate this. Thanks!", \sum_{n=k}^{\infty} \frac{1}{ \binom{n}{k}}  = \frac{k}{k-1} ~~~~ \text{where} ~~~ k \in \mathbb{N} \setminus \{1\}  \sum_{n=k}^{\infty} \frac{1}{ \binom{n}{k}} = \sum_{n=k}^{\infty} \frac{k! (n-k)!}{n!} = k! \sum_{n=k}^{\infty} \frac{ (n-k)!}{n!} = k! \sum_{n=k}^{\infty} \frac{1}{(n-k+1) \cdot (n-k+2)\dots \cdot n},"['calculus', 'combinatorics', 'summation']"
31,Prove that $\int_{0}^{\infty}\frac{(\arctan x)^3}{x^3}dx=\frac{3π}{2}\ln2-\frac{π^3}{16}$,Prove that,\int_{0}^{\infty}\frac{(\arctan x)^3}{x^3}dx=\frac{3π}{2}\ln2-\frac{π^3}{16},"Question : How to prove $$\int_{0}^{\infty}\frac{(\arctan x)^3}{x^3}dx=\frac{3π}{2}\ln2-\frac{π^3}{16}\: ?$$ I was able to prove $$\int_{0}^{\infty}\frac{(\arctan x)^2}{x^2}dx=π\ln2$$ using, $$f(x,y)=\int_{0}^{\infty}\frac {{\arctan(xt)}\cdot{\arctan(yt)}}{t^2} dt$$ at $ f(1,1)$ . But i'm not able to evaluate 1st integral using same method. Is there any other method to evaluate this?","Question : How to prove I was able to prove using, at . But i'm not able to evaluate 1st integral using same method. Is there any other method to evaluate this?","\int_{0}^{\infty}\frac{(\arctan x)^3}{x^3}dx=\frac{3π}{2}\ln2-\frac{π^3}{16}\: ? \int_{0}^{\infty}\frac{(\arctan x)^2}{x^2}dx=π\ln2 f(x,y)=\int_{0}^{\infty}\frac {{\arctan(xt)}\cdot{\arctan(yt)}}{t^2} dt  f(1,1)","['calculus', 'integration', 'definite-integrals']"
32,Lagrangian Mechanics & Derivatives,Lagrangian Mechanics & Derivatives,,"I don't really know whether to put this in Physics forums since it is relating to Mechanics, or Math since the question is actually about the math being done. Don't criticize me over it. So for the question: I was doing some review problems on Lagrange's equations, KE+PE, and I found this document . In the first question's solution, the writer differentiates without explaining the step. They have these: $$\begin{cases} x = r \sin(\theta) \cos(\phi)\\[5 pt] y = r \sin(\theta) \sin(\phi)\\[5 pt] z = r \cos(\theta) \end{cases} $$ and this: $$T = {m\over 2}(\dot x^2 +\dot y^2 +\dot z^2)$$ I never really studied the spherical coordinate system much, and obviously never thought about the derivatives of the conversion into Cartesian. Can someone find or explain the process of taking the derivatives of the first three equations, plugging into the equation for Kinetic Energy, and simplifying? There is a probably a different calculus method for the coordinate system, which I don't know. Thanks! EDIT: While doing taking the derivatives, was the method used actually a separate form of calculus beyond I and II, or was it normal first-order differentiation? If so, how? Here is the part I am speaking of: Solution: The kinetic energy is $T=\frac m2(\dot x^2+\dot y^2+\dot z^2)$ . We substitute $$\begin{cases} x = r \sin(\theta) \cos(\phi)\\[5 pt] y = r \sin(\theta) \sin(\phi)\\[5 pt] z = r \cos(\theta) \end{cases} $$ Differentiating these, substituting into $T$ , and simplifying, we find $$T=\frac m2 (\dot r^2 +r^2\dot\theta^2+r^2\sin^2\theta\dot\phi^2).$$","I don't really know whether to put this in Physics forums since it is relating to Mechanics, or Math since the question is actually about the math being done. Don't criticize me over it. So for the question: I was doing some review problems on Lagrange's equations, KE+PE, and I found this document . In the first question's solution, the writer differentiates without explaining the step. They have these: and this: I never really studied the spherical coordinate system much, and obviously never thought about the derivatives of the conversion into Cartesian. Can someone find or explain the process of taking the derivatives of the first three equations, plugging into the equation for Kinetic Energy, and simplifying? There is a probably a different calculus method for the coordinate system, which I don't know. Thanks! EDIT: While doing taking the derivatives, was the method used actually a separate form of calculus beyond I and II, or was it normal first-order differentiation? If so, how? Here is the part I am speaking of: Solution: The kinetic energy is . We substitute Differentiating these, substituting into , and simplifying, we find","\begin{cases}
x = r \sin(\theta) \cos(\phi)\\[5 pt]
y = r \sin(\theta) \sin(\phi)\\[5 pt]
z = r \cos(\theta)
\end{cases}
 T = {m\over 2}(\dot x^2 +\dot y^2 +\dot z^2) T=\frac m2(\dot x^2+\dot y^2+\dot z^2) \begin{cases}
x = r \sin(\theta) \cos(\phi)\\[5 pt]
y = r \sin(\theta) \sin(\phi)\\[5 pt]
z = r \cos(\theta)
\end{cases}
 T T=\frac m2 (\dot r^2 +r^2\dot\theta^2+r^2\sin^2\theta\dot\phi^2).","['calculus', 'multivariable-calculus', 'classical-mechanics', 'spherical-coordinates', 'euler-lagrange-equation']"
33,Taking an integral of an integrand consisting of different power radical functions,Taking an integral of an integrand consisting of different power radical functions,,"So I have this integral, $$\int_0^1 (1-x^7)^{1/3}-(1-x^3)^{1/7} dx$$ and  I don't know where to start with this. I tried  doing some Algebra, but I'm not recognizing any patterns. (Maybe it is my tired brain, but I'm completely lost.) If any of you can point me in the right direction, give me some useful hints, or explain how to solve it, I would be forever grateful. Thank you!","So I have this integral, $$\int_0^1 (1-x^7)^{1/3}-(1-x^3)^{1/7} dx$$ and  I don't know where to start with this. I tried  doing some Algebra, but I'm not recognizing any patterns. (Maybe it is my tired brain, but I'm completely lost.) If any of you can point me in the right direction, give me some useful hints, or explain how to solve it, I would be forever grateful. Thank you!",,"['calculus', 'integration', 'definite-integrals', 'radicals']"
34,Find $\lim\limits_{n\to\infty}\left(\frac{a_1}{a_2}+\frac{a_2}{a_3}+\frac{a_3}{a_4}+...+\frac{a_n}{a_1}\right)$,Find,\lim\limits_{n\to\infty}\left(\frac{a_1}{a_2}+\frac{a_2}{a_3}+\frac{a_3}{a_4}+...+\frac{a_n}{a_1}\right),"Find $\lim\limits_{n\to\infty}\left(\frac{a_1}{a_2}+\frac{a_2}{a_3}+\frac{a_3}{a_4}+...+\frac{a_n}{a_1}\right)$ if {$a_n$} is random sequence with positive terms. If sequence is increasing ($a_1>a_2>...>a_n$), then $L=+\infty$ What is the limit when sequence is decreasing?","Find $\lim\limits_{n\to\infty}\left(\frac{a_1}{a_2}+\frac{a_2}{a_3}+\frac{a_3}{a_4}+...+\frac{a_n}{a_1}\right)$ if {$a_n$} is random sequence with positive terms. If sequence is increasing ($a_1>a_2>...>a_n$), then $L=+\infty$ What is the limit when sequence is decreasing?",,"['calculus', 'sequences-and-series', 'limits']"
35,Find the value of $\sum_{m=1}^\infty \tan ^ {-1}\frac{2m}{m^4+m^2+2}$,Find the value of,\sum_{m=1}^\infty \tan ^ {-1}\frac{2m}{m^4+m^2+2},How to find value of this sum? $$\sum\limits_{m=1}^\infty \tan^{-1}\left(\frac{2m}{m^4+m^2+2}\right)$$ I can't understand how to simplify this. Should I use any trigonometric substitution to simplify the fraction? Hints and help needed!,How to find value of this sum? I can't understand how to simplify this. Should I use any trigonometric substitution to simplify the fraction? Hints and help needed!,\sum\limits_{m=1}^\infty \tan^{-1}\left(\frac{2m}{m^4+m^2+2}\right),['calculus']
36,Why does my professor say that writing $\int \frac 1x \mathrm{d}x = \ln|x| + C$ is wrong?,Why does my professor say that writing  is wrong?,\int \frac 1x \mathrm{d}x = \ln|x| + C,"My professor says that writing this is convenient $$\int \frac 1x \mathrm{d}x = \ln|x| + C\tag{1}$$ but wrong, since it should be written as: $$\int \frac 1x \mathrm{d}x = \begin{cases}\ln x + C &x > 0\quad(\star)\\[0.2em] \ln(-x) + C &x < 0\end{cases}$$ I was wondering why is that the case. I thought that the two were equivalent, as one can see by the definition of absolute value. In $(\star)$ the equality sign is dropped because the logarithm is not defined in $0$, but that would be the case with $(1)$ as well.","My professor says that writing this is convenient $$\int \frac 1x \mathrm{d}x = \ln|x| + C\tag{1}$$ but wrong, since it should be written as: $$\int \frac 1x \mathrm{d}x = \begin{cases}\ln x + C &x > 0\quad(\star)\\[0.2em] \ln(-x) + C &x < 0\end{cases}$$ I was wondering why is that the case. I thought that the two were equivalent, as one can see by the definition of absolute value. In $(\star)$ the equality sign is dropped because the logarithm is not defined in $0$, but that would be the case with $(1)$ as well.",,"['calculus', 'integration', 'logarithms', 'indefinite-integrals']"
37,The value of $\sqrt{1-\sqrt{1+\sqrt{1-\sqrt{1+\cdots\sqrt{1-\sqrt{1+1}}}}}}$?,The value of ?,\sqrt{1-\sqrt{1+\sqrt{1-\sqrt{1+\cdots\sqrt{1-\sqrt{1+1}}}}}},"How to find value of $\sqrt{1-\sqrt{1+\sqrt{1-\sqrt{1+\cdots\sqrt{1-\sqrt{1+1}}}}}}$ ? I've calculated it by MATLAB for some finite terms and I've got : $0.3001 - 0.4201i$, but I don't know how to find the value analytically! Would you mind helping me find it? Thanks","How to find value of $\sqrt{1-\sqrt{1+\sqrt{1-\sqrt{1+\cdots\sqrt{1-\sqrt{1+1}}}}}}$ ? I've calculated it by MATLAB for some finite terms and I've got : $0.3001 - 0.4201i$, but I don't know how to find the value analytically! Would you mind helping me find it? Thanks",,"['calculus', 'algebra-precalculus', 'problem-solving', 'open-problem']"
38,Show that $\int_{-\pi}^\pi\sin mx\sin nx d x$ is 0 $m\neq n$ and $\pi$ if $m=n$ using integration by parts,Show that  is 0  and  if  using integration by parts,\int_{-\pi}^\pi\sin mx\sin nx d x m\neq n \pi m=n,"Show that  $$\int_{-\pi}^{\pi}\sin{mx}\,\sin{nx}\, d x =\begin{cases} 0&\text{if }m\neq n,\\ \pi&\text{if }m=n. \end{cases}$$ by using integration by parts. I've done the following, but I'm not sure if I went the wrong direction, if I messed up some calculation, or if I'm almost there and just can't see what to do next... $$\int_{-\pi}^{\pi}\sin{mx}\,\sin{nx} \, d x=-\left(\frac{n}{n^2-m}\right)\sin{mx}\cos{nx}+\left(\frac{m}{n^2-m}\right)\cos{mx}\sin{nx}+C$$ $$=-2\left(\frac{n}{n^2-m}\right)\sin{m\pi}\cos{n\pi}+2\left(\frac{m}{n^2-m}\right)\cos{m\pi}\sin{n\pi}$$ Now ... I figure that if $n=m$, then I can just as well replace them all with a 3rd variable... say $z$... $$=-2\left(\frac{z}{z^2-z}\right)\sin{z\pi}\cos{z\pi}+2\left(\frac{z}{z^2-z}\right)\cos{z\pi}\sin{z\pi}$$ Wouldn't that equal 0? Or am I completely mistaken? Addition: By following the suggestions below and using the product-to-sum forumulas, I got the following: $$\frac{1}{2}\int\cos{((n-m)x)}\ dx-\frac{1}{2}\int\cos{((n+m)x)}\ dx=\frac{\sin{((n-m)x)}}{2(n-m)}-\frac{\sin{((n+m)x)}}{2(n+m)}$$ So now if $n=m$, then the first quotient will end up dividing by 0...","Show that  $$\int_{-\pi}^{\pi}\sin{mx}\,\sin{nx}\, d x =\begin{cases} 0&\text{if }m\neq n,\\ \pi&\text{if }m=n. \end{cases}$$ by using integration by parts. I've done the following, but I'm not sure if I went the wrong direction, if I messed up some calculation, or if I'm almost there and just can't see what to do next... $$\int_{-\pi}^{\pi}\sin{mx}\,\sin{nx} \, d x=-\left(\frac{n}{n^2-m}\right)\sin{mx}\cos{nx}+\left(\frac{m}{n^2-m}\right)\cos{mx}\sin{nx}+C$$ $$=-2\left(\frac{n}{n^2-m}\right)\sin{m\pi}\cos{n\pi}+2\left(\frac{m}{n^2-m}\right)\cos{m\pi}\sin{n\pi}$$ Now ... I figure that if $n=m$, then I can just as well replace them all with a 3rd variable... say $z$... $$=-2\left(\frac{z}{z^2-z}\right)\sin{z\pi}\cos{z\pi}+2\left(\frac{z}{z^2-z}\right)\cos{z\pi}\sin{z\pi}$$ Wouldn't that equal 0? Or am I completely mistaken? Addition: By following the suggestions below and using the product-to-sum forumulas, I got the following: $$\frac{1}{2}\int\cos{((n-m)x)}\ dx-\frac{1}{2}\int\cos{((n+m)x)}\ dx=\frac{\sin{((n-m)x)}}{2(n-m)}-\frac{\sin{((n+m)x)}}{2(n+m)}$$ So now if $n=m$, then the first quotient will end up dividing by 0...",,"['calculus', 'integration', 'definite-integrals']"
39,Why does $\int_{0}^{\infty}\frac{dx}{1+(x \sin x)^2}$ diverge?,Why does  diverge?,\int_{0}^{\infty}\frac{dx}{1+(x \sin x)^2},"I'd like your help with understanding and showing why $\int_{0}^{\infty}\frac{dx}{1+(x    \sin x)^2}$ diverges. As I see it the ""problematic spots"" where the function may blow are backed up by the sum with $1$. What can I do in order to show that it does diverge? Thanks a lot!","I'd like your help with understanding and showing why $\int_{0}^{\infty}\frac{dx}{1+(x    \sin x)^2}$ diverges. As I see it the ""problematic spots"" where the function may blow are backed up by the sum with $1$. What can I do in order to show that it does diverge? Thanks a lot!",,['calculus']
40,Partial derivative notation,Partial derivative notation,,"I still have a little problem with notation for partial derivatives. Let $$ f(x,y) = x^2y $$ What do you think that this should equal to? $$ \frac{\partial f}{\partial x}(y,x) =\, ? $$ There are two options $2yx$ or $y^2$ . Do you think that following is the same? $$ \frac{\partial f(y,x)}{\partial x}= \,? $$ And now take substitution $g(x,y)=f(y,x)$ . What is following? $$ \frac{\partial g}{\partial x}(x,y)=\,? $$ I would love to hear your opinions? Based on DanielV comment, I need answer for things like these $$ \frac{\partial f(y,z)}{\partial z} $$ $$ \frac{\partial f(f(y,z),z)}{\partial z} $$ I get constantly confused during physics lectures because of this :(","I still have a little problem with notation for partial derivatives. Let What do you think that this should equal to? There are two options or . Do you think that following is the same? And now take substitution . What is following? I would love to hear your opinions? Based on DanielV comment, I need answer for things like these I get constantly confused during physics lectures because of this :(","
f(x,y) = x^2y
 
\frac{\partial f}{\partial x}(y,x) =\, ?
 2yx y^2 
\frac{\partial f(y,x)}{\partial x}= \,?
 g(x,y)=f(y,x) 
\frac{\partial g}{\partial x}(x,y)=\,?
 
\frac{\partial f(y,z)}{\partial z}
 
\frac{\partial f(f(y,z),z)}{\partial z}
","['calculus', 'notation']"
41,Evaluating $\int_{0}^{\pi/2}\frac{x\sin x\cos x\;dx}{(a^{2}\cos^{2}x+b^{2}\sin^{2}x)^{2}}$,Evaluating,\int_{0}^{\pi/2}\frac{x\sin x\cos x\;dx}{(a^{2}\cos^{2}x+b^{2}\sin^{2}x)^{2}},How to evaluate the following integral $$\int_{0}^{\pi/2}\frac{x\sin x\cos x}{(a^{2}\cos^{2}x+b^{2}\sin^{2}x)^{2}}dx$$ For integrating I took $\cos^{2}x$ outside and applied integration by parts. Given answer is $\dfrac{\pi}{4ab^{2}(a+b)}$. But I am not getting the answer.,How to evaluate the following integral $$\int_{0}^{\pi/2}\frac{x\sin x\cos x}{(a^{2}\cos^{2}x+b^{2}\sin^{2}x)^{2}}dx$$ For integrating I took $\cos^{2}x$ outside and applied integration by parts. Given answer is $\dfrac{\pi}{4ab^{2}(a+b)}$. But I am not getting the answer.,,"['calculus', 'integration', 'trigonometry', 'definite-integrals', 'closed-form']"
42,How to find the limit of these sequences?,How to find the limit of these sequences?,,"Let $\{a_n\}$ be a real-valued sequence such that $a_1 \geq 0$ and $$a_{n+1}=\ln(a_{n}+1)$$ for all $n\ge1$. How can we find the following limits? $$\lim_{n\to \infty}na_n=?,$$ $$\lim_{n\to \infty}\frac{n(na_n-2)}{\ln n}=?$$ Thanks in advance.","Let $\{a_n\}$ be a real-valued sequence such that $a_1 \geq 0$ and $$a_{n+1}=\ln(a_{n}+1)$$ for all $n\ge1$. How can we find the following limits? $$\lim_{n\to \infty}na_n=?,$$ $$\lim_{n\to \infty}\frac{n(na_n-2)}{\ln n}=?$$ Thanks in advance.",,"['calculus', 'limits', 'contest-math']"
43,Strange behavior of $\lim_{x\to0}\frac{\sin\left(x\sin\left(\frac1x\right)\right)}{x\sin\left(\frac1x\right)}$,Strange behavior of,\lim_{x\to0}\frac{\sin\left(x\sin\left(\frac1x\right)\right)}{x\sin\left(\frac1x\right)},"Alright, scratch everything below the line. Let me present one cohesive question not marred by repeated edits. The limit $\lim_{x\to a}f(x)=L$ exists iff for every $\epsilon>0$ there is a $\delta>0$ such that $|f(x)-L|<\epsilon$ when $0<|x-a|<\delta$. Thus, $\lim_{x\to0}\sin\left(\frac1x\right)$ does not exist because, being that it oscillates infinitely near $0$, there is no $\epsilon,\delta$. On the other hand, with the limit$$\lim_{x\to0}\frac{\sin\left(x\sin\left(\frac1x\right)\right)}{x\sin\left(\frac1x\right)}\\\lim_{x\to0}x\sin\left(\frac1x\right)=0\\y=x\sin\left(\frac1x\right)\\\lim_{y\to0}\frac{\sin y}{y}=1\\\lim_{x\to0}\frac{\sin\left(x\sin\left(\frac1x\right)\right)}{x\sin\left(\frac1x\right)}=1$$ this proof can be shown. However, since $\sin\left(\frac1x\right)$ oscillates infinitely, by the same definition of limit we used to show the above, the limit does not exist. How do I resolve this discrepancy?","Alright, scratch everything below the line. Let me present one cohesive question not marred by repeated edits. The limit $\lim_{x\to a}f(x)=L$ exists iff for every $\epsilon>0$ there is a $\delta>0$ such that $|f(x)-L|<\epsilon$ when $0<|x-a|<\delta$. Thus, $\lim_{x\to0}\sin\left(\frac1x\right)$ does not exist because, being that it oscillates infinitely near $0$, there is no $\epsilon,\delta$. On the other hand, with the limit$$\lim_{x\to0}\frac{\sin\left(x\sin\left(\frac1x\right)\right)}{x\sin\left(\frac1x\right)}\\\lim_{x\to0}x\sin\left(\frac1x\right)=0\\y=x\sin\left(\frac1x\right)\\\lim_{y\to0}\frac{\sin y}{y}=1\\\lim_{x\to0}\frac{\sin\left(x\sin\left(\frac1x\right)\right)}{x\sin\left(\frac1x\right)}=1$$ this proof can be shown. However, since $\sin\left(\frac1x\right)$ oscillates infinitely, by the same definition of limit we used to show the above, the limit does not exist. How do I resolve this discrepancy?",,"['calculus', 'limits']"
44,how exactly did calculus change our understanding of the world?,how exactly did calculus change our understanding of the world?,,"I am taking calculus course and I keep wondering if this is really necessary. I know it is the cornerstone of modern science but what I don't understand is why and how. Was it impossible to pursue physics and engineering had calculus not been invented, or without it being applied? What exactly has calculus opened up for us that pre calculus math hadn't?","I am taking calculus course and I keep wondering if this is really necessary. I know it is the cornerstone of modern science but what I don't understand is why and how. Was it impossible to pursue physics and engineering had calculus not been invented, or without it being applied? What exactly has calculus opened up for us that pre calculus math hadn't?",,"['calculus', 'math-history']"
45,Basic Taylor expansion question,Basic Taylor expansion question,,"I seem to have a misunderstanding of how to work with a Taylor series. Suppose I want to write $f(x)=x e^x$'s Taylor expansion of $n$ degree around $0$. I see two ways: 1) Find the $n$th derivative of $f(x)$, this is quite easy: $f^{(n)} (x)=n e^x+x e^x$. And from the formula I get:  $$f(x)=\sum_{k=1}^{n} \frac{x^k}{(k-1)!} + R_{n}(x).$$ 2) Since $e^x$ Taylors expansion is already known, it's also possible to do this: $$f(x)=xe^x=x\left(\sum_{k=0}^{n-1} \frac{x^k}{k!} + R_{n-1}(x)\right)=\sum_{k=0}^{n-1} \frac{x^{k+1}}{k!} + xR_{n-1}(x)$$ But how do I interpret $xR_{n-1}(x)$? I feel like I'm missing something fundamental about the meaning of $R_{n}(x)$.","I seem to have a misunderstanding of how to work with a Taylor series. Suppose I want to write $f(x)=x e^x$'s Taylor expansion of $n$ degree around $0$. I see two ways: 1) Find the $n$th derivative of $f(x)$, this is quite easy: $f^{(n)} (x)=n e^x+x e^x$. And from the formula I get:  $$f(x)=\sum_{k=1}^{n} \frac{x^k}{(k-1)!} + R_{n}(x).$$ 2) Since $e^x$ Taylors expansion is already known, it's also possible to do this: $$f(x)=xe^x=x\left(\sum_{k=0}^{n-1} \frac{x^k}{k!} + R_{n-1}(x)\right)=\sum_{k=0}^{n-1} \frac{x^{k+1}}{k!} + xR_{n-1}(x)$$ But how do I interpret $xR_{n-1}(x)$? I feel like I'm missing something fundamental about the meaning of $R_{n}(x)$.",,"['calculus', 'taylor-expansion']"
46,Integrating $\frac{1}{x}$,Integrating,\frac{1}{x},"There is a general (mis)conception that $$\int \frac{1}{x} \, \mathrm{d}x = \ln|x| + C \label{1} \tag{1}$$ However, taking the indefinite integral as the set of all functions whose derivative is $\frac{1}{x}$ , the technically correct answer should be $$\int \frac{1}{x} \, \mathrm{d}x = \begin{cases}   \ln(x) + C & \text{if $x > 0$} \\    \ln(-x) + D & \text{if $x < 0$}    \end{cases} \label{2} \tag{2}$$ See Your calculus prof lied to you (probably) for more details. Is $\eqref{2}$ correct and is $\eqref{1}$ incorrect? Or are they both acceptable? I suppose $\eqref{2}$ is more correct but it perhaps doesn’t have any additional value compared to $\eqref{1}$ as the definite integral will give the same result for both (as the integral diverges if we move from the negative to positive $x$ -axis). Is there any other example where failing to define a piecewise function (with separate constants) as an integral can have serious consequences?","There is a general (mis)conception that However, taking the indefinite integral as the set of all functions whose derivative is , the technically correct answer should be See Your calculus prof lied to you (probably) for more details. Is correct and is incorrect? Or are they both acceptable? I suppose is more correct but it perhaps doesn’t have any additional value compared to as the definite integral will give the same result for both (as the integral diverges if we move from the negative to positive -axis). Is there any other example where failing to define a piecewise function (with separate constants) as an integral can have serious consequences?","\int \frac{1}{x} \, \mathrm{d}x = \ln|x| + C \label{1} \tag{1} \frac{1}{x} \int \frac{1}{x} \, \mathrm{d}x = \begin{cases} 
 \ln(x) + C & \text{if x > 0} \\  
 \ln(-x) + D & \text{if x < 0}  
 \end{cases} \label{2} \tag{2} \eqref{2} \eqref{1} \eqref{2} \eqref{1} x",['calculus']
47,Why is $\int_{0}^{1}{(1+x^2)^n dx} \sim \frac{2^n}{n} $?,Why is ?,\int_{0}^{1}{(1+x^2)^n dx} \sim \frac{2^n}{n} ,"By $a_n \sim b_n$ I mean that $\lim_{n \rightarrow \infty} \frac{a_n}{b_n} = 1$ . I don't know how to do this problem. I have tried to apply binomial theorem and I got $$\int_{0}^{1}{(1+x^2)^n dx} = \int_0^1 \sum_{k=0}^n{\binom{n}{k}x^{2k}dx} = \sum_{k=0}^n \int_0^1{ \binom{n}{k}x^{2k}dx} = \sum_{k=0}^n  \frac {\binom{n}{k}}{2k+1}$$ But I don't know what I could do with this, nor if it is a correct approach.","By I mean that . I don't know how to do this problem. I have tried to apply binomial theorem and I got But I don't know what I could do with this, nor if it is a correct approach.",a_n \sim b_n \lim_{n \rightarrow \infty} \frac{a_n}{b_n} = 1 \int_{0}^{1}{(1+x^2)^n dx} = \int_0^1 \sum_{k=0}^n{\binom{n}{k}x^{2k}dx} = \sum_{k=0}^n \int_0^1{ \binom{n}{k}x^{2k}dx} = \sum_{k=0}^n  \frac {\binom{n}{k}}{2k+1},"['calculus', 'integration', 'limits']"
48,Is there a rapider or more elegant way to evaluate $\int_0^{+\infty} \frac{\cos(\pi x)\ \text{d}x}{e^{2\pi \sqrt{x}}-1}$?,Is there a rapider or more elegant way to evaluate ?,\int_0^{+\infty} \frac{\cos(\pi x)\ \text{d}x}{e^{2\pi \sqrt{x}}-1},"$$\int_0^{+\infty} \frac{\cos(\pi x)\ \text{d}x}{e^{2\pi \sqrt{x}}-1}$$ First attempt $x\to t^2$ Geometric series by writing the denominator as $e^{2\pi t}(1 - e^{-2\pi t})$ $\cos(\pi t^2) = \Re e^{i\pi t^2}$ This leads me to $$2\sum_{k = 0}^{+\infty} \int_0^{+\infty} t e^{i\pi t^2}e^{-\alpha t}\ \text{d}t$$ Where $\alpha = 2\pi (k+1)$. Now I thought about writing it again as $$-2\sum_{k = 0}^{+\infty}\frac{d}{d\alpha} \int_0^{+\infty} e^{i\pi t^2}e^{-\alpha t}\ \text{d}t$$ The last integral can be evaluated with the use of the Imaginary Error Function, hence a Special Function method. Yet it doesn't seem me the best way. Second Attempt Basically like the previous one with the difference that $\cos( \cdot )$ stays as it; $\pi t^2 \to z$; And this brings $$-\frac{1}{\sqrt{\pi}}\frac{d}{d\alpha} \sum_{k = 0}^{+\infty}\int_0^{+\infty} \frac{\cos(z)}{z} e^{-\alpha \sqrt{\frac{z}{\pi}}}\ \text{d}z$$ But in both cases what I am thinking are just numerical methods. Or at least I could give a try with the stationary phase but... meh. I don't know if I can use residues for this, actually. Even if taking a look at the initial integral, there is this additional way: $$\frac{1}{e^{2\pi t} -1} = \frac{1}{(e^{\pi t}+1)(e^{\pi t}-1)}$$ Which for example has a pole at $t = +i$... But using residues I would obtain $$\pi \cos(\pi)$$ Where as the correct numerical result (which I checked with Mathematica) is $$\color{blue}{0.0732233(...)}$$ And it seems there is not a closed form for this. Any hint/help?","$$\int_0^{+\infty} \frac{\cos(\pi x)\ \text{d}x}{e^{2\pi \sqrt{x}}-1}$$ First attempt $x\to t^2$ Geometric series by writing the denominator as $e^{2\pi t}(1 - e^{-2\pi t})$ $\cos(\pi t^2) = \Re e^{i\pi t^2}$ This leads me to $$2\sum_{k = 0}^{+\infty} \int_0^{+\infty} t e^{i\pi t^2}e^{-\alpha t}\ \text{d}t$$ Where $\alpha = 2\pi (k+1)$. Now I thought about writing it again as $$-2\sum_{k = 0}^{+\infty}\frac{d}{d\alpha} \int_0^{+\infty} e^{i\pi t^2}e^{-\alpha t}\ \text{d}t$$ The last integral can be evaluated with the use of the Imaginary Error Function, hence a Special Function method. Yet it doesn't seem me the best way. Second Attempt Basically like the previous one with the difference that $\cos( \cdot )$ stays as it; $\pi t^2 \to z$; And this brings $$-\frac{1}{\sqrt{\pi}}\frac{d}{d\alpha} \sum_{k = 0}^{+\infty}\int_0^{+\infty} \frac{\cos(z)}{z} e^{-\alpha \sqrt{\frac{z}{\pi}}}\ \text{d}z$$ But in both cases what I am thinking are just numerical methods. Or at least I could give a try with the stationary phase but... meh. I don't know if I can use residues for this, actually. Even if taking a look at the initial integral, there is this additional way: $$\frac{1}{e^{2\pi t} -1} = \frac{1}{(e^{\pi t}+1)(e^{\pi t}-1)}$$ Which for example has a pole at $t = +i$... But using residues I would obtain $$\pi \cos(\pi)$$ Where as the correct numerical result (which I checked with Mathematica) is $$\color{blue}{0.0732233(...)}$$ And it seems there is not a closed form for this. Any hint/help?",,"['calculus', 'integration', 'definite-integrals', 'special-functions', 'residue-calculus']"
49,Computing $\sum _{ k=1 }^{ \infty }{ \sum _{ n=0 }^{ \infty }{ \frac { 1 }{ { k\left( k+n \right) }^{ 2 } } } } $,Computing,\sum _{ k=1 }^{ \infty }{ \sum _{ n=0 }^{ \infty }{ \frac { 1 }{ { k\left( k+n \right) }^{ 2 } } } } ,While solving a problem I encountered this: $$\sum _{ k=1 }^{ \infty  }{ \sum _{ n=0 }^{ \infty  }{ \frac { 1 }{ { k\left( k+n \right)  }^{ 2 } }  }  } $$ For this I tried the following: $$\sum _{ k=1 }^{ \infty  }{ \sum _{ n=0 }^{ \infty  }{ \frac { 1 }{ { k\left( k+n \right)  }^{ 2 } }  }  } =\sum _{ k=1 }^{ \infty  }{ \sum _{ n=1 }^{ \infty  }{ \frac { 1 }{ { k\left( k+n \right)  }^{ 2 } }  }  } +\zeta \left( 3 \right) =\sum _{ k=1 }^{ \infty  }{ \sum _{ n=1 }^{ k }{ \frac { 1 }{ { k\left( n \right)  }^{ 2 } }  }  } +\zeta \left( 3 \right)  $$ From here I couldn't proceed. I'm new to multiple summations. Please help.,While solving a problem I encountered this: $$\sum _{ k=1 }^{ \infty  }{ \sum _{ n=0 }^{ \infty  }{ \frac { 1 }{ { k\left( k+n \right)  }^{ 2 } }  }  } $$ For this I tried the following: $$\sum _{ k=1 }^{ \infty  }{ \sum _{ n=0 }^{ \infty  }{ \frac { 1 }{ { k\left( k+n \right)  }^{ 2 } }  }  } =\sum _{ k=1 }^{ \infty  }{ \sum _{ n=1 }^{ \infty  }{ \frac { 1 }{ { k\left( k+n \right)  }^{ 2 } }  }  } +\zeta \left( 3 \right) =\sum _{ k=1 }^{ \infty  }{ \sum _{ n=1 }^{ k }{ \frac { 1 }{ { k\left( n \right)  }^{ 2 } }  }  } +\zeta \left( 3 \right)  $$ From here I couldn't proceed. I'm new to multiple summations. Please help.,,"['calculus', 'sequences-and-series', 'summation']"
50,Can we speak of derivatives of sets?,Can we speak of derivatives of sets?,,"Suppose we have a monotone sequence of sets: $$A_1,\ldots,A_n$$ $$A_i \subseteq A_{i+1}$$ I think this is a function from $\mathbb N$ to a space of sets. Can we define a function from $\mathbb R$ to a space of sets? Could we then define a derivative of this function?","Suppose we have a monotone sequence of sets: $$A_1,\ldots,A_n$$ $$A_i \subseteq A_{i+1}$$ I think this is a function from $\mathbb N$ to a space of sets. Can we define a function from $\mathbb R$ to a space of sets? Could we then define a derivative of this function?",,['calculus']
51,Integral becomes improper after a substitution,Integral becomes improper after a substitution,,"I'm suprised about the following phenomenon which I would like to discuss with you. Consider the proper integral $$\int_{\pi/4}^{\pi/2}\frac{1}{\sin(x)}dx.$$ Since $\sin(x)$ is a diffeomorphism on the interval $(\pi/4,\pi/2)$ we can make the substitution $\phi(x):=\arcsin(x)$. Since $d\phi(x)=\frac{dx}{\cos(\arcsin(x))}=\frac{dx}{\sqrt{1-x^2}}$ we get: $$\int_{\pi/4}^{\pi/2}\frac{1}{\sin(x)}dx=\int_{1/\sqrt{2}}^{1}\frac{1}{x\cdot \sqrt{1-x^2}}dx.$$ Suddenly the integral becomes improper, which feels somehow 'wrong' to me. But I do not think that there is a mistake in the argumentation which leads from the initial integral to the improper, new one. Do you know further examples similar to the above one? I hope someone of you can help me to eliminate my 'uncomfortable' or 'wrong' freeling about this situation, for -as the calculation shows- the situation is quite natural. Best wishes edit: Another (maybe more familiar) notation to write the substitution would be: $z:=\sin(x)\Rightarrow dz=\cos(x)dx=\sqrt{1-z^2}dx\Rightarrow \frac{dz}{\sqrt{1-z^2}}=dx$. Hence we get the integral $$\int_{1/\sqrt{2}}^{1}\frac{1}{z\cdot\sqrt{1-z^2}}dz$$","I'm suprised about the following phenomenon which I would like to discuss with you. Consider the proper integral $$\int_{\pi/4}^{\pi/2}\frac{1}{\sin(x)}dx.$$ Since $\sin(x)$ is a diffeomorphism on the interval $(\pi/4,\pi/2)$ we can make the substitution $\phi(x):=\arcsin(x)$. Since $d\phi(x)=\frac{dx}{\cos(\arcsin(x))}=\frac{dx}{\sqrt{1-x^2}}$ we get: $$\int_{\pi/4}^{\pi/2}\frac{1}{\sin(x)}dx=\int_{1/\sqrt{2}}^{1}\frac{1}{x\cdot \sqrt{1-x^2}}dx.$$ Suddenly the integral becomes improper, which feels somehow 'wrong' to me. But I do not think that there is a mistake in the argumentation which leads from the initial integral to the improper, new one. Do you know further examples similar to the above one? I hope someone of you can help me to eliminate my 'uncomfortable' or 'wrong' freeling about this situation, for -as the calculation shows- the situation is quite natural. Best wishes edit: Another (maybe more familiar) notation to write the substitution would be: $z:=\sin(x)\Rightarrow dz=\cos(x)dx=\sqrt{1-z^2}dx\Rightarrow \frac{dz}{\sqrt{1-z^2}}=dx$. Hence we get the integral $$\int_{1/\sqrt{2}}^{1}\frac{1}{z\cdot\sqrt{1-z^2}}dz$$",,"['calculus', 'integration', 'improper-integrals', 'transformation', 'substitution']"
52,A closed form for $\sum\limits_n(e-(1+1/n)^n)$,A closed form for,\sum\limits_n(e-(1+1/n)^n),"I have been having some trouble trying to find a closed form for this sum. It seems to converge really slowly. Find a closed form for $$S=\sum_{n=1}^\infty\left[e-\left(1+\dfrac{1}{n}\right)^n\right].$$ All I got so far is $$ \begin{align} e-\left(1+\dfrac{1}{n}\right)^{n} & = \sum_{k=0}^\infty\frac{1}{k!} -\sum_{k=0}^n\binom{n}{k}\frac{1}{n^{k}} \\ & = \sum_{k=0}^\infty\frac{1}{k!}\left(1-\dfrac{n!}{(n-k)!}\dfrac{1}{n^k}\right) \\ & = \sum_{k=0}^\infty\frac{1}{k!}\left(1-\dfrac{(n)_k}{n^k}\right) \\ \end{align}, $$ $$ S=\sum_{k=0}^\infty\frac{1}{k!}\sum_{n=1}^\infty\left(1-\dfrac{(n)_k}{n^k}\right). $$ Where $(n)_k$ is the Pochhammer symbol. But I don not know how I could carry on from here.","I have been having some trouble trying to find a closed form for this sum. It seems to converge really slowly. Find a closed form for $$S=\sum_{n=1}^\infty\left[e-\left(1+\dfrac{1}{n}\right)^n\right].$$ All I got so far is $$ \begin{align} e-\left(1+\dfrac{1}{n}\right)^{n} & = \sum_{k=0}^\infty\frac{1}{k!} -\sum_{k=0}^n\binom{n}{k}\frac{1}{n^{k}} \\ & = \sum_{k=0}^\infty\frac{1}{k!}\left(1-\dfrac{n!}{(n-k)!}\dfrac{1}{n^k}\right) \\ & = \sum_{k=0}^\infty\frac{1}{k!}\left(1-\dfrac{(n)_k}{n^k}\right) \\ \end{align}, $$ $$ S=\sum_{k=0}^\infty\frac{1}{k!}\sum_{n=1}^\infty\left(1-\dfrac{(n)_k}{n^k}\right). $$ Where $(n)_k$ is the Pochhammer symbol. But I don not know how I could carry on from here.",,"['calculus', 'sequences-and-series', 'closed-form']"
53,"Closed-form of $\int_0^1 \operatorname{Li}_p(x) \, dx$",Closed-form of,"\int_0^1 \operatorname{Li}_p(x) \, dx","While I've studied integrals involving polylogarithm functions I've observed that $$\int_0^1 \operatorname{Li}_p(x) \, dx \stackrel{?}{=} \sum_{k=2}^p(-1)^{p+k}\zeta(k)+(-1)^{p+1},\tag{1}$$ for any integer $p\geq2$. Here $\zeta$ is the Riemann zeta function . After that I have three questions. $1^\text{st}$ Question. Is $(1)$ true? If it is, how could we prove it? $2^\text{nd}$ Question. If it's a well-known result could you give any reference? $3^\text{rd}$ Question. I think there is also a similar closed-form of $\int_0^b \operatorname{Li}_p(x) \, dx$, for any integer $b \geq 1$. What is the closed-form of this integral?","While I've studied integrals involving polylogarithm functions I've observed that $$\int_0^1 \operatorname{Li}_p(x) \, dx \stackrel{?}{=} \sum_{k=2}^p(-1)^{p+k}\zeta(k)+(-1)^{p+1},\tag{1}$$ for any integer $p\geq2$. Here $\zeta$ is the Riemann zeta function . After that I have three questions. $1^\text{st}$ Question. Is $(1)$ true? If it is, how could we prove it? $2^\text{nd}$ Question. If it's a well-known result could you give any reference? $3^\text{rd}$ Question. I think there is also a similar closed-form of $\int_0^b \operatorname{Li}_p(x) \, dx$, for any integer $b \geq 1$. What is the closed-form of this integral?",,"['calculus', 'definite-integrals', 'special-functions', 'closed-form', 'polylogarithm']"
54,Limit of $\int_0^1\frac1x B_{2n+1}\left(\left\{\frac1x\right\}\right)dx$,Limit of,\int_0^1\frac1x B_{2n+1}\left(\left\{\frac1x\right\}\right)dx,"Set $$u_n= \int_0^1 \frac{B_{2n+1}\left(\left\{\frac1x\right\}\right)}{x}dx\tag1$$ where $\left\{t\right\}=t-\lfloor t \rfloor$ denotes the fractional part of $t$ and where $B_n(\cdot)$ are the Bernoulli polynomials: $$ \begin{aligned}B_{1}(x)&=x-\frac12\\B_{3}(x)&=x^3-\frac32x^2+\frac12x\\\ldots\,&= \ldots\end{aligned}$$ I'm interested in finding $\lim\limits_{n \to +\infty}|u_n|.$  I've tried to see what Wolfram|Alpha gives with no success. My guess is that $$\lim\limits_{n \to +\infty}|u_n|=+\infty. \tag2$$ Could you prove/disprove $(2)$? Thank you.","Set $$u_n= \int_0^1 \frac{B_{2n+1}\left(\left\{\frac1x\right\}\right)}{x}dx\tag1$$ where $\left\{t\right\}=t-\lfloor t \rfloor$ denotes the fractional part of $t$ and where $B_n(\cdot)$ are the Bernoulli polynomials: $$ \begin{aligned}B_{1}(x)&=x-\frac12\\B_{3}(x)&=x^3-\frac32x^2+\frac12x\\\ldots\,&= \ldots\end{aligned}$$ I'm interested in finding $\lim\limits_{n \to +\infty}|u_n|.$  I've tried to see what Wolfram|Alpha gives with no success. My guess is that $$\lim\limits_{n \to +\infty}|u_n|=+\infty. \tag2$$ Could you prove/disprove $(2)$? Thank you.",,"['calculus', 'integration', 'sequences-and-series', 'convergence-divergence']"
55,Prove that the unit circle is path-connected?,Prove that the unit circle is path-connected?,,"I need to show that the unit circle is path connected and connected.  I was able to show that it is connected, by $f:[0,2\pi] \to \mathbb{R}^2$, $f(x)=(r\cos x,r \sin x)$ which is a continuous function. The interval $[0,2\pi]$ is connected and the continuous image of a connected set is connected.  Thus the unit circle is connected.  I'm not sure how to prove path-connectedness, which is the stronger condition.  Thanks!","I need to show that the unit circle is path connected and connected.  I was able to show that it is connected, by $f:[0,2\pi] \to \mathbb{R}^2$, $f(x)=(r\cos x,r \sin x)$ which is a continuous function. The interval $[0,2\pi]$ is connected and the continuous image of a connected set is connected.  Thus the unit circle is connected.  I'm not sure how to prove path-connectedness, which is the stronger condition.  Thanks!",,['calculus']
56,Prove $\int_0^{\pi/4} \frac{x \cos 2x}{1-\sin x} \mathrm dx > \frac{1}{4}$,Prove,\int_0^{\pi/4} \frac{x \cos 2x}{1-\sin x} \mathrm dx > \frac{1}{4},"How can I prove this inequality : $$\int_0^{\frac{\pi}{4}} \frac{x \cos(2x)}{1-\sin(x)} \mathrm{d}x > \frac{1}{4}.$$ It was given by my teacher as a challenge but I can't figure out that how to solve it. For indefinite integral, Usual substitution fails and the product $x\cos(2x)$ hints integration by part , but it made it only uglier and hence unsuccessful. Please give a hint or an insightful answer through which it can be easily proven. Thanks !","How can I prove this inequality : It was given by my teacher as a challenge but I can't figure out that how to solve it. For indefinite integral, Usual substitution fails and the product hints integration by part , but it made it only uglier and hence unsuccessful. Please give a hint or an insightful answer through which it can be easily proven. Thanks !",\int_0^{\frac{\pi}{4}} \frac{x \cos(2x)}{1-\sin(x)} \mathrm{d}x > \frac{1}{4}. x\cos(2x),"['calculus', 'integration', 'inequality', 'definite-integrals']"
57,"Prove $\int_{\mathbb{R}^n}e^{-\max\{|x_1|,\ldots,|x_n|\}}dx=2^nn!$",Prove,"\int_{\mathbb{R}^n}e^{-\max\{|x_1|,\ldots,|x_n|\}}dx=2^nn!","Prove $\int_{\mathbb{R}^n}e^{-\max\{|x_1|,\ldots,|x_n|\}}dx=2^nn!$ My attempt: On the region where $x_1$ has the largest absolute value $\int_{\mathbb{R}^n}e^{-\max\{|x_1|,\ldots,|x_n|\}}=2^n\int_{\mathbb{R}^n}e^{-|x_1|}dx=2^n\int_0^{\infty}\int_{\mathbb{S}^{n-1}_r}e^{-|x_1|}dSdr$ But I got stuck here.",Prove My attempt: On the region where has the largest absolute value But I got stuck here.,"\int_{\mathbb{R}^n}e^{-\max\{|x_1|,\ldots,|x_n|\}}dx=2^nn! x_1 \int_{\mathbb{R}^n}e^{-\max\{|x_1|,\ldots,|x_n|\}}=2^n\int_{\mathbb{R}^n}e^{-|x_1|}dx=2^n\int_0^{\infty}\int_{\mathbb{S}^{n-1}_r}e^{-|x_1|}dSdr","['calculus', 'integration']"
58,Derivative of $(x-1)(x-2)(x-3) \cdots (x-10)$ at $x=6$,Derivative of  at,(x-1)(x-2)(x-3) \cdots (x-10) x=6,"I can see that by applying the product rule, all resulting expressions containing $(x-6)$ would become zero, hence leaving $(1)(x-1)(x-2)(x-3)(x-4)(x-5)(x-7)(x-8)(x-9)(x-10)$, which, at $x=6$, is $2880$. However, I'm not sure how to formally write out a concise method for finding this solution.","I can see that by applying the product rule, all resulting expressions containing $(x-6)$ would become zero, hence leaving $(1)(x-1)(x-2)(x-3)(x-4)(x-5)(x-7)(x-8)(x-9)(x-10)$, which, at $x=6$, is $2880$. However, I'm not sure how to formally write out a concise method for finding this solution.",,"['calculus', 'derivatives', 'polynomials']"
59,Derivative of multivariate normal distribution wrt mean and covariance,Derivative of multivariate normal distribution wrt mean and covariance,,"I want to differentiate this wrt $\mu$ and $\Sigma$ : $${1\over \sqrt{(2\pi)^k |\Sigma |}} e^{-0.5 (x-\mu)^T \Sigma^{-1} (x-\mu)} $$ I'm following the matrix cookbook here and also this answer . The solution given in the answer (2nd link), doesn't match with what I read in the cookbook. For example, for this term, if I follow rule 81 from the linked cookbook, I get a different answer (differentiating wrt $\mu$) : $(x-\mu)^T \Sigma^{-1} (x-\mu)$ According to the cookbook, the answer should be : $-(\Sigma^{-1} + \Sigma^{-T}) (x-\mu)$ . Or, am I missing something here? Also, how do I differentiate $(x-\mu)^T \Sigma^{-1} (x-\mu)$ with respect to $\Sigma$ ?","I want to differentiate this wrt $\mu$ and $\Sigma$ : $${1\over \sqrt{(2\pi)^k |\Sigma |}} e^{-0.5 (x-\mu)^T \Sigma^{-1} (x-\mu)} $$ I'm following the matrix cookbook here and also this answer . The solution given in the answer (2nd link), doesn't match with what I read in the cookbook. For example, for this term, if I follow rule 81 from the linked cookbook, I get a different answer (differentiating wrt $\mu$) : $(x-\mu)^T \Sigma^{-1} (x-\mu)$ According to the cookbook, the answer should be : $-(\Sigma^{-1} + \Sigma^{-T}) (x-\mu)$ . Or, am I missing something here? Also, how do I differentiate $(x-\mu)^T \Sigma^{-1} (x-\mu)$ with respect to $\Sigma$ ?",,"['calculus', 'matrices', 'derivatives']"
60,How to find $\int_{-1}^1 \frac{\cos x}{a^x+1}\mathrm dx$,How to find,\int_{-1}^1 \frac{\cos x}{a^x+1}\mathrm dx,Evaluate $$\int_{-1}^1 \frac{\cos x}{a^x+1}\mathrm dx$$ where $a$ is a real parameter $a\geq1$. I can easily find the definite integral for $a=1$. It is $\sin(1)$. In wolframalpha.com when I put $\displaystyle\int_{-1}^1 \frac{\cos x}{a^x+1}\text{d}x$ it shows me a very complicated formula with complex numbers and functions I didn't study but it says that definite integral is $= 0.841471\ldots$. How can I find that integral?,Evaluate $$\int_{-1}^1 \frac{\cos x}{a^x+1}\mathrm dx$$ where $a$ is a real parameter $a\geq1$. I can easily find the definite integral for $a=1$. It is $\sin(1)$. In wolframalpha.com when I put $\displaystyle\int_{-1}^1 \frac{\cos x}{a^x+1}\text{d}x$ it shows me a very complicated formula with complex numbers and functions I didn't study but it says that definite integral is $= 0.841471\ldots$. How can I find that integral?,,"['calculus', 'integration', 'definite-integrals']"
61,Calculate $f^{(25)}(0)$ for $f(x)=x^2 \sin(x)$,Calculate  for,f^{(25)}(0) f(x)=x^2 \sin(x),"Calculate $f^{(25)}(0)$ for $f(x)=x^2 \sin(x)$. The answer is too short for me to understand, and the answer is $- 25 \cdot 24 \cdot 8^{23}$","Calculate $f^{(25)}(0)$ for $f(x)=x^2 \sin(x)$. The answer is too short for me to understand, and the answer is $- 25 \cdot 24 \cdot 8^{23}$",,['calculus']
62,What is the purpose of the limit?,What is the purpose of the limit?,,"I haven't taken Calculas yet, but I see the use of limit (approaching zero or infinity) in other classes such as physics. I just wanted some intuitive explanation of the limit. I was thinking that theoretically, infinity or zero would make sense, but when we have real world problems, there's always some sort of limitation which is why we have to use these things. Is this understanding of mine correct?","I haven't taken Calculas yet, but I see the use of limit (approaching zero or infinity) in other classes such as physics. I just wanted some intuitive explanation of the limit. I was thinking that theoretically, infinity or zero would make sense, but when we have real world problems, there's always some sort of limitation which is why we have to use these things. Is this understanding of mine correct?",,"['calculus', 'soft-question']"
63,Incorrect manipulation of limits,Incorrect manipulation of limits,,"Here's my manipulation of a particular limit: $\displaystyle \lim\limits_{h\rightarrow 0}\Big[\frac{f(x+h)g(x) - f(x)g(x+h)}{h}\Big]$ Using the properties of limits: $\displaystyle \begin{align*} &=\frac{\lim\limits_{h\rightarrow 0}\Big[f(x+h)g(x) - f(x)g(x+h)\Big]}{\lim\limits_{h\rightarrow 0}h}\\ &=\frac{\lim\limits_{h\rightarrow 0}\Big[f(x+h)g(x)\Big] - \lim\limits_{h\rightarrow 0}\Big[f(x)g(x+h)\Big]}{\lim\limits_{h\rightarrow 0}h}\\ &=\frac{\lim\limits_{h\rightarrow 0}\Big[f(x+h)\Big]\lim\limits_{h\rightarrow 0}\Big[g(x)\Big] - \lim\limits_{h\rightarrow 0}\Big[f(x)\Big]\lim\limits_{h\rightarrow 0}\Big[g(x+h)\Big]}{\lim\limits_{h\rightarrow 0}h}\\ &=\frac{f(x)\lim\limits_{h\rightarrow 0}\Big[g(x)\Big] - f(x)\lim\limits_{h\rightarrow 0}\Big[g(x+h)\Big]}{\lim\limits_{h\rightarrow 0}h}\\ &=\frac{f(x)\Big(\lim\limits_{h\rightarrow 0}\Big[g(x)\Big] - \lim\limits_{h\rightarrow 0}\Big[g(x+h)\Big]\Big)}{\lim\limits_{h\rightarrow 0}h}\\ &=\frac{f(x)\Big(\lim\limits_{h\rightarrow 0}\Big[g(x) - g(x+h)\Big]\Big)}{\lim\limits_{h\rightarrow 0}h}\\ &=f(x)\lim\limits_{h\rightarrow 0}\Big(\frac{g(x) - g(x+h)}{h}\Big)\\ &=-f(x)g'(x)\end{align*}$ I'm pretty sure that my end result is incorrect, as I've used arbitrary functions for $f(x)$ and $g(x)$ and it didn't support my conclusion. I think that the factoring of $f(x)$ might be what is incorrect in my manipulation, but I'm not 100% sure. Could someone explain to me what I did wrong and why it is wrong? Which one of the limit ""axioms"" did I use incorrectly? Thank you.","Here's my manipulation of a particular limit: $\displaystyle \lim\limits_{h\rightarrow 0}\Big[\frac{f(x+h)g(x) - f(x)g(x+h)}{h}\Big]$ Using the properties of limits: $\displaystyle \begin{align*} &=\frac{\lim\limits_{h\rightarrow 0}\Big[f(x+h)g(x) - f(x)g(x+h)\Big]}{\lim\limits_{h\rightarrow 0}h}\\ &=\frac{\lim\limits_{h\rightarrow 0}\Big[f(x+h)g(x)\Big] - \lim\limits_{h\rightarrow 0}\Big[f(x)g(x+h)\Big]}{\lim\limits_{h\rightarrow 0}h}\\ &=\frac{\lim\limits_{h\rightarrow 0}\Big[f(x+h)\Big]\lim\limits_{h\rightarrow 0}\Big[g(x)\Big] - \lim\limits_{h\rightarrow 0}\Big[f(x)\Big]\lim\limits_{h\rightarrow 0}\Big[g(x+h)\Big]}{\lim\limits_{h\rightarrow 0}h}\\ &=\frac{f(x)\lim\limits_{h\rightarrow 0}\Big[g(x)\Big] - f(x)\lim\limits_{h\rightarrow 0}\Big[g(x+h)\Big]}{\lim\limits_{h\rightarrow 0}h}\\ &=\frac{f(x)\Big(\lim\limits_{h\rightarrow 0}\Big[g(x)\Big] - \lim\limits_{h\rightarrow 0}\Big[g(x+h)\Big]\Big)}{\lim\limits_{h\rightarrow 0}h}\\ &=\frac{f(x)\Big(\lim\limits_{h\rightarrow 0}\Big[g(x) - g(x+h)\Big]\Big)}{\lim\limits_{h\rightarrow 0}h}\\ &=f(x)\lim\limits_{h\rightarrow 0}\Big(\frac{g(x) - g(x+h)}{h}\Big)\\ &=-f(x)g'(x)\end{align*}$ I'm pretty sure that my end result is incorrect, as I've used arbitrary functions for $f(x)$ and $g(x)$ and it didn't support my conclusion. I think that the factoring of $f(x)$ might be what is incorrect in my manipulation, but I'm not 100% sure. Could someone explain to me what I did wrong and why it is wrong? Which one of the limit ""axioms"" did I use incorrectly? Thank you.",,"['calculus', 'limits']"
64,"Is ""$f$"" the function or is ""$f(x)$"" the function? [duplicate]","Is """" the function or is """" the function? [duplicate]",f f(x),"This question already has answers here : A nomenclature issue in Complex Analysis, what is difference between between writing ""f(z)"" and ""f""? (5 answers) Closed 5 years ago . This may be a weak question but I'm just confused on what the function actually is. Say we have $f(x) = x^2$ . So what is the function? $x^2$ ? $f$ ? $f(x)$ ? $f(x) = x^2$ ? I just always thought that $f(x)$ is what we refer to as the function but my textbook for calculus says stuff like ""if there exists functions $f$ where ...""","This question already has answers here : A nomenclature issue in Complex Analysis, what is difference between between writing ""f(z)"" and ""f""? (5 answers) Closed 5 years ago . This may be a weak question but I'm just confused on what the function actually is. Say we have . So what is the function? ? ? ? ? I just always thought that is what we refer to as the function but my textbook for calculus says stuff like ""if there exists functions where ...""",f(x) = x^2 x^2 f f(x) f(x) = x^2 f(x) f,"['calculus', 'functions', 'notation', 'terminology']"
65,Minimizing a quadratic function subject to quadratic constraints,Minimizing a quadratic function subject to quadratic constraints,,"Okay, so I am attempting to minimize the function $$f(x,y, z) = x^2 + y^2 + z^2$$ subject to the constraint of $$4x^2 + 2y^2 +z^2 = 4$$ I attempted to solve using Lagrange multiplier method, but was unable to find a $\lambda$ that made the system consistent. $$2x = \lambda8x$$ $$2y = \lambda4y$$ $$2z = \lambda2z$$ Wouldn't it be the case that the first equation suggests $\lambda = 1/4$ but the second equation suggests $\lambda = 1/2$? I am unsure of where to go from here although I have spent time trying to figure out. Intuitively, I know that it must be the case that the minimum occurs at $(1,0,0)$ and is equal to $1$, but I can not show this using mathematical reasoning.","Okay, so I am attempting to minimize the function $$f(x,y, z) = x^2 + y^2 + z^2$$ subject to the constraint of $$4x^2 + 2y^2 +z^2 = 4$$ I attempted to solve using Lagrange multiplier method, but was unable to find a $\lambda$ that made the system consistent. $$2x = \lambda8x$$ $$2y = \lambda4y$$ $$2z = \lambda2z$$ Wouldn't it be the case that the first equation suggests $\lambda = 1/4$ but the second equation suggests $\lambda = 1/2$? I am unsure of where to go from here although I have spent time trying to figure out. Intuitively, I know that it must be the case that the minimum occurs at $(1,0,0)$ and is equal to $1$, but I can not show this using mathematical reasoning.",,"['calculus', 'multivariable-calculus', 'optimization', 'lagrange-multiplier', 'qcqp']"
66,Are there any conditions of integration?,Are there any conditions of integration?,,"When we differentiate a function $f(x)$, there are conditions under which the derivative would not exist and cannot become differentiable. However, I have tried looking online for any conditions for integration and I haven't found anything. Are there any cases where $F(x)$ does not exist from $\int f(x)dx$? In other words, what makes a function non-integrable?","When we differentiate a function $f(x)$, there are conditions under which the derivative would not exist and cannot become differentiable. However, I have tried looking online for any conditions for integration and I haven't found anything. Are there any cases where $F(x)$ does not exist from $\int f(x)dx$? In other words, what makes a function non-integrable?",,['calculus']
67,Evaluating the indefinite integral $\int\log\!\left(x+\sqrt{x^2-1}\right)\!dx$,Evaluating the indefinite integral,\int\log\!\left(x+\sqrt{x^2-1}\right)\!dx,"I came across the following integral, and I don't know how to solve it. $$ \int\log\left(x+\sqrt{x^2-1}\right)dx $$ I tried the ""obvious"" substitution of $x=\sec\theta$, which gives you: $$ \int\tan\theta\sec\theta\log\left(\tan\theta+\sec\theta\right)d\theta $$ However, this doesn't simplify it much, in the sense that I have no idea how to solve this now! Take out the common factor of $\sec$ from the log, or perhaps do $u=\tan\theta+\sec\theta$, but both of these lead to dead ends (at least for me). In case you are wondering, Wolfram|Alpha claims the answer is: $$x\log\left(x+\sqrt{x^2-1}\right)-\sqrt{x^2-1}+c$$","I came across the following integral, and I don't know how to solve it. $$ \int\log\left(x+\sqrt{x^2-1}\right)dx $$ I tried the ""obvious"" substitution of $x=\sec\theta$, which gives you: $$ \int\tan\theta\sec\theta\log\left(\tan\theta+\sec\theta\right)d\theta $$ However, this doesn't simplify it much, in the sense that I have no idea how to solve this now! Take out the common factor of $\sec$ from the log, or perhaps do $u=\tan\theta+\sec\theta$, but both of these lead to dead ends (at least for me). In case you are wondering, Wolfram|Alpha claims the answer is: $$x\log\left(x+\sqrt{x^2-1}\right)-\sqrt{x^2-1}+c$$",,"['calculus', 'integration', 'indefinite-integrals']"
68,Limit of $x^2\sin\left(\ln\sqrt{\cos\frac{\pi}{x}}\right)$,Limit of,x^2\sin\left(\ln\sqrt{\cos\frac{\pi}{x}}\right),Find $$\lim_{x\to\infty}x^2\sin\left(\ln\sqrt{\cos\frac{\pi}{x}}\right).$$ I tried substituting $x=1/t$ with $t$ approaching $0$ but the term inside the bracket is not giving me ideas on how to compute the limit.,Find $$\lim_{x\to\infty}x^2\sin\left(\ln\sqrt{\cos\frac{\pi}{x}}\right).$$ I tried substituting $x=1/t$ with $t$ approaching $0$ but the term inside the bracket is not giving me ideas on how to compute the limit.,,['calculus']
69,"Find the value of the integral $\int_0^1\int_0^1e^{\max(x^2,y^2)}dxdy$",Find the value of the integral,"\int_0^1\int_0^1e^{\max(x^2,y^2)}dxdy","I am currently having difficulty trying to evaluate a certain double integral. $$\int_0^1\int_0^1e^{\max(x^2,y^2)}dxdy$$ I've broken it down into two cases, (i) $\max(x^2,y^2)=y^2$ then $$\int_0^1\int_0^1e^{\max(x^2,y^2)}dxdy=\int_0^1e^{y^2}dy$$ (ii) $\max(x^2,y^2)=x^2$ then $$\int_0^1\int_0^1e^{\max(x^2,y^2)}dxdy=\int_0^1e^{x^2}dx$$ since the inner integral does not depend on $y$ I believe that this is correct. It is at this point that I cannot evaluate. From my understanding this integral cannot be solved by any traditional means. By using series, I can write $$\int_0^1e^{x^2}dx = \int_0^1\sum_{n=0}^{\infty}\frac{x^{2n}}{n!}dx = \sum_{n=0}^{\infty}\frac{x^{(2n+1)}}{(2n+1)(n!)}|_0^1 = \sum_{n=0}^{\infty}\frac{1}{(2n+1)(n!)}$$ Would this be the correct way of doing this? Also, if it is the correct method, is that series the appropriate answer? I started to have second thoughts here so I have not shown convergence (or not), I suspect this would be the next step.","I am currently having difficulty trying to evaluate a certain double integral. I've broken it down into two cases, (i) then (ii) then since the inner integral does not depend on I believe that this is correct. It is at this point that I cannot evaluate. From my understanding this integral cannot be solved by any traditional means. By using series, I can write Would this be the correct way of doing this? Also, if it is the correct method, is that series the appropriate answer? I started to have second thoughts here so I have not shown convergence (or not), I suspect this would be the next step.","\int_0^1\int_0^1e^{\max(x^2,y^2)}dxdy \max(x^2,y^2)=y^2 \int_0^1\int_0^1e^{\max(x^2,y^2)}dxdy=\int_0^1e^{y^2}dy \max(x^2,y^2)=x^2 \int_0^1\int_0^1e^{\max(x^2,y^2)}dxdy=\int_0^1e^{x^2}dx y \int_0^1e^{x^2}dx = \int_0^1\sum_{n=0}^{\infty}\frac{x^{2n}}{n!}dx = \sum_{n=0}^{\infty}\frac{x^{(2n+1)}}{(2n+1)(n!)}|_0^1 = \sum_{n=0}^{\infty}\frac{1}{(2n+1)(n!)}","['calculus', 'integration']"
70,"Need help solving - $ \int (\sin 101x) \cdot\sin^{99}x\,dx $",Need help solving -," \int (\sin 101x) \cdot\sin^{99}x\,dx ","I have a complicated integral to solve. I tried to split ($101 x$) and proceed but I am getting a pretty nasty answer while evaluating using parts. are there any simpler methods to evaluate this integral? $$ \int\!\sin (101x)\cdot\sin^{99}(x)\, dx $$","I have a complicated integral to solve. I tried to split ($101 x$) and proceed but I am getting a pretty nasty answer while evaluating using parts. are there any simpler methods to evaluate this integral? $$ \int\!\sin (101x)\cdot\sin^{99}(x)\, dx $$",,"['calculus', 'integration', 'indefinite-integrals']"
71,n-th derivative of $\frac{\ln x}{x}$.,n-th derivative of .,\frac{\ln x}{x},"Let $f(x)=\frac{\ln x}{x},x>0$. Show that $$f^{(n)}(1)=(-1)^{n+1}(n!)(1+\frac{1}{2}+\cdot+\frac{1}{n})$$ Trial: n-th derivative of $\ln x$ is $$(-1)^{n-1}(n-1)! x^{-n}$$ and n-th derivative of $\frac{1}{x}$ is $$(-1)^n n! x^{-(n+1)}$$Then If I use Leibnitz's Theorem I need to face a big calculation.Please help.","Let $f(x)=\frac{\ln x}{x},x>0$. Show that $$f^{(n)}(1)=(-1)^{n+1}(n!)(1+\frac{1}{2}+\cdot+\frac{1}{n})$$ Trial: n-th derivative of $\ln x$ is $$(-1)^{n-1}(n-1)! x^{-n}$$ and n-th derivative of $\frac{1}{x}$ is $$(-1)^n n! x^{-(n+1)}$$Then If I use Leibnitz's Theorem I need to face a big calculation.Please help.",,"['calculus', 'derivatives']"
72,"Prove that $ f(x) $ has at least two real roots in $ (0,\pi) $",Prove that  has at least two real roots in," f(x)   (0,\pi) ","Let $ f $ be a continuous function defined on $ [0,\pi] $. Suppose that $$ \int_{0}^{\pi}f(x)\sin {x} dx=0,   \int_{0}^{\pi}f(x)\cos {x} dx=0 $$ Prove that $ f(x) $ has at least two real roots in $ (0,\pi) $","Let $ f $ be a continuous function defined on $ [0,\pi] $. Suppose that $$ \int_{0}^{\pi}f(x)\sin {x} dx=0,   \int_{0}^{\pi}f(x)\cos {x} dx=0 $$ Prove that $ f(x) $ has at least two real roots in $ (0,\pi) $",,['calculus']
73,Where is the flaw in evaluating the following integral?,Where is the flaw in evaluating the following integral?,,"I was trying to evaluate a complicated integral by substitution and along the way I got stuck in nonsensical answer. Surprisingly enough the point I wanted to discuss can be demonstrated using the following primitive integral: $\displaystyle\int_0^\pi \sin\theta d\theta=-\cos\theta|_0^\pi=-\cos\pi+\cos 0=1+1=2$ Now Imagine we are trying to do the same integral in another way, by substitution. If we take $\sin\theta\equiv y$  then the limits of the integral will change accordingly from $0$ to $\pi$ to from $0$ to $0$, which will kill the integral instantly and give us $0$! So either there is a flaw in my solution that I cannot find, or that there are conditions under which one can (or cannot) use integration by substitution that I am not aware of (at least I have never seen it in college level calculus).","I was trying to evaluate a complicated integral by substitution and along the way I got stuck in nonsensical answer. Surprisingly enough the point I wanted to discuss can be demonstrated using the following primitive integral: $\displaystyle\int_0^\pi \sin\theta d\theta=-\cos\theta|_0^\pi=-\cos\pi+\cos 0=1+1=2$ Now Imagine we are trying to do the same integral in another way, by substitution. If we take $\sin\theta\equiv y$  then the limits of the integral will change accordingly from $0$ to $\pi$ to from $0$ to $0$, which will kill the integral instantly and give us $0$! So either there is a flaw in my solution that I cannot find, or that there are conditions under which one can (or cannot) use integration by substitution that I am not aware of (at least I have never seen it in college level calculus).",,"['calculus', 'integration', 'fake-proofs']"
74,What are polar co-ordinates?,What are polar co-ordinates?,,"This is a very basic question that I feel that I should know the answer to but haven't been able to think through clearly. In linear algebra, we learn that the basis of a finite dimensional vector space can be thought of as 'co-ordinates' of that space. And, we model what we intuitively understand as the euclidean plane, using the vector space $\mathbb{R^2}$ equipped with the standard inner product and metric etc. The underlying space is taken to be independent of the choice of basis, that is we understand that properties that are inherent to the space are those that will be invariant under change of basis. Now, $\mathbb{R^2}$ comes with a canonical basis: this can be understood as saying that given any arbitrary two dimensional vector space and any basis, the vectors $v_i$ of the basis under the co-ordinate map maps to $e_i$. Since, we have also introduced inner products and thus a notion of parallel, the intuitive picture we now have of the co-odrinate grid is a criss-cross of lines. and the 'co-ordinates' are called, imaginatively, 'rectangular co-ordinates'. In school, we also learn about polar 'co-ordinates' of the plane. The associated picture is of concentric circles and rays fanning out of the origin. However, these 'co-ordinates' do not fit within the 'Basic Linear Algebra' framework (since among other things, $0$ has no unique representation and the functions that change the variables are not linear). The one way of seeing the transformation of the 'rulings' of the plane is to consider $\mathbb{R^2}$ as $\mathbb{C}$ and the change as the map $\exp: \mathbb C \to \mathbb C$. What is the framework in which the notion of 'co-ordinates' subsumes both these pictures (likewise for cylindrical, spherical, etc in dimension(?) three). My second and connected question: is there a linear algebraic connection for using two numbers to represent points in polar co-ordinate, i.e. is it because the vector space dimension of $\mathbb{E^2}$ is two. My third question is: am I confusing different concepts of 'dimension' here? Added : Thanks for all the replies. They are all great but given my continuing dissatisfaction, either I have not really understood the answers or haven't been able to communicate the question properly (or perhaps and quite likely, I don't know what I want to ask). Now, when we think of a (topological) manifold, we think of some object that is locally euclidean, i.e., we already have a 'handle' on $\mathbb{E^n}$ and want to use our knowledge of being able to do things, such as calculus, onto the new object . In my question, I am looking at ways we can 'handle' $\mathbb{E^2}$ itself, so invoking manifolds, seems a bit like putting the cart before the horse. I want to say something like this: The point of polar co-ordinates is to represent the plane by looking at it as $S^1\times \mathbb{R}$, where $S^1$ is a basic object like $\mathbb R$.","This is a very basic question that I feel that I should know the answer to but haven't been able to think through clearly. In linear algebra, we learn that the basis of a finite dimensional vector space can be thought of as 'co-ordinates' of that space. And, we model what we intuitively understand as the euclidean plane, using the vector space $\mathbb{R^2}$ equipped with the standard inner product and metric etc. The underlying space is taken to be independent of the choice of basis, that is we understand that properties that are inherent to the space are those that will be invariant under change of basis. Now, $\mathbb{R^2}$ comes with a canonical basis: this can be understood as saying that given any arbitrary two dimensional vector space and any basis, the vectors $v_i$ of the basis under the co-ordinate map maps to $e_i$. Since, we have also introduced inner products and thus a notion of parallel, the intuitive picture we now have of the co-odrinate grid is a criss-cross of lines. and the 'co-ordinates' are called, imaginatively, 'rectangular co-ordinates'. In school, we also learn about polar 'co-ordinates' of the plane. The associated picture is of concentric circles and rays fanning out of the origin. However, these 'co-ordinates' do not fit within the 'Basic Linear Algebra' framework (since among other things, $0$ has no unique representation and the functions that change the variables are not linear). The one way of seeing the transformation of the 'rulings' of the plane is to consider $\mathbb{R^2}$ as $\mathbb{C}$ and the change as the map $\exp: \mathbb C \to \mathbb C$. What is the framework in which the notion of 'co-ordinates' subsumes both these pictures (likewise for cylindrical, spherical, etc in dimension(?) three). My second and connected question: is there a linear algebraic connection for using two numbers to represent points in polar co-ordinate, i.e. is it because the vector space dimension of $\mathbb{E^2}$ is two. My third question is: am I confusing different concepts of 'dimension' here? Added : Thanks for all the replies. They are all great but given my continuing dissatisfaction, either I have not really understood the answers or haven't been able to communicate the question properly (or perhaps and quite likely, I don't know what I want to ask). Now, when we think of a (topological) manifold, we think of some object that is locally euclidean, i.e., we already have a 'handle' on $\mathbb{E^n}$ and want to use our knowledge of being able to do things, such as calculus, onto the new object . In my question, I am looking at ways we can 'handle' $\mathbb{E^2}$ itself, so invoking manifolds, seems a bit like putting the cart before the horse. I want to say something like this: The point of polar co-ordinates is to represent the plane by looking at it as $S^1\times \mathbb{R}$, where $S^1$ is a basic object like $\mathbb R$.",,"['calculus', 'linear-algebra']"
75,Solve this limit $\lim\limits_{x\to 1}\left(\dfrac{2017}{1-x^{2017}} -\dfrac{2018}{1-x^{2018}}\right)$,Solve this limit,\lim\limits_{x\to 1}\left(\dfrac{2017}{1-x^{2017}} -\dfrac{2018}{1-x^{2018}}\right),"\begin{align} \lim\limits_{x\to 1}\left(\dfrac{2017}{1-x^{2017}} -\dfrac{2018}{1-x^{2018}}\right) &= \lim\limits_{x\to 1}\dfrac{2017(x^{2017} + \dots + 1) - 2018(x^{2016} + \dots + 1)}{(1-x)(x^{2016} + \dots +1)(x^{2017} + \dots +1)}\\\\ &= \lim\limits_{x\to 1}\dfrac{2017x^{2017} - x^{2016} - \dots - 1}{(1-x)(x^{2016} + \dots +1)(x^{2017} + \dots +1)} \end{align} Did I do the right way with those step above? I think next step is to separate: $2017x^{2017} = \underbrace{x^{2017} + \dots + x^{2017}}_{\text{2017 addends}}$ Then combine with the rest and factorize $(1-x)$ , but it has a little confused after factorizing. Please help me!!?","Did I do the right way with those step above? I think next step is to separate: Then combine with the rest and factorize , but it has a little confused after factorizing. Please help me!!?","\begin{align}
\lim\limits_{x\to 1}\left(\dfrac{2017}{1-x^{2017}} -\dfrac{2018}{1-x^{2018}}\right)
&= \lim\limits_{x\to 1}\dfrac{2017(x^{2017} + \dots + 1) - 2018(x^{2016} + \dots + 1)}{(1-x)(x^{2016} + \dots +1)(x^{2017} + \dots +1)}\\\\
&= \lim\limits_{x\to 1}\dfrac{2017x^{2017} - x^{2016} - \dots - 1}{(1-x)(x^{2016} + \dots +1)(x^{2017} + \dots +1)}
\end{align} 2017x^{2017} = \underbrace{x^{2017} + \dots + x^{2017}}_{\text{2017 addends}} (1-x)","['calculus', 'limits']"
76,Prove that $\ln{\left({A^6\sqrt{\pi}\over 2^{7\over6}e}\right)}=\sum\limits_{n=1}^{\infty}{(-1)^{n+1}\over n(n+1)}\eta(n)$,Prove that,\ln{\left({A^6\sqrt{\pi}\over 2^{7\over6}e}\right)}=\sum\limits_{n=1}^{\infty}{(-1)^{n+1}\over n(n+1)}\eta(n),"Show that $$\ln{\left({A^6\sqrt{\pi}\over 2^{7\over6}e}\right)}=\sum_{n=1}^{\infty}{(-1)^{n+1}\over n(n+1)}\eta(n)$$ (where $\eta(n)$ is the Dirichlet eta function, and A is the Glaisher-Kinkelin constant). I try: $$\ln{\left({A^6\sqrt{\pi}\over 2^{7\over6}e}\right)}=\sum_{n=1}^{\infty}{(-1)^{n+1}\over n}\eta(n)-\sum_{n=1}^{\infty}{(-1)^{n+1}\over n+1}\eta(n)$$ We use this series $$\ln{{\pi\over 2}}=\sum_{n=1}^{\infty}{(-1)^{n+1}\over n}\eta(n)$$ to simplify to $$-\ln{\left({A^6\over 2^{1\over6}\sqrt{\pi}e}\right)}=\sum_{n=1}^{\infty}{(-1)^{n+1}\over n+1}\eta(n)$$ We have $$\ln{\left[\prod_{k=1}^{\infty}\left({k\over k+1}\right)^{(-1)^{k+1}}\right]}=\sum_{n=1}^{\infty}{(-1)^n\eta(n)\over n}$$ We can't use this to apply on the above series. I just wonder, is there an infinite product for $$\ln{\left[F(k)\right]}=\sum_{n=1}^{\infty}{(-1)^n\eta(n)\over 1+n}$$ Can anyone please give a hand here? Thank you.","Show that $$\ln{\left({A^6\sqrt{\pi}\over 2^{7\over6}e}\right)}=\sum_{n=1}^{\infty}{(-1)^{n+1}\over n(n+1)}\eta(n)$$ (where $\eta(n)$ is the Dirichlet eta function, and A is the Glaisher-Kinkelin constant). I try: $$\ln{\left({A^6\sqrt{\pi}\over 2^{7\over6}e}\right)}=\sum_{n=1}^{\infty}{(-1)^{n+1}\over n}\eta(n)-\sum_{n=1}^{\infty}{(-1)^{n+1}\over n+1}\eta(n)$$ We use this series $$\ln{{\pi\over 2}}=\sum_{n=1}^{\infty}{(-1)^{n+1}\over n}\eta(n)$$ to simplify to $$-\ln{\left({A^6\over 2^{1\over6}\sqrt{\pi}e}\right)}=\sum_{n=1}^{\infty}{(-1)^{n+1}\over n+1}\eta(n)$$ We have $$\ln{\left[\prod_{k=1}^{\infty}\left({k\over k+1}\right)^{(-1)^{k+1}}\right]}=\sum_{n=1}^{\infty}{(-1)^n\eta(n)\over n}$$ We can't use this to apply on the above series. I just wonder, is there an infinite product for $$\ln{\left[F(k)\right]}=\sum_{n=1}^{\infty}{(-1)^n\eta(n)\over 1+n}$$ Can anyone please give a hand here? Thank you.",,"['calculus', 'sequences-and-series', 'closed-form', 'infinite-product']"
77,Proving $\lim\limits_{x \to \infty} xf(x)=0$ if $\int_{0}^{\infty}f(x) dx$ converges.,Proving  if  converges.,\lim\limits_{x \to \infty} xf(x)=0 \int_{0}^{\infty}f(x) dx,"Let $f(x)$ be a monotone non-increasing function such that $\int_{0}^{\infty}f(x) dx$ converges. Prove: $\lim\limits_{x \to \infty} xf(x)=0$. My question is, why can't I simply contradict any other possibility by using the Integral Limit Comparison Test with $1\over x$? I am, after all, to show that $f(x)=o(x)$ as $x\to \infty$. I really don't understand why monotony is crucial here. I could use some help.","Let $f(x)$ be a monotone non-increasing function such that $\int_{0}^{\infty}f(x) dx$ converges. Prove: $\lim\limits_{x \to \infty} xf(x)=0$. My question is, why can't I simply contradict any other possibility by using the Integral Limit Comparison Test with $1\over x$? I am, after all, to show that $f(x)=o(x)$ as $x\to \infty$. I really don't understand why monotony is crucial here. I could use some help.",,"['calculus', 'integration']"
78,Proving $~\prod~\frac{\cosh\left(n^2+n+\frac12\right)+i\sinh\left(n+\frac12\right)}{\cosh\left(n^2+n+\frac12\right)-i\sinh\left(n+\frac12\right)}~=~i$,Proving,~\prod~\frac{\cosh\left(n^2+n+\frac12\right)+i\sinh\left(n+\frac12\right)}{\cosh\left(n^2+n+\frac12\right)-i\sinh\left(n+\frac12\right)}~=~i,"How could we prove that $${\LARGE\prod_{\Large n\ge0}}~\frac{\cosh\left(n^2+n+\dfrac12\right)+i\sinh\left(n+\dfrac12\right)}{\cosh\left(n^2+n+\dfrac12\right)-i\sinh\left(n+\dfrac12\right)}~=~i$$ This is problem $A12-1$ from the Harvard College Mathematics Review , Volume $4$, Spring $2012$, Chapter $9$, Page $77$, proposed by Moubinool Omarjee, Paris, France . Needless to say, despite thinking on and off about it for the past couple of weeks, I haven’t yet been able to crack it, partly due to the fact that the argument of $\cosh$ is different than that of $\sinh$. I’ve also noticed that, by completing the square, we have $n^2+n+\dfrac12=\left(n+\dfrac12\right)^2+\left(\dfrac12\right)^2$. That’s about it, I’m afraid.","How could we prove that $${\LARGE\prod_{\Large n\ge0}}~\frac{\cosh\left(n^2+n+\dfrac12\right)+i\sinh\left(n+\dfrac12\right)}{\cosh\left(n^2+n+\dfrac12\right)-i\sinh\left(n+\dfrac12\right)}~=~i$$ This is problem $A12-1$ from the Harvard College Mathematics Review , Volume $4$, Spring $2012$, Chapter $9$, Page $77$, proposed by Moubinool Omarjee, Paris, France . Needless to say, despite thinking on and off about it for the past couple of weeks, I haven’t yet been able to crack it, partly due to the fact that the argument of $\cosh$ is different than that of $\sinh$. I’ve also noticed that, by completing the square, we have $n^2+n+\dfrac12=\left(n+\dfrac12\right)^2+\left(\dfrac12\right)^2$. That’s about it, I’m afraid.",,"['calculus', 'closed-form', 'infinite-product', 'hyperbolic-functions']"
79,Is the max of two differentiable functions piecewise-differentiable?,Is the max of two differentiable functions piecewise-differentiable?,,"The question here asks: Given that $f$ and $g$ are two real functions and both are differentiable, is it true to say that $h=max(f,g)$ is differentiable too? Convincing arguments have been presented there that the answer is No . So, how about a slightly weaker question:  Given that $f$ and $g$ are two real, differentiable functions, is it always true that $h=max(f,g)$ is piecewise-differentiable? (For the purposes of this question, 'piecewise' is to be taken as user86418 defined it in a comment: ""The domain can be divided into subintervals so that the set of endpoints is discrete"", i.e., ""each endpoint is isolated in the set of endpoints.""  Further, the set of endpoints may or may not be finite.)","The question here asks: Given that $f$ and $g$ are two real functions and both are differentiable, is it true to say that $h=max(f,g)$ is differentiable too? Convincing arguments have been presented there that the answer is No . So, how about a slightly weaker question:  Given that $f$ and $g$ are two real, differentiable functions, is it always true that $h=max(f,g)$ is piecewise-differentiable? (For the purposes of this question, 'piecewise' is to be taken as user86418 defined it in a comment: ""The domain can be divided into subintervals so that the set of endpoints is discrete"", i.e., ""each endpoint is isolated in the set of endpoints.""  Further, the set of endpoints may or may not be finite.)",,['calculus']
80,"How can I show that $ \int_0^\pi \frac{x\,dx}{1+\cos^2(x)} = \frac{\pi^2}{2\sqrt{2}} $",How can I show that," \int_0^\pi \frac{x\,dx}{1+\cos^2(x)} = \frac{\pi^2}{2\sqrt{2}} ","Show that $$ \int_0^\pi  \frac{x\,dx}{1+\cos^2(x)} = \frac{\pi^2}{2\sqrt{2}}  $$ I tried using change of variable $x = \pi-y$ and then ended up with integral $\int_0^\pi \frac{1}{1+\cos^2(y)}dy$ which I think doesn't make thing easier.  I am wondering if there is any other clever change of variable or some trick to compute this original integral.","Show that $$ \int_0^\pi  \frac{x\,dx}{1+\cos^2(x)} = \frac{\pi^2}{2\sqrt{2}}  $$ I tried using change of variable $x = \pi-y$ and then ended up with integral $\int_0^\pi \frac{1}{1+\cos^2(y)}dy$ which I think doesn't make thing easier.  I am wondering if there is any other clever change of variable or some trick to compute this original integral.",,"['calculus', 'integration', 'definite-integrals']"
81,Harmonic number identity,Harmonic number identity,,I search for an elementary proof of the following identity: $$ \sum_{i=1}^{n-k} \frac{(-1)^{i+1}}{i}\binom{n}{i+k}=\binom{n}{k}\left(H_n-H_k\right) $$ I have found the following proof: $$ \sum_{i=1}^{n-k} \frac{(-1)^{i+1}}{i}\binom{n}{i+k}=\binom{n}{k}\left(H_n-H_k\right)\iff\sum_{i=1}^{n-k} \frac{(-1)^{i+1}}{i}\frac{k!(n-k)!}{(i+k)!(n-i-k)!}=H_n-H_k $$ Now: $$ \sum_{i=1}^{n-k} \frac{(-1)^{i+1}}{i}\frac{k!(n-k)!}{(i+k)!(n-i-k)!}=\sum_{i=1}^{n-k} \frac{(-1)^{i+1}}{i}\frac{i!\cdot k!}{(i+k)!}\frac{(n-k)!}{i!\cdot(n-i-k)!}=\sum_{i=1}^{n-k} (-1)^{i+1}\frac{\Gamma(i)\cdot \Gamma(k+1)}{\Gamma(i+k+1)}\binom{n-k}{i}={\sum_{i=1}^{n-k} (-1)^{i+1}\cdot\int_{0}^{1} x^{i-1}(1-x)^k dx\cdot\binom{n-k}{i}}={\int_{0}^{1} -\frac{(1-x)^k}{x}\cdot\sum_{i=1}^{n-k} \binom{n-k}{i}(-x)^{i}} \space dx={\int_{0}^{1} -\frac{(1-x)^k}{x}\cdot ((1-x)^{n-k}-1) \space dx}={\int_{0}^{1} \frac{1}{x}\cdot \left((1-x)^{k}-(1-x)^n\right) \space dx}={\int_{0}^{1} \frac{1}{1-x}\cdot \left(x^{k}-x^n\right) \space dx}={\int_{0}^{1} \frac{1-x^n}{1-x}-\frac{1-x^k}{1-x}\space dx}={\int_{0}^{1} \frac{1-x^n}{1-x}\space dx-\int_{0}^{1}\frac{1-x^k}{1-x}\space dx}={\int_{0}^{1} \sum_{i=0}^{n-1}x^i\space dx-\int_{0}^{1}\sum_{i=0}^{k-1}x^i\space dx}={\sum_{i=0}^{n-1}\int_{0}^{1}x^i\space dx-\sum_{i=0}^{k-1}\int_{0}^{1} x^i\space dx}={\sum_{i=0}^{n-1}\frac{1}{i+1}-\sum_{i=0}^{k-1}\frac{1}{i+1}}=H_n-H_k $$ But think it isn't very elegant since it uses rather advanced techniques like the integral representation of the Beta-function. So is there a more elegant way?,I search for an elementary proof of the following identity: $$ \sum_{i=1}^{n-k} \frac{(-1)^{i+1}}{i}\binom{n}{i+k}=\binom{n}{k}\left(H_n-H_k\right) $$ I have found the following proof: $$ \sum_{i=1}^{n-k} \frac{(-1)^{i+1}}{i}\binom{n}{i+k}=\binom{n}{k}\left(H_n-H_k\right)\iff\sum_{i=1}^{n-k} \frac{(-1)^{i+1}}{i}\frac{k!(n-k)!}{(i+k)!(n-i-k)!}=H_n-H_k $$ Now: $$ \sum_{i=1}^{n-k} \frac{(-1)^{i+1}}{i}\frac{k!(n-k)!}{(i+k)!(n-i-k)!}=\sum_{i=1}^{n-k} \frac{(-1)^{i+1}}{i}\frac{i!\cdot k!}{(i+k)!}\frac{(n-k)!}{i!\cdot(n-i-k)!}=\sum_{i=1}^{n-k} (-1)^{i+1}\frac{\Gamma(i)\cdot \Gamma(k+1)}{\Gamma(i+k+1)}\binom{n-k}{i}={\sum_{i=1}^{n-k} (-1)^{i+1}\cdot\int_{0}^{1} x^{i-1}(1-x)^k dx\cdot\binom{n-k}{i}}={\int_{0}^{1} -\frac{(1-x)^k}{x}\cdot\sum_{i=1}^{n-k} \binom{n-k}{i}(-x)^{i}} \space dx={\int_{0}^{1} -\frac{(1-x)^k}{x}\cdot ((1-x)^{n-k}-1) \space dx}={\int_{0}^{1} \frac{1}{x}\cdot \left((1-x)^{k}-(1-x)^n\right) \space dx}={\int_{0}^{1} \frac{1}{1-x}\cdot \left(x^{k}-x^n\right) \space dx}={\int_{0}^{1} \frac{1-x^n}{1-x}-\frac{1-x^k}{1-x}\space dx}={\int_{0}^{1} \frac{1-x^n}{1-x}\space dx-\int_{0}^{1}\frac{1-x^k}{1-x}\space dx}={\int_{0}^{1} \sum_{i=0}^{n-1}x^i\space dx-\int_{0}^{1}\sum_{i=0}^{k-1}x^i\space dx}={\sum_{i=0}^{n-1}\int_{0}^{1}x^i\space dx-\sum_{i=0}^{k-1}\int_{0}^{1} x^i\space dx}={\sum_{i=0}^{n-1}\frac{1}{i+1}-\sum_{i=0}^{k-1}\frac{1}{i+1}}=H_n-H_k $$ But think it isn't very elegant since it uses rather advanced techniques like the integral representation of the Beta-function. So is there a more elegant way?,,"['calculus', 'sequences-and-series', 'binomial-coefficients', 'harmonic-numbers', 'beta-function']"
82,Suggestion for Computing an Integral,Suggestion for Computing an Integral,,"Let $$A=\left\{(x,y,z)\in \mathbb R^3:\dfrac{x^2}{2}+\dfrac{y^4}{4}+\dfrac{z^6}{6}\leq1\right\}.$$ Then I want to compute the following integral: $$\frac{1}{\operatorname{vol}(A)}\displaystyle\int_{\partial A}^{}\!\frac{1}{\sqrt{x^2+y^6+z^{10}}}\, d(x,y,z)$$ Should I use spherical coordinates or something like that? I am a beginner to this topic, so any help would be nice. Edit: I put the factor $\frac{1}{\operatorname{vol}(A)}$ before the integral (that's exactly my task now), but there should be no different concerning our problem... $$I := \frac{1}{\lambda_3(A)} \int\limits_{\partial A} \frac{1}{\sqrt{x^2 + y^6 + z^{10}}} \, dS_{\partial A}$$","Let $$A=\left\{(x,y,z)\in \mathbb R^3:\dfrac{x^2}{2}+\dfrac{y^4}{4}+\dfrac{z^6}{6}\leq1\right\}.$$ Then I want to compute the following integral: $$\frac{1}{\operatorname{vol}(A)}\displaystyle\int_{\partial A}^{}\!\frac{1}{\sqrt{x^2+y^6+z^{10}}}\, d(x,y,z)$$ Should I use spherical coordinates or something like that? I am a beginner to this topic, so any help would be nice. Edit: I put the factor $\frac{1}{\operatorname{vol}(A)}$ before the integral (that's exactly my task now), but there should be no different concerning our problem... $$I := \frac{1}{\lambda_3(A)} \int\limits_{\partial A} \frac{1}{\sqrt{x^2 + y^6 + z^{10}}} \, dS_{\partial A}$$",,"['calculus', 'integration', 'analysis', 'definite-integrals']"
83,The intuition behind Trig substitutions in calculus,The intuition behind Trig substitutions in calculus,,"I'm going through the MIT open calculus course, and in one of the lectures (19-28min marks) the professor uses the trig substitution $x = \tan \theta$ to find the integral of $\frac{dx}{x^2 \sqrt{1+x^2}}$. His answer: $-\csc(\arctan  x) + c$, which he shows is equivalent to $-\frac{1+x^2}{x} + c$ by drawing a right triangle on the blackboard. I get the math behind each step of it, but I can't wrap my head around why that equivalence works.  We just used an arbitrary $x = \tan \theta$ substitution, where $\theta$ moves differently than x does, and the expression $-\frac{1+x^2}{x} + c$ by itself doesn't know anything about trigonometry.  But I type both into Excel for a bunch of different x values, and obviously they are equivalent. I guess I'm not really sure what my question is here, but I could just use some perspective.  It just seems like substituting ANY function in for x then integrating it shouldn't work, especially when crossing into polar coordinates.","I'm going through the MIT open calculus course, and in one of the lectures (19-28min marks) the professor uses the trig substitution $x = \tan \theta$ to find the integral of $\frac{dx}{x^2 \sqrt{1+x^2}}$. His answer: $-\csc(\arctan  x) + c$, which he shows is equivalent to $-\frac{1+x^2}{x} + c$ by drawing a right triangle on the blackboard. I get the math behind each step of it, but I can't wrap my head around why that equivalence works.  We just used an arbitrary $x = \tan \theta$ substitution, where $\theta$ moves differently than x does, and the expression $-\frac{1+x^2}{x} + c$ by itself doesn't know anything about trigonometry.  But I type both into Excel for a bunch of different x values, and obviously they are equivalent. I guess I'm not really sure what my question is here, but I could just use some perspective.  It just seems like substituting ANY function in for x then integrating it shouldn't work, especially when crossing into polar coordinates.",,"['calculus', 'trigonometry']"
84,What are some difficult integrals done by substitution and elementary functions?,What are some difficult integrals done by substitution and elementary functions?,,What are some examples of difficult integrals that are done using substitutions? For example:  $$\int{\frac{(1+x^{2})dx}{(1-x^{2})\sqrt{1+x^{4}}}}$$ Please no laplace and fourier transforms as I haven't studied those yet.,What are some examples of difficult integrals that are done using substitutions? For example:  $$\int{\frac{(1+x^{2})dx}{(1-x^{2})\sqrt{1+x^{4}}}}$$ Please no laplace and fourier transforms as I haven't studied those yet.,,"['calculus', 'integration']"
85,Mellin transform of $\sin x$ aka $\int^{\infty}_0 x^{s-1}\sin x dx $ [duplicate],Mellin transform of  aka  [duplicate],\sin x \int^{\infty}_0 x^{s-1}\sin x dx ,"This question already has answers here : Proof of the identity $\int_0^{+\infty}\frac{\sin(x)}{x^\alpha}dx=\frac{\Gamma(\alpha/2)\Gamma(1-\alpha/2)}{2\Gamma(\alpha)}$ for $\alpha\in (0,2)$. (3 answers) Closed 3 years ago . I am trying to find the Mellin transform of $\sin x $ , put in other words to solve: $$\int^{\infty}_0  x^{s-1}\sin x \mathrm{d} x $$ And I know that the answer is: $$\Gamma(s) \sin \left(\frac{\pi s}{2}\right)$$ From several tables on the internet but I couldn't find any justification. How can this identity be proven?","This question already has answers here : Proof of the identity $\int_0^{+\infty}\frac{\sin(x)}{x^\alpha}dx=\frac{\Gamma(\alpha/2)\Gamma(1-\alpha/2)}{2\Gamma(\alpha)}$ for $\alpha\in (0,2)$. (3 answers) Closed 3 years ago . I am trying to find the Mellin transform of , put in other words to solve: And I know that the answer is: From several tables on the internet but I couldn't find any justification. How can this identity be proven?",\sin x  \int^{\infty}_0  x^{s-1}\sin x \mathrm{d} x  \Gamma(s) \sin \left(\frac{\pi s}{2}\right),"['calculus', 'integration', 'complex-analysis', 'contour-integration', 'mellin-transform']"
86,"If the absolute value of an analytic function $f$ is a constant, must $f$ be a constant?","If the absolute value of an analytic function  is a constant, must  be a constant?",f f,"I've been thinking how to prove that an analytic function $f$ is a constant if the absolute value of $f$ is a constant, but I haven't figured it out yet. What I was thinking is to use Cauchy-Riemann equations, but it didn't work well... If this is not true, I would like to know the counterexample... Here is what I tried: $$|f|=|u+iv|=\sqrt {u^2+v^2}$$ Thus $u^2+v^2$ is a constant. (1)    $\displaystyle u\frac {\delta u}{\delta x}+v\frac {\delta v}{\delta x}=0 $ (2)    $\displaystyle u\frac {\delta u}{\delta y}+v\frac {\delta v}{\delta y}=0 $ Plug Cauchy Riemann into (2). $$\displaystyle -u\frac {\delta v}{\delta x}+v\frac {\delta u}{\delta x}=0 $$ and I'm stuck here...","I've been thinking how to prove that an analytic function $f$ is a constant if the absolute value of $f$ is a constant, but I haven't figured it out yet. What I was thinking is to use Cauchy-Riemann equations, but it didn't work well... If this is not true, I would like to know the counterexample... Here is what I tried: $$|f|=|u+iv|=\sqrt {u^2+v^2}$$ Thus $u^2+v^2$ is a constant. (1)    $\displaystyle u\frac {\delta u}{\delta x}+v\frac {\delta v}{\delta x}=0 $ (2)    $\displaystyle u\frac {\delta u}{\delta y}+v\frac {\delta v}{\delta y}=0 $ Plug Cauchy Riemann into (2). $$\displaystyle -u\frac {\delta v}{\delta x}+v\frac {\delta u}{\delta x}=0 $$ and I'm stuck here...",,['calculus']
87,"Integral of floor function: $\int \,\left\lfloor\frac{1}{x}\right\rfloor\, dx$",Integral of floor function:,"\int \,\left\lfloor\frac{1}{x}\right\rfloor\, dx","How would you go about solving integral of a floor? The particular problem I have is: $$\int \,\left\lfloor\frac{1}{x}\right\rfloor\, dx$$","How would you go about solving integral of a floor? The particular problem I have is: $$\int \,\left\lfloor\frac{1}{x}\right\rfloor\, dx$$",,"['calculus', 'integration', 'indefinite-integrals', 'ceiling-and-floor-functions']"
88,"if $\int_1^{\infty}f(x)\ \mathrm dx$ converges, must $\int_1^{\infty}f(x)\sin x\ \mathrm dx$ converge?","if  converges, must  converge?",\int_1^{\infty}f(x)\ \mathrm dx \int_1^{\infty}f(x)\sin x\ \mathrm dx,"I can't use any of the convergence tests I learned because I have no information on $f(x)$, in particular I don't know if it's continuous or positive. The only thing I could think of was that if $\displaystyle \int_{1}^{\infty}f(x)\ \mathrm dx$ was absolutely convergent, then $|f(x)\sin x| \leq |f(x)|$ would imply by the comparison test that $\displaystyle \int_{1}^{\infty}f(x)\sin x\ \mathrm dx$ converges. So if I want to find a counter-example I have to pick $f(x)$ so that $\displaystyle \int_{1}^{\infty}f(x)\ \mathrm dx$ conditionally converges, but I can't think of one.","I can't use any of the convergence tests I learned because I have no information on $f(x)$, in particular I don't know if it's continuous or positive. The only thing I could think of was that if $\displaystyle \int_{1}^{\infty}f(x)\ \mathrm dx$ was absolutely convergent, then $|f(x)\sin x| \leq |f(x)|$ would imply by the comparison test that $\displaystyle \int_{1}^{\infty}f(x)\sin x\ \mathrm dx$ converges. So if I want to find a counter-example I have to pick $f(x)$ so that $\displaystyle \int_{1}^{\infty}f(x)\ \mathrm dx$ conditionally converges, but I can't think of one.",,"['calculus', 'integration', 'convergence-divergence', 'improper-integrals']"
89,Solving $\left(x-c_1\frac{d}{dx}\right)^nf(x)=0$ for $f(x)$,Solving  for,\left(x-c_1\frac{d}{dx}\right)^nf(x)=0 f(x),I'm given that $$\left(x-c_1\frac{d}{dx}\right)^nf(x) =  0$$ I have to solve for $f(x)$ in terms of $n$ . For $n=0$ : $$f(x)=0 \tag{0}$$ For $n= 1$ : $$\begin{align} xf(x) - c_1f'(x) &= 0 \\ \quad\implies\quad f(x) &= c_2\exp\left(\frac{x^2}{2c_1}\right) \tag{1} \end{align}$$ For $n=2$ : $$\begin{align} \left(x-c_1\frac{d}{dx}\right)^1(xf(x) - c_1f'(x)) &= 0 \\[4pt] \quad\implies\quad x^2f(x) -xc_1f'(x) -c_1(f(x)+xf'(x)) +c_1^2f''(x) &=0 \\[4pt] \quad\implies\quad f(x) = k_1\exp\left(\frac{-x^2}{2c_1}\right) + k_2x\exp\left(\frac{-x^2}{2c_1}\right) & \tag{2} \end{align}$$ The case for $n= 3$ gets so complicated that I haven't put up the solution. The solution is based on hermitian polynomials.,I'm given that I have to solve for in terms of . For : For : For : The case for gets so complicated that I haven't put up the solution. The solution is based on hermitian polynomials.,"\left(x-c_1\frac{d}{dx}\right)^nf(x) =  0 f(x) n n=0 f(x)=0 \tag{0} n= 1 \begin{align}
xf(x) - c_1f'(x) &= 0 \\
\quad\implies\quad f(x) &= c_2\exp\left(\frac{x^2}{2c_1}\right) \tag{1}
\end{align} n=2 \begin{align}
\left(x-c_1\frac{d}{dx}\right)^1(xf(x) - c_1f'(x)) &= 0 \\[4pt]
\quad\implies\quad x^2f(x) -xc_1f'(x) -c_1(f(x)+xf'(x)) +c_1^2f''(x) &=0 \\[4pt]
\quad\implies\quad f(x) = k_1\exp\left(\frac{-x^2}{2c_1}\right)
+ k_2x\exp\left(\frac{-x^2}{2c_1}\right) & \tag{2}
\end{align} n= 3","['calculus', 'integration', 'ordinary-differential-equations', 'derivatives', 'hermite-polynomials']"
90,Show that $\int_0^1 \frac{\ln(1+x)}x\mathrm dx=-\frac12\int_0^1 \frac{\ln x}{1-x}\mathrm dx$ without actually evaluating both integrals,Show that  without actually evaluating both integrals,\int_0^1 \frac{\ln(1+x)}x\mathrm dx=-\frac12\int_0^1 \frac{\ln x}{1-x}\mathrm dx,"While doing some research on the 'alternating Basel Problem' I have come across this related post which states the equality $$\int_0^1 \frac{\ln(1+x)}x\mathrm dx=-\frac12\int_0^1 \frac{\ln x}{1-x}\mathrm dx\tag1$$ Using the Dilogarithm one can show that 'alternating Basler Problem' is a direct consequence of this equation and yields to $$\sum_{n=1}^{\infty}\frac{(-1)^{n+1}}{n^2}=\frac{\pi^2}{12}$$ Therefore I have no doubts to trust the author of the the cited post. However, I tried to verify the equality by myself and failed. For this purpose I enforced the substitution $x\mapsto1+x$ within the integral on the right $$\begin{align} -\frac12\int_0^1 \frac{\ln x}{1-x}\mathrm dx=-\frac12\int_{(0-1)}^{(1-1)} \frac{\ln(1+x)}{1-(1+x)}\mathrm dx=-\frac12\int_{-1}^{0} \frac{\ln(1+x)}x\mathrm dx \end{align}$$ But from hereon I am not sure how to proceed. Clearly now I have to show that $$\begin{align} -\frac12\int_{-1}^0\frac{\ln(1+x)}x\mathrm dx&=\int_0^1 \frac{\ln(1+x)}x\mathrm dx\\ \frac12\int_0^1\frac{\ln(1-x)}x\mathrm dx&=\int_0^1 \frac{\ln(1+x)}x\mathrm dx\\ 0&=\int_0^1 \frac1x\left(\ln(1+x)-\frac12\ln(1-x)\right)\mathrm dx \end{align}$$ It seems like I have made a mistake somewhere inbetween since WolframAlpha does not agree with my reasoning. Additionally I have no idea how to proceed. To be honest I am quite confused right now. First of all where exactly did I went wrong? Furthermore could someone provide a complete proof for the given equality? Please tell me when this question has been asked before. Thanks in advance!","While doing some research on the 'alternating Basel Problem' I have come across this related post which states the equality Using the Dilogarithm one can show that 'alternating Basler Problem' is a direct consequence of this equation and yields to Therefore I have no doubts to trust the author of the the cited post. However, I tried to verify the equality by myself and failed. For this purpose I enforced the substitution within the integral on the right But from hereon I am not sure how to proceed. Clearly now I have to show that It seems like I have made a mistake somewhere inbetween since WolframAlpha does not agree with my reasoning. Additionally I have no idea how to proceed. To be honest I am quite confused right now. First of all where exactly did I went wrong? Furthermore could someone provide a complete proof for the given equality? Please tell me when this question has been asked before. Thanks in advance!","\int_0^1 \frac{\ln(1+x)}x\mathrm dx=-\frac12\int_0^1 \frac{\ln x}{1-x}\mathrm dx\tag1 \sum_{n=1}^{\infty}\frac{(-1)^{n+1}}{n^2}=\frac{\pi^2}{12} x\mapsto1+x \begin{align}
-\frac12\int_0^1 \frac{\ln x}{1-x}\mathrm dx=-\frac12\int_{(0-1)}^{(1-1)} \frac{\ln(1+x)}{1-(1+x)}\mathrm dx=-\frac12\int_{-1}^{0} \frac{\ln(1+x)}x\mathrm dx
\end{align} \begin{align}
-\frac12\int_{-1}^0\frac{\ln(1+x)}x\mathrm dx&=\int_0^1 \frac{\ln(1+x)}x\mathrm dx\\
\frac12\int_0^1\frac{\ln(1-x)}x\mathrm dx&=\int_0^1 \frac{\ln(1+x)}x\mathrm dx\\
0&=\int_0^1 \frac1x\left(\ln(1+x)-\frac12\ln(1-x)\right)\mathrm dx
\end{align}","['calculus', 'integration', 'definite-integrals', 'logarithms']"
91,Prove that $\ln2<\frac{1}{\sqrt[3]3}$,Prove that,\ln2<\frac{1}{\sqrt[3]3},Prove that $$\ln2<\frac{1}{\sqrt[3]3}$$ without calculator. Even $\ln(1+x)\leq x-\frac{x^2}{2}+\frac{x^3}{3}-...+\frac{x^{51}}{51}$ does not help here and we need another Taylor.,Prove that $$\ln2<\frac{1}{\sqrt[3]3}$$ without calculator. Even $\ln(1+x)\leq x-\frac{x^2}{2}+\frac{x^3}{3}-...+\frac{x^{51}}{51}$ does not help here and we need another Taylor.,,"['calculus', 'algebra-precalculus', 'inequality']"
92,Sum of factorial fractions,Sum of factorial fractions,,Find the sum $$\sum\limits_{a=0}^{\infty}\sum\limits_{b=0}^{\infty}\sum\limits_{c=0}^{\infty}\frac{1}{(a+b+c)!}$$ I tried making something like a geometric series but couldn't. Then I couldn't think of anything.,Find the sum $$\sum\limits_{a=0}^{\infty}\sum\limits_{b=0}^{\infty}\sum\limits_{c=0}^{\infty}\frac{1}{(a+b+c)!}$$ I tried making something like a geometric series but couldn't. Then I couldn't think of anything.,,"['calculus', 'summation', 'factorial']"
93,Evaluation of $ \int \tan x\sqrt{1+\sin x}\ dx$,Evaluation of, \int \tan x\sqrt{1+\sin x}\ dx,"Calculation of $$\int \tan x\sqrt{1+\sin x}\ dx$$ $\bf{My\; Try:}$ Let $(1+\sin x)= t^2\;,$ Then $\displaystyle \cos xdx = 2tdt\Rightarrow dx = \frac{2t}{\sqrt{2-t^2}}dt$ So Integral is $\displaystyle  = \displaystyle 2\int \frac{t^2}{\sqrt{2-t^2}} \frac{(t^2-1)}{\sqrt{2-t^2}}dt = 2\int\frac{t^4-t^2}{2-t^2}dt $ Now How Can I solve after that? Help me. Thanks",Calculation of Let Then So Integral is Now How Can I solve after that? Help me. Thanks,"\int \tan x\sqrt{1+\sin x}\ dx \bf{My\; Try:} (1+\sin x)= t^2\;, \displaystyle \cos xdx = 2tdt\Rightarrow dx = \frac{2t}{\sqrt{2-t^2}}dt \displaystyle  = \displaystyle 2\int \frac{t^2}{\sqrt{2-t^2}} \frac{(t^2-1)}{\sqrt{2-t^2}}dt = 2\int\frac{t^4-t^2}{2-t^2}dt ","['calculus', 'integration', 'indefinite-integrals', 'trigonometric-integrals']"
94,Can every real polynomial be factored up to quadratic factors?,Can every real polynomial be factored up to quadratic factors?,,"I know that you can't factor a real polynomial into $\Pi_{i=1}^N(x-a_i)$ in general. But is it possible to factor every real finite polynomial into this form: $(\Pi_{i=1}^N a_ix^2 + b_ix + c_i) (\Pi_{i=1}^Mx-d_i)$  where the second term is possibly empty? This is at least true for polynomials with odd powers because they must have at least one real root. (My reasoning was false, edit see below) So I wonder if it is also true for even powers? Edit: Berci has pointed out a lapse in my reasoning. For an odd power, once you factor out the first root, it is conceivable that you may hit an even-degree polynomial that is irreducible.","I know that you can't factor a real polynomial into $\Pi_{i=1}^N(x-a_i)$ in general. But is it possible to factor every real finite polynomial into this form: $(\Pi_{i=1}^N a_ix^2 + b_ix + c_i) (\Pi_{i=1}^Mx-d_i)$  where the second term is possibly empty? This is at least true for polynomials with odd powers because they must have at least one real root. (My reasoning was false, edit see below) So I wonder if it is also true for even powers? Edit: Berci has pointed out a lapse in my reasoning. For an odd power, once you factor out the first root, it is conceivable that you may hit an even-degree polynomial that is irreducible.",,"['calculus', 'abstract-algebra', 'polynomials']"
95,Two very advanced harmonic series of weight $5$,Two very advanced harmonic series of weight,5,"Very recently Cornel discovered two ( update: in fact there are more as seen from the new entires )  fascinating results involving harmonic series using ideas from his book, (Almost) Impossible Integrals, Sums, and Series , and which are the core of a new paper he's preparing: \begin{equation*} \sum _{n=1}^{\infty } \frac{H_n H_{2 n}}{(2 n)^3} \end{equation*} \begin{equation*} =\frac{307}{128}\zeta(5)-\frac{1}{16}\zeta (2) \zeta (3)+\frac{1}{3}\log ^3(2)\zeta (2) -\frac{7}{8}  \log ^2(2)\zeta (3)-\frac{1}{15} \log ^5(2) \end{equation*} \begin{equation*} -2 \log (2) \operatorname{Li}_4\left(\frac{1}{2}\right) -2 \operatorname{Li}_5\left(\frac{1}{2}\right); \end{equation*} and \begin{equation*} \sum _{n=1}^{\infty } \frac{H_n H_{2 n}}{(2 n-1)^3} \end{equation*} \begin{equation*} =6 \log (2)-2 \log ^2(2)-\frac{1}{12}\log ^4(2)+\frac{1}{12} \log ^5(2)-\frac{3}{2} \zeta (2)-\frac{21}{8} \zeta (3)+\frac{173}{32} \zeta (4) \end{equation*} \begin{equation*} +\frac{527}{128} \zeta (5)-\frac{21 }{16}\zeta (2) \zeta (3)+\frac{3}{2} \log (2) \zeta (2)-\frac{7}{2}\log (2)\zeta (3)-4\log (2)\zeta (4)+\frac{1}{2} \log ^2(2) \zeta (2) \end{equation*} \begin{equation*} -\frac{1}{2}  \log ^3(2)\zeta (2)+\frac{7}{4}\log ^2(2)\zeta (3)-2 \operatorname{Li}_4\left(\frac{1}{2}\right)+2 \log (2)\operatorname{Li}_4\left(\frac{1}{2}\right), \end{equation*} or, after adjustments, the form $$\sum _{n=1}^{\infty}\frac{H_n H_{2 n}}{(2 n+1)^3}$$ $$=\frac{1}{12}\log ^5(2)+\frac{31}{128} \zeta (5)-\frac{1}{2} \log ^3(2)\zeta (2)+\frac{7}{4} \log ^2(2)  \zeta (3)-\frac{17}{8} \log (2)\zeta (4) \\+2\log (2) \operatorname{Li}_4\left(\frac{1}{2}\right).$$ Update I : A new series entry obtained based on the aforementioned series \begin{equation*} \sum _{n=1}^{\infty } \frac{H_n H_{2 n}^{(2)}}{(2 n)^2} \end{equation*} \begin{equation*} =\frac{23 }{32}\zeta (2) \zeta (3)-\frac{581}{128} \zeta (5)-\frac{2}{3}\log ^3(2) \zeta (2)+\frac{7}{4} \log^2(2)\zeta (3) +\frac{2}{15} \log ^5(2) \end{equation*} \begin{equation*} +4\log (2) \operatorname{Li}_4\left(\frac{1}{2}\right) +4 \operatorname{Li}_5\left(\frac{1}{2}\right); \end{equation*} Update II : Another new series entry obtained based on the aforementioned series \begin{equation*} \sum _{n=1}^{\infty } \frac{H_n H_{2 n}^2}{(2 n)^2} \end{equation*} \begin{equation*} =\frac{23 }{32}\zeta (2) \zeta (3)+\frac{917 }{128}\zeta (5)+\frac{2}{3}  \log ^3(2)\zeta (2)-\frac{7}{4}  \log ^2(2)\zeta (3)-\frac{2}{15} \log ^5(2) \end{equation*} \begin{equation*} -4 \log (2)\operatorname{Li}_4\left(\frac{1}{2}\right)-4 \operatorname{Li}_5\left(\frac{1}{2}\right); \end{equation*} Update III : And a new series entry from the same class of series with an unexpected (and outstanding) closed-form \begin{equation*} \sum _{n=1}^{\infty } \frac{H_{2n} H_{n}^{(2)}}{(2 n)^2}=\frac{101 }{64}\zeta (5)-\frac{5 }{16}\zeta (2) \zeta (3); \end{equation*} It's interesting to note that $\displaystyle \sum _{n=1}^{\infty } \frac{H_{n} H_{n}^{(2)}}{n^2}=\zeta(2)\zeta(3)+\zeta(5)$ , which may be found calculated in the book, (Almost) Impossible Integrals, Sums, and Series , by series manipulations. A note : The series from UPDATE III seems to be known in literature, and it already appeared here https://math.stackexchange.com/q/1868355 (see $(3)$ ). Update IV : Again a new series entry from the same class of series \begin{equation*} \sum _{n=1}^{\infty } \frac{H_n^2 H_{2 n}}{(2 n)^2} \end{equation*} \begin{equation*} =\frac{9 }{16}\zeta (2) \zeta (3)+\frac{421 }{64}\zeta (5)+\frac{2}{3} \log ^3(2)\zeta (2) -\frac{7}{4} \log ^2(2)\zeta (3) -\frac{2}{15} \log^5(2) \end{equation*} \begin{equation*} -4 \log(2)\operatorname{Li}_4\left(\frac{1}{2}\right) -4 \operatorname{Li}_5\left(\frac{1}{2}\right); \end{equation*} Update V : A strong series - September 26, 2019 $$\sum _{n=1}^{\infty } \frac{H_{2n} H_n^{(2)}}{(2 n+1)^2}$$ $$=\frac{4}{3}\log ^3(2)\zeta (2) -\frac{7}{2}\log^2(2)\zeta (3)-\frac{21}{16}\zeta(2)\zeta(3)+\frac{713}{64} \zeta (5)-\frac{4}{15} \log ^5(2)$$ $$-8 \log (2)\operatorname{Li}_4\left(\frac{1}{2}\right) -8\operatorname{Li}_5\left(\frac{1}{2}\right);$$ Update VI : Three very challenging series - September 28, 2019 $$i) \ \sum _{n=1}^{\infty } \frac{H_n H_{2 n}^{(2)}}{(2 n+1)^2}$$ $$=\frac{35}{32} \zeta (2) \zeta (3)-\frac{651}{128} \zeta (5)+\frac{1}{3}\log^3(2)\zeta(2)-\frac{7}{4}\log^2(2)\zeta (3)+\frac{53}{16} \log (2)\zeta (4) -\frac{1}{30} \log ^5(2)$$ $$+4 \operatorname{Li}_5\left(\frac{1}{2}\right);$$ $$ii) \ \sum _{n=1}^{\infty } \frac{H_n H_{2 n}^2}{(2 n+1)^2}$$ $$=\frac{35}{32} \zeta (2) \zeta (3)+\frac{465}{128} \zeta (5)+\frac{1}{2}\log^3(2)\zeta(2)-\frac{7}{4}\log^2(2)\zeta (3)-\frac{11}{16} \log (2)\zeta (4) -\frac{1}{12} \log ^5(2)$$ $$-2\log(2) \operatorname{Li}_4\left(\frac{1}{2}\right);$$ $$iii) \ \sum _{n=1}^{\infty } \frac{H_n^2 H_{2 n}}{(2 n+1)^2}$$ $$=\frac{21}{16} \zeta (2) \zeta (3)-\frac{217}{64} \zeta (5)+\frac{2}{3}\log^3(2)\zeta(2)-\frac{7}{4}\log^2(2)\zeta (3)+ \log (2)\zeta (4) -\frac{1}{15} \log ^5(2)$$ $$+8\operatorname{Li}_5\left(\frac{1}{2}\right);$$ Update VII : Critical series relation used in the Update VI - September 28, 2019 $$i) \sum _{n=1}^{\infty } \frac{H_n H_{2 n}^2}{(2 n+1)^2}-\sum _{n=1}^{\infty } \frac{H_n H_{2 n}^{(2)}}{(2 n+1)^2}$$ $$=\frac{1}{6}\log ^3(2)\zeta (2) -4\log (2)\zeta (4)+\frac{279}{32} \zeta (5)-\frac{1}{20} \log ^5(2)-2 \log (2)\operatorname{Li}_4\left(\frac{1}{2}\right) -4 \operatorname{Li}_5\left(\frac{1}{2}\right);$$ $$ii) \ 4 \sum _{n=1}^{\infty } \frac{H_n H_{2 n}^2}{(2 n+1)^2}-\sum _{n=1}^{\infty } \frac{H_n^2 H_{2 n}}{(2 n+1)^2}$$ $$=\frac{49}{16} \zeta (2) \zeta (3)+\frac{1147}{64}\zeta (5)+\frac{4}{3}\log^3(2)\zeta (2) -\frac{21}{4} \log ^2(2)\zeta (3) -\frac{15}{4}\log (2)\zeta (4)-\frac{4}{15} \log ^5(2)$$ $$-8 \log (2)\operatorname{Li}_4\left(\frac{1}{2}\right) -8\operatorname{Li}_5\left(\frac{1}{2}\right),$$ where $H_n^{(m)}=1+\frac{1}{2^m}+\cdots+\frac{1}{n^m}, \ m\ge1,$ designates the $n$ th generalized harmonic number of order $m$ , $\zeta$ represents the Riemann zeta function, and $\operatorname{Li}_n$ denotes the Polylogarithm function. A note : for example, for those interested, one of the possible ways of calculating both series from UPDATE III and UPDATE IV is based on building a system of relations with the two series by exploiting $\displaystyle \int_0^1 x^{n-1} \log^2(1-x)\textrm{d}x=\frac{H_n^2+H_n^{(2)}}{n}$ and $\displaystyle \sum_{n=1}^{\infty} x^n(H_n^2-H_n^{(2)})=\frac{\log^2(1-x)}{1-x}$ . Apart from this, the series from UPDATE III allows at least a (very) elegant approach by using different means. Using the first series we may obtain (based on the series representation of $\log(1-x)\log(1+x)$ and the integral $\int_0^1 x^{n-1}\operatorname{Li}_2(x)\textrm{d}x$ ) a way for proving that $$\int_0^1 \frac{\operatorname{Li}_2(x) \log (1+x) \log (1-x)}{x} \textrm{d}x=\frac{29 }{64}\zeta (5)-\frac{5 }{8}\zeta (2) \zeta (3).$$ Then, based on the solution below and using the alternating harmonic series in the book, (Almost) Impossible Integrals, Sums, and Series , we have $$\int_0^1 \frac{\operatorname{Li}_2(-x) \log (1+x) \log (1-x)}{x} \textrm{d}x$$ $$=\frac{5 }{16}\zeta (2) \zeta (3)+\frac{123 }{32}\zeta (5)+\frac{2}{3}  \log ^3(2)\zeta (2)-\frac{7}{4}  \log ^2(2)\zeta (3)-\frac{2}{15}\log ^5(2)\\-4 \log (2)\operatorname{Li}_4\left(\frac{1}{2}\right)-4 \operatorname{Li}_5\left(\frac{1}{2}\right).$$ And if we add up the two previous integrals, we get $$\int_0^1 \frac{\operatorname{Li}_2(x^2) \log (1+x) \log (1-x)}{x} \textrm{d}x$$ $$=\frac{275}{32}\zeta (5)-\frac{5 }{8}\zeta (2) \zeta (3)+\frac{4}{3}  \log ^3(2)\zeta (2)-\frac{7}{2}  \log ^2(2)\zeta (3)-\frac{4}{15}\log ^5(2)\\-8 \log (2)\operatorname{Li}_4\left(\frac{1}{2}\right)-8 \operatorname{Li}_5\left(\frac{1}{2}\right).$$ Update (integrals): Another curious integral arising during the calculations $$\int_0^1 \frac{x \log (x) \log(1-x^2) \operatorname{Li}_2(x)}{1-x^2} \textrm{d}x=\frac{41 }{32}\zeta (2) \zeta (3)-\frac{269 }{128}\zeta (5).$$ QUESTION : Have these series ever been known in literature? I'm not interested in solutions but only if the series appear anywhere in the literature.","Very recently Cornel discovered two ( update: in fact there are more as seen from the new entires )  fascinating results involving harmonic series using ideas from his book, (Almost) Impossible Integrals, Sums, and Series , and which are the core of a new paper he's preparing: and or, after adjustments, the form Update I : A new series entry obtained based on the aforementioned series Update II : Another new series entry obtained based on the aforementioned series Update III : And a new series entry from the same class of series with an unexpected (and outstanding) closed-form It's interesting to note that , which may be found calculated in the book, (Almost) Impossible Integrals, Sums, and Series , by series manipulations. A note : The series from UPDATE III seems to be known in literature, and it already appeared here https://math.stackexchange.com/q/1868355 (see ). Update IV : Again a new series entry from the same class of series Update V : A strong series - September 26, 2019 Update VI : Three very challenging series - September 28, 2019 Update VII : Critical series relation used in the Update VI - September 28, 2019 where designates the th generalized harmonic number of order , represents the Riemann zeta function, and denotes the Polylogarithm function. A note : for example, for those interested, one of the possible ways of calculating both series from UPDATE III and UPDATE IV is based on building a system of relations with the two series by exploiting and . Apart from this, the series from UPDATE III allows at least a (very) elegant approach by using different means. Using the first series we may obtain (based on the series representation of and the integral ) a way for proving that Then, based on the solution below and using the alternating harmonic series in the book, (Almost) Impossible Integrals, Sums, and Series , we have And if we add up the two previous integrals, we get Update (integrals): Another curious integral arising during the calculations QUESTION : Have these series ever been known in literature? I'm not interested in solutions but only if the series appear anywhere in the literature.","\begin{equation*}
\sum _{n=1}^{\infty } \frac{H_n H_{2 n}}{(2 n)^3}
\end{equation*} \begin{equation*}
=\frac{307}{128}\zeta(5)-\frac{1}{16}\zeta (2) \zeta (3)+\frac{1}{3}\log ^3(2)\zeta (2) -\frac{7}{8}  \log ^2(2)\zeta (3)-\frac{1}{15} \log ^5(2)
\end{equation*} \begin{equation*}
-2 \log (2) \operatorname{Li}_4\left(\frac{1}{2}\right) -2 \operatorname{Li}_5\left(\frac{1}{2}\right);
\end{equation*} \begin{equation*}
\sum _{n=1}^{\infty } \frac{H_n H_{2 n}}{(2 n-1)^3}
\end{equation*} \begin{equation*}
=6 \log (2)-2 \log ^2(2)-\frac{1}{12}\log ^4(2)+\frac{1}{12} \log ^5(2)-\frac{3}{2} \zeta (2)-\frac{21}{8} \zeta (3)+\frac{173}{32} \zeta (4)
\end{equation*} \begin{equation*}
+\frac{527}{128} \zeta (5)-\frac{21 }{16}\zeta (2) \zeta (3)+\frac{3}{2} \log (2) \zeta (2)-\frac{7}{2}\log (2)\zeta (3)-4\log (2)\zeta (4)+\frac{1}{2} \log ^2(2) \zeta (2)
\end{equation*} \begin{equation*}
-\frac{1}{2}  \log ^3(2)\zeta (2)+\frac{7}{4}\log ^2(2)\zeta (3)-2 \operatorname{Li}_4\left(\frac{1}{2}\right)+2 \log (2)\operatorname{Li}_4\left(\frac{1}{2}\right),
\end{equation*} \sum _{n=1}^{\infty}\frac{H_n H_{2 n}}{(2 n+1)^3} =\frac{1}{12}\log ^5(2)+\frac{31}{128} \zeta (5)-\frac{1}{2} \log ^3(2)\zeta (2)+\frac{7}{4} \log ^2(2)  \zeta (3)-\frac{17}{8} \log (2)\zeta (4) \\+2\log (2) \operatorname{Li}_4\left(\frac{1}{2}\right). \begin{equation*}
\sum _{n=1}^{\infty } \frac{H_n H_{2 n}^{(2)}}{(2 n)^2}
\end{equation*} \begin{equation*}
=\frac{23 }{32}\zeta (2) \zeta (3)-\frac{581}{128} \zeta (5)-\frac{2}{3}\log ^3(2) \zeta (2)+\frac{7}{4} \log^2(2)\zeta (3) +\frac{2}{15} \log ^5(2)
\end{equation*} \begin{equation*}
+4\log (2) \operatorname{Li}_4\left(\frac{1}{2}\right) +4 \operatorname{Li}_5\left(\frac{1}{2}\right);
\end{equation*} \begin{equation*}
\sum _{n=1}^{\infty } \frac{H_n H_{2 n}^2}{(2 n)^2}
\end{equation*} \begin{equation*}
=\frac{23 }{32}\zeta (2) \zeta (3)+\frac{917 }{128}\zeta (5)+\frac{2}{3}  \log ^3(2)\zeta (2)-\frac{7}{4}  \log ^2(2)\zeta (3)-\frac{2}{15} \log ^5(2)
\end{equation*} \begin{equation*}
-4 \log (2)\operatorname{Li}_4\left(\frac{1}{2}\right)-4 \operatorname{Li}_5\left(\frac{1}{2}\right);
\end{equation*} \begin{equation*}
\sum _{n=1}^{\infty } \frac{H_{2n} H_{n}^{(2)}}{(2 n)^2}=\frac{101 }{64}\zeta (5)-\frac{5 }{16}\zeta (2) \zeta (3);
\end{equation*} \displaystyle \sum _{n=1}^{\infty } \frac{H_{n} H_{n}^{(2)}}{n^2}=\zeta(2)\zeta(3)+\zeta(5) (3) \begin{equation*}
\sum _{n=1}^{\infty } \frac{H_n^2 H_{2 n}}{(2 n)^2}
\end{equation*} \begin{equation*}
=\frac{9 }{16}\zeta (2) \zeta (3)+\frac{421 }{64}\zeta (5)+\frac{2}{3} \log ^3(2)\zeta (2) -\frac{7}{4} \log ^2(2)\zeta (3) -\frac{2}{15} \log^5(2)
\end{equation*} \begin{equation*}
-4 \log(2)\operatorname{Li}_4\left(\frac{1}{2}\right) -4 \operatorname{Li}_5\left(\frac{1}{2}\right);
\end{equation*} \sum _{n=1}^{\infty } \frac{H_{2n} H_n^{(2)}}{(2 n+1)^2} =\frac{4}{3}\log ^3(2)\zeta (2) -\frac{7}{2}\log^2(2)\zeta (3)-\frac{21}{16}\zeta(2)\zeta(3)+\frac{713}{64} \zeta (5)-\frac{4}{15} \log ^5(2) -8 \log (2)\operatorname{Li}_4\left(\frac{1}{2}\right) -8\operatorname{Li}_5\left(\frac{1}{2}\right); i) \ \sum _{n=1}^{\infty } \frac{H_n H_{2 n}^{(2)}}{(2 n+1)^2} =\frac{35}{32} \zeta (2) \zeta (3)-\frac{651}{128} \zeta (5)+\frac{1}{3}\log^3(2)\zeta(2)-\frac{7}{4}\log^2(2)\zeta (3)+\frac{53}{16} \log (2)\zeta (4) -\frac{1}{30} \log ^5(2) +4 \operatorname{Li}_5\left(\frac{1}{2}\right); ii) \ \sum _{n=1}^{\infty } \frac{H_n H_{2 n}^2}{(2 n+1)^2} =\frac{35}{32} \zeta (2) \zeta (3)+\frac{465}{128} \zeta (5)+\frac{1}{2}\log^3(2)\zeta(2)-\frac{7}{4}\log^2(2)\zeta (3)-\frac{11}{16} \log (2)\zeta (4) -\frac{1}{12} \log ^5(2) -2\log(2) \operatorname{Li}_4\left(\frac{1}{2}\right); iii) \ \sum _{n=1}^{\infty } \frac{H_n^2 H_{2 n}}{(2 n+1)^2} =\frac{21}{16} \zeta (2) \zeta (3)-\frac{217}{64} \zeta (5)+\frac{2}{3}\log^3(2)\zeta(2)-\frac{7}{4}\log^2(2)\zeta (3)+ \log (2)\zeta (4) -\frac{1}{15} \log ^5(2) +8\operatorname{Li}_5\left(\frac{1}{2}\right); i) \sum _{n=1}^{\infty } \frac{H_n H_{2 n}^2}{(2 n+1)^2}-\sum _{n=1}^{\infty } \frac{H_n H_{2 n}^{(2)}}{(2 n+1)^2} =\frac{1}{6}\log ^3(2)\zeta (2) -4\log (2)\zeta (4)+\frac{279}{32} \zeta (5)-\frac{1}{20} \log ^5(2)-2 \log (2)\operatorname{Li}_4\left(\frac{1}{2}\right) -4 \operatorname{Li}_5\left(\frac{1}{2}\right); ii) \ 4 \sum _{n=1}^{\infty } \frac{H_n H_{2 n}^2}{(2 n+1)^2}-\sum _{n=1}^{\infty } \frac{H_n^2 H_{2 n}}{(2 n+1)^2} =\frac{49}{16} \zeta (2) \zeta (3)+\frac{1147}{64}\zeta (5)+\frac{4}{3}\log^3(2)\zeta (2) -\frac{21}{4} \log ^2(2)\zeta (3) -\frac{15}{4}\log (2)\zeta (4)-\frac{4}{15} \log ^5(2) -8 \log (2)\operatorname{Li}_4\left(\frac{1}{2}\right) -8\operatorname{Li}_5\left(\frac{1}{2}\right), H_n^{(m)}=1+\frac{1}{2^m}+\cdots+\frac{1}{n^m}, \ m\ge1, n m \zeta \operatorname{Li}_n \displaystyle \int_0^1 x^{n-1} \log^2(1-x)\textrm{d}x=\frac{H_n^2+H_n^{(2)}}{n} \displaystyle \sum_{n=1}^{\infty} x^n(H_n^2-H_n^{(2)})=\frac{\log^2(1-x)}{1-x} \log(1-x)\log(1+x) \int_0^1 x^{n-1}\operatorname{Li}_2(x)\textrm{d}x \int_0^1 \frac{\operatorname{Li}_2(x) \log (1+x) \log (1-x)}{x} \textrm{d}x=\frac{29 }{64}\zeta (5)-\frac{5 }{8}\zeta (2) \zeta (3). \int_0^1 \frac{\operatorname{Li}_2(-x) \log (1+x) \log (1-x)}{x} \textrm{d}x =\frac{5 }{16}\zeta (2) \zeta (3)+\frac{123 }{32}\zeta (5)+\frac{2}{3}  \log ^3(2)\zeta (2)-\frac{7}{4}  \log ^2(2)\zeta (3)-\frac{2}{15}\log ^5(2)\\-4 \log (2)\operatorname{Li}_4\left(\frac{1}{2}\right)-4 \operatorname{Li}_5\left(\frac{1}{2}\right). \int_0^1 \frac{\operatorname{Li}_2(x^2) \log (1+x) \log (1-x)}{x} \textrm{d}x =\frac{275}{32}\zeta (5)-\frac{5 }{8}\zeta (2) \zeta (3)+\frac{4}{3}  \log ^3(2)\zeta (2)-\frac{7}{2}  \log ^2(2)\zeta (3)-\frac{4}{15}\log ^5(2)\\-8 \log (2)\operatorname{Li}_4\left(\frac{1}{2}\right)-8 \operatorname{Li}_5\left(\frac{1}{2}\right). \int_0^1 \frac{x \log (x) \log(1-x^2) \operatorname{Li}_2(x)}{1-x^2} \textrm{d}x=\frac{41 }{32}\zeta (2) \zeta (3)-\frac{269 }{128}\zeta (5).","['calculus', 'integration', 'sequences-and-series', 'reference-request', 'harmonic-numbers']"
96,Closed form expression for infinite series,Closed form expression for infinite series,,"I was given the following function: $$ f(x) =  x + \frac{2x^3}{1\cdot3} + \frac{2\cdot4x^5}{1\cdot3\cdot5} + \frac{2\cdot4\cdot6x^7}{1\cdot3\cdot5\cdot7}...   $$ $$ \forall x    \in [0,1) $$ And then I was asked to find the value of $ f(\frac{1}{\sqrt{2}}) $ , which obviously requires me to compute the closed form expression of the infinite series. I tried 'Integration as a limit of sum' but I was unable to modify the expression accordingly. How do I approach the problem?","I was given the following function: And then I was asked to find the value of , which obviously requires me to compute the closed form expression of the infinite series. I tried 'Integration as a limit of sum' but I was unable to modify the expression accordingly. How do I approach the problem?"," f(x) =  x + \frac{2x^3}{1\cdot3} + \frac{2\cdot4x^5}{1\cdot3\cdot5} + \frac{2\cdot4\cdot6x^7}{1\cdot3\cdot5\cdot7}...     \forall x    \in [0,1)   f(\frac{1}{\sqrt{2}}) ","['calculus', 'sequences-and-series']"
97,Prove that polynomial of degree $4$ with real roots cannot have $\pm 1$ as coefficients (IITJEE),Prove that polynomial of degree  with real roots cannot have  as coefficients (IITJEE),4 \pm 1,"So I was going through  my 11th class package on Quadratic equations and I saw a question to prove that a polynomial of $4$th degree with all real roots cannot have $\pm 1$ as all its coefficients. I tried proving it using calculus, by showing that at least one consecutive maxima  and minima will lie either above or below the x axis, but couldn't solve it using that. I also tried using Descartes Rule of Signs but couldn't solve it with that too. Any help?","So I was going through  my 11th class package on Quadratic equations and I saw a question to prove that a polynomial of $4$th degree with all real roots cannot have $\pm 1$ as all its coefficients. I tried proving it using calculus, by showing that at least one consecutive maxima  and minima will lie either above or below the x axis, but couldn't solve it using that. I also tried using Descartes Rule of Signs but couldn't solve it with that too. Any help?",,"['calculus', 'algebra-precalculus', 'polynomials', 'quadratics']"
98,Some interesting integrals with dilogarithm,Some interesting integrals with dilogarithm,,"Calculating without techniques involving the contour integration $$a) \ \int_0^{2\pi} \frac{(\operatorname{Li}_2(e^{-i x}))^2-(\operatorname{Li}_2(e^{i x}))^2}{e^{-i x}-e^{i x}}\textrm{d}x;$$ $$b) \ \int_0^{2\pi} \frac{(\operatorname{Li}_2(e^{-i x}))^3-(\operatorname{Li}_2(e^{i x}))^3}{e^{-i x}-e^{i x}}\textrm{d}x.$$ I'm working now on such a method. What would your real method inspiration be here? Supplementary question : Calculate $$ \int_0^{2\pi} \frac{(\operatorname{Li}_2(e^{-i x}))^4-(\operatorname{Li}_2(e^{i x}))^4}{e^{-i x}-e^{i x}}\textrm{d}x.$$ Moreover, may we hope for a generalization of the type below? $$ I(n)=\int_0^{2\pi} \frac{(\operatorname{Li}_2(e^{-i x}))^n-(\operatorname{Li}_2(e^{i x}))^n}{e^{-i x}-e^{i x}}\textrm{d}x.$$ Preparing another two generalizations: $$ i) \ J(n,m)=\int_0^{2\pi} \frac{(\operatorname{Li}_m(e^{-i x}))^n-(\operatorname{Li}_m(e^{i x}))^n}{e^{-i x}-e^{i x}}\textrm{d}x;$$ $$ ii) \ K(n)=\int_0^{2\pi} \frac{\operatorname{Li}_2(e^{-i x})\operatorname{Li}_3(e^{-i x})\cdots \operatorname{Li}_n(e^{-i x})-\operatorname{Li}_2(e^{i x})\operatorname{Li}_3(e^{i x})\cdots \operatorname{Li}_n(e^{i x})}{e^{-i x}-e^{i x}}\textrm{d}x.$$","Calculating without techniques involving the contour integration $$a) \ \int_0^{2\pi} \frac{(\operatorname{Li}_2(e^{-i x}))^2-(\operatorname{Li}_2(e^{i x}))^2}{e^{-i x}-e^{i x}}\textrm{d}x;$$ $$b) \ \int_0^{2\pi} \frac{(\operatorname{Li}_2(e^{-i x}))^3-(\operatorname{Li}_2(e^{i x}))^3}{e^{-i x}-e^{i x}}\textrm{d}x.$$ I'm working now on such a method. What would your real method inspiration be here? Supplementary question : Calculate $$ \int_0^{2\pi} \frac{(\operatorname{Li}_2(e^{-i x}))^4-(\operatorname{Li}_2(e^{i x}))^4}{e^{-i x}-e^{i x}}\textrm{d}x.$$ Moreover, may we hope for a generalization of the type below? $$ I(n)=\int_0^{2\pi} \frac{(\operatorname{Li}_2(e^{-i x}))^n-(\operatorname{Li}_2(e^{i x}))^n}{e^{-i x}-e^{i x}}\textrm{d}x.$$ Preparing another two generalizations: $$ i) \ J(n,m)=\int_0^{2\pi} \frac{(\operatorname{Li}_m(e^{-i x}))^n-(\operatorname{Li}_m(e^{i x}))^n}{e^{-i x}-e^{i x}}\textrm{d}x;$$ $$ ii) \ K(n)=\int_0^{2\pi} \frac{\operatorname{Li}_2(e^{-i x})\operatorname{Li}_3(e^{-i x})\cdots \operatorname{Li}_n(e^{-i x})-\operatorname{Li}_2(e^{i x})\operatorname{Li}_3(e^{i x})\cdots \operatorname{Li}_n(e^{i x})}{e^{-i x}-e^{i x}}\textrm{d}x.$$",,"['calculus', 'integration', 'complex-analysis', 'definite-integrals', 'special-functions']"
99,How to prove $\lim_{x\rightarrow0^+}\sum_{k=1}^{+\infty}\frac{\sin{(x\sqrt{k})}}{k}=\pi$?,How to prove ?,\lim_{x\rightarrow0^+}\sum_{k=1}^{+\infty}\frac{\sin{(x\sqrt{k})}}{k}=\pi,$$\lim_{x\rightarrow0^+}\sum_{k=1}^{+\infty}\frac{\sin{(x\sqrt{k})}}{k}=\pi$$ I have tried to expand the $\sin{(x\sqrt{k})}$ but still cannot get $\pi$.,$$\lim_{x\rightarrow0^+}\sum_{k=1}^{+\infty}\frac{\sin{(x\sqrt{k})}}{k}=\pi$$ I have tried to expand the $\sin{(x\sqrt{k})}$ but still cannot get $\pi$.,,"['calculus', 'sequences-and-series', 'limits']"
