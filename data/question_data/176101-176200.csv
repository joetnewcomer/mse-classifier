,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Double Integral $\iint\limits_D\frac{dx\,dy}{(x^2+y^2)^2}$ where $D=\{(x,y): x^2+y^2\le1,\space x+y\ge1\}$",Double Integral  where,"\iint\limits_D\frac{dx\,dy}{(x^2+y^2)^2} D=\{(x,y): x^2+y^2\le1,\space x+y\ge1\}","Let $D=\{(x,y)\in \Bbb R^2 : x^2+y^2\le1,\space x+y\ge1\}$.  The integral to be calculated over $D$ is the following: \begin{equation} \iint_D \frac{dx\,dy}{(x^2+y^2)^2} \end{equation} I do not know how to approach the problem.  I have tried integrating the function in cartesian coordinates but it doesn't seem to work out. I have also tried the variable change $u=x^2+y^2$ and $v=x+y$ (with the associated jacobian transformation) and again I cannot obtain the result.","Let $D=\{(x,y)\in \Bbb R^2 : x^2+y^2\le1,\space x+y\ge1\}$.  The integral to be calculated over $D$ is the following: \begin{equation} \iint_D \frac{dx\,dy}{(x^2+y^2)^2} \end{equation} I do not know how to approach the problem.  I have tried integrating the function in cartesian coordinates but it doesn't seem to work out. I have also tried the variable change $u=x^2+y^2$ and $v=x+y$ (with the associated jacobian transformation) and again I cannot obtain the result.",,"['calculus', 'integration', 'multivariable-calculus', 'multiple-integral', 'bounds-of-integration']"
1,Find a vector field $G$ with curl ($G$) = $F$,Find a vector field  with curl () =,G G F,"Let $F(x, y, z) = (y, z, x^2)$ on $\mathbb{R}^3$. We know that $$y = \frac{\partial G_3}{ \partial y} - \frac{\partial G_2 }{\partial z}, \\ z = \frac{\partial G_1}{ \partial z} - \frac{\partial G_3 }{\partial x}, \\  x^2 = \frac{\partial G_2}{ \partial x} - \frac{\partial G_1 }{\partial y}.$$ How do I go further?","Let $F(x, y, z) = (y, z, x^2)$ on $\mathbb{R}^3$. We know that $$y = \frac{\partial G_3}{ \partial y} - \frac{\partial G_2 }{\partial z}, \\ z = \frac{\partial G_1}{ \partial z} - \frac{\partial G_3 }{\partial x}, \\  x^2 = \frac{\partial G_2}{ \partial x} - \frac{\partial G_1 }{\partial y}.$$ How do I go further?",,"['multivariable-calculus', 'vector-fields']"
2,Surface Integral,Surface Integral,,"How to find the surface integral of such term $\int \int_{F_+} (y-z)dydz + (z-x)dzdx +(x-y)dxdy$ where $F_+$ is the surface $x^2+y^2 = z^2$ $(0 \leq z \leq h )$ oriented outward. There were other problems, where I could just parametrize the $F_+$ and then compute $\vec{n}$ and simply put in the surface integral formula, but here I'm confused on how to carry on. Hints please. Thanks.","How to find the surface integral of such term $\int \int_{F_+} (y-z)dydz + (z-x)dzdx +(x-y)dxdy$ where $F_+$ is the surface $x^2+y^2 = z^2$ $(0 \leq z \leq h )$ oriented outward. There were other problems, where I could just parametrize the $F_+$ and then compute $\vec{n}$ and simply put in the surface integral formula, but here I'm confused on how to carry on. Hints please. Thanks.",,['multivariable-calculus']
3,divergence free vector fields on non-simply connected domains,divergence free vector fields on non-simply connected domains,,"We know that divergence free vector fields are themselves curls of vector fields on simply connected domains. I want to construct a counter example in the case the domain is not simply connected. So consider an infinite line of charge along the $z$-axis of constant charge density. Then its electric field is given (unless I have made a mistake!) by $$\vec{E} = k\langle\frac{x}{x^2+y^2}, \frac{y}{x^2+ y^2},0\rangle.$$ By Gauss' theorem this should be divergence free (also follows from a simple computation). Can it be shown that this is not the curl of some vector field? I guess in general if we can find a surface without boundary on which the flux is not zero then by Stokes' theorem the electric field cannot be the curl of a vector potential. But the problem is that there cannot find a closed surface without boundary around the $z$-axis, and so maybe one has to take the unit sphere and remove a small cylinder and use some approximation argument. Any ideas?","We know that divergence free vector fields are themselves curls of vector fields on simply connected domains. I want to construct a counter example in the case the domain is not simply connected. So consider an infinite line of charge along the $z$-axis of constant charge density. Then its electric field is given (unless I have made a mistake!) by $$\vec{E} = k\langle\frac{x}{x^2+y^2}, \frac{y}{x^2+ y^2},0\rangle.$$ By Gauss' theorem this should be divergence free (also follows from a simple computation). Can it be shown that this is not the curl of some vector field? I guess in general if we can find a surface without boundary on which the flux is not zero then by Stokes' theorem the electric field cannot be the curl of a vector potential. But the problem is that there cannot find a closed surface without boundary around the $z$-axis, and so maybe one has to take the unit sphere and remove a small cylinder and use some approximation argument. Any ideas?",,['multivariable-calculus']
4,"Converting unit square domain in (x,y) to polar coordinates","Converting unit square domain in (x,y) to polar coordinates",,I have the following double integral $\int_{0}^{1}\int_{0}^{1}\frac{x}{\sqrt{x^2+y^2}}dxdy$ The integrand is fairly simple: $\frac{x}{\sqrt{x^2+y^2}}dxdy=\frac{r\cos(\theta )}{\sqrt{r^2}}rd\theta{}dr=r\cos{(\theta)}d\theta{}dr$ My trouble is with the limits of integration. I've tried: $0 \leq y \leq 1$ means $0 \leq{} r\sin(\theta{}) \leq 1$ so $0 \leq \theta \leq arcsin(1/r)$ But why isn't it just $0<\theta < \pi{}/2$ since the unit square is in the first quadrant? My hunch for $r$ is that it varies within $1 \leq r \leq \sqrt{2}$ So we have $\int_{1}^{\sqrt{2}}\int_{0}^{\arcsin(1/r)}r\cos{(\theta)}d\theta{}dr=\int_{1}^{\sqrt{2}}1dr=\sqrt{2}-1$ My book gives $2 (\ln(\sqrt{2} + 1) + \sqrt{2} − 1)$ Any advice on how to visualize this is much appreciated.,I have the following double integral The integrand is fairly simple: My trouble is with the limits of integration. I've tried: means so But why isn't it just since the unit square is in the first quadrant? My hunch for is that it varies within So we have My book gives Any advice on how to visualize this is much appreciated.,\int_{0}^{1}\int_{0}^{1}\frac{x}{\sqrt{x^2+y^2}}dxdy \frac{x}{\sqrt{x^2+y^2}}dxdy=\frac{r\cos(\theta )}{\sqrt{r^2}}rd\theta{}dr=r\cos{(\theta)}d\theta{}dr 0 \leq y \leq 1 0 \leq{} r\sin(\theta{}) \leq 1 0 \leq \theta \leq arcsin(1/r) 0<\theta < \pi{}/2 r 1 \leq r \leq \sqrt{2} \int_{1}^{\sqrt{2}}\int_{0}^{\arcsin(1/r)}r\cos{(\theta)}d\theta{}dr=\int_{1}^{\sqrt{2}}1dr=\sqrt{2}-1 2 (\ln(\sqrt{2} + 1) + \sqrt{2} − 1),"['integration', 'multivariable-calculus', 'polar-coordinates']"
5,Extrema of $e^{xy}$ under condition $x^2+y^2\leq 2$,Extrema of  under condition,e^{xy} x^2+y^2\leq 2,"Let $f:\mathbb{R}^2 \rightarrow \mathbb{R}$ such that $f(x, y)=e^{xy}$. Find the extrema of the function under the restriction $(x, y) \in \mathcal{D}$ where $\mathcal{D}=\{(x,y)\mid x^2+y^2\leq 2\}$. Ok. I proved using the gradient that in the internal  there are no extrema values since the gradient is not equal zero for any $x, y$. Now what about the frontier? I cannot have a visualization (graph) of the function to use it in order to evaluate /see the extrema on the frontier. And I cannot use the Lagrange theorem. Any suggestions?","Let $f:\mathbb{R}^2 \rightarrow \mathbb{R}$ such that $f(x, y)=e^{xy}$. Find the extrema of the function under the restriction $(x, y) \in \mathcal{D}$ where $\mathcal{D}=\{(x,y)\mid x^2+y^2\leq 2\}$. Ok. I proved using the gradient that in the internal  there are no extrema values since the gradient is not equal zero for any $x, y$. Now what about the frontier? I cannot have a visualization (graph) of the function to use it in order to evaluate /see the extrema on the frontier. And I cannot use the Lagrange theorem. Any suggestions?",,"['multivariable-calculus', 'maxima-minima']"
6,Find a path of a particle,Find a path of a particle,,"I'm stuck with the following question: Let P be a particle at point $(1,2)$ on the surface $z=x^2y^2$. At $t=0$ the particle is left and moves freely. Find the path that the particle passes during the period of time between $t=0$ and until is stops. My Try: First of all, I used GeoGebra to draw the function $f(x,y)=x^2y^2$ and the point $P(1,2,4)$. I know that the particle will move in the direction of the gradient, hence I calculated the gradient$$\vec{\nabla}f(x,y)=(2xy^2,2x^2y)\underbrace{\Rightarrow}_{x=1,y=2}\vec{\nabla}f=(8,4)$$ Now, I think that the particle will stop when it reaches the origin, but I'm not sure it is true, and if it is true how to explain it. Also, I don't understand how the calculation of $\vec{\nabla}f(x,y)$ could help me in finding the explicit form of the path. Please help, thank you.","I'm stuck with the following question: Let P be a particle at point $(1,2)$ on the surface $z=x^2y^2$. At $t=0$ the particle is left and moves freely. Find the path that the particle passes during the period of time between $t=0$ and until is stops. My Try: First of all, I used GeoGebra to draw the function $f(x,y)=x^2y^2$ and the point $P(1,2,4)$. I know that the particle will move in the direction of the gradient, hence I calculated the gradient$$\vec{\nabla}f(x,y)=(2xy^2,2x^2y)\underbrace{\Rightarrow}_{x=1,y=2}\vec{\nabla}f=(8,4)$$ Now, I think that the particle will stop when it reaches the origin, but I'm not sure it is true, and if it is true how to explain it. Also, I don't understand how the calculation of $\vec{\nabla}f(x,y)$ could help me in finding the explicit form of the path. Please help, thank you.",,"['multivariable-calculus', 'functions']"
7,Does being a local minimum imply a positive definite hessian?,Does being a local minimum imply a positive definite hessian?,,"If $p\in R^{m}$ is a local minimum of  $F:R^{m}\rightarrow R$, then can we conclude that $\dfrac{\partial ^2F}{\partial x \partial x'}[p]$ is positive definite? I guess you guys answers have concluded that $\dfrac{\partial ^2F}{\partial x \partial x'}[p]$ can be only positive semi-definite. How can I prove this result then?","If $p\in R^{m}$ is a local minimum of  $F:R^{m}\rightarrow R$, then can we conclude that $\dfrac{\partial ^2F}{\partial x \partial x'}[p]$ is positive definite? I guess you guys answers have concluded that $\dfrac{\partial ^2F}{\partial x \partial x'}[p]$ can be only positive semi-definite. How can I prove this result then?",,"['multivariable-calculus', 'optimization']"
8,derivative of a symmetric bilinear form (quadratic form version),derivative of a symmetric bilinear form (quadratic form version),,"Let $A=A^T\in \mathbb R^{k\times k}$ be a nonzero symmetric matrix and define $F:\mathbb R^k\to\mathbb R$ by $$f(x):=x^TAx$$ Then why $df(x)\xi=2x^TA\xi$ for $x,\xi\in\mathbb R^k$?","Let $A=A^T\in \mathbb R^{k\times k}$ be a nonzero symmetric matrix and define $F:\mathbb R^k\to\mathbb R$ by $$f(x):=x^TAx$$ Then why $df(x)\xi=2x^TA\xi$ for $x,\xi\in\mathbb R^k$?",,"['linear-algebra', 'multivariable-calculus', 'differential-geometry', 'derivatives', 'quadratic-forms']"
9,limits multivariable calculus. where am i wrong with my attempt?,limits multivariable calculus. where am i wrong with my attempt?,,"P : $\lim_{(x,y) \to (0,0)} f(x,y)$ where $$f(x,y) = y\sin\frac1x + \frac{xy}{x^{2} + y^{2}}$$ Text book says Limit doesnot exist . So where i am wrong with my proof below ? EDITED ATTEMPT : Or we can write $2 \delta < \varepsilon$, which shows limit exists. Is there something I missed?","P : $\lim_{(x,y) \to (0,0)} f(x,y)$ where $$f(x,y) = y\sin\frac1x + \frac{xy}{x^{2} + y^{2}}$$ Text book says Limit doesnot exist . So where i am wrong with my proof below ? EDITED ATTEMPT : Or we can write $2 \delta < \varepsilon$, which shows limit exists. Is there something I missed?",,"['multivariable-calculus', 'self-learning']"
10,"What is the gradient of $f(x, y, z) = \sqrt{x^2+y^2+z^2}$?",What is the gradient of ?,"f(x, y, z) = \sqrt{x^2+y^2+z^2}","What is the gradient of $f(x, y, z) = \sqrt{x^2+y^2+z^2}$? I know that $\nabla f = \left\langle\frac{\partial f}{\partial x}, \frac{\partial f}{\partial y}, \frac{\partial f}{\partial z}\right\rangle$ or equivalently $\nabla f = \frac{\partial f}{\partial x}\mathbf{i} + \frac{\partial f}{\partial y}\mathbf{j} + \frac{\partial f}{\partial z}\mathbf{k}$. Eventually, I am going to evaluate this gradient at a point and then dot it with some given unit vector to find a directional derivative. I think maybe what is troubling me is the radical in $f$. Will I have to use the chain rule in order to find the three partial derivatives? I tried this: $$\frac{\partial f}{\partial x} = \frac{1}{2}(x^2 + y^2 + z^2)^{-\frac{1}{2}}2x$$ $$= \frac{x}{\sqrt{x^2 + y^2 + z^2}}$$ That result looks ugly to me. However, if I did that partial derivative correctly, then I think I know what I am doing.","What is the gradient of $f(x, y, z) = \sqrt{x^2+y^2+z^2}$? I know that $\nabla f = \left\langle\frac{\partial f}{\partial x}, \frac{\partial f}{\partial y}, \frac{\partial f}{\partial z}\right\rangle$ or equivalently $\nabla f = \frac{\partial f}{\partial x}\mathbf{i} + \frac{\partial f}{\partial y}\mathbf{j} + \frac{\partial f}{\partial z}\mathbf{k}$. Eventually, I am going to evaluate this gradient at a point and then dot it with some given unit vector to find a directional derivative. I think maybe what is troubling me is the radical in $f$. Will I have to use the chain rule in order to find the three partial derivatives? I tried this: $$\frac{\partial f}{\partial x} = \frac{1}{2}(x^2 + y^2 + z^2)^{-\frac{1}{2}}2x$$ $$= \frac{x}{\sqrt{x^2 + y^2 + z^2}}$$ That result looks ugly to me. However, if I did that partial derivative correctly, then I think I know what I am doing.",,"['multivariable-calculus', 'partial-derivative']"
11,whats the difference between $|v|$ and $||v||$?,whats the difference between  and ?,|v| ||v||,$v$ being a vector. I never understood what they mean and haven't found online resources. Just a quick question. Thought it was absolute and magnitude respectively when regarding vectors. need confirmation,$v$ being a vector. I never understood what they mean and haven't found online resources. Just a quick question. Thought it was absolute and magnitude respectively when regarding vectors. need confirmation,,"['multivariable-calculus', 'notation', 'normed-spaces']"
12,"Find partial derivative at point $(0,0)$ of $(xy)/(x^2+y^2)$",Find partial derivative at point  of,"(0,0) (xy)/(x^2+y^2)","It's a bit wierd question but I have to ask it. $$ \text{Let }\space f(x, y) = \begin{cases} \dfrac{xy}{x^2 + y^2},  & \text{if $(x, y) \ne (0,0)$} \\ 0, & \text{if $(x, y) = (0, 0)$}  \\ \end{cases}$$ The following question is: Do partial derivatives of $f(x, y)$ exist at $(0, 0)$? If so, find them. if not, prove. As I know it should be simple, Just derive $\dfrac{df}{\partial x} 0 = 0, \dfrac{df}{\partial y} 0 = 0$. But I must admit it seems wierd. where have I wrong? How should I solve such questions? thanks in advance!","It's a bit wierd question but I have to ask it. $$ \text{Let }\space f(x, y) = \begin{cases} \dfrac{xy}{x^2 + y^2},  & \text{if $(x, y) \ne (0,0)$} \\ 0, & \text{if $(x, y) = (0, 0)$}  \\ \end{cases}$$ The following question is: Do partial derivatives of $f(x, y)$ exist at $(0, 0)$? If so, find them. if not, prove. As I know it should be simple, Just derive $\dfrac{df}{\partial x} 0 = 0, \dfrac{df}{\partial y} 0 = 0$. But I must admit it seems wierd. where have I wrong? How should I solve such questions? thanks in advance!",,"['multivariable-calculus', 'partial-derivative']"
13,"Prove that $2\int_a^b \int_a^x f(x)f(y) \, dy \, dx = \left[ \int_a^b f(x) \, dx \right]^2$",Prove that,"2\int_a^b \int_a^x f(x)f(y) \, dy \, dx = \left[ \int_a^b f(x) \, dx \right]^2","Suppose $f$ is a continuous single-variable function, prove that: $$2\int_a^b \int_a^x f(x)f(y) \, dy \, dx = \left[ \int_a^b f(x) \, dx \right]^2$$ This question was just on my Calculus III final exam and I couldn't figure it out, could someone provide some insight, please?","Suppose $f$ is a continuous single-variable function, prove that: $$2\int_a^b \int_a^x f(x)f(y) \, dy \, dx = \left[ \int_a^b f(x) \, dx \right]^2$$ This question was just on my Calculus III final exam and I couldn't figure it out, could someone provide some insight, please?",,"['integration', 'multivariable-calculus']"
14,Tangent plane and Parametrized Surface,Tangent plane and Parametrized Surface,,"""Given a sphere of radius $2$ centered at the origin, find the equation for the plane that is tangent to it at the point $(1,1,\sqrt[]{2})$ by considering the sphere as a surface parametrzed by $\Phi(\theta, \phi) = (2\cos(\theta)\sin(\phi), 2\sin(\theta)\sin(\phi), 2\cos(\phi))$"" I'm not really sure what I'm supposed to do here. The question is asking for a plane tangent to a point, but why do we care about the radius and parametrization of the sphere? Couldn't I find a tangent plane to the point without that information?","""Given a sphere of radius $2$ centered at the origin, find the equation for the plane that is tangent to it at the point $(1,1,\sqrt[]{2})$ by considering the sphere as a surface parametrzed by $\Phi(\theta, \phi) = (2\cos(\theta)\sin(\phi), 2\sin(\theta)\sin(\phi), 2\cos(\phi))$"" I'm not really sure what I'm supposed to do here. The question is asking for a plane tangent to a point, but why do we care about the radius and parametrization of the sphere? Couldn't I find a tangent plane to the point without that information?",,['multivariable-calculus']
15,Double integral,Double integral,,"Calculate the iterated integral $$\int_{1} ^4\int_{1} ^2 \left(\frac xy+\frac yx\right)\,dy\,dx$$ This is the work that I've done, but it'd lead me to the wrong answer, so either I did it completely wrong or I made in error in my calculation. $$\int_{1} ^4\int_{1} ^2 \left(\frac xy+\frac yx\right)\,dy\,dx= \int_{1} ^4 \left[xln(y)+{y^2\over 2x}  \right]_{1} ^2 dx=\int_{1} ^4 \left[xln(2)+ {3\over 2x}\right]dx= \left[{ln(2)x^2\over 2}+\frac32ln(x)\right]_{1} ^4= {15\over 2}ln(2)+ {3\over 2}ln(4)$$    The answer in the back of the book says it's ${21\over 2}ln(2)$","Calculate the iterated integral $$\int_{1} ^4\int_{1} ^2 \left(\frac xy+\frac yx\right)\,dy\,dx$$ This is the work that I've done, but it'd lead me to the wrong answer, so either I did it completely wrong or I made in error in my calculation. $$\int_{1} ^4\int_{1} ^2 \left(\frac xy+\frac yx\right)\,dy\,dx= \int_{1} ^4 \left[xln(y)+{y^2\over 2x}  \right]_{1} ^2 dx=\int_{1} ^4 \left[xln(2)+ {3\over 2x}\right]dx= \left[{ln(2)x^2\over 2}+\frac32ln(x)\right]_{1} ^4= {15\over 2}ln(2)+ {3\over 2}ln(4)$$    The answer in the back of the book says it's ${21\over 2}ln(2)$",,"['multivariable-calculus', 'integration']"
16,How to prove $\int_0^\infty e^{-x^2}cos(2bx) dx = \frac{\sqrt{\pi}}{2} e^{-b^2}$,How to prove,\int_0^\infty e^{-x^2}cos(2bx) dx = \frac{\sqrt{\pi}}{2} e^{-b^2},"I've been grappling for a few hours with this problem ($b$ is a parameter) $\int_0^\infty e^{-x^2}cos(2bx) dx = \frac{\sqrt{\pi}}{2} e^{-b^2}$ Tried direct integration by parts, differentiation w.r.t. $b$, then integrating... all to no avail. I think the second approach is the way... Pls help","I've been grappling for a few hours with this problem ($b$ is a parameter) $\int_0^\infty e^{-x^2}cos(2bx) dx = \frac{\sqrt{\pi}}{2} e^{-b^2}$ Tried direct integration by parts, differentiation w.r.t. $b$, then integrating... all to no avail. I think the second approach is the way... Pls help",,"['real-analysis', 'multivariable-calculus']"
17,integration over a ball,integration over a ball,,"I try to compute the value of the following integral: Let $V=B_R(0)\subset \mathbb{R}^3$ be the Ball with radius $R$ around zero. How can I compute \[\int_V \frac{1}{\left|\vec{x}-\vec{y}\right|}d^3y.\] First I substitute $z:=y-x$. Then I get the integral: \[\int_{V+z} \frac{1}{\left|\vec{z}\right|}d^3z\]  Then I introduce spherical coordinates and I get: \[\int_{} \sin^2(\theta) \;d\theta \,dr\,d\phi.\] I can evaluate the integral, But I don't know how the integration area is changed by the transformation into spherical coordinates. Can you help me? Regards","I try to compute the value of the following integral: Let $V=B_R(0)\subset \mathbb{R}^3$ be the Ball with radius $R$ around zero. How can I compute \[\int_V \frac{1}{\left|\vec{x}-\vec{y}\right|}d^3y.\] First I substitute $z:=y-x$. Then I get the integral: \[\int_{V+z} \frac{1}{\left|\vec{z}\right|}d^3z\]  Then I introduce spherical coordinates and I get: \[\int_{} \sin^2(\theta) \;d\theta \,dr\,d\phi.\] I can evaluate the integral, But I don't know how the integration area is changed by the transformation into spherical coordinates. Can you help me? Regards",,"['integration', 'multivariable-calculus']"
18,Bounds for double integral,Bounds for double integral,,"I have an assignment to find the surface of a figure created by the intersection of two cylinders: $$  x^2 + z^2 = 4 $$ $$ x^2 + y^2 = 4 $$ I've made it to this form: $$ x = \sqrt{4 - z^2} $$ $$ y = z $$ But I have no idea how to find the bounds neccesary for the integrals, nor how to find the function to integrate.","I have an assignment to find the surface of a figure created by the intersection of two cylinders: $$  x^2 + z^2 = 4 $$ $$ x^2 + y^2 = 4 $$ I've made it to this form: $$ x = \sqrt{4 - z^2} $$ $$ y = z $$ But I have no idea how to find the bounds neccesary for the integrals, nor how to find the function to integrate.",,"['multivariable-calculus', 'integration']"
19,Recommendations for a Comprehensive Problem Book(s) in Calculus $3$.,Recommendations for a Comprehensive Problem Book(s) in Calculus .,3,"I am on the lookout for a comprehensive problem book specifically tailored to Multivariable Calculus and Vector Calculus (Calculus $3$ ), covering topics such as multiple integrals, partial differentiation, and other advanced concepts of Calculus $3$ . While I have found numerous resources for Calculus $1$ and $2$ , there seems to be a scarcity when it comes to Multivariable Calculus and Vector Calculus (Calculus $3$ ) Calculus $3$ . Could anyone recommend a problem book that provides a wide array of problems with varying difficulty levels in Multivariable Calculus and Vector Calculus (Calculus $3$ )? For context I have read:  Stewart's calculus, Thomas' calculus, Larson's Calculus, Baby Rudin and linear algebra by Hoffman and Kunze. EDIT: There are some good recommendations in the comments, but I am specifically looking for problem books that come with personal endorsements from individuals who have read and worked through them. Thank you in advance for your suggestions!","I am on the lookout for a comprehensive problem book specifically tailored to Multivariable Calculus and Vector Calculus (Calculus ), covering topics such as multiple integrals, partial differentiation, and other advanced concepts of Calculus . While I have found numerous resources for Calculus and , there seems to be a scarcity when it comes to Multivariable Calculus and Vector Calculus (Calculus ) Calculus . Could anyone recommend a problem book that provides a wide array of problems with varying difficulty levels in Multivariable Calculus and Vector Calculus (Calculus )? For context I have read:  Stewart's calculus, Thomas' calculus, Larson's Calculus, Baby Rudin and linear algebra by Hoffman and Kunze. EDIT: There are some good recommendations in the comments, but I am specifically looking for problem books that come with personal endorsements from individuals who have read and worked through them. Thank you in advance for your suggestions!",3 3 1 2 3 3 3,"['calculus', 'multivariable-calculus', 'vector-analysis', 'problem-solving', 'book-recommendation']"
20,"Elementary proof of $\left(1+\frac{t}{\sqrt{n}}\right)^{n}e^{-\sqrt{n}t}\le\left(1+t\right)e^{-t}$ for $n\in\mathbb{N},t\ge0$ .",Elementary proof of  for  .,"\left(1+\frac{t}{\sqrt{n}}\right)^{n}e^{-\sqrt{n}t}\le\left(1+t\right)e^{-t} n\in\mathbb{N},t\ge0","I am looking for an elementary proof for the inequality $\left(1+\frac{t}{\sqrt{n}}\right)^{n}e^{-\sqrt{n}t}\leq\left(1+t\right)e^{-t}$ for $n\in\mathbb{N},t\geq0 $ I encountered this inequality while writing an advanced exercise for first year students. I assumed it can be done by defining the function $$\varphi\left(x\right)=\left(1+\frac{t}{x}\right)^{x^{2}}e^{-xt}\,,$$ and show it monotonically decreases for $x\geq1$ and positive $t$ , but failed to do so. Does anyone know an elementary way to prove the above inequality?","I am looking for an elementary proof for the inequality for I encountered this inequality while writing an advanced exercise for first year students. I assumed it can be done by defining the function and show it monotonically decreases for and positive , but failed to do so. Does anyone know an elementary way to prove the above inequality?","\left(1+\frac{t}{\sqrt{n}}\right)^{n}e^{-\sqrt{n}t}\leq\left(1+t\right)e^{-t} n\in\mathbb{N},t\geq0  \varphi\left(x\right)=\left(1+\frac{t}{x}\right)^{x^{2}}e^{-xt}\,, x\geq1 t","['calculus', 'multivariable-calculus', 'inequality', 'exponential-function']"
21,"Find the limit (if it exists) $\lim_{(x,y) \to (0,0)} \dfrac{xy}{x^2 + |y|}.$",Find the limit (if it exists),"\lim_{(x,y) \to (0,0)} \dfrac{xy}{x^2 + |y|}.","I want to find the limit $$\lim_{(x,y) \to (0,0)} \dfrac{x \sin(y)}{x^2 + |y|},$$ if it exists. My idea was to use the fundamental trig limit to obtain $$\lim_{(x,y) \to (0,0)} \dfrac{x \sin(y)}{x^2 + |y|} = \lim_{(x,y) \to (0,0)} \dfrac{xy}{x^2 + |y|} \dfrac{\sin{y}}{y},$$ but now, I need to calculate the limit of the first factor, which I can't. If you solve the limit computationally, you'll know it exists and it equals zero, so you could use polar coordinates to prove it. But the exercise do not say the limit exists, so the use of polar coordinates is not allowed. Do you know how to find this limit $$\lim_{(x,y) \to (0,0)} \dfrac{xy}{x^2 + |y|}?$$","I want to find the limit if it exists. My idea was to use the fundamental trig limit to obtain but now, I need to calculate the limit of the first factor, which I can't. If you solve the limit computationally, you'll know it exists and it equals zero, so you could use polar coordinates to prove it. But the exercise do not say the limit exists, so the use of polar coordinates is not allowed. Do you know how to find this limit","\lim_{(x,y) \to (0,0)} \dfrac{x \sin(y)}{x^2 + |y|}, \lim_{(x,y) \to (0,0)} \dfrac{x \sin(y)}{x^2 + |y|} = \lim_{(x,y) \to (0,0)} \dfrac{xy}{x^2 + |y|} \dfrac{\sin{y}}{y}, \lim_{(x,y) \to (0,0)} \dfrac{xy}{x^2 + |y|}?",['multivariable-calculus']
22,Diffrentiability in Multivariate calculus [closed],Diffrentiability in Multivariate calculus [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed last year . This post was edited and submitted for review last year and failed to reopen the post: Original close reason(s) were not resolved Improve this question Let, $f(x, y, z) =x^3+y^3+z^3$ $L$ be a linear map from $\mathbb R^3$ to $\mathbb R$ Satisfying $$\displaystyle\lim_{(x, y, z) \to (0, 0,0)} \frac{f(1+x, 1+y, 1+z) -f(1, 1,1) -L(x, y, z) }{\sqrt{x^2+y^2+z^2}}=0$$ Then find the value of $L(1, 2,4)$ I am unable to understand how to approach. Pls help IIT JAM 2023","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed last year . This post was edited and submitted for review last year and failed to reopen the post: Original close reason(s) were not resolved Improve this question Let, be a linear map from to Satisfying Then find the value of I am unable to understand how to approach. Pls help IIT JAM 2023","f(x, y, z) =x^3+y^3+z^3 L \mathbb R^3 \mathbb R \displaystyle\lim_{(x, y, z) \to (0, 0,0)} \frac{f(1+x, 1+y, 1+z) -f(1, 1,1) -L(x, y, z) }{\sqrt{x^2+y^2+z^2}}=0 L(1, 2,4)",['multivariable-calculus']
23,Evaluate triple integrals $\int_{0}^{1}\int_{0}^{1}\int_{0}^{1}\sqrt[3]{\log{(xyz)}}dxdydz$,Evaluate triple integrals,\int_{0}^{1}\int_{0}^{1}\int_{0}^{1}\sqrt[3]{\log{(xyz)}}dxdydz,"I am trying to evaluate this integral: $$\int_{0}^{1}\int_{0}^{1}\int_{0}^{1}\sqrt[3]{\log{(xyz)}}dxdydz$$ Honestly, I have no ideas to deal with this. I hope I can be helped by everyone. I just need a hint to process; thank you.","I am trying to evaluate this integral: Honestly, I have no ideas to deal with this. I hope I can be helped by everyone. I just need a hint to process; thank you.",\int_{0}^{1}\int_{0}^{1}\int_{0}^{1}\sqrt[3]{\log{(xyz)}}dxdydz,['multivariable-calculus']
24,Gradient of a function that takes in two vectors,Gradient of a function that takes in two vectors,,"Say I have a function like $$f(\mathbf{x}, \mathbf{y})= \mathbf{x}^T\mathbf{y}$$ How can I compute its gradient?",Say I have a function like How can I compute its gradient?,"f(\mathbf{x}, \mathbf{y})= \mathbf{x}^T\mathbf{y}","['multivariable-calculus', 'derivatives']"
25,Gateaux derivatives is a linear continuous operator,Gateaux derivatives is a linear continuous operator,,"In Clarke's book p.61, it is said that the Gâteaux derivatives $F'(x;v)$ at $x$ in the direction $v$ of $F:X\to Y$ ( $X,Y$ being normed spaces) imply that $v\mapsto F'(x;v)$ is linear continuous. But in the Wikipedia page (paragraph dedicated to Fréchet derivatives), first they say that in general $F'(x;v)$ may fail to be linear or continuous but in the Banach settings $F'(x;v)$ is linear. Does Wikipedia miss the continuity property or the definition of the book is false in infinite dimensional settings ?","In Clarke's book p.61, it is said that the Gâteaux derivatives at in the direction of ( being normed spaces) imply that is linear continuous. But in the Wikipedia page (paragraph dedicated to Fréchet derivatives), first they say that in general may fail to be linear or continuous but in the Banach settings is linear. Does Wikipedia miss the continuity property or the definition of the book is false in infinite dimensional settings ?","F'(x;v) x v F:X\to Y X,Y v\mapsto F'(x;v) F'(x;v) F'(x;v)","['real-analysis', 'multivariable-calculus', 'derivatives', 'gateaux-derivative']"
26,Intersection of Sphere and Plane - Lagrange Multiplier,Intersection of Sphere and Plane - Lagrange Multiplier,,"I got a sphere with $x^2+y^2+z^2=1$ and a plane with $x+y+z=1$ . I should minimize and maximize the distance from the intersection to (0,0,0). First thing that threw me off, is that $x^2+y^2+z^2=1$ is centered around $(0,0,0)$ . So, every point that is on the sphere, and therefore every point that is on the intersection, has the same distance to $(0,0,0)$ , right? Not sure what to minimize? Since we are so supposed to use Langrage Multipliers, I tried $$ f:x^2+y^2+z^2=1$$ $$g:x+y+z-1=0 $$ $$ \nabla_f=\nabla_g \lambda, $$ and got $$\left\{\begin{array}{l}2x=\lambda \\2y=\lambda \\2z=\lambda \end{array}\right.$$ Together with g that gave me $x=y=z=1/3$ . Geometrically I have $(1,0,0),(0,1,0),(0,0,1)$ on my intersection, and I concluded that the intersection is the circle with the center $(1/3,1/3,1/3)$ and radius ${\sqrt2/\sqrt3}$ . Why did the Lagrange Multplier Method give me the center of the circle? Shouldn't it give me the circle itself? I am not sure what I did wrong. Also: Any guesses what one could maximize/minimize here? Every help is much appreciated! Best regards!","I got a sphere with and a plane with . I should minimize and maximize the distance from the intersection to (0,0,0). First thing that threw me off, is that is centered around . So, every point that is on the sphere, and therefore every point that is on the intersection, has the same distance to , right? Not sure what to minimize? Since we are so supposed to use Langrage Multipliers, I tried and got Together with g that gave me . Geometrically I have on my intersection, and I concluded that the intersection is the circle with the center and radius . Why did the Lagrange Multplier Method give me the center of the circle? Shouldn't it give me the circle itself? I am not sure what I did wrong. Also: Any guesses what one could maximize/minimize here? Every help is much appreciated! Best regards!","x^2+y^2+z^2=1 x+y+z=1 x^2+y^2+z^2=1 (0,0,0) (0,0,0) 
f:x^2+y^2+z^2=1 g:x+y+z-1=0
 
\nabla_f=\nabla_g \lambda,
 \left\{\begin{array}{l}2x=\lambda \\2y=\lambda \\2z=\lambda \end{array}\right. x=y=z=1/3 (1,0,0),(0,1,0),(0,0,1) (1/3,1/3,1/3) {\sqrt2/\sqrt3}","['real-analysis', 'multivariable-calculus', 'lagrange-multiplier']"
27,How to use Leibniz notation properly,How to use Leibniz notation properly,,"I think that I didn't understant properly how to use Leibniz notation for derivatives and partial derivatives. I know that: $$\frac{df}{dx}=f'$$ And here I don't have any problem. But then if $g,f$ are two functions, how should I intend: $$\frac{df}{dg}$$ Is it $f'\circ g$ ? Things get worse when we have to work in more variables.Let: $\mathbf{f}:\mathbb{R}^n\to\mathbb{R}^m$ $\mathbf{g}:\mathbb{R}^m\to\mathbb{R}^p$ $\mathbf{\Phi}:=\mathbf{g}   \circ  \mathbf{f}$ $\mathbf{\Phi}(\mathbf{x})=(\Phi_1(\mathbf{x}),...,\Phi_p(\mathbf{x}))$ Here's how I would write the $j$ -th  partial derivative of the $i$ -th component function of $\mathbf{\Phi}$ : $$\frac{\partial \Phi_i}{\partial x_j}(\mathbf{x})=\sum_{k=1}^{m} \left[ \frac{\partial g_i}{\partial x_k}(\mathbf{f}(\mathbf{x}))\right ]\left[\frac{\partial f_k}{\partial x_i}(\mathbf{x})\right ] $$ Or if I want to omit the argument $$\frac{\partial \Phi_i}{\partial x_j}=\sum_{k=1}^{m} \left[ \frac{\partial g_i}{\partial x_k}\circ \mathbf{f}\right ]\left[\frac{\partial f_k}{\partial x_i}\right ] $$ But my book writes it in this way: $$\frac{\partial \Phi_i}{\partial x_j}=\sum_{k=1}^{m}  \frac{\partial g_i}{\partial f_k} \frac{\partial f_k}{\partial x_i} $$ So am I supposed to understand by magic that: $$\frac{\partial g_i}{\partial f_k}:=\frac{\partial g_i}{\partial x_k}\circ \mathbf{f}$$ I know that the formula given by the book is more elegant and synthetic, but when I read it the first time I didn't understand anything. My question is: Is there a standard convention for this kind of notation? Because I'm seriously hating this notation, not only because of how unreadable is(to me), but also because all of the ""differential cancellation"" that we make in ODE(but this maybe will be part of a future question). Thank you :)","I think that I didn't understant properly how to use Leibniz notation for derivatives and partial derivatives. I know that: And here I don't have any problem. But then if are two functions, how should I intend: Is it ? Things get worse when we have to work in more variables.Let: Here's how I would write the -th  partial derivative of the -th component function of : Or if I want to omit the argument But my book writes it in this way: So am I supposed to understand by magic that: I know that the formula given by the book is more elegant and synthetic, but when I read it the first time I didn't understand anything. My question is: Is there a standard convention for this kind of notation? Because I'm seriously hating this notation, not only because of how unreadable is(to me), but also because all of the ""differential cancellation"" that we make in ODE(but this maybe will be part of a future question). Thank you :)","\frac{df}{dx}=f' g,f \frac{df}{dg} f'\circ g \mathbf{f}:\mathbb{R}^n\to\mathbb{R}^m \mathbf{g}:\mathbb{R}^m\to\mathbb{R}^p \mathbf{\Phi}:=\mathbf{g}   \circ  \mathbf{f} \mathbf{\Phi}(\mathbf{x})=(\Phi_1(\mathbf{x}),...,\Phi_p(\mathbf{x})) j i \mathbf{\Phi} \frac{\partial \Phi_i}{\partial x_j}(\mathbf{x})=\sum_{k=1}^{m} \left[ \frac{\partial g_i}{\partial x_k}(\mathbf{f}(\mathbf{x}))\right ]\left[\frac{\partial f_k}{\partial x_i}(\mathbf{x})\right ]  \frac{\partial \Phi_i}{\partial x_j}=\sum_{k=1}^{m} \left[ \frac{\partial g_i}{\partial x_k}\circ \mathbf{f}\right ]\left[\frac{\partial f_k}{\partial x_i}\right ]  \frac{\partial \Phi_i}{\partial x_j}=\sum_{k=1}^{m}  \frac{\partial g_i}{\partial f_k} \frac{\partial f_k}{\partial x_i}  \frac{\partial g_i}{\partial f_k}:=\frac{\partial g_i}{\partial x_k}\circ \mathbf{f}","['multivariable-calculus', 'derivatives', 'partial-derivative']"
28,Double integral over a typical region.,Double integral over a typical region.,,"Question : Let $R$ be the region in $xy$ -plane bounded by the curves $y=x^2,y=4x^2,xy=1,xy=5$ . Then find the value of line integral $\iint_R\frac{y^2}{x}dydx$ . I found it tough and time taking if I evaluate this integral from general method, is there any theorem which make it easy? Since the question is asked in competitive exam so I hope there must be an easy and fast way to solve it. Any help will be appreciable. Thanks in advance.","Question : Let be the region in -plane bounded by the curves . Then find the value of line integral . I found it tough and time taking if I evaluate this integral from general method, is there any theorem which make it easy? Since the question is asked in competitive exam so I hope there must be an easy and fast way to solve it. Any help will be appreciable. Thanks in advance.","R xy y=x^2,y=4x^2,xy=1,xy=5 \iint_R\frac{y^2}{x}dydx","['calculus', 'integration', 'multivariable-calculus', 'multiple-integral']"
29,Proving spheres are orthogonal,Proving spheres are orthogonal,,"Given two spheres in $\mathbb{R}^3$ : $x^2+y^2+z^2=2ax; \ \  \ x^2+y^2+z^2 = 2by$ and $a,b>0$ , and $\gamma$ the intersection of the spheres, show that for any $p_0 \in \gamma$ , the spheres are orthogonal at $p_0$ . I am not sure I fully understand the problem but here is what I tried: First of all assuming $p_0$ is some point s.t each sphere can be represented as a function $z_1, z_2 : \mathbb{R}^2 \to \mathbb{R}$ in a neighborhood of $p_0$ (if it isn't we can use another variable), what I think we want to show is that the tangent spaces to $z_1, z_2$ are orthogonal at this point, i.e $\langle\nabla z_1(p_0), \nabla z_2(p_0)\rangle=0.$ But when I calculate this I get that it does not equal 0: $z_1 = \sqrt{2ax-x^2-y^2}, z_2 = \sqrt{2by-x^2-y^2}$ $\nabla z_1 = (\frac{2a-2x}{2 \sqrt{2ax-x^2-y^2}}, \frac{-2y}{2 \sqrt{2ax-x^2-y^2}})$ $\nabla z_2 = (\frac{-2x}{2 \sqrt{2by-x^2-y^2}}, \frac{2b-2y}{2 \sqrt{2by-x^2-y^2}})$ $\langle\nabla z_1(p_0), \nabla z_2(p_0)\rangle \neq 0.$ Can someone explain where is my mistake?","Given two spheres in : and , and the intersection of the spheres, show that for any , the spheres are orthogonal at . I am not sure I fully understand the problem but here is what I tried: First of all assuming is some point s.t each sphere can be represented as a function in a neighborhood of (if it isn't we can use another variable), what I think we want to show is that the tangent spaces to are orthogonal at this point, i.e But when I calculate this I get that it does not equal 0: Can someone explain where is my mistake?","\mathbb{R}^3 x^2+y^2+z^2=2ax; \ \  \ x^2+y^2+z^2 = 2by a,b>0 \gamma p_0 \in \gamma p_0 p_0 z_1, z_2 : \mathbb{R}^2 \to \mathbb{R} p_0 z_1, z_2 \langle\nabla z_1(p_0), \nabla z_2(p_0)\rangle=0. z_1 = \sqrt{2ax-x^2-y^2}, z_2 = \sqrt{2by-x^2-y^2} \nabla z_1 = (\frac{2a-2x}{2 \sqrt{2ax-x^2-y^2}}, \frac{-2y}{2 \sqrt{2ax-x^2-y^2}}) \nabla z_2 = (\frac{-2x}{2 \sqrt{2by-x^2-y^2}}, \frac{2b-2y}{2 \sqrt{2by-x^2-y^2}}) \langle\nabla z_1(p_0), \nabla z_2(p_0)\rangle \neq 0.","['multivariable-calculus', 'vector-analysis', 'spheres', 'solid-geometry', 'tangent-spaces']"
30,How can I prove that $y-x+x^{5}-\frac{xy^{4}}{2(1+x^{2})^{2}}-\frac{x^{3}}{1+y^{2}}>0$ when $x>0$ and $1<y<1.5$?,How can I prove that  when  and ?,y-x+x^{5}-\frac{xy^{4}}{2(1+x^{2})^{2}}-\frac{x^{3}}{1+y^{2}}>0 x>0 1<y<1.5,"I would like to prove that $$y-x+x^{5}-\frac{xy^{4}}{2(1+x^{2})^{2}}-\frac{x^{3}}{1+y^{2}}>0$$ for all real numbers $x > 0$ and $1 < y < 1.5$ . This seems true when plotted on WolframAlpha, but I don't know how to prove it. I tried replacing some of the terms using the given inequalities to obtain a simpler function, but any perturbation I make seems to render the inequality untrue. How would you approach this problem?","I would like to prove that for all real numbers and . This seems true when plotted on WolframAlpha, but I don't know how to prove it. I tried replacing some of the terms using the given inequalities to obtain a simpler function, but any perturbation I make seems to render the inequality untrue. How would you approach this problem?",y-x+x^{5}-\frac{xy^{4}}{2(1+x^{2})^{2}}-\frac{x^{3}}{1+y^{2}}>0 x > 0 1 < y < 1.5,"['real-analysis', 'multivariable-calculus', 'inequality']"
31,"Counter example to: If $F$ is a conservative field in region $A$ and $B$, so $F$ is conservative in $A \cup B$","Counter example to: If  is a conservative field in region  and , so  is conservative in",F A B F A \cup B,"I am looking for a counter example and am explanation for why the following statement is false: If $F$ is a conservative field in region $A$ and $B$ , so $F$ is conservative in $A \cup B$ . And what about $A \cap B$ (is it true in that case)?","I am looking for a counter example and am explanation for why the following statement is false: If is a conservative field in region and , so is conservative in . And what about (is it true in that case)?",F A B F A \cup B A \cap B,"['calculus', 'multivariable-calculus']"
32,What is the actual difference between del and d in multivariate calculus?,What is the actual difference between del and d in multivariate calculus?,,"Recently I've tried to find the difference between partial differentiation and total differentiation. I've heard the total derivative is defined on single value functions, while the partial derivative by contrast is defined on multivariate functions. My problem is, that total differentiation is used on multivariate functions all the time. Every time I come up with a rigorous definition I arrive at a contradiction. I will share what I have defined so far, and hopefully you can enlighten me. Let $$f: (x_1, ... , x_n) \rightarrow f(x_1, ..., x_n)$$ and it's partial derivative by the difference quotient $$\frac{\partial f}{\partial x_i} = \lim_{h \to 0} \frac{f(x_1,..,x_i+h,...x_n)- f(x_1,..., x_n)}{h}$$ the total derivative must by contrast account for interdependence between $x_k$ in the domain of f. $$\frac{df}{dx_i}\stackrel{?}{=} \sum_k{\frac{\partial f}{\partial x_k} \frac{\partial x_k}{\partial x_i}}$$ This seemed sensible to me, until I realized it simplified to $$n \frac{\partial f}{\partial x_i}$$ which definitely isn't right. Can someone tell me where I've made an error? Or provide better definition? This issue really annoys me, since all my research so far didn't answer this question at all. Edit: Ok thank you for all the responses! I'm just writing out the final formula for total derivatives for quick lookup now: $\frac{d}{d x_i}$ is defined recursively as $$\frac{df}{dx_i}\stackrel{!}{=} \sum_k{\frac{\partial f}{\partial x_k} \frac{d x_k}{d x_i}}$$ until $x_k$ has a domain without interdependence, in which case $\frac{\partial x_j}{\partial x_i}$ = $\frac{d x_j}{d x_i}$ and the entire expression can be calculated by limits.","Recently I've tried to find the difference between partial differentiation and total differentiation. I've heard the total derivative is defined on single value functions, while the partial derivative by contrast is defined on multivariate functions. My problem is, that total differentiation is used on multivariate functions all the time. Every time I come up with a rigorous definition I arrive at a contradiction. I will share what I have defined so far, and hopefully you can enlighten me. Let and it's partial derivative by the difference quotient the total derivative must by contrast account for interdependence between in the domain of f. This seemed sensible to me, until I realized it simplified to which definitely isn't right. Can someone tell me where I've made an error? Or provide better definition? This issue really annoys me, since all my research so far didn't answer this question at all. Edit: Ok thank you for all the responses! I'm just writing out the final formula for total derivatives for quick lookup now: is defined recursively as until has a domain without interdependence, in which case = and the entire expression can be calculated by limits.","f: (x_1, ... , x_n) \rightarrow f(x_1, ..., x_n) \frac{\partial f}{\partial x_i} = \lim_{h \to 0} \frac{f(x_1,..,x_i+h,...x_n)- f(x_1,..., x_n)}{h} x_k \frac{df}{dx_i}\stackrel{?}{=} \sum_k{\frac{\partial f}{\partial x_k} \frac{\partial x_k}{\partial x_i}} n \frac{\partial f}{\partial x_i} \frac{d}{d x_i} \frac{df}{dx_i}\stackrel{!}{=} \sum_k{\frac{\partial f}{\partial x_k} \frac{d x_k}{d x_i}} x_k \frac{\partial x_j}{\partial x_i} \frac{d x_j}{d x_i}","['calculus', 'multivariable-calculus', 'derivatives', 'partial-derivative']"
33,Why do both $\iint_R(x^2+y^2)\ dA$ and $\iiint_E 1\ dxdydz$ give the volume of $z=x^2+y^2$? What is the difference between $R$ and $E$?,Why do both  and  give the volume of ? What is the difference between  and ?,\iint_R(x^2+y^2)\ dA \iiint_E 1\ dxdydz z=x^2+y^2 R E,"I can't understand how do we calculate volume  with triple integral. for example $z =x^2+y^2$ , we can calculate its volume with both: $$\iint\limits_R (x^2+y^2)\ dA$$ and $$\iiint\limits_E 1\ dxdydz$$ what is difference between $E$ and $R$ here?","I can't understand how do we calculate volume  with triple integral. for example , we can calculate its volume with both: and what is difference between and here?",z =x^2+y^2 \iint\limits_R (x^2+y^2)\ dA \iiint\limits_E 1\ dxdydz E R,"['calculus', 'multivariable-calculus', 'definite-integrals', 'volume']"
34,"KKT multipliers and ""active"" and ""inactive"" constraints on the generalized Lagrangian $L$","KKT multipliers and ""active"" and ""inactive"" constraints on the generalized Lagrangian",L,"The textbook Deep Learning by Goodfellow, Bengio, and Courville, says the following in a section on constrained optimization : The inequality constraints are particularly interesting. We say that a constraint $h^{(i)}(\mathbf{x})$ is active if $h^{(i)}(\mathbf{x}^*) = 0$ . If a constraint is not active, then the solution to the problem found using that constraint would remain at least a local solution if that constraint were removed. It is possible that an inactive constraint excludes  other solutions. For example, a convex problem with an entire region of globally optimal points (a wide, flat region of equal cost) could have a subset of this region eliminated by constraints, or a nonconvex problem could have better local stationary points excluded by a constraint that is inactive at convergence. Yet the point found at convergence remains a stationary point whether or not the inactive constraints are included. Because an inactive $h^{(i)}$ has negative value, then the solution to $\min_{\boldsymbol{\mathcal{x}}} \max_{\boldsymbol{\mathcal{\lambda}}} \max_{\boldsymbol{\mathcal{\alpha, \alpha}}\ge 0} L(\boldsymbol{\mathcal{x}}, \boldsymbol{\mathcal{\lambda}}, \boldsymbol{\mathcal{\alpha}})$ will have $\alpha_i = 0$ . We can thus observe  that at the solution, $\mathbf{\alpha} \odot \mathbf{h(x)} = \mathbf{0}$ . In other words, for all $i$ , we know that at least one of the constraints $\alpha_i \ge 0$ or $h^{(i)}(x) \le 0$ must be active at the solution. To gain some intuition for this idea, we can say that either the solution is on the boundary imposed by the inequality and we must use its KKT multiplier to influence the  solution to $\mathbf{x}$ , or the inequality has no influence on the solution and we represent this by zeroing out its KKT multiplier. Prior to this section, the authors define the aforementioned functions as follows: To define the Lagrangian, we first need to describe $\mathbb{S}$ in terms of equations and inequalities. We want a description of $\mathbb{S}$ in terms of $m$ functions $g^{(i)}$ and $n$ functions $h^{(j)}$ so that $\mathbb{S} = \{ \mathbf{x} | \forall i, g^{(i)}(\mathbf{x}) = 0 \ \text{and} \ \forall j, h^{(j)}(\mathbf{x}) \le 0 \}$ . The equations involving $g^{(i)}$ are called the equality constraints , and the inequalities involving $h^{(j)}$ are called the inequality constraints . So it seems that the $h^{(i)}$ being described here is the ""inactive"" constraint. Furthermore, when the authors say that, because an inactive $h^{(i)}$ has negative value, the solution to $\min_{\boldsymbol{\mathcal{x}}} \max_{\boldsymbol{\mathcal{\lambda}}} \max_{\boldsymbol{\mathcal{\alpha, \alpha}}\ge 0} L(\boldsymbol{\mathcal{x}}, \boldsymbol{\mathcal{\lambda}}, \boldsymbol{\mathcal{\alpha}})$ will have $\alpha_i = 0$ , this is because, in the section prior to saying this, they introduce new variables $\lambda_i$ and $\alpha_j$ for each constraint (these are called KKT multipliers), and define the generalized Lagrangian as $$L(\boldsymbol{\mathcal{x}}, \boldsymbol{\mathcal{\lambda}}, \boldsymbol{\mathcal{\alpha}}) = f(\mathbf{x}) + \sum_i \lambda_i g^{(i)} (\mathbf{x}) + \sum_{j} \alpha_j h^{(j)}(\mathbf{x})$$ So therefore, evidently, if we are calculating $\min_{\boldsymbol{\mathcal{x}}} \max_{\boldsymbol{\mathcal{\lambda}}} \max_{\boldsymbol{\mathcal{\alpha, \alpha}}\ge 0} L(\boldsymbol{\mathcal{x}}, \boldsymbol{\mathcal{\lambda}}, \boldsymbol{\mathcal{\alpha}})$ , then, in order to satisfy $\max_{\boldsymbol{\mathcal{\alpha, \alpha}}\ge 0}$ , we require $\alpha_j = 0$ , since, again, $h^{(j)} \le 0$ (that is, it is ""inactive""). But this section still leaves me unclear on a number of things: When the authors refer to ""convergence"" in this context, they're referring to convergence to the stationary point, right? Why is it the case that an ""inactive"" constraint potentially excludes other solutions? Is this just due to the fact that the values being considered during convergence are constrained to $h^{(j)}(\mathbf{x}) \le 0$ , and so we are not also considering the values $h^{(j)}(\mathbf{x}) \ge 0$ ? I'm not understanding the following explanation and the idea of how the KKT multipliers influence the solution: To gain some intuition for this idea, we can say that either the solution is on the boundary imposed by the inequality and we must use its KKT multiplier to influence the  solution to $\mathbf{x}$ , or the inequality has no influence on the solution and we represent this by zeroing out its KKT multiplier. I would greatly appreciate it if people would please take the time to clarify these points.","The textbook Deep Learning by Goodfellow, Bengio, and Courville, says the following in a section on constrained optimization : The inequality constraints are particularly interesting. We say that a constraint is active if . If a constraint is not active, then the solution to the problem found using that constraint would remain at least a local solution if that constraint were removed. It is possible that an inactive constraint excludes  other solutions. For example, a convex problem with an entire region of globally optimal points (a wide, flat region of equal cost) could have a subset of this region eliminated by constraints, or a nonconvex problem could have better local stationary points excluded by a constraint that is inactive at convergence. Yet the point found at convergence remains a stationary point whether or not the inactive constraints are included. Because an inactive has negative value, then the solution to will have . We can thus observe  that at the solution, . In other words, for all , we know that at least one of the constraints or must be active at the solution. To gain some intuition for this idea, we can say that either the solution is on the boundary imposed by the inequality and we must use its KKT multiplier to influence the  solution to , or the inequality has no influence on the solution and we represent this by zeroing out its KKT multiplier. Prior to this section, the authors define the aforementioned functions as follows: To define the Lagrangian, we first need to describe in terms of equations and inequalities. We want a description of in terms of functions and functions so that . The equations involving are called the equality constraints , and the inequalities involving are called the inequality constraints . So it seems that the being described here is the ""inactive"" constraint. Furthermore, when the authors say that, because an inactive has negative value, the solution to will have , this is because, in the section prior to saying this, they introduce new variables and for each constraint (these are called KKT multipliers), and define the generalized Lagrangian as So therefore, evidently, if we are calculating , then, in order to satisfy , we require , since, again, (that is, it is ""inactive""). But this section still leaves me unclear on a number of things: When the authors refer to ""convergence"" in this context, they're referring to convergence to the stationary point, right? Why is it the case that an ""inactive"" constraint potentially excludes other solutions? Is this just due to the fact that the values being considered during convergence are constrained to , and so we are not also considering the values ? I'm not understanding the following explanation and the idea of how the KKT multipliers influence the solution: To gain some intuition for this idea, we can say that either the solution is on the boundary imposed by the inequality and we must use its KKT multiplier to influence the  solution to , or the inequality has no influence on the solution and we represent this by zeroing out its KKT multiplier. I would greatly appreciate it if people would please take the time to clarify these points.","h^{(i)}(\mathbf{x}) h^{(i)}(\mathbf{x}^*) = 0 h^{(i)} \min_{\boldsymbol{\mathcal{x}}} \max_{\boldsymbol{\mathcal{\lambda}}} \max_{\boldsymbol{\mathcal{\alpha, \alpha}}\ge 0} L(\boldsymbol{\mathcal{x}}, \boldsymbol{\mathcal{\lambda}}, \boldsymbol{\mathcal{\alpha}}) \alpha_i = 0 \mathbf{\alpha} \odot \mathbf{h(x)} = \mathbf{0} i \alpha_i \ge 0 h^{(i)}(x) \le 0 \mathbf{x} \mathbb{S} \mathbb{S} m g^{(i)} n h^{(j)} \mathbb{S} = \{ \mathbf{x} | \forall i, g^{(i)}(\mathbf{x}) = 0 \ \text{and} \ \forall j, h^{(j)}(\mathbf{x}) \le 0 \} g^{(i)} h^{(j)} h^{(i)} h^{(i)} \min_{\boldsymbol{\mathcal{x}}} \max_{\boldsymbol{\mathcal{\lambda}}} \max_{\boldsymbol{\mathcal{\alpha, \alpha}}\ge 0} L(\boldsymbol{\mathcal{x}}, \boldsymbol{\mathcal{\lambda}}, \boldsymbol{\mathcal{\alpha}}) \alpha_i = 0 \lambda_i \alpha_j L(\boldsymbol{\mathcal{x}}, \boldsymbol{\mathcal{\lambda}}, \boldsymbol{\mathcal{\alpha}}) = f(\mathbf{x}) + \sum_i \lambda_i g^{(i)} (\mathbf{x}) + \sum_{j} \alpha_j h^{(j)}(\mathbf{x}) \min_{\boldsymbol{\mathcal{x}}} \max_{\boldsymbol{\mathcal{\lambda}}} \max_{\boldsymbol{\mathcal{\alpha, \alpha}}\ge 0} L(\boldsymbol{\mathcal{x}}, \boldsymbol{\mathcal{\lambda}}, \boldsymbol{\mathcal{\alpha}}) \max_{\boldsymbol{\mathcal{\alpha, \alpha}}\ge 0} \alpha_j = 0 h^{(j)} \le 0 h^{(j)}(\mathbf{x}) \le 0 h^{(j)}(\mathbf{x}) \ge 0 \mathbf{x}","['multivariable-calculus', 'optimization', 'machine-learning', 'lagrange-multiplier', 'karush-kuhn-tucker']"
35,Why is the directional derivative zero at any point of the level curve along the direction of the tangent line to the level curve at that point?,Why is the directional derivative zero at any point of the level curve along the direction of the tangent line to the level curve at that point?,,"Let $f : \Bbb R^2 \longrightarrow \Bbb R$ be a scalar function defined over the plane $\Bbb R^2.$ Let $l$ be a level curve of the function $f$ where $f(x,y) = k$ for all $(x,y) \in l.$ Let $(x_0,y_0) \in l$ and consider the unit tangent vector $(u,v)$ to $l$ at $(x_0,y_0).$ Suppose that the directional derivative of $f$ exists at $(x_0,y_0).$ Show that the directional derivative of $f$ at $(x_0,y_0)$ in the direction of $(u,v)$ is zero. So what I need to show is that the limit $$\lim\limits_{h \to 0} \frac {f(x_0+hu,y_0+hv) - f(x_0,y_0)} {h} = 0.$$ Now I observe that the point $(x_0+hu,y_0+hv)$ is a point on the tangent to $l$ at $(x_0,y_0).$ Also I know that $f(x_0,y_0)=k.$ Now how do I compute the limit? Any help in this regard is highly appreciated. Thank you very much.",Let be a scalar function defined over the plane Let be a level curve of the function where for all Let and consider the unit tangent vector to at Suppose that the directional derivative of exists at Show that the directional derivative of at in the direction of is zero. So what I need to show is that the limit Now I observe that the point is a point on the tangent to at Also I know that Now how do I compute the limit? Any help in this regard is highly appreciated. Thank you very much.,"f : \Bbb R^2 \longrightarrow \Bbb R \Bbb R^2. l f f(x,y) = k (x,y) \in l. (x_0,y_0) \in l (u,v) l (x_0,y_0). f (x_0,y_0). f (x_0,y_0) (u,v) \lim\limits_{h \to 0} \frac {f(x_0+hu,y_0+hv) - f(x_0,y_0)} {h} = 0. (x_0+hu,y_0+hv) l (x_0,y_0). f(x_0,y_0)=k.","['multivariable-calculus', 'proof-writing']"
36,"Derivative of $\int_0^tf(x,t)dx$?",Derivative of ?,"\int_0^tf(x,t)dx","Derivative of $\int_0^tf(x,t)dx$ ? Fundamental theorem of calculus works for $\int_0^tf(x)dx$ $$\frac{d}{dt}\int_0^tf(x)dx=f(t)$$ but how about this case?",Derivative of ? Fundamental theorem of calculus works for but how about this case?,"\int_0^tf(x,t)dx \int_0^tf(x)dx \frac{d}{dt}\int_0^tf(x)dx=f(t)","['calculus', 'integration', 'multivariable-calculus', 'derivatives']"
37,"Unit square, Riemann zeta function: $\int_0^1\int_0^1\frac{(-\log(xy))^s}{1-xy}\,dx\,dy = \Gamma(s+2) \zeta(s+2), \operatorname{Re}(s)>1$","Unit square, Riemann zeta function:","\int_0^1\int_0^1\frac{(-\log(xy))^s}{1-xy}\,dx\,dy = \Gamma(s+2) \zeta(s+2), \operatorname{Re}(s)>1","I want to prove following integral: For $\operatorname{Re}(s)>1,$ $$ \int_0^1 \int_0^1 \frac{(-\log(xy))^s}{1-xy}\,dx\,dy = \Gamma(s+2)\,\zeta(s+2).  $$ I am having trouble with proving this equation. What can be a good parametrization for this integral?  My trial was treating $t = -\log(xy),$ but this does not work well...",I want to prove following integral: For I am having trouble with proving this equation. What can be a good parametrization for this integral?  My trial was treating but this does not work well...,"\operatorname{Re}(s)>1, 
\int_0^1 \int_0^1 \frac{(-\log(xy))^s}{1-xy}\,dx\,dy = \Gamma(s+2)\,\zeta(s+2). 
 t = -\log(xy),","['calculus', 'integration', 'multivariable-calculus', 'riemann-zeta', 'zeta-functions']"
38,"Differentiability of $f(x, y) = |xy|$ at $0$; is this a mistake by Munkres?",Differentiability of  at ; is this a mistake by Munkres?,"f(x, y) = |xy| 0","I am reading Analysis on Manifolds by Munkres, and question $1$ on page $54$ says Show that the function $f(x, y) = |xy|$ is differentiable at $0$ , but it is not of class $C^1$ in any neighborhood of $0$ . I know that if a function $f$ is differentiable at a point, then all its partial derivatives exist at that point. However, $$D_1f(x, y) = \begin{cases}  |y|&\text{if}\, x>0 \\   -|y| &\text{if}\, x<0 \end{cases} $$ and $D_1f(0, 0)$ does not exist. How can $f$ be differentiable at $0$ ?","I am reading Analysis on Manifolds by Munkres, and question on page says Show that the function is differentiable at , but it is not of class in any neighborhood of . I know that if a function is differentiable at a point, then all its partial derivatives exist at that point. However, and does not exist. How can be differentiable at ?","1 54 f(x, y) = |xy| 0 C^1 0 f D_1f(x, y) = \begin{cases}
 |y|&\text{if}\, x>0 \\
  -|y| &\text{if}\, x<0
\end{cases}
 D_1f(0, 0) f 0","['real-analysis', 'multivariable-calculus']"
39,Intuition of definition of divergence,Intuition of definition of divergence,,"Intution :  The divergence of a three-dimensional vector field is the extent to which the vector field flow behaves like a source at a given point. But if my vector field is $F=\langle P,Q,R\rangle$ then formula is for divergence is given as $P_x+Q_y+R_z$ . I want to know how this formula capute that intutitve idea. I studied using MIT OCW. But professor didn't talk about how we get formula from the idea.  So,I see videos from Khan academy, if we consider $i$ component i.e. $P$ , the divergence is positive ( Intution) if $P_x>0$ and vice versa.similarly for $j,k$ component. But a vector field need not be oriented along axis .he tells something like for an arbitrary vector field we can decompose vectors into components.but I didn't get that thing Could someone please explain how we get this formula from intution of divergence. Thanks!","Intution :  The divergence of a three-dimensional vector field is the extent to which the vector field flow behaves like a source at a given point. But if my vector field is then formula is for divergence is given as . I want to know how this formula capute that intutitve idea. I studied using MIT OCW. But professor didn't talk about how we get formula from the idea.  So,I see videos from Khan academy, if we consider component i.e. , the divergence is positive ( Intution) if and vice versa.similarly for component. But a vector field need not be oriented along axis .he tells something like for an arbitrary vector field we can decompose vectors into components.but I didn't get that thing Could someone please explain how we get this formula from intution of divergence. Thanks!","F=\langle P,Q,R\rangle P_x+Q_y+R_z i P P_x>0 j,k","['multivariable-calculus', 'vector-analysis', 'fluid-dynamics', 'divergence-operator']"
40,Simplifing a Double Integral,Simplifing a Double Integral,,"I would like to know how this result from a textbook was obtained: $$ \int_0^1du\int_0^u\frac{u}{\sqrt{1-u}}\ln\frac{u}{v}\, dv = \int_0^1\frac{u^2}{\sqrt{1-u}}\, du=\frac{16}{15} $$ Is this some special result which I need to know? Otherwise if I simplify using the standard approach : $$ \int_0^1 \frac{u^2}{\sqrt{1-u}}\ln u\, du - \int_0^1\frac{u}{\sqrt{1-u}}\int_0^u (1)(\ln v)\,dv $$ which would require the value of $\ln(0)$ . I have verified that the result $\frac{16}{15}$ is indeed correct using WolframAlpha, but I do not know how the simplification from the text was obtained.","I would like to know how this result from a textbook was obtained: Is this some special result which I need to know? Otherwise if I simplify using the standard approach : which would require the value of . I have verified that the result is indeed correct using WolframAlpha, but I do not know how the simplification from the text was obtained.","
\int_0^1du\int_0^u\frac{u}{\sqrt{1-u}}\ln\frac{u}{v}\, dv = \int_0^1\frac{u^2}{\sqrt{1-u}}\, du=\frac{16}{15}
 
\int_0^1 \frac{u^2}{\sqrt{1-u}}\ln u\, du - \int_0^1\frac{u}{\sqrt{1-u}}\int_0^u (1)(\ln v)\,dv
 \ln(0) \frac{16}{15}","['integration', 'multivariable-calculus', 'definite-integrals']"
41,One-forms are dual to tangent vectors,One-forms are dual to tangent vectors,,"In my class it was said that ""A tangent vector $X \in T_p(\mathbb{R}^n)$ acts on a one-form to give a real number"" and ""A one-form acts on a tangent vector to give a real number"" Now the 'tangent space' $T_p(\mathbb{R}^n)$ is a $n$-dimensional vector space and the elements of $T_p(\mathbb{R}^n)$ which we call tangent vectors are actually derivations, which are linear maps $w : C^{\infty}(\mathbb{R}^n) \to \mathbb{R}$ satisfying a product rule. One-forms are elements of the dual vector space $T_p^*(\mathbb{R}^n)$, which we call the cotangent space. They are by definition of a dual vector space, linear maps from $T_p(\mathbb{R}^n)$ to $\mathbb{R}$, e.g $f : T_p(\mathbb{R}^n) \to \mathbb{R}$. From this it is easy to see that a one-form takes as input a tangent vector and outputs a real number. However I'm having trouble seeing how a tangent vector (derivation) takes as input a one-form to output a real number since it's domain isn't even $T_p^*(\mathbb{R}^n)$.","In my class it was said that ""A tangent vector $X \in T_p(\mathbb{R}^n)$ acts on a one-form to give a real number"" and ""A one-form acts on a tangent vector to give a real number"" Now the 'tangent space' $T_p(\mathbb{R}^n)$ is a $n$-dimensional vector space and the elements of $T_p(\mathbb{R}^n)$ which we call tangent vectors are actually derivations, which are linear maps $w : C^{\infty}(\mathbb{R}^n) \to \mathbb{R}$ satisfying a product rule. One-forms are elements of the dual vector space $T_p^*(\mathbb{R}^n)$, which we call the cotangent space. They are by definition of a dual vector space, linear maps from $T_p(\mathbb{R}^n)$ to $\mathbb{R}$, e.g $f : T_p(\mathbb{R}^n) \to \mathbb{R}$. From this it is easy to see that a one-form takes as input a tangent vector and outputs a real number. However I'm having trouble seeing how a tangent vector (derivation) takes as input a one-form to output a real number since it's domain isn't even $T_p^*(\mathbb{R}^n)$.",,"['multivariable-calculus', 'differential-geometry', 'vector-spaces']"
42,Difficult integration by parts in deriving Euler-Lagrange equations,Difficult integration by parts in deriving Euler-Lagrange equations,,"I am doing some reading about the calculus of variations and I am finding it really difficult to see how the integrals are being manipulated. I sense it is due to an application of integration by parts (or some multivariable calculus) but I've been staring at this for some time and am not making any progress. In this situation, I should say that $F = F(x,y,y',y'')\in C^3(D)$ for some $D \subseteq \mathbb{R}^4$ and that $\eta \in C^4([a,b])$ is arbitrary, except that it satisfies $\eta(a) = \eta(b) = \eta'(a) = \eta'(b) = 0$. The book I am reading ( Differential and Integral Equations by P.J. Collins, pp 202) says Because we are treating $x,y,y',y''$ as independent variables, I can see what happens to the last two terms inside the first integral - both the $\eta$ and $\eta'$ are integrated whilst the $F_{y''}$ is treated as a constant, explaining why those two terms come up in the first box on the second line. However, I am incredibly stumped what happens after that. In particular, I am not sure how the integral on the second line arises. Is it some application of a product/chain rule-type thing? Any insight into this would help a lot. Thanks!","I am doing some reading about the calculus of variations and I am finding it really difficult to see how the integrals are being manipulated. I sense it is due to an application of integration by parts (or some multivariable calculus) but I've been staring at this for some time and am not making any progress. In this situation, I should say that $F = F(x,y,y',y'')\in C^3(D)$ for some $D \subseteq \mathbb{R}^4$ and that $\eta \in C^4([a,b])$ is arbitrary, except that it satisfies $\eta(a) = \eta(b) = \eta'(a) = \eta'(b) = 0$. The book I am reading ( Differential and Integral Equations by P.J. Collins, pp 202) says Because we are treating $x,y,y',y''$ as independent variables, I can see what happens to the last two terms inside the first integral - both the $\eta$ and $\eta'$ are integrated whilst the $F_{y''}$ is treated as a constant, explaining why those two terms come up in the first box on the second line. However, I am incredibly stumped what happens after that. In particular, I am not sure how the integral on the second line arises. Is it some application of a product/chain rule-type thing? Any insight into this would help a lot. Thanks!",,"['integration', 'multivariable-calculus']"
43,Find the work done by a force field,Find the work done by a force field,,"I am new to vector calculus and found this problem in the textbook which I am not sure how to work with, but I want to learn to do so: Show details to find the work done by the force field $\mathbf{F} =x^3\,\mathbf{i}+y^3\,\mathbf{j}$   in moving an object from $P(1, 0)$ to $Q(2, 2).$","I am new to vector calculus and found this problem in the textbook which I am not sure how to work with, but I want to learn to do so: Show details to find the work done by the force field $\mathbf{F} =x^3\,\mathbf{i}+y^3\,\mathbf{j}$   in moving an object from $P(1, 0)$ to $Q(2, 2).$",,"['calculus', 'multivariable-calculus', 'vectors']"
44,Proving the Harnack Inequality for Harmonic Functions,Proving the Harnack Inequality for Harmonic Functions,,"I am putting together a proof for the Harnack inequality for harmonic functions defined on a balls. I would like to do this using the mean value property of Harmonic functions. I am thinking of doing this. Let us fix $x_0$, $y_0$ in some ball of radius $r$ centered around the origin. Now, we will construct two sub-balls around each of these balls. Specifically, let us take some arbitrarily small $\epsilon$ ball around $x_0$. Now, if we take $\epsilon$ small enough we can contain this sub-ball in a ball $B_{r_{y_0}} (y_0)$ around $y_0$ such that the ball around $y_0$ is a subset of our original ball $B_r$ on which the function is defined/harmonic. The mean value property then tells us that: $$ C(\epsilon) \cdot u (x_0)  = \int_{B_{\epsilon}(x_0)} u(x) \mathrm{d}x $$ and moreover: $$ C(r_y) \cdot u(y_0) = \int_{B_{r_{y}}(y_0)} u(y) \mathrm{d}y $$ Moreover, because the domain of the $y$ integral contains the domain of the $x$ integral: $$ C(r_y) \cdot u(y_0) = \int_{B_{r_{y}}(y_0)} u(y) \mathrm{d}y \geq \int_{B_{\epsilon}(x_0)} u(x) \mathrm{d}x = C(\epsilon) \cdot u (x_0)  $$ Hence: $$ \frac{C(r_y)}{C(\epsilon)} u(y_0) \geq u(x_0) $$ Now, my only issue with the above proof is dependencies. Specifically, it seems like my choice of constants determined is a function of the initial points I choose, which does not seem to be correct (through the general statement of the inequality). Could someone please help me verify if this is correct?","I am putting together a proof for the Harnack inequality for harmonic functions defined on a balls. I would like to do this using the mean value property of Harmonic functions. I am thinking of doing this. Let us fix $x_0$, $y_0$ in some ball of radius $r$ centered around the origin. Now, we will construct two sub-balls around each of these balls. Specifically, let us take some arbitrarily small $\epsilon$ ball around $x_0$. Now, if we take $\epsilon$ small enough we can contain this sub-ball in a ball $B_{r_{y_0}} (y_0)$ around $y_0$ such that the ball around $y_0$ is a subset of our original ball $B_r$ on which the function is defined/harmonic. The mean value property then tells us that: $$ C(\epsilon) \cdot u (x_0)  = \int_{B_{\epsilon}(x_0)} u(x) \mathrm{d}x $$ and moreover: $$ C(r_y) \cdot u(y_0) = \int_{B_{r_{y}}(y_0)} u(y) \mathrm{d}y $$ Moreover, because the domain of the $y$ integral contains the domain of the $x$ integral: $$ C(r_y) \cdot u(y_0) = \int_{B_{r_{y}}(y_0)} u(y) \mathrm{d}y \geq \int_{B_{\epsilon}(x_0)} u(x) \mathrm{d}x = C(\epsilon) \cdot u (x_0)  $$ Hence: $$ \frac{C(r_y)}{C(\epsilon)} u(y_0) \geq u(x_0) $$ Now, my only issue with the above proof is dependencies. Specifically, it seems like my choice of constants determined is a function of the initial points I choose, which does not seem to be correct (through the general statement of the inequality). Could someone please help me verify if this is correct?",,"['real-analysis', 'multivariable-calculus', 'proof-verification', 'partial-differential-equations', 'harmonic-functions']"
45,Why is it contradicting?,Why is it contradicting?,,"Let $P$ and $Q$ be functions of $r$ and $r$ be a function of $(x,y,z)$. Also let $f$ be a function of $(x,y)$. If: $$P(x,y,z) + f (x,y)= Q(x,y,z) \tag{1} $$ By $(1)$ $$\dfrac{\partial P}{\partial x}  \neq \dfrac{\partial Q}{\partial x} \Rightarrow \dfrac{dP}{dr} \dfrac{\partial r}{\partial x} \neq \dfrac{dQ}{dr} \dfrac{\partial r}{\partial x}\Rightarrow \dfrac{dP}{dr} \neq \dfrac{dQ}{dr}  \tag{2} $$ Also by $(1)$ $$\dfrac{\partial P}{\partial z}  = \dfrac{\partial Q}{\partial z}\Rightarrow \dfrac{dP}{dr} \dfrac{\partial r}{\partial z} = \dfrac{dQ}{dr} \dfrac{\partial r}{\partial z} \Rightarrow \dfrac{dP}{dr} = \dfrac{dQ}{dr}  \tag{3}$$ $(2)$ and $(3)$ contradict. Why is this so?","Let $P$ and $Q$ be functions of $r$ and $r$ be a function of $(x,y,z)$. Also let $f$ be a function of $(x,y)$. If: $$P(x,y,z) + f (x,y)= Q(x,y,z) \tag{1} $$ By $(1)$ $$\dfrac{\partial P}{\partial x}  \neq \dfrac{\partial Q}{\partial x} \Rightarrow \dfrac{dP}{dr} \dfrac{\partial r}{\partial x} \neq \dfrac{dQ}{dr} \dfrac{\partial r}{\partial x}\Rightarrow \dfrac{dP}{dr} \neq \dfrac{dQ}{dr}  \tag{2} $$ Also by $(1)$ $$\dfrac{\partial P}{\partial z}  = \dfrac{\partial Q}{\partial z}\Rightarrow \dfrac{dP}{dr} \dfrac{\partial r}{\partial z} = \dfrac{dQ}{dr} \dfrac{\partial r}{\partial z} \Rightarrow \dfrac{dP}{dr} = \dfrac{dQ}{dr}  \tag{3}$$ $(2)$ and $(3)$ contradict. Why is this so?",,"['calculus', 'multivariable-calculus', 'partial-derivative', 'chain-rule']"
46,Curl of a cross product with constant vector,Curl of a cross product with constant vector,,"If $\mathbf a$ is a constant vector in the 3-dimensional space and $\mathbf s=x\mathbf e_x+y\mathbf e_y +z\mathbf e_z$, I want to show that  $$\nabla \land \left(\mathbf a \land \mathbf s\right) = 2\mathbf a. $$ I have done as follows: $$\nabla \land \left(\mathbf a \land \mathbf s\right)=(\nabla \cdot \mathbf s)\mathbf a\ -\ (\nabla \cdot \mathbf a)\mathbf s=3\mathbf a\ -\ (\nabla \cdot \mathbf a)\mathbf s $$ But I am confused as to how the last part is computed. Could you explicitly show how $(\nabla \cdot \mathbf a)\mathbf s$ equals $\mathbf a$ or point out any other mistake?","If $\mathbf a$ is a constant vector in the 3-dimensional space and $\mathbf s=x\mathbf e_x+y\mathbf e_y +z\mathbf e_z$, I want to show that  $$\nabla \land \left(\mathbf a \land \mathbf s\right) = 2\mathbf a. $$ I have done as follows: $$\nabla \land \left(\mathbf a \land \mathbf s\right)=(\nabla \cdot \mathbf s)\mathbf a\ -\ (\nabla \cdot \mathbf a)\mathbf s=3\mathbf a\ -\ (\nabla \cdot \mathbf a)\mathbf s $$ But I am confused as to how the last part is computed. Could you explicitly show how $(\nabla \cdot \mathbf a)\mathbf s$ equals $\mathbf a$ or point out any other mistake?",,"['multivariable-calculus', 'vector-analysis']"
47,Is every path a reparametrization of a path with non zero velocity?,Is every path a reparametrization of a path with non zero velocity?,,"Let $\alpha:[0,1] \to \mathbb{R}^n$ be a non-constant smooth path, and suppose $\alpha'(0)=0$. Do there exist a smooth path $\beta:[a,b]\to \mathbb{R}^n$ and a smooth increasing function $h:[0,1] \to [a,b]$, such that $\alpha=\beta \circ h,h(0)=0$ and $\beta'(0) \neq 0$. Note $h$ must satisfy $h'(0)=0$. Example: $n=1,\alpha(t)=t^2$, take $h(t)=\alpha(t)$, $\beta=\text{Id}$. It's easy to shows that if the answer is positive for $n=1$, then it is positive for every dimension $n$. So we are reduced to the one-dimensional case.","Let $\alpha:[0,1] \to \mathbb{R}^n$ be a non-constant smooth path, and suppose $\alpha'(0)=0$. Do there exist a smooth path $\beta:[a,b]\to \mathbb{R}^n$ and a smooth increasing function $h:[0,1] \to [a,b]$, such that $\alpha=\beta \circ h,h(0)=0$ and $\beta'(0) \neq 0$. Note $h$ must satisfy $h'(0)=0$. Example: $n=1,\alpha(t)=t^2$, take $h(t)=\alpha(t)$, $\beta=\text{Id}$. It's easy to shows that if the answer is positive for $n=1$, then it is positive for every dimension $n$. So we are reduced to the one-dimensional case.",,"['calculus', 'multivariable-calculus', 'derivatives', 'parametrization']"
48,Relating an integral over the n-ball with the surface area of the (n-1)-sphere,Relating an integral over the n-ball with the surface area of the (n-1)-sphere,,"I'm asking for help in order to prove the following formula: $$\int_{|\mathbf{x}|<1}x_1^2 d\mathbf{x}= \frac{\omega_{n}}{n\left(n+2\right)} $$ Where $\mathbf{x}=(x_1,\dots,x_n)\in \mathbb{R}^n $, and $\omega_n$ is the area of the $(n-1)$-sphere. \  I already proved the formula in the cases $n=2$ and $n=3$, using respectively polar coordinates and Fubini's theorem. However I don't have knowledge of any theorem that could help me in the general case aside from Fubini's theorem, which allows me to proceed in the following way: $$\int_{|\mathbf{x}|<1}x_1^2 d\mathbf{x}= \int_{-1}^{1}\left(\int_{D_{\bar{x}_1}}x_1^2\mathrm{d}x_2\dots\mathrm{d}x_n\right)\mathrm{d}x_1= \int_{-1}^{1}x_1^2 \mathcal{L}^{n-1}(D_{\bar{x}_1})\mathrm{d}x_1 $$ Where $D_{\bar{x}_1}= \left\{|\mathbf{x}|<1\right\}\cap \left\{x_1=\bar{x}_1\right\}$, which is an $(n-1)$-ball of radius $\sqrt{1-x_1^2}$, and $\mathcal{L}^{n-1}$ denotes the Lebesgue measure on $\mathbb{R}^{n-1}$. However, this doesn't help as I'm supposed to relate the integral to the measure of the $(n-1)$-sphere, not the $(n-1)$-ball. Even then I could only go as far as saying $$\mathcal{L}^{n-1}(D_{\bar{x}_1})= \left(1-x_1^2\right)^{\frac{n-1}{2}}\mathcal{L}^{n-1}(D) $$ Where $D$ is the unit ball in $\mathbb{R}^{n-1}$, but I still can't compute the following integral when $n$ is even: $$\int_{-1}^{1}x^2(1-x^2)^{\frac{n-1}{2}}\mathrm{d}x $$ I guess that I need some form of Stokes's theorem, but I only studied the classical results in $\mathbb{R}^3$, and the generalized version that I've found is expressed through differential forms. Is it possible to solve this in a more elementary way? Edit: the number of dimensions was incorrect in some instances","I'm asking for help in order to prove the following formula: $$\int_{|\mathbf{x}|<1}x_1^2 d\mathbf{x}= \frac{\omega_{n}}{n\left(n+2\right)} $$ Where $\mathbf{x}=(x_1,\dots,x_n)\in \mathbb{R}^n $, and $\omega_n$ is the area of the $(n-1)$-sphere. \  I already proved the formula in the cases $n=2$ and $n=3$, using respectively polar coordinates and Fubini's theorem. However I don't have knowledge of any theorem that could help me in the general case aside from Fubini's theorem, which allows me to proceed in the following way: $$\int_{|\mathbf{x}|<1}x_1^2 d\mathbf{x}= \int_{-1}^{1}\left(\int_{D_{\bar{x}_1}}x_1^2\mathrm{d}x_2\dots\mathrm{d}x_n\right)\mathrm{d}x_1= \int_{-1}^{1}x_1^2 \mathcal{L}^{n-1}(D_{\bar{x}_1})\mathrm{d}x_1 $$ Where $D_{\bar{x}_1}= \left\{|\mathbf{x}|<1\right\}\cap \left\{x_1=\bar{x}_1\right\}$, which is an $(n-1)$-ball of radius $\sqrt{1-x_1^2}$, and $\mathcal{L}^{n-1}$ denotes the Lebesgue measure on $\mathbb{R}^{n-1}$. However, this doesn't help as I'm supposed to relate the integral to the measure of the $(n-1)$-sphere, not the $(n-1)$-ball. Even then I could only go as far as saying $$\mathcal{L}^{n-1}(D_{\bar{x}_1})= \left(1-x_1^2\right)^{\frac{n-1}{2}}\mathcal{L}^{n-1}(D) $$ Where $D$ is the unit ball in $\mathbb{R}^{n-1}$, but I still can't compute the following integral when $n$ is even: $$\int_{-1}^{1}x^2(1-x^2)^{\frac{n-1}{2}}\mathrm{d}x $$ I guess that I need some form of Stokes's theorem, but I only studied the classical results in $\mathbb{R}^3$, and the generalized version that I've found is expressed through differential forms. Is it possible to solve this in a more elementary way? Edit: the number of dimensions was incorrect in some instances",,"['real-analysis', 'integration', 'multivariable-calculus']"
49,Why normal vector and acceleration aren't the same?,Why normal vector and acceleration aren't the same?,,"I know the derivative of position vector function $r(t)$ is velocity, and its unit vector is tangent vector, therefore, the derivative of tangent vector is the unit vector of acceleration and normal vector. Why isn't that the case?","I know the derivative of position vector function $r(t)$ is velocity, and its unit vector is tangent vector, therefore, the derivative of tangent vector is the unit vector of acceleration and normal vector. Why isn't that the case?",,['multivariable-calculus']
50,Does this integral converge $\int_{\mathbb{R}^2}\frac{1}{x^4y^4+1}\ dxdy $?,Does this integral converge ?,\int_{\mathbb{R}^2}\frac{1}{x^4y^4+1}\ dxdy ,"I want to find out whether this integral is convergent or not. $$\int_{\mathbb{R}^2}\frac{1}{x^4y^4+1}\ dxdy $$ I've tried to calculate it using the following variable changement, but it does'nt work i guess.$(x,y)=(r\cdot \cos(\theta),r\cdot \sin(\theta))$. I also though of comparing the general term to another one that converge but i couldn't find.","I want to find out whether this integral is convergent or not. $$\int_{\mathbb{R}^2}\frac{1}{x^4y^4+1}\ dxdy $$ I've tried to calculate it using the following variable changement, but it does'nt work i guess.$(x,y)=(r\cdot \cos(\theta),r\cdot \sin(\theta))$. I also though of comparing the general term to another one that converge but i couldn't find.",,"['calculus', 'integration', 'multivariable-calculus', 'multiple-integral']"
51,Computing $\underset{x^2+y^2+(z-2)^2\le 1}{\int\int\int}{1\over x^2+y^2+z^2}dxdydz$ in Spherical Coordinates,Computing  in Spherical Coordinates,\underset{x^2+y^2+(z-2)^2\le 1}{\int\int\int}{1\over x^2+y^2+z^2}dxdydz,"Compute: $\underset{x^2+y^2+(z-2)^2\le 1}{\int\int\int}{1\over x^2+y^2+z^2}dxdydz$. Hint given : show that $\cos \theta> {r^2+3\over 4r}$ $1<r<3$ What I already did : I shift the unit sphere two coordinates upwards. With $z=r\cos \theta$, assisted by a general drawn line from the sphere (suppose from $a=(x,y,z)$) to the origin, we get that $x^2+y^2$ equals $a$'s projection on the $z$-axis, which by simple computations equals $(r\sin\theta)^2$. Then : $$x^2+y^2+z^2-4z+4=r^2-4r\cos\theta+4\le 1\Rightarrow \cos \theta \ge {r^2+3\over 4r}$$ (How is the strong inequality achieved? I tried showing it but the RHS are variables.) Obviously $1<r<3$. The change of variables is injective and surjective using the inequality in the hint, and the remaining term is $r^2\sin \theta$, but I have no how $\theta$ acts in a single round. I find myself starting from $\theta=0$ (r=1), and again $\theta =0 $ for $r=3$. Do you have any idea how one can proceed from here? While I do understand how to bound the variables in the unit sphere(or, obviously any sphere centered at the origin), here it all seems to collapse. Final answer is told to be : $\pi(2-{3\over 2}\log 3)$, for those who are interested or need it.","Compute: $\underset{x^2+y^2+(z-2)^2\le 1}{\int\int\int}{1\over x^2+y^2+z^2}dxdydz$. Hint given : show that $\cos \theta> {r^2+3\over 4r}$ $1<r<3$ What I already did : I shift the unit sphere two coordinates upwards. With $z=r\cos \theta$, assisted by a general drawn line from the sphere (suppose from $a=(x,y,z)$) to the origin, we get that $x^2+y^2$ equals $a$'s projection on the $z$-axis, which by simple computations equals $(r\sin\theta)^2$. Then : $$x^2+y^2+z^2-4z+4=r^2-4r\cos\theta+4\le 1\Rightarrow \cos \theta \ge {r^2+3\over 4r}$$ (How is the strong inequality achieved? I tried showing it but the RHS are variables.) Obviously $1<r<3$. The change of variables is injective and surjective using the inequality in the hint, and the remaining term is $r^2\sin \theta$, but I have no how $\theta$ acts in a single round. I find myself starting from $\theta=0$ (r=1), and again $\theta =0 $ for $r=3$. Do you have any idea how one can proceed from here? While I do understand how to bound the variables in the unit sphere(or, obviously any sphere centered at the origin), here it all seems to collapse. Final answer is told to be : $\pi(2-{3\over 2}\log 3)$, for those who are interested or need it.",,"['integration', 'multivariable-calculus', 'indefinite-integrals']"
52,"Help with Change of Variable for the function $f(x,y)=e^{\frac{x}{2x+3y}}$",Help with Change of Variable for the function,"f(x,y)=e^{\frac{x}{2x+3y}}","Let $D$ be the open triangle with the vertices $(0,0), (3,0), (0,2)$. For $f(x,y)=e^{ \frac{x}{2x+3y}}$ show that $f$ is integrable on $D$ and prove that $\iint_Df(x,y)dxdy=6\sqrt{e}-6$. I was able to prove that $f$ is integrable on $D$, since $f$ is continuous everywhere but $(0,0)$ and around $(0,0)$, we have that $\frac{x}{2x+3y}<\frac{x}{2x}=\frac{1}{2}$, and therefore $f$ is bounded with a finite number of points where it's not continuous, and therefore, is integrable. I also represented $D$ as $x\in (0,3)$ , $  y\in (0,-\frac{3x}{2}+3)$ since $y=-\frac{3x}{2}+2 $ is the hypertenuse of $D$. Once I got to calculating the integral itself, I tried multiple changes of variables, such as polar, $u=x, v=\frac{1}{2x+3y}$, $u=x, v=2x+3y$, $u=\frac{1}{2x+3y}, v=-\frac{3x}{2}+3$, and none of these gave an integral that could be calculated using analytical tools only (no numerical tools. I also checked this with mathematica and all of these integrals require numerical tools to calculate). What change of variables can be used here? Thanks!","Let $D$ be the open triangle with the vertices $(0,0), (3,0), (0,2)$. For $f(x,y)=e^{ \frac{x}{2x+3y}}$ show that $f$ is integrable on $D$ and prove that $\iint_Df(x,y)dxdy=6\sqrt{e}-6$. I was able to prove that $f$ is integrable on $D$, since $f$ is continuous everywhere but $(0,0)$ and around $(0,0)$, we have that $\frac{x}{2x+3y}<\frac{x}{2x}=\frac{1}{2}$, and therefore $f$ is bounded with a finite number of points where it's not continuous, and therefore, is integrable. I also represented $D$ as $x\in (0,3)$ , $  y\in (0,-\frac{3x}{2}+3)$ since $y=-\frac{3x}{2}+2 $ is the hypertenuse of $D$. Once I got to calculating the integral itself, I tried multiple changes of variables, such as polar, $u=x, v=\frac{1}{2x+3y}$, $u=x, v=2x+3y$, $u=\frac{1}{2x+3y}, v=-\frac{3x}{2}+3$, and none of these gave an integral that could be calculated using analytical tools only (no numerical tools. I also checked this with mathematica and all of these integrals require numerical tools to calculate). What change of variables can be used here? Thanks!",,"['calculus', 'integration', 'multivariable-calculus', 'definite-integrals']"
53,Boundary of unit sphere [duplicate],Boundary of unit sphere [duplicate],,"This question already has an answer here : Is a sphere a closed set? (1 answer) Closed 8 years ago . Let $S$ be a unit sphere in $\mathbb{R}^3$ - I am told that $\partial S = \emptyset $, but why does the unit sphere have no boundary?","This question already has an answer here : Is a sphere a closed set? (1 answer) Closed 8 years ago . Let $S$ be a unit sphere in $\mathbb{R}^3$ - I am told that $\partial S = \emptyset $, but why does the unit sphere have no boundary?",,"['calculus', 'real-analysis', 'multivariable-calculus']"
54,"Global optimum of $f(x,y)=e^{2x}(x + y^2 + 2y)$",Global optimum of,"f(x,y)=e^{2x}(x + y^2 + 2y)","I'm asked to find local/global optima of $f(x,y)=e^{2x}(x + y^2 + 2y)$ over $\mathbb R^2$. Using first and second order conditions I've found that $(\frac 12,-1)$ is the only local extremum of $f$. Specifically, it's a local strict minimum. Plotting the function suggests that it also a global minimum, but how can I prove that ? I don't see any algebraic way of proving $$\forall x,y, e^{2x}(x + y^2 + 2y)\geq -\frac{e}2$$ There's a tedious way: for a fixed $y$, define $g_y(x)=e^{2x}(x + y^2 + 2y)$. Differentiation shows that $g_y$ has a global minimum at $x=-\frac{2y^2+4y+1}{2}$ and $$g_y(-\frac{2y^2+4y+1}{2})=\frac{-e^{-2y^2-4y-1}}{2}$$ Differentiation over $y$ shows that $\displaystyle y \to \frac{-e^{-2y^2-4y-1}}{2}$ has a global minimum at $y=-1$ (the value there is $-\frac{e}2$), hence $-\frac{e}2$ is a global minimum. My proof is very computational and would take quite some time without a computer to assist with the computations. Is there any better way ?","I'm asked to find local/global optima of $f(x,y)=e^{2x}(x + y^2 + 2y)$ over $\mathbb R^2$. Using first and second order conditions I've found that $(\frac 12,-1)$ is the only local extremum of $f$. Specifically, it's a local strict minimum. Plotting the function suggests that it also a global minimum, but how can I prove that ? I don't see any algebraic way of proving $$\forall x,y, e^{2x}(x + y^2 + 2y)\geq -\frac{e}2$$ There's a tedious way: for a fixed $y$, define $g_y(x)=e^{2x}(x + y^2 + 2y)$. Differentiation shows that $g_y$ has a global minimum at $x=-\frac{2y^2+4y+1}{2}$ and $$g_y(-\frac{2y^2+4y+1}{2})=\frac{-e^{-2y^2-4y-1}}{2}$$ Differentiation over $y$ shows that $\displaystyle y \to \frac{-e^{-2y^2-4y-1}}{2}$ has a global minimum at $y=-1$ (the value there is $-\frac{e}2$), hence $-\frac{e}2$ is a global minimum. My proof is very computational and would take quite some time without a computer to assist with the computations. Is there any better way ?",,"['multivariable-calculus', 'optimization']"
55,Find the minimal value of $\frac{x(x-1)+y(y-1)}{2}-xy$,Find the minimal value of,\frac{x(x-1)+y(y-1)}{2}-xy,"I need to find the minimal value of $f(x, y) = \frac{x(x-1)+y(y-1)}{2}-xy$ where $x$ and $y$ are both positive integers. I tried to find the minimum with the help of derivatives: 1) With respect to x: $ f'(x, y) = x - y - \frac{1}{2}$ 2) With respect to y: $ f'(x, y) = y - x - \frac{1}{2}$ I have read that the extremal points of function of two variables can be found if we set both derivatives(with respect to x and y) to 0, but this cannot happen since their sum is always $-1$. Could somebody help me to find the minimum(might be without calculus?) EDIT: From the comments below it seems that this function doesn't have a global minimum. So I want to change the statement as follows: find the minimum of $f(x, y)$ where $x + y = n$","I need to find the minimal value of $f(x, y) = \frac{x(x-1)+y(y-1)}{2}-xy$ where $x$ and $y$ are both positive integers. I tried to find the minimum with the help of derivatives: 1) With respect to x: $ f'(x, y) = x - y - \frac{1}{2}$ 2) With respect to y: $ f'(x, y) = y - x - \frac{1}{2}$ I have read that the extremal points of function of two variables can be found if we set both derivatives(with respect to x and y) to 0, but this cannot happen since their sum is always $-1$. Could somebody help me to find the minimum(might be without calculus?) EDIT: From the comments below it seems that this function doesn't have a global minimum. So I want to change the statement as follows: find the minimum of $f(x, y)$ where $x + y = n$",,"['multivariable-calculus', 'functions', 'discrete-mathematics', 'optimization']"
56,Must $\vec{n}$ be a Unit Normal Vector (Stokes' Theorem)?,Must  be a Unit Normal Vector (Stokes' Theorem)?,\vec{n},"If $S$ is an oriented, smooth surface that is bounded by a simple, closed, smooth boundary curve $C$ with positive orientation, then for some vector field $\vec{F}$: $$\oint_C \vec{F} \cdot d\vec{r} =  \iint_S {\rm curl} \> \vec{F} \cdot d\vec{S}$$ The latter integral can be written equivalently as follows for some vector $\vec{n}$, given that it is normal to the surface $S$ and has the proper orientation: $$\iint_S {\rm curl} \> \vec{F} \cdot \vec{n} \> dS$$ Ultimately, my question is whether or not this normal vector, $\vec{n}$, must be a unit normal vector or not (or if there are other constraints that must be imposed on it). The reason I ask this is because, while working on a problem involving Stokes' Theorem, I deduced that the appropriate normal vector for some surface was $\hat{i} + \hat{k}$, and so I normalized it, yielding $\frac{1}{\sqrt 2}\hat{i} + \frac{1}{\sqrt 2}\hat{k}$. My answer ended up being off by a factor of $\frac{1}{\sqrt 2}$ which makes me think that how I have defined $\vec{n}$ for these types of problems is incorrect. [Edit] For those interested, the problem was to evaluate $\oint_C \vec{F} \cdot d\vec{r}$ for $\vec{F}(x, y, z) = xy\>\hat{i} + 2z\>\hat{j} + 6y\>\hat{k}$ such that $C$ is the counterclockwise-oriented curve of intersection of the plane $x + z = 1$ and the cylinder $x^2 + y^2 = 36$.","If $S$ is an oriented, smooth surface that is bounded by a simple, closed, smooth boundary curve $C$ with positive orientation, then for some vector field $\vec{F}$: $$\oint_C \vec{F} \cdot d\vec{r} =  \iint_S {\rm curl} \> \vec{F} \cdot d\vec{S}$$ The latter integral can be written equivalently as follows for some vector $\vec{n}$, given that it is normal to the surface $S$ and has the proper orientation: $$\iint_S {\rm curl} \> \vec{F} \cdot \vec{n} \> dS$$ Ultimately, my question is whether or not this normal vector, $\vec{n}$, must be a unit normal vector or not (or if there are other constraints that must be imposed on it). The reason I ask this is because, while working on a problem involving Stokes' Theorem, I deduced that the appropriate normal vector for some surface was $\hat{i} + \hat{k}$, and so I normalized it, yielding $\frac{1}{\sqrt 2}\hat{i} + \frac{1}{\sqrt 2}\hat{k}$. My answer ended up being off by a factor of $\frac{1}{\sqrt 2}$ which makes me think that how I have defined $\vec{n}$ for these types of problems is incorrect. [Edit] For those interested, the problem was to evaluate $\oint_C \vec{F} \cdot d\vec{r}$ for $\vec{F}(x, y, z) = xy\>\hat{i} + 2z\>\hat{j} + 6y\>\hat{k}$ such that $C$ is the counterclockwise-oriented curve of intersection of the plane $x + z = 1$ and the cylinder $x^2 + y^2 = 36$.",,"['multivariable-calculus', 'surfaces', 'stokes-theorem']"
57,Can anyone help me understand Lagrange Multipliers?,Can anyone help me understand Lagrange Multipliers?,,"I'm currently trying to understand the method of Lagrange Multipliers. The explanation I'm currently looking at says something along the lines of ""Suppose we wish to minimise the function $f(x,y)$ subject to the constraint $g(x,y)=0$, and that this minimum is the point $(x_{0}, y_{0})$. Then $\nabla f(x_{0}, y_{0})$ is the normal to the function $f$ at this point. Furthermore, the normal vectors of $f$ and $g$ are are parallel. Thus, $\nabla f(x_{0}, y_{0})=\lambda \nabla g(x_{0}, y_{0})$."" (Source: http://www.slimy.com/~steuard/teaching/tutorials/Lagrange.html ) I really don't understand why the normal vectors of $f$ and $g$ are are parallel, or how this gives rise to the equation $\nabla f(x_{0}, y_{0})=\lambda \nabla g(x_{0}, y_{0})$. Could someone please explain this to me? Many thanks.","I'm currently trying to understand the method of Lagrange Multipliers. The explanation I'm currently looking at says something along the lines of ""Suppose we wish to minimise the function $f(x,y)$ subject to the constraint $g(x,y)=0$, and that this minimum is the point $(x_{0}, y_{0})$. Then $\nabla f(x_{0}, y_{0})$ is the normal to the function $f$ at this point. Furthermore, the normal vectors of $f$ and $g$ are are parallel. Thus, $\nabla f(x_{0}, y_{0})=\lambda \nabla g(x_{0}, y_{0})$."" (Source: http://www.slimy.com/~steuard/teaching/tutorials/Lagrange.html ) I really don't understand why the normal vectors of $f$ and $g$ are are parallel, or how this gives rise to the equation $\nabla f(x_{0}, y_{0})=\lambda \nabla g(x_{0}, y_{0})$. Could someone please explain this to me? Many thanks.",,"['calculus', 'multivariable-calculus', 'optimization', 'lagrange-multiplier']"
58,How to find extrema of $\sqrt{x_1^2 + x^2_2 + x^2_3}$ defined on $\{x \in \mathbb{R}^3 : x_1^2 + 2x^2_2 + 3x^2_3 < 1\}$,How to find extrema of  defined on,\sqrt{x_1^2 + x^2_2 + x^2_3} \{x \in \mathbb{R}^3 : x_1^2 + 2x^2_2 + 3x^2_3 < 1\},"I have a function $g: U \to\mathbb{R}$ where  $$U :=\{x \in \mathbb{R}^3 : x_1^2 + 2x^2_2 + 3x^2_3 < 1\}$$  and  $$g(x) = \sqrt{x_1^2 + x^2_2 + x^2_3}$$ I would like to find out if g(x) has any extrema. What I've tried so far: $U$ is an open set. Now I'm looking for $\nabla g(a)$, where $x \in U$. $$\nabla g(x) = ( \frac{x_1}{\sqrt{x_1^2 + x^2_2 + x^2_3}}, \frac{x_2}{\sqrt{x_1^2 + x^2_2 + x^2_3}}, \frac{x_3}{\sqrt{x_1^2 + x^2_2 + x^2_3}} )$$ If I want to get local extrema of $g$ then I have to find $a \in U$ such that $\nabla g(a) = (0,0,0)$. The only solution I can think of is the $a=(0,0,0)$ point. However, if $x_1, x_2, x_3 = 0$ then $\frac{x_1}{\sqrt{x_1^2 + x^2_2 + x^2_3}} = \frac{0}{\sqrt{0}}$ which is undefined. And now I'm stuck.","I have a function $g: U \to\mathbb{R}$ where  $$U :=\{x \in \mathbb{R}^3 : x_1^2 + 2x^2_2 + 3x^2_3 < 1\}$$  and  $$g(x) = \sqrt{x_1^2 + x^2_2 + x^2_3}$$ I would like to find out if g(x) has any extrema. What I've tried so far: $U$ is an open set. Now I'm looking for $\nabla g(a)$, where $x \in U$. $$\nabla g(x) = ( \frac{x_1}{\sqrt{x_1^2 + x^2_2 + x^2_3}}, \frac{x_2}{\sqrt{x_1^2 + x^2_2 + x^2_3}}, \frac{x_3}{\sqrt{x_1^2 + x^2_2 + x^2_3}} )$$ If I want to get local extrema of $g$ then I have to find $a \in U$ such that $\nabla g(a) = (0,0,0)$. The only solution I can think of is the $a=(0,0,0)$ point. However, if $x_1, x_2, x_3 = 0$ then $\frac{x_1}{\sqrt{x_1^2 + x^2_2 + x^2_3}} = \frac{0}{\sqrt{0}}$ which is undefined. And now I'm stuck.",,"['real-analysis', 'multivariable-calculus', 'optimization']"
59,"If a function vanishes on the boundary of a domain, its gradient on the boundary is a multiple of normal vector","If a function vanishes on the boundary of a domain, its gradient on the boundary is a multiple of normal vector",,"I have seen in many papers that to obtain some results about PDEs is used the following argument: If $\phi=0$ in $\partial\Omega$ then $\nabla \phi=\dfrac{\partial\phi}{\partial n}n$, where $n$ is the unit vector and  $\dfrac{\partial\phi}{\partial n}$ is the normal derivative. Do you know how can I obtain some formal proof about this argument?","I have seen in many papers that to obtain some results about PDEs is used the following argument: If $\phi=0$ in $\partial\Omega$ then $\nabla \phi=\dfrac{\partial\phi}{\partial n}n$, where $n$ is the unit vector and  $\dfrac{\partial\phi}{\partial n}$ is the normal derivative. Do you know how can I obtain some formal proof about this argument?",,"['multivariable-calculus', 'partial-differential-equations']"
60,Solving $4y^4 - 4x^4 + x + y = 0$ (equation system of partial derivates),Solving  (equation system of partial derivates),4y^4 - 4x^4 + x + y = 0,"I need help solving the following equation system: $$ \frac{\partial}{\partial x} = 8xy + 4y^2 + \frac{y}{x^2 + y^2} = 0 $$ $$ \frac{\partial}{\partial y} = 8xy + 4x^2 - \frac{x}{x^2 + y^2} = 0 $$ I've managed to simplify this down to the following: $$ 4x^4 - 4y^4 + x + y \Leftrightarrow 4x^4 + x = 4y^4 - y $$ But I can't find a way to separate the $x$ or $y$. Wolfram-Alpha says the solution is $y = -x$, and I'm assuming there must be some simple trick (creating a square etc) to find that solution since I very much doubt solving a general 4th degree equation is part of this particular problem, but I just can't figure out how. The full problem is from an exercise in my course book in multivariable calculus, I'll post the whole problem below if it turns out I missed something essential in the problem statement. Please help, it's extremely frustrating to get stuck on this subproblem which really has nothing to do with calculus at all. If there is some trick that can be applied to solve this particular equation I very much would like to know and never get stuck like this again. Whole problem: ""Find and classify the stationary points of the following function"" $$ f(x,y) = 4xy(x+y) + \arctan \frac{x}{y} $$","I need help solving the following equation system: $$ \frac{\partial}{\partial x} = 8xy + 4y^2 + \frac{y}{x^2 + y^2} = 0 $$ $$ \frac{\partial}{\partial y} = 8xy + 4x^2 - \frac{x}{x^2 + y^2} = 0 $$ I've managed to simplify this down to the following: $$ 4x^4 - 4y^4 + x + y \Leftrightarrow 4x^4 + x = 4y^4 - y $$ But I can't find a way to separate the $x$ or $y$. Wolfram-Alpha says the solution is $y = -x$, and I'm assuming there must be some simple trick (creating a square etc) to find that solution since I very much doubt solving a general 4th degree equation is part of this particular problem, but I just can't figure out how. The full problem is from an exercise in my course book in multivariable calculus, I'll post the whole problem below if it turns out I missed something essential in the problem statement. Please help, it's extremely frustrating to get stuck on this subproblem which really has nothing to do with calculus at all. If there is some trick that can be applied to solve this particular equation I very much would like to know and never get stuck like this again. Whole problem: ""Find and classify the stationary points of the following function"" $$ f(x,y) = 4xy(x+y) + \arctan \frac{x}{y} $$",,"['calculus', 'multivariable-calculus', 'polynomials', 'systems-of-equations', 'partial-derivative']"
61,How to show this function is surjective,How to show this function is surjective,,"$T(x,y,z) = (2x + y + 3z, 3y - 4z, 5x)$ for $R^3 \rightarrow R^3$ I read the meaning of surjective over and over, but I don't understand how to show it algebraically. So I just guessed: $2x + y + 3z = a \\ 3y - 4z = b \\ 5x = c$ So $x = \frac{c}{5}$. Then we have $\frac{2c}{5} + y + 3z = a$ and $3y - 4z = b$ I'm lost here. I'm not sure what I'm supposed to do, but I just guessed and and trying to express things in other variables. I'm not sure what I am doing.","$T(x,y,z) = (2x + y + 3z, 3y - 4z, 5x)$ for $R^3 \rightarrow R^3$ I read the meaning of surjective over and over, but I don't understand how to show it algebraically. So I just guessed: $2x + y + 3z = a \\ 3y - 4z = b \\ 5x = c$ So $x = \frac{c}{5}$. Then we have $\frac{2c}{5} + y + 3z = a$ and $3y - 4z = b$ I'm lost here. I'm not sure what I'm supposed to do, but I just guessed and and trying to express things in other variables. I'm not sure what I am doing.",,"['multivariable-calculus', 'functions']"
62,Contradictory area elements in Cartesian and polar coordinates [duplicate],Contradictory area elements in Cartesian and polar coordinates [duplicate],,"This question already has answers here : Explain $\iint \mathrm dx\,\mathrm dy = \iint r \,\mathrm \,d\alpha\,\mathrm dr$ (4 answers) Closed 4 years ago . We all know that the area element $dA$ in Cartesian coordinates is given by $$dA = dx\ dy.$$ With a bit of geometry, we can also see that the area element $dA$ in polar coordinates is given by $$dA = r\ dr\ d\theta.$$ If this is the case, when why doesn't $dx\ dy = r\ dr\ d\theta$? By implicitly differentiating the equations $x = r \cos \theta$ and $y = r \sin \theta$, we have that $$dx = dr \cos \theta - r \sin \theta\ d\theta$$ and $$dy = dr \sin \theta + r \cos \theta\ d\theta.$$ Thus, \begin{align*} dx\ dy &= (dr \cos \theta - r \sin \theta\ d\theta)(dr \sin \theta + r \cos \theta\ d\theta)\\ &= dr^2 \cos\theta \sin\theta+r\ dr \cos^2 \theta\ d\theta-r\ dr \sin^2 \theta\ d\theta-r^2\sin\theta\cos\theta\ d\theta^2. \end{align*} It is not evident to me that this expression equals $r\ dr\ d\theta$, if it does at all. Why does this discrepancy exist? Is it the case that $dA$ in Cartesian coordinates is simply not the same thing as $dA$ in polar coordinates? If so, why do both correspond to area elements in the plane?","This question already has answers here : Explain $\iint \mathrm dx\,\mathrm dy = \iint r \,\mathrm \,d\alpha\,\mathrm dr$ (4 answers) Closed 4 years ago . We all know that the area element $dA$ in Cartesian coordinates is given by $$dA = dx\ dy.$$ With a bit of geometry, we can also see that the area element $dA$ in polar coordinates is given by $$dA = r\ dr\ d\theta.$$ If this is the case, when why doesn't $dx\ dy = r\ dr\ d\theta$? By implicitly differentiating the equations $x = r \cos \theta$ and $y = r \sin \theta$, we have that $$dx = dr \cos \theta - r \sin \theta\ d\theta$$ and $$dy = dr \sin \theta + r \cos \theta\ d\theta.$$ Thus, \begin{align*} dx\ dy &= (dr \cos \theta - r \sin \theta\ d\theta)(dr \sin \theta + r \cos \theta\ d\theta)\\ &= dr^2 \cos\theta \sin\theta+r\ dr \cos^2 \theta\ d\theta-r\ dr \sin^2 \theta\ d\theta-r^2\sin\theta\cos\theta\ d\theta^2. \end{align*} It is not evident to me that this expression equals $r\ dr\ d\theta$, if it does at all. Why does this discrepancy exist? Is it the case that $dA$ in Cartesian coordinates is simply not the same thing as $dA$ in polar coordinates? If so, why do both correspond to area elements in the plane?",,['multivariable-calculus']
63,Integrating sin(x) on a unit circle,Integrating sin(x) on a unit circle,,"I am trying to integrate $\int\int_{D} sin(x)$ where $D$ is a unit circle centered at $(0,0)$. My approach is to turn the area into the polar coordinate so I have $D$ as $0\leq r\leq1$ , $0 \leq \theta \leq 2\pi$. Which turns the integral into: $$\int^{2\pi}_{0}\int^{1}_{0} \sin(r\cos(\theta)) |r| drd\theta$$ and it is not integrable. I also tried the Cartesian approach by evaluating: $$\int^{1}_{0}\int^{\sqrt{1-x^2}}_{0} \sin(x) dydx$$ which is also not integrable Which direction or method should I use to integrate this problem? Edit* Thank you so much for the answers, I agree that because of symmetry, the answer is zero. The hint says don't do too work work also lol.","I am trying to integrate $\int\int_{D} sin(x)$ where $D$ is a unit circle centered at $(0,0)$. My approach is to turn the area into the polar coordinate so I have $D$ as $0\leq r\leq1$ , $0 \leq \theta \leq 2\pi$. Which turns the integral into: $$\int^{2\pi}_{0}\int^{1}_{0} \sin(r\cos(\theta)) |r| drd\theta$$ and it is not integrable. I also tried the Cartesian approach by evaluating: $$\int^{1}_{0}\int^{\sqrt{1-x^2}}_{0} \sin(x) dydx$$ which is also not integrable Which direction or method should I use to integrate this problem? Edit* Thank you so much for the answers, I agree that because of symmetry, the answer is zero. The hint says don't do too work work also lol.",,"['calculus', 'multivariable-calculus']"
64,Finding the Absolute Maximum and Minimum of a 3D Function,Finding the Absolute Maximum and Minimum of a 3D Function,,"Find the absolute maximum and minimum values of the function: $$f(x,y)=2x^3+2xy^2-x-y^2$$ on the unit disk $D=\{(x,y):x^2+y^2\leq 1\}$.","Find the absolute maximum and minimum values of the function: $$f(x,y)=2x^3+2xy^2-x-y^2$$ on the unit disk $D=\{(x,y):x^2+y^2\leq 1\}$.",,"['multivariable-calculus', 'optimization']"
65,Minimum value of the function $\sqrt{(1+1/m)(1+1/n)}$,Minimum value of the function,\sqrt{(1+1/m)(1+1/n)},"If $m, n$ are positive real variables whose sum is a constant $k$, then what is the minimum value of $$\sqrt{\bigg(1 + \frac{1}{m}\bigg)\bigg(1 + \frac{1}{n}\bigg)}$$","If $m, n$ are positive real variables whose sum is a constant $k$, then what is the minimum value of $$\sqrt{\bigg(1 + \frac{1}{m}\bigg)\bigg(1 + \frac{1}{n}\bigg)}$$",,"['multivariable-calculus', 'inequality', 'optimization']"
66,Area between two circles as a double integral in polar coordinates,Area between two circles as a double integral in polar coordinates,,"Find the area between the circles $x^{2} + y^{2} = 4$ and  $x^{2} + y^{2} = 6x$ using polar coordinates. I have found that the equation of the first circle, call it $C_1$, is $r=2$ on the other hand, for $C_2$, I get that its equation is $r = 6cos{\theta}$. Then, to find the bounds of integration, I have found that their angle of intersection should be $\theta = \arccos(1/3)$ and $\theta = -\arccos(1/3)$. Then, to set up the double integral: $A= \displaystyle\int_{-\arccos(1/3)}^{\arccos(1/3)} \displaystyle\int_{6\cos{\theta}}^2  \mathrm{r}\,\mathrm{d}r\, \mathrm{d}{\theta}$ However, when evaluating this integral with the calculator, I get a negative value. What would be the problem in this case? Thanks in advance for your help.","Find the area between the circles $x^{2} + y^{2} = 4$ and  $x^{2} + y^{2} = 6x$ using polar coordinates. I have found that the equation of the first circle, call it $C_1$, is $r=2$ on the other hand, for $C_2$, I get that its equation is $r = 6cos{\theta}$. Then, to find the bounds of integration, I have found that their angle of intersection should be $\theta = \arccos(1/3)$ and $\theta = -\arccos(1/3)$. Then, to set up the double integral: $A= \displaystyle\int_{-\arccos(1/3)}^{\arccos(1/3)} \displaystyle\int_{6\cos{\theta}}^2  \mathrm{r}\,\mathrm{d}r\, \mathrm{d}{\theta}$ However, when evaluating this integral with the calculator, I get a negative value. What would be the problem in this case? Thanks in advance for your help.",,['multivariable-calculus']
67,"Integral$\int_{0}^{1} \int_{-1}^{1} |x + y|\,\mathrm dy\,\mathrm dx$",Integral,"\int_{0}^{1} \int_{-1}^{1} |x + y|\,\mathrm dy\,\mathrm dx","Here is the question. I put the equation in the following double integral: $$\int_{0}^{1} \int_{-1}^{1} |x + y|\,\mathrm dy\,\mathrm dx$$ I know you can break up the absolute function into the following. I'm not really sure what to do next. I looked at this link but I don't know when x + y is nonnegative and when it's negative as we need the values of both x and y and when calculating the inner integral we're only doing it with respect to y. So I'm not exactly sure how to determine when |x + y| is nonnegative and when it is negative.  $$     |\,x + y\,| = \left\{      \begin{array}{lr}        x + y & : x + y >0 \Leftrightarrow y > -x \\        -(x + y) & : x + y < 0 \Leftrightarrow y < -x      \end{array}    \right.  $$ However, I came up with a ""solution"" which is quite silly but I thought it might work. $$\int_{0}^{1} | \int_{-1}^{1} x \, dy \, + \int_{-1}^{1} y \,dy\, | = \int_{0}^{1}  |\, 2x\, |  = 1 $$ I'm lost and any help would be greately appreciated.","Here is the question. I put the equation in the following double integral: $$\int_{0}^{1} \int_{-1}^{1} |x + y|\,\mathrm dy\,\mathrm dx$$ I know you can break up the absolute function into the following. I'm not really sure what to do next. I looked at this link but I don't know when x + y is nonnegative and when it's negative as we need the values of both x and y and when calculating the inner integral we're only doing it with respect to y. So I'm not exactly sure how to determine when |x + y| is nonnegative and when it is negative.  $$     |\,x + y\,| = \left\{      \begin{array}{lr}        x + y & : x + y >0 \Leftrightarrow y > -x \\        -(x + y) & : x + y < 0 \Leftrightarrow y < -x      \end{array}    \right.  $$ However, I came up with a ""solution"" which is quite silly but I thought it might work. $$\int_{0}^{1} | \int_{-1}^{1} x \, dy \, + \int_{-1}^{1} y \,dy\, | = \int_{0}^{1}  |\, 2x\, |  = 1 $$ I'm lost and any help would be greately appreciated.",,['multivariable-calculus']
68,"Fast way to integrate $\frac{x^2-y^2}{(x^2+y^2)^2} dx \,dy$ in unit square",Fast way to integrate  in unit square,"\frac{x^2-y^2}{(x^2+y^2)^2} dx \,dy","I am looking for a fast way to integrate $$ \int_0^1 \int_0^1 \frac{x^2-y^2}{(x^2+y^2)^2} dx \,dy$$ using standard techniques ( no complex analysis and no functional analysis). I am aware that wolframalpha spits out a solution, but this one is quite long, I assume that there is a faster way to do this. The result will be $\frac{\pm \pi}{2}$(depending on which integral you do first). By the way: Please be aware of the fact, that fubini's theorem does not hold in this case.","I am looking for a fast way to integrate $$ \int_0^1 \int_0^1 \frac{x^2-y^2}{(x^2+y^2)^2} dx \,dy$$ using standard techniques ( no complex analysis and no functional analysis). I am aware that wolframalpha spits out a solution, but this one is quite long, I assume that there is a faster way to do this. The result will be $\frac{\pm \pi}{2}$(depending on which integral you do first). By the way: Please be aware of the fact, that fubini's theorem does not hold in this case.",,['integration']
69,Compute: $\int_{0}^{1}\int_{x}^{1} e^{x/y}$,Compute:,\int_{0}^{1}\int_{x}^{1} e^{x/y},"Compute: $\int_{0}^{1}\int_{x}^{1} e^{x/y}$ I just don't know how to compute this integral. I tried u = x/y, but that didn't really lead me anywhere. It was suggested by fellows on a IRC that I graph this, but I didn't really understand. Could anyone expand on this?","Compute: $\int_{0}^{1}\int_{x}^{1} e^{x/y}$ I just don't know how to compute this integral. I tried u = x/y, but that didn't really lead me anywhere. It was suggested by fellows on a IRC that I graph this, but I didn't really understand. Could anyone expand on this?",,['multivariable-calculus']
70,"Find unit normal vector to the surface $z=x^4y+xy^2$ at the point $(1,1,2)$",Find unit normal vector to the surface  at the point,"z=x^4y+xy^2 (1,1,2)","I've been trying to solve this question: Find a unit vector with positive $z$ component which is normal to the surface $z=x^4y+xy^2$ at the point $(1,1,2)$ on the surface. My working: Let $z=f(x,y) = x^4 y + xy^2$, $$\begin{split}\frac{\partial F}{\partial x} &= 4x^3y+y^2\\  \frac{\partial F}{\partial x}(1,1) &= 4(1)^3(1)+(1)^2 = 5\\ \frac{\partial F}{\partial y} &= x^4+2xy\\ \frac{\partial F}{\partial y} &= (1)^4+2(1)(1)=3 \end{split} $$ Therefore the normal vector is $(5, 3, -1)^T$ But the answers say,  $(-\frac{1}{7}\sqrt{35}, -\frac{3}{35}\sqrt{35}, \frac{1}{35}\sqrt{35})^T$ I assume the words unit, positive in the question has something to do with this? I also noticed that when I multiply the components of my answer by $-\frac{\sqrt{35}}{5}$ the answer pops out.","I've been trying to solve this question: Find a unit vector with positive $z$ component which is normal to the surface $z=x^4y+xy^2$ at the point $(1,1,2)$ on the surface. My working: Let $z=f(x,y) = x^4 y + xy^2$, $$\begin{split}\frac{\partial F}{\partial x} &= 4x^3y+y^2\\  \frac{\partial F}{\partial x}(1,1) &= 4(1)^3(1)+(1)^2 = 5\\ \frac{\partial F}{\partial y} &= x^4+2xy\\ \frac{\partial F}{\partial y} &= (1)^4+2(1)(1)=3 \end{split} $$ Therefore the normal vector is $(5, 3, -1)^T$ But the answers say,  $(-\frac{1}{7}\sqrt{35}, -\frac{3}{35}\sqrt{35}, \frac{1}{35}\sqrt{35})^T$ I assume the words unit, positive in the question has something to do with this? I also noticed that when I multiply the components of my answer by $-\frac{\sqrt{35}}{5}$ the answer pops out.",,"['multivariable-calculus', 'vectors', 'surfaces']"
71,Integration with change of variables (multivariable).,Integration with change of variables (multivariable).,,"The following are the problems that I have been working on. It involves change in variables with 2,3 variables respectively. (1)Let $R$ be the trapezoid with vertices at $(0,1),(1,0),(0,2)$ and $(2,0)$ . Using the substitutions $u = y-x$ and $v = y +x$ , evaluate $$\int\int_R  e^{{y-x}\over{y+x}} dA$$ . (2)Evaluate the following integral $$\int\int\int_D (x^2y + 3xyz)dV$$ where D is the region in 3-space defined by $1 \le x \le 2, 0 \le xy \le 2, 0 \le z \le 1$ using the substitution $u =x , v = xy, w=3z$ . Here are what I tried. 1), I understand the part where the parallel lines $x+y = 1$ and $x+y=2$ is used to find the limit of integration of $v$ , but what am I supposed to do with that of $u$ ?  One side of the trapezoid is vertical and the other side is horizontal and it looks nothing like the equation $v$ . I was thinking about trying to doubling the trapezoid so that it becomes a parallelogram, but I am not sure if that even works. I understand the idea and the fact that $$\int\int_R f(x,y) dA = \int\int_S f(g(u,v),h(u,v))|{ \partial{(x,y)}\over{\partial(u,v)}}|dvdu$$ , but this is more of an algebraic thing that I am stuck with. 2), Again, I understand the theory, but I am stuck with the algebraic part. The approach I made was $$\int_0^1 \int_0^2 \int_1^2 (uv+3vw)|{1\over{3u}}|dudvdw$$ but I ended up having to integrate an improper integral with the result being $-\infty$ ... Can someone help out ?","The following are the problems that I have been working on. It involves change in variables with 2,3 variables respectively. (1)Let be the trapezoid with vertices at and . Using the substitutions and , evaluate . (2)Evaluate the following integral where D is the region in 3-space defined by using the substitution . Here are what I tried. 1), I understand the part where the parallel lines and is used to find the limit of integration of , but what am I supposed to do with that of ?  One side of the trapezoid is vertical and the other side is horizontal and it looks nothing like the equation . I was thinking about trying to doubling the trapezoid so that it becomes a parallelogram, but I am not sure if that even works. I understand the idea and the fact that , but this is more of an algebraic thing that I am stuck with. 2), Again, I understand the theory, but I am stuck with the algebraic part. The approach I made was but I ended up having to integrate an improper integral with the result being ... Can someone help out ?","R (0,1),(1,0),(0,2) (2,0) u = y-x v = y +x \int\int_R  e^{{y-x}\over{y+x}} dA \int\int\int_D (x^2y + 3xyz)dV 1 \le x \le 2, 0 \le xy \le 2, 0 \le z \le 1 u =x , v = xy, w=3z x+y = 1 x+y=2 v u v \int\int_R f(x,y) dA = \int\int_S f(g(u,v),h(u,v))|{ \partial{(x,y)}\over{\partial(u,v)}}|dvdu \int_0^1 \int_0^2 \int_1^2 (uv+3vw)|{1\over{3u}}|dudvdw -\infty",['multivariable-calculus']
72,Evaluate the Integral using Contour Integration (Theorem of Residues),Evaluate the Integral using Contour Integration (Theorem of Residues),,"$$ J(a,b)=\int_{0}^{\infty }\frac{\sin(b x)}{\sinh(a x)} dx $$ This integral is difficult because contour integrals normally cannot be solved with a sin(x) term in the numerator because of singularity issues between the 1st quadrant to the 2nd quadrant in the upper half circle of the contour. I've assumed: $$ \sin(bx)=e^{ibz} $$ since it effectively IS the sine term in the upper half circle. I've also used the following substitutions: $$ x=z  ;  z=re^{i\theta}   ;  z=\cos(\theta)+i\sin(\theta) $$ From what I understand, the x range has to include all values somehow. When I plug in the substitutions and the Euler forms of sin and sinh, the integral becomes: $$ 2\int_{-\infty }^{\infty }\frac{e^{ibx}}{e^{ax}-e^{ax}}dx $$ Have I screwed up the subs?  Did I reduce incorrectly?  Not sure what to go from here. If anyone could help shed some light it would be very much appreciated.","$$ J(a,b)=\int_{0}^{\infty }\frac{\sin(b x)}{\sinh(a x)} dx $$ This integral is difficult because contour integrals normally cannot be solved with a sin(x) term in the numerator because of singularity issues between the 1st quadrant to the 2nd quadrant in the upper half circle of the contour. I've assumed: $$ \sin(bx)=e^{ibz} $$ since it effectively IS the sine term in the upper half circle. I've also used the following substitutions: $$ x=z  ;  z=re^{i\theta}   ;  z=\cos(\theta)+i\sin(\theta) $$ From what I understand, the x range has to include all values somehow. When I plug in the substitutions and the Euler forms of sin and sinh, the integral becomes: $$ 2\int_{-\infty }^{\infty }\frac{e^{ibx}}{e^{ax}-e^{ax}}dx $$ Have I screwed up the subs?  Did I reduce incorrectly?  Not sure what to go from here. If anyone could help shed some light it would be very much appreciated.",,"['multivariable-calculus', 'mathematical-physics']"
73,Partial derivative VS total derivative?,Partial derivative VS total derivative?,,My friends argue this $d_t( \partial_{\dot{x}} g)=1+2\dot{\dot{x}} \not = \partial_t (\partial_{\dot{x} }g)$ where $g=t\dot x + x^2 + \dot{x}^2$. Why?,My friends argue this $d_t( \partial_{\dot{x}} g)=1+2\dot{\dot{x}} \not = \partial_t (\partial_{\dot{x} }g)$ where $g=t\dot x + x^2 + \dot{x}^2$. Why?,,"['multivariable-calculus', 'derivatives']"
74,Confusion regarding orientation of curves in Green's Theorem,Confusion regarding orientation of curves in Green's Theorem,,"I am in the middle of helping some friends out with their vector calculus assignment (I don't do this course). Now in their assignment they have the following question: Consider the integral $$\oint_{C_1} \frac{-y^3 dx + xy^2 dy}{(x^2 + y^2)^2}$$     where $C_1$ is the ellipse $x^2 + 4y^2 = 4$. Assuming that Green's Theorem can be applied to the region $D$ between the circle $C_2 : x^2 + y^2 = 9$ and the ellipse $C_1$, show that $$\oint_{C_1}\frac{-y^3 dx + xy^2 dy}{(x^2 + y^2)^2} = \oint_{C_2} \frac{-y^3 dx + xy^2 dy}{(x^2 + y^2)^2}$$     where $C_1$ and $C_2$ are both traversed in the anti - clockwise direction sense as viewed from the positive $z$ - direction. Now let us call $M = \frac{-y^3}{(x^2 + y^2)^2}$ and $N = \frac{xy^2}{(x^2 + y^2)^2}$. I want to invoke something about Green's Theorem that tells me something like $$\oint_{C_1} M dx + N dy - \oint_{C_2} M dx + N dy = \int\int_D (N_x - M_y) dxdy.$$ If this holds since the right hand side is zero, we would have our desired equality. However what is causing the confusion is the left hand side. Is this even valid? In all the problems we have encountered, the curves $C_1$ and $C_2$ are traversed in opposite directions. For example $C_2$ is traversed clockwise and $C_1$ is traversed counter - clockwise. However now both curves are traversed anti - clockwise so how do we get around this? Is there a mistake in the assignment? Thanks.","I am in the middle of helping some friends out with their vector calculus assignment (I don't do this course). Now in their assignment they have the following question: Consider the integral $$\oint_{C_1} \frac{-y^3 dx + xy^2 dy}{(x^2 + y^2)^2}$$     where $C_1$ is the ellipse $x^2 + 4y^2 = 4$. Assuming that Green's Theorem can be applied to the region $D$ between the circle $C_2 : x^2 + y^2 = 9$ and the ellipse $C_1$, show that $$\oint_{C_1}\frac{-y^3 dx + xy^2 dy}{(x^2 + y^2)^2} = \oint_{C_2} \frac{-y^3 dx + xy^2 dy}{(x^2 + y^2)^2}$$     where $C_1$ and $C_2$ are both traversed in the anti - clockwise direction sense as viewed from the positive $z$ - direction. Now let us call $M = \frac{-y^3}{(x^2 + y^2)^2}$ and $N = \frac{xy^2}{(x^2 + y^2)^2}$. I want to invoke something about Green's Theorem that tells me something like $$\oint_{C_1} M dx + N dy - \oint_{C_2} M dx + N dy = \int\int_D (N_x - M_y) dxdy.$$ If this holds since the right hand side is zero, we would have our desired equality. However what is causing the confusion is the left hand side. Is this even valid? In all the problems we have encountered, the curves $C_1$ and $C_2$ are traversed in opposite directions. For example $C_2$ is traversed clockwise and $C_1$ is traversed counter - clockwise. However now both curves are traversed anti - clockwise so how do we get around this? Is there a mistake in the assignment? Thanks.",,['multivariable-calculus']
75,Prove that there exists a nearest point in a closed set $A \subset \mathbf{R}^n$ to a point outside of $A$,Prove that there exists a nearest point in a closed set  to a point outside of,A \subset \mathbf{R}^n A,"I know that the assertion can be proved by a direct application of the Bolzano-Weierstrass Theorem. I am interested in proving this using the extreme value theorem for continuous functions. Claim: Let $x_0 \notin A\subset \mathbf{R}^n$. $A$ is closed. Then there is an $x_1 \in A$ such that $|x_1-x_0| \leq |x-x_0|, \forall x \in A$. (The norm is Euclidean) Proof: Since $x_0 \notin A$ we have $0<|x-x_0|$. Thus $d=\inf_{x \in A}|x-x_0|$ can be defined. Take a $\delta>0$. Consider the set $S=\{x:|x-x_0| \leq d+\delta\} \cap A$. Clearly $S$ is bounded. It is also closed, being the intersection of two closed sets. Because the function $f(x)=|x-x_0|$ is continuous, it will attain its minimum value over $S$. So there exists an $x_1 \in A$ s.t. $|x_1-x_0| \leq |x-x_0|$  for all $x\in A$ with $|x-x_0| \leq d+\delta$. But this means that $d \leq |x_1-x_0| \leq d + \delta$ for an arbitrary $\delta$. Hence, $|x_1-x_0|=d=\inf_{x \in A}|x-x_0|$. Please tell me if this is correct, specially the last line about which I have doubts.","I know that the assertion can be proved by a direct application of the Bolzano-Weierstrass Theorem. I am interested in proving this using the extreme value theorem for continuous functions. Claim: Let $x_0 \notin A\subset \mathbf{R}^n$. $A$ is closed. Then there is an $x_1 \in A$ such that $|x_1-x_0| \leq |x-x_0|, \forall x \in A$. (The norm is Euclidean) Proof: Since $x_0 \notin A$ we have $0<|x-x_0|$. Thus $d=\inf_{x \in A}|x-x_0|$ can be defined. Take a $\delta>0$. Consider the set $S=\{x:|x-x_0| \leq d+\delta\} \cap A$. Clearly $S$ is bounded. It is also closed, being the intersection of two closed sets. Because the function $f(x)=|x-x_0|$ is continuous, it will attain its minimum value over $S$. So there exists an $x_1 \in A$ s.t. $|x_1-x_0| \leq |x-x_0|$  for all $x\in A$ with $|x-x_0| \leq d+\delta$. But this means that $d \leq |x_1-x_0| \leq d + \delta$ for an arbitrary $\delta$. Hence, $|x_1-x_0|=d=\inf_{x \in A}|x-x_0|$. Please tell me if this is correct, specially the last line about which I have doubts.",,"['real-analysis', 'multivariable-calculus']"
76,Trouble setting up double integrals,Trouble setting up double integrals,,"I am studying for an entrance exam and have troubles to set up double integrals appropriately. Actually my biggest problem is that I don't get the notation. $$ A = \{(x,y) | 0 \leq x + y \leq 1,  0 \leq x-y \leq \pi\} $$ $$ \iint_A e^{x+y} \sin(x-y)\mathrm dx\mathrm dy $$ and for another example: $$ R = \{(x,y) | 1 \leq x^2 + y^2 \leq 4,  y \geq 0\} $$ $$ \iint_R \frac{\mathrm dx\mathrm dy}{(x^2+y^2)^2} $$ Normally I would go draw a picture of something like a line or circle. When I have an equation like $x+y=z$ for example. I tried interpreting the inequality as an area so for the first one I came up with the between 0 and the line $y=1-x$ which seemed reasonable for I failed to connect this to the other inequality. I hope somebody can point out how to set this up or give some hints how to interpret this notation. Any help is greatly appreciated!","I am studying for an entrance exam and have troubles to set up double integrals appropriately. Actually my biggest problem is that I don't get the notation. $$ A = \{(x,y) | 0 \leq x + y \leq 1,  0 \leq x-y \leq \pi\} $$ $$ \iint_A e^{x+y} \sin(x-y)\mathrm dx\mathrm dy $$ and for another example: $$ R = \{(x,y) | 1 \leq x^2 + y^2 \leq 4,  y \geq 0\} $$ $$ \iint_R \frac{\mathrm dx\mathrm dy}{(x^2+y^2)^2} $$ Normally I would go draw a picture of something like a line or circle. When I have an equation like $x+y=z$ for example. I tried interpreting the inequality as an area so for the first one I came up with the between 0 and the line $y=1-x$ which seemed reasonable for I failed to connect this to the other inequality. I hope somebody can point out how to set this up or give some hints how to interpret this notation. Any help is greatly appreciated!",,"['calculus', 'integration', 'multivariable-calculus', 'definite-integrals', 'analytic-geometry']"
77,Flux calculation - what did I do wrong?,Flux calculation - what did I do wrong?,,"The exercise asks to calculate the flux of $\mathbf{F}=(4x,4y,z^2)$ through the surface $x^2+y^2=25, 0\le z \le 2$ I calculated using Gauss' theorem and  I obtained $500\pi$ , which is, as the teacher says, the correct answer. The exercise also asks to calculate it as $$\iint_S \mathbf{F}·d\mathbf{S}=\iint_S\mathbf{F}(\mathbf{S})·\mathbf{n}\ dS$$ Using cylindrical coordinates: $\mathbf{S}=(5\cos\theta, 5\sin\theta, z), \theta \in [0,2\pi], z \in [0, 2]$ And $\mathbf{F}(\mathbf{S})=(20\cos\theta, 20\sin\theta, z^2)$ And the unitary normal vector of the surface is $\mathbf{n}= \frac{\mathbf{S}_\theta \times \mathbf{S}_z}{\lVert \mathbf{S}_\theta \times \mathbf{S}_z \rVert}=(5\cos\theta,5\sin\theta,0)$ And $dS=5d\theta dz$ So $$\iint_S \mathbf{F}·d\mathbf{S}=\int_0^{2\pi} \int_0^2(20\cos^2(\theta)+20\sin^2(\theta))5dzd\theta=400\pi\neq500\pi$$ What did I do wrong?","The exercise asks to calculate the flux of through the surface I calculated using Gauss' theorem and  I obtained , which is, as the teacher says, the correct answer. The exercise also asks to calculate it as Using cylindrical coordinates: And And the unitary normal vector of the surface is And So What did I do wrong?","\mathbf{F}=(4x,4y,z^2) x^2+y^2=25, 0\le z \le 2 500\pi \iint_S \mathbf{F}·d\mathbf{S}=\iint_S\mathbf{F}(\mathbf{S})·\mathbf{n}\ dS \mathbf{S}=(5\cos\theta, 5\sin\theta, z), \theta \in [0,2\pi], z \in [0, 2] \mathbf{F}(\mathbf{S})=(20\cos\theta, 20\sin\theta, z^2) \mathbf{n}= \frac{\mathbf{S}_\theta \times \mathbf{S}_z}{\lVert \mathbf{S}_\theta \times \mathbf{S}_z \rVert}=(5\cos\theta,5\sin\theta,0) dS=5d\theta dz \iint_S \mathbf{F}·d\mathbf{S}=\int_0^{2\pi} \int_0^2(20\cos^2(\theta)+20\sin^2(\theta))5dzd\theta=400\pi\neq500\pi","['integration', 'multivariable-calculus', 'definite-integrals', 'divergence-theorem']"
78,Contradiction (or mistake) in $\displaystyle \iint x^y ~ dx ~ dy$,Contradiction (or mistake) in,\displaystyle \iint x^y ~ dx ~ dy,"I came across this double integral at an Instagram post and I tried to solve it. The integral in question is the following: $$I = \iint x^y ~ dx ~ dy$$ So, I begun by calculating the inner integral first getting: $$\int x^y ~ dx = \frac{{x}^{y+1}}{y+1} + c_1$$ Then I have to integrate this with respect to $\displaystyle y$ : $$\int \frac{{x}^{y+1}}{y+1} + c_1 ~ dy = \int \frac{{x}^{y+1}}{y+1} ~ dy + \int c_1 ~ dy = \int \frac{{x}^{y+1}}{y+1} ~ dy + {c}_{1}y$$ I figured I'd solve the first integral with integration by parts using this formula: $$\int u ~ dv = uv - \int v ~ du$$ $$u = {x}^{y+1}$$ $$du = {x}^{y+1} \ln(x) ~ dy$$ $$dv = \frac{1}{y+1} ~ dy$$ $$v = \ln \bigl( |x+1| \bigl)$$ Plugging all this back to the formula I get: $$\int \frac{{x}^{y+1}}{y+1} ~ dy = {x}^{y+1} \ln \bigl( |x+1| \bigl) ~ - \int \ln \bigl( |x+1| \bigl) {x}^{y+1} \ln(x) ~ dy = {x}^{y+1} \ln \bigl( |x+1| \bigl) ~ - {x}^{y+1} \ln \bigl( |x+1| \bigl) ~ + c_2 = c_2$$ Therefore I get the answer to the original integral to be: $$I = \iint x^y ~ dx ~ dy = {c}_{1}y + c_2$$ This did seem odd and I used Wolfram Alpha to check my answer. Acccording to Wolfram the correct answer is: $$I = \iint x^y ~ dx ~ dy = \text{Ei}\bigl( (y+1) \ln(x) \bigl) ~ + {c}_{1}x + c_2$$ Ei is supposed to be the exponensial integral: $$\text{Ei}(x) = - \int_{-x}^{\infty} \frac{{e}^{-t}}{t} ~ dt$$ I did some research on this and I figured out that Wolfram (and some other sites) solve this integral using u-substitution. So my question is, did I do something wrong in the calculation process or is integration by parts prohibited in this integral and if so why?. Also, I noticed that the first constant is multiplied with x instead of y even if the integral is with respect to y, which is weird.","I came across this double integral at an Instagram post and I tried to solve it. The integral in question is the following: So, I begun by calculating the inner integral first getting: Then I have to integrate this with respect to : I figured I'd solve the first integral with integration by parts using this formula: Plugging all this back to the formula I get: Therefore I get the answer to the original integral to be: This did seem odd and I used Wolfram Alpha to check my answer. Acccording to Wolfram the correct answer is: Ei is supposed to be the exponensial integral: I did some research on this and I figured out that Wolfram (and some other sites) solve this integral using u-substitution. So my question is, did I do something wrong in the calculation process or is integration by parts prohibited in this integral and if so why?. Also, I noticed that the first constant is multiplied with x instead of y even if the integral is with respect to y, which is weird.",I = \iint x^y ~ dx ~ dy \int x^y ~ dx = \frac{{x}^{y+1}}{y+1} + c_1 \displaystyle y \int \frac{{x}^{y+1}}{y+1} + c_1 ~ dy = \int \frac{{x}^{y+1}}{y+1} ~ dy + \int c_1 ~ dy = \int \frac{{x}^{y+1}}{y+1} ~ dy + {c}_{1}y \int u ~ dv = uv - \int v ~ du u = {x}^{y+1} du = {x}^{y+1} \ln(x) ~ dy dv = \frac{1}{y+1} ~ dy v = \ln \bigl( |x+1| \bigl) \int \frac{{x}^{y+1}}{y+1} ~ dy = {x}^{y+1} \ln \bigl( |x+1| \bigl) ~ - \int \ln \bigl( |x+1| \bigl) {x}^{y+1} \ln(x) ~ dy = {x}^{y+1} \ln \bigl( |x+1| \bigl) ~ - {x}^{y+1} \ln \bigl( |x+1| \bigl) ~ + c_2 = c_2 I = \iint x^y ~ dx ~ dy = {c}_{1}y + c_2 I = \iint x^y ~ dx ~ dy = \text{Ei}\bigl( (y+1) \ln(x) \bigl) ~ + {c}_{1}x + c_2 \text{Ei}(x) = - \int_{-x}^{\infty} \frac{{e}^{-t}}{t} ~ dt,"['calculus', 'integration', 'multivariable-calculus', 'solution-verification', 'indefinite-integrals']"
79,Find the volume by using triple integral,Find the volume by using triple integral,,"Calculate the volume of the contents of the bowl $K$ , which is given by $x^2 + y^2 \leq z \leq 1$ . $$x^2+y^2\leq z\leq 1$$ $$x^2+y^2=1\iff y=\pm\sqrt{1-x^2}$$ $$-1\leq x\leq 1$$ $$-\sqrt{1-x^2}\leq y\leq\sqrt{1-x^2}$$ $$\iiint 1~\mathrm{d}x~\mathrm{d}y~\mathrm{d}z=\iint\left(\biggl[z\biggr]_{x^2+y^2}^y\right)~\mathrm{d}x~\mathrm{d}y=\iint\left(-x^2+y^2)~\mathrm{d}y\right)~\mathrm{d}x=\int\biggl[y-yx^2+\frac{y^3}{3}\biggr]_{-\sqrt{1-x^2}}^{\sqrt{1-x^2}}=\int\left(\sqrt{1-x^2}-\sqrt{1-x^2}x^2+\frac{\sqrt{1-x^2}^3}{3}\right)-\left(-\sqrt{1-x^2}+\sqrt{1-x^2}x^2-\frac{\sqrt{1-x^2}^3}{3}\right)=\int_{-1}^12\sqrt{1-x^2}~\mathrm{d}x-\int_{-1}^12\sqrt{1-x^2}x^2+\int_{-1}^1\frac{\sqrt{1-x^2}}{3}$$ I don't know if I did right so far but as you can see I got something that is kinda hard to integrate and I'm pretty sure I wasn't meant to solve it this way so can someone please explain?","Calculate the volume of the contents of the bowl , which is given by . I don't know if I did right so far but as you can see I got something that is kinda hard to integrate and I'm pretty sure I wasn't meant to solve it this way so can someone please explain?",K x^2 + y^2 \leq z \leq 1 x^2+y^2\leq z\leq 1 x^2+y^2=1\iff y=\pm\sqrt{1-x^2} -1\leq x\leq 1 -\sqrt{1-x^2}\leq y\leq\sqrt{1-x^2} \iiint 1~\mathrm{d}x~\mathrm{d}y~\mathrm{d}z=\iint\left(\biggl[z\biggr]_{x^2+y^2}^y\right)~\mathrm{d}x~\mathrm{d}y=\iint\left(-x^2+y^2)~\mathrm{d}y\right)~\mathrm{d}x=\int\biggl[y-yx^2+\frac{y^3}{3}\biggr]_{-\sqrt{1-x^2}}^{\sqrt{1-x^2}}=\int\left(\sqrt{1-x^2}-\sqrt{1-x^2}x^2+\frac{\sqrt{1-x^2}^3}{3}\right)-\left(-\sqrt{1-x^2}+\sqrt{1-x^2}x^2-\frac{\sqrt{1-x^2}^3}{3}\right)=\int_{-1}^12\sqrt{1-x^2}~\mathrm{d}x-\int_{-1}^12\sqrt{1-x^2}x^2+\int_{-1}^1\frac{\sqrt{1-x^2}}{3},"['calculus', 'integration', 'multivariable-calculus', 'definite-integrals', 'partial-derivative']"
80,"Directional derivative zero, minimum and convexity","Directional derivative zero, minimum and convexity",,"Let $f:\mathbb R^n \to \mathbb R$ be convex, let $u\in \mathbb R^n$ , $v\in \mathbb R^n\setminus \{0\}$ and assume that the directional derivative of $f$ at $u$ in direction $v$ is $0$ . I'm wondering if this implies that $f$ has a global minimum at $x$ . The function $g:\mathbb R\to \mathbb R, t\mapsto f(x+tv)$ is convex and its right-derivative at $0$ is zero, hence $g$ has a global minimum at $0$ , thus $f$ is minimized at $x$ when restricted along direction $v$ . I don't see a reason why $x$ should be a global minimizer. Can someone provide a counterexample ?","Let be convex, let , and assume that the directional derivative of at in direction is . I'm wondering if this implies that has a global minimum at . The function is convex and its right-derivative at is zero, hence has a global minimum at , thus is minimized at when restricted along direction . I don't see a reason why should be a global minimizer. Can someone provide a counterexample ?","f:\mathbb R^n \to \mathbb R u\in \mathbb R^n v\in \mathbb R^n\setminus \{0\} f u v 0 f x g:\mathbb R\to \mathbb R, t\mapsto f(x+tv) 0 g 0 f x v x","['multivariable-calculus', 'convex-analysis', 'convex-optimization', 'examples-counterexamples']"
81,Why do we need wedge product for $dxdy$ to polar coordinates when $dx$ and $dy$ are perpendicular to each other?,Why do we need wedge product for  to polar coordinates when  and  are perpendicular to each other?,dxdy dx dy,"Why can't we convert $dx$ and $dy$ to polar and straight out multiply the answer to get the area element? By multiply I mean, taking x=rcos(theta) and y=… and then taking differentials dx and dy and multiplying them. Answers here point out that wedge is supposed to be used but this is just a rectangle so do we still need it and why? Thank you.","Why can't we convert and to polar and straight out multiply the answer to get the area element? By multiply I mean, taking x=rcos(theta) and y=… and then taking differentials dx and dy and multiplying them. Answers here point out that wedge is supposed to be used but this is just a rectangle so do we still need it and why? Thank you.",dx dy,"['multivariable-calculus', 'differential-geometry', 'coordinate-systems', 'exterior-algebra']"
82,Solve double integral $\iint_E\frac{1 + x}{1 + 2x^2 + 3y^2} dA$ ellipstic area $E$,Solve double integral  ellipstic area,\iint_E\frac{1 + x}{1 + 2x^2 + 3y^2} dA E,"I am trying to solve the integral $$\iint_E\frac{1 + x}{1 + 2x^2 + 3y^2} dA$$ where E is the elliptical area given by $$2x^2 + 3y^2\leq 6$$ I have tried substitution with $(x, y)\mapsto(\sqrt{3} r\cos\theta, \sqrt{2}r\sin\theta)$ , where the new ranges are $r\in [0, 1]$ and $\theta\in [0, 2\pi]$ . Then I substitute that into the integral and solve it with the new limits. Is this the right way to go? I get an answer of $\pi\ln 7$ and that seems a bit weird but I am pretty unsure. Can someone guide me in the right direction in this problem? Thanks!","I am trying to solve the integral where E is the elliptical area given by I have tried substitution with , where the new ranges are and . Then I substitute that into the integral and solve it with the new limits. Is this the right way to go? I get an answer of and that seems a bit weird but I am pretty unsure. Can someone guide me in the right direction in this problem? Thanks!","\iint_E\frac{1 + x}{1 + 2x^2 + 3y^2} dA 2x^2 + 3y^2\leq 6 (x, y)\mapsto(\sqrt{3} r\cos\theta, \sqrt{2}r\sin\theta) r\in [0, 1] \theta\in [0, 2\pi] \pi\ln 7","['calculus', 'integration', 'multivariable-calculus', 'elliptic-equations']"
83,"$ \int_{[0,1]^n} \min(x_1,\ldots,x_n) \, dx_1\cdots dx_n $",," \int_{[0,1]^n} \min(x_1,\ldots,x_n) \, dx_1\cdots dx_n ","I need to compute: $$ \int_{[0,1]^n} \min(x_1,\ldots,x_n) \, dx_1\cdots dx_n $$ I have shown that: $$\int _{0}^{1} \min( x_{k} ,\dots,x_{n})^{m} dx_{k} = \min( x_{k+1} ,\dots,x_{n})^{m} -\frac{m}{m+1} \min( x_{k+1} ,\dots,x_{n})^{m+1}$$ and tried to do it recursively: $ \begin{array}{l} \int _{0}^{1} ...\int _{0}^{1} \min( x_{1} ,...,x_{n}) dx_{1} ...dx_{n} =\int _{0}^{1} ...\int _{0}^{1} \min( x_{2} ,...,x_{n}) -\frac{1}{2} \min( x_{2} ,...,x_{n})^{2} dx_{2} ...dx_{n} =\\ =\int _{0}^{1} ...\int _{0}^{1} \min( x_{3} ,...,x_{n}) -\frac{2}{2}  \min( x_{3} ,...,x_{n})^{2} +\frac{1}{3} \min( x_{3} ,...,x_{n})^{3} dx_{3} ...dx_{n} = \end{array}$ but I don't see how I can get something from this. Can anyone help?",I need to compute: I have shown that: and tried to do it recursively: but I don't see how I can get something from this. Can anyone help?," \int_{[0,1]^n} \min(x_1,\ldots,x_n) \, dx_1\cdots dx_n  \int _{0}^{1} \min( x_{k} ,\dots,x_{n})^{m} dx_{k} = \min( x_{k+1} ,\dots,x_{n})^{m} -\frac{m}{m+1} \min( x_{k+1} ,\dots,x_{n})^{m+1}  \begin{array}{l}
\int _{0}^{1} ...\int _{0}^{1} \min( x_{1} ,...,x_{n}) dx_{1} ...dx_{n} =\int _{0}^{1} ...\int _{0}^{1} \min( x_{2} ,...,x_{n}) -\frac{1}{2} \min( x_{2} ,...,x_{n})^{2} dx_{2} ...dx_{n} =\\
=\int _{0}^{1} ...\int _{0}^{1} \min( x_{3} ,...,x_{n}) -\frac{2}{2}  \min( x_{3} ,...,x_{n})^{2} +\frac{1}{3} \min( x_{3} ,...,x_{n})^{3} dx_{3} ...dx_{n} =
\end{array}","['multivariable-calculus', 'multiple-integral']"
84,Line integral of non conservative vector field,Line integral of non conservative vector field,,"I'm having trouble finding the line integral of this problem. I have been given a vector field $F=(2x\sin(\pi y)-e^z,\pi x^2\cos(\pi y)-3e^z,-xe^z)$ Where the curve $C$ intercepts between $z=\ln(1+x)$ and $y=x$ from $(0,0,0)$ to $(1,1,\ln(2)$ . So I try to do this by solving with: $\int_{C}^{} F \cdot dr$ I started of by determining conservativity and it is non conservative, $\frac{\partial f_1}{\partial y} = \frac{\partial f_2}{\partial x}=2x\pi \cos(\pi y)$ $\frac{\partial f_1}{\partial z} = \frac{\partial f_3}{\partial x}=-e^z$ $-3e^z=\frac{\partial f_2}{\partial z} \ne \frac{\partial f_3}{\partial y}=0$ Next I found the vector function by using the two coordinats $(0,0,0)$ & $(1,1,\ln(2)$ , $r(t)=(t)\hat{i}+(t)\hat{j}+(\ln(2)t)\hat{k}$ From this vector function we could say that, $x=t$ , $y=t$ & $z=\ln(2)t$ Now usually I believe I should substitute $(x,y,z)$ into $F$ and then take the dot product between $F$ and $r'(t)$ . But I'm not sure this correct, because I also have to take $z=\ln(1+x)$ and $y=x$ into consideration. So now I'm stuck on how to proceed. What am I supposed to do with $z=\ln(1+x)$ and $y=x$ ? And is it even the correct approach to this problem?","I'm having trouble finding the line integral of this problem. I have been given a vector field Where the curve intercepts between and from to . So I try to do this by solving with: I started of by determining conservativity and it is non conservative, Next I found the vector function by using the two coordinats & , From this vector function we could say that, , & Now usually I believe I should substitute into and then take the dot product between and . But I'm not sure this correct, because I also have to take and into consideration. So now I'm stuck on how to proceed. What am I supposed to do with and ? And is it even the correct approach to this problem?","F=(2x\sin(\pi y)-e^z,\pi x^2\cos(\pi y)-3e^z,-xe^z) C z=\ln(1+x) y=x (0,0,0) (1,1,\ln(2) \int_{C}^{} F \cdot dr \frac{\partial f_1}{\partial y} = \frac{\partial f_2}{\partial x}=2x\pi \cos(\pi y) \frac{\partial f_1}{\partial z} = \frac{\partial f_3}{\partial x}=-e^z -3e^z=\frac{\partial f_2}{\partial z} \ne \frac{\partial f_3}{\partial y}=0 (0,0,0) (1,1,\ln(2) r(t)=(t)\hat{i}+(t)\hat{j}+(\ln(2)t)\hat{k} x=t y=t z=\ln(2)t (x,y,z) F F r'(t) z=\ln(1+x) y=x z=\ln(1+x) y=x","['calculus', 'multivariable-calculus', 'vector-fields', 'line-integrals']"
85,"$\iiint_M (x+y+z)\,dx\,dy\,dz$ over $M=\{(x,y,z)\in\mathbb{R^3}: 0≤z≤(x^2+y^2)^2≤81\}$",over,"\iiint_M (x+y+z)\,dx\,dy\,dz M=\{(x,y,z)\in\mathbb{R^3}: 0≤z≤(x^2+y^2)^2≤81\}","$$\iiint_M (x+y+z)\,dx\,dy\,dz$$ over $M=\{(x,y,z)\in\mathbb{R^3}: 0≤z≤(x^2+y^2)^2≤81\}$ . How would I express this with the correct bounds? Once I have the bounds I can continue on my own but I need the bounds, since this is the very first time encountering this type of boundering with the $M$ . Any hints about the change of bounds would really help.","over . How would I express this with the correct bounds? Once I have the bounds I can continue on my own but I need the bounds, since this is the very first time encountering this type of boundering with the . Any hints about the change of bounds would really help.","\iiint_M (x+y+z)\,dx\,dy\,dz M=\{(x,y,z)\in\mathbb{R^3}: 0≤z≤(x^2+y^2)^2≤81\} M","['real-analysis', 'multivariable-calculus', 'definite-integrals', 'multiple-integral', 'bounds-of-integration']"
86,"Intuitively, we expect a level set in $\mathbb{R}^3$ to be a $2$-dimensional surface. Why?","Intuitively, we expect a level set in  to be a -dimensional surface. Why?",\mathbb{R}^3 2,"I am watching a lecture about multivariable mathematics (Math 3500 Day 20: Continuity and Preimages) by Prof. Theodore Shifrin. Let $f:\mathbb{R}^3\to\mathbb{R}$ be a function. Let $c\in\mathbb{R}$ be a real number. Suppose that $\{x\in\mathbb{R}^3 | f(x)=c\}\neq\emptyset$ . Intuitively, we expect the set $\{x\in\mathbb{R}^3 | f(x)=c\}$ to be a $2$ -dimensional surface. (1) Why do we expect this set $\{x\in\mathbb{R}^3 | f(x)=c\}$ is $2$ -dimensional? For example, if $f(x) = c$ for all $x\in\mathbb{R}^3$ , then the set $\{x\in\mathbb{R}^3 | f(x)=c\}$ is $\mathbb{R}^3$ , which is not a $2$ -dimensional surface. But we don't think this is a typical case. (2) For what $f:\mathbb{R}^3\to\mathbb{R}$ , is the set $\{x\in\mathbb{R}^3 | f(x)=c\}$ $2$ -dimensional? (3) I don't know the definition that a subset of $\mathbb{R}^3$ is $2$ -dimensional. What book should I read?","I am watching a lecture about multivariable mathematics (Math 3500 Day 20: Continuity and Preimages) by Prof. Theodore Shifrin. Let be a function. Let be a real number. Suppose that . Intuitively, we expect the set to be a -dimensional surface. (1) Why do we expect this set is -dimensional? For example, if for all , then the set is , which is not a -dimensional surface. But we don't think this is a typical case. (2) For what , is the set -dimensional? (3) I don't know the definition that a subset of is -dimensional. What book should I read?",f:\mathbb{R}^3\to\mathbb{R} c\in\mathbb{R} \{x\in\mathbb{R}^3 | f(x)=c\}\neq\emptyset \{x\in\mathbb{R}^3 | f(x)=c\} 2 \{x\in\mathbb{R}^3 | f(x)=c\} 2 f(x) = c x\in\mathbb{R}^3 \{x\in\mathbb{R}^3 | f(x)=c\} \mathbb{R}^3 2 f:\mathbb{R}^3\to\mathbb{R} \{x\in\mathbb{R}^3 | f(x)=c\} 2 \mathbb{R}^3 2,"['multivariable-calculus', 'definition', 'surfaces']"
87,"How to prove that the limit of $f(x,y)=\dfrac{x^2 \sin(y) + y^2 \sin(x)}{x^2+y^2}$ is $0$ as $(x,y)$ approaches $(0,0)$?",How to prove that the limit of  is  as  approaches ?,"f(x,y)=\dfrac{x^2 \sin(y) + y^2 \sin(x)}{x^2+y^2} 0 (x,y) (0,0)","I need to show that $\displaystyle\lim_{(x,y)\rightarrow(0,0)}\dfrac{x^2 \sin(y) + y^2 \sin(x)}{x^2+y^2}$ exists. I know that it is equal to zero. Until now, all I know how to do is to prove using the $\epsilon-\delta$ definition. I tried to prove it by the following way: Let $\delta>0$ be a real number such that $0<\sqrt{x^2+y^2}<\delta$ . We have $0< x^2+y^2<\delta^2$ . We know that $\left\vert x^2\sin(y)+y^2\sin(x)\right\vert\leq\left\vert x^2\sin(y)\right\vert+\left\vert y^2\sin(x)\right\vert=x^2\left\vert\sin(y)\right\vert+y^2\left\vert\sin(x)\right\vert\leq x^2+y^2$ . Thus $$0<\left\vert x^2\sin(y)+y^2\sin(x)\right\vert\leq x^2+y^2<\delta^2$$ and dividing the inequality by $x^2+y^2>0$ we have $$ 0<\dfrac{\left\vert x^2\sin(y)+y^2\sin(x)\right\vert}{x^2+y^2}<1<\dfrac{\delta^2}{x^2+y^2}. $$ I thought that this could be useful because $\dfrac{\left\vert x^2\sin(y)+y^2\sin(x)\right\vert}{x^2+y^2}=\left\vert\dfrac{x^2\sin(y)+y^2\sin(x)}{x^2+y^2}\right\vert$ , but I don't know how to proceed.","I need to show that exists. I know that it is equal to zero. Until now, all I know how to do is to prove using the definition. I tried to prove it by the following way: Let be a real number such that . We have . We know that . Thus and dividing the inequality by we have I thought that this could be useful because , but I don't know how to proceed.","\displaystyle\lim_{(x,y)\rightarrow(0,0)}\dfrac{x^2 \sin(y) + y^2 \sin(x)}{x^2+y^2} \epsilon-\delta \delta>0 0<\sqrt{x^2+y^2}<\delta 0< x^2+y^2<\delta^2 \left\vert x^2\sin(y)+y^2\sin(x)\right\vert\leq\left\vert x^2\sin(y)\right\vert+\left\vert y^2\sin(x)\right\vert=x^2\left\vert\sin(y)\right\vert+y^2\left\vert\sin(x)\right\vert\leq x^2+y^2 0<\left\vert x^2\sin(y)+y^2\sin(x)\right\vert\leq x^2+y^2<\delta^2 x^2+y^2>0  0<\dfrac{\left\vert x^2\sin(y)+y^2\sin(x)\right\vert}{x^2+y^2}<1<\dfrac{\delta^2}{x^2+y^2}.  \dfrac{\left\vert x^2\sin(y)+y^2\sin(x)\right\vert}{x^2+y^2}=\left\vert\dfrac{x^2\sin(y)+y^2\sin(x)}{x^2+y^2}\right\vert","['multivariable-calculus', 'epsilon-delta']"
88,Compute $\iiint x+y+z$ over the region inside $x^2+y^2+z^2 \le 1$ in the fist octant,Compute  over the region inside  in the fist octant,\iiint x+y+z x^2+y^2+z^2 \le 1,"I feel this should be an easy question, but I seem to be struggling with it. So, I started by finding my bounds of integration. In this case, I get $0 \le x \le 1$ , $0 \le y \le \sqrt{1-x^2}$ and $0 \le z \le \sqrt{1-x^2-y^2}$ . Then, upon integrating, I get: \begin{align} = {} & \int_0^1 \int_0^{\sqrt{1-x^2}}\int_0^{\sqrt{1-x^2-y^2}}(x+y+z) \, dz \, dy \, dx \\[8pt] = {} &  \int_0^1 \int_0^{\sqrt{1-x^2}}(\sqrt{1-x^2-y^2})(x+y) - \frac{1-x^2-y^2}{2} \, dy \, dx \end{align} From here the integration got pretty hairy, and using an online calculator the next inner integral with respect to $y$ resulted in imaginary numbers, which seems way too complex for a final answer of $\frac{3\pi}{16}$ . My guess is my bounds of integration are wrong, but I'm not sure why or what the right ones should be. Thanks!","I feel this should be an easy question, but I seem to be struggling with it. So, I started by finding my bounds of integration. In this case, I get , and . Then, upon integrating, I get: From here the integration got pretty hairy, and using an online calculator the next inner integral with respect to resulted in imaginary numbers, which seems way too complex for a final answer of . My guess is my bounds of integration are wrong, but I'm not sure why or what the right ones should be. Thanks!","0 \le x \le 1 0 \le y \le \sqrt{1-x^2} 0 \le z \le \sqrt{1-x^2-y^2} \begin{align}
= {} & \int_0^1 \int_0^{\sqrt{1-x^2}}\int_0^{\sqrt{1-x^2-y^2}}(x+y+z) \, dz \, dy \, dx \\[8pt]
= {} &  \int_0^1 \int_0^{\sqrt{1-x^2}}(\sqrt{1-x^2-y^2})(x+y) - \frac{1-x^2-y^2}{2} \, dy \, dx
\end{align} y \frac{3\pi}{16}","['integration', 'multivariable-calculus', 'multiple-integral']"
89,Where is the mistake here (proof of the dot product),Where is the mistake here (proof of the dot product),,"Consider two vectors $\vec{u},\vec{v}$ in $\mathbb R^n$ , if we sum up those two vectors we will get a parallelogram with sides length $\vec{u},\vec{v}$ . And in this parallelogram we have two triangles With sides length $\vec{u},\vec{v}, \vec{u}+\vec{v}$ . By the law of cosine : $$\| \vec{u}+\vec{v} \|^2= \|\vec{u}\|^2+\|\vec{v}\|^2-2 \|\vec{u}\|\|\vec{v}\|\cos(\theta) $$ Where $\theta$ Is the angle between $\vec{u}+\vec{v}$ $$(\vec{u}+\vec{v})(\vec{u}+\vec{v})= \vec{u}\cdot\vec{u}+ \vec{v}\cdot\vec{v} -2 \|\vec{u}\|\|\vec{v}\|\cos(\theta)  $$ $$2 \vec{u}\cdot\vec{v}=-2 \|\vec{u}\|\|\vec{v}\|\cos(\theta)  $$ And then $$\vec{u}\cdot\vec{v}=-\|\vec{u}\|\|\vec{v}\|\cos(\theta)  $$ What is that? I’m sure that the formula of dot product with no minus sign, i’ve checked the proof a lot of times but i didn’t found any mistake, can you tell me  where is it? Here’s a quick picture :","Consider two vectors in , if we sum up those two vectors we will get a parallelogram with sides length . And in this parallelogram we have two triangles With sides length . By the law of cosine : Where Is the angle between And then What is that? I’m sure that the formula of dot product with no minus sign, i’ve checked the proof a lot of times but i didn’t found any mistake, can you tell me  where is it? Here’s a quick picture :","\vec{u},\vec{v} \mathbb R^n \vec{u},\vec{v} \vec{u},\vec{v}, \vec{u}+\vec{v} \| \vec{u}+\vec{v} \|^2= \|\vec{u}\|^2+\|\vec{v}\|^2-2 \|\vec{u}\|\|\vec{v}\|\cos(\theta)  \theta \vec{u}+\vec{v} (\vec{u}+\vec{v})(\vec{u}+\vec{v})= \vec{u}\cdot\vec{u}+ \vec{v}\cdot\vec{v} -2 \|\vec{u}\|\|\vec{v}\|\cos(\theta)   2 \vec{u}\cdot\vec{v}=-2 \|\vec{u}\|\|\vec{v}\|\cos(\theta)   \vec{u}\cdot\vec{v}=-\|\vec{u}\|\|\vec{v}\|\cos(\theta)  ","['multivariable-calculus', 'vectors']"
90,"Validity of this particular ""Chain Rule""","Validity of this particular ""Chain Rule""",,"For two multivariable function $y(m,n)$ and $x(m,n)$ does it make sense / is it mathematically correct to talk of the following chain rules - $$\frac{dy}{dx}=\frac{\partial y}{\partial m}\frac{dm}{dx}+\frac{\partial y}{\partial n}\frac{dn}{dx}\tag{1}$$ and $$\frac{dx}{dy}=\frac{\partial x}{\partial m}\frac{dm}{dy}+\frac{\partial x}{\partial n}\frac{dn}{dy}\tag{2}$$ simultaneously , where m, n can be rewritten as $m=m(x,y),\,n=n(x,y)$ and $d/dx,\,d/dy$ of m, n exists. The context is this PhysicsSE question - if that is relevant. How correct/wrong is this ""Chain rule""? Any intuitive/geometric argument together with a mathematical proof, if possible, is highly appreciated.","For two multivariable function and does it make sense / is it mathematically correct to talk of the following chain rules - and simultaneously , where m, n can be rewritten as and of m, n exists. The context is this PhysicsSE question - if that is relevant. How correct/wrong is this ""Chain rule""? Any intuitive/geometric argument together with a mathematical proof, if possible, is highly appreciated.","y(m,n) x(m,n) \frac{dy}{dx}=\frac{\partial y}{\partial m}\frac{dm}{dx}+\frac{\partial y}{\partial n}\frac{dn}{dx}\tag{1} \frac{dx}{dy}=\frac{\partial x}{\partial m}\frac{dm}{dy}+\frac{\partial x}{\partial n}\frac{dn}{dy}\tag{2} m=m(x,y),\,n=n(x,y) d/dx,\,d/dy","['multivariable-calculus', 'differential-geometry', 'chain-rule']"
91,"$\lim_{(x,y,z) \to (0,0,0)} \frac{xyz}{x^2+y^2+z^2}=0$",,"\lim_{(x,y,z) \to (0,0,0)} \frac{xyz}{x^2+y^2+z^2}=0","How to show that $$\lim_{(x,y,z) \to (0,0,0)} \frac{xyz}{x^2+y^2+z^2}=0,$$ where $x,y,z>0$ . My attempt: $$||(x,y,z)|| < \delta \implies |x|, |y|, |z| < \delta$$ $$\left | \frac{xyz}{x^2+y^2+z^2} \right | < \left | \frac{xyz}{x^2}\right | < \frac{\delta^3}{x^2}.$$ Now, I do not know how to proceed, and I think my attempt might be wrong.","How to show that where . My attempt: Now, I do not know how to proceed, and I think my attempt might be wrong.","\lim_{(x,y,z) \to (0,0,0)} \frac{xyz}{x^2+y^2+z^2}=0, x,y,z>0 ||(x,y,z)|| < \delta \implies |x|, |y|, |z| < \delta \left | \frac{xyz}{x^2+y^2+z^2} \right | < \left | \frac{xyz}{x^2}\right | < \frac{\delta^3}{x^2}.",['multivariable-calculus']
92,Intuition about Euler's Theorem on homogeneous equations,Intuition about Euler's Theorem on homogeneous equations,,"I wonder, what would be the intuition or motivation to studying Euler Formula for homogeneous function $f:\mathbb{R}^k \to \mathbb{R}$ such that $f(tx) = t^n f$ , for all $t>0$ . $\sum x_i \frac{\partial f}{\partial x_i} = n f$ I understand its proof and can do some problem but it feels really artificial or rather just manipulation process in doing such problems. Kindly share the intuition or importance of Euler theorem, or share the sources where I can read about it. It would be helpful for me. Thanks in advanced.","I wonder, what would be the intuition or motivation to studying Euler Formula for homogeneous function such that , for all . I understand its proof and can do some problem but it feels really artificial or rather just manipulation process in doing such problems. Kindly share the intuition or importance of Euler theorem, or share the sources where I can read about it. It would be helpful for me. Thanks in advanced.",f:\mathbb{R}^k \to \mathbb{R} f(tx) = t^n f t>0 \sum x_i \frac{\partial f}{\partial x_i} = n f,"['calculus', 'multivariable-calculus', 'intuition', 'homogeneous-equation', 'motivation']"
93,"Calculate the following integral $\iint_{T}\frac{x^2\sin(xy)}{y}\,dx\,dy$",Calculate the following integral,"\iint_{T}\frac{x^2\sin(xy)}{y}\,dx\,dy","Calculate the following integral $$\iint_{T}\frac{x^2\sin(xy)}{y}\,dx\,dy\,,$$ where $$T=\{(x,y)\in\mathbb{R}^2:x^2<y<2x^2,y^2<x<2y^2\}$$ I found the $1/2\leq x\leq 1,1/2\leq y\leq 1$ but i got stuck on how set the limits of the integral",Calculate the following integral where I found the but i got stuck on how set the limits of the integral,"\iint_{T}\frac{x^2\sin(xy)}{y}\,dx\,dy\,, T=\{(x,y)\in\mathbb{R}^2:x^2<y<2x^2,y^2<x<2y^2\} 1/2\leq x\leq 1,1/2\leq y\leq 1","['calculus', 'integration', 'multivariable-calculus', 'multiple-integral', 'fubini-tonelli-theorems']"
94,"Find the directional derivative of $x^2-xy-2y^2$ at $(1,2)$ along the vector that goes from this point to $(3,4)$",Find the directional derivative of  at  along the vector that goes from this point to,"x^2-xy-2y^2 (1,2) (3,4)","I used this formula (in blue, you have to scroll down a bit), and did this: $$\lim_{h \rightarrow 0} \frac{f(1+3h,2+4h)-f(1,2)}{h} = \\ \lim_{h\rightarrow 0}\frac{(1+3h)^2-(1+3h)(2+4h)-2(2+4h)^2+11}{h} = \\ \lim_{h\rightarrow 0} \frac{2-36h-35h^2}{h} = \lim_{h \rightarrow 0 } 2/h - 36 - 35h = \infty$$ What went wrong?","I used this formula (in blue, you have to scroll down a bit), and did this: What went wrong?","\lim_{h \rightarrow 0} \frac{f(1+3h,2+4h)-f(1,2)}{h} = \\
\lim_{h\rightarrow 0}\frac{(1+3h)^2-(1+3h)(2+4h)-2(2+4h)^2+11}{h} = \\
\lim_{h\rightarrow 0} \frac{2-36h-35h^2}{h} = \lim_{h \rightarrow 0 } 2/h - 36 - 35h = \infty","['calculus', 'multivariable-calculus']"
95,"Extreme on the multivariate function $f(x,y) = x^2+xy+y^2+y$",Extreme on the multivariate function,"f(x,y) = x^2+xy+y^2+y","Find the extreme of $$f(x,y) = x^2+xy+y^2+y$$ I think from what I learn on the function with two variables, we need to find the second derivatives to solve this kind of question. However, after I figured out both $f_x$ and $f_y$ , $$f_x=2x+y, f_y=x+2y+1$$ I am stuck on what I should do next since this function will have $f_{xx}$ , $f_{xy}$ , $f_{yx}$ , $f_{yy}$ , four second derivatives. Can someone lead me out?","Find the extreme of I think from what I learn on the function with two variables, we need to find the second derivatives to solve this kind of question. However, after I figured out both and , I am stuck on what I should do next since this function will have , , , , four second derivatives. Can someone lead me out?","f(x,y) = x^2+xy+y^2+y f_x f_y f_x=2x+y, f_y=x+2y+1 f_{xx} f_{xy} f_{yx} f_{yy}","['multivariable-calculus', 'optimization']"
96,Proof that derivative is the best linear approximation?,Proof that derivative is the best linear approximation?,,"I found this answer that stated the following theorem - Theorem: Let 𝑓 be a real valued function defined in a neighbourhood of point 𝑎 and continuous at 𝑎 and lets assume that it is approximated by a linear function 𝑔 given by 𝑔(𝑥)=𝐴𝑥+𝐵 in the neighbourhood of 𝑎. Then we say that 𝑔 is best linear approximation of 𝑓 in the neighbourhood of 𝑎 if the following equation holds : $$ \lim_{x\to a}  \frac{f(x)-g(x)}{x-a}=0$$ Such a linear approximation exists if and only if 𝑓′(𝑎) exists and moreover in that case we have 𝑔(𝑥)=𝑓(𝑎)+𝑓′(𝑎)(𝑥−𝑎). This answer also uses this theorem to prove that the derivative is truly the best linear approximation. More like this is the 'sense' in which it is the best approximation. After researching online I found that the idea seems to be that the derivative is the only linear approximation for which the approximation error tends to $0$ faster than $𝑥-𝑎$ as $𝑥→𝑎$ , and based on this we call it the best approximation. My question is, how does this actually prove that the derivative will beat any other linear approximation? How does it formally (if possible intuitively also) prove that the derivative is better than all the other approximations.","I found this answer that stated the following theorem - Theorem: Let 𝑓 be a real valued function defined in a neighbourhood of point 𝑎 and continuous at 𝑎 and lets assume that it is approximated by a linear function 𝑔 given by 𝑔(𝑥)=𝐴𝑥+𝐵 in the neighbourhood of 𝑎. Then we say that 𝑔 is best linear approximation of 𝑓 in the neighbourhood of 𝑎 if the following equation holds : Such a linear approximation exists if and only if 𝑓′(𝑎) exists and moreover in that case we have 𝑔(𝑥)=𝑓(𝑎)+𝑓′(𝑎)(𝑥−𝑎). This answer also uses this theorem to prove that the derivative is truly the best linear approximation. More like this is the 'sense' in which it is the best approximation. After researching online I found that the idea seems to be that the derivative is the only linear approximation for which the approximation error tends to faster than as , and based on this we call it the best approximation. My question is, how does this actually prove that the derivative will beat any other linear approximation? How does it formally (if possible intuitively also) prove that the derivative is better than all the other approximations.", \lim_{x\to a}  \frac{f(x)-g(x)}{x-a}=0 0 𝑥-𝑎 𝑥→𝑎,"['calculus', 'multivariable-calculus', 'derivatives', 'partial-derivative', 'linear-approximation']"
97,Domain of $\sqrt[4]{1-xy}$,Domain of,\sqrt[4]{1-xy},"I'm having hard time understanding the graph of the domain  (within $\mathbb{R}^2$ ) of the function $$\sqrt[4]{1-xy}$$ So that function exists under the condition $1-xy\ge0$ which leads to $xy\le1$ . So the domain of the function is $$Dom(f)=\{\forall(x,y)\in \mathbb{R}^2 | xy\le1\}$$ Which plots to I know how to graph a domain of a function, I'm having hard time understanding why the graph of $xy\le1$ is like the picture above.","I'm having hard time understanding the graph of the domain  (within ) of the function So that function exists under the condition which leads to . So the domain of the function is Which plots to I know how to graph a domain of a function, I'm having hard time understanding why the graph of is like the picture above.","\mathbb{R}^2 \sqrt[4]{1-xy} 1-xy\ge0 xy\le1 Dom(f)=\{\forall(x,y)\in \mathbb{R}^2 | xy\le1\} xy\le1",['multivariable-calculus']
98,Evaluate: $\left(\frac{\partial }{\partial x}+\frac{\partial }{\partial y}+\frac{\partial }{\partial z}\right)^2u$,Evaluate:,\left(\frac{\partial }{\partial x}+\frac{\partial }{\partial y}+\frac{\partial }{\partial z}\right)^2u,"If $u=\ln(x^3+y^3+z^3-3xyz)$ , show that $$\bigg(\dfrac{\partial }{\partial x}+\dfrac{\partial }{\partial y}+\dfrac{\partial }{\partial z}\bigg)^2u=\dfrac{-9}{(x+y+z)^2}$$ I don't know how to interpret $\bigg(\dfrac{\partial }{\partial x}+\dfrac{\partial }{\partial y}+\dfrac{\partial }{\partial z}\bigg)^2u$ . If $$\bigg(\dfrac{\partial }{\partial x}+\dfrac{\partial }{\partial y}+\dfrac{\partial }{\partial z}\bigg)^2u=\dfrac{\partial ^2u}{\partial x^2}+\dfrac{\partial ^2u}{\partial y^2}+\dfrac{\partial ^2u}{\partial z^2}+2\dfrac{\partial ^2u}{\partial x\partial y}+2\dfrac{\partial ^2u}{\partial y\partial z}+2\dfrac{\partial ^2u}{\partial z\partial x}$$ then is there any form of theory or properties regarding this, because I don't want to calculate every term and plug it into the giant expression. I also observe that I can made the given problem into the homogenous function of degree $3$ . Is that useful? Please help.","If , show that I don't know how to interpret . If then is there any form of theory or properties regarding this, because I don't want to calculate every term and plug it into the giant expression. I also observe that I can made the given problem into the homogenous function of degree . Is that useful? Please help.",u=\ln(x^3+y^3+z^3-3xyz) \bigg(\dfrac{\partial }{\partial x}+\dfrac{\partial }{\partial y}+\dfrac{\partial }{\partial z}\bigg)^2u=\dfrac{-9}{(x+y+z)^2} \bigg(\dfrac{\partial }{\partial x}+\dfrac{\partial }{\partial y}+\dfrac{\partial }{\partial z}\bigg)^2u \bigg(\dfrac{\partial }{\partial x}+\dfrac{\partial }{\partial y}+\dfrac{\partial }{\partial z}\bigg)^2u=\dfrac{\partial ^2u}{\partial x^2}+\dfrac{\partial ^2u}{\partial y^2}+\dfrac{\partial ^2u}{\partial z^2}+2\dfrac{\partial ^2u}{\partial x\partial y}+2\dfrac{\partial ^2u}{\partial y\partial z}+2\dfrac{\partial ^2u}{\partial z\partial x} 3,"['multivariable-calculus', 'logarithms', 'partial-derivative']"
99,Find absolute maxima and minima of a multivariable function in the domain D,Find absolute maxima and minima of a multivariable function in the domain D,,"I am trying to find the absolute maxima and minima of $ f(x,y) = 2x^3 + y^4$ in the domain $D = \{(x,y)| x^2 + y^2 \le 1 \}$ I have made an attempt as shown in attached picture. Please ignore dashed areas. Attached picture . The answer is (1,0) and (-1,0). I do NOT want to use the Lagrange multiplier method to solve. Is it legal to substitute $y^4 = (1-x^2)^2$ into $f(x,y)$ to make a single variable $f(x)$ and then find $f'(x) =0 $ ? Then, after finding the $x$ can I substitute into $x^2 +y^2 = 1$ to find y? Then can I plug it back into $f(x,y)$ to find critical points? I want to know how to find max and min on the boundary $x^2 + y^2 = 1$ without the LM method? Thanks for your help!","I am trying to find the absolute maxima and minima of in the domain I have made an attempt as shown in attached picture. Please ignore dashed areas. Attached picture . The answer is (1,0) and (-1,0). I do NOT want to use the Lagrange multiplier method to solve. Is it legal to substitute into to make a single variable and then find ? Then, after finding the can I substitute into to find y? Then can I plug it back into to find critical points? I want to know how to find max and min on the boundary without the LM method? Thanks for your help!"," f(x,y) = 2x^3 + y^4 D = \{(x,y)| x^2 + y^2 \le 1 \} y^4 = (1-x^2)^2 f(x,y) f(x) f'(x) =0  x x^2 +y^2 = 1 f(x,y) x^2 + y^2 = 1","['multivariable-calculus', 'partial-derivative']"
