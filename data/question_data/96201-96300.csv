,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Question on the proof $\int_0^\infty \frac{\sin(at)}{t}dt=\frac{\pi}{2} \operatorname{sgn}(a)$.,Question on the proof .,\int_0^\infty \frac{\sin(at)}{t}dt=\frac{\pi}{2} \operatorname{sgn}(a),"In my solution, for the proof of $$\int_0^\infty \frac{\sin(ax)}{x}dx=\frac{\pi}{2} \operatorname{sgn}(a),$$ they do as under. The only important thing is where the red square is (the rest is as usual). The says that $\sin(t)\geq \frac{t}{2}$ when $[0,\pi/6]$ and $\sin(t)\geq \frac{1}{2}$ when $t\in [\pi/6,\pi/2]$. But why don't the simply use the fact that $\sin(t)\geq \frac{t}{2}$ on $[0,\pi/2]$, what gives $$\int_0^{\pi/6}e^{-R\sin(t)}dt\leq \int_0^{\pi/2}e^{-Rt/2}dt=\frac{-2}{R}\left[e^{-Rt/2}\right]_{0}^{\pi/2}=\frac{-2}{R}(e^{-R\pi/4}-1)\underset{R\to \infty }{\longrightarrow }0.$$ Is there something I didn't get ? Because taking $\sin(t)\geq t/2$ for all $t\in [0,\pi/2]$ instead of taking $\sin(t)\geq t/2$ on $[0,\pi/6]$ and $\sin(t)\geq 1/2$ on $[\pi/6,\pi/2]$ looks to work great, no ?","In my solution, for the proof of $$\int_0^\infty \frac{\sin(ax)}{x}dx=\frac{\pi}{2} \operatorname{sgn}(a),$$ they do as under. The only important thing is where the red square is (the rest is as usual). The says that $\sin(t)\geq \frac{t}{2}$ when $[0,\pi/6]$ and $\sin(t)\geq \frac{1}{2}$ when $t\in [\pi/6,\pi/2]$. But why don't the simply use the fact that $\sin(t)\geq \frac{t}{2}$ on $[0,\pi/2]$, what gives $$\int_0^{\pi/6}e^{-R\sin(t)}dt\leq \int_0^{\pi/2}e^{-Rt/2}dt=\frac{-2}{R}\left[e^{-Rt/2}\right]_{0}^{\pi/2}=\frac{-2}{R}(e^{-R\pi/4}-1)\underset{R\to \infty }{\longrightarrow }0.$$ Is there something I didn't get ? Because taking $\sin(t)\geq t/2$ for all $t\in [0,\pi/2]$ instead of taking $\sin(t)\geq t/2$ on $[0,\pi/6]$ and $\sin(t)\geq 1/2$ on $[\pi/6,\pi/2]$ looks to work great, no ?",,['complex-analysis']
1,Laurent series around z=-i for $\frac{1}{z(z-1)}$ and $1<|z+i|<\sqrt2$,Laurent series around z=-i for  and,\frac{1}{z(z-1)} 1<|z+i|<\sqrt2,"I'm given the function : $$f(z)=\frac{1}{z(z-1)}$$ I'm interesting in finding the Laurent series around $z=-i$ for the one finite circular ring corresponding to this function given its singularities ( I hope I'm using the right words here). I have some ideas but having seen very few problems, I'm not sure about them. So this question is mostly here to check if the way I do things is correct. I think the area we are interested in is the following : $1<|z+i|<\sqrt2$ $f(z)$ can be written as $f(z)=\frac{1}{z-1}-\frac{1}{z}$ We can write the first term as $$\frac{1}{z-1}=\frac{-1}{(1+i)(1-\frac{z+i}{1+i})}$$ $$\frac{-1}{(1+i)}\frac{1}{(1-\frac{z+i}{1+i})}=\frac{-1}{(1+i)}\sum_{n=0}^\infty\left(\frac{z+i}{1+i}\right)^n$$ I tried to turn this in the form of the geometric series. This is valid for $$\frac{|z+i|}{|1+i|}<1=>|z+i|<\sqrt2$$ For the other part of the inequality I will try to do the same for the second term of $f(z)$ : $$\frac{1}{z}=\frac{1}{(z+i)(1-\frac{i}{z+i})}=\frac{1}{z+i}\sum_{n=0}^\infty\left(\frac{i}{z+i}\right)^n$$ which gives the inequality we are looking for : $$\frac{|i|}{|z+i|}<1=>|z+i|>1$$ Finally, this leads to the Laurent Series: $$f(z)=\sum_{n=0}^\infty\left(\frac{z+i}{1+i}\right)^n-\sum_{n=0}^\infty\left(\frac{i}{z+i}\right)^n$$ The left part is the analytic part , and the right one is the principal part except for the n=0 term. Is everything alright with my solution? Should I provide more details if I'm asked in a test?","I'm given the function : $$f(z)=\frac{1}{z(z-1)}$$ I'm interesting in finding the Laurent series around $z=-i$ for the one finite circular ring corresponding to this function given its singularities ( I hope I'm using the right words here). I have some ideas but having seen very few problems, I'm not sure about them. So this question is mostly here to check if the way I do things is correct. I think the area we are interested in is the following : $1<|z+i|<\sqrt2$ $f(z)$ can be written as $f(z)=\frac{1}{z-1}-\frac{1}{z}$ We can write the first term as $$\frac{1}{z-1}=\frac{-1}{(1+i)(1-\frac{z+i}{1+i})}$$ $$\frac{-1}{(1+i)}\frac{1}{(1-\frac{z+i}{1+i})}=\frac{-1}{(1+i)}\sum_{n=0}^\infty\left(\frac{z+i}{1+i}\right)^n$$ I tried to turn this in the form of the geometric series. This is valid for $$\frac{|z+i|}{|1+i|}<1=>|z+i|<\sqrt2$$ For the other part of the inequality I will try to do the same for the second term of $f(z)$ : $$\frac{1}{z}=\frac{1}{(z+i)(1-\frac{i}{z+i})}=\frac{1}{z+i}\sum_{n=0}^\infty\left(\frac{i}{z+i}\right)^n$$ which gives the inequality we are looking for : $$\frac{|i|}{|z+i|}<1=>|z+i|>1$$ Finally, this leads to the Laurent Series: $$f(z)=\sum_{n=0}^\infty\left(\frac{z+i}{1+i}\right)^n-\sum_{n=0}^\infty\left(\frac{i}{z+i}\right)^n$$ The left part is the analytic part , and the right one is the principal part except for the n=0 term. Is everything alright with my solution? Should I provide more details if I'm asked in a test?",,"['complex-analysis', 'laurent-series']"
2,Formal Adjoint of $\overline{\partial}$ operator,Formal Adjoint of  operator,\overline{\partial},"Context: The Futaki Invariant in Kähler Geometry. Reference: Page 24 of Gang Tian's book, Canonical Metrics in Kähler Geometry . Let $(M, g, \omega)$ be a compact Kähler manifold with Kähler metric $g$ and Kähler form $\omega$. Let $X$ be a holomorphic vector field on $M$. Since $\omega$ is closed and $X$ is holomorphic, $$\overline{\partial}(i_X \omega) =0.$$ Hence, by the Hodge theorem, there exists a smooth function $\vartheta_X$ and a harmonic 1-form $\alpha$ such that $$i_X \omega = \alpha - \overline{\partial} \vartheta_X.$$ In particular, $$\alpha = i_X \omega + \overline{\partial} \vartheta_X$$ and $\overline{\partial} \alpha =0$. Claim: $\overline{\partial}^{\ast} \alpha =0$, where $\overline{\partial}^{\ast}$ denotes the formal adjoint of $\overline{\partial}$. This is clearly an elementary observation, but it is not clicking for me. Any help is appreciated. Thanks in advance. (Edit): Apologies for asking two questions in the same post. Claim: If $X^i$ denote the components of the holomorphic vector field described above. How does $$X^i = g^{i\overline{j}} \frac{\partial \alpha}{\partial \overline{z}^j} - g^{i \overline{j}} \frac{\partial \vartheta_X}{\partial \overline{z}^j}?$$ I want to get a really clear understanding of every computation and do not want to simply brush things by.","Context: The Futaki Invariant in Kähler Geometry. Reference: Page 24 of Gang Tian's book, Canonical Metrics in Kähler Geometry . Let $(M, g, \omega)$ be a compact Kähler manifold with Kähler metric $g$ and Kähler form $\omega$. Let $X$ be a holomorphic vector field on $M$. Since $\omega$ is closed and $X$ is holomorphic, $$\overline{\partial}(i_X \omega) =0.$$ Hence, by the Hodge theorem, there exists a smooth function $\vartheta_X$ and a harmonic 1-form $\alpha$ such that $$i_X \omega = \alpha - \overline{\partial} \vartheta_X.$$ In particular, $$\alpha = i_X \omega + \overline{\partial} \vartheta_X$$ and $\overline{\partial} \alpha =0$. Claim: $\overline{\partial}^{\ast} \alpha =0$, where $\overline{\partial}^{\ast}$ denotes the formal adjoint of $\overline{\partial}$. This is clearly an elementary observation, but it is not clicking for me. Any help is appreciated. Thanks in advance. (Edit): Apologies for asking two questions in the same post. Claim: If $X^i$ denote the components of the holomorphic vector field described above. How does $$X^i = g^{i\overline{j}} \frac{\partial \alpha}{\partial \overline{z}^j} - g^{i \overline{j}} \frac{\partial \vartheta_X}{\partial \overline{z}^j}?$$ I want to get a really clear understanding of every computation and do not want to simply brush things by.",,"['complex-analysis', 'differential-geometry']"
3,Bound on the derivative of a holomorphic function from right half plane to unit disc,Bound on the derivative of a holomorphic function from right half plane to unit disc,,"Let $D=\{z\in\mathbb{C}:|z|<1\}$ and let $V=\{z\in\mathbb{C}:\Re(z)>0\}$. Let $f:V\to D$ be a holomorphic function. Prove that $$\forall z\in V:|f'(z)|\leq\frac{1-|f(z)|^2}{2\Re(z)}.$$ By taking $B_z=\{\xi\in V:|\xi-z|<\Re(z)\}$ and using Cauchy's formula, I only managed to obtain $$|f'(z)|\leq\frac{\sup\limits_{\partial B_z}|f|}{\Re(z)}\leq\frac{1}{\Re(z)}.$$ Edit: It seems to be very much related to Schwarz lemma. Maybe it is possible to use some mapping from $D$ to $V$, say $\phi:D\to V$ and then look at$f\circ \phi:D\to D$.","Let $D=\{z\in\mathbb{C}:|z|<1\}$ and let $V=\{z\in\mathbb{C}:\Re(z)>0\}$. Let $f:V\to D$ be a holomorphic function. Prove that $$\forall z\in V:|f'(z)|\leq\frac{1-|f(z)|^2}{2\Re(z)}.$$ By taking $B_z=\{\xi\in V:|\xi-z|<\Re(z)\}$ and using Cauchy's formula, I only managed to obtain $$|f'(z)|\leq\frac{\sup\limits_{\partial B_z}|f|}{\Re(z)}\leq\frac{1}{\Re(z)}.$$ Edit: It seems to be very much related to Schwarz lemma. Maybe it is possible to use some mapping from $D$ to $V$, say $\phi:D\to V$ and then look at$f\circ \phi:D\to D$.",,"['complex-analysis', 'cauchy-integral-formula']"
4,Complex Anaylsis after Ahlfors,Complex Anaylsis after Ahlfors,,"My university offers $3$ complex analysis courses: an introduction computational course Chapters $1$ - $5$ of Ahlfors a course covering compactness and convergence in the space of analytic functions, Riemann mapping theorem, Weierstrass factorization theorem, Runge's theorem, Mittag-Leffler theorem, analytic continuation and Riemann surfaces, and Picard theorems I plan to take these three in the next few years. However, I am curious about complex analysis and would like to continue my studies after the introductory level. Which area(s) of complex analysis are worth studying currently i.e. several complex variables, operator theory, or differential equations? Which texts should I pursue after Ahlfors? I am studying physics also, so a text with rigorous results in quantum mechanics or other related fields would be nice :) Thanks in advance for advice!","My university offers $3$ complex analysis courses: an introduction computational course Chapters $1$ - $5$ of Ahlfors a course covering compactness and convergence in the space of analytic functions, Riemann mapping theorem, Weierstrass factorization theorem, Runge's theorem, Mittag-Leffler theorem, analytic continuation and Riemann surfaces, and Picard theorems I plan to take these three in the next few years. However, I am curious about complex analysis and would like to continue my studies after the introductory level. Which area(s) of complex analysis are worth studying currently i.e. several complex variables, operator theory, or differential equations? Which texts should I pursue after Ahlfors? I am studying physics also, so a text with rigorous results in quantum mechanics or other related fields would be nice :) Thanks in advance for advice!",,"['complex-analysis', 'reference-request']"
5,Entire function having the property [duplicate],Entire function having the property [duplicate],,"This question already has answers here : Entire function with vanishing derivatives? (3 answers) Closed 6 years ago . Let $f$ be an entire function. Consider $A=\{z \in \Bbb{C} : f^{(n)}(z)=0\; \text{for some}\; n \in \Bbb{N}\}$. Then how to prove if $A=\Bbb{C}$, then $f$ is a polynomial ? This is same as proving if $f$ is not a polynomial then $A$ is not all of $\Bbb{C}$. I show the above statement with a particular example, like $f(z)=\sin z$ How to prove generally ?   Any ideas ?","This question already has answers here : Entire function with vanishing derivatives? (3 answers) Closed 6 years ago . Let $f$ be an entire function. Consider $A=\{z \in \Bbb{C} : f^{(n)}(z)=0\; \text{for some}\; n \in \Bbb{N}\}$. Then how to prove if $A=\Bbb{C}$, then $f$ is a polynomial ? This is same as proving if $f$ is not a polynomial then $A$ is not all of $\Bbb{C}$. I show the above statement with a particular example, like $f(z)=\sin z$ How to prove generally ?   Any ideas ?",,['complex-analysis']
6,Harmonic Functions and Partial Derivatives with Chain Rule (Complex Variables),Harmonic Functions and Partial Derivatives with Chain Rule (Complex Variables),,"Suppose that an analytic function $w= f(z) = u(x,y) + iv(x,y)$ maps a domain $D_z$ in the $z$ plane onto a domain $D_w$ in the $w$ plane. Let a function $h(u,v)$ with continuous first and second partial derivatives be defined on $D_w$. Show using chain rule that if   $H(x,y) = h\left( u(x,y) , v(x,y) \right)$ then   $$H_{xx} (x,y) + H_{yy} (x,y) = \left( h_{uu}(u,v) + h_{vv}(u,v) \right) |f’(z)|^2.$$   How does it follow from this that $H(x,y)$ is harmonic in $D_z$ when $h(u,v)$ is harmonic in $D_w?$ I feel that this is just a huge messy chain rule using partial derivatives problem, is there another approach to this or at least a way to do this elegantly without creating a big mess of terms? We know that since $f$ is analytic, the Cauchy-Riemann equations hold: $u_x = v_y \text{ and } u_y = -v_x$. Also, the functions $u$ and $v$ satisfy Laplace’s Equation. The continuity conditions on the partial derivatives yield $h_{vu} = h_{uv}$. (I am having trouble putting these together as well.)","Suppose that an analytic function $w= f(z) = u(x,y) + iv(x,y)$ maps a domain $D_z$ in the $z$ plane onto a domain $D_w$ in the $w$ plane. Let a function $h(u,v)$ with continuous first and second partial derivatives be defined on $D_w$. Show using chain rule that if   $H(x,y) = h\left( u(x,y) , v(x,y) \right)$ then   $$H_{xx} (x,y) + H_{yy} (x,y) = \left( h_{uu}(u,v) + h_{vv}(u,v) \right) |f’(z)|^2.$$   How does it follow from this that $H(x,y)$ is harmonic in $D_z$ when $h(u,v)$ is harmonic in $D_w?$ I feel that this is just a huge messy chain rule using partial derivatives problem, is there another approach to this or at least a way to do this elegantly without creating a big mess of terms? We know that since $f$ is analytic, the Cauchy-Riemann equations hold: $u_x = v_y \text{ and } u_y = -v_x$. Also, the functions $u$ and $v$ satisfy Laplace’s Equation. The continuity conditions on the partial derivatives yield $h_{vu} = h_{uv}$. (I am having trouble putting these together as well.)",,['complex-analysis']
7,Finding zeroes and poles of the Weierstrass $\wp$ and $\wp^{'}$ function associated with a lattice.,Finding zeroes and poles of the Weierstrass  and  function associated with a lattice.,\wp \wp^{'},"I have a lattice, $\Omega$, with basis $\lbrace 2+i, 1+3i\rbrace$ and fundamental region (square) $P$ with vertices $1+2i,\ 2, \ -1+i\ $ and $-i$. I want to find the zeroes and poles of $\wp$ and $\wp^{'}$ in $P$, along with their orders; where $$\wp=\frac{1}{z^2}+\sum_{\omega\in \Omega\backslash\lbrace0\rbrace}\left(\frac{1}{\left(z-\omega\right)^2}-\frac{1}{\omega^2}\right),$$ and $$\wp^{'}=-\frac{2}{z^3}+\sum_{\omega\in \Omega\backslash\lbrace0\rbrace}\left(\frac{-2}{\left(z-\omega\right)^3}\right)=-2\sum_{\omega\in \Omega}\frac{1}{\left(z-\omega\right)^3}.$$ I'd appreciate any guidance you may have to offer.","I have a lattice, $\Omega$, with basis $\lbrace 2+i, 1+3i\rbrace$ and fundamental region (square) $P$ with vertices $1+2i,\ 2, \ -1+i\ $ and $-i$. I want to find the zeroes and poles of $\wp$ and $\wp^{'}$ in $P$, along with their orders; where $$\wp=\frac{1}{z^2}+\sum_{\omega\in \Omega\backslash\lbrace0\rbrace}\left(\frac{1}{\left(z-\omega\right)^2}-\frac{1}{\omega^2}\right),$$ and $$\wp^{'}=-\frac{2}{z^3}+\sum_{\omega\in \Omega\backslash\lbrace0\rbrace}\left(\frac{-2}{\left(z-\omega\right)^3}\right)=-2\sum_{\omega\in \Omega}\frac{1}{\left(z-\omega\right)^3}.$$ I'd appreciate any guidance you may have to offer.",,"['complex-analysis', 'elliptic-functions']"
8,Complex argument for Fourier transform,Complex argument for Fourier transform,,"While computing the convolution of Gaussian functions of type $\varphi_a(x)=e^{-\pi x^2/a}$, $x\in\mathbb{R}^d$, $a\in\mathbb{R}, a\neq 0$, I wrote without thinking: $\begin{align} \varphi_{a}*\varphi_{b}\left(x\right)&=\int e^{-\pi y^{2}/a}e^{-\pi\left(x-y\right)^{2}/b}\mathrm{d}y=e^{-\pi x^{2}/b}\int e^{2\pi xy/b}e^{-\pi\left(\frac{1}{a}+\frac{1}{b}\right)y^{2}}\mathrm{d}y\\&=e^{-\pi x^{2}/b}\int e^{-2\pi i\left(ix/b\right)y}e^{-\pi cy^{2}}\mathrm{d}y=\varphi_{b}\left(x\right)\mathcal{F}\left[\varphi_{\frac{1}{c}}\right]\left(\frac{ix}{b}\right)\\&=\varphi_{b}\left(x\right)\left(\frac{ab}{a+b}\right)^{d/2}\varphi_{c}\left(\frac{ix}{b}\right), \end{align}$ where $c=\frac{1}{a}+\frac{1}{b}=\frac{a+b}{ab}$ and $\mathcal{F}$ stands for the Fourier transform. In particular, we have for Gaussian functions that $$\mathcal{F}[\varphi_c](\omega)=c^{d/2}\varphi_{1/c}(\omega).$$ Even if this yields the expected correct result, I am not able to justify this fact. Is it legitimate to argue as before and thus evaluate the Fourier transform at a complex point even if it takes $\mathbb{R}^d$ arguments by definition? Perhaps Paley-Wiener theory or Laplace transform are involved, but I cannot unravel their role.","While computing the convolution of Gaussian functions of type $\varphi_a(x)=e^{-\pi x^2/a}$, $x\in\mathbb{R}^d$, $a\in\mathbb{R}, a\neq 0$, I wrote without thinking: $\begin{align} \varphi_{a}*\varphi_{b}\left(x\right)&=\int e^{-\pi y^{2}/a}e^{-\pi\left(x-y\right)^{2}/b}\mathrm{d}y=e^{-\pi x^{2}/b}\int e^{2\pi xy/b}e^{-\pi\left(\frac{1}{a}+\frac{1}{b}\right)y^{2}}\mathrm{d}y\\&=e^{-\pi x^{2}/b}\int e^{-2\pi i\left(ix/b\right)y}e^{-\pi cy^{2}}\mathrm{d}y=\varphi_{b}\left(x\right)\mathcal{F}\left[\varphi_{\frac{1}{c}}\right]\left(\frac{ix}{b}\right)\\&=\varphi_{b}\left(x\right)\left(\frac{ab}{a+b}\right)^{d/2}\varphi_{c}\left(\frac{ix}{b}\right), \end{align}$ where $c=\frac{1}{a}+\frac{1}{b}=\frac{a+b}{ab}$ and $\mathcal{F}$ stands for the Fourier transform. In particular, we have for Gaussian functions that $$\mathcal{F}[\varphi_c](\omega)=c^{d/2}\varphi_{1/c}(\omega).$$ Even if this yields the expected correct result, I am not able to justify this fact. Is it legitimate to argue as before and thus evaluate the Fourier transform at a complex point even if it takes $\mathbb{R}^d$ arguments by definition? Perhaps Paley-Wiener theory or Laplace transform are involved, but I cannot unravel their role.",,"['real-analysis', 'complex-analysis', 'fourier-analysis', 'fourier-transform']"
9,Is the infinite product of $-1 \times -1 \times -1 \times\dots = -i$?,Is the infinite product of ?,-1 \times -1 \times -1 \times\dots = -i,"So I woke up this morning and I was thinking about the infinite product $-1 \times -1 \times -1 \times\dots$, and what it equals. I came to the conclusion that it equals $-i$. Alternatively stated, $ {\displaystyle \prod_{i}^{\infty} (-1)} = -i $ Here's how I reached this: $${\prod_{i}^{\infty} (-1)} = e^{\ln({\displaystyle \prod_{i}^{\infty} (-1)})} = e^{\displaystyle \sum_{i}^{\infty}{\ln(-1)}}= e^{\displaystyle \sum_{i}^{\infty}{i\pi}}=e^{i\pi\displaystyle \sum_{i}^{\infty}{1}}$$ Now, here's where I'm a little hesitant. I want to say that, from $\zeta(0)=-\frac{1}{2}$, we can conclude that $$e^{i\pi\displaystyle \sum_{i}^{\infty}{1}} = e^{-\frac{1}{2}i\pi} = -i$$. I have been told before that the sum $\displaystyle \sum_{i}^{\infty}{1}$ is not actually $-\frac{1}{2}$, but I'm not really sure why. It would seem that if this is the case, then my product would in fact not be $-i$. Though, I must say that $-i$ sort of makes sense, because multiplying complex numbers is essentially rotating them, and so rotating by $180$ every time will get you $180+180+180+...$ is the same as $180*(1+1+1+...)$ which is (if my premise is right) $180*(-\frac{1}{2})=-90$. $-90$ degrees on the complex plane turns out to be $-i$. So my question is, is there a hole in my logic? I know what not accounting for $\zeta(0)=-\frac{1}{2}$, the sum $1+1+1+...$ is divergent, but taking that into account, can I say with confidence that $-1 \times -1 \times -1 \times\dots = -i$?","So I woke up this morning and I was thinking about the infinite product $-1 \times -1 \times -1 \times\dots$, and what it equals. I came to the conclusion that it equals $-i$. Alternatively stated, $ {\displaystyle \prod_{i}^{\infty} (-1)} = -i $ Here's how I reached this: $${\prod_{i}^{\infty} (-1)} = e^{\ln({\displaystyle \prod_{i}^{\infty} (-1)})} = e^{\displaystyle \sum_{i}^{\infty}{\ln(-1)}}= e^{\displaystyle \sum_{i}^{\infty}{i\pi}}=e^{i\pi\displaystyle \sum_{i}^{\infty}{1}}$$ Now, here's where I'm a little hesitant. I want to say that, from $\zeta(0)=-\frac{1}{2}$, we can conclude that $$e^{i\pi\displaystyle \sum_{i}^{\infty}{1}} = e^{-\frac{1}{2}i\pi} = -i$$. I have been told before that the sum $\displaystyle \sum_{i}^{\infty}{1}$ is not actually $-\frac{1}{2}$, but I'm not really sure why. It would seem that if this is the case, then my product would in fact not be $-i$. Though, I must say that $-i$ sort of makes sense, because multiplying complex numbers is essentially rotating them, and so rotating by $180$ every time will get you $180+180+180+...$ is the same as $180*(1+1+1+...)$ which is (if my premise is right) $180*(-\frac{1}{2})=-90$. $-90$ degrees on the complex plane turns out to be $-i$. So my question is, is there a hole in my logic? I know what not accounting for $\zeta(0)=-\frac{1}{2}$, the sum $1+1+1+...$ is divergent, but taking that into account, can I say with confidence that $-1 \times -1 \times -1 \times\dots = -i$?",,"['complex-analysis', 'riemann-zeta', 'infinite-product']"
10,Proof of Inversion formula for characteristic function,Proof of Inversion formula for characteristic function,,"I have a question about the proof to the inversion formula for characteristic function. The Theorem is stated as following: $\lim_{T\rightarrow\infty}\frac{1}{2\pi}\int_{-T}^T \frac{e^{-ita} - e^{-itb}}{it}\phi(t)dt = \mathbb{P}(a,b) + \frac{1}{2}\mathbb{P}(\{a,b\})$, where $\phi_{X}(t)$ is the characteristic function of a random variable. In the proof of Chung in his book ""A course in probability theory"" on page 162 there is the following identity: \begin{align}  \int_{-T}^{T}\frac{e^{-ita} - e^{-itb}}{2\pi it}e^{itx}dt &= \int_{-T}^{T}\frac{e^{it(x - a)} - e^{it(x-b)}}{2 \pi it}dt \\ &= \frac{1}{\pi}\int_{0}^{T}\frac{\sin(t(x-a))}{t}dt - \frac{1}{\pi}\int_{0}^{T}\frac{\sin(t(x-b))}{t}dt \end{align} I don't know how to show this. My attempt is the following:   \begin{align} \frac{e^{-ita} - e^{-itb}}{it}e^{itx} &= \frac{e^{it(x - a)} - e^{it(x-b)}}{it}\\&=\frac{-i\left(e^{it(x - a)} - e^{it(x-b)}\right)}{t}\\ &=\frac{\sin(t(x-a)) - \sin(t(x-b)) + i\left(\cos(t(x-b)) - \cos(t(x-a))  \right)}{t}. \end{align} Has anyone an idea?","I have a question about the proof to the inversion formula for characteristic function. The Theorem is stated as following: $\lim_{T\rightarrow\infty}\frac{1}{2\pi}\int_{-T}^T \frac{e^{-ita} - e^{-itb}}{it}\phi(t)dt = \mathbb{P}(a,b) + \frac{1}{2}\mathbb{P}(\{a,b\})$, where $\phi_{X}(t)$ is the characteristic function of a random variable. In the proof of Chung in his book ""A course in probability theory"" on page 162 there is the following identity: \begin{align}  \int_{-T}^{T}\frac{e^{-ita} - e^{-itb}}{2\pi it}e^{itx}dt &= \int_{-T}^{T}\frac{e^{it(x - a)} - e^{it(x-b)}}{2 \pi it}dt \\ &= \frac{1}{\pi}\int_{0}^{T}\frac{\sin(t(x-a))}{t}dt - \frac{1}{\pi}\int_{0}^{T}\frac{\sin(t(x-b))}{t}dt \end{align} I don't know how to show this. My attempt is the following:   \begin{align} \frac{e^{-ita} - e^{-itb}}{it}e^{itx} &= \frac{e^{it(x - a)} - e^{it(x-b)}}{it}\\&=\frac{-i\left(e^{it(x - a)} - e^{it(x-b)}\right)}{t}\\ &=\frac{\sin(t(x-a)) - \sin(t(x-b)) + i\left(\cos(t(x-b)) - \cos(t(x-a))  \right)}{t}. \end{align} Has anyone an idea?",,"['calculus', 'complex-analysis']"
11,foliation with many tangencies,foliation with many tangencies,,"Suppose you have smooth foliation on a Euclidean ball $\mathbb{B}^{4} \subset \mathbb{C}^{2}$, whose leaves are holomorphic curves with respect to the standard complex structure. Let $(z_{1},z_{2})$ be coordinates on $\mathbb{C}^{2}$. Suppose that at every point $p$ in the $z_{1}$-axis, the leaf of the foliation through $p$ meets the $z_{1}$-axis tangentially. Can we deduce that in fact the $z_{1}$-axis must be a leaf of the foliation? how to show it?","Suppose you have smooth foliation on a Euclidean ball $\mathbb{B}^{4} \subset \mathbb{C}^{2}$, whose leaves are holomorphic curves with respect to the standard complex structure. Let $(z_{1},z_{2})$ be coordinates on $\mathbb{C}^{2}$. Suppose that at every point $p$ in the $z_{1}$-axis, the leaf of the foliation through $p$ meets the $z_{1}$-axis tangentially. Can we deduce that in fact the $z_{1}$-axis must be a leaf of the foliation? how to show it?",,"['complex-geometry', 'geometric-topology', 'holomorphic-functions', 'complex-manifolds', 'foliations']"
12,Does a branch cut discontinuity determine a function near the branch point?,Does a branch cut discontinuity determine a function near the branch point?,,"Suppose $g(z)$ is analytic on a disc centered at the origin, except along the negative real axis where it has a branch cut discontinuity. Also assume that $g(0)=0$. Let $h(x)$ give the discontinuity across the branch cut of $g(z)$ at $z =-x$.  The question is to what extent does $h(x)$ determine $g(z)$. It is clear that adding a function that is analytic everywhere on the disc does not affect $h(x)$, since the discontinuity for such a function would be zero.  But is $g(z)$ otherwise determined by $h(x)$, up to this ambiguity? I made a little progress thinking about integrating $g(z)$ around a contour that follows a circle $C(r)$ around the origin from $r e^{-i \pi}$ to $r e^{i\pi}$, and then follows the branch cut to the origin, and then goes back along the lower half of the branch cut.  This then gives the relation $$\int_{C(r)}  g(z) dz = \int_0^r h(x) dx$$ but I was unable to see if I could then invert this relation to get just $g(z)$.","Suppose $g(z)$ is analytic on a disc centered at the origin, except along the negative real axis where it has a branch cut discontinuity. Also assume that $g(0)=0$. Let $h(x)$ give the discontinuity across the branch cut of $g(z)$ at $z =-x$.  The question is to what extent does $h(x)$ determine $g(z)$. It is clear that adding a function that is analytic everywhere on the disc does not affect $h(x)$, since the discontinuity for such a function would be zero.  But is $g(z)$ otherwise determined by $h(x)$, up to this ambiguity? I made a little progress thinking about integrating $g(z)$ around a contour that follows a circle $C(r)$ around the origin from $r e^{-i \pi}$ to $r e^{i\pi}$, and then follows the branch cut to the origin, and then goes back along the lower half of the branch cut.  This then gives the relation $$\int_{C(r)}  g(z) dz = \int_0^r h(x) dx$$ but I was unable to see if I could then invert this relation to get just $g(z)$.",,"['complex-analysis', 'contour-integration', 'analyticity', 'branch-cuts', 'analytic-continuation']"
13,Proving result of complex numbers,Proving result of complex numbers,,"Let $w,z$ be complex such that $wz\neq0$. Let $$t = 2- \left|\frac{w}{|w|} + \frac{z}{|z|}\right|.$$ Show that $0 \leq t \leq 2$, and that $$|w| + |z| - t\text{max}(|w|,|z|) \leq |w+z| \leq |w| + |z| - t\text{min}(|w|,|z|).$$ The first part I've shown, but the latter part I've struggled quite a bit with.","Let $w,z$ be complex such that $wz\neq0$. Let $$t = 2- \left|\frac{w}{|w|} + \frac{z}{|z|}\right|.$$ Show that $0 \leq t \leq 2$, and that $$|w| + |z| - t\text{max}(|w|,|z|) \leq |w+z| \leq |w| + |z| - t\text{min}(|w|,|z|).$$ The first part I've shown, but the latter part I've struggled quite a bit with.",,['complex-analysis']
14,Use the ML estimate to check that $|\int_\gamma e^z -\bar{z}| \leq 57$.,Use the ML estimate to check that .,|\int_\gamma e^z -\bar{z}| \leq 57,"Use the ML estimate to check that $|\int_\gamma e^z -\bar{z}| \leq 57$  where $\gamma$ is the boundary of the triangle with vertices at $0, 3i, -4$. I have that $L = 12$, the length of the triangle. I am having trouble figuring out M so that ML = 57. I was trying to follow an example that my professor gave us. By the triangle inequality $|e^z -\bar{z}| \leq |e^z| + |\bar{z}|$. Then $|e^z|= e^x \leq 1 $ since $-4 \leq x \leq 0$. Also $|\bar{z}| = \sqrt{x^2 + y^2} \leq 5$. So by my estimate $ |\int_\gamma e^z -\bar{z}| \leq 12(1+5) = 72$. Where is my thinking going wrong? I'm not sure how we are suppose to come up with 57?","Use the ML estimate to check that $|\int_\gamma e^z -\bar{z}| \leq 57$  where $\gamma$ is the boundary of the triangle with vertices at $0, 3i, -4$. I have that $L = 12$, the length of the triangle. I am having trouble figuring out M so that ML = 57. I was trying to follow an example that my professor gave us. By the triangle inequality $|e^z -\bar{z}| \leq |e^z| + |\bar{z}|$. Then $|e^z|= e^x \leq 1 $ since $-4 \leq x \leq 0$. Also $|\bar{z}| = \sqrt{x^2 + y^2} \leq 5$. So by my estimate $ |\int_\gamma e^z -\bar{z}| \leq 12(1+5) = 72$. Where is my thinking going wrong? I'm not sure how we are suppose to come up with 57?",,['complex-analysis']
15,Convergence of $\sum_{n=1}^{\infty}\frac{\mu(n)\chi(n)}{n^s}$ on $\Re{s}=1$,Convergence of  on,\sum_{n=1}^{\infty}\frac{\mu(n)\chi(n)}{n^s} \Re{s}=1,"Let $\chi$ be a dirichlet character mod $q$ . Does the dirichlet series for $$\frac{1}{L(s,\chi)}=\sum_{n=1}^{\infty}\frac{\mu(n)\chi(n)}{n^s}$$ converge for any $s$ on the line $\Re(s)=1$ and is this value equal to $\frac{1}{L(s,\chi)}$ ? I can see that it does converge for the principle character using an estimate for $M(x)$ but still dont know whether this value is $\frac{1}{L(s,\chi_0)}$","Let $\chi$ be a dirichlet character mod $q$ . Does the dirichlet series for $$\frac{1}{L(s,\chi)}=\sum_{n=1}^{\infty}\frac{\mu(n)\chi(n)}{n^s}$$ converge for any $s$ on the line $\Re(s)=1$ and is this value equal to $\frac{1}{L(s,\chi)}$ ? I can see that it does converge for the principle character using an estimate for $M(x)$ but still dont know whether this value is $\frac{1}{L(s,\chi_0)}$",,"['complex-analysis', 'number-theory', 'analytic-number-theory', 'dirichlet-series']"
16,Justifying exchanging limit and integral arising in a contour integration with a branch point,Justifying exchanging limit and integral arising in a contour integration with a branch point,,"I'd like to solve $\displaystyle \int_0^\infty \frac{x^\alpha}{x(x+1)}dx,$ where $\alpha \in (0,1).$ The answer is  $\frac{\pi}{\sin (\alpha \pi)}.$ Typically, to solve it, we use contour integral and residue theorem as follows. Let $C=C_{r}^R-I_{r,R}^- -C_r+I_{r,R}^+$ denote the simple closed positively oriented contour, where $-C_r$ and $C_{r}^R$ are the portions of the circles $C_r(0)$ and $C_R(0)$, respectively, and $-I_{r,R}^-$ and $I_{r,R}^+$ the horizontal segments joining them. We select a small value of $r$ and a large value of $R$ so that the nonzero poles $-1$ of $\displaystyle f(z):=\frac{z^\alpha}{z (z+1)}$ lie inside $C.$  We use the branch of $z^\alpha$ corresponding to the branch of the logarithm $\log_0$ as follows: $\displaystyle z^\alpha=e^{\alpha \log_0 (z)} =|z|^\alpha e^{i \alpha\theta}$ for $z=re^{i\theta}\neq 0$ and $\theta \in (0,2\pi]$ Then $\displaystyle \int_C f(z)dz=\int_{C_{r}^R}f(z)dz-\int_{I_{r,R}^-}f(z)dz -\int_{C_r}f(z)dz+\int_{I_{r,R}^+}f(z)dz.$ Using the residue theorem,     \begin{equation}\label{8-29} \int_C f(z)dz=2\pi i \textrm{Res}[f,-1]. \end{equation}  On the other hand, $\displaystyle \lim_{r\to 0^+}\int_{C_r^R}f(z)dz=\int_{C_R^+(0)}f(z)dz$, and it can be shown that $\displaystyle\lim_{r \to 0^+} \int_{C_r}f(z)=\lim_{R\to \infty}\int_{C_R^+(0)}f(z)dz=0,$ by M-L inequlity. My question arises in the next part (most textbooks don't explain it in detail): Because of the branch we chose for $z^\alpha,$  $\displaystyle \lim_{r\to 0^+} \int_{I_{r,R}^+}f(z)dz=\int_0^R\frac{x^\alpha}{x(x+1)}$ and $\displaystyle\lim_{r\to 0^+} \int_{I_{r,R}^-}f(z)dz=\int_0^R\frac{x^\alpha e^{i\alpha 2\pi}}{x(x+1)}$. Note that since $Q$ has a zero of order at most $1$ at the origin, the above two integrals converge. I understand that the integrand $f(z)$ on the upper horizontal line approaches $\frac{x^\alpha}{x(x+1)}$, where $x$ is a real number. Similarly, $f(z)$ on the lower horizontal line approaches $\frac{x^\alpha e^{i\alpha 2\pi}}{x(x+1)}$. I'd like to prove $\displaystyle \lim_{r\to 0^+} \int_{I_{r,R}^+}f(z)dz=\int_0^R\frac{x^\alpha P(x)}{Q(x)}$ in detail. What theorem do I use for this equality. Do I use Lebesgue dominated convergence theorem? I appreciate if you give any comments about it. Thanks in advance.","I'd like to solve $\displaystyle \int_0^\infty \frac{x^\alpha}{x(x+1)}dx,$ where $\alpha \in (0,1).$ The answer is  $\frac{\pi}{\sin (\alpha \pi)}.$ Typically, to solve it, we use contour integral and residue theorem as follows. Let $C=C_{r}^R-I_{r,R}^- -C_r+I_{r,R}^+$ denote the simple closed positively oriented contour, where $-C_r$ and $C_{r}^R$ are the portions of the circles $C_r(0)$ and $C_R(0)$, respectively, and $-I_{r,R}^-$ and $I_{r,R}^+$ the horizontal segments joining them. We select a small value of $r$ and a large value of $R$ so that the nonzero poles $-1$ of $\displaystyle f(z):=\frac{z^\alpha}{z (z+1)}$ lie inside $C.$  We use the branch of $z^\alpha$ corresponding to the branch of the logarithm $\log_0$ as follows: $\displaystyle z^\alpha=e^{\alpha \log_0 (z)} =|z|^\alpha e^{i \alpha\theta}$ for $z=re^{i\theta}\neq 0$ and $\theta \in (0,2\pi]$ Then $\displaystyle \int_C f(z)dz=\int_{C_{r}^R}f(z)dz-\int_{I_{r,R}^-}f(z)dz -\int_{C_r}f(z)dz+\int_{I_{r,R}^+}f(z)dz.$ Using the residue theorem,     \begin{equation}\label{8-29} \int_C f(z)dz=2\pi i \textrm{Res}[f,-1]. \end{equation}  On the other hand, $\displaystyle \lim_{r\to 0^+}\int_{C_r^R}f(z)dz=\int_{C_R^+(0)}f(z)dz$, and it can be shown that $\displaystyle\lim_{r \to 0^+} \int_{C_r}f(z)=\lim_{R\to \infty}\int_{C_R^+(0)}f(z)dz=0,$ by M-L inequlity. My question arises in the next part (most textbooks don't explain it in detail): Because of the branch we chose for $z^\alpha,$  $\displaystyle \lim_{r\to 0^+} \int_{I_{r,R}^+}f(z)dz=\int_0^R\frac{x^\alpha}{x(x+1)}$ and $\displaystyle\lim_{r\to 0^+} \int_{I_{r,R}^-}f(z)dz=\int_0^R\frac{x^\alpha e^{i\alpha 2\pi}}{x(x+1)}$. Note that since $Q$ has a zero of order at most $1$ at the origin, the above two integrals converge. I understand that the integrand $f(z)$ on the upper horizontal line approaches $\frac{x^\alpha}{x(x+1)}$, where $x$ is a real number. Similarly, $f(z)$ on the lower horizontal line approaches $\frac{x^\alpha e^{i\alpha 2\pi}}{x(x+1)}$. I'd like to prove $\displaystyle \lim_{r\to 0^+} \int_{I_{r,R}^+}f(z)dz=\int_0^R\frac{x^\alpha P(x)}{Q(x)}$ in detail. What theorem do I use for this equality. Do I use Lebesgue dominated convergence theorem? I appreciate if you give any comments about it. Thanks in advance.",,"['complex-analysis', 'improper-integrals', 'contour-integration', 'branch-points']"
17,What is the derivative of a polynomial at $\infty$?,What is the derivative of a polynomial at ?,\infty,"Let $f$ be a polynomial defined on the Riemann sphere. I'm struggling to understand in what sense such a map can be said to be ""holomorphic"" at $\infty$. What is the derivative of $f$ at $\infty$? I have a chart $z\to\frac1z$ mapping $\infty$ to $0$ and vice versa. So I think I need to work out the derivative of $1/f(\frac 1 z)$ at $z=0$. So: $$\lim_{z\to 0} \frac {\frac{1}{f(\frac1z)}-\frac1{f(\frac 1 0)}} {z}=\lim_{z\to0}\frac{1}{zf(\frac 1 z)}$$ Expanding the polynomial $f$, we see that if $\deg f>1$, $zf(\frac 1 z)\to \infty$ as $z\to 0$, so the derivative of $f$ at infinity is $0$, but if $f$ is affine of leading coefficient $a$, the derivative will be $\frac 1 a$. Is this correct? And what is the meaning of the calculation I've just done ? In particular, does this result not depend on the choice of chart?","Let $f$ be a polynomial defined on the Riemann sphere. I'm struggling to understand in what sense such a map can be said to be ""holomorphic"" at $\infty$. What is the derivative of $f$ at $\infty$? I have a chart $z\to\frac1z$ mapping $\infty$ to $0$ and vice versa. So I think I need to work out the derivative of $1/f(\frac 1 z)$ at $z=0$. So: $$\lim_{z\to 0} \frac {\frac{1}{f(\frac1z)}-\frac1{f(\frac 1 0)}} {z}=\lim_{z\to0}\frac{1}{zf(\frac 1 z)}$$ Expanding the polynomial $f$, we see that if $\deg f>1$, $zf(\frac 1 z)\to \infty$ as $z\to 0$, so the derivative of $f$ at infinity is $0$, but if $f$ is affine of leading coefficient $a$, the derivative will be $\frac 1 a$. Is this correct? And what is the meaning of the calculation I've just done ? In particular, does this result not depend on the choice of chart?",,"['complex-analysis', 'complex-manifolds', 'riemann-sphere']"
18,Rigorous statement on the possible shapes of branch cuts,Rigorous statement on the possible shapes of branch cuts,,"I have read on numerous occasions, e.g. in this answer that a branch cut of the complex logarithm can be any curve that connects origin and complex infinity and does not intersect itself. I am looking for a more rigorous version of that statement. My question: Is it possible to define a branch cut as a curve in the complex plane given by an implicit equation $F(x,y)=0$? If so, what are the conditions on $F$ so that it represents a branch cut?","I have read on numerous occasions, e.g. in this answer that a branch cut of the complex logarithm can be any curve that connects origin and complex infinity and does not intersect itself. I am looking for a more rigorous version of that statement. My question: Is it possible to define a branch cut as a curve in the complex plane given by an implicit equation $F(x,y)=0$? If so, what are the conditions on $F$ so that it represents a branch cut?",,"['complex-analysis', 'riemann-surfaces']"
19,Either $f$ is a polynomial or $|f(z_j)| > e^{n|z_j|}. $,Either  is a polynomial or,f |f(z_j)| > e^{n|z_j|}. ,"Me and a friend of mine didn't manage to solve the following problem. Let $f: \mathbb{C} \to \mathbb{C}$ be an intere holomorphic function having a finite number of zeroes. Then either $f$ is a polynomial or there is a succession $\{z_j\}$ such that $z_j \to \infty$ and there exist $r$ such that eventually $$|f(z_j)| > e^{r|z_j|}. $$ Attempts Let's call $h = \frac{f}{g}$, where $g$ is the polynomial that vanishes on zeroes of $f$ with the same multiplicity of $f$. We tried to look at $\frac{h'}{h}$, the logarithmic derivative of $h$ , but without good ideas. One can observe that $h$, when it's not constant, must have an essential singularity at infty.","Me and a friend of mine didn't manage to solve the following problem. Let $f: \mathbb{C} \to \mathbb{C}$ be an intere holomorphic function having a finite number of zeroes. Then either $f$ is a polynomial or there is a succession $\{z_j\}$ such that $z_j \to \infty$ and there exist $r$ such that eventually $$|f(z_j)| > e^{r|z_j|}. $$ Attempts Let's call $h = \frac{f}{g}$, where $g$ is the polynomial that vanishes on zeroes of $f$ with the same multiplicity of $f$. We tried to look at $\frac{h'}{h}$, the logarithmic derivative of $h$ , but without good ideas. One can observe that $h$, when it's not constant, must have an essential singularity at infty.",,"['complex-analysis', 'holomorphic-functions']"
20,Evaluating $\frac{1}{2 \pi i} \int_{|z|=3} \frac{e^{\pi z}}{z^2(z^2+2z+2)}dz$,Evaluating,\frac{1}{2 \pi i} \int_{|z|=3} \frac{e^{\pi z}}{z^2(z^2+2z+2)}dz,"I need some help with Complex Analysis: To evaluate the integral $$\frac{1}{2 \pi i} \int_{|z|=3} \frac{e^{\pi z}}{z^2(z^2+2z+2)}dz$$ Here is what I tried: So, $f(z)=\frac{e^{\pi z}}{z^2(z^2+2z+2)}$ has 3 singularities, $z_0 = 0$, $z_0= -1+i $ and $z_0=-1-i$. And all of them are interior to the contour. $\Rightarrow$ We need to find the residues at all the 3 points. $$Res_{z_0=0}(f(z)) = Res_{z_0=0} \left (\frac{e^{\pi z}}{z^2(z^2+2z+2)} \right)\\=\frac{1}{2}(\pi-1)$$ $$Res_{z_0=-1+i}(f(z)) = Res_{z_0=-1+i} \left (\frac{e^{\pi z}}{z^2(z^2+2z+2)} \right)\\=-\frac{e^{-\pi}}{4}$$ $$Res_{z_0=-1-i}(f(z)) = Res_{z_0=-1-i} \left (\frac{e^{\pi z}}{z^2(z^2+2z+2)} \right)\\=-\frac{e^{-\pi}}{4}$$ $$\Rightarrow \frac{1}{2\pi i}\int_{|z|=3} \frac{e^{\pi z}}{z^2(z^2+2z+2)}dz = \frac{1}{2 \pi i} \times \left[ 2\pi i \left(\frac{1}{2}(\pi -1) - \frac{e^{-\pi}}{4} - \frac{e^{-\pi}}{4}\right)\right]\\ = \left( \frac{1}{2}(\pi-1)-\frac{e^{-\pi}}{2}\right)\\ = \frac{\pi-1-e^{-\pi}}{2}$$ But I was told that this was wrong. I couldn't find any mistakes for my work. Can any of you check to see if my work is valid? Or, if it is wrong, how else can I evaluate this? Any helps or comments would be appreciated.   Can someone provide a valid solution (or a different approach)to evaluate this integral? Because some comments say it is wrong. But, some say it is correct. I am confused....","I need some help with Complex Analysis: To evaluate the integral $$\frac{1}{2 \pi i} \int_{|z|=3} \frac{e^{\pi z}}{z^2(z^2+2z+2)}dz$$ Here is what I tried: So, $f(z)=\frac{e^{\pi z}}{z^2(z^2+2z+2)}$ has 3 singularities, $z_0 = 0$, $z_0= -1+i $ and $z_0=-1-i$. And all of them are interior to the contour. $\Rightarrow$ We need to find the residues at all the 3 points. $$Res_{z_0=0}(f(z)) = Res_{z_0=0} \left (\frac{e^{\pi z}}{z^2(z^2+2z+2)} \right)\\=\frac{1}{2}(\pi-1)$$ $$Res_{z_0=-1+i}(f(z)) = Res_{z_0=-1+i} \left (\frac{e^{\pi z}}{z^2(z^2+2z+2)} \right)\\=-\frac{e^{-\pi}}{4}$$ $$Res_{z_0=-1-i}(f(z)) = Res_{z_0=-1-i} \left (\frac{e^{\pi z}}{z^2(z^2+2z+2)} \right)\\=-\frac{e^{-\pi}}{4}$$ $$\Rightarrow \frac{1}{2\pi i}\int_{|z|=3} \frac{e^{\pi z}}{z^2(z^2+2z+2)}dz = \frac{1}{2 \pi i} \times \left[ 2\pi i \left(\frac{1}{2}(\pi -1) - \frac{e^{-\pi}}{4} - \frac{e^{-\pi}}{4}\right)\right]\\ = \left( \frac{1}{2}(\pi-1)-\frac{e^{-\pi}}{2}\right)\\ = \frac{\pi-1-e^{-\pi}}{2}$$ But I was told that this was wrong. I couldn't find any mistakes for my work. Can any of you check to see if my work is valid? Or, if it is wrong, how else can I evaluate this? Any helps or comments would be appreciated.   Can someone provide a valid solution (or a different approach)to evaluate this integral? Because some comments say it is wrong. But, some say it is correct. I am confused....",,"['complex-analysis', 'residue-calculus', 'cauchy-integral-formula']"
21,Find branch points as zeroes of derivative,Find branch points as zeroes of derivative,,A non-constant holomorphic function $f:X\to Y$ between Riemann Surfaces has a branch point at $p\in X$ if there is no open neighbourhood around p on which $f$ is injective. I looked up examples and saw that sometimes people only look at the zeroes of the derivative and say that these are the branch points. Why is this the case?,A non-constant holomorphic function $f:X\to Y$ between Riemann Surfaces has a branch point at $p\in X$ if there is no open neighbourhood around p on which $f$ is injective. I looked up examples and saw that sometimes people only look at the zeroes of the derivative and say that these are the branch points. Why is this the case?,,"['complex-analysis', 'riemann-surfaces']"
22,Finding a closed form for $\int_0^{\infty} \frac{\sin(x/\epsilon)}{1+x^2}dx$ in terms of $\epsilon$?,Finding a closed form for  in terms of ?,\int_0^{\infty} \frac{\sin(x/\epsilon)}{1+x^2}dx \epsilon,$$\int_0^{\infty} \frac{\sin(x/\epsilon)}{1+x^2}dx$$ We can use complex analysis to show that $\int_0^{\infty} \frac{\cos(x/\epsilon)}{1+x^2}dx = \frac{\pi}{2}e^{-1/\epsilon}$ but this sin version is causing trouble. Does anyone know a closed form solution like this for it or is it a wasted effort? Thanks.,$$\int_0^{\infty} \frac{\sin(x/\epsilon)}{1+x^2}dx$$ We can use complex analysis to show that $\int_0^{\infty} \frac{\cos(x/\epsilon)}{1+x^2}dx = \frac{\pi}{2}e^{-1/\epsilon}$ but this sin version is causing trouble. Does anyone know a closed form solution like this for it or is it a wasted effort? Thanks.,,"['calculus', 'complex-analysis', 'improper-integrals', 'closed-form']"
23,Calculate $\lim_{R \to \infty} \int_{|z| = R} \frac{f(z)}{(z-a)(z-b)} dz$,Calculate,\lim_{R \to \infty} \int_{|z| = R} \frac{f(z)}{(z-a)(z-b)} dz,"Let $f$ be an entire function and let $a$, $b \in \mathbb{C}$ with $a \neq b$. 1) Calculate $ \int_{|z| = R}  \frac{f(z)}{(z-a)(z-b)} dz$, if $R > |a|, |b|$. 2) Suppose $f$ is bounded and evaluate $\lim_{R \to \infty} \int_{|z| = R}  \frac{f(z)}{(z-a)(z-b)} dz$ For question (1) I used the fact that $ \int_{|z| = R}  \frac{f(z)}{(z-a)(z-b)} dz = \frac{1}{a-b}   (\int_{|z| = R}  \frac{f(z)}{z-a} dz - \int_{|z| = R} \frac{f(z)}{z-b} dz ) \mbox{(partial fractions)}$, and then applied the Cauchy Integral formula to get that, $\frac{1}{a-b}   (\int_{|z| = R}  \frac{f(z)}{z-a} dz - \int_{|z| = R} \frac{f(z)}{z-b} dz ) = 2\pi i \ \frac{f(a)-f(b)}{a-b}$ Now I'm stuck at the second question because I've found the integral to not be dependent on $R$.","Let $f$ be an entire function and let $a$, $b \in \mathbb{C}$ with $a \neq b$. 1) Calculate $ \int_{|z| = R}  \frac{f(z)}{(z-a)(z-b)} dz$, if $R > |a|, |b|$. 2) Suppose $f$ is bounded and evaluate $\lim_{R \to \infty} \int_{|z| = R}  \frac{f(z)}{(z-a)(z-b)} dz$ For question (1) I used the fact that $ \int_{|z| = R}  \frac{f(z)}{(z-a)(z-b)} dz = \frac{1}{a-b}   (\int_{|z| = R}  \frac{f(z)}{z-a} dz - \int_{|z| = R} \frac{f(z)}{z-b} dz ) \mbox{(partial fractions)}$, and then applied the Cauchy Integral formula to get that, $\frac{1}{a-b}   (\int_{|z| = R}  \frac{f(z)}{z-a} dz - \int_{|z| = R} \frac{f(z)}{z-b} dz ) = 2\pi i \ \frac{f(a)-f(b)}{a-b}$ Now I'm stuck at the second question because I've found the integral to not be dependent on $R$.",,['complex-analysis']
24,Prove differentiability of $\sin(z)$ with use of $\phi(z)$.,Prove differentiability of  with use of .,\sin(z) \phi(z),"Prove that $\sin(z)$ is differentiable in $a$ with the use of a function $\phi$, that satisfies $\sin(z) = \sin(a) + (z-a)\dot\phi(z)$ and $\phi$ is continuous at $a$. I need to show this by useing powerseries. A hint given is that $\sin(z) = \sin(a + z - a)$ It is clear that $\phi(z) = \cos(z)$, but I'm having trouble showing this with powerseries. All help is much appreciated","Prove that $\sin(z)$ is differentiable in $a$ with the use of a function $\phi$, that satisfies $\sin(z) = \sin(a) + (z-a)\dot\phi(z)$ and $\phi$ is continuous at $a$. I need to show this by useing powerseries. A hint given is that $\sin(z) = \sin(a + z - a)$ It is clear that $\phi(z) = \cos(z)$, but I'm having trouble showing this with powerseries. All help is much appreciated",,['complex-analysis']
25,An analytic function is the identity,An analytic function is the identity,,"$W$ is a bounded connected open subset of $\mathbb C$. If $\varphi : W \to W $ is an analytic function, such that $\varphi(w) = w$ and $\varphi'(w) = 1$, for some $w \in W$, then $\,\varphi={\rm Id}$. I'm thinking I need to somehow implement the Schwarz Lemma? But I don't know exactly how to do that here...","$W$ is a bounded connected open subset of $\mathbb C$. If $\varphi : W \to W $ is an analytic function, such that $\varphi(w) = w$ and $\varphi'(w) = 1$, for some $w \in W$, then $\,\varphi={\rm Id}$. I'm thinking I need to somehow implement the Schwarz Lemma? But I don't know exactly how to do that here...",,"['complex-analysis', 'analyticity']"
26,How to evaluate the following complex limit?,How to evaluate the following complex limit?,,"I have to evaluate the following limit: $$\lim_{z\rightarrow \frac{\sqrt3i}{2}}\frac{z}{4z^2+3}$$ I know the limit doesn't exist. I tried proving it by letting: $$z = x +iy,\\y =\frac{\sqrt3i}{2} $$ And then evaluating the new limit for $$x\rightarrow0\_$$ and $$x\rightarrow0_+$$ and hence show they do not equal one another. However, this approach didn't work since I got to  $$\lim_{x\rightarrow0\_}\frac{x+i\sqrt3/2}{4x(x+i\sqrt3)}$$ and got stuck. Could I get some help guys? Edit: sorry if the formatting isn't that good. I'm still new to this site.","I have to evaluate the following limit: $$\lim_{z\rightarrow \frac{\sqrt3i}{2}}\frac{z}{4z^2+3}$$ I know the limit doesn't exist. I tried proving it by letting: $$z = x +iy,\\y =\frac{\sqrt3i}{2} $$ And then evaluating the new limit for $$x\rightarrow0\_$$ and $$x\rightarrow0_+$$ and hence show they do not equal one another. However, this approach didn't work since I got to  $$\lim_{x\rightarrow0\_}\frac{x+i\sqrt3/2}{4x(x+i\sqrt3)}$$ and got stuck. Could I get some help guys? Edit: sorry if the formatting isn't that good. I'm still new to this site.",,"['complex-analysis', 'limits']"
27,Reference book for complex analysis.,Reference book for complex analysis.,,"I have a complex analysis test in 15 days. I have never studied the subject before. The only analysis I know is the first 7 chapters of baby Rudin. I plan to learn some multi-variable analysis and then start complex analysis. I have Rudin's Real and Complex Analysis and Complex Analysis by Lars Ahlfors, but they seem like books that would take a lot of time to study. I'm looking for a book with really simple proofs, yet ones which cover a decent bit of ground. The easiest book I have read so for is Real Analysis by Robert Bartle. Can someone suggest a book for complex analysis which is as easy as Bartle? Thanks.","I have a complex analysis test in 15 days. I have never studied the subject before. The only analysis I know is the first 7 chapters of baby Rudin. I plan to learn some multi-variable analysis and then start complex analysis. I have Rudin's Real and Complex Analysis and Complex Analysis by Lars Ahlfors, but they seem like books that would take a lot of time to study. I'm looking for a book with really simple proofs, yet ones which cover a decent bit of ground. The easiest book I have read so for is Real Analysis by Robert Bartle. Can someone suggest a book for complex analysis which is as easy as Bartle? Thanks.",,"['complex-analysis', 'reference-request']"
28,Asymptotic expansion of a given integral,Asymptotic expansion of a given integral,,"I need to find the first three terms in the asymptotic expansion of given integral $$\int_0^1ln(1+t)e^{ixsin^2t}dt$$ as $x$ tends to infinity. Using steepest descent method, we deform contour C:$0\lt t \le 1$ into contours along which $\Im A(t)$ is constant, where $A(t)= i \sin^2t$. To find constant contour along $t=0$, set $\sin t=u+iv$, $i \sin^2t=-2uv+i(u^2-v^2)$. Thus $\Im A(t)=u^2-v^2$. At $t=0$, $\Im A(t) =0$. Thus, at $t=0$, $u=v$. $\Re A(t)=-2v^2$. Hence, $e^{ix \sin^2t}=e^{-2xv^2}$. I think I'm in the wrong way, can anybody help me to solve this.","I need to find the first three terms in the asymptotic expansion of given integral $$\int_0^1ln(1+t)e^{ixsin^2t}dt$$ as $x$ tends to infinity. Using steepest descent method, we deform contour C:$0\lt t \le 1$ into contours along which $\Im A(t)$ is constant, where $A(t)= i \sin^2t$. To find constant contour along $t=0$, set $\sin t=u+iv$, $i \sin^2t=-2uv+i(u^2-v^2)$. Thus $\Im A(t)=u^2-v^2$. At $t=0$, $\Im A(t) =0$. Thus, at $t=0$, $u=v$. $\Re A(t)=-2v^2$. Hence, $e^{ix \sin^2t}=e^{-2xv^2}$. I think I'm in the wrong way, can anybody help me to solve this.",,"['calculus', 'complex-analysis', 'asymptotics']"
29,"Calculate the path integral: $\int_{\lambda}\left[2z+\sinh\left(z\right)\right]\,\mathrm{d}z$",Calculate the path integral:,"\int_{\lambda}\left[2z+\sinh\left(z\right)\right]\,\mathrm{d}z","Calculate the path integral: $$\int_{\lambda}\left[2z + \sinh\left(z\right)\right]\,\mathrm{d}z$$ where $\displaystyle\lambda\left(t\right) = \frac{t^{2}}{4} + \frac{\mathrm{i}t}{2}\,,\quad \left(~0 ≤ t ≤ 4~\right)$ . Im not sure how to parameterize this and also how to answer the rest of the question so any help will be appreciated.",Calculate the path integral: where . Im not sure how to parameterize this and also how to answer the rest of the question so any help will be appreciated.,"\int_{\lambda}\left[2z + \sinh\left(z\right)\right]\,\mathrm{d}z \displaystyle\lambda\left(t\right) =
\frac{t^{2}}{4} + \frac{\mathrm{i}t}{2}\,,\quad
\left(~0 ≤ t ≤ 4~\right)",['integration']
30,Contour integral of $\frac{e^{-ux}}{Ax^2+Bx+C}$,Contour integral of,\frac{e^{-ux}}{Ax^2+Bx+C},"I'm having a little trouble figuring this one out. I've found the poles to be at $$\frac{-B\pm\sqrt{B^2-4AC}}{2A}$$ Am I right to assume the residues can be found by this? $$\text{Res}\bigg[ \lim_{s\to \frac{-B+ \sqrt{B^2-4AC}}{2A}}\frac{(s+\frac{-B+ \sqrt{B^2-4AC}}{2A})e^{-ux}}{s(s+\frac{-B+ \sqrt{B^2-4AC}}{2A})(s-\frac{-B- \sqrt{B^2-4AC}}{2A})} \\ +\lim_{s\to \frac{-B- \sqrt{B^2-4AC}}{2A}}\frac{(s-\frac{-B+ \sqrt{B^2-4AC}}{2A})\cdot e^{-ux}}{s(s+\frac{-B+ \sqrt{B^2-4AC}}{2A})(s-\frac{-B- \sqrt{B^2-4AC}}{2A})}\bigg]$$ My only problem is this seems a bit excessive. Is there an alternative, simpler way to find the residue here?","I'm having a little trouble figuring this one out. I've found the poles to be at $$\frac{-B\pm\sqrt{B^2-4AC}}{2A}$$ Am I right to assume the residues can be found by this? $$\text{Res}\bigg[ \lim_{s\to \frac{-B+ \sqrt{B^2-4AC}}{2A}}\frac{(s+\frac{-B+ \sqrt{B^2-4AC}}{2A})e^{-ux}}{s(s+\frac{-B+ \sqrt{B^2-4AC}}{2A})(s-\frac{-B- \sqrt{B^2-4AC}}{2A})} \\ +\lim_{s\to \frac{-B- \sqrt{B^2-4AC}}{2A}}\frac{(s-\frac{-B+ \sqrt{B^2-4AC}}{2A})\cdot e^{-ux}}{s(s+\frac{-B+ \sqrt{B^2-4AC}}{2A})(s-\frac{-B- \sqrt{B^2-4AC}}{2A})}\bigg]$$ My only problem is this seems a bit excessive. Is there an alternative, simpler way to find the residue here?",,"['complex-analysis', 'contour-integration']"
31,Show that the function $\sum_{n=1}^{\infty}z^{n!}$ cannot be analytically continued beyond the unit disk,Show that the function  cannot be analytically continued beyond the unit disk,\sum_{n=1}^{\infty}z^{n!},"Let $f=\sum_{n=1}^{\infty}z^{n!}$. Show that $f$ cannot be analytically continued beyond the unit disk. My thought so far: consider a root of unity, say $r=e^{2\pi ik}$, where $k$ is a rational number. Now consider the path $t\rightarrow tr, t\in [0,1]$ I want to show that the sum $\lim_{t\rightarrow 1^{-}}\sum_{n=1}^{\infty}f(tr) = \lim_{t\rightarrow 1^{-}}\sum_{n=1}^{\infty}t^{n!}e^{2\pi irn!}$ blows up. Can I use the Abel's theorem here? How do I show that the sum diverges?","Let $f=\sum_{n=1}^{\infty}z^{n!}$. Show that $f$ cannot be analytically continued beyond the unit disk. My thought so far: consider a root of unity, say $r=e^{2\pi ik}$, where $k$ is a rational number. Now consider the path $t\rightarrow tr, t\in [0,1]$ I want to show that the sum $\lim_{t\rightarrow 1^{-}}\sum_{n=1}^{\infty}f(tr) = \lim_{t\rightarrow 1^{-}}\sum_{n=1}^{\infty}t^{n!}e^{2\pi irn!}$ blows up. Can I use the Abel's theorem here? How do I show that the sum diverges?",,['complex-analysis']
32,"What is the basic difference between differentiable, analytic and holomorphic function?","What is the basic difference between differentiable, analytic and holomorphic function?",,"The function $f(z)$ is said to be analytic at $z_0$ if its derivative exists at each point $z$ in some neighborhood of $z_0$ , and the function is said to be differentiable if its derivative exist at each point in its domain. So whats the difference?","The function is said to be analytic at if its derivative exists at each point in some neighborhood of , and the function is said to be differentiable if its derivative exist at each point in its domain. So whats the difference?",f(z) z_0 z z_0,"['calculus', 'complex-analysis']"
33,Derivation of a series expansion for Riemann Zeta function,Derivation of a series expansion for Riemann Zeta function,,"Though there is a vast amount of literature on Riemann's Zeta Function, but, I was struck by this formula of the series, which is given in Wikipedia. Even after seeing several tracts from this site as well as others, I am unable to find its derivation. If it is a duplicate, or the question is asked before, please let me know. The question is how does the below two series, given in the link above, be derived? $$\zeta(s)=\frac{1}{s-1}\sum_{n=1}^{\infty}\left(\frac{n}{(n+1)^s}-\frac{n-s}{n^s}\right)\forall \Re(s)>0$$ and $$\zeta(s)=\frac{1}{s-1}\sum_{n=1}^{\infty}\frac{n(n+1)}{2}\left(\frac{2n+3+s}{(n+1)^{s+2}}-\frac{2n-1-s}{n^{s+2}}\right)\forall \Re(s)>-1$$ I once got a comment that these formulae are untrue. Are their claims right? But, since it is there in Wkipedia, it deserves some crucial examination. The series are instructive in that,if they are true, they give us analytic continuation without the use of Integration. I guess it is by using the Mittag-Leffler Theorem as the reference in the article points to Knopp's Theory of Functions book, if which I have no copy but am unsure. Thanks beforehand","Though there is a vast amount of literature on Riemann's Zeta Function, but, I was struck by this formula of the series, which is given in Wikipedia. Even after seeing several tracts from this site as well as others, I am unable to find its derivation. If it is a duplicate, or the question is asked before, please let me know. The question is how does the below two series, given in the link above, be derived? and I once got a comment that these formulae are untrue. Are their claims right? But, since it is there in Wkipedia, it deserves some crucial examination. The series are instructive in that,if they are true, they give us analytic continuation without the use of Integration. I guess it is by using the Mittag-Leffler Theorem as the reference in the article points to Knopp's Theory of Functions book, if which I have no copy but am unsure. Thanks beforehand",\zeta(s)=\frac{1}{s-1}\sum_{n=1}^{\infty}\left(\frac{n}{(n+1)^s}-\frac{n-s}{n^s}\right)\forall \Re(s)>0 \zeta(s)=\frac{1}{s-1}\sum_{n=1}^{\infty}\frac{n(n+1)}{2}\left(\frac{2n+3+s}{(n+1)^{s+2}}-\frac{2n-1-s}{n^{s+2}}\right)\forall \Re(s)>-1,"['complex-analysis', 'number-theory', 'analytic-number-theory', 'riemann-zeta']"
34,Conformal map of an annulus onto a strip to solve BVP?,Conformal map of an annulus onto a strip to solve BVP?,,"I have a problem involving conformal maps on annuli, about which I can't find very much at all here on SE, nor in two or three Complex Analysis texts. My difficulty involves firstly a wrinkle in solving under-specified Dirichlet problems, and latterly in transforming the annulus. The problem is as follows: Write down the solution $u(x,y)$ to the Dirichlet problem for the following region and boundary conditions:   $$U = \{x+iy:0 \leq y \leq1\}, \qquad u(x,0)=0, \qquad u(x,1)=1$$   Hence, using appropriate conformal maps, solve the Dirichlet problem for the region with boundary conditions:   $$V = \{z: r \leq |z| \leq R \}, \qquad u(z)=0 \;\textrm{when} \; |z|=r, \qquad u(z)=1 \;\textrm{when} \; |z|=R,  $$ Firstly, $U$ is an infinite horizontal strip, so has no boundary conditions for $x$. Clearly $u(x,y)=y$ is one such solution, but given then region is unbounded am I right in thinking we don't have uniqueness? The method I'm used to via separation of variables and Fourier analysis doesn't get me very far. Secondly, I take it we wish to conformally map the annulus $V$ onto the strip $U$. But $U$ is simply connected and $V$ is not, so surely this can't be possible? Happily glossing over the first question, with the latter I am not sure how to proceed. Any comments welcomed! Update Jan '17: Following comments, I think this is how these regions look on the Riemann sphere! The strip maps to the half of the sphere that lies in/over/under (you get the idea!) the upper half plane $\mathbb {H} : \Im (z) \geqslant 0$ minus a circle (?) from the pole $N$ to the point $i$ on the circumference. The annulus maps onto a 'belt' around the circumference. So actually, to shift between the two, could we slide the strip-projection down underneath the sphere (to avoid going through $N$) and fit it onto the belt?","I have a problem involving conformal maps on annuli, about which I can't find very much at all here on SE, nor in two or three Complex Analysis texts. My difficulty involves firstly a wrinkle in solving under-specified Dirichlet problems, and latterly in transforming the annulus. The problem is as follows: Write down the solution $u(x,y)$ to the Dirichlet problem for the following region and boundary conditions:   $$U = \{x+iy:0 \leq y \leq1\}, \qquad u(x,0)=0, \qquad u(x,1)=1$$   Hence, using appropriate conformal maps, solve the Dirichlet problem for the region with boundary conditions:   $$V = \{z: r \leq |z| \leq R \}, \qquad u(z)=0 \;\textrm{when} \; |z|=r, \qquad u(z)=1 \;\textrm{when} \; |z|=R,  $$ Firstly, $U$ is an infinite horizontal strip, so has no boundary conditions for $x$. Clearly $u(x,y)=y$ is one such solution, but given then region is unbounded am I right in thinking we don't have uniqueness? The method I'm used to via separation of variables and Fourier analysis doesn't get me very far. Secondly, I take it we wish to conformally map the annulus $V$ onto the strip $U$. But $U$ is simply connected and $V$ is not, so surely this can't be possible? Happily glossing over the first question, with the latter I am not sure how to proceed. Any comments welcomed! Update Jan '17: Following comments, I think this is how these regions look on the Riemann sphere! The strip maps to the half of the sphere that lies in/over/under (you get the idea!) the upper half plane $\mathbb {H} : \Im (z) \geqslant 0$ minus a circle (?) from the pole $N$ to the point $i$ on the circumference. The annulus maps onto a 'belt' around the circumference. So actually, to shift between the two, could we slide the strip-projection down underneath the sphere (to avoid going through $N$) and fit it onto the belt?",,"['complex-analysis', 'conformal-geometry', 'mobius-transformation']"
35,Have I developed new elliptic functions?,Have I developed new elliptic functions?,,"While tinkering with the log-derivative of the function \begin{align}\varphi(z,q)&=2e^{-\pi qz^2-\pi q/4}\sinh\pi qz \prod_{k\ge1}(1-e^{-2k\pi q})(1-e^{-2k\pi q+2\pi qz})(1-e^{-2k\pi q-2\pi qz})\tag1\\ &=\frac2{\sqrt{q}}e^{-\tfrac{\pi}{4q}}\sin \pi z \prod_{k\ge1}(1-e^{-2k\pi/q})(1-e^{-2k\pi/q+2i\pi z})(1-e^{-2k\pi/q-2i\pi z})\tag2 \end{align} I found I could create a function around its moment integral (with an additional constant $\alpha$): $$u_n(z,\alpha;q)=\exp{\int_0^\alpha y^n \dfrac{\varphi'}{\varphi}(y+z,q)\,dy}\tag3$$ I also know that $\varphi(z+i/q,q)=-e^{\pi/q-2i\pi z}\varphi(z,q)$ and $\varphi(z+1,q)=-\varphi(z,q)$ (each following respectively from $(1)$ and $(2)$) and so $$\frac{\varphi'}{\varphi}(z+i/q,q)=-2i\pi+\frac{\varphi'}{\varphi}(z,q),\qquad\frac{\varphi'}{\varphi}(z+1,q)=\frac{\varphi'}{\varphi}(z,q)$$ If I plug these into $(3)$ I'll get \begin{align}u_n(z+i/q,\alpha,q)&=\exp\int_0^\alpha y^n\frac{\varphi'}{\varphi}(y+z+i/q,q)\,dy\\ &=\exp\int_0^\alpha y^n\left(-2i\pi+\frac{\varphi'}{\varphi}(y+z,q)\right)\,dy\\ &=e^{-2i\pi\alpha^{n+1}/(n+1)}u_n(z,\alpha,q)\end{align} and \begin{align}u_n(z+1,\alpha,q)&=\exp\int_0^\alpha y^n\frac{\varphi'}{\varphi}(y+z+1,q)\,dy\\ &=\exp\int_0^\alpha y^n\frac{\varphi'}{\varphi}(y+z,q)\,dy\\ &=u_n(z,\alpha,q)\end{align} But I've noticed that $\frac{\varphi(z+\alpha,q)}{\varphi(z,q)}$ satisfies similar properties: \begin{align}\frac{\varphi(z+\alpha+i/q,q)}{\varphi(z+i/q,q)}&=\frac{-e^{\pi/q-2i\pi(z+\alpha)}\varphi(z+\alpha,q)}{-e^{\pi/q-2i\pi z}\varphi(z,q)}=e^{-2i\alpha\pi}\frac{\varphi(z+\alpha,q)}{\varphi(z,q)}\\ \frac{\varphi(z+\alpha+1,q)}{\varphi(z+1,q)}&=\frac{-\varphi(z+\alpha,q)}{-\varphi(z,q)}=\frac{\varphi(z+\alpha,q)}{\varphi(z,q)}\end{align} So with the right exponents, I can combine them into a doubly periodic function:\begin{align}e_n(z,\alpha,q):&=\left[\frac{\varphi(z+\alpha,q)}{\varphi(z,q)}\right]^{\alpha^n}u_n^{-n-1}(z,\alpha,q)\tag4\\ &\\ e_n(z+1,\alpha,q)&=\left[\frac{-\varphi(z+\alpha,q)}{-\varphi(z,q)}\right]^{\alpha^n}u_n^{-n-1}(z+1,\alpha,q)\\ &=\left[\frac{\varphi(z+\alpha,q)}{\varphi(z,q)}\right]^{\alpha^n}u_n^{-n-1}(z,\alpha,q)\\ &=e_n(z,\alpha,q)\\ &\\ e_n(z+i/q,\alpha,q)&=\left[e^{-2\alpha i\pi}\frac{\varphi(z+\alpha,q)}{\varphi(z,q)}\right]^{\alpha^n}u_n^{-n-1}(z+i/q,\alpha,q)\\ &=e^{-2i\pi\alpha^{n+1}}\left[\frac{\varphi(z+\alpha,q)}{\varphi(z,q)}\right]^{\alpha^n}e^{2i\pi\alpha^{n+1}}u_n^{-n-1}(z,\alpha,q)\\ &=e_n(z,\alpha,q)\end{align} But the strangest property of $e_n$ follows from a transformation for $\varphi(z,q)$: $$\varphi(z,q)=-iq^{-1/2}e^{-\pi qz^2}\varphi(iqz,1/q)$$ which leads to \begin{align}e_n(z,\alpha,q)&=\left[\frac{-iq^{-1/2}e^{-\pi q(z+\alpha)^2}\varphi(iq(z+\alpha),1/q)}{-iq^{-1/2}e^{-\pi qz^2}\varphi(iqz,1/q)}\right]^{\alpha^n}\\ &\quad\exp\Big[-(n+1)\int_0^\alpha y^n\left\{-2\pi q(y+z)+iq\frac{\varphi'}{\varphi}(iqy+iqz,1/q)\right\}\,dy\Big]\\[2ex] &=e^{-\pi q\alpha^n(\alpha^2+2\alpha z)}\left[\frac{\varphi(iqz+\alpha iq,1/q)}{\varphi(iqz,1/q)}\right]^{\alpha^n}\\ &\quad\exp\Big[\left\{2\pi q\alpha^{n+2}\cdot\frac{n+1}{n+2}+2\pi qz\alpha^{n+1}-iq(n+1)\int_0^\alpha y^n\frac{\varphi'}{\varphi}(iqy+iqz,1/q)\,dy\right\}\Big]\\[2ex] &=e^{n\alpha^{n+1}\pi q/(n+2)}\left[\frac{\varphi(iqz+\alpha iq,1/q)}{\varphi(iqz,1/q)}\right]^{\alpha^n}\exp\int_0^{\alpha iq}-(n+1)(iq)^{-n}x^n\frac{\varphi'}{\varphi}(x+iqz,1/q),dx\\ &=e^{n\alpha^{n+1}\pi q/(n+2)}\left[\frac{\varphi(iqz+\alpha iq,1/q)}{\varphi(iqz,1/q)}\right]^{\alpha^n}u_n^{-(n+1)(iq)^{-n}}(iqz,\alpha iq,1/q)\\ &=e^{n\alpha^{n+1}\pi q/(n+2)}\left[\frac{\varphi(iqz+\alpha iq,1/q)}{\varphi(iqz,1/q)}\right]^{\alpha^n}\left[\frac{\varphi(iqz+\alpha iq, 1/q)}{\varphi(iqz,1/q)}\right]^{-\alpha^n}e_n^{(iq)^{-n}}(iqz,\alpha iq,1/q)\\ &=e^{\alpha^{n+1}n\pi q/(n+2)}e_n^{(iq)^{-n}}(iqz,\alpha iq,1/q) \end{align} I would like to know the degrees of the zeros and poles of $e_n$ so I can determine its Mittag-Leffler expansion. The above transformation appears to change their nature, so this may prove to be very thorny. [Edit] I have found a tractable form for $e_1(z,\alpha;q)$ using the formula \begin{align}\exp\int_0^z\ln\varphi(y,q)\,dy=&e^{\pi qz^3/3-\pi z(q+q^{-1})/6}\varphi^z(z,q)\\ &\cdot\prod_{k\ge1}\underbrace{\bigg(\frac{1-e^{-2k\pi q-2\pi qz}}{1-e^{-2k\pi q+2\pi qz}}\bigg)^k}_{p_1(z,q)}\underbrace{\bigg(\frac{1-e^{-2k\pi/q+2i\pi z}}{1-e^{-2k\pi/q-2i\pi z}}\bigg)^{ik/q}}_{p_2(z,q)}:\tag5 \end{align} I've posted the details as an answer.","While tinkering with the log-derivative of the function \begin{align}\varphi(z,q)&=2e^{-\pi qz^2-\pi q/4}\sinh\pi qz \prod_{k\ge1}(1-e^{-2k\pi q})(1-e^{-2k\pi q+2\pi qz})(1-e^{-2k\pi q-2\pi qz})\tag1\\ &=\frac2{\sqrt{q}}e^{-\tfrac{\pi}{4q}}\sin \pi z \prod_{k\ge1}(1-e^{-2k\pi/q})(1-e^{-2k\pi/q+2i\pi z})(1-e^{-2k\pi/q-2i\pi z})\tag2 \end{align} I found I could create a function around its moment integral (with an additional constant $\alpha$): $$u_n(z,\alpha;q)=\exp{\int_0^\alpha y^n \dfrac{\varphi'}{\varphi}(y+z,q)\,dy}\tag3$$ I also know that $\varphi(z+i/q,q)=-e^{\pi/q-2i\pi z}\varphi(z,q)$ and $\varphi(z+1,q)=-\varphi(z,q)$ (each following respectively from $(1)$ and $(2)$) and so $$\frac{\varphi'}{\varphi}(z+i/q,q)=-2i\pi+\frac{\varphi'}{\varphi}(z,q),\qquad\frac{\varphi'}{\varphi}(z+1,q)=\frac{\varphi'}{\varphi}(z,q)$$ If I plug these into $(3)$ I'll get \begin{align}u_n(z+i/q,\alpha,q)&=\exp\int_0^\alpha y^n\frac{\varphi'}{\varphi}(y+z+i/q,q)\,dy\\ &=\exp\int_0^\alpha y^n\left(-2i\pi+\frac{\varphi'}{\varphi}(y+z,q)\right)\,dy\\ &=e^{-2i\pi\alpha^{n+1}/(n+1)}u_n(z,\alpha,q)\end{align} and \begin{align}u_n(z+1,\alpha,q)&=\exp\int_0^\alpha y^n\frac{\varphi'}{\varphi}(y+z+1,q)\,dy\\ &=\exp\int_0^\alpha y^n\frac{\varphi'}{\varphi}(y+z,q)\,dy\\ &=u_n(z,\alpha,q)\end{align} But I've noticed that $\frac{\varphi(z+\alpha,q)}{\varphi(z,q)}$ satisfies similar properties: \begin{align}\frac{\varphi(z+\alpha+i/q,q)}{\varphi(z+i/q,q)}&=\frac{-e^{\pi/q-2i\pi(z+\alpha)}\varphi(z+\alpha,q)}{-e^{\pi/q-2i\pi z}\varphi(z,q)}=e^{-2i\alpha\pi}\frac{\varphi(z+\alpha,q)}{\varphi(z,q)}\\ \frac{\varphi(z+\alpha+1,q)}{\varphi(z+1,q)}&=\frac{-\varphi(z+\alpha,q)}{-\varphi(z,q)}=\frac{\varphi(z+\alpha,q)}{\varphi(z,q)}\end{align} So with the right exponents, I can combine them into a doubly periodic function:\begin{align}e_n(z,\alpha,q):&=\left[\frac{\varphi(z+\alpha,q)}{\varphi(z,q)}\right]^{\alpha^n}u_n^{-n-1}(z,\alpha,q)\tag4\\ &\\ e_n(z+1,\alpha,q)&=\left[\frac{-\varphi(z+\alpha,q)}{-\varphi(z,q)}\right]^{\alpha^n}u_n^{-n-1}(z+1,\alpha,q)\\ &=\left[\frac{\varphi(z+\alpha,q)}{\varphi(z,q)}\right]^{\alpha^n}u_n^{-n-1}(z,\alpha,q)\\ &=e_n(z,\alpha,q)\\ &\\ e_n(z+i/q,\alpha,q)&=\left[e^{-2\alpha i\pi}\frac{\varphi(z+\alpha,q)}{\varphi(z,q)}\right]^{\alpha^n}u_n^{-n-1}(z+i/q,\alpha,q)\\ &=e^{-2i\pi\alpha^{n+1}}\left[\frac{\varphi(z+\alpha,q)}{\varphi(z,q)}\right]^{\alpha^n}e^{2i\pi\alpha^{n+1}}u_n^{-n-1}(z,\alpha,q)\\ &=e_n(z,\alpha,q)\end{align} But the strangest property of $e_n$ follows from a transformation for $\varphi(z,q)$: $$\varphi(z,q)=-iq^{-1/2}e^{-\pi qz^2}\varphi(iqz,1/q)$$ which leads to \begin{align}e_n(z,\alpha,q)&=\left[\frac{-iq^{-1/2}e^{-\pi q(z+\alpha)^2}\varphi(iq(z+\alpha),1/q)}{-iq^{-1/2}e^{-\pi qz^2}\varphi(iqz,1/q)}\right]^{\alpha^n}\\ &\quad\exp\Big[-(n+1)\int_0^\alpha y^n\left\{-2\pi q(y+z)+iq\frac{\varphi'}{\varphi}(iqy+iqz,1/q)\right\}\,dy\Big]\\[2ex] &=e^{-\pi q\alpha^n(\alpha^2+2\alpha z)}\left[\frac{\varphi(iqz+\alpha iq,1/q)}{\varphi(iqz,1/q)}\right]^{\alpha^n}\\ &\quad\exp\Big[\left\{2\pi q\alpha^{n+2}\cdot\frac{n+1}{n+2}+2\pi qz\alpha^{n+1}-iq(n+1)\int_0^\alpha y^n\frac{\varphi'}{\varphi}(iqy+iqz,1/q)\,dy\right\}\Big]\\[2ex] &=e^{n\alpha^{n+1}\pi q/(n+2)}\left[\frac{\varphi(iqz+\alpha iq,1/q)}{\varphi(iqz,1/q)}\right]^{\alpha^n}\exp\int_0^{\alpha iq}-(n+1)(iq)^{-n}x^n\frac{\varphi'}{\varphi}(x+iqz,1/q),dx\\ &=e^{n\alpha^{n+1}\pi q/(n+2)}\left[\frac{\varphi(iqz+\alpha iq,1/q)}{\varphi(iqz,1/q)}\right]^{\alpha^n}u_n^{-(n+1)(iq)^{-n}}(iqz,\alpha iq,1/q)\\ &=e^{n\alpha^{n+1}\pi q/(n+2)}\left[\frac{\varphi(iqz+\alpha iq,1/q)}{\varphi(iqz,1/q)}\right]^{\alpha^n}\left[\frac{\varphi(iqz+\alpha iq, 1/q)}{\varphi(iqz,1/q)}\right]^{-\alpha^n}e_n^{(iq)^{-n}}(iqz,\alpha iq,1/q)\\ &=e^{\alpha^{n+1}n\pi q/(n+2)}e_n^{(iq)^{-n}}(iqz,\alpha iq,1/q) \end{align} I would like to know the degrees of the zeros and poles of $e_n$ so I can determine its Mittag-Leffler expansion. The above transformation appears to change their nature, so this may prove to be very thorny. [Edit] I have found a tractable form for $e_1(z,\alpha;q)$ using the formula \begin{align}\exp\int_0^z\ln\varphi(y,q)\,dy=&e^{\pi qz^3/3-\pi z(q+q^{-1})/6}\varphi^z(z,q)\\ &\cdot\prod_{k\ge1}\underbrace{\bigg(\frac{1-e^{-2k\pi q-2\pi qz}}{1-e^{-2k\pi q+2\pi qz}}\bigg)^k}_{p_1(z,q)}\underbrace{\bigg(\frac{1-e^{-2k\pi/q+2i\pi z}}{1-e^{-2k\pi/q-2i\pi z}}\bigg)^{ik/q}}_{p_2(z,q)}:\tag5 \end{align} I've posted the details as an answer.",,"['complex-analysis', 'elliptic-functions']"
36,Complex exponential series convergence $\sum_{n=0}^{\infty} \frac{z^n}{n!}$,Complex exponential series convergence,\sum_{n=0}^{\infty} \frac{z^n}{n!},"I'm hoping someone can help me with the following question from Stein and Shakarchi Volume 1 on Fourier Analysis (p. 24): For $z \in \mathbb C$, we define the complex exponential by  $$\sum_{n=0}^{\infty} \frac{z^n}{n!}.$$  Prove that the above definition makes sense, by showing the series converges for every complex number $z$. Moreover, show that the convergence is uniform on every bounded subset of $\mathbb C$. I know that convergence is easily shown with the ratio test or an absolute convergence argument, but I'm trying to prove convergence formally, and keep getting stuck. So far, I've tried the following. A series converges if the sequence of partial sums  $$\sum_{j=0}^{n} \frac{z^j}{j!}$$  converges as $n \to \infty$. So showing that  $$\lim_{n \to \infty} \left| \sum_{j=0}^{n} \frac{z^j}{j!} - e^z \right| = 0$$  appears to be the goal. We could also use the $N-\epsilon$ definition, which may help, or show the sequence is Cauchy. But I can't seem to get any of these to work. With the uniform convergence, I seem to run into the same problems. Any help or hints would be appreciated.","I'm hoping someone can help me with the following question from Stein and Shakarchi Volume 1 on Fourier Analysis (p. 24): For $z \in \mathbb C$, we define the complex exponential by  $$\sum_{n=0}^{\infty} \frac{z^n}{n!}.$$  Prove that the above definition makes sense, by showing the series converges for every complex number $z$. Moreover, show that the convergence is uniform on every bounded subset of $\mathbb C$. I know that convergence is easily shown with the ratio test or an absolute convergence argument, but I'm trying to prove convergence formally, and keep getting stuck. So far, I've tried the following. A series converges if the sequence of partial sums  $$\sum_{j=0}^{n} \frac{z^j}{j!}$$  converges as $n \to \infty$. So showing that  $$\lim_{n \to \infty} \left| \sum_{j=0}^{n} \frac{z^j}{j!} - e^z \right| = 0$$  appears to be the goal. We could also use the $N-\epsilon$ definition, which may help, or show the sequence is Cauchy. But I can't seem to get any of these to work. With the uniform convergence, I seem to run into the same problems. Any help or hints would be appreciated.",,"['sequences-and-series', 'complex-analysis', 'fourier-analysis', 'fourier-series']"
37,"Prob. 14, Chap. 3, in Baby Rudin: The arithmetic mean of a complex sequence","Prob. 14, Chap. 3, in Baby Rudin: The arithmetic mean of a complex sequence",,"Here's Prob. 14, Chap. 3, in the book Principles of Mathematical Analysis by Walter Rudin, 3rd edition: If $\left\{ s_n \right\}$ is a complex sequence, define its arithmetic mean $\sigma_n$ by $$ \sigma_n = \frac{s_0 + s_1 + \cdots + s_n}{n+1} \ \ \ (n = 0, 1, 2, \ldots). $$ (a) If $\lim s_n = s$ , prove that $\lim \ \sigma_n = s$ . (b) Construct a sequence $\left\{ s_n \right\}$ which does not converge, although $\lim \ \sigma_n = 0$ . (c) Can it happen that $s_n > 0$ for all $n$ and that $\lim \sup s_n = \infty$ , although $\lim \ \sigma_n = 0$ ? (d) Put $a_n = s_n - s_{n-1}$ , for $n \geq 1$ . Show that $$s_n - \sigma_n = \frac{1}{n+1} \sum_{k=1}^n k a_k.$$ Assume that $\lim \left( n a_n \right) = 0$ and that $\left\{ \sigma_n \right\}$ converges. Prove that $\left\{ s_n \right\}$ converges. [This gives a converse of (a), but under the aditional assumption that $n a_n \to 0$ . ] (e) Derive the last condition from a weaker hypothesis: Assume $M < \infty$ , $\left\vert n a_n \right\vert \leq M$ for all $n$ , and $\lim \ \sigma_n = \sigma$ . Prove that $\lim s_n  = \sigma$ , by completing the following outline: If $m < n$ , then $$s_n - \sigma_n = \frac{m+1}{n-m} \left( \sigma_n - \sigma_m \right) + \frac{1}{n-m} \sum_{i=m+1}^n \left( s_n - s_i \right).$$ For these $i$ , $$ \left\vert s_n - s_i \right\vert \leq \frac{(n-i)M}{i+1} \leq \frac{(n-m-1)M}{m+2}.$$ Fix $\varepsilon > 0$ and associate with each $n$ the integer $m$ that satisfies $$ m \leq \frac{n-\varepsilon}{1+ \varepsilon} < m +1.$$ Then $\frac{m+1}{n-m} \leq \frac{1}{\varepsilon}$ and $\left\vert s_n - s_i \right\vert < M \varepsilon$ . Hence $$ \lim_{n\to\infty} \sup \left\vert s_n - \sigma \right\vert \leq M \varepsilon.$$ Since $\varepsilon$ was arbitrary, $\lim s_n = \sigma$ . My effort: Part (a): If $\lim s_n = s$ , then we can find a natural number $N$ such that $n > N$ implies that $$ \left\vert s_n - s \right\vert < 1.$$ So, for $n > N$ , we have \begin{align} \left\vert \sigma_n - s \right\vert &= \left\vert \frac{ s_0 + s_1 + \cdots + s_n}{n +1} - s \right\vert \\ &\leq \frac{1}{n+1} \left( \left\vert s_0 - s \right\vert +  \cdots + \left\vert s_N - s \right\vert + \cdots + \left\vert s_n - s \right\vert \right) \\ &\leq \frac{1}{n+1} \left( (N+1) \max \left\{ \left\vert s_0 - s \right\vert, \ldots,  \left\vert s_N - s \right\vert \right\} + \left\vert s_{N+1} - s \right\vert + \cdots + \left\vert s_n - s \right\vert \right) \\ &< \frac{1}{n+1} \left( (N+1) \max \left\{ \left\vert s_0 - s \right\vert, \ldots,  \left\vert s_N - s \right\vert \right\} + (n-N)  \right) \end{align} Let $\varepsilon > 0$ be given. What next? Part (b): Let $s_n = (-1){n+1}$ for $n = 0, 1, 2, \ldots$ . Then $$ \sigma_n = \begin{cases} \frac{1}{n+1} \ \mbox{ if } n \mbox{ is even}; \\ 0 \ \mbox{ if } n \mbox{ is odd}. \end{cases} $$ Then $\left\{ s_n \right\}$ fails to converge, but $\lim \ \sigma_n = 0$ . Is this example correct? Part (c): My feeling is the answer is no, but I cannot establish this rigorously. How to? Part (d): If we put $a_n = s_n - s_{n-1}$ , for $n \geq 1$ , then $s_n = a_0 + s_1 + \cdots + a_n$ , and so \begin{align} s_n - \sigma_n &= s_n - \frac{ s_0 + s_1 + \cdots + s_n}{n+1} \\ &= \frac{ (n+1) s_n - s_0 - s_1 - \cdots - s_n }{n+1} \\  &= \frac{ (n+1) \left( s_0 + a_1 + \cdots + a_n \right) - s_0 - \left( s_0 + a_1 \right) - \left( s_0 + a_1 + a_2 \right) - \cdot -  \left( s_0 + a_1 +  \cdots + a_n \right) }{n+1} \\ &= \frac{ a_1 + 2 a_2 + \cdots + n a_n }{n+1}. \end{align} Now we assume that $\lim_{n \to \infty} n a_n = 0$ and that $\left\{ \sigma_n \right\}$ converges. How to show that $\left\{ s_n \right\}$ convreges? Part (e): If $m < n$ , then \begin{align} & \frac{ m+1 }{ n-m } \left( \sigma_n - \sigma_m \right) + \frac{1}{n-m} \sum_{i = m+1}^n \left( s_n - s_i \right) \\ &= \frac{ m+1 }{ n-m } \left( \frac{ s_0 + s_1 + \cdots + s_n}{n+1} - \frac{ s_0 + s_1 + \cdots + s_m}{m+1}  \right) + \frac{1}{n-m} \sum_{i = m+1}^n \left( s_n - s_i \right) \\ &= s_n + \frac{1}{n-m} \left[ (m+1) \frac{ s_0 + \cdots + s_n}{n+1} - \left( s_0 + \cdots + s_n \right) \right] \\ &= s_n - \sigma_n. \end{align} How to proceed from here?","Here's Prob. 14, Chap. 3, in the book Principles of Mathematical Analysis by Walter Rudin, 3rd edition: If is a complex sequence, define its arithmetic mean by (a) If , prove that . (b) Construct a sequence which does not converge, although . (c) Can it happen that for all and that , although ? (d) Put , for . Show that Assume that and that converges. Prove that converges. [This gives a converse of (a), but under the aditional assumption that . ] (e) Derive the last condition from a weaker hypothesis: Assume , for all , and . Prove that , by completing the following outline: If , then For these , Fix and associate with each the integer that satisfies Then and . Hence Since was arbitrary, . My effort: Part (a): If , then we can find a natural number such that implies that So, for , we have Let be given. What next? Part (b): Let for . Then Then fails to converge, but . Is this example correct? Part (c): My feeling is the answer is no, but I cannot establish this rigorously. How to? Part (d): If we put , for , then , and so Now we assume that and that converges. How to show that convreges? Part (e): If , then How to proceed from here?","\left\{ s_n \right\} \sigma_n  \sigma_n = \frac{s_0 + s_1 + \cdots + s_n}{n+1} \ \ \ (n = 0, 1, 2, \ldots).  \lim s_n = s \lim \ \sigma_n = s \left\{ s_n \right\} \lim \ \sigma_n = 0 s_n > 0 n \lim \sup s_n = \infty \lim \ \sigma_n = 0 a_n = s_n - s_{n-1} n \geq 1 s_n - \sigma_n = \frac{1}{n+1} \sum_{k=1}^n k a_k. \lim \left( n a_n \right) = 0 \left\{ \sigma_n \right\} \left\{ s_n \right\} n a_n \to 0 M < \infty \left\vert n a_n \right\vert \leq M n \lim \ \sigma_n = \sigma \lim s_n  = \sigma m < n s_n - \sigma_n = \frac{m+1}{n-m} \left( \sigma_n - \sigma_m \right) + \frac{1}{n-m} \sum_{i=m+1}^n \left( s_n - s_i \right). i  \left\vert s_n - s_i \right\vert \leq \frac{(n-i)M}{i+1} \leq \frac{(n-m-1)M}{m+2}. \varepsilon > 0 n m  m \leq \frac{n-\varepsilon}{1+ \varepsilon} < m +1. \frac{m+1}{n-m} \leq \frac{1}{\varepsilon} \left\vert s_n - s_i \right\vert < M \varepsilon  \lim_{n\to\infty} \sup \left\vert s_n - \sigma \right\vert \leq M \varepsilon. \varepsilon \lim s_n = \sigma \lim s_n = s N n > N  \left\vert s_n - s \right\vert < 1. n > N \begin{align}
\left\vert \sigma_n - s \right\vert &= \left\vert \frac{ s_0 + s_1 + \cdots + s_n}{n +1} - s \right\vert \\
&\leq \frac{1}{n+1} \left( \left\vert s_0 - s \right\vert +  \cdots + \left\vert s_N - s \right\vert + \cdots + \left\vert s_n - s \right\vert \right) \\
&\leq \frac{1}{n+1} \left( (N+1) \max \left\{ \left\vert s_0 - s \right\vert, \ldots,  \left\vert s_N - s \right\vert \right\} + \left\vert s_{N+1} - s \right\vert + \cdots + \left\vert s_n - s \right\vert \right) \\
&< \frac{1}{n+1} \left( (N+1) \max \left\{ \left\vert s_0 - s \right\vert, \ldots,  \left\vert s_N - s \right\vert \right\} + (n-N)  \right)
\end{align} \varepsilon > 0 s_n = (-1){n+1} n = 0, 1, 2, \ldots  \sigma_n = \begin{cases} \frac{1}{n+1} \ \mbox{ if } n \mbox{ is even}; \\ 0 \ \mbox{ if } n \mbox{ is odd}. \end{cases}  \left\{ s_n \right\} \lim \ \sigma_n = 0 a_n = s_n - s_{n-1} n \geq 1 s_n = a_0 + s_1 + \cdots + a_n \begin{align}
s_n - \sigma_n &= s_n - \frac{ s_0 + s_1 + \cdots + s_n}{n+1} \\
&= \frac{ (n+1) s_n - s_0 - s_1 - \cdots - s_n }{n+1} \\ 
&= \frac{ (n+1) \left( s_0 + a_1 + \cdots + a_n \right) - s_0 - \left( s_0 + a_1 \right) - \left( s_0 + a_1 + a_2 \right) - \cdot -  \left( s_0 + a_1 +  \cdots + a_n \right) }{n+1} \\
&= \frac{ a_1 + 2 a_2 + \cdots + n a_n }{n+1}.
\end{align} \lim_{n \to \infty} n a_n = 0 \left\{ \sigma_n \right\} \left\{ s_n \right\} m < n \begin{align}
& \frac{ m+1 }{ n-m } \left( \sigma_n - \sigma_m \right) + \frac{1}{n-m} \sum_{i = m+1}^n \left( s_n - s_i \right) \\
&= \frac{ m+1 }{ n-m } \left( \frac{ s_0 + s_1 + \cdots + s_n}{n+1} - \frac{ s_0 + s_1 + \cdots + s_m}{m+1}  \right) + \frac{1}{n-m} \sum_{i = m+1}^n \left( s_n - s_i \right) \\
&= s_n + \frac{1}{n-m} \left[ (m+1) \frac{ s_0 + \cdots + s_n}{n+1} - \left( s_0 + \cdots + s_n \right) \right] \\
&= s_n - \sigma_n.
\end{align}","['real-analysis', 'sequences-and-series', 'complex-analysis', 'analysis', 'convergence-divergence']"
38,If $f$ and $g$ are branches of $z^a$ and $z^b$ respectively show that $fg$ is a branch of $z^{a+b}$,If  and  are branches of  and  respectively show that  is a branch of,f g z^a z^b fg z^{a+b},"Suppose $f: G\rightarrow \mathbb{C}$ is a branch of $z^a$. Then $f(z) = e^{ah_1(z)}$ for all $z\in G$. Likewise if $g:G\rightarrow \mathbb{C}$ is a branch of $z^b$ then $g(z) = e^{bh_2(z)}$ for all $z\in G$. Here $h_1$ and $h_2$ are branches of the logarithm on $G$, and hence they differ by $2\pi k i$ with $k\in \mathbb{Z}$. However then $fg(z) = f(z)g(z) = e^{ah_1}\cdot e^{b(h_1+2\pi k i)}= e^{(a+b)h_1+2\pi k b i}$, which is not a branch of $z^{a+b}$. Question: Should I be using the same branch of $\log$ when defining the branches of $z^a$ and $z^b$. That is, should I write $g(z) = e^{bh_1(z)}$, beacause then everything works out. Also, why should I be choosing the same $\log$. Thanks.","Suppose $f: G\rightarrow \mathbb{C}$ is a branch of $z^a$. Then $f(z) = e^{ah_1(z)}$ for all $z\in G$. Likewise if $g:G\rightarrow \mathbb{C}$ is a branch of $z^b$ then $g(z) = e^{bh_2(z)}$ for all $z\in G$. Here $h_1$ and $h_2$ are branches of the logarithm on $G$, and hence they differ by $2\pi k i$ with $k\in \mathbb{Z}$. However then $fg(z) = f(z)g(z) = e^{ah_1}\cdot e^{b(h_1+2\pi k i)}= e^{(a+b)h_1+2\pi k b i}$, which is not a branch of $z^{a+b}$. Question: Should I be using the same branch of $\log$ when defining the branches of $z^a$ and $z^b$. That is, should I write $g(z) = e^{bh_1(z)}$, beacause then everything works out. Also, why should I be choosing the same $\log$. Thanks.",,['complex-analysis']
39,Evaluating this complicated integral using complex analysis,Evaluating this complicated integral using complex analysis,,"I am trying to evaluate this integral: $$\boxed{\int_{-\pi}^\pi\sin(2\cos\theta)\cos((2m+1)\theta)\,d\theta}$$ where $m\in\mathbb{N}$, using complex analysis methods. What I have done is to find the residue of $\sin(z+\frac 1z)$: Since $$\sin(z+\frac 1z)=\sum_{k=0}^\infty\frac{(-1)^k(z+z^{-1})^{2k+1}}{(2k+1)!}$$, and using the Binomial theorem, we have $$(z+z^{-1})^{2k+1}=\sum_{r=0}^{2k+1}{{2k+1}\choose r}z^{2k+1-2r}$$. Combining these two facts we have that the residue (coefficient of $z^{-1}$) is: $$\sum_{k=0}^\infty\frac{(-1)^k}{(2k+1)!}{{2k+1}\choose{k+1}}$$. After this I am kind of stuck. I am aware of the standard technique of substituting $\cos\theta=\frac{z+z^{-1}}{2}$, $d\theta=\frac{dz}{iz}$, etc, but I am not sure what to do with the $\cos((2m+1)\theta)$. Thanks for any help. By the way, if it helps, the answer I am supposed to get is $$\boxed{2\pi\sum_{k=m}^\infty\frac{(-1)^k}{(2k+1)!}{{2k+1}\choose {k-m}}}$$. Update: Using David Holden's excellent hint, I proceded to find the residue of the integrand. So the integral becomes $\frac{1}{2i}\int_C\sin(z+z^{-1})(z^{2m}+z^{-2m-2})\,dz$. I find the residue of the integrand to be $$\sum_{k=m}^\infty \frac{(-1)^k}{(2k+1)!}{{2k+1}\choose{k+m+1}}+\sum_{k=0}^\infty\frac{(-1)^k}{(2k+1)!}{{2k+1}\choose{k-m}}$$ I may have made a mistake along the way, I can't get to the final answer.","I am trying to evaluate this integral: $$\boxed{\int_{-\pi}^\pi\sin(2\cos\theta)\cos((2m+1)\theta)\,d\theta}$$ where $m\in\mathbb{N}$, using complex analysis methods. What I have done is to find the residue of $\sin(z+\frac 1z)$: Since $$\sin(z+\frac 1z)=\sum_{k=0}^\infty\frac{(-1)^k(z+z^{-1})^{2k+1}}{(2k+1)!}$$, and using the Binomial theorem, we have $$(z+z^{-1})^{2k+1}=\sum_{r=0}^{2k+1}{{2k+1}\choose r}z^{2k+1-2r}$$. Combining these two facts we have that the residue (coefficient of $z^{-1}$) is: $$\sum_{k=0}^\infty\frac{(-1)^k}{(2k+1)!}{{2k+1}\choose{k+1}}$$. After this I am kind of stuck. I am aware of the standard technique of substituting $\cos\theta=\frac{z+z^{-1}}{2}$, $d\theta=\frac{dz}{iz}$, etc, but I am not sure what to do with the $\cos((2m+1)\theta)$. Thanks for any help. By the way, if it helps, the answer I am supposed to get is $$\boxed{2\pi\sum_{k=m}^\infty\frac{(-1)^k}{(2k+1)!}{{2k+1}\choose {k-m}}}$$. Update: Using David Holden's excellent hint, I proceded to find the residue of the integrand. So the integral becomes $\frac{1}{2i}\int_C\sin(z+z^{-1})(z^{2m}+z^{-2m-2})\,dz$. I find the residue of the integrand to be $$\sum_{k=m}^\infty \frac{(-1)^k}{(2k+1)!}{{2k+1}\choose{k+m+1}}+\sum_{k=0}^\infty\frac{(-1)^k}{(2k+1)!}{{2k+1}\choose{k-m}}$$ I may have made a mistake along the way, I can't get to the final answer.",,['complex-analysis']
40,Convergence of a power series and interchanging order of summation and integration.,Convergence of a power series and interchanging order of summation and integration.,,"If we have the expression $$f(x) = \frac{1}{(2\pi i)^n} \int_{\gamma_1} \int_{\gamma_2} \cdots \int_{\gamma_n} f(z) \prod_{j=1}^n \left( \sum_{i=0}^{\infty} \frac{x_j^i}{z_j^{i+1}} \right)dz_j.$$ How would I show that the series $\prod_{j=1}^{n} \sum_{i=0}^{\infty} \frac{x_j^i}{z_j^{i+1}}dz_j$ converges absolutely, such that I can write $f(x)$ as $$f(x) = \frac{1}{(2\pi i)^n} \sum_{i=0}^{\infty} \prod_{j=1}^n \int_{\gamma_j} \frac{f(z)}{z_j^{i+1}}dz_j?$$ Note that this is a small argument that makes up a larger proof that I'm working on.","If we have the expression $$f(x) = \frac{1}{(2\pi i)^n} \int_{\gamma_1} \int_{\gamma_2} \cdots \int_{\gamma_n} f(z) \prod_{j=1}^n \left( \sum_{i=0}^{\infty} \frac{x_j^i}{z_j^{i+1}} \right)dz_j.$$ How would I show that the series $\prod_{j=1}^{n} \sum_{i=0}^{\infty} \frac{x_j^i}{z_j^{i+1}}dz_j$ converges absolutely, such that I can write $f(x)$ as $$f(x) = \frac{1}{(2\pi i)^n} \sum_{i=0}^{\infty} \prod_{j=1}^n \int_{\gamma_j} \frac{f(z)}{z_j^{i+1}}dz_j?$$ Note that this is a small argument that makes up a larger proof that I'm working on.",,['sequences-and-series']
41,Some problems to understand $kx-\omega t$.,Some problems to understand .,kx-\omega t,"Travelling waves are of the form $f(x-ct)$, where $c$ is the speed. Now if we have something like $$ u(x,t)=e^{i(kx-\omega t)} \tag{$*$} $$ when I see it right, we can write this as $$ u(x,t)=e^{\frac{i}{k}(x-ct)},\quad c:=\omega/k. $$ Hence, am I right to say that $(*)$ is a travelling wave, winding around the $x-$axis to the right with speed $\omega/k$? What I am a bit confused about is that we now have the factor $1/k$. Moreover, when considering $f(x-ct)$ we have one speed $c$ which is multiplicatd with $t$; here, we seem to have two kind of speeds (some spatial, namely $k$, which is multiplied with space $x$ and some temporal, namely $\omega$, which is multiplied with time $t$. In other words, I am not sure what $kx-\omega t$ actually means.","Travelling waves are of the form $f(x-ct)$, where $c$ is the speed. Now if we have something like $$ u(x,t)=e^{i(kx-\omega t)} \tag{$*$} $$ when I see it right, we can write this as $$ u(x,t)=e^{\frac{i}{k}(x-ct)},\quad c:=\omega/k. $$ Hence, am I right to say that $(*)$ is a travelling wave, winding around the $x-$axis to the right with speed $\omega/k$? What I am a bit confused about is that we now have the factor $1/k$. Moreover, when considering $f(x-ct)$ we have one speed $c$ which is multiplicatd with $t$; here, we seem to have two kind of speeds (some spatial, namely $k$, which is multiplied with space $x$ and some temporal, namely $\omega$, which is multiplied with time $t$. In other words, I am not sure what $kx-\omega t$ actually means.",,['complex-analysis']
42,Supplementary Books to Complex Analysis of Rudin's RCA?,Supplementary Books to Complex Analysis of Rudin's RCA?,,"I will be doing a reading course in the complex analysis starting on this Fall Semester. The assigned book is Rudin's Real and Complex Analysis. From my understanding, Rudin treats complex analysis very elegantly, but very terse. I am curious if you could suggest some books in the complex analysis that can accomodate Rudin, with particular emphasis on the extensive treatment and/or clear explanations. I am embarrassed to ask my professor as I do not want to impose a bad impression on me. Also, are previous chapters in Rudin-RCA a must requirement for later chapters in the complex analysis? I am currently reading through Berberian and Kolmogorov/Fomin to learn some basics of measure theory and banach space, but I have not completely learned them yet.","I will be doing a reading course in the complex analysis starting on this Fall Semester. The assigned book is Rudin's Real and Complex Analysis. From my understanding, Rudin treats complex analysis very elegantly, but very terse. I am curious if you could suggest some books in the complex analysis that can accomodate Rudin, with particular emphasis on the extensive treatment and/or clear explanations. I am embarrassed to ask my professor as I do not want to impose a bad impression on me. Also, are previous chapters in Rudin-RCA a must requirement for later chapters in the complex analysis? I am currently reading through Berberian and Kolmogorov/Fomin to learn some basics of measure theory and banach space, but I have not completely learned them yet.",,['complex-analysis']
43,Jordan curve theorem for a simple polygon (elementary proof),Jordan curve theorem for a simple polygon (elementary proof),,Let $C$ be a simple (Jordan) polygon in the plane. I would like to prove the Jordan curve theorem for $C$ using an elementary method. I think that we can prove it using the winding number (via complex analysis) with respect to $C$. Am I mistaken? Related question: Triangle inside a simply connected open subset of the complex plane .,Let $C$ be a simple (Jordan) polygon in the plane. I would like to prove the Jordan curve theorem for $C$ using an elementary method. I think that we can prove it using the winding number (via complex analysis) with respect to $C$. Am I mistaken? Related question: Triangle inside a simply connected open subset of the complex plane .,,"['complex-analysis', 'geometry', 'algebraic-topology']"
44,Finding all $z\in \mathbb{C}$ such that the series $\sum\limits_{n=1}^{\infty} \frac{1}{1+z^n}$ converges,Finding all  such that the series  converges,z\in \mathbb{C} \sum\limits_{n=1}^{\infty} \frac{1}{1+z^n},"I am trying to find out all $z\in \mathbb{C}$ such that the series $\displaystyle \sum_{n=1}^{\infty} \frac{1}{1+z^n}$ converges. I notice that for $\left|z\right|\leq 1$, we have $\left|1+z^n\right|\leq 1+\left|z\right|^n\leq 1 + 1=2$ and hence $\limsup_{n\to \infty}\frac{1}{1+z^n}\ge 1/2$ which means that $\frac{1}{1+z^n}$ does not go to zero and so the series does not converge for $|z|\leq 1$. $\left|\frac{1}{1+z^n}\right|=\sqrt{1/\left(1+2\Re(z^n)+\left|z\right|^{2n}\right)}$ and I suspect $1/\left(1+2\Re(z^n)+\left|z\right|^{2n}\right)^{1/2n}$  goes to $1/\left|z\right|$ but I am unable to prove that. Edit:  Suppose $|z|>1$. Suppose $z=r(\cos\theta + i \sin \theta)$ with $r>1$. Then $\displaystyle |1+z^n|=\sqrt{1+2r^n\cos n\theta+r^{2n}}>(r^n-1)$, so $\displaystyle \frac{1}{|1+z^n|}<\frac{1}{r^n-1}$. We will try to prove that $\displaystyle \sum \frac{1}{r^n-1}$ is convergent which will give us our desired result by the comparison test. Note that $\displaystyle \frac{r^n-1}{r^{n+1}-1}=\frac{r^{n-1}+\dots+1}{r^n+\dots+1}=1- (r-1)\frac{r^n}{r^{n+1}-1}$ which goes to $1/r<1$ and hence $\displaystyle \sum \frac{1}{r^n-1}$ is convergent by the ratio test.","I am trying to find out all $z\in \mathbb{C}$ such that the series $\displaystyle \sum_{n=1}^{\infty} \frac{1}{1+z^n}$ converges. I notice that for $\left|z\right|\leq 1$, we have $\left|1+z^n\right|\leq 1+\left|z\right|^n\leq 1 + 1=2$ and hence $\limsup_{n\to \infty}\frac{1}{1+z^n}\ge 1/2$ which means that $\frac{1}{1+z^n}$ does not go to zero and so the series does not converge for $|z|\leq 1$. $\left|\frac{1}{1+z^n}\right|=\sqrt{1/\left(1+2\Re(z^n)+\left|z\right|^{2n}\right)}$ and I suspect $1/\left(1+2\Re(z^n)+\left|z\right|^{2n}\right)^{1/2n}$  goes to $1/\left|z\right|$ but I am unable to prove that. Edit:  Suppose $|z|>1$. Suppose $z=r(\cos\theta + i \sin \theta)$ with $r>1$. Then $\displaystyle |1+z^n|=\sqrt{1+2r^n\cos n\theta+r^{2n}}>(r^n-1)$, so $\displaystyle \frac{1}{|1+z^n|}<\frac{1}{r^n-1}$. We will try to prove that $\displaystyle \sum \frac{1}{r^n-1}$ is convergent which will give us our desired result by the comparison test. Note that $\displaystyle \frac{r^n-1}{r^{n+1}-1}=\frac{r^{n-1}+\dots+1}{r^n+\dots+1}=1- (r-1)\frac{r^n}{r^{n+1}-1}$ which goes to $1/r<1$ and hence $\displaystyle \sum \frac{1}{r^n-1}$ is convergent by the ratio test.",,['sequences-and-series']
45,Continuity on the set $K_{1/3}\times K_{1/3}$.,Continuity on the set .,K_{1/3}\times K_{1/3},"Let $K_{1/3}$ be the usual Cantor set, $Q=K_{1/3}\times K_{1/3}$ and $z_{n,k}$ the centers of the $4^n$ squares of the n-th step in the construction of $Q$. In some lecture notes I read it is stated without a proof that the sequence  $$g_n(z)=4^{-n}\sum\limits_{k=1}^{4^n} (z-z_{n,k})^{-1}$$ converges to a function $g$ which is continuous on $S^2$ and holomorhic off $Q$. The only thing that challenges me is the continuity of $g$ on the points of $Q$. Any ideas?","Let $K_{1/3}$ be the usual Cantor set, $Q=K_{1/3}\times K_{1/3}$ and $z_{n,k}$ the centers of the $4^n$ squares of the n-th step in the construction of $Q$. In some lecture notes I read it is stated without a proof that the sequence  $$g_n(z)=4^{-n}\sum\limits_{k=1}^{4^n} (z-z_{n,k})^{-1}$$ converges to a function $g$ which is continuous on $S^2$ and holomorhic off $Q$. The only thing that challenges me is the continuity of $g$ on the points of $Q$. Any ideas?",,"['real-analysis', 'complex-analysis']"
46,VERIFICATION: Prove that $\int_{-\infty}^{\infty}\frac{1-b+x^{2}}{\left(1-b+x^{2}\right)^{2}+4bx^{2}}dx=\pi$ for $0<b<1$,VERIFICATION: Prove that  for,\int_{-\infty}^{\infty}\frac{1-b+x^{2}}{\left(1-b+x^{2}\right)^{2}+4bx^{2}}dx=\pi 0<b<1,"I need some reassurance that what I did here actually shows what need to be shown. Please correct me if I'm wrong. In Donald Sarason's ""Notes on complex function theory"", this question appears at section VII.4, (pg 93) in the context of Cauchy's theorem for convex region. To be accurate, the exercise is Let $0<b<1$. Derive the equality $$\int_{-\infty}^{\infty}\frac{1-b+x^{2}}{\left(1-b+x^{2}\right)^{2}+4bx^{2}}dx=\pi$$ by integrating the function  $\left(1+z^{2}\right)^{-1}$ around the rectangle with vertices $\pm a,\pm a+i\sqrt{b}$ $a>0$ and taking limit as $a\rightarrow\infty$ I tried to follow the suggestion and got (by Cauchy's theorem for convex region): $$\int_{-a}^{a}\left(1+t^{2}\right)^{-1}dt+\int_{0}^{\sqrt{b}}\left(1+\left(a+it\right)^{2}\right)^{-1}\cdot i\cdot dt+\int_{a}^{-a}\left(1+\left(i\sqrt{b}+t\right)^{2}\right)^{-1}dt+\int_{\sqrt{b}}^{0}\left(1+\left(-a+it\right)^{2}\right)^{-1}\cdot i\cdot dt=0$$ Or in somewhat more conventional form: $$\int_{-a}^{a}\left(1+t^{2}\right)^{-1}dt-\int_{-a}^{a}\left(1+\left(i\sqrt{b}-t\right)^{2}\right)^{-1}dt=i\left[\int_{0}^{\sqrt{b}}\left(1+\left(-a-it\right)^{2}\right)^{-1}dt-\int_{0}^{\sqrt{b}}\left(1+\left(a+it\right)^{2}\right)^{-1}dt\right]$$ Assuming I didn't make any mistakes so far, we get that RHS is zero hence: $$\int_{-a}^{a}\left(1+\left(i\sqrt{b}-t\right)^{2}\right)^{-1}dt=\int_{-a}^{a}\left(1+t^{2}\right)^{-1}dt$$ Taking limit $a\rightarrow\infty$ gives us $\pi$ on the RHS. So We'll have to figure out what the LHS has to do with the function in the question... Cauchy's theorem gives us ""free of charge"" that the integral of any imaginary part will be equal to zero, so in order to simplify the real part, I'll multiply and divide by the complex conjugate of $1+\left(i\sqrt{b}-t\right)^{2} $ which is  $\overline{1-b+t^{2}-2i\sqrt{b}t}=1-b+t^{2}+2i\sqrt{b}t$ and get: $\int_{-a}^{a}\frac{1}{1-b+t^{2}-2i\sqrt{b}t}dt=\int_{-a}^{a}\frac{1-b+t^{2}+2i\sqrt{b}t}{\left(1-b+t^{2}-2i\sqrt{b}t\right)\left(1-b+t^{2}+2i\sqrt{b}t\right)}dt=\int_{-a}^{a}\frac{1-b+t^{2}+2i\sqrt{b}t}{\left(1-b+t^{2}\right)^{2}+4bt^{2}}dt$ hence (by preceding statement) we have: $$\lim_{a\rightarrow\infty}\int_{-a}^{a}\frac{1-b+t^{2}}{\left(1-b+t^{2}\right)^{2}+4bt^{2}}dt=\lim_{a\rightarrow\infty}\int_{-a}^{a}\left(1+t^{2}\right)^{-1}dt$$ And (as stated before and easy to see): $$\lim_{a\rightarrow\infty}\int_{-a}^{a}\left(1+t^{2}\right)^{-1}dt=\pi$$ So indeed  $$\int_{- \infty}^{\infty}\frac{1-b+t^{2}}{\left(1-b+t^{2}\right)^{2}+4bt^{2}}dt = \pi$$","I need some reassurance that what I did here actually shows what need to be shown. Please correct me if I'm wrong. In Donald Sarason's ""Notes on complex function theory"", this question appears at section VII.4, (pg 93) in the context of Cauchy's theorem for convex region. To be accurate, the exercise is Let $0<b<1$. Derive the equality $$\int_{-\infty}^{\infty}\frac{1-b+x^{2}}{\left(1-b+x^{2}\right)^{2}+4bx^{2}}dx=\pi$$ by integrating the function  $\left(1+z^{2}\right)^{-1}$ around the rectangle with vertices $\pm a,\pm a+i\sqrt{b}$ $a>0$ and taking limit as $a\rightarrow\infty$ I tried to follow the suggestion and got (by Cauchy's theorem for convex region): $$\int_{-a}^{a}\left(1+t^{2}\right)^{-1}dt+\int_{0}^{\sqrt{b}}\left(1+\left(a+it\right)^{2}\right)^{-1}\cdot i\cdot dt+\int_{a}^{-a}\left(1+\left(i\sqrt{b}+t\right)^{2}\right)^{-1}dt+\int_{\sqrt{b}}^{0}\left(1+\left(-a+it\right)^{2}\right)^{-1}\cdot i\cdot dt=0$$ Or in somewhat more conventional form: $$\int_{-a}^{a}\left(1+t^{2}\right)^{-1}dt-\int_{-a}^{a}\left(1+\left(i\sqrt{b}-t\right)^{2}\right)^{-1}dt=i\left[\int_{0}^{\sqrt{b}}\left(1+\left(-a-it\right)^{2}\right)^{-1}dt-\int_{0}^{\sqrt{b}}\left(1+\left(a+it\right)^{2}\right)^{-1}dt\right]$$ Assuming I didn't make any mistakes so far, we get that RHS is zero hence: $$\int_{-a}^{a}\left(1+\left(i\sqrt{b}-t\right)^{2}\right)^{-1}dt=\int_{-a}^{a}\left(1+t^{2}\right)^{-1}dt$$ Taking limit $a\rightarrow\infty$ gives us $\pi$ on the RHS. So We'll have to figure out what the LHS has to do with the function in the question... Cauchy's theorem gives us ""free of charge"" that the integral of any imaginary part will be equal to zero, so in order to simplify the real part, I'll multiply and divide by the complex conjugate of $1+\left(i\sqrt{b}-t\right)^{2} $ which is  $\overline{1-b+t^{2}-2i\sqrt{b}t}=1-b+t^{2}+2i\sqrt{b}t$ and get: $\int_{-a}^{a}\frac{1}{1-b+t^{2}-2i\sqrt{b}t}dt=\int_{-a}^{a}\frac{1-b+t^{2}+2i\sqrt{b}t}{\left(1-b+t^{2}-2i\sqrt{b}t\right)\left(1-b+t^{2}+2i\sqrt{b}t\right)}dt=\int_{-a}^{a}\frac{1-b+t^{2}+2i\sqrt{b}t}{\left(1-b+t^{2}\right)^{2}+4bt^{2}}dt$ hence (by preceding statement) we have: $$\lim_{a\rightarrow\infty}\int_{-a}^{a}\frac{1-b+t^{2}}{\left(1-b+t^{2}\right)^{2}+4bt^{2}}dt=\lim_{a\rightarrow\infty}\int_{-a}^{a}\left(1+t^{2}\right)^{-1}dt$$ And (as stated before and easy to see): $$\lim_{a\rightarrow\infty}\int_{-a}^{a}\left(1+t^{2}\right)^{-1}dt=\pi$$ So indeed  $$\int_{- \infty}^{\infty}\frac{1-b+t^{2}}{\left(1-b+t^{2}\right)^{2}+4bt^{2}}dt = \pi$$",,"['complex-analysis', 'proof-verification', 'complex-integration']"
47,Reordering a conditionally convergent series,Reordering a conditionally convergent series,,"I have the series $$\sum_{n=1}^\infty(-1)^{n+1}\frac{1}{n}=\ln(2),$$ and I want to reorder it to $$\sum_{n=1}^\infty\frac{8n-3}{2n(4n-3)(4n-1)}.$$ If we write the terms of the first series we get $1+\frac{1}{3}-\frac{1}{2}+\frac{1}{5}+\frac{1}{7}-\frac{1}{4}+\frac{1}{9}+\frac{1}{11}-\frac{1}{6}+...$, if we group each set of three successive terms we get $\frac{1}{6}+\frac{13}{140}+\frac{7}{198}+...$ 1 How do I show that this is equal to the second series? 2 How do I show that the second series cannot have the values $\ln(2)$? I was thinking about using partial fractions for the first one, but I'm not sure how.","I have the series $$\sum_{n=1}^\infty(-1)^{n+1}\frac{1}{n}=\ln(2),$$ and I want to reorder it to $$\sum_{n=1}^\infty\frac{8n-3}{2n(4n-3)(4n-1)}.$$ If we write the terms of the first series we get $1+\frac{1}{3}-\frac{1}{2}+\frac{1}{5}+\frac{1}{7}-\frac{1}{4}+\frac{1}{9}+\frac{1}{11}-\frac{1}{6}+...$, if we group each set of three successive terms we get $\frac{1}{6}+\frac{13}{140}+\frac{7}{198}+...$ 1 How do I show that this is equal to the second series? 2 How do I show that the second series cannot have the values $\ln(2)$? I was thinking about using partial fractions for the first one, but I'm not sure how.",,"['sequences-and-series', 'complex-analysis', 'convergence-divergence']"
48,Solving $z^3 e^{1-z}=1$ inside the unit circle,Solving  inside the unit circle,z^3 e^{1-z}=1,"Prove that $z^3 e^{1-z}=1$ has exactly two roots inside the circle $|z|=1$ . I showed that $z=1$ is a solution on the boundary of the circle, how can I find the other solution?","Prove that has exactly two roots inside the circle . I showed that is a solution on the boundary of the circle, how can I find the other solution?",z^3 e^{1-z}=1 |z|=1 z=1,"['complex-analysis', 'roots']"
49,Complex substitution allowed but changes result,Complex substitution allowed but changes result,,"It is well known that $$ I := \int_L \frac{1}{z} ~\text{d}z = 2 \pi i $$ where $L$ is the complex unit circle, parametrized by $\gamma(t) = e^{it}, 0 \leq t \leq 2 \pi$. However, using complex substitution, I obtain the following: by definition op complex line integrals, we have $$ I = \int_{t = 0}^{t = 2\pi} \frac{1}{e^{it}} \cdot i e^{it} ~\text{d}t $$ Since $e^{it}$ is complex differentiable everywhere, and since $1/z$ is complex differentiable on the entire complex unit circle $L$, we can use complex substitution: $u = e^{it}$ and $\text{d}u = i e^{it} ~\text{d}t$, hence $$ I = \int_{u = 1}^{u = 1} \frac{1}{u} ~\text{d}u = 0 $$ since the integral is from 1 to 1. Obviously, something went wrong. My teacher said that it was because both $1/z$ was not defined on the whole interior of $L$ (since $z = 0$ causes trouble) and because it's ""anti-derivative"" Log$(z)$ is not continuous on $L$ (it's not continuous on the negative real axis). If either $1/z$ was defined on the whole interior of $L$ or Log$(z)$ was continuous on $L$ itself, then the above would be true. For example, $$ \int_L z^2 ~\text{d}z = 0 $$ However, if you are just given $$ \int_{t = 0}^{t = 2\pi} \frac{1}{e^{it}} \cdot i e^{it} ~\text{d}t $$ Then you have no idea that this integral comes from some line integral over some line $L$. So my question is, what conditions have to be met in order to apply the equality $$ \int_{t = a}^{t = b} f(\gamma(t)) \cdot \gamma'(t) ~\text{d}t = \int_{t = \gamma(a)}^{t = \gamma(b)} f(t) ~\text{d}t $$ for $\gamma : [a, b] \to M$, $f : D \to \mathbb{C}$ such that $M \subset D$, and why can't I write $$ I = \int_{t = 0}^{t = 2\pi} \frac{1}{e^{it}} \cdot i e^{it} ~\text{d}t = \int_{u = 1}^{u = 1} \frac{1}{u} ~\text{d}u $$ My book on Complex Analysis simply says that $\gamma$ needs to be complex differentiable on $[a, b]$ (and $e^{it}$ is complex differentiable on $[0, 2 \pi]$) and that $f$ needs to be continuous on $M$ (and $1/z$ is continuous on $L$, the image of $e^{it}$). Either my book is wrong, or (most likely) I'm missing something.","It is well known that $$ I := \int_L \frac{1}{z} ~\text{d}z = 2 \pi i $$ where $L$ is the complex unit circle, parametrized by $\gamma(t) = e^{it}, 0 \leq t \leq 2 \pi$. However, using complex substitution, I obtain the following: by definition op complex line integrals, we have $$ I = \int_{t = 0}^{t = 2\pi} \frac{1}{e^{it}} \cdot i e^{it} ~\text{d}t $$ Since $e^{it}$ is complex differentiable everywhere, and since $1/z$ is complex differentiable on the entire complex unit circle $L$, we can use complex substitution: $u = e^{it}$ and $\text{d}u = i e^{it} ~\text{d}t$, hence $$ I = \int_{u = 1}^{u = 1} \frac{1}{u} ~\text{d}u = 0 $$ since the integral is from 1 to 1. Obviously, something went wrong. My teacher said that it was because both $1/z$ was not defined on the whole interior of $L$ (since $z = 0$ causes trouble) and because it's ""anti-derivative"" Log$(z)$ is not continuous on $L$ (it's not continuous on the negative real axis). If either $1/z$ was defined on the whole interior of $L$ or Log$(z)$ was continuous on $L$ itself, then the above would be true. For example, $$ \int_L z^2 ~\text{d}z = 0 $$ However, if you are just given $$ \int_{t = 0}^{t = 2\pi} \frac{1}{e^{it}} \cdot i e^{it} ~\text{d}t $$ Then you have no idea that this integral comes from some line integral over some line $L$. So my question is, what conditions have to be met in order to apply the equality $$ \int_{t = a}^{t = b} f(\gamma(t)) \cdot \gamma'(t) ~\text{d}t = \int_{t = \gamma(a)}^{t = \gamma(b)} f(t) ~\text{d}t $$ for $\gamma : [a, b] \to M$, $f : D \to \mathbb{C}$ such that $M \subset D$, and why can't I write $$ I = \int_{t = 0}^{t = 2\pi} \frac{1}{e^{it}} \cdot i e^{it} ~\text{d}t = \int_{u = 1}^{u = 1} \frac{1}{u} ~\text{d}u $$ My book on Complex Analysis simply says that $\gamma$ needs to be complex differentiable on $[a, b]$ (and $e^{it}$ is complex differentiable on $[0, 2 \pi]$) and that $f$ needs to be continuous on $M$ (and $1/z$ is continuous on $L$, the image of $e^{it}$). Either my book is wrong, or (most likely) I'm missing something.",,"['complex-analysis', 'derivatives', 'continuity', 'substitution', 'line-integrals']"
50,A complex polynomial satisfying $p(z)=p(\bar z) \forall z$ on the unit circle is constant,A complex polynomial satisfying  on the unit circle is constant,p(z)=p(\bar z) \forall z,"This question was part of a test on Complex Analysis. Let $p(z) \in \Bbb{C}$ be a complex polynomial such that $p(z)=p(\bar z) \forall z$ on the unit circle ($∣z∣=1$). Show that $p(z)$ is constant. Now, I think the best way to approach this is via the Identity Theorem, but I have not been able to come up with the appropriate functions to make it work. A more direct approach, that is assuming $p(z)=a_nz^n+...+a_1z+a_0={\bar a_n}{\bar z^n}+...+{\bar a_1}{\bar z}+\bar a_0$, did not help either. Any ideas?","This question was part of a test on Complex Analysis. Let $p(z) \in \Bbb{C}$ be a complex polynomial such that $p(z)=p(\bar z) \forall z$ on the unit circle ($∣z∣=1$). Show that $p(z)$ is constant. Now, I think the best way to approach this is via the Identity Theorem, but I have not been able to come up with the appropriate functions to make it work. A more direct approach, that is assuming $p(z)=a_nz^n+...+a_1z+a_0={\bar a_n}{\bar z^n}+...+{\bar a_1}{\bar z}+\bar a_0$, did not help either. Any ideas?",,"['complex-analysis', 'polynomials']"
51,Deck transformation of $p : Y \to X : z \mapsto z^3 - 3z$,Deck transformation of,p : Y \to X : z \mapsto z^3 - 3z,"Let $X = \mathbb{C} \setminus \{ \pm 2 \}$ and $Y = \mathbb{C} \setminus \{ \pm 1, \pm 2 \}$. The map $$ p : Y \to X : z \mapsto z^3 - 3z $$ is a 3-branched covering. Problem: Find $\operatorname{Deck}(Y/X)$, the group of Deck transformations of $Y$. My try: My only idea is that $\operatorname{Deck}(Y/X) = \pi_1(Y)$ when $Y$ is the universal covering, but I don't think it is.","Let $X = \mathbb{C} \setminus \{ \pm 2 \}$ and $Y = \mathbb{C} \setminus \{ \pm 1, \pm 2 \}$. The map $$ p : Y \to X : z \mapsto z^3 - 3z $$ is a 3-branched covering. Problem: Find $\operatorname{Deck}(Y/X)$, the group of Deck transformations of $Y$. My try: My only idea is that $\operatorname{Deck}(Y/X) = \pi_1(Y)$ when $Y$ is the universal covering, but I don't think it is.",,"['complex-analysis', 'algebraic-topology', 'riemann-surfaces', 'covering-spaces', 'mobius-transformation']"
52,To show an entire function is constant. (only with imaginary bound) [duplicate],To show an entire function is constant. (only with imaginary bound) [duplicate],,This question already has answers here : Showing Entire Function is Bounded [closed] (2 answers) Closed 8 years ago . Assume $|f(z)|\leq 1/|y|$ for all $z\in\mathbb{C}$. Here $f$ is entire and we express $z=x+iy$. Then is $f$ constant ?,This question already has answers here : Showing Entire Function is Bounded [closed] (2 answers) Closed 8 years ago . Assume $|f(z)|\leq 1/|y|$ for all $z\in\mathbb{C}$. Here $f$ is entire and we express $z=x+iy$. Then is $f$ constant ?,,['complex-analysis']
53,How to prove this complex inequality elegantly?,How to prove this complex inequality elegantly?,,"Question Let $z_{1,2}\in U(0,1)\subset \Bbb C$, prove that  $$\frac{|z_1|-|z_2|}{1-|z_1||z_2|}\le\left|\frac{z_1+z_2}{1+\overline{z_1}z_2}\right|\le\frac{|z_1|+|z_2|}{1+|z_1||z_2|}$$ Actually I haven't come up with any reasonably good proof so far. All I could do was simply use brute force, i.e., relations like $|z|^2=z\overline z$. When I finished my brute-force proof and rewound it, I found it could be simplified into the following form, which looks not as horrible: Let $w=2|z_1z_2|-z_1\bar {z_2}-z_2\bar{z_1}\ge 0$. Square the inequality, and denote the middle one as $\frac AB < 1$. Then  $$\frac{A-w}{B-w}\le\frac AB\le \frac{A+w}{B+w}$$ which is the desired result. Seems good. But indeed doesn't. Because it comes in hindsight : it's only after I had brute-forced and rewound that I formulated this short one. So apart from this one, is there any other more elegant or advanced proof? Incidentally, the structure $\displaystyle\frac{|x|\pm|y|}{1\pm|x||y|}$ frequently occurs, is it of any significance?","Question Let $z_{1,2}\in U(0,1)\subset \Bbb C$, prove that  $$\frac{|z_1|-|z_2|}{1-|z_1||z_2|}\le\left|\frac{z_1+z_2}{1+\overline{z_1}z_2}\right|\le\frac{|z_1|+|z_2|}{1+|z_1||z_2|}$$ Actually I haven't come up with any reasonably good proof so far. All I could do was simply use brute force, i.e., relations like $|z|^2=z\overline z$. When I finished my brute-force proof and rewound it, I found it could be simplified into the following form, which looks not as horrible: Let $w=2|z_1z_2|-z_1\bar {z_2}-z_2\bar{z_1}\ge 0$. Square the inequality, and denote the middle one as $\frac AB < 1$. Then  $$\frac{A-w}{B-w}\le\frac AB\le \frac{A+w}{B+w}$$ which is the desired result. Seems good. But indeed doesn't. Because it comes in hindsight : it's only after I had brute-forced and rewound that I formulated this short one. So apart from this one, is there any other more elegant or advanced proof? Incidentally, the structure $\displaystyle\frac{|x|\pm|y|}{1\pm|x||y|}$ frequently occurs, is it of any significance?",,"['complex-analysis', 'inequality', 'complex-numbers', 'alternative-proof']"
54,What is the complex line integral measuring? How do we motivate it?,What is the complex line integral measuring? How do we motivate it?,,How do we motivate it? I am not necessarily looking for a geometric answer to my question so much as I am looking for a way to motivate the idea of a complex line integral. For any path $\gamma$ and any function $f(z)$ we have $$\int_\gamma f(z)=\int f(\gamma(t))\gamma '(t)dt$$ and it turns out that this has a lot of power in terms of characterizing functions. But historically how did we make a decision to define things this way? What motivates this? I've gotten a lot of after the fact answers but I don't really feel like this is satisfactory. It turns out this is useful doesn't motivate its original discovery/definition very well. Possible questions: What is the complex line integral measuring?,How do we motivate it? I am not necessarily looking for a geometric answer to my question so much as I am looking for a way to motivate the idea of a complex line integral. For any path and any function we have and it turns out that this has a lot of power in terms of characterizing functions. But historically how did we make a decision to define things this way? What motivates this? I've gotten a lot of after the fact answers but I don't really feel like this is satisfactory. It turns out this is useful doesn't motivate its original discovery/definition very well. Possible questions: What is the complex line integral measuring?,\gamma f(z) \int_\gamma f(z)=\int f(\gamma(t))\gamma '(t)dt,"['integration', 'complex-analysis', 'soft-question']"
55,Definition of a esssential singularity - equivalence?,Definition of a esssential singularity - equivalence?,,"I previously held the conception that an essential singularity could be defined as a point $z_0$ of the function $f(z)$ for which: $$\lim_{z\rightarrow z_0}(z-z_0)^nf(z)$$ is not finite for any finite $n$. Although I don't think this definition is wrong (please correct me if it is), I am under the impression it is not the most useful. I think another definition of an essential singularity is: The point $z_0$ is an essential singularity of the function $f(z)$ if and only if: $$\lim_{z\rightarrow z_0}f(z)$$ can be made to take at least two different values (taking the point at infinity to be only one value) when approaching from two different directions. Would this definition/statement be correct? And if so can an equivalence be shown between these two definitions.","I previously held the conception that an essential singularity could be defined as a point $z_0$ of the function $f(z)$ for which: $$\lim_{z\rightarrow z_0}(z-z_0)^nf(z)$$ is not finite for any finite $n$. Although I don't think this definition is wrong (please correct me if it is), I am under the impression it is not the most useful. I think another definition of an essential singularity is: The point $z_0$ is an essential singularity of the function $f(z)$ if and only if: $$\lim_{z\rightarrow z_0}f(z)$$ can be made to take at least two different values (taking the point at infinity to be only one value) when approaching from two different directions. Would this definition/statement be correct? And if so can an equivalence be shown between these two definitions.",,['complex-analysis']
56,Cauchy Residue Theorem Integral,Cauchy Residue Theorem Integral,,I have been given the integral $$\int_0^ {2\pi} \frac{sin^2\theta} {2 - cos\theta} d\theta $$ I have use the substitutions $z=e^{i\theta}$ |$d\theta = \frac{1}{iz}dz$ and a lot of algebra to transform the integral into this $$\frac{-i}{2} \oint \frac{1}{z^2}\frac{(z-1)^2}{z^2-4z+1}dz$$ In order to find the residues i further broke the integral into $$\frac{-i}{2} \oint \frac{1}{z^2}\frac{(z-1)^2}{(z+-r_1)(z-r_2)}dz$$ where $r_1 = 2+\sqrt{3}$ and $r_2 = 2-\sqrt{3}$ giving me three residues at $z=0|z=r_1|z=r_2 $ My question is where do I go from here? Thanks.,I have been given the integral $$\int_0^ {2\pi} \frac{sin^2\theta} {2 - cos\theta} d\theta $$ I have use the substitutions $z=e^{i\theta}$ |$d\theta = \frac{1}{iz}dz$ and a lot of algebra to transform the integral into this $$\frac{-i}{2} \oint \frac{1}{z^2}\frac{(z-1)^2}{z^2-4z+1}dz$$ In order to find the residues i further broke the integral into $$\frac{-i}{2} \oint \frac{1}{z^2}\frac{(z-1)^2}{(z+-r_1)(z-r_2)}dz$$ where $r_1 = 2+\sqrt{3}$ and $r_2 = 2-\sqrt{3}$ giving me three residues at $z=0|z=r_1|z=r_2 $ My question is where do I go from here? Thanks.,,"['complex-analysis', 'definite-integrals', 'complex-numbers', 'contour-integration', 'residue-calculus']"
57,Does there exists such real analytic function? (NBHM 2016),Does there exists such real analytic function? (NBHM 2016),,"a)Let $f(z)=e^x+iv$ then Cauchy Riemann equation will give us contradiction thus this cannot be true as $e^x=v_y \text{and} 0=v_x$, now $v_x=0 \implies v=g(y)$ and first equation then gives $g'(y)=e^x$ which is not true. b) is true take the zero function. c) This is not true since $f$ is entire and bounded thus constant and $f(0)=1 \implies f(z)=1 \quad \forall z\in \Bbb{C} $ but that contradicts $|f(z)|\le e^{-|z|}\quad \forall z$. Am I correct?","a)Let $f(z)=e^x+iv$ then Cauchy Riemann equation will give us contradiction thus this cannot be true as $e^x=v_y \text{and} 0=v_x$, now $v_x=0 \implies v=g(y)$ and first equation then gives $g'(y)=e^x$ which is not true. b) is true take the zero function. c) This is not true since $f$ is entire and bounded thus constant and $f(0)=1 \implies f(z)=1 \quad \forall z\in \Bbb{C} $ but that contradicts $|f(z)|\le e^{-|z|}\quad \forall z$. Am I correct?",,['complex-analysis']
58,Determine if $f(z)$ has a branch point where it is not analtyic?,Determine if  has a branch point where it is not analtyic?,f(z),Let us say that you have a function $f(z)$ how would determine if the point $z=z_0$ is a branch point of $f(z)$ (and its order) given that $f(z)$ is not analytic at this point. (For reference: this question (and the links in the answer) Showing $1$ is not a branch point for $f(z) = z^2$? gives the case where $f(z)$ is not analytic at $z_0$),Let us say that you have a function $f(z)$ how would determine if the point $z=z_0$ is a branch point of $f(z)$ (and its order) given that $f(z)$ is not analytic at this point. (For reference: this question (and the links in the answer) Showing $1$ is not a branch point for $f(z) = z^2$? gives the case where $f(z)$ is not analytic at $z_0$),,"['complex-analysis', 'branch-points']"
59,Analytic function with vanishing derivatives.,Analytic function with vanishing derivatives.,,"A function that is analytic in the whole plane and which vanishes along with all its derivatives at any one point in the plane is identical to $0$. Now consider a function $f(z)$, which is supposedly analytic everywhere such that $$\lim_{z\rightarrow\infty}f^{(n)}(z)=0$$ for $n=0, 1, 2...$ Is the conclusion that $f(z)$ is identical to $0$ the only possibility?","A function that is analytic in the whole plane and which vanishes along with all its derivatives at any one point in the plane is identical to $0$. Now consider a function $f(z)$, which is supposedly analytic everywhere such that $$\lim_{z\rightarrow\infty}f^{(n)}(z)=0$$ for $n=0, 1, 2...$ Is the conclusion that $f(z)$ is identical to $0$ the only possibility?",,['complex-analysis']
60,Prove two polynomials are equal,Prove two polynomials are equal,,"define$$f^{-1}(a)=\{z\in \mathbb{C}:f(z)=a\}$$ $f$ and $g$ are polynomials, $$f^{-1}(0)=g^{-1}(0) ,f^{-1}(1)=g^{-1}(1)$$ prove $f=g$ I wonder if there is a complex analysis way to solve it?","define$$f^{-1}(a)=\{z\in \mathbb{C}:f(z)=a\}$$ $f$ and $g$ are polynomials, $$f^{-1}(0)=g^{-1}(0) ,f^{-1}(1)=g^{-1}(1)$$ prove $f=g$ I wonder if there is a complex analysis way to solve it?",,"['complex-analysis', 'polynomials']"
61,How to use Cauchy-Reimann equations to show that complex conjugate of a variable be treated as a constant,How to use Cauchy-Reimann equations to show that complex conjugate of a variable be treated as a constant,,Why can the complex conjugate of a variable be treated as a constant when differentiating with respect to that variable?,Why can the complex conjugate of a variable be treated as a constant when differentiating with respect to that variable?,,['complex-analysis']
62,"If an entire function satisfies $|f(z)| \leq C e^{M|z|}$, then $f(x)$ can't decay super-exponentially as $x\to\infty$","If an entire function satisfies , then  can't decay super-exponentially as",|f(z)| \leq C e^{M|z|} f(x) x\to\infty,"Let $f$ be a non-zero entire function.  Suppose there are positive real numbers $C$ and $M$ such that $|f| \leq C e^{M|z|}$ . Show that there is no function $g(x)$ , defined on $x>0$ with $\lim_{x \to \infty} g(x)=+\infty$ such that $f(x)=O(e^{-xg(x)})$ as $x \to \infty$ . Source: I'm reading Complex Analysis by Stein. From the assumption, I can know the order of $f$ is less than or equal to $1$ . Then how can I get from there?","Let be a non-zero entire function.  Suppose there are positive real numbers and such that . Show that there is no function , defined on with such that as . Source: I'm reading Complex Analysis by Stein. From the assumption, I can know the order of is less than or equal to . Then how can I get from there?",f C M |f| \leq C e^{M|z|} g(x) x>0 \lim_{x \to \infty} g(x)=+\infty f(x)=O(e^{-xg(x)}) x \to \infty f 1,"['complex-analysis', 'asymptotics']"
63,"Very tricky radius of convergence involving a non-monotonic summand,","Very tricky radius of convergence involving a non-monotonic summand,",,"Edit:  hints or solutions are welcome. This question is something weird that I have not seen before, so I don't have much of a starting point - hadamard's radius of convergence formula also doesn't seem helpful.  The series is: $$\sum_{n=0}^{\infty} \cos(\alpha(\sqrt{1+n^2}))z^n$$ The two-part question is: What is the radius of convergence if $\alpha$ is any real number?  What if $\alpha$ is a complex number? This is an old complex analysis test question, so I think the square root is complex whether $\alpha$  is real or complex. Thanks,","Edit:  hints or solutions are welcome. This question is something weird that I have not seen before, so I don't have much of a starting point - hadamard's radius of convergence formula also doesn't seem helpful.  The series is: $$\sum_{n=0}^{\infty} \cos(\alpha(\sqrt{1+n^2}))z^n$$ The two-part question is: What is the radius of convergence if $\alpha$ is any real number?  What if $\alpha$ is a complex number? This is an old complex analysis test question, so I think the square root is complex whether $\alpha$  is real or complex. Thanks,",,"['real-analysis', 'sequences-and-series', 'complex-analysis', 'convergence-divergence']"
64,Image of a function under unit disk.,Image of a function under unit disk.,,"What can we say about the image of the following function under open unit disk: $$f(z)=\frac{1}{(1-z)(1-a z)},\quad 0<a\leq1.$$ I think the complement of the image domain is a convex set. But I don't have proof.","What can we say about the image of the following function under open unit disk: $$f(z)=\frac{1}{(1-z)(1-a z)},\quad 0<a\leq1.$$ I think the complement of the image domain is a convex set. But I don't have proof.",,['complex-analysis']
65,evaluate the integral,evaluate the integral,,"Evaluate the integral from: $$\int_0^{\infty} \frac{x \cdot \sin(2x)}{x^2+3}dx$$ The way I approach this problem is $$\int_0^{\infty} \frac{x \cdot \sin(2x)}{x^2+3}dx  = \frac{1}{2}\int_{-\infty}^{\infty} \frac{z \cdot e^{i2z}}{(z - i\sqrt{3})(i+i\sqrt{3})}dz$$ and $$ \text{Res}_{i\sqrt3}(f(z)) = \frac{e ^{-2\sqrt3}}{2\sqrt3}$$ Then, the integral will be:  $$\frac{1}{2}\int_{-\infty}^{\infty} \frac{z \cdot e^{i2z}}{(z - i\sqrt{3})(i+i\sqrt{3})}dz = \frac{1}{2} \cdot 2\pi i \cdot \frac{e^{-2\sqrt3}}{2\sqrt3} = \frac{\pi i e^{-2\sqrt3}}{2\sqrt3}$$ Is my approach correct? if not, can someone show me? Sorry because I just learn about residue theorem and don't know if my work is correct or not.","Evaluate the integral from: $$\int_0^{\infty} \frac{x \cdot \sin(2x)}{x^2+3}dx$$ The way I approach this problem is $$\int_0^{\infty} \frac{x \cdot \sin(2x)}{x^2+3}dx  = \frac{1}{2}\int_{-\infty}^{\infty} \frac{z \cdot e^{i2z}}{(z - i\sqrt{3})(i+i\sqrt{3})}dz$$ and $$ \text{Res}_{i\sqrt3}(f(z)) = \frac{e ^{-2\sqrt3}}{2\sqrt3}$$ Then, the integral will be:  $$\frac{1}{2}\int_{-\infty}^{\infty} \frac{z \cdot e^{i2z}}{(z - i\sqrt{3})(i+i\sqrt{3})}dz = \frac{1}{2} \cdot 2\pi i \cdot \frac{e^{-2\sqrt3}}{2\sqrt3} = \frac{\pi i e^{-2\sqrt3}}{2\sqrt3}$$ Is my approach correct? if not, can someone show me? Sorry because I just learn about residue theorem and don't know if my work is correct or not.",,"['complex-analysis', 'analysis']"
66,Contour integrals in complex analysis that don't use a closed contour - do we have path independence?,Contour integrals in complex analysis that don't use a closed contour - do we have path independence?,,"I've noticed that the vast majority of integration problems that I work on in complex analysis are on closed contours, using the Residue Theorem.  (If the contour is not closed, we usually close it with a big circle or semi-circle or box.) Does anyone ever integrate from one starting point to a different ending point in complex analysis?  And, integrating on this non-closed path, would we have path-independence? Lately, I've been trying to make as close of a connection as possible between complex and real analysis.  My first mistake was in claiming that holomorphic functions are conservative, trying to agree with the Cauchy-Goursat integral theorem in a simply connected domain.  It turns out that the conjugate is conservative, but not the function itself. If we get path-independence in complex analysis, then it should follow that this is not a consequence of the integrand being conservative (it is not necessarily equivalent to a gradient field on $R^2$), but from something else.  What is this something else? Thanks,","I've noticed that the vast majority of integration problems that I work on in complex analysis are on closed contours, using the Residue Theorem.  (If the contour is not closed, we usually close it with a big circle or semi-circle or box.) Does anyone ever integrate from one starting point to a different ending point in complex analysis?  And, integrating on this non-closed path, would we have path-independence? Lately, I've been trying to make as close of a connection as possible between complex and real analysis.  My first mistake was in claiming that holomorphic functions are conservative, trying to agree with the Cauchy-Goursat integral theorem in a simply connected domain.  It turns out that the conjugate is conservative, but not the function itself. If we get path-independence in complex analysis, then it should follow that this is not a consequence of the integrand being conservative (it is not necessarily equivalent to a gradient field on $R^2$), but from something else.  What is this something else? Thanks,",,"['integration', 'complex-analysis', 'analyticity']"
67,"Let $f(z)$ be a function analytic in a domain containing the segment $[0,1]$ and satisfying $f(z+1)=azf(z)+p(z)$.",Let  be a function analytic in a domain containing the segment  and satisfying .,"f(z) [0,1] f(z+1)=azf(z)+p(z)","Let $f(z)$ be a function analytic in a domain containing the segment $[0,1]$ and satisfying   $$ f(z+1)=azf(z)+p(z) $$   in that domain, where $a\in\mathbb{R}$ and $p$ is a polynomial. Show that $f$ can be analytically continued to a domain $\{z\in\mathbb{C}\,:\,|\Im z|<\varepsilon\}$ for some $\varepsilon>0$. I don't quite know how to work with this. My attempt was to derive this equation until the polynomial disappears, but that gives me the equation (supposing $p$ has degree $(n-1)$) $$ f^{(n)}(z+1)=naf^{(n-1)}(z)+azf^{(n)}(z), $$ which I don't find helps much. I can't even think of a way to define this function which would just leave testing analyticity at each integer. Any help is greatly appreciated. Thank you","Let $f(z)$ be a function analytic in a domain containing the segment $[0,1]$ and satisfying   $$ f(z+1)=azf(z)+p(z) $$   in that domain, where $a\in\mathbb{R}$ and $p$ is a polynomial. Show that $f$ can be analytically continued to a domain $\{z\in\mathbb{C}\,:\,|\Im z|<\varepsilon\}$ for some $\varepsilon>0$. I don't quite know how to work with this. My attempt was to derive this equation until the polynomial disappears, but that gives me the equation (supposing $p$ has degree $(n-1)$) $$ f^{(n)}(z+1)=naf^{(n-1)}(z)+azf^{(n)}(z), $$ which I don't find helps much. I can't even think of a way to define this function which would just leave testing analyticity at each integer. Any help is greatly appreciated. Thank you",,"['complex-analysis', 'analytic-continuation']"
68,A question regarding a proof in Ahlfors,A question regarding a proof in Ahlfors,,"Ahlfors says the following: if $f (z) $ is analytic on a disc, then its integral along any closed path contained in the disc is $0$. The proof for this is the following: Let $F (z)=\int_\sigma  {f (z)dz}$ where $\sigma$ is a rectangular path that starts at a fixed point $z_0$ (they say in the middle of the disc),  and ends at $z$. Rectangular path in the sense that if we have a path from $(x_0, y_0) to (x, y)$, then we move from $(x_0, y_0)\to (x, y_0)\to (x, y)$, or $(x_0, y_0)\to (x_0, y)\to (x, y)$. So anyway, we have $F (z)= \int {f (z)dx+if (z)dy}$. Moving along the first rectangular path and differentiating wrt y, we get $dF/dy=if (z)$. Similarly, moving along the second path, we get $dF (z)/dx =f (z)$. This shows that $F (z)$ is analytic. We also have the fact that $\int {f (z) dz} $ is an exact differential, and hence dependant only on its end points. This proves that the integral on any closed path will be $0$. My question is that this proof works for any function $f (x, y)$ integrable on all rectangular paths, and in any open set (not just a disc). So what role does the analyticity of $f (z)$ and the shape of the disc have to play in this proof?","Ahlfors says the following: if $f (z) $ is analytic on a disc, then its integral along any closed path contained in the disc is $0$. The proof for this is the following: Let $F (z)=\int_\sigma  {f (z)dz}$ where $\sigma$ is a rectangular path that starts at a fixed point $z_0$ (they say in the middle of the disc),  and ends at $z$. Rectangular path in the sense that if we have a path from $(x_0, y_0) to (x, y)$, then we move from $(x_0, y_0)\to (x, y_0)\to (x, y)$, or $(x_0, y_0)\to (x_0, y)\to (x, y)$. So anyway, we have $F (z)= \int {f (z)dx+if (z)dy}$. Moving along the first rectangular path and differentiating wrt y, we get $dF/dy=if (z)$. Similarly, moving along the second path, we get $dF (z)/dx =f (z)$. This shows that $F (z)$ is analytic. We also have the fact that $\int {f (z) dz} $ is an exact differential, and hence dependant only on its end points. This proves that the integral on any closed path will be $0$. My question is that this proof works for any function $f (x, y)$ integrable on all rectangular paths, and in any open set (not just a disc). So what role does the analyticity of $f (z)$ and the shape of the disc have to play in this proof?",,[]
69,"Inverse image of $[-2,2]$ under cosine.",Inverse image of  under cosine.,"[-2,2]","I solved the following problem: Let $g(z) = \cos z$.  Find $g^{-1}[-2,2]$. but my solution was kind of long.  I was wondering if there was a faster way to do this problem. Here's my solution: Write $\cos z = \frac{e^{iz} + e^{-iz}}{2}$, and $z = a+bi$, so $$\cos z = \frac{e^{-b + ia} + e^{b - ia}}{2} = \frac{e^{-b}}{2}[\cos a + i \sin a] + \frac{e^b}{2}[\cos a - i \sin a]$$ $$ = \frac{e^{-b} + e^b}{2} \cos a + i \frac{e^{-b} - e^b}{2} \sin a$$ We first of all want $\cos z$ to be real, so either (i) $e^{-b} - e^b = 0$ or (ii) $\sin a = 0$.  The first case is not interesting, this just says that $b = 0$, and we already know in this case that $\cos a \in [-1,1]$.  For the second case, we will have $a = k \pi$ for $k \in \mathbb{Z}$.  This implies that $$\cos z = \pm \frac{e^{-b} + e^{b}}{2}$$ so to make $\cos z \in [-2,2]$ we need $h(b) := e^{-b} + e^b$ to be in $[-4,4]$.  Clearly $h$ is an even function, increasing in either direction, so we need to solve $e^{-x} + e^x = 4$ for $x$.  Let $y = e^x$, then $\frac{1}{y} + y =4$, so $y^2 - 4y + 1 =0$.  Then $$y= \frac{4 \pm \sqrt{16 - 4}}{2} = 2 \pm \sqrt{3}$$ so $x = \log (2 \pm \sqrt{3})$.  Looking at the equation we were supposed to solve, we know without calculating anything that $- \log(2 + \sqrt{3}) = \log(2 - \sqrt{3})$.  Letting $\alpha = \log(2 + \sqrt{3})$, it holds that $e^b + e^{-b} \leq 4$ for $- \alpha \leq b \leq \alpha$. Thus $g^{-1}[-2,2]$ consists of the real line unioned together with $$\bigcup\limits_{k \in \mathbb{Z}} \{ k \pi + bi : -\alpha \leq b \leq \alpha\}$$","I solved the following problem: Let $g(z) = \cos z$.  Find $g^{-1}[-2,2]$. but my solution was kind of long.  I was wondering if there was a faster way to do this problem. Here's my solution: Write $\cos z = \frac{e^{iz} + e^{-iz}}{2}$, and $z = a+bi$, so $$\cos z = \frac{e^{-b + ia} + e^{b - ia}}{2} = \frac{e^{-b}}{2}[\cos a + i \sin a] + \frac{e^b}{2}[\cos a - i \sin a]$$ $$ = \frac{e^{-b} + e^b}{2} \cos a + i \frac{e^{-b} - e^b}{2} \sin a$$ We first of all want $\cos z$ to be real, so either (i) $e^{-b} - e^b = 0$ or (ii) $\sin a = 0$.  The first case is not interesting, this just says that $b = 0$, and we already know in this case that $\cos a \in [-1,1]$.  For the second case, we will have $a = k \pi$ for $k \in \mathbb{Z}$.  This implies that $$\cos z = \pm \frac{e^{-b} + e^{b}}{2}$$ so to make $\cos z \in [-2,2]$ we need $h(b) := e^{-b} + e^b$ to be in $[-4,4]$.  Clearly $h$ is an even function, increasing in either direction, so we need to solve $e^{-x} + e^x = 4$ for $x$.  Let $y = e^x$, then $\frac{1}{y} + y =4$, so $y^2 - 4y + 1 =0$.  Then $$y= \frac{4 \pm \sqrt{16 - 4}}{2} = 2 \pm \sqrt{3}$$ so $x = \log (2 \pm \sqrt{3})$.  Looking at the equation we were supposed to solve, we know without calculating anything that $- \log(2 + \sqrt{3}) = \log(2 - \sqrt{3})$.  Letting $\alpha = \log(2 + \sqrt{3})$, it holds that $e^b + e^{-b} \leq 4$ for $- \alpha \leq b \leq \alpha$. Thus $g^{-1}[-2,2]$ consists of the real line unioned together with $$\bigcup\limits_{k \in \mathbb{Z}} \{ k \pi + bi : -\alpha \leq b \leq \alpha\}$$",,"['complex-analysis', 'complex-numbers']"
70,Problem in exercise of Complex Analysis,Problem in exercise of Complex Analysis,,"I have a Complex Analysis exam in 2 days. The last exam had, among other exercises, the following: Let $f$ be a function holomorphic in $\mathbb{D}\smallsetminus\{0\}$ that does not have a removable singularity ad the origin. What kind of singularities can it have? Why? Show that the origin is an essential singularity for $e^f$ . Point one is fairly easy: it can either have a pole or an essential singularity, because those are the only possible isolated singularities except for a removable one, which is excluded by hypothesis, and that singularity is surely isolated since the function is holomorphic in the rest of the disk $\mathbb{D}$ . But how do I go about the second one? I thought of trying to prove the conclusions of the Casorati-Weierstrass theorem , because that would exclude a removable singularity since the function would not be bounded, and a pole since the modulus would wildly oscillate and therefore not tend to infinity, which is equivalent to 0 being a pole. But I'm still stuck. I mean, if $f$ has real part going to $-\infty$ and imaginary part doing whatever it wants, then $e^f$ has a removable singularity at 0, yet $f$ still has a pole, since whatever the imaginary part does, the modulus will tend to infinity. Am I missing something or is this really an impossible exercise right out of an exam? And if not - which I guess is most likely - what am I missing, and how do I solve this?","I have a Complex Analysis exam in 2 days. The last exam had, among other exercises, the following: Let be a function holomorphic in that does not have a removable singularity ad the origin. What kind of singularities can it have? Why? Show that the origin is an essential singularity for . Point one is fairly easy: it can either have a pole or an essential singularity, because those are the only possible isolated singularities except for a removable one, which is excluded by hypothesis, and that singularity is surely isolated since the function is holomorphic in the rest of the disk . But how do I go about the second one? I thought of trying to prove the conclusions of the Casorati-Weierstrass theorem , because that would exclude a removable singularity since the function would not be bounded, and a pole since the modulus would wildly oscillate and therefore not tend to infinity, which is equivalent to 0 being a pole. But I'm still stuck. I mean, if has real part going to and imaginary part doing whatever it wants, then has a removable singularity at 0, yet still has a pole, since whatever the imaginary part does, the modulus will tend to infinity. Am I missing something or is this really an impossible exercise right out of an exam? And if not - which I guess is most likely - what am I missing, and how do I solve this?",f \mathbb{D}\smallsetminus\{0\} e^f \mathbb{D} f -\infty e^f f,['complex-analysis']
71,Sequence of polynomials converging to a discontinuous function in $\mathbb{C}$ [closed],Sequence of polynomials converging to a discontinuous function in  [closed],\mathbb{C},"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Is there a sequence of polynomials $P_n $ such that $\displaystyle\lim_{n\rightarrow\infty} P_n (z) $ exists everywhere in $\mathbb{C}$ and equals to $1$ if $\text{Im} (z)>0$, $0$ if $\text{Im} (z) = 0$ and $-1$ if $\text{Im} (z) < 0$? Intuitively, I guess such polynomial doesn't exist, but I have no idea how to prove or disprove it..","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Is there a sequence of polynomials $P_n $ such that $\displaystyle\lim_{n\rightarrow\infty} P_n (z) $ exists everywhere in $\mathbb{C}$ and equals to $1$ if $\text{Im} (z)>0$, $0$ if $\text{Im} (z) = 0$ and $-1$ if $\text{Im} (z) < 0$? Intuitively, I guess such polynomial doesn't exist, but I have no idea how to prove or disprove it..",,"['complex-analysis', 'analysis', 'polynomials']"
72,What proof uses both the Riemann Hypothesis and its negation?,What proof uses both the Riemann Hypothesis and its negation?,,"Some time ago I happened to see a proof that was remarkable in that it used both the Riemann Hypothesis and its negation. That is, it considered the two cases: RH is true, and RH is false, obtaining, after a non-trivial chain of reasoning in each case, the theorem in question. I failed to bookmark it well enough that I can readily retrieve it, so I’m asking the community’s help. What reminded me of this result was this question on MO about famous vacuously true statements . Obviously, one of the cases in the proof is vacuous and, since it involves the Riemann Hypothesis, conceivably qualifies as being famous.","Some time ago I happened to see a proof that was remarkable in that it used both the Riemann Hypothesis and its negation. That is, it considered the two cases: RH is true, and RH is false, obtaining, after a non-trivial chain of reasoning in each case, the theorem in question. I failed to bookmark it well enough that I can readily retrieve it, so I’m asking the community’s help. What reminded me of this result was this question on MO about famous vacuously true statements . Obviously, one of the cases in the proof is vacuous and, since it involves the Riemann Hypothesis, conceivably qualifies as being famous.",,['complex-analysis']
73,plot graph of function $f(z)=\frac{1+z}{1-z}$,plot graph of function,f(z)=\frac{1+z}{1-z},I am not able to plot graph of function $f(z)=\frac{1+z}{1-z}$. can anyone tell me how to do this without using any software?,I am not able to plot graph of function $f(z)=\frac{1+z}{1-z}$. can anyone tell me how to do this without using any software?,,"['complex-analysis', 'graphing-functions']"
74,exponential type of entire function?,exponential type of entire function?,,"I'm looking at an entire function of the form $$ f(\lambda):=p(\lambda)e^{-\lambda}+q(\lambda)\;, $$ where $p$ and $q$ are polynomials and $\lambda\in\mathbb{C}$. I need to establish that $f$ is an entire function of finite exponential type, and to determine its order. This would be helpful in what I'm planning on doing down the road. Any ideas are welcome. This is what I have done so far. Begin by noting that  $$ e^{-\lambda}=\displaystyle\sum_{n=0}^{\infty}\frac{(-1)^n\lambda^n}{n!}\;. $$ Thus, $$ \begin{array}{lcl} |f(\lambda)| &\leq& \displaystyle\sum_{n=0}^{\infty}\left|\frac{\lambda^n p(\lambda)}{n!}\right|+|q(\lambda)|\\ &\leq& e^{|\lambda|+\ln|p(\lambda)|}+e^{\ln|q(\lambda)|}\;. \end{array} $$ We say that $f$ is of order $\rho$ if $|f(z)|\leq ce^{{|z|}^{\rho}}$ for $|z|$ large enough, so that $|f(z)|e^{-{|z|}^{\rho}}$ is bounded.","I'm looking at an entire function of the form $$ f(\lambda):=p(\lambda)e^{-\lambda}+q(\lambda)\;, $$ where $p$ and $q$ are polynomials and $\lambda\in\mathbb{C}$. I need to establish that $f$ is an entire function of finite exponential type, and to determine its order. This would be helpful in what I'm planning on doing down the road. Any ideas are welcome. This is what I have done so far. Begin by noting that  $$ e^{-\lambda}=\displaystyle\sum_{n=0}^{\infty}\frac{(-1)^n\lambda^n}{n!}\;. $$ Thus, $$ \begin{array}{lcl} |f(\lambda)| &\leq& \displaystyle\sum_{n=0}^{\infty}\left|\frac{\lambda^n p(\lambda)}{n!}\right|+|q(\lambda)|\\ &\leq& e^{|\lambda|+\ln|p(\lambda)|}+e^{\ln|q(\lambda)|}\;. \end{array} $$ We say that $f$ is of order $\rho$ if $|f(z)|\leq ce^{{|z|}^{\rho}}$ for $|z|$ large enough, so that $|f(z)|e^{-{|z|}^{\rho}}$ is bounded.",,"['real-analysis', 'complex-analysis']"
75,"Is there an analytic function $f$ on $\mathbb{C}\setminus[-1,1]$ that satisfies $e^{f(z)}=\frac{z+1}{z-1}$?",Is there an analytic function  on  that satisfies ?,"f \mathbb{C}\setminus[-1,1] e^{f(z)}=\frac{z+1}{z-1}","I'm having trouble proving or disproving this question. I kind of expect that there is no such function since the definition of the logarithm of a function $\phi$ that is analytic on a simply connected open set $U$ is $$L_\phi(z)=\int^z_{z_0}\frac{\phi'(\zeta)}{\phi(\zeta)}d\zeta + w_0.$$ With $w_0$ being a complex number such that $e^{w_0}=f(z_0)$. But in our case we are looking for an analytic function on $\mathbb{C}\setminus[-1,1]$ which is not simply connected. But on the other hand if I let $\phi(z)=\frac{z+1}{z-1}$ and $\gamma$ be a path in $\mathbb{C}\setminus[-1,1]$ from $z_0$ to $z$ and define $f(z)=L_\gamma\phi(z)$ as $$L_\gamma\phi(z)=\int^z_{z_0,\gamma}\frac{\phi'(\zeta)}{\phi(\zeta)}d\zeta + w_0.$$ Then for any two different paths in $\mathbb{C}\setminus[-1,1]$ connecting $z_0$ and $z$ the results of $f(z)$ will differ by an integer multiple of $2\pi i$. So even though $f$ may not be well defined the exponential of $f$ is well defined since $$e^{L_{\gamma_1}\phi(z)}=e^{L_{\gamma_2}\phi(z)+m2\pi i}=\phi(z)=\frac{z+1}{z-1}.$$ These have been my attempts so far, but I am not sure if I am on the right track or completely missing something.","I'm having trouble proving or disproving this question. I kind of expect that there is no such function since the definition of the logarithm of a function $\phi$ that is analytic on a simply connected open set $U$ is $$L_\phi(z)=\int^z_{z_0}\frac{\phi'(\zeta)}{\phi(\zeta)}d\zeta + w_0.$$ With $w_0$ being a complex number such that $e^{w_0}=f(z_0)$. But in our case we are looking for an analytic function on $\mathbb{C}\setminus[-1,1]$ which is not simply connected. But on the other hand if I let $\phi(z)=\frac{z+1}{z-1}$ and $\gamma$ be a path in $\mathbb{C}\setminus[-1,1]$ from $z_0$ to $z$ and define $f(z)=L_\gamma\phi(z)$ as $$L_\gamma\phi(z)=\int^z_{z_0,\gamma}\frac{\phi'(\zeta)}{\phi(\zeta)}d\zeta + w_0.$$ Then for any two different paths in $\mathbb{C}\setminus[-1,1]$ connecting $z_0$ and $z$ the results of $f(z)$ will differ by an integer multiple of $2\pi i$. So even though $f$ may not be well defined the exponential of $f$ is well defined since $$e^{L_{\gamma_1}\phi(z)}=e^{L_{\gamma_2}\phi(z)+m2\pi i}=\phi(z)=\frac{z+1}{z-1}.$$ These have been my attempts so far, but I am not sure if I am on the right track or completely missing something.",,['complex-analysis']
76,Prove that if $f$ is entire and $|f(z)| \leq |z|^2+12$ then $f$ is a polynomial of deg $\leq 2$,Prove that if  is entire and  then  is a polynomial of deg,f |f(z)| \leq |z|^2+12 f \leq 2,"[Solution Verification] Prove that if $f$ is entire and $|f(z)| \leq |z|^2+12$ for all $z \in \mathbb C$ then $f$ is a polynomial of degree $\leq 2$ So here's my proof, and there is a problematic thing I would like to address: Since $f(z)$ is entire, we can develop a power series around $z=0$, so that $f(z)=\Sigma_{n=0}^\infty a_nz^n$, with $a_n= \frac {f^{(n)}(0)}{n!}$. It will suffice to prove that $f^{(n)}=0$ for all $n \geq 3$ Let there be a circle $C_R$ with radius $R$ centered at $z=0$. So by the general Cauchy Integral Formula we get that: $$f^{(n)}(0)=\frac{n!}{2\pi i}\int_{C_R}\frac{f(z)}{z^{n+1}}dz$$ So we know that $$|f^{(n)}(0)|=|\frac{n!}{2\pi i}\int_{C_R}\frac{f(z)}{z^{n+1}}dz| \leq \frac{n!}{2\pi} \cdot Length(C_R) \cdot \max _{z \in C_R} \frac{1}{|z^{n+1}|} \cdot  \max _{z \in C_R}|f(z)|=\\ =\frac{n!}{2\pi} \cdot 2 \pi R \cdot \frac {1}{R^{n+1}} \cdot \max _{z \in C_R}|f(z)|=n! \frac {|z|^2+12}{R^n} \leq n!\frac {R^2+12}{R^n} $$ So when $R \rightarrow \infty$, for $n \geq 3$ we get $|f^{(n)}(0)| \leq 0$ hence $f^{(n)}(0)=0$ for $n \geq 3$, hence QED. My problem: Is this statement correct? $$\max _{z \in C_R}|f(z)|=|z|^2+12$$ As this is not a constant, it seems like $f$ does not have a maximum in a circle $C_R$, so I'm not sure I can use it. Thank you!","[Solution Verification] Prove that if $f$ is entire and $|f(z)| \leq |z|^2+12$ for all $z \in \mathbb C$ then $f$ is a polynomial of degree $\leq 2$ So here's my proof, and there is a problematic thing I would like to address: Since $f(z)$ is entire, we can develop a power series around $z=0$, so that $f(z)=\Sigma_{n=0}^\infty a_nz^n$, with $a_n= \frac {f^{(n)}(0)}{n!}$. It will suffice to prove that $f^{(n)}=0$ for all $n \geq 3$ Let there be a circle $C_R$ with radius $R$ centered at $z=0$. So by the general Cauchy Integral Formula we get that: $$f^{(n)}(0)=\frac{n!}{2\pi i}\int_{C_R}\frac{f(z)}{z^{n+1}}dz$$ So we know that $$|f^{(n)}(0)|=|\frac{n!}{2\pi i}\int_{C_R}\frac{f(z)}{z^{n+1}}dz| \leq \frac{n!}{2\pi} \cdot Length(C_R) \cdot \max _{z \in C_R} \frac{1}{|z^{n+1}|} \cdot  \max _{z \in C_R}|f(z)|=\\ =\frac{n!}{2\pi} \cdot 2 \pi R \cdot \frac {1}{R^{n+1}} \cdot \max _{z \in C_R}|f(z)|=n! \frac {|z|^2+12}{R^n} \leq n!\frac {R^2+12}{R^n} $$ So when $R \rightarrow \infty$, for $n \geq 3$ we get $|f^{(n)}(0)| \leq 0$ hence $f^{(n)}(0)=0$ for $n \geq 3$, hence QED. My problem: Is this statement correct? $$\max _{z \in C_R}|f(z)|=|z|^2+12$$ As this is not a constant, it seems like $f$ does not have a maximum in a circle $C_R$, so I'm not sure I can use it. Thank you!",,"['complex-analysis', 'solution-verification']"
77,Is there a proof show that : $\cos(z)$ and $\sin(z)$ are images of unbounded functions?,Is there a proof show that :  and  are images of unbounded functions?,\cos(z) \sin(z),"if we knew that :cos and sin are bounded function $\mathbb{R}$ for any real number $x$ . let $z $ be a complex variable , Is there a proof show that : $\cos(z)$ and $\sin(z)$ are images of  unbounded functions ? Any kind of help is appreciated.","if we knew that :cos and sin are bounded function $\mathbb{R}$ for any real number $x$ . let $z $ be a complex variable , Is there a proof show that : $\cos(z)$ and $\sin(z)$ are images of  unbounded functions ? Any kind of help is appreciated.",,['complex-analysis']
78,The group of automorphisms of the unit disk [closed],The group of automorphisms of the unit disk [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question Does the group of (conformal) automorphisms of the complex unit disk have a normal subgroup? (different from the identity and the group itself)","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question Does the group of (conformal) automorphisms of the complex unit disk have a normal subgroup? (different from the identity and the group itself)",,"['abstract-algebra', 'complex-analysis']"
79,Fundamental theorem of calculus and complex integration,Fundamental theorem of calculus and complex integration,,"I am teaching myself complex integration, and unfortunately my text book has left me confused as to when I can apply  the Fundamental theorem of calculus for complex integration. Consider the following on the unit circle (centered at $0$ with radius $1$) $$\oint cosec^{2}\left ( z \right )$$ i believe this integral to be $0$ because the  antederivative is $cot(z)$ and is defined on the unit circle, and $cosec(z)$ is continuous on the unit circle. The fact that the unit circle contains $0$, on which neither $cosec(z)$ nor $cot(z)$ is defined is irrelevant. The only thing that matters is that the statements above hold true on the path itself. consider now $$\oint \frac{1}{z}$$ also on the unit circle is the sole reason the FTOC fails to apply , that the antiderivative $ln(z)$ is not well defined at $z=1$ , assuming a branch cut $[0,+infinity]$ ? and therefore if we took the same integral on the unit circle minus ${1}$, would the integral exist and be $= 0$ ? Thank you","I am teaching myself complex integration, and unfortunately my text book has left me confused as to when I can apply  the Fundamental theorem of calculus for complex integration. Consider the following on the unit circle (centered at $0$ with radius $1$) $$\oint cosec^{2}\left ( z \right )$$ i believe this integral to be $0$ because the  antederivative is $cot(z)$ and is defined on the unit circle, and $cosec(z)$ is continuous on the unit circle. The fact that the unit circle contains $0$, on which neither $cosec(z)$ nor $cot(z)$ is defined is irrelevant. The only thing that matters is that the statements above hold true on the path itself. consider now $$\oint \frac{1}{z}$$ also on the unit circle is the sole reason the FTOC fails to apply , that the antiderivative $ln(z)$ is not well defined at $z=1$ , assuming a branch cut $[0,+infinity]$ ? and therefore if we took the same integral on the unit circle minus ${1}$, would the integral exist and be $= 0$ ? Thank you",,"['complex-analysis', 'complex-integration']"
80,A consequence of Schwarz lemma,A consequence of Schwarz lemma,,"Suppose that for some $\epsilon>0$ the function $f$ is holomorphic on $B(0,1+\epsilon)$ such that $f(a) = 0$ and $|f(z)|\leq1$ if $|z| \leq 1$ . Prove for $|z| \leq 1$ : $$|f(z)|\leq \left|\frac{z-a}{1-\overline{a}z}\right|.$$ I tried using the lemma of Schwarz which states that on the unit sphere, if $f(0) = 0$ and $|f(z)|\leq1$ then $|f(z)|\leq |z|$ . I think I am missing here a smart translation or something, any tips?","Suppose that for some the function is holomorphic on such that and if . Prove for : I tried using the lemma of Schwarz which states that on the unit sphere, if and then . I think I am missing here a smart translation or something, any tips?","\epsilon>0 f B(0,1+\epsilon) f(a) = 0 |f(z)|\leq1 |z| \leq 1 |z| \leq 1 |f(z)|\leq \left|\frac{z-a}{1-\overline{a}z}\right|. f(0) = 0 |f(z)|\leq1 |f(z)|\leq |z|",['complex-analysis']
81,Calculating integral using Cauchy integral formula in two variables,Calculating integral using Cauchy integral formula in two variables,,"I want to compute the integral: $\iint_{\partial_0P}\frac{1}{1-4zw}dzdw$ (or any similar integral) using Cauchy integral formula for two complex variables over polydiscs. The distinguished boundary is given by: $\partial_0P={\{(z,w):|z|=1, |w|=1}\}$. Nowhere online have I found an example of how to calculate such an integral. Would be really grateful if someone could show me how to do it, or give a link to a text with examples.","I want to compute the integral: $\iint_{\partial_0P}\frac{1}{1-4zw}dzdw$ (or any similar integral) using Cauchy integral formula for two complex variables over polydiscs. The distinguished boundary is given by: $\partial_0P={\{(z,w):|z|=1, |w|=1}\}$. Nowhere online have I found an example of how to calculate such an integral. Would be really grateful if someone could show me how to do it, or give a link to a text with examples.",,"['complex-analysis', 'several-complex-variables']"
82,"Why does the Residue Theorem still hold, when I let my contour get infinitely large?","Why does the Residue Theorem still hold, when I let my contour get infinitely large?",,"The theorem (as I know it) only allows for a finite set of isolated singularities. I integrated, along a square box, a function that has simple poles at all the non-zero integers -- and a triple pole at zero.  Then I let the box get infinitely large to help prove that the sum of $1/n^2$ is $\pi^2 / 6$. But why can the Residue Theorem still be applied, even though the box is getting infinitely large, and the poles will eventually become an infinite set? ...I know that a box is compact, and poles at the integers means this set of poles is a discrete set, hence the set of poles in this compact box ...is finite.  But something about taking the limit is bugging me. Thanks,","The theorem (as I know it) only allows for a finite set of isolated singularities. I integrated, along a square box, a function that has simple poles at all the non-zero integers -- and a triple pole at zero.  Then I let the box get infinitely large to help prove that the sum of $1/n^2$ is $\pi^2 / 6$. But why can the Residue Theorem still be applied, even though the box is getting infinitely large, and the poles will eventually become an infinite set? ...I know that a box is compact, and poles at the integers means this set of poles is a discrete set, hence the set of poles in this compact box ...is finite.  But something about taking the limit is bugging me. Thanks,",,"['complex-analysis', 'residue-calculus']"
83,Textbook +reference book in complex analysis,Textbook +reference book in complex analysis,,"Which book can be used as an introductory textbook in complex analysis? I have some choices (more suggestions are welcomed) Marsden & Hoffman J.B. Conway Ahlfors Palka Lang Stein & Shakarchi I want a textbook which is affordable,builds my concepts and lays a strong foundation of complex analysis.the book should cover the concepts that are needed in a complex analysis course in a formidable manner.Also it should be such that I can use it for an exam Also I would be happy if someone can provide me  a reference book that can be used side by side with the textbook for studying in more detail","Which book can be used as an introductory textbook in complex analysis? I have some choices (more suggestions are welcomed) Marsden & Hoffman J.B. Conway Ahlfors Palka Lang Stein & Shakarchi I want a textbook which is affordable,builds my concepts and lays a strong foundation of complex analysis.the book should cover the concepts that are needed in a complex analysis course in a formidable manner.Also it should be such that I can use it for an exam Also I would be happy if someone can provide me  a reference book that can be used side by side with the textbook for studying in more detail",,"['complex-analysis', 'soft-question', 'book-recommendation']"
84,Pole and removable sigularity,Pole and removable sigularity,,"I try to solve the following problem. I do not sure how to begin : Let $f$ be a holomorphic function on $\mathbb{C}\setminus \{0\}$. Assume that there exists a constant $C > 0$ and a real constant $M$ such that $$|f(z)| \leq C|z|^M$$ for $0 < |z| < \frac{1}{2}.$ Show that $z=0$ is either a pole or a removable singularities for $f$, and find sharp bound for $O_0(f)$, the order of $f$ at $0$ (I think that the order means the of $z$ in $f(z)$. I think that $f$ might should take the form $f(z) = \frac{g(z)}{z^{O_0(f)}}$ where $g$ is entire.) I am not sure I should if I should write $f := \frac{g}{z^n}$ for some $n \in \mathbb{N} \cup \{0\}$ where $g$ is entire.(I have no particular reasons for writing $f$ in this form except that the most of the questions ask about poles or singularity of $f$, $f$ is often written in this form) I guess that the condition, $|f(z)| \leq C|z|^M$ for $0 < |z| < \frac{1}{2}$, might connect to that $f$ is a polynmial of degree at most $M$ on $0 < |z| < \frac{1}{2}$, but it seems that this contradict the form $f = g/ z^n$. So I am confusing how to start.","I try to solve the following problem. I do not sure how to begin : Let $f$ be a holomorphic function on $\mathbb{C}\setminus \{0\}$. Assume that there exists a constant $C > 0$ and a real constant $M$ such that $$|f(z)| \leq C|z|^M$$ for $0 < |z| < \frac{1}{2}.$ Show that $z=0$ is either a pole or a removable singularities for $f$, and find sharp bound for $O_0(f)$, the order of $f$ at $0$ (I think that the order means the of $z$ in $f(z)$. I think that $f$ might should take the form $f(z) = \frac{g(z)}{z^{O_0(f)}}$ where $g$ is entire.) I am not sure I should if I should write $f := \frac{g}{z^n}$ for some $n \in \mathbb{N} \cup \{0\}$ where $g$ is entire.(I have no particular reasons for writing $f$ in this form except that the most of the questions ask about poles or singularity of $f$, $f$ is often written in this form) I guess that the condition, $|f(z)| \leq C|z|^M$ for $0 < |z| < \frac{1}{2}$, might connect to that $f$ is a polynmial of degree at most $M$ on $0 < |z| < \frac{1}{2}$, but it seems that this contradict the form $f = g/ z^n$. So I am confusing how to start.",,['complex-analysis']
85,"About the ""mixed"" form of Gauss and Fresnel integrals","About the ""mixed"" form of Gauss and Fresnel integrals",,"How to integrate the ""mixed"" form of Gauss and Fresnel integrals as following? $$\int_{-\infty}^{+\infty} {e^{-x^2-ia(x+b)^2} dx} $$ where $a \in R, b \in R$. [EDIT] As Claude Leibovici pointed out, by completing the square in the exponent as following: $$-x^2-ia(x+b)^2 = -(1+ia)x^2 -i(2ab)x -i(ab^2) \\   = -(1+ia) (x + \frac{iab}{1+ia})^2 + c$$ where $c = -i(ab^2) - \frac{a^2b^2}{1+ia}$, the above integral is reduced to: $$e^c \int_{-\infty - id}^{+\infty - id} {e^{-(1+ia) y^2} dy}$$ where $d = \frac{ab^2}{1 + a^2}$. This integral is equal to: $$I_0 \equiv e^c \int_{-\infty}^{+\infty} {e^{-(1+ia) y^2} dy}$$. This is justified by the integration over the following contour to be equal to zero: $$y \in (-\infty, +\infty) \cup (+\infty, +\infty -id) \cup (+\infty -id, -\infty -id) \cup (-\infty -id, -\infty)$$ The complex Gauss integral $I_0$ is still in the form of ""mixed"" real Gauss and Fresnel integrals. The question is how to derive and justify that the result can be written as $e^c\sqrt{\frac{\pi}{1+ia}}$?","How to integrate the ""mixed"" form of Gauss and Fresnel integrals as following? $$\int_{-\infty}^{+\infty} {e^{-x^2-ia(x+b)^2} dx} $$ where $a \in R, b \in R$. [EDIT] As Claude Leibovici pointed out, by completing the square in the exponent as following: $$-x^2-ia(x+b)^2 = -(1+ia)x^2 -i(2ab)x -i(ab^2) \\   = -(1+ia) (x + \frac{iab}{1+ia})^2 + c$$ where $c = -i(ab^2) - \frac{a^2b^2}{1+ia}$, the above integral is reduced to: $$e^c \int_{-\infty - id}^{+\infty - id} {e^{-(1+ia) y^2} dy}$$ where $d = \frac{ab^2}{1 + a^2}$. This integral is equal to: $$I_0 \equiv e^c \int_{-\infty}^{+\infty} {e^{-(1+ia) y^2} dy}$$. This is justified by the integration over the following contour to be equal to zero: $$y \in (-\infty, +\infty) \cup (+\infty, +\infty -id) \cup (+\infty -id, -\infty -id) \cup (-\infty -id, -\infty)$$ The complex Gauss integral $I_0$ is still in the form of ""mixed"" real Gauss and Fresnel integrals. The question is how to derive and justify that the result can be written as $e^c\sqrt{\frac{\pi}{1+ia}}$?",,"['integration', 'complex-analysis', 'contour-integration']"
86,Geometry of complex number,Geometry of complex number,,"I'm having a hard time understand the geometry of complex number. My professor showed these two examples in class and say it's very easy to recognize their geometry, but it doesn't seem easy for me at all. Here are the examples: a) $$z=\frac{a+dx+cx^2+bcx +i(ax+dx^2 -cx+b)}{1+x^2}$$ b) $$z=\frac{a-cx+i(b-dx)}{1-x}$$ where $a,b,c,d$ are fixed and $x$ is a real number. On part a), some of my classmate say it's a circle, but I don't know how can they see that. I wonder if anyone would please explain it to me.","I'm having a hard time understand the geometry of complex number. My professor showed these two examples in class and say it's very easy to recognize their geometry, but it doesn't seem easy for me at all. Here are the examples: a) $$z=\frac{a+dx+cx^2+bcx +i(ax+dx^2 -cx+b)}{1+x^2}$$ b) $$z=\frac{a-cx+i(b-dx)}{1-x}$$ where $a,b,c,d$ are fixed and $x$ is a real number. On part a), some of my classmate say it's a circle, but I don't know how can they see that. I wonder if anyone would please explain it to me.",,['complex-analysis']
87,Finding all possible limits of certain sequences,Finding all possible limits of certain sequences,,"I know I can find sequences $(z_n)$, $(w_n) $ $\subset \mathbb{C}$ such that $|z_n | \to 1 $, $|w_n| \to 1 $ and $$ \Big| \frac{ w_n - z_n}{1 - \overline{w_n} z_n } \Big| \; \; \text{does NOT converge to 1 } $$ For instance, if I take $z_n = 1 + 1/n $ and $w_n = 1 - 1/n $. However, My question is: How can I find all possible limits of such a sequences (the sequences with the required property)?? thanks","I know I can find sequences $(z_n)$, $(w_n) $ $\subset \mathbb{C}$ such that $|z_n | \to 1 $, $|w_n| \to 1 $ and $$ \Big| \frac{ w_n - z_n}{1 - \overline{w_n} z_n } \Big| \; \; \text{does NOT converge to 1 } $$ For instance, if I take $z_n = 1 + 1/n $ and $w_n = 1 - 1/n $. However, My question is: How can I find all possible limits of such a sequences (the sequences with the required property)?? thanks",,[]
88,Find all holomorphic diffeomorphisms $f:\mathbb{CP}^1\to\mathbb{CP}^1$,Find all holomorphic diffeomorphisms,f:\mathbb{CP}^1\to\mathbb{CP}^1,"The complex projective line $\mathbb{CP}^1$ is the complex manifold defined by the quotient of $\mathbb{C}^2-\{(0,0)\}$ by the relation $z\sim w$ if $z=\lambda w$ for $\lambda\in\mathbb{C}-\{0\}$. I am trying to show that a map  $$f:\mathbb{CP}^1\to\mathbb{CP}^1$$ is a (holomorphic) diffeomorphism if and only if $f$ is obtained from an invertible matrix $M\in\mathrm{GL}(2,\mathbb{C})$ by quotienting $$M:\mathbb{C}^2-\{0\}\to\mathbb{C}^2-\{0\}.$$ I was able to show that every such $M$ indeed gives a diffeomorphism, but I am not able to prove the other direction. How show that every diffeomorphism arise in this way?","The complex projective line $\mathbb{CP}^1$ is the complex manifold defined by the quotient of $\mathbb{C}^2-\{(0,0)\}$ by the relation $z\sim w$ if $z=\lambda w$ for $\lambda\in\mathbb{C}-\{0\}$. I am trying to show that a map  $$f:\mathbb{CP}^1\to\mathbb{CP}^1$$ is a (holomorphic) diffeomorphism if and only if $f$ is obtained from an invertible matrix $M\in\mathrm{GL}(2,\mathbb{C})$ by quotienting $$M:\mathbb{C}^2-\{0\}\to\mathbb{C}^2-\{0\}.$$ I was able to show that every such $M$ indeed gives a diffeomorphism, but I am not able to prove the other direction. How show that every diffeomorphism arise in this way?",,"['complex-analysis', 'complex-geometry', 'projective-geometry']"
89,Convergence on the boudary,Convergence on the boudary,,"Consider this power series $$\sum_{n=0}^{\infty}\frac{(3n)! (2n)!}{(n)!(4n)!}z^n $$ The radius of convergence is $\displaystyle \frac{64}{27}$. But how do we know where it's convergent on the boundary $|z|=\displaystyle \frac{64}{27}$, $z \in \mathbb{C}$? Abel's theorem seems to not work here.","Consider this power series $$\sum_{n=0}^{\infty}\frac{(3n)! (2n)!}{(n)!(4n)!}z^n $$ The radius of convergence is $\displaystyle \frac{64}{27}$. But how do we know where it's convergent on the boundary $|z|=\displaystyle \frac{64}{27}$, $z \in \mathbb{C}$? Abel's theorem seems to not work here.",,['complex-analysis']
90,density on smooth boundary in several variables complex analysis,density on smooth boundary in several variables complex analysis,,"Assume bounded domain (open and connected) $\Omega\subset \mathbb{C}^n$, and a smooth function $\rho:\mathbb{C}^n\longrightarrow \mathbb{R}$ such that $\rho(x) = 0$ for all $x\in \partial \Omega$, $\rho (x) < 0$ for all $x\in \Omega$ and $\rho(x) > 0$ for all $x\in \mathbb{C}^n\backslash \overline{\Omega}$. And $\nabla \rho \neq 0$ on $\partial \Omega$. We say $\partial \Omega$ is smooth. Now let $z\in \partial \Omega$, we denote by $\tau(z)$ the expression $$ \tau(z) = \lim_{\varepsilon \longrightarrow  0^+}  \frac{vol(S(z,\varepsilon)\cap \Omega)}{vol(S(z,\varepsilon))}$$ where $S(z,\varepsilon) = \{x\in \mathbb{C}^n: |x - z| = \varepsilon\}$ -- the boundary of ball $B(z,\varepsilon)$ in $\mathbb{C}^n$ as usual. And $vol$ denote the usual measure on $\partial \Omega$. Show that when $\rho$ is smooth as above, we always have $\tau(z) = \frac{1}{2}$ for all $z\in \partial \Omega$. Furthermore, if $\partial \Omega$ is piece-wise smooth, then $\tau(z)$ is defined on  $\partial \Omega$ and not zero. I read this result in the book "" The Bochner--Martinelli Intergral and It's application "" but I don't understand why this fact is trivial - as the author said.","Assume bounded domain (open and connected) $\Omega\subset \mathbb{C}^n$, and a smooth function $\rho:\mathbb{C}^n\longrightarrow \mathbb{R}$ such that $\rho(x) = 0$ for all $x\in \partial \Omega$, $\rho (x) < 0$ for all $x\in \Omega$ and $\rho(x) > 0$ for all $x\in \mathbb{C}^n\backslash \overline{\Omega}$. And $\nabla \rho \neq 0$ on $\partial \Omega$. We say $\partial \Omega$ is smooth. Now let $z\in \partial \Omega$, we denote by $\tau(z)$ the expression $$ \tau(z) = \lim_{\varepsilon \longrightarrow  0^+}  \frac{vol(S(z,\varepsilon)\cap \Omega)}{vol(S(z,\varepsilon))}$$ where $S(z,\varepsilon) = \{x\in \mathbb{C}^n: |x - z| = \varepsilon\}$ -- the boundary of ball $B(z,\varepsilon)$ in $\mathbb{C}^n$ as usual. And $vol$ denote the usual measure on $\partial \Omega$. Show that when $\rho$ is smooth as above, we always have $\tau(z) = \frac{1}{2}$ for all $z\in \partial \Omega$. Furthermore, if $\partial \Omega$ is piece-wise smooth, then $\tau(z)$ is defined on  $\partial \Omega$ and not zero. I read this result in the book "" The Bochner--Martinelli Intergral and It's application "" but I don't understand why this fact is trivial - as the author said.",,"['complex-analysis', 'several-complex-variables']"
91,"Contour integral $\int_{|z|=1}\frac{2z^2+z}{z^2-1}\, dz$ using residues",Contour integral  using residues,"\int_{|z|=1}\frac{2z^2+z}{z^2-1}\, dz","I am trying to evaluate the contour integral $$\int_{|z|=1}\frac{2z^2+z}{z^2-1}\, dz.$$ In this case the two singular points lie on the boundary (on the contour). So do I count the residues at this points or do I ignore them ?","I am trying to evaluate the contour integral $$\int_{|z|=1}\frac{2z^2+z}{z^2-1}\, dz.$$ In this case the two singular points lie on the boundary (on the contour). So do I count the residues at this points or do I ignore them ?",,"['complex-analysis', 'contour-integration', 'residue-calculus']"
92,Laurent series expansion of $f(z)= \frac{\sinh(z)}{z^3}$,Laurent series expansion of,f(z)= \frac{\sinh(z)}{z^3},"Find the Laurent- series expansion of $$f(z)= \frac{\sinh(z)}{z^3}$$ With small manipulations, I came up with below thing, $$\frac{\sinh(z)}{z^3}=\frac{1}{z^2}+\frac{1}{3!}+\frac{z^2}{5!}+...$$ Is it useful to find Laurent series?","Find the Laurent- series expansion of $$f(z)= \frac{\sinh(z)}{z^3}$$ With small manipulations, I came up with below thing, $$\frac{\sinh(z)}{z^3}=\frac{1}{z^2}+\frac{1}{3!}+\frac{z^2}{5!}+...$$ Is it useful to find Laurent series?",,"['complex-analysis', 'laurent-series']"
93,Complex integral using cauchy residue formula,Complex integral using cauchy residue formula,,"I want to compute $ \displaystyle \int_{0}^{+\infty} \frac{dx}{x^n-1} $ I've proved that $ \displaystyle \int_{0}^{+\infty} \frac{dx}{x^n+1} = \frac{\pi}{n\sin\left(\frac{\pi}{n}\right)}$ in a previous question by using some contour integration (in 3 parts like here : image ) and using cauchy residue formula. Given that $ \displaystyle \frac{1}{x^{n}-1}-\frac{1}{x^{n}+1} = 2 \frac{1}{x^{2n}-1}$ so  we just have to compute $ \displaystyle \int_{-\infty}^{\infty} \frac{dx}{x^{2n}-1} $ , the other integral being $\displaystyle \frac{\pi}{n\sin\left(\frac{\pi}{n}\right)}$. The singularities in this integral are $ z_k=e^{i k \pi / n} $ for $ k=0,\dots,2n-1  $ If we use cauchy residue formula we would find, if I note $ S=\{ z_k \big| \Im(z_k) \geq 0 \} $  $$ \displaystyle \int_{-\infty}^{\infty} \frac{dx}{x^{2n}-1} =  2i\pi \sum_{z_k \in S} Res(z_k) = \frac{i\pi}{n} \sum_{z_k \in S} z_k  $$ For instance for $n=2$ the solution with positive imaginary part of $z^4=1$ gives $S=\{1,-1,i\}$ and then using this formula $ \displaystyle \int_{-\infty}^{\infty} \frac{dx} {x^4-1}  = -\frac{\pi}{2} $ , which seems to be correct using some calculator. So, can it be simplified ? I don't like the fact that I need to use S. Thanks in advance.","I want to compute $ \displaystyle \int_{0}^{+\infty} \frac{dx}{x^n-1} $ I've proved that $ \displaystyle \int_{0}^{+\infty} \frac{dx}{x^n+1} = \frac{\pi}{n\sin\left(\frac{\pi}{n}\right)}$ in a previous question by using some contour integration (in 3 parts like here : image ) and using cauchy residue formula. Given that $ \displaystyle \frac{1}{x^{n}-1}-\frac{1}{x^{n}+1} = 2 \frac{1}{x^{2n}-1}$ so  we just have to compute $ \displaystyle \int_{-\infty}^{\infty} \frac{dx}{x^{2n}-1} $ , the other integral being $\displaystyle \frac{\pi}{n\sin\left(\frac{\pi}{n}\right)}$. The singularities in this integral are $ z_k=e^{i k \pi / n} $ for $ k=0,\dots,2n-1  $ If we use cauchy residue formula we would find, if I note $ S=\{ z_k \big| \Im(z_k) \geq 0 \} $  $$ \displaystyle \int_{-\infty}^{\infty} \frac{dx}{x^{2n}-1} =  2i\pi \sum_{z_k \in S} Res(z_k) = \frac{i\pi}{n} \sum_{z_k \in S} z_k  $$ For instance for $n=2$ the solution with positive imaginary part of $z^4=1$ gives $S=\{1,-1,i\}$ and then using this formula $ \displaystyle \int_{-\infty}^{\infty} \frac{dx} {x^4-1}  = -\frac{\pi}{2} $ , which seems to be correct using some calculator. So, can it be simplified ? I don't like the fact that I need to use S. Thanks in advance.",,"['complex-analysis', 'contour-integration', 'residue-calculus', 'cauchy-principal-value']"
94,Contour Integral of $\sin(z)/(z^2-z)$,Contour Integral of,\sin(z)/(z^2-z),"Find the integral $\int_{\lambda}\frac{\sin(z)}{z(z-1)}$ where $\lambda(t) = 10e^{it},t\in[0,2\pi]$ We notice that there are poles at $z = 0$ and $z=1$.  So we can use residue theorem but I am confused as to how to handle the coefficient 10 in $10e^{it}$.","Find the integral $\int_{\lambda}\frac{\sin(z)}{z(z-1)}$ where $\lambda(t) = 10e^{it},t\in[0,2\pi]$ We notice that there are poles at $z = 0$ and $z=1$.  So we can use residue theorem but I am confused as to how to handle the coefficient 10 in $10e^{it}$.",,"['integration', 'complex-analysis', 'contour-integration', 'complex-integration']"
95,Proving $f(z)$ entire function in complex analysis,Proving  entire function in complex analysis,f(z),"If $f\in C(\Bbb C)\cap H(\Bbb C\backslash \delta B_1(0))$ then $f\in H(\Bbb C)$ [C means continuous, $\Bbb C$ means complex plane, H means analytic and $\delta$ means boundary] I don't even know where to start. Thank you...","If $f\in C(\Bbb C)\cap H(\Bbb C\backslash \delta B_1(0))$ then $f\in H(\Bbb C)$ [C means continuous, $\Bbb C$ means complex plane, H means analytic and $\delta$ means boundary] I don't even know where to start. Thank you...",,['complex-analysis']
96,Why is $\arg(i\cosh x)=\frac{\pi}{2}$?,Why is ?,\arg(i\cosh x)=\frac{\pi}{2},I was told $\arg(i\cosh (x))=\frac{\pi}{2}$ and $\arg(\cosh (x))=0$ but I can't figure out why. Could someone explain it to me?,I was told $\arg(i\cosh (x))=\frac{\pi}{2}$ and $\arg(\cosh (x))=0$ but I can't figure out why. Could someone explain it to me?,,"['complex-analysis', 'hyperbolic-functions']"
97,Contour integral using residue,Contour integral using residue,,"Assume that $f(z) \in \{\sqrt{2z^2 + 1}\}$ $,f(0) = 1$ We have a cut: $\gamma = \{|z| = \frac{1}{\sqrt2}, Re(z) \geqslant 0 \}$ $\oint\limits_{|z|=1} \frac{z dz}{(z+2)(f(z) + 3)}$ I found singularities: $z_1 = 2$ and $z_{2,3} = -2$. But they are not in our area $|z| < 1$. According to residue theorem, it's mean that integral is equal $0$. But in book they have completely different answer: $\pi i( \frac{17}{12} - \sqrt2 )$ What have I missed?","Assume that $f(z) \in \{\sqrt{2z^2 + 1}\}$ $,f(0) = 1$ We have a cut: $\gamma = \{|z| = \frac{1}{\sqrt2}, Re(z) \geqslant 0 \}$ $\oint\limits_{|z|=1} \frac{z dz}{(z+2)(f(z) + 3)}$ I found singularities: $z_1 = 2$ and $z_{2,3} = -2$. But they are not in our area $|z| < 1$. According to residue theorem, it's mean that integral is equal $0$. But in book they have completely different answer: $\pi i( \frac{17}{12} - \sqrt2 )$ What have I missed?",,"['integration', 'complex-analysis', 'contour-integration', 'residue-calculus']"
98,Contour integration of $\int_{-\infty}^{\infty}\frac {\sin^3 x}{x^3} dx$: where are the singularities?,Contour integration of : where are the singularities?,\int_{-\infty}^{\infty}\frac {\sin^3 x}{x^3} dx,"I have just begun to study complex analysis and I'm trying to calculate $$  \int_{- \infty}^{\infty} \frac {\sin^3 x}{x^3} dx $$ with the ""help"" of an exercisebook. I have followed these steps: $$\int_{- \infty}^{\infty}\left( \frac {e^{ix}-e^{-ix}}{2i}\right)^3 \frac {1}{x^3} dx$$ $$\frac {1}{(2i)^3} \left(\int_{- \infty}^{\infty} \frac {e^{3ix}}{x^3} dx - \int_{- \infty}^{\infty} \frac {3e^{2ix}}{x^3}dx  - \int_{- \infty}^{\infty} \frac {e^{-3ix}}{x^3}dx + \int_{- \infty}^{\infty} \frac {3e^{-2ix}}{x^3}dx\right)$$ The book says that If we consider a bend path with radius $R\to \infty $ on the upper half-plane, the first and second integrals are equal to zero because the closed curve doesn't contain any singularity. But if we consider the inferior half-plane (and the corresponding half-circle driven clockwise), the path contains the singularity $x=0$. But it was told me that  $x=0$ isn't a singularity point because $ \lim_{x \to 0} \frac {\sin x}{x}=1 $. Now, I can't undestand: If $x=0$ is a singularity and why Why the upper half-plane doesn't contain the singularity and why the inferior one does. Many thanks for your help Reading the the comments, I have made this sketch can you tell me if it is correct?","I have just begun to study complex analysis and I'm trying to calculate $$  \int_{- \infty}^{\infty} \frac {\sin^3 x}{x^3} dx $$ with the ""help"" of an exercisebook. I have followed these steps: $$\int_{- \infty}^{\infty}\left( \frac {e^{ix}-e^{-ix}}{2i}\right)^3 \frac {1}{x^3} dx$$ $$\frac {1}{(2i)^3} \left(\int_{- \infty}^{\infty} \frac {e^{3ix}}{x^3} dx - \int_{- \infty}^{\infty} \frac {3e^{2ix}}{x^3}dx  - \int_{- \infty}^{\infty} \frac {e^{-3ix}}{x^3}dx + \int_{- \infty}^{\infty} \frac {3e^{-2ix}}{x^3}dx\right)$$ The book says that If we consider a bend path with radius $R\to \infty $ on the upper half-plane, the first and second integrals are equal to zero because the closed curve doesn't contain any singularity. But if we consider the inferior half-plane (and the corresponding half-circle driven clockwise), the path contains the singularity $x=0$. But it was told me that  $x=0$ isn't a singularity point because $ \lim_{x \to 0} \frac {\sin x}{x}=1 $. Now, I can't undestand: If $x=0$ is a singularity and why Why the upper half-plane doesn't contain the singularity and why the inferior one does. Many thanks for your help Reading the the comments, I have made this sketch can you tell me if it is correct?",,"['integration', 'complex-analysis', 'contour-integration']"
99,Help understand part of the proof. Radius of convergence is $\frac{1}{\limsup |a_n|^{1/n}}$,Help understand part of the proof. Radius of convergence is,\frac{1}{\limsup |a_n|^{1/n}},"Can you help me understand the highlighted parts of the proof. Thanks :) Theorem: Let $\sum{a_nz^n}$ be a power series, let r be its radius of convergence. Then $\frac{1}{r} = \limsup |a_n|^{1/n}$. Proof: Let $t = \limsup |a_n|^{1/n}$. Suppose first that $t \ne 0, \infty$. Give $\epsilon > 0$, there exits only a finite number of n such that $|a_n|^{1/n} \ge t + \epsilon$. Thus for all but a finite number of n, we have $|a_n| \le (t +\epsilon)^n$, whence the series $\sum{a_nz^n}$ converges absolutely if $|z| < \frac{1}{t+\epsilon}$,  by comparison with the geometric series . Therefore the radius of convergence $r$ satisfies $r \ge \frac{1}{t+\epsilon}$ for every $\epsilon > 0$, whence $r\ge \frac{1}{t}$. Conversely, given $\epsilon$ there exists infinitely many n such that $|a_n|^{1/n} \ge t-\epsilon$ and therefore, $|a_n|\ge (t-\epsilon)^n$. Hence the series $\sum{a_nz^n}$ does not converge if $|z| = \frac{1}{t-\epsilon}$, because it's $n^{th}$ term doesn't even tend to 0. Therefore $r \le \frac{1}{t-\epsilon}$ for every $\epsilon > 0$ , whence $r\le \frac{1}{t}$. This concludes the proof for $t \ne 0,\infty$. For the first highlighted part, I don't understand where the geometric series part comes from.  $\sum{|a_n||z^n|} \le \sum{(1+\epsilon)^n\frac{1}{(t+\epsilon)^n}} = \sum1$, am I doing this wrong? And on the second part why wouldn't the equality with $\frac{1}{t-\epsilon}$ make it converge? Thanks!","Can you help me understand the highlighted parts of the proof. Thanks :) Theorem: Let $\sum{a_nz^n}$ be a power series, let r be its radius of convergence. Then $\frac{1}{r} = \limsup |a_n|^{1/n}$. Proof: Let $t = \limsup |a_n|^{1/n}$. Suppose first that $t \ne 0, \infty$. Give $\epsilon > 0$, there exits only a finite number of n such that $|a_n|^{1/n} \ge t + \epsilon$. Thus for all but a finite number of n, we have $|a_n| \le (t +\epsilon)^n$, whence the series $\sum{a_nz^n}$ converges absolutely if $|z| < \frac{1}{t+\epsilon}$,  by comparison with the geometric series . Therefore the radius of convergence $r$ satisfies $r \ge \frac{1}{t+\epsilon}$ for every $\epsilon > 0$, whence $r\ge \frac{1}{t}$. Conversely, given $\epsilon$ there exists infinitely many n such that $|a_n|^{1/n} \ge t-\epsilon$ and therefore, $|a_n|\ge (t-\epsilon)^n$. Hence the series $\sum{a_nz^n}$ does not converge if $|z| = \frac{1}{t-\epsilon}$, because it's $n^{th}$ term doesn't even tend to 0. Therefore $r \le \frac{1}{t-\epsilon}$ for every $\epsilon > 0$ , whence $r\le \frac{1}{t}$. This concludes the proof for $t \ne 0,\infty$. For the first highlighted part, I don't understand where the geometric series part comes from.  $\sum{|a_n||z^n|} \le \sum{(1+\epsilon)^n\frac{1}{(t+\epsilon)^n}} = \sum1$, am I doing this wrong? And on the second part why wouldn't the equality with $\frac{1}{t-\epsilon}$ make it converge? Thanks!",,"['complex-analysis', 'power-series', 'limsup-and-liminf']"
