,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Find intersection of the two surfaces $x^2-y^2-z^2=1$ and $x+y=1$,Find intersection of the two surfaces  and,x^2-y^2-z^2=1 x+y=1,"Find intersection of this two surfaces $$x^2-y^2-z^2=1$$  and $$x+y=1.$$ I know that the first is hyperboloid of two sheet and the second is plane,  but how can i find the intersection? Is it possible do calculus in one variable? How?","Find intersection of this two surfaces $$x^2-y^2-z^2=1$$  and $$x+y=1.$$ I know that the first is hyperboloid of two sheet and the second is plane,  but how can i find the intersection? Is it possible do calculus in one variable? How?",,['multivariable-calculus']
1,"Is $\left( {{\partial ^2 f}\over{\partial t\,\partial s}}\right)\bigg|_{t = s = 0} = ab - ba?$",Is,"\left( {{\partial ^2 f}\over{\partial t\,\partial s}}\right)\bigg|_{t = s = 0} = ab - ba?","This is a followup to my previous question here . Let $a, b \in M_n(\mathbb{R})$. Consider the function$$f: \mathbb{R}^2 \to M_n(\mathbb{R}), \text{ }(t, s) \mapsto e^{t \cdot a} e^{s \cdot b} e^{-t \cdot a} e^{-s \cdot b}.$$In my previous question, I asked for a way to see that such function is infinitely differentiable. Can anyone supply a rigorous proof of the fact that$$\left( {{\partial ^2 f}\over{\partial t\,\partial s}}\right)\bigg|_{t = s = 0} = ab - ba?$$All proofs I've tried coming up with I feel lack rigour...","This is a followup to my previous question here . Let $a, b \in M_n(\mathbb{R})$. Consider the function$$f: \mathbb{R}^2 \to M_n(\mathbb{R}), \text{ }(t, s) \mapsto e^{t \cdot a} e^{s \cdot b} e^{-t \cdot a} e^{-s \cdot b}.$$In my previous question, I asked for a way to see that such function is infinitely differentiable. Can anyone supply a rigorous proof of the fact that$$\left( {{\partial ^2 f}\over{\partial t\,\partial s}}\right)\bigg|_{t = s = 0} = ab - ba?$$All proofs I've tried coming up with I feel lack rigour...",,"['real-analysis', 'linear-algebra']"
2,General formula for integration on $m$-dimensional hypersurface in $\mathbb{R}^n$ ($m<n$)?,General formula for integration on -dimensional hypersurface in  ()?,m \mathbb{R}^n m<n,"Let $S$ be a two-dimensional surface embedded in $\mathbb{R}^3$. We suppose that $S$ is parameterized as $\vec x (t,s)$, where $t,s$ vary in some region $T$ of the plane. Then the surface integral of a scalar function $f(\vec x)$ over $S$ is given by: $$\int\int_S f dS = \int\int_T f(\vec x(t,s)) \left| \frac{\partial\vec x}{\partial s} \times \frac{\partial\vec x}{\partial t} \right| dt ds $$ What is the generalization of this formula to hypersurfaces of dimension $m$ embeeded in $\mathbb{R}^n$, where $m<n$? That is, let $S$ be parameterized as $\vec x(t_1,\dots,t_m)$, where $\vec x \in \mathbb{R}^n$ and $t_1,\dots,t_m$ vary over some region of $\mathbb{R}^m$. Then how can I express the following hypersurface-integral: $$\int\dots\int_S f dS$$ as an integration over the variables $t_1,\dots,t_m$? Note that I am assuming the usual Euclidean measures in $\mathbb{R}^n$.","Let $S$ be a two-dimensional surface embedded in $\mathbb{R}^3$. We suppose that $S$ is parameterized as $\vec x (t,s)$, where $t,s$ vary in some region $T$ of the plane. Then the surface integral of a scalar function $f(\vec x)$ over $S$ is given by: $$\int\int_S f dS = \int\int_T f(\vec x(t,s)) \left| \frac{\partial\vec x}{\partial s} \times \frac{\partial\vec x}{\partial t} \right| dt ds $$ What is the generalization of this formula to hypersurfaces of dimension $m$ embeeded in $\mathbb{R}^n$, where $m<n$? That is, let $S$ be parameterized as $\vec x(t_1,\dots,t_m)$, where $\vec x \in \mathbb{R}^n$ and $t_1,\dots,t_m$ vary over some region of $\mathbb{R}^m$. Then how can I express the following hypersurface-integral: $$\int\dots\int_S f dS$$ as an integration over the variables $t_1,\dots,t_m$? Note that I am assuming the usual Euclidean measures in $\mathbb{R}^n$.",,"['integration', 'multivariable-calculus']"
3,Why can't I measure the distance this way?,Why can't I measure the distance this way?,,"The problem is to find the distance between the point $(3, -2, 4)$ and the plane $2x-5y+z=10$ I tought of doing it like this: The shortest line between the point and the plane is orthogonal to the plane, so it's direction is $<2, -5, 1>$, and a point on this line is $(3, -2, 4)$ . That means that the line has the parametric equations $x=3+2t, y=-2-5t, z=4+t$. I plugged in $x, y, z$ into the plane equation and got $\dfrac{1}{11}$ for $t$. This means that the distance between the plane and the point should be the distance between the point $(3, -2, 4)$ and the point $x=3+2(\dfrac{1}{11}), y=-2-5(\dfrac{1}{11}), z=4+(\dfrac{1}{11})$ I got $\dfrac{\sqrt{29}}{11}$ as the distance, but WolframAlpha says its $\sqrt{\frac{10}{3}}$","The problem is to find the distance between the point $(3, -2, 4)$ and the plane $2x-5y+z=10$ I tought of doing it like this: The shortest line between the point and the plane is orthogonal to the plane, so it's direction is $<2, -5, 1>$, and a point on this line is $(3, -2, 4)$ . That means that the line has the parametric equations $x=3+2t, y=-2-5t, z=4+t$. I plugged in $x, y, z$ into the plane equation and got $\dfrac{1}{11}$ for $t$. This means that the distance between the plane and the point should be the distance between the point $(3, -2, 4)$ and the point $x=3+2(\dfrac{1}{11}), y=-2-5(\dfrac{1}{11}), z=4+(\dfrac{1}{11})$ I got $\dfrac{\sqrt{29}}{11}$ as the distance, but WolframAlpha says its $\sqrt{\frac{10}{3}}$",,"['calculus', 'geometry', 'multivariable-calculus', 'analytic-geometry', '3d']"
4,I had to evaluate the surface intregral $\int\int_s \operatorname{curl}\vec{F} \cdot \hat{n}\ dS $,I had to evaluate the surface intregral,\int\int_s \operatorname{curl}\vec{F} \cdot \hat{n}\ dS ,"where S is that part of surface of paraboloid   $z= 1 - x^2 -y^2$ for which $z \geqslant 0 $ and $ \vec{F} = y\hat{i} + z\hat{j} + x\hat{k}  $ I found the curl of $\vec{F}$ which was correct. But for finding $\hat{n}$ I assumed $\phi = z + x^2 + y^2 -1$ and used $$ \hat{n} = \frac{\operatorname{grad}\phi}{|\operatorname{grad} \phi|} = \frac{2x \hat{i} +2y\hat{j}+\hat{k}}{3}$$ but in the book it is written that $\hat{n}$ is ""obviously"" $\hat{k}$ Is it correct or wrong and why?","where S is that part of surface of paraboloid   $z= 1 - x^2 -y^2$ for which $z \geqslant 0 $ and $ \vec{F} = y\hat{i} + z\hat{j} + x\hat{k}  $ I found the curl of $\vec{F}$ which was correct. But for finding $\hat{n}$ I assumed $\phi = z + x^2 + y^2 -1$ and used $$ \hat{n} = \frac{\operatorname{grad}\phi}{|\operatorname{grad} \phi|} = \frac{2x \hat{i} +2y\hat{j}+\hat{k}}{3}$$ but in the book it is written that $\hat{n}$ is ""obviously"" $\hat{k}$ Is it correct or wrong and why?",,"['multivariable-calculus', 'vectors']"
5,"Why does $\left(\int_{-\infty}^{\infty}e^{-t^2} dt \right)^2= \int_{-\infty}^{\infty}\int_{-\infty}^{\infty}e^{-(x^2 + y^2)}dx\,dy$?",Why does ?,"\left(\int_{-\infty}^{\infty}e^{-t^2} dt \right)^2= \int_{-\infty}^{\infty}\int_{-\infty}^{\infty}e^{-(x^2 + y^2)}dx\,dy","Why does  $$\left(\int_{-\infty}^{\infty}e^{-t^2}dt\right)^2 = \int_{-\infty}^{\infty}\int_{-\infty}^{\infty}e^{-(x^2 + y^2)}dx\,dy ?$$ This came up while studying Fourier analysis. What's the underlying theorem?","Why does  $$\left(\int_{-\infty}^{\infty}e^{-t^2}dt\right)^2 = \int_{-\infty}^{\infty}\int_{-\infty}^{\infty}e^{-(x^2 + y^2)}dx\,dy ?$$ This came up while studying Fourier analysis. What's the underlying theorem?",,"['multivariable-calculus', 'definite-integrals', 'fourier-analysis', 'improper-integrals']"
6,Showing that $f_{xy} = f_{yx}$ for the following function.,Showing that  for the following function.,f_{xy} = f_{yx},"Show that for the function  $$f(x,y) = 9x^3y+2y^3+10x^2y^2+9$$ satisfies the equality $$f_{yx} = f_{xy}$$ by computing the partial derivatives. I know that $f_y= 9x^3+6y^2$ because we exclude all terms with $x$ and constants. So $f_{yx}=27x^2$. $f_x = 10y^2$ because all the terms with $y$ go away. But it does not satisfy the equality. Why not?","Show that for the function  $$f(x,y) = 9x^3y+2y^3+10x^2y^2+9$$ satisfies the equality $$f_{yx} = f_{xy}$$ by computing the partial derivatives. I know that $f_y= 9x^3+6y^2$ because we exclude all terms with $x$ and constants. So $f_{yx}=27x^2$. $f_x = 10y^2$ because all the terms with $y$ go away. But it does not satisfy the equality. Why not?",,"['calculus', 'multivariable-calculus', 'partial-derivative']"
7,"What is the matrix $\left[ DS(A) \right]$, which gives $\left[ DS(A) \right] H=AH+HA$?","What is the matrix , which gives ?",\left[ DS(A) \right] \left[ DS(A) \right] H=AH+HA,"In Hubbard's multivariable calculus book $DS(A):H \mapsto AH+HA$ is  introduced as a linear transformation where $A$ is an $n \times n$ matrix,  $S(A)=A^2$, and $D$ is the notation for derivative.  It is used to prove that $S$ has a derivative if $\left[ DS(A) \right] H=AH+HA$ using the following limit: $$\lim_{H \to 0}\frac{1}{||H||}||(S(A+H)-S(A))-\left[ DS(A) \right] H||=0$$ This limit really gives $0$, so S has a derivative. But the actual derivative matrix $\left[ DS(A) \right]$ is not given in the book and I can't see what kind of a matrix gives $AH+HA$ when it is multiplied by $H$. What is this matrix?","In Hubbard's multivariable calculus book $DS(A):H \mapsto AH+HA$ is  introduced as a linear transformation where $A$ is an $n \times n$ matrix,  $S(A)=A^2$, and $D$ is the notation for derivative.  It is used to prove that $S$ has a derivative if $\left[ DS(A) \right] H=AH+HA$ using the following limit: $$\lim_{H \to 0}\frac{1}{||H||}||(S(A+H)-S(A))-\left[ DS(A) \right] H||=0$$ This limit really gives $0$, so S has a derivative. But the actual derivative matrix $\left[ DS(A) \right]$ is not given in the book and I can't see what kind of a matrix gives $AH+HA$ when it is multiplied by $H$. What is this matrix?",,['linear-algebra']
8,$f(x)$ be the characteristic polynomial of a matrix $A \in M_n(\mathbb R)$ ; then is it true that $f(1)=1+\operatorname{trace}(A)+O(\|A\|^2)$?,be the characteristic polynomial of a matrix  ; then is it true that ?,f(x) A \in M_n(\mathbb R) f(1)=1+\operatorname{trace}(A)+O(\|A\|^2),Let $f(x)$ be the characteristic polynomial of a matrix $A \in M_n(\mathbb R)$; then is it true that $f(1)=1+\operatorname{trace}(A)+O(\|A\|^2)$ ?   I need a proof if it is true ; or any modification that is true .  Thanks in advance,Let $f(x)$ be the characteristic polynomial of a matrix $A \in M_n(\mathbb R)$; then is it true that $f(1)=1+\operatorname{trace}(A)+O(\|A\|^2)$ ?   I need a proof if it is true ; or any modification that is true .  Thanks in advance,,"['linear-algebra', 'matrices']"
9,"How to find cartesian coordinate of velocity of particle on the trajectory, $Ax^2 +2Bxy +Cy^2=1, A,B,C >0.$","How to find cartesian coordinate of velocity of particle on the trajectory,","Ax^2 +2Bxy +Cy^2=1, A,B,C >0.","Consider a particle with constant speed $|w|=w_o$ moving on trajectory $Ax^2 +2Bxy +Cy^2=1, A,B,C >0.$ Could anyone advise me how to express cartesian coordinates of $v$ in terms of $x$ and $y \ ?$ Here is my attempt: Let $x=u\text{cos}\theta-v\text{sin}\theta, \ y=u\text{sin}\theta+v\text{cos}\theta,$ where $\text{tan}(2\theta) = \dfrac{B}{A-C}.$ Then the equation is reduced to one in terms of only $u^2$ and $v^2.$ So the space curve $r(u)=(u,g(u))$, for some function $g.$ And $w=\dfrac{dr(u)}{dt}= (\dfrac{du}{dt}, \dfrac{dg}{du} \dfrac{du}{dt}) \ ?$","Consider a particle with constant speed $|w|=w_o$ moving on trajectory $Ax^2 +2Bxy +Cy^2=1, A,B,C >0.$ Could anyone advise me how to express cartesian coordinates of $v$ in terms of $x$ and $y \ ?$ Here is my attempt: Let $x=u\text{cos}\theta-v\text{sin}\theta, \ y=u\text{sin}\theta+v\text{cos}\theta,$ where $\text{tan}(2\theta) = \dfrac{B}{A-C}.$ Then the equation is reduced to one in terms of only $u^2$ and $v^2.$ So the space curve $r(u)=(u,g(u))$, for some function $g.$ And $w=\dfrac{dr(u)}{dt}= (\dfrac{du}{dt}, \dfrac{dg}{du} \dfrac{du}{dt}) \ ?$",,"['multivariable-calculus', 'differential-geometry']"
10,Does $\int_cf\:dx$ depend on the parameterization of $C$?,Does  depend on the parameterization of ?,\int_cf\:dx C,"As long as we don't switch the orientation, does $\int_cf\:dx$ depend on the parameterization of $C$ or no? I have a feeling that it does not depend. However, can someone give me a rigorous proof as to why it does not depend?","As long as we don't switch the orientation, does $\int_cf\:dx$ depend on the parameterization of $C$ or no? I have a feeling that it does not depend. However, can someone give me a rigorous proof as to why it does not depend?",,['multivariable-calculus']
11,"Why does $\nabla F{(x,y,z)}$ point in the direction of greatest increase of the function, and why is $|\nabla F(x,y,z)|$ its slope?","Why does  point in the direction of greatest increase of the function, and why is  its slope?","\nabla F{(x,y,z)} |\nabla F(x,y,z)|","Why does $$\nabla F{(x,y,z)}$$ point in the direction of greatest increase of the function and why is $$|\nabla F{(x,y,z)}|$$ it's slope (I should actually ask what the slope would mean here as I'm not entirely sure here as we are working in $3D$ and I can't really picture what a slope would be here normally I think a line in $2D$ and it's a change in $y$) over a change in $x$ but obviously that intuition fails here? After reading about the $\nabla$ operator severals times I understand that it has these properties but I'm not exactly sure why. I know people usually want to see effort on what you have done here but I'm not really sure what to put here, I don't see why this should be the case other than thinking there could possibly be some link between the rate of increase and the gradients but as for a proof I have no idea. Thanks.","Why does $$\nabla F{(x,y,z)}$$ point in the direction of greatest increase of the function and why is $$|\nabla F{(x,y,z)}|$$ it's slope (I should actually ask what the slope would mean here as I'm not entirely sure here as we are working in $3D$ and I can't really picture what a slope would be here normally I think a line in $2D$ and it's a change in $y$) over a change in $x$ but obviously that intuition fails here? After reading about the $\nabla$ operator severals times I understand that it has these properties but I'm not exactly sure why. I know people usually want to see effort on what you have done here but I'm not really sure what to put here, I don't see why this should be the case other than thinking there could possibly be some link between the rate of increase and the gradients but as for a proof I have no idea. Thanks.",,['multivariable-calculus']
12,How to express curvature of a level set in terms of derivatives of a function?,How to express curvature of a level set in terms of derivatives of a function?,,"Suppose I have a smooth function $u:\mathbb R^n\to\mathbb R$. Assume that its gradient doesn't vanish (near any point where we investigate it). Is there a list of different (intrinsic and extrinsic) curvature quantities of level sets of $u$ in terms of derivatives of $u$? I have been unable to find such a list. The level set is a Riemannian manifold and its curvature can be described by various curvature tensors. It is also a submanifold of the ambient $\mathbb R^n$ and the second fundamental form describes its curvature as a submanifold. These are what I refer to as intrinsic and extrinsic curvature quantities. Here are two examples of questions that the list should answer. I am looking for a resource that would contain the answer to these two questions and many others, not just the answer to these two. These example questions give a criterion for what I am looking for, that's all. This question is a reference request. If $n=3$, what is the Gaussian curvature of $u^{-1}(u(0))$ at $0$ in terms of derivatives of $u$? How to express the mean curvature of the level set in terms of derivatives of $u$ in any dimension?","Suppose I have a smooth function $u:\mathbb R^n\to\mathbb R$. Assume that its gradient doesn't vanish (near any point where we investigate it). Is there a list of different (intrinsic and extrinsic) curvature quantities of level sets of $u$ in terms of derivatives of $u$? I have been unable to find such a list. The level set is a Riemannian manifold and its curvature can be described by various curvature tensors. It is also a submanifold of the ambient $\mathbb R^n$ and the second fundamental form describes its curvature as a submanifold. These are what I refer to as intrinsic and extrinsic curvature quantities. Here are two examples of questions that the list should answer. I am looking for a resource that would contain the answer to these two questions and many others, not just the answer to these two. These example questions give a criterion for what I am looking for, that's all. This question is a reference request. If $n=3$, what is the Gaussian curvature of $u^{-1}(u(0))$ at $0$ in terms of derivatives of $u$? How to express the mean curvature of the level set in terms of derivatives of $u$ in any dimension?",,"['multivariable-calculus', 'differential-geometry', 'reference-request', 'riemannian-geometry', 'curvature']"
13,$\displaystyle\iiint_E (x²+y²) \;\mathrm{d}V$ where $E$ is the region between the spheres $x^2+y^2+z^2 = 4$ and $x^2 + y^2 + z^2 = 9$,where  is the region between the spheres  and,\displaystyle\iiint_E (x²+y²) \;\mathrm{d}V E x^2+y^2+z^2 = 4 x^2 + y^2 + z^2 = 9,"To be honest I'm not even too sure of what I'm integrating. I'm picturing two spheres touching each other, with a cylinder of two different radii going from the center of one to the other and I'm supposed to calculate the volume of the space inside the cylinder not occupied by the spheres. Is that correct? I'm still stuck though, I don't really know how to start this. EDIT - Accidentally wrote the wrong integral.","To be honest I'm not even too sure of what I'm integrating. I'm picturing two spheres touching each other, with a cylinder of two different radii going from the center of one to the other and I'm supposed to calculate the volume of the space inside the cylinder not occupied by the spheres. Is that correct? I'm still stuck though, I don't really know how to start this. EDIT - Accidentally wrote the wrong integral.",,['multivariable-calculus']
14,Example where partial derivatives commute but are not continuous.,Example where partial derivatives commute but are not continuous.,,"I am looking for an example of a function $f:\mathbb R^2\to\mathbb R$ such that there is a point $x\in\mathbb R^2$ with the following properties: 1) All partial derivatives of second order exist in a neighborhood of $x$. 2) At least one of those partial derivatives is not continuous in $x$. 3) The Hessian matrix of $f$ in $x$ is symmetric. I think it should be possible to find such a function but I wasn't very successful in finding one. If we drop the first property it is easy, with it however, I didn't find any example yet. Any help appreciated.","I am looking for an example of a function $f:\mathbb R^2\to\mathbb R$ such that there is a point $x\in\mathbb R^2$ with the following properties: 1) All partial derivatives of second order exist in a neighborhood of $x$. 2) At least one of those partial derivatives is not continuous in $x$. 3) The Hessian matrix of $f$ in $x$ is symmetric. I think it should be possible to find such a function but I wasn't very successful in finding one. If we drop the first property it is easy, with it however, I didn't find any example yet. Any help appreciated.",,"['real-analysis', 'multivariable-calculus', 'derivatives', 'partial-derivative']"
15,"Inverse of the complex exponential function, considered as a multivariable function","Inverse of the complex exponential function, considered as a multivariable function",,"Consider the complex exponential function $g: \mathbb{C} \to \mathbb{C}, z \mapsto e^z$ . When identifying $\mathbb{C}$ with $\mathbb{R}^2$ in the natural way, then $g$ can be considered as a transformation $f: \mathbb{R}^2 \to \mathbb{R}^2$ . First, I want to concretely find $f(x, y)$ for $(x, y) \in \mathbb{R}^2$ . Next, consider the straight lines parallel to the $x$ - and $y$ -axis. How do their images regarding $f$ look like? Finally, I want to show that $f$ (and therefore the exponential function $g$ ) are locally invertible, (meaning that for each $(x, y) \in \mathbb{R}^2$ , there is a neighbourhood $U \subseteq \mathbb{R}^2$ , $U$ open, in which $f$ is bijective and therefore can be inverted), but that $f$ doesn't have a global inverse function. My attempt: for $z = a + bi \in \mathbb{C}$ : $$e^z = e^{a+bi} = e^a(\cos(b)+ i ºsin(b)) = e^a\cdot \cos(b) + i\cdot e^a\cdot \sin(b)$$ And therefore, I would assume that $f(x, y) = \pmatrix{e^x \cos(y) \cr e^x \sin(y)}$ . If I'm correct with this, I would assume that one could get the image of these straight lines by just fixing either $x$ or $y$ , and seeing what happens: the image of these straight lines would then be $c \pmatrix{\cos(y) \cr \sin(y)}$ or $\pmatrix{c_1 e^x \cr c_2 e^x}$ , with $c, c_1, c_2$ constant (because of the fixed other parameter), would they? I don't really know how to approach the second part though. Thanks in advance.","Consider the complex exponential function . When identifying with in the natural way, then can be considered as a transformation . First, I want to concretely find for . Next, consider the straight lines parallel to the - and -axis. How do their images regarding look like? Finally, I want to show that (and therefore the exponential function ) are locally invertible, (meaning that for each , there is a neighbourhood , open, in which is bijective and therefore can be inverted), but that doesn't have a global inverse function. My attempt: for : And therefore, I would assume that . If I'm correct with this, I would assume that one could get the image of these straight lines by just fixing either or , and seeing what happens: the image of these straight lines would then be or , with constant (because of the fixed other parameter), would they? I don't really know how to approach the second part though. Thanks in advance.","g: \mathbb{C} \to \mathbb{C}, z \mapsto e^z \mathbb{C} \mathbb{R}^2 g f: \mathbb{R}^2 \to \mathbb{R}^2 f(x, y) (x, y) \in \mathbb{R}^2 x y f f g (x, y) \in \mathbb{R}^2 U \subseteq \mathbb{R}^2 U f f z = a + bi \in \mathbb{C} e^z = e^{a+bi} = e^a(\cos(b)+ i ºsin(b)) = e^a\cdot \cos(b) + i\cdot e^a\cdot \sin(b) f(x, y) = \pmatrix{e^x \cos(y) \cr e^x \sin(y)} x y c \pmatrix{\cos(y) \cr \sin(y)} \pmatrix{c_1 e^x \cr c_2 e^x} c, c_1, c_2","['analysis', 'multivariable-calculus', 'exponential-function']"
16,"How can I evaluate this integral over a sphere, with surface area element instead of volume element?","How can I evaluate this integral over a sphere, with surface area element instead of volume element?",,"$$\int_S (x^2 + y^2)d\sigma,$$ where S is the sphere of radius 1 centered at (0,0,0) and $\sigma$ is surface area. I would like some hints on how to proceed.  This is tricky, since I am not being asked for a volume integral computation, so I can't use spherical coordinates, I think. Thanks,","$$\int_S (x^2 + y^2)d\sigma,$$ where S is the sphere of radius 1 centered at (0,0,0) and $\sigma$ is surface area. I would like some hints on how to proceed.  This is tricky, since I am not being asked for a volume integral computation, so I can't use spherical coordinates, I think. Thanks,",,"['real-analysis', 'multivariable-calculus', 'spherical-coordinates', 'surface-integrals']"
17,Why is the support function $\mu_K$ differentiable iff $\mu_K(v)=v\cdot x$ for a unique $x\in K$?,Why is the support function  differentiable iff  for a unique ?,\mu_K \mu_K(v)=v\cdot x x\in K,"I am reading an economics book (for those who are interested, MWG Microeconomic Theory) and there's a theorem that was just given without proof, but I am interested in the proof - also because I cannot seem to get a good feel for the theorem and maybe the proof would help. Theorem: Let $K$ be a non-empty closed subset of $\mathbb{R}^n$ (not necessarily convex). Define the support function $\mu_K(\cdot):\mathbb{R}^n \to \mathbb{R}$ to be $\mu_K(v)=\inf\{v\cdot x : x\in K\}$. Then there is a unique $\tilde{x} \in K$ such that $\tilde{v}\cdot \tilde{x}=\mu_K(\tilde{v})$ if and only if $\mu_K(\cdot)$ is differentiable at $\tilde{v}$. Moreover, in this case, $\nabla \mu_K(\tilde{v})=\tilde{x}$. Further query: In order to get a better feel for the theorem, I thought about the example where $K$ is something like banana-shaped (can't help it, Minions) and $\tilde{v}$ is the direction where there would be two minimizing $\tilde{x}$. However, it is not intuitive to me why $\mu_K(\cdot)$ would not be differentiable at $\tilde{v}$. So as a bonus, does anyone have a good feel on why this is so? Another example I am interested in thinking is convex polygon and $\tilde{v}$ is perpendicular to one of the edges. These will help me get a better feel of the theorem in general.","I am reading an economics book (for those who are interested, MWG Microeconomic Theory) and there's a theorem that was just given without proof, but I am interested in the proof - also because I cannot seem to get a good feel for the theorem and maybe the proof would help. Theorem: Let $K$ be a non-empty closed subset of $\mathbb{R}^n$ (not necessarily convex). Define the support function $\mu_K(\cdot):\mathbb{R}^n \to \mathbb{R}$ to be $\mu_K(v)=\inf\{v\cdot x : x\in K\}$. Then there is a unique $\tilde{x} \in K$ such that $\tilde{v}\cdot \tilde{x}=\mu_K(\tilde{v})$ if and only if $\mu_K(\cdot)$ is differentiable at $\tilde{v}$. Moreover, in this case, $\nabla \mu_K(\tilde{v})=\tilde{x}$. Further query: In order to get a better feel for the theorem, I thought about the example where $K$ is something like banana-shaped (can't help it, Minions) and $\tilde{v}$ is the direction where there would be two minimizing $\tilde{x}$. However, it is not intuitive to me why $\mu_K(\cdot)$ would not be differentiable at $\tilde{v}$. So as a bonus, does anyone have a good feel on why this is so? Another example I am interested in thinking is convex polygon and $\tilde{v}$ is perpendicular to one of the edges. These will help me get a better feel of the theorem in general.",,"['multivariable-calculus', 'convex-analysis', 'support-function']"
18,"Choosing a surface that makes the flux of F maximal,","Choosing a surface that makes the flux of F maximal,",,"For a closed surface S in $R^3$, consider the flux of F, given by the usual flux integral.  For what choice of S will the flux be maximal ? So, I want to apply the divergence theorem and instead look at the triple integral of the divergence of the given vector field F (over a solid that is enclosed by S.) Since the flux integral = the divergence integral, I can aim to maximize the divergence integral. My computation of the divergence gives me -3($x^2 + y^2 + z^2 - \frac{5}{3}$), so this would be the integrand in the triple integral. It sounds reasonable that in order to maximize this triple integral, I should maximize the integrand.  How do I do that? My attempt was to make $x^2 + y^2 + z^2$  - $\frac{5}{3}$ < 0, since there's a factor of -3 to consider.  negative * negative will give me a positive integrand - which would be good for maximizing the flux of F. Then this tells me that I should choose a sphere of radius $\sqrt{(\frac{5}{3})}$. I carried out my work and it looks like I got the correct answer. But I feel like I chose my sphere ...by luck. How do I know for sure that I've maximized the integrand, simply by making $x^2 + y^2 + z^2$  - $\frac{5}{3}$ < 0?  Could I have done even better, achieving a better maximum?  I simply knew that this factor had to be < 0, since it was being multiplied by -3. Thanks,","For a closed surface S in $R^3$, consider the flux of F, given by the usual flux integral.  For what choice of S will the flux be maximal ? So, I want to apply the divergence theorem and instead look at the triple integral of the divergence of the given vector field F (over a solid that is enclosed by S.) Since the flux integral = the divergence integral, I can aim to maximize the divergence integral. My computation of the divergence gives me -3($x^2 + y^2 + z^2 - \frac{5}{3}$), so this would be the integrand in the triple integral. It sounds reasonable that in order to maximize this triple integral, I should maximize the integrand.  How do I do that? My attempt was to make $x^2 + y^2 + z^2$  - $\frac{5}{3}$ < 0, since there's a factor of -3 to consider.  negative * negative will give me a positive integrand - which would be good for maximizing the flux of F. Then this tells me that I should choose a sphere of radius $\sqrt{(\frac{5}{3})}$. I carried out my work and it looks like I got the correct answer. But I feel like I chose my sphere ...by luck. How do I know for sure that I've maximized the integrand, simply by making $x^2 + y^2 + z^2$  - $\frac{5}{3}$ < 0?  Could I have done even better, achieving a better maximum?  I simply knew that this factor had to be < 0, since it was being multiplied by -3. Thanks,",,"['calculus', 'real-analysis', 'multivariable-calculus', 'optimization']"
19,"If the iteration $x^{k+1}=x^k-t_kH_k^{-1}\nabla f(x^k)$ converges superlinearly to a stationary point $x^*\ne x^k$, then $t_k\to 1$","If the iteration  converges superlinearly to a stationary point , then",x^{k+1}=x^k-t_kH_k^{-1}\nabla f(x^k) x^*\ne x^k t_k\to 1,"Let $f\in C^2(\mathbb{R}^n)$ $(H_k)_{k\in\mathbb{N}_0}\subseteq\text{GL}_n(\mathbb{R})$ $x^0\in\mathbb{R}^n$ and $$x^{k+1}:=x^k+t_k d^k\;\;\;\text{for }k\in\mathbb{N}_0\tag{1}$$ with $(t_k)_{k\in\mathbb{N}_0}\subseteq (0,\infty)$ and $$H_kd^k+\nabla f(x^k)=0\;\;\;\text{for all }k\in\mathbb{N}_0\tag{2}$$ $x^\ast\in\mathbb{R}^n\setminus\left\{x^k:k\in\mathbb{N}_0\right\}$ with $x_k\stackrel{k\to\infty}{\to}x^*$ and $\nabla^2f(x^*)\in\text{GL}_n(\mathbb{R})$ Suppose $x_k\stackrel{k\to\infty}{\to}x^*$ superlinearly, i.e. $$\frac{\left\|x^{k+1}-x^*\right\|}{\left\|x^k-x^*\right\|}\stackrel{k\to\infty}{\to}0\tag{3}$$ and $x^*$ is stationary, i.e. $$\nabla f(x^*)=0\tag{4}$$ How can we conclude, that we must have $t_k\stackrel{k\to\infty}{\to}1$? Clearly, by $(1)$ and $(2)$ we've got $$-t_kH_k^{-1}\nabla f(x^k)=x^{k+1}-x^k\stackrel{k\to\infty}{\to}0\tag{5}\;,$$ but is that the right track? Unfortunately, I'm unable to proceed. EDIT: If someone can prove the statement under further restrictions, e.g. $\left\|\;\cdot\;\right\|$-boundedness of all $H_k^{-1}$, I would be happy too.","Let $f\in C^2(\mathbb{R}^n)$ $(H_k)_{k\in\mathbb{N}_0}\subseteq\text{GL}_n(\mathbb{R})$ $x^0\in\mathbb{R}^n$ and $$x^{k+1}:=x^k+t_k d^k\;\;\;\text{for }k\in\mathbb{N}_0\tag{1}$$ with $(t_k)_{k\in\mathbb{N}_0}\subseteq (0,\infty)$ and $$H_kd^k+\nabla f(x^k)=0\;\;\;\text{for all }k\in\mathbb{N}_0\tag{2}$$ $x^\ast\in\mathbb{R}^n\setminus\left\{x^k:k\in\mathbb{N}_0\right\}$ with $x_k\stackrel{k\to\infty}{\to}x^*$ and $\nabla^2f(x^*)\in\text{GL}_n(\mathbb{R})$ Suppose $x_k\stackrel{k\to\infty}{\to}x^*$ superlinearly, i.e. $$\frac{\left\|x^{k+1}-x^*\right\|}{\left\|x^k-x^*\right\|}\stackrel{k\to\infty}{\to}0\tag{3}$$ and $x^*$ is stationary, i.e. $$\nabla f(x^*)=0\tag{4}$$ How can we conclude, that we must have $t_k\stackrel{k\to\infty}{\to}1$? Clearly, by $(1)$ and $(2)$ we've got $$-t_kH_k^{-1}\nabla f(x^k)=x^{k+1}-x^k\stackrel{k\to\infty}{\to}0\tag{5}\;,$$ but is that the right track? Unfortunately, I'm unable to proceed. EDIT: If someone can prove the statement under further restrictions, e.g. $\left\|\;\cdot\;\right\|$-boundedness of all $H_k^{-1}$, I would be happy too.",,"['analysis', 'multivariable-calculus', 'optimization', 'numerical-methods']"
20,What is the physical meaning of this integral?,What is the physical meaning of this integral?,,Let $$I=\int_S ~z~dS$$ Where $S$ is the surface of a hemisphere with equation $x^2+y^2+z^2=4~~~~z \geq0$. I know $$\int_S~dS$$ would be the surface area of the hemisphere but I can't figure out how the $z$ would change this?,Let $$I=\int_S ~z~dS$$ Where $S$ is the surface of a hemisphere with equation $x^2+y^2+z^2=4~~~~z \geq0$. I know $$\int_S~dS$$ would be the surface area of the hemisphere but I can't figure out how the $z$ would change this?,,['multivariable-calculus']
21,"Integration of $|y|^{-2}$ over the ball $B(0,r)$",Integration of  over the ball,"|y|^{-2} B(0,r)","Can one explain why taking an integral of $\frac 1{|y|}$ over a ball in $\mathbb{R}^3$ of radius $r$ is equal to a constant times $r^2$? If $y \in \mathbb{R}^3$, then $$\int_{B(0,r)} \frac{dy}{|y|}=Cr^2$$    where $C$ is an appropriately chosen constant. Why is this true? (This is part of a proof in §12.3.2 of PDE Evans, 2nd edition.)","Can one explain why taking an integral of $\frac 1{|y|}$ over a ball in $\mathbb{R}^3$ of radius $r$ is equal to a constant times $r^2$? If $y \in \mathbb{R}^3$, then $$\int_{B(0,r)} \frac{dy}{|y|}=Cr^2$$    where $C$ is an appropriately chosen constant. Why is this true? (This is part of a proof in §12.3.2 of PDE Evans, 2nd edition.)",,"['integration', 'multivariable-calculus']"
22,Show that Laplacian is zero,Show that Laplacian is zero,,"Let $u: \mathbb{R}^n \rightarrow \mathbb{R}$ be harmonic, i.e. $\Delta u =0.$ Now, I want to show that $\Delta (u(Ox+b))=0$ for an orthogonal matrix $O$ and a constant vector $b$. Does anybody know how this can be shown? Regarding the answer, I received. mhmm. $D(u(Ox+b)) = Du (Ox+b)D(Ox+b)= Du(Ox+b)O.$ I don't quite see how the divergence of this could look like?","Let $u: \mathbb{R}^n \rightarrow \mathbb{R}$ be harmonic, i.e. $\Delta u =0.$ Now, I want to show that $\Delta (u(Ox+b))=0$ for an orthogonal matrix $O$ and a constant vector $b$. Does anybody know how this can be shown? Regarding the answer, I received. mhmm. $D(u(Ox+b)) = Du (Ox+b)D(Ox+b)= Du(Ox+b)O.$ I don't quite see how the divergence of this could look like?",,"['calculus', 'real-analysis', 'analysis', 'multivariable-calculus']"
23,Finding extreme values of a variable on an intersection of a sphere and a plane,Finding extreme values of a variable on an intersection of a sphere and a plane,,"Determine the minimum and maximum value of the variable $z$ defined by the curve given by: \begin{cases} x^2+y^2+z^2=1 \\ x+2y+2z=0 \end{cases} So do I need to find a function $z=f(x,y)$ or just find, implicitly, the derivatives that satisfy $f'_x =0, f'_y=0$? I don't know if it is possible to explicitly parametrize the curve with $z=t$, because that is probably how I would usually solve this kind of problem. Any advice?","Determine the minimum and maximum value of the variable $z$ defined by the curve given by: \begin{cases} x^2+y^2+z^2=1 \\ x+2y+2z=0 \end{cases} So do I need to find a function $z=f(x,y)$ or just find, implicitly, the derivatives that satisfy $f'_x =0, f'_y=0$? I don't know if it is possible to explicitly parametrize the curve with $z=t$, because that is probably how I would usually solve this kind of problem. Any advice?",,"['multivariable-calculus', 'optimization']"
24,Need visualization advice for learning partial derivatives and calculus with more than one variable.,Need visualization advice for learning partial derivatives and calculus with more than one variable.,,"Okay so I just recently started learning calculus with more than one variable and whilst I'm coming to grips with many of the ideas and stuff I'm finding it difficult to visualize certain things for example, what does a directional derivative look like in 3D and stuff like this. Is there a good site or something where I can get a visualization to try and help cement my understanding? Thank you.","Okay so I just recently started learning calculus with more than one variable and whilst I'm coming to grips with many of the ideas and stuff I'm finding it difficult to visualize certain things for example, what does a directional derivative look like in 3D and stuff like this. Is there a good site or something where I can get a visualization to try and help cement my understanding? Thank you.",,"['multivariable-calculus', 'reference-request', 'vectors', 'partial-derivative', 'visualization']"
25,A counterexample for a smoth version of Tietze extension theorem,A counterexample for a smoth version of Tietze extension theorem,,Is there any function $f:F\subset \mathbb{R}^2\rightarrow \mathbb{R}$ with $F$ closed such that $f|F$ is differentiable in every accumulation point but there is no differentiable extension to the entire plane? I think that such function exists but I can't find any.,Is there any function $f:F\subset \mathbb{R}^2\rightarrow \mathbb{R}$ with $F$ closed such that $f|F$ is differentiable in every accumulation point but there is no differentiable extension to the entire plane? I think that such function exists but I can't find any.,,"['real-analysis', 'general-topology', 'multivariable-calculus', 'differential']"
26,Is level set near a maximum value a circle?,Is level set near a maximum value a circle?,,"Let $f$ be a $C^2$ function defined on $[0,1] \times [0,1]$. Let $0 \leq f(x) < 1$ on $[0,1] \times [0,1] \setminus \left(\frac{1}{2},\frac{1}{2}\right)$ and $f(\frac{1}{2},\frac{1}{2})=1$. It has no critical point except $(\frac{1}{2},\frac{1}{2})$. I wonder there exists a number $0<a<1$ such that $f^{-1}(a)$ to be a circle. By the smooth manifold theory, $f^{-1}(a)$ is always a 1-dimensional submanifold. Since $f$ is continuous, it is closed. Thus, it is a compact. But it can still be a line segment. Any reference are welcome. Thanks in advance.","Let $f$ be a $C^2$ function defined on $[0,1] \times [0,1]$. Let $0 \leq f(x) < 1$ on $[0,1] \times [0,1] \setminus \left(\frac{1}{2},\frac{1}{2}\right)$ and $f(\frac{1}{2},\frac{1}{2})=1$. It has no critical point except $(\frac{1}{2},\frac{1}{2})$. I wonder there exists a number $0<a<1$ such that $f^{-1}(a)$ to be a circle. By the smooth manifold theory, $f^{-1}(a)$ is always a 1-dimensional submanifold. Since $f$ is continuous, it is closed. Thus, it is a compact. But it can still be a line segment. Any reference are welcome. Thanks in advance.",,"['analysis', 'multivariable-calculus', 'differential-geometry', 'differential-topology']"
27,Intuitive explanation of the potential function of a vector field,Intuitive explanation of the potential function of a vector field,,"Suppose I have some vector field $$\vec{f}(x,y)=\begin{pmatrix}A(x,y)\\B(x,y)\end{pmatrix}$$ then the potential function (if the field is conservative) can be found by integrating  $A$ with respect to $x$ and $B$ with respect to $y$ and then ""unifying"" the two solutions into a single function. But what does the potential function really mean? Can somebody give me a simple intuitive explanation (maybe graphic) of what this function means?","Suppose I have some vector field $$\vec{f}(x,y)=\begin{pmatrix}A(x,y)\\B(x,y)\end{pmatrix}$$ then the potential function (if the field is conservative) can be found by integrating  $A$ with respect to $x$ and $B$ with respect to $y$ and then ""unifying"" the two solutions into a single function. But what does the potential function really mean? Can somebody give me a simple intuitive explanation (maybe graphic) of what this function means?",,"['real-analysis', 'multivariable-calculus', 'vector-analysis', 'vector-fields']"
28,Parametrising a Sphere,Parametrising a Sphere,,"If parametrising a sphere $r=(\cos{u}\cos{v},\cos{u}\sin{v},\sin{u})$ is it true that limits for $u$ and $v$ will be $-\pi/2$ and $\pi/2$ and $0$ and $2\pi$ respectively? Why is this different to when parametrising a sphere, with parametrization $\rho\sin{\phi}\cos{\theta}, \rho\sin{\phi}\sin{\theta}, \rho\cos{\phi}$ where the limits of $\phi$ are between and $0$ and $\pi$?","If parametrising a sphere $r=(\cos{u}\cos{v},\cos{u}\sin{v},\sin{u})$ is it true that limits for $u$ and $v$ will be $-\pi/2$ and $\pi/2$ and $0$ and $2\pi$ respectively? Why is this different to when parametrising a sphere, with parametrization $\rho\sin{\phi}\cos{\theta}, \rho\sin{\phi}\sin{\theta}, \rho\cos{\phi}$ where the limits of $\phi$ are between and $0$ and $\pi$?",,"['calculus', 'multivariable-calculus']"
29,"Evaluating a seemingly simple limit, using continuity of the partial derivative","Evaluating a seemingly simple limit, using continuity of the partial derivative",,"I am stuck with a seemingly easy problem. I have a function $f(x,y)$ which has continuous first derivatives. Now, I want to show that: $$ \lim_{h \to 0}\dfrac{f(a+hu,b+hv)-f(a,b+hv)}{hu} =f_x(a,b)$$ This is what I have thought: Since the derivatives are continuous, we know that, for each $\epsilon > 0$, there is a $\delta > 0$ such that it is: $$0 < ((x-a)^2 + (y-b)^2)^{1/2} < \delta \implies |f_x(x,y) - f_x(a,b) | = \left|\lim_{h \to 0}\dfrac{f(x+h,y)-f(x,y)}{h} - \lim_{h \to 0}\dfrac{f(a+h,b)-f(a,b)}{h} \right| < \epsilon$$ My plan was to relate the first expression to this definition of the continuity of partial derivative. But the $hv$ which is added to $b$ spoils this idea. I think I am missing something very obvious here, but annoyingly I can't figure what. How should I proceed?","I am stuck with a seemingly easy problem. I have a function $f(x,y)$ which has continuous first derivatives. Now, I want to show that: $$ \lim_{h \to 0}\dfrac{f(a+hu,b+hv)-f(a,b+hv)}{hu} =f_x(a,b)$$ This is what I have thought: Since the derivatives are continuous, we know that, for each $\epsilon > 0$, there is a $\delta > 0$ such that it is: $$0 < ((x-a)^2 + (y-b)^2)^{1/2} < \delta \implies |f_x(x,y) - f_x(a,b) | = \left|\lim_{h \to 0}\dfrac{f(x+h,y)-f(x,y)}{h} - \lim_{h \to 0}\dfrac{f(a+h,b)-f(a,b)}{h} \right| < \epsilon$$ My plan was to relate the first expression to this definition of the continuity of partial derivative. But the $hv$ which is added to $b$ spoils this idea. I think I am missing something very obvious here, but annoyingly I can't figure what. How should I proceed?",,"['calculus', 'limits', 'multivariable-calculus']"
30,A valid method of finding limits in two variables functions?,A valid method of finding limits in two variables functions?,,"I was wondering if in finding the limit of a two variables function (say, $F(x,y)$), I can choose the path by let $y=f(x)$, then find the limit in the same way of that in one variable functions. For example, $$ \lim_{(x,y) \to (0,0)} \frac{xy}{x^2+xy+y^2} $$ (It has no limit there by choosing first $y=0$ and then $y=x$) So I'm asking if the following procedures are correct: Let $y=f(x)$ where $f(0)=0$ since the function passes $(0,0)$ The function then becomes: $$ \frac{xf(x)}{x^2 + xf(x) +f(x)^2} $$ Then it's an indeterminate form $[0/0]$, so I differentiate, $$ \frac{xf'(x)+f(x)}{2x + xf'(x)+f(x) +2f(x)f'(x)} $$ Then it's still $[0/0]$ so I differentiate again, $$\frac{xf''(x)+2f'(x)}{2+xf''(x)+2f'(x) +2f(x)f""(x)+2f'(x)^2}$$ By substituting $x=0$, I get $$\lim F(x,y) = \frac{2f'(x)}{2+2f'(x)+2f'(x)^2}$$ Since $f'(x)$ depends on the path I choose, the limit depends on the path I choose also. Thus, the limit at $(0,0)$ does not exist. So that's all, the question I have are is this a valid method to determine existence of limits? is this a valid method to find the limit? (My teacher says it wont work for 2.) but I'm still unclear about his explanations) (Sorry if I made any mistake or this is a very stupid question, I'm very new to this site and this is my first question, thank you in advance!)","I was wondering if in finding the limit of a two variables function (say, $F(x,y)$), I can choose the path by let $y=f(x)$, then find the limit in the same way of that in one variable functions. For example, $$ \lim_{(x,y) \to (0,0)} \frac{xy}{x^2+xy+y^2} $$ (It has no limit there by choosing first $y=0$ and then $y=x$) So I'm asking if the following procedures are correct: Let $y=f(x)$ where $f(0)=0$ since the function passes $(0,0)$ The function then becomes: $$ \frac{xf(x)}{x^2 + xf(x) +f(x)^2} $$ Then it's an indeterminate form $[0/0]$, so I differentiate, $$ \frac{xf'(x)+f(x)}{2x + xf'(x)+f(x) +2f(x)f'(x)} $$ Then it's still $[0/0]$ so I differentiate again, $$\frac{xf''(x)+2f'(x)}{2+xf''(x)+2f'(x) +2f(x)f""(x)+2f'(x)^2}$$ By substituting $x=0$, I get $$\lim F(x,y) = \frac{2f'(x)}{2+2f'(x)+2f'(x)^2}$$ Since $f'(x)$ depends on the path I choose, the limit depends on the path I choose also. Thus, the limit at $(0,0)$ does not exist. So that's all, the question I have are is this a valid method to determine existence of limits? is this a valid method to find the limit? (My teacher says it wont work for 2.) but I'm still unclear about his explanations) (Sorry if I made any mistake or this is a very stupid question, I'm very new to this site and this is my first question, thank you in advance!)",,['multivariable-calculus']
31,Iterated limits of $\frac{x-y}{x^3-y}$,Iterated limits of,\frac{x-y}{x^3-y},Why it the following limits look like this: $$\lim_{x\rightarrow -1} \frac{x-y}{x^3-y}=1$$ but suprisingly  $$\lim_{y\rightarrow -1} \frac{x-y}{x^3-y}=\frac{1}{1-x+x^2}$$I thought that after substituting the value of $y=-1$ the limit will be equal $\frac{1}{x^2}$. I do not know what am i doing wrong.,Why it the following limits look like this: $$\lim_{x\rightarrow -1} \frac{x-y}{x^3-y}=1$$ but suprisingly  $$\lim_{y\rightarrow -1} \frac{x-y}{x^3-y}=\frac{1}{1-x+x^2}$$I thought that after substituting the value of $y=-1$ the limit will be equal $\frac{1}{x^2}$. I do not know what am i doing wrong.,,"['limits', 'multivariable-calculus', 'functions']"
32,I need help setting up these limits of integration (triple integrals),I need help setting up these limits of integration (triple integrals),,"I need to find the volume of the solid bound on top by $z=7$, bottom by $z=7x^2+7y^2$, integrating over $z$. I've looked in three different textbooks and still don't understand, asked my professor and they won't write back. So I have drawn a picture, and I have the following (the red limits are wrong): \begin{align} \int_{\color{red}{1/\sqrt{2}}}^{\color{red}{-1/\sqrt{2}}}\int_{\color{red}{-\sqrt{1/\sqrt{2}-x^2}}}^{\color{red}{\sqrt{1/\sqrt{2}-x^2}}}\int_{7x^2+7y^2}^7z\:dz\:dy\:dx.\tag{1} \end{align} Could anyone give me some pointers?","I need to find the volume of the solid bound on top by $z=7$, bottom by $z=7x^2+7y^2$, integrating over $z$. I've looked in three different textbooks and still don't understand, asked my professor and they won't write back. So I have drawn a picture, and I have the following (the red limits are wrong): \begin{align} \int_{\color{red}{1/\sqrt{2}}}^{\color{red}{-1/\sqrt{2}}}\int_{\color{red}{-\sqrt{1/\sqrt{2}-x^2}}}^{\color{red}{\sqrt{1/\sqrt{2}-x^2}}}\int_{7x^2+7y^2}^7z\:dz\:dy\:dx.\tag{1} \end{align} Could anyone give me some pointers?",,"['integration', 'multivariable-calculus']"
33,f continuously differentiable implies f is Lipschitz on compact subsets,f continuously differentiable implies f is Lipschitz on compact subsets,,"It is a more general form of the question here , only here $U$ is not a convex set but an open and connected subset of $\mathbb{R}^n$. I need to show that $f$ is $M$ Lipschitz on any compact $K \subset U$. My attempt goes like this: $U$ is an open connected set, and $K \subset U$ so for any two points $x,y \in K$ there is a finite set of points $\{x_i\}_{i=1}^{r}\in K$ and we'll denote $x_1:=x, x_r:=y$ so for every $i=2,3,...,r$ the straight segment $[x_{i-1},x_{i}]$ is contained by $K$. By the mean value theorem for several variables , $\forall i=2,3,...,r:\ \lvert f(x_{i-1})-f(x_i) \rvert= \lVert f'(s_i) ( x_{i-1} - x_i ) \rVert$ when $s_i\in U$. Notice that since $s_i ,\ i=2,3,...,r$ is finite thus bounded, $f'$ exists and continuous - thus $\exists T := \max_{i=1,2,..,r} \{ \lVert f'(s_i) \rVert \}$, and because $K$ is compact, $\exists D:= \ diam \{ K \} \geq \max_{i=2,3,...,r} \{ \lVert x_{i-1} -x_i \rVert \}$ hence: $$\lvert f(x)-f(y) \rvert=\lvert f(x_{1})-f(x_2) +f(x_2)-f(x_3)+.... +f(x_{r-1})-f(y)\rvert \leq  TB\cdot r$$ and since the diameter of $K$ is finite, every $x \neq y \ \in K$ have a real positive number $t$ so that $\lVert x-y \rVert \cdot t = B$ and that gives $||f(x)-f(y)|| \leq T \cdot t \cdot||x-y||$. Is it o.k?","It is a more general form of the question here , only here $U$ is not a convex set but an open and connected subset of $\mathbb{R}^n$. I need to show that $f$ is $M$ Lipschitz on any compact $K \subset U$. My attempt goes like this: $U$ is an open connected set, and $K \subset U$ so for any two points $x,y \in K$ there is a finite set of points $\{x_i\}_{i=1}^{r}\in K$ and we'll denote $x_1:=x, x_r:=y$ so for every $i=2,3,...,r$ the straight segment $[x_{i-1},x_{i}]$ is contained by $K$. By the mean value theorem for several variables , $\forall i=2,3,...,r:\ \lvert f(x_{i-1})-f(x_i) \rvert= \lVert f'(s_i) ( x_{i-1} - x_i ) \rVert$ when $s_i\in U$. Notice that since $s_i ,\ i=2,3,...,r$ is finite thus bounded, $f'$ exists and continuous - thus $\exists T := \max_{i=1,2,..,r} \{ \lVert f'(s_i) \rVert \}$, and because $K$ is compact, $\exists D:= \ diam \{ K \} \geq \max_{i=2,3,...,r} \{ \lVert x_{i-1} -x_i \rVert \}$ hence: $$\lvert f(x)-f(y) \rvert=\lvert f(x_{1})-f(x_2) +f(x_2)-f(x_3)+.... +f(x_{r-1})-f(y)\rvert \leq  TB\cdot r$$ and since the diameter of $K$ is finite, every $x \neq y \ \in K$ have a real positive number $t$ so that $\lVert x-y \rVert \cdot t = B$ and that gives $||f(x)-f(y)|| \leq T \cdot t \cdot||x-y||$. Is it o.k?",,"['calculus', 'real-analysis', 'multivariable-calculus', 'proof-verification']"
34,"Chain rule, directional derivative - multivariable calculus","Chain rule, directional derivative - multivariable calculus",,"I am having a difficult time to understand the chain rule, and I have this exercise: Let $f: \mathbb{R}^2 \rightarrow \mathbb{R}$ to be a differentiable function. Define $\psi(x,y)=f(xy,x^2y^2)$. How to compute the partial derivatives and how to proof that the directional derivative $D_{(-x,y)}\psi(x,y)=0$?","I am having a difficult time to understand the chain rule, and I have this exercise: Let $f: \mathbb{R}^2 \rightarrow \mathbb{R}$ to be a differentiable function. Define $\psi(x,y)=f(xy,x^2y^2)$. How to compute the partial derivatives and how to proof that the directional derivative $D_{(-x,y)}\psi(x,y)=0$?",,['multivariable-calculus']
35,ANSML - Proving of the matrix identity $\nabla_AtrABA^TC = CAB+C^TAB^T$,ANSML - Proving of the matrix identity,\nabla_AtrABA^TC = CAB+C^TAB^T,"(ANSML is a tag I would like to use for Andrew Ng's Stanford Machine Learning - 2008) In this course, there were four matrix identities that I would like to prove. \begin{align} \nabla_a \text{tr}AB &= B^T\\ \nabla_{A^T}f(A) &= (\nabla_Af(A))^T\\ \nabla_A\text{tr}ABA^TC &= CAB+C^TAB^T\\ \nabla_A |A| &= |A| (A^{-1})^T \end{align} where $A$ is an $m\times n$ matrix and $B$ is an $n \times m$ matrix, and $f:\mathbb{R}^{m \times n} \mapsto \mathbb{R}$ such that $f(A) = \text{tr}AB$. So (to show I did my homework) I was able to prove the first two equations by using the fact that \begin{align} f(A) = \text{tr}AB  &=\sum_{i=1}^nA_{1i}B_{i1} +\sum_{i=1}^nA_{2i}B_{i2} + \cdots + \sum_{i=1}^nA_{mi}B_{m1} \\ &= \sum_{j=1}^{m}\sum_{i=1}^{n} A_{ji}B_{ij}\\ \end{align} and so for the first equation, \begin{align} \nabla_a \text{tr}AB &= \begin{bmatrix}\frac{\partial f}{\partial A_{11}}&\frac{\partial f}{\partial A_{12}} & \cdots &  \frac{\partial f}{\partial A_{1n}}\\ \frac{\partial f}{\partial A_{21}} & \frac{\partial f}{\partial A_{22}} & \cdots & \frac{\partial f}{\partial A_{2n}}\\ \vdots&\vdots&\ddots&\vdots\\ \frac{\partial f}{\partial A_{m1}}&\frac{\partial f}{\partial A_{m2}} & \cdots & \frac{\partial f}{\partial A_{mn}}\end{bmatrix}\\&=B^T  \end{align} by just doing the partial differentiation. My question is: How do I start proving the third equation? How do I start proving the fourth equation? Note that these eventually lead to the normal equations of the LMS for the gradient descent algorithms. (oh, please also guide me on whether this is classified correctly under the correct tags. I am very new to this topic).","(ANSML is a tag I would like to use for Andrew Ng's Stanford Machine Learning - 2008) In this course, there were four matrix identities that I would like to prove. \begin{align} \nabla_a \text{tr}AB &= B^T\\ \nabla_{A^T}f(A) &= (\nabla_Af(A))^T\\ \nabla_A\text{tr}ABA^TC &= CAB+C^TAB^T\\ \nabla_A |A| &= |A| (A^{-1})^T \end{align} where $A$ is an $m\times n$ matrix and $B$ is an $n \times m$ matrix, and $f:\mathbb{R}^{m \times n} \mapsto \mathbb{R}$ such that $f(A) = \text{tr}AB$. So (to show I did my homework) I was able to prove the first two equations by using the fact that \begin{align} f(A) = \text{tr}AB  &=\sum_{i=1}^nA_{1i}B_{i1} +\sum_{i=1}^nA_{2i}B_{i2} + \cdots + \sum_{i=1}^nA_{mi}B_{m1} \\ &= \sum_{j=1}^{m}\sum_{i=1}^{n} A_{ji}B_{ij}\\ \end{align} and so for the first equation, \begin{align} \nabla_a \text{tr}AB &= \begin{bmatrix}\frac{\partial f}{\partial A_{11}}&\frac{\partial f}{\partial A_{12}} & \cdots &  \frac{\partial f}{\partial A_{1n}}\\ \frac{\partial f}{\partial A_{21}} & \frac{\partial f}{\partial A_{22}} & \cdots & \frac{\partial f}{\partial A_{2n}}\\ \vdots&\vdots&\ddots&\vdots\\ \frac{\partial f}{\partial A_{m1}}&\frac{\partial f}{\partial A_{m2}} & \cdots & \frac{\partial f}{\partial A_{mn}}\end{bmatrix}\\&=B^T  \end{align} by just doing the partial differentiation. My question is: How do I start proving the third equation? How do I start proving the fourth equation? Note that these eventually lead to the normal equations of the LMS for the gradient descent algorithms. (oh, please also guide me on whether this is classified correctly under the correct tags. I am very new to this topic).",,"['multivariable-calculus', 'machine-learning', 'gradient-flows']"
36,What are some good books on vector analysis in higher dimenesion,What are some good books on vector analysis in higher dimenesion,,What is some good books specifically on vector analysis in higher dimension? Standard vector calculus book usually only introduced double and triple integral method,What is some good books specifically on vector analysis in higher dimension? Standard vector calculus book usually only introduced double and triple integral method,,"['real-analysis', 'multivariable-calculus', 'reference-request', 'vector-analysis', 'book-recommendation']"
37,Derive the equation of first variation for a flow of a vector field.,Derive the equation of first variation for a flow of a vector field.,,"This is a problem from Susan Colley's Vector Calculus. I have trouble understanding the solution to it. Problem: Derive the equation of first variation for a flow of a vector field. That is, if $\mathbf{F}$ is a vector field of class $C^1$ with flow $\phi$ of class $C^2$, show that $$\frac{\partial}{\partial t}D_{\mathbf{x}}\phi(\mathbf{x},t)=D\mathbf{F}(\phi(\mathbf{x},t))D_{\mathbf{x}}\phi(\mathbf{x},t).$$ Here the expression ""$D_{\mathbf{x}}\phi(\mathbf{x},t)$"" means to differentiate $\phi$ with respect to the variables $x_1,x_2,\ldots ,x_n,$ that is, by holding $t$ fixed. Solution: By definition of a flow of $\mathbf{F}$, we know that $\frac{\partial}{\partial t}\phi(\mathbf{x},t)=\mathbf{F}(\phi(\mathbf{x},t))$. So  $$\frac{\partial}{\partial t}D_{\mathbf{x}}\phi(\mathbf{x},t)=D_\mathbf{x}(\frac{\partial}{\partial t}\phi(\mathbf{x},t))=D_{\mathbf{x}}\mathbf{F}(\phi(\mathbf{x},t)).$$ Now by the Chain Rule,  $$D_{\mathbf{x}}\mathbf{F}(\phi(\mathbf{x},t))=D\mathbf{F}(\phi(\mathbf{x},t))D_{\mathbf{x}}\phi(\mathbf{x},t).$$ I don't understand the two equations shown in the solution. First, how can we interchange $\frac{\partial}{\partial t}$ and $D_{\mathbf{x}}$ in the first equation? Also, I don't understand how the Chain Rule leads to the second equation, since we're trying to get $D_\mathbf{x}\mathbf{F}$, not $D\mathbf{F}$. This seems to suggest that $D_\mathbf{x}\mathbf{F}$ is just the matrix of $D\mathbf{F}$ with the first $n$ columns. That is, the partials with respect to the variables $x_1,x_2,\ldots,x_n$. This result confuses me. How does this result make sense starting from the definition of the expression $D_{\mathbf{x}}$ given in the problem? I would greatly appreciate it if anyone could explain the above questions to me.","This is a problem from Susan Colley's Vector Calculus. I have trouble understanding the solution to it. Problem: Derive the equation of first variation for a flow of a vector field. That is, if $\mathbf{F}$ is a vector field of class $C^1$ with flow $\phi$ of class $C^2$, show that $$\frac{\partial}{\partial t}D_{\mathbf{x}}\phi(\mathbf{x},t)=D\mathbf{F}(\phi(\mathbf{x},t))D_{\mathbf{x}}\phi(\mathbf{x},t).$$ Here the expression ""$D_{\mathbf{x}}\phi(\mathbf{x},t)$"" means to differentiate $\phi$ with respect to the variables $x_1,x_2,\ldots ,x_n,$ that is, by holding $t$ fixed. Solution: By definition of a flow of $\mathbf{F}$, we know that $\frac{\partial}{\partial t}\phi(\mathbf{x},t)=\mathbf{F}(\phi(\mathbf{x},t))$. So  $$\frac{\partial}{\partial t}D_{\mathbf{x}}\phi(\mathbf{x},t)=D_\mathbf{x}(\frac{\partial}{\partial t}\phi(\mathbf{x},t))=D_{\mathbf{x}}\mathbf{F}(\phi(\mathbf{x},t)).$$ Now by the Chain Rule,  $$D_{\mathbf{x}}\mathbf{F}(\phi(\mathbf{x},t))=D\mathbf{F}(\phi(\mathbf{x},t))D_{\mathbf{x}}\phi(\mathbf{x},t).$$ I don't understand the two equations shown in the solution. First, how can we interchange $\frac{\partial}{\partial t}$ and $D_{\mathbf{x}}$ in the first equation? Also, I don't understand how the Chain Rule leads to the second equation, since we're trying to get $D_\mathbf{x}\mathbf{F}$, not $D\mathbf{F}$. This seems to suggest that $D_\mathbf{x}\mathbf{F}$ is just the matrix of $D\mathbf{F}$ with the first $n$ columns. That is, the partials with respect to the variables $x_1,x_2,\ldots,x_n$. This result confuses me. How does this result make sense starting from the definition of the expression $D_{\mathbf{x}}$ given in the problem? I would greatly appreciate it if anyone could explain the above questions to me.",,"['multivariable-calculus', 'vectors', 'vector-analysis']"
38,Maximum Volume of a rectangular box in ellipsoid,Maximum Volume of a rectangular box in ellipsoid,,"This is the problem I am working on: Find the maximum volume of a rectangular box that can be inscribed in the ellipsoid : $x^2/25 + y^2/4 + z^2/49 = 1$ with sides parallel to the coordinate axis I know the Volume equation is going to be $V = 8xyz$. Using Lagrange: $\nabla V = \lambda\nabla g = \langle8yz, 8xz, 8xy\rangle = \lambda\langle2x/25, 2y/4, 2z/49\rangle$ Solving for y: $x = 25y/4, z = 49y/4$ Plugging that into $g$, I get $y= .453$, and then $x = 2.831, z = 5.548$, for a $V = 56.9$ This is the wrong answer. Can someone walk me through this and tell me where I went wrong? Thank you in advance!","This is the problem I am working on: Find the maximum volume of a rectangular box that can be inscribed in the ellipsoid : $x^2/25 + y^2/4 + z^2/49 = 1$ with sides parallel to the coordinate axis I know the Volume equation is going to be $V = 8xyz$. Using Lagrange: $\nabla V = \lambda\nabla g = \langle8yz, 8xz, 8xy\rangle = \lambda\langle2x/25, 2y/4, 2z/49\rangle$ Solving for y: $x = 25y/4, z = 49y/4$ Plugging that into $g$, I get $y= .453$, and then $x = 2.831, z = 5.548$, for a $V = 56.9$ This is the wrong answer. Can someone walk me through this and tell me where I went wrong? Thank you in advance!",,"['multivariable-calculus', 'optimization', 'volume']"
39,circle as polar coordinates,circle as polar coordinates,,"Let $D$ be the interior of the circle of $x^2+y^2=2x$. Find $$\int \int _D \sqrt{x^2+y^2} dA$$ I have a solution to this but it is not clear. It just says in the polar coordinates, the circle is $r^2 =2r\cosθ ⇒ r =0$ and $2\cosθ$. How did they straight away know this? I just tried to let $x-1=r\cos\theta$ and $y=r\sin\theta$ but it turns out to be so hard to integrate.","Let $D$ be the interior of the circle of $x^2+y^2=2x$. Find $$\int \int _D \sqrt{x^2+y^2} dA$$ I have a solution to this but it is not clear. It just says in the polar coordinates, the circle is $r^2 =2r\cosθ ⇒ r =0$ and $2\cosθ$. How did they straight away know this? I just tried to let $x-1=r\cos\theta$ and $y=r\sin\theta$ but it turns out to be so hard to integrate.",,['multivariable-calculus']
40,Lagrangians : Why is $\frac{\partial (x^2)}{\partial \dot x} = 0$?,Lagrangians : Why is ?,\frac{\partial (x^2)}{\partial \dot x} = 0,"In working with Lagrangians, when we write $L = T - V$. Then we use an equation of this sort (considering only one dimension for simplicity): $$ \dfrac{d}{dt}\left(\dfrac{\partial L}{\partial \dot x}\right) = \dfrac{\partial L}{\partial x} $$ Now, for simplicity, write the Lagrangian of a mass $m$ attached to a spring of constant $k$. So, we have: $L = 0.5m{\dot x}^2 - 0.5kx^2$. We then write $\dfrac{\partial L}{\partial \dot x} = m\dot x$, taking $\dfrac{\partial (0.5kx^2)}{\partial \dot x} = 0$. My question is, how is that valid? Isn't it like saying that $x$ and $\dot x$ are independent? But that doesn't make sense intuitively. Velocity can be thought of as a function of the displacement. So, what's going on?","In working with Lagrangians, when we write $L = T - V$. Then we use an equation of this sort (considering only one dimension for simplicity): $$ \dfrac{d}{dt}\left(\dfrac{\partial L}{\partial \dot x}\right) = \dfrac{\partial L}{\partial x} $$ Now, for simplicity, write the Lagrangian of a mass $m$ attached to a spring of constant $k$. So, we have: $L = 0.5m{\dot x}^2 - 0.5kx^2$. We then write $\dfrac{\partial L}{\partial \dot x} = m\dot x$, taking $\dfrac{\partial (0.5kx^2)}{\partial \dot x} = 0$. My question is, how is that valid? Isn't it like saying that $x$ and $\dot x$ are independent? But that doesn't make sense intuitively. Velocity can be thought of as a function of the displacement. So, what's going on?",,"['multivariable-calculus', 'partial-derivative']"
41,The Idea behind the Second Partial Derivative Test,The Idea behind the Second Partial Derivative Test,,"I'm currently learning about local extrema in serveral variables and have come across the second derivative test for classifying critical points of multivariable functions. I have read and understood the test (see link below), however I don't understand the idea behind it. Why is the critical point of a function a minimum if the eigenvalues of the Hessian matrix are all positive? I understand the idea behind the single variable case, however I am confused about the role of eigenvalues in the case of several variables. http://en.wikipedia.org/wiki/Second_partial_derivative_test Any insight into this would be much appreciated. Thanks.","I'm currently learning about local extrema in serveral variables and have come across the second derivative test for classifying critical points of multivariable functions. I have read and understood the test (see link below), however I don't understand the idea behind it. Why is the critical point of a function a minimum if the eigenvalues of the Hessian matrix are all positive? I understand the idea behind the single variable case, however I am confused about the role of eigenvalues in the case of several variables. http://en.wikipedia.org/wiki/Second_partial_derivative_test Any insight into this would be much appreciated. Thanks.",,"['multivariable-calculus', 'eigenvalues-eigenvectors', 'partial-derivative']"
42,Show that $-\frac{2yx^3}{(x^2+y^2)^2}$ is bounded.,Show that  is bounded.,-\frac{2yx^3}{(x^2+y^2)^2},"Show that $-\frac{2yx^3}{(x^2+y^2)^2}$ is bounded. I'm approaching this starting with $$ \left| \frac{2yx^3}{(x^2+y^2)^2} \right| = \left| \frac{2yx^3}{x^4+2x^2y^2+y^4} \right| \leq \left| \frac{2yx^3}{2x^2y^2} \right| = \left| \frac{x}{y}\right|.$$ However, this doesn't get me anywhere. What am I missing?","Show that $-\frac{2yx^3}{(x^2+y^2)^2}$ is bounded. I'm approaching this starting with $$ \left| \frac{2yx^3}{(x^2+y^2)^2} \right| = \left| \frac{2yx^3}{x^4+2x^2y^2+y^4} \right| \leq \left| \frac{2yx^3}{2x^2y^2} \right| = \left| \frac{x}{y}\right|.$$ However, this doesn't get me anywhere. What am I missing?",,"['multivariable-calculus', 'inequality']"
43,The number of vertices in a polytope is finite,The number of vertices in a polytope is finite,,"I want to prove the following: Let $K$ be a convex polytope. Show that $K$ has a finite number of extreme points. I have seen the bound for the cardinality of the set of extreme points: $|E| \leq 2$ $ n\choose 2$ I know that the $n$ comes from the number of half-spaces that form a polytope, the 2 in the binomial coefficient comes from that the extreme points are vertices, because they are in the intersection of two hyperplanes, but I dont know how to write and complete this better :) but I dont know how to prove it, because if I prove that result I answer the above problem. Can someone help me to prove this?","I want to prove the following: Let $K$ be a convex polytope. Show that $K$ has a finite number of extreme points. I have seen the bound for the cardinality of the set of extreme points: $|E| \leq 2$ $ n\choose 2$ I know that the $n$ comes from the number of half-spaces that form a polytope, the 2 in the binomial coefficient comes from that the extreme points are vertices, because they are in the intersection of two hyperplanes, but I dont know how to write and complete this better :) but I dont know how to prove it, because if I prove that result I answer the above problem. Can someone help me to prove this?",,"['multivariable-calculus', 'proof-writing', 'polytopes']"
44,"Isothermal parameterization, Inverse of the Gauss Map","Isothermal parameterization, Inverse of the Gauss Map",,"This problem is from Do Carmo's Differential Geometry of Curves and Surfaces. It is question 13 from chapter 3.5, to be specific. Suppose that S is a minimal surface without any umbilical points (that is to say that $k_1 = -k_2$ everywhere). Let $\bar{x}$ be a parameterization of the unit sphere by stereograhic projection, and consider a neighborhood $V$ of a point $p$ on the surface so that the Gauss map $N: S \rightarrow S^2$ restricted to the neighborhood $V$ is a diffeomorphism. The question is to show that the parameterization $q= N^{-1}$ o $\bar x$ is isothermal, meaning that $<q_u, q_u > = <q_v, q_v>$ and $<q_u,q_v> = 0$ everywhere on $S$. Now when I saw this question, my first instinct was to try to verify that $q$ was isothermal directly by computing the parameterization in some kind of coordinates directly. I know that stereographic projection is given by the formulas: $$ x= \frac {4u}{u^2+v^2+4}$$ $$ y = \frac {4v}{u^2+v^2+4}$$ $$ z = \frac {2(u^2+v^2)}{u^2+v^2+4} $$ I figured with this information, maybe I could find a way to write down what $q$ is in terms of $u$ and $v$ and take partials. The problem is that I don't know how to write down anything about $N^{-1}$. Like when working with $N$, I can say that a point on a surface $S$ goes to it's normal, which is something that I can compute in terms of cross products of partial derivatives of a parameterization of the surface. Is this method workable? I don't know if I can proceed any further this way. If not, what can I do to approach this problem?","This problem is from Do Carmo's Differential Geometry of Curves and Surfaces. It is question 13 from chapter 3.5, to be specific. Suppose that S is a minimal surface without any umbilical points (that is to say that $k_1 = -k_2$ everywhere). Let $\bar{x}$ be a parameterization of the unit sphere by stereograhic projection, and consider a neighborhood $V$ of a point $p$ on the surface so that the Gauss map $N: S \rightarrow S^2$ restricted to the neighborhood $V$ is a diffeomorphism. The question is to show that the parameterization $q= N^{-1}$ o $\bar x$ is isothermal, meaning that $<q_u, q_u > = <q_v, q_v>$ and $<q_u,q_v> = 0$ everywhere on $S$. Now when I saw this question, my first instinct was to try to verify that $q$ was isothermal directly by computing the parameterization in some kind of coordinates directly. I know that stereographic projection is given by the formulas: $$ x= \frac {4u}{u^2+v^2+4}$$ $$ y = \frac {4v}{u^2+v^2+4}$$ $$ z = \frac {2(u^2+v^2)}{u^2+v^2+4} $$ I figured with this information, maybe I could find a way to write down what $q$ is in terms of $u$ and $v$ and take partials. The problem is that I don't know how to write down anything about $N^{-1}$. Like when working with $N$, I can say that a point on a surface $S$ goes to it's normal, which is something that I can compute in terms of cross products of partial derivatives of a parameterization of the surface. Is this method workable? I don't know if I can proceed any further this way. If not, what can I do to approach this problem?",,"['multivariable-calculus', 'differential-geometry', 'surfaces', 'minimal-surfaces']"
45,Non-unique direction of steepest ascent,Non-unique direction of steepest ascent,,"The gradient $\nabla f$ of a differentiable function $f(x,y)$ points in the direction of steepest ascent at a given point $(x_0,y_0)$. The slope of this ascent is the magnitude of the gradient $\|\nabla f(x_0,y_0)\|$. It seems possible that there could be a non-parallel vector $u$ such that the (directional) derivative $\nabla_{u}f (x_0,y_0)$ in the direction of $u$ is also equal to $\|\nabla f(x_0,y_0)\|$. Thus the direction of steepest ascent would not be unique - the gradient just happens to equal one of directions of steepest ascent. Can this happen? Is there a function $f(x,y)$ and a point $(x_0,y_0)$ such that $f$ is differentiable at $(x_0,y_0)$, There are two unit vectors $u\neq v$ such that $$\nabla_{u}f (x_0,y_0)=\nabla_{v}f (x_0,y_0)=\|\nabla f(x_0,y_0)\|\neq 0?$$ In the cases I've thought of where there are obviously two methods of steepest ascent (like a hyperbolic paraboloid) the gradient is zero.","The gradient $\nabla f$ of a differentiable function $f(x,y)$ points in the direction of steepest ascent at a given point $(x_0,y_0)$. The slope of this ascent is the magnitude of the gradient $\|\nabla f(x_0,y_0)\|$. It seems possible that there could be a non-parallel vector $u$ such that the (directional) derivative $\nabla_{u}f (x_0,y_0)$ in the direction of $u$ is also equal to $\|\nabla f(x_0,y_0)\|$. Thus the direction of steepest ascent would not be unique - the gradient just happens to equal one of directions of steepest ascent. Can this happen? Is there a function $f(x,y)$ and a point $(x_0,y_0)$ such that $f$ is differentiable at $(x_0,y_0)$, There are two unit vectors $u\neq v$ such that $$\nabla_{u}f (x_0,y_0)=\nabla_{v}f (x_0,y_0)=\|\nabla f(x_0,y_0)\|\neq 0?$$ In the cases I've thought of where there are obviously two methods of steepest ascent (like a hyperbolic paraboloid) the gradient is zero.",,['multivariable-calculus']
46,How to determine continuity in higher dim,How to determine continuity in higher dim,,"$$f(x,y) = \frac{1-\cos{\sqrt{xy}}}{y}$$ $$f(x,0) = \frac{x}{2}$$ How do I prove this is continuous in the quadrant $x,y \ge 0 $? I can't find counterexamples (weak). I'm just starting working in higher dimensions and don't have a feel for the tricks here. Something about cosines always being continuous? Is there a rule in $\mathbb R^2$ like how polynomials in $\mathbb R$ are always continuous on their domain? What tricks should I instinctively be thinking of in a problem like this?","$$f(x,y) = \frac{1-\cos{\sqrt{xy}}}{y}$$ $$f(x,0) = \frac{x}{2}$$ How do I prove this is continuous in the quadrant $x,y \ge 0 $? I can't find counterexamples (weak). I'm just starting working in higher dimensions and don't have a feel for the tricks here. Something about cosines always being continuous? Is there a rule in $\mathbb R^2$ like how polynomials in $\mathbb R$ are always continuous on their domain? What tricks should I instinctively be thinking of in a problem like this?",,"['limits', 'multivariable-calculus', 'continuity']"
47,Prove that a multivariable function has a global minimum,Prove that a multivariable function has a global minimum,,"I'm doing an Introduction to Machine Learning course by myself using some open university coursebook and it has the following question which I've tried to solve, but to no avail: Let there be a Lipschitz function $g:\mathbb{R}^n\rightarrow \mathbb{R}$. Meaning the following holds: $|g(x)-g(y)| \leq L \,\cdot \parallel x-y\parallel$ for some constant $L\geq 0$. Prove that the following function   $f:\mathbb{R}^n\rightarrow\mathbb{R}$ defined as: $f(x) = \parallel\,x\,\parallel ^2 + \, g(x)$ has a global minimum OK so I want to show that function basically goes to infinity in every direction but I am having trouble proving it. I tried going directly from the definition but I can't figure out what the Lipschitz function gives me (I'm sure I need to use it somehow) Any help is appreciated! Thank you to anyone who helps","I'm doing an Introduction to Machine Learning course by myself using some open university coursebook and it has the following question which I've tried to solve, but to no avail: Let there be a Lipschitz function $g:\mathbb{R}^n\rightarrow \mathbb{R}$. Meaning the following holds: $|g(x)-g(y)| \leq L \,\cdot \parallel x-y\parallel$ for some constant $L\geq 0$. Prove that the following function   $f:\mathbb{R}^n\rightarrow\mathbb{R}$ defined as: $f(x) = \parallel\,x\,\parallel ^2 + \, g(x)$ has a global minimum OK so I want to show that function basically goes to infinity in every direction but I am having trouble proving it. I tried going directly from the definition but I can't figure out what the Lipschitz function gives me (I'm sure I need to use it somehow) Any help is appreciated! Thank you to anyone who helps",,"['calculus', 'multivariable-calculus', 'machine-learning', 'lipschitz-functions']"
48,Is this function continuous? Polar coordinates,Is this function continuous? Polar coordinates,,"Is the function $f:\mathbb R^2\to \mathbb R^2$ given in polar coordinates by $f(r,\theta)=(1,\theta)$ continuous? How would one prove it? My guess would be yes, since geometricly it simply change the whole plane into $S^1$ in a way that seems continuous, but I don't know how to show it (one way I thought is to show that it is continuous in each coordinate in the range, but I couldn't tell if ($f(x)=\frac{1}{\|x\|}x$ is continuous . I believe it is). Thanks","Is the function $f:\mathbb R^2\to \mathbb R^2$ given in polar coordinates by $f(r,\theta)=(1,\theta)$ continuous? How would one prove it? My guess would be yes, since geometricly it simply change the whole plane into $S^1$ in a way that seems continuous, but I don't know how to show it (one way I thought is to show that it is continuous in each coordinate in the range, but I couldn't tell if ($f(x)=\frac{1}{\|x\|}x$ is continuous . I believe it is). Thanks",,"['calculus', 'general-topology', 'multivariable-calculus', 'polar-coordinates']"
49,Trying to find function that defines a parabolic surface,Trying to find function that defines a parabolic surface,,"Say we are working in three dimensions and we have a function $u_1(x, y) = x^2$. Ie. this is just the regular $x^2$ parabola except it's now defined all along the way $y$-axis and forms a surface. Say we also have a function $u_2(x, y) = y^2$. Ie. this is just the regular $y^2$ parabola except it's now defined all along the way $x$-axis and forms a surface. ...now where I'm going with this is that I would like to be able to define $u_3(x,y)$ such that it is the 'same kind of parabola' except instead being on the $y$-axis or the $x$-axis it is now defined on the vector $(1,1)$...Ie. one of the above surface 'rotated' 45 degrees about the $z$ axis. What would be the equation for $u(x,y)$ in this case?","Say we are working in three dimensions and we have a function $u_1(x, y) = x^2$. Ie. this is just the regular $x^2$ parabola except it's now defined all along the way $y$-axis and forms a surface. Say we also have a function $u_2(x, y) = y^2$. Ie. this is just the regular $y^2$ parabola except it's now defined all along the way $x$-axis and forms a surface. ...now where I'm going with this is that I would like to be able to define $u_3(x,y)$ such that it is the 'same kind of parabola' except instead being on the $y$-axis or the $x$-axis it is now defined on the vector $(1,1)$...Ie. one of the above surface 'rotated' 45 degrees about the $z$ axis. What would be the equation for $u(x,y)$ in this case?",,"['geometry', 'multivariable-calculus']"
50,Can every differentiable scalar function be written as a divergence of some vector field?,Can every differentiable scalar function be written as a divergence of some vector field?,,"My question is simple: can every differentiable function $f$ defined on a bounded, connected subset of $\mathbb{R}^3$ be written as a divergence of some vector field ? That is, given the vector field $\mathbf{F}$, you can write:$$f=\nabla\cdot\mathbf{F}$$ Is this always possible? How to prove it?","My question is simple: can every differentiable function $f$ defined on a bounded, connected subset of $\mathbb{R}^3$ be written as a divergence of some vector field ? That is, given the vector field $\mathbf{F}$, you can write:$$f=\nabla\cdot\mathbf{F}$$ Is this always possible? How to prove it?",,"['calculus', 'multivariable-calculus', 'vector-analysis']"
51,"Show that $F(x)=(x,f(x))$ is differentiable where $f:\mathbb{R}^n\rightarrow\mathbb{R}^k$ is.",Show that  is differentiable where  is.,"F(x)=(x,f(x)) f:\mathbb{R}^n\rightarrow\mathbb{R}^k","Show that $F(x)=(x,f(x))$ is differentiable where $f:\mathbb{R}^n\rightarrow\mathbb{R}^k$ is and show the matrix $dF(x)$. This is an exercise of my homework but I'm insecurity with this. So a will write my attempt. My problem is understand how to write the matrix: $F(x)=(x,f(x))$ is differentiable because yours components are (the professor prove that in class). So the matrix is: $$ dF(x)= \left( \begin{array}{cc} Id_{n\times n} & 0_{n\times k} \\ 0_{k\times n} & df(x)  \\ \end{array} \right)  $$ where $$ df(x)=\left( \begin{array}{ccccc}  f_1'(x)&0&\cdots&0 \\ 0&f'_2(x)&\cdots&0\\ \vdots&\cdots&\ddots&\vdots\\ 0&\cdots&0& f'(k) \end{array} \right) $$ ( $f(x)=(f_1(x),f_2(x),...,f_k(x))$) Being right or wrong my thinking it would be great too someone please explain to me how I can understand intuitively the matrix of the differential, if possible indicating some online document easily accessible and didactic language.","Show that $F(x)=(x,f(x))$ is differentiable where $f:\mathbb{R}^n\rightarrow\mathbb{R}^k$ is and show the matrix $dF(x)$. This is an exercise of my homework but I'm insecurity with this. So a will write my attempt. My problem is understand how to write the matrix: $F(x)=(x,f(x))$ is differentiable because yours components are (the professor prove that in class). So the matrix is: $$ dF(x)= \left( \begin{array}{cc} Id_{n\times n} & 0_{n\times k} \\ 0_{k\times n} & df(x)  \\ \end{array} \right)  $$ where $$ df(x)=\left( \begin{array}{ccccc}  f_1'(x)&0&\cdots&0 \\ 0&f'_2(x)&\cdots&0\\ \vdots&\cdots&\ddots&\vdots\\ 0&\cdots&0& f'(k) \end{array} \right) $$ ( $f(x)=(f_1(x),f_2(x),...,f_k(x))$) Being right or wrong my thinking it would be great too someone please explain to me how I can understand intuitively the matrix of the differential, if possible indicating some online document easily accessible and didactic language.",,"['multivariable-calculus', 'derivatives']"
52,Maximum value of a given set [closed],Maximum value of a given set [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question Let, $a$ be a fixed positive real number. Consider the set $$S=\{x_{1}x_{2}...x_{n}:x_{i}\ge0(1\le i\le n),\sum_{i=1}^{n}x_{i}=a\}.$$ Find the maximum value of $S$. I know that the answer is $\bigl(\dfrac{a}{n}\bigr)^{n}$. But how I can prove it? I tried it but I can't proceed it anyway.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question Let, $a$ be a fixed positive real number. Consider the set $$S=\{x_{1}x_{2}...x_{n}:x_{i}\ge0(1\le i\le n),\sum_{i=1}^{n}x_{i}=a\}.$$ Find the maximum value of $S$. I know that the answer is $\bigl(\dfrac{a}{n}\bigr)^{n}$. But how I can prove it? I tried it but I can't proceed it anyway.",,"['real-analysis', 'multivariable-calculus']"
53,How does an Iterated Integral Work?,How does an Iterated Integral Work?,,"I am simply confused because of planes now. Consider: $$J = \int_{R}\int_{R} e^{-(x^2 + y^2)} dxdy$$ What is the geometrical aspect of this integral? This represents the volume under $h(x,y) = e^{-(x^2 + y^2)}$ I believe. Then how is: $$I = \int_{R} e^{-x^2} dx = \int_{R} e^{-y^2} dy$$? How does that statement hold true? Which are independent/dependent variables? I am utterly confused.","I am simply confused because of planes now. Consider: $$J = \int_{R}\int_{R} e^{-(x^2 + y^2)} dxdy$$ What is the geometrical aspect of this integral? This represents the volume under $h(x,y) = e^{-(x^2 + y^2)}$ I believe. Then how is: $$I = \int_{R} e^{-x^2} dx = \int_{R} e^{-y^2} dy$$? How does that statement hold true? Which are independent/dependent variables? I am utterly confused.",,"['calculus', 'real-analysis', 'integration', 'analysis', 'multivariable-calculus']"
54,"conical surface, parametrization, immersion, Gaussian and mean curvatures","conical surface, parametrization, immersion, Gaussian and mean curvatures",,"""Find the parametric form of a conical surface $S$ which is spanned by all rays starting $($but not including $)$ a fixed point $\gamma$ and passing through an arbitrary point on $\gamma$ and passing through an arbitrary point on $\gamma$. Formulate a condition which is necessary and sufficient for $S$ to be immersed. Find the Gaussian and mean curvatures."" My progress so far: We might as well assume the distinguished point is the origin. Then our surface is parameterized as $$X(s,t) = t\gamma(s),\text{ }t \neq 0,$$$$X_s = \dot{\gamma}(s),$$$$X_t = \gamma(s).$$What do I do next? Could I have a hint?","""Find the parametric form of a conical surface $S$ which is spanned by all rays starting $($but not including $)$ a fixed point $\gamma$ and passing through an arbitrary point on $\gamma$ and passing through an arbitrary point on $\gamma$. Formulate a condition which is necessary and sufficient for $S$ to be immersed. Find the Gaussian and mean curvatures."" My progress so far: We might as well assume the distinguished point is the origin. Then our surface is parameterized as $$X(s,t) = t\gamma(s),\text{ }t \neq 0,$$$$X_s = \dot{\gamma}(s),$$$$X_t = \gamma(s).$$What do I do next? Could I have a hint?",,['multivariable-calculus']
55,Does the inverse function theorem fail for $\frac {\partial r}{\partial x}$,Does the inverse function theorem fail for,\frac {\partial r}{\partial x},"This is a follow-up to a question that I answered (though, not well enough). Why is it that $\frac {\partial r}{\partial x} = \cos(\theta) = \frac {\partial x}{\partial r} = \frac {\partial}{\partial r}(r\cos(\theta))$? $r$ and $x$ should be continuously differentiable so the inverse function theorem should apply.  And I don't think $r$ should be a function of $\theta$ (even though $\frac {\partial r}{\partial x}$ is).  Can someone explain this to me?","This is a follow-up to a question that I answered (though, not well enough). Why is it that $\frac {\partial r}{\partial x} = \cos(\theta) = \frac {\partial x}{\partial r} = \frac {\partial}{\partial r}(r\cos(\theta))$? $r$ and $x$ should be continuously differentiable so the inverse function theorem should apply.  And I don't think $r$ should be a function of $\theta$ (even though $\frac {\partial r}{\partial x}$ is).  Can someone explain this to me?",,['multivariable-calculus']
56,How can the derivative of the Euclidean norm be exhibited without considering partial derivatives?,How can the derivative of the Euclidean norm be exhibited without considering partial derivatives?,,"Let $f: \mathbb{R}^n \to \mathbb{R}$ be given by $f(x) = \|x\|$. I would like to show that $Df(a)h = \frac{a\cdot h}{\|a\|}$ without resorting to using partial derivatives. I considered the expression $\frac{\|a+h\| - \|a\| - \frac{a \cdot h}{\|a\|}}{\|h\|} = \frac{\|a+h\| - \|a\|}{\|h\|} - \frac{a \cdot h}{\|a\|\|h\|}$ which I was sure I could manipulate to show that this approached $0$ as $h \to 0$ using some combination of the triangle inequalities and possibly Cauchy-Schwarz (looking at the last term in the expression), but I was unable to pin it down.","Let $f: \mathbb{R}^n \to \mathbb{R}$ be given by $f(x) = \|x\|$. I would like to show that $Df(a)h = \frac{a\cdot h}{\|a\|}$ without resorting to using partial derivatives. I considered the expression $\frac{\|a+h\| - \|a\| - \frac{a \cdot h}{\|a\|}}{\|h\|} = \frac{\|a+h\| - \|a\|}{\|h\|} - \frac{a \cdot h}{\|a\|\|h\|}$ which I was sure I could manipulate to show that this approached $0$ as $h \to 0$ using some combination of the triangle inequalities and possibly Cauchy-Schwarz (looking at the last term in the expression), but I was unable to pin it down.",,"['analysis', 'multivariable-calculus']"
57,Surface integral problem $\iint_{S}{x^2dS}$,Surface integral problem,\iint_{S}{x^2dS},"Let S be the portion of the cylinder $x^2+y^2=4$ between the planes $z=0$ and $z=x+3$. Compute the following integral: $$\displaystyle\iint_{S}{x^2dS}$$ I know the typical conversion formula is: $$\displaystyle\iint_{S}{f(x,y,z)dS} = \displaystyle\iint_{D}{f(\Phi(u,v))||T_u x T_v||dudv}$$ My problem for this is I'm not sure how to parametrize this surface. Would I parametrize the base of the cylinder (the disc) so that $\Phi(r,\theta) = (rcos(\theta), rsin(\theta), 0)$ or do $\Phi(u,v) = (u,v,u+3)$ or something completely different? Thanks in advance. also, although it may be a more complicated method, I could achieve the same result using a standard triple integral correct?","Let S be the portion of the cylinder $x^2+y^2=4$ between the planes $z=0$ and $z=x+3$. Compute the following integral: $$\displaystyle\iint_{S}{x^2dS}$$ I know the typical conversion formula is: $$\displaystyle\iint_{S}{f(x,y,z)dS} = \displaystyle\iint_{D}{f(\Phi(u,v))||T_u x T_v||dudv}$$ My problem for this is I'm not sure how to parametrize this surface. Would I parametrize the base of the cylinder (the disc) so that $\Phi(r,\theta) = (rcos(\theta), rsin(\theta), 0)$ or do $\Phi(u,v) = (u,v,u+3)$ or something completely different? Thanks in advance. also, although it may be a more complicated method, I could achieve the same result using a standard triple integral correct?",,"['multivariable-calculus', 'surface-integrals']"
58,"What do gradient, curl, and div input and output?","What do gradient, curl, and div input and output?",,"What do gradient, curl, and div input and output? (e.g. vector field or scalar function of several variables)","What do gradient, curl, and div input and output? (e.g. vector field or scalar function of several variables)",,"['multivariable-calculus', 'notation', 'vector-fields']"
59,Geometric interpretation of ${\partial f\over \partial x}= {\partial f \over \partial y}$,Geometric interpretation of,{\partial f\over \partial x}= {\partial f \over \partial y},"I know that $${\partial f\over \partial x}= {\partial f \over \partial y}$$ iff there exists a differentiable function $g$ (of one variable) such that $g(x+y)=f(x,y)$ (where $f : D\subseteq \mathbb R^2 \to \mathbb R$ and $D$ is an open set), but I don´t know what is the geometric interpretation of this fact. So I would really appreciate if you can help me with this","I know that iff there exists a differentiable function (of one variable) such that (where and is an open set), but I don´t know what is the geometric interpretation of this fact. So I would really appreciate if you can help me with this","{\partial f\over \partial x}= {\partial f \over \partial y} g g(x+y)=f(x,y) f : D\subseteq \mathbb R^2 \to \mathbb R D","['multivariable-calculus', 'partial-derivative', 'differential']"
60,"Find $b$ so that $f(x,y) = y^3+3x^2y-15y-12bx$ has some critical point",Find  so that  has some critical point,"b f(x,y) = y^3+3x^2y-15y-12bx","I am trying to solve this excersice but I can't seem to get to anything but dead ends. Let $b\gt 0$ and $f(x,y) = y^3+3x^2y-15y-12bx$, find all possible values of $b$ so that $f$ has at least one critical point. I started by deriving: $f_x(x,y) = 6xy-12b$ $f_y(x,y) = 3y^2+3x^2-15$ So, if $(x,y)$ is a critical point: $xy = 2b$ $x^2+y^2 = 5$ That would say that the possible values of $b$ are those that define an homographic function $y = \frac{1}{x}2b$ such that its graphic intersects with the border of the circle centered at the origin with radius equal to $\sqrt{5}$. That is my intuition, but I can't seem to find a way of getting those values in numbers. I don't know if it would help, or if it is even correct, but I also attempted using Lagrange multipliers but that route didn't yield any valid result. Thank you very much.","I am trying to solve this excersice but I can't seem to get to anything but dead ends. Let $b\gt 0$ and $f(x,y) = y^3+3x^2y-15y-12bx$, find all possible values of $b$ so that $f$ has at least one critical point. I started by deriving: $f_x(x,y) = 6xy-12b$ $f_y(x,y) = 3y^2+3x^2-15$ So, if $(x,y)$ is a critical point: $xy = 2b$ $x^2+y^2 = 5$ That would say that the possible values of $b$ are those that define an homographic function $y = \frac{1}{x}2b$ such that its graphic intersects with the border of the circle centered at the origin with radius equal to $\sqrt{5}$. That is my intuition, but I can't seem to find a way of getting those values in numbers. I don't know if it would help, or if it is even correct, but I also attempted using Lagrange multipliers but that route didn't yield any valid result. Thank you very much.",,['multivariable-calculus']
61,Expanding $(1 - x + 2y)^3$ in powers of $x-1$ and $y-2$ with a Taylor series,Expanding  in powers of  and  with a Taylor series,(1 - x + 2y)^3 x-1 y-2,"I would like to do this. I observe that I can write $$f(x,y) = (1 - x + 2y)^3 = (2(y-2) - (x-1) + 4)^3.$$ It's easy to do this via algebra directly. However, I'm asked to do it by computing the Taylor series. Is it correct to say that I could expand the function $$f(a,b) = (2a - b + 4)^3$$ (where $a = y-2$ and $b = x-1$) around the point $(2,1)$ to the third-order term like so: $$f(a,b) = f(2,1) + f_a(2,1)a + f_b(2,1)b + \frac{1}{2}f_{aa}(2,1)a^2 + \frac{1}{2}f_{bb}(2,1)b^2 + f_{ab}(2,1)ab + \cdots$$ (where I've neglected to write the third order term for simplicity's sake)? Or am I missing the point of the question / is my approach incorrect?","I would like to do this. I observe that I can write $$f(x,y) = (1 - x + 2y)^3 = (2(y-2) - (x-1) + 4)^3.$$ It's easy to do this via algebra directly. However, I'm asked to do it by computing the Taylor series. Is it correct to say that I could expand the function $$f(a,b) = (2a - b + 4)^3$$ (where $a = y-2$ and $b = x-1$) around the point $(2,1)$ to the third-order term like so: $$f(a,b) = f(2,1) + f_a(2,1)a + f_b(2,1)b + \frac{1}{2}f_{aa}(2,1)a^2 + \frac{1}{2}f_{bb}(2,1)b^2 + f_{ab}(2,1)ab + \cdots$$ (where I've neglected to write the third order term for simplicity's sake)? Or am I missing the point of the question / is my approach incorrect?",,"['multivariable-calculus', 'taylor-expansion', 'partial-derivative']"
62,Show this function has infinitely many critical points and classify;,Show this function has infinitely many critical points and classify;,,"Show that $$f(x,y)=x^2-x+\cos(xy)$$has inifinitely many critical points and classify; Partial Derivative w.r.t. $x$ $$f_{x}=2x-1-y\sin(xy)=0$$ Partial Derivative w.r.t. $y$ $$f_{y}=-x\sin(xy)=0$$ Now trying to simultaneously solve; you get that $$\sin(xy)=\dfrac{1-2x}{x-y}$$ is that enough to show infinite solutions? And how would I classify these?, use the hessian method?","Show that $$f(x,y)=x^2-x+\cos(xy)$$has inifinitely many critical points and classify; Partial Derivative w.r.t. $x$ $$f_{x}=2x-1-y\sin(xy)=0$$ Partial Derivative w.r.t. $y$ $$f_{y}=-x\sin(xy)=0$$ Now trying to simultaneously solve; you get that $$\sin(xy)=\dfrac{1-2x}{x-y}$$ is that enough to show infinite solutions? And how would I classify these?, use the hessian method?",,"['multivariable-calculus', 'optimization']"
63,2nd derivative test fail,2nd derivative test fail,,"I trying to solve this problem in Advanced Calc by Buck, sec 3.6 problem 9: Let $f(x,y)=(y-x^{2})(y-2x^{2})$. Show that the origin is a critical point for $f$ which is a saddle point, although on any line through the origin, $f$ has a local minimum at $(0,0)$. Solution: We have \begin{align*} f(x,y) & =(y-x^{2})(y-2x^{2})\\  & =y^{2}-3x^{2}y+2x^{4} \end{align*} so that \begin{align*} f_{1}(x,y) & =-6xy+8x^{3} &  & (1)\\ f_{2}(x,y) & =2y-3x^{2} &  & (2) \end{align*} set (1) and (2) equal to zero and solve: from (2)  $2y-3x^{2}=0\,\Longrightarrow y=\frac{3}{2}x^{2}$ in (1)  $-6xy+8x^{3}=0\,\Longrightarrow-9x^{3}+8x^{3}=0\,\Longrightarrow x=0,\Longrightarrow y=0$ hence (0,0) is a critical point of $f$. (0,0) is a saddle point: By Theorem 19 page 157: If the determinant of the hessian (2nd order partial derivatives matrix) is negative at $p_{0}$, then $p_{0}$is a saddle point. hence $H=\left[\begin{array}{cc} f_{11} & f_{12}\\ f_{21} & f_{22} \end{array}\right]=\left[\begin{array}{cc} -6y+24x^{2} & -6x\\ -6x & 2 \end{array}\right]$ $\Delta=-12y+48x^{2}-36x^{2}=12(x^{2}-y)$ at (0,0) $\Delta=0$, therefore the second derivative test is inconclusive. However since $f(x,y)=(y-x^{2})(y-2x^{2})$, then if $x^{2}<y<2x^{2}$ we have $f(x,y)<0$, also if ($y<x^{2}$ or $y>2x^{2}$) we have $f(x,y)>0$, and we have $f(x,y)=0$ if $x=y=0$. Therefore the critical point (0,0) is a saddle point. I don't feel confident about the proof of (0,0) is a saddle point. Also I am not sure how to do the last part (any line through the origin, $f$ has a local minimum at $(0,0)$) any help appreciated.","I trying to solve this problem in Advanced Calc by Buck, sec 3.6 problem 9: Let $f(x,y)=(y-x^{2})(y-2x^{2})$. Show that the origin is a critical point for $f$ which is a saddle point, although on any line through the origin, $f$ has a local minimum at $(0,0)$. Solution: We have \begin{align*} f(x,y) & =(y-x^{2})(y-2x^{2})\\  & =y^{2}-3x^{2}y+2x^{4} \end{align*} so that \begin{align*} f_{1}(x,y) & =-6xy+8x^{3} &  & (1)\\ f_{2}(x,y) & =2y-3x^{2} &  & (2) \end{align*} set (1) and (2) equal to zero and solve: from (2)  $2y-3x^{2}=0\,\Longrightarrow y=\frac{3}{2}x^{2}$ in (1)  $-6xy+8x^{3}=0\,\Longrightarrow-9x^{3}+8x^{3}=0\,\Longrightarrow x=0,\Longrightarrow y=0$ hence (0,0) is a critical point of $f$. (0,0) is a saddle point: By Theorem 19 page 157: If the determinant of the hessian (2nd order partial derivatives matrix) is negative at $p_{0}$, then $p_{0}$is a saddle point. hence $H=\left[\begin{array}{cc} f_{11} & f_{12}\\ f_{21} & f_{22} \end{array}\right]=\left[\begin{array}{cc} -6y+24x^{2} & -6x\\ -6x & 2 \end{array}\right]$ $\Delta=-12y+48x^{2}-36x^{2}=12(x^{2}-y)$ at (0,0) $\Delta=0$, therefore the second derivative test is inconclusive. However since $f(x,y)=(y-x^{2})(y-2x^{2})$, then if $x^{2}<y<2x^{2}$ we have $f(x,y)<0$, also if ($y<x^{2}$ or $y>2x^{2}$) we have $f(x,y)>0$, and we have $f(x,y)=0$ if $x=y=0$. Therefore the critical point (0,0) is a saddle point. I don't feel confident about the proof of (0,0) is a saddle point. Also I am not sure how to do the last part (any line through the origin, $f$ has a local minimum at $(0,0)$) any help appreciated.",,"['calculus', 'multivariable-calculus']"
64,Limit of two variable does not exist?,Limit of two variable does not exist?,,"I got this limit on my midterm: $$\lim_{(x,y)\to 0,0} \frac{(x^2+2x-4y^2+4y)} {(x+2y)} $$ and if I were to plug in $y=-\frac{x} {2}$ it gives me that the limit equals $\frac{0} {0}$ as opposed to the typical answer from every other path of $2$.  Is my reasoning wrong, or you can simply simplify it and not worry about the different paths?","I got this limit on my midterm: $$\lim_{(x,y)\to 0,0} \frac{(x^2+2x-4y^2+4y)} {(x+2y)} $$ and if I were to plug in $y=-\frac{x} {2}$ it gives me that the limit equals $\frac{0} {0}$ as opposed to the typical answer from every other path of $2$.  Is my reasoning wrong, or you can simply simplify it and not worry about the different paths?",,"['limits', 'multivariable-calculus']"
65,Proving that limit exist,Proving that limit exist,,"To show that limit exist and is equal to zero $$\lim_{(x,y)\to(0,0)}\frac{\sin(x^2y + xy^2)}{xy}$$","To show that limit exist and is equal to zero $$\lim_{(x,y)\to(0,0)}\frac{\sin(x^2y + xy^2)}{xy}$$",,"['limits', 'multivariable-calculus']"
66,Double Integral: finding the area using a parametric equation,Double Integral: finding the area using a parametric equation,,$$ r = \cos (3\theta) $$ I need to find the area of one loop of the rose made by this function. I know that the bound for $\theta$ is $-\pi/2$ to $\pi/2$ for one of the loops. Although I don't know how to set up my $r$ values. I believe that the interior function would simply be $1$ since we're just trying to find the area. Can you help me set up this problem?,$$ r = \cos (3\theta) $$ I need to find the area of one loop of the rose made by this function. I know that the bound for $\theta$ is $-\pi/2$ to $\pi/2$ for one of the loops. Although I don't know how to set up my $r$ values. I believe that the interior function would simply be $1$ since we're just trying to find the area. Can you help me set up this problem?,,"['integration', 'multivariable-calculus']"
67,Existence of a unique maximizer of a strict quasi-concave function defined over a convex set,Existence of a unique maximizer of a strict quasi-concave function defined over a convex set,,"Set $S \subset \mathbb R^2$ is compact and convex. A typical element of $S$ is $s=(s_1,s_2) \in S$. Also, $d \in \mathbb R^2$ is a fixed element such that there exists $s \in S$ such that $s \gt d$. Here  $s \gt d$ means $s_1 \gt d_1$ and $s_2 \gt d_2$ $$\underset{(d_1,d_2)\le(s_1,s_2) \in S}{\overset{}{\operatorname{arg \;\; max}}} \; (s_1-d_1)(s_2-d_2)$$ Let $H(s_1,s_2)=(s_1-d_1)(s_2-d_2)$. Since  $H$ is strictly quasi concave on $\{s \in S: s \gt d \}$, there exists $s \in S$ such that $s \gt d$ and $S$ is convex, so the maximizer of $H$ is unique. My question: I did not get the last part. Why is maximizer of $H$ unique?","Set $S \subset \mathbb R^2$ is compact and convex. A typical element of $S$ is $s=(s_1,s_2) \in S$. Also, $d \in \mathbb R^2$ is a fixed element such that there exists $s \in S$ such that $s \gt d$. Here  $s \gt d$ means $s_1 \gt d_1$ and $s_2 \gt d_2$ $$\underset{(d_1,d_2)\le(s_1,s_2) \in S}{\overset{}{\operatorname{arg \;\; max}}} \; (s_1-d_1)(s_2-d_2)$$ Let $H(s_1,s_2)=(s_1-d_1)(s_2-d_2)$. Since  $H$ is strictly quasi concave on $\{s \in S: s \gt d \}$, there exists $s \in S$ such that $s \gt d$ and $S$ is convex, so the maximizer of $H$ is unique. My question: I did not get the last part. Why is maximizer of $H$ unique?",,"['calculus', 'real-analysis', 'multivariable-calculus', 'self-learning', 'convex-analysis']"
68,How to prove this multivariable integral identity?,How to prove this multivariable integral identity?,,"By numerical experimentation I found that $$ \lim_{\beta \rightarrow \infty} \frac 1 \beta \int_0^{\beta}dx \int_0^{\beta}dy \, f\left( |x-y| \right) = 2\int_0^{\infty}dx \, f(x) $$ if $f:\mathbb{R} \rightarrow \mathbb{R} $ goes to zero sufficiently fast etc. How can we prove this identity (I am happy with a hint/sketch) and what is its geometrical meaning? Are there generalizations? My own attempt: write the double integral on the left-hand side as  $$ \int_0^{\beta}dx \int_0^{x}dy \, f\left( x-y \right) + \int_0^{\beta}dx \int_x^{\beta}dy \, f\left( y-x \right) \\= \int_0^{\beta}dx \int_0^{x}dy \, f\left( x-y \right) + \int_0^{\beta}dy \int_0^{y}dx \, f\left( y-x \right) \\= 2 \int_0^{\beta}dx \int_0^{x}dy \, f\left( x-y \right). $$ Not sure what do do next.","By numerical experimentation I found that $$ \lim_{\beta \rightarrow \infty} \frac 1 \beta \int_0^{\beta}dx \int_0^{\beta}dy \, f\left( |x-y| \right) = 2\int_0^{\infty}dx \, f(x) $$ if $f:\mathbb{R} \rightarrow \mathbb{R} $ goes to zero sufficiently fast etc. How can we prove this identity (I am happy with a hint/sketch) and what is its geometrical meaning? Are there generalizations? My own attempt: write the double integral on the left-hand side as  $$ \int_0^{\beta}dx \int_0^{x}dy \, f\left( x-y \right) + \int_0^{\beta}dx \int_x^{\beta}dy \, f\left( y-x \right) \\= \int_0^{\beta}dx \int_0^{x}dy \, f\left( x-y \right) + \int_0^{\beta}dy \int_0^{y}dx \, f\left( y-x \right) \\= 2 \int_0^{\beta}dx \int_0^{x}dy \, f\left( x-y \right). $$ Not sure what do do next.",,"['integration', 'multivariable-calculus', 'improper-integrals']"
69,Doubt on understanding continuity .,Doubt on understanding continuity .,,"Just preparing for my multivariable-calculus exam and wanted to clear these things: I've come across many questions of sort below , especially 2-dimensional regions , and wanted to understand the Idea behind them.... Prove the continuity of $f(x,y)$ on $\mathbb R^2$where, $$f(x,y) = \begin{cases} \text{some fn./value is given} & \text{, if x,y in region1 } \\ \text{some other fn./value is given} & \text{, if x,y in region2} \end{cases}$$ Here ,region $1$ and region $2$ consist of all those points $(x,y)$ satisfying respective inequalities in $x$ and $y$... to clearly understand my above statements consider example:  $$f(x,y)= \begin{cases}  e^{-\text(\frac{1}{|x-y|})} & \text{if $x\neq y$} \\ 0 & \text{if $x=y$} \end{cases} $$ Now if I've to prove continuity on $\mathbb R^2$ : STEP 1 : I should pick up any $(x_0,y_0)$ in $\mathbb R^2$ where continuity can be proved, STEP 2 : Now what I've to show that limit of $f(x,y)$ where $(x,y)$ are in region $1$ must be equal to limit of $f$ at $(x_0,y_0)$. similarly ,show the above for region $2$. Am I correct with this procedure.....","Just preparing for my multivariable-calculus exam and wanted to clear these things: I've come across many questions of sort below , especially 2-dimensional regions , and wanted to understand the Idea behind them.... Prove the continuity of $f(x,y)$ on $\mathbb R^2$where, $$f(x,y) = \begin{cases} \text{some fn./value is given} & \text{, if x,y in region1 } \\ \text{some other fn./value is given} & \text{, if x,y in region2} \end{cases}$$ Here ,region $1$ and region $2$ consist of all those points $(x,y)$ satisfying respective inequalities in $x$ and $y$... to clearly understand my above statements consider example:  $$f(x,y)= \begin{cases}  e^{-\text(\frac{1}{|x-y|})} & \text{if $x\neq y$} \\ 0 & \text{if $x=y$} \end{cases} $$ Now if I've to prove continuity on $\mathbb R^2$ : STEP 1 : I should pick up any $(x_0,y_0)$ in $\mathbb R^2$ where continuity can be proved, STEP 2 : Now what I've to show that limit of $f(x,y)$ where $(x,y)$ are in region $1$ must be equal to limit of $f$ at $(x_0,y_0)$. similarly ,show the above for region $2$. Am I correct with this procedure.....",,"['multivariable-calculus', 'continuity']"
70,What is an exact differential?,What is an exact differential?,,"My book says ""A differential expression $M(x, y)dx+N(x, y)dy$ is an exact differential in a region $R$ of the $xy$-plane if it corresponds to the differential of some function $f(x, y)$ defined on $R$"" What I understand is that $M(x, y)dx+N(x, y)dy$ is called an exact differential if it is equal to a function that is integrable (its indefinite integral exists). Is my understanding correct?","My book says ""A differential expression $M(x, y)dx+N(x, y)dy$ is an exact differential in a region $R$ of the $xy$-plane if it corresponds to the differential of some function $f(x, y)$ defined on $R$"" What I understand is that $M(x, y)dx+N(x, y)dy$ is called an exact differential if it is equal to a function that is integrable (its indefinite integral exists). Is my understanding correct?",,"['multivariable-calculus', 'definition']"
71,Equation of ellipsoid surface obtained by revolving an ellipse,Equation of ellipsoid surface obtained by revolving an ellipse,,"I'm working through the following example from the Princeton Review book: If the ellipse $x^{2} + x^{2/9}=1$ in the $xz-$plane is revolved around the $z-$axis, what's the equation of the resulting ellipsoid surface? Now, the curve $f(x,z)=x^{2}+x^{2/9}-1=0$ is being revolved around the $z-$axis, so I replace $x$ with $\pm \sqrt{x^{2}+y^{2}}$, and obtain $(\pm \sqrt{x^{2}+y^{2}})^{2}+(\pm \sqrt{x^{2}+y^{2}})^{2/9}=1$, which becomes $x^{2}+y^{2}+(x^{2}+y^{2})^{1/9}=1$. My problem, however, is that the book gets $x^{2}+y^{2}+\frac{1}{9}z^{2}=1$. Which one of us is correct? And, if it's the book, how do they get $\frac{1}{9}z^{2}$ from $(\pm \sqrt{x^{2}+y^{2}})^{2/9}$? Thank you in advance! :)","I'm working through the following example from the Princeton Review book: If the ellipse $x^{2} + x^{2/9}=1$ in the $xz-$plane is revolved around the $z-$axis, what's the equation of the resulting ellipsoid surface? Now, the curve $f(x,z)=x^{2}+x^{2/9}-1=0$ is being revolved around the $z-$axis, so I replace $x$ with $\pm \sqrt{x^{2}+y^{2}}$, and obtain $(\pm \sqrt{x^{2}+y^{2}})^{2}+(\pm \sqrt{x^{2}+y^{2}})^{2/9}=1$, which becomes $x^{2}+y^{2}+(x^{2}+y^{2})^{1/9}=1$. My problem, however, is that the book gets $x^{2}+y^{2}+\frac{1}{9}z^{2}=1$. Which one of us is correct? And, if it's the book, how do they get $\frac{1}{9}z^{2}$ from $(\pm \sqrt{x^{2}+y^{2}})^{2/9}$? Thank you in advance! :)",,"['calculus', 'multivariable-calculus']"
72,help with strange Double Integral: $\iint_E {x\sin(y) \over y}\ \rm{dx\ dy}$,help with strange Double Integral:,\iint_E {x\sin(y) \over y}\ \rm{dx\ dy},"i'm having trouble with this double integral: $$ \iint_E {x\sin(y) \over y}\ \rm{dx\ dy},\ \ \ \  E=\Big\{(x,y) \in \mathbb{R^2} \mid 0<y\le x\ \ \  \land\ \ \  x^2+y^2 \le \pi y\Big\} $$ i've tried using polar coordinates, but after i made the domain normal i realized that the integrand got a lot more complicated.. then i've tried another transform: $u=y/x, v=y$; with even worse results. i'm looking mainly for a tip on how to tackle this, also i'd like to know the reasoning behind an eventual tip... thanks in advance!","i'm having trouble with this double integral: $$ \iint_E {x\sin(y) \over y}\ \rm{dx\ dy},\ \ \ \  E=\Big\{(x,y) \in \mathbb{R^2} \mid 0<y\le x\ \ \  \land\ \ \  x^2+y^2 \le \pi y\Big\} $$ i've tried using polar coordinates, but after i made the domain normal i realized that the integrand got a lot more complicated.. then i've tried another transform: $u=y/x, v=y$; with even worse results. i'm looking mainly for a tip on how to tackle this, also i'd like to know the reasoning behind an eventual tip... thanks in advance!",,"['calculus', 'integration', 'multivariable-calculus']"
73,Multivariable optimization - how to parametrize a boundary?,Multivariable optimization - how to parametrize a boundary?,,"A metal plate has the shape of the region $x^2 + y^2 \leq  1$ . The plate is heated so that the temperature at any point $(x,y)$ on it is indicated by $$T(x,y) = 2x^2 + y^2 - y + 3$$ Find the hottest and coldest points on the plate and the temperature at each of these points. (Hint: Parametrize the boundary of the plate in order to find any critical points there.) I know how to do the actual optimization part of this problem. I already found a critical point at (0,0.5) by setting the first partial derivatives equal to 0. My problem is, how do I parametrize the boundary to find the other ones? I've seen solutions where they used cos(t) and sin(t) - where and how did they know how to do that?","A metal plate has the shape of the region . The plate is heated so that the temperature at any point on it is indicated by Find the hottest and coldest points on the plate and the temperature at each of these points. (Hint: Parametrize the boundary of the plate in order to find any critical points there.) I know how to do the actual optimization part of this problem. I already found a critical point at (0,0.5) by setting the first partial derivatives equal to 0. My problem is, how do I parametrize the boundary to find the other ones? I've seen solutions where they used cos(t) and sin(t) - where and how did they know how to do that?","x^2 + y^2 \leq  1 (x,y) T(x,y) = 2x^2 + y^2 - y + 3","['multivariable-calculus', 'optimization', 'parametric']"
74,Taking the partial derivative of $z=F(x/y)$,Taking the partial derivative of,z=F(x/y),I have just started on chapter for partial derivative and I have a very basic question: Please go easy on me since I just started on the topic today. Let the function be: $$z=F\left(\frac{x}{y}\right)$$ I am wondering if the reasoning of mine is correct. $$\frac{\partial z}{\partial x}=\frac{F'\left(\frac{x}{y}\right)}{y}$$ now what I am intrested to know is the logic behind it. I use the chain rule: $$F'\left(\frac{x}{y}\right)* ?$$ here is the question: Do I leave $$\frac{1}{y}$$ and differentiate x which is equal to 1. Second part which obviously is just as easy when you get the hang of it: $$\frac{\partial z}{\partial y}=-\frac{x F'\left(\frac{x}{y}\right)}{y^2}$$ I use the same logic: Chain rule: $$F'\left(\frac{x}{y}\right)* ?$$ now I leave $$\frac{x}{1}$$ And differentiate $$\frac{1}{y}$$ $$F'\left(\frac{x}{y}\right)*x*\frac{-1}{y^2}$$ Is my logic correct or is it something I am missing?,I have just started on chapter for partial derivative and I have a very basic question: Please go easy on me since I just started on the topic today. Let the function be: $$z=F\left(\frac{x}{y}\right)$$ I am wondering if the reasoning of mine is correct. $$\frac{\partial z}{\partial x}=\frac{F'\left(\frac{x}{y}\right)}{y}$$ now what I am intrested to know is the logic behind it. I use the chain rule: $$F'\left(\frac{x}{y}\right)* ?$$ here is the question: Do I leave $$\frac{1}{y}$$ and differentiate x which is equal to 1. Second part which obviously is just as easy when you get the hang of it: $$\frac{\partial z}{\partial y}=-\frac{x F'\left(\frac{x}{y}\right)}{y^2}$$ I use the same logic: Chain rule: $$F'\left(\frac{x}{y}\right)* ?$$ now I leave $$\frac{x}{1}$$ And differentiate $$\frac{1}{y}$$ $$F'\left(\frac{x}{y}\right)*x*\frac{-1}{y^2}$$ Is my logic correct or is it something I am missing?,,"['calculus', 'multivariable-calculus', 'partial-derivative']"
75,"How to prove that $\int_0^b\Big(\int_0^xf(x,y)\;dy\Big)\;dx=\int_0^b\Big(\int_y^bf(x,y)\;dx\Big)\;dy$?",How to prove that ?,"\int_0^b\Big(\int_0^xf(x,y)\;dy\Big)\;dx=\int_0^b\Big(\int_y^bf(x,y)\;dx\Big)\;dy","Problem. Let $f:[0,b]\times[0,b]\to\mathbb{R}$ be continuous. Prove that   $$\int_0^b\left(\int_0^xf(x,y)\;dy\right)\;dx=\int_0^b\left(\int_y^bf(x,y)\;dx\right)\;dy.\tag{1}$$ My first thought was to use Fubini's theorem: the left hand side of $(1)$ equals the double integral $$\iint_{D_1} f(x,y)\;dA\tag{2}$$ and the right-hand side equals $$\iint_{D_2} f(x,y)\;dA,\tag{3}$$ where $D_1=\{(x,y);\;0\leq x\leq b,\;0\leq y\leq x\}$ and $D_2=\{(x,y);\;0\leq y\leq b,\;y\leq x\leq b\}$. Since $D_1=D_2$, the integrals $(2)$ and $(3)$ are the same and thus $(1)$ holds. However, the problem  is proposed before multiple integrals be defined. So my question is: how to solve the problem using single variable integrals? Remark. In the section that proposes the problem, we have the following theorem: if $f:[a,b]\times[c,d]\to\mathbb{R}$ is continuous, then $$\int_a^b\left(\int_c^df(s,t)\;ds\right)\;ds=\int_c^d\left(\int_a^bf(s,t)\;ds\right)\;dt.$$ Proof: Let $\varphi:[a,b]\to\mathbb{R}$ be given by $$\varphi(x)=\int_c^d\left(\int_a^xf(s,t)\;ds\right)\;dt.$$ Then, $$\int_a^b\left(\int_c^df(s,t)\;ds\right)\;ds=\varphi(a)+\int_a^b\varphi'(s)\;ds=\varphi(b)=\int_c^d\left(\int_a^bf(s,t)\;ds\right)\;dt.$$ I tried to apply a similar argument to the problem, but I couldn't do it. Thanks.","Problem. Let $f:[0,b]\times[0,b]\to\mathbb{R}$ be continuous. Prove that   $$\int_0^b\left(\int_0^xf(x,y)\;dy\right)\;dx=\int_0^b\left(\int_y^bf(x,y)\;dx\right)\;dy.\tag{1}$$ My first thought was to use Fubini's theorem: the left hand side of $(1)$ equals the double integral $$\iint_{D_1} f(x,y)\;dA\tag{2}$$ and the right-hand side equals $$\iint_{D_2} f(x,y)\;dA,\tag{3}$$ where $D_1=\{(x,y);\;0\leq x\leq b,\;0\leq y\leq x\}$ and $D_2=\{(x,y);\;0\leq y\leq b,\;y\leq x\leq b\}$. Since $D_1=D_2$, the integrals $(2)$ and $(3)$ are the same and thus $(1)$ holds. However, the problem  is proposed before multiple integrals be defined. So my question is: how to solve the problem using single variable integrals? Remark. In the section that proposes the problem, we have the following theorem: if $f:[a,b]\times[c,d]\to\mathbb{R}$ is continuous, then $$\int_a^b\left(\int_c^df(s,t)\;ds\right)\;ds=\int_c^d\left(\int_a^bf(s,t)\;ds\right)\;dt.$$ Proof: Let $\varphi:[a,b]\to\mathbb{R}$ be given by $$\varphi(x)=\int_c^d\left(\int_a^xf(s,t)\;ds\right)\;dt.$$ Then, $$\int_a^b\left(\int_c^df(s,t)\;ds\right)\;ds=\varphi(a)+\int_a^b\varphi'(s)\;ds=\varphi(b)=\int_c^d\left(\int_a^bf(s,t)\;ds\right)\;dt.$$ I tried to apply a similar argument to the problem, but I couldn't do it. Thanks.",,"['calculus', 'real-analysis', 'multivariable-calculus']"
76,condition for differentiability,condition for differentiability,,"Lets say you have a function: $$f: \mathbb{R}^2 \rightarrow \mathbb{R^2}=((u(x,y),v(x,y)).$$ Does it follow directly from this definition: http://en.wikipedia.org/wiki/Differentiable_function#Differentiability_in_higher_dimensions That $f$ is differentiable if and only if both $u$ and $v$ are differentiable? Update: A similar question is if $k:\mathbb{R}^2\rightarrow \mathbb{R}$ is differentiable, and $l:\mathbb{R}^2\rightarrow \mathbb{R}$ and $m:\mathbb{R}^2\rightarrow \mathbb{R}$ is differentiable, is then $k(l(x,y),m(x,y))$ differentiable? I am using this for something in complex analysis.","Lets say you have a function: $$f: \mathbb{R}^2 \rightarrow \mathbb{R^2}=((u(x,y),v(x,y)).$$ Does it follow directly from this definition: http://en.wikipedia.org/wiki/Differentiable_function#Differentiability_in_higher_dimensions That $f$ is differentiable if and only if both $u$ and $v$ are differentiable? Update: A similar question is if $k:\mathbb{R}^2\rightarrow \mathbb{R}$ is differentiable, and $l:\mathbb{R}^2\rightarrow \mathbb{R}$ and $m:\mathbb{R}^2\rightarrow \mathbb{R}$ is differentiable, is then $k(l(x,y),m(x,y))$ differentiable? I am using this for something in complex analysis.",,"['calculus', 'real-analysis', 'multivariable-calculus']"
77,Find the angle of intersection of the plane $4x+4y−1z=0$ with the plane $−4x−2y+3z=0$.,Find the angle of intersection of the plane  with the plane .,4x+4y−1z=0 −4x−2y+3z=0,"Find the angle of intersection in radians of the plane $4x+4y−1z=0$ with the plane $−4x−2y+3z=0$. Attempt: Write $\overrightarrow{n_1} = (4,4,-1)$ and $\overrightarrow{n_2} = (-4, -2, 3)$ and then $\displaystyle \theta = \cos^{-1}\Big(\frac{\overrightarrow{n_1}\cdot\overrightarrow{n_2}}{|\overrightarrow{n_1}|\overrightarrow{n_2}|}\Big)=\cos^{-1}\big(\frac{-27}{|\sqrt{33}|\sqrt{29}|}\big)$. However, this was the incorrect answer.","Find the angle of intersection in radians of the plane $4x+4y−1z=0$ with the plane $−4x−2y+3z=0$. Attempt: Write $\overrightarrow{n_1} = (4,4,-1)$ and $\overrightarrow{n_2} = (-4, -2, 3)$ and then $\displaystyle \theta = \cos^{-1}\Big(\frac{\overrightarrow{n_1}\cdot\overrightarrow{n_2}}{|\overrightarrow{n_1}|\overrightarrow{n_2}|}\Big)=\cos^{-1}\big(\frac{-27}{|\sqrt{33}|\sqrt{29}|}\big)$. However, this was the incorrect answer.",,['multivariable-calculus']
78,"Finding multivariable limit $\lim_{(x,y,z)\to(0,0,0)} \frac{xyz}{(x^2+y^2+z^2)^{a/2}}$",Finding multivariable limit,"\lim_{(x,y,z)\to(0,0,0)} \frac{xyz}{(x^2+y^2+z^2)^{a/2}}","Let $a>0$. Find $$\lim_{(x,y,z)\to(0,0,0)} \frac{xyz}{(x^2+y^2+z^2)^{a/2}}$$ After playing around with this a little bit, it looks like the limit is $0$ for $a<3$ and else it is $\infty$. But how do I actually compute this limit? Are there any nice tricks to evaluate limits of three variables? Thank you.","Let $a>0$. Find $$\lim_{(x,y,z)\to(0,0,0)} \frac{xyz}{(x^2+y^2+z^2)^{a/2}}$$ After playing around with this a little bit, it looks like the limit is $0$ for $a<3$ and else it is $\infty$. But how do I actually compute this limit? Are there any nice tricks to evaluate limits of three variables? Thank you.",,"['limits', 'multivariable-calculus']"
79,"Evaluating $\lim\limits_{(x,y)\rightarrow(1,1)} \frac {\sin(x) - \sin (y)} {x-y}$",Evaluating,"\lim\limits_{(x,y)\rightarrow(1,1)} \frac {\sin(x) - \sin (y)} {x-y}","I am taking a calculus exam in less than one week, and I've stumbled upon this expression. $$\lim\limits_{(x,y)\rightarrow(1,1)} \frac {\sin(x) - \sin (y)} {x-y}$$ Which I know to be cos(1), but I cannot seem to find the inequalities to make an $\epsilon-\delta$ proof of said limit. I've tried coordinate change and Taylor, to no avail. Whenever I do Taylor(1) or equivalent infinitesimals, any variable I have manages to cancel out. If I don't, the thing just grows and grows... Is there something I am entirely missing from the start?","I am taking a calculus exam in less than one week, and I've stumbled upon this expression. $$\lim\limits_{(x,y)\rightarrow(1,1)} \frac {\sin(x) - \sin (y)} {x-y}$$ Which I know to be cos(1), but I cannot seem to find the inequalities to make an $\epsilon-\delta$ proof of said limit. I've tried coordinate change and Taylor, to no avail. Whenever I do Taylor(1) or equivalent infinitesimals, any variable I have manages to cancel out. If I don't, the thing just grows and grows... Is there something I am entirely missing from the start?",,"['calculus', 'limits', 'multivariable-calculus']"
80,"Finding the partial derivatives of $h(x)=\int_{0}^{\|x\|} f(t)\, dt$",Finding the partial derivatives of,"h(x)=\int_{0}^{\|x\|} f(t)\, dt","Find the partial derivatives of $$h(x_1,\dots,x_n)=\int_{0}^{\|x\|} f(t) dt$$ where $\|x\|$ is the Euclidean norm of $x=(x_1,\dots,x_n)$ and $f$ is some continuous function. I'm sorry but I'm really not too sure how to approach this. Any help would be great! (This is not homework, I'm preparing for an exam.)","Find the partial derivatives of $$h(x_1,\dots,x_n)=\int_{0}^{\|x\|} f(t) dt$$ where $\|x\|$ is the Euclidean norm of $x=(x_1,\dots,x_n)$ and $f$ is some continuous function. I'm sorry but I'm really not too sure how to approach this. Any help would be great! (This is not homework, I'm preparing for an exam.)",,"['integration', 'multivariable-calculus', 'partial-derivative']"
81,Prove that the gradient transforms as a vector under rotations,Prove that the gradient transforms as a vector under rotations,,"I have not been able to make the following problem: Consider that $f$ is a function of only two variables, $y$ and $z$. Show that the gradient: $$\nabla f=\left(\frac{\partial f}{\partial y}\right)\hat{e_{y}}+\left(\frac{\partial f}{\partial z}\right)\hat{e_{z}}$$ transforms as a vector under rotations. My idea is to use relationships: $$\bar{y}=y\cos\phi+z\sin\phi$$ $$\bar{z}=-y\sin\phi+z\cos\phi$$ Solving this system of equations for $y$ and $z$, and determining the derivative: $\partial y/\partial \bar{y}$, $\partial z/\partial \bar{y}$, $\partial y/\partial \bar{z}$ y $\partial z/\partial \bar{y}$. I can perform these steps without any problem, but then I do not know what to do. If anyone could help me I would appreciate it too.","I have not been able to make the following problem: Consider that $f$ is a function of only two variables, $y$ and $z$. Show that the gradient: $$\nabla f=\left(\frac{\partial f}{\partial y}\right)\hat{e_{y}}+\left(\frac{\partial f}{\partial z}\right)\hat{e_{z}}$$ transforms as a vector under rotations. My idea is to use relationships: $$\bar{y}=y\cos\phi+z\sin\phi$$ $$\bar{z}=-y\sin\phi+z\cos\phi$$ Solving this system of equations for $y$ and $z$, and determining the derivative: $\partial y/\partial \bar{y}$, $\partial z/\partial \bar{y}$, $\partial y/\partial \bar{z}$ y $\partial z/\partial \bar{y}$. I can perform these steps without any problem, but then I do not know what to do. If anyone could help me I would appreciate it too.",,"['calculus', 'multivariable-calculus']"
82,Confounding Lagrange multiplier problem,Confounding Lagrange multiplier problem,,"Optimize $f(x,y,z) = 4x^2 + 3y^2 + 5z^2$ over $g(x,y,z) = xy + 2yz + 3xz = 6$ According to the theorem the gradients must be parallell, $\nabla f = \lambda \nabla g$, so their cross product must equal zero i.e. $\nabla f \times \nabla g = \mathbf{0}$. This results in the following system of equations: $$ \begin{cases} 3y(2y+3x) = 5z(x+2z)  \\ 5z(y + 3z) = 4x(2y + 3x) \\ 4x(x+  2z) = 3y(y+3z)  \end{cases} $$ A system of equations which got me stumped, as I am unable to derive anything useful/sensible from it. Yes I did attempt to incorporate the constraint, albeit unsuccessfully.Now since Lagrange multipliers are failing me (?), I have no clue as to how I can progress. Any help?","Optimize $f(x,y,z) = 4x^2 + 3y^2 + 5z^2$ over $g(x,y,z) = xy + 2yz + 3xz = 6$ According to the theorem the gradients must be parallell, $\nabla f = \lambda \nabla g$, so their cross product must equal zero i.e. $\nabla f \times \nabla g = \mathbf{0}$. This results in the following system of equations: $$ \begin{cases} 3y(2y+3x) = 5z(x+2z)  \\ 5z(y + 3z) = 4x(2y + 3x) \\ 4x(x+  2z) = 3y(y+3z)  \end{cases} $$ A system of equations which got me stumped, as I am unable to derive anything useful/sensible from it. Yes I did attempt to incorporate the constraint, albeit unsuccessfully.Now since Lagrange multipliers are failing me (?), I have no clue as to how I can progress. Any help?",,"['multivariable-calculus', 'optimization', 'lagrange-multiplier']"
83,Area of a Curved Surface,Area of a Curved Surface,,Find the area of the part o the surface $z=xy$ that lies within the cylinder $x^2+y^2=1$. I'm not sure how to set up the surface integral to compute this.,Find the area of the part o the surface $z=xy$ that lies within the cylinder $x^2+y^2=1$. I'm not sure how to set up the surface integral to compute this.,,"['integration', 'multivariable-calculus']"
84,Question on Green's Theorem,Question on Green's Theorem,,"Consider the vector field $\textbf{f}(x,y)=(ye^{xy}+y^2\sqrt{x})\textbf{i}+(xe^{xy}+\frac{4}{3}yx^{\frac{3}{2}})\textbf{j}$. Use Green's Theorem to evaluate $\int_C\textbf{f} \dot d\textbf{r}$, where $C$ is the ellipse given by $(x-1)^2+\frac{y^2}{9}=1$, oriented counterclockwise. $\int_C\textbf{f} \dot d\textbf{r} = \int \int_R (\frac{\partial Q}{\partial x} -\frac{\partial P}{\partial y}) \ dx \ dy$ $=\int \int_R (xe^{xy}+ye^{xy}+2yx^\frac{1}{2})-(ye^{xy}+xe^{xy}+2\sqrt{x}y) \ dx \ dy$ $=\int \int_R 2y\sqrt{x}-2\sqrt{x}y \ dx \ dy$ What would the bounds be on the integral? I think I should parametrize to polar coordinates, but I'm not sure how to do that when the ellipse's center isn't the origin. Or would I just use $0\leq x \leq 2$ and $-\sqrt{9(1-(x-1)^2)} \leq y \leq  +\sqrt{9(1-(x-1)^2)}$ ? Thanks.","Consider the vector field $\textbf{f}(x,y)=(ye^{xy}+y^2\sqrt{x})\textbf{i}+(xe^{xy}+\frac{4}{3}yx^{\frac{3}{2}})\textbf{j}$. Use Green's Theorem to evaluate $\int_C\textbf{f} \dot d\textbf{r}$, where $C$ is the ellipse given by $(x-1)^2+\frac{y^2}{9}=1$, oriented counterclockwise. $\int_C\textbf{f} \dot d\textbf{r} = \int \int_R (\frac{\partial Q}{\partial x} -\frac{\partial P}{\partial y}) \ dx \ dy$ $=\int \int_R (xe^{xy}+ye^{xy}+2yx^\frac{1}{2})-(ye^{xy}+xe^{xy}+2\sqrt{x}y) \ dx \ dy$ $=\int \int_R 2y\sqrt{x}-2\sqrt{x}y \ dx \ dy$ What would the bounds be on the integral? I think I should parametrize to polar coordinates, but I'm not sure how to do that when the ellipse's center isn't the origin. Or would I just use $0\leq x \leq 2$ and $-\sqrt{9(1-(x-1)^2)} \leq y \leq  +\sqrt{9(1-(x-1)^2)}$ ? Thanks.",,"['integration', 'multivariable-calculus']"
85,derivatives of a vector of functions with respect to a vector,derivatives of a vector of functions with respect to a vector,,"Let $\vec W \in \mathbb R^3$. What is the general solution to: $$\frac{\partial}{\partial \vec{W}} \begin{pmatrix}         f(\vec W) \\         g(\vec W)         \end{pmatrix} $$ I think that in the case where $f$ and $g$ are linear I could rewrite: $$\begin{pmatrix}         f(\vec W) \\         g(\vec W)         \end{pmatrix} =A\cdot \vec W $$ for some suitable matrix $A$ and then this would break down to: $$\frac{\partial}{\partial \vec{W}}A\cdot \vec W=A $$ Is this correct? So my question really aims for the general case, i.e. when $f$ and $g$ are not necessarily linear. It feels kind of wrong to take the derivatives along the rows given that $\vec W$ is a column-vector.","Let $\vec W \in \mathbb R^3$. What is the general solution to: $$\frac{\partial}{\partial \vec{W}} \begin{pmatrix}         f(\vec W) \\         g(\vec W)         \end{pmatrix} $$ I think that in the case where $f$ and $g$ are linear I could rewrite: $$\begin{pmatrix}         f(\vec W) \\         g(\vec W)         \end{pmatrix} =A\cdot \vec W $$ for some suitable matrix $A$ and then this would break down to: $$\frac{\partial}{\partial \vec{W}}A\cdot \vec W=A $$ Is this correct? So my question really aims for the general case, i.e. when $f$ and $g$ are not necessarily linear. It feels kind of wrong to take the derivatives along the rows given that $\vec W$ is a column-vector.",,"['multivariable-calculus', 'derivatives', 'vector-analysis', 'vectors']"
86,Parametric equation of a circle given starting point.,Parametric equation of a circle given starting point.,,"Find the parametric equations of a circle with radius of $5$ where you start at point $(5,0)$ at $v=0$ and you travel clockwise with a period of $3$. So, I know that I require to have a $x(v)$ and $y(v)$ answer. So for $x(v)$, Since it starts at $5$, I figured the answer would be $x(v) = 5 + 5\cos()$ and for $y(v)$, since it starts at $0$, its simply $y(v) = 0 + 5 \sin()$. However, I am not too sure about what to enter in the parentheses.( I know that we would need $bv$, where $b$ is the coefficient to $v$). Since it says $3$ period, is it found like this? $$3b = 2 \pi, \quad b = \frac{2}{3} \pi$$ And so, the answer for $x$ would be $x(v) = 5 + 5\cos(2/3\pi v)$ and for $y; y(v) = 5 \sin(2/3\pi v)$. My answers are wrong, could you explain where I went wrong. Thanks! calculus","Find the parametric equations of a circle with radius of $5$ where you start at point $(5,0)$ at $v=0$ and you travel clockwise with a period of $3$. So, I know that I require to have a $x(v)$ and $y(v)$ answer. So for $x(v)$, Since it starts at $5$, I figured the answer would be $x(v) = 5 + 5\cos()$ and for $y(v)$, since it starts at $0$, its simply $y(v) = 0 + 5 \sin()$. However, I am not too sure about what to enter in the parentheses.( I know that we would need $bv$, where $b$ is the coefficient to $v$). Since it says $3$ period, is it found like this? $$3b = 2 \pi, \quad b = \frac{2}{3} \pi$$ And so, the answer for $x$ would be $x(v) = 5 + 5\cos(2/3\pi v)$ and for $y; y(v) = 5 \sin(2/3\pi v)$. My answers are wrong, could you explain where I went wrong. Thanks! calculus",,"['calculus', 'multivariable-calculus', 'circles', 'parametric']"
87,"Line integrals of vector fields-positive, negative, or zero","Line integrals of vector fields-positive, negative, or zero",,"I have a question about line integrals of vector fields being positive, negative, or zero. If you are measuring the work it takes to ""push"" a point on the curve through the vector field, does this mean that going in the same direction is negative, opposite direction is positive, and perpendicular is zero? Someone please correct me if I'm wrong.","I have a question about line integrals of vector fields being positive, negative, or zero. If you are measuring the work it takes to ""push"" a point on the curve through the vector field, does this mean that going in the same direction is negative, opposite direction is positive, and perpendicular is zero? Someone please correct me if I'm wrong.",,"['multivariable-calculus', 'visualization']"
88,Changing order of integration in cylindrical coordinates,Changing order of integration in cylindrical coordinates,,"I'm having a problem in changing order of integration in triple integration, in cylindrical coordinates. I would be grateful for a little help.The question is: Let D be the region bounded below by the cone $z= \sqrt{x^2 + y^2} $ and above by the parabola $z=2-x^2-y^2$. Set up the triple integrals in cylindrical coordinates that give the volume of D using the following orders of integration. (a) $dzdrd\theta$, (b)$drdzd\theta$, (c) $d\theta dzdr$ I drew the graph, and it looks like an ice cream cone, with radius of 1. I figured out (a), which was $ 0\leq \theta  \leq 2\pi$, $0 \leq r \leq 1$, and $r \leq z \leq 2-r^2$. which would give the equation  $\int_0^{2\pi}  \int_0^1  \int_r^{2-r^2} dzrdrd\theta $ . And this was the method that our professor taught us. But I'm not sure what to do for (b) and (c). Which way should I look at the graph? For (b), i guess the interval of integration for $\theta$ is $ 0\leq \theta  \leq 2\pi$ but I'm not sure for $z$ and $r$..... I thought in double integral with polar coordinates, I can't change the order of $drd\theta$. Why can I do it here?","I'm having a problem in changing order of integration in triple integration, in cylindrical coordinates. I would be grateful for a little help.The question is: Let D be the region bounded below by the cone $z= \sqrt{x^2 + y^2} $ and above by the parabola $z=2-x^2-y^2$. Set up the triple integrals in cylindrical coordinates that give the volume of D using the following orders of integration. (a) $dzdrd\theta$, (b)$drdzd\theta$, (c) $d\theta dzdr$ I drew the graph, and it looks like an ice cream cone, with radius of 1. I figured out (a), which was $ 0\leq \theta  \leq 2\pi$, $0 \leq r \leq 1$, and $r \leq z \leq 2-r^2$. which would give the equation  $\int_0^{2\pi}  \int_0^1  \int_r^{2-r^2} dzrdrd\theta $ . And this was the method that our professor taught us. But I'm not sure what to do for (b) and (c). Which way should I look at the graph? For (b), i guess the interval of integration for $\theta$ is $ 0\leq \theta  \leq 2\pi$ but I'm not sure for $z$ and $r$..... I thought in double integral with polar coordinates, I can't change the order of $drd\theta$. Why can I do it here?",,"['calculus', 'integration', 'multivariable-calculus']"
89,Surface Integral of a Right Circular Cone,Surface Integral of a Right Circular Cone,,"Use a surface integral to show that the surface area of a right circular cone of radius $R$ and height $h$ is $\pi R \sqrt{h^2+R^2}$. Hint -- Use the parametrization $x=r\cos\theta$, $y=r\sin\theta$, $z=\dfrac{h}{R}r$, for $0\leq r \leq R$, and $0\leq \theta \leq 2\pi$. Could someone explain how to set up this integral? What would you integrate? This was the solution given, but I don't understand the steps. Thanks.","Use a surface integral to show that the surface area of a right circular cone of radius $R$ and height $h$ is $\pi R \sqrt{h^2+R^2}$. Hint -- Use the parametrization $x=r\cos\theta$, $y=r\sin\theta$, $z=\dfrac{h}{R}r$, for $0\leq r \leq R$, and $0\leq \theta \leq 2\pi$. Could someone explain how to set up this integral? What would you integrate? This was the solution given, but I don't understand the steps. Thanks.",,['multivariable-calculus']
90,Can someone verify this identity for switching the order of integration,Can someone verify this identity for switching the order of integration,,"Can someone verify that the identity $$\int_a^b \int_x^b f(x,y) \,dy\,dx =\int_a^b\int_a^y f(x,y) \,dx\, dy$$ is true? For the function $f(x,y)=x^2+y^2 $ I get the same for both integrals: $$ \int_a^b\int_a^y (x^2+y^2) \, dx\, dy=\int_a^b \int_x^b (x^2+y^2) \, dy\,dx= \frac{1}{3} (a-b)^2 \left(a^2+a b+b^2\right).$$ Thanks!","Can someone verify that the identity $$\int_a^b \int_x^b f(x,y) \,dy\,dx =\int_a^b\int_a^y f(x,y) \,dx\, dy$$ is true? For the function $f(x,y)=x^2+y^2 $ I get the same for both integrals: $$ \int_a^b\int_a^y (x^2+y^2) \, dx\, dy=\int_a^b \int_x^b (x^2+y^2) \, dy\,dx= \frac{1}{3} (a-b)^2 \left(a^2+a b+b^2\right).$$ Thanks!",,"['integration', 'multivariable-calculus']"
91,Optimization of parallelepiped inside an ellipsoid,Optimization of parallelepiped inside an ellipsoid,,"Let $K \in R^3$  the ellipsoid given by the equation $ \frac{x^2}{a^2} + \frac{y^2}{b^2} + \frac{z^2}{c^2} = 1 $ with $a,b,c > 0$ , let $(x,y,z) \in K$ on the first octant, consider the parallelepiped of vertices $(\pm x,\pm y,\pm z)$ inscribed on $K$  with volume $V = 8xyz$. How can I find the maximum possible value of $V$? I stuck with this hard problem for me i tried to find the explicit equation and then get the maximum values : Let $P=(x,y,z)$ be a point on the ellipsoid with $x,y,z\gt 0$.Then i took the eight different points with $P_i (\pm x,\pm y,\pm z)$  the vertices of a parallelepiped with the side length $2x , 2y$ and $2z$. Then, the volume parallelepiped is $V = 2x\cdot 2y\cdot 2z = 8 xyz$ and i remembered that $V$ is maximum if and only if $V^2$ is maximum . Some help please.","Let $K \in R^3$  the ellipsoid given by the equation $ \frac{x^2}{a^2} + \frac{y^2}{b^2} + \frac{z^2}{c^2} = 1 $ with $a,b,c > 0$ , let $(x,y,z) \in K$ on the first octant, consider the parallelepiped of vertices $(\pm x,\pm y,\pm z)$ inscribed on $K$  with volume $V = 8xyz$. How can I find the maximum possible value of $V$? I stuck with this hard problem for me i tried to find the explicit equation and then get the maximum values : Let $P=(x,y,z)$ be a point on the ellipsoid with $x,y,z\gt 0$.Then i took the eight different points with $P_i (\pm x,\pm y,\pm z)$  the vertices of a parallelepiped with the side length $2x , 2y$ and $2z$. Then, the volume parallelepiped is $V = 2x\cdot 2y\cdot 2z = 8 xyz$ and i remembered that $V$ is maximum if and only if $V^2$ is maximum . Some help please.",,"['multivariable-calculus', 'derivatives', 'optimization', 'volume']"
92,Flux Integral - where did I go wrong?,Flux Integral - where did I go wrong?,,"S is the graph $z=25-(x^2+y^2)$ over the disk $x^2+y^2\leq 9$ and $\varphi = z^2dx\wedge dy$. Find $\int_S \varphi$. According to the book the answer is $3843\pi$, but the answer I got is different. What I did: First define $k(x,y)=(x,y,25-(x^2+y^2))$ then $k_x=(1,0,-2x)$ and $k_y=(0,1,-2y)$. Now, I have that $\varphi (k_x,k_y)=(25-(x^2+y^2))^2dx\wedge dy (k_x,k_y)=(25-(x^2+y^2))^2$. I ought to find $\int_S\varphi$ which will be given by $$\int_S\varphi=\int_0^3\int_0^{\sqrt{9-y^2}}625-50(x^2+y^2)+(x^2+y^2)^2dxdy$$. To make it easier, I changed to polar coordinates: $x=r\cos\phi,y=r\sin\psi$. Then I have $$\int_S\varphi = \int_0^{\color{red}{2\pi}}\int_0^3625r-50r^3+r^5drd\phi\\=\int_0^{\color{red}{2\pi}}\left(\frac{625}{2}(3)^2-\frac{50}{4}(3)^4+\frac{1}{6}(3)^6\right)d\phi\\=\int_0^{\color{red}{2\pi}}\left(\frac{5625}{2}-\frac{4050}{4}+\frac{726}{6}\right)d\varphi\\=\int_0^{\color{red}{2\pi}} 1921\; d\phi\\=3842\pi.$$ Looks like I have missed something, maybe my change to polar coordinates is wrong or there's another mistake that I cannot see. Update:Fixed the limits of integration","S is the graph $z=25-(x^2+y^2)$ over the disk $x^2+y^2\leq 9$ and $\varphi = z^2dx\wedge dy$. Find $\int_S \varphi$. According to the book the answer is $3843\pi$, but the answer I got is different. What I did: First define $k(x,y)=(x,y,25-(x^2+y^2))$ then $k_x=(1,0,-2x)$ and $k_y=(0,1,-2y)$. Now, I have that $\varphi (k_x,k_y)=(25-(x^2+y^2))^2dx\wedge dy (k_x,k_y)=(25-(x^2+y^2))^2$. I ought to find $\int_S\varphi$ which will be given by $$\int_S\varphi=\int_0^3\int_0^{\sqrt{9-y^2}}625-50(x^2+y^2)+(x^2+y^2)^2dxdy$$. To make it easier, I changed to polar coordinates: $x=r\cos\phi,y=r\sin\psi$. Then I have $$\int_S\varphi = \int_0^{\color{red}{2\pi}}\int_0^3625r-50r^3+r^5drd\phi\\=\int_0^{\color{red}{2\pi}}\left(\frac{625}{2}(3)^2-\frac{50}{4}(3)^4+\frac{1}{6}(3)^6\right)d\phi\\=\int_0^{\color{red}{2\pi}}\left(\frac{5625}{2}-\frac{4050}{4}+\frac{726}{6}\right)d\varphi\\=\int_0^{\color{red}{2\pi}} 1921\; d\phi\\=3842\pi.$$ Looks like I have missed something, maybe my change to polar coordinates is wrong or there's another mistake that I cannot see. Update:Fixed the limits of integration",,"['integration', 'multivariable-calculus', 'definite-integrals', 'differential-forms']"
93,Normal derivative,Normal derivative,,"Let $f(x,y)=\frac{1}{2}\log(x^2+y^2)$ in $\mathbb{R}^2\setminus (0,0)$. Is the limit of normal derivative of $f$ with respect to the unit circle ($\mathbb{S}=\{(x,y): \: x^2+y^2=1\}$) as $(x,y)$ approaches to a point on $\mathbb{S}$ equal to $1$?","Let $f(x,y)=\frac{1}{2}\log(x^2+y^2)$ in $\mathbb{R}^2\setminus (0,0)$. Is the limit of normal derivative of $f$ with respect to the unit circle ($\mathbb{S}=\{(x,y): \: x^2+y^2=1\}$) as $(x,y)$ approaches to a point on $\mathbb{S}$ equal to $1$?",,"['calculus', 'multivariable-calculus']"
94,Smoothness of $f(x)/(1+|f(x)|)$ where $f \in C^1(E)$ for $E$ an open subset of $\mathbb{R}^n$,Smoothness of  where  for  an open subset of,f(x)/(1+|f(x)|) f \in C^1(E) E \mathbb{R}^n,"(a) Show that if $E$ is an open subset of $\mathbb{R}$ and $f \in C^1(E)$ then the function $$F(x) = \frac{f(x)}{1+|f(x)|}$$ satisfies $F \in C^1(E)$. (b) Extend the results of part (a) to $f \in C^1(E)$ for $E$ an open subset of $\mathbb{R}^n$. Hint part (a): Show that if $f(x) \neq 0$ at $x \in E$ then $$F'(x)=\frac{f'(x)}{(1+|f(x)|)^2}$$ and that for $x_0 \in E, f(x_0)=0$ then $F'(x_0)=f'(x_0)$ and that $lim_{x \rightarrow x_0} F'(x)=F'(x_0)$ Comments: Showed part (a), but I can not generalize to the $\mathbb{R}^n$.","(a) Show that if $E$ is an open subset of $\mathbb{R}$ and $f \in C^1(E)$ then the function $$F(x) = \frac{f(x)}{1+|f(x)|}$$ satisfies $F \in C^1(E)$. (b) Extend the results of part (a) to $f \in C^1(E)$ for $E$ an open subset of $\mathbb{R}^n$. Hint part (a): Show that if $f(x) \neq 0$ at $x \in E$ then $$F'(x)=\frac{f'(x)}{(1+|f(x)|)^2}$$ and that for $x_0 \in E, f(x_0)=0$ then $F'(x_0)=f'(x_0)$ and that $lim_{x \rightarrow x_0} F'(x)=F'(x_0)$ Comments: Showed part (a), but I can not generalize to the $\mathbb{R}^n$.",,"['real-analysis', 'multivariable-calculus', 'derivatives']"
95,$\iiint \frac{1}{x^2+y^2+(z-2)^2}dA$ where $A=\{x^2+y^2+z^2 \leq 1\}$ check my answer!,where  check my answer!,\iiint \frac{1}{x^2+y^2+(z-2)^2}dA A=\{x^2+y^2+z^2 \leq 1\},"I would like someone to review my solution please, the original question is to calculate $\iiint \frac{1}{x^2+y^2+(z-2)^2}dA$ where $A=\{x^2+y^2+z^2 \leq 1\}$ What I did: First I changed variables to polar coordinates in order to simplify the boundaries: $x=r\sin\theta cos\phi$, $y=r\sin\theta \sin\phi$, $z=r\cos\theta$, $0\leq r \leq 1$, $0\leq \theta \leq \pi$, $0 \leq \phi \leq 2\pi$ and the jacobian is $r^2\sin\theta$. to get the following result: $$\int_{0}^{2\pi}\int_{0}^{\pi}\int_{0}^{1} \frac{r^2sin\theta}{r^2-2rcos\theta+4}drd\theta d\phi$$ We can see that $\phi$ doesn't appear in any integral, so we can just multiply by $2\pi-0=2\pi$ and forget about it: $$\int_{0}^{2\pi}\int_{0}^{\pi}\int_{0}^{1} \frac{r^2sin\theta}{r^2-2rcos\theta+4}drd\theta d\phi =2\pi \int_{0}^{\pi}\int_{0}^{1} \frac{r^2sin\theta}{r^2-2rcos\theta+4}drd\theta$$ now I used substitution, $\alpha=-cos\theta$, $d\alpha =sin\theta d\theta$, $-1 \leq \alpha \leq 1$ $$2\pi \int_{0}^{\pi}\int_{0}^{1} \frac{r^2sin\theta}{r^2-2rcos\theta+4}drd\theta=2\pi \int_{-1}^{1}\int_{0}^{1}\frac{r^2sin\theta}{r^2+2r\alpha+4}dr\frac{d\alpha}{sin\theta}$$ cancel the sine to get: $$2\pi \int_{-1}^{1}\int_{0}^{1}\frac{r^2}{r^2+2r\alpha+4}drd\alpha$$ this integral is very difficult (at least wasn't apparent to me) if we integrate by $r$. luckily, Fubini's theorem states that we can integrate by $\alpha$ first and the result won't change: $$2\pi \int_{-1}^{1}\int_{0}^{1}\frac{r^2}{r^2+2r\alpha+4}drd\alpha=2\pi\int_{0}^{1}\int_{-1}^{1}\frac{r^2}{r^2+2r\alpha+4}d\alpha dr $$ The antiderivative of $$\frac{1}{r^2+2r\alpha+4}$$ with respect to alpha is $$\frac{\ln(r^2+2r\alpha+4)}{2r}$$ since $\alpha$ goes from $-1$ to $1$: $$\frac{\ln(r^2+2r+4)}{2r}-\frac{\ln(r^2-2r+4)}{2r} = \frac{\ln(r+2)^2-\ln(r-2)^2}{2r}=\frac{\ln(\frac{r+2}{r-2})}{r}$$ so: $$2\pi\int_{0}^{1}\int_{-1}^{1}\frac{r^2}{r^2+2r\alpha+4}d\alpha dr=2\pi \int_{0}^{1}r\ln(\frac{r+2}{r-2})dr$$ Now I integrated by parts $\int uv'=uv-\int u'v$ where $u=\ln(\frac{r+2}{r-2})$, $u'=\frac{-4}{r^2-4}$, $v'=r$, $v=\frac{r^2}{2}$: $$\int r\ln(\frac{r+2}{r-2})dr=\frac{r^2ln(\frac{r+2}{r-2})}{2}-\int\frac{-2r^2}{r^2-4}dr =\frac{r^2ln(\frac{r+2}{r-2})}{2}+2(r+\ln(\frac{r-2}{r+2})+2)$$ when $r=1$: $$\frac{1^2ln(-3)}{2}+2(1+\ln(\frac{-1}{3})+2)=\frac{1}{2}\ln(-3)-2\ln(-3)+6=-\frac{3}{2}\ln(3)-\frac{3\pi i}{2}+6$$ when $r=0$: $$0+2(0+\ln(-1)+2)=2\ln(-1)+4=2\ln(1)+2\pi i+4=4+2\pi i$$ Subtract the 2 results to get: $$-\frac{3}{2}\ln(3)-\frac{3\pi i}{2}+6-4-2\pi i=2-\frac{3}{2}\ln(3)-\frac{7\pi i}{2}$$ Multiply this result by $2\pi$ to reach the final answer which is $$4\pi-3\pi \ln(3)-7\pi^2i$$ Is this indeed the correct answer? Is there a better way of solving this? this seems like a very difficult way to do the exercise.","I would like someone to review my solution please, the original question is to calculate $\iiint \frac{1}{x^2+y^2+(z-2)^2}dA$ where $A=\{x^2+y^2+z^2 \leq 1\}$ What I did: First I changed variables to polar coordinates in order to simplify the boundaries: $x=r\sin\theta cos\phi$, $y=r\sin\theta \sin\phi$, $z=r\cos\theta$, $0\leq r \leq 1$, $0\leq \theta \leq \pi$, $0 \leq \phi \leq 2\pi$ and the jacobian is $r^2\sin\theta$. to get the following result: $$\int_{0}^{2\pi}\int_{0}^{\pi}\int_{0}^{1} \frac{r^2sin\theta}{r^2-2rcos\theta+4}drd\theta d\phi$$ We can see that $\phi$ doesn't appear in any integral, so we can just multiply by $2\pi-0=2\pi$ and forget about it: $$\int_{0}^{2\pi}\int_{0}^{\pi}\int_{0}^{1} \frac{r^2sin\theta}{r^2-2rcos\theta+4}drd\theta d\phi =2\pi \int_{0}^{\pi}\int_{0}^{1} \frac{r^2sin\theta}{r^2-2rcos\theta+4}drd\theta$$ now I used substitution, $\alpha=-cos\theta$, $d\alpha =sin\theta d\theta$, $-1 \leq \alpha \leq 1$ $$2\pi \int_{0}^{\pi}\int_{0}^{1} \frac{r^2sin\theta}{r^2-2rcos\theta+4}drd\theta=2\pi \int_{-1}^{1}\int_{0}^{1}\frac{r^2sin\theta}{r^2+2r\alpha+4}dr\frac{d\alpha}{sin\theta}$$ cancel the sine to get: $$2\pi \int_{-1}^{1}\int_{0}^{1}\frac{r^2}{r^2+2r\alpha+4}drd\alpha$$ this integral is very difficult (at least wasn't apparent to me) if we integrate by $r$. luckily, Fubini's theorem states that we can integrate by $\alpha$ first and the result won't change: $$2\pi \int_{-1}^{1}\int_{0}^{1}\frac{r^2}{r^2+2r\alpha+4}drd\alpha=2\pi\int_{0}^{1}\int_{-1}^{1}\frac{r^2}{r^2+2r\alpha+4}d\alpha dr $$ The antiderivative of $$\frac{1}{r^2+2r\alpha+4}$$ with respect to alpha is $$\frac{\ln(r^2+2r\alpha+4)}{2r}$$ since $\alpha$ goes from $-1$ to $1$: $$\frac{\ln(r^2+2r+4)}{2r}-\frac{\ln(r^2-2r+4)}{2r} = \frac{\ln(r+2)^2-\ln(r-2)^2}{2r}=\frac{\ln(\frac{r+2}{r-2})}{r}$$ so: $$2\pi\int_{0}^{1}\int_{-1}^{1}\frac{r^2}{r^2+2r\alpha+4}d\alpha dr=2\pi \int_{0}^{1}r\ln(\frac{r+2}{r-2})dr$$ Now I integrated by parts $\int uv'=uv-\int u'v$ where $u=\ln(\frac{r+2}{r-2})$, $u'=\frac{-4}{r^2-4}$, $v'=r$, $v=\frac{r^2}{2}$: $$\int r\ln(\frac{r+2}{r-2})dr=\frac{r^2ln(\frac{r+2}{r-2})}{2}-\int\frac{-2r^2}{r^2-4}dr =\frac{r^2ln(\frac{r+2}{r-2})}{2}+2(r+\ln(\frac{r-2}{r+2})+2)$$ when $r=1$: $$\frac{1^2ln(-3)}{2}+2(1+\ln(\frac{-1}{3})+2)=\frac{1}{2}\ln(-3)-2\ln(-3)+6=-\frac{3}{2}\ln(3)-\frac{3\pi i}{2}+6$$ when $r=0$: $$0+2(0+\ln(-1)+2)=2\ln(-1)+4=2\ln(1)+2\pi i+4=4+2\pi i$$ Subtract the 2 results to get: $$-\frac{3}{2}\ln(3)-\frac{3\pi i}{2}+6-4-2\pi i=2-\frac{3}{2}\ln(3)-\frac{7\pi i}{2}$$ Multiply this result by $2\pi$ to reach the final answer which is $$4\pi-3\pi \ln(3)-7\pi^2i$$ Is this indeed the correct answer? Is there a better way of solving this? this seems like a very difficult way to do the exercise.",,"['calculus', 'integration', 'multivariable-calculus', 'logarithms']"
96,"Solve $\iint \exp(\frac{x}{y}) \, dx \, dy$",Solve,"\iint \exp(\frac{x}{y}) \, dx \, dy","Solve  $$\iint_D \exp\left(\frac{x}{y}\right) \, dx \, dy$$ where $D=\{(x,y): 1\leq y \leq 2, y \leq x \leq y^3 \}$ My attempt: $$\iint_D \exp\left(\frac{x}{y}\right) \, dx \, dy = \int_1^{\sqrt[3]{2}} \int_y^{y^3}  \exp\left(\frac{x}{y}\right) \, dx \, dy + \int_{\sqrt[3]{2}}^2 \int_{y}^2  \exp\left(\frac{x}{y}\right) \, dx \, dy$$ But i dont know how to solve $$ \int y \exp\left(\frac{2}{y}\right) \, dy$$ Am I doing someting wrong or should we do a change of variable to solve this? Thanks in advance","Solve  $$\iint_D \exp\left(\frac{x}{y}\right) \, dx \, dy$$ where $D=\{(x,y): 1\leq y \leq 2, y \leq x \leq y^3 \}$ My attempt: $$\iint_D \exp\left(\frac{x}{y}\right) \, dx \, dy = \int_1^{\sqrt[3]{2}} \int_y^{y^3}  \exp\left(\frac{x}{y}\right) \, dx \, dy + \int_{\sqrt[3]{2}}^2 \int_{y}^2  \exp\left(\frac{x}{y}\right) \, dx \, dy$$ But i dont know how to solve $$ \int y \exp\left(\frac{2}{y}\right) \, dy$$ Am I doing someting wrong or should we do a change of variable to solve this? Thanks in advance",,"['integration', 'multivariable-calculus', 'definite-integrals']"
97,Solving Simplified Hamilton's Equation,Solving Simplified Hamilton's Equation,,"I have a question on a project that I am working on. I have included a large amount of the background information so that all relevant information is included, however the question is as follows (it is also #12 below): Using a simplified version of $H$ given as $H(p,x)=\frac{p^2}{2}+\frac{x^2}{2}$ , consider a particle with initial position $a$ and no initial momentum. Solve Hamilton's equations for this particle. In other words, find the curve $\gamma(t)=(x(t),p(t))$ that solves Hamilton's equations with the initial conditions $x(0)=a$ and $p(0)=0$ . EDIT This is the answer that I have given so far: Using the example of the Harmonic Oscillator, with potential energy is $V(x) = \displaystyle\frac{kx^2}{2}$ for some constant $k$ , and allowing $k$ and $m$ to be equal to $1$ for simplicity, the Hamiltonian is given by: $$H(p,x) = \frac{p^2}{2} + \frac{x^2}{2}.$$ We can solve Hamilton's equations for a particle with initial position $a$ and no initial momentum, to find closed curve $\gamma(t)=(x(t),p(t))$ , with $x(0)=a$ and $p(0)=0$ . In actuality, we are finding $\dot{x}$ and $\dot{p}$ . Starting with the former, $\dot{x}$ : $$ \frac{\partial x}{\partial t} =\dot{x} =\frac{\partial H}{\partial p} =\frac{\partial}{\partial p}\left(\frac{p^2}{2} + \frac{x^2}{2}\right) =\frac{\partial}{\partial p}\left(\frac{x^2}{2}\right)   + \frac{\partial}{\partial p}\left(\frac{p^2}{2}\right) =0+\frac{2}{2}p =p.$$ We now integrate $\displaystyle\frac{\partial x}{\partial t}=p$ to get $x(t)$ : $$x(t)=\int{\frac{\partial x}{\partial t} dt} = \int{p dt} = pt + c_1.$$ Since we know $x(0)=a$ , $a$ is the initial condition of $x(t)$ , which implies $c_1=a$ , giving $x(t)=pt+a$ . Similarly, we can find $p(t)$ : $$ \frac{\partial p}{\partial t} =\dot{p} =-\frac{\partial H}{\partial x} =-\frac{\partial}{\partial x}\left(\frac{p^2}{2} +\frac{x^2}{2 }\right) =-\frac{\partial}{\partial x}\left(\frac{x^2}{2}\right) + \frac{\partial}{\partial x}\left(\frac{p^2}{2}\right) =-\frac{2}{2}x+0=-x. $$ We now integrate $\frac{\partial p}{\partial t}=-x$ to get $p(t)$ : $$p(t)=\int{\frac{\partial p}{\partial t} dt} = \int{-x dt} = -xt + c_2.$$ Since we know $p(0)=0$ , $0$ is the initial condition of $p(t)$ , which implies $c_2=0$ , giving $p(t)=-xt$ . Therefore, $\gamma(t)=(x(t),p(t))$ is given by the closed curve solving Hamilton's equations $\gamma(t)=\big(pt+a,-xt\big)$ . Here is the full information:","I have a question on a project that I am working on. I have included a large amount of the background information so that all relevant information is included, however the question is as follows (it is also #12 below): Using a simplified version of given as , consider a particle with initial position and no initial momentum. Solve Hamilton's equations for this particle. In other words, find the curve that solves Hamilton's equations with the initial conditions and . EDIT This is the answer that I have given so far: Using the example of the Harmonic Oscillator, with potential energy is for some constant , and allowing and to be equal to for simplicity, the Hamiltonian is given by: We can solve Hamilton's equations for a particle with initial position and no initial momentum, to find closed curve , with and . In actuality, we are finding and . Starting with the former, : We now integrate to get : Since we know , is the initial condition of , which implies , giving . Similarly, we can find : We now integrate to get : Since we know , is the initial condition of , which implies , giving . Therefore, is given by the closed curve solving Hamilton's equations . Here is the full information:","H H(p,x)=\frac{p^2}{2}+\frac{x^2}{2} a \gamma(t)=(x(t),p(t)) x(0)=a p(0)=0 V(x) = \displaystyle\frac{kx^2}{2} k k m 1 H(p,x) = \frac{p^2}{2} + \frac{x^2}{2}. a \gamma(t)=(x(t),p(t)) x(0)=a p(0)=0 \dot{x} \dot{p} \dot{x} 
\frac{\partial x}{\partial t}
=\dot{x}
=\frac{\partial H}{\partial p}
=\frac{\partial}{\partial p}\left(\frac{p^2}{2} + \frac{x^2}{2}\right)
=\frac{\partial}{\partial p}\left(\frac{x^2}{2}\right)
  + \frac{\partial}{\partial p}\left(\frac{p^2}{2}\right)
=0+\frac{2}{2}p
=p. \displaystyle\frac{\partial x}{\partial t}=p x(t) x(t)=\int{\frac{\partial x}{\partial t} dt} = \int{p dt} = pt + c_1. x(0)=a a x(t) c_1=a x(t)=pt+a p(t) 
\frac{\partial p}{\partial t}
=\dot{p}
=-\frac{\partial H}{\partial x}
=-\frac{\partial}{\partial x}\left(\frac{p^2}{2} +\frac{x^2}{2 }\right)
=-\frac{\partial}{\partial x}\left(\frac{x^2}{2}\right)
+ \frac{\partial}{\partial x}\left(\frac{p^2}{2}\right)
=-\frac{2}{2}x+0=-x.
 \frac{\partial p}{\partial t}=-x p(t) p(t)=\int{\frac{\partial p}{\partial t} dt} = \int{-x dt} = -xt + c_2. p(0)=0 0 p(t) c_2=0 p(t)=-xt \gamma(t)=(x(t),p(t)) \gamma(t)=\big(pt+a,-xt\big)","['multivariable-calculus', 'mathematical-physics']"
98,Maximum/Minimum of Curvature - Ellipse,Maximum/Minimum of Curvature - Ellipse,,"Find the sum of the maximum and minimum of the curvature of the ellipse: $9(x-1)^2 + y^2 = 9$. Hint (Use the parametrization $x(t) = 1 + \cos(t)$) Tried to use parametrization like that, but then get stuck trying to find the curvature function and max/minimizing it.","Find the sum of the maximum and minimum of the curvature of the ellipse: $9(x-1)^2 + y^2 = 9$. Hint (Use the parametrization $x(t) = 1 + \cos(t)$) Tried to use parametrization like that, but then get stuck trying to find the curvature function and max/minimizing it.",,"['multivariable-calculus', 'conic-sections', 'curvature']"
99,Inverse of a multivariables function,Inverse of a multivariables function,,"What would the inverse of the following functions be? \begin{align*} f(x,y,z)&:= (x-3y + 5z -14, x-4y+5z-3, 2x-3y+4z+1) \\ g(x,y)&:= (5x-3y-22, 2x - 2y -9) \end{align*} I would normally do these by using the matrix system, and by applying the Gauss-Jordan method I'd get the identity matrix and the inverse. But since I've got loose numbers with no variables, I don't know how to do this. And how would i be able to check if the answer is right once i got it? Thanks","What would the inverse of the following functions be? \begin{align*} f(x,y,z)&:= (x-3y + 5z -14, x-4y+5z-3, 2x-3y+4z+1) \\ g(x,y)&:= (5x-3y-22, 2x - 2y -9) \end{align*} I would normally do these by using the matrix system, and by applying the Gauss-Jordan method I'd get the identity matrix and the inverse. But since I've got loose numbers with no variables, I don't know how to do this. And how would i be able to check if the answer is right once i got it? Thanks",,['multivariable-calculus']
