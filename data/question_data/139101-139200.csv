,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Find a particular solution for $y''+2y'+2y=\ln(t)$,Find a particular solution for,y''+2y'+2y=\ln(t),"It's easy to know that the ode's complementary solutions are $$e^{-t}\cos t, e^{-t}\sin t$$ hence we can write the general solution as  $$y(t)=c_1(t)\cdot e^{-t}\cos t+c_2(t)\cdot e^{-t}\sin t $$  And there comes $$c_1'(t)\cdot e^{-t}\cos t+c_2'(t)\cdot e^{-t}\sin t=0 \\ c_1'(t)\cdot e^{-t}(-\sin t- \cos t)+c_2'(t)\cdot e^{-t}(\cos t-\sin t)=\ln x$$ By solve $c_1'(t)$ and $c_2'(t)$, I get $$c_1'(t)=-e^{t}\ln t\cdot\sin t,c_2'(t)=e^{t}\ln t\cdot\cos t $$ But I can't integrate it to get an exact solution. So is there any other way to get a particular solution such that I can write the solution as  $$y(t)=y_c(t)+y_p(t) $$","It's easy to know that the ode's complementary solutions are $$e^{-t}\cos t, e^{-t}\sin t$$ hence we can write the general solution as  $$y(t)=c_1(t)\cdot e^{-t}\cos t+c_2(t)\cdot e^{-t}\sin t $$  And there comes $$c_1'(t)\cdot e^{-t}\cos t+c_2'(t)\cdot e^{-t}\sin t=0 \\ c_1'(t)\cdot e^{-t}(-\sin t- \cos t)+c_2'(t)\cdot e^{-t}(\cos t-\sin t)=\ln x$$ By solve $c_1'(t)$ and $c_2'(t)$, I get $$c_1'(t)=-e^{t}\ln t\cdot\sin t,c_2'(t)=e^{t}\ln t\cdot\cos t $$ But I can't integrate it to get an exact solution. So is there any other way to get a particular solution such that I can write the solution as  $$y(t)=y_c(t)+y_p(t) $$",,['ordinary-differential-equations']
1,How do I find dx/dt implicitly with the function $\tan(x)=4t^{-1}$?,How do I find dx/dt implicitly with the function ?,\tan(x)=4t^{-1},"This question is a trigonometric one from what I can tell. I understand that you need to differentiate the given function and the unknown variable on top ($dx$) will correspond to the $x$ unknowns, for example $5x^2$ will give us $10x\frac{dx}{dt}$. With this specific question I can only get to $-\frac{\sec^2x}{4t^2}$ but the answer is $-\frac{\cos^2x}{4t^2}$. I also do not understand how $\sec^2x$ becomes $\cos^2x$. Thanks.","This question is a trigonometric one from what I can tell. I understand that you need to differentiate the given function and the unknown variable on top ($dx$) will correspond to the $x$ unknowns, for example $5x^2$ will give us $10x\frac{dx}{dt}$. With this specific question I can only get to $-\frac{\sec^2x}{4t^2}$ but the answer is $-\frac{\cos^2x}{4t^2}$. I also do not understand how $\sec^2x$ becomes $\cos^2x$. Thanks.",,"['ordinary-differential-equations', 'trigonometry', 'implicit-differentiation']"
2,General solution to a first-order partial differential equation,General solution to a first-order partial differential equation,,"$$ \begin{cases} \displaystyle u(x+u)\frac {\partial 𝑢}{\partial 𝑥} - y(y+u)\frac {\partial 𝑢}{\partial 𝑦}  = 0 \\ u=\sqrt y ,x =1 \end{cases} $$ my idea: Can we solve by the method :  $$\frac {𝑑x}{u(𝑥+u )} =  \frac{𝑑y}{-y(𝑦 +u)}$$","$$ \begin{cases} \displaystyle u(x+u)\frac {\partial 𝑢}{\partial 𝑥} - y(y+u)\frac {\partial 𝑢}{\partial 𝑦}  = 0 \\ u=\sqrt y ,x =1 \end{cases} $$ my idea: Can we solve by the method :  $$\frac {𝑑x}{u(𝑥+u )} =  \frac{𝑑y}{-y(𝑦 +u)}$$",,"['ordinary-differential-equations', 'partial-differential-equations']"
3,Find a particular integral for $y''+y'+y = 2+x+\cos(x)$,Find a particular integral for,y''+y'+y = 2+x+\cos(x),"If it were merely $y''+y'+y = \cos(x)$, then I know that I would try $a\cos(kx) + b\sin(kx)$, but with the added $2 + x$, I am not entirely sure.","If it were merely $y''+y'+y = \cos(x)$, then I know that I would try $a\cos(kx) + b\sin(kx)$, but with the added $2 + x$, I am not entirely sure.",,['ordinary-differential-equations']
4,"How to know the singular points of non-linear, second order ODEs?","How to know the singular points of non-linear, second order ODEs?",,"I am interested in learning whether there is a standard, systematic way of determining the singular points of non-linear, second degree ODEs. Particularly, I am interested in determining at what time this autonomous equation will blow-up, without actually having to solve the equation: $$ x''(t)=\frac{(x'(t))^2}{3}+e^{x(t)}\quad;\quad x(0)=0,\quad x'(0)=0~~.\tag{1}$$ Equation (1) is actually solvable by very clever substitutions (see here, in eqworld ), but I am interested more in the theory and more flexible procedures -- or useful theorems. I know Equation (1) will blow-up, because the solution to the related equation $$\chi''=e^\chi\quad;\quad \chi(0)=0,\quad \chi'(0)=0~~.\tag{2}$$ diverges at $t=\pi/\sqrt{2}$. Right side of Equation (1) grows even faster than (1), so it should blow-up at $t<\pi/\sqrt{2}$ as well, as numerical exploration indicates. We can prove that Equation (2) blows-up by noting that $$ (\chi')^2=2(e^\chi-1)~~.$$ Then, we calculate the integral $$\int_0^\infty \frac{dz}{\sqrt{2(e^z-1)}}=\frac{\pi}{\sqrt 2}~~,$$ from where we can deduce that solution to Eq. (2) blows-up at $\pi/\sqrt{2}$ without actually having to solve (2). Can we maybe adapt something like this to second order? It goes without saying: any help, comment, question, or thought will be very appreciated.","I am interested in learning whether there is a standard, systematic way of determining the singular points of non-linear, second degree ODEs. Particularly, I am interested in determining at what time this autonomous equation will blow-up, without actually having to solve the equation: $$ x''(t)=\frac{(x'(t))^2}{3}+e^{x(t)}\quad;\quad x(0)=0,\quad x'(0)=0~~.\tag{1}$$ Equation (1) is actually solvable by very clever substitutions (see here, in eqworld ), but I am interested more in the theory and more flexible procedures -- or useful theorems. I know Equation (1) will blow-up, because the solution to the related equation $$\chi''=e^\chi\quad;\quad \chi(0)=0,\quad \chi'(0)=0~~.\tag{2}$$ diverges at $t=\pi/\sqrt{2}$. Right side of Equation (1) grows even faster than (1), so it should blow-up at $t<\pi/\sqrt{2}$ as well, as numerical exploration indicates. We can prove that Equation (2) blows-up by noting that $$ (\chi')^2=2(e^\chi-1)~~.$$ Then, we calculate the integral $$\int_0^\infty \frac{dz}{\sqrt{2(e^z-1)}}=\frac{\pi}{\sqrt 2}~~,$$ from where we can deduce that solution to Eq. (2) blows-up at $\pi/\sqrt{2}$ without actually having to solve (2). Can we maybe adapt something like this to second order? It goes without saying: any help, comment, question, or thought will be very appreciated.",,['ordinary-differential-equations']
5,Complex Values in Second Order Differential Equations,Complex Values in Second Order Differential Equations,,"Recently I've learned that second order linear homogeneous differential equations can be solved by assuming the function to be something like this.  $$Ay''+By'+Cy=0$$ $$y = e^{St} $$ $$AS^2+BS+C=0$$ When encountering underdamped systems, the value of S would be imaginary, leaving you with Euler's identity. $$e^{i\alpha}=\cos(\alpha t)+i\sin(\alpha t)$$ When solving for the fundamental solutions our professor disregarded the imaginary coefficient and claimed that the fundamental solutions are the imaginary component and the real component. How is this so??","Recently I've learned that second order linear homogeneous differential equations can be solved by assuming the function to be something like this.  $$Ay''+By'+Cy=0$$ $$y = e^{St} $$ $$AS^2+BS+C=0$$ When encountering underdamped systems, the value of S would be imaginary, leaving you with Euler's identity. $$e^{i\alpha}=\cos(\alpha t)+i\sin(\alpha t)$$ When solving for the fundamental solutions our professor disregarded the imaginary coefficient and claimed that the fundamental solutions are the imaginary component and the real component. How is this so??",,"['ordinary-differential-equations', 'complex-numbers']"
6,Prove that this sequence converges to a point,Prove that this sequence converges to a point,,"I encounter a problem about genetics equilibrium under the condition of mutation that needs me to ask for whether the following sequence converges to a point and if yes, what that point is. $$\eqalign{   & {a_1} = 0.5  \cr    & u = 0.7  \cr    & v = 0.55 \cr} $$ $$\eqalign{   & {a_1} \in (0,1)  \cr    & {a_2} = {a_1}(1 - u) + v(1 - {a_1}){\rm{ }}  \cr    & u,v \in (0,1)  \cr    & {a_3} = {a_2}(1 - u) + v(1 - {a_2})  \cr    & {a_n} \to ?{\rm{ }} \cr} $$ when $$n \to \infty $$ The more important question is how is the answer derived? As a biomedical sciences student I only have background in Calculus I, II and linear algebra. No analysis background.","I encounter a problem about genetics equilibrium under the condition of mutation that needs me to ask for whether the following sequence converges to a point and if yes, what that point is. $$\eqalign{   & {a_1} = 0.5  \cr    & u = 0.7  \cr    & v = 0.55 \cr} $$ $$\eqalign{   & {a_1} \in (0,1)  \cr    & {a_2} = {a_1}(1 - u) + v(1 - {a_1}){\rm{ }}  \cr    & u,v \in (0,1)  \cr    & {a_3} = {a_2}(1 - u) + v(1 - {a_2})  \cr    & {a_n} \to ?{\rm{ }} \cr} $$ when $$n \to \infty $$ The more important question is how is the answer derived? As a biomedical sciences student I only have background in Calculus I, II and linear algebra. No analysis background.",,"['calculus', 'ordinary-differential-equations', 'analysis']"
7,Differential equation of first order,Differential equation of first order,,I have this simple differential equation: $y'=(\tan x)y.$ after integrating $\frac{y'}{y(x)}= \tan x$ i came up with $\log y(x)=-\log \cos(x)+1.$ now my question is this one:  why $ e^{-\log \cos(x)}=\sec(x)?$ thank you for your time,I have this simple differential equation: $y'=(\tan x)y.$ after integrating $\frac{y'}{y(x)}= \tan x$ i came up with $\log y(x)=-\log \cos(x)+1.$ now my question is this one:  why $ e^{-\log \cos(x)}=\sec(x)?$ thank you for your time,,"['ordinary-differential-equations', 'exponential-function']"
8,Integrating Factor Initial Value Problems,Integrating Factor Initial Value Problems,,How do I solve for the initial value with the given equation: $xy'+y = e^{\sin x}\cos x$ for y $\left(π\right)$ = 1 I have tried to isolate the $y'$ by multiplying the whole equation by $\frac 1x$ and I got: $y' + \frac 1x$$y= \frac 1x$$e^{\sin x}\cos x$ I thus got my integrating factor as: $I\left(x\right)$ = $e^{∫ \frac 1x}$ = $e^{\log x}$ = x I'm not really sure how do I continue from here though.,How do I solve for the initial value with the given equation: for y = 1 I have tried to isolate the by multiplying the whole equation by and I got: I thus got my integrating factor as: = = = x I'm not really sure how do I continue from here though.,xy'+y = e^{\sin x}\cos x \left(π\right) y' \frac 1x y' + \frac 1xy= \frac 1xe^{\sin x}\cos x I\left(x\right) e^{∫ \frac 1x} e^{\log x},['ordinary-differential-equations']
9,On the solution of one matrix differential equation,On the solution of one matrix differential equation,,"We have the next equation  $$\dot K=AK+KA^T+HH^T,$$ where $K(t),A(t),H \in R^{n \times n}, K-$is a symmetric matrix. How one can prove that the solution of this equation is as follows: $$K(t)=\int_0^te^{As}HH^T e^{A^Ts}ds$$ on $ [0,t]$, provideed that $K(0)=\boldsymbol{0}$?","We have the next equation  $$\dot K=AK+KA^T+HH^T,$$ where $K(t),A(t),H \in R^{n \times n}, K-$is a symmetric matrix. How one can prove that the solution of this equation is as follows: $$K(t)=\int_0^te^{As}HH^T e^{A^Ts}ds$$ on $ [0,t]$, provideed that $K(0)=\boldsymbol{0}$?",,"['matrices', 'ordinary-differential-equations', 'matrix-equations', 'matrix-calculus']"
10,attempting to solve the diff equation $y'(x^2+1)-2xy=4\sqrt{y(x^2+1)}$,attempting to solve the diff equation,y'(x^2+1)-2xy=4\sqrt{y(x^2+1)},$$y'(x^2+1)-2xy=4\sqrt{y(x^2+1)}$$ $$y'\sqrt{(x^2+1)}-\frac{2xy}{\sqrt{(x^2+1)}}=4\sqrt{y}$$ $$\frac{y'\sqrt{(x^2+1)}-\frac{2xy}{\sqrt{(x^2+1)}}}{x^2+1}= \frac{4\sqrt{y}}{x^2+1}$$ I tried to solve this but I can't get rid of the 2 which would have enabled me to wrtie $$(\frac{y}{x^2+1})'$$ how do I solve this?,$$y'(x^2+1)-2xy=4\sqrt{y(x^2+1)}$$ $$y'\sqrt{(x^2+1)}-\frac{2xy}{\sqrt{(x^2+1)}}=4\sqrt{y}$$ $$\frac{y'\sqrt{(x^2+1)}-\frac{2xy}{\sqrt{(x^2+1)}}}{x^2+1}= \frac{4\sqrt{y}}{x^2+1}$$ I tried to solve this but I can't get rid of the 2 which would have enabled me to wrtie $$(\frac{y}{x^2+1})'$$ how do I solve this?,,"['calculus', 'ordinary-differential-equations']"
11,Why Does the Characteristic Equation of a Differential Equation Depend on the Solution?,Why Does the Characteristic Equation of a Differential Equation Depend on the Solution?,,"I have learnt about the characteristic equations of differential equations (D.E.) only informally and recently observed that the way they are defined seems to depend not only on the equation, but on the solution / eigenfunctions. e.g. compare the following: First , a 2nd order constant coefficient D.E. $$ay'' + by' + cy = 0,$$ with characteristic polynomial $p(D) = aD^2 + bD + C$ (which we can find by taking the ansatz $y = e^{\lambda x}$ and substituting into the D.E.).$\\[5pt]$ Second , a 2nd order Cauchy-Euler D.E. $$x^2 \, y'' + \alpha \, x \, y' + \beta\, y = 0,$$ with characteristic polynomial $f(D) = D^2 +(\alpha-1)D + \beta$, which we can find by taking the ansatz $y = x^r$ and substituting into the D.E.). Clearly the characteristic polynomial in each case would be different if we started with a different ansatz , which leads me to suspect that my informal understanding is missing an important point in how these polynomials are defined. Can anyone clarify the situation, please? I suspect this is an issue with definitions, but am curious to know if the bigger picture might lend greater insight into D.E.","I have learnt about the characteristic equations of differential equations (D.E.) only informally and recently observed that the way they are defined seems to depend not only on the equation, but on the solution / eigenfunctions. e.g. compare the following: First , a 2nd order constant coefficient D.E. $$ay'' + by' + cy = 0,$$ with characteristic polynomial $p(D) = aD^2 + bD + C$ (which we can find by taking the ansatz $y = e^{\lambda x}$ and substituting into the D.E.).$\\[5pt]$ Second , a 2nd order Cauchy-Euler D.E. $$x^2 \, y'' + \alpha \, x \, y' + \beta\, y = 0,$$ with characteristic polynomial $f(D) = D^2 +(\alpha-1)D + \beta$, which we can find by taking the ansatz $y = x^r$ and substituting into the D.E.). Clearly the characteristic polynomial in each case would be different if we started with a different ansatz , which leads me to suspect that my informal understanding is missing an important point in how these polynomials are defined. Can anyone clarify the situation, please? I suspect this is an issue with definitions, but am curious to know if the bigger picture might lend greater insight into D.E.",,"['ordinary-differential-equations', 'definition', 'eigenfunctions', 'characteristics']"
12,Power series solution of $y'' + e^x y = 0$,Power series solution of,y'' + e^x y = 0,"In the book of Int. to the Ordinary Differential Equation by Coddington, at page 130, in question 130, it is asked that The equation $$y'' + e^x y = 0$$ has a solution $\phi$ of the form    $$\phi(x) = \sum_{k=0}^\infty c_k x^k$$ which satisfies $\phi (0) =  1$, $\phi'(0) = 0$. Find $c_k$. I have plugged the Power series solution $\phi$ into the ODE, and found that every $$\sum_{k_0}^\infty [(k+2)(k+1)a_{k+2} + a_k e^x] x^k = 0$$. However, we can interpret this result in two different way. First; For a given $x$, the expression $$[(k+2)(k+1)a_{k+2} + a_k e^x]$$ has to be zero for all $k=0,1....$, Second; we can write this equation as $$\sum_{k_0}^\infty [ (k+2)(k+1)a_{k+2}x^k + a_k e^x x^k] = 0 $$, and since each $x^j$ and $x^ie^x$ are linearly independent provided that $x\not = 0$, each coefficient $a_k$ has to be zero. Since in particular, we are dealing with $x = 0$, we can still reach the same conclusion as in the first case, but what if we were dealing with $x=x_0 \not = 0$, then can we apply the first logic ?","In the book of Int. to the Ordinary Differential Equation by Coddington, at page 130, in question 130, it is asked that The equation $$y'' + e^x y = 0$$ has a solution $\phi$ of the form    $$\phi(x) = \sum_{k=0}^\infty c_k x^k$$ which satisfies $\phi (0) =  1$, $\phi'(0) = 0$. Find $c_k$. I have plugged the Power series solution $\phi$ into the ODE, and found that every $$\sum_{k_0}^\infty [(k+2)(k+1)a_{k+2} + a_k e^x] x^k = 0$$. However, we can interpret this result in two different way. First; For a given $x$, the expression $$[(k+2)(k+1)a_{k+2} + a_k e^x]$$ has to be zero for all $k=0,1....$, Second; we can write this equation as $$\sum_{k_0}^\infty [ (k+2)(k+1)a_{k+2}x^k + a_k e^x x^k] = 0 $$, and since each $x^j$ and $x^ie^x$ are linearly independent provided that $x\not = 0$, each coefficient $a_k$ has to be zero. Since in particular, we are dealing with $x = 0$, we can still reach the same conclusion as in the first case, but what if we were dealing with $x=x_0 \not = 0$, then can we apply the first logic ?",,['ordinary-differential-equations']
13,How do I find nullclines for an ODE given only one second order ODE?,How do I find nullclines for an ODE given only one second order ODE?,,"My textbook asks me to draw an outline of the phase space for $\frac{d^2x}{dt^2}-x\frac{dx}{dt}+x^2=0$ by studying the nullclines, but it never showed how to find the nullclines for a single equation like this, only with a system of equations. How can I accomplish this?","My textbook asks me to draw an outline of the phase space for $\frac{d^2x}{dt^2}-x\frac{dx}{dt}+x^2=0$ by studying the nullclines, but it never showed how to find the nullclines for a single equation like this, only with a system of equations. How can I accomplish this?",,"['ordinary-differential-equations', 'mathematical-modeling']"
14,Proof of uniqueness to the right,Proof of uniqueness to the right,,"There is a function $f: \mathbb{R} \times \mathbb{R} \rightarrow \mathbb{R}$ given. This function is non-increasing, so that we have: $$\forall\,{x_1, x_2 \in \mathbb{R}},\; x_1< x_2 \implies f(t, x_1) - f(t, x_2) \ge 0.$$ There is also a differential equation given with the initial condition: $$\begin{cases} x'=f(t,x)\\x(t_0) = x_0.\end{cases}$$ Let's consider two solutions of the equation above: $\phi_1, \phi_2$. To show uniqueness, it should be proved that $\phi_1 \equiv\phi_2$. This is my attempt: assume $\phi_1 \not\equiv \phi_2$ and $\phi_1 < \phi_2$. Because both $\phi_1$ and $\phi_2$ are solutions I can write: $$\begin{cases} \phi_1'=f(t,\phi_1)\\\phi(t_0) = x_0\end{cases}$$ and also $$\begin{cases} \phi_2'=f(t,\phi_2)\\\phi_2(t_0) = x_0.\end{cases}$$ Now I can consider this  $$\phi_1' - \phi_2' = f(t,\phi_1) - f(t,\phi_2) \ge 0,$$ thus $$\phi_1' \ge \phi_2'.$$ By integrating both sides of the equation above I do get $$\phi_1 - \phi_2 \ge C.$$ However that doesn't lead me to anything useful. I was trying to show that $\phi_1$ and $\phi_2$ differ by at most a constant and then use Picard's theorem . Unfortunately my attempt failed. I would appreciate any hints or tips.","There is a function $f: \mathbb{R} \times \mathbb{R} \rightarrow \mathbb{R}$ given. This function is non-increasing, so that we have: $$\forall\,{x_1, x_2 \in \mathbb{R}},\; x_1< x_2 \implies f(t, x_1) - f(t, x_2) \ge 0.$$ There is also a differential equation given with the initial condition: $$\begin{cases} x'=f(t,x)\\x(t_0) = x_0.\end{cases}$$ Let's consider two solutions of the equation above: $\phi_1, \phi_2$. To show uniqueness, it should be proved that $\phi_1 \equiv\phi_2$. This is my attempt: assume $\phi_1 \not\equiv \phi_2$ and $\phi_1 < \phi_2$. Because both $\phi_1$ and $\phi_2$ are solutions I can write: $$\begin{cases} \phi_1'=f(t,\phi_1)\\\phi(t_0) = x_0\end{cases}$$ and also $$\begin{cases} \phi_2'=f(t,\phi_2)\\\phi_2(t_0) = x_0.\end{cases}$$ Now I can consider this  $$\phi_1' - \phi_2' = f(t,\phi_1) - f(t,\phi_2) \ge 0,$$ thus $$\phi_1' \ge \phi_2'.$$ By integrating both sides of the equation above I do get $$\phi_1 - \phi_2 \ge C.$$ However that doesn't lead me to anything useful. I was trying to show that $\phi_1$ and $\phi_2$ differ by at most a constant and then use Picard's theorem . Unfortunately my attempt failed. I would appreciate any hints or tips.",,"['ordinary-differential-equations', 'proof-verification']"
15,Find general solution to this PDE,Find general solution to this PDE,,"$$x^2z{\partial z\over\partial x} + y^2z{\partial z \over \partial y} = x+y$$  My attempt:  $${dx\over x^2z}={dy\over y^2z}={dz\over x+y}$$ Notice ${dx\over x^2z}={dy\over y^2z} \text{ we can multiply by } z \text{ and after integration} \Rightarrow {1\over x} = {1\over y} + C_1$ Here I stuck, 'cause I can't find new combination to integrate. I'm sure there are a lot of people quite good at finding these combination. So my question is also what are you looking at first. Is there common tricks to get this done?","$$x^2z{\partial z\over\partial x} + y^2z{\partial z \over \partial y} = x+y$$  My attempt:  $${dx\over x^2z}={dy\over y^2z}={dz\over x+y}$$ Notice ${dx\over x^2z}={dy\over y^2z} \text{ we can multiply by } z \text{ and after integration} \Rightarrow {1\over x} = {1\over y} + C_1$ Here I stuck, 'cause I can't find new combination to integrate. I'm sure there are a lot of people quite good at finding these combination. So my question is also what are you looking at first. Is there common tricks to get this done?",,"['ordinary-differential-equations', 'partial-differential-equations']"
16,Solving $dy/dt = k(A-y)$ (phrased as rate of change probelm),Solving  (phrased as rate of change probelm),dy/dt = k(A-y),"The Problem The rate at which temperature decreases in a house is proportional to the difference between the current house-temperature and the temperature outside. It's -10 degrees outside, at the start it's 20 degrees inside the house and after an hour it's 17 degrees. After how long is it minus degrees inside? My solution (attempt) We know that $$dy/dt = k(y+10) \\ y(0) = 20 \\ y(1) = 17$$ We do a variable substitution $u(t) = y(t) + 10$ and we now have $$ du/dt = ku \\ u(0) = 30 \\ u(1) = 27$$ A solution to the equation is $u(t) = e^{kt} + A$ $$u(0) = 30 \rightarrow e^{0k}+A =  1+A = 30 \rightarrow A = 29$$ $$u(1) = 27 \rightarrow e^k + 29 = 27 \rightarrow k = ln(-2) \rightarrow Undefined$$ And that's where I'm stuck. Am I supposed to re-write the difference $y+10$ to something else?","The Problem The rate at which temperature decreases in a house is proportional to the difference between the current house-temperature and the temperature outside. It's -10 degrees outside, at the start it's 20 degrees inside the house and after an hour it's 17 degrees. After how long is it minus degrees inside? My solution (attempt) We know that $$dy/dt = k(y+10) \\ y(0) = 20 \\ y(1) = 17$$ We do a variable substitution $u(t) = y(t) + 10$ and we now have $$ du/dt = ku \\ u(0) = 30 \\ u(1) = 27$$ A solution to the equation is $u(t) = e^{kt} + A$ $$u(0) = 30 \rightarrow e^{0k}+A =  1+A = 30 \rightarrow A = 29$$ $$u(1) = 27 \rightarrow e^k + 29 = 27 \rightarrow k = ln(-2) \rightarrow Undefined$$ And that's where I'm stuck. Am I supposed to re-write the difference $y+10$ to something else?",,['ordinary-differential-equations']
17,Solve the differential equation 2y'=yx/(x^2 + 1) - 2x/y,Solve the differential equation 2y'=yx/(x^2 + 1) - 2x/y,,"I have to solve the equation: $$ 2y'= {\frac{xy}{x^2+1}} - {\frac{2x}{y}} $$ I know the first step is to divide by y, which gives the following equation: $$ {\frac{2y'}{y}} ={\frac{x}{x^2+1}} - {\frac{2x}{y^2}}$$ According to my notes I get that I should make a substitution:  $$ z = {\frac{1}{y^2}} $$ and  the derivative of z:$$ z' = {\frac{y'}{y^3}}$$ But I don't know how to proceed after this... Any help is appreciated!","I have to solve the equation: $$ 2y'= {\frac{xy}{x^2+1}} - {\frac{2x}{y}} $$ I know the first step is to divide by y, which gives the following equation: $$ {\frac{2y'}{y}} ={\frac{x}{x^2+1}} - {\frac{2x}{y^2}}$$ According to my notes I get that I should make a substitution:  $$ z = {\frac{1}{y^2}} $$ and  the derivative of z:$$ z' = {\frac{y'}{y^3}}$$ But I don't know how to proceed after this... Any help is appreciated!",,['ordinary-differential-equations']
18,l'Hopital's rule for 2 variables to compute Jacobian matrix,l'Hopital's rule for 2 variables to compute Jacobian matrix,,"I have a system of three ODEs and I have computed the Jacobian matrix. One of the steady states is (0,0,0) and I am trying to linearize the system around this steady state. In the Jacobian matrix two of the terms are of the form $cx^2\over cx+y$ and $z\over y$.Here, $x,y,z$ are the variables of the system and $c$ is a known constant. But when substituting x=0,y=0 and z=0 to the above terms it will be $0\over 0$. So, in this case, can I use L'hospital rule for 2 variables to compute the Jacobian around that steady state? That is I want to find $\lim_{(x,y)\to (0,0)}{ cx^2\over cx+y}$ and $\lim_{(z,y)\to (0,0)} {z\over y}$. I referred to the article on l'Hopital's rule for multi variable functions and with what it says in the article I could not find the limit of $\lim_{(x,y)\to (0,0)}{ cx^2\over cx+y}$ and the limit of $\lim_{(z,y)\to (0,0)} {z\over y}$ does not exist. Can someone please let me know a method to evaluate the two terms around the steady state.","I have a system of three ODEs and I have computed the Jacobian matrix. One of the steady states is (0,0,0) and I am trying to linearize the system around this steady state. In the Jacobian matrix two of the terms are of the form $cx^2\over cx+y$ and $z\over y$.Here, $x,y,z$ are the variables of the system and $c$ is a known constant. But when substituting x=0,y=0 and z=0 to the above terms it will be $0\over 0$. So, in this case, can I use L'hospital rule for 2 variables to compute the Jacobian around that steady state? That is I want to find $\lim_{(x,y)\to (0,0)}{ cx^2\over cx+y}$ and $\lim_{(z,y)\to (0,0)} {z\over y}$. I referred to the article on l'Hopital's rule for multi variable functions and with what it says in the article I could not find the limit of $\lim_{(x,y)\to (0,0)}{ cx^2\over cx+y}$ and the limit of $\lim_{(z,y)\to (0,0)} {z\over y}$ does not exist. Can someone please let me know a method to evaluate the two terms around the steady state.",,"['ordinary-differential-equations', 'limits', 'multivariable-calculus', 'jacobian', 'steady-state']"
19,Green's Function for a Fourth-Order Differential Equation,Green's Function for a Fourth-Order Differential Equation,,"I have just begun to look at Green's functions and am studying a fourth-order equation $\frac{d^4y}{dx^4}=f(x) \:\:\:\:\:\:y(0)=y'(0)=0\:\:\:\:\:\:y(1)=y'(1)=0$ In particular I have to show that the Green's function $G(x,u)$ for this equation satisfies a condition $\lim_{\epsilon\to0}\bigg[\frac{\partial^3G}{\partial x^3}\bigg]_{x=u-\epsilon}^{u+\epsilon}=1$ and must demonstrate the continuity of the Green's function and its first and second partial derivatives with respect to $x$ at $x=u$.  I am fairly new to Green's functions so would appreciate some pointers.","I have just begun to look at Green's functions and am studying a fourth-order equation $\frac{d^4y}{dx^4}=f(x) \:\:\:\:\:\:y(0)=y'(0)=0\:\:\:\:\:\:y(1)=y'(1)=0$ In particular I have to show that the Green's function $G(x,u)$ for this equation satisfies a condition $\lim_{\epsilon\to0}\bigg[\frac{\partial^3G}{\partial x^3}\bigg]_{x=u-\epsilon}^{u+\epsilon}=1$ and must demonstrate the continuity of the Green's function and its first and second partial derivatives with respect to $x$ at $x=u$.  I am fairly new to Green's functions so would appreciate some pointers.",,"['ordinary-differential-equations', 'greens-function']"
20,Wronskian of Airy functions.,Wronskian of Airy functions.,,"I am trying to show that that the Airy functions defined below satisfy: $W[Ai(x),Bi(x)]=1/\pi$. $$Ai(x)=\frac{1}{\pi} \int_0^\infty \cos(t^3/3+xt)dt$$ $$Bi(x)=\frac{1}{\pi}\int_0^\infty \bigg[ \exp(-t^3/3+xt)+\sin(t^3/3+xt)\bigg]dt $$ I tried to compute it directly but I got stuck, here's the last term I got: $$Ai(x)Bi'(x)-Ai'(x)Bi(x) = \frac{1}{\pi^2}\bigg[ \int_0^\infty \cos(t^3/3+xt)dt \int_0^\infty \bigg( s\exp(-s^3/3+xs)+s\cos(s^3/3+xs)\bigg) ds + \int_0^\infty \sin(t^3/3+xt)tdt\int_0^\infty \bigg(\exp(-s^3/3+xs)+\sin(s^3/3+xs)\bigg)ds \bigg]$$ I don't see how to proceed from here, I guess I need complex integration contour but how exactly? Thanks. I want also to show that $Bi(x),Bi'(x)>0 \forall x>0$, and to conclude the asymptotic identities: $$Bi(x) \sim \pi^{-1/2}x^{-1/4}\exp(2/3 x^{3/2})$$ $$Bi'(x)\sim \pi^{-1/2}x^{1/4}\exp(2/3 x^{3/2})$$","I am trying to show that that the Airy functions defined below satisfy: $W[Ai(x),Bi(x)]=1/\pi$. $$Ai(x)=\frac{1}{\pi} \int_0^\infty \cos(t^3/3+xt)dt$$ $$Bi(x)=\frac{1}{\pi}\int_0^\infty \bigg[ \exp(-t^3/3+xt)+\sin(t^3/3+xt)\bigg]dt $$ I tried to compute it directly but I got stuck, here's the last term I got: $$Ai(x)Bi'(x)-Ai'(x)Bi(x) = \frac{1}{\pi^2}\bigg[ \int_0^\infty \cos(t^3/3+xt)dt \int_0^\infty \bigg( s\exp(-s^3/3+xs)+s\cos(s^3/3+xs)\bigg) ds + \int_0^\infty \sin(t^3/3+xt)tdt\int_0^\infty \bigg(\exp(-s^3/3+xs)+\sin(s^3/3+xs)\bigg)ds \bigg]$$ I don't see how to proceed from here, I guess I need complex integration contour but how exactly? Thanks. I want also to show that $Bi(x),Bi'(x)>0 \forall x>0$, and to conclude the asymptotic identities: $$Bi(x) \sim \pi^{-1/2}x^{-1/4}\exp(2/3 x^{3/2})$$ $$Bi'(x)\sim \pi^{-1/2}x^{1/4}\exp(2/3 x^{3/2})$$",,"['ordinary-differential-equations', 'special-functions', 'wronskian']"
21,Solve pde problem,Solve pde problem,,"For each of the following PDE. (a) solve the characteristic equation (b) define a transformation of the PDE. And obtain the transformed equation. (c) find the general solution of the transformed equation. $$xu_x-yu_y+u =x $$ Let $r=r(r,s) ,s=s (r,s) $ Char. eq. : $$\frac{dy}{dx}= \frac {-y}{x} $$ $$\frac{dy}{y}= \frac {-dx}{x} $$ $$lny =-lnx + c$$ $$s=c =lnx+lny=lnxy $$ let r=x $$u_x=u_r +\frac {u_s}{x}$$ $$u_y=0 +\frac {u_s}{y}$$ Substitute in eq.$(r=x,s=lnxy)$ $$ru_r+u_s -u_s+u =r $$ $$ru_r+u=r $$ First one homogeneous  eq $$u_r+\frac {u}{r}=0$$ $$M= exp ( \int (1/r))=r$$ $$ru_r+u=0$$ $$u = \frac {F (s)}{r}=\frac{F (lnxy) }{x}$$ How to find nonhomogenes  for this problem?  Thanks","For each of the following PDE. (a) solve the characteristic equation (b) define a transformation of the PDE. And obtain the transformed equation. (c) find the general solution of the transformed equation. $$xu_x-yu_y+u =x $$ Let $r=r(r,s) ,s=s (r,s) $ Char. eq. : $$\frac{dy}{dx}= \frac {-y}{x} $$ $$\frac{dy}{y}= \frac {-dx}{x} $$ $$lny =-lnx + c$$ $$s=c =lnx+lny=lnxy $$ let r=x $$u_x=u_r +\frac {u_s}{x}$$ $$u_y=0 +\frac {u_s}{y}$$ Substitute in eq.$(r=x,s=lnxy)$ $$ru_r+u_s -u_s+u =r $$ $$ru_r+u=r $$ First one homogeneous  eq $$u_r+\frac {u}{r}=0$$ $$M= exp ( \int (1/r))=r$$ $$ru_r+u=0$$ $$u = \frac {F (s)}{r}=\frac{F (lnxy) }{x}$$ How to find nonhomogenes  for this problem?  Thanks",,"['ordinary-differential-equations', 'partial-differential-equations', 'characteristics']"
22,Lyapunov Function for Nonlinear Systems,Lyapunov Function for Nonlinear Systems,,"Since there is no systematic method to find Lyapunov functions, how should I approach the question shown below to find corresponding Lyapunov function? With $\alpha<0$ $$\begin{align}  x_1'&=-3x_2\\     x_2'&=x_1-\alpha(2x_2^3-x_2)\\     \end{align}     $$","Since there is no systematic method to find Lyapunov functions, how should I approach the question shown below to find corresponding Lyapunov function? With $\alpha<0$ $$\begin{align}  x_1'&=-3x_2\\     x_2'&=x_1-\alpha(2x_2^3-x_2)\\     \end{align}     $$",,"['ordinary-differential-equations', 'control-theory', 'nonlinear-system', 'lyapunov-functions']"
23,Are multiple kinds of attractors (chaotic and otherwise) possible within a single system of differential equations?,Are multiple kinds of attractors (chaotic and otherwise) possible within a single system of differential equations?,,"I’m looking for any $n$-dimensional system of first order differential equations where depending on the initial conditions you can end up in a number of attractors, for example multiple chaotic orbits, fixed points, periodic etc. More specifically, I’m looking for a system that has two or more different chaotic attractors with optionally period orbits or fixed points. I have only ever seen one system that happened to be three-dimensional which had two chaotic attractors and they had the property of being identical – reflected across the origin. I can't remember what it was. One thing I’m currently exploring is random matrices, as they appear to have some peculiar properties (complex uniformly distributed eigenvectors). If you use them as a linkage/weighting matrix in a dynamical system, chaotic behavior is trivial to achieve, but I’m not certain that they have multiple distinct orbits.","I’m looking for any $n$-dimensional system of first order differential equations where depending on the initial conditions you can end up in a number of attractors, for example multiple chaotic orbits, fixed points, periodic etc. More specifically, I’m looking for a system that has two or more different chaotic attractors with optionally period orbits or fixed points. I have only ever seen one system that happened to be three-dimensional which had two chaotic attractors and they had the property of being identical – reflected across the origin. I can't remember what it was. One thing I’m currently exploring is random matrices, as they appear to have some peculiar properties (complex uniformly distributed eigenvectors). If you use them as a linkage/weighting matrix in a dynamical system, chaotic behavior is trivial to achieve, but I’m not certain that they have multiple distinct orbits.",,['ordinary-differential-equations']
24,Check of Laplace transform,Check of Laplace transform,,"This afternoon I solved a ODE with a Laplace transform. Now I want to check if the solution whether it is correct, but I cannot get to the solution. The ODE is: $$\ddot{x} +4x = f(t), x(t=0)=3, \dot{x}(t=0)=-1$$ As a solution I found:$$ {x(t) =3\cos(2t)-\frac 12\sin(2t)+  \frac 12\int_0^t f(\tau) \, \sin(2(t-\tau))d\tau}$$ The problem is: How do I check the last part (under the integral?","This afternoon I solved a ODE with a Laplace transform. Now I want to check if the solution whether it is correct, but I cannot get to the solution. The ODE is: $$\ddot{x} +4x = f(t), x(t=0)=3, \dot{x}(t=0)=-1$$ As a solution I found:$$ {x(t) =3\cos(2t)-\frac 12\sin(2t)+  \frac 12\int_0^t f(\tau) \, \sin(2(t-\tau))d\tau}$$ The problem is: How do I check the last part (under the integral?",,"['ordinary-differential-equations', 'laplace-transform']"
25,Solve the differential equation $t y''-y'+4t^3y=0$,Solve the differential equation,t y''-y'+4t^3y=0,Solve the differential equation $t y''-y'+4t^3y=0$  using method reduction where $y_1=\sin (t^2)$ my attempt: $y_2=vy_1=v\sin (t^2)$ $y_2'=v'\sin(t^2)+2t\cos(t^2)\\ y_2''=v''\sin (t^2)+4tv\cos(t^2)+2v\cos(t62)4t^2v\sin(t^2)$ Hence $t y_2''-y_2'+4t^3y_2=0\\ tv''\sin (t^2)+4t^2v\cos(t^2)+2vt\cos(t^2)+4t^3v\sin(t^2)-v'\sin(t^2)-2t\cos(t^2)-4t^3v\sin(t^2)=0\\ v''t\sin(t^2)+4t^2v'\cos(t^2)-v'\sin(t^2)=0$ how to proceed from here?,Solve the differential equation $t y''-y'+4t^3y=0$  using method reduction where $y_1=\sin (t^2)$ my attempt: $y_2=vy_1=v\sin (t^2)$ $y_2'=v'\sin(t^2)+2t\cos(t^2)\\ y_2''=v''\sin (t^2)+4tv\cos(t^2)+2v\cos(t62)4t^2v\sin(t^2)$ Hence $t y_2''-y_2'+4t^3y_2=0\\ tv''\sin (t^2)+4t^2v\cos(t^2)+2vt\cos(t^2)+4t^3v\sin(t^2)-v'\sin(t^2)-2t\cos(t^2)-4t^3v\sin(t^2)=0\\ v''t\sin(t^2)+4t^2v'\cos(t^2)-v'\sin(t^2)=0$ how to proceed from here?,,['ordinary-differential-equations']
26,Find the base of the kernel of $L(y)=x^2y''-3xy'+3y.$,Find the base of the kernel of,L(y)=x^2y''-3xy'+3y.,"Let $L:C^2(I)\rightarrow C(I), L(y)=x^2y''-3xy'+3y.$ Find the kernel of the linear transformation $L$. Can the solution of $L(y)=6$ be expressed in the form $y_H$+$y_L$, where $y_H$ is an arbitrary linear combination of the elements of ker L. What I have tried: Since ker L is subspace of $C^2(I)$ and dim $C^2(I)=2$, dim ker $L\leq 2$. Let $y(x)=x^r$. Then substituting gives $L(x^r)=x^rr^2-3rx^r+3x^r$, hence  $L(x^r)=0$ iff $x^rr^2-3rx^r+3x^r=0.$ $r$ can be solved using the quadratic formula. $$r=\frac{3+i\sqrt3}{2} \vee  r=\frac{3-i\sqrt3}{2}$$ $$y_1(x)=x^\frac{3+i\sqrt3}{2}, y_1(x)=x^\frac{3-i\sqrt3}{2} $$which are linearly independent(?). How would one show that $y_1$ and $y_2$ are LI ?","Let $L:C^2(I)\rightarrow C(I), L(y)=x^2y''-3xy'+3y.$ Find the kernel of the linear transformation $L$. Can the solution of $L(y)=6$ be expressed in the form $y_H$+$y_L$, where $y_H$ is an arbitrary linear combination of the elements of ker L. What I have tried: Since ker L is subspace of $C^2(I)$ and dim $C^2(I)=2$, dim ker $L\leq 2$. Let $y(x)=x^r$. Then substituting gives $L(x^r)=x^rr^2-3rx^r+3x^r$, hence  $L(x^r)=0$ iff $x^rr^2-3rx^r+3x^r=0.$ $r$ can be solved using the quadratic formula. $$r=\frac{3+i\sqrt3}{2} \vee  r=\frac{3-i\sqrt3}{2}$$ $$y_1(x)=x^\frac{3+i\sqrt3}{2}, y_1(x)=x^\frac{3-i\sqrt3}{2} $$which are linearly independent(?). How would one show that $y_1$ and $y_2$ are LI ?",,"['linear-algebra', 'ordinary-differential-equations']"
27,Are these functions linearly dependent?,Are these functions linearly dependent?,,"The Wronskian of two functions is $W(t) = t^2 - 4$. Are these functions linearly dependent? I don't think they are, since the Wronskian is only equal to zero when $t = 2$ or $t = -2$. I'm not sure though, since the Wronskian has thus far only been used in my class for functions of which we know they're solutions to a differential equation. Question: Can you conclude that these functions are linearly independent because their Wronskian is only equal to zero at a couple of points?","The Wronskian of two functions is $W(t) = t^2 - 4$. Are these functions linearly dependent? I don't think they are, since the Wronskian is only equal to zero when $t = 2$ or $t = -2$. I'm not sure though, since the Wronskian has thus far only been used in my class for functions of which we know they're solutions to a differential equation. Question: Can you conclude that these functions are linearly independent because their Wronskian is only equal to zero at a couple of points?",,"['linear-algebra', 'ordinary-differential-equations']"
28,Solve the Initial Value Problem and Plot the Particular Solution with the direction field (MAPLE),Solve the Initial Value Problem and Plot the Particular Solution with the direction field (MAPLE),,"I am fairly new at MAPLE and I'm having some trouble solving this ODE. $$(t+1)\frac{dy}{dt}-2(t^2+t)y=\frac{e^{t^2}}{t+1}$$ My initial value problem is $$t>-1, y(0)=5$$ I put the equation in standard form and typed into maple However I am aware that when my initial value is $y(0)=5$ my equation becomes $4=0$ which is not possible. So I am confused on whether or not it is possible to find a general solution.","I am fairly new at MAPLE and I'm having some trouble solving this ODE. $$(t+1)\frac{dy}{dt}-2(t^2+t)y=\frac{e^{t^2}}{t+1}$$ My initial value problem is $$t>-1, y(0)=5$$ I put the equation in standard form and typed into maple However I am aware that when my initial value is $y(0)=5$ my equation becomes $4=0$ which is not possible. So I am confused on whether or not it is possible to find a general solution.",,"['ordinary-differential-equations', 'maple']"
29,Reduction of second order differential equation $u''=2u^3$,Reduction of second order differential equation,u''=2u^3,"Given the differential equation $u''=2u^3$, what method of reduction can I use to make it easier to solve? The reduction order method requires a solution to be known and I am unsure on where to go from here.","Given the differential equation $u''=2u^3$, what method of reduction can I use to make it easier to solve? The reduction order method requires a solution to be known and I am unsure on where to go from here.",,"['ordinary-differential-equations', 'derivatives']"
30,Stability types in a homogeneous linear system,Stability types in a homogeneous linear system,,I would like to calculate the range of values for which x * (fixed point) = 0 and I want to investigate the type of stability. $$ \frac{d}{du} \begin{bmatrix}x\\y\end{bmatrix} =  \begin{bmatrix}-5&a\\2&1\end{bmatrix} \begin{bmatrix}x\\y\end{bmatrix}$$ I have already satisfied the cases for node and saddle. I want to find the solution for a focus: From my understanding: Focus = eigenvalues which are complex conjugate numbers with a positive real part. In my solution I have obtained that the eigenvalues are: $-2 \pm \sqrt{9+2a}$ However I am unsure of how to satisfy the values for which the stability point is a focus. Any help would be welcome.,I would like to calculate the range of values for which x * (fixed point) = 0 and I want to investigate the type of stability. $$ \frac{d}{du} \begin{bmatrix}x\\y\end{bmatrix} =  \begin{bmatrix}-5&a\\2&1\end{bmatrix} \begin{bmatrix}x\\y\end{bmatrix}$$ I have already satisfied the cases for node and saddle. I want to find the solution for a focus: From my understanding: Focus = eigenvalues which are complex conjugate numbers with a positive real part. In my solution I have obtained that the eigenvalues are: $-2 \pm \sqrt{9+2a}$ However I am unsure of how to satisfy the values for which the stability point is a focus. Any help would be welcome.,,"['calculus', 'matrices', 'ordinary-differential-equations', 'multivariable-calculus', 'dynamical-systems']"
31,"First order non linear differential equation , non separable","First order non linear differential equation , non separable",,"First time I run into an equation of this ""form"", for non linear equations I know separation of variables and substitution. It doesn't seem to be homogenous of degree $0$ so the substitution $v=\frac{x}{t}$ is out of the question? Applying $\ln$ to both sides didn't do much either $$x'(t)=e^{t+x(t)}-1,\quad x(0)=1$$ Wolfram gives the solution $$x(t)=-\ln(c_1-t)-t$$","First time I run into an equation of this ""form"", for non linear equations I know separation of variables and substitution. It doesn't seem to be homogenous of degree $0$ so the substitution $v=\frac{x}{t}$ is out of the question? Applying $\ln$ to both sides didn't do much either $$x'(t)=e^{t+x(t)}-1,\quad x(0)=1$$ Wolfram gives the solution $$x(t)=-\ln(c_1-t)-t$$",,[]
32,Why a n-th order linear homogeneous ODE has exactly n linearly independent solutions?,Why a n-th order linear homogeneous ODE has exactly n linearly independent solutions?,,After some research I cannot find an answer that satisfies me for the question above. I know about the Cauchy criterion but I don't think that it proves the fact that there are exactly n linearly independent solutions to an n-th order linear homogeneous ODE. Is it a dimension problem ? (like maybe we could construct an isomorphism from the ODE to Rn prove that ?),After some research I cannot find an answer that satisfies me for the question above. I know about the Cauchy criterion but I don't think that it proves the fact that there are exactly n linearly independent solutions to an n-th order linear homogeneous ODE. Is it a dimension problem ? (like maybe we could construct an isomorphism from the ODE to Rn prove that ?),,"['linear-algebra', 'ordinary-differential-equations']"
33,Exceptional solutions to ODE,Exceptional solutions to ODE,,"I'm trying to find the general solution for $y'=2(1-y^2)$ such that it also contains the solutions $y=\pm1$. I managed to arrive at $$\frac{\ln|y+1|-\ln|y-1|}{2}=2x+C$$ which gives $$\frac{y+1}{y-1}=Ae^{4x}$$ which further gives $$\frac{2}{y-1}=Ae^{4x}-1$$ so $$y=\frac{2}{Ae^{4x}-1}+1$$.  Now, what I'm unsure about is how to check if this solution satisfies the exceptional solutions since the derivative is an expression containing only the variable $x$ and I'm trying to check if $y=\pm1$ satisfies the ODE. I'm also not sure how I would modify the solution so that it also contains the exceptional solutions.","I'm trying to find the general solution for $y'=2(1-y^2)$ such that it also contains the solutions $y=\pm1$. I managed to arrive at $$\frac{\ln|y+1|-\ln|y-1|}{2}=2x+C$$ which gives $$\frac{y+1}{y-1}=Ae^{4x}$$ which further gives $$\frac{2}{y-1}=Ae^{4x}-1$$ so $$y=\frac{2}{Ae^{4x}-1}+1$$.  Now, what I'm unsure about is how to check if this solution satisfies the exceptional solutions since the derivative is an expression containing only the variable $x$ and I'm trying to check if $y=\pm1$ satisfies the ODE. I'm also not sure how I would modify the solution so that it also contains the exceptional solutions.",,"['calculus', 'ordinary-differential-equations']"
34,First order ordinary differential equation about fish populations in a lake.,First order ordinary differential equation about fish populations in a lake.,,"I have this question which has me stumped, here's the problem. A lake is stocked with a fish population of size $ N(t)$ at time t. Initially the population is $N(0) = N_0$ the evolution of he population is given by this ODE:$$ \frac{dN}{dt}=\frac{aN}{b}(b-N)$$ Where a and b are both positive constants. a) find N(t) b) what is the behavior of N(t) and t tend to infinity So the way the question is set up makes me think its somehow separable here's what i've tried Rearranging this gets me: $$\int \frac{1}{N(b-N)}dN=\int \frac{a}{b}dt$$ Partial fractions on LHS give: $$\int \frac{1}{b(b-N)}+\frac{1}{bN} dN=\int \frac{a}{b}dt$$ evaluating the integrals and simplifying: $$\frac{1}{b}ln(\frac{N}{b-N})=\frac{a}{b}t+C$$ some more fiddling: $$\frac{N}{b-N}=Ae^{at}$$ where A is a postive constant. So i can mess around further getting this sort of thing $N(t)=\large{\frac{Abe^{at}}{1-Ae^{at}}}$ (thanks to martin for picking up the sign error that should be $N(t)=\large{\frac{Abe^{at}}{1+Ae^{at}}}$)thing i'm missing. I've tried subbing in the initial conditions but it really doesn't help i get something no nice looking for my constant A as a result. hopefully you guys can see it. thanks for the help.","I have this question which has me stumped, here's the problem. A lake is stocked with a fish population of size $ N(t)$ at time t. Initially the population is $N(0) = N_0$ the evolution of he population is given by this ODE:$$ \frac{dN}{dt}=\frac{aN}{b}(b-N)$$ Where a and b are both positive constants. a) find N(t) b) what is the behavior of N(t) and t tend to infinity So the way the question is set up makes me think its somehow separable here's what i've tried Rearranging this gets me: $$\int \frac{1}{N(b-N)}dN=\int \frac{a}{b}dt$$ Partial fractions on LHS give: $$\int \frac{1}{b(b-N)}+\frac{1}{bN} dN=\int \frac{a}{b}dt$$ evaluating the integrals and simplifying: $$\frac{1}{b}ln(\frac{N}{b-N})=\frac{a}{b}t+C$$ some more fiddling: $$\frac{N}{b-N}=Ae^{at}$$ where A is a postive constant. So i can mess around further getting this sort of thing $N(t)=\large{\frac{Abe^{at}}{1-Ae^{at}}}$ (thanks to martin for picking up the sign error that should be $N(t)=\large{\frac{Abe^{at}}{1+Ae^{at}}}$)thing i'm missing. I've tried subbing in the initial conditions but it really doesn't help i get something no nice looking for my constant A as a result. hopefully you guys can see it. thanks for the help.",,['ordinary-differential-equations']
35,Solving non-homogeneous linear second-order differential equation with repeated roots,Solving non-homogeneous linear second-order differential equation with repeated roots,,"I have the following second-order linear differential equation that I am unable to solve: $y''+4y'+4y=t$. The method for solving homogeneous linear second-order differential equations obviously doesn't work, but I am unsure how to apply the technique to solve non-homogenous linear second-order differential equations because this equation has repeated roots. Is there a particular method I should be applying?","I have the following second-order linear differential equation that I am unable to solve: $y''+4y'+4y=t$. The method for solving homogeneous linear second-order differential equations obviously doesn't work, but I am unsure how to apply the technique to solve non-homogenous linear second-order differential equations because this equation has repeated roots. Is there a particular method I should be applying?",,['ordinary-differential-equations']
36,How to solve $y'+xy = y^4$?,How to solve ?,y'+xy = y^4,"I want to solve the following differential equation: $$ y' + xy = y^4,\ \ \ \ y(0)=1.$$ I don't know if this is a bernoulli equation, or a homogenous equation, but when I attempted it as a bernoulli equation, I got stuck. I ended up with: $$e^{\frac{-3x^{2}}{2}}v = -3\int e^{\frac{-3x^{2}}{2}}dx$$ But the book says answers does not need to be in closed form, but we have an initial condition..","I want to solve the following differential equation: $$ y' + xy = y^4,\ \ \ \ y(0)=1.$$ I don't know if this is a bernoulli equation, or a homogenous equation, but when I attempted it as a bernoulli equation, I got stuck. I ended up with: $$e^{\frac{-3x^{2}}{2}}v = -3\int e^{\frac{-3x^{2}}{2}}dx$$ But the book says answers does not need to be in closed form, but we have an initial condition..",,['ordinary-differential-equations']
37,Prove that if $f(a)=f(b)=0$ with $f'$ differentiable then for any $c$ there is $x_0$ st. $f'(x_0)=cf(x_0)$.,Prove that if  with  differentiable then for any  there is  st. .,f(a)=f(b)=0 f' c x_0 f'(x_0)=cf(x_0),"Assume $f:[a,b] \to \mathbb R$ is continuous on the closed interval $[a,b]$ and differentiable on $(a,b)$ with $f(a)=f(b)=0$. Prove that for every $c \in \mathbb R$ there exists $x_0 \in (a,b)$ such that $f'(x_0)= cf(x_0)$. Here is my work so far: Assume the case is true for $c = 1$. Then for any other $c$ let $g(x):=f(cx)$. Then since the case holds for $c=1$ there exists $x_0 \in [a/c, b/c]$ such that $f'(cx_0)=1/c f(cx_0)$. My inteuctor said that, while my effort for reducion does not exactly work (since we have to check that our motified value lies ina proper interval and check other things), I can make some similar argument to reduce the case to $c=1$. Some people suggested that I take a look at the logarithmic and exponential functions, but I am not sure how that would lead me anywhere.","Assume $f:[a,b] \to \mathbb R$ is continuous on the closed interval $[a,b]$ and differentiable on $(a,b)$ with $f(a)=f(b)=0$. Prove that for every $c \in \mathbb R$ there exists $x_0 \in (a,b)$ such that $f'(x_0)= cf(x_0)$. Here is my work so far: Assume the case is true for $c = 1$. Then for any other $c$ let $g(x):=f(cx)$. Then since the case holds for $c=1$ there exists $x_0 \in [a/c, b/c]$ such that $f'(cx_0)=1/c f(cx_0)$. My inteuctor said that, while my effort for reducion does not exactly work (since we have to check that our motified value lies ina proper interval and check other things), I can make some similar argument to reduce the case to $c=1$. Some people suggested that I take a look at the logarithmic and exponential functions, but I am not sure how that would lead me anywhere.",,['ordinary-differential-equations']
38,Formula to find a particular solution of a specific linear ODE,Formula to find a particular solution of a specific linear ODE,,"I'm currently following the book ""Differential Equations with Applications and Historical Notes"" by George F.Simmons. When he goes on to talk about particular solutions of linear ODEs and how to find them, one of the methods he proposes as a last resort is ""Variation of parameters"". One of the problems related to that method states the following: Prove that the method of variation of parameters applied to the equation $y''+y=f(x)$ leads to the particular solution:   $$ y_p(x)=\int_{0}^x f(t)\sin(x-t)dt  \tag{1} $$ This is what I've tried to do. I start from the fact that $$ y_p(x)=y_1v_1 + y_2v_2 \tag{2}$$ Where $y_1$ and $y_2$ are solutions to the homogeneous ODE, while $v_1$ and $v_2$ are functions of $x$ to be determined by the following formulas: $$v_1 = \int \frac{-y_2f(x)}{W(y_1,y_2)}dx \tag{3}$$ $$v_2 = \int \frac{y_1f(x)}{W(y_1,y_2)}dx \tag{4}$$ $W(y_1,y_2)$ is the wronskian. In my case I've chosen $y_1=\sin(x)$ and $y_2=\cos(x)$, so that $W(y_1,y_2)=-1$. Using (3) and (4), and substituting into (2), I get: $$ y_p(x)=\sin(x) \int \cos(x)f(x)dx\ - \cos(x)\int \sin(x)f(x) dx \ \ $$ But I can't find a way to get to (1). I've tried integration by parts. Also, I'm not familiar with the concept of convolution yet.","I'm currently following the book ""Differential Equations with Applications and Historical Notes"" by George F.Simmons. When he goes on to talk about particular solutions of linear ODEs and how to find them, one of the methods he proposes as a last resort is ""Variation of parameters"". One of the problems related to that method states the following: Prove that the method of variation of parameters applied to the equation $y''+y=f(x)$ leads to the particular solution:   $$ y_p(x)=\int_{0}^x f(t)\sin(x-t)dt  \tag{1} $$ This is what I've tried to do. I start from the fact that $$ y_p(x)=y_1v_1 + y_2v_2 \tag{2}$$ Where $y_1$ and $y_2$ are solutions to the homogeneous ODE, while $v_1$ and $v_2$ are functions of $x$ to be determined by the following formulas: $$v_1 = \int \frac{-y_2f(x)}{W(y_1,y_2)}dx \tag{3}$$ $$v_2 = \int \frac{y_1f(x)}{W(y_1,y_2)}dx \tag{4}$$ $W(y_1,y_2)$ is the wronskian. In my case I've chosen $y_1=\sin(x)$ and $y_2=\cos(x)$, so that $W(y_1,y_2)=-1$. Using (3) and (4), and substituting into (2), I get: $$ y_p(x)=\sin(x) \int \cos(x)f(x)dx\ - \cos(x)\int \sin(x)f(x) dx \ \ $$ But I can't find a way to get to (1). I've tried integration by parts. Also, I'm not familiar with the concept of convolution yet.",,"['integration', 'ordinary-differential-equations']"
39,Solve the initial value problem: ODE with discontinuous coefficients?,Solve the initial value problem: ODE with discontinuous coefficients?,,"Solve the initial value problem   $$ y'-y = \left\lbrace \begin{aligned} &1 & & \text{when}\quad 0<t<1 \\ &0 & & \text{when}\quad t>1 \end{aligned} \right. ,\qquad y(0)=0 \, . $$ So I understand that $p(t)=-1$ and $g(t)$ is $1$ and $0$ (depending on the $t$ value), and that I'm supposed to solve it as two separate DEs. I got for the first case that $y=-1$ and for the second case that $y=0$. Is this correct? Is this the solution? Or do I have to do something with the initial value $y(0)=0$? Any help is appreciated !!","Solve the initial value problem   $$ y'-y = \left\lbrace \begin{aligned} &1 & & \text{when}\quad 0<t<1 \\ &0 & & \text{when}\quad t>1 \end{aligned} \right. ,\qquad y(0)=0 \, . $$ So I understand that $p(t)=-1$ and $g(t)$ is $1$ and $0$ (depending on the $t$ value), and that I'm supposed to solve it as two separate DEs. I got for the first case that $y=-1$ and for the second case that $y=0$. Is this correct? Is this the solution? Or do I have to do something with the initial value $y(0)=0$? Any help is appreciated !!",,"['ordinary-differential-equations', 'initial-value-problems']"
40,Closed-form solution to $y''=-1/y^2$?,Closed-form solution to ?,y''=-1/y^2,"Consider the differential equation $$y''=-c/y^2,$$ describing the motion of a ball you throw straight up in the air, high enough that you can't assume the force of gravity is constant. We certainly can't solve it by any method we cover in class, nor by any method I know. I like to show how we can derive conservation of energy and hence escape velocity from the DE even though we can't solve it. But Question: Can anyone state definitively that there is in fact no closed-form solution? (For general initial conditions...) Edit: Thanks to various comments, I realize I was being a little dumb - I had conservation of energy, which, as I should have realized years ago, is actually a separable first-order equation, leading at least to implicit solutions: It's easy to see that $$\left(\frac12(y')^2-\frac cy\right)'=0,$$so $$\frac12(y')^2-\frac cy=k,$$which is separable. (You end up with an integral that's basically $$\int\frac{dy}{(1+1/y)^{1/2}},$$with a few irrelevant constants. The idiot-freshman substitution $u=(1+1/y)^{1/2}$ converts that to the integral of a rational function...)","Consider the differential equation $$y''=-c/y^2,$$ describing the motion of a ball you throw straight up in the air, high enough that you can't assume the force of gravity is constant. We certainly can't solve it by any method we cover in class, nor by any method I know. I like to show how we can derive conservation of energy and hence escape velocity from the DE even though we can't solve it. But Question: Can anyone state definitively that there is in fact no closed-form solution? (For general initial conditions...) Edit: Thanks to various comments, I realize I was being a little dumb - I had conservation of energy, which, as I should have realized years ago, is actually a separable first-order equation, leading at least to implicit solutions: It's easy to see that $$\left(\frac12(y')^2-\frac cy\right)'=0,$$so $$\frac12(y')^2-\frac cy=k,$$which is separable. (You end up with an integral that's basically $$\int\frac{dy}{(1+1/y)^{1/2}},$$with a few irrelevant constants. The idiot-freshman substitution $u=(1+1/y)^{1/2}$ converts that to the integral of a rational function...)",,['ordinary-differential-equations']
41,"Differential Equation : $\frac{dy}{dx} +\int_0^5{y\,dx}=27$",Differential Equation :,"\frac{dy}{dx} +\int_0^5{y\,dx}=27","Given $y=f(x)$ , is twice differentiable, passes through the origin and satisfies the equation, $$\frac{dy}{dx} +\int_0^5{y\,dx}=27$$What is the probability that $2$ randomly chosen variables $a$, $b$ from the set $S=\{1,2,3,4\}$ lies on the curve as $(a,b)$? My Attempt: As $\int_0^5{y\,dx}$ is a constant. $$\frac{d^2y}{dx^2}=0$$ Therefore, $y=ax+b$, As curve passes through the origin, $b=0$, so $y=ax$. On putting this in the equation, we get $a=2$. Therefore, $$y=2x.$$ Is my approach right? And also how else can we attempt this question?","Given $y=f(x)$ , is twice differentiable, passes through the origin and satisfies the equation, $$\frac{dy}{dx} +\int_0^5{y\,dx}=27$$What is the probability that $2$ randomly chosen variables $a$, $b$ from the set $S=\{1,2,3,4\}$ lies on the curve as $(a,b)$? My Attempt: As $\int_0^5{y\,dx}$ is a constant. $$\frac{d^2y}{dx^2}=0$$ Therefore, $y=ax+b$, As curve passes through the origin, $b=0$, so $y=ax$. On putting this in the equation, we get $a=2$. Therefore, $$y=2x.$$ Is my approach right? And also how else can we attempt this question?",,"['probability', 'integration', 'ordinary-differential-equations']"
42,"Let $\dot{x}=\arctan(x(t)\cdot t)$, $x(t_0)=x_0$ be an IVP. Prove that if $x_0<0$, then $x(t)<0$ for all $\mathbb{R}$","Let ,  be an IVP. Prove that if , then  for all",\dot{x}=\arctan(x(t)\cdot t) x(t_0)=x_0 x_0<0 x(t)<0 \mathbb{R},"This is a statement of a problem with $4$ sections. I've solved the other ones, but this I couldn't solve it: Let $\dot{x}=\arctan(x(t)\cdot t)$, $x(t_0)=x_0$ be an IVP. Prove that if $x_0<0$, then $x(t)<0$ for all $\mathbb{R}$. Can we say something about the solution without actually having it? How can I say how's the solution if I can't find it?","This is a statement of a problem with $4$ sections. I've solved the other ones, but this I couldn't solve it: Let $\dot{x}=\arctan(x(t)\cdot t)$, $x(t_0)=x_0$ be an IVP. Prove that if $x_0<0$, then $x(t)<0$ for all $\mathbb{R}$. Can we say something about the solution without actually having it? How can I say how's the solution if I can't find it?",,"['ordinary-differential-equations', 'initial-value-problems']"
43,Is a system of ODEs solvable if the coefficient matrix has determinant zero?,Is a system of ODEs solvable if the coefficient matrix has determinant zero?,,"Pardon the simple question, but my memory's failing me on this, and I can't seem to find any answers. I have a system of differential equations, with a coefficient matrix that looks like this, where a, b, and c are constants: \begin{bmatrix}  0& 1& 0& 0& 0& 0\\   0& 0&-a& 0& b& 0\\   0& a& 0& 0& 0& c\\   0& 0& 0& 0& 0& 0\\   0& 0& 0&-1& 0&-a\\   0& 0& 0& 0& a& 0 \end{bmatrix} Now, it's pretty obvious to see that the coefficient matrix has a zero determinant (expand over the first column).  Does this mean that the system is unsolvable?  If so, what can I do to make it solvable?","Pardon the simple question, but my memory's failing me on this, and I can't seem to find any answers. I have a system of differential equations, with a coefficient matrix that looks like this, where a, b, and c are constants: \begin{bmatrix}  0& 1& 0& 0& 0& 0\\   0& 0&-a& 0& b& 0\\   0& a& 0& 0& 0& c\\   0& 0& 0& 0& 0& 0\\   0& 0& 0&-1& 0&-a\\   0& 0& 0& 0& a& 0 \end{bmatrix} Now, it's pretty obvious to see that the coefficient matrix has a zero determinant (expand over the first column).  Does this mean that the system is unsolvable?  If so, what can I do to make it solvable?",,"['matrices', 'ordinary-differential-equations', 'systems-of-equations']"
44,Why does my textbook give this solution of $\cos^{-1}$ when it should be $\sin^{-1}$?,Why does my textbook give this solution of  when it should be ?,\cos^{-1} \sin^{-1},"In my textbook we are trying to solve this separation of variables equation: $$\int {dz\over \sqrt{B^2-z^2}} = \int d\theta$$ Without any explanation the solution is: $$\cos^{-1}\Big( {z\over B} \Big)=\theta-\theta_0$$ But shouldn't it be $\sin^{-1}?$ All of this is going towards trying to find the equation for gravitational potential, the rest of the work I understand but this part is confusing to me. I know that $\cos^{-1}={\pi\over 2}-\sin^{-1}$, but I don't see how they applied it here. Seeing as this is a physics textbook and not a math one I'm not surprised they don't give any explanation, but even Wolfram gives me a different answer which uses $\tan^{-1}$. Is this the right answer? If so, how did the authors get it? Edit: The book does give a value for $B$: $$\Big( {mE\over L^2} \Big){\sqrt{1-{{2\beta L^2\over mE^2}}}} $$ So according to the book $B$ is not negative or an absolute value. Using this information makes it hard for me to find a way to make the integral negative so I can use $\cos^{-1}$","In my textbook we are trying to solve this separation of variables equation: $$\int {dz\over \sqrt{B^2-z^2}} = \int d\theta$$ Without any explanation the solution is: $$\cos^{-1}\Big( {z\over B} \Big)=\theta-\theta_0$$ But shouldn't it be $\sin^{-1}?$ All of this is going towards trying to find the equation for gravitational potential, the rest of the work I understand but this part is confusing to me. I know that $\cos^{-1}={\pi\over 2}-\sin^{-1}$, but I don't see how they applied it here. Seeing as this is a physics textbook and not a math one I'm not surprised they don't give any explanation, but even Wolfram gives me a different answer which uses $\tan^{-1}$. Is this the right answer? If so, how did the authors get it? Edit: The book does give a value for $B$: $$\Big( {mE\over L^2} \Big){\sqrt{1-{{2\beta L^2\over mE^2}}}} $$ So according to the book $B$ is not negative or an absolute value. Using this information makes it hard for me to find a way to make the integral negative so I can use $\cos^{-1}$",,"['calculus', 'ordinary-differential-equations', 'multivariable-calculus']"
45,Solve the Second Order Nonhomogeneous ODE [closed],Solve the Second Order Nonhomogeneous ODE [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question I'm stuck on this problem since I can't find any material in my textbook or internet to solve this. Any help? $$2x^2 \cdot y'' - x \cdot y' + y = x$$ $$y'' - \frac{y'}{2x} + \frac{y}{2x^2} = \frac{1}{2x}$$","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question I'm stuck on this problem since I can't find any material in my textbook or internet to solve this. Any help? $$2x^2 \cdot y'' - x \cdot y' + y = x$$ $$y'' - \frac{y'}{2x} + \frac{y}{2x^2} = \frac{1}{2x}$$",,['ordinary-differential-equations']
46,Reference - basic ODE global uniqueness theorem,Reference - basic ODE global uniqueness theorem,,"Unless I am very badly mistaken it should hold that any solution $f:[0,\infty)\to \mathbb{R}^n$ ($n \in \mathbb{N}$) of the equation $$f'(t)=g(f(t)) \quad \quad (t\in [0, \infty))$$ with a given initial condition $$f(0)=x_0$$ is unique (globally on all of $[0,\infty)$) provided that $g$ is a globally Lipschitz continuous function. However, I don't have an access to a library at the moment and surprisingly I had trouble finding a reference on Google even though it is a fairly basic result. I guess you can get the global uniqueness from the Picard-Lindelöf Theorem which gives me an interval on which the solution is unique whose length should only depend on the Lipschitz constant so I could then glue the unique solutions together to show global uniqueness...But I'd rather use a simple reference to the result I cite above. Thanks for links to any references (preferably those that can be accessed online but inaccessible books are also OK, I can access a physical library, just not every day).","Unless I am very badly mistaken it should hold that any solution $f:[0,\infty)\to \mathbb{R}^n$ ($n \in \mathbb{N}$) of the equation $$f'(t)=g(f(t)) \quad \quad (t\in [0, \infty))$$ with a given initial condition $$f(0)=x_0$$ is unique (globally on all of $[0,\infty)$) provided that $g$ is a globally Lipschitz continuous function. However, I don't have an access to a library at the moment and surprisingly I had trouble finding a reference on Google even though it is a fairly basic result. I guess you can get the global uniqueness from the Picard-Lindelöf Theorem which gives me an interval on which the solution is unique whose length should only depend on the Lipschitz constant so I could then glue the unique solutions together to show global uniqueness...But I'd rather use a simple reference to the result I cite above. Thanks for links to any references (preferably those that can be accessed online but inaccessible books are also OK, I can access a physical library, just not every day).",,"['ordinary-differential-equations', 'lipschitz-functions']"
47,Fourier series formula proof,Fourier series formula proof,,"Is there any proof for this formula? $$f(x)=a_{0}+\sum_{n=1}^{\infty} \Big[a_{n}\cos\Big(\frac{n \pi x}{L}\Big)+b_{n}\sin\Big(\frac{n\pi x}{L}\Big)\Big]$$ It seems no matter how hard I look, this is just a given in any papers on the Fourier series. Can anyone direct me to a proof of this formula or show how it is derived please. Thank you.","Is there any proof for this formula? $$f(x)=a_{0}+\sum_{n=1}^{\infty} \Big[a_{n}\cos\Big(\frac{n \pi x}{L}\Big)+b_{n}\sin\Big(\frac{n\pi x}{L}\Big)\Big]$$ It seems no matter how hard I look, this is just a given in any papers on the Fourier series. Can anyone direct me to a proof of this formula or show how it is derived please. Thank you.",,"['ordinary-differential-equations', 'partial-differential-equations', 'fourier-analysis', 'fourier-series', 'fourier-transform']"
48,What's this equation?,What's this equation?,,"first post here. I'm an economist and I'm a bit rusty with my math. Would someone help out? I've done my homework and searched but couldn't find answers. Question: what is this equation for? $$\frac{\Delta y_{t}}{y_{t}}=s_{t}\frac{\Delta k_{t}}{k_{t}}+\Delta s_{t}\left(\log k_{t}+\frac{\Delta B(s_{t})}{B(s_{t})}\right)$$ sorry for my notations. $\Delta x/x$ is a growth rate over time, $s_{t}\in[0,1]$ is some parameter that varies over time and $B(s_{t})$ is some polynomial in $s_{t}$. clearly the first part relates the growth rate of $y_{t}$ to the growth rate of $k_{t}$ in a linear way with (time-varying) slope $s_{t}$. But I don't want to dismiss the rest of the equation as noise. I suspect some kind of circular movement or oscillations . But I may be wrong. What would a plot look like? Any help is appreciated!!!","first post here. I'm an economist and I'm a bit rusty with my math. Would someone help out? I've done my homework and searched but couldn't find answers. Question: what is this equation for? $$\frac{\Delta y_{t}}{y_{t}}=s_{t}\frac{\Delta k_{t}}{k_{t}}+\Delta s_{t}\left(\log k_{t}+\frac{\Delta B(s_{t})}{B(s_{t})}\right)$$ sorry for my notations. $\Delta x/x$ is a growth rate over time, $s_{t}\in[0,1]$ is some parameter that varies over time and $B(s_{t})$ is some polynomial in $s_{t}$. clearly the first part relates the growth rate of $y_{t}$ to the growth rate of $k_{t}$ in a linear way with (time-varying) slope $s_{t}$. But I don't want to dismiss the rest of the equation as noise. I suspect some kind of circular movement or oscillations . But I may be wrong. What would a plot look like? Any help is appreciated!!!",,"['ordinary-differential-equations', 'graphing-functions']"
49,Can $\mathrm{tan}$ be defined by an IVP with rational functions as coefficients?,Can  be defined by an IVP with rational functions as coefficients?,\mathrm{tan},"We can define $\sin$ and $\cos$ as the solutions to the DE $$f''(x) = -f(x)$$ subject to certain initial conditions. The above DE has constant coefficients, but I'd like to use a similar approach to defining $\tan$, and I'm happy generalize to rational functions, for example $$f''(x) = x^3 f'(x) -\frac{3x}{1-x^2} f(x)$$ would be a valid candidate. Anyway: Question. Can $\mathrm{tan}$ be defined by an IVP with rational functions as coefficients? Note that $$f'(x) = \frac{1}{1+x^2}$$ is solved by $f(x) = \mathrm{arctan}(x),$ so that's a near miss.","We can define $\sin$ and $\cos$ as the solutions to the DE $$f''(x) = -f(x)$$ subject to certain initial conditions. The above DE has constant coefficients, but I'd like to use a similar approach to defining $\tan$, and I'm happy generalize to rational functions, for example $$f''(x) = x^3 f'(x) -\frac{3x}{1-x^2} f(x)$$ would be a valid candidate. Anyway: Question. Can $\mathrm{tan}$ be defined by an IVP with rational functions as coefficients? Note that $$f'(x) = \frac{1}{1+x^2}$$ is solved by $f(x) = \mathrm{arctan}(x),$ so that's a near miss.",,"['real-analysis', 'ordinary-differential-equations', 'trigonometry', 'definition']"
50,"Non linear first order ODE, not exact and not separable","Non linear first order ODE, not exact and not separable",,"I am trying to solve the following differential equation $$tx'(t)=x(t)\left(\ln(x(t))-\ln(t)\right)$$  and I have hit a brick wall. I tried separating but no luck. The equation is not exact $$\int t dx=tx+C$$ and $$\int -(\ln x-\ln t) dt = -t\ln x-t+t\ln t+C$$ The only way I know to solve non linear first order ODEs is Bernoulli but this clearly isn't. What other methods are there for solving non linear first order Equations? P.S. this is not homework, I am self learning for exams. Second p.s. the solution is $$x(t)=te^{ct+1}$$","I am trying to solve the following differential equation $$tx'(t)=x(t)\left(\ln(x(t))-\ln(t)\right)$$  and I have hit a brick wall. I tried separating but no luck. The equation is not exact $$\int t dx=tx+C$$ and $$\int -(\ln x-\ln t) dt = -t\ln x-t+t\ln t+C$$ The only way I know to solve non linear first order ODEs is Bernoulli but this clearly isn't. What other methods are there for solving non linear first order Equations? P.S. this is not homework, I am self learning for exams. Second p.s. the solution is $$x(t)=te^{ct+1}$$",,[]
51,Solve $y'(t)=\operatorname{sin}(t)+\int_0^t y(x)\operatorname{cos}(t-x)dx$ by Laplace transform,Solve  by Laplace transform,y'(t)=\operatorname{sin}(t)+\int_0^t y(x)\operatorname{cos}(t-x)dx,"Question: Solve $y'(t)=\operatorname{sin}(t)+\int_0^t y(x)\operatorname{cos}(t-x)dx$ such that $y(0)=0$ My try: I applied Laplace transform on both sides of the equation. $ sL\{y(t)\} = \frac{1}{s^2+1}+L\{cos(t)*y(t)\} \implies sL\{y(t)\}=\frac{1}{s^2+1}+L\{cos(t)\}\times L\{y(t)\} $ $\implies L\{y(t)\} = \frac{s^2-1}{(s^3-s-1)(s^2+1)} $ (*) Now, I'm stuck on applying the inverse Laplace transform on (*) to find $y(t)$. Any idea?","Question: Solve $y'(t)=\operatorname{sin}(t)+\int_0^t y(x)\operatorname{cos}(t-x)dx$ such that $y(0)=0$ My try: I applied Laplace transform on both sides of the equation. $ sL\{y(t)\} = \frac{1}{s^2+1}+L\{cos(t)*y(t)\} \implies sL\{y(t)\}=\frac{1}{s^2+1}+L\{cos(t)\}\times L\{y(t)\} $ $\implies L\{y(t)\} = \frac{s^2-1}{(s^3-s-1)(s^2+1)} $ (*) Now, I'm stuck on applying the inverse Laplace transform on (*) to find $y(t)$. Any idea?",,"['ordinary-differential-equations', 'laplace-transform']"
52,Form of particular solution to inhomogeneous differential equation,Form of particular solution to inhomogeneous differential equation,,"I want to solve the initial value problem $$x''(t)+3x'(t)+2x(t)=\frac{1}{1+e^t}, \quad x(0)=2\ln2,~x'(0)=1-3\ln 2$$ considering the homogeneous couterpart $$x''(t)+3x'(t)+2x(t)=0$$ with the characteristic polynomial $$ \chi(\lambda)=\lambda^2+3\lambda+2=(\lambda+1)(\lambda+2)$$ the general solution to the homogeneous equation is of the form $$x(t)=c_1e^{-1t}+c_2e^{-2t}$$ using my initial conditions $$x(0)=c_1+c_2=2\ln 2, \quad x'(0)=-c_1-2c_2=1-3\ln 2$$ I have $$c_1=1+\ln2,~c_2=-1+\ln 2,\quad x(t)=(1+\ln 2)e^{-t}+(-1+\ln 2)e^{-2t}$$ Solution using @Karn Watcharasupat's method : $u := x+x', \quad u'=x'+x''$ the equation becomes a first order linear differential equation, with $\mu$ integration factor such that $\mu 2=\mu'\Rightarrow \mu  = e^{2t}$ $$u'+2u=\frac{1}{1+e^t}$$ $$(\mu u)'=\mu \frac{1}{1+e^t}\iff \frac{d\left(e^{2t}u\right)}{dt}=\frac{e^{2t}}{1+e^t}$$ $$ e^{2t}u=\int \frac{e^{2t}}{1+e^t}dt=\int \frac{v-1}{v} dv=\int 1 dv - \int \frac{1}{v}dv=v-\ln |v|=1+e^t-\ln|1+e^t|+C_1$$ for $v:=1+e^t$. And then $$u=\frac{e^t-\ln|1+e^t|+C_2}{e^{2t}}=e^{-t}-e^{-2 t}\ln|1+e^t|+e^{-2t}C_2$$ Plugging back in $$x+x'=C_2e^{-2t}+e^{-t}-e^{-2 t}\ln(1+e^t)$$ which is similarly a first order ODE with $\mu=\mu'\Rightarrow \mu=e^t$ $$\left(x\mu\right)'=\mu\cdot \left(C_2e^{-2t}+e^{-t}-e^{-2 t}\ln(1+e^t)\right)=e^t\left(C_2e^{-2t}+e^{-t}-e^{-2 t}\ln(1+e^t)\right)$$ $$\frac{d\left(xe^t\right)}{dt}=\left(C_2e^{-t}+1-e^{- t}\ln(1+e^t)\right)$$ \begin{align}xe^t&=\int \left(C_2e^{-t}+1-e^{- t}\ln(1+e^t)\right) dt\\&=\int C_2e^{-t} dt+\int 1 dt -\int e^{- t}\ln(1+e^t) dt\\&=-C_2e^{-t}+t-\left[-e^{-t}\ln \left(e^t+1\right)+t-\ln \left|e^t+1\right|+C\right]\\&=-C_2e^{-t}+t+e^{-t}\ln \left(e^t+1\right)-t+\ln \left(e^t+1\right)+C\\&=C_2e^{-t}+e^{-t}\ln \left(e^t+1\right)+\ln \left(e^t+1\right)+C\end{align} And finally $$x=\frac{C_2e^{-t}+e^{-t}\ln \left(e^t+1\right)+\ln \left(e^t+1\right)+C}{e^t}=C_2e^{-2t}+e^{-2t}\ln \left(e^t+1\right)+e^{-t}\ln \left(e^t+1\right)+Ce^{-t}$$ $$x(t)=C_1e^{-t}+C_2e^{-2t}+e^{-t}\ln \left(e^t+1\right)+e^{-2t}\ln \left(e^t+1\right)$$ $$x'(t)=-C_1e^{-t}-2C_2e^{-2t}-e^{-t}\ln \left(e^t+1\right)+\frac{1}{e^t+1}-2e^{-2t}\ln \left(e^t+1\right)+\frac{e^{-t}}{e^t+1}$$ Finding $C_1,~C_2$ $$x(0)=C_1+C_2+2\ln(2)=2\ln(2)\Rightarrow C_1=-C_2$$ $$x'(0)=-C_1-2C_2-\ln 2+\frac{1}{2}-2\ln 2+\frac{1}{2}=1-3\ln 2 \Rightarrow C_1=-2C_2$$ So $$C_1=C_2=0$$ and the solution to the IVP is $$x(t)=e^{-t}\ln \left(e^t+1\right)+e^{-2t}\ln \left(e^t+1\right)$$","I want to solve the initial value problem $$x''(t)+3x'(t)+2x(t)=\frac{1}{1+e^t}, \quad x(0)=2\ln2,~x'(0)=1-3\ln 2$$ considering the homogeneous couterpart $$x''(t)+3x'(t)+2x(t)=0$$ with the characteristic polynomial $$ \chi(\lambda)=\lambda^2+3\lambda+2=(\lambda+1)(\lambda+2)$$ the general solution to the homogeneous equation is of the form $$x(t)=c_1e^{-1t}+c_2e^{-2t}$$ using my initial conditions $$x(0)=c_1+c_2=2\ln 2, \quad x'(0)=-c_1-2c_2=1-3\ln 2$$ I have $$c_1=1+\ln2,~c_2=-1+\ln 2,\quad x(t)=(1+\ln 2)e^{-t}+(-1+\ln 2)e^{-2t}$$ Solution using @Karn Watcharasupat's method : $u := x+x', \quad u'=x'+x''$ the equation becomes a first order linear differential equation, with $\mu$ integration factor such that $\mu 2=\mu'\Rightarrow \mu  = e^{2t}$ $$u'+2u=\frac{1}{1+e^t}$$ $$(\mu u)'=\mu \frac{1}{1+e^t}\iff \frac{d\left(e^{2t}u\right)}{dt}=\frac{e^{2t}}{1+e^t}$$ $$ e^{2t}u=\int \frac{e^{2t}}{1+e^t}dt=\int \frac{v-1}{v} dv=\int 1 dv - \int \frac{1}{v}dv=v-\ln |v|=1+e^t-\ln|1+e^t|+C_1$$ for $v:=1+e^t$. And then $$u=\frac{e^t-\ln|1+e^t|+C_2}{e^{2t}}=e^{-t}-e^{-2 t}\ln|1+e^t|+e^{-2t}C_2$$ Plugging back in $$x+x'=C_2e^{-2t}+e^{-t}-e^{-2 t}\ln(1+e^t)$$ which is similarly a first order ODE with $\mu=\mu'\Rightarrow \mu=e^t$ $$\left(x\mu\right)'=\mu\cdot \left(C_2e^{-2t}+e^{-t}-e^{-2 t}\ln(1+e^t)\right)=e^t\left(C_2e^{-2t}+e^{-t}-e^{-2 t}\ln(1+e^t)\right)$$ $$\frac{d\left(xe^t\right)}{dt}=\left(C_2e^{-t}+1-e^{- t}\ln(1+e^t)\right)$$ \begin{align}xe^t&=\int \left(C_2e^{-t}+1-e^{- t}\ln(1+e^t)\right) dt\\&=\int C_2e^{-t} dt+\int 1 dt -\int e^{- t}\ln(1+e^t) dt\\&=-C_2e^{-t}+t-\left[-e^{-t}\ln \left(e^t+1\right)+t-\ln \left|e^t+1\right|+C\right]\\&=-C_2e^{-t}+t+e^{-t}\ln \left(e^t+1\right)-t+\ln \left(e^t+1\right)+C\\&=C_2e^{-t}+e^{-t}\ln \left(e^t+1\right)+\ln \left(e^t+1\right)+C\end{align} And finally $$x=\frac{C_2e^{-t}+e^{-t}\ln \left(e^t+1\right)+\ln \left(e^t+1\right)+C}{e^t}=C_2e^{-2t}+e^{-2t}\ln \left(e^t+1\right)+e^{-t}\ln \left(e^t+1\right)+Ce^{-t}$$ $$x(t)=C_1e^{-t}+C_2e^{-2t}+e^{-t}\ln \left(e^t+1\right)+e^{-2t}\ln \left(e^t+1\right)$$ $$x'(t)=-C_1e^{-t}-2C_2e^{-2t}-e^{-t}\ln \left(e^t+1\right)+\frac{1}{e^t+1}-2e^{-2t}\ln \left(e^t+1\right)+\frac{e^{-t}}{e^t+1}$$ Finding $C_1,~C_2$ $$x(0)=C_1+C_2+2\ln(2)=2\ln(2)\Rightarrow C_1=-C_2$$ $$x'(0)=-C_1-2C_2-\ln 2+\frac{1}{2}-2\ln 2+\frac{1}{2}=1-3\ln 2 \Rightarrow C_1=-2C_2$$ So $$C_1=C_2=0$$ and the solution to the IVP is $$x(t)=e^{-t}\ln \left(e^t+1\right)+e^{-2t}\ln \left(e^t+1\right)$$",,[]
53,ODE: complex constants in the solution (basic understanding),ODE: complex constants in the solution (basic understanding),,"The solution to oscillatory equations of motion can be solved using complex number terms, so it would look something like: $y(t)=c_1e^{iat}+c_2e^{-iat} \tag{1}$ which is then rearranged applying Euler's identity: $y(t)=(c_1+c_2)\cos(at)+i(c_1-c_2)\sin(at) \tag{2}$ where next, you can get rid of the complex part by redefining: $c_2'=i(c_1-c_2) \tag{3}$ I've done this many times now, but I find the last step is somewhat strange. I know that the integration constants are supposed to be arbitrary constants, and I know that you can solve these ODE's without even using complex numbers. But doesn't equation (3) assume, that the newly defined $c_2'\in \mathbb{C}$ ?","The solution to oscillatory equations of motion can be solved using complex number terms, so it would look something like: $y(t)=c_1e^{iat}+c_2e^{-iat} \tag{1}$ which is then rearranged applying Euler's identity: $y(t)=(c_1+c_2)\cos(at)+i(c_1-c_2)\sin(at) \tag{2}$ where next, you can get rid of the complex part by redefining: $c_2'=i(c_1-c_2) \tag{3}$ I've done this many times now, but I find the last step is somewhat strange. I know that the integration constants are supposed to be arbitrary constants, and I know that you can solve these ODE's without even using complex numbers. But doesn't equation (3) assume, that the newly defined $c_2'\in \mathbb{C}$ ?",,"['complex-numbers', 'ordinary-differential-equations']"
54,"Hello folks, how should I proceed to solve this differential equation through power series?","Hello folks, how should I proceed to solve this differential equation through power series?",,The problem is: $$ y'-y = x \\    y(0) = 0 $$ I know I have use the general form and its derivatives $$ \sum a_n(x-x_0)^n $$ My problem is with the alone $x$ variable on the right side. Could someone give me any tips? Thanks in advance!,The problem is: I know I have use the general form and its derivatives My problem is with the alone variable on the right side. Could someone give me any tips? Thanks in advance!,"
y'-y = x \\   
y(0) = 0
 
\sum a_n(x-x_0)^n
 x","['ordinary-differential-equations', 'power-series']"
55,ODE solver giving unexpected result,ODE solver giving unexpected result,,"I have the following coupled ODEs: $$ \begin{cases} F'(s) & = \lambda F(s) - \lambda (1 - (1 - F(s))^2) + \lambda H'(s)\\ H'(s) & = 1 - H(s) - (1 - F(s))^2, \end{cases} $$ with boundary condition $F(0) = 1-\lambda, H(0) = 0$, here $\lambda \in ]0,1[$. The solution for $F$ I am looking for is a Cummulative Distribution Function (CDF), but when I solve these coupled ODEs with these boundary conditions, I get a result which is not a CDF at all. The question is: how to find the correct solution OR did I make a mistake in deriving these ODEs and do these ODEs indeed not give a CDF as a possible solution? I am using the Python solve odeint","I have the following coupled ODEs: $$ \begin{cases} F'(s) & = \lambda F(s) - \lambda (1 - (1 - F(s))^2) + \lambda H'(s)\\ H'(s) & = 1 - H(s) - (1 - F(s))^2, \end{cases} $$ with boundary condition $F(0) = 1-\lambda, H(0) = 0$, here $\lambda \in ]0,1[$. The solution for $F$ I am looking for is a Cummulative Distribution Function (CDF), but when I solve these coupled ODEs with these boundary conditions, I get a result which is not a CDF at all. The question is: how to find the correct solution OR did I make a mistake in deriving these ODEs and do these ODEs indeed not give a CDF as a possible solution? I am using the Python solve odeint",,"['calculus', 'ordinary-differential-equations', 'probability-distributions', 'numerical-methods']"
56,Proving Peano's Existence Theorem by approximating with $C^{\infty}$ functions using Weierstrass' Theorem.,Proving Peano's Existence Theorem by approximating with  functions using Weierstrass' Theorem.,C^{\infty},"Let $f:B_r(x_0)\to\mathbb{R}^n$ be continuous. Prove there always exists a local solution $x:[0,\delta)\to\mathbb{R}^n$  satisfying   $$x(0)=x_0, \hspace{1cm} x'(t)=f(x(t)), \quad \forall t \in (0,\delta),$$ by approximating $f$ uniformly by $C^{\infty}$ functions. I am looking for proof verification of the following and any suggestions for improvement. I do not feel confident with this proof because I did not use Ascoli-Arzela, which is used in the typical proof of Peano's Existence Theorem. Consider, instead of the open ball $B_r(x_0)$, a closed ball contained in it (since we're showing a local solution, this makes no difference), say $\overline{B_r(x_0)}$. Consider polynomials $P_n(x)$ which converge uniformly to $f$ on the closed ball. These exist because of the Weierstrass' theorem. Now the problems $$\begin{cases} x_n'(t)=P_n(x_n(t))\\ x_n(0)=x_0\end{cases}$$ have a unique local solution in $B_r(x_0)$, since $P_n$ is a polynomial, hence locally Lipschitz on the open ball. Call this solution $x_n$. Moreover, we may extract a convergent subsequence of $x_n$ such that the function $P_n$ has a uniform limit $f$, and therefore the functions $t \mapsto x_n'(t)$ have a uniform limit, which we shall denote by $g(t)$. Now we have a sequence of functions $x_n$ which take the same value at $0$, which are $C^1(B_r(x_0))$ and whose derivatives converge uniformly to a function $g$. Therefore $\exists \lim x_n$ and it is differentiable in a neighborhood of $0$ and its derivative is $g$ because: If $\exists a.f_n(a)\to L$ and $f'_n\to g$ uniformly then $f_n$   has a limit $f$ satisfying $f(a)=L$, $f'=g$. In other words, there is some local solution $x:[0,\delta)\to\mathbb{R}^n$ satisfying $x(0)=x_0$ where $x'(t) = f(x(t))$ for all $t\in[0,\delta)$.","Let $f:B_r(x_0)\to\mathbb{R}^n$ be continuous. Prove there always exists a local solution $x:[0,\delta)\to\mathbb{R}^n$  satisfying   $$x(0)=x_0, \hspace{1cm} x'(t)=f(x(t)), \quad \forall t \in (0,\delta),$$ by approximating $f$ uniformly by $C^{\infty}$ functions. I am looking for proof verification of the following and any suggestions for improvement. I do not feel confident with this proof because I did not use Ascoli-Arzela, which is used in the typical proof of Peano's Existence Theorem. Consider, instead of the open ball $B_r(x_0)$, a closed ball contained in it (since we're showing a local solution, this makes no difference), say $\overline{B_r(x_0)}$. Consider polynomials $P_n(x)$ which converge uniformly to $f$ on the closed ball. These exist because of the Weierstrass' theorem. Now the problems $$\begin{cases} x_n'(t)=P_n(x_n(t))\\ x_n(0)=x_0\end{cases}$$ have a unique local solution in $B_r(x_0)$, since $P_n$ is a polynomial, hence locally Lipschitz on the open ball. Call this solution $x_n$. Moreover, we may extract a convergent subsequence of $x_n$ such that the function $P_n$ has a uniform limit $f$, and therefore the functions $t \mapsto x_n'(t)$ have a uniform limit, which we shall denote by $g(t)$. Now we have a sequence of functions $x_n$ which take the same value at $0$, which are $C^1(B_r(x_0))$ and whose derivatives converge uniformly to a function $g$. Therefore $\exists \lim x_n$ and it is differentiable in a neighborhood of $0$ and its derivative is $g$ because: If $\exists a.f_n(a)\to L$ and $f'_n\to g$ uniformly then $f_n$   has a limit $f$ satisfying $f(a)=L$, $f'=g$. In other words, there is some local solution $x:[0,\delta)\to\mathbb{R}^n$ satisfying $x(0)=x_0$ where $x'(t) = f(x(t))$ for all $t\in[0,\delta)$.",,"['real-analysis', 'ordinary-differential-equations', 'proof-verification', 'weierstrass-approximation']"
57,"Fourier series of $f(x) = 1$ for $x\in[-\pi,0]$, $f(x) = -1$ for $x\in[0,\pi]$.","Fourier series of  for ,  for .","f(x) = 1 x\in[-\pi,0] f(x) = -1 x\in[0,\pi]","I am attempting to solve a Fourier series problem where we have the question defined by a piecewise function: $$f(x) = \begin{cases} 1 & -\pi \leq x \leq 0 \\ -1 & 0 \leq x \leq \pi \end{cases}$$ I can solve it out where I calculate that $A_{n} = 0$, and $A_{0} = 1$, and I then integrate  $$B_{n} = \frac{2}{\pi} \, (1-\cos(\pi \,n))$$ At this point when trying to solve for an equation, it doesn't match up to any of the example solutions online I can find.","I am attempting to solve a Fourier series problem where we have the question defined by a piecewise function: $$f(x) = \begin{cases} 1 & -\pi \leq x \leq 0 \\ -1 & 0 \leq x \leq \pi \end{cases}$$ I can solve it out where I calculate that $A_{n} = 0$, and $A_{0} = 1$, and I then integrate  $$B_{n} = \frac{2}{\pi} \, (1-\cos(\pi \,n))$$ At this point when trying to solve for an equation, it doesn't match up to any of the example solutions online I can find.",,"['ordinary-differential-equations', 'fourier-series']"
58,Solving differential equation with the Dirac Delta Function,Solving differential equation with the Dirac Delta Function,,"I've got a differential equation to solve with the Dirac Delta Function and I'm not really sure how to handle it. I have been instructed to use the Laplace Transform as my method of solution. Here is the equation: $y''+8y'+41y=δ(t-\pi)+δ(t-3\pi)$, $y(0)=1, y'(0)=0$ I have no idea where to begin here. I took the Laplace transform but at this point I'm unsure exactly how to decompose the function after I solved for $y$. Thanks for any help.","I've got a differential equation to solve with the Dirac Delta Function and I'm not really sure how to handle it. I have been instructed to use the Laplace Transform as my method of solution. Here is the equation: $y''+8y'+41y=δ(t-\pi)+δ(t-3\pi)$, $y(0)=1, y'(0)=0$ I have no idea where to begin here. I took the Laplace transform but at this point I'm unsure exactly how to decompose the function after I solved for $y$. Thanks for any help.",,['ordinary-differential-equations']
59,"Why there are no solutions to $ x'(t) = \begin{cases} 1, & \text{if $x$ is rational} \\ -1, & \text{if $x$ is irrational} \end{cases}$?",Why there are no solutions to xx?," x'(t) = \begin{cases} 1, & \text{if   is rational} \\ -1, & \text{if   is irrational} \end{cases}","Why there are no solutions to any initial value problem for this equation $$ x'(t) = \begin{cases} 1,  & \text{if $x$ is rational} \\ -1, & \text{if $x$ is irrational} \end{cases}$$ ? The solutions are $x=\pm t+c$.","Why there are no solutions to any initial value problem for this equation $$ x'(t) = \begin{cases} 1,  & \text{if $x$ is rational} \\ -1, & \text{if $x$ is irrational} \end{cases}$$ ? The solutions are $x=\pm t+c$.",,[]
60,Gradient of a complex function.,Gradient of a complex function.,,"Function  $$𝐴(𝑥,𝑦)=2𝑥𝑦 − i\cdot 𝑥^2𝑦^3.$$ I need to perform some operations on this function, starting with finding its gradient. One way would be to take the partial differential of the function w.r.t $x$ and ignore the partial wrt to $y$. In that case the outcome would come out to be: $$2y - 2ixy^3$$ Is this approach correct? Furthermore i need to calculate, the divergence of the given function. How would i go about that?","Function  $$𝐴(𝑥,𝑦)=2𝑥𝑦 − i\cdot 𝑥^2𝑦^3.$$ I need to perform some operations on this function, starting with finding its gradient. One way would be to take the partial differential of the function w.r.t $x$ and ignore the partial wrt to $y$. In that case the outcome would come out to be: $$2y - 2ixy^3$$ Is this approach correct? Furthermore i need to calculate, the divergence of the given function. How would i go about that?",,"['complex-analysis', 'ordinary-differential-equations', 'multivariable-calculus']"
61,Spotting a pattern for the $n-th$ derivative,Spotting a pattern for the  derivative,n-th,"I have a function $y=\sqrt{\frac {x+1}{1-x}}$ and I am trying to find a pattern for the $n-th$ derivative, I have so far found this: $y'={1\over (x-1)^2({\frac {x+1}{1-x}})^{1/2}}$ $y''={2x+1\over (x-1)^4{(\frac {x+1}{1-x})}^{3/2}}$ $y'''= {3(2x^2+2x+1)\over (x-1)^6{(\frac {x+1}{1-x})}^{5/2}}$ I can see a pattern forming on the denominator but I can't seem to find a pattern on the numerator that I can express in terms of $n$. Any ideas?","I have a function $y=\sqrt{\frac {x+1}{1-x}}$ and I am trying to find a pattern for the $n-th$ derivative, I have so far found this: $y'={1\over (x-1)^2({\frac {x+1}{1-x}})^{1/2}}$ $y''={2x+1\over (x-1)^4{(\frac {x+1}{1-x})}^{3/2}}$ $y'''= {3(2x^2+2x+1)\over (x-1)^6{(\frac {x+1}{1-x})}^{5/2}}$ I can see a pattern forming on the denominator but I can't seem to find a pattern on the numerator that I can express in terms of $n$. Any ideas?",,['ordinary-differential-equations']
62,Find a continuous solution to dy/dx + y = f(x),Find a continuous solution to dy/dx + y = f(x),,"Find a continuous solution satisfying:   $$ \frac{dy}{dx} +y= f(x) $$   Where   $$  f(x) =  \begin{cases} 1  &\text{ for } 0 < x < 1, \\ 0 & \text{ for } x > 1 \end{cases}  $$    with the initial condition $y(0)=0$. I'm not sure what the best way to approach this question is.  I thought I could solve it using Fourier series which gave me the particular solution of: $$f(x) = -\frac12 + \sum_{n=1}^{\infty}\left[-\frac{1}{n\pi} + \frac{1}{n\pi} (-1)^n \right] \sin (n\pi x) $$ Then I found the complementary function $y = e^{-x}$ Is this correct? If so, I'm not sure what the full general solution would be, or if this is even a 'continuous solution'.","Find a continuous solution satisfying:   $$ \frac{dy}{dx} +y= f(x) $$   Where   $$  f(x) =  \begin{cases} 1  &\text{ for } 0 < x < 1, \\ 0 & \text{ for } x > 1 \end{cases}  $$    with the initial condition $y(0)=0$. I'm not sure what the best way to approach this question is.  I thought I could solve it using Fourier series which gave me the particular solution of: $$f(x) = -\frac12 + \sum_{n=1}^{\infty}\left[-\frac{1}{n\pi} + \frac{1}{n\pi} (-1)^n \right] \sin (n\pi x) $$ Then I found the complementary function $y = e^{-x}$ Is this correct? If so, I'm not sure what the full general solution would be, or if this is even a 'continuous solution'.",,"['ordinary-differential-equations', 'continuity', 'fourier-analysis', 'fourier-series']"
63,"Mysterious factor of ""$5$"" appearing in differential equation solution","Mysterious factor of """" appearing in differential equation solution",5,"Please forgive my formatting, this is my first post here. I am trying to solve the differential equation of the form: $x' = A*x$ Where A is the $(n \times n)$ matrix: $         \begin{pmatrix}         2 & -5 \\         1 & -2 \\         \end{pmatrix} $ I found the characteristic equation to be given by: $\lambda^2 + 1 = 0$  which has roots $\lambda = {i, -i}$ Solving the augmented matrix $(A-i*I\ |\ 0)$ gave me the corresponding eigenvector $\phi_1$: $         \begin{pmatrix}         2 + i \\         1 \\         \end{pmatrix} $ This gives the complex solution $x = \phi_1*\exp(it)$ I know that if a solution can be written as $x = u(t) + i*v(t)$, then $u(t)$ and $v(t)$ are also solutions. By Euler's formula, I got: $ u(t) =          \begin{pmatrix}         2 \cos (t) - \sin (t) \\         \cos (t) \\         \end{pmatrix} $ $ v(t) =          \begin{pmatrix}         2 \sin (t) + \cos (t) \\         \sin (t) \\         \end{pmatrix} $ However, the solution in textbook is: $ u(t) =          \begin{pmatrix}         5 \cos (t) \\         2 \cos (t) + \sin (t) \\         \end{pmatrix} $ $ v(t) =          \begin{pmatrix}         5 \sin (t) \\         - \cos (t) + 2 \sin (t) \\         \end{pmatrix} $ What it looks like is they may have used a different eigenvalue / eigenvector, but I can't figure out what they used. I believe my solutions are correct, I checked the first one $\big(u(t)\big)$ by plugging it back in to the original equation. Wolfram alpha also gives the solution with the ""$5$"".  I wonder why? Thanks.","Please forgive my formatting, this is my first post here. I am trying to solve the differential equation of the form: $x' = A*x$ Where A is the $(n \times n)$ matrix: $         \begin{pmatrix}         2 & -5 \\         1 & -2 \\         \end{pmatrix} $ I found the characteristic equation to be given by: $\lambda^2 + 1 = 0$  which has roots $\lambda = {i, -i}$ Solving the augmented matrix $(A-i*I\ |\ 0)$ gave me the corresponding eigenvector $\phi_1$: $         \begin{pmatrix}         2 + i \\         1 \\         \end{pmatrix} $ This gives the complex solution $x = \phi_1*\exp(it)$ I know that if a solution can be written as $x = u(t) + i*v(t)$, then $u(t)$ and $v(t)$ are also solutions. By Euler's formula, I got: $ u(t) =          \begin{pmatrix}         2 \cos (t) - \sin (t) \\         \cos (t) \\         \end{pmatrix} $ $ v(t) =          \begin{pmatrix}         2 \sin (t) + \cos (t) \\         \sin (t) \\         \end{pmatrix} $ However, the solution in textbook is: $ u(t) =          \begin{pmatrix}         5 \cos (t) \\         2 \cos (t) + \sin (t) \\         \end{pmatrix} $ $ v(t) =          \begin{pmatrix}         5 \sin (t) \\         - \cos (t) + 2 \sin (t) \\         \end{pmatrix} $ What it looks like is they may have used a different eigenvalue / eigenvector, but I can't figure out what they used. I believe my solutions are correct, I checked the first one $\big(u(t)\big)$ by plugging it back in to the original equation. Wolfram alpha also gives the solution with the ""$5$"".  I wonder why? Thanks.",,"['linear-algebra', 'ordinary-differential-equations']"
64,General solution of $\dot{x} = A(t) x$,General solution of,\dot{x} = A(t) x,"This is a very basic question, but I'm having trouble solving this. Let $A(t): \mathbb{R} \rightarrow \mathcal{L}(\mathbb{R}^n,\mathbb{R}^n)$ be a $\mathcal{C}^{\infty}$ function, and consider the linear diferential equation $$ \dot{x} = A(t) x$$ $$x(0) = x_0,$$ where $\mathcal{L}(\mathbb{R}^n,\mathbb{R}^n)$ are the linear transformations of $\mathbb{R}^n$ to $\mathbb{R}^n.$ I'm wondering if $ \exp \left (\int_ {0}^{t} A (s) ds \right) x_0 $ is a solution of the above differential equation. As far as I know this is only valid when $A(t) = A_0$, and I could not find any book that says this result is true. NB: If we pretend that life is beautiful and things work as we would like \begin{align*} \frac{d}{dt}\left(\exp \left (\int_ {0}^{t} A (s) ds \right) x_0 \right) &= \frac{d}{dt}\left(\int_{0}^{t} A(s) ds\right) \left(\exp \left(\int_ {0}^{t} A (s) ds \right)\right) x_0\\ &= A(t) \left(\exp \left(\int_ {0}^{t} A (s) ds \right)\right) x_0. \end{align*} But I am not very sure of such manipulations.","This is a very basic question, but I'm having trouble solving this. Let $A(t): \mathbb{R} \rightarrow \mathcal{L}(\mathbb{R}^n,\mathbb{R}^n)$ be a $\mathcal{C}^{\infty}$ function, and consider the linear diferential equation $$ \dot{x} = A(t) x$$ $$x(0) = x_0,$$ where $\mathcal{L}(\mathbb{R}^n,\mathbb{R}^n)$ are the linear transformations of $\mathbb{R}^n$ to $\mathbb{R}^n.$ I'm wondering if $ \exp \left (\int_ {0}^{t} A (s) ds \right) x_0 $ is a solution of the above differential equation. As far as I know this is only valid when $A(t) = A_0$, and I could not find any book that says this result is true. NB: If we pretend that life is beautiful and things work as we would like \begin{align*} \frac{d}{dt}\left(\exp \left (\int_ {0}^{t} A (s) ds \right) x_0 \right) &= \frac{d}{dt}\left(\int_{0}^{t} A(s) ds\right) \left(\exp \left(\int_ {0}^{t} A (s) ds \right)\right) x_0\\ &= A(t) \left(\exp \left(\int_ {0}^{t} A (s) ds \right)\right) x_0. \end{align*} But I am not very sure of such manipulations.",,"['ordinary-differential-equations', 'dynamical-systems']"
65,A way to show $\int_0^\infty e^{-t^2}dt=\frac{\sqrt{\pi}}{2}$,A way to show,\int_0^\infty e^{-t^2}dt=\frac{\sqrt{\pi}}{2},"Question Let $f(x)=[\int_0^x e^{-t^2}dt]^2$, and $g(x)=\int_0^1 \frac{e^{-x^2(t^2+1)}}{t^2+1} dt$ Show that $$f'(x)+g'(x)=0$$ Hence $$f(x)+g(x)=\frac{\pi}{4}$$ What I did for the first part: $$f'(x)=2(\int_0^x e^{-t^2}dt)\frac{d}{dx}\int_0^x e^{-t^2}dt=2(\int_0^x e^{-t^2}dt)(\int_0^x e^{-x^2}dt)=2xe^{-x^2}\int_0^x e^{-t^2}dt$$ and $$g'(x)=\int_0^1 \frac{\partial}{\partial x}\frac{e^{-x^2(t^2+1)}}{t^2+1} dt=-2x\int_0^1 e^{-x^2(t^2+1)}dt=-2xe^{-x^2}\int_0^1 e^{-x^2t^2}dt$$ So $$f'(x)+g'(x)=2xe^{-x^2}(\int_0^x e^{-t^2}dt-\int_0^1 e^{-x^2t^2}dt)$$ But I can't show that the last term =0, where did I make a mistake, or what should I do to take this further? Any help is appreciated.","Question Let $f(x)=[\int_0^x e^{-t^2}dt]^2$, and $g(x)=\int_0^1 \frac{e^{-x^2(t^2+1)}}{t^2+1} dt$ Show that $$f'(x)+g'(x)=0$$ Hence $$f(x)+g(x)=\frac{\pi}{4}$$ What I did for the first part: $$f'(x)=2(\int_0^x e^{-t^2}dt)\frac{d}{dx}\int_0^x e^{-t^2}dt=2(\int_0^x e^{-t^2}dt)(\int_0^x e^{-x^2}dt)=2xe^{-x^2}\int_0^x e^{-t^2}dt$$ and $$g'(x)=\int_0^1 \frac{\partial}{\partial x}\frac{e^{-x^2(t^2+1)}}{t^2+1} dt=-2x\int_0^1 e^{-x^2(t^2+1)}dt=-2xe^{-x^2}\int_0^1 e^{-x^2t^2}dt$$ So $$f'(x)+g'(x)=2xe^{-x^2}(\int_0^x e^{-t^2}dt-\int_0^1 e^{-x^2t^2}dt)$$ But I can't show that the last term =0, where did I make a mistake, or what should I do to take this further? Any help is appreciated.",,"['ordinary-differential-equations', 'multivariable-calculus']"
66,"Solve this : $\,\displaystyle{\frac{dy}{dx}} = \cfrac{2xy \,e^{(x/y)^2}}{y^2(1+e^{(x/y)^2})+2x^2e^{(x/y)^2}}$",Solve this :,"\,\displaystyle{\frac{dy}{dx}} = \cfrac{2xy \,e^{(x/y)^2}}{y^2(1+e^{(x/y)^2})+2x^2e^{(x/y)^2}}","Solve this : $\,\cfrac{dy}{dx} = \cfrac{2xy \,e^{(x/y)^2}}{y^2(1+e^{(x/y)^2})+2x^2e^{(x/y)^2}}$ I tried to solve it using the homogeneous equation method: $$y=vx\\ \cfrac{dy}{dx}=v\,+ x\cfrac{dv}{dx}$$ $\implies v\,+x\cfrac{dv}{dx} = \cfrac{2v\,e^{1/v^2}}{v^2(1+e^{1/v^2})+2e^{1/v^2}}$ $\implies x\cfrac{dv}{dx}= \cfrac{-v^2(1+e^{1/v^2})}{v^2(1+e^{1/v^2})+2e^{1/v^2}}$ $\implies \cfrac{v^2(1+e^{1/v^2})+2e^{1/v^2}}{v^2(1+e^{1/v^2})}dv=-\cfrac{dx}{x}$ $\implies \left[1 + \cfrac{2e^{1/v^2}}{v^2(1+e^{1/v^2})}\right]dv = -\cfrac{dx}{x}$ after this I have no clue, please give hint to solve the LHS.","Solve this : $\,\cfrac{dy}{dx} = \cfrac{2xy \,e^{(x/y)^2}}{y^2(1+e^{(x/y)^2})+2x^2e^{(x/y)^2}}$ I tried to solve it using the homogeneous equation method: $$y=vx\\ \cfrac{dy}{dx}=v\,+ x\cfrac{dv}{dx}$$ $\implies v\,+x\cfrac{dv}{dx} = \cfrac{2v\,e^{1/v^2}}{v^2(1+e^{1/v^2})+2e^{1/v^2}}$ $\implies x\cfrac{dv}{dx}= \cfrac{-v^2(1+e^{1/v^2})}{v^2(1+e^{1/v^2})+2e^{1/v^2}}$ $\implies \cfrac{v^2(1+e^{1/v^2})+2e^{1/v^2}}{v^2(1+e^{1/v^2})}dv=-\cfrac{dx}{x}$ $\implies \left[1 + \cfrac{2e^{1/v^2}}{v^2(1+e^{1/v^2})}\right]dv = -\cfrac{dx}{x}$ after this I have no clue, please give hint to solve the LHS.",,['ordinary-differential-equations']
67,solving inequality contains logarithm,solving inequality contains logarithm,,"I have the following inequality: $$0.39n\log(n) \leq S \leq 0.5n\log(n)$$ How can I find a proper range for $n$? I can have something like: $$10^{S/0.5} \leq n^n \leq 10^{S/0.39}$$ But it's not merely based on $n$, also it'll produces a large number for most of the numbers and will cause overflow in computer's memory.","I have the following inequality: $$0.39n\log(n) \leq S \leq 0.5n\log(n)$$ How can I find a proper range for $n$? I can have something like: $$10^{S/0.5} \leq n^n \leq 10^{S/0.39}$$ But it's not merely based on $n$, also it'll produces a large number for most of the numbers and will cause overflow in computer's memory.",,"['ordinary-differential-equations', 'inequality', 'logarithms']"
68,"Let $A=\begin{pmatrix} 0 & 0 \\ 1 & 0 \\ \end{pmatrix}$. Find $E^s,E^u$ and $E^c$ of the linear system $x'=Ax$",Let . Find  and  of the linear system,"A=\begin{pmatrix} 0 & 0 \\ 1 & 0 \\ \end{pmatrix} E^s,E^u E^c x'=Ax","Let $A=\begin{pmatrix}  0 & 0  \\    1 & 0 \\    \end{pmatrix}$ . Find the stable, unstable and center subspaces $E^s,E^u$ and $E^c$ of the linear system $x'=Ax$ . I've found the eigenvalues: $\lambda^2=0$ therefore $\lambda=0$ . Thus the eigenvector is $v=(0,1)^T$ (Solving the system I obtained $v_1=0$ and $v_2$ is any arbitrary number) and finally $E^c=span\{(0,1)\}, E^s=\{0\}=E^u$ However in the answers from the book says that $E^c=\mathbb R^2$ and I think it's wrong OR  am I wrong?","Let . Find the stable, unstable and center subspaces and of the linear system . I've found the eigenvalues: therefore . Thus the eigenvector is (Solving the system I obtained and is any arbitrary number) and finally However in the answers from the book says that and I think it's wrong OR  am I wrong?","A=\begin{pmatrix}  0 & 0  \\    1 & 0 \\    \end{pmatrix} E^s,E^u E^c x'=Ax \lambda^2=0 \lambda=0 v=(0,1)^T v_1=0 v_2 E^c=span\{(0,1)\}, E^s=\{0\}=E^u E^c=\mathbb R^2",['ordinary-differential-equations']
69,"Critical point analysis for $x'=y,y'=x^2-y-\epsilon$",Critical point analysis for,"x'=y,y'=x^2-y-\epsilon","I'm going through question 5 the past exam here . For starters, I'm trying to find and classify the critical points of the system $$\begin{align} x'&=y, \\ y'&=x^2-y-\epsilon.  \end{align}$$ I've found that: The system has no critical points if $\epsilon<0$. The system has a critical point at $(0,0)$ if $\epsilon=0$. The system has two critical points at $(\pm \sqrt{\epsilon},0)$ if $\epsilon>0$. I've managed to classify the critical points, except for the following boundary cases: $(0,0)$ when $\epsilon=0$, as the linearized system has zero determinant. $(-\sqrt{\epsilon},0) $ when $\epsilon=1/64$, which falls on the parabola in the trace-det critical point picture . All I have is computer generated trajectories, which make me suspect that $(0,0)$ is a saddle. I'd like to know whether my list of boundary cases is corret, and within the list, what is the type of the critical points. Thank you!","I'm going through question 5 the past exam here . For starters, I'm trying to find and classify the critical points of the system $$\begin{align} x'&=y, \\ y'&=x^2-y-\epsilon.  \end{align}$$ I've found that: The system has no critical points if $\epsilon<0$. The system has a critical point at $(0,0)$ if $\epsilon=0$. The system has two critical points at $(\pm \sqrt{\epsilon},0)$ if $\epsilon>0$. I've managed to classify the critical points, except for the following boundary cases: $(0,0)$ when $\epsilon=0$, as the linearized system has zero determinant. $(-\sqrt{\epsilon},0) $ when $\epsilon=1/64$, which falls on the parabola in the trace-det critical point picture . All I have is computer generated trajectories, which make me suspect that $(0,0)$ is a saddle. I'd like to know whether my list of boundary cases is corret, and within the list, what is the type of the critical points. Thank you!",,"['ordinary-differential-equations', 'nonlinear-system']"
70,How to show that the solution of the differential Riccati equation is symmetric?,How to show that the solution of the differential Riccati equation is symmetric?,,"Let $t\leq t_{1}$ be an arbitrary time at which the solution $P(t)$ of the following Riccati differential equation exists: $\dot{P}(t) =-P(t) A(t) - A^{T}(t)P(t) -Q(t) + P(t)B(t)R^{-1}(t)B^{T}(t)P(t)\\ P(t_{1})=M$ with $M=M^{T}\geq 0$, $Q(t)=Q^{T}(t)\geq 0$ and $R(t)=R^{T}>0$ for all $t\in [t_{0},t_{1}]$. $Q,R,M,A,B$ are  real and continuous matrices of appropriate dimensions. How can I show that $P(t)$ is a symmetric matrix and $P(t)\geq 0$.","Let $t\leq t_{1}$ be an arbitrary time at which the solution $P(t)$ of the following Riccati differential equation exists: $\dot{P}(t) =-P(t) A(t) - A^{T}(t)P(t) -Q(t) + P(t)B(t)R^{-1}(t)B^{T}(t)P(t)\\ P(t_{1})=M$ with $M=M^{T}\geq 0$, $Q(t)=Q^{T}(t)\geq 0$ and $R(t)=R^{T}>0$ for all $t\in [t_{0},t_{1}]$. $Q,R,M,A,B$ are  real and continuous matrices of appropriate dimensions. How can I show that $P(t)$ is a symmetric matrix and $P(t)\geq 0$.",,"['ordinary-differential-equations', 'optimal-control']"
71,Second-Order Nonlinear Ordinary Differential Equation - with a scalar multiple,Second-Order Nonlinear Ordinary Differential Equation - with a scalar multiple,,"I studied differential equations back in the day but we never covered second-order nonlinear equations (that I can recall). I have the following equation: $$y''=2\biggl(\frac{y'^{2}}{y}-\frac{y'}{x}\biggr)$$ I tried to follow this Solving a second-order nonlinear ordinary differential equation but the ""2"" out front is throwing me off. I am not a student and this is not homework. I am fairly certain that the first-order solution to this problem will be a Bernoulli type nonlinear equation and that much I can solve. It's just this 2 out front - and getting from a second-order form to a first-order form - that are throwing me. Any help in solving for $y'$ would be greatly appreciated! P. S. This is my first post. My apologies if there are any rules that I have failed to follow. -- Edit: The form of the first-order solution should have the form $$y'(x)=P(x)y(x)+Q(x)y(x)^{2}$$ which would then be solved by the Bernoulli method. But how do we get from the second-order form to this one? I've been trying it on my own and nothing is working. Thanks. Sorry for not being more specific.","I studied differential equations back in the day but we never covered second-order nonlinear equations (that I can recall). I have the following equation: $$y''=2\biggl(\frac{y'^{2}}{y}-\frac{y'}{x}\biggr)$$ I tried to follow this Solving a second-order nonlinear ordinary differential equation but the ""2"" out front is throwing me off. I am not a student and this is not homework. I am fairly certain that the first-order solution to this problem will be a Bernoulli type nonlinear equation and that much I can solve. It's just this 2 out front - and getting from a second-order form to a first-order form - that are throwing me. Any help in solving for $y'$ would be greatly appreciated! P. S. This is my first post. My apologies if there are any rules that I have failed to follow. -- Edit: The form of the first-order solution should have the form $$y'(x)=P(x)y(x)+Q(x)y(x)^{2}$$ which would then be solved by the Bernoulli method. But how do we get from the second-order form to this one? I've been trying it on my own and nothing is working. Thanks. Sorry for not being more specific.",,['ordinary-differential-equations']
72,How to show a solution to an ODE system doesn't exist,How to show a solution to an ODE system doesn't exist,,"Show that each solution $(x(t), y(t))$ of the initial value problem   $$ \left\{\begin{array}{cc}x' =&x^2+y \\ y' =&y^2+x \end{array}\right.\qquad \left\{\begin{array}{cc}x(0) =&x_0 \\ y(0) =&y_0 \end{array}\right. $$   with $x_0>0$ and $y_0>0$ cannot exist on an interval of the form $[0,\infty)$. I have been learning about different theorems to show existence but I am not sure how I would show this DNE. I put it into matlab using this code and got no solutions but is there a way to show this algebraically or some other way? syms x(t) y(t) x0 y0  ode1 = diff(x) == x^2+y; ode2 = diff(y) == y^2+x; odes = [ode1; ode2] S = dsolve(odes)  xSol(t) = S.x ySol(t) = S.y  [xSol(t), ySol(t)] = dsolve(odes)  cond1 = x(0) == x0; cond2 = y(0) == y0; conds = [cond1; cond2]; [uSol(t), vSol(t)] = dsolve(odes,conds)  fplot(xSol) hold on fplot(ySol) grid on legend('xSol','ySol','Location','best')","Show that each solution $(x(t), y(t))$ of the initial value problem   $$ \left\{\begin{array}{cc}x' =&x^2+y \\ y' =&y^2+x \end{array}\right.\qquad \left\{\begin{array}{cc}x(0) =&x_0 \\ y(0) =&y_0 \end{array}\right. $$   with $x_0>0$ and $y_0>0$ cannot exist on an interval of the form $[0,\infty)$. I have been learning about different theorems to show existence but I am not sure how I would show this DNE. I put it into matlab using this code and got no solutions but is there a way to show this algebraically or some other way? syms x(t) y(t) x0 y0  ode1 = diff(x) == x^2+y; ode2 = diff(y) == y^2+x; odes = [ode1; ode2] S = dsolve(odes)  xSol(t) = S.x ySol(t) = S.y  [xSol(t), ySol(t)] = dsolve(odes)  cond1 = x(0) == x0; cond2 = y(0) == y0; conds = [cond1; cond2]; [uSol(t), vSol(t)] = dsolve(odes,conds)  fplot(xSol) hold on fplot(ySol) grid on legend('xSol','ySol','Location','best')",,['ordinary-differential-equations']
73,The general solution of $y'=\vert y-t\vert$,The general solution of,y'=\vert y-t\vert,"How to solve the following ODE? $$y' = | y-t |$$ To eliminate the absolute value, I divided the domain into two parts $\{ y(t) > t \}$ and $\{ y(t) < t \}$. In $\{y(t)>t\}$, the ODE becomes $y'=y-t$. I found $y_+(t)=Ce^t+t+1$. In $\{y(t)<t\}$, the ODE becomes $y'=-y+t$, so the solution is $y_-(t)=Ce^{-t}+t-1$. How to write the general solution?","How to solve the following ODE? $$y' = | y-t |$$ To eliminate the absolute value, I divided the domain into two parts $\{ y(t) > t \}$ and $\{ y(t) < t \}$. In $\{y(t)>t\}$, the ODE becomes $y'=y-t$. I found $y_+(t)=Ce^t+t+1$. In $\{y(t)<t\}$, the ODE becomes $y'=-y+t$, so the solution is $y_-(t)=Ce^{-t}+t-1$. How to write the general solution?",,['ordinary-differential-equations']
74,Solving non-linear second order ODEs,Solving non-linear second order ODEs,,"Originally, I intended to solve the following pde: $$\frac{1}{r}\frac{\partial}{\partial r}\bigg(r \theta^{\beta}\frac{\partial \theta}{\partial r}\bigg) +\frac{\partial }{\partial z}\bigg(\theta^{\beta} \frac{\partial \theta}{\partial z} \bigg)=0 ;\ 0\leq r \leq r_0; \ 0 \leq z \leq l$$ with the following BCs: $$\theta(r,0) = 1 \text{ ; } \theta(r,l) = \theta_0 \text{ (a constant)}$$ $$\frac{\partial \theta}{\partial r}\bigg\rvert_{(0,z)}=\frac{\partial \theta}{\partial r}\bigg\rvert_{(r_0,z)}=0$$ where $\beta$ is some constant. I employed variable separation method, assuming the solution to be of the form $\theta(r,z) = R(r)Z(z)$ This lead to the following ODEs: $$R'' + \frac{\beta R'^2}{R} + \frac{R'}{r} - \lambda^2 R =0 \qquad ; \qquad Z'' + \frac{\beta Z'^2}{Z} + \lambda^2 Z =0$$ $\lambda^2$ being separation constant Now, How do I handle these non-linear ODEs to find closed-form solution(does it exists)? Any tricks/suggestion would be greatly appreciated. Edit: As suggest by @Professor Vector, we can use variable transform in the equation and BCs and solve it like this","Originally, I intended to solve the following pde: $$\frac{1}{r}\frac{\partial}{\partial r}\bigg(r \theta^{\beta}\frac{\partial \theta}{\partial r}\bigg) +\frac{\partial }{\partial z}\bigg(\theta^{\beta} \frac{\partial \theta}{\partial z} \bigg)=0 ;\ 0\leq r \leq r_0; \ 0 \leq z \leq l$$ with the following BCs: $$\theta(r,0) = 1 \text{ ; } \theta(r,l) = \theta_0 \text{ (a constant)}$$ $$\frac{\partial \theta}{\partial r}\bigg\rvert_{(0,z)}=\frac{\partial \theta}{\partial r}\bigg\rvert_{(r_0,z)}=0$$ where $\beta$ is some constant. I employed variable separation method, assuming the solution to be of the form $\theta(r,z) = R(r)Z(z)$ This lead to the following ODEs: $$R'' + \frac{\beta R'^2}{R} + \frac{R'}{r} - \lambda^2 R =0 \qquad ; \qquad Z'' + \frac{\beta Z'^2}{Z} + \lambda^2 Z =0$$ $\lambda^2$ being separation constant Now, How do I handle these non-linear ODEs to find closed-form solution(does it exists)? Any tricks/suggestion would be greatly appreciated. Edit: As suggest by @Professor Vector, we can use variable transform in the equation and BCs and solve it like this",,['ordinary-differential-equations']
75,Student T distribution as a solution of a differential equation,Student T distribution as a solution of a differential equation,,"From the links between probability theory and analysis, we know that lots of pdf usually represent a solution to a differential equation, e.g. the normal distribution is the solution to the heat equation. However, what can be said about the Student T distribution? To my best knowledge, there is no PDE or ODE that admits as a solution the function $$ f(x)=\frac{\Gamma \left( \frac{\nu + 1}{2}\right)}{\sqrt{\nu \pi \sigma^2}\Gamma \left( \frac{\nu}{2}\right)} \left( 1 + \frac{(x-\mu)^2}{\nu\sigma^2} \right)^{-\frac{\nu + 1}{2}} $$ Any toughts about this question would help me a lot! :)","From the links between probability theory and analysis, we know that lots of pdf usually represent a solution to a differential equation, e.g. the normal distribution is the solution to the heat equation. However, what can be said about the Student T distribution? To my best knowledge, there is no PDE or ODE that admits as a solution the function $$ f(x)=\frac{\Gamma \left( \frac{\nu + 1}{2}\right)}{\sqrt{\nu \pi \sigma^2}\Gamma \left( \frac{\nu}{2}\right)} \left( 1 + \frac{(x-\mu)^2}{\nu\sigma^2} \right)^{-\frac{\nu + 1}{2}} $$ Any toughts about this question would help me a lot! :)",,"['real-analysis', 'probability', 'ordinary-differential-equations', 'partial-differential-equations', 'stochastic-pde']"
76,"Question: Properties of differential equation (linear, homogeneous, order, constant coefficients..)","Question: Properties of differential equation (linear, homogeneous, order, constant coefficients..)",,"Hi maths people I have question for test I write next week. There are differential equations and you say what property they have. But my issue is I maybe don't understand all property right. For order I count maximum number of derivative line. By this I mean for example $y''' + y''$ maximum line is $3$ so this is 3th order. Linear you check if exponent of $y$ or $y$ with lines is equal to $1$. Example $(y'')^4$ not linear, $y^2$ not linear, but $y+y''$ is linear. Homogeneous you check if equation is equal with zero and check if function have.. I call it disturbing function. If it have disturbing function you have no homogenetic. I don't can explain good sorry but here is example: $y'''+2y'' = 0$ this is homo because equal to zero and no disturbing function. $y'''-6xy' = 2-3e^x$ this is no homo because there is disturbung function $2$ But I have question, what if this is $y'''-6xy' = 3e^x$ (so without $2$) instead? I think is homogeneous because $x$ and $y$ belong to equation so there is no disturbing function. Is this right? But what is constant coefficient ? I think coefficient is the thing factorized by the variables. When it is number, it is constant coefficient.  But I don't know.. can you please give example? Here is summary I make examples (can you say if this is right?): $y''' +2y'' -5y'+3y+2=0$, 3th order, linear, constant coefficients, no homo $2xy+x^2y'=0$, 1st order, linear, no constant coefficients because muliply by $x$, homo Can you please say if all is good? My friend also not sure we learn   together and this is only thing we must understanded then ready for   test in school! Thank you very much for read all my question!!","Hi maths people I have question for test I write next week. There are differential equations and you say what property they have. But my issue is I maybe don't understand all property right. For order I count maximum number of derivative line. By this I mean for example $y''' + y''$ maximum line is $3$ so this is 3th order. Linear you check if exponent of $y$ or $y$ with lines is equal to $1$. Example $(y'')^4$ not linear, $y^2$ not linear, but $y+y''$ is linear. Homogeneous you check if equation is equal with zero and check if function have.. I call it disturbing function. If it have disturbing function you have no homogenetic. I don't can explain good sorry but here is example: $y'''+2y'' = 0$ this is homo because equal to zero and no disturbing function. $y'''-6xy' = 2-3e^x$ this is no homo because there is disturbung function $2$ But I have question, what if this is $y'''-6xy' = 3e^x$ (so without $2$) instead? I think is homogeneous because $x$ and $y$ belong to equation so there is no disturbing function. Is this right? But what is constant coefficient ? I think coefficient is the thing factorized by the variables. When it is number, it is constant coefficient.  But I don't know.. can you please give example? Here is summary I make examples (can you say if this is right?): $y''' +2y'' -5y'+3y+2=0$, 3th order, linear, constant coefficients, no homo $2xy+x^2y'=0$, 1st order, linear, no constant coefficients because muliply by $x$, homo Can you please say if all is good? My friend also not sure we learn   together and this is only thing we must understanded then ready for   test in school! Thank you very much for read all my question!!",,"['calculus', 'analysis', 'ordinary-differential-equations', 'functions']"
77,I need some help with this bernoulli's equation that is given in my assignment [closed],I need some help with this bernoulli's equation that is given in my assignment [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question Solve: $$y′−\frac{6y}{x}=\frac{y^5}{x^{13}}$$ I have tried again and again but my answer is still wrong. Can someone show me the steps to solving this question?","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question Solve: $$y′−\frac{6y}{x}=\frac{y^5}{x^{13}}$$ I have tried again and again but my answer is still wrong. Can someone show me the steps to solving this question?",,"['calculus', 'ordinary-differential-equations']"
78,Getting rid of absolute value after integration,Getting rid of absolute value after integration,,"I have this differential equation in an exercise: $$y' = \frac{y}{\sqrt{1-x^2}}$$ I solved it like this: $$\frac{dy}{dx} = \frac{y}{\sqrt{1-x^2}}$$ $$\frac{1}{y}dy = \frac{1}{\sqrt{1-x^2}}dx$$ $$\int \frac{1}{y} \,dy = \int \frac{1}{\sqrt{1-x^2}} \,dx$$ $$\ln \,\lvert\,y\,\lvert + C_1 = \arcsin\,x + C_2$$ $$\lvert\,y\,\lvert\,= {e}^{\arcsin\,x + C_3}$$ $$\lvert\,y\,\lvert\,=C{e}^{\arcsin\,x}$$ $$y=±C{e}^{\arcsin\,x}$$ However, the solution given in my textbook is $$y=C{e}^{\arcsin\,x}$$ How to get rid of the absolute value? Did I do something wrong? Some of the other exercises indicates when $y > 0$ but this one has no such indication. I guess it can be deducted?","I have this differential equation in an exercise: $$y' = \frac{y}{\sqrt{1-x^2}}$$ I solved it like this: $$\frac{dy}{dx} = \frac{y}{\sqrt{1-x^2}}$$ $$\frac{1}{y}dy = \frac{1}{\sqrt{1-x^2}}dx$$ $$\int \frac{1}{y} \,dy = \int \frac{1}{\sqrt{1-x^2}} \,dx$$ $$\ln \,\lvert\,y\,\lvert + C_1 = \arcsin\,x + C_2$$ $$\lvert\,y\,\lvert\,= {e}^{\arcsin\,x + C_3}$$ $$\lvert\,y\,\lvert\,=C{e}^{\arcsin\,x}$$ $$y=±C{e}^{\arcsin\,x}$$ However, the solution given in my textbook is $$y=C{e}^{\arcsin\,x}$$ How to get rid of the absolute value? Did I do something wrong? Some of the other exercises indicates when $y > 0$ but this one has no such indication. I guess it can be deducted?",,"['ordinary-differential-equations', 'indefinite-integrals', 'absolute-value']"
79,"PDE $\Delta u=u^3$ in $B(0,1)\subset\mathbb{R}^n$ with boundary condition $u=0$ on $\partial B(0,1)$",PDE  in  with boundary condition  on,"\Delta u=u^3 B(0,1)\subset\mathbb{R}^n u=0 \partial B(0,1)","I have to solve PDE $\Delta u=u^3$ in $B(0,1)\subset\mathbb{R}^n$ with boundary condition $u=0$ on $\partial B(0,1)$. Is there an explicit expression for the solution? I know that the solution to Poisson equation $-\Delta u=f$ can be obtained by convolution with the fundamental solution as $$u(x)=\int_{\mathbb{R}^n}\Phi(x-y)f(y)\text{d}y .$$ But now I'm confused because the integral depends on $u$ itself. I tried to solve the radial version of this equation $$u^{\prime\prime}(r)+\frac{u^{\prime}(r)(n-1)}{r}-u^3(r)=0$$ but this seems impossible me to solve. And I'm not even sure if the equation is rotation invariant. Any help would be appreciated.","I have to solve PDE $\Delta u=u^3$ in $B(0,1)\subset\mathbb{R}^n$ with boundary condition $u=0$ on $\partial B(0,1)$. Is there an explicit expression for the solution? I know that the solution to Poisson equation $-\Delta u=f$ can be obtained by convolution with the fundamental solution as $$u(x)=\int_{\mathbb{R}^n}\Phi(x-y)f(y)\text{d}y .$$ But now I'm confused because the integral depends on $u$ itself. I tried to solve the radial version of this equation $$u^{\prime\prime}(r)+\frac{u^{\prime}(r)(n-1)}{r}-u^3(r)=0$$ but this seems impossible me to solve. And I'm not even sure if the equation is rotation invariant. Any help would be appreciated.",,"['ordinary-differential-equations', 'partial-differential-equations']"
80,Does homoclinic orbit co-exists with periodic orbits?,Does homoclinic orbit co-exists with periodic orbits?,,"Assume that an autonomous differential equation  $$ \frac{dx}{dt}=F(x), \quad x\in R^n,\quad F:R^n\to R^n, \quad n>2$$ has a homoclinic orbit $x=x_{h}(t).$  Does it ever imply that the equation has periodic orbits? I guess for $n=2$ this is the case. Can something be said about higher dimensions?","Assume that an autonomous differential equation  $$ \frac{dx}{dt}=F(x), \quad x\in R^n,\quad F:R^n\to R^n, \quad n>2$$ has a homoclinic orbit $x=x_{h}(t).$  Does it ever imply that the equation has periodic orbits? I guess for $n=2$ this is the case. Can something be said about higher dimensions?",,"['ordinary-differential-equations', 'dynamical-systems']"
81,What method should be used to solve the following differential equation?,What method should be used to solve the following differential equation?,,"I have the differential equation: $$y^{2}dy = x\left ( x dy - y dx \right ) e^{\frac{x}{y}}$$ and I need to solve for a general solution. I'm getting stuck trying to solve for a general solution, as there is no definite Substitution that seems appropriate, and solving for $dy/dx$ is harder that I first thought. What method should be applied to solve for $Y$ with independent variable $x$?","I have the differential equation: $$y^{2}dy = x\left ( x dy - y dx \right ) e^{\frac{x}{y}}$$ and I need to solve for a general solution. I'm getting stuck trying to solve for a general solution, as there is no definite Substitution that seems appropriate, and solving for $dy/dx$ is harder that I first thought. What method should be applied to solve for $Y$ with independent variable $x$?",,['ordinary-differential-equations']
82,Integrate $\int\dfrac{1}{e^{2/y}}dy$,Integrate,\int\dfrac{1}{e^{2/y}}dy,$$\int\dfrac{1}{e^\frac{2}{y}}dy$$ I'm trying to integrate $\frac{dy}{dt}=e^{2/y}$. I've separated the equation to $\frac{1}{e^{2/y}}dy=dt$ so that I can integrate each side with respect to the corresponding variables. Computing the integral of $dt$ is trivial but I'm confused on how to compute the integral of $\frac{1}{e^{2/y}}dy$.,$$\int\dfrac{1}{e^\frac{2}{y}}dy$$ I'm trying to integrate $\frac{dy}{dt}=e^{2/y}$. I've separated the equation to $\frac{1}{e^{2/y}}dy=dt$ so that I can integrate each side with respect to the corresponding variables. Computing the integral of $dt$ is trivial but I'm confused on how to compute the integral of $\frac{1}{e^{2/y}}dy$.,,"['integration', 'ordinary-differential-equations', 'derivatives', 'indefinite-integrals']"
83,How to solve tougher Clairaut's equation,How to solve tougher Clairaut's equation,,"Since I have been finding all the answers here, so I am asking you all to help me with this one also:- Basically, my teacher / professor ask me to mug up all these, please can you help me find a general or any type of hints with which I can be able to solve these equations :: For $$ y=2xp + y^2 p^3 $$ $$ y^2 =v , x=u $$ For $$ y+px =x^4 p^2 $$ --> $$ (1/x) = u, y=v $$ For $$(p^2  + 1 ) (x-y) ^2 = (x+yp) ^2 $$ , $$ x=r cosθ , y= r sinθ $$ For $$ x^2 p^2 + 2xyp + y^2 (1+p) =0 $$ $$ xy =u, y=v $$ And the list goes on. $p$ here means $dy/dx$; $y$ being a function of $x$ alone What to do. Please guide here.","Since I have been finding all the answers here, so I am asking you all to help me with this one also:- Basically, my teacher / professor ask me to mug up all these, please can you help me find a general or any type of hints with which I can be able to solve these equations :: For $$ y=2xp + y^2 p^3 $$ $$ y^2 =v , x=u $$ For $$ y+px =x^4 p^2 $$ --> $$ (1/x) = u, y=v $$ For $$(p^2  + 1 ) (x-y) ^2 = (x+yp) ^2 $$ , $$ x=r cosθ , y= r sinθ $$ For $$ x^2 p^2 + 2xyp + y^2 (1+p) =0 $$ $$ xy =u, y=v $$ And the list goes on. $p$ here means $dy/dx$; $y$ being a function of $x$ alone What to do. Please guide here.",,['ordinary-differential-equations']
84,"If $y^3 + 3a^2x + x^3 = 0,$ then prove that $y'' + \frac{2a^2x^2}{y^5} = 0$",If  then prove that,"y^3 + 3a^2x + x^3 = 0, y'' + \frac{2a^2x^2}{y^5} = 0",I am comfortable with second derivatives but I am just unable to set all the variables up in such a format that I get the latter (the part which needs to be proven). A hint would be a lot of help.,I am comfortable with second derivatives but I am just unable to set all the variables up in such a format that I get the latter (the part which needs to be proven). A hint would be a lot of help.,,"['calculus', 'ordinary-differential-equations', 'derivatives']"
85,Solve $y’’ + 2y’ +y = xe^{-x}$,Solve,y’’ + 2y’ +y = xe^{-x},"So my questions is to solve: $y’’ + 2y’ +y = xe^{-x}$ The general solution is: $(Ax + B)e^{-x} = Axe^{-x} + Be^{-x}$. To Find the particular solution we could assume a solution of the form $y_p = Axe^{-x}$ but we see that this solution would be covered by the general solution. Instead we try to use $Ax^2e^{-x}$. What is the intuition behind multiplying with $x$? Why not add a polynomial, a sine or something else? Solving for $A$ gives me $\frac{1}{2}x^2e^{-x}$. WolframAlpha suggests $\frac{1}{6}x^3e^{-x}$ as the correct answer. Should I have looked for a solution of the form $Ax^3e^{-x}$ and multiplied $Axe^{-x} \times x^2$? What would be the intuition / reason for that?","So my questions is to solve: $y’’ + 2y’ +y = xe^{-x}$ The general solution is: $(Ax + B)e^{-x} = Axe^{-x} + Be^{-x}$. To Find the particular solution we could assume a solution of the form $y_p = Axe^{-x}$ but we see that this solution would be covered by the general solution. Instead we try to use $Ax^2e^{-x}$. What is the intuition behind multiplying with $x$? Why not add a polynomial, a sine or something else? Solving for $A$ gives me $\frac{1}{2}x^2e^{-x}$. WolframAlpha suggests $\frac{1}{6}x^3e^{-x}$ as the correct answer. Should I have looked for a solution of the form $Ax^3e^{-x}$ and multiplied $Axe^{-x} \times x^2$? What would be the intuition / reason for that?",,['ordinary-differential-equations']
86,"What should I study to understand how to operate with differentials such as ""dx""?","What should I study to understand how to operate with differentials such as ""dx""?",,"I study Physics and I have study real analysis little time ago. It is common practice in physics to operate with differentials in a very informal way.   For example : When solving differential equations we multiply and cancel out dx's all day long, sometimes we hear that we just need to think about them as little delta x. My question is: What should I study, to understand formally the nature of these mathematical object ""dx"" ""dy"" and how to operate with them, it makes me preety confused when , for example, we try to solve for the lenght of a curve and some dx² shows up. I remember when in some physical arguments we just vanish higher powers of dx saying that "" if dx is small dx² is even smaller "" haha, i Know its funny, i want to get rid of this informal understanding and have a solid background. Thank you guys in advance. -","I study Physics and I have study real analysis little time ago. It is common practice in physics to operate with differentials in a very informal way.   For example : When solving differential equations we multiply and cancel out dx's all day long, sometimes we hear that we just need to think about them as little delta x. My question is: What should I study, to understand formally the nature of these mathematical object ""dx"" ""dy"" and how to operate with them, it makes me preety confused when , for example, we try to solve for the lenght of a curve and some dx² shows up. I remember when in some physical arguments we just vanish higher powers of dx saying that "" if dx is small dx² is even smaller "" haha, i Know its funny, i want to get rid of this informal understanding and have a solid background. Thank you guys in advance. -",,"['ordinary-differential-equations', 'derivatives', 'differential-geometry', 'differential-forms']"
87,Integrating factor for a differential equation,Integrating factor for a differential equation,,"Find the integrating factor for the equation: $(3x+\frac{6}{y})\mathrm{d}x+(\frac{x^2}{y}+\frac{3y}{x})\mathrm{d}y=0$. Write $P_1(x,y)=2x+\frac{6}{y}$, $Q_1(x,y)=\frac{x^2}{y}$, $P_2(x,y)=x$, and $Q_2(x,y)=\frac{3y}{x}$, then $P_1(x,y)\mathrm{d}x+Q_1(x,y)\mathrm{d}y+P_2(x,y)\mathrm{d}x+Q_2(x,y)\mathrm{d}y=0$. For $P_1(x,y)\mathrm{d}x+Q_1(x,y)\mathrm{d}y$, notice that $\frac{1}{P_1(x,y)}(\frac{\partial Q_1(x,y)}{\partial x}-\frac{\partial P_1(x,y)}{\partial y})=\frac{1}{y}$, and the integrating factor for this part is $\mu_1(y)=\mathrm{e}^{\int\frac{1}{y}\mathrm{d}y}=y$. Hence, by computing $\int_{x_0}^x\mu_1(y)P_1(x,y)\mathrm{d}x+\int_{y_0}^y\mu_1(y)Q_1(x_0,y)\mathrm{d}y$, one obtains $\Phi_1(x,y)=x^2y+6x$. Similary, for $P_2(x,y)\mathrm{d}x+Q_2(x,y)\mathrm{d}y$, notice that $\frac{1}{Q_2(x,y)}(\frac{\partial P_2(x,y)}{\partial y}-\frac{\partial Q_2(x,y)}{\partial x})=\frac{1}{x}$, and the integrating factor for this part is $\mu_2(x)=\mathrm{e}^{\int\frac{1}{x}\mathrm{d}x}=x$. Hence, by computing $\int_{x_0}^x\mu_2(y)P_2(x,y)\mathrm{d}x+\int_{y_0}^y\mu_2(y)Q_2(x_0,y)\mathrm{d}y$, one obtains $\Phi_2(x,y)=\frac{x^3}{3}+\frac{3y^2}{2}$. In order to find the integrating factor for the whole equation, one needs to find two smooth functions $g_1(t)$ and $g_2(t)$ such that $\mu_1g_1(\Phi_1(x,y))=\mu_2g_2(\Phi_2(x,y))$, i.e., $yg_1(x^2y+6x)=xg_2(\frac{x^3}{3}+\frac{3y^2}{2})$. However, it seems impossible, does not it?","Find the integrating factor for the equation: $(3x+\frac{6}{y})\mathrm{d}x+(\frac{x^2}{y}+\frac{3y}{x})\mathrm{d}y=0$. Write $P_1(x,y)=2x+\frac{6}{y}$, $Q_1(x,y)=\frac{x^2}{y}$, $P_2(x,y)=x$, and $Q_2(x,y)=\frac{3y}{x}$, then $P_1(x,y)\mathrm{d}x+Q_1(x,y)\mathrm{d}y+P_2(x,y)\mathrm{d}x+Q_2(x,y)\mathrm{d}y=0$. For $P_1(x,y)\mathrm{d}x+Q_1(x,y)\mathrm{d}y$, notice that $\frac{1}{P_1(x,y)}(\frac{\partial Q_1(x,y)}{\partial x}-\frac{\partial P_1(x,y)}{\partial y})=\frac{1}{y}$, and the integrating factor for this part is $\mu_1(y)=\mathrm{e}^{\int\frac{1}{y}\mathrm{d}y}=y$. Hence, by computing $\int_{x_0}^x\mu_1(y)P_1(x,y)\mathrm{d}x+\int_{y_0}^y\mu_1(y)Q_1(x_0,y)\mathrm{d}y$, one obtains $\Phi_1(x,y)=x^2y+6x$. Similary, for $P_2(x,y)\mathrm{d}x+Q_2(x,y)\mathrm{d}y$, notice that $\frac{1}{Q_2(x,y)}(\frac{\partial P_2(x,y)}{\partial y}-\frac{\partial Q_2(x,y)}{\partial x})=\frac{1}{x}$, and the integrating factor for this part is $\mu_2(x)=\mathrm{e}^{\int\frac{1}{x}\mathrm{d}x}=x$. Hence, by computing $\int_{x_0}^x\mu_2(y)P_2(x,y)\mathrm{d}x+\int_{y_0}^y\mu_2(y)Q_2(x_0,y)\mathrm{d}y$, one obtains $\Phi_2(x,y)=\frac{x^3}{3}+\frac{3y^2}{2}$. In order to find the integrating factor for the whole equation, one needs to find two smooth functions $g_1(t)$ and $g_2(t)$ such that $\mu_1g_1(\Phi_1(x,y))=\mu_2g_2(\Phi_2(x,y))$, i.e., $yg_1(x^2y+6x)=xg_2(\frac{x^3}{3}+\frac{3y^2}{2})$. However, it seems impossible, does not it?",,"['ordinary-differential-equations', 'integrating-factor']"
88,Frechet differentiability of ODE functional,Frechet differentiability of ODE functional,,"Setup: Suppose that $q(x)$ is a strictly positive $C^{2}$ function and consider the initial value problem: \begin{equation} \begin{aligned} y''+q(x)y=&0\\ y(0)=&k\\ y'(0)=&c \end{aligned} \end{equation} We know that such an initial value problem has a unique solution which we will denote by $f^q(x)$. Define the functional $F_{x}$ by \begin{equation} \begin{aligned} F_{x}:C^{2}(\mathbb{R};\mathbb{R})&\rightarrow \mathbb{R}\\ %C^{1,2}(\mathbb{R}^2;\mathbb{R})\\ F_{x}(q)&\mapsto f^{q}(x). \end{aligned} \end{equation} Question: Is the functional $F_{x}$ Frechet differentiable?  How can we determine if it is?","Setup: Suppose that $q(x)$ is a strictly positive $C^{2}$ function and consider the initial value problem: \begin{equation} \begin{aligned} y''+q(x)y=&0\\ y(0)=&k\\ y'(0)=&c \end{aligned} \end{equation} We know that such an initial value problem has a unique solution which we will denote by $f^q(x)$. Define the functional $F_{x}$ by \begin{equation} \begin{aligned} F_{x}:C^{2}(\mathbb{R};\mathbb{R})&\rightarrow \mathbb{R}\\ %C^{1,2}(\mathbb{R}^2;\mathbb{R})\\ F_{x}(q)&\mapsto f^{q}(x). \end{aligned} \end{equation} Question: Is the functional $F_{x}$ Frechet differentiable?  How can we determine if it is?",,"['functional-analysis', 'analysis', 'ordinary-differential-equations', 'functional-calculus', 'frechet-derivative']"
89,Proof the following!,Proof the following!,,"$$a_0(x)\frac{d^2y}{dx^2}+a_1(x)\frac{dy}{dx}+a_2(x)y=0$$ A) Let $f_1$ & $f_2$ are two solutions to the above differential equation. Show that $f_1$ & $f_2$ are linearly independent on $a \leq x \leq b$ and $A_1$,$A_2$,$B_1$&$B_2$  are constants such that $A_1B_2-A_2B_1\neq 0$ then the solution $A_1f_1+A_2f_2$ & $B_1f_1+B_2f_2$ are also linearly independent on $a \leq x \leq b$ My work is down! I assume that the solution of the differential equation are linearly independent then we can write them as follows $$A_1f_1+A_2f_2=0$$ $$\frac{f_1}{f_2}=-\frac{A_1}{A_2}$$ $$B_1f_1+B_2f_2=0$$ $$B_1 f'_1+B_2 f'_2=0$$ $$\frac{f'_1}{f'_2}=-\frac{B_1}{B_2}$$ Since the two solutions are linearly independent their Wronskian are not zero! $$W[f_1(x),f_2(x)]=f_1f_2'-f_2f_1'\neq 0$$ $W(x)\neq 0$ therefore $ W'(x)\neq 0$ $$W(x)[f_1,f_2]=(-A_1)(-B_2)-(A_2)(B_1)$$ $$(-A_1)(-B_2)-(A_2)(B_1)\neq 0$$ What I do is very foolish. Can someone propose a proper way of doing things! B) Let set ${f_1,f_2}$ be two solutions to the above differential equation and ${g_1,g_2}$ be another set then show that the wronskian is $W[f_1(x),f_2(x)]=cW[g_1(x),g_2(x)]$ such that $c\neq 0$ Since $f_1$ & $f_2$ are solutions, then $$a_0f_1''+a_1f_1'+a_2f_1+a_0f_2''+a_1f_2'+a_2f_2=0=0$$ $$a_0(f_1f_2''-f_2f_1'')+a_1(f_1f_2'-f_2f_1')+a_2(f_2f_1-f_1f_2)=0$$ $$a_0W'[f_1(x),f_2(x)]+a_1W[f_1(x),f_2(x)]=0$$ $$W'[f_1(x),f_2(x)]=-\frac{a_1}{a_0}W[f_1(x),f_2(x)]$$ $$W'[g_1(x),g_2(x)]=-\frac{a_1}{a_0}W[g_1(x),g_2(x)]$$ $$\int\frac{dW[g_1(x),g_2(x)]}{W[g_1(x),g_2(x)]}=\int \frac{dW[f_1(x),f_2(x)]}{W[f_1(x),f_2(x)]}$$ $$W[f_1(x),f_2(x)]=cW[g_1(x),g_2(x)]$$ Totally stuck! This is bad. I can't even proceed from the question! Hope someone help me in this question","$$a_0(x)\frac{d^2y}{dx^2}+a_1(x)\frac{dy}{dx}+a_2(x)y=0$$ A) Let $f_1$ & $f_2$ are two solutions to the above differential equation. Show that $f_1$ & $f_2$ are linearly independent on $a \leq x \leq b$ and $A_1$,$A_2$,$B_1$&$B_2$  are constants such that $A_1B_2-A_2B_1\neq 0$ then the solution $A_1f_1+A_2f_2$ & $B_1f_1+B_2f_2$ are also linearly independent on $a \leq x \leq b$ My work is down! I assume that the solution of the differential equation are linearly independent then we can write them as follows $$A_1f_1+A_2f_2=0$$ $$\frac{f_1}{f_2}=-\frac{A_1}{A_2}$$ $$B_1f_1+B_2f_2=0$$ $$B_1 f'_1+B_2 f'_2=0$$ $$\frac{f'_1}{f'_2}=-\frac{B_1}{B_2}$$ Since the two solutions are linearly independent their Wronskian are not zero! $$W[f_1(x),f_2(x)]=f_1f_2'-f_2f_1'\neq 0$$ $W(x)\neq 0$ therefore $ W'(x)\neq 0$ $$W(x)[f_1,f_2]=(-A_1)(-B_2)-(A_2)(B_1)$$ $$(-A_1)(-B_2)-(A_2)(B_1)\neq 0$$ What I do is very foolish. Can someone propose a proper way of doing things! B) Let set ${f_1,f_2}$ be two solutions to the above differential equation and ${g_1,g_2}$ be another set then show that the wronskian is $W[f_1(x),f_2(x)]=cW[g_1(x),g_2(x)]$ such that $c\neq 0$ Since $f_1$ & $f_2$ are solutions, then $$a_0f_1''+a_1f_1'+a_2f_1+a_0f_2''+a_1f_2'+a_2f_2=0=0$$ $$a_0(f_1f_2''-f_2f_1'')+a_1(f_1f_2'-f_2f_1')+a_2(f_2f_1-f_1f_2)=0$$ $$a_0W'[f_1(x),f_2(x)]+a_1W[f_1(x),f_2(x)]=0$$ $$W'[f_1(x),f_2(x)]=-\frac{a_1}{a_0}W[f_1(x),f_2(x)]$$ $$W'[g_1(x),g_2(x)]=-\frac{a_1}{a_0}W[g_1(x),g_2(x)]$$ $$\int\frac{dW[g_1(x),g_2(x)]}{W[g_1(x),g_2(x)]}=\int \frac{dW[f_1(x),f_2(x)]}{W[f_1(x),f_2(x)]}$$ $$W[f_1(x),f_2(x)]=cW[g_1(x),g_2(x)]$$ Totally stuck! This is bad. I can't even proceed from the question! Hope someone help me in this question",,"['ordinary-differential-equations', 'proof-verification']"
90,Help with a differential equation using variation of parameters,Help with a differential equation using variation of parameters,,"I've been asked to find the general solution of this system: $\begin{cases} x_1'= -x_2 + 2 \\   x_2'= 2x_1 +3x_2 +t\end{cases}$ So, we have been working on this with a friend and were wondering if there's a better method to solve it. We wanted to used variations of parameters. To start with, we found the eigenvalues: $\lambda_1= \frac {3+\sqrt17}{2}$ $\lambda_2=\frac {3-\sqrt17}{2}$ Then, we computed the eigenvectors and found the $X_h$, the homogenous solution. With that, we set out to find $X_p(t$), by solving $Q(t).C'(t)=b(t)$ where $X_p$ stands for a particular solution. We learned that we need to find $C(t)$ to get $X_p(t)= Q(t).C(t)$ in order to, finally, get the general solution, $X_g$, where $X_g= X_p + X_h$. In our case, we had: $ e^{\frac{3}{2}t}\left(\begin{matrix} 2e^{\frac {\sqrt 17}{2}t} & 2e^{-\frac {\sqrt 17}{2}t} \\ (3+\sqrt 17) e^{\frac {\sqrt 17}{2} t}&(3-\sqrt 17) e^{-\frac {\sqrt 17}{2}t}\\ \end{matrix}\right)$. $\left(\begin{matrix} c_1' \\ c_2'\\ \end{matrix}\right) =\left(\begin{matrix} 2 \\ t\\ \end{matrix}\right)$ I prefer to avoid the rest of the computations, I believe they are unnecessarily complicated and you don't need to see them to understand the point. In short, we found ourselves dealing with a pretty complicated integral to find $C(t)$ and very long computations and started wondering if we were mistaking somewhere or if maybe there's a better method than this one. Thanks for the help! (P.S. : How can I write the braces for the system of equations? I tried many times and failed) EDIT Solved the problem with the braces","I've been asked to find the general solution of this system: $\begin{cases} x_1'= -x_2 + 2 \\   x_2'= 2x_1 +3x_2 +t\end{cases}$ So, we have been working on this with a friend and were wondering if there's a better method to solve it. We wanted to used variations of parameters. To start with, we found the eigenvalues: $\lambda_1= \frac {3+\sqrt17}{2}$ $\lambda_2=\frac {3-\sqrt17}{2}$ Then, we computed the eigenvectors and found the $X_h$, the homogenous solution. With that, we set out to find $X_p(t$), by solving $Q(t).C'(t)=b(t)$ where $X_p$ stands for a particular solution. We learned that we need to find $C(t)$ to get $X_p(t)= Q(t).C(t)$ in order to, finally, get the general solution, $X_g$, where $X_g= X_p + X_h$. In our case, we had: $ e^{\frac{3}{2}t}\left(\begin{matrix} 2e^{\frac {\sqrt 17}{2}t} & 2e^{-\frac {\sqrt 17}{2}t} \\ (3+\sqrt 17) e^{\frac {\sqrt 17}{2} t}&(3-\sqrt 17) e^{-\frac {\sqrt 17}{2}t}\\ \end{matrix}\right)$. $\left(\begin{matrix} c_1' \\ c_2'\\ \end{matrix}\right) =\left(\begin{matrix} 2 \\ t\\ \end{matrix}\right)$ I prefer to avoid the rest of the computations, I believe they are unnecessarily complicated and you don't need to see them to understand the point. In short, we found ourselves dealing with a pretty complicated integral to find $C(t)$ and very long computations and started wondering if we were mistaking somewhere or if maybe there's a better method than this one. Thanks for the help! (P.S. : How can I write the braces for the system of equations? I tried many times and failed) EDIT Solved the problem with the braces",,"['calculus', 'ordinary-differential-equations', 'eigenvalues-eigenvectors', 'vector-analysis']"
91,How can I solve $ yy''+y'+1=0$?,How can I solve ?, yy''+y'+1=0,"I know that a particular solution for this equation is $y=-x$ . So, I have tried to find another solution with $y=xf(x)$ but I have encountered an equation even more difficult. I also have attempted to make $u=y'$ and $u=yy'$ but it was not successful.","I know that a particular solution for this equation is . So, I have tried to find another solution with but I have encountered an equation even more difficult. I also have attempted to make and but it was not successful.",y=-x y=xf(x) u=y' u=yy',['ordinary-differential-equations']
92,All circles are straight lines. What have I done wrong?,All circles are straight lines. What have I done wrong?,,"I was solving this problem: Find all plane curves where all tangent lines intersect in a single point . So, I reasoned that, the tangent vector must be parallel to $\mathbf p - \mathbf r(s)$, where $\mathbf p = (p_x, p_y)$ is the point of intersection and $\mathbf r(s) = (x(s), y(s))$ is the curve itself, arc length parameterized. That is: $$ T(s)\quad||\quad (\mathbf p - \mathbf r(s)) \quad\implies\quad T(s) = H(s) (\mathbf p - \mathbf r(s)), \quad\mbox{ for some function $H$}. $$ Solving it gives: $$ \mathbf r'(s) = H(s) (\mathbf p - \mathbf r(s)) \quad\implies\quad \mathbf r(s) = \mathbf p_0 - \mathbf A\exp\int H(s)ds $$ Hereby, dividing both vector components: $$ \frac{p_y - y(s)}{p_x - x(s)} = \frac{A_y \exp(...)}{A_x \exp(...)} = \frac{A_y}{A_x} \quad\implies\quad y = ax + b $$ It gives a straight line. As it should. No matter what choice of $H(s)$ is made. But then, I tried the following way: $$ \mathbf r'(s) = H(s) (\mathbf p - \mathbf r(s)) \quad\implies\quad 1 = \mathbf r'(s)^2 = H(s)^2 (\mathbf p - \mathbf r(s))^2 $$ That is: $$ (\mathbf p - \mathbf r(s))^2 = \frac{1}{H(s)^2}  \quad\implies\quad (p_x - x(s))^2 + (p_y - y(s))^2 = \frac{1}{H(s)^2} $$ That is, a circle, with a ""radius"" of $1/H(s)$. Since $H$ is a proportion between tangent vector and distance from the curve to the point, I can simply find all curves such that $H(s) = 1/R$ constant. And this gives a true circle, in contradiction with the previous result. What have I done wrong?","I was solving this problem: Find all plane curves where all tangent lines intersect in a single point . So, I reasoned that, the tangent vector must be parallel to $\mathbf p - \mathbf r(s)$, where $\mathbf p = (p_x, p_y)$ is the point of intersection and $\mathbf r(s) = (x(s), y(s))$ is the curve itself, arc length parameterized. That is: $$ T(s)\quad||\quad (\mathbf p - \mathbf r(s)) \quad\implies\quad T(s) = H(s) (\mathbf p - \mathbf r(s)), \quad\mbox{ for some function $H$}. $$ Solving it gives: $$ \mathbf r'(s) = H(s) (\mathbf p - \mathbf r(s)) \quad\implies\quad \mathbf r(s) = \mathbf p_0 - \mathbf A\exp\int H(s)ds $$ Hereby, dividing both vector components: $$ \frac{p_y - y(s)}{p_x - x(s)} = \frac{A_y \exp(...)}{A_x \exp(...)} = \frac{A_y}{A_x} \quad\implies\quad y = ax + b $$ It gives a straight line. As it should. No matter what choice of $H(s)$ is made. But then, I tried the following way: $$ \mathbf r'(s) = H(s) (\mathbf p - \mathbf r(s)) \quad\implies\quad 1 = \mathbf r'(s)^2 = H(s)^2 (\mathbf p - \mathbf r(s))^2 $$ That is: $$ (\mathbf p - \mathbf r(s))^2 = \frac{1}{H(s)^2}  \quad\implies\quad (p_x - x(s))^2 + (p_y - y(s))^2 = \frac{1}{H(s)^2} $$ That is, a circle, with a ""radius"" of $1/H(s)$. Since $H$ is a proportion between tangent vector and distance from the curve to the point, I can simply find all curves such that $H(s) = 1/R$ constant. And this gives a true circle, in contradiction with the previous result. What have I done wrong?",,"['ordinary-differential-equations', 'differential-geometry', 'curves', 'plane-curves']"
93,Show $(\frac{\partial \ln p}{\partial \ln V})_{T} = \frac{V}{p}(\frac{\partial p}{\partial V})_{T}$,Show,(\frac{\partial \ln p}{\partial \ln V})_{T} = \frac{V}{p}(\frac{\partial p}{\partial V})_{T},"Question: In thermodynamics, the pressure of a system, $p$, can be considered as a function of the variables $V$ (volume) and $T$ (temperature) or as a function of the variables $V$ and $S$ (entropy). (i) By expressing $p(V,S)$ in the form $p(V,S(V,T))$ evaluate $(\frac{\partial p}{\partial V})_{T} - (\frac{\partial p}{\partial V})_{S}$ in terms of $(\frac{\partial S}{\partial V})_{T}$ and $(\frac{\partial S}{\partial p})_{V}$. (ii) Hence, using $TdS = dU + pdV$ (conservation of energy with $U$ the internal energy), show that: $(\frac{\partial \ln p}{\partial \ln V})_{T} - (\frac{\partial \ln p}{\partial \ln V})_{S} = (\frac{\partial (pV)}{\partial T})_{V} [ \frac{p^{-1}(\frac{\partial U}{\partial V})_{T}+1}{(\frac{\partial U}{\partial T})_{V}}]$. [Hint: $(\frac{\partial \ln p}{\partial \ln V})_{T} = \frac{V}{p}(\frac{\partial p}{\partial V})_{T}$] (This question is from http://www.damtp.cam.ac.uk/user/examples/A3a.pdf .) ------------------------------------------------------------------------------------------- My Attempt: (i) By Chain Rule: $dp = (\frac{\partial p}{\partial V})_{S}dV + (\frac{\partial p}{\partial S})_{V}dS$ =>$(\frac{\partial p}{\partial V})_{T} - (\frac{\partial p}{\partial V})_{S} = (\frac{\partial p}{\partial S})_{V} (\frac{\partial S}{\partial V})_{T} = \frac{(\frac{\partial S}{\partial V})_{T}}{(\frac{\partial S}{\partial p})_{V}}$ (by reciprocal rule) (ii) $TdS = dU + pdV$ => $T (\frac{\partial S}{\partial V})_{T} = (\frac{\partial U}{\partial V})_{T} + p$ and $T (\frac{\partial S}{\partial p})_{V} = (\frac{\partial U}{\partial p})_{V}$ So $(\frac{\partial p}{\partial V})_{T} - (\frac{\partial p}{\partial V})_{S} = p [\frac{(p^{-1}\frac{\partial U}{\partial V})_{T} + 1}{(\frac{\partial U}{\partial p})_{V}}]$ Then observe $dS = (\frac{\partial S}{\partial V})_{T}dV + (\frac{\partial S}{\partial T})_{V}dT $ So $dp = [(\frac{\partial p}{\partial V})_{S} + (\frac{\partial p}{\partial S})_{V}(\frac{\partial S}{\partial V})_{T}]dV + (\frac{\partial p}{\partial S})_{V}(\frac{\partial S}{\partial T})_{V}dT$ => $(\frac{\partial p}{\partial U})_{V} = (\frac{\partial p}{\partial S})_{V} (\frac{\partial S}{\partial T})_{V} (\frac{\partial T}{\partial U})_{V}$ Then by Chain Rule (using our expression for $dS$) $(\frac{\partial S}{\partial p})_{V} = (\frac{\partial S}{\partial T})_{V} (\frac{\partial T}{\partial p})_{V}$ => $(\frac{\partial p}{\partial T})_{V} = (\frac{\partial p}{\partial S})_{V}(\frac{\partial S}{\partial T})_{V}$ And so (using the results above and the Reciprocal Rule): $(\frac{\partial p}{\partial V})_{T} - (\frac{\partial p}{\partial V})_{S} = p [\frac{p^{-1}(\frac{\partial U}{\partial V})_{T} + 1}{(\frac{\partial U}{\partial p})_{V}}] =  p (\frac{\partial p}{\partial U})_{V} [{p^{-1}(\frac{\partial U}{\partial V})_{T} + 1}] = p (\frac{\partial p}{\partial S})_{V} (\frac{\partial S}{\partial T})_{V} (\frac{\partial T}{\partial U})_{V} [{p^{-1}(\frac{\partial U}{\partial V})_{T} + 1}] = p (\frac{\partial p}{\partial T})_{V} [\frac{ {p^{-1}(\frac{\partial U}{\partial V})_{T} + 1}}{(\frac{\partial U}{\partial T})_{V}}]$ (This is where I am stuck) ------------------------------------------------------------------------------------------- Comments: The issue I have with the question (I assume) is that I am unable to derive the expression in the hint, i.e. showing that $(\frac{\partial \ln p}{\partial \ln V})_{T} = \frac{V}{p}(\frac{\partial p}{\partial V})_{T}$. I would assume that a very similar expression exists when keeping $S$ constant.","Question: In thermodynamics, the pressure of a system, $p$, can be considered as a function of the variables $V$ (volume) and $T$ (temperature) or as a function of the variables $V$ and $S$ (entropy). (i) By expressing $p(V,S)$ in the form $p(V,S(V,T))$ evaluate $(\frac{\partial p}{\partial V})_{T} - (\frac{\partial p}{\partial V})_{S}$ in terms of $(\frac{\partial S}{\partial V})_{T}$ and $(\frac{\partial S}{\partial p})_{V}$. (ii) Hence, using $TdS = dU + pdV$ (conservation of energy with $U$ the internal energy), show that: $(\frac{\partial \ln p}{\partial \ln V})_{T} - (\frac{\partial \ln p}{\partial \ln V})_{S} = (\frac{\partial (pV)}{\partial T})_{V} [ \frac{p^{-1}(\frac{\partial U}{\partial V})_{T}+1}{(\frac{\partial U}{\partial T})_{V}}]$. [Hint: $(\frac{\partial \ln p}{\partial \ln V})_{T} = \frac{V}{p}(\frac{\partial p}{\partial V})_{T}$] (This question is from http://www.damtp.cam.ac.uk/user/examples/A3a.pdf .) ------------------------------------------------------------------------------------------- My Attempt: (i) By Chain Rule: $dp = (\frac{\partial p}{\partial V})_{S}dV + (\frac{\partial p}{\partial S})_{V}dS$ =>$(\frac{\partial p}{\partial V})_{T} - (\frac{\partial p}{\partial V})_{S} = (\frac{\partial p}{\partial S})_{V} (\frac{\partial S}{\partial V})_{T} = \frac{(\frac{\partial S}{\partial V})_{T}}{(\frac{\partial S}{\partial p})_{V}}$ (by reciprocal rule) (ii) $TdS = dU + pdV$ => $T (\frac{\partial S}{\partial V})_{T} = (\frac{\partial U}{\partial V})_{T} + p$ and $T (\frac{\partial S}{\partial p})_{V} = (\frac{\partial U}{\partial p})_{V}$ So $(\frac{\partial p}{\partial V})_{T} - (\frac{\partial p}{\partial V})_{S} = p [\frac{(p^{-1}\frac{\partial U}{\partial V})_{T} + 1}{(\frac{\partial U}{\partial p})_{V}}]$ Then observe $dS = (\frac{\partial S}{\partial V})_{T}dV + (\frac{\partial S}{\partial T})_{V}dT $ So $dp = [(\frac{\partial p}{\partial V})_{S} + (\frac{\partial p}{\partial S})_{V}(\frac{\partial S}{\partial V})_{T}]dV + (\frac{\partial p}{\partial S})_{V}(\frac{\partial S}{\partial T})_{V}dT$ => $(\frac{\partial p}{\partial U})_{V} = (\frac{\partial p}{\partial S})_{V} (\frac{\partial S}{\partial T})_{V} (\frac{\partial T}{\partial U})_{V}$ Then by Chain Rule (using our expression for $dS$) $(\frac{\partial S}{\partial p})_{V} = (\frac{\partial S}{\partial T})_{V} (\frac{\partial T}{\partial p})_{V}$ => $(\frac{\partial p}{\partial T})_{V} = (\frac{\partial p}{\partial S})_{V}(\frac{\partial S}{\partial T})_{V}$ And so (using the results above and the Reciprocal Rule): $(\frac{\partial p}{\partial V})_{T} - (\frac{\partial p}{\partial V})_{S} = p [\frac{p^{-1}(\frac{\partial U}{\partial V})_{T} + 1}{(\frac{\partial U}{\partial p})_{V}}] =  p (\frac{\partial p}{\partial U})_{V} [{p^{-1}(\frac{\partial U}{\partial V})_{T} + 1}] = p (\frac{\partial p}{\partial S})_{V} (\frac{\partial S}{\partial T})_{V} (\frac{\partial T}{\partial U})_{V} [{p^{-1}(\frac{\partial U}{\partial V})_{T} + 1}] = p (\frac{\partial p}{\partial T})_{V} [\frac{ {p^{-1}(\frac{\partial U}{\partial V})_{T} + 1}}{(\frac{\partial U}{\partial T})_{V}}]$ (This is where I am stuck) ------------------------------------------------------------------------------------------- Comments: The issue I have with the question (I assume) is that I am unable to derive the expression in the hint, i.e. showing that $(\frac{\partial \ln p}{\partial \ln V})_{T} = \frac{V}{p}(\frac{\partial p}{\partial V})_{T}$. I would assume that a very similar expression exists when keeping $S$ constant.",,"['calculus', 'ordinary-differential-equations', 'multivariable-calculus', 'partial-differential-equations', 'partial-derivative']"
94,What is the rigorous justification for treating differentials as fractions while solving differential equations? [duplicate],What is the rigorous justification for treating differentials as fractions while solving differential equations? [duplicate],,"This question already has answers here : What am I doing when I separate the variables of a differential equation? (5 answers) Closed 7 years ago . For example, given the differential equation $\dfrac{\mathrm{d}y}{\mathrm{d}x}=y\tag*{}$ We do, $\dfrac{\mathrm{d}y}{y}=\mathrm{d}x\tag{*}$ At which point we go and integrate both sides. Is there a rigorous justification for being able to go to $(*)?$","This question already has answers here : What am I doing when I separate the variables of a differential equation? (5 answers) Closed 7 years ago . For example, given the differential equation $\dfrac{\mathrm{d}y}{\mathrm{d}x}=y\tag*{}$ We do, $\dfrac{\mathrm{d}y}{y}=\mathrm{d}x\tag{*}$ At which point we go and integrate both sides. Is there a rigorous justification for being able to go to $(*)?$",,"['calculus', 'ordinary-differential-equations']"
95,Parallel transport attempt solution. Should I parametrize the path like so.,Parallel transport attempt solution. Should I parametrize the path like so.,,"Context: Past exam for class that I sit my final for tomorrow :). We are in a $2$-dimensional surface, with coordinates $(\theta,\phi)$. Consider the metric $ds^2 = r_0^2 d\theta^2 + r_0^2 \sin^2(\theta)d\phi^2$ I have shown that the only non-zero Christoffel symbols are: $$\Gamma_{12}^{\,\,\, 2}=\Gamma_{21}^{\,\,\, 2}=\cot(\theta),\qquad \Gamma_{22}^{\,\,\, 1}=-\sin(\theta)\cos(\theta)$$ I want to show that if a contravariant vector $a^i$ undergoes parallel transport around the circle from $\theta = \pi/4$ from $\phi=0$ to $\phi=2\pi$ and $a^1=0$, $a^2=1$ at $\phi=0$ then at $\phi=2\pi$ we have: $$a^1 = \frac{\sqrt{2}}{2}\sin(\sqrt{2}\pi),\qquad a^2=\cos(\sqrt{2}\pi)$$ My attempt: We have that $$0=\frac{Da^\lambda}{Dt}=\frac{da^\lambda}{dt}+\Gamma_{\mu\nu}^{\,\,\, \lambda}a^\mu \frac{dx^\nu}{dt}$$ (where $x^1=\theta,x^2=\phi$ is convention, and does not refer to cartesian coordinates). So I have: $$\dot{a}^1=-\Gamma_{\mu\nu}^{\,\,\, 1}a^\mu \dot{x}^\nu=\sin(\theta)\cos(\theta)a^2 \dot{\phi}$$ $$\dot{a}^2=-\Gamma_{\mu\nu}^{\,\,\,2}a^\mu \dot{x}^\nu=-\cot(\theta)(a^1\dot{\phi}+a^2\dot{\theta})$$ Now since $\theta$ stays constant, we have $\theta=\frac{\pi}{4}$ and  $\dot{\theta}=0$, and so the above refines to: $$\dot{a}^1=-\Gamma_{\mu\nu}^{\,\,\, 1}a^\mu \dot{x}^\nu=\frac12a^2 \dot{\phi}$$ $$\dot{a}^2=-\Gamma_{\mu\nu}^{\,\,\,2}a^\mu \dot{x}^\nu=-(a^1\dot{\phi})$$ What to do with $\dot{\phi}$? Should I parametrize $\phi$? Say we take $\phi(t) = 2\pi t$ so that this moves along a circle over $t\in [0,1]$, then we have: $\dot{\phi}=2\pi$ and hence: $$\dot{a}^1=-\Gamma_{\mu\nu}^{\,\,\, 1}a^\mu \dot{x}^\nu=\frac12a^2 2\pi$$ $$\dot{a}^2=-\Gamma_{\mu\nu}^{\,\,\,2}a^\mu \dot{x}^\nu=-(a^12\pi)$$ So we have: $$\begin{bmatrix}\dot{a}^1\\\dot{a}^2\end{bmatrix} = \begin{bmatrix}0&\pi \\-2\pi&0\end{bmatrix}\begin{bmatrix}a^1\\a^2\end{bmatrix}$$ and solve this in the classical way: Eigenvalues are $\pm \sqrt{2}\pi i$ and eigenvectors: $$(1,\sqrt{2}i),(1,-\sqrt{2} i)$$ So we have: $$\begin{bmatrix}a^1\\a^2\end{bmatrix} = e^{\sqrt{2}\pi i t}\begin{bmatrix}1\\\sqrt{2}i\end{bmatrix} + e^{-\sqrt{2}\pi i}\begin{bmatrix}1\\-\sqrt{2}i\end{bmatrix}$$ So $$a^1=\cos(\sqrt{2}\pi t) + i\sin(\sqrt{2}\pi t)+\cos(-\sqrt{2}\pi t) + i\sin(-\sqrt{2}\pi t)$$ $$=2\cos(\sqrt{2}\pi t)$$ Made an error apparently. Is this now the right method? Or something is still wrong?","Context: Past exam for class that I sit my final for tomorrow :). We are in a $2$-dimensional surface, with coordinates $(\theta,\phi)$. Consider the metric $ds^2 = r_0^2 d\theta^2 + r_0^2 \sin^2(\theta)d\phi^2$ I have shown that the only non-zero Christoffel symbols are: $$\Gamma_{12}^{\,\,\, 2}=\Gamma_{21}^{\,\,\, 2}=\cot(\theta),\qquad \Gamma_{22}^{\,\,\, 1}=-\sin(\theta)\cos(\theta)$$ I want to show that if a contravariant vector $a^i$ undergoes parallel transport around the circle from $\theta = \pi/4$ from $\phi=0$ to $\phi=2\pi$ and $a^1=0$, $a^2=1$ at $\phi=0$ then at $\phi=2\pi$ we have: $$a^1 = \frac{\sqrt{2}}{2}\sin(\sqrt{2}\pi),\qquad a^2=\cos(\sqrt{2}\pi)$$ My attempt: We have that $$0=\frac{Da^\lambda}{Dt}=\frac{da^\lambda}{dt}+\Gamma_{\mu\nu}^{\,\,\, \lambda}a^\mu \frac{dx^\nu}{dt}$$ (where $x^1=\theta,x^2=\phi$ is convention, and does not refer to cartesian coordinates). So I have: $$\dot{a}^1=-\Gamma_{\mu\nu}^{\,\,\, 1}a^\mu \dot{x}^\nu=\sin(\theta)\cos(\theta)a^2 \dot{\phi}$$ $$\dot{a}^2=-\Gamma_{\mu\nu}^{\,\,\,2}a^\mu \dot{x}^\nu=-\cot(\theta)(a^1\dot{\phi}+a^2\dot{\theta})$$ Now since $\theta$ stays constant, we have $\theta=\frac{\pi}{4}$ and  $\dot{\theta}=0$, and so the above refines to: $$\dot{a}^1=-\Gamma_{\mu\nu}^{\,\,\, 1}a^\mu \dot{x}^\nu=\frac12a^2 \dot{\phi}$$ $$\dot{a}^2=-\Gamma_{\mu\nu}^{\,\,\,2}a^\mu \dot{x}^\nu=-(a^1\dot{\phi})$$ What to do with $\dot{\phi}$? Should I parametrize $\phi$? Say we take $\phi(t) = 2\pi t$ so that this moves along a circle over $t\in [0,1]$, then we have: $\dot{\phi}=2\pi$ and hence: $$\dot{a}^1=-\Gamma_{\mu\nu}^{\,\,\, 1}a^\mu \dot{x}^\nu=\frac12a^2 2\pi$$ $$\dot{a}^2=-\Gamma_{\mu\nu}^{\,\,\,2}a^\mu \dot{x}^\nu=-(a^12\pi)$$ So we have: $$\begin{bmatrix}\dot{a}^1\\\dot{a}^2\end{bmatrix} = \begin{bmatrix}0&\pi \\-2\pi&0\end{bmatrix}\begin{bmatrix}a^1\\a^2\end{bmatrix}$$ and solve this in the classical way: Eigenvalues are $\pm \sqrt{2}\pi i$ and eigenvectors: $$(1,\sqrt{2}i),(1,-\sqrt{2} i)$$ So we have: $$\begin{bmatrix}a^1\\a^2\end{bmatrix} = e^{\sqrt{2}\pi i t}\begin{bmatrix}1\\\sqrt{2}i\end{bmatrix} + e^{-\sqrt{2}\pi i}\begin{bmatrix}1\\-\sqrt{2}i\end{bmatrix}$$ So $$a^1=\cos(\sqrt{2}\pi t) + i\sin(\sqrt{2}\pi t)+\cos(-\sqrt{2}\pi t) + i\sin(-\sqrt{2}\pi t)$$ $$=2\cos(\sqrt{2}\pi t)$$ Made an error apparently. Is this now the right method? Or something is still wrong?",,"['ordinary-differential-equations', 'differential-geometry', 'proof-verification', 'parametric', 'transport-equation']"
96,differential equation with linear coefficients other answer than in book,differential equation with linear coefficients other answer than in book,,"I have a differential equation: $$ (x+2y-4)dx +(-2x+4y)dy = 0 $$ Since the coefficients of $dx$ and $dy$ are assumed to define line in the plain, so: $$ 7y -3 = 0 $$ $$ 2x+1 = 0 $$ Point od the intersection of these lines is:$ (x,y) = (2,1)  $ Next, I'm trying to move origin of the plain to the intesection point. We know that relations between coordinates are: $$ x = \bar{x} +2  $$ $$ y = \bar{y} +1 $$ where  $\bar{x}$, $\bar{y}$ are coordinates measured from point $ (2,1)$ After substitution these relations, equation simplifices to form: $$ (\bar{x} + 2 \bar{y})d\bar{x} + (-2\bar{x}+4\bar{y})d\bar{y} =0  $$ Now I'm trying to do substitution: $$ \bar{x} = u \bar{y}, d\bar{x} = u d\bar{y} + \bar{y}du $$ So after substitution and simplifications I'm obtaining: $$ (u^{2} + 4) \bar{y}d\bar{y} + (u+2)\bar{y}^2 du  = 0$$ Now, I'm dividing equation both sides by $(u^2+4)(\bar{y}^2)$ and I'm obtaining equation with separable variables: $$ \frac{d\bar{y}}{\bar{y}} + \frac{u+2}{u^2+4}du = 0 $$ Because:  $$ \int \frac{u+2}{u^2+4} = arctan(\frac{u}{2}) + \frac{1}{2} ln|4+u^2| + C$$ So, I have a solution: $$ ln|\bar{y}| + arctan(\frac{u}{2})+ \frac{1}{2}ln|(4+u^2)| = C  $$ After substitution relationship between $\bar{x},x$ and $\bar{y},y$ and simplifications, I'm obtaining: $$   ln|4(y-1)^{2} + (x-2)^2| + 2 arctan(\frac{x-2}{2y-2}) = C  $$ Now I have a problem because answer from book to this exercise is: $$   ln|4(y-1)^{2} + (x-2)^2| -2  arctan(\frac{2y-2}{x-2})+= C  $$ I've check that this solutions we may obtain with substitution: $$ \bar{y} = u\bar{x}, d\bar{y} = u d \bar{x} + \bar{x}du $$ Is my answer wrong? I would be grateful for explaining. Best regards","I have a differential equation: $$ (x+2y-4)dx +(-2x+4y)dy = 0 $$ Since the coefficients of $dx$ and $dy$ are assumed to define line in the plain, so: $$ 7y -3 = 0 $$ $$ 2x+1 = 0 $$ Point od the intersection of these lines is:$ (x,y) = (2,1)  $ Next, I'm trying to move origin of the plain to the intesection point. We know that relations between coordinates are: $$ x = \bar{x} +2  $$ $$ y = \bar{y} +1 $$ where  $\bar{x}$, $\bar{y}$ are coordinates measured from point $ (2,1)$ After substitution these relations, equation simplifices to form: $$ (\bar{x} + 2 \bar{y})d\bar{x} + (-2\bar{x}+4\bar{y})d\bar{y} =0  $$ Now I'm trying to do substitution: $$ \bar{x} = u \bar{y}, d\bar{x} = u d\bar{y} + \bar{y}du $$ So after substitution and simplifications I'm obtaining: $$ (u^{2} + 4) \bar{y}d\bar{y} + (u+2)\bar{y}^2 du  = 0$$ Now, I'm dividing equation both sides by $(u^2+4)(\bar{y}^2)$ and I'm obtaining equation with separable variables: $$ \frac{d\bar{y}}{\bar{y}} + \frac{u+2}{u^2+4}du = 0 $$ Because:  $$ \int \frac{u+2}{u^2+4} = arctan(\frac{u}{2}) + \frac{1}{2} ln|4+u^2| + C$$ So, I have a solution: $$ ln|\bar{y}| + arctan(\frac{u}{2})+ \frac{1}{2}ln|(4+u^2)| = C  $$ After substitution relationship between $\bar{x},x$ and $\bar{y},y$ and simplifications, I'm obtaining: $$   ln|4(y-1)^{2} + (x-2)^2| + 2 arctan(\frac{x-2}{2y-2}) = C  $$ Now I have a problem because answer from book to this exercise is: $$   ln|4(y-1)^{2} + (x-2)^2| -2  arctan(\frac{2y-2}{x-2})+= C  $$ I've check that this solutions we may obtain with substitution: $$ \bar{y} = u\bar{x}, d\bar{y} = u d \bar{x} + \bar{x}du $$ Is my answer wrong? I would be grateful for explaining. Best regards",,"['ordinary-differential-equations', 'homogeneous-equation']"
97,Show that $f$ & $g$ is a solution to the below differential equation!,Show that  &  is a solution to the below differential equation!,f g,"$\frac{dy}{dx}+P(x)y=0$ Show that if f and g are solutions to the differential equation where $c_1$ and $c_2$ are arbitrary constants then $c_1f$ & $c_2g$ are also solution to the differential equation My attempt  Since this equation is separable therefore, $P(x)dx+\frac{dy}{y}=0$ By This differential equation must be exact! $\frac{\partial P(x)}{\partial y}=\frac{\partial y^{-1}}{\partial x}=0$ $\int_{} P(x)=f+g+c_1$ $\int_{}  \frac{1} {y} =lny+c_2$ I know this is lousy. Can someone guide me?","$\frac{dy}{dx}+P(x)y=0$ Show that if f and g are solutions to the differential equation where $c_1$ and $c_2$ are arbitrary constants then $c_1f$ & $c_2g$ are also solution to the differential equation My attempt  Since this equation is separable therefore, $P(x)dx+\frac{dy}{y}=0$ By This differential equation must be exact! $\frac{\partial P(x)}{\partial y}=\frac{\partial y^{-1}}{\partial x}=0$ $\int_{} P(x)=f+g+c_1$ $\int_{}  \frac{1} {y} =lny+c_2$ I know this is lousy. Can someone guide me?",,"['ordinary-differential-equations', 'proof-writing']"
98,"prove that every solution of analytic ODE x˙=f(x,t) is analytic","prove that every solution of analytic ODE x˙=f(x,t) is analytic",,"i have searched in many books but i did not find a proof for the statement in the title.  I know its linked with Cauchy's theorem, but i need a full and reasoned proof. Thanks.","i have searched in many books but i did not find a proof for the statement in the title.  I know its linked with Cauchy's theorem, but i need a full and reasoned proof. Thanks.",,"['real-analysis', 'functional-analysis', 'ordinary-differential-equations', 'analytic-functions']"
99,Differential equation....,Differential equation....,,"Let y(x) be the continuous solution of the initial value problem,  $$\frac{dy} {dx}  + 2y=f(x)$$,  $y(0)=0$ where  $$f(x) =\begin{cases} 1&\text{if  }x\in[0,1]\\0&\text{if  }x>1\end{cases}$$  then find $$y(\frac{3}{2})$$ This question has been asked in net csir 2015..... And I am not able to solve it.... Please guide me.... in solving the integral we arrive at after taking integrating factor which is $e^{2x} $ and then we get the solution as $$e^{2x}. y=\int f(x). e^{2x} dx + c$$ where c is arbitrary constant....  Please help me to solve this further....","Let y(x) be the continuous solution of the initial value problem,  $$\frac{dy} {dx}  + 2y=f(x)$$,  $y(0)=0$ where  $$f(x) =\begin{cases} 1&\text{if  }x\in[0,1]\\0&\text{if  }x>1\end{cases}$$  then find $$y(\frac{3}{2})$$ This question has been asked in net csir 2015..... And I am not able to solve it.... Please guide me.... in solving the integral we arrive at after taking integrating factor which is $e^{2x} $ and then we get the solution as $$e^{2x}. y=\int f(x). e^{2x} dx + c$$ where c is arbitrary constant....  Please help me to solve this further....",,['ordinary-differential-equations']
