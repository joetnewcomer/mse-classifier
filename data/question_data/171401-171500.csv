,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"What is the conditional probability that the number of heads equals the number showing on the die, conditional on knowing that the die showed 1?","What is the conditional probability that the number of heads equals the number showing on the die, conditional on knowing that the die showed 1?",,"Suppose we flip two fair coins and roll one fair six-sided die. What is the conditional probability that the number of heads equals the number showing on the die, conditional on knowing that the die showed 1? Let's define the following: $A=\{\text{#H = # on die}\}$ $B=\{\text{# on die = 1}\}$ We want to find: $P(A|B)=\dfrac{P(A\cap B)}{P(B)}=\dfrac{P(\{\text{#H = # on die}\} \cap \{\text{# on die = 1}\})}{P(\{\text{# on die = 1}\})}$ I drew a tree diagram to help me: Basically we toss two coins, and the final toss can match with either number on the dice. Now $P(B)=1/6=(1/2)(1/2)(1/6)(4)$ For the numerator, we want $\{\text{#H = # on die}\} \cap \{\text{# on die = 1}\}$. The more restrictive here is that the die must roll a 1: The orange show the only two paths that are the intersection. This equals $(2)(1/2)(1/2)(1/6)=1/12$ Therefore our $P(A|B)=(1/12)/(1/6)=(1/2)$ as our final answer. Is this correct? I'm wondering if it makes sense because the dice rolled a $1$, and there are only two options on a coin, that thus the 50/50.","Suppose we flip two fair coins and roll one fair six-sided die. What is the conditional probability that the number of heads equals the number showing on the die, conditional on knowing that the die showed 1? Let's define the following: $A=\{\text{#H = # on die}\}$ $B=\{\text{# on die = 1}\}$ We want to find: $P(A|B)=\dfrac{P(A\cap B)}{P(B)}=\dfrac{P(\{\text{#H = # on die}\} \cap \{\text{# on die = 1}\})}{P(\{\text{# on die = 1}\})}$ I drew a tree diagram to help me: Basically we toss two coins, and the final toss can match with either number on the dice. Now $P(B)=1/6=(1/2)(1/2)(1/6)(4)$ For the numerator, we want $\{\text{#H = # on die}\} \cap \{\text{# on die = 1}\}$. The more restrictive here is that the die must roll a 1: The orange show the only two paths that are the intersection. This equals $(2)(1/2)(1/2)(1/6)=1/12$ Therefore our $P(A|B)=(1/12)/(1/6)=(1/2)$ as our final answer. Is this correct? I'm wondering if it makes sense because the dice rolled a $1$, and there are only two options on a coin, that thus the 50/50.",,"['probability', 'statistics', 'conditional-probability']"
1,Deviation of empirical average from the mean for the fourth moment,Deviation of empirical average from the mean for the fourth moment,,"Suppose that $\{ X_n \}_{n \in \mathbb{N}}$ is a sequence of real i.i.d. random variables  (with finite fourth order moments) with mean $\mu$. We want to show that there exists a constant $C>0$ (independent of $N$) such that $$ \mathbb{E} \bigg[ \bigg( \frac{1}{N} \sum_{i=1}^N X_i - \mu \bigg)^4 \bigg] \leq C N^{-2}. $$ By direct expansion, we get \begin{eqnarray}  \mathbb{E} \bigg[ \bigg( \frac{1}{N} \sum_{i=1}^N X_i - \mu \bigg)^4 \bigg] & = & \mathbb{E} \bigg[ \bigg( \frac{1}{N} \sum_{i=1}^N X_i  \bigg)^4 \bigg] - 4 \mathbb{E} \bigg[ \bigg( \frac{1}{N} \sum_{i=1}^N X_i \bigg)^3 \mu \bigg] \nonumber \\ &  & +6 \mathbb{E} \bigg[ \bigg( \frac{1}{N} \sum_{i=1}^N X_i  \bigg)^2 \mu^2 \bigg] - 4 \mathbb{E} \bigg[ \bigg( \frac{1}{N} \sum_{i=1}^N X_i  \bigg) \mu^3 \bigg] + \mu^4. \end{eqnarray} Clearly, by independence, the first two terms converge in $N$ with the order $O(N^{-3})$ and $O(N^{-2})$ respectively. But how about the remaining terms?  Any ideas?","Suppose that $\{ X_n \}_{n \in \mathbb{N}}$ is a sequence of real i.i.d. random variables  (with finite fourth order moments) with mean $\mu$. We want to show that there exists a constant $C>0$ (independent of $N$) such that $$ \mathbb{E} \bigg[ \bigg( \frac{1}{N} \sum_{i=1}^N X_i - \mu \bigg)^4 \bigg] \leq C N^{-2}. $$ By direct expansion, we get \begin{eqnarray}  \mathbb{E} \bigg[ \bigg( \frac{1}{N} \sum_{i=1}^N X_i - \mu \bigg)^4 \bigg] & = & \mathbb{E} \bigg[ \bigg( \frac{1}{N} \sum_{i=1}^N X_i  \bigg)^4 \bigg] - 4 \mathbb{E} \bigg[ \bigg( \frac{1}{N} \sum_{i=1}^N X_i \bigg)^3 \mu \bigg] \nonumber \\ &  & +6 \mathbb{E} \bigg[ \bigg( \frac{1}{N} \sum_{i=1}^N X_i  \bigg)^2 \mu^2 \bigg] - 4 \mathbb{E} \bigg[ \bigg( \frac{1}{N} \sum_{i=1}^N X_i  \bigg) \mu^3 \bigg] + \mu^4. \end{eqnarray} Clearly, by independence, the first two terms converge in $N$ with the order $O(N^{-3})$ and $O(N^{-2})$ respectively. But how about the remaining terms?  Any ideas?",,"['probability', 'statistics', 'sampling', 'central-limit-theorem', 'expected-value']"
2,Expectation $T(T-1)$ where $T$ is the sample mean of i.i.d. Bernoulli random numbers,Expectation  where  is the sample mean of i.i.d. Bernoulli random numbers,T(T-1) T,"I want the expectation of $T(T-1)$ where $T$ is the sample mean of i.i.d. Bernoulli random variables with parameter $p$. Using the linearity property, we have  $$\mathbb E\{T(T - 1)\} = \mathbb E(T^2) - \mathbb E(T).$$ Since $\mathbb E(T) = p$ and $\mathbb E(T^2) = \tfrac{p(1-p)}{n} + p^2$, I believe the answer should be $\tfrac{p^2(n-1)}{n} - \tfrac{p(n-1)}{n}$ but in my notes it says that the expectation is $n(n-1)p^2$. Are my notes incorrect or did I make an error? Thanks.","I want the expectation of $T(T-1)$ where $T$ is the sample mean of i.i.d. Bernoulli random variables with parameter $p$. Using the linearity property, we have  $$\mathbb E\{T(T - 1)\} = \mathbb E(T^2) - \mathbb E(T).$$ Since $\mathbb E(T) = p$ and $\mathbb E(T^2) = \tfrac{p(1-p)}{n} + p^2$, I believe the answer should be $\tfrac{p^2(n-1)}{n} - \tfrac{p(n-1)}{n}$ but in my notes it says that the expectation is $n(n-1)p^2$. Are my notes incorrect or did I make an error? Thanks.",,"['probability', 'statistics', 'random-variables', 'expected-value']"
3,Probability of exactly $2$ aces within first $5$ cards?,Probability of exactly  aces within first  cards?,2 5,"Every person gets $5$ cards from a deck of cards ($52$). What is the probability that the first $5$ cards will contain exactly $2$ aces? I have tried to calculate it by $\frac{5}{52} \times \frac{5}{47} = \frac{25}{2444}$. I know my answer is incorrect, but I dont know how I should approach this.","Every person gets $5$ cards from a deck of cards ($52$). What is the probability that the first $5$ cards will contain exactly $2$ aces? I have tried to calculate it by $\frac{5}{52} \times \frac{5}{47} = \frac{25}{2444}$. I know my answer is incorrect, but I dont know how I should approach this.",,"['probability', 'statistics']"
4,Sufficient Statistics: Proof of a lemma by Halmos and Savage,Sufficient Statistics: Proof of a lemma by Halmos and Savage,,"I am reading the paper ""Application of the Radon-Nikodym Theorem to the Theory of Sufficient Statistics"" by Halmos and Savage and have much trouble following the proof of Lemma 7. Below is (my paraphrase of) the statement of the lemma and its proof. Lemma: Let $\mathcal{P}$ be a family of probability measures on the measurable space $(\Omega, \mathcal{F})$. If $\mathcal{P}$ is dominated by a finite measure $\nu$ (i.e. $\mathbb{P} \ll \nu$ for all $\mathbb{P}\in\mathcal{P}$), then there exists a countable subset $\mathcal{P}_0\subset\mathcal{P}$ such that for every $A\in\mathcal{F}$, $\mathbb{P}_0(A)=0$ for all $\mathbb{P}_0\in\mathcal{P}_0$ implies $\mathbb{P}(A)=0$ for all $\mathbb{P}\in\mathcal{P}$. The proof provided in the paper is as follows. Define the collection of sets $\mathcal{K}$ like so: We say that the $\mathcal{F}$-measurable set $K\in\mathcal{K}$ if and only if there exists some $\mathbb{P}\in\mathcal{P}$ corresponding to this $K$ such that $\mathbb{P}(K)>0$ and $\frac{d\mathbb{P}}{d\nu}>0$ on $K$. Let $\mathcal{C}$ be the collection of all sets of the form $\dot{\bigcup}^\infty_{i=1}K_i$, where $(K_i)^\infty_{i=1}\subset\mathcal{K}$ are disjoint. Then it can be shown that $\mathcal{C}$ is closed under countable unions. We now construct our countable subset $\mathcal{P}_0$. Choose a sequence $(C_i)^\infty_{i=1}\subset\mathcal{C}$ such that $\nu(C_i)\to\sup_{C\in\mathcal{C}}\nu(C)$ and let $C$ be the union of the $C_i$s. Then since $\mathcal{C}$ is closed under countable unions, $C\in\mathcal{C}$ and there exists $(K_i)^\infty_{i=1}\subset\mathcal{K}$ such that $C=\dot{\bigcup}^\infty_{i=1}K_i$. We then let $\mathcal{P}_0=\{\mathbb{P}_1, \mathbb{P}_2,\cdots\}$, where each $\mathbb{P}_i$ is the probability measure corresponding to $K_i$. Let $A\in\mathcal{F}$ be such that $\mathbb{P}_i(A)=0$ for each $i$ and $\mathbb{P}$ be any probability measure in $\mathcal{P}$. Denote $B=\{\omega\in\Omega: \frac{d\mathbb{P}}{d\nu}(\omega)>0\}$ Since $\color{red}{\mathbb{P}(A\cap B^c)=0}$, we may assume WLOG that $A\subset B$. It remains to show $\mathbb{P}(A)=0$. We first show that $\mathbb{P}(A\cap C^c)=0$. Suppose not. Then $\nu(A\cap C^c)>0$ and therefore, because $\color{red}{A\cap C^c\in\mathcal{K}}$, $\color{red}{A\cup C\in\mathcal{C}}$ with $\color{red}{\nu(A\cup C)>\nu(C)}$, contradicting the maximality of $\nu(C)$. Hence $\mathbb{P}(A\cap C^c)=0$. Finally we show also that $\mathbb{P}(A\cap C)=0$. By $\sigma$-additivity and the fact that $\mathbb{P} \ll \nu$, this follows if we can show that $\nu(A\cap K_i)=0$ for every i. But this is true since $0 = \mathbb{P}_i(A\cap K_i) = \int_{A\cap K_i} \frac{d\mathbb{P}_i}{d\nu} d\nu$ and $\frac{d\mathbb{P}_i}{d\nu}$ is strictly positive on $A\cap K_i$. This completes the proof. I am most definitely missing many obvious things but I am unable to grasp nor understand why the following claims are true: $\mathbb{P}(A\cap B^c)=0$ ${A\cap C^c\in\mathcal{K}}$ $A\cup C\in\mathcal{C}$ $\nu(A\cup C)$ is strictly greater than $\nu(C)$ The motivation behind the construction of $\mathcal{P}_0$ I would appreciate it if anyone could enlighten me on this. Thank you!","I am reading the paper ""Application of the Radon-Nikodym Theorem to the Theory of Sufficient Statistics"" by Halmos and Savage and have much trouble following the proof of Lemma 7. Below is (my paraphrase of) the statement of the lemma and its proof. Lemma: Let $\mathcal{P}$ be a family of probability measures on the measurable space $(\Omega, \mathcal{F})$. If $\mathcal{P}$ is dominated by a finite measure $\nu$ (i.e. $\mathbb{P} \ll \nu$ for all $\mathbb{P}\in\mathcal{P}$), then there exists a countable subset $\mathcal{P}_0\subset\mathcal{P}$ such that for every $A\in\mathcal{F}$, $\mathbb{P}_0(A)=0$ for all $\mathbb{P}_0\in\mathcal{P}_0$ implies $\mathbb{P}(A)=0$ for all $\mathbb{P}\in\mathcal{P}$. The proof provided in the paper is as follows. Define the collection of sets $\mathcal{K}$ like so: We say that the $\mathcal{F}$-measurable set $K\in\mathcal{K}$ if and only if there exists some $\mathbb{P}\in\mathcal{P}$ corresponding to this $K$ such that $\mathbb{P}(K)>0$ and $\frac{d\mathbb{P}}{d\nu}>0$ on $K$. Let $\mathcal{C}$ be the collection of all sets of the form $\dot{\bigcup}^\infty_{i=1}K_i$, where $(K_i)^\infty_{i=1}\subset\mathcal{K}$ are disjoint. Then it can be shown that $\mathcal{C}$ is closed under countable unions. We now construct our countable subset $\mathcal{P}_0$. Choose a sequence $(C_i)^\infty_{i=1}\subset\mathcal{C}$ such that $\nu(C_i)\to\sup_{C\in\mathcal{C}}\nu(C)$ and let $C$ be the union of the $C_i$s. Then since $\mathcal{C}$ is closed under countable unions, $C\in\mathcal{C}$ and there exists $(K_i)^\infty_{i=1}\subset\mathcal{K}$ such that $C=\dot{\bigcup}^\infty_{i=1}K_i$. We then let $\mathcal{P}_0=\{\mathbb{P}_1, \mathbb{P}_2,\cdots\}$, where each $\mathbb{P}_i$ is the probability measure corresponding to $K_i$. Let $A\in\mathcal{F}$ be such that $\mathbb{P}_i(A)=0$ for each $i$ and $\mathbb{P}$ be any probability measure in $\mathcal{P}$. Denote $B=\{\omega\in\Omega: \frac{d\mathbb{P}}{d\nu}(\omega)>0\}$ Since $\color{red}{\mathbb{P}(A\cap B^c)=0}$, we may assume WLOG that $A\subset B$. It remains to show $\mathbb{P}(A)=0$. We first show that $\mathbb{P}(A\cap C^c)=0$. Suppose not. Then $\nu(A\cap C^c)>0$ and therefore, because $\color{red}{A\cap C^c\in\mathcal{K}}$, $\color{red}{A\cup C\in\mathcal{C}}$ with $\color{red}{\nu(A\cup C)>\nu(C)}$, contradicting the maximality of $\nu(C)$. Hence $\mathbb{P}(A\cap C^c)=0$. Finally we show also that $\mathbb{P}(A\cap C)=0$. By $\sigma$-additivity and the fact that $\mathbb{P} \ll \nu$, this follows if we can show that $\nu(A\cap K_i)=0$ for every i. But this is true since $0 = \mathbb{P}_i(A\cap K_i) = \int_{A\cap K_i} \frac{d\mathbb{P}_i}{d\nu} d\nu$ and $\frac{d\mathbb{P}_i}{d\nu}$ is strictly positive on $A\cap K_i$. This completes the proof. I am most definitely missing many obvious things but I am unable to grasp nor understand why the following claims are true: $\mathbb{P}(A\cap B^c)=0$ ${A\cap C^c\in\mathcal{K}}$ $A\cup C\in\mathcal{C}$ $\nu(A\cup C)$ is strictly greater than $\nu(C)$ The motivation behind the construction of $\mathcal{P}_0$ I would appreciate it if anyone could enlighten me on this. Thank you!",,"['real-analysis', 'probability-theory', 'statistics', 'measure-theory', 'statistical-inference']"
5,upper bound for variance when using estimated values,upper bound for variance when using estimated values,,"Let’s say I have a parameterspace $\Omega$ with known probability density function $p(\omega), \omega \in \Omega$. I want to estimate the expectation $E[x]$ of a variable $x$ depending on $\omega \in \Omega$.  I cannot calculate directly $x$ but I can make an estimation $\tilde{x}$ such that $\tilde{x}- x \leq \epsilon, \epsilon >  0$ and $x \leq \tilde{x}$. It’s easy to prove that $|E[\tilde{x}] – E[x]| \leq \epsilon$. Is there a way to calculate a similar upper bound for  $|Var[\tilde{x}] – Var[x] |$? Kind regards, Koen","Let’s say I have a parameterspace $\Omega$ with known probability density function $p(\omega), \omega \in \Omega$. I want to estimate the expectation $E[x]$ of a variable $x$ depending on $\omega \in \Omega$.  I cannot calculate directly $x$ but I can make an estimation $\tilde{x}$ such that $\tilde{x}- x \leq \epsilon, \epsilon >  0$ and $x \leq \tilde{x}$. It’s easy to prove that $|E[\tilde{x}] – E[x]| \leq \epsilon$. Is there a way to calculate a similar upper bound for  $|Var[\tilde{x}] – Var[x] |$? Kind regards, Koen",,"['probability', 'statistics']"
6,approximation to standard normal distribution,approximation to standard normal distribution,,"I have a sequence of independent, but non-identically distributed Bernoulli random variables $X_i$'s taking on value $1$ with probability $p_{i1}\cdot p_{i2}$, where $i=1,\ldots,n$. Let $X=\sum_{i=1}^n X_i$. Using  Lyapunov central limit theorem, I have approximated the probability $\Pr[X \geq k]$ by standard normal distribution. However, for some values of $k$ the approximated value is not close to the exact value. I wanted to ask that why this happens? Thanks in advance for your help.","I have a sequence of independent, but non-identically distributed Bernoulli random variables $X_i$'s taking on value $1$ with probability $p_{i1}\cdot p_{i2}$, where $i=1,\ldots,n$. Let $X=\sum_{i=1}^n X_i$. Using  Lyapunov central limit theorem, I have approximated the probability $\Pr[X \geq k]$ by standard normal distribution. However, for some values of $k$ the approximated value is not close to the exact value. I wanted to ask that why this happens? Thanks in advance for your help.",,"['statistics', 'normal-distribution', 'central-limit-theorem']"
7,Estimate degrees of freedom in sample variance.,Estimate degrees of freedom in sample variance.,,"Given a sequence of independent identically distributed random variables $X_1,\ldots,X_m \sim \chi^2_n / n$ is there literature on estimates for the degrees of freedom $n$? In an attempt to find the MLE I calculated the roots of the log likelihood function assuming continuous values of $n$. This tells us that $n$ should satisfy $$2\frac{1}{n} - \psi(n) = \log \left( \sqrt{2}\prod_{i=1}^m x_i^{\frac{1}{m}} \right) $$ where $\psi$ denotes the digamma function. This estimate is not quite as insightful as I'd hoped. An easy estimate is simply noting that $\operatorname{Var}(\chi^2_n / n) = 2/n$. However, I don't know whether this will actually be a good estimate in practice.","Given a sequence of independent identically distributed random variables $X_1,\ldots,X_m \sim \chi^2_n / n$ is there literature on estimates for the degrees of freedom $n$? In an attempt to find the MLE I calculated the roots of the log likelihood function assuming continuous values of $n$. This tells us that $n$ should satisfy $$2\frac{1}{n} - \psi(n) = \log \left( \sqrt{2}\prod_{i=1}^m x_i^{\frac{1}{m}} \right) $$ where $\psi$ denotes the digamma function. This estimate is not quite as insightful as I'd hoped. An easy estimate is simply noting that $\operatorname{Var}(\chi^2_n / n) = 2/n$. However, I don't know whether this will actually be a good estimate in practice.",,"['probability', 'statistics', 'reference-request', 'statistical-inference', 'parameter-estimation']"
8,"How to show $\operatorname{Cov}(b_0,b_1)=-\frac{\sigma\bar{x}}{S_{xx}}$",How to show,"\operatorname{Cov}(b_0,b_1)=-\frac{\sigma\bar{x}}{S_{xx}}","Consider the equation $y_i=\beta_0+\beta_1x_i+\epsilon_i$ for $i=1, \dotsc, n$. We have unbiased estimators $b_0$ and $b_1$ for $\beta_0$ and $\beta_1$ respectively, where $b_0=\bar{y}-b_1\bar{x}$ and $b_1= S_{xy} / S_{xx}$. How does one show that $\operatorname{Cov}(b_0,b_1)=-\frac{\sigma\bar{x}}{S_{xx}}$ I tried using $\operatorname{Cov}(b_0,b_1)=E(b_0b_1)-E(b_0)E(b_1)$ to no avail as it just equals $0$ when I try and do that. Thanks!","Consider the equation $y_i=\beta_0+\beta_1x_i+\epsilon_i$ for $i=1, \dotsc, n$. We have unbiased estimators $b_0$ and $b_1$ for $\beta_0$ and $\beta_1$ respectively, where $b_0=\bar{y}-b_1\bar{x}$ and $b_1= S_{xy} / S_{xx}$. How does one show that $\operatorname{Cov}(b_0,b_1)=-\frac{\sigma\bar{x}}{S_{xx}}$ I tried using $\operatorname{Cov}(b_0,b_1)=E(b_0b_1)-E(b_0)E(b_1)$ to no avail as it just equals $0$ when I try and do that. Thanks!",,"['statistics', 'regression', 'covariance']"
9,Sampling Distribution of Variances,Sampling Distribution of Variances,,"Please consider this problem and my solution to it. I get the feeling, my approach is way off. Problem: A normal population has a variance of $15$. If samples of size $5$ are drawn from this population, what percentage an be expected to have variances less than $10$. Answer The sample variance has a chi-square distribution with $4$ degrees of freedom. Also observe that $\frac{10}{15} = 0.666667$. That is, you need to adjust for the population variance. I then went to this website: https://stattrek.com/online-calculator/chi-square.aspx and I entered $4$ for the degrees of freedom and $0.666667$ for the Chi-Square critical value. I then got an answer of $0.05$ but the book gets an answer of $0.50$. What did I do wrong? Thanks, Bob","Please consider this problem and my solution to it. I get the feeling, my approach is way off. Problem: A normal population has a variance of $15$. If samples of size $5$ are drawn from this population, what percentage an be expected to have variances less than $10$. Answer The sample variance has a chi-square distribution with $4$ degrees of freedom. Also observe that $\frac{10}{15} = 0.666667$. That is, you need to adjust for the population variance. I then went to this website: https://stattrek.com/online-calculator/chi-square.aspx and I entered $4$ for the degrees of freedom and $0.666667$ for the Chi-Square critical value. I then got an answer of $0.05$ but the book gets an answer of $0.50$. What did I do wrong? Thanks, Bob",,"['probability', 'statistics']"
10,Prove that the standard deviation is less than half the range,Prove that the standard deviation is less than half the range,,"Taken from ""An Introduction to Quantum Physics"" by Stefanas Trachanas (Question 2.4). I need to prove that for an arbitrary statistical distribution: $$ \Delta A ≤ \frac{|a_{max}-a_{min}|}{2} $$ Where $a_{min}$ & $a_{max}$ are the minimum & maximum possible values of the distribution,respectively. I have proved this for 2 special cases: The case in which the mean is at the centre of the range, & the case with only two possible outcomes. How do I prove the general case?","Taken from ""An Introduction to Quantum Physics"" by Stefanas Trachanas (Question 2.4). I need to prove that for an arbitrary statistical distribution: $$ \Delta A ≤ \frac{|a_{max}-a_{min}|}{2} $$ Where $a_{min}$ & $a_{max}$ are the minimum & maximum possible values of the distribution,respectively. I have proved this for 2 special cases: The case in which the mean is at the centre of the range, & the case with only two possible outcomes. How do I prove the general case?",,"['statistics', 'inequality', 'standard-deviation']"
11,Coefficient of Determination and Correlation between observed and fitted value in Multiple Linear Regression.,Coefficient of Determination and Correlation between observed and fitted value in Multiple Linear Regression.,,"Consider Multiple Linear Model $$y= X\beta + \epsilon$$ Then using Ordinary Least Square, we get estimate of $\beta$ as $$\hat{\beta} = (X'X)^{-1}X'y$$ And $$\hat{y} = X\hat{\beta}$$ $$SS_{\rm Res}= (y-X\hat{\beta})'(y-X\hat{\beta})$$ $$R^2= 1-\frac{SS_{\rm Res}}{SS_{\rm Total}}  $$ From here how can we show $$R^2 = (\operatorname{Correlation} ( y, \hat{y}))^2$$ This can be easily shown in Simple Linear Model as there is only One explanatory variable but I am not able to show this in Multiple Linear Model.","Consider Multiple Linear Model Then using Ordinary Least Square, we get estimate of as And From here how can we show This can be easily shown in Simple Linear Model as there is only One explanatory variable but I am not able to show this in Multiple Linear Model.","y= X\beta + \epsilon \beta \hat{\beta} = (X'X)^{-1}X'y \hat{y} = X\hat{\beta} SS_{\rm Res}= (y-X\hat{\beta})'(y-X\hat{\beta}) R^2= 1-\frac{SS_{\rm Res}}{SS_{\rm Total}}   R^2 = (\operatorname{Correlation} ( y, \hat{y}))^2","['linear-algebra', 'statistics', 'correlation', 'linear-regression']"
12,Probabilities regarding casino slot machine,Probabilities regarding casino slot machine,,"Exercise : A casino slot machine has been programmed so as to offer total winnings $X$ euros per hour, regardless of other hours, with $μ_x = E[X] = 180$ and $σ_x = V[X] = 10.125$ . From long term data we know that the value $Y$ in euros that players bet per hour (independent of the values that are played at other hours and the winnings values) follows the uniform distribution over the interval $[100,300]$ . (a) Calculate approximately the probability that in the duration of one month the slot machine has yielded total winnings of over $135.000$ euros. (b) Calculate approximatel the probability that in the duration of one month the clear profit of the casino is over $10.000$ euros. (c) Let it be that we want to change the parameter $\sigma$ in the program of the slot machine. What is the biggest value of $\sigma$ for which the clear profit that the slot machine yields for the casino is over $10.000$ with probability at least $95%$ ? (Suppose that the casino operates the 24hrs per day and that every month has 30 days). Attempt - Question : (a) Since we are asked to calculate the probability of winnings over the course of one month, we should multiply the variable $X$ by $24 \cdot 30 = 720$ . Thus, what we need to find, is : $$P[720X > 135.000] = 1 - P[720X \leq 135.000] = 1 - P[X \leq 187.5] = 1 - P[X-180 \leq 7.5] = 1 - P\bigg[\frac{X-180}{45\sqrt{5}} \leq \frac{7.5}{45\sqrt{5}}\bigg] = 1 - P\bigg[Z \leq \frac{7.5}{45\sqrt{5}}\bigg]$$ which can be calculated approximately via the $\Phi$ probability function boards. (b) The clear profit of the casino in the duration of one month is the total value of the bets by the players minus the total winnings, thus $720(Y-X)$ . Now, the probability of the clear profit of the casino being over $10.000$ per month is : $$P[720(Y-X) > 10.000] = 1 - P[720(Y-X) \leq 10.000] = 1 - P[Y-X \leq 125/9$$ Since $Y \sim U(100,300)$ , it will be $E[Y] = 200$ and $V[Y] = 10000/3$ . How should I proceed now to calculate the probability above ? How would I form a normal distribution simulation for $2$ variables this time, which follow different distributions ? (c) For the probability of the casino earnings (total profit) being more than $10.000$ with at least $95%$ probability, I assume that something like this is needed : $$P[720(Y-X) > 10.000] = 0.95$$ but proceeding in this case I have the same issue as before, thus leading to the initial question. How would I proceed with implementing the parameters of the distributions both the variables $X$ and $Y$ into a normal distribution simulation fraction in order to produce an approximate probability ? Also, is my approach for part (a) correct ?","Exercise : A casino slot machine has been programmed so as to offer total winnings euros per hour, regardless of other hours, with and . From long term data we know that the value in euros that players bet per hour (independent of the values that are played at other hours and the winnings values) follows the uniform distribution over the interval . (a) Calculate approximately the probability that in the duration of one month the slot machine has yielded total winnings of over euros. (b) Calculate approximatel the probability that in the duration of one month the clear profit of the casino is over euros. (c) Let it be that we want to change the parameter in the program of the slot machine. What is the biggest value of for which the clear profit that the slot machine yields for the casino is over with probability at least ? (Suppose that the casino operates the 24hrs per day and that every month has 30 days). Attempt - Question : (a) Since we are asked to calculate the probability of winnings over the course of one month, we should multiply the variable by . Thus, what we need to find, is : which can be calculated approximately via the probability function boards. (b) The clear profit of the casino in the duration of one month is the total value of the bets by the players minus the total winnings, thus . Now, the probability of the clear profit of the casino being over per month is : Since , it will be and . How should I proceed now to calculate the probability above ? How would I form a normal distribution simulation for variables this time, which follow different distributions ? (c) For the probability of the casino earnings (total profit) being more than with at least probability, I assume that something like this is needed : but proceeding in this case I have the same issue as before, thus leading to the initial question. How would I proceed with implementing the parameters of the distributions both the variables and into a normal distribution simulation fraction in order to produce an approximate probability ? Also, is my approach for part (a) correct ?","X μ_x = E[X] = 180 σ_x = V[X] = 10.125 Y [100,300] 135.000 10.000 \sigma \sigma 10.000 95% X 24 \cdot 30 = 720 P[720X > 135.000] = 1 - P[720X \leq 135.000] = 1 - P[X \leq 187.5] = 1 - P[X-180 \leq 7.5] = 1 - P\bigg[\frac{X-180}{45\sqrt{5}} \leq \frac{7.5}{45\sqrt{5}}\bigg] = 1 - P\bigg[Z \leq \frac{7.5}{45\sqrt{5}}\bigg] \Phi 720(Y-X) 10.000 P[720(Y-X) > 10.000] = 1 - P[720(Y-X) \leq 10.000] = 1 - P[Y-X \leq 125/9 Y \sim U(100,300) E[Y] = 200 V[Y] = 10000/3 2 10.000 95% P[720(Y-X) > 10.000] = 0.95 X Y","['probability', 'probability-theory', 'statistics', 'probability-distributions', 'probability-limit-theorems']"
13,Random number weighted probability - where highest probability is least likely,Random number weighted probability - where highest probability is least likely,,"I want to do a standard picking a random number by weighted probability problem. Example Data Set: Person A    70 Person B    30 Person C    40 So normally, these are the probabilities of being picked randomly: Person A    50% Person B    21% Person C    29% Now I want to make it so it's inverted, where the higher your probability, the less likely you are to be picked. How do I invert it? The way I tried: Invert the probabilities Person A    50% Person B    79% Person C    71% Add those up .5 + .79 + .71 = 2 Divide them by the new total: Person A    .5/2  = 25% Person B    .79/2 = 40% Person C    .71/2 = 35% I'm not confident in that answer though - is that the correct way of donig it? Or am I thinking about it wrong?","I want to do a standard picking a random number by weighted probability problem. Example Data Set: Person A    70 Person B    30 Person C    40 So normally, these are the probabilities of being picked randomly: Person A    50% Person B    21% Person C    29% Now I want to make it so it's inverted, where the higher your probability, the less likely you are to be picked. How do I invert it? The way I tried: Invert the probabilities Person A    50% Person B    79% Person C    71% Add those up .5 + .79 + .71 = 2 Divide them by the new total: Person A    .5/2  = 25% Person B    .79/2 = 40% Person C    .71/2 = 35% I'm not confident in that answer though - is that the correct way of donig it? Or am I thinking about it wrong?",,"['probability', 'probability-theory', 'statistics', 'probability-distributions']"
14,Find the ML-estimatior $\hat{\mu}$ of $\mu$ and determine if this estimator is unbiased.,Find the ML-estimatior  of  and determine if this estimator is unbiased.,\hat{\mu} \mu,"Let $X_1,X_2,...,X_n$ be a sample from a distribution that has the CDF $$F(x)=1-\frac{1}{(x+1)^{\mu}}, \quad x>0,$$ where $\mu > 0$ is an unknown parameter. Find the ML-estimatior   $\hat{\mu}$ of $\mu$ and determine if this estimator is unbiased. Solution: Differentiation of the CDF yeilds the PDF $$f(x)=\frac{\mu}{(x+1)^{\mu+1}}. \tag1$$ The likelyhood function is then $$L(\mu)=\frac{\mu^n}{\prod_i(x+1)^{\mu+1}}. \tag 2 $$ Taking the logarithm gives $$l(\theta)=n\ln(\mu)-(\mu+1)\sum_i\ln{(x_i+1)}.\tag3$$ Differentiating gives $$l'(\mu)=\frac{n}{\mu}-\sum_i\ln(x_i+1)\Rightarrow \hat{\mu}=\frac{n}{\sum_i\ln(x_i+1)}.\tag4$$ The estimator is not unbiased. To see this we can set $n=1$ and assume $\mu=1.$ We then get $$E[\hat{\mu}]=\int_0^{\infty}P(X>x) \ dx = \int_0^{\infty}\frac{1}{x+1}=\infty \neq \mu.\tag 5$$ Questions: I don't understand $(5)$. To me it seems as $$P(X>x)=1-P(X<x)=1-F(x)=\frac{1}{1+x},$$with $\mu=1$. But where does $n=1$ play a role here? Should I not be using $\hat{\mu}$ somehow to compute $E[\hat{\mu}]$","Let $X_1,X_2,...,X_n$ be a sample from a distribution that has the CDF $$F(x)=1-\frac{1}{(x+1)^{\mu}}, \quad x>0,$$ where $\mu > 0$ is an unknown parameter. Find the ML-estimatior   $\hat{\mu}$ of $\mu$ and determine if this estimator is unbiased. Solution: Differentiation of the CDF yeilds the PDF $$f(x)=\frac{\mu}{(x+1)^{\mu+1}}. \tag1$$ The likelyhood function is then $$L(\mu)=\frac{\mu^n}{\prod_i(x+1)^{\mu+1}}. \tag 2 $$ Taking the logarithm gives $$l(\theta)=n\ln(\mu)-(\mu+1)\sum_i\ln{(x_i+1)}.\tag3$$ Differentiating gives $$l'(\mu)=\frac{n}{\mu}-\sum_i\ln(x_i+1)\Rightarrow \hat{\mu}=\frac{n}{\sum_i\ln(x_i+1)}.\tag4$$ The estimator is not unbiased. To see this we can set $n=1$ and assume $\mu=1.$ We then get $$E[\hat{\mu}]=\int_0^{\infty}P(X>x) \ dx = \int_0^{\infty}\frac{1}{x+1}=\infty \neq \mu.\tag 5$$ Questions: I don't understand $(5)$. To me it seems as $$P(X>x)=1-P(X<x)=1-F(x)=\frac{1}{1+x},$$with $\mu=1$. But where does $n=1$ play a role here? Should I not be using $\hat{\mu}$ somehow to compute $E[\hat{\mu}]$",,"['probability', 'statistics', 'probability-distributions']"
15,What is the correct way to obtain the position of a quartile and its value?,What is the correct way to obtain the position of a quartile and its value?,,"I'm studying statistics, specifically position measurements. The problem is that I have seen many ways to calculate the quartile, quintile, percentile, decile, etc. The main formulas that I have seen to calculate the POSITION of a quartile are: $\frac{(n+1)i}{4}$ and $\frac{ni}{4}$, where $n =$ number of data, $i =$ number of quartile$(1, 2, 3)$ Some websites claim that one formula is to calculate odd data and the other in pairs. However, in many exercises, they use the formula (n + 1) q / 4 for a number of even data and odd numbers of data, without distinction. What has given me success in the exercises (so far), is to obtain the POSITION of the quartile with the formula $\frac{(n+1)i}{4}$, without distinguishing between odd and even data, and to obtain the VALUE of the quartile I have two options: If the position of the quartile is a decimal, the VALUE will be the average between the two closest integers. If the position of the quartile is an INTEGER, the VALUE will be the data that is in that position. And I have the same doubt, with the formulas for quintile, decile and percentile. But my recently exposed methodology has worked well for me, however I come to ask, Is the way I am getting the POSITION and VALUE of the position measurements correct or not correct at all? Thanks in advance.","I'm studying statistics, specifically position measurements. The problem is that I have seen many ways to calculate the quartile, quintile, percentile, decile, etc. The main formulas that I have seen to calculate the POSITION of a quartile are: $\frac{(n+1)i}{4}$ and $\frac{ni}{4}$, where $n =$ number of data, $i =$ number of quartile$(1, 2, 3)$ Some websites claim that one formula is to calculate odd data and the other in pairs. However, in many exercises, they use the formula (n + 1) q / 4 for a number of even data and odd numbers of data, without distinction. What has given me success in the exercises (so far), is to obtain the POSITION of the quartile with the formula $\frac{(n+1)i}{4}$, without distinguishing between odd and even data, and to obtain the VALUE of the quartile I have two options: If the position of the quartile is a decimal, the VALUE will be the average between the two closest integers. If the position of the quartile is an INTEGER, the VALUE will be the data that is in that position. And I have the same doubt, with the formulas for quintile, decile and percentile. But my recently exposed methodology has worked well for me, however I come to ask, Is the way I am getting the POSITION and VALUE of the position measurements correct or not correct at all? Thanks in advance.",,"['probability', 'statistics']"
16,Use CLT to find the probability,Use CLT to find the probability,,"$X$ is a discrete random variable with the following density function:   $$     f_X(n)   = \begin{cases}         c e^{-2} \, \frac{2^n}{n!}       & n \geq 0, \\         c 3^n       & n < 0.     \end{cases} $$   Define the variables $V$ as follows:   $$     V   = \begin{cases}         0       & X < 0 \\         X       & X \geq 0.     \end{cases} $$   Let $V_1, V_2, V_3, \dotsc$ be a sequence of independent and identically distributed random variables each having the same distribution as $V$. Use the central limit theorem to approximately find $P(20 < \sum_{i=1}^{20} V_i < 30)$. (Original image here .) Not a homework. The entire problem could be found at https://math.stackexchange.com/questions/2885578/find-the-expected-value-of-the-sum-of-random-variables . But it is not that relevant. My work: In order to use CLT we assume that the variable is normal and then find the mean and std of the random variable. $\mathbb E[V]=\sum_{n\geq 0}nce^{-2}2^n/n!=2c$ But how to find the variance for the Normal r.v.? $\mathbb E[V^2]=\sum_{n\geq 0}n^2ce^{-2}2^n/n!=6c$ (not sure if it correct) So $\operatorname{Var}[V]=6c-4c^2$","$X$ is a discrete random variable with the following density function:   $$     f_X(n)   = \begin{cases}         c e^{-2} \, \frac{2^n}{n!}       & n \geq 0, \\         c 3^n       & n < 0.     \end{cases} $$   Define the variables $V$ as follows:   $$     V   = \begin{cases}         0       & X < 0 \\         X       & X \geq 0.     \end{cases} $$   Let $V_1, V_2, V_3, \dotsc$ be a sequence of independent and identically distributed random variables each having the same distribution as $V$. Use the central limit theorem to approximately find $P(20 < \sum_{i=1}^{20} V_i < 30)$. (Original image here .) Not a homework. The entire problem could be found at https://math.stackexchange.com/questions/2885578/find-the-expected-value-of-the-sum-of-random-variables . But it is not that relevant. My work: In order to use CLT we assume that the variable is normal and then find the mean and std of the random variable. $\mathbb E[V]=\sum_{n\geq 0}nce^{-2}2^n/n!=2c$ But how to find the variance for the Normal r.v.? $\mathbb E[V^2]=\sum_{n\geq 0}n^2ce^{-2}2^n/n!=6c$ (not sure if it correct) So $\operatorname{Var}[V]=6c-4c^2$",,"['calculus', 'probability', 'statistics', 'central-limit-theorem']"
17,Examples non experiments in probability,Examples non experiments in probability,,"I'm reading a book on probability theory and they say that an experiment is Any procedure that has not got a pre-determined outcome In the Wikipedia page they, instead, that an experiment should: be infinitely repeatable have well-defined set of possible outcomes Now, I really don't see why it has to be infinitely repeatable. I mean, it makes sense only for frequentist probability right? Surely not for bayesian one. Anyway, my question is: then what is NOT an experiment? what are some examples of procedures that are not experiments? My Solution My idea is that the following are experiments: Tossing a fair coin, and looking at which side is facing upward after landing. Tossing a fair dice, and looking at which side is facing upward after landing. Picking up a numbered ball from within a box (where balls are placed randomly and the picking up mechanism is fair) and looking at the number of the ball. However, I can't quite make up any sensible example of something that is NOT an experiment. For instance, I think that also the following is an experiment: Tossing a non-fair coin that always lands on HEAD and looking at the side facing upwards. because even though the coin is biased, it is infinitely repeatable and has well-defined set of possible outcomes. What are some examples of non-experiments?","I'm reading a book on probability theory and they say that an experiment is Any procedure that has not got a pre-determined outcome In the Wikipedia page they, instead, that an experiment should: be infinitely repeatable have well-defined set of possible outcomes Now, I really don't see why it has to be infinitely repeatable. I mean, it makes sense only for frequentist probability right? Surely not for bayesian one. Anyway, my question is: then what is NOT an experiment? what are some examples of procedures that are not experiments? My Solution My idea is that the following are experiments: Tossing a fair coin, and looking at which side is facing upward after landing. Tossing a fair dice, and looking at which side is facing upward after landing. Picking up a numbered ball from within a box (where balls are placed randomly and the picking up mechanism is fair) and looking at the number of the ball. However, I can't quite make up any sensible example of something that is NOT an experiment. For instance, I think that also the following is an experiment: Tossing a non-fair coin that always lands on HEAD and looking at the side facing upwards. because even though the coin is biased, it is infinitely repeatable and has well-defined set of possible outcomes. What are some examples of non-experiments?",,"['probability', 'probability-theory', 'statistics', 'examples-counterexamples']"
18,"In a survey of 100 people (population=1000), 100 people responded A and 0 people responded B. How to determine margin of error?","In a survey of 100 people (population=1000), 100 people responded A and 0 people responded B. How to determine margin of error?",,"I took a few stats classes in university but it's been a decade since I did any of this so I apologize if this is trivial. I am looking at a research paper and 100 people were surveyed (total population is 1000). All 100 people responded A and 0 people responded B. Trying to determine how to calculate a margin of error for say a 95% (or 99%) confidence level, but things seem confusing (to me lol) when dealing with a completely lopsided response. Can anyone help? Thank you!","I took a few stats classes in university but it's been a decade since I did any of this so I apologize if this is trivial. I am looking at a research paper and 100 people were surveyed (total population is 1000). All 100 people responded A and 0 people responded B. Trying to determine how to calculate a margin of error for say a 95% (or 99%) confidence level, but things seem confusing (to me lol) when dealing with a completely lopsided response. Can anyone help? Thank you!",,"['statistics', 'confidence-interval']"
19,Practical physical processes for various random distributions?,Practical physical processes for various random distributions?,,"You can draw from the Cauchy distribution by attaching a stick to a spindle somewhere on the y-axis, spinning it, and reading off the x-intercept as your drawn value. Where you place the spindle on the y-axis parameterizes the distribution. Are there (practical) physical processes for other distributions? Especially ones that could actually generate all possible values? Throwing darts at a dart board, for instance, is a poor process for the normal distribution since there’s a bound on how far you’ll ever get from the center. For the Geometric distribution you can roll a die until you get a 1, say, though this requires an appropriate die for each value of the single parameter, so it’s not as ideal as the Cauchy case. EDIT: In particular I'm thinking of processes that give you some physical intuition for the distribution. Sure you can convert a randomly drawn number from one distribution into a draw from another distribution, but that doesn't give you any intuition for the second distribution.","You can draw from the Cauchy distribution by attaching a stick to a spindle somewhere on the y-axis, spinning it, and reading off the x-intercept as your drawn value. Where you place the spindle on the y-axis parameterizes the distribution. Are there (practical) physical processes for other distributions? Especially ones that could actually generate all possible values? Throwing darts at a dart board, for instance, is a poor process for the normal distribution since there’s a bound on how far you’ll ever get from the center. For the Geometric distribution you can roll a die until you get a 1, say, though this requires an appropriate die for each value of the single parameter, so it’s not as ideal as the Cauchy case. EDIT: In particular I'm thinking of processes that give you some physical intuition for the distribution. Sure you can convert a randomly drawn number from one distribution into a draw from another distribution, but that doesn't give you any intuition for the second distribution.",,"['probability', 'statistics', 'probability-distributions']"
20,Add more weight to components of equation?,Add more weight to components of equation?,,"I'm not sure how to ask this question, so please bear with me. I'm not even sure if it's possible with just this information. This is the only information that we received. I'm using this equation for rankings: $$\text{CONSLOSS}+{\text{LOSS}} - {\frac {\text{IN}/\text{OUT}} {\text{IN}/\text{OUT}  + 1}}$$ CONSLOSS    LOSS   MONTHS    IN   OUT   Rank formula Row1    2            25    25        30   10    26.25 Row2    1            1     25        8000 1000  1.111 Row3    0            0     25        100  90    -0.526315789 Based on the result, Row1 is worse off, which is correct mathematically-speaking. But for payroll, Row2 is worse than Row1 because in 25 months, it only last 1 month, and it's the last month of the sample. They're adding more weight to that one loss and the fact that their IN & OUT churn is much greater than the other two rows. I guess my question is... is there a way I can add something to this formula so that Row2 ends up having a higher value because a component was given more weight?","I'm not sure how to ask this question, so please bear with me. I'm not even sure if it's possible with just this information. This is the only information that we received. I'm using this equation for rankings: $$\text{CONSLOSS}+{\text{LOSS}} - {\frac {\text{IN}/\text{OUT}} {\text{IN}/\text{OUT}  + 1}}$$ CONSLOSS    LOSS   MONTHS    IN   OUT   Rank formula Row1    2            25    25        30   10    26.25 Row2    1            1     25        8000 1000  1.111 Row3    0            0     25        100  90    -0.526315789 Based on the result, Row1 is worse off, which is correct mathematically-speaking. But for payroll, Row2 is worse than Row1 because in 25 months, it only last 1 month, and it's the last month of the sample. They're adding more weight to that one loss and the fact that their IN & OUT churn is much greater than the other two rows. I guess my question is... is there a way I can add something to this formula so that Row2 ends up having a higher value because a component was given more weight?",,"['probability', 'statistics', 'discrete-mathematics', 'curves', 'elementary-functions']"
21,Bijection Explanation?,Bijection Explanation?,,"Can anyone help explain what bijection is in the context of this problem, and how exactly it's used to derive the particular solution From the definition provided it seems as though a bijection is a translation provided to a set of points, but I'm not sure that I understand how that is applied, especially in the context of the problem. Thanks!","Can anyone help explain what bijection is in the context of this problem, and how exactly it's used to derive the particular solution From the definition provided it seems as though a bijection is a translation provided to a set of points, but I'm not sure that I understand how that is applied, especially in the context of the problem. Thanks!",,"['probability', 'combinatorics', 'statistics']"
22,Why do we have to calculate 1-binomcdf for P(X>11)?,Why do we have to calculate 1-binomcdf for P(X>11)?,,Why do we have to calculate 1-binomcdf for P(X>11)? Can't we just calculate binomcdf with left and right bound like the normalcdf?,Why do we have to calculate 1-binomcdf for P(X>11)? Can't we just calculate binomcdf with left and right bound like the normalcdf?,,['statistics']
23,Minimization problem with latent function and splines,Minimization problem with latent function and splines,,"I have a dataset consisting of pairs $(x_i, y_i)$. I want to determine the function $f$, so $$ f(x)f(y) = 1 $$ with the constraint that $f(x) \leq x$, $f'(x) \geq 0$ and $f''(x) \geq 0$. I was thinking that using splines in some way while constraining the parameters should let me find $f$ satisfying the constraints but I'm unsure how to define the minimization problem in the context of these splines. Any ideas? Data is available here: ""x"" ""y"" 0.8 1.111 0.76 1.163 0.98 0.92   0.66 1.316 0.9 1 0.78 1.136 1.031 0.87 1.042 0.86 0.85 1.053 1.087 0.82 0.83 1.075 1.099 0.81 0.93 0.97 0.4 2 0.34 2.273 1.053 0.85 1.075 0.83 1 0.9 0.89 1.01 0.91 0.99 0.92 0.98 0.95 0.95 0.82 1.087 0.86 1.042 0.88 1.02 0.41 1.961 0.72 1.22 0.96 0.94 0.7 1.25 1.02 0.88 1.111 0.8 0.81 1.099 1.136 0.78 0.94 0.96 1.19 0.74 0.31 2.439 0.39 2.041 1.25 0.7 0.99 0.91 0.87 1.031 0.97 0.93 1.064 0.84 0.44 1.852 0.84 1.064 0.38 2.083 1.163 0.76 0.68 1.282 0.42 1.923 0.33 2.326 0.75 1.176 0.62 1.389 0.77 1.149 0.61 1.408 0.74 1.19 0.51 1.639 0.6 1.429 0.58 1.471 1.176 0.75 1.124 0.79 0.5 1.667 1.01 0.89 0.46 1.786 1.205 0.73 0.65 1.333 0.48 1.724 0.55 1.538 0.54 1.563 0.37 2.128 0.79 1.124 0.45 1.818 1.149 0.77 0.73 1.205 0.3 2.5 1.22 0.72 0.28 2.632 0.71 1.235 0.35 2.222 0.64 1.351 0.53 1.587 0.63 1.37 0.36 2.174 0.49 1.695 0.32 2.381 0.56 1.515 0.59 1.449 0.67 1.299 0.43 1.887 0.25 2.857 0.69 1.266 0.47 1.754 0.52 1.613","I have a dataset consisting of pairs $(x_i, y_i)$. I want to determine the function $f$, so $$ f(x)f(y) = 1 $$ with the constraint that $f(x) \leq x$, $f'(x) \geq 0$ and $f''(x) \geq 0$. I was thinking that using splines in some way while constraining the parameters should let me find $f$ satisfying the constraints but I'm unsure how to define the minimization problem in the context of these splines. Any ideas? Data is available here: ""x"" ""y"" 0.8 1.111 0.76 1.163 0.98 0.92   0.66 1.316 0.9 1 0.78 1.136 1.031 0.87 1.042 0.86 0.85 1.053 1.087 0.82 0.83 1.075 1.099 0.81 0.93 0.97 0.4 2 0.34 2.273 1.053 0.85 1.075 0.83 1 0.9 0.89 1.01 0.91 0.99 0.92 0.98 0.95 0.95 0.82 1.087 0.86 1.042 0.88 1.02 0.41 1.961 0.72 1.22 0.96 0.94 0.7 1.25 1.02 0.88 1.111 0.8 0.81 1.099 1.136 0.78 0.94 0.96 1.19 0.74 0.31 2.439 0.39 2.041 1.25 0.7 0.99 0.91 0.87 1.031 0.97 0.93 1.064 0.84 0.44 1.852 0.84 1.064 0.38 2.083 1.163 0.76 0.68 1.282 0.42 1.923 0.33 2.326 0.75 1.176 0.62 1.389 0.77 1.149 0.61 1.408 0.74 1.19 0.51 1.639 0.6 1.429 0.58 1.471 1.176 0.75 1.124 0.79 0.5 1.667 1.01 0.89 0.46 1.786 1.205 0.73 0.65 1.333 0.48 1.724 0.55 1.538 0.54 1.563 0.37 2.128 0.79 1.124 0.45 1.818 1.149 0.77 0.73 1.205 0.3 2.5 1.22 0.72 0.28 2.632 0.71 1.235 0.35 2.222 0.64 1.351 0.53 1.587 0.63 1.37 0.36 2.174 0.49 1.695 0.32 2.381 0.56 1.515 0.59 1.449 0.67 1.299 0.43 1.887 0.25 2.857 0.69 1.266 0.47 1.754 0.52 1.613",,"['statistics', 'optimization', 'regression', 'spline']"
24,Two types of coins are being tossed,Two types of coins are being tossed,,"Let's assume we have two types of unfair coins. One has $70\%$ probability of getting head, and the other has $70\%$ change of getting tail. Now if we throw coin A $k$ times and coin B $n$ times. What will be the probability of getting at least $w$ heads. $w < k+n.$ I have it figured out when it comes to one coin. By using Normal distribution (aproximating Binomial distribution). But things get too complicated with second coin. Could you help me out?","Let's assume we have two types of unfair coins. One has $70\%$ probability of getting head, and the other has $70\%$ change of getting tail. Now if we throw coin A $k$ times and coin B $n$ times. What will be the probability of getting at least $w$ heads. $w < k+n.$ I have it figured out when it comes to one coin. By using Normal distribution (aproximating Binomial distribution). But things get too complicated with second coin. Could you help me out?",,"['probability', 'statistics']"
25,How to calculate critical value in hypothesis testing?,How to calculate critical value in hypothesis testing?,,"You wish to test the following claim ($H_a$) at a significance level of alpha=0.10. $H_o: \mu=70.4$ $H_a: \mu<70.4$ You believe the population is normally distributed and you know the standard deviation is $\sigma=7.6$, sample mean $M=69.3$ for a sample size of $n=51$. What is the critical value for this test? I cannot understand how to find/calculate a critical value for this test. I believe it must be based on $\alpha$, but apparently this is beyond my scope of intuition as 0.1, 0.9, 1-$\alpha$/2, etc. has not worked. Any help would be greatly provided in verbose yet simple terms. This is an intro to stats course for non-majors.","You wish to test the following claim ($H_a$) at a significance level of alpha=0.10. $H_o: \mu=70.4$ $H_a: \mu<70.4$ You believe the population is normally distributed and you know the standard deviation is $\sigma=7.6$, sample mean $M=69.3$ for a sample size of $n=51$. What is the critical value for this test? I cannot understand how to find/calculate a critical value for this test. I believe it must be based on $\alpha$, but apparently this is beyond my scope of intuition as 0.1, 0.9, 1-$\alpha$/2, etc. has not worked. Any help would be greatly provided in verbose yet simple terms. This is an intro to stats course for non-majors.",,"['statistics', 'hypothesis-testing']"
26,Generating samples from certain regions of a Gaussian distribution,Generating samples from certain regions of a Gaussian distribution,,"Let $X$ be a Gaussian random variable where for simplicity, $X \sim N(0,1)$. I am interested in generating samples of $X$ in the following cases: $X \mid X \in (a,b)$ where $a < b$ or $X \mid X > b$. I am aware that I can do rejection sampling for this and especially for the latter, Wikipedia says (under rejection sampling) that exponential tilting is a very efficient manner to generate samples for $X \mid X>b$. I am wondering though: is there a better way to do this without rejection sampling? In other words, do algorithms exist wherein the above scenarios can be sampled by just a simple scaling/translation of a random variable that can be easily sampled? Thoughts/comments appreciated. Thanks!","Let $X$ be a Gaussian random variable where for simplicity, $X \sim N(0,1)$. I am interested in generating samples of $X$ in the following cases: $X \mid X \in (a,b)$ where $a < b$ or $X \mid X > b$. I am aware that I can do rejection sampling for this and especially for the latter, Wikipedia says (under rejection sampling) that exponential tilting is a very efficient manner to generate samples for $X \mid X>b$. I am wondering though: is there a better way to do this without rejection sampling? In other words, do algorithms exist wherein the above scenarios can be sampled by just a simple scaling/translation of a random variable that can be easily sampled? Thoughts/comments appreciated. Thanks!",,"['probability', 'probability-theory', 'statistics', 'random-variables', 'monte-carlo']"
27,What fraction of the standard deviation should the error bars be?,What fraction of the standard deviation should the error bars be?,,"I am certainly new to statistics. I did some simulations and got a lot of data. From the data I ran a AWK script to calculate the average $\bar x$; minimum, $x_0$ and standard deviation, $\sigma$ (the one where you divide by $N$, not $N-1$). Now I want to plot the data. I guess, I can draw the histogram $\bar x$ high but I am confused how long my error bar should be, like should it be, one standard deviation long (68% confidence) or $2\sigma$ (95% confidence) or $3\sigma$ (99.7% confidence) long. or should I draw it from min-value to max-value","I am certainly new to statistics. I did some simulations and got a lot of data. From the data I ran a AWK script to calculate the average $\bar x$; minimum, $x_0$ and standard deviation, $\sigma$ (the one where you divide by $N$, not $N-1$). Now I want to plot the data. I guess, I can draw the histogram $\bar x$ high but I am confused how long my error bar should be, like should it be, one standard deviation long (68% confidence) or $2\sigma$ (95% confidence) or $3\sigma$ (99.7% confidence) long. or should I draw it from min-value to max-value",,"['statistics', 'standard-deviation']"
28,Can Random Variables be written $P(X)$ instead of $P(X=x)$ as a shorthand?,Can Random Variables be written  instead of  as a shorthand?,P(X) P(X=x),"Recently I asked a question and used the shorthand $P(A)$ for a random variable $A$ to quickly reason about conditional probabilities. However, I was informed that this must be written $P(A=a)$ for random variables and the notational shorthand does not make sense, and is only for events. Is this true? In particular, I am interested in Bayesian Networks and want to write a factorisation such as $$P(A,B,C) = P(A)P(B\mid A)P(C\mid A,B) = P(A)P(B)P(C\mid A,B)$$ to say that the structure of the Bayesian Network is a graph with two root nodes corresponding to $A$ and $B$ which are not dependent on any other random variable and a third node corresponding to $C$ which is dependent on $A$ and $B$ (represented by directed edges). Must I instead write $$P(A=a,B=b,C=c) = P(A=a)P(B=b\mid A=a)P(C=c\mid A=a,B=b) = P(A=a)P(B=b)P(C=c\mid A=a,B=b)$$ to be mathematically coherent? Would I need to say this is for each $a,b,c$? Edit: An example I am particularly interested in is on page 3 of this document , or equivalently the wikipedia entry for the chain rule of probability . Is it valid to write the chain rule of probability like this? Edit: I am particularly confused as so much of the literature of Bayesian Networks seems to use this shorthand, such as this , this , this , this , this , and this .","Recently I asked a question and used the shorthand $P(A)$ for a random variable $A$ to quickly reason about conditional probabilities. However, I was informed that this must be written $P(A=a)$ for random variables and the notational shorthand does not make sense, and is only for events. Is this true? In particular, I am interested in Bayesian Networks and want to write a factorisation such as $$P(A,B,C) = P(A)P(B\mid A)P(C\mid A,B) = P(A)P(B)P(C\mid A,B)$$ to say that the structure of the Bayesian Network is a graph with two root nodes corresponding to $A$ and $B$ which are not dependent on any other random variable and a third node corresponding to $C$ which is dependent on $A$ and $B$ (represented by directed edges). Must I instead write $$P(A=a,B=b,C=c) = P(A=a)P(B=b\mid A=a)P(C=c\mid A=a,B=b) = P(A=a)P(B=b)P(C=c\mid A=a,B=b)$$ to be mathematically coherent? Would I need to say this is for each $a,b,c$? Edit: An example I am particularly interested in is on page 3 of this document , or equivalently the wikipedia entry for the chain rule of probability . Is it valid to write the chain rule of probability like this? Edit: I am particularly confused as so much of the literature of Bayesian Networks seems to use this shorthand, such as this , this , this , this , this , and this .",,"['probability', 'statistics', 'notation', 'random-variables', 'bayesian-network']"
29,What are real-world use cases for start-exclusive ranges/intervals?,What are real-world use cases for start-exclusive ranges/intervals?,,"Having a continuous range that is start-inclusive and end-exclusive is helpful for bucketing, binning, and histograms. There are countless cases for continuous ranges that are start-inclusive and end-inclusive (defining the span of a graph axis, an acceptable range of values, etc). But what about ranges that are start-exclusive/end-inclusive or start-exclusive/end-exclusive? Are there real-world applications for those? Can you list any applications in practical mathematical modeling, statistics, machine learning, industry, etc?","Having a continuous range that is start-inclusive and end-exclusive is helpful for bucketing, binning, and histograms. There are countless cases for continuous ranges that are start-inclusive and end-inclusive (defining the span of a graph axis, an acceptable range of values, etc). But what about ranges that are start-exclusive/end-inclusive or start-exclusive/end-exclusive? Are there real-world applications for those? Can you list any applications in practical mathematical modeling, statistics, machine learning, industry, etc?",,"['statistics', 'discrete-mathematics', 'continuity']"
30,Poisson process strictly bounded by another?,Poisson process strictly bounded by another?,,"Consider two random processes $X, Y$. $Y$ is a Poisson process with rate $\lambda$. $X$ behaves as follows: whenever $X < Y$, it acts equivalent to a Poisson process with rate $\lambda$ (independent of $Y$). Whenever $X = Y$, it waits until $Y$ increments, so that $Y - X = 1$, before continuing to increment itself. (In other words, $X$ never allows itself to surpass $Y$). My question is: what is known about the distribution of $X$? Specifically, can anyone offer any bounds regarding the expected time until $X > n$, for arbitrary $n$? My simulations indicate that it's roughly Y's arrival time plus some very slowly growing ""lag"" when $n$ is very big. This lag is sort of intuitive: consider the case where you have a whole bunch of processes each bounding the one to its left; in that case you would intuitively have quite a big discrepancy between the leftmost process and the rightmost one.","Consider two random processes $X, Y$. $Y$ is a Poisson process with rate $\lambda$. $X$ behaves as follows: whenever $X < Y$, it acts equivalent to a Poisson process with rate $\lambda$ (independent of $Y$). Whenever $X = Y$, it waits until $Y$ increments, so that $Y - X = 1$, before continuing to increment itself. (In other words, $X$ never allows itself to surpass $Y$). My question is: what is known about the distribution of $X$? Specifically, can anyone offer any bounds regarding the expected time until $X > n$, for arbitrary $n$? My simulations indicate that it's roughly Y's arrival time plus some very slowly growing ""lag"" when $n$ is very big. This lag is sort of intuitive: consider the case where you have a whole bunch of processes each bounding the one to its left; in that case you would intuitively have quite a big discrepancy between the leftmost process and the rightmost one.",,"['probability', 'statistics', 'probability-distributions', 'random-variables', 'poisson-process']"
31,Kata's for Statistics,Kata's for Statistics,,"In programming one way at getting better at common problems is solving them in different ways with exercises known as 'kata'. I was wondering, since I'm long out of school, are there available exercises for statistics to increase ones math ability outside of just doing the same problems over and over again out of a textbook?","In programming one way at getting better at common problems is solving them in different ways with exercises known as 'kata'. I was wondering, since I'm long out of school, are there available exercises for statistics to increase ones math ability outside of just doing the same problems over and over again out of a textbook?",,['statistics']
32,Hypothesis Testing: One and Two-Sided Tests,Hypothesis Testing: One and Two-Sided Tests,,"The general rule of hypotheses chosen for testing difference in means of two groups $x$ and $y$ is to choose the follwoing: $H_0: \mu_x = \mu_y$, $H_1: \mu_x \neq \mu_y$ A $t$-test is then conducted to examine whether the null hypothesis is rejected. However, what is the hypothesis testing design when instead the hypothesis is the following: $H_0: \mu_x \leq \mu_y$, $H_1: \mu_x > \mu_y$. Any standard testing procedures that somebody can point to would be helpful.","The general rule of hypotheses chosen for testing difference in means of two groups $x$ and $y$ is to choose the follwoing: $H_0: \mu_x = \mu_y$, $H_1: \mu_x \neq \mu_y$ A $t$-test is then conducted to examine whether the null hypothesis is rejected. However, what is the hypothesis testing design when instead the hypothesis is the following: $H_0: \mu_x \leq \mu_y$, $H_1: \mu_x > \mu_y$. Any standard testing procedures that somebody can point to would be helpful.",,"['probability', 'statistics', 'statistical-inference', 'hypothesis-testing']"
33,95% Confidence Interval for $\lambda$,95% Confidence Interval for,\lambda,"Consider a random sample $X_1,X_2,..,X_n$ from a variable with density function   $$f_X(x)=2\lambda\pi xe^{-\lambda\pi x^2} \ \ \ \ \ \ \  x>0$$   A useful estimator of $\lambda$ is $$\hat{\lambda}=\frac{n}{\pi\sum_{i=1}^{n} X^2_1}$$   Derive a 95% confidence interval for $\lambda$ $\big($a hint is provided suggesting to consider the distribution of $\frac{\lambda}{\hat{\lambda}}\big).$ Taking the advice of the hint, I attempted to find the distribution of  $\frac{\lambda}{\hat{\lambda}}.$ $$\frac{\lambda}{\hat{\lambda}}=\frac{\lambda}{\frac{n}{\pi\sum_{i=1}^{n} X^2_1}}=\frac{\pi\lambda}{n}\sum_{i=1}^{n} X^2_i$$ It can be shown that $$\frac{\pi}{n}\sum_{i=1}^{n} X^2_i\sim\text{Gamma}\Big(n,\frac{1}{n\lambda}\Big)$$  and hence $$\lambda\Bigg(\frac{\pi}{n}\sum_{i=1}^{n} X^2_i\Bigg)\sim\text{Gamma}\Big(n,\frac{1}{n}\Big)$$ But how does this help find a confidence interval? The only formula I really know for confidence intervals for similar types of questions is $\hat{\lambda}\pm z_{0.975}\text {se}(\hat{\lambda})$ where $Z\sim N(0,1)$ Edit , using the pivotal method: $$\mathbb{P}\Big(g_{\frac{\alpha}{2}}\leq \frac{\lambda}{\hat{\lambda}}\leq g_{1-\frac{\alpha}{2}}\Big)=0.95$$ $$\mathbb{P}\Big(\hat{\lambda}g_{0.025}\leq\lambda\leq\hat{\lambda}g_{0.975}\Big)=0.95$$ Hence a 95% confidence interval is $$\Big(\hat{\lambda}g_{0.025},\hat{\lambda}g_{0.975}\Big)$$ where $g_{\frac{\alpha}{2}}$ is the $\frac{\alpha}{2}$%tile of the $\text{Gamma}(n,\frac{1}{n})$ distribution.","Consider a random sample $X_1,X_2,..,X_n$ from a variable with density function   $$f_X(x)=2\lambda\pi xe^{-\lambda\pi x^2} \ \ \ \ \ \ \  x>0$$   A useful estimator of $\lambda$ is $$\hat{\lambda}=\frac{n}{\pi\sum_{i=1}^{n} X^2_1}$$   Derive a 95% confidence interval for $\lambda$ $\big($a hint is provided suggesting to consider the distribution of $\frac{\lambda}{\hat{\lambda}}\big).$ Taking the advice of the hint, I attempted to find the distribution of  $\frac{\lambda}{\hat{\lambda}}.$ $$\frac{\lambda}{\hat{\lambda}}=\frac{\lambda}{\frac{n}{\pi\sum_{i=1}^{n} X^2_1}}=\frac{\pi\lambda}{n}\sum_{i=1}^{n} X^2_i$$ It can be shown that $$\frac{\pi}{n}\sum_{i=1}^{n} X^2_i\sim\text{Gamma}\Big(n,\frac{1}{n\lambda}\Big)$$  and hence $$\lambda\Bigg(\frac{\pi}{n}\sum_{i=1}^{n} X^2_i\Bigg)\sim\text{Gamma}\Big(n,\frac{1}{n}\Big)$$ But how does this help find a confidence interval? The only formula I really know for confidence intervals for similar types of questions is $\hat{\lambda}\pm z_{0.975}\text {se}(\hat{\lambda})$ where $Z\sim N(0,1)$ Edit , using the pivotal method: $$\mathbb{P}\Big(g_{\frac{\alpha}{2}}\leq \frac{\lambda}{\hat{\lambda}}\leq g_{1-\frac{\alpha}{2}}\Big)=0.95$$ $$\mathbb{P}\Big(\hat{\lambda}g_{0.025}\leq\lambda\leq\hat{\lambda}g_{0.975}\Big)=0.95$$ Hence a 95% confidence interval is $$\Big(\hat{\lambda}g_{0.025},\hat{\lambda}g_{0.975}\Big)$$ where $g_{\frac{\alpha}{2}}$ is the $\frac{\alpha}{2}$%tile of the $\text{Gamma}(n,\frac{1}{n})$ distribution.",,"['probability', 'statistics']"
34,Hard to understand hypothesis test problem.,Hard to understand hypothesis test problem.,,"In some university were collected 10 data from females and males. Something similar to M F Verify the hypothesis $\mu_M-\mu_F=360g$ knowing that $\mu_M-\mu_F>360$ with $\alpha=.01$ This was an exam problem (I don't recall the exact statement but it was something very similar to this one, the image that I put here is not the one that was in the exam I mean I don't recall the  given data). My solution This problem is about hypothesis test (I think). Data: We have this data coming from some university. Our study parameter is $\mu_M-\mu_F$. And we have $\alpha=.01$ Supposition. We don't know the distribution of our data but w.l.o.g. let's suppose it follows a normal distribution. (I think I'm wrong here because the sample is small n=10). We also know the variance of $M$ and $F$ (was asked to calculate in  before question) Hypothesis $H_A=\mu_M-\mu_F>360$ $H_0=\mu_M-\mu_F\le 360$ (Note that here we must have $\le$ althoug was given in the text $\mu_M-\mu_F=360$) then the test statistic, the region, value of test statistic, conclusion,p value, etc. I concluded that we should not deny null hypothesis. Can someone check if what I did is correct? Am I very wrong? Thanks in advance for your time","In some university were collected 10 data from females and males. Something similar to M F Verify the hypothesis $\mu_M-\mu_F=360g$ knowing that $\mu_M-\mu_F>360$ with $\alpha=.01$ This was an exam problem (I don't recall the exact statement but it was something very similar to this one, the image that I put here is not the one that was in the exam I mean I don't recall the  given data). My solution This problem is about hypothesis test (I think). Data: We have this data coming from some university. Our study parameter is $\mu_M-\mu_F$. And we have $\alpha=.01$ Supposition. We don't know the distribution of our data but w.l.o.g. let's suppose it follows a normal distribution. (I think I'm wrong here because the sample is small n=10). We also know the variance of $M$ and $F$ (was asked to calculate in  before question) Hypothesis $H_A=\mu_M-\mu_F>360$ $H_0=\mu_M-\mu_F\le 360$ (Note that here we must have $\le$ althoug was given in the text $\mu_M-\mu_F=360$) then the test statistic, the region, value of test statistic, conclusion,p value, etc. I concluded that we should not deny null hypothesis. Can someone check if what I did is correct? Am I very wrong? Thanks in advance for your time",,"['probability', 'statistics', 'normal-distribution', 'hypothesis-testing', 'descriptive-statistics']"
35,UMVUE for a function of parameter [duplicate],UMVUE for a function of parameter [duplicate],,"This question already has an answer here : Finding UMVUE of $\theta$ when the underlying distribution is exponential distribution (1 answer) Closed 4 years ago . Let's say in the exponential distribution, the cdf if $$f(x|\lambda)=\frac{1}{\lambda}\exp\left\{-\frac{x}{\lambda}\right\}$$ If we have $n$ observations: $X_1, X_2, \cdots, X_n$. Then we know since it belongs to the exponential family we have the UMVUE for $\lambda$ is $$T({\bf X})=\sum^n_{i=1}X_i$$ And $$E(T)=E\left(\sum^n_{i=1}X_i\right)=\sum^n_{i=1}E(X_i)=n\lambda$$ Then  $$\hat{\lambda}_{UMVUE}=\frac{T}{n}=\bar{X}$$ Then, what if we want to find the UMVUE of $\frac{1}{\lambda}$?","This question already has an answer here : Finding UMVUE of $\theta$ when the underlying distribution is exponential distribution (1 answer) Closed 4 years ago . Let's say in the exponential distribution, the cdf if $$f(x|\lambda)=\frac{1}{\lambda}\exp\left\{-\frac{x}{\lambda}\right\}$$ If we have $n$ observations: $X_1, X_2, \cdots, X_n$. Then we know since it belongs to the exponential family we have the UMVUE for $\lambda$ is $$T({\bf X})=\sum^n_{i=1}X_i$$ And $$E(T)=E\left(\sum^n_{i=1}X_i\right)=\sum^n_{i=1}E(X_i)=n\lambda$$ Then  $$\hat{\lambda}_{UMVUE}=\frac{T}{n}=\bar{X}$$ Then, what if we want to find the UMVUE of $\frac{1}{\lambda}$?",,"['statistics', 'statistical-inference']"
36,Convolution of two PDF: $1/(2\sqrt{3x})$,Convolution of two PDF:,1/(2\sqrt{3x}),"I'm trying to find the result of the sum of two PDF that is the square of two continuous uniform distribution (rectangular distribution) that have $\mu =0$ and $\sigma =1$.  The square of this continuous uniform distribution is defined from 0 to 3 and is $$p(x)= \frac{1}{2 \sqrt{3x}}$$ Now i need to find the PDF of the sum of two random variables with p(x) as distribution. The convolution integral is $$p(u)=\int_0^3 p(u-t)p(t)dt=\int_0^3 \frac{dt}{12 \sqrt{t(u-t)}}= \frac{arcsin \left( \sqrt{ \frac{3}{u}} \right)}{6}$$ This funcion is not defined on R from 0 to 6. If i extract the real part of $(p(u))$ i obtain the correct PDF from 0 to 3 but the part from 3 to 6 is wrong and p(u) is not normalized from 0 to 6. I simulate this PDF with python, here is an image Simulation of PDF: https://i.sstatic.net/0GRjF.jpg Plot of the PDF: https://i.sstatic.net/pvcQG.jpg what did I do wrong?","I'm trying to find the result of the sum of two PDF that is the square of two continuous uniform distribution (rectangular distribution) that have $\mu =0$ and $\sigma =1$.  The square of this continuous uniform distribution is defined from 0 to 3 and is $$p(x)= \frac{1}{2 \sqrt{3x}}$$ Now i need to find the PDF of the sum of two random variables with p(x) as distribution. The convolution integral is $$p(u)=\int_0^3 p(u-t)p(t)dt=\int_0^3 \frac{dt}{12 \sqrt{t(u-t)}}= \frac{arcsin \left( \sqrt{ \frac{3}{u}} \right)}{6}$$ This funcion is not defined on R from 0 to 6. If i extract the real part of $(p(u))$ i obtain the correct PDF from 0 to 3 but the part from 3 to 6 is wrong and p(u) is not normalized from 0 to 6. I simulate this PDF with python, here is an image Simulation of PDF: https://i.sstatic.net/0GRjF.jpg Plot of the PDF: https://i.sstatic.net/pvcQG.jpg what did I do wrong?",,"['probability', 'analysis', 'statistics']"
37,"$X=\sum_{i=1}^{N}X_i$,estimator for $N$(continuation)",",estimator for (continuation)",X=\sum_{i=1}^{N}X_i N,"Let $X_i$ , $i\geq 1$ , be independent and identically distributed random variables having the uniform distribution over $(0,1)$ . Let $X$ be defined as $X=\sum_{i=1}^{N}X_i$ , where $N$ is an unknown integer. (a) Find an unbiased estimator $T(X)$ of $N$ . (b) Decide with adequate reasons, if $\dfrac{T(X)}{N}$ converges to $1$ almost surely, as $N$ goes to infinity. Now, in my previous question I wanted to know something different ( link ) but not the solution. So, I tried to find the solution after @Ben's hint. Now, we know that $E(2X)=N$ . But since, $2X$ is not always natural number, I need to find the value, $E([2X]+1)$ . Here, $[\cdot]$ is box function. To do that, we need to find the distribution of $[2X]$ . Now, $P([2X]=k)=P(k\leq 2X<k+1)$ , $k=0,1,\dots,2N-1$ Although, I could not find a way to compute $P(k\leq 2X<k+1)$ . Any help appreciated.","Let , , be independent and identically distributed random variables having the uniform distribution over . Let be defined as , where is an unknown integer. (a) Find an unbiased estimator of . (b) Decide with adequate reasons, if converges to almost surely, as goes to infinity. Now, in my previous question I wanted to know something different ( link ) but not the solution. So, I tried to find the solution after @Ben's hint. Now, we know that . But since, is not always natural number, I need to find the value, . Here, is box function. To do that, we need to find the distribution of . Now, , Although, I could not find a way to compute . Any help appreciated.","X_i i\geq 1 (0,1) X X=\sum_{i=1}^{N}X_i N T(X) N \dfrac{T(X)}{N} 1 N E(2X)=N 2X E([2X]+1) [\cdot] [2X] P([2X]=k)=P(k\leq 2X<k+1) k=0,1,\dots,2N-1 P(k\leq 2X<k+1)","['probability', 'statistics', 'statistical-inference', 'law-of-large-numbers']"
38,"pdf from mean, mode, median","pdf from mean, mode, median",,"I have been given the mean, median and mode of a function and have to find the probability density function. mean: $\gamma - \beta\Gamma_1$ median: $\gamma-\beta(ln2)^{1/\delta}$ mode: $\gamma-\beta(1-1/\delta)^{1/\delta}$ I am also given that  $$\Gamma_k=\Gamma(1+k/\delta)$$ $$\Gamma(z)=\int_0^\infty t^{z-1}dt$$ $$ -\infty<x<\gamma, \beta>0, \gamma>0 $$ Now I understand  how to calculate the mean, mode and median when given a probability density function. However I'm struggling to go backwards. I initially tried to ""reverse"" the process by differentiating the mean or median however I know this is skipping the substitution over the given limit. I then looked for patterns with known distributions and realised they are from Weibull distribution however $\gamma-$. Does this mean essentially this is a typical Weibull distribution however shifted by $\gamma$ and therefore the pdf will be $\gamma-Weibull pdf""$","I have been given the mean, median and mode of a function and have to find the probability density function. mean: $\gamma - \beta\Gamma_1$ median: $\gamma-\beta(ln2)^{1/\delta}$ mode: $\gamma-\beta(1-1/\delta)^{1/\delta}$ I am also given that  $$\Gamma_k=\Gamma(1+k/\delta)$$ $$\Gamma(z)=\int_0^\infty t^{z-1}dt$$ $$ -\infty<x<\gamma, \beta>0, \gamma>0 $$ Now I understand  how to calculate the mean, mode and median when given a probability density function. However I'm struggling to go backwards. I initially tried to ""reverse"" the process by differentiating the mean or median however I know this is skipping the substitution over the given limit. I then looked for patterns with known distributions and realised they are from Weibull distribution however $\gamma-$. Does this mean essentially this is a typical Weibull distribution however shifted by $\gamma$ and therefore the pdf will be $\gamma-Weibull pdf""$",,"['statistics', 'means', 'density-function']"
39,Forecasting seasonal data,Forecasting seasonal data,,"I am fairly new to time series modelling. Suppose that I have time series of electricity consumed per day of one company. The series is on workdays only and sometimes there is NA value because of a public holiday. I would like to forecast future electricity consumption. I am familiar with the ARIMA modelling in R, however to properly find seasonal component in R I need to (using auto.arima) specificy frequency of the data, which I believe is double seasonal - that is, depends on both workday and month of the year. Because I was unable to fit the ARIMA, I found a post about predicting a time series using linear regression. Thus my question is, whether the following is statistically correct approach. To deseason my data, I would start with a linear regression $$y_i = day_i + month_i + \epsilon_i,$$ which gives me estimates $y^{seasonal}_i$ of the seasonality of the data. Then I would model the rest of the series, that is $y_i - y^{seasonal}_i$ via ARIMA using Box-Jenkins for series without seasonal component, so basically to model the trend in the data. The forecasting would be simply to forecast from both of the models and sum it. Is my reasoning mathematically correct? Can it be used for correlated data?","I am fairly new to time series modelling. Suppose that I have time series of electricity consumed per day of one company. The series is on workdays only and sometimes there is NA value because of a public holiday. I would like to forecast future electricity consumption. I am familiar with the ARIMA modelling in R, however to properly find seasonal component in R I need to (using auto.arima) specificy frequency of the data, which I believe is double seasonal - that is, depends on both workday and month of the year. Because I was unable to fit the ARIMA, I found a post about predicting a time series using linear regression. Thus my question is, whether the following is statistically correct approach. To deseason my data, I would start with a linear regression $$y_i = day_i + month_i + \epsilon_i,$$ which gives me estimates $y^{seasonal}_i$ of the seasonality of the data. Then I would model the rest of the series, that is $y_i - y^{seasonal}_i$ via ARIMA using Box-Jenkins for series without seasonal component, so basically to model the trend in the data. The forecasting would be simply to forecast from both of the models and sum it. Is my reasoning mathematically correct? Can it be used for correlated data?",,"['statistics', 'time-series']"
40,Variance of the number of copies of a random variable needed to exceed a given sum,Variance of the number of copies of a random variable needed to exceed a given sum,,"Let ${X_i}$ be independent, identically distributed, random variables each with mean $M$ and variance $\sigma^2$. Let $Y(z)$ be the number of these random variables we need to add together to exceed z, that is, the smallest integer such that $X_1 + X_2 + ... + X_Y > z.$ It seems clear that as $z$ approaches infinity, $Y(z))$ should be about $z/M$, so that $E(Y(z))M/z$ should approach $1$. But what is the variance of $Y(z)$ for large $z$? Intuitively, when we add about $z/M$ copies of $X_i$ together, the variance of the resulting sum is about $\sigma^2 z/M$. So typical values will differ from $z$ by about $\sigma \sqrt{z/M}$, which we can fix by adding or subtracting about $\sigma\sqrt{z/M}/M$ copies of $X_i$. So I would conjecture that if we denote the variance of $Y(z)$ by $V(z)$, then $$lim_{z \to \infty} V(z) M^3/(\sigma^2 z)$$ should exist and be positive. Is this true? What is the limit?","Let ${X_i}$ be independent, identically distributed, random variables each with mean $M$ and variance $\sigma^2$. Let $Y(z)$ be the number of these random variables we need to add together to exceed z, that is, the smallest integer such that $X_1 + X_2 + ... + X_Y > z.$ It seems clear that as $z$ approaches infinity, $Y(z))$ should be about $z/M$, so that $E(Y(z))M/z$ should approach $1$. But what is the variance of $Y(z)$ for large $z$? Intuitively, when we add about $z/M$ copies of $X_i$ together, the variance of the resulting sum is about $\sigma^2 z/M$. So typical values will differ from $z$ by about $\sigma \sqrt{z/M}$, which we can fix by adding or subtracting about $\sigma\sqrt{z/M}/M$ copies of $X_i$. So I would conjecture that if we denote the variance of $Y(z)$ by $V(z)$, then $$lim_{z \to \infty} V(z) M^3/(\sigma^2 z)$$ should exist and be positive. Is this true? What is the limit?",,"['probability', 'statistics']"
41,Question about central limit theorem on two exercises.,Question about central limit theorem on two exercises.,,"I was presented two formulas, if random variables ${X_1,...,X_n}$ form a random sample of a distribution of mean $\mu$ and standard deviation $\sigma$ and $n \to \infty$: \begin{align} &P\left(\frac{\overline{X_n}-\mu}{\sigma/\sqrt n}< a\right) = \Phi(a) \:\:\:\: (1) \\ &P\left(\frac{\overline{X_n}-n\mu}{\sigma\sqrt n}< a\right) = \Phi(a) \:\: (2)  \end{align} where $\Phi$ is the cdf of a standard normal distribution. But I not sure when to use which. For example. Each minute a machine produces $4$ meters of rope with standard deviation of $0.4$ meters. Assuming the amount produced in differet minutes are i.i.d, what is the probability that the machine will produce at least $250$ meters. I'm supposed to use $(2)$ but why? Another example: $16$ digits are chosen at random from the set $\{0,...,9\}$. What is the probability that their average will lie between $4$ and $6$? I'm supposed to use $(1)$ but why?","I was presented two formulas, if random variables ${X_1,...,X_n}$ form a random sample of a distribution of mean $\mu$ and standard deviation $\sigma$ and $n \to \infty$: \begin{align} &P\left(\frac{\overline{X_n}-\mu}{\sigma/\sqrt n}< a\right) = \Phi(a) \:\:\:\: (1) \\ &P\left(\frac{\overline{X_n}-n\mu}{\sigma\sqrt n}< a\right) = \Phi(a) \:\: (2)  \end{align} where $\Phi$ is the cdf of a standard normal distribution. But I not sure when to use which. For example. Each minute a machine produces $4$ meters of rope with standard deviation of $0.4$ meters. Assuming the amount produced in differet minutes are i.i.d, what is the probability that the machine will produce at least $250$ meters. I'm supposed to use $(2)$ but why? Another example: $16$ digits are chosen at random from the set $\{0,...,9\}$. What is the probability that their average will lie between $4$ and $6$? I'm supposed to use $(1)$ but why?",,"['probability', 'statistics', 'central-limit-theorem']"
42,BlackJack Card Counting Probabilities,BlackJack Card Counting Probabilities,,"Note: This is related to this question but I'm going to frame the problem in a completely different way (hopefully a more productive way). Lets say we have a 2-deck blackjack game, half of the cards have been seen, 52 remain unseen.  We know that we have seen 5 more low cards than high cards (low cards = 2/3/4/5/6, high cards = 10/J/Q/K/A, neutral = 7/8/9). Ultimately I'm trying to determine the probability that the next card dealt will be a high card. There are 104! possible shuffles of 2 decks of cards, but in this case we don't care about suits, or even the specific card value, we just care about Hi/Lo/Ne(utral) Taking that into account the number of possible shuffles is 104! / (40!*40!*24!) - which still equals a very huge number (2.5e+46) - too big for me to write code to brute force this problem. Problem 1 - How many of those possible shuffles results in 5 more low cards than high cards in the first 52 cards? Problem 2 - What % of those have 17 high cards remaining? 18? 19? etc (there are somewhere between 17-28 high cards remaining unseen)","Note: This is related to this question but I'm going to frame the problem in a completely different way (hopefully a more productive way). Lets say we have a 2-deck blackjack game, half of the cards have been seen, 52 remain unseen.  We know that we have seen 5 more low cards than high cards (low cards = 2/3/4/5/6, high cards = 10/J/Q/K/A, neutral = 7/8/9). Ultimately I'm trying to determine the probability that the next card dealt will be a high card. There are 104! possible shuffles of 2 decks of cards, but in this case we don't care about suits, or even the specific card value, we just care about Hi/Lo/Ne(utral) Taking that into account the number of possible shuffles is 104! / (40!*40!*24!) - which still equals a very huge number (2.5e+46) - too big for me to write code to brute force this problem. Problem 1 - How many of those possible shuffles results in 5 more low cards than high cards in the first 52 cards? Problem 2 - What % of those have 17 high cards remaining? 18? 19? etc (there are somewhere between 17-28 high cards remaining unseen)",,"['probability', 'statistics', 'card-games']"
43,How can I estimate the centre of mass with obscured/missing data?,How can I estimate the centre of mass with obscured/missing data?,,"How can I estimate the centre of mass for a sample of simple point objects with uniform mass distributed in 2 dimensions when parts of the sample are obscured? For example consider a collection of points where we have absolute knowledge over most of the space but inside a rectangular region we have no knowledge. We cannot just assume there are no points in the space. Does the answer to the problem change if we know the overall number of points? For instance if we know there are 1000 points in total but we can only observe 800. This question may be overly broad. To clarify: I am asking what methods can be used to solve questions like this, what are their limitations and what are the recent advances in mathematics related to solving these types of questions. (I am not a mathematician)","How can I estimate the centre of mass for a sample of simple point objects with uniform mass distributed in 2 dimensions when parts of the sample are obscured? For example consider a collection of points where we have absolute knowledge over most of the space but inside a rectangular region we have no knowledge. We cannot just assume there are no points in the space. Does the answer to the problem change if we know the overall number of points? For instance if we know there are 1000 points in total but we can only observe 800. This question may be overly broad. To clarify: I am asking what methods can be used to solve questions like this, what are their limitations and what are the recent advances in mathematics related to solving these types of questions. (I am not a mathematician)",,['statistics']
44,Ring Around the Robot - Chance of ending on specific node,Ring Around the Robot - Chance of ending on specific node,,"$N$ nodes $(Node_1 .. Node_N)$ are arranged in a circle, and a robot is placed at $Node_1$. The robot moves clockwise with probability $p$ and counter-clockwise with prob. $(1-p)$. Given integers $S, B \in \mathbb{N}$, where $1<=B<=N$, what's the probability of it landing on $Node_B$ after taking $S$ steps? I know there's a mathematical formulation of this problem, but I haven't been able to shift from an algorithmic frame of mind. What I've come up with is: E = minabs(S - B) # How many steps is the minimum allowed to get to Node_B? if(S < E) { Prob = 0 } # There aren't enough steps to get to Node_B if (S == E) && (S-B < 0) { Prob = (1 - p)^S } # Only S counter-clockwise steps will get to Node_B. if (S == E) && (S-B > 0) { Prob = p^S } # Only S clockwise steps will get to Node_B. However, I'm stuck trying to think through the possible scenarios when $S > E$. Extracting the cases where the robot goes completely around the ring in either direction, or where a move in one direction is countered by the opposite move have me overwhelmed, and thinking there must be a better way.","$N$ nodes $(Node_1 .. Node_N)$ are arranged in a circle, and a robot is placed at $Node_1$. The robot moves clockwise with probability $p$ and counter-clockwise with prob. $(1-p)$. Given integers $S, B \in \mathbb{N}$, where $1<=B<=N$, what's the probability of it landing on $Node_B$ after taking $S$ steps? I know there's a mathematical formulation of this problem, but I haven't been able to shift from an algorithmic frame of mind. What I've come up with is: E = minabs(S - B) # How many steps is the minimum allowed to get to Node_B? if(S < E) { Prob = 0 } # There aren't enough steps to get to Node_B if (S == E) && (S-B < 0) { Prob = (1 - p)^S } # Only S counter-clockwise steps will get to Node_B. if (S == E) && (S-B > 0) { Prob = p^S } # Only S clockwise steps will get to Node_B. However, I'm stuck trying to think through the possible scenarios when $S > E$. Extracting the cases where the robot goes completely around the ring in either direction, or where a move in one direction is countered by the opposite move have me overwhelmed, and thinking there must be a better way.",,"['combinatorics', 'statistics']"
45,How to understand the expression $\int_{t\in\mathcal{T}}Y(t)dI\{t\ge T\}$,How to understand the expression,\int_{t\in\mathcal{T}}Y(t)dI\{t\ge T\},"The random process $Y(t)$ indexed by $t\in \mathcal{T}$ denotes outcomes under treatment levels in $\mathcal{T}$ . In practice, one cannot observe $Y(t)$ for all $t\in \mathcal{T}$ . Rather, only a single $Y(t_0)$ can be observed, where $t_0$ is the realization of a random variable $T$. Thus, the observed outcome is the random variable $$Y=Y(T)=\int_{t\in\mathcal{T}}Y(t)dI\{t\ge T\}$$ My question is how to understand the expression $\int_{t\in\mathcal{T}}Y(t)dI\{t\ge T\}$. Why is this equal to $Y(T)$.","The random process $Y(t)$ indexed by $t\in \mathcal{T}$ denotes outcomes under treatment levels in $\mathcal{T}$ . In practice, one cannot observe $Y(t)$ for all $t\in \mathcal{T}$ . Rather, only a single $Y(t_0)$ can be observed, where $t_0$ is the realization of a random variable $T$. Thus, the observed outcome is the random variable $$Y=Y(T)=\int_{t\in\mathcal{T}}Y(t)dI\{t\ge T\}$$ My question is how to understand the expression $\int_{t\in\mathcal{T}}Y(t)dI\{t\ge T\}$. Why is this equal to $Y(T)$.",,"['probability', 'probability-theory', 'statistics', 'measure-theory', 'random-variables']"
46,Constructing a symmetrical $100(1-a)\%$ confidence interval for $\theta$.,Constructing a symmetrical  confidence interval for .,100(1-a)\% \theta,"Exercise : Let $X_1, \dots, X_n$ be a random sample from the distribution function $F(x) =1 - \frac{\theta^3}{x^3}, \; x \geq \theta$ where $\theta >0$ unknown parameter. (i) Find a maximum likelihood estimator for $\theta$ (ii) Find a sufficient and complete statistics function $T$ , for $\theta$ . (iii) Check if the maximum likelihood estimator you found is unbiased for $\theta$ . (iv) Find the distribution of $Y = T/\theta$ . (v) Construct a symmetrical $100(1-a)\%$ confidence interval for $\theta$ . Question : I have successfully solved each one of the parts (i) to (iv) but I find myself stuck on (v). I am not very familiar with confidence intervals, so it could be something simple. I would really appreciate a thorough explanation or solution so as I can grasp the idea of such question parts, since this is a usual exams question.","Exercise : Let be a random sample from the distribution function where unknown parameter. (i) Find a maximum likelihood estimator for (ii) Find a sufficient and complete statistics function , for . (iii) Check if the maximum likelihood estimator you found is unbiased for . (iv) Find the distribution of . (v) Construct a symmetrical confidence interval for . Question : I have successfully solved each one of the parts (i) to (iv) but I find myself stuck on (v). I am not very familiar with confidence intervals, so it could be something simple. I would really appreciate a thorough explanation or solution so as I can grasp the idea of such question parts, since this is a usual exams question.","X_1, \dots, X_n F(x) =1 - \frac{\theta^3}{x^3}, \; x \geq \theta \theta >0 \theta T \theta \theta Y = T/\theta 100(1-a)\% \theta","['probability', 'statistics', 'probability-distributions', 'maximum-likelihood', 'confidence-interval']"
47,Posterior distribution based on the conjugate Gaussian-gamma prior: Exercise 2.44 from Bishop's book,Posterior distribution based on the conjugate Gaussian-gamma prior: Exercise 2.44 from Bishop's book,,"I am not sure how to tag a question such that different communities in the stackexchange can see at the same time. I have posted a question in the ""cross validated"" community. In order to avoid multiple copies of the same question in the different community, I hope it is acceptable to share the link to the question: https://stats.stackexchange.com/q/350030/204499 . I would be happy to receive your feedback and comments therein. Thank you so much in advance,","I am not sure how to tag a question such that different communities in the stackexchange can see at the same time. I have posted a question in the ""cross validated"" community. In order to avoid multiple copies of the same question in the different community, I hope it is acceptable to share the link to the question: https://stats.stackexchange.com/q/350030/204499 . I would be happy to receive your feedback and comments therein. Thank you so much in advance,",,"['probability-theory', 'statistics', 'probability-distributions', 'machine-learning', 'bayesian']"
48,How to understand a 'shifted' lognormal distribution random variable (RV) and its results,How to understand a 'shifted' lognormal distribution random variable (RV) and its results,,"This is an applied math question. I am doing some numerical work, in Python, using Scipy.stats.  But it is really the underlying math that matters, and I am questioning the results/implementation.  It is really the math that counts. The general problem is I am using lognormal (LN) RVs to obtain multiplicative results through iteration.  So, for example, I have a starting 'known' LN RV which is sort of like a Dirac-delta function: if $Y=e^X$, where Y is lognormal and X is thus normal.  To be clear, Y has both a mean and an SD (standard deviation) which can be calculated/observed empirically.  Underylying it is a normal distribution for X with parameters $\mu$ and $\sigma$, which can be derived from Y's mean and SD (see: https://en.wikipedia.org/wiki/Log-normal_distribution ). Since it is lognormal, I can multiply it by another LN distribution to get a new lognormal distribution.  in practice - if we call the parameters of the first distribution $mu_1$ and $sigma_1$, and those of the second $mu_2$ and $sigma_2$ , we can calculate the $X$ representation as: $$\mu - \mu_1 + \mu_2$$ $$\sigma = (\sigma_1^2 + \sigma_2^2)^{0.5}$$ assuming, of course, independence. All works well.  But Python offers an additional parameter 'offset', which shifts the lognormal left or right by the fixed amount.  Thus, if you have a wrapper around the Scipy calls that creates an object RV=Lognorm(100000, 10000, -50000) the pdf delivered does, indeed, have an SD = 10,000, but centered at 50,000 (since the 100,000 offset is offset by -50,000). What I struggle with is this. If you, in fact, ask the package fro the mean and SD for RV, it gives mean=50,000 and SD = 10,000.  Thus, it looks like it creates an RV that is not totally shifted left by 50,000 - which would possibly allow positive probability of values less than zero - but that it adjusts the mean downward by 50,000. It looks to me like a bit of a software kludge that works.  To my way of thinking, shifting to the left by 'n' units could/should preserve all central moments, but(1) will allow negative values and (2) there should not exist a proper, 2-parameter lognormal that gives the same pdf - i.e., pdf(100000, 10000) shifted left 50000 is not pdf(50000, 10000) since the pdf has, in its definition, $e^{ln(x)}$ and the shift should appear as $e^{ln(x)-s}$, where $s$ is the shift amount. Am I missing something here, or is this just a convention of Python which does not conform to the actual definition of the lognorm distribution?  Or am I wrong on the definition/understanding of a three-parameter lognormal distribution?","This is an applied math question. I am doing some numerical work, in Python, using Scipy.stats.  But it is really the underlying math that matters, and I am questioning the results/implementation.  It is really the math that counts. The general problem is I am using lognormal (LN) RVs to obtain multiplicative results through iteration.  So, for example, I have a starting 'known' LN RV which is sort of like a Dirac-delta function: if $Y=e^X$, where Y is lognormal and X is thus normal.  To be clear, Y has both a mean and an SD (standard deviation) which can be calculated/observed empirically.  Underylying it is a normal distribution for X with parameters $\mu$ and $\sigma$, which can be derived from Y's mean and SD (see: https://en.wikipedia.org/wiki/Log-normal_distribution ). Since it is lognormal, I can multiply it by another LN distribution to get a new lognormal distribution.  in practice - if we call the parameters of the first distribution $mu_1$ and $sigma_1$, and those of the second $mu_2$ and $sigma_2$ , we can calculate the $X$ representation as: $$\mu - \mu_1 + \mu_2$$ $$\sigma = (\sigma_1^2 + \sigma_2^2)^{0.5}$$ assuming, of course, independence. All works well.  But Python offers an additional parameter 'offset', which shifts the lognormal left or right by the fixed amount.  Thus, if you have a wrapper around the Scipy calls that creates an object RV=Lognorm(100000, 10000, -50000) the pdf delivered does, indeed, have an SD = 10,000, but centered at 50,000 (since the 100,000 offset is offset by -50,000). What I struggle with is this. If you, in fact, ask the package fro the mean and SD for RV, it gives mean=50,000 and SD = 10,000.  Thus, it looks like it creates an RV that is not totally shifted left by 50,000 - which would possibly allow positive probability of values less than zero - but that it adjusts the mean downward by 50,000. It looks to me like a bit of a software kludge that works.  To my way of thinking, shifting to the left by 'n' units could/should preserve all central moments, but(1) will allow negative values and (2) there should not exist a proper, 2-parameter lognormal that gives the same pdf - i.e., pdf(100000, 10000) shifted left 50000 is not pdf(50000, 10000) since the pdf has, in its definition, $e^{ln(x)}$ and the shift should appear as $e^{ln(x)-s}$, where $s$ is the shift amount. Am I missing something here, or is this just a convention of Python which does not conform to the actual definition of the lognorm distribution?  Or am I wrong on the definition/understanding of a three-parameter lognormal distribution?",,"['statistics', 'computational-mathematics']"
49,Find the mathematical expectation of the given process?,Find the mathematical expectation of the given process?,,"$$E[\cos(2\pi t+\theta)\sin(2\pi f(t+\tau)+\theta)]$$ where $$f=a+b\cos(\alpha)$$ and $\alpha$ is uniformly distributed on the interval (0,$\pi$). $a$ and $b$ are constants My approach: $$=\cos(2\pi t+\theta)E[\sin(2\pi f(t+\tau)+\theta)]$$ $$=\cos(2\pi t+\theta)E[\sin(2\pi (a+b\cos(\alpha))(t+\tau)+\theta)]$$ $$=\cos(2\pi t+\theta)E[\sin(2\pi a(t+\tau)+2\pi b\cos(\alpha)(t+\tau)+\theta)]$$ $$=\cos(2\pi t+\theta)\int\limits_{0}^{\pi} \sin(2\pi a(t+\tau)+2\pi b\cos(\alpha)(t+\tau)+\theta)\frac{1}{\pi}d\alpha$$ $$\bigg/ 2\pi a(t+\tau)+2\pi b\cos(\alpha)(t+\tau)+\theta=x /d \bigg/$$ $$\bigg/d\alpha=-\frac{dx}{2\pi b\sin(\alpha)}\bigg/$$ $$=\cos(2\pi t+\theta)\frac{1}{2\pi^2 b\sin(\alpha)}\Big[\cos( 2\pi a(t+\tau)- 2\pi b(t+\tau)+\theta)-\cos( 2\pi a(t+\tau)+ 2\pi b(t+\tau)+\theta)\Big]$$ after applying: $$\cos x-\cos y = -2\sin\frac{x+y}{2}\sin\frac{x-y}{2}$$ I get: $$=\frac{\sin(2\pi a(t+\tau)+\theta)\sin(2\pi b(t+\tau))}{\pi^2b \sin(\alpha)}$$ Am I wrong or is this correct? For me the solution looks a little bit long and I was expecting a simpler solution. Maybe there are some properties I have overseen. Any help would be much appreciated.","$$E[\cos(2\pi t+\theta)\sin(2\pi f(t+\tau)+\theta)]$$ where $$f=a+b\cos(\alpha)$$ and $\alpha$ is uniformly distributed on the interval (0,$\pi$). $a$ and $b$ are constants My approach: $$=\cos(2\pi t+\theta)E[\sin(2\pi f(t+\tau)+\theta)]$$ $$=\cos(2\pi t+\theta)E[\sin(2\pi (a+b\cos(\alpha))(t+\tau)+\theta)]$$ $$=\cos(2\pi t+\theta)E[\sin(2\pi a(t+\tau)+2\pi b\cos(\alpha)(t+\tau)+\theta)]$$ $$=\cos(2\pi t+\theta)\int\limits_{0}^{\pi} \sin(2\pi a(t+\tau)+2\pi b\cos(\alpha)(t+\tau)+\theta)\frac{1}{\pi}d\alpha$$ $$\bigg/ 2\pi a(t+\tau)+2\pi b\cos(\alpha)(t+\tau)+\theta=x /d \bigg/$$ $$\bigg/d\alpha=-\frac{dx}{2\pi b\sin(\alpha)}\bigg/$$ $$=\cos(2\pi t+\theta)\frac{1}{2\pi^2 b\sin(\alpha)}\Big[\cos( 2\pi a(t+\tau)- 2\pi b(t+\tau)+\theta)-\cos( 2\pi a(t+\tau)+ 2\pi b(t+\tau)+\theta)\Big]$$ after applying: $$\cos x-\cos y = -2\sin\frac{x+y}{2}\sin\frac{x-y}{2}$$ I get: $$=\frac{\sin(2\pi a(t+\tau)+\theta)\sin(2\pi b(t+\tau))}{\pi^2b \sin(\alpha)}$$ Am I wrong or is this correct? For me the solution looks a little bit long and I was expecting a simpler solution. Maybe there are some properties I have overseen. Any help would be much appreciated.",,"['statistics', 'expectation']"
50,Linear regression with 2 unknown intercepts,Linear regression with 2 unknown intercepts,,"The linear equation $y=2.2+0.6(x+1.2)$ has the slope $0.6$, the given y-intercept $2.2$ and x-intercept $-1.2$. The table is $$ \begin{array}{c|lcr} x & y \\ \hline 1 & 3.52 \\  2 & 4.12 \\  3 & 4.72 \\  4 & 5.32 \\  5 & 5.92 \\ \end{array} $$ From the equation (and the blue line on the graph ) the actual y-intercept is $2.92$ and the actual x-intercept is $-4.8\bar{6}$ ($-4\frac{13}{15}$). When writing a regression for this data, how do I relate the ""actual"" intercepts to the equation input x- and y-intercepts? Here is what I know. From the data I can determine the slope $0.6$, and I know that every regression line with slope $0.6$ has to go through the point $(\bar{x}, \bar{y})$ (the means of the x- and y-values) which here is $(3,4.72)$. The line also has to go through the point $(-b_2, b_0)$, which secretly is $(-1.2, 2.2)$. The information I actually know when writing a regression from the data alone is $y=b_0+b_1(x+b_2)$ (linear given) $b_1 = 0.6$ $\bar{x}=3$ $\bar{y}=4.72$ regression line of slope $b_1=0.6$ has the point $(\bar{x}, \bar{y})=(3,4.72)$ regression line of slope $b_1=0.6$ has the point $(-b_2, b_0)$. The equations for $b_0$ and $b_2$ are simple but co-dependent: $$ b_0 = y - b_1(x+b_2) \\ b_2 = \frac{y-b_0}{-b_1}+x $$ Let $b_2=0;x=3$ in  $$ b_0=4.72-0.6(3-0) \\  b_0=2.92. $$ Let $b_0=0;x=3$ in  $$ b_2 = \frac{4.72-0}{-.6}+3 \\  b_2=-4.8\bar{6}. $$ These are the observed x- and y-intercepts, but not the orginal inputs. Put these back into the original linear equation where $x=3$: $$4.72=2.92+0.6(3+-4.8\bar{6})$$ I find that $4.72=2.92+4.72$ thus $4.72=7.64$. Let $x=3$ in 2-variable derivation of $b_0$ where $y=2.2+0.6(x)$ (1 unknown): $$ \bar{y} = b_0+0.6(\bar{x}) \\ 4 = b_0+1.8 \\ 2.2 = b_0. $$ This is correct. If I let $x=3$ and use the same strategy for 3-variable derivation of $b_0$ where $y=2.2+0.6(x+1.2)$ (2 unknowns): $$ \bar{y} = b_0+0.6(\bar{x}+b_2) \\ 4.72 = b_0+1.8+.6b_2 \\ 2.92 = b_0+0.6b_2.  $$ The result is balanced: $$ 2.92 = 2.2+0.6(1.2) \\ 2.92 = 2.2+0.72 \\ 2.92 = 2.92.  $$ but does not give $b_0$ or $b_2$ because they are defined in terms of one another. There are infinitely many real solutions to $2.92 = b_0+0.6b_2$. How shall I decouple the two intercepts to find the original equation $y=2.2+0.6(x+1.2)$ from the data and knowing only the 6 listed facts above?","The linear equation $y=2.2+0.6(x+1.2)$ has the slope $0.6$, the given y-intercept $2.2$ and x-intercept $-1.2$. The table is $$ \begin{array}{c|lcr} x & y \\ \hline 1 & 3.52 \\  2 & 4.12 \\  3 & 4.72 \\  4 & 5.32 \\  5 & 5.92 \\ \end{array} $$ From the equation (and the blue line on the graph ) the actual y-intercept is $2.92$ and the actual x-intercept is $-4.8\bar{6}$ ($-4\frac{13}{15}$). When writing a regression for this data, how do I relate the ""actual"" intercepts to the equation input x- and y-intercepts? Here is what I know. From the data I can determine the slope $0.6$, and I know that every regression line with slope $0.6$ has to go through the point $(\bar{x}, \bar{y})$ (the means of the x- and y-values) which here is $(3,4.72)$. The line also has to go through the point $(-b_2, b_0)$, which secretly is $(-1.2, 2.2)$. The information I actually know when writing a regression from the data alone is $y=b_0+b_1(x+b_2)$ (linear given) $b_1 = 0.6$ $\bar{x}=3$ $\bar{y}=4.72$ regression line of slope $b_1=0.6$ has the point $(\bar{x}, \bar{y})=(3,4.72)$ regression line of slope $b_1=0.6$ has the point $(-b_2, b_0)$. The equations for $b_0$ and $b_2$ are simple but co-dependent: $$ b_0 = y - b_1(x+b_2) \\ b_2 = \frac{y-b_0}{-b_1}+x $$ Let $b_2=0;x=3$ in  $$ b_0=4.72-0.6(3-0) \\  b_0=2.92. $$ Let $b_0=0;x=3$ in  $$ b_2 = \frac{4.72-0}{-.6}+3 \\  b_2=-4.8\bar{6}. $$ These are the observed x- and y-intercepts, but not the orginal inputs. Put these back into the original linear equation where $x=3$: $$4.72=2.92+0.6(3+-4.8\bar{6})$$ I find that $4.72=2.92+4.72$ thus $4.72=7.64$. Let $x=3$ in 2-variable derivation of $b_0$ where $y=2.2+0.6(x)$ (1 unknown): $$ \bar{y} = b_0+0.6(\bar{x}) \\ 4 = b_0+1.8 \\ 2.2 = b_0. $$ This is correct. If I let $x=3$ and use the same strategy for 3-variable derivation of $b_0$ where $y=2.2+0.6(x+1.2)$ (2 unknowns): $$ \bar{y} = b_0+0.6(\bar{x}+b_2) \\ 4.72 = b_0+1.8+.6b_2 \\ 2.92 = b_0+0.6b_2.  $$ The result is balanced: $$ 2.92 = 2.2+0.6(1.2) \\ 2.92 = 2.2+0.72 \\ 2.92 = 2.92.  $$ but does not give $b_0$ or $b_2$ because they are defined in terms of one another. There are infinitely many real solutions to $2.92 = b_0+0.6b_2$. How shall I decouple the two intercepts to find the original equation $y=2.2+0.6(x+1.2)$ from the data and knowing only the 6 listed facts above?",,"['linear-algebra', 'ordinary-differential-equations', 'statistics', 'linear-regression', 'regression-analysis']"
51,Is it possible to answer this problem with standard Central Limit Theorem or should we use Lindeberg-Feller CLT?,Is it possible to answer this problem with standard Central Limit Theorem or should we use Lindeberg-Feller CLT?,,"I have the following problem on my Statistics I problem set: Suppose that $X_t = \mu + U_t$, where $U_t = V_t + \rho V_{t-1}$ and   $V_t$ are iid standard normal variables. Apply a CLT to find the limiting distribution of $\sqrt{n} (\bar{X}_n -\mu)$ Let $\hat{\theta}_n = (\hat\mu_n, \hat\rho_n)$ be the MLE for $\theta = (\mu, \rho)$. Find the asymptotic distribution of   $\sqrt{n}(\hat{\theta}_n - \theta)$. Compare the asymptotic distributions of $\sqrt{n}(\hat\mu_n - \mu)$ and $\sqrt{n}(\bar{X}_n - \mu)$. Explain your answer. I cannot prove part 1, since $X_{t}$ variables are not iid, as required by the standard CLT. I understand that we should use Lindeberg-Feller CLT or something stronger to prove this result. Can anyone do it with standard CLT?","I have the following problem on my Statistics I problem set: Suppose that $X_t = \mu + U_t$, where $U_t = V_t + \rho V_{t-1}$ and   $V_t$ are iid standard normal variables. Apply a CLT to find the limiting distribution of $\sqrt{n} (\bar{X}_n -\mu)$ Let $\hat{\theta}_n = (\hat\mu_n, \hat\rho_n)$ be the MLE for $\theta = (\mu, \rho)$. Find the asymptotic distribution of   $\sqrt{n}(\hat{\theta}_n - \theta)$. Compare the asymptotic distributions of $\sqrt{n}(\hat\mu_n - \mu)$ and $\sqrt{n}(\bar{X}_n - \mu)$. Explain your answer. I cannot prove part 1, since $X_{t}$ variables are not iid, as required by the standard CLT. I understand that we should use Lindeberg-Feller CLT or something stronger to prove this result. Can anyone do it with standard CLT?",,"['probability-theory', 'statistics', 'convergence-divergence', 'central-limit-theorem', 'parameter-estimation']"
52,"In a random permutation, does uniform contiguous pair probability guarantee uniform permutation probability?","In a random permutation, does uniform contiguous pair probability guarantee uniform permutation probability?",,"Let's say I have a set of $N$ random $k$-permutations $P_1,\ldots,P_N$ selected according to some probability distribution. I consider the probability distribution of the frequencies of contiguous pairs in a permuted sequence. I'm not sure how to express this properly so I'll give an example: with $k=4$ and the permutation $P_i=(24)$ we would reorder the sequence $[1,2,3,4]$ to $[1,4,3,2]$; what I call ""contiguous pairs"" for $P_i$ would be $(1, 4)$, $(4, 3)$, $(3, 2)$ and $(2, 1)$. So I can count the frequencies of the $k(k - 1)$ possible pairs for my $N$ permutations. Now, my intuition is that, if my permutations are sampled according to a uniform distribution, then each of these frequencies should be about the same as $N \rightarrow \infty$, and they would follow a binomial distribution with $N$ trials and probability $1 / (k - 1)$, because for each permutation any element $a$ may be followed by any of the other $k - 1$ elements with equal probability. I'm not completely sure this is really correct, though, because there are relationships between the frequency values (i.e. $\sum_{i \in \{1,\ldots,k\}\setminus{\{a\}}}\text{frequency}((a, i)) = N\, \forall\, a \in \{1,\ldots,k\}$). My question is, assuming the previous is actually correct, or otherwise that we know that uniformly sampled permutations have a probability distribution of frequencies of contiguous pairs $D$, can we invert the implication? That is, would observing $D$ in another set of random permutations mean they follow a uniform probability distribution? EDIT: I noticed that the above condition is definitely not enough for a uniform permutation distribution. You could imagine a random permutation such that the first element is always the same but the remaining ones are uniformly shuffled, then it would fulfill the condition but it wouldn't be what I am looking for. So I guess the conditions that I'd need to check are, following a uniform distribution of contiguous pairs and uniform probability of each element falling into each position. Background: I answered this question in Stack Overflow: How to verify that a shuffling algorithm is uniform? (I invite anyone willing to it to comment on my answer or post their own if they think it's wrong). I am a software engineer, so my background in statistics is not the strongest, but (after a misguided attempt) I proposed a small code snippet to measure the frequency with which each possible permutation was generated. While this is (I think) a correct approach, in the sense that it is measuring ""the right thing"", it takes a large number of trials to have significant results, so I was wondering if it may be possible to analyse a smaller statistic, such as the distribution of frequencies of contiguous pairs.","Let's say I have a set of $N$ random $k$-permutations $P_1,\ldots,P_N$ selected according to some probability distribution. I consider the probability distribution of the frequencies of contiguous pairs in a permuted sequence. I'm not sure how to express this properly so I'll give an example: with $k=4$ and the permutation $P_i=(24)$ we would reorder the sequence $[1,2,3,4]$ to $[1,4,3,2]$; what I call ""contiguous pairs"" for $P_i$ would be $(1, 4)$, $(4, 3)$, $(3, 2)$ and $(2, 1)$. So I can count the frequencies of the $k(k - 1)$ possible pairs for my $N$ permutations. Now, my intuition is that, if my permutations are sampled according to a uniform distribution, then each of these frequencies should be about the same as $N \rightarrow \infty$, and they would follow a binomial distribution with $N$ trials and probability $1 / (k - 1)$, because for each permutation any element $a$ may be followed by any of the other $k - 1$ elements with equal probability. I'm not completely sure this is really correct, though, because there are relationships between the frequency values (i.e. $\sum_{i \in \{1,\ldots,k\}\setminus{\{a\}}}\text{frequency}((a, i)) = N\, \forall\, a \in \{1,\ldots,k\}$). My question is, assuming the previous is actually correct, or otherwise that we know that uniformly sampled permutations have a probability distribution of frequencies of contiguous pairs $D$, can we invert the implication? That is, would observing $D$ in another set of random permutations mean they follow a uniform probability distribution? EDIT: I noticed that the above condition is definitely not enough for a uniform permutation distribution. You could imagine a random permutation such that the first element is always the same but the remaining ones are uniformly shuffled, then it would fulfill the condition but it wouldn't be what I am looking for. So I guess the conditions that I'd need to check are, following a uniform distribution of contiguous pairs and uniform probability of each element falling into each position. Background: I answered this question in Stack Overflow: How to verify that a shuffling algorithm is uniform? (I invite anyone willing to it to comment on my answer or post their own if they think it's wrong). I am a software engineer, so my background in statistics is not the strongest, but (after a misguided attempt) I proposed a small code snippet to measure the frequency with which each possible permutation was generated. While this is (I think) a correct approach, in the sense that it is measuring ""the right thing"", it takes a large number of trials to have significant results, so I was wondering if it may be possible to analyse a smaller statistic, such as the distribution of frequencies of contiguous pairs.",,"['statistics', 'permutations']"
53,How to calculate probability distribution for combination of functions,How to calculate probability distribution for combination of functions,,"please excuse (or change, if possible) the title if it doesn't make sense. I have a problem which is something like this: You have a variable $i$ which starts at $i=1$. You also have a target number of $j$, and you have an n-sided die (in my case $j=6$ and $n=6$ but ideally i'd like to be able to solve this generally.) Now you repeatedly roll the n-sided die, each time the die the lands on a number greater than $i$ you increment $i$ by 1. This stops once $i=j$. I've already calculated the mean number of rolls until $i=j$ as: $$\sum_{x=n-(j-1)}^{n-1} \frac{n}{x}$$ Now i'd like to be able to produce a probability distribution of how many rolls until $i=j$. I'm currently only looking at $j=6$ and $n=6$ and have come up with a solution, however it is very manual. I can model the probability of raising $i$ from 1 to 2 (assuming 6-sided die) in $x$ rolls as: $$p_1(x)=\frac 16^{x-1}\times \frac 56 $$ Similarly the probability of raising $i$ from 2 to 3 in $x$ rolls $$p_2(x)=\frac{2}{6}^{x-1}\times \frac 46 $$ (I'll skip the definition of $p_3(x)$ to $p_5(x)$) Now for the probability of raising $i$ from 1 to 6 in just 5 rolls would be $$p_1(1) \times p_2(1) \times ... \times p_5(1)$$ But what I need to do next is the probability of raising $i$ from 1 to 6 in 6 rolls, I realise I need to do something like: $$p_1(2) \times p_2(1) \times ... \times p_5(1) + p_1(1) \times p_2(2) \times ... \times p_5(1) + ... \times p_4(1) \times p_5(2)$$ (Not sure if I removed too much from the above equation but essentially the sum of all the different products of $p_{1-5}$ where the arguments to the functions add up to 6, does that make sense?) And then the above but for all arguments summing to 7 and on to Infinity. So I'm wondering how to generalise this last step? It seems to be that it could/should be able to be represented as a function. Maybe there is something similar that already exists? Thank you in advance. Let me know if i need to edit the question to clarify anything :)","please excuse (or change, if possible) the title if it doesn't make sense. I have a problem which is something like this: You have a variable $i$ which starts at $i=1$. You also have a target number of $j$, and you have an n-sided die (in my case $j=6$ and $n=6$ but ideally i'd like to be able to solve this generally.) Now you repeatedly roll the n-sided die, each time the die the lands on a number greater than $i$ you increment $i$ by 1. This stops once $i=j$. I've already calculated the mean number of rolls until $i=j$ as: $$\sum_{x=n-(j-1)}^{n-1} \frac{n}{x}$$ Now i'd like to be able to produce a probability distribution of how many rolls until $i=j$. I'm currently only looking at $j=6$ and $n=6$ and have come up with a solution, however it is very manual. I can model the probability of raising $i$ from 1 to 2 (assuming 6-sided die) in $x$ rolls as: $$p_1(x)=\frac 16^{x-1}\times \frac 56 $$ Similarly the probability of raising $i$ from 2 to 3 in $x$ rolls $$p_2(x)=\frac{2}{6}^{x-1}\times \frac 46 $$ (I'll skip the definition of $p_3(x)$ to $p_5(x)$) Now for the probability of raising $i$ from 1 to 6 in just 5 rolls would be $$p_1(1) \times p_2(1) \times ... \times p_5(1)$$ But what I need to do next is the probability of raising $i$ from 1 to 6 in 6 rolls, I realise I need to do something like: $$p_1(2) \times p_2(1) \times ... \times p_5(1) + p_1(1) \times p_2(2) \times ... \times p_5(1) + ... \times p_4(1) \times p_5(2)$$ (Not sure if I removed too much from the above equation but essentially the sum of all the different products of $p_{1-5}$ where the arguments to the functions add up to 6, does that make sense?) And then the above but for all arguments summing to 7 and on to Infinity. So I'm wondering how to generalise this last step? It seems to be that it could/should be able to be represented as a function. Maybe there is something similar that already exists? Thank you in advance. Let me know if i need to edit the question to clarify anything :)",,['statistics']
54,Sufficient statistics for beta-binomial distribution,Sufficient statistics for beta-binomial distribution,,"The beta-binomial pmf is $$f_X(x) = {n \choose x}{B(x+\alpha, n-x+\beta)\over B(\alpha, \beta)}$$ where $B$ is the beta function. The numerator is the issue here when trying to separate data from parameters. I tried using $$B(x+\alpha, n-x+\beta) \propto \Gamma(y+\alpha)\Gamma(n-x+\beta)$$ and the fact that $x$ is discrete but that led me to a polynomial where parameters and data are still intertwined through the exponents and coefficients. Is this solvable at all?","The beta-binomial pmf is $$f_X(x) = {n \choose x}{B(x+\alpha, n-x+\beta)\over B(\alpha, \beta)}$$ where $B$ is the beta function. The numerator is the issue here when trying to separate data from parameters. I tried using $$B(x+\alpha, n-x+\beta) \propto \Gamma(y+\alpha)\Gamma(n-x+\beta)$$ and the fact that $x$ is discrete but that led me to a polynomial where parameters and data are still intertwined through the exponents and coefficients. Is this solvable at all?",,"['statistics', 'special-functions', 'gamma-function', 'beta-function']"
55,Find the marginal probability density function,Find the marginal probability density function,,"The random vector $[\,X \,\,\, Y \,]'$ has probability density function $f_{X,Y} (x,y) = ke^{-2x^2-3xy-\frac{9}{2}y^2}$, where $k$ is some constant Find $k.$ Find the marginal probability density functions of $X$ and $Y.$ I know for it to be a valid pdf its integral from negative to positive infinity must be equal to one, and that it must be greater than $0$ for all $x.$ But for starters I'm not sure on the integration.","The random vector $[\,X \,\,\, Y \,]'$ has probability density function $f_{X,Y} (x,y) = ke^{-2x^2-3xy-\frac{9}{2}y^2}$, where $k$ is some constant Find $k.$ Find the marginal probability density functions of $X$ and $Y.$ I know for it to be a valid pdf its integral from negative to positive infinity must be equal to one, and that it must be greater than $0$ for all $x.$ But for starters I'm not sure on the integration.",,"['statistics', 'density-function']"
56,F - measure in Clustering,F - measure in Clustering,,"We can define the F - measure as follows: $$F_\alpha=\frac{1}{\alpha \frac{1}{P}+(1-\alpha)\frac{1}{R}} $$ Now we might be interested in choosing a good $\alpha$. In the article The truth of the F-measure the author states that one can choose the conditions: $$\beta=\frac R P, \text{ where } \frac{\partial F_{\alpha}}{\partial P} = \frac{\partial F_\alpha}{\partial R}$$ and then we obtain $\alpha=1/(\beta^2+1)$ and $$F_\beta=\frac{(1+\beta^2)PR}{\beta^2 P+R} $$ It is said that The motivation behind this condition is that at the point where the gradients of $E$ w.r.t. $P$ and $R$ are equal, the ratio of $R$ against $P$ should be a desired ratio $\beta$. I understand that the condition will guarantee that the user is willing to trade an increment in precision for an equal loss in recall. But I do not get why the equality of both partial derivatives correspond to these hypothesis. I would rather understand when one partial derivative equals the other partial derivative multiplied by minus one. Could anyone explain me why the desired condition (condition in words) correspond to this equality (condition in math terms)? EDIT: Well, we could do the following: $$\partial F=\frac{\partial F_{\alpha}}{\partial P}\partial P+\frac{\partial F_\alpha}{\partial R}\partial R.$$ And since we want for $\partial P=-\partial R$ that $\partial F=0$, we obtain easily the condition. But I have one problem with this: Since $\left. \frac{\partial F_\alpha}{\partial P} \right/ \frac{\partial F_\alpha}{\partial R}=1$, and the fact that the gradient is perpendicular to each level curve ( https://ocw.mit.edu/courses/mathematics/18-02sc-multivariable-calculus-fall-2010/2.-partial-derivatives/part-b-chain-rule-gradient-and-directional-derivatives/session-36-proof/MIT18_02SC_pb_32_comb.pdf ) we would have that the level curve must have $m=-1$. Nonetheless, when I calculate the level curve for some constant $c$ I get the result, $$R(P)=\frac{c(1-\alpha ) P}{P-c\alpha},$$ which clearly is not a linear function with $m=-1$. What am I missing?","We can define the F - measure as follows: $$F_\alpha=\frac{1}{\alpha \frac{1}{P}+(1-\alpha)\frac{1}{R}} $$ Now we might be interested in choosing a good $\alpha$. In the article The truth of the F-measure the author states that one can choose the conditions: $$\beta=\frac R P, \text{ where } \frac{\partial F_{\alpha}}{\partial P} = \frac{\partial F_\alpha}{\partial R}$$ and then we obtain $\alpha=1/(\beta^2+1)$ and $$F_\beta=\frac{(1+\beta^2)PR}{\beta^2 P+R} $$ It is said that The motivation behind this condition is that at the point where the gradients of $E$ w.r.t. $P$ and $R$ are equal, the ratio of $R$ against $P$ should be a desired ratio $\beta$. I understand that the condition will guarantee that the user is willing to trade an increment in precision for an equal loss in recall. But I do not get why the equality of both partial derivatives correspond to these hypothesis. I would rather understand when one partial derivative equals the other partial derivative multiplied by minus one. Could anyone explain me why the desired condition (condition in words) correspond to this equality (condition in math terms)? EDIT: Well, we could do the following: $$\partial F=\frac{\partial F_{\alpha}}{\partial P}\partial P+\frac{\partial F_\alpha}{\partial R}\partial R.$$ And since we want for $\partial P=-\partial R$ that $\partial F=0$, we obtain easily the condition. But I have one problem with this: Since $\left. \frac{\partial F_\alpha}{\partial P} \right/ \frac{\partial F_\alpha}{\partial R}=1$, and the fact that the gradient is perpendicular to each level curve ( https://ocw.mit.edu/courses/mathematics/18-02sc-multivariable-calculus-fall-2010/2.-partial-derivatives/part-b-chain-rule-gradient-and-directional-derivatives/session-36-proof/MIT18_02SC_pb_32_comb.pdf ) we would have that the level curve must have $m=-1$. Nonetheless, when I calculate the level curve for some constant $c$ I get the result, $$R(P)=\frac{c(1-\alpha ) P}{P-c\alpha},$$ which clearly is not a linear function with $m=-1$. What am I missing?",,"['statistics', 'machine-learning', 'clustering']"
57,Inverse Fourier Transform of the Cauchy distribution,Inverse Fourier Transform of the Cauchy distribution,,"Given the characteristic function of the cauchy distribution in the form $$\hat{f}(q) = \exp(-\gamma|q|) $$ I am unsure how to derive the original probability distribution function $$ f(x) = \frac{\gamma}{\pi(\gamma^2+x^2)}$$ via the inverse Fourier transform, which I have tried using the following form. $$ f(x) = \frac{1}{2\pi}\int_{-\infty}^\infty \hat{f}(q)e^{iqx} \, dq $$ I suspect I am going wrong when transforming with respect to the absolute value $|q|$ in the characteristic function as I am unsure how to eliminate it. Any insight is very much appreciated.","Given the characteristic function of the cauchy distribution in the form $$\hat{f}(q) = \exp(-\gamma|q|) $$ I am unsure how to derive the original probability distribution function $$ f(x) = \frac{\gamma}{\pi(\gamma^2+x^2)}$$ via the inverse Fourier transform, which I have tried using the following form. $$ f(x) = \frac{1}{2\pi}\int_{-\infty}^\infty \hat{f}(q)e^{iqx} \, dq $$ I suspect I am going wrong when transforming with respect to the absolute value $|q|$ in the characteristic function as I am unsure how to eliminate it. Any insight is very much appreciated.",,"['statistics', 'probability-distributions', 'fourier-analysis', 'fourier-transform', 'characteristic-functions']"
58,Probability distribution of faulty buses made during one week,Probability distribution of faulty buses made during one week,,"I've been trying to figure out the following question: I modelled the discrete random variable X with a binomial distribution such that: X ~ Bin(3, 3/5) I took the number of trials to be 3 because there can be between zero and three faulty buses ( successful trials ) on the Monday in question. I took the probability of having one faulty bus on a given day to be 3/5. I calculated this by taking the probability of one bus on one day to be 1/5 (because there are five days) and multiplying by three (because there are three faulty buses made that week). This gave me Pr(success) = 3/5 When I used the equation V(X) = npq (n=trials, p=success probability, q=failure probability) I found the variance of X to be equal to 18/25. ( npq = 3 x 3/5 x 2/5 = 18/25 ) In the answers for this question though, the variance is listed as being 12/25: I don't know what I've done wrong here. Have I missed out some fundamental bit of information? Is the answer sheet wrong? Any help is massively appreciated. Thank you for taking the time to read all of this :)","I've been trying to figure out the following question: I modelled the discrete random variable X with a binomial distribution such that: X ~ Bin(3, 3/5) I took the number of trials to be 3 because there can be between zero and three faulty buses ( successful trials ) on the Monday in question. I took the probability of having one faulty bus on a given day to be 3/5. I calculated this by taking the probability of one bus on one day to be 1/5 (because there are five days) and multiplying by three (because there are three faulty buses made that week). This gave me Pr(success) = 3/5 When I used the equation V(X) = npq (n=trials, p=success probability, q=failure probability) I found the variance of X to be equal to 18/25. ( npq = 3 x 3/5 x 2/5 = 18/25 ) In the answers for this question though, the variance is listed as being 12/25: I don't know what I've done wrong here. Have I missed out some fundamental bit of information? Is the answer sheet wrong? Any help is massively appreciated. Thank you for taking the time to read all of this :)",,"['probability', 'statistics', 'probability-distributions', 'binomial-distribution']"
59,How to Make This Estimator Unbiased?,How to Make This Estimator Unbiased?,,"Could someone clarify if I'm interpreting this question correctly? As the sample size increases and approaches infinity, then the expected value of the estimator would approach $0.$ The estimator is biased because $θ$ is not equal to $θ/n.$ But, if $n = 1,$ then wouldn't the expected value${} = θ$? Is this how the statistician's estimator would become unbiased? Clarification appreciated!","Could someone clarify if I'm interpreting this question correctly? As the sample size increases and approaches infinity, then the expected value of the estimator would approach $0.$ The estimator is biased because $θ$ is not equal to $θ/n.$ But, if $n = 1,$ then wouldn't the expected value${} = θ$? Is this how the statistician's estimator would become unbiased? Clarification appreciated!",,['statistics']
60,Estimating a measurement system's standard deviation,Estimating a measurement system's standard deviation,,"I need to know how precise a measurement system is, expressed as a standard deviation. I don't really have much of a background in math so please excuse me if I'm a bit unclear or inaccurate about something. The simplest way I know of doing this is by taking e.g. 100 measurements of the same object and then using the usual sample standard deviation formula. Unfortunately, I can't use this method. I must measure different objects multiple times. Let's say 10 objects, 10 times each. The thing that comes to mind is to calculate the mean for each group, subtract the relevant means from each measurement (sort of a normalisation) and then calculate the standard deviation from the resulting 100 numbers. Does this make sense? If not, how do I approach the problem?","I need to know how precise a measurement system is, expressed as a standard deviation. I don't really have much of a background in math so please excuse me if I'm a bit unclear or inaccurate about something. The simplest way I know of doing this is by taking e.g. 100 measurements of the same object and then using the usual sample standard deviation formula. Unfortunately, I can't use this method. I must measure different objects multiple times. Let's say 10 objects, 10 times each. The thing that comes to mind is to calculate the mean for each group, subtract the relevant means from each measurement (sort of a normalisation) and then calculate the standard deviation from the resulting 100 numbers. Does this make sense? If not, how do I approach the problem?",,"['probability', 'statistics', 'normal-distribution', 'standard-deviation']"
61,(Probability) Independent Probability Question,(Probability) Independent Probability Question,,"A car race is very  dangerous, and a crash can cause serious injuries. The league requires that anyone who has a crash to have a medical examination before they are  allowed to race again. A certain racer has an independent .04 probability of a crash in a race a)  What is the probability that he will have his first crash within the first 30 races  she runs this season? My solution Treating like the lottery problem Probability of not having a crash P(First Crash In 30 Races) = $.04^{30}$ But this produces the wrong answer since the book says that the answer is $.7061$ . Could someone explain why my approach doesn't work and how to properly go about this problem?","A car race is very  dangerous, and a crash can cause serious injuries. The league requires that anyone who has a crash to have a medical examination before they are  allowed to race again. A certain racer has an independent .04 probability of a crash in a race a)  What is the probability that he will have his first crash within the first 30 races  she runs this season? My solution Treating like the lottery problem Probability of not having a crash P(First Crash In 30 Races) = But this produces the wrong answer since the book says that the answer is . Could someone explain why my approach doesn't work and how to properly go about this problem?",.04^{30} .7061,"['probability', 'probability-theory', 'statistics']"
62,Random variables with rapidly varying tails,Random variables with rapidly varying tails,,"I have been trying to prove the following: Consider an i.i.d. sample of random variables $\left\{ X_n \right\}$. Their distribution $F$ is said to satisfy the rapidly varying tail condition , if   $\forall a > 1$ the following holds:   $$ \lim_{x \to \infty} \frac{1 - F(ax)}{1 - F(x)} = 0 $$   Show that if $\displaystyle \frac{\max_{i=1,\dots,n} X_i}{b_n} \overset{\mathbb{P}}{\to} 1$ (convergence in probability), for a sequence   $b_n \to \infty$, then $F$ must satisfy the rapidly varying tail condition. I consider the definition of convergence in probability, $$    \lim_{n \to \infty} \left(    \left|\frac{\max_{i=1, \dots, n}(X_1, \dots, X_n}{n} - 1 \right| > \varepsilon \right) = 0 $$ and write (for the positive part): \begin{align*}     \mathbb{P}\left(\max_{i=1,\dots,n} X_i > (1 + \varepsilon) b_n\right) &=      \mathbb{P}\left[ \left(     \bigcap_1^n X_i \leq (1 + \varepsilon) b_n \right)^c \right] \\ &= \mathbb{P}\left(     \bigcup_1^n X_i > (1 + \varepsilon) b_n \right) =    n \mathbb{P}(X_1 > (1 + \varepsilon) b_n) \\ \end{align*} For the negative part, I know that \begin{align*}     \mathbb{P}\left(\max_{i=1,\dots,n} X_i < (1 - \varepsilon) b_n\right) &=      \mathbb{P}\left[     \bigcap_1^n X_i < (1 - \varepsilon) b_n \right] \\ &= 1 - n\mathbb{P}(X_i \geq (1 - \varepsilon)b_n) \end{align*} Taking limits in the positive and negative parts and equating them as they both have to be equal to 0 obtain $$ \lim_{n \to \infty} n \mathbb{P}(X_1 > (1 + \varepsilon) b_n) = 0, \quad \lim_{n \to \infty} n \mathbb{P}(X_1 \geq (1 - \varepsilon) b_n) = 1 $$ However, at this point I'm stuck. I can obviously deduce that $$ \lim_{n \to \infty} \frac{1 - F(az_n)}{1 - F(z_n)} = 0, \quad a := \frac{1}{1-\varepsilon} > 1, \; z_n = (1 - \varepsilon) b_n $$ however this does not exactly imply the rapidly varying tail condition, which must hold for arbitrary $x \to \infty$. Any ideas?","I have been trying to prove the following: Consider an i.i.d. sample of random variables $\left\{ X_n \right\}$. Their distribution $F$ is said to satisfy the rapidly varying tail condition , if   $\forall a > 1$ the following holds:   $$ \lim_{x \to \infty} \frac{1 - F(ax)}{1 - F(x)} = 0 $$   Show that if $\displaystyle \frac{\max_{i=1,\dots,n} X_i}{b_n} \overset{\mathbb{P}}{\to} 1$ (convergence in probability), for a sequence   $b_n \to \infty$, then $F$ must satisfy the rapidly varying tail condition. I consider the definition of convergence in probability, $$    \lim_{n \to \infty} \left(    \left|\frac{\max_{i=1, \dots, n}(X_1, \dots, X_n}{n} - 1 \right| > \varepsilon \right) = 0 $$ and write (for the positive part): \begin{align*}     \mathbb{P}\left(\max_{i=1,\dots,n} X_i > (1 + \varepsilon) b_n\right) &=      \mathbb{P}\left[ \left(     \bigcap_1^n X_i \leq (1 + \varepsilon) b_n \right)^c \right] \\ &= \mathbb{P}\left(     \bigcup_1^n X_i > (1 + \varepsilon) b_n \right) =    n \mathbb{P}(X_1 > (1 + \varepsilon) b_n) \\ \end{align*} For the negative part, I know that \begin{align*}     \mathbb{P}\left(\max_{i=1,\dots,n} X_i < (1 - \varepsilon) b_n\right) &=      \mathbb{P}\left[     \bigcap_1^n X_i < (1 - \varepsilon) b_n \right] \\ &= 1 - n\mathbb{P}(X_i \geq (1 - \varepsilon)b_n) \end{align*} Taking limits in the positive and negative parts and equating them as they both have to be equal to 0 obtain $$ \lim_{n \to \infty} n \mathbb{P}(X_1 > (1 + \varepsilon) b_n) = 0, \quad \lim_{n \to \infty} n \mathbb{P}(X_1 \geq (1 - \varepsilon) b_n) = 1 $$ However, at this point I'm stuck. I can obviously deduce that $$ \lim_{n \to \infty} \frac{1 - F(az_n)}{1 - F(z_n)} = 0, \quad a := \frac{1}{1-\varepsilon} > 1, \; z_n = (1 - \varepsilon) b_n $$ however this does not exactly imply the rapidly varying tail condition, which must hold for arbitrary $x \to \infty$. Any ideas?",,"['probability', 'statistics', 'probability-distributions', 'convergence-divergence', 'weak-convergence']"
63,P-Value from Sign Test,P-Value from Sign Test,,"I'm so confused with this question and its answer provided as following: The Question The Answer provided I totally don't understand why when we calculate the P-value, we need to calculate as $P(X \ge 1) = 1-P(X=0).$ Since we set the data less than 2 as positive sign here, then we only have 1 positive sign in the data set. Then what does $P(X=0)$ represent? And what does $P(X \ge 1)$ stand for? Thank you for your help, I really can't get any answer directly from Google.","I'm so confused with this question and its answer provided as following: The Question The Answer provided I totally don't understand why when we calculate the P-value, we need to calculate as $P(X \ge 1) = 1-P(X=0).$ Since we set the data less than 2 as positive sign here, then we only have 1 positive sign in the data set. Then what does $P(X=0)$ represent? And what does $P(X \ge 1)$ stand for? Thank you for your help, I really can't get any answer directly from Google.",,"['statistics', 'hypothesis-testing']"
64,"What is the Probability Generating Function (PGF) for the ""Matching Problem""?","What is the Probability Generating Function (PGF) for the ""Matching Problem""?",,"I've been working on a set of questions that ask me to prove various results regarding probabilities concerning the classic ""matching problem"". There are $n$ letters written to different people, and envelopes correspondingly addressed. The letters are shuffled such that any particular letter-envelope allocation is equally likely as any other. Define a ""match"" if a particular letter is placed in its correct envelope. The question began by letting the notation $M_{n,j}=n!P(A_{n,j})$ represent the number of permutations resulting in $j$ matches out of $n$ letters, where $A_{n,j}$ is the event that $j$ matches have occurred out of $n$ letters. Part a) of the question asked me to show that: $$M_{n,j}={j+1\over n+1}M_{n+1,j+1}$$ I found this easy enough. The next question defined the generating function for the probability of receiving $j$ matches out of $n$ letters: $G_n(z)=\sum_{j=0}^nP(A_{n,j})z^j$, and asked me, using part a) to prove that: $$G_{n+1}(z)=1+\int_{1}^zG_n(w)dw$$ Once again, I had no trouble doing this using the first result. It was the third part of the question, however, that confused me. It read ""hence find the pgf (probability generating function) $G_n(z)$"". The result of the next question leads me to believe that the solution is: $$G_n(z)=\sum_{k=0}^n{(z-1)^k\over k!}$$ That said, I have no idea how to actually reach this conclusion, and would appreciate some help getting there, preferably using properties of generating functions. It would be preferable to avoid using the formula for number of derangements, as we have not covered this in class and therefore is likely not involved in the expected solution. Thanks!","I've been working on a set of questions that ask me to prove various results regarding probabilities concerning the classic ""matching problem"". There are $n$ letters written to different people, and envelopes correspondingly addressed. The letters are shuffled such that any particular letter-envelope allocation is equally likely as any other. Define a ""match"" if a particular letter is placed in its correct envelope. The question began by letting the notation $M_{n,j}=n!P(A_{n,j})$ represent the number of permutations resulting in $j$ matches out of $n$ letters, where $A_{n,j}$ is the event that $j$ matches have occurred out of $n$ letters. Part a) of the question asked me to show that: $$M_{n,j}={j+1\over n+1}M_{n+1,j+1}$$ I found this easy enough. The next question defined the generating function for the probability of receiving $j$ matches out of $n$ letters: $G_n(z)=\sum_{j=0}^nP(A_{n,j})z^j$, and asked me, using part a) to prove that: $$G_{n+1}(z)=1+\int_{1}^zG_n(w)dw$$ Once again, I had no trouble doing this using the first result. It was the third part of the question, however, that confused me. It read ""hence find the pgf (probability generating function) $G_n(z)$"". The result of the next question leads me to believe that the solution is: $$G_n(z)=\sum_{k=0}^n{(z-1)^k\over k!}$$ That said, I have no idea how to actually reach this conclusion, and would appreciate some help getting there, preferably using properties of generating functions. It would be preferable to avoid using the formula for number of derangements, as we have not covered this in class and therefore is likely not involved in the expected solution. Thanks!",,"['probability', 'sequences-and-series', 'combinatorics', 'statistics', 'generating-functions']"
65,Which statistical test should I use in this situation (sample size question)?,Which statistical test should I use in this situation (sample size question)?,,"Assume I have 5 millions oranges. Now I want to test a hypothesis. If there is a black dot on an orange, then the orange is BAD. Within these 5 millions oranges, I have been told that which are bad. However, I cannot check all bad oranges to see whether there is black dot on each. I want to find the sample size that I need to prove my hypothesis is right at 95% sure.","Assume I have 5 millions oranges. Now I want to test a hypothesis. If there is a black dot on an orange, then the orange is BAD. Within these 5 millions oranges, I have been told that which are bad. However, I cannot check all bad oranges to see whether there is black dot on each. I want to find the sample size that I need to prove my hypothesis is right at 95% sure.",,['statistics']
66,Adding Gaussian Distributions,Adding Gaussian Distributions,,"I am trying to show that a set of numbers distributed from a Gaussian distribution {g1, g2,...,gn} with a standard deviation of 1 and a mean of zero can be transformed to a set of Gaussian numbers {G1, G2,...,Gn} that have a standard deviation of s and a mean of m by the formula: Gi = s * gi + m  (ignoring any normalization constants) Despite my best efforts I cannot seem to find a way to prove this well known relationship true.","I am trying to show that a set of numbers distributed from a Gaussian distribution {g1, g2,...,gn} with a standard deviation of 1 and a mean of zero can be transformed to a set of Gaussian numbers {G1, G2,...,Gn} that have a standard deviation of s and a mean of m by the formula: Gi = s * gi + m  (ignoring any normalization constants) Despite my best efforts I cannot seem to find a way to prove this well known relationship true.",,"['statistics', 'probability-distributions', 'normal-distribution']"
67,I'm so confused with Null hypothesis and Alternative hypothesis in this solution,I'm so confused with Null hypothesis and Alternative hypothesis in this solution,,"So the question says ""A company that claims the average time a customer waits on hold is less than $5$ minutes. A sample of $35$ customers have an average wait time of $4.78$ minutes . Assume the population standard deviation for the wait time is $1.6$ minutes. Test the company's claim"" So to me the null hypothesis is the status quo therefore $H_0\lt 5$ whereas the alternative hypothesis $H_1$ should be $H_1\ge5$ However the official answer to this solution is completely opposite it's stated $H_0\ge5$ , $H_1\lt5$ What am I missing here?","So the question says ""A company that claims the average time a customer waits on hold is less than $5$ minutes. A sample of $35$ customers have an average wait time of $4.78$ minutes . Assume the population standard deviation for the wait time is $1.6$ minutes. Test the company's claim"" So to me the null hypothesis is the status quo therefore $H_0\lt 5$ whereas the alternative hypothesis $H_1$ should be $H_1\ge5$ However the official answer to this solution is completely opposite it's stated $H_0\ge5$ , $H_1\lt5$ What am I missing here?",,"['probability', 'statistics']"
68,Sinusoidal regression,Sinusoidal regression,,"I am trying to do my homework on finding parameters with some data and I am kind of stuck. The problem is to find parameters $(T_m, T_0, t_0, \omega) \in \mathbb R \times \mathbb R \times \mathbb R_{+} \times \mathbb R_{+}$ such that $$T_i = T_m + T_0 \sin (\omega (t_i-t_0)) + \epsilon_i$$ for all the data point $(t_i, T_i)$. $\epsilon_i$ is a small noise. I tried to minimize the quadratic error but since the quadratic error function is not convex, the minimization is not guaranteed to be global. Can someone help me find a method to solve the problem?","I am trying to do my homework on finding parameters with some data and I am kind of stuck. The problem is to find parameters $(T_m, T_0, t_0, \omega) \in \mathbb R \times \mathbb R \times \mathbb R_{+} \times \mathbb R_{+}$ such that $$T_i = T_m + T_0 \sin (\omega (t_i-t_0)) + \epsilon_i$$ for all the data point $(t_i, T_i)$. $\epsilon_i$ is a small noise. I tried to minimize the quadratic error but since the quadratic error function is not convex, the minimization is not guaranteed to be global. Can someone help me find a method to solve the problem?",,"['statistics', 'trigonometry', 'numerical-methods']"
69,Covariance of two standard normal random variables,Covariance of two standard normal random variables,,"Let $X$ follow the standard normal distribution $N(0,1)$ Let $a>0$ Let $Y=X$ if $|X|<a$ $ $ $ $ $ $ $ $ $ $ $ $ $Y=-X$ if $|X|\geq a$ Then, it is easily shown that Y follows the standard normal distribution $N(0,1)$ What is $Cov(X,Y)$? Is the random vector $(X,Y)$ a multivariate normal? Firstly, since $E(X)=E(Y)=0$, $Cov(X,Y)=E(XY)$ I think $E(XY)=E(X^{2}1_{|X|<a}) - E(X^{2}1_{|X|\geq a})$ how do I proceed to solve this problem? Secondly, I think the random vector is not multivariate normal since if it were, it would be true that $X+Y$ is normal but I think it is not","Let $X$ follow the standard normal distribution $N(0,1)$ Let $a>0$ Let $Y=X$ if $|X|<a$ $ $ $ $ $ $ $ $ $ $ $ $ $Y=-X$ if $|X|\geq a$ Then, it is easily shown that Y follows the standard normal distribution $N(0,1)$ What is $Cov(X,Y)$? Is the random vector $(X,Y)$ a multivariate normal? Firstly, since $E(X)=E(Y)=0$, $Cov(X,Y)=E(XY)$ I think $E(XY)=E(X^{2}1_{|X|<a}) - E(X^{2}1_{|X|\geq a})$ how do I proceed to solve this problem? Secondly, I think the random vector is not multivariate normal since if it were, it would be true that $X+Y$ is normal but I think it is not",,"['probability', 'statistics', 'normal-distribution']"
70,Can Pythagoras Theorem be used to average a set of values for Comparison.,Can Pythagoras Theorem be used to average a set of values for Comparison.,,"My basic math training tells me that you can apply Pythagoras theorem in N-Dimensional space allowing you to measure the size of a vector from The origin to a point. If you do this for multiple data points you can compare the length of the vector, to work out which one is larger. Is this a form of averaging? Am I missing something from a Mathematical theory standpoint or is it actually commonplace? Are there benefits of using this approach vs. Geometric Means or Arithmetic Means? You can assume this is for Positive Numbers only.","My basic math training tells me that you can apply Pythagoras theorem in N-Dimensional space allowing you to measure the size of a vector from The origin to a point. If you do this for multiple data points you can compare the length of the vector, to work out which one is larger. Is this a form of averaging? Am I missing something from a Mathematical theory standpoint or is it actually commonplace? Are there benefits of using this approach vs. Geometric Means or Arithmetic Means? You can assume this is for Positive Numbers only.",,"['geometry', 'statistics', 'means']"
71,A multiple-choice examination consists of $75$ questions- Probability,A multiple-choice examination consists of  questions- Probability,75,"A multiple-choice examination consists of $75$  questions, each having possible choices a, b, c, d, and e. Approximate the probability that a student will get at most $13$  answers correct if she randomly guesses at each answer. (Note that, if she randomly guesses at each answer, then the probability that she gets any one answer correct is $0.2$.) Use the normal approximation to the binomial with a correction for continuity. I tried a bit  Binomial Problem with n = 75 P(correct answer)=0.2 Binomial probability:P(X = x)=$0.10171948927$ I am I correct?","A multiple-choice examination consists of $75$  questions, each having possible choices a, b, c, d, and e. Approximate the probability that a student will get at most $13$  answers correct if she randomly guesses at each answer. (Note that, if she randomly guesses at each answer, then the probability that she gets any one answer correct is $0.2$.) Use the normal approximation to the binomial with a correction for continuity. I tried a bit  Binomial Problem with n = 75 P(correct answer)=0.2 Binomial probability:P(X = x)=$0.10171948927$ I am I correct?",,"['probability', 'probability-theory', 'statistics']"
72,Find the maximum likelihood estimator of b (Regression coefficient),Find the maximum likelihood estimator of b (Regression coefficient),,"Consider the regression model: $y_i = bx_i + e_i,\quad     1 ≤ i ≤ n$, Suppose that $x_i$’s take values −1 or +1 and $e_i$’s have density $f(t) ={\frac{1}{2}}e^{−|t|}, t \in \mathbb{R}$. Find the maximum likelihood estimator of $b$. Therefore  $\; y_i-bx_i \sim \epsilon \quad \text{,which follows}\quad f(t) ={\frac{1}{2}}e^{−|t|}\\ \therefore f(y,b,x_i)= {\frac{1}{2}}e^{−|y_i-bx_i|}\\ \Rightarrow L(y,x_i,b) = {\frac{1}{2}}^n e^{−\sum|y_i-bx_i|}\\ \Rightarrow \frac{\partial\log L(y,x_i,b)}{\partial b} = -\frac{\partial{\sum |y_i-bx_i|}}{\partial b} $ Any ideas about how to proceed??","Consider the regression model: $y_i = bx_i + e_i,\quad     1 ≤ i ≤ n$, Suppose that $x_i$’s take values −1 or +1 and $e_i$’s have density $f(t) ={\frac{1}{2}}e^{−|t|}, t \in \mathbb{R}$. Find the maximum likelihood estimator of $b$. Therefore  $\; y_i-bx_i \sim \epsilon \quad \text{,which follows}\quad f(t) ={\frac{1}{2}}e^{−|t|}\\ \therefore f(y,b,x_i)= {\frac{1}{2}}e^{−|y_i-bx_i|}\\ \Rightarrow L(y,x_i,b) = {\frac{1}{2}}^n e^{−\sum|y_i-bx_i|}\\ \Rightarrow \frac{\partial\log L(y,x_i,b)}{\partial b} = -\frac{\partial{\sum |y_i-bx_i|}}{\partial b} $ Any ideas about how to proceed??",,"['probability', 'statistics', 'maximum-likelihood', 'linear-regression']"
73,Calculating the betweenness centrality of this small graph?,Calculating the betweenness centrality of this small graph?,,"I don't exactly get the calculation method for computing the betweenness centrality of nodes. Given the following graph represented as below: I want to calculate the betweenness centrality of each node. The formula I believe should be $$g(v) = \sum_{s\neq t \neq v} \frac{\sigma_{st}(v)}{\sigma_{st}}$$ where $\sigma$ means the shortest path from one node s to another node t, for a certain node v involved in the path. Question: does the $s$ and $t$ nodes represent every possible pair of nodes? To give an example, suppose $s = 1$ and $t = 4$. Then my $\sigma_{14}(2) = 1$, and similarly $\sigma_{13}(2) = 1$, and $\sigma_{15}(2) = 0$. So summing it all up, I have $g(v) = 2 / 3$, since there are 3 paths? But with the above data, how can I quickly compute by hand the betweeness centrality of each node? If for example I have node 5 isolated from the rest of the nodes, then is $\sigma_{st}$ still 3? Because then there will be no shortest path from 1 to 5. Going by the above example, I say the betweenness centrality of nodes 1 to 5 is 0, 2/3, 3/3, 2/3, 0, will this be correct? But if I look at it from another perspective, there could be theoretically 10 shortest paths (5 choose 2 = 10). Using the above information, what if I want to compute further statistics like edge centrality? Is there an efficient way to do this?","I don't exactly get the calculation method for computing the betweenness centrality of nodes. Given the following graph represented as below: I want to calculate the betweenness centrality of each node. The formula I believe should be $$g(v) = \sum_{s\neq t \neq v} \frac{\sigma_{st}(v)}{\sigma_{st}}$$ where $\sigma$ means the shortest path from one node s to another node t, for a certain node v involved in the path. Question: does the $s$ and $t$ nodes represent every possible pair of nodes? To give an example, suppose $s = 1$ and $t = 4$. Then my $\sigma_{14}(2) = 1$, and similarly $\sigma_{13}(2) = 1$, and $\sigma_{15}(2) = 0$. So summing it all up, I have $g(v) = 2 / 3$, since there are 3 paths? But with the above data, how can I quickly compute by hand the betweeness centrality of each node? If for example I have node 5 isolated from the rest of the nodes, then is $\sigma_{st}$ still 3? Because then there will be no shortest path from 1 to 5. Going by the above example, I say the betweenness centrality of nodes 1 to 5 is 0, 2/3, 3/3, 2/3, 0, will this be correct? But if I look at it from another perspective, there could be theoretically 10 shortest paths (5 choose 2 = 10). Using the above information, what if I want to compute further statistics like edge centrality? Is there an efficient way to do this?",,"['statistics', 'graph-theory']"
74,variance of regression estimators,variance of regression estimators,,"Given the regression eqn: $y_0= \beta_0 +\beta_1 x_i + \epsilon_i$ I am having difficulty in calculating the variance of $\beta_0$ Here is how I proceeded:- $\operatorname{Var}(b_0)= \operatorname{Var}(\bar Y -b_1\bar X)$, where $b_0,b_1 \text{are parameters estimator} $; \begin{align} \operatorname{Var}(b_0)& =\operatorname{Var}(\bar Y)+\operatorname{Var}(b_1\bar X) -2\operatorname{Cov}(\bar Y,b_1\bar X)\\[10pt] &= \operatorname{Var}(\bar Y)+(\bar X)^2\operatorname{Var}(b_1) -2\bar X\operatorname{Cov}(\bar Y,b_1)\\ \end{align} I have already got the value of $Var(b_1)$,but i cannot prove $\operatorname{Cov}(\bar Y,b_1)=0$. Thanks!","Given the regression eqn: $y_0= \beta_0 +\beta_1 x_i + \epsilon_i$ I am having difficulty in calculating the variance of $\beta_0$ Here is how I proceeded:- $\operatorname{Var}(b_0)= \operatorname{Var}(\bar Y -b_1\bar X)$, where $b_0,b_1 \text{are parameters estimator} $; \begin{align} \operatorname{Var}(b_0)& =\operatorname{Var}(\bar Y)+\operatorname{Var}(b_1\bar X) -2\operatorname{Cov}(\bar Y,b_1\bar X)\\[10pt] &= \operatorname{Var}(\bar Y)+(\bar X)^2\operatorname{Var}(b_1) -2\bar X\operatorname{Cov}(\bar Y,b_1)\\ \end{align} I have already got the value of $Var(b_1)$,but i cannot prove $\operatorname{Cov}(\bar Y,b_1)=0$. Thanks!",,"['statistics', 'regression', 'linear-regression']"
75,Intuition behind the critical difference of ANOVA,Intuition behind the critical difference of ANOVA,,"I am studying Analysis of Variance. Suppose,  we have done ANOVA and found out that null hypothesis is rejected. This means there is a significant difference between at least one pair of the treatments. Now, we would like to know about those pairs. For that my book is calculating something called as Critical Difference between any two pairs: $CD.=t_{n-k}(\alpha/2).S_{E}^2\sqrt{2/n}$ Here, $n-k$ is the degree of freedom of the error. And $S_{E}^2$ is the sum of square due to error. I am not able to understand the intuition behind the above formula for critical difference.","I am studying Analysis of Variance. Suppose,  we have done ANOVA and found out that null hypothesis is rejected. This means there is a significant difference between at least one pair of the treatments. Now, we would like to know about those pairs. For that my book is calculating something called as Critical Difference between any two pairs: $CD.=t_{n-k}(\alpha/2).S_{E}^2\sqrt{2/n}$ Here, $n-k$ is the degree of freedom of the error. And $S_{E}^2$ is the sum of square due to error. I am not able to understand the intuition behind the above formula for critical difference.",,"['statistics', 'self-learning', 'variance']"
76,"Statistics - Chebyshev's rule, my answer is wrong for some reason?","Statistics - Chebyshev's rule, my answer is wrong for some reason?",,"I have the following problem : Determine what age interval will contain at least 95% of the data (Chebyshev's) ? Now, I have standard deviation of 1.516, mean of 19.211. The formula is $1-(1/k^2) = .95$ So I solve for k to get $\sqrt 2$. Now, I calculate the interval by mean + $\sqrt 2$*standard deviation = RIGHT AGE INTERVAL Why is this wrong? I get approximately $21.3578$. The left interval, let's just skip it for now. Is my logic off?","I have the following problem : Determine what age interval will contain at least 95% of the data (Chebyshev's) ? Now, I have standard deviation of 1.516, mean of 19.211. The formula is $1-(1/k^2) = .95$ So I solve for k to get $\sqrt 2$. Now, I calculate the interval by mean + $\sqrt 2$*standard deviation = RIGHT AGE INTERVAL Why is this wrong? I get approximately $21.3578$. The left interval, let's just skip it for now. Is my logic off?",,['statistics']
77,What is the characteristic function of a p.d.f with $\mathbb{R}^+$ support?,What is the characteristic function of a p.d.f with  support?,\mathbb{R}^+,"Considering a generic p.d.f. $p(x)$, we know that the characteristic of such distribution is given by $\varphi(t)=E[e^{i t x}]$. Here $t,x\in (-\infty,\infty)$. Now I would like to ask what is the characteristic function of a p.d.f. where its support is not the whole real numbers, for instance, the support is $\mathbb{R}^+$. I already understand that as follows: Assume a two dimensional distribution $f(x,y)$ in $\mathbb{R}^2$ with characteristic function $E[e^{i(k_x x+k_y y)}]$. By using polar coordinates $x=r \cos \theta$ and $x=r \sin \theta$ and averaging over $\theta$ we find $$ p(r)=r\int_{0}^{2\pi} d\theta\, f(r\cos\theta,r\sin\theta). $$ Now the support of the distribution $p(r)$ is $\mathbb{R}^+$. In addition, we can average out the characteristic function too, $$ \frac{1}{2\pi} E\left[ \int_{0}^{2\pi}d\theta\, e^{i r k\cos(\theta-\theta_k)}\right]=E[J_0(k\, r)],$$ where in the above $k_x=k \cos \theta_k$ and $k_y=k \sin \theta_k$. In the above, $J_0(k\, r)$ is the Bessel function of the first kind. In other words, I think the characteristic function for a general distribution $p(r)$ with $\mathbb{R}^+$ is $E[J_0(k\, r)]$. I am not sure that the above conclusion is true. And if it is true I am not sure it is unique. Also what is the systematic way to find the above result?","Considering a generic p.d.f. $p(x)$, we know that the characteristic of such distribution is given by $\varphi(t)=E[e^{i t x}]$. Here $t,x\in (-\infty,\infty)$. Now I would like to ask what is the characteristic function of a p.d.f. where its support is not the whole real numbers, for instance, the support is $\mathbb{R}^+$. I already understand that as follows: Assume a two dimensional distribution $f(x,y)$ in $\mathbb{R}^2$ with characteristic function $E[e^{i(k_x x+k_y y)}]$. By using polar coordinates $x=r \cos \theta$ and $x=r \sin \theta$ and averaging over $\theta$ we find $$ p(r)=r\int_{0}^{2\pi} d\theta\, f(r\cos\theta,r\sin\theta). $$ Now the support of the distribution $p(r)$ is $\mathbb{R}^+$. In addition, we can average out the characteristic function too, $$ \frac{1}{2\pi} E\left[ \int_{0}^{2\pi}d\theta\, e^{i r k\cos(\theta-\theta_k)}\right]=E[J_0(k\, r)],$$ where in the above $k_x=k \cos \theta_k$ and $k_y=k \sin \theta_k$. In the above, $J_0(k\, r)$ is the Bessel function of the first kind. In other words, I think the characteristic function for a general distribution $p(r)$ with $\mathbb{R}^+$ is $E[J_0(k\, r)]$. I am not sure that the above conclusion is true. And if it is true I am not sure it is unique. Also what is the systematic way to find the above result?",,"['probability-theory', 'statistics', 'probability-distributions']"
78,Identiy matrix with lambda,Identiy matrix with lambda,,"I need some help with my homework in a subject called ""Matrices in statistics"". The task is to show that  $$ P_{ij}(\lambda)^{-1} = P_{ij}\left(\frac{1}{\lambda}\right), $$ where $P_{ij} $ is an identity matrix, where the value of i-th row and j-th column is $\lambda.$ Here's my initial solution (which wasn't enough for the teacher): -- We need to show, that $$ P_{ij}\left(\frac{1}{\lambda}\right) P_{ij}({\lambda}) =  P_{ij}({\lambda}) P_{ij}\left(\frac{1}{\lambda}\right) = I_n   $$ So: 1) $$ P_{ij}\left(\frac{1}{\lambda}\right) P_{ij}({\lambda}) = P_{ij}\left(\frac{1}{\lambda} \cdot\lambda\right)   =  P_{ij}(1) = I_n$$ And 2)  $$  P_{ij}({\lambda})P_{ij}\left(\frac{1}{\lambda}\right) = P_{ij}\left(\lambda\cdot\frac{1}{\lambda}\right)   =  P_{ij}(1) = I_n $$ Q.E.D I submitted this solution, but my lecturer gave it back and wrote, that I need to supplement this solution. More precisely, I need to show, that $$ \left(P_{ij}(\lambda)P_{ij}\left(\frac{1}{\lambda}\right)\right)_{kl} = \begin{cases} 1, k=l  \\ 0, k \neq l \end{cases} $$ And that's what gets me confused - I'm not sure, how to do it.  I would be really thankful, if you could help me with this one!","I need some help with my homework in a subject called ""Matrices in statistics"". The task is to show that  $$ P_{ij}(\lambda)^{-1} = P_{ij}\left(\frac{1}{\lambda}\right), $$ where $P_{ij} $ is an identity matrix, where the value of i-th row and j-th column is $\lambda.$ Here's my initial solution (which wasn't enough for the teacher): -- We need to show, that $$ P_{ij}\left(\frac{1}{\lambda}\right) P_{ij}({\lambda}) =  P_{ij}({\lambda}) P_{ij}\left(\frac{1}{\lambda}\right) = I_n   $$ So: 1) $$ P_{ij}\left(\frac{1}{\lambda}\right) P_{ij}({\lambda}) = P_{ij}\left(\frac{1}{\lambda} \cdot\lambda\right)   =  P_{ij}(1) = I_n$$ And 2)  $$  P_{ij}({\lambda})P_{ij}\left(\frac{1}{\lambda}\right) = P_{ij}\left(\lambda\cdot\frac{1}{\lambda}\right)   =  P_{ij}(1) = I_n $$ Q.E.D I submitted this solution, but my lecturer gave it back and wrote, that I need to supplement this solution. More precisely, I need to show, that $$ \left(P_{ij}(\lambda)P_{ij}\left(\frac{1}{\lambda}\right)\right)_{kl} = \begin{cases} 1, k=l  \\ 0, k \neq l \end{cases} $$ And that's what gets me confused - I'm not sure, how to do it.  I would be really thankful, if you could help me with this one!",,"['linear-algebra', 'matrices', 'statistics']"
79,Beginner probability question: Bimodal distribution (ie like some Yelp reviews),Beginner probability question: Bimodal distribution (ie like some Yelp reviews),,"Background Let's say a Yelp reviewer either gives 1 stars or 5 stars because when her experience is average she doesn't feel as motivated to write a review. Sometimes she will give 2 or 4 stars, and extremely rarely will give 3 stars. Let's say $X =$ number of stars she will give Question 1 You work for Yelp and your boss asks you what kind of RV is $X$ and what is the associated probability mass function? What is the formula for $P(X=k)$ ? For example, if $X =$ average male height in feet, then $X$ is like a normal RV and we can use the pdf to find the $P(X>12)$ My attempt Maybe you say to the boss, $X$ is a Beta RV with parameters like $(\frac{1}{2},\frac{1}{2})$ although Beta is continuous In general I can't find an explicit pmf for the bimodal. When I go on the wikipedia for the Multimodal Distribution, it is the first distribution I've seen that doesn't have a pmf/pdf, cdf, mean, etc. It seems like the Bimodal should have its own thing like the Poisson or Gamma... Thanks for your help and putting up with my ignorance.","Background Let's say a Yelp reviewer either gives 1 stars or 5 stars because when her experience is average she doesn't feel as motivated to write a review. Sometimes she will give 2 or 4 stars, and extremely rarely will give 3 stars. Let's say $X =$ number of stars she will give Question 1 You work for Yelp and your boss asks you what kind of RV is $X$ and what is the associated probability mass function? What is the formula for $P(X=k)$ ? For example, if $X =$ average male height in feet, then $X$ is like a normal RV and we can use the pdf to find the $P(X>12)$ My attempt Maybe you say to the boss, $X$ is a Beta RV with parameters like $(\frac{1}{2},\frac{1}{2})$ although Beta is continuous In general I can't find an explicit pmf for the bimodal. When I go on the wikipedia for the Multimodal Distribution, it is the first distribution I've seen that doesn't have a pmf/pdf, cdf, mean, etc. It seems like the Bimodal should have its own thing like the Poisson or Gamma... Thanks for your help and putting up with my ignorance.",,"['probability', 'statistics']"
80,How to find the probabilities that maximize the standard deviation?,How to find the probabilities that maximize the standard deviation?,,"Consider the problem: ""one dice has three faces $1,2,3$ with probabilities $p_1,p_2,p_3$ and it is thrown many times with a mean value $a$. What are the values for $p_1,p_2,p_3$ which maximizes the uncertainty consistent with the mean value $a$?"" Here I believe uncertainty should be understood as standard deviation. So, the experiment for a single such dice being thrown has outcomes described by the random variable $X$ taking values on $\{1,2,3\}$ with probabilites $p_1,p_2,p_3$ respectively. I believe that it all boils down to maximizing $$\sigma^2(p_1,p_2,p_3)=E[X^2](p_1,p_2,p_3)-E[X]^2(p_1,p_2,p_3)$$ subject to the constraints $$g(p_1,p_2,p_3)=p_1+p_2+p_3=1\quad h(p_1,p_2,p_3)=E[X](p_1,p_2,p_3)=p_1+2p_2+3p_3=a.$$ Thus it seems we should use Lagrange multipliers and solve $$\nabla \sigma^2=\lambda \nabla g+\mu\nabla h,\\ g(p_1,p_2,p_3)=1, \\ h(p_1,p_2,p_3)=a.$$ Furthermore, it is clear that we have $$\dfrac{\partial}{\partial p_i}E[f(X)]=\dfrac{\partial}{\partial p_i}\sum_j f(x_j)p_j=f(x_i).$$ so that we have $$\nabla \sigma^2(p_1,p_2,p_3)=(1-2E[X],4-4E[X],9-6E[X]).$$ Thus we have the system of equations $$\begin{cases}1-2E[X]&=\lambda+\mu \\ 4-4E[X]&=\lambda+2\mu\\ 9-6E[X]&=\lambda+3\mu\\ p_1+2p_2+3p_3&= a \\ p_1+p_2+p_3&= 1.\end{cases}$$ The fourth equation imposes $E[X]=a$. Hence substituting it on the first and second we can find $\mu = 3-2a$ and $\lambda = -2$. But now this ought to be wrong. If I substitute this on the third equation I get $$9-6E[X]=-2+9-6a\Longleftrightarrow 6E[X]=6a+2$$ which is incompatible with the fourth equation which tells that $E[X]=a$. So this method doesn't work. What am I doing wrong here? What is the right way to solve this problem?","Consider the problem: ""one dice has three faces $1,2,3$ with probabilities $p_1,p_2,p_3$ and it is thrown many times with a mean value $a$. What are the values for $p_1,p_2,p_3$ which maximizes the uncertainty consistent with the mean value $a$?"" Here I believe uncertainty should be understood as standard deviation. So, the experiment for a single such dice being thrown has outcomes described by the random variable $X$ taking values on $\{1,2,3\}$ with probabilites $p_1,p_2,p_3$ respectively. I believe that it all boils down to maximizing $$\sigma^2(p_1,p_2,p_3)=E[X^2](p_1,p_2,p_3)-E[X]^2(p_1,p_2,p_3)$$ subject to the constraints $$g(p_1,p_2,p_3)=p_1+p_2+p_3=1\quad h(p_1,p_2,p_3)=E[X](p_1,p_2,p_3)=p_1+2p_2+3p_3=a.$$ Thus it seems we should use Lagrange multipliers and solve $$\nabla \sigma^2=\lambda \nabla g+\mu\nabla h,\\ g(p_1,p_2,p_3)=1, \\ h(p_1,p_2,p_3)=a.$$ Furthermore, it is clear that we have $$\dfrac{\partial}{\partial p_i}E[f(X)]=\dfrac{\partial}{\partial p_i}\sum_j f(x_j)p_j=f(x_i).$$ so that we have $$\nabla \sigma^2(p_1,p_2,p_3)=(1-2E[X],4-4E[X],9-6E[X]).$$ Thus we have the system of equations $$\begin{cases}1-2E[X]&=\lambda+\mu \\ 4-4E[X]&=\lambda+2\mu\\ 9-6E[X]&=\lambda+3\mu\\ p_1+2p_2+3p_3&= a \\ p_1+p_2+p_3&= 1.\end{cases}$$ The fourth equation imposes $E[X]=a$. Hence substituting it on the first and second we can find $\mu = 3-2a$ and $\lambda = -2$. But now this ought to be wrong. If I substitute this on the third equation I get $$9-6E[X]=-2+9-6a\Longleftrightarrow 6E[X]=6a+2$$ which is incompatible with the fourth equation which tells that $E[X]=a$. So this method doesn't work. What am I doing wrong here? What is the right way to solve this problem?",,"['probability', 'probability-theory', 'statistics', 'problem-solving']"
81,"""relative frequency distribution"" of function values","""relative frequency distribution"" of function values",,"Let $\ f(x):U\longrightarrow\mathbb{R}$ be a continuous real-valued function over a closed interval $U\subseteq\mathbb{R}$. I would like to define a ""relative frequency distribution"" function, $\ \mathcal{F}:\mathbb{R}\longrightarrow[0,1]$ which measures in some sense ""how often"" the function $f$ takes a value $y$. The idea is made more precise as follows. Let $\{J_k\}$ be a family of disjoint intervals that covers the reals: \begin{equation} \bigcup_{k\in\mathbb{Z}}J_k=\mathbb{R}\qquad J_i\ \cap J_j = \emptyset\quad\text{if}\quad i\neq j \end{equation} Let also $y_k\in J_k$ be a value in each interval. Define \begin{equation} F(y_k):=\frac{\lambda[f^\leftarrow(J_k)]}{\lambda[U]} \end{equation} where $\lambda$ is the standard (Lebesgue) measure. Finally, I'd like to ""define"", with a lot of handwaving, \begin{equation} \mathcal{F}(y) :=\lim_{\lambda[J_k]\rightarrow 0}F(y_k) \end{equation} Of course, this definition makes no sense because $y$ is not well defined (how to pick $y$ as the interval $J_k$ becomes smaller?) and also because it all collapses to zero...but I hope that the sense of it is clear. My question is: how could I formally define the function $\mathcal{F}$? The discrete version of the idea works because it's all about counting how many points lie in the preimage of each $y$, but I don't know how to extend it to the continuous case, or even if it's possible.","Let $\ f(x):U\longrightarrow\mathbb{R}$ be a continuous real-valued function over a closed interval $U\subseteq\mathbb{R}$. I would like to define a ""relative frequency distribution"" function, $\ \mathcal{F}:\mathbb{R}\longrightarrow[0,1]$ which measures in some sense ""how often"" the function $f$ takes a value $y$. The idea is made more precise as follows. Let $\{J_k\}$ be a family of disjoint intervals that covers the reals: \begin{equation} \bigcup_{k\in\mathbb{Z}}J_k=\mathbb{R}\qquad J_i\ \cap J_j = \emptyset\quad\text{if}\quad i\neq j \end{equation} Let also $y_k\in J_k$ be a value in each interval. Define \begin{equation} F(y_k):=\frac{\lambda[f^\leftarrow(J_k)]}{\lambda[U]} \end{equation} where $\lambda$ is the standard (Lebesgue) measure. Finally, I'd like to ""define"", with a lot of handwaving, \begin{equation} \mathcal{F}(y) :=\lim_{\lambda[J_k]\rightarrow 0}F(y_k) \end{equation} Of course, this definition makes no sense because $y$ is not well defined (how to pick $y$ as the interval $J_k$ becomes smaller?) and also because it all collapses to zero...but I hope that the sense of it is clear. My question is: how could I formally define the function $\mathcal{F}$? The discrete version of the idea works because it's all about counting how many points lie in the preimage of each $y$, but I don't know how to extend it to the continuous case, or even if it's possible.",,"['statistics', 'measure-theory', 'functions']"
82,Why Cost Function for Linear Regression Is Always a Convex Shaped Function?,Why Cost Function for Linear Regression Is Always a Convex Shaped Function?,,"This diagram is from Andrew Ng course for ML/DL: But isn't the cost function (least squares function) shape depends on scatter of the data ? For example below, the minimum will be at (0,1): that doesn't correspond to convex shape (if you will imagine it in 3d plot), that Andrew Ng showed above. UPDATE Oh, i think I understand... my example is a convex shape too, but simply shifted by coordinates, relatively to the Andrew's example. Am i right?","This diagram is from Andrew Ng course for ML/DL: But isn't the cost function (least squares function) shape depends on scatter of the data ? For example below, the minimum will be at (0,1): that doesn't correspond to convex shape (if you will imagine it in 3d plot), that Andrew Ng showed above. UPDATE Oh, i think I understand... my example is a convex shape too, but simply shifted by coordinates, relatively to the Andrew's example. Am i right?",,"['statistics', 'statistical-inference', 'machine-learning', 'least-squares', 'linear-regression']"
83,Deriving the marginal of x from a uniform on the unit circle,Deriving the marginal of x from a uniform on the unit circle,,"So this is a rather theoretical question as I kinda don't understand how to approach this from the perspective I want or how that approach is flawed (which I suspect might be the case). Let's consider the uniform distribution of the points $(x,y)$ on the unit circle. Note that it is degenerate as it has zero measure in the 2D space. We are interested in finding out what is the marginal of $x$ under this distribution. By changing to polar coordinates one can easily see that this corresponds to a uniform over the angle $\theta$. Since $x=\cos(\theta)$ by the change of variable formula we have that $$ p(x) = \frac{1}{2 \pi} \left|\frac{d x}{d \theta}\right|^{-1} = \frac{1}{2 \pi} \frac{1}{\sqrt{1 - x^2}}$$ This, of course, is wrong (a bit) since we have to take into account the fact that the cosine is not bijective so we have to split it to its to branches (where it is the same) and add them so the first factor actually is $\pi^{-1}$ and you can convince yourself this is the correct choice by the fact that $$\int_{-1}^{1} \sqrt{1-x^2} dx = \pi$$ Ok, however now I want to somehow derive that without using polar coordinates. Here is my approach and please anyone corrects me on this or help me finish it. Using the definition of the unit circle we have that the joint distribution is $$p(x,y) = \frac{1}{2 \pi} \delta (x^2 + y^2 - 1)$$ where $\delta$ is a dirac measure. Now trying to integrate that over $y$ gives me issues. Speicifically, since outside the dirac measure the function is constant it would seem that $p(x) = \frac{1}{2 \pi}$ which we know is wrong. So why is this wrong and how is the correct way to derive the result (I think I missing some knowledge of how to correctly do this integral).","So this is a rather theoretical question as I kinda don't understand how to approach this from the perspective I want or how that approach is flawed (which I suspect might be the case). Let's consider the uniform distribution of the points $(x,y)$ on the unit circle. Note that it is degenerate as it has zero measure in the 2D space. We are interested in finding out what is the marginal of $x$ under this distribution. By changing to polar coordinates one can easily see that this corresponds to a uniform over the angle $\theta$. Since $x=\cos(\theta)$ by the change of variable formula we have that $$ p(x) = \frac{1}{2 \pi} \left|\frac{d x}{d \theta}\right|^{-1} = \frac{1}{2 \pi} \frac{1}{\sqrt{1 - x^2}}$$ This, of course, is wrong (a bit) since we have to take into account the fact that the cosine is not bijective so we have to split it to its to branches (where it is the same) and add them so the first factor actually is $\pi^{-1}$ and you can convince yourself this is the correct choice by the fact that $$\int_{-1}^{1} \sqrt{1-x^2} dx = \pi$$ Ok, however now I want to somehow derive that without using polar coordinates. Here is my approach and please anyone corrects me on this or help me finish it. Using the definition of the unit circle we have that the joint distribution is $$p(x,y) = \frac{1}{2 \pi} \delta (x^2 + y^2 - 1)$$ where $\delta$ is a dirac measure. Now trying to integrate that over $y$ gives me issues. Speicifically, since outside the dirac measure the function is constant it would seem that $p(x) = \frac{1}{2 \pi}$ which we know is wrong. So why is this wrong and how is the correct way to derive the result (I think I missing some knowledge of how to correctly do this integral).",,"['calculus', 'statistics', 'dirac-delta', 'density-function']"
84,Generating samples within a sphere according to a specified distribution,Generating samples within a sphere according to a specified distribution,,"Let's consider a ball in $\mathbb{R}^n$ centered at some point $x$ with radius $r$. I am interested in generating samples (random points) within this ball. It is well known that, according to sources such as link , using Gaussian random variables and normalizing them produces random points that are uniformly distributed within a sphere. Now let's say I want to generate random points within this ball according to a specified distribution. Are there general procedures for doing this? Or, are there other known specific approaches that produce specific distributions within the ball?","Let's consider a ball in $\mathbb{R}^n$ centered at some point $x$ with radius $r$. I am interested in generating samples (random points) within this ball. It is well known that, according to sources such as link , using Gaussian random variables and normalizing them produces random points that are uniformly distributed within a sphere. Now let's say I want to generate random points within this ball according to a specified distribution. Are there general procedures for doing this? Or, are there other known specific approaches that produce specific distributions within the ball?",,"['geometry', 'statistics', 'probability-distributions', 'reference-request', 'random-variables']"
85,Sufficiency and Completeness of Gamma Random Variable for Normal Distribution,Sufficiency and Completeness of Gamma Random Variable for Normal Distribution,,"Let $X\sim N(0,\theta)$ for $\theta>0$.  Show that $X^2$ is complete and sufficient for $\theta$.  I assume this is referring to $\theta$ as the variance of $X$. I'm unsure of how to show sufficiency in this context.  I assumed that I would take the likelihood function of $X$ and divide it by the PDF of $X^2$ (where $X^2\sim GAM(\frac{1}{2},2\theta)$), but when I take that ratio $\theta$ is still leftover in the expression, suggesting that $X^2$ is NOT sufficient; but since that's what I'm supposed to show, clearly I'm doing something wrong.  So I'm not sure how I'm supposed to show sufficiency.  I'm sure it's simple, but I'm just not seeing it.","Let $X\sim N(0,\theta)$ for $\theta>0$.  Show that $X^2$ is complete and sufficient for $\theta$.  I assume this is referring to $\theta$ as the variance of $X$. I'm unsure of how to show sufficiency in this context.  I assumed that I would take the likelihood function of $X$ and divide it by the PDF of $X^2$ (where $X^2\sim GAM(\frac{1}{2},2\theta)$), but when I take that ratio $\theta$ is still leftover in the expression, suggesting that $X^2$ is NOT sufficient; but since that's what I'm supposed to show, clearly I'm doing something wrong.  So I'm not sure how I'm supposed to show sufficiency.  I'm sure it's simple, but I'm just not seeing it.",,"['probability', 'statistics', 'probability-distributions', 'random-variables', 'sufficient-statistics']"
86,Linear model $Y= X\beta +\epsilon$. Show that the two subcomponents $\hat{\beta_1}$ and $\hat{\beta_2}$ of the BLUE $\hat{\beta}$ are independent.,Linear model . Show that the two subcomponents  and  of the BLUE  are independent.,Y= X\beta +\epsilon \hat{\beta_1} \hat{\beta_2} \hat{\beta},"Suppose a linear model $Y= X\beta +\epsilon$ where $\epsilon \sim N(0,\sigma ^2I)$. Write $X=[X_1;X_2]$ where $X_1$ are the first $p_1$ columns of $X$ nad $X_2$ are the last $p_2$ columns. Similary split $\beta ^T =(\beta_1^T; \beta_2^T)$. If $X_1'X_2 =0$ show that the two subcomponents $\hat{\beta_1}$ and $\hat{\beta_2}$ of the BLUE $\hat{\beta}$ are independent. I know that $\hat{\beta_1}$ and $\hat{\beta_2}$ are normal because of $\epsilon$. I do not know how to start.","Suppose a linear model $Y= X\beta +\epsilon$ where $\epsilon \sim N(0,\sigma ^2I)$. Write $X=[X_1;X_2]$ where $X_1$ are the first $p_1$ columns of $X$ nad $X_2$ are the last $p_2$ columns. Similary split $\beta ^T =(\beta_1^T; \beta_2^T)$. If $X_1'X_2 =0$ show that the two subcomponents $\hat{\beta_1}$ and $\hat{\beta_2}$ of the BLUE $\hat{\beta}$ are independent. I know that $\hat{\beta_1}$ and $\hat{\beta_2}$ are normal because of $\epsilon$. I do not know how to start.",,"['linear-algebra', 'statistics', 'independence']"
87,Calculate distribution of mean and variance given Gaussian data points,Calculate distribution of mean and variance given Gaussian data points,,"I was reading some basic texts on machine learning where you build a Gaussian model of a generative process from a vector of available data points.  To give the contexts and the notations, assume $x_1, x_2, x_n\in\mathbb{R}$ are independent available data points from a Gaussian distribution. You have to estimate $\mu$ (the mean) and $\sigma>0$ (the standard deviation) from these known data points. Using some maximum likelihood estimator, we can say the problem is basically $$\max_{\mu, \sigma}\prod_{i=1}^nf_G(x_i)$$ where $f_G(x_i)$ is the Gaussian PDF with the mean and SD. The solution is easy, just the mean and SD of the data points give the optimum. But I am interested in a more general question where I calculate the joint probability density of $\mu$ and $\sigma$ given the data points? Is there any way to calculate $$f(\mu, \sigma \mid x_1, x_2, \cdots, x_n)=\frac{F(\mu, \sigma,x_1, x_2, \cdots, x_n)}{f(x_1, x_2, \cdots, x_n)}$$ Of course, we throughout assume that the underlying generative process is Gaussian, but I am stuck with the PDFs. Do I need any additional assumption to answer this question?","I was reading some basic texts on machine learning where you build a Gaussian model of a generative process from a vector of available data points.  To give the contexts and the notations, assume $x_1, x_2, x_n\in\mathbb{R}$ are independent available data points from a Gaussian distribution. You have to estimate $\mu$ (the mean) and $\sigma>0$ (the standard deviation) from these known data points. Using some maximum likelihood estimator, we can say the problem is basically $$\max_{\mu, \sigma}\prod_{i=1}^nf_G(x_i)$$ where $f_G(x_i)$ is the Gaussian PDF with the mean and SD. The solution is easy, just the mean and SD of the data points give the optimum. But I am interested in a more general question where I calculate the joint probability density of $\mu$ and $\sigma$ given the data points? Is there any way to calculate $$f(\mu, \sigma \mid x_1, x_2, \cdots, x_n)=\frac{F(\mu, \sigma,x_1, x_2, \cdots, x_n)}{f(x_1, x_2, \cdots, x_n)}$$ Of course, we throughout assume that the underlying generative process is Gaussian, but I am stuck with the PDFs. Do I need any additional assumption to answer this question?",,"['statistics', 'probability-distributions', 'normal-distribution', 'maximum-likelihood']"
88,Geometric Distribution: Tossing a Coin Question,Geometric Distribution: Tossing a Coin Question,,"Suppose that $A$ tosses a coin which lands heads with probability $p_A$ and $B$ tosses a coin which lands heads with probability $p_B$ . They toss their coins simultaneously over and over again, in a competition to see who gets the first head. The one to get the first head is the winner, except that a draw results if they get their first heads together. Calculate P(A wins). Let $X_A$ be the # of tosses that it takes $A$ to get the first head, $X_A \ge 1$ . Let $X_B$ be the # of tosses that it takes $B$ to get the first head, $X_B \ge 1$ . $P(A $ wins $)$ $= P(X_A \lt X_B)$ $=\sum_{i=1}^{\infty}P(X_A<X_B|X_A=i)P(X_A=i)$ $=\sum_{i=1}^{\infty}(1-p_B)^i(1-p_A)^{i-1}p_A$ $=\frac{p_A}{1-p_A}\sum_{i=1}^{\infty}(1-p_B)^i(1-p_A)^i$ $=\frac{p_A}{1-p_A}\sum_{i=1}^{\infty}((1-p_B)(1-p_A))^i$ $=\frac{p_A}{1-p_A}\left(\sum_{i=0}^{\infty}((1-p_B)(1-p_A))^i - ((1-p_B)(1-p_A))^0\right)$ $=\frac{p_A}{1-p_A}\left(\frac{1}{1-(1-p_A)(1-p_B)}-1\right)$ Textbook Answer: $\frac{(1-p_A)p_B}{1−(1−p_A )(1−p_B )}$ They're not the same, I tested with $p_A = 0.2$ , $p_B=0.5$","Suppose that tosses a coin which lands heads with probability and tosses a coin which lands heads with probability . They toss their coins simultaneously over and over again, in a competition to see who gets the first head. The one to get the first head is the winner, except that a draw results if they get their first heads together. Calculate P(A wins). Let be the # of tosses that it takes to get the first head, . Let be the # of tosses that it takes to get the first head, . wins Textbook Answer: They're not the same, I tested with ,",A p_A B p_B X_A A X_A \ge 1 X_B B X_B \ge 1 P(A  ) = P(X_A \lt X_B) =\sum_{i=1}^{\infty}P(X_A<X_B|X_A=i)P(X_A=i) =\sum_{i=1}^{\infty}(1-p_B)^i(1-p_A)^{i-1}p_A =\frac{p_A}{1-p_A}\sum_{i=1}^{\infty}(1-p_B)^i(1-p_A)^i =\frac{p_A}{1-p_A}\sum_{i=1}^{\infty}((1-p_B)(1-p_A))^i =\frac{p_A}{1-p_A}\left(\sum_{i=0}^{\infty}((1-p_B)(1-p_A))^i - ((1-p_B)(1-p_A))^0\right) =\frac{p_A}{1-p_A}\left(\frac{1}{1-(1-p_A)(1-p_B)}-1\right) \frac{(1-p_A)p_B}{1−(1−p_A )(1−p_B )} p_A = 0.2 p_B=0.5,['statistics']
89,Calculating the sample mean and sample standard deviation from confidence interval,Calculating the sample mean and sample standard deviation from confidence interval,,"How to find the sample mean and sample standard deviation if only given the $n$ sample size and that the sample $95%$ confidence interval is $(x, y)$?  If I was given one of them I would know how to find the other one, but what should I do if both of them are unknown?","How to find the sample mean and sample standard deviation if only given the $n$ sample size and that the sample $95%$ confidence interval is $(x, y)$?  If I was given one of them I would know how to find the other one, but what should I do if both of them are unknown?",,"['statistics', 'confidence-interval']"
90,Negative values in PCA,Negative values in PCA,,"I have been trying to understand the meaning of negative values in PCA and what actions/considerations to take when faced with them. The following figure is the scores plot originating from about 6000 variables in four different groups. As it can be seen group 1 clusters nicely in quadrant 2 while the rest are much more scattered. For example, group 3 is both positive and negative along PC2, and one of the samples in the same is almost completly the opposite in quadrant 3. My questions: Should this sample be removed? Could this have arisen as possible mislabeling of original groupings?","I have been trying to understand the meaning of negative values in PCA and what actions/considerations to take when faced with them. The following figure is the scores plot originating from about 6000 variables in four different groups. As it can be seen group 1 clusters nicely in quadrant 2 while the rest are much more scattered. For example, group 3 is both positive and negative along PC2, and one of the samples in the same is almost completly the opposite in quadrant 3. My questions: Should this sample be removed? Could this have arisen as possible mislabeling of original groupings?",,"['linear-algebra', 'statistics']"
91,Expected Value of Drawing Tickets,Expected Value of Drawing Tickets,,"A collection of tickets comes in 4 colors: Red , Blue , White , and Green . There are twice as many reds as blues, equal number of blues   and whites, and three times as many greens as whites. Choose 5 tickets   at random with replacement . Let $X$ be the number of different colors   that appear. Find E(X). $E(X) = \sum_{all \,x}xP(X=x)$ where $X \in \{1, 2, 3, 4\}$ $= 1P(X=1) + 2P(X=2)+3P(X=3)+4P(X=4)$ Each $P(X=x)$ calculation is fairly complicated as I need to account every combination such as for $P(X=4) = \frac{5!}{1!1!1!2!}(2(\frac{1}{7})^3(\frac{2}{7})(\frac{3}{7}) + (\frac{1}{7})^2(\frac{2}{7})^2(\frac{3}{7}) + (\frac{1}{7})^2(\frac{2}{7})(\frac{3}{7})^2)$ However, the answer for E(X) is just $2(1-(\frac{6}{7})^5)+1-(\frac{5}{7})^5+1-(\frac{4}{7})^5$ How did they come up with that? Is it just a simplified version of what I'm doing?","A collection of tickets comes in 4 colors: Red , Blue , White , and Green . There are twice as many reds as blues, equal number of blues   and whites, and three times as many greens as whites. Choose 5 tickets   at random with replacement . Let $X$ be the number of different colors   that appear. Find E(X). $E(X) = \sum_{all \,x}xP(X=x)$ where $X \in \{1, 2, 3, 4\}$ $= 1P(X=1) + 2P(X=2)+3P(X=3)+4P(X=4)$ Each $P(X=x)$ calculation is fairly complicated as I need to account every combination such as for $P(X=4) = \frac{5!}{1!1!1!2!}(2(\frac{1}{7})^3(\frac{2}{7})(\frac{3}{7}) + (\frac{1}{7})^2(\frac{2}{7})^2(\frac{3}{7}) + (\frac{1}{7})^2(\frac{2}{7})(\frac{3}{7})^2)$ However, the answer for E(X) is just $2(1-(\frac{6}{7})^5)+1-(\frac{5}{7})^5+1-(\frac{4}{7})^5$ How did they come up with that? Is it just a simplified version of what I'm doing?",,"['probability', 'statistics']"
92,Poisson sand timer,Poisson sand timer,,"Imagine a sand clock that drops grains of sand from an upper bulb to the lower one at random intervals. The probability that $k$ grains of sand are dropped in $t$ seconds is $$\frac{(\lambda t)^k}{k!}e^{-\lambda t}$$ Assume $\lambda$ is known. How can I estimate the elapsed time when I see $n$ more grains of sand in the lower bulb? I guess the problem is very common. What is the canonical approach? Should I compute the a confidence interval for $t$? How? Or, what else?","Imagine a sand clock that drops grains of sand from an upper bulb to the lower one at random intervals. The probability that $k$ grains of sand are dropped in $t$ seconds is $$\frac{(\lambda t)^k}{k!}e^{-\lambda t}$$ Assume $\lambda$ is known. How can I estimate the elapsed time when I see $n$ more grains of sand in the lower bulb? I guess the problem is very common. What is the canonical approach? Should I compute the a confidence interval for $t$? How? Or, what else?",,"['statistics', 'probability-distributions', 'statistical-inference']"
93,You are taking a multiple-choice test with n questions each of which has 4 alternatives. You have mastered 60% of the material,You are taking a multiple-choice test with n questions each of which has 4 alternatives. You have mastered 60% of the material,,"You are taking a multiple-choice test with n questions each of which has 4 alternatives. You have mastered 60% of the material. Assume this means that you have a 0.6 chance of knowing the answer to a random test question, and that if you don’t know the answer to a question then you randomly select among the four answer choices. Assume that this holds for each question, independent of the others, and assume that each correct answer gives 1 point and wrong answers give 0 points, the score is the sum of all points.  For each answer define a random variable Xi (i=1,2,...,n) that takes the value 1 if the  ith answer is correct and 0 otherwise.  a.What is the probability that you answer a particular question correctly?  b.What is your expected score on the exam?  c.Write down a formula for the probability mass function (pmf) for one particular X, obtain the cumulative distribution function (CDF) for Xi and plot the CDF  WORK: for my work so far I have A = Knowing the answer B = All choices are equal and C = Student answers correctly. P(A) = .6, P(B) = .25 I am looking for P(A|C)? = P(C|A)P(A)/P(C)? Other than that I am kind of lost","You are taking a multiple-choice test with n questions each of which has 4 alternatives. You have mastered 60% of the material. Assume this means that you have a 0.6 chance of knowing the answer to a random test question, and that if you don’t know the answer to a question then you randomly select among the four answer choices. Assume that this holds for each question, independent of the others, and assume that each correct answer gives 1 point and wrong answers give 0 points, the score is the sum of all points.  For each answer define a random variable Xi (i=1,2,...,n) that takes the value 1 if the  ith answer is correct and 0 otherwise.  a.What is the probability that you answer a particular question correctly?  b.What is your expected score on the exam?  c.Write down a formula for the probability mass function (pmf) for one particular X, obtain the cumulative distribution function (CDF) for Xi and plot the CDF  WORK: for my work so far I have A = Knowing the answer B = All choices are equal and C = Student answers correctly. P(A) = .6, P(B) = .25 I am looking for P(A|C)? = P(C|A)P(A)/P(C)? Other than that I am kind of lost",,"['probability', 'statistics']"
94,Can I assume that $0^0 = 0$ when dealing with the center of order $0$ in statistics?,Can I assume that  when dealing with the center of order  in statistics?,0^0 = 0 0,"I came up to the concept of centers in statistics. Honestly, I never heard about this before few days ago. Given a collection of numbers $\{x_i\}$, $i \in \{1, \ldots, N\}$, the   center of order $r$ is defined as the number $c$ which minimizes the   following function: $$f_r(c) = \sum_{i=1}^N \left|x_i - c\right|^r.$$ In particular, it comes out that: The center of order $0$ is the mode of the collection $\{x_i\}$. The center of order $1$ is the median of the collection $\{x_i\}$. The center of order $2$ is the mean of the collection $\{x_i\}$. For fun, I was able to prove point 3 (very easy) since $f$ is smooth. Point 2 is somehow hard, but I think I can solve it. Instead, for point 1, I'm having some troubles. Consider the function $f_0(c)$. If $c \neq x_i$, then $x_i - c \neq 0$ and then $$\left|x_i - c\right|^0 = 1.$$ Therefore, if I choose $c$ such that $c \neq x_i ~\forall i$, then I get that: $$f_0(c) = N.$$ Now, $\color{red}{\text{I assume in this context that}~ 0^0 = 0}$. That is, if $c = x_j$ for some $j$, I get: $$\left|x_i - c\right|^0 = 0.$$ If the value of $x_j$ is repeated exactly $m$ times, then I get: $$f_0(x_j) = N - m.$$ Therefore if $x_j$ correspond to the mode of the collection, then $m$ is maximum, and hence $f_0(x_j)$ attains its minimum. Is this ""proof"" correct? A numerical ""evidence"" I consider the collection $\{1, 2, 2, 2, 3, 4, 5, 6\}$. In this case, the mean is $3.125$, the median is $2.5$ (between $2$ and $3$) and the mode is $2$. Hereafter, I plot the function $f_r(c)$ for $r=2$ (mean) and $r=1$ (median). Also I plot the function for $r=0.1$, $r=0.01$, $r=0.001$ and $r=0.0001$.","I came up to the concept of centers in statistics. Honestly, I never heard about this before few days ago. Given a collection of numbers $\{x_i\}$, $i \in \{1, \ldots, N\}$, the   center of order $r$ is defined as the number $c$ which minimizes the   following function: $$f_r(c) = \sum_{i=1}^N \left|x_i - c\right|^r.$$ In particular, it comes out that: The center of order $0$ is the mode of the collection $\{x_i\}$. The center of order $1$ is the median of the collection $\{x_i\}$. The center of order $2$ is the mean of the collection $\{x_i\}$. For fun, I was able to prove point 3 (very easy) since $f$ is smooth. Point 2 is somehow hard, but I think I can solve it. Instead, for point 1, I'm having some troubles. Consider the function $f_0(c)$. If $c \neq x_i$, then $x_i - c \neq 0$ and then $$\left|x_i - c\right|^0 = 1.$$ Therefore, if I choose $c$ such that $c \neq x_i ~\forall i$, then I get that: $$f_0(c) = N.$$ Now, $\color{red}{\text{I assume in this context that}~ 0^0 = 0}$. That is, if $c = x_j$ for some $j$, I get: $$\left|x_i - c\right|^0 = 0.$$ If the value of $x_j$ is repeated exactly $m$ times, then I get: $$f_0(x_j) = N - m.$$ Therefore if $x_j$ correspond to the mode of the collection, then $m$ is maximum, and hence $f_0(x_j)$ attains its minimum. Is this ""proof"" correct? A numerical ""evidence"" I consider the collection $\{1, 2, 2, 2, 3, 4, 5, 6\}$. In this case, the mean is $3.125$, the median is $2.5$ (between $2$ and $3$) and the mode is $2$. Hereafter, I plot the function $f_r(c)$ for $r=2$ (mean) and $r=1$ (median). Also I plot the function for $r=0.1$, $r=0.01$, $r=0.001$ and $r=0.0001$.",,"['analysis', 'limits', 'statistics']"
95,Tossing two dices with indications of $X$ and $Y$ respectively. Probability questions around $S=X+Y$.,Tossing two dices with indications of  and  respectively. Probability questions around .,X Y S=X+Y,"Exercise : We toss two dices. Let $X$ be the indication of the result of the first one and $Y$ the indication of the result of the second one. If $S=X+Y$ , find the following : (a) The probability mass function $p(s_j)$ of the random variable $S$ . (b) The mean value $E[S]$ of the random variable $S$ . (c) The variance $V[S]$ of the random variable $S$ . Attempt : (a) So, $S$ is the summation of the indications of the two dices, which means that the value of $S$ will rely in $[2,12]$ , which is obvious. How would one continue to finding the probability mass function though ? For (b) and (c), I do not know how to continue (I think you need (a) for those as well). This is not a homework question, as it is an exam question which I'm trying to figure out in order for the upcoming semester tests. I would really appreciate any help on understanding the problem and the questions asked.","Exercise : We toss two dices. Let be the indication of the result of the first one and the indication of the result of the second one. If , find the following : (a) The probability mass function of the random variable . (b) The mean value of the random variable . (c) The variance of the random variable . Attempt : (a) So, is the summation of the indications of the two dices, which means that the value of will rely in , which is obvious. How would one continue to finding the probability mass function though ? For (b) and (c), I do not know how to continue (I think you need (a) for those as well). This is not a homework question, as it is an exam question which I'm trying to figure out in order for the upcoming semester tests. I would really appreciate any help on understanding the problem and the questions asked.","X Y S=X+Y p(s_j) S E[S] S V[S] S S S [2,12]","['probability', 'combinatorics', 'probability-theory', 'statistics', 'dice']"
96,Maximum likelihood estimate of gaussian given rounded values,Maximum likelihood estimate of gaussian given rounded values,,"Suppose there is a hidden gaussian with mean $\mu$ and variance $\sigma^2$, and that $X_i \sim \mathcal{N}(\mu,\sigma^2)$ where the $X_i$ are i.i.d.  If I can only oberve the rounded value of $X_i$, i.e. $Y_i = \lfloor X_i + 1/2 \rfloor$, is there an effective means of computing the maximum likelihood estimates of $\mu$ and $\sigma$?","Suppose there is a hidden gaussian with mean $\mu$ and variance $\sigma^2$, and that $X_i \sim \mathcal{N}(\mu,\sigma^2)$ where the $X_i$ are i.i.d.  If I can only oberve the rounded value of $X_i$, i.e. $Y_i = \lfloor X_i + 1/2 \rfloor$, is there an effective means of computing the maximum likelihood estimates of $\mu$ and $\sigma$?",,"['statistics', 'maximum-likelihood', 'parameter-estimation']"
97,Average and standard deviation equation system,Average and standard deviation equation system,,Every exam has 100 points. Student's average of 3 exams is 88 points and standard deviation is 3. How many points should he get on fourth and fifth exam so that average is 90 and standard deviation stays same (=3). I tried solving equations $(x_1+x_2+x_3)/3=88$ and $(x_1+x_2+x_3+x_4+x_5)/5=90$. Since $x_1+x_2+x_3=264$ it means that $(264+x_4+x_5)/5=90$ so $x_4+x_5=186$. Then I tried to use equations for standard deviation but I haven't managed to get anything useful.,Every exam has 100 points. Student's average of 3 exams is 88 points and standard deviation is 3. How many points should he get on fourth and fifth exam so that average is 90 and standard deviation stays same (=3). I tried solving equations $(x_1+x_2+x_3)/3=88$ and $(x_1+x_2+x_3+x_4+x_5)/5=90$. Since $x_1+x_2+x_3=264$ it means that $(264+x_4+x_5)/5=90$ so $x_4+x_5=186$. Then I tried to use equations for standard deviation but I haven't managed to get anything useful.,,"['statistics', 'average', 'standard-deviation']"
98,Odds of two names appearing together in a print ad - help with a gift to boyfriend.,Odds of two names appearing together in a print ad - help with a gift to boyfriend.,,"A print ad (for Loving Embrace pendants) used my name, Jennifer and my boyfriend's name, Matthew in their sample pendant.  What are the odds that those two names would be choosen?  Howmanyofme.com shows that there are 1,521,455 Jennifer's in the US and 1,075,792 Matthews. It doesn't have to be perfect; I'm just going to send him the advertisement with a note and would like to let him know what the odds are that we'd be paired together.","A print ad (for Loving Embrace pendants) used my name, Jennifer and my boyfriend's name, Matthew in their sample pendant.  What are the odds that those two names would be choosen?  Howmanyofme.com shows that there are 1,521,455 Jennifer's in the US and 1,075,792 Matthews. It doesn't have to be perfect; I'm just going to send him the advertisement with a note and would like to let him know what the odds are that we'd be paired together.",,['statistics']
99,Conditional expectation: treating $X_1$ as constant?,Conditional expectation: treating  as constant?,X_1,"I have ben having this confusion for quite some time. Here is my question. For simplicity, suppose we have two r.v.'s $X_1$ and $X_2$ defined on $\left(\Omega,\mathcal{A},P\right)$ and they are independent. I am interested in, say, finding an upper bound for $\mathbb{E}\left[\left|X_1 + X_2 \right|\right]$. In statistics/machine learning literature, often I see arguments go like this: We ""first treat $X_1$ as constant"", and $\mathbb{E}\left[ \left|x_1 + X_2\right| \right]$ is upper bounded by a constant/function depends on $x_1$, and then we treat $x_1$ as a random variable and ""take expectation wrt to $X_1$"". I have been self-studying measure theory based probability, and I have been trying to make this kind of argument rigorous but cannot achieve it. I am aware of Fubini Theorem, but we do not necessarily have product space/measure here. I am aware of conditional probability defined through Radon-Nikodym, but I don't see any connection. It seems that this kind of argument is using some sort of ""iterated integral"" but I can't formalize it.","I have ben having this confusion for quite some time. Here is my question. For simplicity, suppose we have two r.v.'s $X_1$ and $X_2$ defined on $\left(\Omega,\mathcal{A},P\right)$ and they are independent. I am interested in, say, finding an upper bound for $\mathbb{E}\left[\left|X_1 + X_2 \right|\right]$. In statistics/machine learning literature, often I see arguments go like this: We ""first treat $X_1$ as constant"", and $\mathbb{E}\left[ \left|x_1 + X_2\right| \right]$ is upper bounded by a constant/function depends on $x_1$, and then we treat $x_1$ as a random variable and ""take expectation wrt to $X_1$"". I have been self-studying measure theory based probability, and I have been trying to make this kind of argument rigorous but cannot achieve it. I am aware of Fubini Theorem, but we do not necessarily have product space/measure here. I am aware of conditional probability defined through Radon-Nikodym, but I don't see any connection. It seems that this kind of argument is using some sort of ""iterated integral"" but I can't formalize it.",,"['real-analysis', 'probability', 'probability-theory', 'statistics', 'measure-theory']"
