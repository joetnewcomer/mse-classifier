,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Why doesn't the gamma distribution have the memoryless property?,Why doesn't the gamma distribution have the memoryless property?,,"The gamma distribution essentially tells us the probability of $k$ events happening in a given amount of time, $t$ . It seems to me that there are certain examples of the gamma distribution where it behaves memoryless. For example, the probability of 2 customers entering a store in 3 hours GIVEN that no customer has entered in the first hour is equivalent to the probability of 2 customers entering a store in 2 hours. Is my example properly demonstrating ""memoryless-ness""? What would be an example of it having memory using my store scenario?","The gamma distribution essentially tells us the probability of events happening in a given amount of time, . It seems to me that there are certain examples of the gamma distribution where it behaves memoryless. For example, the probability of 2 customers entering a store in 3 hours GIVEN that no customer has entered in the first hour is equivalent to the probability of 2 customers entering a store in 2 hours. Is my example properly demonstrating ""memoryless-ness""? What would be an example of it having memory using my store scenario?",k t,"['statistics', 'probability-distributions', 'gamma-distribution']"
1,Total average of averages not same as the average of total values,Total average of averages not same as the average of total values,,"I am having a strange problem while computing the overall percentage. Let me demonstrate my problem using an example. Assume that I am receiving multiple batches of apple from the vendor and the number of good apple received in each batch are computed to display as percentage as below: If I find the average of the last column (Good Apple Percentage), I get $\frac{(98.5+98+99)}{3} = 98.5 $ % However, if I find the total no of apples and total number of bad apples first (column 2 and 3), Total No of Apples $= 200+100+300 = 600$ Total No of Bad Apples $= 3+2+3= 8$ Then compute the total percentage, $\frac{600-8}{600}= 98.67$ % Why is the total average of the average not the same as the average of total values? There is no rounding up or rounding down necessary for individual percentages (Column 4), so shouldn't the two percentage be the same? What am I missing?","I am having a strange problem while computing the overall percentage. Let me demonstrate my problem using an example. Assume that I am receiving multiple batches of apple from the vendor and the number of good apple received in each batch are computed to display as percentage as below: If I find the average of the last column (Good Apple Percentage), I get % However, if I find the total no of apples and total number of bad apples first (column 2 and 3), Total No of Apples Total No of Bad Apples Then compute the total percentage, % Why is the total average of the average not the same as the average of total values? There is no rounding up or rounding down necessary for individual percentages (Column 4), so shouldn't the two percentage be the same? What am I missing?",\frac{(98.5+98+99)}{3} = 98.5  = 200+100+300 = 600 = 3+2+3= 8 \frac{600-8}{600}= 98.67,"['statistics', 'average', 'means', 'rounding-error']"
2,Fair coin toss and Bayes,Fair coin toss and Bayes,,"You have a coin and your prior assumption is that its probability of heads $\theta$ is chosen from a uniform distribution on $[0, 1]$ . You toss the coin 10 times and get 6 heads. What is the estimate of $\theta$ ? I figured that it has to be $\frac{6}{10}$ but is there a theorem or rule that can upend my guess?",You have a coin and your prior assumption is that its probability of heads is chosen from a uniform distribution on . You toss the coin 10 times and get 6 heads. What is the estimate of ? I figured that it has to be but is there a theorem or rule that can upend my guess?,"\theta [0, 1] \theta \frac{6}{10}","['statistics', 'statistical-inference', 'bayesian', 'parameter-estimation']"
3,Wording of a statistics question,Wording of a statistics question,,"Apologies if this is not the correct area to post this but, I have a question about the specific wording of an assignment. We have been given this sentence, basically The occurrence of false positives [in some experiment] is 40% What does this mean? Does it mean that 40% of positives are false? Or 40% of all tested patients are specifically both false and positive? Or say 40% of those that are false are positive? I'm quite confused as to what this means, and none of the people I have asked understand either. Thanks","Apologies if this is not the correct area to post this but, I have a question about the specific wording of an assignment. We have been given this sentence, basically The occurrence of false positives [in some experiment] is 40% What does this mean? Does it mean that 40% of positives are false? Or 40% of all tested patients are specifically both false and positive? Or say 40% of those that are false are positive? I'm quite confused as to what this means, and none of the people I have asked understand either. Thanks",,['statistics']
4,Basic maths: Interview question getting proportion from averages,Basic maths: Interview question getting proportion from averages,,"It's probably simple but I was given this question in a video interview recently and I spent ages coming up with two different answers. (please let me know if this is the wrong place for this, I'm not entirely sure where is best suited for this type of question) Question as follows: A mobile app is on both iPhone and Android. Overall, there are 600,000   app users who log into the app an average of 11 times a month. The   average iPhone user logs in 7 times a month. The average Android user   logs in 13 times a month. What proportion of users access the app with   an iPhone? My two answers: Answer one $a$ : proportion of iphone users $$\frac{7}{20\cdot a} = 11$$ $$a=\frac{11 \cdot 20}{7}$$ $$=\frac{220}{7}$$ $$31.43% $$ Answer two Answer: $33.33\%$ Are either of these right or have I completely lost the plot?","It's probably simple but I was given this question in a video interview recently and I spent ages coming up with two different answers. (please let me know if this is the wrong place for this, I'm not entirely sure where is best suited for this type of question) Question as follows: A mobile app is on both iPhone and Android. Overall, there are 600,000   app users who log into the app an average of 11 times a month. The   average iPhone user logs in 7 times a month. The average Android user   logs in 13 times a month. What proportion of users access the app with   an iPhone? My two answers: Answer one : proportion of iphone users Answer two Answer: Are either of these right or have I completely lost the plot?",a \frac{7}{20\cdot a} = 11 a=\frac{11 \cdot 20}{7} =\frac{220}{7} 31.43%  33.33\%,"['statistics', 'recreational-mathematics', 'percentages']"
5,Difference between $\operatorname{Var}(Y)$ and $\operatorname{Var}(Y\mid X)$?,Difference between  and ?,\operatorname{Var}(Y) \operatorname{Var}(Y\mid X),"What is the difference between $\mathrm{var}(Y)$ and $\mathrm{var}(Y\mid X)$ ? If $Y = c + \beta X$ and $\operatorname{var}(X)=\sigma^2$ , won't both come out to be the same, i.e., $\beta^2\sigma^2$ ?","What is the difference between and ? If and , won't both come out to be the same, i.e., ?",\mathrm{var}(Y) \mathrm{var}(Y\mid X) Y = c + \beta X \operatorname{var}(X)=\sigma^2 \beta^2\sigma^2,"['statistics', 'variance']"
6,"Derive unbiased estimator for $\theta$ when $X_i\sim f(x\mid\theta)=\frac{2x}{\theta^2}\mathbb{1}_{(0,\theta)}(x)$",Derive unbiased estimator for  when,"\theta X_i\sim f(x\mid\theta)=\frac{2x}{\theta^2}\mathbb{1}_{(0,\theta)}(x)","Exercise: Let $X_1,\ldots,X_n$ be a random sample from the distribution with density $$f(x\mid\theta) = \dfrac{2x}{\theta^2}\mathbb{1}_{(0,\theta)}(x)$$ w.r.t. the Lebesgue measure. Derive an unbiased estimator for $\theta$ . What I've tried: I need to find an estimator $\delta(X_1,\ldots,X_n)$ such that $\operatorname{E}\big[\delta(X_1,\ldots,X_n)\big] = \theta$ . I tried the maximum likelihood estimator but that got me nowhere. The log-likelihood would be equal to $\log L = \log\prod\limits_{i = 1}^n\dfrac{2x_i}{\theta^2}\mathbb{1}_{(0,\theta)}(x_i) = \sum\limits_{i= 1}^n2x_i - 2n\log\theta$ (I'm not sure if I can leave the indicator function like this btw). If I now take the derivate w.r.t. $\theta$ and set it to zero I get that $\hat{\theta}_{ML} = 0$ , which is not an unbiased estimator. Question: How do I solve this exercise? In general; what would a efficient approach be to find an unbiased estimator in exercises like this one? Thanks in advance!","Exercise: Let be a random sample from the distribution with density w.r.t. the Lebesgue measure. Derive an unbiased estimator for . What I've tried: I need to find an estimator such that . I tried the maximum likelihood estimator but that got me nowhere. The log-likelihood would be equal to (I'm not sure if I can leave the indicator function like this btw). If I now take the derivate w.r.t. and set it to zero I get that , which is not an unbiased estimator. Question: How do I solve this exercise? In general; what would a efficient approach be to find an unbiased estimator in exercises like this one? Thanks in advance!","X_1,\ldots,X_n f(x\mid\theta) = \dfrac{2x}{\theta^2}\mathbb{1}_{(0,\theta)}(x) \theta \delta(X_1,\ldots,X_n) \operatorname{E}\big[\delta(X_1,\ldots,X_n)\big] = \theta \log L = \log\prod\limits_{i = 1}^n\dfrac{2x_i}{\theta^2}\mathbb{1}_{(0,\theta)}(x_i) = \sum\limits_{i= 1}^n2x_i - 2n\log\theta \theta \hat{\theta}_{ML} = 0","['statistics', 'probability-distributions', 'statistical-inference', 'parameter-estimation']"
7,Difference between statistics and stochastic? [closed],Difference between statistics and stochastic? [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question Can somebody explain me the difference between statistics and stochastic? I know that stochastic calculates probabilities but isn't statistics the same?","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question Can somebody explain me the difference between statistics and stochastic? I know that stochastic calculates probabilities but isn't statistics the same?",,"['statistics', 'stochastic-analysis']"
8,Why log likelihoods are additive and !log likelihoods are multiplicative,Why log likelihoods are additive and !log likelihoods are multiplicative,,Reading accepted answer for Why we consider log likelihood instead of Likelihood in Gaussian Distribution by user jokek states that total likelihood is product of likelihoods. If apply log to likelihoods then total likelihood is sum instead of product. Why applying log function to likelihoods change computing total likelihood from product to sum ? What is the intuition behind this ?,Reading accepted answer for Why we consider log likelihood instead of Likelihood in Gaussian Distribution by user jokek states that total likelihood is product of likelihoods. If apply log to likelihoods then total likelihood is sum instead of product. Why applying log function to likelihoods change computing total likelihood from product to sum ? What is the intuition behind this ?,,"['statistics', 'logarithms', 'machine-learning']"
9,"How to maximize Std Dev given a range of possible values, a number of values, and a specific mean?","How to maximize Std Dev given a range of possible values, a number of values, and a specific mean?",,"( I'm asking here and not stats.stackexchange because I'd like a mathematical proof of this ) In this question: Prove how to maximize Standard Deviation given a certain mean $\bar{x}$ and set of values ; as pointed out by @mathguy in his second paragraph, I assumed that the mean and values were not independent and that the mean was $\frac{a+b}{2}$ where $a$ and $b$ are the minimum and maximimum values of the range respectively. I'd like to understand how to maximize the SD of $n$ values in a range $[a,b]$ for an arbitrary mean $\bar{x}=y$. For example, how would you maximize the standard deviation for $5$ values in the range $[0,1]$ with a mean of $0.3$? Ideally I'd love to have a solution for this specific example (or another) and an understanding for the general solution. Should we use calc, and if so how? Can we use something else?","( I'm asking here and not stats.stackexchange because I'd like a mathematical proof of this ) In this question: Prove how to maximize Standard Deviation given a certain mean $\bar{x}$ and set of values ; as pointed out by @mathguy in his second paragraph, I assumed that the mean and values were not independent and that the mean was $\frac{a+b}{2}$ where $a$ and $b$ are the minimum and maximimum values of the range respectively. I'd like to understand how to maximize the SD of $n$ values in a range $[a,b]$ for an arbitrary mean $\bar{x}=y$. For example, how would you maximize the standard deviation for $5$ values in the range $[0,1]$ with a mean of $0.3$? Ideally I'd love to have a solution for this specific example (or another) and an understanding for the general solution. Should we use calc, and if so how? Can we use something else?",,"['statistics', 'optimization', 'standard-deviation']"
10,How can I evaluate $\int_{-\infty}^{\infty} e^{-x^2} dx$ without using polar coordinates [duplicate],How can I evaluate  without using polar coordinates [duplicate],\int_{-\infty}^{\infty} e^{-x^2} dx,"This question already has answers here : Evaluation of Gaussian integral $\int_{0}^{\infty} \mathrm{e}^{-x^2} dx$ (21 answers) Closed 8 years ago . I know from probability class that the area under the bell curve $e^{-x^2}$ is $\sqrt{\pi}$. I would like to be able to verify this, so in other words, solve this integral: $$\int_{-\infty}^{\infty} e^{-x^2} dx $$ The proof we saw in class used polar coordinates, but I don't like polar coordinates! Is there another way to evalutuate it? Thanks!","This question already has answers here : Evaluation of Gaussian integral $\int_{0}^{\infty} \mathrm{e}^{-x^2} dx$ (21 answers) Closed 8 years ago . I know from probability class that the area under the bell curve $e^{-x^2}$ is $\sqrt{\pi}$. I would like to be able to verify this, so in other words, solve this integral: $$\int_{-\infty}^{\infty} e^{-x^2} dx $$ The proof we saw in class used polar coordinates, but I don't like polar coordinates! Is there another way to evalutuate it? Thanks!",,"['calculus', 'integration', 'statistics', 'normal-distribution', 'gaussian-integral']"
11,Simplest way to integrate this expression : $\int_{-\infty}^{+\infty} e^{-x^2/2} dx$ [duplicate],Simplest way to integrate this expression :  [duplicate],\int_{-\infty}^{+\infty} e^{-x^2/2} dx,This question already has answers here : Evaluation of Gaussian integral $\int_{0}^{\infty} \mathrm{e}^{-x^2} dx$ (21 answers) Closed 8 years ago . I'm toying around with statistics and calculus for a project of mine and I'm trying to find the simplest/fastest way to integrate this formula : $$\int_{-\infty}^{+\infty} e^{-x^2/2} dx$$ I do not want to use a table. I'm taking this opportunity to get more practice with my new calculus skills It seems that a Taylor series approx is the only way to go Best Regards,This question already has answers here : Evaluation of Gaussian integral $\int_{0}^{\infty} \mathrm{e}^{-x^2} dx$ (21 answers) Closed 8 years ago . I'm toying around with statistics and calculus for a project of mine and I'm trying to find the simplest/fastest way to integrate this formula : $$\int_{-\infty}^{+\infty} e^{-x^2/2} dx$$ I do not want to use a table. I'm taking this opportunity to get more practice with my new calculus skills It seems that a Taylor series approx is the only way to go Best Regards,,"['calculus', 'integration', 'statistics', 'normal-distribution']"
12,"Standard deviation of mean of a set of numbers, which are imprecise","Standard deviation of mean of a set of numbers, which are imprecise",,"I have a problem which seems very simple, but for some reason I can not find out what I have to do exactly. Let's say I have a set of derived values, where each of them has an individual error:     $$X_{all}=(x_1 \pm \sigma_{x_1}, x_2 \pm \sigma_{x_2}, ..., x_n \pm \sigma_{x_n})$$ (where $\sigma_i$ stands for the standard deviation). Now I want to have the average value of $X_{all}$ and some confidence of that value. The average is of course: $X_{avg}=\frac{1}{N}\sum x_i$ But for the standard deviation of $X_{avg}$, I dont know what I should use. There are two possibilities that seem neccesary: 1) From error-propagation: $$\sigma_{X_{avg}} = \sqrt{\frac{1}{N} \sum_i \sigma_{x_i}^2}$$ 2) Normal standard-deviation when creating a mean value: $$\sigma_{X_{avg}} = \sqrt{\frac{1}{N} \sum_i (x_i-X_{avg})^2}$$ Concrete Example: I perform a measurement to get the value $X$. In order to get a statistical significant knowlegde about $X$ and its standard deviation, I perform the measurement n times, leading to the results $x_i$. However, I can not measure $x_i$ directly, but only $y_i=x_i+BG$, where BG is a background value. For each measurement of $y_i$, I automatically get the information about $BG$ 1000 times, which gives me $BG_{avg}$ and $\sigma_{BG}$ for each $y_i$ ($BG$ is gauss distributed). Now I have $x_i = y_i - BG_{avg}$, thus I get a $\sigma_{x_i}=\sigma_{BG}$. Other Concrete Example: I want to know the average of the lap-time of a racing car. I measure 100 laps. However, I know my clock has an uncertainty $\sigma_{clock}$. Moreover, for some reason I use for each lap a different clock with a different uncertainty $\sigma_{clock_i}$. So I get 100 times $t_i$ for the time in lap $i$, with an uncertainty of $\sigma_{clock_i}$, corresponding to the uncertainty I introduce due to the clock itself. What is my uncertainty of the average lap-time of the racing car?","I have a problem which seems very simple, but for some reason I can not find out what I have to do exactly. Let's say I have a set of derived values, where each of them has an individual error:     $$X_{all}=(x_1 \pm \sigma_{x_1}, x_2 \pm \sigma_{x_2}, ..., x_n \pm \sigma_{x_n})$$ (where $\sigma_i$ stands for the standard deviation). Now I want to have the average value of $X_{all}$ and some confidence of that value. The average is of course: $X_{avg}=\frac{1}{N}\sum x_i$ But for the standard deviation of $X_{avg}$, I dont know what I should use. There are two possibilities that seem neccesary: 1) From error-propagation: $$\sigma_{X_{avg}} = \sqrt{\frac{1}{N} \sum_i \sigma_{x_i}^2}$$ 2) Normal standard-deviation when creating a mean value: $$\sigma_{X_{avg}} = \sqrt{\frac{1}{N} \sum_i (x_i-X_{avg})^2}$$ Concrete Example: I perform a measurement to get the value $X$. In order to get a statistical significant knowlegde about $X$ and its standard deviation, I perform the measurement n times, leading to the results $x_i$. However, I can not measure $x_i$ directly, but only $y_i=x_i+BG$, where BG is a background value. For each measurement of $y_i$, I automatically get the information about $BG$ 1000 times, which gives me $BG_{avg}$ and $\sigma_{BG}$ for each $y_i$ ($BG$ is gauss distributed). Now I have $x_i = y_i - BG_{avg}$, thus I get a $\sigma_{x_i}=\sigma_{BG}$. Other Concrete Example: I want to know the average of the lap-time of a racing car. I measure 100 laps. However, I know my clock has an uncertainty $\sigma_{clock}$. Moreover, for some reason I use for each lap a different clock with a different uncertainty $\sigma_{clock_i}$. So I get 100 times $t_i$ for the time in lap $i$, with an uncertainty of $\sigma_{clock_i}$, corresponding to the uncertainty I introduce due to the clock itself. What is my uncertainty of the average lap-time of the racing car?",,"['statistics', 'stochastic-processes']"
13,"medians and medoids are to 2, as X and Y are to 3","medians and medoids are to 2, as X and Y are to 3",,"What is the word for the values derived from an ordered set such that the values divide (by virtue of their positions; not by their value) the set into 3 subsets that have an equal or nearly equal number of members?  What is the word when the values are drawn from the set? What is the generic word that applies regardless of the number of subsets? EDIT: The parenthetical ""by virtue of their positions"" is probably unnecessary because, as I said, the set is ordered and the subsets have a (nearly) equal number of members. EDIT: Four answers are sought: a word for a value in the case of 3 subsets, a word for a datapoint in the case of 3 subsets, a word for a value in the general case, a word for a datapoint in the general case.","What is the word for the values derived from an ordered set such that the values divide (by virtue of their positions; not by their value) the set into 3 subsets that have an equal or nearly equal number of members?  What is the word when the values are drawn from the set? What is the generic word that applies regardless of the number of subsets? EDIT: The parenthetical ""by virtue of their positions"" is probably unnecessary because, as I said, the set is ordered and the subsets have a (nearly) equal number of members. EDIT: Four answers are sought: a word for a value in the case of 3 subsets, a word for a datapoint in the case of 3 subsets, a word for a value in the general case, a word for a datapoint in the general case.",,"['statistics', 'terminology']"
14,How do percentiles work?,How do percentiles work?,,"If I have 5 students (A-E) that score 80%, 70%, 70%, 60% and 50% on a test what percentiles do they fall in? A - 20th percentile (80%) B - 40th percentile (70%) C - 40th percentile (70%) D - 80th percentile (60%) E - 100th percentile (50%) Is this correct? Let me expand the question as I wasn't clear earlier: If A is in the top 20th percentile, are B and C in the top 40th percentile or top 60th percentile?","If I have 5 students (A-E) that score 80%, 70%, 70%, 60% and 50% on a test what percentiles do they fall in? A - 20th percentile (80%) B - 40th percentile (70%) C - 40th percentile (70%) D - 80th percentile (60%) E - 100th percentile (50%) Is this correct? Let me expand the question as I wasn't clear earlier: If A is in the top 20th percentile, are B and C in the top 40th percentile or top 60th percentile?",,['statistics']
15,"Empirical Relationship between mean, median and mode.(Derivation)","Empirical Relationship between mean, median and mode.(Derivation)",,How did we get the Empirical Formula? This formula has been etched into us in school but I want to know how this formula came about and to know if it's applicable for all statistical distributions or can only be used with large enough data. $$(\text{mean})-(\text{mode})=3(\text{mean}-\text{median})$$,How did we get the Empirical Formula? This formula has been etched into us in school but I want to know how this formula came about and to know if it's applicable for all statistical distributions or can only be used with large enough data.,(\text{mean})-(\text{mode})=3(\text{mean}-\text{median}),['statistics']
16,Coupon collector's variation with unequal probabilities and uneven number of items required,Coupon collector's variation with unequal probabilities and uneven number of items required,,"I am not sure about this being a negative binomial distribution problem or a variation of Coupon collector's problem. Here's the problem, Suppose, you want to build a house and I told you that you need certain type and certain number of items to build it. Let's consider you need Bricks $- ~4$ , Cement $-~ 1$ , Metal $- ~1$ , Gravel $- \ 1$ , Wood $-\ 2$ Now, in order to get these items, you need to open a locker and every time you open it you get only one item. Also, know that the locker contains an item that you don't need at all - Feathers. The following are their probabilities (Let's use their initials for the sake of simplicity) B - 30% C - 5% F - 10% G - 10% M - 35% W - 10% The question here is what's the average number of times you will have to open the locker if you want to build a house? The way I thought about solving this is by first multiplying the no of items required for a type by its expected number which is $\frac{1}{probability}$ for that item (for ex. $3.33$ times for Bricks multiplied by the number we want which is $4$ ) and then adding together for all the type of materials we want. I am not so good at this type of problems so please guide me.","I am not sure about this being a negative binomial distribution problem or a variation of Coupon collector's problem. Here's the problem, Suppose, you want to build a house and I told you that you need certain type and certain number of items to build it. Let's consider you need Bricks , Cement , Metal , Gravel , Wood Now, in order to get these items, you need to open a locker and every time you open it you get only one item. Also, know that the locker contains an item that you don't need at all - Feathers. The following are their probabilities (Let's use their initials for the sake of simplicity) B - 30% C - 5% F - 10% G - 10% M - 35% W - 10% The question here is what's the average number of times you will have to open the locker if you want to build a house? The way I thought about solving this is by first multiplying the no of items required for a type by its expected number which is for that item (for ex. times for Bricks multiplied by the number we want which is ) and then adding together for all the type of materials we want. I am not so good at this type of problems so please guide me.",- ~4 -~ 1 - ~1 - \ 1 -\ 2 \frac{1}{probability} 3.33 4,"['probability', 'statistics', 'coupon-collector']"
17,Why can't Wolfram Alpha compute this integral?,Why can't Wolfram Alpha compute this integral?,,$$\int_0^\infty \int_0^\infty \lambda_1\lambda_2 \mid{x - y} \mid e^{-\lambda_1x - \lambda_2y} dy dx$$ $$= \int_0^{\infty} e^{-\lambda_1x}\bigg[ \int_0^x(x - y)e^{-\lambda_2y}dy + \int_x^\infty(y - x)e^{-\lambda_2y}dy\bigg] dx$$ It seems like a straight forward but tedious integral to compute. Is there a way I can input this so that Wolfram is less confused by $x$ and $y$ being treated as variables and constants in different situations? Also Is there a way to specify that $\lambda_1$ and $\lambda_2$ are positive constants? I replaced $\lambda_1$ and $\lambda_2$ with $\pi$ and $e$ and it gave me an answer.,It seems like a straight forward but tedious integral to compute. Is there a way I can input this so that Wolfram is less confused by and being treated as variables and constants in different situations? Also Is there a way to specify that and are positive constants? I replaced and with and and it gave me an answer.,\int_0^\infty \int_0^\infty \lambda_1\lambda_2 \mid{x - y} \mid e^{-\lambda_1x - \lambda_2y} dy dx = \int_0^{\infty} e^{-\lambda_1x}\bigg[ \int_0^x(x - y)e^{-\lambda_2y}dy + \int_x^\infty(y - x)e^{-\lambda_2y}dy\bigg] dx x y \lambda_1 \lambda_2 \lambda_1 \lambda_2 \pi e,"['integration', 'statistics', 'expected-value', 'wolfram-alpha']"
18,How many 5-letter words can we make if the letters are in order?,How many 5-letter words can we make if the letters are in order?,,"Using the $26$ English letters, the number of $5$ -letter words that can be made if the letters are distinct is determined as follows: $26P5=26\times25\times24\times23\times22=7893600$ different words. What if the letters in each word are in alphabetical order? For example, the word JLOQY is valid, but the word JUMPY is invalid since U can not be before M","Using the English letters, the number of -letter words that can be made if the letters are distinct is determined as follows: different words. What if the letters in each word are in alphabetical order? For example, the word JLOQY is valid, but the word JUMPY is invalid since U can not be before M",26 5 26P5=26\times25\times24\times23\times22=7893600,"['combinatorics', 'statistics', 'permutations', 'combinations']"
19,Expectation of sample standard deviation,Expectation of sample standard deviation,,"Suppose we draw a random sample $X_1,X_2,\ldots,X_n$ from $N(\mu,\sigma^2)$ population. Let $S^2$ be the sample variance given by $\frac{1}{n-1}\sum_{i=1}^{n}(X_i-\bar{X})^2$ Now, we are to find $E(S)$. It is simple enough if we find the pdf of $S$ by transformations and then calculate $E(S)$ by standard method. But is there a simpler and less tedious approach?","Suppose we draw a random sample $X_1,X_2,\ldots,X_n$ from $N(\mu,\sigma^2)$ population. Let $S^2$ be the sample variance given by $\frac{1}{n-1}\sum_{i=1}^{n}(X_i-\bar{X})^2$ Now, we are to find $E(S)$. It is simple enough if we find the pdf of $S$ by transformations and then calculate $E(S)$ by standard method. But is there a simpler and less tedious approach?",,"['probability', 'statistics']"
20,When does the inequality change in probability problems and why does it?,When does the inequality change in probability problems and why does it?,,"From what I've learned in my stats class when you have $P(X \gt x)$ you make it $P(X \gt x) = 1-P(X \le x)$. I think I understand that you have to do this inequality change because you can't calculate a probability of any possible number being greater than $x$, but I don't understand why greater than changes to less than or equal to. Why is this the case? Also, does it work that way in reverse? Is $P(X \ge x)=1-P(X \lt x)$?","From what I've learned in my stats class when you have $P(X \gt x)$ you make it $P(X \gt x) = 1-P(X \le x)$. I think I understand that you have to do this inequality change because you can't calculate a probability of any possible number being greater than $x$, but I don't understand why greater than changes to less than or equal to. Why is this the case? Also, does it work that way in reverse? Is $P(X \ge x)=1-P(X \lt x)$?",,"['probability', 'statistics']"
21,"Rolling a die, probability of the sum","Rolling a die, probability of the sum",,"I need help with a particular problem in my statistics textbook. Imagine rolling a normal die with six sides $100$ times. I need to find the probability that the sum of the values rolled in those $100$ times is less than $300$ . So for the sum, we want to look at the random variable $Y=X_1+X_2+...+X_{100}$ . Every $X_i$ should have the same mean and variance, let's say the mean is $\mu$ and the variance is $\sigma^2$ . Then the mean of $Y$ would be $100\mu$ and the variance is $100\sigma^2$ . We want to find $P(Y<300)$ . Using a continuity correction, we want to look at $P(Y<300.5)$ . Then $P(Y<300.5)=P\left({Z<\dfrac{300.5-100\mu}{\sqrt{100 \sigma^2}}}\right)$ . I could find the answer from here. However, I am having a hard time figuring out what $\mu$ and $\sigma^2$ should equal. I know that $\mu=np$ and $\sigma^2=np(1-p)$ for a normal approximation. But I don't know what $n$ and $p$ would be for the $X_1, X_2, ..., X_{100}$ or if that is the correct way to go about this problem. Any help is appreciated, thank you.","I need help with a particular problem in my statistics textbook. Imagine rolling a normal die with six sides times. I need to find the probability that the sum of the values rolled in those times is less than . So for the sum, we want to look at the random variable . Every should have the same mean and variance, let's say the mean is and the variance is . Then the mean of would be and the variance is . We want to find . Using a continuity correction, we want to look at . Then . I could find the answer from here. However, I am having a hard time figuring out what and should equal. I know that and for a normal approximation. But I don't know what and would be for the or if that is the correct way to go about this problem. Any help is appreciated, thank you.","100 100 300 Y=X_1+X_2+...+X_{100} X_i \mu \sigma^2 Y 100\mu 100\sigma^2 P(Y<300) P(Y<300.5) P(Y<300.5)=P\left({Z<\dfrac{300.5-100\mu}{\sqrt{100 \sigma^2}}}\right) \mu \sigma^2 \mu=np \sigma^2=np(1-p) n p X_1, X_2, ..., X_{100}","['probability', 'statistics', 'probability-distributions', 'normal-distribution', 'dice']"
22,"Testing $ H_0: p_1 = \ldots = p_k $ with a sequence $ x_1, \ldots, x_k $ of realizations of $ X_1 \sim B(n_1, p_1), \ldots, X_k \sim B(n_k, p_k) $",Testing  with a sequence  of realizations of," H_0: p_1 = \ldots = p_k   x_1, \ldots, x_k   X_1 \sim B(n_1, p_1), \ldots, X_k \sim B(n_k, p_k) ","Let $ X_1 \sim B(n_1, p_1), \ldots, X_k \sim B(n_k, p_k) $ be independent random variables and $ x_1, \ldots, x_k $ a sequence of realizations of them. I know the value of $n_1, \ldots, n_k $ but not that of $ p_1, \ldots, p_k $ and I'm looking for a way to test $ H_0: p_1 = \ldots = p_k $.","Let $ X_1 \sim B(n_1, p_1), \ldots, X_k \sim B(n_k, p_k) $ be independent random variables and $ x_1, \ldots, x_k $ a sequence of realizations of them. I know the value of $n_1, \ldots, n_k $ but not that of $ p_1, \ldots, p_k $ and I'm looking for a way to test $ H_0: p_1 = \ldots = p_k $.",,"['probability', 'statistics', 'statistical-inference', 'binomial-distribution']"
23,"For two continuous RVs $X$ and $Y$ such that $Y=X$, does $P(X=Y)=1$ hold?","For two continuous RVs  and  such that , does  hold?",X Y Y=X P(X=Y)=1,"Given that there are two continuous random variables $X$ and $Y$ such that $Y=X$. Does this mean that $P(X=Y)=1$? My guess is that though $X$ and $Y$ are separately continuous, it is not mentioned that they are jointly continuous. So the joint density may not exist, in which case I cannot conclude that $P(X=Y)=1$. In other words, there does not exist any integrable function $f$ such that $P(X\le x,Y\le y)=\int_{-\infty}^x\int_{-\infty}^y f(u,v)\,du\,dv$ unless both the RVs are jointly continuous. But whenever it is said that $X=Y$, isn't it understood as being true almost everywhere, i.e., with probability $1$? So should I conclude that $P(X=Y)=0$ in any case? This also leads me to ask if it is necessarily true that $P(X=Y)=\int\int_{\substack\{(u,v):u=v\}} f(u,v)\,du\,dv=0$ for any two continuous RVs $X$ and $Y$.","Given that there are two continuous random variables $X$ and $Y$ such that $Y=X$. Does this mean that $P(X=Y)=1$? My guess is that though $X$ and $Y$ are separately continuous, it is not mentioned that they are jointly continuous. So the joint density may not exist, in which case I cannot conclude that $P(X=Y)=1$. In other words, there does not exist any integrable function $f$ such that $P(X\le x,Y\le y)=\int_{-\infty}^x\int_{-\infty}^y f(u,v)\,du\,dv$ unless both the RVs are jointly continuous. But whenever it is said that $X=Y$, isn't it understood as being true almost everywhere, i.e., with probability $1$? So should I conclude that $P(X=Y)=0$ in any case? This also leads me to ask if it is necessarily true that $P(X=Y)=\int\int_{\substack\{(u,v):u=v\}} f(u,v)\,du\,dv=0$ for any two continuous RVs $X$ and $Y$.",,"['probability', 'statistics', 'random-variables']"
24,Are dependent variables random?,Are dependent variables random?,,"A linear regression model can be described as: $$ y = \beta_0 + \beta_1 X + \epsilon $$ where $\epsilon$ is the zero mean normal error. My question is: Is $X$ random variable? If no, then how can we define $$ \mathbb{E}[y\mid X]$$ as $X$ is a deterministic. If yes, then what do we mean by this (found in the wikipedia page) ""we want to find how changing the value of $X$, changes $typical/expected$ value of $y$?"" Are we talking about an instance of random X or expected value of X? link for wiki page: https://en.wikipedia.org/wiki/Regression_analysis","A linear regression model can be described as: $$ y = \beta_0 + \beta_1 X + \epsilon $$ where $\epsilon$ is the zero mean normal error. My question is: Is $X$ random variable? If no, then how can we define $$ \mathbb{E}[y\mid X]$$ as $X$ is a deterministic. If yes, then what do we mean by this (found in the wikipedia page) ""we want to find how changing the value of $X$, changes $typical/expected$ value of $y$?"" Are we talking about an instance of random X or expected value of X? link for wiki page: https://en.wikipedia.org/wiki/Regression_analysis",,"['statistics', 'normal-distribution', 'regression', 'conditional-expectation', 'linear-regression']"
25,Show $\mathbb{E}[X] \le \mathbb{E}[Y]$,Show,\mathbb{E}[X] \le \mathbb{E}[Y],"I have a problem that I'm having trouble to identify the correct integral intervals for proof. I would like to have some help on the thought process. Problem: Let $X$ and $Y$ have densities $f$ and $g$, respectively, and    $f(x)   \begin{cases} \ge g(x),  & \text{if $x$ }\le a;\\ \le g(x), & \text{if $x$ }\ge a \end{cases} $ Show that $\mathbb{E}[X] \le \mathbb{E}[Y]$ Since $\mathbb{E}[X]= \displaystyle  \int_{-\infty}^{\infty} xf(x)\, dx$ I will have to identify intervals (one positive and one negative) that are able to prove $\mathbb{E}[X] \le \mathbb{E}[Y]$ for all cases. However, I feel there may be an intersection, which leads to 3 intervals total, but I'm not sure how to divide up the segments. I would like some help with laying out the proof.","I have a problem that I'm having trouble to identify the correct integral intervals for proof. I would like to have some help on the thought process. Problem: Let $X$ and $Y$ have densities $f$ and $g$, respectively, and    $f(x)   \begin{cases} \ge g(x),  & \text{if $x$ }\le a;\\ \le g(x), & \text{if $x$ }\ge a \end{cases} $ Show that $\mathbb{E}[X] \le \mathbb{E}[Y]$ Since $\mathbb{E}[X]= \displaystyle  \int_{-\infty}^{\infty} xf(x)\, dx$ I will have to identify intervals (one positive and one negative) that are able to prove $\mathbb{E}[X] \le \mathbb{E}[Y]$ for all cases. However, I feel there may be an intersection, which leads to 3 intervals total, but I'm not sure how to divide up the segments. I would like some help with laying out the proof.",,"['probability', 'statistics', 'proof-verification', 'continuity', 'density-function']"
26,Expected value of the number of distinct results of die rolls in $N$ trials,Expected value of the number of distinct results of die rolls in  trials,N,"Given $N$ trials of a die roll, where we have defined $D$ as the number of distinct outcomes, what would be the mean and standard deviation of $D$? If we have defined $I(k)$ as an indicator random variable which equals 1 if outcome $k$ (such as 6) appears at least once, and 0 otherwise, for $k\in\{ 1,\dots,6\}$, then by definition $$D = \sum\limits_{k=1}^6 I(k)$$ How do the dependencies between the $I(k)$ play into the solution? (Which is the part that is tripping me up the most.)","Given $N$ trials of a die roll, where we have defined $D$ as the number of distinct outcomes, what would be the mean and standard deviation of $D$? If we have defined $I(k)$ as an indicator random variable which equals 1 if outcome $k$ (such as 6) appears at least once, and 0 otherwise, for $k\in\{ 1,\dots,6\}$, then by definition $$D = \sum\limits_{k=1}^6 I(k)$$ How do the dependencies between the $I(k)$ play into the solution? (Which is the part that is tripping me up the most.)",,"['probability', 'statistics', 'dice', 'variance']"
27,"Standard deviation of $x_1,x_2,x_3,....,x_{18}$",Standard deviation of,"x_1,x_2,x_3,....,x_{18}","If $\sum^{18}_{i=1} (x_i-8)=9$ and $\sum^{18}_{i=1} (x_i-8)^2=45$, then find standard deviation of $x_1,x_2,x_3,...,x_{18}$ Using $\sum^{18}_{i=1} (x_i-8)=9$, I got mean mean of $x_1,x_2,x_3,...,x_{18}$ as $\frac{17}{2}$ but how to use second condition to find variance so that standard deviation can be found?","If $\sum^{18}_{i=1} (x_i-8)=9$ and $\sum^{18}_{i=1} (x_i-8)^2=45$, then find standard deviation of $x_1,x_2,x_3,...,x_{18}$ Using $\sum^{18}_{i=1} (x_i-8)=9$, I got mean mean of $x_1,x_2,x_3,...,x_{18}$ as $\frac{17}{2}$ but how to use second condition to find variance so that standard deviation can be found?",,"['statistics', 'euler-mascheroni-constant']"
28,Equality-constrained least-squares problem via Lagrange multipliers,Equality-constrained least-squares problem via Lagrange multipliers,,"I am taking a Theory of Linear Models class and got the following assignment: Solve the Least Squares Probem using Lagrange Multipliers. We are in the 3rd week of this class so we have only covered the basics. I don't have much experience in this field and the problem statement is not too elaborate so I need some perspective. I have researched and all the information I can find is on Constrained Linear Models, some have what they call ""linear constraints"", like here: Then again, it says ""When we compare different models"". Am I supposed to solve a problem with a linear constraint or is that something completely different?  Any tips to get me started would be highly appreciated.","I am taking a Theory of Linear Models class and got the following assignment: Solve the Least Squares Probem using Lagrange Multipliers. We are in the 3rd week of this class so we have only covered the basics. I don't have much experience in this field and the problem statement is not too elaborate so I need some perspective. I have researched and all the information I can find is on Constrained Linear Models, some have what they call ""linear constraints"", like here: Then again, it says ""When we compare different models"". Am I supposed to solve a problem with a linear constraint or is that something completely different?  Any tips to get me started would be highly appreciated.",,"['statistics', 'regression', 'lagrange-multiplier', 'least-squares', 'quadratic-programming']"
29,What is the variance of a variable given itself?,What is the variance of a variable given itself?,,"Given an event $X$, what is $\operatorname{var}[X\mid X]$. In addition, what would $E[\operatorname{var}(X\mid X)]$ be? I have been told that $\operatorname{var}[X\mid X] = 0$, but I don't understand why - $\operatorname{var}[X\mid X]$ should be a random variable, and $X\mid X$ has no more information than $X$, so $\operatorname{var}[X\mid X]$ should equal $\operatorname{var}[X]$, correct?","Given an event $X$, what is $\operatorname{var}[X\mid X]$. In addition, what would $E[\operatorname{var}(X\mid X)]$ be? I have been told that $\operatorname{var}[X\mid X] = 0$, but I don't understand why - $\operatorname{var}[X\mid X]$ should be a random variable, and $X\mid X$ has no more information than $X$, so $\operatorname{var}[X\mid X]$ should equal $\operatorname{var}[X]$, correct?",,"['statistics', 'random-variables', 'expectation', 'variance']"
30,Is it true that $P(A|B)+P(A|\overline B) = 1$?,Is it true that ?,P(A|B)+P(A|\overline B) = 1,"tl;dr $P(A|B) + P(A|\overline B)=1$. My question is, is this true? More detail The book I'm reading (Statistics for Business and Economics, Paul Newbold et al) has this example (paraphrased a little). 10% athletes have used performance enhancing drugs. A test is available that correctly identifies an athlete's drug usage 90% of the time. If an athlete is a drug user, the probability is 0.9 that the athlete is correctly identified by the test as a drug user. Similarly is not a drug user, the prob is 0.9 that the athlete is correctly identified as not using drugs. So this is fine so far. From this I'd get the following: Let D = athlete is a drug user, + = test calls positive, - = test calls negative $ \begin{align}    P(D) &= 0.10  \implies P(\overline D)\\    P(+|D) &= 0.90 \\    P(-|\overline D) &= 0.90   \end{align} $ Where the example looses me is that it says that the following can also be defined from the above information... $ \begin{align}    P(+|\overline D) &= 0.10 \\    P(-|D) &= 0.10   \end{align} $ And this is where I'm struggling... it seems that they can only be getting this by assuming $P(+|D)+P(+|\overline D)=1$, or more generally $P(A|B) + P(A|\overline B)=1$. My question is, is this true? Here's what I've tried so far to see if it is true... $ \begin{align} P(A|B)+P(A|\overline B) &= \frac{P(A \cap B)}{P(B)} + \frac{P(A \cap \overline B)}{P(\overline B)}\\ &= \frac{P(A \cap B)P(\overline B) + P(A \cap \overline B)P(B)}{P(B)P(\overline B)} \\ &= \frac{P(A \cap B)(1-P(B)) + P(A \cap \overline B)P(B)}{P(B)P(\overline B)}\\ &= \frac{P(A \cap B) - P(A \cap B)P(B) + P(A \cap \overline B)P(B)}{P(B)P(\overline B)}\\ &= \frac{P(A \cap B)}{P(B)(1 - P(B))} + \frac{P(A \cap \overline B) - P(A \cap B)}{P(\overline B)} \\ &= \frac{P(A \cap B)}{P(B)(1 - P(B))} + \frac{P(A \cap \overline B) - (1 - P(A \cap \overline B))}{P(\overline B)} \\ &= \frac{P(A \cap B)}{P(B)(1 - P(B))} + \frac{2\cdot P(A \cap \overline B) - 1}{P(\overline B)} \\ &= \frac{P(A \cap B)}{P^2(B)} + \frac{2\cdot P(A \cap \overline B) - 1}{P(\overline B)} \\ &= ????? \end{align}  $ And then stuck... can't see how this is true. And looking at a Venn diagram representation it didn't enlighten me... any thoughts on how this question's answer in the book is making the assertions it is? Many thanks.","tl;dr $P(A|B) + P(A|\overline B)=1$. My question is, is this true? More detail The book I'm reading (Statistics for Business and Economics, Paul Newbold et al) has this example (paraphrased a little). 10% athletes have used performance enhancing drugs. A test is available that correctly identifies an athlete's drug usage 90% of the time. If an athlete is a drug user, the probability is 0.9 that the athlete is correctly identified by the test as a drug user. Similarly is not a drug user, the prob is 0.9 that the athlete is correctly identified as not using drugs. So this is fine so far. From this I'd get the following: Let D = athlete is a drug user, + = test calls positive, - = test calls negative $ \begin{align}    P(D) &= 0.10  \implies P(\overline D)\\    P(+|D) &= 0.90 \\    P(-|\overline D) &= 0.90   \end{align} $ Where the example looses me is that it says that the following can also be defined from the above information... $ \begin{align}    P(+|\overline D) &= 0.10 \\    P(-|D) &= 0.10   \end{align} $ And this is where I'm struggling... it seems that they can only be getting this by assuming $P(+|D)+P(+|\overline D)=1$, or more generally $P(A|B) + P(A|\overline B)=1$. My question is, is this true? Here's what I've tried so far to see if it is true... $ \begin{align} P(A|B)+P(A|\overline B) &= \frac{P(A \cap B)}{P(B)} + \frac{P(A \cap \overline B)}{P(\overline B)}\\ &= \frac{P(A \cap B)P(\overline B) + P(A \cap \overline B)P(B)}{P(B)P(\overline B)} \\ &= \frac{P(A \cap B)(1-P(B)) + P(A \cap \overline B)P(B)}{P(B)P(\overline B)}\\ &= \frac{P(A \cap B) - P(A \cap B)P(B) + P(A \cap \overline B)P(B)}{P(B)P(\overline B)}\\ &= \frac{P(A \cap B)}{P(B)(1 - P(B))} + \frac{P(A \cap \overline B) - P(A \cap B)}{P(\overline B)} \\ &= \frac{P(A \cap B)}{P(B)(1 - P(B))} + \frac{P(A \cap \overline B) - (1 - P(A \cap \overline B))}{P(\overline B)} \\ &= \frac{P(A \cap B)}{P(B)(1 - P(B))} + \frac{2\cdot P(A \cap \overline B) - 1}{P(\overline B)} \\ &= \frac{P(A \cap B)}{P^2(B)} + \frac{2\cdot P(A \cap \overline B) - 1}{P(\overline B)} \\ &= ????? \end{align}  $ And then stuck... can't see how this is true. And looking at a Venn diagram representation it didn't enlighten me... any thoughts on how this question's answer in the book is making the assertions it is? Many thanks.",,"['probability', 'statistics', 'bayes-theorem']"
31,Confidence intervals without the knowing the distribution of the data,Confidence intervals without the knowing the distribution of the data,,"I am given the data set containing the values 12.09, 11.18, 9.97, 10.5,0 9.92, 9.97, 11.84, 10.93, 10.70. I am asked to construct a 90% confidence interval for the mean but I am not told the distribution. I am told to use the software package R in order to justify any assumptions I make. Even once I have plotted this data in R though I am not seeing a clear distribution and thus cannot construct the confidence interval. Can anyone help? I have also found the sample mean to be 10.78889 and the standard deviation to be 0.8029702.","I am given the data set containing the values 12.09, 11.18, 9.97, 10.5,0 9.92, 9.97, 11.84, 10.93, 10.70. I am asked to construct a 90% confidence interval for the mean but I am not told the distribution. I am told to use the software package R in order to justify any assumptions I make. Even once I have plotted this data in R though I am not seeing a clear distribution and thus cannot construct the confidence interval. Can anyone help? I have also found the sample mean to be 10.78889 and the standard deviation to be 0.8029702.",,"['statistics', 'confidence-interval']"
32,"I am confused about the kernel of a matrix and the ""kernel""","I am confused about the kernel of a matrix and the ""kernel""",,"In linear algebra, the kernel of a matrix is its null space. In machine learning and statistics, there are a bunch of matrices are called ""kernel"". For example, I am totally confused. The second ""kernal"" concept looks very much like a projection to me, rather than a ""null space"". Why they are given the same name? Is there any connection between the two concepts? Thank you!","In linear algebra, the kernel of a matrix is its null space. In machine learning and statistics, there are a bunch of matrices are called ""kernel"". For example, I am totally confused. The second ""kernal"" concept looks very much like a projection to me, rather than a ""null space"". Why they are given the same name? Is there any connection between the two concepts? Thank you!",,"['linear-algebra', 'statistics', 'machine-learning']"
33,"Binomial distribution, given the number of success, what is the expected total number of trials?","Binomial distribution, given the number of success, what is the expected total number of trials?",,"For a random variable that follows binomial distribution, $X|N=n\sim Binomial(n,p)$. What is the expectation of $N$ when we know the value of the random variable but don't know the total? ie. What is $E[N|X=k]$? Do we need to know the distribution of $N$ first? If so, please assume $N\sim Pois(\lambda)$ Note: I am not sure if my notation is entirely correct","For a random variable that follows binomial distribution, $X|N=n\sim Binomial(n,p)$. What is the expectation of $N$ when we know the value of the random variable but don't know the total? ie. What is $E[N|X=k]$? Do we need to know the distribution of $N$ first? If so, please assume $N\sim Pois(\lambda)$ Note: I am not sure if my notation is entirely correct",,"['probability', 'statistics', 'binomial-distribution']"
34,Statistical independence of degree in Erdos-Renyi random graph model,Statistical independence of degree in Erdos-Renyi random graph model,,"Let $d(v)$ denote the degree of the vertex $v$ in the random graph $G$ coming from the Erdos-Renyi model. I would like to calculate $\mathbb{E}[d(v) d(u)]$. Clearly, $$\mathbb{E}[d(u)] = \mathbb{E}[d(v)] = p \cdot (|N| - 1),$$ where p is the edge selection probability specified by the model. But are $d(v)$ and $d(u)$ statistically independent so that $$\mathbb{E}[d(v) d(u)] = \mathbb{E}[d(v)]\cdot\mathbb{E}[d(u)]?$$ Is it true that we can break this into the following two conditionally independent cases: if $u,v$ adjacent: $$\mathbb{E}[d(v)] = \mathbb{E}[d(u)] = (|N| - 2) + 1$$ otherwise: $$\mathbb{E}[d(v)] = \mathbb{E}[d(u)] = (|N| - 2)$$","Let $d(v)$ denote the degree of the vertex $v$ in the random graph $G$ coming from the Erdos-Renyi model. I would like to calculate $\mathbb{E}[d(v) d(u)]$. Clearly, $$\mathbb{E}[d(u)] = \mathbb{E}[d(v)] = p \cdot (|N| - 1),$$ where p is the edge selection probability specified by the model. But are $d(v)$ and $d(u)$ statistically independent so that $$\mathbb{E}[d(v) d(u)] = \mathbb{E}[d(v)]\cdot\mathbb{E}[d(u)]?$$ Is it true that we can break this into the following two conditionally independent cases: if $u,v$ adjacent: $$\mathbb{E}[d(v)] = \mathbb{E}[d(u)] = (|N| - 2) + 1$$ otherwise: $$\mathbb{E}[d(v)] = \mathbb{E}[d(u)] = (|N| - 2)$$",,"['probability', 'statistics', 'graph-theory']"
35,Question about the definition of independent events,Question about the definition of independent events,,"If you have two events A and B that are independent, then it is said that $p(A)p(B)=p(A\cap B)$, and illustrated in a venn diagram as two areas that do not overlap. The opposite goes for dependent events A and B, where if A is dependent on B, then $p(A|B)p(B)=p(A\cap B)$ and in the venn diagram, the areas representing these events do overlap. My questions are: Are there any instances where event A does overlap B but is not dependent on B? Are there instances where A does not overlap with B, but is dependent on B? My guess here is that there are no such cases, where if one instance is satisfied then it by definition calls for the other. For instance, regarding question 1, if A overlaps B, then a dependence between the two exists. For question 2, if A does not overlap B, then it cannot be dependent on it. Are these ideas correct, or are there any situations where this might not work?","If you have two events A and B that are independent, then it is said that $p(A)p(B)=p(A\cap B)$, and illustrated in a venn diagram as two areas that do not overlap. The opposite goes for dependent events A and B, where if A is dependent on B, then $p(A|B)p(B)=p(A\cap B)$ and in the venn diagram, the areas representing these events do overlap. My questions are: Are there any instances where event A does overlap B but is not dependent on B? Are there instances where A does not overlap with B, but is dependent on B? My guess here is that there are no such cases, where if one instance is satisfied then it by definition calls for the other. For instance, regarding question 1, if A overlaps B, then a dependence between the two exists. For question 2, if A does not overlap B, then it cannot be dependent on it. Are these ideas correct, or are there any situations where this might not work?",,"['probability', 'statistics']"
36,Poisson processes and ballistic missiles,Poisson processes and ballistic missiles,,"In response to an attack of 10 missiles, a response of 500 antiballistic missiles are launched. The missile targets of each antimissile are independent, and equiprobably picked. Each antimissile has a $.1$ chance to hit. What is the probability of all 10 missiles being hit? The question then asks the student to use a Poisson process, although I'm willing to solve this using other methods. I thought I'd have $$X=\sum X_i$$ with $$X_i=1,0$$ if hit or not hit respectively. Then $$P(X_i=1)=\sum_{k=1}^{500}\,_{500}\text{C}_kp^k(1-p)^{500-k}$$ and $p=1/100$. I'm fairly certain my approach is wrong, and I do not know how to finish the problem.","In response to an attack of 10 missiles, a response of 500 antiballistic missiles are launched. The missile targets of each antimissile are independent, and equiprobably picked. Each antimissile has a $.1$ chance to hit. What is the probability of all 10 missiles being hit? The question then asks the student to use a Poisson process, although I'm willing to solve this using other methods. I thought I'd have $$X=\sum X_i$$ with $$X_i=1,0$$ if hit or not hit respectively. Then $$P(X_i=1)=\sum_{k=1}^{500}\,_{500}\text{C}_kp^k(1-p)^{500-k}$$ and $p=1/100$. I'm fairly certain my approach is wrong, and I do not know how to finish the problem.",,"['probability', 'statistics']"
37,Covariance for equal variances,Covariance for equal variances,,"If X and Y are independent random variables with equal variances, find Cov(X+Y, X-Y). I am confused on how to do this? I feel like I am over thinking this question.","If X and Y are independent random variables with equal variances, find Cov(X+Y, X-Y). I am confused on how to do this? I feel like I am over thinking this question.",,"['probability', 'statistics']"
38,"If $X$ has CDF $F$, how can I find the CDF of $U= \max \{0,X \}$?","If  has CDF , how can I find the CDF of ?","X F U= \max \{0,X \}","If $X$ has CDF $F$, how can I find the CDF of $U=\max\{0,X\}$? Obviously the suport of $U$ consists solely of nonnegative values. Am I right then in thinking  that for $u=0, F_U (u)=F_X(0)$ and for  $u > 0$, $F_U (u)  =F_X(u)$? Thank you.","If $X$ has CDF $F$, how can I find the CDF of $U=\max\{0,X\}$? Obviously the suport of $U$ consists solely of nonnegative values. Am I right then in thinking  that for $u=0, F_U (u)=F_X(0)$ and for  $u > 0$, $F_U (u)  =F_X(u)$? Thank you.",,"['probability', 'statistics', 'self-learning']"
39,can I get the correct average of a set of numbers from the averages of several subsets?,can I get the correct average of a set of numbers from the averages of several subsets?,,Let's say I have this set of numbers: 565 212 812 895 443 73 468 900 299 993 252 740 291 112 (average 503.9285714286) I'd like to split them apart into 3 sets of unequal size: 565 212 812 (529.6666666667)   443 73 468 900 299 895 (513)    993 252 740 291 112 (477.6) Then take the average of each set and (somehow) get the average of the entire set from the 3 averages. Assume that the number of subsets is variable and the number of values in each set is also variable.,Let's say I have this set of numbers: 565 212 812 895 443 73 468 900 299 993 252 740 291 112 (average 503.9285714286) I'd like to split them apart into 3 sets of unequal size: 565 212 812 (529.6666666667)   443 73 468 900 299 895 (513)    993 252 740 291 112 (477.6) Then take the average of each set and (somehow) get the average of the entire set from the 3 averages. Assume that the number of subsets is variable and the number of values in each set is also variable.,,['statistics']
40,What is the $k$th factorial moment of the binomial distribution?,What is the th factorial moment of the binomial distribution?,k,I'm not sure what to do from here. $$E[x(x-1)(x-2)\ldots(x-k+1)]=E\left[x!\over k!\right]={1\over k!}\left[\sum x!p(x)\right]={1 \over k!}\left[\sum\frac{n!}{(n-x)!}p^{x}q^{n-x}\right]$$,I'm not sure what to do from here. $$E[x(x-1)(x-2)\ldots(x-k+1)]=E\left[x!\over k!\right]={1\over k!}\left[\sum x!p(x)\right]={1 \over k!}\left[\sum\frac{n!}{(n-x)!}p^{x}q^{n-x}\right]$$,,['statistics']
41,Change mean of a set of values,Change mean of a set of values,,"I'm trying to solve this problem, but I'm not even sure how to formulate it in a coherent mathematical manner, or even what branch of mathematics this might fall in to. Basically I have a set of weights, where each weight individually must remain in the range $[0,1]$.  I want to change the mean of the weights to some new mean, also in the $[0,1]$ range, by modifying all the weights slightly (that is, I can't add or remove weights; only modify their values). Also, ideally, after changing the mean to a new value, if I do the algorithm again, and try to return to the original mean, I'll get the same original weights.  That is, the mapping function can work as its own inverse.  Which I think implies certain things about the distribution of the values of the weights before and after the mapping, but I'm not sure how to describe it in mathematical terms. Last, the amount of movement of individual weights should be minimized, probably in a least squares sort of way.  That is, I'd prefer to move all the values a slight amount over moving a single value from 0 to 1, for instance. Does anyone know how I might go about this sort of remapping?  Basically I have four requirements: After modifying the original weights, the new values stay within $[0,1]$. The new mean of the modified weights must be the mean I wanted The mapping can be applied again to get back to the original weights. The change in weights is minimized in a least squares-esque manner.","I'm trying to solve this problem, but I'm not even sure how to formulate it in a coherent mathematical manner, or even what branch of mathematics this might fall in to. Basically I have a set of weights, where each weight individually must remain in the range $[0,1]$.  I want to change the mean of the weights to some new mean, also in the $[0,1]$ range, by modifying all the weights slightly (that is, I can't add or remove weights; only modify their values). Also, ideally, after changing the mean to a new value, if I do the algorithm again, and try to return to the original mean, I'll get the same original weights.  That is, the mapping function can work as its own inverse.  Which I think implies certain things about the distribution of the values of the weights before and after the mapping, but I'm not sure how to describe it in mathematical terms. Last, the amount of movement of individual weights should be minimized, probably in a least squares sort of way.  That is, I'd prefer to move all the values a slight amount over moving a single value from 0 to 1, for instance. Does anyone know how I might go about this sort of remapping?  Basically I have four requirements: After modifying the original weights, the new values stay within $[0,1]$. The new mean of the modified weights must be the mean I wanted The mapping can be applied again to get back to the original weights. The change in weights is minimized in a least squares-esque manner.",,"['linear-algebra', 'statistics']"
42,Calculating the variance of an estimator (unclear on one step),Calculating the variance of an estimator (unclear on one step),,How can you go from $4V(\bar X)$ to $\displaystyle \frac{4}{n}V(X_1)$? I understand the rest of the steps...,How can you go from $4V(\bar X)$ to $\displaystyle \frac{4}{n}V(X_1)$? I understand the rest of the steps...,,"['probability', 'statistics', 'parameter-estimation']"
43,"I'm asked to give a combinatorial proof of the following question, how would I go about doing it?","I'm asked to give a combinatorial proof of the following question, how would I go about doing it?",,"The hint we're given is to think of it in terms of grid paths. I don't necessarily want the answer, I'm interested in learning how to do this. Could anyone offer an explanation (clearly please) on how I would go about proving this?","The hint we're given is to think of it in terms of grid paths. I don't necessarily want the answer, I'm interested in learning how to do this. Could anyone offer an explanation (clearly please) on how I would go about proving this?",,"['probability', 'statistics', 'discrete-mathematics']"
44,What is a 'critical value' in statistics?,What is a 'critical value' in statistics?,,"Here's where I encountered this word: The raw material needed for the manufacture of medicine has to be at least $97\%$ pure. A buyer analyzes the nullhypothesis, that the proportion is $\mu_0=97\%$, with the alternative hypothesis that the proportion is higher than $97\%$. He decides to buy the raw material if the nulhypothesis gets rejected with $\alpha = 0.05$. So if the calculated critical value is equal to $t_{\alpha} = 98 \%$, he'll only buy if he finds a proportion of $98\%$ or higher with his analysis. The risk that he buys a raw material with a proportion of $97\%$ (nullhypothesis is true) is $100 \times \alpha = 5 \%$ I don't really understand what is meant by 'critical value'","Here's where I encountered this word: The raw material needed for the manufacture of medicine has to be at least $97\%$ pure. A buyer analyzes the nullhypothesis, that the proportion is $\mu_0=97\%$, with the alternative hypothesis that the proportion is higher than $97\%$. He decides to buy the raw material if the nulhypothesis gets rejected with $\alpha = 0.05$. So if the calculated critical value is equal to $t_{\alpha} = 98 \%$, he'll only buy if he finds a proportion of $98\%$ or higher with his analysis. The risk that he buys a raw material with a proportion of $97\%$ (nullhypothesis is true) is $100 \times \alpha = 5 \%$ I don't really understand what is meant by 'critical value'",,['statistics']
45,Generate a random pair of integers whose product is less than or equal to x?,Generate a random pair of integers whose product is less than or equal to x?,,"Ideally, the distribution over the acceptable pairs would be close to uniform. x and the pair are all positive integers (This is for code, so I need a constructive solution) Thanks!","Ideally, the distribution over the acceptable pairs would be close to uniform. x and the pair are all positive integers (This is for code, so I need a constructive solution) Thanks!",,['statistics']
46,Cumulative density function of a maximum and minimum,Cumulative density function of a maximum and minimum,,"It is given that both $Y$ and $X$ are $U(0,a)$, and that $Z_+ = \max(X,Y)$ and $Z_- = \min(X,Y)$. I need to find the CDF for both zetas. I know that both $X$ and $Y$ have to be smaller or equal to $Z_+$ and bigger or equal to $Z_-$. For $Z_+$: $$F_{Z_+}(z) = P(Z \leq z)$$ And for $Z_-$: $$F_{Z_-}(z) = P(Z \leq z)$$ This were I'm stuck, what is the next thing to do?","It is given that both $Y$ and $X$ are $U(0,a)$, and that $Z_+ = \max(X,Y)$ and $Z_- = \min(X,Y)$. I need to find the CDF for both zetas. I know that both $X$ and $Y$ have to be smaller or equal to $Z_+$ and bigger or equal to $Z_-$. For $Z_+$: $$F_{Z_+}(z) = P(Z \leq z)$$ And for $Z_-$: $$F_{Z_-}(z) = P(Z \leq z)$$ This were I'm stuck, what is the next thing to do?",,"['probability', 'statistics']"
47,Showing that two variables do no have a bivariate normal distribution,Showing that two variables do no have a bivariate normal distribution,,"If $X_1$ is $N(0,1)$ and $X_2 = -X_1$ if $-1 \leq X_1 \leq 1$ or $X_2 = X_1$ otherwise, how do you prove that $X_1$ and $X_2$ do not have a bivariate normal distribution? Attempt: Using the Jacobian method I proved that the distribution of $X_2$ is the standard normal distribution. To prove that $X_1$ and $X_2$ do not have a bivariate normal distribution there is a hint that says to consider the linear combination $X_1-X_2$ where $P(X_1-X_2) = P(|X_1|>1) = 0.3174$.","If $X_1$ is $N(0,1)$ and $X_2 = -X_1$ if $-1 \leq X_1 \leq 1$ or $X_2 = X_1$ otherwise, how do you prove that $X_1$ and $X_2$ do not have a bivariate normal distribution? Attempt: Using the Jacobian method I proved that the distribution of $X_2$ is the standard normal distribution. To prove that $X_1$ and $X_2$ do not have a bivariate normal distribution there is a hint that says to consider the linear combination $X_1-X_2$ where $P(X_1-X_2) = P(|X_1|>1) = 0.3174$.",,"['probability', 'statistics']"
48,Confusion about covariance,Confusion about covariance,,"$\newcommand{\Cov}{\operatorname{Cov}}$ $X_i$ from $i=1,\ldots,n$ is a set of random variables The following confuses me: $\Cov\left(\sum_{i=1}^n X_i, \sum_{j=1}^n X_j\right) =$ the sum of all possible covariance pairs (so $n\cdot n$ terms) (source is the book I'm currently reading) In my thoughts, the expansion might as well be $$\Cov(X_1, X_1)+\Cov(X_2, X_2)+\cdots+\Cov(X_n, X_n)$$ Or $$\Cov(X_1 + X_2 + \cdots +X_n, X_1 + X_2 + \cdots +X_n)$$","$\newcommand{\Cov}{\operatorname{Cov}}$ $X_i$ from $i=1,\ldots,n$ is a set of random variables The following confuses me: $\Cov\left(\sum_{i=1}^n X_i, \sum_{j=1}^n X_j\right) =$ the sum of all possible covariance pairs (so $n\cdot n$ terms) (source is the book I'm currently reading) In my thoughts, the expansion might as well be $$\Cov(X_1, X_1)+\Cov(X_2, X_2)+\cdots+\Cov(X_n, X_n)$$ Or $$\Cov(X_1 + X_2 + \cdots +X_n, X_1 + X_2 + \cdots +X_n)$$",,"['probability', 'statistics', 'random-variables']"
49,Finding probability $P(X+Y < 1)$ with CDF,Finding probability  with CDF,P(X+Y < 1),"Suppose I have a Cumulative Distribution Function like this: $$F(x,y)=\frac { (x\cdot y)^{ 2 } }{ 4 } $$ where $0<x<2$ and $0<y<1$. And I want to find the probability of $P(X+Y<1)$. Since $x<1-y$ and $y<1-x$, I plug these back into the CDF to get this: $$F(1-y,1-x)=\frac { ((1-y)\cdot (1-x))^{ 2 } }{ 4 } $$ Because of the constraint where $0<x<2$ and $0<y<1$, I integrate according to the range of values: $$\int _{ 0 }^{ 1 }{ \int _{ 0 }^{ 2 }{ \frac { ((1-y)\cdot (1-x))^{ 2 } }{ 4 } dxdy }  } =\frac { 1 }{ 18 } $$ This answer, however, is incorrect. My intuition for doing this is that because the two variables are somewhat dependent on each other to maintain the inequality of less than $1$, I want to ""sum""(or integrate) all the probabilities within the possible range of values of $x$ and $y$ that satisfy the inequality. Somehow, the answer, which is $\frac{1}{24}$, doesn't seem to agree with my intuition. What have I done wrong?","Suppose I have a Cumulative Distribution Function like this: $$F(x,y)=\frac { (x\cdot y)^{ 2 } }{ 4 } $$ where $0<x<2$ and $0<y<1$. And I want to find the probability of $P(X+Y<1)$. Since $x<1-y$ and $y<1-x$, I plug these back into the CDF to get this: $$F(1-y,1-x)=\frac { ((1-y)\cdot (1-x))^{ 2 } }{ 4 } $$ Because of the constraint where $0<x<2$ and $0<y<1$, I integrate according to the range of values: $$\int _{ 0 }^{ 1 }{ \int _{ 0 }^{ 2 }{ \frac { ((1-y)\cdot (1-x))^{ 2 } }{ 4 } dxdy }  } =\frac { 1 }{ 18 } $$ This answer, however, is incorrect. My intuition for doing this is that because the two variables are somewhat dependent on each other to maintain the inequality of less than $1$, I want to ""sum""(or integrate) all the probabilities within the possible range of values of $x$ and $y$ that satisfy the inequality. Somehow, the answer, which is $\frac{1}{24}$, doesn't seem to agree with my intuition. What have I done wrong?",,"['probability', 'statistics']"
50,Determining p-th Quantile From Probability Density Function,Determining p-th Quantile From Probability Density Function,,"I'm not sure how to derive the $p$-th quantile. I know that it is point which divides the distribution of $X$ into two parts, but I'm not sure what I'm supposed to do here. If the random variable $X$ has probability density function    $f(x) =  \lambda e^{-\lambda x}$ for $x > 0$. ($\lambda > 0$),    determine the $p$-th quantile $x_p$ in terms of $\lambda$ and $p$.","I'm not sure how to derive the $p$-th quantile. I know that it is point which divides the distribution of $X$ into two parts, but I'm not sure what I'm supposed to do here. If the random variable $X$ has probability density function    $f(x) =  \lambda e^{-\lambda x}$ for $x > 0$. ($\lambda > 0$),    determine the $p$-th quantile $x_p$ in terms of $\lambda$ and $p$.",,"['statistics', 'probability-distributions']"
51,Confusion about joint distribution between two independent random variables,Confusion about joint distribution between two independent random variables,,"Let $X,Y$ be independent random variables, uniform on $(0,1)$. a) $P(X+Y>1.5)$. b) $P(X>Y \mid X>1/2)$. c) $P(\tan^{-1}(Y/X)<t)$ for all $0<t<\pi/2$. e) $E(\tan^{-1}(Y/X))$. I could use the definitions I learned about joint distribution to solve part (a). But I am not sure how to approach the second one when there is conditional probability involves. And for the last two parts, I don't even know how to solve them when there is function like $\tan$ involves.","Let $X,Y$ be independent random variables, uniform on $(0,1)$. a) $P(X+Y>1.5)$. b) $P(X>Y \mid X>1/2)$. c) $P(\tan^{-1}(Y/X)<t)$ for all $0<t<\pi/2$. e) $E(\tan^{-1}(Y/X))$. I could use the definitions I learned about joint distribution to solve part (a). But I am not sure how to approach the second one when there is conditional probability involves. And for the last two parts, I don't even know how to solve them when there is function like $\tan$ involves.",,"['probability', 'statistics']"
52,Degrees of freedom: when to use infinity?,Degrees of freedom: when to use infinity?,,"I have this question: When performing a certain task under simulated weightlessness, the pulse rate of $42$ astronaut trainees increased on the average by $26.4$ beats per minute with a standard deviation of $4.28$ beats per minute. Construct a two sided $95\%$ confidence interval for the true average increase in the pulse rate of the astronaut trainees performing the given task. This is what I worked out: $$ 26.4 \pm  2.021 \cdot \left(\frac{4.28 }{\sqrt{42}} \right) = (25.065, 27.735) $$ I got this from taking the $95\%$ two sided confidence interval from the table on degree of freedom of $40$. I assumed this, because of my sample size being $42$, with the closes number being $40$. I checked the answers I was given and they seem to use infinity for the degrees of freedom, my question is: when are we suppose to the infinity and when do we use the actual rows/degrees of freedom numbers?","I have this question: When performing a certain task under simulated weightlessness, the pulse rate of $42$ astronaut trainees increased on the average by $26.4$ beats per minute with a standard deviation of $4.28$ beats per minute. Construct a two sided $95\%$ confidence interval for the true average increase in the pulse rate of the astronaut trainees performing the given task. This is what I worked out: $$ 26.4 \pm  2.021 \cdot \left(\frac{4.28 }{\sqrt{42}} \right) = (25.065, 27.735) $$ I got this from taking the $95\%$ two sided confidence interval from the table on degree of freedom of $40$. I assumed this, because of my sample size being $42$, with the closes number being $40$. I checked the answers I was given and they seem to use infinity for the degrees of freedom, my question is: when are we suppose to the infinity and when do we use the actual rows/degrees of freedom numbers?",,['statistics']
53,Understanding summation identity,Understanding summation identity,,I'm currently working on proposition 6.3.1 from {Introduction to Statistical Time Series and I have the following equality (consider $\theta_0 = 1$ ) \begin{equation*} \sum_{j = 1}^n \left(\theta_0 u_j + \theta_1 u_{j-1} + \cdots + \theta_q u_{j - q} \right) = \sum_{k = 0}^q \theta_k \sum_{j = 1}^{n} u_j + \sum_{s = 1}^q \sum_{j = s}^q \theta_j u_{j - s} - \sum_{s = 0}^{q-1}\sum_{j = s + 1}^q \theta_j u_{n - s}. \end{equation*} I didn't manage to find if this right. Any tip on how to proof that this works will be appreciated!,I'm currently working on proposition 6.3.1 from {Introduction to Statistical Time Series and I have the following equality (consider ) I didn't manage to find if this right. Any tip on how to proof that this works will be appreciated!,"\theta_0 = 1 \begin{equation*}
\sum_{j = 1}^n \left(\theta_0 u_j + \theta_1 u_{j-1} + \cdots + \theta_q u_{j - q} \right) = \sum_{k = 0}^q \theta_k \sum_{j = 1}^{n} u_j + \sum_{s = 1}^q \sum_{j = s}^q \theta_j u_{j - s} - \sum_{s = 0}^{q-1}\sum_{j = s + 1}^q \theta_j u_{n - s}.
\end{equation*}","['statistics', 'summation']"
54,"The ""turning-point fraction"" of a random sample from a discrete distribution must have expectation less than 2/3?","The ""turning-point fraction"" of a random sample from a discrete distribution must have expectation less than 2/3?",,"A sequence of reals $x_1,...,x_n$ is said to have a turning point at index-value $i$ ( $1\lt i\lt n$ ) iff $x_{i-1}\lt x_{i}\gt x_{i+1}$ or $x_{i-1}\gt x_{i}\lt x_{i+1}$ .  The number of turning points in the sequence is denoted $T(x_1,...,x_n)$ , and we define the turning-point fraction as $$R(x_1,...,x_n)={\text{number of turning points}\over\text{number of potential turning points}}={T(x_1,...,x_n)\over n-2}$$ so $0\le R(x_1,...,x_n)\le 1.$ If $X_1,...,X_n$ are random variables, we define the corresponding r.v.s $T_n=T(X_1,...,X_n)$ and $R_n=R(X_1,...,X_n).$ Conjecture: If $X_1,...,X_n$ are i.i.d. r.v.s with any discrete distribution, then $E[R_n]\lt{2\over 3}$ . (It's easy to show that $E[R_n]={2\over 3}$ when the $X_i$ are i.i.d. with any continuous distribution.) Supposing the $X_i$ are i.i.d. with a discrete distribution having p.m.f. $p()$ and c.d.f. $F()$ , we have the following: $$\begin{align*}E[R_n] &={1\over n-2}E\left[ \sum_{i=2}^{n-1}\mathbb{1}_{(X_{i-1}<X_i>X_{i+1}) \text{ or } (X_{i-1}>X_i<X_{i+1})}\right]\\ &=P[(X_1<X_2>X_3) \text{ or } (X_1>X_2<X_3)]\\ &=P[X_1<X_2>X_3] + P[X_1>X_2<X_3]\\ &=\sum_{x: p(x)>0} p(x)\left(P[X_1<x>X_3\mid X_2=x] + P[X_1>x<X_3\mid X_2=x]\right)\\ &=\sum_{x: p(x)>0} p(x)\left(P[X_1<x]^2 + P[X_1>x]^2\right)\\ &=\sum_{x: p(x)>0} p(x)\left(\left(F(x)-p(x)\right)^2 + \left(1-F(x)\right)^2\right)\\ \end{align*}$$ Question : How to show that this must be less than 2/3, if such is the case? Or find a counterexample if not? NB : Simulations suggest that for a given finite support,  a uniform distribution might maximize $E[R_n]$ .  When the $X_i$ are i.i.d. DiscreteUniform $\{1,...,m\}$ , we have $p(x)={1\over m}$ and $F(x)={x\over m}$ for $x=1,...,m$ ,  and the above summation reduces to $$E[R_n]={(2m-1)(m-1)\over 3m^2}\lt{2\over 3}$$ with $E[R_n]$ approaching ${2\over 3}$ from below as $m\to\infty.$","A sequence of reals is said to have a turning point at index-value ( ) iff or .  The number of turning points in the sequence is denoted , and we define the turning-point fraction as so If are random variables, we define the corresponding r.v.s and Conjecture: If are i.i.d. r.v.s with any discrete distribution, then . (It's easy to show that when the are i.i.d. with any continuous distribution.) Supposing the are i.i.d. with a discrete distribution having p.m.f. and c.d.f. , we have the following: Question : How to show that this must be less than 2/3, if such is the case? Or find a counterexample if not? NB : Simulations suggest that for a given finite support,  a uniform distribution might maximize .  When the are i.i.d. DiscreteUniform , we have and for ,  and the above summation reduces to with approaching from below as","x_1,...,x_n i 1\lt i\lt n x_{i-1}\lt x_{i}\gt x_{i+1} x_{i-1}\gt x_{i}\lt x_{i+1} T(x_1,...,x_n) R(x_1,...,x_n)={\text{number of turning points}\over\text{number of potential turning points}}={T(x_1,...,x_n)\over n-2} 0\le R(x_1,...,x_n)\le 1. X_1,...,X_n T_n=T(X_1,...,X_n) R_n=R(X_1,...,X_n). X_1,...,X_n E[R_n]\lt{2\over 3} E[R_n]={2\over 3} X_i X_i p() F() \begin{align*}E[R_n]
&={1\over n-2}E\left[ \sum_{i=2}^{n-1}\mathbb{1}_{(X_{i-1}<X_i>X_{i+1}) \text{ or } (X_{i-1}>X_i<X_{i+1})}\right]\\
&=P[(X_1<X_2>X_3) \text{ or } (X_1>X_2<X_3)]\\
&=P[X_1<X_2>X_3] + P[X_1>X_2<X_3]\\
&=\sum_{x: p(x)>0} p(x)\left(P[X_1<x>X_3\mid X_2=x] + P[X_1>x<X_3\mid X_2=x]\right)\\
&=\sum_{x: p(x)>0} p(x)\left(P[X_1<x]^2 + P[X_1>x]^2\right)\\
&=\sum_{x: p(x)>0} p(x)\left(\left(F(x)-p(x)\right)^2 + \left(1-F(x)\right)^2\right)\\
\end{align*} E[R_n] X_i \{1,...,m\} p(x)={1\over m} F(x)={x\over m} x=1,...,m E[R_n]={(2m-1)(m-1)\over 3m^2}\lt{2\over 3} E[R_n] {2\over 3} m\to\infty.","['probability', 'statistics', 'random-variables', 'expected-value', 'time-series']"
55,Question about non-i.i.d. Bernoulli random variables,Question about non-i.i.d. Bernoulli random variables,,"Let $X_1, X_2, \dots, X_n \sim \operatorname{Bernoulli}(p)$ and $\bar{X}=\frac{1}{n}\sum\limits_{i=1}^nX_i$ . Find an upper bound for $\mathbb{P}(|\bar{X}-p| > \epsilon) \forall \epsilon > 0$ . Note that random variables are not independent. $\textbf{What I've tried:}$ We know that $\mathbb{E}[\bar{X}] = \mathbb{E}[X_1] = p$ . So we can use Chebyshev's inequality because $\mathbb{P}(|\bar{X}-p| > \epsilon) = \mathbb{P}(|\bar{X}-\mathbb{E}[\bar{X}]| > \epsilon) \le \mathbb{P}(|\bar{X}-\mathbb{E}[\bar{X}]| \ge \epsilon) \stackrel{Chebyshev}{\le} \frac{\operatorname{Var}(\bar{X})}{\epsilon^2} \le \frac{\operatorname{Var}(\sum\limits_{i=1}^n X_i)}{n^2\epsilon^2} \le \frac{n \sum\limits_{i=1}^n \operatorname{Var}(X_i)}{n^2\epsilon^2} \le \frac{n^2  \operatorname{Var}(X_1)}{n^2\epsilon^2} = \frac{p(1-p)}{\epsilon^2}$ So, $\frac{p(1-p)}{\epsilon^2}$ is an upper bound. Is my proof true? Thanks!","Let and . Find an upper bound for . Note that random variables are not independent. We know that . So we can use Chebyshev's inequality because So, is an upper bound. Is my proof true? Thanks!","X_1, X_2, \dots, X_n \sim \operatorname{Bernoulli}(p) \bar{X}=\frac{1}{n}\sum\limits_{i=1}^nX_i \mathbb{P}(|\bar{X}-p| > \epsilon) \forall \epsilon > 0 \textbf{What I've tried:} \mathbb{E}[\bar{X}] = \mathbb{E}[X_1] = p \mathbb{P}(|\bar{X}-p| > \epsilon) = \mathbb{P}(|\bar{X}-\mathbb{E}[\bar{X}]| > \epsilon) \le \mathbb{P}(|\bar{X}-\mathbb{E}[\bar{X}]| \ge \epsilon) \stackrel{Chebyshev}{\le} \frac{\operatorname{Var}(\bar{X})}{\epsilon^2} \le \frac{\operatorname{Var}(\sum\limits_{i=1}^n X_i)}{n^2\epsilon^2} \le \frac{n \sum\limits_{i=1}^n \operatorname{Var}(X_i)}{n^2\epsilon^2} \le \frac{n^2  \operatorname{Var}(X_1)}{n^2\epsilon^2} = \frac{p(1-p)}{\epsilon^2} \frac{p(1-p)}{\epsilon^2}","['probability', 'statistics']"
56,Indicators and sampling with/without replacement,Indicators and sampling with/without replacement,,"I was reading the problem in this post: Solving for an expected value from discrete random variables : An urn contains $30$ marbles of which 8 are black, $12$ are red, and $10$ are blue. Randomly, select four marbles without replacement. Let $X$ be the number of black marbles in the sample of four. Compute $E(X)$ . I understand the solution using indicator random variables: We consider that the drawn marbles can be placed in a line, and on doing so let $X_i$ be the indicator that the $i$ -th marble in this line is black.  The probability that a particular marble in the line will be black is: $8/30$ .  Thus $\mathsf E(X_i)=8/30$ for all four marbles. By the Linearity of Expectation then: $E(X) $ $= \sum\limits_{i=1}^4 E(X_i) = \frac{16}{15}$ By the same logic, if we sampled with replacement, we should get the same answer. To me this is unintuitive. For instance, if we only had two black balls and we ask the same problem, wouldn't the two $E(X)$ still be the same? If we are sampling without replacement shouldn't the fact that sampling $3$ or $4$ black balls being impossible make this value different from where you sample with replacement (and it is possible to sample $3$ or $4$ balls)? Can someone give me some intuition of why this is reasonable? Much appreciated!","I was reading the problem in this post: Solving for an expected value from discrete random variables : An urn contains marbles of which 8 are black, are red, and are blue. Randomly, select four marbles without replacement. Let be the number of black marbles in the sample of four. Compute . I understand the solution using indicator random variables: We consider that the drawn marbles can be placed in a line, and on doing so let be the indicator that the -th marble in this line is black.  The probability that a particular marble in the line will be black is: .  Thus for all four marbles. By the Linearity of Expectation then: By the same logic, if we sampled with replacement, we should get the same answer. To me this is unintuitive. For instance, if we only had two black balls and we ask the same problem, wouldn't the two still be the same? If we are sampling without replacement shouldn't the fact that sampling or black balls being impossible make this value different from where you sample with replacement (and it is possible to sample or balls)? Can someone give me some intuition of why this is reasonable? Much appreciated!",30 12 10 X E(X) X_i i 8/30 \mathsf E(X_i)=8/30 E(X)  = \sum\limits_{i=1}^4 E(X_i) = \frac{16}{15} E(X) 3 4 3 4,"['probability', 'statistics']"
57,Why is $E[X^{2}] \ge E[X]^{2}$?,Why is ?,E[X^{2}] \ge E[X]^{2},"I was trying to prove that $E[X^{2}] \ge E[X]^{2} \quad \mathbf{(0)}$ . Where $E[X]$ is the expected value of a random variable, $X$ , i.e., $E[X] = \sum_{x}x p_{X}(x)$ Now, I'm not asking how to prove $\mathbf{(0)}$ , I know the method using variance etc. I'm asking is why is $\mathbf{(3)}$ true? (In other words, how to prove this continuing from $\mathbf{(3)}$ . $$\begin{align*} E[X]^{2} \qquad & \longleftrightarrow \qquad ( \ \sum_{x}x \ p_{X}(x) \ )^{2} \\ & \longleftrightarrow \qquad ( \ x_{1} \ p_{X}(x_{1}) + x_{2} \ p_{X}(x_{2}) + \dots + x_{n} \ p_{X}(x_{n}) \ )^{2} \\ & \longleftrightarrow \qquad \ x_{1}^{2} \ p_{X}(x_{1})^{2} + x_{2}^{2} \ p_{X}(x_{2})^{2} + \dots + x_{n}^{2} \ p_{X}(x_{n})^{2} + \dots + 2( \ x_{i}x_{j} \ p_{X}(x_{i}) \ p_{X}(x_{j}) ) + \dots \quad \mathbf{(1)} \\  \textrm{And likewise, } \\\\ E[X^{2}] \qquad & \longleftrightarrow \qquad \sum_{x}x^{2} \ p_{X}(x) \\ & \longleftrightarrow \qquad x_{1}^{2} \ p_{X}(x_{1}) + x_{2}^{2} \ p_{X}(x_{2})+ \dots + x_{n}^{2} \ p_{X}(x_{n}) \quad \mathbf{(2)}\\ \textrm{Now, why is:  } \\ \end{align*} \\ x_{1}^{2} \ p_{X}(x_{1}) + x_{2}^{2} \ p_{X}(x_{2})+ \dots + x_{n}^{2} \ p_{X}(x_{n}) \ge \ x_{1}^{2} \ p_{X}(x_{1})^{2} + x_{2}^{2} \ p_{X}(x_{2})^{2} + \dots + x_{n}^{2} \ p_{X}(x_{n})^{2} + \dots + 2( \ x_{i}x_{j} \ p_{X}(x_{i}) \ p_{X}(x_{j}) ) + \dots \qquad \mathbf{(3)}\\ $$ $ \ \ \quad$ i.e., why is, $\mathbf{(1)} \ge \mathbf{(2)}$","I was trying to prove that . Where is the expected value of a random variable, , i.e., Now, I'm not asking how to prove , I know the method using variance etc. I'm asking is why is true? (In other words, how to prove this continuing from . i.e., why is,","E[X^{2}] \ge E[X]^{2} \quad \mathbf{(0)} E[X] X E[X] = \sum_{x}x p_{X}(x) \mathbf{(0)} \mathbf{(3)} \mathbf{(3)} \begin{align*}
E[X]^{2} \qquad & \longleftrightarrow \qquad ( \ \sum_{x}x \ p_{X}(x) \ )^{2} \\
& \longleftrightarrow \qquad ( \ x_{1} \ p_{X}(x_{1}) + x_{2} \ p_{X}(x_{2}) + \dots + x_{n} \ p_{X}(x_{n}) \ )^{2} \\
& \longleftrightarrow \qquad \ x_{1}^{2} \ p_{X}(x_{1})^{2} + x_{2}^{2} \ p_{X}(x_{2})^{2} + \dots + x_{n}^{2} \ p_{X}(x_{n})^{2} + \dots + 2( \ x_{i}x_{j} \ p_{X}(x_{i}) \ p_{X}(x_{j}) ) + \dots \quad \mathbf{(1)} \\ 
\textrm{And likewise, } \\\\
E[X^{2}] \qquad & \longleftrightarrow \qquad \sum_{x}x^{2} \ p_{X}(x) \\
& \longleftrightarrow \qquad x_{1}^{2} \ p_{X}(x_{1}) + x_{2}^{2} \ p_{X}(x_{2})+ \dots + x_{n}^{2} \ p_{X}(x_{n}) \quad \mathbf{(2)}\\
\textrm{Now, why is:  } \\
\end{align*} \\
x_{1}^{2} \ p_{X}(x_{1}) + x_{2}^{2} \ p_{X}(x_{2})+ \dots + x_{n}^{2} \ p_{X}(x_{n}) \ge \ x_{1}^{2} \ p_{X}(x_{1})^{2} + x_{2}^{2} \ p_{X}(x_{2})^{2} + \dots + x_{n}^{2} \ p_{X}(x_{n})^{2} + \dots + 2( \ x_{i}x_{j} \ p_{X}(x_{i}) \ p_{X}(x_{j}) ) + \dots \qquad \mathbf{(3)}\\
  \ \ \quad \mathbf{(1)} \ge \mathbf{(2)}","['probability', 'statistics', 'summation', 'proof-explanation', 'expected-value']"
58,What is $\mathbb{1}$ with a subscript? [duplicate],What is  with a subscript? [duplicate],\mathbb{1},"This question already has an answer here : meaning of subscript notation $\ 1_{a=a'}$ (1 answer) Closed 1 year ago . In my textbook it's estimating $\mu = P(X > 2)$ with monte carlo estimation, and I'm confused about the line $\mu = P(X > 2) = E(\mathbb{1}_{\{X>2\}})$ . What would the $\mathbb{1}_{\{X>2\}}$ mean ? It's used earlier as a remark ""Let $A$ be a proper subset of $\mathbb{R}^d$ . If $g(x) = \mathbb{1}_A(x)$ , then $E(g(X)) = E(\mathbb{1}_A(X)) = 0 \times P(\mathbb{1}_A(x) = 0) + 1 \times P(\mathbb{1}_A(x) = 1) $","This question already has an answer here : meaning of subscript notation $\ 1_{a=a'}$ (1 answer) Closed 1 year ago . In my textbook it's estimating with monte carlo estimation, and I'm confused about the line . What would the mean ? It's used earlier as a remark ""Let be a proper subset of . If , then",\mu = P(X > 2) \mu = P(X > 2) = E(\mathbb{1}_{\{X>2\}}) \mathbb{1}_{\{X>2\}} A \mathbb{R}^d g(x) = \mathbb{1}_A(x) E(g(X)) = E(\mathbb{1}_A(X)) = 0 \times P(\mathbb{1}_A(x) = 0) + 1 \times P(\mathbb{1}_A(x) = 1) ,"['statistics', 'notation', 'monte-carlo']"
59,"Hypothesis test, finding p-value","Hypothesis test, finding p-value",,"A coin has a probability of getting tails of $\theta$ unknown. We would like to do the following hypothesis test over the value of $\theta$ : $$\begin{cases}H_0 : \theta=0.5 \\ H_1 : \theta > 0.5 \end{cases}$$ Suppose we flipped the coin 5 times and got 4 tails. Calculate the p-value. Let $X$ be a random variable such that it takes $1$ if we got tails, and $0$ if heads (a Bernoulli distribution with unknown parameter $\theta$ ) and $X_1, \dots, X_5 $ a simple random sample of $X$ . Then the p-value is going to be $P_{H_0}(T\geq t)$ (assuming $H_0$ is true), with $T=\overline{X}_n$ and $t=\frac{4}{5}=0.8$ . So, $P_{H_0}(T\geq t)=P_{H_0}(\overline{X}_n\geq0.8)=1-P_{H_0}(\overline{X}_n <0.8)$ By the central limit theorem, $\overline{X}_n \sim N\left(0.5,\frac{(0.5)(1-0.5)}{5} \right)=N(0.5, 0.05)$ (approximately). So, $p-value=1-\phi \left(\frac{0.8-0.5}{0.22} \right)=0.0869$ which is incorrect. Where's my mistake? The correct answer is 0.187","A coin has a probability of getting tails of unknown. We would like to do the following hypothesis test over the value of : Suppose we flipped the coin 5 times and got 4 tails. Calculate the p-value. Let be a random variable such that it takes if we got tails, and if heads (a Bernoulli distribution with unknown parameter ) and a simple random sample of . Then the p-value is going to be (assuming is true), with and . So, By the central limit theorem, (approximately). So, which is incorrect. Where's my mistake? The correct answer is 0.187","\theta \theta \begin{cases}H_0 : \theta=0.5 \\ H_1 : \theta > 0.5 \end{cases} X 1 0 \theta X_1, \dots, X_5  X P_{H_0}(T\geq t) H_0 T=\overline{X}_n t=\frac{4}{5}=0.8 P_{H_0}(T\geq t)=P_{H_0}(\overline{X}_n\geq0.8)=1-P_{H_0}(\overline{X}_n <0.8) \overline{X}_n \sim N\left(0.5,\frac{(0.5)(1-0.5)}{5} \right)=N(0.5, 0.05) p-value=1-\phi \left(\frac{0.8-0.5}{0.22} \right)=0.0869","['statistics', 'hypothesis-testing', 'central-limit-theorem', 'probability-limit-theorems', 'p-value']"
60,Correlation of $X^3$ and $Y$,Correlation of  and,X^3 Y,Suppose that $X$ and $Y$ are two uncorrelated random variables and the PDF of them are both even. Can we expect that $X^3$ and $Y$ are also uncorrelated? Thanks.,Suppose that and are two uncorrelated random variables and the PDF of them are both even. Can we expect that and are also uncorrelated? Thanks.,X Y X^3 Y,"['probability', 'statistics', 'correlation']"
61,Can mode lie between mean and median?,Can mode lie between mean and median?,,The distribution is left-skewed if mean<median<mode. The distribution is right-skewed if mean>median>mode. Can mode lie between mean and median?,The distribution is left-skewed if mean<median<mode. The distribution is right-skewed if mean>median>mode. Can mode lie between mean and median?,,['statistics']
62,What exactly am I doing wrong in this problem?,What exactly am I doing wrong in this problem?,,"There are two local factories that produce microwaves. Each microwave produced at factory A is defective with probability $.05$ , whereas each one produced at factory B is defective with probability $.01$ . Suppose you purchase two microwaves that were produced at the same factory, which is equally likely to have been either factory A or factory B. If the first microwave that you check is defective, what is the conditional probability that the other one is also defective? Ok so below is my attempts to this problem. Obviously what I got is wrong, but I'm confused on what I did that was wrong. I'm trying to figure out what is wrong with my understanding. Note: I didn't know how to include fancy symbols like I see on other post so I just installed a picture instead. My work:","There are two local factories that produce microwaves. Each microwave produced at factory A is defective with probability , whereas each one produced at factory B is defective with probability . Suppose you purchase two microwaves that were produced at the same factory, which is equally likely to have been either factory A or factory B. If the first microwave that you check is defective, what is the conditional probability that the other one is also defective? Ok so below is my attempts to this problem. Obviously what I got is wrong, but I'm confused on what I did that was wrong. I'm trying to figure out what is wrong with my understanding. Note: I didn't know how to include fancy symbols like I see on other post so I just installed a picture instead. My work:",.05 .01,['statistics']
63,Problem in obtaining expected value,Problem in obtaining expected value,,"Suppose that we have the following probability density function \begin{equation} f(x)=\frac{\alpha x_m^{\alpha}}{x^{\alpha+1}}, \quad x>x_m \end{equation} and its cumulative density function \begin{equation} F(x)=1-\left(\frac{x_m}{x}\right)^{\alpha}, \quad x>x_m \end{equation} I calculate expected value of $X$ in two ways. First way: \begin{eqnarray} \int_{x_m}^{\infty}xf(x)dx&=&\int_{x_m}^{\infty}\frac{\alpha x_m^{\alpha}}{x^{\alpha}}dx\\ &=&\frac{\alpha x_m}{\alpha-1},\quad \alpha>1 \end{eqnarray} Second way: \begin{eqnarray} \int_{x_m}^{\infty}(1-F(x))dx&=&\int_{x_m}^{\infty} \left(\frac{x_m}{x}\right)^{\alpha} dx\\ &=&\frac{x_m}{\alpha-1},\quad \alpha>1 \end{eqnarray} why the second way gives an incorrect answer? I do not know where I am doing wrong.",Suppose that we have the following probability density function and its cumulative density function I calculate expected value of in two ways. First way: Second way: why the second way gives an incorrect answer? I do not know where I am doing wrong.,"\begin{equation}
f(x)=\frac{\alpha x_m^{\alpha}}{x^{\alpha+1}}, \quad x>x_m
\end{equation} \begin{equation}
F(x)=1-\left(\frac{x_m}{x}\right)^{\alpha}, \quad x>x_m
\end{equation} X \begin{eqnarray}
\int_{x_m}^{\infty}xf(x)dx&=&\int_{x_m}^{\infty}\frac{\alpha x_m^{\alpha}}{x^{\alpha}}dx\\
&=&\frac{\alpha x_m}{\alpha-1},\quad \alpha>1
\end{eqnarray} \begin{eqnarray}
\int_{x_m}^{\infty}(1-F(x))dx&=&\int_{x_m}^{\infty} \left(\frac{x_m}{x}\right)^{\alpha} dx\\
&=&\frac{x_m}{\alpha-1},\quad \alpha>1
\end{eqnarray}","['integration', 'statistics', 'probability-distributions', 'expected-value']"
64,Meaning of the p-value,Meaning of the p-value,,"Suppos that we have a null-hypothesis $H_0: \ \theta=\theta_0$ . Our alternative hypothesis could be for example $H_1: \ \theta\ne \theta_0$ . We want to test the null-hypothesis so we construct a test-statistic $T$ which has some probability distribution. Based on the data we compute the numerical value of the test statistic to be $t$ . For some reason, we define $p:=2 \mathrm{min}\left\{\mathbb{P}\left(T\ge t\mid H_0  \right),\mathbb{P}(T \le t\mid H_0)\right\}$ and if the p-value is very small, we abandon the null-hypothesis. Could someone please clarify, how does the p-value imply that the null-hypothesis is incorrect? And also in cases when we have $H_1: \ \theta>\theta_0$ or $H_1: \ \theta < \theta_0 $ . I think it would be more convenient to check the probability of having $T\in \left(t-\varepsilon, t+\varepsilon \right)$ assuming that the null-hypothesis holds.","Suppos that we have a null-hypothesis . Our alternative hypothesis could be for example . We want to test the null-hypothesis so we construct a test-statistic which has some probability distribution. Based on the data we compute the numerical value of the test statistic to be . For some reason, we define and if the p-value is very small, we abandon the null-hypothesis. Could someone please clarify, how does the p-value imply that the null-hypothesis is incorrect? And also in cases when we have or . I think it would be more convenient to check the probability of having assuming that the null-hypothesis holds.","H_0: \ \theta=\theta_0 H_1: \ \theta\ne \theta_0 T t p:=2 \mathrm{min}\left\{\mathbb{P}\left(T\ge t\mid H_0  \right),\mathbb{P}(T \le t\mid H_0)\right\} H_1: \ \theta>\theta_0 H_1: \ \theta < \theta_0  T\in \left(t-\varepsilon, t+\varepsilon \right)","['statistics', 'statistical-inference']"
65,Addition law for non mutually exclusive events,Addition law for non mutually exclusive events,,The addition law for non mutually exclusive events is given in my textbook as $P(A \space \text{or} \space B)=P(A \space\cup \space B)= P(A)+P(B)-P(A \space \cap \space B)$ I understand the logic behind this and would be fine if it were written as $P(A \space \text{or} \space B)=P(A)+P(B)-P(A \space \cap \space B)$ however I am fairly certain that in this case it is incorrect to say that $P(A \space \text{or} \space B)=P(A \space\cup \space B)$ Here is a diagram to further elaborate From the diagram would it not be true that $P(A \space \cup \space B)=P(A \space \text{or} \space B) + P(A \space \text{and} \space B)$ ? Is there a mistake in my textbook or am I missing something crucial?,The addition law for non mutually exclusive events is given in my textbook as I understand the logic behind this and would be fine if it were written as however I am fairly certain that in this case it is incorrect to say that Here is a diagram to further elaborate From the diagram would it not be true that ? Is there a mistake in my textbook or am I missing something crucial?,P(A \space \text{or} \space B)=P(A \space\cup \space B)= P(A)+P(B)-P(A \space \cap \space B) P(A \space \text{or} \space B)=P(A)+P(B)-P(A \space \cap \space B) P(A \space \text{or} \space B)=P(A \space\cup \space B) P(A \space \cup \space B)=P(A \space \text{or} \space B) + P(A \space \text{and} \space B),"['probability', 'statistics', 'elementary-set-theory']"
66,Create Gaussian distribution from random number generator output,Create Gaussian distribution from random number generator output,,I have a random number generator with output between -1 and +1 having a uniform distribution. Is there a simple mathematical formula that would convert this into an estimated Gaussian distribution (around 0)?,I have a random number generator with output between -1 and +1 having a uniform distribution. Is there a simple mathematical formula that would convert this into an estimated Gaussian distribution (around 0)?,,"['statistics', 'probability-distributions', 'gaussian']"
67,The Variance Rule of $V(cX) = c^2V(X)$,The Variance Rule of,V(cX) = c^2V(X),"As a statistics major, I learned a while back that the $V(cX) = c^2 V(X)$ , where $V(X)$ is the variance of $X$ . However, I never quite understood why that was the case. Consider this: We have an event $X$ such that each event is independent of any previous events. Take for instance, a roll of copper wire. We know that the mean length is $150 \text{m}$ and the standard deviation is $4\text{m}$ . If we want to find the variance of $5$ rolls of copper wire, we could write this as $V(5X) = 25V(X) = 400\text{m}^2$ . However, an alternative way to write the problem is doing $V(X + X + X + X + X) = V(X) + \ ... \ + V(X)$ - as they are all independent. Thus, we can simplify to $5V(X)$ and get $80\text{m}^2$ . This second way seems like it should be the same as the first way, but they produce different answers. Can anyone explain this? I was helping a friend out with a similar problem and the second way actually produces the correct answer, so can anyone explain why this is the case?","As a statistics major, I learned a while back that the , where is the variance of . However, I never quite understood why that was the case. Consider this: We have an event such that each event is independent of any previous events. Take for instance, a roll of copper wire. We know that the mean length is and the standard deviation is . If we want to find the variance of rolls of copper wire, we could write this as . However, an alternative way to write the problem is doing - as they are all independent. Thus, we can simplify to and get . This second way seems like it should be the same as the first way, but they produce different answers. Can anyone explain this? I was helping a friend out with a similar problem and the second way actually produces the correct answer, so can anyone explain why this is the case?",V(cX) = c^2 V(X) V(X) X X 150 \text{m} 4\text{m} 5 V(5X) = 25V(X) = 400\text{m}^2 V(X + X + X + X + X) = V(X) + \ ... \ + V(X) 5V(X) 80\text{m}^2,"['probability', 'statistics', 'variance']"
68,Uniform Distributions Ratio [duplicate],Uniform Distributions Ratio [duplicate],,"This question already has answers here : pdf of a quotient of uniform random variables (2 answers) Closed 3 years ago . Let $\xi$ is $U(0, 1)$ , $\nu$ is $U(0, 1)$ . What type of distribution is $g = \frac{\xi}{\nu}$ ? I have build logarithm of $g$ , here is the plot but it seems like it is not normal distribution: Distribution Hist","This question already has answers here : pdf of a quotient of uniform random variables (2 answers) Closed 3 years ago . Let is , is . What type of distribution is ? I have build logarithm of , here is the plot but it seems like it is not normal distribution: Distribution Hist","\xi U(0, 1) \nu U(0, 1) g = \frac{\xi}{\nu} g","['probability', 'statistics', 'probability-distributions', 'uniform-distribution']"
69,Stationary Distribution of a Stochastic Processes,Stationary Distribution of a Stochastic Processes,,"A Markov Chain with states 0,1,... has transition probabilities $$p_{jk}=e^{-a} \sum_{r=0}^k \left( \begin{matrix} j \\ r \end{matrix} \right) p^r (1-p)^{j-r} a^{k-r} / (k-r)!$$ Show that the limiting distribution $\{ v_k\}$ is Poisson with parameter $a/(1-p)$ . My attempt was using: $$ \sum_{k=0}^\infty p_{jk} = 1 $$ and $$ v_k = \sum_{j=0}^\infty v_j p_{jk} $$ But I am really out of order on how to simplify $$ v_k = \sum_{j=0}^\infty v_j e^{-a} \sum_{r=0}^k \left( \begin{matrix} j \\ r \end{matrix} \right) p^r (1-p)^{j-r} a^{k-r} / (k-r)! $$","A Markov Chain with states 0,1,... has transition probabilities Show that the limiting distribution is Poisson with parameter . My attempt was using: and But I am really out of order on how to simplify",p_{jk}=e^{-a} \sum_{r=0}^k \left( \begin{matrix} j \\ r \end{matrix} \right) p^r (1-p)^{j-r} a^{k-r} / (k-r)! \{ v_k\} a/(1-p)  \sum_{k=0}^\infty p_{jk} = 1   v_k = \sum_{j=0}^\infty v_j p_{jk}   v_k = \sum_{j=0}^\infty v_j e^{-a} \sum_{r=0}^k \left( \begin{matrix} j \\ r \end{matrix} \right) p^r (1-p)^{j-r} a^{k-r} / (k-r)! ,"['statistics', 'stochastic-processes', 'markov-chains', 'markov-process', 'stationary-processes']"
70,Hypothesis Testing show LRT is Chi-Square test,Hypothesis Testing show LRT is Chi-Square test,,"Let $(X_1,...,X_n)$ be a random sample with PDF $f(x;\theta) = \frac{x}{\theta}\exp(-x^2/(2\theta)), \theta > 0$ I want to show that the likelihood ratio test of $H_0 : \theta \le \theta_0$ against $H_1 : \theta > \theta_0$ where $\theta_0>0$ is given is a Chi-square test This gives that the the likelihood function $\displaystyle L(\theta) = \frac{\prod x_i}{\theta^n}\exp(-\sum x_i^2/2\theta)$ I am going to set $t = \prod X_i$ and $s = \sum X_i^2$ . So we get $\displaystyle L(\theta) = \frac{t}{\theta^n}\exp(-s/2\theta)$ . And $\max_{\theta \ge 0 }L(\theta)$ occurs when $\theta = \frac{s}{2n}$ And $\max_{0 \le \theta \le \theta_0} L(\theta) = \begin{cases}    L(\frac{s}{2n})&\text{if }\theta_0 \ge \frac{s}{2n}\\                 L(\theta_0)&\text{else}         \end{cases}$ Now we have $$ \Lambda_{H_0} = \frac{\max_{0 \le \theta \le \theta_0} L(\theta)}{\max_{0 \le \theta } L(\theta)} = \begin{cases} 1 &\text{if } \theta_0 \ge \frac{s}{2n}\\ \bigg (\frac{s}{2n\theta_0}\bigg)^n\exp(n - s/(2\theta_0))&\text{else} \end{cases} $$ Hopefully I have calculated both of those correct, now is where I run into my issue I don't quite see how this is a Chi-square test.","Let be a random sample with PDF I want to show that the likelihood ratio test of against where is given is a Chi-square test This gives that the the likelihood function I am going to set and . So we get . And occurs when And Now we have Hopefully I have calculated both of those correct, now is where I run into my issue I don't quite see how this is a Chi-square test.","(X_1,...,X_n) f(x;\theta) = \frac{x}{\theta}\exp(-x^2/(2\theta)), \theta > 0 H_0 : \theta \le \theta_0 H_1 : \theta > \theta_0 \theta_0>0 \displaystyle L(\theta) = \frac{\prod x_i}{\theta^n}\exp(-\sum x_i^2/2\theta) t = \prod X_i s = \sum X_i^2 \displaystyle L(\theta) = \frac{t}{\theta^n}\exp(-s/2\theta) \max_{\theta \ge 0 }L(\theta) \theta = \frac{s}{2n} \max_{0 \le \theta \le \theta_0} L(\theta) = \begin{cases}
   L(\frac{s}{2n})&\text{if }\theta_0 \ge \frac{s}{2n}\\
                L(\theta_0)&\text{else}
        \end{cases} 
\Lambda_{H_0} = \frac{\max_{0 \le \theta \le \theta_0} L(\theta)}{\max_{0 \le \theta } L(\theta)} = \begin{cases} 1 &\text{if } \theta_0 \ge \frac{s}{2n}\\ \bigg (\frac{s}{2n\theta_0}\bigg)^n\exp(n - s/(2\theta_0))&\text{else}
\end{cases}
","['statistics', 'probability-distributions', 'statistical-inference', 'hypothesis-testing', 'maximum-likelihood']"
71,"if a scatter plot is above a given equation, is it a bad fit","if a scatter plot is above a given equation, is it a bad fit",,"So, a friend of mine asked for help with a question concerning scatter plots. She graphed it out and looked like To me, it looked like a good fit. However, other friends said that it was wasn't a good fit because all the data is above the equation and said ""you want the data to be evenly spread above and below the line"". It has been a while since I've done scatter plots, but I want to know the answer to my dumb question: If all the given data is above a given model but relatively close to the given model, is it still a bad fit because the data isn't spread evenly above and below the data? Thank you so much! It's just a dumb question I have and I'm just curious as I haven't done scatter plots in a very long time :)","So, a friend of mine asked for help with a question concerning scatter plots. She graphed it out and looked like To me, it looked like a good fit. However, other friends said that it was wasn't a good fit because all the data is above the equation and said ""you want the data to be evenly spread above and below the line"". It has been a while since I've done scatter plots, but I want to know the answer to my dumb question: If all the given data is above a given model but relatively close to the given model, is it still a bad fit because the data isn't spread evenly above and below the data? Thank you so much! It's just a dumb question I have and I'm just curious as I haven't done scatter plots in a very long time :)",,['statistics']
72,How many distinct $6$ digit numbers are there in which all of the digits $1$ to $5$ appear?,How many distinct  digit numbers are there in which all of the digits  to  appear?,6 1 5,"For part (i), I think it's just $6!$ . (ii), I think if we treat $\texttt{123}$ as a block, then we should have 4 slots intead of 6 slots now, so the answer should be $4!$ . (iii) $\frac{6!}{2}$ - this should also be correct. (iv) -not sure what do to- need help and explanation. I did some programming and checked one by one, and if my code is correct, the answer is 5280 ?","For part (i), I think it's just . (ii), I think if we treat as a block, then we should have 4 slots intead of 6 slots now, so the answer should be . (iii) - this should also be correct. (iv) -not sure what do to- need help and explanation. I did some programming and checked one by one, and if my code is correct, the answer is 5280 ?",6! \texttt{123} 4! \frac{6!}{2},"['combinatorics', 'statistics', 'permutations', 'combinations']"
73,"If $X_n$ and $Y_n$ are independent does $(X_n,Y_n)\overset{d}{\rightarrow}(X,Y)$?",If  and  are independent does ?,"X_n Y_n (X_n,Y_n)\overset{d}{\rightarrow}(X,Y)","More formally: If $X_n\overset{d}{\rightarrow}X$ and $Y_n\overset{d}{\rightarrow}Y$ and also $X_i$ and $Y_j$ are independent for all i,j; does $(X_n,Y_n)\overset{d}{\rightarrow}(X,Y)$ ? I am aware of the Cramer-Wold theorem to prove asymptotic convergence of vector of random variables but I can't quite figure out how to apply it here. (To be honest I don't even know if the statement is true but it feels like it should be).","More formally: If and and also and are independent for all i,j; does ? I am aware of the Cramer-Wold theorem to prove asymptotic convergence of vector of random variables but I can't quite figure out how to apply it here. (To be honest I don't even know if the statement is true but it feels like it should be).","X_n\overset{d}{\rightarrow}X Y_n\overset{d}{\rightarrow}Y X_i Y_j (X_n,Y_n)\overset{d}{\rightarrow}(X,Y)","['probability', 'statistics', 'random']"
74,"Underflow while evaluating softmax, despite using exp-normalize","Underflow while evaluating softmax, despite using exp-normalize",,"I have a very simple linear classifier that uses softmax (with exp-normalize trick) for the output: h = self.A.dot(x) z = self.B.dot(h) nz = z - max(z) e = np.exp(nz) s = np.sum(e) p = e / s loss = -np.log(p[k]) I understand that softmax is given by: $\frac{e^{Z_i}}{\sum_{j=0}^{n} e^{z_j}}$ For numerical stability, the exp-normalize trick is used: $\frac{e^{Z_i} - max(Z)}{\sum_{j=0}^{n} e^{z_j} - max(Z)}$ I believe that I understand the motivation for this, and how it eliminates underflow/overflow for the exponentiation. The problem is, that in some cases, some elements of the numerator are very very small. Dividing this element by anything greater than 1.0 results in underflow, and I am not sure how to handle this. For example, this is the specific case I am debugging ( I've truncated most of the numbers to two decimal places for readability ): z = [10869.44 , 10837.85, 10851.28, 10136.48] nz =  [0., -31.58, -18.15, -732.95] e = [1.0, 1.91e-014, 1.30e-008, 4.80e-319] s = 1.000000013039 Dividing the last element of e , ( 4.80e-319 ) by s results in underflow. I've looked at many questions on SE and lots of blogs that talk about the exp-normalize trick, but none of them seem to address how to achieve numerical stability during this division.","I have a very simple linear classifier that uses softmax (with exp-normalize trick) for the output: h = self.A.dot(x) z = self.B.dot(h) nz = z - max(z) e = np.exp(nz) s = np.sum(e) p = e / s loss = -np.log(p[k]) I understand that softmax is given by: For numerical stability, the exp-normalize trick is used: I believe that I understand the motivation for this, and how it eliminates underflow/overflow for the exponentiation. The problem is, that in some cases, some elements of the numerator are very very small. Dividing this element by anything greater than 1.0 results in underflow, and I am not sure how to handle this. For example, this is the specific case I am debugging ( I've truncated most of the numbers to two decimal places for readability ): z = [10869.44 , 10837.85, 10851.28, 10136.48] nz =  [0., -31.58, -18.15, -732.95] e = [1.0, 1.91e-014, 1.30e-008, 4.80e-319] s = 1.000000013039 Dividing the last element of e , ( 4.80e-319 ) by s results in underflow. I've looked at many questions on SE and lots of blogs that talk about the exp-normalize trick, but none of them seem to address how to achieve numerical stability during this division.",\frac{e^{Z_i}}{\sum_{j=0}^{n} e^{z_j}} \frac{e^{Z_i} - max(Z)}{\sum_{j=0}^{n} e^{z_j} - max(Z)},"['statistics', 'numerical-methods', 'computer-science', 'numerical-linear-algebra', 'machine-learning']"
75,Example of a maximum likelihood estimator that is not a sufficient statistic,Example of a maximum likelihood estimator that is not a sufficient statistic,,"I am currently researching on providing some bounds on estimation using some information theoretic tools (I won't expend on that here for now, I may make a post about it later) and turns out that given a phenomenon $X$ , an observation $Y$ , then $\hat{x}(Y)$ , the maximum likelihood estimator of $X$ based on $Y$ , may apparently not be a sufficient statistic and this is a something I would like to study, the answer to this post states that such an example exists when $Y$ consists of samples that are not i.i.d but fails to provide such an example and I haven't found anything about it. Have anyone seen something of the sort ?","I am currently researching on providing some bounds on estimation using some information theoretic tools (I won't expend on that here for now, I may make a post about it later) and turns out that given a phenomenon , an observation , then , the maximum likelihood estimator of based on , may apparently not be a sufficient statistic and this is a something I would like to study, the answer to this post states that such an example exists when consists of samples that are not i.i.d but fails to provide such an example and I haven't found anything about it. Have anyone seen something of the sort ?",X Y \hat{x}(Y) X Y Y,"['statistics', 'estimation', 'maximum-likelihood', 'sufficient-statistics']"
76,"Proving if $X$ is a random variable and $f$ is a continuous function, then $f(X)$ is a random variable","Proving if  is a random variable and  is a continuous function, then  is a random variable",X f f(X),"I'm reading ""Fundamental of Mathematical Statistics"" by Gupta and Kapoor and the authors make the claim that ""if $X$ is a random variable and $f$ is a continuous function, then $f(X)$ is a random variable"". The proof has been skipped as it was beyond the scope of the textbook. However, here's my question: There's not much information about given about $f$, so I assume $f$ is a real valued function on $\mathbb{R}$. So clearly the composition $f(X)$ is also a random variable. The hypothesis that $f$ is continuous is never used. So, does it mean that $f$ does not have be continuous? Or am I wrong somewhere?","I'm reading ""Fundamental of Mathematical Statistics"" by Gupta and Kapoor and the authors make the claim that ""if $X$ is a random variable and $f$ is a continuous function, then $f(X)$ is a random variable"". The proof has been skipped as it was beyond the scope of the textbook. However, here's my question: There's not much information about given about $f$, so I assume $f$ is a real valued function on $\mathbb{R}$. So clearly the composition $f(X)$ is also a random variable. The hypothesis that $f$ is continuous is never used. So, does it mean that $f$ does not have be continuous? Or am I wrong somewhere?",,['statistics']
77,Maximum Likelihood Estimator for Poisson Distribution,Maximum Likelihood Estimator for Poisson Distribution,,"Studying for my upcoming exams I came upon this weird MLE exercise : Let the random variable $X$ follow the Poisson Distribution with unknown parameter $\theta >0$. In $50$ observations of $X$, you only know that $20$ of them are zero. Find the Maximum Likelihood Estimator of $\theta$ using only this fact. How would one proceed to finding the MLE using the fact that you have $20$ zero observations ? I have never came upon such a problem of MLE.","Studying for my upcoming exams I came upon this weird MLE exercise : Let the random variable $X$ follow the Poisson Distribution with unknown parameter $\theta >0$. In $50$ observations of $X$, you only know that $20$ of them are zero. Find the Maximum Likelihood Estimator of $\theta$ using only this fact. How would one proceed to finding the MLE using the fact that you have $20$ zero observations ? I have never came upon such a problem of MLE.",,"['probability', 'statistics', 'probability-distributions', 'poisson-distribution', 'maximum-likelihood']"
78,Determine the type of the correlation,Determine the type of the correlation,,"If the equation of the regression line of y on x is  $$y=3-x$$ Then the correlation between x and y is // (inverse , perfect inverse )?  Does the coeffecient of x means the correlation in perfect as it equals -1 ?.","If the equation of the regression line of y on x is  $$y=3-x$$ Then the correlation between x and y is // (inverse , perfect inverse )?  Does the coeffecient of x means the correlation in perfect as it equals -1 ?.",,['statistics']
79,Unbiased estimator for $\theta$,Unbiased estimator for,\theta,"Exercise : Let $X_1, \dots, X_n$ be a random sample $(n>1)$ from the distribution with pdf $f(x) = \theta x^{-2}, \; \; 0 < \theta \leq x < \infty$ , where $\theta$ an unknown parameter. Find the Maximum Likelihood Estimator $\hat{\theta}$ of $\theta$ and determine if it's an unbiased estimator for the parameter $\theta$ . Attempt : The likelihood function is : $$L(x;\theta) = \prod_{i=1}^n \theta x^{-2} \mathbb{I}_{[\theta, + \infty)}(x_i) = \theta^n \mathbb{I}_{[\theta, + \infty)}(\min x_i)$$ and thus the MLE is : $\hat{\theta} = \min x_i$ . Now, in order to determine if it's an unbiased estimator for $\theta$ , I have to find : $$\mathbb{E} [\min x_i |\theta] $$ and determine whether it's equal to $\theta$ or not. How does one proceed with calculating $\mathbb{E} [\min x_i |\theta] $ ? Or is there another way of determining if $\hat{\theta}$ is an unbiased estimator for $\theta$ ?","Exercise : Let be a random sample from the distribution with pdf , where an unknown parameter. Find the Maximum Likelihood Estimator of and determine if it's an unbiased estimator for the parameter . Attempt : The likelihood function is : and thus the MLE is : . Now, in order to determine if it's an unbiased estimator for , I have to find : and determine whether it's equal to or not. How does one proceed with calculating ? Or is there another way of determining if is an unbiased estimator for ?","X_1, \dots, X_n (n>1) f(x) = \theta x^{-2}, \; \; 0 < \theta \leq x < \infty \theta \hat{\theta} \theta \theta L(x;\theta) = \prod_{i=1}^n \theta x^{-2} \mathbb{I}_{[\theta, + \infty)}(x_i) = \theta^n \mathbb{I}_{[\theta, + \infty)}(\min x_i) \hat{\theta} = \min x_i \theta \mathbb{E} [\min x_i |\theta]  \theta \mathbb{E} [\min x_i |\theta]  \hat{\theta} \theta","['probability', 'statistics', 'probability-distributions', 'expected-value', 'maximum-likelihood']"
80,"Showing inequality: $pe^{x(1-p)}+(1-p)e^{-xp} \leq e^{x^2(3/4)p}$ for $0 \leq p \leq 1/2, 0 \leq x \leq 1$?",Showing inequality:  for ?,"pe^{x(1-p)}+(1-p)e^{-xp} \leq e^{x^2(3/4)p} 0 \leq p \leq 1/2, 0 \leq x \leq 1","How can I show that $$pe^{x(1-p)}+(1-p)e^{-xp} \leq e^{x^2(3/4)p}$$ for $0 \leq p \leq 1/2, 0 \leq x \leq 1$? I've been stuck on this for a long time; I tried expanding out the taylor series on either side, and I tried using convexity, but neither method seems to help. I was able to get the inequality down to $\leq  e^{x^2(1-p)p}$ on the right side using the method here but I couldn't see a way to further tighten the upper bound.","How can I show that $$pe^{x(1-p)}+(1-p)e^{-xp} \leq e^{x^2(3/4)p}$$ for $0 \leq p \leq 1/2, 0 \leq x \leq 1$? I've been stuck on this for a long time; I tried expanding out the taylor series on either side, and I tried using convexity, but neither method seems to help. I was able to get the inequality down to $\leq  e^{x^2(1-p)p}$ on the right side using the method here but I couldn't see a way to further tighten the upper bound.",,"['statistics', 'inequality', 'exponential-function', 'moment-generating-functions']"
81,"How to find UMVUE of $\theta^k$ when $x_1, \ldots, x_n$ is a sample from Bernoulli$(\theta)$?",How to find UMVUE of  when  is a sample from Bernoulli?,"\theta^k x_1, \ldots, x_n (\theta)","Let $x_1, x_2, \ldots, x_n$ be a random sample from the Bernoulli ( $\theta$ ). The question is to find the UMVUE of $\theta^k$ . I know the $\sum_1^nx_i$ is the complete sufficient statistics for $\theta$ . Is $\left(\frac{\sum_1^nx_i}{n}\right)^k$ the estimator or any other possible estimator? Could someone just help me?",Let be a random sample from the Bernoulli ( ). The question is to find the UMVUE of . I know the is the complete sufficient statistics for . Is the estimator or any other possible estimator? Could someone just help me?,"x_1, x_2, \ldots, x_n \theta \theta^k \sum_1^nx_i \theta \left(\frac{\sum_1^nx_i}{n}\right)^k","['probability', 'statistics', 'probability-distributions', 'statistical-inference', 'parameter-estimation']"
82,Roulette probability based on last 10 rolls,Roulette probability based on last 10 rolls,,"Let me preface by saying I'm not good at math. This question is purely from a mathematical standpoint. Thanks very much in advance! Ok, so lets say I want to calculate the odds of a roulette wheel landing on red or black based on the last $10$ rolls. I realize that every roll is independent of each other and each roll has a $50\%$ chance of landing on red or black (assuming no $0$). But how could I calculate the probability of rolling a red or black on the $11$th roll if I know the previous $10$ rolls? For example if the last 10 rolls had $5$ reds and $5$ blacks, I'd assume the $11$th roll would be a $50-50$ chance since there were an equal number of reds and blacks for the previous $10$ rolls (please correct me if this isn't correct). What if there were only $1$ red and $9$ blacks in the last $10$ rolls? How would I calculate the probability of getting a red or black on the $11$th roll? I'm assuming there's some kind of formula I could use to calculate this right?","Let me preface by saying I'm not good at math. This question is purely from a mathematical standpoint. Thanks very much in advance! Ok, so lets say I want to calculate the odds of a roulette wheel landing on red or black based on the last $10$ rolls. I realize that every roll is independent of each other and each roll has a $50\%$ chance of landing on red or black (assuming no $0$). But how could I calculate the probability of rolling a red or black on the $11$th roll if I know the previous $10$ rolls? For example if the last 10 rolls had $5$ reds and $5$ blacks, I'd assume the $11$th roll would be a $50-50$ chance since there were an equal number of reds and blacks for the previous $10$ rolls (please correct me if this isn't correct). What if there were only $1$ red and $9$ blacks in the last $10$ rolls? How would I calculate the probability of getting a red or black on the $11$th roll? I'm assuming there's some kind of formula I could use to calculate this right?",,"['probability', 'statistics']"
83,Kullback-Leibler divergence of two exponential distributions with different scale parameters,Kullback-Leibler divergence of two exponential distributions with different scale parameters,,"The question is as follows: ""Calculate the Kullback-Leibler divergence between two exponential distributions with different scale parameters. When is it maximal?"" I have tried something but I come to a wrong conclusion (at least comparing with Wikipedia). Let the KL-divergence between the approximating distribution $p_\theta$ and the ""true"" distribution $p_{\theta_0}$ be defined as $M(\theta) = P_{\theta_0} \log \frac{P_\theta}{P_{\theta_0}}$ The density of an exponential distribution is given by $p_\theta(x) = \theta e^{-\theta x}$ hence for the ""true"" distribution we have $p_{\theta_0}(x) = \theta_0 e^{-\theta_0 x}$ which gives $P_{\theta_0}\log \frac{P_\theta}{P_{\theta_0}} = P_{\theta_0} \log \frac{\theta e^{-\theta x}}{\theta_0 e^{-\theta_0 x}}$ which we can simplify to $P_{\theta_0}\log \frac{P_\theta}{P_{\theta_0}} = P_{\theta_0} \log(\theta) - \log(\theta_0) - (\theta - \theta_0)x$ (This is where I think I might have made a possible mistake) Because $x$ under the true distribution is exponentially distributed with scale parameter $\theta_0$ its mean is given by $1/\theta_0$ and as such we find that the KL-divergence is $M(\theta) = \log(\theta) - \log(\theta_0) - (\theta - \theta_0)\frac{1}{\theta_0} =\log(\theta) - \log(\theta_0) -\frac{\theta}{\theta_0}+1$ However, Wikipedia ( link ) gives the following KL-divergence for two exponential distributions $M(\theta) =\log(\theta) - \log(\theta_0) +\frac{\theta}{\theta_0}-1$ My answer has the signs flipped, where did I make an error?","The question is as follows: ""Calculate the Kullback-Leibler divergence between two exponential distributions with different scale parameters. When is it maximal?"" I have tried something but I come to a wrong conclusion (at least comparing with Wikipedia). Let the KL-divergence between the approximating distribution $p_\theta$ and the ""true"" distribution $p_{\theta_0}$ be defined as $M(\theta) = P_{\theta_0} \log \frac{P_\theta}{P_{\theta_0}}$ The density of an exponential distribution is given by $p_\theta(x) = \theta e^{-\theta x}$ hence for the ""true"" distribution we have $p_{\theta_0}(x) = \theta_0 e^{-\theta_0 x}$ which gives $P_{\theta_0}\log \frac{P_\theta}{P_{\theta_0}} = P_{\theta_0} \log \frac{\theta e^{-\theta x}}{\theta_0 e^{-\theta_0 x}}$ which we can simplify to $P_{\theta_0}\log \frac{P_\theta}{P_{\theta_0}} = P_{\theta_0} \log(\theta) - \log(\theta_0) - (\theta - \theta_0)x$ (This is where I think I might have made a possible mistake) Because $x$ under the true distribution is exponentially distributed with scale parameter $\theta_0$ its mean is given by $1/\theta_0$ and as such we find that the KL-divergence is $M(\theta) = \log(\theta) - \log(\theta_0) - (\theta - \theta_0)\frac{1}{\theta_0} =\log(\theta) - \log(\theta_0) -\frac{\theta}{\theta_0}+1$ However, Wikipedia ( link ) gives the following KL-divergence for two exponential distributions $M(\theta) =\log(\theta) - \log(\theta_0) +\frac{\theta}{\theta_0}-1$ My answer has the signs flipped, where did I make an error?",,['statistics']
84,Sum of uniform and exponential random variables,Sum of uniform and exponential random variables,,"$$U \sim \operatorname{unif}(0,1);X \sim \operatorname{expo}(1) .$$ $U,X$ indep. Find the PDF of $U+X$. Here's my answer, but I find this answer implausible, not sure where I went wrong. \begin{align} F_Y(y) & =P(U+X \leq y) \\ &= \int_{-\infty}^{\infty} P(U+X < y \mid X=x)f_X(x)\,dx \\ &= \int_{-\infty}^{\infty} P(U < y - X\mid X=x)f_X(x)\,dx \\ &= \int_{-\infty}^{\infty} P(U < y - x\mid X=x)f_X(x)\,dx \\ &= \int_{-\infty}^{\infty} P(U < y - x)f_X(x)\,dx \\ &= \int_{-\infty}^{\infty} F_U(y-x)f_X(x)\,dx \\ &= \int_{-\infty}^{\infty} (y-x)f_X(x)\,dx \\ &= \operatorname E_X[y-X] \\  &= y - \operatorname E_X[X] \\ &= y - 1/\lambda \\ &= y - 1/1 \\ &= y - 1 \end{align} $$ f_Y(y) = \frac d {dy} F_Y(y) = 1 $$","$$U \sim \operatorname{unif}(0,1);X \sim \operatorname{expo}(1) .$$ $U,X$ indep. Find the PDF of $U+X$. Here's my answer, but I find this answer implausible, not sure where I went wrong. \begin{align} F_Y(y) & =P(U+X \leq y) \\ &= \int_{-\infty}^{\infty} P(U+X < y \mid X=x)f_X(x)\,dx \\ &= \int_{-\infty}^{\infty} P(U < y - X\mid X=x)f_X(x)\,dx \\ &= \int_{-\infty}^{\infty} P(U < y - x\mid X=x)f_X(x)\,dx \\ &= \int_{-\infty}^{\infty} P(U < y - x)f_X(x)\,dx \\ &= \int_{-\infty}^{\infty} F_U(y-x)f_X(x)\,dx \\ &= \int_{-\infty}^{\infty} (y-x)f_X(x)\,dx \\ &= \operatorname E_X[y-X] \\  &= y - \operatorname E_X[X] \\ &= y - 1/\lambda \\ &= y - 1/1 \\ &= y - 1 \end{align} $$ f_Y(y) = \frac d {dy} F_Y(y) = 1 $$",,"['probability', 'integration', 'statistics']"
85,Interchange of expected value and summation,Interchange of expected value and summation,,Hey guys I'm studying Statistics and I'm currently at unbiased estimators. I'm trying to find the estimators for different problems. My question is : I know that the following formula holds $$E (\sum_{i=0}^n X_{i}) =\sum_{i=0}^n(E( X_{i}))$$ where $X_{i}$ are the possible values of a random vector. I think this is true because of Fubini's theorem but correct me if I am wrong. My question is if the following formula is also true $$E (\sum_{i=0}^n(X_{i}-X)^2) =\sum_{i=0}^n(E( X_{i}-X)^2)$$ where by $X$ I mean the $X=(\sum_{i=0}^n X_{i})/n$. Of course $(X_{i}-X)^2$ isn't a linear equation so I don't know if that means anything. Can you please explain me if both formulas are true and why?,Hey guys I'm studying Statistics and I'm currently at unbiased estimators. I'm trying to find the estimators for different problems. My question is : I know that the following formula holds $$E (\sum_{i=0}^n X_{i}) =\sum_{i=0}^n(E( X_{i}))$$ where $X_{i}$ are the possible values of a random vector. I think this is true because of Fubini's theorem but correct me if I am wrong. My question is if the following formula is also true $$E (\sum_{i=0}^n(X_{i}-X)^2) =\sum_{i=0}^n(E( X_{i}-X)^2)$$ where by $X$ I mean the $X=(\sum_{i=0}^n X_{i})/n$. Of course $(X_{i}-X)^2$ isn't a linear equation so I don't know if that means anything. Can you please explain me if both formulas are true and why?,,"['probability', 'statistics']"
86,a good book for Introduction to Mathematical Statistics,a good book for Introduction to Mathematical Statistics,,"I am trying to read this book (Introduction to Mathematical Statistics by Robert,Joseph, Allen,7th edition) I find it hard to follow. So, can anyone please recommend another book has similar content? My background is Math bachelor level and I will continue my master in Stat  next Fall.  Thank you in advanced.","I am trying to read this book (Introduction to Mathematical Statistics by Robert,Joseph, Allen,7th edition) I find it hard to follow. So, can anyone please recommend another book has similar content? My background is Math bachelor level and I will continue my master in Stat  next Fall.  Thank you in advanced.",,[]
87,Do the mean and variance of a random variable define it completely?,Do the mean and variance of a random variable define it completely?,,"Do the mean and variance of a random variable define it completely? In particular, if $X$ is a random variable, such that $E(X) = \operatorname{Var}(X) = u$, does that imply that $X \sim \operatorname{Poisson}(u)$ ? If so, then a proof that a RV is Poisson would require only to show the above relationship which is very useful. Otherwise, what measures can uniquely define a random variable, or a Poisson Random Variable?","Do the mean and variance of a random variable define it completely? In particular, if $X$ is a random variable, such that $E(X) = \operatorname{Var}(X) = u$, does that imply that $X \sim \operatorname{Poisson}(u)$ ? If so, then a proof that a RV is Poisson would require only to show the above relationship which is very useful. Otherwise, what measures can uniquely define a random variable, or a Poisson Random Variable?",,"['probability', 'statistics', 'probability-distributions']"
88,Given the PDF of $X$ find the PDF of $Y$ using CDF,Given the PDF of  find the PDF of  using CDF,X Y,"Suppose $X$ has PDF   $$f_X(x) = \frac{x}{18}, \quad 0 \le x \le 6.$$   Determine the probability distribution of the random variable $Y = 2X+10$ using the distribution function (CDF) method. Would you kindly tell me if my approach is correct? Approach: $$F_Y(y) = P(Y \leq y) = P(2X+10 \leq y) = P\left(X \leq \frac{y-10} {2}\right)$$ $$ \int^\frac{y-10} {2}_0 \frac{x}{18}\, dx= \frac{(y-10)^2} {144}.$$ I just started learning CDF's. Am I correct on this one?","Suppose $X$ has PDF   $$f_X(x) = \frac{x}{18}, \quad 0 \le x \le 6.$$   Determine the probability distribution of the random variable $Y = 2X+10$ using the distribution function (CDF) method. Would you kindly tell me if my approach is correct? Approach: $$F_Y(y) = P(Y \leq y) = P(2X+10 \leq y) = P\left(X \leq \frac{y-10} {2}\right)$$ $$ \int^\frac{y-10} {2}_0 \frac{x}{18}\, dx= \frac{(y-10)^2} {144}.$$ I just started learning CDF's. Am I correct on this one?",,"['probability', 'statistics', 'probability-distributions', 'random-variables']"
89,Two independent geometric random variables - proof of sum,Two independent geometric random variables - proof of sum,,"If $X$ and $Y$ are independent geometric random variables, $X \sim G(p)$ and $Y \sim G(q)$ then if $Z = X+Y$ I need to show that: $$P[Z=z] = \frac{pq}{p-q}[(1-q)^{z-1}-(1-p)^{z-1}]$$ My attempt: \begin{align} P[Z=z] &= \sum_{k=1}^z P[X=k]P[Y=z-k] && \text{(not sure of my summation limits here)}  \\ &= \sum_{k=1}^z p(1-p)^{k-1} \cdot q(1-q)^{z-k-1} \\ &= \frac{pq}{(1-p)}\cdot \frac{(1-q)^z}{(1-q)}\cdot\sum_{k=1}^z (\frac{1-p}{1-q})^k \\ &= \frac{pq}{(1-p)}\cdot \frac{(1-q)^z}{(1-q)} \cdot \frac{1-(\frac{1-p}{1-q})^k}{1-\frac{1-p}{1-q}} \\ &= \frac{pq}{(1-p)}\cdot \frac{(1-q)^z}{(p-q)} \left[1 -(\frac{1-p}{1-q})^k\right] \\ &= \frac{pq}{p-q}\left[\frac{(1-q)^z}{1-p} - \frac{(1-p)^z}{1-p}\right] \end{align} The result is pretty close to the answer. The only discrepancy is the first expression in the parentheses, $\frac{(1-q)^z}{1-p}$ which should be $\frac{(1-q)^z}{1-q}$ . Could someone please have a look at my working and show me where I have gone wrong? Or perhaps a neater calculation? Thanks! PS I did check similar questions answered here, but couldn't find anything relevant to my problem. Is the sum of two independent geometric random variables with the same success probability a geometric random variable? How to compute the sum of random variables of geometric distribution","If and are independent geometric random variables, and then if I need to show that: My attempt: The result is pretty close to the answer. The only discrepancy is the first expression in the parentheses, which should be . Could someone please have a look at my working and show me where I have gone wrong? Or perhaps a neater calculation? Thanks! PS I did check similar questions answered here, but couldn't find anything relevant to my problem. Is the sum of two independent geometric random variables with the same success probability a geometric random variable? How to compute the sum of random variables of geometric distribution","X Y X \sim G(p) Y \sim G(q) Z = X+Y P[Z=z] = \frac{pq}{p-q}[(1-q)^{z-1}-(1-p)^{z-1}] \begin{align}
P[Z=z] &= \sum_{k=1}^z P[X=k]P[Y=z-k] && \text{(not sure of my summation limits here)}  \\
&= \sum_{k=1}^z p(1-p)^{k-1} \cdot q(1-q)^{z-k-1} \\
&= \frac{pq}{(1-p)}\cdot \frac{(1-q)^z}{(1-q)}\cdot\sum_{k=1}^z (\frac{1-p}{1-q})^k \\
&= \frac{pq}{(1-p)}\cdot \frac{(1-q)^z}{(1-q)} \cdot \frac{1-(\frac{1-p}{1-q})^k}{1-\frac{1-p}{1-q}} \\
&= \frac{pq}{(1-p)}\cdot \frac{(1-q)^z}{(p-q)} \left[1 -(\frac{1-p}{1-q})^k\right] \\
&= \frac{pq}{p-q}\left[\frac{(1-q)^z}{1-p} - \frac{(1-p)^z}{1-p}\right]
\end{align} \frac{(1-q)^z}{1-p} \frac{(1-q)^z}{1-q}","['probability', 'statistics']"
90,Showing consistency of MLE for exponential distribution parameter,Showing consistency of MLE for exponential distribution parameter,,"We have $n$ iid random variables all taken from an $Exponential( \lambda)$ distribution. I have found the MLE of $\lambda$ to be $\frac{n}{\Sigma _{i=1}^{n} X_i}$. However I am struggling to prove that this is a consistent estimator. I have had two ideas as to how to approach this: 1) Through the weak law of large numbers which involves, in this case, the reciprocals of both the estimator and what I'm trying to estimate. 2) Through showing that the expected value of the MLE converges in probability to $\lambda$ and that it's variance converges to $0$ as $n$ tends to $\infty$. However, I am struggling with 1 because I cannot manipulate the reciprocal, and I am struggling with 2 because I don't know how to calculate the expected value of the reciprocal of a sum of the RVs. Any help?","We have $n$ iid random variables all taken from an $Exponential( \lambda)$ distribution. I have found the MLE of $\lambda$ to be $\frac{n}{\Sigma _{i=1}^{n} X_i}$. However I am struggling to prove that this is a consistent estimator. I have had two ideas as to how to approach this: 1) Through the weak law of large numbers which involves, in this case, the reciprocals of both the estimator and what I'm trying to estimate. 2) Through showing that the expected value of the MLE converges in probability to $\lambda$ and that it's variance converges to $0$ as $n$ tends to $\infty$. However, I am struggling with 1 because I cannot manipulate the reciprocal, and I am struggling with 2 because I don't know how to calculate the expected value of the reciprocal of a sum of the RVs. Any help?",,"['statistics', 'parameter-estimation']"
91,Linear objective function with quadratic constraints,Linear objective function with quadratic constraints,,"The context is ordinary multivariate regression with $k$ (>1) regressors, i.e. $Y = X\beta + \epsilon$, where $Y \in \mathbb{R}^{n \times 1}$ vector of predicted variable, $X \in \mathbb{R}^{n \times (k+1)}$ matrix of regressor variables(including ones in the first column)  $\beta \in \mathbb{R}^{(k+1) \times 1}$ vector of coefficients, including intercept. Say, I have already estimated $\beta$ as $\hat{\beta} = (X'X)^{-1} X'Y.$ I have to solve the following program: minimize $f(B) = L\beta$   ( $L$ is a fixed $1\times (k+1)-$vector   ) such that: $[(\beta-\hat{\beta})' \cdot X'X \cdot (\beta-\hat{\beta})] / [(Y - X\hat{\beta})' (Y - X\hat{\beta}) ]$   is less than a given value $c$. Note that this is a linear optimization program with respect to $\beta$ with quadratic constraints. I don't understand how we can solve this optimization - I was going through some online resources, each of which involve manually computing gradients of the objective as well as constraint functions - which I want to avoid (at least manually doing this). Can you please help solve this optimization problem in R ? The inputs would be: $X$, $Y$, $\hat{\beta}$, $L$ and $c$ Please let me know if any further information is required - the set-up is pretty general.","The context is ordinary multivariate regression with $k$ (>1) regressors, i.e. $Y = X\beta + \epsilon$, where $Y \in \mathbb{R}^{n \times 1}$ vector of predicted variable, $X \in \mathbb{R}^{n \times (k+1)}$ matrix of regressor variables(including ones in the first column)  $\beta \in \mathbb{R}^{(k+1) \times 1}$ vector of coefficients, including intercept. Say, I have already estimated $\beta$ as $\hat{\beta} = (X'X)^{-1} X'Y.$ I have to solve the following program: minimize $f(B) = L\beta$   ( $L$ is a fixed $1\times (k+1)-$vector   ) such that: $[(\beta-\hat{\beta})' \cdot X'X \cdot (\beta-\hat{\beta})] / [(Y - X\hat{\beta})' (Y - X\hat{\beta}) ]$   is less than a given value $c$. Note that this is a linear optimization program with respect to $\beta$ with quadratic constraints. I don't understand how we can solve this optimization - I was going through some online resources, each of which involve manually computing gradients of the objective as well as constraint functions - which I want to avoid (at least manually doing this). Can you please help solve this optimization problem in R ? The inputs would be: $X$, $Y$, $\hat{\beta}$, $L$ and $c$ Please let me know if any further information is required - the set-up is pretty general.",,"['statistics', 'optimization', 'convex-optimization', 'regression', 'qclp']"
92,Expected value of a uniform distribution,Expected value of a uniform distribution,,Let $f(x) = 0.025x + 0.15$ for $2 < x < 6$. The expected value formula is $1/2 \cdot (b-a)$. So is the expected value just $1/2 \cdot (6-2) = 4$ or do I have to integrate $f(x)$ first?,Let $f(x) = 0.025x + 0.15$ for $2 < x < 6$. The expected value formula is $1/2 \cdot (b-a)$. So is the expected value just $1/2 \cdot (6-2) = 4$ or do I have to integrate $f(x)$ first?,,"['probability', 'statistics', 'uniform-distribution']"
93,Weighted product vs. weighted sum,Weighted product vs. weighted sum,,"I've been searching for almost a day now and I'm running out of steam... can someone give me a nice, easy to grasp explanation/example of what a weighted product does compared to what a weighted sum does? I'm having trouble coming up with an interpretation I can work with, especially when looking at weighted joint probabilities. To be perfectly clear, I'm talking about  $P(X) = \prod_i p(x_i)^{w_i}$ vs. $S(X) = \frac{\sum_i w_i * p(x_i)}{\sum_i w_i}$.","I've been searching for almost a day now and I'm running out of steam... can someone give me a nice, easy to grasp explanation/example of what a weighted product does compared to what a weighted sum does? I'm having trouble coming up with an interpretation I can work with, especially when looking at weighted joint probabilities. To be perfectly clear, I'm talking about  $P(X) = \prod_i p(x_i)^{w_i}$ vs. $S(X) = \frac{\sum_i w_i * p(x_i)}{\sum_i w_i}$.",,['statistics']
94,the degree of freedom of a chi-squared random variable goes to infinity,the degree of freedom of a chi-squared random variable goes to infinity,,"Hi guys, I've used an calculator to show that this is correct. I am just wondering what is the other way to prove that this statement is true. Thanks!","Hi guys, I've used an calculator to show that this is correct. I am just wondering what is the other way to prove that this statement is true. Thanks!",,"['statistics', 'probability-distributions', 'chi-squared']"
95,Help in understanding Derivation of Posterior in Gaussian Process,Help in understanding Derivation of Posterior in Gaussian Process,,"According to the textbook Gaussian Process in Machine Learning, it is given that \begin{align*} p(w\mid X,y) &\propto \exp\left(-\frac{1}{2\sigma_n^2}(y-X^Tw)(y-X^Tw)\right)\exp\left(-\frac{1}{2}w^T\Sigma_{p}^{-1}w\right) \\ &\propto \exp\left(-\frac{1}{2}(w-\bar{w})^T\left(\frac{1}{\sigma_n^2}XX^T + \Sigma_p^{-1}\right)(w-\bar{w})\right) \end{align*}  where $\bar{w} = \sigma_n^{-2}(\sigma_n^{-2}XX^T + \Sigma_p^{-1})^{-1}Xy$. I can't really understand how the first step leads to the second step. Can someone kindly show me how the derivation is done? Thanks","According to the textbook Gaussian Process in Machine Learning, it is given that \begin{align*} p(w\mid X,y) &\propto \exp\left(-\frac{1}{2\sigma_n^2}(y-X^Tw)(y-X^Tw)\right)\exp\left(-\frac{1}{2}w^T\Sigma_{p}^{-1}w\right) \\ &\propto \exp\left(-\frac{1}{2}(w-\bar{w})^T\left(\frac{1}{\sigma_n^2}XX^T + \Sigma_p^{-1}\right)(w-\bar{w})\right) \end{align*}  where $\bar{w} = \sigma_n^{-2}(\sigma_n^{-2}XX^T + \Sigma_p^{-1})^{-1}Xy$. I can't really understand how the first step leads to the second step. Can someone kindly show me how the derivation is done? Thanks",,"['linear-algebra', 'probability', 'statistics', 'machine-learning']"
96,Combinations Proof [closed],Combinations Proof [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Show that $2^n = \sum_{i=0}^n \binom ni$. I tried expanding $\sum_{i=0}^n \binom ni$ into sum of: $\frac{n!}{(n-r)!r!}$, and found the common ratio and then used the sum formula, but I did not get to $2^n$.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Show that $2^n = \sum_{i=0}^n \binom ni$. I tried expanding $\sum_{i=0}^n \binom ni$ into sum of: $\frac{n!}{(n-r)!r!}$, and found the common ratio and then used the sum formula, but I did not get to $2^n$.",,"['probability', 'statistics', 'permutations', 'combinations']"
97,What is KL-Divergence? Why Do I need it? How do I use it?,What is KL-Divergence? Why Do I need it? How do I use it?,,"I am currently studying KL Divergence. But It seems very confusing that I don't maybe understand why do I ever need it and what is that for? As I have been reading stuff about Mutual Information, it looks like it is about the amount of Entropy between two probability distributions, for example, P(A) and P(B|A), especially for the conditional probability situation. Can somebody give me a clear explanation about KL-Divergence?","I am currently studying KL Divergence. But It seems very confusing that I don't maybe understand why do I ever need it and what is that for? As I have been reading stuff about Mutual Information, it looks like it is about the amount of Entropy between two probability distributions, for example, P(A) and P(B|A), especially for the conditional probability situation. Can somebody give me a clear explanation about KL-Divergence?",,"['statistics', 'mathematical-physics', 'machine-learning', 'data-analysis', 'data-mining']"
98,"A bag contains 2 red, 3 green and 2 blue balls. Two balls are drawn at random. What is the probability that none of the balls drawn is blue?","A bag contains 2 red, 3 green and 2 blue balls. Two balls are drawn at random. What is the probability that none of the balls drawn is blue?",,"A bag contains 2 red, 3 green and 2 blue balls. Two balls are drawn at random. What is the probability that none of the balls drawn is blue? I am helpless regarding this. I don't know how to solve it. My teacher asked me to solve it by finding the probability that the balls drawn are blue and then subtracting it from 1. But I want to solve it straight forward and directly. Is it possible? If yes, how?","A bag contains 2 red, 3 green and 2 blue balls. Two balls are drawn at random. What is the probability that none of the balls drawn is blue? I am helpless regarding this. I don't know how to solve it. My teacher asked me to solve it by finding the probability that the balls drawn are blue and then subtracting it from 1. But I want to solve it straight forward and directly. Is it possible? If yes, how?",,"['probability', 'statistics', 'permutations', 'combinations']"
99,Maximum Likelihood Estimation of Brownian Motion Drift,Maximum Likelihood Estimation of Brownian Motion Drift,,"I'm looking at times series of stock movements over 10 minute windows, and am trying to measure the ""trend"" of these movements. Method A is to simply calculate $\Delta P$, the difference between the final value and the initial value. Method B is to use MLE to calculate the maximum likelihood value of the drift coefficient using the Brownian Motion model $dP(t)=\mu P(t) dt + \sigma P(t)  dB(t)$. My intuition is that, if I am able to calculate the estimate $\hat{\mu}$, it will be a better measure of the trend since the Brownian motion is able to take into account volatility. However, another part of me thinks that $\hat{\mu}$ may actually just be a linear combo of  $\Delta P$ (i.e. $\hat{\mu}$ is completely determined by the first and last values of the time series). Any thoughts or semi-rigorous explanations would greatly appreciated! And let me know if anything else needs clarifying.","I'm looking at times series of stock movements over 10 minute windows, and am trying to measure the ""trend"" of these movements. Method A is to simply calculate $\Delta P$, the difference between the final value and the initial value. Method B is to use MLE to calculate the maximum likelihood value of the drift coefficient using the Brownian Motion model $dP(t)=\mu P(t) dt + \sigma P(t)  dB(t)$. My intuition is that, if I am able to calculate the estimate $\hat{\mu}$, it will be a better measure of the trend since the Brownian motion is able to take into account volatility. However, another part of me thinks that $\hat{\mu}$ may actually just be a linear combo of  $\Delta P$ (i.e. $\hat{\mu}$ is completely determined by the first and last values of the time series). Any thoughts or semi-rigorous explanations would greatly appreciated! And let me know if anything else needs clarifying.",,"['probability', 'statistics', 'brownian-motion', 'finance', 'maximum-likelihood']"
