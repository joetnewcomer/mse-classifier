,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Maximum load of a bin in the $n$ balls with weights into $m$ bins problem,Maximum load of a bin in the  balls with weights into  bins problem,n m,"$n$ balls, each with a weight $p_i$, are thrown into $m$ bins. Each bin is chosen with uniform probability. Prove or disprove that the expected value of the maximum load among the loads of bins is $\frac1m\sum_{j=1}^n p_j$, where with ""load"" means the sum of the weights of the balls in that bin. Now, I was able to model the problem on the expected value of each bin and this is: $E[X_i]=\frac1m\sum_{j=1}^n p_j$, where $X_i$ is the load of the bin $i$. Should I calculate something like this: $$E[\max_{1 \leq i \leq n} {X_i}]$$ Do you have any idea? Or is the equation to disprove? But, I have no idea how to have to find a counterexample to disprove with expected values.","$n$ balls, each with a weight $p_i$, are thrown into $m$ bins. Each bin is chosen with uniform probability. Prove or disprove that the expected value of the maximum load among the loads of bins is $\frac1m\sum_{j=1}^n p_j$, where with ""load"" means the sum of the weights of the balls in that bin. Now, I was able to model the problem on the expected value of each bin and this is: $E[X_i]=\frac1m\sum_{j=1}^n p_j$, where $X_i$ is the load of the bin $i$. Should I calculate something like this: $$E[\max_{1 \leq i \leq n} {X_i}]$$ Do you have any idea? Or is the equation to disprove? But, I have no idea how to have to find a counterexample to disprove with expected values.",,"['probability', 'balls-in-bins']"
1,$X+Y\in L^1$ implies $X \in L^1$ given $X$ and $Y$ are independent random variables,implies  given  and  are independent random variables,X+Y\in L^1 X \in L^1 X Y,"This problem can be found here , which is a previous prelim exam problem of UT Austin. Let $X$ and $Y$ be two independent random variables with $X+Y \in L^1$. Show that $X\in L^1$. Generally, in real analysis, $f+g\in L^1$ does not imply $f\in L^1$, so I guess this must have something to do with their independence. I guess it might be something like $EX=E(X+Y|Y=y)-y$, but I'm not sure whether I can write like that without knowing $X\in L^1$ or $Y\in L^1$ first. Or, it should be proved in another way? Could you please help? Thanks.","This problem can be found here , which is a previous prelim exam problem of UT Austin. Let $X$ and $Y$ be two independent random variables with $X+Y \in L^1$. Show that $X\in L^1$. Generally, in real analysis, $f+g\in L^1$ does not imply $f\in L^1$, so I guess this must have something to do with their independence. I guess it might be something like $EX=E(X+Y|Y=y)-y$, but I'm not sure whether I can write like that without knowing $X\in L^1$ or $Y\in L^1$ first. Or, it should be proved in another way? Could you please help? Thanks.",,"['probability', 'probability-theory']"
2,Determining boundaries of Probability Density Function integral for a requested probability,Determining boundaries of Probability Density Function integral for a requested probability,,"This isn't one specific homework question, but a concept I'm having trouble with in class. We were asked on a couple of questions recently on homework dealing with the probability density function of two random variables, $f_{X,Y}(x,y)$. We were given a joint probability density function and asked to find a given probability, like $P[X + Y > 5]$. One solid example being: Given a Joint PDF $f_{X,Y}(x,y)$ let A be the event that $X + Y \leq 1$. Now, I know that $$P[A] = \int_A\int f_{X,Y}(x,y)dxdy$$ (at least, that's how my book writes it). My question is, how do I determine the bounds of those two integrals? In the solution manual for this particular problem, it is stated that the solution is $$P[X+Y\leq 1] = \int_0^1\int_0^{1-x}f_{X,Y}(x,y)dxdy$$ I can see pretty clearly that $x + (1-x)$ will always be less than or equal to one for $0 \leq x \leq 1$, so I understand why those bounds work. I'm just not sure I could have come up with them. Is there a process for figuring this out that I am missing? A similar question posed to us was given another joint PDF, let A be the event that $ X+Y>5$. I have no idea what the bounds would be for this one. Can someone show me how to find the integral bounds for questions like this?","This isn't one specific homework question, but a concept I'm having trouble with in class. We were asked on a couple of questions recently on homework dealing with the probability density function of two random variables, $f_{X,Y}(x,y)$. We were given a joint probability density function and asked to find a given probability, like $P[X + Y > 5]$. One solid example being: Given a Joint PDF $f_{X,Y}(x,y)$ let A be the event that $X + Y \leq 1$. Now, I know that $$P[A] = \int_A\int f_{X,Y}(x,y)dxdy$$ (at least, that's how my book writes it). My question is, how do I determine the bounds of those two integrals? In the solution manual for this particular problem, it is stated that the solution is $$P[X+Y\leq 1] = \int_0^1\int_0^{1-x}f_{X,Y}(x,y)dxdy$$ I can see pretty clearly that $x + (1-x)$ will always be less than or equal to one for $0 \leq x \leq 1$, so I understand why those bounds work. I'm just not sure I could have come up with them. Is there a process for figuring this out that I am missing? A similar question posed to us was given another joint PDF, let A be the event that $ X+Y>5$. I have no idea what the bounds would be for this one. Can someone show me how to find the integral bounds for questions like this?",,"['probability', 'integration', 'probability-distributions', 'random-variables']"
3,Continuous Mapping Theorem (CMT) for a sequence of random vectors,Continuous Mapping Theorem (CMT) for a sequence of random vectors,,"I need help proving the Continuous Mapping Theorem (CMT) for random vectors. I'm currently reading Econometric Analysis for Cross Section and Panel Data by Jeffrey M. Wooldridge (Chapter 3, pp. 40 - 41, 2nd edition). Unfortunately, he leaves it to the reader to prove most asymptotic results. Additionally, almost every other econometrics textbook I read simply states the result. Definition 1: A sequence of random variables $x_n$ converges in distribution to a continuous random variable $x$ if and only if $\forall s \in \mathbb{R} \ \forall \epsilon >0   \ \exists N \ s.t. \  \forall n>N \; |Prob(x_n \leq s) - Prob(x \leq s)|<\epsilon$. We write $x_n \to^d x.$ [Note: A continuous random variable is one for which the cumulative distribution function is continuous.] Definition 2: A sequence of K $\times$ 1 random vectors $\mathbf{x}_n$ converges in distribution to the continuous random $K \times 1$ vector $\mathbf{x}$ if and only if $\forall \mathbf{c} \in \mathbb{R}^{K}$ such that $\mathbf{c}^T\mathbf{c} = 1$, $\mathbf{c}^T\mathbf{x}_n \to^d \mathbf{c}^T\mathbf{x}$, and we write $\mathbf{x}_n \to^d \mathbf{x}.$ Theorem 1: Let $\mathbf{x}_n$ be a sequence of $K \times 1$ random vectors such that $\mathbf{x}_n \to^d \mathbf{x}$. If $\mathbf{g}:\mathbb{R}^k\to\mathbb{R}^{\ell}$ is a continuous function, then $\mathbf{g}(\mathbf{x}_n)$ $\to^d$ $\mathbf{g}(\mathbf{x}).$ Definition 3: A sequence of random variables $x_n$ is bounded in probability if and only if $\forall \epsilon>0 \ \exists b_{\epsilon}>0 \ \exists N \ s.t. \forall n>N \ Prob(|x_n|>b_{\epsilon})$. A vector $\mathbf{x}_n$ is bounded in probability if and only if the random variables which constitute the vector of random variables are themselves bounded in probability. Theorem 2: If $\mathbf{x}_n \to^d \mathbf{x}$, where $\mathbf{x}$ is a $K \times 1$ vector, then $\mathbf{x}_n = O_p(1)$. I need rigorous proofs for Theorems 1 and 2. This problem has been frustrating me for a couple days now, so any help would go a long way. Thanks. CS","I need help proving the Continuous Mapping Theorem (CMT) for random vectors. I'm currently reading Econometric Analysis for Cross Section and Panel Data by Jeffrey M. Wooldridge (Chapter 3, pp. 40 - 41, 2nd edition). Unfortunately, he leaves it to the reader to prove most asymptotic results. Additionally, almost every other econometrics textbook I read simply states the result. Definition 1: A sequence of random variables $x_n$ converges in distribution to a continuous random variable $x$ if and only if $\forall s \in \mathbb{R} \ \forall \epsilon >0   \ \exists N \ s.t. \  \forall n>N \; |Prob(x_n \leq s) - Prob(x \leq s)|<\epsilon$. We write $x_n \to^d x.$ [Note: A continuous random variable is one for which the cumulative distribution function is continuous.] Definition 2: A sequence of K $\times$ 1 random vectors $\mathbf{x}_n$ converges in distribution to the continuous random $K \times 1$ vector $\mathbf{x}$ if and only if $\forall \mathbf{c} \in \mathbb{R}^{K}$ such that $\mathbf{c}^T\mathbf{c} = 1$, $\mathbf{c}^T\mathbf{x}_n \to^d \mathbf{c}^T\mathbf{x}$, and we write $\mathbf{x}_n \to^d \mathbf{x}.$ Theorem 1: Let $\mathbf{x}_n$ be a sequence of $K \times 1$ random vectors such that $\mathbf{x}_n \to^d \mathbf{x}$. If $\mathbf{g}:\mathbb{R}^k\to\mathbb{R}^{\ell}$ is a continuous function, then $\mathbf{g}(\mathbf{x}_n)$ $\to^d$ $\mathbf{g}(\mathbf{x}).$ Definition 3: A sequence of random variables $x_n$ is bounded in probability if and only if $\forall \epsilon>0 \ \exists b_{\epsilon}>0 \ \exists N \ s.t. \forall n>N \ Prob(|x_n|>b_{\epsilon})$. A vector $\mathbf{x}_n$ is bounded in probability if and only if the random variables which constitute the vector of random variables are themselves bounded in probability. Theorem 2: If $\mathbf{x}_n \to^d \mathbf{x}$, where $\mathbf{x}$ is a $K \times 1$ vector, then $\mathbf{x}_n = O_p(1)$. I need rigorous proofs for Theorems 1 and 2. This problem has been frustrating me for a couple days now, so any help would go a long way. Thanks. CS",,"['probability', 'statistics', 'probability-theory', 'convergence-divergence']"
4,"Prove that if X and Y are Normal and independent random variables, X+Y and X−Y are independent","Prove that if X and Y are Normal and independent random variables, X+Y and X−Y are independent",,"Prove that if X and Y are Normal and independent random variables, X+Y and X−Y are independent. Note that X and Y also have the same mean and standard deviation. Note that this is a duplicate of Prove that if $X$ and $Y$ are Normal and independent random variables, $X+Y$ and $X-Y$ are independent , however, there isn't a complete solution to the answer given and I do not understand exactly what the hints are suggesting. My attempt was to check if $f_{x+y,x-y}(u,v) = f_{x+y}(u)f_{x-y}(v)$, however, this does not seem to be working out too nicely.","Prove that if X and Y are Normal and independent random variables, X+Y and X−Y are independent. Note that X and Y also have the same mean and standard deviation. Note that this is a duplicate of Prove that if $X$ and $Y$ are Normal and independent random variables, $X+Y$ and $X-Y$ are independent , however, there isn't a complete solution to the answer given and I do not understand exactly what the hints are suggesting. My attempt was to check if $f_{x+y,x-y}(u,v) = f_{x+y}(u)f_{x-y}(v)$, however, this does not seem to be working out too nicely.",,"['probability', 'probability-theory']"
5,Combinatorial properties of permutation groups,Combinatorial properties of permutation groups,,"Let $P_n$ denote the set of pairs $(x,y)$ of permutations on $S_{2n}$, where each permutation is a product of $n$ disjoint cycles of length two. Let i and j be two fixed elements of the set $\{1,2, \cdots,2n\}$. Select an element $(x,y)$ of $P_n$. What is the probability that the product $xy$ contains $i$ and $j$ in the same cycle?","Let $P_n$ denote the set of pairs $(x,y)$ of permutations on $S_{2n}$, where each permutation is a product of $n$ disjoint cycles of length two. Let i and j be two fixed elements of the set $\{1,2, \cdots,2n\}$. Select an element $(x,y)$ of $P_n$. What is the probability that the product $xy$ contains $i$ and $j$ in the same cycle?",,"['probability', 'combinatorics', 'permutations']"
6,Secretary problem for unknown n?,Secretary problem for unknown n?,,"So one of my good friends is starting to date again (after being out of the country for two years), and I think that it might be helpful, or at least fun, to keep track of her dates in a ranked fashion so that we can always be on the look-out for the optimum stopping point (i.e. who she should marry) in a semi-rigourous fashion (yes, we're nerding out about this).  So I understand what the procedure is for the secretary problem with a known n, but since we're going to be doing this on the fly, how do we know when to accept the new best ranked guy as the one?  Thanks!","So one of my good friends is starting to date again (after being out of the country for two years), and I think that it might be helpful, or at least fun, to keep track of her dates in a ranked fashion so that we can always be on the look-out for the optimum stopping point (i.e. who she should marry) in a semi-rigourous fashion (yes, we're nerding out about this).  So I understand what the procedure is for the secretary problem with a known n, but since we're going to be doing this on the fly, how do we know when to accept the new best ranked guy as the one?  Thanks!",,"['probability', 'optimization']"
7,A proof that Skorohod metric is a metric,A proof that Skorohod metric is a metric,,"I'm reading Billingsley's ""Convergence of probability measures"" (1968), p. 111. The definitions are: $D$ - the space of $\textit{cadlag}$ functions on [0,1], $\Lambda$ - the class of strictly increasing, continuous mappings of [0,1] onto itself. For $x,y\in D$ define  $$d(x,y):=\inf\{\varepsilon>0:\ \exists\lambda\in\Lambda:\ \sup_t|\lambda(t)-t|<\varepsilon \text{ and } \\ \sup_t|x(t)-y(\lambda(t))|<\varepsilon\}.\tag{1}$$ I'm stuck with the proof that $d(x,y)=0$ implies $x=y$. The author claims: ""$d(x,y)=0$ implies that for each $t$ either $x(t)=y(t)$ or $x(t)=y(t-)$, which in turn implies $x=y$."" This is what I tried: let $x,y\in D$, $d(x,y)=0$ and $t\in[0,1]$. Now from (1) it follows that there exists a sequence $(z_n)\subset[0,1]$ such that $z_n\to t$ and $y(z_n)\to x(t)$ as $n\to\infty$. If $t$ is a continuity point of $y$, then $y(z_n)\to y(t)$, thus $x(t)=y(t)$. If $y$ has a jump at $t$ and $(z_n)$ has a subsequence $(z_{n_k})$ such that $z_{n_k}\geq t, \forall k$, then $y(z_{n_k})\to x(t)$ and $y(z_{n_k})\to y(t)$, as $k\to\infty$, thus $y(t)=x(t)$. Otherwise, $z_n<t$ for $n$ large enough and $y(z_n)\to y(t-)$, as $n\to\infty$, thus $x(t)=y(t-)$. Now suppose that $y=\mathbf{1}_{[t,1]}$, then $y$ has a jump at $t$ and if $d(x,y)=0$, then $x=\mathbf{1}_{(t,1]}$. But this is a contradiction since $x\neq y$ and $x$ is not $\textit{cadlag}$. Where am I wrong?","I'm reading Billingsley's ""Convergence of probability measures"" (1968), p. 111. The definitions are: $D$ - the space of $\textit{cadlag}$ functions on [0,1], $\Lambda$ - the class of strictly increasing, continuous mappings of [0,1] onto itself. For $x,y\in D$ define  $$d(x,y):=\inf\{\varepsilon>0:\ \exists\lambda\in\Lambda:\ \sup_t|\lambda(t)-t|<\varepsilon \text{ and } \\ \sup_t|x(t)-y(\lambda(t))|<\varepsilon\}.\tag{1}$$ I'm stuck with the proof that $d(x,y)=0$ implies $x=y$. The author claims: ""$d(x,y)=0$ implies that for each $t$ either $x(t)=y(t)$ or $x(t)=y(t-)$, which in turn implies $x=y$."" This is what I tried: let $x,y\in D$, $d(x,y)=0$ and $t\in[0,1]$. Now from (1) it follows that there exists a sequence $(z_n)\subset[0,1]$ such that $z_n\to t$ and $y(z_n)\to x(t)$ as $n\to\infty$. If $t$ is a continuity point of $y$, then $y(z_n)\to y(t)$, thus $x(t)=y(t)$. If $y$ has a jump at $t$ and $(z_n)$ has a subsequence $(z_{n_k})$ such that $z_{n_k}\geq t, \forall k$, then $y(z_{n_k})\to x(t)$ and $y(z_{n_k})\to y(t)$, as $k\to\infty$, thus $y(t)=x(t)$. Otherwise, $z_n<t$ for $n$ large enough and $y(z_n)\to y(t-)$, as $n\to\infty$, thus $x(t)=y(t-)$. Now suppose that $y=\mathbf{1}_{[t,1]}$, then $y$ has a jump at $t$ and if $d(x,y)=0$, then $x=\mathbf{1}_{(t,1]}$. But this is a contradiction since $x\neq y$ and $x$ is not $\textit{cadlag}$. Where am I wrong?",,"['probability', 'skorohod-space']"
8,coin flips and markov chain,coin flips and markov chain,,"Consider the case of an infinite (or finite $n$) string of coin tosses, and let $q$ and $1-q$ be the probabilities that the coin comes up tails and heads, respectively.  (For simplicity, we can take $q=\frac12$ so that the fraction of tails and heads are the same.) Let $p$ be the probability that, if a given toss is tails, it will be followed by tails.  (If $q = \frac12$, this is the same probability as for getting heads after heads, might as well be a different probability though.) What is the probability of getting three or more tails consecutively out of $n$ flips (and alternatively out of infinite number of flips). For example: $TTT-H-TTT-HH-TTTT\dots$ We can have half tails and half heads in total (when $q=\frac12$).  $p$ does not affect the fraction of tails and heads in the limit, but affects how they are clustered. So when $p=1$ we have only 2 separate 'sections' such that one section is composed of only tails and the other runs of only heads. (ex: $TTTTT \dots HHHHH$). For $p=0$, it will be like $THTHTHTH\dots$ I am looking for: The fraction of tails that are in sections of size three or more. The expected size of sections with tails. I'd be very thankful if you could help me with it!","Consider the case of an infinite (or finite $n$) string of coin tosses, and let $q$ and $1-q$ be the probabilities that the coin comes up tails and heads, respectively.  (For simplicity, we can take $q=\frac12$ so that the fraction of tails and heads are the same.) Let $p$ be the probability that, if a given toss is tails, it will be followed by tails.  (If $q = \frac12$, this is the same probability as for getting heads after heads, might as well be a different probability though.) What is the probability of getting three or more tails consecutively out of $n$ flips (and alternatively out of infinite number of flips). For example: $TTT-H-TTT-HH-TTTT\dots$ We can have half tails and half heads in total (when $q=\frac12$).  $p$ does not affect the fraction of tails and heads in the limit, but affects how they are clustered. So when $p=1$ we have only 2 separate 'sections' such that one section is composed of only tails and the other runs of only heads. (ex: $TTTTT \dots HHHHH$). For $p=0$, it will be like $THTHTHTH\dots$ I am looking for: The fraction of tails that are in sections of size three or more. The expected size of sections with tails. I'd be very thankful if you could help me with it!",,"['probability', 'probability-theory', 'probability-distributions', 'markov-chains']"
9,"Coupon Problem generalized, or Birthday problem backward.","Coupon Problem generalized, or Birthday problem backward.",,"I want to solve a variation on the Coupon Collector Problem , or (alternately) a slight variant on the standard Birthday Problem. I have a slight variant on the standard birthday problem . In the standard Coupon Collector problem, someone is choosing coupons at random (with replacement) from n different possible coupons. Duplicate coupons do us no good; we need a complete set. The standard question is ""What is the expected number of coupons (or probability distribution in number of coupons) to collect them all? In the standard birthday problem, we choose k items from n options with replacement (such as k people in a room, each with one of 365 possible birthdays) and try to determine the probability distribution for how many unique values there will be (will they have the same birthday?). In my problem, someone has chosen k items from n options and I know that there were p distinct values, but I don't know what k was. If $p=n$ then this is the coupon problem, but I want to allow for values of p that are less than n. I want to determine the probability distribution for k (actually, all I need is the expected value of k, but the distribution would be interesting as well) as a function of p and n.","I want to solve a variation on the Coupon Collector Problem , or (alternately) a slight variant on the standard Birthday Problem. I have a slight variant on the standard birthday problem . In the standard Coupon Collector problem, someone is choosing coupons at random (with replacement) from n different possible coupons. Duplicate coupons do us no good; we need a complete set. The standard question is ""What is the expected number of coupons (or probability distribution in number of coupons) to collect them all? In the standard birthday problem, we choose k items from n options with replacement (such as k people in a room, each with one of 365 possible birthdays) and try to determine the probability distribution for how many unique values there will be (will they have the same birthday?). In my problem, someone has chosen k items from n options and I know that there were p distinct values, but I don't know what k was. If then this is the coupon problem, but I want to allow for values of p that are less than n. I want to determine the probability distribution for k (actually, all I need is the expected value of k, but the distribution would be interesting as well) as a function of p and n.",p=n,"['probability', 'combinatorics', 'discrete-mathematics', 'coupon-collector', 'birthday']"
10,Expectation and Variance of Ratio Estimator,Expectation and Variance of Ratio Estimator,,"Let $X$ and $Y$ be positive random variables such that  $$E(Y\mid X)= aX $$ $$\operatorname{Var}(Y\mid X) = b^2X^2 $$ $$a,b > 0 \text{ are constants}.$$ Let $R = \dfrac{\bar{Y}}{\bar{X}}=\dfrac{\sum_{i=1}^nY_i}{\sum_{i=1}^nX_i}$. Is there an easy way to solve for $E(R)$ and $\operatorname{Var}(R)$ using the info above, without having to take the Taylor series expansion of $\frac{\bar{Y}}{\bar{X}}$ around $\mu_X,\mu_Y$?","Let $X$ and $Y$ be positive random variables such that  $$E(Y\mid X)= aX $$ $$\operatorname{Var}(Y\mid X) = b^2X^2 $$ $$a,b > 0 \text{ are constants}.$$ Let $R = \dfrac{\bar{Y}}{\bar{X}}=\dfrac{\sum_{i=1}^nY_i}{\sum_{i=1}^nX_i}$. Is there an easy way to solve for $E(R)$ and $\operatorname{Var}(R)$ using the info above, without having to take the Taylor series expansion of $\frac{\bar{Y}}{\bar{X}}$ around $\mu_X,\mu_Y$?",,"['probability', 'statistics']"
11,Maximizing gambling performance over the long run,Maximizing gambling performance over the long run,,"Background. We can play a game in which we can put one dollar and get out $X$ dollars, where $X$ is 2 dollars with probability $p>1/2$, or zero dollars with probability $1-p$. We also assume that different plays of this game are independent. Note that $E[X] > 1$, meaning that we have an advantage. We begin with one dollar and start playing this game, such that we play with a fraction $f\in[0,1]$ of our current fortune each time we play. Thus—and here we let $X,X_1,X_2,\ldots$ denote (independent) random variables having the distribution of our plays as described above—our initial fortune is $F_0 = 1$, our fortune after 1 play is $F_1 = 1-f+fX_1 = 1+f(X_1-1)$, and in general, it is easily calculated that our fortune after $n$ plays is $$F_n = \prod_{i=1}^n(1+f(X_i-1)).$$ Since the plays are independent, our expected fortune after $n$ plays is $$E[F_n] = E\bigg[ \prod_{i=1}^n(1+f(X_i-1)) \bigg] = (1+f(E[X]-1))^n.$$ Since $E[X] > 1$, it is clear that $E[F_n] \to \infty$ no matter what $f$ we choose. However, for any given $n$ we see that $E[F_n]$ is largest for $f=1$. Does this mean we should choose $f=1$? This is probably a bad idea, because in this case, the probability of going broke after $n$ or fewer plays is $1-p^n$, which approaches one as $n\to\infty$. In other words, if we choose $f=1$, we will eventually go broke for sure. (For a further explanation of this, feel free to refer to my previous question, Resolving a paradox concerning an expected value .) So what strategy should we take to maximize our long-term performance? Some authors have suggested the approach of maximizing the “exponential rate of growth.” Let me explain. Imagine that $F_n = e^{nG_n}$. Here, $G_n$ is the “exponential rate of growth” of $F_n$. We can write $$G_n = \frac{1}{n}\log(F_n) = \frac{1}{n}\log\bigg( \prod_{i=1}^n(1+f(X_i-1)) \bigg) = \frac{1}{n} \sum_{i=1}^n \log(1+f(X_i-1)).$$ Using the law of large numbers, we find that $$G_n \to E[\log(1+f(X-1))] \quad \text{almost surely}.$$ Now, $G := E[\log(1+f(X-1))]$ is what some authors refer to as the “exponential rate of growth” that we should aim at maximizing. Indeed, $G$ seems to be the “exponential rate of growth” at the “infinity,” in some sense. In our present case, we find that $$G = \log(1+f)p + \log(1-f)(1-p),$$ which—interestingly—is maximized at $f=2p-1$. According to this, we have the largest exponential rate of growth if we choose $f=2p-1$, and this is the value for $f$ at which some authors suggest gamblers place their bets. Question 1. Why should I care about this? Can you give me some intuitive explanation of why my goal should be to maximize the exponential rate of growth, as opposed to maximizing $E[F_n]$ (i.e. to choose $f=1$), or choosing $f=0.99$ to keep $E[F_n]$ high while avoiding that almost sure bankruptcy? I don’t have a natural feel for what to do and why, in order to get as much growth as possible in the long run. Question 2. How can it be possible that the exponential rate of growth is maximized at $f=2p-1$, yet $E[F_n]$ is always the highest for $f=1$? That doesn’t make much sense to me. Wouldn’t you expect $E[F_n]$ to eventually become the highest at $f=2p-1$? In other words, how can I we—in the “infinity”—have the greatest growth at $f=2p-1$ but the greatest expectation value at $f=1$? Question 3. Here is a graph that shows $G$ as a function of $f$ for $p=2/3$. The maximum is indeed at $2p-1=1/3$. However, something interesting happens around $f\approx 0.618$, when the curve goes below zero. Supposedly, this is the point beyond which we are almost sure to end up with a loss, i.e. end up with less than 1 dollar. Do you understand why this is? Furthermore, it still remains a mystery to me why the curve for $E[F_n]$ wouldn’t show similarly interesting features, instead of being a monotonically increasing function of $f$.","Background. We can play a game in which we can put one dollar and get out $X$ dollars, where $X$ is 2 dollars with probability $p>1/2$, or zero dollars with probability $1-p$. We also assume that different plays of this game are independent. Note that $E[X] > 1$, meaning that we have an advantage. We begin with one dollar and start playing this game, such that we play with a fraction $f\in[0,1]$ of our current fortune each time we play. Thus—and here we let $X,X_1,X_2,\ldots$ denote (independent) random variables having the distribution of our plays as described above—our initial fortune is $F_0 = 1$, our fortune after 1 play is $F_1 = 1-f+fX_1 = 1+f(X_1-1)$, and in general, it is easily calculated that our fortune after $n$ plays is $$F_n = \prod_{i=1}^n(1+f(X_i-1)).$$ Since the plays are independent, our expected fortune after $n$ plays is $$E[F_n] = E\bigg[ \prod_{i=1}^n(1+f(X_i-1)) \bigg] = (1+f(E[X]-1))^n.$$ Since $E[X] > 1$, it is clear that $E[F_n] \to \infty$ no matter what $f$ we choose. However, for any given $n$ we see that $E[F_n]$ is largest for $f=1$. Does this mean we should choose $f=1$? This is probably a bad idea, because in this case, the probability of going broke after $n$ or fewer plays is $1-p^n$, which approaches one as $n\to\infty$. In other words, if we choose $f=1$, we will eventually go broke for sure. (For a further explanation of this, feel free to refer to my previous question, Resolving a paradox concerning an expected value .) So what strategy should we take to maximize our long-term performance? Some authors have suggested the approach of maximizing the “exponential rate of growth.” Let me explain. Imagine that $F_n = e^{nG_n}$. Here, $G_n$ is the “exponential rate of growth” of $F_n$. We can write $$G_n = \frac{1}{n}\log(F_n) = \frac{1}{n}\log\bigg( \prod_{i=1}^n(1+f(X_i-1)) \bigg) = \frac{1}{n} \sum_{i=1}^n \log(1+f(X_i-1)).$$ Using the law of large numbers, we find that $$G_n \to E[\log(1+f(X-1))] \quad \text{almost surely}.$$ Now, $G := E[\log(1+f(X-1))]$ is what some authors refer to as the “exponential rate of growth” that we should aim at maximizing. Indeed, $G$ seems to be the “exponential rate of growth” at the “infinity,” in some sense. In our present case, we find that $$G = \log(1+f)p + \log(1-f)(1-p),$$ which—interestingly—is maximized at $f=2p-1$. According to this, we have the largest exponential rate of growth if we choose $f=2p-1$, and this is the value for $f$ at which some authors suggest gamblers place their bets. Question 1. Why should I care about this? Can you give me some intuitive explanation of why my goal should be to maximize the exponential rate of growth, as opposed to maximizing $E[F_n]$ (i.e. to choose $f=1$), or choosing $f=0.99$ to keep $E[F_n]$ high while avoiding that almost sure bankruptcy? I don’t have a natural feel for what to do and why, in order to get as much growth as possible in the long run. Question 2. How can it be possible that the exponential rate of growth is maximized at $f=2p-1$, yet $E[F_n]$ is always the highest for $f=1$? That doesn’t make much sense to me. Wouldn’t you expect $E[F_n]$ to eventually become the highest at $f=2p-1$? In other words, how can I we—in the “infinity”—have the greatest growth at $f=2p-1$ but the greatest expectation value at $f=1$? Question 3. Here is a graph that shows $G$ as a function of $f$ for $p=2/3$. The maximum is indeed at $2p-1=1/3$. However, something interesting happens around $f\approx 0.618$, when the curve goes below zero. Supposedly, this is the point beyond which we are almost sure to end up with a loss, i.e. end up with less than 1 dollar. Do you understand why this is? Furthermore, it still remains a mystery to me why the curve for $E[F_n]$ wouldn’t show similarly interesting features, instead of being a monotonically increasing function of $f$.",,"['probability', 'infinity', 'finance']"
12,Find E(XY) and covariance,Find E(XY) and covariance,,"I am given n independent Bernoulli trials, prob success = p. If X is # of successes, and Y is the number of failures, what is E(XY) and Cov(X,Y)? I was trying to use E(XY) - E(X)E(Y), the second component is easy, but I can't think of an easy way of finding E(XY) (maybe there isn't any?) Thanks!","I am given n independent Bernoulli trials, prob success = p. If X is # of successes, and Y is the number of failures, what is E(XY) and Cov(X,Y)? I was trying to use E(XY) - E(X)E(Y), the second component is easy, but I can't think of an easy way of finding E(XY) (maybe there isn't any?) Thanks!",,['probability']
13,"What is ""sampling from a distribution""?","What is ""sampling from a distribution""?",,"Exercise 4.11.3 of Grimmett and Stirzaker's Probability and Random Processes reads ""Use the rejection method to sample from the gamma density $\Gamma(\lambda,t)$ where $t (\geq 1)$ may not be assumed integral."" What exactly is this exercise asking for? More generally, what is meant by ""sampling from a distribution"" (or ""sampling from a density"")? Section 4.11 of the given textbook refers to ""sampling"" over and over, but doesn't define it. It seems, based on the examples, that it means to simply find a random variable with the given distribution. If that's correct, why is it called ""sampling""? Am I supposed to use a computer for this exercise?","Exercise 4.11.3 of Grimmett and Stirzaker's Probability and Random Processes reads ""Use the rejection method to sample from the gamma density $\Gamma(\lambda,t)$ where $t (\geq 1)$ may not be assumed integral."" What exactly is this exercise asking for? More generally, what is meant by ""sampling from a distribution"" (or ""sampling from a density"")? Section 4.11 of the given textbook refers to ""sampling"" over and over, but doesn't define it. It seems, based on the examples, that it means to simply find a random variable with the given distribution. If that's correct, why is it called ""sampling""? Am I supposed to use a computer for this exercise?",,"['probability', 'statistics', 'sampling']"
14,Computing quadratic variation for stable Levy flights with $0<\alpha<2$?,Computing quadratic variation for stable Levy flights with ?,0<\alpha<2,"The wiki page on semi-martingales states that Every Lévy process is a semimartingale. and that The quadratic variation exists for every semimartingale. Let $X_t$ be a stable Levy process with $X_t$ distributed as $S(\alpha, \beta, \mu \, t, \sigma \, t^{\frac{1}{\alpha}} ; 0)$. It's increments  $X_{t+ \delta t}-X_t$ follow $ \mu \, \delta t + \sigma \, {\delta t}^{\frac{1}{\alpha}} Y$, where $Y$ follows standard stable distribution $S(\alpha, \beta, 0, 1\, ; 0)$. Now the quadratic variation of such a process: $$  [X]_t = \lim_{\vert\vert P \vert\vert \to 0} \sum_i (X_{t_{i+1}}- X_{t_i})^2 = \lim_{\vert\vert P \vert\vert \to 0} \sum_i (\mu \, \delta t_i + \sigma \, {\delta t_i}^{\frac{1}{\alpha}} Y_i)^2 $$ To simplify things, assume that $\mu = 0$, and that $\delta t_i$ are the same, i.e. $\delta t_i = t/n$: $$  [X]_t = \sigma^2 t^{\frac{2}{\alpha}}  \lim_{n \to \infty} {n}^{-\frac{2}{\alpha}} \sum_{i=0}^{n-1} Y_i^2 $$ For $\alpha =2$ the limiting random variable is that of $S/n$ where $S$ follows $\chi^2_{n}$ which converges to a degenerate distribution concentrated at $x=1$. Added : The sum can not converge in probability to a degenerate distribution for $\alpha<2$, because $\mathbb{E}(Y_i^2) = \infty$ for $0<\alpha<2$, which implies the convergence in distribution should be to a distribution with infinite mean. Simulation shows this is indeed the case: How can I formally see that the above limit does converge in probability ? Was the limiting distribution studied, even if only in the symmetric case of $\beta=0$ ? Thank you.","The wiki page on semi-martingales states that Every Lévy process is a semimartingale. and that The quadratic variation exists for every semimartingale. Let $X_t$ be a stable Levy process with $X_t$ distributed as $S(\alpha, \beta, \mu \, t, \sigma \, t^{\frac{1}{\alpha}} ; 0)$. It's increments  $X_{t+ \delta t}-X_t$ follow $ \mu \, \delta t + \sigma \, {\delta t}^{\frac{1}{\alpha}} Y$, where $Y$ follows standard stable distribution $S(\alpha, \beta, 0, 1\, ; 0)$. Now the quadratic variation of such a process: $$  [X]_t = \lim_{\vert\vert P \vert\vert \to 0} \sum_i (X_{t_{i+1}}- X_{t_i})^2 = \lim_{\vert\vert P \vert\vert \to 0} \sum_i (\mu \, \delta t_i + \sigma \, {\delta t_i}^{\frac{1}{\alpha}} Y_i)^2 $$ To simplify things, assume that $\mu = 0$, and that $\delta t_i$ are the same, i.e. $\delta t_i = t/n$: $$  [X]_t = \sigma^2 t^{\frac{2}{\alpha}}  \lim_{n \to \infty} {n}^{-\frac{2}{\alpha}} \sum_{i=0}^{n-1} Y_i^2 $$ For $\alpha =2$ the limiting random variable is that of $S/n$ where $S$ follows $\chi^2_{n}$ which converges to a degenerate distribution concentrated at $x=1$. Added : The sum can not converge in probability to a degenerate distribution for $\alpha<2$, because $\mathbb{E}(Y_i^2) = \infty$ for $0<\alpha<2$, which implies the convergence in distribution should be to a distribution with infinite mean. Simulation shows this is indeed the case: How can I formally see that the above limit does converge in probability ? Was the limiting distribution studied, even if only in the symmetric case of $\beta=0$ ? Thank you.",,"['probability', 'probability-distributions', 'stochastic-processes', 'levy-processes', 'quadratic-variation']"
15,Conditional density of two jointly gaussian random vectors,Conditional density of two jointly gaussian random vectors,,"In my estimation theory textbook, the following is stated as a reminder without any further explanation: Consider the gaussian random vector $\bf{z} = \begin{pmatrix}\bf{x} \\ \bf{y}\end{pmatrix}$ with mean $\hat{z} = \begin{pmatrix}\hat{x} \\ \hat{y}\end{pmatrix}$ and covariance matrix $\bf{C}_z = \begin{pmatrix} \bf{C}_{xx} & \bf{C}_{xy} \\ \bf{C}_{yx} & \bf{C}_{yy} \end{pmatrix}$ If a measurement $y^*$ is given, the conditional density of $x$ conditioned on that measurement $f\left(x | y^*\right)$ is gaussian with mean $\hat{x} + \bf{C}_{xy}\bf{C}_{yy}^{-1} \left( y^* - \hat{y} \right)$ and covariance matrix $\bf{C}_{xx} - \bf{C}_{xy} \bf{C}_{yy}^{-1} \bf{C}_{yx}$ (Pseudo-inverses replace inverses when necessary) Having never worked with conditional densities before, I don't see how to derive these formulas, or what the intuition behind them is.","In my estimation theory textbook, the following is stated as a reminder without any further explanation: Consider the gaussian random vector $\bf{z} = \begin{pmatrix}\bf{x} \\ \bf{y}\end{pmatrix}$ with mean $\hat{z} = \begin{pmatrix}\hat{x} \\ \hat{y}\end{pmatrix}$ and covariance matrix $\bf{C}_z = \begin{pmatrix} \bf{C}_{xx} & \bf{C}_{xy} \\ \bf{C}_{yx} & \bf{C}_{yy} \end{pmatrix}$ If a measurement $y^*$ is given, the conditional density of $x$ conditioned on that measurement $f\left(x | y^*\right)$ is gaussian with mean $\hat{x} + \bf{C}_{xy}\bf{C}_{yy}^{-1} \left( y^* - \hat{y} \right)$ and covariance matrix $\bf{C}_{xx} - \bf{C}_{xy} \bf{C}_{yy}^{-1} \bf{C}_{yx}$ (Pseudo-inverses replace inverses when necessary) Having never worked with conditional densities before, I don't see how to derive these formulas, or what the intuition behind them is.",,"['probability', 'statistics']"
16,probability that point is within triangle formed by three lines of bearing,probability that point is within triangle formed by three lines of bearing,,"This is a basic probability problem, and I can get the solution. But for a while I was using a wrong approach. My question for the forum is why my initial approach was wrong. The problem: You're on a ship sailing off a coast in a 2-dimensional world, and to fix your position you take three lines of bearing. Each of the three readings is independent and has independent errors. Errors are symmetrical for each bearing, i.e. you're equally likely to get a bearing which is too high as a bearing which is too low. The three observed lines of bearing will form a triangle. What is the probability of your ship being inside the triangle. The solution: The probability is 25%. To see this, consider each line of bearing as having equal probability of being too high or too low. You therefore have eight error possibilities: +++, ++-, +-+, etc. If you draw out all eight, you'll see that in two of them the ship is in the triangle formed. Hence, 25%. My original, incorrect approach: I drew out three observed lines of bearing, and considered the possibility that the ship was in the triangle formed. However, the three lines divide the plane into only seven areas. In this approach, I considered the probability that the ship was ""above"" or ""below"" a given line of bearing as 50%. (As opposed to the correct approach, where the probability that an observed line was ""above"" or ""below"" the correct position of the ship was 50%.) But, like I said, the ship has only seven (not eight) possible combinations of ""above"" and ""below"" for the three lines of bearing -- one of those eight combinations is a geometrical impossibility. So this line of reasoning was not fruitful, and I couldn't get anywhere until I thought the correct way. My question for the forum: Why was my original approach wrong? I'm thinking it has something to do with considering the position of the ship as the random variable rather than the errors of each bearing line as random variables. Or else, in drawing three bearing lines, I'm already excluding some probabilities (i.e. making a choice)? I know I'm being fast and loose with my terminology, but I'm hoping that if you think of three bearing lines on a plane, my meanings are clear.","This is a basic probability problem, and I can get the solution. But for a while I was using a wrong approach. My question for the forum is why my initial approach was wrong. The problem: You're on a ship sailing off a coast in a 2-dimensional world, and to fix your position you take three lines of bearing. Each of the three readings is independent and has independent errors. Errors are symmetrical for each bearing, i.e. you're equally likely to get a bearing which is too high as a bearing which is too low. The three observed lines of bearing will form a triangle. What is the probability of your ship being inside the triangle. The solution: The probability is 25%. To see this, consider each line of bearing as having equal probability of being too high or too low. You therefore have eight error possibilities: +++, ++-, +-+, etc. If you draw out all eight, you'll see that in two of them the ship is in the triangle formed. Hence, 25%. My original, incorrect approach: I drew out three observed lines of bearing, and considered the possibility that the ship was in the triangle formed. However, the three lines divide the plane into only seven areas. In this approach, I considered the probability that the ship was ""above"" or ""below"" a given line of bearing as 50%. (As opposed to the correct approach, where the probability that an observed line was ""above"" or ""below"" the correct position of the ship was 50%.) But, like I said, the ship has only seven (not eight) possible combinations of ""above"" and ""below"" for the three lines of bearing -- one of those eight combinations is a geometrical impossibility. So this line of reasoning was not fruitful, and I couldn't get anywhere until I thought the correct way. My question for the forum: Why was my original approach wrong? I'm thinking it has something to do with considering the position of the ship as the random variable rather than the errors of each bearing line as random variables. Or else, in drawing three bearing lines, I'm already excluding some probabilities (i.e. making a choice)? I know I'm being fast and loose with my terminology, but I'm hoping that if you think of three bearing lines on a plane, my meanings are clear.",,['probability']
17,Diffusions - global and local,Diffusions - global and local,,"Suppose $dX_t = \mu(X_t)dt + \sigma(X_t)dW_t$ is a diffusion. Is there a sense in which the dynamics are ""dominated"" locally by the diffusion term, and dominated globally by the drift term? If $\mu$ and $\sigma$ are constants, then the law of the iterated logarithm says that the contribution from the diffusion term is slightly greater than $\sqrt{t}$, whereas the contribution from the drift term is linear. On the other hand, over small timescales, small variations in the noise dominate any estimate one can make of the drift term. Does a similar principle apply to more general diffusions?","Suppose $dX_t = \mu(X_t)dt + \sigma(X_t)dW_t$ is a diffusion. Is there a sense in which the dynamics are ""dominated"" locally by the diffusion term, and dominated globally by the drift term? If $\mu$ and $\sigma$ are constants, then the law of the iterated logarithm says that the contribution from the diffusion term is slightly greater than $\sqrt{t}$, whereas the contribution from the drift term is linear. On the other hand, over small timescales, small variations in the noise dominate any estimate one can make of the drift term. Does a similar principle apply to more general diffusions?",,"['probability', 'intuition', 'stochastic-processes']"
18,Complexity - why is RL=NL when omitting the demand for polynomial run-time?,Complexity - why is RL=NL when omitting the demand for polynomial run-time?,,"The complexity class RL is described at the complexity zoo as: Has the same relation to L as RP does to P. The randomized machine must halt with probability 1 on any input. It must also run in polynomial time (since otherwise we would just get NL). The question is - how can we get NL when omitting the demand for polynomial time? I have a solution of my own but it seems strange to me. My solution: If suffices to solve ST-CON. We can use the same NL algorithm for ST-CON (guessing a path) with one major difference - we count the number of steps we make, and if it suppresses the number of vertices in the graph, we restart the computation, without remembering ANYTHING. This means we can play this game indefinitely. If the graph is not ST-connected, then we'll never halt, but if it's ST-connected we'll halt in probability 1 (this is the same as saying that a geometric random variable obtains a finite value in probability 1). However, since we do not halt for NO-instances, this solution ""feels wrong"" to me. Is there another solution? And is my solution correct?","The complexity class RL is described at the complexity zoo as: Has the same relation to L as RP does to P. The randomized machine must halt with probability 1 on any input. It must also run in polynomial time (since otherwise we would just get NL). The question is - how can we get NL when omitting the demand for polynomial time? I have a solution of my own but it seems strange to me. My solution: If suffices to solve ST-CON. We can use the same NL algorithm for ST-CON (guessing a path) with one major difference - we count the number of steps we make, and if it suppresses the number of vertices in the graph, we restart the computation, without remembering ANYTHING. This means we can play this game indefinitely. If the graph is not ST-connected, then we'll never halt, but if it's ST-connected we'll halt in probability 1 (this is the same as saying that a geometric random variable obtains a finite value in probability 1). However, since we do not halt for NO-instances, this solution ""feels wrong"" to me. Is there another solution? And is my solution correct?",,"['algorithms', 'probability', 'computer-science']"
19,Convergence of Step Functions Generated by Uniformly Distributed Random Points,Convergence of Step Functions Generated by Uniformly Distributed Random Points,,"I have encountered a surprisingly complicated problem to solve and I'm looking for some help. It could be difficult because I don't have a background in probability and so don't know the appropriate terms to search, or it is a genuinely difficult thing to prove. Preamble: Let $f:[0,1] \to \mathbb{R}$ be a continuous function. Then, for $n\geq 1$ we consider evenly spaced points $0 \leq x_1 < x_2 < \dots < x_n \leq 1$ and a partition $\mathcal{P}_n$ of the interval $[0,1]$ into exactly $n$ disjoint intervals so that each $x_i$ belongs to exactly one of these partition intervals. Using these points and the partition we can construct a step function approximation of $f$ , denoted $f_n$ , by assigning $f_n(x) = f(x_k)$ for all $x$ in the $k$ th partition interval. Then, a typical exercise one might encounter in real analysis is to prove that $\lim_{n\to \infty} \|f_n - f\|_\infty \to 0$ , which follows form the uniform continuity of $f$ . My Problem: Now, suppose that for $n\geq 1$ we have $u_1,\dots,u_n$ drawn independently form the uniform distribution on $[0,1]$ and we set the $x_1,\dots,x_n$ to be the corresponding order statistics. My question is: if we construct the step functions $f_n$ as above, can we still get uniform convergence to the original function $f$ with high probability? What I have so Far: A previous question on here has provided that if the $x_1,\dots,x_n$ are the order statistics of the i.i.d. points $u_1,\dots,u_n$ we have that $$\mathbb{P}\bigg(\max_{1 \leq k \leq n} |x_{k+1} - x_{k}| \leq \delta \bigg) = \sum_{k = 0}^{\lfloor 1/\delta\rfloor} (-1)^k{n+1\choose k}(1 - k\delta)^n $$ where $x_0 = 0$ , $x_{n+1} = 1$ , and for all $\delta \in [1/(n+1),1]$ . Of course, once one can argue that with high probability the points become close together, one can again use uniform continuity of $f$ on $[0,1]$ to get the desired result. However, I'm unable to get anything asymptotic out of the above formula. I've run simulations with $\delta = 1/\sqrt{n}$ , for example, and the above probability quickly converges to 1 as $n \to \infty$ , but again, I can't prove it. Question: It seemed to me that my problem would have been answered at some point in the mathematical literature, but I can't find any reference. Therefore, could someone either point me to a reference or help me out with a proof here? Thank you!","I have encountered a surprisingly complicated problem to solve and I'm looking for some help. It could be difficult because I don't have a background in probability and so don't know the appropriate terms to search, or it is a genuinely difficult thing to prove. Preamble: Let be a continuous function. Then, for we consider evenly spaced points and a partition of the interval into exactly disjoint intervals so that each belongs to exactly one of these partition intervals. Using these points and the partition we can construct a step function approximation of , denoted , by assigning for all in the th partition interval. Then, a typical exercise one might encounter in real analysis is to prove that , which follows form the uniform continuity of . My Problem: Now, suppose that for we have drawn independently form the uniform distribution on and we set the to be the corresponding order statistics. My question is: if we construct the step functions as above, can we still get uniform convergence to the original function with high probability? What I have so Far: A previous question on here has provided that if the are the order statistics of the i.i.d. points we have that where , , and for all . Of course, once one can argue that with high probability the points become close together, one can again use uniform continuity of on to get the desired result. However, I'm unable to get anything asymptotic out of the above formula. I've run simulations with , for example, and the above probability quickly converges to 1 as , but again, I can't prove it. Question: It seemed to me that my problem would have been answered at some point in the mathematical literature, but I can't find any reference. Therefore, could someone either point me to a reference or help me out with a proof here? Thank you!","f:[0,1] \to \mathbb{R} n\geq 1 0 \leq x_1 < x_2 < \dots < x_n \leq 1 \mathcal{P}_n [0,1] n x_i f f_n f_n(x) = f(x_k) x k \lim_{n\to \infty} \|f_n - f\|_\infty \to 0 f n\geq 1 u_1,\dots,u_n [0,1] x_1,\dots,x_n f_n f x_1,\dots,x_n u_1,\dots,u_n \mathbb{P}\bigg(\max_{1 \leq k \leq n} |x_{k+1} - x_{k}| \leq \delta \bigg) = \sum_{k = 0}^{\lfloor 1/\delta\rfloor} (-1)^k{n+1\choose k}(1 - k\delta)^n  x_0 = 0 x_{n+1} = 1 \delta \in [1/(n+1),1] f [0,1] \delta = 1/\sqrt{n} n \to \infty","['real-analysis', 'probability', 'statistics', 'uniform-convergence', 'order-statistics']"
20,How to Evaluate a Multi Variable Derivative?,How to Evaluate a Multi Variable Derivative?,,"I am an engineering student learning about Copulas ( https://en.wikipedia.org/wiki/Copula_(probability_theory) ) for my bachelor's project (2 years from now). I am interested in using them for the purpose of simulating correlated failure times of machine parts. I have been self-studying topics in Probability Theory for the last year. As I understand, a Copula Function is basically a CDF (Cumulative Density Function) of correlated Random Variables: $$C(u_1,u_2,\dots,u_d)=\Pr[X_1\leq F_1^{-1}(u_1),X_2\leq F_2^{-1}(u_2),\dots,X_d\leq F_d^{-1}(u_d)]$$ $$c(u_1,u_2,\dots,u_d) = \frac{\partial^d}{\partial u_1 \partial u_2 \dots \partial u_d} C(u_1,u_2,\dots,u_d)$$ I am interested in trying to understand the following question: Given some real world data, how exactly do we estimate the parameters of a given Copula function? For the Non-Copula case, this looks pretty straightforward to understand. For some generic probability distribution function $p(x;\theta)$ where $x$ is the data and $\theta$ is the parameter vector, I can differentiate the log-likelihood function $l(x, \theta)$ with respect to all $\theta$ parameters, set the derivatives to 0 and estimate all parameters. However, I am not sure how to repeat this process for the Copula case. For example, suppose I choose a Gaussian Copula (here, $u$ is a Uniform Random Variable): $$\text{Standard Normal CDF:} \quad   F(x) = \frac{1}{\sqrt{2\pi}} \int_{-\infty}^{x} e^{-\frac{1}{2}t^2} dt $$ $$\text{Inverse of a Standard Normal CDF (undefined, needs to be numerically calculated)} : \quad F^{-1}$$ $$ \text{Joint Normal CDF with mean=0 and correlation matrix R:} \quad F(y_1, y_2, ..., y_n) = \frac{1}{(2\pi)^{n/2} |R|^{1/2}} \int_{-\infty}^{y_1} \cdots \int_{-\infty}^{y_n} e^{-\frac{1}{2} \mathbf{y}^T R^{-1} \mathbf{y}} dy_1 \cdots dy_n $$ $$ \text{Gaussian Copula :} \quad  C(u_1, u_2, ..., u_n) = \Phi_{\rho}(F^{-1}(u_1), F^{-1}(u_2), ..., F^{-1}(u_n))$$ $$ C(u_1, u_2, ..., u_n) = \frac{1}{(2\pi)^{n/2} |R|^{1/2}} \int_{-\infty}^{F^{-1}(u_1)} \cdots \int_{-\infty}^{F^{-1}(u_n)} e^{-\frac{1}{2} \mathbf{x}^T R^{-1} \mathbf{x}} dx_1 \cdots dx_n $$ I can also write the Probability Distribution Function and the Log-Likelihood function for a Gaussian Multivariate : $$ \text{Multivariate Normal:} \quad  f(x) = \frac{1}{\sqrt{(2\pi)^k|\Sigma|}} \exp\left(-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu)\right) $$ $$ \rho_{ij} = \frac{\sigma_{ij}}{\sqrt{\sigma_{ii}\sigma_{jj}}} $$ $$ L(\mu, \Sigma | X) = \prod_{i=1}^{n} f(x_i | \mu, \Sigma) $$ $$ f(x_i | \mu, \Sigma) = \frac{1}{\sqrt{(2\pi)^k|\Sigma|}} \exp\left(-\frac{1}{2}(x_i-\mu)^T\Sigma^{-1}(x_i-\mu)\right) $$ $$ \log L(\mu, \Sigma | X) = \sum_{i=1}^{n} \log f(x_i | \mu, \Sigma) $$ $$ \log L(\mu, \Sigma | X) = -\frac{nk}{2} \log(2\pi) - \frac{n}{2} \log|\Sigma| - \frac{1}{2} \sum_{i=1}^{n} (x_i-\mu)^T\Sigma^{-1}(x_i-\mu) $$ I am not sure how exactly we would set up the likelihood function for this Copula to estimate its parameters. For example, suppose I have two random variables $x_1$ and $x_2$ . I believe they each have marginal distributions that follow an Exponential Probability Distribution $x_i \sim Exp(\lambda_i)$ . My goal is to model both of these Exponential Random Variables using a Gaussian Copula. Prior to doing even beginning to do Copula estimation, I would first use standard MLE (Maximum Likelihood Estimation) to estimate each $\lambda_i$ independently. From here, I would transform the original random variables into the following format (Uniform Transformation via the CDF): $$u_i = F(x_i|\lambda_i) = 1 - e^{-\lambda_i x_i}$$ Estimating the parameters of the Copula will now be done on the transformed data using $u_i$ and not the original data $x_i$ . After this point, note that the only parameters that need to be estimated are all the correlation parameters** $\rho$ which themselves are a function of $\sigma_{i,j}$ . Since a Copula Function is basically a CDF, I think we can try to determine the corresponding PDF using the derivative-integral relationship: $$ f_{C_\Sigma}(u) = \frac{\partial^n C_\Sigma(u)}{\partial u_1 \partial u_2 ... \partial u_n} $$ From here, I might be able to then write the Likelihood function of this Copula: $$ L(\Sigma; u) = \prod_{i=1}^{n} f_{C_\Sigma}(u_i) $$ At this point, I am confused and longer sure how to proceed. I am not sure what will be the exact function form of $ f_{C_\Sigma}(u_i)$ . The multivariate derivative looks very complicated. I am guessing that it might be related to the pdf of a multivariate normal? $$ f_{C_\Sigma}(u) = \frac{1}{\sqrt{det(\Sigma)}} e^{-\frac{1}{2} z^T (I - \Sigma^{-1}) z} $$ where $z = (\Phi^{-1}(u_1), \Phi^{-1}(u_2), ..., \Phi^{-1}(u_n))^T$ , $\Sigma$ is the correlation matrix, and $I$ is an identity matrix. Can someone please show me how to do this? From a given choice of Copula function, how would I write its corresponding likelihood function?","I am an engineering student learning about Copulas ( https://en.wikipedia.org/wiki/Copula_(probability_theory) ) for my bachelor's project (2 years from now). I am interested in using them for the purpose of simulating correlated failure times of machine parts. I have been self-studying topics in Probability Theory for the last year. As I understand, a Copula Function is basically a CDF (Cumulative Density Function) of correlated Random Variables: I am interested in trying to understand the following question: Given some real world data, how exactly do we estimate the parameters of a given Copula function? For the Non-Copula case, this looks pretty straightforward to understand. For some generic probability distribution function where is the data and is the parameter vector, I can differentiate the log-likelihood function with respect to all parameters, set the derivatives to 0 and estimate all parameters. However, I am not sure how to repeat this process for the Copula case. For example, suppose I choose a Gaussian Copula (here, is a Uniform Random Variable): I can also write the Probability Distribution Function and the Log-Likelihood function for a Gaussian Multivariate : I am not sure how exactly we would set up the likelihood function for this Copula to estimate its parameters. For example, suppose I have two random variables and . I believe they each have marginal distributions that follow an Exponential Probability Distribution . My goal is to model both of these Exponential Random Variables using a Gaussian Copula. Prior to doing even beginning to do Copula estimation, I would first use standard MLE (Maximum Likelihood Estimation) to estimate each independently. From here, I would transform the original random variables into the following format (Uniform Transformation via the CDF): Estimating the parameters of the Copula will now be done on the transformed data using and not the original data . After this point, note that the only parameters that need to be estimated are all the correlation parameters** which themselves are a function of . Since a Copula Function is basically a CDF, I think we can try to determine the corresponding PDF using the derivative-integral relationship: From here, I might be able to then write the Likelihood function of this Copula: At this point, I am confused and longer sure how to proceed. I am not sure what will be the exact function form of . The multivariate derivative looks very complicated. I am guessing that it might be related to the pdf of a multivariate normal? where , is the correlation matrix, and is an identity matrix. Can someone please show me how to do this? From a given choice of Copula function, how would I write its corresponding likelihood function?","C(u_1,u_2,\dots,u_d)=\Pr[X_1\leq F_1^{-1}(u_1),X_2\leq F_2^{-1}(u_2),\dots,X_d\leq F_d^{-1}(u_d)] c(u_1,u_2,\dots,u_d) = \frac{\partial^d}{\partial u_1 \partial u_2 \dots \partial u_d} C(u_1,u_2,\dots,u_d) p(x;\theta) x \theta l(x, \theta) \theta u \text{Standard Normal CDF:} \quad   F(x) = \frac{1}{\sqrt{2\pi}} \int_{-\infty}^{x} e^{-\frac{1}{2}t^2} dt  \text{Inverse of a Standard Normal CDF (undefined, needs to be numerically calculated)} : \quad F^{-1}  \text{Joint Normal CDF with mean=0 and correlation matrix R:} \quad F(y_1, y_2, ..., y_n) = \frac{1}{(2\pi)^{n/2} |R|^{1/2}} \int_{-\infty}^{y_1} \cdots \int_{-\infty}^{y_n} e^{-\frac{1}{2} \mathbf{y}^T R^{-1} \mathbf{y}} dy_1 \cdots dy_n   \text{Gaussian Copula :} \quad  C(u_1, u_2, ..., u_n) = \Phi_{\rho}(F^{-1}(u_1), F^{-1}(u_2), ..., F^{-1}(u_n))  C(u_1, u_2, ..., u_n) = \frac{1}{(2\pi)^{n/2} |R|^{1/2}} \int_{-\infty}^{F^{-1}(u_1)} \cdots \int_{-\infty}^{F^{-1}(u_n)} e^{-\frac{1}{2} \mathbf{x}^T R^{-1} \mathbf{x}} dx_1 \cdots dx_n  
\text{Multivariate Normal:} \quad  f(x) = \frac{1}{\sqrt{(2\pi)^k|\Sigma|}} \exp\left(-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu)\right)
 
\rho_{ij} = \frac{\sigma_{ij}}{\sqrt{\sigma_{ii}\sigma_{jj}}}
 
L(\mu, \Sigma | X) = \prod_{i=1}^{n} f(x_i | \mu, \Sigma)
 
f(x_i | \mu, \Sigma) = \frac{1}{\sqrt{(2\pi)^k|\Sigma|}} \exp\left(-\frac{1}{2}(x_i-\mu)^T\Sigma^{-1}(x_i-\mu)\right)
 
\log L(\mu, \Sigma | X) = \sum_{i=1}^{n} \log f(x_i | \mu, \Sigma)
 
\log L(\mu, \Sigma | X) = -\frac{nk}{2} \log(2\pi) - \frac{n}{2} \log|\Sigma| - \frac{1}{2} \sum_{i=1}^{n} (x_i-\mu)^T\Sigma^{-1}(x_i-\mu)
 x_1 x_2 x_i \sim Exp(\lambda_i) \lambda_i u_i = F(x_i|\lambda_i) = 1 - e^{-\lambda_i x_i} u_i x_i \rho \sigma_{i,j} 
f_{C_\Sigma}(u) = \frac{\partial^n C_\Sigma(u)}{\partial u_1 \partial u_2 ... \partial u_n}
 
L(\Sigma; u) = \prod_{i=1}^{n} f_{C_\Sigma}(u_i)
  f_{C_\Sigma}(u_i) 
f_{C_\Sigma}(u) = \frac{1}{\sqrt{det(\Sigma)}} e^{-\frac{1}{2} z^T (I - \Sigma^{-1}) z}
 z = (\Phi^{-1}(u_1), \Phi^{-1}(u_2), ..., \Phi^{-1}(u_n))^T \Sigma I",['probability']
21,Analyzing Cumulative Distribution Functions in Sampling Without Replacement vs. With Replacement,Analyzing Cumulative Distribution Functions in Sampling Without Replacement vs. With Replacement,,"I am studying a population of $N$ bits, comprising $K$ ones and $N-K$ zeros. For sampling $n$ bits without replacement, the situation conforms to a hypergeometric distribution. The sum of these $n$ bits, $S_n$ , yields a mean of $n\frac{K}{N}$ and a variance of $n \frac{K}{N} \frac{N-K}{N} \frac{N-n}{N-1}$ . Conversely, sampling $n'$ bits with replacement aligns with a binomial distribution, with the sum $S_{n'}$ having a mean of $n'\frac{K}{N}$ and a variance of $n' \frac{K}{N} \frac{N-K}{N}$ . For my analysis, I plotted the cumulative distribution functions (CDFs) for the normalized sums $\frac{S_n}{n}$ and $\frac{S_{n'}}{n'}$ , considering values of $n'$ within the range $\left[n,\lfloor n\frac{N-1}{N-n}\rfloor\right]$ . I observed that for normalized sums exceeding $\frac{K}{N}$ , the binomial CDF consistently lies below the hypergeometric CDF. The trend is longer followed for $n'>n\frac{N-1}{N-n}$ . It is noted that the variance of the normalised hypergeometric distribution is lower than that of the binomial distribution if $n'<n\frac{N-1}{N-n}$ . If $X$ is a hypergeometric distribution with n draws without replacement from a population of size $N$ with $K$ successes and $Y$ is a binomial distribution $B(n',K/N)$ , then what is the maximum $n'$ for which $F_Y(f n')\leq F_X(f  n)$ for $f\geq K/N$ ? . I suppose that the maximum $n'= \lfloor n\frac{N-1}{N-n}\rfloor$ . Heres an animation for $\frac{K}{N}=0.5$ , with $N=50$ where the number of binomial trials is fixed at $n'=n\frac{N-1}{N-n}=21$ and number of hypergeometric trials is fixed at $n=15$ . The portion marked green is the region where the normalized sums are greater than $p=\frac{K}{N}$ . In this region the binomial CDF is below the hypergeometric CDF. I'm curious if this relationship between the distributions' CDFs is a recognized phenomenon. Does anyone know of relevant research articles on this topic? Additionally, here’s the Mathematica code used for generating these plots, adjustable for different $p=K/N$ values: Manipulate[Nx = 10^2;  n = 30;  x = p Nx;  ListPlot[{Table[{k/Floor[binomialtrials],       CDF[BinomialDistribution[Floor[binomialtrials], p], k]}, {k, 1,       Floor[binomialtrials]}],     Table[{k/n,       CDF[HypergeometricDistribution[n, Floor[x], Nx], k]}, {k, 1,       n}]}, Joined -> True, PlotRange -> All,    PlotLegends -> {""bin"", ""hype""},    Epilog -> {RGBColor[0, 1, 0, 0.25], Rectangle[{p, 0}, {1, 1}], Red,      Line[{{p, 0}, {p, 1}}]}], {binomialtrials, n, n (Nx - 1)/(Nx - n),    1}, {p, 10^-2, 1}] Does anyone have insights or references which might explain this pattern? EDIT Let $h(x;n,N,K)$ denote the probability mass function of the hypergeometric distribution and $b(x;n,p)$ that of binomial distribution, where $p=K/N$ .I need to compare the hypergeometric distribution and the modified binomial distribution, where the number of samples $n'=a n$ , where $a= \frac {N-1}{N-n}$ .Denoting $x'=a x $ , let us first figure out the ration $\frac{h(x;n,N,K)}{b(x';n',p)}$ . Note that in general $x'$ and $n'$ need not be integers. For simplicity lets start by assuming they are. Now we can compare the probabilities. $$ \begin{aligned} \frac{h(x;n,N,K)}{b(ax;an,p)}&=&\frac{b(x;n,p)}{b(ax;an,p)}\frac{h(x;n,N,K)}{b(x;n,p)}\\ &=&\frac{{n\choose x}p^x(1-p)^{n-x}}{{an\choose ax}p^{ax}(1-p)^{a(n-x)}}\frac{h(x;n,N,K)}{b(x;n,p)}\\ &=& \frac{n!}{x!(n-x)!}\frac{(ax)! (a(n-x))!}{(an)!}p^{x-ax}(1-p)^{(n-x)-(a(n-x))}\frac{h(x;n,N,K)}{b(x;n,p)}\\ \end{aligned} $$ Applying stirlings approximation $n!\sim \sqrt{2 \pi n}\left(\frac{n}{e}\right)^n$ , we get, $$ \begin{aligned} \frac{h(x;n,N,K)}{b(ax;an,p)}&\sim&\sqrt{a}\left(\frac{(1-x/n)^{n-x}(x/n)^{x}}{(1-K/N)^{n-x}(K/N)^{x}}\right)^{a-1} \frac{h(x;n,N,K)}{b(x;n,p)}\\ &\sim& \sqrt{a}\left(\left(\frac{N}{n}\right)^n\left(\frac{x}{K}\right)^x\left(\frac{n-x}{N-K}\right)^{n-x}\right)^{a-1}\frac{h(x;n,N,K)}{b(x;n,p)}\\ \end{aligned} $$ I'm stuck here. My goal here is to proceed similar to this answer by LPZ .","I am studying a population of bits, comprising ones and zeros. For sampling bits without replacement, the situation conforms to a hypergeometric distribution. The sum of these bits, , yields a mean of and a variance of . Conversely, sampling bits with replacement aligns with a binomial distribution, with the sum having a mean of and a variance of . For my analysis, I plotted the cumulative distribution functions (CDFs) for the normalized sums and , considering values of within the range . I observed that for normalized sums exceeding , the binomial CDF consistently lies below the hypergeometric CDF. The trend is longer followed for . It is noted that the variance of the normalised hypergeometric distribution is lower than that of the binomial distribution if . If is a hypergeometric distribution with n draws without replacement from a population of size with successes and is a binomial distribution , then what is the maximum for which for ? . I suppose that the maximum . Heres an animation for , with where the number of binomial trials is fixed at and number of hypergeometric trials is fixed at . The portion marked green is the region where the normalized sums are greater than . In this region the binomial CDF is below the hypergeometric CDF. I'm curious if this relationship between the distributions' CDFs is a recognized phenomenon. Does anyone know of relevant research articles on this topic? Additionally, here’s the Mathematica code used for generating these plots, adjustable for different values: Manipulate[Nx = 10^2;  n = 30;  x = p Nx;  ListPlot[{Table[{k/Floor[binomialtrials],       CDF[BinomialDistribution[Floor[binomialtrials], p], k]}, {k, 1,       Floor[binomialtrials]}],     Table[{k/n,       CDF[HypergeometricDistribution[n, Floor[x], Nx], k]}, {k, 1,       n}]}, Joined -> True, PlotRange -> All,    PlotLegends -> {""bin"", ""hype""},    Epilog -> {RGBColor[0, 1, 0, 0.25], Rectangle[{p, 0}, {1, 1}], Red,      Line[{{p, 0}, {p, 1}}]}], {binomialtrials, n, n (Nx - 1)/(Nx - n),    1}, {p, 10^-2, 1}] Does anyone have insights or references which might explain this pattern? EDIT Let denote the probability mass function of the hypergeometric distribution and that of binomial distribution, where .I need to compare the hypergeometric distribution and the modified binomial distribution, where the number of samples , where .Denoting , let us first figure out the ration . Note that in general and need not be integers. For simplicity lets start by assuming they are. Now we can compare the probabilities. Applying stirlings approximation , we get, I'm stuck here. My goal here is to proceed similar to this answer by LPZ .","N K N-K n n S_n n\frac{K}{N} n \frac{K}{N} \frac{N-K}{N} \frac{N-n}{N-1} n' S_{n'} n'\frac{K}{N} n' \frac{K}{N} \frac{N-K}{N} \frac{S_n}{n} \frac{S_{n'}}{n'} n' \left[n,\lfloor n\frac{N-1}{N-n}\rfloor\right] \frac{K}{N} n'>n\frac{N-1}{N-n} n'<n\frac{N-1}{N-n} X N K Y B(n',K/N) n' F_Y(f n')\leq F_X(f  n) f\geq K/N n'= \lfloor n\frac{N-1}{N-n}\rfloor \frac{K}{N}=0.5 N=50 n'=n\frac{N-1}{N-n}=21 n=15 p=\frac{K}{N} p=K/N h(x;n,N,K) b(x;n,p) p=K/N n'=a n a= \frac {N-1}{N-n} x'=a x  \frac{h(x;n,N,K)}{b(x';n',p)} x' n' 
\begin{aligned}
\frac{h(x;n,N,K)}{b(ax;an,p)}&=&\frac{b(x;n,p)}{b(ax;an,p)}\frac{h(x;n,N,K)}{b(x;n,p)}\\
&=&\frac{{n\choose x}p^x(1-p)^{n-x}}{{an\choose ax}p^{ax}(1-p)^{a(n-x)}}\frac{h(x;n,N,K)}{b(x;n,p)}\\
&=& \frac{n!}{x!(n-x)!}\frac{(ax)! (a(n-x))!}{(an)!}p^{x-ax}(1-p)^{(n-x)-(a(n-x))}\frac{h(x;n,N,K)}{b(x;n,p)}\\
\end{aligned}
 n!\sim \sqrt{2 \pi n}\left(\frac{n}{e}\right)^n 
\begin{aligned}
\frac{h(x;n,N,K)}{b(ax;an,p)}&\sim&\sqrt{a}\left(\frac{(1-x/n)^{n-x}(x/n)^{x}}{(1-K/N)^{n-x}(K/N)^{x}}\right)^{a-1} \frac{h(x;n,N,K)}{b(x;n,p)}\\
&\sim& \sqrt{a}\left(\left(\frac{N}{n}\right)^n\left(\frac{x}{K}\right)^x\left(\frac{n-x}{N-K}\right)^{n-x}\right)^{a-1}\frac{h(x;n,N,K)}{b(x;n,p)}\\
\end{aligned}
","['probability', 'probability-distributions', 'upper-lower-bounds', 'cumulative-distribution-functions']"
22,Maximum of Gaussians error check: Expectation of maximum of folded-normally distributed random variables,Maximum of Gaussians error check: Expectation of maximum of folded-normally distributed random variables,,"I am trying to show that if $Z_1, Z_2, \ldots, Z_n\sim\mathcal{N}(0, \sigma^2)$ are i.i.d, then $\mathbb{E}[\max(|Z_1|, |Z_2|, \ldots, |Z_n|)]\leq \sigma\sqrt{2\log (2n)}$ . I tried to use the tail bound: $$\mathbb{E}[\max(|Z_1|, |Z_2|, \ldots, |Z_n|)]=\int_0^{\infty}\mathbb{P}(\max(|Z_1|, |Z_2|, \ldots, |Z_n|)>t)dt$$ However, we see that $$\mathbb{P}(\max(|Z_1|, |Z_2|, \ldots, |Z_n|)>t) = \mathbb{P}\left(\bigcup_{i=1}^n\{|Z_i|>t \}\right)\leq \sum_{i=1}^n\mathbb{P}(|Z_i|>t)\leq 2ne^{-t^2/2\sigma^2}$$ so $$\mathbb{E}[\max(|Z_1|, |Z_2|, \ldots, |Z_n|)]\leq 2n\int_0^{\infty} e^{-t^2/2\sigma^2}dt = 2n\sigma\sqrt{2/\pi}$$ which is of course, not the bound I want. Is there any way I can change some of these steps differently to get the bound I want? (Edit: I already looked at this question Expectation of the maximum of gaussian random variables , but the top answer suggested you could also approach this by a union bound and tail bound approach rather than the very nonintuitive exponential approach, so that was what I was trying to emulate.)","I am trying to show that if are i.i.d, then . I tried to use the tail bound: However, we see that so which is of course, not the bound I want. Is there any way I can change some of these steps differently to get the bound I want? (Edit: I already looked at this question Expectation of the maximum of gaussian random variables , but the top answer suggested you could also approach this by a union bound and tail bound approach rather than the very nonintuitive exponential approach, so that was what I was trying to emulate.)","Z_1, Z_2, \ldots, Z_n\sim\mathcal{N}(0, \sigma^2) \mathbb{E}[\max(|Z_1|, |Z_2|, \ldots, |Z_n|)]\leq \sigma\sqrt{2\log (2n)} \mathbb{E}[\max(|Z_1|, |Z_2|, \ldots, |Z_n|)]=\int_0^{\infty}\mathbb{P}(\max(|Z_1|, |Z_2|, \ldots, |Z_n|)>t)dt \mathbb{P}(\max(|Z_1|, |Z_2|, \ldots, |Z_n|)>t) = \mathbb{P}\left(\bigcup_{i=1}^n\{|Z_i|>t \}\right)\leq \sum_{i=1}^n\mathbb{P}(|Z_i|>t)\leq 2ne^{-t^2/2\sigma^2} \mathbb{E}[\max(|Z_1|, |Z_2|, \ldots, |Z_n|)]\leq 2n\int_0^{\infty} e^{-t^2/2\sigma^2}dt = 2n\sigma\sqrt{2/\pi}","['probability', 'statistics', 'normal-distribution']"
23,UMVUEs for the means of $3$ independent normal distributions with the sum of means being $1$,UMVUEs for the means of  independent normal distributions with the sum of means being,3 1,"Let $\theta_1, \theta_2$ and $\theta_3$ be nonnegative parameters with the constraint $\theta_1+\theta_2+\theta_3=1$ . We observe $X_{i 1}=\theta_1+\epsilon_{i 1}, X_{i 2}=\theta_2+\epsilon_{i 2}, X_{i 3}=\theta_3+\epsilon_{i 3}$ for $i=1,2, \ldots, n$ , where $\epsilon_{i k} \sim N(0,1)$ are independent normal random variables $(k=1,2,3)$ . Derive the UMVUE for $\theta_1$ . My problem in solving it is, I don't know how to accurately use the constraint $\theta_1+\theta_2+\theta_3=1$ , and I also don't have any idea what  steps would it be like when finding the UMVUE like this. Can you provide any suggestion/solution for me? Thank you!","Let and be nonnegative parameters with the constraint . We observe for , where are independent normal random variables . Derive the UMVUE for . My problem in solving it is, I don't know how to accurately use the constraint , and I also don't have any idea what  steps would it be like when finding the UMVUE like this. Can you provide any suggestion/solution for me? Thank you!","\theta_1, \theta_2 \theta_3 \theta_1+\theta_2+\theta_3=1 X_{i 1}=\theta_1+\epsilon_{i 1}, X_{i 2}=\theta_2+\epsilon_{i 2}, X_{i 3}=\theta_3+\epsilon_{i 3} i=1,2, \ldots, n \epsilon_{i k} \sim N(0,1) (k=1,2,3) \theta_1 \theta_1+\theta_2+\theta_3=1","['probability', 'probability-theory', 'statistics', 'statistical-inference', 'umvue']"
24,"When does $\mathbb{E}[|X-Y|]\leq\mathbb{E}[X]$ hold for $X,Y\geq 0$ i.i.d.?",When does  hold for  i.i.d.?,"\mathbb{E}[|X-Y|]\leq\mathbb{E}[X] X,Y\geq 0","Let $X,Y\geq 0$ be i.i.d. random variables with a continuous distribution with PDF $f$ and CDF $F$ . My question is: Under what conditions does the following inequality hold, \begin{align} \mathbb{E}[|X-Y|] \leq \mathbb{E}[X]. \end{align} If $X,Y\sim Exp(\lambda)$ , then the above identity can easily be shown to hold with equality. Is it the case that if the distribution is more heavy-tailed than the exponential distribution, then the inequality does not hold? Formally, this would correspond to the hazard rate $f(x)/(1-F(x))$ being nondecreasing (for the exponential distribution the hazard rate is constant).","Let be i.i.d. random variables with a continuous distribution with PDF and CDF . My question is: Under what conditions does the following inequality hold, If , then the above identity can easily be shown to hold with equality. Is it the case that if the distribution is more heavy-tailed than the exponential distribution, then the inequality does not hold? Formally, this would correspond to the hazard rate being nondecreasing (for the exponential distribution the hazard rate is constant).","X,Y\geq 0 f F \begin{align}
\mathbb{E}[|X-Y|] \leq \mathbb{E}[X].
\end{align} X,Y\sim Exp(\lambda) f(x)/(1-F(x))","['probability', 'probability-theory', 'probability-distributions', 'stochastic-processes', 'random-variables']"
25,Is the distribution of the Pearson correlation symmetric around zero?,Is the distribution of the Pearson correlation symmetric around zero?,,"Let $(X_1, Y_1), \ldots, (X_n, Y_n)$ be a sample from a bivariate distribution $\operatorname{Law}(X_1, Y_1)$ . It is known that if $\operatorname{Law}(X_1, Y_1)$ is bivariate normal and $\operatorname{Corr}(X_1, Y_1) = 0$ then the density function of the sample Pearson correlation coefficient $\hat{\rho}(X,Y)$ is $$ f(r) = \frac{(1-r^2)^{\frac{n-4}{2}}}{B(0.5, 0.5(n-2))}, \quad r \in [-1,1] $$ where $$ \hat{\rho}(\mathbf{X},\mathbf{Y}) = \frac{\sum_{i=1}^n (X_i - \overline{X})(Y_i - \overline{Y})}{\sqrt{\sum_{i=1}^n (X_i - \overline{X})^2}\sqrt{\sum_{i=1}^n (Y_i - \overline{Y})^2}}. $$ So in this case the distribution of the sample correlation is symmetric around zero. Will the symmetric property hold for an arbitrary bivariate distribution with square integrable marginals and zero correlation between components? I know how to prove that even in this arbitrary setting $$ \hat{\rho} \xrightarrow[n \to \infty]{d, \mathbb{P}} 0, $$ so the asymptotic distribution of $\hat{\rho}$ is symmetric around zero. What I can't handle is how to prove the property for a fixed $n \in \mathbb{N}$ . Thank you in advance. UPD. More general question: consider the general correlation coefficient $$ \hat{r}_f(\mathbf{X},\mathbf{Y}) := \frac{\sum_{i,j}c_{i,j}(\mathbf{X})c_{i,j}(\mathbf{Y})}{\sqrt{\sum_{i,j}c^2_{i,j}(\mathbf{X})}\sqrt{\sum_{i,j}c^2_{i,j}(\mathbf{Y})}}, $$ where $c_{i,j}(\mathbf{X}) = f(X_i, X_j)$ for some antisymmetric function $f: \mathbb{R}^2 \to \mathbb{R}$ . It is easy to derive that for the Pearson correlation coefficient $f(t,s) = t-s$ . Is $\hat{r}_f$ symmetric around zero assuming $X_1, Y_1$ is independent?",Let be a sample from a bivariate distribution . It is known that if is bivariate normal and then the density function of the sample Pearson correlation coefficient is where So in this case the distribution of the sample correlation is symmetric around zero. Will the symmetric property hold for an arbitrary bivariate distribution with square integrable marginals and zero correlation between components? I know how to prove that even in this arbitrary setting so the asymptotic distribution of is symmetric around zero. What I can't handle is how to prove the property for a fixed . Thank you in advance. UPD. More general question: consider the general correlation coefficient where for some antisymmetric function . It is easy to derive that for the Pearson correlation coefficient . Is symmetric around zero assuming is independent?,"(X_1, Y_1), \ldots, (X_n, Y_n) \operatorname{Law}(X_1, Y_1) \operatorname{Law}(X_1, Y_1) \operatorname{Corr}(X_1, Y_1) = 0 \hat{\rho}(X,Y) 
f(r) = \frac{(1-r^2)^{\frac{n-4}{2}}}{B(0.5, 0.5(n-2))}, \quad r \in [-1,1]
 
\hat{\rho}(\mathbf{X},\mathbf{Y}) = \frac{\sum_{i=1}^n (X_i - \overline{X})(Y_i - \overline{Y})}{\sqrt{\sum_{i=1}^n (X_i - \overline{X})^2}\sqrt{\sum_{i=1}^n (Y_i - \overline{Y})^2}}.
 
\hat{\rho} \xrightarrow[n \to \infty]{d, \mathbb{P}} 0,
 \hat{\rho} n \in \mathbb{N} 
\hat{r}_f(\mathbf{X},\mathbf{Y}) := \frac{\sum_{i,j}c_{i,j}(\mathbf{X})c_{i,j}(\mathbf{Y})}{\sqrt{\sum_{i,j}c^2_{i,j}(\mathbf{X})}\sqrt{\sum_{i,j}c^2_{i,j}(\mathbf{Y})}},
 c_{i,j}(\mathbf{X}) = f(X_i, X_j) f: \mathbb{R}^2 \to \mathbb{R} f(t,s) = t-s \hat{r}_f X_1, Y_1","['probability', 'statistics', 'probability-distributions']"
26,Decomposition for the first hitting time,Decomposition for the first hitting time,,"A homogeneous Markov chain $\{X_n\}_{n\in\mathbb N}$ with discrete state space $\mathcal{S}$ . Set $$\tau_{k}:=\text{inf} \left\{n\ge 0:\, X_n=k  \right\}.$$ where $\tau_{k}$ is defined to be $+\infty$ , when doesn't exist any $n$ such that $X_n=k$ . $\textbf{1}.$ Now consider the Ehrenfest model ,its state space $\mathcal{S}$ is a finite set $\left\{0,1,2,...,N\right\}$ and one-step transition matrix is $$\left(\begin{array}{ccccccc} 0 & 1 & & & & & \\ \frac{1}{N} & 0 & \frac{N-1}{N} & & & & \\ & \frac{2}{N} & 0 & \ddots & & & \\ & & \frac{3}{N} & \ddots & \ddots & & \\ & & & \ddots & 0 & \frac{2}{N} & \\ & & & & \frac{N-1}{N} & 0 & \frac{1}{N} \\ & & & & & 1 & 0 \end{array}\right).$$ From an intuitive perspective, let $T_{ij}:=\inf\left\{n\ge 0:X_{n}=j,X_{0}=i\right\}$ , $i<j$ ,be the hitting time of reaching $j$ starting from $i$ .Since $T_{i,N}=\sum_{k=i}^{N-1}T_{k,k+1},$ then $${\color{Red} {\text{ for any } i<N,\mathbb{E}(\tau_{N}\mid X_{0}=i)=\mathbb{E}(\tau_{i+1}\mid X_{0}=i)+\mathbb{E}(\tau_{i+2}\mid X_{0}=i+1)+\cdots+\mathbb{E}(\tau_{N}\mid X_0=N-1).（*）}}\quad$$ But how can it be proven rigorously? By linearity of expectation,we have $$\begin{align}    \mathbb{E}\left[\tau_{N}\mid X_{0}=i\right]&=\mathbb{E}\left[\tau_{i+1}+\sum_{t=i}^{N-2}(\tau_{t+2}-\tau_{t+1})\mid X_{0}=i\right] \\     &=\mathbb{E}\left(\tau_{i+1}\mid X_{0}=i\right)+\mathbb{E}\left(\tau_{i+2}-\tau_{i+1}\mid X_{0}=i\right)+\\&\cdots+\mathbb{E}\left(\tau_{N}-\tau_{N-1}\mid X_0=i\right). \end{align}$$ How to prove that formally \begin{align}     &\mathbb{E}\left(\tau_{i+2}-\tau_{i+1}\mid   X_{0}=i\right)=\mathbb{E}\left(\tau_{i+2}\mid   X_{0}=i+1\right);\\      &\qquad\qquad\qquad\qquad\cdots\cdots \\     &\mathbb{E}\left(\tau_{N}-\tau_{N-1}\mid X_0=i\right)=\mathbb{E}\left(\tau_{N}\mid X_0=N-1\right) .\end{align} $\textbf{2}.$ Does this conclusion $(*)$ still hold in general homogeneous Markov chain $\{X_n\}_{n\in\mathbb N}$ with discrete state space $\mathcal{S}$ ? A modest attempt on $\textbf{2}$ ： Let the state space $\mathcal{S}$ is $\left\{0,1,2\right\}$ and one-step transition matrix is $$ \begin{pmatrix}  1/3&  1/3&  1/3\\  0&  1/2&  1/2\\  0&  0&  1\\ \end{pmatrix}$$ I find that $$\mathbb{E}\left(\tau_{2}\mid X_{0}=0\right){\color{Red} \ne }\mathbb{E}\left(\tau_{1}\mid X_{0}=0\right)+\mathbb{E}\left(\tau_{2}\mid X_{0}=1\right).$$ Any help will be greatly appreciated！","A homogeneous Markov chain with discrete state space . Set where is defined to be , when doesn't exist any such that . Now consider the Ehrenfest model ,its state space is a finite set and one-step transition matrix is From an intuitive perspective, let , ,be the hitting time of reaching starting from .Since then But how can it be proven rigorously? By linearity of expectation,we have How to prove that formally Does this conclusion still hold in general homogeneous Markov chain with discrete state space ? A modest attempt on ： Let the state space is and one-step transition matrix is I find that Any help will be greatly appreciated！","\{X_n\}_{n\in\mathbb N} \mathcal{S} \tau_{k}:=\text{inf} \left\{n\ge 0:\, X_n=k  \right\}. \tau_{k} +\infty n X_n=k \textbf{1}. \mathcal{S} \left\{0,1,2,...,N\right\} \left(\begin{array}{ccccccc}
0 & 1 & & & & & \\
\frac{1}{N} & 0 & \frac{N-1}{N} & & & & \\
& \frac{2}{N} & 0 & \ddots & & & \\
& & \frac{3}{N} & \ddots & \ddots & & \\
& & & \ddots & 0 & \frac{2}{N} & \\
& & & & \frac{N-1}{N} & 0 & \frac{1}{N} \\
& & & & & 1 & 0
\end{array}\right). T_{ij}:=\inf\left\{n\ge 0:X_{n}=j,X_{0}=i\right\} i<j j i T_{i,N}=\sum_{k=i}^{N-1}T_{k,k+1}, {\color{Red} {\text{ for any } i<N,\mathbb{E}(\tau_{N}\mid X_{0}=i)=\mathbb{E}(\tau_{i+1}\mid X_{0}=i)+\mathbb{E}(\tau_{i+2}\mid X_{0}=i+1)+\cdots+\mathbb{E}(\tau_{N}\mid X_0=N-1).（*）}}\quad \begin{align}
   \mathbb{E}\left[\tau_{N}\mid X_{0}=i\right]&=\mathbb{E}\left[\tau_{i+1}+\sum_{t=i}^{N-2}(\tau_{t+2}-\tau_{t+1})\mid X_{0}=i\right] \\
    &=\mathbb{E}\left(\tau_{i+1}\mid X_{0}=i\right)+\mathbb{E}\left(\tau_{i+2}-\tau_{i+1}\mid X_{0}=i\right)+\\&\cdots+\mathbb{E}\left(\tau_{N}-\tau_{N-1}\mid X_0=i\right).
\end{align} \begin{align}
    &\mathbb{E}\left(\tau_{i+2}-\tau_{i+1}\mid 
 X_{0}=i\right)=\mathbb{E}\left(\tau_{i+2}\mid 
 X_{0}=i+1\right);\\
     &\qquad\qquad\qquad\qquad\cdots\cdots \\
    &\mathbb{E}\left(\tau_{N}-\tau_{N-1}\mid X_0=i\right)=\mathbb{E}\left(\tau_{N}\mid X_0=N-1\right)
.\end{align} \textbf{2}. (*) \{X_n\}_{n\in\mathbb N} \mathcal{S} \textbf{2} \mathcal{S} \left\{0,1,2\right\}  \begin{pmatrix}
 1/3&  1/3&  1/3\\
 0&  1/2&  1/2\\
 0&  0&  1\\
\end{pmatrix} \mathbb{E}\left(\tau_{2}\mid X_{0}=0\right){\color{Red} \ne }\mathbb{E}\left(\tau_{1}\mid X_{0}=0\right)+\mathbb{E}\left(\tau_{2}\mid X_{0}=1\right).","['probability', 'stochastic-processes', 'markov-chains']"
27,Sufficient conditions for $E(G\eta|Z=1)\geq 0$,Sufficient conditions for,E(G\eta|Z=1)\geq 0,"Consider three random variables $G,Z,\eta$ . $G$ and $Z$ are   binary. We assume $$ \begin{aligned} &(1) \quad E(\eta|Z=1)=0,\\ &(2) \quad \Pr(G=1| Z=1)=1. \end{aligned} $$ In turn, $$ \begin{aligned} E(G\eta|Z=1)& =E(G \eta|G=1, Z=1)\Pr(G=1|Z=1)= E(\eta| G=1, Z=1). \end{aligned} $$ Further, observe that $$ \begin{aligned} E(\eta|Z=1)&=E( \eta|G=1, Z=1)\Pr(G=1|Z=1)+E(\eta|G=0, Z=1)\Pr(G=0|Z=1)=E( \eta|G=1, Z=1). \end{aligned} $$ Therefore, $$ (3) \quad E(G\eta|Z=1)=0. $$ Question : Instead of (3), I'd like to write down some sufficient conditions to get the weaker conclusion $$ (3') \quad E(G\eta|Z=1)\geq 0. $$ To this end, I would like to replace (2) with ""some"" inequality condition, such as $$ \begin{aligned} & E(\eta| Z=1, G=1)\geq E(\eta| Z=1, G=0)\\ & \Pr(G=1|Z=1)\geq \Pr(G=0|Z=1)\\ & \Pr(G=1|Z=1)\geq \Pr(G=1)\\ \end{aligned} $$ or similar. I can keep (1). Any idea?","Consider three random variables . and are   binary. We assume In turn, Further, observe that Therefore, Question : Instead of (3), I'd like to write down some sufficient conditions to get the weaker conclusion To this end, I would like to replace (2) with ""some"" inequality condition, such as or similar. I can keep (1). Any idea?","G,Z,\eta G Z 
\begin{aligned}
&(1) \quad E(\eta|Z=1)=0,\\
&(2) \quad \Pr(G=1| Z=1)=1.
\end{aligned}
 
\begin{aligned}
E(G\eta|Z=1)& =E(G \eta|G=1, Z=1)\Pr(G=1|Z=1)= E(\eta| G=1, Z=1).
\end{aligned}
 
\begin{aligned}
E(\eta|Z=1)&=E( \eta|G=1, Z=1)\Pr(G=1|Z=1)+E(\eta|G=0, Z=1)\Pr(G=0|Z=1)=E( \eta|G=1, Z=1).
\end{aligned}
 
(3) \quad E(G\eta|Z=1)=0.
 
(3') \quad E(G\eta|Z=1)\geq 0.
 
\begin{aligned}
& E(\eta| Z=1, G=1)\geq E(\eta| Z=1, G=0)\\
& \Pr(G=1|Z=1)\geq \Pr(G=0|Z=1)\\
& \Pr(G=1|Z=1)\geq \Pr(G=1)\\
\end{aligned}
","['probability', 'random-variables', 'expected-value', 'conditional-probability', 'conditional-expectation']"
28,Expected Maximum Value of 10 Randomly Selected Balls from an Urn,Expected Maximum Value of 10 Randomly Selected Balls from an Urn,,There are $20$ balls in an urn labeled from $1$ to $20$ . You randomly pick $10$ balls out of this urn. What is the expected maximum value of the $10$ balls you picked out? I was able to solve the problem using quite tedious combinatorics as shown below. Is there any other method to solve it? My Solution: $$\frac{20\cdot\binom{19}{9} + 19\cdot\binom{18}{9} +\dots+10\cdot\binom{9}{9}}{\binom{20}{10}}  = \frac{210}{11} $$,There are balls in an urn labeled from to . You randomly pick balls out of this urn. What is the expected maximum value of the balls you picked out? I was able to solve the problem using quite tedious combinatorics as shown below. Is there any other method to solve it? My Solution:,20 1 20 10 10 \frac{20\cdot\binom{19}{9} + 19\cdot\binom{18}{9} +\dots+10\cdot\binom{9}{9}}{\binom{20}{10}}  = \frac{210}{11} ,"['probability', 'combinatorics', 'binomial-coefficients', 'expected-value', 'order-statistics']"
29,A probability problem about picking balls - and somehow related to solar panels,A probability problem about picking balls - and somehow related to solar panels,,"CONTEXT Hello everyone! I decided to make this post for a friend of mine, who is currently working on energy-related subjects. She had been asked to simulate how solar panels would react when being randomly damaged. She was able to complete this task, but wanted to make sure there was no mistake in her code, so she tried to compute the theorical probabilistic results. So, she shared her work with me and a group of friends by simplifying all the complicated physics that was hidden, leaving us with something that looked like a very classic school probability problem. The thing is, we all kinda suck at math today (we're finishing our engineering studies, so yeah, long time since we last used our brain for math stuff). This is where I need your help; there isn't any knowledge related to solar panels needed to help her, and we were hoping some of you could give an answer that would help computing the theorical probabilities. Here is the problem: THE PROBLEM We have a bag containing $r$ red balls, $g$ green balls and $b$ blue balls. We pick a ball at random in the bag, draw a line on it, and put it back in the bag. When a ball has a fixed number of $n$ lines drawned on it, we don't put it back in the bag but place it in a separated box. We're repeating this process until eventually the bag gets emptied, and all the balls are in our box. Question: On average, how many picks do we have to make to have at least one ball of each color in our box? DISCUSSION It is interesting to note that this is actually a finite problem, and that no matter how we pick the balls it will take exactly $n(b+r+g)$ picks to have our box filled with all the balls. The pigeonhole principle also helps to grant a (slightly) better upper boundary for the average we're looking for. Let's suppose without any loss of generality that $g=\min \{r,g,b\}$ ; then we can be sure we have at least one ball of each color after $n(r+b)+g(n-1)+1$ picks, which represents the worst case scenario: we take out all red and blue balls, then draw $n-1$ lines on every green ball before finally taking out one of the green balls in the next pick. Sadly, no one in our group was able to find anything better than an upper bound. We had much trouble finding out what the right modelisation of random variables was, and could not handle the fact that the number of balls in the bag randomly change overtime. So, does anyone have an idea how to solve this problem? We're actually trying to solve for precise values in our context, with $b=r=20$ and $g=n=10$ ; but it would be great if we could find a solution for the general case!","CONTEXT Hello everyone! I decided to make this post for a friend of mine, who is currently working on energy-related subjects. She had been asked to simulate how solar panels would react when being randomly damaged. She was able to complete this task, but wanted to make sure there was no mistake in her code, so she tried to compute the theorical probabilistic results. So, she shared her work with me and a group of friends by simplifying all the complicated physics that was hidden, leaving us with something that looked like a very classic school probability problem. The thing is, we all kinda suck at math today (we're finishing our engineering studies, so yeah, long time since we last used our brain for math stuff). This is where I need your help; there isn't any knowledge related to solar panels needed to help her, and we were hoping some of you could give an answer that would help computing the theorical probabilities. Here is the problem: THE PROBLEM We have a bag containing red balls, green balls and blue balls. We pick a ball at random in the bag, draw a line on it, and put it back in the bag. When a ball has a fixed number of lines drawned on it, we don't put it back in the bag but place it in a separated box. We're repeating this process until eventually the bag gets emptied, and all the balls are in our box. Question: On average, how many picks do we have to make to have at least one ball of each color in our box? DISCUSSION It is interesting to note that this is actually a finite problem, and that no matter how we pick the balls it will take exactly picks to have our box filled with all the balls. The pigeonhole principle also helps to grant a (slightly) better upper boundary for the average we're looking for. Let's suppose without any loss of generality that ; then we can be sure we have at least one ball of each color after picks, which represents the worst case scenario: we take out all red and blue balls, then draw lines on every green ball before finally taking out one of the green balls in the next pick. Sadly, no one in our group was able to find anything better than an upper bound. We had much trouble finding out what the right modelisation of random variables was, and could not handle the fact that the number of balls in the bag randomly change overtime. So, does anyone have an idea how to solve this problem? We're actually trying to solve for precise values in our context, with and ; but it would be great if we could find a solution for the general case!","r g b n n(b+r+g) g=\min \{r,g,b\} n(r+b)+g(n-1)+1 n-1 b=r=20 g=n=10",['probability']
30,Pathwise differentiability of stochastic integrals,Pathwise differentiability of stochastic integrals,,"My question: Is there a necessary and/or sufficient condition we can place on suitable continuous $f : [0,\infty) \rightarrow \mathbb{R}$ which allows us to determine whether the process $$X_t := \int_0^t f(t-s) dW_s$$ has differentiable paths? I was motivated to ask this after looking at the SDE in this thread : \begin{align} dX_t &= Y_t dt \\\\ dY_t &= -X_t dt + b dW_t \end{align} to which I found the solution, when $X_0 = Y_0 = 0$ , \begin{align} X_t &= b \int_0^t \sin(t-s) dW_s \\\\ Y_t &= b \int_0^t \cos(t-s) dW_s \\\\ \end{align} Now, from the SDE and the pathwise continuity of solutions, it is clear to see that $X_t$ will be pathwise differentiable (with derivative $Y_t$ ), whereas $Y_t$ will not be. However this was unintuitive to me just looking at the integrals themselves! I know from this thread that we cannot hope for differentiable paths when we replace the integrand with just $f(s)$ . Moreover, I know that convolutions with white noise of the form \begin{equation} Y_t := \int_{-\infty}^\infty f(t-s) dW_s \end{equation} are pathwise differentiable if the square of the Fourier transform of $f$ decays faster than $|k|^{-1}$ as $|k| \rightarrow \infty$ (the square of the Fourier transform of $f$ is the spectral density of $Y$ ). However, I don't think this result holds in our case since we aren't integrating over the whole line and, in any case $\sin$ and $\cos$ are not $L^1$ .","My question: Is there a necessary and/or sufficient condition we can place on suitable continuous which allows us to determine whether the process has differentiable paths? I was motivated to ask this after looking at the SDE in this thread : to which I found the solution, when , Now, from the SDE and the pathwise continuity of solutions, it is clear to see that will be pathwise differentiable (with derivative ), whereas will not be. However this was unintuitive to me just looking at the integrals themselves! I know from this thread that we cannot hope for differentiable paths when we replace the integrand with just . Moreover, I know that convolutions with white noise of the form are pathwise differentiable if the square of the Fourier transform of decays faster than as (the square of the Fourier transform of is the spectral density of ). However, I don't think this result holds in our case since we aren't integrating over the whole line and, in any case and are not .","f : [0,\infty) \rightarrow \mathbb{R} X_t := \int_0^t f(t-s) dW_s \begin{align}
dX_t &= Y_t dt \\\\
dY_t &= -X_t dt + b dW_t
\end{align} X_0 = Y_0 = 0 \begin{align}
X_t &= b \int_0^t \sin(t-s) dW_s \\\\
Y_t &= b \int_0^t \cos(t-s) dW_s \\\\
\end{align} X_t Y_t Y_t f(s) \begin{equation}
Y_t := \int_{-\infty}^\infty f(t-s) dW_s
\end{equation} f |k|^{-1} |k| \rightarrow \infty f Y \sin \cos L^1","['probability', 'stochastic-processes', 'stochastic-calculus', 'stochastic-integrals', 'stochastic-analysis']"
31,Wheel of Fortune design,Wheel of Fortune design,,"In the case of a generalized Wheel of Fortune, the Expected Value is simply the dot-product of a Probabilities vector with a corresponding Values vector: $$E(W)=\sum p_i v_i$$ By way of example, a three-slice wheel with two slices having a $25\%$ chance of ""hitting"" and the third slice having a $50\%$ chance of hitting, using values for the three slices respectively of 1, 4, 10 would yield : $$E(W) = (.25\cdot 1) + (.25\cdot 4) + (.50\cdot 10) = 6.25$$ If the goal were to have the same $ E(W) $ but make the probabilities for each slice as close in value as possible, one could define a simple error function acknowledging that perfectly equal slices would each have $\frac{1}{3}$ probability of hitting. $$Err(p) = \sum ( p_i - \overline{p} )^2$$ This error could never be zero unless the $E(W)$ value were changed to 5, which is not desirable. $$E(W) = \left(\frac{1}{3}\cdot 1\right ) + \left(\frac{1}{3}\cdot 4 \right) + \left(\frac{1}{3}\cdot 10\right) = 5$$ An alternate error function may be considered without regard to the mean probability: $$Err(p) = \sum p_i^2$$ These $p_i$ values are probabilities: $$\sum p_i = 1$$ $$0 < p_i < 1$$ Question: Given $E(W)$ and each value on the Wheel of Fortune $(v_1 \ldots v_n)$ as a priori constant, is there a well known way to establish $(p_1 \ldots p_n)$ such that either error function $Err(p)$ is minimized? Its safe to assume the error function is continuous. I don't think simplex can work because of the constraints about probabilities summing to 1.","In the case of a generalized Wheel of Fortune, the Expected Value is simply the dot-product of a Probabilities vector with a corresponding Values vector: By way of example, a three-slice wheel with two slices having a chance of ""hitting"" and the third slice having a chance of hitting, using values for the three slices respectively of 1, 4, 10 would yield : If the goal were to have the same but make the probabilities for each slice as close in value as possible, one could define a simple error function acknowledging that perfectly equal slices would each have probability of hitting. This error could never be zero unless the value were changed to 5, which is not desirable. An alternate error function may be considered without regard to the mean probability: These values are probabilities: Question: Given and each value on the Wheel of Fortune as a priori constant, is there a well known way to establish such that either error function is minimized? Its safe to assume the error function is continuous. I don't think simplex can work because of the constraints about probabilities summing to 1.",E(W)=\sum p_i v_i 25\% 50\% E(W) = (.25\cdot 1) + (.25\cdot 4) + (.50\cdot 10) = 6.25  E(W)  \frac{1}{3} Err(p) = \sum ( p_i - \overline{p} )^2 E(W) E(W) = \left(\frac{1}{3}\cdot 1\right ) + \left(\frac{1}{3}\cdot 4 \right) + \left(\frac{1}{3}\cdot 10\right) = 5 Err(p) = \sum p_i^2 p_i \sum p_i = 1 0 < p_i < 1 E(W) (v_1 \ldots v_n) (p_1 \ldots p_n) Err(p),"['probability', 'probability-theory', 'probability-distributions', 'problem-solving']"
32,Bayes' Theorem Probability Question,Bayes' Theorem Probability Question,,"You go on vacation and ask your friends to water your plant. If your friends water the plant, it will survive your absence with probability $0.9$ . Otherwise, if they forget to water it, it will die with probability $0.6$ . Your friends will forget to water your plant with probability $0.3$ . You return home from your vacation and find your plant dead. What is the probability that your friends did not water it? Solution attempt: Let A denote event your friends water the plant. Let B denote event the plant dies. We have $P(B^C|A)=0.9, P(B|A^c)=0.6,P(A^c)=0.3$ We want to calculate $P(A^c|B) = \frac{P(B|A^c) \cdot P(A^c)}{P(B|A^c) \cdot P(A^c)+P(B|A)P(A)} = \frac{0.6 \cdot 0.3}{0.6 \cdot 0.3 + (1-0.9) \cdot (1-0.3)} = 0.72$ . Is this correct?","You go on vacation and ask your friends to water your plant. If your friends water the plant, it will survive your absence with probability . Otherwise, if they forget to water it, it will die with probability . Your friends will forget to water your plant with probability . You return home from your vacation and find your plant dead. What is the probability that your friends did not water it? Solution attempt: Let A denote event your friends water the plant. Let B denote event the plant dies. We have We want to calculate . Is this correct?","0.9 0.6 0.3 P(B^C|A)=0.9, P(B|A^c)=0.6,P(A^c)=0.3 P(A^c|B) = \frac{P(B|A^c) \cdot P(A^c)}{P(B|A^c) \cdot P(A^c)+P(B|A)P(A)} = \frac{0.6 \cdot 0.3}{0.6 \cdot 0.3 + (1-0.9) \cdot (1-0.3)} = 0.72","['probability', 'probability-distributions']"
33,"Show that $\lim_{n \rightarrow \infty} \frac{N_n(i,j)}{N_n(i)}=P_{ij}$",Show that,"\lim_{n \rightarrow \infty} \frac{N_n(i,j)}{N_n(i)}=P_{ij}","Let $X_n$ be an irreducible finite state Markov chain with the transition matrix $P=(P_{ij})$ . Set for any $i, j$ $$N_n(i)=\sum_{m=0}^{n} I_{\{X_m=i\}}$$ and similarly define: $$N_n(i,j)=\sum_{m=0}^{n} I_{\{X_m=i,X_{m+1}=j\}}$$ Show that: $\quad$ $\displaystyle{\lim_{n \rightarrow \infty} \frac{N_n(i,j)}{N_n(i)}}=P_{ij}$ I believe that we could use the fact that since the state space is finite and the Markov Chain is irreducible, the states are recurrent. Hence for large $n$ , we can guarantee that $N_n(i) \neq 0$ . Now, the Markov Chain Law of Large Numbers states that: $$ \frac{N_n(i)}{n} \rightarrow \frac{1}{E_i(T_i)} \ \text{almost surely}$$ where $E_i(T_i)$ is the expected time of the first return to state $i$ . I was thinking if I can take another chain $Y_n=(X_n,X_{n+1})$ and say the same about $N_n (i,j)$ but I am doubtful about how to formulate this. Can anyone help out? My Approach : For any initial distribution $\pi$ , we can write: $$\frac{1}{n} \sum_{m=0}^{n-1} I_{\{X_m=i\}} \rightarrow \pi_i$$ . Also using the SLLN, $$\frac{1}{n} \sum_{m=0}^{n-1} I_{\{X_m=i, X_{m+1}=j\}} \rightarrow \pi_i.P_{ij}$$ . Taking the ratio we can say that $\frac{N_n(i,j)}{N_n(i)} \rightarrow P_{ij}$ . Is this correct? Or am I missing something major?","Let be an irreducible finite state Markov chain with the transition matrix . Set for any and similarly define: Show that: I believe that we could use the fact that since the state space is finite and the Markov Chain is irreducible, the states are recurrent. Hence for large , we can guarantee that . Now, the Markov Chain Law of Large Numbers states that: where is the expected time of the first return to state . I was thinking if I can take another chain and say the same about but I am doubtful about how to formulate this. Can anyone help out? My Approach : For any initial distribution , we can write: . Also using the SLLN, . Taking the ratio we can say that . Is this correct? Or am I missing something major?","X_n P=(P_{ij}) i, j N_n(i)=\sum_{m=0}^{n} I_{\{X_m=i\}} N_n(i,j)=\sum_{m=0}^{n} I_{\{X_m=i,X_{m+1}=j\}} \quad \displaystyle{\lim_{n \rightarrow \infty} \frac{N_n(i,j)}{N_n(i)}}=P_{ij} n N_n(i) \neq 0  \frac{N_n(i)}{n} \rightarrow \frac{1}{E_i(T_i)} \ \text{almost surely} E_i(T_i) i Y_n=(X_n,X_{n+1}) N_n (i,j) \pi \frac{1}{n} \sum_{m=0}^{n-1} I_{\{X_m=i\}} \rightarrow \pi_i \frac{1}{n} \sum_{m=0}^{n-1} I_{\{X_m=i, X_{m+1}=j\}} \rightarrow \pi_i.P_{ij} \frac{N_n(i,j)}{N_n(i)} \rightarrow P_{ij}","['probability', 'probability-theory', 'probability-distributions', 'stochastic-processes', 'markov-chains']"
34,Y.A. Rozanov 'Probability Theory A Concise Course' Problem 2.17,Y.A. Rozanov 'Probability Theory A Concise Course' Problem 2.17,,"Problem Statement: Given any $n$ events $A_1,A_2, ...,A_n$ , prove that the probability of exactly $m$ ( $m \le n$ ) of them happening is $$P_m - \binom{m+1}{m}P_{m+1} + \binom{m+2}{m}P_{m+2} - \cdots \pm \binom{n}{m}P_n$$ where $P_k = \sum_{1\le i_1<i_2 \cdots <i_k \le n}\Pr(\bigcap_{r=1}^k A_{i_r})$ My thoughts: This looks quite similar to the inclusion-exclusion principle where we had: $$\sum_{i=1}^n(-1)^{i+1}P_i$$ but here we have $$\sum_{i=m}^n(-1)^{i+m}\binom{i}{m}P_i$$ I understand that $P_k$ implies you should sum the probabilities of all the combinations of $A$ of length $k$ . Since this already includes the combinations, I don't understand why we need a binomial coefficient before each term. To find the required probability, one can add all possible probabilities of a combination of $m$ events happening, then subtract those of $m+1$ events happening (since the first one includes this). The same question has been asked before here and here . But in the first one, the answerer uses the Indicator function (I'm aware of its basic properties, but the answerer does something which is not clear to me), and in the second, the OP themselves provide an answer (but it has a flaw (?) - they take $\Pr(M \cap N^C) = \Pr(M) - \Pr(N)$ ). So, I'm looking for an answer that at least clearly states how can I proceed with the proof, the reason for the binomial coefficients and uses the Indicator function as less as possible (since till now the author has not discussed it in the book).","Problem Statement: Given any events , prove that the probability of exactly ( ) of them happening is where My thoughts: This looks quite similar to the inclusion-exclusion principle where we had: but here we have I understand that implies you should sum the probabilities of all the combinations of of length . Since this already includes the combinations, I don't understand why we need a binomial coefficient before each term. To find the required probability, one can add all possible probabilities of a combination of events happening, then subtract those of events happening (since the first one includes this). The same question has been asked before here and here . But in the first one, the answerer uses the Indicator function (I'm aware of its basic properties, but the answerer does something which is not clear to me), and in the second, the OP themselves provide an answer (but it has a flaw (?) - they take ). So, I'm looking for an answer that at least clearly states how can I proceed with the proof, the reason for the binomial coefficients and uses the Indicator function as less as possible (since till now the author has not discussed it in the book).","n A_1,A_2, ...,A_n m m \le n P_m - \binom{m+1}{m}P_{m+1} + \binom{m+2}{m}P_{m+2} - \cdots \pm \binom{n}{m}P_n P_k = \sum_{1\le i_1<i_2 \cdots <i_k \le n}\Pr(\bigcap_{r=1}^k A_{i_r}) \sum_{i=1}^n(-1)^{i+1}P_i \sum_{i=m}^n(-1)^{i+m}\binom{i}{m}P_i P_k A k m m+1 \Pr(M \cap N^C) = \Pr(M) - \Pr(N)","['probability', 'probability-theory', 'proof-writing']"
35,"Prove that $p_n\to 1/2,$ and $q_n/(1/4)^n\to -1$",Prove that  and,"p_n\to 1/2, q_n/(1/4)^n\to -1","Here is problem 10 of 13th Annual Harvard-MIT Mathematics Tournament Team Round A 2010 Call a 2n-digit base-10 number special if we can split its digits into two multisets of size n such that the sum of the numbers in the two sets is the same. Let $p_n$ be the probability that a randomly chosen 2n-digit number is special. We allow leading zeroes in 2n-digit numbers. Prove that $p_n\to 1/2$ as $n\to\infty$ . Let $q_n=p_n-1/2.$ Prove that $\lim\limits_{n\to\infty} q_n/(1/4)^n = -1.$ There is an official solution to this problem, though I don't understand it fully. I was therefore thinking of requesting an answer here in the hopes that I'd understand it better. For convenience, here is a link to the official solution. To reiterate, it is not necessary to answer all of the questions I ask here, though it may be easier than coming up with an alternative solution to this problem. The main thing I don't understand about the solution to part a is why their proof shows that $p_n$ converges to $1/2$ . The proof of the second part of this question given in the official solution is quite hard for me to understand. In particular, I have the following questions about the solution. It seems that I can't fully understand the proof of part (a), which is why I can't seem to prove claims that follow from a similar argument to part 1 in this question. Edit: I've removed some previous questions so that this post no longer has as many questions. Why is a number good if it has any odd digits? Again, this seems similar to the proof of part a). If there are no odd digits, why does the sum being divisible by 4 imply the number is good? The only change from the official solution that I think should be made is that 8-k should be replaced with 4-k. Here is my take of the case where the sum of the digits is congruent to 0 modulo 4 and all the digits are even, where balancing argument A refers to Apass.Jack's final algorithm in his solution: Also, even if there are no odd digits, if the sum of the digits is divisible by 4, then the number is balanced. Indeed, in this case, the number of even numbers congruent to 2 modulo 4 must be even. We first set aside 10 occurrences of the digits 0,4,6,8. We then perform balancing argument A on the remaining digits, which still have a sum congruent to 0 modulo 4. Then if $S_1$ and $S_2$ are the resulting sets of digits, and $s_i$ denotes the sum of all numbers in $S_i$ for $i=1,2,$ we have $s_1 + s_2 \equiv 0\mod 4$ and both $s_1$ and $s_2$ are even, so $s_1 - s_2\equiv -2s_2\equiv 0\mod 4.$ Let $d = |s_1-s_2|.$ Suppose $s_1 \leq s_2$ . We now add $(10-d/2)/2$ occurrences of the two numbers 4 and 6 and $(10+d/2)/2$ occurrences of the two numbers 0 and 8 to $S_1$ . Finally, we add $(10+d/2)/2$ occurrences of the two numbers 4 and 6 and $(10-d/2)/2$ occurrences of 0 and 8 to $S_2.$ Then the difference between the new sums $s_1$ and $s_2$ is now zero.","Here is problem 10 of 13th Annual Harvard-MIT Mathematics Tournament Team Round A 2010 Call a 2n-digit base-10 number special if we can split its digits into two multisets of size n such that the sum of the numbers in the two sets is the same. Let be the probability that a randomly chosen 2n-digit number is special. We allow leading zeroes in 2n-digit numbers. Prove that as . Let Prove that There is an official solution to this problem, though I don't understand it fully. I was therefore thinking of requesting an answer here in the hopes that I'd understand it better. For convenience, here is a link to the official solution. To reiterate, it is not necessary to answer all of the questions I ask here, though it may be easier than coming up with an alternative solution to this problem. The main thing I don't understand about the solution to part a is why their proof shows that converges to . The proof of the second part of this question given in the official solution is quite hard for me to understand. In particular, I have the following questions about the solution. It seems that I can't fully understand the proof of part (a), which is why I can't seem to prove claims that follow from a similar argument to part 1 in this question. Edit: I've removed some previous questions so that this post no longer has as many questions. Why is a number good if it has any odd digits? Again, this seems similar to the proof of part a). If there are no odd digits, why does the sum being divisible by 4 imply the number is good? The only change from the official solution that I think should be made is that 8-k should be replaced with 4-k. Here is my take of the case where the sum of the digits is congruent to 0 modulo 4 and all the digits are even, where balancing argument A refers to Apass.Jack's final algorithm in his solution: Also, even if there are no odd digits, if the sum of the digits is divisible by 4, then the number is balanced. Indeed, in this case, the number of even numbers congruent to 2 modulo 4 must be even. We first set aside 10 occurrences of the digits 0,4,6,8. We then perform balancing argument A on the remaining digits, which still have a sum congruent to 0 modulo 4. Then if and are the resulting sets of digits, and denotes the sum of all numbers in for we have and both and are even, so Let Suppose . We now add occurrences of the two numbers 4 and 6 and occurrences of the two numbers 0 and 8 to . Finally, we add occurrences of the two numbers 4 and 6 and occurrences of 0 and 8 to Then the difference between the new sums and is now zero.","p_n p_n\to 1/2 n\to\infty q_n=p_n-1/2. \lim\limits_{n\to\infty} q_n/(1/4)^n = -1. p_n 1/2 S_1 S_2 s_i S_i i=1,2, s_1 + s_2 \equiv 0\mod 4 s_1 s_2 s_1 - s_2\equiv -2s_2\equiv 0\mod 4. d = |s_1-s_2|. s_1 \leq s_2 (10-d/2)/2 (10+d/2)/2 S_1 (10+d/2)/2 (10-d/2)/2 S_2. s_1 s_2","['calculus', 'probability', 'combinatorics', 'elementary-number-theory', 'contest-math']"
36,"Prove formally that $\frac{\hat{p}_1-\hat{p}_2}{\sqrt{\hat{p}(1-\hat{p})\left(\frac{1}{n_1}+\frac{1}{n_2}\right)}}$ converges to $N(0,1)$",Prove formally that  converges to,"\frac{\hat{p}_1-\hat{p}_2}{\sqrt{\hat{p}(1-\hat{p})\left(\frac{1}{n_1}+\frac{1}{n_2}\right)}} N(0,1)","I'm not able to prove that $$\frac{\hat{p}_1-\hat{p}_2}{\sqrt{\hat{p}(1-\hat{p})\!\left(\dfrac{1}{n_1}+\dfrac{1}{n_2}\right)}}$$ converges in distribution to $N(0,1)$ . Here, $\hat{p}_1$ and $\hat{p}_2$ are independent estimations of the same proportion, $p$ , with sample sizes $n_1$ and $n_2$ , respectively. Besides, $$\hat{p}=\frac{n_1\hat{p}_1+n_2\hat{p}_2}{n_1+n_2}.$$ I know that $$\frac{\hat{p}_i-p}{\sqrt{\dfrac{p(1-p)}{n_i}}}$$ converges in distribution to $N(0,1)$ , for $i=1,2$ . My idea was to somehow subtract these two fractions to get the desired property, but convergence in distribution is not guaranteed to be preserved under substraction. I also have that $$\text{E}(\hat{p}_1-\hat{p}_2)=0,\ \text{Var}(\hat{p}_1-\hat{p}_2)=p(1-p)\!\left(\dfrac{1}{n_1}+\dfrac{1}{n_2}\right).$$ However, I am not able to come up with a way to apply the Central Limit Theorem or something similar. Any help would be appreciated. PD : sorry if this was asked before, I searched in aproach.xyz and couldn't find anything.","I'm not able to prove that converges in distribution to . Here, and are independent estimations of the same proportion, , with sample sizes and , respectively. Besides, I know that converges in distribution to , for . My idea was to somehow subtract these two fractions to get the desired property, but convergence in distribution is not guaranteed to be preserved under substraction. I also have that However, I am not able to come up with a way to apply the Central Limit Theorem or something similar. Any help would be appreciated. PD : sorry if this was asked before, I searched in aproach.xyz and couldn't find anything.","\frac{\hat{p}_1-\hat{p}_2}{\sqrt{\hat{p}(1-\hat{p})\!\left(\dfrac{1}{n_1}+\dfrac{1}{n_2}\right)}} N(0,1) \hat{p}_1 \hat{p}_2 p n_1 n_2 \hat{p}=\frac{n_1\hat{p}_1+n_2\hat{p}_2}{n_1+n_2}. \frac{\hat{p}_i-p}{\sqrt{\dfrac{p(1-p)}{n_i}}} N(0,1) i=1,2 \text{E}(\hat{p}_1-\hat{p}_2)=0,\ \text{Var}(\hat{p}_1-\hat{p}_2)=p(1-p)\!\left(\dfrac{1}{n_1}+\dfrac{1}{n_2}\right).","['probability', 'probability-distributions', 'normal-distribution', 'bernoulli-distribution']"
37,Principle of Contraction for Random Variables,Principle of Contraction for Random Variables,,"Let $\epsilon_1, \epsilon_2, \epsilon_3, ..., \epsilon_n, ...$ be a sequence of independent random variables where $P[\epsilon_i=-1]=P[\epsilon_i=1] = 1/2$ for all $i$ , i.e. the so-called Rademacher sequence. Let $u_1, u_2, u_3, ..., u_n, ...$ be a sequence of reals. Define a random series $S=\sum_{i=1}^\infty \epsilon_i u_i$ . Let $\lambda_i\in [0,1]$ , fixed, for all $i$ . Define another random series $S_\lambda=\sum_{i=1}^\infty \lambda_i \epsilon_i u_i$ . Principle of Contration : If $S$ converges almost surely, then $S_\lambda$ also converges almost surely. I tried to prove that $\{\sum_{i=1}^N \lambda_i \epsilon_i u_i\}_N$ is a Cauchy sequence almost surely but I failed in that $\epsilon_i u_i$ can be positive for some $i$ 's and negative for some other $i$ 's. To be more specific, for $N_2>N_1$ , $$\left|\sum_{i=1}^{N_1} \lambda_i \epsilon_i u_i - \sum_{i=1}^{N_2} \lambda_i \epsilon_i u_i\right|=\left|\sum_{i=N_1+1}^{N_2} \lambda_i \epsilon_i u_i\right|.$$ We want the RHS above goes to zero as $N_1, N_2 \to \infty$ . What we have from the almost sure convergence of $S$ is, $\left|\sum_{i=N_1+1}^{N_2} \epsilon_i u_i\right|$ goes to zero as $N_1, N_2 \to \infty$ , which I don't know how to use to derive the desired convergence above. Thanks for any help. Edit: The book mentions that, if $S$ converges almost surely, then $\mathbb P[|S|>x]$ goes to zero very rapidly as $x\to\infty$ . One can use this fact to prove the Principle of Contration . I didn't see how and so tried the Cauchy sequence argument above. By the way, I also didn't see why the probability $\mathbb P[|S|>x]$ decreases rapidly though I know it will decrease to zero as $x\to\infty$ .","Let be a sequence of independent random variables where for all , i.e. the so-called Rademacher sequence. Let be a sequence of reals. Define a random series . Let , fixed, for all . Define another random series . Principle of Contration : If converges almost surely, then also converges almost surely. I tried to prove that is a Cauchy sequence almost surely but I failed in that can be positive for some 's and negative for some other 's. To be more specific, for , We want the RHS above goes to zero as . What we have from the almost sure convergence of is, goes to zero as , which I don't know how to use to derive the desired convergence above. Thanks for any help. Edit: The book mentions that, if converges almost surely, then goes to zero very rapidly as . One can use this fact to prove the Principle of Contration . I didn't see how and so tried the Cauchy sequence argument above. By the way, I also didn't see why the probability decreases rapidly though I know it will decrease to zero as .","\epsilon_1, \epsilon_2, \epsilon_3, ..., \epsilon_n, ... P[\epsilon_i=-1]=P[\epsilon_i=1] = 1/2 i u_1, u_2, u_3, ..., u_n, ... S=\sum_{i=1}^\infty \epsilon_i u_i \lambda_i\in [0,1] i S_\lambda=\sum_{i=1}^\infty \lambda_i \epsilon_i u_i S S_\lambda \{\sum_{i=1}^N \lambda_i \epsilon_i u_i\}_N \epsilon_i u_i i i N_2>N_1 \left|\sum_{i=1}^{N_1} \lambda_i \epsilon_i u_i - \sum_{i=1}^{N_2} \lambda_i \epsilon_i u_i\right|=\left|\sum_{i=N_1+1}^{N_2} \lambda_i \epsilon_i u_i\right|. N_1, N_2 \to \infty S \left|\sum_{i=N_1+1}^{N_2} \epsilon_i u_i\right| N_1, N_2 \to \infty S \mathbb P[|S|>x] x\to\infty \mathbb P[|S|>x] x\to\infty","['probability', 'measure-theory', 'convergence-divergence', 'random-variables', 'rademacher-distribution']"
38,Measurable argmax correspondence on probability spaces,Measurable argmax correspondence on probability spaces,,"I'm trying to wrap my head around the ""Measurable maximum theorem"", Thm 14.91 in ""A hitchhiker's guide to infinite dimensional analysis"" by Aliprantis & Border. I wonder if I can use it in a case when the underlying measurable space is a probability space. (I will explain in which sense below). The statement of the theorem goes like this: Let $X$ be a polish space and $(S,\Sigma)$ a measurable space. Let $\varphi: S \twoheadrightarrow X$ (My clarification: $\varphi$ is set valued/a correspondance) be a weakly measurable correspondance with nonempty compact values, and suppose that $f: S \times X \to \mathbb{R}$ is a Caratheodory function (measurable in $s$ and continuous in $x$ ). Define the value function $m$ by: $$m(s) = \max_{x \in \varphi(s)} f(s,x),$$ and the correspondence $$ \mu(s) = \{ x \in \varphi(s): f(s,x) = m(s) \}.$$ Then: The value function $m$ is measurable. The argmax correspondance $\mu$ is measurable, has nonempty compact values and admits a measurable selector. Clarification: By weakly measurable correspondence is meant that $\{s \in S: \varphi(s) \cap K \neq \emptyset \}$ belongs to $\Sigma$ for each compact set $K$ . My question is the following; suppose that I have a probability space $\left( \Omega, \mathcal{A}, \mathbb{P} \right)$ and a Caratheodory function $f: \Omega \times \mathbb{R}^d \to \mathbb{R}$ . I would like to check that the argmax correspondence $$\text{argmax}_{x \in \mathbb{R}} = f(\omega,x)$$ is a measurable correspondence and admits a measurable selector. Is it possible to use the theorem above to do this? If yes, how do I define $\varphi$ and check that it's weakly measurable in the above sense?","I'm trying to wrap my head around the ""Measurable maximum theorem"", Thm 14.91 in ""A hitchhiker's guide to infinite dimensional analysis"" by Aliprantis & Border. I wonder if I can use it in a case when the underlying measurable space is a probability space. (I will explain in which sense below). The statement of the theorem goes like this: Let be a polish space and a measurable space. Let (My clarification: is set valued/a correspondance) be a weakly measurable correspondance with nonempty compact values, and suppose that is a Caratheodory function (measurable in and continuous in ). Define the value function by: and the correspondence Then: The value function is measurable. The argmax correspondance is measurable, has nonempty compact values and admits a measurable selector. Clarification: By weakly measurable correspondence is meant that belongs to for each compact set . My question is the following; suppose that I have a probability space and a Caratheodory function . I would like to check that the argmax correspondence is a measurable correspondence and admits a measurable selector. Is it possible to use the theorem above to do this? If yes, how do I define and check that it's weakly measurable in the above sense?","X (S,\Sigma) \varphi: S \twoheadrightarrow X \varphi f: S \times X \to \mathbb{R} s x m m(s) = \max_{x \in \varphi(s)} f(s,x),  \mu(s) = \{ x \in \varphi(s): f(s,x) = m(s) \}. m \mu \{s \in S: \varphi(s) \cap K \neq \emptyset \} \Sigma K \left( \Omega, \mathcal{A}, \mathbb{P} \right) f: \Omega \times \mathbb{R}^d \to \mathbb{R} \text{argmax}_{x \in \mathbb{R}} = f(\omega,x) \varphi","['probability', 'measurable-functions', 'set-valued-analysis']"
39,What is the probability of a random line passing through the unit disk meet the y-axis?,What is the probability of a random line passing through the unit disk meet the y-axis?,,"This is a question that I came up myself. So it might have some of the errors pointed in the comments below. Consider the open unit disk centered at (0,0) and the set of all straight lines of the plane that intersect the y-axis. Hence, we are consedering the set of straight lines that have the form: y=lx+m, $l\in\mathbb{R}, m\in\mathbb{R}$ . What is the probability of a randomly selected line that passes through the unit disk to intesect the y-axis inside the unit disk? I don't really know how to approach this kind of problems. At first I try to see which lines pass through the unit disk. The coefficients must obey $|m|<\sqrt{l^2+1}$ . To intersect the y-axis inside the unit disk we must have $|m|<1$ . Thus, for a fixed $l\in\mathbb{R}$ the proportion of the lines that meet the y-axis inside the unit disk is $1/\sqrt{l^2+1}$ (lenght of (-1,1)/ length of $(-\sqrt(l^2+1),\sqrt(l^2+1))$ . Now the probability must be the mean value of $1/\sqrt{l^2+1}$ for $l\in(-\infty,+\infty)$ , which is the integral of this function over that interval. But the integral $$\int\limits_{-\infty}^{\infty}\dfrac{1}{\sqrt{l^2+1}}=\infty.$$ Hence, this reasoning - which seems right to me - doesn't lead to an answer. I don't really know how to approach this kind of problems. Do you have any hints? Suggestions? Or maybe an answer?","This is a question that I came up myself. So it might have some of the errors pointed in the comments below. Consider the open unit disk centered at (0,0) and the set of all straight lines of the plane that intersect the y-axis. Hence, we are consedering the set of straight lines that have the form: y=lx+m, . What is the probability of a randomly selected line that passes through the unit disk to intesect the y-axis inside the unit disk? I don't really know how to approach this kind of problems. At first I try to see which lines pass through the unit disk. The coefficients must obey . To intersect the y-axis inside the unit disk we must have . Thus, for a fixed the proportion of the lines that meet the y-axis inside the unit disk is (lenght of (-1,1)/ length of . Now the probability must be the mean value of for , which is the integral of this function over that interval. But the integral Hence, this reasoning - which seems right to me - doesn't lead to an answer. I don't really know how to approach this kind of problems. Do you have any hints? Suggestions? Or maybe an answer?","l\in\mathbb{R}, m\in\mathbb{R} |m|<\sqrt{l^2+1} |m|<1 l\in\mathbb{R} 1/\sqrt{l^2+1} (-\sqrt(l^2+1),\sqrt(l^2+1)) 1/\sqrt{l^2+1} l\in(-\infty,+\infty) \int\limits_{-\infty}^{\infty}\dfrac{1}{\sqrt{l^2+1}}=\infty.","['probability', 'euclidean-geometry']"
40,Mean value theorem under an expectation?,Mean value theorem under an expectation?,,"Let $f:\mathbb{R} \rightarrow \mathbb{R}$ be a continuous function. Consider the expected value of $f$ under the probability density function $\pi(x)$ defined on $(-\infty,\infty)$ . $$ \int_{-\infty}^{\infty} \pi(x) f(x) dx = \mu. $$ Is there some type of ""mean value theorem under expectations"" that would allow us to write $\mu = Mf(x^*)$ where $M\in\mathbb{R}$ under some restrictions to $\pi$ and $f$ without requiring that the domain be bounded?","Let be a continuous function. Consider the expected value of under the probability density function defined on . Is there some type of ""mean value theorem under expectations"" that would allow us to write where under some restrictions to and without requiring that the domain be bounded?","f:\mathbb{R} \rightarrow \mathbb{R} f \pi(x) (-\infty,\infty) 
\int_{-\infty}^{\infty} \pi(x) f(x) dx = \mu.
 \mu = Mf(x^*) M\in\mathbb{R} \pi f","['probability', 'probability-theory', 'probability-distributions']"
41,How to Calculate the Product of Summations [closed],How to Calculate the Product of Summations [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 1 year ago . Improve this question Let $X_1, \dots X_n \overset{i.i.d.}{\sim} \mathbb{E}[X_i] = \mu, \mathbb{V}[X_i] = \sigma^2, \mu\in\mathbb{R}, \sigma^2 > 0, \mathbb{E}[(X_i)^4] < \infty.$ $$ \mathbb{E}\left[\sum_{i=1}^n X_i\sum_{j=1}^n X_j\sum_{k=1}^n X_k \sum_{l=1}^n X_l \right]\\ = \sum_{i=1}^n \mathbb{E}\left[(X_i)^4 \right] + 4\sum_{i=1}^n \sum_{l\neq i}^n\mathbb{E}\left[(X_i)^3X_l \right] + 3\sum_{i=1}^n \sum_{j\neq i}^n\mathbb{E}\left[(X_i)^2(X_j)^2 \right]\\ + 6\sum_{i=1}^n \sum_{j\neq i}^n \sum_{k\neq i,j}^n\mathbb{E}\left[(X_i)^2 X_j X_k \right] + \sum_{i=1}^n \sum_{j\neq i}^n \sum_{k\neq i,j}^n \sum_{l\neq i,j,k}^n \mathbb{E}\left[X_i X_j X_k X_l \right] $$ In the expansion of this equation, $4$ , $3$ and $6$ appear in the coefficients, but I do not know how to find these coefficients.","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 1 year ago . Improve this question Let In the expansion of this equation, , and appear in the coefficients, but I do not know how to find these coefficients.","X_1, \dots X_n \overset{i.i.d.}{\sim} \mathbb{E}[X_i] = \mu, \mathbb{V}[X_i] = \sigma^2, \mu\in\mathbb{R}, \sigma^2 > 0, \mathbb{E}[(X_i)^4] < \infty. 
\mathbb{E}\left[\sum_{i=1}^n X_i\sum_{j=1}^n X_j\sum_{k=1}^n X_k \sum_{l=1}^n X_l \right]\\
= \sum_{i=1}^n \mathbb{E}\left[(X_i)^4 \right] + 4\sum_{i=1}^n \sum_{l\neq i}^n\mathbb{E}\left[(X_i)^3X_l \right] + 3\sum_{i=1}^n \sum_{j\neq i}^n\mathbb{E}\left[(X_i)^2(X_j)^2 \right]\\ + 6\sum_{i=1}^n \sum_{j\neq i}^n \sum_{k\neq i,j}^n\mathbb{E}\left[(X_i)^2 X_j X_k \right] + \sum_{i=1}^n \sum_{j\neq i}^n \sum_{k\neq i,j}^n \sum_{l\neq i,j,k}^n \mathbb{E}\left[X_i X_j X_k X_l \right]
 4 3 6","['probability', 'statistics', 'summation']"
42,Prove $\pi$-$\lambda$ theorem from Monotone Class Theorem,Prove - theorem from Monotone Class Theorem,\pi \lambda,"I am trying to solve this exercise from Billingsley's Probability and Measure Exercise 3.12 Deduce the $\pi-\lambda$ theorem from the monotone class theorem by showing directly that, if a $\lambda$ -system $\mathscr{L}$ contains a $\pi$ -system $\mathscr{P}$ , then $\mathscr{L}$ also contains the field generated by $\mathscr{P}$ . Here is what I have come up with: The monotone class theorem applies to an (algebra/field). Therefore, we need some field to apply it to and not just a $\pi$ -system. The natural choice would be the field (not $\sigma$ -field) generated by $\mathscr{P}$ . We also need some monotone class. We claim that $\mathscr{L}$ is a monotone class. Using the alternate axiom $(\lambda'_2)$ which says that $A,B \in \mathscr{L}$ and $A\subset B$ imply $B\setminus A = \mathscr{L}$ , we can easily show that $\mathscr{L}$ is closed under monotone unions and intersections. To see this, fix $A_1,A_2,\dots,\in \mathscr{L}$ where $A_n \uparrow A$ . Then define the sets $B_1=A_1$ $B_2=A_2\setminus B_1$ , $B_3=A_3\setminus B_1 \cup B_2$ and so on which are elements of $\mathscr{L}$ by $(\lambda_2')$ . Then $B_1\cup B_2 \cup \dots$ are all disjoint so by $(\lambda_3)$ which says that $A_1,A_2,\dots, \in \mathscr{L}$ and $A_n\cap A_m=\emptyset$ for $m\neq n$ imply $\bigcup_n \in \mathscr{L}$ , we conclude that $\mathscr{L}$ is closed under increasing unions. The proof for decreasing unions is similar. Now to use the monotone class theorem, we finally need to show that the field generated by $\mathscr{P}$ is a subset of $\mathscr{L}$ . This holds by minimality of the field generated by $\mathscr{P}$ because $\mathscr{L}$ is a field. To see this, it is closed under complements as it is a $\lambda$ -system, it contains $\Omega$ as it is a $\lambda$ -system, but I am not sure how to show $A\cup B\in \mathscr{L}$ . What can I do from here to show this fact? Is it even true?","I am trying to solve this exercise from Billingsley's Probability and Measure Exercise 3.12 Deduce the theorem from the monotone class theorem by showing directly that, if a -system contains a -system , then also contains the field generated by . Here is what I have come up with: The monotone class theorem applies to an (algebra/field). Therefore, we need some field to apply it to and not just a -system. The natural choice would be the field (not -field) generated by . We also need some monotone class. We claim that is a monotone class. Using the alternate axiom which says that and imply , we can easily show that is closed under monotone unions and intersections. To see this, fix where . Then define the sets , and so on which are elements of by . Then are all disjoint so by which says that and for imply , we conclude that is closed under increasing unions. The proof for decreasing unions is similar. Now to use the monotone class theorem, we finally need to show that the field generated by is a subset of . This holds by minimality of the field generated by because is a field. To see this, it is closed under complements as it is a -system, it contains as it is a -system, but I am not sure how to show . What can I do from here to show this fact? Is it even true?","\pi-\lambda \lambda \mathscr{L} \pi \mathscr{P} \mathscr{L} \mathscr{P} \pi \sigma \mathscr{P} \mathscr{L} (\lambda'_2) A,B \in \mathscr{L} A\subset B B\setminus A = \mathscr{L} \mathscr{L} A_1,A_2,\dots,\in \mathscr{L} A_n \uparrow A B_1=A_1 B_2=A_2\setminus B_1 B_3=A_3\setminus B_1 \cup B_2 \mathscr{L} (\lambda_2') B_1\cup B_2 \cup \dots (\lambda_3) A_1,A_2,\dots, \in \mathscr{L} A_n\cap A_m=\emptyset m\neq n \bigcup_n \in \mathscr{L} \mathscr{L} \mathscr{P} \mathscr{L} \mathscr{P} \mathscr{L} \lambda \Omega \lambda A\cup B\in \mathscr{L}","['probability', 'probability-theory', 'measure-theory', 'solution-verification']"
43,How to calculate the probability or 50% or more matches on n randomly assigned unique pairs,How to calculate the probability or 50% or more matches on n randomly assigned unique pairs,,"FTR: This could not be a lower priority question. It's so not important, but I really want to know. Let's say I have n unique pairs. They are like keys (A) and locks (B), and every one of the n locks can be opened by exactly one of the n keys. And, of course we are completely randomly assigning each key to a random lock to see if it works. (BTW, it took me an embarrassing amount of counting combinations to figure out the that number of combinations is n!, but, in my defense, I've never actually used factorials in anything.) So, given n pairs, there are n! possible combinations. How does one calculate the chances that there are at least x correct matches? I'm in particular looking to see the chances for at least one correct match, and for at least 50% correct matches. I've tried internet searches, but I haven't been able to word it to get what I'm looking for. I made a spreadsheet and went up to 5-pair combinations. But I have no idea how to turn that data into any kind of formula. It doesn't paste well, so I'll paste the text and include an image with better formatting. Total #     Possible       Combs w/      Probability of   Combs with      Probability  of pairs    combinations   matches ≥ 1   matches ≥ 1      matches ≥ 50%   of matches ≥ 50% 1           1              1             100.00%          ?               ? 2           2              1              50.00%          ?               ?  3           6              4              66.67%          ?               ?  4           24             15             62.50%          ?               ? 5           120            73             60.83%          ?               ? I think I got all the requirements for a well-formed question. If I missed anything, it was accidental, let me know and I'll fix it. Again, this is not important, just something that's been bugging me. Thank you for any help you can provide. Especially replies that explain ""this is why/how it works this way"" In that ""teach a person to fish"" kinda way. Chances of correctly matching pairs","FTR: This could not be a lower priority question. It's so not important, but I really want to know. Let's say I have n unique pairs. They are like keys (A) and locks (B), and every one of the n locks can be opened by exactly one of the n keys. And, of course we are completely randomly assigning each key to a random lock to see if it works. (BTW, it took me an embarrassing amount of counting combinations to figure out the that number of combinations is n!, but, in my defense, I've never actually used factorials in anything.) So, given n pairs, there are n! possible combinations. How does one calculate the chances that there are at least x correct matches? I'm in particular looking to see the chances for at least one correct match, and for at least 50% correct matches. I've tried internet searches, but I haven't been able to word it to get what I'm looking for. I made a spreadsheet and went up to 5-pair combinations. But I have no idea how to turn that data into any kind of formula. It doesn't paste well, so I'll paste the text and include an image with better formatting. Total #     Possible       Combs w/      Probability of   Combs with      Probability  of pairs    combinations   matches ≥ 1   matches ≥ 1      matches ≥ 50%   of matches ≥ 50% 1           1              1             100.00%          ?               ? 2           2              1              50.00%          ?               ?  3           6              4              66.67%          ?               ?  4           24             15             62.50%          ?               ? 5           120            73             60.83%          ?               ? I think I got all the requirements for a well-formed question. If I missed anything, it was accidental, let me know and I'll fix it. Again, this is not important, just something that's been bugging me. Thank you for any help you can provide. Especially replies that explain ""this is why/how it works this way"" In that ""teach a person to fish"" kinda way. Chances of correctly matching pairs",,['probability']
44,Integration of power law distribution and negative arguments in the lower incomplete gamma,Integration of power law distribution and negative arguments in the lower incomplete gamma,,"Dear mathematical acolytes, I am working as a materials scientist and my current topic is related to some probabilistic considerations of the microstructures of metals. I have the probability of something occuring $ P_\mathrm{occur} $ which is dependent on the diameter, $ c $ , of something in the microstructure. This occurance probability is then modified with the probability density distribution of $c$ as $ P_\mathrm{occur}\left( c \right) p_\mathrm{size}\left( c \right) $ where $$ P_\mathrm{occur}\left( c \right) = 1 - \exp{\left( -B\left( \frac{c}{c_\mathrm{N}} \right)^3 \right)},  \\ p_\mathrm{size}\left( c \right) = \frac{m-1}{c_\mathrm{min}}\left( \frac{c}{c_\mathrm{min}} \right)^{-m}. $$ The probability density $ p_\mathrm{size}\left( c \right) $ is a power-law distribution with a lower bound at $ c_\mathrm{min} $ (a positive number) and upper bound at $ \infty $ . The exponent is subject to $ m > 1 $ . The parameter $ B $ in the occurance probability assumes a value between $ 0 $ and $ 1 $ , and $c_\mathrm{N} $ is a positive number of the same order of $ c_\mathrm{min} $ . The modified occurance probability is then to be integrated over the size $ c $ as: $$ \int_{c_\mathrm{min}}^\infty{P_\mathrm{occur}\left( c \right) p_\mathrm{size}\left( c \right) \mathrm{d}c} = \\ \int_{c_\mathrm{min}}^\infty{ \left( 1 - \exp{\left( -B\left( \frac{c}{c_\mathrm{N}} \right)^3 \right)} \right) \frac{m-1}{c_\mathrm{min}}\left( \frac{c}{c_\mathrm{min}} \right)^{-m} {d}c} $$ Here the first question appears, how is this to be integrated? Can it be shown using common mathematical functions? As I am of little mathematical prowess, I tried using the symbolical library SymPy in Python to carry out the integration, and also to compare with a numerical integration using the trapezoidal rule. What happens is that the symbolical and the numerical integrations yields the same result, which is great, but that the symbolical integration returns a function named lowergamma(a,x) , SymPy Docs , with a negative argument a evaluated at x . This is supposed to be the incomplete lower gamma Wikipedia , however, the incomplete lower gamma should not take negative arguments. What puzzles me is that the symbolical integration with inserted numerical values in SymPy gives the same result as the trapezoidal numerical integration, even though the symbolical result uses the lower incomplete gamma with negative values, which should not be possible. Here a cluster of questions appears, how can SymPy use negative values in its lower incomplete gamma? Neither SciPy nor Matlab can do this. What is different? How can I account for this in another library/language? Thankful for comments and answers! Update after answer from K.defaoite The negative values in the argument of the incomplete gamma function also appears in the accepted answer below. This can be computed using 8.5.1 in the DLMF where a confluent hypergeometric function is used. Using this along with the solution presented below gives the same answer as both the symbolical and the numerical integration. The code is updated. The code I used for my symbolical/numerical comparison outputs this: Symbolic integral before evaluation = Symbolic integral before evaluation = 0.279982455532194*gamma(2/3)*lowergamma(-2/3, 0.5)/gamma(5/3) + 1.0 - 0.419973683298291*gamma(-2/3) Value of symbolical integration =  0.744656471805332 Value of numerical integration  =  0.7446564718064296 Integral by K.defaoite          =  0.7446564718053317 The code itself, including the parameters used for evaluation: import sympy as sym import numpy as np import scipy.special  # ---- Symbolical integration ----  c = sym.symbols('c', positive=True) cmin = sym.symbols('cmin', positive=True) cmax = sym.symbols('cmax', positive=True) cN = sym.symbols('cN', positive=True) B = sym.symbols('B', positive=True) m = sym.symbols('m', positive=True)  func = (m-1)/(cmin**(1-m))*c**-m*(1 - sym.exp(-B*(c/cN)**3)) integrated = sym.integrate(func,(c, cmin, sym.oo), conds='separate')  # ---- Evaluation and comparison to numerical integration ----  Bnum = 0.5          # Somewhere between 0 and 1 cminnum = 0.1       # Small number, lower bound of power law dist. cNnum = 0.1         # Parameter on the order of cmin mnum = 3            # Exponent of power law dist, must be larger than 1, realistic up to 20  func = integrated[0].subs(B, Bnum).subs(cN, cNnum).subs(cmin, cminnum).subs(m, mnum)  cnum = np.logspace(np.log10(cminnum), 82, 100000000) func_num = (mnum-1)/(cminnum**(1-mnum))*cnum**-mnum*(1. - np.exp(-Bnum*(cnum/cNnum)**3.)) trapz_func_num = np.trapz(func_num, cnum)  # ---- Integral by K.defaoite ----  a = (mnum - 1.)/3. z = Bnum*(cminnum/cNnum)**3. upper_gamma = scipy.special.gamma(-a) - z**(-a)/(-a)*scipy.special.hyp1f1(-a, -a+1., -z, out=None) int_Kdefaoite = 1. - a*z**a*(upper_gamma)  # ---- Compare ----  print('Symbolic integral before evaluation =', func) print('Value of symbolical integration = ', sym.N(func)) print('Value of numerical integration = ', trapz_func_num) print('Integral by K.defaoite = ', int_Kdefaoite)","Dear mathematical acolytes, I am working as a materials scientist and my current topic is related to some probabilistic considerations of the microstructures of metals. I have the probability of something occuring which is dependent on the diameter, , of something in the microstructure. This occurance probability is then modified with the probability density distribution of as where The probability density is a power-law distribution with a lower bound at (a positive number) and upper bound at . The exponent is subject to . The parameter in the occurance probability assumes a value between and , and is a positive number of the same order of . The modified occurance probability is then to be integrated over the size as: Here the first question appears, how is this to be integrated? Can it be shown using common mathematical functions? As I am of little mathematical prowess, I tried using the symbolical library SymPy in Python to carry out the integration, and also to compare with a numerical integration using the trapezoidal rule. What happens is that the symbolical and the numerical integrations yields the same result, which is great, but that the symbolical integration returns a function named lowergamma(a,x) , SymPy Docs , with a negative argument a evaluated at x . This is supposed to be the incomplete lower gamma Wikipedia , however, the incomplete lower gamma should not take negative arguments. What puzzles me is that the symbolical integration with inserted numerical values in SymPy gives the same result as the trapezoidal numerical integration, even though the symbolical result uses the lower incomplete gamma with negative values, which should not be possible. Here a cluster of questions appears, how can SymPy use negative values in its lower incomplete gamma? Neither SciPy nor Matlab can do this. What is different? How can I account for this in another library/language? Thankful for comments and answers! Update after answer from K.defaoite The negative values in the argument of the incomplete gamma function also appears in the accepted answer below. This can be computed using 8.5.1 in the DLMF where a confluent hypergeometric function is used. Using this along with the solution presented below gives the same answer as both the symbolical and the numerical integration. The code is updated. The code I used for my symbolical/numerical comparison outputs this: Symbolic integral before evaluation = Symbolic integral before evaluation = 0.279982455532194*gamma(2/3)*lowergamma(-2/3, 0.5)/gamma(5/3) + 1.0 - 0.419973683298291*gamma(-2/3) Value of symbolical integration =  0.744656471805332 Value of numerical integration  =  0.7446564718064296 Integral by K.defaoite          =  0.7446564718053317 The code itself, including the parameters used for evaluation: import sympy as sym import numpy as np import scipy.special  # ---- Symbolical integration ----  c = sym.symbols('c', positive=True) cmin = sym.symbols('cmin', positive=True) cmax = sym.symbols('cmax', positive=True) cN = sym.symbols('cN', positive=True) B = sym.symbols('B', positive=True) m = sym.symbols('m', positive=True)  func = (m-1)/(cmin**(1-m))*c**-m*(1 - sym.exp(-B*(c/cN)**3)) integrated = sym.integrate(func,(c, cmin, sym.oo), conds='separate')  # ---- Evaluation and comparison to numerical integration ----  Bnum = 0.5          # Somewhere between 0 and 1 cminnum = 0.1       # Small number, lower bound of power law dist. cNnum = 0.1         # Parameter on the order of cmin mnum = 3            # Exponent of power law dist, must be larger than 1, realistic up to 20  func = integrated[0].subs(B, Bnum).subs(cN, cNnum).subs(cmin, cminnum).subs(m, mnum)  cnum = np.logspace(np.log10(cminnum), 82, 100000000) func_num = (mnum-1)/(cminnum**(1-mnum))*cnum**-mnum*(1. - np.exp(-Bnum*(cnum/cNnum)**3.)) trapz_func_num = np.trapz(func_num, cnum)  # ---- Integral by K.defaoite ----  a = (mnum - 1.)/3. z = Bnum*(cminnum/cNnum)**3. upper_gamma = scipy.special.gamma(-a) - z**(-a)/(-a)*scipy.special.hyp1f1(-a, -a+1., -z, out=None) int_Kdefaoite = 1. - a*z**a*(upper_gamma)  # ---- Compare ----  print('Symbolic integral before evaluation =', func) print('Value of symbolical integration = ', sym.N(func)) print('Value of numerical integration = ', trapz_func_num) print('Integral by K.defaoite = ', int_Kdefaoite)"," P_\mathrm{occur}   c  c  P_\mathrm{occur}\left( c \right) p_\mathrm{size}\left( c \right)  
P_\mathrm{occur}\left( c \right) = 1 - \exp{\left( -B\left( \frac{c}{c_\mathrm{N}} \right)^3 \right)}, 
\\
p_\mathrm{size}\left( c \right) = \frac{m-1}{c_\mathrm{min}}\left( \frac{c}{c_\mathrm{min}} \right)^{-m}.
  p_\mathrm{size}\left( c \right)   c_\mathrm{min}   \infty   m > 1   B   0   1  c_\mathrm{N}   c_\mathrm{min}   c  
\int_{c_\mathrm{min}}^\infty{P_\mathrm{occur}\left( c \right) p_\mathrm{size}\left( c \right) \mathrm{d}c} = \\
\int_{c_\mathrm{min}}^\infty{ \left( 1 - \exp{\left( -B\left( \frac{c}{c_\mathrm{N}} \right)^3 \right)} \right) \frac{m-1}{c_\mathrm{min}}\left( \frac{c}{c_\mathrm{min}} \right)^{-m} {d}c}
","['probability', 'integration', 'probability-distributions', 'gamma-function']"
45,"If you throw a dice 5 times, what is the expected value of the square of the median?","If you throw a dice 5 times, what is the expected value of the square of the median?",,"My question: If you throw a dice 5 times, what is the expected value of the square of the median of the 5 results? A slightly modified question would be: If you throw a dice 5 times, what is the expected value of the median? The answer would be 3.5 by symmetry. For the square, it seems to be that symmetry does not hold anymore. Is there a ""smart"" way to solve this problem? If there isn't a smart way to solve the problem, if there a smart way to estimate the answer?","My question: If you throw a dice 5 times, what is the expected value of the square of the median of the 5 results? A slightly modified question would be: If you throw a dice 5 times, what is the expected value of the median? The answer would be 3.5 by symmetry. For the square, it seems to be that symmetry does not hold anymore. Is there a ""smart"" way to solve this problem? If there isn't a smart way to solve the problem, if there a smart way to estimate the answer?",,"['probability', 'expected-value', 'dice', 'symmetry']"
46,Does the sum of random variables sampled with/without substitution differ for large populations?,Does the sum of random variables sampled with/without substitution differ for large populations?,,"We have a population of $N$ different balls. Half the balls are red, and half the balls are blue. We perform $N$ trials. In trials $i = 1,\cdots,N$ we pick a ball $B_i$ randomly. First, we pick the balls with replacement.  Then we pick the balls without replacement. Define the sum $S = \displaystyle\sum_{i=2}^N \sigma_i$ where for each trial $i \in (2,3,...N)$ $$\sigma_i = \ \begin{cases}        1 & \text{if } B_i\text{ has same color as } B_{i-1} \\       0 & \text{otherwise}     \end{cases} $$ If the balls are picked with replacement the probability mass function (pmf) for $\sigma_i$ is $g(\sigma_i) =  \begin{cases}        0.5 & \text{for } \sigma_i=1 \\       0.5 & \text{for } \sigma_i=0     \end{cases} $ . Accordingly, the probability mass function for $S$ is described by the Binomial distribution $$ f(s)= \binom{N-1}{s}\times0.5^{s}\times0.5^{N-1-s} $$ In the limit $N\rightarrow\infty$ , the binomial distribution becomes a Gaussian distribution. I have performed a few computer simulations where the balls are picked without replacement, and the pmf for $S$ converges to the same binomial/Gaussian distribution in the limit $N\rightarrow\infty$ . This convergence occurs even if $\sigma_i$ is no longer perfectly i.i.d (independent and identically distributed). Why does the sum $S$ converge to the same distribution whether the balls are picked with or without replacement? I suspect that I need a central limit theorem for weakly correlated variables. Note: I want proof, but all explanations are welcome. I suspect there exists a fundamental explanation obvious for somebody with more statistics experience than myself.","We have a population of different balls. Half the balls are red, and half the balls are blue. We perform trials. In trials we pick a ball randomly. First, we pick the balls with replacement.  Then we pick the balls without replacement. Define the sum where for each trial If the balls are picked with replacement the probability mass function (pmf) for is . Accordingly, the probability mass function for is described by the Binomial distribution In the limit , the binomial distribution becomes a Gaussian distribution. I have performed a few computer simulations where the balls are picked without replacement, and the pmf for converges to the same binomial/Gaussian distribution in the limit . This convergence occurs even if is no longer perfectly i.i.d (independent and identically distributed). Why does the sum converge to the same distribution whether the balls are picked with or without replacement? I suspect that I need a central limit theorem for weakly correlated variables. Note: I want proof, but all explanations are welcome. I suspect there exists a fundamental explanation obvious for somebody with more statistics experience than myself.","N N i = 1,\cdots,N B_i S = \displaystyle\sum_{i=2}^N \sigma_i i \in (2,3,...N) \sigma_i = \ \begin{cases} 
      1 & \text{if } B_i\text{ has same color as } B_{i-1} \\
      0 & \text{otherwise} 
   \end{cases}
 \sigma_i g(\sigma_i) =  \begin{cases} 
      0.5 & \text{for } \sigma_i=1 \\
      0.5 & \text{for } \sigma_i=0 
   \end{cases}  S 
f(s)= \binom{N-1}{s}\times0.5^{s}\times0.5^{N-1-s}
 N\rightarrow\infty S N\rightarrow\infty \sigma_i S","['probability', 'statistics', 'probability-distributions', 'central-limit-theorem', 'law-of-large-numbers']"
47,n-player survivor game,n-player survivor game,,"Came up with a following game recently and after trying to understand the general strategy for hours I have to admit I failed at finding one, so I thought asking here would be a good idea. As a good friend of mine restated: Define the ""n-player survivor game"" as follows: label the players 1, .., n. First, in ascending order by index, each player publicly announces who they plan to eliminate (possibly themselves). Then, in descending order by index, each player eliminates the player they previously announced. If a player is already eliminated, they can no longer eliminate the player they previously announced. Each player is rational, with the following goals [in order]: (1) survive (don't get eliminated); (2) leave as few survivors as possible. If some player k can make multiple decisions with the same outcomes w.r.t. goals (1) and (2), they choose a decision uniformly at random among those decisions. If you try for n=3 and 4, it quickly becomes clear that players will follow a mixed strategy. Is there a closed form P_n(k) for the probability that player k survives in the n-player survivor game? (Players are not allowed to agree on strategies beforehand. The only information they can share is their announcement of who to eliminate.) We found a strategy for n=3 and made a tree of choices for n=4, but there's no clear sign of it being trivial for any given n. I can answer questions about the game, so you can ask in comments. I'll be up for a while. The game runs exactly once, so there may not be a clear winner, just surviving and eliminated players. I'm noting ""player k chooses player j"" as k!j to simplify the notation.","Came up with a following game recently and after trying to understand the general strategy for hours I have to admit I failed at finding one, so I thought asking here would be a good idea. As a good friend of mine restated: Define the ""n-player survivor game"" as follows: label the players 1, .., n. First, in ascending order by index, each player publicly announces who they plan to eliminate (possibly themselves). Then, in descending order by index, each player eliminates the player they previously announced. If a player is already eliminated, they can no longer eliminate the player they previously announced. Each player is rational, with the following goals [in order]: (1) survive (don't get eliminated); (2) leave as few survivors as possible. If some player k can make multiple decisions with the same outcomes w.r.t. goals (1) and (2), they choose a decision uniformly at random among those decisions. If you try for n=3 and 4, it quickly becomes clear that players will follow a mixed strategy. Is there a closed form P_n(k) for the probability that player k survives in the n-player survivor game? (Players are not allowed to agree on strategies beforehand. The only information they can share is their announcement of who to eliminate.) We found a strategy for n=3 and made a tree of choices for n=4, but there's no clear sign of it being trivial for any given n. I can answer questions about the game, so you can ask in comments. I'll be up for a while. The game runs exactly once, so there may not be a clear winner, just surviving and eliminated players. I'm noting ""player k chooses player j"" as k!j to simplify the notation.",,"['probability', 'combinatorial-game-theory']"
48,Expected number of rolls until all consecutive differences have been seen,Expected number of rolls until all consecutive differences have been seen,,"Call a consecutive difference"" the absolute value of the difference between two consecutive rolls of a $6$ sided die. For example, the sequence of rolls $143511$ has the corresponding sequence of consecutive differences $31240$ . What is the expected number of rolls until all $6$ consecutive differences have appeared? I can see that there are $6$ possible consecutive differences: $0, 1,...,5$ and they appear among any pair of dice with probability $6/36, 10/36, 8/36, 6/36, 4/36, 2/36$ respectively. However, they could come in all sorts of orders. I am happy with answers that are close approximations. By simulation the answer is around 25.8.","Call a consecutive difference"" the absolute value of the difference between two consecutive rolls of a sided die. For example, the sequence of rolls has the corresponding sequence of consecutive differences . What is the expected number of rolls until all consecutive differences have appeared? I can see that there are possible consecutive differences: and they appear among any pair of dice with probability respectively. However, they could come in all sorts of orders. I am happy with answers that are close approximations. By simulation the answer is around 25.8.","6 143511 31240 6 6 0, 1,...,5 6/36, 10/36, 8/36, 6/36, 4/36, 2/36","['probability', 'probability-theory', 'expected-value', 'dice']"
49,"If the positive part of submartingale is uniformly integrable, it is closable","If the positive part of submartingale is uniformly integrable, it is closable",,"I am kind of confused in reading the next proof of a theorem in ""Stochastic Analysis: Itô and Malliavin Calculus"" in Tandem by Matsumoto & Taniguchi; Here, a closable submartingale $\{ Z_n \}_n$ is defined as a submartingale that is bounded by an integrable random variable $Z$ in $$ Z_n \leq \textrm{E}[Z|\mathcal{F}_n]. $$ Where I am stuck : The equation in the middle, \begin{equation} \mathrm{E}[Y|\mathcal{F}_n] = \lim_{m \rightarrow \infty} \mathrm{E}[X_m^+ | \mathcal{F}_n]. \tag{1} \label{eq:question} \end{equation} I don't see why we can get the limit out of the expectation. The text says ""since $X_n^+$ converges also in $L^1$ "", but I don't think when $X_n \rightarrow X$ in $L^1$ , it always holds for a sub- $\sigma$ -algebra $\mathcal{G}$ , $$ \textrm{E}[X_n | \mathcal{G}] \rightarrow \textrm{E}[X | \mathcal{G}] \quad \textrm{a.s.} $$ For we have a counterexample: we take $\mathcal{G} = \mathcal{F}$ (where $\mathcal{F}$ is the $\sigma$ -algebra of the whole probability space) and $\{X_n\}$ such that $X_n \rightarrow X$ in $L^1$ but not $\textrm{a.s.}$ , then $$ \textrm{E}[X_n | \mathcal{F}] = X_n \not\rightarrow X = \textrm{E}[X | \mathcal{F}]  \quad \textrm{a.s.} $$ So how can we validate Eq.\eqref{eq:question}?","I am kind of confused in reading the next proof of a theorem in ""Stochastic Analysis: Itô and Malliavin Calculus"" in Tandem by Matsumoto & Taniguchi; Here, a closable submartingale is defined as a submartingale that is bounded by an integrable random variable in Where I am stuck : The equation in the middle, I don't see why we can get the limit out of the expectation. The text says ""since converges also in "", but I don't think when in , it always holds for a sub- -algebra , For we have a counterexample: we take (where is the -algebra of the whole probability space) and such that in but not , then So how can we validate Eq.\eqref{eq:question}?","\{ Z_n \}_n Z 
Z_n \leq \textrm{E}[Z|\mathcal{F}_n].
 \begin{equation}
\mathrm{E}[Y|\mathcal{F}_n] = \lim_{m \rightarrow \infty} \mathrm{E}[X_m^+ | \mathcal{F}_n].
\tag{1}
\label{eq:question}
\end{equation} X_n^+ L^1 X_n \rightarrow X L^1 \sigma \mathcal{G} 
\textrm{E}[X_n | \mathcal{G}] \rightarrow \textrm{E}[X | \mathcal{G}] \quad \textrm{a.s.}
 \mathcal{G} = \mathcal{F} \mathcal{F} \sigma \{X_n\} X_n \rightarrow X L^1 \textrm{a.s.} 
\textrm{E}[X_n | \mathcal{F}] = X_n \not\rightarrow X = \textrm{E}[X | \mathcal{F}]  \quad \textrm{a.s.}
","['probability', 'probability-theory', 'martingales', 'uniform-integrability']"
50,What happens if I do a fractional number of Bernoulli trials?,What happens if I do a fractional number of Bernoulli trials?,,"I want to simulate $n$ independent Bernoulli trials with probability of success $p$ , and calculate the probability that at least one of those trials succeeds. If multiple trials succeed, I don't particularly care how many. So I use this formula to calculate the overall probability of at least one success: $$ 1 - (1 - p)^n $$ I then do a single Bernoulli trial with the above probability. That works quite well, as it allows me to aggregate many Bernoulli trials into a single meta-trial. If this meta-trial fails, I can later conduct another (once a meta-trial succeeds, I stop running trials altogether). (I am aware that I could instead draw from a geometric distribution in advance, add up the values of $n$ , and wait until I exceed the value drawn. But keeping track of the total value of $n$ is inconvenient, so I don't do this.) Now, I'm beginning to think that I want to have ""fractional trials"" to deal with cases where an event is smeared out over time instead of happening in a single discrete lump. There are two ""obvious"" ways to do that: Just let $n$ be a positive real number (technically, a floating point number) and use the same formula as above. Use a Poisson distribution with $\lambda = np$ , so that the resulting probability is $1 - e^{-np}$ . I understand, in general terms, what (2) is simulating: It's a Poisson process with rate $p$ and length or ""duration"" $n$ . On average, a success happens every $\frac{1}{p}$ units of length, and we're asking whether any successes happen within the next $n$ units of length. What I don't understand is (1). I can visualize it as a binomial distribution for integral $n$ , but if $n$ is a real number, it's unclear to me what the probability actually represents, in a simple and intuitive way. I can see that: (1) is equivalent to (2) for large $n$ and small $p$ (by the Poisson limit theorem). For both (1) and (2), the probability of at least one success is not affected by combining or splitting meta-trials, when $p$ is held constant. So neither of them is ""obviously wrong."" For non-small $p$ , (1) has a higher probability of a success than (2) (by playing around in Desmos). For small $p$ , (1) is still bigger, but the difference is negligible. I believe that this corresponds to the fact that in (1), $p$ is a probability, and we approach a degenerate case as $p$ approaches 1, while in (2), $p$ is ""just"" a density factor and is not bounded above by $p = 1$ . My understanding of the geometric distribution suggests that (1) should have a success on average every $\frac{1}{p}$ units of length. But that seems unlikely since (2) already has that property, and (1) is always greater than (2). Ultimately, I need to choose between these two ways of modeling my problem, and I want to understand what (1) represents in order to make that decision. What does the binomial distribution intuitively represent, if $n$ is not an integer?","I want to simulate independent Bernoulli trials with probability of success , and calculate the probability that at least one of those trials succeeds. If multiple trials succeed, I don't particularly care how many. So I use this formula to calculate the overall probability of at least one success: I then do a single Bernoulli trial with the above probability. That works quite well, as it allows me to aggregate many Bernoulli trials into a single meta-trial. If this meta-trial fails, I can later conduct another (once a meta-trial succeeds, I stop running trials altogether). (I am aware that I could instead draw from a geometric distribution in advance, add up the values of , and wait until I exceed the value drawn. But keeping track of the total value of is inconvenient, so I don't do this.) Now, I'm beginning to think that I want to have ""fractional trials"" to deal with cases where an event is smeared out over time instead of happening in a single discrete lump. There are two ""obvious"" ways to do that: Just let be a positive real number (technically, a floating point number) and use the same formula as above. Use a Poisson distribution with , so that the resulting probability is . I understand, in general terms, what (2) is simulating: It's a Poisson process with rate and length or ""duration"" . On average, a success happens every units of length, and we're asking whether any successes happen within the next units of length. What I don't understand is (1). I can visualize it as a binomial distribution for integral , but if is a real number, it's unclear to me what the probability actually represents, in a simple and intuitive way. I can see that: (1) is equivalent to (2) for large and small (by the Poisson limit theorem). For both (1) and (2), the probability of at least one success is not affected by combining or splitting meta-trials, when is held constant. So neither of them is ""obviously wrong."" For non-small , (1) has a higher probability of a success than (2) (by playing around in Desmos). For small , (1) is still bigger, but the difference is negligible. I believe that this corresponds to the fact that in (1), is a probability, and we approach a degenerate case as approaches 1, while in (2), is ""just"" a density factor and is not bounded above by . My understanding of the geometric distribution suggests that (1) should have a success on average every units of length. But that seems unlikely since (2) already has that property, and (1) is always greater than (2). Ultimately, I need to choose between these two ways of modeling my problem, and I want to understand what (1) represents in order to make that decision. What does the binomial distribution intuitively represent, if is not an integer?","n p 
1 - (1 - p)^n
 n n n \lambda = np 1 - e^{-np} p n \frac{1}{p} n n n n p p p p p p p p = 1 \frac{1}{p} n","['probability', 'probability-distributions', 'soft-question', 'poisson-distribution']"
51,"Find the minimum of $P(X=0)$ when $E[X]=1,E[X^2]=2,E[X^3]=5$ using the probability generating function",Find the minimum of  when  using the probability generating function,"P(X=0) E[X]=1,E[X^2]=2,E[X^3]=5","I was given the following exercise. Let $X$ be a random variable that takes non-negative natural number values such that $E[X]=1,E[X^2]=2,E[X^3]=5$ . Find the minimum value of $P(X=0)$ using the taylor expansion of the probability generating function at $z=1$ . I know the method not using the generating function stated in this question . My attempt: Let $G(z)=E[z^X]$ be the probability generating function of $X$ . Then by definition, $G(z) = P(X=0)+P(X=1)z+P(X=2)z^2+\cdots $ Also, since $E[\frac{X(X-1)\cdots (X-n+1)}{n!}]=\frac{G^{(n)}(1)}{n!}$ according to Wikipedia , we have $\displaystyle G(z) = \sum_{n=0}^{\infty}E\left[\frac{X(X-1)\cdots (X-n+1)}{n!}\right](z-1)^n$ Substituting $z=0$ yields $\displaystyle P(X=0) = \sum_{n=0}^{\infty}E\left[\frac{X(X-1)\cdots (X-n+1)}{n!}\right](-1)^n$ Note that for $n=0,1,2,3$ , the coefficient can be calculated as follows: $\begin{align} E[1] &= 1  \\ E[X]&= 1 \\ E[X(X-1)/2] &= E[X^2]/2 -E[X]/2 = 1-1/2 =1/2 \\ E[X(X-1)(X-2)/3!] &= E[X^3]/6 -E[X^2]/2 +E[X]/3 = 5/6-2/2+1/3 \\ &= 1/6 \end{align}$ Therefore, $\displaystyle \begin{align} P(X=0) &= \sum_{n=0}^{\infty}E\left[\frac{X(X-1)\cdots (X-n+1)}{n!}\right](-1)^n \\ &=1-1+\frac{1}{2} -\frac{1}{6} +\sum_{n=4}^{\infty}E\left[\frac{X(X-1)\cdots (X-n+1)}{n!}\right](-1)^n \\ &= \frac{1}{3} + \sum_{n=4}^{\infty}E\left[\frac{X(X-1)\cdots (X-n+1)}{n!}\right](-1)^n\end{align}$ According to the question linked above, $1/3$ is the minimum, so I think we need to prove that the sum is non-negative to complete the proof. However, I was unable to do so. Am I on the right path? If not, what is the correct one? If yes, how can I finish it?","I was given the following exercise. Let be a random variable that takes non-negative natural number values such that . Find the minimum value of using the taylor expansion of the probability generating function at . I know the method not using the generating function stated in this question . My attempt: Let be the probability generating function of . Then by definition, Also, since according to Wikipedia , we have Substituting yields Note that for , the coefficient can be calculated as follows: Therefore, According to the question linked above, is the minimum, so I think we need to prove that the sum is non-negative to complete the proof. However, I was unable to do so. Am I on the right path? If not, what is the correct one? If yes, how can I finish it?","X E[X]=1,E[X^2]=2,E[X^3]=5 P(X=0) z=1 G(z)=E[z^X] X G(z) = P(X=0)+P(X=1)z+P(X=2)z^2+\cdots  E[\frac{X(X-1)\cdots (X-n+1)}{n!}]=\frac{G^{(n)}(1)}{n!} \displaystyle G(z) = \sum_{n=0}^{\infty}E\left[\frac{X(X-1)\cdots (X-n+1)}{n!}\right](z-1)^n z=0 \displaystyle P(X=0) = \sum_{n=0}^{\infty}E\left[\frac{X(X-1)\cdots (X-n+1)}{n!}\right](-1)^n n=0,1,2,3 \begin{align} E[1] &= 1  \\ E[X]&= 1 \\ E[X(X-1)/2] &= E[X^2]/2 -E[X]/2 = 1-1/2 =1/2 \\ E[X(X-1)(X-2)/3!] &= E[X^3]/6 -E[X^2]/2 +E[X]/3 = 5/6-2/2+1/3 \\ &= 1/6 \end{align} \displaystyle \begin{align} P(X=0) &= \sum_{n=0}^{\infty}E\left[\frac{X(X-1)\cdots (X-n+1)}{n!}\right](-1)^n \\ &=1-1+\frac{1}{2} -\frac{1}{6} +\sum_{n=4}^{\infty}E\left[\frac{X(X-1)\cdots (X-n+1)}{n!}\right](-1)^n \\ &= \frac{1}{3} + \sum_{n=4}^{\infty}E\left[\frac{X(X-1)\cdots (X-n+1)}{n!}\right](-1)^n\end{align} 1/3","['probability', 'generating-functions']"
52,"What are the odds that after hitting shuffle twice on a 155 unique songs playlist on spotify, 3 of the 6 first songs are the same on both shuffle.","What are the odds that after hitting shuffle twice on a 155 unique songs playlist on spotify, 3 of the 6 first songs are the same on both shuffle.",,"Imagine you have $155$ unique songs in a playlist on Spotify. You hit shuffle. Out of the first $6$ songs, you have $3$ particular songs that we'll name ""song A"", ""song B"", and ""song C"". The order in which these $3$ songs show up within those first $6$ songs doesn't matter. Then, you hit shuffle again and get another set of $6$ songs. $3$ of those $6$ songs are once again A, B, and C. What are the odds of this happening? I'm kinda stuck trying to math this. I know that you have $$\frac{155!}{6!(155-6)!}$$ different ways to select $6$ songs and that would be a denominator for a probability ""P"". You would then get a numerator and multiply $P$ by itself ( $P^2$ ) because we shuffle $2$ times. Anyways, I think that's what I need to do. The numerator is where I get stuck. Not sure how to calculate it. Anyone can help? Am I on the right track?","Imagine you have unique songs in a playlist on Spotify. You hit shuffle. Out of the first songs, you have particular songs that we'll name ""song A"", ""song B"", and ""song C"". The order in which these songs show up within those first songs doesn't matter. Then, you hit shuffle again and get another set of songs. of those songs are once again A, B, and C. What are the odds of this happening? I'm kinda stuck trying to math this. I know that you have different ways to select songs and that would be a denominator for a probability ""P"". You would then get a numerator and multiply by itself ( ) because we shuffle times. Anyways, I think that's what I need to do. The numerator is where I get stuck. Not sure how to calculate it. Anyone can help? Am I on the right track?",155 6 3 3 6 6 3 6 \frac{155!}{6!(155-6)!} 6 P P^2 2,"['probability', 'combinations']"
53,Linear-time sampling of stochastic processes?,Linear-time sampling of stochastic processes?,,"Are there any stochastic processes $(X_t)_{t \in \mathbb{R}^d}$ such that almost surely paths are continuous but nowhere differentiable and sampling of $n$ points $X_{t_n}$ on a path can be done in $O(n)$ time? Most sampling techniques I have in mind require at least $O(n \log n)$ time. On the the other hand, all linear-time samplers I know, create processes such that 1) fails; like Perlin-noise, White noise, Pink noise, etc. Is it even theoretically possible? So this might be a very fundamental question.","Are there any stochastic processes such that almost surely paths are continuous but nowhere differentiable and sampling of points on a path can be done in time? Most sampling techniques I have in mind require at least time. On the the other hand, all linear-time samplers I know, create processes such that 1) fails; like Perlin-noise, White noise, Pink noise, etc. Is it even theoretically possible? So this might be a very fundamental question.",(X_t)_{t \in \mathbb{R}^d} n X_{t_n} O(n) O(n \log n),"['probability', 'stochastic-processes', 'random', 'random-functions']"
54,The probability that more than 10500 passengers travel with buses in 72 hours,The probability that more than 10500 passengers travel with buses in 72 hours,,"Question : Buses go from a terminal to a destination city with a rate of $10$ bus per hour. The number of passengers on each bus is independent of the other buses and assumed to follow this distribution: $10$ passengers with a probability of $0.6$ , $20$ passengers with a probability of $0.2$ , and $30$ passengers with a probability of $0.2$ . What is the probability that in $72$ hours, more than $10500$ passengers reach the destination using the buses in this terminal? (Hint: you should use normal approximation ) Note : I've seen a lot of similar questions. However, this one asks for the probability of something related to number of passengers, and not a probability which is related to the waiting time of the buses. My problem is that I cannot even understand what random variable we are looking for. For instance, can I conclude that in $72$ hours, $720$ buses will pass? If yes, then what? How should I proceed? I mean, first of all I need somebody to rewrite the question in a  mathematical way.","Question : Buses go from a terminal to a destination city with a rate of bus per hour. The number of passengers on each bus is independent of the other buses and assumed to follow this distribution: passengers with a probability of , passengers with a probability of , and passengers with a probability of . What is the probability that in hours, more than passengers reach the destination using the buses in this terminal? (Hint: you should use normal approximation ) Note : I've seen a lot of similar questions. However, this one asks for the probability of something related to number of passengers, and not a probability which is related to the waiting time of the buses. My problem is that I cannot even understand what random variable we are looking for. For instance, can I conclude that in hours, buses will pass? If yes, then what? How should I proceed? I mean, first of all I need somebody to rewrite the question in a  mathematical way.",10 10 0.6 20 0.2 30 0.2 72 10500 72 720,"['probability', 'random-variables']"
55,Probability of recurrence for a random walk in $\mathbb Z^3$,Probability of recurrence for a random walk in,\mathbb Z^3,"Let $\mathbf X(n)$ be a random walk in $\mathbb Z^3$ in the following sense: We start at the point $\mathbf 0=(0,0,0)$ and for each step, we randomly decide in which of the three directions we move by $\pm 1$ step (i.e., there are $6$ possibilities for each step, each with probability $1/6$ ). It is well-known that this random walk is transient, i.e. $\mathbf P(\mathbf X(n)=\mathbf 0\text{ for some }n\geq 1) \neq 1$ . My question is if this probability can actually be calculated; or if there is some result on what this value is. All sources I found only mention the $\neq 1$ part, but do not comment on the actual value.","Let be a random walk in in the following sense: We start at the point and for each step, we randomly decide in which of the three directions we move by step (i.e., there are possibilities for each step, each with probability ). It is well-known that this random walk is transient, i.e. . My question is if this probability can actually be calculated; or if there is some result on what this value is. All sources I found only mention the part, but do not comment on the actual value.","\mathbf X(n) \mathbb Z^3 \mathbf 0=(0,0,0) \pm 1 6 1/6 \mathbf P(\mathbf X(n)=\mathbf 0\text{ for some }n\geq 1) \neq 1 \neq 1","['probability', 'stochastic-processes', 'markov-chains', 'random-walk']"
56,Wasserstein Metric: Question About Empirical Computation,Wasserstein Metric: Question About Empirical Computation,,"I am trying to estimate the Wasserstein distance between two empirical distributions for which I only have two sets of data which effectively create two histograms. I am reading here that the computation for this 1-dimensional case where we want to compute $W_p(P,Q)$ when $p=1$ then the formula is: $$W_1(P,Q) = \sum_{i=1}^n |X_i - Y_i|$$ where we have $n$ data points and $X_i$ and $Y_i$ come from the data sets representing $P$ and $Q$ respectively. My question here is: isn't the order of the $X_i$ and $Y_i$ important? I am envisioning two Gaussians with the same distribution, $P=Q \implies W_1(P,Q)=0$ but the data is the same but order is reversed: $X_i = Y_{(n+1)-i}$ . This empirical estimate will be non-zero. I am just asking here because there is no mention of the order of the data but it does seem important. I am trying to compute some of these metrics and I'm wondering if I should first sort the data somehow.","I am trying to estimate the Wasserstein distance between two empirical distributions for which I only have two sets of data which effectively create two histograms. I am reading here that the computation for this 1-dimensional case where we want to compute when then the formula is: where we have data points and and come from the data sets representing and respectively. My question here is: isn't the order of the and important? I am envisioning two Gaussians with the same distribution, but the data is the same but order is reversed: . This empirical estimate will be non-zero. I am just asking here because there is no mention of the order of the data but it does seem important. I am trying to compute some of these metrics and I'm wondering if I should first sort the data somehow.","W_p(P,Q) p=1 W_1(P,Q) = \sum_{i=1}^n |X_i - Y_i| n X_i Y_i P Q X_i Y_i P=Q \implies W_1(P,Q)=0 X_i = Y_{(n+1)-i}","['probability', 'probability-distributions']"
57,Optimal strategy for selling turnips,Optimal strategy for selling turnips,,"You have a pile of $N$ turnips that you need to get rid of in $n$ days. The turnip price every day is independently and uniformly distributed in $[0, 1]$ . You can sell any amount of turnips every day, but you must sell everything by the last day. What strategy should you employ to maximize your profits? ( Context. This is related to the ""stalk market"" in Animal Crossing: New Horizons ; see edit history.)","You have a pile of turnips that you need to get rid of in days. The turnip price every day is independently and uniformly distributed in . You can sell any amount of turnips every day, but you must sell everything by the last day. What strategy should you employ to maximize your profits? ( Context. This is related to the ""stalk market"" in Animal Crossing: New Horizons ; see edit history.)","N n [0, 1]","['probability', 'optimization', 'expected-value']"
58,Combinations & probability: dividing 9 people into 3 groups,Combinations & probability: dividing 9 people into 3 groups,,"I'm struggling to understand the procedure to solve the following problem: The group consists of 9 people, 3 men and 6 women. They are divided randomly into 3 groups (3 persons each). What's the probability that.. a) all men are in the same group? b) all men are in different groups? I somehow managed to calculate a) as follows: all combinations: 9!/(3!^4) = 280 combinations of all men in one group: 6!/(3!*3!*2!) = 10 probability: 10/280 = 0,03571.. Please, do let me know if I am doing this wrong. Also, I do not know how to figure out b) all men in different groups. Asking for your advice, thank you!","I'm struggling to understand the procedure to solve the following problem: The group consists of 9 people, 3 men and 6 women. They are divided randomly into 3 groups (3 persons each). What's the probability that.. a) all men are in the same group? b) all men are in different groups? I somehow managed to calculate a) as follows: all combinations: 9!/(3!^4) = 280 combinations of all men in one group: 6!/(3!*3!*2!) = 10 probability: 10/280 = 0,03571.. Please, do let me know if I am doing this wrong. Also, I do not know how to figure out b) all men in different groups. Asking for your advice, thank you!",,"['probability', 'combinatorics', 'combinations']"
59,Calculating probability of next event given remaining count and range for each,Calculating probability of next event given remaining count and range for each,,"(Apologies if my use of terms is off - I am not a mathematician by trade and what I did learn way back was in a different language) What I know: the total length of the stream, the body of possible events, the pop-count for each event, and the range of each event (essentially the index of the last instance of this event). What I want: Given an incoming stream of events I am trying to predict what the next event is likely to be, i.e. calculate the probability of the next event being a particular one of the known population. Example: Let's say the incoming stream is ABABCCCC (not known by the receiver) Known by the receiver: Length=8     Count Range  A: 2     3      B: 2     4      C: 4     8 Ignoring the range component we can trivially calculate the probability of each event by dividing its pop-count into the total message length: Count Range Prob A: 2     3     0.25 B: 2     4     0.25 C: 4     8     0.50 When looking at the range we can calculate the local probability of each event being next (by local I mean considering only the current event). Count Range Local prob A: 2     3     2/3 = 0.6666 B: 2     4     2/4 = 0.5 C: 4     8     4/8 = 0.5 But how do I combine the two types of probability into one value without enumerating all combinations and testing each one to see if it matches the constraints? It's obvious from inspection that in this particular case the probability of the next event being a C is 0.0 here as having anything but A or B as the first event would prevent all of the As and Bs from occurring within their range, but it's not clear to me what the formal calculation should look like. - Some more context: In the real scenario, number of unique events can run into the low thousands while the stream length can be up to a few billions while the million range will be more typical. I can pre-calculate a few incoming events essentially for free so I want to pick the most probably one(s) for that in an attempt to save overall cost. Events can come and go - one of the static events is Define New Event - I did not include this fact initially because it does not affect the issue at hand. Sometimes all live ranges will be so long that the individual ranges don't matter - I can just go with the straight probability based on pop-count alone, but every once in a while there'll be short bursts of events that are short-lived but whose probability will locally exceed those of the longer-lived, more populous events. Calculation does not have to be exact - if I can calculate a reasonable trend then that will definitely help.","(Apologies if my use of terms is off - I am not a mathematician by trade and what I did learn way back was in a different language) What I know: the total length of the stream, the body of possible events, the pop-count for each event, and the range of each event (essentially the index of the last instance of this event). What I want: Given an incoming stream of events I am trying to predict what the next event is likely to be, i.e. calculate the probability of the next event being a particular one of the known population. Example: Let's say the incoming stream is ABABCCCC (not known by the receiver) Known by the receiver: Length=8     Count Range  A: 2     3      B: 2     4      C: 4     8 Ignoring the range component we can trivially calculate the probability of each event by dividing its pop-count into the total message length: Count Range Prob A: 2     3     0.25 B: 2     4     0.25 C: 4     8     0.50 When looking at the range we can calculate the local probability of each event being next (by local I mean considering only the current event). Count Range Local prob A: 2     3     2/3 = 0.6666 B: 2     4     2/4 = 0.5 C: 4     8     4/8 = 0.5 But how do I combine the two types of probability into one value without enumerating all combinations and testing each one to see if it matches the constraints? It's obvious from inspection that in this particular case the probability of the next event being a C is 0.0 here as having anything but A or B as the first event would prevent all of the As and Bs from occurring within their range, but it's not clear to me what the formal calculation should look like. - Some more context: In the real scenario, number of unique events can run into the low thousands while the stream length can be up to a few billions while the million range will be more typical. I can pre-calculate a few incoming events essentially for free so I want to pick the most probably one(s) for that in an attempt to save overall cost. Events can come and go - one of the static events is Define New Event - I did not include this fact initially because it does not affect the issue at hand. Sometimes all live ranges will be so long that the individual ranges don't matter - I can just go with the straight probability based on pop-count alone, but every once in a while there'll be short bursts of events that are short-lived but whose probability will locally exceed those of the longer-lived, more populous events. Calculation does not have to be exact - if I can calculate a reasonable trend then that will definitely help.",,['probability']
60,Picking pawns from pouch,Picking pawns from pouch,,"You have a pouch containing 4 chess pawns. Your prior knowledge is that the pouch does not contain exactly 2 black and 2 white pieces. All other proportions of colours are equally probable (e.g. 3 black and 1 white is equally probable as 4 black pieces). The first piece drawn from the bag is black. What is the probability that the next piece drawn is also black? I tried solving this problem in the following way: The states can be represented by the number of black pieces in the pouch and is then written as: $$B = \{0,1,3,4\}$$ , with probability distribution $$P = \{\frac{1}{4},\frac{1}{4},\frac{1}{4},\frac{1}{4}\}$$ . The possible states of a measurement are picking up a black piece or picking up a white one. We denote these states as $$C = \{b, w\}$$ The first measurement has a probability distribution of $$Q = \{q_{b}, q_{w}\} = \{\frac{1}{2},\frac{1}{2}\}$$ where we are equally likely to pick up a white or a black piece. This is due to the weighted sum of black and white pieces in the possible states being equal. Let's say we pick a black piece. Now reevaluate the probabilities of the states $B$ . This can be done by counting in how many ways we could have picked a black piece from each state and weighting the probabilities by that number. $$P|b = \{0,\frac{1}{8},\frac{3}{8},\frac{4}{8}\}$$ From these probabilities we can once again do a weighted sum of black and white pieces. It's a bit more complicated this time so I'll write it out. $$b_{sum} = 0\cdot-1+\frac{1}{8}\cdot 0 +\frac{3}{8}\cdot 2 +\frac{4}{8}\cdot 3 = \frac{18}{8} = \frac{9}{4}$$ $$w_{sum} = 0\cdot4+\frac{1}{8}\cdot 3 +\frac{3}{8}\cdot 1 +\frac{4}{8}\cdot 0 = \frac{6}{8} = \frac{3}{4}$$ $$Q|b = \{q_b|b, q_w|b\} = \{\frac{b_{sum}}{b_{sum} + w_{sum}}, \frac{w_{sum}}{b_{sum} + w_{sum}}\} = \{\frac{3}{4}, \frac{1}{4}\}$$ This result was so unintuitive to me that I had to doubt the logic of my reasoning. I tried redoing the calculations with a bag of pieces where the state of two black and two white was allowed and got a similar result of black being much more likely as the second pick if it was the first. Is this correct? How can it be understood in relation to 4 uncorrelated chess pawns in a bag where each measurement would have a probability of $\frac{1}{2}$ to be true?","You have a pouch containing 4 chess pawns. Your prior knowledge is that the pouch does not contain exactly 2 black and 2 white pieces. All other proportions of colours are equally probable (e.g. 3 black and 1 white is equally probable as 4 black pieces). The first piece drawn from the bag is black. What is the probability that the next piece drawn is also black? I tried solving this problem in the following way: The states can be represented by the number of black pieces in the pouch and is then written as: , with probability distribution . The possible states of a measurement are picking up a black piece or picking up a white one. We denote these states as The first measurement has a probability distribution of where we are equally likely to pick up a white or a black piece. This is due to the weighted sum of black and white pieces in the possible states being equal. Let's say we pick a black piece. Now reevaluate the probabilities of the states . This can be done by counting in how many ways we could have picked a black piece from each state and weighting the probabilities by that number. From these probabilities we can once again do a weighted sum of black and white pieces. It's a bit more complicated this time so I'll write it out. This result was so unintuitive to me that I had to doubt the logic of my reasoning. I tried redoing the calculations with a bag of pieces where the state of two black and two white was allowed and got a similar result of black being much more likely as the second pick if it was the first. Is this correct? How can it be understood in relation to 4 uncorrelated chess pawns in a bag where each measurement would have a probability of to be true?","B = \{0,1,3,4\} P = \{\frac{1}{4},\frac{1}{4},\frac{1}{4},\frac{1}{4}\} C = \{b, w\} Q = \{q_{b}, q_{w}\} = \{\frac{1}{2},\frac{1}{2}\} B P|b = \{0,\frac{1}{8},\frac{3}{8},\frac{4}{8}\} b_{sum} = 0\cdot-1+\frac{1}{8}\cdot 0 +\frac{3}{8}\cdot 2 +\frac{4}{8}\cdot 3 = \frac{18}{8} = \frac{9}{4} w_{sum} = 0\cdot4+\frac{1}{8}\cdot 3 +\frac{3}{8}\cdot 1 +\frac{4}{8}\cdot 0 = \frac{6}{8} = \frac{3}{4} Q|b = \{q_b|b, q_w|b\} = \{\frac{b_{sum}}{b_{sum} + w_{sum}}, \frac{w_{sum}}{b_{sum} + w_{sum}}\} = \{\frac{3}{4}, \frac{1}{4}\} \frac{1}{2}","['probability', 'discrete-mathematics']"
61,Probabilistic modelling,Probabilistic modelling,,"This question is about how to make sense of a probabilistic model I'm reading about: You have three random variable $A$ , $B$ and $C$ that are all real-valued. You want to model an input-output relationship with these random variables, by assuming the following relationships between them: It is assumed that $A$ is the constant random variable that only takes the value $a\in \mathbb {R}$ , where $a$ is thought of as input. Furthermore, $P(B=b | A=a)=\mathcal{N}(b;3\cdot e^a,1)$ and $P(C=c | B=b)=\mathcal{N}(c;2\cdot b^2,1)$ , where $\mathcal{N}(x;\mu,1)$ denotes the probability density of a normal distribution with mean $\mu$ and variance $1$ . My questions are: Does an equation like $P(B=b | A=a)=\mathcal{N}(b;3\cdot e^a,1)$ even make sense? If we takes samples, on the left we have a number between $0$ and $1$ but on the right we have a number that can be larger, as the pdf does not need to stay within $[0,1]$ , right? What is the output? In the (not online available) text I'm reading, the above is all that is mentioned. I would assume that to arrive at the output, one needs to proceed in the following way: Given $a$ , draw a number $b$ from a normally distribution with mean $3\cdot e^a$ and unit variance and then similarly draw $c$ , the output, from a normally distribution with mean with mean $2\cdot b^2$ and unit variance. But I'm not sure if that's correct; also, it is not clear to me, in case this interpretation is indeed correct, why conditional probabilities in the model formulation are needed.","This question is about how to make sense of a probabilistic model I'm reading about: You have three random variable , and that are all real-valued. You want to model an input-output relationship with these random variables, by assuming the following relationships between them: It is assumed that is the constant random variable that only takes the value , where is thought of as input. Furthermore, and , where denotes the probability density of a normal distribution with mean and variance . My questions are: Does an equation like even make sense? If we takes samples, on the left we have a number between and but on the right we have a number that can be larger, as the pdf does not need to stay within , right? What is the output? In the (not online available) text I'm reading, the above is all that is mentioned. I would assume that to arrive at the output, one needs to proceed in the following way: Given , draw a number from a normally distribution with mean and unit variance and then similarly draw , the output, from a normally distribution with mean with mean and unit variance. But I'm not sure if that's correct; also, it is not clear to me, in case this interpretation is indeed correct, why conditional probabilities in the model formulation are needed.","A B C A a\in \mathbb
{R} a P(B=b | A=a)=\mathcal{N}(b;3\cdot e^a,1) P(C=c | B=b)=\mathcal{N}(c;2\cdot b^2,1) \mathcal{N}(x;\mu,1) \mu 1 P(B=b | A=a)=\mathcal{N}(b;3\cdot e^a,1) 0 1 [0,1] a b 3\cdot e^a c 2\cdot b^2","['probability', 'mathematical-modeling', 'density-function']"
62,Out of the box & WOW effect Probability,Out of the box & WOW effect Probability,,"It is a common knowledge, that problems from graph theory/combinatorics can be often solved via short and astonishing probabilistic reasoning. In contrast to this, it is much harder to find such ""out of the box""/""WOW effect"" solutions for analysis, topology or algebra problems. So, what are your favorite problems like this, how do you prove them? This question was inspired by a very nice analysis problem: evaluate $ \ \lim_{n\to \infty} e^{-n} \cdot \sum_{k=0}^{n}\frac{n^k}{k!}$ . with the following, extremely beautiful solution: This is $P[N_n\leqslant n]$ where $N_n$ is a random variable with Poisson distribution of parameter $n$ . Hence each $N_n$ is distributed like $X_1+\cdots+X_n$ where the random variables $(X_k)$ are independent and identically distributed with Poisson distribution of parameter $1$ . By the central limit theorem, $Y_n=\frac1{\sqrt{n}}(X_1+\cdots+X_n-n)$ converges in distribution to a standard normal random variable $Z$ , in particular, $P[Y_n\leqslant 0]\to P[Z\leqslant0]$ . Finally, $P[Z\leqslant0]=\frac12$ and $[N_n\leqslant n]=[Y_n\leqslant 0]$ hence $P[N_n\leqslant n]\to\frac12$ , QED. Both, question and solution come from Evaluating $\lim\limits_{n\to\infty} e^{-n} \sum\limits_{k=0}^{n} \frac{n^k}{k!}$ . I think  that such a list might be helpful for educational purposes. Such problems act on the imagination of students/listeners and much more likely raise their interest.","It is a common knowledge, that problems from graph theory/combinatorics can be often solved via short and astonishing probabilistic reasoning. In contrast to this, it is much harder to find such ""out of the box""/""WOW effect"" solutions for analysis, topology or algebra problems. So, what are your favorite problems like this, how do you prove them? This question was inspired by a very nice analysis problem: evaluate . with the following, extremely beautiful solution: This is where is a random variable with Poisson distribution of parameter . Hence each is distributed like where the random variables are independent and identically distributed with Poisson distribution of parameter . By the central limit theorem, converges in distribution to a standard normal random variable , in particular, . Finally, and hence , QED. Both, question and solution come from Evaluating $\lim\limits_{n\to\infty} e^{-n} \sum\limits_{k=0}^{n} \frac{n^k}{k!}$ . I think  that such a list might be helpful for educational purposes. Such problems act on the imagination of students/listeners and much more likely raise their interest.", \ \lim_{n\to \infty} e^{-n} \cdot \sum_{k=0}^{n}\frac{n^k}{k!} P[N_n\leqslant n] N_n n N_n X_1+\cdots+X_n (X_k) 1 Y_n=\frac1{\sqrt{n}}(X_1+\cdots+X_n-n) Z P[Y_n\leqslant 0]\to P[Z\leqslant0] P[Z\leqslant0]=\frac12 [N_n\leqslant n]=[Y_n\leqslant 0] P[N_n\leqslant n]\to\frac12,"['probability', 'probability-theory']"
63,Mean Number of Samples from Uniform Distribution to Achieve a Desired Total,Mean Number of Samples from Uniform Distribution to Achieve a Desired Total,,"Problem Statement I'm interested in the mean number of samples from a given uniform distribution of integers I would need to take to reach a desired total or more. For example, a six-sided dice is a uniform distribution of integers from $1$ through to $6$ . The number of times you have to roll a six-sided dice ( $r$ ) to achieve a desired total or greater ( $t$ ) produces a distribution. For example, here is a graph produced by sampling dice rolls, aiming for a total of $80$ per run: Graph of six-sided dice rolls with a target of $80$ The mean of this distribution is approximately $23.332448$ . This is the number I am interested in deriving. Simply 23 would be too imprecise for what I need. Right now I am determining this by simply sampling large numbers of dice rolls and then calculating the average of that data set, however, I would like to instead understand the statistics involved and compute the mean, or a reasonable approximation of the mean. One might try to derive the mean of the number of rolls needed $P(r=t)=0.5$ by simply using the mean of the uniform distribution, and dividing the total $t$ by that mean: $$\frac{t}{(max-min)/2+min} = \frac{80}{(6-1)/2+1} \approx 22.857$$ I will call this the 'naive' approximation. As you can see, this result can be significantly off the desired result. Sometimes, it happens to be close to the right answer, however, I am interested in many cases where it is unacceptably imprecise. Ultimately, I want to have a method or formula that takes an arbitrary continuous uniform distribution of integers (such as a die) and the desired total, which tells me the mean number of samples from that distribution I would need to take in order to reach that total. Prior Research I've looked at a few posts that talk about this subject, however, none of them were able to provide the complete answer to me. Here are two of the things I've found and read: A Similar Question on This Forum Number of dice rolls taken to reach a certain sum This was useful in creating an approximation of the actual distribution I'm trying to find. I used this to turn the following recursive function into the following code (in rust, dependency on the cached crate for memoizing the recursive results to improve performance to something usable): $$P(S_t=s) = \sum_{i=1}^6P(S_{t-1} = s-i)/6$$ With the following terminators: $P(S_0=0) = 1$ $P(S_0<0) = P(S_{t>0}=0) = 0$ #[cached] pub fn p(t: i32, s: i32) -> f64 {     if s <= 0 && t <= 0 {         return 1.0;     }      if s <= 0 || t <= 0 {         return 0.0;     }      (1..(std::cmp::min(6, s) + 1)).map(|i| p(t - 1, s - i)).sum::<f64>() / 6.0 } Which, when run, can be used to create a graph comparing the frequency of the sampled results to the frequency predicted by that algorithm. In the graph, the blue line is the result of the algorithm, while the orange line is sampled data from a simple PRNG using a uniform distribution (the same data as in the first graph). Note that to get this graph, you have to divide the results of this algorithm by the inverse of the mean of the uniform distribution (so $3.5^{-1}$ in this example) The author of the original answer suggests dividing by $P(S_t=36)$ (where $36$ was their target) however fails to realise that this is just an approximation of the inverse of the mean. I'm not actually sure why the mean of the uniform pops out here, so that's an interesting tidbit. This looks pretty good, however, it does not provide the mean number of rolls as best I can tell. The author of the answer to the linked question states that the mean in their example is ""about $10.5238577$ "" , however, they don't state how they derived that number and I haven't been able to figure it out. It's also not generalised to any uniform, however, I don't believe it would be difficult to generalise. I don't anticipate this to be an obstacle if someone finds out how to derive the mean from that answer. A Similar Question on Reddit On average, how many rolls of a fair die would it take to get a cumulative score above n? This was useful in creating a different approach to solving this problem, where I iterated $r$ (the number of rolls) upwards from 1, each time producing an approximation of the distribution of the combined rolls using a normal distribution. The first normal distribution to have a cumulative distribution function for the given target of less than $0.5$ indicated when the integer mean number of rolls was being made. Again, however, like the previous solution, this only produced the integer number of rolls. I need to know the mean number of rolls more precisely than this. There are a number of other answers than the top up-voted answer on this Reddit post with differing amounts of clear information. The answer from the user u/possiblywrong shows an interesting cumulative distribution function which I wonder if it would solve my problem. However, I am unable to figure out how to reproduce their ideas as code or fully understand them. For completeness sake, here is an image of that response in case it is deleted in the future . Thanks Thank you for any time you spend on this, this is doing my head in. It feels like it should be so easy to model, and yet I've lost an entire day researching it only to find vague answers that are either too complicated for me, or are simply missing information that I need to understand them. Hopefully, you can help.","Problem Statement I'm interested in the mean number of samples from a given uniform distribution of integers I would need to take to reach a desired total or more. For example, a six-sided dice is a uniform distribution of integers from through to . The number of times you have to roll a six-sided dice ( ) to achieve a desired total or greater ( ) produces a distribution. For example, here is a graph produced by sampling dice rolls, aiming for a total of per run: Graph of six-sided dice rolls with a target of The mean of this distribution is approximately . This is the number I am interested in deriving. Simply 23 would be too imprecise for what I need. Right now I am determining this by simply sampling large numbers of dice rolls and then calculating the average of that data set, however, I would like to instead understand the statistics involved and compute the mean, or a reasonable approximation of the mean. One might try to derive the mean of the number of rolls needed by simply using the mean of the uniform distribution, and dividing the total by that mean: I will call this the 'naive' approximation. As you can see, this result can be significantly off the desired result. Sometimes, it happens to be close to the right answer, however, I am interested in many cases where it is unacceptably imprecise. Ultimately, I want to have a method or formula that takes an arbitrary continuous uniform distribution of integers (such as a die) and the desired total, which tells me the mean number of samples from that distribution I would need to take in order to reach that total. Prior Research I've looked at a few posts that talk about this subject, however, none of them were able to provide the complete answer to me. Here are two of the things I've found and read: A Similar Question on This Forum Number of dice rolls taken to reach a certain sum This was useful in creating an approximation of the actual distribution I'm trying to find. I used this to turn the following recursive function into the following code (in rust, dependency on the cached crate for memoizing the recursive results to improve performance to something usable): With the following terminators: #[cached] pub fn p(t: i32, s: i32) -> f64 {     if s <= 0 && t <= 0 {         return 1.0;     }      if s <= 0 || t <= 0 {         return 0.0;     }      (1..(std::cmp::min(6, s) + 1)).map(|i| p(t - 1, s - i)).sum::<f64>() / 6.0 } Which, when run, can be used to create a graph comparing the frequency of the sampled results to the frequency predicted by that algorithm. In the graph, the blue line is the result of the algorithm, while the orange line is sampled data from a simple PRNG using a uniform distribution (the same data as in the first graph). Note that to get this graph, you have to divide the results of this algorithm by the inverse of the mean of the uniform distribution (so in this example) The author of the original answer suggests dividing by (where was their target) however fails to realise that this is just an approximation of the inverse of the mean. I'm not actually sure why the mean of the uniform pops out here, so that's an interesting tidbit. This looks pretty good, however, it does not provide the mean number of rolls as best I can tell. The author of the answer to the linked question states that the mean in their example is ""about "" , however, they don't state how they derived that number and I haven't been able to figure it out. It's also not generalised to any uniform, however, I don't believe it would be difficult to generalise. I don't anticipate this to be an obstacle if someone finds out how to derive the mean from that answer. A Similar Question on Reddit On average, how many rolls of a fair die would it take to get a cumulative score above n? This was useful in creating a different approach to solving this problem, where I iterated (the number of rolls) upwards from 1, each time producing an approximation of the distribution of the combined rolls using a normal distribution. The first normal distribution to have a cumulative distribution function for the given target of less than indicated when the integer mean number of rolls was being made. Again, however, like the previous solution, this only produced the integer number of rolls. I need to know the mean number of rolls more precisely than this. There are a number of other answers than the top up-voted answer on this Reddit post with differing amounts of clear information. The answer from the user u/possiblywrong shows an interesting cumulative distribution function which I wonder if it would solve my problem. However, I am unable to figure out how to reproduce their ideas as code or fully understand them. For completeness sake, here is an image of that response in case it is deleted in the future . Thanks Thank you for any time you spend on this, this is doing my head in. It feels like it should be so easy to model, and yet I've lost an entire day researching it only to find vague answers that are either too complicated for me, or are simply missing information that I need to understand them. Hopefully, you can help.",1 6 r t 80 80 23.332448 P(r=t)=0.5 t \frac{t}{(max-min)/2+min} = \frac{80}{(6-1)/2+1} \approx 22.857 P(S_t=s) = \sum_{i=1}^6P(S_{t-1} = s-i)/6 P(S_0=0) = 1 P(S_0<0) = P(S_{t>0}=0) = 0 3.5^{-1} P(S_t=36) 36 10.5238577 r 0.5,"['probability', 'probability-theory', 'dice']"
64,Tail Lower Bounds using Moment Generating Functions,Tail Lower Bounds using Moment Generating Functions,,"Given a random variable $X>0$ with Moment Generating Function $m(s)=E[e^{sX}]$ I'm interested in finding a lower bound $$\Pr[X \ge t] \ge 1-\varepsilon(t),$$ where $t>E[X]$ . A classic technique for finding upper bounds for $\Pr[X \ge t]$ is using Markov's inequality with the Moment Generating Function: $$\Pr[X \ge t] \le E[e^{sX}]e^{-st},$$ for $s\ge 0$ . Since $E[e^{s X}]\ge e^{s E[X]}$ (Jensen's inequality), this bound is useful whenever $t>E[X]$ . (I'm assuming $X$ is a positive random variable, so $E[X]>0$ .) Standard techniques for lower bounds include the second-moment method, such as Cantelli's inequality and Paley-Zygmund. However, they only cover the case $t\in[0,E[X]]$ and say nothing about the case $t>E[X]$ . My best bet so far has been Lévy's and Gil-Pelaez's inversion formulas for the Characteristic Function $m(i s)$ : $$\begin{align}\Pr[X \ge t] &= 1-\frac{1} {2\pi} \lim_{S \to \infty} \int_{-S}^{S} \frac{1 - e^{-ist}} {is}\, m(is)\, ds. \\\text{and}\quad \Pr[X \ge t] &= \frac{1}{2} + \frac{1}{\pi}\int_0^\infty \frac{\operatorname{Im}[e^{-ist}m(i s)]}{s}\,ds.\end{align}$$ However, I don't have any good ideas for bounding those in a useful way. It certainly seems a lot harder than the Markov method for the upper bound. Am I missing a useful approach here?","Given a random variable with Moment Generating Function I'm interested in finding a lower bound where . A classic technique for finding upper bounds for is using Markov's inequality with the Moment Generating Function: for . Since (Jensen's inequality), this bound is useful whenever . (I'm assuming is a positive random variable, so .) Standard techniques for lower bounds include the second-moment method, such as Cantelli's inequality and Paley-Zygmund. However, they only cover the case and say nothing about the case . My best bet so far has been Lévy's and Gil-Pelaez's inversion formulas for the Characteristic Function : However, I don't have any good ideas for bounding those in a useful way. It certainly seems a lot harder than the Markov method for the upper bound. Am I missing a useful approach here?","X>0 m(s)=E[e^{sX}] \Pr[X \ge t] \ge 1-\varepsilon(t), t>E[X] \Pr[X \ge t] \Pr[X \ge t] \le E[e^{sX}]e^{-st}, s\ge 0 E[e^{s X}]\ge e^{s E[X]} t>E[X] X E[X]>0 t\in[0,E[X]] t>E[X] m(i s) \begin{align}\Pr[X \ge t] &= 1-\frac{1} {2\pi} \lim_{S \to \infty} \int_{-S}^{S} \frac{1 - e^{-ist}} {is}\, m(is)\, ds.
\\\text{and}\quad
\Pr[X \ge t] &= \frac{1}{2} + \frac{1}{\pi}\int_0^\infty \frac{\operatorname{Im}[e^{-ist}m(i s)]}{s}\,ds.\end{align}","['probability', 'fourier-analysis', 'characteristic-functions', 'moment-generating-functions', 'distribution-tails']"
65,Probability of receiving a job offer on 3rd application,Probability of receiving a job offer on 3rd application,,"Suppose that when you submit a job application you have a probability of $0.1$ to receive an interview, and a job interview results in a job offer with probability $0.2$ . Also assume you only submit one application at a time (i.e. you wait to know if you have been rejected from the job, either at the application stage or the interview stage before applying to another job). What is the probability of getting your first job offer after submitting at most 3 job applications? Attempt: Either you get a job offer after your first, second, or third application. The probability of getting an offer after your 1st application is $(0.1)(0.2)=0.02$ . The probability of getting an offer after your 2nd application is $(1-0.02)(0.1)(0.2)=0.0196$ The probability of getting an offer after your 3rd application is $(1-0.02)(1-0.02)(0.1)(0.2)=0.0192$ Thus, $0.02+0.0196+0.0192=0.0588$ I don't think my approach is correct, it doesn't make sense to me that you have  a higher probability of getting an offer on your first application than you do on your 2nd or 3rd. I'm stumped as to what the mistake is that I am making.","Suppose that when you submit a job application you have a probability of to receive an interview, and a job interview results in a job offer with probability . Also assume you only submit one application at a time (i.e. you wait to know if you have been rejected from the job, either at the application stage or the interview stage before applying to another job). What is the probability of getting your first job offer after submitting at most 3 job applications? Attempt: Either you get a job offer after your first, second, or third application. The probability of getting an offer after your 1st application is . The probability of getting an offer after your 2nd application is The probability of getting an offer after your 3rd application is Thus, I don't think my approach is correct, it doesn't make sense to me that you have  a higher probability of getting an offer on your first application than you do on your 2nd or 3rd. I'm stumped as to what the mistake is that I am making.",0.1 0.2 (0.1)(0.2)=0.02 (1-0.02)(0.1)(0.2)=0.0196 (1-0.02)(1-0.02)(0.1)(0.2)=0.0192 0.02+0.0196+0.0192=0.0588,['probability']
66,Probability about center of mass of 2n+1 random variables based on the 4 vertices,Probability about center of mass of 2n+1 random variables based on the 4 vertices,,"There are four points in the coordinate plane as following. A=(1,1), B=(1,-1), C=(-1,1), D=(-1,-1) We will choose $2n+1$ points and each point is one of these 4 points, but the probability of choice is different. P(point is A)= $p$ , $\quad$ P(point is B)= $\frac{1}{2}-p$ P(point is C)= $\frac{1}{2}-p$ , $\quad$ P(point is D)= $p$ This probability is for choice of one point and all $2n+1$ choice are independent. Let $x$ be the center of mass of these $2n+1$ points. and $f(n,p)$ =probability that $x$ is on the first quadrant. For example, $f(0,\frac{1}{2})=\frac{1}{2}$ , $f(1,\frac{1}{2})=\frac{1}{2}$ , $f(0,\frac{1}{3})=\frac{1}{3}$ , $f(1,\frac{1}{3})=\frac{17}{54}$ . Prove: If $\frac{1}{4}<p<\frac{1}{2}$ , $f(n,p)$ is decreasing at n. If you tell me references for this proof, it would be great thanks.","There are four points in the coordinate plane as following. A=(1,1), B=(1,-1), C=(-1,1), D=(-1,-1) We will choose points and each point is one of these 4 points, but the probability of choice is different. P(point is A)= , P(point is B)= P(point is C)= , P(point is D)= This probability is for choice of one point and all choice are independent. Let be the center of mass of these points. and =probability that is on the first quadrant. For example, , , , . Prove: If , is decreasing at n. If you tell me references for this proof, it would be great thanks.","2n+1 p \quad \frac{1}{2}-p \frac{1}{2}-p \quad p 2n+1 x 2n+1 f(n,p) x f(0,\frac{1}{2})=\frac{1}{2} f(1,\frac{1}{2})=\frac{1}{2} f(0,\frac{1}{3})=\frac{1}{3} f(1,\frac{1}{3})=\frac{17}{54} \frac{1}{4}<p<\frac{1}{2} f(n,p)","['probability', 'geometry', 'recurrence-relations', 'random-walk']"
67,Stopping Probabilities for Random Walk with Drift,Stopping Probabilities for Random Walk with Drift,,"[EDIT] After the comments and answer I understood that my formation of the problem is incorrect. However I'm still interested in a stochastic solution to the original riddle. Please skip to the ""Background"" part of this question. And thanks for setting a bounty on this question!! Let $X_1,X_2,...$ be independent and identically distributed random variable. $X_i = 2$ or $X_i=-1$ each with 50% probability. And let $S_n = X_1+\cdots+ X_n$ be the associated random walk. So we can think of this as a random walk with drift $\mu = 0.5$ and step-length = $1.5$ For a given constant $m$ , suppose we define a stopping rule to stop when $S_n \leq -m$ or $S_n \geq K$ . How do we find $K$ , such that the probability of stopping at $S_n \geq K$ is equal to the probability of stopping at $S_n \leq -m$ ? When there is no drift the solution is trivial $K = m$ . I suspect this little modification should be a classical problem in stochastic process too? The solution is apparently $K \sim O(m^2)$ , but I'm looking for a stochastic explanation. see the background below. Background: I found this riddle and its solution . I reproduce the riddle here: At a pivotal moment in an epic battle between the living and the dead, the Night King, head of the army of the dead, raises all the fallen (formerly) living soldiers to join his ranks. This ability obviously presents a huge military advantage, but how big an advantage exactly? Forget the Battle of Winterfell and model our battle as follows. Each army lines up single file, facing the other army. One soldier steps forward from each line and the pair duels — half the time the living soldier wins, half the time the dead soldier wins. If the living soldier wins, he goes to the back of his army’s line, and the dead soldier is out (the living army uses dragonglass weapons, so the dead soldier is dead forever this time). If the dead soldier wins, he goes to the back of their army’s line, but this time the (formerly) living soldier joins him there. (Reanimation is instantaneous for this Night King.) The battle continues until one army is entirely eliminated. What starting sizes of the armies, living and dead, give each army a 50-50 chance of winning? So we can think of this riddle as above problem. Let $m$ be the size of dead army. Let $S_i$ be (current  difference in army sizes - initial difference of army sizes). For each step $S_i$ increments by either −1 or 2. If $S_n=−m$ , that means comparing to the initial state, the dead army is down by $−m$ , the battle ended. If $S_n=K$ , that means comparing to the initial state, the dead army is up by $K$ , the battle ended. The solution is apparently $K \sim O(m^2)$ . The combinatorial argument is nice, but the paper offers no stochastic explanation, which I am truly curious about. I am fine with an approximation solution. So if we replace $X_i$ with a normal random variable with non-zero mean is fine to me too, if that helps with the estimation. But I think for a large enough $n$ this probably doesn't matter anyways.","[EDIT] After the comments and answer I understood that my formation of the problem is incorrect. However I'm still interested in a stochastic solution to the original riddle. Please skip to the ""Background"" part of this question. And thanks for setting a bounty on this question!! Let be independent and identically distributed random variable. or each with 50% probability. And let be the associated random walk. So we can think of this as a random walk with drift and step-length = For a given constant , suppose we define a stopping rule to stop when or . How do we find , such that the probability of stopping at is equal to the probability of stopping at ? When there is no drift the solution is trivial . I suspect this little modification should be a classical problem in stochastic process too? The solution is apparently , but I'm looking for a stochastic explanation. see the background below. Background: I found this riddle and its solution . I reproduce the riddle here: At a pivotal moment in an epic battle between the living and the dead, the Night King, head of the army of the dead, raises all the fallen (formerly) living soldiers to join his ranks. This ability obviously presents a huge military advantage, but how big an advantage exactly? Forget the Battle of Winterfell and model our battle as follows. Each army lines up single file, facing the other army. One soldier steps forward from each line and the pair duels — half the time the living soldier wins, half the time the dead soldier wins. If the living soldier wins, he goes to the back of his army’s line, and the dead soldier is out (the living army uses dragonglass weapons, so the dead soldier is dead forever this time). If the dead soldier wins, he goes to the back of their army’s line, but this time the (formerly) living soldier joins him there. (Reanimation is instantaneous for this Night King.) The battle continues until one army is entirely eliminated. What starting sizes of the armies, living and dead, give each army a 50-50 chance of winning? So we can think of this riddle as above problem. Let be the size of dead army. Let be (current  difference in army sizes - initial difference of army sizes). For each step increments by either −1 or 2. If , that means comparing to the initial state, the dead army is down by , the battle ended. If , that means comparing to the initial state, the dead army is up by , the battle ended. The solution is apparently . The combinatorial argument is nice, but the paper offers no stochastic explanation, which I am truly curious about. I am fine with an approximation solution. So if we replace with a normal random variable with non-zero mean is fine to me too, if that helps with the estimation. But I think for a large enough this probably doesn't matter anyways.","X_1,X_2,... X_i = 2 X_i=-1 S_n = X_1+\cdots+ X_n \mu = 0.5 1.5 m S_n \leq -m S_n \geq K K S_n \geq K S_n \leq -m K = m K \sim O(m^2) m S_i S_i S_n=−m −m S_n=K K K \sim O(m^2) X_i n","['probability', 'probability-theory', 'stochastic-processes', 'martingales', 'random-walk']"
68,Expected number of games so that every player has been an Imposter in Among Us [duplicate],Expected number of games so that every player has been an Imposter in Among Us [duplicate],,"This question already has an answer here : Expected number of times a set of 10 integers (selected from 1-100) is selected before all 100 are seen (1 answer) Closed 3 years ago . Imagine you have $n$ players. In each game, $k$ $(k\leq n)$ players are chosen randomly to do whatever. By game $G$ , what is the probability that every player has been chosen at least once? What is the expected number of games that have to be played so that every player was chosen at least once? Of course, when $G < n/k$ the probability is zero. This idea came from the game Among Us, where there are $n$ players ( $n\leq10$ ) and in each game you have $k$ imposters (usually $1$ , $2$ or $3$ ).","This question already has an answer here : Expected number of times a set of 10 integers (selected from 1-100) is selected before all 100 are seen (1 answer) Closed 3 years ago . Imagine you have players. In each game, players are chosen randomly to do whatever. By game , what is the probability that every player has been chosen at least once? What is the expected number of games that have to be played so that every player was chosen at least once? Of course, when the probability is zero. This idea came from the game Among Us, where there are players ( ) and in each game you have imposters (usually , or ).",n k (k\leq n) G G < n/k n n\leq10 k 1 2 3,"['probability', 'combinatorics', 'combinations', 'expected-value', 'coupon-collector']"
69,$10$ people and $2$ of them are traitors,people and  of them are traitors,10 2,"Let's suppose you are playing a game similiar to “Among Us”. There are $10$ players and $2$ of them are impostor/traitors. Normally, they would kill people secretly stab people, convince, manipulate, lie and etc. to win the game but lets spice things up and suppose that all players decide to eliminite one person at a time and no one leaves the election room! These are the rules. $-$ No killing between rounds other than elections. $-$ They can't vote two people at the same round, one at a time! $-$ Vote priority is determined by number of persons seat. They vote by the numbers $(1,2,3,\dots).$ $-$ Seats are given randomly. Normally, this would be a fairly simple question if there was just one impostor/traitor. For a impostor to win the game, he must either be the last man standing or there must be just one innocent. That means he must sit on one of the green seats like this: Probability of an impostor/traitor win is $\frac{2}{10} = \frac{1}{5}$ (in percentage, $20\%$ ). But what if there were two impostors/traitors? By the way, for an impostor win, innocent players must be at least $n$ where $n$ is the number of impostors in the game. You may have noticed that I said this for a one impostor/traitor situation too. For example, if the $2$ impostors/traitors are in the $7$ and $8$ seats, game is over when the $6$ is out of the election because the only innocent players that are alive are $9$ and $10$ and we have $2$ impostors/traitors. So $n=2$ and voila! Impostor/traitors won. Question is: What is the probabilty for an impostor/traitor win where there are $2$ of them? Side note: I am new to this site so if there is something wrong with the question please let me know.","Let's suppose you are playing a game similiar to “Among Us”. There are players and of them are impostor/traitors. Normally, they would kill people secretly stab people, convince, manipulate, lie and etc. to win the game but lets spice things up and suppose that all players decide to eliminite one person at a time and no one leaves the election room! These are the rules. No killing between rounds other than elections. They can't vote two people at the same round, one at a time! Vote priority is determined by number of persons seat. They vote by the numbers Seats are given randomly. Normally, this would be a fairly simple question if there was just one impostor/traitor. For a impostor to win the game, he must either be the last man standing or there must be just one innocent. That means he must sit on one of the green seats like this: Probability of an impostor/traitor win is (in percentage, ). But what if there were two impostors/traitors? By the way, for an impostor win, innocent players must be at least where is the number of impostors in the game. You may have noticed that I said this for a one impostor/traitor situation too. For example, if the impostors/traitors are in the and seats, game is over when the is out of the election because the only innocent players that are alive are and and we have impostors/traitors. So and voila! Impostor/traitors won. Question is: What is the probabilty for an impostor/traitor win where there are of them? Side note: I am new to this site so if there is something wrong with the question please let me know.","10 2 - - - (1,2,3,\dots). - \frac{2}{10} = \frac{1}{5} 20\% n n 2 7 8 6 9 10 2 n=2 2",['probability']
70,How does ESPN calculate the probability of a team winning a game?,How does ESPN calculate the probability of a team winning a game?,,ESPN has a probability winning percentage in which what team has more of a probability of winning the game. Like team A is up a certain amount of points and time remaining they’ll have a certain percentage chance of winning the game. How does ESPN calculate that?,ESPN has a probability winning percentage in which what team has more of a probability of winning the game. Like team A is up a certain amount of points and time remaining they’ll have a certain percentage chance of winning the game. How does ESPN calculate that?,,"['probability', 'statistics']"
71,"Expected number of children question from ""Introduction to Probability""","Expected number of children question from ""Introduction to Probability""",,"This question appeared on Introduction to Probability (by Joe Blitzstein and Jessica Hwang) A couple decides to keep having children until they have at least one boy and at least one girl, and then stop. Assume they never have twins, that the “trials” are independent with probability $1/2$ of a boy, and that they are fertile enough to keep producing children indefinitely. What is the expected number of children? So the answer and explanation provided in the book are as followed: Let X be the number of children needed, starting with the 2nd child, to obtain one whose gender is not the same as that of the firstborn. Then $X - 1$ is $Geom(1/2)$ , so $E(X) = 2$ . This does not include the firstborn, so the expected total number of children is $E(X + 1) = E(X) + 1 = 3$ I have two question regarding this: Is my approach for the question also correct? Or it shouldn't be that way? Let X be the number of children needed, including the firstborn. Therefore $X - 1 \sim Geom(1/2)$ , but there are two possibility (i.e. first child is a boy, first child is a girl) As a result, $E(X - 1) = 2$ (not sure how to explain this but by Geom(1/2) the expected value should be 1, while there are 2 possibilities so it becomes 2) Geom(p) didn't include the ""success"" case, so we compute it back -> $E(X) = 2+1 = 3$ Is the reason for the question setting X to be ""starting from second child"" to prevent getting 2 possibilities (like I did) and condition on whatever the first child's gender is. Or if anyway can explain the logic behind the formal answer as I am not really sure how the story goes. Thanks a lot! EDIT: suddenly one more approach here (Linearity of expectation), is it also valid? Expectation of having the first child = 1 (regardless of boy/girl) Expectation of having a child of a specific gender = 2 (we need a specific gender that is the opposite sex of the first child) By linearity = 1+2 = 3","This question appeared on Introduction to Probability (by Joe Blitzstein and Jessica Hwang) A couple decides to keep having children until they have at least one boy and at least one girl, and then stop. Assume they never have twins, that the “trials” are independent with probability of a boy, and that they are fertile enough to keep producing children indefinitely. What is the expected number of children? So the answer and explanation provided in the book are as followed: Let X be the number of children needed, starting with the 2nd child, to obtain one whose gender is not the same as that of the firstborn. Then is , so . This does not include the firstborn, so the expected total number of children is I have two question regarding this: Is my approach for the question also correct? Or it shouldn't be that way? Let X be the number of children needed, including the firstborn. Therefore , but there are two possibility (i.e. first child is a boy, first child is a girl) As a result, (not sure how to explain this but by Geom(1/2) the expected value should be 1, while there are 2 possibilities so it becomes 2) Geom(p) didn't include the ""success"" case, so we compute it back -> Is the reason for the question setting X to be ""starting from second child"" to prevent getting 2 possibilities (like I did) and condition on whatever the first child's gender is. Or if anyway can explain the logic behind the formal answer as I am not really sure how the story goes. Thanks a lot! EDIT: suddenly one more approach here (Linearity of expectation), is it also valid? Expectation of having the first child = 1 (regardless of boy/girl) Expectation of having a child of a specific gender = 2 (we need a specific gender that is the opposite sex of the first child) By linearity = 1+2 = 3",1/2 X - 1 Geom(1/2) E(X) = 2 E(X + 1) = E(X) + 1 = 3 X - 1 \sim Geom(1/2) E(X - 1) = 2 E(X) = 2+1 = 3,"['probability', 'probability-distributions', 'expected-value']"
72,A coin is thrown until two heads and two tails appears. What is the cumulative distribution function of this situation?,A coin is thrown until two heads and two tails appears. What is the cumulative distribution function of this situation?,,"A coin is thrown until two heads and two tails appears. Let $Y$ be the number of throws until this happens. What is the cumulative distribution function of $Y$ ? What I have gotten so far: The last throw can end up being either head or tail. Let's look at this situations separately. Last throw is tail: $$\sum^n_{k=2}P(Y=k)k=0,5^k\cdot k(k-1), \qquad n\ge4.$$ This happens to also be the probability mass function when the last throw is head. Now summing up the two cases, we get $$0,5^k\cdot k(k-1)+0,5^k\cdot k(k-1)=2k(k-1)\cdot0,5^k$$ which is the probability mass function of the situation. Does this seem correct?","A coin is thrown until two heads and two tails appears. Let be the number of throws until this happens. What is the cumulative distribution function of ? What I have gotten so far: The last throw can end up being either head or tail. Let's look at this situations separately. Last throw is tail: This happens to also be the probability mass function when the last throw is head. Now summing up the two cases, we get which is the probability mass function of the situation. Does this seem correct?","Y Y \sum^n_{k=2}P(Y=k)k=0,5^k\cdot k(k-1), \qquad n\ge4. 0,5^k\cdot k(k-1)+0,5^k\cdot k(k-1)=2k(k-1)\cdot0,5^k","['probability', 'integration', 'cumulative-distribution-functions']"
73,Expected number of keys to try,Expected number of keys to try,,"You have n keys on your key ring. One of them unlocks the front door, but you don't know which one. Find the expected number of tries it takes to open the front door by using the method of indicator random variables. Note: We try keys without repeats since that key will never work if it doesn't work once. My attempt: Let X be the number of tries we need to open the front door. We see that $$X = 1 + X_1 + X_2 + X_3 + ... + X_n $$ where $X_i = 1$ if the $i^{th}$ try doesn't open the door and $X_i = 0$ if the try opens the door. We need at least one try to open the door which is why there's a $1$ as the first term in the sum. Using linearity of expectation: $$E[X] = 1 + \sum_i {E[X_i]} = 1 + \sum_i {P(X_i = 1)}$$ Now attempting to find $P(X_i = 1)$ . Well we've already tried $i - 1$ keys at this point, so there are $n - i + 1$ keys left. Of those $n - i + 1$ keys, $n - i$ of them are incorrect. Therefore, the probability that the $i^{th}$ try doesn't work is $\frac{n - i}{n - i + 1}$ . So, $$E[X] = 1 + \sum_i {E[X_i]} = 1 + \sum_i {P(X_i = 1)} = 1 + \sum_{i = 1}^{n} \frac{n - i}{n - i + 1}$$ I typed this summation into wolframalpha and got some ugly answer with a $\psi$ in it, while the answer from the book I'm using gives the answer as $\frac{(n+1)}{2}$ . Where am I going wrong? Any advice is appreciated :)","You have n keys on your key ring. One of them unlocks the front door, but you don't know which one. Find the expected number of tries it takes to open the front door by using the method of indicator random variables. Note: We try keys without repeats since that key will never work if it doesn't work once. My attempt: Let X be the number of tries we need to open the front door. We see that where if the try doesn't open the door and if the try opens the door. We need at least one try to open the door which is why there's a as the first term in the sum. Using linearity of expectation: Now attempting to find . Well we've already tried keys at this point, so there are keys left. Of those keys, of them are incorrect. Therefore, the probability that the try doesn't work is . So, I typed this summation into wolframalpha and got some ugly answer with a in it, while the answer from the book I'm using gives the answer as . Where am I going wrong? Any advice is appreciated :)",X = 1 + X_1 + X_2 + X_3 + ... + X_n  X_i = 1 i^{th} X_i = 0 1 E[X] = 1 + \sum_i {E[X_i]} = 1 + \sum_i {P(X_i = 1)} P(X_i = 1) i - 1 n - i + 1 n - i + 1 n - i i^{th} \frac{n - i}{n - i + 1} E[X] = 1 + \sum_i {E[X_i]} = 1 + \sum_i {P(X_i = 1)} = 1 + \sum_{i = 1}^{n} \frac{n - i}{n - i + 1} \psi \frac{(n+1)}{2},"['probability', 'probability-theory', 'discrete-mathematics', 'random-variables']"
74,Equality of Moment Generating Functions,Equality of Moment Generating Functions,,"Let $X,Y$ be be random variables whose moment generating functions $s\mapsto \mathbb{E}(e^{sX})$ exist and agree on either the interval $(-\delta,0]$ or on the interval $[0,\delta)$ for some $\delta > 0$ .  Do $X$ and $Y$ have the same distribution? In particular, is the following argument outline valid: The Laplace transforms (with $s$ now in $\mathbb{C}$ ), $s\mapsto \mathbb{E}(e^{sX})$ exist on some strip $\text{Re}(s)\in (-\delta,0)$ or $\text{Re}(s)\in (0,\delta)$ and are analytic there.  Therefore, they agree on that strip, and so they agree on the boundary $\text{Re}(s)=0$ , so the characteristic functions are the same.  That implies the distributions are the same.","Let be be random variables whose moment generating functions exist and agree on either the interval or on the interval for some .  Do and have the same distribution? In particular, is the following argument outline valid: The Laplace transforms (with now in ), exist on some strip or and are analytic there.  Therefore, they agree on that strip, and so they agree on the boundary , so the characteristic functions are the same.  That implies the distributions are the same.","X,Y s\mapsto \mathbb{E}(e^{sX}) (-\delta,0] [0,\delta) \delta > 0 X Y s \mathbb{C} s\mapsto \mathbb{E}(e^{sX}) \text{Re}(s)\in (-\delta,0) \text{Re}(s)\in (0,\delta) \text{Re}(s)=0","['probability', 'probability-theory', 'laplace-transform', 'fourier-transform', 'moment-generating-functions']"
75,"How to estimate this probability of sum of $(-1,+1)$ valued random variables?",How to estimate this probability of sum of  valued random variables?,"(-1,+1)","Let $x_1,\ldots,x_n$ be independent random variables and $\mathbb{P}(x_i=\pm1)=1/2.$ Prove that exists $C>0$ such that for $0\leq\Delta \leq n/C$ , $$ \mathbb{P}\big(\sum_{i=1}^n x_i>\Delta\big)\geq\frac{1}{C}\exp(-\frac{\Delta^2}{Cn}) $$ The Chernoff bound is an upper bound of the probability, while what I want to prove is lower bound.  Is the statement correct? Is there a reference about the lower bound estimate?","Let be independent random variables and Prove that exists such that for , The Chernoff bound is an upper bound of the probability, while what I want to prove is lower bound.  Is the statement correct? Is there a reference about the lower bound estimate?","x_1,\ldots,x_n \mathbb{P}(x_i=\pm1)=1/2. C>0 0\leq\Delta \leq n/C 
\mathbb{P}\big(\sum_{i=1}^n x_i>\Delta\big)\geq\frac{1}{C}\exp(-\frac{\Delta^2}{Cn})
","['probability', 'probability-theory', 'large-deviation-theory']"
76,Probability of winning high-low with full deck,Probability of winning high-low with full deck,,"I play a game on a site I use that's a version of the casino game of ""High Low."" A standard 52-card deck is shuffled, and the top card is revealed. The player guesses whether the next card on the top of the deck is higher or lower than the revealed card. This continues iteratively until either (1) the player guesses wrong or (2) there are no more cards left to reveal. If the next card is the same as the revealed card, it is a ""freebie"" for the player and the game continues. Suit is not relevant, just value, with 10 < J < Q < K < A. There is no card replacement. What I am wondering is what is the probability of ""winning the game"" (guessing correctly 51 times in a row) under different strategies. I am just not sure how to abstract the problem. I figure that once you settle on a strategy, it really becomes a question of how the deck is shuffled, i.e. the probability of a specific type of permutation of the cards. These are the two strategies I'm interested in: A ""naive"" strategy where you always guess higher for 2 through 7, always guess lower for 9 through A, and flip a coin for 8. I presume this is an easier question to answer. A ""card counter"" strategy where you keep track of all the cards you have seen, and then choose the more likely option. For example, if the first card is a 2, and the second card is an 8, you would guess the third card is higher since it has a slightly higher probability (24/50 vs. 23/50). For example, imagine the deck was simply sequential (2, 2, 2, 2, 3, 3, ..., K, A, A, A, A). The naive strategy would guess correctly until you got to the first 9, while the card counter strategy would win this game. I was able to make a simulation of the game and the strategies in Python very easily, which provided interesting results for probabilities of lower scores, but because the probability of getting all 51 is correct is so low it doesn't converge meaningfully for higher scores even after millions of trials. How could I go about abstracting the game to determine this probability? The number of permutations of the deck is large but finite, so it seems like a straightforward combinatorics question to me, but I'm getting tripped up on how each element needs to relate to all of those before it and also incorporating the coin flips. I thought about a Markov model but the probability of the next card depends on more than just the last card flipped over. Is this even a tractable question?","I play a game on a site I use that's a version of the casino game of ""High Low."" A standard 52-card deck is shuffled, and the top card is revealed. The player guesses whether the next card on the top of the deck is higher or lower than the revealed card. This continues iteratively until either (1) the player guesses wrong or (2) there are no more cards left to reveal. If the next card is the same as the revealed card, it is a ""freebie"" for the player and the game continues. Suit is not relevant, just value, with 10 < J < Q < K < A. There is no card replacement. What I am wondering is what is the probability of ""winning the game"" (guessing correctly 51 times in a row) under different strategies. I am just not sure how to abstract the problem. I figure that once you settle on a strategy, it really becomes a question of how the deck is shuffled, i.e. the probability of a specific type of permutation of the cards. These are the two strategies I'm interested in: A ""naive"" strategy where you always guess higher for 2 through 7, always guess lower for 9 through A, and flip a coin for 8. I presume this is an easier question to answer. A ""card counter"" strategy where you keep track of all the cards you have seen, and then choose the more likely option. For example, if the first card is a 2, and the second card is an 8, you would guess the third card is higher since it has a slightly higher probability (24/50 vs. 23/50). For example, imagine the deck was simply sequential (2, 2, 2, 2, 3, 3, ..., K, A, A, A, A). The naive strategy would guess correctly until you got to the first 9, while the card counter strategy would win this game. I was able to make a simulation of the game and the strategies in Python very easily, which provided interesting results for probabilities of lower scores, but because the probability of getting all 51 is correct is so low it doesn't converge meaningfully for higher scores even after millions of trials. How could I go about abstracting the game to determine this probability? The number of permutations of the deck is large but finite, so it seems like a straightforward combinatorics question to me, but I'm getting tripped up on how each element needs to relate to all of those before it and also incorporating the coin flips. I thought about a Markov model but the probability of the next card depends on more than just the last card flipped over. Is this even a tractable question?",,"['probability', 'combinatorics', 'stochastic-processes', 'card-games']"
77,Infinite product Lebesgue measure as the pushforward of 1-Lebesgue measure,Infinite product Lebesgue measure as the pushforward of 1-Lebesgue measure,,"I want to construct a Borel map from the unit interval to the Hilbert cube $f: [0,1] \to [0, 1]^\mathbb N$ so that \begin{equation} \lambda \left(f^{-1}\left( \prod_{i \in \mathbb N} E_i\right)\right)= \prod_{i \in \mathbb N} \lambda(E_i) \end{equation} for $\lambda$ the Lebesgue measure on the interval, $E_i \subseteq [0, 1]$ Borel, and $E_i = [0, 1]$ for all but finitely many indices. This gives the construction of the product measure without appealing to the Kolmogorov extension theorem (c.f. Tao's An Introduction to Measure Theory for the Kolmogorov approach to infinite product spaces). In the general case, I want to find a Borel map $f: [0, 1] \to \mathbb R^{\mathbb N}$ so that \begin{equation} \lambda \left(f^{-1}\left( \prod_{i \in \mathbb N} E_i\right)\right)= \prod_{i \in \mathbb N} \mu_i(E_i) \end{equation} for Radon probability measures $\mu_i$ on $\mathbb R$ . My initial thought was to try to encode the Hilbert cube into the dyadic intervals $[1/2^{n + 1}, 1/2^n]$ , e.g. map these into the edges of the Hilbert cube, and try to construct measure preserving maps \begin{equation*} [0, 1] \to \bigsqcup_{n \in \mathbb N} [0, 1] \to [0, 1]^{\mathbb N}. \end{equation*} The first map isn't too bad, however the second is more nebulous. The thought was that this has something to do with independent events in $[0, 1]$ representing a rectangle in the Hilbert cube, e.g. $A \times B \times [0, 1] \times \cdots$ gets pulled back to $A \cap B$ . My second thought was to construct a space-filling curve in spirit of showing the $d$ -dimensional Lebesgue measure $\lambda_d$ can be realised as the pushforward of $\lambda$ (c.f. the discussion here for existence of a space filling curve and here which states the Hilbert and Peano curves are measure preserving space filling curves). The second seems a bit unwieldy but an approach that can work. The first seems more succinct but I can't get the details right. Moreover, the first seems more easy to generalize, i.e. if we replace $\lambda$ on the right hand side of our initial equation with Radon probability measures $\mu_i$ on $\mathbb R$ and the map into the Hilbert cube with a map $f: [0, 1] \to \mathbb R^{\mathbb N}$ by considering the cumulative distribution functions of $\mu_i$ .","I want to construct a Borel map from the unit interval to the Hilbert cube so that for the Lebesgue measure on the interval, Borel, and for all but finitely many indices. This gives the construction of the product measure without appealing to the Kolmogorov extension theorem (c.f. Tao's An Introduction to Measure Theory for the Kolmogorov approach to infinite product spaces). In the general case, I want to find a Borel map so that for Radon probability measures on . My initial thought was to try to encode the Hilbert cube into the dyadic intervals , e.g. map these into the edges of the Hilbert cube, and try to construct measure preserving maps The first map isn't too bad, however the second is more nebulous. The thought was that this has something to do with independent events in representing a rectangle in the Hilbert cube, e.g. gets pulled back to . My second thought was to construct a space-filling curve in spirit of showing the -dimensional Lebesgue measure can be realised as the pushforward of (c.f. the discussion here for existence of a space filling curve and here which states the Hilbert and Peano curves are measure preserving space filling curves). The second seems a bit unwieldy but an approach that can work. The first seems more succinct but I can't get the details right. Moreover, the first seems more easy to generalize, i.e. if we replace on the right hand side of our initial equation with Radon probability measures on and the map into the Hilbert cube with a map by considering the cumulative distribution functions of .","f: [0,1] \to [0, 1]^\mathbb N \begin{equation}
\lambda \left(f^{-1}\left( \prod_{i \in \mathbb N} E_i\right)\right)= \prod_{i \in \mathbb N} \lambda(E_i)
\end{equation} \lambda E_i \subseteq [0, 1] E_i = [0, 1] f: [0, 1] \to \mathbb R^{\mathbb N} \begin{equation}
\lambda \left(f^{-1}\left( \prod_{i \in \mathbb N} E_i\right)\right)= \prod_{i \in \mathbb N} \mu_i(E_i)
\end{equation} \mu_i \mathbb R [1/2^{n + 1}, 1/2^n] \begin{equation*}
[0, 1] \to \bigsqcup_{n \in \mathbb N} [0, 1] \to [0, 1]^{\mathbb N}.
\end{equation*} [0, 1] A \times B \times [0, 1] \times \cdots A \cap B d \lambda_d \lambda \lambda \mu_i \mathbb R f: [0, 1] \to \mathbb R^{\mathbb N} \mu_i","['probability', 'probability-theory']"
78,When can we use limits to overcome $0$ probability events like $\{Y=y \}$?,When can we use limits to overcome  probability events like ?,0 \{Y=y \},"I've seen the way to ""prove""/""derive"" for a continuous random variable $Y$ the probability of event $A$ given the event $\{Y=y\}$ is the intuition that the event $\{Y=y\} = \lim_{\delta \to 0} \{y - \frac{\delta}{2} \le Y\le y + \frac{\delta}{2}\}$ .  What I've seen then is: To find $P(A|Y=y)$ is to first evaluate $$P\left(A|Y\in\left(y-\frac{\delta}{2}, y+\frac{\delta}{2}\right)\right)$$ and then take the limit as $\delta \to 0$ . But doesn't this method assume that $$\lim_{\delta\to 0}P\left(A|Y\in\left(y-\frac{\delta}{2}, y+\frac{\delta}{2}\right)\right)\overset{?}{=}P\left(A|\lim_{\delta\to 0}\bigg\{Y\in\left(y-\frac{\delta}{2}, y+\frac{\delta}{2}\right)\bigg\}\right)=P(A|Y=y) \ ?$$ I might be skirting on the edges of measure theory (which I am not familiar with) but is there an intuitive way to make this claim seem intuitive/convincing? Or is there a result which shows why this is valid to do, if it is? Addition: Thanks to @Masoud - how would you know the limit always exists, if it does? Example: I'd like to add an example which lead me to this. Suppose $N_{t_1, t_2}$ represents the number of occurrences of a phenomenon in the time interval $(t_1, t_2]$ for $0<t_1<t_2$ . Suppose you are given the last occurrence was at time $s$ . Let $X$ be the time until the next occurrence of the phenomenon, starting at time $s$ . We need to find the distribution of $X$ . (For those of you familiar this is related to the well know poison process). Then, the probability $$\mathbb P (X>t|\text{Last occurrence was time }s)=\mathbb{P}(N_{s,s+t} = 0|\text{Last occurrence was time }s)$$ and this point, since there's no way to definition the conditional null set in terms of $N_{t_1, t_2}$ , I saw the source do $$\mathbb{P}(N_{s,s+t} = 0|\text{Last occurrence was time }s) \overset{?}{=} \lim_{h\to 0} \mathbb P(N_{s+h,s+t+h} = 0| N_{s+h, s}=1)$$ On what basis can we apply such a limit? I couldn't find a definition to state when you can do something like this. In this case, the limit is being applied in both the condition to help with the null set, and the set for which we're finding the probability too! Thanks in advance","I've seen the way to ""prove""/""derive"" for a continuous random variable the probability of event given the event is the intuition that the event .  What I've seen then is: To find is to first evaluate and then take the limit as . But doesn't this method assume that I might be skirting on the edges of measure theory (which I am not familiar with) but is there an intuitive way to make this claim seem intuitive/convincing? Or is there a result which shows why this is valid to do, if it is? Addition: Thanks to @Masoud - how would you know the limit always exists, if it does? Example: I'd like to add an example which lead me to this. Suppose represents the number of occurrences of a phenomenon in the time interval for . Suppose you are given the last occurrence was at time . Let be the time until the next occurrence of the phenomenon, starting at time . We need to find the distribution of . (For those of you familiar this is related to the well know poison process). Then, the probability and this point, since there's no way to definition the conditional null set in terms of , I saw the source do On what basis can we apply such a limit? I couldn't find a definition to state when you can do something like this. In this case, the limit is being applied in both the condition to help with the null set, and the set for which we're finding the probability too! Thanks in advance","Y A \{Y=y\} \{Y=y\} = \lim_{\delta \to 0} \{y - \frac{\delta}{2} \le Y\le y + \frac{\delta}{2}\} P(A|Y=y) P\left(A|Y\in\left(y-\frac{\delta}{2}, y+\frac{\delta}{2}\right)\right) \delta \to 0 \lim_{\delta\to 0}P\left(A|Y\in\left(y-\frac{\delta}{2}, y+\frac{\delta}{2}\right)\right)\overset{?}{=}P\left(A|\lim_{\delta\to 0}\bigg\{Y\in\left(y-\frac{\delta}{2}, y+\frac{\delta}{2}\right)\bigg\}\right)=P(A|Y=y) \ ? N_{t_1, t_2} (t_1, t_2] 0<t_1<t_2 s X s X \mathbb P (X>t|\text{Last occurrence was time }s)=\mathbb{P}(N_{s,s+t} = 0|\text{Last occurrence was time }s) N_{t_1, t_2} \mathbb{P}(N_{s,s+t} = 0|\text{Last occurrence was time }s) \overset{?}{=} \lim_{h\to 0} \mathbb P(N_{s+h,s+t+h} = 0| N_{s+h, s}=1)","['probability', 'probability-theory', 'measure-theory', 'probability-distributions', 'conditional-probability']"
79,Intuition for sampling random variables?,Intuition for sampling random variables?,,"I have recently come to understand random variables from the perspective as deterministic measurable functions $X: \Omega \to \mathbb{R}$ . I've been rereading some old statistics text books and realized that in this framework I no longer understand what it means to sample something. For example, in a recent text, I read something along the lines of ""you can sample a geometric random variable with parameter $p$ by flipping a $p$ -weighted coin and counting the number of flips until tails is turned"". I am not sure how to intuitively interpret this as a random variable in this measure theory framework. Somewhat similarly, when texts say ""sample i.i.d $X_1,\ldots, X_n \sim \mathcal{N}(\mu, \sigma^2)$ "" what exactly does this mean? By what process do we actually accomplish this? Does this just mean that we explicitly choose a bunch of functions $X_k: \Omega\to \mathbb{R}$ satisfying equality of distribution functions $F_{X_k}(\alpha) = \Phi(\alpha)$ and independence of laws: $\mathcal{P}_{(X_i, X_j)} = \mathcal{P}_{X_i}\times \mathcal{P}_{X_j}$ ? Any intuitive clarifications would be really helpful! Huge plus if there's a nice way to formalize these methods for sampling and sampling i.i.d etc.","I have recently come to understand random variables from the perspective as deterministic measurable functions . I've been rereading some old statistics text books and realized that in this framework I no longer understand what it means to sample something. For example, in a recent text, I read something along the lines of ""you can sample a geometric random variable with parameter by flipping a -weighted coin and counting the number of flips until tails is turned"". I am not sure how to intuitively interpret this as a random variable in this measure theory framework. Somewhat similarly, when texts say ""sample i.i.d "" what exactly does this mean? By what process do we actually accomplish this? Does this just mean that we explicitly choose a bunch of functions satisfying equality of distribution functions and independence of laws: ? Any intuitive clarifications would be really helpful! Huge plus if there's a nice way to formalize these methods for sampling and sampling i.i.d etc.","X: \Omega \to \mathbb{R} p p X_1,\ldots, X_n \sim \mathcal{N}(\mu, \sigma^2) X_k: \Omega\to \mathbb{R} F_{X_k}(\alpha) = \Phi(\alpha) \mathcal{P}_{(X_i, X_j)} = \mathcal{P}_{X_i}\times \mathcal{P}_{X_j}","['probability', 'probability-theory', 'statistics', 'measure-theory', 'probability-distributions']"
80,A uniform distributed random vector on euclidean ball is sub gaussian,A uniform distributed random vector on euclidean ball is sub gaussian,,"Consider a random vector $X\sim\textrm{Unif}\left[B\left(0,\sqrt{n}\right)\right]$ , that is $X$ is uniformly distributed on the Euclidean ball $B(0,\sqrt{n})$ in $\mathbb{R}^n$ centered at the origin with radius $\sqrt{n}$ . $$B\left(0,\sqrt{n}\right)=\left\{x\in\mathbb{R}^n:x_1^2+x_2^2+...+x_n^2\leq n\right\}.$$ Show that $X$ is sub-Gaussian and $\|X\|_{\Psi_2}\leq C$ , where $C$ is an absolute constant. From the book ""High dimensional probability"" by Vershynin, it said that the above argument is an extension of uniform distribution on the sphere in section 3.4.3. While I am not sure how to connect the argument that uniform distribution on the sphere is sub-Gaussian to this? Thank you!","Consider a random vector , that is is uniformly distributed on the Euclidean ball in centered at the origin with radius . Show that is sub-Gaussian and , where is an absolute constant. From the book ""High dimensional probability"" by Vershynin, it said that the above argument is an extension of uniform distribution on the sphere in section 3.4.3. While I am not sure how to connect the argument that uniform distribution on the sphere is sub-Gaussian to this? Thank you!","X\sim\textrm{Unif}\left[B\left(0,\sqrt{n}\right)\right] X B(0,\sqrt{n}) \mathbb{R}^n \sqrt{n} B\left(0,\sqrt{n}\right)=\left\{x\in\mathbb{R}^n:x_1^2+x_2^2+...+x_n^2\leq n\right\}. X \|X\|_{\Psi_2}\leq C C","['probability', 'probability-theory', 'gaussian']"
81,How can I determine the probability of a number in a random sequence being of a cerrtain type?,How can I determine the probability of a number in a random sequence being of a cerrtain type?,,"I would like to produce some kind of probability function/density for finding out the likelihood of a chosen number, $k$ , to occur in a random sequence of length, $N$ . For Example: Let's say we have a sequence of $N=1000$ , random numbers in the range $\in [0,1]$ . Furthermore, let's truncate the random numbers to have only 3 significant digits (0.001). How can I calculate how many times a particular ""even"" modulo number is expected to occur, such that we have the probability of: (a) $k \in [0.1, 0.2, ..., 0.9]$ (b) $k \in [0.01, 0.02, ..., 0.09]$ (c) $k \in [0.02, 0.05, 0.08]$ Possibly related questions: An integer is chosen at random from the first 1000 positive integers. Probability that is a multiple of both 6 and 8? Question about computing expected value of the limit of a geometric mean of random variables PS. It's quite likely I have not stated the title of this question correctly, please feel free to adjust it.","I would like to produce some kind of probability function/density for finding out the likelihood of a chosen number, , to occur in a random sequence of length, . For Example: Let's say we have a sequence of , random numbers in the range . Furthermore, let's truncate the random numbers to have only 3 significant digits (0.001). How can I calculate how many times a particular ""even"" modulo number is expected to occur, such that we have the probability of: (a) (b) (c) Possibly related questions: An integer is chosen at random from the first 1000 positive integers. Probability that is a multiple of both 6 and 8? Question about computing expected value of the limit of a geometric mean of random variables PS. It's quite likely I have not stated the title of this question correctly, please feel free to adjust it.","k N N=1000 \in [0,1] k \in [0.1, 0.2, ..., 0.9] k \in [0.01, 0.02, ..., 0.09] k \in [0.02, 0.05, 0.08]","['probability', 'sequences-and-series', 'random-variables']"
82,Uniform random numbers adding up to a given $L$,Uniform random numbers adding up to a given,L,"Fix $L \in \mathbb R^{>0}$ , let $x_1, x_2, x_3, \ldots$ be IID uniformly random numbers in $[0, 1]$ , and $$\mathcal N := \min \{{N \in \{1, 2, 3 , \ldots\}} \mid x_1 + x_2 + \cdots + x_N \ge L\}.$$ It's a well-known exercise that $E(\mathcal N \mid L = 1) = e$ . It's not that much harder to describe the distribution for $L \le 1$ and see that $$E\left(\mathcal N \mid 0 \le L \le 1\right) = e^L.$$ Is there a good reference that describes the distribution on $\mathcal N$ for $L > 1$ , where it gets more complicated? The reference provided here , Uspensky 1937, p. 278, doesn't appear to actually discuss the distribution of $\mathcal N$ .","Fix , let be IID uniformly random numbers in , and It's a well-known exercise that . It's not that much harder to describe the distribution for and see that Is there a good reference that describes the distribution on for , where it gets more complicated? The reference provided here , Uspensky 1937, p. 278, doesn't appear to actually discuss the distribution of .","L \in \mathbb R^{>0} x_1, x_2, x_3, \ldots [0, 1] \mathcal N := \min \{{N \in \{1, 2, 3 , \ldots\}} \mid x_1 + x_2 + \cdots + x_N \ge L\}. E(\mathcal N \mid L = 1) = e L \le 1 E\left(\mathcal N \mid 0 \le L \le 1\right) = e^L. \mathcal N L > 1 \mathcal N","['probability', 'probability-distributions', 'reference-request']"
83,What is the probability that two hyperspheres of radii $x$ overlap within a bigger hypersphere?,What is the probability that two hyperspheres of radii  overlap within a bigger hypersphere?,x,"Having a sphere of dimension $N = 5$ , its volume can be calculated as $$\frac{8}{15}\pi^2R^5.$$ If two smaller spheres of radii $x$ are dropped randomly inside of the bigger sphere, how can we find the probability of both spheres overlapping? Can someone point me towards a direction? I am trying to understand the probability of different sizes of smaller spheres.","Having a sphere of dimension , its volume can be calculated as If two smaller spheres of radii are dropped randomly inside of the bigger sphere, how can we find the probability of both spheres overlapping? Can someone point me towards a direction? I am trying to understand the probability of different sizes of smaller spheres.",N = 5 \frac{8}{15}\pi^2R^5. x,"['probability', 'geometry', 'geometric-probability']"
84,"If $\mathbb E[e^{\xi X}]=e^{\frac{\xi^2}{2}}$ for all $\xi >0$ does $X\sim \mathcal N(0,1)$?",If  for all  does ?,"\mathbb E[e^{\xi X}]=e^{\frac{\xi^2}{2}} \xi >0 X\sim \mathcal N(0,1)","I know that if $$\mathbb E[e^{\xi X}]=e^{\frac{\xi^2}{2}}$$ for all $\xi\in\mathbb R$ , then $X\sim \mathcal N(0,1)$ . Now, if $$\mathbb E[e^{\xi X}]=e^{\frac{\xi^2}{2}}$$ for all $\xi >0$ does $X\sim \mathcal N(0,1)$ as well ? I really can't find a counter example, and I know that to have $X\sim Y$ we need that $\mathbb E[e^{tX}]=\mathbb E[e^{tY}]$ for all $|t|\leq t_0$ for some $t_0>0$ . So, I'm not so sure if $\mathbb E[e^{\xi X}]=e^{\frac{\xi^2}{2}}$ for all $\xi>0$ is enough to have $X\sim N(0,1)$ . Any idea ?","I know that if for all , then . Now, if for all does as well ? I really can't find a counter example, and I know that to have we need that for all for some . So, I'm not so sure if for all is enough to have . Any idea ?","\mathbb E[e^{\xi X}]=e^{\frac{\xi^2}{2}} \xi\in\mathbb R X\sim \mathcal N(0,1) \mathbb E[e^{\xi X}]=e^{\frac{\xi^2}{2}} \xi >0 X\sim \mathcal N(0,1) X\sim Y \mathbb E[e^{tX}]=\mathbb E[e^{tY}] |t|\leq t_0 t_0>0 \mathbb E[e^{\xi X}]=e^{\frac{\xi^2}{2}} \xi>0 X\sim N(0,1)",['probability']
85,A coin game and a crazy recurrence,A coin game and a crazy recurrence,,"Consider the following game between two people. You start with a large stack of $n$ fair coins and flip all of them. For all coins that come up heads, toss those coins out the window and pass the remaining coins to the other player. Repeat this process until some player flips no heads. If a player fails to flip any heads, that player loses. Question: Given a (large) value of $n$ , determine which player is more likely to win this game. Let $P_n$ be the probability of losing this game when you go first and start with $n$ coins. Then $P_0=1$ (you can’t flip heads if there aren’t any coins) and $P_n$ satisfies the following recurrence: $$P_n=1-\frac{1}{2^n}\sum_{k=1}^n \binom{n}{k}P_{n-k}$$ While analyzing this, I found out pretty quickly that $P_n$ converges to $1/2$ , so I let $P_n=1/2+Q_n$ and found the following recurrence for $Q_n$ : $$Q_n=-\frac{1}{2^n}\sum_{k=1}^n \binom{n}{k}Q_{n-k}$$ Some initial values of $Q_n$ , starting with $Q_0=1/2$ , are $$\frac{1}{2},\space 0,\space -\frac{1}{4},\space \frac{1}{64},\space \frac{5}{256},\space ....$$ Of course, the sign of $Q_n$ determines which player the game favors. Running a Python script, I determined that $Q_n$ changes signs after $n=8,17,35,72,145,291,583$ (at which point the numbers got too big for my program to handle, since it was dealing with binomial coefficients). I know that these values at which sign changes occur are $\sim c\cdot 2^k$ for some constant $c$ . What I need help with: Can anyone calculate the value of $c$ , or come up with a clever way to calculate the sign of $Q_n$ for arbitrary large $n$ ? What I know already: If it helps, I’ve found out that the EGF (exponential generating function) of $Q_n$ , denoted $f$ , satisfies the following functional equation: $$f(2x)=(1-e^x)f(x)$$ However, I’m not sure how to use this fact. Also, I know that the expected duration of the game (that is, the number of turns before someone loses) is asymptotically $\log_2(n)$ for large $n$ . However, this fact is almost trivial because we expect half of the coins to come up heads (and be thrown out) after each turn.","Consider the following game between two people. You start with a large stack of fair coins and flip all of them. For all coins that come up heads, toss those coins out the window and pass the remaining coins to the other player. Repeat this process until some player flips no heads. If a player fails to flip any heads, that player loses. Question: Given a (large) value of , determine which player is more likely to win this game. Let be the probability of losing this game when you go first and start with coins. Then (you can’t flip heads if there aren’t any coins) and satisfies the following recurrence: While analyzing this, I found out pretty quickly that converges to , so I let and found the following recurrence for : Some initial values of , starting with , are Of course, the sign of determines which player the game favors. Running a Python script, I determined that changes signs after (at which point the numbers got too big for my program to handle, since it was dealing with binomial coefficients). I know that these values at which sign changes occur are for some constant . What I need help with: Can anyone calculate the value of , or come up with a clever way to calculate the sign of for arbitrary large ? What I know already: If it helps, I’ve found out that the EGF (exponential generating function) of , denoted , satisfies the following functional equation: However, I’m not sure how to use this fact. Also, I know that the expected duration of the game (that is, the number of turns before someone loses) is asymptotically for large . However, this fact is almost trivial because we expect half of the coins to come up heads (and be thrown out) after each turn.","n n P_n n P_0=1 P_n P_n=1-\frac{1}{2^n}\sum_{k=1}^n \binom{n}{k}P_{n-k} P_n 1/2 P_n=1/2+Q_n Q_n Q_n=-\frac{1}{2^n}\sum_{k=1}^n \binom{n}{k}Q_{n-k} Q_n Q_0=1/2 \frac{1}{2},\space 0,\space -\frac{1}{4},\space \frac{1}{64},\space \frac{5}{256},\space .... Q_n Q_n n=8,17,35,72,145,291,583 \sim c\cdot 2^k c c Q_n n Q_n f f(2x)=(1-e^x)f(x) \log_2(n) n","['probability', 'sequences-and-series', 'stochastic-processes', 'recurrence-relations', 'asymptotics']"
86,Unexpected answer to an expected value problem,Unexpected answer to an expected value problem,,"Suppose you start on the zero notch of the line of integers. You flip a coin. If you get heads, you move to the integer on the right (+1), and if you get tails, you move to the integer on the left (-1). It turns out that the expected number of flips to reach +1, from 0, is infinity. Why?","Suppose you start on the zero notch of the line of integers. You flip a coin. If you get heads, you move to the integer on the right (+1), and if you get tails, you move to the integer on the left (-1). It turns out that the expected number of flips to reach +1, from 0, is infinity. Why?",,"['probability', 'random-walk']"
87,About a density property of the Nearest Neighbor algorithm: part 2.,About a density property of the Nearest Neighbor algorithm: part 2.,,"Let $(\Omega,\mathcal{F},\mathbb{P})$ be a probability space and $(\mathcal{X},d)$ be metric space. Suppose that $X,X_1,X_2,X_3,... : \Omega\to\mathcal{X}$ are $\mathbb{P}$ -i.i.d. random variables. Get a closed set $K$ of $(\mathcal{X},d)$ and $x\in\partial K$ . Suppose that: $$\exists \delta_x \in(0,1], \frac{\mathbb{P}(X\in \partial K\cap B_r (x))}{\mathbb{P}(X\in B_r (x))}\to \delta_x, r\to 0^+$$ and $$\frac{\mathbb{P}(X\in K^c\cap B_r (x))}{{\mathbb{P}(X\in B_r (x))}}\to0, r\to 0^+$$ where $B_r(x)$ is the open ball centered in $x$ of radius $r$ in $(\mathcal{X},d)$ . Define: $$\forall m\in\mathbb{N}, \pi_m^x: \mathcal{X}^m\to\{1,...,m\}, (x_1,...,x_m)\mapsto \min\left(\operatorname{argmin}_{k\in\{1,...,m\}}\left\{d\left(x,x_k\right)\right\}\right).$$ Define: $$\forall m\in\mathbb{N}, Z_m^x:\Omega\to\mathcal{X}, \omega\mapsto X_{\pi_m^x\left((X_1(\omega),...,X_m(\omega)\right)}(\omega).$$ Is it true that $\mathbb{P}(Z_m^x\in K^c)\to 0, m\to\infty?$ This is a version with stronger hypothesis of this other question that has a negative answer: About a density property of the Nearest Neighbor algorithm",Let be a probability space and be metric space. Suppose that are -i.i.d. random variables. Get a closed set of and . Suppose that: and where is the open ball centered in of radius in . Define: Define: Is it true that This is a version with stronger hypothesis of this other question that has a negative answer: About a density property of the Nearest Neighbor algorithm,"(\Omega,\mathcal{F},\mathbb{P}) (\mathcal{X},d) X,X_1,X_2,X_3,... : \Omega\to\mathcal{X} \mathbb{P} K (\mathcal{X},d) x\in\partial K \exists \delta_x \in(0,1], \frac{\mathbb{P}(X\in \partial K\cap B_r (x))}{\mathbb{P}(X\in B_r (x))}\to \delta_x, r\to 0^+ \frac{\mathbb{P}(X\in K^c\cap B_r (x))}{{\mathbb{P}(X\in B_r (x))}}\to0, r\to 0^+ B_r(x) x r (\mathcal{X},d) \forall m\in\mathbb{N}, \pi_m^x: \mathcal{X}^m\to\{1,...,m\}, (x_1,...,x_m)\mapsto \min\left(\operatorname{argmin}_{k\in\{1,...,m\}}\left\{d\left(x,x_k\right)\right\}\right). \forall m\in\mathbb{N}, Z_m^x:\Omega\to\mathcal{X}, \omega\mapsto X_{\pi_m^x\left((X_1(\omega),...,X_m(\omega)\right)}(\omega). \mathbb{P}(Z_m^x\in K^c)\to 0, m\to\infty?","['probability', 'probability-theory', 'measure-theory', 'martingales', 'geometric-measure-theory']"
88,Probability to find two numbers in the same group,Probability to find two numbers in the same group,,"The integers from 1 to 100 are randomly separated into two groups of 50 integers each. What is the probability that 37 and 89 are in the same group? My reasoning in this exercise is to first put one number in one of the possible 100 positions and then place the second one : For the first one there is no restrictions and for the second one there are 49/99 possible position.Besides the positions of the other numbers are not important so i think that the answer is 49/99 , am i right?","The integers from 1 to 100 are randomly separated into two groups of 50 integers each. What is the probability that 37 and 89 are in the same group? My reasoning in this exercise is to first put one number in one of the possible 100 positions and then place the second one : For the first one there is no restrictions and for the second one there are 49/99 possible position.Besides the positions of the other numbers are not important so i think that the answer is 49/99 , am i right?",,"['probability', 'combinatorics']"
89,Throw 40 dice and arrange them in a row - check my proof,Throw 40 dice and arrange them in a row - check my proof,,"Assume you throw $40$ dice and arrange them in a row so that you got a $40$ -tuple. Then you throw antoher die. The result of this die indicates the number of the starting die of the $40$ -tuple. E.g. you throw a $5$ then you start at the $5$ -th die of the $40$ -tuple. Then you traverse the $40$ -tuple in steps determined by the die you are standing on. Let's say the $40$ -tuple looks like this: $$ (4, 4, 5, 1, 6, 6, 4, 2, 1, 1, 4, 6, ....., 2)$$ If you throw a $3$ you start at the die which shows a $5$ , then you go 5 steps further to the die that shows a $2$ and from there you go $2$ steps further and so on ... If you cannot complete the steps because you would exceed the $40$ -tuple then you remain on the actual die and remove all the subseqeunt dice. Let's say you are on the die which shows the $6$ $$ (3,.., 2, 1, 4, \color{red}6, 4, 5, 5, 2, 1)$$ You cannot go $6$ steps further so you stay there and remove all subsequent dice. You get: $$ (3,.., 2, 1, 4,\color{red}6)$$ So in this case you finally would get a $35$ -tuple beacuse you have removed 5 dice. The question is: If I throw a die a second time to traverse the remaining tuple again how can I estimate the probability of exactly landing on the last die of the remaining tuple? Note that if I once arrive a die which was already visited during the first run I will never leave the path and will automatically end on the last die. My approach: Let be $A$ the event of landing excatly on the last die and $B= A^c$ the complement. If I find an upper boundary $U$ for $P(B)$ I can then estimate $P(A)$ by $P(A)\geq 1-U$ . So I need to figure out when $P(B)$ is highest. If I stand somewhere in the tuple and I am about to take my next steps then the maximum probability of not finishing on a die which I have already visited is $\frac{5}{6}$ . So $P(B)$ must be something like $\left(\frac{5}{6}\right)^k$ . Where $k$ refers to each time I have finished my steps. The smaller $k$ is the greater becomes $\left(\frac{5}{6}\right)^k$ . So $\left(\frac{5}{6}\right)^k$ is highest if I always end my steps on a die showing a $6$ beacuse then I traverse the tuple fastest. So after ending my steps six times on a $6$ I will at least have traversed the tuple. But If I had removed 5 dice after the first run I am even able to traverse the tuple after ending my steps five times on a $6$ . So, $P(B)\leq\left(\frac{5}{6}\right)^5$ . Hence, $P(A)\geq 1-\left(\frac{5}{6}\right)^5$ . What do you think, is this correct? I have absoultey no idea how to tackle this problem in a rigorous way. May be you have different approaches. Any comments or suggestions are welcome!","Assume you throw dice and arrange them in a row so that you got a -tuple. Then you throw antoher die. The result of this die indicates the number of the starting die of the -tuple. E.g. you throw a then you start at the -th die of the -tuple. Then you traverse the -tuple in steps determined by the die you are standing on. Let's say the -tuple looks like this: If you throw a you start at the die which shows a , then you go 5 steps further to the die that shows a and from there you go steps further and so on ... If you cannot complete the steps because you would exceed the -tuple then you remain on the actual die and remove all the subseqeunt dice. Let's say you are on the die which shows the You cannot go steps further so you stay there and remove all subsequent dice. You get: So in this case you finally would get a -tuple beacuse you have removed 5 dice. The question is: If I throw a die a second time to traverse the remaining tuple again how can I estimate the probability of exactly landing on the last die of the remaining tuple? Note that if I once arrive a die which was already visited during the first run I will never leave the path and will automatically end on the last die. My approach: Let be the event of landing excatly on the last die and the complement. If I find an upper boundary for I can then estimate by . So I need to figure out when is highest. If I stand somewhere in the tuple and I am about to take my next steps then the maximum probability of not finishing on a die which I have already visited is . So must be something like . Where refers to each time I have finished my steps. The smaller is the greater becomes . So is highest if I always end my steps on a die showing a beacuse then I traverse the tuple fastest. So after ending my steps six times on a I will at least have traversed the tuple. But If I had removed 5 dice after the first run I am even able to traverse the tuple after ending my steps five times on a . So, . Hence, . What do you think, is this correct? I have absoultey no idea how to tackle this problem in a rigorous way. May be you have different approaches. Any comments or suggestions are welcome!","40 40 40 5 5 40 40 40  (4, 4, 5, 1, 6, 6, 4, 2, 1, 1, 4, 6, ....., 2) 3 5 2 2 40 6  (3,.., 2, 1, 4, \color{red}6, 4, 5, 5, 2, 1) 6  (3,.., 2, 1, 4,\color{red}6) 35 A B= A^c U P(B) P(A) P(A)\geq 1-U P(B) \frac{5}{6} P(B) \left(\frac{5}{6}\right)^k k k \left(\frac{5}{6}\right)^k \left(\frac{5}{6}\right)^k 6 6 6 P(B)\leq\left(\frac{5}{6}\right)^5 P(A)\geq 1-\left(\frac{5}{6}\right)^5","['probability', 'combinatorics', 'proof-verification', 'dice']"
90,Variant on Bayes's Rule and weather forecasting,Variant on Bayes's Rule and weather forecasting,,"A common application of Bayes's Rule is with weather forecasting, but I have a question mapping this to a real-world situation. As in a previous StackExchange question , the simple Bayes's problem is usually framed as below: Marie is getting married tomorrow, at an outdoor ceremony in the   desert. In recent years, it has rained only 5 days each year.   Unfortunately, the weatherman has predicted rain for tomorrow. When it   actually rains, the weatherman correctly forecasts rain 90% of the   time. When it doesn't rain, he incorrectly forecasts rain 10% of the   time. What is the probability that it will rain on the day of Marie's   wedding? To use common notation with the selected answer in that question, let $R$ denote the event that it actually rains (prior). And $P$ denote the event that the weather forecaster is correct. We can then apply Baye's to calculate $P(R|P)$ . However, in reality, weather forecasters themselves seem to issue probabilities that it will rain as opposed to a binary response. For example, the weather forecaster says there is a 70% chance it will rain tomorrow (while being correct only 90% of the time, as before). How does one rationally update their prior $P(R)$ in this case?","A common application of Bayes's Rule is with weather forecasting, but I have a question mapping this to a real-world situation. As in a previous StackExchange question , the simple Bayes's problem is usually framed as below: Marie is getting married tomorrow, at an outdoor ceremony in the   desert. In recent years, it has rained only 5 days each year.   Unfortunately, the weatherman has predicted rain for tomorrow. When it   actually rains, the weatherman correctly forecasts rain 90% of the   time. When it doesn't rain, he incorrectly forecasts rain 10% of the   time. What is the probability that it will rain on the day of Marie's   wedding? To use common notation with the selected answer in that question, let denote the event that it actually rains (prior). And denote the event that the weather forecaster is correct. We can then apply Baye's to calculate . However, in reality, weather forecasters themselves seem to issue probabilities that it will rain as opposed to a binary response. For example, the weather forecaster says there is a 70% chance it will rain tomorrow (while being correct only 90% of the time, as before). How does one rationally update their prior in this case?",R P P(R|P) P(R),"['probability', 'bayesian']"
91,On the mean value theorem for random variables.,On the mean value theorem for random variables.,,"Let $X,Y$ be two random variables that take values in $\mathbb{R}$ and let $f$ be a continuous and differentiable function on $\mathbb{R}$ . Then does there always exist a random variable $C$ such that $$f(X) - f(Y) = f'(C) (X-Y)$$ If $X,Y$ are discrete random variables it seems easy to find such a $C$ through the standard mean value theorem. In the continuous case are we guaranteed the existence since $C$ would be a (measurable ?) function of $X,Y$ ?",Let be two random variables that take values in and let be a continuous and differentiable function on . Then does there always exist a random variable such that If are discrete random variables it seems easy to find such a through the standard mean value theorem. In the continuous case are we guaranteed the existence since would be a (measurable ?) function of ?,"X,Y \mathbb{R} f \mathbb{R} C f(X) - f(Y) = f'(C) (X-Y) X,Y C C X,Y","['real-analysis', 'probability', 'probability-theory']"
92,Car Convoy Problem [closed],Car Convoy Problem [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question Cars travel down a one-way single-track road. The nth driver would like to drive at speed $V_n$ , where $ V_1,V_2, ..., V_n$ are iid random variables. Cars will get bunched into convoys. If $V_2>V_1>V_3$ , then the first convoy will consists of cars 1 and 2 , and will be of length 2. Let L be the length of the first convoy. Find the probability $P(L=n)$ and the expectation $E(L)$ .","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question Cars travel down a one-way single-track road. The nth driver would like to drive at speed , where are iid random variables. Cars will get bunched into convoys. If , then the first convoy will consists of cars 1 and 2 , and will be of length 2. Let L be the length of the first convoy. Find the probability and the expectation .","V_n  V_1,V_2, ..., V_n V_2>V_1>V_3 P(L=n) E(L)","['probability', 'probability-theory', 'probability-distributions', 'conditional-probability', 'elementary-probability']"
93,"Probability question from British Math Olympiad, 1973","Probability question from British Math Olympiad, 1973",,"Recently I got a problem from British Math Olympiad, 1973 It is a probability question. In answering general knowledge questions (framed so that each question is answered yes or no), the teacher's probability of being correct is $\alpha$ and a pupil's probability of being correct is $\beta$ or $\gamma$ according to as the pupil is a boy or a girl.    The probability of a randomly chosen pupil agreeing with the teacher's answer is $\dfrac{1}{2}$ .    Find the ratio of a number of boys to girls in the class. I did it as $$b=\text{Number of boys}$$ $$g=\text{Number of girls}$$ so $$\frac{1}{2}=\Big(\alpha \beta+(1-\alpha)(1-\beta)\Big)\Bigg(\dfrac{b}{b+g}\Bigg)+\Big(\alpha \gamma+(1-\alpha)(1-\gamma)\Big)\Bigg(\dfrac{g}{b+g}\Bigg)$$ $$\frac{b+g}{2}=\Big(\alpha \beta+(1-\alpha)(1-\beta)\Big)b+\Big(\alpha \gamma+(1-\alpha)(1-\gamma)\Big)g$$ divide by g $$\frac{b+g}{2g}=\Big(\alpha \beta+(1-\alpha)(1-\beta)\Big)\Bigg(\dfrac{b}{g}\Bigg)+\Big(\alpha \gamma+(1-\alpha)(1-\gamma)\Big)\Bigg(\dfrac{g}{g}\Bigg)$$ $$\frac{b}{2g}+\frac{1}{2}=\Big(\alpha \beta+(1-\alpha)(1-\beta)\Big)\Bigg(\dfrac{b}{g}\Bigg)+\Big(\alpha \gamma+(1-\alpha)(1-\gamma)\Big)$$ $$\frac{b}{2g}-\Big(\alpha \beta+(1-\alpha)(1-\beta)\Big)\Bigg(\dfrac{b}{g}\Bigg)=\Big(\alpha \gamma+(1-\alpha)(1-\gamma)\Big)-\dfrac{1}{2}$$ $$\frac{b}{g}=\dfrac{\Big(\alpha \gamma+(1-\alpha)(1-\gamma)\Big)-\dfrac{1}{2}}{\dfrac{1}{2}-\Big(\alpha \beta+(1-\alpha)(1-\beta)\Big)}$$ Is it right? Need Suggations.","Recently I got a problem from British Math Olympiad, 1973 It is a probability question. In answering general knowledge questions (framed so that each question is answered yes or no), the teacher's probability of being correct is and a pupil's probability of being correct is or according to as the pupil is a boy or a girl.    The probability of a randomly chosen pupil agreeing with the teacher's answer is .    Find the ratio of a number of boys to girls in the class. I did it as so divide by g Is it right? Need Suggations.",\alpha \beta \gamma \dfrac{1}{2} b=\text{Number of boys} g=\text{Number of girls} \frac{1}{2}=\Big(\alpha \beta+(1-\alpha)(1-\beta)\Big)\Bigg(\dfrac{b}{b+g}\Bigg)+\Big(\alpha \gamma+(1-\alpha)(1-\gamma)\Big)\Bigg(\dfrac{g}{b+g}\Bigg) \frac{b+g}{2}=\Big(\alpha \beta+(1-\alpha)(1-\beta)\Big)b+\Big(\alpha \gamma+(1-\alpha)(1-\gamma)\Big)g \frac{b+g}{2g}=\Big(\alpha \beta+(1-\alpha)(1-\beta)\Big)\Bigg(\dfrac{b}{g}\Bigg)+\Big(\alpha \gamma+(1-\alpha)(1-\gamma)\Big)\Bigg(\dfrac{g}{g}\Bigg) \frac{b}{2g}+\frac{1}{2}=\Big(\alpha \beta+(1-\alpha)(1-\beta)\Big)\Bigg(\dfrac{b}{g}\Bigg)+\Big(\alpha \gamma+(1-\alpha)(1-\gamma)\Big) \frac{b}{2g}-\Big(\alpha \beta+(1-\alpha)(1-\beta)\Big)\Bigg(\dfrac{b}{g}\Bigg)=\Big(\alpha \gamma+(1-\alpha)(1-\gamma)\Big)-\dfrac{1}{2} \frac{b}{g}=\dfrac{\Big(\alpha \gamma+(1-\alpha)(1-\gamma)\Big)-\dfrac{1}{2}}{\dfrac{1}{2}-\Big(\alpha \beta+(1-\alpha)(1-\beta)\Big)},"['probability', 'algebra-precalculus', 'contest-math']"
94,Distance from origin of biased random walk conditioned to be positive at time n,Distance from origin of biased random walk conditioned to be positive at time n,,"Let $S_n$ be the position of a simple random walk on the integers started from $0$ that moves right with probability $p<1/2$ . What is the asymptotic behavior of $$E[ S_n \mid S_n >0 ]$$ as $n \to \infty$ ? This is a large deviation event, so I don't have  good intuition for how far the walk should be. I would believe anything between $O(1)$ and $O(n)$ . However, my gut tells me that it is $O(\sqrt n)$ which is what would occur for $p=1/2$ . Note that $S_k$ is allowed to be nonpositive for $k<n$ , we are just conditioning on its location at time $n$ .","Let be the position of a simple random walk on the integers started from that moves right with probability . What is the asymptotic behavior of as ? This is a large deviation event, so I don't have  good intuition for how far the walk should be. I would believe anything between and . However, my gut tells me that it is which is what would occur for . Note that is allowed to be nonpositive for , we are just conditioning on its location at time .",S_n 0 p<1/2 E[ S_n \mid S_n >0 ] n \to \infty O(1) O(n) O(\sqrt n) p=1/2 S_k k<n n,"['probability', 'random-walk', 'large-deviation-theory']"
95,Probability that n sequences agree in a certain percentage of them,Probability that n sequences agree in a certain percentage of them,,"I am trying to work out what the probability that $n$ coin toss sequences of length $k$ match in $m$ spots. The simplest example would be two sequences of a given length. If I toss a coin 100 times, twice, how many of positions in the sequence will match? My intuition tells me that if I have a fair coin (so $p = 0.5$ ) then I should expect two random sequences to on average, agree in 50% of their locations. I also think that I am correct in saying that the probability of two sequences of length $k$ being in complete agreement is $p^q (1-p)^{(k-q)}$ where $q$ is the number of heads in the sequence. However, I am unable to formalize my particular question (which is a fraction of the sequence, independent of subsequence length), nor am I able to extend this to the probability that 3 sequences of a particular length agreeing in 50% of their locations. Any help would be appreciated. Edit : To be more specific, I am having difficulty with the combinatorics involved when the probability $p \neq 0.5$ . Suppose the first sequence contains 2 heads. It can be $HHTT$ or $HTHT$ or $THTH$ etc.. it doesn't matter. Now I want to calculate the probability that another sequence matches $0, 1, 2, 3, \mathrm{or}\ 4$ of those outcomes. I have chosen $HHTT$ as the first sequence and enumerated the possible matching sequence for each case. In the case of 0 matching outcomes, the only possibility is \begin{array}{cccc} & T & T & H & H \\ \end{array} In the case of 1 matching outcome, the possibilities are: \begin{array}{cccc} & H & T & H & H \\ & T & H & H & H \\ & T & T & T & H \\ & T & T & H & T \\ \end{array} In the case of 2 matching outcomes, the possibilities are: \begin{array}{cccc} & H & H & H & H \\ & H & T & T & H \\ & H & T & H & T \\ & T & H & T & H \\ & T & H & H & T \\ & T & T & T & T \\ \end{array} In the case of 3 matching outcomes, the possibilities are: \begin{array}{cccc} & H & H & T & H \\ & H & T & T & T \\ & H & H & H & T \\ & T & H & T & T \\ \end{array} Finally, for all 4 matching outcomes, the only possibility is: \begin{array}{cccc} & H & H & T & T \\ \end{array} Now the number of combinations for matching $m$ outcomes for a sequence of length $k$ is given by ${k\choose m}$ . The only problem is, because the probability is not $0.5$ , I need to enumerate how many of those contain $x$ number of $H$ , so I can sum up $p^q (1-p)^{(k-q)}$ , each multiplied by the appropriate prefactor. However, I am unable to identify the appropriate pattern . This is the main difficulty I am having. Any help towards figuring out a formula for the probability of two (or more!) sequences of length $k$ matching in $m$ spots, where the probability of each outcome is not 0.5 would be greatly appreciated. Thanks!","I am trying to work out what the probability that coin toss sequences of length match in spots. The simplest example would be two sequences of a given length. If I toss a coin 100 times, twice, how many of positions in the sequence will match? My intuition tells me that if I have a fair coin (so ) then I should expect two random sequences to on average, agree in 50% of their locations. I also think that I am correct in saying that the probability of two sequences of length being in complete agreement is where is the number of heads in the sequence. However, I am unable to formalize my particular question (which is a fraction of the sequence, independent of subsequence length), nor am I able to extend this to the probability that 3 sequences of a particular length agreeing in 50% of their locations. Any help would be appreciated. Edit : To be more specific, I am having difficulty with the combinatorics involved when the probability . Suppose the first sequence contains 2 heads. It can be or or etc.. it doesn't matter. Now I want to calculate the probability that another sequence matches of those outcomes. I have chosen as the first sequence and enumerated the possible matching sequence for each case. In the case of 0 matching outcomes, the only possibility is In the case of 1 matching outcome, the possibilities are: In the case of 2 matching outcomes, the possibilities are: In the case of 3 matching outcomes, the possibilities are: Finally, for all 4 matching outcomes, the only possibility is: Now the number of combinations for matching outcomes for a sequence of length is given by . The only problem is, because the probability is not , I need to enumerate how many of those contain number of , so I can sum up , each multiplied by the appropriate prefactor. However, I am unable to identify the appropriate pattern . This is the main difficulty I am having. Any help towards figuring out a formula for the probability of two (or more!) sequences of length matching in spots, where the probability of each outcome is not 0.5 would be greatly appreciated. Thanks!","n k m p = 0.5 k p^q (1-p)^{(k-q)} q p \neq 0.5 HHTT HTHT THTH 0, 1, 2, 3, \mathrm{or}\ 4 HHTT \begin{array}{cccc}
& T & T & H & H \\
\end{array} \begin{array}{cccc}
& H & T & H & H \\
& T & H & H & H \\
& T & T & T & H \\
& T & T & H & T \\
\end{array} \begin{array}{cccc}
& H & H & H & H \\
& H & T & T & H \\
& H & T & H & T \\
& T & H & T & H \\
& T & H & H & T \\
& T & T & T & T \\
\end{array} \begin{array}{cccc}
& H & H & T & H \\
& H & T & T & T \\
& H & H & H & T \\
& T & H & T & T \\
\end{array} \begin{array}{cccc}
& H & H & T & T \\
\end{array} m k {k\choose m} 0.5 x H p^q (1-p)^{(k-q)} k m","['probability', 'permutations', 'combinations']"
96,Conditional law of total probability,Conditional law of total probability,,"Let $F_1, \dots, F_n$ be a partition of $\Omega$ the sample space. Let $E$ be an event.  The law of total probability tells us: \begin{align} P(E) = \sum_{i=1}^n P(E\vert F_i) P(F_i) \end{align} Let's take now an other arbitrary event $B$ , intuitively conditioning on this new event, we should have: \begin{align} P(E\vert B) = \sum_{i=1}^n P(E\vert F_i, B) P(F_i \vert B) \end{align} Here is my proof: On the left hand side we have: $$ P(E\vert B) = \frac{P(E \cap B)}{P(B)}$$ On the right hand side we have: \begin{align} \sum_{i=1}^n P(E\vert F_i, B) P(F_i \vert B) &= \sum_{i=1}^n \frac{P(E\cap F_i \cap B) }{P(F_i \cap B)} \frac{P(F_i \cap B)}{ P(B)} \\ &= \sum_{i=1}^n \frac{P((E\cap B) \cap F_i)}{P(B)} \\ &= \frac{1}{P(B) }\sum_{i=1}^n P((E\cap B) \cap F_i) \\ &= \frac{P(E\cap B)}{P(B)} \qquad \text{by the law of total probability} \end{align} Is my demonstration correct?","Let be a partition of the sample space. Let be an event.  The law of total probability tells us: Let's take now an other arbitrary event , intuitively conditioning on this new event, we should have: Here is my proof: On the left hand side we have: On the right hand side we have: Is my demonstration correct?","F_1, \dots, F_n \Omega E \begin{align}
P(E) = \sum_{i=1}^n P(E\vert F_i) P(F_i)
\end{align} B \begin{align}
P(E\vert B) = \sum_{i=1}^n P(E\vert F_i, B) P(F_i \vert B)
\end{align}  P(E\vert B) = \frac{P(E \cap B)}{P(B)} \begin{align}
\sum_{i=1}^n P(E\vert F_i, B) P(F_i \vert B) &= \sum_{i=1}^n \frac{P(E\cap F_i \cap B) }{P(F_i \cap B)} \frac{P(F_i \cap B)}{ P(B)} \\
&= \sum_{i=1}^n \frac{P((E\cap B) \cap F_i)}{P(B)} \\
&= \frac{1}{P(B) }\sum_{i=1}^n P((E\cap B) \cap F_i)
\\ &= \frac{P(E\cap B)}{P(B)} \qquad \text{by the law of total probability}
\end{align}","['probability', 'self-learning', 'conditional-probability']"
97,Integration by Substitution in $\int_0^{\infty}x^r\frac 1{\sqrt{2\pi}x}e^{-(\log x)^2/2}[\sin(2\pi\log x)]dx$,Integration by Substitution in,\int_0^{\infty}x^r\frac 1{\sqrt{2\pi}x}e^{-(\log x)^2/2}[\sin(2\pi\log x)]dx,"In Casella and Berger (2002) I found an example for non-unique moments (example 2.3.10 on page 64). They are providing the following 2 pdfs: $f_1(x) = \frac 1{\sqrt{2\pi}x}e^{-(\log x)^2/2}$ , where $0 \leqslant x \leqslant\infty$ and $f_1(x) = f_1(x) [1 + \sin(2\pi\log x)]$ , where $0 \leqslant x \leqslant\infty$$ The former is lognormal with $\mu = 0$ and $\sigma^2 = 1$ . It can be shown that if $x_1 \sim f_1(x)$ , then $E(x_1^r) = e^{r^2/2}$ . Hence, $x_1$ has all the moments. However, $E(x_2^r) = \int_0^{\infty}x^rf1(x)[1+\sin(2\pi\log x)]dx = E(x_1^r)+\int_0^{\infty}x^rf1(x)[\sin(2\pi\log x)]dx.$ Since the last integral is equal to zero, we can show that $x_1$ and $x_2$ have distinct pfds but the same moments. My question is about how to show that the last integral is equal to zero. In exercise 2.35, Casella and Berger (2002, p. 81) show how to prove this (also see here on page 2-11). $\int_0^{\infty}x^rf1(x)[\sin(2\pi\log x)]dx = \int_0^{\infty}x^r\frac 1{\sqrt{2\pi}x}e^{-(\log x)^2/2}[\sin(2\pi\log x)]dx$ Now, Cassella and Berger propose to substitute $y = \log x$ so that $dy = (1/x)dx$ . Hence, $\int_0^{\infty}e^{(y+r)r}\frac 1{\sqrt{2\pi}x}e^{-(y+r)^2/2}[\sin(2\pi y + 2\pi r)]dx$ $\int_{-\infty}^{\infty}\frac 1{\sqrt{2\pi}x}e^{(r^2-y^2)/2}[\sin(2\pi y + 2\pi r)]dx$ Hence, the the integrand is an odd function. Thus, the negative integral cancels the positive one. This all makes sense. However, when I try to understand the substitution performed, I wonder if Casella and Berger meant to substitute using $y + r = \log x$ . My question may be trivial but would this substitution be allowed/ common? If so, then I would never have seen such an integration by substitution using 2 summands.","In Casella and Berger (2002) I found an example for non-unique moments (example 2.3.10 on page 64). They are providing the following 2 pdfs: , where and , where $0 \leqslant x \leqslant\infty$$ The former is lognormal with and . It can be shown that if , then . Hence, has all the moments. However, Since the last integral is equal to zero, we can show that and have distinct pfds but the same moments. My question is about how to show that the last integral is equal to zero. In exercise 2.35, Casella and Berger (2002, p. 81) show how to prove this (also see here on page 2-11). Now, Cassella and Berger propose to substitute so that . Hence, Hence, the the integrand is an odd function. Thus, the negative integral cancels the positive one. This all makes sense. However, when I try to understand the substitution performed, I wonder if Casella and Berger meant to substitute using . My question may be trivial but would this substitution be allowed/ common? If so, then I would never have seen such an integration by substitution using 2 summands.",f_1(x) = \frac 1{\sqrt{2\pi}x}e^{-(\log x)^2/2} 0 \leqslant x \leqslant\infty f_1(x) = f_1(x) [1 + \sin(2\pi\log x)] \mu = 0 \sigma^2 = 1 x_1 \sim f_1(x) E(x_1^r) = e^{r^2/2} x_1 E(x_2^r) = \int_0^{\infty}x^rf1(x)[1+\sin(2\pi\log x)]dx = E(x_1^r)+\int_0^{\infty}x^rf1(x)[\sin(2\pi\log x)]dx. x_1 x_2 \int_0^{\infty}x^rf1(x)[\sin(2\pi\log x)]dx = \int_0^{\infty}x^r\frac 1{\sqrt{2\pi}x}e^{-(\log x)^2/2}[\sin(2\pi\log x)]dx y = \log x dy = (1/x)dx \int_0^{\infty}e^{(y+r)r}\frac 1{\sqrt{2\pi}x}e^{-(y+r)^2/2}[\sin(2\pi y + 2\pi r)]dx \int_{-\infty}^{\infty}\frac 1{\sqrt{2\pi}x}e^{(r^2-y^2)/2}[\sin(2\pi y + 2\pi r)]dx y + r = \log x,"['probability', 'integration', 'substitution', 'moment-generating-functions']"
98,Expansion of $n(n-1)(n-2)...(n-k)$,Expansion of,n(n-1)(n-2)...(n-k),"Is there a way to express the following such that each coefficient of the expansion can be found selectively: $$n(n-1)(n-2)...(n-k)$$ For example, the first term is obviously $n^{k+1}$ and so it's coefficient is $1$ and the last term is $(-1)^k \cdot k! \cdot n$ which has coefficient $(-1)^k \cdot k!$ . I am attempting to generalise the nth derivative of a probability generating function evaluated at $1$ in terms of $E(X^n)$ and this expansion will allow the result to be generalised.","Is there a way to express the following such that each coefficient of the expansion can be found selectively: For example, the first term is obviously and so it's coefficient is and the last term is which has coefficient . I am attempting to generalise the nth derivative of a probability generating function evaluated at in terms of and this expansion will allow the result to be generalised.",n(n-1)(n-2)...(n-k) n^{k+1} 1 (-1)^k \cdot k! \cdot n (-1)^k \cdot k! 1 E(X^n),"['probability', 'algebra-precalculus']"
99,Why is Convolution Well-Defined (Simple Example),Why is Convolution Well-Defined (Simple Example),,"I am having trouble understanding why convolution is well-defined. Let's take a simple example: $(\Omega, \mathcal{F}, P)$ probability space and $X_{1}, X_{2}$ two real random variables where $P(X_{1}=3)=\frac{1}{2},P(X_{2}=2)=\frac{1}{4}$ And $P(X_{1}=1)=\frac{1}{5},P(X_{2}=4)=\frac{1}{3}$ Then my understanding of convolution is $P_{X_{1}+X_{2}}\circ A^{-1}$ where $A: X_{1} \times X_{2}\to \mathbb R,A(x_{1},x_{2})=x_{1}+x_{2}$ So surely, if, for instance $X_{1}+X_{2}=5$ , I get more than one preimage, and hence how can convolution be well-defined? In the above case, I would get: $P_{X_{1}+X_{2}}\circ A^{-1}(5)=P_{X_{1}}(3)P_{X_{2}}(2)=\frac{1}{2}\times\frac{1}{4}=\frac{1}{8}$ while $P_{X_{1}+X_{2}}\circ A^{-1}(5)=P_{X_{1}}(1)P_{X_{2}}(4)=\frac{1}{5}\times\frac{1}{3}=\frac{1}{15}$ I do not know where I am going wrong in my understanding of convolution. Any help is greatly appreciated.","I am having trouble understanding why convolution is well-defined. Let's take a simple example: probability space and two real random variables where And Then my understanding of convolution is where So surely, if, for instance , I get more than one preimage, and hence how can convolution be well-defined? In the above case, I would get: while I do not know where I am going wrong in my understanding of convolution. Any help is greatly appreciated.","(\Omega, \mathcal{F}, P) X_{1}, X_{2} P(X_{1}=3)=\frac{1}{2},P(X_{2}=2)=\frac{1}{4} P(X_{1}=1)=\frac{1}{5},P(X_{2}=4)=\frac{1}{3} P_{X_{1}+X_{2}}\circ A^{-1} A: X_{1} \times X_{2}\to \mathbb R,A(x_{1},x_{2})=x_{1}+x_{2} X_{1}+X_{2}=5 P_{X_{1}+X_{2}}\circ A^{-1}(5)=P_{X_{1}}(3)P_{X_{2}}(2)=\frac{1}{2}\times\frac{1}{4}=\frac{1}{8} P_{X_{1}+X_{2}}\circ A^{-1}(5)=P_{X_{1}}(1)P_{X_{2}}(4)=\frac{1}{5}\times\frac{1}{3}=\frac{1}{15}","['probability', 'probability-theory', 'random-variables', 'convolution']"
