,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Basic combinations logic doubt in probability,Basic combinations logic doubt in probability,,"""If $3$ students are chosen at random from a class with $6$ girls and $4$ boys, what is the probability that all $3$ students chosen will be girls?"" $\left(\dfrac{6}{10}\right)\left(\dfrac{5}{9}\right)\left(\dfrac{4}{8}\right)$ So why can't we use that logic to answer this question? ""A bag holds $4$ red marbles, $5$ blue marbles, and $2$ green marbles. If $5$ marbles are selected one after another without replacement, what is the probability of drawing $2$ red marbles, $2$ blue marbles, and $1$ green marble?"" My answer: $\left(\dfrac{4}{11}\right)\left(\dfrac{3}{10}\right)\left(\dfrac{5}{9}\right)\left(\dfrac{4}{8}\right)\left(\dfrac{2}{7}\right)$ But the correct answer is $\dfrac{(_4C_2) \cdot (_5C_2) \cdot (_2C_1)}{_{11}C_5}$ (where $C$ is a combination). Why doesn't the logic from the first problem work here? The draws are without replacement in all cases.","""If students are chosen at random from a class with girls and boys, what is the probability that all students chosen will be girls?"" So why can't we use that logic to answer this question? ""A bag holds red marbles, blue marbles, and green marbles. If marbles are selected one after another without replacement, what is the probability of drawing red marbles, blue marbles, and green marble?"" My answer: But the correct answer is (where is a combination). Why doesn't the logic from the first problem work here? The draws are without replacement in all cases.",3 6 4 3 \left(\dfrac{6}{10}\right)\left(\dfrac{5}{9}\right)\left(\dfrac{4}{8}\right) 4 5 2 5 2 2 1 \left(\dfrac{4}{11}\right)\left(\dfrac{3}{10}\right)\left(\dfrac{5}{9}\right)\left(\dfrac{4}{8}\right)\left(\dfrac{2}{7}\right) \dfrac{(_4C_2) \cdot (_5C_2) \cdot (_2C_1)}{_{11}C_5} C,"['probability', 'combinatorics', 'permutations', 'combinations']"
1,What is the name of this formula derived from the Poisson distribution?,What is the name of this formula derived from the Poisson distribution?,,I am learning about the Poisson distribution in this document and its link reference. This is the key formula to compute the Poisson distribution: $$ f(k; \lambda)=\frac{\lambda^k e^{-\lambda}}{k!} $$ I saw another related formula somewhere. $$ \sum\limits_{k = x}^{+ \infty} \frac{\lambda^k e^{-\lambda}}{k!} $$ Is there a name for this formula?,I am learning about the Poisson distribution in this document and its link reference. This is the key formula to compute the Poisson distribution: I saw another related formula somewhere. Is there a name for this formula?,"
f(k; \lambda)=\frac{\lambda^k e^{-\lambda}}{k!}
 
\sum\limits_{k = x}^{+ \infty}
\frac{\lambda^k e^{-\lambda}}{k!}
",['probability']
2,Drawing balls with a finite number of replacement,Drawing balls with a finite number of replacement,,"I have to solve this problem: ""Suppose a box contains $18$ balls numbered $1–6$ , three balls with each number. When $4$ balls are drawn without replacement, how many outcomes are possible?"". (The order does not matter). I can't find a simple formula for it. I've tried in this way and I don't know if it is right way: A random outcome could or could not have the number $1$ . If it has it, the outcome could be $111$ plus a number $2\le n \le 6$ , or $11$ plus two numbers or $1$ plus three numbers. In the first case we have a total of ${{5}\choose{1}} = 5 $ outcomes. In the second case we have a total of ${{5}\choose{2}} + 5 = 15$ outcomes. In the last case we have a total of ${{5}\choose{3}} + 5 +5\times 4 = 35 $ outcomes. Finally, if the outcomes does not have the number 1 we have a total of $ {{5}\choose{4}} + 5\times(4\times 3 + 4) + 5\times 4 + 5 = 110$ . So there are 165 possible outcomes. Is it right? If yes, there is a simpler and much more elegant way to prove it? Thanks","I have to solve this problem: ""Suppose a box contains balls numbered , three balls with each number. When balls are drawn without replacement, how many outcomes are possible?"". (The order does not matter). I can't find a simple formula for it. I've tried in this way and I don't know if it is right way: A random outcome could or could not have the number . If it has it, the outcome could be plus a number , or plus two numbers or plus three numbers. In the first case we have a total of outcomes. In the second case we have a total of outcomes. In the last case we have a total of outcomes. Finally, if the outcomes does not have the number 1 we have a total of . So there are 165 possible outcomes. Is it right? If yes, there is a simpler and much more elegant way to prove it? Thanks",18 1–6 4 1 111 2\le n \le 6 11 1 {{5}\choose{1}} = 5  {{5}\choose{2}} + 5 = 15 {{5}\choose{3}} + 5 +5\times 4 = 35   {{5}\choose{4}} + 5\times(4\times 3 + 4) + 5\times 4 + 5 = 110,"['probability', 'combinatorics', 'permutations', 'combinations']"
3,Calculate the expected value for this markov chain,Calculate the expected value for this markov chain,,"Harry's restaurant changes year after year between the states $0$   (bankrupt), $1$ (almost bankrupt) and $2$ (solvent). The transition matrix is    $P= \begin{pmatrix}  1    &  0    &  0   \\  1/2  &  1/4  &  1/4 \\   1/2  &  1/4  &  1/4  \end{pmatrix}$ Calculate the expected value for the amount of years till state $0$ is   reached, if we started from state $2$. I took this question from an exam and try to solve it but I'm not sure how to do this correct? I'm a bit confused we need to work with expected value to calculate the required steps / years to get from state $2$ to state $0$. At least that's how I understood this so far. It all sounds like I need to solve some recursive relations. Let $h(k)$ be the expected number of steps / years in this example until we reach the state $0$ when you are in state $2$. So we have that  $$h(2)=0$$ because when you are in state $2$, you need $0$ steps / years to reach $2$. Then for $k=1$ $$h(1) = 1+0.25h(1)+0.25h(2)+0.5h(0)$$ because when you are in state $1$ you will need a step ($+1$) so you will reach with probability $0.25$ state $1$ again and with probability $0.25$ state $2$ and with probability $0.5$ state $0$. Similarly we do this for $h(0):$ $$h(0) = 1+1h(0)$$ But from here I don't really know how to continue to get the system and calculate the expected number pf steps with that? : /","Harry's restaurant changes year after year between the states $0$   (bankrupt), $1$ (almost bankrupt) and $2$ (solvent). The transition matrix is    $P= \begin{pmatrix}  1    &  0    &  0   \\  1/2  &  1/4  &  1/4 \\   1/2  &  1/4  &  1/4  \end{pmatrix}$ Calculate the expected value for the amount of years till state $0$ is   reached, if we started from state $2$. I took this question from an exam and try to solve it but I'm not sure how to do this correct? I'm a bit confused we need to work with expected value to calculate the required steps / years to get from state $2$ to state $0$. At least that's how I understood this so far. It all sounds like I need to solve some recursive relations. Let $h(k)$ be the expected number of steps / years in this example until we reach the state $0$ when you are in state $2$. So we have that  $$h(2)=0$$ because when you are in state $2$, you need $0$ steps / years to reach $2$. Then for $k=1$ $$h(1) = 1+0.25h(1)+0.25h(2)+0.5h(0)$$ because when you are in state $1$ you will need a step ($+1$) so you will reach with probability $0.25$ state $1$ again and with probability $0.25$ state $2$ and with probability $0.5$ state $0$. Similarly we do this for $h(0):$ $$h(0) = 1+1h(0)$$ But from here I don't really know how to continue to get the system and calculate the expected number pf steps with that? : /",,"['probability', 'matrices', 'probability-theory', 'statistics']"
4,Understanding a probability paradox,Understanding a probability paradox,,"Three prisoners are informed by their jailer that one of them has been chosen at random to be executed and the other two are to be freed. Prisoner A asks the jailer to tell him privately which of his fellow prisoners will be set free, claiming that there would be no harm in divulging this information because he already knows that at least one of the two will go free. The jailer refuses to answer the question, pointing out that if A knew which of his fellow prisoners were to be set free, then his own probability of being executed would rise from $\frac 13$ to $\frac 12$ because he would then be one of two prisoners. What do you think of the jailer’s reasoning? If the jailer refuses to say anything, then the probability that prisoner $A$ is excecuted is $\frac{1}{3}$ . If the jailer says to prisoner $A$ that prisoner $B$ will walk free, then $2$ prisoners remain to be considered, $A$ and $C$ . One dies, one does not. Heads or tails essentially. $\frac{1}{2}$ ought to be the conditional probability that $A$ dies given that $B$ walks free no? Apparently not though, allegedly the correct answer is still $\frac{1}{3}$ . Even my attempt to calculate the correct answer yielded the result $\frac{1}{2}$ . Let $A_D$ and $C_D$ respectively denote the event of $A$ and $C$ dying. Let $B_F$ denote the event that $B$ walks free. Assume that the jailer tells prisoner $A$ that prisoner $B$ will walk free. Here's my attempt. $$P(A_D\mid B_F)=\frac{P(A_D\cap B_F)}{P(B_F)}=\frac{P(A_D\cap B_F)}{P((B_F\cap A_D)\cup (B_F\cap C_D))}=\frac{P(A_D)P(B_F\mid A_D)}{P(A_D)P(B_F\mid A_D)+P(C_D)P(B_F\mid C_D)}=\frac{\frac{1}{3}\times 1}{\frac{1}{3}\times 1+\frac{1}{3}\times 1}=\frac{1}{2}$$ What am I doing wrong? Edit 1: Intuitively I am still troubled but I understand now that $B_F$ may occur even though the jailer does not necessarally say $B$ . Edit 2: I suppose that it makes some sense if the faiths of the prisoners had already been decided before prisoner $A$ asked the jailer the question. If the jailer decides to reveal one of the others who will walk free then that must've been the case.","Three prisoners are informed by their jailer that one of them has been chosen at random to be executed and the other two are to be freed. Prisoner A asks the jailer to tell him privately which of his fellow prisoners will be set free, claiming that there would be no harm in divulging this information because he already knows that at least one of the two will go free. The jailer refuses to answer the question, pointing out that if A knew which of his fellow prisoners were to be set free, then his own probability of being executed would rise from to because he would then be one of two prisoners. What do you think of the jailer’s reasoning? If the jailer refuses to say anything, then the probability that prisoner is excecuted is . If the jailer says to prisoner that prisoner will walk free, then prisoners remain to be considered, and . One dies, one does not. Heads or tails essentially. ought to be the conditional probability that dies given that walks free no? Apparently not though, allegedly the correct answer is still . Even my attempt to calculate the correct answer yielded the result . Let and respectively denote the event of and dying. Let denote the event that walks free. Assume that the jailer tells prisoner that prisoner will walk free. Here's my attempt. What am I doing wrong? Edit 1: Intuitively I am still troubled but I understand now that may occur even though the jailer does not necessarally say . Edit 2: I suppose that it makes some sense if the faiths of the prisoners had already been decided before prisoner asked the jailer the question. If the jailer decides to reveal one of the others who will walk free then that must've been the case.",\frac 13 \frac 12 A \frac{1}{3} A B 2 A C \frac{1}{2} A B \frac{1}{3} \frac{1}{2} A_D C_D A C B_F B A B P(A_D\mid B_F)=\frac{P(A_D\cap B_F)}{P(B_F)}=\frac{P(A_D\cap B_F)}{P((B_F\cap A_D)\cup (B_F\cap C_D))}=\frac{P(A_D)P(B_F\mid A_D)}{P(A_D)P(B_F\mid A_D)+P(C_D)P(B_F\mid C_D)}=\frac{\frac{1}{3}\times 1}{\frac{1}{3}\times 1+\frac{1}{3}\times 1}=\frac{1}{2} B_F B A,"['probability', 'paradoxes']"
5,Finding out probability that the last digit of a product is 5,Finding out probability that the last digit of a product is 5,,"If $n$ positive integers taken at random are multiplied together, show that the probability that the last digit of their product is 5 is $$\frac{5^n-4^n}{{10}^n}$$ My attempt: Let $n$ positive integers be $x_1,x_2, \cdots ,x_n$. Let $a=x_1 \cdot x_2 \cdots x_n$. Let $S$ be the sample set. Then $n(S)=10^n$ since there are 10 possibilities for unit digit of each integer. I couldn't proceed from there. Please help me in this regard. Thanks.","If $n$ positive integers taken at random are multiplied together, show that the probability that the last digit of their product is 5 is $$\frac{5^n-4^n}{{10}^n}$$ My attempt: Let $n$ positive integers be $x_1,x_2, \cdots ,x_n$. Let $a=x_1 \cdot x_2 \cdots x_n$. Let $S$ be the sample set. Then $n(S)=10^n$ since there are 10 possibilities for unit digit of each integer. I couldn't proceed from there. Please help me in this regard. Thanks.",,['probability']
6,Birthday Problem: Asymptotics of Expected Time Until a Match Occurs,Birthday Problem: Asymptotics of Expected Time Until a Match Occurs,,"I'm working on a variant of the birthday problem that I haven't found discussed on this site. Suppose the sequence $(X_n)$ of independent random variables takes values uniformly in $\{ 1,...,N \}$. Let $F_{N} = \min\{ m: X_m = X_k, k<m \}$ be the first time that a match is observed. I want to know what can be said about $E(F_N)$ as $N \to \infty$. It's easy to see that  $$P(F_N = k) = \frac{N}{N} \frac{N-1}{N}... \frac{N - (k-2)}{N} \frac{k-1}{N}.$$ Hence,  $$E(F_N) = \sum_{k=2}^{N+1} k \Big[\frac{N}{N} \frac{N-1}{N}... \frac{N - (k-2)}{N} \frac{k-1}{N} \Big]. $$ Any suggestions about where to go from here?","I'm working on a variant of the birthday problem that I haven't found discussed on this site. Suppose the sequence $(X_n)$ of independent random variables takes values uniformly in $\{ 1,...,N \}$. Let $F_{N} = \min\{ m: X_m = X_k, k<m \}$ be the first time that a match is observed. I want to know what can be said about $E(F_N)$ as $N \to \infty$. It's easy to see that  $$P(F_N = k) = \frac{N}{N} \frac{N-1}{N}... \frac{N - (k-2)}{N} \frac{k-1}{N}.$$ Hence,  $$E(F_N) = \sum_{k=2}^{N+1} k \Big[\frac{N}{N} \frac{N-1}{N}... \frac{N - (k-2)}{N} \frac{k-1}{N} \Big]. $$ Any suggestions about where to go from here?",,"['probability', 'probability-theory', 'probability-limit-theorems']"
7,"Probability for ""drawing balls from urn""","Probability for ""drawing balls from urn""",,"I'm afraid I need a little help with the following: In an urn there are $N$ balls, of which $N-2$ are red and the remaining are blue. Person $A$ draws $k$ balls, so that the first $k-1$ are red and the $k$ ball is blue. Now Person B draws m balls: What's the probability for Person $B$ to draw the last/second blue ball after drawing $(m-1)$ red ones? Meant is, that the drawing stops as soon as the blue ball has been drawn. So the blue one must be the last one. My ideas: there are only $(N-k)$ balls in the urn left, of which $(N-2)-(k-1) = N-k-1$ are red and $1$ is blue. for $m$ we have: $m \in \{1, \dots, N-k\}$ . Shouldn't that be solved with Hypergeometric Distribution? With this I like to calculate the probability for $(m-1)=l$ successes of red, so that the $m$ -th ball is blue: $$P(X=l) = \dfrac{\dbinom{N-k-1}{m-1} \cdot \dbinom{1}{1}}{\dbinom{N-k}{m}}$$","I'm afraid I need a little help with the following: In an urn there are balls, of which are red and the remaining are blue. Person draws balls, so that the first are red and the ball is blue. Now Person B draws m balls: What's the probability for Person to draw the last/second blue ball after drawing red ones? Meant is, that the drawing stops as soon as the blue ball has been drawn. So the blue one must be the last one. My ideas: there are only balls in the urn left, of which are red and is blue. for we have: . Shouldn't that be solved with Hypergeometric Distribution? With this I like to calculate the probability for successes of red, so that the -th ball is blue:","N N-2 A k k-1 k B (m-1) (N-k) (N-2)-(k-1) = N-k-1 1 m m \in \{1, \dots, N-k\} (m-1)=l m P(X=l) = \dfrac{\dbinom{N-k-1}{m-1} \cdot \dbinom{1}{1}}{\dbinom{N-k}{m}}","['probability', 'probability-distributions']"
8,Finding $P(X < Y)$ where $X$ and $Y$ are independent uniform random variables,Finding  where  and  are independent uniform random variables,P(X < Y) X Y,"Suppose $X$ and $Y$ are two independent uniform variables in the intervals $(0,2)$ and $(1,3)$ respectively. I need to find $P(X < Y)$. I've tried in this way: $$ \begin{eqnarray} P(X < Y) &=& \int_1^3 \left\{\int_0^y f_X(x) dx\right\}g_Y(y) dy\\ &=& \frac{1}{4} \int_1^3 \int_0^y dx dy\\ &=& \frac{1}{4} \int_1^3 y dy\\ &=& \frac{1}{8} [y^2]_1^3\\ &=& 1 \end{eqnarray} $$ But I'm suspicious about this result. It implies that $X<Y$ is a sure event, which is not at all true.","Suppose $X$ and $Y$ are two independent uniform variables in the intervals $(0,2)$ and $(1,3)$ respectively. I need to find $P(X < Y)$. I've tried in this way: $$ \begin{eqnarray} P(X < Y) &=& \int_1^3 \left\{\int_0^y f_X(x) dx\right\}g_Y(y) dy\\ &=& \frac{1}{4} \int_1^3 \int_0^y dx dy\\ &=& \frac{1}{4} \int_1^3 y dy\\ &=& \frac{1}{8} [y^2]_1^3\\ &=& 1 \end{eqnarray} $$ But I'm suspicious about this result. It implies that $X<Y$ is a sure event, which is not at all true.",,"['probability', 'random-variables']"
9,What is the probability that 5 randomly chosen cards in a deck add up to 40 or greater?,What is the probability that 5 randomly chosen cards in a deck add up to 40 or greater?,,"I have made a probability game, where you have to pull out any 5 cards without looking (from a deck of 52 cards), and if all five cards add up to 40 or more, they player pulling the 5 cards from the deck wins. What is the probability of winning the game? Face and Ace Card values: Ace = 1 Jack = 11 Queen = 12 King = 13 The value of the number cards are the ones that are stated on the card: for example a card that has 2 on it has a value of 2. There is also a grand prize , and it would be if it just added up to 40. How many combinations are there and why?","I have made a probability game, where you have to pull out any 5 cards without looking (from a deck of 52 cards), and if all five cards add up to 40 or more, they player pulling the 5 cards from the deck wins. What is the probability of winning the game? Face and Ace Card values: Ace = 1 Jack = 11 Queen = 12 King = 13 The value of the number cards are the ones that are stated on the card: for example a card that has 2 on it has a value of 2. There is also a grand prize , and it would be if it just added up to 40. How many combinations are there and why?",,['probability']
10,Conditional distribution of order statistics,Conditional distribution of order statistics,,"Let $X_{(1)},...,X_{(n)}$ be the order statistics of a set of $n$ independent uniform $(0,1)$ random variables. Find the conditional distribution of $X_{(n)}$ given that $X_{(1)}=s_1,X_{(2)}=s_2....,X_{(n-1)}=s_{n-1}$ I need to find: $P[X_{(n)}\le x_n| X_{(1)}=s_1,X_{(2)}=s_2....,X_{(n-1)}=s_{n-1}]$ which is equal to: $${P[X_{(n)}\le x_n, X_{(1)}=s_1,X_{(2)}=s_2....,X_{(n-1)}=s_{n-1}]\over P[X_{(1)}=s_1,X_{(2)}=s_2....,X_{(n-1)}=s_{n-1}]}$$ but I have no idea how to compute the above probability and also I don´t know how to use the fact that the variables are uniform and independent. I would really appreciate if you can help me with this problem","Let $X_{(1)},...,X_{(n)}$ be the order statistics of a set of $n$ independent uniform $(0,1)$ random variables. Find the conditional distribution of $X_{(n)}$ given that $X_{(1)}=s_1,X_{(2)}=s_2....,X_{(n-1)}=s_{n-1}$ I need to find: $P[X_{(n)}\le x_n| X_{(1)}=s_1,X_{(2)}=s_2....,X_{(n-1)}=s_{n-1}]$ which is equal to: $${P[X_{(n)}\le x_n, X_{(1)}=s_1,X_{(2)}=s_2....,X_{(n-1)}=s_{n-1}]\over P[X_{(1)}=s_1,X_{(2)}=s_2....,X_{(n-1)}=s_{n-1}]}$$ but I have no idea how to compute the above probability and also I don´t know how to use the fact that the variables are uniform and independent. I would really appreciate if you can help me with this problem",,"['probability', 'probability-theory', 'probability-distributions', 'random-variables', 'uniform-distribution']"
11,Roll five dice. What's the chance of rolling exactly one pair?,Roll five dice. What's the chance of rolling exactly one pair?,,"If I roll five dice, what's the chance that exactly two of the die show the same number? I know that the total number of possible outcomes is $6^5$ = 7776. I calculated the probability that at least 2 of the die will have the same outcome. To do this, I found the probability that no two die will be alike: $\frac{6!}{7776}$ = .0926 Then I subtract that result from 1: 1 - .0926 = .9074. This is the probability that there be AT LEAST one pair. However, I need to find the probability that there will be EXACTLY one pair. The only way I can think of doing this is by subtracting the prob. that there will be at least five pairs, four pairs, etc. from .9074. But is there a quicker way to solve the problem? Thanks, KM","If I roll five dice, what's the chance that exactly two of the die show the same number? I know that the total number of possible outcomes is $6^5$ = 7776. I calculated the probability that at least 2 of the die will have the same outcome. To do this, I found the probability that no two die will be alike: $\frac{6!}{7776}$ = .0926 Then I subtract that result from 1: 1 - .0926 = .9074. This is the probability that there be AT LEAST one pair. However, I need to find the probability that there will be EXACTLY one pair. The only way I can think of doing this is by subtracting the prob. that there will be at least five pairs, four pairs, etc. from .9074. But is there a quicker way to solve the problem? Thanks, KM",,['probability']
12,Probability in a deck of cards to have two jacks in a row,Probability in a deck of cards to have two jacks in a row,,"In a deck of $36$ cards ($9$ cards per color, $4$ colors) what is the probability to have $2$ jacks (or more) that follow each other?","In a deck of $36$ cards ($9$ cards per color, $4$ colors) what is the probability to have $2$ jacks (or more) that follow each other?",,"['probability', 'combinatorics', 'card-games']"
13,Are $|X|$ and $\operatorname{sgn}(X)$ independent?,Are  and  independent?,|X| \operatorname{sgn}(X),"Let $X$ be a real valued random variable. Let $\operatorname{sgn}(x)$ be $1$ when $x>0$, $-1$ when $x<0$ and $0$ when $x=0$. Why  are $|X|$ and $\operatorname{sgn}(X)$ independent, when the density function of $X$ is symmetric with respect to $0$? Are $|X|$ and $\operatorname{sgn}(X)$ independent, when the density function of $X$ is not necessarily symmetric with respect to $0$? Thanks!","Let $X$ be a real valued random variable. Let $\operatorname{sgn}(x)$ be $1$ when $x>0$, $-1$ when $x<0$ and $0$ when $x=0$. Why  are $|X|$ and $\operatorname{sgn}(X)$ independent, when the density function of $X$ is symmetric with respect to $0$? Are $|X|$ and $\operatorname{sgn}(X)$ independent, when the density function of $X$ is not necessarily symmetric with respect to $0$? Thanks!",,['probability']
14,Monty Hall Three-Door Puzzle,Monty Hall Three-Door Puzzle,,"I have a doubt concerning a question about the Monty Hall Three-Door Puzzle, in probability. I found this problem in Rosen's ""Discrete Mathematics and Its Applications"". The Monty Hall Three-Door Puzzle: Suppose you are a game show contestant. You have a chance to win a large prize. You are asked to select one of three doors to open; the large prize is behind one of the three doors and the other two doors are losers. Once you select a door, the game show host, who knows what is behind each door, does the following. First, whether or not you selected the winning door, he opens one of the other two doors that he knows is a losing door (selecting at random if both are losing doors). Then he asks you whether you would like to switch doors. Which strategy should you use? Should you change doors or keep your original selection, or does it not matter? First of all, before I ask my specific doubt: I understand that the best strategy is switching doors, because the probability that the initially chosen door is incorrect is high (2/3); therefore, it is most probably not the winning door. So, after the host opens a door (which he knows is a losing door), the probability that the prize is in the other closed door (and not in the initially chosen one) is higher (2/3). Now, the specific question which I want to ask (found in Rosen's book): Explain what is wrong with the statement that in the Monty Hall Three-Door Puzzle the probability that the prize is behind the first door you select and the probability that the prize is behind the other of the two doors that Monty does not open are both 1/2, because there are two doors left. When the contestant chooses one door (before the host opens a door), the probability that it has the prize is 1/3. But, when the host opens one door (that he knows is a loosing door), the possibilities of where the prize can be are reduced by one, because now the contestant knows that the prize can only be either on the chosen door, or on the closed door. So, it seems reasonable to think that the probability that the prize is in any one of the two remaining doors is 1/2. But this reasoning is apparently wrong. Can any one help me understand why? Thank you in advance.","I have a doubt concerning a question about the Monty Hall Three-Door Puzzle, in probability. I found this problem in Rosen's ""Discrete Mathematics and Its Applications"". The Monty Hall Three-Door Puzzle: Suppose you are a game show contestant. You have a chance to win a large prize. You are asked to select one of three doors to open; the large prize is behind one of the three doors and the other two doors are losers. Once you select a door, the game show host, who knows what is behind each door, does the following. First, whether or not you selected the winning door, he opens one of the other two doors that he knows is a losing door (selecting at random if both are losing doors). Then he asks you whether you would like to switch doors. Which strategy should you use? Should you change doors or keep your original selection, or does it not matter? First of all, before I ask my specific doubt: I understand that the best strategy is switching doors, because the probability that the initially chosen door is incorrect is high (2/3); therefore, it is most probably not the winning door. So, after the host opens a door (which he knows is a losing door), the probability that the prize is in the other closed door (and not in the initially chosen one) is higher (2/3). Now, the specific question which I want to ask (found in Rosen's book): Explain what is wrong with the statement that in the Monty Hall Three-Door Puzzle the probability that the prize is behind the first door you select and the probability that the prize is behind the other of the two doors that Monty does not open are both 1/2, because there are two doors left. When the contestant chooses one door (before the host opens a door), the probability that it has the prize is 1/3. But, when the host opens one door (that he knows is a loosing door), the possibilities of where the prize can be are reduced by one, because now the contestant knows that the prize can only be either on the chosen door, or on the closed door. So, it seems reasonable to think that the probability that the prize is in any one of the two remaining doors is 1/2. But this reasoning is apparently wrong. Can any one help me understand why? Thank you in advance.",,"['probability', 'discrete-mathematics', 'monty-hall']"
15,A bridge hand void in one suit,A bridge hand void in one suit,,"A bridge hand consists of 13 cards from a standard deck of 52 cards. What is the probability of getting a hand that is void in exactly one suit, ie consisting of exactly 3 suits ?","A bridge hand consists of 13 cards from a standard deck of 52 cards. What is the probability of getting a hand that is void in exactly one suit, ie consisting of exactly 3 suits ?",,"['probability', 'combinatorics', 'card-games']"
16,Sum of random variables with $x_{i+1}<x_i$,Sum of random variables with,x_{i+1}<x_i,"Let $x_{i+1}$ be a uniform distributed random variable in $[0,x_i]$, with $x_0=1$. Does the sum converge and what is its expected value? $$\sum_{n=1}^\infty x_n$$ Does there exist a function $f(n)>1$ such that $\lim_{n->\infty} f(n)=1$ and the sum $$\sum_{n=1}^\infty n^{-f(n)}$$ converges?","Let $x_{i+1}$ be a uniform distributed random variable in $[0,x_i]$, with $x_0=1$. Does the sum converge and what is its expected value? $$\sum_{n=1}^\infty x_n$$ Does there exist a function $f(n)>1$ such that $\lim_{n->\infty} f(n)=1$ and the sum $$\sum_{n=1}^\infty n^{-f(n)}$$ converges?",,"['probability', 'sequences-and-series', 'convergence-divergence']"
17,Improper Random Variables,Improper Random Variables,,"What is an Improper Random Variable? I know the definition in terms of the CDF like, F(∞) - F(-∞) <1. Could any one explain it more clearly, specifically I am looking for an example of an improper random variable. Is Cauchy distributed Random Variable improper? (Since it has a long tail)","What is an Improper Random Variable? I know the definition in terms of the CDF like, F(∞) - F(-∞) <1. Could any one explain it more clearly, specifically I am looking for an example of an improper random variable. Is Cauchy distributed Random Variable improper? (Since it has a long tail)",,"['probability', 'probability-theory', 'probability-distributions']"
18,What is the probability that $X+Y$ and $X$ are both greater than $0$? $X$ and $Y$ are both normal standard gaussian.,What is the probability that  and  are both greater than ?  and  are both normal standard gaussian.,X+Y X 0 X Y,"The question gives me: $X,Y\sim N(0,1)$ iid. I also know that $X+Y\sim N(0,2)$ because it is a sum of normal random variables. From my understanding, the sum and $X$ are not indepedent therefore the way to solve would be to rephrase it like this: $$P(X>0\text{ and }X+Y>0) = P(X+Y>0|X>0)*P(X>0).$$ I know that $P(X>0) = 0.5$ and that I can rewrite the first probability as: $P(Y>-x|X=x,x>0) = 1-P(Y<-x)$ . But all this still depends on x, which I suppose should be removed somehow. I thought of integrating over all possible values of $X$ the cdf of the normal, but it seemed too many calculations for a simple question. How can I solve this in a simpler way?","The question gives me: iid. I also know that because it is a sum of normal random variables. From my understanding, the sum and are not indepedent therefore the way to solve would be to rephrase it like this: I know that and that I can rewrite the first probability as: . But all this still depends on x, which I suppose should be removed somehow. I thought of integrating over all possible values of the cdf of the normal, but it seemed too many calculations for a simple question. How can I solve this in a simpler way?","X,Y\sim N(0,1) X+Y\sim N(0,2) X P(X>0\text{ and }X+Y>0) = P(X+Y>0|X>0)*P(X>0). P(X>0) = 0.5 P(Y>-x|X=x,x>0) = 1-P(Y<-x) X","['probability', 'random-variables', 'normal-distribution']"
19,How do I design the most unfair dice for this game?,How do I design the most unfair dice for this game?,,"I was thinking about a simple dice game where the goal is to roll all the face values of a six-sided die consecutively in order (1,2,3,4,5,6). If I'm not mistaken, the probability of doing this with a fair die is $\left(\frac{1}{6}\right)^6$ . And I think I'm correct in saying that there is no way to bias the die to increase my chances of winning. In other words, a fair (uniform) die maximizes the probability of winning this game. So, I added a new rule: if the rolled value is smaller than the ""target"" value, then the player simply rolls again. For example, {1,2,3,4,5, 2 ,6} counts as a win because rolling a 2 when the target is 6 can be ignored because $2 < 6$ . By removing the ignored values from the equation, I think the probability of winning (with a fair die) has increased from $\left(\frac{1}{6}\times\frac{1}{6}\times\dots\times\frac{1}{6}\right)$ to $\left(\frac{1}{6}\times\frac{1}{5}\times\dots\times\frac{1}{1}\right)$ . In other words, it's now $\frac{1}{6!}$ . My question is: how should I (unfairly) weight my die in order to maximize the probability of winning? I feel like I should favor small values because they carry less risk (1 never loses, 2 only loses if the target is exactly 1, etc). However, I'm not sure how to formulate this problem. Also, I feel intimidated by the fact that 1 never loses. If I design a die that always rolls 1, then I can never lose... but I can never win either. So I'm not sure if maybe I need to constrain my question in some way.","I was thinking about a simple dice game where the goal is to roll all the face values of a six-sided die consecutively in order (1,2,3,4,5,6). If I'm not mistaken, the probability of doing this with a fair die is . And I think I'm correct in saying that there is no way to bias the die to increase my chances of winning. In other words, a fair (uniform) die maximizes the probability of winning this game. So, I added a new rule: if the rolled value is smaller than the ""target"" value, then the player simply rolls again. For example, {1,2,3,4,5, 2 ,6} counts as a win because rolling a 2 when the target is 6 can be ignored because . By removing the ignored values from the equation, I think the probability of winning (with a fair die) has increased from to . In other words, it's now . My question is: how should I (unfairly) weight my die in order to maximize the probability of winning? I feel like I should favor small values because they carry less risk (1 never loses, 2 only loses if the target is exactly 1, etc). However, I'm not sure how to formulate this problem. Also, I feel intimidated by the fact that 1 never loses. If I design a die that always rolls 1, then I can never lose... but I can never win either. So I'm not sure if maybe I need to constrain my question in some way.",\left(\frac{1}{6}\right)^6 2 < 6 \left(\frac{1}{6}\times\frac{1}{6}\times\dots\times\frac{1}{6}\right) \left(\frac{1}{6}\times\frac{1}{5}\times\dots\times\frac{1}{1}\right) \frac{1}{6!},"['probability', 'optimization', 'dice']"
20,"During certain sequences of coin flips, why does HHHT have a greater chance than HHHH?","During certain sequences of coin flips, why does HHHT have a greater chance than HHHH?",,"I was reading an article, They were comparing sequences of coin flips. They said: ""HHHT and HHHH are equal only if flipping an unbiased coin exactly four times or infinitely many times. For values in between these two extremes, probabilities will not be the same. Imagine flipping a coin, say, 20 times and checking whether either HHHH or HHHT arise at least once in that series. Given that the wait time for HHHH is longer than that for HHHT, HHHH will also be less likely to occur at all."" Can someone help me understand why the wait time for HHHH is longer than HHHT for values in between 4 and infinite flips? Naturally, I expected that either of these sequences occurring has the same probability. Since Heads and Tails, each have a 50/50 chance with an unbiased coin. What am I missing in my understanding? Source: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5215234/#!po=6.13208","I was reading an article, They were comparing sequences of coin flips. They said: ""HHHT and HHHH are equal only if flipping an unbiased coin exactly four times or infinitely many times. For values in between these two extremes, probabilities will not be the same. Imagine flipping a coin, say, 20 times and checking whether either HHHH or HHHT arise at least once in that series. Given that the wait time for HHHH is longer than that for HHHT, HHHH will also be less likely to occur at all."" Can someone help me understand why the wait time for HHHH is longer than HHHT for values in between 4 and infinite flips? Naturally, I expected that either of these sequences occurring has the same probability. Since Heads and Tails, each have a 50/50 chance with an unbiased coin. What am I missing in my understanding? Source: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5215234/#!po=6.13208",,['probability']
21,What can r.v.s mean?,What can r.v.s mean?,,"I am reading ""Introduction to Probability"" 2nd edition (Blitzstein). He uses the abbreviation r.v for random variable which he explains. However, without introducing what ""r.v.s"" should mean, he uses it like this: So what do you think this means? This is his first use of the abbreviation so I cannot provide any more info.","I am reading ""Introduction to Probability"" 2nd edition (Blitzstein). He uses the abbreviation r.v for random variable which he explains. However, without introducing what ""r.v.s"" should mean, he uses it like this: So what do you think this means? This is his first use of the abbreviation so I cannot provide any more info.",,['probability']
22,Five people are tossing a coin ten times. What is the probability that at least 1 person gets heads 10 times?,Five people are tossing a coin ten times. What is the probability that at least 1 person gets heads 10 times?,,"I know that the probability that one person getting heads all ten times is 1/(2^10) or 1/1024. I also know the calculation when using ""at least one"" is P(At least one) = 1 - P(None). The probability of one person getting no heads is the same: 1/1024. The part that is confusing is the number of people.  Is it P(At least one) = 1 - (1/1024)^5? If there were 100 people tossing a coin, the probability that at least one person gets all ten heads is P(At least one) = 1 - (1/1024)^100? Is this correct?","I know that the probability that one person getting heads all ten times is 1/(2^10) or 1/1024. I also know the calculation when using ""at least one"" is P(At least one) = 1 - P(None). The probability of one person getting no heads is the same: 1/1024. The part that is confusing is the number of people.  Is it P(At least one) = 1 - (1/1024)^5? If there were 100 people tossing a coin, the probability that at least one person gets all ten heads is P(At least one) = 1 - (1/1024)^100? Is this correct?",,['probability']
23,"An urn contains 5 red, 2 blue, and 9 green balls. Six balls are drawn.","An urn contains 5 red, 2 blue, and 9 green balls. Six balls are drawn.",,"Q: An urn contains 5 red, 2 blue, and 9 green balls. Six balls are drawn. Assuming the drawing is WITH replacement, what is the probability of getting 1 red, 2 blue, and 3 green balls? This is an exam question I got wrong. My answer was: $\frac{{5 \choose 1}{2 \choose 2}{9 \choose 3}}{{16 \choose 6}} $ I checked other questions, such as this one , and they approached it the same way. What am I missing?","Q: An urn contains 5 red, 2 blue, and 9 green balls. Six balls are drawn. Assuming the drawing is WITH replacement, what is the probability of getting 1 red, 2 blue, and 3 green balls? This is an exam question I got wrong. My answer was: I checked other questions, such as this one , and they approached it the same way. What am I missing?",\frac{{5 \choose 1}{2 \choose 2}{9 \choose 3}}{{16 \choose 6}} ,"['probability', 'combinatorics']"
24,How to maximize the expected number of corrected guesses?,How to maximize the expected number of corrected guesses?,,"A, B are to play heads or tails for $N$ rounds. They win a round if both guess correctly. A and B are allowed to communicate their strategy before the game starts. A knows the full sequence of $N$ results right after the game starts, before making the first guess. A and B make their guesses simultaneously, and know each others' previous guesses, as well as the correct results of previous rounds. How to design an algorithm that maximizes the expected number of correct guesses in this game? An obvious solution that's better than random guessing would be for A to  spend the first $\lceil{N/2}\rceil$ rounds communicating the results of the last half of the game to B, giving an expected $N/2\times (1/2)^2+N/2=5N/8$ wins. Would there be better solutions?","A, B are to play heads or tails for rounds. They win a round if both guess correctly. A and B are allowed to communicate their strategy before the game starts. A knows the full sequence of results right after the game starts, before making the first guess. A and B make their guesses simultaneously, and know each others' previous guesses, as well as the correct results of previous rounds. How to design an algorithm that maximizes the expected number of correct guesses in this game? An obvious solution that's better than random guessing would be for A to  spend the first rounds communicating the results of the last half of the game to B, giving an expected wins. Would there be better solutions?",N N \lceil{N/2}\rceil N/2\times (1/2)^2+N/2=5N/8,"['probability', 'algorithms', 'information-theory', 'compression']"
25,Comparing the Kullback-Leibler divergence to the total variation distance on discrete probability densities.,Comparing the Kullback-Leibler divergence to the total variation distance on discrete probability densities.,,"I am trying to get a clearer understanding on how the Kullback_Leibler divergence ranks distributions with respect to the total variation in the discrete setting. let $P,Q$ be two probability measures on $(\Omega, \mathscr {F})$, and let $\nu$ be a $\sigma$-finite measure on the same event space such that $P \ll v, Q \ll v$. Define $\frac{dP}{dv}=p$, $\frac{dQ}{dv}=q$. The total variation distance between P and Q is then: $$ V(P,Q) = \frac{1}{2} \int |p-q|d\nu $$ (in the discrete case we replace the integral with a summation). It is very obvious geometrically what the total variation is measuring since it's fundamentally the $L^1$ distance and no ""special treatment"" is given for different values of $p(x)$ or $q(x)$. The Kullback-Leibler divergence is defined as: $$KL(P,Q) = -\int p \log{\frac{q}{p}} d\nu$$ I understand the information theoretic nature of this divergence (and know it is not symmetric or that the triangle inequality does not hold). What I am missing is how actually does this divergence rate distributions against one another. To get my point across I give an example, say I have three probability distributions $P_1,P_2,P_3$ s.t. $P_1( X = 0) = 1/4 , P_1( X = 1) = 1/2, P_1( X = 2) = 1/4 $ blue. $P_2( X = 0) = 1/3 , P_2( X = 1) = 1/3, P_2( X = 2) = 1/3 $ green. $P_3( X = 0) = 1/4 , P_3( X = 1) = 1/3, P_3( X = 2) = 5/12 $ light blue. The total variation distance between $P_1$ and $P_2$ is the same as the one between $P_1$ and $P_3$ this is geometrically intuitive since the sum of distances between the top of the charts in the two cases is the same. I would like to find a similar way to inspect the chart to quickly determine what should be the rankings for the Kullback-Leibler divergence. For example $KL(P_1,P_2) \approx 0,06$ and $KL(P_1,P_3) \approx 0,07$ but what is the explanation behind this ranking. Moreover when a discrete density assigns probability zero to a value the K-L divergence can completely miss the difference in the distributions since the convention is this case is that $x \log \frac{y}{x}|_{x = 0}= 0$. To cut it short I can't find a (geometric) way to compare the K-L divergence to a symmetric distance like the total variation and I am having some doubts on the validity of considering the K-L divergence a good measure of distance between distributions.","I am trying to get a clearer understanding on how the Kullback_Leibler divergence ranks distributions with respect to the total variation in the discrete setting. let $P,Q$ be two probability measures on $(\Omega, \mathscr {F})$, and let $\nu$ be a $\sigma$-finite measure on the same event space such that $P \ll v, Q \ll v$. Define $\frac{dP}{dv}=p$, $\frac{dQ}{dv}=q$. The total variation distance between P and Q is then: $$ V(P,Q) = \frac{1}{2} \int |p-q|d\nu $$ (in the discrete case we replace the integral with a summation). It is very obvious geometrically what the total variation is measuring since it's fundamentally the $L^1$ distance and no ""special treatment"" is given for different values of $p(x)$ or $q(x)$. The Kullback-Leibler divergence is defined as: $$KL(P,Q) = -\int p \log{\frac{q}{p}} d\nu$$ I understand the information theoretic nature of this divergence (and know it is not symmetric or that the triangle inequality does not hold). What I am missing is how actually does this divergence rate distributions against one another. To get my point across I give an example, say I have three probability distributions $P_1,P_2,P_3$ s.t. $P_1( X = 0) = 1/4 , P_1( X = 1) = 1/2, P_1( X = 2) = 1/4 $ blue. $P_2( X = 0) = 1/3 , P_2( X = 1) = 1/3, P_2( X = 2) = 1/3 $ green. $P_3( X = 0) = 1/4 , P_3( X = 1) = 1/3, P_3( X = 2) = 5/12 $ light blue. The total variation distance between $P_1$ and $P_2$ is the same as the one between $P_1$ and $P_3$ this is geometrically intuitive since the sum of distances between the top of the charts in the two cases is the same. I would like to find a similar way to inspect the chart to quickly determine what should be the rankings for the Kullback-Leibler divergence. For example $KL(P_1,P_2) \approx 0,06$ and $KL(P_1,P_3) \approx 0,07$ but what is the explanation behind this ranking. Moreover when a discrete density assigns probability zero to a value the K-L divergence can completely miss the difference in the distributions since the convention is this case is that $x \log \frac{y}{x}|_{x = 0}= 0$. To cut it short I can't find a (geometric) way to compare the K-L divergence to a symmetric distance like the total variation and I am having some doubts on the validity of considering the K-L divergence a good measure of distance between distributions.",,"['real-analysis', 'probability', 'probability-theory', 'statistics']"
26,Probability problem: $4$ kids hitting a balloon,Probability problem:  kids hitting a balloon,4,"Let's say there is a balloon that blows if it gets a hard hit or 2 medium hits. During a party, if a kid  hitsthe balloon, he has $\frac{1}{4}$ probability getting a hard hit on the balloon and $\frac{1}{4}$ probability for a medium hit and $\frac{1}{2}$ probability of missing the hit. If $4$ kids consecutively hit the balloon(a kid can hit only one time), what's the probability of the balloon to blow? All hits are independent. Any hint would be valuable.","Let's say there is a balloon that blows if it gets a hard hit or 2 medium hits. During a party, if a kid  hitsthe balloon, he has probability getting a hard hit on the balloon and probability for a medium hit and probability of missing the hit. If kids consecutively hit the balloon(a kid can hit only one time), what's the probability of the balloon to blow? All hits are independent. Any hint would be valuable.",\frac{1}{4} \frac{1}{4} \frac{1}{2} 4,"['probability', 'independence']"
27,Why should a physicist care about measurability of random variables?,Why should a physicist care about measurability of random variables?,,"I'm working with some physicists at the moment, and I made the remark that random variables are, technically, defined as measurable functions on some ""background"" probability space, hence requiring the choice of two sets and two sigma algebras.   They immediately asked where the term ""measurable"" came from (I gave the brief history about measuring lengths and areas), and then asked if it had anything to do, in general, with whether or not something was ""measurable in a laboratory"" (I said I wasn't sure).  They then proceeded to say that it was nonsensical to consider any ""non-measurable"" random variables because such things are, almost by definition, not ""interesting"" to the physicist. So, how can I explain to my physicist colleagues that we actually do care about measurability?  Is there an example of a physical quantity which would otherwise be interesting but which turns out to be non-measurable (in the mathematical sense), and which might justify my mathematical nitpickiness to them?  I'm OK with examples from ordinary probability or stochastic process theory.","I'm working with some physicists at the moment, and I made the remark that random variables are, technically, defined as measurable functions on some ""background"" probability space, hence requiring the choice of two sets and two sigma algebras.   They immediately asked where the term ""measurable"" came from (I gave the brief history about measuring lengths and areas), and then asked if it had anything to do, in general, with whether or not something was ""measurable in a laboratory"" (I said I wasn't sure).  They then proceeded to say that it was nonsensical to consider any ""non-measurable"" random variables because such things are, almost by definition, not ""interesting"" to the physicist. So, how can I explain to my physicist colleagues that we actually do care about measurability?  Is there an example of a physical quantity which would otherwise be interesting but which turns out to be non-measurable (in the mathematical sense), and which might justify my mathematical nitpickiness to them?  I'm OK with examples from ordinary probability or stochastic process theory.",,"['probability', 'measure-theory']"
28,Determine the distribution function of this density function,Determine the distribution function of this density function,,"Given is the density function $f(x)=\left\{\begin{matrix} \frac{1}{\pi}\frac{1}{1+x^2}\text{ if }x\geq 0\\  \frac{1}{2}e^x \;\;\;\;\text{ else} \end{matrix}\right. \;\;\;\;$ Determine the (cumulative) distribution function from this density   function. I'm not quite sure how this is done correctly but I need to know it because I need this for another thing I wanted calculate :p If I understood correctly, you determine the distribution function by taking the integral of the density function. So we have that $$F(x) = \int_{-\infty}^{x}f(t) dt$$ Now we need to cover all cases: $x < 0$: $$F(x) = \int_{-\infty}^{0}\frac{1}{2}e^t dt = \left[\frac{1}{2}e^t\right]_{-\infty}^{0}=\frac{1}{2}-(0)=\frac{1}{2}$$ $x \geq 0$: $$F(x)=\int_{0}^{\infty}\frac{1}{\pi} \cdot \frac{1}{1+t^2}dt = \left[\frac{1}{\pi} \cdot \arctan(t)\right]_{0}^{\infty}=\left(\frac{1}{\pi} \cdot \frac{\pi}{2}\right)- \left(\frac{1}{\pi} \cdot 0\right)=\frac{1}{2}$$ Is it really correct like that? Because if this is wrong my next calculation will be wrong too! :(","Given is the density function $f(x)=\left\{\begin{matrix} \frac{1}{\pi}\frac{1}{1+x^2}\text{ if }x\geq 0\\  \frac{1}{2}e^x \;\;\;\;\text{ else} \end{matrix}\right. \;\;\;\;$ Determine the (cumulative) distribution function from this density   function. I'm not quite sure how this is done correctly but I need to know it because I need this for another thing I wanted calculate :p If I understood correctly, you determine the distribution function by taking the integral of the density function. So we have that $$F(x) = \int_{-\infty}^{x}f(t) dt$$ Now we need to cover all cases: $x < 0$: $$F(x) = \int_{-\infty}^{0}\frac{1}{2}e^t dt = \left[\frac{1}{2}e^t\right]_{-\infty}^{0}=\frac{1}{2}-(0)=\frac{1}{2}$$ $x \geq 0$: $$F(x)=\int_{0}^{\infty}\frac{1}{\pi} \cdot \frac{1}{1+t^2}dt = \left[\frac{1}{\pi} \cdot \arctan(t)\right]_{0}^{\infty}=\left(\frac{1}{\pi} \cdot \frac{\pi}{2}\right)- \left(\frac{1}{\pi} \cdot 0\right)=\frac{1}{2}$$ Is it really correct like that? Because if this is wrong my next calculation will be wrong too! :(",,"['probability', 'statistics', 'probability-distributions', 'random-variables']"
29,conditional probability on two variables,conditional probability on two variables,,"How can you express p(x1|x2,x3) in terms of p(x2|x1,x3) and p(x1|x3) and p(x2|x3) with the help of the chain rule ? Source: https://www.hackerearth.com/practice/machine-learning/prerequisites-of-machine-learning/bayes-rules-conditional-probability-chain-rule/tutorial/ what I tried:  $p(x1|x2,x3) = \gamma* p(x1,x2,x3) = \gamma*p(x3|x1,x2)*p(x1,x2) = \gamma*\tau*p(x3|x1,x2)*p(x2|x1)*p(x1) $ ... but the result should be: $$p(x1|x2,x3)=p(x1|x3,x2)=p(x2|x1,x3)*p(x1|x3)/p(x2|x3)$$","How can you express p(x1|x2,x3) in terms of p(x2|x1,x3) and p(x1|x3) and p(x2|x3) with the help of the chain rule ? Source: https://www.hackerearth.com/practice/machine-learning/prerequisites-of-machine-learning/bayes-rules-conditional-probability-chain-rule/tutorial/ what I tried:  $p(x1|x2,x3) = \gamma* p(x1,x2,x3) = \gamma*p(x3|x1,x2)*p(x1,x2) = \gamma*\tau*p(x3|x1,x2)*p(x2|x1)*p(x1) $ ... but the result should be: $$p(x1|x2,x3)=p(x1|x3,x2)=p(x2|x1,x3)*p(x1|x3)/p(x2|x3)$$",,['probability']
30,Probability of selecting elements with replacement,Probability of selecting elements with replacement,,"If I'm selecting $N$ elements uniformly at random (with replacement) from $\{1, \dots, N\}$, what is the chance that a given value is selected at least once? What is the name for the distribution for the more general case where I'm selecting $N$ elements from a domain with $M$ elements?","If I'm selecting $N$ elements uniformly at random (with replacement) from $\{1, \dots, N\}$, what is the chance that a given value is selected at least once? What is the name for the distribution for the more general case where I'm selecting $N$ elements from a domain with $M$ elements?",,"['probability', 'combinatorics']"
31,"CDF of max($X$, $Y$) - where is the mistake?","CDF of max(, ) - where is the mistake?",X Y,"$X$ and $Y$ are independent r.v.'s and we know $F_X(x)$ and $F_Y(y)$. Let $Z=max(X,Y)$. Find $F_Z(z)$. Here's my reasoning: $F_Z(z)=P(Z\leq z)=P(max(X,Y)\leq z)$. I claim that we have 2 cases here: 1) $max(X,Y)=X$. If $X<z$, we are guaranteed that $Y<z$, so $F_Z(z)=P(Z\leq z)=P(X<z)=F_X(z)$ 2) $max(X,Y)=Y$. Similarly, $F_Z(z)=P(Z\leq z)=P(Y<z)=F_Y(z)$ Since we're interested in either case #1 or #2, $F_Z(z)=F_X(z)+F_Y(z)-F_X(z)*F_Y(z)$ However, it's wrong and I know it. But I would like to know where the flaw in my reasoning is. I know the answer to this problem, I just want to know at what moment my reasoning fails.","$X$ and $Y$ are independent r.v.'s and we know $F_X(x)$ and $F_Y(y)$. Let $Z=max(X,Y)$. Find $F_Z(z)$. Here's my reasoning: $F_Z(z)=P(Z\leq z)=P(max(X,Y)\leq z)$. I claim that we have 2 cases here: 1) $max(X,Y)=X$. If $X<z$, we are guaranteed that $Y<z$, so $F_Z(z)=P(Z\leq z)=P(X<z)=F_X(z)$ 2) $max(X,Y)=Y$. Similarly, $F_Z(z)=P(Z\leq z)=P(Y<z)=F_Y(z)$ Since we're interested in either case #1 or #2, $F_Z(z)=F_X(z)+F_Y(z)-F_X(z)*F_Y(z)$ However, it's wrong and I know it. But I would like to know where the flaw in my reasoning is. I know the answer to this problem, I just want to know at what moment my reasoning fails.",,"['probability', 'probability-theory']"
32,Expectation of Exit Time of Brownian Motion from Interval,Expectation of Exit Time of Brownian Motion from Interval,,"I am trying to solve the following: Let $W_t$ be a brownian motion and $a,b >0.$ Define $\tau$ to be the exit time of $W_t$ from $[-a,b]$ , that is $$\tau = \inf\{t \ge 0\ :\ W_{t}(\omega) \notin [-a,b]\}.$$ Show that $\tau$ is integrable and compute $\mathbb{E}(\tau)$ . I have seen this stated without proof multiple places that $\mathbb{E}(\tau)=ab.$ What is the logical argument that backs up this statement?  How are we guaranteed $\tau$ is integrable?","I am trying to solve the following: Let be a brownian motion and Define to be the exit time of from , that is Show that is integrable and compute . I have seen this stated without proof multiple places that What is the logical argument that backs up this statement?  How are we guaranteed is integrable?","W_t a,b >0. \tau W_t [-a,b] \tau = \inf\{t \ge 0\ :\ W_{t}(\omega) \notin [-a,b]\}. \tau \mathbb{E}(\tau) \mathbb{E}(\tau)=ab. \tau","['probability', 'probability-theory', 'stochastic-processes', 'stochastic-calculus', 'brownian-motion']"
33,"In a $10$-member family, what is the probability that the birthdays of the members include all seven days of the week?","In a -member family, what is the probability that the birthdays of the members include all seven days of the week?",10,"Is my solution for the following textbook problem correct? In a 10-member family, what is the probability that the birthdays of the members include all seven days of the week? My solution: All possible combinations are equal to $7^{10}$, which is akin to the problem of distributing $10$ different objects into 10 distinct boxes with repetitive objects allowed. Now, we select $7$ objects (i.e., people) ${10 \choose 7}$, put them in the boxes (i.e., days) so that we have at least one birthday on each day. Accounting for  internal permutation, we have ${10 \choose 7}\cdot7!$ Three objects are left. These could be put in the same box or in different boxes. We break down the possibilities: All three in different boxes. We have $7$ choices for the first object, $6$ for the seven and $5$ for the third. In other words,  ${7 \choose 1}\cdot {6 \choose 1}\cdot {5 \choose 1}$. Now, we have three $2$-member boxes each having a $2!$ internal permutation. Hence, we have $$\frac{{7 \choose 1}\cdot {6 \choose 1}\cdot {5 \choose 1}}{2!\cdot2!\cdot2!}$$ Two  in the same box. We choose a pair put them in any of the seven boxes and there's six choices for the remaining object. Again, factoring in repeated cases, we get $$\frac{{3 \choose 2}\cdot {7 \choose 1}\cdot {6 \choose 1}}{3!\cdot2!}$$ All three one the same  day. This is easy: $$ \frac{{7 \choose 1}}{4!}$$ Now, employing the rule of sum (since the above cases are mutually exclusive), we compute the probability $$ \frac {{10 \choose 7} \cdot 7! \cdot  [\frac{{7 \choose 1}\cdot {6 \choose 1}\cdot {5 \choose 1}}{2!\cdot2!\cdot2!} + \frac{{3 \choose 2}\cdot {7 \choose 1}\cdot {6 \choose 1}}{3!\cdot2!} +\frac{{7 \choose 1}}{4!}]} {7^{10}} $$    which is almost $0.08$. Also, can you think of a better, more systematic (or perhaps general) solution for the above problem? I suspect there's one and that this could be done through computing the complement cases. I have been trying to no avail. I can't eliminate repetitive distributions. Update : Thanks for the replies gentlemen. All were very helpful. Case closed.","Is my solution for the following textbook problem correct? In a 10-member family, what is the probability that the birthdays of the members include all seven days of the week? My solution: All possible combinations are equal to $7^{10}$, which is akin to the problem of distributing $10$ different objects into 10 distinct boxes with repetitive objects allowed. Now, we select $7$ objects (i.e., people) ${10 \choose 7}$, put them in the boxes (i.e., days) so that we have at least one birthday on each day. Accounting for  internal permutation, we have ${10 \choose 7}\cdot7!$ Three objects are left. These could be put in the same box or in different boxes. We break down the possibilities: All three in different boxes. We have $7$ choices for the first object, $6$ for the seven and $5$ for the third. In other words,  ${7 \choose 1}\cdot {6 \choose 1}\cdot {5 \choose 1}$. Now, we have three $2$-member boxes each having a $2!$ internal permutation. Hence, we have $$\frac{{7 \choose 1}\cdot {6 \choose 1}\cdot {5 \choose 1}}{2!\cdot2!\cdot2!}$$ Two  in the same box. We choose a pair put them in any of the seven boxes and there's six choices for the remaining object. Again, factoring in repeated cases, we get $$\frac{{3 \choose 2}\cdot {7 \choose 1}\cdot {6 \choose 1}}{3!\cdot2!}$$ All three one the same  day. This is easy: $$ \frac{{7 \choose 1}}{4!}$$ Now, employing the rule of sum (since the above cases are mutually exclusive), we compute the probability $$ \frac {{10 \choose 7} \cdot 7! \cdot  [\frac{{7 \choose 1}\cdot {6 \choose 1}\cdot {5 \choose 1}}{2!\cdot2!\cdot2!} + \frac{{3 \choose 2}\cdot {7 \choose 1}\cdot {6 \choose 1}}{3!\cdot2!} +\frac{{7 \choose 1}}{4!}]} {7^{10}} $$    which is almost $0.08$. Also, can you think of a better, more systematic (or perhaps general) solution for the above problem? I suspect there's one and that this could be done through computing the complement cases. I have been trying to no avail. I can't eliminate repetitive distributions. Update : Thanks for the replies gentlemen. All were very helpful. Case closed.",,"['probability', 'combinatorics', 'discrete-mathematics', 'recreational-mathematics']"
34,An accountancy of the natural numbers,An accountancy of the natural numbers,,"I guess this formula is known since I believe it's true  $$\sum_{k=2}^\infty\frac{(-1)^{1+\Omega(k)}}{k}=1$$ where $\Omega(k)$ is the number of prime factors of $k$ (not necessary different primes). I can't find it and want a formal proof or a reference. My intuition about this sum is something like this: The probability of a number to have the prime factor $p$ is   $\frac{1}{p}$ and to have the prime factors $p$ or $q$ is   $\frac{1}{p}+\frac{1}{q}-\frac{1}{pq}$ etc. The probability of a number $>1$ to have a prime factor is $1$. Is this sum really not known? Haven't anything been published about it before? I finally realize that the series $$\sum_{k=1}^\infty\frac{(-1)^{\Omega(k)}}{k}=0$$ has been known for a long time, and that solves my confusion.","I guess this formula is known since I believe it's true  $$\sum_{k=2}^\infty\frac{(-1)^{1+\Omega(k)}}{k}=1$$ where $\Omega(k)$ is the number of prime factors of $k$ (not necessary different primes). I can't find it and want a formal proof or a reference. My intuition about this sum is something like this: The probability of a number to have the prime factor $p$ is   $\frac{1}{p}$ and to have the prime factors $p$ or $q$ is   $\frac{1}{p}+\frac{1}{q}-\frac{1}{pq}$ etc. The probability of a number $>1$ to have a prime factor is $1$. Is this sum really not known? Haven't anything been published about it before? I finally realize that the series $$\sum_{k=1}^\infty\frac{(-1)^{\Omega(k)}}{k}=0$$ has been known for a long time, and that solves my confusion.",,"['probability', 'sequences-and-series', 'reference-request', 'math-history', 'conjectures']"
35,$\mathbb{P}(B) = 1 \implies \mathbb{P}(A \mid B) = \mathbb{P}(A)$,,\mathbb{P}(B) = 1 \implies \mathbb{P}(A \mid B) = \mathbb{P}(A),"Suppose I have two events $A$, $B$ from the same sample space with $\mathbb{P}(B) = 1$ and $\mathbb{P}(A) > 0$. How can I show that $$\mathbb{P}(B) = 1 \implies \mathbb{P}(A \mid B) = \mathbb{P}(A)\text{?}$$ The definition of conditional probability doesn't help me, as it isn't clear what can be done with $\mathbb{P}(A \cap B)$. If I use Bayes' Theorem, I get $\mathbb{P}(B \mid A)\mathbb{P}(A)$, so the only way this would work is that $\mathbb{P}(B \mid A) = 1$. This makes intuitive sense, but I can't prove that $\mathbb{P}(B \mid A) = 1$. This should be a trivial question, but I'm not seeing how to do it. HINTS , not full solutions, are appreciated.","Suppose I have two events $A$, $B$ from the same sample space with $\mathbb{P}(B) = 1$ and $\mathbb{P}(A) > 0$. How can I show that $$\mathbb{P}(B) = 1 \implies \mathbb{P}(A \mid B) = \mathbb{P}(A)\text{?}$$ The definition of conditional probability doesn't help me, as it isn't clear what can be done with $\mathbb{P}(A \cap B)$. If I use Bayes' Theorem, I get $\mathbb{P}(B \mid A)\mathbb{P}(A)$, so the only way this would work is that $\mathbb{P}(B \mid A) = 1$. This makes intuitive sense, but I can't prove that $\mathbb{P}(B \mid A) = 1$. This should be a trivial question, but I'm not seeing how to do it. HINTS , not full solutions, are appreciated.",,['probability']
36,"If $4$ people are chosen out of $6$ married couples, what is the chance that exactly one married couple is among the $4$ people?","If  people are chosen out of  married couples, what is the chance that exactly one married couple is among the  people?",4 6 4,"$6$ married couples are standing in a room. If $4$ people are chosen at random, what is the chance that exactly one married couple is among the $4$ people? Total number of ways of selecting $4$ people out of $12$ people is $\binom{12}{4}=\frac{12!}{8!4!}=33\times 15$ I am having difficulty in counting the favourable cases.","$6$ married couples are standing in a room. If $4$ people are chosen at random, what is the chance that exactly one married couple is among the $4$ people? Total number of ways of selecting $4$ people out of $12$ people is $\binom{12}{4}=\frac{12!}{8!4!}=33\times 15$ I am having difficulty in counting the favourable cases.",,"['probability', 'combinations']"
37,Solve the integral $\frac 1 {\sqrt {2 \pi t}}\int_{-\infty}^{\infty} x^2 e^{-\frac {x^2} {2t}}dx$,Solve the integral,\frac 1 {\sqrt {2 \pi t}}\int_{-\infty}^{\infty} x^2 e^{-\frac {x^2} {2t}}dx,"To find the Variance of a Wiener Process, $Var[W(t)]$, I have to compute the integral $$ Var[W(t)]=\dots=\frac 1 {\sqrt {2 \pi t}}\int_{-\infty}^{\infty} x^2 e^{-\frac {x^2} {2t}}dx=\dots=t. $$ I've tried integration by parts to solve the integral but end up with $$ \dots=\frac 1 {\sqrt {2 \pi t}} \left(0 - \int_{-\infty}^{\infty} -\frac {x} {t} \cdot e^{-\frac {x^2} {2t}}\cdot \frac {x^3} 3 dx\right), $$ which is even worse and probably wrong. Can anyone please help me compute the first integral and show how it becomes equal to $t$? (I know that the Variance for a Wiener Process (Standard Brownian motion)is defined as $t$ but want to prove it with the integral above.)","To find the Variance of a Wiener Process, $Var[W(t)]$, I have to compute the integral $$ Var[W(t)]=\dots=\frac 1 {\sqrt {2 \pi t}}\int_{-\infty}^{\infty} x^2 e^{-\frac {x^2} {2t}}dx=\dots=t. $$ I've tried integration by parts to solve the integral but end up with $$ \dots=\frac 1 {\sqrt {2 \pi t}} \left(0 - \int_{-\infty}^{\infty} -\frac {x} {t} \cdot e^{-\frac {x^2} {2t}}\cdot \frac {x^3} 3 dx\right), $$ which is even worse and probably wrong. Can anyone please help me compute the first integral and show how it becomes equal to $t$? (I know that the Variance for a Wiener Process (Standard Brownian motion)is defined as $t$ but want to prove it with the integral above.)",,"['probability', 'integration', 'brownian-motion']"
38,How to get $P(X > x)$ where $K$ is a geometric random variable with parameter $p$?,How to get  where  is a geometric random variable with parameter ?,P(X > x) K p,"I'm trying to understand why $P(K > k)$ where $K$ is a geometric random variable with parameter $p$ and PMF equal to $p(1 − p)^{k}$ for all positive $k$ . It seems to me the answer should in fact be a summation of $(1 − p)^{k}$ over all $K > k$ , but apparently it is not. The reasoning behind that is completely escaping me and I can't find anything on the web explaining it.","I'm trying to understand why where is a geometric random variable with parameter and PMF equal to for all positive . It seems to me the answer should in fact be a summation of over all , but apparently it is not. The reasoning behind that is completely escaping me and I can't find anything on the web explaining it.",P(K > k) K p p(1 − p)^{k} k (1 − p)^{k} K > k,"['probability', 'random-variables']"
39,Maximum a Posteriori (MAP) Estimator of Exponential Random Variable with Uniform Prior,Maximum a Posteriori (MAP) Estimator of Exponential Random Variable with Uniform Prior,,"What would be the Maximum a Posteriori (MAP) estimator for $ \lambda $ for IID $ \left\{ {x}_{i} \right\}_{i = 1}^{N} $ where $ {x}_{i} \sim \exp \left( \lambda \right), \; \lambda \sim U \left[ {u}_{0}, {u}_{1} \right] $? One could assume that $u_0 > 0 $. The Exponential Distribution is given by: $$ f(x; \lambda) = \begin{cases} \lambda {e}^{-\lambda x} & x \ge 0, \\ 0 & x < 0. \end{cases} $$","What would be the Maximum a Posteriori (MAP) estimator for $ \lambda $ for IID $ \left\{ {x}_{i} \right\}_{i = 1}^{N} $ where $ {x}_{i} \sim \exp \left( \lambda \right), \; \lambda \sim U \left[ {u}_{0}, {u}_{1} \right] $? One could assume that $u_0 > 0 $. The Exponential Distribution is given by: $$ f(x; \lambda) = \begin{cases} \lambda {e}^{-\lambda x} & x \ge 0, \\ 0 & x < 0. \end{cases} $$",,"['probability', 'probability-theory', 'probability-distributions', 'estimation', 'parameter-estimation']"
40,Why are the probability of rolling the same number twice and the probability of rolling pairs different?,Why are the probability of rolling the same number twice and the probability of rolling pairs different?,,"Two scenarios: 1. Using one die, roll a 6 twice. $\frac16\times\frac16=\frac1{36}$ Rolling two dice roll the same number (a pair). $\frac6{36}=\frac16$ Why are these two probabilities different? Because the events are independent, isn't rolling a pair the same as rolling a die twice? In a sense, rolling two dice at once is the same as rolling 1 die twice at the same time? How does this ""timing"" issue affect the probability?","Two scenarios: 1. Using one die, roll a 6 twice. $\frac16\times\frac16=\frac1{36}$ Rolling two dice roll the same number (a pair). $\frac6{36}=\frac16$ Why are these two probabilities different? Because the events are independent, isn't rolling a pair the same as rolling a die twice? In a sense, rolling two dice at once is the same as rolling 1 die twice at the same time? How does this ""timing"" issue affect the probability?",,"['probability', 'dice']"
41,Probability $A$ is before $B$ when the 26 letters are arranged randomly,Probability  is before  when the 26 letters are arranged randomly,A B,"The 26 letters A, B, ... , Z are arrange in a random order. [Equivalently, the letters are selected sequentially at random without replacement.] a) What is the probability that A comes before B in the random order? b) What is the probability that A comes before Z in the random order? c) What is the probability that A comes just before B in the random order? Any help would be much appreciated. I was thinking that for part c the answer would be $1/26$ because we have $25!$ ways of having A right before B and $26!$ total arrangements. Not sure how to proceed with a and b, however. Edit: Thank you. For parts (a) and (b) is there a more formal way of getting $1/2$ ? Such as the formula for the total number of ways we can have $A$ before $B$ over the total number of arrangements? Would it be 25 choose 1 ... 2 choose 1 over $26!$ since we can have a in the first spot and B in any spot after it? Then we can have a in the 2nd spot and B in any spot after it. Also, for part (c), doesn't $A$ have to come immediately before $B$ , so wouldn't the probability be $1/26$ ?","The 26 letters A, B, ... , Z are arrange in a random order. [Equivalently, the letters are selected sequentially at random without replacement.] a) What is the probability that A comes before B in the random order? b) What is the probability that A comes before Z in the random order? c) What is the probability that A comes just before B in the random order? Any help would be much appreciated. I was thinking that for part c the answer would be because we have ways of having A right before B and total arrangements. Not sure how to proceed with a and b, however. Edit: Thank you. For parts (a) and (b) is there a more formal way of getting ? Such as the formula for the total number of ways we can have before over the total number of arrangements? Would it be 25 choose 1 ... 2 choose 1 over since we can have a in the first spot and B in any spot after it? Then we can have a in the 2nd spot and B in any spot after it. Also, for part (c), doesn't have to come immediately before , so wouldn't the probability be ?",1/26 25! 26! 1/2 A B 26! A B 1/26,"['probability', 'combinatorics']"
42,Coin flips and prediction - Is this a paradox?,Coin flips and prediction - Is this a paradox?,,"Let's say a coin is given to you which is shown to have two sides (head and tail). I threw the coin 10 times and I got the sequence HHHHHHHHHH (all heads). Now, I am about to throw it the eleventh time. You lose a large bet if you predict the next toss wrongly. How will you predict the outcome of next toss? Here are some of my answers: It is rare to see 10 heads together unless the coin is biased. Hence, the probability that the coin is biased (the hyperparameter, theta) is very high. So, I should bet that the next outcome will also be a head. 10 flips are too small a number to conclude that the coin is biased. Getting 11 heads is extremely rare and hence I must bet on a tail for eleventh toss. Coin flips are IID and hence it does not depend on the previous tosses. You can bet on anything and your chances of winning is the same. Am extremely confused on which of these is a good answer if any of them is a good answer at all. What do you think?","Let's say a coin is given to you which is shown to have two sides (head and tail). I threw the coin 10 times and I got the sequence HHHHHHHHHH (all heads). Now, I am about to throw it the eleventh time. You lose a large bet if you predict the next toss wrongly. How will you predict the outcome of next toss? Here are some of my answers: It is rare to see 10 heads together unless the coin is biased. Hence, the probability that the coin is biased (the hyperparameter, theta) is very high. So, I should bet that the next outcome will also be a head. 10 flips are too small a number to conclude that the coin is biased. Getting 11 heads is extremely rare and hence I must bet on a tail for eleventh toss. Coin flips are IID and hence it does not depend on the previous tosses. You can bet on anything and your chances of winning is the same. Am extremely confused on which of these is a good answer if any of them is a good answer at all. What do you think?",,"['probability', 'independence', 'paradoxes']"
43,Are subsets of two independent sets independent?,Are subsets of two independent sets independent?,,"If sets $A$ and $B$ are independent ($P(A \cap B)=P(A)P(B)$), and $a$ is subset of $A$ while $b$ is subset of $B$, then are $a$ and $b$ independent as well?","If sets $A$ and $B$ are independent ($P(A \cap B)=P(A)P(B)$), and $a$ is subset of $A$ while $b$ is subset of $B$, then are $a$ and $b$ independent as well?",,['probability']
44,Sam Harris' theory of probability on the Second Coming of Christ [closed],Sam Harris' theory of probability on the Second Coming of Christ [closed],,"Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 9 years ago . Improve this question Sam Harris (a famous atheist) argues in an interview with Cenk Uygur that the probability of Jesus Christ coming back to Jackson County, Missouri, USA is less likely than the probability of Jesus Christ coming back anywhere on Earth. He says that it's a ""mathematically true point. This is just probability theory...you're going to hear from a bunch of mathematicians who are going to insist that you grant that."" However, Cenk Uygur (also an atheist) argues that since Jesus Christ is not coming back at all (as the whole thing is ""totally untrue""), then speaking about probabilities makes as much sense as dividing by zero. Can mathematics (probability theory) be applied to a future event that might be impossible, specifically the Second Coming of Jesus Christ? If so, under what conditions/assumptions, would Sam Harris be correct?","Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 9 years ago . Improve this question Sam Harris (a famous atheist) argues in an interview with Cenk Uygur that the probability of Jesus Christ coming back to Jackson County, Missouri, USA is less likely than the probability of Jesus Christ coming back anywhere on Earth. He says that it's a ""mathematically true point. This is just probability theory...you're going to hear from a bunch of mathematicians who are going to insist that you grant that."" However, Cenk Uygur (also an atheist) argues that since Jesus Christ is not coming back at all (as the whole thing is ""totally untrue""), then speaking about probabilities makes as much sense as dividing by zero. Can mathematics (probability theory) be applied to a future event that might be impossible, specifically the Second Coming of Jesus Christ? If so, under what conditions/assumptions, would Sam Harris be correct?",,['probability']
45,Limiting distribution.,Limiting distribution.,,"Let $Y_n \sim \chi^2(n) $. Find the limiting distribution, $(Y_n-n)/ \sqrt{2n}$ as $n\rightarrow \infty $, using moment generating functions. I don't know how to properly calculate the moment generating function. Or to calculate the limit. I'll be grateful for the help and advices.","Let $Y_n \sim \chi^2(n) $. Find the limiting distribution, $(Y_n-n)/ \sqrt{2n}$ as $n\rightarrow \infty $, using moment generating functions. I don't know how to properly calculate the moment generating function. Or to calculate the limit. I'll be grateful for the help and advices.",,"['probability', 'statistics']"
46,Every countably generated sigma algebra is generated by a random variable,Every countably generated sigma algebra is generated by a random variable,,"Suppose I have a sigma algebra which is countably generated. I want to find a random variable such that it is generated by that random variable. If the countable class is just a single set then my random variable is indicator function. But, how to do in this case ? If we sum up all the indicators to define our random variable then the sum may diverge. How to make sure it converge ?","Suppose I have a sigma algebra which is countably generated. I want to find a random variable such that it is generated by that random variable. If the countable class is just a single set then my random variable is indicator function. But, how to do in this case ? If we sum up all the indicators to define our random variable then the sum may diverge. How to make sure it converge ?",,"['real-analysis', 'probability', 'measure-theory', 'probability-theory']"
47,Probability problem ( shuffling cards ),Probability problem ( shuffling cards ),,"Suppose we shuffle a deck of 10 cards, each bearing a distinct number from 1 to 10, to mix the cards thoroughly. We then remove three cards, one at a time, from the deck. What is the probability that we select the three cards in sorted (increasing) order?","Suppose we shuffle a deck of 10 cards, each bearing a distinct number from 1 to 10, to mix the cards thoroughly. We then remove three cards, one at a time, from the deck. What is the probability that we select the three cards in sorted (increasing) order?",,['probability']
48,Relationship between convexity and superadditivity?,Relationship between convexity and superadditivity?,,"This question is a little vague, so let me give some motivation. I was trying to prove the generalized Holder's inequality for probability measures, $$\mathbb{E}(X_1 \dots X_n) \leq \prod_{i=1}^n \|X_i\|_{p_i},$$ where $\sum_{i=1}^n (1/p_i) = 1$, the $X_i$ are random variables, and $$\|X_i\|_{p_i} = \left(\int_\Omega |f(x)|^{p_i}dx\right)^{1/p_i}.$$ To prove this you can use the arithmetic-geometric mean, $$\sum_{i=1}^n x_i^{p_i} \leq \sum_{i=1}^n p_i x_i,$$ where $x_i > 0$ and $\sum p_i = 1$.  In getting through all this I started investigating Jensen's inequality for convex functions. I've known convexity was important but I've never grappled with it from an analytic perspective, so I don't really know the tricks / typical arguments. I tried to prove the AM-GM mean by generalising the proof of Holder for $(1/p) + (1/q) = 1$, which relies on Young's inequality, $$ab \leq \frac{1}{p}a^p + \frac{1}{q}b^q,$$ whence Holder's follows from a clever choice of $a, b$. However I don't see any ways to extend the definition of convexity, which is that for any $\lambda \in [0,1]$, we require $$f(\lambda x + (1-\lambda) y) \leq \lambda f(x) + (1-\lambda) f(y),$$ to something which would involve multiple $\lambda$s which sum to 1.  Another definition of convexity is existence of a vector $V \in \mathbb{R}^n$ such that $$f(y) \geq f(x) + V\cdot(y-x)$$ for all $y \in \mathbb{R}^n$ or $$f(x) = \sup_{z \in \mathbb{R}} L_z(x)$$ where the $L_z$ are the linear support planes for the convex function $f$. I understand all these definitions separately and more or less together, but it feels like I should be able to say something like arithmetic-geometric mean (which uses Jensen's inequality) straight from what of these inequalities. I was thinking maybe the exponential could satisfy something like this: $$f(x+y) \geq f(x) + f(y),$$ so by induction and with $f(x) = e^x$, $$f(a+b+\dots+z) \leq f(a)+f(b)+ \dots + f(z).$$ This is ''superadditivity' and kind of says $f$ keeps growing faster and faster. One soon discovers this property is false, even for the exponential ( $x = 0$). Does it hold for $x >1$? What is the relationship  between $$f(x+y) \geq f(x) + f(y)$$ and  $$f\left(\frac{1}{2}x + \frac{1}{2}y\right) \leq \frac{1}{2}f(x) + \frac{1}{2}f(y)?$$ I'd also like to understand Jensen's inequality a little better. I've heard it kind of generalises the triangle inequality, since $\int |f| \geq |\int f|$ is like $\sum |x_i| \geq |\sum x_i|$. This makes sense, and I have some examples of this working (insightful ones are appreciated), but I don't really see what it's saying. Thanks for any help. @Eric Convex function with $f(0) = 0$ is superadditive on $[0,\infty)$, i.e.  $$f(x+y) \geq f(x)+f(y), \quad x, y \geq 0.$$ First, note that if $f(0) = 0$ and $f$ is convex, i.e. $f(tx + (1-t)y) \leq t f(x) + (1-t)f(y)$, then: \begin{align*} f(tx) &= f(tx + (1-t)\cdot 0) \\ &\leq tf(x) + (1-t)f(0)\\ &= tf(x). \end{align*} Hence, for $a,b \geq 0$, $\frac{a}{a+b}\in [0,1]$ and likewise for $\frac{b}{a+b}$. Thus,  \begin{align*} f(a) + f(b) &= f((a+b)\frac{a}{a+b}) + f((a+b)\frac{b}{a+b}) \\ &\leq \frac{a}{a+b}f(a+b) + \frac{b}{a+b}f(a+b) \\ &= f(a+b). \end{align*} Looks right to me?","This question is a little vague, so let me give some motivation. I was trying to prove the generalized Holder's inequality for probability measures, $$\mathbb{E}(X_1 \dots X_n) \leq \prod_{i=1}^n \|X_i\|_{p_i},$$ where $\sum_{i=1}^n (1/p_i) = 1$, the $X_i$ are random variables, and $$\|X_i\|_{p_i} = \left(\int_\Omega |f(x)|^{p_i}dx\right)^{1/p_i}.$$ To prove this you can use the arithmetic-geometric mean, $$\sum_{i=1}^n x_i^{p_i} \leq \sum_{i=1}^n p_i x_i,$$ where $x_i > 0$ and $\sum p_i = 1$.  In getting through all this I started investigating Jensen's inequality for convex functions. I've known convexity was important but I've never grappled with it from an analytic perspective, so I don't really know the tricks / typical arguments. I tried to prove the AM-GM mean by generalising the proof of Holder for $(1/p) + (1/q) = 1$, which relies on Young's inequality, $$ab \leq \frac{1}{p}a^p + \frac{1}{q}b^q,$$ whence Holder's follows from a clever choice of $a, b$. However I don't see any ways to extend the definition of convexity, which is that for any $\lambda \in [0,1]$, we require $$f(\lambda x + (1-\lambda) y) \leq \lambda f(x) + (1-\lambda) f(y),$$ to something which would involve multiple $\lambda$s which sum to 1.  Another definition of convexity is existence of a vector $V \in \mathbb{R}^n$ such that $$f(y) \geq f(x) + V\cdot(y-x)$$ for all $y \in \mathbb{R}^n$ or $$f(x) = \sup_{z \in \mathbb{R}} L_z(x)$$ where the $L_z$ are the linear support planes for the convex function $f$. I understand all these definitions separately and more or less together, but it feels like I should be able to say something like arithmetic-geometric mean (which uses Jensen's inequality) straight from what of these inequalities. I was thinking maybe the exponential could satisfy something like this: $$f(x+y) \geq f(x) + f(y),$$ so by induction and with $f(x) = e^x$, $$f(a+b+\dots+z) \leq f(a)+f(b)+ \dots + f(z).$$ This is ''superadditivity' and kind of says $f$ keeps growing faster and faster. One soon discovers this property is false, even for the exponential ( $x = 0$). Does it hold for $x >1$? What is the relationship  between $$f(x+y) \geq f(x) + f(y)$$ and  $$f\left(\frac{1}{2}x + \frac{1}{2}y\right) \leq \frac{1}{2}f(x) + \frac{1}{2}f(y)?$$ I'd also like to understand Jensen's inequality a little better. I've heard it kind of generalises the triangle inequality, since $\int |f| \geq |\int f|$ is like $\sum |x_i| \geq |\sum x_i|$. This makes sense, and I have some examples of this working (insightful ones are appreciated), but I don't really see what it's saying. Thanks for any help. @Eric Convex function with $f(0) = 0$ is superadditive on $[0,\infty)$, i.e.  $$f(x+y) \geq f(x)+f(y), \quad x, y \geq 0.$$ First, note that if $f(0) = 0$ and $f$ is convex, i.e. $f(tx + (1-t)y) \leq t f(x) + (1-t)f(y)$, then: \begin{align*} f(tx) &= f(tx + (1-t)\cdot 0) \\ &\leq tf(x) + (1-t)f(0)\\ &= tf(x). \end{align*} Hence, for $a,b \geq 0$, $\frac{a}{a+b}\in [0,1]$ and likewise for $\frac{b}{a+b}$. Thus,  \begin{align*} f(a) + f(b) &= f((a+b)\frac{a}{a+b}) + f((a+b)\frac{b}{a+b}) \\ &\leq \frac{a}{a+b}f(a+b) + \frac{b}{a+b}f(a+b) \\ &= f(a+b). \end{align*} Looks right to me?",,"['real-analysis', 'probability', 'convex-analysis']"
49,Find the median of the exponential random variable with parameter λ,Find the median of the exponential random variable with parameter λ,,The median of a random variable X is a number µ that satisﬁes Find the median of the exponential random variable with parameter λ.,The median of a random variable X is a number µ that satisﬁes Find the median of the exponential random variable with parameter λ.,,"['probability', 'statistics', 'random-variables', 'median']"
50,Conditional probabilities involving the exponential distribution,Conditional probabilities involving the exponential distribution,,"The number of years the laptop functions is exponentially distributed with mean = 5 years. If a customer purchased an old laptop which was used for last two years, what is the probability that it will function for at least 3 years?","The number of years the laptop functions is exponentially distributed with mean = 5 years. If a customer purchased an old laptop which was used for last two years, what is the probability that it will function for at least 3 years?",,"['probability', 'probability-distributions']"
51,The average surface area of a projection of a randomly rotated planar rectangular shape on a two-dimensional surface,The average surface area of a projection of a randomly rotated planar rectangular shape on a two-dimensional surface,,"I have a planar rectangular shape, of dimensions $N$ by $M$, positioned in 3-space above a two-dimensional surface.  Provided a large number of random 3-space rotational orientations of the shape, what is the average surface area $A$ of a projection of the shape on the two-dimensional surface?","I have a planar rectangular shape, of dimensions $N$ by $M$, positioned in 3-space above a two-dimensional surface.  Provided a large number of random 3-space rotational orientations of the shape, what is the average surface area $A$ of a projection of the shape on the two-dimensional surface?",,"['probability', 'geometry']"
52,Expected value and life,Expected value and life,,"Let $e_{x} = \int_{0}^{\infty} p_{x}(t) \ dt$ where $p_{x}(t)$ is the probability that a person aged $x$ will survive at least $t$ more years. Why is $e_{x} \leq e_{x+1}+1$? We know that $e_{x} \geq e_{x+1}$ since the expected future lifetime of a younger person is greater than that of an older person. So maybe we can show that $e_{x}-e_{x+1} \leq 1$ or $$\int_{0}^{\infty} p_{x}(t) - p_{x+1}(t) \ dt \leq 1$$ Edit. We know that for a discrete random variable, $$\mathbb{E}(Y|X) = \int_{\Omega} Y(\omega) \mathbb{P}(dw|X=x)$$ $$= \frac{\int_{X=x} Y(\omega)\mathbb{P}(dw)}{\mathbb{P}(X=x)}$$ $$= \frac{\mathbb{E}(Y \mathbb{1}_{(X=x)})}{\mathbb{P}(X=x)}$$ What does $w$ above represent?","Let $e_{x} = \int_{0}^{\infty} p_{x}(t) \ dt$ where $p_{x}(t)$ is the probability that a person aged $x$ will survive at least $t$ more years. Why is $e_{x} \leq e_{x+1}+1$? We know that $e_{x} \geq e_{x+1}$ since the expected future lifetime of a younger person is greater than that of an older person. So maybe we can show that $e_{x}-e_{x+1} \leq 1$ or $$\int_{0}^{\infty} p_{x}(t) - p_{x+1}(t) \ dt \leq 1$$ Edit. We know that for a discrete random variable, $$\mathbb{E}(Y|X) = \int_{\Omega} Y(\omega) \mathbb{P}(dw|X=x)$$ $$= \frac{\int_{X=x} Y(\omega)\mathbb{P}(dw)}{\mathbb{P}(X=x)}$$ $$= \frac{\mathbb{E}(Y \mathbb{1}_{(X=x)})}{\mathbb{P}(X=x)}$$ What does $w$ above represent?",,"['probability', 'actuarial-science']"
53,Conditional probability,Conditional probability,,"A girl goes to school by bus every day. If it doesn't rain, probability that she will be late for bus is 1/5. If it rains probability that she will be late is 2/3. Probability that it is raining is 1/4. Girl forgot to pick up a bus. Define the probability that it was raining. In this task I have done following using my logic, but I am not sure is it correct: P(late for bus and rained that day) = P(rains)/P(late for school and is raining )= 1/4/2/3 = 3/8. I am not sure if it is correct, so I plead for your help.","A girl goes to school by bus every day. If it doesn't rain, probability that she will be late for bus is 1/5. If it rains probability that she will be late is 2/3. Probability that it is raining is 1/4. Girl forgot to pick up a bus. Define the probability that it was raining. In this task I have done following using my logic, but I am not sure is it correct: P(late for bus and rained that day) = P(rains)/P(late for school and is raining )= 1/4/2/3 = 3/8. I am not sure if it is correct, so I plead for your help.",,"['probability', 'statistics']"
54,Conditional expectation of book Shiryaev page 233 [duplicate],Conditional expectation of book Shiryaev page 233 [duplicate],,"This question already has answers here : Closed 12 years ago . Possible Duplicate: Help with conditional expectation question I have problem with exercise, I didn't solve. Let $X$ and $Y$ be i.i.d. random variables with $E(X)$ defined. Show that $$E(X|X+Y)=E(Y|X+Y)= \frac{X+Y}{2}$$ (a.s.) Thanks very much for your help.","This question already has answers here : Closed 12 years ago . Possible Duplicate: Help with conditional expectation question I have problem with exercise, I didn't solve. Let $X$ and $Y$ be i.i.d. random variables with $E(X)$ defined. Show that $$E(X|X+Y)=E(Y|X+Y)= \frac{X+Y}{2}$$ (a.s.) Thanks very much for your help.",,"['probability', 'probability-theory']"
55,How do we justify certain steps in the solution to gambler's ruin?,How do we justify certain steps in the solution to gambler's ruin?,,"The problem of gambler's ruin asks the following: suppose a player begins with $k$ units of money, $0<k<N$. Each turn he flips a coin and either gains a unit of money with probability $p$ or loses a unit of money with probability $1-p$. The game ends when he reaches $N$ and wins or $0$ in which case he loses the game. What is the probability of losing? The usual solution, which you can find for example on http://en.wikipedia.org/wiki/Gambler%27s_ruin or in Grimmett & Stirzaker - Probability and Random processes, page 17, proceeds by constructing a linear difference equation using the fact (using the notation from wikipedia) that $P(R_n|H)=P(R_{n+1})$ where $R_n$ is the event ""that the player is ruined having started with $n$ units of money"" and $H$ is the event ""of winning the first flip"". What event exactly is $R_n$? Is it correct to consider $H$ to be a single event or should we take a separate event for every coin flip? The approach taken by Grimmett and Stirzaker seems conceptually the same, but instead of using a single probability measure, they use $P_k$ - the probabilities calculated relative to the starting point $k$. Then they use the equation $P_k(A) = P_k(A|B)P(B) + P_k(A|B^C)P(B^C)$, where A is the event of losing the game and B is the event of winning the first flip. I am not completely sure what they mean by $P$, my best guess is that because the probability of $B$ is independent of $k$, they just drop the index. Next they use the fact that $P_k(A|B) = P_{k+1}(A)$ which looks essentially as expressing the same relation as the equation with $R_n$ before. Anyway, I haven't been able to completely justify this relation theoretically, so here comes my main question: How exactly do we justify $P(R_n|H)=P(R_{n+1})$ and $P_k(A|B) = P_{k+1}(A)$? I have tried translating this problem to a more familiar measure-theoretical language, using $\Omega = \lbrace-1,1\rbrace^\mathbb{N}$ as the underlying sample space and defining $M:\lbrace-1,1\rbrace^\mathbb{N}\times\mathbb{Z}\to\mathbb{N}\cup\lbrace\infty\rbrace,$ $M(f,k) = \min\lbrace m\in\mathbb{N}|\sum_{i=1}^m f(i) = k \rbrace$ (where $\min\emptyset := \infty$), which then enables us to define $R_n = \lbrace f\in\Omega|M(f,-n) < M(f,N-n)\rbrace$ and $H = \lbrace f\in\Omega|f(1) = 1\rbrace,$ but this hasn't given me any new intuition and may not even be the correct formalization. It seems increasingly likely that I am missing some implicit assumption in the statement of the problem that is obvious to probabilists but not so much to me ... In this case: What exactly is this assumption?","The problem of gambler's ruin asks the following: suppose a player begins with $k$ units of money, $0<k<N$. Each turn he flips a coin and either gains a unit of money with probability $p$ or loses a unit of money with probability $1-p$. The game ends when he reaches $N$ and wins or $0$ in which case he loses the game. What is the probability of losing? The usual solution, which you can find for example on http://en.wikipedia.org/wiki/Gambler%27s_ruin or in Grimmett & Stirzaker - Probability and Random processes, page 17, proceeds by constructing a linear difference equation using the fact (using the notation from wikipedia) that $P(R_n|H)=P(R_{n+1})$ where $R_n$ is the event ""that the player is ruined having started with $n$ units of money"" and $H$ is the event ""of winning the first flip"". What event exactly is $R_n$? Is it correct to consider $H$ to be a single event or should we take a separate event for every coin flip? The approach taken by Grimmett and Stirzaker seems conceptually the same, but instead of using a single probability measure, they use $P_k$ - the probabilities calculated relative to the starting point $k$. Then they use the equation $P_k(A) = P_k(A|B)P(B) + P_k(A|B^C)P(B^C)$, where A is the event of losing the game and B is the event of winning the first flip. I am not completely sure what they mean by $P$, my best guess is that because the probability of $B$ is independent of $k$, they just drop the index. Next they use the fact that $P_k(A|B) = P_{k+1}(A)$ which looks essentially as expressing the same relation as the equation with $R_n$ before. Anyway, I haven't been able to completely justify this relation theoretically, so here comes my main question: How exactly do we justify $P(R_n|H)=P(R_{n+1})$ and $P_k(A|B) = P_{k+1}(A)$? I have tried translating this problem to a more familiar measure-theoretical language, using $\Omega = \lbrace-1,1\rbrace^\mathbb{N}$ as the underlying sample space and defining $M:\lbrace-1,1\rbrace^\mathbb{N}\times\mathbb{Z}\to\mathbb{N}\cup\lbrace\infty\rbrace,$ $M(f,k) = \min\lbrace m\in\mathbb{N}|\sum_{i=1}^m f(i) = k \rbrace$ (where $\min\emptyset := \infty$), which then enables us to define $R_n = \lbrace f\in\Omega|M(f,-n) < M(f,N-n)\rbrace$ and $H = \lbrace f\in\Omega|f(1) = 1\rbrace,$ but this hasn't given me any new intuition and may not even be the correct formalization. It seems increasingly likely that I am missing some implicit assumption in the statement of the problem that is obvious to probabilists but not so much to me ... In this case: What exactly is this assumption?",,"['probability', 'measure-theory']"
56,name for a rational number between zero and one?,name for a rational number between zero and one?,,"I'm searching for a unified name to convey for the concept that a number will always be between zero and one. Some info for context: in probability we've got a number between 0 and 1.  Percentages appear to be similar in that we've got a number between zero and one, but it is multiplied by one hundred. The nearest names that I've got so far are ""factor"" or ""coefficient"", but both of these names could be larger than 1, or smaller than zero.","I'm searching for a unified name to convey for the concept that a number will always be between zero and one. Some info for context: in probability we've got a number between 0 and 1.  Percentages appear to be similar in that we've got a number between zero and one, but it is multiplied by one hundred. The nearest names that I've got so far are ""factor"" or ""coefficient"", but both of these names could be larger than 1, or smaller than zero.",,"['probability', 'terminology']"
57,How calculate the number of possible different variations?,How calculate the number of possible different variations?,,"I feel stupid, but I don't know how to calculate how many possible variations I can get from for example three spaces (1|2|3) Normally I'd say: ""well that is easy, just take the number of spaces (=3) and 3^3"" But that doesn't work with two spaces, like ""1|2"", there are only 2 different ways on how to arrange two numbers, but 2^2 would be 4. (I want to know how many spaces I need to get ~25000 possible variations)","I feel stupid, but I don't know how to calculate how many possible variations I can get from for example three spaces (1|2|3) Normally I'd say: ""well that is easy, just take the number of spaces (=3) and 3^3"" But that doesn't work with two spaces, like ""1|2"", there are only 2 different ways on how to arrange two numbers, but 2^2 would be 4. (I want to know how many spaces I need to get ~25000 possible variations)",,['probability']
58,moment generating function,moment generating function,,"can anyone help me to inform the name of any book where I can get the following theorem, or give some detailed hint to solve this one: Let $X$ and $Y$ be two random variables, if the moment generating functions of $X$ and $Y$ are equal then the probability distributions of $X$ and $Y$ will be same. In other words, if $E(e^{tX})=E(e^{tY})$ for all $t$ real, then $X$ and $Y$ have the same distribution.","can anyone help me to inform the name of any book where I can get the following theorem, or give some detailed hint to solve this one: Let $X$ and $Y$ be two random variables, if the moment generating functions of $X$ and $Y$ are equal then the probability distributions of $X$ and $Y$ will be same. In other words, if $E(e^{tX})=E(e^{tY})$ for all $t$ real, then $X$ and $Y$ have the same distribution.",,"['probability', 'reference-request']"
59,Find the expectation,Find the expectation,,"A box contain $A$ white and $B$ black balls and $C$ balls are drawn, then the expected value of the number of white balls drawn is ? The answer is $\large \frac{ca}{a+b}$. How to approach this one?","A box contain $A$ white and $B$ black balls and $C$ balls are drawn, then the expected value of the number of white balls drawn is ? The answer is $\large \frac{ca}{a+b}$. How to approach this one?",,"['probability', 'probability-distributions']"
60,3rd axiom of probability for discrete distribution,3rd axiom of probability for discrete distribution,,"it might be a stupid question but I was discussing with a colleague when the 3rd axiom of probability (sigma additivity) is really needed.  I argue that in the case of a discrete distribution, say a single die, the first two axioms are sufficient as this distribution has a finite number of events. Is this right? And then I am stretching it a bit by arguing that for simple/well behaved continuous distributions, such as the uniform distribution, the first two axioms are sufficient to ensure a proper probability distribution. Is that right? I always had the idea that the 3rd axiom was rather there to ensure that more cumbersome distributions or convolutions of distributions would still be proper probability distributions (although I don't have an example at hand). Or is axiom 3 much more vital than I understand? Thanks for any input! Best, Stefan","it might be a stupid question but I was discussing with a colleague when the 3rd axiom of probability (sigma additivity) is really needed.  I argue that in the case of a discrete distribution, say a single die, the first two axioms are sufficient as this distribution has a finite number of events. Is this right? And then I am stretching it a bit by arguing that for simple/well behaved continuous distributions, such as the uniform distribution, the first two axioms are sufficient to ensure a proper probability distribution. Is that right? I always had the idea that the 3rd axiom was rather there to ensure that more cumbersome distributions or convolutions of distributions would still be proper probability distributions (although I don't have an example at hand). Or is axiom 3 much more vital than I understand? Thanks for any input! Best, Stefan",,"['probability', 'probability-theory']"
61,Probability that at least 1 student is taking a language class solution,Probability that at least 1 student is taking a language class solution,,"This is a problem from A First Course in Probability by Ross: An elementary school is offering 3 language classes: one in Spanish, one in French, and one in German. The classes are open to any of the 100 students in the school. There are 28 students in the Spanish class, 26 in the French class, and 16 in the German class. There are 12 students that are in both Spanish and French, 4 that are in both Spanish and German, and 6 that are in both French and German. In addition, there are 2 students taking all 3 classes. The question I am trying to answer is: If 2 students are chosen randomly, what is the probability that at least 1 is taking a language class? From a previous question, the answer that a randomly chosen student is not in any of the language classes is 1/2. The answer to this question is 149/198, and it is calculated as $$1-\frac{50\choose2}{100\choose 2}=1-\frac{49}{198}=\frac{149}{198}.$$ My question is why can't this be calculated as $$1 - P(\text{Both students not taking language classes}) = 1 - \left( \frac{1}{2} \right)^2 = \frac{3}{4}$$ since the individual probability that a student is not taking a language class is 1/2?","This is a problem from A First Course in Probability by Ross: An elementary school is offering 3 language classes: one in Spanish, one in French, and one in German. The classes are open to any of the 100 students in the school. There are 28 students in the Spanish class, 26 in the French class, and 16 in the German class. There are 12 students that are in both Spanish and French, 4 that are in both Spanish and German, and 6 that are in both French and German. In addition, there are 2 students taking all 3 classes. The question I am trying to answer is: If 2 students are chosen randomly, what is the probability that at least 1 is taking a language class? From a previous question, the answer that a randomly chosen student is not in any of the language classes is 1/2. The answer to this question is 149/198, and it is calculated as My question is why can't this be calculated as since the individual probability that a student is not taking a language class is 1/2?",1-\frac{50\choose2}{100\choose 2}=1-\frac{49}{198}=\frac{149}{198}. 1 - P(\text{Both students not taking language classes}) = 1 - \left( \frac{1}{2} \right)^2 = \frac{3}{4},"['probability', 'combinatorics', 'statistics']"
62,"Combinatorics, 72 groups of 4.","Combinatorics, 72 groups of 4.",,"I’m doing an exercise where I simulate a cohort of 288 students and sort them into different groups. For one of the questions, my task is to place the entire cohort into 72 groups of 4, simulating their homework groups. Using code I’ve done this easily enough, however, I’m having trouble with the follow-up question. It asks how many different ways of sorting the 288 students into these 72 groups exist. My immediate thought was to use the multinomial coefficient, I got a very large answer: $${n\choose n_1,n_2,…,n_{72}}= \frac{n!}{n_1!n_2!…n_{72}!}= \frac{288!}{(4!)^{72}}\approx 3.03\times 10^{485}$$ using wolframAlpha’s calculator. I’m unsure of whether this is the answer my lecturers are looking for or whether I’ve made a mistake somewhere. The follow-up questions ask for probabilities of specific events with trivially small answers due to the large sample space of choices. I’d appreciate any help with this or points in the right direction. Maybe I’m just overthinking and it is supposed to be that large. Edit: Some useful comments have helped me realise that my answer is true if the order of the groups themselves matters. The question itself is slightly ambiguous on this point as it doesn't mention how we should treat the groups, however, given the fact that the groups are numbered and are simulating groups of students who take simulated tests, I am assuming that the order of said groups does indeed matter. Also, I should clarify what I meant when I spoke about the follow-up questions. One such question goes ""What is the probability that a student ends up in the exact same homework group (one of the 72 groups of 4) as the other people from their report group (report group: a separate group formed by splitting the cohort into 16 groups of 18(labs), then, and within these labs, students are further split into 6 groups of 3, which are labelled 'A to F' and exist within each lab)?"" For this follow-up question, as each report pod has 3 members, 2 not including the student in question, then, each homework group that satisfies the condition in the question must contain the entire report pod and then there are 285 candidates for the fourth member. I thought that the number of ways we could choose a homework group in this way was $288*285$ - 288 candidates for the student in question and then there are only 285 further choices to make given we fix the report pod into the homework group. Then, assuming each way of choosing the homework groups is equally likely, I deduce the probability of the event as $$\frac{82080}{3.03\times 10^{485}}$$ which is extremely small. The final follow-up asks what the expected number of students in one of the groups of 18 with at least one fellow student from their homework group(one of the 72 groups of 4, chosen independently of the other groups) that was also in their report pod(a group of 3 students within the same group of 18. As you can see, near-zero probabilities don't help me much when dealing with the second follow-up, unless I'm just calculating the probability itself in the completely wrong way. However, I'm not sure how else to think about it. Thank you!","I’m doing an exercise where I simulate a cohort of 288 students and sort them into different groups. For one of the questions, my task is to place the entire cohort into 72 groups of 4, simulating their homework groups. Using code I’ve done this easily enough, however, I’m having trouble with the follow-up question. It asks how many different ways of sorting the 288 students into these 72 groups exist. My immediate thought was to use the multinomial coefficient, I got a very large answer: using wolframAlpha’s calculator. I’m unsure of whether this is the answer my lecturers are looking for or whether I’ve made a mistake somewhere. The follow-up questions ask for probabilities of specific events with trivially small answers due to the large sample space of choices. I’d appreciate any help with this or points in the right direction. Maybe I’m just overthinking and it is supposed to be that large. Edit: Some useful comments have helped me realise that my answer is true if the order of the groups themselves matters. The question itself is slightly ambiguous on this point as it doesn't mention how we should treat the groups, however, given the fact that the groups are numbered and are simulating groups of students who take simulated tests, I am assuming that the order of said groups does indeed matter. Also, I should clarify what I meant when I spoke about the follow-up questions. One such question goes ""What is the probability that a student ends up in the exact same homework group (one of the 72 groups of 4) as the other people from their report group (report group: a separate group formed by splitting the cohort into 16 groups of 18(labs), then, and within these labs, students are further split into 6 groups of 3, which are labelled 'A to F' and exist within each lab)?"" For this follow-up question, as each report pod has 3 members, 2 not including the student in question, then, each homework group that satisfies the condition in the question must contain the entire report pod and then there are 285 candidates for the fourth member. I thought that the number of ways we could choose a homework group in this way was - 288 candidates for the student in question and then there are only 285 further choices to make given we fix the report pod into the homework group. Then, assuming each way of choosing the homework groups is equally likely, I deduce the probability of the event as which is extremely small. The final follow-up asks what the expected number of students in one of the groups of 18 with at least one fellow student from their homework group(one of the 72 groups of 4, chosen independently of the other groups) that was also in their report pod(a group of 3 students within the same group of 18. As you can see, near-zero probabilities don't help me much when dealing with the second follow-up, unless I'm just calculating the probability itself in the completely wrong way. However, I'm not sure how else to think about it. Thank you!","{n\choose n_1,n_2,…,n_{72}}= \frac{n!}{n_1!n_2!…n_{72}!}= \frac{288!}{(4!)^{72}}\approx 3.03\times 10^{485} 288*285 \frac{82080}{3.03\times 10^{485}}","['probability', 'combinatorics']"
63,"Probability of drawing a red ball before a blue ball, after already drawing the first blue ball","Probability of drawing a red ball before a blue ball, after already drawing the first blue ball",,"Given we have $20$ balls in a bucket: $4$ blue, $4$ red, rest are all white. We draw randomly from the bucket without replacement until we see the first blue ball. Now we continue drawing. Which is more likely to happen first - seeing a red ball, or seeing another blue ball? Now, I did some simulations and the answer seems to be that both are equally likely to happen. But I'm having trouble seeing this mathematically. My thought process is as follows: After the first blue ball is drawn, the probability of drawing a red or another blue ball first is determined by how many red and blue balls are left in the bucket. Now, obviously there are only $3$ blue balls left. But the expected number of red balls left are $3\frac{1}{5}$ . This is because, as shown below, , we can think of the order of us drawing balls as a permutation of the balls, and so each of the red ball have equal likelihood of being placed in one of the red slots, and so expected number of red ball in each red slot is $4/5$ , and thus the expected number of red balls after the first ""B"" is $4/5*4 = 3\frac{1}{5}$ . So we are expecting more red balls than blue balls remaining in the bucket. Then shouldn't that mean we have higher probability of draw red ball first before anothehr blue ball?","Given we have balls in a bucket: blue, red, rest are all white. We draw randomly from the bucket without replacement until we see the first blue ball. Now we continue drawing. Which is more likely to happen first - seeing a red ball, or seeing another blue ball? Now, I did some simulations and the answer seems to be that both are equally likely to happen. But I'm having trouble seeing this mathematically. My thought process is as follows: After the first blue ball is drawn, the probability of drawing a red or another blue ball first is determined by how many red and blue balls are left in the bucket. Now, obviously there are only blue balls left. But the expected number of red balls left are . This is because, as shown below, , we can think of the order of us drawing balls as a permutation of the balls, and so each of the red ball have equal likelihood of being placed in one of the red slots, and so expected number of red ball in each red slot is , and thus the expected number of red balls after the first ""B"" is . So we are expecting more red balls than blue balls remaining in the bucket. Then shouldn't that mean we have higher probability of draw red ball first before anothehr blue ball?",20 4 4 3 3\frac{1}{5} 4/5 4/5*4 = 3\frac{1}{5},"['probability', 'probability-distributions', 'conditional-probability']"
64,What is the probability that the sum of 6 four-sided dice is less than or equal to 14?,What is the probability that the sum of 6 four-sided dice is less than or equal to 14?,,"The solution given is shown below. My question is how did they count the numerator like that? What is the explanation for it please? $$\begin{align} \frac{C_6^{14}-C_1^6\times C_6^{10}+C_2^6 \times C_6^6}{4^6}&=\frac{3003-6\times 210+15\times 1}{4^6}\\ &= \frac{1758}{4^6}\\ &= \frac{879}{2048} \end{align}$$ I understand  the denominator namely because each of the four sided dice has four choices and six of them so, all possible outcomes will be $4^6$ . I believe that the 4-sided dice here has 1, 2, 3, 4 printed on its faces. Any help is appreciated.","The solution given is shown below. My question is how did they count the numerator like that? What is the explanation for it please? I understand  the denominator namely because each of the four sided dice has four choices and six of them so, all possible outcomes will be . I believe that the 4-sided dice here has 1, 2, 3, 4 printed on its faces. Any help is appreciated.","\begin{align}
\frac{C_6^{14}-C_1^6\times C_6^{10}+C_2^6 \times C_6^6}{4^6}&=\frac{3003-6\times 210+15\times 1}{4^6}\\
&= \frac{1758}{4^6}\\
&= \frac{879}{2048}
\end{align} 4^6","['probability', 'combinatorics', 'contest-math', 'recreational-mathematics', 'dice']"
65,What is the probability that exactly 2 repairers are called out of 4 repairers?,What is the probability that exactly 2 repairers are called out of 4 repairers?,,"A town contains 4 people who repair televisions. If 4 sets break down, what is the probability that exactly 2 of the repairers are called? I know that the solution is $$\frac{6 * (2^4-2)}{4^4}$$ But I don't understand why we do $-2$ the the numerator. My understanding: 6 is the amount of ways you can combine 4 workers along 2 choices. (4 choose 2). $2^4$ is the amount of times a house can choose 2 repairers. So, in my mind, the solution is: $$\frac{6 * (2^4)}{4^4}$$","A town contains 4 people who repair televisions. If 4 sets break down, what is the probability that exactly 2 of the repairers are called? I know that the solution is But I don't understand why we do the the numerator. My understanding: 6 is the amount of ways you can combine 4 workers along 2 choices. (4 choose 2). is the amount of times a house can choose 2 repairers. So, in my mind, the solution is:",\frac{6 * (2^4-2)}{4^4} -2 2^4 \frac{6 * (2^4)}{4^4},['probability']
66,Evaluating $\sum_{r=0}^{1010} \binom{1010}r \sum_{k=2r+1}^{2021}\binom{2021}k$,Evaluating,\sum_{r=0}^{1010} \binom{1010}r \sum_{k=2r+1}^{2021}\binom{2021}k,"I need to find the summation $$S=\sum_{r=0}^{1010} \binom{1010}r \sum_{k=2r+1}^{2021}\binom{2021}k$$ I tried various things like replacing $k$ by $2021-k$ and trying to add the 2 summations to a pattern but was unable to find a solution. For more insights into the question, this was essential to solve a probability question wherein there were 2 players, A and B. A rolls a dice $2021$ times, and B rolls it $1010$ times. We had to find the probability of A having number of odd numbers more than twice of B. So if B had $r$ odd numbers, A could have odd numbers from $2r+1$ to $2021$ , hence the summation. I can get the required probability by dividing this by $2^{2021+1010}$ .","I need to find the summation I tried various things like replacing by and trying to add the 2 summations to a pattern but was unable to find a solution. For more insights into the question, this was essential to solve a probability question wherein there were 2 players, A and B. A rolls a dice times, and B rolls it times. We had to find the probability of A having number of odd numbers more than twice of B. So if B had odd numbers, A could have odd numbers from to , hence the summation. I can get the required probability by dividing this by .",S=\sum_{r=0}^{1010} \binom{1010}r \sum_{k=2r+1}^{2021}\binom{2021}k k 2021-k 2021 1010 r 2r+1 2021 2^{2021+1010},"['probability', 'combinatorics', 'summation', 'binomial-coefficients', 'puzzle']"
67,Can covariance be negative?,Can covariance be negative?,,"So I always thought that covariance could take any real number. However, in class today my professor gave us a problem where we were supposed to find the covariance, $q$ $$0 = q^2 - 2q - 3 = (q - 3)(q + 1)$$ $$q = 3 \text{ or } q = -1$$ He then said that we should reject the negative case since covariance always needs to be non-negative. In this case, the covariance is a scalar. I know that the covariance matrix needs to be positive, semi-definite and that the elements along the diagonal of that matrix needs to be non-negative(since they're variances). So, since we have a scalar covariance does that mean it necessarily needs to be non-negative? Looking online, people mention that a negative covariance means that a greater value in one variable leads to lesser values in the other, so I'm guessing that covariance is allowed to be negative even in the scalar case?","So I always thought that covariance could take any real number. However, in class today my professor gave us a problem where we were supposed to find the covariance, He then said that we should reject the negative case since covariance always needs to be non-negative. In this case, the covariance is a scalar. I know that the covariance matrix needs to be positive, semi-definite and that the elements along the diagonal of that matrix needs to be non-negative(since they're variances). So, since we have a scalar covariance does that mean it necessarily needs to be non-negative? Looking online, people mention that a negative covariance means that a greater value in one variable leads to lesser values in the other, so I'm guessing that covariance is allowed to be negative even in the scalar case?",q 0 = q^2 - 2q - 3 = (q - 3)(q + 1) q = 3 \text{ or } q = -1,"['probability', 'probability-theory', 'variance', 'covariance']"
68,Coin Flip Problem,Coin Flip Problem,,"So my friend gave me this question this other day, and I've tried to start it (I'll show my logic below), but I couldn't find any efficient way to do the problem. You start out with 1 coin. At the end of each minute, all coins are flipped simultaneously. For each heads that is flipped, you get another coin. But for every tails that is flipped, a coin is lost. (Note any new coins are not flipped until the next moment). Once there are no more coins remaining, the process stops. What is the probability that exactly after 5 minutes (that's 5 sets of flips), that the process will have stopped (so no earlier or no later)? I've taken a few approaches to this problem. What I've tried to do is to find the total amount of possibilities for each amount of coins by the 5th moment, and then multiply that by the probability that all coins will be vanished on the 5th moment. But I'm just not able to calculate how many possible ways exist to get to each amount of total coins by the end. Does anyone have any other ideas, or perhaps a formula to solve this problem?","So my friend gave me this question this other day, and I've tried to start it (I'll show my logic below), but I couldn't find any efficient way to do the problem. You start out with 1 coin. At the end of each minute, all coins are flipped simultaneously. For each heads that is flipped, you get another coin. But for every tails that is flipped, a coin is lost. (Note any new coins are not flipped until the next moment). Once there are no more coins remaining, the process stops. What is the probability that exactly after 5 minutes (that's 5 sets of flips), that the process will have stopped (so no earlier or no later)? I've taken a few approaches to this problem. What I've tried to do is to find the total amount of possibilities for each amount of coins by the 5th moment, and then multiply that by the probability that all coins will be vanished on the 5th moment. But I'm just not able to calculate how many possible ways exist to get to each amount of total coins by the end. Does anyone have any other ideas, or perhaps a formula to solve this problem?",,"['probability', 'combinatorics', 'combinations']"
69,"If you draw 26 cards from 52 cards, what is the probability that you get 4 kings?","If you draw 26 cards from 52 cards, what is the probability that you get 4 kings?",,The 52 cards of a standard playing card deck are randomly distributed to two persons: 26 cards to each person. Find the probability that the first person receives all four Kings. Note: The 52 cards include four Kings. I had this question in my probability exam and my answer was $$ \frac{ {4 \choose 4} . {48 \choose 22}}{52 \choose 26} $$ However the teaching assistant's answer was $(\frac{1}{2})^4 = \frac{1}{16}$ as each card has a probability $\frac{1}{2}$ to go to either of the 2 persons Which answer is correct?,The 52 cards of a standard playing card deck are randomly distributed to two persons: 26 cards to each person. Find the probability that the first person receives all four Kings. Note: The 52 cards include four Kings. I had this question in my probability exam and my answer was However the teaching assistant's answer was as each card has a probability to go to either of the 2 persons Which answer is correct?, \frac{ {4 \choose 4} . {48 \choose 22}}{52 \choose 26}  (\frac{1}{2})^4 = \frac{1}{16} \frac{1}{2},"['probability', 'combinatorics', 'solution-verification']"
70,Jointly Gaussian random vectors,Jointly Gaussian random vectors,,"$\newcommand{cov}{\operatorname{cov}}$ Suppose two scalar valued random variables $X$ and $Y$ are jointly Gaussian. We then have the joint density $$f_{X, Y}(x, y) = \frac{1}{2 \pi \sqrt{|K|}} \exp \left\{ -\frac{1}{2} \begin{bmatrix} x - \mu_X\\ y - \mu_Y \end{bmatrix}^T K^{-1} \begin{bmatrix} x - \mu_X\\ y - \mu_Y \end{bmatrix}  \right\} $$ where $K = \begin{bmatrix} \cov(X, X) & \cov(X, Y)\\ \cov(Y, X) & \cov(Y, Y) \end{bmatrix}$ . Now how do we write the joint density when $X \in \mathbb{R}^m$ and $Y \in \mathbb{R}^n$ are random vectors. Does $K$ become a third order tensor? And what goes in the exponential power? I think $K \in \mathbb{R}^{m \times n}$ where $K_{ij} = \cov(X_i, Y_j)$ even though strict analogy with the scalar case would suggest something like $K \in \mathbb{R}^{2 \times m \times n}$",Suppose two scalar valued random variables and are jointly Gaussian. We then have the joint density where . Now how do we write the joint density when and are random vectors. Does become a third order tensor? And what goes in the exponential power? I think where even though strict analogy with the scalar case would suggest something like,"\newcommand{cov}{\operatorname{cov}} X Y f_{X, Y}(x, y) = \frac{1}{2 \pi \sqrt{|K|}} \exp \left\{ -\frac{1}{2} \begin{bmatrix}
x - \mu_X\\
y - \mu_Y
\end{bmatrix}^T K^{-1} \begin{bmatrix}
x - \mu_X\\
y - \mu_Y
\end{bmatrix}  \right\}  K = \begin{bmatrix}
\cov(X, X) & \cov(X, Y)\\
\cov(Y, X) & \cov(Y, Y)
\end{bmatrix} X \in \mathbb{R}^m Y \in \mathbb{R}^n K K \in \mathbb{R}^{m \times n} K_{ij} = \cov(X_i, Y_j) K \in \mathbb{R}^{2 \times m \times n}","['probability', 'probability-distributions', 'random-variables', 'random-matrices']"
71,Minimize KL divergence + linear function,Minimize KL divergence + linear function,,"I am looking at the following problem: $$ \min_q \underbrace{KL \left[ q(x) ~||~ p(x) \right]}_{=: A} + \underbrace{\mathbb{E}_{x \sim q} \left [ f(x) \right ]}_{=: B}. $$ For $A$ , the solution is $q(x) = p(x)$ . For $B$ , the solution is a point mass/dirac/delta distribution putting all its mass at $arg,\min f(x)$ . Further I know that $A$ should be strictly convex (accd to a comment in this question .) My questions are the following: Is there any hope of finding the minimizer in closed form, making use of the two respective solutions? Something like ""the minimizer lies on a line between the two respective solutions."" ?","I am looking at the following problem: For , the solution is . For , the solution is a point mass/dirac/delta distribution putting all its mass at . Further I know that should be strictly convex (accd to a comment in this question .) My questions are the following: Is there any hope of finding the minimizer in closed form, making use of the two respective solutions? Something like ""the minimizer lies on a line between the two respective solutions."" ?","
\min_q \underbrace{KL \left[ q(x) ~||~ p(x) \right]}_{=: A} + \underbrace{\mathbb{E}_{x \sim q} \left [ f(x) \right ]}_{=: B}.
 A q(x) = p(x) B arg,\min f(x) A","['probability', 'convex-optimization', 'information-theory']"
72,Drunk men finding their tents,Drunk men finding their tents,,"Problem: There are four couples camping at the lakeside. They start drinking and as the women get bored and tired, they all go to sleep into their tents. The men continue and get very drunk. In the morning they all go randomly into a tent (but each to a separate one).  What is the probability that P (all men go to their own tents) P (3 go their own tent, and 1 to a foreign one) P (2 go their own tent, and 2 to a foreign one) P (1 go their own tent, and 3 to a foreign one) P (all men are mistaken) My attempt: P (all men go to their own tents) = 1/4 * 1/3 * 1/2 * 1 = 1/24 = 0.04167 because the P (1 man finds his tent) = 1/4, then the P the next one gets it right is 1/3 because he can go to one less place, etc. P (3 go their own tent, and 1 to a foreign one) = 0 because impossible P (2 go their own tent, and 2 to a foreign one) = (4! / (2!*2!)) / 4! = 6/24 =  0.25 because we need to select two men who go to their right place, two that do not, and (in the denominator:) they can altogether be placed 4! different ways. P (1 go their own tent, and 3 to a foreign one) = (4! / 1!*3!) / 4! = 4/24 = 0.16667 because the same logic as no.3. P (all men are mistaken) = 3/4 * 2/3 * 1/2 * 1 = 6/24 = O.25 because the P that the first man goes to a wrong place is 3/4, the probability that the second one goes to a wrong place is one less: 2/3, etc. Question: But there is something wrong with my attempt as the probabilities do not add up to 100%. Where do I go wrong? 0.04167 0.00000 0.25000 0.16667 0.25000 0.70834","Problem: There are four couples camping at the lakeside. They start drinking and as the women get bored and tired, they all go to sleep into their tents. The men continue and get very drunk. In the morning they all go randomly into a tent (but each to a separate one).  What is the probability that P (all men go to their own tents) P (3 go their own tent, and 1 to a foreign one) P (2 go their own tent, and 2 to a foreign one) P (1 go their own tent, and 3 to a foreign one) P (all men are mistaken) My attempt: P (all men go to their own tents) = 1/4 * 1/3 * 1/2 * 1 = 1/24 = 0.04167 because the P (1 man finds his tent) = 1/4, then the P the next one gets it right is 1/3 because he can go to one less place, etc. P (3 go their own tent, and 1 to a foreign one) = 0 because impossible P (2 go their own tent, and 2 to a foreign one) = (4! / (2!*2!)) / 4! = 6/24 =  0.25 because we need to select two men who go to their right place, two that do not, and (in the denominator:) they can altogether be placed 4! different ways. P (1 go their own tent, and 3 to a foreign one) = (4! / 1!*3!) / 4! = 4/24 = 0.16667 because the same logic as no.3. P (all men are mistaken) = 3/4 * 2/3 * 1/2 * 1 = 6/24 = O.25 because the P that the first man goes to a wrong place is 3/4, the probability that the second one goes to a wrong place is one less: 2/3, etc. Question: But there is something wrong with my attempt as the probabilities do not add up to 100%. Where do I go wrong? 0.04167 0.00000 0.25000 0.16667 0.25000 0.70834",,['probability']
73,Calculate number of subsets,Calculate number of subsets,,"I want to find how many subsets $A$ contains the set $\{ 1,2, \dots, 7 \}$ with the property  $$(3 \in A \iff 2 \in A).$$ The set $\{ 1,2, \dots, 7\}$ has in total $2^7=128$ subsets, right? In order to find the number of subsets $A$ with the property $(3 \in A \iff 2 \in A)$, we have to find the number of subsets that do not contain both $2$ and $3$ and subtract the result by $128$, right? But how do we find the number of subsets of $\{ 1,2, \dots, 7 \}$ that do not conatin both $2$ and $3$ ?","I want to find how many subsets $A$ contains the set $\{ 1,2, \dots, 7 \}$ with the property  $$(3 \in A \iff 2 \in A).$$ The set $\{ 1,2, \dots, 7\}$ has in total $2^7=128$ subsets, right? In order to find the number of subsets $A$ with the property $(3 \in A \iff 2 \in A)$, we have to find the number of subsets that do not contain both $2$ and $3$ and subtract the result by $128$, right? But how do we find the number of subsets of $\{ 1,2, \dots, 7 \}$ that do not conatin both $2$ and $3$ ?",,"['probability', 'elementary-set-theory']"
74,Simple question about probability,Simple question about probability,,"I'm a bit confused about something. Let's say I want to cross a road to my friend's house. The probability of the road to be opened is $p$, and $1-p$ to be closed. So I know the probability for one direction at a time. What would it be if I would like to go and return on the same day?  note: Let's assume that the road was opened/closed for the whole day. My answer is $p^2$ (or $(1-p)^2$), depends on the status of the road.","I'm a bit confused about something. Let's say I want to cross a road to my friend's house. The probability of the road to be opened is $p$, and $1-p$ to be closed. So I know the probability for one direction at a time. What would it be if I would like to go and return on the same day?  note: Let's assume that the road was opened/closed for the whole day. My answer is $p^2$ (or $(1-p)^2$), depends on the status of the road.",,['probability']
75,When sum of two Poisson variables is not Poisson,When sum of two Poisson variables is not Poisson,,"If $X$ and $Y$ are independent Poisson random variables, then $X+Y$ is Poisson. We also know that sum of two dependent Poisson variables might result in another Poisson variable. My question is: what would be the counterexample (not the rigorous proof which might exist) that negates the claim that sum of two Poissons, irrespective of their dependency,  would always result in Poisson.","If $X$ and $Y$ are independent Poisson random variables, then $X+Y$ is Poisson. We also know that sum of two dependent Poisson variables might result in another Poisson variable. My question is: what would be the counterexample (not the rigorous proof which might exist) that negates the claim that sum of two Poissons, irrespective of their dependency,  would always result in Poisson.",,"['probability', 'poisson-distribution']"
76,Six dice blank on five sides. How to roll as one?,Six dice blank on five sides. How to roll as one?,,"I have six six-sided dice. Five of their faces are blank and identical. One face on each die contains the number 1,2,3,4,5, or 6. Suppose I roll them together, the output from this random event is an unordered set for example: {B,B,3,1,B,6} (blank side results, for our purposes, are indistinguishable.) What is a simple way to use this result like an ordinary, fair six-sided die? My first thought was to keep rolling until the only non-blank results are permutations of {A,B,B,B,B,B} {A,A,B,B,B,B} {A,A,A,B,B,B} {A,A,A,A,B,B} {A,A,A,A,A,B} {A,A,A,A,A,A} where A is some repeated number 1-6 and B is blank. This would work but it is not efficient. Obviously the many {B,B,B,B,B,B} results can’t be used (probably?) but, what about mixed results? For any result where one number is repeated more than the rest I could take the most repeated number as the result... but how can I interpret {1,2,1,2,4,B,6}? Basically, I’m looking for a simple function that a human* could remember easily that maps the results of this random event to the numbers 1-6 with equal frequency. *A table is another solution, but I would like fewer than 5 or 6 dead simple rules that use all of the results that are not {B,B,B,B,B,B}. If there is a way to use {B,B,B,B,B,B} that is even better.","I have six six-sided dice. Five of their faces are blank and identical. One face on each die contains the number 1,2,3,4,5, or 6. Suppose I roll them together, the output from this random event is an unordered set for example: {B,B,3,1,B,6} (blank side results, for our purposes, are indistinguishable.) What is a simple way to use this result like an ordinary, fair six-sided die? My first thought was to keep rolling until the only non-blank results are permutations of {A,B,B,B,B,B} {A,A,B,B,B,B} {A,A,A,B,B,B} {A,A,A,A,B,B} {A,A,A,A,A,B} {A,A,A,A,A,A} where A is some repeated number 1-6 and B is blank. This would work but it is not efficient. Obviously the many {B,B,B,B,B,B} results can’t be used (probably?) but, what about mixed results? For any result where one number is repeated more than the rest I could take the most repeated number as the result... but how can I interpret {1,2,1,2,4,B,6}? Basically, I’m looking for a simple function that a human* could remember easily that maps the results of this random event to the numbers 1-6 with equal frequency. *A table is another solution, but I would like fewer than 5 or 6 dead simple rules that use all of the results that are not {B,B,B,B,B,B}. If there is a way to use {B,B,B,B,B,B} that is even better.",,['probability']
77,Is this $\binom{n}{p}$ for $p>n$ make a sense in mathematics or it is $0$ by convention?,Is this  for  make a sense in mathematics or it is  by convention?,\binom{n}{p} p>n 0,"It is well known that gamma function is not defined at negative integers , but my question is to know how i take the value of   $\binom{n}{p}$ for  $p>n$ then is this  make a sense or it is  $0$ by convention ?","It is well known that gamma function is not defined at negative integers , but my question is to know how i take the value of   $\binom{n}{p}$ for  $p>n$ then is this  make a sense or it is  $0$ by convention ?",,"['probability', 'binomial-coefficients', 'definition', 'convention']"
78,Probability that outcome will be familiar given partial familiarity of all possible outcomes.,Probability that outcome will be familiar given partial familiarity of all possible outcomes.,,"Here is a light question: Say that my professor says she will choose 12 definitions from a list of 40, and I will have to answer 7 of those 12 on a test. Say that I know 24 of the 40 possible definitions she will choose from. What is the probability that at least 7 of the definitions on the test will be from the 24 I know? This is really the case for my History Final Today. It did spark my curiosity as to how the probability would be calculated. I know binomial coefficients are involved, but any insights towards a complete solution?","Here is a light question: Say that my professor says she will choose 12 definitions from a list of 40, and I will have to answer 7 of those 12 on a test. Say that I know 24 of the 40 possible definitions she will choose from. What is the probability that at least 7 of the definitions on the test will be from the 24 I know? This is really the case for my History Final Today. It did spark my curiosity as to how the probability would be calculated. I know binomial coefficients are involved, but any insights towards a complete solution?",,"['probability', 'discrete-mathematics', 'binomial-coefficients', 'combinations']"
79,Density of Gaussian Random variable conditioned on sum,Density of Gaussian Random variable conditioned on sum,,"I am struggling with this simple problem. I have two Gaussian independent random variables $X \sim \mathcal{N}(0,\sigma_x^2,), Y \sim \mathcal{N}(0,\sigma_y^2,)$. I have to find the density of $X$ given that $X + Y > 0$. I know that $X, X+Y$ shall be jointly normal distributed and I also know the forms of conditional distribution of $X | X+Y=z$ https://en.wikipedia.org/wiki/Multivariate_normal_distribution https://stats.stackexchange.com/questions/17463/signal-extraction-problem-conditional-expectation-of-one-item-in-sum-of-indepen but somehow I am confused because the condition that I have is that $X+Y > 0$ and not of the form $X+Y = z$. I feel that some integration shall have to be performed but I am not sure how. Any pointers shall be very helpful. It will also help if I can get the conditional mean, variance if not the entire density function. Thanks","I am struggling with this simple problem. I have two Gaussian independent random variables $X \sim \mathcal{N}(0,\sigma_x^2,), Y \sim \mathcal{N}(0,\sigma_y^2,)$. I have to find the density of $X$ given that $X + Y > 0$. I know that $X, X+Y$ shall be jointly normal distributed and I also know the forms of conditional distribution of $X | X+Y=z$ https://en.wikipedia.org/wiki/Multivariate_normal_distribution https://stats.stackexchange.com/questions/17463/signal-extraction-problem-conditional-expectation-of-one-item-in-sum-of-indepen but somehow I am confused because the condition that I have is that $X+Y > 0$ and not of the form $X+Y = z$. I feel that some integration shall have to be performed but I am not sure how. Any pointers shall be very helpful. It will also help if I can get the conditional mean, variance if not the entire density function. Thanks",,"['probability', 'probability-distributions', 'random-variables', 'normal-distribution', 'expectation']"
80,Is this a trick question? Balls into urns probability,Is this a trick question? Balls into urns probability,,"There are two urns. Urn 1 contains 3 white and 2 red ball, urn 2 one white and two red. First, a ball from urn 1 is randomly chosen and placed into urn 2. Finally, a ball from urn 2 is picked. This ball be red: What is the probability that the ball transferred from urn 1 to urn 2 was white? My answer is 3/5 - 3W over 5 balls in urn 1 as the second event does not tell me anything to influence which ball was transferred since urn 2 already has a red ball anyways. Hope to know if my reasoning is valid!","There are two urns. Urn 1 contains 3 white and 2 red ball, urn 2 one white and two red. First, a ball from urn 1 is randomly chosen and placed into urn 2. Finally, a ball from urn 2 is picked. This ball be red: What is the probability that the ball transferred from urn 1 to urn 2 was white? My answer is 3/5 - 3W over 5 balls in urn 1 as the second event does not tell me anything to influence which ball was transferred since urn 2 already has a red ball anyways. Hope to know if my reasoning is valid!",,['probability']
81,Find probability that the sum of two dice is not 6 and not 5?,Find probability that the sum of two dice is not 6 and not 5?,,"When rolling two fair dice, what is P(sum of two dice is not 6 and not 5)? Calculation:  First, I found the probability of two numbers that would roll a sum of 6: (1,5) (2,4) (3,3) (4,2) (5,1)  = 5/36 (each probability is 1/36) Then, I found the probability of two numbers that would roll a sum of 5: (1,4) (2,3) (3,2) (4,1) = 4/36 My first method was to add the probabilities and then subtract from one to give the probability of NOT rolling a sum of 6 or 5: (5/36) + (4/36) = 9/36 1 - 9/36 = 27/36 = 0.75 This turned out to be the accepted answer of my online homework. But then, I realized that the original question asked for P(not sum of 6 AND not sum of 5). So, I recalculated: 1 - 5/36 = 31/36 1 - 4/36 = 32/36 (31/36)(32/36) = 992/1296 ~ 0.7654 (using multiplication rule) When I entered this fraction in, it was incorrect. But since the questions asks for ""AND"" and not ""or"", wouldn't the second probability be the actual correct answer?","When rolling two fair dice, what is P(sum of two dice is not 6 and not 5)? Calculation:  First, I found the probability of two numbers that would roll a sum of 6: (1,5) (2,4) (3,3) (4,2) (5,1)  = 5/36 (each probability is 1/36) Then, I found the probability of two numbers that would roll a sum of 5: (1,4) (2,3) (3,2) (4,1) = 4/36 My first method was to add the probabilities and then subtract from one to give the probability of NOT rolling a sum of 6 or 5: (5/36) + (4/36) = 9/36 1 - 9/36 = 27/36 = 0.75 This turned out to be the accepted answer of my online homework. But then, I realized that the original question asked for P(not sum of 6 AND not sum of 5). So, I recalculated: 1 - 5/36 = 31/36 1 - 4/36 = 32/36 (31/36)(32/36) = 992/1296 ~ 0.7654 (using multiplication rule) When I entered this fraction in, it was incorrect. But since the questions asks for ""AND"" and not ""or"", wouldn't the second probability be the actual correct answer?",,"['probability', 'statistics', 'dice']"
82,How does one calculate probability when there are infinite possibilities?,How does one calculate probability when there are infinite possibilities?,,"For example, if I picked a random integer, from the infinite amount of integers, what would be the probability of picking, say 1? And how can this be extended? Say I have x + y = 0, and I pick a random integer each for x and y, what is the probability of it being a true statement? Please answer keeping in mind I haven't really taken any course in probability or statistics.","For example, if I picked a random integer, from the infinite amount of integers, what would be the probability of picking, say 1? And how can this be extended? Say I have x + y = 0, and I pick a random integer each for x and y, what is the probability of it being a true statement? Please answer keeping in mind I haven't really taken any course in probability or statistics.",,"['probability', 'infinity']"
83,Determining the number of balls in a box,Determining the number of balls in a box,,"I'm facing problems solving this question and I'd like some help: A box contains n balls, where just 2 are white and the rest are red. A random sample of 4 balls is drawn without replacement. It's known that the probability of the 2 white balls are in the sample is 6 times higher than the probability that no white balls are in the sample. Calculate n . I did like that: $$6* (\frac{2}{n} *\frac{1}{n-1} * \frac{n-2}{n-2} * \frac{n-3}{n-3}) = (\frac{n-2}{n} *\frac{n-3}{n-1} * \frac{n-4}{n-2} * \frac{n-5}{n-3}) => n = 8 $$ But, according to the answer of this question, n = 6. I trying to find my mistake. Can someone help me?","I'm facing problems solving this question and I'd like some help: A box contains n balls, where just 2 are white and the rest are red. A random sample of 4 balls is drawn without replacement. It's known that the probability of the 2 white balls are in the sample is 6 times higher than the probability that no white balls are in the sample. Calculate n . I did like that: $$6* (\frac{2}{n} *\frac{1}{n-1} * \frac{n-2}{n-2} * \frac{n-3}{n-3}) = (\frac{n-2}{n} *\frac{n-3}{n-1} * \frac{n-4}{n-2} * \frac{n-5}{n-3}) => n = 8 $$ But, according to the answer of this question, n = 6. I trying to find my mistake. Can someone help me?",,['probability']
84,"If a coin comes up heads, it is tossed exactly two more times. Find $f_Z$ where $Z$ is the number of heads minus the number of tails.","If a coin comes up heads, it is tossed exactly two more times. Find  where  is the number of heads minus the number of tails.",f_Z Z,There are three questions for this problem. Please help me explain the answer for number 3. Find $f_X$ where $X$ is the total number of heads. Yep I got this. Ans: \begin{align}f_X (0)&=P(X =0)=P(T)=\frac12\\ f_X(1)&=P(X =1)=P(HTT)=\frac18 \\f_X (2)&=P(X =2)=P(HHT)+P(HTH)=\frac14\\ f_X (3)&=P(X=3)=P(HHH)=1/8\end{align} Find $f_Y$ where $Y$ is the total number of tails. Yep I got this. Ans: \begin{align}f_Y (0)&=P(Y =0)=P(HHH)=\frac18\\ f_Y (1)&=P(Y =1)=P(T)+P(HHT)+P(HTH)=\frac68=\frac34 \\ f_Y (2)&=P(Y =2)=P(HTT)=\frac18 \end{align} Find $f_Z$ where $Z$ is the number of heads minus the number of tails. I got the answer for this one but don't fully get it. Could anyone please help me explain. Thank you. Ans:  \begin{align}f_Z(−1)&=P(Z =−1)=P(T)+P(HTT)=\frac58\\  f_Z(1)&=P(Z =1)=P(HHT)+P(HTH)=\frac28=\frac14\\  f_Z(3)&=P(Z =3)=P(HHH)=\frac18\end{align},There are three questions for this problem. Please help me explain the answer for number 3. Find $f_X$ where $X$ is the total number of heads. Yep I got this. Ans: \begin{align}f_X (0)&=P(X =0)=P(T)=\frac12\\ f_X(1)&=P(X =1)=P(HTT)=\frac18 \\f_X (2)&=P(X =2)=P(HHT)+P(HTH)=\frac14\\ f_X (3)&=P(X=3)=P(HHH)=1/8\end{align} Find $f_Y$ where $Y$ is the total number of tails. Yep I got this. Ans: \begin{align}f_Y (0)&=P(Y =0)=P(HHH)=\frac18\\ f_Y (1)&=P(Y =1)=P(T)+P(HHT)+P(HTH)=\frac68=\frac34 \\ f_Y (2)&=P(Y =2)=P(HTT)=\frac18 \end{align} Find $f_Z$ where $Z$ is the number of heads minus the number of tails. I got the answer for this one but don't fully get it. Could anyone please help me explain. Thank you. Ans:  \begin{align}f_Z(−1)&=P(Z =−1)=P(T)+P(HTT)=\frac58\\  f_Z(1)&=P(Z =1)=P(HHT)+P(HTH)=\frac28=\frac14\\  f_Z(3)&=P(Z =3)=P(HHH)=\frac18\end{align},,"['probability', 'probability-distributions', 'random-variables']"
85,Probability of choosing 5 out of 60 in ascending order.,Probability of choosing 5 out of 60 in ascending order.,,"The title may be a little misleading. Let's say we choose 5 out of 60 balls. We write down the result which are in a form as $k_1,k_2,k_3,k_4,k_5$. I have to calculate the probability of this happening : \begin{aligned}k_1<k_2<k_3<k_4<k_5\end{aligned} Also, the probability of this happening: \begin{aligned}k_1>\max\{k_2,k_3,k_4,k_5\}\end{aligned} We do care for the order so the number of the elements in the sample space is : $$\frac{60!}{(60-5)!}$$ I am stuck there. I can't think of anything to do to calculate those two probabilities. I would appreciate it if someone could help me. Thanks in advance!","The title may be a little misleading. Let's say we choose 5 out of 60 balls. We write down the result which are in a form as $k_1,k_2,k_3,k_4,k_5$. I have to calculate the probability of this happening : \begin{aligned}k_1<k_2<k_3<k_4<k_5\end{aligned} Also, the probability of this happening: \begin{aligned}k_1>\max\{k_2,k_3,k_4,k_5\}\end{aligned} We do care for the order so the number of the elements in the sample space is : $$\frac{60!}{(60-5)!}$$ I am stuck there. I can't think of anything to do to calculate those two probabilities. I would appreciate it if someone could help me. Thanks in advance!",,"['probability', 'probability-theory', 'statistics', 'combinations']"
86,Genetics and probability (“other than” case),Genetics and probability (“other than” case),,"(Moved from Bio SE due to the mathematical nature of the problem.) If a man and woman, both carriers of a autosomal recessive   disorder (i.e. having genotype $Aa$), produce three children, what is the probability of one or   more children having the disorder? The answer key suggests finding the probability of the children all being normal and then subtracting that from 1: $$Aa \times Aa$$ $$P_{AA\:or\:Aa}=\frac{3}{4}$$ $$\frac{3}{4} \times \frac{3}{4} \times \frac{3}{4} = \frac{27}{64}\tag{3 normal}$$ $$1-\frac{27}{64}=\frac{37}{64}\tag{≥1 abnormal}$$ I understand the logic behind that: If they aren’t all normal, then at least one of them has to be abnormal. However, what if I didn’t want to use the $1-x$ method? What if I wanted to do it the hard way? I tried breaking it into three cases: 1 abnormal, 2 abnormal, and all abnormal. $$P_{aa}=\frac{1}{4}$$ $$\frac{1}{4} \times \frac{3}{4} \times \frac{3}{4} = \frac{9}{64}\tag{1 abnormal, 2 normal}$$ $$\frac{1}{4} \times \frac{1}{4} \times \frac{3}{4} = \frac{3}{64}\tag{2 abnormal, 1 normal}$$ $$\frac{1}{4} \times \frac{1}{4} \times \frac{1}{4} = \frac{1}{64}\tag{3 abnormal, 0 normal}$$ $$\sum P=\frac{13}{64}$$ which obviously isn’t the correct answer. What’s wrong with the way I’m doing it?","(Moved from Bio SE due to the mathematical nature of the problem.) If a man and woman, both carriers of a autosomal recessive   disorder (i.e. having genotype $Aa$), produce three children, what is the probability of one or   more children having the disorder? The answer key suggests finding the probability of the children all being normal and then subtracting that from 1: $$Aa \times Aa$$ $$P_{AA\:or\:Aa}=\frac{3}{4}$$ $$\frac{3}{4} \times \frac{3}{4} \times \frac{3}{4} = \frac{27}{64}\tag{3 normal}$$ $$1-\frac{27}{64}=\frac{37}{64}\tag{≥1 abnormal}$$ I understand the logic behind that: If they aren’t all normal, then at least one of them has to be abnormal. However, what if I didn’t want to use the $1-x$ method? What if I wanted to do it the hard way? I tried breaking it into three cases: 1 abnormal, 2 abnormal, and all abnormal. $$P_{aa}=\frac{1}{4}$$ $$\frac{1}{4} \times \frac{3}{4} \times \frac{3}{4} = \frac{9}{64}\tag{1 abnormal, 2 normal}$$ $$\frac{1}{4} \times \frac{1}{4} \times \frac{3}{4} = \frac{3}{64}\tag{2 abnormal, 1 normal}$$ $$\frac{1}{4} \times \frac{1}{4} \times \frac{1}{4} = \frac{1}{64}\tag{3 abnormal, 0 normal}$$ $$\sum P=\frac{13}{64}$$ which obviously isn’t the correct answer. What’s wrong with the way I’m doing it?",,['probability']
87,Show $X_1$ and $X_2$ have a common Gaussian distribution,Show  and  have a common Gaussian distribution,X_1 X_2,"Anyone has any idea about the following question? Let $\Bbb E(X_1^2)$ and $\Bbb E(X_2^2)$ be finite. Show that if $X_1$ and $X_2$ are independent and likewise $X_1+X_2$ and $X_1-X_2$, then both $X_1$ and $X_2$ have a common Gaussian distribution. There is a hint that ""$2x_1 = 2x_1-x_2+x_2$ and $2x_2=2x_2-x_1+x_1$ and then apply central limit theorem four times"", but I still have no idea how to do this. Thank you.","Anyone has any idea about the following question? Let $\Bbb E(X_1^2)$ and $\Bbb E(X_2^2)$ be finite. Show that if $X_1$ and $X_2$ are independent and likewise $X_1+X_2$ and $X_1-X_2$, then both $X_1$ and $X_2$ have a common Gaussian distribution. There is a hint that ""$2x_1 = 2x_1-x_2+x_2$ and $2x_2=2x_2-x_1+x_1$ and then apply central limit theorem four times"", but I still have no idea how to do this. Thank you.",,"['probability', 'normal-distribution', 'central-limit-theorem', 'independence']"
88,How are the following two Chebychev's inequalities equivalent?,How are the following two Chebychev's inequalities equivalent?,,"I was looking at the following definition of Chebyshev 's inequality $$P(|X - E(X)| \geq r) \leq \frac{Var(X)}{r^2}$$ which includes the expected value and variance of $X$, and then I discovered there's another equivalent Chebyshev's inequality, which involves the standard deviation $\sigma$ $$P(|X - E(X)| \geq r\cdot \sigma) \leq \frac{1}{r^2}$$ but I am not understanding why are these formulas equivalent. Could you please explain to me why this is the case? Note that I know what is the standard deviation.","I was looking at the following definition of Chebyshev 's inequality $$P(|X - E(X)| \geq r) \leq \frac{Var(X)}{r^2}$$ which includes the expected value and variance of $X$, and then I discovered there's another equivalent Chebyshev's inequality, which involves the standard deviation $\sigma$ $$P(|X - E(X)| \geq r\cdot \sigma) \leq \frac{1}{r^2}$$ but I am not understanding why are these formulas equivalent. Could you please explain to me why this is the case? Note that I know what is the standard deviation.",,"['probability', 'inequality']"
89,Expected amount of repeats in a random sequence of integers,Expected amount of repeats in a random sequence of integers,,"I'm looking at a series of random integers generated by a CSPRNG and noticed that there are more repeats (that is a number is in the sequence 2 or more times e.g. 9,3,8,5,6,3 - 3 is a repeat) than I expected. I generated 10,000 numbers, each between 1 and 100,000, this resulted in 9,516 unique numbers. Does this seem correct, and if so, how would I calculated the expected about of unique numbers for n random numbers of a range 1 to x?","I'm looking at a series of random integers generated by a CSPRNG and noticed that there are more repeats (that is a number is in the sequence 2 or more times e.g. 9,3,8,5,6,3 - 3 is a repeat) than I expected. I generated 10,000 numbers, each between 1 and 100,000, this resulted in 9,516 unique numbers. Does this seem correct, and if so, how would I calculated the expected about of unique numbers for n random numbers of a range 1 to x?",,"['probability', 'sequences-and-series', 'random']"
90,Expected number of times a set of 10 integers (selected from 1-100) is selected before all 100 are seen,Expected number of times a set of 10 integers (selected from 1-100) is selected before all 100 are seen,,"Suppose I have a set of 100 integers. I randomly choose 10 of those, make a note of which ones I selected, and repeat the process. What is the expected number of times this process must be repeated before I see all 100 integers? I'm also greatly interested in how this is calculated as I'm trying to increase the expected number of times this process is repeated by changing the set sizes.","Suppose I have a set of 100 integers. I randomly choose 10 of those, make a note of which ones I selected, and repeat the process. What is the expected number of times this process must be repeated before I see all 100 integers? I'm also greatly interested in how this is calculated as I'm trying to increase the expected number of times this process is repeated by changing the set sizes.",,"['probability', 'optimization', 'combinations', 'expectation', 'coupon-collector']"
91,Algorithm for rolling an infinite-sided weighted die,Algorithm for rolling an infinite-sided weighted die,,"If I wanted to have a die that rolled, for example: | Roll | Prob (in %) | |------|-------------| | 1    | 60          | | 2    | 25          | | 3    | 12          | | 4    | 4           | | 5    | 1           | | 6    | 0.2         | | 7    | 0.04        | | ...  | ...         | (These numbers are off the top of my head, and don't necessarily follow a simple algorithm) What kinds of algorithms can I programmatically describe such that I could roll any 1 number with exponentially decreasing odds? I was thinking that if I just generated a table of probabilities using an exponential curve I wouldn't be able to guarantee my function resolves; If I started at the 1 roll and had a few failures in a row, I might never have a succeeding roll; and I can't start at the other end at work my way towards a roll of 1 with a probability of 100% , because it's infinitely long and there is no end to start at 2 . So how can I pick a number from this distribution? If possible, the distribution should exponentially or quadratically decay, but any distribution that could conceivably model something like: 1. The number of rooms in a house 2. The number of items in a treasure chest 3. The number of eyeballs on a mutant A final but not necessary point of consideration would be the ease of which the algorithm can be modified to stretch/shorten the curve, to make low numbers less/more likely. 1: Barring computer precision; a roll of MAXINT or whatever would be the practical maximum 2: Again, in practice a computer could do it because there is a smallest float for the probability to be, but that would be horribly inefficient.  The average case would take billions of rolls, whereas a good algorithm could probably do it in O(1) by just picking some fraction and resolving it.","If I wanted to have a die that rolled, for example: | Roll | Prob (in %) | |------|-------------| | 1    | 60          | | 2    | 25          | | 3    | 12          | | 4    | 4           | | 5    | 1           | | 6    | 0.2         | | 7    | 0.04        | | ...  | ...         | (These numbers are off the top of my head, and don't necessarily follow a simple algorithm) What kinds of algorithms can I programmatically describe such that I could roll any 1 number with exponentially decreasing odds? I was thinking that if I just generated a table of probabilities using an exponential curve I wouldn't be able to guarantee my function resolves; If I started at the 1 roll and had a few failures in a row, I might never have a succeeding roll; and I can't start at the other end at work my way towards a roll of 1 with a probability of 100% , because it's infinitely long and there is no end to start at 2 . So how can I pick a number from this distribution? If possible, the distribution should exponentially or quadratically decay, but any distribution that could conceivably model something like: 1. The number of rooms in a house 2. The number of items in a treasure chest 3. The number of eyeballs on a mutant A final but not necessary point of consideration would be the ease of which the algorithm can be modified to stretch/shorten the curve, to make low numbers less/more likely. 1: Barring computer precision; a roll of MAXINT or whatever would be the practical maximum 2: Again, in practice a computer could do it because there is a smallest float for the probability to be, but that would be horribly inefficient.  The average case would take billions of rolls, whereas a good algorithm could probably do it in O(1) by just picking some fraction and resolving it.",,"['probability', 'exponential-function', 'infinite-groups']"
92,Dice outcomes probability,Dice outcomes probability,,"Two dice are rolled. What is the probability that the sum of the   numbers on the dice is at least 10 Let $Z$ denote the set of successful outcomes: $Z=\{(4,6),(6,4),(5,5),(5,6),(6,5),(6,6)\}\\ \text{Sample space: } S=6^2$ So the answer gives the probability as, $P=\frac{6}{36}$. My question is why are the pairs $(5,5),(6,6)$ only included once? The way I see it for two dice $D_1,D_2$ is it may appear as $D_1: 5,D_2: 5$ or $D_2: 5,D_1: 5$, so why don't we count for this as two outcomes?","Two dice are rolled. What is the probability that the sum of the   numbers on the dice is at least 10 Let $Z$ denote the set of successful outcomes: $Z=\{(4,6),(6,4),(5,5),(5,6),(6,5),(6,6)\}\\ \text{Sample space: } S=6^2$ So the answer gives the probability as, $P=\frac{6}{36}$. My question is why are the pairs $(5,5),(6,6)$ only included once? The way I see it for two dice $D_1,D_2$ is it may appear as $D_1: 5,D_2: 5$ or $D_2: 5,D_1: 5$, so why don't we count for this as two outcomes?",,['probability']
93,Proving negative binomial distribution has a valid pmf,Proving negative binomial distribution has a valid pmf,,"I'm trying to prove $$\sum_{k=r}^\infty \binom{k-1}{r-1}p^rq^{k-r}= 1$$ I'm given a hint to use $(a+b)^m = \sum_{k=0}^\infty \binom{m}{k} a^kb^{m-k}$. I choose to let $a = -q$, $b = 1$, $m = -r$ and I get $$(1-q)^{-r} = \sum_{k=0}^\infty \dfrac{(-r)(-r-1)...(-r-k +1)}{k!}(-q)^k$$ However I am not sure how to transform $$\sum_{k=r}^\infty \binom{k-1}{r-1}p^rq^{k-r} = p^r \sum_{k=r}^\infty \binom{k-1}{r-1}q^{k-r}$$ to something which can use that identity edit: $q = 1-p$","I'm trying to prove $$\sum_{k=r}^\infty \binom{k-1}{r-1}p^rq^{k-r}= 1$$ I'm given a hint to use $(a+b)^m = \sum_{k=0}^\infty \binom{m}{k} a^kb^{m-k}$. I choose to let $a = -q$, $b = 1$, $m = -r$ and I get $$(1-q)^{-r} = \sum_{k=0}^\infty \dfrac{(-r)(-r-1)...(-r-k +1)}{k!}(-q)^k$$ However I am not sure how to transform $$\sum_{k=r}^\infty \binom{k-1}{r-1}p^rq^{k-r} = p^r \sum_{k=r}^\infty \binom{k-1}{r-1}q^{k-r}$$ to something which can use that identity edit: $q = 1-p$",,['probability']
94,Gambling problem,Gambling problem,,"Question Robert will win $\$1$ with probability $\frac{1}{4}$, win $\$2$ with probability $\frac{1}{4}$, and lose $\$1$ with probability $\frac{1}{2}$ in a bet. Each bet is independent. Determine the probability that Robert will win at most $\$20$ after betting $100$ times. Attempt Let $X$ be the amount of money that Robert wins. I know how to determine expected money that Robert would get each bet i.e. $E[X]=\$1\cdot\frac{1}{4}+\$2\cdot\frac{1}{4}-\$1\cdot\frac{1}{2}=\$0.25$. I think the probability would be $100\%$ because after betting $100$ times the expected money that he would get is $\$0.25\cdot100=\$25$, but it's definitely wrong. What is the correct approach to solve this problem? Any help would be appreciated. Thanks in advance.","Question Robert will win $\$1$ with probability $\frac{1}{4}$, win $\$2$ with probability $\frac{1}{4}$, and lose $\$1$ with probability $\frac{1}{2}$ in a bet. Each bet is independent. Determine the probability that Robert will win at most $\$20$ after betting $100$ times. Attempt Let $X$ be the amount of money that Robert wins. I know how to determine expected money that Robert would get each bet i.e. $E[X]=\$1\cdot\frac{1}{4}+\$2\cdot\frac{1}{4}-\$1\cdot\frac{1}{2}=\$0.25$. I think the probability would be $100\%$ because after betting $100$ times the expected money that he would get is $\$0.25\cdot100=\$25$, but it's definitely wrong. What is the correct approach to solve this problem? Any help would be appreciated. Thanks in advance.",,"['probability', 'statistics', 'probability-theory', 'game-theory']"
95,Bolzano–Weierstrass theorem for random variables?,Bolzano–Weierstrass theorem for random variables?,,"I am wondering if there is something similar to the Bolzano–Weierstrass theorem for random sequences. Namely, let $\{x_n\}$ be a bounded random sequence. Is it true that, under some reasonable conditions (I cannot be specific), there exists a subsequence of it that converges almost surely to a constant (not random variable)? thanks in advance.","I am wondering if there is something similar to the Bolzano–Weierstrass theorem for random sequences. Namely, let $\{x_n\}$ be a bounded random sequence. Is it true that, under some reasonable conditions (I cannot be specific), there exists a subsequence of it that converges almost surely to a constant (not random variable)? thanks in advance.",,"['real-analysis', 'probability', 'convergence-divergence', 'random-variables']"
96,What is the probability that at least one letter is in the correct envelope?,What is the probability that at least one letter is in the correct envelope?,,"A secretary types three letters and the three corresponding envelopes. In a hurry, he places at random one letter in each envelope. What is the probability that at least one letter is in the correct envelope? My effort: There are three choices of an envelope for the first letter, then there are two choices of an envelope for the second letter, and finally there is one choice of an envelope for the third letter, thereby making a total of six possible choices. Now we should first try to compute the probability that none of the three letters is in the correct envelope. But how to compute this probability? Once we know this probability, then our required probability is one minus this probability.","A secretary types three letters and the three corresponding envelopes. In a hurry, he places at random one letter in each envelope. What is the probability that at least one letter is in the correct envelope? My effort: There are three choices of an envelope for the first letter, then there are two choices of an envelope for the second letter, and finally there is one choice of an envelope for the third letter, thereby making a total of six possible choices. Now we should first try to compute the probability that none of the three letters is in the correct envelope. But how to compute this probability? Once we know this probability, then our required probability is one minus this probability.",,"['probability', 'statistics', 'probability-theory']"
97,Probablity that 3 husbands sit next to their wives round a circular table,Probablity that 3 husbands sit next to their wives round a circular table,,"There are 3 couples sitting randomly round a 6-seater circular table. What is the probability that all the husbands and wives sit next to each other? My attempt: First wife, say, takes any of the six seats.  That leaves 2/5 seats where her husband can sit next to her. Second wife, say, can take any of the four remaining seats.  There is then only 1 seat out of the remaining 3 where her husband can sit next to her AND leave two empty adjacent seats for the last couple. So the answer is 2/5 * 1/3 = 2/15.","There are 3 couples sitting randomly round a 6-seater circular table. What is the probability that all the husbands and wives sit next to each other? My attempt: First wife, say, takes any of the six seats.  That leaves 2/5 seats where her husband can sit next to her. Second wife, say, can take any of the four remaining seats.  There is then only 1 seat out of the remaining 3 where her husband can sit next to her AND leave two empty adjacent seats for the last couple. So the answer is 2/5 * 1/3 = 2/15.",,"['probability', 'combinatorics']"
98,Upper Bound for $p(1-p) $ where $0 \le p \le 1$,Upper Bound for  where,p(1-p)  0 \le p \le 1,"In a book on statistics, I've seen the upper bound of $p(1-p) $ to be $$ p(1-p) \le \frac{1}{4} $$ for $0 \le p \le 1$ which seemed correct. I tried to duplicate this with a simple derivation, $$p(1-p) = C$$ $$p-p^2 = C$$ Taking derivatives of both sides, gives $$1-2p=0$$ $$p=\frac{1}{2}$$ which is the value of $p$ at the maximum, and $1/2*1/2 = 1/4$. I obtained this without using the constraint $0 \le p \le 1$ though. How would I include this constraint? Through Lagrange? Is that overkill?","In a book on statistics, I've seen the upper bound of $p(1-p) $ to be $$ p(1-p) \le \frac{1}{4} $$ for $0 \le p \le 1$ which seemed correct. I tried to duplicate this with a simple derivation, $$p(1-p) = C$$ $$p-p^2 = C$$ Taking derivatives of both sides, gives $$1-2p=0$$ $$p=\frac{1}{2}$$ which is the value of $p$ at the maximum, and $1/2*1/2 = 1/4$. I obtained this without using the constraint $0 \le p \le 1$ though. How would I include this constraint? Through Lagrange? Is that overkill?",,"['calculus', 'probability', 'inequality', 'quadratics']"
99,Why is using $p$-values bad?,Why is using -values bad?,p,"I was reading this article on nature, and it seems to suggest that using $p$-values is bad, yet most of the textbooks I have read about statistics use $p$-value as a method of rejecting the null-hypothesis.  I am confused, why would textbook teach a method if it is so flawed.","I was reading this article on nature, and it seems to suggest that using $p$-values is bad, yet most of the textbooks I have read about statistics use $p$-value as a method of rejecting the null-hypothesis.  I am confused, why would textbook teach a method if it is so flawed.",,"['probability', 'statistics']"
