,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Can a linear subspace in Banach space be the union of several other subspaces?,Can a linear subspace in Banach space be the union of several other subspaces?,,"It's a well known exercise for students to prove that a linear subspace of $\mathbb{R}^n$ can't be expressed as the countable union of other subspaces. The proof is quite simple, including only the comparison of Lebesgue measure. However, it is not true for the linear space of polynomials. It can be the union of the subspace of degree 1 polynomials, polynomials of degree $\leq 2$, degree $\le 3$, .... By Baire's theorem, a Banach space cannot be covered by countable number of closed subspaces. So my question is whether a (Banach) vector space of uncountable dimension can be written the union of countably many proper subspaces. PS: I know it is rude to consider union of linear subspaces--it may be more appropriate to consider sums.... Just like Goldbach, one should not try to add primes, but multiply them:)","It's a well known exercise for students to prove that a linear subspace of $\mathbb{R}^n$ can't be expressed as the countable union of other subspaces. The proof is quite simple, including only the comparison of Lebesgue measure. However, it is not true for the linear space of polynomials. It can be the union of the subspace of degree 1 polynomials, polynomials of degree $\leq 2$, degree $\le 3$, .... By Baire's theorem, a Banach space cannot be covered by countable number of closed subspaces. So my question is whether a (Banach) vector space of uncountable dimension can be written the union of countably many proper subspaces. PS: I know it is rude to consider union of linear subspaces--it may be more appropriate to consider sums.... Just like Goldbach, one should not try to add primes, but multiply them:)",,"['linear-algebra', 'functional-analysis', 'banach-spaces', 'topological-vector-spaces']"
1,Computing the Frechet differentials,Computing the Frechet differentials,,"I am new to differential calculus on normed spaces and I struggle with some easy things. Let $- \infty <a < b< +\infty$ and $[a, b]$ denote a finite interval. Let $C[a,b]$ denote the collection of all real-valued continuous   functions defined on $[a,b]$. Then, endowed with the usual choice of   norm $\|x\| = \max_{a\leq t \leq b} |x(t)|$, $C[a,b]$ is a Banach   space. Let $\phi \colon \mathbb{R} \to \mathbb{R}$ be a twice differentiable   function, and suppose that its inverse $\phi^{-1} \colon \mathbb{R}  \to \mathbb{R}$ exists and is still twice differentiable. Let the kernel function $K \colon [a,b] \times [a,b] \to \mathbb{R}$ be continuous. Does the Frechet derivative of the   following operator $A$ exist? $$ [A(x)](s) =    \int^b_a K(s,t) \, [ x(t)] \,\mathrm{d}t $$ for all   $x \in C[a,b]$ and for all $s \in [a,b]$. Any ideas or suggestions are much appreciated! Thanks in advance:)","I am new to differential calculus on normed spaces and I struggle with some easy things. Let $- \infty <a < b< +\infty$ and $[a, b]$ denote a finite interval. Let $C[a,b]$ denote the collection of all real-valued continuous   functions defined on $[a,b]$. Then, endowed with the usual choice of   norm $\|x\| = \max_{a\leq t \leq b} |x(t)|$, $C[a,b]$ is a Banach   space. Let $\phi \colon \mathbb{R} \to \mathbb{R}$ be a twice differentiable   function, and suppose that its inverse $\phi^{-1} \colon \mathbb{R}  \to \mathbb{R}$ exists and is still twice differentiable. Let the kernel function $K \colon [a,b] \times [a,b] \to \mathbb{R}$ be continuous. Does the Frechet derivative of the   following operator $A$ exist? $$ [A(x)](s) =    \int^b_a K(s,t) \, [ x(t)] \,\mathrm{d}t $$ for all   $x \in C[a,b]$ and for all $s \in [a,b]$. Any ideas or suggestions are much appreciated! Thanks in advance:)",,"['calculus', 'real-analysis', 'functional-analysis', 'ordinary-differential-equations', 'derivatives']"
2,Resolvent estimate self-adjoint operator,Resolvent estimate self-adjoint operator,,"Let $A:D(A)\longrightarrow H$ be an unbounded self-adjoint (or normal) operator on a Hilbert space $H$. Then we know that $\sigma(A) \neq \emptyset$ and $$\|(\lambda-A)^{-1}\|=\frac{1}{d(\lambda,\sigma(A))}, \quad \forall \lambda \in \rho(A),$$ where $d(\lambda,\sigma(A))=\min_{\mu \in \sigma(A)} |\lambda-\mu|>0$. Do we have a similar formula for $$\|A(\lambda-A)^{-1}\|= ?$$ I point out that $A(\lambda-A)^{-1}$ is a bounded operator since $A(\lambda-A)^{-1}x=-x+\lambda(\lambda-A)^{-1}x$ for any $x \in H$. I have the basic estimate $$\|A(\lambda-A)^{-1}\| \leq 1+\frac{|\lambda|}{d(\lambda,\sigma(A))}.$$ Is it sharp ?","Let $A:D(A)\longrightarrow H$ be an unbounded self-adjoint (or normal) operator on a Hilbert space $H$. Then we know that $\sigma(A) \neq \emptyset$ and $$\|(\lambda-A)^{-1}\|=\frac{1}{d(\lambda,\sigma(A))}, \quad \forall \lambda \in \rho(A),$$ where $d(\lambda,\sigma(A))=\min_{\mu \in \sigma(A)} |\lambda-\mu|>0$. Do we have a similar formula for $$\|A(\lambda-A)^{-1}\|= ?$$ I point out that $A(\lambda-A)^{-1}$ is a bounded operator since $A(\lambda-A)^{-1}x=-x+\lambda(\lambda-A)^{-1}x$ for any $x \in H$. I have the basic estimate $$\|A(\lambda-A)^{-1}\| \leq 1+\frac{|\lambda|}{d(\lambda,\sigma(A))}.$$ Is it sharp ?",,"['functional-analysis', 'operator-theory', 'spectral-theory']"
3,Convolution of a sequence of L1 function has uniformly convergence.,Convolution of a sequence of L1 function has uniformly convergence.,,"Problem: Let $f: \mathbb{R} \to \mathbb{R}$ be bounded uniformly continuous function. And $(K_{n})_{n=1}^{\infty}$ is a sequence of $L^{1}(\mathbb{R})$ function such that $\left\|K_{n}\right\|_{L^{1}} \leq M < +\infty$ $\int_{-\infty}^{\infty}K_{n}(x)dx \to 1$ as $n \to \infty$ $\int_{x:|x|> \delta} |K_{n}(x)| \to 0$ as $n \to \infty$. Then, $K_{n} *f \to f$ uniformly, where $*$ means a convolution. I think I solved this problem, however, I didn't use all conditions I have, especially the condition that $\left\|K_{n}\right\|_{L^{1}}$ is uniformly bounded. Could you check that whether my attempt is right or not? My attempt: Suppose $f\geq 0$. And $||f||_{\infty} <+\infty$ Note that for any $\delta >0$ and any $n \in \mathbb{N}$, $$\int_{-\infty}^{\infty}K_{n}(x)dx = \int_{|x|\leq \delta}K_{n}(x)dx+\int_{x:|x|> \delta} K_{n}(x) $$   and from the fact $|\int_{x:|x|> \delta} K_{n}(x)| \leq \int_{x:|x|> \delta} |K_{n}(x)|,$ $\int_{x:|x|> \delta} K_{n}(x)$ also converges to $0$, hence   $$\int_{|x|\leq \delta}K_{n}(x)dx \to 1 \textrm{ as } n \to \infty , \forall \delta>0. $$   Now from uniform continuity of $f$ and $f\geq 0$, for given $\epsilon>0$, $\exists \delta>0$ such that $$|x-y|<\delta \implies |f(y)-f(x)|<\epsilon \implies -\epsilon +f(x) < f(y) < \epsilon +f(x).$$   Also, take $N_{1}$ such that $\forall n > N_{1}$,     $$\left|\int_{|x|\leq \delta}K_{n}(x)dx - 1\right|< \epsilon \implies 1-\epsilon< \int_{|x|\leq \delta}K_{n}(x)dx<1+\epsilon.$$   Also, take $N_{2}$ such that $\forall n > N_{2}$,    $$\left|\int_{x:|x|> \delta} K_{n}(x)\right|< \epsilon.$$   Now let $N = \max(N_{1}, N_{2})$ Then, for any $x \in \mathbb{R}$ and $\forall n>N$,   \begin{align*} |K_{n}*f(x) - f(x)| &=  \left|\int_{|y|\leq \delta}K_{n}(y)f(x-y)dy+\int_{y:|y|> \delta} K_{n}(y)dy - f(x)\right| \\ & \leq \left|\int_{|y|\leq \delta}K_{n}(y)f(x-y)dx - f(x)\right| + \left|\int_{y:|y|> \delta} K_{n}(y)dy\right| \\ & \leq \left|(f(x)+\epsilon)(1+\epsilon) - f(x)\right| + \epsilon \\ & \leq \left|\epsilon f(x)+\epsilon(1+\epsilon)\right| + \epsilon \\ & \leq \epsilon(||f||_{\infty}+2+\epsilon) \end{align*}   Hence, by letting $\epsilon \to 0$, we can conclude that $K_{n}*f \to f$ uniformly. For general $f$, consider $f=f^{+}-f^{-}$, then each $f^{+}, f^{-}$ is also bounded uniformly continuous function, with the triangle inequality  $$|K_{n}*f - f| \leq|K_{n}*f^{+} - f^{+}|+|K_{n}*f^{-} - f^{-}| $$ gives the desired result.","Problem: Let $f: \mathbb{R} \to \mathbb{R}$ be bounded uniformly continuous function. And $(K_{n})_{n=1}^{\infty}$ is a sequence of $L^{1}(\mathbb{R})$ function such that $\left\|K_{n}\right\|_{L^{1}} \leq M < +\infty$ $\int_{-\infty}^{\infty}K_{n}(x)dx \to 1$ as $n \to \infty$ $\int_{x:|x|> \delta} |K_{n}(x)| \to 0$ as $n \to \infty$. Then, $K_{n} *f \to f$ uniformly, where $*$ means a convolution. I think I solved this problem, however, I didn't use all conditions I have, especially the condition that $\left\|K_{n}\right\|_{L^{1}}$ is uniformly bounded. Could you check that whether my attempt is right or not? My attempt: Suppose $f\geq 0$. And $||f||_{\infty} <+\infty$ Note that for any $\delta >0$ and any $n \in \mathbb{N}$, $$\int_{-\infty}^{\infty}K_{n}(x)dx = \int_{|x|\leq \delta}K_{n}(x)dx+\int_{x:|x|> \delta} K_{n}(x) $$   and from the fact $|\int_{x:|x|> \delta} K_{n}(x)| \leq \int_{x:|x|> \delta} |K_{n}(x)|,$ $\int_{x:|x|> \delta} K_{n}(x)$ also converges to $0$, hence   $$\int_{|x|\leq \delta}K_{n}(x)dx \to 1 \textrm{ as } n \to \infty , \forall \delta>0. $$   Now from uniform continuity of $f$ and $f\geq 0$, for given $\epsilon>0$, $\exists \delta>0$ such that $$|x-y|<\delta \implies |f(y)-f(x)|<\epsilon \implies -\epsilon +f(x) < f(y) < \epsilon +f(x).$$   Also, take $N_{1}$ such that $\forall n > N_{1}$,     $$\left|\int_{|x|\leq \delta}K_{n}(x)dx - 1\right|< \epsilon \implies 1-\epsilon< \int_{|x|\leq \delta}K_{n}(x)dx<1+\epsilon.$$   Also, take $N_{2}$ such that $\forall n > N_{2}$,    $$\left|\int_{x:|x|> \delta} K_{n}(x)\right|< \epsilon.$$   Now let $N = \max(N_{1}, N_{2})$ Then, for any $x \in \mathbb{R}$ and $\forall n>N$,   \begin{align*} |K_{n}*f(x) - f(x)| &=  \left|\int_{|y|\leq \delta}K_{n}(y)f(x-y)dy+\int_{y:|y|> \delta} K_{n}(y)dy - f(x)\right| \\ & \leq \left|\int_{|y|\leq \delta}K_{n}(y)f(x-y)dx - f(x)\right| + \left|\int_{y:|y|> \delta} K_{n}(y)dy\right| \\ & \leq \left|(f(x)+\epsilon)(1+\epsilon) - f(x)\right| + \epsilon \\ & \leq \left|\epsilon f(x)+\epsilon(1+\epsilon)\right| + \epsilon \\ & \leq \epsilon(||f||_{\infty}+2+\epsilon) \end{align*}   Hence, by letting $\epsilon \to 0$, we can conclude that $K_{n}*f \to f$ uniformly. For general $f$, consider $f=f^{+}-f^{-}$, then each $f^{+}, f^{-}$ is also bounded uniformly continuous function, with the triangle inequality  $$|K_{n}*f - f| \leq|K_{n}*f^{+} - f^{+}|+|K_{n}*f^{-} - f^{-}| $$ gives the desired result.",,"['real-analysis', 'functional-analysis', 'convolution']"
4,"Continuous linear operator, $T: (C[0,1],\|\cdot\|_p)\to (C[0,1],\|\cdot\|_p)$ continuous for some $p$","Continuous linear operator,  continuous for some","T: (C[0,1],\|\cdot\|_p)\to (C[0,1],\|\cdot\|_p) p","Observe $C[0,1]$ and for $1\leq p<\infty$ the norm $\|f\|_p=\left(\int_0^1 |f(t)|^p\, dt\right)^{1/p}$. Let $T: C[0,1]\to C[0,1]$ be an arbitrary linear operator. Show, that when it exists a $1\leq p<\infty$ such that $T: (C[0,1],\|\cdot\|_p)\to (C[0,1],\|\cdot\|_p)$ is continuous, then is $T: (C[0,1],\|\cdot\|_\infty)\to (C[0,1],\|\cdot\|_\infty)$ continuous. I do not really know how to start here. Thanks in advance for any help.","Observe $C[0,1]$ and for $1\leq p<\infty$ the norm $\|f\|_p=\left(\int_0^1 |f(t)|^p\, dt\right)^{1/p}$. Let $T: C[0,1]\to C[0,1]$ be an arbitrary linear operator. Show, that when it exists a $1\leq p<\infty$ such that $T: (C[0,1],\|\cdot\|_p)\to (C[0,1],\|\cdot\|_p)$ is continuous, then is $T: (C[0,1],\|\cdot\|_\infty)\to (C[0,1],\|\cdot\|_\infty)$ continuous. I do not really know how to start here. Thanks in advance for any help.",,['functional-analysis']
5,On the proof of the Hermitian functions being a basis of $L^2(R)$ space.,On the proof of the Hermitian functions being a basis of  space.,L^2(R),Define $h_k(x) = H_k(x) e^{- x^2/2} $ where $H_k(x)$ is the k-th Hermitian polynomial. Assuming already having shown that the $h_k(x)$ form an orthonormal system in $L^2(R)$ with the usual inner product how can one prove that they are a basis?,Define $h_k(x) = H_k(x) e^{- x^2/2} $ where $H_k(x)$ is the k-th Hermitian polynomial. Assuming already having shown that the $h_k(x)$ form an orthonormal system in $L^2(R)$ with the usual inner product how can one prove that they are a basis?,,"['real-analysis', 'functional-analysis', 'hilbert-spaces']"
6,Is there a reverse triangle inequality equivalent for $L^p$ spaces with $0<p<1$?,Is there a reverse triangle inequality equivalent for  spaces with ?,L^p 0<p<1,"I was trying to follow the proof for the reverse triangle inequality in the reals, but I got an inconsistency. Obviously, something is wrong, but I can't see what. Here is what I did: In $L^p$ spaces with $0<p<1$, we have the reverse Minkowski's inequality: $$||f+g||_p \geq ||f||_p + ||g||_p$$ So the following derivation is true: $||f+g||_p - ||f||_p \geq ||g||_p$ Given that this is true for any $f,g \in L^p$, we can substitute $g$ with $g-f$ to get: $||g||_p - ||f||_p \geq ||g-f||_p \tag{1}\label{1}$ On the other hand, from reverse Minkowski's inequality, we get: $||f+g||_p - ||g||_p \geq ||f||_p$ Substituting $f$ with $f-g$ we get: $||f||_p - ||g||_p \geq ||f-g||_p$ Multiplying by $-1$, we therefore obtain: $||g||_p - ||f||_p \leq -||g-f||_p\tag{2}\label{2}$ Equations \ref{1} and \ref{2} are supposed to be true at the same time, but they are obviously inconsistent. However, I cannot find any mistake in my reasoning. What have I done wrong?","I was trying to follow the proof for the reverse triangle inequality in the reals, but I got an inconsistency. Obviously, something is wrong, but I can't see what. Here is what I did: In $L^p$ spaces with $0<p<1$, we have the reverse Minkowski's inequality: $$||f+g||_p \geq ||f||_p + ||g||_p$$ So the following derivation is true: $||f+g||_p - ||f||_p \geq ||g||_p$ Given that this is true for any $f,g \in L^p$, we can substitute $g$ with $g-f$ to get: $||g||_p - ||f||_p \geq ||g-f||_p \tag{1}\label{1}$ On the other hand, from reverse Minkowski's inequality, we get: $||f+g||_p - ||g||_p \geq ||f||_p$ Substituting $f$ with $f-g$ we get: $||f||_p - ||g||_p \geq ||f-g||_p$ Multiplying by $-1$, we therefore obtain: $||g||_p - ||f||_p \leq -||g-f||_p\tag{2}\label{2}$ Equations \ref{1} and \ref{2} are supposed to be true at the same time, but they are obviously inconsistent. However, I cannot find any mistake in my reasoning. What have I done wrong?",,"['real-analysis', 'functional-analysis', 'inequality', 'lp-spaces']"
7,Orthogonal Projection of a function onto $M$ [closed],Orthogonal Projection of a function onto  [closed],M,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question Let $I_1, · · · , I_N$ be pairwise disjoint intervals whose union is $[0,1]$. Let   $$M = \lbrace g ∈ L^2([0,1]) :\text{ g is constant on $I_n$ } \forall n \rbrace.$$    Suppose $f \in L^2([0,1])$. Determine $P_M f$. Please help.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question Let $I_1, · · · , I_N$ be pairwise disjoint intervals whose union is $[0,1]$. Let   $$M = \lbrace g ∈ L^2([0,1]) :\text{ g is constant on $I_n$ } \forall n \rbrace.$$    Suppose $f \in L^2([0,1])$. Determine $P_M f$. Please help.",,"['functional-analysis', 'hilbert-spaces', 'approximation-theory']"
8,"{$x_1, x_2, ...,x_n$} is linearly independent in normed space $X$. Show for any scalars $a_1, ..., a_n$ there is $f$ in dual $X'$ with $f(x_i) = a_i$",{} is linearly independent in normed space . Show for any scalars  there is  in dual  with,"x_1, x_2, ...,x_n X a_1, ..., a_n f X' f(x_i) = a_i","Let $X$ be a normed space, $n\in N$ and {$x_1, x_2, ...,x_n$} be a linearly independent set in $X$. Prove that for any scalars $\alpha_1, \alpha_2, ..., \alpha_n$ there exists $f$ in the dual space $X'$ such that $f(x_i) = \alpha_i$; $ i = 1, 2, ..., n$. (I tried it by using the theorem: For any non-zero $x_0$ in a normed space $X$ we have a linear functional $f$ such that $||f||=1 $ and $f(x_0)=||x_0||$. But I could not succeed. )","Let $X$ be a normed space, $n\in N$ and {$x_1, x_2, ...,x_n$} be a linearly independent set in $X$. Prove that for any scalars $\alpha_1, \alpha_2, ..., \alpha_n$ there exists $f$ in the dual space $X'$ such that $f(x_i) = \alpha_i$; $ i = 1, 2, ..., n$. (I tried it by using the theorem: For any non-zero $x_0$ in a normed space $X$ we have a linear functional $f$ such that $||f||=1 $ and $f(x_0)=||x_0||$. But I could not succeed. )",,"['functional-analysis', 'linear-transformations', 'dual-spaces']"
9,Tensor product of two distributions $u \in \mathcal{D}(X)$ and $v \in \mathcal{D}(Y)$,Tensor product of two distributions  and,u \in \mathcal{D}(X) v \in \mathcal{D}(Y),"I'm following the proof of the theorem 4.3.3 p. 47 of ""Introduction to the distributions theory"" by Friedlander and Joshi. We have the following identity \begin{align*} \textbf{(1)}  \displaystyle \langle u \otimes v, \varphi \rangle = \langle v(y), \langle u(x), \varphi(x,y) \rangle \rangle = \langle u(x), \langle v(y), \varphi(x,y) \rangle \rangle \end{align*} where $\varphi \in \mathcal{D}(X\times Y)$. Ok I understand that this identity is worth. However, the same theorem, there is the next point $\textbf{(4)}$ The tensor product is a separately continuous bilinear form on $\mathcal{D}'(X) \times \mathcal{D}'(Y)$ and in the proof it says that $(4)$ is immediate consequence of $(1)$. Sincerely, I did not understand what it means ""separately"" and how $(1)$ implies $(4)$. Thank you for each reply.","I'm following the proof of the theorem 4.3.3 p. 47 of ""Introduction to the distributions theory"" by Friedlander and Joshi. We have the following identity \begin{align*} \textbf{(1)}  \displaystyle \langle u \otimes v, \varphi \rangle = \langle v(y), \langle u(x), \varphi(x,y) \rangle \rangle = \langle u(x), \langle v(y), \varphi(x,y) \rangle \rangle \end{align*} where $\varphi \in \mathcal{D}(X\times Y)$. Ok I understand that this identity is worth. However, the same theorem, there is the next point $\textbf{(4)}$ The tensor product is a separately continuous bilinear form on $\mathcal{D}'(X) \times \mathcal{D}'(Y)$ and in the proof it says that $(4)$ is immediate consequence of $(1)$. Sincerely, I did not understand what it means ""separately"" and how $(1)$ implies $(4)$. Thank you for each reply.",,"['functional-analysis', 'distribution-theory', 'locally-convex-spaces']"
10,"If $f\in L^1(\Bbb R,dx)$ then prove that for almost every $x\in\Bbb R$ $\lim\limits_{n\to \infty} f(nx) = 0.$",If  then prove that for almost every,"f\in L^1(\Bbb R,dx) x\in\Bbb R \lim\limits_{n\to \infty} f(nx) = 0.","If $f\in L^1(\Bbb R,dx)$ Then prove that for almost every $x\in\Bbb R$ $$\lim_{n\to \infty} f(nx) = 0$$ Be aware this statement is different from the following: $$ f\in L^1(\Bbb R,dx)\implies  \lim_{|x|\to \infty} f(x) = 0$$ which is a false statement. Indeed, We set the functionn $f$ ([see its construction here}[1]) \begin{equation} f(x)= \begin{cases}  2^{n/2}\cdot \underbrace{-2^{2n+2}(x-n)^2+2^{n+2}(x-n)}_{P_n}& \text{if} ~~ n\le x\le n+\frac{1}{2^n} ~~\text{for some $n\in\mathbb{N}$}\\ 0 &\text{ if}~~~j+\frac{1}{2^j}\le x\le j+1~~\text{for some $j\in\mathbb{N}$}\\ f(-x)& \text{if }~~x\lt  0. \end{cases} \end{equation} ( $h =1$ , $ \varepsilon_n  =\frac{1}{2^n}$ , $a_n = n$ and $b_n =n+\frac{1}{2^n}$ ) One can check that $f$ is an even and continuous function. Further, we have $$ \int_\mathbb{R} f(x)\,dx= 2\sum_{n=0}^{\infty}\int_{n}^{n+\frac{1}{2^n}}2^{n/2} P_n(x) dx = 2\sum_{n=0}^{\infty}-4.2^{n/2} \left[ \frac{2^{2n}}{3}(x-n)^3-\frac{2^n}{2}(x-n)^2\right]_{n}^{n+\frac{1}{2^n}}\\ = \frac43\sum_{n=0}^{\infty} \frac{1}{2^{n/2}}<\infty $$ Morerover, for every $n\in\mathbb{N}$ one has $$f(n) = 0~~~~\text{and} ~~~f(n+\frac{1}{2^{n+1}}) = 2^{n/2} $$ Therefore $$\lim_{|x| \to \infty}|f(x)|\not \to 0 $$ further, $\lim_{|x| \to \infty}|f(x)|$ does not exist. Whereas in this case for all $x\not \in \{n+\frac{1}{2^{n+1}}, n \in \Bbb N\} $ $$\lim_{j\to \infty} f(jx) = 0$$ I also tried to construct a contradiction with this function Does this integral converge or diverge ? $\int_\Bbb R \left (\frac{2+\cos x}{3}\right )^{x^4}dx?$ . Sill we have $$\lim_{j\to \infty} f(jx) = 0~~~~x\not\in \{2n\pi:~~ n \in \Bbb N\}$$ Also notice that this question is differ from Let $f\in L^1(R)$ set $f_n(x)=\dfrac{f(nx)}{n}$ prove that $\lim_{n \to \infty}f_n=0$ for a.e x Prove that for almost every $x\in$ $\mathbb{R}$ , $\lim_{n\to\infty}n^{-p}f(nx)=0$ . where the situation is easy to manage. [1]: https://math.stackexchange.com/q/2143818","If Then prove that for almost every Be aware this statement is different from the following: which is a false statement. Indeed, We set the functionn ([see its construction here}[1]) ( , , and ) One can check that is an even and continuous function. Further, we have Morerover, for every one has Therefore further, does not exist. Whereas in this case for all I also tried to construct a contradiction with this function Does this integral converge or diverge ? $\int_\Bbb R \left (\frac{2+\cos x}{3}\right )^{x^4}dx?$ . Sill we have Also notice that this question is differ from Let $f\in L^1(R)$ set $f_n(x)=\dfrac{f(nx)}{n}$ prove that $\lim_{n \to \infty}f_n=0$ for a.e x Prove that for almost every $x\in$ $\mathbb{R}$ , $\lim_{n\to\infty}n^{-p}f(nx)=0$ . where the situation is easy to manage. [1]: https://math.stackexchange.com/q/2143818","f\in L^1(\Bbb R,dx) x\in\Bbb R \lim_{n\to \infty} f(nx) = 0  f\in L^1(\Bbb R,dx)\implies  \lim_{|x|\to \infty} f(x) = 0 f \begin{equation}
f(x)= \begin{cases}
 2^{n/2}\cdot \underbrace{-2^{2n+2}(x-n)^2+2^{n+2}(x-n)}_{P_n}& \text{if} ~~ n\le x\le n+\frac{1}{2^n} ~~\text{for some n\in\mathbb{N}}\\
0 &\text{ if}~~~j+\frac{1}{2^j}\le x\le j+1~~\text{for some j\in\mathbb{N}}\\ f(-x)& \text{if }~~x\lt  0.
\end{cases}
\end{equation} h =1  \varepsilon_n  =\frac{1}{2^n} a_n = n b_n =n+\frac{1}{2^n} f  \int_\mathbb{R} f(x)\,dx= 2\sum_{n=0}^{\infty}\int_{n}^{n+\frac{1}{2^n}}2^{n/2} P_n(x) dx = 2\sum_{n=0}^{\infty}-4.2^{n/2}
\left[ \frac{2^{2n}}{3}(x-n)^3-\frac{2^n}{2}(x-n)^2\right]_{n}^{n+\frac{1}{2^n}}\\
= \frac43\sum_{n=0}^{\infty} \frac{1}{2^{n/2}}<\infty  n\in\mathbb{N} f(n) = 0~~~~\text{and} ~~~f(n+\frac{1}{2^{n+1}}) = 2^{n/2}  \lim_{|x| \to \infty}|f(x)|\not \to 0  \lim_{|x| \to \infty}|f(x)| x\not \in \{n+\frac{1}{2^{n+1}}, n \in \Bbb N\}  \lim_{j\to \infty} f(jx) = 0 \lim_{j\to \infty} f(jx) = 0~~~~x\not\in \{2n\pi:~~ n \in \Bbb N\}","['real-analysis', 'functional-analysis', 'measure-theory', 'lebesgue-integral', 'baire-category']"
11,How to show that $\|f+g\|_p=\|f\|_p+\|g\|_p$ implies $f$ and $g$ are positively linearly dependent?,How to show that  implies  and  are positively linearly dependent?,\|f+g\|_p=\|f\|_p+\|g\|_p f g,"Suppose $1<p<\infty$ and let $f,g\in L^p$. It is said in Wikipedia that $$ \|f+g\|_p=\|f\|_p+\|g\|_p\tag{*} $$ if and only if $f=cg$ for some $c\geq 0$ or $g=0$. The ""if"" direction is trivial. I would like to prove the other direction. (I believe this must have been asked before but I can't find one here.) Suppose (*) is true. By the triangle inequality $$ \|f+g\|_p\leq\||f|+|g|\|_p\leq\|f\|_p+\|g\|_p $$ and thus $$ \|f+g\|_p=\||f|+|g|\|_p $$ which yields $|f+g|=|f|+|g|$ almost everywhere. Suppose $g\neq 0$. Then for a.e. $x$, one has $$ f(x)=a(x)g(x) $$ for some $a(x)\geq 0$. I'm stuck here with showing that $a(x)$ is a constant.","Suppose $1<p<\infty$ and let $f,g\in L^p$. It is said in Wikipedia that $$ \|f+g\|_p=\|f\|_p+\|g\|_p\tag{*} $$ if and only if $f=cg$ for some $c\geq 0$ or $g=0$. The ""if"" direction is trivial. I would like to prove the other direction. (I believe this must have been asked before but I can't find one here.) Suppose (*) is true. By the triangle inequality $$ \|f+g\|_p\leq\||f|+|g|\|_p\leq\|f\|_p+\|g\|_p $$ and thus $$ \|f+g\|_p=\||f|+|g|\|_p $$ which yields $|f+g|=|f|+|g|$ almost everywhere. Suppose $g\neq 0$. Then for a.e. $x$, one has $$ f(x)=a(x)g(x) $$ for some $a(x)\geq 0$. I'm stuck here with showing that $a(x)$ is a constant.",,['real-analysis']
12,"Prove or give a counterexample: if $X=R\oplus N$ with $N$ finite dimensional, then $R$ is closed.","Prove or give a counterexample: if  with  finite dimensional, then  is closed.",X=R\oplus N N R,"Let $X$ be a Banach space and $N,R$ two subspace of $X$. Suppose further that    $X=N\oplus R$ (i.e., $N\cap R=\{0\}$ and $X=N+R$). If $N$ is finite dimensional, then does $R$ have to be closed? There is a famous ""weaker"" resut as follows: Let $X,Y$ be Banach spaces and $T\in L(X,Y)$. If there exists some finite dimensional subspace $N$  such that $Y=T(X)\oplus N$, then $T(X)$ is closed. This result is very useful in the theory of Fredholm operators. So I guess the previous result is NOT true. Otherwise, the textbook will prove the first one instead of the second one. I'm trying to construct a counterexample but can't find it.","Let $X$ be a Banach space and $N,R$ two subspace of $X$. Suppose further that    $X=N\oplus R$ (i.e., $N\cap R=\{0\}$ and $X=N+R$). If $N$ is finite dimensional, then does $R$ have to be closed? There is a famous ""weaker"" resut as follows: Let $X,Y$ be Banach spaces and $T\in L(X,Y)$. If there exists some finite dimensional subspace $N$  such that $Y=T(X)\oplus N$, then $T(X)$ is closed. This result is very useful in the theory of Fredholm operators. So I guess the previous result is NOT true. Otherwise, the textbook will prove the first one instead of the second one. I'm trying to construct a counterexample but can't find it.",,"['functional-analysis', 'operator-theory', 'banach-spaces']"
13,Is the inverse of an adjointable Hilbert module operator always adjointable?,Is the inverse of an adjointable Hilbert module operator always adjointable?,,"Suppose $T:E\rightarrow F$ is a bounded adjointable bijective operator between Hilbert $A$-modules, where $A$ is some $C^*$-algebra. Then by the opening mapping theorem one knows that the inverse map $F\rightarrow E$ (let's called it tentatively $T^{-1}$) is bounded. However, is it $T^{-1}$ always adjointable? If not, what is a concrete example? Thanks.","Suppose $T:E\rightarrow F$ is a bounded adjointable bijective operator between Hilbert $A$-modules, where $A$ is some $C^*$-algebra. Then by the opening mapping theorem one knows that the inverse map $F\rightarrow E$ (let's called it tentatively $T^{-1}$) is bounded. However, is it $T^{-1}$ always adjointable? If not, what is a concrete example? Thanks.",,"['functional-analysis', 'operator-theory', 'operator-algebras']"
14,A good resource on the Radon-Nikodym Property in reflexive Banach Spaces?,A good resource on the Radon-Nikodym Property in reflexive Banach Spaces?,,"I'm looking for a good resource that builds the theory of the Radon-Nikodym Property. I'm not particularly interested in the measure-theoretic characterisation; I'd like the geometry of Banach Spaces version, involving strongly exposed points of convex sets. If possible, I would also like the proofs to concentrate more a geometric approach over a convex/variational analysis approach, though this is not a deal-breaker. Thanks in advance.","I'm looking for a good resource that builds the theory of the Radon-Nikodym Property. I'm not particularly interested in the measure-theoretic characterisation; I'd like the geometry of Banach Spaces version, involving strongly exposed points of convex sets. If possible, I would also like the proofs to concentrate more a geometric approach over a convex/variational analysis approach, though this is not a deal-breaker. Thanks in advance.",,"['functional-analysis', 'reference-request', 'banach-spaces', 'geometric-functional-analysis']"
15,"Isn't my example contradicting that $\mathcal C[0,1]$ with sup norm is complete",Isn't my example contradicting that  with sup norm is complete,"\mathcal C[0,1]","We know that $\mathcal C[0,1]$ with sup norm is complete. However if we take the sequence of functions $(f_n)$ as below then one can see the internal distance between two functions $f_m,f_n$ are tending to zero at a point as $m,n$ are getting larger. However $f_n$ is tending nowhere as the left nonzero part of $f_n$ is tending to a vertical line and hence converge to the discontinuous function which is $0$ at 0 and $1-x$ in $(0,1]$: So where am I going wrong?","We know that $\mathcal C[0,1]$ with sup norm is complete. However if we take the sequence of functions $(f_n)$ as below then one can see the internal distance between two functions $f_m,f_n$ are tending to zero at a point as $m,n$ are getting larger. However $f_n$ is tending nowhere as the left nonzero part of $f_n$ is tending to a vertical line and hence converge to the discontinuous function which is $0$ at 0 and $1-x$ in $(0,1]$: So where am I going wrong?",,"['functional-analysis', 'banach-spaces', 'normed-spaces']"
16,IVP and Discontinuity,IVP and Discontinuity,,"I am continuing my effort to learn analysis from Thomson Bruckner and Bruckner's book. I ran into an interesting problem relating to Intermediate Value Property (IVP). The problem goes as follows: Suppse $f$ has IVP on $(a,b)$ and discontinuous at $x_0 \in (a,b)$. Prove that there exists a $y \in \mathbb{R}$ such that $\{x : f(x) = y\}$ is infinite. My Proof is as follows: Since $f$ is not continuous at $x_o$, we take a sequence of $x_i \rightarrow x_0$. We have for all $\forall \delta > 0 \ \exists n > N$  $|x_n - x_0| < \delta$. Let us consider a monotone subsequence of $x_i$. Now let  $k > N, \ x_k < x_{k+1} < \cdots < x_{k+m} \cdots < x_0$ be one such sequence. Let us say $\nexists y_i \in (x_k, x_{k+1}), y_{i+1} \in (x_{k+1}, x_{k+2}) \cdots$ such that $f(y_i) = f(y_{i+1}) = f(y_{i+2}) \cdots $ and $f(x_{k+i}) != f(x_{k+j}), \ i \ne j$. We have, $f$ by IVP, takes on all the values between $(f(x_k), f(x_0))$ since by our assumption $\nexists y_i \in (x_{k}, x_{k+1}) \cdots $ such that $f(y_i) = f(y_{i+1}) = \cdots$ i.e. $(f(x_{k+i}), f(x_{k+i+1}))$ are all mutually disjoint, our choice of $x_k$ ensures that $f(x_k)$ has a montonic sub-sequence and $\forall \epsilon > 0 \ \exists m > M, \ |f(x_m) - f(x_0)| < \epsilon$. A contradiction. Now to my QUESTION, is my proof right? It seems right to me. Thanks in advance to your answer.","I am continuing my effort to learn analysis from Thomson Bruckner and Bruckner's book. I ran into an interesting problem relating to Intermediate Value Property (IVP). The problem goes as follows: Suppse $f$ has IVP on $(a,b)$ and discontinuous at $x_0 \in (a,b)$. Prove that there exists a $y \in \mathbb{R}$ such that $\{x : f(x) = y\}$ is infinite. My Proof is as follows: Since $f$ is not continuous at $x_o$, we take a sequence of $x_i \rightarrow x_0$. We have for all $\forall \delta > 0 \ \exists n > N$  $|x_n - x_0| < \delta$. Let us consider a monotone subsequence of $x_i$. Now let  $k > N, \ x_k < x_{k+1} < \cdots < x_{k+m} \cdots < x_0$ be one such sequence. Let us say $\nexists y_i \in (x_k, x_{k+1}), y_{i+1} \in (x_{k+1}, x_{k+2}) \cdots$ such that $f(y_i) = f(y_{i+1}) = f(y_{i+2}) \cdots $ and $f(x_{k+i}) != f(x_{k+j}), \ i \ne j$. We have, $f$ by IVP, takes on all the values between $(f(x_k), f(x_0))$ since by our assumption $\nexists y_i \in (x_{k}, x_{k+1}) \cdots $ such that $f(y_i) = f(y_{i+1}) = \cdots$ i.e. $(f(x_{k+i}), f(x_{k+i+1}))$ are all mutually disjoint, our choice of $x_k$ ensures that $f(x_k)$ has a montonic sub-sequence and $\forall \epsilon > 0 \ \exists m > M, \ |f(x_m) - f(x_0)| < \epsilon$. A contradiction. Now to my QUESTION, is my proof right? It seems right to me. Thanks in advance to your answer.",,"['real-analysis', 'functional-analysis', 'analysis']"
17,"self-adjoint operator, such that $T^2=T^3,$ is orthogonal projection.","self-adjoint operator, such that  is orthogonal projection.","T^2=T^3,","Let $T$ be a self-adjoint operator on a Hilbert space $H$, such that $T^2=T^3.$   Prove that $T$ is an orthogonal projection. Is that true if we had $T^4=T^3$? Thank you for the help.","Let $T$ be a self-adjoint operator on a Hilbert space $H$, such that $T^2=T^3.$   Prove that $T$ is an orthogonal projection. Is that true if we had $T^4=T^3$? Thank you for the help.",,"['functional-analysis', 'operator-theory', 'hilbert-spaces', 'adjoint-operators']"
18,Image of $A^\frac{1}{2}$ equal to image of $A$,Image of  equal to image of,A^\frac{1}{2} A,"Let $A\in B(H)$ be a closed range positive operator, and $A^\frac{1}{2}$ its square root. Clearly image of $A$ is a subset of image of $A^\frac{1}{2}~~$($R(A)\subset R(A^\frac{1}{2})$). How do we prove $R(A)= R(A^\frac{1}{2})$?  I edite the question","Let $A\in B(H)$ be a closed range positive operator, and $A^\frac{1}{2}$ its square root. Clearly image of $A$ is a subset of image of $A^\frac{1}{2}~~$($R(A)\subset R(A^\frac{1}{2})$). How do we prove $R(A)= R(A^\frac{1}{2})$?  I edite the question",,['functional-analysis']
19,Show that the divergence operator is onto,Show that the divergence operator is onto,,"Came across this while reading Temam's text on Navier Stokes. Lemma 2.4 states that the divergence operator $\nabla\cdot$ maps $\bf{H}_0^1(\Omega)$ $\textit{onto}$ $L^2(\Omega)/\mathbb{R}$ where the latter is the subspace of $L^2(\Omega)$ of elements $f$ satisfying $\int_\Omega f=0$. To prove this statement we consider $A=\nabla$ (the gradient operator) defined on $L^2(\Omega)$ (mapping into $\bf{H}^{-1}(\Omega)$). Earlier, it'd been shown that the operator $A$ restricted to $L^2(\Omega)/\mathbb{R}$ is injective. So if we simply set $R(A):=A(L^2(\Omega)/\mathbb{R})\,(=A(L^2(\Omega))$, we know that $A$ is an isomorphism between $L^2(\Omega)/\mathbb{R}$ and $R(A)$. So far, I don't think anything profound has been said. Now, the proof proceeds with the following statement (paraphrased): by transposition, the adjoint $A^*\in L(\bf{H_0^1(\Omega)}$ $,L^2(\Omega))$ is an isomorphism from the $\textit{orthogonal}$ of $R(A)$  $\textit{onto}$ $L^2(\Omega)/\mathbb{R}$. My question is, what's the justification for this last statement??  Perhaps I'm a little rusty, but I'm guessing I'm failing to make the necessary manipulations to relate the ranges of $A$ and $A^*$ and the orthogonal spaces of them etc. etc.","Came across this while reading Temam's text on Navier Stokes. Lemma 2.4 states that the divergence operator $\nabla\cdot$ maps $\bf{H}_0^1(\Omega)$ $\textit{onto}$ $L^2(\Omega)/\mathbb{R}$ where the latter is the subspace of $L^2(\Omega)$ of elements $f$ satisfying $\int_\Omega f=0$. To prove this statement we consider $A=\nabla$ (the gradient operator) defined on $L^2(\Omega)$ (mapping into $\bf{H}^{-1}(\Omega)$). Earlier, it'd been shown that the operator $A$ restricted to $L^2(\Omega)/\mathbb{R}$ is injective. So if we simply set $R(A):=A(L^2(\Omega)/\mathbb{R})\,(=A(L^2(\Omega))$, we know that $A$ is an isomorphism between $L^2(\Omega)/\mathbb{R}$ and $R(A)$. So far, I don't think anything profound has been said. Now, the proof proceeds with the following statement (paraphrased): by transposition, the adjoint $A^*\in L(\bf{H_0^1(\Omega)}$ $,L^2(\Omega))$ is an isomorphism from the $\textit{orthogonal}$ of $R(A)$  $\textit{onto}$ $L^2(\Omega)/\mathbb{R}$. My question is, what's the justification for this last statement??  Perhaps I'm a little rusty, but I'm guessing I'm failing to make the necessary manipulations to relate the ranges of $A$ and $A^*$ and the orthogonal spaces of them etc. etc.",,"['functional-analysis', 'partial-differential-equations', 'operator-theory']"
20,Gate 2011-Find $p $ such that given series is convergent.,Gate 2011-Find  such that given series is convergent.,p ,"Let $x=(x_1,x_2,\ldots) \in l^4$, $x\ne 0$. For which of the following values of $p$ the series $\sum\limits_{i=1}^\infty x_iy_i$ converges for every $y=(y_1,y_2,\ldots) \in l^p$. (A) $1$;   (B) $2$;   (C) $3$;   (D) $4$ I have used holders inequality. I got $\frac{1}{p}=1-\frac{1}{4}$. But this option is not in the list. Please help me. Thank you in advance.","Let $x=(x_1,x_2,\ldots) \in l^4$, $x\ne 0$. For which of the following values of $p$ the series $\sum\limits_{i=1}^\infty x_iy_i$ converges for every $y=(y_1,y_2,\ldots) \in l^p$. (A) $1$;   (B) $2$;   (C) $3$;   (D) $4$ I have used holders inequality. I got $\frac{1}{p}=1-\frac{1}{4}$. But this option is not in the list. Please help me. Thank you in advance.",,"['real-analysis', 'sequences-and-series']"
21,Does Stone-Weierstrass hold for sets of functions that only separate points on a dense subspace?,Does Stone-Weierstrass hold for sets of functions that only separate points on a dense subspace?,,Supose $X$ is a compact Hausdorff topological space and $Y \subseteq X$ a dense subset. If $S$ is a set of functions in $C(X)$ such that separates points in $Y$ then the Stone-Weierstrass theorem still hold?,Supose $X$ is a compact Hausdorff topological space and $Y \subseteq X$ a dense subset. If $S$ is a set of functions in $C(X)$ such that separates points in $Y$ then the Stone-Weierstrass theorem still hold?,,"['general-topology', 'functional-analysis']"
22,Proof that $L^{p}$ is complete in Folland's Real Analysis,Proof that  is complete in Folland's Real Analysis,L^{p},"The following is from Folland's Real Analysis, Theorem 6.6. The theorem states: $\underline{\text{Theorem } 6.6:}$ For $1 \leq p < \infty$, $L^{p}$ is a Banach space. The proof makes use of Theorem 5.1 which is as follows: $\underline{\text{Theorem } 5.1:}$ A normed vector space $X$ is complete iff every absolutely convergent series in $X$ converges. $\underline{\text{The Proof of Theorem 6.6}:}$ We use Theorem 5.1.  Suppose $\left \{ f_{k} \right \} \subset L^{p}$ and $\displaystyle \sum_{k=1}^{\infty} ||f_{k}||_{p} = B < \infty$. Let $\displaystyle G_{n} = \sum_{k=1}^{n} |f_{k}|$ and $\displaystyle G = \sum_{k=1}^{\infty} |f_{k}|$. Then \begin{equation*} \begin{aligned} ||G_{n}||_{p} =  \big( \int \big| \sum_{k=1}^{n} |f_{k}|  \big|^{p} \big)^{1/p} \\ = \big( \int (|f_{1}| + \dots + |f_{n}|)^{p} \big)^{1/p} \\ \leq \big( \int |f_{1}|^{p} + \dots + \int |f_{n}|^{p} \big)^{1/p} \\ \leq \big( \int |f_{1}|^{p} \big)^{1/p} + \dots + \big( \int |f_{n}|^{p} \big)^{1/p} \\ = \sum_{k=1}^{n} ||f_{k}||_{p} \\ \leq B \end{aligned} \end{equation*} for all $n$. Therefore, by the Monotone Convergence Theorem (since $\displaystyle \sum_{k=1}^{n} |f_{k}| \leq \sum_{k=1}^{n+1}|f_{k}|)$ \begin{equation*} \int G^{p} = \lim \int G_{n}^{p} \leq B^{p} \end{equation*} Thus, $G \in L^{p}$, and in particular, $G(x) < \infty$ a.e., implying that the series $\displaystyle \sum_{k=1}^{\infty} f_{k}$ converges a.e. Denoting its sum by $F$, we have $|F| \leq G$ and hence $F \in L^{p}$. Moreover, \begin{equation*} \begin{aligned} |F - \sum_{k=1}^{n} f_{k}|^{p} \leq (2G)^{p} \in L^{1} \end{aligned} \end{equation*} Thus, by the Dominated Convergence Theorem, \begin{equation*} \begin{aligned} \lim_{n \rightarrow \infty} ||F - \sum_{k=1}^{n} f_{k}||_{p}^{p} = \lim_{n \rightarrow \infty} \int \big| F - \sum_{k=1}^{n} f_{k} \big|^{p}  = \int \lim_{n \rightarrow \infty} \big| F - \sum_{k=1}^{n} f_{k} \big|^{p} = 0 \end{aligned} \end{equation*} Thus ,the series $\displaystyle \sum_{k=1}^{\infty} f_{k}$ converges in the $L^{p}$ norm. This completes the proof. My question is why does this show that every absolutely convergent series in $X$ converges (thus allowing us to apply Theorem 5.1 thereby completing the proof)? Doesn't $\lim_{n \rightarrow \infty} ||F - \sum_{k=1}^{n} f_{k}||_{p}^{p} = 0$ in fact show that the series merely converges in $L^{p}$? Not converge absolutely in $L^{p}$?","The following is from Folland's Real Analysis, Theorem 6.6. The theorem states: $\underline{\text{Theorem } 6.6:}$ For $1 \leq p < \infty$, $L^{p}$ is a Banach space. The proof makes use of Theorem 5.1 which is as follows: $\underline{\text{Theorem } 5.1:}$ A normed vector space $X$ is complete iff every absolutely convergent series in $X$ converges. $\underline{\text{The Proof of Theorem 6.6}:}$ We use Theorem 5.1.  Suppose $\left \{ f_{k} \right \} \subset L^{p}$ and $\displaystyle \sum_{k=1}^{\infty} ||f_{k}||_{p} = B < \infty$. Let $\displaystyle G_{n} = \sum_{k=1}^{n} |f_{k}|$ and $\displaystyle G = \sum_{k=1}^{\infty} |f_{k}|$. Then \begin{equation*} \begin{aligned} ||G_{n}||_{p} =  \big( \int \big| \sum_{k=1}^{n} |f_{k}|  \big|^{p} \big)^{1/p} \\ = \big( \int (|f_{1}| + \dots + |f_{n}|)^{p} \big)^{1/p} \\ \leq \big( \int |f_{1}|^{p} + \dots + \int |f_{n}|^{p} \big)^{1/p} \\ \leq \big( \int |f_{1}|^{p} \big)^{1/p} + \dots + \big( \int |f_{n}|^{p} \big)^{1/p} \\ = \sum_{k=1}^{n} ||f_{k}||_{p} \\ \leq B \end{aligned} \end{equation*} for all $n$. Therefore, by the Monotone Convergence Theorem (since $\displaystyle \sum_{k=1}^{n} |f_{k}| \leq \sum_{k=1}^{n+1}|f_{k}|)$ \begin{equation*} \int G^{p} = \lim \int G_{n}^{p} \leq B^{p} \end{equation*} Thus, $G \in L^{p}$, and in particular, $G(x) < \infty$ a.e., implying that the series $\displaystyle \sum_{k=1}^{\infty} f_{k}$ converges a.e. Denoting its sum by $F$, we have $|F| \leq G$ and hence $F \in L^{p}$. Moreover, \begin{equation*} \begin{aligned} |F - \sum_{k=1}^{n} f_{k}|^{p} \leq (2G)^{p} \in L^{1} \end{aligned} \end{equation*} Thus, by the Dominated Convergence Theorem, \begin{equation*} \begin{aligned} \lim_{n \rightarrow \infty} ||F - \sum_{k=1}^{n} f_{k}||_{p}^{p} = \lim_{n \rightarrow \infty} \int \big| F - \sum_{k=1}^{n} f_{k} \big|^{p}  = \int \lim_{n \rightarrow \infty} \big| F - \sum_{k=1}^{n} f_{k} \big|^{p} = 0 \end{aligned} \end{equation*} Thus ,the series $\displaystyle \sum_{k=1}^{\infty} f_{k}$ converges in the $L^{p}$ norm. This completes the proof. My question is why does this show that every absolutely convergent series in $X$ converges (thus allowing us to apply Theorem 5.1 thereby completing the proof)? Doesn't $\lim_{n \rightarrow \infty} ||F - \sum_{k=1}^{n} f_{k}||_{p}^{p} = 0$ in fact show that the series merely converges in $L^{p}$? Not converge absolutely in $L^{p}$?",,"['real-analysis', 'functional-analysis', 'lp-spaces']"
23,how to prove the operator $L$ is zero.,how to prove the operator  is zero.,L,"Problem For  $f, g \in C([0; 1])$  define $$d(f,g):= \int_{0}^{1}\min\{1,\vert f(x)-g(x)\vert\}dx $$ (a) Prove that $d$ is a distance on $C([0,1]).$ (b) Let $L: C([0,1])\to \mathbb{R}$  be a linear operator, continuous with respect to the topology induced by  $d$. Prove that $L = 0.$ The part (a) is easy to solve. But I have no idea how to start for part (b). Please leave some hints, not a whole solution, to me.","Problem For  $f, g \in C([0; 1])$  define $$d(f,g):= \int_{0}^{1}\min\{1,\vert f(x)-g(x)\vert\}dx $$ (a) Prove that $d$ is a distance on $C([0,1]).$ (b) Let $L: C([0,1])\to \mathbb{R}$  be a linear operator, continuous with respect to the topology induced by  $d$. Prove that $L = 0.$ The part (a) is easy to solve. But I have no idea how to start for part (b). Please leave some hints, not a whole solution, to me.",,"['real-analysis', 'functional-analysis', 'measure-theory', 'operator-theory', 'lebesgue-measure']"
24,Bounding norm in $\ell_p$ by the norm in $\ell_{\infty}$ using multiplication by a vector,Bounding norm in  by the norm in  using multiplication by a vector,\ell_p \ell_{\infty},"Let $p \in [1, \infty)$. Is there a vector $y \in \mathbb{R}^{\mathbb{N}}$ such that for every $x \in \ell_p$ we have $\|x\|_p \leq \|xy\|_{\infty}$? The multiplication is pointwise, and the norm on the right might be infinite. Thank you!","Let $p \in [1, \infty)$. Is there a vector $y \in \mathbb{R}^{\mathbb{N}}$ such that for every $x \in \ell_p$ we have $\|x\|_p \leq \|xy\|_{\infty}$? The multiplication is pointwise, and the norm on the right might be infinite. Thank you!",,"['functional-analysis', 'normed-spaces', 'lp-spaces']"
25,Showing a measure is transformation invariant as in the proof of Krylov Bogolubov,Showing a measure is transformation invariant as in the proof of Krylov Bogolubov,,"First, context: Let $X$ be a compact metric space, and $C(X)$ the set of continuous functions on $X$ equipped with the sup norm. Let $T:X\to X$ continuous. Fix $x \in X$. Then one can show that $S_f^n(x) =\displaystyle \frac1n\sum_{k=0}^{n-1}f(T^k(x))$ is a bounded linear functional on $C(X)$, which has a convergent subsequence for all $g\in C(X)$. Denote the limit to be $S_g^\infty(x)$. This gives rise to the linear functional $L_x(g) = S_g^\infty(x)$, which is positive, so by Riesz Representation Theorem, we have $L_x(g) = \int_X gd\mu$ for some Borel probability measure. Now we are basically at my question. The author of the book I'm using (Dynamical Systems by Brin & Stuck) next shows that $S_g^\infty (x) = S_g^\infty (Tx)$ to conclude that $\mu$ is $T$-invariant. However, I don't know why this is. If we could work with characteristic functions, we would have the following: $\mu(A) = \int_X {\mathcal{X}}_A d\mu = L_x(\mathcal{X}_A)= L_x(\mathcal{X}_A\circ T) = \int_X \mathcal{X}_A \circ T d\mu = \mu(T^{-1}(A)).$ However, we've been working with continuous functions. It is not true, I don't think, that we can approximate simple functions by continuous functions in the sup norm. So I'm quite confused about how we get that $\mu$ is $T-$invariant. Moreover, I'm not sure I get why $T$ being continuous is necessary. For more context, here is the statement of the the theorem. Let $X$ be a compact metric space and $T: X → X$ a continuous map. Then there is a $T$-invariant Borel probability measure $\mu$ on $X$.","First, context: Let $X$ be a compact metric space, and $C(X)$ the set of continuous functions on $X$ equipped with the sup norm. Let $T:X\to X$ continuous. Fix $x \in X$. Then one can show that $S_f^n(x) =\displaystyle \frac1n\sum_{k=0}^{n-1}f(T^k(x))$ is a bounded linear functional on $C(X)$, which has a convergent subsequence for all $g\in C(X)$. Denote the limit to be $S_g^\infty(x)$. This gives rise to the linear functional $L_x(g) = S_g^\infty(x)$, which is positive, so by Riesz Representation Theorem, we have $L_x(g) = \int_X gd\mu$ for some Borel probability measure. Now we are basically at my question. The author of the book I'm using (Dynamical Systems by Brin & Stuck) next shows that $S_g^\infty (x) = S_g^\infty (Tx)$ to conclude that $\mu$ is $T$-invariant. However, I don't know why this is. If we could work with characteristic functions, we would have the following: $\mu(A) = \int_X {\mathcal{X}}_A d\mu = L_x(\mathcal{X}_A)= L_x(\mathcal{X}_A\circ T) = \int_X \mathcal{X}_A \circ T d\mu = \mu(T^{-1}(A)).$ However, we've been working with continuous functions. It is not true, I don't think, that we can approximate simple functions by continuous functions in the sup norm. So I'm quite confused about how we get that $\mu$ is $T-$invariant. Moreover, I'm not sure I get why $T$ being continuous is necessary. For more context, here is the statement of the the theorem. Let $X$ be a compact metric space and $T: X → X$ a continuous map. Then there is a $T$-invariant Borel probability measure $\mu$ on $X$.",,"['real-analysis', 'functional-analysis', 'measure-theory', 'dynamical-systems', 'ergodic-theory']"
26,Could Pre-image theorem be generalized to Hilbert Manifolds?,Could Pre-image theorem be generalized to Hilbert Manifolds?,,"$f:M\to N$ is a smooth map between manifolds of dimensions $m\geq n$. If $y\in N$ is a regular value, then the set $f^{-1}(y)$ is a smooth manifold of dimension $m-n$ or $\emptyset$. Could the Pre-image theorem be generalized to Hilbert space or other infinite dimensional spaces?","$f:M\to N$ is a smooth map between manifolds of dimensions $m\geq n$. If $y\in N$ is a regular value, then the set $f^{-1}(y)$ is a smooth manifold of dimension $m-n$ or $\emptyset$. Could the Pre-image theorem be generalized to Hilbert space or other infinite dimensional spaces?",,"['general-topology', 'functional-analysis', 'hilbert-spaces', 'differential-topology', 'banach-spaces']"
27,In a unital $C^*$-algebra: Why is $a^*a\le \|a\|^21_A$?,In a unital -algebra: Why is ?,C^* a^*a\le \|a\|^21_A,"Let $A$ be a unital $C^*$-algebra, $a\in A$. Why is $a^*a\le \|a\|^21_A$? I think this is a functional calculus argument. The functional calculus to $a^*a$ is an isomorphism of $C^*$-algebras $$C(\sigma(a^*a))\to C^*(a^*a,1_A),\; f\mapsto f(a^*a).$$ We have that $\|a\|^2=\|a^*a\|$ and $\sigma(a^*a)\subseteq [0,\|a\|^2]$. My first guess was to consider the function $f(x)=|x|-x$, but $f$ is zero on $\sigma(a^*a)$, so it doesn't work. So, how to prove $a^*a\le \|a\|^21_A$? Thank you.","Let $A$ be a unital $C^*$-algebra, $a\in A$. Why is $a^*a\le \|a\|^21_A$? I think this is a functional calculus argument. The functional calculus to $a^*a$ is an isomorphism of $C^*$-algebras $$C(\sigma(a^*a))\to C^*(a^*a,1_A),\; f\mapsto f(a^*a).$$ We have that $\|a\|^2=\|a^*a\|$ and $\sigma(a^*a)\subseteq [0,\|a\|^2]$. My first guess was to consider the function $f(x)=|x|-x$, but $f$ is zero on $\sigma(a^*a)$, so it doesn't work. So, how to prove $a^*a\le \|a\|^21_A$? Thank you.",,['functional-analysis']
28,"Derivative of $\|A - S\,S^\mathsf{T}\|_\mathsf{F}^2$ wrt. $S$",Derivative of  wrt.,"\|A - S\,S^\mathsf{T}\|_\mathsf{F}^2 S","Fix $A\in M_n(\mathbb{C})$ and let $f : M_{nm}(\mathbb{C}) \to \mathbb{R}$ be defined as $f(S) = \tfrac{1}{2}\|A - S\,S^\mathsf{T}\|_\mathsf{F}^2$ (yes I do mean the transpose and not the adjoint). I want to compute $\frac{\partial f}{\partial S}$. From the Matrix Cookbook 2.8.1 ( link ) we could use the chain rule $$\frac{\partial f}{\partial S_{ij}} = -\mathsf{tr}\,\left[(A^\mathsf{T} - SS^\mathsf{T})\frac{\partial S S^\mathsf{T}}{\partial S_{ij}}\right].$$ Working with this we can see $$\frac{\partial S S^\mathsf{T}_{kl}}{\partial S_{ij}} = \begin{cases}2 s_{ij} & \text{if } k=l=i\\s_{lj} & \text{if }k=i\neq j\\s_{kj} & \text{if }j=i\neq k\\ 0 & \text{otherwise}\end{cases}$$ so $$\frac{\partial S S^\mathsf{T}}{\partial S_{ij}} = S_je_i^\mathsf{T} + e_iS_j^\mathsf{T}$$ where $S_j$ is the $j$-th column of $S$. It follows that $$\frac{\partial f}{\partial S_{ij}} = -\mathsf{tr}\,\left[(A^\mathsf{T} - SS^\mathsf{T})(S_je_i^\mathsf{T} + e_iS_j^\mathsf{T})\right].$$ How can I simplify this further ? Ideally I would have a closed form expression for $f'(S)$ without having to index with coordinates.","Fix $A\in M_n(\mathbb{C})$ and let $f : M_{nm}(\mathbb{C}) \to \mathbb{R}$ be defined as $f(S) = \tfrac{1}{2}\|A - S\,S^\mathsf{T}\|_\mathsf{F}^2$ (yes I do mean the transpose and not the adjoint). I want to compute $\frac{\partial f}{\partial S}$. From the Matrix Cookbook 2.8.1 ( link ) we could use the chain rule $$\frac{\partial f}{\partial S_{ij}} = -\mathsf{tr}\,\left[(A^\mathsf{T} - SS^\mathsf{T})\frac{\partial S S^\mathsf{T}}{\partial S_{ij}}\right].$$ Working with this we can see $$\frac{\partial S S^\mathsf{T}_{kl}}{\partial S_{ij}} = \begin{cases}2 s_{ij} & \text{if } k=l=i\\s_{lj} & \text{if }k=i\neq j\\s_{kj} & \text{if }j=i\neq k\\ 0 & \text{otherwise}\end{cases}$$ so $$\frac{\partial S S^\mathsf{T}}{\partial S_{ij}} = S_je_i^\mathsf{T} + e_iS_j^\mathsf{T}$$ where $S_j$ is the $j$-th column of $S$. It follows that $$\frac{\partial f}{\partial S_{ij}} = -\mathsf{tr}\,\left[(A^\mathsf{T} - SS^\mathsf{T})(S_je_i^\mathsf{T} + e_iS_j^\mathsf{T})\right].$$ How can I simplify this further ? Ideally I would have a closed form expression for $f'(S)$ without having to index with coordinates.",,"['linear-algebra', 'functional-analysis', 'optimization', 'operator-theory', 'convex-optimization']"
29,Showing that a subset of a set of functions is closed.,Showing that a subset of a set of functions is closed.,,"I'm an undergraduate with little to no background in functional analysis and topology. The whole concept of function spaces is quite fuzzy to me, and I'm having a difficult time conceptualizing it. (Things like there being different notions of compactness in general topological spaces is one of many things confusing me because of what I've learned so far. I have learned many things which turn out to be true only in metric spaces, or in $\mathbb{R}^n$ specifically.) Consider the following situation: Let $A \subset \mathbb{R}^n$ and $[a, b] \subset \mathbb{R}$. Let $F$ denote the set of all functions from $A$ to $[a, b]$, and $G \subset F$ denote those functions which possess a particular attribute that we are interested in. In order to finish a larger proof, I'd like to show that $G$ is closed; later on, I want to work with pointwise convergence of functions in $G$. Since we are dealing with a function space, I'm a bit unsure about how to do this, because I'm uncertain about what constitutes a limit point in this space. I have showed that, for any sequence $(f_n)_1^\infty$ of functions in $G$ converging pointwise to some $f \in F$, $f$ must be in $G$. I believe that this shows that $G$ is closed, and I believe that it has to do with the connection between the product topology and pointwise convergence of functions, but I would really appreciate feedback on this; have I misunderstood what ""closed set"" means in this context? Thanks! EDIT: In my case, $G \subset F$ is the set of all functions $f:A \rightarrow [a, b]$ such that $f(a) + f(b) + f(c) = c(f)$, for any three pair-wise orthogonal unit vectors $a, b, c$, where $c(f)$ is a constant depending only on $f$. Second attempt: Take any function $f \in F \setminus G$. There exist two sets of orthogonal unit vectors $(v_1, v_2, v_3)$ and $(v_4, v_5, v_6)$ such that \begin{equation*} \Delta = \left| \sum_{i=1}^3 f(v_i) - f(v_{i + 3}) \right| > 0. \end{equation*} The set \begin{equation*} B_{\Delta/6} = \{ f \in F : \max(|f(v_i) - g(v_i)|) < \Delta / 6, i = 1, 2, \dots 6 \}. \end{equation*} is an open neighborhood of $f$. Take any $g \in B_{\Delta/6}$, and let $\delta_i = g(v_i) - f(v_i)$, for $i = 1, 2, \dots 6$, so that $|\delta_i| < \Delta / 6$. We get \begin{equation*} \begin{split} \left| \sum_{i=1}^3 (g(v_i) - g(v_{i+3})) \right| = \left| \sum_{i=1}^3 (f(v_i) + \delta_i - f(v_{i+3}) - \delta_{i+3}) \right| \geq\\ \left| \sum_{i=1}^3 (f(v_i) - f(v_{i+3})) \right| - \left|\sum_{i=1}^3 (\delta_{i+3} - \delta_i) \right| = \Delta - \left|\sum_{i=1}^3 (\delta_{i+3} - \delta_i) \right| > \Delta - \Delta = 0, \end{split} \end{equation*} using the reverse triangle inequality. Thus $g \in F \setminus G$, so that $B_{ \Delta / 6} \subset F \setminus G$, meaning $F \setminus G$ is open. We conclude that $(F \setminus G)^C = G$ is closed. Any thoughts?","I'm an undergraduate with little to no background in functional analysis and topology. The whole concept of function spaces is quite fuzzy to me, and I'm having a difficult time conceptualizing it. (Things like there being different notions of compactness in general topological spaces is one of many things confusing me because of what I've learned so far. I have learned many things which turn out to be true only in metric spaces, or in $\mathbb{R}^n$ specifically.) Consider the following situation: Let $A \subset \mathbb{R}^n$ and $[a, b] \subset \mathbb{R}$. Let $F$ denote the set of all functions from $A$ to $[a, b]$, and $G \subset F$ denote those functions which possess a particular attribute that we are interested in. In order to finish a larger proof, I'd like to show that $G$ is closed; later on, I want to work with pointwise convergence of functions in $G$. Since we are dealing with a function space, I'm a bit unsure about how to do this, because I'm uncertain about what constitutes a limit point in this space. I have showed that, for any sequence $(f_n)_1^\infty$ of functions in $G$ converging pointwise to some $f \in F$, $f$ must be in $G$. I believe that this shows that $G$ is closed, and I believe that it has to do with the connection between the product topology and pointwise convergence of functions, but I would really appreciate feedback on this; have I misunderstood what ""closed set"" means in this context? Thanks! EDIT: In my case, $G \subset F$ is the set of all functions $f:A \rightarrow [a, b]$ such that $f(a) + f(b) + f(c) = c(f)$, for any three pair-wise orthogonal unit vectors $a, b, c$, where $c(f)$ is a constant depending only on $f$. Second attempt: Take any function $f \in F \setminus G$. There exist two sets of orthogonal unit vectors $(v_1, v_2, v_3)$ and $(v_4, v_5, v_6)$ such that \begin{equation*} \Delta = \left| \sum_{i=1}^3 f(v_i) - f(v_{i + 3}) \right| > 0. \end{equation*} The set \begin{equation*} B_{\Delta/6} = \{ f \in F : \max(|f(v_i) - g(v_i)|) < \Delta / 6, i = 1, 2, \dots 6 \}. \end{equation*} is an open neighborhood of $f$. Take any $g \in B_{\Delta/6}$, and let $\delta_i = g(v_i) - f(v_i)$, for $i = 1, 2, \dots 6$, so that $|\delta_i| < \Delta / 6$. We get \begin{equation*} \begin{split} \left| \sum_{i=1}^3 (g(v_i) - g(v_{i+3})) \right| = \left| \sum_{i=1}^3 (f(v_i) + \delta_i - f(v_{i+3}) - \delta_{i+3}) \right| \geq\\ \left| \sum_{i=1}^3 (f(v_i) - f(v_{i+3})) \right| - \left|\sum_{i=1}^3 (\delta_{i+3} - \delta_i) \right| = \Delta - \left|\sum_{i=1}^3 (\delta_{i+3} - \delta_i) \right| > \Delta - \Delta = 0, \end{split} \end{equation*} using the reverse triangle inequality. Thus $g \in F \setminus G$, so that $B_{ \Delta / 6} \subset F \setminus G$, meaning $F \setminus G$ is open. We conclude that $(F \setminus G)^C = G$ is closed. Any thoughts?",,"['real-analysis', 'general-topology', 'functional-analysis']"
30,Integrable function which limit does not go to 0 for x to infinity,Integrable function which limit does not go to 0 for x to infinity,,"I want to find a function, such that the function shall be $p$ -integrable in the sense of $\int_{\mathbb{R}}|f(x)|^pdx<\infty$ for any $p\in[1,\infty)$ and that this does NOT imply $\lim_{x\to\infty}f(x)=0$ . Now it's similar to the question here Continuous unbounded but integrable functions , but I'm not looking for a function which is unbounded in any point, just one which limit in infinity does not converge to $0$ or better say does not exist. Does anyone know of any examples?","I want to find a function, such that the function shall be -integrable in the sense of for any and that this does NOT imply . Now it's similar to the question here Continuous unbounded but integrable functions , but I'm not looking for a function which is unbounded in any point, just one which limit in infinity does not converge to or better say does not exist. Does anyone know of any examples?","p \int_{\mathbb{R}}|f(x)|^pdx<\infty p\in[1,\infty) \lim_{x\to\infty}f(x)=0 0","['real-analysis', 'functional-analysis']"
31,Prove that every element $a$ of a C*-algebra $A$ is a finite linear combination of unitary elements of $A$,Prove that every element  of a C*-algebra  is a finite linear combination of unitary elements of,a A A,"Prove that every element $a$ of a C*-algebra $A$ is a finite linear combination of unitary elements of $A$. I have no idea to figure it out, any help would be appreciated.","Prove that every element $a$ of a C*-algebra $A$ is a finite linear combination of unitary elements of $A$. I have no idea to figure it out, any help would be appreciated.",,"['functional-analysis', 'c-star-algebras']"
32,"Closed subspaces of $L^{\infty}[0,1]$",Closed subspaces of,"L^{\infty}[0,1]","I would like to prove that $L^\infty[0,1]$ (bounded functions in $[0,1]$) has closed subspaces isomorphic to $c_0$ (space of sequences converging to zero). Do you have any ideas? Thanks in advance.","I would like to prove that $L^\infty[0,1]$ (bounded functions in $[0,1]$) has closed subspaces isomorphic to $c_0$ (space of sequences converging to zero). Do you have any ideas? Thanks in advance.",,"['functional-analysis', 'lp-spaces']"
33,$L_p$ space inclusion for Riemann-Stieltjes integral,space inclusion for Riemann-Stieltjes integral,L_p,"The integral here is defined in the Riemann-Stieltjes sense, the interval $[a,b]$ contains $\psi$'s support, and $\alpha<1$. $X$ is $\alpha$-Hölder continuous. \begin{align*}  \left|\int_a^b \psi(v)\mathrm{d}X(v)\right|&\leq \|\psi\|_{\infty}\lim\limits_{\left|\mathcal{P}\subseteq{[a,b]}\right|\to 0}\sum\limits_{i=0}^{n-1}\left|X(v_{i+1})-X(v_i)\right|\\ &\leq \|\psi\|_{\infty}\mu([a,b])^{1-\frac{1}{\alpha}}\lim\limits_{\left|\mathcal{P}\subseteq [a,b]\right|\to 0}\left(\sum\limits_{i=0}^{n-1}\left|X(v_{i+1})-X(v_i)\right|^{\frac{1}{\alpha}}\right)^{\alpha}, \end{align*} where $\mu$ is the standard Lebesgue measure. Have I correctly used the result that, for $1\leq p<q\leq\infty$, where $A$ is a finite measure space and $f$ is measurable (with measure $\mu$),we have $$\|f\|_p\leq \mu(A)^{\frac{1}{p}-\frac{1}{q}}\|f\|_q$$ ?","The integral here is defined in the Riemann-Stieltjes sense, the interval $[a,b]$ contains $\psi$'s support, and $\alpha<1$. $X$ is $\alpha$-Hölder continuous. \begin{align*}  \left|\int_a^b \psi(v)\mathrm{d}X(v)\right|&\leq \|\psi\|_{\infty}\lim\limits_{\left|\mathcal{P}\subseteq{[a,b]}\right|\to 0}\sum\limits_{i=0}^{n-1}\left|X(v_{i+1})-X(v_i)\right|\\ &\leq \|\psi\|_{\infty}\mu([a,b])^{1-\frac{1}{\alpha}}\lim\limits_{\left|\mathcal{P}\subseteq [a,b]\right|\to 0}\left(\sum\limits_{i=0}^{n-1}\left|X(v_{i+1})-X(v_i)\right|^{\frac{1}{\alpha}}\right)^{\alpha}, \end{align*} where $\mu$ is the standard Lebesgue measure. Have I correctly used the result that, for $1\leq p<q\leq\infty$, where $A$ is a finite measure space and $f$ is measurable (with measure $\mu$),we have $$\|f\|_p\leq \mu(A)^{\frac{1}{p}-\frac{1}{q}}\|f\|_q$$ ?",,"['real-analysis', 'functional-analysis', 'analysis', 'proof-verification']"
34,Is there a injective compact operator $T$ such that #$sp(T) < \infty$?,Is there a injective compact operator  such that #?,T sp(T) < \infty,"Let $X$ a Banach spaces such that $\dim X = \infty$, and $T: X\to X$ a injective compact operator. Is there $T$ such that #$sp(T) < \infty$  ? Thanks","Let $X$ a Banach spaces such that $\dim X = \infty$, and $T: X\to X$ a injective compact operator. Is there $T$ such that #$sp(T) < \infty$  ? Thanks",,"['functional-analysis', 'spectral-theory']"
35,Definition of hyperfinite von Neumann algebras,Definition of hyperfinite von Neumann algebras,,"Let $M$ be a (not necessarily separable) von Neumann algebra. I am interested to understand the non separable case. In the book [1, page 49], the authors says that $M$ is hyperfinite if we can write $M=\overline{\cup_\alpha M_\alpha}^{w^*}$ where $(M_\alpha)$ is a net of finite dimensional subalgebras directed by inclusion. 1) Is it equivalent to the definition of [2, page 97] ? This definition says that $M$ is approximately finite dimensional if for any $x_1,x_2,\ldots,x_n \in M$ and any $\sigma$-strong* neighborhood $V$ of $0$ in $M$ there exists a finite dimensional $*$-subalgebra $N$ such that  $x_j \in N + V$ for any $j = 1,2,\ldots,n$. 2) In these definitions, is it to be assumed that $1_M \in M_\alpha$ and $1_M \in N$ (i.e. the subalgebras are unital subalgebras)? Is there any difference ? [1] Sinclair, Smith, Finite von Neumann algebras and MASAS [2] Takesaki, Theory of operator algebras 3","Let $M$ be a (not necessarily separable) von Neumann algebra. I am interested to understand the non separable case. In the book [1, page 49], the authors says that $M$ is hyperfinite if we can write $M=\overline{\cup_\alpha M_\alpha}^{w^*}$ where $(M_\alpha)$ is a net of finite dimensional subalgebras directed by inclusion. 1) Is it equivalent to the definition of [2, page 97] ? This definition says that $M$ is approximately finite dimensional if for any $x_1,x_2,\ldots,x_n \in M$ and any $\sigma$-strong* neighborhood $V$ of $0$ in $M$ there exists a finite dimensional $*$-subalgebra $N$ such that  $x_j \in N + V$ for any $j = 1,2,\ldots,n$. 2) In these definitions, is it to be assumed that $1_M \in M_\alpha$ and $1_M \in N$ (i.e. the subalgebras are unital subalgebras)? Is there any difference ? [1] Sinclair, Smith, Finite von Neumann algebras and MASAS [2] Takesaki, Theory of operator algebras 3",,"['functional-analysis', 'operator-algebras', 'von-neumann-algebras']"
36,Weak Convergence of Composition in Sobolev Space,Weak Convergence of Composition in Sobolev Space,,"Let $\Omega\subset \mathbb R^d$ be a bounded domain with Lipschitz boundary, $1<p<\infty$, and suppose $h\colon \mathbb R\to \mathbb R$ is bounded and Lipschitz, $u_n \rightharpoonup u$ in $W^{1,p}(\Omega)$ ($\rightharpoonup$ denoting the weak convergence). Is it true that $h(u_n) \rightharpoonup h(u)$ in $W^{1,p}(\Omega)$? Are there other, similar convergence principles which  generalize this finding? What, if $p=1$? Note, that $h$ is differentiable almost everywhere and that the generalized chain rule states that for $\Omega$ as given, $h$ Lipschitz and $u\in W^{1,p}(\Omega)$ one has $h(u) = h\circ u \in W^{1,p}(\Omega)$ and $$D_i(h(u)) = h_B(u)D_iu,$$  where $h_B\colon \mathbb R\to\mathbb R$ is a Borel-measurable function such that $f_B = f'$ a.e. in $\mathbb R$. As an example of interest, one can take for $h$ the truncation $\tau_t\colon \mathbb R\to \mathbb R$, defined by $$\tau_t(s) = \begin{cases}  t, &\text{if }s\geq t,\\ s, &\text{if }-t < s < t,\\ -t, &\text{if }s\leq -t, \end{cases}$$ which is clearly Lipschitz. Suppose for some measurable functions $u$, $u_n$ that $\tau_t(u_n) \rightharpoonup \tau_t(u)$ in $W^{1,p}(\Omega)$ for every $t>0$ and let $\varphi \in W^{1,p}(\Omega)\cap L^\infty(\Omega)$. Then, for every $\varepsilon > 0$, $$\tau_\varepsilon(u_n-\varphi)\rightharpoonup \tau_\varepsilon(u-\varphi)\quad\text{in }W^{1,p}(\Omega),$$ as, for $k=\|\varphi\|_{L^\infty(\Omega)}$, $$\tau_\varepsilon(u_n-\varphi) = \tau_\varepsilon(\tau_{\varepsilon +k}(u_n) - \varphi).$$","Let $\Omega\subset \mathbb R^d$ be a bounded domain with Lipschitz boundary, $1<p<\infty$, and suppose $h\colon \mathbb R\to \mathbb R$ is bounded and Lipschitz, $u_n \rightharpoonup u$ in $W^{1,p}(\Omega)$ ($\rightharpoonup$ denoting the weak convergence). Is it true that $h(u_n) \rightharpoonup h(u)$ in $W^{1,p}(\Omega)$? Are there other, similar convergence principles which  generalize this finding? What, if $p=1$? Note, that $h$ is differentiable almost everywhere and that the generalized chain rule states that for $\Omega$ as given, $h$ Lipschitz and $u\in W^{1,p}(\Omega)$ one has $h(u) = h\circ u \in W^{1,p}(\Omega)$ and $$D_i(h(u)) = h_B(u)D_iu,$$  where $h_B\colon \mathbb R\to\mathbb R$ is a Borel-measurable function such that $f_B = f'$ a.e. in $\mathbb R$. As an example of interest, one can take for $h$ the truncation $\tau_t\colon \mathbb R\to \mathbb R$, defined by $$\tau_t(s) = \begin{cases}  t, &\text{if }s\geq t,\\ s, &\text{if }-t < s < t,\\ -t, &\text{if }s\leq -t, \end{cases}$$ which is clearly Lipschitz. Suppose for some measurable functions $u$, $u_n$ that $\tau_t(u_n) \rightharpoonup \tau_t(u)$ in $W^{1,p}(\Omega)$ for every $t>0$ and let $\varphi \in W^{1,p}(\Omega)\cap L^\infty(\Omega)$. Then, for every $\varepsilon > 0$, $$\tau_\varepsilon(u_n-\varphi)\rightharpoonup \tau_\varepsilon(u-\varphi)\quad\text{in }W^{1,p}(\Omega),$$ as, for $k=\|\varphi\|_{L^\infty(\Omega)}$, $$\tau_\varepsilon(u_n-\varphi) = \tau_\varepsilon(\tau_{\varepsilon +k}(u_n) - \varphi).$$",,"['functional-analysis', 'sobolev-spaces', 'weak-convergence']"
37,Why have the Mathematicians defined the boundedness in Functional Analysis so much different from that in Calculus?,Why have the Mathematicians defined the boundedness in Functional Analysis so much different from that in Calculus?,,"Let us consider $R$ with the norm $||x||=|x| $ for the whole discussion. Now the identity mapping $I$ from $R$ to $R$ is unbounded in Calculus but in Functional Analysis treating the same identity mapping $I$ as a linear transformation from the vector space $R$ to the vector space $R$, it becomes bounded. Why have the Mathematicians defined the boundedness in Functional Analysis so much different from that in Calculus?","Let us consider $R$ with the norm $||x||=|x| $ for the whole discussion. Now the identity mapping $I$ from $R$ to $R$ is unbounded in Calculus but in Functional Analysis treating the same identity mapping $I$ as a linear transformation from the vector space $R$ to the vector space $R$, it becomes bounded. Why have the Mathematicians defined the boundedness in Functional Analysis so much different from that in Calculus?",,"['calculus', 'functional-analysis', 'functions']"
38,Is there a more elementary proof of this Hilbert Space fact?,Is there a more elementary proof of this Hilbert Space fact?,,"Suppose $H$ be a Hilbert space in which there is an $A=\left \{ y_i \right \}^{\infty }_{i=1}$ such that any vector $x\in H$ is a $finite$ linear combination of elements from  $A$. Then $H$ is finite dimensional. The result is true for an arbitrary Banach space as can be seen by defining $A_k=$ span $\left \{ y_1,\cdots ,y_k \right \}$ and noting that by hypothesis $H=\bigcup _kA_k$ and then the result follows by a typical Baire argument. The problem is, the exercise appears in a book before Baire's Theorem is proved, so I am looking for a more elementary proof, one that uses specifically the fact that $H$ is a Hilbert space.","Suppose $H$ be a Hilbert space in which there is an $A=\left \{ y_i \right \}^{\infty }_{i=1}$ such that any vector $x\in H$ is a $finite$ linear combination of elements from  $A$. Then $H$ is finite dimensional. The result is true for an arbitrary Banach space as can be seen by defining $A_k=$ span $\left \{ y_1,\cdots ,y_k \right \}$ and noting that by hypothesis $H=\bigcup _kA_k$ and then the result follows by a typical Baire argument. The problem is, the exercise appears in a book before Baire's Theorem is proved, so I am looking for a more elementary proof, one that uses specifically the fact that $H$ is a Hilbert space.",,"['real-analysis', 'functional-analysis', 'hilbert-spaces']"
39,If a subspace is not complemented then the identity map can't be extended,If a subspace is not complemented then the identity map can't be extended,,"Let $(X, \|\cdot\|)$ be a Banach space, $Y \subset X$ a closed subspace.   $Y$ is called complemented if there is a closed subspace $Z \subset X$ such that $X =Y \oplus Z$ as topological vector spaces. Show that if a closed subspace $Y$ is not complemented, then the identity map on $Y$ can not be extended to a continuous linear function on $X$. Hi, I think I should do this by contradiction, but I don't know how, I wish you could help me! Thank you so much!","Let $(X, \|\cdot\|)$ be a Banach space, $Y \subset X$ a closed subspace.   $Y$ is called complemented if there is a closed subspace $Z \subset X$ such that $X =Y \oplus Z$ as topological vector spaces. Show that if a closed subspace $Y$ is not complemented, then the identity map on $Y$ can not be extended to a continuous linear function on $X$. Hi, I think I should do this by contradiction, but I don't know how, I wish you could help me! Thank you so much!",,"['functional-analysis', 'banach-spaces']"
40,"What does ""Kuratowski's theorem"" refer to in the context of dense linear subspaces being Borel?","What does ""Kuratowski's theorem"" refer to in the context of dense linear subspaces being Borel?",,"Kuratowski was a busy man who showed many results in topology and functional analysis, so when a writer says that some result follows from ''Kuratowski's theorem"", it could apply to many different ones. I am currently studying ""Stochastic Partial Differential Equations: An Introduction"", by Wei Liu and Michael Röckner and in Chapter 4, they introduce the Gelfand triple $\left(V,H,V^*\right)$ and sketch the situation where they work in. For this Gelfand triple (or evolution triple), we have a reflexive Banach space $\left(V,\|\cdot\|_{V}\right)$ and a Hilbert space $\left(H,\langle\cdot,\cdot\rangle_{H}\right)$, such that $V \subset H$ and $V$ can be continuously and densely embedded in $H$. It also follows that $H^*$ can be densely embedded into $V^*$, by restricting the functionals on $H$ to $V$ (call this (isomorphic!) map $\rho$). As the Hilbert space $H$ and its dual are isomorphic by the Riesz representation map $\Phi$, we can identify $H$ and its image under the map $\rho\circ\Phi$; we will write $\bar{H}$ for $\rho(\Phi(H))$. Then, they claim that by Kuratowski's theorem , we know that  $$ V \in \mathcal{B}(H) \quad \text{ and } \quad \bar{H}\in\mathcal{B}\left(V^*\right) $$ but I don't know which theorem they refer to and that is my question. I've scoured the internet to find what they mean, but my attempts have not yet been fruitful, so I was wondering if any of you could help me out.","Kuratowski was a busy man who showed many results in topology and functional analysis, so when a writer says that some result follows from ''Kuratowski's theorem"", it could apply to many different ones. I am currently studying ""Stochastic Partial Differential Equations: An Introduction"", by Wei Liu and Michael Röckner and in Chapter 4, they introduce the Gelfand triple $\left(V,H,V^*\right)$ and sketch the situation where they work in. For this Gelfand triple (or evolution triple), we have a reflexive Banach space $\left(V,\|\cdot\|_{V}\right)$ and a Hilbert space $\left(H,\langle\cdot,\cdot\rangle_{H}\right)$, such that $V \subset H$ and $V$ can be continuously and densely embedded in $H$. It also follows that $H^*$ can be densely embedded into $V^*$, by restricting the functionals on $H$ to $V$ (call this (isomorphic!) map $\rho$). As the Hilbert space $H$ and its dual are isomorphic by the Riesz representation map $\Phi$, we can identify $H$ and its image under the map $\rho\circ\Phi$; we will write $\bar{H}$ for $\rho(\Phi(H))$. Then, they claim that by Kuratowski's theorem , we know that  $$ V \in \mathcal{B}(H) \quad \text{ and } \quad \bar{H}\in\mathcal{B}\left(V^*\right) $$ but I don't know which theorem they refer to and that is my question. I've scoured the internet to find what they mean, but my attempts have not yet been fruitful, so I was wondering if any of you could help me out.",,"['functional-analysis', 'reference-request', 'topological-vector-spaces']"
41,Injectivity of the Fourier transform on the $n$-torus,Injectivity of the Fourier transform on the -torus,n,"I've seen stated several times without proof that the Fourier transform (giving the Fourier coefficients $(c_k(f))$ of a function $f$) defined on $L^1(\mathbb{T}^n)$ (and not just on $L^2$) is injective. I am wondering how to prove that. I've see a proof that the Fourier transform is injective on $L^2$, but how to extend the injectivity to $L^1$ ?","I've seen stated several times without proof that the Fourier transform (giving the Fourier coefficients $(c_k(f))$ of a function $f$) defined on $L^1(\mathbb{T}^n)$ (and not just on $L^2$) is injective. I am wondering how to prove that. I've see a proof that the Fourier transform is injective on $L^2$, but how to extend the injectivity to $L^1$ ?",,"['real-analysis', 'functional-analysis', 'fourier-analysis', 'fourier-series', 'fourier-transform']"
42,"Why is a set complete in $C[0,1]$ also complete in $L_2[0,1]$?",Why is a set complete in  also complete in ?,"C[0,1] L_2[0,1]","I was asked to prove that $\{{t^{3n}}\}_{n=0}^{\infty}$ is complete in $L_2[0,1]$ (complete system). And the solution says that it is sufficient to show completeness in $C[0,1]$. Why is that? Is it simply because continuity on a closed interval implies integrability on that interval? I am not even sure how correct it is, but what I ultimately want to know is the simple claim the enables this equivalence.","I was asked to prove that $\{{t^{3n}}\}_{n=0}^{\infty}$ is complete in $L_2[0,1]$ (complete system). And the solution says that it is sufficient to show completeness in $C[0,1]$. Why is that? Is it simply because continuity on a closed interval implies integrability on that interval? I am not even sure how correct it is, but what I ultimately want to know is the simple claim the enables this equivalence.",,['functional-analysis']
43,Seminorm $p$ induces norm on $V/\text{ker}(p)$,Seminorm  induces norm on,p V/\text{ker}(p),"I am stuck in the following problem: Let $V$ be a vector space and $p$ seminorm in $V$. Show that $p$ induces norm on quotient space $V/\text{ker}(p)$ defined as $\lVert v+\text{ker}(p)\rVert=p(v)$. It's easy to show the axioms of norm, except the case $$\lVert v+\text{ker}(p)\rVert=p(v)=0 \Rightarrow v+\text{ker}(p)=0\in V/\text{ker}(p) .$$ So we should show that $p(v)=0$ implies $v=0$. But because $p$ is seminorm, there can be non-zero vectors which norms are zero. I don't know how to proceed, any help or hints would be appreciated.","I am stuck in the following problem: Let $V$ be a vector space and $p$ seminorm in $V$. Show that $p$ induces norm on quotient space $V/\text{ker}(p)$ defined as $\lVert v+\text{ker}(p)\rVert=p(v)$. It's easy to show the axioms of norm, except the case $$\lVert v+\text{ker}(p)\rVert=p(v)=0 \Rightarrow v+\text{ker}(p)=0\in V/\text{ker}(p) .$$ So we should show that $p(v)=0$ implies $v=0$. But because $p$ is seminorm, there can be non-zero vectors which norms are zero. I don't know how to proceed, any help or hints would be appreciated.",,"['linear-algebra', 'functional-analysis', 'quotient-spaces']"
44,Proof that no normed space is compact,Proof that no normed space is compact,,"The notes for my functional analysis class casually state that every nontrivial normed space is not compact, but do not give a proof. I can't tell if this is because it is a trivial proof or because it is too complicated to be given inline. Is there a good proof for this? I have searched around the internet for a while and haven't been able to find one.","The notes for my functional analysis class casually state that every nontrivial normed space is not compact, but do not give a proof. I can't tell if this is because it is a trivial proof or because it is too complicated to be given inline. Is there a good proof for this? I have searched around the internet for a while and haven't been able to find one.",,"['functional-analysis', 'normed-spaces']"
45,"If $T$ is a bounded linear operator between Hilbert Spaces and $\lVert{T}\rVert = \lVert{T^{-1}}\rVert =1$, is $T$ unitary?","If  is a bounded linear operator between Hilbert Spaces and , is  unitary?",T \lVert{T}\rVert = \lVert{T^{-1}}\rVert =1 T,"If $T:K \rightarrow L$ is a bounded linear operator between two Hilbert Spaces $K$ and $L$, then we have automatically that if $T$ is unitary, then $\lVert{T}\rVert = \lVert{T^{-1}}\rVert = 1$ by the following: $\lVert{Tx}\rVert^{2}_{L} = \langle Tx, Tx\rangle_{L} = \langle x, x\rangle_{K} = \lVert{x}\rVert^{2}_{K} \Rightarrow \lVert{Tx}\rVert_{L} = \lVert{x}\rVert_{K}$ Then immediately from the definition of the operator norm we get $\lVert{T}\rVert = 1$, similarly we can obtain $\lVert{T^{-1}}\rVert = 1$. However, I get a little confused when going the other way, proving or disproving the converse... (Any insight or hints are much appreciated!).","If $T:K \rightarrow L$ is a bounded linear operator between two Hilbert Spaces $K$ and $L$, then we have automatically that if $T$ is unitary, then $\lVert{T}\rVert = \lVert{T^{-1}}\rVert = 1$ by the following: $\lVert{Tx}\rVert^{2}_{L} = \langle Tx, Tx\rangle_{L} = \langle x, x\rangle_{K} = \lVert{x}\rVert^{2}_{K} \Rightarrow \lVert{Tx}\rVert_{L} = \lVert{x}\rVert_{K}$ Then immediately from the definition of the operator norm we get $\lVert{T}\rVert = 1$, similarly we can obtain $\lVert{T^{-1}}\rVert = 1$. However, I get a little confused when going the other way, proving or disproving the converse... (Any insight or hints are much appreciated!).",,['functional-analysis']
46,Fixed point of an invariant mapping,Fixed point of an invariant mapping,,"Let $X$ be non empty and $T: X \to X$ a mapping such that $T^n$ has a unique fixed point $x$, then $x$ is also a unique fixed point of T. If I assume $T$ has two fixed points $x$ and $v$ $\implies$ $T^nv=v$ so $v$ is also a fixed point of $T^n$ which is a contradiction. Is this the proper way to do the proof? Edit: All of the details of the question are below. Let $X$ be a nonempty set and $T : X \to X$ be a mapping. If, for an $n \in N$, $n \geq 2$, there exists a unique fixed point $x \in X$ for $T^n$ , then $x$ is a also a unique fixed point for $T$.","Let $X$ be non empty and $T: X \to X$ a mapping such that $T^n$ has a unique fixed point $x$, then $x$ is also a unique fixed point of T. If I assume $T$ has two fixed points $x$ and $v$ $\implies$ $T^nv=v$ so $v$ is also a fixed point of $T^n$ which is a contradiction. Is this the proper way to do the proof? Edit: All of the details of the question are below. Let $X$ be a nonempty set and $T : X \to X$ be a mapping. If, for an $n \in N$, $n \geq 2$, there exists a unique fixed point $x \in X$ for $T^n$ , then $x$ is a also a unique fixed point for $T$.",,"['linear-algebra', 'functional-analysis']"
47,When Schrodinger operator has discrete spectrum?,When Schrodinger operator has discrete spectrum?,,"On $L^{2}(\mathbb{R})$ we have a linear operator $S=-\frac{d^{2}}{dx^{2}}+u(x)$. As I understand for some choices of potential $u$ (like harmonic oscillator $u(x)=\frac{\omega x^2}{2}$) Schrodinger operator will have  only a countable set of $\lambda_{n} \in \mathbb{R}, f_{n} \in L^{2}(\mathbb{R}), (f_{n} \neq 0)$ such that $S f_{n}=\lambda_{n} f_{n} \\$. My question is for what other choices (if any) of a linear subspace $V$ (possibly without a non-trivial norm) of the space of set-theoretical functions $Map(\mathbb{R},\mathbb{R})$ Schrodinger operator will have only countably many real eigenvalues (say $u$ has finitely many poles on $\mathbb{R}$ and outside poles is infinitely differentiable. Probably a satisfactory answer can be achieved with weaker  regularity assumptions on the potential)?","On $L^{2}(\mathbb{R})$ we have a linear operator $S=-\frac{d^{2}}{dx^{2}}+u(x)$. As I understand for some choices of potential $u$ (like harmonic oscillator $u(x)=\frac{\omega x^2}{2}$) Schrodinger operator will have  only a countable set of $\lambda_{n} \in \mathbb{R}, f_{n} \in L^{2}(\mathbb{R}), (f_{n} \neq 0)$ such that $S f_{n}=\lambda_{n} f_{n} \\$. My question is for what other choices (if any) of a linear subspace $V$ (possibly without a non-trivial norm) of the space of set-theoretical functions $Map(\mathbb{R},\mathbb{R})$ Schrodinger operator will have only countably many real eigenvalues (say $u$ has finitely many poles on $\mathbb{R}$ and outside poles is infinitely differentiable. Probably a satisfactory answer can be achieved with weaker  regularity assumptions on the potential)?",,['functional-analysis']
48,Uniform convergence and interchange of limits,Uniform convergence and interchange of limits,,"We consider $f_n(x)=x^n$ on $[0,1]$. Each function $f_n(x)$ is continuous, but the limit function $f(x)$ is not continuous: $$     f(x)=\left\{                 \begin{array}{ll}                   0, 0\leq x<1\\                   1, x=1\\                 \end{array}               \right. $$ Question 1: How can we prove that: $$ \lim_{n\rightarrow \infty}(\lim_{x\rightarrow 1}f_n(x))=1 $$ $$ \lim_{x\rightarrow 1}(\lim_{n\rightarrow \infty}f_n(x))=0 $$ Question 2: Is uniform convergence of $f_n(x)\rightarrow f(x)$ a sufficient condition to get the same result if we interchange the limits?","We consider $f_n(x)=x^n$ on $[0,1]$. Each function $f_n(x)$ is continuous, but the limit function $f(x)$ is not continuous: $$     f(x)=\left\{                 \begin{array}{ll}                   0, 0\leq x<1\\                   1, x=1\\                 \end{array}               \right. $$ Question 1: How can we prove that: $$ \lim_{n\rightarrow \infty}(\lim_{x\rightarrow 1}f_n(x))=1 $$ $$ \lim_{x\rightarrow 1}(\lim_{n\rightarrow \infty}f_n(x))=0 $$ Question 2: Is uniform convergence of $f_n(x)\rightarrow f(x)$ a sufficient condition to get the same result if we interchange the limits?",,"['functional-analysis', 'convergence-divergence', 'uniform-convergence']"
49,Invertibility of an operator $T$ if $\|I-T\|<1$,Invertibility of an operator  if,T \|I-T\|<1,"Let $X $ be a Banach space $(X,\|.\|)$ with $\dim(X)=\infty $ and $T\in B(X) $. Suppose that $\left\| I-T\right\| < 1$. Show that $T^{-1}\in B\left( X\right)$ and $\left\| I-T^{-1}\right\| \leq \dfrac {\left\| I-T\right\| } {1-\left\| I-T\right\| }$.","Let $X $ be a Banach space $(X,\|.\|)$ with $\dim(X)=\infty $ and $T\in B(X) $. Suppose that $\left\| I-T\right\| < 1$. Show that $T^{-1}\in B\left( X\right)$ and $\left\| I-T^{-1}\right\| \leq \dfrac {\left\| I-T\right\| } {1-\left\| I-T\right\| }$.",,"['functional-analysis', 'operator-theory', 'banach-spaces', 'banach-algebras']"
50,An application of Baire 's Theorem,An application of Baire 's Theorem,,"Definition :  Let $S$ be a subset of a metric space $(X,d)$. A point $x \in S$ is called an isolated point if $\exists \varepsilon >0 $ s.t $B(x,\varepsilon) \cap S \setminus \{x\}= \emptyset. $ Baire's Theorem : Let $ (X,d)$ be a complete metric space. Then, the interior of any countable union of closed subsets is nonempty implies the interior of one of the closed subsets is nonempty as well. With the theorem and the definiton in mind, I am supposed to prove the following; Propositon : If $X$ is  a complete metric space which has $\textbf{no}$ isolated points, then $X$ is uncountable. I wrote down as follows : By having no isolated points , we have $\forall x \in X, \quad \forall \varepsilon> 0  \quad B(x,\varepsilon) \cap X\ \{x\} \ne \emptyset.$ And  I assume the assertion of the proposition is false. In other words, $X $ is countable and it can be rewritten as  $X= (S^c) \cup S$ for some $S^c $ which is countable and and $S = \bigcup_{n=1}^\infty S_n$ is uncountable and each $S_n$ is closed. I somehow must try to get a contradiction with the Baire's Theorem. But I could not. Help me if my starting point is wrong and if it is guide me to another direction.","Definition :  Let $S$ be a subset of a metric space $(X,d)$. A point $x \in S$ is called an isolated point if $\exists \varepsilon >0 $ s.t $B(x,\varepsilon) \cap S \setminus \{x\}= \emptyset. $ Baire's Theorem : Let $ (X,d)$ be a complete metric space. Then, the interior of any countable union of closed subsets is nonempty implies the interior of one of the closed subsets is nonempty as well. With the theorem and the definiton in mind, I am supposed to prove the following; Propositon : If $X$ is  a complete metric space which has $\textbf{no}$ isolated points, then $X$ is uncountable. I wrote down as follows : By having no isolated points , we have $\forall x \in X, \quad \forall \varepsilon> 0  \quad B(x,\varepsilon) \cap X\ \{x\} \ne \emptyset.$ And  I assume the assertion of the proposition is false. In other words, $X $ is countable and it can be rewritten as  $X= (S^c) \cup S$ for some $S^c $ which is countable and and $S = \bigcup_{n=1}^\infty S_n$ is uncountable and each $S_n$ is closed. I somehow must try to get a contradiction with the Baire's Theorem. But I could not. Help me if my starting point is wrong and if it is guide me to another direction.",,"['real-analysis', 'general-topology', 'functional-analysis', 'analysis']"
51,Is a cone in Banach space always a closed subset?,Is a cone in Banach space always a closed subset?,,"Let $(\mathbb{X}, || \cdot||)$ be a real Banach space. We define a subset $P$ of $\mathbb{X}$ by $P := \{ x \in \mathbb{X} : x\geq 0\}$. In general, $P$ is termed a positive cone of $\mathbb{X}$. However, $\mathbb{X}$ is quite abstract and could be any real Banach space, so that I am wondering that whether $P$ always be a closed subset of $\mathbb{X}$ (as primitive)? If so, how to show that? In fact, there are many different definitions in textbooks for "" cone "". One is defined as ""A subset $C$ of $\mathbb{X}$ is called a cone iff (i) $C$ is nonempty and nontrival ($C \neq \{0\}$); (ii) $C$ is closed and convex; (iii) $\lambda C \subset C$ for any nonnegative real number $\lambda$; (iv) $C \cap (-C) = \{ 0\}$."" On the other hand, other textbook defines it as "" A subset $C$ of $\mathbb{X}$ is called a cone iff (iii) and (iv) are satisfied."" Therefore, it makes me confused about whether a positive cone $P := \{ x \in \mathbb{X} : x\geq 0\}$ is always a closed subset. I thought a positive cone $P$ is always closed. Because by the construction of $P$, for any convergent sequence $\{x_n \} \subset P$ such that $ x_n \rightarrow x \in \mathbb{X}$ (i.e., $||x_n - x|| \rightarrow 0$ as $n \rightarrow \infty$), we have $x_n \geq 0$ for all $n$. And, it is clear intuitively that the limit $x$ of this sequence should also be nonnegative. But how to prove it rigorously? Thanks for helping in advance!","Let $(\mathbb{X}, || \cdot||)$ be a real Banach space. We define a subset $P$ of $\mathbb{X}$ by $P := \{ x \in \mathbb{X} : x\geq 0\}$. In general, $P$ is termed a positive cone of $\mathbb{X}$. However, $\mathbb{X}$ is quite abstract and could be any real Banach space, so that I am wondering that whether $P$ always be a closed subset of $\mathbb{X}$ (as primitive)? If so, how to show that? In fact, there are many different definitions in textbooks for "" cone "". One is defined as ""A subset $C$ of $\mathbb{X}$ is called a cone iff (i) $C$ is nonempty and nontrival ($C \neq \{0\}$); (ii) $C$ is closed and convex; (iii) $\lambda C \subset C$ for any nonnegative real number $\lambda$; (iv) $C \cap (-C) = \{ 0\}$."" On the other hand, other textbook defines it as "" A subset $C$ of $\mathbb{X}$ is called a cone iff (iii) and (iv) are satisfied."" Therefore, it makes me confused about whether a positive cone $P := \{ x \in \mathbb{X} : x\geq 0\}$ is always a closed subset. I thought a positive cone $P$ is always closed. Because by the construction of $P$, for any convergent sequence $\{x_n \} \subset P$ such that $ x_n \rightarrow x \in \mathbb{X}$ (i.e., $||x_n - x|| \rightarrow 0$ as $n \rightarrow \infty$), we have $x_n \geq 0$ for all $n$. And, it is clear intuitively that the limit $x$ of this sequence should also be nonnegative. But how to prove it rigorously? Thanks for helping in advance!",,"['real-analysis', 'general-topology', 'functional-analysis', 'functional-equations']"
52,"If $M$ is a proper subspace of $\mathbb{C}^n$, then there is a nonzero linear functional $f$ on $\mathbb{C}^n$ such that $f(M)=0$","If  is a proper subspace of , then there is a nonzero linear functional  on  such that",M \mathbb{C}^n f \mathbb{C}^n f(M)=0,"If $M$ is a proper subspace of $\mathbb{C}^n$, then there is a nonzero linear functional $f$ on $\mathbb{C}^n$ such that $f(M)=0$ I've tried to prove it by Hahn-Banach's theorem. Are  there any other simpler ways to prove it?","If $M$ is a proper subspace of $\mathbb{C}^n$, then there is a nonzero linear functional $f$ on $\mathbb{C}^n$ such that $f(M)=0$ I've tried to prove it by Hahn-Banach's theorem. Are  there any other simpler ways to prove it?",,"['linear-algebra', 'functional-analysis']"
53,Conway's proof of Goldstine's theorem.,Conway's proof of Goldstine's theorem.,,"In proving Goldstine's theorem, Conway states the following. Suppose $B$ is the weak-star closure of $J(B_X)$ in $B_{X''}$, and assume there is some $x_0'' \in B_{X''}\smallsetminus B$. He claims Hahn-Banach implies there is some $x'\in X'$ and $\alpha,\varepsilon$ such that $$\langle x',x\rangle  < \alpha<\alpha+\varepsilon < \langle x',x_0''\rangle$$ for every $x\in B$. He asks the reader to figure out why this is true.  Could someone explain? His version of Hahn Banach is the usual one. I'm aware of certain geometric versions. In this case, $B$ is convex and weak-star closed, so it is convex and closed, and $\{x_0''\}$ is of course convex and compact, so I can separate them by a norm closed hyperplane, but I want a weak-star closed hyperplane (that is, I get some functional $\psi\in X'''$ that defines the hyperplane, but I want something in $X'$, right?)","In proving Goldstine's theorem, Conway states the following. Suppose $B$ is the weak-star closure of $J(B_X)$ in $B_{X''}$, and assume there is some $x_0'' \in B_{X''}\smallsetminus B$. He claims Hahn-Banach implies there is some $x'\in X'$ and $\alpha,\varepsilon$ such that $$\langle x',x\rangle  < \alpha<\alpha+\varepsilon < \langle x',x_0''\rangle$$ for every $x\in B$. He asks the reader to figure out why this is true.  Could someone explain? His version of Hahn Banach is the usual one. I'm aware of certain geometric versions. In this case, $B$ is convex and weak-star closed, so it is convex and closed, and $\{x_0''\}$ is of course convex and compact, so I can separate them by a norm closed hyperplane, but I want a weak-star closed hyperplane (that is, I get some functional $\psi\in X'''$ that defines the hyperplane, but I want something in $X'$, right?)",,['functional-analysis']
54,Introduction to viscosity solutions theory,Introduction to viscosity solutions theory,,"Can you recommend an introduction to viscosity solutions theory ? More specifically, I'm looking for a modern treatment similar to Chapter 10 of Evans's Partial Differential Equations , but somewhat more detailed and comprehensive. (Of course, I'm aware of the User's Guide , but it is not quite what I'm looking for).","Can you recommend an introduction to viscosity solutions theory ? More specifically, I'm looking for a modern treatment similar to Chapter 10 of Evans's Partial Differential Equations , but somewhat more detailed and comprehensive. (Of course, I'm aware of the User's Guide , but it is not quite what I'm looking for).",,"['functional-analysis', 'analysis']"
55,"How to prove that there exist $a$ and $b$ in [0,1] such that $\left| f\left( a \right) +g\left( b \right) -ab \right| \ge \frac { 1 }{ 4 } $?","How to prove that there exist  and  in [0,1] such that ?",a b \left| f\left( a \right) +g\left( b \right) -ab \right| \ge \frac { 1 }{ 4 } ,"Let $f$ and $g$ be any real-valued functions defined on [0,1],Prove that there exist $a$ and $b$ in [0,1] such that $$\left| f\left( a \right) +g\left( b \right) -ab \right| \ge \frac { 1 }{ 4 }  $$ I don't know how can I start with this question. So , I need some hints which can help me to approach this problem .","Let $f$ and $g$ be any real-valued functions defined on [0,1],Prove that there exist $a$ and $b$ in [0,1] such that $$\left| f\left( a \right) +g\left( b \right) -ab \right| \ge \frac { 1 }{ 4 }  $$ I don't know how can I start with this question. So , I need some hints which can help me to approach this problem .",,"['algebra-precalculus', 'functional-analysis', 'functions']"
56,Is the closure of a compact set compact?,Is the closure of a compact set compact?,,While looking up information on compact operators I came across these two conflicting posts. If a set is compact then it is closed Topology: Example of a compact set but its closure not compact So the first link says that if a set $U$ is compact then it is closed. $U$ closed means $U = \overline{U}$ and hence $\overline{U}$ is compact. This seems to be in direct contradiction with the second post?,While looking up information on compact operators I came across these two conflicting posts. If a set is compact then it is closed Topology: Example of a compact set but its closure not compact So the first link says that if a set $U$ is compact then it is closed. $U$ closed means $U = \overline{U}$ and hence $\overline{U}$ is compact. This seems to be in direct contradiction with the second post?,,"['general-topology', 'functional-analysis', 'compactness']"
57,Triangle Equality in a normed linear space,Triangle Equality in a normed linear space,,"The following statement is true or false: If $x, y$ are elements of a normed linear space, then $$\|x + y\| = \|x\| + \|y\| \iff x = 0\ \text{or}\ y = tx$$ for some $t ≥ 0$. What I have tried is as follows: It is clear that if $x = 0\ \text{or}\ y = tx $ then the equality will hold. But for the converse part, let \begin{align*} \|x+y\|& =\|x\|+\|y\|\\ \implies \|x+y\|^2 & =(\|x\|+\|y\|)^2\\ \end{align*}  After that I stuck. Also in the following article Characterization of the norm triangle equality , I have read that in the case of a strictly convex normed linear space $V$, the equality $\|x + y\| = \|x\| + \|y\|$ holds for nonzero vectors $x,y ∈ V$ if and only if $\frac{x}{\|x\|} = \frac{y}{\|y\|} $. Thank you for the help.","The following statement is true or false: If $x, y$ are elements of a normed linear space, then $$\|x + y\| = \|x\| + \|y\| \iff x = 0\ \text{or}\ y = tx$$ for some $t ≥ 0$. What I have tried is as follows: It is clear that if $x = 0\ \text{or}\ y = tx $ then the equality will hold. But for the converse part, let \begin{align*} \|x+y\|& =\|x\|+\|y\|\\ \implies \|x+y\|^2 & =(\|x\|+\|y\|)^2\\ \end{align*}  After that I stuck. Also in the following article Characterization of the norm triangle equality , I have read that in the case of a strictly convex normed linear space $V$, the equality $\|x + y\| = \|x\| + \|y\|$ holds for nonzero vectors $x,y ∈ V$ if and only if $\frac{x}{\|x\|} = \frac{y}{\|y\|} $. Thank you for the help.",,"['functional-analysis', 'normed-spaces']"
58,Analogy and connection between roots of unity and the solutions to $f^{(n)}(x)=f(x)$,Analogy and connection between roots of unity and the solutions to,f^{(n)}(x)=f(x),"In the number theory we have roots of unity, i.e. the $n$ solutions of: $$x^n=1,~~~n=1,2,3,\dots$$ $$x_1=1$$ $$x_2=(-1,1)$$ $$x_3=\left( 1, e^{\dfrac{\pi i}{3}}, e^{\dfrac{2 \pi i}{3}} \right)$$ $$x_4=(1,-1,i,-i)$$ etc. If we consider a simple ODE: $$f^{(n)}(x)=f(x),~~~n=1,2,3,\dots$$ We obtain a something very similar (in my opinion): $$f_1(x)=C e^x$$ $$f_2(x)=C_1 e^x+C_2 e^{-x}$$ $$f_3(x)=C_1 e^x+C_2 e^{-x/2} \sin \left( \frac{\sqrt{3}}{2} x \right)+C_3 e^{-x/2} \cos \left( \frac{\sqrt{3}}{2} x \right)$$ $$f_4(x)=C_1 e^x+C_2 e^{-x}+C_3 e^{ix}+C_4 e^{-ix}$$ etc. We can always switch between the exponential and trigonometric forms of course. Do these functions play as important role in functional analysis or other fields, as the roots of unity play in number theory? What are they called? What are some examples of their use? (I mean the whole set of these functions, not just the exponent or trig functions). If possible, please offer an intuitive explanation of the connection/analogy between roots of unity and these functions.","In the number theory we have roots of unity, i.e. the $n$ solutions of: $$x^n=1,~~~n=1,2,3,\dots$$ $$x_1=1$$ $$x_2=(-1,1)$$ $$x_3=\left( 1, e^{\dfrac{\pi i}{3}}, e^{\dfrac{2 \pi i}{3}} \right)$$ $$x_4=(1,-1,i,-i)$$ etc. If we consider a simple ODE: $$f^{(n)}(x)=f(x),~~~n=1,2,3,\dots$$ We obtain a something very similar (in my opinion): $$f_1(x)=C e^x$$ $$f_2(x)=C_1 e^x+C_2 e^{-x}$$ $$f_3(x)=C_1 e^x+C_2 e^{-x/2} \sin \left( \frac{\sqrt{3}}{2} x \right)+C_3 e^{-x/2} \cos \left( \frac{\sqrt{3}}{2} x \right)$$ $$f_4(x)=C_1 e^x+C_2 e^{-x}+C_3 e^{ix}+C_4 e^{-ix}$$ etc. We can always switch between the exponential and trigonometric forms of course. Do these functions play as important role in functional analysis or other fields, as the roots of unity play in number theory? What are they called? What are some examples of their use? (I mean the whole set of these functions, not just the exponent or trig functions). If possible, please offer an intuitive explanation of the connection/analogy between roots of unity and these functions.",,"['functional-analysis', 'number-theory', 'ordinary-differential-equations', 'roots-of-unity']"
59,I want to prove that $C_0(X)$ is Banach,I want to prove that  is Banach,C_0(X),"Let $X$ be locally compact Hausdorff space. I'm trying to prove that $$ C_0(X)=\{ f:X\to \mathbb{C} \; | \; f \text{ is continuous and }\forall \epsilon>0 \; \exists K(\text{compact}) \subset X \text{ s.t. } |f|<\epsilon \text{ on } X\setminus K\} $$ is complete space with $\sup$ norm. I tried as follows: Let $f_n$ be a Cauchy sequence in $C_0(X)$. Then for all $x\in X$, $$ |f_n(x) - f_m(x)| \le \|f_n - f_m\|_\infty \to 0 $$ as $n,m\to \infty$. So $\{f_n\}$ is Cauchy in $\mathbb C$ and therefore the limit $f(x) := \lim_{n\to \infty} f_n(x)$ exsits. Now I'm trying to show that this $f(x)$ satisfies $f\in C_0(X)$ and $\|f - f_n\|_\infty \to 0$ as $n\to \infty$. (1) Continuity: Since $\forall \epsilon>0$, $\exists N$: $\forall n,m\ge N$, $\forall x \in X, $ $|f_n(x) - f_m(x)| \le \|f_n - f_m\|_\infty < \epsilon$, taking $m\to \infty$, we have $|f_n(x) - f(x)| \le \epsilon$ so that $\{f_n\}$ converges uniformly to $f$ on $\mathbb C$, therefore $f$ is continuous. (2) $\forall \epsilon>0 $ $\exists K(\text{compact}) \subset X \text{ s.t. } |f|<\epsilon \text{ on } X\setminus K$ Since $f_N \in C_0(X)$, $\exists K$(compact) $\subset X$ s.t. $|f_N|< \epsilon$ on $X\setminus K$. So $$ |f| \le |f-f_N| + |f_N| \le \epsilon + \epsilon = 2\epsilon. $$ (3) From (1), we have $|f_n(x) - f(x)| \le \epsilon $ for $n \ge N$. So $\| f_n - f\|_\infty \le \epsilon$. I'm wondering that my proof is correct or not. Would you please confirm my solution? In fact, I'm wondering that $2\epsilon$ argument works or not in (2). Also I think I did not use the property that $X$ is locally compact and Hausdorff in my solution.","Let $X$ be locally compact Hausdorff space. I'm trying to prove that $$ C_0(X)=\{ f:X\to \mathbb{C} \; | \; f \text{ is continuous and }\forall \epsilon>0 \; \exists K(\text{compact}) \subset X \text{ s.t. } |f|<\epsilon \text{ on } X\setminus K\} $$ is complete space with $\sup$ norm. I tried as follows: Let $f_n$ be a Cauchy sequence in $C_0(X)$. Then for all $x\in X$, $$ |f_n(x) - f_m(x)| \le \|f_n - f_m\|_\infty \to 0 $$ as $n,m\to \infty$. So $\{f_n\}$ is Cauchy in $\mathbb C$ and therefore the limit $f(x) := \lim_{n\to \infty} f_n(x)$ exsits. Now I'm trying to show that this $f(x)$ satisfies $f\in C_0(X)$ and $\|f - f_n\|_\infty \to 0$ as $n\to \infty$. (1) Continuity: Since $\forall \epsilon>0$, $\exists N$: $\forall n,m\ge N$, $\forall x \in X, $ $|f_n(x) - f_m(x)| \le \|f_n - f_m\|_\infty < \epsilon$, taking $m\to \infty$, we have $|f_n(x) - f(x)| \le \epsilon$ so that $\{f_n\}$ converges uniformly to $f$ on $\mathbb C$, therefore $f$ is continuous. (2) $\forall \epsilon>0 $ $\exists K(\text{compact}) \subset X \text{ s.t. } |f|<\epsilon \text{ on } X\setminus K$ Since $f_N \in C_0(X)$, $\exists K$(compact) $\subset X$ s.t. $|f_N|< \epsilon$ on $X\setminus K$. So $$ |f| \le |f-f_N| + |f_N| \le \epsilon + \epsilon = 2\epsilon. $$ (3) From (1), we have $|f_n(x) - f(x)| \le \epsilon $ for $n \ge N$. So $\| f_n - f\|_\infty \le \epsilon$. I'm wondering that my proof is correct or not. Would you please confirm my solution? In fact, I'm wondering that $2\epsilon$ argument works or not in (2). Also I think I did not use the property that $X$ is locally compact and Hausdorff in my solution.",,"['real-analysis', 'functional-analysis']"
60,Continuous semi-norms on subspace,Continuous semi-norms on subspace,,"Suppose $X$ is a locally convex topological vector space, let $P$ be the set of all continuous semi-norms on $X$. Suppose $M$ is a subspace of $X$, denote $P|_M$ as the set of semi-norms in $P$ restricted on $M$. Is it true that $P|_M$ is the set of continuous semi-norms on $M$?","Suppose $X$ is a locally convex topological vector space, let $P$ be the set of all continuous semi-norms on $X$. Suppose $M$ is a subspace of $X$, denote $P|_M$ as the set of semi-norms in $P$ restricted on $M$. Is it true that $P|_M$ is the set of continuous semi-norms on $M$?",,"['functional-analysis', 'topological-vector-spaces', 'locally-convex-spaces']"
61,Find the bounds for the norm $T:l_2 \to l_2$.,Find the bounds for the norm .,T:l_2 \to l_2,"Given $T:l_2 \to l_2$ define as $T((x_1,x_2,\ldots,x_n,\ldots))=(x_2-x_1,x_3-x_2,\ldots,x_{n+1}-x_n,\ldots)$ then which of the following is true, $\|T\|=1$ $\|T\|\geq2$ $1<\|T\|\leq2$ None of above. What I did- I used $\|T\|^2=\langle T,T\rangle$, so after calculation I got $\|T(x)\| = \left( \sum_{i=1}^\infty (x_{i+1}-x_i)^2 \right)^{1/2}$. Now I got stuck. How to proceed further? Please help.","Given $T:l_2 \to l_2$ define as $T((x_1,x_2,\ldots,x_n,\ldots))=(x_2-x_1,x_3-x_2,\ldots,x_{n+1}-x_n,\ldots)$ then which of the following is true, $\|T\|=1$ $\|T\|\geq2$ $1<\|T\|\leq2$ None of above. What I did- I used $\|T\|^2=\langle T,T\rangle$, so after calculation I got $\|T(x)\| = \left( \sum_{i=1}^\infty (x_{i+1}-x_i)^2 \right)^{1/2}$. Now I got stuck. How to proceed further? Please help.",,['functional-analysis']
62,Morrey's inequality for Sobolev spaces of fractional order,Morrey's inequality for Sobolev spaces of fractional order,,"Let $H^s(\mathbb T)$, where $s\in\mathbb R$,  be the space of $2\pi$-periodic functions, $u(x)=\sum_{k\in\mathbb Z}\hat u_k\,\mathrm{e}^{ikx}$, such that  $$ \|u\|_{H^s}^2=\sum_{k\in\mathbb Z}(1+k^2)^{s}\lvert \hat u_k\rvert^2<\infty. $$ Assume now that $s\in \big(\frac{1}{2},\frac{3}{2}\big)$. Is it true that there exist a constant $c=c_s$, such that $$ \lvert u(x)-u(y)\rvert\le c \|u\|_{H^s}\lvert x-y\rvert^{s-\frac{1}{2}}? $$ If $s=1$, then the above is a special case of the the celebrated Morrey's inequality. Reference would be welcome.","Let $H^s(\mathbb T)$, where $s\in\mathbb R$,  be the space of $2\pi$-periodic functions, $u(x)=\sum_{k\in\mathbb Z}\hat u_k\,\mathrm{e}^{ikx}$, such that  $$ \|u\|_{H^s}^2=\sum_{k\in\mathbb Z}(1+k^2)^{s}\lvert \hat u_k\rvert^2<\infty. $$ Assume now that $s\in \big(\frac{1}{2},\frac{3}{2}\big)$. Is it true that there exist a constant $c=c_s$, such that $$ \lvert u(x)-u(y)\rvert\le c \|u\|_{H^s}\lvert x-y\rvert^{s-\frac{1}{2}}? $$ If $s=1$, then the above is a special case of the the celebrated Morrey's inequality. Reference would be welcome.",,"['real-analysis', 'functional-analysis', 'sobolev-spaces', 'harmonic-analysis', 'holder-spaces']"
63,What is the image of the linear mapping ${P} : \mathbb{V}\rightarrow \mathbb{V}$ where $(Pf)(x)= [f(x) + f(-x)]/2$,What is the image of the linear mapping  where,{P} : \mathbb{V}\rightarrow \mathbb{V} (Pf)(x)= [f(x) + f(-x)]/2,"Let the linear mapping ${P} : \mathbb{V}\rightarrow \mathbb{V}$ where $\mathbb{V}$ is the space of all functions real valueted of real variable, namely x, we set the image under ${P}$ of a function f(x) to be $$(Pf)(x)= \frac{f(x) + f(-x)}{2},$$ what can i say about the image of $\mathbb{V}$ under ${P}$ ? My initial hypothesis was that the direct image on the whole domain would be the set of all function but the odd functions, i proved if $\mathbb{V}$ is composed only by either odd function or even functions, but trying to be more general, stating $\mathbb{V}$ to be the set defined on the first paragraph i could not prove. Someone know a way to do this?","Let the linear mapping ${P} : \mathbb{V}\rightarrow \mathbb{V}$ where $\mathbb{V}$ is the space of all functions real valueted of real variable, namely x, we set the image under ${P}$ of a function f(x) to be $$(Pf)(x)= \frac{f(x) + f(-x)}{2},$$ what can i say about the image of $\mathbb{V}$ under ${P}$ ? My initial hypothesis was that the direct image on the whole domain would be the set of all function but the odd functions, i proved if $\mathbb{V}$ is composed only by either odd function or even functions, but trying to be more general, stating $\mathbb{V}$ to be the set defined on the first paragraph i could not prove. Someone know a way to do this?",,"['real-analysis', 'general-topology', 'functional-analysis']"
64,Is the sum of an infinite series of elements in the span of an orthonormal set also in that set?,Is the sum of an infinite series of elements in the span of an orthonormal set also in that set?,,"If $(e_k)$ is an orthonormal sequence in some Hilbert space $H$ does it follow that, if for a set of scalars $\{\alpha_k\}$, the series $$\sum_{k=1}^{\infty}\alpha_ke_k$$ converges to an $x \in H$, then $x\in span(e_k)=M$? For a finite sum the answer would obviously be true, but I often miss subtleties when infinity comes to play. I think that we could possibly have $x\in \bar M$ and not $x\in M$ if there are an infinite number of non-zero scalars in $\{\alpha_k\}$, but before pursuing this I'd like to confirm whether $x$ will always just be an element of the span or not. EDIT: The two excellent answers below indicate to me that I have asked a question with answers possibly above my needs and current ability to understand. So to hopefully aid answering I'd like to give more context to my question. The question stems from a problem in Kreyszig's introductory functional analysis textbook, which, in the terminology developed above, asks: ""For any $x\in H$ show that $x\in \bar M$ if $x=\sum_{k=1}^{\infty}\langle x,e_k\rangle e_k$"". If the solution to this problem is different from the general question I asked please explain why and if possible give a hint for a possible proof I could use. I should also add that I am not at all familiar with topology as that course follows functional analysis in my university.","If $(e_k)$ is an orthonormal sequence in some Hilbert space $H$ does it follow that, if for a set of scalars $\{\alpha_k\}$, the series $$\sum_{k=1}^{\infty}\alpha_ke_k$$ converges to an $x \in H$, then $x\in span(e_k)=M$? For a finite sum the answer would obviously be true, but I often miss subtleties when infinity comes to play. I think that we could possibly have $x\in \bar M$ and not $x\in M$ if there are an infinite number of non-zero scalars in $\{\alpha_k\}$, but before pursuing this I'd like to confirm whether $x$ will always just be an element of the span or not. EDIT: The two excellent answers below indicate to me that I have asked a question with answers possibly above my needs and current ability to understand. So to hopefully aid answering I'd like to give more context to my question. The question stems from a problem in Kreyszig's introductory functional analysis textbook, which, in the terminology developed above, asks: ""For any $x\in H$ show that $x\in \bar M$ if $x=\sum_{k=1}^{\infty}\langle x,e_k\rangle e_k$"". If the solution to this problem is different from the general question I asked please explain why and if possible give a hint for a possible proof I could use. I should also add that I am not at all familiar with topology as that course follows functional analysis in my university.",,"['sequences-and-series', 'functional-analysis', 'fourier-series']"
65,Can $C^\infty(\mathbb{T})$ become a Banach space?,Can  become a Banach space?,C^\infty(\mathbb{T}),"Let $T$ be the unit circle and $C^\infty(\mathbb{T})$ the set of functions defined on $\mathbb{T}$ which have derivatives of every order. I know that $C^\infty(\mathbb{T})$ with the metric induced by the seminorms  $$\sup_{t\in\mathbb{R}}|f^{(l)}(e^{it})|,l\geq 0$$ is complete (but not a Banach space with the seminorms themselves i.e. its locally convex structure cannot be defined by one norm). Is there any chance that we can define some kind of norm on $C^\infty(\mathbb{T})$ in order to become a Banach space?","Let $T$ be the unit circle and $C^\infty(\mathbb{T})$ the set of functions defined on $\mathbb{T}$ which have derivatives of every order. I know that $C^\infty(\mathbb{T})$ with the metric induced by the seminorms  $$\sup_{t\in\mathbb{R}}|f^{(l)}(e^{it})|,l\geq 0$$ is complete (but not a Banach space with the seminorms themselves i.e. its locally convex structure cannot be defined by one norm). Is there any chance that we can define some kind of norm on $C^\infty(\mathbb{T})$ in order to become a Banach space?",,['functional-analysis']
66,convolution with integration by parts,convolution with integration by parts,,"I have a question for an equation from a paper. The paper says, $$ \frac{\partial c}{\partial t}*g=\int_0^t \frac{\partial c(t-\tau)}{\partial \tau}g(\tau) d\tau=c*\frac{\partial g}{\partial t}+cg_0-c_0g $$ When I use the rule of integration by parts, I got different answer. More specifically, my derivation shows that the right hand side is in negative. Here is my derivation, $$ \frac{\partial c}{\partial t}*g=c(t-\tau)g(\tau)|_0^t-\int_0^t c(t-\tau)\frac{\partial g(\tau)}{\partial \tau}d\tau=-(c*\frac{\partial g}{\partial t}+cg_0-c_0g ) $$ I have been struggling for this for the whole day. Hope someone can help me. Thanks in advance.","I have a question for an equation from a paper. The paper says, $$ \frac{\partial c}{\partial t}*g=\int_0^t \frac{\partial c(t-\tau)}{\partial \tau}g(\tau) d\tau=c*\frac{\partial g}{\partial t}+cg_0-c_0g $$ When I use the rule of integration by parts, I got different answer. More specifically, my derivation shows that the right hand side is in negative. Here is my derivation, $$ \frac{\partial c}{\partial t}*g=c(t-\tau)g(\tau)|_0^t-\int_0^t c(t-\tau)\frac{\partial g(\tau)}{\partial \tau}d\tau=-(c*\frac{\partial g}{\partial t}+cg_0-c_0g ) $$ I have been struggling for this for the whole day. Hope someone can help me. Thanks in advance.",,"['calculus', 'algebra-precalculus', 'functional-analysis']"
67,Proving that dual space of $L^\infty(\mathbb{R})$ is not separable,Proving that dual space of  is not separable,L^\infty(\mathbb{R}),"This is the second part of a problem in Stein and Shakarchi's Functional Analysis. I proved in the first part that $L^\infty(\mathbb{R})$ is not separable by constructing for each $a \in \mathbb{R}$ an $f_a \in L^\infty$, with $\|f_a - f_b\| \geq 1$ if $a \neq b$. I tried similar trick to dual space of $L^\infty(\mathbb{R})$, but I don't think I have enough intuition about the space to show that it is not separable. Can anyone help me out? Thank you so much!","This is the second part of a problem in Stein and Shakarchi's Functional Analysis. I proved in the first part that $L^\infty(\mathbb{R})$ is not separable by constructing for each $a \in \mathbb{R}$ an $f_a \in L^\infty$, with $\|f_a - f_b\| \geq 1$ if $a \neq b$. I tried similar trick to dual space of $L^\infty(\mathbb{R})$, but I don't think I have enough intuition about the space to show that it is not separable. Can anyone help me out? Thank you so much!",,"['real-analysis', 'functional-analysis', 'lp-spaces', 'dual-spaces', 'separable-spaces']"
68,Are all operators to or from $\ell_1$ completely continuous?,Are all operators to or from  completely continuous?,\ell_1,"Let $E$ and $F$ be two Banach spaces, and let $T \in \mathcal{L}(E, F)$. Consider the following property (P). For every weakly convergent sequence $(u_n)$ in $E$, $u_n \rightharpoonup u$, then $Tu_n \to Tu$ strongly in $F$. Assume that either $E = \ell^1$ or $F = \ell^1$. Does every operator $T \in \mathcal{L}(E, F)$ satisfy (P)? Edit. Here, we denote by $\mathcal{L}(E, F)$ the space of continuous, i.e. bounded, linear operators from $E$ into $F$ equipped with the norm$$\|T\|_{\mathcal{L}(E, F)} = \sup_{x \in E,\,\|x\| \le 1} \|Tx\|.$$","Let $E$ and $F$ be two Banach spaces, and let $T \in \mathcal{L}(E, F)$. Consider the following property (P). For every weakly convergent sequence $(u_n)$ in $E$, $u_n \rightharpoonup u$, then $Tu_n \to Tu$ strongly in $F$. Assume that either $E = \ell^1$ or $F = \ell^1$. Does every operator $T \in \mathcal{L}(E, F)$ satisfy (P)? Edit. Here, we denote by $\mathcal{L}(E, F)$ the space of continuous, i.e. bounded, linear operators from $E$ into $F$ equipped with the norm$$\|T\|_{\mathcal{L}(E, F)} = \sup_{x \in E,\,\|x\| \le 1} \|Tx\|.$$",,"['functional-analysis', 'operator-theory', 'banach-spaces']"
69,Eigenvalue equation and separable solutions,Eigenvalue equation and separable solutions,,"Recently, studying Quantum Mechanics I found a doubt regarding separable solutions and eigenvalue equations for differential operators. Suppose we are considering some space $\mathcal{H}$ of functions in $\mathbb{R}^3$ with values in $\mathbb{C}$, like $L^2(\mathbb{R}^3)$. Now consider a certain differential operator $A$ in $\mathcal{H}$ and the eigenvalue equation for $A$: $$A\psi = \lambda \psi.$$ This is a partial differential equation, if $A$ is a differential operator. Now, suppose for simplicity we already know the spectrum of $A$ and we want to solve it to find the eigenvectors. Since it is a PDE the first strategy would be separation of variables. In that case we consider, using for example cartesian coordinates that $\psi(x,y,z)=X(x)Y(y)Z(z)$. If everything works, what we will achieve is that we will find that if $\psi$ is separable, then it is a solution with $X$,$Y$ and $Z$ given by something we found . This, however, doesn't say the converse: that if $\psi$ is an eigenfunction of $A$, it is necessarily of the form $\psi(x,y,z)=X(x)Y(y)Z(z)$ . Indeed, if $\psi_1$ and $\psi_2$ are separable solutions their sum, which is not a separable solution in general, also satisfies $A(\psi_1+\psi_2)=\lambda(\psi_1+\psi_2)$. My question is: if $\psi$ is an eigenfunction of a differential operator $A$ for a known eigenvalue $\lambda$, is $\psi$ necessarily separable? My whole point is: when we pick the eigenvalue equation and use separation of variables we show that ""being separable implies being an eigenfunction"", but the converse doesn't seem to be imediate. Is the converse true?","Recently, studying Quantum Mechanics I found a doubt regarding separable solutions and eigenvalue equations for differential operators. Suppose we are considering some space $\mathcal{H}$ of functions in $\mathbb{R}^3$ with values in $\mathbb{C}$, like $L^2(\mathbb{R}^3)$. Now consider a certain differential operator $A$ in $\mathcal{H}$ and the eigenvalue equation for $A$: $$A\psi = \lambda \psi.$$ This is a partial differential equation, if $A$ is a differential operator. Now, suppose for simplicity we already know the spectrum of $A$ and we want to solve it to find the eigenvectors. Since it is a PDE the first strategy would be separation of variables. In that case we consider, using for example cartesian coordinates that $\psi(x,y,z)=X(x)Y(y)Z(z)$. If everything works, what we will achieve is that we will find that if $\psi$ is separable, then it is a solution with $X$,$Y$ and $Z$ given by something we found . This, however, doesn't say the converse: that if $\psi$ is an eigenfunction of $A$, it is necessarily of the form $\psi(x,y,z)=X(x)Y(y)Z(z)$ . Indeed, if $\psi_1$ and $\psi_2$ are separable solutions their sum, which is not a separable solution in general, also satisfies $A(\psi_1+\psi_2)=\lambda(\psi_1+\psi_2)$. My question is: if $\psi$ is an eigenfunction of a differential operator $A$ for a known eigenvalue $\lambda$, is $\psi$ necessarily separable? My whole point is: when we pick the eigenvalue equation and use separation of variables we show that ""being separable implies being an eigenfunction"", but the converse doesn't seem to be imediate. Is the converse true?",,"['analysis', 'functional-analysis', 'partial-differential-equations', 'eigenvalues-eigenvectors', 'quantum-mechanics']"
70,sum of open balls in normed space,sum of open balls in normed space,,"Let $X$ be a normed nonempty space and $x \in X$ . We define the set: $$B(x,r)=\{y \in X:\|y-x\|<r\}$$ ; I have to show that: $$B(x+x',r+r')=B(x,r)+B(x',r')$$ . I proved an inclusion like that: let $a \in B(x,r)+B(x',r')$ ; so $a=a_{1}+a_{2}$ , with $a_{1}\in B(x,r)$ and $a_{2}$ in the other ball; we have that $$\|x-a_1\|<r, \|x'-a_2\|<r'$$ ; suming up, we obtain: $\|x+x'-a_1-a_2\|\le \|x-a_1\|+\|x-a_2\|<r+r'$ ; so $\|x+x'-a\|<r+r'$ and we obtain that $a \in B(x+x',r+r')$ ; for the reverse inclusion, I dont see a solution at all; let $a \in B(x+x',r+r'$ ; so we have that $\|x+x'-a\|<r+r'$ ; I have to find $a_1,a_2 $ , such that $a=a_1+a_2$ and $a_1\in B(x,r)$ and $a_2$ in the other ball. Is a useful idea to use that these balls are convex?","Let be a normed nonempty space and . We define the set: ; I have to show that: . I proved an inclusion like that: let ; so , with and in the other ball; we have that ; suming up, we obtain: ; so and we obtain that ; for the reverse inclusion, I dont see a solution at all; let ; so we have that ; I have to find , such that and and in the other ball. Is a useful idea to use that these balls are convex?","X x \in X B(x,r)=\{y \in X:\|y-x\|<r\} B(x+x',r+r')=B(x,r)+B(x',r') a \in B(x,r)+B(x',r') a=a_{1}+a_{2} a_{1}\in B(x,r) a_{2} \|x-a_1\|<r, \|x'-a_2\|<r' \|x+x'-a_1-a_2\|\le \|x-a_1\|+\|x-a_2\|<r+r' \|x+x'-a\|<r+r' a \in B(x+x',r+r') a \in B(x+x',r+r' \|x+x'-a\|<r+r' a_1,a_2  a=a_1+a_2 a_1\in B(x,r) a_2",['functional-analysis']
71,Polynomials form a Hilbert basis for $L^2$,Polynomials form a Hilbert basis for,L^2,"If you form a set of orthonormal polynomials on $[0,1]$, by applying the Gram-Schmidt process from monomials $\{1, x, x^2, \dots \}$ then what is required to show that this is a basis for $L^2[0,1]$? $\text{Span}\{ e_n \}_{n \in \mathbb{N}} = L^2[0,1]$? How can I use this to prove the above? Edit: I believe I need to show that the span of the vectors I got from Gram-Schmidt is orthonormal and complete. I can show it is orthonormal, to show completeness I need to use Stone-Weierstrass to show this for continuous functions on the domain, and then a density argument for $L^2$.","If you form a set of orthonormal polynomials on $[0,1]$, by applying the Gram-Schmidt process from monomials $\{1, x, x^2, \dots \}$ then what is required to show that this is a basis for $L^2[0,1]$? $\text{Span}\{ e_n \}_{n \in \mathbb{N}} = L^2[0,1]$? How can I use this to prove the above? Edit: I believe I need to show that the span of the vectors I got from Gram-Schmidt is orthonormal and complete. I can show it is orthonormal, to show completeness I need to use Stone-Weierstrass to show this for continuous functions on the domain, and then a density argument for $L^2$.",,"['real-analysis', 'functional-analysis', 'hilbert-spaces']"
72,$U^\dagger U=id \nRightarrow UU^\dagger=id$ for infinite dimensional vector spaces,for infinite dimensional vector spaces,U^\dagger U=id \nRightarrow UU^\dagger=id,"I wasn't sure whether this question was appropriate for math.stackexchange or physics.stackexchange. I don't really have an understanding of bounded linear operators or Hilbert spaces so this question may be slightly informal. Nevertheless, let $U$ be a linear operator with adjoint $U^\dagger$. I've read that for only finite dimensional vector spaces, $U^\dagger U=id \Rightarrow UU^\dagger=id$. Could someone please explain why this is the case and provide an example of an infinite dimensional vector space for which the implication doesn't hold?","I wasn't sure whether this question was appropriate for math.stackexchange or physics.stackexchange. I don't really have an understanding of bounded linear operators or Hilbert spaces so this question may be slightly informal. Nevertheless, let $U$ be a linear operator with adjoint $U^\dagger$. I've read that for only finite dimensional vector spaces, $U^\dagger U=id \Rightarrow UU^\dagger=id$. Could someone please explain why this is the case and provide an example of an infinite dimensional vector space for which the implication doesn't hold?",,['functional-analysis']
73,Is it true $\left \| T(x) \right \| \le \left \| T \right \| \cdot \left \| x \right \| $,Is it true,\left \| T(x) \right \| \le \left \| T \right \| \cdot \left \| x \right \| ,Let be $E$ a real Banach space and $E^*$ the real dual space. $\forall T \in E^*$ Is it true $\left \| T(x) \right \| \le \left \| T \right \| \cdot \left \|  x \right \| $? Why? Let be $\{ T_n \}_n$ a Cauchy's sequence. Is it true $\left \| T_n(x)-T_m(x) \right \| \le \left \| T_n-T_m \right \| \cdot \left \|  x \right \| $? Why? Thanks to all. NOTE: In my book (Brezis' one) the norm is define as: $$ \left \| T \right \|= \sup_{\left \| x \right \| \le 1} \left \| T(x) \right \| $$,Let be $E$ a real Banach space and $E^*$ the real dual space. $\forall T \in E^*$ Is it true $\left \| T(x) \right \| \le \left \| T \right \| \cdot \left \|  x \right \| $? Why? Let be $\{ T_n \}_n$ a Cauchy's sequence. Is it true $\left \| T_n(x)-T_m(x) \right \| \le \left \| T_n-T_m \right \| \cdot \left \|  x \right \| $? Why? Thanks to all. NOTE: In my book (Brezis' one) the norm is define as: $$ \left \| T \right \|= \sup_{\left \| x \right \| \le 1} \left \| T(x) \right \| $$,,['functional-analysis']
74,"$c_0$, the space of sequences converging $0$ is complete with dual $\ell^1(\mathbb{N})$",", the space of sequences converging  is complete with dual",c_0 0 \ell^1(\mathbb{N}),"Let $c_0$ be the space of all complex sequences $(a_n)$ such that $$\lim_{n \to \infty} |a_n| =0$$  with norm $\|(a_n)\|_{c_0} = \sup_{n} |a_n|$. Is it fair to say that: Let $\{(a_n)\}_{n \in \mathbb{N}}$ be a cauchy sequence in $c_0$. Let $\epsilon >0$. Then there exists $N$ such that for $n,m \geq N$,  $$\|(a_n) - (a_m)\|_{c_0} = \sup_{k} |a_{n,k}-a_{m,k}| < \frac{\epsilon}{2}.$$ Let $n_0 \geq N$. Notice also that since $(a_{n_0}) \in c_0$, there exists $K$ such that, for $k \geq K$, $|a_{n_0,k}| < \frac{\epsilon}{2}$. Therefore, define $(a) \in c_0$ as the sequence $a_k = a_{n_0,k}$ for $k < K$ and $a_k = 0$ for $k \geq K$. Then for $n_0$ as before and  $m \geq N$, $\|(a_m)-(a)\|_{c_0} \leq \|(a_m)-(a_{n_0}) \|_{c_0} +  \|(a_m)-(a_{n_0}) \|_{c_0} < \epsilon$. Thus, $\{(a_n)\}$ converges so $c_0$ is complete.  ? I was unsure about this proof since it seems that the cauchy sequence could converge to different limits, but I suppose in the uniform norm of $c_0$, the limits would only differ by $\epsilon$ so the limit is unique. Finally I need to show that $\ell^1(\mathbb{N})$ is the dual space of $c_0$. Is it correct to say that, given $(x_n) \in \ell^1$, I want the action of $$(x_n) : c_0 \to \mathbb{C}$$ to be defined as $$(x_n): (a_n) \mapsto \sum_{n \in \mathbb{N}} x_n\overline{a_n}?$$ This clearly converges by comparison, and I'm left to show that all such linear functionals arise this way. It seems prudent to say that a linear functional on $(a_n) \in c_0$ can be determined by it's action on finite truncations of $(a_n)$, and therefore can be identified with some element in $$\operatorname{span}\{e_i\}_{i \in \mathbb{N}}$$ for $e_i$ the orthonormal hilbert basis for $\ell^1(\mathbb{N})$. A very slight hint on how to proceed with this would be appreciated, but please please only a slight hint. I want to proceed on my own.","Let $c_0$ be the space of all complex sequences $(a_n)$ such that $$\lim_{n \to \infty} |a_n| =0$$  with norm $\|(a_n)\|_{c_0} = \sup_{n} |a_n|$. Is it fair to say that: Let $\{(a_n)\}_{n \in \mathbb{N}}$ be a cauchy sequence in $c_0$. Let $\epsilon >0$. Then there exists $N$ such that for $n,m \geq N$,  $$\|(a_n) - (a_m)\|_{c_0} = \sup_{k} |a_{n,k}-a_{m,k}| < \frac{\epsilon}{2}.$$ Let $n_0 \geq N$. Notice also that since $(a_{n_0}) \in c_0$, there exists $K$ such that, for $k \geq K$, $|a_{n_0,k}| < \frac{\epsilon}{2}$. Therefore, define $(a) \in c_0$ as the sequence $a_k = a_{n_0,k}$ for $k < K$ and $a_k = 0$ for $k \geq K$. Then for $n_0$ as before and  $m \geq N$, $\|(a_m)-(a)\|_{c_0} \leq \|(a_m)-(a_{n_0}) \|_{c_0} +  \|(a_m)-(a_{n_0}) \|_{c_0} < \epsilon$. Thus, $\{(a_n)\}$ converges so $c_0$ is complete.  ? I was unsure about this proof since it seems that the cauchy sequence could converge to different limits, but I suppose in the uniform norm of $c_0$, the limits would only differ by $\epsilon$ so the limit is unique. Finally I need to show that $\ell^1(\mathbb{N})$ is the dual space of $c_0$. Is it correct to say that, given $(x_n) \in \ell^1$, I want the action of $$(x_n) : c_0 \to \mathbb{C}$$ to be defined as $$(x_n): (a_n) \mapsto \sum_{n \in \mathbb{N}} x_n\overline{a_n}?$$ This clearly converges by comparison, and I'm left to show that all such linear functionals arise this way. It seems prudent to say that a linear functional on $(a_n) \in c_0$ can be determined by it's action on finite truncations of $(a_n)$, and therefore can be identified with some element in $$\operatorname{span}\{e_i\}_{i \in \mathbb{N}}$$ for $e_i$ the orthonormal hilbert basis for $\ell^1(\mathbb{N})$. A very slight hint on how to proceed with this would be appreciated, but please please only a slight hint. I want to proceed on my own.",,"['linear-algebra', 'functional-analysis', 'proof-verification', 'hilbert-spaces', 'duality-theorems']"
75,Different proofs for the $L^2$ isometry of the Fourier transform on $\Bbb R$,Different proofs for the  isometry of the Fourier transform on,L^2 \Bbb R,"Over the years I have come across several different proofs for the $L^2$ isometry of the Fourier transform (as it exists as an integral operator on $\Bbb R$). Often the traditional proofs hinge on the use of the Schwartz space or $L^1(\Bbb R)\cap L^2(\Bbb R)$ in conjunction with the convolution theorem. I recently came up with a proof that doesn't use the convolution theorem at all and is instead somewhat of a ""pure"" $L^2$ approach while still working on $L^1(\Bbb R)\cap L^2(\Bbb R)$. I am sure it is not a new proof, but I will post it as an answer below. This led me to wonder just how many different fairly well-known proofs there are for the $L^2$ isometry of the Fourier transform on $\Bbb R$. I was hoping that we could collect some of them in a big list. Of course replicating a full proof is not advisable since they can be quite lengthy, but a brief, rough outline would be quite appreciated along with a text or PDF reference for the full proof. One of the issues with integral transform theory is that proof techniques vary wildly from one integral transform to another. What I am hoping to accomplish with this list is that it will provide a wealth of approaches for showing $L^2$ properties of integral transforms.","Over the years I have come across several different proofs for the $L^2$ isometry of the Fourier transform (as it exists as an integral operator on $\Bbb R$). Often the traditional proofs hinge on the use of the Schwartz space or $L^1(\Bbb R)\cap L^2(\Bbb R)$ in conjunction with the convolution theorem. I recently came up with a proof that doesn't use the convolution theorem at all and is instead somewhat of a ""pure"" $L^2$ approach while still working on $L^1(\Bbb R)\cap L^2(\Bbb R)$. I am sure it is not a new proof, but I will post it as an answer below. This led me to wonder just how many different fairly well-known proofs there are for the $L^2$ isometry of the Fourier transform on $\Bbb R$. I was hoping that we could collect some of them in a big list. Of course replicating a full proof is not advisable since they can be quite lengthy, but a brief, rough outline would be quite appreciated along with a text or PDF reference for the full proof. One of the issues with integral transform theory is that proof techniques vary wildly from one integral transform to another. What I am hoping to accomplish with this list is that it will provide a wealth of approaches for showing $L^2$ properties of integral transforms.",,"['functional-analysis', 'fourier-analysis', 'big-list']"
76,Hint for Lebesgue theory/functional analysis type of problem,Hint for Lebesgue theory/functional analysis type of problem,,"I am trying to solve the following problem, but I am not too familiar with functional analysis. Could you guys tell me where I should start? Thanks! Let $f \in L^1(\mathbb{R})$ and define  $$f_n(x) = \frac{1}{n} \int_x^{x+n} f(t)\,dt.$$ Show that $\|f_n\|_1 \leq \|f\|_1$ and $\|f_n-f\|_1 \to 0$ as $n \to 0$. This seem quite intuitive given $f_n$, but I have no idea where to start to formally prove it. Thank you so much!","I am trying to solve the following problem, but I am not too familiar with functional analysis. Could you guys tell me where I should start? Thanks! Let $f \in L^1(\mathbb{R})$ and define  $$f_n(x) = \frac{1}{n} \int_x^{x+n} f(t)\,dt.$$ Show that $\|f_n\|_1 \leq \|f\|_1$ and $\|f_n-f\|_1 \to 0$ as $n \to 0$. This seem quite intuitive given $f_n$, but I have no idea where to start to formally prove it. Thank you so much!",,"['functional-analysis', 'measure-theory', 'lebesgue-integral', 'lp-spaces']"
77,"Find $f\in L^2(0,1)$ with $\int_0^1 xf(x)dx = \langle x, f(x)\rangle = 1$ of minimal norm.",Find  with  of minimal norm.,"f\in L^2(0,1) \int_0^1 xf(x)dx = \langle x, f(x)\rangle = 1","I would like to get more hints to the following question. Find $f\in L^2(0,1)$ with $\int_0^1 xf(x)dx = \langle x, f(x)\rangle = 1$ of minimal norm (with the standard norm in $L^2(0,1)$). I figured that I need to do something with orthogonality, but I have no Idea how to proceed. I think I should decompose the space $M = \{g\in L^2(0,1)| \int_0^1 xg(x)dx= 1\}$ in a direct sum, such that $M = G\oplus G^{\perp}$. Furthermore, I could imagine this space $M$ as a hyperplane with $G^{\perp}$ sticking out and which holds the solution. So maybe I need to do something with the an inproduct being zero and maybe something with translations. Question: is that even remotely correct and if so, how could I tie that together? Thank you for your time.","I would like to get more hints to the following question. Find $f\in L^2(0,1)$ with $\int_0^1 xf(x)dx = \langle x, f(x)\rangle = 1$ of minimal norm (with the standard norm in $L^2(0,1)$). I figured that I need to do something with orthogonality, but I have no Idea how to proceed. I think I should decompose the space $M = \{g\in L^2(0,1)| \int_0^1 xg(x)dx= 1\}$ in a direct sum, such that $M = G\oplus G^{\perp}$. Furthermore, I could imagine this space $M$ as a hyperplane with $G^{\perp}$ sticking out and which holds the solution. So maybe I need to do something with the an inproduct being zero and maybe something with translations. Question: is that even remotely correct and if so, how could I tie that together? Thank you for your time.",,"['functional-analysis', 'normed-spaces', 'approximation']"
78,The dual vector space is always complete. [duplicate],The dual vector space is always complete. [duplicate],,"This question already has answers here : Proof of ""Dual normed vector space is complete"" (2 answers) Closed 6 years ago . If $N$ is a normed a linear space, then its dual vector space $N^*$ is always complete. Attempt: Let $\{f_n\}$ be a Cauchy sequence in $N^*$. Then, for some $\varepsilon > 0$ , there exists $m,n \in \mathbb{N}$ such that $\|f_n - f_m \| < \varepsilon$. The way to show that the limit lies in $N^*$ would be to show that $f_n(x)$ converges in $K = \mathbb{C}$ or $\mathbb{R}$. How do I show that the limit of linear functionals is still a linear functional?","This question already has answers here : Proof of ""Dual normed vector space is complete"" (2 answers) Closed 6 years ago . If $N$ is a normed a linear space, then its dual vector space $N^*$ is always complete. Attempt: Let $\{f_n\}$ be a Cauchy sequence in $N^*$. Then, for some $\varepsilon > 0$ , there exists $m,n \in \mathbb{N}$ such that $\|f_n - f_m \| < \varepsilon$. The way to show that the limit lies in $N^*$ would be to show that $f_n(x)$ converges in $K = \mathbb{C}$ or $\mathbb{R}$. How do I show that the limit of linear functionals is still a linear functional?",,"['linear-algebra', 'functional-analysis', 'normed-spaces', 'complete-spaces']"
79,How do I prove that $I+T^*T$ is invertible?,How do I prove that  is invertible?,I+T^*T,"Let $T$ be a bounded linear operator in a Hilbert space, $T^*$ the adjoint of $T$ .  Then how to show that $I + T^*T$ is invertible? Thanks.","Let be a bounded linear operator in a Hilbert space, the adjoint of .  Then how to show that is invertible? Thanks.",T T^* T I + T^*T,['functional-analysis']
80,Generalized Monomials,Generalized Monomials,,"Let $P$ be the set of all power functions $p_a$: $(0, \infty)\longrightarrow\mathbb{R}$, $x\mapsto x^a$, indexed by $a\in [0, \infty)$. Is $P$ linearly independent over $\mathbb{R}$? Intuitively, the answer is clearly yes (at least to me), but it seems to be escaping straightforward proof attempts. Follow-up question: Does the subspace of $C^{\infty}((0, \infty))$ spanned by $P$ admit some ""nice"" characterization?","Let $P$ be the set of all power functions $p_a$: $(0, \infty)\longrightarrow\mathbb{R}$, $x\mapsto x^a$, indexed by $a\in [0, \infty)$. Is $P$ linearly independent over $\mathbb{R}$? Intuitively, the answer is clearly yes (at least to me), but it seems to be escaping straightforward proof attempts. Follow-up question: Does the subspace of $C^{\infty}((0, \infty))$ spanned by $P$ admit some ""nice"" characterization?",,"['linear-algebra', 'functional-analysis']"
81,"Linear map $L : C([0,1])\rightarrow C([0,1])$ continuous?",Linear map  continuous?,"L : C([0,1])\rightarrow C([0,1])","Let $X=C([0,1])$ equipped with the norm $\Vert\cdot \Vert=\max_{x\in [0,1]}|f(x)|$. If $L:X\rightarrow X$  is linear, is $L$  continuous? If not, what if $Lf\ge 0$ for $f\ge0$ for $\forall x \in [0,1]$ is assumed? Edit: Rephrased the question. Edit2: Attempt, Let, $\Vert f_n \Vert \rightarrow 0$ when $n\rightarrow \infty$ and $f_n=\sum_{i=0}^{\infty}\alpha^{(n)}_i x^{i} $ then $\Vert Lf_n\Vert=\max_{x\in [0,1]}|\sum_{i=0}^{\infty}\alpha^{(n)}_i Lx^{i}| \rightarrow 0$ Because $\forall \alpha^{(n)}_i \rightarrow 0$ when $n\rightarrow \infty$. But i don't know if this is allowed?","Let $X=C([0,1])$ equipped with the norm $\Vert\cdot \Vert=\max_{x\in [0,1]}|f(x)|$. If $L:X\rightarrow X$  is linear, is $L$  continuous? If not, what if $Lf\ge 0$ for $f\ge0$ for $\forall x \in [0,1]$ is assumed? Edit: Rephrased the question. Edit2: Attempt, Let, $\Vert f_n \Vert \rightarrow 0$ when $n\rightarrow \infty$ and $f_n=\sum_{i=0}^{\infty}\alpha^{(n)}_i x^{i} $ then $\Vert Lf_n\Vert=\max_{x\in [0,1]}|\sum_{i=0}^{\infty}\alpha^{(n)}_i Lx^{i}| \rightarrow 0$ Because $\forall \alpha^{(n)}_i \rightarrow 0$ when $n\rightarrow \infty$. But i don't know if this is allowed?",,['functional-analysis']
82,Why in normed vector spaces we can define infinite series but in metric space we can not?,Why in normed vector spaces we can define infinite series but in metric space we can not?,,"We usually define infinite series by partial sums and an inifinite series is said to converge if its partial sum converges. So, if $X$ is a normed vector spaces and $s_n=x_1+...+x_m$ is a partial sum then infinite series converges to s if \begin{align} \lim_{n \to \infty}||s-s_n||=0. \end{align} My question why can't the same be done in vector metric spaces? We can still define converges as \begin{align} \lim_{n \to \infty}d(s,s_n)=0 \end{align} Certainly when a metric is induced by a norm this is not a problem. But why is it a problem in the case when metric can not be defined by a norm?","We usually define infinite series by partial sums and an inifinite series is said to converge if its partial sum converges. So, if $X$ is a normed vector spaces and $s_n=x_1+...+x_m$ is a partial sum then infinite series converges to s if \begin{align} \lim_{n \to \infty}||s-s_n||=0. \end{align} My question why can't the same be done in vector metric spaces? We can still define converges as \begin{align} \lim_{n \to \infty}d(s,s_n)=0 \end{align} Certainly when a metric is induced by a norm this is not a problem. But why is it a problem in the case when metric can not be defined by a norm?",,"['functional-analysis', 'metric-spaces', 'normed-spaces']"
83,"Prove $f:GL(n,\mathbb{R})\rightarrow GL(n,\mathbb{R})$ defined by $f(x):=x^{-1}$ is continuous",Prove  defined by  is continuous,"f:GL(n,\mathbb{R})\rightarrow GL(n,\mathbb{R}) f(x):=x^{-1}","I have to prove that $f:GL(n,\mathbb{R})\rightarrow GL(n,\mathbb{R})$ defined by $f(x):=x^{-1}$ is continuous. What I have so far: Consider $Inc \circ f: GL(n,\mathbb{R})\rightarrow \mathbb{R}^{n^2}$, where $Inc$ is the inclusion map from $GL(n,\mathbb{R})$ into $\mathbb{R}^{n^2}$. Throughout we take the standard topology on $\mathbb{R}^{n^2}$ and the relative topology on $GL(n,\mathbb{R})$. I've managed to prove that $Inc$ is continuous, $Inc \circ f$ continuous  $\iff f$ continuous and that $GL(n,\mathbb{R})$ is open in $\mathbb{R}^{n^2}$. How can I use this information to prove that $f$ is continuous?","I have to prove that $f:GL(n,\mathbb{R})\rightarrow GL(n,\mathbb{R})$ defined by $f(x):=x^{-1}$ is continuous. What I have so far: Consider $Inc \circ f: GL(n,\mathbb{R})\rightarrow \mathbb{R}^{n^2}$, where $Inc$ is the inclusion map from $GL(n,\mathbb{R})$ into $\mathbb{R}^{n^2}$. Throughout we take the standard topology on $\mathbb{R}^{n^2}$ and the relative topology on $GL(n,\mathbb{R})$. I've managed to prove that $Inc$ is continuous, $Inc \circ f$ continuous  $\iff f$ continuous and that $GL(n,\mathbb{R})$ is open in $\mathbb{R}^{n^2}$. How can I use this information to prove that $f$ is continuous?",,"['real-analysis', 'general-topology', 'functional-analysis', 'continuity', 'matrix-calculus']"
84,A very simple question: what spaces of function does the Laplace transform map from and into?,A very simple question: what spaces of function does the Laplace transform map from and into?,,"Given a function $f$, we can write $f\colon\mathbb{R} \to \mathbb{R}$ to denote that $f$ takes a number from $\mathbb{R}$ into $\mathbb{R}$. Easy enough. Given the Laplace transform operator $(\mathcal{L}f)(s) = \int_{0}^{\infty} e^{-st} f(t) dt$, can we in a similar fashion write: $(\mathcal{L}f)(s)\colon A \to B$ where $A,B$ are function spaces? What are $A$ and $B$ precisely speaking? What about the Fourier transform?  $\int_{0}^{\infty} e^{-iwt} f(t) dt$","Given a function $f$, we can write $f\colon\mathbb{R} \to \mathbb{R}$ to denote that $f$ takes a number from $\mathbb{R}$ into $\mathbb{R}$. Easy enough. Given the Laplace transform operator $(\mathcal{L}f)(s) = \int_{0}^{\infty} e^{-st} f(t) dt$, can we in a similar fashion write: $(\mathcal{L}f)(s)\colon A \to B$ where $A,B$ are function spaces? What are $A$ and $B$ precisely speaking? What about the Fourier transform?  $\int_{0}^{\infty} e^{-iwt} f(t) dt$",,"['functional-analysis', 'soft-question', 'notation', 'hilbert-spaces', 'laplace-transform']"
85,Compact diagonal operator,Compact diagonal operator,,"Suppose $A : H \to H$, where $H$ is a Hilbert space, is bounded. Also, $A$ is a diagonal operator with diagonal $\{a_n\}$. Show: If $A$ is compact, then $a_n \to 0$ as $n \to \infty$. Should I prove this by contrapositive?","Suppose $A : H \to H$, where $H$ is a Hilbert space, is bounded. Also, $A$ is a diagonal operator with diagonal $\{a_n\}$. Show: If $A$ is compact, then $a_n \to 0$ as $n \to \infty$. Should I prove this by contrapositive?",,"['functional-analysis', 'operator-theory', 'hilbert-spaces', 'compact-operators']"
86,Is $L^1(X) \cap L^2(X)$ a closed subspace of $L^2(X)$ and $L^1(X)$?,Is  a closed subspace of  and ?,L^1(X) \cap L^2(X) L^2(X) L^1(X),Suppose that $X$ be a locally compact Hausdorff space. Could we say that $L^1(X)\cap L^2(X)$ is closed subspace of $L^1(X)$ and $L^2(X)$?,Suppose that $X$ be a locally compact Hausdorff space. Could we say that $L^1(X)\cap L^2(X)$ is closed subspace of $L^1(X)$ and $L^2(X)$?,,"['real-analysis', 'analysis', 'functional-analysis', 'normed-spaces']"
87,What is $H_0^1$ space?,What is  space?,H_0^1,"I'm reading a book and it says that the $H_0^1(\Omega)$ space is defined as ""the completion of $C_0^\infty(\Omega)$ w.r.t the Sobolev norm $\| \cdot \|_1$, where $C_0^\infty(\Omega)$ is the space of infinitely differentiable functions which are nonzero only on a compact subset of $\Omega$"". Can I simply understand the $H_0^1(\Omega)$ space as the space of all functions $u$ in $H^1(\Omega)$ whose value on the boundary of $\Omega$ is $0$ ($u\big |_{\partial\Omega}=0$)?","I'm reading a book and it says that the $H_0^1(\Omega)$ space is defined as ""the completion of $C_0^\infty(\Omega)$ w.r.t the Sobolev norm $\| \cdot \|_1$, where $C_0^\infty(\Omega)$ is the space of infinitely differentiable functions which are nonzero only on a compact subset of $\Omega$"". Can I simply understand the $H_0^1(\Omega)$ space as the space of all functions $u$ in $H^1(\Omega)$ whose value on the boundary of $\Omega$ is $0$ ($u\big |_{\partial\Omega}=0$)?",,['functional-analysis']
88,Hilbert space and uncountable cardinal,Hilbert space and uncountable cardinal,,Given an uncountable cardinal does there exist Hilbert space with orthonormal basis of that cardinality?,Given an uncountable cardinal does there exist Hilbert space with orthonormal basis of that cardinality?,,"['functional-analysis', 'hilbert-spaces', 'cardinals']"
89,"Prove that, in a $C^*$-algebra, if a self-adjoint $a$ has infinite spectrum, then the algebra is infinite-dimensional","Prove that, in a -algebra, if a self-adjoint  has infinite spectrum, then the algebra is infinite-dimensional",C^* a,"Question:Let $A$ be a $C^*$-algebra, $a \in A$ self adjoint. Suppose that the spectrum $\sigma(a)$ is an infinite set. Show that $A$ is infinite-dimensional. How can i prove it? I guess: Let $A$ be finite dimensional. Thus it is isomorphic with direct sum of matrixes $(n_i)$.$\sigma(a)$ is eigenvalue of this direct sum. Can  I say then that $\sigma(a)$ is finite? Is it true?","Question:Let $A$ be a $C^*$-algebra, $a \in A$ self adjoint. Suppose that the spectrum $\sigma(a)$ is an infinite set. Show that $A$ is infinite-dimensional. How can i prove it? I guess: Let $A$ be finite dimensional. Thus it is isomorphic with direct sum of matrixes $(n_i)$.$\sigma(a)$ is eigenvalue of this direct sum. Can  I say then that $\sigma(a)$ is finite? Is it true?",,"['functional-analysis', 'banach-spaces', 'operator-algebras', 'c-star-algebras', 'banach-algebras']"
90,"Prob. 10, Sec. 4.2 in Kreyszig's functional analysis book: There is a linear functional for every sublinear functional ...","Prob. 10, Sec. 4.2 in Kreyszig's functional analysis book: There is a linear functional for every sublinear functional ...",,"If $p$ is a sublinear functional on a real vector space $X$, then there exists a linear functional $\tilde{f}$ on $X$ such that $-p(-x) \leq \tilde{f}(x) \leq p(x)$ for all $x \in X$. How to prove this result? For all $x, y \in X$, we have $p(x+y) \leq p(x) + p(y)$. And, for all $x \in X$ and for all $\alpha \in \mathbb{R}$ such that $\alpha > 0$, we have $p(\alpha x) = \alpha p(x)$. These two conditions imply that $p(\theta) = 0$, where $\theta$ denotes the zero vector in $X$, and $-p(-x) \leq p(x)$ for all $x \in X$. What next? How to proceed from here?","If $p$ is a sublinear functional on a real vector space $X$, then there exists a linear functional $\tilde{f}$ on $X$ such that $-p(-x) \leq \tilde{f}(x) \leq p(x)$ for all $x \in X$. How to prove this result? For all $x, y \in X$, we have $p(x+y) \leq p(x) + p(y)$. And, for all $x \in X$ and for all $\alpha \in \mathbb{R}$ such that $\alpha > 0$, we have $p(\alpha x) = \alpha p(x)$. These two conditions imply that $p(\theta) = 0$, where $\theta$ denotes the zero vector in $X$, and $-p(-x) \leq p(x)$ for all $x \in X$. What next? How to proceed from here?",,"['real-analysis', 'analysis', 'functional-analysis', 'vector-spaces', 'normed-spaces']"
91,Usefulness of Functional analysis,Usefulness of Functional analysis,,"I heard that functional analysis can be applied to many problems in signal processing. I'm trying to explain to my engineer friend why it is useful, but I learnt it in a pure math setting. Can anyone give me some insight on how functional analysis can be applied in the domain of engineering?","I heard that functional analysis can be applied to many problems in signal processing. I'm trying to explain to my engineer friend why it is useful, but I learnt it in a pure math setting. Can anyone give me some insight on how functional analysis can be applied in the domain of engineering?",,['functional-analysis']
92,"Prob. 3, Sec. 2.8 in Erwine Kreyszig's Introductory Functional Analysis with Applications","Prob. 3, Sec. 2.8 in Erwine Kreyszig's Introductory Functional Analysis with Applications",,"Let $C[-1,1]$ denote the normed space of all (real or complex-valued) functions defined and continuous on the closed interval $[-1,1]$ on the real line, with the norm given by $$\Vert x \Vert_{C[-1,1]} \colon= \max_{0 \leq t \leq 1} \vert x(t) \vert \ \ \ \mbox{ for all }  \ \ x \in C[-1,1].$$ Let the functional $f$ on $C[-1,1]$ be defined by  $$f(x) \colon= \int_{-1}^0 x(t) \ \mathrm{d} t \ - \ \int_0^1 x(t) \ \mathrm{d} t \ \ \ \mbox{ for all  }  \ \ x \in C[-1,1].$$ Then $f$ is linear and bounded with norm $\Vert f \Vert \leq 2$. How to determine the exact value of $\Vert f \Vert$? My work: For any $x \in C[-1, 1]$, we have  \begin{eqnarray*} \vert f(x) \vert &=& \left\vert \int_{-1}^0 x(t) \ \mathrm{d} t \ - \ \int_0^1 x(t) \ \mathrm{d} t \  \right\vert \\  &\leq& \left\vert \int_{-1}^0 x(t) \ \mathrm{d} t \ \right\vert \  +  \ \left\vert \int_0^1 x(t) \ \mathrm{d} t \ \right\vert \\  &\leq& \int_{-1}^0 \vert x(t) \vert  \ \mathrm{d} t + \int_0^1 \vert x(t) \vert \ \mathrm{d} t \\  &=& \int_{-1}^1 \vert x(t) \vert  \ \mathrm{d} t \\ &\leq& \int_{-1}^1 \max_{0\leq s \leq 1} \vert x(s) \vert  \ \mathrm{d} t \\ &=& \int_{-1}^1 \Vert x \Vert_{C[-1, 1]}  \ \mathrm{d} t \\ &=& \Vert x \Vert_{C[-1, 1]} \ \int_{-1}^1  \mathrm{d} t \\  &=& 2 \Vert x \Vert_{C[-1,1]}. \end{eqnarray*} Thus, $f$ is bounded and taking the supremum over all $x \in C[-1, 1]$ such that $\Vert x \Vert_{C[-1, 1]} = 1$, we get  $$\Vert f \Vert \leq 2.$$ Now we require an element $x_0 \in C[-1, 1]$ such that $\Vert x_0 \Vert_{C[-1, 1]} = 1$ and $\vert f(x_0) \vert = 2$. However, I haven't been able to locate such an $x_0$. Can anybody please be of any help?","Let $C[-1,1]$ denote the normed space of all (real or complex-valued) functions defined and continuous on the closed interval $[-1,1]$ on the real line, with the norm given by $$\Vert x \Vert_{C[-1,1]} \colon= \max_{0 \leq t \leq 1} \vert x(t) \vert \ \ \ \mbox{ for all }  \ \ x \in C[-1,1].$$ Let the functional $f$ on $C[-1,1]$ be defined by  $$f(x) \colon= \int_{-1}^0 x(t) \ \mathrm{d} t \ - \ \int_0^1 x(t) \ \mathrm{d} t \ \ \ \mbox{ for all  }  \ \ x \in C[-1,1].$$ Then $f$ is linear and bounded with norm $\Vert f \Vert \leq 2$. How to determine the exact value of $\Vert f \Vert$? My work: For any $x \in C[-1, 1]$, we have  \begin{eqnarray*} \vert f(x) \vert &=& \left\vert \int_{-1}^0 x(t) \ \mathrm{d} t \ - \ \int_0^1 x(t) \ \mathrm{d} t \  \right\vert \\  &\leq& \left\vert \int_{-1}^0 x(t) \ \mathrm{d} t \ \right\vert \  +  \ \left\vert \int_0^1 x(t) \ \mathrm{d} t \ \right\vert \\  &\leq& \int_{-1}^0 \vert x(t) \vert  \ \mathrm{d} t + \int_0^1 \vert x(t) \vert \ \mathrm{d} t \\  &=& \int_{-1}^1 \vert x(t) \vert  \ \mathrm{d} t \\ &\leq& \int_{-1}^1 \max_{0\leq s \leq 1} \vert x(s) \vert  \ \mathrm{d} t \\ &=& \int_{-1}^1 \Vert x \Vert_{C[-1, 1]}  \ \mathrm{d} t \\ &=& \Vert x \Vert_{C[-1, 1]} \ \int_{-1}^1  \mathrm{d} t \\  &=& 2 \Vert x \Vert_{C[-1,1]}. \end{eqnarray*} Thus, $f$ is bounded and taking the supremum over all $x \in C[-1, 1]$ such that $\Vert x \Vert_{C[-1, 1]} = 1$, we get  $$\Vert f \Vert \leq 2.$$ Now we require an element $x_0 \in C[-1, 1]$ such that $\Vert x_0 \Vert_{C[-1, 1]} = 1$ and $\vert f(x_0) \vert = 2$. However, I haven't been able to locate such an $x_0$. Can anybody please be of any help?",,"['real-analysis', 'analysis', 'functional-analysis', 'normed-spaces']"
93,Proving that a sequence in $L^2(\mathbb R)$ is relatively compact,Proving that a sequence in  is relatively compact,L^2(\mathbb R),"I have a bounded sequence $\{f_n\}_n$ in $L^2(\mathbb R)$ such that $\mbox{supp } f_n$ is uniformly bounded and $$ \int_{\mathbb R} x^2 |\Theta_n(x) (F f_n)(x)|^2 dx \leq C^2 $$ for all $n$, where $\Theta_n(x) := \frac{\sin(x/n)}{x/n}$ and $Ff_n$ is the Fourier transform of $f_n$. I'd like to prove that $\{f_n\}_n$ is relatively compact in $L^2(\mathbb R)$. From the condition on the supports of $f_n$, i know that $Ff_n$ is smooth and has uniformly bounded derivatives. The following characterization of relatively compact subsets of $L^2(\mathbb R)$ holds: a set $A \subset L^2(\mathbb R)$ is relatively compact if and only if: $A$ is bounded; $\int_{\mathbb R-(-R,R)} |f|^2 \to 0$ as $R \to \infty$, uniformly with respect to $f \in A$; $\int_{\mathbb R} |f(x-y)-f(x)|^2 dx \to 0$ as $y \to 0$, uniformly with respect to $f \in A$. The first condition holds by hypothesis, and the second condition is easily verified. How can I check the third one?","I have a bounded sequence $\{f_n\}_n$ in $L^2(\mathbb R)$ such that $\mbox{supp } f_n$ is uniformly bounded and $$ \int_{\mathbb R} x^2 |\Theta_n(x) (F f_n)(x)|^2 dx \leq C^2 $$ for all $n$, where $\Theta_n(x) := \frac{\sin(x/n)}{x/n}$ and $Ff_n$ is the Fourier transform of $f_n$. I'd like to prove that $\{f_n\}_n$ is relatively compact in $L^2(\mathbb R)$. From the condition on the supports of $f_n$, i know that $Ff_n$ is smooth and has uniformly bounded derivatives. The following characterization of relatively compact subsets of $L^2(\mathbb R)$ holds: a set $A \subset L^2(\mathbb R)$ is relatively compact if and only if: $A$ is bounded; $\int_{\mathbb R-(-R,R)} |f|^2 \to 0$ as $R \to \infty$, uniformly with respect to $f \in A$; $\int_{\mathbb R} |f(x-y)-f(x)|^2 dx \to 0$ as $y \to 0$, uniformly with respect to $f \in A$. The first condition holds by hypothesis, and the second condition is easily verified. How can I check the third one?",,"['functional-analysis', 'hilbert-spaces', 'compactness']"
94,Can every Hausdorff topological space be homeomorphically embedded in a topological vector space?,Can every Hausdorff topological space be homeomorphically embedded in a topological vector space?,,"It's true that for any metric space, we can isometrically embed it in a Banach space, so that the image of the metric space by that embedding is a linearly independent set. Is the analogous theorem for topological spaces true? Often topological vector spaces are required to be Hausdorff, so with that definition the theorem could only potentially be true for topological spaces which are also Hausdorff. So, to make it clear what I mean, rephrasing the title. Given a topological space $ (X, \tau) $ is it possible to find a topological vector space $ V $ and an embedding (homeomorphic onto the image) $ f:X \rightarrow  V $ such that $ f(X) $ is a linearly independent subset of $ V $? Or can we at least somehow weaken this statement to make it true?","It's true that for any metric space, we can isometrically embed it in a Banach space, so that the image of the metric space by that embedding is a linearly independent set. Is the analogous theorem for topological spaces true? Often topological vector spaces are required to be Hausdorff, so with that definition the theorem could only potentially be true for topological spaces which are also Hausdorff. So, to make it clear what I mean, rephrasing the title. Given a topological space $ (X, \tau) $ is it possible to find a topological vector space $ V $ and an embedding (homeomorphic onto the image) $ f:X \rightarrow  V $ such that $ f(X) $ is a linearly independent subset of $ V $? Or can we at least somehow weaken this statement to make it true?",,"['functional-analysis', 'topological-vector-spaces']"
95,A function that is both open and closed but not continuous,A function that is both open and closed but not continuous,,"This does not have to be a very extravagant example just something that I can wrap my head around to have a concrete idea. I was thinking that this could be satisfied by the function $f: [0, 2\pi) \rightarrow B_1 = \{(x,y): x^2 + y^2 = 1\}$ $$ f(x) = (\cos(x),\sin(x)) $$ The point of discontinuity is obviously at $(1,0)$. I was hoping to get a little help convincing myself that this is both an open and closed mapping. (Still getting use to the definition). So, my definition as stated follows. Let $f:X \rightarrow Y$ be a function on the indicated spaces. Then $f$ is an $\bf{open}$ $\bf{function}$ or $\bf{open}$ $\bf{mapping}$ if for each open set $O$ in $X$, $f(O)$ is open in $Y$. The function $f$ is a $\bf{closed}$ $\bf{function}$ or $\bf{closed}$ $\bf{mapping}$ if for each closed set $C$ in $X$, $f(C)$ is closed in $Y$. My idea was along the lines of the following. Let $O$ be an open set in the interval $[0, 2\pi)$. Then $O = (a,b)$, $a>0, b<2\pi$.  Suppose $U = (0, 2\pi) = \cup O$. Where $U$ is the collection of all open sets $O$. Then $f(U)$ is the unit circle excluding the point $(1,0)$ Therefore an open set. Let $C$ be a closed set in the interval $[0, 2\pi)$. Let $\epsilon > 0$ be given. Then $C = [a, b]$ such that $a \geq 0$, $b \leq 2\pi- \epsilon$. Suppose $H = [0, 2\pi- \epsilon]= \cup C$. $H$ is the collection of all closed sets $C$. Then $f(H)$ is the approximately the unit circle radius 1 starting at the point $(1,0)$ ending and including a point before the point $(\cos(2\pi- \epsilon), \sin(2\pi- \epsilon))$. Therefore a closed set. Thus we have found a discontinuous, closed and open map.","This does not have to be a very extravagant example just something that I can wrap my head around to have a concrete idea. I was thinking that this could be satisfied by the function $f: [0, 2\pi) \rightarrow B_1 = \{(x,y): x^2 + y^2 = 1\}$ $$ f(x) = (\cos(x),\sin(x)) $$ The point of discontinuity is obviously at $(1,0)$. I was hoping to get a little help convincing myself that this is both an open and closed mapping. (Still getting use to the definition). So, my definition as stated follows. Let $f:X \rightarrow Y$ be a function on the indicated spaces. Then $f$ is an $\bf{open}$ $\bf{function}$ or $\bf{open}$ $\bf{mapping}$ if for each open set $O$ in $X$, $f(O)$ is open in $Y$. The function $f$ is a $\bf{closed}$ $\bf{function}$ or $\bf{closed}$ $\bf{mapping}$ if for each closed set $C$ in $X$, $f(C)$ is closed in $Y$. My idea was along the lines of the following. Let $O$ be an open set in the interval $[0, 2\pi)$. Then $O = (a,b)$, $a>0, b<2\pi$.  Suppose $U = (0, 2\pi) = \cup O$. Where $U$ is the collection of all open sets $O$. Then $f(U)$ is the unit circle excluding the point $(1,0)$ Therefore an open set. Let $C$ be a closed set in the interval $[0, 2\pi)$. Let $\epsilon > 0$ be given. Then $C = [a, b]$ such that $a \geq 0$, $b \leq 2\pi- \epsilon$. Suppose $H = [0, 2\pi- \epsilon]= \cup C$. $H$ is the collection of all closed sets $C$. Then $f(H)$ is the approximately the unit circle radius 1 starting at the point $(1,0)$ ending and including a point before the point $(\cos(2\pi- \epsilon), \sin(2\pi- \epsilon))$. Therefore a closed set. Thus we have found a discontinuous, closed and open map.",,"['general-topology', 'functional-analysis']"
96,"Continous spectrum of compact, self-adjoint operators on a Hilbert space","Continous spectrum of compact, self-adjoint operators on a Hilbert space",,"Suppose $H$ is a Hilbert space and $T: H \to H$ is a self-adjoint compact operator. Define the continuous spectrum of $T$ to be $c(T) := \{\lambda \in \mathbb{C} \mid T-\lambda I$ is injective, non-surjective, and $\mathrm{im}(T)$ is dense in $H\}$. Is $c(T)$ necessarily empty? If not, what is an example of when $c(T)$ is non-empty? What conditions can one impose to ensure that $c(T)$ is empty? This question came up when I am trying to write down explicitly the spectrum of integral operators on $L^2[0,1]$, defined by $f(x) \mapsto \int K(x,y)f(y) dy\,$,  where $K(x,y)$ is bounded and continous on $[0,1]^2$. Clearly, the point spectrum of this operator is taken care of by the spectral theorem. Residual spectrum is empty in this case.","Suppose $H$ is a Hilbert space and $T: H \to H$ is a self-adjoint compact operator. Define the continuous spectrum of $T$ to be $c(T) := \{\lambda \in \mathbb{C} \mid T-\lambda I$ is injective, non-surjective, and $\mathrm{im}(T)$ is dense in $H\}$. Is $c(T)$ necessarily empty? If not, what is an example of when $c(T)$ is non-empty? What conditions can one impose to ensure that $c(T)$ is empty? This question came up when I am trying to write down explicitly the spectrum of integral operators on $L^2[0,1]$, defined by $f(x) \mapsto \int K(x,y)f(y) dy\,$,  where $K(x,y)$ is bounded and continous on $[0,1]^2$. Clearly, the point spectrum of this operator is taken care of by the spectral theorem. Residual spectrum is empty in this case.",,"['analysis', 'functional-analysis']"
97,"If $T^2=T$ then determine whether $\ker T=\operatorname{Range}\,(T)^\perp$.",If  then determine whether .,"T^2=T \ker T=\operatorname{Range}\,(T)^\perp","Let $T$ be linear operator on a finite dimensional inner product space $V$ such that $T^2=T$. Determine whether $\ker T=\operatorname{Range}\,(T)^\perp$. I have proved that $\ker T=\operatorname{Range}\,(T)^\perp$ under the assumption that $T$ is Hermitian. I guessed that the answer is yes but still in trouble to make it. I also want to know whether $T^2=T$ on $V$ will imply that $T$ is Hermitian.","Let $T$ be linear operator on a finite dimensional inner product space $V$ such that $T^2=T$. Determine whether $\ker T=\operatorname{Range}\,(T)^\perp$. I have proved that $\ker T=\operatorname{Range}\,(T)^\perp$ under the assumption that $T$ is Hermitian. I guessed that the answer is yes but still in trouble to make it. I also want to know whether $T^2=T$ on $V$ will imply that $T$ is Hermitian.",,"['functional-analysis', 'inner-products', 'orthogonality']"
98,"If $\sup_{T\in \tau}|y^*(Tx)|<\infty$ then $\tau$ is bounded in $L(X,Y)$",If  then  is bounded in,"\sup_{T\in \tau}|y^*(Tx)|<\infty \tau L(X,Y)","Let $X$ be a Banach space, $Y$ a normed vector space and $\tau\subset L(X,Y)$. Show that if $\sup_{T\in \tau}|y^*(Tx)|<\infty$ for all $x\in X,y^*\in Y^*$ then $\tau$ is bounded in $L(X,Y)$. Seems that we have to use the Banach-Steinhaus theorem which would yield that $\tau\subset L(X,Y)$ is bounded. But I don't know how to show that $\tau$ is points wise bounded. I don't see any connection to the assumption.","Let $X$ be a Banach space, $Y$ a normed vector space and $\tau\subset L(X,Y)$. Show that if $\sup_{T\in \tau}|y^*(Tx)|<\infty$ for all $x\in X,y^*\in Y^*$ then $\tau$ is bounded in $L(X,Y)$. Seems that we have to use the Banach-Steinhaus theorem which would yield that $\tau\subset L(X,Y)$ is bounded. But I don't know how to show that $\tau$ is points wise bounded. I don't see any connection to the assumption.",,"['functional-analysis', 'operator-theory', 'banach-spaces']"
99,"Why is Isom(E,F) open in the set of bounded linear operators between E and F?","Why is Isom(E,F) open in the set of bounded linear operators between E and F?",,"Let $ E $ and $ F $ be Banach spaces. According to the lecture notes I'm reading $ Isom(E,F) $ (the set of continuous isomorphisms between $ E $ and $ F $ with continuous inverse) is open in the set of bounded linear operators between $ E $ and $ F $. Supposedly, it follows from the fact that the set of invertible elements of a Banach algebra is open. But I fail to see in what Banach algebra one could embed $ Isom(E,F) $. Any hints?","Let $ E $ and $ F $ be Banach spaces. According to the lecture notes I'm reading $ Isom(E,F) $ (the set of continuous isomorphisms between $ E $ and $ F $ with continuous inverse) is open in the set of bounded linear operators between $ E $ and $ F $. Supposedly, it follows from the fact that the set of invertible elements of a Banach algebra is open. But I fail to see in what Banach algebra one could embed $ Isom(E,F) $. Any hints?",,['functional-analysis']
