,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Probability that the 10th class this semester is the 3rd class cancelled when chances are independent with 0.05 probability each day?,Probability that the 10th class this semester is the 3rd class cancelled when chances are independent with 0.05 probability each day?,,"Every day, a lecture may be cancelled due to inclement weather with probability 0.05. Class cancellations on different days are independent. Compute the probability that the tenth class this semester is the 3rd class cancelled? This is a practice exam so the exact answer isn't near as important as the proper solution. My assumption is P(3rd cancelled is 10th class) = P(2 cancellations in 9 classes)*P(cancelled)","Every day, a lecture may be cancelled due to inclement weather with probability 0.05. Class cancellations on different days are independent. Compute the probability that the tenth class this semester is the 3rd class cancelled? This is a practice exam so the exact answer isn't near as important as the proper solution. My assumption is P(3rd cancelled is 10th class) = P(2 cancellations in 9 classes)*P(cancelled)",,"['probability', 'statistics']"
1,Covariance Matrix,Covariance Matrix,,"I'm studying pattern classification and there are some terms that I'm not familiar with. The first term I don’t understand is “covariance matrix”. Suppose I have database of $k$ samples, where each one is a feature vector of length $d$ . How do I build the covariance matrix from my database, and what is the meaning of that matrix?","I'm studying pattern classification and there are some terms that I'm not familiar with. The first term I don’t understand is “covariance matrix”. Suppose I have database of samples, where each one is a feature vector of length . How do I build the covariance matrix from my database, and what is the meaning of that matrix?",k d,"['linear-algebra', 'statistics']"
2,Linear relationship of a company's profit,Linear relationship of a company's profit,,"Assume a linear relationship for a company that has several shops is not known. Let $Y_i$ be the profit the shop number $i$ makes in the coming year. Let $x_i$ be the size of the shop number $i$ . We assume that for all these shops the following relationship holds. $$Y_i = \alpha + \beta x_i + \epsilon_i$$ where $\epsilon_i$ is a random term for which $E[\epsilon_i] = 0$ and such that $\epsilon_1,\epsilon_2,...$ are $i.i.d$ . $\alpha, \beta$ and $\sigma$ are unknown and must be estimated. a.) If we want to open a shop with size 3, what is the expected profit in terms of $\alpha$ and $\beta$ ? b.) Estimate $\alpha$ and $\beta$ using linear regression for the following data $x_i = 1,2,3,4,5,6,7,8,9$ corresponding to $y_i = 0,1,1,2,1,3,3,3,4$ . For part a, is the expected profit going to be $Y_i = \alpha + \beta x_i$ , where $x_i = 3$ , since $\epsilon_i$ has mean $0$ ? For part b, we have not yet been taught linear regression but I did google it and I know that I must find $a$ and $b$ minimizing the sum of the distance square: $$\sum^n_i (Y_i -(a - bx_i))^2$$ then the estimate of $\alpha$ and $\beta$ are then $a$ and $b$ which minimize the above expression. Also, why would the given data values be necessary to find $\alpha$ and $\beta$ ? Isn't those values only necessary to find the standard deviation?","Assume a linear relationship for a company that has several shops is not known. Let be the profit the shop number makes in the coming year. Let be the size of the shop number . We assume that for all these shops the following relationship holds. where is a random term for which and such that are . and are unknown and must be estimated. a.) If we want to open a shop with size 3, what is the expected profit in terms of and ? b.) Estimate and using linear regression for the following data corresponding to . For part a, is the expected profit going to be , where , since has mean ? For part b, we have not yet been taught linear regression but I did google it and I know that I must find and minimizing the sum of the distance square: then the estimate of and are then and which minimize the above expression. Also, why would the given data values be necessary to find and ? Isn't those values only necessary to find the standard deviation?","Y_i i x_i i Y_i = \alpha + \beta x_i + \epsilon_i \epsilon_i E[\epsilon_i] = 0 \epsilon_1,\epsilon_2,... i.i.d \alpha, \beta \sigma \alpha \beta \alpha \beta x_i = 1,2,3,4,5,6,7,8,9 y_i = 0,1,1,2,1,3,3,3,4 Y_i = \alpha + \beta x_i x_i = 3 \epsilon_i 0 a b \sum^n_i (Y_i -(a - bx_i))^2 \alpha \beta a b \alpha \beta","['probability', 'statistics', 'regression']"
3,What is the Cumulative Distribution Function of the following random variable?,What is the Cumulative Distribution Function of the following random variable?,,"Suppose that we have $2n$ iid random variables $X_1,…,X_n,Y_1,…,Y_n$ where $n$ is a large number.  I want to find $P((k∑_iX_iY_i+(∑_iX_i)(∑_jY_j))<c)$ for any integer c. Since $n$ is a large number and all the random variables are $iid$, using central limit theorem, we can say that $k∑_iX_iY_i$, $(∑_iX_i)$ and $(∑_jY_j)$ are approximately normal random variables and $(∑_iX_i)$$(∑_jY_j)$ is the product of two normal random variables which would have Normal Product Distribution . So $k∑_iX_iY_i+(∑_iX_i)(∑_jY_j)$ is the sum of one normal and one normal product random variable which are dependent. Now the question is how can we find $P((k∑_iX_iY_i+(∑_iX_i)(∑_jY_j)) \le c)$ for any integer c?","Suppose that we have $2n$ iid random variables $X_1,…,X_n,Y_1,…,Y_n$ where $n$ is a large number.  I want to find $P((k∑_iX_iY_i+(∑_iX_i)(∑_jY_j))<c)$ for any integer c. Since $n$ is a large number and all the random variables are $iid$, using central limit theorem, we can say that $k∑_iX_iY_i$, $(∑_iX_i)$ and $(∑_jY_j)$ are approximately normal random variables and $(∑_iX_i)$$(∑_jY_j)$ is the product of two normal random variables which would have Normal Product Distribution . So $k∑_iX_iY_i+(∑_iX_i)(∑_jY_j)$ is the sum of one normal and one normal product random variable which are dependent. Now the question is how can we find $P((k∑_iX_iY_i+(∑_iX_i)(∑_jY_j)) \le c)$ for any integer c?",,"['probability', 'statistics']"
4,Hypothesis testing for normally distributed random variable,Hypothesis testing for normally distributed random variable,,"I have some random variable: ${X ~ N(\mu, 1)}$ I define null hypothesis and alternative hypothesis as follows: ${H_0 : \mu = 0}$ ${H_1 : \mu \neq 0}$ Then, let ${x}$ be a number that comes out of my random variable. I want to reject my null hypothesis if ${|x| \geq 3}$ And then I need to calculate probability of possible errors. So, first of all I need to find the test statistic: ${ \displaystyle z = \frac{\bar{x} - \mu_0}{ \displaystyle \frac{s_x}{\sqrt{n}}}}$ I know that ${\mu_0}$ = 0 and sample size should probably be equal to ${1}$ (?). How to calculate ${\bar{x}}$ (sample average)? Is it the same as expectation? My question may be trivial, but I'm totally confused with it.","I have some random variable: ${X ~ N(\mu, 1)}$ I define null hypothesis and alternative hypothesis as follows: ${H_0 : \mu = 0}$ ${H_1 : \mu \neq 0}$ Then, let ${x}$ be a number that comes out of my random variable. I want to reject my null hypothesis if ${|x| \geq 3}$ And then I need to calculate probability of possible errors. So, first of all I need to find the test statistic: ${ \displaystyle z = \frac{\bar{x} - \mu_0}{ \displaystyle \frac{s_x}{\sqrt{n}}}}$ I know that ${\mu_0}$ = 0 and sample size should probably be equal to ${1}$ (?). How to calculate ${\bar{x}}$ (sample average)? Is it the same as expectation? My question may be trivial, but I'm totally confused with it.",,"['statistics', 'random-variables']"
5,Where does the Chi-square equation come from?,Where does the Chi-square equation come from?,,"A Chi-Square random variable is defined as $Χ^2_{df} = \frac{( n - 1 )  s^2 }{σ^2}$. I cannot find a source for this anywhere on the internet, and my textbook is of no help. Does anyone know where this formula came from and why it makes up what we call the Chi-Square?","A Chi-Square random variable is defined as $Χ^2_{df} = \frac{( n - 1 )  s^2 }{σ^2}$. I cannot find a source for this anywhere on the internet, and my textbook is of no help. Does anyone know where this formula came from and why it makes up what we call the Chi-Square?",,"['probability', 'statistics']"
6,Expectations Homework Questions Clarification,Expectations Homework Questions Clarification,,"This is another one of the questions I didn't get a chance to ask the TA at my school today. I thought I had a pretty good grasp on Expectations but apparently I could still use some clarification. Hopefully someone can help me. Suppose that $n$ people take a blood test for a disease, where each person has probability $p$ of having the disease, independent of other persons. To save time and money, blood samples from $k$ people are pooled together. If none of the $k$ persons has the disease then the test will be negative, but otherwise it will be positive. If the pooled test i sportive then each of the $k$ persons is tested separately (so $k+1$ tests are done in that case) Let $X$ be the number of tests required for a group of $k$ people. Show that $$ E(X)=k+1-k(1-p)^{k} $$","This is another one of the questions I didn't get a chance to ask the TA at my school today. I thought I had a pretty good grasp on Expectations but apparently I could still use some clarification. Hopefully someone can help me. Suppose that $n$ people take a blood test for a disease, where each person has probability $p$ of having the disease, independent of other persons. To save time and money, blood samples from $k$ people are pooled together. If none of the $k$ persons has the disease then the test will be negative, but otherwise it will be positive. If the pooled test i sportive then each of the $k$ persons is tested separately (so $k+1$ tests are done in that case) Let $X$ be the number of tests required for a group of $k$ people. Show that $$ E(X)=k+1-k(1-p)^{k} $$",,['statistics']
7,Mutually independent distribution,Mutually independent distribution,,"Let the mutually independent random variables $X_1, X_2$, and $X_3$ be $N(0,1)$, $N(2,4)$, and $N(-1,1)$, respectively. Compute the probability that exactly two of these three variables are less than zero.","Let the mutually independent random variables $X_1, X_2$, and $X_3$ be $N(0,1)$, $N(2,4)$, and $N(-1,1)$, respectively. Compute the probability that exactly two of these three variables are less than zero.",,"['probability', 'statistics']"
8,What is the distribution of sum of dependent normal random variables?,What is the distribution of sum of dependent normal random variables?,,"If $X_1,\ldots,X_n$ are dependent normal random variables, what would be the distribution of $X_1+\ldots+Xn$? Is it still normal?","If $X_1,\ldots,X_n$ are dependent normal random variables, what would be the distribution of $X_1+\ldots+Xn$? Is it still normal?",,"['probability', 'statistics']"
9,poisson distribution of chocolate,poisson distribution of chocolate,,Let the number of chocolate drops in a certain type of cookie have a Poisson distribution. We want the probability that a cookie of this type contains at least two chocolate drops to be greater than 0.99. Find the smallest value of the mean that the distribution can take.,Let the number of chocolate drops in a certain type of cookie have a Poisson distribution. We want the probability that a cookie of this type contains at least two chocolate drops to be greater than 0.99. Find the smallest value of the mean that the distribution can take.,,['statistics']
10,"What is the $P( |X-10| > 2)$ of a normal distribution when the mean is 10, and the standard deviation is 6?","What is the  of a normal distribution when the mean is 10, and the standard deviation is 6?",P( |X-10| > 2),"I couldn't figure out this question:  What is the $P( |X-10| > 2)$ of a normal distribution when the mean is 10, and the standard deviation is 6?","I couldn't figure out this question:  What is the $P( |X-10| > 2)$ of a normal distribution when the mean is 10, and the standard deviation is 6?",,"['probability', 'statistics']"
11,Decide probabilistically whether leaf labels in a decision tree sum to zero?,Decide probabilistically whether leaf labels in a decision tree sum to zero?,,"I have the following problem, which might or might not be very easy to answer for someone with even a light background in statistics - but I don't even know where to start. Hence, I will give it a shot and post it here: Terminology By a decision tree I will mean a directed, acyclic graph $G=(V,E)$ where each vertex $v\in V$ has indegree $0$ or $1$, and there is precisely one vertex with indegree zero, called the root . For each vertex $v\in V$, let $\newcommand{\out}{\mathrm{out}}\delta_\out(v)=\{ e\in E \mid \exists w\in V: e=(v,w)\}$ be the set of outgoing edges. For each edge $e=(v,w)\in E$, let $$p(e):=\frac{1}{\sharp\delta_\out(v)}$$ be the probability of this edge. For each leaf $v\in V_0:=\{ v\in V \mid \sharp\delta_\out(v)=0\}$, there is a unique path from the root to $v$. Let $e_1,\ldots,e_r\in E$ be the edges of this path. Then, we write $$p(v):=\prod_{i=1}^r p(e_i)$$ and call it the probability of this leaf. Problem Description Let $a,b\in\newcommand{\Z}{\mathbb{Z}}\Z$ with $a<0<b$. Consider a decision tree $(V,E)$ whose leaves are labelled with integer values from the interval $[a,b]$. In other words, we have a function $\ell: V_0 \to \Z\cap[a,b]$. Question: Is the sum over all leaf labels equal to zero or not? i.e. decide whether $$\sum_{v\in V_0} \ell(v) = 0$$ or not. Now in my case there are a lot of leaves, way too many to compute $\sum_{v\in V_0} \ell(v)$ explicitly. However, traversing a path from the root to some leaf $v$ and thereby computing $p(v)$ is easy. Now, I was wondering: Is there a method to probabilistically answer the question from a smaller number of samples $v\in V_0$ together with the values $p(v)$ and $\ell(v)$? Unfortunately, I do not know anything about the distribution of the values along the leaves.","I have the following problem, which might or might not be very easy to answer for someone with even a light background in statistics - but I don't even know where to start. Hence, I will give it a shot and post it here: Terminology By a decision tree I will mean a directed, acyclic graph $G=(V,E)$ where each vertex $v\in V$ has indegree $0$ or $1$, and there is precisely one vertex with indegree zero, called the root . For each vertex $v\in V$, let $\newcommand{\out}{\mathrm{out}}\delta_\out(v)=\{ e\in E \mid \exists w\in V: e=(v,w)\}$ be the set of outgoing edges. For each edge $e=(v,w)\in E$, let $$p(e):=\frac{1}{\sharp\delta_\out(v)}$$ be the probability of this edge. For each leaf $v\in V_0:=\{ v\in V \mid \sharp\delta_\out(v)=0\}$, there is a unique path from the root to $v$. Let $e_1,\ldots,e_r\in E$ be the edges of this path. Then, we write $$p(v):=\prod_{i=1}^r p(e_i)$$ and call it the probability of this leaf. Problem Description Let $a,b\in\newcommand{\Z}{\mathbb{Z}}\Z$ with $a<0<b$. Consider a decision tree $(V,E)$ whose leaves are labelled with integer values from the interval $[a,b]$. In other words, we have a function $\ell: V_0 \to \Z\cap[a,b]$. Question: Is the sum over all leaf labels equal to zero or not? i.e. decide whether $$\sum_{v\in V_0} \ell(v) = 0$$ or not. Now in my case there are a lot of leaves, way too many to compute $\sum_{v\in V_0} \ell(v)$ explicitly. However, traversing a path from the root to some leaf $v$ and thereby computing $p(v)$ is easy. Now, I was wondering: Is there a method to probabilistically answer the question from a smaller number of samples $v\in V_0$ together with the values $p(v)$ and $\ell(v)$? Unfortunately, I do not know anything about the distribution of the values along the leaves.",,"['probability', 'combinatorics', 'statistics', 'graph-theory']"
12,Some Questions on Determinants and Geometry,Some Questions on Determinants and Geometry,,"For real valued matrices, I know that the absolute value of the determinant is equivalent to the volume of the vectors forming the parallelepiped in the matrix. Suppose that $A$ and $B$ are real valued, $n \times n$ matrices with $det (A) = a$ and $det(B) = b$. So my questions are inspired by Wilks' Lambda : What happens in the geometric sense when adding $A+B$?  Vector-wise addition, sure, but is there a simpler (alternative) way of explaining the idea of what happens to the parallelepipeds defined by two matrices $A$ and $B$?  I guess I want a statement that says,  something along the lines of $$\\\\ \text{Given the parallelepiped defined by $A$ and parallelepiped defined by $B$,$\\$ then the parallelepiped defined by $A+B$ is ...}$$ Given $det (A) = a$ and $det(B) = b$, is there a way to describe $det(A+B)$ in terms of $a$ and $b$? for $n=2$ we know the  $$\begin{array}{rcl} a&=& a_{11} \cdot a_{22} - a_{12} \cdot a_{21}\\ b&=& b_{11} \cdot b_{22} - b_{12} \cdot b_{21}\\ det(A+B)&=& (a_{11} + b_{11}) \cdot (a_{22}+b_{22}) - (a_{12} + b_{12}) \cdot (a_{21} + b_{21})\\ &=& a_{11}\cdot a_{22}+b_{11}\cdot b_{22} + a_{11} \cdot b_{22}+b_{11}\cdot a_{22} - \left( a_{12}\cdot a_{21}+b_{12}\cdot b_{21} + a_{12} \cdot b_{21}+b_{12}\cdot a_{21}\right) \\ &=&\left( a_{11} \cdot a_{22} - a_{12} \cdot a_{21}\right) + \left(  b_{11} \cdot b_{22} - b_{12} \cdot b_{21}\right) + \left( a_{11} \cdot b_{22}+b_{11}\cdot a_{22} -  a_{12} \cdot b_{21}+b_{12}\cdot a_{21}\right)\\ &=& a+b+\left( a_{11} \cdot b_{22}+b_{11}\cdot a_{22} -  a_{12} \cdot b_{21}+b_{12}\cdot a_{21}\right) \end{array}$$ The math gets ugly for $n=3$ and higher. Thanks.","For real valued matrices, I know that the absolute value of the determinant is equivalent to the volume of the vectors forming the parallelepiped in the matrix. Suppose that $A$ and $B$ are real valued, $n \times n$ matrices with $det (A) = a$ and $det(B) = b$. So my questions are inspired by Wilks' Lambda : What happens in the geometric sense when adding $A+B$?  Vector-wise addition, sure, but is there a simpler (alternative) way of explaining the idea of what happens to the parallelepipeds defined by two matrices $A$ and $B$?  I guess I want a statement that says,  something along the lines of $$\\\\ \text{Given the parallelepiped defined by $A$ and parallelepiped defined by $B$,$\\$ then the parallelepiped defined by $A+B$ is ...}$$ Given $det (A) = a$ and $det(B) = b$, is there a way to describe $det(A+B)$ in terms of $a$ and $b$? for $n=2$ we know the  $$\begin{array}{rcl} a&=& a_{11} \cdot a_{22} - a_{12} \cdot a_{21}\\ b&=& b_{11} \cdot b_{22} - b_{12} \cdot b_{21}\\ det(A+B)&=& (a_{11} + b_{11}) \cdot (a_{22}+b_{22}) - (a_{12} + b_{12}) \cdot (a_{21} + b_{21})\\ &=& a_{11}\cdot a_{22}+b_{11}\cdot b_{22} + a_{11} \cdot b_{22}+b_{11}\cdot a_{22} - \left( a_{12}\cdot a_{21}+b_{12}\cdot b_{21} + a_{12} \cdot b_{21}+b_{12}\cdot a_{21}\right) \\ &=&\left( a_{11} \cdot a_{22} - a_{12} \cdot a_{21}\right) + \left(  b_{11} \cdot b_{22} - b_{12} \cdot b_{21}\right) + \left( a_{11} \cdot b_{22}+b_{11}\cdot a_{22} -  a_{12} \cdot b_{21}+b_{12}\cdot a_{21}\right)\\ &=& a+b+\left( a_{11} \cdot b_{22}+b_{11}\cdot a_{22} -  a_{12} \cdot b_{21}+b_{12}\cdot a_{21}\right) \end{array}$$ The math gets ugly for $n=3$ and higher. Thanks.",,"['linear-algebra', 'geometry', 'statistics', 'determinant']"
13,Question about variance and its relation to standard deviation,Question about variance and its relation to standard deviation,,"I understand from my lecturer that variance an standard deviation are central to statistics. I do not understand the signifigance of both values, except that both measures the variability, and variance is the square of standard deviation. Why is there a need for two standards then? Why must sd be squared to obtain variance? Why can't it be sd cubed, or even sd square rooted? Wouldnt sd cubed give us a more esaggerated value, which is better? Also, how were these standards invented? They seem so non intuitive to me, then just takig a value then taking the difference wrt to the mean","I understand from my lecturer that variance an standard deviation are central to statistics. I do not understand the signifigance of both values, except that both measures the variability, and variance is the square of standard deviation. Why is there a need for two standards then? Why must sd be squared to obtain variance? Why can't it be sd cubed, or even sd square rooted? Wouldnt sd cubed give us a more esaggerated value, which is better? Also, how were these standards invented? They seem so non intuitive to me, then just takig a value then taking the difference wrt to the mean",,['statistics']
14,Calculating Variance of a binomial distribution using the standard formula $E(X^2) - \mu^2$,Calculating Variance of a binomial distribution using the standard formula,E(X^2) - \mu^2,"Binomial problems: Mean and standard deviation Suppose that the New England Colonials baseball team is equally likely to win any particular game as not to win it. Suppose also that we choose a random sample of Colonials games. Estimate the number of games in the sample that the Colonials win by giving the mean of the relevant distribution (that is, the expectation of the relevant random variable). Do not round your response. Quantify the uncertainty of your estimate by giving the standard deviation of the distribution. Round your response to at least three decimal places. I've calculated the mean to be $10 (np=20*0.5)$. The short cut for calculating the variance of a binomial distribution is $np(1-p)$, but can you show me how to use the standard discrete distribution formula for variance ($Var(X) = E(X^2) - \mu^2$)to calculate variance in this case?","Binomial problems: Mean and standard deviation Suppose that the New England Colonials baseball team is equally likely to win any particular game as not to win it. Suppose also that we choose a random sample of Colonials games. Estimate the number of games in the sample that the Colonials win by giving the mean of the relevant distribution (that is, the expectation of the relevant random variable). Do not round your response. Quantify the uncertainty of your estimate by giving the standard deviation of the distribution. Round your response to at least three decimal places. I've calculated the mean to be $10 (np=20*0.5)$. The short cut for calculating the variance of a binomial distribution is $np(1-p)$, but can you show me how to use the standard discrete distribution formula for variance ($Var(X) = E(X^2) - \mu^2$)to calculate variance in this case?",,"['probability', 'statistics']"
15,A confusing excersice about Bayes' rule,A confusing excersice about Bayes' rule,,"The following is from a textbook one bayesian stats. that I can't understand some deduction. It is relevant about multiple parameters to be estimated. The jth observation in the ith group is denoted by $y_{ij}$, where $$(y_{ij}|\mu_i,\sigma)\sim N(\mu_i,\sigma^2) \quad j=1,2, \dots, n_i \quad i= 1,2, \dots, m$$ Also the $y_{ij}$ are independent from each other. Suppose $\mu_i \sim N(\mu,\tau^2)$ and denote $$\theta= (\mu, \log(\sigma),\log(\tau))$$ $$Y=\{y_{ij}: j=1,\dots, n_i, i=1,\dots, n\}$$ $$Z=(\mu_1,\dots, \mu_m)$$ $$n=n_1+n_2+\cdots +n_m$$ So $\theta$ is the unknown parameters interested. Take its prior distribution as $p(\theta) \propto \tau$. Then by Bayes rule, it is not difficult to get the posterior distribution: $$p(Z,\theta|Y) \propto p(\theta) \prod\limits_{i = 1}^m {p(\mu_i|\mu,\tau)} \prod\limits_{i = 1}^m \prod\limits_{j = 1}^{n_i} {p(y_{ij}|\mu_i,\sigma)}$$ This is the place I can't understand. How to get this formula if No.3 formula is not correct in this thread: I am confused about Bayes' rule in MCMC Could someone explain it in detail? If there are any excellent books that could help me, please list them.","The following is from a textbook one bayesian stats. that I can't understand some deduction. It is relevant about multiple parameters to be estimated. The jth observation in the ith group is denoted by $y_{ij}$, where $$(y_{ij}|\mu_i,\sigma)\sim N(\mu_i,\sigma^2) \quad j=1,2, \dots, n_i \quad i= 1,2, \dots, m$$ Also the $y_{ij}$ are independent from each other. Suppose $\mu_i \sim N(\mu,\tau^2)$ and denote $$\theta= (\mu, \log(\sigma),\log(\tau))$$ $$Y=\{y_{ij}: j=1,\dots, n_i, i=1,\dots, n\}$$ $$Z=(\mu_1,\dots, \mu_m)$$ $$n=n_1+n_2+\cdots +n_m$$ So $\theta$ is the unknown parameters interested. Take its prior distribution as $p(\theta) \propto \tau$. Then by Bayes rule, it is not difficult to get the posterior distribution: $$p(Z,\theta|Y) \propto p(\theta) \prod\limits_{i = 1}^m {p(\mu_i|\mu,\tau)} \prod\limits_{i = 1}^m \prod\limits_{j = 1}^{n_i} {p(y_{ij}|\mu_i,\sigma)}$$ This is the place I can't understand. How to get this formula if No.3 formula is not correct in this thread: I am confused about Bayes' rule in MCMC Could someone explain it in detail? If there are any excellent books that could help me, please list them.",,"['probability', 'statistics', 'bayesian']"
16,A question about $\sum_{i=1}^n x_i x_i^T = X^TX$,A question about,\sum_{i=1}^n x_i x_i^T = X^TX,"For a set of column vectors $x_1,\dots,x_n$, the identity shows that $\sum_{i=1}^n x_i x_i^T = X^TX$. I can show this by seeing the $(p,q)$ entry of the resulting matrix is $\sum_{i=1}^n (X^T)_{pi}X_{iq} = \sum_{i=1}^n x_{ip} x_{iq}$. Is there a quicker way of seeing this? and, does $xx^T$ have a special name?","For a set of column vectors $x_1,\dots,x_n$, the identity shows that $\sum_{i=1}^n x_i x_i^T = X^TX$. I can show this by seeing the $(p,q)$ entry of the resulting matrix is $\sum_{i=1}^n (X^T)_{pi}X_{iq} = \sum_{i=1}^n x_{ip} x_{iq}$. Is there a quicker way of seeing this? and, does $xx^T$ have a special name?",,['statistics']
17,"Average, standard deviation and min/max values","Average, standard deviation and min/max values",,"I'm analzying a computer science paper and just found in the experimental setup the following statement: Average (standard deviation) of number of files per peer: 464 (554) Min - max number of files per peer: 100 - 4,774 Are these numbers possible at all? It does not say anything of a normal distribution, but how is it possible that the standard deviation is 554, but the min number of files per peer is 100?","I'm analzying a computer science paper and just found in the experimental setup the following statement: Average (standard deviation) of number of files per peer: 464 (554) Min - max number of files per peer: 100 - 4,774 Are these numbers possible at all? It does not say anything of a normal distribution, but how is it possible that the standard deviation is 554, but the min number of files per peer is 100?",,"['statistics', 'average', 'standard-deviation']"
18,"A tourist in France wants to visit 12 different cities, find the probability.","A tourist in France wants to visit 12 different cities, find the probability.",,"The Question : A tourist in France wants to visit 12 different cities. If the route is randomly selected, what is the probability that she will   visit the cities in alphabetical order? I thought about this in two ways and I got two different answers, both of them look correct to me ! but only one is correct. 1/144 (12 cities times 12 times to make the arrangement) 1/479001600 (which is generated by the permutation 12 P 12) Which one is correct? and is there a better answer? Please explain how do you know if the problem is permutation or combination or just simple multiplication.","The Question : A tourist in France wants to visit 12 different cities. If the route is randomly selected, what is the probability that she will   visit the cities in alphabetical order? I thought about this in two ways and I got two different answers, both of them look correct to me ! but only one is correct. 1/144 (12 cities times 12 times to make the arrangement) 1/479001600 (which is generated by the permutation 12 P 12) Which one is correct? and is there a better answer? Please explain how do you know if the problem is permutation or combination or just simple multiplication.",,['statistics']
19,How many degrees of freedom?,How many degrees of freedom?,,"I have another question on my stats homework, relating to degrees of freedom. However, I have NO idea how this question even relates to degrees of freedom! I understand degrees of freedom on their own, i.e. how when calculating standard deviation you divide by df instead of total n because the centered scores always equal out to zero, but I don't get how that relates to this question. Is the professor just trying to throw us off with irrelevant info? Is the answer simply 10? Last Saturday, Karl went to a party at a friend’s house. His friend had ordered 4 medium (8 slice) pizzas from Flying Tomato Pizza. There was a “Veggie” pizza (with Mushroom, Green Pepper, Tomato, & Onion), a “Greek” pizza (with Black Olives, Tomato, Onion, & Feta Cheese), and two “Meat Lovers” pizzas (with Pepperoni, Ham, Bacon, & Italian Sausage). Karl is vegetarian, and when he goes to get a slice of pizza, there remain 6 slices of the “Veggie” pizza, 4 slices of the “Greek” pizza, and 9 slices of the “Meat Lovers” pizzas. How many degrees of freedom does Karl have in picking his slice of pizza?","I have another question on my stats homework, relating to degrees of freedom. However, I have NO idea how this question even relates to degrees of freedom! I understand degrees of freedom on their own, i.e. how when calculating standard deviation you divide by df instead of total n because the centered scores always equal out to zero, but I don't get how that relates to this question. Is the professor just trying to throw us off with irrelevant info? Is the answer simply 10? Last Saturday, Karl went to a party at a friend’s house. His friend had ordered 4 medium (8 slice) pizzas from Flying Tomato Pizza. There was a “Veggie” pizza (with Mushroom, Green Pepper, Tomato, & Onion), a “Greek” pizza (with Black Olives, Tomato, Onion, & Feta Cheese), and two “Meat Lovers” pizzas (with Pepperoni, Ham, Bacon, & Italian Sausage). Karl is vegetarian, and when he goes to get a slice of pizza, there remain 6 slices of the “Veggie” pizza, 4 slices of the “Greek” pizza, and 9 slices of the “Meat Lovers” pizzas. How many degrees of freedom does Karl have in picking his slice of pizza?",,['statistics']
20,Show that an estimator has a lower variance than another estimator,Show that an estimator has a lower variance than another estimator,,"Let $X $ be observed data. Let $\hat{\theta}(X)$ be an unbiased estimate of $\theta$ and let T be a sufficient statistic for $\theta$. Define the new estimator  $\hat\theta^{*}$ of $\theta$, $$ \hat\theta^{*}(X) =E(\hat\theta(X)| T) $$ Then, show that: $\hat\theta^{*}(X)$ has a variance that is lower than (or equal to) that of $ \hat\theta$ Hint: for any two random variables $X$ and $Y$, $\operatorname{VAR}(X)= E(\operatorname{VAR}[X|Y]) +VAR[E(X|Y)]$ and $E(E(X|Y)=E(X)$","Let $X $ be observed data. Let $\hat{\theta}(X)$ be an unbiased estimate of $\theta$ and let T be a sufficient statistic for $\theta$. Define the new estimator  $\hat\theta^{*}$ of $\theta$, $$ \hat\theta^{*}(X) =E(\hat\theta(X)| T) $$ Then, show that: $\hat\theta^{*}(X)$ has a variance that is lower than (or equal to) that of $ \hat\theta$ Hint: for any two random variables $X$ and $Y$, $\operatorname{VAR}(X)= E(\operatorname{VAR}[X|Y]) +VAR[E(X|Y)]$ and $E(E(X|Y)=E(X)$",,"['probability', 'statistics']"
21,Exponential Distribution MLE,Exponential Distribution MLE,,The lifetime of a type of component has an exponential distribution with rate λ per hour. Ten of these components were tested but the only recorded results were that 3 components had failed within 100 hours and 7 had survived that time. I have been asked to (a) Find the maximum likelihood estimate of λ. (b) Find the approximate standard error of this estimator. Can you help me please?,The lifetime of a type of component has an exponential distribution with rate λ per hour. Ten of these components were tested but the only recorded results were that 3 components had failed within 100 hours and 7 had survived that time. I have been asked to (a) Find the maximum likelihood estimate of λ. (b) Find the approximate standard error of this estimator. Can you help me please?,,"['statistics', 'exponential-function']"
22,Needing to find a variance from a data set below,Needing to find a variance from a data set below,,"I am trying to get the variance of the data set below. I get a negative number upon applying 1/2(2.5)^2 + 1(3)^2 + 0.5(4.5)^2 + 1(5)^2 + 1(6)^2 - (17.5)^2 = variance, but a negative and weird number. Please use this data below from the link, the problem is as is and the sample space is what I also got. But I got a mean of 17.5 and not sure how to to do the variance. http://answers.yahoo.com/question/index?qid=20100120103118AAld5Yx","I am trying to get the variance of the data set below. I get a negative number upon applying 1/2(2.5)^2 + 1(3)^2 + 0.5(4.5)^2 + 1(5)^2 + 1(6)^2 - (17.5)^2 = variance, but a negative and weird number. Please use this data below from the link, the problem is as is and the sample space is what I also got. But I got a mean of 17.5 and not sure how to to do the variance. http://answers.yahoo.com/question/index?qid=20100120103118AAld5Yx",,['statistics']
23,Difference between E( expression ) and E[ expression ] for expected value,Difference between E( expression ) and E[ expression ] for expected value,,"I don't understand the difference in notation between E( expression ) and E[ expression ] for [expected value][1]. The Wikipedia article seems to indicate E( ) is used for an arbitrary function of X, but I'm not sure what the difference in meaning is. Google pointed me to an example of a usage difference [here][2], but the article didn't help to resolve my misunderstanding much: In the following the operations E[ ] and Var[ ] (square brackets as   opposed to parentheses before !) mean expected value and variance with   respect to the structure function (prior distribution) U(η, θ) over   HxΘ. Also, what does it mean when expected value is applied as an operator?.","I don't understand the difference in notation between E( expression ) and E[ expression ] for [expected value][1]. The Wikipedia article seems to indicate E( ) is used for an arbitrary function of X, but I'm not sure what the difference in meaning is. Google pointed me to an example of a usage difference [here][2], but the article didn't help to resolve my misunderstanding much: In the following the operations E[ ] and Var[ ] (square brackets as   opposed to parentheses before !) mean expected value and variance with   respect to the structure function (prior distribution) U(η, θ) over   HxΘ. Also, what does it mean when expected value is applied as an operator?.",,"['probability', 'statistics']"
24,Estimating the covariance matrix with a set of vectors for the Mahalanobis distance,Estimating the covariance matrix with a set of vectors for the Mahalanobis distance,,"I am trying to figure out how to use the Mahalanobis distance still.  I am having trouble figuring out how to produce my own covariance matrix. I guess the relevant link is http://en.wikipedia.org/wiki/Estimation_of_covariance_matrices , but I am still stuck.  What I have is a set of points in space, every single point in my data set.  I want to find the distance between any two of them using this type of distance, but how do I form the covariance matrix? The webpage is not very clear to me.","I am trying to figure out how to use the Mahalanobis distance still.  I am having trouble figuring out how to produce my own covariance matrix. I guess the relevant link is http://en.wikipedia.org/wiki/Estimation_of_covariance_matrices , but I am still stuck.  What I have is a set of points in space, every single point in my data set.  I want to find the distance between any two of them using this type of distance, but how do I form the covariance matrix? The webpage is not very clear to me.",,"['matrices', 'statistics']"
25,Odds of 1 out of 7 NFL teams making the playoffs,Odds of 1 out of 7 NFL teams making the playoffs,,"I have a potential prop bet in the making where my opponent has to pick 7 NFL teams not to make the playoffs for this upcoming season. If all 7 of their teams miss the playoffs, they win, if at least 1 of their teams make the playoffs, I win. I've already gone ahead and calculated the vig free odds for the worst 7 teams to make the playoffs based on the odds off of one of the top online sports books: Colts: 9.06% Browns: 9.50% Vikings: 11.37% Jaguars: 11.69% Rams: 13.22% Buccaneers: 18.01% Redskins: 18.01% Now my question is how do I figure out what the odds are of at least 1 of those above teams making the playoffs in order for me to win my bet? Thanks.","I have a potential prop bet in the making where my opponent has to pick 7 NFL teams not to make the playoffs for this upcoming season. If all 7 of their teams miss the playoffs, they win, if at least 1 of their teams make the playoffs, I win. I've already gone ahead and calculated the vig free odds for the worst 7 teams to make the playoffs based on the odds off of one of the top online sports books: Colts: 9.06% Browns: 9.50% Vikings: 11.37% Jaguars: 11.69% Rams: 13.22% Buccaneers: 18.01% Redskins: 18.01% Now my question is how do I figure out what the odds are of at least 1 of those above teams making the playoffs in order for me to win my bet? Thanks.",,['statistics']
26,How to do a regression with only integer values and a fixed intercept?,How to do a regression with only integer values and a fixed intercept?,,"I need to write some code for an application that takes in a series of 2D points whose values are integers, and determines a polynomial regression that passes through the origin. I know how to do this via a CAS, but is anyone familiar with the math behind a regression of this type?","I need to write some code for an application that takes in a series of 2D points whose values are integers, and determines a polynomial regression that passes through the origin. I know how to do this via a CAS, but is anyone familiar with the math behind a regression of this type?",,"['statistics', 'regression']"
27,Unconfounded assumption,Unconfounded assumption,,"In the notation of the unconfounded assumption, does  $$\left(Y(0),Y(1)\right)\perp W \mid X $$ mean $$ f(Y(0),Y(1), W\mid X)=f(Y(0),Y(1)\mid X)\cdot f(W\mid X)$$ ? I can prove that the second line if the set of random variables $(Y(0),Y(1))$ is independent of $W$ given $X$: $$f(Y(0),Y(1), W\mid X)=f(Y(0),Y(1)\mid W,X)\cdot f(W|X)$$ by the conditioning rule. Since $f((Y(0),Y(1)|W,X)$ does not depend on $W$ by the assumption stated, the result is obtained. But every signle paper omits this discussion. I am studying this treatment effect literature by myself, so I need to understabd this fundamental assumption based on my econometrics knowledge.","In the notation of the unconfounded assumption, does  $$\left(Y(0),Y(1)\right)\perp W \mid X $$ mean $$ f(Y(0),Y(1), W\mid X)=f(Y(0),Y(1)\mid X)\cdot f(W\mid X)$$ ? I can prove that the second line if the set of random variables $(Y(0),Y(1))$ is independent of $W$ given $X$: $$f(Y(0),Y(1), W\mid X)=f(Y(0),Y(1)\mid W,X)\cdot f(W|X)$$ by the conditioning rule. Since $f((Y(0),Y(1)|W,X)$ does not depend on $W$ by the assumption stated, the result is obtained. But every signle paper omits this discussion. I am studying this treatment effect literature by myself, so I need to understabd this fundamental assumption based on my econometrics knowledge.",,['statistics']
28,Solving a Maximum Likelihood Estimation with an exponential distribution,Solving a Maximum Likelihood Estimation with an exponential distribution,,"I need someone's insight on applying a MLE for an exponential distribution. In a finance paper, I have the following: $\displaystyle d_i \sim \frac{\epsilon_i}{\lambda_i}$ where $\epsilon_i$ is i.i.d. exponentially distributed with parameter $= 1$. and $i=1,\ldots,n$. $d_i$ are duration time values like time between two events. The $\epsilon$ are not observed. $\lambda_i$ are not observed and must be replaced with estimates from an optimal filter under a $2^k$ states where $k$ can take value $2 \ldots 10$. Conditional on $\lambda_i$ the $d_i$ have an exponential distribution of $\lambda_i$ with density $p(d_i|\lambda_i) = \lambda_i \exp[-\lambda_i d_i]$ The $\epsilon_i$ in $\displaystyle d_i \sim \frac{\epsilon_i}{\lambda_i}$ confuses me in the MLE application. First, is the $\epsilon_i$ relevant in the MLE computation? If yes, how does it influence the likelihood fucntion below: $$ \mathcal{L}(\lambda,d_1,\dots,d_n)=\prod_{i=1}^n f(d_i,\lambda)=\prod_{i=1}^n \lambda e^{-\lambda d}=\lambda^ne^{-\lambda\sum_{i=1}^nd_i} $$","I need someone's insight on applying a MLE for an exponential distribution. In a finance paper, I have the following: $\displaystyle d_i \sim \frac{\epsilon_i}{\lambda_i}$ where $\epsilon_i$ is i.i.d. exponentially distributed with parameter $= 1$. and $i=1,\ldots,n$. $d_i$ are duration time values like time between two events. The $\epsilon$ are not observed. $\lambda_i$ are not observed and must be replaced with estimates from an optimal filter under a $2^k$ states where $k$ can take value $2 \ldots 10$. Conditional on $\lambda_i$ the $d_i$ have an exponential distribution of $\lambda_i$ with density $p(d_i|\lambda_i) = \lambda_i \exp[-\lambda_i d_i]$ The $\epsilon_i$ in $\displaystyle d_i \sim \frac{\epsilon_i}{\lambda_i}$ confuses me in the MLE application. First, is the $\epsilon_i$ relevant in the MLE computation? If yes, how does it influence the likelihood fucntion below: $$ \mathcal{L}(\lambda,d_1,\dots,d_n)=\prod_{i=1}^n f(d_i,\lambda)=\prod_{i=1}^n \lambda e^{-\lambda d}=\lambda^ne^{-\lambda\sum_{i=1}^nd_i} $$",,"['probability', 'statistics', 'economics']"
29,KL divergence between Bernoulli Distribution with parameter $p$ and Gaussian Distribution,KL divergence between Bernoulli Distribution with parameter  and Gaussian Distribution,p,"I am trying to find the Kullback–Leibler divergence between Bernoulli Distribution on two points $T, -T$ with parameter $p$ and Gaussian Distribution with mean $\mu$ and variance $\sigma^2$. My attempt is as follows: Let $$ b(x) = q\delta(x-T)+p\delta(x+T) \sim \text{Bernoulli}(p) \\ g(x) \sim N(\mu, \sigma^2). $$ $$ \begin{align} D(b||g) &= \int_{-\infty}^{\infty}b(x)\log \left( \frac{b(x)}{g(x)}\right) dx \\ &=\int_{-\infty}^{\infty}b(x)\log \left( b(x) \right) dx - \int_{-\infty}^{\infty}b(x)\log \left( g(x) \right) dx \\  &=A-B \end{align} $$ My questions are as follows: Can I use the continuous representation of Bernoulli RV with the help of $\delta(.)$ functions where $\delta(.)$ is Dirac Delta function? Does $A$ exist? Because, on the set $\mathbb{R}-\{\pm T\}$, $\log(\delta(x \mp T))$ is $-\infty$. If we cannot calculate the KLD between a continuous and a discrete random variable, what is the KLD analogue for this case? My thought was that $B$ alone can serve as a distance. For example, if we want to measure the distance of $b(x)$ from two different Gaussian distributions $g_1(x), g_2(x)$, only $B$ depends on $g_1(x)$ or $g_2(x)$, and thus can contribute to KLD.","I am trying to find the Kullback–Leibler divergence between Bernoulli Distribution on two points $T, -T$ with parameter $p$ and Gaussian Distribution with mean $\mu$ and variance $\sigma^2$. My attempt is as follows: Let $$ b(x) = q\delta(x-T)+p\delta(x+T) \sim \text{Bernoulli}(p) \\ g(x) \sim N(\mu, \sigma^2). $$ $$ \begin{align} D(b||g) &= \int_{-\infty}^{\infty}b(x)\log \left( \frac{b(x)}{g(x)}\right) dx \\ &=\int_{-\infty}^{\infty}b(x)\log \left( b(x) \right) dx - \int_{-\infty}^{\infty}b(x)\log \left( g(x) \right) dx \\  &=A-B \end{align} $$ My questions are as follows: Can I use the continuous representation of Bernoulli RV with the help of $\delta(.)$ functions where $\delta(.)$ is Dirac Delta function? Does $A$ exist? Because, on the set $\mathbb{R}-\{\pm T\}$, $\log(\delta(x \mp T))$ is $-\infty$. If we cannot calculate the KLD between a continuous and a discrete random variable, what is the KLD analogue for this case? My thought was that $B$ alone can serve as a distance. For example, if we want to measure the distance of $b(x)$ from two different Gaussian distributions $g_1(x), g_2(x)$, only $B$ depends on $g_1(x)$ or $g_2(x)$, and thus can contribute to KLD.",,"['real-analysis', 'statistics']"
30,Is There a $R^2 \rightarrow R^2$ Linear Transformation to Make XOR Problem Separable?,Is There a  Linear Transformation to Make XOR Problem Separable?,R^2 \rightarrow R^2,"By Cover's Theorem(1965), it is possible to make patterns separable if the original feature space is transformed to a higher-dimensional space. Think of the XOR problem. It is not possible to separate the two classes with a hyperplane. One trick is to use Neural Networks, which transformed the feature space linearly to a higher dimensional space. Another is the kernel trick with non-linear transformation. But can we make the classes separable only using a low-dimensional linear transformation, i.e. $R^2 \rightarrow R^2$ Linear Transformation? I think I cannot find one. Is there any way to prove that such a transformation does not exist?","By Cover's Theorem(1965), it is possible to make patterns separable if the original feature space is transformed to a higher-dimensional space. Think of the XOR problem. It is not possible to separate the two classes with a hyperplane. One trick is to use Neural Networks, which transformed the feature space linearly to a higher dimensional space. Another is the kernel trick with non-linear transformation. But can we make the classes separable only using a low-dimensional linear transformation, i.e. $R^2 \rightarrow R^2$ Linear Transformation? I think I cannot find one. Is there any way to prove that such a transformation does not exist?",,"['statistics', 'machine-learning']"
31,What is the probability of two people meeting?,What is the probability of two people meeting?,,"I am trying to figure out a solution to the following problem: Let there be two groups of people, Group A and Group B. Group A represents x percent (e.g. 1%) of the world's population, and Group B represents y percent (e.g. 2%) of the world's population. What is the probability that a person from Group A will meet a person from Group B? Assume the following things: The average human being meets z people (e.g. 100,000) in a lifetime. The world's population is kept at a constant k people. Everyone in the world was born and will die at the same time. Disclaimer: I came up with this question myself, but I'm not a mathematician, so please feel free to clean this up if need be. Also, if there is not enough information in the problem to solve it, add assumptions and please indicate the reasons for adding them. The assumptions I wrote are my attempt at making the problem easier. If they are not necessary, and removing any produces a more accurate answer, then I encourage the removal of them.","I am trying to figure out a solution to the following problem: Let there be two groups of people, Group A and Group B. Group A represents x percent (e.g. 1%) of the world's population, and Group B represents y percent (e.g. 2%) of the world's population. What is the probability that a person from Group A will meet a person from Group B? Assume the following things: The average human being meets z people (e.g. 100,000) in a lifetime. The world's population is kept at a constant k people. Everyone in the world was born and will die at the same time. Disclaimer: I came up with this question myself, but I'm not a mathematician, so please feel free to clean this up if need be. Also, if there is not enough information in the problem to solve it, add assumptions and please indicate the reasons for adding them. The assumptions I wrote are my attempt at making the problem easier. If they are not necessary, and removing any produces a more accurate answer, then I encourage the removal of them.",,"['probability', 'statistics', 'discrete-mathematics']"
32,"Is this a place to use Variance, if so what is the meaning of the value?","Is this a place to use Variance, if so what is the meaning of the value?",,"I want to know if this is a good place to calculate variance in my data,and how to interpret or explain the units of the variance answer. I  have 2 lists of corresponding data. ListA has a starting price, ListB has the ending price of the corresponding item in ListA. Subtracting the two lists item-wise and looking at the differences in price is not very relevant because the items in the list are not closely related. For example is could be prices of bikes mixed in with prices of cars. I want to be able to say something like      ""These 30,000 items typically varied in price (beginning versus ending) by x%"" *some specificity on what typically means may be needed* It sounds kind of like an average but I'm not sure if that's the bets way to capture what's going on since (again) the items are not closely related even though the ""method"" by which their prices might change is. For example the could be House prices, sold by a set of the same realtors. The ""method"" is real-estate sales, but the houses themselves are not related to an extent that we should be compare the prices of the houses. Instead we should compare the mark-up or mark-down of the house prices form their own starting points, as this could later be related to the effectiveness of the realtor to sell. Is this a variance problem? If not, what calculation will lead me to an outcome where I can make the statement above? ""These 30,000 items typically varied in price by x%""","I want to know if this is a good place to calculate variance in my data,and how to interpret or explain the units of the variance answer. I  have 2 lists of corresponding data. ListA has a starting price, ListB has the ending price of the corresponding item in ListA. Subtracting the two lists item-wise and looking at the differences in price is not very relevant because the items in the list are not closely related. For example is could be prices of bikes mixed in with prices of cars. I want to be able to say something like      ""These 30,000 items typically varied in price (beginning versus ending) by x%"" *some specificity on what typically means may be needed* It sounds kind of like an average but I'm not sure if that's the bets way to capture what's going on since (again) the items are not closely related even though the ""method"" by which their prices might change is. For example the could be House prices, sold by a set of the same realtors. The ""method"" is real-estate sales, but the houses themselves are not related to an extent that we should be compare the prices of the houses. Instead we should compare the mark-up or mark-down of the house prices form their own starting points, as this could later be related to the effectiveness of the realtor to sell. Is this a variance problem? If not, what calculation will lead me to an outcome where I can make the statement above? ""These 30,000 items typically varied in price by x%""",,"['statistics', 'normal-distribution']"
33,significance test,significance test,,"I've analysed newspapers by counting the language distributions of the articles. The results look like that: Day 1               Day 2              Day 3  Economy             Economy            Economy language 1: 0,35    language 1: 0,30   language 1: 0,90 language 2: 0,11    language 2: 0,10   language 2: 0,00 language 3: 0,54    language 3: 0,60   language 3: 0,10  Sports              Sports             Sports language 1: 0,40    language 1: 0,30   language 1: 1.00 language 2: 0,20    language 2: 0,20   language 2: 0,00 language 3: 0,40    language 3: 0,50   language 3: 0,00 I've have already posted another question on that topic ( Remove statistical outliers ), but here comes my second problem. First of all, I want to remove all statistical outliers from data (e.g. day 3), to make it ""clean"" (see my other question ( other post ). After that, I want to terminate which changes in my data are just ""noise"" and witch are significant changes. But I'm not sure how to do it. I was thinking of the following approach: I could calculate the standard deviation (like in my other post ) and treat every value outside of it as a ""significant change"". But I think this will cause a mistake if all my values are slightly increasing or decreasing. Is there any mathematical technique to find the significant changes in my data? Thanks in advance. (PS: I have only a few samples (~ 150 days).)","I've analysed newspapers by counting the language distributions of the articles. The results look like that: Day 1               Day 2              Day 3  Economy             Economy            Economy language 1: 0,35    language 1: 0,30   language 1: 0,90 language 2: 0,11    language 2: 0,10   language 2: 0,00 language 3: 0,54    language 3: 0,60   language 3: 0,10  Sports              Sports             Sports language 1: 0,40    language 1: 0,30   language 1: 1.00 language 2: 0,20    language 2: 0,20   language 2: 0,00 language 3: 0,40    language 3: 0,50   language 3: 0,00 I've have already posted another question on that topic ( Remove statistical outliers ), but here comes my second problem. First of all, I want to remove all statistical outliers from data (e.g. day 3), to make it ""clean"" (see my other question ( other post ). After that, I want to terminate which changes in my data are just ""noise"" and witch are significant changes. But I'm not sure how to do it. I was thinking of the following approach: I could calculate the standard deviation (like in my other post ) and treat every value outside of it as a ""significant change"". But I think this will cause a mistake if all my values are slightly increasing or decreasing. Is there any mathematical technique to find the significant changes in my data? Thanks in advance. (PS: I have only a few samples (~ 150 days).)",,"['statistics', 'standard-deviation']"
34,MA process ACF proof - don't understand it,MA process ACF proof - don't understand it,,"I've got the proof but I don't understand a small detail. As you know for an MA process: $X_n = \sum _{i=0} ^q \beta_i Z_{n-i}$ where $Z_n$ is WGN (pure Gaussian random process). Then the ACF is: $\gamma(k) = Cov(\sum _{i=0} ^q \beta_i Z_{n-i}, \sum _{j=0} ^q \beta_j Z_{n-j + k}) = \sum _{i=0} ^q \sum _{j=0} ^q \beta_i \beta_j Cov(Z_{n-i}, Z_{n-j+k}) = \sum _{i=0} ^q \sum _{j=0} ^q \beta_i \beta_j Cov(Z_n, Z_{n +i-j+k})$ But because $\{Z_{n+i}\}$ is iid wrt i then: $Cov(Z_n, Z_{n +i-j+k}) = 0$ for $k + i - j \neq 0$ and $Cov(Z_n, Z_{n +i-j+k}) = \sigma_z ^2$ for $k + i - j = 0$. So: $\gamma(k) = \sigma_z ^2 \sum _{i=0} ^q \sum _{j=0} ^q \beta_i \beta_j$ But the book says this equals: $\sigma_z ^2 \sum_{i=0} ^{q-k} \beta_i \beta_{i+k}$ . For some reason I can't see how. If the sums were to infinity then I would agree, but they are not.","I've got the proof but I don't understand a small detail. As you know for an MA process: $X_n = \sum _{i=0} ^q \beta_i Z_{n-i}$ where $Z_n$ is WGN (pure Gaussian random process). Then the ACF is: $\gamma(k) = Cov(\sum _{i=0} ^q \beta_i Z_{n-i}, \sum _{j=0} ^q \beta_j Z_{n-j + k}) = \sum _{i=0} ^q \sum _{j=0} ^q \beta_i \beta_j Cov(Z_{n-i}, Z_{n-j+k}) = \sum _{i=0} ^q \sum _{j=0} ^q \beta_i \beta_j Cov(Z_n, Z_{n +i-j+k})$ But because $\{Z_{n+i}\}$ is iid wrt i then: $Cov(Z_n, Z_{n +i-j+k}) = 0$ for $k + i - j \neq 0$ and $Cov(Z_n, Z_{n +i-j+k}) = \sigma_z ^2$ for $k + i - j = 0$. So: $\gamma(k) = \sigma_z ^2 \sum _{i=0} ^q \sum _{j=0} ^q \beta_i \beta_j$ But the book says this equals: $\sigma_z ^2 \sum_{i=0} ^{q-k} \beta_i \beta_{i+k}$ . For some reason I can't see how. If the sums were to infinity then I would agree, but they are not.",,"['probability', 'sequences-and-series', 'statistics', 'stochastic-processes', 'signal-processing']"
35,Quantile of Chi-squared = inverse Quantile of inverse Chi-squared distribution?,Quantile of Chi-squared = inverse Quantile of inverse Chi-squared distribution?,,"I used to think that the following held true: If $Y\sim \chi^2$, then $\frac{1}{Y}\sim \operatorname{inv}\chi^2$, the inverse $\chi^2$-distribution. Let $\chi^2_\alpha$ denote the $\alpha$-quantile of $Y$, then $\frac{1}{\chi^2_\alpha}$ is the $\alpha$-quantile of $\frac{1}{Y}$, meaning $$P\left(Y\leq \chi^2_\alpha\right)=P\left(\frac{1}{Y}\leq\frac{1}{\chi^2_\alpha}\right)=\alpha.$$ Now I figured out that this cannot be true, right? But what is the relationship between the two quantiles then? (Or is it true after all?)","I used to think that the following held true: If $Y\sim \chi^2$, then $\frac{1}{Y}\sim \operatorname{inv}\chi^2$, the inverse $\chi^2$-distribution. Let $\chi^2_\alpha$ denote the $\alpha$-quantile of $Y$, then $\frac{1}{\chi^2_\alpha}$ is the $\alpha$-quantile of $\frac{1}{Y}$, meaning $$P\left(Y\leq \chi^2_\alpha\right)=P\left(\frac{1}{Y}\leq\frac{1}{\chi^2_\alpha}\right)=\alpha.$$ Now I figured out that this cannot be true, right? But what is the relationship between the two quantiles then? (Or is it true after all?)",,"['statistics', 'probability-distributions']"
36,"Given 13 cards and having at least one ace, what's the probability you hold all aces?","Given 13 cards and having at least one ace, what's the probability you hold all aces?",,"Question: A deck of cards is shuffled and dealt to four players, with each receiving 13 cards. Find: The probability that the first player holds all the aces given that she holds at least one. Attempt at solution: P(Player 1 has 4 aces | at least one)=P(4 aces)/(1-P(none)) =binomial(4,4)*binomial(48,9)/binomial(52,13)/(binomial(52,13)/binomial(52,13)-binomial(4,0)*binomial(48,13)/binomial(52,13))=bimonial(48,9)/(binomial(52,13)-binomial(48,13))=5/1318=.003794. This is the right answer, according to the text. But I'm not sure why P(Player 1 has 4 aces | at least one)=P(4 aces)/(1-P(none)). I really struggle with these type of equations. Can someone teach me how to solve P(A|A,B,C,D,...)? Also, I'm curious why I couldn't solve it this way. I get a wrong answer: AP^3*q^9 + AAP^2*q^9 + AAAp*q^9 + AAAAq^9 =binomial(12,3)*3*2*1/(51*50*49) + binomial(11,2)*2*1/(50*49) + binomial(10,1)*1/49= 25% (where A stands for ace). Thanks in advance!!! This is for review, not homework.","Question: A deck of cards is shuffled and dealt to four players, with each receiving 13 cards. Find: The probability that the first player holds all the aces given that she holds at least one. Attempt at solution: P(Player 1 has 4 aces | at least one)=P(4 aces)/(1-P(none)) =binomial(4,4)*binomial(48,9)/binomial(52,13)/(binomial(52,13)/binomial(52,13)-binomial(4,0)*binomial(48,13)/binomial(52,13))=bimonial(48,9)/(binomial(52,13)-binomial(48,13))=5/1318=.003794. This is the right answer, according to the text. But I'm not sure why P(Player 1 has 4 aces | at least one)=P(4 aces)/(1-P(none)). I really struggle with these type of equations. Can someone teach me how to solve P(A|A,B,C,D,...)? Also, I'm curious why I couldn't solve it this way. I get a wrong answer: AP^3*q^9 + AAP^2*q^9 + AAAp*q^9 + AAAAq^9 =binomial(12,3)*3*2*1/(51*50*49) + binomial(11,2)*2*1/(50*49) + binomial(10,1)*1/49= 25% (where A stands for ace). Thanks in advance!!! This is for review, not homework.",,"['probability', 'statistics']"
37,Probability - Coin Toss - Find Formula,Probability - Coin Toss - Find Formula,,"The problem statement, all variables and given/known data: Suppose a fair coin is tossed $n$ times. Find simple formulae in terms of $n$ and $k$ for a) $P(k-1 \mbox{ heads} \mid k-1 \mbox{ or } k \mbox{ heads})$ b) $P(k \mbox{ heads} \mid k-1 \mbox{ or } k \mbox{ heads})$ Relevant equations: $P(k \mbox{ heads in } n \mbox{ fair tosses})=\binom{n}{k}2^{-n}\quad (0\leq k\leq n)$ The attempt at a solution: I'm stuck on the conditional probability. I've dabbled with it a little bit but I'm confused what $k-1$ intersect $k$ is. This is for review and not homework. The answer to a) is $k/(n+1)$ . I tried $P(k-1 \mbox{ heads} \mid k \mbox{ heads})=P(k-1 \cap K)/P(K \mbox{ heads})=P(K-1)/P(K).$ I also was thinking about $$P(A\mid A,B)=P(A\cap (A\cup B))/P(A\cup B)=P(A\cup (A\cap B))/P(A\cup B)=P(A)/(P(A)+P(B)-P(AB))$$","The problem statement, all variables and given/known data: Suppose a fair coin is tossed times. Find simple formulae in terms of and for a) b) Relevant equations: The attempt at a solution: I'm stuck on the conditional probability. I've dabbled with it a little bit but I'm confused what intersect is. This is for review and not homework. The answer to a) is . I tried I also was thinking about","n n k P(k-1 \mbox{ heads} \mid k-1 \mbox{ or } k \mbox{ heads}) P(k \mbox{ heads} \mid k-1 \mbox{ or } k \mbox{ heads}) P(k \mbox{ heads in } n \mbox{ fair tosses})=\binom{n}{k}2^{-n}\quad (0\leq k\leq n) k-1 k k/(n+1) P(k-1 \mbox{ heads} \mid k \mbox{ heads})=P(k-1 \cap K)/P(K \mbox{ heads})=P(K-1)/P(K). P(A\mid A,B)=P(A\cap (A\cup B))/P(A\cup B)=P(A\cup (A\cap B))/P(A\cup B)=P(A)/(P(A)+P(B)-P(AB))","['probability', 'statistics']"
38,Standard normal distribution probabilities,Standard normal distribution probabilities,,"Ok so I am having difficulty understand the concept behind standard normal distribution probabilities, in the questions I am getting a graph and a table FILLED with numbers, top header column has values from 0.01 to 0.09 and on left I have 0.0 to 3.8! and the questions are like : i) P(Z<1.5)= etc. Now I do not get what they mean by calculating the area at the bottom of the curve (NOT sure what the curve represents!) to the left, so please when explaining use an example and use simple terminology","Ok so I am having difficulty understand the concept behind standard normal distribution probabilities, in the questions I am getting a graph and a table FILLED with numbers, top header column has values from 0.01 to 0.09 and on left I have 0.0 to 3.8! and the questions are like : i) P(Z<1.5)= etc. Now I do not get what they mean by calculating the area at the bottom of the curve (NOT sure what the curve represents!) to the left, so please when explaining use an example and use simple terminology",,"['probability', 'statistics', 'normal-distribution']"
39,Kolmogorov-Smirnov test,Kolmogorov-Smirnov test,,"Five observations from an underlying loss distribution are: $0.1,\ 0.2,\ 0.5,\ 0.7,\ 1.3$. Find the value of the Kolmogorov-Smirnov test statistic for test that the underlying distribution has p.d.f. $f(x) = 4/(1+x)^5$.","Five observations from an underlying loss distribution are: $0.1,\ 0.2,\ 0.5,\ 0.7,\ 1.3$. Find the value of the Kolmogorov-Smirnov test statistic for test that the underlying distribution has p.d.f. $f(x) = 4/(1+x)^5$.",,['statistics']
40,What is the distribution of the euclidean distance between two normally distributed random variables with non-zero means?,What is the distribution of the euclidean distance between two normally distributed random variables with non-zero means?,,"Assuming two uncorrelated random variable (RVs) with Gaussian distributions $x\sim N(m_1,s)$ and $y\sim N(m_2,s)$, so with non-zero mean and same variance , what is the distribution of $z=\sqrt{(x^2 + y^2)}$? Is there a known parametric distribution for z? I have already researched this problem, but I am not sure whether z is a Rician distributed RV. It has been proven that z is Ricianly distributed only when x OR y have a zero mean, because they are considered to be circular bivariate RVS in these demonstrations. I would like to know if the Ricean distribution holds when BOTH uncorrelated Gaussian RVs x and y have non-zero means. All ideas are welcome! Thank you!","Assuming two uncorrelated random variable (RVs) with Gaussian distributions $x\sim N(m_1,s)$ and $y\sim N(m_2,s)$, so with non-zero mean and same variance , what is the distribution of $z=\sqrt{(x^2 + y^2)}$? Is there a known parametric distribution for z? I have already researched this problem, but I am not sure whether z is a Rician distributed RV. It has been proven that z is Ricianly distributed only when x OR y have a zero mean, because they are considered to be circular bivariate RVS in these demonstrations. I would like to know if the Ricean distribution holds when BOTH uncorrelated Gaussian RVs x and y have non-zero means. All ideas are welcome! Thank you!",,['statistics']
41,Simple Least Squares Regression?,Simple Least Squares Regression?,,"I have a vector X of 50 real numbers and a vector Y of 50 real numbers. I want to model them as y = ax + b How do I determine a and b such that it minimizes the square of the error to this training set? That is given X = (x1,x2,...,x50) Y = (y1,y2,...,y50) What is the closed form for a = ??? b = ??? See also: https://codereview.stackexchange.com/questions/10122/c-correlation-leastsquarescoefs","I have a vector X of 50 real numbers and a vector Y of 50 real numbers. I want to model them as y = ax + b How do I determine a and b such that it minimizes the square of the error to this training set? That is given X = (x1,x2,...,x50) Y = (y1,y2,...,y50) What is the closed form for a = ??? b = ??? See also: https://codereview.stackexchange.com/questions/10122/c-correlation-leastsquarescoefs",,"['linear-algebra', 'statistics', 'regression', 'machine-learning']"
42,Calculate Probability Given Probability Generating Function,Calculate Probability Given Probability Generating Function,,"I've come across a statistics problem that I can't seem to figure out how to solve: ""A certain discrete random variable has probability generating function:  $$ \pi_x(q) = \dfrac{1}{3}\dfrac{2+q}{2-q} $$ Compute p(x) for x = 0,1,2,3,4,5. (Hint: the formula for summing a geometric series will help you expand the denominator)."" I'm not entirely sure what sort of answer this problem requires. q is not given, so is it only possible to solve this in terms of q? What would be a good way to start solving this problem (especially since I don't know of any way to solve for p(x) given a probability generating function)? Any help would be greatly appreciated.","I've come across a statistics problem that I can't seem to figure out how to solve: ""A certain discrete random variable has probability generating function:  $$ \pi_x(q) = \dfrac{1}{3}\dfrac{2+q}{2-q} $$ Compute p(x) for x = 0,1,2,3,4,5. (Hint: the formula for summing a geometric series will help you expand the denominator)."" I'm not entirely sure what sort of answer this problem requires. q is not given, so is it only possible to solve this in terms of q? What would be a good way to start solving this problem (especially since I don't know of any way to solve for p(x) given a probability generating function)? Any help would be greatly appreciated.",,['statistics']
43,How can I find the expected value due to the trials instead of simply expected value of trials of a geometric distribution?,How can I find the expected value due to the trials instead of simply expected value of trials of a geometric distribution?,,"Suppose in a game, if I win in the $j$th round, I gain $+\$2^{j-1}$ and if I don't win in the $j$th, I lose $-\$2^{j-1}$. If I lose, I will keep playing until I win. Once I win, I leave the game. Otherwise, I continue to play until 30 rounds and leave the game even if I don't win. In other words, I will just stop at the $30$th round. Each round is independent and the probability of winning in each round is $\frac{9}{13}$. I let $X$ be a random variable of my winnings. I want to find my expected winnings. Since it works in a way that I would stop during my first win, I have a feeling that $X$ should be distributed over the Geometric Distribution. The game is either a win or a lose, so it is pretty much like a Bernoulli trial. But since I am not getting the expected number of rounds played, the Bernoulli trials cannot be just $0$ or $1$. So I thought I could modify it to become this way: $$ { X }_{ j }=\left\{\begin{matrix} +2^{j-1} & if\;  win\\  -2^{j-1} & if\;  lose \end{matrix}\right. $$ Then, $E(X)=E(X_1+X_2+\cdots +X_{30})=E(X_1)+E(X_2)+\cdots +E(X_{30})$ However, because I thought this is a Geometric Distribution, the expected value is just $\frac{1}{p}=\frac{13}{9}$. But I don't think the expected winnings is $\frac{13}{9}$ and is wrong. Is what I have done correct? So, instead of the usual finding of the expected number of trials of a standard geometric distribution, how can I find an expected number of another factor due to the trials (in this case, the expected number of winnings from the trials)? Edit: What I attempted to do was to make use of an indicator function to determine the expectation. But it doesn't seem successful.","Suppose in a game, if I win in the $j$th round, I gain $+\$2^{j-1}$ and if I don't win in the $j$th, I lose $-\$2^{j-1}$. If I lose, I will keep playing until I win. Once I win, I leave the game. Otherwise, I continue to play until 30 rounds and leave the game even if I don't win. In other words, I will just stop at the $30$th round. Each round is independent and the probability of winning in each round is $\frac{9}{13}$. I let $X$ be a random variable of my winnings. I want to find my expected winnings. Since it works in a way that I would stop during my first win, I have a feeling that $X$ should be distributed over the Geometric Distribution. The game is either a win or a lose, so it is pretty much like a Bernoulli trial. But since I am not getting the expected number of rounds played, the Bernoulli trials cannot be just $0$ or $1$. So I thought I could modify it to become this way: $$ { X }_{ j }=\left\{\begin{matrix} +2^{j-1} & if\;  win\\  -2^{j-1} & if\;  lose \end{matrix}\right. $$ Then, $E(X)=E(X_1+X_2+\cdots +X_{30})=E(X_1)+E(X_2)+\cdots +E(X_{30})$ However, because I thought this is a Geometric Distribution, the expected value is just $\frac{1}{p}=\frac{13}{9}$. But I don't think the expected winnings is $\frac{13}{9}$ and is wrong. Is what I have done correct? So, instead of the usual finding of the expected number of trials of a standard geometric distribution, how can I find an expected number of another factor due to the trials (in this case, the expected number of winnings from the trials)? Edit: What I attempted to do was to make use of an indicator function to determine the expectation. But it doesn't seem successful.",,"['probability', 'statistics']"
44,Finding the probability of getting no successes in a Geometric Distribution,Finding the probability of getting no successes in a Geometric Distribution,,"In Geometric Distribution, I am getting the probability for doing $x$ number of trials and get my first success with each trial of probability $p$. So suppose I want to find what's the probability of doing 30 trials and get my first success on the 30th trial, I do this: $$ P(X=30)=(1-p)^{30-1}p$$ Now, then if I want to find the probability for not getting a single success at all even after doing $30$ trials on this same distribution, what should I do? The parameters of the Geometric Distribution doesn't seem to let me find this. I thought of using like $1$ minus the CDF of 30 trials of the geometric distribution but I am not sure if it would be accurate.","In Geometric Distribution, I am getting the probability for doing $x$ number of trials and get my first success with each trial of probability $p$. So suppose I want to find what's the probability of doing 30 trials and get my first success on the 30th trial, I do this: $$ P(X=30)=(1-p)^{30-1}p$$ Now, then if I want to find the probability for not getting a single success at all even after doing $30$ trials on this same distribution, what should I do? The parameters of the Geometric Distribution doesn't seem to let me find this. I thought of using like $1$ minus the CDF of 30 trials of the geometric distribution but I am not sure if it would be accurate.",,"['probability', 'statistics']"
45,Combining 1D normal distributions into a 2D distribution,Combining 1D normal distributions into a 2D distribution,,"First of all, apologies for my poor terminology - I have a particular problem which I understand in own terms, but I am having difficulty in applying the mathematics in the correct manner. My problem is that I have a point in 2D space with an uncertainty in two directions.  These directions happen to be perpendicular to one another, however they are not necessarily perpendicular to the axes.  (If it helps, the point represents a top-down view of an object from an image - there is uncertainty horizontally in the image as well as a larger uncertainty in the depth of the object).  I can find the standard deviation of the two components and represent them as univariate distributions, but I'd instead like to represent them as a 2D distribution as they should be. I can completely see that this is possible and probably very simple but I just can't quite make the leap from my visualisation of the problem to the mathematical formalism - I only need to calculate the parameters of the 2D distribution (specifically, I guess, the covariance - I know the mean).  If someone could just give me a prod in the right direction I would be very grateful.","First of all, apologies for my poor terminology - I have a particular problem which I understand in own terms, but I am having difficulty in applying the mathematics in the correct manner. My problem is that I have a point in 2D space with an uncertainty in two directions.  These directions happen to be perpendicular to one another, however they are not necessarily perpendicular to the axes.  (If it helps, the point represents a top-down view of an object from an image - there is uncertainty horizontally in the image as well as a larger uncertainty in the depth of the object).  I can find the standard deviation of the two components and represent them as univariate distributions, but I'd instead like to represent them as a 2D distribution as they should be. I can completely see that this is possible and probably very simple but I just can't quite make the leap from my visualisation of the problem to the mathematical formalism - I only need to calculate the parameters of the 2D distribution (specifically, I guess, the covariance - I know the mean).  If someone could just give me a prod in the right direction I would be very grateful.",,"['probability', 'statistics', 'probability-distributions', 'normal-distribution']"
46,Using Basu's Theorem,Using Basu's Theorem,,"I have the following question: What have I done so far: I have showed that Y4 is sufficient and complete for theta. Now I need to apply Basu's theorem, and I am not exactly sure how to show that Y1 / Y4 or (Y1+Y2)/(Y3+Y4) are ancillary statistics. Help would be great. Thanks.","I have the following question: What have I done so far: I have showed that Y4 is sufficient and complete for theta. Now I need to apply Basu's theorem, and I am not exactly sure how to show that Y1 / Y4 or (Y1+Y2)/(Y3+Y4) are ancillary statistics. Help would be great. Thanks.",,['statistics']
47,Showing family is NOT complete,Showing family is NOT complete,,"How would I show that $$f(x;\theta) = \frac1{2\theta}$$ where $x$ is between positive and negative $\theta$ and $\theta$ is between $0$ and $\infty$ is NOT a complete family? I know that I need to find a non-zero function $u(x)$ whose expectation will be $0$, but I am struggling with finding this function. Thanks","How would I show that $$f(x;\theta) = \frac1{2\theta}$$ where $x$ is between positive and negative $\theta$ and $\theta$ is between $0$ and $\infty$ is NOT a complete family? I know that I need to find a non-zero function $u(x)$ whose expectation will be $0$, but I am struggling with finding this function. Thanks",,['statistics']
48,z-interval and sample size what is a normal sample size,z-interval and sample size what is a normal sample size,,Can a Z-interval be used when the sample size is between 15-30? does the variable play a role? I'm not too sure if it makes a difference. I know it can be used if the population is a normal or large sample size but is 15-30 consider a normal size,Can a Z-interval be used when the sample size is between 15-30? does the variable play a role? I'm not too sure if it makes a difference. I know it can be used if the population is a normal or large sample size but is 15-30 consider a normal size,,"['statistics', 'soft-question']"
49,"In general, $\textit{Var}(X) = E(X^2) - [E(X)]^2$","In general,",\textit{Var}(X) = E(X^2) - [E(X)]^2,"This is from page 25 of this book : In general, it may be shown that   $$\textit{Var}(X) = E(X^2) - [E(X)]^2$$ I can't remember ever seeing that ""In general"" elsewhere. So if this identity only holds ""in general"" are there cases where  $$\textit{Var}(X) \neq E(X^2) - [E(X)]^2$$ Even in cases where there is no second moment, I think the identity should hold. Because neither the variance nor the second moment exist. But maybe this is what they're talking about.","This is from page 25 of this book : In general, it may be shown that   $$\textit{Var}(X) = E(X^2) - [E(X)]^2$$ I can't remember ever seeing that ""In general"" elsewhere. So if this identity only holds ""in general"" are there cases where  $$\textit{Var}(X) \neq E(X^2) - [E(X)]^2$$ Even in cases where there is no second moment, I think the identity should hold. Because neither the variance nor the second moment exist. But maybe this is what they're talking about.",,['statistics']
50,Binomial distributions,Binomial distributions,,"If I'm tossing 4 pennies at once, and then recording how many heads there came out to be 32 times, is that a Binomial experiment?","If I'm tossing 4 pennies at once, and then recording how many heads there came out to be 32 times, is that a Binomial experiment?",,"['statistics', 'discrete-mathematics']"
51,Problem of hypergeometric testing.,Problem of hypergeometric testing.,,"This is actually a computational biology problem, but you don't really need biology knowledge to understand it: You are given expression values of a given protein P for 10 individuals with a normal condition and 10 individuals with a disease condition. Normal: 5.2 6.4 7.8 3.1 2.9 1.0 2.3 0.6 4.3 3.2 Disease: 7.8 9.1 10.4 11.5 4.3 6.5 7.6 6.7 10.1 2.1 Your team built a disease predictor such that when the expression of the protein is higher than 5.5, the predictor claims that the individual has the disease. You now want to evaluate out of the disease predictions made by the predictor if the actual number of disease individuals predicted is obtained by chance. Compute the p-value according to the correct statistical test seen in class and assume that a p-value < 0.05 significantly   differs from what should be obtained by chance. Show your calculations. I was given the standard answer that $$ p-value = 1 - \sum_{i=0}^7 \frac {\binom {10} i \binom {20-10}{i}} {\binom {20} {10}} $$ which is using the hypergeometric distribution. I know what is a $p-value$, but what is hypothesis we are testing with this $p-value$? For me it seems that the formula is calculating if we pick 10 people from the 20 samples, what's the probability that we get more than 7 normal people.  But this probability doesn't seem to have any connection with predictor.  I'm confused...","This is actually a computational biology problem, but you don't really need biology knowledge to understand it: You are given expression values of a given protein P for 10 individuals with a normal condition and 10 individuals with a disease condition. Normal: 5.2 6.4 7.8 3.1 2.9 1.0 2.3 0.6 4.3 3.2 Disease: 7.8 9.1 10.4 11.5 4.3 6.5 7.6 6.7 10.1 2.1 Your team built a disease predictor such that when the expression of the protein is higher than 5.5, the predictor claims that the individual has the disease. You now want to evaluate out of the disease predictions made by the predictor if the actual number of disease individuals predicted is obtained by chance. Compute the p-value according to the correct statistical test seen in class and assume that a p-value < 0.05 significantly   differs from what should be obtained by chance. Show your calculations. I was given the standard answer that $$ p-value = 1 - \sum_{i=0}^7 \frac {\binom {10} i \binom {20-10}{i}} {\binom {20} {10}} $$ which is using the hypergeometric distribution. I know what is a $p-value$, but what is hypothesis we are testing with this $p-value$? For me it seems that the formula is calculating if we pick 10 people from the 20 samples, what's the probability that we get more than 7 normal people.  But this probability doesn't seem to have any connection with predictor.  I'm confused...",,"['probability', 'statistics']"
52,Likelihood ratio interpretation,Likelihood ratio interpretation,,"I have $X_1, \ldots, X_n$ and $Y_1, \ldots, Y_n$ as as random samples from two normal distributions with means $0$ and variances $\theta_1$ and $\theta_2$ respectively.The null hypothesis is $\theta_1 = \theta_2$ and the alternative is $\theta_1$ not equal to $\theta_2$ I calculated the likelihood ratio (which is shown below) and now I am trying to figure out what this likelihood ratio is a function of. I believe it is a function of $F$ but I am unsure how to show that it is $F$-distributed with $v_1 = n$, and $v_2 = m$. Thanks for the help. $$ \lambda={    {   \left\{ {\textstyle 1\over\textstyle  2\pi\bigl[\,(\,\sum x_i^2+\sum y_i^2\,)/(n+m)\, \bigr]} \right\}^{n+m\over2} } \over \biggl[{    {\textstyle1\over\textstyle 2\pi(\sum x_i^2 /n)}      }\biggl]^{n/2} \biggl[{    {\textstyle1\over\textstyle 2\pi(\sum y_i^2 /m)}      }\biggl]^{m/2} } $$","I have $X_1, \ldots, X_n$ and $Y_1, \ldots, Y_n$ as as random samples from two normal distributions with means $0$ and variances $\theta_1$ and $\theta_2$ respectively.The null hypothesis is $\theta_1 = \theta_2$ and the alternative is $\theta_1$ not equal to $\theta_2$ I calculated the likelihood ratio (which is shown below) and now I am trying to figure out what this likelihood ratio is a function of. I believe it is a function of $F$ but I am unsure how to show that it is $F$-distributed with $v_1 = n$, and $v_2 = m$. Thanks for the help. $$ \lambda={    {   \left\{ {\textstyle 1\over\textstyle  2\pi\bigl[\,(\,\sum x_i^2+\sum y_i^2\,)/(n+m)\, \bigr]} \right\}^{n+m\over2} } \over \biggl[{    {\textstyle1\over\textstyle 2\pi(\sum x_i^2 /n)}      }\biggl]^{n/2} \biggl[{    {\textstyle1\over\textstyle 2\pi(\sum y_i^2 /m)}      }\biggl]^{m/2} } $$",,"['probability', 'statistics']"
53,What are some of the disadvantages of working with log likelihood function instead of likelihood function?,What are some of the disadvantages of working with log likelihood function instead of likelihood function?,,"As the title suggested, I want to know why people often use log likelihood function, instead of likelihood function by itself. What I know, is that, if $\hat{\theta}$ is the maximum of a likelihood function $f(\theta; \mathbf{x})$, then it is also the maximum of $g(\theta) := \log (f(\theta; \mathbf{x}))$. Are there some other reasons why we are interested in $g$ instead of $f$?","As the title suggested, I want to know why people often use log likelihood function, instead of likelihood function by itself. What I know, is that, if $\hat{\theta}$ is the maximum of a likelihood function $f(\theta; \mathbf{x})$, then it is also the maximum of $g(\theta) := \log (f(\theta; \mathbf{x}))$. Are there some other reasons why we are interested in $g$ instead of $f$?",,['statistics']
54,A proof about random variables,A proof about random variables,,How to prove that given a random variable $X$ deﬁned on a sample space $W$ and $Y = X^2$ is also a random variable defined on the sample space $W$. I tried to use some definitions of random variables but I am not familiar with mapping. Can someone explain how to construct a formal proof?,How to prove that given a random variable $X$ deﬁned on a sample space $W$ and $Y = X^2$ is also a random variable defined on the sample space $W$. I tried to use some definitions of random variables but I am not familiar with mapping. Can someone explain how to construct a formal proof?,,"['probability', 'statistics']"
55,"Need to express curves as a set of gaussians, and compare two of these sets","Need to express curves as a set of gaussians, and compare two of these sets",,"I have two xy curves, defined numerically on a given (potentially different) range of x coordinates. What I need to do is to compare these two curves with the following strategy: express each curve as a sum of unknown gaussian functions, to be determined. compare the two sets of gaussians. obtain a similarity score ranging from 0% (absolutely no similarity) to 100 % (they are the same). I am not looking for exceedingly fancy algorithms for these tasks, but any hint and keywords to search for will certainly be welcome.","I have two xy curves, defined numerically on a given (potentially different) range of x coordinates. What I need to do is to compare these two curves with the following strategy: express each curve as a sum of unknown gaussian functions, to be determined. compare the two sets of gaussians. obtain a similarity score ranging from 0% (absolutely no similarity) to 100 % (they are the same). I am not looking for exceedingly fancy algorithms for these tasks, but any hint and keywords to search for will certainly be welcome.",,"['statistics', 'computer-science']"
56,Drawing samples from an LP program,Drawing samples from an LP program,,"Say I have an LP program in standard form: \begin{equation*} \begin{array}{rl}     \mathbf{x}^* = \underset{\mathbf{x}}{\text{arg}\;\text{min}}        & \mathbf{c}^T\mathbf{x} \\     \mbox{s.t.} & \mathbf{A}\mathbf{x} = \mathbf{b} \\                 & \mathbf{x} \ge 0.     \end{array} \end{equation*} Say that the $\mathbf{c}$ follows a normal distribution $N \left(\mathbf{\mu}, \mathbf{\sigma} \right)$, and that I draw multiple samples from it. What distribution would the corresponding $\mathbf{x}^*$ realizations follow? How could I proceed to analytically describe $P\left(\mathbf{x}^*\right | \mathbf{c})$ as a function of $\mu$ and $\sigma$? Finally, and more generally, is there a topic in the literature that studies this sampling problem? (maybe in the context of optimization in general) Perhaps there are known relationships between this sampling problem and Sensitivity Analysis of LP solutions?","Say I have an LP program in standard form: \begin{equation*} \begin{array}{rl}     \mathbf{x}^* = \underset{\mathbf{x}}{\text{arg}\;\text{min}}        & \mathbf{c}^T\mathbf{x} \\     \mbox{s.t.} & \mathbf{A}\mathbf{x} = \mathbf{b} \\                 & \mathbf{x} \ge 0.     \end{array} \end{equation*} Say that the $\mathbf{c}$ follows a normal distribution $N \left(\mathbf{\mu}, \mathbf{\sigma} \right)$, and that I draw multiple samples from it. What distribution would the corresponding $\mathbf{x}^*$ realizations follow? How could I proceed to analytically describe $P\left(\mathbf{x}^*\right | \mathbf{c})$ as a function of $\mu$ and $\sigma$? Finally, and more generally, is there a topic in the literature that studies this sampling problem? (maybe in the context of optimization in general) Perhaps there are known relationships between this sampling problem and Sensitivity Analysis of LP solutions?",,"['statistics', 'optimization', 'linear-programming']"
57,Normalizing a conditional probability to within range of a Sigmoid function,Normalizing a conditional probability to within range of a Sigmoid function,,"Given the following scenario from another post of mine where we are building a matrix that expresses the probability of first order transitions from one character to another in an english text. We take a book, and count the number of times the letter 'e' occurs in that book -- say 15,000.  Then we count the number of times the next letter is 'f' -- say, 200.  With this in hand, we put $M(\text{'e'}, \text{'f'}) = 200/15000 = 1.33\%$. Say instead we want to normalize this conditional probability to a range between 0 - 1, but discluding the absolute values 0 or 1 (only getting infinitesimely close to each extreme). Is there an accepted way to use a sigmoid function for this sort of normalization of a probability? I don't know if this is a common practice, however, I think it would be useful in an AI application I am working on.","Given the following scenario from another post of mine where we are building a matrix that expresses the probability of first order transitions from one character to another in an english text. We take a book, and count the number of times the letter 'e' occurs in that book -- say 15,000.  Then we count the number of times the next letter is 'f' -- say, 200.  With this in hand, we put $M(\text{'e'}, \text{'f'}) = 200/15000 = 1.33\%$. Say instead we want to normalize this conditional probability to a range between 0 - 1, but discluding the absolute values 0 or 1 (only getting infinitesimely close to each extreme). Is there an accepted way to use a sigmoid function for this sort of normalization of a probability? I don't know if this is a common practice, however, I think it would be useful in an AI application I am working on.",,"['linear-algebra', 'probability', 'matrices', 'statistics']"
58,Interpret density plot,Interpret density plot,,"I'm trying to understand this density plot.  The X axis is the time between requests.  What is the probability of the purple data source having a time between request of 500?  What is the probability of the purple data source having a time between requests of 250 - 500? Also, where's a good source to explain how to interpret a density plot? https://i.sstatic.net/Usre8.png","I'm trying to understand this density plot.  The X axis is the time between requests.  What is the probability of the purple data source having a time between request of 500?  What is the probability of the purple data source having a time between requests of 250 - 500? Also, where's a good source to explain how to interpret a density plot? https://i.sstatic.net/Usre8.png",,"['probability', 'statistics']"
59,Base-rate fallacy?,Base-rate fallacy?,,"I tried to make a counterexample that splitting data into sets can lead to the wrong conclusion and it seems to me to generate a fallacy just by splitting data into subsets. What I did was making up sequences that can mean observation i.e. the sequence 0,1 means ""not A and then B (A=0, B=1)"" and the sequence 1,1 means ""A occured and then B occured"" and likewise common truth values . Then I arranged 40 + 40 of these values, looked at the first forty ""base-rates"" and could conclude that there wasn't a base-rate that strengthened that A would imply B, there were too many other occurences of ""not A and then B"" in the first subset. In the second subset the conclusion was the same: Looking at the base-rates of sequences implied that A doesn't cause B according to the numbers of the sequences. And when the whole population of sequences, instead of two samples, are examined then there is support for the conclusion ""A causes B"" according to base-rates. Which fallacy is this if any? If you like to know the actual example I have it written down somewhere and I apologize if this questions is obviously mistaken about some assumption (it wasn't Granger-test about cause /effect, I only looked at base-rates to make an example that even though all observations are considered, the opposite conclusion is made compared to looking at all the data in a population from a fallacy that a conclusion about subset A + a consludion about subset B is correct even though we examined all observation.) Do you agree that the result is somewhat strange and a fallacy? An interpretation could be that A means ""it's cloudy"" and B means ""it rains"" and I'm trying to conclude whether cloudiness is an accurate predictor for rain and I found that putting together conclusions from samples doesn't make the same conclusion as looking at the whole population.","I tried to make a counterexample that splitting data into sets can lead to the wrong conclusion and it seems to me to generate a fallacy just by splitting data into subsets. What I did was making up sequences that can mean observation i.e. the sequence 0,1 means ""not A and then B (A=0, B=1)"" and the sequence 1,1 means ""A occured and then B occured"" and likewise common truth values . Then I arranged 40 + 40 of these values, looked at the first forty ""base-rates"" and could conclude that there wasn't a base-rate that strengthened that A would imply B, there were too many other occurences of ""not A and then B"" in the first subset. In the second subset the conclusion was the same: Looking at the base-rates of sequences implied that A doesn't cause B according to the numbers of the sequences. And when the whole population of sequences, instead of two samples, are examined then there is support for the conclusion ""A causes B"" according to base-rates. Which fallacy is this if any? If you like to know the actual example I have it written down somewhere and I apologize if this questions is obviously mistaken about some assumption (it wasn't Granger-test about cause /effect, I only looked at base-rates to make an example that even though all observations are considered, the opposite conclusion is made compared to looking at all the data in a population from a fallacy that a conclusion about subset A + a consludion about subset B is correct even though we examined all observation.) Do you agree that the result is somewhat strange and a fallacy? An interpretation could be that A means ""it's cloudy"" and B means ""it rains"" and I'm trying to conclude whether cloudiness is an accurate predictor for rain and I found that putting together conclusions from samples doesn't make the same conclusion as looking at the whole population.",,"['probability', 'statistics']"
60,Calculating the Similarity of n-dimensional Vectors,Calculating the Similarity of n-dimensional Vectors,,"What's doing guys? I was going to post this on MathOverflow initially, but got scared off by their FAQ, haha. Apologies in advance if I butcher any of the terminology; I majored in math in undergrad but a lot of that knowledge left me like water through a sieve. So, what I've been playing with are similarity calculations for n-dimensional vectors. Specifically, cosine similarity. What I start out with are multiple arrays/matrices/sets. For example: SetN = { red, white, blue }  Set1 = { 30, 25, 25 } Set2 = { 20, 18, 6 } Where the individual elements represent frequency, e.g. for Set1, there were 30 instances of red, 25 instances of white, and 25 instances of blue, and so on. The examples above are simplified, and the actual sets I'm working with have exponential distributions and other complications. This necessitates other questions which I will save for StackExchange. At the moment though, what I want to figure out is if I am calculating the cosine similarity correctly because with certain sets, I get answers that look plain wrong. SetX = { 20, 0, 0 } SetY = { 20, 20, 20 }  Norm = |( red, white, blue )| = sqrt( red^2 + white^2 + blue^2 ) Then I use the norm to convert the sets to unit vectors by dividing each element in the set: uvX = { 1, 0, 0 } uvY = { 1/sqrt(3), 1/sqrt(3), 1/sqrt(3) } Then, I find the dot product to calculate the cosine similarity, and I get 1/sqrt(3). Which comes out to: 57.7%. The thing is, even taking into account that I normalized the vectors to unit vectors, 20 units of red in Set X does not seem like 57.7% of Set Y with 20 red, 20 white, and 20 blue. It seems like the similarity figure is a bit too large. Are my calculations botched? Or is there some kind of mental illusion I'm failing to see here.","What's doing guys? I was going to post this on MathOverflow initially, but got scared off by their FAQ, haha. Apologies in advance if I butcher any of the terminology; I majored in math in undergrad but a lot of that knowledge left me like water through a sieve. So, what I've been playing with are similarity calculations for n-dimensional vectors. Specifically, cosine similarity. What I start out with are multiple arrays/matrices/sets. For example: SetN = { red, white, blue }  Set1 = { 30, 25, 25 } Set2 = { 20, 18, 6 } Where the individual elements represent frequency, e.g. for Set1, there were 30 instances of red, 25 instances of white, and 25 instances of blue, and so on. The examples above are simplified, and the actual sets I'm working with have exponential distributions and other complications. This necessitates other questions which I will save for StackExchange. At the moment though, what I want to figure out is if I am calculating the cosine similarity correctly because with certain sets, I get answers that look plain wrong. SetX = { 20, 0, 0 } SetY = { 20, 20, 20 }  Norm = |( red, white, blue )| = sqrt( red^2 + white^2 + blue^2 ) Then I use the norm to convert the sets to unit vectors by dividing each element in the set: uvX = { 1, 0, 0 } uvY = { 1/sqrt(3), 1/sqrt(3), 1/sqrt(3) } Then, I find the dot product to calculate the cosine similarity, and I get 1/sqrt(3). Which comes out to: 57.7%. The thing is, even taking into account that I normalized the vectors to unit vectors, 20 units of red in Set X does not seem like 57.7% of Set Y with 20 red, 20 white, and 20 blue. It seems like the similarity figure is a bit too large. Are my calculations botched? Or is there some kind of mental illusion I'm failing to see here.",,['matrices']
61,a question about Erlang/chi square distribution,a question about Erlang/chi square distribution,,"Suppose you have $$ Y = X^2+Y^2  $$ where $X$ and $Y$ are both Gaussian with zero mean and variance $\sigma^2/2$ (you can think of $y$ as the square norm of $Z = X + jY$). The pdf should be Erlang , but I'm not sure about the values of $\lambda$ and $k$.","Suppose you have $$ Y = X^2+Y^2  $$ where $X$ and $Y$ are both Gaussian with zero mean and variance $\sigma^2/2$ (you can think of $y$ as the square norm of $Z = X + jY$). The pdf should be Erlang , but I'm not sure about the values of $\lambda$ and $k$.",,"['statistics', 'probability-distributions']"
62,Nt+1 = λNt ⇔ ΔNt to t+1 = RNt,Nt+1 = λNt ⇔ ΔNt to t+1 = RNt,,"I'm struggling in my subject that has a component of maths in it, please help. I need to make $N_{t+1} = \lambda Nt$ become $\Delta N_{t\ \text{to}\ t+1} = RN_t$ showing working. $N_{t+1}$ is the population size at time $t+1$. $N_t$ is the population size at $t$. $\lambda$ is a constant factor by which the population increases per time unit. Thank you.","I'm struggling in my subject that has a component of maths in it, please help. I need to make $N_{t+1} = \lambda Nt$ become $\Delta N_{t\ \text{to}\ t+1} = RN_t$ showing working. $N_{t+1}$ is the population size at time $t+1$. $N_t$ is the population size at $t$. $\lambda$ is a constant factor by which the population increases per time unit. Thank you.",,['statistics']
63,Statistics question to apply bell curve to formula,Statistics question to apply bell curve to formula,,"I am trying to write a formula that would give a person a score, based on a formula. It's for a video game, and I have worked up a formula using aggregate stats like total kills divided by total deaths, win percentage, etc. They are all ratios. I also would like to multiply this by the number of games that they have played, but I am finding this dramatically effects the score when people have massive amounts of games. How would I normalize this over my population? For instance: Score = (Kills / Deaths) * (Wins / Games) * ( Games ) Is there anyway to give people credit for doing well over many games? I have people with 5000 games that have a massive score, even though the stats used in the rest of the formula are very bad.  I don't want to do 5000 / 2 or 5000 / .1 because the problem persists. I'd like to somehow apply a normal distribution Thanks","I am trying to write a formula that would give a person a score, based on a formula. It's for a video game, and I have worked up a formula using aggregate stats like total kills divided by total deaths, win percentage, etc. They are all ratios. I also would like to multiply this by the number of games that they have played, but I am finding this dramatically effects the score when people have massive amounts of games. How would I normalize this over my population? For instance: Score = (Kills / Deaths) * (Wins / Games) * ( Games ) Is there anyway to give people credit for doing well over many games? I have people with 5000 games that have a massive score, even though the stats used in the rest of the formula are very bad.  I don't want to do 5000 / 2 or 5000 / .1 because the problem persists. I'd like to somehow apply a normal distribution Thanks",,['statistics']
64,GLR test of hypothesis for exponential distributions,GLR test of hypothesis for exponential distributions,,"I'm having trouble with this exercise from Bain and Engelhardt's textbook: Consider independent random samples of size $n_1$ and $n_2$ from respective exponential distributions $X_i \sim EXP(\theta_1)$ and $Y_i \sim EXP(\theta_2)$. Derive the Generalize Likelihood Ratio test of $H_0:\theta_1=\theta_2$ versus $H_1:\theta_1\neq\theta_2$. The Generalized Likelihood Ratio is defined by $\lambda(\vec{x})=\frac{\max_{\theta\in\Omega_0}f(\vec{x};\vec{\theta})}{\max_{\theta\in\Omega}f(\vec{x};\vec{\theta})}=\frac{f(\vec{x};\hat{\vec{\theta}_0})}{f(\vec{x};\hat{\vec{\theta}})}$, where $\hat{\vec{\theta}}$ denotes the usual Maximum Likelihood Estimator of $\vec{\theta}$ and $\hat{\vec{\theta_0}}$ denotes the MLE under the restriction that $H_0$ is true. One is then supposed to apply the Neyman-Pearson lemma. I've thought about this exercise for some time now, unsuccesfully. Thank you for any help given.","I'm having trouble with this exercise from Bain and Engelhardt's textbook: Consider independent random samples of size $n_1$ and $n_2$ from respective exponential distributions $X_i \sim EXP(\theta_1)$ and $Y_i \sim EXP(\theta_2)$. Derive the Generalize Likelihood Ratio test of $H_0:\theta_1=\theta_2$ versus $H_1:\theta_1\neq\theta_2$. The Generalized Likelihood Ratio is defined by $\lambda(\vec{x})=\frac{\max_{\theta\in\Omega_0}f(\vec{x};\vec{\theta})}{\max_{\theta\in\Omega}f(\vec{x};\vec{\theta})}=\frac{f(\vec{x};\hat{\vec{\theta}_0})}{f(\vec{x};\hat{\vec{\theta}})}$, where $\hat{\vec{\theta}}$ denotes the usual Maximum Likelihood Estimator of $\vec{\theta}$ and $\hat{\vec{\theta_0}}$ denotes the MLE under the restriction that $H_0$ is true. One is then supposed to apply the Neyman-Pearson lemma. I've thought about this exercise for some time now, unsuccesfully. Thank you for any help given.",,['statistics']
65,Formula to generate a score from 1 to 100 based on 2 percentages?,Formula to generate a score from 1 to 100 based on 2 percentages?,,"I am trying to come up with a formula that will result in a score of 1 to 100 (never anything lower or higher). I have two numbers that I can use to come up with this score, a specific percent and an average percent (from all of the others in the set). The score would essentially not be able to reach the upper or lower bounds, just get infinitely closer. The idea would be to assign a score of 50 if the specific percent matched the average percent, and scale from there. I know I've done something like this in the past, but I've been racking my brain off and on all day and haven't been able to come up with anything. Any ideas? Edit: I forgot to mention the most important part. The percentages will for the most part be between 0.01% and 2.0%. So the average could be something like 0.42%, etc.","I am trying to come up with a formula that will result in a score of 1 to 100 (never anything lower or higher). I have two numbers that I can use to come up with this score, a specific percent and an average percent (from all of the others in the set). The score would essentially not be able to reach the upper or lower bounds, just get infinitely closer. The idea would be to assign a score of 50 if the specific percent matched the average percent, and scale from there. I know I've done something like this in the past, but I've been racking my brain off and on all day and haven't been able to come up with anything. Any ideas? Edit: I forgot to mention the most important part. The percentages will for the most part be between 0.01% and 2.0%. So the average could be something like 0.42%, etc.",,"['probability', 'analysis', 'statistics', 'algorithms']"
66,Density Question - Statistics,Density Question - Statistics,,"A point is picked randomly in space. Its three coordinates $X$, $Y$, and $Z$ are independent standard normal variables. Let $R = \sqrt{X^2+Y^2+Z^2}$ be the distance from the point from the origin. Find: a) The density of $R^2$ (don't get how to set up the integral for this) b) The density of $R$ (don't get part a) c) $E(R)$ d) $\textrm{Var}(R)$ I don't get how to use the change of variables since we are dealing with $X$, $Y$ and a $Z$. Can you please explain how I can do this? Also, can it be done using spherical coordinates? I am lost on the coordinates available for us on this problem.","A point is picked randomly in space. Its three coordinates $X$, $Y$, and $Z$ are independent standard normal variables. Let $R = \sqrt{X^2+Y^2+Z^2}$ be the distance from the point from the origin. Find: a) The density of $R^2$ (don't get how to set up the integral for this) b) The density of $R$ (don't get part a) c) $E(R)$ d) $\textrm{Var}(R)$ I don't get how to use the change of variables since we are dealing with $X$, $Y$ and a $Z$. Can you please explain how I can do this? Also, can it be done using spherical coordinates? I am lost on the coordinates available for us on this problem.",,['statistics']
67,"Uniform $(-1,1)$ distribution",Uniform  distribution,"(-1,1)","Let $X$ and $Y$ be independent with uniform $(-1,1)$ distribution. Please help in finding: a) $P(X^2+Y^2 \leq r^2)$ b) The CDF of $R^2 = X^2 + Y^2$ c) The density of $R^2$ All I tried was breaking it down into cases, for part a we have 2 cases, where the circle is inscribed in the square and vice versa. I need help espcecially with part b, then I can try c. Can someone please explain?","Let $X$ and $Y$ be independent with uniform $(-1,1)$ distribution. Please help in finding: a) $P(X^2+Y^2 \leq r^2)$ b) The CDF of $R^2 = X^2 + Y^2$ c) The density of $R^2$ All I tried was breaking it down into cases, for part a we have 2 cases, where the circle is inscribed in the square and vice versa. I need help espcecially with part b, then I can try c. Can someone please explain?",,['statistics']
68,Determining the distribution of a population from a sample,Determining the distribution of a population from a sample,,I have a uniformly collected sample of 10000 data points from a population of about 200000. I'd like to find out what the distribution of the population is. How can I do this rigourously?,I have a uniformly collected sample of 10000 data points from a population of about 200000. I'd like to find out what the distribution of the population is. How can I do this rigourously?,,['statistics']
69,How to compare randomness of two sets of data?,How to compare randomness of two sets of data?,,"Given two sets of random numbers, is it possible to say that one set of random numbers has a greater degree of randomness when compared to the other? Or one set of numbers is more random when compared to the other? EDIT: Consider this situation: A hacker needs to know the target address where a heap/library/base of the executable is located. Once he knows the address he can take advantage of it and compromise the system. Previously, the location was fixed across all computers and so it was easy for the hackers to hack the computer. There are two software S1 and S2. S1 generates a random number where the heap/library/base of the executable is located. So now, it is difficult for the hacker to predict the location. Between S1 and S2, both of which have random number generators, which one is better? Can we compare based on the random numbers generated by each software?","Given two sets of random numbers, is it possible to say that one set of random numbers has a greater degree of randomness when compared to the other? Or one set of numbers is more random when compared to the other? EDIT: Consider this situation: A hacker needs to know the target address where a heap/library/base of the executable is located. Once he knows the address he can take advantage of it and compromise the system. Previously, the location was fixed across all computers and so it was easy for the hackers to hack the computer. There are two software S1 and S2. S1 generates a random number where the heap/library/base of the executable is located. So now, it is difficult for the hacker to predict the location. Between S1 and S2, both of which have random number generators, which one is better? Can we compare based on the random numbers generated by each software?",,"['statistics', 'random']"
70,"Chebyshev's inequality, variance and mean","Chebyshev's inequality, variance and mean",,"I am trying to implement a solution (working code) for the 4.1 paragraph in this paper . The problem: We have words with lengths for instance:  $l_1$ = 1, $l_2$ = 2, $l_3$ = 3, $l_4$ = 8 and $l_5$ = 7. These words will be part of the white-list. We calculate the sample mean and the variance of the lengths of these words. $\mu = \frac{1}{N}\sum_{i = 1}^N X_i$ So, $\mu = 4.2$ in our case. Next step is to calculate the variance. $\sigma^2 = \frac{1}{N}\sum_{i = 1}^N (X_i - \mu)^2$ So, $\sigma^2 = 7.76$ After all calculations are done we get another list of words and the goal of the algorithm is to assess the anomaly of a string with length l , by calculating the ''distance'' of the length l from the mean $\mu$ of value l of the length distribution. This distance is expressed with the help of the Chebyshev inequality. $p(\mid x-\mu \mid > t) < \frac{\mu^2}{t^2}$ When l is far away from $\mu$, considering the variance of the length distribution, then the probability of any (legitimate) string x having a greater length than l should be small.  Thus, to obtain a quantitative measure of the distance between a string of length l and the mean $\mu$ of the length distribution, we substitute t with the difference between $\mu$ and l . $p(\mid x-\mu \mid > \mid l-\mu \mid) < p(l)=\frac{\sigma^2}{(l-\mu)^2}$ Having the information above, if I run it with the next numbers: 1, 5, 10. I get these probabilities: p(1) =0.757 p(5) =12.125 p(10) =0.230 Which I don't understand why some probabilities I get are bigger than 1, they are not supposed to be bigger than 1. I am trying to understand if the formulas described above are correct or maybe I am using them wrong. Thank you.","I am trying to implement a solution (working code) for the 4.1 paragraph in this paper . The problem: We have words with lengths for instance:  $l_1$ = 1, $l_2$ = 2, $l_3$ = 3, $l_4$ = 8 and $l_5$ = 7. These words will be part of the white-list. We calculate the sample mean and the variance of the lengths of these words. $\mu = \frac{1}{N}\sum_{i = 1}^N X_i$ So, $\mu = 4.2$ in our case. Next step is to calculate the variance. $\sigma^2 = \frac{1}{N}\sum_{i = 1}^N (X_i - \mu)^2$ So, $\sigma^2 = 7.76$ After all calculations are done we get another list of words and the goal of the algorithm is to assess the anomaly of a string with length l , by calculating the ''distance'' of the length l from the mean $\mu$ of value l of the length distribution. This distance is expressed with the help of the Chebyshev inequality. $p(\mid x-\mu \mid > t) < \frac{\mu^2}{t^2}$ When l is far away from $\mu$, considering the variance of the length distribution, then the probability of any (legitimate) string x having a greater length than l should be small.  Thus, to obtain a quantitative measure of the distance between a string of length l and the mean $\mu$ of the length distribution, we substitute t with the difference between $\mu$ and l . $p(\mid x-\mu \mid > \mid l-\mu \mid) < p(l)=\frac{\sigma^2}{(l-\mu)^2}$ Having the information above, if I run it with the next numbers: 1, 5, 10. I get these probabilities: p(1) =0.757 p(5) =12.125 p(10) =0.230 Which I don't understand why some probabilities I get are bigger than 1, they are not supposed to be bigger than 1. I am trying to understand if the formulas described above are correct or maybe I am using them wrong. Thank you.",,"['calculus', 'statistics']"
71,File Size Stats,File Size Stats,,"This is kind of a programming question, but really it's math in disguise! I'm working on a little project that will look at the size of a file and make sure it's in within an acceptable range based on previous file sizes. I know how to get the average file size of previous files and all that. I'm wondering if there is an equation or a method that I can dynamically create an acceptable range depending on avg file size, number of files, or some other statistical value. I can provide more details if needed, but I really don't know where to start.","This is kind of a programming question, but really it's math in disguise! I'm working on a little project that will look at the size of a file and make sure it's in within an acceptable range based on previous file sizes. I know how to get the average file size of previous files and all that. I'm wondering if there is an equation or a method that I can dynamically create an acceptable range depending on avg file size, number of files, or some other statistical value. I can provide more details if needed, but I really don't know where to start.",,"['analysis', 'statistics']"
72,How to estimate failure probability from count until first failure?,How to estimate failure probability from count until first failure?,,"What would be the formula to estimate the rate of failure of some test as a percentage chance of failure from the number of runs of the test until the first failure was seen? For example, considering 0 to mean failure and 1 to mean success, the following are possible samples from which each should have an estimated failure rate: 0 (failed on first try, I would estimate failure rate to be 100%) 11110 (failed on fifth try, so answer is something less than around 20% failure rate) 1111111110 (failed on tenth try, so answer is something less than around 10% failure rate) Working the other way around, imagine the answer was a 10% failure rate. On average, what test will the first failure be seen at?  Perhaps it is $(9/10)^n$ < 5/10?  What value of n do we reach a 50% chance of failure? Five tries is 59% chance of success, six tries 53%, and seven tries is 48%. Therefore, on average I think we will fail most likely on the seventh trial.  So what would be formula to work backwards from 7 to get ~10%? So what would the answer be? (1 minus the nth root of .5) where n is the first trial to fail","What would be the formula to estimate the rate of failure of some test as a percentage chance of failure from the number of runs of the test until the first failure was seen? For example, considering 0 to mean failure and 1 to mean success, the following are possible samples from which each should have an estimated failure rate: 0 (failed on first try, I would estimate failure rate to be 100%) 11110 (failed on fifth try, so answer is something less than around 20% failure rate) 1111111110 (failed on tenth try, so answer is something less than around 10% failure rate) Working the other way around, imagine the answer was a 10% failure rate. On average, what test will the first failure be seen at?  Perhaps it is $(9/10)^n$ < 5/10?  What value of n do we reach a 50% chance of failure? Five tries is 59% chance of success, six tries 53%, and seven tries is 48%. Therefore, on average I think we will fail most likely on the seventh trial.  So what would be formula to work backwards from 7 to get ~10%? So what would the answer be? (1 minus the nth root of .5) where n is the first trial to fail",,"['probability', 'statistics', 'parameter-estimation']"
73,Mean of interpolated data or interpolation of means in geostatistics,Mean of interpolated data or interpolation of means in geostatistics,,"Say I have a time series, with actual measurements of a variable $a$ in different locations.  If I want to know the average of $p$ from time $t_1$ to $t_n$, I could say that $\overline{a_{p}}=\frac{\sum\limits_{t=1}^n a_{{p}_t}}{n}$, where $p$ is the coordinate of the point of measurement.  So far, so good.  Let's generalize and call this averaging function $m_p=f(a_p,t)$, where $f(a,t)$ is some deterministic function and $m$ is its result. Now, say I want to calculate $m$ for a location $o$, where $o$ is a points for which I don't have actual measurements and $a_o$ was estimated through a an interpolating function $g(a,o)$.  My intuition tells me that in this case, we should first estimate every $a_{o_t}$ before applying $f(a,t)$. In other words, considering that $a_o = g(a,o)$, we get $m_o$ by doing: $m_o=f[g(a,o),t]=f(a_o,t)$ But I have seen so many papers that do the other way around.  They first calculate $f(a,t)$ for every known $a$ and then interpolate the results using the same g() even though there is no guarantee that $m$ behaves like $a$, or: $m_o=g[f(a,t),o]=g(m,o)$ In some cases, they use the same logic when instead of $t$, there is some other variable $b$, i.e., it's not a time series, but $f(a,b)$ is a deterministic function. Are the models in those papers conceptually wrong?  If they are wrong, is there a techcnical term to call this kind of mistake?","Say I have a time series, with actual measurements of a variable $a$ in different locations.  If I want to know the average of $p$ from time $t_1$ to $t_n$, I could say that $\overline{a_{p}}=\frac{\sum\limits_{t=1}^n a_{{p}_t}}{n}$, where $p$ is the coordinate of the point of measurement.  So far, so good.  Let's generalize and call this averaging function $m_p=f(a_p,t)$, where $f(a,t)$ is some deterministic function and $m$ is its result. Now, say I want to calculate $m$ for a location $o$, where $o$ is a points for which I don't have actual measurements and $a_o$ was estimated through a an interpolating function $g(a,o)$.  My intuition tells me that in this case, we should first estimate every $a_{o_t}$ before applying $f(a,t)$. In other words, considering that $a_o = g(a,o)$, we get $m_o$ by doing: $m_o=f[g(a,o),t]=f(a_o,t)$ But I have seen so many papers that do the other way around.  They first calculate $f(a,t)$ for every known $a$ and then interpolate the results using the same g() even though there is no guarantee that $m$ behaves like $a$, or: $m_o=g[f(a,t),o]=g(m,o)$ In some cases, they use the same logic when instead of $t$, there is some other variable $b$, i.e., it's not a time series, but $f(a,b)$ is a deterministic function. Are the models in those papers conceptually wrong?  If they are wrong, is there a techcnical term to call this kind of mistake?",,['statistics']
74,How to calculate likelihood to succeed knowing attempts and successful attempts amounts?,How to calculate likelihood to succeed knowing attempts and successful attempts amounts?,,"Say I have two algorithms that I don't know how they work but I know what they are meant to achieve. I tried algorithm A once and it succeeded. And tried algorithm B 100 times and succeeded 99 times. So A succeeded 100% times and B succeeded 99% times, but my common sense tells me B is still more ""reliable"" than A. How can I express this mathematically, or, how can I calculate which algorithm should I choose if I have to choose one when all I know about each of them is how many times it has been tested and how many times it succeeded (if it didn't that just means it failed for what I need)? Please be as simple as possible I'm a newbie at math.","Say I have two algorithms that I don't know how they work but I know what they are meant to achieve. I tried algorithm A once and it succeeded. And tried algorithm B 100 times and succeeded 99 times. So A succeeded 100% times and B succeeded 99% times, but my common sense tells me B is still more ""reliable"" than A. How can I express this mathematically, or, how can I calculate which algorithm should I choose if I have to choose one when all I know about each of them is how many times it has been tested and how many times it succeeded (if it didn't that just means it failed for what I need)? Please be as simple as possible I'm a newbie at math.",,"['probability', 'statistics', 'probability-theory']"
75,How to calculate correlation between poll statistics and one's answers?,How to calculate correlation between poll statistics and one's answers?,,"I have statistics of $100$ questions which can be answered either ""yes"" or ""no"": 1) $63.3 - 36.7$ ($63.3\%$ respondents answered ""yes"" and $36.7\%$ answered ""no"") 2) $30.1 - 69.9$ ... 100) $88.0 - 12.0$ That $100$ answers would be our sample. Then I ask the same $100$ questions to $101^{st}$ respondent and get new set of answers: 1) yes 2) yes ... 100) no What I need to do is some how calculate ""correlation"" value between this respondent and overall sample. Any method will be OK, I just need to get some number. Therefore there may be different ""right"" answers. Thanks in advance.","I have statistics of $100$ questions which can be answered either ""yes"" or ""no"": 1) $63.3 - 36.7$ ($63.3\%$ respondents answered ""yes"" and $36.7\%$ answered ""no"") 2) $30.1 - 69.9$ ... 100) $88.0 - 12.0$ That $100$ answers would be our sample. Then I ask the same $100$ questions to $101^{st}$ respondent and get new set of answers: 1) yes 2) yes ... 100) no What I need to do is some how calculate ""correlation"" value between this respondent and overall sample. Any method will be OK, I just need to get some number. Therefore there may be different ""right"" answers. Thanks in advance.",,['statistics']
76,Probability of coin flip given forecasts,Probability of coin flip given forecasts,,"Suppose you have a coin that flips $H$ or $T$ with some unknown probability. You also have access to two devices, $A$ and $B$ , where $A$ correctly predicts the outcome of the coin with $p = 0.7$ and $B$ with $p = 0.6$ . What is the probability $A's$ forecast is correct given $B$ agrees? How about when $B$ disagrees? I'm curious how we would go about using these tools. How can we compute the conditional probability of the outcome given that $A$ and $B$ agree vs disagree. Intuitively, it does not seem possible for $A$ and $B$ to be independent of each other. How could we go about computing their covariance if this is the case. If they were to be independent, I would say that the probability of agreement $= 0.7 \cdot 0.6 + 0.3 \cdot 0.4 = 0.54$ So 54% of the time you could have some level of confidence in your prediction. I wonder if we can say this though and am trying to tie in concepts of conditional probability and correlation. If we blindly followed tool $A$ we could correctly predict for $70%$ of the coin flips. Can we use $B$ in any way to increase that portion? To me it seems like we can not as that would involve going against $A$ at some points which seems suboptimal. EDIT: After thinking about it, I believe A and B can have independent predictions. Let's assume they are if that's true. (however I'm curious of what would change if we increased correlation. I'm assuming it is not possible for correlation to be 1 as they must be different at some points to have differing proportions. What is max correlation in that case? My intuition tells me the higher the correlation, the less you'd consider the forecast with worse probability.)","Suppose you have a coin that flips or with some unknown probability. You also have access to two devices, and , where correctly predicts the outcome of the coin with and with . What is the probability forecast is correct given agrees? How about when disagrees? I'm curious how we would go about using these tools. How can we compute the conditional probability of the outcome given that and agree vs disagree. Intuitively, it does not seem possible for and to be independent of each other. How could we go about computing their covariance if this is the case. If they were to be independent, I would say that the probability of agreement So 54% of the time you could have some level of confidence in your prediction. I wonder if we can say this though and am trying to tie in concepts of conditional probability and correlation. If we blindly followed tool we could correctly predict for of the coin flips. Can we use in any way to increase that portion? To me it seems like we can not as that would involve going against at some points which seems suboptimal. EDIT: After thinking about it, I believe A and B can have independent predictions. Let's assume they are if that's true. (however I'm curious of what would change if we increased correlation. I'm assuming it is not possible for correlation to be 1 as they must be different at some points to have differing proportions. What is max correlation in that case? My intuition tells me the higher the correlation, the less you'd consider the forecast with worse probability.)",H T A B A p = 0.7 B p = 0.6 A's B B A B A B = 0.7 \cdot 0.6 + 0.3 \cdot 0.4 = 0.54 A 70% B A,"['statistics', 'conditional-probability', 'covariance', 'correlation']"
77,Efficient and unbiased estimation of the location ($\mu$) of truncated normal distribution with known scale ($\sigma^2$) and truncation points,Efficient and unbiased estimation of the location () of truncated normal distribution with known scale () and truncation points,\mu \sigma^2,"I have one observation $x$ which I know comes from the following truncated normal distribution : $$x \sim TN(\mu, \sigma^2, -\delta, \delta) \;\textrm{ where }\; \delta > 0$$ In my problem, the scale parameter $\sigma^2$ and the truncation points $-\delta$ and $\delta$ are known, but $\mu$ is not. I know that we can obtain $\hat{\mu}$ through maximum likelihood estimation: $$\hat{\mu} = argmax_{\mu \in \mathbb{R}} \frac{\phi\left(\frac{x - \mu}{\sigma}\right)}{\sigma\left(\Phi\left(\frac{\delta - \mu}{\sigma}\right) - \Phi\left(\frac{-\delta - \mu}{\sigma}\right)\right)}$$ But because I only have one observation, I am finding in simulations that the consistency guarantees of MLE are not sufficient and I actually have considerable bias in my estimates ( here they find a similar bias issue with MLE in the comments). So my questions are: For my estimation problem, are there any alternative estimators that deliver lower variance than MLE? Does a bias correction for the MLE estimator $\hat{\mu}$ in my case exist and/or how can I find it? Because my case (known $\sigma$ and truncation $-\delta, \delta$ ) is not typically analysed in the literature, I have been unsuccessful in finding anything specific to my problem in textbooks or research articles. Everything I have consulted (e.g. Clifford (1991)) discusses the more general case of many samples and unknown $\mu$ and $\sigma$ with unrestricted $a$ and $b$ truncation points. Any help is much appreciated. Answers that rely on numerical methods are perfectly acceptable. Reference: Cohen, A. Clifford. Truncated and censored samples: theory and applications. CRC press, 1991.","I have one observation which I know comes from the following truncated normal distribution : In my problem, the scale parameter and the truncation points and are known, but is not. I know that we can obtain through maximum likelihood estimation: But because I only have one observation, I am finding in simulations that the consistency guarantees of MLE are not sufficient and I actually have considerable bias in my estimates ( here they find a similar bias issue with MLE in the comments). So my questions are: For my estimation problem, are there any alternative estimators that deliver lower variance than MLE? Does a bias correction for the MLE estimator in my case exist and/or how can I find it? Because my case (known and truncation ) is not typically analysed in the literature, I have been unsuccessful in finding anything specific to my problem in textbooks or research articles. Everything I have consulted (e.g. Clifford (1991)) discusses the more general case of many samples and unknown and with unrestricted and truncation points. Any help is much appreciated. Answers that rely on numerical methods are perfectly acceptable. Reference: Cohen, A. Clifford. Truncated and censored samples: theory and applications. CRC press, 1991.","x x \sim TN(\mu, \sigma^2, -\delta, \delta) \;\textrm{ where }\; \delta > 0 \sigma^2 -\delta \delta \mu \hat{\mu} \hat{\mu} = argmax_{\mu \in \mathbb{R}} \frac{\phi\left(\frac{x - \mu}{\sigma}\right)}{\sigma\left(\Phi\left(\frac{\delta - \mu}{\sigma}\right) - \Phi\left(\frac{-\delta - \mu}{\sigma}\right)\right)} \hat{\mu} \sigma -\delta, \delta \mu \sigma a b","['statistics', 'normal-distribution', 'variance', 'maximum-likelihood']"
78,"Probability that maximum of two iid Unif(0, 1) r.v.s is less than the minimum of two other iid Unif(0,1) r.v.s?","Probability that maximum of two iid Unif(0, 1) r.v.s is less than the minimum of two other iid Unif(0,1) r.v.s?",,"Specifically, let $X_1, X_2, X_3, X_4$ ~ $Unif(0, 1)$ . What is $$P(max(X_1, X_2) \lt min(X_3, X_4))$$ Similarly, what is $$P(min(X_1, X_2) \gt max(X_3, X_4))$$ ?","Specifically, let ~ . What is Similarly, what is ?","X_1, X_2, X_3, X_4 Unif(0, 1) P(max(X_1, X_2) \lt min(X_3, X_4)) P(min(X_1, X_2) \gt max(X_3, X_4))","['probability', 'statistics', 'uniform-distribution']"
79,Hypergeometric-like distribution but where non-successes are replaced?,Hypergeometric-like distribution but where non-successes are replaced?,,"I'm working on a card game and say the deck has C cards where the player draws 3 cards every turn, picks a card, and the rest are shuffled back into the deck. They can do this N times. There are X of special cards which the player will nearly always pick if drawn. I'm trying to determine the best value of X to ensure the player sees on average around 2 or 3 of these cards in N draws. This seems similar to what hypergeometric calculators do, but if I'm not mistaken, they assume that no cards are replaced, and binomial calculators assume all cards are replaced. I could simulate this over a couple thousand runs in a python script, but is there a good mathematical formula I could apply to think kind of problem?","I'm working on a card game and say the deck has C cards where the player draws 3 cards every turn, picks a card, and the rest are shuffled back into the deck. They can do this N times. There are X of special cards which the player will nearly always pick if drawn. I'm trying to determine the best value of X to ensure the player sees on average around 2 or 3 of these cards in N draws. This seems similar to what hypergeometric calculators do, but if I'm not mistaken, they assume that no cards are replaced, and binomial calculators assume all cards are replaced. I could simulate this over a couple thousand runs in a python script, but is there a good mathematical formula I could apply to think kind of problem?",,"['probability', 'statistics', 'card-games']"
80,How to derive likelihood function,How to derive likelihood function,,"I have been struggling a lot with the concept of likelihood and I'd really appreciate it if someone could verify if my understanding is correct and give input. If I understand this correcly, we pick a point on x and then asks ourselves given the data on this exact x point in this case $x_0$ , what is the likelihood that we observe a data point t, as in which parameter are most likely to obsreved and if we keep doing that for all x points then we can approximate the function for the likeli hood?","I have been struggling a lot with the concept of likelihood and I'd really appreciate it if someone could verify if my understanding is correct and give input. If I understand this correcly, we pick a point on x and then asks ourselves given the data on this exact x point in this case , what is the likelihood that we observe a data point t, as in which parameter are most likely to obsreved and if we keep doing that for all x points then we can approximate the function for the likeli hood?",x_0,"['probability', 'statistics', 'machine-learning', 'bayesian', 'maximum-likelihood']"
81,Check if the sample mean squared is an unbiased estimator for the mean squared,Check if the sample mean squared is an unbiased estimator for the mean squared,,"My professor gave us the following problem : Let $ \{ y_1, y_2, \ldots, y_N \}$ be a random sample drawn from $N(\theta, \sigma^2)$ where $ \sigma^2$ is known. We want to check if this estimator is unbiased for $\theta^2$ and if it may be consistent. We want to compute the ML estimate of $\theta ^2$ . Since the ML estimator of $\theta$ is $\hat{\theta}_N = \bar{y}_N $ , we could get the ML estimate of $\theta^2$ using the invariance principle by setting $\hat{\theta}_N^2 = \bar{y}_N^2$ . And then it provides as solution: $$ E_\theta [\bar{y}_N^2] = \frac{(N-1)^2 + N}{N^2} \theta^2 + \frac{\sigma^2}{N}$$ which I believe to be wrong since this is what I did: $$E_\theta [\bar{y}_N^2] = E (\frac{1}{N^2} \sum (y_i^2)) = \frac{1}{N^2} \sum E(y_i)^2 = \frac{1}{N^2} (\sum Var(y_i) + E(y_i)^2) = \frac{1}{N^2} (N \sigma^2 + N^2 \theta^2) = \frac{\sigma^2}{N} + \theta^2$$ which becomes unbiased as N goes to infinity. Is my solution correct?","My professor gave us the following problem : Let be a random sample drawn from where is known. We want to check if this estimator is unbiased for and if it may be consistent. We want to compute the ML estimate of . Since the ML estimator of is , we could get the ML estimate of using the invariance principle by setting . And then it provides as solution: which I believe to be wrong since this is what I did: which becomes unbiased as N goes to infinity. Is my solution correct?"," \{ y_1, y_2, \ldots, y_N \} N(\theta, \sigma^2)  \sigma^2 \theta^2 \theta ^2 \theta \hat{\theta}_N = \bar{y}_N  \theta^2 \hat{\theta}_N^2 = \bar{y}_N^2  E_\theta [\bar{y}_N^2] = \frac{(N-1)^2 + N}{N^2} \theta^2 + \frac{\sigma^2}{N} E_\theta [\bar{y}_N^2] = E (\frac{1}{N^2} \sum (y_i^2)) = \frac{1}{N^2} \sum E(y_i)^2 = \frac{1}{N^2} (\sum Var(y_i) + E(y_i)^2) = \frac{1}{N^2} (N \sigma^2 + N^2 \theta^2) = \frac{\sigma^2}{N} + \theta^2",['statistics']
82,Bayesian Inference Intractability,Bayesian Inference Intractability,,"When looking at Bayesian posteriors $$   p(z \mid x) = \frac{p(x \mid z)p(z)}{\int p(x \mid z')p(z')dz'} $$ The denominator commonly intractable. I understand this is due to the possibility of high dimensionality, but I'm not sure why a Monte-Carlo estimate approach is not commonly used e.g. $$ \int p(x \mid z')p(z')dz' = \mathbb{E}_z(p(x \mid z))  \approx \frac{1}{L}\sum_{i=1}^{L} p(x \mid z_i) $$ Particularly when we usually choose a prior $p(z)$ which we can easily sample. Any help would be appreciated.","When looking at Bayesian posteriors The denominator commonly intractable. I understand this is due to the possibility of high dimensionality, but I'm not sure why a Monte-Carlo estimate approach is not commonly used e.g. Particularly when we usually choose a prior which we can easily sample. Any help would be appreciated.","
  p(z \mid x) = \frac{p(x \mid z)p(z)}{\int p(x \mid z')p(z')dz'}
 
\int p(x \mid z')p(z')dz' = \mathbb{E}_z(p(x \mid z)) 
\approx \frac{1}{L}\sum_{i=1}^{L} p(x \mid z_i)
 p(z)","['statistics', 'statistical-inference', 'machine-learning', 'bayesian', 'monte-carlo']"
83,Number of trials required to break even with a certain probability,Number of trials required to break even with a certain probability,,"I made a problem myself while reading an old econometrics book, but having a hard time solving it. A single trial of a game is as follows. 1. You pay L dollars to start the game. 2. Toss a coin until you get heads. (The probability for heads and tails are equal.) 3. You earn $2^m$ dollars, where $m$ is the number of tails before heads. $I(n)$ is the income you get from $n$ trials. $I(n)=\sum_{i=1}^n (G_i - L)$ , where $G_i$ is the money you earn from the $i$ -th game. If $L=10000$ , what is the minimum value of $n$ for $P[I(n)\ge 0]\ge 1/2$ ? The expected value of income from a single trial, $$\begin{align}E[I(1)]&=\frac12(2^0-L)+\frac1{2^2}(2^1-L)+\frac1{2^3}(2^2-L)+ \ldots\\&=-L\left( \frac12+\frac1{2^2}+\frac1{2^3} + \ldots\right)+\frac12+\frac12+ \ldots\\&=\infty\end{align}$$ However, $P[I(1)\ge0]=1/2^{15}+1/2^{16}+1/2^{17}+\ldots=1/2^{14}$ Intuitionally, since a single trial has an expectation of infinity, you can expect $$\lim_{n\to\infty}P[I(n)\ge0]=1$$ I ran a simulation, and got the expected result. The number of samples of $I(n)$ was $10000$ . (L = 10) n      , P[I(n) >= 0]       1, 0.0646       2, 0.0787       4, 0.0867       8, 0.0984      16, 0.1058      32, 0.1206      64, 0.1327     128, 0.1350     256, 0.1426     512, 0.1583    1024, 0.1781    2048, 0.1962    4096, 0.2266    8192, 0.2529   16384, 0.2858   32768, 0.3344   65536, 0.3909  131072, 0.4659  262144, 0.5602  524288, 0.6633 1048576, 0.7953  (L = 20) n      , P[I(n) >= 0]       1, 0.0300       2, 0.0354       4, 0.0374       8, 0.0378      16, 0.0399      32, 0.0438      64, 0.0481     128, 0.0537     256, 0.0565     512, 0.0566    1024, 0.0611    2048, 0.0646    4096, 0.0650    8192, 0.0632   16384, 0.0654   32768, 0.0647   65536, 0.0690  131072, 0.0755  262144, 0.0728  524288, 0.0754 1048576, 0.0773 You can see $P$ converges very slowly with only $L=20$ , and we need to calculate $P$ for $L=10000$ . It doesn't seem possible to get the result by simulation within reasonable time. It seems best to get a simple algebraic solution for $f(n)=P[I(n)\ge0]$ , but is it possible? What are possible approaches to solve this problem?","I made a problem myself while reading an old econometrics book, but having a hard time solving it. A single trial of a game is as follows. 1. You pay L dollars to start the game. 2. Toss a coin until you get heads. (The probability for heads and tails are equal.) 3. You earn dollars, where is the number of tails before heads. is the income you get from trials. , where is the money you earn from the -th game. If , what is the minimum value of for ? The expected value of income from a single trial, However, Intuitionally, since a single trial has an expectation of infinity, you can expect I ran a simulation, and got the expected result. The number of samples of was . (L = 10) n      , P[I(n) >= 0]       1, 0.0646       2, 0.0787       4, 0.0867       8, 0.0984      16, 0.1058      32, 0.1206      64, 0.1327     128, 0.1350     256, 0.1426     512, 0.1583    1024, 0.1781    2048, 0.1962    4096, 0.2266    8192, 0.2529   16384, 0.2858   32768, 0.3344   65536, 0.3909  131072, 0.4659  262144, 0.5602  524288, 0.6633 1048576, 0.7953  (L = 20) n      , P[I(n) >= 0]       1, 0.0300       2, 0.0354       4, 0.0374       8, 0.0378      16, 0.0399      32, 0.0438      64, 0.0481     128, 0.0537     256, 0.0565     512, 0.0566    1024, 0.0611    2048, 0.0646    4096, 0.0650    8192, 0.0632   16384, 0.0654   32768, 0.0647   65536, 0.0690  131072, 0.0755  262144, 0.0728  524288, 0.0754 1048576, 0.0773 You can see converges very slowly with only , and we need to calculate for . It doesn't seem possible to get the result by simulation within reasonable time. It seems best to get a simple algebraic solution for , but is it possible? What are possible approaches to solve this problem?",2^m m I(n) n I(n)=\sum_{i=1}^n (G_i - L) G_i i L=10000 n P[I(n)\ge 0]\ge 1/2 \begin{align}E[I(1)]&=\frac12(2^0-L)+\frac1{2^2}(2^1-L)+\frac1{2^3}(2^2-L)+ \ldots\\&=-L\left( \frac12+\frac1{2^2}+\frac1{2^3} + \ldots\right)+\frac12+\frac12+ \ldots\\&=\infty\end{align} P[I(1)\ge0]=1/2^{15}+1/2^{16}+1/2^{17}+\ldots=1/2^{14} \lim_{n\to\infty}P[I(n)\ge0]=1 I(n) 10000 P L=20 P L=10000 f(n)=P[I(n)\ge0],"['probability', 'statistics', 'gambling']"
84,"Let $Y_1, \dots, Y_n \sim \; \textrm{iid}$ with pdf $f_Y(y)$. Show that the UMVUE of $\theta$ is given by $\frac{n-1}{\sum_{i=1}^n Y_i}$ [duplicate]",Let  with pdf . Show that the UMVUE of  is given by  [duplicate],"Y_1, \dots, Y_n \sim \; \textrm{iid} f_Y(y) \theta \frac{n-1}{\sum_{i=1}^n Y_i}","This question already has an answer here : Finding UMVUE of $\theta$ when the underlying distribution is exponential distribution (1 answer) Closed 3 months ago . I'm having a difficult time figuring out where to go here. Question: Let $Y_1,\dots, Y_n$ be iid random variables with pdf $f_Y(y) = \theta e^{-\theta y} \;,\; y >0\;,\;\theta >0.$ Show that the uniformly minimal variance unbiased estimator (UMVUE) of $\theta$ is given by $ \frac{n-1}{\sum_{i=1}^n Y_i}.$ We were given the following theorem in class: Theorem: If we have $Y1,\ldots,Yn$ iid random variables and Y belongs to an exponential family (with a single parameter θ), then, under some technical conditions, we say that $ U = \sum_{i=1}^n t(Y_i)$ is a *complete and sufficient statistic for $\theta$ . My work: Our pdf belongs to an exponential family with $h(y) = 1$ , $c(\theta) = \theta$ , $w(\theta) = -\theta$ , and $t(y) = y$ . Therefore, $U = \sum_{i=1}^n Y_i$ is a complete and sufficient statistic for $\theta$ . Now, to show that it is the UMVUE of $\theta$ , I need to show that it is unbiased. $B(\hat{\theta}) = E[\hat{\theta}] - \theta$ . We can rewrite our pdf to be $\frac{1}{\frac{1}{\theta}}e^{\frac{-y}{\frac{1}{\theta}}}$ , which is the exponential with $\beta = \frac{1}{\theta}$ , so $E[Y] = \frac{1}{\theta}$ . Therefore $\begin{align} E[\hat{\theta}] &= E[\sum_{i=1}^n Y_i] = \sum_{i=1}^n E[Y_i] = nE[Y] \notag \\ &nE[Y] = \frac{n}{\theta} \notag \\ &B(\hat{\theta}) = \frac{n}{\theta} - \theta \notag \end{align}$ which will be unbiased if $\hat{\theta} = \frac{\theta^2}{n}E[nY] = Var(\bar{Y})E[nY]$ . At this point I feel like I've sort of lost the plot and am no longer sure what to do.","This question already has an answer here : Finding UMVUE of $\theta$ when the underlying distribution is exponential distribution (1 answer) Closed 3 months ago . I'm having a difficult time figuring out where to go here. Question: Let be iid random variables with pdf Show that the uniformly minimal variance unbiased estimator (UMVUE) of is given by We were given the following theorem in class: Theorem: If we have iid random variables and Y belongs to an exponential family (with a single parameter θ), then, under some technical conditions, we say that is a *complete and sufficient statistic for . My work: Our pdf belongs to an exponential family with , , , and . Therefore, is a complete and sufficient statistic for . Now, to show that it is the UMVUE of , I need to show that it is unbiased. . We can rewrite our pdf to be , which is the exponential with , so . Therefore which will be unbiased if . At this point I feel like I've sort of lost the plot and am no longer sure what to do.","Y_1,\dots, Y_n f_Y(y) = \theta e^{-\theta y} \;,\; y >0\;,\;\theta >0. \theta 
\frac{n-1}{\sum_{i=1}^n Y_i}. Y1,\ldots,Yn 
U = \sum_{i=1}^n t(Y_i) \theta h(y) = 1 c(\theta) = \theta w(\theta) = -\theta t(y) = y U = \sum_{i=1}^n Y_i \theta \theta B(\hat{\theta}) = E[\hat{\theta}] - \theta \frac{1}{\frac{1}{\theta}}e^{\frac{-y}{\frac{1}{\theta}}} \beta = \frac{1}{\theta} E[Y] = \frac{1}{\theta} \begin{align}
E[\hat{\theta}] &= E[\sum_{i=1}^n Y_i] = \sum_{i=1}^n E[Y_i] = nE[Y] \notag \\
&nE[Y] = \frac{n}{\theta} \notag \\
&B(\hat{\theta}) = \frac{n}{\theta} - \theta \notag
\end{align} \hat{\theta} = \frac{\theta^2}{n}E[nY] = Var(\bar{Y})E[nY]","['statistics', 'probability-distributions', 'parameter-estimation', 'sufficient-statistics', 'exponential-family']"
85,Law of large number with subset of the variables,Law of large number with subset of the variables,,"Let $(X_i, Y_i)_{i=1}^{\infty}$ be iid continuous random vectors with continuous joint density, where $X_1$ have support $\mathcal{X}$ . Let $B_n\subset \mathcal{X}\subset\mathbb{R}$ be decreasing subsets (open intervals) such that $\cap B_n= x_0\in\mathcal{X}$ . Let $S = \{i\leq n: X_i\in B_n\}$ . I want to show that $$ \frac{1}{|S|}\sum_{i\in S}Y_i \overset{P}{\to} \mathbb{E}[Y_1\mid X_1=x_0], \,\,as\,\,n\to\infty.  $$ I assume that the necessary condition for this convergence is $|S|\to\infty$ or that $nP(X_i\in B_n)\to\infty$ . Is it sufficient? Is there some theory that describes this?","Let be iid continuous random vectors with continuous joint density, where have support . Let be decreasing subsets (open intervals) such that . Let . I want to show that I assume that the necessary condition for this convergence is or that . Is it sufficient? Is there some theory that describes this?","(X_i, Y_i)_{i=1}^{\infty} X_1 \mathcal{X} B_n\subset \mathcal{X}\subset\mathbb{R} \cap B_n= x_0\in\mathcal{X} S = \{i\leq n: X_i\in B_n\} 
\frac{1}{|S|}\sum_{i\in S}Y_i \overset{P}{\to} \mathbb{E}[Y_1\mid X_1=x_0], \,\,as\,\,n\to\infty. 
 |S|\to\infty nP(X_i\in B_n)\to\infty","['statistics', 'statistical-inference', 'central-limit-theorem', 'law-of-large-numbers']"
86,Can I analytically integrate a high dimensional Normal distribution? [closed],Can I analytically integrate a high dimensional Normal distribution? [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 months ago . Improve this question Let's say $X \sim \mathcal{N}(\mu, \Sigma)$ , where $\mu \in \mathbb{R}^{3}$ . If I have two half spaces: $H_{1} = \{x: a^{T}x \geq 0\}, H_{2} = \{x: b^{T}x \geq 0\}$ , is there a way I can compute the total probability mass in the area $H_{1} \cap H_{2}$ ?","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 months ago . Improve this question Let's say , where . If I have two half spaces: , is there a way I can compute the total probability mass in the area ?","X \sim \mathcal{N}(\mu, \Sigma) \mu \in \mathbb{R}^{3} H_{1} = \{x: a^{T}x \geq 0\}, H_{2} = \{x: b^{T}x \geq 0\} H_{1} \cap H_{2}","['calculus', 'integration', 'analysis', 'statistics']"
87,Scrabble probability of Player A playing a U word?,Scrabble probability of Player A playing a U word?,,"so I was recently involved in a probability debate with a friend involving Scrabble: I had been selected to be Player 1. It was my turn to play (first play of the game) and I had a q and was looking for a word that would have a U in it. I was contemplating skipping my turn in the hopes that my adversary would play a U. However, he told me that, from my perspective, it would be about a 4 * 4/93 chance that he would play a word with a U in it, since 4 was the average length of a scrabble word and there are 4/93 possible tiles in the bag. I disagreed, but could not come up with a valid counter, aside from some vague musings about dependent probabilities. Later on, I did some digging. It looks like you'd have to figure out the probability that  both that my friend (Player 2) has a U and will play it. I did some math and it seems like one approach could be to use a hypergeometric solution, like that posited here: Scrabble Probability to figure out the probability that he has a u. I followed this approach to figure out that the probability that my friend had at least one U (given that I don't have one), which came out to about 25.54%. I then multiplied this by the (number of words that are seven letters or less and have at least one u in them in the Scrabble dictionary)/(total number of words that are seven letters or less in the dictionary) to arrive at at about a 4.21% probability. My main question is where did I err? Would appreciate any and all insights!","so I was recently involved in a probability debate with a friend involving Scrabble: I had been selected to be Player 1. It was my turn to play (first play of the game) and I had a q and was looking for a word that would have a U in it. I was contemplating skipping my turn in the hopes that my adversary would play a U. However, he told me that, from my perspective, it would be about a 4 * 4/93 chance that he would play a word with a U in it, since 4 was the average length of a scrabble word and there are 4/93 possible tiles in the bag. I disagreed, but could not come up with a valid counter, aside from some vague musings about dependent probabilities. Later on, I did some digging. It looks like you'd have to figure out the probability that  both that my friend (Player 2) has a U and will play it. I did some math and it seems like one approach could be to use a hypergeometric solution, like that posited here: Scrabble Probability to figure out the probability that he has a u. I followed this approach to figure out that the probability that my friend had at least one U (given that I don't have one), which came out to about 25.54%. I then multiplied this by the (number of words that are seven letters or less and have at least one u in them in the Scrabble dictionary)/(total number of words that are seven letters or less in the dictionary) to arrive at at about a 4.21% probability. My main question is where did I err? Would appreciate any and all insights!",,"['probability', 'probability-theory', 'statistics', 'card-games']"
88,Expected value and variance of Sigmoid and SiLU on a normally distributed random variable for variational approximation,Expected value and variance of Sigmoid and SiLU on a normally distributed random variable for variational approximation,,"I am trying to apply Assumed Density Filtering (ADF) according to the paper Lightweight Probabilistic Deep Networks to my own model, and I need to implement the variational approximation layer of Sigmoid and SiLU function. I tried to look for the equations for Sigmoid layer. In the paper Variational Learning in Nonlinear Gaussian Belief Networks , the authors mentioned that they have a closed form solution for calculating the expected value for Sigmoid layer with the equation: $$ M(μ,σ) = Φ(\frac{μ}{\sqrt{1+σ^2}}) $$ However, according to this question , there is only an approximation solution. Did I miss out some assumptions from the paper or misunderstood either of them? For SiLU, I am unable to find out resources for it so far. Would appreciate if anyone could provide some guidance or point me to some resources for it.","I am trying to apply Assumed Density Filtering (ADF) according to the paper Lightweight Probabilistic Deep Networks to my own model, and I need to implement the variational approximation layer of Sigmoid and SiLU function. I tried to look for the equations for Sigmoid layer. In the paper Variational Learning in Nonlinear Gaussian Belief Networks , the authors mentioned that they have a closed form solution for calculating the expected value for Sigmoid layer with the equation: However, according to this question , there is only an approximation solution. Did I miss out some assumptions from the paper or misunderstood either of them? For SiLU, I am unable to find out resources for it so far. Would appreciate if anyone could provide some guidance or point me to some resources for it.","
M(μ,σ) = Φ(\frac{μ}{\sqrt{1+σ^2}})
","['statistics', 'machine-learning']"
89,Connection between statistical and functional dependence of random variables,Connection between statistical and functional dependence of random variables,,"For simplicity lets consider finite probability space $(\Omega, \mathcal{F}, \mathbb{P})$ and two random variables $\xi, \eta$ on it. I wonder is there any connection between statistical and functional dependence of random variables? For example, if I have $\xi = f\circ \eta$ for some $f$ , does it imply that $\xi$ and $\eta$ statistically dependent and vice versa ? Or, if they are functionally independent, does it imply that they are statistically independent and vice versa?","For simplicity lets consider finite probability space and two random variables on it. I wonder is there any connection between statistical and functional dependence of random variables? For example, if I have for some , does it imply that and statistically dependent and vice versa ? Or, if they are functionally independent, does it imply that they are statistically independent and vice versa?","(\Omega, \mathcal{F}, \mathbb{P}) \xi, \eta \xi = f\circ \eta f \xi \eta","['probability', 'probability-theory', 'statistics', 'random-variables']"
90,Cardinality of a set of random variables (measurable functions): $|L_0|=|L_p|=|L_\infty|$ for any $p >0$?,Cardinality of a set of random variables (measurable functions):  for any ?,|L_0|=|L_p|=|L_\infty| p >0,"How can we compare the cardinalities of   different sets of random variables on a given probability space $(\Omega, \mathcal F, P)$ . Is $|L_1|>|L_\infty|$ , while $L_\infty$ is dense in $L_1$ ? When does the following $$|L_p|=|L_\infty|$$ hold for all $p\ge1$ ? How large can be the set $L_0$ of all random variables compared to $L_\infty$ ? How much are we lucky if a given distribution has a finite mean or finite variance? How restrictive is if a statement only holds for random variables with mgf? How are these cardinalities connected to the cardinality of $\Omega$ , See Wikipedia for definition of $L_p$ spaces. Here, $L_0$ denotes the set of all random variables (Borel measurable functions) defined on the probability space. Specifically interested in two cases of $(\Omega, 2^\Omega)$ where $\Omega$ is a finite set and $(\mathbb R, \mathcal B(\mathbb R)).$ For the latter, from here , we know that $$|L_0|=|\mathbb R|,$$ whereas the cardinality of the set of all Lebesgue measurable functions is $|2^\mathbb R|$ (which shows how small is the set of random variables, but note that they have the same cardinality of $|\mathbb R|$ considering equivalence classes). From the above, I think we have $$|L_{\frac{1}{p}}|=|L_p|=|\mathbb R|$$ for all $p\ge1$ as $$|\mathbb R|=|L_0|\ge|L_{\frac{1}{p}}|\ge|L_p|\ge|L_\infty|\ge|\mathbb R|.$$ On the other hand, when $\Omega$ is finite, we have $$|L_0|=|L_p|=|L_{\frac{1}{p}}|=|L_\infty|$$ for any $p\ge1$ . Can we generalize these two observations as follows? 1- For any given $(\Omega, \mathcal F, P)$ , we always have $$|L_0|=|L_{\frac{1}{p}}|=|L_p|=|L_\infty|$$ for any $p\ge 1$ . If yes , then 2- How can we define a bijection (one-to-one correspondence) for each pair of these spaces? In question 1, I also guess considering equivalence classes does not change the result. PS: Related Stack Exchange questions on sets with $|\mathbb R|$ cardinality: Cardinality of set of real continuous functions Cardinality of the borel measurable functions Cardinality of the set of entire functions Cardinality of the set of Lebesgue measurable functions under equivalence The cardinality of the Riemann integrable functions is $|2^\mathbb R|.$ Cardinality of the set of Riemann integrable functions on [0,1]","How can we compare the cardinalities of   different sets of random variables on a given probability space . Is , while is dense in ? When does the following hold for all ? How large can be the set of all random variables compared to ? How much are we lucky if a given distribution has a finite mean or finite variance? How restrictive is if a statement only holds for random variables with mgf? How are these cardinalities connected to the cardinality of , See Wikipedia for definition of spaces. Here, denotes the set of all random variables (Borel measurable functions) defined on the probability space. Specifically interested in two cases of where is a finite set and For the latter, from here , we know that whereas the cardinality of the set of all Lebesgue measurable functions is (which shows how small is the set of random variables, but note that they have the same cardinality of considering equivalence classes). From the above, I think we have for all as On the other hand, when is finite, we have for any . Can we generalize these two observations as follows? 1- For any given , we always have for any . If yes , then 2- How can we define a bijection (one-to-one correspondence) for each pair of these spaces? In question 1, I also guess considering equivalence classes does not change the result. PS: Related Stack Exchange questions on sets with cardinality: Cardinality of set of real continuous functions Cardinality of the borel measurable functions Cardinality of the set of entire functions Cardinality of the set of Lebesgue measurable functions under equivalence The cardinality of the Riemann integrable functions is Cardinality of the set of Riemann integrable functions on [0,1]","(\Omega, \mathcal F, P) |L_1|>|L_\infty| L_\infty L_1 |L_p|=|L_\infty| p\ge1 L_0 L_\infty \Omega L_p L_0 (\Omega, 2^\Omega) \Omega (\mathbb R, \mathcal B(\mathbb R)). |L_0|=|\mathbb R|, |2^\mathbb R| |\mathbb R| |L_{\frac{1}{p}}|=|L_p|=|\mathbb R| p\ge1 |\mathbb R|=|L_0|\ge|L_{\frac{1}{p}}|\ge|L_p|\ge|L_\infty|\ge|\mathbb R|. \Omega |L_0|=|L_p|=|L_{\frac{1}{p}}|=|L_\infty| p\ge1 (\Omega, \mathcal F, P) |L_0|=|L_{\frac{1}{p}}|=|L_p|=|L_\infty| p\ge 1 |\mathbb R| |2^\mathbb R|.","['real-analysis', 'probability', 'measure-theory', 'statistics', 'elementary-set-theory']"
91,How to design this two sample exponential distribution test?,How to design this two sample exponential distribution test?,,"Given independent random samples $(X_1,...,X_m)$ and $(Y_1,...,Y_n)$ , respectively, from the following distributions of $X$ and $Y: X \sim \lambda_1 \exp (-\lambda_1 x) I(x >0)$ , and $Y \sim \lambda_2 \exp (-\lambda_2 y) I(y >0)$ . Consider the problem of testing the null hypothesis $H_0:\lambda_1=\lambda_2 $ against the alternative: $H_1:\lambda_1 \neq \lambda_2 $ . a. Formulate the underlying testing problem as that of testing one of the parameters in a multiparameter exponential family, having expressed the family explicitly in terms of all the parameters and the corresponding statistics. b. Give the formula of the UMPU test at level $\alpha$ , in its conditional form, involving these statistics. c. Describe how this test can be stated equivalently as an unconditional test. What are the ultimate test statistic and the rejection region (in terms of a known distribution)? Some examples of the similar question: Say $X$ and $Y$ are independent. $X \sim Bin(m, p_1), Y\sim Bin(n , p_2)$ .We want to test $$H_0: p_1=p_2 \text{against} H_1: p_1>p_2,$$ Then $(X,Y)\sim f_{\theta_1,\theta_2} (x,y)=e^{\theta_1 T_1 + \theta_2 T_2-A(\theta_1,\theta_2 )}h(x,y)$ with $\theta_1=\log \frac{p_1 (1-p_2)}{p_2 (1-p_1)}, T_1=X, \theta_2=\log \frac{p_2}{1-p_2}, T_2=X+Y$ $$H_0: \theta_1=0 \text{ against } H_1: \theta_1>0.$$ The UMPU test $ \phi_0 (T_1,T_2) = \begin{cases} 1 ,  \text{if} T_1 > c(T_2) \\       \psi(T_2) ,  \text{if} T_1=c(T_2) \\ 0, \text{if} T_1<c(T_2) \end{cases}$ where $c(T_2)$ and $\psi(T_2)$ are such that $E_{\theta_1=0} (\phi_0 (T_1, T_2) | T_2)=\alpha$ . Since the conditional distribution $T_1=X$ given $T_2=X+Y=t_2$ is $$P(X=x | X+Y=t_2)=\frac{{m\choose x}{n \choose t_2-x} }{m+n \choose t_2}$$ $c(t_2)$ and $\psi(t_2)$ are such that $$\sum\limits_{x > c(t_2)}  {m\choose x} {n \choose t_2-x}+ \psi(t_2) {m \choose c(t_2) } {n \choose t_2-c(t_2)}={m+n \choose t_2}\alpha$$","Given independent random samples and , respectively, from the following distributions of and , and . Consider the problem of testing the null hypothesis against the alternative: . a. Formulate the underlying testing problem as that of testing one of the parameters in a multiparameter exponential family, having expressed the family explicitly in terms of all the parameters and the corresponding statistics. b. Give the formula of the UMPU test at level , in its conditional form, involving these statistics. c. Describe how this test can be stated equivalently as an unconditional test. What are the ultimate test statistic and the rejection region (in terms of a known distribution)? Some examples of the similar question: Say and are independent. .We want to test Then with The UMPU test where and are such that . Since the conditional distribution given is and are such that","(X_1,...,X_m) (Y_1,...,Y_n) X Y: X \sim \lambda_1 \exp (-\lambda_1 x) I(x >0) Y \sim \lambda_2 \exp (-\lambda_2 y) I(y >0) H_0:\lambda_1=\lambda_2  H_1:\lambda_1 \neq \lambda_2  \alpha X Y X \sim Bin(m, p_1), Y\sim Bin(n , p_2) H_0: p_1=p_2 \text{against} H_1: p_1>p_2, (X,Y)\sim f_{\theta_1,\theta_2} (x,y)=e^{\theta_1 T_1 + \theta_2 T_2-A(\theta_1,\theta_2 )}h(x,y) \theta_1=\log \frac{p_1 (1-p_2)}{p_2 (1-p_1)}, T_1=X, \theta_2=\log \frac{p_2}{1-p_2}, T_2=X+Y H_0: \theta_1=0 \text{ against } H_1: \theta_1>0.  \phi_0 (T_1,T_2) = \begin{cases} 1 ,  \text{if} T_1 > c(T_2) \\
      \psi(T_2) ,  \text{if} T_1=c(T_2) \\
0, \text{if} T_1<c(T_2) \end{cases} c(T_2) \psi(T_2) E_{\theta_1=0} (\phi_0 (T_1, T_2) | T_2)=\alpha T_1=X T_2=X+Y=t_2 P(X=x | X+Y=t_2)=\frac{{m\choose x}{n \choose t_2-x} }{m+n \choose t_2} c(t_2) \psi(t_2) \sum\limits_{x > c(t_2)}  {m\choose x} {n \choose t_2-x}+ \psi(t_2) {m \choose c(t_2) } {n \choose t_2-c(t_2)}={m+n \choose t_2}\alpha","['statistics', 'hypothesis-testing']"
92,How to combine two probabilities for the same event? Context: error correction codes / decoding,How to combine two probabilities for the same event? Context: error correction codes / decoding,,"I'm learning the maths behind error correction codes. For this purpose I made this question for myself: Assume there are two random bits $x_0$ , $x_1$ , which are both i.i.d. and have a 50% chance of being 0 or 1 (the information bits) and an additional check bit $x_2 = x_0 \mathbin{\mathsf{XOR}} x_1$ ). You now transfer all 3 bits through an additive white gaussian noise channel (AWGNC), one by one. The AWGNC adds noise to each bit independently and on the receiver side, you can only restore each bit with some probability, depending on what you received. You do this for each bit individually and independently of the other bits and conclude that the 3 probabilities of the bits to be 1 are $p = (0.2, 0.9, 0.7)$ , I.e. $P(x_0 = 1 \;|\; \text{given the noisy version of $x_0$ that you received}) = 0.2$ $P(x_1 = 1 \;|\; \text{given the noisy version of $x_1$ that you  received}) = 0.9$ $P(x_2 = 1 \;|\; \text{given the noisy version of $x_2$ that you received}) = 0.7$ Obviously, the best guess $y$ for the sent bits $x$ is $y = (0, 1, 1)$ . How to calculate the combined probability of this guess to be correct? Or of any other guess? I.e. how to calculate $P(x = (0, 1, 1) \;|\; p = (0.2, 0.9, 0.7))$ or other guesses? Using the fact that the originally sent $x_2$ is the XOR of the other two originally sent bits, we can use the probabilities $p_0$ and $p_1$ to infer another probability about $x_2$ : $$ \begin{align} p_2' := {} &P(x_2 = 1 \mid p_0 = 0.2, p_1 = 0.9) \\[4pt] = {} & P(x_0 = 0 \mid p_0 = 0.2) \cdot P(x_1 = 1 \mid p_1 = 0.9) \\  {} & + P(x_0 = 1 \mid p_0 = 0.2) \cdot P(x_1 = 0 \mid p_1 = 0.9)\\[4pt] = {} & (1 - 0.2) \cdot 0.9 + 0.2 \cdot (1 - 0.9) \\[4pt] = {} & 0.8 \cdot 0.9 + 0.2 \cdot 0.1\\[4pt] = {} & 0.72 + 0.02\\[4pt] = {} & 0.74. \end{align} $$ How to combine the probabilities $p_2' = 0.74$ and $p_2 = 0.7$ into the combined probability $p_2'' := P(x_2 = 1  \;|\; p = (0.2, 0.9, 0.7))$ ? Does the question make sense in this form? Do I need to know the distribution of the probability after the channel, given a bit's value before the channel? To give an illustration and overview of the relations for transferring a single bit b:","I'm learning the maths behind error correction codes. For this purpose I made this question for myself: Assume there are two random bits , , which are both i.i.d. and have a 50% chance of being 0 or 1 (the information bits) and an additional check bit ). You now transfer all 3 bits through an additive white gaussian noise channel (AWGNC), one by one. The AWGNC adds noise to each bit independently and on the receiver side, you can only restore each bit with some probability, depending on what you received. You do this for each bit individually and independently of the other bits and conclude that the 3 probabilities of the bits to be 1 are , I.e. Obviously, the best guess for the sent bits is . How to calculate the combined probability of this guess to be correct? Or of any other guess? I.e. how to calculate or other guesses? Using the fact that the originally sent is the XOR of the other two originally sent bits, we can use the probabilities and to infer another probability about : How to combine the probabilities and into the combined probability ? Does the question make sense in this form? Do I need to know the distribution of the probability after the channel, given a bit's value before the channel? To give an illustration and overview of the relations for transferring a single bit b:","x_0 x_1 x_2 = x_0 \mathbin{\mathsf{XOR}} x_1 p = (0.2, 0.9, 0.7) P(x_0 = 1 \;|\; \text{given the noisy version of x_0 that you received}) = 0.2 P(x_1 = 1 \;|\; \text{given the noisy version of x_1 that you 
received}) = 0.9 P(x_2 = 1 \;|\; \text{given the noisy version of x_2 that you received}) = 0.7 y x y = (0, 1, 1) P(x = (0, 1, 1) \;|\; p = (0.2, 0.9, 0.7)) x_2 p_0 p_1 x_2 
\begin{align}
p_2' := {} &P(x_2 = 1 \mid p_0 = 0.2, p_1 = 0.9) \\[4pt]
= {} & P(x_0 = 0 \mid p_0 = 0.2) \cdot P(x_1 = 1 \mid p_1 = 0.9) \\
 {} & + P(x_0 = 1 \mid p_0 = 0.2) \cdot P(x_1 = 0 \mid p_1 = 0.9)\\[4pt]
= {} & (1 - 0.2) \cdot 0.9 + 0.2 \cdot (1 - 0.9) \\[4pt]
= {} & 0.8 \cdot 0.9 + 0.2 \cdot 0.1\\[4pt]
= {} & 0.72 + 0.02\\[4pt]
= {} & 0.74.
\end{align}
 p_2' = 0.74 p_2 = 0.7 p_2'' := P(x_2 = 1  \;|\; p = (0.2, 0.9, 0.7))","['statistics', 'conditional-probability', 'statistical-inference']"
93,"Gaussian fit for dice rolls has peculiar constants, looking for their origin","Gaussian fit for dice rolls has peculiar constants, looking for their origin",,"For a programming project I want to describe huge quantities of dice rolls using a gaussian. Hence I set out to find a relation between: $size$ = the number of sides a single die has, $amount$ = the number of same sided dice rolled at once, and the gaussian that describes the probability of rolling a specific total sum $x$ with all of these dice. Dice in this case mean some abstract object that on 'rolling' give a random integer number between 1 and $size$ (inclusive), just like normal dice would. Let the gaussian be: $$ P(x) = A * e^{-\frac{(x-\mu)^2}{2\sigma^2}} $$ Where usually $A = \frac{1}{\sigma \sqrt{2 \pi}}$ is used as normalisation constant while $\mu = amount * \frac{size + 1}{2}$ is straightforward. Now, using several parameters for $size$ and $amount$ I fitted simulated distributions to the gaussian using $A$ and $\sigma$ as fitting parameters. I found the following holds true in very good approximation when $size$ and $amount$ are both bigger than like 4: $$\sigma = a * size * \sqrt{amount}$$ $$A = \frac{b}{size * \sqrt{amount}}$$ with the two constants: $$a \approx 0.28915937$$ $$b \approx 137445.476$$ Now I am asking myself (and in extension you) if the constants $a$ and $b$ that appear here can somehow be explained. I would be surprised if these are just some *shrug* numbers that randomly appear in a system as simple as same-sided dice and would be much more satisfied if they could be explained and maybe consist of well-known numbers like $\pi$ and $e$ . Please help me satisfy my curiosity here! I am aware that I am using a continuous probability distribution function to describe discrete events but I am pretty sure this does not invalidate the question. Also I did not study mathematics, so please assume that I only have surface knowledge regarding black magic aka mathematics. edit: I should add that the distribution I fitted is a histogram of $x$ over 100k simulated rolls. Therefore the integral over the whole distribution is not 1 and $b$ is large for this reason. I am mainly interested in the $\sigma$ .","For a programming project I want to describe huge quantities of dice rolls using a gaussian. Hence I set out to find a relation between: = the number of sides a single die has, = the number of same sided dice rolled at once, and the gaussian that describes the probability of rolling a specific total sum with all of these dice. Dice in this case mean some abstract object that on 'rolling' give a random integer number between 1 and (inclusive), just like normal dice would. Let the gaussian be: Where usually is used as normalisation constant while is straightforward. Now, using several parameters for and I fitted simulated distributions to the gaussian using and as fitting parameters. I found the following holds true in very good approximation when and are both bigger than like 4: with the two constants: Now I am asking myself (and in extension you) if the constants and that appear here can somehow be explained. I would be surprised if these are just some *shrug* numbers that randomly appear in a system as simple as same-sided dice and would be much more satisfied if they could be explained and maybe consist of well-known numbers like and . Please help me satisfy my curiosity here! I am aware that I am using a continuous probability distribution function to describe discrete events but I am pretty sure this does not invalidate the question. Also I did not study mathematics, so please assume that I only have surface knowledge regarding black magic aka mathematics. edit: I should add that the distribution I fitted is a histogram of over 100k simulated rolls. Therefore the integral over the whole distribution is not 1 and is large for this reason. I am mainly interested in the .",size amount x size  P(x) = A * e^{-\frac{(x-\mu)^2}{2\sigma^2}}  A = \frac{1}{\sigma \sqrt{2 \pi}} \mu = amount * \frac{size + 1}{2} size amount A \sigma size amount \sigma = a * size * \sqrt{amount} A = \frac{b}{size * \sqrt{amount}} a \approx 0.28915937 b \approx 137445.476 a b \pi e x b \sigma,"['statistics', 'probability-distributions']"
94,A small lemma on cache resets (Bloom filters in particular),A small lemma on cache resets (Bloom filters in particular),,"Assume a fixed set of message $D$ and an associated distribution for selecting each message $d_i$ such that the total probability $\sum_{i \in D} d_i = 1$ . We create a cache with $M$ bits and $k$ hashes, where each message from $D$ gets mapped to $k$ unique entries between $[1,M]$ (i.e., a Bloom Filter). More formally, a Bloom filter is an array of $M$ bits initially set to 0. It employs $k$ hashes, each of which maps or hashes some set element to one of the $m$ array positions with a random distribution. These functions are denoted by $h_1,h_2, \cdots, h_k$ . To add an element $x$ to the Bloom Filter, we compute $k$ hash functions to determine the $k$ positions in the bit array and set the bits to these positions to 1. In other words, $h_i(x) = 1$ for the $i$ selected. We introduce a random variable $Y_j$ to represent the count of occupied slots in the Bloom Filter at the $j$ -th iteration. Furthermore, we assume that once $Y_j$ reaches or exceeds a threshold $\sigma$ , the Bloom Filter is reset such that the $M$ bits are set to 0 and the process concludes. I am interested in proving the following lemma: Let $X_{j} = \mathbb{1}_{Y_j \geq \sigma\; | \; Y_{j-1} < \sigma}$ (i.e. the $j+1$ -st draw to result in a reset given that it did not in the $j$ -th draw), then $P(X_j = 1) \leq P(X_{j+1} = 1)$ . I am finding it challenging to prove this lemma. I have verified its validity via simulations and it seems to hold. I can also brute force the computation for very simple cases and it also works. Please note that this situation differs from demonstrating that for $X'_{j} = \mathbb{1}_{Y_j \geq \sigma}$ , the property $P(X'_j = 1) \leq P(X'_{j+1} = 1)$ is relatively simple to establish using a sample path argument. I mention this because I originally thought that the proof would be trivial using this argument. The main difficulty arises because, for any specified number of set bits, it's possible to construct sequences of messages of any length that have resulted in that filter being filled. I would appreciate any help. A counter-example would also do the trick. Thanks!","Assume a fixed set of message and an associated distribution for selecting each message such that the total probability . We create a cache with bits and hashes, where each message from gets mapped to unique entries between (i.e., a Bloom Filter). More formally, a Bloom filter is an array of bits initially set to 0. It employs hashes, each of which maps or hashes some set element to one of the array positions with a random distribution. These functions are denoted by . To add an element to the Bloom Filter, we compute hash functions to determine the positions in the bit array and set the bits to these positions to 1. In other words, for the selected. We introduce a random variable to represent the count of occupied slots in the Bloom Filter at the -th iteration. Furthermore, we assume that once reaches or exceeds a threshold , the Bloom Filter is reset such that the bits are set to 0 and the process concludes. I am interested in proving the following lemma: Let (i.e. the -st draw to result in a reset given that it did not in the -th draw), then . I am finding it challenging to prove this lemma. I have verified its validity via simulations and it seems to hold. I can also brute force the computation for very simple cases and it also works. Please note that this situation differs from demonstrating that for , the property is relatively simple to establish using a sample path argument. I mention this because I originally thought that the proof would be trivial using this argument. The main difficulty arises because, for any specified number of set bits, it's possible to construct sequences of messages of any length that have resulted in that filter being filled. I would appreciate any help. A counter-example would also do the trick. Thanks!","D d_i \sum_{i \in D} d_i = 1 M k D k [1,M] M k m h_1,h_2, \cdots, h_k x k k h_i(x) = 1 i Y_j j Y_j \sigma M X_{j} = \mathbb{1}_{Y_j \geq \sigma\; | \; Y_{j-1} < \sigma} j+1 j P(X_j = 1) \leq P(X_{j+1} = 1) X'_{j} = \mathbb{1}_{Y_j \geq \sigma} P(X'_j = 1) \leq P(X'_{j+1} = 1)","['probability', 'statistics', 'algorithms', 'computer-science']"
95,Understanding a measurabiliy statement from Section 6.3 in Lehmann and Romano,Understanding a measurabiliy statement from Section 6.3 in Lehmann and Romano,,"This paragraph is at the end of Section 6.3 in the book Testing Statistical Hypotheses by Lehmann and Romano: In most applications, $M(x)$ is a measurable function taking on values in a Euclidean space and it is convenient to take $\mathcal B$ as the class of Borel sets. If $\phi(x) = \psi[M(x)]$ is then an arbitrary measurable function depending only on $M(x)$ , it is not clear that $\psi(m)$ is necessarily $\mathcal B$ -measurable. This measurability can be concluded if $\mathcal X$ is also Euclidean with $\mathcal A$ the class of Borel sets, and if the range of $M$ is a Borel set. We shall prove it here only under the additional assumption (which in applications is usually obvious, and which will not be verified explicitly in each case) that there exists a vector-valued Borel-measurable function $Y(x)$ such that $[M(x), Y (x)]$ maps $\mathcal X$ onto a Borel subset of the product space $\mathcal M\times \mathcal Y$ , that this mapping is $1 : 1$ , and that the inverse mapping is also Borel-measurable. Given any measurable function $\phi(x)$ of $x$ , there exists then a measurable function $\phi'$ of $(m, y)$ such that $\phi(x) ≡ \phi' [M(x), Y (x)]$ . If $\phi$ depends only on $M(x)$ , then $\phi'$ depends only on $m$ , so that $\phi'$ $(m, y) = \psi(m)$ say, and $\psi$ is a measurable function of $m$ . I don't understand how to formalize the argument: How to choose $\phi'$ ? Why $\phi'$ depends only on $m$ if $\phi$ depends only on $M(x)$ ? Where do we need $Y(x)$ to be 1:1 with measurable inverse and measurable range? Can someone clarify the argument? Edit: Why is $\psi(m)$ a measurable function of $m$ ?","This paragraph is at the end of Section 6.3 in the book Testing Statistical Hypotheses by Lehmann and Romano: In most applications, is a measurable function taking on values in a Euclidean space and it is convenient to take as the class of Borel sets. If is then an arbitrary measurable function depending only on , it is not clear that is necessarily -measurable. This measurability can be concluded if is also Euclidean with the class of Borel sets, and if the range of is a Borel set. We shall prove it here only under the additional assumption (which in applications is usually obvious, and which will not be verified explicitly in each case) that there exists a vector-valued Borel-measurable function such that maps onto a Borel subset of the product space , that this mapping is , and that the inverse mapping is also Borel-measurable. Given any measurable function of , there exists then a measurable function of such that . If depends only on , then depends only on , so that say, and is a measurable function of . I don't understand how to formalize the argument: How to choose ? Why depends only on if depends only on ? Where do we need to be 1:1 with measurable inverse and measurable range? Can someone clarify the argument? Edit: Why is a measurable function of ?","M(x) \mathcal B \phi(x) = \psi[M(x)] M(x) \psi(m) \mathcal B \mathcal X \mathcal A M Y(x) [M(x), Y (x)] \mathcal X \mathcal M\times \mathcal Y 1 : 1 \phi(x) x \phi' (m, y) \phi(x) ≡ \phi' [M(x), Y (x)] \phi M(x) \phi' m \phi' (m, y) = \psi(m) \psi m \phi' \phi' m \phi M(x) Y(x) \psi(m) m","['measure-theory', 'statistics', 'proof-explanation', 'statistical-inference', 'measurable-functions']"
96,Balanced Snowball Sampling,Balanced Snowball Sampling,,"There is a method in qualitative research called ""balanced snowball sampling"", which runs as follows. Say the interviews are assessing perspectives on some issue, each interviewee is asked to recommend two further interviewees, one who will offer a more positive perspective, and one who will offer a more negative perspective than their own. In a simple model of this we are sampling some continuous distribution $p(x)$ . However, we are not allows to sample $p(x)$ directly: instead we start from some arbitrary initial sample of a single point (not necessarily drawn from $p(x)$ , but necessarily within its support), and the only allowed mechanism for growing the sample size is take some point $x_i$ in our sample, and generate two additional points $x_j^>$ and $x_j^<$ drawn randomly from $p(x|x>x_i)$ and $p(x|x<x_i)$ respectively. Interestingly, if you apply this method recursively (generating two points from every point in your sample, and two points from each of those points, and so on), the sample distribution does converge, but not to $p(x)$ . Instead, the sample distribution over represents tail events. I have two questions: What distribution does the sample converge to? Is there a straightforward way of including a rejection (discarding certain points from the sample) which means that the sample does converge to $p(x)$ ?","There is a method in qualitative research called ""balanced snowball sampling"", which runs as follows. Say the interviews are assessing perspectives on some issue, each interviewee is asked to recommend two further interviewees, one who will offer a more positive perspective, and one who will offer a more negative perspective than their own. In a simple model of this we are sampling some continuous distribution . However, we are not allows to sample directly: instead we start from some arbitrary initial sample of a single point (not necessarily drawn from , but necessarily within its support), and the only allowed mechanism for growing the sample size is take some point in our sample, and generate two additional points and drawn randomly from and respectively. Interestingly, if you apply this method recursively (generating two points from every point in your sample, and two points from each of those points, and so on), the sample distribution does converge, but not to . Instead, the sample distribution over represents tail events. I have two questions: What distribution does the sample converge to? Is there a straightforward way of including a rejection (discarding certain points from the sample) which means that the sample does converge to ?",p(x) p(x) p(x) x_i x_j^> x_j^< p(x|x>x_i) p(x|x<x_i) p(x) p(x),"['statistics', 'sampling']"
97,Lower bound on sample size to determine coin fairness,Lower bound on sample size to determine coin fairness,,"This is a conclusion I came to through very basic knowledge of statistics and error analysis. Suppose we want to determine the fairness of a coin. To do this, we need to determine the probability of the coin landing on either Heads or Tails and we do this through repeated flipping. We have an amount of uncertainty we are willing to allow in our measurement of the probability. We define the variable $f$ as follows: $$f =  \begin{cases} 1, & \text{if the coin lands on Heads} \\ 0, & \text{if the coin lands on Tails} \end{cases}$$ Then our measurement of the probability $P(H)$ of the coin landing on heads is equal to the sample average of $f$ , $\bar f$ . The formula for the standard error of the measurement of $f$ through $n$ samples is: $$\Delta f = \frac{\sigma_f}{\sqrt{n}}$$ Now, since $f$ can only have values $0$ and $1$ , its standard deviation cannot be greater than $\frac{1}{2}$ . So we have: $$\Delta f < \frac{1}{2\sqrt{n}}$$ So if we flip the coin $n$ times, we can be pretty confident our error in estimating the probability is at most $\frac{1}{2\sqrt{n}}$ . Rearranging: $$n<\frac{1}{4(\Delta f)^2}$$ So to measure the probability with an error of $\Delta f$ we can be pretty confident we'll need to flip the coin $\frac{1}{4(\Delta f)^2}$ times at most. Then for example, if I want to determine the probability of the coin landing of Heads within an error of 5%, I'll need to flip it at most 100 times. Is this reasoning correct?","This is a conclusion I came to through very basic knowledge of statistics and error analysis. Suppose we want to determine the fairness of a coin. To do this, we need to determine the probability of the coin landing on either Heads or Tails and we do this through repeated flipping. We have an amount of uncertainty we are willing to allow in our measurement of the probability. We define the variable as follows: Then our measurement of the probability of the coin landing on heads is equal to the sample average of , . The formula for the standard error of the measurement of through samples is: Now, since can only have values and , its standard deviation cannot be greater than . So we have: So if we flip the coin times, we can be pretty confident our error in estimating the probability is at most . Rearranging: So to measure the probability with an error of we can be pretty confident we'll need to flip the coin times at most. Then for example, if I want to determine the probability of the coin landing of Heads within an error of 5%, I'll need to flip it at most 100 times. Is this reasoning correct?","f f = 
\begin{cases}
1, & \text{if the coin lands on Heads} \\
0, & \text{if the coin lands on Tails}
\end{cases} P(H) f \bar f f n \Delta f = \frac{\sigma_f}{\sqrt{n}} f 0 1 \frac{1}{2} \Delta f < \frac{1}{2\sqrt{n}} n \frac{1}{2\sqrt{n}} n<\frac{1}{4(\Delta f)^2} \Delta f \frac{1}{4(\Delta f)^2}","['probability', 'statistics', 'standard-deviation', 'standard-error']"
98,Asymptotic distribution of $\frac{1}{n m} \sum_{i=1}^n \sum_{j=1}^m 1(X_i > Y_j)$,Asymptotic distribution of,\frac{1}{n m} \sum_{i=1}^n \sum_{j=1}^m 1(X_i > Y_j),"Suppose that $X_1, ..., X_n$ are i.i.d. draws of some random variable $X$ ; likewise, $Y_1, ..., Y_m$ are i.i.d. draws of some random variable $Y$ . If we want to estimate $P(X > Y)$ , we may consider the fraction of all the $(X_i, Y_j)$ pairs which have the property that $X_i > Y_j$ . That is, consider $$\frac{1}{n m} \sum_{i=1}^n \sum_{j=1}^m 1(X_i > Y_j) = \frac{1}{n m} \sum_{i, j} 1(X_i > Y_j)$$ where $1$ is the indicator function. One sees that this is an unbiased estimator of $P(X > Y)$ : $$ E[\frac{1}{n m} \sum_{i=1}^n \sum_{j=1}^m 1(X_i > Y_j)] = \frac{1}{n m} \sum_{i=1}^n \sum_{j=1}^m E[1(X_i > Y_j)] = \frac{nm}{nm}P(X > Y) = P(X > Y)$$ I have two (related) questions, however: (1) Can one show that our estimator is consistent using (something like) the law of large numbers? I'm a bit confused here since the LLN usually applies to a simple sample average (with a single summation). (2) Can one show that our estimator is asymptotically normal using (something like) the central limit theorem?","Suppose that are i.i.d. draws of some random variable ; likewise, are i.i.d. draws of some random variable . If we want to estimate , we may consider the fraction of all the pairs which have the property that . That is, consider where is the indicator function. One sees that this is an unbiased estimator of : I have two (related) questions, however: (1) Can one show that our estimator is consistent using (something like) the law of large numbers? I'm a bit confused here since the LLN usually applies to a simple sample average (with a single summation). (2) Can one show that our estimator is asymptotically normal using (something like) the central limit theorem?","X_1, ..., X_n X Y_1, ..., Y_m Y P(X > Y) (X_i, Y_j) X_i > Y_j \frac{1}{n m} \sum_{i=1}^n \sum_{j=1}^m 1(X_i > Y_j) = \frac{1}{n m} \sum_{i, j} 1(X_i > Y_j) 1 P(X > Y)  E[\frac{1}{n m} \sum_{i=1}^n \sum_{j=1}^m 1(X_i > Y_j)] = \frac{1}{n m} \sum_{i=1}^n \sum_{j=1}^m E[1(X_i > Y_j)] = \frac{nm}{nm}P(X > Y) = P(X > Y)","['probability', 'statistics']"
99,What makes the Mean Squared Error so special compared to other upper bounds?,What makes the Mean Squared Error so special compared to other upper bounds?,,"Let $X$ be some measure space (esp probability space), $Y$ some metric space and we consider $g:X\to Y$ as an estimator for $f:X\to Y$ . It seems convenient to consider an estimation as 'good' in case for any small $\epsilon > 0$ the measure $ \mu(\{d(f,g) > \epsilon\}) $ is small. Using Markov's Inequality we have for any $h:\mathbb{R}\to \mathbb{R}$ that is positive and non decreasing on $\mathbb{R}_{\geq 0}$ that: $$ \mu(\{d(f,g) > \epsilon\}) \quad \leq \quad  \frac{1}{h(\epsilon)} \int_X h(d(f,g))\; d\mu $$ Thus, there is a lot of choices for upper bounds choosing different $h$ (x^n, exp, ..). Nevertheless, it seems that mostly only the Mean Squared Error of $f$ and $g$ (where $h=x^2$ ) is considered and we try to find a $g$ that minimizes the Mean Squared Error. What makes it so special compared to other choices? Why don't we use another $h$ and find an estimator $g$ minimizing $\int_X h(d(f,g))\; d\mu$ ?","Let be some measure space (esp probability space), some metric space and we consider as an estimator for . It seems convenient to consider an estimation as 'good' in case for any small the measure is small. Using Markov's Inequality we have for any that is positive and non decreasing on that: Thus, there is a lot of choices for upper bounds choosing different (x^n, exp, ..). Nevertheless, it seems that mostly only the Mean Squared Error of and (where ) is considered and we try to find a that minimizes the Mean Squared Error. What makes it so special compared to other choices? Why don't we use another and find an estimator minimizing ?","X Y g:X\to Y f:X\to Y \epsilon > 0  \mu(\{d(f,g) > \epsilon\})  h:\mathbb{R}\to \mathbb{R} \mathbb{R}_{\geq 0}  \mu(\{d(f,g) > \epsilon\}) \quad \leq \quad  \frac{1}{h(\epsilon)} \int_X h(d(f,g))\; d\mu  h f g h=x^2 g h g \int_X h(d(f,g))\; d\mu","['statistics', 'optimization', 'estimation']"
