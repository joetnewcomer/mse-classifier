,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Conformal mapping from a wedge to the upper half complex plane,Conformal mapping from a wedge to the upper half complex plane,,"I found (L. J. Laslett, "" On Intensity Limitations Imposed by Transverse Space-Charge Effects in Circular Particle Accelerators "", Proceedings of The 1963 Summer Study on Storage Rings, Accelerators and Experimentation at Super-High Energies , Lawrence Radiation Laboratory, 1963 pp. 324-367) a conformal mapping formula which is supposed to map a wedge (coordinate $z=-X$ ) with an angle of $2\alpha$ at the sharp corner into the upper half plane. The sharp corner of the wedge is mapped to $z=0$ . $$z' =ic'\left(\frac{z}{X} +1\right)^{\frac{\pi}{2\alpha}}$$ Does this conformal transformation indeed map a wedge on the upper half plane? If I parametrize the points on the upper flank of the wedge  by (I represent here the complex numbers as vector $ z=x+iy = (x,y)^T$ ): $$z = \left(\begin{array}{c} -X \\ 0\end{array}\right) + t\left(\begin{array}{c} 1 \\ \tan(\alpha)\end{array}\right)$$ with $t=[0,  \infty]$ I have difficulties to see that $z'$ ends up to be a real number -- i.e. the lower limit of the upper plane. Moreover I wonder of the role of the parameter $c'$ . Is it  free or does it depend on $X$ or $\alpha$ ? Thank you for any help.","I found (L. J. Laslett, "" On Intensity Limitations Imposed by Transverse Space-Charge Effects in Circular Particle Accelerators "", Proceedings of The 1963 Summer Study on Storage Rings, Accelerators and Experimentation at Super-High Energies , Lawrence Radiation Laboratory, 1963 pp. 324-367) a conformal mapping formula which is supposed to map a wedge (coordinate ) with an angle of at the sharp corner into the upper half plane. The sharp corner of the wedge is mapped to . Does this conformal transformation indeed map a wedge on the upper half plane? If I parametrize the points on the upper flank of the wedge  by (I represent here the complex numbers as vector ): with I have difficulties to see that ends up to be a real number -- i.e. the lower limit of the upper plane. Moreover I wonder of the role of the parameter . Is it  free or does it depend on or ? Thank you for any help.","z=-X 2\alpha z=0 z' =ic'\left(\frac{z}{X} +1\right)^{\frac{\pi}{2\alpha}}  z=x+iy = (x,y)^T z = \left(\begin{array}{c} -X \\ 0\end{array}\right) + t\left(\begin{array}{c} 1 \\ \tan(\alpha)\end{array}\right) t=[0,  \infty] z' c' X \alpha","['complex-analysis', 'conformal-geometry']"
1,"How do I prove the ""mean value property"" for Helmholtz equation?","How do I prove the ""mean value property"" for Helmholtz equation?",,"Suppose $u: \mathbb{R}^2 \to \mathbb{R}$ is a $C^2$ function that satisfies the Helmholtz equation $-\Delta u = \lambda u$ for $\lambda \in \mathbb{R}$ . I am trying to prove something that looks like a modified mean value property, namely that $$\frac{1}{2\pi r}\int_{\partial B(z_0,r)} u \,\mathrm{d}\Gamma = \begin{cases} u(z_0) \cdot J_0(\sqrt{\lambda} r) &\quad \text{if } \lambda > 0\\ u(z_0) &\quad\text{if } \lambda = 0\\ u(z_0) \cdot I_0(\sqrt{-\lambda} r) &\quad\text{if }\lambda < 0\end{cases}$$ I used polar coordinates and tried to approach the equation with separation of variables, saying that $u(r, \theta) = R(r) \Theta(\theta)$ . I got $\Theta(\theta) = C_1 e^{i m \theta} + C_2 e^{- i m \theta}$ , from the equation $$ \partial_{\theta}^2 \Theta = - C \Theta $$ For $R(r)$ , I got the (modified / standard, depending on $\lambda$ ) Bessel equation. However, I don't know how to proceed. If $\Theta(\theta)$ was a harmonic function, I could simply integrate and put the Bessel part before the integral and then apply the mean value theorem. However, I am stuck, since it is not a harmonic function. Ultimately, I have three questions; What is the justification for using separation of variables? I have used it, but I don't know if I can, since the statements is phrased for every solution of the Helmholtz equation; what if there are solutions that don't have separated variables? When solving the Bessel equation, we get multiple solutions $J_m$ and when solving the modified Bessel equations, we get multiple solutions $I_m$ . Why are there only $J_0$ and $I_0$ in the final result? As mentioned above, how do I proceed to actually show this property?","Suppose is a function that satisfies the Helmholtz equation for . I am trying to prove something that looks like a modified mean value property, namely that I used polar coordinates and tried to approach the equation with separation of variables, saying that . I got , from the equation For , I got the (modified / standard, depending on ) Bessel equation. However, I don't know how to proceed. If was a harmonic function, I could simply integrate and put the Bessel part before the integral and then apply the mean value theorem. However, I am stuck, since it is not a harmonic function. Ultimately, I have three questions; What is the justification for using separation of variables? I have used it, but I don't know if I can, since the statements is phrased for every solution of the Helmholtz equation; what if there are solutions that don't have separated variables? When solving the Bessel equation, we get multiple solutions and when solving the modified Bessel equations, we get multiple solutions . Why are there only and in the final result? As mentioned above, how do I proceed to actually show this property?","u: \mathbb{R}^2 \to \mathbb{R} C^2 -\Delta u = \lambda u \lambda \in \mathbb{R} \frac{1}{2\pi r}\int_{\partial B(z_0,r)} u \,\mathrm{d}\Gamma = \begin{cases} u(z_0) \cdot J_0(\sqrt{\lambda} r) &\quad \text{if } \lambda > 0\\ u(z_0) &\quad\text{if } \lambda = 0\\ u(z_0) \cdot I_0(\sqrt{-\lambda} r) &\quad\text{if }\lambda < 0\end{cases} u(r, \theta) = R(r) \Theta(\theta) \Theta(\theta) = C_1 e^{i m \theta} + C_2 e^{- i m \theta}  \partial_{\theta}^2 \Theta = - C \Theta  R(r) \lambda \Theta(\theta) J_m I_m J_0 I_0","['real-analysis', 'complex-analysis', 'special-functions', 'harmonic-analysis', 'bessel-functions']"
2,How do I evaluate this integral using Cauchy's theorem?,How do I evaluate this integral using Cauchy's theorem?,,"I have a physic paper to do and one of the question is to demonstrate this equality using Cauchy's theorem : $$\int_{-\infty}^{\infty} e^{i\zeta^2 sgn \varphi''(k_0) } d\zeta = \sqrt{\Pi} e^{\frac{i\Pi}{4}*sng \varphi''(k_0)}$$ sng being the sign function What I have used to try to solve this is this calculation : With $x=\zeta$ and $a=-i*sng\varphi''(k_0)$ , we have : \begin{align*} I &= \int_{-\infty}^{\infty} e^{-ax^2 } dx \\  I^2 &= \int_{-\infty}^{\infty} e^{-ax^2 } dx \int_{-\infty}^{\infty} e^{-ay^2 } dy \\ &=\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} e^{-ax^2 } e^{-ay^2 } dxdy \\ &=\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} e^{-a(x^2+y^2) } dxdy \\ &=\int_{0}^{2\pi} \int_{0}^{\infty} e^{-ar^2} rdrd\theta \\ &=2\pi \int_{0}^{\infty} e^{-u} \frac{du}{2a} \\ I^2 &=\frac{\pi}{a} \end{align*} So $$I=\sqrt{\frac{\pi}{a}}$$ Therefore $$\int_{-\infty}^{\infty} e^{i\zeta^2 sgn \varphi''(k_0) } d\zeta = \sqrt{\frac{\pi}{-i*sgn \varphi''(k_0)}} = \sqrt{\pi * i * sgn   \varphi''(k_0)}$$ The result I have is far from what I'm looking for. I also know that the fact that a is complex might make my calculations false, but I have to say that I'm quite lost. I didn't understand how to use Cauchy's theorem for this problem. If anyone could help me I would be very greatful ! :) Thanks in advance and have a good day","I have a physic paper to do and one of the question is to demonstrate this equality using Cauchy's theorem : sng being the sign function What I have used to try to solve this is this calculation : With and , we have : So Therefore The result I have is far from what I'm looking for. I also know that the fact that a is complex might make my calculations false, but I have to say that I'm quite lost. I didn't understand how to use Cauchy's theorem for this problem. If anyone could help me I would be very greatful ! :) Thanks in advance and have a good day","\int_{-\infty}^{\infty} e^{i\zeta^2 sgn \varphi''(k_0) } d\zeta = \sqrt{\Pi} e^{\frac{i\Pi}{4}*sng \varphi''(k_0)} x=\zeta a=-i*sng\varphi''(k_0) \begin{align*}
I &= \int_{-\infty}^{\infty} e^{-ax^2 } dx \\ 
I^2 &= \int_{-\infty}^{\infty} e^{-ax^2 } dx \int_{-\infty}^{\infty} e^{-ay^2 } dy \\
&=\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} e^{-ax^2 } e^{-ay^2 } dxdy \\
&=\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} e^{-a(x^2+y^2) } dxdy \\
&=\int_{0}^{2\pi} \int_{0}^{\infty} e^{-ar^2} rdrd\theta \\
&=2\pi \int_{0}^{\infty} e^{-u} \frac{du}{2a} \\
I^2 &=\frac{\pi}{a}
\end{align*} I=\sqrt{\frac{\pi}{a}} \int_{-\infty}^{\infty} e^{i\zeta^2 sgn \varphi''(k_0) } d\zeta = \sqrt{\frac{\pi}{-i*sgn \varphi''(k_0)}} = \sqrt{\pi * i * sgn   \varphi''(k_0)}","['integration', 'complex-analysis', 'mathematical-physics', 'cauchy-integral-formula']"
3,"Compute $\int_0^\infty \frac{\sin(ax)}{b^2+x^2}~dx$, where $a>0, b>0$","Compute , where","\int_0^\infty \frac{\sin(ax)}{b^2+x^2}~dx a>0, b>0","If the $\sin(ax)$ function is replaced by $\cos (ax)$ , it's well known and can be solved by many ways. But if we want to solve the sine version integral, i.e. $$I=\int_0^\infty \frac{\sin(ax)}{b^2+x^2}~dx$$ It seems not that trivial as thought. Let $x=bt, k=ab,$ $$I=\frac{1}b\int_0^\infty \frac{\sin(kt)}{1+t^2}~dt,~~~~F=F(k)=\int_0^\infty \frac{\sin(kt)}{1+t^2}~dt$$ Now, we compute $F$ : $$F'=\int_0^\infty \frac{t\cos(kt)}{1+t^2}~dt~~ \overset{\theta=kt}{\longrightarrow} ~~F'=\int_0^\infty \frac{\theta\cos(\theta)}{k^2+\theta^2}d\theta$$ Take second derivative $$F''=-\int_0^\infty \frac{2k\theta\cos(\theta)}{(k^2+\theta^2)^2}d\theta=\int_0^\infty k\cos(\theta)d\left(\frac{1}{k^2+\theta^2}\right)$$ Integration by part $$F''=-\frac{1}k+\int_0^\infty \frac{k\sin(\theta)}{k^2+\theta^2}d\theta~~ \overset{\theta=kt}{\longrightarrow} ~~F''=-\frac{1}k+\int_0^\infty \frac{\sin(kt)}{1+t^2}dt$$ Therefore, $$F''(k)=-\frac{1}k+F(k)$$ Solve this 2nd order inhomogeneous differential equation and we get $$F(k)=c_1 e^k+c_2 e^{-k}+\text{P.V}\left(\frac{1}2e^k\int_k^\infty \frac{e^{-t}}{t}dt+\frac{1}2e^{-k}\int^k_{-\infty} \frac{e^{t}}{t}dt\right)$$ Define: $\displaystyle\text{Ei}(z)=\text{P.V}\left(-\int_{-z}^\infty \frac{e^{-t}}{t}dt\right)$ , we get $$F(k)=c_1 e^k+c_2 e^{-k}+\frac{1}2\left(-e^k\text{Ei}(-k)+e^{-k}\text{Ei}(k)\right)$$ From the integral $\displaystyle F(k)=\int_0^\infty \frac{\sin(kt)}{1+t^2}~dt$ we can see $F(0)=0$ and $\displaystyle\lim_{k\to\infty} F(k)$ is bounded, hence, $c_1=c_2=0$ $$\int_0^\infty \frac{\sin(kt)}{1+t^2}~dt=\frac{-e^k\text{Ei}(-k)+e^{-k}\text{Ei}(k)}2$$ Finally, $$\boxed{\int_0^\infty \frac{\sin(ax)}{b^2+x^2}~dx=\frac{-e^{ab}\text{Ei}(-ab)+e^{-ab}\text{Ei}(ab)}{2b}}$$ It seems this is the simplest form I can get. Are there other simple ways to solve this integral, such as contour integral, etc?","If the function is replaced by , it's well known and can be solved by many ways. But if we want to solve the sine version integral, i.e. It seems not that trivial as thought. Let Now, we compute : Take second derivative Integration by part Therefore, Solve this 2nd order inhomogeneous differential equation and we get Define: , we get From the integral we can see and is bounded, hence, Finally, It seems this is the simplest form I can get. Are there other simple ways to solve this integral, such as contour integral, etc?","\sin(ax) \cos (ax) I=\int_0^\infty \frac{\sin(ax)}{b^2+x^2}~dx x=bt, k=ab, I=\frac{1}b\int_0^\infty \frac{\sin(kt)}{1+t^2}~dt,~~~~F=F(k)=\int_0^\infty \frac{\sin(kt)}{1+t^2}~dt F F'=\int_0^\infty \frac{t\cos(kt)}{1+t^2}~dt~~ \overset{\theta=kt}{\longrightarrow} ~~F'=\int_0^\infty \frac{\theta\cos(\theta)}{k^2+\theta^2}d\theta F''=-\int_0^\infty \frac{2k\theta\cos(\theta)}{(k^2+\theta^2)^2}d\theta=\int_0^\infty k\cos(\theta)d\left(\frac{1}{k^2+\theta^2}\right) F''=-\frac{1}k+\int_0^\infty \frac{k\sin(\theta)}{k^2+\theta^2}d\theta~~ \overset{\theta=kt}{\longrightarrow} ~~F''=-\frac{1}k+\int_0^\infty \frac{\sin(kt)}{1+t^2}dt F''(k)=-\frac{1}k+F(k) F(k)=c_1 e^k+c_2 e^{-k}+\text{P.V}\left(\frac{1}2e^k\int_k^\infty \frac{e^{-t}}{t}dt+\frac{1}2e^{-k}\int^k_{-\infty} \frac{e^{t}}{t}dt\right) \displaystyle\text{Ei}(z)=\text{P.V}\left(-\int_{-z}^\infty \frac{e^{-t}}{t}dt\right) F(k)=c_1 e^k+c_2 e^{-k}+\frac{1}2\left(-e^k\text{Ei}(-k)+e^{-k}\text{Ei}(k)\right) \displaystyle F(k)=\int_0^\infty \frac{\sin(kt)}{1+t^2}~dt F(0)=0 \displaystyle\lim_{k\to\infty} F(k) c_1=c_2=0 \int_0^\infty \frac{\sin(kt)}{1+t^2}~dt=\frac{-e^k\text{Ei}(-k)+e^{-k}\text{Ei}(k)}2 \boxed{\int_0^\infty \frac{\sin(ax)}{b^2+x^2}~dx=\frac{-e^{ab}\text{Ei}(-ab)+e^{-ab}\text{Ei}(ab)}{2b}}","['integration', 'complex-analysis', 'definite-integrals', 'improper-integrals', 'contour-integration']"
4,How to compute the following Complex integral,How to compute the following Complex integral,,"I am trying to compute the following complex-valued integral $(1.3.10)$ by using contour integration and the residue theorem. The substitution is shown right below $(1.3.10)$ and the answer is shown in $(1.3.11)$ . By goal is to reproduce $(1.3.11)$ . $$ Since $-\pi < k < \pi$ the contour integration should be clockwise around the unit circle. I will be using the residue theorem which is based on counterclockwise contours. We see $$ P(x,z) = \frac{1}{2\pi} \int_{-\pi}^{\pi} \frac{e^{-ikx} dk}{1 - z(pe^{ik} + qe^{-ik})} = \frac{1}{2\pi} \int_{\text{clockwise}} \frac{w^x idw/w}{1 - z(pw^* + qw)} = \frac{i}{2\pi}\int_{\text{clockwise}} \frac{w^{x-1}dw}{1 - z(pw^* + qw)} $$ $$ = -\frac{i}{2\pi}\int_{\text{counter clockwise}} \frac{w^{x-1}dw}{1 - z(pw^* + qw)} = \text{sum of residues} $$ The above seems to suggest that for $x < 1$ there are additional poles at $w = 0$ , and so it seemed that $P(x,z)$ would have two forms, one for $|x| < 1$ and $|x| \ge 1$ , but the answer seems to give one form for $P(x,z)$ . Does that mean $w = 0$ is never a pole regardless of the value of x? How do I get the final answer?","I am trying to compute the following complex-valued integral by using contour integration and the residue theorem. The substitution is shown right below and the answer is shown in . By goal is to reproduce . $$ Since the contour integration should be clockwise around the unit circle. I will be using the residue theorem which is based on counterclockwise contours. We see The above seems to suggest that for there are additional poles at , and so it seemed that would have two forms, one for and , but the answer seems to give one form for . Does that mean is never a pole regardless of the value of x? How do I get the final answer?","(1.3.10) (1.3.10) (1.3.11) (1.3.11) -\pi < k < \pi 
P(x,z) = \frac{1}{2\pi} \int_{-\pi}^{\pi} \frac{e^{-ikx} dk}{1 - z(pe^{ik} + qe^{-ik})} = \frac{1}{2\pi} \int_{\text{clockwise}} \frac{w^x idw/w}{1 - z(pw^* + qw)} = \frac{i}{2\pi}\int_{\text{clockwise}} \frac{w^{x-1}dw}{1 - z(pw^* + qw)}
 
= -\frac{i}{2\pi}\int_{\text{counter clockwise}} \frac{w^{x-1}dw}{1 - z(pw^* + qw)} = \text{sum of residues}
 x < 1 w = 0 P(x,z) |x| < 1 |x| \ge 1 P(x,z) w = 0","['complex-analysis', 'contour-integration', 'complex-integration']"
5,A uniformly bounded sequence of analytic functions converging on the boundary of the domain? [closed],A uniformly bounded sequence of analytic functions converging on the boundary of the domain? [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed last year . Improve this question Suppose that we have a sequence of analytic functions $f_n:D(0,\rho_n)\to\mathbb C$ where $(\rho_n)_n$ is a decreasing sequence of real numbers $>1$ that converges to $1$ . Assume furthermore that $|f_n(z)|\leq M$ for all $z\in D(0, \rho_n)$ and all $n=1,2,\ldots$ Suppose that $f_n$ converges to an analytic function $f$ on the open unit disc, uniformly on compact subsets. Question : Does $f_n$ converge (pointwise) on the unit circle?","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed last year . Improve this question Suppose that we have a sequence of analytic functions where is a decreasing sequence of real numbers that converges to . Assume furthermore that for all and all Suppose that converges to an analytic function on the open unit disc, uniformly on compact subsets. Question : Does converge (pointwise) on the unit circle?","f_n:D(0,\rho_n)\to\mathbb C (\rho_n)_n >1 1 |f_n(z)|\leq M z\in D(0, \rho_n) n=1,2,\ldots f_n f f_n","['complex-analysis', 'limits', 'uniform-convergence', 'analytic-functions', 'equicontinuity']"
6,Two complex numbers are symmetric with respect to a circle iff a certain equation is satisfied,Two complex numbers are symmetric with respect to a circle iff a certain equation is satisfied,,"Let $ \gamma  = $ { $z \in \mathbb{C} : |z-a| = R$ }. Two complex numbers $z_1,z_2$ are said to be symmetric with respect to $\gamma$ iff $$ (z_1-a)\overline{(z_2-a)} = R^2. $$ I am trying to prove that if $\forall \alpha,\beta \in \gamma$ , $$ \Bigg | \frac{z_1-\alpha}{z_2 - \alpha} \Bigg | =  \Bigg |\frac{z_1-\beta}{z_2 - \beta} \Bigg | \qquad \qquad (1)$$ then $z_1 $ and $z_2$ are symmetric with respect to $\gamma$ . I was able to prove the converse using the preliminary Möbius transformation $$ T(z) = \frac{R^2}{z-a} + \overline{a}$$ and properties of the cross-ratio, but, in trying to apply these techniques, I was not able to obtain any substantial progress. I need some help proving this result. I found the problem in one of my problem sheets in a course in complex analysis mainly based in Silverman's and Lang's textbooks on the subject. Addendum: Considering a comment that was erased, if one considers the transformation $$T(z) = \frac{z-\alpha}{z-\beta}$$ where $\alpha,\beta \in \gamma$ , $\alpha \neq \beta$ , we have, by hypothesis, that if $w_1 = T(z_1)$ and $w_2 = T(z_2)$ , $$ |w_1| = |w_2|$$ thus, if $w = (w_1 + w_2)/2$ , $w_1$ and $w_2$ are symmetric with respect to $L = \{ wt : t \in \mathbb{R}\}$ , which is a line that ""passes through"" $0$ and $\infty$ , thus, by symmetry preserving of Möbius transformations, $z_1$ and $z_2$ are symmetric with respect to some line or circle which contains $\alpha$ and $\beta$ . In addition, $\alpha $ and $\beta$ where chosen arbitrarily from $\alpha$ , thus, for any $\alpha, \beta, \delta \in \gamma$ , mutually distinct, $z_1$ and $z_2$ are symmetric with respect to a line or circle which contains $\alpha$ and $\beta$ and also with respect to a line or circle which passes through $\alpha$ and $\delta$ , however, transitivity of these properties, i.e. deducing that there exists a circle which contains $\alpha,\beta$ and $\gamma$ such that $z_1$ and $z_2$ are symmetric with respect to, seems distant to prove.","Let { }. Two complex numbers are said to be symmetric with respect to iff I am trying to prove that if , then and are symmetric with respect to . I was able to prove the converse using the preliminary Möbius transformation and properties of the cross-ratio, but, in trying to apply these techniques, I was not able to obtain any substantial progress. I need some help proving this result. I found the problem in one of my problem sheets in a course in complex analysis mainly based in Silverman's and Lang's textbooks on the subject. Addendum: Considering a comment that was erased, if one considers the transformation where , , we have, by hypothesis, that if and , thus, if , and are symmetric with respect to , which is a line that ""passes through"" and , thus, by symmetry preserving of Möbius transformations, and are symmetric with respect to some line or circle which contains and . In addition, and where chosen arbitrarily from , thus, for any , mutually distinct, and are symmetric with respect to a line or circle which contains and and also with respect to a line or circle which passes through and , however, transitivity of these properties, i.e. deducing that there exists a circle which contains and such that and are symmetric with respect to, seems distant to prove."," \gamma  =  z \in \mathbb{C} : |z-a| = R z_1,z_2 \gamma  (z_1-a)\overline{(z_2-a)} = R^2.  \forall \alpha,\beta \in \gamma  \Bigg | \frac{z_1-\alpha}{z_2 - \alpha} \Bigg | =  \Bigg |\frac{z_1-\beta}{z_2 - \beta} \Bigg | \qquad \qquad (1) z_1  z_2 \gamma  T(z) = \frac{R^2}{z-a} + \overline{a} T(z) = \frac{z-\alpha}{z-\beta} \alpha,\beta \in \gamma \alpha \neq \beta w_1 = T(z_1) w_2 = T(z_2)  |w_1| = |w_2| w = (w_1 + w_2)/2 w_1 w_2 L = \{ wt : t \in \mathbb{R}\} 0 \infty z_1 z_2 \alpha \beta \alpha  \beta \alpha \alpha, \beta, \delta \in \gamma z_1 z_2 \alpha \beta \alpha \delta \alpha,\beta \gamma z_1 z_2","['complex-analysis', 'mobius-transformation', 'cross-ratio']"
7,Where is my mistake in this reasoning?,Where is my mistake in this reasoning?,,"One can vertify that $1+\frac{1}{2}z^2+\frac{1}{2}z^3$ has no root in the disk $D(0,1.05)$ , so $f(z)=\dfrac{1}{1+\frac{1}{2}z^2+\frac{1}{2}z^3}$ should be analytic in $D(0,1.05)$ . Assume it has Taylor series: $$f(z)=\sum_{n=0}^\infty c_nz^n,z\in D(0,1.05)$$ On the other hand, note that when $z\in D(0,1)$ , $\frac{1}{2}z^2+\frac{1}{2}z^3\in D(0,1)$ . Since $\dfrac{1}{1+w}=\sum_{n=0}^\infty (-w)^n,w\in D(0,1)$ , we also obtain $$f(z)=\sum_{n=0}^\infty \left(-\frac{1}{2}z^2-\frac{1}{2}z^3\right)^n,z\in D(0,1)\subset D(0,1.05)$$ In $D(0,1)$ , the two series equal to each other, so they should have the same corresponding coefficients. Therefore they should also have the same convergence radius $R$ . By the first series, $R\geq 1.05$ . However, the second series is not convergent at $z=1$ , thus $R\leq 1$ . There is a contradiction!","One can vertify that has no root in the disk , so should be analytic in . Assume it has Taylor series: On the other hand, note that when , . Since , we also obtain In , the two series equal to each other, so they should have the same corresponding coefficients. Therefore they should also have the same convergence radius . By the first series, . However, the second series is not convergent at , thus . There is a contradiction!","1+\frac{1}{2}z^2+\frac{1}{2}z^3 D(0,1.05) f(z)=\dfrac{1}{1+\frac{1}{2}z^2+\frac{1}{2}z^3} D(0,1.05) f(z)=\sum_{n=0}^\infty c_nz^n,z\in D(0,1.05) z\in D(0,1) \frac{1}{2}z^2+\frac{1}{2}z^3\in D(0,1) \dfrac{1}{1+w}=\sum_{n=0}^\infty (-w)^n,w\in D(0,1) f(z)=\sum_{n=0}^\infty \left(-\frac{1}{2}z^2-\frac{1}{2}z^3\right)^n,z\in D(0,1)\subset D(0,1.05) D(0,1) R R\geq 1.05 z=1 R\leq 1","['calculus', 'sequences-and-series', 'complex-analysis', 'taylor-expansion']"
8,"Can this given $f: S^1\to \mathbb C$ be extended to a continuous $F: \overline{\mathbb D}\to \mathbb C, F$ is holomorphic on $\mathbb D$?",Can this given  be extended to a continuous  is holomorphic on ?,"f: S^1\to \mathbb C F: \overline{\mathbb D}\to \mathbb C, F \mathbb D","Suppose that $f: \mathbb S^1\to \mathbb C$ is continuous such that $f(z)=f(\bar z)$ for all $z\in \mathbb S^1$ . Can it be extended to a continuous $F: \overline{\mathbb D}\to \mathbb C$ such that $ F$ is holomorphic on $\mathbb D$ ? If $f$ is constant, then the result is obviously true. So suppose that $f$ is not constant. Suppose that such an extension $F$ exists. Take any $r\in (0.2,1)$ . For any $z\in D_{1/10}(0)$ , we have $$F(z)=\int_{|z|=r}F(u)/(u-z) \,du\tag 1$$ $(1)$ gives $F(z)=\sum_{k\ge 0}\left(\int_{|z|=r}\frac{F(u)}{u^{k+1}}\right)z^k=\sum_{k\ge 0} a_k(r) z^k$ , where $(r)$ denotes that $a_k$ depends upon $r$ . Calculations show that $2\pi r^ka_k(r)=\color{blue}{\int_0^{2\pi} F(re^{-i\theta})e^{ki\theta} \,d\theta}$ . By continuity of $F,F(re^{-i\theta})\overbrace{\to}^{r\to 1-} F(e^{-i\theta})$ $$\implies 2\pi a_k(r)\overbrace{\to}^{r\to 1-}\int_0^{2\pi} \color{blue}{F(e^{-i\theta})}e^{ki\theta} \,d\theta=\int_0^{2\pi} \color{blue}{F(e^{i\theta})}e^{ki\theta} \,d\theta=i\int_{|z|=1}F(z)z^{k-1}dz=0\,\forall k\ge 1$$ It follows that $a_k(r)\to 0$ as $r\to 1-$ . $\color{red}{\text{Since $z$ is fixed and power series representation is unique, we must have $a_k(r)=$ constant.}}$ Hence $a_k(r)=0$ for all $k\ge 1$ . It follows that $F$ is a constant in $D_{1/10}(0)$ , whence by identity theorem it follows that $F$ is constant which contradicts our assumption. So such an extension is not possible. Is this correct? I am not sure about validity of the read part. Can anyone please help me justify or disprove the red colored part? Thanks.","Suppose that is continuous such that for all . Can it be extended to a continuous such that is holomorphic on ? If is constant, then the result is obviously true. So suppose that is not constant. Suppose that such an extension exists. Take any . For any , we have gives , where denotes that depends upon . Calculations show that . By continuity of It follows that as . Hence for all . It follows that is a constant in , whence by identity theorem it follows that is constant which contradicts our assumption. So such an extension is not possible. Is this correct? I am not sure about validity of the read part. Can anyone please help me justify or disprove the red colored part? Thanks.","f: \mathbb S^1\to \mathbb C f(z)=f(\bar z) z\in \mathbb S^1 F: \overline{\mathbb D}\to \mathbb C  F \mathbb D f f F r\in (0.2,1) z\in D_{1/10}(0) F(z)=\int_{|z|=r}F(u)/(u-z) \,du\tag 1 (1) F(z)=\sum_{k\ge 0}\left(\int_{|z|=r}\frac{F(u)}{u^{k+1}}\right)z^k=\sum_{k\ge 0} a_k(r) z^k (r) a_k r 2\pi r^ka_k(r)=\color{blue}{\int_0^{2\pi} F(re^{-i\theta})e^{ki\theta} \,d\theta} F,F(re^{-i\theta})\overbrace{\to}^{r\to 1-} F(e^{-i\theta}) \implies 2\pi a_k(r)\overbrace{\to}^{r\to 1-}\int_0^{2\pi} \color{blue}{F(e^{-i\theta})}e^{ki\theta} \,d\theta=\int_0^{2\pi} \color{blue}{F(e^{i\theta})}e^{ki\theta} \,d\theta=i\int_{|z|=1}F(z)z^{k-1}dz=0\,\forall k\ge 1 a_k(r)\to 0 r\to 1- \color{red}{\text{Since z is fixed and power series representation is unique, we must have a_k(r)= constant.}} a_k(r)=0 k\ge 1 F D_{1/10}(0) F","['complex-analysis', 'continuity', 'power-series', 'cauchy-integral-formula']"
9,Computing a Fourier transform and imaginary part dependence,Computing a Fourier transform and imaginary part dependence,,"I would like to compute the following Fourier transform: $$\int_{-\infty}^\infty (1 + (x+it)^2)^{-s} e^{i x \xi} dx$$ and to explicitly see the dependence in $s$ , in particular the imaginary part. Since the variables are nonreal, I am not so sure what kind of change of variables can be done.","I would like to compute the following Fourier transform: and to explicitly see the dependence in , in particular the imaginary part. Since the variables are nonreal, I am not so sure what kind of change of variables can be done.",\int_{-\infty}^\infty (1 + (x+it)^2)^{-s} e^{i x \xi} dx s,"['integration', 'complex-analysis', 'analysis', 'fourier-analysis']"
10,Complex conjugate by complex integration,Complex conjugate by complex integration,,"By Cauchy's Theorem we have $ f(a)=\frac{1}{2\pi i}\int_{\gamma}\frac{f(w)}{w-a}dw $ where $\gamma$ is the path $\gamma(t)=b+re^{it},~t\in[0,2\pi],$ $a\in B_r(b)$ where $B_r(b)$ is the closed ball of radius $r$ with center $b,$ fully lying in the domain of $f.$ Now, in case of $f(z)=\bar{z},$ we can't apply Cauchy's Theorem as $f$ is not an analytic function. So my doubt is whether we can say $    \bar{a}=\frac{1}{2\pi i}\int_{\gamma}\frac{\bar{z}}{z-a}dz $ for the path $\gamma$ with center different from $a.$ Any counter example or suggestions or hints is fully appreciated. Thanks in advance. EDIT: There was a mistake in the question from my side. I have edited the question. This is what I tried so far. $\frac{1}{2\pi i}\int_{\gamma}\frac{\bar{z}}{z-a}dz\\ =\frac{1}{2\pi i}\int_{0}^{2\pi}\frac{(\bar{b}+re^{-i\theta})ire^{i\theta}d\theta}{(b-a)+re^{i\theta}}\\ =\frac{\bar{b}}{2\pi i}\int_0^{2\pi}\frac{ire^{i\theta}d\theta}{b-a+re^{i\theta}} +\frac{1}{2\pi}\int_0^{2\pi}\frac{r^2d\theta}{b-a+re^{i\theta}}\\ =\frac{\bar{b}}{2\pi i}\int_{\gamma}\frac{zdz}{z+b-a} +\frac{r^2}{2\pi}\int_0^{2\pi}\frac{d\theta}{b-a+re^{i\theta}}\\ =\bar{a}(b-a)+\frac{r^2}{2\pi}\int_0^{2\pi}\frac{d\theta}{b-a+re^{i\theta}} $ How to proceed further?","By Cauchy's Theorem we have where is the path where is the closed ball of radius with center fully lying in the domain of Now, in case of we can't apply Cauchy's Theorem as is not an analytic function. So my doubt is whether we can say for the path with center different from Any counter example or suggestions or hints is fully appreciated. Thanks in advance. EDIT: There was a mistake in the question from my side. I have edited the question. This is what I tried so far. How to proceed further?","
f(a)=\frac{1}{2\pi i}\int_{\gamma}\frac{f(w)}{w-a}dw
 \gamma \gamma(t)=b+re^{it},~t\in[0,2\pi], a\in B_r(b) B_r(b) r b, f. f(z)=\bar{z}, f 
   \bar{a}=\frac{1}{2\pi i}\int_{\gamma}\frac{\bar{z}}{z-a}dz
 \gamma a. \frac{1}{2\pi i}\int_{\gamma}\frac{\bar{z}}{z-a}dz\\
=\frac{1}{2\pi i}\int_{0}^{2\pi}\frac{(\bar{b}+re^{-i\theta})ire^{i\theta}d\theta}{(b-a)+re^{i\theta}}\\
=\frac{\bar{b}}{2\pi i}\int_0^{2\pi}\frac{ire^{i\theta}d\theta}{b-a+re^{i\theta}} +\frac{1}{2\pi}\int_0^{2\pi}\frac{r^2d\theta}{b-a+re^{i\theta}}\\
=\frac{\bar{b}}{2\pi i}\int_{\gamma}\frac{zdz}{z+b-a} +\frac{r^2}{2\pi}\int_0^{2\pi}\frac{d\theta}{b-a+re^{i\theta}}\\
=\bar{a}(b-a)+\frac{r^2}{2\pi}\int_0^{2\pi}\frac{d\theta}{b-a+re^{i\theta}}
","['complex-analysis', 'analysis', 'complex-integration', 'cauchy-integral-formula']"
11,Convergence of generalized hypergeometric function for the case $p=q+1$,Convergence of generalized hypergeometric function for the case,p=q+1,"it is known that the generalized hypergeometric function is defined by: \begin{equation} 	\label{e:pFq} 	{}_{p}F_q(\textbf{a};\textbf{b};z)=\sum_{n=0}^{\infty}\frac{(a_1)_n\cdots (a_p)_n}{(b_1)_n\cdots(b_q)_n}\frac{z^n}{n!}, \end{equation} where \begin{equation} 	\label{relposchgamma} 	(z)_n = \frac{\Gamma(z+n)}{\Gamma(z)} \end{equation} is the Pochammer symbol, $\textbf{a}\in\mathbb{C}^p$ , $\textbf{b}\in\mathbb{C}^q$ and $z\in\mathbb{C}$ . I am studying the case $p=q+1$ . On the one hand, I know by comparison limit test that it is absolutely convergent if $\alpha=\Re\left(\sum_{j=0}^{q}b_j-\sum_{j=0}^{q+1}a_j\right)>0$ . On the other hand, I read in the literature that if $\alpha\leq -1$ it is divergent; and, if $-1<\alpha\leq 0$ and $z\neq 1$ , the series converges, but I don't know how to prove it, so I would like you to give me some help to try it out. Thanks a lot, Ivan.","it is known that the generalized hypergeometric function is defined by: where is the Pochammer symbol, , and . I am studying the case . On the one hand, I know by comparison limit test that it is absolutely convergent if . On the other hand, I read in the literature that if it is divergent; and, if and , the series converges, but I don't know how to prove it, so I would like you to give me some help to try it out. Thanks a lot, Ivan.","\begin{equation}
	\label{e:pFq}
	{}_{p}F_q(\textbf{a};\textbf{b};z)=\sum_{n=0}^{\infty}\frac{(a_1)_n\cdots (a_p)_n}{(b_1)_n\cdots(b_q)_n}\frac{z^n}{n!},
\end{equation} \begin{equation}
	\label{relposchgamma}
	(z)_n = \frac{\Gamma(z+n)}{\Gamma(z)}
\end{equation} \textbf{a}\in\mathbb{C}^p \textbf{b}\in\mathbb{C}^q z\in\mathbb{C} p=q+1 \alpha=\Re\left(\sum_{j=0}^{q}b_j-\sum_{j=0}^{q+1}a_j\right)>0 \alpha\leq -1 -1<\alpha\leq 0 z\neq 1","['complex-analysis', 'analysis', 'convergence-divergence', 'hypergeometric-function', 'absolute-convergence']"
12,Differential form $\sqrt{z}dz$ does not transform uniquely?,Differential form  does not transform uniquely?,\sqrt{z}dz,"On page 107 of his Algebraic Curves and Riemann surfaces Miranda writes The definition of a meromorphic or holomorphic $1$ -form $\omega$ suggests that in order to define $\omega$ on a Riemann surface $X$ , one must give local expression for $\omega$ (of the form $f(z)dz$ ) in each chart of an atlas for $X$ . In fact, one can define $\omega$ by giving a single formula in a single chart. […] A [second] problem may arise, namely that the local expression does not transform uniquely to the other points of $X$ . For example, consider the meromorphic $1$ -form $\sqrt{z}dz$ defined on the complex plane with the negative axis removed, where the branch of the square root is chosen so that $\sqrt{1}=1$ . This can be extended to the negative real axis but not uniquely. Hence we do not obtain a meromorphic $1$ -form on the whole of $\mathbb{C}^*$ . I am not sure that I understand this paragraph. Miranda seems to consider the chart $\phi\colon \mathbb{C}\setminus \mathbb{R}_{\leq 0}\rightarrow \mathbb{C}\setminus \mathbb{R}_{\leq0};z\mapsto z$ . Denote the corresponding local coordinate by $z$ . Then we considers the $1$ -form $\sqrt{z}dz$ , where $\sqrt{-}$ denotes the principal branch of the square root. Now, what is meant by the above sentence marked in bold? The principal branch of the square root function cannot be extended to a global holomorphic function. Does Miranda refer to the fact that it can locally be analytically continued so that one obtains a holomorphic function $f\colon U\rightarrow V$ such that $\mathbb{R}_{\leq 0}\subset U$ and $f(z)=\sqrt{z}$ for $z\in U\cap(\mathbb{C}\setminus \mathbb{R}_{\leq0})$ ? And this extension is not unique?","On page 107 of his Algebraic Curves and Riemann surfaces Miranda writes The definition of a meromorphic or holomorphic -form suggests that in order to define on a Riemann surface , one must give local expression for (of the form ) in each chart of an atlas for . In fact, one can define by giving a single formula in a single chart. […] A [second] problem may arise, namely that the local expression does not transform uniquely to the other points of . For example, consider the meromorphic -form defined on the complex plane with the negative axis removed, where the branch of the square root is chosen so that . This can be extended to the negative real axis but not uniquely. Hence we do not obtain a meromorphic -form on the whole of . I am not sure that I understand this paragraph. Miranda seems to consider the chart . Denote the corresponding local coordinate by . Then we considers the -form , where denotes the principal branch of the square root. Now, what is meant by the above sentence marked in bold? The principal branch of the square root function cannot be extended to a global holomorphic function. Does Miranda refer to the fact that it can locally be analytically continued so that one obtains a holomorphic function such that and for ? And this extension is not unique?",1 \omega \omega X \omega f(z)dz X \omega X 1 \sqrt{z}dz \sqrt{1}=1 1 \mathbb{C}^* \phi\colon \mathbb{C}\setminus \mathbb{R}_{\leq 0}\rightarrow \mathbb{C}\setminus \mathbb{R}_{\leq0};z\mapsto z z 1 \sqrt{z}dz \sqrt{-} f\colon U\rightarrow V \mathbb{R}_{\leq 0}\subset U f(z)=\sqrt{z} z\in U\cap(\mathbb{C}\setminus \mathbb{R}_{\leq0}),"['complex-analysis', 'differential-forms', 'riemann-surfaces', 'branch-cuts']"
13,"Rudin's RCA, Theorem $4.12 $","Rudin's RCA, Theorem",4.12 ,"There are things that we need for the proof of the theorem: ] 1 There is the theorem: If $L$ is a continuous linear functional on $H$ , then there is a unique $y$ $\in$ $H$ such that $Lx$ $=$ $(x,y)$ ( $x$ $\in$ $H$ ). There is the proof: If $Lx$ $=$ $0$ for all $x$ , take $y$ $=$ $0$ . Otherwise, define $M$ $=$ ${x: Lx = 0 }$ . The linearity of $L$ shows that $M$ is a subspace. The continuity of $L$ shows that $M$ is closed. Since $Lx$ $\neq$ $0$ for some $x$ $\in$ $H$ , Theorem $4.11$ shows that $M^\bot$ does not consist of $0$ alone. Hence there exists $z$ $\in$ $M^\bot$ , with $||z||$ $=$ $1$ . Put $u$ $=$ $(Lx)z$ $-$ $(Lz)x$ . Since $Lu$ $=$ $(Lx)(Lz)$ $-$ $(Lz)(Lx)$ $=$ $0$ , we have $u$ $\in$ $M$ . Thus $(u,z)$ $=$ $0$ . This gives $Lx$ $=$ $(Lx)$$(z,z)$ $=$ $(Lz)$$(x,z)$ . Thus the theorem holds with $y$ $=$ $\alpha z$ , where $\bar \alpha$ $=$ $Lz$ . I don't understand why do we get $y$ $=$ $0$ if $Lx$ $=$ $0$ for all $x$ . I also don't understand why is $Lu$ equal of $(Lx)(Lz)$ $-$ $(Lz)(Lx)$ and how does it give $Lx$ $=$ $(Lx)$$(z,z)$ $=$ $(Lz)$$(x,z)$ , and why does theorem hold when $y$ $=$ $\alpha z$ , where $\bar \alpha$ $=$ $Lz$ ? Any help would be appreciated.","There are things that we need for the proof of the theorem: ] 1 There is the theorem: If is a continuous linear functional on , then there is a unique such that ( ). There is the proof: If for all , take . Otherwise, define . The linearity of shows that is a subspace. The continuity of shows that is closed. Since for some , Theorem shows that does not consist of alone. Hence there exists , with . Put . Since , we have . Thus . This gives . Thus the theorem holds with , where . I don't understand why do we get if for all . I also don't understand why is equal of and how does it give , and why does theorem hold when , where ? Any help would be appreciated.","L H y \in H Lx = (x,y) x \in H Lx = 0 x y = 0 M = {x: Lx = 0 } L M L M Lx \neq 0 x \in H 4.11 M^\bot 0 z \in M^\bot ||z|| = 1 u = (Lx)z - (Lz)x Lu = (Lx)(Lz) - (Lz)(Lx) = 0 u \in M (u,z) = 0 Lx = (Lx)(z,z) = (Lz)(x,z) y = \alpha z \bar \alpha = Lz y = 0 Lx = 0 x Lu (Lx)(Lz) - (Lz)(Lx) Lx = (Lx)(z,z) = (Lz)(x,z) y = \alpha z \bar \alpha = Lz","['real-analysis', 'complex-analysis', 'analysis', 'linear-transformations', 'hilbert-spaces']"
14,Show that $(S_n)_{n\in\mathbb{N}}$ is tight,Show that  is tight,(S_n)_{n\in\mathbb{N}},"Let $(X_n)_{n\in\mathbb{N}}$ be independent Bernoulli random variables such that $$\mathbf{P}(X_{n}=1)=1-\mathbf{P}(X_{n}=0)=1/n^2.$$ Set $S_{n}:=X_1+\cdots+X_n.$ Show that $(S_n)_{n\in\mathbb{N}}$ is tight. For each $n$ , $X_{k}$ $(1\le k\le n)$ be independent random variables with characteristic function $\phi_{X_k}(t)=(1-\frac{1}{k^2})+\frac{1}{k^2}e^{it} (1\le k\le n).$ Then $$\phi_{S_{n}}(t)=E\exp(itS_{n})=\prod_{k=1}^{n}(1+\frac{1}{k^2}(e^{it}-1))$$ By Lévy’s continuity theorem, If $\phi_{S_{n}}(t)$ converges pointwise to a  limit $\phi_{S_{\infty}}(t)$ that is continuous at $0$ , then the asssociated sequence of distributions $S_{n}$ is tight. But how can I find the $\phi_{S_{\infty}}(t):=\displaystyle \lim_{ n\to \infty}\phi_{S_{n}}(t), t\in \mathbb{R}$ ,which is continuous at $0$ ?","Let be independent Bernoulli random variables such that Set Show that is tight. For each , be independent random variables with characteristic function Then By Lévy’s continuity theorem, If converges pointwise to a  limit that is continuous at , then the asssociated sequence of distributions is tight. But how can I find the ,which is continuous at ?","(X_n)_{n\in\mathbb{N}} \mathbf{P}(X_{n}=1)=1-\mathbf{P}(X_{n}=0)=1/n^2. S_{n}:=X_1+\cdots+X_n. (S_n)_{n\in\mathbb{N}} n X_{k} (1\le k\le n) \phi_{X_k}(t)=(1-\frac{1}{k^2})+\frac{1}{k^2}e^{it} (1\le k\le n). \phi_{S_{n}}(t)=E\exp(itS_{n})=\prod_{k=1}^{n}(1+\frac{1}{k^2}(e^{it}-1)) \phi_{S_{n}}(t) \phi_{S_{\infty}}(t) 0 S_{n} \phi_{S_{\infty}}(t):=\displaystyle \lim_{ n\to \infty}\phi_{S_{n}}(t), t\in \mathbb{R} 0","['complex-analysis', 'probability-theory', 'characteristic-functions']"
15,Curves where holomorphic function is real valued through a critical point.,Curves where holomorphic function is real valued through a critical point.,,"Let $f:\Omega\to \mathbb{C}$ be a holomorphic function, where $\Omega$ is an open set containing $\alpha\in \mathbb{R}$ , and suppose that $f\big|_{\Omega \hspace{0.5mm} \cap \hspace{0.5mm}\mathbb{R}}$ is real valued (so that $f^{(k)}(\alpha)$ are real valued for all $k$ ). Suppose that $f'(\alpha)=0$ and that $f''(\alpha)\ne 0$ . For $r>0$ such that $\{z\in \mathbb{C}:|z-\alpha|\le r\}\subset \Omega$ , define $g=g_{r}:[0,2\pi)\to \mathbb{C}$ by $$g(\theta)=f(\alpha+r\text{e}^{\theta i}).$$ I am trying to prove that there exists a $r_0>0$ , such that for all $0<r\le r_0$ , there are exactly four distinct values $\theta_1, \theta_2, \theta_3, \theta_4\in [0,2\pi)$ such that $g(\theta_i)\in \mathbb{R}$ . What I amble to do, and where my approach falls short. If we use a power series expansion about $\alpha$ , we have $$f(\alpha+r\text{e}^{\theta i})=f(\alpha)+\frac{1}{2}r^2\text{e}^{2\theta i}f''(\alpha)+R(r,\theta)$$ with $R(r,\theta)=O(r^3)$ uniformly in $\theta$ as $r\to 0^{+}$ . If $C>0$ is such that $|R(r,\theta)|\le Cr^3$ for $r$ sufficiently small, then by geometric considerations, the argument of $\frac{1}{2}r^2\text{e}^{2\theta i}f''(\alpha)+R(r,\theta)$ cannot differ from $2\theta=\text{arg}(\frac{1}{2}r^2\text{e}^{2\theta i}f''(\alpha))$ by more than $\theta^{\ast}$ , as shown in the image below: Here $P=\frac{1}{2}r^2\text{e}^{2\theta i}f''(\alpha)$ , $|P-Q|=Cr^3$ and $\angle P Q 0$ is a right angle. Thus, $\theta^{\ast}=\arcsin(\frac{2Cr}{f''(\alpha)})=O(r)$ as $r\to 0^{+}$ . This allows me to write $$f(\alpha+r\text{e}^{\theta i})-f(\alpha)=(\frac{1}{2}r^2f''(\alpha)+O(r^3))\text{e}^{(2\theta +O(r))i}.$$ For sufficiently small $r$ , this allows me to conclude that there are at least four values of $\theta$ such that $g(\theta)$ is real valued, given by $$\theta_1=0, \hspace{4mm} \theta_2\approx \frac{\pi}{2}, \hspace{4mm} \theta_3=\pi, \hspace{4mm} \theta_3\approx \frac{3\pi}{2}.$$ The problem is that I am unable to show that there are exactly 4 zeros when $r$ is sufficiently small. I have tried bounding the number of zeros of $$h(z)=\frac{1}{2i}(f(\alpha+r\text{e}^{zi})-f(\alpha+r\text{e}^{-zi}))$$ on the real line using different techinques, but the bounds I get are not much better than 16 zeros, which is not good enough (you may assume that $f$ satisfies $f(\overline{z})=\overline{f(z)}$ ). I also had the idea to consider the stable and unstable manifolds of the dymaical system $x'(t)=f'(x(t))$ near the critical point $x=\alpha$ , but this did not lead anywhere. Besides the values $\theta=0$ and $\theta=\pi$ , where $f$ is definitely real valued, I may compute for $\xi=u+iv$ that $$\text{Im}f(\alpha+\xi)=f''(\alpha)uv+\frac{1}{6}f^{3}(\alpha)(3u^2v-v^3)+\frac{1}{6}f^{(4)}(\alpha)(u^3v-uv^3)+O(|\xi|^5).$$ If I set the left hand size equal to zero and ignore the big $O$ -term, then I get an approximation for the nontrivial curve through $\alpha$ for which $f(z)$ is real valued: $$v=\pm \sqrt{\frac{6f''(\alpha)+3f^{(3)}(\alpha)u^2+f^{(4)}(\alpha)u^3}{f^{(3)}(\alpha)+f^{(4)}(\alpha) u}}$$ (assuming $f^{(3)}(\alpha)$ and $f^{(4)}(\alpha)$ are not both zero). There may be a very simple way to prove the statement, but I am unable to see it. Any help would be greatly appreciated.","Let be a holomorphic function, where is an open set containing , and suppose that is real valued (so that are real valued for all ). Suppose that and that . For such that , define by I am trying to prove that there exists a , such that for all , there are exactly four distinct values such that . What I amble to do, and where my approach falls short. If we use a power series expansion about , we have with uniformly in as . If is such that for sufficiently small, then by geometric considerations, the argument of cannot differ from by more than , as shown in the image below: Here , and is a right angle. Thus, as . This allows me to write For sufficiently small , this allows me to conclude that there are at least four values of such that is real valued, given by The problem is that I am unable to show that there are exactly 4 zeros when is sufficiently small. I have tried bounding the number of zeros of on the real line using different techinques, but the bounds I get are not much better than 16 zeros, which is not good enough (you may assume that satisfies ). I also had the idea to consider the stable and unstable manifolds of the dymaical system near the critical point , but this did not lead anywhere. Besides the values and , where is definitely real valued, I may compute for that If I set the left hand size equal to zero and ignore the big -term, then I get an approximation for the nontrivial curve through for which is real valued: (assuming and are not both zero). There may be a very simple way to prove the statement, but I am unable to see it. Any help would be greatly appreciated.","f:\Omega\to \mathbb{C} \Omega \alpha\in \mathbb{R} f\big|_{\Omega \hspace{0.5mm} \cap \hspace{0.5mm}\mathbb{R}} f^{(k)}(\alpha) k f'(\alpha)=0 f''(\alpha)\ne 0 r>0 \{z\in \mathbb{C}:|z-\alpha|\le r\}\subset \Omega g=g_{r}:[0,2\pi)\to \mathbb{C} g(\theta)=f(\alpha+r\text{e}^{\theta i}). r_0>0 0<r\le r_0 \theta_1, \theta_2, \theta_3, \theta_4\in [0,2\pi) g(\theta_i)\in \mathbb{R} \alpha f(\alpha+r\text{e}^{\theta i})=f(\alpha)+\frac{1}{2}r^2\text{e}^{2\theta i}f''(\alpha)+R(r,\theta) R(r,\theta)=O(r^3) \theta r\to 0^{+} C>0 |R(r,\theta)|\le Cr^3 r \frac{1}{2}r^2\text{e}^{2\theta i}f''(\alpha)+R(r,\theta) 2\theta=\text{arg}(\frac{1}{2}r^2\text{e}^{2\theta i}f''(\alpha)) \theta^{\ast} P=\frac{1}{2}r^2\text{e}^{2\theta i}f''(\alpha) |P-Q|=Cr^3 \angle P Q 0 \theta^{\ast}=\arcsin(\frac{2Cr}{f''(\alpha)})=O(r) r\to 0^{+} f(\alpha+r\text{e}^{\theta i})-f(\alpha)=(\frac{1}{2}r^2f''(\alpha)+O(r^3))\text{e}^{(2\theta +O(r))i}. r \theta g(\theta) \theta_1=0, \hspace{4mm} \theta_2\approx \frac{\pi}{2}, \hspace{4mm} \theta_3=\pi, \hspace{4mm} \theta_3\approx \frac{3\pi}{2}. r h(z)=\frac{1}{2i}(f(\alpha+r\text{e}^{zi})-f(\alpha+r\text{e}^{-zi})) f f(\overline{z})=\overline{f(z)} x'(t)=f'(x(t)) x=\alpha \theta=0 \theta=\pi f \xi=u+iv \text{Im}f(\alpha+\xi)=f''(\alpha)uv+\frac{1}{6}f^{3}(\alpha)(3u^2v-v^3)+\frac{1}{6}f^{(4)}(\alpha)(u^3v-uv^3)+O(|\xi|^5). O \alpha f(z) v=\pm \sqrt{\frac{6f''(\alpha)+3f^{(3)}(\alpha)u^2+f^{(4)}(\alpha)u^3}{f^{(3)}(\alpha)+f^{(4)}(\alpha) u}} f^{(3)}(\alpha) f^{(4)}(\alpha)",['complex-analysis']
16,Stein complex analysis exercise 4.12,Stein complex analysis exercise 4.12,,"Let $f$ be a function on $\Bbb R$ that satisfies $$f(x) = O(e^{-\pi x^2})\quad\text{and}\quad\hat{f}(\xi) = O(e^{-\pi\xi^2}).$$ Then if $f$ is even then $\hat{f}$ extends to an even entire function. Moreover, if $g(z) = \hat{f}(z^{1/2})$ , then g satisfies $$|g(x)|\leq ce^{-\pi x}\quad\text{and}\quad |g(z)|\leq ce^{\pi R\sin^2(\theta/2)}\leq ce^{\pi|z|}$$ when $x\in\Bbb R$ and $z = Re^{i\theta}$ with $R\geq 0$ and $\theta\in\Bbb R$ . Question. Apply the Phragmen-Lindelof principle to the function $$F(z) = g(z)e^{\gamma z}\quad\text{where}\ \gamma = i\pi{e^{-i\pi/(2\beta)}\over \sin\pi/(2\beta)}$$ and the sector $0\leq\theta\leq\pi/\beta<\pi$ , and let $\beta\to\color{red}{1}$ to deduce that $e^{\pi z}g(z)$ is bounded in the closed upper half-plane. My attempt: We apply the Phragmen-Lindelof on the given sector (we don't rotate). First, if $z = re^{i\theta}$ then \begin{align*} e^{\gamma z} &= \exp\left(i\pi{e^{-i\pi/(2\beta)}\over \sin\pi/(2\beta)} z\right)\\ i\pi{e^{-i\pi/(2\beta)}\over \sin\pi/(2\beta)}r(\cos\theta+i\sin\theta) & = i\pi{\cos(\pi/2\beta)-i\sin(\pi/2\beta)\over\sin(\pi/2\beta)}r(\cos\theta+i\sin\theta)\\ & \overset{\mathrm{\operatorname{Re}}}{=} {-\pi r\over\sin(\pi/2\beta)}(\cos(\pi/2\beta)\sin\theta-\sin(\pi/2\beta)\cos\theta)\\ & = -\pi r{\sin(\theta-\pi/2\beta)\over\sin(\pi/2\beta)}\\ \end{align*} Note that $0<\theta<\pi/\beta$ so $$-{\pi\over 2}<-{\pi\over 2\beta}<\theta-{\pi\over 2\beta}<{\pi\over 2\beta}<{\pi\over 2}$$ and $\sin$ is strictly increasing function on $(-\pi/2,\pi/2)$ . This implies ${\sin(\theta-\pi/2\beta)\over\sin(\pi/2\beta)}<1$ . But this is not good. $$|F(z)| = |g(z)e^{\gamma z}|=|g(z)|e^{\operatorname{Re}(\gamma z)} = ce^{\pi r(1-\epsilon)},\quad\epsilon<1,$$ by the above argument. So we can't apply P-L principle. Even if I can apply, I'm not sure how the function is bounded on the boundary of the given sector. I'm stuck here. Could you help?","Let be a function on that satisfies Then if is even then extends to an even entire function. Moreover, if , then g satisfies when and with and . Question. Apply the Phragmen-Lindelof principle to the function and the sector , and let to deduce that is bounded in the closed upper half-plane. My attempt: We apply the Phragmen-Lindelof on the given sector (we don't rotate). First, if then Note that so and is strictly increasing function on . This implies . But this is not good. by the above argument. So we can't apply P-L principle. Even if I can apply, I'm not sure how the function is bounded on the boundary of the given sector. I'm stuck here. Could you help?","f \Bbb R f(x) = O(e^{-\pi x^2})\quad\text{and}\quad\hat{f}(\xi) = O(e^{-\pi\xi^2}). f \hat{f} g(z) = \hat{f}(z^{1/2}) |g(x)|\leq ce^{-\pi x}\quad\text{and}\quad |g(z)|\leq ce^{\pi R\sin^2(\theta/2)}\leq ce^{\pi|z|} x\in\Bbb R z = Re^{i\theta} R\geq 0 \theta\in\Bbb R F(z) = g(z)e^{\gamma z}\quad\text{where}\ \gamma = i\pi{e^{-i\pi/(2\beta)}\over \sin\pi/(2\beta)} 0\leq\theta\leq\pi/\beta<\pi \beta\to\color{red}{1} e^{\pi z}g(z) z = re^{i\theta} \begin{align*}
e^{\gamma z} &= \exp\left(i\pi{e^{-i\pi/(2\beta)}\over \sin\pi/(2\beta)} z\right)\\
i\pi{e^{-i\pi/(2\beta)}\over \sin\pi/(2\beta)}r(\cos\theta+i\sin\theta) & = i\pi{\cos(\pi/2\beta)-i\sin(\pi/2\beta)\over\sin(\pi/2\beta)}r(\cos\theta+i\sin\theta)\\
& \overset{\mathrm{\operatorname{Re}}}{=} {-\pi r\over\sin(\pi/2\beta)}(\cos(\pi/2\beta)\sin\theta-\sin(\pi/2\beta)\cos\theta)\\
& = -\pi r{\sin(\theta-\pi/2\beta)\over\sin(\pi/2\beta)}\\
\end{align*} 0<\theta<\pi/\beta -{\pi\over 2}<-{\pi\over 2\beta}<\theta-{\pi\over 2\beta}<{\pi\over 2\beta}<{\pi\over 2} \sin (-\pi/2,\pi/2) {\sin(\theta-\pi/2\beta)\over\sin(\pi/2\beta)}<1 |F(z)| = |g(z)e^{\gamma z}|=|g(z)|e^{\operatorname{Re}(\gamma z)} = ce^{\pi r(1-\epsilon)},\quad\epsilon<1,","['complex-analysis', 'fourier-analysis']"
17,Prove that $f(z)=az+b$.,Prove that .,f(z)=az+b,"Let $f$ an analytic function in a domain $D$ such that $f''(z)=0$ for all $z\in D$ . Prove that there exist constants $a,b\in \Bbb C$ such that $f(z)=az+b$ . Try: If we consider the function $g(z)=f'(z)$ , we have that $g'(z)=f''(z)=0$ in $D$ . And we already have a theorem that guarantees us that $g$ is constant in $D$ , that is to say that $g(z)=a$ for $a\in \Bbb C$ . So, $f'(z)=a$ . But I don't know how to continue from here, any help. I have tried Cauchy equations.","Let an analytic function in a domain such that for all . Prove that there exist constants such that . Try: If we consider the function , we have that in . And we already have a theorem that guarantees us that is constant in , that is to say that for . So, . But I don't know how to continue from here, any help. I have tried Cauchy equations.","f D f''(z)=0 z\in D a,b\in \Bbb C f(z)=az+b g(z)=f'(z) g'(z)=f''(z)=0 D g D g(z)=a a\in \Bbb C f'(z)=a","['complex-analysis', 'analytic-functions']"
18,"A problem from Stein and Shakarchi complex analysis (problem 5, Chapter 3)","A problem from Stein and Shakarchi complex analysis (problem 5, Chapter 3)",,"The origin question is below: Let $$g(z)=\frac{1}{2\pi i}\int_{-M}^M\frac{h(x)}{x-z}dx$$ where $h$ is continuous and supported in $[-M,M]$ . Prove that the function $g$ is holomorphic in $\mathbb{C}\backslash[-M,M]$ , and vanished at infinity, that is $\lim_{|z|\to\infty}|g(z)|=0$ . Moreover, the ""jump"" of $g$ across $[-M,M]$ is $h$ , that is $$h(z)=\lim_{\varepsilon\to0+}g(x+i\varepsilon)-g(x-i\varepsilon).$$ If $h$ satisfies a mild smoothness condition, for instance a Hölder condition with exponent $\alpha$ , then $g(x+i\varepsilon)$ and $g(x-i\varepsilon)$ converge uniformly to functions $g_+(x)$ and $g_-(x)$ as $\varepsilon\to0$ . Then, $g$ can be characterized as the unique holomorphic function that satisfies: $g$ is holomorphic outside $[-M,M]$ , $g$ vanished at infinity, $g(x+i\varepsilon)$ and $g(x-i\varepsilon)$ converges uniformly to the functions $g_+(x)$ and $g_-(x)$ with $$g_+(x)-g_-(x)=h(x)$$ . The first problem is easy as long as one notice that $g(x+i\varepsilon)-g(x-i\varepsilon)=h*K_\varepsilon$ , where $K_\varepsilon(x)=\frac{\varepsilon}{\pi(x^2+\varepsilon^2)}$ is a good kernel. I found it difficult to prove that $g(x\pm i\varepsilon)\rightrightarrows g_\pm(x)$ . As a matter of fact, the real part of $g_\varepsilon^\pm$ is nothing but $\pm\frac{1}{2}(g_\varepsilon^+-g_\varepsilon^-)$ which had been proved to converge uniformly to $\pm\frac{1}{2}h(x)$ , but the imaginary part is propotional to $$\int_{-M}^Mh(t)\frac{t-x}{(t-x)^2+\varepsilon^2}dt.$$ I even cannot prove that it does converge to some function. and I didn't know how to use the Hölder condtion as well. I saw that follows from this condition, given $\varepsilon>0$ , one have $g_\varepsilon^\pm(x):=g(x\pm i\varepsilon)$ also satisfies the Hölder condition. But what can I do with it?","The origin question is below: Let where is continuous and supported in . Prove that the function is holomorphic in , and vanished at infinity, that is . Moreover, the ""jump"" of across is , that is If satisfies a mild smoothness condition, for instance a Hölder condition with exponent , then and converge uniformly to functions and as . Then, can be characterized as the unique holomorphic function that satisfies: is holomorphic outside , vanished at infinity, and converges uniformly to the functions and with . The first problem is easy as long as one notice that , where is a good kernel. I found it difficult to prove that . As a matter of fact, the real part of is nothing but which had been proved to converge uniformly to , but the imaginary part is propotional to I even cannot prove that it does converge to some function. and I didn't know how to use the Hölder condtion as well. I saw that follows from this condition, given , one have also satisfies the Hölder condition. But what can I do with it?","g(z)=\frac{1}{2\pi i}\int_{-M}^M\frac{h(x)}{x-z}dx h [-M,M] g \mathbb{C}\backslash[-M,M] \lim_{|z|\to\infty}|g(z)|=0 g [-M,M] h h(z)=\lim_{\varepsilon\to0+}g(x+i\varepsilon)-g(x-i\varepsilon). h \alpha g(x+i\varepsilon) g(x-i\varepsilon) g_+(x) g_-(x) \varepsilon\to0 g g [-M,M] g g(x+i\varepsilon) g(x-i\varepsilon) g_+(x) g_-(x) g_+(x)-g_-(x)=h(x) g(x+i\varepsilon)-g(x-i\varepsilon)=h*K_\varepsilon K_\varepsilon(x)=\frac{\varepsilon}{\pi(x^2+\varepsilon^2)} g(x\pm i\varepsilon)\rightrightarrows g_\pm(x) g_\varepsilon^\pm \pm\frac{1}{2}(g_\varepsilon^+-g_\varepsilon^-) \pm\frac{1}{2}h(x) \int_{-M}^Mh(t)\frac{t-x}{(t-x)^2+\varepsilon^2}dt. \varepsilon>0 g_\varepsilon^\pm(x):=g(x\pm i\varepsilon)",['complex-analysis']
19,Help verifying and simplifying $ \int_0^\infty \cos x^2 dx $ (the Fresnel integral) via complex contour integration,Help verifying and simplifying  (the Fresnel integral) via complex contour integration, \int_0^\infty \cos x^2 dx ,"Find $ \int_0^\infty \cos x^2 dx $ . Note: This is the Fresnel integral, whose derivation is available on this site and elsewhere .  I'd like verification of my proof, as well any recommended improvements to the exposition, which to me is simpler than much of what's published. Solution : We use the technique of contour integrals in the complex plane, creating three contours: $\alpha$ , from $0$ to $R$ along the real axis; $\beta$ , from $R$ to $Re^{i \pi/4}$ in a circular arc, and $\gamma$ , from $Re^{i \pi/4}$ to $0$ in a straight line. We first show that $\lim_{R \to \infty} \int_\beta e^{-z^2}dz = 0$ . $\int_\beta e^{-z^2}dz = \int_0^{\pi/4}e^{-R^2e^{2i\theta}}\cdot iRe^{i\theta}d\theta$ .  Since $|e^z| = |e^{\Re(z)}|$ and $|\int f(x) dx| \leq \int |f(x)| dx$ , we have $|\int_\beta e^{-z^2}dz| \leq \int_0^{\pi/4} |Re^{-R^2\cos {2\theta}}|d\theta$ .  Since $0 \leq \theta \leq \pi/4$ , $0 \leq \cos {2\theta} \leq 1$ , and so this goes to $0$ as $R \to \infty$ .  From this, we conclude $\int_\gamma e^{-z^2}dz = - \int_\alpha e^{-z^2}dz$ , since $e^{-z^2}$ is entire. Since the Gaussian integral $\int^\infty_{-\infty} e^{-x^2}dx = \sqrt \pi$ , and $e^{-x^2}$ is even, $\lim_{R \to \infty} \int_\gamma e^{-z^2}dz = - \int_0^\infty e^{-x^2}dx = - \sqrt \pi / 2$ . Also note that $\int_\gamma e^{-z^2} dz = \int_R^0 e^{-[re^{i\pi/4}]^2}e^{i\pi/4}dr = \frac{-\sqrt 2}{2}(1+i)\int_0^Re^{-ir^2}dr$ .  Thus, $\lim_{R \to \infty} \int_0^Re^{-ir^2}dr = \sqrt{2\pi}/4 + ki$ for some real $k$ , and its complex conjugate $\int_0^Re^{ir^2}dr = \sqrt{2\pi}/4 - ki$ . Finally, we conclude $\int_0^\infty \cos x^2 dx = \int_0^\infty \frac{e^{ix^2} + e^{-ix^2}}{2} dx = \frac{\sqrt{2\pi}}{4}$ , QED. Is my proof correct? I tried to skip mechanical steps while not omitting any conceptual leaps.  My goal is for the exposition to be simple, clear, and direct.  Did I succeed? Could the writing and exposition be improved? How?","Find . Note: This is the Fresnel integral, whose derivation is available on this site and elsewhere .  I'd like verification of my proof, as well any recommended improvements to the exposition, which to me is simpler than much of what's published. Solution : We use the technique of contour integrals in the complex plane, creating three contours: , from to along the real axis; , from to in a circular arc, and , from to in a straight line. We first show that . .  Since and , we have .  Since , , and so this goes to as .  From this, we conclude , since is entire. Since the Gaussian integral , and is even, . Also note that .  Thus, for some real , and its complex conjugate . Finally, we conclude , QED. Is my proof correct? I tried to skip mechanical steps while not omitting any conceptual leaps.  My goal is for the exposition to be simple, clear, and direct.  Did I succeed? Could the writing and exposition be improved? How?", \int_0^\infty \cos x^2 dx  \alpha 0 R \beta R Re^{i \pi/4} \gamma Re^{i \pi/4} 0 \lim_{R \to \infty} \int_\beta e^{-z^2}dz = 0 \int_\beta e^{-z^2}dz = \int_0^{\pi/4}e^{-R^2e^{2i\theta}}\cdot iRe^{i\theta}d\theta |e^z| = |e^{\Re(z)}| |\int f(x) dx| \leq \int |f(x)| dx |\int_\beta e^{-z^2}dz| \leq \int_0^{\pi/4} |Re^{-R^2\cos {2\theta}}|d\theta 0 \leq \theta \leq \pi/4 0 \leq \cos {2\theta} \leq 1 0 R \to \infty \int_\gamma e^{-z^2}dz = - \int_\alpha e^{-z^2}dz e^{-z^2} \int^\infty_{-\infty} e^{-x^2}dx = \sqrt \pi e^{-x^2} \lim_{R \to \infty} \int_\gamma e^{-z^2}dz = - \int_0^\infty e^{-x^2}dx = - \sqrt \pi / 2 \int_\gamma e^{-z^2} dz = \int_R^0 e^{-[re^{i\pi/4}]^2}e^{i\pi/4}dr = \frac{-\sqrt 2}{2}(1+i)\int_0^Re^{-ir^2}dr \lim_{R \to \infty} \int_0^Re^{-ir^2}dr = \sqrt{2\pi}/4 + ki k \int_0^Re^{ir^2}dr = \sqrt{2\pi}/4 - ki \int_0^\infty \cos x^2 dx = \int_0^\infty \frac{e^{ix^2} + e^{-ix^2}}{2} dx = \frac{\sqrt{2\pi}}{4},"['complex-analysis', 'solution-verification', 'proof-writing', 'contour-integration']"
20,Finding poles of $f(z) = z/(1-\cos z)$,Finding poles of,f(z) = z/(1-\cos z),"I'm trying to self-learn complex analysis and am working on a question (from a practice exam) that asks me to find all the poles of $$f(z) = {z\over 1-\cos z}$$ and compute the residues at each pole. Now if $z_0 = 2\pi n$ where $n$ is a nonzero integer, then $$\lim_{z\to z_0} {(z-z_0)^2 z\over 1-\cos z} = \lim_{z\to z_0} {2(z-z_0) z + (z-z_0)^2 \over \sin z} = \lim_{z\to z_0} {4z - 2z_0 + (z-z_0) \over \cos z} = 2z_0, $$ which is neither zero nor infinity, so $f$ has a pole of order $2$ at all of these points. If you try this with $z_0 = 0$ and $m=1$ , you get $$\lim_{z\to 0} {z^{2} \over 1-\cos z} = \lim_{z\to 0} {2z\over \sin z} = \lim_{z\to 0} {2\over \cos z} =2,$$ which says that $0$ is a pole of order $1$ and also tells us that the residue at $0$ is $2$ . I decided to check if these are the correct poles and typed this into WolframAlpha: https://www.wolframalpha.com/input?i=poles+of+z%2F%281-cos+z%29 It says that there is no pole at $z=0$ , which is strange. Am I misunderstanding the concept of pole? My definition of pole (I'm learning out of Complex Variables by Francis J. Flanagan) is $z_0$ such that $\lim z\to z_0 |f(z)| = \infty$ , and by this definition, $0$ is a pole. (By the way, I still have to compute the residues here which is a huge mess according to the formula I know: $$ {\rm Res}(f; z_0) = \lim_{z\to z_0} ((z-z_0)^2 f(z))'$$ so I guess a subquestion would be: Is there any way to compute these residues without differentiating the inside of that and then using l'Hospital's rule over and over? WolframAlpha says the answer should be $2$ at every pole.)","I'm trying to self-learn complex analysis and am working on a question (from a practice exam) that asks me to find all the poles of and compute the residues at each pole. Now if where is a nonzero integer, then which is neither zero nor infinity, so has a pole of order at all of these points. If you try this with and , you get which says that is a pole of order and also tells us that the residue at is . I decided to check if these are the correct poles and typed this into WolframAlpha: https://www.wolframalpha.com/input?i=poles+of+z%2F%281-cos+z%29 It says that there is no pole at , which is strange. Am I misunderstanding the concept of pole? My definition of pole (I'm learning out of Complex Variables by Francis J. Flanagan) is such that , and by this definition, is a pole. (By the way, I still have to compute the residues here which is a huge mess according to the formula I know: so I guess a subquestion would be: Is there any way to compute these residues without differentiating the inside of that and then using l'Hospital's rule over and over? WolframAlpha says the answer should be at every pole.)","f(z) = {z\over 1-\cos z} z_0 = 2\pi n n \lim_{z\to z_0} {(z-z_0)^2 z\over 1-\cos z} =
\lim_{z\to z_0} {2(z-z_0) z + (z-z_0)^2 \over \sin z} =
\lim_{z\to z_0} {4z - 2z_0 + (z-z_0) \over \cos z} = 2z_0,
 f 2 z_0 = 0 m=1 \lim_{z\to 0} {z^{2} \over 1-\cos z} = \lim_{z\to 0} {2z\over \sin z} = \lim_{z\to 0} {2\over \cos z} =2, 0 1 0 2 z=0 z_0 \lim z\to z_0 |f(z)| = \infty 0  {\rm Res}(f; z_0) = \lim_{z\to z_0} ((z-z_0)^2 f(z))' 2",['complex-analysis']
21,Derivation of the behavior of solutions to $\tan x = x$,Derivation of the behavior of solutions to,\tan x = x,"This question is related to Chapter IV, Note IV.36 of Flajolet & Sedgewick's Analytic Combinatorics, and The question : Sum of the squares of the reciprocals of the fixed points of the tangent function as well: Let $x_k$ be the $k^{th}$ positive root of the equation $\tan z = z$ .  Then, the sum $S_r = \sum_k x_k^{-2r}$ are rational numbers for $r \ge 1$ .  For instances, $S_1 = 1/10$ , $S_2 = 1/350$ , $S_3 = 1/7875$ (from Note IV.36, pp. 269.) I follow the approach in the book for Bernoulli numbers (Chapter IV, IV.6.1, pp. 268.)  Consider the function: \begin{align} f(z) = \frac{1}{\tan z - z} \tag{1} \end{align} It is obvious that $\{x_k\}$ are poles of $f(z)$ , with $k \in \mathbb{Z} \backslash \{0\}$ .  Further, \begin{align} Res[f(z);z=x_k] &= \frac{1}{\frac{d}{dz}(\tan z - z)|_{z=x_k}} \\ &= \frac{1}{\tan^2 x_k} \\ &= \frac{1}{x_k^2} \tag{2} \end{align} Hence, \begin{align} \frac{1}{\tan z - z} \sim \frac{1}{x_k^2}\cdot \frac{1}{z-x_k}, \text{ for } z \to x_k \tag{3} \end{align} By the Cauchy's coefficient formula, we have \begin{align} f_n = [z^n]f(z) &= \int_C \frac{f(z)}{z^{n+1}} dz \tag{4} \\ &= -\sum_{k \in \mathbb{Z} \backslash \{0\}} \frac{1}{x_k^2}\cdot \frac{1}{x_k^{n+1}} \end{align} where $C$ is a contour encircling all poles.  Since $f(z)$ is an odd function, the poles are in pairs like $\pm x_k$ .  Then, $f_n = 0$ , when $n$ is even.  As a result, \begin{align} f_{2n-1} &= -2 \sum_{k=1}^\infty x_k^{-2(n+1)}, \text{ for } n \ge 1 \tag{5} \end{align} Therefore, the following relation is established: \begin{align} S_r = \sum_{k=1}^\infty x_k^{-2r} = -\frac{1}{2}f_{2r-3}, \text{ for } r > 1 \tag{6} \end{align} From the expansion of (1), that is, \begin{align} \frac{1}{\tan z - z} = \frac{3}{z^3} - \frac{6}{5z} - \frac{1}{175}z - \frac{2}{7875}z^3-\frac{37}{3031875}z^5+O(z^6) \tag{7} \end{align} It shows that $S_2$ and $S_3$ calculated from (6) are correct.  But $S_1$ cannot be calculated from (6) since $f_{-1}$ is related to the pole at $z=0$ , which is excluded from (6). Then, for $S_1$ , I follow the approach in an answer to The question to consider the integral in the region including $z=0$ .  That is, \begin{align} \int_C f(z)dz = 2i\pi \sum_{k \in \mathbb{Z}} Res[f(z); z=x_k] \tag{8} \end{align} From the expansion in (7), we have $Res[f(z);z=0]=-\frac{6}{5}$ .  Together with (2), (8) becomes \begin{align} \int_C f(z)dz = 2i\pi \left(-\frac{6}{5} + 2\sum_{k=1}^\infty x_k^{-2}\right) \tag{9} \end{align} Since it is found that (details in an answer to The question ) \begin{align} \int_C f(z)dz = -2i\pi \tag{10} \end{align} (9) becomes \begin{align} -\frac{6}{5} + 2\sum_{k=1}^\infty x_k^{-2} = -1 \end{align} Or \begin{align} S_1 = \sum_{k=1}^\infty x_k^{-2} = \frac{1}{10} \tag{11} \end{align} This result is well known as proved in The question . It looks the flow of logic leading to the results (6) and (11) are both correct.  However, the point I don't understand is: both (4) and (9) include an integral around the same contour and both give the same result ( $-2i\pi$ ).  Nevertheless, by Cauchy's residue theorem, they equal to the sum of different sets of residues - one with the pole at $0$ (9) while the other without (4).  The difference in residue set is due to the difference in the regions in concern ( $\mathbb{C}$ vs. $\mathbb{C} \backslash \{0\}$ .)  But why the contour integrals of a function at these different regions give the same result? Could you please indicate what is wrong in the above logic?  Thank you.","This question is related to Chapter IV, Note IV.36 of Flajolet & Sedgewick's Analytic Combinatorics, and The question : Sum of the squares of the reciprocals of the fixed points of the tangent function as well: Let be the positive root of the equation .  Then, the sum are rational numbers for .  For instances, , , (from Note IV.36, pp. 269.) I follow the approach in the book for Bernoulli numbers (Chapter IV, IV.6.1, pp. 268.)  Consider the function: It is obvious that are poles of , with .  Further, Hence, By the Cauchy's coefficient formula, we have where is a contour encircling all poles.  Since is an odd function, the poles are in pairs like .  Then, , when is even.  As a result, Therefore, the following relation is established: From the expansion of (1), that is, It shows that and calculated from (6) are correct.  But cannot be calculated from (6) since is related to the pole at , which is excluded from (6). Then, for , I follow the approach in an answer to The question to consider the integral in the region including .  That is, From the expansion in (7), we have .  Together with (2), (8) becomes Since it is found that (details in an answer to The question ) (9) becomes Or This result is well known as proved in The question . It looks the flow of logic leading to the results (6) and (11) are both correct.  However, the point I don't understand is: both (4) and (9) include an integral around the same contour and both give the same result ( ).  Nevertheless, by Cauchy's residue theorem, they equal to the sum of different sets of residues - one with the pole at (9) while the other without (4).  The difference in residue set is due to the difference in the regions in concern ( vs. .)  But why the contour integrals of a function at these different regions give the same result? Could you please indicate what is wrong in the above logic?  Thank you.","x_k k^{th} \tan z = z S_r = \sum_k x_k^{-2r} r \ge 1 S_1 = 1/10 S_2 = 1/350 S_3 = 1/7875 \begin{align}
f(z) = \frac{1}{\tan z - z} \tag{1}
\end{align} \{x_k\} f(z) k \in \mathbb{Z} \backslash \{0\} \begin{align}
Res[f(z);z=x_k] &= \frac{1}{\frac{d}{dz}(\tan z - z)|_{z=x_k}} \\
&= \frac{1}{\tan^2 x_k} \\
&= \frac{1}{x_k^2} \tag{2}
\end{align} \begin{align}
\frac{1}{\tan z - z} \sim \frac{1}{x_k^2}\cdot \frac{1}{z-x_k}, \text{ for } z \to x_k \tag{3}
\end{align} \begin{align}
f_n = [z^n]f(z) &= \int_C \frac{f(z)}{z^{n+1}} dz \tag{4} \\
&= -\sum_{k \in \mathbb{Z} \backslash \{0\}} \frac{1}{x_k^2}\cdot \frac{1}{x_k^{n+1}}
\end{align} C f(z) \pm x_k f_n = 0 n \begin{align}
f_{2n-1} &= -2 \sum_{k=1}^\infty x_k^{-2(n+1)}, \text{ for } n \ge 1 \tag{5}
\end{align} \begin{align}
S_r = \sum_{k=1}^\infty x_k^{-2r} = -\frac{1}{2}f_{2r-3}, \text{ for } r > 1 \tag{6}
\end{align} \begin{align}
\frac{1}{\tan z - z} = \frac{3}{z^3} - \frac{6}{5z} - \frac{1}{175}z - \frac{2}{7875}z^3-\frac{37}{3031875}z^5+O(z^6) \tag{7}
\end{align} S_2 S_3 S_1 f_{-1} z=0 S_1 z=0 \begin{align}
\int_C f(z)dz = 2i\pi \sum_{k \in \mathbb{Z}} Res[f(z); z=x_k] \tag{8}
\end{align} Res[f(z);z=0]=-\frac{6}{5} \begin{align}
\int_C f(z)dz = 2i\pi \left(-\frac{6}{5} + 2\sum_{k=1}^\infty x_k^{-2}\right) \tag{9}
\end{align} \begin{align}
\int_C f(z)dz = -2i\pi \tag{10}
\end{align} \begin{align}
-\frac{6}{5} + 2\sum_{k=1}^\infty x_k^{-2} = -1
\end{align} \begin{align}
S_1 = \sum_{k=1}^\infty x_k^{-2} = \frac{1}{10} \tag{11}
\end{align} -2i\pi 0 \mathbb{C} \mathbb{C} \backslash \{0\}","['complex-analysis', 'asymptotics', 'power-series', 'complex-integration', 'residue-calculus']"
22,"Cauchy's Integral Theorem. Does it have to be a ""curved"" closed contour?","Cauchy's Integral Theorem. Does it have to be a ""curved"" closed contour?",,"My question is (e). I know f is analytic by the Cauchy-Riemann condition for (a). For the results of (b), (c), and (d), I get 4/3, 8/3 + 2i, 1/3 + i5/3. So, to make the closed loop, I did (b)+(c)-(d), but it does not give me 0. Cauchy's integral formula says it should be 0 tho. What did I wrong?","My question is (e). I know f is analytic by the Cauchy-Riemann condition for (a). For the results of (b), (c), and (d), I get 4/3, 8/3 + 2i, 1/3 + i5/3. So, to make the closed loop, I did (b)+(c)-(d), but it does not give me 0. Cauchy's integral formula says it should be 0 tho. What did I wrong?",,['complex-analysis']
23,$\pi^2 \frac{\cos(\pi z)}{\sin^{2}(\pi z)} = \sum_{n \in \mathbb{Z}} \frac{(-1)^n}{(z-n)^2}$,,\pi^2 \frac{\cos(\pi z)}{\sin^{2}(\pi z)} = \sum_{n \in \mathbb{Z}} \frac{(-1)^n}{(z-n)^2},"I am supposed to prove: $$\underbrace{\pi^2 \frac{\cos(\pi z)}{\sin^{2}(\pi z)}}_\text{:=f(z)}=\underbrace{\sum_{n \in \mathbb{Z}} \frac{(-1)^n}{(z-n)^2}}_\text{:=g(z)}$$ I was able to show that both sides have the same poles and the same singular parts. Therefore, $h=f-g$ is an entire function. Clearly, both $f$ and $g$ have period $2$ , so $h$ also has period $2$ . So, if I can show that $h(z)$ is bounded in the vertical strip $0 \leq \Re(z) \leq 2$ , I can invoke Liouville's to get $h$ is consant. To evaluate that constant, one can use the fact that $\lim_{z \to 0}\Big(f(z)-\frac{1}{z^2}\Big)=-\frac{\pi^2}{6}=\sum_{n\neq 0} \frac{(-1)^n}{(z-n)^2}$ implying $h \equiv 0$ and we are done. So, how should I show that $h$ is bounded in that strip?","I am supposed to prove: I was able to show that both sides have the same poles and the same singular parts. Therefore, is an entire function. Clearly, both and have period , so also has period . So, if I can show that is bounded in the vertical strip , I can invoke Liouville's to get is consant. To evaluate that constant, one can use the fact that implying and we are done. So, how should I show that is bounded in that strip?",\underbrace{\pi^2 \frac{\cos(\pi z)}{\sin^{2}(\pi z)}}_\text{:=f(z)}=\underbrace{\sum_{n \in \mathbb{Z}} \frac{(-1)^n}{(z-n)^2}}_\text{:=g(z)} h=f-g f g 2 h 2 h(z) 0 \leq \Re(z) \leq 2 h \lim_{z \to 0}\Big(f(z)-\frac{1}{z^2}\Big)=-\frac{\pi^2}{6}=\sum_{n\neq 0} \frac{(-1)^n}{(z-n)^2} h \equiv 0 h,"['complex-analysis', 'power-series', 'laurent-series']"
24,Integration of $\frac{x^{1/3}}{1+x^2} dx$ [duplicate],Integration of  [duplicate],\frac{x^{1/3}}{1+x^2} dx,"This question already has answers here : integration using residue (3 answers) Closed 1 year ago . I have problem with integration $I = \int_0^\infty \frac{x^{1/3}}{1+x^2} dx$ using residue theory. Define $\log z$ on the complex plane except the positive real line so that its imaginary part is in $(0, 2\pi)$ . Consider a counterclockwise path $C$ with a small circle around $0$ , a real line from $0$ to $\infty$ on the upper half plane, a big circle around $0$ , and a real line from $\infty$ to $0$ on the lower half plane. The integral $\int_0^\infty \frac{z^{1/3}}{1+z^2} dz$ converges to $(1-e^{2\pi i /3})I$ as on the lower real line $z^{1/3} = e^{2\pi i /3}x^{1/3}$ . Using residues I have $\frac{1}{2\pi i} \int_0^\infty \frac{z^{1/3}}{1+z^2} dz = \frac{1}{2i} (e^{\pi i /6} - e^{\pi i /2})$ . But this leads to $I = \frac{\pi i}{\sqrt 3}$ . Where did this argument go wrong? Is it not OK to apply residue theorem in this situation?","This question already has answers here : integration using residue (3 answers) Closed 1 year ago . I have problem with integration using residue theory. Define on the complex plane except the positive real line so that its imaginary part is in . Consider a counterclockwise path with a small circle around , a real line from to on the upper half plane, a big circle around , and a real line from to on the lower half plane. The integral converges to as on the lower real line . Using residues I have . But this leads to . Where did this argument go wrong? Is it not OK to apply residue theorem in this situation?","I = \int_0^\infty \frac{x^{1/3}}{1+x^2} dx \log z (0, 2\pi) C 0 0 \infty 0 \infty 0 \int_0^\infty \frac{z^{1/3}}{1+z^2} dz (1-e^{2\pi i /3})I z^{1/3} = e^{2\pi i /3}x^{1/3} \frac{1}{2\pi i} \int_0^\infty \frac{z^{1/3}}{1+z^2} dz = \frac{1}{2i} (e^{\pi i /6} - e^{\pi i /2}) I = \frac{\pi i}{\sqrt 3}",['complex-analysis']
25,"Given a laurent series, how do we show it doesnt have a pole? [closed]","Given a laurent series, how do we show it doesnt have a pole? [closed]",,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 1 year ago . Improve this question Ive been given a Laurent series and told to show that it doesn't have a pole at z = 0, I tried finding the function the Laurent series represents but that is too complex is there any other way to show the series doesn't have a pole at a certain point? $\sum_{n=0}^{\infty} \frac{z^n}{-2^n} + \sum_{n=0}^{\infty} \frac{n}{z^n}$","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 1 year ago . Improve this question Ive been given a Laurent series and told to show that it doesn't have a pole at z = 0, I tried finding the function the Laurent series represents but that is too complex is there any other way to show the series doesn't have a pole at a certain point?",\sum_{n=0}^{\infty} \frac{z^n}{-2^n} + \sum_{n=0}^{\infty} \frac{n}{z^n},"['complex-analysis', 'laurent-series', 'cauchy-integral-formula']"
26,How to remove a removable singularity,How to remove a removable singularity,,"I learned about Riemann’s theorem on removable singularities, which states: Let $D \subset \mathbb{C}$ be a open subset, $a \in D$ and let $f$ be a holomorphic function defined on $D\setminus\{a\}$ . The following are equivalent: $f$ is holomorphically extendable over $a$ $f$ is continuously extendable over $a$ There exists a neighborhood of $a$ such that $f$ is bounded $\displaystyle \lim_{z \to a} (z-a) f(z) = 0$ Because of this theorem I know that a function can be extendable over a, but how does the extending work in practice? I tried on this example. Let $$ f(z) := \frac{\sin(z)-z}{z^2}. $$ First I tried 4. to see if it is extendable. $$ \lim_{z \to 0} z \frac{\sin(z)-z}{z^2}  = \lim_{z \to 0} \frac{\sin(z)}{z} - 1  = \lim_{z \to 0} \frac{\cos(z)}{1} - 1  = 0 $$ Thus $f$ is holomorphically extendable over $0$ . Now I want to find the value $f(0)$ My idea would be to use a taylor series. I can't do the Taylor series of $f$ in $0$ , but I can do the Taylor series of $\sin(z)-z$ in $0$ : $$ \sin(z)-z  = -z + \sum_{k=0}^{\infty} (-1)^k \frac{z^{2k+1}}{(2k+1)!}  = \sum_{k=1}^{\infty} (-1)^k \frac{z^{2k+1}}{(2k+1)!} $$ Now I can divide the taylor series of $\sin(z)-z$ by $z^2$ : $$ \frac{\sin(z)-z}{z^2}  = \sum_{k=1}^{\infty} (-1)^k \frac{z^{2k-1}}{(2k+1)!} $$ Now if I take this Taylor series and let $z \to 0$ , then I get $$ \lim_{z \to 0} \sum_{k=1}^{\infty} (-1)^k \frac{z^{2k+1}}{(2k+1)!}  = 0 $$ This would mean, if I define $f(0):=0$ , then $f$ is continuous and thus by 2. also holomorphic. I have 3 Questions: (i) First, is the way I solved this correct? (ii) Is there another method to do this? (iii) In this case the denominator was a (Taylor) polynomial which was the reason why I was able to find the Taylor series of $f$ . How should one approach the problem if the denominator is not a polynomial? Is there a more general way?","I learned about Riemann’s theorem on removable singularities, which states: Let be a open subset, and let be a holomorphic function defined on . The following are equivalent: is holomorphically extendable over is continuously extendable over There exists a neighborhood of such that is bounded Because of this theorem I know that a function can be extendable over a, but how does the extending work in practice? I tried on this example. Let First I tried 4. to see if it is extendable. Thus is holomorphically extendable over . Now I want to find the value My idea would be to use a taylor series. I can't do the Taylor series of in , but I can do the Taylor series of in : Now I can divide the taylor series of by : Now if I take this Taylor series and let , then I get This would mean, if I define , then is continuous and thus by 2. also holomorphic. I have 3 Questions: (i) First, is the way I solved this correct? (ii) Is there another method to do this? (iii) In this case the denominator was a (Taylor) polynomial which was the reason why I was able to find the Taylor series of . How should one approach the problem if the denominator is not a polynomial? Is there a more general way?","D \subset \mathbb{C} a \in D f D\setminus\{a\} f a f a a f \displaystyle \lim_{z \to a} (z-a) f(z) = 0 
f(z) := \frac{\sin(z)-z}{z^2}.
 
\lim_{z \to 0} z \frac{\sin(z)-z}{z^2} 
= \lim_{z \to 0} \frac{\sin(z)}{z} - 1 
= \lim_{z \to 0} \frac{\cos(z)}{1} - 1 
= 0
 f 0 f(0) f 0 \sin(z)-z 0 
\sin(z)-z 
= -z + \sum_{k=0}^{\infty} (-1)^k \frac{z^{2k+1}}{(2k+1)!} 
= \sum_{k=1}^{\infty} (-1)^k \frac{z^{2k+1}}{(2k+1)!}
 \sin(z)-z z^2 
\frac{\sin(z)-z}{z^2} 
= \sum_{k=1}^{\infty} (-1)^k \frac{z^{2k-1}}{(2k+1)!}
 z \to 0 
\lim_{z \to 0} \sum_{k=1}^{\infty} (-1)^k \frac{z^{2k+1}}{(2k+1)!} 
= 0
 f(0):=0 f f","['complex-analysis', 'analysis', 'taylor-expansion']"
27,How to integrate $\int_0^{2\pi} \ln \vert \cos \pi e^{i\theta}\vert d \theta$ using complex analysis?,How to integrate  using complex analysis?,\int_0^{2\pi} \ln \vert \cos \pi e^{i\theta}\vert d \theta,"I'm trying to find the value $\int_0^{2\pi} \ln | \cos \pi e^{i\theta}\vert d \theta$ for the entire function $\cos z$ (Here the $\ln$ is natural logarithm ) I put the $z = e^{i\theta}$ , then we have $dz= iz d\theta$ . Therefore, $$\int_0^{2\pi} \ln \vert \cos \pi e^{i\theta}\vert d \theta = \int_{\vert z \vert =1} \frac{\ln\vert \cos \pi z\vert}{iz} dz$$ Therefore isolated singularities are $z=0, \frac{1}{2}$ and $\frac{-1}{2}$ . say $g(z) = \frac{\ln\vert \cos \pi z\vert}{iz}$ For the $z=0$ case, $\operatorname{res}(g,0) = 0$ [simple pole]. But I'm stuck for solving the other cases $\frac{1}{2}$ and $\frac{-1}{2}$ . How can I integrate that?","I'm trying to find the value for the entire function (Here the is natural logarithm ) I put the , then we have . Therefore, Therefore isolated singularities are and . say For the case, [simple pole]. But I'm stuck for solving the other cases and . How can I integrate that?","\int_0^{2\pi} \ln | \cos \pi e^{i\theta}\vert d \theta \cos z \ln z = e^{i\theta} dz= iz d\theta \int_0^{2\pi} \ln \vert \cos \pi e^{i\theta}\vert d \theta = \int_{\vert z \vert =1} \frac{\ln\vert \cos \pi z\vert}{iz} dz z=0, \frac{1}{2} \frac{-1}{2} g(z) = \frac{\ln\vert \cos \pi z\vert}{iz} z=0 \operatorname{res}(g,0) = 0 \frac{1}{2} \frac{-1}{2}","['integration', 'complex-analysis']"
28,Relation between roots of $f$ and roots of the partial sums of its power-series,Relation between roots of  and roots of the partial sums of its power-series,f,"It is well known we can write any holomorphic function as a local power series, for example $$\exp(z) = \sum_{n=0}^\infty \frac{z^n}{n!}$$ Obviously each partial sums are polynomials of degree $n$ which have always $n$ roots. I now wonder what is the relation or if there is any relation between the roots of a holomorphic function and the roots of its partial sums. For exmample it is well known that the exponential function does not have any roots, but for the partial sums $$(p_1(z)=1,) p_2(z)=1+z, p_3(z)=1+z+\frac{z^2}{2}, p_4(z)=1+z+\frac{z^2}{2}+ \frac{z^3}{6},..$$ we have the zero sets $$\{-1\}, \{-1-i,-1+i\},\{\approx-1,5961,\approx -0.702\pm1.807i\},..$$ (exact forms of the last roots are very poor) For other holomorphic function that have roots, for example the Sine, we know $$\sin(z)=\sum_{n=0}^\infty(-1)^n \frac{z^{2n+1}}{(2n+1)!}$$ It has roots in $k\pi$ , $k\in\mathbb{Z}$ , and its partial sums $$ p_1(z)=z, p_2(z)=z-\frac{z^3}{6}, p_3(z)=z-\frac{z^3}{6}+ \frac{z^5}{120},..$$ have the zero sets $$\{0\},\{0,\pm\sqrt{6}\},\{0,\pm3.2369 \pm 0.6908 i\},..$$ Obviously $0$ is always gonna be a root, but whats is about the other roots? Do the roots of the partial sums converge towards the roots of the limit function (what sounds reasonable)? And if so, what happens in the case where the limit function itself has no roots (e.g. exponential function?) May the zero set be diverging? Is there any relation between the zeros of the partial sums (that always exists) and the zeros of the limit function? Edit: I made some mathematica code to plot the zeros for increasing partial sums and indeed it looks like in the case of the exponential function its zeros are diverging. Since I have no idea how (or if its even possible) to upload mathematica code here, here some images For the sine on the other hand it seems like that all the sine zeros are generated, but also there are many diverging roots. However I could only calculate up to $n=50$ because for $n$ too big mathematica really needs some time to actually calculate the roots.","It is well known we can write any holomorphic function as a local power series, for example Obviously each partial sums are polynomials of degree which have always roots. I now wonder what is the relation or if there is any relation between the roots of a holomorphic function and the roots of its partial sums. For exmample it is well known that the exponential function does not have any roots, but for the partial sums we have the zero sets (exact forms of the last roots are very poor) For other holomorphic function that have roots, for example the Sine, we know It has roots in , , and its partial sums have the zero sets Obviously is always gonna be a root, but whats is about the other roots? Do the roots of the partial sums converge towards the roots of the limit function (what sounds reasonable)? And if so, what happens in the case where the limit function itself has no roots (e.g. exponential function?) May the zero set be diverging? Is there any relation between the zeros of the partial sums (that always exists) and the zeros of the limit function? Edit: I made some mathematica code to plot the zeros for increasing partial sums and indeed it looks like in the case of the exponential function its zeros are diverging. Since I have no idea how (or if its even possible) to upload mathematica code here, here some images For the sine on the other hand it seems like that all the sine zeros are generated, but also there are many diverging roots. However I could only calculate up to because for too big mathematica really needs some time to actually calculate the roots.","\exp(z) = \sum_{n=0}^\infty \frac{z^n}{n!} n n (p_1(z)=1,) p_2(z)=1+z, p_3(z)=1+z+\frac{z^2}{2}, p_4(z)=1+z+\frac{z^2}{2}+ \frac{z^3}{6},.. \{-1\}, \{-1-i,-1+i\},\{\approx-1,5961,\approx -0.702\pm1.807i\},.. \sin(z)=\sum_{n=0}^\infty(-1)^n \frac{z^{2n+1}}{(2n+1)!} k\pi k\in\mathbb{Z}  p_1(z)=z, p_2(z)=z-\frac{z^3}{6}, p_3(z)=z-\frac{z^3}{6}+ \frac{z^5}{120},.. \{0\},\{0,\pm\sqrt{6}\},\{0,\pm3.2369 \pm 0.6908 i\},.. 0 n=50 n","['real-analysis', 'complex-analysis', 'power-series', 'roots']"
29,Show $z^5+6z^3-10$ has exactly two zeroes on the annulus $2<\vert z \vert<3$,Show  has exactly two zeroes on the annulus,z^5+6z^3-10 2<\vert z \vert<3,So I need to show and find the zeros of $$z^5+6z^3-10$$ on $\{z \in \mathbb{C} : 2 < \vert z \vert < 3\}$ . Whats the quickest way of doing this? I was reading Gamelin-Greene and they split the function into BIG+little. Here is $6z^3$ my big and $z^5-10$ my little? OR By Rouche's Theorem can I let $f(z)=z^5+6z^3-10$ and let $h(z)=z^5-10$ ?,So I need to show and find the zeros of on . Whats the quickest way of doing this? I was reading Gamelin-Greene and they split the function into BIG+little. Here is my big and my little? OR By Rouche's Theorem can I let and let ?,z^5+6z^3-10 \{z \in \mathbb{C} : 2 < \vert z \vert < 3\} 6z^3 z^5-10 f(z)=z^5+6z^3-10 h(z)=z^5-10,"['complex-analysis', 'roots']"
30,Complex function maps into lines and circles,Complex function maps into lines and circles,,We have the following function: $$f(z) = \frac{z-1}{z-i}$$ What is $f$ of the real line (so $f(\mathbb{R}))$ ? What we did in the solutions was: $$f(\infty) = 1 \\ f(0) = 1/i = -i\\ f(1) =0\\$$ Then we said: $$|z-(a+bi)| = r\\ |1-a-bi| = r\implies (1-a)²+b²=r² \implies a = 1/2 \\ |-i-a-bi| = r\implies a²+(b+1)^2 = r²\implies b = -1/2\\ |a+bi| = r \implies\\ \implies a²+b² = r² \implies r = \sqrt{1/4 + 1/4} = \\ =\sqrt{2}/2 \implies |z-(1/2-i/2)| = \sqrt{2}/2\\$$ However I dont understand what we just did above. Can somebody explain what the procedure was and why. What would $f$ do to the imaginary line $\mathbb{I}$ or maybe the outside of the unit circle? I really need help with understanding the procedure for exercises like this one.,We have the following function: What is of the real line (so ? What we did in the solutions was: Then we said: However I dont understand what we just did above. Can somebody explain what the procedure was and why. What would do to the imaginary line or maybe the outside of the unit circle? I really need help with understanding the procedure for exercises like this one.,"f(z) = \frac{z-1}{z-i} f f(\mathbb{R})) f(\infty) = 1 \\
f(0) = 1/i = -i\\
f(1) =0\\ |z-(a+bi)| = r\\
|1-a-bi| = r\implies (1-a)²+b²=r² \implies a = 1/2 \\
|-i-a-bi| = r\implies a²+(b+1)^2 = r²\implies b = -1/2\\
|a+bi| = r \implies\\
\implies a²+b² = r² \implies r = \sqrt{1/4 + 1/4} = \\
=\sqrt{2}/2 \implies |z-(1/2-i/2)| = \sqrt{2}/2\\ f \mathbb{I}","['calculus', 'complex-analysis', 'complex-numbers', 'mobius-transformation']"
31,Does $\lim_{n\to+\infty}\sqrt[n]{z_1^{n}+z_2^{n}+...+z_k^{n}}=0\Rightarrow z_1=z_2=...=z_k=0$ hold for complex numbers?,Does  hold for complex numbers?,\lim_{n\to+\infty}\sqrt[n]{z_1^{n}+z_2^{n}+...+z_k^{n}}=0\Rightarrow z_1=z_2=...=z_k=0,"$$\lim_{n\to+\infty}\sqrt[n]{z_1^{n}+z_2^{n}+...+z_k^{n}}=0\Rightarrow z_1=z_2=...=z_k=0$$ This is right for real numbers because if we let $z_i=\max\{z_j\}$ , $$0=\lim_{n\to+\infty}\sqrt[n]{z_1^{n}+z_2^{n}+...+z_k^{n}}=\lim_{n\to+\infty}z_i\sqrt[n]{(\frac{z_1}{z_i})^{n}+(\frac{z_2}{z_i})^{n}+...+(\frac{z_i}{z_i})^{n}+...+(\frac{z_k}{z_i})^{n}}=z_i$$ $$\Rightarrow \max\{z_j\}=0\Rightarrow z_j=0,\ \ \forall j\in\{1,2,3,...k\}$$ My question is, does this hold for all complex numbers ? Since in this case $\sqrt[n]{x}$ may have multiple values, we will only use one of them, which makes the thing more complicate. Background: Let M be a $k\times k$ matrix, if $trace(M^n)=0,\ \ \forall n\in \mathbb{N}$ , then M is nilpotent. We can proof this with Newton's identity or Vandermonde determinant. But they are both algebraic methods. If the proposition above is true, we can find an analytical way.","This is right for real numbers because if we let , My question is, does this hold for all complex numbers ? Since in this case may have multiple values, we will only use one of them, which makes the thing more complicate. Background: Let M be a matrix, if , then M is nilpotent. We can proof this with Newton's identity or Vandermonde determinant. But they are both algebraic methods. If the proposition above is true, we can find an analytical way.","\lim_{n\to+\infty}\sqrt[n]{z_1^{n}+z_2^{n}+...+z_k^{n}}=0\Rightarrow z_1=z_2=...=z_k=0 z_i=\max\{z_j\} 0=\lim_{n\to+\infty}\sqrt[n]{z_1^{n}+z_2^{n}+...+z_k^{n}}=\lim_{n\to+\infty}z_i\sqrt[n]{(\frac{z_1}{z_i})^{n}+(\frac{z_2}{z_i})^{n}+...+(\frac{z_i}{z_i})^{n}+...+(\frac{z_k}{z_i})^{n}}=z_i \Rightarrow \max\{z_j\}=0\Rightarrow z_j=0,\ \ \forall j\in\{1,2,3,...k\} \sqrt[n]{x} k\times k trace(M^n)=0,\ \ \forall n\in \mathbb{N}","['complex-analysis', 'analysis']"
32,"On the number of roots of $p(z,\bar z)$",On the number of roots of,"p(z,\bar z)","Let $p$ be a polynomial with complex (or even real) coefficients in the variables $z$ , $\bar z$ , where $\bar z$ is the conjugate of $z$ . What can we say on the number of complex roots of $p$ ? Clearly $p$ can have both zero roots (e.g. $p(z,\bar z) = z + \bar z - i$ ) or infinite roots (e.g. $p(z,\bar z) = z + \bar z$ ). I'd like to know if we can say anything when the number of roots is known to be finite. Clearly this relates in some way to the number of real solutions to the system $$ \begin{cases} P(x,y) = 0, \\ Q(x,y) = 0, \end{cases} $$ where $P,Q$ are polynomials with real coefficients. I know some vague things about Bezout's Theorem, but since this is not my field I'm not sure if this result can be applied to this specific case. Besides, maybe there are some better results for this kind of polynomials which I have failed to find. Thanks in advance to everyone who will help!","Let be a polynomial with complex (or even real) coefficients in the variables , , where is the conjugate of . What can we say on the number of complex roots of ? Clearly can have both zero roots (e.g. ) or infinite roots (e.g. ). I'd like to know if we can say anything when the number of roots is known to be finite. Clearly this relates in some way to the number of real solutions to the system where are polynomials with real coefficients. I know some vague things about Bezout's Theorem, but since this is not my field I'm not sure if this result can be applied to this specific case. Besides, maybe there are some better results for this kind of polynomials which I have failed to find. Thanks in advance to everyone who will help!","p z \bar z \bar z z p p p(z,\bar z) = z + \bar z - i p(z,\bar z) = z + \bar z 
\begin{cases}
P(x,y) = 0, \\
Q(x,y) = 0,
\end{cases}
 P,Q","['complex-analysis', 'polynomials', 'complex-numbers', 'roots']"
33,Why do we use exponentials while integrating trigonometric functions in complex analysis,Why do we use exponentials while integrating trigonometric functions in complex analysis,,"Let p(x) be some polynomial function. Now, we have an integral of the form : $$I=\int_{-\infty}^{\infty} \frac{\cos(x)}{p(x)}dx$$ What is usually done is that, we define this integral as : $$I'=\int_{-\infty}^{\infty} \frac{e^{iz}}{p(z)}dz$$ Then we use the residue theorem, to integrate over the upper half of the complex plane. This gets separated into two integrals, over the curve and over the real axis. We can show that as $R\rightarrow\infty$ , the integral over the curve vanishes, and we are left with just the integral over the real axis. Then we use the fact that $\cos(x)$ is just the real part of $e^{ix}$ . So, comparing the real parts of the solution, we find the answer to our initial problem. My question is, why do we need to take $e^{iz}$ in the first place ? Is there some reason why we can't work with $\cos(x)$ directly? Moreover, depending on how we proceed, we can get different values of the residue. Consider the function $$f(z)=\frac{\cos(z)}{z^2}$$ Expanding using a taylor series, we can see, the $z^-1$ term doesn't exist, and so the residue is $0$ . Similarly, if I use the exponential, then I can use the following formula : $$Re(z=0)=\frac{1}{1!}\frac{d}{dz}(z-0)^2\frac{e^{iz}}{z^2}|_{z=0} = i$$ Hence, depending on what function I use, I'd get different values of the residue. The same thing happens for the function : $$f(z)=\frac{\cos(z)}{z^2}$$ I get the residue $\frac{\cosh(1)}{2i}$ or $\frac{1}{2ei}$ depending on whether I take the exponential or keep my cosine function. So, why do we replace trigonometric functions with complex exponentials in these problems ? I think this has something to do with the integral over the curve as $R\rightarrow\infty$ . Any help in understanding this would be highly appreciated.","Let p(x) be some polynomial function. Now, we have an integral of the form : What is usually done is that, we define this integral as : Then we use the residue theorem, to integrate over the upper half of the complex plane. This gets separated into two integrals, over the curve and over the real axis. We can show that as , the integral over the curve vanishes, and we are left with just the integral over the real axis. Then we use the fact that is just the real part of . So, comparing the real parts of the solution, we find the answer to our initial problem. My question is, why do we need to take in the first place ? Is there some reason why we can't work with directly? Moreover, depending on how we proceed, we can get different values of the residue. Consider the function Expanding using a taylor series, we can see, the term doesn't exist, and so the residue is . Similarly, if I use the exponential, then I can use the following formula : Hence, depending on what function I use, I'd get different values of the residue. The same thing happens for the function : I get the residue or depending on whether I take the exponential or keep my cosine function. So, why do we replace trigonometric functions with complex exponentials in these problems ? I think this has something to do with the integral over the curve as . Any help in understanding this would be highly appreciated.",I=\int_{-\infty}^{\infty} \frac{\cos(x)}{p(x)}dx I'=\int_{-\infty}^{\infty} \frac{e^{iz}}{p(z)}dz R\rightarrow\infty \cos(x) e^{ix} e^{iz} \cos(x) f(z)=\frac{\cos(z)}{z^2} z^-1 0 Re(z=0)=\frac{1}{1!}\frac{d}{dz}(z-0)^2\frac{e^{iz}}{z^2}|_{z=0} = i f(z)=\frac{\cos(z)}{z^2} \frac{\cosh(1)}{2i} \frac{1}{2ei} R\rightarrow\infty,"['integration', 'complex-analysis', 'complex-integration', 'residue-calculus', 'cauchy-principal-value']"
34,Classification of essential singularity with Maximum,Classification of essential singularity with Maximum,,"I am trying to proof the following statements: Let $f \colon \{ z \in \mathbb{C} : 0 < \vert z \vert < r_0 \}$ be a holomorphic function. For $0<r<r_0$ we define $M_r(f):= \operatorname{max} \{ \vert f(z) \vert : \vert z \vert = r\}$ . The following statements hold true: i) $0$ is removable iff $M_r(f)$ is bounded for $r \rightarrow 0$ . ii) $0$ is a Pole iff $M_r(f) \rightarrow \infty$ and $\exists l \in \mathbb{N}: M_r(z^lf)$ is bounded for $r \rightarrow 0$ . iii) $0$ is an essential singularity iff $\forall l \in \mathbb{N}:  M_r(z^lf)\rightarrow \infty $ I have managed to prove i) and ii). Also, because of that the direction ""<="" is clear to me for iii), but I am struggling with the other one. I would be very thankful for help.","I am trying to proof the following statements: Let be a holomorphic function. For we define . The following statements hold true: i) is removable iff is bounded for . ii) is a Pole iff and is bounded for . iii) is an essential singularity iff I have managed to prove i) and ii). Also, because of that the direction ""<="" is clear to me for iii), but I am struggling with the other one. I would be very thankful for help.",f \colon \{ z \in \mathbb{C} : 0 < \vert z \vert < r_0 \} 0<r<r_0 M_r(f):= \operatorname{max} \{ \vert f(z) \vert : \vert z \vert = r\} 0 M_r(f) r \rightarrow 0 0 M_r(f) \rightarrow \infty \exists l \in \mathbb{N}: M_r(z^lf) r \rightarrow 0 0 \forall l \in \mathbb{N}:  M_r(z^lf)\rightarrow \infty ,['complex-analysis']
35,Hermite polynomials for non-integer degree,Hermite polynomials for non-integer degree,,"I have solved an eigenvalue problem using Mathematica and the answer is in terms of Hermite polynomials. Now, for integer degrees $H_n(z)$ , I can find a nice definition. However, in the solution to the aforementioned problem, $n$ is not an integer. For example, my Mathematica solution contains HermiteH[a,b] where a and b are both real numbers. The ""degree"" of the polynomial in this case is a . Where can I find a definition for this? I suspect I can just generalize the contour integral to use a gamma function instead of a factorial so that $$ H_a(z) = \frac{\Gamma(a+1)}{2\pi i} \oint_C \frac{e^{2tx-t^2}}{t^{a+1}} \, dt $$ for a contour $C$ around the origin, vs. $$ H_n(z) = \frac{n!}{2\pi i} \oint_C \frac{e^{2tx-t^2}}{t^{n+1}} \, dt $$ where $n$ is a nonnegative integer. Is this correct, and if so, what's a relatively authoritative source for the generalization? Ideally, I'd prefer a series representation (or something else a bit more explicit) if it's known.","I have solved an eigenvalue problem using Mathematica and the answer is in terms of Hermite polynomials. Now, for integer degrees , I can find a nice definition. However, in the solution to the aforementioned problem, is not an integer. For example, my Mathematica solution contains HermiteH[a,b] where a and b are both real numbers. The ""degree"" of the polynomial in this case is a . Where can I find a definition for this? I suspect I can just generalize the contour integral to use a gamma function instead of a factorial so that for a contour around the origin, vs. where is a nonnegative integer. Is this correct, and if so, what's a relatively authoritative source for the generalization? Ideally, I'd prefer a series representation (or something else a bit more explicit) if it's known.","H_n(z) n 
H_a(z) = \frac{\Gamma(a+1)}{2\pi i} \oint_C \frac{e^{2tx-t^2}}{t^{a+1}} \, dt
 C 
H_n(z) = \frac{n!}{2\pi i} \oint_C \frac{e^{2tx-t^2}}{t^{n+1}} \, dt
 n","['complex-analysis', 'physics', 'mathematica', 'hermite-polynomials']"
36,A Counterexample to the Mean Value Theorem for Integrals (Complex Case),A Counterexample to the Mean Value Theorem for Integrals (Complex Case),,"The problem at hand is to prove the following ""counterexample"" to the Mean Value Theorem: Let $f:\left[0, 2\pi\right] \to \mathbb{R}$ be Riemann-integrable, $f(x) \geq 0 \ \forall \, x \in \left[0,2\pi\right]$ and $\int_{0}^{2\pi} f(x) \text{d}x > 0$ . Prove there exists a continuous function $g: \left[0, 2\pi\right] \to \mathbb{C}$ , such that for all $\xi \in \left[0, 2\pi\right]$ it holds: $$\int_{0}^{2\pi} f(x)g(x)\text{d}x \neq g(\xi)\int_{0}^{2\pi} f(x)\text{d}x$$ . Own thoughts and tries: Naturally, we notice that $g(x)\in \mathbb{C} \ \forall \, x \in \left[0,2\pi\right]$ and this already suggests an idea. For example, we know that $e^{ix} \neq 0$ for all $x \in \left[0, 2\pi\right]$ and still $\int_{0}^{2\pi} e^{ix} \text{d}x = 0$ . Therefore, it would suffice to find $g : \left[0, 2\pi\right] \to \mathbb{C}$ such that $g(\xi) \neq 0 \ \forall \, \xi \in \left[0, 2\pi\right]$ and for which $\int_{0}^{2\pi} f(x)g(x)\text{d}x = 0$ . So I imagine that multiplication by $g$ could result in $fg$ being shifted in a way such that ""half of the integrand is below zero"". However, we still need to use the fact that $f(0)=f(2\pi)$ and I haven't got much of an idea how to utilize that. Also, there is no condition on the sign of $g$ and so boundedness claims from Riemann-integrability don't look like much help either. Any enlightening hint or advice would be much appreciated. Ideally, it would guide towards the solution without revealing it completely (just to help get off the saddle point). UPDATE: Actually, knowing $f(0)=f(2\pi)$ allows us to continue $f$ on $\mathbb{R}$ by means of $2\pi$ -periodisation. Identifying the continuation of $f$ with $f$ , write $\int_{0}^{2\pi} f(x)\text{d}x = \int_{-\pi}^{\pi} f(x)\text{d}x > 0$ . Further, if we assume that g is $C_{2\pi}^{0}(\mathbb{R})$ (i.e. continuous and $2\pi$ -periodic on $\mathbb{R}$ ) and even (i.e. $g(x)=g(-x)$ for all $x\in\left[0,2\pi\right]$ ), we can rewrite the integral as (since (fg) is also $2\pi$ -periodic): $$\int_{0}^{2\pi} f(x)g(x)\text{d}x = \int_{-\pi}^{\pi} f(x)g(x)\text{d}x = \int_{-\pi}^{\pi} f(x)g(-x)\text{d}x =(f * g)(0)$$ where $(f*g)$ denotes the convolution of the functions. Following this reasoning, it suffices to find $g \in C_{2\pi}^{0}(\mathbb{R})$ - even, such that $(f*g)(0) = 0$ and $g(x) \neq 0$ for all $x \in \left[0,2\pi\right]$ . Any ideas (perhaps using the Convolution theorem)?","The problem at hand is to prove the following ""counterexample"" to the Mean Value Theorem: Let be Riemann-integrable, and . Prove there exists a continuous function , such that for all it holds: . Own thoughts and tries: Naturally, we notice that and this already suggests an idea. For example, we know that for all and still . Therefore, it would suffice to find such that and for which . So I imagine that multiplication by could result in being shifted in a way such that ""half of the integrand is below zero"". However, we still need to use the fact that and I haven't got much of an idea how to utilize that. Also, there is no condition on the sign of and so boundedness claims from Riemann-integrability don't look like much help either. Any enlightening hint or advice would be much appreciated. Ideally, it would guide towards the solution without revealing it completely (just to help get off the saddle point). UPDATE: Actually, knowing allows us to continue on by means of -periodisation. Identifying the continuation of with , write . Further, if we assume that g is (i.e. continuous and -periodic on ) and even (i.e. for all ), we can rewrite the integral as (since (fg) is also -periodic): where denotes the convolution of the functions. Following this reasoning, it suffices to find - even, such that and for all . Any ideas (perhaps using the Convolution theorem)?","f:\left[0, 2\pi\right] \to \mathbb{R} f(x) \geq 0 \ \forall \, x \in \left[0,2\pi\right] \int_{0}^{2\pi} f(x) \text{d}x > 0 g: \left[0, 2\pi\right] \to \mathbb{C} \xi \in \left[0, 2\pi\right] \int_{0}^{2\pi} f(x)g(x)\text{d}x \neq g(\xi)\int_{0}^{2\pi} f(x)\text{d}x g(x)\in \mathbb{C} \ \forall \, x \in \left[0,2\pi\right] e^{ix} \neq 0 x \in \left[0, 2\pi\right] \int_{0}^{2\pi} e^{ix} \text{d}x = 0 g : \left[0, 2\pi\right] \to \mathbb{C} g(\xi) \neq 0 \ \forall \, \xi \in \left[0, 2\pi\right] \int_{0}^{2\pi} f(x)g(x)\text{d}x = 0 g fg f(0)=f(2\pi) g f(0)=f(2\pi) f \mathbb{R} 2\pi f f \int_{0}^{2\pi} f(x)\text{d}x = \int_{-\pi}^{\pi} f(x)\text{d}x > 0 C_{2\pi}^{0}(\mathbb{R}) 2\pi \mathbb{R} g(x)=g(-x) x\in\left[0,2\pi\right] 2\pi \int_{0}^{2\pi} f(x)g(x)\text{d}x = \int_{-\pi}^{\pi} f(x)g(x)\text{d}x = \int_{-\pi}^{\pi} f(x)g(-x)\text{d}x =(f * g)(0) (f*g) g \in C_{2\pi}^{0}(\mathbb{R}) (f*g)(0) = 0 g(x) \neq 0 x \in \left[0,2\pi\right]","['complex-analysis', 'fourier-analysis', 'mean-value-theorem']"
37,Proof of expansion of $e^{ix}$,Proof of expansion of,e^{ix},"I am reading Lévy Processes and Infinitely Divisible Distributions by Ken-iti Sato and I don't understand how the expansion $$\tag{1} e^{iu} = \sum_{k=0}^{n-1}\frac{(iu)^k}{k!} + \theta\frac{|u|^n}{n!} $$ for each $u\in\mathbb{R}$ and some $\theta\in\mathbb{C}$ with $|\theta|\leq 1$ is derived in Lemma 8.6. The proof just states that it follows immediately from the identity $$\tag{2} e^{iu} = \sum_{k=0}^{n-1}\frac{(iu)^k}{k!} + \frac{i^n}{(n-1)!}\int_0^u(u-v)^{n-1}e^{iv}dv\ . $$ My questions are: Where does identity (2) come from? The Taylor formula for real-valued functions seems to yield this expression if applied to $f(u)=e^{iu}$ , but this is not a real-valued function and all versions for complex functions look different. How is the use of the standard Taylor formula justified for functions $f:\mathbb{R}\to\mathbb{C}$ ? How does (1) follow from (2)? I thought about some kind of mean value theorem, but wasn't able to see how the simple expression in (1) can be obtained from the integral in (2). For my purposes, it would be sufficient to derive the formula for $n=2$ , if that makes it easier to explain.","I am reading Lévy Processes and Infinitely Divisible Distributions by Ken-iti Sato and I don't understand how the expansion for each and some with is derived in Lemma 8.6. The proof just states that it follows immediately from the identity My questions are: Where does identity (2) come from? The Taylor formula for real-valued functions seems to yield this expression if applied to , but this is not a real-valued function and all versions for complex functions look different. How is the use of the standard Taylor formula justified for functions ? How does (1) follow from (2)? I thought about some kind of mean value theorem, but wasn't able to see how the simple expression in (1) can be obtained from the integral in (2). For my purposes, it would be sufficient to derive the formula for , if that makes it easier to explain.","\tag{1}
e^{iu} = \sum_{k=0}^{n-1}\frac{(iu)^k}{k!} + \theta\frac{|u|^n}{n!}
 u\in\mathbb{R} \theta\in\mathbb{C} |\theta|\leq 1 \tag{2}
e^{iu} = \sum_{k=0}^{n-1}\frac{(iu)^k}{k!} + \frac{i^n}{(n-1)!}\int_0^u(u-v)^{n-1}e^{iv}dv\ .
 f(u)=e^{iu} f:\mathbb{R}\to\mathbb{C} n=2","['real-analysis', 'calculus', 'complex-analysis', 'taylor-expansion', 'exponential-function']"
38,Representation of $\sum_{k=1}^{\infty} \frac{f^{(k)}(a)}{k!} k^{-p} $ in terms of another series,Representation of  in terms of another series,\sum_{k=1}^{\infty} \frac{f^{(k)}(a)}{k!} k^{-p} ,"I face a problem when I'm dealing with one of the transforms and the problem is as follows: Suppose that we have $$ f(a+z) = \sum_{k=0}^{\infty} \frac{f^{(k)}(a)}{k!}z^{k} \tag{1} $$ $$ f\left(a+e^{\theta x}\right) = \sum_{k=0}^{\infty} \frac{f^{(k)}(a)}{k!}e^{\theta k x} \tag{2} $$ and I want to express the following series in terms of equation $\text{(1)}$ or $\text{(2)}$ $$\sum_{k=1}^{\infty} \frac{f^{(k)}(a)}{k!} k^{-p} $$ where $ 0 < p < 1 $ . Is there any way that we can do this thing? Or, is it impossible to represent the third series in terms of equation $\text{(1)}$ or $\text{(2)}$","I face a problem when I'm dealing with one of the transforms and the problem is as follows: Suppose that we have and I want to express the following series in terms of equation or where . Is there any way that we can do this thing? Or, is it impossible to represent the third series in terms of equation or", f(a+z) = \sum_{k=0}^{\infty} \frac{f^{(k)}(a)}{k!}z^{k} \tag{1}   f\left(a+e^{\theta x}\right) = \sum_{k=0}^{\infty} \frac{f^{(k)}(a)}{k!}e^{\theta k x} \tag{2}  \text{(1)} \text{(2)} \sum_{k=1}^{\infty} \frac{f^{(k)}(a)}{k!} k^{-p}   0 < p < 1  \text{(1)} \text{(2)},"['real-analysis', 'integration', 'complex-analysis', 'fourier-series', 'fourier-transform']"
39,What are the possible expansions of f(z) = $\frac{e^{1/z}}{z}$ about z = i,What are the possible expansions of f(z) =  about z = i,\frac{e^{1/z}}{z},"I am trying to find all the possible expansions of f(z) = $\frac{e^{1/z}}{z}$ about  = i, and I got something but I am not sure if my reasoning is right. We know we have a singularity at z = 0, so we are going to have two domains. The first one is |z| < 1, while the second one is |z| > 1. If  understand it correctly, the first domain (inside the disk of radius 1), will be expanded with a Taylor series, due to the absence of singularities, while the second one (|z| > 1) will need a Laurent series to be computed, as we have a singularity at z = 0. This is what I have done so far: $$\frac{e^{1/z}}{z} = \frac{e^{-i}}{z} + \frac{e^{-i}(z-i)}{z} + \frac{(e^{-i}+2)(z-i)^2}{2z} + . . .$$ But I am not sure if that is correct, and I am not sure how to account for the different domains.","I am trying to find all the possible expansions of f(z) = about  = i, and I got something but I am not sure if my reasoning is right. We know we have a singularity at z = 0, so we are going to have two domains. The first one is |z| < 1, while the second one is |z| > 1. If  understand it correctly, the first domain (inside the disk of radius 1), will be expanded with a Taylor series, due to the absence of singularities, while the second one (|z| > 1) will need a Laurent series to be computed, as we have a singularity at z = 0. This is what I have done so far: But I am not sure if that is correct, and I am not sure how to account for the different domains.",\frac{e^{1/z}}{z} \frac{e^{1/z}}{z} = \frac{e^{-i}}{z} + \frac{e^{-i}(z-i)}{z} + \frac{(e^{-i}+2)(z-i)^2}{2z} + . . .,"['complex-analysis', 'complex-integration']"
40,Reference for Complex Manifolds for Great Picard Theorem and Julia Sets,Reference for Complex Manifolds for Great Picard Theorem and Julia Sets,,"I’ve recently been looking to understand the proofs of some theorems about complex analysis and Julia sets that require results on complex manifolds, especially The Great Picard Theorem. I need The Uniformization Theorem, then I need to understand why the plane with two points removed can’t have the entire complex plane as its cover. I know basic complex analysis, real differential topology and results on coverings from algebraic topology. Where can I find a text with the sort of results I need?","I’ve recently been looking to understand the proofs of some theorems about complex analysis and Julia sets that require results on complex manifolds, especially The Great Picard Theorem. I need The Uniformization Theorem, then I need to understand why the plane with two points removed can’t have the entire complex plane as its cover. I know basic complex analysis, real differential topology and results on coverings from algebraic topology. Where can I find a text with the sort of results I need?",,"['complex-analysis', 'reference-request', 'complex-manifolds']"
41,"How to prove or disprove $ |r'(a)| \leq c_1 \sup_{x \in [a-1/2,a+1/2]} |r(x)|$?",How to prove or disprove ?," |r'(a)| \leq c_1 \sup_{x \in [a-1/2,a+1/2]} |r(x)|","Let matrix $ A  = \begin{bmatrix} 		a & 1 \\ 0 & a 	\end{bmatrix}$ is a Jordan matrix with $ -1 < a < 1 $ . Let $ r(z) = \frac{p(z)}{q(z)} $ is any an irreducible rational function, where $p(z)$ and $q(z)$ are polynomials of degree $k$ with real coefficients , and $p(z)$ and $q(z)$ are not zero on the interval $E = \{v^\top Av | v \in \mathbb{R}^2, \|v\| = 1\} = [a-1/2, a+1/2]$ . My problem is finding a positive number $c$ (possibly depends on $k$ ) such that \begin{equation}\notag 		\|r(A)\|_2 \leq c \sup_{x \in E} |r(x)|. \end{equation} Now I have get that \begin{equation}\notag 		r(A) = \begin{bmatrix} 			r(a) & r'(a) \\ 0 & r(a) 		\end{bmatrix} \end{equation} and $\|r(A)\|_2 \leq \sqrt{2}\|r(A)\|_1 = \sqrt{2}(|r(a)| + |r'(a)|)$ . Thus I guess that there may exist a positive number $c_1$ (possibly depends on $k$ ) such that \begin{equation}\notag 		|r'(a)|  \leq c_1 \sup_{x \in E} |r(x)|. \end{equation} However, I don't know how to prove or disprove this conjecture.","Let matrix is a Jordan matrix with . Let is any an irreducible rational function, where and are polynomials of degree with real coefficients , and and are not zero on the interval . My problem is finding a positive number (possibly depends on ) such that Now I have get that and . Thus I guess that there may exist a positive number (possibly depends on ) such that However, I don't know how to prove or disprove this conjecture."," A  = \begin{bmatrix}
		a & 1 \\ 0 & a
	\end{bmatrix}  -1 < a < 1   r(z) = \frac{p(z)}{q(z)}  p(z) q(z) k p(z) q(z) E = \{v^\top Av | v \in \mathbb{R}^2, \|v\| = 1\} = [a-1/2, a+1/2] c k \begin{equation}\notag
		\|r(A)\|_2 \leq c \sup_{x \in E} |r(x)|.
\end{equation} \begin{equation}\notag
		r(A) = \begin{bmatrix}
			r(a) & r'(a) \\ 0 & r(a)
		\end{bmatrix}
\end{equation} \|r(A)\|_2 \leq \sqrt{2}\|r(A)\|_1 = \sqrt{2}(|r(a)| + |r'(a)|) c_1 k \begin{equation}\notag
		|r'(a)|  \leq c_1 \sup_{x \in E} |r(x)|.
\end{equation}","['real-analysis', 'complex-analysis', 'functional-analysis', 'analysis', 'rational-functions']"
42,"Is there an interesting example of a chaotic dynamical system on $\widehat{\mathbb{C}}^n$, where $\widehat{\mathbb{C}}$ is the Riemann sphere?","Is there an interesting example of a chaotic dynamical system on , where  is the Riemann sphere?",\widehat{\mathbb{C}}^n \widehat{\mathbb{C}},"This is for a mathematical visualization project I'm interested in. I am looking for an example of a chaotic, continuous-time dynamical system on $\widehat{\mathbb{C}}^n$ . Here $n$ is arbitrary, but I would also like to hear about examples for specific $n$ . I am particularly interested in systems that are highly chaotic: i. e. they generally do not converge to a stable orbit or limit, and are quite ""irregular"". Topological mixing might be a desirable property. Ideally such a system will be specified by a differential equation and make some use of the complex structure.  I am not very well-versed in dynamical systems, so please excuse me if this comes off as obtuse. Can anyone please provide an example of such a system, or direct me to a reference where I can read about explicit examples of complex dynamical systems along these lines? Thank you.","This is for a mathematical visualization project I'm interested in. I am looking for an example of a chaotic, continuous-time dynamical system on . Here is arbitrary, but I would also like to hear about examples for specific . I am particularly interested in systems that are highly chaotic: i. e. they generally do not converge to a stable orbit or limit, and are quite ""irregular"". Topological mixing might be a desirable property. Ideally such a system will be specified by a differential equation and make some use of the complex structure.  I am not very well-versed in dynamical systems, so please excuse me if this comes off as obtuse. Can anyone please provide an example of such a system, or direct me to a reference where I can read about explicit examples of complex dynamical systems along these lines? Thank you.",\widehat{\mathbb{C}}^n n n,"['complex-analysis', 'dynamical-systems']"
43,Bound the derivative at zero of an analytic function with $f(0.5) = 0$,Bound the derivative at zero of an analytic function with,f(0.5) = 0,"The following is a problem from the UW-Madison complex analysis qualifying exam. Let $f:\mathbb{D}\to\mathbb{D}$ be analytic, where $\mathbb{D}=\{z : |z| < 1\}$ . Assume that $f(\frac{1}{2}) = 0$ . Show that $|f'(0)| \leq \frac{25}{32}$ . Using the Schwartz-Pick (S-P) lemma, we can say $$|f(0)|= \left|\frac{f(1/2)-f(0)}{1-\overline{f(1/2)}f(0)}\right| \leq \left|\frac{1/2-0}{1-\overline{\frac{1}{2}}0}\right| = 1/2.$$ Not sure if this will help. There is a first part to this qual problem: Show that $|f'(0)| \leq 1-|f(0)|^2.$ It is a simple consequence of S-P lemma for $z=0$ .","The following is a problem from the UW-Madison complex analysis qualifying exam. Let be analytic, where . Assume that . Show that . Using the Schwartz-Pick (S-P) lemma, we can say Not sure if this will help. There is a first part to this qual problem: Show that It is a simple consequence of S-P lemma for .",f:\mathbb{D}\to\mathbb{D} \mathbb{D}=\{z : |z| < 1\} f(\frac{1}{2}) = 0 |f'(0)| \leq \frac{25}{32} |f(0)|= \left|\frac{f(1/2)-f(0)}{1-\overline{f(1/2)}f(0)}\right| \leq \left|\frac{1/2-0}{1-\overline{\frac{1}{2}}0}\right| = 1/2. |f'(0)| \leq 1-|f(0)|^2. z=0,[]
44,Contour integral $\oint_{|z|=1}\frac{z^2\sin(1/z)}{z-2}dz$,Contour integral,\oint_{|z|=1}\frac{z^2\sin(1/z)}{z-2}dz,"How do I compute this integral? $$\oint_{|z|=1}\frac{z^2\sin(1/z)}{z-2} \, dz$$ I tried substituting $1/z$ with $z$ and ended up with $$\oint_{|z|=1}\frac{\sin(z)}{z^3(1-2z)} \, dz$$ At this point I thought of using the residue theorem and got $2i\pi(2-4\sin(\frac{1}{2}))$ but the correct answer should be $\frac{i\pi}{6}$ . Can someone help me?",How do I compute this integral? I tried substituting with and ended up with At this point I thought of using the residue theorem and got but the correct answer should be . Can someone help me?,"\oint_{|z|=1}\frac{z^2\sin(1/z)}{z-2} \, dz 1/z z \oint_{|z|=1}\frac{\sin(z)}{z^3(1-2z)} \, dz 2i\pi(2-4\sin(\frac{1}{2})) \frac{i\pi}{6}","['complex-analysis', 'contour-integration', 'complex-integration']"
45,"Let $f:\mathbb{C}\to \mathbb{C}$, $f(z)=z^2$ and $B = \{z \in \mathbb{C},Re(z)\leq0\}$. Show that $f^{-1}(B)$ its a closed set","Let ,  and . Show that  its a closed set","f:\mathbb{C}\to \mathbb{C} f(z)=z^2 B = \{z \in \mathbb{C},Re(z)\leq0\} f^{-1}(B)","Let $f:\mathbb{C}\to \mathbb{C}$ , $f(z)=z^2$ and $B = \{z \in \mathbb{C},Re(z)\leq0\}$ . Show that $f^{-1}(B)$ its a closed set. This is my attempt: Let $w \in B, w =a+bi, a\leq 0$ Putting in the polar form: $|w|\cdot \cos(\theta) = a \implies \cos(\theta)=\frac{a}{\sqrt{a^2+b^2}}\leq 0$ $\cos(\theta)\leq 0 \implies \frac{\pi}{2}\leq\theta\leq\frac{3\pi}{2}$ I think that the interval of values to the argument of w its relevant to the question. But I dont know how to proceed from this point. I tried to part of the definition of a inverse function: $$ f: A \to B $$ $$ f^{-1}(X) = \{x\in A: f(x) \in X\} $$ But i didnt get anywhere as well","Let , and . Show that its a closed set. This is my attempt: Let Putting in the polar form: I think that the interval of values to the argument of w its relevant to the question. But I dont know how to proceed from this point. I tried to part of the definition of a inverse function: But i didnt get anywhere as well","f:\mathbb{C}\to \mathbb{C} f(z)=z^2 B = \{z \in \mathbb{C},Re(z)\leq0\} f^{-1}(B) w \in B, w =a+bi, a\leq 0 |w|\cdot \cos(\theta) = a \implies \cos(\theta)=\frac{a}{\sqrt{a^2+b^2}}\leq 0 \cos(\theta)\leq 0 \implies \frac{\pi}{2}\leq\theta\leq\frac{3\pi}{2}  f: A \to B   f^{-1}(X) = \{x\in A: f(x) \in X\} ","['complex-analysis', 'complex-numbers']"
46,$(a\otimes b)^z = a^z \otimes b^z$ for elements in a $C^*$-algebra and $z\in \mathbb{C}$.,for elements in a -algebra and .,(a\otimes b)^z = a^z \otimes b^z C^* z\in \mathbb{C},"Let $A$ and $B$ be unital $C^*$ -algebras. Let $a\in A$ and $b \in B$ be positive and invertible elements, so that in particular we can use the continuous functional calculus to define $a^z$ and $b^z$ and $(a\otimes b)^z$ where $z\in \mathbb{C}$ . I want to show that $$(a\otimes b)^z = a^z\otimes b^z$$ as elements of the $C^*$ -algebra $A\otimes B$ (say equiped with the minimal norm, but I don't think the choice of norm matters). Attempt : Let $n \in \mathbb{N}\setminus \{0\}$ . Then clearly $(a\otimes b)^{1/n} = a^{1/n} \otimes b^{1/n}$ by uniqueness of the positive $n^{th}$ root of a positive element. Hence, $(a\otimes b)^{m/n}= (a^{1/n}\otimes b^{1/n})^m = a^{m/n}\otimes b^{m/n}$ for all $m,n \in \mathbb{N}\setminus \{0\}$ . Applying the same argument with $a$ replaced by $a^{-1}$ and $b$ by $b^{-1}$ yields $(a\otimes b)^q = a^q \otimes b^q$ for all $q\in \mathbb{Q}$ . By density of $\mathbb{Q}$ in $\mathbb{R}$ and using the fact that $x \mapsto x^z$ is uniformly continuous on compacts, I can then deduce that $(a\otimes b)^r = a^r \otimes b^r$ for all $r\in \mathbb{R}$ . How can I deduce that the equality holds for all complex numbers? Perhaps we must prove that $$z \mapsto (a\otimes b)^z, \quad z \mapsto a^z \otimes b^z$$ are analytic functions $\mathbb{C}\to A\otimes B$ that agree on $\mathbb{R}$ , so that they agree everywhere?","Let and be unital -algebras. Let and be positive and invertible elements, so that in particular we can use the continuous functional calculus to define and and where . I want to show that as elements of the -algebra (say equiped with the minimal norm, but I don't think the choice of norm matters). Attempt : Let . Then clearly by uniqueness of the positive root of a positive element. Hence, for all . Applying the same argument with replaced by and by yields for all . By density of in and using the fact that is uniformly continuous on compacts, I can then deduce that for all . How can I deduce that the equality holds for all complex numbers? Perhaps we must prove that are analytic functions that agree on , so that they agree everywhere?","A B C^* a\in A b \in B a^z b^z (a\otimes b)^z z\in \mathbb{C} (a\otimes b)^z = a^z\otimes b^z C^* A\otimes B n \in \mathbb{N}\setminus \{0\} (a\otimes b)^{1/n} = a^{1/n} \otimes b^{1/n} n^{th} (a\otimes b)^{m/n}= (a^{1/n}\otimes b^{1/n})^m = a^{m/n}\otimes b^{m/n} m,n \in \mathbb{N}\setminus \{0\} a a^{-1} b b^{-1} (a\otimes b)^q = a^q \otimes b^q q\in \mathbb{Q} \mathbb{Q} \mathbb{R} x \mapsto x^z (a\otimes b)^r = a^r \otimes b^r r\in \mathbb{R} z \mapsto (a\otimes b)^z, \quad z \mapsto a^z \otimes b^z \mathbb{C}\to A\otimes B \mathbb{R}","['complex-analysis', 'operator-theory']"
47,Charaterization of the component of exterior bundle,Charaterization of the component of exterior bundle,,"Let $(M,J)$ be an almost complex manifold,consider the complexified tangent bundle it has two subbundle $T^{(0,1)}M$ and $T^{(1,0)}M$ ,where $T^{(0,1)}M$ is the eigenbundle of eigen value $i$ associcated to $J$ . Then we can consider the decomposition of the exterior bundle $$\Lambda^{1,0} M:=\left\{\xi \in \Lambda_{\mathbb{C}}^{1} M \mid \xi(Z)=0 \forall Z \in T^{0,1} M\right\}\\\Lambda^{0,1} M:=\left\{\xi \in \Lambda_{\mathbb{C}}^{1} M \mid \xi(Z)=0 \forall Z \in T^{1,0} M\right\}$$ Furthure more we have, $\Lambda^{p,q} = \Lambda^{p, 0} \otimes \Lambda^{0, q}$ Then I need to prove the following charaterization (which appears on Moroianu's Kahler geometry note): $\left.\omega \text { is a section of } \Lambda^{k, 0} M \text { if and only if } Z\right\lrcorner \omega=0 \text { for all } Z \in T^{0,1} M \text {. }$ $\omega$ is a section of $\Lambda^{p, q} M$ if and only if it vanishes whenever applied to $p+1$ vectors from $T^{1,0} M$ or to $q+1$ vectors from $T^{0,1} M$ given $\omega\in \Lambda^{1,0}M$ the $(0,2)$ component of $d\omega$ vanish if and only if for all $Z,W \in T^{0,1}M$ , $d\omega (Z,W) = 0$ My attempt:If we write under the local coordinate the only if part is easy to check,I don't know how to check the if part.","Let be an almost complex manifold,consider the complexified tangent bundle it has two subbundle and ,where is the eigenbundle of eigen value associcated to . Then we can consider the decomposition of the exterior bundle Furthure more we have, Then I need to prove the following charaterization (which appears on Moroianu's Kahler geometry note): is a section of if and only if it vanishes whenever applied to vectors from or to vectors from given the component of vanish if and only if for all , My attempt:If we write under the local coordinate the only if part is easy to check,I don't know how to check the if part.","(M,J) T^{(0,1)}M T^{(1,0)}M T^{(0,1)}M i J \Lambda^{1,0} M:=\left\{\xi \in \Lambda_{\mathbb{C}}^{1} M \mid \xi(Z)=0 \forall Z \in T^{0,1} M\right\}\\\Lambda^{0,1} M:=\left\{\xi \in \Lambda_{\mathbb{C}}^{1} M \mid \xi(Z)=0 \forall Z \in T^{1,0} M\right\} \Lambda^{p,q} = \Lambda^{p, 0} \otimes \Lambda^{0, q} \left.\omega \text { is a section of } \Lambda^{k, 0} M \text { if and only if } Z\right\lrcorner \omega=0 \text { for all } Z \in T^{0,1} M \text {. } \omega \Lambda^{p, q} M p+1 T^{1,0} M q+1 T^{0,1} M \omega\in \Lambda^{1,0}M (0,2) d\omega Z,W \in T^{0,1}M d\omega (Z,W) = 0","['complex-analysis', 'differential-geometry', 'smooth-manifolds']"
48,An exercise from Stein's complex analysis - Phragmen-Lindelof principle,An exercise from Stein's complex analysis - Phragmen-Lindelof principle,,"I am considering exercise 9 from chapter 4 of Stein and Sharkarchi's complex analysis: (a). Let $F$ be a holomorphic function in the right half-plane that extends continuously to the boundary, that is, the imaginary axis. Suppose that $|F(iy)|\leq 1$ for all $y \in \mathbb{R}$ , and $|F(z)| \leq Ce^{c|z|^\gamma}$ for some $c,C >0$ and $0 <\gamma <1$ . Prove that $|F(z) |\leq 1$ for all $z $ in the right half plane. (b). More generally, let $S$ be a sector whose vertex is the origin, and forming an angle of $\pi/\beta$ . Let $F$ be a holomorphic function in $S$ that is continuous on the closure of $S$ , so that $|F(z)| \leq 1$ on the boundary of $S$ and $|F(z)|\leq Ce^{c|z|^\alpha}$ for some $c,C>0$ and $0<\alpha < \beta$ . Prove that $|F(z)| \leq 1$ for all $z \in S$ . I was able to prove part (a) by considering the function $F_{\epsilon}(z) = F(z) e^{-\epsilon z^D}$ , where $\gamma<D<1$ and showing that $F_{\epsilon}(z)\leq 1$ for all $z$ in the right half plane. This is the idea behind the Phragmen-Lindelof principle. I assume that a similar approach is needed for part (b), but I can't seem to find a good candidate for $F_\epsilon$ in this case. For reference, Chapter 4 of Stein's complex analysis gives a nice demonstration of this proof tactic.","I am considering exercise 9 from chapter 4 of Stein and Sharkarchi's complex analysis: (a). Let be a holomorphic function in the right half-plane that extends continuously to the boundary, that is, the imaginary axis. Suppose that for all , and for some and . Prove that for all in the right half plane. (b). More generally, let be a sector whose vertex is the origin, and forming an angle of . Let be a holomorphic function in that is continuous on the closure of , so that on the boundary of and for some and . Prove that for all . I was able to prove part (a) by considering the function , where and showing that for all in the right half plane. This is the idea behind the Phragmen-Lindelof principle. I assume that a similar approach is needed for part (b), but I can't seem to find a good candidate for in this case. For reference, Chapter 4 of Stein's complex analysis gives a nice demonstration of this proof tactic.","F |F(iy)|\leq 1 y \in \mathbb{R} |F(z)| \leq Ce^{c|z|^\gamma} c,C >0 0 <\gamma <1 |F(z) |\leq 1 z  S \pi/\beta F S S |F(z)| \leq 1 S |F(z)|\leq Ce^{c|z|^\alpha} c,C>0 0<\alpha < \beta |F(z)| \leq 1 z \in S F_{\epsilon}(z) = F(z) e^{-\epsilon z^D} \gamma<D<1 F_{\epsilon}(z)\leq 1 z F_\epsilon","['complex-analysis', 'fourier-analysis', 'maximum-principle']"
49,"Complex Analysis: Analytical Function $ f(z) ={z^{2}}/({\mathrm{e}^{x} \cos y+i \mathrm{e}^{x} \sin y})\,$?",Complex Analysis: Analytical Function ?," f(z) ={z^{2}}/({\mathrm{e}^{x} \cos y+i \mathrm{e}^{x} \sin y})\,","Problem In which region of the complex plane is the following function analytic? $$f(z) = \dfrac{z^{2}}{\mathrm{e}^{x} \cos y+i \mathrm{e}^{x} \sin y}$$ If the function has a derivative over its domain, determine $f'(z)$ . Progress First I expressed $f (z)$ as $u (x, y) + v (x, y).$ $$f(z) = \left[ \dfrac{x.\cos y + y.\sin y}{\mathrm{e}^x} + \left( \dfrac{y\cos y + x\sin y}{\mathrm{e}^x} \right) i \right],$$ $$f(z) = u(x,y) + v(x,y).$$ Then I used the Cauchy-Riemann equations $\dfrac{\partial u}{\partial x} = -\left(\cos\left(y\right)x+y\sin\left(y\right)-\cos\left(y\right)\right)\mathrm{e}^{-x}$ $\dfrac{\partial u}{\partial y} = \mathrm{e}^{-x}\left(-x\sin\left(y\right)+\sin\left(y\right)+y\cos\left(y\right)\right)$ $\dfrac{\partial v}{\partial y} = \mathrm{e}^{-x}\left(-y\sin\left(y\right)+x\cos\left(y\right)+\cos\left(y\right)\right)$ $\dfrac{\partial v}{\partial x} = -\left(\sin\left(y\right)x-\sin\left(y\right)+y\cos\left(y\right)\right)\mathrm{e}^{-x}$ then $\begin{aligned} &\frac{\partial u}{\partial x}=\frac{\partial v}{\partial y} \\ &\frac{\partial v}{\partial x}=-\frac{\partial u}{\partial y} \end{aligned}$ But I don't really understand the rationale for using the Cauchy-Rieman equations in this problem, and I can't determine what the region is. I am trying to see it from the most essential aspect (using epsilon and delta, and compact sets) but I don't understand.","Problem In which region of the complex plane is the following function analytic? If the function has a derivative over its domain, determine . Progress First I expressed as Then I used the Cauchy-Riemann equations then But I don't really understand the rationale for using the Cauchy-Rieman equations in this problem, and I can't determine what the region is. I am trying to see it from the most essential aspect (using epsilon and delta, and compact sets) but I don't understand.","f(z) = \dfrac{z^{2}}{\mathrm{e}^{x} \cos y+i \mathrm{e}^{x} \sin y} f'(z) f (z) u (x, y) + v (x, y). f(z) = \left[ \dfrac{x.\cos y + y.\sin y}{\mathrm{e}^x} + \left( \dfrac{y\cos y + x\sin y}{\mathrm{e}^x} \right) i \right], f(z) = u(x,y) + v(x,y). \dfrac{\partial u}{\partial x} = -\left(\cos\left(y\right)x+y\sin\left(y\right)-\cos\left(y\right)\right)\mathrm{e}^{-x} \dfrac{\partial u}{\partial y} = \mathrm{e}^{-x}\left(-x\sin\left(y\right)+\sin\left(y\right)+y\cos\left(y\right)\right) \dfrac{\partial v}{\partial y} = \mathrm{e}^{-x}\left(-y\sin\left(y\right)+x\cos\left(y\right)+\cos\left(y\right)\right) \dfrac{\partial v}{\partial x} = -\left(\sin\left(y\right)x-\sin\left(y\right)+y\cos\left(y\right)\right)\mathrm{e}^{-x} \begin{aligned}
&\frac{\partial u}{\partial x}=\frac{\partial v}{\partial y} \\
&\frac{\partial v}{\partial x}=-\frac{\partial u}{\partial y}
\end{aligned}","['complex-analysis', 'functions', 'cauchy-riemann-equations']"
50,Schwarz-Pick Lemma from upper half plane,Schwarz-Pick Lemma from upper half plane,,"Let $f: UHP \to D_1(0)$ map the upper half of the complex plane to the unit disk. It is known that $|f(z)|\leq 1$ for real $z$ and also at infinity. Furthermore, consider that $f$ is meromorphic in the UHP. Then, by the Maximus Modulus Principle one concludes that $|f(z)|\leq 1$ for all the domain. I am trying to show that $$g(z) = \frac{f(z)-f(\omega)}{1-f(z)\bar{f(\omega)}}*\left(\frac{z-\omega}{z-\bar{\omega}}\right)^{-1}$$ is also bounded as $|g(z)|\leq 1$ , in the UHP and for any $\omega$ (parameter) also in the UHP. I know that $g(z)$ is meromorphic in the UHP, and if I managed to show that it is bounded in the boundaries, I would use the MMP again to generalize for the whole UHP. Both when $z$ is real or infinity, I was able to show that the second term is $\leq 1$ . However, the term with $f(z)$ seems a bit harder to analyse. How can I proceed?","Let map the upper half of the complex plane to the unit disk. It is known that for real and also at infinity. Furthermore, consider that is meromorphic in the UHP. Then, by the Maximus Modulus Principle one concludes that for all the domain. I am trying to show that is also bounded as , in the UHP and for any (parameter) also in the UHP. I know that is meromorphic in the UHP, and if I managed to show that it is bounded in the boundaries, I would use the MMP again to generalize for the whole UHP. Both when is real or infinity, I was able to show that the second term is . However, the term with seems a bit harder to analyse. How can I proceed?",f: UHP \to D_1(0) |f(z)|\leq 1 z f |f(z)|\leq 1 g(z) = \frac{f(z)-f(\omega)}{1-f(z)\bar{f(\omega)}}*\left(\frac{z-\omega}{z-\bar{\omega}}\right)^{-1} |g(z)|\leq 1 \omega g(z) z \leq 1 f(z),['complex-analysis']
51,How to prove $|z_1+z_2|<|1+\bar{z_1}z_2|$ if $|z_1|<1$ an $|z_2|<1$ [duplicate],How to prove  if  an  [duplicate],|z_1+z_2|<|1+\bar{z_1}z_2| |z_1|<1 |z_2|<1,"This question already has answers here : Show that $\left|\frac{\alpha - \beta}{1-\bar{\alpha}\beta}\right| < 1$ when $|\alpha|,|\beta| < 1$ (4 answers) Closed 2 years ago . I would like to prove that $|z_1+z_2|<|1+\bar{z_1}z_2|$ if $|z_1|<1$ an $|z_2|<1$ . I tried to multiply the numerator and denominator by $|1+z_1\bar{z_2}|$ or consider the square, but I couldn't finish anything. Someone has a hint as I can solve this problem?","This question already has answers here : Show that $\left|\frac{\alpha - \beta}{1-\bar{\alpha}\beta}\right| < 1$ when $|\alpha|,|\beta| < 1$ (4 answers) Closed 2 years ago . I would like to prove that if an . I tried to multiply the numerator and denominator by or consider the square, but I couldn't finish anything. Someone has a hint as I can solve this problem?",|z_1+z_2|<|1+\bar{z_1}z_2| |z_1|<1 |z_2|<1 |1+z_1\bar{z_2}|,"['complex-analysis', 'analysis']"
52,Solve a contour integral: $\int_{\gamma}\frac{z^2+1}{z(16z^2+1)}$,Solve a contour integral:,\int_{\gamma}\frac{z^2+1}{z(16z^2+1)},"I am trying to solve a contour integral: $$\int_{\gamma}\frac{z^2+1}{z(16z^2+1)}$$ Where $\gamma$ is the postivley oriented circular contour of radius 1/4 about the point 1. My attempt at the solution: $\frac{z^2+1}{z(16z^2+1)}$ has singularitites at $z=0$ and $z= +i1/4$ and $z=-i1/4$ I am trying to see if the poles are insider countour, however i don't know how to releate complex poles to real adius.","I am trying to solve a contour integral: Where is the postivley oriented circular contour of radius 1/4 about the point 1. My attempt at the solution: has singularitites at and and I am trying to see if the poles are insider countour, however i don't know how to releate complex poles to real adius.",\int_{\gamma}\frac{z^2+1}{z(16z^2+1)} \gamma \frac{z^2+1}{z(16z^2+1)} z=0 z= +i1/4 z=-i1/4,"['integration', 'complex-analysis']"
53,Solving $\cos(2z) + (2-2i)\cos(z) = 2i-1$,Solving,\cos(2z) + (2-2i)\cos(z) = 2i-1,"I'm trying to solve $$\cos(2z) + (2-2i)\cos(z) = 2i-1$$ when $z \in \mathbb{C}$ . My work so far I want to use formula $\cos(2z) = 2\cos^2(z) - 1$ to expand $\cos(2z)$ : $$2\cos^2(z) - 1 + (2-2i)\cos(z) = 2i-1$$ Let $t := \cos(z)$ $$2t^2 - 1 +2t - 2it -2i + 1 =0$$ $$2t^2 + 2t(1-i) - 2i =0$$ $$t^2 + t(1-i) - i = 0$$ $$\Delta = (1-i)^2 - 4 \cdot (-i) = (1-i)^2 + 4i = 1-2i-1+4i = 2i$$ $$\sqrt{\Delta} = \sqrt{2i}$$ So it turns out that $t = \frac{1 - i \pm \sqrt{2i}}{2}$ Expanding $t$ as $cos(z)$ and using fact that $cos(z) = \frac{e^{iz} + e^{-iz}}{2}$ we end up with: $$e^{iz} + e^{-iz} = 1-i\pm\sqrt{2i}$$ and here I got stuck, I'm not sure what should I do next. I tried to multiply by $e^{ix}$ but it doesn't seem to be a good idea. I tried to use fact that $\sqrt{i} = \cos(\pi / 4) + i \sin(\pi /4)$ but it also brought me nothing. Could you please help me solving this equation?","I'm trying to solve when . My work so far I want to use formula to expand : Let So it turns out that Expanding as and using fact that we end up with: and here I got stuck, I'm not sure what should I do next. I tried to multiply by but it doesn't seem to be a good idea. I tried to use fact that but it also brought me nothing. Could you please help me solving this equation?",\cos(2z) + (2-2i)\cos(z) = 2i-1 z \in \mathbb{C} \cos(2z) = 2\cos^2(z) - 1 \cos(2z) 2\cos^2(z) - 1 + (2-2i)\cos(z) = 2i-1 t := \cos(z) 2t^2 - 1 +2t - 2it -2i + 1 =0 2t^2 + 2t(1-i) - 2i =0 t^2 + t(1-i) - i = 0 \Delta = (1-i)^2 - 4 \cdot (-i) = (1-i)^2 + 4i = 1-2i-1+4i = 2i \sqrt{\Delta} = \sqrt{2i} t = \frac{1 - i \pm \sqrt{2i}}{2} t cos(z) cos(z) = \frac{e^{iz} + e^{-iz}}{2} e^{iz} + e^{-iz} = 1-i\pm\sqrt{2i} e^{ix} \sqrt{i} = \cos(\pi / 4) + i \sin(\pi /4),"['complex-analysis', 'complex-numbers']"
54,$\int_\gamma\frac{1}{\sqrt z}dz$ where $\gamma$ is the lower half of the unit circle from $+1$ to $-1$,where  is the lower half of the unit circle from  to,\int_\gamma\frac{1}{\sqrt z}dz \gamma +1 -1,"To solve this I put $\gamma(t)=e^{-it}$ with $t\in(0,\pi)$ . Then $$ \int_\gamma z^{-\frac{1}{2}}dz=-\int_0^\pi e^{\frac{it}{2}}ie^{-it}dt=-i\int_0^\pi e^{-\frac{it}{2}}dt=2(e^{i\pi/2}-e^{0})=-2-2i. $$ But if I use $\sigma(t)=e^{it}$ , $t\in(\pi,2\pi)$ , then $$ \int_\gamma z^{-\frac{1}{2}}dz=-\int_\sigma z^{-\frac{1}{2}}dz=-\int_\pi^{2\pi}e^{-\frac{it}{2}}ie^{it}dt=-i\int_\pi^{2\pi}e^{\frac{it}{2}}dt=-2(e^{\pi i}-e^\frac{\pi i}{2})=2+2i. $$ I cant see where is the problem. I'll thank you for any help.","To solve this I put with . Then But if I use , , then I cant see where is the problem. I'll thank you for any help.","\gamma(t)=e^{-it} t\in(0,\pi) 
\int_\gamma z^{-\frac{1}{2}}dz=-\int_0^\pi e^{\frac{it}{2}}ie^{-it}dt=-i\int_0^\pi e^{-\frac{it}{2}}dt=2(e^{i\pi/2}-e^{0})=-2-2i.
 \sigma(t)=e^{it} t\in(\pi,2\pi) 
\int_\gamma z^{-\frac{1}{2}}dz=-\int_\sigma z^{-\frac{1}{2}}dz=-\int_\pi^{2\pi}e^{-\frac{it}{2}}ie^{it}dt=-i\int_\pi^{2\pi}e^{\frac{it}{2}}dt=-2(e^{\pi i}-e^\frac{\pi i}{2})=2+2i.
",['complex-analysis']
55,Contour integral along a straight line - why does this simple practice problem fail to be simple?,Contour integral along a straight line - why does this simple practice problem fail to be simple?,,"Use the residue theorem to compute: $$I=\int_0^\infty\frac{1}{x^3+1}\,\mathrm{d}x$$ By using the contour that goes first from $0\to r$ along the real axis ( $\gamma_1$ ), then in an arc from $r\to r\exp(\frac{2}{3}\pi i)$ ( $\gamma_2$ ), then in a straight line from $r\exp(\frac{2}{3}\pi i)\to0$ ( $\gamma_3$ ), taking limits as $r\to\infty$ . Firstly we need to show that the integral along this contour is equivalent to the integral along the real axis, as $r\to\infty$ , so it first must be shown that: $$\lim_{r\to\infty}\int_{\gamma_2}\frac{1}{z^3+1}\,\mathrm{d}z=0$$ This part is straightforward: noticing that the arc, when cubed, is transformed to a circle of radius $r^3$ - missing the point $(r^3,0)$ - and adding $1$ to all values on this circle shifts the circle such that the smallest value of $|z^3+1|$ is $r^3-1$ : $$0\le\lim_{r\to\infty}\left|\int_{\gamma_2}\frac{1}{z^3+1}\,dz\right|\le\lim_{r\to\infty}\frac{2}{3}\pi r\cdot\sup_{\gamma_2}\frac{1}{|z^3+1|}\le\lim_{r\to\infty}\frac{2}{3}\pi r\cdot\frac{1}{r^3-1}=0$$ So the contour $\gamma_2$ is accounted for. Sadly, using the same estimation trick on the straight line segment $\gamma_3$ fails, since the maximum value of $(z^3+1)^{-1}$ on $\gamma_3$ is just $1$ , which fails to give a limit to zero. Deciding to crack the integral by hand, I proceeded: $$\begin{align}\int_{\gamma_3}\frac{1}{z^3+1}\,\mathrm{d}z&=\int_r^0\frac{\exp\frac{2}{3}\pi i}{(t\exp\frac{2}{3}\pi i)^3+1}\,\mathrm{d}t\\&=-\exp\frac{2}{3}\pi i\int_0^r\frac{1}{t^3+1}\,\mathrm{d}t\end{align}$$ And got immediately stuck. According to Wolfram Alpha, the antiderivative does exist but it is not at all clear that as $r\to\infty$ , the integral goes to $0$ . Besides, this is a practice problem; although university level, I doubt one has to crack a very tricky antiderivative and an unclear limit. What am I doing wrong? As far as I understand it, in order for the residue theorem to be of any use, the contour integral enclosing the singularity must first be shown to evaluate to the integral along the real axis.","Use the residue theorem to compute: By using the contour that goes first from along the real axis ( ), then in an arc from ( ), then in a straight line from ( ), taking limits as . Firstly we need to show that the integral along this contour is equivalent to the integral along the real axis, as , so it first must be shown that: This part is straightforward: noticing that the arc, when cubed, is transformed to a circle of radius - missing the point - and adding to all values on this circle shifts the circle such that the smallest value of is : So the contour is accounted for. Sadly, using the same estimation trick on the straight line segment fails, since the maximum value of on is just , which fails to give a limit to zero. Deciding to crack the integral by hand, I proceeded: And got immediately stuck. According to Wolfram Alpha, the antiderivative does exist but it is not at all clear that as , the integral goes to . Besides, this is a practice problem; although university level, I doubt one has to crack a very tricky antiderivative and an unclear limit. What am I doing wrong? As far as I understand it, in order for the residue theorem to be of any use, the contour integral enclosing the singularity must first be shown to evaluate to the integral along the real axis.","I=\int_0^\infty\frac{1}{x^3+1}\,\mathrm{d}x 0\to r \gamma_1 r\to r\exp(\frac{2}{3}\pi i) \gamma_2 r\exp(\frac{2}{3}\pi i)\to0 \gamma_3 r\to\infty r\to\infty \lim_{r\to\infty}\int_{\gamma_2}\frac{1}{z^3+1}\,\mathrm{d}z=0 r^3 (r^3,0) 1 |z^3+1| r^3-1 0\le\lim_{r\to\infty}\left|\int_{\gamma_2}\frac{1}{z^3+1}\,dz\right|\le\lim_{r\to\infty}\frac{2}{3}\pi r\cdot\sup_{\gamma_2}\frac{1}{|z^3+1|}\le\lim_{r\to\infty}\frac{2}{3}\pi r\cdot\frac{1}{r^3-1}=0 \gamma_2 \gamma_3 (z^3+1)^{-1} \gamma_3 1 \begin{align}\int_{\gamma_3}\frac{1}{z^3+1}\,\mathrm{d}z&=\int_r^0\frac{\exp\frac{2}{3}\pi i}{(t\exp\frac{2}{3}\pi i)^3+1}\,\mathrm{d}t\\&=-\exp\frac{2}{3}\pi i\int_0^r\frac{1}{t^3+1}\,\mathrm{d}t\end{align} r\to\infty 0","['integration', 'complex-analysis', 'improper-integrals', 'residue-calculus']"
56,continuous extension of holomorphic function up to the boundary,continuous extension of holomorphic function up to the boundary,,"Denote $S=\{z \in \mathbb{C}|0 \leq \text{Re}(z) \leq 1\}$ , let $X$ be a Banach space and let $f:S^\circ \rightarrow X$ be a holomorphic function. Under what assumptions does $f$ have a unique continuous extension $\tilde{f}:S \rightarrow X$ ? (Here $S^\circ$ denotes the set $\{z \in \mathbb{C}|0 < \text{Re}(z) < 1\}$ ). The reason I ask this question : Using the Weierstrass M-test I saw that a series of the form $\sum_{n=1}^{+\infty}f_n(z)$ converges absolutely and uniformly on $\boldsymbol{S^\circ}$ (where $f_n:S \rightarrow X$ are holomorphic in $S^\circ$ and continuous in $S$ for every $n \in \mathbb{N}$ ) so that I was able to define a function $f:S^{\circ} \rightarrow X$ by the formula $f(z)=\sum_{n=1}^{+\infty}f_n(z)$ (where the convergence happens with respect to the norm of $X$ ). I would like to extend $f$ continuously in $S$ (in a unique way). Is it possible?","Denote , let be a Banach space and let be a holomorphic function. Under what assumptions does have a unique continuous extension ? (Here denotes the set ). The reason I ask this question : Using the Weierstrass M-test I saw that a series of the form converges absolutely and uniformly on (where are holomorphic in and continuous in for every ) so that I was able to define a function by the formula (where the convergence happens with respect to the norm of ). I would like to extend continuously in (in a unique way). Is it possible?",S=\{z \in \mathbb{C}|0 \leq \text{Re}(z) \leq 1\} X f:S^\circ \rightarrow X f \tilde{f}:S \rightarrow X S^\circ \{z \in \mathbb{C}|0 < \text{Re}(z) < 1\} \sum_{n=1}^{+\infty}f_n(z) \boldsymbol{S^\circ} f_n:S \rightarrow X S^\circ S n \in \mathbb{N} f:S^{\circ} \rightarrow X f(z)=\sum_{n=1}^{+\infty}f_n(z) X f S,"['complex-analysis', 'functional-analysis', 'continuity']"
57,Solve the equation $2\sin{ix} -3i\cos{ix}=3i$,Solve the equation,2\sin{ix} -3i\cos{ix}=3i,"I have got an answer for this, but I know that it is wrong because it contains $\cos^{-1}\left(-\frac{3}{\sqrt{5}}\right)$ , which is undefined. So I was wondering if the issue is with the method I am using or if I have made a mistake with the numbers. I rewrote the equation as $$3i\cosh{x}-2i\sinh{x}=-3i$$ by using $\cos{ix}=\cosh{x}$ and $\sin{ix}=i\sinh{x}$ . I then compared this to the compound angle formula for $\cos{a+bi}$ , which is: $$r\cos(a+bi)=r\cos{a}\cosh{b}-ir\sin{a}\sinh{b}$$ So, letting $r\cos{a}=3i$ and $r\sin{a}=2$ gives me $a=\tan^{-1}\frac{2}{3i}$ and $r=i\sqrt{5}$ . This means that my original equation becomes: $$\cos\left(\tan^{-1}\left(-\frac{2}{3}i\right)+ix\right)=-\frac{3}{\sqrt{5}}$$ which is impossible because the $\cos$ function will only produce values between $-1$ and $1$ . I can't see anything that is wrong with what I have done so I was wondering if I am missing something.","I have got an answer for this, but I know that it is wrong because it contains , which is undefined. So I was wondering if the issue is with the method I am using or if I have made a mistake with the numbers. I rewrote the equation as by using and . I then compared this to the compound angle formula for , which is: So, letting and gives me and . This means that my original equation becomes: which is impossible because the function will only produce values between and . I can't see anything that is wrong with what I have done so I was wondering if I am missing something.",\cos^{-1}\left(-\frac{3}{\sqrt{5}}\right) 3i\cosh{x}-2i\sinh{x}=-3i \cos{ix}=\cosh{x} \sin{ix}=i\sinh{x} \cos{a+bi} r\cos(a+bi)=r\cos{a}\cosh{b}-ir\sin{a}\sinh{b} r\cos{a}=3i r\sin{a}=2 a=\tan^{-1}\frac{2}{3i} r=i\sqrt{5} \cos\left(\tan^{-1}\left(-\frac{2}{3}i\right)+ix\right)=-\frac{3}{\sqrt{5}} \cos -1 1,"['complex-analysis', 'trigonometry', 'complex-numbers']"
58,How to show $\int_{0}^{+\infty} d x \frac{\sqrt{x}}{\left(x^{2}+1\right)^{2}}=\frac{\pi}{4 \sqrt{2}} $ with residue theorem,How to show  with residue theorem,\int_{0}^{+\infty} d x \frac{\sqrt{x}}{\left(x^{2}+1\right)^{2}}=\frac{\pi}{4 \sqrt{2}} ,"I'm trying to calculate the following integral using the residue theorem. $$ I=\int_{0}^{+\infty} d x \frac{\sqrt{x}}{\left(x^{2}+1\right)^{2}}=\frac{\pi}{4 \sqrt{2}} $$ But somehow I'm not getting the correct results, and I was hoping you could help spot where things go wrong? Because I have looked it through several times and can't seem to find anything wrong. Here is my approach: Define: $$ f(z)=\frac{(z)^{1 / 2}}{\left(z^{2}+1\right)^{2}}=\frac{(z)^{1 / 2}}{(z+i)^{2}(z-i)^{2}} $$ f has poles of 2nd order at $z=\pm i$ . And it has a branch point at $z=0$ . Maintaining $f$ as a single-valued function is fairly easy, if I define $z=|z|e^{i\theta} $ and restrict $\theta\in[0,2\pi]$ . I want to integrate $f$ over the following contour: $$ \oint f(z) d z=\int_{\Gamma^-} f(z) d z+\int_{c_{r}} f(z) d z+\int_{\Gamma^{+}} f(z) d z+\int_{C_{R}} f(z) d z=2 \pi i \operatorname{Res}(f, z=i) $$ The integral along the infinite halfcircle ( $C_R$ where $R\rightarrow \infty$ ) converges to zero. The same goes for the infinitesimal circle $c_r$ as $r\rightarrow 0$ . The parametrization of $\Gamma^+$ gives the integral we are trying to solve: $$ \int_{\Gamma^{+}} f(z) d z=\int_{0}^{\infty} \frac{\sqrt{x}}{\left(x^{2}+1\right)^{2}} d x=I $$ If we want to parametrize $\Gamma^-$ we can set $z=xe^{i\pi}$ and $dz=-dx$ and integrate from $-\infty$ to $0$ : $$ \int_{\Gamma^-} f(z) d z=\int_{-\infty}^{0} \frac{x^{1 / 2} e^{i \pi / 2}}{\left(x^{2} e^{2 i \pi}+1\right)^{2}}(-d x) $$ but substituting $x=-u$ and $dx=-du$ , changing sign of limits and reversing the limits ends up being equivalent with $$ =\int_{0}^{\infty} \frac{\left(u\right)^{1 / 2}}{\left(u^{2}+1\right)^{2}} d u=I $$ Calculating the residue of the enclosed pole: $$ \operatorname{Res}(f, z=i)=\lim _{z \rightarrow i}\left[\frac{d}{d z}(z-i)^{2} f(z)\right]=\lim _{z \rightarrow i}\left[\frac{d}{d z} \frac{z^{1 / 2}}{(z+i)^{2}}\right]=\frac{e^{-i \pi / 4}}{8}=\frac{1}{8}\left(\frac{\sqrt{2}}{2}-\frac{\sqrt{2}}{2} i\right) $$ Which ends up giving: $$ \begin{aligned} &\Rightarrow \oint f(z) d z=2 I=2 \pi i \frac{1}{8}(1-i) \frac{\sqrt{2}}{2} \\ &\Rightarrow I=\int_{0}^{\infty} \frac{\sqrt{x}}{\left(x^{2}+1\right)} d x=\frac{\pi}{8} \frac{\sqrt{2}}{2} i(1-i)=\frac{\pi}{8} \frac{\sqrt{2}}{2}(1+i) \end{aligned} $$ Which of course isn't quite right.","I'm trying to calculate the following integral using the residue theorem. But somehow I'm not getting the correct results, and I was hoping you could help spot where things go wrong? Because I have looked it through several times and can't seem to find anything wrong. Here is my approach: Define: f has poles of 2nd order at . And it has a branch point at . Maintaining as a single-valued function is fairly easy, if I define and restrict . I want to integrate over the following contour: The integral along the infinite halfcircle ( where ) converges to zero. The same goes for the infinitesimal circle as . The parametrization of gives the integral we are trying to solve: If we want to parametrize we can set and and integrate from to : but substituting and , changing sign of limits and reversing the limits ends up being equivalent with Calculating the residue of the enclosed pole: Which ends up giving: Which of course isn't quite right.","
I=\int_{0}^{+\infty} d x \frac{\sqrt{x}}{\left(x^{2}+1\right)^{2}}=\frac{\pi}{4 \sqrt{2}}
 
f(z)=\frac{(z)^{1 / 2}}{\left(z^{2}+1\right)^{2}}=\frac{(z)^{1 / 2}}{(z+i)^{2}(z-i)^{2}}
 z=\pm i z=0 f z=|z|e^{i\theta}  \theta\in[0,2\pi] f 
\oint f(z) d z=\int_{\Gamma^-} f(z) d z+\int_{c_{r}} f(z) d z+\int_{\Gamma^{+}} f(z) d z+\int_{C_{R}} f(z) d z=2 \pi i \operatorname{Res}(f, z=i)
 C_R R\rightarrow \infty c_r r\rightarrow 0 \Gamma^+ 
\int_{\Gamma^{+}} f(z) d z=\int_{0}^{\infty} \frac{\sqrt{x}}{\left(x^{2}+1\right)^{2}} d x=I
 \Gamma^- z=xe^{i\pi} dz=-dx -\infty 0 
\int_{\Gamma^-} f(z) d z=\int_{-\infty}^{0} \frac{x^{1 / 2} e^{i \pi / 2}}{\left(x^{2} e^{2 i \pi}+1\right)^{2}}(-d x)
 x=-u dx=-du 
=\int_{0}^{\infty} \frac{\left(u\right)^{1 / 2}}{\left(u^{2}+1\right)^{2}} d u=I
 
\operatorname{Res}(f, z=i)=\lim _{z \rightarrow i}\left[\frac{d}{d z}(z-i)^{2} f(z)\right]=\lim _{z \rightarrow i}\left[\frac{d}{d z} \frac{z^{1 / 2}}{(z+i)^{2}}\right]=\frac{e^{-i \pi / 4}}{8}=\frac{1}{8}\left(\frac{\sqrt{2}}{2}-\frac{\sqrt{2}}{2} i\right)
 
\begin{aligned}
&\Rightarrow \oint f(z) d z=2 I=2 \pi i \frac{1}{8}(1-i) \frac{\sqrt{2}}{2} \\
&\Rightarrow I=\int_{0}^{\infty} \frac{\sqrt{x}}{\left(x^{2}+1\right)} d x=\frac{\pi}{8} \frac{\sqrt{2}}{2} i(1-i)=\frac{\pi}{8} \frac{\sqrt{2}}{2}(1+i)
\end{aligned}
","['complex-analysis', 'complex-integration', 'residue-calculus']"
59,Proof about meromorphic function which its image is in $ \mathbb{C}\cup\left\{ \infty\right\} $,Proof about meromorphic function which its image is in, \mathbb{C}\cup\left\{ \infty\right\} ,"Let $ D^{*}=D\left(0,1\right)\setminus\left\{ 0\right\}  $ . Assume $ f:D^{*}\to\mathbb{C}\cup\left\{ \infty\right\}  $ is meromorphic with a sequence of poles $z_n\in D^*$ which converge to $0$ . Prove that the image of $ f $ is densed in $ \mathbb{C}\cup\left\{ \infty\right\}  $ . I'd like to see a good proof for that. I'll share my attempt anyway and I'd be glad to hear what you guys think: Assume by contradiction that the image of $D^*$ under $ f $ is not densed. Then one can find an open disk $ D\left(a,r\right) $ (center $ a $ and radius $r $ ), such that $ f\left(D^{*}\right)\cap D\left(a,r\right)=\emptyset $ . Thus, the function defined by $ h\left(z\right)=\frac{1}{f\left(z\right)-a} $ is holomorphic in $D^* $ since the denominator never vanish, and  for $z_k$ , a pole of $ z$ , we have $h(z_k)=0$ Next, notice that $0 $ cannot be a deleted singularity of $ h $ since then by uniqueness theorem we'll get that $ h$ is constant zero, and also $0 $ cannot be a pole of $ h $ because zeroes of meromorphic function cannot accumulate at a pole. Thus we can conclude that $0 $ is an essential singularity of $h $ , and thus by the Casorati-Weierstrass theorem, the image of $D^* $ under $h$ is densed in $\mathbb{C} $ . Next, fix $z_0\neq a$ in $D(a,r )$ and fix $\varepsilon>0 $ small enough so that $ D\left(z_{0},\varepsilon\right)\subset D\left(a,r\right) $ and also $a\notin D(z_0,\varepsilon)$ . Then, by the open map theorem, since $ \frac{1}{z-a} $ is holomorphic in an open neighborhood of $D(z_0,\varepsilon)$ , we know that $ \left\{ \frac{1}{z-a}:z\in D\left(z_{0},\varepsilon\right)\right\}  $ is an open set, and thus there exists $z_1$ \in $D^*$ such that $ \frac{1}{f\left(z_{1}\right)-a}=h\left(z_{1}\right)\in\left\{ \frac{1}{z-a}:z\in D\left(z_{0},\varepsilon\right)\right\}  $ So we have found $z_1\in D^*$ such that $ f\left(z_{1}\right)\in D\left(z_{0},\varepsilon\right)\subset D\left(a,r\right) $ which is a contradiction. A few thoughts: This is not intuitive for me because Im used to be careful of writing things like $f(z)=\infty $ and stuff like that. 1.The proof is correct? 2.Can we say that if $z_k$ is a pole of $ f $ then $f(z_k)=\infty $ ? can we say that if $z_k $ is a pole of $ f $ then $1/f(z_k)=0$ ? 3.Im not sure what does it mean that the image is densed in $ f:D^{*}\to\mathbb{C}\cup\left\{ \infty\right\}  $ . Proving that the image is densed in $\mathbb{C} $ is enough? 4.I did not talk about the case where $a=\infty$ . Does it changes anything? 5.Do you have simpler proof? Any clarifications would be very helpful. Thanks in advance.","Let . Assume is meromorphic with a sequence of poles which converge to . Prove that the image of is densed in . I'd like to see a good proof for that. I'll share my attempt anyway and I'd be glad to hear what you guys think: Assume by contradiction that the image of under is not densed. Then one can find an open disk (center and radius ), such that . Thus, the function defined by is holomorphic in since the denominator never vanish, and  for , a pole of , we have Next, notice that cannot be a deleted singularity of since then by uniqueness theorem we'll get that is constant zero, and also cannot be a pole of because zeroes of meromorphic function cannot accumulate at a pole. Thus we can conclude that is an essential singularity of , and thus by the Casorati-Weierstrass theorem, the image of under is densed in . Next, fix in and fix small enough so that and also . Then, by the open map theorem, since is holomorphic in an open neighborhood of , we know that is an open set, and thus there exists \in such that So we have found such that which is a contradiction. A few thoughts: This is not intuitive for me because Im used to be careful of writing things like and stuff like that. 1.The proof is correct? 2.Can we say that if is a pole of then ? can we say that if is a pole of then ? 3.Im not sure what does it mean that the image is densed in . Proving that the image is densed in is enough? 4.I did not talk about the case where . Does it changes anything? 5.Do you have simpler proof? Any clarifications would be very helpful. Thanks in advance."," D^{*}=D\left(0,1\right)\setminus\left\{ 0\right\}    f:D^{*}\to\mathbb{C}\cup\left\{ \infty\right\}   z_n\in D^* 0  f   \mathbb{C}\cup\left\{ \infty\right\}   D^*  f   D\left(a,r\right)   a  r   f\left(D^{*}\right)\cap D\left(a,r\right)=\emptyset   h\left(z\right)=\frac{1}{f\left(z\right)-a}  D^*  z_k  z h(z_k)=0 0   h   h 0   h  0  h  D^*  h \mathbb{C}  z_0\neq a D(a,r ) \varepsilon>0   D\left(z_{0},\varepsilon\right)\subset D\left(a,r\right)  a\notin D(z_0,\varepsilon)  \frac{1}{z-a}  D(z_0,\varepsilon)  \left\{ \frac{1}{z-a}:z\in D\left(z_{0},\varepsilon\right)\right\}   z_1 D^*  \frac{1}{f\left(z_{1}\right)-a}=h\left(z_{1}\right)\in\left\{ \frac{1}{z-a}:z\in D\left(z_{0},\varepsilon\right)\right\}   z_1\in D^*  f\left(z_{1}\right)\in D\left(z_{0},\varepsilon\right)\subset D\left(a,r\right)  f(z)=\infty  z_k  f  f(z_k)=\infty  z_k   f  1/f(z_k)=0  f:D^{*}\to\mathbb{C}\cup\left\{ \infty\right\}   \mathbb{C}  a=\infty",['complex-analysis']
60,"Validity of proof $\zeta(s) \neq 0$ for $\sigma\gt1$, where $\sigma$ is the real part of $s$","Validity of proof  for , where  is the real part of",\zeta(s) \neq 0 \sigma\gt1 \sigma s,"The Riemann zeta function is can be expressed as an infinite series, as well as an infinite Euler product over primes $p$ . $$ \zeta(s) = \sum_n 1/n^s = \prod_p(1-1/p^s)^{-1} $$ Here $s=\sigma+it$ and the function is defined for $\sigma>1$ . A natural question to ask is whether there are any zeros in the region $\sigma>1$ . Question: Is the following outline proof sufficient and correct? Step 1 We note that none of the factors $(1-1/p^s)^{-1}$ is ever zero, because $p^s = e^{s\ln(p)} \neq 0$ for $\sigma>1$ . Step 2 The previous step is insufficient. We also need to demonstrate that the infinite product doesn't converge to zero. To do this, we make use of the following convergence criteria: if $\sum|a_n|$ converges, then $\prod(1+a_n)$ converges to a finite non-zero value. Step 3 In this case $\sum |a_n| = \sum 1/p^s$ , which we know converges for $\sigma > 1$ . Therefore the Euler Product converges to a non-zero finite value.","The Riemann zeta function is can be expressed as an infinite series, as well as an infinite Euler product over primes . Here and the function is defined for . A natural question to ask is whether there are any zeros in the region . Question: Is the following outline proof sufficient and correct? Step 1 We note that none of the factors is ever zero, because for . Step 2 The previous step is insufficient. We also need to demonstrate that the infinite product doesn't converge to zero. To do this, we make use of the following convergence criteria: if converges, then converges to a finite non-zero value. Step 3 In this case , which we know converges for . Therefore the Euler Product converges to a non-zero finite value.",p  \zeta(s) = \sum_n 1/n^s = \prod_p(1-1/p^s)^{-1}  s=\sigma+it \sigma>1 \sigma>1 (1-1/p^s)^{-1} p^s = e^{s\ln(p)} \neq 0 \sigma>1 \sum|a_n| \prod(1+a_n) \sum |a_n| = \sum 1/p^s \sigma > 1,"['complex-analysis', 'convergence-divergence', 'analytic-number-theory', 'riemann-zeta', 'euler-product']"
61,Limit of $\exp(f(x))$ implies existence of limit of $f(x)$,Limit of  implies existence of limit of,\exp(f(x)) f(x),"My question comes from this observation: If $f(x)$ is a complex-valued, continuous function on interval $(0,1)$ , and we know that limit of $f(x)$ at $x=1$ exists and finite, then we know that limit of $\exp(f(x))$ at $x=1$ exists, since $exp(x)$ function is continuous. I guess that the converse still holds: if we know that limit of $\exp(f(x))$ at $x=1$ exists and it is not 0, then limit of $f(x)$ at $x=1$ exists. But I am stuck here, since the logarithmic function is not single-valued. Thus, even if we know the limit of $\exp(f(x))$ at $x=1$ , we don't even know what the limit of $f(x)$ at $x=1$ could be. How do I approach this problem? Any help is appreciated.","My question comes from this observation: If is a complex-valued, continuous function on interval , and we know that limit of at exists and finite, then we know that limit of at exists, since function is continuous. I guess that the converse still holds: if we know that limit of at exists and it is not 0, then limit of at exists. But I am stuck here, since the logarithmic function is not single-valued. Thus, even if we know the limit of at , we don't even know what the limit of at could be. How do I approach this problem? Any help is appreciated.","f(x) (0,1) f(x) x=1 \exp(f(x)) x=1 exp(x) \exp(f(x)) x=1 f(x) x=1 \exp(f(x)) x=1 f(x) x=1","['real-analysis', 'complex-analysis', 'analytic-functions']"
62,Multi-keyhole contour integral with branch cut,Multi-keyhole contour integral with branch cut,,"How to construct a contour to calculate complex line integral $$\frac{1}{2\pi i}\int_{c-i\infty}^{c+i\infty}\arctan\left(\frac{1}{z}\right)\arctan\left(\frac{1}{s-z}\right)\,\mathrm{d}z$$ This integral is derived from the Laplace transform of the square of the Sinc function. $$\mathscr{L}[f^2(t);s]=\frac{1}{2\pi i}\int_{c-i\infty}^{c+i\infty}F\left(z\right)F\left(s-z\right)\,\mathrm{d}z$$ As shown in the expression above, Wikipedia gives the Laplace transform formula of function product as. I want to verify this formula by taking function as the Sinc function. I've found six singularities $z=\pm\,\!i,0,s,s\pm\,\!i$ so far, but I don't know how to construct the contour. I already know how to calculate $\displaystyle\int_{0}^{+\infty}\!\left(\frac{\sin(x)}{x}\right)^{\!\!2}\,e^{-sx}\,dx$ through the parametric integral, but now I don't know how to construct the contour and use the residue theorem to calculate the arctangent complex integral.","How to construct a contour to calculate complex line integral This integral is derived from the Laplace transform of the square of the Sinc function. As shown in the expression above, Wikipedia gives the Laplace transform formula of function product as. I want to verify this formula by taking function as the Sinc function. I've found six singularities so far, but I don't know how to construct the contour. I already know how to calculate through the parametric integral, but now I don't know how to construct the contour and use the residue theorem to calculate the arctangent complex integral.","\frac{1}{2\pi i}\int_{c-i\infty}^{c+i\infty}\arctan\left(\frac{1}{z}\right)\arctan\left(\frac{1}{s-z}\right)\,\mathrm{d}z \mathscr{L}[f^2(t);s]=\frac{1}{2\pi i}\int_{c-i\infty}^{c+i\infty}F\left(z\right)F\left(s-z\right)\,\mathrm{d}z z=\pm\,\!i,0,s,s\pm\,\!i \displaystyle\int_{0}^{+\infty}\!\left(\frac{\sin(x)}{x}\right)^{\!\!2}\,e^{-sx}\,dx","['complex-analysis', 'laplace-transform', 'contour-integration']"
63,Doubt regarding the proof of Prime Number Theorem,Doubt regarding the proof of Prime Number Theorem,,"I am studying the proof of the Prime Number Theorem from Introduction to Analytic Number Theory by Tom M. Apostol and I came across this result: If $c>1$ and $x \geq 1$ , we have: $$\frac{\psi_1(x)}{x^2} = \frac{1}{2\pi i}\int_{c-\infty i}^{c+\infty i} \frac{x^{s-1}}{s(s+1)}\left(-\frac{\zeta'(s)}{\zeta(s)}\right)ds$$ Here, $\psi_1(x) = \int_1^x \psi(t)dt$ and $\psi(t)$ is the Chebyshev $\psi$ function. I understood its proof but I am having trouble understanding the motivation behind the next result. The book says : The quotient $-\frac{\zeta'(s)}{\zeta(s)}$ has a first order pole at $s=1$ with residue 1. So, if we subtract this pole we get the formula $$\frac{\psi_1(x)}{x^2} - \frac{1}{2}\left(1-\frac{1}{x}\right)^2 = \frac{1}{2\pi i}\int_{c-\infty i}^{c+\infty i} \frac{x^{s-1}}{s(s+1)}\left(-\frac{\zeta'(s)}{\zeta(s)}-\frac{1}{s-1}\right)ds$$ Specifically, I am not able to see why we need to subtract the pole. Clearly we have $c>1$ , so the limits of the integral have $Re(s)>1$ . Hence the term $-\frac{\zeta'(s)}{\zeta(s)}$ in the integrand would never take the input $s=1$ . So, why do we bother subtracting the pole ? This might seem like a silly question but I am completely confused. Any help shall be highly appreciated.","I am studying the proof of the Prime Number Theorem from Introduction to Analytic Number Theory by Tom M. Apostol and I came across this result: If and , we have: Here, and is the Chebyshev function. I understood its proof but I am having trouble understanding the motivation behind the next result. The book says : The quotient has a first order pole at with residue 1. So, if we subtract this pole we get the formula Specifically, I am not able to see why we need to subtract the pole. Clearly we have , so the limits of the integral have . Hence the term in the integrand would never take the input . So, why do we bother subtracting the pole ? This might seem like a silly question but I am completely confused. Any help shall be highly appreciated.",c>1 x \geq 1 \frac{\psi_1(x)}{x^2} = \frac{1}{2\pi i}\int_{c-\infty i}^{c+\infty i} \frac{x^{s-1}}{s(s+1)}\left(-\frac{\zeta'(s)}{\zeta(s)}\right)ds \psi_1(x) = \int_1^x \psi(t)dt \psi(t) \psi -\frac{\zeta'(s)}{\zeta(s)} s=1 \frac{\psi_1(x)}{x^2} - \frac{1}{2}\left(1-\frac{1}{x}\right)^2 = \frac{1}{2\pi i}\int_{c-\infty i}^{c+\infty i} \frac{x^{s-1}}{s(s+1)}\left(-\frac{\zeta'(s)}{\zeta(s)}-\frac{1}{s-1}\right)ds c>1 Re(s)>1 -\frac{\zeta'(s)}{\zeta(s)} s=1,"['complex-analysis', 'number-theory', 'analytic-number-theory', 'riemann-zeta']"
64,What does it mean for a complex function to have a period of 1?,What does it mean for a complex function to have a period of 1?,,"If a complex valued function $f$ has a period of $1$ does it mean that $f(z)=f(z+1)$ in the same sense as real functions? Moreover, if $f$ has lets say a period, that is not necessarily real say $w$ , is it also the case that $f(z)=f(z+w)$ ?","If a complex valued function has a period of does it mean that in the same sense as real functions? Moreover, if has lets say a period, that is not necessarily real say , is it also the case that ?",f 1 f(z)=f(z+1) f w f(z)=f(z+w),['complex-analysis']
65,Showing $\frac{\sin((2n+1)\theta)}{\sin\theta}=(2n+1)\prod_{k=1}^n\left(1-\frac{\sin^2\theta}{\sin^2\frac{k\pi}{2n+1}}\right)$,Showing,\frac{\sin((2n+1)\theta)}{\sin\theta}=(2n+1)\prod_{k=1}^n\left(1-\frac{\sin^2\theta}{\sin^2\frac{k\pi}{2n+1}}\right),"A problem I solved previously I get $$\frac{\sin(n\theta)}{\sin(\theta)} = 2^{n-1}\prod_{k=1}^{n-1}\bigg(\cos(\theta)-\cos{\bigg(\frac{k\pi}{n}}\bigg)\bigg)$$ So considering $z^{4n+2} = 1$ leads to $$\frac{\sin((2n+1)\theta)}{\sin(\theta)} =  2^{2n}\prod_{k=1}^{2n}\bigg(\cos(\theta)-\cos\bigg(\frac{k\pi}{2n+1}\bigg)\bigg)......................(1)$$ Now $$\cos\bigg(\frac{2n\pi}{2n+1}\bigg) = \cos\bigg(\pi-\frac{\pi}{2n+1}\bigg) =-\cos\bigg(\frac{\pi}{2n+1}\bigg)$$ $$\cos\bigg(\frac{(2n-1)\pi}{2n+1}\bigg) = \cos\bigg(\pi-\frac{2\pi}{2n+1}\bigg) =-\cos\bigg(\frac{2\pi}{2n+1}\bigg)$$ $$...........................................................$$ $$\cos\bigg(\frac{(n+1)\pi}{2n+1}\bigg) = \cos\bigg(\pi-\frac{n\pi}{2n+1}\bigg) =-\cos\bigg(\frac{n\pi}{2n+1}\bigg)$$ multiplying terms $k = 1$ with $k = 2n, k =2$ with $k = 2n-1\dots k = n$ with $k = n+1$ terms, from $......(1)$ I get $$\frac{\sin((2n+1)\theta)}{\sin(\theta)} = 2^{2n}\cdot\bigg(\cos(\theta)+\cos\bigg(\frac{\pi}{2n+1}\bigg)\bigg)\cdot \bigg(\cos(\theta)-\cos\bigg(\frac{\pi}{2n+1}\bigg)\bigg)\hspace{82pt}\cdot\bigg(\cos(\theta)+\cos\bigg(\frac{2\pi}{2n+1}\bigg)\bigg)\cdot\bigg(\cos(\theta)-\cos\bigg(\frac{2\pi}{2n+1}\bigg)\bigg)........\hspace{56pt}\bigg(\cos(\theta)+\cos\bigg(\frac{n\pi}{2n+1}\bigg)\bigg)\cdot\bigg(\cos(\theta)-\cos\bigg(\frac{n\pi}{2n+1}\bigg)\bigg)$$ $$ \hspace{35pt}= 2^{2n}\prod_{k = 1}^{n} \bigg(\cos^{2}(\theta)-\cos^{2}\bigg(\frac{k\pi}{2n+1}\bigg)\bigg).............(2)$$ How can I prove $$\frac{\sin((2n+1)\theta)}{\sin(\theta)} = (2n+1)\prod_{k = 1}^{n}\bigg(1-\frac{\sin^2(\theta)}{\sin^2\big(\frac{k\pi}{2n+1}\big)}\bigg)$$ from my calculation? Is my way of approaching this problem is ok or not? If it isn't give me one or a few hints.","A problem I solved previously I get So considering leads to Now multiplying terms with with with terms, from I get How can I prove from my calculation? Is my way of approaching this problem is ok or not? If it isn't give me one or a few hints.","\frac{\sin(n\theta)}{\sin(\theta)} = 2^{n-1}\prod_{k=1}^{n-1}\bigg(\cos(\theta)-\cos{\bigg(\frac{k\pi}{n}}\bigg)\bigg) z^{4n+2} = 1 \frac{\sin((2n+1)\theta)}{\sin(\theta)} =  2^{2n}\prod_{k=1}^{2n}\bigg(\cos(\theta)-\cos\bigg(\frac{k\pi}{2n+1}\bigg)\bigg)......................(1) \cos\bigg(\frac{2n\pi}{2n+1}\bigg) = \cos\bigg(\pi-\frac{\pi}{2n+1}\bigg)
=-\cos\bigg(\frac{\pi}{2n+1}\bigg) \cos\bigg(\frac{(2n-1)\pi}{2n+1}\bigg) = \cos\bigg(\pi-\frac{2\pi}{2n+1}\bigg) =-\cos\bigg(\frac{2\pi}{2n+1}\bigg) ........................................................... \cos\bigg(\frac{(n+1)\pi}{2n+1}\bigg) = \cos\bigg(\pi-\frac{n\pi}{2n+1}\bigg) =-\cos\bigg(\frac{n\pi}{2n+1}\bigg) k = 1 k = 2n, k =2 k = 2n-1\dots k = n k = n+1 ......(1) \frac{\sin((2n+1)\theta)}{\sin(\theta)} = 2^{2n}\cdot\bigg(\cos(\theta)+\cos\bigg(\frac{\pi}{2n+1}\bigg)\bigg)\cdot \bigg(\cos(\theta)-\cos\bigg(\frac{\pi}{2n+1}\bigg)\bigg)\hspace{82pt}\cdot\bigg(\cos(\theta)+\cos\bigg(\frac{2\pi}{2n+1}\bigg)\bigg)\cdot\bigg(\cos(\theta)-\cos\bigg(\frac{2\pi}{2n+1}\bigg)\bigg)........\hspace{56pt}\bigg(\cos(\theta)+\cos\bigg(\frac{n\pi}{2n+1}\bigg)\bigg)\cdot\bigg(\cos(\theta)-\cos\bigg(\frac{n\pi}{2n+1}\bigg)\bigg)  \hspace{35pt}= 2^{2n}\prod_{k = 1}^{n} \bigg(\cos^{2}(\theta)-\cos^{2}\bigg(\frac{k\pi}{2n+1}\bigg)\bigg).............(2) \frac{\sin((2n+1)\theta)}{\sin(\theta)} = (2n+1)\prod_{k = 1}^{n}\bigg(1-\frac{\sin^2(\theta)}{\sin^2\big(\frac{k\pi}{2n+1}\big)}\bigg)","['sequences-and-series', 'complex-analysis', 'trigonometry']"
66,Complex integration $\int_{0}^{1}\frac{\sqrt[3]{4x^{2}\left(1-x\right)}}{\left(1+x\right)^{3}}dx$,Complex integration,\int_{0}^{1}\frac{\sqrt[3]{4x^{2}\left(1-x\right)}}{\left(1+x\right)^{3}}dx,"I have integral $$I_1=\int_{0}^{1}\frac{\sqrt[3]{4x^{2}\left(1-x\right)}}{\left(1+x\right)^{3}}dx.$$ I tried something like this: $$f\left(z\right)=\frac{\sqrt[3]{4z^{2}\left(1-z\right)}}{\left(1+z\right)^{3}}=\frac{\left(1-z\right)}{\left(1+z\right)^{3}}\left(\frac{2z}{1-z}\right)^{\frac{2}{3}}$$ Using the figure I have $$I=\int_{C_{R}}f\left(z\right)dz+\int_{C_{r1}}f\left(z\right)dz+\int_{z_{1}}f\left(z\right)dz+\int_{C_{r2}}f\left(z\right)dz+\int_{z_{2}}f\left(z\right)dz.\tag1$$ Since I have only one singularity in my contour: $$\operatorname {Res}\left(f,z=-1\right)	=\frac{1}{\left(3-1\right)!}\cdot\lim_{z\rightarrow\left(-1\right)}\left[\left(z+1\right)^{3}\cdot f\left(z\right)\right]^{''}\\ 	=\frac{1}{2}\cdot\lim_{z\rightarrow\left(-1\right)}\frac{-2\cdot4^{\frac{1}{3}}z^{2}}{9\left(-z^{2}\left(-1+z\right)\right)^{\frac{5}{3}}}\\ 	=\frac{1}{2}\cdot\frac{-2\cdot4^{\frac{1}{3}}\left(-1\right)^{2}}{9\left(-\left(-1\right)^{2}\cdot\left(-1-1\right)\right)^{\frac{5}{3}}}\\ 	=-\frac{2^{\frac{2}{3}}\cdot1}{9\left(2\right)^{\frac{5}{3}}}=-\frac{1}{9}2^{\frac{2}{3}-\frac{5}{3}}=-\frac{1}{9}2^{-1}=-\frac{1}{18}.$$ Thus I got $$I=2\pi i\cdot\left(-\frac{1}{18}\right)=-\frac{\pi i}{9}.$$ Now, I use Jordan's lemma and get: $$\lim_{z\rightarrow0}z\cdot f\left(z\right)=0$$ $$\lim_{z\rightarrow1}\left(z-1\right)f\left(z\right)=0$$ $$\lim_{z\rightarrow\infty}z\cdot f\left(z\right)=0$$ So I conclude that $$\lim_{r\rightarrow0}\int_{C_{r1}}f\left(z\right)dz=0$$ $$\lim_{r\rightarrow0}\int_{C_{r2}}f\left(z\right)dz=0.$$ $$\lim_{R\rightarrow\infty}\int_{C_{R}}f\left(z\right)dz=0.$$ When I put $r\rightarrow0$ and $R\rightarrow\infty$ into (1) and put that on $z_1$ the argument of the function  is 0, and on $z_2$ the argument is $2\pi \cdot \frac{2}{3}$ then I have: $$I_{1}\left(1-e^{i\frac{4\pi}{3}}\right)=-\frac{\pi}{9}i.$$ Now I have the problem because on the left side I have real and imaginary part and on the right hand side I only have imaginary part and I don't know what to do.","I have integral I tried something like this: Using the figure I have Since I have only one singularity in my contour: Thus I got Now, I use Jordan's lemma and get: So I conclude that When I put and into (1) and put that on the argument of the function  is 0, and on the argument is then I have: Now I have the problem because on the left side I have real and imaginary part and on the right hand side I only have imaginary part and I don't know what to do.","I_1=\int_{0}^{1}\frac{\sqrt[3]{4x^{2}\left(1-x\right)}}{\left(1+x\right)^{3}}dx. f\left(z\right)=\frac{\sqrt[3]{4z^{2}\left(1-z\right)}}{\left(1+z\right)^{3}}=\frac{\left(1-z\right)}{\left(1+z\right)^{3}}\left(\frac{2z}{1-z}\right)^{\frac{2}{3}} I=\int_{C_{R}}f\left(z\right)dz+\int_{C_{r1}}f\left(z\right)dz+\int_{z_{1}}f\left(z\right)dz+\int_{C_{r2}}f\left(z\right)dz+\int_{z_{2}}f\left(z\right)dz.\tag1 \operatorname {Res}\left(f,z=-1\right)	=\frac{1}{\left(3-1\right)!}\cdot\lim_{z\rightarrow\left(-1\right)}\left[\left(z+1\right)^{3}\cdot f\left(z\right)\right]^{''}\\
	=\frac{1}{2}\cdot\lim_{z\rightarrow\left(-1\right)}\frac{-2\cdot4^{\frac{1}{3}}z^{2}}{9\left(-z^{2}\left(-1+z\right)\right)^{\frac{5}{3}}}\\
	=\frac{1}{2}\cdot\frac{-2\cdot4^{\frac{1}{3}}\left(-1\right)^{2}}{9\left(-\left(-1\right)^{2}\cdot\left(-1-1\right)\right)^{\frac{5}{3}}}\\
	=-\frac{2^{\frac{2}{3}}\cdot1}{9\left(2\right)^{\frac{5}{3}}}=-\frac{1}{9}2^{\frac{2}{3}-\frac{5}{3}}=-\frac{1}{9}2^{-1}=-\frac{1}{18}. I=2\pi i\cdot\left(-\frac{1}{18}\right)=-\frac{\pi i}{9}. \lim_{z\rightarrow0}z\cdot f\left(z\right)=0 \lim_{z\rightarrow1}\left(z-1\right)f\left(z\right)=0 \lim_{z\rightarrow\infty}z\cdot f\left(z\right)=0 \lim_{r\rightarrow0}\int_{C_{r1}}f\left(z\right)dz=0 \lim_{r\rightarrow0}\int_{C_{r2}}f\left(z\right)dz=0. \lim_{R\rightarrow\infty}\int_{C_{R}}f\left(z\right)dz=0. r\rightarrow0 R\rightarrow\infty z_1 z_2 2\pi \cdot \frac{2}{3} I_{1}\left(1-e^{i\frac{4\pi}{3}}\right)=-\frac{\pi}{9}i.","['complex-analysis', 'contour-integration', 'complex-integration']"
67,"Suppose $\lim_n e^{itb_n}$ exists for all $|t|\le \delta$, show that $\limsup |b_n| < \infty$","Suppose  exists for all , show that",\lim_n e^{itb_n} |t|\le \delta \limsup |b_n| < \infty,"I would like some help with the following: Let $(b_n)_{n \ge 1}$ be a sequence of numbers such that $\lim_n e^{itb_n}$ exists for all $|t|\le \delta$ , $\delta >0$ . Show that $\limsup |b_n| < \infty$ . Edit: as per Mindlack 's hint, below is an attempt to a solution. For each $n$ define $$ f_n(t) = e^{itb_n}, \quad |t| < \delta. $$ Then, by assumption, $(f_n(t))_n$ converges for every $|t|\le \delta$ . Obviously each $f_n$ is square integrable since $$ \int_{-\delta}^{\delta} \left | f_n \right |^2 \, d \mu = \int_{-\delta}^{\delta} 1 \, d \mu = 2\delta. $$ As pointwise convergence implies convergence in $L^2$ , and $L^2([-t,t], \mu)$ is a complete metric space, the limit is also square integrable. To calculate the Fourier transform of this limit, one may use the Dominated convergence theorem. \begin{align*} \int_{-\delta}^{\delta} e^{-2 \pi it \xi}\lim_n f_n(t) \, d \mu(t) &= \lim_n\int_{-\delta}^{\delta} e^{-2 \pi it \xi}f_n(t) \, d \mu(t) \\ &= \lim_n\int_{-\delta}^{\delta} e^{-2 \pi it \xi}e^{itb_n} \, d \mu(t) \\ &= \lim_n\int_{-\delta}^{\delta} e^{it(b_n -2 \pi \xi)}\, d \mu(t)\\ &= \lim_n \left (\frac{e^{i\delta(b_n -2 \pi \xi)}}{i(b_n -2 \pi \xi)} - \frac{e^{-i\delta(b_n -2 \pi \xi)}}{i(b_n -2 \pi \xi)} \right ) \\ &= \lim_n \frac{2i \sin(\delta(b_n -2 \pi \xi))}{i(b_n -2 \pi \xi)} \\ &= \lim_n \frac{2 \sin(\delta(b_n -2 \pi \xi))}{b_n -2 \pi \xi}. \end{align*} I'm not sure what conclusion I could draw from this? Thanks in advance!","I would like some help with the following: Let be a sequence of numbers such that exists for all , . Show that . Edit: as per Mindlack 's hint, below is an attempt to a solution. For each define Then, by assumption, converges for every . Obviously each is square integrable since As pointwise convergence implies convergence in , and is a complete metric space, the limit is also square integrable. To calculate the Fourier transform of this limit, one may use the Dominated convergence theorem. I'm not sure what conclusion I could draw from this? Thanks in advance!","(b_n)_{n \ge 1} \lim_n e^{itb_n} |t|\le \delta \delta >0 \limsup |b_n| < \infty n 
f_n(t) = e^{itb_n}, \quad |t| < \delta.
 (f_n(t))_n |t|\le \delta f_n 
\int_{-\delta}^{\delta} \left | f_n \right |^2 \, d \mu = \int_{-\delta}^{\delta} 1 \, d \mu = 2\delta.
 L^2 L^2([-t,t], \mu) \begin{align*}
\int_{-\delta}^{\delta} e^{-2 \pi it \xi}\lim_n f_n(t) \, d \mu(t) &= \lim_n\int_{-\delta}^{\delta} e^{-2 \pi it \xi}f_n(t) \, d \mu(t) \\
&= \lim_n\int_{-\delta}^{\delta} e^{-2 \pi it \xi}e^{itb_n} \, d \mu(t) \\
&= \lim_n\int_{-\delta}^{\delta} e^{it(b_n -2 \pi \xi)}\, d \mu(t)\\
&= \lim_n \left (\frac{e^{i\delta(b_n -2 \pi \xi)}}{i(b_n -2 \pi \xi)} - \frac{e^{-i\delta(b_n -2 \pi \xi)}}{i(b_n -2 \pi \xi)} \right ) \\
&= \lim_n \frac{2i \sin(\delta(b_n -2 \pi \xi))}{i(b_n -2 \pi \xi)} \\
&= \lim_n \frac{2 \sin(\delta(b_n -2 \pi \xi))}{b_n -2 \pi \xi}.
\end{align*}","['sequences-and-series', 'complex-analysis', 'complex-numbers', 'limsup-and-liminf']"
68,Alternative method for evaluating double infinite sum,Alternative method for evaluating double infinite sum,,"I've come across the following double infinite sum through my current work: $$\sum_{k=0}^\infty \sum_{m=0}^\infty \binom{m+k}{m} \frac{a^k b^m}{k! \; m!},$$ where a and b are real constants. I found a method to evaluate this sum using complex analysis, in particular Egorychev's method stating that $$\binom{m+k}{m} = \frac{1}{2\pi j} \oint_C \frac{(1+z)^{m+k}}{z^{m+1}} \mbox{d}z,$$ where the countour is a unit circle centered around the origin Substituting this and using the complex integral representation of the modified Bessel function gives the apparent result that $$\sum_{k=0}^\infty \sum_{m=0}^\infty \binom{m+k}{m} \frac{a^k b^m}{k! \; m!} = \exp(a + b) I_0(2\sqrt{ab}).$$ Is there another way to evaluate this sum to a) check this result and b) to extend the result to higher dimensions e.g. $$\sum_{k=0}^\infty \sum_{m=0}^\infty \sum_{n=0}^\infty  (k+m+n)!\frac{a^k b^m c^n}{k!^2 \; m!^2 \; n!^2}$$ for real a, b and c? Egorychev's method becomes significantly more complicated in 3 or more dimensions! If it's possible to reduce the dimensionality of the sum, that would still be useful. As always, any help greatly appreciated!","I've come across the following double infinite sum through my current work: where a and b are real constants. I found a method to evaluate this sum using complex analysis, in particular Egorychev's method stating that where the countour is a unit circle centered around the origin Substituting this and using the complex integral representation of the modified Bessel function gives the apparent result that Is there another way to evaluate this sum to a) check this result and b) to extend the result to higher dimensions e.g. for real a, b and c? Egorychev's method becomes significantly more complicated in 3 or more dimensions! If it's possible to reduce the dimensionality of the sum, that would still be useful. As always, any help greatly appreciated!","\sum_{k=0}^\infty \sum_{m=0}^\infty \binom{m+k}{m} \frac{a^k b^m}{k! \; m!}, \binom{m+k}{m} = \frac{1}{2\pi j} \oint_C \frac{(1+z)^{m+k}}{z^{m+1}} \mbox{d}z, \sum_{k=0}^\infty \sum_{m=0}^\infty \binom{m+k}{m} \frac{a^k b^m}{k! \; m!} = \exp(a + b) I_0(2\sqrt{ab}). \sum_{k=0}^\infty \sum_{m=0}^\infty \sum_{n=0}^\infty  (k+m+n)!\frac{a^k b^m c^n}{k!^2 \; m!^2 \; n!^2}","['sequences-and-series', 'complex-analysis']"
69,Number of zeros outside the disk $\{ z : |z| \leq 2 \}$,Number of zeros outside the disk,\{ z : |z| \leq 2 \},"I need to count (including the multiplicities of the zeros) number of the zeros outside the disk $\{ z : |z| \leq  2 \}$ for the polynomial $f(z) = z^7 +9z^4 -7z +3$ . I know this should be direct application for Rouche's theorem, but I tried all choices for the two functions to get the required inequality $ |p(z)| < |q(z)|$ for $|z|=2 $ , but none of them works. Should I consider a different curve or what terms I should consider to get the required inequality? I think $z^7 +3$ should work but couldn't confirm that.","I need to count (including the multiplicities of the zeros) number of the zeros outside the disk for the polynomial . I know this should be direct application for Rouche's theorem, but I tried all choices for the two functions to get the required inequality for , but none of them works. Should I consider a different curve or what terms I should consider to get the required inequality? I think should work but couldn't confirm that.",\{ z : |z| \leq  2 \} f(z) = z^7 +9z^4 -7z +3  |p(z)| < |q(z)| |z|=2  z^7 +3,"['complex-analysis', 'roots', 'rouches-theorem']"
70,complex inequality (solution verification) [duplicate],complex inequality (solution verification) [duplicate],,"This question already exists : Solution verification to complex analysis problem, prove $f$ is a polynomial. Closed 3 years ago . Let $f$ be entire, $|f(z)|\leq 3|z|^4+1$ prove $f$ is a polynomial with deggre $\leq 4$ Solution: $f^{(4)}(z_0)=\frac{4!}{2\pi i} \int_c\frac{f(z)}{(z-z_0)^5}dz$ , $\Rightarrow$ $|f^{(4)}(z_0)|\leq \frac{4!}{2\pi i} \int_c |\frac{f(z)}{(z-z_0)^5}|dz \leq \frac{4!}{2\pi i} \int_c \frac{|f(z)|}{|(z-z_0)^5|}dz \leq$ $$\leq \frac{4!}{2\pi i} \int_{0}^{2\pi}\frac{|f(z_0+re^{it})ire^{it}|}{|(re^{it})^5|}dt \leq \frac{4!}{2\pi i} \int_{0}^{2\pi}\frac{(3(|z_0|+r)^4+1)r}{r^5}dt \leq  \frac{4!}{2\pi i} 2\pi\frac{(3(|z_0|+r)^4+1)}{r^4}$$ that means $f^{(4)}(z)$ is bounded so from Liouville's theorem its constant and therefore $f$ is a polynomial with deggre $\leq 4$ Is my solution correct ?","This question already exists : Solution verification to complex analysis problem, prove $f$ is a polynomial. Closed 3 years ago . Let be entire, prove is a polynomial with deggre Solution: , that means is bounded so from Liouville's theorem its constant and therefore is a polynomial with deggre Is my solution correct ?",f |f(z)|\leq 3|z|^4+1 f \leq 4 f^{(4)}(z_0)=\frac{4!}{2\pi i} \int_c\frac{f(z)}{(z-z_0)^5}dz \Rightarrow |f^{(4)}(z_0)|\leq \frac{4!}{2\pi i} \int_c |\frac{f(z)}{(z-z_0)^5}|dz \leq \frac{4!}{2\pi i} \int_c \frac{|f(z)|}{|(z-z_0)^5|}dz \leq \leq \frac{4!}{2\pi i} \int_{0}^{2\pi}\frac{|f(z_0+re^{it})ire^{it}|}{|(re^{it})^5|}dt \leq \frac{4!}{2\pi i} \int_{0}^{2\pi}\frac{(3(|z_0|+r)^4+1)r}{r^5}dt \leq  \frac{4!}{2\pi i} 2\pi\frac{(3(|z_0|+r)^4+1)}{r^4} f^{(4)}(z) f \leq 4,"['complex-analysis', 'solution-verification']"
71,"What is essential non-isolated singularity, of $f(z) = \sin\left(\frac{1}{\cos(\frac{1}{z})}\right)$.","What is essential non-isolated singularity, of .",f(z) = \sin\left(\frac{1}{\cos(\frac{1}{z})}\right),"Let a function $f$ be defined as $f(z) = \sin\left(\dfrac{1}{\cos\left(\frac{1}{z}\right)}\right)$ . I need to check what type of singularity it has at $z = 0$ ? I found it is non-isolated as it is a limit point of the set of singularities. Now in the answer key, It is written that it is essential and non-isolated. Now this confuses me as I have read that essential singularity is a type of isolated singularity. I even googled and saw the same. Can anyone throw some light on the meaning of essential non-isolated singularity? It would be a great help.","Let a function be defined as . I need to check what type of singularity it has at ? I found it is non-isolated as it is a limit point of the set of singularities. Now in the answer key, It is written that it is essential and non-isolated. Now this confuses me as I have read that essential singularity is a type of isolated singularity. I even googled and saw the same. Can anyone throw some light on the meaning of essential non-isolated singularity? It would be a great help.",f f(z) = \sin\left(\dfrac{1}{\cos\left(\frac{1}{z}\right)}\right) z = 0,"['complex-analysis', 'definition', 'singularity']"
72,Integrating in the right hand plane,Integrating in the right hand plane,,"I am trying to find the value of: $$\int_\Gamma \frac{1}{z} dz.$$ where $\Gamma$ is the semi circle in the right hand plane, traversed from $-i$ to $i$ my plan was to use the parameterization $\gamma(t)=\exp(it)$ . So $\gamma(t)'=i\exp(it)$ . Now using the formula: $$\int_\Gamma f(z) \, dz= \int_0^1 f(\gamma(t))\gamma(t)' \, dt$$ $$\int_\Gamma \frac{1}{z} dz= \int_0^1 \frac{i\exp(it)}{\exp(it)} \, dt$$ $$\int_\Gamma \frac{1}{z} dz= \int_0^1 i \, dt$$ $$\int_\Gamma \frac{1}{z} \, dz= i.$$ However this doesn't seem right and I am not sure how to verify it! Can anyone confirm? Also does anyone have any tips to check these things like online calculators or intuition because I can't see how complex integration works compared to real integration!","I am trying to find the value of: where is the semi circle in the right hand plane, traversed from to my plan was to use the parameterization . So . Now using the formula: However this doesn't seem right and I am not sure how to verify it! Can anyone confirm? Also does anyone have any tips to check these things like online calculators or intuition because I can't see how complex integration works compared to real integration!","\int_\Gamma \frac{1}{z} dz. \Gamma -i i \gamma(t)=\exp(it) \gamma(t)'=i\exp(it) \int_\Gamma f(z) \, dz= \int_0^1 f(\gamma(t))\gamma(t)' \, dt \int_\Gamma \frac{1}{z} dz= \int_0^1 \frac{i\exp(it)}{\exp(it)} \, dt \int_\Gamma \frac{1}{z} dz= \int_0^1 i \, dt \int_\Gamma \frac{1}{z} \, dz= i.","['complex-analysis', 'contour-integration']"
73,Computing Derivatives of Functions $\mathbb{R} \to \mathbb{C}$,Computing Derivatives of Functions,\mathbb{R} \to \mathbb{C},"In every complex analysis book I have come across (mainly Ahlfors and Stein/Shakarchi), the calculation $\frac{d}{dt} e^{it} = ie^{it}$ is taken for granted. But I want to look at this more carefully, because it doesn't seem immediately obvious to me. The function $f(t) = e^{it}$ is a function $\mathbb{R} \to \mathbb{C}$ , and for any function $\mathbb{R} \to \mathbb{C}$ we define the derivative by dealing with the real and imaginary parts separately: $\frac{d}{dt}(u(t) + iv(t)) := u'(t) + iv'(t)$ . So working from the definition, I would compute $\frac{d}{dt}e^{it}$ by writing $e^{it} = \cos(t) + i\sin(t)$ and differentiating each component. This does give us $ie^{it}$ , but what the authors of these books seem to suggest without proof is that there is a type of chain rule that can be applied to make the calculation simpler. This chain rule would have to apply to compositions $\mathbb{R} \to \mathbb{C} \to \mathbb{C}$ , but the only chain rules I have seen explicitly described are for compositions of differentiable functions $\mathbb{R} \to \mathbb{R} \to \mathbb{R}$ and for holomorphic functions $\mathbb{C} \to \mathbb{C} \to \mathbb{C}$ . In other places in the books, a chain rule for compositions $\mathbb{R} \to \mathbb{R} \to \mathbb{C}$ was used, but the proof of this one is trivial in light of the definition of derivatives of functions $\mathbb{R} \to \mathbb{C}$ and the ordinary real chain rule. But the case $\mathbb{R} \to \mathbb{C} \to \mathbb{C}$ is different from all of these, and I'm surprised none of the authors have mentioned it, as it doesn't seem to follow immediately from either the $\mathbb{R} \to \mathbb{R} \to \mathbb{R}$ or $\mathbb{C} \to \mathbb{C} \to \mathbb{C}$ chain rule. Does such a chain rule actually exist? And if so, how do we prove it?","In every complex analysis book I have come across (mainly Ahlfors and Stein/Shakarchi), the calculation is taken for granted. But I want to look at this more carefully, because it doesn't seem immediately obvious to me. The function is a function , and for any function we define the derivative by dealing with the real and imaginary parts separately: . So working from the definition, I would compute by writing and differentiating each component. This does give us , but what the authors of these books seem to suggest without proof is that there is a type of chain rule that can be applied to make the calculation simpler. This chain rule would have to apply to compositions , but the only chain rules I have seen explicitly described are for compositions of differentiable functions and for holomorphic functions . In other places in the books, a chain rule for compositions was used, but the proof of this one is trivial in light of the definition of derivatives of functions and the ordinary real chain rule. But the case is different from all of these, and I'm surprised none of the authors have mentioned it, as it doesn't seem to follow immediately from either the or chain rule. Does such a chain rule actually exist? And if so, how do we prove it?",\frac{d}{dt} e^{it} = ie^{it} f(t) = e^{it} \mathbb{R} \to \mathbb{C} \mathbb{R} \to \mathbb{C} \frac{d}{dt}(u(t) + iv(t)) := u'(t) + iv'(t) \frac{d}{dt}e^{it} e^{it} = \cos(t) + i\sin(t) ie^{it} \mathbb{R} \to \mathbb{C} \to \mathbb{C} \mathbb{R} \to \mathbb{R} \to \mathbb{R} \mathbb{C} \to \mathbb{C} \to \mathbb{C} \mathbb{R} \to \mathbb{R} \to \mathbb{C} \mathbb{R} \to \mathbb{C} \mathbb{R} \to \mathbb{C} \to \mathbb{C} \mathbb{R} \to \mathbb{R} \to \mathbb{R} \mathbb{C} \to \mathbb{C} \to \mathbb{C},"['complex-analysis', 'chain-rule']"
74,How do I show the inequality $\tan(|\Re(\pi z/4)|) \le |\tan(\pi z/4 )|$ for $z$ in the unit disc?,How do I show the inequality  for  in the unit disc?,\tan(|\Re(\pi z/4)|) \le |\tan(\pi z/4 )| z,"I trying to prove the ""Schwarz's lemma for harmonic functions:"" If $u:\Bbb D \to \Bbb R$ is harmonic, $u(0) = 0$ , and $|u(z)| \le 1$ for each $z \in \Bbb D$ , then $$ |u(z)| \le \frac{4}{\pi}\arctan(|z|). $$ The idea I have is to notice that since $\Bbb D$ is simply connected, $u$ is the real part of an analytic function $f:\Bbb D \to \Bbb C$ . In particular, we may choose its harmonic conjugate so that $f(0) = 0$ . Now since $|u(z)| \le 1$ , $f(\Bbb D) \subseteq (-1,1)\times\Bbb R$ , and we can map this infinite strip conformally onto $\Bbb D$ by the map $z \mapsto \tan\left(\frac{\pi}{4} z\right)$ . From here, we can use the standard Schwarz lemma on the function $g:\Bbb D \to \Bbb D$ defined by $$ g(z) = \tan\left(\frac{\pi}{4}f(z)\right) $$ since $g(0) = 0$ . This gives $$ |g(z)| \le |z|, $$ and unpacking this gives $$ \left|\tan\left(\frac{\pi}{4}f(z)\right)\right| \le |z|. $$ In order to complete the proof, I must show the inequality $$ \tan\left(\left|\mathrm{Re}\left(\frac{\pi}{4}z\right)\right|\right) \le \left|\tan\left(\frac{\pi}{4}z\right)\right|, $$ so that I can then get $$ \tan\left(\left|\frac{\pi}{4}u(z)\right|\right) \le |z| $$ and hence $$ |u(z)| \le \frac{4}{\pi}\arctan(|z|). $$ I found that you can write $\tan(z)$ in terms of its real and imaginary parts as $$ \tan(x + iy) = \frac{\sin(2x) + i\sinh(2y)}{\cos(2x) + \cosh(2y)}, $$ and using Desmos I assured myself that the inequality is true, but I have no clue how to show such an inequality. Any help is appreciated!","I trying to prove the ""Schwarz's lemma for harmonic functions:"" If is harmonic, , and for each , then The idea I have is to notice that since is simply connected, is the real part of an analytic function . In particular, we may choose its harmonic conjugate so that . Now since , , and we can map this infinite strip conformally onto by the map . From here, we can use the standard Schwarz lemma on the function defined by since . This gives and unpacking this gives In order to complete the proof, I must show the inequality so that I can then get and hence I found that you can write in terms of its real and imaginary parts as and using Desmos I assured myself that the inequality is true, but I have no clue how to show such an inequality. Any help is appreciated!","u:\Bbb D \to \Bbb R u(0) = 0 |u(z)| \le 1 z \in \Bbb D  |u(z)| \le \frac{4}{\pi}\arctan(|z|).  \Bbb D u f:\Bbb D \to \Bbb C f(0) = 0 |u(z)| \le 1 f(\Bbb D) \subseteq (-1,1)\times\Bbb R \Bbb D z \mapsto \tan\left(\frac{\pi}{4} z\right) g:\Bbb D \to \Bbb D  g(z) = \tan\left(\frac{\pi}{4}f(z)\right)  g(0) = 0  |g(z)| \le |z|,   \left|\tan\left(\frac{\pi}{4}f(z)\right)\right| \le |z|.   \tan\left(\left|\mathrm{Re}\left(\frac{\pi}{4}z\right)\right|\right) \le \left|\tan\left(\frac{\pi}{4}z\right)\right|,   \tan\left(\left|\frac{\pi}{4}u(z)\right|\right) \le |z|   |u(z)| \le \frac{4}{\pi}\arctan(|z|).  \tan(z)  \tan(x + iy) = \frac{\sin(2x) + i\sinh(2y)}{\cos(2x) + \cosh(2y)}, ","['complex-analysis', 'inequality']"
75,"Define an operator $T\in B(C[0,1])$ such that: $(Tf)(x)=xf(x)$ for all $x\in [0,1]$ and $f\in C[0,1]$. Prove that $T$ has no eignvalues",Define an operator  such that:  for all  and . Prove that  has no eignvalues,"T\in B(C[0,1]) (Tf)(x)=xf(x) x\in [0,1] f\in C[0,1] T","Define an operator $T\in B(C[0,1])$ such that: $(Tf)(x)=xf(x)$ for all $x\in [0,1]$ and $f\in C[0,1]$ . Prove that $T$ has no eignvalues and find $\sigma(T)$ . I think that what is meant is to show that there are no $\lambda\in C$ such that $Tf(x)=\lambda f(x)$ . By contradiction: $Tf(x)=\lambda f(x)$ = {by definition} = $xf(x)$ . However this equation is true iff $f(x)=0$ for all $x \in [0,1]$ , however we're given that $f\in C[0,1]$ . The spectrum of T is: All the scalars $\lambda$ such that $\lambda*I-T$ is not invertible. I am not sure if it is fine to connect that with the first part. Since T has no eign-values so $T-I$ is not injective then not invertible.","Define an operator such that: for all and . Prove that has no eignvalues and find . I think that what is meant is to show that there are no such that . By contradiction: = {by definition} = . However this equation is true iff for all , however we're given that . The spectrum of T is: All the scalars such that is not invertible. I am not sure if it is fine to connect that with the first part. Since T has no eign-values so is not injective then not invertible.","T\in B(C[0,1]) (Tf)(x)=xf(x) x\in [0,1] f\in C[0,1] T \sigma(T) \lambda\in C Tf(x)=\lambda f(x) Tf(x)=\lambda f(x) xf(x) f(x)=0 x \in [0,1] f\in C[0,1] \lambda \lambda*I-T T-I","['real-analysis', 'complex-analysis']"
76,Existence of rectifiable/piecewise $C^1$ curves between two points of an open connected domain in $\mathbb{C}$,Existence of rectifiable/piecewise  curves between two points of an open connected domain in,C^1 \mathbb{C},"The question is the same as the title. Precisely, Suppose $\Omega \subseteq \mathbb{C}$ is an open connected domain. Given two points $z_0, z_1 \in \Omega$ , does there exist a rectifiable curve $\gamma : [0, 1] \to \Omega$ with $\gamma(0) = z_0, \gamma(1) = z_1$ . What about piecewise $C^1$ $\gamma$ ? Since $\mathbb{C}$ is locally path connected and $\Omega$ is connected, we have that $\Omega$ is path connected, so that there is a continuous curve $\gamma$ which starts at $z_0$ and ends at $z_1$ . But can we always choose $\gamma$ to be rectifiable or piecewise $C^1$ (the latter would imply the former though).","The question is the same as the title. Precisely, Suppose is an open connected domain. Given two points , does there exist a rectifiable curve with . What about piecewise ? Since is locally path connected and is connected, we have that is path connected, so that there is a continuous curve which starts at and ends at . But can we always choose to be rectifiable or piecewise (the latter would imply the former though).","\Omega \subseteq \mathbb{C} z_0, z_1 \in \Omega \gamma : [0, 1] \to \Omega \gamma(0) = z_0, \gamma(1) = z_1 C^1 \gamma \mathbb{C} \Omega \Omega \gamma z_0 z_1 \gamma C^1","['complex-analysis', 'analysis', 'curves', 'connectedness', 'path-connected']"
77,Cauchy's integral formula when $z_0$ lies outside of contour w/o residue thrm,Cauchy's integral formula when  lies outside of contour w/o residue thrm,z_0,"I understand there are many questions regarding this topic (Complex integral where poles are outside of the given region) I just wanted to double check with everyone what I gathered so far: $$f(z_0) = \frac{1}{2\pi i}\int_\Gamma \frac{f(z)}{z-z_0}dz = 0, \\ $$ if $z_0$ lies outside of the given contour and there exists a closed loop around the pole where the loop is analytic everywhere (this is my understanding of holomorphic ). I think this is true due to the path independence but I can't prove it exactly. Can anyone please help? One specific example will be $$\int_C \frac{ze^z}{2z-3}dz$$ where C be the circle $|z-1.5| = 2$ traversed once in the positive sense. I calculated that $z_0 = 3/2$ does not lie inside of the curve ( $z$ intersects with the real axis at $\pm \sqrt{1.75}$ ). Hence, I claim according to the above assumption because the pole does not lie inside of the region of interest ( $C$ ), the integral is $0$ . I stated w/o residue thrm because we didn't learn it. I see many answers use residue thrm in their answer so it will be great if you could explain it w/o residue thrm!","I understand there are many questions regarding this topic (Complex integral where poles are outside of the given region) I just wanted to double check with everyone what I gathered so far: if lies outside of the given contour and there exists a closed loop around the pole where the loop is analytic everywhere (this is my understanding of holomorphic ). I think this is true due to the path independence but I can't prove it exactly. Can anyone please help? One specific example will be where C be the circle traversed once in the positive sense. I calculated that does not lie inside of the curve ( intersects with the real axis at ). Hence, I claim according to the above assumption because the pole does not lie inside of the region of interest ( ), the integral is . I stated w/o residue thrm because we didn't learn it. I see many answers use residue thrm in their answer so it will be great if you could explain it w/o residue thrm!","f(z_0) = \frac{1}{2\pi i}\int_\Gamma \frac{f(z)}{z-z_0}dz = 0, \\  z_0 \int_C \frac{ze^z}{2z-3}dz |z-1.5| = 2 z_0 = 3/2 z \pm \sqrt{1.75} C 0","['integration', 'complex-analysis', 'contour-integration']"
78,"A ""simple"" coupled system of first order PDEs","A ""simple"" coupled system of first order PDEs",,"I'm trying to solve/ understand the the following system of PDEs: $$\begin{cases} \partial_xf(x,y)+\partial_yg(x,y) &= 0,\\ \partial_xg(x,y)-\partial_yf(x,y) &= 0, \end{cases}$$ for the functions $f$ and $g$ . Here's what I saw so far: by deriving each line by $x$ or $y$ and substituing in the other equations, we can see that de system becomes $$\begin{cases} (\partial^2_x+\partial^2_y)f(x,y) &= 0,\\ (\partial^2_x+\partial^2_y)g(x,y) &= 0, \end{cases}$$ so each function must satisfy the 2-dimensional Laplace equation, for which I know the solutions. But, if I'm not mistaken, this manipulation results in finding a particular case form of solutions, i.e. a subset of solutions in the bigger set of solutions that the initial system admits. Is that right ? these equations are the Cauchy-Riemann equations, thus this system is exactly equivalent to asking that the complexe map $$F(x+iy)=g(x,y)+if(x,y)$$ is holomorphic (or $\mathbb{C}$ -differentiable) but, up to my knowledge, there exist no generic explicit expression for such maps. Does this means that this system of PDEs is just a constraint on the form of $f$ and $g$ but that there is no generic explicit solution ? In general, how to solve this system ? I'm also very interested in a way (coordinate change for example) to obtain two decoupled equations.","I'm trying to solve/ understand the the following system of PDEs: for the functions and . Here's what I saw so far: by deriving each line by or and substituing in the other equations, we can see that de system becomes so each function must satisfy the 2-dimensional Laplace equation, for which I know the solutions. But, if I'm not mistaken, this manipulation results in finding a particular case form of solutions, i.e. a subset of solutions in the bigger set of solutions that the initial system admits. Is that right ? these equations are the Cauchy-Riemann equations, thus this system is exactly equivalent to asking that the complexe map is holomorphic (or -differentiable) but, up to my knowledge, there exist no generic explicit expression for such maps. Does this means that this system of PDEs is just a constraint on the form of and but that there is no generic explicit solution ? In general, how to solve this system ? I'm also very interested in a way (coordinate change for example) to obtain two decoupled equations.","\begin{cases}
\partial_xf(x,y)+\partial_yg(x,y) &= 0,\\
\partial_xg(x,y)-\partial_yf(x,y) &= 0,
\end{cases} f g x y \begin{cases}
(\partial^2_x+\partial^2_y)f(x,y) &= 0,\\
(\partial^2_x+\partial^2_y)g(x,y) &= 0,
\end{cases} F(x+iy)=g(x,y)+if(x,y) \mathbb{C} f g","['complex-analysis', 'partial-differential-equations', 'systems-of-equations']"
79,$\operatorname{Aut}(\mathbb{H})$ acts on circles,acts on circles,\operatorname{Aut}(\mathbb{H}),"Suppose $\mathbb{H}=\{z \in \mathbb{C}\mid \operatorname{Im}(z)>0\}$ . Is it true that $\operatorname{Aut}(\mathbb{H})$ can map any circle in $\mathbb{H}$ to any circle in $\mathbb{H}$ (i.e. for any two circles $C_1,C_2$ with all their points in $\mathbb{H}$ there's some element of $\operatorname{Aut}(\mathbb{H})$ that carries $C_1$ to $C_2$ )? The only useful fact I know is that $f\in \operatorname{Aut}(\mathbb{H}) \Rightarrow f=\frac{az+b}{cz+d}, a,b,c,d \in \mathbb{R}, ad-bc \neq 0 $ . Thank you for any help!",Suppose . Is it true that can map any circle in to any circle in (i.e. for any two circles with all their points in there's some element of that carries to )? The only useful fact I know is that . Thank you for any help!,"\mathbb{H}=\{z \in \mathbb{C}\mid \operatorname{Im}(z)>0\} \operatorname{Aut}(\mathbb{H}) \mathbb{H} \mathbb{H} C_1,C_2 \mathbb{H} \operatorname{Aut}(\mathbb{H}) C_1 C_2 f\in \operatorname{Aut}(\mathbb{H}) \Rightarrow f=\frac{az+b}{cz+d}, a,b,c,d \in \mathbb{R}, ad-bc \neq 0 ","['complex-analysis', 'complex-numbers', 'circles', 'mobius-transformation']"
80,Cauchy-Riemann Equation for Surface Equations,Cauchy-Riemann Equation for Surface Equations,,"Suppose we are given smooth functions $W,V:\mathbb{R}^2\times\mathbb{C}\to\mathbb{C}^2$ and are asked to determine if the function $Q(W(x,y,z(x,y)),V(x,y,z(x,y))$ solving $$ Q(W(x,y,z(x,y)),V(x,y,z(x,y)))=0, $$ is analytic. Following Chapter 10 of Lectures on Random Lozenge  Tilings , Gorin states that the sufficient condition for $Q$ to be analytic is to establish $W(V)$ is analytic or in other words $$\frac{\partial W}{\partial\bar{V}}=0. $$ Of course this form of the Cauchy-Riemann equations $$\frac{\partial f}{\partial \bar{z}}=0 $$ is recognisable when establishing $f(z):\mathbb{C}\to\mathbb{C}$ is analytic, but I don't understand how $\frac{\partial W}{\partial\bar{V}}=0$ implies $Q$ is analytic. What's the basic reason for this? Also, would $\frac{\partial V}{\partial\bar{W}}=0$ do the job, too? For context, see the latter portion of Chapter 9 from the linked reference which derives the surface equation $Q=0$ from the method of complex characteristics and where there is a concrete example of the functions $W,V$ .","Suppose we are given smooth functions and are asked to determine if the function solving is analytic. Following Chapter 10 of Lectures on Random Lozenge  Tilings , Gorin states that the sufficient condition for to be analytic is to establish is analytic or in other words Of course this form of the Cauchy-Riemann equations is recognisable when establishing is analytic, but I don't understand how implies is analytic. What's the basic reason for this? Also, would do the job, too? For context, see the latter portion of Chapter 9 from the linked reference which derives the surface equation from the method of complex characteristics and where there is a concrete example of the functions .","W,V:\mathbb{R}^2\times\mathbb{C}\to\mathbb{C}^2 Q(W(x,y,z(x,y)),V(x,y,z(x,y)) 
Q(W(x,y,z(x,y)),V(x,y,z(x,y)))=0,
 Q W(V) \frac{\partial W}{\partial\bar{V}}=0.
 \frac{\partial f}{\partial \bar{z}}=0
 f(z):\mathbb{C}\to\mathbb{C} \frac{\partial W}{\partial\bar{V}}=0 Q \frac{\partial V}{\partial\bar{W}}=0 Q=0 W,V","['complex-analysis', 'characteristics', 'cauchy-riemann-equations']"
81,Compute $\int_{-\infty}^{\infty}\frac{x\sin(\pi x)}{(x-3)(x-2)}dx$ using residue thoerem,Compute  using residue thoerem,\int_{-\infty}^{\infty}\frac{x\sin(\pi x)}{(x-3)(x-2)}dx,"I am trying to compute $\int_{-\infty}^{\infty}\frac{x\sin(\pi x)}{(x-3)(x-2)}dx$ using the residue theorem. To do so, I am integrating the function $f(z)=\frac{ze^{i\pi z}}{(z-3)(z-2)}$ over a the frontier of $\{z:|z|<R,Im(z)>0\}-(\{z:|z-2|<r\}\cup\{z:|z-3|<r\})$ (a semicircle that ""avoids"" the singularities of $f$ ). I have used Jordan's lemma to prove that the integral over the big semicircle is null when $R\longrightarrow \infty$ . My problem is I do not know how to compute the integral over the small semicircles when $r\longrightarrow 0$ . How could I approach this? Thanks in advance.","I am trying to compute using the residue theorem. To do so, I am integrating the function over a the frontier of (a semicircle that ""avoids"" the singularities of ). I have used Jordan's lemma to prove that the integral over the big semicircle is null when . My problem is I do not know how to compute the integral over the small semicircles when . How could I approach this? Thanks in advance.","\int_{-\infty}^{\infty}\frac{x\sin(\pi x)}{(x-3)(x-2)}dx f(z)=\frac{ze^{i\pi z}}{(z-3)(z-2)} \{z:|z|<R,Im(z)>0\}-(\{z:|z-2|<r\}\cup\{z:|z-3|<r\}) f R\longrightarrow \infty r\longrightarrow 0","['complex-analysis', 'improper-integrals', 'residue-calculus']"
82,"Proposition about Weierstrass's elliptic function, or $\wp$ function.","Proposition about Weierstrass's elliptic function, or  function.",\wp,"I cannot prove the proposition about Elliptic functions. Proposition; Every Elliptic function $f$ of order 2 whose pole set is contained in the lattice $\Lambda$ is written as $f=a+b \wp $ , where $\wp$ is Weierstrass's elliptic function, i.e. \begin{equation} \wp (z)=\dfrac{1}{z^2} + \sum_{\omega \in \Lambda-\{0\}} \bigg( \dfrac{1}{(z-\omega)^2} - \dfrac{1}{\omega^2} \Bigg) \end{equation} In this page Direct construction of an arbitrary elliptic function of order $2$ with pole set contained in its lattice. , it is said that for every $a \in \Lambda$ , the Laurent series of $f$ about $a$ is written as \begin{equation} f(z)=\sum_{n=-2}^{\infty} c_n (z-a)^n \quad (c_{-2}\neq 0). \end{equation} And let $g:=f-c_{-2} \wp$ . The Laurent series of $g(z)$ about $a$ is written as \begin{equation} g(z)=\sum_{n=-1}^{\infty} c_{n} (z-a)^n. \end{equation} But I cannot understand why $c_{-2}$ disappears. I have \begin{equation} g(z)= \sum_{n=-2}^{\infty} c_n (z-a)^n -c_{-2}  \left( \dfrac{1}{z^2} + \sum_{\omega \in \Lambda-\{0\}} \bigg( \dfrac{1}{(z-\omega)^2} - \dfrac{1}{\omega^2} \Bigg) \right). \end{equation} I don't know what should I do in order to see the Laurent series of $g(z)$ about $a$ . How should I deformate $g(z)$ ? I would like you to give me some ideas.","I cannot prove the proposition about Elliptic functions. Proposition; Every Elliptic function of order 2 whose pole set is contained in the lattice is written as , where is Weierstrass's elliptic function, i.e. In this page Direct construction of an arbitrary elliptic function of order $2$ with pole set contained in its lattice. , it is said that for every , the Laurent series of about is written as And let . The Laurent series of about is written as But I cannot understand why disappears. I have I don't know what should I do in order to see the Laurent series of about . How should I deformate ? I would like you to give me some ideas.","f \Lambda f=a+b \wp  \wp \begin{equation}
\wp (z)=\dfrac{1}{z^2} + \sum_{\omega \in \Lambda-\{0\}} \bigg( \dfrac{1}{(z-\omega)^2} - \dfrac{1}{\omega^2} \Bigg)
\end{equation} a \in \Lambda f a \begin{equation}
f(z)=\sum_{n=-2}^{\infty} c_n (z-a)^n \quad (c_{-2}\neq 0).
\end{equation} g:=f-c_{-2} \wp g(z) a \begin{equation}
g(z)=\sum_{n=-1}^{\infty} c_{n} (z-a)^n.
\end{equation} c_{-2} \begin{equation}
g(z)=
\sum_{n=-2}^{\infty} c_n (z-a)^n -c_{-2}  \left( \dfrac{1}{z^2} + \sum_{\omega \in \Lambda-\{0\}} \bigg( \dfrac{1}{(z-\omega)^2} - \dfrac{1}{\omega^2} \Bigg) \right).
\end{equation} g(z) a g(z)","['complex-analysis', 'laurent-series', 'elliptic-functions']"
83,Integral with residue theorem,Integral with residue theorem,,"I have to resolve the following integral for a proof of theorem. It is used the residue theorem. However I am not in confidence with this argument. I would like to have more detailed step. The integral is $$\int_{-\infty}^{\infty}\frac{{\rm d}k_{1}}{2\pi} \frac{e^{{\rm i}k_{1}\,x_{1}}}{{\rm i}k_{0} + k_{1}}$$ The integral can be solved in the comples plane in the half circle with radius $R\rightarrow \infty$ that rests on the real axis and lies in the upper half plane. $$\int_{-\infty}^{\infty}\frac{dk_1}{2\pi} \frac{e^{ik_1 x_1}}{ik_0+k_1}=\int_{half\,circle}\frac{dk_1}{2\pi} \frac{e^{ik_1 x_1}}{ik_0+k_1} $$ The integral on the circumnference goes to zero, infact, using the change of variable $k_1=Re^{i\theta}$ , one has: \begin{align} &\int_{\smallfrown R}\frac{dk_1}{2\pi} \frac{e^{ik_1 x_1}}{ik_0+k_1} \\[5mm] = &\ \int_{0}^{\pi} \frac{d\theta i Re^{i\theta}}{2\pi}\frac{e^{ix_1Rcos\theta}e^{-x_1Rsin\theta}}{ik_0+Re^{i\theta}}\rightarrow 0 \,\,\,\mbox{for}\,R\rightarrow\infty \end{align} And here the first question: how can it goes to zero? At this point one can resolves using the residue theorem. The unique pole is in $k_1=-ik_0$ so to have a non zero result, one needs $k_0<0$ . Why is the integral equal to zero in the case $k_0>0$ ? So in the hypothesis that $x_1>0$ and $k_0<0$ one has: $$\int_{-\infty}^{\infty}\frac{dk_1}{2\pi} \frac{e^{ik_1 x_1}}{ik_0+k_1}=ie^{k_0x_1}$$","I have to resolve the following integral for a proof of theorem. It is used the residue theorem. However I am not in confidence with this argument. I would like to have more detailed step. The integral is The integral can be solved in the comples plane in the half circle with radius that rests on the real axis and lies in the upper half plane. The integral on the circumnference goes to zero, infact, using the change of variable , one has: And here the first question: how can it goes to zero? At this point one can resolves using the residue theorem. The unique pole is in so to have a non zero result, one needs . Why is the integral equal to zero in the case ? So in the hypothesis that and one has:","\int_{-\infty}^{\infty}\frac{{\rm d}k_{1}}{2\pi} \frac{e^{{\rm i}k_{1}\,x_{1}}}{{\rm i}k_{0} + k_{1}} R\rightarrow \infty \int_{-\infty}^{\infty}\frac{dk_1}{2\pi} \frac{e^{ik_1 x_1}}{ik_0+k_1}=\int_{half\,circle}\frac{dk_1}{2\pi} \frac{e^{ik_1 x_1}}{ik_0+k_1}
 k_1=Re^{i\theta} \begin{align}
&\int_{\smallfrown R}\frac{dk_1}{2\pi} \frac{e^{ik_1 x_1}}{ik_0+k_1}
\\[5mm] = &\
\int_{0}^{\pi} \frac{d\theta i Re^{i\theta}}{2\pi}\frac{e^{ix_1Rcos\theta}e^{-x_1Rsin\theta}}{ik_0+Re^{i\theta}}\rightarrow 0 \,\,\,\mbox{for}\,R\rightarrow\infty
\end{align} k_1=-ik_0 k_0<0 k_0>0 x_1>0 k_0<0 \int_{-\infty}^{\infty}\frac{dk_1}{2\pi} \frac{e^{ik_1 x_1}}{ik_0+k_1}=ie^{k_0x_1}","['integration', 'complex-analysis', 'complex-integration', 'residue-calculus']"
84,Interpreting the logarithm as a sum of simple poles along the negative real axis,Interpreting the logarithm as a sum of simple poles along the negative real axis,,"I've heard it remarked that you can basically consider $\log z$ to be a function which has simple poles everywhere on the negative real axis (with a constant ""residue density"" at each pole).  This would be something like $$ \log z = \int_0^\infty \frac{dx}{z + x} $$ But of course the integral on the right-hand side actually diverges.  We actually get $$ \int_0^\infty \frac{dx}{z + x} = \lim_{b \to \infty} \int_0^b \frac{dx}{z + x} = \lim_{b \to \infty} \left( \log(z + b) - \log(z) \right) = \infty $$ In physics, there are a variety of methods for subtracting out the divergent part of such a limit to get a finite answer (various flavors of regularization and renormalization ).  I'm wondering whether there is a standard approach here so that something similar can be done to ""rescue"" the first equation above from the divergent part of the integral. Another way of phrasing the problem above is that I showed that the Stieltjes transform of a constant on the interval $(-\infty, 0]$ does not exist.  But perhaps there is another density function $\rho$ so that $\log z$ is the Stieltjes transform of $\rho$ . $$ \log z = \int_0^\infty \frac{\rho(x)}{z + x} dx $$ What is $\rho$ ?  Well, the Stieltjes inversion formula says that it should be given by $$ \begin{align} \rho(x) &= \lim_{\epsilon \to 0} \frac{\log(x+i\epsilon) - \log(x-i\epsilon)}{2\pi i} \\ &= \frac{(\log |x| + \pi i) - (\log |x| - \pi i)}{2\pi i} \\ &= 1 \end{align} $$ But this gets me exactly back to the integral that I started with, which is divergent!  Hopefully I am just missing something obvious. Edit: Alternate statement of question There has been a lot of confusion in the comments below about what I am looking for, so let me restate it in a very narrow way.  I would be satisfied with either of the following: A sequence of meromorphic functions $f_n(z)$ with simple poles along the negative real axis with the following properties: a. The poles become dense in the limit $n \to \infty$ . b. $\lim_{n \to \infty} f_n(z) = \log z$ A proof that there is no such sequence.","I've heard it remarked that you can basically consider to be a function which has simple poles everywhere on the negative real axis (with a constant ""residue density"" at each pole).  This would be something like But of course the integral on the right-hand side actually diverges.  We actually get In physics, there are a variety of methods for subtracting out the divergent part of such a limit to get a finite answer (various flavors of regularization and renormalization ).  I'm wondering whether there is a standard approach here so that something similar can be done to ""rescue"" the first equation above from the divergent part of the integral. Another way of phrasing the problem above is that I showed that the Stieltjes transform of a constant on the interval does not exist.  But perhaps there is another density function so that is the Stieltjes transform of . What is ?  Well, the Stieltjes inversion formula says that it should be given by But this gets me exactly back to the integral that I started with, which is divergent!  Hopefully I am just missing something obvious. Edit: Alternate statement of question There has been a lot of confusion in the comments below about what I am looking for, so let me restate it in a very narrow way.  I would be satisfied with either of the following: A sequence of meromorphic functions with simple poles along the negative real axis with the following properties: a. The poles become dense in the limit . b. A proof that there is no such sequence.","\log z  \log z = \int_0^\infty \frac{dx}{z + x}   \int_0^\infty \frac{dx}{z + x} = \lim_{b \to \infty} \int_0^b \frac{dx}{z + x} = \lim_{b \to \infty} \left( \log(z + b) - \log(z) \right) = \infty  (-\infty, 0] \rho \log z \rho  \log z = \int_0^\infty \frac{\rho(x)}{z + x} dx  \rho  \begin{align} \rho(x) &= \lim_{\epsilon \to 0} \frac{\log(x+i\epsilon) - \log(x-i\epsilon)}{2\pi i} \\ &= \frac{(\log |x| + \pi i) - (\log |x| - \pi i)}{2\pi i} \\ &= 1 \end{align}  f_n(z) n \to \infty \lim_{n \to \infty} f_n(z) = \log z","['complex-analysis', 'logarithms', 'integral-transforms', 'divergent-integrals']"
85,Understanding Complex Operators,Understanding Complex Operators,,"I am not a follower of Schaum's Outline of Complex Variables but for seeking my professor lecture I read the third chapter called Complex Differentiation and the Cauchy-Riemann Equations . And I introduced some of the complex operators which isn't explained well manner in that chapter. Here are those: If $A(x,y)=P(x,y)+iQ(x,y)$ is a complex continuously differentiable function of $x$ and $y$ (vector? isn't those come from $\mathbb R$ ) then $$\text{grad }A=\nabla A=\frac{\partial P}{\partial x}-\frac{\partial Q}{\partial y}+i\left(\frac{\partial P}{\partial y}+\frac{\partial Q}{\partial x}\right)$$ The $\nabla$ del symbol can be interpreted as a vector of partial derivative operators, and its three possible meanings—gradient, divergence, and curl—can be formally viewed as the product with a scalar, a dot product, and a cross product, respectively, of the del ""operator"" with the field. But I can't relate the above operation with any of those mentioned category (linked statement from Wikipedia). Rather it seems complex multiplication of two number. The divergence of $A$ is, $$\text{div }A=\nabla\cdot A=\text{Re}\{\bar\nabla A\}=\text{Re}\left\{\left(\frac{\partial}{\partial x}-i\frac{\partial}{\partial y}\right)(P+iQ)\right \}$$ The curl of $A$ is, $$|\text{curl }A|=|\nabla \times A|=|\text{Im}\{\bar \nabla A\}|=\left|\text{Im}\left\{\left(\frac{\partial}{\partial x}-i\frac{\partial}{\partial y} \right)(P+iQ) \right\}  \right|=\left| \left(\frac{\partial Q}{\partial x}-\frac{\partial P}{\partial y} \right)\right|$$ There is no reference to how those formulas come from. I really want to know their derivation. Any reference or solution would be great helpful for me.","I am not a follower of Schaum's Outline of Complex Variables but for seeking my professor lecture I read the third chapter called Complex Differentiation and the Cauchy-Riemann Equations . And I introduced some of the complex operators which isn't explained well manner in that chapter. Here are those: If is a complex continuously differentiable function of and (vector? isn't those come from ) then The del symbol can be interpreted as a vector of partial derivative operators, and its three possible meanings—gradient, divergence, and curl—can be formally viewed as the product with a scalar, a dot product, and a cross product, respectively, of the del ""operator"" with the field. But I can't relate the above operation with any of those mentioned category (linked statement from Wikipedia). Rather it seems complex multiplication of two number. The divergence of is, The curl of is, There is no reference to how those formulas come from. I really want to know their derivation. Any reference or solution would be great helpful for me.","A(x,y)=P(x,y)+iQ(x,y) x y \mathbb R \text{grad }A=\nabla A=\frac{\partial P}{\partial x}-\frac{\partial Q}{\partial y}+i\left(\frac{\partial P}{\partial y}+\frac{\partial Q}{\partial x}\right) \nabla A \text{div }A=\nabla\cdot A=\text{Re}\{\bar\nabla A\}=\text{Re}\left\{\left(\frac{\partial}{\partial x}-i\frac{\partial}{\partial y}\right)(P+iQ)\right \} A |\text{curl }A|=|\nabla \times A|=|\text{Im}\{\bar \nabla A\}|=\left|\text{Im}\left\{\left(\frac{\partial}{\partial x}-i\frac{\partial}{\partial y} \right)(P+iQ) \right\}  \right|=\left| \left(\frac{\partial Q}{\partial x}-\frac{\partial P}{\partial y} \right)\right|","['complex-analysis', 'multivariable-calculus', 'vector-analysis']"
86,Finding roots of an equation dealing complex numbers,Finding roots of an equation dealing complex numbers,,"For the equation $z^6  + 6z + 20 = 0,$ z is a complex number Putting z=x+iy is tiresome . Moreover my question demands to find the roots lying in each quadrant . Is there an easy way out? Edit. The actual statement is The number of roots in 1st,2nd,3rd ,4th quadrant are","For the equation z is a complex number Putting z=x+iy is tiresome . Moreover my question demands to find the roots lying in each quadrant . Is there an easy way out? Edit. The actual statement is The number of roots in 1st,2nd,3rd ,4th quadrant are","z^6
 + 6z + 20 = 0,","['complex-analysis', 'complex-numbers', 'contest-math']"
87,Path Independence of Line Integrals,Path Independence of Line Integrals,,"The Cauchy-Goursat theorem states that if a function $f$ is analytic on, and in the interior of, a contour $C$ then: $$\int_{C} f(z) \hspace{1mm} dz = 0.$$ From here, a lot of lecture notes deduce the following. Cor. Suppose $f$ is analytic on some simply connected region $A$ . Then for any two points $a, b \in A$ we have that $$\int_{C} f(z) \hspace{1mm} dz$$ is independent of the contour $C$ in $A$ joining $a$ and $b$ . However, the 'proof' often only shows $$\int_{C_1} f(z) \hspace{1mm} dz = \int_{C_2} f(z) \hspace{1mm} dz.$$ when $C_1$ and $C_2$ are non-intersecting (because then $C := C_1\cup C_2$ is a closed contour). What is the best way to prove independence for all $C_1$ and $C_2$ ? I can 'see' that one can just pick a third contour $C_3$ which doesn't intersect either $C_1$ or $C_2$ , and the proof follows from that. But how can I make the existence of $C_3$ rigorous without 'advanced machinery'?","The Cauchy-Goursat theorem states that if a function is analytic on, and in the interior of, a contour then: From here, a lot of lecture notes deduce the following. Cor. Suppose is analytic on some simply connected region . Then for any two points we have that is independent of the contour in joining and . However, the 'proof' often only shows when and are non-intersecting (because then is a closed contour). What is the best way to prove independence for all and ? I can 'see' that one can just pick a third contour which doesn't intersect either or , and the proof follows from that. But how can I make the existence of rigorous without 'advanced machinery'?","f C \int_{C} f(z) \hspace{1mm} dz = 0. f A a, b \in A \int_{C} f(z) \hspace{1mm} dz C A a b \int_{C_1} f(z) \hspace{1mm} dz = \int_{C_2} f(z) \hspace{1mm} dz. C_1 C_2 C := C_1\cup C_2 C_1 C_2 C_3 C_1 C_2 C_3","['complex-analysis', 'contour-integration']"
88,Moebius transformation in upper half plane model,Moebius transformation in upper half plane model,,"I am studying Hyperbolic Geometry on my own. More especially, I am studying the Moebius transformation of the upper half plane model in hyperbolic geometry. But I got stuck studying it. I am looking for a solution of this problem. The problem is as follows: Find the Moebius transformation  that rotates the hyperbolic plane about $i$ through an angle of $\frac { \pi}{4}$ . Please help me. Thanking in advanced.","I am studying Hyperbolic Geometry on my own. More especially, I am studying the Moebius transformation of the upper half plane model in hyperbolic geometry. But I got stuck studying it. I am looking for a solution of this problem. The problem is as follows: Find the Moebius transformation  that rotates the hyperbolic plane about through an angle of . Please help me. Thanking in advanced.",i \frac { \pi}{4},"['complex-analysis', 'algebraic-topology']"
89,How to determine the residue of an (arithmetic) Dirichlet series,How to determine the residue of an (arithmetic) Dirichlet series,,"Consider a multiplicative function $f(n)$ that we write in the form $f(n) = h(n)n^a$ for a certain $a>0$ and $h(n)$ a multiplicative function such that $h(n) \asymp 1$ (more precisely, we can take $h(p^k) = (1-p^{-2})^3$ for all $k>0$ , even if in fact I am interested in this function with two different values of $h(p)$ and $h(p^2)$ ). I denote the Dirichlet series $D_f(s)$ associated to $f$ . My question is: what is known about the poles and residues of $D_f$ ? I can write what I believe to be true, but maybe extra hypotheses are needed on the function $h(n)$ . At least $D_f$ converges for $\Re(s)>a+1$ by the bound on $f(n)$ . I think it has a pole at $s=a+1$ , and meromorphic continuation up to $\Re(s)>a$ . I am particularly interested in the residue of $D_f(s)$ at $s=a$ . I guess it is $$R := \prod_p \left(1 - \frac 1p \right) \left( 1 + \frac{h(p)}{p} + \frac{h(p^2)}{p^2} + \cdots \right)$$ I would like to know if this is true, even up to adding some hypothesis, and why it is so. I thought of it as follows: we know the asymptotics $$\sum_{n<x} f(n) = \sum_{n<x} h(n)n^a \sim R \frac{x^{a+1}}{a+1}$$ and we know that the Dirichlet series is related by Mellin transform to this partial sum, more precisely $$D_f(s) = s \int_1^\infty x^{-s-1} \left(\sum_{n<x} f(n) \right) dx \sim \frac{Rs}{a+1} \int_1^\infty x^{a - s} dx \sim \frac{Rs}{(a+1)(a + 1 - s)} $$ Here the residue at $s=a+1$ is obviously $R$ , but of course I cannot substitute that roughly the equivalent.","Consider a multiplicative function that we write in the form for a certain and a multiplicative function such that (more precisely, we can take for all , even if in fact I am interested in this function with two different values of and ). I denote the Dirichlet series associated to . My question is: what is known about the poles and residues of ? I can write what I believe to be true, but maybe extra hypotheses are needed on the function . At least converges for by the bound on . I think it has a pole at , and meromorphic continuation up to . I am particularly interested in the residue of at . I guess it is I would like to know if this is true, even up to adding some hypothesis, and why it is so. I thought of it as follows: we know the asymptotics and we know that the Dirichlet series is related by Mellin transform to this partial sum, more precisely Here the residue at is obviously , but of course I cannot substitute that roughly the equivalent.",f(n) f(n) = h(n)n^a a>0 h(n) h(n) \asymp 1 h(p^k) = (1-p^{-2})^3 k>0 h(p) h(p^2) D_f(s) f D_f h(n) D_f \Re(s)>a+1 f(n) s=a+1 \Re(s)>a D_f(s) s=a R := \prod_p \left(1 - \frac 1p \right) \left( 1 + \frac{h(p)}{p} + \frac{h(p^2)}{p^2} + \cdots \right) \sum_{n<x} f(n) = \sum_{n<x} h(n)n^a \sim R \frac{x^{a+1}}{a+1} D_f(s) = s \int_1^\infty x^{-s-1} \left(\sum_{n<x} f(n) \right) dx \sim \frac{Rs}{a+1} \int_1^\infty x^{a - s} dx \sim \frac{Rs}{(a+1)(a + 1 - s)}  s=a+1 R,"['complex-analysis', 'number-theory', 'arithmetic', 'analytic-number-theory', 'dirichlet-series']"
90,Computing the Hardy-Ramanujan asymptotic formula using method of steepest descent/saddle point method,Computing the Hardy-Ramanujan asymptotic formula using method of steepest descent/saddle point method,,"I am trying to obtain and prove the Hardy-Ramanujan asymptotic approximation formula given by: $$p(n) \sim \frac{1}{4n\sqrt{3}}e^{\pi\sqrt{\frac{2n}{3}}},$$ by using Dedekind's eta function $$\eta(z)=e^{\frac{i\pi z}{12}}\prod_{n=1}^{\infty}(1-e^{2\pi inz})=\prod_{n=1}^{\infty}\frac{1}{1-z^{n}}$$ and the method of steepest descent (or saddle point method). I am stuck on formulating the integral to which this method can be applied. I understand that we can use the generating function: $$f(z)=1+\sum_{n=1}^{\infty}p(n)z^{n}$$ to represent $p(n)$ as the integral $$p(n)=\frac{1}{2\pi i}\int_{C}\frac{f(z)}{z^{n+1}} \, dz$$ around a closed path $C$ entirely within the unit circle enclosing the origin. Using Dedekind's eta function gives me that $$f(z)=e^{\frac{i\pi z}{12}}(\eta(z))^{-1}.$$ Since $\eta(-\frac{1}{z})=\sqrt{\frac{z}{i}}\eta(z)$ I have that $$f(z)=\sqrt{\frac{z}{i}}e^{\frac{i\pi}{12z}}e^{\frac{i\pi z}{12}}f\left(-\frac{1}{z}\right).$$ However, if $z$ is restricted appropriately and $z \to 0$ , then $\Im(-\frac{1}{z}) \to \infty$ implies that $f(-\frac{1}{z}) \to 1$ since $f(z)=1+\mathcal{O}(e^{-2\pi y})$ , where $z=x+iy$ , $y \geq 1$ . So now the integral I am interested in is $$p_{1}(n)=\int_{\gamma}\sqrt{\frac{z}{i}}e^{\frac{i\pi}{12z}}e^{\frac{i\pi z}{12}}e^{-2\pi inz} \, dz.$$ Is this the correct integral to consider? How do I now apply the method of steepest descent/saddle point method to obtain the Hardy-Ramanujan asymptotic approximation formula?","I am trying to obtain and prove the Hardy-Ramanujan asymptotic approximation formula given by: by using Dedekind's eta function and the method of steepest descent (or saddle point method). I am stuck on formulating the integral to which this method can be applied. I understand that we can use the generating function: to represent as the integral around a closed path entirely within the unit circle enclosing the origin. Using Dedekind's eta function gives me that Since I have that However, if is restricted appropriately and , then implies that since , where , . So now the integral I am interested in is Is this the correct integral to consider? How do I now apply the method of steepest descent/saddle point method to obtain the Hardy-Ramanujan asymptotic approximation formula?","p(n) \sim \frac{1}{4n\sqrt{3}}e^{\pi\sqrt{\frac{2n}{3}}}, \eta(z)=e^{\frac{i\pi z}{12}}\prod_{n=1}^{\infty}(1-e^{2\pi inz})=\prod_{n=1}^{\infty}\frac{1}{1-z^{n}} f(z)=1+\sum_{n=1}^{\infty}p(n)z^{n} p(n) p(n)=\frac{1}{2\pi i}\int_{C}\frac{f(z)}{z^{n+1}} \, dz C f(z)=e^{\frac{i\pi z}{12}}(\eta(z))^{-1}. \eta(-\frac{1}{z})=\sqrt{\frac{z}{i}}\eta(z) f(z)=\sqrt{\frac{z}{i}}e^{\frac{i\pi}{12z}}e^{\frac{i\pi z}{12}}f\left(-\frac{1}{z}\right). z z \to 0 \Im(-\frac{1}{z}) \to \infty f(-\frac{1}{z}) \to 1 f(z)=1+\mathcal{O}(e^{-2\pi y}) z=x+iy y \geq 1 p_{1}(n)=\int_{\gamma}\sqrt{\frac{z}{i}}e^{\frac{i\pi}{12z}}e^{\frac{i\pi z}{12}}e^{-2\pi inz} \, dz.","['combinatorics', 'complex-analysis', 'number-theory', 'integer-partitions', 'laplace-method']"
91,Why is this a proof for Brouwer's fixed point theorem,Why is this a proof for Brouwer's fixed point theorem,,"our teacher said that we can prove the Brouwer's fixed point theorem using the index $n(f\circ \gamma_r,0)$ where $\gamma_r (t)=re ^{it}$ , but I don't understand how come any help would be a lot appreciated.Here's what he's done Let $D$ the closed unit disk. $f : D\rightarrow D$ a continuous function. $f$ has a fixed point in $D$ . So we have : $n(f\circ \gamma_0,0) = 0 $ if $f$ has no fixed point in $D$ , we can show that : The image of $\partial D$ by $1+\frac{f}{g}$ is in the open half plane { $z=x+iy|x>0$ }, where $g:D\rightarrow D$ s.t $z \mapsto -z.\;\;$ (1) We can conclude that : $n(f\circ \gamma_1,0) = n(g \circ \gamma_1,0) = 1.\;\;$ (2) Hence we have a contradiction. I don't see exactly why (1) & (2) are true and what gives us the contradiction.Thanks in advance for your help.","our teacher said that we can prove the Brouwer's fixed point theorem using the index where , but I don't understand how come any help would be a lot appreciated.Here's what he's done Let the closed unit disk. a continuous function. has a fixed point in . So we have : if has no fixed point in , we can show that : The image of by is in the open half plane { }, where s.t (1) We can conclude that : (2) Hence we have a contradiction. I don't see exactly why (1) & (2) are true and what gives us the contradiction.Thanks in advance for your help.","n(f\circ \gamma_r,0) \gamma_r (t)=re ^{it} D f : D\rightarrow D f D n(f\circ \gamma_0,0) = 0  f D \partial D 1+\frac{f}{g} z=x+iy|x>0 g:D\rightarrow D z \mapsto -z.\;\; n(f\circ \gamma_1,0) = n(g \circ \gamma_1,0) = 1.\;\;",['complex-analysis']
92,"Proof: If convergence of Dirichlet series in one point, then uniform convergent in a sector","Proof: If convergence of Dirichlet series in one point, then uniform convergent in a sector",,"I'm currently reading the proof the theorem: if a Dirichlet serie converges at some point, $s_0$ , then the serie is uniformly convergent in a sector around that point. (Montgomery and Vaughan: Multiplicative Number Theory I, Thr 1.1). But there are small things I don't understand. So, first we define $R(u)=\sum_{n>u}a_n n^{-s_0}$ to be the remainter term of a Dirichlet serie. We note that $a_n=(R(n-1)-R(n))n^{s_0}$ . Then the proof say: ""so by partial summation: \begin{align} \sum^{N}_{n=M+1}a_nn^{-s}&=\sum^{N}_{n=M+1}(R(n-1)-R(n))n^{s_0-s}\\ &=R(M)M^{s_0s}-R(N)N^{s_0-s}-\sum^{N}_{n=M+1}R(n-1)((n-1)^{s_0-s}-n^{s_0-s})"" \end{align} Maybe someone can explain why the last equal-sign holds. The next question is how I can justify this bound: $$\int^{\infty}_{M} u^{\sigma_0 - \sigma -1} \,du \leq \frac{1}{\sigma - \sigma_0}$$ when $|R(u)|\leq\epsilon$ for all $u\geq M$ and if $\sigma>\sigma_0$ ?","I'm currently reading the proof the theorem: if a Dirichlet serie converges at some point, , then the serie is uniformly convergent in a sector around that point. (Montgomery and Vaughan: Multiplicative Number Theory I, Thr 1.1). But there are small things I don't understand. So, first we define to be the remainter term of a Dirichlet serie. We note that . Then the proof say: ""so by partial summation: Maybe someone can explain why the last equal-sign holds. The next question is how I can justify this bound: when for all and if ?","s_0 R(u)=\sum_{n>u}a_n n^{-s_0} a_n=(R(n-1)-R(n))n^{s_0} \begin{align}
\sum^{N}_{n=M+1}a_nn^{-s}&=\sum^{N}_{n=M+1}(R(n-1)-R(n))n^{s_0-s}\\
&=R(M)M^{s_0s}-R(N)N^{s_0-s}-\sum^{N}_{n=M+1}R(n-1)((n-1)^{s_0-s}-n^{s_0-s})""
\end{align} \int^{\infty}_{M} u^{\sigma_0 - \sigma -1} \,du \leq \frac{1}{\sigma - \sigma_0} |R(u)|\leq\epsilon u\geq M \sigma>\sigma_0","['complex-analysis', 'number-theory', 'analytic-number-theory', 'dirichlet-series']"
93,solve for the Laurent series of the function $f(z) = \frac{z-12}{z^2+z-6}$ that is valid for $1<|z-1|<4$.,solve for the Laurent series of the function  that is valid for .,f(z) = \frac{z-12}{z^2+z-6} 1<|z-1|<4,"I am about to solve for the Laurent series of the function $f(z) = \frac{z-12}{z^2+z-6}$ that is valid for $1<|z-1|<4$ . What I did is I use the partial fraction decomposition to rewrite the $f(z)$ into $f(z) = \frac{3}{z+3}+\frac{2}{z-2}$ .  Now based on the region to where the function $f$ should be valid on is that $1< |z-1|< 4$ , I'm not sure if I did it right when I assumed that $\left|\frac{2}{z}\right|<1$ and $\left|\frac{3}{z}\right|<1$ . (I just did it with brute force to arrive on the two inequalities). Can you help me with that? Assuming my two inequalities are correct, I have now $\frac{3}{z+3} = \frac{3/z}{1+3/z} = 3/z \sum_{n=0}^{\infty} \left(- \frac{3}{z}\right)^n = \sum_{n=0}^{\infty} (-1)^{n-1}3^nz^{-n} = \sum_{n=1}^{\infty} (-1)^n3^{n+1}z^{-(n+1)}$ , and $\frac{2}{z-2} = \frac{2/z}{1-2/z} = 2/z \sum_{n=0}^{\infty}  \left(\frac{2}{z}\right)^n = \sum_{n=0}^{\infty} \frac{2^{n+1}}{z^{n+1}}.$ Then after that, I combined which I have the result as $f(z) = \frac{z-12}{z^2+z-6} = \sum_{n=0}^{\infty} \frac{2^{n+1}}{z^{n+1}} + \sum_{n=1}^{\infty} (-1)^n(3)^{n+1}z^{-(n+1)}$ . Now, did I do it correctly? or I did wrong on the inequalities of the region to where the laurent should be valud to?  Thanks for those who can help.","I am about to solve for the Laurent series of the function that is valid for . What I did is I use the partial fraction decomposition to rewrite the into .  Now based on the region to where the function should be valid on is that , I'm not sure if I did it right when I assumed that and . (I just did it with brute force to arrive on the two inequalities). Can you help me with that? Assuming my two inequalities are correct, I have now , and Then after that, I combined which I have the result as . Now, did I do it correctly? or I did wrong on the inequalities of the region to where the laurent should be valud to?  Thanks for those who can help.",f(z) = \frac{z-12}{z^2+z-6} 1<|z-1|<4 f(z) f(z) = \frac{3}{z+3}+\frac{2}{z-2} f 1< |z-1|< 4 \left|\frac{2}{z}\right|<1 \left|\frac{3}{z}\right|<1 \frac{3}{z+3} = \frac{3/z}{1+3/z} = 3/z \sum_{n=0}^{\infty} \left(- \frac{3}{z}\right)^n = \sum_{n=0}^{\infty} (-1)^{n-1}3^nz^{-n} = \sum_{n=1}^{\infty} (-1)^n3^{n+1}z^{-(n+1)} \frac{2}{z-2} = \frac{2/z}{1-2/z} = 2/z \sum_{n=0}^{\infty}  \left(\frac{2}{z}\right)^n = \sum_{n=0}^{\infty} \frac{2^{n+1}}{z^{n+1}}. f(z) = \frac{z-12}{z^2+z-6} = \sum_{n=0}^{\infty} \frac{2^{n+1}}{z^{n+1}} + \sum_{n=1}^{\infty} (-1)^n(3)^{n+1}z^{-(n+1)},"['complex-analysis', 'analysis', 'laurent-series']"
94,Examples of irreducible holomorphic function in more than one variable.,Examples of irreducible holomorphic function in more than one variable.,,I'm studying analysis in several complex variables and in particular Weierstrass preparation theorem caught my interest (I'll include the theorem for clarity). In the examples I came up with I only found functions that could be written as the product of an unit and linear Weierstrass polynomials. It's never implied that every Weierstrass irreducible polynomial is of degree 1 or that in general irreducible functions are the degree 1 polynomial so I was looking for some examples of holomoprhic functions that are irreducible (at the origin) but are not polynomials of degree 1.,I'm studying analysis in several complex variables and in particular Weierstrass preparation theorem caught my interest (I'll include the theorem for clarity). In the examples I came up with I only found functions that could be written as the product of an unit and linear Weierstrass polynomials. It's never implied that every Weierstrass irreducible polynomial is of degree 1 or that in general irreducible functions are the degree 1 polynomial so I was looking for some examples of holomoprhic functions that are irreducible (at the origin) but are not polynomials of degree 1.,,"['complex-analysis', 'several-complex-variables']"
95,Find the product of all values of $(1+i\sqrt 3)^{\frac{3}{4}}$.,Find the product of all values of .,(1+i\sqrt 3)^{\frac{3}{4}},Find the product of all values of $(1+i\sqrt 3)^{\frac{3}{4}}$ . My try: $(1+i\sqrt 3)^{\frac{3}{4}}=\exp (\frac{3}{4}(Log(1+i\sqrt 3)))=\exp(\frac{3}{4}(\log2+i\frac{\pi}{3}+2n\pi i))$ . I am kinda stuck on how to find the product of all values of  the above expression. Can someone please help me out.,Find the product of all values of . My try: . I am kinda stuck on how to find the product of all values of  the above expression. Can someone please help me out.,(1+i\sqrt 3)^{\frac{3}{4}} (1+i\sqrt 3)^{\frac{3}{4}}=\exp (\frac{3}{4}(Log(1+i\sqrt 3)))=\exp(\frac{3}{4}(\log2+i\frac{\pi}{3}+2n\pi i)),"['complex-analysis', 'discrete-mathematics', 'logarithms']"
96,What do we mean visually by complex eigen values of a matrix? Intuition behind the rotation of space using a 2x2 matrix and eigen values?,What do we mean visually by complex eigen values of a matrix? Intuition behind the rotation of space using a 2x2 matrix and eigen values?,,"The rotation matrix on $\Bbb R^2$ , the Euclidean plane given by $$\begin{bmatrix}0&-1\\1&0\end{bmatrix}$$ has two imaginary eigen values $i$ and $-i$ . The definition of eigen vectors are those vectors $x$ that are parallel to $x$ [i.e. $Ax= \lambda x$ ]. Here the definition says $Ax=ix$ or $Ax=-ix$ , since multiplying by $ i $ rotates my space by ninety degrees , does that essentially mean that we see two vectors in complex planes that are perpendicular to each other as being parallel to each other at the same time. What intuition am I missing here?","The rotation matrix on , the Euclidean plane given by has two imaginary eigen values and . The definition of eigen vectors are those vectors that are parallel to [i.e. ]. Here the definition says or , since multiplying by rotates my space by ninety degrees , does that essentially mean that we see two vectors in complex planes that are perpendicular to each other as being parallel to each other at the same time. What intuition am I missing here?",\Bbb R^2 \begin{bmatrix}0&-1\\1&0\end{bmatrix} i -i x x Ax= \lambda x Ax=ix Ax=-ix  i ,"['linear-algebra', 'matrices', 'complex-analysis', 'eigenvalues-eigenvectors', 'linear-transformations']"
97,Biharmonic version of Poisson Integral,Biharmonic version of Poisson Integral,,"Background The Poisson Integral $$ \tilde h(r e^{i \theta}) = \frac{1}{2 \pi}\int_{-\pi}^\pi h(e^{i \phi}) P_r(\theta - \phi) d\phi$$ takes an arbitrary continuous complex-valued function $h(e^{i \theta})$ defined on the unit circle and extends it to a function $\tilde h(z)$ defined inside the unit disk such that $\tilde h(z)$ is harmonic ( $\Delta \tilde h(z) = 0$ ) and has boundary values $h(z)$ on the unit circle. $P_r(\theta)$ is the so-called Poisson Kernel and, among other representations, $$P_r(\theta) = \Re \left( \frac{1 + r e^{i \theta}} {1 - r e^{i \theta}} \right) , \ \ \ \ r e^{i \theta} \in \mathbb{D}.$$ Question Is there a different kernel function I could use which would make $\tilde h(z)$ biharmonic instead of just harmonic inside the unit disk?  That is, I'd like to find something to replace $P_r(\theta)$ with so that $\Delta^2 \tilde h(z) = 0$ .","Background The Poisson Integral takes an arbitrary continuous complex-valued function defined on the unit circle and extends it to a function defined inside the unit disk such that is harmonic ( ) and has boundary values on the unit circle. is the so-called Poisson Kernel and, among other representations, Question Is there a different kernel function I could use which would make biharmonic instead of just harmonic inside the unit disk?  That is, I'd like to find something to replace with so that ."," \tilde h(r e^{i \theta}) = \frac{1}{2 \pi}\int_{-\pi}^\pi h(e^{i \phi}) P_r(\theta - \phi) d\phi h(e^{i \theta}) \tilde h(z) \tilde h(z) \Delta \tilde h(z) = 0 h(z) P_r(\theta) P_r(\theta) = \Re \left( \frac{1 + r e^{i \theta}} {1 - r e^{i \theta}} \right) , \ \ \ \ r e^{i \theta} \in \mathbb{D}. \tilde h(z) P_r(\theta) \Delta^2 \tilde h(z) = 0","['integration', 'complex-analysis', 'harmonic-functions']"
98,Convergence of integral using Cauchy's theorem,Convergence of integral using Cauchy's theorem,,"I've always thought that integrals of the form $\int_0^{x_0}  \frac{dx}{x^d}$ for $d\geq1$ don't converge. However, during a calculation, an integral of this kind (with $d=2$ ) appeared and I really needed to evaluate it in some way. Here's what I thought: given that, for $d=2$ , the integral is even, we can write it like (also adding a convergence factor) $$ \int_0^{x_0} \frac{dx}{x^2} = \frac{1}{2} \lim_{\delta \rightarrow 0} \int_{-x_0}^{x_0}\frac{dx}{(x-i\delta)^2}$$ Now, let $x\in \mathbb{C}$ and use Cauchy's theorem for the pole located at $x=i\delta$ $$ \int_{-x_0}^{x_0}\frac{dx}{(x-i\delta)^2} = 2\pi i Res\big[(x-i\delta)^{-2},x=i\delta\big] - \int_{\Gamma} \frac{dx}{(x-i\delta)^2} $$ where the contour is $\Gamma = \{x_0e^{i\theta}, \theta \in [0,\pi] \} $ In fact, the residue evaluates to zero. For the integral that is missing, let me perform the change of variables $x=x_0e^{i\theta}$ and $dx= ix_0e^{i\theta} d\theta$ , such that $$\int_{\Gamma} \frac{dx}{(x-i\delta)^2} = ix_0 \int_0^\pi d\theta \  \frac{e^{i\theta}}{x_0^2e^{2i\theta} - 2i\delta x_0e^{i\theta} - \delta^2} = ix_0 \int_0^\pi d\theta \  \frac{1}{x_0^2e^{i\theta} - 2i\delta x_0- \delta^2e^{-i\theta}}$$ A primitive for the last integrand is $$\frac{i}{e^{i\theta}x_0^2-i\delta x_0}$$ which implies $$\int_{\Gamma} \frac{dx}{(x-i\delta)^2}  = \frac{2x_0}{x_0^2+\delta^2}$$ Therefore, plugging all these results together seems to imply that $$ \int_0^{x_0} \frac{dx}{x^2}  = - \frac{1}{x_0}$$ Can anyone please tell me what did I do wrong? Because I'm pretty sure this should diverge, but I can't find the wrong step here.","I've always thought that integrals of the form for don't converge. However, during a calculation, an integral of this kind (with ) appeared and I really needed to evaluate it in some way. Here's what I thought: given that, for , the integral is even, we can write it like (also adding a convergence factor) Now, let and use Cauchy's theorem for the pole located at where the contour is In fact, the residue evaluates to zero. For the integral that is missing, let me perform the change of variables and , such that A primitive for the last integrand is which implies Therefore, plugging all these results together seems to imply that Can anyone please tell me what did I do wrong? Because I'm pretty sure this should diverge, but I can't find the wrong step here.","\int_0^{x_0}  \frac{dx}{x^d} d\geq1 d=2 d=2  \int_0^{x_0} \frac{dx}{x^2} = \frac{1}{2} \lim_{\delta \rightarrow 0} \int_{-x_0}^{x_0}\frac{dx}{(x-i\delta)^2} x\in \mathbb{C} x=i\delta  \int_{-x_0}^{x_0}\frac{dx}{(x-i\delta)^2} = 2\pi i Res\big[(x-i\delta)^{-2},x=i\delta\big] - \int_{\Gamma} \frac{dx}{(x-i\delta)^2}  \Gamma = \{x_0e^{i\theta}, \theta \in [0,\pi] \}  x=x_0e^{i\theta} dx= ix_0e^{i\theta} d\theta \int_{\Gamma} \frac{dx}{(x-i\delta)^2} = ix_0 \int_0^\pi d\theta \  \frac{e^{i\theta}}{x_0^2e^{2i\theta} - 2i\delta x_0e^{i\theta} - \delta^2} = ix_0 \int_0^\pi d\theta \  \frac{1}{x_0^2e^{i\theta} - 2i\delta x_0- \delta^2e^{-i\theta}} \frac{i}{e^{i\theta}x_0^2-i\delta x_0} \int_{\Gamma} \frac{dx}{(x-i\delta)^2}  = \frac{2x_0}{x_0^2+\delta^2}  \int_0^{x_0} \frac{dx}{x^2}  = - \frac{1}{x_0}","['calculus', 'integration', 'complex-analysis', 'convergence-divergence']"
99,If |a|> |a+b+c| prove that there is complex root such that |z|< 2,If |a|> |a+b+c| prove that there is complex root such that |z|< 2,,"Let $a x^2 + b x +c =0$ be a quadratic equation where $|a|> |a+b+c| $ , $a,b,c \in  \mathbb{R}$ . Prove that this equation has at least one solution $ z \in \mathbb{C}$ such that $|z| < 2$ . I don't know how to prove this, I noticed that $|a+b+c | = |f(1)|$ , so $|a|> |f(1)|$ , but I'm not sure if it helps. Also, $|z|= \frac{b^2}{4a^2} + \frac{ 4ac - b^2}{4 a^2}  <4\implies a c <4 a^2  $ . Can anyone help? I would be greatly thankful.","Let be a quadratic equation where , . Prove that this equation has at least one solution such that . I don't know how to prove this, I noticed that , so , but I'm not sure if it helps. Also, . Can anyone help? I would be greatly thankful.","a x^2 + b x +c =0 |a|> |a+b+c|  a,b,c \in  \mathbb{R}  z \in \mathbb{C} |z| < 2 |a+b+c | = |f(1)| |a|> |f(1)| |z|= \frac{b^2}{4a^2} + \frac{ 4ac - b^2}{4 a^2}  <4\implies a c <4 a^2  ","['complex-analysis', 'quadratics']"
