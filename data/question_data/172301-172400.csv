,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Proof of Simpson's Paradox,Proof of Simpson's Paradox,,"I am studying Implicit Function Theorem and its application in Simpson's Paradox. I got the following problem. I tried it myself, but not sure if my answer is correct. I would really appreciate it if someone could help me check! Problem: A company tests a new medicine in city $C$ and $C'$ . In each city, the tests are conducted in two labs, $U$ and $U'$ . In each lab, there is a test group ( $T$ ) receiving the new medicine and a control group ( $T'$ ) receiving old medicine. Some people became health ( $H$ ), the other did not ( $H'$ ). The new medicine is judged to be better if a higher percentage of people who took the new medicine becomes health than those who took the old one. There exist samples in which the new medicine is better than the old at each of the four labs and in the aggregate in each city, but worse when aggregated over the whole test population. In other samples, the conclusions oscillate with the level: the new medicine is worse than the old at each of the four facilities, is better in each city, but is worse when aggregated over the whole population, and so forth. Present an analytical proof (not using counterexamples) that each of the above scenario is possible using the Implicit Function Theorem. My attempt: Define the following mutually exclusive groups: \begin{equation} S_1 = TCU,\space\space\space\space S_2 = TCU',\space\space\space\space S_3 = TC'U,\space\space\space\space S_4 = TC'U' \\ S_5 = T'CU, \space\space S_6 = T'CU',\space\space S_7 = T'C'U,\space\space S_8 = T'C'U'. \end{equation} Let $x_i = Pr\{H|S_i\}$ and $d_i = Pr\{S_i\}$ for $I = 1, \dots, 8$ . Let \begin{equation} y_1 = Pr\{H|TC\},\space y_2 = Pr\{H|TC'\},\space y_3 = Pr\{H|T'C\},\space y_4 = Pr\{H|T'C'\}, \end{equation} aggregating over the type of test lab. Let \begin{equation} z_1 = Pr\{H|T\}\space\space\space\space and\space\space\space\space z_2 = Pr\{H|T'\}, \end{equation} the overall aggregate variables. We first show that \begin{equation} y_i = \frac{x_{2j - 1}d_{2j - 1} + x_{2j}d_{2j}}{d_{2j-1} + d_{2j}}. \end{equation} Consider the case when $j = 1$ , then we want to show \begin{equation} Pr\{H|TC\} = \frac{Pr\{H|TCU\}Pr\{TCU\} + Pr\{H|TCU'\}Pr\{TCU'\}}{Pr\{TCU\} + Pr\{TCU'\}}. \end{equation} By Kolmogorov definition and axiom of conditional probability, we have \begin{equation} Pr\{H|TC\} = \frac{Pr\{H \cap TC\}}{Pr\{TC\}} = \frac{Pr\{H \cap TCU\} + Pr\{H \cap TCU'\}}{Pr\{TC\}} = \frac{Pr\{H|TCU\}Pr\{TCU\} + Pr\{H|TCU'\}Pr\{TCU'\}}{Pr\{TC\}}. \end{equation} But $Pr\{TC\} = Pr\{TCU\} + Pr\{TCU'\} - Pr\{TCU \cap TCU'\} = Pr\{TCU\} + Pr\{TCU'\}$ because $TCU \cap TCU' = \emptyset$ . We proved that $y_1 = \frac{x_{1}d_{1} + x_{2}d_{2}}{d_{1} + d_{2}}$ . Similarly, we are able to prove that $y_i = \frac{x_{2j - 1}d_{2j - 1} + x_{2j}d_{2j}}{d_{2j-1} + d_{2j}}$ for all $j = 1, 2, 3, 4$ . By an analogous argument, we are able to prove that \begin{equation} z_1 = \frac{\sum_{j = 1}^{4}x_jd_j}{\sum_{j = 1}^{4}d_j}\space\space\space\space and\space\space\space\space z_2 = \frac{\sum_{j = 5}^{8}x_jd_j}{\sum_{j = 5}^{8}d_j}. \end{equation} Now, consider the map $F:[0, 1]^8 \times \Sigma(8) \to \mathbb{R}^7$ defined by \begin{equation} F(x_1, \dots, x_8, d_1, \dots, d_8) = (x_1 - x_5, x_2 - x_6, x_3 - x_7, x_4 - x_8, y_1 - y_3, y_2 - y_4, z_1 - z_2), \end{equation} where $\Sigma(8) = \{(d_1, \dots, d_8) | d_i \geq 0, \sum_{i}d_i = 1, i = 1, \dots, 8\}$ . Write $d_8 = 1 - \sum_{i = 1}^{7}d_i$ , then we have \begin{equation} F(x_1, \dots, x_8, d_1, \dots, d_7) = (x_1 - x_5, x_2 - x_6, x_3 - x_7, x_4 - x_8, \frac{x_1d_1 + x_2d_2}{d_1 + d_2} - \frac{x_5d_5 + x_6d_6}{d_5 + d_6}, \frac{x_3d_3 + x_4d_4}{d_3 + d_4} - \frac{x_7d_7 + x_8(1 - \sum_{i = i}^{7}d_i)}{d_7 + (1 - \sum_{i = 1}^{7}d_i)}, \frac{\sum_{i = 1}^{4}x_id_i}{\sum_{i = 1}^{4}d_i} - \frac{\sum_{i = 5}^{7}x_id_i + x_8(1 - \sum_{i = 1}^{7}d_i)}{1 - \sum_{1 = 1}^{4}d_i}). \end{equation} Calculate the Jacobian DF: \begin{pmatrix} 1 & 0 & 0 & 0 & -1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\ 0 & 1 & 0 & 0 & 0 & -1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\ 0 & 0 & 1 & 0 & 0 & 0 & -1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\ 0 & 0 & 0 & 1 & 0 & 0 & 0 & -1 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\ \frac{d_1}{d_1 + d_2} & \frac{d_2}{d_1 + d_2} & 0 & 0 & -\frac{d_5}{d_5 + d_6} & -\frac{d_6}{d_5 + d_6} & 0 & 0 & \frac{(x_1 - x_2)d_2}{(d_1 + d_2)^2} & \frac{(x_2 - x_1)d_1}{(d_1 + d_2)^2} & 0 & 0 & \frac{(-x_5 + x_6)d_6}{(d_5 + d_6)^2} & \frac{(x_5 - x_6)d_5}{(d_5 + d_6)^2} & 0\\ 0 & 0 & \frac{d_3}{d_3 + d_4} & \frac{d_4}{d_3 + d_4} & 0 & 0 & -\frac{d_7}{1 - \sum_{i = 1}^{6}d_i} & -\frac{1 - \sum_{i = 1}^{7}d_i}{1 - \sum_{i = 1}^{6}d_i} & 0 & 0 & \frac{(x_3 - x_4)d_4}{(d_3 + d_4)^2} - \frac{(x_7 - x_8)d_7}{(1 - \sum_{i = 1}^{6}di)^2} & \frac{(x_4 - x_3)d_3}{(d_3 + d_4)^2} - \frac{(x_7 - x_8)d_7}{(1 - \sum_{i = 1}^{6}di)^2} & -\frac{(x_7 - x_8)d_7}{(1 - \sum_{i = 1}^{6}di)^2} & -\frac{(x_7 - x_8)d_7}{(1 - \sum_{i = 1}^{6}di)^2} & -\frac{x_7 - x_8}{1 - \sum_{i = 1}^{6}d_i}\\ \frac{d_1}{\sum_{i = 1}^{4}d_i} & \frac{d_2}{\sum_{i = 1}^{4}d_i} & \frac{d_3}{\sum_{i = 1}^{4}d_i} & \frac{d_4}{\sum_{i = 1}^{4}d_i} & -\frac{d_5}{1 - \sum_{i = 1}^{4}d_i} & -\frac{d_6}{1 - \sum_{i = 1}^{4}d_i} & -\frac{d_7}{1 - \sum_{i = 1}^{4}d_i} & \frac{1 - \sum_{i = 1}^{7}d_i}{1 - \sum_{i = 1}^{4}d_i} & \frac{x_1\sum_{i = 1}^{4}d_i - \sum_{i = 1}^{4}x_id_i}{(\sum_{i = 1}^{4}d_i)^2} - \frac{-x_8(1 - \sum_{i = 1}^{4}d_i) + (\sum_{i = 5}^{7}x_id_i + x_8 - x_8\sum_{i = 1}^{7}d_i)}{(1 - \sum_{i = 1}^{4}d_i)^2} & \frac{x_2\sum_{i = 1}^{4}d_i - \sum_{i = 1}^{4}x_id_i}{(\sum_{i = 1}^{4}d_i)^2} - \frac{-x_8(1 - \sum_{i = 1}^{4}d_i) + (\sum_{i = 5}^{7}x_id_i + x_8 - x_8\sum_{i = 1}^{7}d_i)}{(1 - \sum_{i = 1}^{4}d_i)^2} & \frac{x_3\sum_{i = 1}^{4}d_i - \sum_{i = 1}^{4}x_id_i}{(\sum_{i = 1}^{4}d_i)^2} - \frac{-x_8(1 - \sum_{i = 1}^{4}d_i) + (\sum_{i = 5}^{7}x_id_i + x_8 - x_8\sum_{i = 1}^{7}d_i)}{(1 - \sum_{i = 1}^{4}d_i)^2} & \frac{x_4\sum_{i = 1}^{4}d_i - \sum_{i = 1}^{4}x_id_i}{(\sum_{i = 1}^{4}d_i)^2} - \frac{-x_8(1 - \sum_{i = 1}^{4}d_i) + (\sum_{i = 5}^{7}x_id_i + x_8 - x_8\sum_{i = 1}^{7}d_i)}{(1 - \sum_{i = 1}^{4}d_i)^2} & -\frac{x_5 - x_8}{1 - \sum_{i = 1}^{4}d_i} & -\frac{x_6 - x_8}{1 - \sum_{i = 1}^{4}d_i} & -\frac{x_7 - x_8}{1 - \sum_{i = 1}^{4}d_i} \end{pmatrix} If we take $x_1 = x_5 \neq x_2 = x_6 \neq x_3 = x_7 \neq x_4 = x_8$ , DF has rank 7. Let $(\mathbf{x^*}, \mathbf{d^*})$ be a point with the properties \begin{equation} x_1 = x_5 \neq x_2 = x_6 \neq x_3 = x_7 \neq x_4 = x_8 \\ d_1 = \dots = d_8 = \frac{1}{8}. \end{equation} Then, $F(\mathbf{x^*}, \mathbf{d^*}) = 0$ and $DF(\mathbf{x^*}, \mathbf{d^*})$ has maximal rank. By Implicit Function Theorem, $F$ is locally onto a neighborhood of $\mathbf{0}$ . In other words, if we choose any sign pattern $(\varepsilon_1, \dots, \varepsilon_7)$ , where each $\varepsilon_i = \pm 1$ , in the target space $\mathbb{R}^7$ and a point $\mathbf{z} = (z_1, \dots, z_7)$ near $\mathbf{0}$ that realizes this sign pattern, then there exists a point $\mathbf{x'}, \mathbf{d'}$ in $[0, 1]^8 \times \Sigma(8)$ , such that $F(\mathbf{x'}, \mathbf{d'}) = \mathbf{z}$ . The point $(\mathbf{x'}, \mathbf{d'})$ corresponds to a partitioning of the test population into $S_1, \dots, S_8$ so that the 7-tuple \begin{equation} Pr\{H|TCU\} - Pr\{H|T'CU\}, Pr\{H|TCU'\} - Pr\{H|T'CU""\}, \\ Pr\{H|TC'U\} - Pr\{H|T'C'U\}, Pr\{H|TC'U'\} - Pr\{H|T'C'U'\}, \\ Pr\{H|TC\} - Pr\{H|T'C\}, Pr\{H|TC'\} - Pr\{H|T'C'\}, \\ Pr\{H|T\} - Pr\{H|T'\},\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space \end{equation} has the preassigned sign pattern $(\varepsilon_1, \dots, \varepsilon_7)$ . I am not completely sure about my answer, especially the step where I calculated $y_i$ and $z_i$ as well as the step where I picked an $(\mathbf{x^*}, \mathbf{d^*})$ . Could someone please help me check? Thanks a lot in advance!","I am studying Implicit Function Theorem and its application in Simpson's Paradox. I got the following problem. I tried it myself, but not sure if my answer is correct. I would really appreciate it if someone could help me check! Problem: A company tests a new medicine in city and . In each city, the tests are conducted in two labs, and . In each lab, there is a test group ( ) receiving the new medicine and a control group ( ) receiving old medicine. Some people became health ( ), the other did not ( ). The new medicine is judged to be better if a higher percentage of people who took the new medicine becomes health than those who took the old one. There exist samples in which the new medicine is better than the old at each of the four labs and in the aggregate in each city, but worse when aggregated over the whole test population. In other samples, the conclusions oscillate with the level: the new medicine is worse than the old at each of the four facilities, is better in each city, but is worse when aggregated over the whole population, and so forth. Present an analytical proof (not using counterexamples) that each of the above scenario is possible using the Implicit Function Theorem. My attempt: Define the following mutually exclusive groups: Let and for . Let aggregating over the type of test lab. Let the overall aggregate variables. We first show that Consider the case when , then we want to show By Kolmogorov definition and axiom of conditional probability, we have But because . We proved that . Similarly, we are able to prove that for all . By an analogous argument, we are able to prove that Now, consider the map defined by where . Write , then we have Calculate the Jacobian DF: If we take , DF has rank 7. Let be a point with the properties Then, and has maximal rank. By Implicit Function Theorem, is locally onto a neighborhood of . In other words, if we choose any sign pattern , where each , in the target space and a point near that realizes this sign pattern, then there exists a point in , such that . The point corresponds to a partitioning of the test population into so that the 7-tuple has the preassigned sign pattern . I am not completely sure about my answer, especially the step where I calculated and as well as the step where I picked an . Could someone please help me check? Thanks a lot in advance!","C C' U U' T T' H H' \begin{equation}
S_1 = TCU,\space\space\space\space S_2 = TCU',\space\space\space\space S_3 = TC'U,\space\space\space\space S_4 = TC'U' \\
S_5 = T'CU, \space\space S_6 = T'CU',\space\space S_7 = T'C'U,\space\space S_8 = T'C'U'.
\end{equation} x_i = Pr\{H|S_i\} d_i = Pr\{S_i\} I = 1, \dots, 8 \begin{equation}
y_1 = Pr\{H|TC\},\space y_2 = Pr\{H|TC'\},\space y_3 = Pr\{H|T'C\},\space y_4 = Pr\{H|T'C'\},
\end{equation} \begin{equation}
z_1 = Pr\{H|T\}\space\space\space\space and\space\space\space\space z_2 = Pr\{H|T'\},
\end{equation} \begin{equation}
y_i = \frac{x_{2j - 1}d_{2j - 1} + x_{2j}d_{2j}}{d_{2j-1} + d_{2j}}.
\end{equation} j = 1 \begin{equation}
Pr\{H|TC\} = \frac{Pr\{H|TCU\}Pr\{TCU\} + Pr\{H|TCU'\}Pr\{TCU'\}}{Pr\{TCU\} + Pr\{TCU'\}}.
\end{equation} \begin{equation}
Pr\{H|TC\} = \frac{Pr\{H \cap TC\}}{Pr\{TC\}} = \frac{Pr\{H \cap TCU\} + Pr\{H \cap TCU'\}}{Pr\{TC\}} = \frac{Pr\{H|TCU\}Pr\{TCU\} + Pr\{H|TCU'\}Pr\{TCU'\}}{Pr\{TC\}}.
\end{equation} Pr\{TC\} = Pr\{TCU\} + Pr\{TCU'\} - Pr\{TCU \cap TCU'\} = Pr\{TCU\} + Pr\{TCU'\} TCU \cap TCU' = \emptyset y_1 = \frac{x_{1}d_{1} + x_{2}d_{2}}{d_{1} + d_{2}} y_i = \frac{x_{2j - 1}d_{2j - 1} + x_{2j}d_{2j}}{d_{2j-1} + d_{2j}} j = 1, 2, 3, 4 \begin{equation}
z_1 = \frac{\sum_{j = 1}^{4}x_jd_j}{\sum_{j = 1}^{4}d_j}\space\space\space\space and\space\space\space\space z_2 = \frac{\sum_{j = 5}^{8}x_jd_j}{\sum_{j = 5}^{8}d_j}.
\end{equation} F:[0, 1]^8 \times \Sigma(8) \to \mathbb{R}^7 \begin{equation}
F(x_1, \dots, x_8, d_1, \dots, d_8) = (x_1 - x_5, x_2 - x_6, x_3 - x_7, x_4 - x_8, y_1 - y_3, y_2 - y_4, z_1 - z_2),
\end{equation} \Sigma(8) = \{(d_1, \dots, d_8) | d_i \geq 0, \sum_{i}d_i = 1, i = 1, \dots, 8\} d_8 = 1 - \sum_{i = 1}^{7}d_i \begin{equation}
F(x_1, \dots, x_8, d_1, \dots, d_7) = (x_1 - x_5, x_2 - x_6, x_3 - x_7, x_4 - x_8, \frac{x_1d_1 + x_2d_2}{d_1 + d_2} - \frac{x_5d_5 + x_6d_6}{d_5 + d_6}, \frac{x_3d_3 + x_4d_4}{d_3 + d_4} - \frac{x_7d_7 + x_8(1 - \sum_{i = i}^{7}d_i)}{d_7 + (1 - \sum_{i = 1}^{7}d_i)}, \frac{\sum_{i = 1}^{4}x_id_i}{\sum_{i = 1}^{4}d_i} - \frac{\sum_{i = 5}^{7}x_id_i + x_8(1 - \sum_{i = 1}^{7}d_i)}{1 - \sum_{1 = 1}^{4}d_i}).
\end{equation} \begin{pmatrix}
1 & 0 & 0 & 0 & -1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
0 & 1 & 0 & 0 & 0 & -1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
0 & 0 & 1 & 0 & 0 & 0 & -1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
0 & 0 & 0 & 1 & 0 & 0 & 0 & -1 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
\frac{d_1}{d_1 + d_2} & \frac{d_2}{d_1 + d_2} & 0 & 0 & -\frac{d_5}{d_5 + d_6} & -\frac{d_6}{d_5 + d_6} & 0 & 0 & \frac{(x_1 - x_2)d_2}{(d_1 + d_2)^2} & \frac{(x_2 - x_1)d_1}{(d_1 + d_2)^2} & 0 & 0 & \frac{(-x_5 + x_6)d_6}{(d_5 + d_6)^2} & \frac{(x_5 - x_6)d_5}{(d_5 + d_6)^2} & 0\\
0 & 0 & \frac{d_3}{d_3 + d_4} & \frac{d_4}{d_3 + d_4} & 0 & 0 & -\frac{d_7}{1 - \sum_{i = 1}^{6}d_i} & -\frac{1 - \sum_{i = 1}^{7}d_i}{1 - \sum_{i = 1}^{6}d_i} & 0 & 0 & \frac{(x_3 - x_4)d_4}{(d_3 + d_4)^2} - \frac{(x_7 - x_8)d_7}{(1 - \sum_{i = 1}^{6}di)^2} & \frac{(x_4 - x_3)d_3}{(d_3 + d_4)^2} - \frac{(x_7 - x_8)d_7}{(1 - \sum_{i = 1}^{6}di)^2} & -\frac{(x_7 - x_8)d_7}{(1 - \sum_{i = 1}^{6}di)^2} & -\frac{(x_7 - x_8)d_7}{(1 - \sum_{i = 1}^{6}di)^2} & -\frac{x_7 - x_8}{1 - \sum_{i = 1}^{6}d_i}\\
\frac{d_1}{\sum_{i = 1}^{4}d_i} & \frac{d_2}{\sum_{i = 1}^{4}d_i} & \frac{d_3}{\sum_{i = 1}^{4}d_i} & \frac{d_4}{\sum_{i = 1}^{4}d_i} & -\frac{d_5}{1 - \sum_{i = 1}^{4}d_i} & -\frac{d_6}{1 - \sum_{i = 1}^{4}d_i} & -\frac{d_7}{1 - \sum_{i = 1}^{4}d_i} & \frac{1 - \sum_{i = 1}^{7}d_i}{1 - \sum_{i = 1}^{4}d_i} & \frac{x_1\sum_{i = 1}^{4}d_i - \sum_{i = 1}^{4}x_id_i}{(\sum_{i = 1}^{4}d_i)^2} - \frac{-x_8(1 - \sum_{i = 1}^{4}d_i) + (\sum_{i = 5}^{7}x_id_i + x_8 - x_8\sum_{i = 1}^{7}d_i)}{(1 - \sum_{i = 1}^{4}d_i)^2} & \frac{x_2\sum_{i = 1}^{4}d_i - \sum_{i = 1}^{4}x_id_i}{(\sum_{i = 1}^{4}d_i)^2} - \frac{-x_8(1 - \sum_{i = 1}^{4}d_i) + (\sum_{i = 5}^{7}x_id_i + x_8 - x_8\sum_{i = 1}^{7}d_i)}{(1 - \sum_{i = 1}^{4}d_i)^2} & \frac{x_3\sum_{i = 1}^{4}d_i - \sum_{i = 1}^{4}x_id_i}{(\sum_{i = 1}^{4}d_i)^2} - \frac{-x_8(1 - \sum_{i = 1}^{4}d_i) + (\sum_{i = 5}^{7}x_id_i + x_8 - x_8\sum_{i = 1}^{7}d_i)}{(1 - \sum_{i = 1}^{4}d_i)^2} & \frac{x_4\sum_{i = 1}^{4}d_i - \sum_{i = 1}^{4}x_id_i}{(\sum_{i = 1}^{4}d_i)^2} - \frac{-x_8(1 - \sum_{i = 1}^{4}d_i) + (\sum_{i = 5}^{7}x_id_i + x_8 - x_8\sum_{i = 1}^{7}d_i)}{(1 - \sum_{i = 1}^{4}d_i)^2} & -\frac{x_5 - x_8}{1 - \sum_{i = 1}^{4}d_i} & -\frac{x_6 - x_8}{1 - \sum_{i = 1}^{4}d_i} & -\frac{x_7 - x_8}{1 - \sum_{i = 1}^{4}d_i}
\end{pmatrix} x_1 = x_5 \neq x_2 = x_6 \neq x_3 = x_7 \neq x_4 = x_8 (\mathbf{x^*}, \mathbf{d^*}) \begin{equation}
x_1 = x_5 \neq x_2 = x_6 \neq x_3 = x_7 \neq x_4 = x_8 \\
d_1 = \dots = d_8 = \frac{1}{8}.
\end{equation} F(\mathbf{x^*}, \mathbf{d^*}) = 0 DF(\mathbf{x^*}, \mathbf{d^*}) F \mathbf{0} (\varepsilon_1, \dots, \varepsilon_7) \varepsilon_i = \pm 1 \mathbb{R}^7 \mathbf{z} = (z_1, \dots, z_7) \mathbf{0} \mathbf{x'}, \mathbf{d'} [0, 1]^8 \times \Sigma(8) F(\mathbf{x'}, \mathbf{d'}) = \mathbf{z} (\mathbf{x'}, \mathbf{d'}) S_1, \dots, S_8 \begin{equation}
Pr\{H|TCU\} - Pr\{H|T'CU\}, Pr\{H|TCU'\} - Pr\{H|T'CU""\}, \\
Pr\{H|TC'U\} - Pr\{H|T'C'U\}, Pr\{H|TC'U'\} - Pr\{H|T'C'U'\}, \\
Pr\{H|TC\} - Pr\{H|T'C\}, Pr\{H|TC'\} - Pr\{H|T'C'\}, \\
Pr\{H|T\} - Pr\{H|T'\},\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space\space
\end{equation} (\varepsilon_1, \dots, \varepsilon_7) y_i z_i (\mathbf{x^*}, \mathbf{d^*})","['linear-algebra', 'statistics', 'solution-verification', 'conditional-probability', 'implicit-function-theorem']"
1,"Prove $\ell(\theta^{(t+1)}) \geq \ell(\theta^{(t)})$, answer proof not clear, need some expainations","Prove , answer proof not clear, need some expainations",\ell(\theta^{(t+1)}) \geq \ell(\theta^{(t)}),"Question The problem is to proof the inequation, but the answer is too elliptical, can anyone give some comment or explaination to help me build up the logic chain? Answer The confusion part: why (1) is not $=$ . (2) why they directly come up $\theta^{(t+1)} > \theta^{(t+1)}$ . is there missing something between (0) and (1)?","Question The problem is to proof the inequation, but the answer is too elliptical, can anyone give some comment or explaination to help me build up the logic chain? Answer The confusion part: why (1) is not . (2) why they directly come up . is there missing something between (0) and (1)?",= \theta^{(t+1)} > \theta^{(t+1)},"['real-analysis', 'probability', 'probability-theory', 'statistics', 'self-learning']"
2,An inequality regarding sums of sigmoid/logistic functions,An inequality regarding sums of sigmoid/logistic functions,,"Let $\sigma(x)=1/(1+e^{-x})$ denote the sigmoid/logistic function and let $a,b,c,d>0$ such that $a\geq c$ and $a+b=c+d$ . Prove that $$ \sigma(2a-b)-\sigma(2c-d)\geq \sigma(2a+b)-\sigma(2c+d). $$ Note that both sides of the inequality are non-negative. The proof is easy if the coefficient 2 was a 1, or if the function $\sigma$ was a linear function. I simulated over 1 million values and the result seems to hold, but I'm stuck on the proof. I tried using the Lipschitz condition, subadditivity, and direct computation.","Let denote the sigmoid/logistic function and let such that and . Prove that Note that both sides of the inequality are non-negative. The proof is easy if the coefficient 2 was a 1, or if the function was a linear function. I simulated over 1 million values and the result seems to hold, but I'm stuck on the proof. I tried using the Lipschitz condition, subadditivity, and direct computation.","\sigma(x)=1/(1+e^{-x}) a,b,c,d>0 a\geq c a+b=c+d 
\sigma(2a-b)-\sigma(2c-d)\geq \sigma(2a+b)-\sigma(2c+d).
 \sigma","['statistics', 'functions', 'logistic-regression']"
3,Good Book on survival analysis,Good Book on survival analysis,,"I am looking for a comprehensive textbook on survival analysis, either in German or English, from the basics to modern methods including competing risks. It should be easier to understand than the Kalbfleisch & Prentice book ""The Statistical Analysis of Failure Time Data"", which has some terrible notations, e.g. in the unification of discrete, continuous and mixed distributions, many references to derivations later in the book, and inconsistent terms - for example, lambda stands for both the hazard function and the parameter of the exponential distribution, and in places where both are discussed, it is not always clear what is meant.","I am looking for a comprehensive textbook on survival analysis, either in German or English, from the basics to modern methods including competing risks. It should be easier to understand than the Kalbfleisch & Prentice book ""The Statistical Analysis of Failure Time Data"", which has some terrible notations, e.g. in the unification of discrete, continuous and mixed distributions, many references to derivations later in the book, and inconsistent terms - for example, lambda stands for both the hazard function and the parameter of the exponential distribution, and in places where both are discussed, it is not always clear what is meant.",,"['probability', 'analysis', 'statistics', 'reference-request', 'book-recommendation']"
4,Properties of a random permutation matrix,Properties of a random permutation matrix,,"Given a uniformly sampled permutation matrix $\Pi\in\{0,1\}^{n\times n}$ , what can we say about the matrix $E$ where $$ \Pi = I + E, $$ where $I$ is the identity matrix. More precisely. what can we say about the following: What is the statistical distribution of $E$ ? What is the mean of $E$ ? What is the variance of $E$ ? Thanks. Motivation: This is useful in the shuffled linear regression problem where observations are in the form of $$ y=\Pi X\beta=X\beta+EX\beta, $$ where $y$ and $X$ are observed, $\Pi$ and $\beta$ are unknown, and the goal is to estimate $\beta$ . I was wondering if we can view $EX\beta$ like some sort of noise, akin the usual linear regression with additive noise.","Given a uniformly sampled permutation matrix , what can we say about the matrix where where is the identity matrix. More precisely. what can we say about the following: What is the statistical distribution of ? What is the mean of ? What is the variance of ? Thanks. Motivation: This is useful in the shuffled linear regression problem where observations are in the form of where and are observed, and are unknown, and the goal is to estimate . I was wondering if we can view like some sort of noise, akin the usual linear regression with additive noise.","\Pi\in\{0,1\}^{n\times n} E 
\Pi = I + E,
 I E E E 
y=\Pi X\beta=X\beta+EX\beta,
 y X \Pi \beta \beta EX\beta","['probability', 'statistics', 'permutations', 'random-matrices', 'permutation-matrices']"
5,Why do we multiply by the value on the normal curve instead of the area under the curve in naive anomaly detection algorithm?,Why do we multiply by the value on the normal curve instead of the area under the curve in naive anomaly detection algorithm?,,"In the naive unsupervised anomaly detection algorithm, we go through each feature and calculate the probability of getting the value. Then, we multiply the probability for each feature to calculate the net probability. But, in multiplication, we use the actual value on the normal curve: $$\frac{1}{\sigma \sqrt{2 \pi}} \exp{\left(-\frac{(x - \mu) ^ 2}{2\sigma^ 2}\right)}$$ Shouldn't we multiply by the area under the curve for getting such an extreme value i.e. the area under the curve for $(-\infty, -x) \cup (x, \infty)$ I can imagine a scenario where the $\sigma$ is high (the curve is highly spread out) and so even the probability of getting the mean is low. How does this work then? Sorry if this is a stupid question, I am new to statistics. Thanks!","In the naive unsupervised anomaly detection algorithm, we go through each feature and calculate the probability of getting the value. Then, we multiply the probability for each feature to calculate the net probability. But, in multiplication, we use the actual value on the normal curve: Shouldn't we multiply by the area under the curve for getting such an extreme value i.e. the area under the curve for I can imagine a scenario where the is high (the curve is highly spread out) and so even the probability of getting the mean is low. How does this work then? Sorry if this is a stupid question, I am new to statistics. Thanks!","\frac{1}{\sigma \sqrt{2 \pi}} \exp{\left(-\frac{(x - \mu) ^ 2}{2\sigma^ 2}\right)} (-\infty, -x) \cup (x, \infty) \sigma","['probability', 'statistics', 'normal-distribution']"
6,Does reparameterization trick make sense?,Does reparameterization trick make sense?,,"Given $x_t=(1-t)x_0+ty+t\epsilon_t\eta_t$ , where $\eta_t\sim N(0,I)$ , how can the analytic form of $p(x_{t-\delta}|x_t,x_0)$ be derived ? Since what we have is $p(x_{t-\delta}|x_0,y)$ and $p(x_{t-\delta}|x_0,y)$ , I tried to rewrite $p(x_{t-\delta}|x_t,x_0)$ as, \begin{align*} p(x_{t-\delta}|x_t,x_0) = \int_{y} q(x_{t-\delta}|x_t,x_0,y)*q(y|x_0,x_t) \,dy  \end{align*} I don't know how to continue from here. While I don't know how to solve the problem using the basics of probability, a so called reparameterization trick may help. Since $x_t=(1-t)x_0+ty+\epsilon_t\eta_t$ , we have \begin{align*} y=\frac{1}{t}x_t-\frac{1-t}{t}x_0-\epsilon_t*\eta_t \end{align*} . Does this means $y\sim N(\frac{1}{t}x_t-\frac{1-t}{t}x_0,\epsilon_tI)$ ? Since $x_{t-\delta}=(1-t-\delta)x_0+(t-\delta)y+(t-\delta)\epsilon_{t-\delta}\eta_{t-\delta}$ , we may substitute the expression for y and get \begin{align*} x_{t-\delta}=(1-t-\delta)x_0+\frac{t-\delta}{t}x_t-\frac{t-\delta}{t}(1-t)x_0-(t-\delta)\epsilon_t\eta_t+(t-\delta)\epsilon_{t-\delta}\eta_{t-\delta} =\frac{\delta}{t}x_0+\frac{t-\delta}{t}x_t+(t-\delta)(\epsilon_t\eta_t+\epsilon_{t-\delta}\eta_{t-\delta}) \end{align*} , therefore we may conclude $$ p(x_{t-\delta}|x_t,x_0)=N(x_{t-\delta};\frac{\delta}{t}x_0+\frac{t-\delta}{t}x_t,(t-\delta)\sqrt{\epsilon_t^2+\epsilon_{t-\delta}^2}I) $$ This is indeed the solution given in the paper (equation 10) https://openreview.net/pdf?id=VmyFF5lL3F . Is the solution derived by using the reparameterization trick make sense? If so how can we achieve the same solution using the basics of probability ? Thanks for your help in advance !","Given , where , how can the analytic form of be derived ? Since what we have is and , I tried to rewrite as, I don't know how to continue from here. While I don't know how to solve the problem using the basics of probability, a so called reparameterization trick may help. Since , we have . Does this means ? Since , we may substitute the expression for y and get , therefore we may conclude This is indeed the solution given in the paper (equation 10) https://openreview.net/pdf?id=VmyFF5lL3F . Is the solution derived by using the reparameterization trick make sense? If so how can we achieve the same solution using the basics of probability ? Thanks for your help in advance !","x_t=(1-t)x_0+ty+t\epsilon_t\eta_t \eta_t\sim N(0,I) p(x_{t-\delta}|x_t,x_0) p(x_{t-\delta}|x_0,y) p(x_{t-\delta}|x_0,y) p(x_{t-\delta}|x_t,x_0) \begin{align*}
p(x_{t-\delta}|x_t,x_0) = \int_{y} q(x_{t-\delta}|x_t,x_0,y)*q(y|x_0,x_t) \,dy 
\end{align*} x_t=(1-t)x_0+ty+\epsilon_t\eta_t \begin{align*}
y=\frac{1}{t}x_t-\frac{1-t}{t}x_0-\epsilon_t*\eta_t
\end{align*} y\sim N(\frac{1}{t}x_t-\frac{1-t}{t}x_0,\epsilon_tI) x_{t-\delta}=(1-t-\delta)x_0+(t-\delta)y+(t-\delta)\epsilon_{t-\delta}\eta_{t-\delta} \begin{align*}
x_{t-\delta}=(1-t-\delta)x_0+\frac{t-\delta}{t}x_t-\frac{t-\delta}{t}(1-t)x_0-(t-\delta)\epsilon_t\eta_t+(t-\delta)\epsilon_{t-\delta}\eta_{t-\delta}
=\frac{\delta}{t}x_0+\frac{t-\delta}{t}x_t+(t-\delta)(\epsilon_t\eta_t+\epsilon_{t-\delta}\eta_{t-\delta})
\end{align*} 
p(x_{t-\delta}|x_t,x_0)=N(x_{t-\delta};\frac{\delta}{t}x_0+\frac{t-\delta}{t}x_t,(t-\delta)\sqrt{\epsilon_t^2+\epsilon_{t-\delta}^2}I)
","['probability', 'statistics', 'probability-distributions', 'conditional-probability']"
7,Uniform convergence in distribution implies convergence of moments,Uniform convergence in distribution implies convergence of moments,,"I am reading a paper in which the author wants to prove the convergence of the moments. He transforms the object of interest $\varepsilon^{-1} (\vartheta_\varepsilon^*-\vartheta_0)$ into \begin{align*} \varepsilon^{-1} (\vartheta_\varepsilon^*-\vartheta_0)=\Delta_\varepsilon +   \frac{\bar{\vartheta}_{\tau_\varepsilon}-\vartheta_0}{\varepsilon} R_\varepsilon^*  \end{align*} Now, he shows that $\Delta_\varepsilon$ converges uniformly to the normal distribution $N(0,I(\vartheta_0)^{-1})\overset{d}{=}:\zeta$ (using the uniform CLT) and that \begin{align*} \sup_{\vartheta_0 \in \mathbb{K}}\mathbb{E}_{\vartheta_0} \left| \frac{\bar{\vartheta}_{\tau_\varepsilon}-\vartheta_0}{\varepsilon} R_\varepsilon^* \right|^p \underset{\varepsilon \rightarrow 0}{\longrightarrow} 0 \end{align*} Hence, $\varepsilon^{-1} (\vartheta_\varepsilon^*-\vartheta_0) \rightarrow N(0,I(\vartheta_0)^{-1})$ as $\varepsilon \rightarrow 0$ . But he also claims that the moments converge (as a consequence of this proof!), i.e. that for any $p>0$ : $\mathbb{E}_{\vartheta_0} |\varepsilon^{-1} (\vartheta_\varepsilon^*-\vartheta_0)|^p \rightarrow \mathbb{E}_{\vartheta_0}|\zeta|^p $ . My question: Why does this hold? I am of course familiar with the well-known counterexamples of ""convergence in distribution implies convergence of moments"" and the ability to use uniform integrability. But here the author seems (as he claims so) to have shown the moment convergence already; but I am unable to see this connection.","I am reading a paper in which the author wants to prove the convergence of the moments. He transforms the object of interest into Now, he shows that converges uniformly to the normal distribution (using the uniform CLT) and that Hence, as . But he also claims that the moments converge (as a consequence of this proof!), i.e. that for any : . My question: Why does this hold? I am of course familiar with the well-known counterexamples of ""convergence in distribution implies convergence of moments"" and the ability to use uniform integrability. But here the author seems (as he claims so) to have shown the moment convergence already; but I am unable to see this connection.","\varepsilon^{-1} (\vartheta_\varepsilon^*-\vartheta_0) \begin{align*}
\varepsilon^{-1} (\vartheta_\varepsilon^*-\vartheta_0)=\Delta_\varepsilon +   \frac{\bar{\vartheta}_{\tau_\varepsilon}-\vartheta_0}{\varepsilon} R_\varepsilon^* 
\end{align*} \Delta_\varepsilon N(0,I(\vartheta_0)^{-1})\overset{d}{=}:\zeta \begin{align*}
\sup_{\vartheta_0 \in \mathbb{K}}\mathbb{E}_{\vartheta_0} \left| \frac{\bar{\vartheta}_{\tau_\varepsilon}-\vartheta_0}{\varepsilon} R_\varepsilon^* \right|^p \underset{\varepsilon \rightarrow 0}{\longrightarrow} 0
\end{align*} \varepsilon^{-1} (\vartheta_\varepsilon^*-\vartheta_0) \rightarrow N(0,I(\vartheta_0)^{-1}) \varepsilon \rightarrow 0 p>0 \mathbb{E}_{\vartheta_0} |\varepsilon^{-1} (\vartheta_\varepsilon^*-\vartheta_0)|^p \rightarrow \mathbb{E}_{\vartheta_0}|\zeta|^p ","['probability', 'statistics', 'stochastic-analysis', 'central-limit-theorem', 'uniform-integrability']"
8,Can anything be said about convexity of this function?,Can anything be said about convexity of this function?,,"I have the following optimization problem, to find the Excess Mass of for a given $t \ge 0$ $EM(t) = \sup_{u \ge 0}\  \mathbb{P}\Big[s(X) \ge u\Big] - t \cdot Leb\ (\{s \ge u\})$ where, $s:R^d \to R^+$ is a scoring function $X$ is a random variable from a distribution $f$ be the PDF of the above-said distribution $s \ge u$ is the level set of $s$ at level $u$ $Leb$ is the Lebesgue measure I was wondering if anything can be commented on the convexity of the function. i.e., positive, negative, or could be anything? Basically, my main objective is to improve the time complexity (keeping the $t$ fixed) using binary search over linear search if anything could be commented on that. Even if generalizing is not possible, what could be the conditions for which the function is concave/convex? I have tried plotting it on a few datasets ( $X$ ) and scoring functions ( $s$ ) and always found the graphs concave upwards. So, in this case, the maximum lies at the end. Although I need some theoretical backing to make a statement conclusively. Reference: On Anomaly Ranking and Excess-Mass Curves Edit: I plotted $EM_t(u)$ vs $u$ by keeping the $t$ fixed.","I have the following optimization problem, to find the Excess Mass of for a given where, is a scoring function is a random variable from a distribution be the PDF of the above-said distribution is the level set of at level is the Lebesgue measure I was wondering if anything can be commented on the convexity of the function. i.e., positive, negative, or could be anything? Basically, my main objective is to improve the time complexity (keeping the fixed) using binary search over linear search if anything could be commented on that. Even if generalizing is not possible, what could be the conditions for which the function is concave/convex? I have tried plotting it on a few datasets ( ) and scoring functions ( ) and always found the graphs concave upwards. So, in this case, the maximum lies at the end. Although I need some theoretical backing to make a statement conclusively. Reference: On Anomaly Ranking and Excess-Mass Curves Edit: I plotted vs by keeping the fixed.",t \ge 0 EM(t) = \sup_{u \ge 0}\  \mathbb{P}\Big[s(X) \ge u\Big] - t \cdot Leb\ (\{s \ge u\}) s:R^d \to R^+ X f s \ge u s u Leb t X s EM_t(u) u t,"['probability', 'measure-theory', 'statistics', 'multivariable-calculus']"
9,Sum of normal densities,Sum of normal densities,,"Suppose $Y$ is a random variable whose distribution is completely known. For $i=1,\dots,d$ , $\beta_i$ are positive constants, $g_i(\cdot)$ are exponential functions with the form $g_i(x) = \exp(a_i(x-b_i)^2 + c_i)$ , where $a_i,b_i,c_i$ are all constants (can be positive or negative). We also have $\sum_{i}\beta_i = 1$ . I am wondering if there is any way to give an analytical form (in terms of distribution of $Y$ ) for the probability of the event $\{\sum_{i=1}^d \beta_i g_i(Y)\geq\beta_1g_1(Y)\}?$ Say $Y$ follows some normal distribution. We can easily give a closed form for the probability of the event above for $d\leq2$ . But I don't know how to do so for $d=3$ ; discussing the convexity/monotonicity and searching for equilibriums seem to be too complicated. I would greatly appreciate it if any advice can be given.","Suppose is a random variable whose distribution is completely known. For , are positive constants, are exponential functions with the form , where are all constants (can be positive or negative). We also have . I am wondering if there is any way to give an analytical form (in terms of distribution of ) for the probability of the event Say follows some normal distribution. We can easily give a closed form for the probability of the event above for . But I don't know how to do so for ; discussing the convexity/monotonicity and searching for equilibriums seem to be too complicated. I would greatly appreciate it if any advice can be given.","Y i=1,\dots,d \beta_i g_i(\cdot) g_i(x) = \exp(a_i(x-b_i)^2 + c_i) a_i,b_i,c_i \sum_{i}\beta_i = 1 Y \{\sum_{i=1}^d \beta_i g_i(Y)\geq\beta_1g_1(Y)\}? Y d\leq2 d=3","['probability', 'probability-theory', 'statistics', 'probability-distributions']"
10,Convergence in distribution of two sequences,Convergence in distribution of two sequences,,"Let $\left\{\xi_n\right\}_{n = 1} ^ \infty, \left\{\eta_n\right\}_{n = 1} ^ \infty, \left\{\zeta_n\right\}_{n = 1} ^ \infty$ be sequences such that: $$ \xi_n \xrightarrow{d} \xi\\ |\xi_n - \eta_n| \leq \zeta_n|\xi_n|\\ \zeta_n \xrightarrow{\mathbb{P}}0 $$ then why does $\eta_n \xrightarrow{d} \xi$ , where $\xrightarrow{\mathbb{P}}$ is a convergence in probability and $\xrightarrow{d}$ is a convergence in distribution? Unfortunately, I did not have any useful ideas for solving this problem. I'd be grateful if someone could give me a hint as I don't quite understand where to start.","Let be sequences such that: then why does , where is a convergence in probability and is a convergence in distribution? Unfortunately, I did not have any useful ideas for solving this problem. I'd be grateful if someone could give me a hint as I don't quite understand where to start.","\left\{\xi_n\right\}_{n = 1} ^ \infty, \left\{\eta_n\right\}_{n = 1} ^ \infty, \left\{\zeta_n\right\}_{n = 1} ^ \infty 
\xi_n \xrightarrow{d} \xi\\
|\xi_n - \eta_n| \leq \zeta_n|\xi_n|\\
\zeta_n \xrightarrow{\mathbb{P}}0
 \eta_n \xrightarrow{d} \xi \xrightarrow{\mathbb{P}} \xrightarrow{d}","['probability', 'statistics']"
11,How to transform a function f(x) such that it matches the central moments of g(x) up to nth central moment?,How to transform a function f(x) such that it matches the central moments of g(x) up to nth central moment?,,"Suppose I have 2 functions, a given function f(x) and a target function g(x). Let $M_{f}^{n}$ denote the nth central moment of function f(x). In the discrete case for N samples of f(x): $M_{f}^{n}=\tfrac{1}{N}\sum_{i=1}^{N}(f(x) - \mu)^{n}$ And $\mu$ is the mean. In the continuous case: $M_{f}^{n}=E[(f - E(f))^{n}]$ I would like to transform f(x) into $f_{g}^{n}(x)$ such that: $M_{f_{g}^{n}}^{1}=M_{g}^{1}$ $M_{f_{g}^{n}}^{2}=M_{g}^{2}$ [...] $M_{f_{g}^{n}}^{n}=M_{g}^{n}$ Upto a specified n. For n=2 case, there is a direct transformation: $f_{g}^{2}(x) = f_1\cdot\frac{M_{g}^{2}}{M_{f_1}^{2}} + M_{g}^{2}$ Where: $f_1(x) = f(x)-M_{f}^{1}$ I can't think of something for n=3,4. It could be the case that such a transformation might not be possible. In which case, is it possible to propose a numerical method that can find a solution upto a specified epsilon? The only thing we know about g(x) are its n central moments. I'm looking for a computationally efficient transformation, yet a fairly general solution. Ideally, an affine or polynomial transformation is preferred, but not required. The target is computational efficiency . The ""transformation"" for n=2 is O(1), assuming that the computation of the nth moment is O(1), and subtracting the 1st moment is O(1).","Suppose I have 2 functions, a given function f(x) and a target function g(x). Let denote the nth central moment of function f(x). In the discrete case for N samples of f(x): And is the mean. In the continuous case: I would like to transform f(x) into such that: [...] Upto a specified n. For n=2 case, there is a direct transformation: Where: I can't think of something for n=3,4. It could be the case that such a transformation might not be possible. In which case, is it possible to propose a numerical method that can find a solution upto a specified epsilon? The only thing we know about g(x) are its n central moments. I'm looking for a computationally efficient transformation, yet a fairly general solution. Ideally, an affine or polynomial transformation is preferred, but not required. The target is computational efficiency . The ""transformation"" for n=2 is O(1), assuming that the computation of the nth moment is O(1), and subtracting the 1st moment is O(1).",M_{f}^{n} M_{f}^{n}=\tfrac{1}{N}\sum_{i=1}^{N}(f(x) - \mu)^{n} \mu M_{f}^{n}=E[(f - E(f))^{n}] f_{g}^{n}(x) M_{f_{g}^{n}}^{1}=M_{g}^{1} M_{f_{g}^{n}}^{2}=M_{g}^{2} M_{f_{g}^{n}}^{n}=M_{g}^{n} f_{g}^{2}(x) = f_1\cdot\frac{M_{g}^{2}}{M_{f_1}^{2}} + M_{g}^{2} f_1(x) = f(x)-M_{f}^{1},"['statistics', 'functions', 'numerical-methods']"
12,"Prove posterior mean is positive if and only if signal is positive, assuming zero prior mean [closed]","Prove posterior mean is positive if and only if signal is positive, assuming zero prior mean [closed]",,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 12 months ago . Improve this question Suppose that: $\Delta \sim G$ , where $G$ is a distribution that is symmetric about the origin I get a normally-distributed signal: $\hat{\delta} \: |\Delta, \tau^2 \sim N(\Delta, \tau^2)$ How can I prove that the posterior mean $E(\Delta | \hat{\delta})$ is positive if and only if the signal $\hat{\delta}$ is positive. (Intuition: The prior mean is zero, so the posterior mean should assume the sign of the signal $\hat{\delta}$ )","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 12 months ago . Improve this question Suppose that: , where is a distribution that is symmetric about the origin I get a normally-distributed signal: How can I prove that the posterior mean is positive if and only if the signal is positive. (Intuition: The prior mean is zero, so the posterior mean should assume the sign of the signal )","\Delta \sim G G \hat{\delta} \: |\Delta, \tau^2 \sim N(\Delta, \tau^2) E(\Delta | \hat{\delta}) \hat{\delta} \hat{\delta}","['probability-theory', 'statistics', 'statistical-inference', 'bayesian']"
13,Characteristic function of Dirichlet Process,Characteristic function of Dirichlet Process,,"Suppose $P \sim \text{DP}(\alpha,G) $ where $G \sim N(0,1)$ is the base measure and $\alpha > 0$ is the concentration parameter. The stick breaking representation says that $P$ can be expressed as \begin{align*} P = \sum_{j=1}^{\infty} W_j \delta_{\theta_j} \; \; \; \; \; \; \; , \; \; \; \; W_j = V_j \prod_{l=1}^{j-1} (1-V_l)    \end{align*} where $\theta_j \stackrel{iid}{\sim} N(0,1) $ and $ V_l \stackrel{iid}{\sim} \text{Beta}(1,\alpha) $ . It follows that the characteristic function of $P$ is given by $$ \varphi_{P}(t) = \sum_{j=1}^{\infty} W_j e^{\mathbf{i}  t \delta_j  } $$ It seems intuitively clear to me that $\left| \varphi_P(t) \right|$ is bounded away from zero (even at large $t$ ) with high probability but I don't know how to make this rigorous. Specifically, how does $$ \mathbb{P}( \left| \varphi_P(t)   \right| \leq \epsilon ) $$ behave as $ |t| \rightarrow \infty $ and $\epsilon \rightarrow 0$ .","Suppose where is the base measure and is the concentration parameter. The stick breaking representation says that can be expressed as where and . It follows that the characteristic function of is given by It seems intuitively clear to me that is bounded away from zero (even at large ) with high probability but I don't know how to make this rigorous. Specifically, how does behave as and .","P \sim \text{DP}(\alpha,G)  G \sim N(0,1) \alpha > 0 P \begin{align*} P = \sum_{j=1}^{\infty} W_j \delta_{\theta_j} \; \; \; \; \; \; \; , \; \; \; \; W_j = V_j \prod_{l=1}^{j-1} (1-V_l)    \end{align*} \theta_j \stackrel{iid}{\sim} N(0,1)   V_l \stackrel{iid}{\sim} \text{Beta}(1,\alpha)  P  \varphi_{P}(t) = \sum_{j=1}^{\infty} W_j e^{\mathbf{i}  t \delta_j  }  \left| \varphi_P(t) \right| t  \mathbb{P}( \left| \varphi_P(t)   \right| \leq \epsilon )   |t| \rightarrow \infty  \epsilon \rightarrow 0","['real-analysis', 'probability', 'statistics', 'stochastic-processes']"
14,Rademacher complexity of Binary classification,Rademacher complexity of Binary classification,,"I am trying to show the inequality below, please note that in this case I am considering the labels to be $Y_i \in \{0, 1\}$ , I state this since I have seen results but for labels that are in $\{0,1\}$ . The inequality  I want to show is: $$  \mathbb{E}\max_{f\in F}\left[ \frac{1}{n}\sum_{i=1}^n\epsilon_i\mathbb{1} \{ y_i\neq f(x_i) \} \right]\leq \mathbb{E}\max_{f\in F}\left[ \frac{1}{n}\sum_{i=1}^n\epsilon_i f(x_i) \right] $$ where $\epsilon_i$ is a Rademacher random variable and the labels $Y_i\in \{ 0,1 \}$ as well as the outputs of $f$ , the $\mathbb{1} \{ y_i\neq f(x_i) \}$ is the indicator function. My attempt of solution: I rewritten the indicator function as follows: $$ \mathbb{1} \{ y_i\neq f(x_i)\}=y_i + f(x_i) - 2y_if(x_i) $$ And replaced it into the expression that became the following: $$  \mathbb{E}\max_{f\in F}\left[\frac{1}{n}\sum_{i=1}^n\epsilon_i\mathbb{1} \{ y_i\neq f(x_i) \} \right]=\mathbb{E}\max_{f\in F}\left[\frac{1}{n}\sum_{i=1}^n\epsilon_i f(x_i)-\frac{1}{n}\sum_{i=1}^n\epsilon_i (2f(x_i)-1)y_i  \right] $$ I rewritten it this way since the term $(2f(x_i)-1)$ has a similar distribution as the Rademacher random variable, but I don't know how to continue or if this approach is correct, thanks for any help.","I am trying to show the inequality below, please note that in this case I am considering the labels to be , I state this since I have seen results but for labels that are in . The inequality  I want to show is: where is a Rademacher random variable and the labels as well as the outputs of , the is the indicator function. My attempt of solution: I rewritten the indicator function as follows: And replaced it into the expression that became the following: I rewritten it this way since the term has a similar distribution as the Rademacher random variable, but I don't know how to continue or if this approach is correct, thanks for any help.","Y_i \in \{0, 1\} \{0,1\}  
\mathbb{E}\max_{f\in F}\left[ \frac{1}{n}\sum_{i=1}^n\epsilon_i\mathbb{1} \{ y_i\neq f(x_i) \} \right]\leq \mathbb{E}\max_{f\in F}\left[ \frac{1}{n}\sum_{i=1}^n\epsilon_i f(x_i) \right]
 \epsilon_i Y_i\in \{ 0,1 \} f \mathbb{1} \{ y_i\neq f(x_i) \} 
\mathbb{1} \{ y_i\neq f(x_i)\}=y_i + f(x_i) - 2y_if(x_i)
  
\mathbb{E}\max_{f\in F}\left[\frac{1}{n}\sum_{i=1}^n\epsilon_i\mathbb{1} \{ y_i\neq f(x_i) \} \right]=\mathbb{E}\max_{f\in F}\left[\frac{1}{n}\sum_{i=1}^n\epsilon_i f(x_i)-\frac{1}{n}\sum_{i=1}^n\epsilon_i (2f(x_i)-1)y_i  \right]
 (2f(x_i)-1)","['statistics', 'machine-learning', 'rademacher-distribution']"
15,Bound on inverse covariance from covariance in regularized covariance estimation problem,Bound on inverse covariance from covariance in regularized covariance estimation problem,,"In this paper by Bickel and Levina , I am confused about result (A15) which claims that since $$ (A14) \qquad \| \text{Var}(\mathbf{X}) - \widehat{\text{Var}}(\mathbf{X})\|_{\max} = O_P(n^{-1/2} \log^{1/2}p) $$ then it follows that $$ (A15) \qquad \| \text{Var}^{-1}(\mathbf{Z}_j^{(k)}) - \widehat{\text{Var}}^{-1}(\mathbf{Z}_{j}^{(k)})\|_{\max} = O_P(n^{-1/2} \log^{1/2}p) $$ where $\mathbb{R}^p \ni \mathbf{X} = (X_1,\dots,X_p) \sim N(0,\Sigma_p)$ and $$ \mathbf{Z_j^{(k)}} =(X_{\max(1, j-k)}, \dots, X_j) $$ is the collection of $X_j$ and $k$ previous neighbours in $\mathbf{X}$ . The estimated quantities are based on an i.i.d. sample $\mathbf{X}_1,\dots, \mathbf{X}_n \sim N(0,\Sigma_p)$ , so $$ \widehat{\text{Var}}(\mathbf{X}) := \frac{1}{n} \sum_{i=1}^n (\mathbf{X}_i - \overline{\mathbf{X}})(\mathbf{X}_i - \overline{\mathbf{X}})^T $$ and $$ \widehat{\text{Var}}^{-1}(\mathbf{Z}_j^{(k)}) := \left ( \frac{1}{n} \sum_{i=1}^n (\mathbf{Z}_{i,j}^{(k)} - {\overline{\mathbf{Z}}_{j}^{(k)} })(\mathbf{Z}_{i,j}^{(k)} - {\overline{\mathbf{Z}}_{j}^{(k)} })^T\right)^{-1} $$ where $\mathbf{Z}_{i,j}^{(k)} = (X_{i, {\max(1, j-k)}}, \dots, X_{i,j})$ - i.e. the collection of $X_j$ and its k previous neighbours for the $i$ -th observation. The authors take: $k  \asymp (n^{-1} \log p)^{-1/2(\alpha+1)}$ . For the purpose of this question I think that exact meaning of $\alpha$ is not important and we can think of it as some positive constant.  I am unsure how the bound on the element-wise maximum of the sample covariance matrix in (A14) leads to the same bound on the inverse covariance in (A15). It seems to be a trivial step in their proof so I feel like that I must be missing something obvious here.","In this paper by Bickel and Levina , I am confused about result (A15) which claims that since then it follows that where and is the collection of and previous neighbours in . The estimated quantities are based on an i.i.d. sample , so and where - i.e. the collection of and its k previous neighbours for the -th observation. The authors take: . For the purpose of this question I think that exact meaning of is not important and we can think of it as some positive constant.  I am unsure how the bound on the element-wise maximum of the sample covariance matrix in (A14) leads to the same bound on the inverse covariance in (A15). It seems to be a trivial step in their proof so I feel like that I must be missing something obvious here.","
(A14) \qquad \| \text{Var}(\mathbf{X}) - \widehat{\text{Var}}(\mathbf{X})\|_{\max} = O_P(n^{-1/2} \log^{1/2}p)
 
(A15) \qquad \| \text{Var}^{-1}(\mathbf{Z}_j^{(k)}) - \widehat{\text{Var}}^{-1}(\mathbf{Z}_{j}^{(k)})\|_{\max} = O_P(n^{-1/2} \log^{1/2}p)
 \mathbb{R}^p \ni \mathbf{X} = (X_1,\dots,X_p) \sim N(0,\Sigma_p) 
\mathbf{Z_j^{(k)}} =(X_{\max(1, j-k)}, \dots, X_j)
 X_j k \mathbf{X} \mathbf{X}_1,\dots, \mathbf{X}_n \sim N(0,\Sigma_p) 
\widehat{\text{Var}}(\mathbf{X}) := \frac{1}{n} \sum_{i=1}^n (\mathbf{X}_i - \overline{\mathbf{X}})(\mathbf{X}_i - \overline{\mathbf{X}})^T
 
\widehat{\text{Var}}^{-1}(\mathbf{Z}_j^{(k)}) := \left (
\frac{1}{n} \sum_{i=1}^n (\mathbf{Z}_{i,j}^{(k)} - {\overline{\mathbf{Z}}_{j}^{(k)} })(\mathbf{Z}_{i,j}^{(k)} - {\overline{\mathbf{Z}}_{j}^{(k)} })^T\right)^{-1}
 \mathbf{Z}_{i,j}^{(k)} = (X_{i, {\max(1, j-k)}}, \dots, X_{i,j}) X_j i k  \asymp (n^{-1} \log p)^{-1/2(\alpha+1)} \alpha","['probability', 'statistics', 'machine-learning', 'covariance', 'concentration-of-measure']"
16,Why is OLS valid for the AR process?,Why is OLS valid for the AR process?,,"Is it valid to apply OLS to the AR process? I learn that there exist correlation between explanatory variables and error term in AR model. I'm wondering how can show that $$E(u_t|x_t)\ne0$$ ,where vector of explanatory variable $x_t=(1, y_1,y_2,...,y_{t-1})$ And if AR model can not satisfy the assumption of BLUE, why OLS still used to estimate coefficient of AR model? Statistical proof would be greatly appreciated, and if not, an intuition would be enough. Remind that I'm looking for insights, not all the right answers.","Is it valid to apply OLS to the AR process? I learn that there exist correlation between explanatory variables and error term in AR model. I'm wondering how can show that ,where vector of explanatory variable And if AR model can not satisfy the assumption of BLUE, why OLS still used to estimate coefficient of AR model? Statistical proof would be greatly appreciated, and if not, an intuition would be enough. Remind that I'm looking for insights, not all the right answers.","E(u_t|x_t)\ne0 x_t=(1, y_1,y_2,...,y_{t-1})","['statistics', 'time-series']"
17,What is the geometrical difference between $Z_{\alpha/2}$ and $E_{a}$?,What is the geometrical difference between  and ?,Z_{\alpha/2} E_{a},"What is the geometrical difference between $Z_{\alpha/2}$ and $E_{a}$ ? Let's say we have a generator of toys and the weight is distributed with a standard deviation of $4kg$ and a mean of $5kg$ for example. I know that the interval of confidence is defined as $[\mu+E_a,\mu-E_a]$ being $E_a=Z_{\alpha/2}\frac{\sigma}{\sqrt{n}}$ the random error and $\sigma$ the standard deviation. Which then the extreme values of that interval, are $\mu+E_a$ and $\mu-E_a$ , which then I suppose $E_a$ is a value with units of $kg$ , and then since those are the extreme values, I'm assuming that $E_a$ are these values that would be showed in the graph that limit the area $1-\alpha$ : But then I think, then what is $Z_{\alpha/2}$ ? Since I thought that it was literally the limit that would separate the area $1-\alpha$ . Is $Z_{\alpha/2}$ just the equivalent to the above in a distribution that represents $f(X)$ and not $f(\overline{X})$ ? Or is it just the equivalent to the above in a normal distribution $N(0,1)$ ? Also I notice that the graph it is delimited by $X_{\alpha/2}$ , so is $X_{\alpha/2}=E_a$ and then $Z_{\alpha/2}$ is just $Z_{\alpha/2}=\frac{X_{\alpha/2}-\mu}{\sigma}$ . In general this question is for me to join spots and make it have sense.","What is the geometrical difference between and ? Let's say we have a generator of toys and the weight is distributed with a standard deviation of and a mean of for example. I know that the interval of confidence is defined as being the random error and the standard deviation. Which then the extreme values of that interval, are and , which then I suppose is a value with units of , and then since those are the extreme values, I'm assuming that are these values that would be showed in the graph that limit the area : But then I think, then what is ? Since I thought that it was literally the limit that would separate the area . Is just the equivalent to the above in a distribution that represents and not ? Or is it just the equivalent to the above in a normal distribution ? Also I notice that the graph it is delimited by , so is and then is just . In general this question is for me to join spots and make it have sense.","Z_{\alpha/2} E_{a} 4kg 5kg [\mu+E_a,\mu-E_a] E_a=Z_{\alpha/2}\frac{\sigma}{\sqrt{n}} \sigma \mu+E_a \mu-E_a E_a kg E_a 1-\alpha Z_{\alpha/2} 1-\alpha Z_{\alpha/2} f(X) f(\overline{X}) N(0,1) X_{\alpha/2} X_{\alpha/2}=E_a Z_{\alpha/2} Z_{\alpha/2}=\frac{X_{\alpha/2}-\mu}{\sigma}","['statistics', 'normal-distribution', 'standard-deviation', 'confidence-interval']"
18,Density estimation with Orthogonal series,Density estimation with Orthogonal series,,"I have found this problem from the article http://www.yaroslavvb.com/papers/watson-density.pdf . In this article the probability density function has considered as \begin{equation}   f(x) = \sum_{m=0}^{\infty}\alpha_{m}\phi_{m}(x), \end{equation} and the estimator is \begin{equation}  f^{\ast}_{n}(x) = \sum_{m=0}^{\infty} \lambda_{m}a_{m}\phi_{m}(x), \end{equation} where \begin{equation}    a_{m} = \frac{1}{n}\sum_{k=1}^{n}\phi_{m}(x_k). \end{equation} Here $\{\phi_{m}(x)\}$ is an orthonormal basis. According to the article \begin{equation}   E \int (f(x)-f^{\ast}(x))^2dx= \sum_{m=0}^{\infty}E(\alpha_{m}-\lambda_{m}a_{m})^2=\sum_{m=0}^{\infty}\{\alpha_{m}^2(1-\lambda_{m})^2+\frac{1}{n}\lambda^2_{m}\text{var}(\phi_{m}(x))\}. \end{equation} I have been trying to prove this. My approach is \begin{equation*} \begin{split}  E\int (f(x)-f^{\ast}(x))^2dx & = \int E(f(x)-f^{\ast}(x))^2dx\; [by Fubini]\\ & = \int E\left[\sum_{m=0}^{\infty}(\alpha_{m}-\lambda_{m}a_{m})\phi_{m}(x)\right]^2dx\\ & = \int E\left(\left[\sum_{m=0}^{\infty}(\alpha_{m}-\lambda_{m}a_{m})^2\phi_{m}(x)^2\right]+2 \sum_{m=0}^{\infty}\sum_{j=0}^{\infty}(\alpha_{m}-\lambda_{m}a_{m})(\alpha_{j}-\lambda_{j}a_{j})\phi_{m}(x)\phi_{j}(x)\right)dx\\ & = E\left(\left[\sum_{m=0}^{\infty}(\alpha_{m}-\lambda_{m}a_{m})^2\int\phi_{m}(x)^2dx\right]+2 \sum_{m=0}^{\infty}\sum_{j=0}^{\infty}(\alpha_{m}-\lambda_{m}a_{m})(\alpha_{j}-\lambda_{j}a_{j})\int\phi_{m}(x)\phi_{j}(x)dx\right)\\ & = \sum_{m=0}^{\infty}E(\alpha_{m}-\lambda_{m}a_{m})^2. \end{split} \end{equation*} Note that $\alpha_{m}=E\phi_{m}(x)$ . Now, \begin{equation} \begin{split} E(\alpha_m-\lambda_m a_m)^2 & = E(\alpha_m-\alpha_m \lambda_m+\alpha_m \lambda_m+\lambda_m a_m)^2\\ & = E[\alpha_{m}(1-\lambda_m)+\lambda_m(\alpha_m-a_m)]^2\\ & = E[\alpha_{m}^2(1-\lambda_m)^2+2\alpha_{m}(1-\lambda_m)\lambda_m(\alpha_m-a_m)+\lambda_m^2(\alpha_m-a_m)^2]\\ & = \alpha_{m}^2(1-\lambda_m)^2+ 2\alpha_{m}(1-\lambda_m)\lambda_mE(\alpha_m-a_m)+\lambda_m^2E(\alpha_m-a_m)^2. \end{split} \end{equation} Since \begin{equation} \begin{split}  E(\alpha_{m}-a_{m}) & = \alpha_{m}-Ea_{m}\\ & = \alpha_{m}-\frac{1}{n}\sum_{k=1}^{n}E\phi_{m}(x_k)\\ & = \alpha_{m}-\frac{1}{n}\sum_{k=1}^{n}\alpha_{m}\\ & = \alpha_{m}-\alpha_{m}=0. \end{split} \end{equation} Therefore, \begin{equation}  \sum_{m=1}^{\infty} E(\alpha_{m}-\lambda_{m}a_{m})^2=\sum_{m=1}^{\infty}\alpha_{m}^2(1-\lambda_{m})^2+\lambda_{m}^2E(\alpha_{m}-a_{m})^2. \end{equation} I was wondering is there any way to prove \begin{equation}   E(\alpha_{m}-a_{m})^2=\frac{1}{n}\text{var}(\phi_{m}(x)). \end{equation}","I have found this problem from the article http://www.yaroslavvb.com/papers/watson-density.pdf . In this article the probability density function has considered as and the estimator is where Here is an orthonormal basis. According to the article I have been trying to prove this. My approach is Note that . Now, Since Therefore, I was wondering is there any way to prove","\begin{equation}
  f(x) = \sum_{m=0}^{\infty}\alpha_{m}\phi_{m}(x),
\end{equation} \begin{equation}
 f^{\ast}_{n}(x) = \sum_{m=0}^{\infty} \lambda_{m}a_{m}\phi_{m}(x),
\end{equation} \begin{equation}
   a_{m} = \frac{1}{n}\sum_{k=1}^{n}\phi_{m}(x_k).
\end{equation} \{\phi_{m}(x)\} \begin{equation}
  E \int (f(x)-f^{\ast}(x))^2dx= \sum_{m=0}^{\infty}E(\alpha_{m}-\lambda_{m}a_{m})^2=\sum_{m=0}^{\infty}\{\alpha_{m}^2(1-\lambda_{m})^2+\frac{1}{n}\lambda^2_{m}\text{var}(\phi_{m}(x))\}.
\end{equation} \begin{equation*}
\begin{split}
 E\int (f(x)-f^{\ast}(x))^2dx & = \int E(f(x)-f^{\ast}(x))^2dx\; [by Fubini]\\
& = \int E\left[\sum_{m=0}^{\infty}(\alpha_{m}-\lambda_{m}a_{m})\phi_{m}(x)\right]^2dx\\
& = \int E\left(\left[\sum_{m=0}^{\infty}(\alpha_{m}-\lambda_{m}a_{m})^2\phi_{m}(x)^2\right]+2 \sum_{m=0}^{\infty}\sum_{j=0}^{\infty}(\alpha_{m}-\lambda_{m}a_{m})(\alpha_{j}-\lambda_{j}a_{j})\phi_{m}(x)\phi_{j}(x)\right)dx\\
& = E\left(\left[\sum_{m=0}^{\infty}(\alpha_{m}-\lambda_{m}a_{m})^2\int\phi_{m}(x)^2dx\right]+2 \sum_{m=0}^{\infty}\sum_{j=0}^{\infty}(\alpha_{m}-\lambda_{m}a_{m})(\alpha_{j}-\lambda_{j}a_{j})\int\phi_{m}(x)\phi_{j}(x)dx\right)\\
& = \sum_{m=0}^{\infty}E(\alpha_{m}-\lambda_{m}a_{m})^2.
\end{split}
\end{equation*} \alpha_{m}=E\phi_{m}(x) \begin{equation}
\begin{split}
E(\alpha_m-\lambda_m a_m)^2 & = E(\alpha_m-\alpha_m \lambda_m+\alpha_m \lambda_m+\lambda_m a_m)^2\\
& = E[\alpha_{m}(1-\lambda_m)+\lambda_m(\alpha_m-a_m)]^2\\
& = E[\alpha_{m}^2(1-\lambda_m)^2+2\alpha_{m}(1-\lambda_m)\lambda_m(\alpha_m-a_m)+\lambda_m^2(\alpha_m-a_m)^2]\\
& = \alpha_{m}^2(1-\lambda_m)^2+ 2\alpha_{m}(1-\lambda_m)\lambda_mE(\alpha_m-a_m)+\lambda_m^2E(\alpha_m-a_m)^2.
\end{split}
\end{equation} \begin{equation}
\begin{split}
 E(\alpha_{m}-a_{m}) & = \alpha_{m}-Ea_{m}\\
& = \alpha_{m}-\frac{1}{n}\sum_{k=1}^{n}E\phi_{m}(x_k)\\
& = \alpha_{m}-\frac{1}{n}\sum_{k=1}^{n}\alpha_{m}\\
& = \alpha_{m}-\alpha_{m}=0.
\end{split}
\end{equation} \begin{equation}
 \sum_{m=1}^{\infty} E(\alpha_{m}-\lambda_{m}a_{m})^2=\sum_{m=1}^{\infty}\alpha_{m}^2(1-\lambda_{m})^2+\lambda_{m}^2E(\alpha_{m}-a_{m})^2.
\end{equation} \begin{equation}
  E(\alpha_{m}-a_{m})^2=\frac{1}{n}\text{var}(\phi_{m}(x)).
\end{equation}","['statistics', 'eigenvalues-eigenvectors', 'fourier-series', 'density-function', 'mean-square-error']"
19,Joint density of transformation,Joint density of transformation,,"Let $X, Y$ be two independent exponential random variables, and let $U = \frac{X}{Y}, V = X + Y$ . I am trying to prove that $U$ and $V$ are independent, so I computed their individual densities which yield $f_U(t) = \frac{ab}{(a t + b)^2}, f_V(t) = \frac{ab}{a +b}\left(e^{-bt}-e^{-at}\right)$ , where $a,b$ are the parameters of $X$ and $Y$ . How do I compute their joint density, and if it's not possible, is there any other way to prove independence?","Let be two independent exponential random variables, and let . I am trying to prove that and are independent, so I computed their individual densities which yield , where are the parameters of and . How do I compute their joint density, and if it's not possible, is there any other way to prove independence?","X, Y U = \frac{X}{Y}, V = X + Y U V f_U(t) = \frac{ab}{(a t + b)^2}, f_V(t) = \frac{ab}{a +b}\left(e^{-bt}-e^{-at}\right) a,b X Y","['probability', 'statistics', 'probability-distributions']"
20,Upper bounds on the Stirling approximation of binomial coefficients,Upper bounds on the Stirling approximation of binomial coefficients,,"The Stirling approximation for binomial coefficients gives $$ \log \binom{n+k}{k} \leq (n+k) \log (n+k) - n \log n - k \log k =: f(n, k) \text{.} $$ I want to obtain a nice upper bound on the right-hand side $f(n, k)$ to make it easier to handle (to be more specific, I want to use the resulting upper bounds to evaluate the integral $\int_0^1 \sqrt{f(n, 1/x)} \, dx$ ). A naive approach would be the following. Setting $g(x) = x \log x$ for $x > 0$ , we can rewrite $$ f(n, k) = g(n + k) - g(n) - g(k) \text{.} $$ Noting that $g$ is a convex function, we can use the Jensen inequality to get $$ g(n) + g(k) \geq 2 g\left( \frac{n + k}{2} \right) =  2 \cdot \frac{n + k}{2} \log \left( \frac{n + k}{2} \right) =  g(n + k) - (n + k) \log 2 \text{.} $$ Therefore we have $$ f(n, k) \leq (n + k) \log 2 \text{.} $$ However, this is too crude: the resulting bound is $$ \binom{n + k}{k} \leq 2^{n+k} $$ So what we have just done is nothing more than $$ \text{(# of ways to select $k$ items out of $n + k$)} \leq  \text{(# of ways to select some items out of $n + k$)} \text{.} $$ Question : Is there any sophisticated way of upper-bounding $f(n, k)$ ?","The Stirling approximation for binomial coefficients gives I want to obtain a nice upper bound on the right-hand side to make it easier to handle (to be more specific, I want to use the resulting upper bounds to evaluate the integral ). A naive approach would be the following. Setting for , we can rewrite Noting that is a convex function, we can use the Jensen inequality to get Therefore we have However, this is too crude: the resulting bound is So what we have just done is nothing more than Question : Is there any sophisticated way of upper-bounding ?","
\log \binom{n+k}{k} \leq (n+k) \log (n+k) - n \log n - k \log k =: f(n, k) \text{.}
 f(n, k) \int_0^1 \sqrt{f(n, 1/x)} \, dx g(x) = x \log x x > 0 
f(n, k) = g(n + k) - g(n) - g(k) \text{.}
 g 
g(n) + g(k) \geq 2 g\left( \frac{n + k}{2} \right) = 
2 \cdot \frac{n + k}{2} \log \left( \frac{n + k}{2} \right) = 
g(n + k) - (n + k) \log 2
\text{.}
 
f(n, k) \leq (n + k) \log 2 \text{.}
 
\binom{n + k}{k} \leq 2^{n+k}
 
\text{(# of ways to select k items out of n + k)}
\leq 
\text{(# of ways to select some items out of n + k)}
\text{.}
 f(n, k)","['probability', 'combinatorics', 'statistics']"
21,Variance of Order Statistics,Variance of Order Statistics,,"I have a question about bounding the variance of order statistics. Given that for $i \in \{1,\cdots,\lambda\}$ , denote $Bin(s,\frac{1}{n})$ to be a binomial random variable with success probability $\frac{1}{n}$ and $s$ independent experiments. Define $W_i=Bin(n-s,\frac{1}{n})-Bin(s,\frac{1}{n})$ , where $n \in \mathbb{N}$ is some constant w.r.t s and $\lambda$ . All $W_i$ are i.i.d random variables. Is there any estimate that I can use to upper bound the variance of the largest order statistics $Z= \max_{i \in [\lambda]}\{W_i\}$ , i.e. $Var(Z)\leq U$ ? I am aware that we can use $\max_{i \in [\lambda]}\{W_i\}\leq \sum W_i$ to bound the variance $Var(Z)\leq \sum Var(W_i)=\lambda * n \frac{1}{n}(1-\frac{1}{n})= \lambda(1-\frac{1}{n})$ . But I wonder whether we can derive any tighter upper bound in this case. So we can bound the variance within some lower order term in $\lambda$ or even constant $O(1)$ . Thank you!","I have a question about bounding the variance of order statistics. Given that for , denote to be a binomial random variable with success probability and independent experiments. Define , where is some constant w.r.t s and . All are i.i.d random variables. Is there any estimate that I can use to upper bound the variance of the largest order statistics , i.e. ? I am aware that we can use to bound the variance . But I wonder whether we can derive any tighter upper bound in this case. So we can bound the variance within some lower order term in or even constant . Thank you!","i \in \{1,\cdots,\lambda\} Bin(s,\frac{1}{n}) \frac{1}{n} s W_i=Bin(n-s,\frac{1}{n})-Bin(s,\frac{1}{n}) n \in \mathbb{N} \lambda W_i Z= \max_{i \in [\lambda]}\{W_i\} Var(Z)\leq U \max_{i \in [\lambda]}\{W_i\}\leq \sum W_i Var(Z)\leq \sum Var(W_i)=\lambda * n \frac{1}{n}(1-\frac{1}{n})= \lambda(1-\frac{1}{n}) \lambda O(1)","['probability', 'probability-theory', 'analysis', 'statistics', 'order-statistics']"
22,Hypergeometric distribution with multiple observations,Hypergeometric distribution with multiple observations,,"This is my maiden question on Math stack exchange so do forgive me if I am not following any community norms or not presenting my questions as clear as it should be. I am trying to find probabilities with hypergeometric distribution. I will be working with multiple random and independent observations being made at the same time and I am unclear of how to handle it in the manner that is presented to me. The usual probability mass function ("" PMF "") is this: $$P(x)=\frac{\binom{k}{x}\cdot\binom{N-k}{n-x}}{\binom{N}{n}}$$ For the purposes of this post, I shall provide a hypothetical question here to illustrate the issue, Suppose a certain disease affects 400 ( $k$ ) people in a population of 20,000 people ( $N$ ). If a random sample of 1,000 people ( $n$ ) is taken and tested without replacement what is the probability that exactly 20 ( $x$ ) of them have the disease if people were taken and tested, one at a time? 10 at a time? 7 at a time? For scenario 1 If I am making one observation at a time, I can proceed with using the PMF as per normal such that, $$P(x=20|N=20,000, n=1,000, k=400)$$ $$P(x=20)=\frac{\binom{400}{20}\cdot\binom{20,000-400}{1,000-20}}{\binom{20,000}{1,000}}$$ For scenario 2 If I am making 10 observations at a time, my understanding is that, all I would need to do is to divide all the variables $(x, N, n, k)$ by 10. This means that $P(x=20|N=20,000, n=1,000, k=400)$ adjusted for 10 events being observed at a time would give us, $$P(x=2|N=2,000, n=100, k=40)$$ $$P(x=2)=\frac{\binom{40}{2}\cdot\binom{2,000-40}{100-2}}{\binom{2,000}{100}}$$ For scenario 3 Now, this is where things get hairy. If I am making 7 observations at a time, I cannot simply divide all the variables by 7 like the way I did in scenario 2. I will have remainders for everything, especially for $n$ where I will have a remainder of 6 and I have no idea what to do with it. In summary I am asking whether, dividing all variables $(x, N, n, k)$ by the number of observations being made at the same time a mathematically sound way to handle multiple observations in hypergeometric distributions? (aka is my method in scenario 2 correct) if so, how do I go about handling remainders in $n$ ? how would you handle scenario 3? I have attempted to work with ChatGPT on this issue. However, it is, to say the least, rather unreliable at math. Thus, it took me some time to discover this community and to ask this question.","This is my maiden question on Math stack exchange so do forgive me if I am not following any community norms or not presenting my questions as clear as it should be. I am trying to find probabilities with hypergeometric distribution. I will be working with multiple random and independent observations being made at the same time and I am unclear of how to handle it in the manner that is presented to me. The usual probability mass function ("" PMF "") is this: For the purposes of this post, I shall provide a hypothetical question here to illustrate the issue, Suppose a certain disease affects 400 ( ) people in a population of 20,000 people ( ). If a random sample of 1,000 people ( ) is taken and tested without replacement what is the probability that exactly 20 ( ) of them have the disease if people were taken and tested, one at a time? 10 at a time? 7 at a time? For scenario 1 If I am making one observation at a time, I can proceed with using the PMF as per normal such that, For scenario 2 If I am making 10 observations at a time, my understanding is that, all I would need to do is to divide all the variables by 10. This means that adjusted for 10 events being observed at a time would give us, For scenario 3 Now, this is where things get hairy. If I am making 7 observations at a time, I cannot simply divide all the variables by 7 like the way I did in scenario 2. I will have remainders for everything, especially for where I will have a remainder of 6 and I have no idea what to do with it. In summary I am asking whether, dividing all variables by the number of observations being made at the same time a mathematically sound way to handle multiple observations in hypergeometric distributions? (aka is my method in scenario 2 correct) if so, how do I go about handling remainders in ? how would you handle scenario 3? I have attempted to work with ChatGPT on this issue. However, it is, to say the least, rather unreliable at math. Thus, it took me some time to discover this community and to ask this question.","P(x)=\frac{\binom{k}{x}\cdot\binom{N-k}{n-x}}{\binom{N}{n}} k N n x P(x=20|N=20,000, n=1,000, k=400) P(x=20)=\frac{\binom{400}{20}\cdot\binom{20,000-400}{1,000-20}}{\binom{20,000}{1,000}} (x, N, n, k) P(x=20|N=20,000, n=1,000, k=400) P(x=2|N=2,000, n=100, k=40) P(x=2)=\frac{\binom{40}{2}\cdot\binom{2,000-40}{100-2}}{\binom{2,000}{100}} n (x, N, n, k) n","['probability', 'statistics', 'probability-distributions']"
23,"Does $\text{cov}(\lVert X-X' \rVert, \lVert X-X'' \rVert) \geq 0$ hold for i.i.d. random vectors?",Does  hold for i.i.d. random vectors?,"\text{cov}(\lVert X-X' \rVert, \lVert X-X'' \rVert) \geq 0","Let $X$ , $X'$ , and $X''$ be i.i.d. random vectors taking values in $\mathbb{R}^N$ . Is it true that $$\text{cov}(\lVert X-X' \rVert, \lVert X-X'' \rVert) \geq 0?$$ My numerical simulations suggest that it is, but I have so far only been able to show the following: $\text{cov}(\lVert X \rVert, \lVert X \rVert) = \text{var} (\lVert X \rVert) \geq 0$ $\text{cov}(\lVert -X' \rVert, \lVert -X'' \rVert) = \text{cov}(\lVert X' \rVert, \lVert X'' \rVert) = 0$ $\text{cov}(X-X',X-X'') = \text{var}(X) \geq 0$ for $X, X', X''$ with dimension $1$","Let , , and be i.i.d. random vectors taking values in . Is it true that My numerical simulations suggest that it is, but I have so far only been able to show the following: for with dimension","X X' X'' \mathbb{R}^N \text{cov}(\lVert X-X' \rVert, \lVert X-X'' \rVert) \geq 0? \text{cov}(\lVert X \rVert, \lVert X \rVert) = \text{var} (\lVert X \rVert) \geq 0 \text{cov}(\lVert -X' \rVert, \lVert -X'' \rVert) = \text{cov}(\lVert X' \rVert, \lVert X'' \rVert) = 0 \text{cov}(X-X',X-X'') = \text{var}(X) \geq 0 X, X', X'' 1","['probability', 'statistics', 'inequality', 'random-variables', 'covariance']"
24,How to find the probability of the largest $k$ values from $n$ sorted stacks being in the top $m$ items from each stack?,How to find the probability of the largest  values from  sorted stacks being in the top  items from each stack?,k n m,Let’s say I have a set $U$ containing some values. I randomly distribute these values into $n$ stacks and sort each stack from largest to smallest. Then I take the top $m$ items from each stack to form a set $S$ . What is the probability the largest $k$ values in $U$ are also in $S$ ? I can see trivially that the probability is $1$ if $m=k$ but that’s as far as I’ve got.,Let’s say I have a set containing some values. I randomly distribute these values into stacks and sort each stack from largest to smallest. Then I take the top items from each stack to form a set . What is the probability the largest values in are also in ? I can see trivially that the probability is if but that’s as far as I’ve got.,U n m S k U S 1 m=k,['statistics']
25,"Compare the variances of $X^2$, $X$ and $\sqrt{X}$.","Compare the variances of ,  and .",X^2 X \sqrt{X},"Compare the variances of $X^2$ , $X$ and $\sqrt{X}$ . Is there a way to effectively compare sizes using the variance equation below? $$Var(𝑋)=𝐸[(𝑋−𝐸[𝑋])^2] = 𝐸[𝑋^2]−(𝐸[𝑋])^2$$","Compare the variances of , and . Is there a way to effectively compare sizes using the variance equation below?",X^2 X \sqrt{X} Var(𝑋)=𝐸[(𝑋−𝐸[𝑋])^2] = 𝐸[𝑋^2]−(𝐸[𝑋])^2,"['probability', 'probability-theory', 'statistics', 'variance']"
26,Spearman's rho for tied ranks,Spearman's rho for tied ranks,,I know how to prove that Spearman's $ \rho / r_s$ can be written as $r_s = 1-\frac{6\sum\limits_{i=1}^nd_i^2}{n(n^2-1)}$ with $d_i=R(x_i)-R(y_i)$ when there are no ties. Now I came across the formula for tied ranks: $r_s = 1-\frac{6\left(\sum\limits_{i=1}^nd_i^2+\sum\limits_{j=1}^n\frac{t_j^3-t_j}{12}\right)}{n(n^2-1)}$ where $t_j$ represents the $j^{th}$ tie length. (I found this formula at the following link: https://www.onlinemath4all.com/spearman-rank-correlation-coefficient.html ) Another version of this formula would be $r_s = \frac{\frac{n^3-n}{6}-\sum d_i^2 - \sum T_x -\sum T_y}{\sqrt{(\frac{n^3-n}{6}-2\sum T_x)(\frac{n^3-n}{6}-2\sum T_y)}}$ with $\sum T_x = \frac{\sum t_i^3-t_i}{12}$ and $\sum T_y = \frac{\sum t_i^3-t_i}{12}$ where $t_i$ is the number of groups the random variables $X$ and $Y$ tie respectively. (I found this formula at the following link: http://webspace.ship.edu/pgmarr/Geo441/Lectures/Lec%2011%20-%20Spearman%27s%20and%20Cramer%27s%20Correlation.pdf ) I'm unable to prove either of both formulas for tied ranks. I tried to rewrite $R(x_i)$ in a different way but always failed to obtain the formula. My question therefore is if anyone has a hint on how to prove any of the two formulas or maybe if someone has a complete proof? Thank you very much in advance for any help.,I know how to prove that Spearman's can be written as with when there are no ties. Now I came across the formula for tied ranks: where represents the tie length. (I found this formula at the following link: https://www.onlinemath4all.com/spearman-rank-correlation-coefficient.html ) Another version of this formula would be with and where is the number of groups the random variables and tie respectively. (I found this formula at the following link: http://webspace.ship.edu/pgmarr/Geo441/Lectures/Lec%2011%20-%20Spearman%27s%20and%20Cramer%27s%20Correlation.pdf ) I'm unable to prove either of both formulas for tied ranks. I tried to rewrite in a different way but always failed to obtain the formula. My question therefore is if anyone has a hint on how to prove any of the two formulas or maybe if someone has a complete proof? Thank you very much in advance for any help., \rho / r_s r_s = 1-\frac{6\sum\limits_{i=1}^nd_i^2}{n(n^2-1)} d_i=R(x_i)-R(y_i) r_s = 1-\frac{6\left(\sum\limits_{i=1}^nd_i^2+\sum\limits_{j=1}^n\frac{t_j^3-t_j}{12}\right)}{n(n^2-1)} t_j j^{th} r_s = \frac{\frac{n^3-n}{6}-\sum d_i^2 - \sum T_x -\sum T_y}{\sqrt{(\frac{n^3-n}{6}-2\sum T_x)(\frac{n^3-n}{6}-2\sum T_y)}} \sum T_x = \frac{\sum t_i^3-t_i}{12} \sum T_y = \frac{\sum t_i^3-t_i}{12} t_i X Y R(x_i),"['statistics', 'correlation']"
27,Interpreting Gaussian measurements in terms of information theory,Interpreting Gaussian measurements in terms of information theory,,"I have a quantity that I want to measure, and I have obtained three sets of measurements A, B, and C, each represented by their mean $\mu_A$ , $\mu_B$ , $\mu_C$ , and standard deviation $\sigma_A$ , $\sigma_B$ , $\sigma_C$ , respectively. Assuming that the measurements follow a Gaussian distribution, I want to understand which set of measurements contains more information about the true value of the quantity being measured from an information theory perspective. To give some context, let me provide numerical examples. Let's say that the true value of the quantity being measured is $x = 10$ . Set A has measurements with mean $\mu_A = 9.9$ and $\sigma_A = 0.1$ , set B has mean $\mu_B = 10$ and $\sigma_B = 1.0$ , and set C mean $\mu_C = 8$ and $\sigma_C = 10$ . It's intuitive to say that it's set A due to the low standard deviation (assuming there's no bias), but how can I quantify the amount of information that each set of measurements provides about the true value (perhaps as $-\log_2 p(X)$ )? Is there any way to compare the information content of the sets A, B, and C? Thank you very much for your help!","I have a quantity that I want to measure, and I have obtained three sets of measurements A, B, and C, each represented by their mean , , , and standard deviation , , , respectively. Assuming that the measurements follow a Gaussian distribution, I want to understand which set of measurements contains more information about the true value of the quantity being measured from an information theory perspective. To give some context, let me provide numerical examples. Let's say that the true value of the quantity being measured is . Set A has measurements with mean and , set B has mean and , and set C mean and . It's intuitive to say that it's set A due to the low standard deviation (assuming there's no bias), but how can I quantify the amount of information that each set of measurements provides about the true value (perhaps as )? Is there any way to compare the information content of the sets A, B, and C? Thank you very much for your help!",\mu_A \mu_B \mu_C \sigma_A \sigma_B \sigma_C x = 10 \mu_A = 9.9 \sigma_A = 0.1 \mu_B = 10 \sigma_B = 1.0 \mu_C = 8 \sigma_C = 10 -\log_2 p(X),"['statistics', 'information-theory', 'entropy', 'descriptive-statistics']"
28,Reference on the sum of absolute differences between $n$ samples from a random variable,Reference on the sum of absolute differences between  samples from a random variable,n,"Let $X_1, X_2,\ldots X_n$ be $n$ samples taken of a random variable with a given distribution (so in particular it is i.i.d.). Is there literature on or a name for the random variable defined by $$Y = \sum_{i=1}^{n-1}\left|X_i-X_{i+1}\right|?$$ If necessary feel free to add further assumptions, such as $X_i$ being non-negative, or the $X_i$ being drawn from specific distributions.","Let be samples taken of a random variable with a given distribution (so in particular it is i.i.d.). Is there literature on or a name for the random variable defined by If necessary feel free to add further assumptions, such as being non-negative, or the being drawn from specific distributions.","X_1, X_2,\ldots X_n n Y = \sum_{i=1}^{n-1}\left|X_i-X_{i+1}\right|? X_i X_i","['probability', 'statistics', 'probability-distributions', 'reference-request', 'order-statistics']"
29,Brownian motion (Wiener process) as a random function,Brownian motion (Wiener process) as a random function,,"In many articles concerned with functional data analysis, it is considered a regressor $X$ which is a random variable valued in some infinite dimensional set $F$ equipped with (semi/pseudo) metric $d$ . The assumption that $F$ is infinite-dimensional and equipped with (semi/pseudo) metric $d$ makes sense if I think that it is some class of functions (e.g., $C[0,1]$ or $L^2[0,1]$ ). Question If $X:=W=\{W_t, t\in [0,1]\}$ is the standard Wiener process on $[0,1]$ , what the set $F$ should exactly be? Comments Following Bosq (2000) p.15-16 , let $W=\{W_t, t\in T\}$ be a family of random variables defined on $(\Omega,\mathcal A,P)$ with values in a measurable space $(E,\mathcal B)$ . In order to interpret $W$ as a random function, consider the space $E^T$ of mappings from $T$ to $E$ equipped with the $\sigma$ -algebra $\mathcal S=\sigma(\pi_t,t\in T)$ where $\pi_t:E^T\to E$ is defined by $\pi_t(x)=x_t $ for $x\in E^T$ . Because $W_t^{-1}(B)=W_t^{-1}(\pi_t^{-1}(B))$ for all $B\in\mathcal B, t\in T,$ he inferred that $W$ is $\mathcal A - \mathcal S$ measurable. In this sense, $W$ can be seem as a random function. Back to my case, it seems that the set $E^T$ of mappings is directly related to the set $F$ thaI mentioned in the begining. (Is $F=L^2[0,1]$ ?) I'm not much experienced in this field. Can someone give me directions?","In many articles concerned with functional data analysis, it is considered a regressor which is a random variable valued in some infinite dimensional set equipped with (semi/pseudo) metric . The assumption that is infinite-dimensional and equipped with (semi/pseudo) metric makes sense if I think that it is some class of functions (e.g., or ). Question If is the standard Wiener process on , what the set should exactly be? Comments Following Bosq (2000) p.15-16 , let be a family of random variables defined on with values in a measurable space . In order to interpret as a random function, consider the space of mappings from to equipped with the -algebra where is defined by for . Because for all he inferred that is measurable. In this sense, can be seem as a random function. Back to my case, it seems that the set of mappings is directly related to the set thaI mentioned in the begining. (Is ?) I'm not much experienced in this field. Can someone give me directions?","X F d F d C[0,1] L^2[0,1] X:=W=\{W_t, t\in [0,1]\} [0,1] F W=\{W_t, t\in T\} (\Omega,\mathcal A,P) (E,\mathcal B) W E^T T E \sigma \mathcal S=\sigma(\pi_t,t\in T) \pi_t:E^T\to E \pi_t(x)=x_t  x\in E^T W_t^{-1}(B)=W_t^{-1}(\pi_t^{-1}(B)) B\in\mathcal B, t\in T, W \mathcal A - \mathcal S W E^T F F=L^2[0,1]","['functional-analysis', 'measure-theory', 'statistics', 'stochastic-processes']"
30,Computation of Statistical Curvature for a Distribution [closed],Computation of Statistical Curvature for a Distribution [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed last year . Improve this question $\newcommand{\bracket}[1]{\left ( #1 \right )}$ $\newcommand{\curly}[1]{\left \{ #1 \right \} }$ $\newcommand{\squared}[1]{\left [ #1 \right ]}$ $\newcommand\tab[1][1cm]{\hspace*{#1}} $ This post is purely about checking my computation . I am getting a result I am not supposed to get , which means there must be a computation mistake but I really need help finding it . To answer this post, all you need to do is to follow through my calculation and find out the first mistake you see. (Update: the LaTeX newcommand issue and the font issue has been completely resolved.) Fix positive integer $d$ and real number $\theta$ . Define function $f: \mathbb{R}^d \to \mathbb{R}$ by setting, for every $x = (x_1, \cdots, x_d)$ : \begin{equation*} f(x) = C \exp \curly{- \sum_{i=1}^d (x_i-\theta)^4} \end{equation*} Here $C$ is a constant such that $f$ becomes a probability density function with respect to the Lebesgue measure. The integral calculator shows that: \begin{equation*} \int_{\mathbb{R}} \exp(-x^4)\, dx = \frac{1}{2} \Gamma \bracket{\frac{1}{4}} \end{equation*} \begin{equation*} \int_{\mathbb{R}} x^3\exp(-x^4)\,dx = 0 \end{equation*} \begin{equation*} \int_{\mathbb{R}} x^2\exp(-x^4)\,dx = \frac{1}{2} \Gamma \bracket{\frac{3}{4}} \end{equation*} \begin{equation*} \int_{\mathbb{R}} x^4\exp(-x^4)\, dx = \frac{1}{8} \Gamma \bracket{\frac{1}{4}} \end{equation*} \begin{equation*} \int_{\mathbb{R}} x^6\exp(-x^4)\, dx = \frac{3}{8} \Gamma \bracket{\frac{3}{4}} \end{equation*} Therefore, $C = \bracket{\frac{1}{2} \Gamma \bracket{\frac{1}{4}}}^{-d}$ . Next, define: \begin{equation*} l_{\theta}(x) = \ln (C) - \sum_{i=1}^d (x_i-\theta)^4  \end{equation*} \begin{equation*} \dot{l_{\theta}}(x) = 4 \sum_{i=1}^d (x_i-\theta)^3 \end{equation*} \begin{equation*} \ddot{l_{\theta}}(x) = - 12 \sum_{i=1}^d (x_i - \theta)^2 \end{equation*} And we define the matrix: \begin{equation*}     M_{\theta} =     \begin{bmatrix}         \mathbb{E}_{\theta} \squared{\dot{l_{\theta}}^2} & \mathbb{E}_{\theta} \squared{\dot{l_{\theta}}\ddot{l_{\theta}}} \\         \mathbb{E}_{\theta} \squared{\dot{l_{\theta}}\ddot{l_{\theta}}} & \mathbb{E}_{\theta} \squared{\ddot{l_{\theta}}^2} - \iota_{\theta}^2      \end{bmatrix} \end{equation*} Here $\iota_{\theta} = \mathbb{E}_{\theta} \squared{\dot{l_{\theta}}^2}$ . Finally, the statistical curvature $\gamma_{\theta}$ is defined as: \begin{equation*}     \gamma_{\theta} = \sqrt{\frac{\det{M_{\theta}}}{\iota_{\theta}^3}} =     \sqrt{\frac{\mathbb{E}_{\theta}\squared{\ddot{l_{\theta}}^2}}{\iota_{\theta}^2}      - \frac{\mathbb{E}_{\theta}^2\squared{\dot{l_{\theta}} \ddot{l_{\theta}}}}{\iota_{\theta}^3}- 1} \end{equation*} Our goal is to compute the curvature for this $f$ . We will be repeatedly using the formula: \begin{equation*} \bracket{\sum_{i=1}^da_i}^2 = \sum_{i=1}^da_i^2 + 2\sum_{i=1}^d \sum_{j=1}^{i-1} a_ia_j \end{equation*} We have: \begin{equation*}     \begin{split}     & \iota_{\theta} = \mathbb{E}_{\theta} \squared{\dot{l_{\theta}}^2}      = \int_{\mathbb{R}^d} \bracket{4 \sum_{i=1}^d (x_i-\theta)^3}^2 C \exp{- \sum_{i=1}^d (x_i-\theta)^4} dx     \\ & = 16 C \curly{\sum_{i=1}^d \int_{\mathbb{R}^d} x_i^6 \exp{- \sum_{i=1}^d x_i^4}  dx +     2 \sum_{i=1}^d \sum_{j=1}^{i-1}\int_{\mathbb{R}^d} x_i^3x_j^3 \exp{- \sum_{i=1}^d x_i^4}  dx }     \\ & = 16 C d \bracket{\frac{1}{2} \Gamma \bracket{\frac{1}{4}}}^{d-1} \frac{3}{8} \Gamma \bracket{\frac{3}{4}}     = 12d \bracket{\Gamma \bracket{\frac{1}{4}}}^{-1}\Gamma \bracket{\frac{3}{4}}     \end{split} \end{equation*} Clearly, $\mathbb{E}_{\theta} \squared{\dot{l_{\theta}} \ddot{l_{\theta}} } = 0$ . Finally: \begin{equation*}     \begin{split}         & \mathbb{E}_{\theta} \squared{\ddot{l_{\theta}}^2} =         \mathbb{E}_{\theta} \squared{ \curly{- 12 \sum_{i=1}^d (x_i - \theta)^2 }^2 }         \\ & = 144C \curly{\sum_{i=1}^d \int_{\mathbb{R}^d} x_i^4 \exp{-\sum_{i=1}^d x_i^4} dx          + 2\sum_{i=1}^d \sum_{j=1}^{i-1} \int_{\mathbb{R}^d} x_i^2x_j^2 \exp{-\sum_{i=1}^d x_i^4} dx}         \\ & = 144C \curly{d \bracket{\frac{1}{2} \Gamma\bracket{\frac{1}{4}}}^{d-1} \frac{1}{8} \Gamma \bracket{\frac{1}{4}} +         d(d-1) \bracket{\frac{1}{2} \Gamma\bracket{\frac{1}{4}}}^{d-2} \bracket{\frac{1}{2} \Gamma \bracket{\frac{3}{4}}}^2}         \\ & = 36d + 144d(d-1) \bracket{\Gamma\bracket{\frac{1}{4}}}^{-2}\bracket{\Gamma\bracket{\frac{3}{4}}}^{2}     \end{split} \end{equation*} We see that the last entry is: \begin{equation*}     \mathbb{E}_{\theta} \squared{\ddot{l_{\theta}}^2} - \iota_{\theta}^2       = 36d - 144d \bracket{\Gamma\bracket{\frac{1}{4}}}^{-2}\bracket{\Gamma\bracket{\frac{3}{4}}}^{2} \end{equation*} Now we have a problem. The covariance matrix $M_{\theta}$ is positive-semidefinite. The statistical curvature should be a real number. However, my computation shows that this is not the case for $f$ . \begin{equation*}     M_{\theta} =     \begin{bmatrix}         12d \bracket{\Gamma \bracket{\frac{1}{4}}}^{-1}\Gamma \bracket{\frac{3}{4}} & 0 \\         0 &  36d - 144d \bracket{\Gamma\bracket{\frac{1}{4}}}^{-2}\bracket{\Gamma\bracket{\frac{3}{4}}}^{2}     \end{bmatrix} \end{equation*} \begin{equation*}     \gamma_{\theta} = \frac{\sqrt{\bracket{\Gamma \bracket{\frac{1}{4}}}^2 - 4 \bracket{\Gamma \bracket{\frac{3}{4}}}^2}}     {2 \Gamma \bracket{\frac{3}{4}}}  \end{equation*} What went wrong ?","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed last year . Improve this question This post is purely about checking my computation . I am getting a result I am not supposed to get , which means there must be a computation mistake but I really need help finding it . To answer this post, all you need to do is to follow through my calculation and find out the first mistake you see. (Update: the LaTeX newcommand issue and the font issue has been completely resolved.) Fix positive integer and real number . Define function by setting, for every : Here is a constant such that becomes a probability density function with respect to the Lebesgue measure. The integral calculator shows that: Therefore, . Next, define: And we define the matrix: Here . Finally, the statistical curvature is defined as: Our goal is to compute the curvature for this . We will be repeatedly using the formula: We have: Clearly, . Finally: We see that the last entry is: Now we have a problem. The covariance matrix is positive-semidefinite. The statistical curvature should be a real number. However, my computation shows that this is not the case for . What went wrong ?","\newcommand{\bracket}[1]{\left ( #1 \right )} \newcommand{\curly}[1]{\left \{ #1 \right \} } \newcommand{\squared}[1]{\left [ #1 \right ]} \newcommand\tab[1][1cm]{\hspace*{#1}}  d \theta f: \mathbb{R}^d \to \mathbb{R} x = (x_1, \cdots, x_d) \begin{equation*}
f(x) = C \exp \curly{- \sum_{i=1}^d (x_i-\theta)^4}
\end{equation*} C f \begin{equation*}
\int_{\mathbb{R}} \exp(-x^4)\, dx = \frac{1}{2} \Gamma \bracket{\frac{1}{4}}
\end{equation*} \begin{equation*}
\int_{\mathbb{R}} x^3\exp(-x^4)\,dx = 0
\end{equation*} \begin{equation*}
\int_{\mathbb{R}} x^2\exp(-x^4)\,dx = \frac{1}{2} \Gamma \bracket{\frac{3}{4}}
\end{equation*} \begin{equation*}
\int_{\mathbb{R}} x^4\exp(-x^4)\, dx = \frac{1}{8} \Gamma \bracket{\frac{1}{4}}
\end{equation*} \begin{equation*}
\int_{\mathbb{R}} x^6\exp(-x^4)\, dx = \frac{3}{8} \Gamma \bracket{\frac{3}{4}}
\end{equation*} C = \bracket{\frac{1}{2} \Gamma \bracket{\frac{1}{4}}}^{-d} \begin{equation*}
l_{\theta}(x) = \ln (C) - \sum_{i=1}^d (x_i-\theta)^4 
\end{equation*} \begin{equation*}
\dot{l_{\theta}}(x) = 4 \sum_{i=1}^d (x_i-\theta)^3
\end{equation*} \begin{equation*}
\ddot{l_{\theta}}(x) = - 12 \sum_{i=1}^d (x_i - \theta)^2
\end{equation*} \begin{equation*}
    M_{\theta} =
    \begin{bmatrix}
        \mathbb{E}_{\theta} \squared{\dot{l_{\theta}}^2} & \mathbb{E}_{\theta} \squared{\dot{l_{\theta}}\ddot{l_{\theta}}} \\
        \mathbb{E}_{\theta} \squared{\dot{l_{\theta}}\ddot{l_{\theta}}} & \mathbb{E}_{\theta} \squared{\ddot{l_{\theta}}^2} - \iota_{\theta}^2 
    \end{bmatrix}
\end{equation*} \iota_{\theta} = \mathbb{E}_{\theta} \squared{\dot{l_{\theta}}^2} \gamma_{\theta} \begin{equation*}
    \gamma_{\theta} = \sqrt{\frac{\det{M_{\theta}}}{\iota_{\theta}^3}} =
    \sqrt{\frac{\mathbb{E}_{\theta}\squared{\ddot{l_{\theta}}^2}}{\iota_{\theta}^2} 
    - \frac{\mathbb{E}_{\theta}^2\squared{\dot{l_{\theta}} \ddot{l_{\theta}}}}{\iota_{\theta}^3}- 1}
\end{equation*} f \begin{equation*}
\bracket{\sum_{i=1}^da_i}^2 = \sum_{i=1}^da_i^2 + 2\sum_{i=1}^d \sum_{j=1}^{i-1} a_ia_j
\end{equation*} \begin{equation*}
    \begin{split}
    & \iota_{\theta} = \mathbb{E}_{\theta} \squared{\dot{l_{\theta}}^2} 
    = \int_{\mathbb{R}^d} \bracket{4 \sum_{i=1}^d (x_i-\theta)^3}^2 C \exp{- \sum_{i=1}^d (x_i-\theta)^4} dx
    \\ & = 16 C \curly{\sum_{i=1}^d \int_{\mathbb{R}^d} x_i^6 \exp{- \sum_{i=1}^d x_i^4}  dx +
    2 \sum_{i=1}^d \sum_{j=1}^{i-1}\int_{\mathbb{R}^d} x_i^3x_j^3 \exp{- \sum_{i=1}^d x_i^4}  dx }
    \\ & = 16 C d \bracket{\frac{1}{2} \Gamma \bracket{\frac{1}{4}}}^{d-1} \frac{3}{8} \Gamma \bracket{\frac{3}{4}}
    = 12d \bracket{\Gamma \bracket{\frac{1}{4}}}^{-1}\Gamma \bracket{\frac{3}{4}}
    \end{split}
\end{equation*} \mathbb{E}_{\theta} \squared{\dot{l_{\theta}} \ddot{l_{\theta}} } = 0 \begin{equation*}
    \begin{split}
        & \mathbb{E}_{\theta} \squared{\ddot{l_{\theta}}^2} =
        \mathbb{E}_{\theta} \squared{ \curly{- 12 \sum_{i=1}^d (x_i - \theta)^2 }^2 }
        \\ & = 144C \curly{\sum_{i=1}^d \int_{\mathbb{R}^d} x_i^4 \exp{-\sum_{i=1}^d x_i^4} dx 
        + 2\sum_{i=1}^d \sum_{j=1}^{i-1} \int_{\mathbb{R}^d} x_i^2x_j^2 \exp{-\sum_{i=1}^d x_i^4} dx}
        \\ & = 144C \curly{d \bracket{\frac{1}{2} \Gamma\bracket{\frac{1}{4}}}^{d-1} \frac{1}{8} \Gamma \bracket{\frac{1}{4}} +
        d(d-1) \bracket{\frac{1}{2} \Gamma\bracket{\frac{1}{4}}}^{d-2} \bracket{\frac{1}{2} \Gamma \bracket{\frac{3}{4}}}^2}
        \\ & = 36d + 144d(d-1) \bracket{\Gamma\bracket{\frac{1}{4}}}^{-2}\bracket{\Gamma\bracket{\frac{3}{4}}}^{2}
    \end{split}
\end{equation*} \begin{equation*}
    \mathbb{E}_{\theta} \squared{\ddot{l_{\theta}}^2} - \iota_{\theta}^2  
    = 36d - 144d \bracket{\Gamma\bracket{\frac{1}{4}}}^{-2}\bracket{\Gamma\bracket{\frac{3}{4}}}^{2}
\end{equation*} M_{\theta} f \begin{equation*}
    M_{\theta} =
    \begin{bmatrix}
        12d \bracket{\Gamma \bracket{\frac{1}{4}}}^{-1}\Gamma \bracket{\frac{3}{4}} & 0 \\
        0 &  36d - 144d \bracket{\Gamma\bracket{\frac{1}{4}}}^{-2}\bracket{\Gamma\bracket{\frac{3}{4}}}^{2}
    \end{bmatrix}
\end{equation*} \begin{equation*}
    \gamma_{\theta} = \frac{\sqrt{\bracket{\Gamma \bracket{\frac{1}{4}}}^2 - 4 \bracket{\Gamma \bracket{\frac{3}{4}}}^2}}
    {2 \Gamma \bracket{\frac{3}{4}}} 
\end{equation*}","['probability-theory', 'statistics', 'solution-verification', 'statistical-inference']"
31,Convergence of the Expectation-Maximization algorithm,Convergence of the Expectation-Maximization algorithm,,"Studying the Expectation-Maximization algorithm, I noticed that I couldn't find any proof that the parameters actually converge, nor that the limit is a local extremum of the likelihood (or even just a point where the gradient vanishes). The proofs that I found use the argument that at each step the likelihood increases, and thus as it is a monotonically increasing bounded sequence it must converge. But my 2 questions remain unanswered: Why does the convergence of the values of the likelihood function imply the convergence of the parameters? Assuming the parameters converge, why do they converge to a local extremum of the likelihood function? I would love to see a proof, or even a good reference will do. Thanks","Studying the Expectation-Maximization algorithm, I noticed that I couldn't find any proof that the parameters actually converge, nor that the limit is a local extremum of the likelihood (or even just a point where the gradient vanishes). The proofs that I found use the argument that at each step the likelihood increases, and thus as it is a monotonically increasing bounded sequence it must converge. But my 2 questions remain unanswered: Why does the convergence of the values of the likelihood function imply the convergence of the parameters? Assuming the parameters converge, why do they converge to a local extremum of the likelihood function? I would love to see a proof, or even a good reference will do. Thanks",,"['statistics', 'machine-learning', 'expectation-maximization']"
32,Ask minimal sufficient statistics for double-exponential distribution,Ask minimal sufficient statistics for double-exponential distribution,,"Let $X_1,...,X_n$ be a random sample from double-exponential $(\mu, 1), \mu \in \mathcal{R}$ , i.e., the joint pdf of $X$ is $$f_\mu (x)= \frac{1}{2^n} \exp(-\Sigma_{i=1}^n |x_i-\mu|)$$ Consider $\mathcal{F}_0=\{f_0,f_1,...,f_n \}$ , where each $f_j$ is the pdf with $\mu=j,j=,1,...,n$ . By Theorem 6.6.5a in Casella and Berger's statistical inference textbook, a minimal sufficient statistics for $\mathcal{F}_0$ is $$T=(\exp(\Sigma_{i=1}^n |X_i|-   \Sigma_{i=1}^n |X_i-j|),j=1,...,n)$$ which is equivalent to $$U=(\Sigma_{i=1}^n |X_i|-   \Sigma_{i=1}^n |X_i-j|,j=1,...,n)$$ We can further show that $U$ is equivalent to $S$ , the set of order  statistics. Since $S$ is sufficient, by Theorem 6.6.5b, $S, U$ and $T$ are all minimal sufficient. I need the help that how I can justify the step "" $U$ is equivalent to $S$ , the set of order  statistics.""","Let be a random sample from double-exponential , i.e., the joint pdf of is Consider , where each is the pdf with . By Theorem 6.6.5a in Casella and Berger's statistical inference textbook, a minimal sufficient statistics for is which is equivalent to We can further show that is equivalent to , the set of order  statistics. Since is sufficient, by Theorem 6.6.5b, and are all minimal sufficient. I need the help that how I can justify the step "" is equivalent to , the set of order  statistics.""","X_1,...,X_n (\mu, 1), \mu \in \mathcal{R} X f_\mu (x)= \frac{1}{2^n} \exp(-\Sigma_{i=1}^n |x_i-\mu|) \mathcal{F}_0=\{f_0,f_1,...,f_n \} f_j \mu=j,j=,1,...,n \mathcal{F}_0 T=(\exp(\Sigma_{i=1}^n |X_i|-   \Sigma_{i=1}^n |X_i-j|),j=1,...,n) U=(\Sigma_{i=1}^n |X_i|-   \Sigma_{i=1}^n |X_i-j|,j=1,...,n) U S S S, U T U S","['probability', 'statistics']"
33,Variance of mean from a model $X_t=\mu+a_t-\theta a_{t-1}$,Variance of mean from a model,X_t=\mu+a_t-\theta a_{t-1},"Let $X_t$ be generated by the following model: $$X_t=\mu+a_t-\theta a_{t-1}$$ where $a_t\sim N(0,1)$ i.i.d. Let $\bar{X}=(\sum_{t=1}^nX_t)/n$ . Then $\operatorname{var}((\sum_{t=1}^nX_t)/n)=\frac{1}{n^2}\sum_{t=1}^n\operatorname{var}(X_t)+\frac{2}{n^2}\sum_{t=1}^n\sum_{j=1}^{t-1}\operatorname{cov}(X_t,X_j)$ . I am not sure how the last sentence comes out. Can anyone explain a bit?",Let be generated by the following model: where i.i.d. Let . Then . I am not sure how the last sentence comes out. Can anyone explain a bit?,"X_t X_t=\mu+a_t-\theta a_{t-1} a_t\sim N(0,1) \bar{X}=(\sum_{t=1}^nX_t)/n \operatorname{var}((\sum_{t=1}^nX_t)/n)=\frac{1}{n^2}\sum_{t=1}^n\operatorname{var}(X_t)+\frac{2}{n^2}\sum_{t=1}^n\sum_{j=1}^{t-1}\operatorname{cov}(X_t,X_j)",['probability-theory']
34,limit of perturbed rank deficient matrix as perturbation goes to zero,limit of perturbed rank deficient matrix as perturbation goes to zero,,Given a $p \times p$ matrix $X^TX$ such that rank $(X^TX) = r<p$ . How can I evaluate the following limit: $$ \lim_{\lambda \to 0} (X^TX + \lambda I)^{-1}. $$,Given a matrix such that rank . How can I evaluate the following limit:,"p \times p X^TX (X^TX) = r<p 
\lim_{\lambda \to 0} (X^TX + \lambda I)^{-1}.
","['linear-algebra', 'matrices', 'limits', 'statistics']"
35,"Find the value of the $5$th decile, $D_5$.","Find the value of the th decile, .",5 D_5,"For the data set: $$18,15,12,6,8,2,3,5,20,10$$ Find the value of the $5$ th decile, $D_5$ . I computed this 2 ways and each time I got a different answer. If the sample size is $n$ , then the rank of the $m$ th decile is $\frac{mn}{10}$ . So in our case it would be $\frac{5(10)}{10}=5$ . So it would be the fifth value in the data after we arrange them from the smallest to the largest. $$2,3,5,6,8,10,12,15,18,20$$ So it would be $D_5=8$ . We know that $D_5=Q_2$ , where $Q_2$ is the second quartile. $Q_2$ is the value with $50%$ of the data below it, so it is the mean of the data. In this case the mean is $9$ So is it $8$ or $9$ ? Any help would be appreciated. Thanks!","For the data set: Find the value of the th decile, . I computed this 2 ways and each time I got a different answer. If the sample size is , then the rank of the th decile is . So in our case it would be . So it would be the fifth value in the data after we arrange them from the smallest to the largest. So it would be . We know that , where is the second quartile. is the value with of the data below it, so it is the mean of the data. In this case the mean is So is it or ? Any help would be appreciated. Thanks!","18,15,12,6,8,2,3,5,20,10 5 D_5 n m \frac{mn}{10} \frac{5(10)}{10}=5 2,3,5,6,8,10,12,15,18,20 D_5=8 D_5=Q_2 Q_2 Q_2 50% 9 8 9","['statistics', 'quantile']"
36,Rigorous introduction to statistics for self study,Rigorous introduction to statistics for self study,,"I want to start learning statistics. I have taken proof-based Calculus 1 and 2, as well as two proof-based courses in Linear Algebra (1 and 2). What is a good introductory-level (but rigorous enough) book to start self-learning statistics? Also, if you know about any other resources (other than books) to help my self study, you can recommend them. Thanks in advance!","I want to start learning statistics. I have taken proof-based Calculus 1 and 2, as well as two proof-based courses in Linear Algebra (1 and 2). What is a good introductory-level (but rigorous enough) book to start self-learning statistics? Also, if you know about any other resources (other than books) to help my self study, you can recommend them. Thanks in advance!",,"['statistics', 'reference-request', 'soft-question', 'self-learning', 'book-recommendation']"
37,How to illustrate both of distributions are the same,How to illustrate both of distributions are the same,,"Suppose $X_1,X_2,\ldots,X_{n};X^{'}_1,X^{'}_2,\ldots,X^{'}_{n}$ are all independent identically distributed (i.i.d.) random variables defined on the probability space $(\Omega,\mathcal{F},\mathbf{P})$ and having the common distribution $F$ . $\mathbb{I}_{(-\infty,t]}(x)$ be the indicator for the interval $-\infty<x \le t$ . Let $F_{n}$ denote the emprical distribution function of $X_1,X_2,\ldots,X_{n},$ given by $$F_{n}(t)=F_{n}(t,\omega)=\frac{1}{n}\sum_{k=1}^{n}\mathbb{I}_{(-\infty,t]}(X_{k}(\omega))=\frac{1}{n}\sum_{k=1}^{n}\mathbb{I}_{ [ X_{k}\le t]}, \quad \forall t\in \mathbf{R}.$$ Similarly, $$F^{'}_{n}(t)=F^{'}_{n}(t,\omega)=\frac{1}{n}\sum_{k=1}^{n}\mathbb{I}_{(-\infty,t]}(X^{'}_{k}(\omega))=\frac{1}{n}\sum_{k=1}^{n}\mathbb{I}_{ [ X^{'}_{k}\le t]}, \quad \forall t\in \mathbf{R}.$$ Thus we have $$F_{n}(t)-F^{'}_{n}(t)=\frac{1}{n}\sum_{k=1}^{n}\left(\mathbb{I}_{ [ X_{k}\le t]}-\mathbb{I}_{ [ X^{'}_{k}\le t]}\right), \quad \forall t\in \mathbf{R}.$$ For any fixed $t\in \mathbf{R},$ $$\mathbb{I}_{ [ X_{k}\le t]}-\mathbb{I}_{ [ X^{'}_{k}\le t]}=\begin{cases}  -1& \text{with probability}\quad F(t)(1-F(t)) ,\\   0& \text{with probability}\quad 1-2F(t)(1-F(t)), \\   1& \text{with probability}\quad F(t)(1-F(t)). \end{cases}$$ also $\mathbb{I}_{ [ X^{'}_{k}\le t]}-\mathbb{I}_{ [ X_{k}\le t]}$ as well. I know that for any fixed $t\in\mathbf{R},$ the distribution of $$D_{n}(t,\omega)=\frac{1}{n}\left |\sum_{k=1}^{n}\left(\mathbb{I}_{[ X_{k}\le t]}-\mathbb{I}_{ [ X^{'}_{k}\le t]}\right)\right |$$ is the same as the distribution of $$D^{'}_{n}(t,\omega)=\frac{1}{n}\left |\sum_{k=1}^{n}\left (\mathbb{I}_{[ X^{'}_{k}\le t]}-\mathbb{I}_{ [ X_{k}\le t]}\right)\right|.$$ But I don't understand that the distribution of $\displaystyle\sup_{t\in\mathbf {R}}D_{n}(t,\omega)$ is the same as the distribution of $\displaystyle\sup_{t\in\mathbf {R}}D^{'}_{n}(t,\omega).$ How to illustrate this rigorously?","Suppose are all independent identically distributed (i.i.d.) random variables defined on the probability space and having the common distribution . be the indicator for the interval . Let denote the emprical distribution function of given by Similarly, Thus we have For any fixed also as well. I know that for any fixed the distribution of is the same as the distribution of But I don't understand that the distribution of is the same as the distribution of How to illustrate this rigorously?","X_1,X_2,\ldots,X_{n};X^{'}_1,X^{'}_2,\ldots,X^{'}_{n} (\Omega,\mathcal{F},\mathbf{P}) F \mathbb{I}_{(-\infty,t]}(x) -\infty<x \le t F_{n} X_1,X_2,\ldots,X_{n}, F_{n}(t)=F_{n}(t,\omega)=\frac{1}{n}\sum_{k=1}^{n}\mathbb{I}_{(-\infty,t]}(X_{k}(\omega))=\frac{1}{n}\sum_{k=1}^{n}\mathbb{I}_{ [ X_{k}\le t]}, \quad \forall t\in \mathbf{R}. F^{'}_{n}(t)=F^{'}_{n}(t,\omega)=\frac{1}{n}\sum_{k=1}^{n}\mathbb{I}_{(-\infty,t]}(X^{'}_{k}(\omega))=\frac{1}{n}\sum_{k=1}^{n}\mathbb{I}_{ [ X^{'}_{k}\le t]}, \quad \forall t\in \mathbf{R}. F_{n}(t)-F^{'}_{n}(t)=\frac{1}{n}\sum_{k=1}^{n}\left(\mathbb{I}_{ [ X_{k}\le t]}-\mathbb{I}_{ [ X^{'}_{k}\le t]}\right), \quad \forall t\in \mathbf{R}. t\in \mathbf{R}, \mathbb{I}_{ [ X_{k}\le t]}-\mathbb{I}_{ [ X^{'}_{k}\le t]}=\begin{cases}
 -1& \text{with probability}\quad F(t)(1-F(t)) ,\\
  0& \text{with probability}\quad 1-2F(t)(1-F(t)), \\
  1& \text{with probability}\quad F(t)(1-F(t)).
\end{cases} \mathbb{I}_{ [ X^{'}_{k}\le t]}-\mathbb{I}_{ [ X_{k}\le t]} t\in\mathbf{R}, D_{n}(t,\omega)=\frac{1}{n}\left |\sum_{k=1}^{n}\left(\mathbb{I}_{[ X_{k}\le t]}-\mathbb{I}_{ [ X^{'}_{k}\le t]}\right)\right | D^{'}_{n}(t,\omega)=\frac{1}{n}\left |\sum_{k=1}^{n}\left (\mathbb{I}_{[ X^{'}_{k}\le t]}-\mathbb{I}_{ [ X_{k}\le t]}\right)\right|. \displaystyle\sup_{t\in\mathbf {R}}D_{n}(t,\omega) \displaystyle\sup_{t\in\mathbf {R}}D^{'}_{n}(t,\omega).","['probability-theory', 'statistics', 'probability-distributions']"
38,Non-existence of Lebesgue probability densities,Non-existence of Lebesgue probability densities,,"A standard result taught in mathematical statistics courses is that the multivariate gaussian only has a density if the covariance matrix is non singular: i.e. if $X \sim N_p(\mu, \Sigma)$ and $\Sigma$ is nonsingular, then the (Lebesgue) density is given by $$ f(x) = (2\pi)^{-p/2} |\Sigma|^{-1/2} \exp (-1/2 (x-\mu)^T \Sigma (x-\mu)). $$ Given an i.i.d. sample from a univariate Gaussian: $X_1,\dots,X_n \sim N(\mu, 1)$ , and taking $\bar{X}$ be the sample average, it is straight forward to show that $(X_1,\dots,X_n)|\bar{X} \sim N(\bar{X} 1_n, I_n - n^{-1}1_n1_n^T) $ where $1_n$ is the $n$ -dimensional vector of ones, and $I_n$ is the $n\times n$ identity matrix. Here it is straight forward to see that the covariance matrix is rank deficient and so $X|\bar{X}$ does not have a Lebesgue density. My question is: more generally (in non Gaussian settings say), how can I verify whether a Lebesgue density exists for a given random vector? Is it sufficient compute the covariance matrix and verify that it is full rank? or are there cases where the covariance is full rank but the Lebesgue density still does not exist?","A standard result taught in mathematical statistics courses is that the multivariate gaussian only has a density if the covariance matrix is non singular: i.e. if and is nonsingular, then the (Lebesgue) density is given by Given an i.i.d. sample from a univariate Gaussian: , and taking be the sample average, it is straight forward to show that where is the -dimensional vector of ones, and is the identity matrix. Here it is straight forward to see that the covariance matrix is rank deficient and so does not have a Lebesgue density. My question is: more generally (in non Gaussian settings say), how can I verify whether a Lebesgue density exists for a given random vector? Is it sufficient compute the covariance matrix and verify that it is full rank? or are there cases where the covariance is full rank but the Lebesgue density still does not exist?","X \sim N_p(\mu, \Sigma) \Sigma 
f(x) = (2\pi)^{-p/2} |\Sigma|^{-1/2} \exp (-1/2 (x-\mu)^T \Sigma (x-\mu)).
 X_1,\dots,X_n \sim N(\mu, 1) \bar{X} (X_1,\dots,X_n)|\bar{X} \sim N(\bar{X} 1_n, I_n - n^{-1}1_n1_n^T)  1_n n I_n n\times n X|\bar{X}","['probability', 'probability-theory', 'statistics', 'statistical-inference', 'density-function']"
39,How to find variance in Poisson?,How to find variance in Poisson?,,The number of ice creams sold per hour from Mr Fishy’s van is observed to be a Poisson random variable with parameter 𝜆=8. Each ice cream costs two pounds but Mr Fishy has to pay five pounds per hour for the pitch. What is the variance of his hourly profit (measured in pounds and ignoring all other income and expenses)?,The number of ice creams sold per hour from Mr Fishy’s van is observed to be a Poisson random variable with parameter 𝜆=8. Each ice cream costs two pounds but Mr Fishy has to pay five pounds per hour for the pitch. What is the variance of his hourly profit (measured in pounds and ignoring all other income and expenses)?,,"['statistics', 'poisson-distribution']"
40,Does partial maximization/minimization always give the the same result as global optimization?,Does partial maximization/minimization always give the the same result as global optimization?,,"Suppose I want to optimize the function,f(x), where x is a vector. x can be seperated into two sub-vectors, $(x)=(x_{1},x_{2})$ . I can first partially optimize $x_{1}$ , and treat $x_{2}$ as constant, so that I get the optimal $x^{*}_{1}$ as a function of $x_{2}$ .Then I can optimize the object function as a function of $x_{2}, i.e. f(x^{*}_{1}(x_{2}),x_{2})$ . My question is does this always give the same result, as I directly optimize f(x) over x? Can this be proved? The question arised from the maximum likelihood estimation of normal distribution, where $\sigma$ and $\mu$ are all unknown. We always calculate $\hat{\mu}$ first, then express $\hat{\sigma}$ as a function of $\hat{\mu}$ . I want to know does this procedure can be applied to any kind of problem?","Suppose I want to optimize the function,f(x), where x is a vector. x can be seperated into two sub-vectors, . I can first partially optimize , and treat as constant, so that I get the optimal as a function of .Then I can optimize the object function as a function of . My question is does this always give the same result, as I directly optimize f(x) over x? Can this be proved? The question arised from the maximum likelihood estimation of normal distribution, where and are all unknown. We always calculate first, then express as a function of . I want to know does this procedure can be applied to any kind of problem?","(x)=(x_{1},x_{2}) x_{1} x_{2} x^{*}_{1} x_{2} x_{2}, i.e. f(x^{*}_{1}(x_{2}),x_{2}) \sigma \mu \hat{\mu} \hat{\sigma} \hat{\mu}","['statistics', 'optimization', 'maximum-likelihood']"
41,Asymptotic Confidence Interval for ML-Estimate of Gamma-distribution,Asymptotic Confidence Interval for ML-Estimate of Gamma-distribution,,"Assume I have a sample of $n \in \mathbb{N}$ data points $x_1,\ldots, x_n$ , which are asummed to come from iid drawings of a Gamma-distribution. I may assume the shape paramter $k\in\mathbb{R}_+$ and the sample mean $\bar{x}$ , but not the sample variance, are known. To avoid confusion the Gamma(k, $\theta$ ) density function used here is $f(x) = \frac{1}{\Gamma(k) \theta^k} x^{k-1} e^{-\frac{x}{\theta}}.$ I am trying to calculate the Maximum-Likelihood Estimator $\hat{\theta}$ and then find an asymptotic 95% Confidence Interval for that estimate. The MLE was no problem but I'm not sure about the asymptotic CI and would be very grateful, for corrections if I made a mistake there. The likelihood function has the form $$\mathcal{L} = \prod_{i=1}^{n} f(x_i, \theta) = \left(\frac{1}{\Gamma(k)\theta^k}\right)^n \prod_{i=1}^{n} x_i^{k-1} e^{-\frac{x_i}{\theta}}.$$ From there we get the log-likelihood $$ \ell = \ln(\mathcal{L}) = (k-1) \sum_{i=1}^{n} \ln(x_i) - \sum_{i=1}^{n} \frac{x_i}{\theta} - n\cdot \ln(\Gamma(k)) - nk\cdot\ln(\theta).$$ Differentiating with respect to $\theta$ and then solving for it yieds the Maximum-Likelihood Estimator $$\hat{\theta} = \frac{\bar{x}}{k}.$$ To find now an asymptotic 95%-Confidence Interval for $\hat{\theta}$ I first calculated the mean and variance of the Gamma(k, $\theta$ ) distribution, which are $$\mathbb{E}[X] = k\theta, \quad\quad \text{Var}(X)= k^2 \theta.$$ Given that the sample variance is unknown, I first calculated the variance of my estimate and then an estiamte of that variance: $\begin{align*} 			\text{Var}(\hat{\theta}) =& Var(\frac{1}{k} \frac{1}{n} \sum_{i=1}^{n}X_i) \\ 			=& \left(\frac{1}{kn} \right)^2 \sum_{i=1}^{n} \text{Var}(X_i) \\ 			\overset{iid}{=}& \left(\frac{1}{kn} \right)^2 \cdot n \cdot k\theta^2 \\ 			=& \frac{\theta^2}{kn} \; =: \sigma^2 \\ 			\hat{\sigma^2} =& \frac{\hat{\theta^2}}{kn} \\ 			=& \frac{(\frac{\bar{x}}{k})^2}{kn} \\ 			=& \frac{1}{kn} \cdot \frac{1}{k^2} \frac{1}{n^2} \left(\sum_{i=1}^{n}x_i\right)^2 \\ 			=& \frac{1}{k^3} \cdot \frac{1}{n^3} \left(\sum_{i=1}^{n}x_i\right)^2 \\ 			=& \frac{1}{k^3n} \bar{x}^2 		\end{align*}$ From that I have constructed the asymptotic Confidence Interval $\begin{array}{lrcccl} &z_{0.025} &\leq& \frac{\hat{\theta} - \mathbb{E}\left[\hat{\theta}\right]}{ \sqrt{ \frac{\hat{\sigma^2}}{n} } } &\leq& z_{0.975} \\ \Leftrightarrow & \hat{\theta} - z_{0.975} \sqrt{ \frac{\hat{\sigma^2}}{n} } &\leq& \theta &\leq& \hat{\theta} + z_{0.975} \sqrt{ \frac{\hat{\sigma^2}}{n} } \\ \Leftrightarrow & \frac{\bar{x}}{k} - 1.96 \sqrt{ \frac{\bar{x}^2}{k^3n^2}} &\leq& \theta &\leq& \frac{\bar{x}}{k} - 1.96 \sqrt{ \frac{\bar{x}^2}{k^3n^2}} \end{array}$ Although I can't find any mistakes (though admittedly I'm also not an expert in statistics), the results from calculating $\hat{\sigma^2}$ on, seem a bit strange to me. As I said, I would be very glad if someone could check whether I indeed made a mistake or if this can be solved somewhat more elegantly.","Assume I have a sample of data points , which are asummed to come from iid drawings of a Gamma-distribution. I may assume the shape paramter and the sample mean , but not the sample variance, are known. To avoid confusion the Gamma(k, ) density function used here is I am trying to calculate the Maximum-Likelihood Estimator and then find an asymptotic 95% Confidence Interval for that estimate. The MLE was no problem but I'm not sure about the asymptotic CI and would be very grateful, for corrections if I made a mistake there. The likelihood function has the form From there we get the log-likelihood Differentiating with respect to and then solving for it yieds the Maximum-Likelihood Estimator To find now an asymptotic 95%-Confidence Interval for I first calculated the mean and variance of the Gamma(k, ) distribution, which are Given that the sample variance is unknown, I first calculated the variance of my estimate and then an estiamte of that variance: From that I have constructed the asymptotic Confidence Interval Although I can't find any mistakes (though admittedly I'm also not an expert in statistics), the results from calculating on, seem a bit strange to me. As I said, I would be very glad if someone could check whether I indeed made a mistake or if this can be solved somewhat more elegantly.","n \in \mathbb{N} x_1,\ldots, x_n k\in\mathbb{R}_+ \bar{x} \theta f(x) = \frac{1}{\Gamma(k) \theta^k} x^{k-1} e^{-\frac{x}{\theta}}. \hat{\theta} \mathcal{L} = \prod_{i=1}^{n} f(x_i, \theta) = \left(\frac{1}{\Gamma(k)\theta^k}\right)^n \prod_{i=1}^{n} x_i^{k-1} e^{-\frac{x_i}{\theta}}.  \ell = \ln(\mathcal{L}) = (k-1) \sum_{i=1}^{n} \ln(x_i) - \sum_{i=1}^{n} \frac{x_i}{\theta} - n\cdot \ln(\Gamma(k)) - nk\cdot\ln(\theta). \theta \hat{\theta} = \frac{\bar{x}}{k}. \hat{\theta} \theta \mathbb{E}[X] = k\theta, \quad\quad \text{Var}(X)= k^2 \theta. \begin{align*}
			\text{Var}(\hat{\theta}) =& Var(\frac{1}{k} \frac{1}{n} \sum_{i=1}^{n}X_i) \\
			=& \left(\frac{1}{kn} \right)^2 \sum_{i=1}^{n} \text{Var}(X_i) \\
			\overset{iid}{=}& \left(\frac{1}{kn} \right)^2 \cdot n \cdot k\theta^2 \\
			=& \frac{\theta^2}{kn} \; =: \sigma^2 \\
			\hat{\sigma^2} =& \frac{\hat{\theta^2}}{kn} \\
			=& \frac{(\frac{\bar{x}}{k})^2}{kn} \\
			=& \frac{1}{kn} \cdot \frac{1}{k^2} \frac{1}{n^2} \left(\sum_{i=1}^{n}x_i\right)^2 \\
			=& \frac{1}{k^3} \cdot \frac{1}{n^3} \left(\sum_{i=1}^{n}x_i\right)^2 \\
			=& \frac{1}{k^3n} \bar{x}^2
		\end{align*} \begin{array}{lrcccl}
&z_{0.025} &\leq& \frac{\hat{\theta} - \mathbb{E}\left[\hat{\theta}\right]}{ \sqrt{ \frac{\hat{\sigma^2}}{n} } } &\leq& z_{0.975} \\
\Leftrightarrow & \hat{\theta} - z_{0.975} \sqrt{ \frac{\hat{\sigma^2}}{n} } &\leq& \theta &\leq& \hat{\theta} + z_{0.975} \sqrt{ \frac{\hat{\sigma^2}}{n} } \\
\Leftrightarrow & \frac{\bar{x}}{k} - 1.96 \sqrt{ \frac{\bar{x}^2}{k^3n^2}} &\leq& \theta &\leq& \frac{\bar{x}}{k} - 1.96 \sqrt{ \frac{\bar{x}^2}{k^3n^2}}
\end{array} \hat{\sigma^2}","['statistics', 'maximum-likelihood', 'confidence-interval']"
42,Intuition for Local vs. Global notions of Metric Entropy in Statistics,Intuition for Local vs. Global notions of Metric Entropy in Statistics,,"I am looking for intuition regarding the following statement on page 4 of this paper by Gassiat and Van Handel: However, in finite dimensional settings, global entropy bounds are known to yield sub-optimal results, and here local entropy bounds are essential to obtain optimal convergence rates of estimators. The paper itself and the cited references all show this claim generally by arguing that using global entropy bounds yield suboptimal rates, and then showing that the localized approach achieves the optimal/better rates. So from that perspective, the statement is clear, and I guess it is enough justification for the claim. What I am looking for though is some intuition on why this happens to be the case. What is it (from an intuitive perspective) about localized analyses that makes them sharper? How should one think about localized notions of dimension as opposed to global ones? I'm also interested in how other branches of mathematics (analysis, geometry etc) approach this question. Some background: For a subset $T$ of a metric space $(X,d)$ , the covering number $N(T,\epsilon)$ is the smallest possible number of $\epsilon$ -balls that can cover $T$ . Formally, $$ N(T,\epsilon) := \inf \{ n:  \exists \{x_i\}_{i=1}^n \subset X: T \subset \bigcup_{i=1}^n B_{x_i}(\epsilon)   \} $$ where $B_{x_i}(\epsilon)$ is the ball (in the metric $d$ ) that is centered at $x_i$ and has radius $\epsilon$ . The metric entropy is $\log N(T, \epsilon)$ . In a statistical setting, covering numbers are useful for establishing uniform laws. For example, suppose $X, X_1,\dots, X_n$ are i.i.d. random vectors and $F$ is a class of functions, results of the following flavor are common: $$ \mathbb{P} \left( \sup_{f \in F} \left | \frac{1}{n} \sum_{i=1}^n f(X_i) - \mathbb{E} [f(X)] \right | > \epsilon \right) \le g( N(F, \epsilon'), ...), $$ where $g$ is some function of the covering number and possibly other parameters of the problem. The result basically says that if the function class $F$ is not too large/complex (as measured by the covering number), then with high probability (over the sample), the worst case fluctuation of an empirical average from it's true mean is not too large. Other related notions here are the Rademacher complexity, and VC dimension, or if $F$ is finite, then we can use the cardinality of $F$ . Localization: A localized covering number is given by $$ N(T \cap B_{t_0} (\delta), \epsilon), $$ where $t_0 \in T$ is a fixed point. Generally, $t_0$ is taken to be the 'true' parameter/function that generated the data, say $f^*$ , and so the RHS of the above bound becomes something like: $$ g'( N(F \cap B_{f^*} (\delta), \epsilon), ...). $$ for some different function $g'$ . This generally yields better (smaller) upper bounds than in the non-localized analyses. This style of analysis has become popular in the statistics literature over the last 15-20 years, for example this paper uses a localized version of the Rademacher complexity .","I am looking for intuition regarding the following statement on page 4 of this paper by Gassiat and Van Handel: However, in finite dimensional settings, global entropy bounds are known to yield sub-optimal results, and here local entropy bounds are essential to obtain optimal convergence rates of estimators. The paper itself and the cited references all show this claim generally by arguing that using global entropy bounds yield suboptimal rates, and then showing that the localized approach achieves the optimal/better rates. So from that perspective, the statement is clear, and I guess it is enough justification for the claim. What I am looking for though is some intuition on why this happens to be the case. What is it (from an intuitive perspective) about localized analyses that makes them sharper? How should one think about localized notions of dimension as opposed to global ones? I'm also interested in how other branches of mathematics (analysis, geometry etc) approach this question. Some background: For a subset of a metric space , the covering number is the smallest possible number of -balls that can cover . Formally, where is the ball (in the metric ) that is centered at and has radius . The metric entropy is . In a statistical setting, covering numbers are useful for establishing uniform laws. For example, suppose are i.i.d. random vectors and is a class of functions, results of the following flavor are common: where is some function of the covering number and possibly other parameters of the problem. The result basically says that if the function class is not too large/complex (as measured by the covering number), then with high probability (over the sample), the worst case fluctuation of an empirical average from it's true mean is not too large. Other related notions here are the Rademacher complexity, and VC dimension, or if is finite, then we can use the cardinality of . Localization: A localized covering number is given by where is a fixed point. Generally, is taken to be the 'true' parameter/function that generated the data, say , and so the RHS of the above bound becomes something like: for some different function . This generally yields better (smaller) upper bounds than in the non-localized analyses. This style of analysis has become popular in the statistics literature over the last 15-20 years, for example this paper uses a localized version of the Rademacher complexity .","T (X,d) N(T,\epsilon) \epsilon T 
N(T,\epsilon) := \inf \{ n:  \exists \{x_i\}_{i=1}^n \subset X: T \subset \bigcup_{i=1}^n B_{x_i}(\epsilon) 
 \}
 B_{x_i}(\epsilon) d x_i \epsilon \log N(T, \epsilon) X, X_1,\dots, X_n F 
\mathbb{P} \left( \sup_{f \in F} \left | \frac{1}{n} \sum_{i=1}^n f(X_i) - \mathbb{E} [f(X)] \right | > \epsilon \right) \le g( N(F, \epsilon'), ...),
 g F F F 
N(T \cap B_{t_0} (\delta), \epsilon),
 t_0 \in T t_0 f^* 
g'( N(F \cap B_{f^*} (\delta), \epsilon), ...).
 g'","['probability', 'geometry', 'analysis', 'statistics', 'machine-learning']"
43,"Kalman Filtering the Vasicek Model, are there different Kalman Filters for the same application? [closed]","Kalman Filtering the Vasicek Model, are there different Kalman Filters for the same application? [closed]",,"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed last year . Improve this question While studying parameter estimation in affine term structure models, I stumbeled across two papers. Affine Term-Structure Models: Theory and Implementation by David Bolder (2001) https://www.researchgate.net/publication/4744752_Affine_Term-Structure_Models_Theory_and_Implementation Calibration of the Vasicek Model of Interest rates Using Bicriteria Optimization by Jasurkova and Stehlikova (2020) http://www.iam.fmph.uniba.sk/amuc/ojs/index.php/algoritmy/article/view/1585 In both papers, a Kalman filter is implemented for the Vasicek model. In Bolder's work, for a 3-factor Vasicek model, and in Jasurkova and Stehlikova's work, a 1-factor Vasicek model. However, in my opinion, both methods should be independent of the number of factors. But upon closer inspection, there are a few differences, in addition to some different writing styles. When both present the necessary steps for implementing the Kalman filter, there are some discrepancies: -In the first and second step, everythink agrees in both papers. When moving to the third step, however, things differ: Bolder writes in equation (74) the following: $var[y_{t_i} \vert \mathcal{F}_{t_{i}}] = (I-K_{t_i}H)var[y_{t_i} \vert \mathcal{F}_{t_{i-1}}]$ whereas Jasurkova and Stehlikova state that: (page 214) $Var[r_{t_i} \vert \mathcal{F}_{t_{i}}] = (I-K_{t_i}H)Var[R_{t_i} \vert \mathcal{F}_{t_{i-1}}]$ the small $y$ in Bolder's work corresponds to the small $r$ , which are in both cases the short rates. And for the bond rates Bolder writes $z_{t_i}$ corresponding to $R_{t_i}$ in the work from Jasurkova and Stehlikova. Proceeding to step 4, when the state vector/variable is updated things continue to differ: Bolder writes: $\mathbb{E}[y_{t_{i+1}} \vert \mathcal{F}_{t_{i}}] = C + F\mathbb{E}[y_{t_{i}} \vert \mathcal{F}_{t_{i}}]$ In  the other paper it is written that: $\mathbb{E}[r_{t_{i+1}} \vert \mathcal{F}_{t_{i+1}}] = C + F\mathbb{E}[r_{t_{i}} \vert \mathcal{F}_{t_{i}}]$ and for the conditional variance: $var[y_{t_{i+1}} \vert \mathcal{F}_{t_{i}}] = var[y_{t_{i}} \vert \mathcal{F}_{t_{i-1}}]-Fvar[y_{t_{i}} \vert \mathcal{F}_{t_{i}}]F^T + Q$ $Var[r_{t_{i+1}} \vert \mathcal{F}_{t_{i}}] = FVar[r_{t_{i}} \vert \mathcal{F}_{t_{i}}]F^T + Q$ Additionally, the construction of the Likelihood function differs, beside the fact that Bolder uses the log-likelihood function: Log-likelihood function by Bolder (equation (77)): $l(\theta) = - \frac{nNln(2\pi)}{2}-\frac{1}{2} \sum_{i=1}^N [ln(det(var[y_{t_{i}} \vert \mathcal{F}_{t_{i-1}}])) + \zeta_{t_i}^{T}(var[y_{t_{i}} \vert \mathcal{F}_{t_{i-1}}]^{-1}\zeta_{t_i}]$ The Likelihood function by Jasurkova and Stehlikova: $\mathcal{L}(\kappa,\theta,\sigma,\lambda) = \prod_{i=1}^n \frac{1}{(2 \pi )^{\frac{m}{2}} \vert Var[R_{t_i} \vert \mathcal{F}_{t_{i-1}}] \vert ^{\frac{1}{2}} } e^{-\frac{1}{2} \zeta_{t_i}^{T}Var[R_{t_i} \vert \mathcal{F}_{t_{i-1}}]^{-1}\zeta_{t_i}}$ In total, these differences should result in a completely different likelihood function (beside the log) and therefore also in a different output of the Kalman filter. My question now is whether there is a mistake in one of the papers? Or are there different Kalman filters that can explain these differences?","Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed last year . Improve this question While studying parameter estimation in affine term structure models, I stumbeled across two papers. Affine Term-Structure Models: Theory and Implementation by David Bolder (2001) https://www.researchgate.net/publication/4744752_Affine_Term-Structure_Models_Theory_and_Implementation Calibration of the Vasicek Model of Interest rates Using Bicriteria Optimization by Jasurkova and Stehlikova (2020) http://www.iam.fmph.uniba.sk/amuc/ojs/index.php/algoritmy/article/view/1585 In both papers, a Kalman filter is implemented for the Vasicek model. In Bolder's work, for a 3-factor Vasicek model, and in Jasurkova and Stehlikova's work, a 1-factor Vasicek model. However, in my opinion, both methods should be independent of the number of factors. But upon closer inspection, there are a few differences, in addition to some different writing styles. When both present the necessary steps for implementing the Kalman filter, there are some discrepancies: -In the first and second step, everythink agrees in both papers. When moving to the third step, however, things differ: Bolder writes in equation (74) the following: whereas Jasurkova and Stehlikova state that: (page 214) the small in Bolder's work corresponds to the small , which are in both cases the short rates. And for the bond rates Bolder writes corresponding to in the work from Jasurkova and Stehlikova. Proceeding to step 4, when the state vector/variable is updated things continue to differ: Bolder writes: In  the other paper it is written that: and for the conditional variance: Additionally, the construction of the Likelihood function differs, beside the fact that Bolder uses the log-likelihood function: Log-likelihood function by Bolder (equation (77)): The Likelihood function by Jasurkova and Stehlikova: In total, these differences should result in a completely different likelihood function (beside the log) and therefore also in a different output of the Kalman filter. My question now is whether there is a mistake in one of the papers? Or are there different Kalman filters that can explain these differences?","var[y_{t_i} \vert \mathcal{F}_{t_{i}}] = (I-K_{t_i}H)var[y_{t_i} \vert \mathcal{F}_{t_{i-1}}] Var[r_{t_i} \vert \mathcal{F}_{t_{i}}] = (I-K_{t_i}H)Var[R_{t_i} \vert \mathcal{F}_{t_{i-1}}] y r z_{t_i} R_{t_i} \mathbb{E}[y_{t_{i+1}} \vert \mathcal{F}_{t_{i}}] = C + F\mathbb{E}[y_{t_{i}} \vert \mathcal{F}_{t_{i}}] \mathbb{E}[r_{t_{i+1}} \vert \mathcal{F}_{t_{i+1}}] = C + F\mathbb{E}[r_{t_{i}} \vert \mathcal{F}_{t_{i}}] var[y_{t_{i+1}} \vert \mathcal{F}_{t_{i}}] = var[y_{t_{i}} \vert \mathcal{F}_{t_{i-1}}]-Fvar[y_{t_{i}} \vert \mathcal{F}_{t_{i}}]F^T + Q Var[r_{t_{i+1}} \vert \mathcal{F}_{t_{i}}] = FVar[r_{t_{i}} \vert \mathcal{F}_{t_{i}}]F^T + Q l(\theta) = - \frac{nNln(2\pi)}{2}-\frac{1}{2} \sum_{i=1}^N [ln(det(var[y_{t_{i}} \vert \mathcal{F}_{t_{i-1}}])) + \zeta_{t_i}^{T}(var[y_{t_{i}} \vert \mathcal{F}_{t_{i-1}}]^{-1}\zeta_{t_i}] \mathcal{L}(\kappa,\theta,\sigma,\lambda) = \prod_{i=1}^n \frac{1}{(2 \pi )^{\frac{m}{2}} \vert Var[R_{t_i} \vert \mathcal{F}_{t_{i-1}}] \vert ^{\frac{1}{2}} } e^{-\frac{1}{2} \zeta_{t_i}^{T}Var[R_{t_i} \vert \mathcal{F}_{t_{i-1}}]^{-1}\zeta_{t_i}}","['statistics', 'stochastic-processes', 'maximum-likelihood', 'kalman-filter', 'stochastic-programming']"
44,Conditional Second Moments of Multivariate Normal Variable on Binary Vectors,Conditional Second Moments of Multivariate Normal Variable on Binary Vectors,,"Suppose we observe a binary table $Y \in \mathbb R^{N \times G}$ , corresponding to $N$ observations of $G$ dimensional binary vectors $Y_1, \cdots, Y_n$ . We imagine each vector $Y_i$ is generated from an unobserved multivariate normal vector $w_i \in \mathbb R^{k}$ through the following process: $W_i \sim N(0, I_k)$ , where $I_k$ is the k-dimensional identity matrix. $U_i = BW_i$ , where $B \in \mathbb R^{G \times K}$ is known. So $U_i$ is $G$ dimensional $Y_i \sim \text{Bernoulli}(\sigma(U_i))$ , where $\sigma(x)= \frac{1}{1+e^{-x}}$ is the sigmoid(logistic) function applying to $U_i$ component-wise. Now denote $W= [W_1^T, \cdots, W_n^{T}] \in \mathbb R^{N \times K}$ , and I am interested in computing the conditional second moments of $W$ on Y, e.g. : $$\mathbb E[W^{T}W |Y]$$ Here is my current approach: To proceed the computation, I think it would be easier to write $$\mathbb E[W^{T}W |Y] = E[W|Y]^{T} E[W|Y] + \text{Cov}(W|Y)$$ To compute $E[W|Y]$ ,  we just need to run a series of penalized logistic regressions to compute its posterior mean, as $B$ is known. However, I find it difficult to compute the conditional covariance of $W_i$ on $Y_i$ . If $Y_i$ is also normal, $W_i$ and $Y_i$ would be jointly Gaussian, and we can compute the conditional variance using the conditional variance formula for Gaussian. Is there an easy way to compute this entity when $Y_i$ is discrete? Thank you so much and happy holidays!","Suppose we observe a binary table , corresponding to observations of dimensional binary vectors . We imagine each vector is generated from an unobserved multivariate normal vector through the following process: , where is the k-dimensional identity matrix. , where is known. So is dimensional , where is the sigmoid(logistic) function applying to component-wise. Now denote , and I am interested in computing the conditional second moments of on Y, e.g. : Here is my current approach: To proceed the computation, I think it would be easier to write To compute ,  we just need to run a series of penalized logistic regressions to compute its posterior mean, as is known. However, I find it difficult to compute the conditional covariance of on . If is also normal, and would be jointly Gaussian, and we can compute the conditional variance using the conditional variance formula for Gaussian. Is there an easy way to compute this entity when is discrete? Thank you so much and happy holidays!","Y \in \mathbb R^{N \times G} N G Y_1, \cdots, Y_n Y_i w_i \in \mathbb R^{k} W_i \sim N(0, I_k) I_k U_i = BW_i B \in \mathbb R^{G \times K} U_i G Y_i \sim \text{Bernoulli}(\sigma(U_i)) \sigma(x)= \frac{1}{1+e^{-x}} U_i W= [W_1^T, \cdots, W_n^{T}] \in \mathbb R^{N \times K} W \mathbb E[W^{T}W |Y] \mathbb E[W^{T}W |Y] = E[W|Y]^{T} E[W|Y] + \text{Cov}(W|Y) E[W|Y] B W_i Y_i Y_i W_i Y_i Y_i","['statistics', 'conditional-probability', 'machine-learning', 'covariance', 'bayesian']"
45,Questions about the relation between convergence in distribution and convergence in probability,Questions about the relation between convergence in distribution and convergence in probability,,"I have two sequences of random variables $\{ X_n\}$ and $\{Y_n \}$ . I know that $X_n \to^d D, Y_n \to^d D$ . Can I conclude that $X_n - Y_n \to^p 0$ ? If I cannot, what other conditions do I need for the conclusion to hold? Thanks.","I have two sequences of random variables and . I know that . Can I conclude that ? If I cannot, what other conditions do I need for the conclusion to hold? Thanks.","\{ X_n\} \{Y_n \} X_n \to^d D, Y_n \to^d D X_n - Y_n \to^p 0","['probability', 'statistics', 'statistical-inference']"
46,Deterministic Simpson's Paradox Antidote,Deterministic Simpson's Paradox Antidote,,"Suppose I have eight positive numbers $a_i,b_i,c_i,d_i$ for $i=1,2$ satisfying $$\frac{a_i}{b_i}\le \frac{c_i}{d_i}\hspace{1in}(1)$$ I'm looking for additional conditions that will ensure \begin{align}\frac{a_1+a_2}{b_1+b_2}\le\frac{c_1+c_2}{d_1+d_2} \hspace{1in}(*)\end{align} I found something nice but perhaps not tight enough. I'm hoping to use any slack in equations (1) to tighten (2) and (3) below. Claim : For (*) to hold, it is sufficient that $$\frac{a_1}{b_1}\le\frac{a_2}{b_2}\hspace{1in}(2)$$ and $$\frac{d_1}{b_1}\le\frac{d_2}{b_2}\hspace{1in}(3)$$ Pf : Start by subtracting the two inequalities in (1), $$\frac{a_2}{b_2}-\frac{c_1}{d_1} \le \frac{c_2}{d_2}-\frac{a_1}{b_1}$$ Since the right side is positive (due to combining (1) and (2)), we may multiply by $d_1b_2\le b_1d_2$ (assumed true), \begin{align*} a_2d_1-c_1b_2\le c_2b_1-a_1d_2\\ \end{align*} Add in $a_1d_1\le c_1b_1$ and $a_2d_2\le c_2b_2$ then factor, \begin{align*} a_1d_1+a_2d_2+d_1a_2+a_1d_2\le& b_1c_2+c_1b_2+c_1b_1+c_2b_2\\ (a_1+a_2)(d_1+d_2) \le & (b_1+b_2)(c_1+c_2)\\ \frac{a_1+a_2}{b_1+b_2}\le &\frac{c_1+c_2}{d_1+d_2} \end{align*} Note, I did not require $a_i,c_i>0$ .","Suppose I have eight positive numbers for satisfying I'm looking for additional conditions that will ensure I found something nice but perhaps not tight enough. I'm hoping to use any slack in equations (1) to tighten (2) and (3) below. Claim : For (*) to hold, it is sufficient that and Pf : Start by subtracting the two inequalities in (1), Since the right side is positive (due to combining (1) and (2)), we may multiply by (assumed true), Add in and then factor, Note, I did not require .","a_i,b_i,c_i,d_i i=1,2 \frac{a_i}{b_i}\le \frac{c_i}{d_i}\hspace{1in}(1) \begin{align}\frac{a_1+a_2}{b_1+b_2}\le\frac{c_1+c_2}{d_1+d_2} \hspace{1in}(*)\end{align} \frac{a_1}{b_1}\le\frac{a_2}{b_2}\hspace{1in}(2) \frac{d_1}{b_1}\le\frac{d_2}{b_2}\hspace{1in}(3) \frac{a_2}{b_2}-\frac{c_1}{d_1} \le \frac{c_2}{d_2}-\frac{a_1}{b_1} d_1b_2\le b_1d_2 \begin{align*}
a_2d_1-c_1b_2\le c_2b_1-a_1d_2\\
\end{align*} a_1d_1\le c_1b_1 a_2d_2\le c_2b_2 \begin{align*}
a_1d_1+a_2d_2+d_1a_2+a_1d_2\le& b_1c_2+c_1b_2+c_1b_1+c_2b_2\\
(a_1+a_2)(d_1+d_2) \le & (b_1+b_2)(c_1+c_2)\\
\frac{a_1+a_2}{b_1+b_2}\le &\frac{c_1+c_2}{d_1+d_2}
\end{align*} a_i,c_i>0","['probability', 'statistics', 'inequality', 'conditional-probability', 'paradoxes']"
47,Variational Autencoders and the inequality $\mathbb{E}_{z∼q(z|x)}log (p_{model}(x | z)) − D_{KL}(q(z | x)||p_{model}(z)) ≤ log (p_{model}(x))$,Variational Autencoders and the inequality,\mathbb{E}_{z∼q(z|x)}log (p_{model}(x | z)) − D_{KL}(q(z | x)||p_{model}(z)) ≤ log (p_{model}(x)),"I am reading section $20.10.3$ of the book Deep Learning on Variational Autoencoders, where the authors write: To generate a sample from the model, the VAE ﬁrst draws a sample $z$ from the code distribution $p_{model}(z)$ . The sample is then run through a differentiable generator network $g(z)$ . Finally, $x$ is sampled from a distribution $p_{model}(x;g(z)) =p_{model}(x | z)$ . During training, however, the approximate inference network (or encoder) $q(z | x)$ is used to obtain $z$ , and $p_{model}(x | z)$ is then viewed as a decoder network.The key insight behind variational autoencoders is that they can be trained by maximizing the variational lower bound $L(q)$ associated with data point $x:$ $$L(q) = \mathbb{E}_{z∼q(z|x)}log (p_{model}(z, x)) + H(q(z | x))$$ $$= \mathbb{E}_{z∼q(z|x)}log (p_{model}(x | z)) − D_{KL}(q(z | > x)||p_{model}(z))$$ $$≤ log (p_{model}(x))$$ I'm not sure about the last inequality. I know that the $KL$ divergence is always positive, but I'm not sure why the expectation is not present. By definition: $\mathbb{E}_{z∼q(z|x)}log (p_{model}(x | z)) = \sum_{z \in Z} q(z|x) log (p_{model}(x | z))$ , but how does this relate to $log (p_{model}(x))$ ?","I am reading section of the book Deep Learning on Variational Autoencoders, where the authors write: To generate a sample from the model, the VAE ﬁrst draws a sample from the code distribution . The sample is then run through a differentiable generator network . Finally, is sampled from a distribution . During training, however, the approximate inference network (or encoder) is used to obtain , and is then viewed as a decoder network.The key insight behind variational autoencoders is that they can be trained by maximizing the variational lower bound associated with data point I'm not sure about the last inequality. I know that the divergence is always positive, but I'm not sure why the expectation is not present. By definition: , but how does this relate to ?","20.10.3 z p_{model}(z) g(z) x p_{model}(x;g(z)) =p_{model}(x | z) q(z | x) z p_{model}(x | z) L(q) x: L(q) = \mathbb{E}_{z∼q(z|x)}log (p_{model}(z, x)) + H(q(z | x)) = \mathbb{E}_{z∼q(z|x)}log (p_{model}(x | z)) − D_{KL}(q(z |
> x)||p_{model}(z)) ≤ log (p_{model}(x)) KL \mathbb{E}_{z∼q(z|x)}log (p_{model}(x | z)) = \sum_{z \in Z} q(z|x) log (p_{model}(x | z)) log (p_{model}(x))","['statistics', 'machine-learning']"
48,Covariance of $X$ and $Y$ is 0,Covariance of  and  is 0,X Y,"Let $X$ be a random variable. Is it possible to construct a random variable $Y=g(X)$ , with $g$ strictly monotone, such that $\text{cov}(X,Y)=0$ ?","Let be a random variable. Is it possible to construct a random variable , with strictly monotone, such that ?","X Y=g(X) g \text{cov}(X,Y)=0","['probability', 'statistics', 'covariance', 'correlation']"
49,Evaluating $\lim\limits_{n\to\infty} e^{-n} \sum\limits_{k=0}^{n} \frac{n^k}{k!}$,Evaluating,\lim\limits_{n\to\infty} e^{-n} \sum\limits_{k=0}^{n} \frac{n^k}{k!},"I'm supposed to calculate: $$\lim_{n\to\infty} e^{-n} \sum_{k=0}^{n} \frac{n^k}{k!}$$ By using WolframAlpha, I might guess that the limit is $\frac{1}{2}$ , which is a pretty interesting and nice result. I wonder in which ways we may approach it.","I'm supposed to calculate: By using WolframAlpha, I might guess that the limit is , which is a pretty interesting and nice result. I wonder in which ways we may approach it.",\lim_{n\to\infty} e^{-n} \sum_{k=0}^{n} \frac{n^k}{k!} \frac{1}{2},"['calculus', 'real-analysis', 'sequences-and-series', 'limits']"
50,"Suppose $X_n /a $ converges to standard normal in distribution. How to say normally that $X_n$ converges to normal $n(0, a^2)$?",Suppose  converges to standard normal in distribution. How to say normally that  converges to normal ?,"X_n /a  X_n n(0, a^2)","Suppose $X_n /a $ converges to standard normal in distribution. How to say formally that $X_n$ converges to normal $n(0, a^2)$ in distribution? Slutsky's theorem? I need a formal statement. Thanks! My question is from Casella & Berger exercise 5.44. Let $X_i,i=1,2,...,$ be independent Bernoulli(p) random variables and let $Y_n= \frac{1}{n}\Sigma_{i=1}^n X_i$ . Show that $\sqrt{n}(Y_n-p) \rightarrow n[0,p(1-p)]$ in distribution. This question is not difficult for me. Since they are iid, thus they satisfy Lindeberg condition and qualify for using central limit theorem. $E(Y_n)=p$ and $Var(Y_n)=\frac{1}{n} p(1-p)$ , thus $\frac{\sqrt{n} (Y_n-p) }{\sqrt{p(1-p)}} \rightarrow n(0,1)$ in distribution. Now the last step and also my question is how to say $\sqrt{n}(Y_n-p) \rightarrow n[0,p(1-p)]$ in distribution? The solution I found in website is saying this step needs Slutsky's theorem.","Suppose converges to standard normal in distribution. How to say formally that converges to normal in distribution? Slutsky's theorem? I need a formal statement. Thanks! My question is from Casella & Berger exercise 5.44. Let be independent Bernoulli(p) random variables and let . Show that in distribution. This question is not difficult for me. Since they are iid, thus they satisfy Lindeberg condition and qualify for using central limit theorem. and , thus in distribution. Now the last step and also my question is how to say in distribution? The solution I found in website is saying this step needs Slutsky's theorem.","X_n /a  X_n n(0, a^2) X_i,i=1,2,..., Y_n= \frac{1}{n}\Sigma_{i=1}^n X_i \sqrt{n}(Y_n-p) \rightarrow n[0,p(1-p)] E(Y_n)=p Var(Y_n)=\frac{1}{n} p(1-p) \frac{\sqrt{n} (Y_n-p) }{\sqrt{p(1-p)}} \rightarrow n(0,1) \sqrt{n}(Y_n-p) \rightarrow n[0,p(1-p)]","['probability', 'statistics']"
51,Histogram asymptotic bias,Histogram asymptotic bias,,"I am reading All of Statistics from Casella. When trying to show the bias for a histogram estimator for some density distribution, he starts developing the formula for pj, that is, the probability some observations lies in that bin. Then he uses taylor approximation for that formula. However, developing the integral for that pj by myself do not show the same results from that book. Treating x as a constant, makes it to vanish. Where the j comes from? Can you develop step by step that integral? Let's take a closer look at the bias-variance tradeoff using equation (20.9). Consider some $x \in B_j$ . For any other $u \in B_j$ , $$ f(u)  \approx f(x)+(u-x) f^{\prime}(x) $$ and so $$ \begin{aligned}  p_j=\int_{B_j} f(u) d u & \approx \int_{B_j}\left(f(x)+(u-x)  f^{\prime}(x)\right) d u \\ &=f(x) h+h  f^{\prime}(x)\left(h\left(j-\frac{1}{2}\right)-x\right) .  \end{aligned} $$","I am reading All of Statistics from Casella. When trying to show the bias for a histogram estimator for some density distribution, he starts developing the formula for pj, that is, the probability some observations lies in that bin. Then he uses taylor approximation for that formula. However, developing the integral for that pj by myself do not show the same results from that book. Treating x as a constant, makes it to vanish. Where the j comes from? Can you develop step by step that integral? Let's take a closer look at the bias-variance tradeoff using equation (20.9). Consider some . For any other , and so","x \in B_j u \in B_j  f(u)
 \approx f(x)+(u-x) f^{\prime}(x)   \begin{aligned}
 p_j=\int_{B_j} f(u) d u & \approx \int_{B_j}\left(f(x)+(u-x)
 f^{\prime}(x)\right) d u \\ &=f(x) h+h
 f^{\prime}(x)\left(h\left(j-\frac{1}{2}\right)-x\right) .
 \end{aligned} ","['statistics', 'nonparametric-statistics']"
52,"MLE for $\theta>0$ with $(X_1,\dots,X_n)\sim \mathcal N(\theta, 2\theta)$",MLE for  with,"\theta>0 (X_1,\dots,X_n)\sim \mathcal N(\theta, 2\theta)","I want to determine the MLE for $\theta$ given a sample $(X_1,\dots, X_n)\sim \mathcal N(\theta, 2\theta)$ . I know that the likelihood function is $$f(X;\theta) = \frac{1}{2\sqrt\theta}\prod_{i=1}^n\exp\left(-\frac{(X_i-\theta)^2}{4\theta}\right).$$ The log likelihood function is therefore $$L(X;\theta) = -\log(2\sqrt\theta) -\sum_{i=1}^n \frac{(X_i-\theta)^2}{4\theta}.$$ If we differentiate and solve $ \frac{\partial L}{\partial \theta} = -\frac{1}{2\theta} - \sum_{i=1}^n \left[\frac{X_i^2}{4\theta^2}+\frac{1}{4}\right]\\$ we get \begin{align*}         0 &= -\frac{1}{2\theta} -\sum_{i=1}^n \left[\frac{X_i^2}{4\theta^2}+\frac 1 4\right]\\     \iff 0 &= 2\theta - \sum_{i=1}^n[X_i^2+\theta^2]\\     \iff 0 &= -n\theta^2 + 2\theta - \sum_{i=1}^n X_i^2\\     \iff 0 &= \theta^2 -\frac{2}{n}\theta + \frac{1}{n}\sum_{i=1}^n X_i^2 \end{align*} Which is $0$ if $\theta_{1,2} = \frac 1 n \pm\sqrt{\frac 1 {n^2} - \frac{1}{n}\sum_{i=1}^n X_i^2}$ . But this is highly implausible because the square root term is most likely negative. From experimentations in Python I can say that $$\theta^\ast = \frac 1 n + \sqrt{\frac{1}{n^2} + \left(\frac{1}{n}\sum_{i=1}^n X_i\right)}$$ seems to work quite well. What am I doing wrong?",I want to determine the MLE for given a sample . I know that the likelihood function is The log likelihood function is therefore If we differentiate and solve we get Which is if . But this is highly implausible because the square root term is most likely negative. From experimentations in Python I can say that seems to work quite well. What am I doing wrong?,"\theta (X_1,\dots, X_n)\sim \mathcal N(\theta, 2\theta) f(X;\theta) = \frac{1}{2\sqrt\theta}\prod_{i=1}^n\exp\left(-\frac{(X_i-\theta)^2}{4\theta}\right). L(X;\theta) = -\log(2\sqrt\theta) -\sum_{i=1}^n \frac{(X_i-\theta)^2}{4\theta}.  \frac{\partial L}{\partial \theta} = -\frac{1}{2\theta} - \sum_{i=1}^n \left[\frac{X_i^2}{4\theta^2}+\frac{1}{4}\right]\\ \begin{align*}
        0 &= -\frac{1}{2\theta} -\sum_{i=1}^n \left[\frac{X_i^2}{4\theta^2}+\frac 1 4\right]\\
    \iff 0 &= 2\theta - \sum_{i=1}^n[X_i^2+\theta^2]\\
    \iff 0 &= -n\theta^2 + 2\theta - \sum_{i=1}^n X_i^2\\
    \iff 0 &= \theta^2 -\frac{2}{n}\theta + \frac{1}{n}\sum_{i=1}^n X_i^2
\end{align*} 0 \theta_{1,2} = \frac 1 n \pm\sqrt{\frac 1 {n^2} - \frac{1}{n}\sum_{i=1}^n X_i^2} \theta^\ast = \frac 1 n + \sqrt{\frac{1}{n^2} + \left(\frac{1}{n}\sum_{i=1}^n X_i\right)}","['probability', 'statistics', 'solution-verification', 'maximum-likelihood']"
53,Mixture density neural network prediction bias,Mixture density neural network prediction bias,,"I am not totally sure if this belongs here, but I thought it would be the best place to get an answer. I am using a mixture density network (MDN) to make some predictions. My model is very simple with one hidden layer only with 10 nodes (the details of the network shouldn't matter for my question but I can provide more if needed). Also my MDN has only one gaussian component which basically mean that my MDN predicts for each input a mean and standard deviation of a Gaussian from which to sample the output. During the training I am basically minimizing the log-likelihood between the prediction and the expected output: $$log(\sigma(x_{in})) + \frac{(y_{real}-\mu(x_{in}))^2}{2\sigma(x_{in})^2}$$ where $\sigma(x_{in})$ and $\mu(x_{in})$ are predicted by the network and are functions of the input. The network seems to be training well i.e. the loss goes down and I am attaching below 2 histograms I obtained after training the network and trying it on new data. The first one is a histogram of $\frac{dy}{\mu(x_{in})}$ , where $dy = y_{real}-\mu(x_{in})$ . The second histogram shows $\frac{dy}{\sigma(x_{in})}$ . Based on these it seems like the network is doing pretty well (the data has Gaussian noise added to it). However when I try to compute the mean and the error on the mean for $dy$ I get: $$\frac{\sum_i{\frac{dy_i}{\sigma_i^2}}}{\sum_i{1/\sigma_i^2}} = -0.000172 $$ and $$\sqrt{\frac{1}{\sum_i{1/\sigma_i^2}}} = 0.000003$$ where the sum is over all the data points I test the MDN on. This means that my predictions are biased by -0.000172. However, I am not sure why that is the case, as the MDN should easily notice that and add 0.000172 to all the $\mu$ predictions. I tried training several MDN's with lots of different parameters and I get the same result i.e. the result is biased (not always by the same amount or direction). Am I missing something or missinterpreting the results? Shouldn't the mean of my errors be consistent with zero and shouldn't simply adding that bias (0.000172 in this case) solve the issue? Any insight would be really appreciated.","I am not totally sure if this belongs here, but I thought it would be the best place to get an answer. I am using a mixture density network (MDN) to make some predictions. My model is very simple with one hidden layer only with 10 nodes (the details of the network shouldn't matter for my question but I can provide more if needed). Also my MDN has only one gaussian component which basically mean that my MDN predicts for each input a mean and standard deviation of a Gaussian from which to sample the output. During the training I am basically minimizing the log-likelihood between the prediction and the expected output: where and are predicted by the network and are functions of the input. The network seems to be training well i.e. the loss goes down and I am attaching below 2 histograms I obtained after training the network and trying it on new data. The first one is a histogram of , where . The second histogram shows . Based on these it seems like the network is doing pretty well (the data has Gaussian noise added to it). However when I try to compute the mean and the error on the mean for I get: and where the sum is over all the data points I test the MDN on. This means that my predictions are biased by -0.000172. However, I am not sure why that is the case, as the MDN should easily notice that and add 0.000172 to all the predictions. I tried training several MDN's with lots of different parameters and I get the same result i.e. the result is biased (not always by the same amount or direction). Am I missing something or missinterpreting the results? Shouldn't the mean of my errors be consistent with zero and shouldn't simply adding that bias (0.000172 in this case) solve the issue? Any insight would be really appreciated.",log(\sigma(x_{in})) + \frac{(y_{real}-\mu(x_{in}))^2}{2\sigma(x_{in})^2} \sigma(x_{in}) \mu(x_{in}) \frac{dy}{\mu(x_{in})} dy = y_{real}-\mu(x_{in}) \frac{dy}{\sigma(x_{in})} dy \frac{\sum_i{\frac{dy_i}{\sigma_i^2}}}{\sum_i{1/\sigma_i^2}} = -0.000172  \sqrt{\frac{1}{\sum_i{1/\sigma_i^2}}} = 0.000003 \mu,"['statistics', 'neural-networks']"
54,Mean and variance of a probability distribution.,Mean and variance of a probability distribution.,,"I am confused between mean and variance of a statistical data and the probability distribution. Are both of them different to each-other? as in its simple form, the mean is given in terms of the sum of variables and its frequency divided by total no. of frequency. But when it comes to probability distribution, the mean is computed in totally different way and there is no concept of frequency etc. If both mean represents the same thing then can we conclude that the statistical variable is replaced by random variable and its frequency is substituted by the probability of accurance of the random variable ?","I am confused between mean and variance of a statistical data and the probability distribution. Are both of them different to each-other? as in its simple form, the mean is given in terms of the sum of variables and its frequency divided by total no. of frequency. But when it comes to probability distribution, the mean is computed in totally different way and there is no concept of frequency etc. If both mean represents the same thing then can we conclude that the statistical variable is replaced by random variable and its frequency is substituted by the probability of accurance of the random variable ?",,"['probability', 'statistics', 'means']"
55,Independent random variables and product spaces,Independent random variables and product spaces,,"Let's say we have a measurable space $(\Omega,\mathcal{A},P)$ and some independent random Variables $X$ and $Y$ . Then we know that $P(X+Y \le s)$ is equal to $P(\{a \in \Omega : X(a)+Y(a) \le s\})$ . Now $P_{X}$ together with the Borel sets form a measurable space, analog also with $Y$ , so we construct the product space with the mass $P_{X}\otimes P_{Y}$ . The question is, how can we show that $$P(\{a \in \Omega : X(a)+Y(a) \le s\}) = P(X+Y \le s) = (P_{X}\otimes P_{Y})(\{(a,b) \in \mathbb{R^2} : a + b \le s\})$$ The first equality is just definition, but how do we prove the second equality?","Let's say we have a measurable space and some independent random Variables and . Then we know that is equal to . Now together with the Borel sets form a measurable space, analog also with , so we construct the product space with the mass . The question is, how can we show that The first equality is just definition, but how do we prove the second equality?","(\Omega,\mathcal{A},P) X Y P(X+Y \le s) P(\{a \in \Omega : X(a)+Y(a) \le s\}) P_{X} Y P_{X}\otimes P_{Y} P(\{a \in \Omega : X(a)+Y(a) \le s\}) = P(X+Y \le s) = (P_{X}\otimes P_{Y})(\{(a,b) \in \mathbb{R^2} : a + b \le s\})","['probability-theory', 'statistics', 'stochastic-analysis']"
56,An identity between iid R.V. and its ladder R.V. in Fluctuation theory/Random walk.,An identity between iid R.V. and its ladder R.V. in Fluctuation theory/Random walk.,,"Let $\{X_n\}_{n=0}^\infty \space$ be a sequence of i.i.d non-lattice R.V. with $X_0=0,\space \space  0\lt E[X_1]\lt\infty $ Let a partial sum $S_n = X_1 + X_2 + ... +X_n. \space(S_0 = 0)$ and first positive partial sum, $S_T$ where $T = min\{n;S_n\gt0\}$ and continuing $T_k = min\{n;n\gt T_{k-1}, S_n\gt S_{T_{k-1}}\} $ , Let $Z_k = S_{T_k} - S_{T_{k-1}}$ (aka Ladder R.V.) and a partial sum of $Z_k, \space\space   S_{Z_n} = Z_1 + Z_2 + ... +Z_n. \space(Z_0 = 0)$ For any real number $ x, h(\gt0)$ , $$ p\{x\le first \space\space S_n \lt x+h\} = p\{x\le first \space\space S_{Z_n} \lt x+h\}, \space as \space\space x\to\infty $$ I can't get this identity at all. Eventually, I've just found out and understood  that (by using an extended version of Renewal Theorem) $$\lim_{x\to\infty}\sum_{k=1}^\infty p\{x\le first \space\space S_{Z_k} \lt x+h\} = \frac{h}{E[Z_1]} =  \frac{h}{E[X_1]E[T]} = \lim_{x\to\infty}\sum_{n=1}^\infty p\{x\le first \space\space S_n \lt x+h\}$$ Nonetheless, that does NOT necessarily mean that the two probabilities have to be identical $for \space n$ ?","Let be a sequence of i.i.d non-lattice R.V. with Let a partial sum and first positive partial sum, where and continuing , Let (aka Ladder R.V.) and a partial sum of For any real number , I can't get this identity at all. Eventually, I've just found out and understood  that (by using an extended version of Renewal Theorem) Nonetheless, that does NOT necessarily mean that the two probabilities have to be identical ?","\{X_n\}_{n=0}^\infty \space X_0=0,\space \space  0\lt E[X_1]\lt\infty  S_n = X_1 + X_2 + ... +X_n. \space(S_0 = 0) S_T T = min\{n;S_n\gt0\} T_k = min\{n;n\gt T_{k-1}, S_n\gt S_{T_{k-1}}\}  Z_k = S_{T_k} - S_{T_{k-1}} Z_k, \space\space   S_{Z_n} = Z_1 + Z_2 + ... +Z_n. \space(Z_0 = 0)  x, h(\gt0)  p\{x\le first \space\space S_n \lt x+h\} = p\{x\le first \space\space S_{Z_n} \lt x+h\}, \space as \space\space x\to\infty  \lim_{x\to\infty}\sum_{k=1}^\infty p\{x\le first \space\space S_{Z_k} \lt x+h\} = \frac{h}{E[Z_1]} =  \frac{h}{E[X_1]E[T]} = \lim_{x\to\infty}\sum_{n=1}^\infty p\{x\le first \space\space S_n \lt x+h\} for \space n","['probability', 'statistics', 'stochastic-processes', 'random-walk', 'renewal-processes']"
57,Closed form of series with factorial-squared denominator?,Closed form of series with factorial-squared denominator?,,"Does the following series have a closed-form expression: $$\sum_{k=0}^{\infty} \frac{z^k}{(k!)^2}$$ I know that it must converge because: $$\sum_{k=0}^{\infty} \frac{z^k}{k!} = e^z$$ and the $(k!)^2$ denominator obviously increases more quickly than the $k!$ denominator. This problem came up in computing the probability of a draw in a football match with each team's goal scoring modeled as a Poisson process. Thanks, John","Does the following series have a closed-form expression: $$\sum_{k=0}^{\infty} \frac{z^k}{(k!)^2}$$ I know that it must converge because: $$\sum_{k=0}^{\infty} \frac{z^k}{k!} = e^z$$ and the $(k!)^2$ denominator obviously increases more quickly than the $k!$ denominator. This problem came up in computing the probability of a draw in a football match with each team's goal scoring modeled as a Poisson process. Thanks, John",,"['sequences-and-series', 'summation', 'factorial', 'closed-form', 'poisson-distribution']"
58,Agent-Based Wealth Model: Proving Inequality,Agent-Based Wealth Model: Proving Inequality,,"Consider the following agent-based model: There are $N$ agents Every agent starts with $1 At each time interval (i.e. at each step), every agent gives \$1 to a randomly chosen agent. I want to find how unequal the wealth distribution becomes over a long period of time. After running a simulation for a large number of agents, I find that the wealth distribution becomes over a long period of time approaches (what I am ""by eye"" guessing to be) a Boltzmann distribution. I am curious as to why this happens from a derivation standpoint. I have tried to find sample derivations online, but only find kinetic-model related Boltzmann distribution derivations. Can anyone point me to any resources or share a derivation that explain this result?","Consider the following agent-based model: There are agents Every agent starts with $1 At each time interval (i.e. at each step), every agent gives \$1 to a randomly chosen agent. I want to find how unequal the wealth distribution becomes over a long period of time. After running a simulation for a large number of agents, I find that the wealth distribution becomes over a long period of time approaches (what I am ""by eye"" guessing to be) a Boltzmann distribution. I am curious as to why this happens from a derivation standpoint. I have tried to find sample derivations online, but only find kinetic-model related Boltzmann distribution derivations. Can anyone point me to any resources or share a derivation that explain this result?",N,"['probability', 'statistics', 'proof-writing', 'statistical-mechanics']"
59,"Generalising ""the mean of the means is the mean""","Generalising ""the mean of the means is the mean""",,"It's an interesting exercise to prove that the ""mean of the means is the mean"", by which I mean given a finite list $X=[x_1,\dots,x_n]$ we can define the arithmetic mean $$\mu(X)=\frac{1}{n}\sum_{i=1}^nx_i, \tag{1}$$ and we consider the list of means  of non-empty sublists of $X$ , writing $S_\mu(X)=[\mu(A)\mid A\subseteq X, A\neq\emptyset]$ (Note that $|S_\mu(X)| =2^n-1$ since both $X$ and $S_\mu(X)$ are allowed to have repeated elements). Then we have $$\mu(X) = \mu(S_\mu(X)). \tag{2}$$ Let's call property (2) sample invariance , as we can think of $S_\mu(X)$ as the list of all possible samples from $X$ . Once one has proved (2), it's simple to generalise this statement to show the sample invariance of function means: given an invertible function $f:\mathbb{R}\to\mathbb{R}$ we define the $f$ -mean by 'conguation' of $\mu$ (where $f$ is considered to act element-wise on $X$ ): $$\bar{f}(X) = f^{-1}\left(\frac{1}{n}\sum_{i=1}^nf(x_i)\right) = (f^{-1}\circ\mu\circ f)(X).$$ One can show that $\bar{f}(X) = \bar{f}(S_{\bar{f}}(X))$ . For expedient choices of $f$ this shows that the geometric and harmonic means are also sample invariant, along with countless others. However, there are other functions that we might expect to be sample invariant, perhaps the median or the mode? Does this characterise all sample invariant functions? I suspect not - there are clearly other functions such as $\max$ and $\min$ that are sample invariant but it's not immediately clear that they appear as $f$ -means. How would one prove this? Can we classify all sample invariant functions, or perhaps just provide equivalent conditions for sample invariance?","It's an interesting exercise to prove that the ""mean of the means is the mean"", by which I mean given a finite list we can define the arithmetic mean and we consider the list of means  of non-empty sublists of , writing (Note that since both and are allowed to have repeated elements). Then we have Let's call property (2) sample invariance , as we can think of as the list of all possible samples from . Once one has proved (2), it's simple to generalise this statement to show the sample invariance of function means: given an invertible function we define the -mean by 'conguation' of (where is considered to act element-wise on ): One can show that . For expedient choices of this shows that the geometric and harmonic means are also sample invariant, along with countless others. However, there are other functions that we might expect to be sample invariant, perhaps the median or the mode? Does this characterise all sample invariant functions? I suspect not - there are clearly other functions such as and that are sample invariant but it's not immediately clear that they appear as -means. How would one prove this? Can we classify all sample invariant functions, or perhaps just provide equivalent conditions for sample invariance?","X=[x_1,\dots,x_n] \mu(X)=\frac{1}{n}\sum_{i=1}^nx_i, \tag{1} X S_\mu(X)=[\mu(A)\mid A\subseteq X, A\neq\emptyset] |S_\mu(X)| =2^n-1 X S_\mu(X) \mu(X) = \mu(S_\mu(X)). \tag{2} S_\mu(X) X f:\mathbb{R}\to\mathbb{R} f \mu f X \bar{f}(X) = f^{-1}\left(\frac{1}{n}\sum_{i=1}^nf(x_i)\right) = (f^{-1}\circ\mu\circ f)(X). \bar{f}(X) = \bar{f}(S_{\bar{f}}(X)) f \max \min f","['statistics', 'average', 'means', 'central-tendency']"
60,What are some recommended Rating Systems for a Single-Elimination Bracket Tournament?,What are some recommended Rating Systems for a Single-Elimination Bracket Tournament?,,"I have gathered data on a set of certain contests. The contests are in the form of single-elimination. That is, there are $2^n$ competitors in $n$ rounds. In each game, two players face each other, and the loser gets eliminated, until only one player remains who is the winner. Now, the data I have is of multiple such contests, taking place annually. One caveat is that once a player wins, they don't play in these contests anymore. I want to ask for recommended rating systems for such a contest. I considered Elo Rating System, but as some winners play less matches than those who have never won, and Elo depends more on matches won, it wasn't as effective. I didn't understand Glicko, but I feel this won't work, as well. I currently just use the victory percentage, which I calculate as $S=100 \times \frac {1.0\times v + 0.5 \times d} {m}$ where $v$ is victories, $d$ is draws and $m$ is the number of matches. One thing is that the players get a score in each match (which generally ranges from 100 to 10000, but isn't limited by anything), which I think can be used in some way.","I have gathered data on a set of certain contests. The contests are in the form of single-elimination. That is, there are competitors in rounds. In each game, two players face each other, and the loser gets eliminated, until only one player remains who is the winner. Now, the data I have is of multiple such contests, taking place annually. One caveat is that once a player wins, they don't play in these contests anymore. I want to ask for recommended rating systems for such a contest. I considered Elo Rating System, but as some winners play less matches than those who have never won, and Elo depends more on matches won, it wasn't as effective. I didn't understand Glicko, but I feel this won't work, as well. I currently just use the victory percentage, which I calculate as where is victories, is draws and is the number of matches. One thing is that the players get a score in each match (which generally ranges from 100 to 10000, but isn't limited by anything), which I think can be used in some way.",2^n n S=100 \times \frac {1.0\times v + 0.5 \times d} {m} v d m,['statistics']
61,How to give a high-probability uniform estimation of a potential having access to noisy pointwise estimates of the associated vector field?,How to give a high-probability uniform estimation of a potential having access to noisy pointwise estimates of the associated vector field?,,"As in the title, our goal is to estimate uniformly and with high probability (and up to a constant) a potential having access to noisy pointwise estimates of the associated vector field (i.e., the gradient of the potential). Here how I tried to formalize the problem. Suppose $d \in \mathbb{N}$ and let $\mathcal{B}_1^d$ be the unitary closed ball of $\mathbb{R}^d$ centered in the origin. Let $\mathcal{F}$ be the class of all $C^1$ functions $F : \Omega \to \mathbb{R}$ , where $\Omega$ is any open set of $\mathbb{R}^d$ containing $[-1,1]^d$ , and such that $\forall x\in[-1,1]^d, \nabla F(x) \in \mathcal{B}_1^d$ . Suppose that, for each $F \in \mathcal{F}$ , we have the following interaction protocol: For each $t=1,2,\dots$ We select a point $X_t \in [-1,1]^d$ (a selection based on past observations and possibly some randomization, but not on the knowledge of $F$ ) We observe a $\mathcal{B}_1^d$ -valued random variable $Y_t^F$ such that $\mathbb{E}[Y_t^F \mid X_1,Y_1^F,\dots,X_{t-1},Y_{t-1}^F,X_t] = \mathbb{E}[Y_t^F \mid X_t] =\nabla F(X_t)$ . Basically, we query a point in the domain and we see a noisy (and bounded) reconstruction in that point of the vector field associated to the gradient of the potential $F$ . Regardless which potential $F \in \mathcal{F}$ we are interacting with, our goal is to give a uniform reconstruction of $F-F(0)$ with high-probability using the previous interaction protocol , i.e. we want to find a strategy to select the points $X_1,X_2,\dots$ and a family of estimators $(\Phi_{x,t})_{x \in (-1,1)^d,t \in \mathbb{N}}$ , where $\forall x \in [-1,1]^d, \forall t \in \mathbb{N}, \Phi_{x,t} : \big([-1,1]^d\times\mathcal{B}_1^d\big)^t \to \mathbb{R}$ , such that $$\forall \varepsilon >0, \forall \delta \in (0,1), \exists T \in \mathbb{N}, \forall t \ge T, \forall F \in \mathcal{F}, \\ \mathbb{P}\bigg[ \sup_{x \in [0,1]^d}\Big|\Phi_{x,t}(X_1,Y_1^F,\dots,X_t,Y_t^F) - \big(F(x)-F(0)\big)\Big| \ge \varepsilon \bigg] \le \delta.$$ Notice that estimating $F-F(0)$ instead of $F$ is just a trick to get rid of the constant we never see. It is interesting to start with the case $d = 1$ , where I'm quite confident that the problem is solvable via Monte Carlo integration in the following way. Define $$\Phi_{x,t}(x_1,y_1,\dots,x_t,y_t) = \frac{1}{t} \sum_{s=1}^t \big(y_t \cdot \mathbb{I}\{\min(x,0)\le x_t \le \max(x,0)\} \cdot \operatorname{sgn}(x)\big)$$ and select the random variables $X_1,X_2, \dots$ just as family of independent $[-1,1]$ -valued uniform random variables. But what about the general case? What are sensible estimators and strategies to solve the problem? And what are the best achievable decaying rate depending on $t, \varepsilon$ and on the dimension $d$ for the quantity $$\mathbb{P}\bigg[ \sup_{x \in [0,1]^d}\Big|\Phi_{x,t}(X_1,Y_1^F,\dots,X_t,Y_t^F) - \big(F(x)-F(0)\big)\Big| \ge \varepsilon \bigg] ?$$","As in the title, our goal is to estimate uniformly and with high probability (and up to a constant) a potential having access to noisy pointwise estimates of the associated vector field (i.e., the gradient of the potential). Here how I tried to formalize the problem. Suppose and let be the unitary closed ball of centered in the origin. Let be the class of all functions , where is any open set of containing , and such that . Suppose that, for each , we have the following interaction protocol: For each We select a point (a selection based on past observations and possibly some randomization, but not on the knowledge of ) We observe a -valued random variable such that . Basically, we query a point in the domain and we see a noisy (and bounded) reconstruction in that point of the vector field associated to the gradient of the potential . Regardless which potential we are interacting with, our goal is to give a uniform reconstruction of with high-probability using the previous interaction protocol , i.e. we want to find a strategy to select the points and a family of estimators , where , such that Notice that estimating instead of is just a trick to get rid of the constant we never see. It is interesting to start with the case , where I'm quite confident that the problem is solvable via Monte Carlo integration in the following way. Define and select the random variables just as family of independent -valued uniform random variables. But what about the general case? What are sensible estimators and strategies to solve the problem? And what are the best achievable decaying rate depending on and on the dimension for the quantity","d \in \mathbb{N} \mathcal{B}_1^d \mathbb{R}^d \mathcal{F} C^1 F : \Omega \to \mathbb{R} \Omega \mathbb{R}^d [-1,1]^d \forall x\in[-1,1]^d, \nabla F(x) \in \mathcal{B}_1^d F \in \mathcal{F} t=1,2,\dots X_t \in [-1,1]^d F \mathcal{B}_1^d Y_t^F \mathbb{E}[Y_t^F \mid X_1,Y_1^F,\dots,X_{t-1},Y_{t-1}^F,X_t] = \mathbb{E}[Y_t^F \mid X_t] =\nabla F(X_t) F F \in \mathcal{F} F-F(0) X_1,X_2,\dots (\Phi_{x,t})_{x \in (-1,1)^d,t \in \mathbb{N}} \forall x \in [-1,1]^d, \forall t \in \mathbb{N}, \Phi_{x,t} : \big([-1,1]^d\times\mathcal{B}_1^d\big)^t \to \mathbb{R} \forall \varepsilon >0, \forall \delta \in (0,1), \exists T \in \mathbb{N}, \forall t \ge T, \forall F \in \mathcal{F}, \\
\mathbb{P}\bigg[ \sup_{x \in [0,1]^d}\Big|\Phi_{x,t}(X_1,Y_1^F,\dots,X_t,Y_t^F) - \big(F(x)-F(0)\big)\Big| \ge \varepsilon \bigg] \le \delta. F-F(0) F d = 1 \Phi_{x,t}(x_1,y_1,\dots,x_t,y_t) = \frac{1}{t} \sum_{s=1}^t \big(y_t \cdot \mathbb{I}\{\min(x,0)\le x_t \le \max(x,0)\} \cdot \operatorname{sgn}(x)\big) X_1,X_2, \dots [-1,1] t, \varepsilon d \mathbb{P}\bigg[ \sup_{x \in [0,1]^d}\Big|\Phi_{x,t}(X_1,Y_1^F,\dots,X_t,Y_t^F) - \big(F(x)-F(0)\big)\Big| \ge \varepsilon \bigg] ?","['probability-theory', 'statistics', 'statistical-inference', 'machine-learning', 'parameter-estimation']"
62,A likelihood problem with a biased coin but with missing data,A likelihood problem with a biased coin but with missing data,,"I'm trying to build up an intuition about likelihoods and have come up with a few problems. This one builds on top of a previous problem: A likelihood problem with a biased coin Suppose an unknown number of people flip an unfair coin $k$ times and $Z_i$ is the number of people who landed $i$ heads where $i\in{0,1,...,k}$ . Now suppose only $Z_0$ is unknown (so we know $Z_1,...Z_k$ ). I would like to find the likelihood $l(Z_1,...,Z_k|p)$ and so used the following argument: Let $X_j ∼ Bin(N,π)$ where $X_j$ is the number of heads person $j$ landed. Suppose that observations are available for $Y_j = X_j| {X_j >0}$ ( $Y_j$ follows a truncated binomial distribution). Consequently, we have the following probability mass for the observations $j =1, 2, . . . , N:$ $P(X_j=j|X_j>0)=\frac{{N \choose j}p^j(1-p)^{N-j}}{1-(1-p)^N}$ And so (I think): $l(Z_1,...,Z_k|p)={\sum_{j=1}^kZ_j \choose Z_1,Z_2,...,Z_k}\Pi_{i=1}^k\Big({k \choose i}{\frac{ p^i(1-p)^{k-i}}{1-(1-p)^k}}\Big)^{Z_i}$ Is this correct?","I'm trying to build up an intuition about likelihoods and have come up with a few problems. This one builds on top of a previous problem: A likelihood problem with a biased coin Suppose an unknown number of people flip an unfair coin times and is the number of people who landed heads where . Now suppose only is unknown (so we know ). I would like to find the likelihood and so used the following argument: Let where is the number of heads person landed. Suppose that observations are available for ( follows a truncated binomial distribution). Consequently, we have the following probability mass for the observations And so (I think): Is this correct?","k Z_i i i\in{0,1,...,k} Z_0 Z_1,...Z_k l(Z_1,...,Z_k|p) X_j ∼ Bin(N,π) X_j j Y_j = X_j| {X_j >0} Y_j j =1, 2, . . . , N: P(X_j=j|X_j>0)=\frac{{N \choose j}p^j(1-p)^{N-j}}{1-(1-p)^N} l(Z_1,...,Z_k|p)={\sum_{j=1}^kZ_j \choose Z_1,Z_2,...,Z_k}\Pi_{i=1}^k\Big({k \choose i}{\frac{ p^i(1-p)^{k-i}}{1-(1-p)^k}}\Big)^{Z_i}","['probability', 'statistics', 'maximum-likelihood']"
63,Asymptotic Joint Distribution of Variance and Ratio of Mean and Standard Deviation,Asymptotic Joint Distribution of Variance and Ratio of Mean and Standard Deviation,,"I am working on an exercise from a textbook about asymptotic distributions and I happen to see the question and I am interested in knowing how to solve it. The question is: If $X_i$ are i.i.d with mean $\mu$ , variance $\sigma^2$ , assuming that $\mathrm{E}(X^4_1)<\infty$ . I am interested in deriving the asymptotic distribution of $(S^2_n, \bar X_n/S_n)^\top$ . $\bar X_n$ is the sample mean and $S^2_n$ sample variance. Here's what I did so far: By the bivariate CLT, we have that $\sqrt{n}\left(\begin{pmatrix} S^2 \ \\ \overline{X}/S  \end{pmatrix}  - \begin{pmatrix} \mu \\ \sigma^2   \end{pmatrix}\right)\stackrel{d}{\rightarrow} N(0, J_{g(a)} \Sigma J'_{g(a)}) $ If we let $g(u,v) = \begin{pmatrix} v-u^2 \\ \frac{u}{\sqrt{v-u^2}} \end{pmatrix} $ then we have $$  J  = \begin{pmatrix} -2u & 1 \\  \frac{v}{(v-u)\sqrt{v-u^2}} & \frac{-u}{2(v-u^2)^{3/2}} \end{pmatrix}  \text{ so that } J_{g(a)}=  \begin{pmatrix} 0 & 1 \\  \frac{1}{\sigma } & 0 \end{pmatrix} \text{ where }  a = \begin{pmatrix} 0\\\sigma^2 \end{pmatrix},  \text{ and }    \Sigma  =  \begin{pmatrix} \sigma^2  & \mu_3  \\  \mu_3 & \mu_4-\sigma^4 \end{pmatrix}. $$ Covariance Matrix: $$J_{g(a)} \Sigma J'_{g(a)} = \begin{pmatrix} 0 & 1 \\  \frac{1}{\sigma } & 0 \end{pmatrix} \begin{pmatrix} \sigma^2  & \mu_3  \\  \mu_3 & \mu_4-\sigma^4 \end{pmatrix} \begin{pmatrix} 0 & 1 \\  \frac{1}{\sigma } & 0 \end{pmatrix} = \begin{pmatrix} \mu_4 - \sigma^4 & \frac{\mu_3}{\sigma} \\  \frac{\mu_3}{\sigma} & 1 \end{pmatrix} $$ $$ \begin{pmatrix} S^2 \ \\ \overline{X}/S   \end{pmatrix}  \stackrel{\text{asym}}{\sim}  N\left( \begin{bmatrix} \mu \\ \sigma  \end{bmatrix}; \  \frac{1}{n} \begin{bmatrix} \mu_4 - \sigma^4 & \frac{\mu_3}{\sigma} \\  \frac{\mu_3}{\sigma} & 1 \end{bmatrix} \right) $$","I am working on an exercise from a textbook about asymptotic distributions and I happen to see the question and I am interested in knowing how to solve it. The question is: If are i.i.d with mean , variance , assuming that . I am interested in deriving the asymptotic distribution of . is the sample mean and sample variance. Here's what I did so far: By the bivariate CLT, we have that If we let then we have Covariance Matrix:","X_i \mu \sigma^2 \mathrm{E}(X^4_1)<\infty (S^2_n, \bar X_n/S_n)^\top \bar X_n S^2_n \sqrt{n}\left(\begin{pmatrix}
S^2 \ \\ \overline{X}/S  \end{pmatrix} 
-
\begin{pmatrix}
\mu \\ \sigma^2  
\end{pmatrix}\right)\stackrel{d}{\rightarrow} N(0, J_{g(a)} \Sigma J'_{g(a)})  g(u,v) = \begin{pmatrix}
v-u^2 \\ \frac{u}{\sqrt{v-u^2}}
\end{pmatrix}   
J 
=
\begin{pmatrix}
-2u & 1 \\ 
\frac{v}{(v-u)\sqrt{v-u^2}} & \frac{-u}{2(v-u^2)^{3/2}}
\end{pmatrix} 
\text{ so that } J_{g(a)}= 
\begin{pmatrix}
0 & 1 \\ 
\frac{1}{\sigma } & 0
\end{pmatrix}
\text{ where } 
a = \begin{pmatrix}
0\\\sigma^2
\end{pmatrix},  \text{ and }   
\Sigma 
= 
\begin{pmatrix}
\sigma^2  & \mu_3  \\ 
\mu_3 & \mu_4-\sigma^4
\end{pmatrix}.
 J_{g(a)} \Sigma J'_{g(a)} =
\begin{pmatrix}
0 & 1 \\ 
\frac{1}{\sigma } & 0
\end{pmatrix}
\begin{pmatrix}
\sigma^2  & \mu_3  \\ 
\mu_3 & \mu_4-\sigma^4
\end{pmatrix}
\begin{pmatrix}
0 & 1 \\ 
\frac{1}{\sigma } & 0
\end{pmatrix}
=
\begin{pmatrix}
\mu_4 - \sigma^4 & \frac{\mu_3}{\sigma} \\ 
\frac{\mu_3}{\sigma} & 1
\end{pmatrix}
  \begin{pmatrix}
S^2 \ \\ \overline{X}/S  
\end{pmatrix} 
\stackrel{\text{asym}}{\sim} 
N\left(
\begin{bmatrix}
\mu \\ \sigma 
\end{bmatrix}; \ 
\frac{1}{n}
\begin{bmatrix}
\mu_4 - \sigma^4 & \frac{\mu_3}{\sigma} \\ 
\frac{\mu_3}{\sigma} & 1
\end{bmatrix}
\right)
","['statistics', 'probability-distributions', 'solution-verification', 'asymptotics']"
64,How many hands does it take to draw all 52 different cards from an infinite deck of cards? [duplicate],How many hands does it take to draw all 52 different cards from an infinite deck of cards? [duplicate],,"This question already has an answer here : Expected number of times a set of 10 integers (selected from 1-100) is selected before all 100 are seen (1 answer) Closed last year . Say you have a deck of cards 52 distinct cards labeled numbers 1 through 52. Each turn you are given a hand of 5 different cards, each of which are labeled 1–52. Each card has an equal chance of being drawn. Each turn all cards labeled 1–52 are in play; ex: if you draw a 7 one turn, you can draw the 7 again on a future turn. How many expected turns does it take until you have collected all cards labeled 1 through 52?","This question already has an answer here : Expected number of times a set of 10 integers (selected from 1-100) is selected before all 100 are seen (1 answer) Closed last year . Say you have a deck of cards 52 distinct cards labeled numbers 1 through 52. Each turn you are given a hand of 5 different cards, each of which are labeled 1–52. Each card has an equal chance of being drawn. Each turn all cards labeled 1–52 are in play; ex: if you draw a 7 one turn, you can draw the 7 again on a future turn. How many expected turns does it take until you have collected all cards labeled 1 through 52?",,"['probability', 'statistics', 'probability-distributions', 'card-games', 'coupon-collector']"
65,Proving the existence of MLE for logistic distribution,Proving the existence of MLE for logistic distribution,,"Let $X_{1},\cdots,X_{n}\overset{IID}{\sim}\operatorname{Logis}(\theta,\sigma),\theta\in\mathbb{R},\sigma>0$ . Prove that there exists an MLE of $\eta = (\theta,\sigma)^T$ . I want to prove this by the following theorem: For the log-likelihood function $l(\theta)$ whose second partial derivatives are all continous, if the Hessian matrix is negative-definite and limiting $\theta$ to the boundary of the parameter space makes $l(\theta)$ go to negative infinity, there exists a unique solution to $\dot{l}(\theta) = 0$ , which is the MLE of $\theta$ . Since the pdf for Logistic distribution is $$f(x;\theta,\sigma)=\frac{1}{\sigma}\frac{e^{-\frac{x-\theta}{\sigma}}}{(1+e^{-\frac{x-\theta}{\sigma}})^2}$$ , the log-likelihood function is $$l(\theta,\sigma) = -n\log{\sigma} -n\frac{\bar{x}-\theta}{\sigma} -2 \sum_{i=1}^{n}{\log{(1+e^{-\frac{x_{i}-\theta}{\sigma}})}}       $$ and the Hessian matrix is $\begin{pmatrix} \frac{\partial^2 l}{\partial \theta^2} & \frac{\partial^2 l}{\partial \theta \partial\sigma} \\ \frac{\partial^2 l}{\partial \sigma \partial\theta} & \frac{\partial^2 l}{\partial \sigma^2} \end{pmatrix}$ where $$ \begin{aligned} &\frac{\partial^2 l}{\partial \theta^2}=-\frac{2}{\sigma^2} \sum_{i=1}^n \frac{e^{-\frac{x_i-\theta}{\sigma}}}{\left(1+e^{-\frac{x_i-\theta}{\sigma}}\right)^2} \\ &\frac{\partial^2 l}{\partial \theta \partial \sigma} =\frac{\partial^2 l}{\partial \sigma \partial \theta} =-\frac{n}{\sigma^2}+\frac{2}{\sigma^3} \sum_{i=1}^n \frac{e^{-\frac{x_i-\theta}{\sigma}}\left(\sigma\left(1+e^{-\frac{x_i-\theta}{\sigma}}\right)-\left(x_i-\theta\right)\right)}{\left(1+e^{-\frac{x_i-\theta}{\sigma}}\right)^2} \\ &\frac{\partial^2 l}{\partial \sigma^2} =\frac{n}{\sigma^2}-\frac{2}{\sigma^3} \sum_{i=1}^n x_i+\frac{2 n \theta}{\sigma^3}+\frac{2}{\sigma^4} \sum_{i=1}^n \frac{e^{-\frac{x_i-\theta}{\sigma}}\left(x_i-\theta\right)\left(2 \sigma\left(1+e^{-\frac{x_i-\theta}{\sigma}}\right)-\left(x_i-\theta\right)\right)}{\left(1+e^{-\frac{x_i-\theta}{\sigma}}\right)^2} \end{aligned} $$ I could show that $\lim_{\theta \rightarrow \infty}{l(\theta,\sigma^*)}=\lim_{\theta \rightarrow -\infty}{l(\theta,\sigma^*)}=\lim_{\sigma \rightarrow 0+}{l(\theta^*,\sigma)}=\lim_{\sigma \rightarrow \infty}{l(\theta^*,\sigma)}=-\infty$ somehow, but I don't know how to show that the hessian matrix is negative-definite.","Let . Prove that there exists an MLE of . I want to prove this by the following theorem: For the log-likelihood function whose second partial derivatives are all continous, if the Hessian matrix is negative-definite and limiting to the boundary of the parameter space makes go to negative infinity, there exists a unique solution to , which is the MLE of . Since the pdf for Logistic distribution is , the log-likelihood function is and the Hessian matrix is where I could show that somehow, but I don't know how to show that the hessian matrix is negative-definite.","X_{1},\cdots,X_{n}\overset{IID}{\sim}\operatorname{Logis}(\theta,\sigma),\theta\in\mathbb{R},\sigma>0 \eta = (\theta,\sigma)^T l(\theta) \theta l(\theta) \dot{l}(\theta) = 0 \theta f(x;\theta,\sigma)=\frac{1}{\sigma}\frac{e^{-\frac{x-\theta}{\sigma}}}{(1+e^{-\frac{x-\theta}{\sigma}})^2} l(\theta,\sigma) = -n\log{\sigma} -n\frac{\bar{x}-\theta}{\sigma} -2 \sum_{i=1}^{n}{\log{(1+e^{-\frac{x_{i}-\theta}{\sigma}})}}        \begin{pmatrix}
\frac{\partial^2 l}{\partial \theta^2} & \frac{\partial^2 l}{\partial \theta \partial\sigma} \\
\frac{\partial^2 l}{\partial \sigma \partial\theta} & \frac{\partial^2 l}{\partial \sigma^2}
\end{pmatrix} 
\begin{aligned}
&\frac{\partial^2 l}{\partial \theta^2}=-\frac{2}{\sigma^2} \sum_{i=1}^n \frac{e^{-\frac{x_i-\theta}{\sigma}}}{\left(1+e^{-\frac{x_i-\theta}{\sigma}}\right)^2} \\
&\frac{\partial^2 l}{\partial \theta \partial \sigma} =\frac{\partial^2 l}{\partial \sigma \partial \theta} =-\frac{n}{\sigma^2}+\frac{2}{\sigma^3} \sum_{i=1}^n \frac{e^{-\frac{x_i-\theta}{\sigma}}\left(\sigma\left(1+e^{-\frac{x_i-\theta}{\sigma}}\right)-\left(x_i-\theta\right)\right)}{\left(1+e^{-\frac{x_i-\theta}{\sigma}}\right)^2} \\
&\frac{\partial^2 l}{\partial \sigma^2} =\frac{n}{\sigma^2}-\frac{2}{\sigma^3} \sum_{i=1}^n x_i+\frac{2 n \theta}{\sigma^3}+\frac{2}{\sigma^4} \sum_{i=1}^n \frac{e^{-\frac{x_i-\theta}{\sigma}}\left(x_i-\theta\right)\left(2 \sigma\left(1+e^{-\frac{x_i-\theta}{\sigma}}\right)-\left(x_i-\theta\right)\right)}{\left(1+e^{-\frac{x_i-\theta}{\sigma}}\right)^2}
\end{aligned}
 \lim_{\theta \rightarrow \infty}{l(\theta,\sigma^*)}=\lim_{\theta \rightarrow -\infty}{l(\theta,\sigma^*)}=\lim_{\sigma \rightarrow 0+}{l(\theta^*,\sigma)}=\lim_{\sigma \rightarrow \infty}{l(\theta^*,\sigma)}=-\infty","['linear-algebra', 'matrices', 'statistics', 'statistical-inference', 'maximum-likelihood']"
66,How to find two small matrices $M_1$ and $M_2$ such that $M_1 M_2 A \approx M A$?,How to find two small matrices  and  such that ?,M_1 M_2 M_1 M_2 A \approx M A,"If we have a matrix $M$ and we want to find its least squares approximation as the product of two smaller (as in less rows or columns) matrices $M_1M_2$ of a given size, we can simply run SVD and pick the entries with the biggest singular values. It's not true, however, that we can do the same to approximate $MA$ as $M_1M_2A$ . For instance, if the rows of A have a mean of $0$ and $M$ is the identity, we need to run PCA on $A$ (instead of $M$ ) to find $M_1$ and $M_2$ . So, short of running gradient descent, is there a simple way of finding the solution? My current best guess is $(MV)(V^T)A$ , with $V$ being the top principal components of $A$ . But that is obviously suboptimal. It would also be very nice if interpreting the columns of $A$ as data samples there was a natural way of applying regularization, so that for few samples or strong regularization the solution was approximately the SVD of $M$ .","If we have a matrix and we want to find its least squares approximation as the product of two smaller (as in less rows or columns) matrices of a given size, we can simply run SVD and pick the entries with the biggest singular values. It's not true, however, that we can do the same to approximate as . For instance, if the rows of A have a mean of and is the identity, we need to run PCA on (instead of ) to find and . So, short of running gradient descent, is there a simple way of finding the solution? My current best guess is , with being the top principal components of . But that is obviously suboptimal. It would also be very nice if interpreting the columns of as data samples there was a natural way of applying regularization, so that for few samples or strong regularization the solution was approximately the SVD of .",M M_1M_2 MA M_1M_2A 0 M A M M_1 M_2 (MV)(V^T)A V A A M,"['linear-algebra', 'statistics', 'matrix-decomposition', 'svd', 'principal-component-analysis']"
67,"Why is it assumed that the mode, in a grouped frequency distribution, lies in the modal class(the class with maximum frequency)?","Why is it assumed that the mode, in a grouped frequency distribution, lies in the modal class(the class with maximum frequency)?",,"I am in 10th standard. We are given a formula to find the mode mode = l +[(f1-f0)/(2f1-f0-f2)]h Where l is the lower limit, F1 the modal class i.e the class with most frequencies, f0 the frequency of class preceding the modal class, F2 the frequency of class succeeding the modal class. Here it is said that it the mode lies in the modal class. But why? Why do we assume that the mode lies in the modal class, even if the actual mode maybe far off.","I am in 10th standard. We are given a formula to find the mode mode = l +[(f1-f0)/(2f1-f0-f2)]h Where l is the lower limit, F1 the modal class i.e the class with most frequencies, f0 the frequency of class preceding the modal class, F2 the frequency of class succeeding the modal class. Here it is said that it the mode lies in the modal class. But why? Why do we assume that the mode lies in the modal class, even if the actual mode maybe far off.",,"['statistics', 'central-tendency']"
68,"Are Confidence Intervals Sometimes ""Arbitrarily"" Multiplied by 2?","Are Confidence Intervals Sometimes ""Arbitrarily"" Multiplied by 2?",,"I am reading an health research paper in which the authors are calculating the percent of males that have a certain disease, and the confidence intervals on this percentage. The authors state that: They studied 20808 males 67.1% of males that they studied have the disease A 95% Confidence Interval of (65.8% and 68.4%) Using the information provided and this post ( Confidence interval without std? ), I tried to calculate this number myself: 2* sqrt((0.671 - 0.671^2)/20808) * 100 = 0.651 % My number comes out as exactly half of the estimates provided by the authors i.e. 68.4 - 67.1 = 67.1 - 65.8 = 2 * 0.651 . I tried to research online to see that if there might be some other formulas that can be used which will result in my calculations being equivalent to the calculations of the authors, but I could not find anything. Does anyone know that if sometimes the Confidence Intervals are ""arbitrarily"" multiplied by 2? (perhaps for a more ""conservative"" estimate) Thank you!","I am reading an health research paper in which the authors are calculating the percent of males that have a certain disease, and the confidence intervals on this percentage. The authors state that: They studied 20808 males 67.1% of males that they studied have the disease A 95% Confidence Interval of (65.8% and 68.4%) Using the information provided and this post ( Confidence interval without std? ), I tried to calculate this number myself: 2* sqrt((0.671 - 0.671^2)/20808) * 100 = 0.651 % My number comes out as exactly half of the estimates provided by the authors i.e. 68.4 - 67.1 = 67.1 - 65.8 = 2 * 0.651 . I tried to research online to see that if there might be some other formulas that can be used which will result in my calculations being equivalent to the calculations of the authors, but I could not find anything. Does anyone know that if sometimes the Confidence Intervals are ""arbitrarily"" multiplied by 2? (perhaps for a more ""conservative"" estimate) Thank you!",,"['probability', 'statistics', 'confidence-interval']"
69,Quantile estimation with apriori known expectation,Quantile estimation with apriori known expectation,,"I have the following problem: If we have a typical random sample $\{X_1, X_2, ...\}$ from some unknown distribution and we want to estimate a quantile we just need to sort our observations and take a specific observation from this sorted sequence. Let us know assume that we know additionally that $\mathbb{E}[X_i] = 0$ (or any other number). My question is: If we have our observations $\{x_1, x_2, ..., x_n\}$ , can we substract from them its sample mean (that should be close to $0$ as $\mathbb{E}[X_i] = 0$ ) and then sort them and take a specific quantile. Is it mathematically correct? Can I say sth about my new quantile estimator? Does it have better or worse properties than the standard one?","I have the following problem: If we have a typical random sample from some unknown distribution and we want to estimate a quantile we just need to sort our observations and take a specific observation from this sorted sequence. Let us know assume that we know additionally that (or any other number). My question is: If we have our observations , can we substract from them its sample mean (that should be close to as ) and then sort them and take a specific quantile. Is it mathematically correct? Can I say sth about my new quantile estimator? Does it have better or worse properties than the standard one?","\{X_1, X_2, ...\} \mathbb{E}[X_i] = 0 \{x_1, x_2, ..., x_n\} 0 \mathbb{E}[X_i] = 0","['statistics', 'estimation', 'quantile']"
70,How do I - formally correct - convert discrete distributions into continous ones?,How do I - formally correct - convert discrete distributions into continous ones?,,"I came across the following question when I was dealing with size-distribution of particles in a gas and was trying to formally convert the binned data to a continous size-distribution. Prior to measurements I divided the measuring range of particle sizes $x$ in $k$ subintervals $[x'_{k},x'_{k+1}]$ and bin sizes $\Delta x_k$ . Every particle within the k-th subinterval is considered to be of size $x_k$ . The total amount of particles detected over the measuring range is given by $N_{tot}$ . Consequently it is $N_{tot} = \sum_k N(x_k) := \sum_k N_k =  \sum_k \frac{N_k}{\Delta x_k}\Delta x_k$ where, $N(x_k) =  N_k$ is the amount counted within the k-th bin. Since bin sizes are not normalized, the particles counted within a bin is, per construction, dependent on bin width and $\frac{N_k}{\Delta x_k}$ represents a normalized view. My question is: How do I - formally correct - turn this discrete distribution into a continous one, as given below? $\int_0^{\infty} \frac{\partial N(x)}{\partial x} \,\operatorname{d}x = \int_0^{\infty} \,  \operatorname{d}N(x) = N_\text{tot}$ My approach was considering the limit of $k \to \infty$ or in other words $\Delta x_k \to 0$ , which however brought me to a similiar expression, but left the $N_k$ somehow untouched $\int_0^{\infty} \frac{N_k}{\partial x} \,\operatorname{d}x$","I came across the following question when I was dealing with size-distribution of particles in a gas and was trying to formally convert the binned data to a continous size-distribution. Prior to measurements I divided the measuring range of particle sizes in subintervals and bin sizes . Every particle within the k-th subinterval is considered to be of size . The total amount of particles detected over the measuring range is given by . Consequently it is where, is the amount counted within the k-th bin. Since bin sizes are not normalized, the particles counted within a bin is, per construction, dependent on bin width and represents a normalized view. My question is: How do I - formally correct - turn this discrete distribution into a continous one, as given below? My approach was considering the limit of or in other words , which however brought me to a similiar expression, but left the somehow untouched","x k [x'_{k},x'_{k+1}] \Delta x_k x_k N_{tot} N_{tot} = \sum_k N(x_k) := \sum_k N_k =  \sum_k \frac{N_k}{\Delta x_k}\Delta x_k N(x_k) =  N_k \frac{N_k}{\Delta x_k} \int_0^{\infty} \frac{\partial N(x)}{\partial x} \,\operatorname{d}x = \int_0^{\infty} \,  \operatorname{d}N(x) = N_\text{tot} k \to \infty \Delta x_k \to 0 N_k \int_0^{\infty} \frac{N_k}{\partial x} \,\operatorname{d}x","['probability', 'statistics', 'data-analysis']"
71,What is the name of the distribution of the maximum number of distinguishable balls in a single distinguishable box?,What is the name of the distribution of the maximum number of distinguishable balls in a single distinguishable box?,,"Imagine that there are $k$ distinguishable balls and $n$ distinguishable boxes. Each ball is placed into a random box. Next we calculate the maximum number of balls in a single box, which will be a value between $\left \lceil \dfrac{k}{n}\right \rceil$ , when the balls are distributed almost evenly, and $k$ , all balls in one box. Let's call this $X_{k,n}$ What distribution does $X_{k,n}$ follow? I've encountered a situation where $k$ is about $100,000$ and $n$ is about $100$ . How could I estimate the CDF for these particular values? What is $\mathbb{P}(X_{k,n}<2000)$ ?","Imagine that there are distinguishable balls and distinguishable boxes. Each ball is placed into a random box. Next we calculate the maximum number of balls in a single box, which will be a value between , when the balls are distributed almost evenly, and , all balls in one box. Let's call this What distribution does follow? I've encountered a situation where is about and is about . How could I estimate the CDF for these particular values? What is ?","k n \left \lceil \dfrac{k}{n}\right \rceil k X_{k,n} X_{k,n} k 100,000 n 100 \mathbb{P}(X_{k,n}<2000)","['probability', 'statistics', 'balls-in-bins']"
72,"What is the distribution of $Y_n=\ln\left(\text{ }1+\big(\frac{1}{n}\sum_{i=1}^{n}X_i\big)^2\text{ }\right)$, where $\forall i: X_i \sim G({1\over2})$","What is the distribution of , where",Y_n=\ln\left(\text{ }1+\big(\frac{1}{n}\sum_{i=1}^{n}X_i\big)^2\text{ }\right) \forall i: X_i \sim G({1\over2}),"Given $\big(X_i\big)_{i=1}^{\infty}$ a series of independent random variables, $X_i \sim G({1\over2})$ (Geometric distribution) for all $i \ge 1$ . For $n \ge 2$ , we mark the following: $$\bar X_n = \frac{1}{n}\sum_{i=1}^{n}X_i  \quad\quad\quad  Y_n=\ln\big(1 + (\bar X_n)^2 \big)  \quad\quad\quad T_n = (Y_n - \ln5)^2 $$ And we need to find the value $C_n$ and the distribution of $T$ , which satisfies: $$ \frac{1}{C_n} \sum_{n=1}^{12} T_n  \overset{d}{\to} T $$ $$$$ Well, i'll save you the trouble. The final and correct answer is $$C_n=\frac{32}{25n}, \quad T_n \sim \chi^2_{(12)} \text{  (chi distribution with 12 degrees of freedom)}$$ But i can't understand why. This is all I know so far: Let $\big(Z_i\big)_{i=1}^{n}$ be a series of independent random variable with the same distribution $Z_i \sim N(\mu, \sigma^2)$ , then we know that $\frac{Z_i - \mu}{\sigma} \sim N(0,1)$ for all $i$ , and we know that the distribution of the following sum is: $\sum_{i=1}^n  \big( \frac{Z_i-\mu}{\sigma} \big)^2 \sim \chi^2_{(n)}$ . My guess is that in my question: $Z_i := Y_n = \ln\big(1 + (\bar X_n)^2 \big)$ $\mu := E(Y_n)  = \ln5$ $\sigma^2 := V(Z_i) = C_n$ and thus: $$\sum_{i=1}^n  \big( \frac{Z_i-\mu}{\sigma} \big)^2  =   \frac{\sum_{i=1}^n  ( Z_i-\mu )^2}{{\sigma}^2} := \frac{\sum_{n=1}^{12} T_n}{C_n}   \overset{d}{\to} T $$ But i can't understand how is that $E(Y_n)=\ln5$ , or even what is the distribution of $Y_n$ ? Am I on the right track? What are your thoughts about this question? How would you solve it?","Given a series of independent random variables, (Geometric distribution) for all . For , we mark the following: And we need to find the value and the distribution of , which satisfies: Well, i'll save you the trouble. The final and correct answer is But i can't understand why. This is all I know so far: Let be a series of independent random variable with the same distribution , then we know that for all , and we know that the distribution of the following sum is: . My guess is that in my question: and thus: But i can't understand how is that , or even what is the distribution of ? Am I on the right track? What are your thoughts about this question? How would you solve it?","\big(X_i\big)_{i=1}^{\infty} X_i \sim G({1\over2}) i \ge 1 n \ge 2 \bar X_n = \frac{1}{n}\sum_{i=1}^{n}X_i  \quad\quad\quad 
Y_n=\ln\big(1 + (\bar X_n)^2 \big)  \quad\quad\quad
T_n = (Y_n - \ln5)^2
 C_n T 
\frac{1}{C_n} \sum_{n=1}^{12} T_n  \overset{d}{\to} T
  C_n=\frac{32}{25n}, \quad T_n \sim \chi^2_{(12)} \text{  (chi distribution with 12 degrees of freedom)} \big(Z_i\big)_{i=1}^{n} Z_i \sim N(\mu, \sigma^2) \frac{Z_i - \mu}{\sigma} \sim N(0,1) i \sum_{i=1}^n  \big( \frac{Z_i-\mu}{\sigma} \big)^2 \sim \chi^2_{(n)} Z_i := Y_n = \ln\big(1 + (\bar X_n)^2 \big) \mu := E(Y_n)  = \ln5 \sigma^2 := V(Z_i) = C_n \sum_{i=1}^n  \big( \frac{Z_i-\mu}{\sigma} \big)^2  =  
\frac{\sum_{i=1}^n  ( Z_i-\mu )^2}{{\sigma}^2} :=
\frac{\sum_{n=1}^{12} T_n}{C_n}   \overset{d}{\to} T
 E(Y_n)=\ln5 Y_n","['probability', 'statistics', 'probability-distributions']"
73,Hoeffding's type inequality for isotonic regression,Hoeffding's type inequality for isotonic regression,,"Let $n \in \mathbb{N}$ and let $0 \le y_1 \le \dots \le y_n \le 1$ . Suppose that $(Y_{k,t})_{k\in\{1,\dots,n\}, t\in\mathbb{N}}$ is a family of independent random variables such that, for each $k\in\{1,\dots,n\}$ , $(Y_{k,t})_{t\in\mathbb{N}}$ is a sequence of Bernoulli random variables of parameter $y_k$ . Let $T_1,\dots,T_n\in\mathbb{N}$ . Let $(\hat{Y}_1,\dots,\hat{Y}_n)$ be the solution of the quadratic constrained minimization problem \begin{equation*}    \min_{0\le\hat{y}_1\le\dots\le\hat{y}_n\le1} \sum_{k=1}^n \sum_{t=1}^{T_k}(\hat{y_k}-Y_{k,t})^2 \end{equation*} I'm looking for Hoeffding's inequality type guarantees for these estimators. Precisely, can we found (sharp, or nearly sharp, and hopefully better than the ones that hold for Hoeffding's inequality) constants $c_1,c_2>0$ such that, for each $n \in \mathbb{N}$ , each $0\le y_1 \le \dots\le y_n \le 1$ , each $T_1,\dots, T_n\in\mathbb{N}$ , each $a_1,\dots,a_n \in \mathbb{R}$ and each $\delta\in (0,1)$ it holds \begin{equation*}    \mathbb{P}\bigg[ \bigg| \sum_{k=1}^n a_k\hat{Y}_k- \sum_{k=1}^n a_ky_k\bigg|\ge \sqrt{c_1 \sum_{k=1}^n\frac{a_k^2}{T_k} \log \Big(\frac{c_2}{\delta}\Big)}    \bigg] \le \delta \;? \end{equation*} (Notice that this inequality would hold with $c_1 = \frac{1}{2}$ and $c_2 = 2$ if we replace each estimator $\hat{Y}_k$ with $\frac{1}{T_k} \sum_{t=1}^{T_k} Y_{k,t}$ , due to Hoeffding's inequality ). Even the cases where all the $a_k$ are $0$ except one whose value is $1$ , or all the $a_k$ are $0$ except two whose value is $-1$ and $1$ respectively, or all the $a_k$ are equal to $1/n$ , would be interesting for me. I've seen that the solution to the previous minimization problem goes under the name isotonic regression , but I realized that the literature is extremely vast and found myself quickly lost. I would very much appreciate even a pointer to some reference where this problem is properly addressed.","Let and let . Suppose that is a family of independent random variables such that, for each , is a sequence of Bernoulli random variables of parameter . Let . Let be the solution of the quadratic constrained minimization problem I'm looking for Hoeffding's inequality type guarantees for these estimators. Precisely, can we found (sharp, or nearly sharp, and hopefully better than the ones that hold for Hoeffding's inequality) constants such that, for each , each , each , each and each it holds (Notice that this inequality would hold with and if we replace each estimator with , due to Hoeffding's inequality ). Even the cases where all the are except one whose value is , or all the are except two whose value is and respectively, or all the are equal to , would be interesting for me. I've seen that the solution to the previous minimization problem goes under the name isotonic regression , but I realized that the literature is extremely vast and found myself quickly lost. I would very much appreciate even a pointer to some reference where this problem is properly addressed.","n \in \mathbb{N} 0 \le y_1 \le \dots \le y_n \le 1 (Y_{k,t})_{k\in\{1,\dots,n\}, t\in\mathbb{N}} k\in\{1,\dots,n\} (Y_{k,t})_{t\in\mathbb{N}} y_k T_1,\dots,T_n\in\mathbb{N} (\hat{Y}_1,\dots,\hat{Y}_n) \begin{equation*}
   \min_{0\le\hat{y}_1\le\dots\le\hat{y}_n\le1} \sum_{k=1}^n \sum_{t=1}^{T_k}(\hat{y_k}-Y_{k,t})^2
\end{equation*} c_1,c_2>0 n \in \mathbb{N} 0\le y_1 \le \dots\le y_n \le 1 T_1,\dots, T_n\in\mathbb{N} a_1,\dots,a_n \in \mathbb{R} \delta\in (0,1) \begin{equation*}
   \mathbb{P}\bigg[ \bigg| \sum_{k=1}^n a_k\hat{Y}_k- \sum_{k=1}^n a_ky_k\bigg|\ge \sqrt{c_1 \sum_{k=1}^n\frac{a_k^2}{T_k} \log \Big(\frac{c_2}{\delta}\Big)}    \bigg] \le \delta \;?
\end{equation*} c_1 = \frac{1}{2} c_2 = 2 \hat{Y}_k \frac{1}{T_k} \sum_{t=1}^{T_k} Y_{k,t} a_k 0 1 a_k 0 -1 1 a_k 1/n","['statistics', 'convex-optimization', 'regression', 'concentration-of-measure', 'large-deviation-theory']"
74,How to integrate products of exponential of exponential (or polynomials) and Gaussian functions,How to integrate products of exponential of exponential (or polynomials) and Gaussian functions,,"Gaussian functions often appear in conditional expectation integrals. I am interested to know if analytic integrals of the following forms are available $$ \int \exp(-\exp(a x))   \exp(\frac{-(x-\mu)^2}{\sigma^2}) \; dx \quad\quad\quad (*) $$ or \begin{equation} \int \exp( P(a x))   \exp(\frac{-(x-\mu)^2}{\sigma^2}) \; dx \end{equation} where $P$ is a polynomial in $x$ , and $a$ , $\mu$ and $\sigma$ are real constants. While the first integral is the one I would like to solve, I can rewrite the double exponential as a series \begin{eqnarray} \text{Series}[\exp (-\exp (a x)),\{x,0,8\}] &=& \exp\left( -1-a x-\frac{a^2 x^2}{2}-\frac{a^3 x^3}{6}-\frac{a^4 x^4}{24}-\frac{a^5 x^5}{120}-\frac{a^6 x^6}{720}-\frac{a^7 x^7}{5040}+O\left(x^8\right)   \right)      \\ &=& \frac{1}{e}-\frac{a x}{e}+\frac{a^3 x^3}{6 e}+\frac{a^4 x^4}{24 e}-\frac{a^5 x^5}{60 e}-\frac{a^6 x^6}{80 e}-\frac{a^7 x^7}{560 e}+O\left(x^8\right) \end{eqnarray} and this allows the integral in equation $(*)$ to be written as a sum of integrals of the form. \begin{equation} \sum_{n=1}^{\infty} c_n \int(ax)^n  \exp(\frac{-(x-\mu)^2}{\sigma^2}) \; dx \end{equation} so that each term looks like it is related to a moment-like integral (as listed on https://en.wikipedia.org/wiki/List_of_integrals_of_Gaussian_functions ). $\int \phi(x) \; dx=\Phi(x)+C$ $\int x \phi(x) \;dx=−\phi(x)+C$ $\int x^2 \phi(x)dx=Φ(x)−x\phi(x)+C$ $\int x^{2k+1} \phi(x)\;dx=−\phi(x)\sum_{j=0}^{k}\frac{(2k)!!}{(2j)!!} x^{2j}+C$ $\int x^{2k+2} \phi(x)\;dx=−\phi(x)\sum_{j=0}^{k}\frac{(2k+1)!!}{(2j+1)!!}x^{2j+1}+(2k+1)!!\Phi(x)+C$ While practically it may be possible to truncate the series and obtain numerical results, it would be much nicer if the definite integral for the exponent of exponent form exists. I would be grateful if anyone recognises the form of the integral in equation $(*)$ and could point me to its definite integrated form. I have not been able to locate it in some of the standard references.","Gaussian functions often appear in conditional expectation integrals. I am interested to know if analytic integrals of the following forms are available or where is a polynomial in , and , and are real constants. While the first integral is the one I would like to solve, I can rewrite the double exponential as a series and this allows the integral in equation to be written as a sum of integrals of the form. so that each term looks like it is related to a moment-like integral (as listed on https://en.wikipedia.org/wiki/List_of_integrals_of_Gaussian_functions ). While practically it may be possible to truncate the series and obtain numerical results, it would be much nicer if the definite integral for the exponent of exponent form exists. I would be grateful if anyone recognises the form of the integral in equation and could point me to its definite integrated form. I have not been able to locate it in some of the standard references.","
\int \exp(-\exp(a x))   \exp(\frac{-(x-\mu)^2}{\sigma^2}) \; dx \quad\quad\quad (*)
 \begin{equation}
\int \exp( P(a x))   \exp(\frac{-(x-\mu)^2}{\sigma^2}) \; dx
\end{equation} P x a \mu \sigma \begin{eqnarray}
\text{Series}[\exp (-\exp (a x)),\{x,0,8\}] &=& \exp\left( -1-a x-\frac{a^2 x^2}{2}-\frac{a^3 x^3}{6}-\frac{a^4 x^4}{24}-\frac{a^5 x^5}{120}-\frac{a^6 x^6}{720}-\frac{a^7 x^7}{5040}+O\left(x^8\right)   \right)      \\
&=& \frac{1}{e}-\frac{a x}{e}+\frac{a^3 x^3}{6 e}+\frac{a^4 x^4}{24 e}-\frac{a^5 x^5}{60 e}-\frac{a^6 x^6}{80 e}-\frac{a^7 x^7}{560 e}+O\left(x^8\right)
\end{eqnarray} (*) \begin{equation}
\sum_{n=1}^{\infty} c_n \int(ax)^n  \exp(\frac{-(x-\mu)^2}{\sigma^2}) \; dx
\end{equation} \int \phi(x) \; dx=\Phi(x)+C \int x \phi(x) \;dx=−\phi(x)+C \int x^2 \phi(x)dx=Φ(x)−x\phi(x)+C \int x^{2k+1} \phi(x)\;dx=−\phi(x)\sum_{j=0}^{k}\frac{(2k)!!}{(2j)!!} x^{2j}+C \int x^{2k+2} \phi(x)\;dx=−\phi(x)\sum_{j=0}^{k}\frac{(2k+1)!!}{(2j+1)!!}x^{2j+1}+(2k+1)!!\Phi(x)+C (*)","['integration', 'statistics', 'expected-value', 'conditional-expectation', 'gaussian']"
75,What is the expectation of the exponential distribution multiplied by indicator function?,What is the expectation of the exponential distribution multiplied by indicator function?,,"I am reading research paper [A New Bayesian Lasso] , where $u$ has the distribution The expectation of $u_j$ is given by $$\frac{1}{\lambda}+|\beta_j|$$ . I know that the term $\frac{1}{\lambda}$ is the expectation of the exponential distribution but where did the term $|\beta_j|$ come from? I have tried to calculate $$\int _{|\beta_j|}^\infty u_j \lambda \text{Exp}(-\lambda u_j)du_j=\text{Exp}(-\lambda |\beta_j| )\left(\frac{1}{\lambda}+|\beta_j|\right)$$ which gives $\frac{1}{\lambda}+|\beta_j|$ multiplied by $\text{Exp}(-\lambda |\beta_j| )$ .","I am reading research paper [A New Bayesian Lasso] , where has the distribution The expectation of is given by . I know that the term is the expectation of the exponential distribution but where did the term come from? I have tried to calculate which gives multiplied by .",u u_j \frac{1}{\lambda}+|\beta_j| \frac{1}{\lambda} |\beta_j| \int _{|\beta_j|}^\infty u_j \lambda \text{Exp}(-\lambda u_j)du_j=\text{Exp}(-\lambda |\beta_j| )\left(\frac{1}{\lambda}+|\beta_j|\right) \frac{1}{\lambda}+|\beta_j| \text{Exp}(-\lambda |\beta_j| ),"['probability', 'statistics', 'expected-value']"
76,Can we leverage a priori information about monotonicity of parameters to improve estimation?,Can we leverage a priori information about monotonicity of parameters to improve estimation?,,"Suppose $(X_t)_{t \in\mathbb{N}}$ and $(Y_t)_{t \in \mathbb{N}}$ are two independent sequences of i.i.d. Bernoulli random variables, the first one of parameter $x \in [0,1]$ and the second one of parameter $y \in [x,1]$ (so, in particular $\forall t \in \mathbb{N}, \mathbb{P}[X_t = 1] =x = (1-\mathbb{P}[X_t = 0])$ and $\forall t \in \mathbb{N}, \mathbb{P}[Y_t = 1] =y = (1-\mathbb{P}[Y_t = 0])$ ). Our goal is to estimate $y-x$ using $X_1,\dots,X_{T_1},Y_1,\dots,Y_{T_2}$ , where $T_1,T_2 \in \mathbb{N}$ . My first guess was to use the estimate $$\frac{1}{T_2} \sum_{t=1}^{T_2} Y_t - \frac{1}{T_1} \sum_{t=1}^{T_1} X_t$$ because, for any $\varepsilon > 0$ , we can rely on Hoeffding's inequality \begin{equation*} \mathbb{P}\Bigg[\bigg| \Big(\frac{1}{T_2} \sum_{t=1}^{T_2} Y_t - \frac{1}{T_1} \sum_{t=1}^{T_1} X_t\Big) -(y-x)\bigg| \ge \varepsilon\Bigg] \le 2 \exp\Bigg(-\frac{2\varepsilon^2}{\frac{1}{T_1}+\frac{1}{T_2}}\Bigg) \;,    \end{equation*} which, for any $\delta \in (0,1)$ , can be re-read as \begin{equation*} \mathbb{P}\Bigg[\bigg| \Big(\frac{1}{T_2} \sum_{t=1}^{T_2} Y_t - \frac{1}{T_1} \sum_{t=1}^{T_1} X_t\Big) -(y-x)\bigg| \ge \sqrt{\frac{1}{2}\Big( \frac{1}{T_1}+\frac{1}{T_2}\Big)\log\Big(\frac{2}{\delta}\Big)}\Bigg] \le \delta\;. \end{equation*} However, due to noise, it could very well happen that $\frac{1}{T_2} \sum_{t=1}^{T_2} Y_t - \frac{1}{T_1} \sum_{t=1}^{T_1} X_t <0$ , meaning that our estimate is completely meaningless given our prior information that $y\ge x$ . I thought, since $\big(\frac{1}{T_1} \sum_{t=1}^{T_1} X_t,\frac{1}{T_2}\sum_{t=1}^{T_2} Y_t\big)$ is the solution to the unconstrained minimization problem relative to the function $$ (x',y') \mapsto \bigg(\sum_{t=1}^{T_1} (X_t-x')^2+ \sum_{t=1}^{T_2}(Y_t-y')^2\bigg) \;,$$ that a better idea could be to return the estimate $\hat{y}_{T_1,T_2}-\hat{x}_{T_1,T_2}$ , where $(\hat{x}_{T_1,T_2},\hat{y}_{T_1,T_2})$ is the solution to the corresponding constrained minimization problem, i.e., $$ (\hat{x}_{T_1,T_2},\hat{y}_{T_1,T_2}) \in \mathrm{argmin}_{(x',y') \in [0,1]^2 \\ \textrm{ s.t. }x' \le y'} \Big(\sum_{t=1}^{T_1} (X_t-x')^2+ \sum_{t=1}^{T_2}(Y_t-y')^2\Big) \;. $$ Doing this, by construction, we are guaranteed to have $\hat{y}_{T_1,T_2} - \hat{x}_{T_1,T_2} \ge 0$ . I'm wondering if an analogous to the guarantees we have derived from Hoeffding's inequality for the estimator $\frac{1}{T_2} \sum_{t=1}^{T_2} Y_t - \frac{1}{T_1} \sum_{t=1}^{T_1} X_t$ holds also for the estimator $\hat{y}_{T_1,T_2}-\hat{x}_{T_1,T_2}$ , maybe relying on other probabilistic arguments. Here the question: Do there exist constants $c_1,c_2>0$ such that for every $x,y \in [0,1]$ with $x\le y$ , for any $T_1,T_2 \in \mathbb{N}$ and for any $\delta \in (0,1)$ we have that $$\mathbb{P}\Bigg[\bigg|(\hat{y}_{T_1,T_2}-\hat{x}_{T_1,T_2}) -(y-x)\bigg| \ge \sqrt{c_1\Big( \frac{1}{T_1}+\frac{1}{T_2}\Big)\log\Big(\frac{c_2}{\delta}\Big)}\Bigg] \le \delta\;.$$ In this case, might we also guarantee that $c_1 \le \frac{1}{2}$ and $c_2 \le 2$ ?","Suppose and are two independent sequences of i.i.d. Bernoulli random variables, the first one of parameter and the second one of parameter (so, in particular and ). Our goal is to estimate using , where . My first guess was to use the estimate because, for any , we can rely on Hoeffding's inequality which, for any , can be re-read as However, due to noise, it could very well happen that , meaning that our estimate is completely meaningless given our prior information that . I thought, since is the solution to the unconstrained minimization problem relative to the function that a better idea could be to return the estimate , where is the solution to the corresponding constrained minimization problem, i.e., Doing this, by construction, we are guaranteed to have . I'm wondering if an analogous to the guarantees we have derived from Hoeffding's inequality for the estimator holds also for the estimator , maybe relying on other probabilistic arguments. Here the question: Do there exist constants such that for every with , for any and for any we have that In this case, might we also guarantee that and ?","(X_t)_{t \in\mathbb{N}} (Y_t)_{t \in \mathbb{N}} x \in [0,1] y \in [x,1] \forall t \in \mathbb{N}, \mathbb{P}[X_t = 1] =x = (1-\mathbb{P}[X_t = 0]) \forall t \in \mathbb{N}, \mathbb{P}[Y_t = 1] =y = (1-\mathbb{P}[Y_t = 0]) y-x X_1,\dots,X_{T_1},Y_1,\dots,Y_{T_2} T_1,T_2 \in \mathbb{N} \frac{1}{T_2} \sum_{t=1}^{T_2} Y_t - \frac{1}{T_1} \sum_{t=1}^{T_1} X_t \varepsilon > 0 \begin{equation*}
\mathbb{P}\Bigg[\bigg| \Big(\frac{1}{T_2} \sum_{t=1}^{T_2} Y_t - \frac{1}{T_1} \sum_{t=1}^{T_1} X_t\Big) -(y-x)\bigg| \ge \varepsilon\Bigg] \le 2 \exp\Bigg(-\frac{2\varepsilon^2}{\frac{1}{T_1}+\frac{1}{T_2}}\Bigg) \;,   
\end{equation*} \delta \in (0,1) \begin{equation*}
\mathbb{P}\Bigg[\bigg| \Big(\frac{1}{T_2} \sum_{t=1}^{T_2} Y_t - \frac{1}{T_1} \sum_{t=1}^{T_1} X_t\Big) -(y-x)\bigg| \ge \sqrt{\frac{1}{2}\Big( \frac{1}{T_1}+\frac{1}{T_2}\Big)\log\Big(\frac{2}{\delta}\Big)}\Bigg] \le \delta\;.
\end{equation*} \frac{1}{T_2} \sum_{t=1}^{T_2} Y_t - \frac{1}{T_1} \sum_{t=1}^{T_1} X_t <0 y\ge x \big(\frac{1}{T_1} \sum_{t=1}^{T_1} X_t,\frac{1}{T_2}\sum_{t=1}^{T_2} Y_t\big)  (x',y') \mapsto \bigg(\sum_{t=1}^{T_1} (X_t-x')^2+ \sum_{t=1}^{T_2}(Y_t-y')^2\bigg) \;, \hat{y}_{T_1,T_2}-\hat{x}_{T_1,T_2} (\hat{x}_{T_1,T_2},\hat{y}_{T_1,T_2})  (\hat{x}_{T_1,T_2},\hat{y}_{T_1,T_2}) \in \mathrm{argmin}_{(x',y') \in [0,1]^2 \\ \textrm{ s.t. }x' \le y'} \Big(\sum_{t=1}^{T_1} (X_t-x')^2+ \sum_{t=1}^{T_2}(Y_t-y')^2\Big) \;.  \hat{y}_{T_1,T_2} - \hat{x}_{T_1,T_2} \ge 0 \frac{1}{T_2} \sum_{t=1}^{T_2} Y_t - \frac{1}{T_1} \sum_{t=1}^{T_1} X_t \hat{y}_{T_1,T_2}-\hat{x}_{T_1,T_2} c_1,c_2>0 x,y \in [0,1] x\le y T_1,T_2 \in \mathbb{N} \delta \in (0,1) \mathbb{P}\Bigg[\bigg|(\hat{y}_{T_1,T_2}-\hat{x}_{T_1,T_2}) -(y-x)\bigg| \ge \sqrt{c_1\Big( \frac{1}{T_1}+\frac{1}{T_2}\Big)\log\Big(\frac{c_2}{\delta}\Big)}\Bigg] \le \delta\;. c_1 \le \frac{1}{2} c_2 \le 2","['probability-theory', 'statistics', 'concentration-of-measure', 'parameter-estimation']"
77,How to get the rejection region and type II error probability?,How to get the rejection region and type II error probability?,,"In this paper https://arxiv.org/abs/2102.00356 , in the section 5.2 the author does the independent test on Section 5. Assume that $\pi$ is the coupling of probability measures $\mu$ and $\nu$ on $[0,1]$ . The hypothesis test for independence is that $$ H_0: \pi=\mu\times \nu \, , H_a: \pi\neq \mu\times \nu $$ The test statistic is $W(\hat{\pi}^N)$ . In my understanding, this Corollary says that under $H_0$ holds, we reject the $H_0$ if $$ W(\hat{\pi}^N)>C(\nu)(C_N+\frac{\sigma}{\sqrt{N}}\Phi^{-1}(1-\alpha)) $$ In the paper, the author upper bound the estimator by an asymptotic normal  random variable as in the proof in P11, that is $$ W(\hat{\pi}^N)\le C(\nu)T_N(\pi) $$ where under $H_0$ holds, $\sqrt{N}(T_N(\pi)-C_N)/\sigma\to N(0,1)$ in Lemma A.1 (page 25). My question is that Q1: How to get this rejection region? It seems that we need to upper bound $$ P(W(\hat{\pi}^N)>C(\nu)(C_N+\frac{\sigma}{\sqrt{N}}\Phi^{-1}(1-\alpha))|H_0 true)\le \alpha $$ for significance level $\alpha$ . Q2: In the simulation, for two data sets $X\sim Unif[0,1]$ and $Y=0.2X$ (they are dependent), why $$ P(\text{type II error})=P(\text{accept} H_0|H_0 \text{false})=P(W(\hat{\pi}^N)>>C(\nu)(C_N+\frac{\sigma}{\sqrt{N}}\Phi^{-1}(1-\alpha))? $$ It seems this Corollary holds as $H_0$ is true. But here our data samples are not independent ( $H_0$ is wrong).","In this paper https://arxiv.org/abs/2102.00356 , in the section 5.2 the author does the independent test on Section 5. Assume that is the coupling of probability measures and on . The hypothesis test for independence is that The test statistic is . In my understanding, this Corollary says that under holds, we reject the if In the paper, the author upper bound the estimator by an asymptotic normal  random variable as in the proof in P11, that is where under holds, in Lemma A.1 (page 25). My question is that Q1: How to get this rejection region? It seems that we need to upper bound for significance level . Q2: In the simulation, for two data sets and (they are dependent), why It seems this Corollary holds as is true. But here our data samples are not independent ( is wrong).","\pi \mu \nu [0,1] 
H_0: \pi=\mu\times \nu \, , H_a: \pi\neq \mu\times \nu
 W(\hat{\pi}^N) H_0 H_0 
W(\hat{\pi}^N)>C(\nu)(C_N+\frac{\sigma}{\sqrt{N}}\Phi^{-1}(1-\alpha))
 
W(\hat{\pi}^N)\le C(\nu)T_N(\pi)
 H_0 \sqrt{N}(T_N(\pi)-C_N)/\sigma\to N(0,1) 
P(W(\hat{\pi}^N)>C(\nu)(C_N+\frac{\sigma}{\sqrt{N}}\Phi^{-1}(1-\alpha))|H_0 true)\le \alpha
 \alpha X\sim Unif[0,1] Y=0.2X 
P(\text{type II error})=P(\text{accept} H_0|H_0 \text{false})=P(W(\hat{\pi}^N)>>C(\nu)(C_N+\frac{\sigma}{\sqrt{N}}\Phi^{-1}(1-\alpha))?
 H_0 H_0","['probability', 'statistics']"
78,Help with proof (by induction) for unbiasedness of an estimator,Help with proof (by induction) for unbiasedness of an estimator,,"I am reading a paper where the following estimator is used for estimating the sample mean from a series of observations/data-points $\{r_1, r_2,....,r_n\}$ : $$ r_n = \lambda_n p + (1-\lambda_n) \hat{p_{n-1}} $$ , where $\hat{p_{n-1}}$ is defined as: $$ \hat{p_{n-1}} = \frac{\sum_{i=1}^{n-1} r_i}{n-1}$$ . For more context, it is assumed that the observations $\{r_1, r_2,....,r_n\}$ are collected sequentially, i.e., first $r_1$ is observed, followed by $r_2$ and so on. Also the subsequent $r$ values depend on the previous values. It is given that $$\mathbb{E}[r_1] = \mathbb{E}[\hat{p_{1}}] = p  $$ , where $p$ is the $\textbf{true}$ estimate of the sample mean. It is claimed in the paper that the estimator $r_n$ is an unbiased estimator of the true mean $p$ . The proof in the paper works as follows by induction: Base case $$\mathbb{E}[r_1] = \mathbb{E}[\hat{p_{1}}] = p  $$ . Then by induction: $$\mathbb{E}[\hat{p_{n}}] = \frac{(n-1) \mathbb{E}[\hat{p_{n-1}}] + \mathbb{E}[r_n] }{n} \\  = \frac{ \lambda_n p + (n-\lambda_n) \mathbb{E}[\hat{p_{n-1}}]   }{n} \\ = p $$ I don't understand how 3rd step is derived from the second step. $$\mathbb{E}[r_n] = \mathbb{E}[\lambda_n p + (1-\lambda_n) \hat{p_{n-1}}] \\  = \lambda_n p + (1-\lambda_n) \mathbb{E}[\hat{p_{n-1}}] \\ = p $$ Is this correct? From my understanding, for proof by induction, first base case should be correct, followed by assuming the statement for some value $k$ , followed by extending it for case $k+1$ . In this proof, I couldn't generalize from $r_k$ to $r_{k+1}$ (or from $\hat{p_{n}}$ to $\hat{p_{n-1}}$ ). They use these equations for the final proof of unbiasedness as follows:","I am reading a paper where the following estimator is used for estimating the sample mean from a series of observations/data-points : , where is defined as: . For more context, it is assumed that the observations are collected sequentially, i.e., first is observed, followed by and so on. Also the subsequent values depend on the previous values. It is given that , where is the estimate of the sample mean. It is claimed in the paper that the estimator is an unbiased estimator of the true mean . The proof in the paper works as follows by induction: Base case . Then by induction: I don't understand how 3rd step is derived from the second step. Is this correct? From my understanding, for proof by induction, first base case should be correct, followed by assuming the statement for some value , followed by extending it for case . In this proof, I couldn't generalize from to (or from to ). They use these equations for the final proof of unbiasedness as follows:","\{r_1, r_2,....,r_n\}  r_n = \lambda_n p + (1-\lambda_n) \hat{p_{n-1}}  \hat{p_{n-1}}  \hat{p_{n-1}} = \frac{\sum_{i=1}^{n-1} r_i}{n-1} \{r_1, r_2,....,r_n\} r_1 r_2 r \mathbb{E}[r_1] = \mathbb{E}[\hat{p_{1}}] = p   p \textbf{true} r_n p \mathbb{E}[r_1] = \mathbb{E}[\hat{p_{1}}] = p   \mathbb{E}[\hat{p_{n}}] = \frac{(n-1) \mathbb{E}[\hat{p_{n-1}}] + \mathbb{E}[r_n] }{n} \\ 
= \frac{ \lambda_n p + (n-\lambda_n) \mathbb{E}[\hat{p_{n-1}}]   }{n} \\
= p  \mathbb{E}[r_n] = \mathbb{E}[\lambda_n p + (1-\lambda_n) \hat{p_{n-1}}] \\ 
= \lambda_n p + (1-\lambda_n) \mathbb{E}[\hat{p_{n-1}}] \\
= p  k k+1 r_k r_{k+1} \hat{p_{n}} \hat{p_{n-1}}","['statistics', 'solution-verification', 'induction', 'expected-value', 'conditional-expectation']"
79,Conditional probability with 4 coins,Conditional probability with 4 coins,,"The question: A box contains four coins, two of which are fair, one double-headed (i.e., heads on both sides), and the third is biased in such a way that it comes up heads with probability 1/4. A coin is drawn at random from the box and flipped twice. If both flips result in heads, what is the probability that the coin drawn was double-headed? From what I understand, there are 2 fair coins with a 1/2 chance to get heads, 1 coin that has 100% chance of getting heads, and one coin with a 1/4 chance to get heads. Does this mean, for example, that the chance of getting heads in both flips from a fair coin is 1/8? Since there's a 2/4 (1/2) chance to pick one? I just cannot understand the formulation of the question but I assume we have to use Baye's theorem here? I would appreciate any help here! Thanks","The question: A box contains four coins, two of which are fair, one double-headed (i.e., heads on both sides), and the third is biased in such a way that it comes up heads with probability 1/4. A coin is drawn at random from the box and flipped twice. If both flips result in heads, what is the probability that the coin drawn was double-headed? From what I understand, there are 2 fair coins with a 1/2 chance to get heads, 1 coin that has 100% chance of getting heads, and one coin with a 1/4 chance to get heads. Does this mean, for example, that the chance of getting heads in both flips from a fair coin is 1/8? Since there's a 2/4 (1/2) chance to pick one? I just cannot understand the formulation of the question but I assume we have to use Baye's theorem here? I would appreciate any help here! Thanks",,"['probability', 'statistics', 'bayes-theorem']"
80,p-value expressed in terms of angles,p-value expressed in terms of angles,,"Let $X_1,...,X_n$ be i.i.d. random variables with $E(X_i)=\mu$ and $V(X_i)=\sigma^2$ . Suppose we are to test $H_0 : \mu=0$ against $H_1 : \mu >0$ , we try to base our test statistic on $\tau_n = \frac{\sqrt{n}\bar{X}}{s_n}$ where $s_n$ is the sample standard deviation. Again, see that $\tau_n$ can be written as $\sqrt{n-1}\cot \theta$ where $\theta$ is the angle between $(1,....,1)'/ \sqrt{n}$ and $(X_1,...,X_n)$ . It can also be observed that $\tau_n$ is a monotonic decreasing function of $\theta$ . My question is can we find the p-value expressed in terms of the observed $\theta$ , say $\theta_0$ ?","Let be i.i.d. random variables with and . Suppose we are to test against , we try to base our test statistic on where is the sample standard deviation. Again, see that can be written as where is the angle between and . It can also be observed that is a monotonic decreasing function of . My question is can we find the p-value expressed in terms of the observed , say ?","X_1,...,X_n E(X_i)=\mu V(X_i)=\sigma^2 H_0 : \mu=0 H_1 : \mu >0 \tau_n = \frac{\sqrt{n}\bar{X}}{s_n} s_n \tau_n \sqrt{n-1}\cot \theta \theta (1,....,1)'/ \sqrt{n} (X_1,...,X_n) \tau_n \theta \theta \theta_0","['probability-theory', 'statistics', 'probability-distributions', 'statistical-inference', 'hypothesis-testing']"
81,How to compare scores with different possible point totals,How to compare scores with different possible point totals,,"Is there way to fairly compare multiple scores with varying possible point totals such as 26/90, 54/70,67/80, etc...? This is based on the same test but not all questions apply to everyone taking it, so people don't lose or gain points if they are not able to answer. We also can not only compare questions relating to all participants. 90 is the maximum amount possible to score if all questions answered.","Is there way to fairly compare multiple scores with varying possible point totals such as 26/90, 54/70,67/80, etc...? This is based on the same test but not all questions apply to everyone taking it, so people don't lose or gain points if they are not able to answer. We also can not only compare questions relating to all participants. 90 is the maximum amount possible to score if all questions answered.",,['statistics']
82,Statistic distribution of the sum of $n$ random variables,Statistic distribution of the sum of  random variables,n,"Assume we have $n$ real variables $x_i$ ,  where ${i=1,2,\cdots, n}$ . They are independent random variables uniformly distributed in $[0,1]$ . We define the variable $y=\frac{\sum_{j=1}^n x_j\exp(i 2\pi j/n)}{\sum_{j=1}^n x_j}$ . The question is to find the p.d.f. of $|y|$ , when $n$ is large enough. I tried to think about the central limit theorem. But it looks this is not a standard form of that. I also tried to derive the pdf by regarding $y$ as the sum of many random variables, which is also hard given the complicated formula. This question also has a clear geometric picture. But I am not sure how to find the statistics from it. I am basically stuck here.","Assume we have real variables ,  where . They are independent random variables uniformly distributed in . We define the variable . The question is to find the p.d.f. of , when is large enough. I tried to think about the central limit theorem. But it looks this is not a standard form of that. I also tried to derive the pdf by regarding as the sum of many random variables, which is also hard given the complicated formula. This question also has a clear geometric picture. But I am not sure how to find the statistics from it. I am basically stuck here.","n x_i {i=1,2,\cdots, n} [0,1] y=\frac{\sum_{j=1}^n x_j\exp(i 2\pi j/n)}{\sum_{j=1}^n x_j} |y| n y","['statistics', 'probability-distributions', 'random-variables']"
83,Convergence in law of maximum likelihood estimator and the method of moments estimator of the uniform distribution,Convergence in law of maximum likelihood estimator and the method of moments estimator of the uniform distribution,,"So I have these random variables $X_1,\ldots,X_n $ iid. and a uniform distribution: $f_X(x)=1/\theta*\textbf{1}_{0\leq x\leq\theta} $ . The maximum likelihood estimator is $\tilde{\theta}_n=max\{ X_1,\ldots,X_n\}$ and the method of moments estimator $\hat{\theta}_n=2/n\sum_{i=1}^nX_i$ . These are estimators for $\theta$ . Now I need to find the asymptomatic laws of these two: $$ \sqrt n (\tilde{\theta}_n-\theta)$$ and $$n(\hat{\theta}_n-\theta)$$ For the first one I want to use the central limit theorem somehow but the estimator is not a sum and I'm a bit lost. I also cannot see how I can use Slutsky, the delta method or the continuous application theorems. For the second I have: $$n(\hat{\theta}_n-\theta)=2(\sum X_i-\theta n/2)=2\sum (X_i-\theta/2)$$ and $(X_i-\theta/2)$ is a $Unif[-\theta/2,\theta/2]$ but the dostribution associated to this sum (that I find online) is a distribution that we haven't seen in class so I am not so sure. Any help is appreciated! Thanks Edit: additional question. Also how can I show that the second one ( $\hat{\theta}_n$ ) is not a sufficient statistic? It is quite obvious how to show that the first one IS.","So I have these random variables iid. and a uniform distribution: . The maximum likelihood estimator is and the method of moments estimator . These are estimators for . Now I need to find the asymptomatic laws of these two: and For the first one I want to use the central limit theorem somehow but the estimator is not a sum and I'm a bit lost. I also cannot see how I can use Slutsky, the delta method or the continuous application theorems. For the second I have: and is a but the dostribution associated to this sum (that I find online) is a distribution that we haven't seen in class so I am not so sure. Any help is appreciated! Thanks Edit: additional question. Also how can I show that the second one ( ) is not a sufficient statistic? It is quite obvious how to show that the first one IS.","X_1,\ldots,X_n  f_X(x)=1/\theta*\textbf{1}_{0\leq x\leq\theta}  \tilde{\theta}_n=max\{ X_1,\ldots,X_n\} \hat{\theta}_n=2/n\sum_{i=1}^nX_i \theta  \sqrt n (\tilde{\theta}_n-\theta) n(\hat{\theta}_n-\theta) n(\hat{\theta}_n-\theta)=2(\sum X_i-\theta n/2)=2\sum (X_i-\theta/2) (X_i-\theta/2) Unif[-\theta/2,\theta/2] \hat{\theta}_n","['probability', 'statistics', 'random-variables']"
84,How to calculate the statistical uncertainty in a particle physics simulation?,How to calculate the statistical uncertainty in a particle physics simulation?,,"I have a Monte Carlo code which simulates ions in a Tokamak . Most of the particles remain trapped forever. However, some of the particles escape. I can use my code to predict the fraction of particles that escape versus those that stay trapped. The code models collisions using a stochastic collision operator. Therefore, there is a statistical uncertainty with my results. Do you know any techniques to calculate this statistical uncertainty? One idea I had is to use the Bootstrapping technique . I'll quickly explain my plan now: Suppose we have $N$ trapped particles and $n<N$ that escape. We denote the particles that are trapped with $t_i$ (for $i\in\{1,2,...,N\}$ ) and the ones that escape with $e_i$ (for $i\in\{1,2,...,n\}$ ). Hence, the estimate for the fraction of markers that escape is $n/(n+N)$ . To calculate the uncertainty, we make a list which looks like the following: $$\{t_1,t_2,...,t_N,e_1,e_2,...,e_n\}.$$ We resample this list (with replacement) $m$ times (e.g. $m=100$ ) to produce lists which may look something like this: $$\underbrace{\{t_{36}, e_{12}, t_{444}, t_{321},...\}}_{n+N\ \mathrm{elements}}.$$ Then calculate the fraction of markers which escape for each of the $m$ cases and take away $n/(n+N)$ to produce a list of values with length $m$ . Finally, take, e.g. a 95% quantile of this to get a 95% confidence interval. Can you see any problems with this method? Is there a more straightforward method I could be using? I know barely any statistics, so any advice is appreciated.","I have a Monte Carlo code which simulates ions in a Tokamak . Most of the particles remain trapped forever. However, some of the particles escape. I can use my code to predict the fraction of particles that escape versus those that stay trapped. The code models collisions using a stochastic collision operator. Therefore, there is a statistical uncertainty with my results. Do you know any techniques to calculate this statistical uncertainty? One idea I had is to use the Bootstrapping technique . I'll quickly explain my plan now: Suppose we have trapped particles and that escape. We denote the particles that are trapped with (for ) and the ones that escape with (for ). Hence, the estimate for the fraction of markers that escape is . To calculate the uncertainty, we make a list which looks like the following: We resample this list (with replacement) times (e.g. ) to produce lists which may look something like this: Then calculate the fraction of markers which escape for each of the cases and take away to produce a list of values with length . Finally, take, e.g. a 95% quantile of this to get a 95% confidence interval. Can you see any problems with this method? Is there a more straightforward method I could be using? I know barely any statistics, so any advice is appreciated.","N n<N t_i i\in\{1,2,...,N\} e_i i\in\{1,2,...,n\} n/(n+N) \{t_1,t_2,...,t_N,e_1,e_2,...,e_n\}. m m=100 \underbrace{\{t_{36}, e_{12}, t_{444}, t_{321},...\}}_{n+N\ \mathrm{elements}}. m n/(n+N) m","['statistics', 'physics', 'mathematical-physics', 'computational-mathematics', 'monte-carlo']"
85,How to find a statistical function from this model?,How to find a statistical function from this model?,,"We note that the set of parameters $\quad \theta = (q_{k},\Sigma^{(k)} )_{k \in [K]} $ where $\Sigma^{(k)}$ is a SDP Matrix (symmetric definite matrix) We have also $\quad \mathbb{P}[z_{u}=k]=q_{k}\quad$ with $\quad q_{k}\geq0 \quad$ and $\sum_{k \in [K]} q_{k}=1 \quad and \quad z_{u}$ is random variable (type of $u\in [P]$ ) wich has values in [K] as $u \in [P],\quad q_{k}*P \quad$ is the number of u such that $z_{u}=k \quad$ and with $\quad \mathbb{P}_{\theta} (rep. \mathbb{E}_{\theta})\quad $ the conditional probability for the parameters given these information below : $(N_{uj}|(z_{u}=k,(\alpha_{kj})_{kj}) \quad \sim \quad Poisson(exp(\alpha_{kj}))$ $(N_{uj}|(z_{u}=k,(\alpha_{kj})_{kj}))_{j\in [J]} \quad $ are independant and K vectors (in dimension J) and $\quad (\alpha_{kj}:j\in [J])_k\in[K]\quad$ are independant and for all $k \in[K] \quad (\alpha_{kj})_{j \in [J]}\quad \sim \quad\mathcal{N}(0,\Sigma^{(k)})$ $\mathbb{P}[z_{u}=k]=q_{k}\quad$ $N_{uj} > 0 \quad \forall u \in [P] \quad and \quad \forall j \in [J]$ we are willing to find the following function $R_{\theta}((c_{j})_{j=1}^{J})=\frac{1}{P} \sum_{u_{0} \in[P]} \mathbb{P}_{\theta}(\sum_{j \in [J]} N_{u_{0}j}>0 | \sum_{u \in [P]}N_{uj}=c_{j}\quad \forall j \in [J])$ I tried to calculate it but the result does not depend on $\theta$ , can somoene tell me how can I calculate this with given informations","We note that the set of parameters where is a SDP Matrix (symmetric definite matrix) We have also with and is random variable (type of ) wich has values in [K] as is the number of u such that and with the conditional probability for the parameters given these information below : are independant and K vectors (in dimension J) and are independant and for all we are willing to find the following function I tried to calculate it but the result does not depend on , can somoene tell me how can I calculate this with given informations","\quad \theta = (q_{k},\Sigma^{(k)} )_{k \in [K]}  \Sigma^{(k)} \quad \mathbb{P}[z_{u}=k]=q_{k}\quad \quad q_{k}\geq0 \quad \sum_{k \in [K]} q_{k}=1 \quad and \quad z_{u} u\in [P] u \in [P],\quad q_{k}*P \quad z_{u}=k \quad \quad \mathbb{P}_{\theta} (rep. \mathbb{E}_{\theta})\quad  (N_{uj}|(z_{u}=k,(\alpha_{kj})_{kj}) \quad \sim \quad Poisson(exp(\alpha_{kj})) (N_{uj}|(z_{u}=k,(\alpha_{kj})_{kj}))_{j\in [J]} \quad  \quad (\alpha_{kj}:j\in [J])_k\in[K]\quad k \in[K] \quad (\alpha_{kj})_{j \in [J]}\quad \sim \quad\mathcal{N}(0,\Sigma^{(k)}) \mathbb{P}[z_{u}=k]=q_{k}\quad N_{uj} > 0 \quad \forall u \in [P] \quad and \quad \forall j \in [J] R_{\theta}((c_{j})_{j=1}^{J})=\frac{1}{P} \sum_{u_{0} \in[P]} \mathbb{P}_{\theta}(\sum_{j \in [J]} N_{u_{0}j}>0 | \sum_{u \in [P]}N_{uj}=c_{j}\quad \forall j \in [J]) \theta","['probability', 'statistics', 'probability-distributions', 'conditional-probability', 'education']"
86,Group lasso with weighted parameters and L0 norm penalty,Group lasso with weighted parameters and L0 norm penalty,,"I have explored the following hard problem for a long time. I need some help for the (possibly) final steps. Specifically, \begin{equation}\tag{1} \min_{\mathbf{x}\in\mathbf{R}^n}\left\{ f(\mathbf{x}):= \frac{1}{2}\|\mathbf{x}-\mathbf{v}\|_2^2 + \lambda\|\mathbf{Ux}\|_2+\lambda_0\|\mathbf{x}\|_0\right\}. \end{equation} where $\mathbf{v}\in\mathbf{R}^n$ is a fixed vector and $\mathbf{U}=\mathbf{diag}(\mathbf{u})$ with $u_i>0, \forall i=1,\ldots,n$ , and $\lambda, \lambda_0>0$ . Since we have no idea about how many nonzero elements the optimal $\mathbf{x}^*$ has, we define $\Omega^k=\{\mathbf{x}\mid \|\mathbf{x}\|_0=k, \mathbf{x}\in \mathbf{R}^n\}$ to represent the set of all $n$ -dimensional vectors with exact $k$ non-zero elements. We can show that $\mathbf{x}=\mathbf{0}$ if $\mathbf{U}^{-1}\mathbf{v}\le \lambda$ , which is a sufficient but not necessary condition due to the existence of $\ell_0$ penalty. Otherwise, we assume the optimal $\mathbf{x}^*\in\Omega^k$ , then the original problem can be reduced to \begin{equation}\tag{2} \min_{\mathbf{x}_k\in\Omega^k}\left\{ f(\mathbf{x}_k):= \frac{1}{2}\|\mathbf{x}_k-\mathbf{v}\|_2^2 + \lambda\|\mathbf{U}_k\mathbf{x}_k\|_2+\lambda_0k\right\} \end{equation} where the subscripts $k$ denote notations with $k$ nonzero entries.  The solution to (2) can be computed by the following fixed point operator (I've shown it has a unique fixed point. You may be very smart to propose a closed-form solution for this group lasso problem with weighted parameters within the group.) $$ \mathbf{x}_k=T(\mathbf{x}_k) = (\mathbf{I}+\frac{\lambda \mathbf{U}_k^2}{\|\mathbf{U}_k\mathbf{x}_k\|_2})^{-1}\mathbf{v}_k. $$ For convenience, let $\mathbf{A}_k=(\mathbf{I}+\frac{\lambda \mathbf{U}_k^2}{\|\mathbf{U}_k\mathbf{x}_k\|_2})^{-1}$ , then $\mathbf{A}_k$ is a positive definite dianonal matrix with diagonal entries $A_{ki}\in(0,1),\forall i=1,\ldots,n$ . Plugging this into (2) yields \begin{align}\tag{3} f(\mathbf{x}_k)=& \frac{1}{2}\|\mathbf{A}_k\mathbf{v}_k-\mathbf{v}\|_2^2 + \lambda\|\mathbf{U}_k\mathbf{A}_k\mathbf{v}_k\|_2+\lambda_0k\\ =&\frac{1}{2}\|\mathbf{A}_k\mathbf{v}_k\|_2^2-\mathbf{v}_k^T\mathbf{A}_k\mathbf{v}_k + \lambda\|\mathbf{U}_k\mathbf{A}_k\mathbf{v}_k\|_2 +\frac{1}{2}\|\mathbf{v}\|_2^2+\lambda_0k\\ =&-\mathbf{v}_k^T(\mathbf{A}_k-\frac{1}{2}\mathbf{A}^2_k)\mathbf{v}_k + \lambda\|\mathbf{U}_k\mathbf{A}_k\mathbf{v}_k\|_2 +\frac{1}{2}\|\mathbf{v}\|_2^2+\lambda_0k \end{align} where $\mathbf{A}_k-\frac{1}{2}\mathbf{A}^2_k\succ\mathbf{0}$ since $A_{ki}\in(0,1),\forall i=1,\ldots,n$ . The intuition for doing this is from this paper ''Neural Network Compression via $\ell_0$ Sparse Group Lasso on the Mobile System'', in which the solution to the following similar but simpler problem is proposed. \begin{equation}\tag{4} \min_{\mathbf{x}\in\mathbf{R}^n}\left\{ f(\mathbf{x}):= \frac{1}{2}\|\mathbf{x}-\mathbf{v}\|_2^2 + \lambda\|\mathbf{x}\|_2+\lambda_0\|\mathbf{x}\|_0\right\}. \end{equation} The only difference is that there are no weights for the group lasso term in (4). This problem looks very hard, because we need to try the $2^n$ possibilities to get the minimum objective value. But actually we only need to check $n+1$ possibilities, which is great. The solution is motivated by the following simple derivations. Since we have known the closed-form solution for group lasso, i.e. $\mathbf{x}=(\|\mathbf{v}\|_2-\lambda,0)_+\frac{\mathbf{v}}{\|\mathbf{v}\|_2}=(1-\frac{\lambda}{\|\mathbf{v}\|_2},0)_+\mathbf{v}$ . Suppose $\mathbf{x}^*\in\Omega^k$ , \begin{align} f(\mathbf{x}_k)=&\frac{1}{2}\|\mathbf{x}_k-\mathbf{v}\|_2^2 + \lambda\|\mathbf{x}_k\|_2+\lambda_0k\\ =&\frac{1}{2}\left\|(\|1-\frac{\lambda}{\|\mathbf{v}_k\|_2})\mathbf{v}_k-\mathbf{v}_k-\mathbf{v}_k^-\right\|_2^2 + \lambda\left\|(\|\mathbf{v}_k\|_2-\lambda)\frac{\mathbf{v}_k}{\|\mathbf{v}_k\|_2}\right\|_2+\lambda_0k\\ =&\frac{1}{2}\left\|-\frac{\lambda}{\|\mathbf{v}_k\|_2}\mathbf{v}_k-\mathbf{v}_k^-\right\|_2^2 + \lambda(\|\mathbf{v}_k\|_2-\lambda)+\lambda_0k\\ =&\frac{1}{2}\lambda^2+\frac{1}{2}\|\mathbf{v}_k^-\|_2^2 + \lambda\|\mathbf{v}_k\|_2-\lambda^2+\lambda_0k\\ =&-\frac{1}{2}\lambda^2 + \lambda\|\mathbf{v}_k\|_2-\frac{1}{2}\|\mathbf{v}_k\|_2^2+\frac{1}{2}\|\mathbf{v}_k\|_2^2+\frac{1}{2}\|\mathbf{v}_k^-\|_2^2+\lambda_0k\\ =&-\frac{1}{2}(\|\mathbf{v}_k\|_2-\lambda)^2+\frac{1}{2}\|\mathbf{v}\|_2^2+\lambda_0k \end{align} where $\mathbf{v}_k^-=\mathbf{v}-\mathbf{v}_k$ . The above implies that the greater $\|\mathbf{v}_k\|_2$ is, the smaller the objective value is, since the other terms are fixed. Thus, we only need to sort $\mathbf{v}$ by the absolute values of its elements in descending order and go through each (ordered) $\mathbf{v}_k$ . Finally, we compare the minimum of them with $\frac{1}{2}\|\mathbf{v}\|_2^2$ (corresponding to the solution of $\mathbf{0}$ ). For the weighted version, I got stuck at (3). I appreciate any instruction or comments.","I have explored the following hard problem for a long time. I need some help for the (possibly) final steps. Specifically, where is a fixed vector and with , and . Since we have no idea about how many nonzero elements the optimal has, we define to represent the set of all -dimensional vectors with exact non-zero elements. We can show that if , which is a sufficient but not necessary condition due to the existence of penalty. Otherwise, we assume the optimal , then the original problem can be reduced to where the subscripts denote notations with nonzero entries.  The solution to (2) can be computed by the following fixed point operator (I've shown it has a unique fixed point. You may be very smart to propose a closed-form solution for this group lasso problem with weighted parameters within the group.) For convenience, let , then is a positive definite dianonal matrix with diagonal entries . Plugging this into (2) yields where since . The intuition for doing this is from this paper ''Neural Network Compression via Sparse Group Lasso on the Mobile System'', in which the solution to the following similar but simpler problem is proposed. The only difference is that there are no weights for the group lasso term in (4). This problem looks very hard, because we need to try the possibilities to get the minimum objective value. But actually we only need to check possibilities, which is great. The solution is motivated by the following simple derivations. Since we have known the closed-form solution for group lasso, i.e. . Suppose , where . The above implies that the greater is, the smaller the objective value is, since the other terms are fixed. Thus, we only need to sort by the absolute values of its elements in descending order and go through each (ordered) . Finally, we compare the minimum of them with (corresponding to the solution of ). For the weighted version, I got stuck at (3). I appreciate any instruction or comments.","\begin{equation}\tag{1}
\min_{\mathbf{x}\in\mathbf{R}^n}\left\{ f(\mathbf{x}):= \frac{1}{2}\|\mathbf{x}-\mathbf{v}\|_2^2 + \lambda\|\mathbf{Ux}\|_2+\lambda_0\|\mathbf{x}\|_0\right\}.
\end{equation} \mathbf{v}\in\mathbf{R}^n \mathbf{U}=\mathbf{diag}(\mathbf{u}) u_i>0, \forall i=1,\ldots,n \lambda, \lambda_0>0 \mathbf{x}^* \Omega^k=\{\mathbf{x}\mid \|\mathbf{x}\|_0=k, \mathbf{x}\in \mathbf{R}^n\} n k \mathbf{x}=\mathbf{0} \mathbf{U}^{-1}\mathbf{v}\le \lambda \ell_0 \mathbf{x}^*\in\Omega^k \begin{equation}\tag{2}
\min_{\mathbf{x}_k\in\Omega^k}\left\{ f(\mathbf{x}_k):= \frac{1}{2}\|\mathbf{x}_k-\mathbf{v}\|_2^2 + \lambda\|\mathbf{U}_k\mathbf{x}_k\|_2+\lambda_0k\right\}
\end{equation} k k 
\mathbf{x}_k=T(\mathbf{x}_k) = (\mathbf{I}+\frac{\lambda \mathbf{U}_k^2}{\|\mathbf{U}_k\mathbf{x}_k\|_2})^{-1}\mathbf{v}_k.
 \mathbf{A}_k=(\mathbf{I}+\frac{\lambda \mathbf{U}_k^2}{\|\mathbf{U}_k\mathbf{x}_k\|_2})^{-1} \mathbf{A}_k A_{ki}\in(0,1),\forall i=1,\ldots,n \begin{align}\tag{3}
f(\mathbf{x}_k)=& \frac{1}{2}\|\mathbf{A}_k\mathbf{v}_k-\mathbf{v}\|_2^2 + \lambda\|\mathbf{U}_k\mathbf{A}_k\mathbf{v}_k\|_2+\lambda_0k\\
=&\frac{1}{2}\|\mathbf{A}_k\mathbf{v}_k\|_2^2-\mathbf{v}_k^T\mathbf{A}_k\mathbf{v}_k + \lambda\|\mathbf{U}_k\mathbf{A}_k\mathbf{v}_k\|_2 +\frac{1}{2}\|\mathbf{v}\|_2^2+\lambda_0k\\
=&-\mathbf{v}_k^T(\mathbf{A}_k-\frac{1}{2}\mathbf{A}^2_k)\mathbf{v}_k + \lambda\|\mathbf{U}_k\mathbf{A}_k\mathbf{v}_k\|_2 +\frac{1}{2}\|\mathbf{v}\|_2^2+\lambda_0k
\end{align} \mathbf{A}_k-\frac{1}{2}\mathbf{A}^2_k\succ\mathbf{0} A_{ki}\in(0,1),\forall i=1,\ldots,n \ell_0 \begin{equation}\tag{4}
\min_{\mathbf{x}\in\mathbf{R}^n}\left\{ f(\mathbf{x}):= \frac{1}{2}\|\mathbf{x}-\mathbf{v}\|_2^2 + \lambda\|\mathbf{x}\|_2+\lambda_0\|\mathbf{x}\|_0\right\}.
\end{equation} 2^n n+1 \mathbf{x}=(\|\mathbf{v}\|_2-\lambda,0)_+\frac{\mathbf{v}}{\|\mathbf{v}\|_2}=(1-\frac{\lambda}{\|\mathbf{v}\|_2},0)_+\mathbf{v} \mathbf{x}^*\in\Omega^k \begin{align}
f(\mathbf{x}_k)=&\frac{1}{2}\|\mathbf{x}_k-\mathbf{v}\|_2^2 + \lambda\|\mathbf{x}_k\|_2+\lambda_0k\\
=&\frac{1}{2}\left\|(\|1-\frac{\lambda}{\|\mathbf{v}_k\|_2})\mathbf{v}_k-\mathbf{v}_k-\mathbf{v}_k^-\right\|_2^2 + \lambda\left\|(\|\mathbf{v}_k\|_2-\lambda)\frac{\mathbf{v}_k}{\|\mathbf{v}_k\|_2}\right\|_2+\lambda_0k\\
=&\frac{1}{2}\left\|-\frac{\lambda}{\|\mathbf{v}_k\|_2}\mathbf{v}_k-\mathbf{v}_k^-\right\|_2^2 + \lambda(\|\mathbf{v}_k\|_2-\lambda)+\lambda_0k\\
=&\frac{1}{2}\lambda^2+\frac{1}{2}\|\mathbf{v}_k^-\|_2^2 + \lambda\|\mathbf{v}_k\|_2-\lambda^2+\lambda_0k\\
=&-\frac{1}{2}\lambda^2 + \lambda\|\mathbf{v}_k\|_2-\frac{1}{2}\|\mathbf{v}_k\|_2^2+\frac{1}{2}\|\mathbf{v}_k\|_2^2+\frac{1}{2}\|\mathbf{v}_k^-\|_2^2+\lambda_0k\\
=&-\frac{1}{2}(\|\mathbf{v}_k\|_2-\lambda)^2+\frac{1}{2}\|\mathbf{v}\|_2^2+\lambda_0k
\end{align} \mathbf{v}_k^-=\mathbf{v}-\mathbf{v}_k \|\mathbf{v}_k\|_2 \mathbf{v} \mathbf{v}_k \frac{1}{2}\|\mathbf{v}\|_2^2 \mathbf{0}","['analysis', 'statistics', 'optimization', 'sparsity']"
87,Flipping $n$ sticky coins until they are all heads,Flipping  sticky coins until they are all heads,n,"Consider a collection of $n$ coins, of which $k$ initially are heads. These coins are ""sticky"" and, when flipped, remain the same with probability $p > 1/2$ , and flip over with probability $1-p < 1/2$ . Time proceeds in synchronous rounds, and in each round, we flip each coin. As a function of $k$ , $p$ , and $n$ , what is the expected number of rounds before all coins land heads? In particular, I am interested in a lower bound on the expected number of rounds before all coins land heads (especially for $k=n-1$ ). For a constant $p$ , the expected number of rounds before all coins land heads is lower-bounded by an exponential function, but for $p \approx 1 - \frac{1}{poly(n)}$ , the answer is less clear. It's also possible to frame this question as a Markov chain (which can also be thought of as a Kronecker product of $n$ smaller two-state Markov chains). In this formulation, it is easy to write a formula for the expected number of rounds before all coins land heads, but I'm interested in a clean asymptotic expression in $k$ , $n$ , and $p$ . Edit: In the Markov chain formulation, the transition matrix is a $2^n$ by $2^n$ matrix $P$ where the $(i,j)^{th}$ entry is the probability of transitioning from state $i$ to $j$ . We can assume that the all-heads state is an absorbing state and therefore write $P$ as \begin{pmatrix} Q&R \\ \mathbf{0} &1\end{pmatrix} where $Q$ is a $2^n - 1$ by $2^n - 1$ matrix, $R$ is a $2^n - 1$ by $1$ matrix, and $\mathbf{0}$ is a $1$ by $2^n - 1$ matrix of all zeroes. Now, letting $N = (I - Q)^{-1}$ (or equivalently $N = \sum_{k=1}^\infty Q^k$ ) be the fundamental matrix, we can see that the expected number of steps until absorption from a state $i$ is the $i^{th}$ entry of $N \mathbf{1}$ . (Wikipedia article here .) However, this expression still seems nontrivial to analyze with respect to asymptotic bounds.","Consider a collection of coins, of which initially are heads. These coins are ""sticky"" and, when flipped, remain the same with probability , and flip over with probability . Time proceeds in synchronous rounds, and in each round, we flip each coin. As a function of , , and , what is the expected number of rounds before all coins land heads? In particular, I am interested in a lower bound on the expected number of rounds before all coins land heads (especially for ). For a constant , the expected number of rounds before all coins land heads is lower-bounded by an exponential function, but for , the answer is less clear. It's also possible to frame this question as a Markov chain (which can also be thought of as a Kronecker product of smaller two-state Markov chains). In this formulation, it is easy to write a formula for the expected number of rounds before all coins land heads, but I'm interested in a clean asymptotic expression in , , and . Edit: In the Markov chain formulation, the transition matrix is a by matrix where the entry is the probability of transitioning from state to . We can assume that the all-heads state is an absorbing state and therefore write as where is a by matrix, is a by matrix, and is a by matrix of all zeroes. Now, letting (or equivalently ) be the fundamental matrix, we can see that the expected number of steps until absorption from a state is the entry of . (Wikipedia article here .) However, this expression still seems nontrivial to analyze with respect to asymptotic bounds.","n k p > 1/2 1-p < 1/2 k p n k=n-1 p p \approx 1 - \frac{1}{poly(n)} n k n p 2^n 2^n P (i,j)^{th} i j P \begin{pmatrix} Q&R \\ \mathbf{0} &1\end{pmatrix} Q 2^n - 1 2^n - 1 R 2^n - 1 1 \mathbf{0} 1 2^n - 1 N = (I - Q)^{-1} N = \sum_{k=1}^\infty Q^k i i^{th} N \mathbf{1}","['probability', 'probability-theory', 'statistics', 'asymptotics', 'markov-chains']"
88,"If set $C$ has 60 elements, and set $B_i$ has 9 elements randomly sampled from $C$, what is the mean value of $i$ to seeing all elements of $C$?","If set  has 60 elements, and set  has 9 elements randomly sampled from , what is the mean value of  to seeing all elements of ?",C B_i C i C,"This question is inspired by the Yu-Gi-Oh TCG. Every so often, the game receives a new set containing either 60 or 100 new cards (this is the set $C$ in the question title). However, they don't just sell you the 60 or 100 cards upfront. No, instead you must buy booster packs , each of which contains 9 cards randomly sampled from the 60 or 100 cards of the entire set (this is the set $B_i$ in the question title). With the question's inspiration out of the way, my question is this: On average, how many booster packs are required to collect the entire 60 or 100-card set? A related question would be: What is the probability of having the entire set after opening $x$ booster packs?","This question is inspired by the Yu-Gi-Oh TCG. Every so often, the game receives a new set containing either 60 or 100 new cards (this is the set in the question title). However, they don't just sell you the 60 or 100 cards upfront. No, instead you must buy booster packs , each of which contains 9 cards randomly sampled from the 60 or 100 cards of the entire set (this is the set in the question title). With the question's inspiration out of the way, my question is this: On average, how many booster packs are required to collect the entire 60 or 100-card set? A related question would be: What is the probability of having the entire set after opening booster packs?",C B_i x,"['probability', 'statistics']"
89,Proving a result in maximum likelihood inference,Proving a result in maximum likelihood inference,,"I need help proving a result shown in a paper. I am reading Assessing the Quadratic Approximation to the Log Likelihood Function in Nonnormal Linear Models by Salomon Minkin. The paper defines several concepts that are used in the argument, so I'll state those here: Definitions Let $\beta \in \mathbb{R}^m$ . Let $L(\beta;x)$ be a a log-likelihood function and $\hat{\beta}$ be the maximum likelihood estimator (MLE) of the parameter $\beta$ given data $x$ ( $x$ is a vector of observations) Let $Q(\beta;\hat{\beta},x)$ be the quadratic approximation to $L(\beta;x)$ around the $\hat{\beta}$ (i.e., the second degree Taylor approximation about $\hat{\beta}$ ). The argument uses the ""drop"" in the loglikelihood functions as you move away from their common maximizer at $\hat{\beta}$ Let $D_L(\beta):=D_L(\beta;\hat{\beta},x)=L(\hat{\beta};x) - L(\beta;x)$ be the drop in the $L$ at point $\beta$ . Similarly, $D_Q(\beta):=D_Q(\beta;\hat{\beta},x)=Q(\hat{\beta};\hat{\beta},x) - Q(\beta;\hat{\beta},x)$ be the drop in the quadratic approximation to $L$ at $\beta$ . Proof Plan The author then uses $D_L,D_Q$ in the main part of the argument, reproduced below: To me it's not clear/obvious that $\beta\in R_L(a_0-d) \implies \beta \in R_Q(a_0) \;\;\forall a_0 \leq a$ so I tried to prove this to myself. Let's start with $a_0=a$ . Here are the series of implications I am trying to prove (there may be a more straightforward approach). The first implication (marked with $(*)$ ) is the one I'm not sure about, but if I can prove it the rest of the proof here is pretty straightforward. I basically assumed it was true and continued on the proof, now coming back to shore up $(*)$ . $(*): \beta \in R_L(a-d) \implies \beta \in R_A(d)$ $(1): (*) \implies D_Q(\beta) < D_L + d$ $(2): \beta \in R_L(a-d)  \implies D_L(\beta) \leq a - d $ $(3): (2) \wedge (1) \implies D_Q(\beta) < D_L + d \leq (a-d) + d \implies D_Q(\beta) < a$ $(4): (3) \implies \beta \in R_Q(a) \implies R_L(a-d) \subset R_Q(a)$ So, assuming $(*)$ we've shown $\beta \in R_L(a-d) \implies \beta \in R_Q(a)$ . The generalization to $a_0\leq a$ is also straightforward due the definition of $R_Q$ . For any decreasing sequence of values $s_1>s_2>s_3...>s_n$ defines a decreasing sequence of sets in $\mathbb{R}^{m}$ (ellipsoids) $R_Q(s_1)\supset R_Q(s_2)\supset R_Q(s_3)...\supset R_Q(s_n)$ Substituting $a_0 < a$ for $a$ into $(*)$ and proceeding with $(1)-(4)$ gets us the general result stated in the paper: $$\beta \in R_L(a_0-d) \implies D_Q(\beta) < a_0 \implies \beta \in R_Q(a_0) \implies R_L(a_0-d) \subset R_Q(a_0) \;\;\forall a_0 \leq a$$ $\square$ Proving $(*)$ The jumping off point of my proof is $(*)$ , which I am not sure I can rigorously prove. I feel it needs to use the fact that $R_Q(a) \subset R_A(d)$ and that the regions $R_L(z)$ are connected (as mentioned in the above passage). My attempt $R_Q(a) \subset R_A(d) \implies |D_Q(\beta)-D_L(\beta)| < d\;\; \forall \beta \in R_Q(a)$ by the definition of $R_A(d)$ To show $R_L(a-d) \in R_A(d)$ , there are two cases: Case 1: $R_L(a) \setminus R_Q(a) = \emptyset$ $R_L(a) \setminus R_Q(a) = \emptyset \implies R_L(a) \subset R_Q(a) \implies R_L(a) \subset R_A(d)$ . By the definition of $R_L(z)$ , $R_L(a-d) \subset R_L(a) \implies R_L(a-d) \subset R_A(d)$ . Case 2: $R_L(a) \setminus R_Q(a) \neq \emptyset$ Let $G = R_L(a) \setminus R_Q(a)$ In this case, we know that $D_L(g) < D_Q(g)\;\;\forall g \in G$ : Proof : Assume $g \in G: D_L(g)-D_Q(g) = k > 0$ . This means that $D_L(g) = a+k$ which contradicts the fact that $g \in R_L(a)\;\;\;\square$ Since $D_L(g)< D_Q(g)$ over $G$ , and also that $R_Q(a) \in R_A(d)$ , then $\exists c<d:R_L(a-c) \subset R_Q(a)$ . By definition, $R_L(a-d) \subset R_L(a-c) \subset R_Q(a) \subset R_A(d)\;\; \square$ Turns out this appears to simultaneously prove the overall point I was trying to understand. Is this correct? Am I missing something?","I need help proving a result shown in a paper. I am reading Assessing the Quadratic Approximation to the Log Likelihood Function in Nonnormal Linear Models by Salomon Minkin. The paper defines several concepts that are used in the argument, so I'll state those here: Definitions Let . Let be a a log-likelihood function and be the maximum likelihood estimator (MLE) of the parameter given data ( is a vector of observations) Let be the quadratic approximation to around the (i.e., the second degree Taylor approximation about ). The argument uses the ""drop"" in the loglikelihood functions as you move away from their common maximizer at Let be the drop in the at point . Similarly, be the drop in the quadratic approximation to at . Proof Plan The author then uses in the main part of the argument, reproduced below: To me it's not clear/obvious that so I tried to prove this to myself. Let's start with . Here are the series of implications I am trying to prove (there may be a more straightforward approach). The first implication (marked with ) is the one I'm not sure about, but if I can prove it the rest of the proof here is pretty straightforward. I basically assumed it was true and continued on the proof, now coming back to shore up . So, assuming we've shown . The generalization to is also straightforward due the definition of . For any decreasing sequence of values defines a decreasing sequence of sets in (ellipsoids) Substituting for into and proceeding with gets us the general result stated in the paper: Proving The jumping off point of my proof is , which I am not sure I can rigorously prove. I feel it needs to use the fact that and that the regions are connected (as mentioned in the above passage). My attempt by the definition of To show , there are two cases: Case 1: . By the definition of , . Case 2: Let In this case, we know that : Proof : Assume . This means that which contradicts the fact that Since over , and also that , then . By definition, Turns out this appears to simultaneously prove the overall point I was trying to understand. Is this correct? Am I missing something?","\beta \in \mathbb{R}^m L(\beta;x) \hat{\beta} \beta x x Q(\beta;\hat{\beta},x) L(\beta;x) \hat{\beta} \hat{\beta} \hat{\beta} D_L(\beta):=D_L(\beta;\hat{\beta},x)=L(\hat{\beta};x) - L(\beta;x) L \beta D_Q(\beta):=D_Q(\beta;\hat{\beta},x)=Q(\hat{\beta};\hat{\beta},x) - Q(\beta;\hat{\beta},x) L \beta D_L,D_Q \beta\in R_L(a_0-d) \implies \beta \in R_Q(a_0) \;\;\forall a_0 \leq a a_0=a (*) (*) (*): \beta \in R_L(a-d) \implies \beta \in R_A(d) (1): (*) \implies D_Q(\beta) < D_L + d (2): \beta \in R_L(a-d)  \implies D_L(\beta) \leq a - d  (3): (2) \wedge (1) \implies D_Q(\beta) < D_L + d \leq (a-d) + d \implies D_Q(\beta) < a (4): (3) \implies \beta \in R_Q(a) \implies R_L(a-d) \subset R_Q(a) (*) \beta \in R_L(a-d) \implies \beta \in R_Q(a) a_0\leq a R_Q s_1>s_2>s_3...>s_n \mathbb{R}^{m} R_Q(s_1)\supset R_Q(s_2)\supset R_Q(s_3)...\supset R_Q(s_n) a_0 < a a (*) (1)-(4) \beta \in R_L(a_0-d) \implies D_Q(\beta) < a_0 \implies \beta \in R_Q(a_0) \implies R_L(a_0-d) \subset R_Q(a_0) \;\;\forall a_0 \leq a \square (*) (*) R_Q(a) \subset R_A(d) R_L(z) R_Q(a) \subset R_A(d) \implies |D_Q(\beta)-D_L(\beta)| < d\;\; \forall \beta \in R_Q(a) R_A(d) R_L(a-d) \in R_A(d) R_L(a) \setminus R_Q(a) = \emptyset R_L(a) \setminus R_Q(a) = \emptyset \implies R_L(a) \subset R_Q(a) \implies R_L(a) \subset R_A(d) R_L(z) R_L(a-d) \subset R_L(a) \implies R_L(a-d) \subset R_A(d) R_L(a) \setminus R_Q(a) \neq \emptyset G = R_L(a) \setminus R_Q(a) D_L(g) < D_Q(g)\;\;\forall g \in G g \in G: D_L(g)-D_Q(g) = k > 0 D_L(g) = a+k g \in R_L(a)\;\;\;\square D_L(g)< D_Q(g) G R_Q(a) \in R_A(d) \exists c<d:R_L(a-c) \subset R_Q(a) R_L(a-d) \subset R_L(a-c) \subset R_Q(a) \subset R_A(d)\;\; \square","['real-analysis', 'general-topology', 'probability-theory', 'statistics', 'solution-verification']"
90,"find the complete statistic for Uniform($\theta,\theta+1$)",find the complete statistic for Uniform(),"\theta,\theta+1","Assume $x_1x_2,\dots,x_n$ are i.i.d Uniform( $\theta,\theta+1$ ), want to know if $x_{(n)}$ , the order statistic, is a complete statistic. This appears in a course slides, but I don't know if the result is right, since for $n=1$ the result is wrong. (by using the definition of complete statistic and the function $f(t)=sin(2\pi t)$ ). any hint would be appreciated!","Assume are i.i.d Uniform( ), want to know if , the order statistic, is a complete statistic. This appears in a course slides, but I don't know if the result is right, since for the result is wrong. (by using the definition of complete statistic and the function ). any hint would be appreciated!","x_1x_2,\dots,x_n \theta,\theta+1 x_{(n)} n=1 f(t)=sin(2\pi t)","['statistics', 'statistical-inference']"
91,Derive CDF of EPV of deferred whole life insurance,Derive CDF of EPV of deferred whole life insurance,,"I'm studying actuarial mathmatics. Can you help me solving this question? The PV random variable of $u$ -year deferred whole life insurance benefit is $Z = \begin{cases}  0, & \mbox{$T_x$ < $u$} \\  v^{T_x}, & \mbox{$T_x$ $\ge$ $u$} \end{cases}$ Note that discount factor $v=e^{-\delta}$ . and $Z$ is decreasing function of $T_x$ when $T_x >u$ . Assuming constant force of mortality $\mu$ and force of interest $\delta$ , How can I derive the Cumulative distribution function(CDF) of $Z$ and calculate median of $Z$ ? This is my idea: let $T_x = t$ . $f_x(t) = \mu e^{-\mu t},\, F_x(t) = {_t}q_x = 1-e^{-\mu t},\, S_x(t) = {_t}p_x = e^{-\mu t}$ . $P(Z=0) = P(T_x \leq u) = 1-e^{-\mu u}$ $P(Z=v^t) = {_u|_t}q_x = {_u}p_x{_t}q_{x+u} = e^{-\mu t}(1-e^{-\mu t}) = e^{-\mu t} - e^{-\mu (u+t)}$ but I cannot express it for function of $Z$ . I got probabilities for $Z$ , but they are also function of $t (T_x)$ . CDF should be $f: Z \rightarrow [0,1]$ , but there is another variable $t$ . Could you help me how can I get appropriate function for $Z$ , please? Thank you for your help.","I'm studying actuarial mathmatics. Can you help me solving this question? The PV random variable of -year deferred whole life insurance benefit is Note that discount factor . and is decreasing function of when . Assuming constant force of mortality and force of interest , How can I derive the Cumulative distribution function(CDF) of and calculate median of ? This is my idea: let . . but I cannot express it for function of . I got probabilities for , but they are also function of . CDF should be , but there is another variable . Could you help me how can I get appropriate function for , please? Thank you for your help.","u Z = \begin{cases} 
0, & \mbox{T_x < u} \\ 
v^{T_x}, & \mbox{T_x \ge u}
\end{cases} v=e^{-\delta} Z T_x T_x >u \mu \delta Z Z T_x = t f_x(t) = \mu e^{-\mu t},\, F_x(t) = {_t}q_x = 1-e^{-\mu t},\, S_x(t) = {_t}p_x = e^{-\mu t} P(Z=0) = P(T_x \leq u) = 1-e^{-\mu u} P(Z=v^t) = {_u|_t}q_x = {_u}p_x{_t}q_{x+u} = e^{-\mu t}(1-e^{-\mu t}) = e^{-\mu t} - e^{-\mu (u+t)} Z Z t (T_x) f: Z \rightarrow [0,1] t Z","['statistics', 'actuarial-science']"
92,Construction of Wiener measure(or Brownian motion),Construction of Wiener measure(or Brownian motion),,"In this definition of Wiener's measure , we define the measure of a standard Brownian motion by extending the f.d.d. distribution on set of all continuous functions. However, we also know that the set of all continuous functions is not measurable in the measurable space of all functions, with $\sigma$ -field generated by all pointwise projection maps $\pi_t(\omega)=\omega(t)$ . This fact, in some textbooks(like Durrett's PTE), asks us to constraint functions on rational points and then show that the sample paths are uniformly continuous with probability 1. So my question is that whether my following understanding is correct: if we start with all functions $\{\omega:[0,\infty)\mapsto\mathbb{R}\}$ then the measurability of $C(\mathbb{R})$ is indeed a problem, which requires a detour via rational approximations; but if we start with $C(\mathbb{R})$ then everything is fine. But in this case what is the $\sigma$ -field? so the reason for starting from all functions to construct the Brownian motion is that we want more generality, that we don't want to assume in advance that the sample paths are continuous almost surely?","In this definition of Wiener's measure , we define the measure of a standard Brownian motion by extending the f.d.d. distribution on set of all continuous functions. However, we also know that the set of all continuous functions is not measurable in the measurable space of all functions, with -field generated by all pointwise projection maps . This fact, in some textbooks(like Durrett's PTE), asks us to constraint functions on rational points and then show that the sample paths are uniformly continuous with probability 1. So my question is that whether my following understanding is correct: if we start with all functions then the measurability of is indeed a problem, which requires a detour via rational approximations; but if we start with then everything is fine. But in this case what is the -field? so the reason for starting from all functions to construct the Brownian motion is that we want more generality, that we don't want to assume in advance that the sample paths are continuous almost surely?","\sigma \pi_t(\omega)=\omega(t) \{\omega:[0,\infty)\mapsto\mathbb{R}\} C(\mathbb{R}) C(\mathbb{R}) \sigma","['probability', 'brownian-motion', 'wiener-measure']"
93,Can we calculate the opponent's hidden values in this statistical battle?,Can we calculate the opponent's hidden values in this statistical battle?,,"First-order statistical battle Imagine there is a game in which the user should guess what values the opponent is hiding from the user. In the first battle, the opponent has two hidden values a and b where a is the mean and b is the standard deviation (in a normal distribution). The rules of the game are: User knows how the generation system works on the opponent's side. User does not know what the a and b values are. User can ask the opponent to generate a new value using the values a and b and show it to the user. The user can ask for a new number infinitely. ✅ Solution In the first battle, the user wins. Because after generating so many numbers, the user eventually finds a and b or at least gets very close to them. Second-order statistical battle Imagine a new game where the opponent hides four static values a , b , c , and d . The same rules of the previous game apply to this game, but instead of only a and b , they apply to c and d as well. In this battle, every time the user asks for a new number, the opponent first generates a new tuple (X=mean, Y=stdDev) where X is generated using a and b ( a is mean and b is stddev) and Y is generated using c and d ( c is mean and d is the stddev). The opponent then generates a new number using (X, Y) and sends it to the user. Can the user find out what those four values are eventually? ❓ Possible solution? A potential solution that one might propose is to generate K numbers (where K is large enough) and then calculate the mean and stddev of these K numbers, let it be (X1, Y1). Then repeat this step and generate another K number and calculate a new tuple (X2, Y2). We repeat this until we have so many tuples of Xn and Yn. Then we can calculate a and b using all the Xn, and c and d using all the Yn. Questions of post Does the proposed solution work? Can the user find a , b , c , and d using this method? If that method doesn't work, can the user figure out what those four values are using any other approach?","First-order statistical battle Imagine there is a game in which the user should guess what values the opponent is hiding from the user. In the first battle, the opponent has two hidden values a and b where a is the mean and b is the standard deviation (in a normal distribution). The rules of the game are: User knows how the generation system works on the opponent's side. User does not know what the a and b values are. User can ask the opponent to generate a new value using the values a and b and show it to the user. The user can ask for a new number infinitely. ✅ Solution In the first battle, the user wins. Because after generating so many numbers, the user eventually finds a and b or at least gets very close to them. Second-order statistical battle Imagine a new game where the opponent hides four static values a , b , c , and d . The same rules of the previous game apply to this game, but instead of only a and b , they apply to c and d as well. In this battle, every time the user asks for a new number, the opponent first generates a new tuple (X=mean, Y=stdDev) where X is generated using a and b ( a is mean and b is stddev) and Y is generated using c and d ( c is mean and d is the stddev). The opponent then generates a new number using (X, Y) and sends it to the user. Can the user find out what those four values are eventually? ❓ Possible solution? A potential solution that one might propose is to generate K numbers (where K is large enough) and then calculate the mean and stddev of these K numbers, let it be (X1, Y1). Then repeat this step and generate another K number and calculate a new tuple (X2, Y2). We repeat this until we have so many tuples of Xn and Yn. Then we can calculate a and b using all the Xn, and c and d using all the Yn. Questions of post Does the proposed solution work? Can the user find a , b , c , and d using this method? If that method doesn't work, can the user figure out what those four values are using any other approach?",,['statistics']
94,Tail bounds for sub-Gaussian and sub-exponential distributions,Tail bounds for sub-Gaussian and sub-exponential distributions,,"Massart and Laurent (see [ 1 ], Lemma 1 on page 1325] give tail bounds for $\chi^2$ random variables. A corollary of their bound is the following: $$P\left[\frac{1}{k} X \leq 1- 2\sqrt{\frac{x}{k}} \right]\leq \exp (-x) $$ $$P\left[\frac{1}{k} X \geq 1+2\sqrt{\frac{x}{k}}+2 \frac{x}{k} \right]\leq \exp (-x) $$ I am looking for similar statements for sub-Gaussian and sub-exponential random variables, but could only find the following statement for independent $\sigma^2$ -sub-Gaussian RV: $$P\left[ \frac{1}{k} \sum_{i=1}^{n} X_i \geq t \right]\leq \exp \left(-\frac{n t^2}{\frac{2}{n}\sum_{i=1}^{n} \sigma_i^2}\right) $$ which is similar to the second concentration inequality (""upper tail"") by Massart and Laurent. I couldn't find any equivalent for the first one (""lower tail""). Furthermore, I couldn't find any inequalities for sub-exponential RV without any additional prerequisites (e.g., maximum known). Is there any similar statements to the first (""upper"") bound by Massart and Laurent for sub-Gaussian distributions and similar statements for both bounds for sub-exponential distributions? Thank you for your help!","Massart and Laurent (see [ 1 ], Lemma 1 on page 1325] give tail bounds for random variables. A corollary of their bound is the following: I am looking for similar statements for sub-Gaussian and sub-exponential random variables, but could only find the following statement for independent -sub-Gaussian RV: which is similar to the second concentration inequality (""upper tail"") by Massart and Laurent. I couldn't find any equivalent for the first one (""lower tail""). Furthermore, I couldn't find any inequalities for sub-exponential RV without any additional prerequisites (e.g., maximum known). Is there any similar statements to the first (""upper"") bound by Massart and Laurent for sub-Gaussian distributions and similar statements for both bounds for sub-exponential distributions? Thank you for your help!",\chi^2 P\left[\frac{1}{k} X \leq 1- 2\sqrt{\frac{x}{k}} \right]\leq \exp (-x)  P\left[\frac{1}{k} X \geq 1+2\sqrt{\frac{x}{k}}+2 \frac{x}{k} \right]\leq \exp (-x)  \sigma^2 P\left[ \frac{1}{k} \sum_{i=1}^{n} X_i \geq t \right]\leq \exp \left(-\frac{n t^2}{\frac{2}{n}\sum_{i=1}^{n} \sigma_i^2}\right) ,"['probability', 'probability-theory', 'statistics', 'probability-limit-theorems', 'concentration-of-measure']"
95,"What is the smallest unseen number in an iid sample? (From ""A number NOBODY has thought of - Numberphile"")","What is the smallest unseen number in an iid sample? (From ""A number NOBODY has thought of - Numberphile"")",,"In this Numberphile video , the question: ""What is a number nobody has thought of?"" is addressed. The method is as follows: Estimate a number $N$ as the number of times humans have thought of numbers Estimate a probability distribution $\mathbb{P}$ for what number you think of when you have a thought and suppose that each though is an independent draw from this Calculate the distribution of the maximum of $N$ independent draws from $\mathbb{P}$ More precisely, this is the answering the question: ""What is the largest number someone has thought of?"" (and if you add 1 you will surely get a number nobody has thought of). A more interesting question in my view is ""What is the smallest number nobody has thought of?"". If we agree with step 1 and step 2 from the Numberphile video, then this ammounts to: What is the distribution of the smallest integer $I$ so that $N$ iid draws from a distribution $\mathbb{P}$ on the integers does not contain $I$ . (In other words: the event that $\{I > x\}$ is the event that the numbers $\{1,\ldots,x\}$ all appear in our sample). Surely someone has thought of this before....is there an elegant way to calculate this?","In this Numberphile video , the question: ""What is a number nobody has thought of?"" is addressed. The method is as follows: Estimate a number as the number of times humans have thought of numbers Estimate a probability distribution for what number you think of when you have a thought and suppose that each though is an independent draw from this Calculate the distribution of the maximum of independent draws from More precisely, this is the answering the question: ""What is the largest number someone has thought of?"" (and if you add 1 you will surely get a number nobody has thought of). A more interesting question in my view is ""What is the smallest number nobody has thought of?"". If we agree with step 1 and step 2 from the Numberphile video, then this ammounts to: What is the distribution of the smallest integer so that iid draws from a distribution on the integers does not contain . (In other words: the event that is the event that the numbers all appear in our sample). Surely someone has thought of this before....is there an elegant way to calculate this?","N \mathbb{P} N \mathbb{P} I N \mathbb{P} I \{I > x\} \{1,\ldots,x\}","['probability', 'probability-theory', 'statistics', 'random-variables', 'recreational-mathematics']"
96,When are levy flights superdiffusive and why? [closed],When are levy flights superdiffusive and why? [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question A stable distribution that is centered and symmetrical has a value $\alpha \leq 1$ the expected value of the distribution is undefined. I have also been told that if a Levy Flight has it's step lengths drawn from the absolute of the stable distribution it will become superdiffusive when $\alpha = 1$ but not when $2 \geq \alpha > 1$ . Is it true that levy flights would only be superdiffusive when $\alpha \leq 1$ and why is that?","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question A stable distribution that is centered and symmetrical has a value the expected value of the distribution is undefined. I have also been told that if a Levy Flight has it's step lengths drawn from the absolute of the stable distribution it will become superdiffusive when but not when . Is it true that levy flights would only be superdiffusive when and why is that?",\alpha \leq 1 \alpha = 1 2 \geq \alpha > 1 \alpha \leq 1,"['statistics', 'probability-distributions', 'random-walk', 'levy-processes']"
97,Expected Value of Slot Machine,Expected Value of Slot Machine,,"I have a probability question that has to do with slot machines. Here is how the game works: There are two reels, one on the left and one on the right.  There are several symbols on each reel, one of which is an 8. The 8 symbol lands on the left reel 1 in 9 plays of the game (or spins). The 8 symbol lands on the right reel 1 in 10 plays. The reels spin independently of each other, and each play is independent from previous plays. Each play of the game spins both reels. Each reel has a large 8 above it, split into 8 segments. As the 8 symbol lands on the corresponding reel below it, one additional segment of the large 8 lights up. Once both large 8s are fully lit (i.e. at least 8-8s have landed on each reel) a 50 credit bonus is paid and the game ends. If one reel’s large 8 is already fully lit, the game isn’t over yet (i.e. do NOT pay the 10 credit bonus on a spin that completes the game), and a new 8 lands on its corresponding reel, a 10 credit bonus is paid. Each play of the game costs 1 credit. I need to compute the expected number of credits won or lost while playing this game. Well I have an idea on how to approach this. On the first reel, an eight appears 1 every 9 spins. On the second reel, it appears 1 every 10 spins. Therefore, the odds favoring an 8 is 1 in 9 and 1 in 10. What I think the expected value of this scenario is this: If $n$ is the number of reels, then $$EV = -1(\frac{n-1}{n})(\frac{n-1}{n}) + 9(\frac{1}{10})(\frac{n-1}{n}) + 9(\frac{1}{11})(\frac{n-1}{n}) + 49 (\frac{1}{10})(\frac{1}{11}). $$ Do you think I am approaching in the right direction? Thank you for your help!","I have a probability question that has to do with slot machines. Here is how the game works: There are two reels, one on the left and one on the right.  There are several symbols on each reel, one of which is an 8. The 8 symbol lands on the left reel 1 in 9 plays of the game (or spins). The 8 symbol lands on the right reel 1 in 10 plays. The reels spin independently of each other, and each play is independent from previous plays. Each play of the game spins both reels. Each reel has a large 8 above it, split into 8 segments. As the 8 symbol lands on the corresponding reel below it, one additional segment of the large 8 lights up. Once both large 8s are fully lit (i.e. at least 8-8s have landed on each reel) a 50 credit bonus is paid and the game ends. If one reel’s large 8 is already fully lit, the game isn’t over yet (i.e. do NOT pay the 10 credit bonus on a spin that completes the game), and a new 8 lands on its corresponding reel, a 10 credit bonus is paid. Each play of the game costs 1 credit. I need to compute the expected number of credits won or lost while playing this game. Well I have an idea on how to approach this. On the first reel, an eight appears 1 every 9 spins. On the second reel, it appears 1 every 10 spins. Therefore, the odds favoring an 8 is 1 in 9 and 1 in 10. What I think the expected value of this scenario is this: If is the number of reels, then Do you think I am approaching in the right direction? Thank you for your help!",n EV = -1(\frac{n-1}{n})(\frac{n-1}{n}) + 9(\frac{1}{10})(\frac{n-1}{n}) + 9(\frac{1}{11})(\frac{n-1}{n}) + 49 (\frac{1}{10})(\frac{1}{11}). ,"['statistics', 'expected-value', 'monte-carlo']"
98,Shifting functions to minimise the maximum variance accross a domain.,Shifting functions to minimise the maximum variance accross a domain.,,Assume we have a family of $N$ continuous functions $f_i(x)\in C_\infty$ along domain $D$ . Define a set of constants $c_i \in  \mathbb{R}$ and define the functions $g_i(x)$ so each $g_i(x)$ . \begin{equation} 	g_i(x) = f_i(x) + c_i \end{equation} The mean of the functions $g_i$ at $x$ is denoted $\mu_g(x)$ \begin{equation} 	\mu_g(x) = \frac{1}{N} \sum_{i=1}^{N} (g_i(x)) \end{equation} We define the variance of $g_i(x)$ using the following: \begin{equation} 	Var_g(x) = \frac{1}{N} \sum_{i=1}^{N} (g_i(x) - \mu_g(x))^2 \end{equation} Our goal is to find the set of constants $c_i$ to minimise the quantity. \begin{equation} \max_{x \in D} \{ (Var_g(x)) \}  \end{equation} What is a reasonable strategy for finding the set of $c_i$ 's?,Assume we have a family of continuous functions along domain . Define a set of constants and define the functions so each . The mean of the functions at is denoted We define the variance of using the following: Our goal is to find the set of constants to minimise the quantity. What is a reasonable strategy for finding the set of 's?,"N f_i(x)\in C_\infty D c_i \in  \mathbb{R} g_i(x) g_i(x) \begin{equation}
	g_i(x) = f_i(x) + c_i
\end{equation} g_i x \mu_g(x) \begin{equation}
	\mu_g(x) = \frac{1}{N} \sum_{i=1}^{N} (g_i(x))
\end{equation} g_i(x) \begin{equation}
	Var_g(x) = \frac{1}{N} \sum_{i=1}^{N} (g_i(x) - \mu_g(x))^2
\end{equation} c_i \begin{equation}
\max_{x \in D} \{ (Var_g(x)) \} 
\end{equation} c_i",['statistics']
99,Powers of Non-i.i.d. Random Matrices,Powers of Non-i.i.d. Random Matrices,,"Suppose there is some Random Matrix $A$ which exists in $\mathbb{R}^{N\times N}$ . Each element in $A$ has a different $\mu$ and $\sigma$ . However, all elements are independent of eachother. $A$ is a Ginibre ensemble in that it is non-Hermitian. Furthermore, the eigenvalues of $A$ are mostly real but some are imaginary. What are the distributions of $A^M$ where $M$ is a natural number? So far, I have done numerical experiments by using expressions for the distributions of eigenvalues (eq 2.15) and the $U$ and $V$ matrices from the means of $A$ . I approximated the distribution of $A = U \Sigma V^T$ where all randomness is contained inside $\Sigma$ and $U$ and $V$ are fixed. Then I tried to recreate the distribution of $A$ by drawing samples from the distribution for $\Sigma$ and carrying out the matrix products. However, the distributions from recreating $A$ from sampling from the eigenvalue pdfs were not similar to the original distributions of $A$ . Any information or resources is appreciated.","Suppose there is some Random Matrix which exists in . Each element in has a different and . However, all elements are independent of eachother. is a Ginibre ensemble in that it is non-Hermitian. Furthermore, the eigenvalues of are mostly real but some are imaginary. What are the distributions of where is a natural number? So far, I have done numerical experiments by using expressions for the distributions of eigenvalues (eq 2.15) and the and matrices from the means of . I approximated the distribution of where all randomness is contained inside and and are fixed. Then I tried to recreate the distribution of by drawing samples from the distribution for and carrying out the matrix products. However, the distributions from recreating from sampling from the eigenvalue pdfs were not similar to the original distributions of . Any information or resources is appreciated.",A \mathbb{R}^{N\times N} A \mu \sigma A A A^M M U V A A = U \Sigma V^T \Sigma U V A \Sigma A A,"['probability-theory', 'statistics', 'reference-request', 'random-matrices']"
