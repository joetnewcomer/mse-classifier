,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,How do I calculate the derivative of a composition $R^{n} \rightarrow R^{n \times n} \rightarrow R^{n}$?,How do I calculate the derivative of a composition ?,R^{n} \rightarrow R^{n \times n} \rightarrow R^{n},"I am having problems calculating the derivative of a function. Let $C:\mathbb{R}^{n \times n} \longrightarrow \mathbb{R}^{n}$ with $C(M) = (I - M)^{-1}(I + M)x_0$ for (I - M) invertible ( $x_0 \in \mathbb{R}^n$ , $I$ identity) and $J:\mathbb{R}^{n} \longrightarrow \mathbb{R}^{n \times n}$ with $J(x)^T = -J(x)$ for all $x \in \mathbb{R}^n$ be two mappings. What is the derivative of the function $f(x) = C(J(x)) = (I - J(x))^{-1}(I + J(x))x_0$ with respect to $x$ ? How does the chain rule apply here? I would say that the derivative has the form $D_xf(x) = 2(I - J(x))^{-1} D_x J(x) (I + J(x))^{-1}x_0$ , where $ D_x J(x)$ is a third-order tensor or something like that. But as you can see, I'm not very familiar with the subject.","I am having problems calculating the derivative of a function. Let with for (I - M) invertible ( , identity) and with for all be two mappings. What is the derivative of the function with respect to ? How does the chain rule apply here? I would say that the derivative has the form , where is a third-order tensor or something like that. But as you can see, I'm not very familiar with the subject.",C:\mathbb{R}^{n \times n} \longrightarrow \mathbb{R}^{n} C(M) = (I - M)^{-1}(I + M)x_0 x_0 \in \mathbb{R}^n I J:\mathbb{R}^{n} \longrightarrow \mathbb{R}^{n \times n} J(x)^T = -J(x) x \in \mathbb{R}^n f(x) = C(J(x)) = (I - J(x))^{-1}(I + J(x))x_0 x D_xf(x) = 2(I - J(x))^{-1} D_x J(x) (I + J(x))^{-1}x_0  D_x J(x),"['matrices', 'multivariable-calculus', 'tensor-products', 'matrix-calculus', 'chain-rule']"
1,"Evaluating $\lim_{(x, y) \rightarrow (0, 0)} \frac{x^2 y + x \sin y}{\sqrt{x^2 + y^2 - x y}}$",Evaluating,"\lim_{(x, y) \rightarrow (0, 0)} \frac{x^2 y + x \sin y}{\sqrt{x^2 + y^2 - x y}}","I'm trying to find the following limit: $$\lim_{(x, y) \rightarrow (0, 0)} \frac{x^2 y + x \sin y}{\sqrt{x^2 + y^2 - x y}}$$ In both iterated limits I have obtained $0$ . I have also tried to get the limit in the line $y = x$ , and I also get $0$ . I don't know how to deal with that numerator. I have also tried: $$\frac{x^2 y + x \sin y}{\sqrt{x^2 + y^2 - x y}} = \frac{x (x y + \sin y)}{\sqrt{x^2 + y^2 - x y}} = \frac{x y (x + \frac{\sin y}{y})}{\sqrt{x^2 + y^2 - x y}}$$ I would like to use something like $|x| \le \sqrt{x^2 + y^2}$ and $|y| \le \sqrt{x^2 + y^2}$ , but the negative term in the square root doesn't allow me to use this method.","I'm trying to find the following limit: In both iterated limits I have obtained . I have also tried to get the limit in the line , and I also get . I don't know how to deal with that numerator. I have also tried: I would like to use something like and , but the negative term in the square root doesn't allow me to use this method.","\lim_{(x, y) \rightarrow (0, 0)} \frac{x^2 y + x \sin y}{\sqrt{x^2 + y^2 - x y}} 0 y = x 0 \frac{x^2 y + x \sin y}{\sqrt{x^2 + y^2 - x y}} = \frac{x (x y + \sin y)}{\sqrt{x^2 + y^2 - x y}} = \frac{x y (x + \frac{\sin y}{y})}{\sqrt{x^2 + y^2 - x y}} |x| \le \sqrt{x^2 + y^2} |y| \le \sqrt{x^2 + y^2}","['real-analysis', 'limits', 'multivariable-calculus']"
2,"How do I express the region bounded by $z=x^2, z+y=1, z-y=1$ as a z-simple triple integral?",How do I express the region bounded by  as a z-simple triple integral?,"z=x^2, z+y=1, z-y=1","I've been able to figure out the y-simple and x-simple triple integrals, but I'm having trouble with the z-simple one. I split the region in half over the x-axis, from what I can see, the projection onto the xy-plane of this is a rectangle of $[-1,1] \times [0,1]$ and $x^2 \leq z \leq 1-y$ .","I've been able to figure out the y-simple and x-simple triple integrals, but I'm having trouble with the z-simple one. I split the region in half over the x-axis, from what I can see, the projection onto the xy-plane of this is a rectangle of and .","[-1,1] \times [0,1] x^2 \leq z \leq 1-y","['integration', 'multivariable-calculus', 'volume']"
3,"What are the extremes of the function $ f\left(x,y\right)=xy\sqrt{1-\frac{x^2}{a^2}-\frac{y^2}{b^2}} $?",What are the extremes of the function ?," f\left(x,y\right)=xy\sqrt{1-\frac{x^2}{a^2}-\frac{y^2}{b^2}} ","$ f\left(x,y\right)=xy\sqrt{1-\frac{x^2}{a^2}-\frac{y^2}{b^2}} $ ; where a,b are constants. I have tried to differentiate the equation, but I get stuck in a very hard system after this. The answer of the problem is: $ f_{max}=\frac{ab}{3\sqrt{3}};f_{min}=-\frac{ab}{3\sqrt{3}} $","; where a,b are constants. I have tried to differentiate the equation, but I get stuck in a very hard system after this. The answer of the problem is:"," f\left(x,y\right)=xy\sqrt{1-\frac{x^2}{a^2}-\frac{y^2}{b^2}}   f_{max}=\frac{ab}{3\sqrt{3}};f_{min}=-\frac{ab}{3\sqrt{3}} ","['analysis', 'multivariable-calculus', 'extreme-value-analysis']"
4,"Limit existing: $\lim_{(x,y)\to(0,0)} \frac{xy^2}{(x^2+y^2)^{3/2}}$",Limit existing:,"\lim_{(x,y)\to(0,0)} \frac{xy^2}{(x^2+y^2)^{3/2}}","Does this limit exist? $$\lim_{(x,y)\to(0,0)} \frac{xy^2}{(x^2+y^2)^{3/2}}$$ I tried some sequnces $(\frac{1}{n},\frac{1}{n})$ , and similar, and limit is $0$ . But I can't prove for all. Also, can't prove that there is no limit.","Does this limit exist? I tried some sequnces , and similar, and limit is . But I can't prove for all. Also, can't prove that there is no limit.","\lim_{(x,y)\to(0,0)} \frac{xy^2}{(x^2+y^2)^{3/2}} (\frac{1}{n},\frac{1}{n}) 0","['calculus', 'limits', 'multivariable-calculus']"
5,"Let $a+b+c=3,$ then prove$\sqrt[3]{\frac{a+b}{5ab+4}}+\sqrt[3]{\frac{c+b}{5cb+4}}+\sqrt[3]{\frac{a+c}{5ac+4}}\ge \sqrt[3]{6}$",Let  then prove,"a+b+c=3, \sqrt[3]{\frac{a+b}{5ab+4}}+\sqrt[3]{\frac{c+b}{5cb+4}}+\sqrt[3]{\frac{a+c}{5ac+4}}\ge \sqrt[3]{6}","Problem If $a,b,c\ge 0: a+b+c=3,$ then $$\sqrt[3]{\frac{a+b}{5ab+4}}+\sqrt[3]{\frac{c+b}{5cb+4}}+\sqrt[3]{\frac{a+c}{5ac+4}}\ge \sqrt[3]{6}.\tag{1}$$ I came up with when trying to prove $$\frac{a+b}{5ab+4}+\frac{c+b}{5cb+4}+\frac{a+c}{5ac+4}\ge \frac{2}{3},$$ which is not hard by $uvw$ method. I'm looking for a nice proof $(1).$ It might be useful if the solver give motivate path. Thank you for helping.",Problem If then I came up with when trying to prove which is not hard by method. I'm looking for a nice proof It might be useful if the solver give motivate path. Thank you for helping.,"a,b,c\ge 0: a+b+c=3, \sqrt[3]{\frac{a+b}{5ab+4}}+\sqrt[3]{\frac{c+b}{5cb+4}}+\sqrt[3]{\frac{a+c}{5ac+4}}\ge \sqrt[3]{6}.\tag{1} \frac{a+b}{5ab+4}+\frac{c+b}{5cb+4}+\frac{a+c}{5ac+4}\ge \frac{2}{3}, uvw (1).","['algebra-precalculus', 'multivariable-calculus', 'inequality', 'symmetric-polynomials', 'uvw']"
6,"Is there an incompressible vector field $\mathbf{F}$ with $\nabla \times \mathbf{F} = (y^2, z^2, x^2)$?",Is there an incompressible vector field  with ?,"\mathbf{F} \nabla \times \mathbf{F} = (y^2, z^2, x^2)","I want to find an incompressible vector field $\mathbf{F}$ such that $\nabla \times \mathbf{F} = (y^2,z^2,x^2)$ . After some attempts to find such $\mathbf{F}$ , I think the vector field $\mathbf{F}$ with given conditions may not exist. However even for this side, I do not have an idea to proceed. Since $\mathbf{F}$ is incompressible we have $\mathbf{F} = \nabla \times \mathbf{G}$ for some $\mathbf{G}$ , which leads to $\nabla \times(\nabla \times \mathbf{G}) = (y^2,z^2,x^2)$ . However there is no additional property that I know about double curl to prove nonexistence of such $\mathbf{F}$ . Thanks in advance for any form of help, hint, or solution.","I want to find an incompressible vector field such that . After some attempts to find such , I think the vector field with given conditions may not exist. However even for this side, I do not have an idea to proceed. Since is incompressible we have for some , which leads to . However there is no additional property that I know about double curl to prove nonexistence of such . Thanks in advance for any form of help, hint, or solution.","\mathbf{F} \nabla \times \mathbf{F} = (y^2,z^2,x^2) \mathbf{F} \mathbf{F} \mathbf{F} \mathbf{F} = \nabla \times \mathbf{G} \mathbf{G} \nabla \times(\nabla \times \mathbf{G}) = (y^2,z^2,x^2) \mathbf{F}","['multivariable-calculus', 'vector-analysis', 'vector-fields']"
7,"Multivariable limits: $ \lim_{{(x,y) \to (0,0)}} \frac{{x^4 + y^4}}{{\sqrt{{x^2 + y^4}}}} $",Multivariable limits:," \lim_{{(x,y) \to (0,0)}} \frac{{x^4 + y^4}}{{\sqrt{{x^2 + y^4}}}} ","$$ \text{Evaluate the following limit: } A= \lim_{{(x,y) \to (0,0)}} \frac{{x^4 + y^4}}{{\sqrt{{x^2 + y^4}}}}$$ I've tried using polar coordinates, but am having trouble solving this. $$ \lim_{{r \to 0}} \frac{{(r\cos(\theta))^4 + (r\sin(\theta))^4}}{{\sqrt{{(r\cos(\theta))^2 + (r\sin(\theta))^4}}}} $$ After substituting, my first thought was to rationalize the denominator, which resulted in this: $$ \lim_{{r \to 0}} \frac{{\sqrt{{(r\cos(\theta))^2 + (r\sin(\theta))^4)}}{{(r\cos(\theta))^4 + (r\sin(\theta))^4) }}}}{{(r\cos(\theta))^2 + (r\sin(\theta))^4}} $$ But from here I'm having trouble moving forward. Can anyone provide any hints or tips? Would be greatly appreciated!","I've tried using polar coordinates, but am having trouble solving this. After substituting, my first thought was to rationalize the denominator, which resulted in this: But from here I'm having trouble moving forward. Can anyone provide any hints or tips? Would be greatly appreciated!"," \text{Evaluate the following limit: }
A= \lim_{{(x,y) \to (0,0)}} \frac{{x^4 + y^4}}{{\sqrt{{x^2 + y^4}}}} 
\lim_{{r \to 0}} \frac{{(r\cos(\theta))^4 + (r\sin(\theta))^4}}{{\sqrt{{(r\cos(\theta))^2 + (r\sin(\theta))^4}}}}
 
\lim_{{r \to 0}} \frac{{\sqrt{{(r\cos(\theta))^2 + (r\sin(\theta))^4)}}{{(r\cos(\theta))^4 + (r\sin(\theta))^4)
}}}}{{(r\cos(\theta))^2 + (r\sin(\theta))^4}}
","['limits', 'multivariable-calculus']"
8,"What is the ""polar coordinate function""?","What is the ""polar coordinate function""?",,"I'm reading Tapp's Differential Geometry of Curves and Surfaces, I have this problem: $\quad\color{green}{\text{Exercise 1.10.}}$ Prove that the arc length, $L$ , of the graph of the polar coordinate function $r(\theta)$ , $\theta \in [a, b]$ , is What is the ""polar coordinate function""? I tried a few guesses but nothing I thought seemed to make sense nor would give me the arclength function above. Using the definition of arclength, I tried to ""reverse engineer"" it and I got: $$\left(\int_{a}^{\theta} r(x)\, dx,\, r(\theta) \right)$$ This seems to be the only function that would make sense here but I have no idea what $r(\theta)$ would be. This is — perhaps — the least worst thing I could think of.","I'm reading Tapp's Differential Geometry of Curves and Surfaces, I have this problem: Prove that the arc length, , of the graph of the polar coordinate function , , is What is the ""polar coordinate function""? I tried a few guesses but nothing I thought seemed to make sense nor would give me the arclength function above. Using the definition of arclength, I tried to ""reverse engineer"" it and I got: This seems to be the only function that would make sense here but I have no idea what would be. This is — perhaps — the least worst thing I could think of.","\quad\color{green}{\text{Exercise 1.10.}} L r(\theta) \theta \in [a, b] \left(\int_{a}^{\theta} r(x)\, dx,\, r(\theta) \right) r(\theta)","['calculus', 'integration', 'multivariable-calculus', 'differential-geometry', 'polar-coordinates']"
9,limits of 2 variables with trigonometric terms,limits of 2 variables with trigonometric terms,,"I'm trying to determine the following limit $$ \lim_{(x,y) \to (0,0)} \frac{x^2-\sin(x^2y^2)+y^2}{x^2+\sin(x^2y^2)+y^2}$$ I tried to use polar coordinates and then Taylor and got $$ \lim_{r \to 0} \frac{2-2 \cdot \cos^2(\theta) \cdot \sin^2(\theta) \cdot \cos(r^2\cos^2(\theta)\sin^2(\theta))}{2+2 \cdot \cos^2(\theta) \cdot \sin^2(\theta) \cdot \cos(r^2\cos^2(\theta)\sin^2(\theta))}$$ Which does not say anything I guess? How can I solve this type of questions?",I'm trying to determine the following limit I tried to use polar coordinates and then Taylor and got Which does not say anything I guess? How can I solve this type of questions?," \lim_{(x,y) \to (0,0)} \frac{x^2-\sin(x^2y^2)+y^2}{x^2+\sin(x^2y^2)+y^2}  \lim_{r \to 0} \frac{2-2 \cdot \cos^2(\theta) \cdot \sin^2(\theta) \cdot \cos(r^2\cos^2(\theta)\sin^2(\theta))}{2+2 \cdot \cos^2(\theta) \cdot \sin^2(\theta) \cdot \cos(r^2\cos^2(\theta)\sin^2(\theta))}","['calculus', 'limits', 'multivariable-calculus', 'polar-coordinates']"
10,"Prove that $\lim_{(x,y) \to (0,0)} \frac{xy(x-y)}{x^3 + y^3}$ does not exist",Prove that  does not exist,"\lim_{(x,y) \to (0,0)} \frac{xy(x-y)}{x^3 + y^3}","I am trying to prove that the following limit does not exist. $$\lim\limits_{(x,y) \to (0,0)} \frac{xy(x-y)}{x^3 + y^3}$$ I have tried several paths such as: $\operatorname{\gamma}(t) = (t,0)$ $\operatorname{\gamma}(t) = (0,t)$ $\operatorname{\gamma}(t) = (t,t)$ $\operatorname{\gamma}(t) = (t,t^2)$ $\operatorname{\gamma}(t) = (t^2,t)$ but all these paths equal $0$ . I have started think that the limit is in fact $0$ and I expended a quite long time trying to prove it by the squeeze theorem and them I gave up and looked over WolframAlpha and learned that the limit does not exist. I do not know how to prove it. Can someone, please: Show for this particular limit a path that is different than $0$ ? Explain the thought processes I should apply to this kind of problem? How does one get the feeling that this limit does not exist after trying so many paths?","I am trying to prove that the following limit does not exist. I have tried several paths such as: but all these paths equal . I have started think that the limit is in fact and I expended a quite long time trying to prove it by the squeeze theorem and them I gave up and looked over WolframAlpha and learned that the limit does not exist. I do not know how to prove it. Can someone, please: Show for this particular limit a path that is different than ? Explain the thought processes I should apply to this kind of problem? How does one get the feeling that this limit does not exist after trying so many paths?","\lim\limits_{(x,y) \to (0,0)} \frac{xy(x-y)}{x^3 + y^3} \operatorname{\gamma}(t) = (t,0) \operatorname{\gamma}(t) = (0,t) \operatorname{\gamma}(t) = (t,t) \operatorname{\gamma}(t) = (t,t^2) \operatorname{\gamma}(t) = (t^2,t) 0 0 0","['calculus', 'limits', 'multivariable-calculus']"
11,Finding minimum value of $x^2+y^2+xy+x-4y+9$,Finding minimum value of,x^2+y^2+xy+x-4y+9,"What is the minimum value of $f(x,y)=x^2+y^2+xy+x-4y+9$ ? I tried completing squares, $$x^2+y^2+xy+x-4y+9=\frac12(x^2+2xy+y^2+x^2+2x+1+y^2-8y+16+1)=\frac12[(x+y)^2+(x+1)^2+(y-4)^2+1]$$ But not sure how to continue.","What is the minimum value of ? I tried completing squares, But not sure how to continue.","f(x,y)=x^2+y^2+xy+x-4y+9 x^2+y^2+xy+x-4y+9=\frac12(x^2+2xy+y^2+x^2+2x+1+y^2-8y+16+1)=\frac12[(x+y)^2+(x+1)^2+(y-4)^2+1]","['multivariable-calculus', 'optimization']"
12,The anti-derivative of any matrix function,The anti-derivative of any matrix function,,"If we have some differentiable function $f:\mathbb{R}^n\mapsto\mathbb{R}^m$ , we can always calculate the Jacobian of this function, i.e., $$ \frac{df}{dx}(x) = \begin{pmatrix}\frac{\partial f_1 }{\partial x_1 } & \cdots & \frac{\partial f_1 }{\partial x_n } \\ \vdots & \ddots & \vdots \\ \frac{\partial f_m }{\partial x_1 } & \cdots & \frac{\partial f_m }{\partial x_n } \end{pmatrix} $$ So, for example if $f=\begin{pmatrix} x_1+x_2^2 \\ \sin(x_1 x_2) \end{pmatrix}$ , we have $$ F(x) = \frac{df}{dx}(x) = \begin{pmatrix} 1 & 2 x_2 \\ x_2 \cos(x_1x_2 ) & x_1 \cos(x_1x_2 ) \end{pmatrix}. $$ My question is, can we find an $f$ for any $F(x)$ ? In other words, is any matrix function of the form $$F(x_1, \ldots, x_n) = \begin{pmatrix} F_{1,1}(x_1, \ldots, x_n) & \cdots & F_{1,n}(x_1, \ldots, x_n) \\ \vdots & \ddots & \vdots \\ F_{m,1}(x_1, \ldots, x_n) & \cdots & F_{m,n}(x_1, \ldots, x_n) \end{pmatrix}, \quad (F_{i,j}\text{ is assumed to be continuous}) $$ a Jacobian matrix for some mapping $f$ ? On one hand this seems trivial, on the other hand I cannot find anything useful. I already tried to have it row by row, but finding the integral basically from a freaky row-vector is not really insightful... (my concern is that if I take $F(x)$ as some super weird matrix function there will not exist an $f$ ...) (NB: please add some reference or keywords in your answer)","If we have some differentiable function , we can always calculate the Jacobian of this function, i.e., So, for example if , we have My question is, can we find an for any ? In other words, is any matrix function of the form a Jacobian matrix for some mapping ? On one hand this seems trivial, on the other hand I cannot find anything useful. I already tried to have it row by row, but finding the integral basically from a freaky row-vector is not really insightful... (my concern is that if I take as some super weird matrix function there will not exist an ...) (NB: please add some reference or keywords in your answer)","f:\mathbb{R}^n\mapsto\mathbb{R}^m  \frac{df}{dx}(x) = \begin{pmatrix}\frac{\partial f_1 }{\partial x_1 } & \cdots & \frac{\partial f_1 }{\partial x_n } \\ \vdots & \ddots & \vdots \\ \frac{\partial f_m }{\partial x_1 } & \cdots & \frac{\partial f_m }{\partial x_n } \end{pmatrix}  f=\begin{pmatrix} x_1+x_2^2 \\ \sin(x_1 x_2) \end{pmatrix}  F(x) = \frac{df}{dx}(x) = \begin{pmatrix} 1 & 2 x_2 \\ x_2 \cos(x_1x_2 ) & x_1 \cos(x_1x_2 ) \end{pmatrix}.  f F(x) F(x_1, \ldots, x_n) = \begin{pmatrix} F_{1,1}(x_1, \ldots, x_n) & \cdots & F_{1,n}(x_1, \ldots, x_n) \\ \vdots & \ddots & \vdots \\ F_{m,1}(x_1, \ldots, x_n) & \cdots & F_{m,n}(x_1, \ldots, x_n) \end{pmatrix}, \quad (F_{i,j}\text{ is assumed to be continuous})  f F(x) f","['integration', 'multivariable-calculus']"
13,"What is the derivative of $\sum_{i,j}^n \langle A^{ij}x_i,x_j \rangle$",What is the derivative of,"\sum_{i,j}^n \langle A^{ij}x_i,x_j \rangle","Given different vectors $x_1,\dots,x_n$ and $n^2$ matrices $A^{11}\dots,A^{nn}$ with $A^{ij}=A^{ji}$ , I would like to calculate  the derivative with respect to $x_k$ of $$\sum_{i,j}^n \langle A^{ij}x_i,x_j \rangle$$ Am I right that this should be $\sum_{i\not= k}\langle A^{ik}x_i,x_k\rangle + 2\langle A^{kk}x_k,x_k\rangle$","Given different vectors and matrices with , I would like to calculate  the derivative with respect to of Am I right that this should be","x_1,\dots,x_n n^2 A^{11}\dots,A^{nn} A^{ij}=A^{ji} x_k \sum_{i,j}^n \langle A^{ij}x_i,x_j \rangle \sum_{i\not= k}\langle A^{ik}x_i,x_k\rangle + 2\langle A^{kk}x_k,x_k\rangle","['multivariable-calculus', 'partial-derivative', 'matrix-calculus']"
14,"What does $\int_CF=\int_a^bF(C(t))\cdot\frac{dC}{dt}\,dt$ actually mean?",What does  actually mean?,"\int_CF=\int_a^bF(C(t))\cdot\frac{dC}{dt}\,dt","Let $F$ be a continuous vector field on an open set $U$ and $C$ is a continuously differentiable curve on $U$ . We define the integral of $F$ along $C$ to be $$\int_CF=\int_a^bF(C(t))\cdot\frac{dC}{dt}\,dt$$ using the chain rule $$\int_CF=\int_{C(a)}^{C(b)}F(C)dC$$ But what does this all mean? I mean is there any geometric interpretation to the integral curve? or can you just describe what does the integral curve do? and the reason why we decompose a field with a curve?",Let be a continuous vector field on an open set and is a continuously differentiable curve on . We define the integral of along to be using the chain rule But what does this all mean? I mean is there any geometric interpretation to the integral curve? or can you just describe what does the integral curve do? and the reason why we decompose a field with a curve?,"F U C U F C \int_CF=\int_a^bF(C(t))\cdot\frac{dC}{dt}\,dt \int_CF=\int_{C(a)}^{C(b)}F(C)dC","['calculus', 'multivariable-calculus', 'intuition', 'vector-fields']"
15,Prove $\lim\limits_{x^2 + y^2 \to +\infty} x^2 -2xy + 2y^2 = +\infty$,Prove,\lim\limits_{x^2 + y^2 \to +\infty} x^2 -2xy + 2y^2 = +\infty,"Prove that $$\lim_{x^2 + y^2 \to +\infty} x^2 -2xy + 2y^2 = +\infty$$ My attempt: $$x^2 + 2y^2 = x^2+y^2 + y^2 	\implies \lim_{x^2 + y^2 \to +\infty}x^2 +2y^2 = +\infty$$ Then, from Cauchy-Schwarz: $$x^2 + 2y^2 \geq 2\sqrt2xy \geq 2xy $$ Thus, $$x^2+2y^2 -2xy \geq 0$$ I think I am on the correct path, but I don't know how to proceed.","Prove that My attempt: Then, from Cauchy-Schwarz: Thus, I think I am on the correct path, but I don't know how to proceed.",\lim_{x^2 + y^2 \to +\infty} x^2 -2xy + 2y^2 = +\infty x^2 + 2y^2 = x^2+y^2 + y^2 	\implies \lim_{x^2 + y^2 \to +\infty}x^2 +2y^2 = +\infty x^2 + 2y^2 \geq 2\sqrt2xy \geq 2xy  x^2+2y^2 -2xy \geq 0,"['real-analysis', 'calculus', 'limits', 'multivariable-calculus']"
16,How to evaluate $\iint_R \sin(\frac{y-x}{y+x})dydx$ with Jacobian substitution?,How to evaluate  with Jacobian substitution?,\iint_R \sin(\frac{y-x}{y+x})dydx,"I want to calculate this integral with substitution $x=u+v , \ y=u-v$ : $$\iint_R \sin\left(\frac{y-x}{y+x}\right)dydx$$ $$R:= \{(x,y):x+y≤\pi, y≥0,x≥0\}$$ but I don't know how to set new bounds for $u$ and $v$ .",I want to calculate this integral with substitution : but I don't know how to set new bounds for and .,"x=u+v , \ y=u-v \iint_R \sin\left(\frac{y-x}{y+x}\right)dydx R:= \{(x,y):x+y≤\pi, y≥0,x≥0\} u v","['integration', 'multivariable-calculus', 'substitution', 'jacobian', 'bounds-of-integration']"
17,Integrating $\int_{1}^{\infty}\int_{1}^{\infty}(x+y)^2e^{-(x+y)}dydx$,Integrating,\int_{1}^{\infty}\int_{1}^{\infty}(x+y)^2e^{-(x+y)}dydx,"How to evaluate the following double integral $$\int_{1}^{\infty}\int_{1}^{\infty}(x+y)^2e^{-(x+y)}dydx\,?$$ Is there an easier way to evaluate this than to brute force it through integration by parts many many times? I don't think polar coordinate transformation would help for this but I could be mistaken.",How to evaluate the following double integral Is there an easier way to evaluate this than to brute force it through integration by parts many many times? I don't think polar coordinate transformation would help for this but I could be mistaken.,"\int_{1}^{\infty}\int_{1}^{\infty}(x+y)^2e^{-(x+y)}dydx\,?","['integration', 'multivariable-calculus']"
18,"Calculating $\lim_{(x,y) \to(0,0)} \frac{x^2y}{x^2+y^4}$",Calculating,"\lim_{(x,y) \to(0,0)} \frac{x^2y}{x^2+y^4}","I can't figure out how to calculate this limit (or prove it does not exist) $$ \lim_{(x,y) \to(0,0)} \frac{x^2y}{x^2+y^4} $$ I've tried with restrictions on $y=mx$ and curves of the form $y=x^n$ .  The limit should not exist but even with polar coordinates I can't figure it out",I can't figure out how to calculate this limit (or prove it does not exist) I've tried with restrictions on and curves of the form .  The limit should not exist but even with polar coordinates I can't figure it out,"
\lim_{(x,y) \to(0,0)} \frac{x^2y}{x^2+y^4}
 y=mx y=x^n","['limits', 'multivariable-calculus']"
19,continuity of a multivariable function at a point,continuity of a multivariable function at a point,,"I want to know whether the function $\dfrac{x^2y}{x-y}$ is continuous at $(0,0)$ or not. when I switch to polar coordinate i get the limit of : $\dfrac{(r \cos^2 \theta \sin \theta)}{\cos \theta - \sin \theta}$ when r is going to zero. can I say that this limit does not exist because there are points where $\theta = \dfrac{\pi}{4}$ and then the denominator is zero, and therefore the function is not continuous at $(0,0)$ ? the value of the function when x is equal to y is 0 thank you","I want to know whether the function is continuous at or not. when I switch to polar coordinate i get the limit of : when r is going to zero. can I say that this limit does not exist because there are points where and then the denominator is zero, and therefore the function is not continuous at ? the value of the function when x is equal to y is 0 thank you","\dfrac{x^2y}{x-y} (0,0) \dfrac{(r \cos^2 \theta \sin \theta)}{\cos \theta - \sin \theta} \theta = \dfrac{\pi}{4} (0,0)","['multivariable-calculus', 'continuity']"
20,Minimum of $x_1^2+x_2^4$,Minimum of,x_1^2+x_2^4,"I am asked to find a minimum of $f(x_1, x_2) = x_1^2+x_2^4$ applying the optimality conditions. I am stuck. What I have found is not conclusive. I show what I have done: Testing the First-Order Necessary Conditions I computed the gradient: $\left(\frac{\partial f}{\partial x_1}=2x_1 , \frac{\partial f}{\partial x_2}=4x_2^3\right)$ Now when doing: $\left(\frac{\partial f}{\partial x_1}, \frac{\partial f}{\partial x_2}\right)=0$ I obtain the stationary point $x^*=[0, 0]$ . Now, Testing the Second-Order Necessary Conditions Obtaing the Hessian matrix of the form: $[[2,0],[0, 12x_2^2]]$ . And the last eigenvalue is not constant? So now, I do not know how to proceed. By definition, it has to be positive semi-definite in order to possibly be an optimiser (or positive definite, then minimum for sure), but here... I do not know what to do. Thank you","I am asked to find a minimum of applying the optimality conditions. I am stuck. What I have found is not conclusive. I show what I have done: Testing the First-Order Necessary Conditions I computed the gradient: Now when doing: I obtain the stationary point . Now, Testing the Second-Order Necessary Conditions Obtaing the Hessian matrix of the form: . And the last eigenvalue is not constant? So now, I do not know how to proceed. By definition, it has to be positive semi-definite in order to possibly be an optimiser (or positive definite, then minimum for sure), but here... I do not know what to do. Thank you","f(x_1, x_2) = x_1^2+x_2^4 \left(\frac{\partial f}{\partial x_1}=2x_1 , \frac{\partial f}{\partial x_2}=4x_2^3\right) \left(\frac{\partial f}{\partial x_1}, \frac{\partial f}{\partial x_2}\right)=0 x^*=[0, 0] [[2,0],[0, 12x_2^2]]","['calculus', 'multivariable-calculus', 'optimization', 'maxima-minima', 'hessian-matrix']"
21,"If the total differential is a scalar, how can it also be a covector used to calculate the directional derivative at a point?","If the total differential is a scalar, how can it also be a covector used to calculate the directional derivative at a point?",,"In multivariable calculus, the gradient of a function $f(x,y)$ at a given point is the covariant vector: $$\vec\nabla_f=\begin{bmatrix}\frac{\partial f}{\partial x},\frac{\partial f}{\partial y}\end{bmatrix}$$ while the corresponding contravariant vector of differentials is $$\mathrm  d\vec x=[\mathrm dx, \mathrm dy]$$ Their dot product results in the total differential of the function at that given point: $$\mathrm df=\frac{\partial f}{\partial x}\mathrm dx+\frac{\partial f}{\partial y}\mathrm dy.$$ So far, so good. Except that this last calculation is supposed to yield a scalar value according to Reflections on Relativity by Kevin Brown (*): ""dy [read df for notational consistency] equals the scalar (dot) product of these two vectors... The scalar quantity dy is called the total differential of y."" At the same time, this last calculation is also referred to as a 1-form ; a (0,1)-tensor; or a covector (actually an element of the cotangent space), thus enabling the calculation of the directional derivative at the point under consideration, and in the direction of a vector $\mathbf {\vec v}$ in the tangent space , as the dot product: $$\langle \mathrm df , \mathbf{\vec v}\rangle\to\mathbb R.$$ The question: Since $\mathrm df$ cannot be a scalar and a covector at the same time, which one is it, and what's wrong in the above definitions that explains this apparent contradiction? (*) Please note that this seems to be a slight of hand (or possible in-correction in the quoted source after the accepted answer and its associated comment: "" Mathematically, total differentials are covectors (or covector fields) . You may apply them to vectors (or vector fields) in order to obtain scalars (or scalar fields). But they themselves should not be thought as scalars."" In the accepted answer the total differential is referred to as the ""differential operator at $p$ of $f.$ ""","In multivariable calculus, the gradient of a function at a given point is the covariant vector: while the corresponding contravariant vector of differentials is Their dot product results in the total differential of the function at that given point: So far, so good. Except that this last calculation is supposed to yield a scalar value according to Reflections on Relativity by Kevin Brown (*): ""dy [read df for notational consistency] equals the scalar (dot) product of these two vectors... The scalar quantity dy is called the total differential of y."" At the same time, this last calculation is also referred to as a 1-form ; a (0,1)-tensor; or a covector (actually an element of the cotangent space), thus enabling the calculation of the directional derivative at the point under consideration, and in the direction of a vector in the tangent space , as the dot product: The question: Since cannot be a scalar and a covector at the same time, which one is it, and what's wrong in the above definitions that explains this apparent contradiction? (*) Please note that this seems to be a slight of hand (or possible in-correction in the quoted source after the accepted answer and its associated comment: "" Mathematically, total differentials are covectors (or covector fields) . You may apply them to vectors (or vector fields) in order to obtain scalars (or scalar fields). But they themselves should not be thought as scalars."" In the accepted answer the total differential is referred to as the ""differential operator at of ""","f(x,y) \vec\nabla_f=\begin{bmatrix}\frac{\partial f}{\partial x},\frac{\partial f}{\partial y}\end{bmatrix} \mathrm  d\vec x=[\mathrm dx, \mathrm dy] \mathrm df=\frac{\partial f}{\partial x}\mathrm dx+\frac{\partial f}{\partial y}\mathrm dy. \mathbf {\vec v} \langle \mathrm df , \mathbf{\vec v}\rangle\to\mathbb R. \mathrm df p f.",['multivariable-calculus']
22,Use greens theorem to find work done,Use greens theorem to find work done,,"Use Green's Theorem to find the work done by the force $\mathbf{F}(x,y)=x(x+y)\mathbf{i}+xy^2\mathbf{j}$ in moving a particle from the origin along the $x$ -axis to $(1,0)$ , then along the line segment to $(0,1)$ , and back to the origin along the $y$ -axis. So I was able to find $\frac{\partial Q}{\partial x} -\frac{\partial P}{\partial y}$ to be $y^2 -x$ and I integrated that with respect to $y$ and $x$ by using $y= 1-x$ as my upper bound and $y=0$ as my lower bound, and $0 < x < 1$ for my $x$ integral. but it came out to $-\frac{7}{36}$ , and the answer is $-\frac1{12}$ . I'm not sure if I'm doing something fundamentally wrong here or if its a calculation error. I checked it twice. How do I do it correctly?","Use Green's Theorem to find the work done by the force in moving a particle from the origin along the -axis to , then along the line segment to , and back to the origin along the -axis. So I was able to find to be and I integrated that with respect to and by using as my upper bound and as my lower bound, and for my integral. but it came out to , and the answer is . I'm not sure if I'm doing something fundamentally wrong here or if its a calculation error. I checked it twice. How do I do it correctly?","\mathbf{F}(x,y)=x(x+y)\mathbf{i}+xy^2\mathbf{j} x (1,0) (0,1) y \frac{\partial Q}{\partial x} -\frac{\partial P}{\partial y} y^2 -x y x y= 1-x y=0 0 < x < 1 x -\frac{7}{36} -\frac1{12}","['multivariable-calculus', 'line-integrals', 'greens-theorem']"
23,"use implicit differentiation to find $\partial z/\partial x$, $\partial z/\partial y$","use implicit differentiation to find ,",\partial z/\partial x \partial z/\partial y,"I can't find the word implicit differentiation anywhere in the book, but I'm assuming it means solve for $z$ in this case and differentiate with respect to $x$, then $y$ in this problem. But when I took the derivative with respect to $x$ of 47 after solving for $z$, i get a different answer. I got $$z = \dfrac{\sqrt{-x^2-2y^2+1}}{\sqrt{3}}$$ and for the derivative of that: $$-\dfrac{x}{\sqrt{3}\sqrt{-x^2-2y^2+1}}$$ (i got these results on https://www.derivative-calculator.net/ ) this is different than the answer in the book. am i not supposed to solve for $z$ and differentiate with respect to $x$ then $y$? Is this another form of the answer? help.. the answer is $-x/3z$ ... which I don't get..","I can't find the word implicit differentiation anywhere in the book, but I'm assuming it means solve for $z$ in this case and differentiate with respect to $x$, then $y$ in this problem. But when I took the derivative with respect to $x$ of 47 after solving for $z$, i get a different answer. I got $$z = \dfrac{\sqrt{-x^2-2y^2+1}}{\sqrt{3}}$$ and for the derivative of that: $$-\dfrac{x}{\sqrt{3}\sqrt{-x^2-2y^2+1}}$$ (i got these results on https://www.derivative-calculator.net/ ) this is different than the answer in the book. am i not supposed to solve for $z$ and differentiate with respect to $x$ then $y$? Is this another form of the answer? help.. the answer is $-x/3z$ ... which I don't get..",,"['calculus', 'multivariable-calculus', 'partial-derivative', 'implicit-differentiation']"
24,Volume integral.,Volume integral.,,"Calculate the volume integral of $T = xyz^2$ over the prism defined by vertices $(0,0,0), (0,0,3),(1,0,0), (0,1,0),(1, 0, 3), (0, 1, 3)$. The limits of integration taken in the given answer are : for x,  $0$  to $1- y$, for y, $0$ to  $1$ and for z, $0$  to $3$. I don't understand why $1-y$ is the upper limit. Should not it be $1$ ? And how do they came up with $1- y$ not something else ?","Calculate the volume integral of $T = xyz^2$ over the prism defined by vertices $(0,0,0), (0,0,3),(1,0,0), (0,1,0),(1, 0, 3), (0, 1, 3)$. The limits of integration taken in the given answer are : for x,  $0$  to $1- y$, for y, $0$ to  $1$ and for z, $0$  to $3$. I don't understand why $1-y$ is the upper limit. Should not it be $1$ ? And how do they came up with $1- y$ not something else ?",,"['calculus', 'integration', 'multivariable-calculus', 'vector-analysis', 'multiple-integral']"
25,"Show $ \int_0^1 \int_0^1 \log \left| x-y\right|\,dx\,dy>-\infty.$",Show," \int_0^1 \int_0^1 \log \left| x-y\right|\,dx\,dy>-\infty.","I'm struggling to show that $ \int_0^1 \int_0^1 \log \left| x-y\right|\,dx\,dy >-\infty$ which means that $f(x,y):=\log| x-y|$ is in $L^1([0,1]^2,\lambda\otimes \lambda)$. The part ""$<+\infty$"" is not difficult. The lower bound $1-\frac{1}{u} \leq \log u$ for all $u>0$, reduces the problem to $ \int_0^1 \int_0^1  \frac{1}{\left| x-y\right|}\,dx\,dy>-\infty$. Any help/hint would be appreciated.","I'm struggling to show that $ \int_0^1 \int_0^1 \log \left| x-y\right|\,dx\,dy >-\infty$ which means that $f(x,y):=\log| x-y|$ is in $L^1([0,1]^2,\lambda\otimes \lambda)$. The part ""$<+\infty$"" is not difficult. The lower bound $1-\frac{1}{u} \leq \log u$ for all $u>0$, reduces the problem to $ \int_0^1 \int_0^1  \frac{1}{\left| x-y\right|}\,dx\,dy>-\infty$. Any help/hint would be appreciated.",,['multivariable-calculus']
26,Evaluate $\int_0^1 \int_0^{1-y} \cos \left(\frac{x-y}{x+y}\right)dxdy$,Evaluate,\int_0^1 \int_0^{1-y} \cos \left(\frac{x-y}{x+y}\right)dxdy,Evaluate the following double integral $$\int_0^1 \int_0^{1-y} \cos \left(\frac{x-y}{x+y}\right)dxdy$$ I tried transforming to \begin{align} x+y &=u\\ x-y &=v \end{align} but I think it is getting complicated.  Thanks in advance.,Evaluate the following double integral I tried transforming to but I think it is getting complicated.  Thanks in advance.,"\int_0^1 \int_0^{1-y} \cos \left(\frac{x-y}{x+y}\right)dxdy \begin{align}
x+y &=u\\
x-y &=v
\end{align}","['integration', 'multivariable-calculus', 'multiple-integral']"
27,Finding surface integral of a vector field over quarter of a cylinder,Finding surface integral of a vector field over quarter of a cylinder,,"Currently I am studying vector calculus at my university, and I came across a question that I was having problem in solving. The question is this Question Evaluate $$\iint\limits_S \vec{A} \cdot \hat{n}\,dS$$ over the entire surface $S$ of the region bounded by the cylinder $x^2 +z^2 =9$,  $x=0$, $y=0$, $y=8$, $z=0$, if $\vec{A}= 6z\,\hat{i}+(2x+y)\,\hat{j}-x\,\hat{k} $ The given answer is 18$\pi$ .","Currently I am studying vector calculus at my university, and I came across a question that I was having problem in solving. The question is this Question Evaluate $$\iint\limits_S \vec{A} \cdot \hat{n}\,dS$$ over the entire surface $S$ of the region bounded by the cylinder $x^2 +z^2 =9$,  $x=0$, $y=0$, $y=8$, $z=0$, if $\vec{A}= 6z\,\hat{i}+(2x+y)\,\hat{j}-x\,\hat{k} $ The given answer is 18$\pi$ .",,"['multivariable-calculus', 'vector-analysis', 'surface-integrals', 'divergence-operator']"
28,Calculate volume between two geometric figures,Calculate volume between two geometric figures,,I have a figure C that is defined as the intersection between the sphere $x^2+y^2+z^2 \le 1 $ and the cyllinder $x^2+y^2 \le \frac{1}{4}$. How should i calculate the volume of this figure?,I have a figure C that is defined as the intersection between the sphere $x^2+y^2+z^2 \le 1 $ and the cyllinder $x^2+y^2 \le \frac{1}{4}$. How should i calculate the volume of this figure?,,"['geometry', 'multivariable-calculus', 'integral-geometry']"
29,Volume of the ellipsoid $(x+2y)^2+(x-2y+z)^2+3z^2=1$,Volume of the ellipsoid,(x+2y)^2+(x-2y+z)^2+3z^2=1,"Find the volume of the ellipsoid $(x+2y)^2+(x-2y+z)^2+3z^2=1$, using integration. It is clear that this is not centered at the origin. So, how do I find the limits for an integral? Any suggestion please. I have no clue at all to start.","Find the volume of the ellipsoid $(x+2y)^2+(x-2y+z)^2+3z^2=1$, using integration. It is clear that this is not centered at the origin. So, how do I find the limits for an integral? Any suggestion please. I have no clue at all to start.",,"['integration', 'geometry', 'multivariable-calculus']"
30,Surjectivity of derivative of a vector valued function,Surjectivity of derivative of a vector valued function,,"Let $f:\mathbb R^3\to \mathbb R^3$ be a function such that $f(x,y,z)=f(x+y,0,x+z)$ for all $(x,y,z)\in \mathbb R^3$. I want to prove that $f^{'}(x)$ can never be onto for all point $x\in \mathbb R^3$ of the type $(a,0,c)$. Here if $f$ is a $C^{1}$ function, then by using inverse mapping theorem the problem may be solved. But unfortunately it is not given. Please help me to solve the problem.","Let $f:\mathbb R^3\to \mathbb R^3$ be a function such that $f(x,y,z)=f(x+y,0,x+z)$ for all $(x,y,z)\in \mathbb R^3$. I want to prove that $f^{'}(x)$ can never be onto for all point $x\in \mathbb R^3$ of the type $(a,0,c)$. Here if $f$ is a $C^{1}$ function, then by using inverse mapping theorem the problem may be solved. But unfortunately it is not given. Please help me to solve the problem.",,"['real-analysis', 'multivariable-calculus', 'derivatives']"
31,How does one parameterize $x^2 + xy + y^2 = \frac{1}{2}$?,How does one parameterize ?,x^2 + xy + y^2 = \frac{1}{2},"Parameterize the curve $C$ that intersects the surface   $x^2+y^2+z^2=1$ and the plane $x+y+z=0$. I have this replacing equations: $$ x^2+y^2+(-x-y)^2=1$$ and clearing have the following: $$ x^2+xy+y^2=1/2$$ which it is the equation of an ellipse but I find it difficult parameterization values Any advice will be of much help, thanks in advance","Parameterize the curve $C$ that intersects the surface   $x^2+y^2+z^2=1$ and the plane $x+y+z=0$. I have this replacing equations: $$ x^2+y^2+(-x-y)^2=1$$ and clearing have the following: $$ x^2+xy+y^2=1/2$$ which it is the equation of an ellipse but I find it difficult parameterization values Any advice will be of much help, thanks in advance",,"['integration', 'multivariable-calculus', 'parametric', 'line-integrals']"
32,"If $f: \mathbb{R}^2 \to \mathbb{R}$ is a $C^1$ function, then $f$ is not bijective","If  is a  function, then  is not bijective",f: \mathbb{R}^2 \to \mathbb{R} C^1 f,"If $f: \mathbb{R}^2 \to \mathbb{R}$ is a $C^1$ function, then $f$ is not bijective. Can someone explain why this is true or give me some hint? I don't realize how is bijection related with being a $C^1$ function, is it somehow related with the inverse function theorem?","If $f: \mathbb{R}^2 \to \mathbb{R}$ is a $C^1$ function, then $f$ is not bijective. Can someone explain why this is true or give me some hint? I don't realize how is bijection related with being a $C^1$ function, is it somehow related with the inverse function theorem?",,"['calculus', 'multivariable-calculus']"
33,"Limit of a multivariable function: $x^2\log(x^2+y^2)$, $(x,y)\to(0,0)$","Limit of a multivariable function: ,","x^2\log(x^2+y^2) (x,y)\to(0,0)","Can someone help me to solve this limit? $$\lim\limits_{(x,y)\to (0,0)} x^2\log(x^2+y^2)$$ For any line $y=mx$ the result is $0$, so, the candidate is $0$.  I tried to use the squeeze theorem, polar coordinates, etc. but I can't solve it. Thanks.","Can someone help me to solve this limit? $$\lim\limits_{(x,y)\to (0,0)} x^2\log(x^2+y^2)$$ For any line $y=mx$ the result is $0$, so, the candidate is $0$.  I tried to use the squeeze theorem, polar coordinates, etc. but I can't solve it. Thanks.",,"['limits', 'multivariable-calculus']"
34,All line integrals in the world are zero...?,All line integrals in the world are zero...?,,"Using Stokes' theorem, the line integral of a vector field gives a surface integral of the curl of the vector field, and after that, if we apply Gauss' divergence theorem in that, it gives a volume integral of the divergence of the curl of that vector field. But we know the divergence of the curl of a vector field is $0$. … so how can it be possible? Where is the mistake??","Using Stokes' theorem, the line integral of a vector field gives a surface integral of the curl of the vector field, and after that, if we apply Gauss' divergence theorem in that, it gives a volume integral of the divergence of the curl of that vector field. But we know the divergence of the curl of a vector field is $0$. … so how can it be possible? Where is the mistake??",,['multivariable-calculus']
35,Is $\emptyset$ in $R^n$ an open set?,Is  in  an open set?,\emptyset R^n,"The complement of $\emptyset$ in $R^n$ is $R^n$ itself, which is an open set itself. So, $\emptyset$ should be a closed set, by definition of closed set. However, Tom M. Apostol's book says it is an open set. Am I going wrong somewhere in my argument? If so, where?","The complement of $\emptyset$ in $R^n$ is $R^n$ itself, which is an open set itself. So, $\emptyset$ should be a closed set, by definition of closed set. However, Tom M. Apostol's book says it is an open set. Am I going wrong somewhere in my argument? If so, where?",,['multivariable-calculus']
36,"Prove using $ \varepsilon-\delta $ that $ \lim_{(x,y)\to(1,1)} \frac {x^2+2xy-3y^2}{x^2-y^2} = 2 $",Prove using  that," \varepsilon-\delta   \lim_{(x,y)\to(1,1)} \frac {x^2+2xy-3y^2}{x^2-y^2} = 2 ","Prove limit using $ \varepsilon-\delta $ definition that: $$ \lim_{(x,y)\to(1,1)} \frac  {x^2+2xy-3y^2}{x^2-y^2} = 2 $$ I've been reading quite a lot about how to prove limits; so I want to show what I've done so far in this one, so you can tell me any suggestion (tricks) and even point out any mistake. What I've tried: I want to find $ \delta $ for every $ \varepsilon $ that verifies: $$ 0 < \left \| (x,y) - (1,1) \right \| < \delta \Rightarrow \left | \frac {x^2+2xy-3y^2}{x^2-y^2} - 2 \right | < \varepsilon $$ So here is my attempt: $$ \begin{align*} \left | \frac {x^2+2xy-3y^2}{x^2-y^2} - 2 \right | &\overset{(1)}{=} \left | \frac {y-x}{y+x} \right | \\   &\overset{(2)}{\leq} \frac {|x|+|y|}{|x+y|} \\   &\overset{(3)}{\leq} \frac {2\left \| (x,y)-(1,1) \right \|}{|x+y|} \\  &\overset{(4)}{\leq} 4\left \| (x,y)-(1,1) \right \| \\  & < \ 4 \delta \end{align*} $$ So I can take $ \delta = \varepsilon / 4 $. Is this right? Justifications: (1) Basic operations. (2) Triangle inequality. (3) I used $ |x| \leq \left \| (x,y)-(1,1) \right \| $. (4) I supposed $ |x| < 1/2 $ and also $ |y| < 1/2 $ then $ |x+y| < 1/2 $. (I don't understand why this step holds though). (5) The metric I'm using is: $ \left \| (x,y) \right \| = \sqrt{x^2 + y^2} $","Prove limit using $ \varepsilon-\delta $ definition that: $$ \lim_{(x,y)\to(1,1)} \frac  {x^2+2xy-3y^2}{x^2-y^2} = 2 $$ I've been reading quite a lot about how to prove limits; so I want to show what I've done so far in this one, so you can tell me any suggestion (tricks) and even point out any mistake. What I've tried: I want to find $ \delta $ for every $ \varepsilon $ that verifies: $$ 0 < \left \| (x,y) - (1,1) \right \| < \delta \Rightarrow \left | \frac {x^2+2xy-3y^2}{x^2-y^2} - 2 \right | < \varepsilon $$ So here is my attempt: $$ \begin{align*} \left | \frac {x^2+2xy-3y^2}{x^2-y^2} - 2 \right | &\overset{(1)}{=} \left | \frac {y-x}{y+x} \right | \\   &\overset{(2)}{\leq} \frac {|x|+|y|}{|x+y|} \\   &\overset{(3)}{\leq} \frac {2\left \| (x,y)-(1,1) \right \|}{|x+y|} \\  &\overset{(4)}{\leq} 4\left \| (x,y)-(1,1) \right \| \\  & < \ 4 \delta \end{align*} $$ So I can take $ \delta = \varepsilon / 4 $. Is this right? Justifications: (1) Basic operations. (2) Triangle inequality. (3) I used $ |x| \leq \left \| (x,y)-(1,1) \right \| $. (4) I supposed $ |x| < 1/2 $ and also $ |y| < 1/2 $ then $ |x+y| < 1/2 $. (I don't understand why this step holds though). (5) The metric I'm using is: $ \left \| (x,y) \right \| = \sqrt{x^2 + y^2} $",,"['limits', 'multivariable-calculus']"
37,Derivative of dot product?,Derivative of dot product?,,"What's the derivative ${\partial \over \partial x} \langle x, f(x)\rangle$? According to the product rule it should be $1\cdot f(x) + x \cdot f'(x) $ but in my previous post I was told that this makes no sense. Here $f: \mathbb R \to \mathbb R^2$ and $1$ is the constant one vector and $x \in \mathbb R^2$.","What's the derivative ${\partial \over \partial x} \langle x, f(x)\rangle$? According to the product rule it should be $1\cdot f(x) + x \cdot f'(x) $ but in my previous post I was told that this makes no sense. Here $f: \mathbb R \to \mathbb R^2$ and $1$ is the constant one vector and $x \in \mathbb R^2$.",,"['multivariable-calculus', 'derivatives']"
38,On Lagrange Multipliers,On Lagrange Multipliers,,"I only recently started studying the Lagrange Multipliers, and was given a task to create some challenging problems on them and also provide solutions. Could somebody please suggest how I could get started on this? Some example problems would be welcome! Thanks very much!","I only recently started studying the Lagrange Multipliers, and was given a task to create some challenging problems on them and also provide solutions. Could somebody please suggest how I could get started on this? Some example problems would be welcome! Thanks very much!",,"['calculus', 'multivariable-calculus', 'lagrange-multiplier']"
39,"Demand $z=x+y$ and $x^2/4 + y^2/5 + z^2/25 = 1$. What is the maximum value of $f(x,y,z) = x^2+y^2+z^2$?",Demand  and . What is the maximum value of ?,"z=x+y x^2/4 + y^2/5 + z^2/25 = 1 f(x,y,z) = x^2+y^2+z^2","Demand $z=x+y$ and $x^2/4 + y^2/5 + z^2/25 = 1$. What is the maximum value of $f(x,y,z) = x^2+y^2+z^2$? I've been attempting this with Lagrange multipliers in a few different ways. However, the resulting system of equations with two lagrangians has so many variables that it becomes very complicated. Can someone show how this is to be done manually? I also attempted turning it into two unknowns by replacing $z$ with $x+y$. However, this also led nowhere.","Demand $z=x+y$ and $x^2/4 + y^2/5 + z^2/25 = 1$. What is the maximum value of $f(x,y,z) = x^2+y^2+z^2$? I've been attempting this with Lagrange multipliers in a few different ways. However, the resulting system of equations with two lagrangians has so many variables that it becomes very complicated. Can someone show how this is to be done manually? I also attempted turning it into two unknowns by replacing $z$ with $x+y$. However, this also led nowhere.",,"['multivariable-calculus', 'optimization', 'lagrange-multiplier', 'maxima-minima', 'qcqp']"
40,Partial Derivatives and the Fundamental Theorem of Calculus,Partial Derivatives and the Fundamental Theorem of Calculus,,"I am being asked to evaluate the 1st-order partial derivatives $-$ $f_{x}$(x,y) and $f_{y}(x,y)$ $-$ of the following multi-variable function: $f(x,y) = \int_{y}^{x} cos(-1t^2 + 3t -1) dt$. Any help is appreciated.","I am being asked to evaluate the 1st-order partial derivatives $-$ $f_{x}$(x,y) and $f_{y}(x,y)$ $-$ of the following multi-variable function: $f(x,y) = \int_{y}^{x} cos(-1t^2 + 3t -1) dt$. Any help is appreciated.",,"['multivariable-calculus', 'partial-derivative']"
41,Why does Continuous Partial Differentiability Imply Total Differentiability?,Why does Continuous Partial Differentiability Imply Total Differentiability?,,"Let $f: \mathbb{R}^d \to \mathbb{R}$ be such that the partial derivatives $\frac{\partial f}{\partial x_i}:\mathbb{R}^d \to \mathbb{R}$ exist everywhere and are continuous. Then show that $f$ is totally differentiable everywhere, which in particular implies that the gradient is given by $\nabla f(x_0)= \left( \frac{\partial f}{\partial x_1}(x_0), \ldots, \frac{\partial f}{\partial x_d}(x_0) \right)$ and the directional derivatives are given by $D_vf(x_0) = v \cdot \nabla f(x_0)$. I am trying to understand why this result can be used to prove Rademacher's Differentiation Theorem since I have an upcoming presentation. As always, any advice would be greatly appreciated.","Let $f: \mathbb{R}^d \to \mathbb{R}$ be such that the partial derivatives $\frac{\partial f}{\partial x_i}:\mathbb{R}^d \to \mathbb{R}$ exist everywhere and are continuous. Then show that $f$ is totally differentiable everywhere, which in particular implies that the gradient is given by $\nabla f(x_0)= \left( \frac{\partial f}{\partial x_1}(x_0), \ldots, \frac{\partial f}{\partial x_d}(x_0) \right)$ and the directional derivatives are given by $D_vf(x_0) = v \cdot \nabla f(x_0)$. I am trying to understand why this result can be used to prove Rademacher's Differentiation Theorem since I have an upcoming presentation. As always, any advice would be greatly appreciated.",,"['measure-theory', 'multivariable-calculus', 'derivatives']"
42,"Geometric interpretation of the norm $\|\vec x\|={(|x_1|+|x_2|)\over 3}+{2\max(|x_1|,|x_2|)\over 3}$",Geometric interpretation of the norm,"\|\vec x\|={(|x_1|+|x_2|)\over 3}+{2\max(|x_1|,|x_2|)\over 3}","Let $p:\mathbb R^2 \to \mathbb R$ be a norm so that $$ \|\vec x\| ={(|x_1|+|x_2|)\over 3}+{2\max(|x_1|,|x_2|)\over 3} ={{\|\vec x\|_1\over 3}}+{2\|\vec x\|_\infty\over 3}. $$ I need to graph the neighbourhood of radius $1$ around $(0,0)$ : $V_1 ((0,0))$ with this norm, but I don't even know the points that are in this neighbourhood I really don't know how to geometrically visualize it . I tried to separate the norm in to parts: I want that to find all $(x_1, x_2) \in \mathbb{R}^2$ that satisfy $$ {(|x_{1}|+|x_{2}|)\over 3}+{2\max(|x_1|,|x_2|)\over 3} < 1 $$ so: $$ \frac{|x_1|+|x_2|}{3} < \frac{1}{2} \qquad \text{and} \qquad \frac{2\max(|x_1|,|x_2|)}{3} < {1\over 2}. $$ I know that the first inequality is a rotated square (geometrically) and the second one is a square, but from this point I don't see how to find the points that satisfy the given norm and visualize it geometrically.","Let be a norm so that I need to graph the neighbourhood of radius around : with this norm, but I don't even know the points that are in this neighbourhood I really don't know how to geometrically visualize it . I tried to separate the norm in to parts: I want that to find all that satisfy so: I know that the first inequality is a rotated square (geometrically) and the second one is a square, but from this point I don't see how to find the points that satisfy the given norm and visualize it geometrically.","p:\mathbb R^2 \to \mathbb R 
\|\vec x\|
={(|x_1|+|x_2|)\over 3}+{2\max(|x_1|,|x_2|)\over 3}
={{\|\vec x\|_1\over 3}}+{2\|\vec x\|_\infty\over 3}.
 1 (0,0) V_1 ((0,0)) (x_1, x_2) \in \mathbb{R}^2 
{(|x_{1}|+|x_{2}|)\over 3}+{2\max(|x_1|,|x_2|)\over 3}
< 1
 
\frac{|x_1|+|x_2|}{3}
< \frac{1}{2}
\qquad \text{and} \qquad
\frac{2\max(|x_1|,|x_2|)}{3} < {1\over 2}.
","['real-analysis', 'multivariable-calculus', 'normed-spaces']"
43,Continuity conditions for multivariate functions.,Continuity conditions for multivariate functions.,,"Is the following true ? A proof or counter-example or reference would be nice. A function $f:\mathbb{R}^2 \rightarrow \mathbb{R}$ is continous at $(0,0)$ if and only if if for all $a, b$, the limits $$\lim\limits_{t \to 0} f(at,bt)$$ exist are all are equal. Can the condition of approach in all directions be weakened to the equallty of approach along two distinct lines ?  One direction is of course trivial. I think it is implicitly assumed that $f$ is continuous on $\mathbb{R}^2-\{(0,0)\}$","Is the following true ? A proof or counter-example or reference would be nice. A function $f:\mathbb{R}^2 \rightarrow \mathbb{R}$ is continous at $(0,0)$ if and only if if for all $a, b$, the limits $$\lim\limits_{t \to 0} f(at,bt)$$ exist are all are equal. Can the condition of approach in all directions be weakened to the equallty of approach along two distinct lines ?  One direction is of course trivial. I think it is implicitly assumed that $f$ is continuous on $\mathbb{R}^2-\{(0,0)\}$",,"['real-analysis', 'multivariable-calculus', 'examples-counterexamples']"
44,How can ${\iint\limits_{D}{{e^{x^2+y^2}}}}dxdy$ be found?,How can  be found?,{\iint\limits_{D}{{e^{x^2+y^2}}}}dxdy,"How can  ${\iint\limits_{D}{{e^{x^2+y^2}}}}dxdy $  be found, if $D$ is $x$ O $y$ axis? So far I have done it this far: $$\iint\limits_D{e^{x^2+y^2}}dxdy=\int_{-\infty}^{\infty}dx\int_{-\infty}^{\infty}e^{x^2+y^2}dy=\int_{-\infty}^{\infty}dx\lim_{b\to\infty}\int_{-b}^{b}e^{x^2+y^2}dy=\cdots$$ And then I am stuck there as $e^{x^2+y^2}$, appears to have no integral in terms of elementary functions. How do I approach this problem? EDIT: In my country $x$ O $y$ is used equivalently to $\Bbb{R}^{2}$. The rest of integral and functions is as they should be $e^{x^2+y^2}$.","How can  ${\iint\limits_{D}{{e^{x^2+y^2}}}}dxdy $  be found, if $D$ is $x$ O $y$ axis? So far I have done it this far: $$\iint\limits_D{e^{x^2+y^2}}dxdy=\int_{-\infty}^{\infty}dx\int_{-\infty}^{\infty}e^{x^2+y^2}dy=\int_{-\infty}^{\infty}dx\lim_{b\to\infty}\int_{-b}^{b}e^{x^2+y^2}dy=\cdots$$ And then I am stuck there as $e^{x^2+y^2}$, appears to have no integral in terms of elementary functions. How do I approach this problem? EDIT: In my country $x$ O $y$ is used equivalently to $\Bbb{R}^{2}$. The rest of integral and functions is as they should be $e^{x^2+y^2}$.",,"['calculus', 'integration', 'multivariable-calculus', 'definite-integrals', 'improper-integrals']"
45,A generalization of the mean value theorem?,A generalization of the mean value theorem?,,"Let $U \subset \mathbb{R}^d$ be open and path-connected. Let $f: U \to \mathbb{R}^m $ be differentiable on $U$ and suppose there exists a real $M$ such that $|| D_f(x) || \leq M $ for all $x \in U$. then, $$ \|f(b) - f(a) \| \leq M\|b-a\|.$$ for all $a,b \in U$. Is this result true. Can someone show me how to prove it? thanks","Let $U \subset \mathbb{R}^d$ be open and path-connected. Let $f: U \to \mathbb{R}^m $ be differentiable on $U$ and suppose there exists a real $M$ such that $|| D_f(x) || \leq M $ for all $x \in U$. then, $$ \|f(b) - f(a) \| \leq M\|b-a\|.$$ for all $a,b \in U$. Is this result true. Can someone show me how to prove it? thanks",,"['calculus', 'real-analysis']"
46,Optimization with a few Variables (AMC 12 question),Optimization with a few Variables (AMC 12 question),,"In the 2013 AMC 12B, question 17 says: Let $a$,$b$, and $c$ be real numbers such that $a+b+c=2$, and $a^2+b^2+c^2=12$ What is the difference between the maximum and minimum possible values of $c$? I was wondering if there is a quick and easy solution using multivariable calculus for this problem. (I've only taken single variable) The only solution I've seen uses the Cauchy-Schwarz inequality.","In the 2013 AMC 12B, question 17 says: Let $a$,$b$, and $c$ be real numbers such that $a+b+c=2$, and $a^2+b^2+c^2=12$ What is the difference between the maximum and minimum possible values of $c$? I was wondering if there is a quick and easy solution using multivariable calculus for this problem. (I've only taken single variable) The only solution I've seen uses the Cauchy-Schwarz inequality.",,"['multivariable-calculus', 'optimization']"
47,Geometric interpretation of derivative of a function of more than one variable,Geometric interpretation of derivative of a function of more than one variable,,"A function $f$ is defined on an open set $D$ of $\mathbb R^{2}$ is called a differentiable at a point $x\in D$ if there is a vector $m \in \mathbb R^{2} $ such that $$\lim_{h\to 0} \frac{f(x+h)-f(x)-m\cdot h}{|h|}=0.$$ My questions are : (1) What is a geometric  interpretation of $f:\mathbb R^{2} \to \mathbb R$ is a differentiable at a point in $D$ ? ( Let $f:\mathbb R^{2} \to \mathbb R $such that  $f(x, y)= \frac{x^{3}y}{x^{4}+y^{2}}$ for $(x,y)\not = (0,0)$ and $f(0,0)= 0$. Notice that all the directional derivatives of $f$ exists at $(0, 0)$  and they are equal at $(0, 0)$ but although $f$ is fails to be differentiable at $(0,0)$. ) (2) What is a geometric interpretation of $f:D\subset \mathbb R^{n}\to \mathbb R^{m}$ is differentiable at point in $D$ ?","A function $f$ is defined on an open set $D$ of $\mathbb R^{2}$ is called a differentiable at a point $x\in D$ if there is a vector $m \in \mathbb R^{2} $ such that $$\lim_{h\to 0} \frac{f(x+h)-f(x)-m\cdot h}{|h|}=0.$$ My questions are : (1) What is a geometric  interpretation of $f:\mathbb R^{2} \to \mathbb R$ is a differentiable at a point in $D$ ? ( Let $f:\mathbb R^{2} \to \mathbb R $such that  $f(x, y)= \frac{x^{3}y}{x^{4}+y^{2}}$ for $(x,y)\not = (0,0)$ and $f(0,0)= 0$. Notice that all the directional derivatives of $f$ exists at $(0, 0)$  and they are equal at $(0, 0)$ but although $f$ is fails to be differentiable at $(0,0)$. ) (2) What is a geometric interpretation of $f:D\subset \mathbb R^{n}\to \mathbb R^{m}$ is differentiable at point in $D$ ?",,"['real-analysis', 'multivariable-calculus', 'differential-geometry']"
48,Use implicit differentiation to find dy/dx,Use implicit differentiation to find dy/dx,,"$xy+x=2$ I know the answer is $-(1+y)\over x$, but I don't know how to solve to get the answer. Thank you!","$xy+x=2$ I know the answer is $-(1+y)\over x$, but I don't know how to solve to get the answer. Thank you!",,"['calculus', 'multivariable-calculus', 'implicit-differentiation']"
49,Implicit differentiation,Implicit differentiation,,"I want to differentiate $x^2 + y^2=1$ with respect to $x$. The answer is $2x +2yy' = 0$. Can some explain what is implicit differentiation and from where did $y'$ appear ? I can understand that $2x +2yy' = 0$ is a partial derivative but then it becomes multi calc not single. This is in a chapter about chain rule so I assume there is some use of the chain rule here but I can't see any composite functions here. We can express y in terms of x but y is not composite. P.S: I am NOT looking for HOW to solve the problem, I am looking for the WHY as stated above.","I want to differentiate $x^2 + y^2=1$ with respect to $x$. The answer is $2x +2yy' = 0$. Can some explain what is implicit differentiation and from where did $y'$ appear ? I can understand that $2x +2yy' = 0$ is a partial derivative but then it becomes multi calc not single. This is in a chapter about chain rule so I assume there is some use of the chain rule here but I can't see any composite functions here. We can express y in terms of x but y is not composite. P.S: I am NOT looking for HOW to solve the problem, I am looking for the WHY as stated above.",,"['calculus', 'limits', 'multivariable-calculus', 'implicit-differentiation']"
50,How can one show that $ f(0)\ln(\frac{b}{a})=\lim_{\epsilon\rightarrow 0}\int_{\epsilon a}^{\epsilon b} \frac{f(x)}{x}dx$?,How can one show that ?, f(0)\ln(\frac{b}{a})=\lim_{\epsilon\rightarrow 0}\int_{\epsilon a}^{\epsilon b} \frac{f(x)}{x}dx,"Let $f:[0, 1] \rightarrow \mathbb{R}$ a continuous function. If $a>0$, show that: $$ f(0)\ln(\frac{b}{a})=\lim_{\epsilon\rightarrow 0}\int_{\epsilon a}^{\epsilon b} \frac{f(x)}{x}dx$$ Tried using Riemann sum, but did not succeed.","Let $f:[0, 1] \rightarrow \mathbb{R}$ a continuous function. If $a>0$, show that: $$ f(0)\ln(\frac{b}{a})=\lim_{\epsilon\rightarrow 0}\int_{\epsilon a}^{\epsilon b} \frac{f(x)}{x}dx$$ Tried using Riemann sum, but did not succeed.",,"['integration', 'limits', 'multivariable-calculus']"
51,Is there a need for another integration technique?,Is there a need for another integration technique?,,"I'm being asked to calculate $$I\triangleq\int_0^1\int_{e^{\large x}}^e{xe^y\over(\ln y)^2}\,dy\,dx\quad.$$ I got stuck on the indefinite inner one, $$J\triangleq\int{e^ydy\over(\ln y)^2}\quad.$$ At first, I tried substitution with $u=e^y$, $u=\ln y$ and $u=(\ln y)^2$, none of them useful. Then I looked up Wolfram Alpha and it says $J$ can't be written in terms of elementary functions. I assume there's an analytical way to find $I$ without $J$, otherwise the answer is what Wolfram said and the estimate from the Double Integral Calculator that $I\approx6.21799$.","I'm being asked to calculate $$I\triangleq\int_0^1\int_{e^{\large x}}^e{xe^y\over(\ln y)^2}\,dy\,dx\quad.$$ I got stuck on the indefinite inner one, $$J\triangleq\int{e^ydy\over(\ln y)^2}\quad.$$ At first, I tried substitution with $u=e^y$, $u=\ln y$ and $u=(\ln y)^2$, none of them useful. Then I looked up Wolfram Alpha and it says $J$ can't be written in terms of elementary functions. I assume there's an analytical way to find $I$ without $J$, otherwise the answer is what Wolfram said and the estimate from the Double Integral Calculator that $I\approx6.21799$.",,"['integration', 'multivariable-calculus']"
52,How would I use linear approximation to estimate $\sqrt{3.90^2 + 3.02^2}$?,How would I use linear approximation to estimate ?,\sqrt{3.90^2 + 3.02^2},I want to use the linear approximation to estimate $\sqrt{3.90^2 + 3.02^2}$ but I am stuck. Would I first replace the numbers with $x$ and $y$ respectively then get the partial differentiation for $x$ and $y$? I would appreciate any help. Thanks.,I want to use the linear approximation to estimate $\sqrt{3.90^2 + 3.02^2}$ but I am stuck. Would I first replace the numbers with $x$ and $y$ respectively then get the partial differentiation for $x$ and $y$? I would appreciate any help. Thanks.,,"['calculus', 'multivariable-calculus']"
53,"Does $\lim_{(x,y) \to (0,0)} \frac{x^4+y^4}{x^3+y^3}$ exist?",Does  exist?,"\lim_{(x,y) \to (0,0)} \frac{x^4+y^4}{x^3+y^3}","Does the following limit exist?   $$ \lim_{(x,y) \to (0,0)} \frac{x^4+y^4}{x^3+y^3}$$ I am not looking for any work, just a quick yes or no answer. I have already done the work on this problem and I just want to know if I my answer is consistent with a general consensus.","Does the following limit exist?   $$ \lim_{(x,y) \to (0,0)} \frac{x^4+y^4}{x^3+y^3}$$ I am not looking for any work, just a quick yes or no answer. I have already done the work on this problem and I just want to know if I my answer is consistent with a general consensus.",,"['limits', 'multivariable-calculus']"
54,Partial derivative involving trace of a matrix,Partial derivative involving trace of a matrix,,"Suppose that I have a symmetric Toeplitz $n\times n$ matrix $$\mathbf{A}=\left[\begin{array}{cccc}a_1&a_2&\cdots& a_n\\a_2&a_1&\cdots&a_{n-1}\\\vdots&\vdots&\ddots&\vdots\\a_n&a_{n-1}&\cdots&a_1\end{array}\right]$$ where $a_i \geq 0$ , and a diagonal matrix $$\mathbf{B}=\left[\begin{array}{cccc}b_1&0&\cdots& 0\\0&b_2&\cdots&0\\\vdots&\vdots&\ddots&\vdots\\0&0&\cdots&b_n\end{array}\right]$$ where $b_i = \frac{c}{\beta_i}$ for some constant $c>0$ such that $\beta_i>0$ . Let $$\mathbf{M}=\mathbf{A}(\mathbf{A}+\mathbf{B})^{-1}\mathbf{A}$$ Can one express a partial derivative $\partial_{\beta_i} \operatorname{Tr}[\mathbf{M}]$ in closed form, where $\operatorname{Tr}[\mathbf{M}]$ is the trace operator?","Suppose that I have a symmetric Toeplitz matrix where , and a diagonal matrix where for some constant such that . Let Can one express a partial derivative in closed form, where is the trace operator?",n\times n \mathbf{A}=\left[\begin{array}{cccc}a_1&a_2&\cdots& a_n\\a_2&a_1&\cdots&a_{n-1}\\\vdots&\vdots&\ddots&\vdots\\a_n&a_{n-1}&\cdots&a_1\end{array}\right] a_i \geq 0 \mathbf{B}=\left[\begin{array}{cccc}b_1&0&\cdots& 0\\0&b_2&\cdots&0\\\vdots&\vdots&\ddots&\vdots\\0&0&\cdots&b_n\end{array}\right] b_i = \frac{c}{\beta_i} c>0 \beta_i>0 \mathbf{M}=\mathbf{A}(\mathbf{A}+\mathbf{B})^{-1}\mathbf{A} \partial_{\beta_i} \operatorname{Tr}[\mathbf{M}] \operatorname{Tr}[\mathbf{M}],"['matrices', 'multivariable-calculus', 'partial-derivative', 'trace', 'scalar-fields']"
55,finding unknown variable in Gaussian Integral,finding unknown variable in Gaussian Integral,,"Given values of d, p and $\sigma$, is it possible to calculate the value of $\mu$? $$1-\frac{1}{2\pi\sigma^2}\int_{-\infty}^{\infty}\int_{y-d}^{y+d}\exp\big(-{x^2}/{2\sigma^2}\big) \exp\big(-{(y-\mu)^2}/{2\sigma^2}\big) \,\mathrm{d}x\,\mathrm{d}y < p$$","Given values of d, p and $\sigma$, is it possible to calculate the value of $\mu$? $$1-\frac{1}{2\pi\sigma^2}\int_{-\infty}^{\infty}\int_{y-d}^{y+d}\exp\big(-{x^2}/{2\sigma^2}\big) \exp\big(-{(y-\mu)^2}/{2\sigma^2}\big) \,\mathrm{d}x\,\mathrm{d}y < p$$",,"['integration', 'multivariable-calculus', 'inequality', 'normal-distribution']"
56,"If $B$ is compact, then $\{x\}\times B$ is compact","If  is compact, then  is compact",B \{x\}\times B,"In Spivak's Calculus on Manifolds , he writes on page 8: If $B\subset\mathbb R^m$ is compact, and $x\in\mathbb R^n$ , then it is easy to see that $\{x\}\times B\subset\mathbb R^{n+m}$ is compact. Here, $\{x\}\times B$ is defined as $\{(x^1,\dots,x^n,b^1,\dots,b^m):(b^1,\dots,b^m)\in B\}$ . Spivak uses the above fact to prove that the product of two compact sets is compact, and so we are not allowed use this more general statement to conclude the above. Despite Spivak's assertion that this is ""easy to see"", I don't think the proof is completely trivial (or at least it is not short). Is my attempt correct? The basic idea is that if $\{A_i\}_{i\in I}$ is an open cover of $\{x\}\times B$ , then for each collection $A_i$ of open sets of $\mathbb R^{n+m}$ , we can find a corresponding collection $\alpha_i$ of open sets of $\mathbb R^m$ ; from there, we can use the compactness of $B$ to find a finite subcover of $\{A_i\}_{i\in I}$ . In more detail, suppose $\{A_i\}_{i\in I}$ is an open cover of $\{x\}\times B$ . For each $A_i\subset \mathbb R^{n+m}$ , define $\alpha_i\subset\mathbb R^m$ so that $(y^1,\dots,y^m)\in\alpha_i$ if and only if $(x^1,\dots,x^n,y^1\dots,y^m)\in A_i$ . We claim that $\{\alpha_i\}_{i\in I}$ is an open cover of $B$ . Indeed, if $(b^1,\dots,b^m)\in B$ , then $(x^1,\dots,x^n,b^1,\dots,b^m)\in\{x\}\times B$ , and so there is an $i\in I$ such that $(x^1,\dots,x^n,b^1,\dots,b^m)\in A_i$ , hence $(b^1,\dots,b^m)\in\alpha_i$ ; this shows that $\{\alpha_i\}_{i\in I}$ is a cover of $B$ . To prove that it is an open cover, note that if $i\in I$ and $(y^1,\dots,y^m)\in \alpha_i$ , then $(x^1,\dots,x^n,y_1,\dots,y^m)\in A_i$ . Since $A_i$ is open, there is a $\delta>0$ such that $$ (x^1-\delta,x^1+\delta)\times\dots\times(x^n-\delta,x^n+\delta)\times(y^1-\delta,y^1+\delta)\times\dots\times(y^m-\delta,y^m+\delta)\subset A_i \, . $$ Hence, $$ (y^1-\delta,y^1+\delta)\times\dots\times(y^m-\delta,y^m+\delta)\subset\alpha_i \, , $$ and $\alpha_i$ is open. Since $\{\alpha_i\}_{i\in I}$ is an open cover of $B$ , it has a finite subcover $\{\alpha_i\}_{i\in I'}$ . Then, $\{A_i\}_{i\in I'}$ is a finite subcover of $\{A_i\}_{i\in I}$ , for if $(x^1,\dots,x^n,b^1,\dots,b^m)\in\{x\}\times B$ , then $(b^1,\dots,b^m)\in B$ , so there is an $i\in I'$ such that $(b^1,\dots,b^m)\in\alpha_i$ , and consequently $(x^1,\dots,x^n,b^1,\dots,b^m)\in A_i$ . This completes the proof.","In Spivak's Calculus on Manifolds , he writes on page 8: If is compact, and , then it is easy to see that is compact. Here, is defined as . Spivak uses the above fact to prove that the product of two compact sets is compact, and so we are not allowed use this more general statement to conclude the above. Despite Spivak's assertion that this is ""easy to see"", I don't think the proof is completely trivial (or at least it is not short). Is my attempt correct? The basic idea is that if is an open cover of , then for each collection of open sets of , we can find a corresponding collection of open sets of ; from there, we can use the compactness of to find a finite subcover of . In more detail, suppose is an open cover of . For each , define so that if and only if . We claim that is an open cover of . Indeed, if , then , and so there is an such that , hence ; this shows that is a cover of . To prove that it is an open cover, note that if and , then . Since is open, there is a such that Hence, and is open. Since is an open cover of , it has a finite subcover . Then, is a finite subcover of , for if , then , so there is an such that , and consequently . This completes the proof.","B\subset\mathbb R^m x\in\mathbb R^n \{x\}\times B\subset\mathbb R^{n+m} \{x\}\times B \{(x^1,\dots,x^n,b^1,\dots,b^m):(b^1,\dots,b^m)\in B\} \{A_i\}_{i\in I} \{x\}\times B A_i \mathbb R^{n+m} \alpha_i \mathbb R^m B \{A_i\}_{i\in I} \{A_i\}_{i\in I} \{x\}\times B A_i\subset \mathbb R^{n+m} \alpha_i\subset\mathbb R^m (y^1,\dots,y^m)\in\alpha_i (x^1,\dots,x^n,y^1\dots,y^m)\in A_i \{\alpha_i\}_{i\in I} B (b^1,\dots,b^m)\in B (x^1,\dots,x^n,b^1,\dots,b^m)\in\{x\}\times B i\in I (x^1,\dots,x^n,b^1,\dots,b^m)\in A_i (b^1,\dots,b^m)\in\alpha_i \{\alpha_i\}_{i\in I} B i\in I (y^1,\dots,y^m)\in \alpha_i (x^1,\dots,x^n,y_1,\dots,y^m)\in A_i A_i \delta>0 
(x^1-\delta,x^1+\delta)\times\dots\times(x^n-\delta,x^n+\delta)\times(y^1-\delta,y^1+\delta)\times\dots\times(y^m-\delta,y^m+\delta)\subset A_i \, .
 
(y^1-\delta,y^1+\delta)\times\dots\times(y^m-\delta,y^m+\delta)\subset\alpha_i \, ,
 \alpha_i \{\alpha_i\}_{i\in I} B \{\alpha_i\}_{i\in I'} \{A_i\}_{i\in I'} \{A_i\}_{i\in I} (x^1,\dots,x^n,b^1,\dots,b^m)\in\{x\}\times B (b^1,\dots,b^m)\in B i\in I' (b^1,\dots,b^m)\in\alpha_i (x^1,\dots,x^n,b^1,\dots,b^m)\in A_i","['real-analysis', 'general-topology', 'multivariable-calculus', 'solution-verification', 'compactness']"
57,Lagrange Multipliers Question - some extremum points are missed (not detected) by the method,Lagrange Multipliers Question - some extremum points are missed (not detected) by the method,,"I was reading about Lagrange multipliers. My book says that if $f(x,y,z)$ has in the point $(x_0, y_0, z_0)$ an extremum under the condition that $g(x,y,z) = k$ , and if $\nabla g \ne (0,0,0)$ , then there exists a number $\lambda$ such that $$\nabla f (x_0, y_0, z_0) = \lambda \nabla g (x_0, y_0, z_0) \tag{1}$$ and $$g(x_0, y_0, z_0) = k \tag{2}$$ But then I was working through this simple example. Find the extremums of $f(x,y,z) = xyz$ under the condition $g(x,y,z) = x+y+z = 1$ where $x,y,z \ge 0$ I noticed that here the Lagrange method (i.e. solving the system $(1), (2)$ ) misses to detect/find the  extremum points $P (x,y,z)$ , such that e.g. $x = 0$ and $y+z = 1$ and $y,z$ are positive. It only detects/finds the four points $(1/3, 1/3, 1/3), (0,0,1), (0,1,0), (0,0,1)$ . So what am I missing here? I guess in my book the theorem is stated somewhat informally, and that's why the Lagrange method is missing to detect these points. So why are these points $P$ missed? I mean, they are obviously extremum (minimum) points of $f$ but they do not satisfy the system $(1), (2)$ for any $\lambda$ .","I was reading about Lagrange multipliers. My book says that if has in the point an extremum under the condition that , and if , then there exists a number such that and But then I was working through this simple example. Find the extremums of under the condition where I noticed that here the Lagrange method (i.e. solving the system ) misses to detect/find the  extremum points , such that e.g. and and are positive. It only detects/finds the four points . So what am I missing here? I guess in my book the theorem is stated somewhat informally, and that's why the Lagrange method is missing to detect these points. So why are these points missed? I mean, they are obviously extremum (minimum) points of but they do not satisfy the system for any .","f(x,y,z) (x_0, y_0, z_0) g(x,y,z) = k \nabla g \ne (0,0,0) \lambda \nabla f (x_0, y_0, z_0) = \lambda \nabla g (x_0, y_0, z_0) \tag{1} g(x_0, y_0, z_0) = k \tag{2} f(x,y,z) = xyz g(x,y,z) = x+y+z = 1 x,y,z \ge 0 (1), (2) P (x,y,z) x = 0 y+z = 1 y,z (1/3, 1/3, 1/3), (0,0,1), (0,1,0), (0,0,1) P f (1), (2) \lambda","['calculus', 'multivariable-calculus', 'lagrange-multiplier']"
58,How to prove that this function $(x^2 + y^2) \exp{(\frac{xy}{x^2+y^2})}$ has limit?,How to prove that this function  has limit?,(x^2 + y^2) \exp{(\frac{xy}{x^2+y^2})},"I have this multivariable function, and I need to prove that limit does exist and it's equal to zero. $$(x^2 + y^2) \exp{\left(\frac{xy}{x^2+y^2}\right)}$$ for $(x, y) \rightarrow (0, 0)$ I've tried using polar coordinates method, and  I've got: $$\rho^2\exp{\frac{1}{\rho}}$$ then I write this inequality showing that: $$\left|(x^2 + y^2) \exp{\left(\frac{xy}{x^2+y^2}\right)}\right| \leq \left|\frac{1}{\rho}\right|$$ but the right hand side diverges as $\rho \to 0$ , and therefore i can't tell nothing about the left hand side. I've tried using the restriction method, I've chosen: $(mx^n, 0)$ and I've obtained, $$m^2x^2x^n * \exp{\frac{0}{m^2x^2x^n}} = 0$$ but I can't say if the limit does exist, because restriction method tells me if the limit doesn't exist. how can I do it? EDIT (solved): there was an error in the polar coordinates substitution, there isn't $\frac{1}{\rho}$ , instead I should've written $\rho^2*\exp{\left(\frac{\rho^2*(\cos * \sin)}{\rho^2}\right)}$ and the rest is straightforward, I've obtained $\rho^2*e$ which is the right hand side of the inequality, and it converges as expected.","I have this multivariable function, and I need to prove that limit does exist and it's equal to zero. for I've tried using polar coordinates method, and  I've got: then I write this inequality showing that: but the right hand side diverges as , and therefore i can't tell nothing about the left hand side. I've tried using the restriction method, I've chosen: and I've obtained, but I can't say if the limit does exist, because restriction method tells me if the limit doesn't exist. how can I do it? EDIT (solved): there was an error in the polar coordinates substitution, there isn't , instead I should've written and the rest is straightforward, I've obtained which is the right hand side of the inequality, and it converges as expected.","(x^2 + y^2) \exp{\left(\frac{xy}{x^2+y^2}\right)} (x, y) \rightarrow (0, 0) \rho^2\exp{\frac{1}{\rho}} \left|(x^2 + y^2) \exp{\left(\frac{xy}{x^2+y^2}\right)}\right| \leq \left|\frac{1}{\rho}\right| \rho \to 0 (mx^n, 0) m^2x^2x^n * \exp{\frac{0}{m^2x^2x^n}} = 0 \frac{1}{\rho} \rho^2*\exp{\left(\frac{\rho^2*(\cos * \sin)}{\rho^2}\right)} \rho^2*e","['limits', 'multivariable-calculus']"
59,High-precision second-order difference quotient of 2 variables functions,High-precision second-order difference quotient of 2 variables functions,,"For one variable function, 2th order difference quotient can be: $$  \frac{f(x+h) - 2f(x) + f(x-h)}{h^2},  $$ which can also be: $$ \frac{-f(x-2h) + 16f(x-h) - 30f(x) + 16f(x+h) - f(x+2h)}{12h^2} $$ with a higher precision. For two variables function, difference quotient of $\displaystyle \smash[t]{\frac{\partial^2 f}{\partial x \, \partial y}}$ can be: $$ \frac{f(x+h,y+h) - f(x+h,y-h) - f(x-h,y-h) + f(x-h,y+h)}{4h^2}. $$ Is there some other form of this difference quotient with a higher precision?","For one variable function, 2th order difference quotient can be: which can also be: with a higher precision. For two variables function, difference quotient of can be: Is there some other form of this difference quotient with a higher precision?"," 
\frac{f(x+h) - 2f(x) + f(x-h)}{h^2}, 
 
\frac{-f(x-2h) + 16f(x-h) - 30f(x) + 16f(x+h) - f(x+2h)}{12h^2}
 \displaystyle \smash[t]{\frac{\partial^2 f}{\partial x \, \partial y}} 
\frac{f(x+h,y+h) - f(x+h,y-h) - f(x-h,y-h) + f(x-h,y+h)}{4h^2}.
","['calculus', 'multivariable-calculus', 'derivatives', 'numerical-methods', 'finite-differences']"
60,Proving that local extremum is a critical point.,Proving that local extremum is a critical point.,,"The theorem says "" If the function $f:\Bbb{R}^n→\Bbb{R}$ has a local extremum at $α∈\Bbb{R}^n$ , then $α$ is a critical point "". For $n=1$ , its quite simple by using the definition that WLOG assuming $f$ has local maximum at $x=\alpha$ , $f(x)\le f(\alpha)$ whenever $|x-\alpha|<\delta$ . So we can say that $\dfrac{f(\alpha+h)-f(\alpha)}{h}\le 0$ for all $0<h<\delta$ and from this, it can be shown that $f'(\alpha)\le0$ and similarly considering $-\delta<h<0$ , we get $f'(\alpha)\ge0$ and from this we can conclude that $f'(\alpha)=0$ which completes the theorem. But how do I choose the neighbourhood when it comes to $n>1$ ? I can anticipate that $|x-\alpha|<\delta$ will be changed to $||x-\alpha||<\delta$ but it is also true that $\dfrac{df(\alpha)}{dx}$ will not suit in that case to the definition of critical point.","The theorem says "" If the function has a local extremum at , then is a critical point "". For , its quite simple by using the definition that WLOG assuming has local maximum at , whenever . So we can say that for all and from this, it can be shown that and similarly considering , we get and from this we can conclude that which completes the theorem. But how do I choose the neighbourhood when it comes to ? I can anticipate that will be changed to but it is also true that will not suit in that case to the definition of critical point.",f:\Bbb{R}^n→\Bbb{R} α∈\Bbb{R}^n α n=1 f x=\alpha f(x)\le f(\alpha) |x-\alpha|<\delta \dfrac{f(\alpha+h)-f(\alpha)}{h}\le 0 0<h<\delta f'(\alpha)\le0 -\delta<h<0 f'(\alpha)\ge0 f'(\alpha)=0 n>1 |x-\alpha|<\delta ||x-\alpha||<\delta \dfrac{df(\alpha)}{dx},['multivariable-calculus']
61,Do continuous conservative vector fields on $\mathbb{R}^3$ form a semigroup under composition?,Do continuous conservative vector fields on  form a semigroup under composition?,\mathbb{R}^3,"Let $\mathcal{F}$ denote the set of conservative vector fields on $\mathbb{R}^3$ that are continuous.  That is $$ \mathcal{F}=\{F:\mathbb{R}^3 \rightarrow \mathbb{R}^3: F \text{ is continuous and } F=\nabla \phi \text{ for some } \phi \in C^1(\mathbb{R}^3) \}.$$ Is $\mathcal{F} $ closed under composition? I suspect it is not since no property like this is mentioned when one studies conservative vector fields (and we do love algebraic structures which appear naturally in analysis, so certainly if this were a semigroup someone would have made mention of it). Does anyone have a nice example of $F\in\mathcal{F}$ and $G\in\mathcal{F}$ , such that $F\circ G \notin\mathcal{F}$ ?","Let denote the set of conservative vector fields on that are continuous.  That is Is closed under composition? I suspect it is not since no property like this is mentioned when one studies conservative vector fields (and we do love algebraic structures which appear naturally in analysis, so certainly if this were a semigroup someone would have made mention of it). Does anyone have a nice example of and , such that ?",\mathcal{F} \mathbb{R}^3  \mathcal{F}=\{F:\mathbb{R}^3 \rightarrow \mathbb{R}^3: F \text{ is continuous and } F=\nabla \phi \text{ for some } \phi \in C^1(\mathbb{R}^3) \}. \mathcal{F}  F\in\mathcal{F} G\in\mathcal{F} F\circ G \notin\mathcal{F},"['abstract-algebra', 'multivariable-calculus', 'vector-fields', 'semigroups']"
62,Jacobian for Conversion Between Polar and Cartesian Resembles a Rotation Matrix,Jacobian for Conversion Between Polar and Cartesian Resembles a Rotation Matrix,,"In matrix form, supposing $z=f(x,y)$ where x,y represent the cartesian coordinate system, one can write the chain rule: $ \begin{bmatrix} z_x \\ z_y  \end{bmatrix} = \begin{bmatrix} r_x & \theta_x \\ r_y & \theta_y  \end{bmatrix}     \begin{bmatrix} z_r \\ z_\theta  \end{bmatrix}$ Which turns out to be $ \begin{bmatrix} z_x \\ z_y  \end{bmatrix} =  \begin{bmatrix} \cos\theta & -\frac{\sin\theta}{r} \\ \sin\theta & \frac{\cos\theta}{r}  \end{bmatrix}    \begin{bmatrix} z_r \\ z_\theta  \end{bmatrix}$ Why does this middle matrix resemble a rotation and a scaling by 1/r so much?","In matrix form, supposing where x,y represent the cartesian coordinate system, one can write the chain rule: Which turns out to be Why does this middle matrix resemble a rotation and a scaling by 1/r so much?","z=f(x,y)  \begin{bmatrix}
z_x \\
z_y 
\end{bmatrix} = \begin{bmatrix}
r_x & \theta_x \\
r_y & \theta_y 
\end{bmatrix}   
 \begin{bmatrix}
z_r \\
z_\theta 
\end{bmatrix}  \begin{bmatrix}
z_x \\
z_y 
\end{bmatrix} =  \begin{bmatrix}
\cos\theta & -\frac{\sin\theta}{r} \\
\sin\theta & \frac{\cos\theta}{r} 
\end{bmatrix}  
 \begin{bmatrix}
z_r \\
z_\theta 
\end{bmatrix}","['linear-algebra', 'matrices', 'multivariable-calculus']"
63,Finding the volume with triple integrals,Finding the volume with triple integrals,,"I want to find the volume of a function described by: $$ G= \{(x,y,z)|\sqrt{x^2+y^2} \le z \le 1, (x-1)^2+y^2 \le 1\}$$ This question can be best solved in cylindrical coordinates. So if I follow that process, I get the following limits: $$ r \le z \le 1$$ $$ 0 \le r \le 2\cos(\theta)$$ $$ -\frac{\pi}{2} \le \theta \le \frac{\pi}{2}$$ I am fairly certain that these limits are correct. So continuing, to find the volume of G: $$\begin{align} \iiint r \ dz\ dr\ d\theta &= \int^{\frac{\pi}{2}}_{-\frac{\pi}{2}} \int^{2\cos(\theta)}_{0} \int^{1}_{r} r \ dz \ dr \ d\theta\\ &= \int^{\frac{\pi}{2}}_{-\frac{\pi}{2}} \int^{2\cos(\theta)}_{0} r-r^2  \ dr \ d\theta\\ &= \int^{\frac{\pi}{2}}_{-\frac{\pi}{2}} \frac{(2\cos(\theta))^2}{2}-\frac{(2\cos(\theta))^3}{3}   \ d\theta\\ &= \pi - \frac{32}{9} \end{align}$$ Solving the above integral I get a negative answer which does not make sense considering the physical quantity is volume, which has to be positive. Where am I going wrong?","I want to find the volume of a function described by: This question can be best solved in cylindrical coordinates. So if I follow that process, I get the following limits: I am fairly certain that these limits are correct. So continuing, to find the volume of G: Solving the above integral I get a negative answer which does not make sense considering the physical quantity is volume, which has to be positive. Where am I going wrong?"," G= \{(x,y,z)|\sqrt{x^2+y^2} \le z \le 1, (x-1)^2+y^2 \le 1\}  r \le z \le 1  0 \le r \le 2\cos(\theta)  -\frac{\pi}{2} \le \theta \le \frac{\pi}{2} \begin{align}
\iiint r \ dz\ dr\ d\theta
&= \int^{\frac{\pi}{2}}_{-\frac{\pi}{2}} \int^{2\cos(\theta)}_{0} \int^{1}_{r} r \ dz \ dr \ d\theta\\
&= \int^{\frac{\pi}{2}}_{-\frac{\pi}{2}} \int^{2\cos(\theta)}_{0} r-r^2  \ dr \ d\theta\\
&= \int^{\frac{\pi}{2}}_{-\frac{\pi}{2}} \frac{(2\cos(\theta))^2}{2}-\frac{(2\cos(\theta))^3}{3}   \ d\theta\\
&= \pi - \frac{32}{9}
\end{align}","['integration', 'multivariable-calculus', 'multiple-integral', 'cylindrical-coordinates']"
64,How can I calculate the following double limit? Or does it diverge?,How can I calculate the following double limit? Or does it diverge?,,"$$\lim_{(x, y)\to(0,2)}\left(\frac{y\sin(xe^y)}{x}\right)$$ Here we deal with $\frac{0}{0}$ indeterminate form. What I could see is that $$\left|\frac{y\sin(xe^y)}{x} \right| \leq \left|\frac{y}{x}\right|$$ but what to do with that I don't know. If the $y \to 0$ I would know that it diverges.",Here we deal with indeterminate form. What I could see is that but what to do with that I don't know. If the I would know that it diverges.,"\lim_{(x, y)\to(0,2)}\left(\frac{y\sin(xe^y)}{x}\right) \frac{0}{0} \left|\frac{y\sin(xe^y)}{x} \right| \leq \left|\frac{y}{x}\right| y \to 0","['limits', 'multivariable-calculus']"
65,Calculate the volume between $z=\sqrt{x^2+y^2}$ and $z=x^2+y^2$.,Calculate the volume between  and .,z=\sqrt{x^2+y^2} z=x^2+y^2,"Calculate the volume between $z=\sqrt{x^2+y^2}$ and $z=x^2+y^2$ . Attempt We project on the $xy$ plane the intersection between $z=\sqrt{x^2+y^2}$ and $z=x^2+y^2$ , which is the circle $x^2+y^2=1, z=1$ . We can conclude that the region between $z=\sqrt{x^2+y^2}$ and $z=x^2+y^2$ can be described by $$-1\leq x\leq 1, -\sqrt{1-x^2}\leq y \leq \sqrt{1-x^2}, x^2+y^2\leq z \leq \sqrt{x^2+y^2}$$ The volume is given by $$V=\iiint_W dxdydz=\int_{-1}^{1} \int_{-\sqrt{1-x^2}}^{\sqrt{1-x^2}} \int_{x^2+y^2}^{\sqrt{x^2+y^2}} dxdydz$$ When I try to solve this, I get a difficult expression and cannot calculate it. So I think, everything I have done is wrong.","Calculate the volume between and . Attempt We project on the plane the intersection between and , which is the circle . We can conclude that the region between and can be described by The volume is given by When I try to solve this, I get a difficult expression and cannot calculate it. So I think, everything I have done is wrong.","z=\sqrt{x^2+y^2} z=x^2+y^2 xy z=\sqrt{x^2+y^2} z=x^2+y^2 x^2+y^2=1, z=1 z=\sqrt{x^2+y^2} z=x^2+y^2 -1\leq x\leq 1, -\sqrt{1-x^2}\leq y \leq \sqrt{1-x^2}, x^2+y^2\leq z \leq \sqrt{x^2+y^2} V=\iiint_W dxdydz=\int_{-1}^{1} \int_{-\sqrt{1-x^2}}^{\sqrt{1-x^2}} \int_{x^2+y^2}^{\sqrt{x^2+y^2}} dxdydz","['multivariable-calculus', 'volume', 'multiple-integral']"
66,"Show that the limit in $(0,0)$ of $\frac{xy}{x^3-y}$ doesn't exist.",Show that the limit in  of  doesn't exist.,"(0,0) \frac{xy}{x^3-y}","I'm trying to show that the limit below doesn't exist, I think it's quite simples but I couldn't until now. $$\lim_{(x,y)\to (0,0)}\dfrac{xy}{x^3-y}$$ My approach is try to find two curves in the domain that have different limits in $(0,0)$ I couldn't find any curve that the limit isn't $0$ . Any tips? Thanks.","I'm trying to show that the limit below doesn't exist, I think it's quite simples but I couldn't until now. My approach is try to find two curves in the domain that have different limits in I couldn't find any curve that the limit isn't . Any tips? Thanks.","\lim_{(x,y)\to (0,0)}\dfrac{xy}{x^3-y} (0,0) 0","['limits', 'multivariable-calculus']"
67,"Is $D = \{(x,y) \in\Bbb R^2\mid x^2y=1\}$ a closed set or open set?",Is  a closed set or open set?,"D = \{(x,y) \in\Bbb R^2\mid x^2y=1\}","Is $D = \{(x,y) \in\Bbb R^2\mid x^2y=1\}$ an open or closed set? Correct me if I'm wrong, an open set is a set that doesn't contain all its limits. From graphing $y = 1/x^2$ I can see that the curves converge towards the $x$ - and $y$ -axis but never touch the axes. Therefore, the set $D$ is an open set. Thats my intuition but I don't know how to formally prove it.","Is an open or closed set? Correct me if I'm wrong, an open set is a set that doesn't contain all its limits. From graphing I can see that the curves converge towards the - and -axis but never touch the axes. Therefore, the set is an open set. Thats my intuition but I don't know how to formally prove it.","D = \{(x,y) \in\Bbb R^2\mid x^2y=1\} y = 1/x^2 x y D","['multivariable-calculus', 'metric-spaces']"
68,"Surface integral on $S=\{(x,y,z)|x^2+y^2+z^2=1,x+y+z\leq 1\}$",Surface integral on,"S=\{(x,y,z)|x^2+y^2+z^2=1,x+y+z\leq 1\}","Let $S=\{(x,y,z)|x^2+y^2+z^2=1,x+y+z\leq 1\}$ , $F(x,y,z)=(x,0,-x)$ and $n(x,y,z)$ be the unit normal vector of $S$ such that $n(0,0,-1)=(0,0,-1)$ . I want to evaluate $\displaystyle \iint_{S}F(x,y,z)\cdot n(x,y,z)dS$ . My Attempt Let $f(x,y,z)=x^2+y^2+z^2-1$ . Then $n$ can be calculated by $n=\frac{\nabla f}{|\nabla f|}=(x,y,z)$ . This satisfies the condition stated in the problem. Therefore we have $\displaystyle \iint_{S}F(x,y,z)\cdot n(x,y,z)dS=\iint_{S}(x^2-zx)dS$ . Now we need to calculate this surface integral, but I'm encountering issues. According to this website , I have two options. One option is to find an orthogonal projection of $S$ . The other option is to find a parameterization of $S$ . However, I couldn't do either of them. Is there a simple expression for them? Any help is appreciated.","Let , and be the unit normal vector of such that . I want to evaluate . My Attempt Let . Then can be calculated by . This satisfies the condition stated in the problem. Therefore we have . Now we need to calculate this surface integral, but I'm encountering issues. According to this website , I have two options. One option is to find an orthogonal projection of . The other option is to find a parameterization of . However, I couldn't do either of them. Is there a simple expression for them? Any help is appreciated.","S=\{(x,y,z)|x^2+y^2+z^2=1,x+y+z\leq 1\} F(x,y,z)=(x,0,-x) n(x,y,z) S n(0,0,-1)=(0,0,-1) \displaystyle \iint_{S}F(x,y,z)\cdot n(x,y,z)dS f(x,y,z)=x^2+y^2+z^2-1 n n=\frac{\nabla f}{|\nabla f|}=(x,y,z) \displaystyle \iint_{S}F(x,y,z)\cdot n(x,y,z)dS=\iint_{S}(x^2-zx)dS S S","['multivariable-calculus', 'multiple-integral', 'surface-integrals']"
69,Find the area bounded by the curve $x^4+y^4=x^2+y^2$ [closed],Find the area bounded by the curve  [closed],x^4+y^4=x^2+y^2,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question I am stuck with this problem which deals with evaluating an Area The problem reads : Find the area bounded by the curve $x^4+y^4=x^2+y^2$ . I tried factorizing the expression and expressing $y$ in terms of $x$ , not able to proceed with that idea. Someone please help me out.","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question I am stuck with this problem which deals with evaluating an Area The problem reads : Find the area bounded by the curve . I tried factorizing the expression and expressing in terms of , not able to proceed with that idea. Someone please help me out.",x^4+y^4=x^2+y^2 y x,"['multivariable-calculus', 'definite-integrals', 'area']"
70,Searching open source (possibly) to perform multivariate limit,Searching open source (possibly) to perform multivariate limit,,"I'm searching same open source software to perform this kind of limit (without restricting and executing the limit to a variable): $$ \lim_{(x, y)\to(0, 0)}\frac{x^3y}{x^6+y^2} $$ I've seen sage and maxima, but i don't know if they can help me... Then, if not this, can they perform double and triple integrals?","I'm searching same open source software to perform this kind of limit (without restricting and executing the limit to a variable): I've seen sage and maxima, but i don't know if they can help me... Then, if not this, can they perform double and triple integrals?","
\lim_{(x, y)\to(0, 0)}\frac{x^3y}{x^6+y^2}
","['integration', 'multivariable-calculus', 'derivatives', 'multiple-integral']"
71,Geometric interpretation of Divergence of $\vec{f} = \frac{1}{r^2} \hat{r}$,Geometric interpretation of Divergence of,\vec{f} = \frac{1}{r^2} \hat{r},"I know that the mathematics tells me that the divergence is zero for the below vector field: $\vec{f} = \frac{1}{r^2} \hat{r}$ But I am more interested in the geometric intuition of it. Here is what I am looking at. The vector length is decreasing as I am increasing the radii of the sphere around origin in 3D space.  Now divergence is defined as $\partial {v_x}/\partial x +\partial {v_y}/\partial y+\partial {v_z}/\partial z$ in cartesian coordinates. Now lets think about a point other than the origin. Lets take $\partial {v_x}/\partial x$ . Now as the vector is decreasing in length as we are increasing the radii, this slope must be less than zero, i.e., $\partial {v_x}/\partial x < 0$ as the value is decreasing as we are increasing the $x$ .  The same logic can be applied to other dimensions, i.e., $\partial {v_y}/\partial y < 0$ $\partial {v_z}/\partial z < 0$ Now given all these inequalities, how can $\partial {v_x}/\partial x +\partial {v_y}/\partial y+\partial {v_z}/\partial z=0 $ ?","I know that the mathematics tells me that the divergence is zero for the below vector field: But I am more interested in the geometric intuition of it. Here is what I am looking at. The vector length is decreasing as I am increasing the radii of the sphere around origin in 3D space.  Now divergence is defined as in cartesian coordinates. Now lets think about a point other than the origin. Lets take . Now as the vector is decreasing in length as we are increasing the radii, this slope must be less than zero, i.e., as the value is decreasing as we are increasing the .  The same logic can be applied to other dimensions, i.e., Now given all these inequalities, how can ?",\vec{f} = \frac{1}{r^2} \hat{r} \partial {v_x}/\partial x +\partial {v_y}/\partial y+\partial {v_z}/\partial z \partial {v_x}/\partial x \partial {v_x}/\partial x < 0 x \partial {v_y}/\partial y < 0 \partial {v_z}/\partial z < 0 \partial {v_x}/\partial x +\partial {v_y}/\partial y+\partial {v_z}/\partial z=0 ,['multivariable-calculus']
72,Why is the gradient normal to tangent vectors?,Why is the gradient normal to tangent vectors?,,"Suppose $f: \mathbb{R}^n \to \mathbb{R}$ is differentiable at $x$ . Let $d_xf$ denote the derivative of $f$ at $x$ . Let $L$ be the level set through $x$ , $L = \{y \in \mathbb{R}^n: f(y) = f(x)\}$ . Suppose $v$ is a tangent vector at $x$ that is tangent to the level set $L$ . Then the claim is that $d_xf(v) = 0$ . Why is this true? Is there a rigorous justification of this? I have seen various answers, like Why is the gradient normal? and Why gradient vector is perpendicular to the plane , but I couldn't really find a rigorous justification of that particular fact, that $d_xf(v) = 0$ . I can see the intuition but I'd like a proof if possible. Also, what does it mean precisely when we say ""Suppose $v$ is a tangent vector at $x$ that is tangent to the level set $L$ ""? Can all these facts and notions be defined and proved in the usual multivariable context of Euclidean space $\mathbb{R}^n$ (like in a normal or advanced Calc III course) or do we need an excursion into differential geometry or something? I'd just like to know because some of the multivariable calculus texts/resources I've seen, as well as some answers on this site, mostly seem to gloss over the details and just roughly justify it by appealing to geometric intuition, which I think is useful but I would also like a proof.","Suppose is differentiable at . Let denote the derivative of at . Let be the level set through , . Suppose is a tangent vector at that is tangent to the level set . Then the claim is that . Why is this true? Is there a rigorous justification of this? I have seen various answers, like Why is the gradient normal? and Why gradient vector is perpendicular to the plane , but I couldn't really find a rigorous justification of that particular fact, that . I can see the intuition but I'd like a proof if possible. Also, what does it mean precisely when we say ""Suppose is a tangent vector at that is tangent to the level set ""? Can all these facts and notions be defined and proved in the usual multivariable context of Euclidean space (like in a normal or advanced Calc III course) or do we need an excursion into differential geometry or something? I'd just like to know because some of the multivariable calculus texts/resources I've seen, as well as some answers on this site, mostly seem to gloss over the details and just roughly justify it by appealing to geometric intuition, which I think is useful but I would also like a proof.",f: \mathbb{R}^n \to \mathbb{R} x d_xf f x L x L = \{y \in \mathbb{R}^n: f(y) = f(x)\} v x L d_xf(v) = 0 d_xf(v) = 0 v x L \mathbb{R}^n,"['multivariable-calculus', 'differential-geometry']"
73,Area between $x=y^2-7$ and $x=e^y$ for $-1\leq y\leq 1$,Area between  and  for,x=y^2-7 x=e^y -1\leq y\leq 1,"I need to find the area of the shaded region here I thought the area would be $\int_{-1}^{1}{y^2-7-e^y}dy$ ,which got me $-\frac{40}{3}-3+\frac1e$ , but I was marked wrong. By inspection it looks like the area under the blue curve has a symmetry that makes its total area $0$ from $x=-7$ to $x=\frac12$ . So I figured the area I'm looking for is the area under the red curve from $x=1/2$ to $x=3$ . I tried this and got an answer of $\frac13 - 2$ which was also marked wrong. What do I do?","I need to find the area of the shaded region here I thought the area would be ,which got me , but I was marked wrong. By inspection it looks like the area under the blue curve has a symmetry that makes its total area from to . So I figured the area I'm looking for is the area under the red curve from to . I tried this and got an answer of which was also marked wrong. What do I do?",\int_{-1}^{1}{y^2-7-e^y}dy -\frac{40}{3}-3+\frac1e 0 x=-7 x=\frac12 x=1/2 x=3 \frac13 - 2,"['integration', 'multivariable-calculus', 'area', 'multiple-integral']"
74,Limit of given fraction approaching to zero [duplicate],Limit of given fraction approaching to zero [duplicate],,"This question already has answers here : Multivariable limit proof: $\lim\limits_{(x,y)\rightarrow (0,0)}\frac{\left|x\right|^a\left|y\right|^b}{\left|x\right|^c + \left|y\right|^d} = 0$ (4 answers) Closed 4 years ago . Show that $\lim_{(x,y) \to (0,0)} f(x,y) = \frac{x^3(y^3 + \pi)}{x^2+y^2}$ is equal to zero. My progress: I have two ideas related to this problem. Initially, I thought about using polar coordinates, but quite uncertain whether it is right approach for this problem or not. Alternatively, I am thinking about squeeze theorem: by AM-GM and triangle inequality, I managed to find a function larger than given $f$ with variables $x,y$ only. Does that imply limit of $f$ will be zero?","This question already has answers here : Multivariable limit proof: $\lim\limits_{(x,y)\rightarrow (0,0)}\frac{\left|x\right|^a\left|y\right|^b}{\left|x\right|^c + \left|y\right|^d} = 0$ (4 answers) Closed 4 years ago . Show that is equal to zero. My progress: I have two ideas related to this problem. Initially, I thought about using polar coordinates, but quite uncertain whether it is right approach for this problem or not. Alternatively, I am thinking about squeeze theorem: by AM-GM and triangle inequality, I managed to find a function larger than given with variables only. Does that imply limit of will be zero?","\lim_{(x,y) \to (0,0)} f(x,y) = \frac{x^3(y^3 + \pi)}{x^2+y^2} f x,y f",['multivariable-calculus']
75,Inequality Limits of Integration for Joint Density Function,Inequality Limits of Integration for Joint Density Function,,"While working to find the limits of integration for a joint PDF, I somehow keep running into an error. $ f(x,y) = kx^3\text{ for }0\leq x\leq 3\text{ and }0\leq y\leq 2 $ While evaluating the probability that $(x,y)$ satisfies $x+y \geq3\ $ I come up with the following integral: $$ k\int_0^3\int_0^{3-x}x^3dy dx $$ Resulting in $$ k(\frac {234}4-\frac {243}5) $$ According to the solution, this is incorrect. Where did I go wrong?","While working to find the limits of integration for a joint PDF, I somehow keep running into an error. While evaluating the probability that satisfies I come up with the following integral: Resulting in According to the solution, this is incorrect. Where did I go wrong?","
f(x,y) = kx^3\text{ for }0\leq x\leq 3\text{ and }0\leq y\leq 2
 (x,y) x+y \geq3\  
k\int_0^3\int_0^{3-x}x^3dy dx
 
k(\frac {234}4-\frac {243}5)
","['calculus', 'probability', 'multivariable-calculus']"
76,"If $\|\langle x_1, x_2, \dotsc, x_n\rangle\|\le \delta$, can I say that $x_i \le \delta$ for each $i$?","If , can I say that  for each ?","\|\langle x_1, x_2, \dotsc, x_n\rangle\|\le \delta x_i \le \delta i","If I have a vector $x \in \mathbb{R}^n$ that is in a neighborhood of $0$ that is large $\delta$ , i.e. $\left \| x \right \| \le \delta$ can I say that all of its components must be $x_i \le \delta$ for each $i =1,\dots,n$ ?","If I have a vector that is in a neighborhood of that is large , i.e. can I say that all of its components must be for each ?","x \in \mathbb{R}^n 0 \delta \left \| x \right \| \le \delta x_i \le \delta i =1,\dots,n","['calculus', 'linear-algebra', 'multivariable-calculus']"
77,Equal volume iff there is a diffeomorphism,Equal volume iff there is a diffeomorphism,,Let $M$ be a compact oriented smooth manifold. Let $w_1$ and $w_2$ be two volume forms. Let integral of both these forms over $M$ be equal i.e $\operatorname{vol}(M)$ be equal wrt both forms. Show that there is a diffeomorphism $f$ from $M$ to $M$ such that $f^*(w_2)=w_1$ Of course if such an f exists then by change of variable formula the volumes shall be equal. Also it was told in class that apparently this isn't the case for symplectic manifolds and this is a global invariant. Any comments on that?,Let be a compact oriented smooth manifold. Let and be two volume forms. Let integral of both these forms over be equal i.e be equal wrt both forms. Show that there is a diffeomorphism from to such that Of course if such an f exists then by change of variable formula the volumes shall be equal. Also it was told in class that apparently this isn't the case for symplectic manifolds and this is a global invariant. Any comments on that?,M w_1 w_2 M \operatorname{vol}(M) f M M f^*(w_2)=w_1,"['multivariable-calculus', 'differential-geometry', 'differential-topology', 'smooth-manifolds', 'symplectic-geometry']"
78,Extrema of function with lagrange multipliers,Extrema of function with lagrange multipliers,,"Let $$f(x_1, ..., x_n) = x_1 + \frac{x_2}{x_1} + \frac{x_3}{x_2} + ...+\frac{x_n}{x_{n-1}} + \frac{1}{x_n}$$ where $x_1, ..., x_n>0$ . I thought that maybe I should cast what above as optimization problem with equality constraint, but I don't know how to do that. Moreover the constraint gives unbounded open set, so even existence of extrema is tricky.","Let where . I thought that maybe I should cast what above as optimization problem with equality constraint, but I don't know how to do that. Moreover the constraint gives unbounded open set, so even existence of extrema is tricky.","f(x_1, ..., x_n) = x_1 + \frac{x_2}{x_1} + \frac{x_3}{x_2} + ...+\frac{x_n}{x_{n-1}} + \frac{1}{x_n} x_1, ..., x_n>0","['multivariable-calculus', 'optimization', 'maxima-minima', 'lagrange-multiplier']"
79,Partial derivative with variables where some are dependent on each other,Partial derivative with variables where some are dependent on each other,,"Say I have a function $f(x,y,z,w)$ . Let $x$ and $y$ each be a function of $z$ and $w$ so $x=x(z,w)$ and $y=y(z,w)$ . Then we have a function of the form $$f(x(z,w),y(z,w),z,w)$$ Using the chain rule for functions of multiple variables I get $$\frac{\partial f}{\partial z} = \frac{\partial f}{\partial x}\frac{\partial x}{\partial z}+ \frac{\partial f}{\partial y}\frac{\partial y}{\partial z}+ \frac{\partial f}{\partial z}\frac{\partial z}{\partial z}+ \frac{\partial f}{\partial w}\frac{\partial w}{\partial z}$$ As $w$ is not dependent on $z$ then $\frac{\partial w}{\partial z}=0$ $$\frac{\partial f}{\partial z} = \frac{\partial f}{\partial x}\frac{\partial x}{\partial z}+ \frac{\partial f}{\partial y}\frac{\partial y}{\partial z}+ \frac{\partial f}{\partial z}1+ \frac{\partial f}{\partial w}0$$ $$\frac{\partial f}{\partial z} = \frac{\partial f}{\partial x}\frac{\partial x}{\partial z}+ \frac{\partial f}{\partial y}\frac{\partial y}{\partial z}+ \frac{\partial f}{\partial z}$$ This means $\frac{\partial x}{\partial z}=0$ and $\frac{\partial y}{\partial z}=0$ but this is not necessarily true because $x(z,w)$ and $y(z,w)$ are dependent on $z$ . I am unsure where this contradiction is coming from. I think I must be applying the chain rule incorrectly. I am also unsure when partially differentiating with respect to $z$ whether to treat just $w$ as a constant or $x,y$ and $w$ as constants. I found similar problems: Partial derivative of a two variables function, one of which dependent on the other Partial Derivatives - constants However these discussed functions that can be written in terms of one variable whereas the function I am confused with can be written in terms of two variables at the least ( $z$ and $w$ ). Please explain what I am doing wrong and thank you for any help!","Say I have a function . Let and each be a function of and so and . Then we have a function of the form Using the chain rule for functions of multiple variables I get As is not dependent on then This means and but this is not necessarily true because and are dependent on . I am unsure where this contradiction is coming from. I think I must be applying the chain rule incorrectly. I am also unsure when partially differentiating with respect to whether to treat just as a constant or and as constants. I found similar problems: Partial derivative of a two variables function, one of which dependent on the other Partial Derivatives - constants However these discussed functions that can be written in terms of one variable whereas the function I am confused with can be written in terms of two variables at the least ( and ). Please explain what I am doing wrong and thank you for any help!","f(x,y,z,w) x y z w x=x(z,w) y=y(z,w) f(x(z,w),y(z,w),z,w) \frac{\partial f}{\partial z} = \frac{\partial f}{\partial x}\frac{\partial x}{\partial z}+ \frac{\partial f}{\partial y}\frac{\partial y}{\partial z}+ \frac{\partial f}{\partial z}\frac{\partial z}{\partial z}+ \frac{\partial f}{\partial w}\frac{\partial w}{\partial z} w z \frac{\partial w}{\partial z}=0 \frac{\partial f}{\partial z} = \frac{\partial f}{\partial x}\frac{\partial x}{\partial z}+ \frac{\partial f}{\partial y}\frac{\partial y}{\partial z}+ \frac{\partial f}{\partial z}1+ \frac{\partial f}{\partial w}0 \frac{\partial f}{\partial z} = \frac{\partial f}{\partial x}\frac{\partial x}{\partial z}+ \frac{\partial f}{\partial y}\frac{\partial y}{\partial z}+ \frac{\partial f}{\partial z} \frac{\partial x}{\partial z}=0 \frac{\partial y}{\partial z}=0 x(z,w) y(z,w) z z w x,y w z w","['multivariable-calculus', 'derivatives', 'partial-differential-equations', 'partial-derivative']"
80,How can I calculate this kind of limit?,How can I calculate this kind of limit?,,"How can I calculate this limit? $$\lim _{(x,y) \to (0,0)} \frac{\vert{x\vert\vert{y}\vert}}{x^2 +y^2}$$ I don't have idea and I will be appreciate for your help.",How can I calculate this limit? I don't have idea and I will be appreciate for your help.,"\lim _{(x,y) \to (0,0)} \frac{\vert{x\vert\vert{y}\vert}}{x^2 +y^2}",['multivariable-calculus']
81,"Is there anyway to see that $h(x,y) = \frac{20}{3+x^2+2y^2}$ represents a graph looking like a mountain?",Is there anyway to see that  represents a graph looking like a mountain?,"h(x,y) = \frac{20}{3+x^2+2y^2}","The function $h(x,y) = \frac{20}{3+x^2+2y^2}$ represents the following graph: Is there anyway to see from the equation, without plotting it, that its graph will look as shown above? Moreover, is there a simple way of coming up with another equation that represents two ""mountains"", of given heights above the $xy$ -plane, next to each other (or even more complicated ""mountain ranges"" with given properties)?","The function represents the following graph: Is there anyway to see from the equation, without plotting it, that its graph will look as shown above? Moreover, is there a simple way of coming up with another equation that represents two ""mountains"", of given heights above the -plane, next to each other (or even more complicated ""mountain ranges"" with given properties)?","h(x,y) = \frac{20}{3+x^2+2y^2} xy","['multivariable-calculus', 'differential-geometry', 'graphing-functions']"
82,Why does $\frac{x^{2}}{1+x^{2}}$ diverge?,Why does  diverge?,\frac{x^{2}}{1+x^{2}},Why does $\frac{x^{2}}{1+x^{2}}$ diverge? I am trying to show that the integral $2\int\int_{\mathbb{R}^{+}}\frac{x^{2}}{(1+x^{2})(1+y^{2})}dxdy$ diverges. The solution says it diverges because $\frac{x^{2}}{1+x^{2}}\geq \frac{1}{2}$ . What does this mean? What theorem is being used in analysis?,Why does diverge? I am trying to show that the integral diverges. The solution says it diverges because . What does this mean? What theorem is being used in analysis?,\frac{x^{2}}{1+x^{2}} 2\int\int_{\mathbb{R}^{+}}\frac{x^{2}}{(1+x^{2})(1+y^{2})}dxdy \frac{x^{2}}{1+x^{2}}\geq \frac{1}{2},['multivariable-calculus']
83,Find the tangent line to a curve,Find the tangent line to a curve,,"Find the tangent line to the curve $x^2y - y^2 + x = 11$ at the point $(3,1)$ I tried to solve it using parametric equations \begin{cases} y = t \\[4px] x = -\dfrac{1}{2t} + \dfrac{\sqrt{1+4t^3 + 44t}}{2t} \end{cases} and the derivative of $x(t)$ , $y(t)$ , $t= 1$ gives the direction vector $( 5/7 , 1 )$ so the line that passes through $(3,1)$ l: $(3,1) + s(5/7 , 1) $ Is it correct? Because using desmos the line doesn't seem to be tangent to the curve.","Find the tangent line to the curve at the point I tried to solve it using parametric equations and the derivative of , , gives the direction vector so the line that passes through l: Is it correct? Because using desmos the line doesn't seem to be tangent to the curve.","x^2y - y^2 + x = 11 (3,1) \begin{cases}
y = t \\[4px]
x = -\dfrac{1}{2t} + \dfrac{\sqrt{1+4t^3 + 44t}}{2t}
\end{cases} x(t) y(t) t= 1 ( 5/7 , 1 ) (3,1) (3,1) + s(5/7 , 1) ","['multivariable-calculus', 'tangent-line']"
84,How do I find a tangent plane without a specified point?,How do I find a tangent plane without a specified point?,,"I was having a problem finding the points on $z=3x^2 - 4y^2$ where vector $n=<3,2,2>$ is normal to the tangent plane. How do we calculate the tangent plane equation without a specific point to calculate it at? I also had an idea to take the cross product of $2$ vectors in the plane and somehow compare it to the $n$ vector but I don't know exactly how to do this. Thank you for any help!",I was having a problem finding the points on where vector is normal to the tangent plane. How do we calculate the tangent plane equation without a specific point to calculate it at? I also had an idea to take the cross product of vectors in the plane and somehow compare it to the vector but I don't know exactly how to do this. Thank you for any help!,"z=3x^2 - 4y^2 n=<3,2,2> 2 n","['multivariable-calculus', 'vectors', 'orthonormal', 'tangent-spaces']"
85,"Clarification of Textbook Explanation of Hessian Matrix, Directional Second Derivative, and Eigenvalues/Eigenvectors","Clarification of Textbook Explanation of Hessian Matrix, Directional Second Derivative, and Eigenvalues/Eigenvectors",,"My machine learning textbook has the following section on the Hessian matrix : When our function has multiple input dimensions, there are many second derivatives. These derivatives can be collected together into a matrix called the Hessian matrix . The Hessian matrix $\mathbf{H}(f)(\mathbf{x})$ is defined such that $$\mathbf{H}(f)(\mathbf{x})_{i, j} = \dfrac{\partial^2}{\partial{x_i}\partial{x_j}} f(\mathbf{x}).$$ Equivalently, the Hessian is the Jacobian of the gradient. Anywhere that the second partial derivatives are continuous, the differential operators are commutative; that is, their order can be swapped: $$\dfrac{\partial^2}{\partial{x_i}\partial{x_j}} f(\mathbf{x}) = \dfrac{\partial^2}{\partial{x_j}\partial{x_i}} f(\mathbf{x}) $$ This implies that $\mathbf{H}_{i, j} = \mathbf{H}_{j, i}$ , so the Hessian matrix is symmetric at such points. Most of the functions we encounter in the context of deep learning have a symmetric Hessian almost everywhere. Because the Hessian matrix is real and symmetric, we can decompose it into a set of real eigenvalues and an orthogonal basis of eigenvectors. The second derivative in a specific direction represented by a unit vector $\mathbf{d}$ is given by $\mathbf{d}^T \mathbf{H} \mathbf{d}$ . When $\mathbf{d}$ is an eigenvector of $\mathbf{H}$ , the second derivative in that direction is given by the corresponding eigenvalue. For other directions of $\mathbf{d}$ , the directional second derivative is a weighted average of all the eigenvalues, with weights between $0$ and $1$ , and eigenvectors that have a smaller angle with $\mathbf{d}$ receiving more weight. The maximum eigenvalue determines the maximum second derivative, and the minimum eigenvalue determines the minimum second derivative. Goodfellow, Ian; Bengio, Yoshua; Courville, Aaron. Deep Learning (Page 84). I understood everything until this part: For other directions of $\mathbf{d}$ , the directional second derivative is a weighted average of all the eigenvalues, with weights between $0$ and $1$ , and eigenvectors that have a smaller angle with $\mathbf{d}$ receiving more weight. The maximum eigenvalue determines the maximum second derivative, and the minimum eigenvalue determines the minimum second derivative. None of this makes any sense to me. For instance, what does it mean by ""other directions of $\mathbf{d}$ ""? $\mathbf{d}$ is a unit vector and therefore inherently has a direction. So to say ""other directions of $\mathbf{d}$ "" makes no sense? Also, why does the maximum eigenvalue determines the maximum second derivative, and the minimum eigenvalue determines the minimum second derivative? I've studied elementary linear algebra (including an introduction to eigenvalues and eigenvectors), but this part is not clear to me. I would greatly appreciate it if people could please take the time to clarify this section.","My machine learning textbook has the following section on the Hessian matrix : When our function has multiple input dimensions, there are many second derivatives. These derivatives can be collected together into a matrix called the Hessian matrix . The Hessian matrix is defined such that Equivalently, the Hessian is the Jacobian of the gradient. Anywhere that the second partial derivatives are continuous, the differential operators are commutative; that is, their order can be swapped: This implies that , so the Hessian matrix is symmetric at such points. Most of the functions we encounter in the context of deep learning have a symmetric Hessian almost everywhere. Because the Hessian matrix is real and symmetric, we can decompose it into a set of real eigenvalues and an orthogonal basis of eigenvectors. The second derivative in a specific direction represented by a unit vector is given by . When is an eigenvector of , the second derivative in that direction is given by the corresponding eigenvalue. For other directions of , the directional second derivative is a weighted average of all the eigenvalues, with weights between and , and eigenvectors that have a smaller angle with receiving more weight. The maximum eigenvalue determines the maximum second derivative, and the minimum eigenvalue determines the minimum second derivative. Goodfellow, Ian; Bengio, Yoshua; Courville, Aaron. Deep Learning (Page 84). I understood everything until this part: For other directions of , the directional second derivative is a weighted average of all the eigenvalues, with weights between and , and eigenvectors that have a smaller angle with receiving more weight. The maximum eigenvalue determines the maximum second derivative, and the minimum eigenvalue determines the minimum second derivative. None of this makes any sense to me. For instance, what does it mean by ""other directions of ""? is a unit vector and therefore inherently has a direction. So to say ""other directions of "" makes no sense? Also, why does the maximum eigenvalue determines the maximum second derivative, and the minimum eigenvalue determines the minimum second derivative? I've studied elementary linear algebra (including an introduction to eigenvalues and eigenvectors), but this part is not clear to me. I would greatly appreciate it if people could please take the time to clarify this section.","\mathbf{H}(f)(\mathbf{x}) \mathbf{H}(f)(\mathbf{x})_{i, j} = \dfrac{\partial^2}{\partial{x_i}\partial{x_j}} f(\mathbf{x}). \dfrac{\partial^2}{\partial{x_i}\partial{x_j}} f(\mathbf{x}) = \dfrac{\partial^2}{\partial{x_j}\partial{x_i}} f(\mathbf{x})  \mathbf{H}_{i, j} = \mathbf{H}_{j, i} \mathbf{d} \mathbf{d}^T \mathbf{H} \mathbf{d} \mathbf{d} \mathbf{H} \mathbf{d} 0 1 \mathbf{d} \mathbf{d} 0 1 \mathbf{d} \mathbf{d} \mathbf{d} \mathbf{d}","['multivariable-calculus', 'eigenvalues-eigenvectors', 'vector-analysis', 'machine-learning', 'hessian-matrix']"
86,Graph $r=\cot(\theta)\csc(\theta)$.,Graph .,r=\cot(\theta)\csc(\theta),"So I am stuck on a graphing question in polar coordinates.  I am not sure how to graph the equation even after writing down a few points: $\cot(0)\csc(0) $ DNE $\cot(\dfrac {\pi}{4})\csc(\dfrac {\pi}{4})= \sqrt{2}$ , $\cot(\dfrac {\pi}{2})\csc(\dfrac {\pi}{2})= 0,$ $\cot(\dfrac {3\pi}{4})\csc(\dfrac {3\pi}{4})= -\sqrt{2}$ , $\cot(\pi)\csc(\pi) $ DNE, and so on. Obviously I can just graph it online, but can someone explain the mechanics to how to graph it without using a graphing calculator or desmos?  Thanks!","So I am stuck on a graphing question in polar coordinates.  I am not sure how to graph the equation even after writing down a few points: DNE , , DNE, and so on. Obviously I can just graph it online, but can someone explain the mechanics to how to graph it without using a graphing calculator or desmos?  Thanks!","\cot(0)\csc(0)  \cot(\dfrac {\pi}{4})\csc(\dfrac {\pi}{4})= \sqrt{2} \cot(\dfrac {\pi}{2})\csc(\dfrac {\pi}{2})= 0, \cot(\dfrac {3\pi}{4})\csc(\dfrac {3\pi}{4})= -\sqrt{2} \cot(\pi)\csc(\pi) ","['multivariable-calculus', 'polar-coordinates']"
87,"Area bounded by $(\sqrt{|x|}+\sqrt{|y|})^{12}=xy$ , how to convert this to polar equation, what to do with absolute values?","Area bounded by  , how to convert this to polar equation, what to do with absolute values?",(\sqrt{|x|}+\sqrt{|y|})^{12}=xy,"The only problem finding the limits of integration. Thats why i want to convert to polar. I want to make a substitution so that the limits of r can be easily evaluated.   I was thinking of  $$ x=r^2 cos^2 \phi $$ $$ y=r^2 sin^2 \phi $$ The absolute values scare me a little.  I am not sure if they even change anything, r is positive, but i dont know what to do with absolute values of trig functions.","The only problem finding the limits of integration. Thats why i want to convert to polar. I want to make a substitution so that the limits of r can be easily evaluated.   I was thinking of  $$ x=r^2 cos^2 \phi $$ $$ y=r^2 sin^2 \phi $$ The absolute values scare me a little.  I am not sure if they even change anything, r is positive, but i dont know what to do with absolute values of trig functions.",,"['calculus', 'integration', 'multivariable-calculus', 'problem-solving', 'polar-coordinates']"
88,"Converting to Complex coordinates to check injectivity of $f(x,y)=(e^x\cos{y},e^x\sin{y})$",Converting to Complex coordinates to check injectivity of,"f(x,y)=(e^x\cos{y},e^x\sin{y})",I have posted the problem below.  I know that this question has been asked  before but I have a question about the proof. I wrote the expression in polar form as $f(z)=e^z$ and to check injectivity I assumed that $f(z_1)=f(z_2)$ which gives $e^{z_1}=e^{z_2}$.  Is that enough to conclude that $z_1=z_2$?  Or should I rewrite the functions as $e^{z_1}=e^{x_1}\cos{y}+ie^{x_1}\sin{y}$?  The first case I doesn't consider the restriction on $y$ and then if that's the case then it seems pointless to have converted to complex form. Thanks!,I have posted the problem below.  I know that this question has been asked  before but I have a question about the proof. I wrote the expression in polar form as $f(z)=e^z$ and to check injectivity I assumed that $f(z_1)=f(z_2)$ which gives $e^{z_1}=e^{z_2}$.  Is that enough to conclude that $z_1=z_2$?  Or should I rewrite the functions as $e^{z_1}=e^{x_1}\cos{y}+ie^{x_1}\sin{y}$?  The first case I doesn't consider the restriction on $y$ and then if that's the case then it seems pointless to have converted to complex form. Thanks!,,"['calculus', 'real-analysis', 'complex-analysis', 'multivariable-calculus', 'proof-verification']"
89,"Does $ \lim_\limits {(x,y)\to (0,0 )} \frac{\sin (x) -\sin (y)}{x + y}$ exist?",Does  exist?," \lim_\limits {(x,y)\to (0,0 )} \frac{\sin (x) -\sin (y)}{x + y}","Does $$\lim_{(x,y)\to (0,0 )} \frac{\sin (x) - \sin (y)}{x + y}$$ exist? It's clear that the $\sin x$ will approach $0$ as $x$ or $y$ is approaching 0. Should I maybe use to find the answer polar coordinates? Where $x = r \cos \varphi$,$y = r \sin \varphi$ and so $r^2=x^2+y^2$. I would appreciate any kind of help.","Does $$\lim_{(x,y)\to (0,0 )} \frac{\sin (x) - \sin (y)}{x + y}$$ exist? It's clear that the $\sin x$ will approach $0$ as $x$ or $y$ is approaching 0. Should I maybe use to find the answer polar coordinates? Where $x = r \cos \varphi$,$y = r \sin \varphi$ and so $r^2=x^2+y^2$. I would appreciate any kind of help.",,"['calculus', 'multivariable-calculus']"
90,Proving that the common normal between any two smooth curves corresponds to a stationary point of their distance apart.,Proving that the common normal between any two smooth curves corresponds to a stationary point of their distance apart.,,"I would highly appreciate any clues as I can't think of a starting point other than to intuitively claim that it ""makes sense"" and finding examples for which it works... And could this proof be extended to curves that can't be represented as functions? Here is an example (which I checked and worked):","I would highly appreciate any clues as I can't think of a starting point other than to intuitively claim that it ""makes sense"" and finding examples for which it works... And could this proof be extended to curves that can't be represented as functions? Here is an example (which I checked and worked):",,['multivariable-calculus']
91,Calculate $\iint_D x dxdy$ using polar coordinates,Calculate  using polar coordinates,\iint_D x dxdy,"Using polar coordinates, I want to calculate $\iint_D x dxdy$, where $D$ is the disk with center $(2,3)$ and radius $2$. $$$$ I have done the following: We have $D=\{(x,y)\mid (x-2)^2+(y-3)^2\leq 4\}$. We use $(x,y)=(r\cos \theta, r\sin \theta)$. From the inequality $$(x-2)^2+(y-3)^2\leq 4\Rightarrow x^2-4x+4+y^2-6y+9\leq 4 \Rightarrow x^2+y^2-4x-6y\leq -9$$ we get $$r^2\cos^2\theta+r^2\sin^2\theta-4r\cos\theta-6r\sin\theta\leq -9 \Rightarrow r^2-r(4\cos\theta-6\sin\theta)+9\leq 0$$  To find for which values of $r$ that inequality is true, we have to find first the roots of $r^2-r(4\cos\theta-6\sin\theta)+9=0$. The roots are $$2\cos \theta+3\sin\theta\pm \sqrt{12\cos\theta\sin\theta-5\cos^2\theta}$$ Therefore, we get the inequality $r^2-r(4\cos\theta-6\sin\theta)+9\leq 0$ for $$2\cos \theta+3\sin\theta-\sqrt{12\cos\theta\sin\theta-5\cos^2\theta}\leq r\\  \leq 2\cos \theta+3\sin\theta+\sqrt{12\cos\theta\sin\theta-5\cos^2\theta}$$ or not? So, at the integral do we use these limits for $r$ ? And what about $\theta$ ? Does it hold that $0\leq \theta\leq 2\pi$ ?","Using polar coordinates, I want to calculate $\iint_D x dxdy$, where $D$ is the disk with center $(2,3)$ and radius $2$. $$$$ I have done the following: We have $D=\{(x,y)\mid (x-2)^2+(y-3)^2\leq 4\}$. We use $(x,y)=(r\cos \theta, r\sin \theta)$. From the inequality $$(x-2)^2+(y-3)^2\leq 4\Rightarrow x^2-4x+4+y^2-6y+9\leq 4 \Rightarrow x^2+y^2-4x-6y\leq -9$$ we get $$r^2\cos^2\theta+r^2\sin^2\theta-4r\cos\theta-6r\sin\theta\leq -9 \Rightarrow r^2-r(4\cos\theta-6\sin\theta)+9\leq 0$$  To find for which values of $r$ that inequality is true, we have to find first the roots of $r^2-r(4\cos\theta-6\sin\theta)+9=0$. The roots are $$2\cos \theta+3\sin\theta\pm \sqrt{12\cos\theta\sin\theta-5\cos^2\theta}$$ Therefore, we get the inequality $r^2-r(4\cos\theta-6\sin\theta)+9\leq 0$ for $$2\cos \theta+3\sin\theta-\sqrt{12\cos\theta\sin\theta-5\cos^2\theta}\leq r\\  \leq 2\cos \theta+3\sin\theta+\sqrt{12\cos\theta\sin\theta-5\cos^2\theta}$$ or not? So, at the integral do we use these limits for $r$ ? And what about $\theta$ ? Does it hold that $0\leq \theta\leq 2\pi$ ?",,"['integration', 'multivariable-calculus', 'polar-coordinates']"
92,"Need a formula for $\frac{d}{dx}f(g(x), h(x))$",Need a formula for,"\frac{d}{dx}f(g(x), h(x))","I know the derivative chain rule $\frac{d}{dx}f(g(x))= f^{\prime}(g(x))\cdot g^{\prime}(x)$. What is the formula if $f$ is a function of two variables, i.e. what is $\frac{d}{dx}f(g(x), h(x))$? Thanks for help.","I know the derivative chain rule $\frac{d}{dx}f(g(x))= f^{\prime}(g(x))\cdot g^{\prime}(x)$. What is the formula if $f$ is a function of two variables, i.e. what is $\frac{d}{dx}f(g(x), h(x))$? Thanks for help.",,"['calculus', 'multivariable-calculus', 'derivatives']"
93,"If $f$ is differentiable, then $f$ is continuous","If  is differentiable, then  is continuous",f f,"Let  $f: \mathbb{R}^2 \to \mathbb{R} $ be a function. Prove or disprove: 1) If $f$ is differentiable at $(a,b)$, then $f$ is continuous at $(a,b)$ 2) If $f$ is continuous at $(a,b)$, then $f$ is differentiable at $(a,b)$ What I already have: If I want to show that $f$ is differentiable at $a$ (and with that also continuous  at $a$), I do it like this: $\lim_{h\to 0}  f(a+h)-f(a)= \lim_{h\to 0} {\frac {f(a+h)-f(a)}{h}\cdot h}$ $=\lim_{h\to 0} {\frac {f(a+h)-f(a)}{h}\cdot \lim_{h\to 0}h}=f'(a)\cdot0=0 $ However here I need to show it for a point $(a,b)$. My idea was to show it like this: If $f$  is differentiable at $(a,b) \to \forall h \in \mathbb{R}^2$ $f((a, b) + h) - f(a, b) = \nabla f(a,b)*h + r(h)$ and $\frac{r(h)}{|h|  }  \to 0 $  for     $h \to 0$ 2) I know that this is not true. So would a counterexample be $f(x,y)= |x| + y| ? $ Thanks in advance!","Let  $f: \mathbb{R}^2 \to \mathbb{R} $ be a function. Prove or disprove: 1) If $f$ is differentiable at $(a,b)$, then $f$ is continuous at $(a,b)$ 2) If $f$ is continuous at $(a,b)$, then $f$ is differentiable at $(a,b)$ What I already have: If I want to show that $f$ is differentiable at $a$ (and with that also continuous  at $a$), I do it like this: $\lim_{h\to 0}  f(a+h)-f(a)= \lim_{h\to 0} {\frac {f(a+h)-f(a)}{h}\cdot h}$ $=\lim_{h\to 0} {\frac {f(a+h)-f(a)}{h}\cdot \lim_{h\to 0}h}=f'(a)\cdot0=0 $ However here I need to show it for a point $(a,b)$. My idea was to show it like this: If $f$  is differentiable at $(a,b) \to \forall h \in \mathbb{R}^2$ $f((a, b) + h) - f(a, b) = \nabla f(a,b)*h + r(h)$ and $\frac{r(h)}{|h|  }  \to 0 $  for     $h \to 0$ 2) I know that this is not true. So would a counterexample be $f(x,y)= |x| + y| ? $ Thanks in advance!",,"['calculus', 'real-analysis', 'analysis', 'multivariable-calculus', 'continuity']"
94,"The plane tangent to the graph of $f$ at $(x_0,y_0,f(x_0,y_0))$ is orthogonal to the vector $(x_0,y_0,f(x_0,y_0))$",The plane tangent to the graph of  at  is orthogonal to the vector,"f (x_0,y_0,f(x_0,y_0)) (x_0,y_0,f(x_0,y_0))","Let $f(x,y) = -(1-x^2-y^2)^{1/2}$ for $(x,y)$ such that $x^2+y^2 < 1$. Show that the plane tangent to the graph of $f$ at $(x_0,y_0,f(x_0,y_0))$ is orthogonal to the vector $(x_0,y_0,f(x_0,y_0))$. I am confused about the overall steps of solving such a problem. The tangent plane is given by $z = f(x_0,y_0) - \frac {x_0} { \sqrt {1-x_0^2-y^2}}(x-x_0) - \frac {y_0}{ \sqrt {1-x_0^2-y_0^2}}(y-y_0)$, which has normal $( \frac {x_0} { \sqrt {1-x_0^2-y^2}} ,  \frac {y_0} { \sqrt {1-x_0^2-y^2}}, -1)$, and here I am stuck. Perhaps I have gone astray, any hints appreciated.","Let $f(x,y) = -(1-x^2-y^2)^{1/2}$ for $(x,y)$ such that $x^2+y^2 < 1$. Show that the plane tangent to the graph of $f$ at $(x_0,y_0,f(x_0,y_0))$ is orthogonal to the vector $(x_0,y_0,f(x_0,y_0))$. I am confused about the overall steps of solving such a problem. The tangent plane is given by $z = f(x_0,y_0) - \frac {x_0} { \sqrt {1-x_0^2-y^2}}(x-x_0) - \frac {y_0}{ \sqrt {1-x_0^2-y_0^2}}(y-y_0)$, which has normal $( \frac {x_0} { \sqrt {1-x_0^2-y^2}} ,  \frac {y_0} { \sqrt {1-x_0^2-y^2}}, -1)$, and here I am stuck. Perhaps I have gone astray, any hints appreciated.",,['multivariable-calculus']
95,"Evaluate $\displaystyle \lim_{(x,y)\to (0,0)}\frac{x^2}{|x|+|y|}\cos(y^2)$",Evaluate,"\displaystyle \lim_{(x,y)\to (0,0)}\frac{x^2}{|x|+|y|}\cos(y^2)","$$\lim_{(x,y)\to (0,0)}\frac{x^2}{|x|+|y|}\cos(y^2)$$ I have tried the following paths: $$(x,kx),(x,kx^2),(ky,y)$$ and I get that the limit is $0$ but according to WA there is not limit , how should I approach this?","$$\lim_{(x,y)\to (0,0)}\frac{x^2}{|x|+|y|}\cos(y^2)$$ I have tried the following paths: $$(x,kx),(x,kx^2),(ky,y)$$ and I get that the limit is $0$ but according to WA there is not limit , how should I approach this?",,"['real-analysis', 'limits', 'multivariable-calculus']"
96,Prove or disprove: All radial vector fields are conservative,Prove or disprove: All radial vector fields are conservative,,"This was a question a calculus student had asked me, and unfortunately I believe I gave an incorrect proof. DEFINITION : A radial vector field is defined by ${\bf F}(x,y) = g(x,y){\bf r},$ where $g$ is a scalar function and ${\bf r}= \langle x,y\rangle$ is a vector. At the time, I did not know the complete definition of a radial vector field. I proved it like so: PROOF : Let $a,b\in\mathbb R$. Take ${\bf F}(x,y) = ax{\mathrm i} + by\mathrm j$. Consider the function $f(x,y) = {1\over2}ax^2 + {1\over2}by^2$. Then clearly $\nabla f(x,y) = ax\mathrm i + by\mathrm j = {\bf F}(x,y)$, hence all radial vector fields are conservative. However, this is not correct because it only works for fixed constants $a,b$. For a general function $g(x,y)$, what might we be able to do? The more I think about it, the less I think the conjecture is true but I can't think of a counter example.","This was a question a calculus student had asked me, and unfortunately I believe I gave an incorrect proof. DEFINITION : A radial vector field is defined by ${\bf F}(x,y) = g(x,y){\bf r},$ where $g$ is a scalar function and ${\bf r}= \langle x,y\rangle$ is a vector. At the time, I did not know the complete definition of a radial vector field. I proved it like so: PROOF : Let $a,b\in\mathbb R$. Take ${\bf F}(x,y) = ax{\mathrm i} + by\mathrm j$. Consider the function $f(x,y) = {1\over2}ax^2 + {1\over2}by^2$. Then clearly $\nabla f(x,y) = ax\mathrm i + by\mathrm j = {\bf F}(x,y)$, hence all radial vector fields are conservative. However, this is not correct because it only works for fixed constants $a,b$. For a general function $g(x,y)$, what might we be able to do? The more I think about it, the less I think the conjecture is true but I can't think of a counter example.",,"['calculus', 'multivariable-calculus', 'proof-writing', 'vectors', 'fake-proofs']"
97,Volume of Intersection of Surfaces,Volume of Intersection of Surfaces,,I hope you can help me with this: What's the volume which is enclosed by the equation $(x^2+y^2+z^2)^2=z(x^2+y^2)$? Whenever I try to calculate the intersection of those surfaces I get lost because I arrive to a 4-degree equation. Thanks!,I hope you can help me with this: What's the volume which is enclosed by the equation $(x^2+y^2+z^2)^2=z(x^2+y^2)$? Whenever I try to calculate the intersection of those surfaces I get lost because I arrive to a 4-degree equation. Thanks!,,"['geometry', 'multivariable-calculus', 'volume']"
98,Trouble with the derivation of the Reynolds Transport Theorem,Trouble with the derivation of the Reynolds Transport Theorem,,"I have been trying to reconcile two different forms of the Reynolds Transport Theorem (RTT) that I have seen in textbooks. The first form comes from a finite volume method cfd textbook. It directly relates the rate of change of a property within a material volume (MV) to some integrals of an associated control volume (CV). I did not understand how they arrived at this form and was trying to derive it myself from the more well know form of RTT (described in paragraph below). The second RTT form I think is much more common, particularly from a math perspective.  $$ \label(1)~~~~~~~~~~~~\frac{d}{dt} \int_{V(t)} F ~dV  = \int_{V(t)} \frac{\partial F}{\partial t} ~dV   ~+ \int_{A(t)} F\mathbf b \cdot \mathbf n  ~dV $$ where V is an arbitrary volume bounded by surface A. F is the (scalar in this case) field of interest, b is the velocity of the surface A and n is the normal vector for the surface A. All of these quantities are in general variable, both spatially and temporally. My understanding is that this second form of the RTT (eqn 2) can be applied to both a material volume (MV) as well as any arbitrary control volume (CV) (this is done in some derivations of the continuity equation I have been looking at. So now we have both $$ 2)~~~~~~~~~~~~ \frac{d}{dt} \int_{MV(t)} F ~dV  = \int_{MV(t)} \frac{\partial F}{\partial t} ~dV   ~+ \int_{A_{MV}(t)} F\mathbf u \cdot \mathbf n  ~dV $$ (In the case of the material volume analysis the velocity of the surface A (i.e. b ) is equal to the fluid velocity u ) And $$ 3)~~~~~~~~~~~~\frac{d}{dt} \int_{CV(t)} F ~dV  = \int_{CV(t)} \frac{\partial F}{\partial t} ~dV   ~+ \int_{A_{CV}(t)} F\mathbf b \cdot \mathbf n  ~dV $$ Now borrowing again from the derivation of the continuity equation and assuming that the two volumes CV and MV are instantaneously coincident we can draw some conclusions. Obviously the first terms of eqns 2 and 3 are not, in general, equal even with CV and MV coincident. However if MV is the same as CV even temporarily then the second terms from each equation should be equal $$ 4)~~~~~~~~~\int_{MV(t)} \frac{\partial F}{\partial t} ~dV  = \int_{CV(t)} \frac{\partial F}{\partial t} ~dV $$ Additionally the third term of equation 2 can be rewritten in terms of an integral over CV rather than MV. $$ 5)~~~~~~~ \int_{A_{MV}(t)} F\mathbf u \cdot \mathbf n  ~dV = \int_{A_{CV}(t)} F\mathbf u \cdot \mathbf n  ~dV$$ In an effort to derive the first form of the RTT described earlier I substituted eqns. 4 and 5 into 2 to arrive at $$ 6)~~~~~~~~~~~~ \frac{d}{dt} \int_{MV(t)} F ~dV  = \int_{CV(t)} \frac{\partial F}{\partial t} ~dV   ~+ \int_{A_{CV}(t)} F\mathbf u \cdot \mathbf n  ~dV $$ So now we have the rate of change of the field inside the material volume described by integrals over the control volume but I feel like it is absolute non-sense for several reasons. The most evident reason being that there is now no reliance at all on b which was never assumed to be zero and should therefore play a role I think in this final equation. So my question FINALLY is what did I do wrong here? Equating the integrals (MV and CV) when the volumes coincide is right out of the textbook derivation of the continuity equation so I feel okay about that.","I have been trying to reconcile two different forms of the Reynolds Transport Theorem (RTT) that I have seen in textbooks. The first form comes from a finite volume method cfd textbook. It directly relates the rate of change of a property within a material volume (MV) to some integrals of an associated control volume (CV). I did not understand how they arrived at this form and was trying to derive it myself from the more well know form of RTT (described in paragraph below). The second RTT form I think is much more common, particularly from a math perspective.  $$ \label(1)~~~~~~~~~~~~\frac{d}{dt} \int_{V(t)} F ~dV  = \int_{V(t)} \frac{\partial F}{\partial t} ~dV   ~+ \int_{A(t)} F\mathbf b \cdot \mathbf n  ~dV $$ where V is an arbitrary volume bounded by surface A. F is the (scalar in this case) field of interest, b is the velocity of the surface A and n is the normal vector for the surface A. All of these quantities are in general variable, both spatially and temporally. My understanding is that this second form of the RTT (eqn 2) can be applied to both a material volume (MV) as well as any arbitrary control volume (CV) (this is done in some derivations of the continuity equation I have been looking at. So now we have both $$ 2)~~~~~~~~~~~~ \frac{d}{dt} \int_{MV(t)} F ~dV  = \int_{MV(t)} \frac{\partial F}{\partial t} ~dV   ~+ \int_{A_{MV}(t)} F\mathbf u \cdot \mathbf n  ~dV $$ (In the case of the material volume analysis the velocity of the surface A (i.e. b ) is equal to the fluid velocity u ) And $$ 3)~~~~~~~~~~~~\frac{d}{dt} \int_{CV(t)} F ~dV  = \int_{CV(t)} \frac{\partial F}{\partial t} ~dV   ~+ \int_{A_{CV}(t)} F\mathbf b \cdot \mathbf n  ~dV $$ Now borrowing again from the derivation of the continuity equation and assuming that the two volumes CV and MV are instantaneously coincident we can draw some conclusions. Obviously the first terms of eqns 2 and 3 are not, in general, equal even with CV and MV coincident. However if MV is the same as CV even temporarily then the second terms from each equation should be equal $$ 4)~~~~~~~~~\int_{MV(t)} \frac{\partial F}{\partial t} ~dV  = \int_{CV(t)} \frac{\partial F}{\partial t} ~dV $$ Additionally the third term of equation 2 can be rewritten in terms of an integral over CV rather than MV. $$ 5)~~~~~~~ \int_{A_{MV}(t)} F\mathbf u \cdot \mathbf n  ~dV = \int_{A_{CV}(t)} F\mathbf u \cdot \mathbf n  ~dV$$ In an effort to derive the first form of the RTT described earlier I substituted eqns. 4 and 5 into 2 to arrive at $$ 6)~~~~~~~~~~~~ \frac{d}{dt} \int_{MV(t)} F ~dV  = \int_{CV(t)} \frac{\partial F}{\partial t} ~dV   ~+ \int_{A_{CV}(t)} F\mathbf u \cdot \mathbf n  ~dV $$ So now we have the rate of change of the field inside the material volume described by integrals over the control volume but I feel like it is absolute non-sense for several reasons. The most evident reason being that there is now no reliance at all on b which was never assumed to be zero and should therefore play a role I think in this final equation. So my question FINALLY is what did I do wrong here? Equating the integrals (MV and CV) when the volumes coincide is right out of the textbook derivation of the continuity equation so I feel okay about that.",,"['multivariable-calculus', 'fluid-dynamics']"
99,"Find an equation for the surface with all points which are equidistant of $(-1,0,0)$ and the plane $x=1$",Find an equation for the surface with all points which are equidistant of  and the plane,"(-1,0,0) x=1","Find an equation for the surface with all points which are equidistant of $(-1,0,0)$ and the plane $x=1$. Draw the surface. First, this is the graph I've depicted: Some ideas to find such equation and the corresponding graph for the surface?","Find an equation for the surface with all points which are equidistant of $(-1,0,0)$ and the plane $x=1$. Draw the surface. First, this is the graph I've depicted: Some ideas to find such equation and the corresponding graph for the surface?",,['multivariable-calculus']
