,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Expressing $\mathbb{R} P^3$ as a fibre bundle,Expressing  as a fibre bundle,\mathbb{R} P^3,"This question came up in office hours with my differential topology prof and since then I've almost settled on an answer. The question was whether we could write $\mathbb{R} P^3$ as a fiber bundle with base space $\mathbb{R} P^2$. We spent a few moments thinking about it before deciding it wasn't relevant to the conversation at hand and moved on. Since then I've done some reading and become aware of a result that says if $M, N$ are compact and connected smooth manifolds and $f:M\rightarrow N$ is a submersion, then the fibers of $f$ are all diffeomorphic to a manifold $F$, and this gives rise to a fibre bundle with total space $M$, fiber $F$ and base $N$. Following that, I wrote a function $$f: \mathbb{R}P^3 \rightarrow  \mathbb{R}P^2$$ defined on homogeneous coordinates by $$(x,y,z,w) \mapsto (x,y,z).$$ $f$ is well-defined, smooth, and unless I've made a silly mistake in calculating Jacobians it's also a submersion. Now, I'm having trouble understanding what the preimage $f^{-1}(p)$ for $p \in \mathbb{R}P^2$ is. Is it simply $\mathbb{R}$ or is it something more complicated than that?","This question came up in office hours with my differential topology prof and since then I've almost settled on an answer. The question was whether we could write $\mathbb{R} P^3$ as a fiber bundle with base space $\mathbb{R} P^2$. We spent a few moments thinking about it before deciding it wasn't relevant to the conversation at hand and moved on. Since then I've done some reading and become aware of a result that says if $M, N$ are compact and connected smooth manifolds and $f:M\rightarrow N$ is a submersion, then the fibers of $f$ are all diffeomorphic to a manifold $F$, and this gives rise to a fibre bundle with total space $M$, fiber $F$ and base $N$. Following that, I wrote a function $$f: \mathbb{R}P^3 \rightarrow  \mathbb{R}P^2$$ defined on homogeneous coordinates by $$(x,y,z,w) \mapsto (x,y,z).$$ $f$ is well-defined, smooth, and unless I've made a silly mistake in calculating Jacobians it's also a submersion. Now, I'm having trouble understanding what the preimage $f^{-1}(p)$ for $p \in \mathbb{R}P^2$ is. Is it simply $\mathbb{R}$ or is it something more complicated than that?",,"['differential-geometry', 'differential-topology', 'projective-space', 'fiber-bundles']"
1,Is every fibre bundle a G-bundle?,Is every fibre bundle a G-bundle?,,"By definition of a fibre bundle $F\hookrightarrow E\xrightarrow \pi B$ every point $p\in B$ has a neighbourhood $U$ such that there exists a diffeomorphism (local trivialization)  $\phi: \pi^{-1} (U)\rightarrow U\times F$. Looking at local trivializations over overlapping open sets $U_i$, $U_j$ one can consider the map $\phi_j\circ\phi_i^{-1}:U_i\cap U_j\times F\rightarrow U_i\cap U_j\times F$, $\phi_j\circ\phi_i^{-1}(x,u)=(x,t_{ji}(x,u))$, with $t_{ji}(x,\cdot):F\rightarrow F$ a diffeomorphism. It follows from the definitions that $t_{ij}(x,t_{ji}(x,u))=u$. Similarly by considering triple intersections one has  $t_{ij} (x,t_{jk}(x,u))=t_{ik}(x,u)$. Usually in the literature a fiber bundle is called a $G$-bundle, or said to have structure group $G$, if it exists a group $G$ such that $t_{ij}(x,u)=\tau_{ij}(x)\cdot u$ with $\tau_{ij}(x)\in G$ and $\cdot$ denoting a left action of $G$ on $F$. Take $G=\mathrm{Diff}(F)$, the group of diffeomorphisms of $F$, acting on $u\in F$ as $(\phi,u)\in \mathrm{Diff}(F)\times F\mapsto \phi(u)$. If $t_{ij}(x,u)=u^\prime$, define $\tau_{ij}(x)=\phi$, where $\phi$ is any element of $\mathrm{Diff}(F)$ such that $\phi(u)=u^\prime$. Doesn't this give $F\hookrightarrow E\xrightarrow \pi B$ the structure of a $G$-bundle? In other words, isn't every fiber bundle a $G$-bundle if I take $G$ to be the group of diffeomorphisms of the fibre?","By definition of a fibre bundle $F\hookrightarrow E\xrightarrow \pi B$ every point $p\in B$ has a neighbourhood $U$ such that there exists a diffeomorphism (local trivialization)  $\phi: \pi^{-1} (U)\rightarrow U\times F$. Looking at local trivializations over overlapping open sets $U_i$, $U_j$ one can consider the map $\phi_j\circ\phi_i^{-1}:U_i\cap U_j\times F\rightarrow U_i\cap U_j\times F$, $\phi_j\circ\phi_i^{-1}(x,u)=(x,t_{ji}(x,u))$, with $t_{ji}(x,\cdot):F\rightarrow F$ a diffeomorphism. It follows from the definitions that $t_{ij}(x,t_{ji}(x,u))=u$. Similarly by considering triple intersections one has  $t_{ij} (x,t_{jk}(x,u))=t_{ik}(x,u)$. Usually in the literature a fiber bundle is called a $G$-bundle, or said to have structure group $G$, if it exists a group $G$ such that $t_{ij}(x,u)=\tau_{ij}(x)\cdot u$ with $\tau_{ij}(x)\in G$ and $\cdot$ denoting a left action of $G$ on $F$. Take $G=\mathrm{Diff}(F)$, the group of diffeomorphisms of $F$, acting on $u\in F$ as $(\phi,u)\in \mathrm{Diff}(F)\times F\mapsto \phi(u)$. If $t_{ij}(x,u)=u^\prime$, define $\tau_{ij}(x)=\phi$, where $\phi$ is any element of $\mathrm{Diff}(F)$ such that $\phi(u)=u^\prime$. Doesn't this give $F\hookrightarrow E\xrightarrow \pi B$ the structure of a $G$-bundle? In other words, isn't every fiber bundle a $G$-bundle if I take $G$ to be the group of diffeomorphisms of the fibre?",,"['differential-geometry', 'fiber-bundles']"
2,Integration of a $2$-form,Integration of a -form,2,"What is $$\int_C{\omega}$$ where $\omega=\frac{dx \wedge dy}{x^2+y^2}$ and $C(t_1,t_2)=(t_1+1)(\cos(2\pi t_2),\sin(2\pi t_2)) : I_2 \rightarrow \mathbb{R}^2 - \text{{(0,0)}}$ ? The integrals of $1$ -forms I understood as we take $dx$ and $dy$ as the derivatives of the parametrisation $C(t)$ w.r.t $t$ . However for $2$ -forms we now have the wedge product $dx \wedge dy$ which is where my problem lies in this question. Is this a matter of differentiation in two variables when computing this wedge? For example, before even calculating the wedge product, what is $dx(t_1,t_2)$ ? The denominator isn't a problem: $x^2+y^2 = (t_1+1)^2$","What is where and ? The integrals of -forms I understood as we take and as the derivatives of the parametrisation w.r.t . However for -forms we now have the wedge product which is where my problem lies in this question. Is this a matter of differentiation in two variables when computing this wedge? For example, before even calculating the wedge product, what is ? The denominator isn't a problem:","\int_C{\omega} \omega=\frac{dx \wedge dy}{x^2+y^2} C(t_1,t_2)=(t_1+1)(\cos(2\pi t_2),\sin(2\pi t_2)) : I_2 \rightarrow \mathbb{R}^2 - \text{{(0,0)}} 1 dx dy C(t) t 2 dx \wedge dy dx(t_1,t_2) x^2+y^2 = (t_1+1)^2","['differential-geometry', 'manifolds', 'differential-forms']"
3,Definition of a $n$ - form on a manifold,Definition of a  - form on a manifold,n,"I am confused about the definition of a differential form on a manifold. The definition I have comes from Bott and Tu and is as follows: A differential form, $\omega$, on a manifold $M$ is a collection of forms $\omega_U$ for $U$ in the atlas defining $M$, which are compatible in the following sense: $i^*\omega_U=j^*\omega_V$ where $i,j$ are the inclusion maps. I am confused as to what exactly $\omega_u$ is. Is it the pull back by a chart of a form on Euclidean space? Moreover, how can I fail the compatibility criterion? It seems to me like it should always be true. I think I simple example would really help me understand but I can't find one. Thanks for your help,","I am confused about the definition of a differential form on a manifold. The definition I have comes from Bott and Tu and is as follows: A differential form, $\omega$, on a manifold $M$ is a collection of forms $\omega_U$ for $U$ in the atlas defining $M$, which are compatible in the following sense: $i^*\omega_U=j^*\omega_V$ where $i,j$ are the inclusion maps. I am confused as to what exactly $\omega_u$ is. Is it the pull back by a chart of a form on Euclidean space? Moreover, how can I fail the compatibility criterion? It seems to me like it should always be true. I think I simple example would really help me understand but I can't find one. Thanks for your help,",,"['differential-geometry', 'algebraic-topology', 'manifolds', 'differential-topology', 'definition']"
4,On sections of the tangent bundle of a Grassmannian,On sections of the tangent bundle of a Grassmannian,,"Being more familiar with linear operators than with geometry, I like to see $G_K(r,n)$ , the Grassmannian of all $r$ dimensional subspaces in $K^{r+n}$ ( $K=\mathbb{R}, \mathbb{C}$ ), as the set of all rank $k$ projections (self-adjoint idempotents) in $M_n(K)$ . And I am also interested in the infinite-dimensional Grassmannians sitting in $B(H)$ , the algebra of bounded linear operators on a separable infinite-dimensional $K$ Hilbert space. In the latter, the projections split into connected components according to their rank and their nullity. These are smooth manifolds, but modelled on an infinite-dimensional (for $r\neq 0$ and $n\neq 0$ ) Banach space. They are the infinite-dimensional analogues of the above. I cheated with the usual notations to include the latter: for instance, $G_\mathbb{C}(3,\infty)$ corresponds to the rank $3$ projections in $B(H)$ . Thinking about some linear questions, I ended up being interested in the following: does there exist a nowhere vanishing section of the tangent bundle of $G_K(r,n)$ ? The two cases I am really comfortable with are $G_\mathbb{R}(1,1)$ (yes, that's $S^1$ and the tangent bundle is trivial), and $G_\mathbb{C}(1,1)$ (no, by the hairy ball theorem since it is $S^2$ ). I vaguely know that under some conditions, the tangent bundle of a manifold admits a nowhere vanishing section if and only if its Euler class (or should  say number?) is zero. And that under some conditions, this coincides with the Euler characteristic of the manifold. Questions: 1 - What is a precise statement and set of conditions for the latter, hopefully applying to the (possibly infinite-dimensional) Grassmannians? 2 - If it applies, what are the relevant Euler invariants (characteristic/class/number) for $G_K(r,n)$ ? After a lot of googling, I think I found $\binom{r+n}{r}$ in the complex case (without being sure because I am having a hard time understanding the geometric language). Is this true? What does the number mean exactly? What about the real case? What about the infinite-dimensional case? 3 - Ultimately, I am mostly interested in knowing when I can say that any section of the tangent bundle of $G_K(r,n)$ must vanish, and how to justify it properly. Could you clarify this for me? 4 - I think it is about time for me to understand these things. Do you know a friendly reference for someone who has a lot of difficulty with geometry? Thank you. Edit: forget the infinite-dimensional analogue. In $B(H)$ , the unitary group is much less twisted than in $M_n$ . A famous theorem of Kuiper shows that it is contractible. If I am not mistaken, this entails that the Grassmannians of $B(H)$ have a trivial tangent bundle.","Being more familiar with linear operators than with geometry, I like to see , the Grassmannian of all dimensional subspaces in ( ), as the set of all rank projections (self-adjoint idempotents) in . And I am also interested in the infinite-dimensional Grassmannians sitting in , the algebra of bounded linear operators on a separable infinite-dimensional Hilbert space. In the latter, the projections split into connected components according to their rank and their nullity. These are smooth manifolds, but modelled on an infinite-dimensional (for and ) Banach space. They are the infinite-dimensional analogues of the above. I cheated with the usual notations to include the latter: for instance, corresponds to the rank projections in . Thinking about some linear questions, I ended up being interested in the following: does there exist a nowhere vanishing section of the tangent bundle of ? The two cases I am really comfortable with are (yes, that's and the tangent bundle is trivial), and (no, by the hairy ball theorem since it is ). I vaguely know that under some conditions, the tangent bundle of a manifold admits a nowhere vanishing section if and only if its Euler class (or should  say number?) is zero. And that under some conditions, this coincides with the Euler characteristic of the manifold. Questions: 1 - What is a precise statement and set of conditions for the latter, hopefully applying to the (possibly infinite-dimensional) Grassmannians? 2 - If it applies, what are the relevant Euler invariants (characteristic/class/number) for ? After a lot of googling, I think I found in the complex case (without being sure because I am having a hard time understanding the geometric language). Is this true? What does the number mean exactly? What about the real case? What about the infinite-dimensional case? 3 - Ultimately, I am mostly interested in knowing when I can say that any section of the tangent bundle of must vanish, and how to justify it properly. Could you clarify this for me? 4 - I think it is about time for me to understand these things. Do you know a friendly reference for someone who has a lot of difficulty with geometry? Thank you. Edit: forget the infinite-dimensional analogue. In , the unitary group is much less twisted than in . A famous theorem of Kuiper shows that it is contractible. If I am not mistaken, this entails that the Grassmannians of have a trivial tangent bundle.","G_K(r,n) r K^{r+n} K=\mathbb{R}, \mathbb{C} k M_n(K) B(H) K r\neq 0 n\neq 0 G_\mathbb{C}(3,\infty) 3 B(H) G_K(r,n) G_\mathbb{R}(1,1) S^1 G_\mathbb{C}(1,1) S^2 G_K(r,n) \binom{r+n}{r} G_K(r,n) B(H) M_n B(H)","['differential-geometry', 'vector-bundles']"
5,Transition functions of trivial vector bundle,Transition functions of trivial vector bundle,,"I have a question on trivial vector bundles. The question is as follows: Can we characterize the transition functions of a trivial vector   bundle in some way? To be very concrete: suppose we have a vector bundle $E$, say of rank $3$, on an algebraic variety $X$ (or manifold if you prefer), and  we look at trivial sub-bundles $0\to F\to E$ of rank $2$. What can we say about the transition functions of $F$ if we know those of $E$? In this particular circumstance, we do have $3\times 3$ matrices at hand, and we want to produce $2\times 2$ matrices. The question is which ones are good. At the beginning, I thought I could extend an argument of pure linear algebra: if we have an exact sequence of vector spaces $0\to V\to W\to W/V\to 0$, we can complete a basis $(e_1,e_2)$ of $V$ to a basis $(e_1,e_2,e_3)$ of $W$, so that $W\to W/V$ is represented by the row vector $e_3$ and $V\to W$ by the $3\times 2$ matrix containing $e_1,e_2$ written as columns. This didn't bring me anywhere, even because I can't figure how to use the triviality hypothesis.","I have a question on trivial vector bundles. The question is as follows: Can we characterize the transition functions of a trivial vector   bundle in some way? To be very concrete: suppose we have a vector bundle $E$, say of rank $3$, on an algebraic variety $X$ (or manifold if you prefer), and  we look at trivial sub-bundles $0\to F\to E$ of rank $2$. What can we say about the transition functions of $F$ if we know those of $E$? In this particular circumstance, we do have $3\times 3$ matrices at hand, and we want to produce $2\times 2$ matrices. The question is which ones are good. At the beginning, I thought I could extend an argument of pure linear algebra: if we have an exact sequence of vector spaces $0\to V\to W\to W/V\to 0$, we can complete a basis $(e_1,e_2)$ of $V$ to a basis $(e_1,e_2,e_3)$ of $W$, so that $W\to W/V$ is represented by the row vector $e_3$ and $V\to W$ by the $3\times 2$ matrix containing $e_1,e_2$ written as columns. This didn't bring me anywhere, even because I can't figure how to use the triviality hypothesis.",,"['algebraic-geometry', 'differential-geometry', 'vector-bundles']"
6,Visualize soliton solutions of a PDE,Visualize soliton solutions of a PDE,,"In trying to visualize soliton solutions of a PDE I faced this sentence: We now think of solitons as self-similar solutions, i.e., solutions which evolve along symmetries of the flow. Question 1: Which solutions are called ""self-similar solutions""? Question 2: What is the meaning of ""symmetries of the flow""? and How can one find them in PDEs? Thanks in advance.","In trying to visualize soliton solutions of a PDE I faced this sentence: We now think of solitons as self-similar solutions, i.e., solutions which evolve along symmetries of the flow. Question 1: Which solutions are called ""self-similar solutions""? Question 2: What is the meaning of ""symmetries of the flow""? and How can one find them in PDEs? Thanks in advance.",,"['differential-geometry', 'partial-differential-equations']"
7,Motivation for the study of the Chern connection,Motivation for the study of the Chern connection,,"Given a Hermitian metric $H$ over a holomorphic vector bundle $E$ with holomorphic structure $\overline{\partial}$, there exists a unique connection $\nabla$ (named afer Chern) satisying the following conditions: 1) $\nabla$ is a $H$-connection, i.e H is parallel with respect to $\nabla$, 2) $\nabla^{0,1} = \overline{\partial}$ My question is, what motivates all this? Do you know any application of this? I mean not only in other fields, I am interested also in its role in geometry. Thank you all for your invaluable help!","Given a Hermitian metric $H$ over a holomorphic vector bundle $E$ with holomorphic structure $\overline{\partial}$, there exists a unique connection $\nabla$ (named afer Chern) satisying the following conditions: 1) $\nabla$ is a $H$-connection, i.e H is parallel with respect to $\nabla$, 2) $\nabla^{0,1} = \overline{\partial}$ My question is, what motivates all this? Do you know any application of this? I mean not only in other fields, I am interested also in its role in geometry. Thank you all for your invaluable help!",,"['differential-geometry', 'applications']"
8,Covariant derivative of tensor in terms of local coordinates,Covariant derivative of tensor in terms of local coordinates,,"Let $f:U \to \mathbb{R}^3$ be a surface with local coordinates $f_i=\frac{\partial f}{\partial u^i}$. Let $\omega$ be a one-form. I want to express $\nabla \omega$ in terms of local coordinates and Christoffel symboles. Where $\nabla$ is the Levi-Civita connection (thus it coincides with the covariant derivative). Let $X=X^if_i,Y=Y^if_i$ be two tangent vector fields on $f$, by definition one has: $$(\nabla_X \omega)(Y)=X^i \frac{\partial (\omega(Y))}{\partial u^i}-\omega (\nabla_XY)=X^i \frac{\partial (\omega(Y^if_i))}{\partial u^i}-\omega(\nabla_{X^if_i} Y^if_i)$$ One has $$\omega(\nabla_{X^if_i} Y^if_i)=\omega (X^i[Y^{j}(\nabla_{f_i}f_j)+Y^{j}_{,i}f_j])=\omega (X^i[Y^{j}(\Gamma^{k}_{ij}f_{k})+Y^{j}_{,i}f_j])=X^{i}Y^{j}\Gamma^{k}_{ij} \omega (f_k)+X^iY^i_{,i} \omega_{j}$$ now to compute $\frac{\partial (\omega(Y^jf_j))}{\partial u^i}=Y^{j}_{,i} \omega_{j}+Y^{j} \omega_{j,i}$,where $\omega_{i}=\omega (f_i)$. Therefore $(\nabla_X \omega)(Y)=X^iY^j(\omega_{j,i}-\Gamma^{k}_{ij} \omega_k)$ Is there a way to simplify further?","Let $f:U \to \mathbb{R}^3$ be a surface with local coordinates $f_i=\frac{\partial f}{\partial u^i}$. Let $\omega$ be a one-form. I want to express $\nabla \omega$ in terms of local coordinates and Christoffel symboles. Where $\nabla$ is the Levi-Civita connection (thus it coincides with the covariant derivative). Let $X=X^if_i,Y=Y^if_i$ be two tangent vector fields on $f$, by definition one has: $$(\nabla_X \omega)(Y)=X^i \frac{\partial (\omega(Y))}{\partial u^i}-\omega (\nabla_XY)=X^i \frac{\partial (\omega(Y^if_i))}{\partial u^i}-\omega(\nabla_{X^if_i} Y^if_i)$$ One has $$\omega(\nabla_{X^if_i} Y^if_i)=\omega (X^i[Y^{j}(\nabla_{f_i}f_j)+Y^{j}_{,i}f_j])=\omega (X^i[Y^{j}(\Gamma^{k}_{ij}f_{k})+Y^{j}_{,i}f_j])=X^{i}Y^{j}\Gamma^{k}_{ij} \omega (f_k)+X^iY^i_{,i} \omega_{j}$$ now to compute $\frac{\partial (\omega(Y^jf_j))}{\partial u^i}=Y^{j}_{,i} \omega_{j}+Y^{j} \omega_{j,i}$,where $\omega_{i}=\omega (f_i)$. Therefore $(\nabla_X \omega)(Y)=X^iY^j(\omega_{j,i}-\Gamma^{k}_{ij} \omega_k)$ Is there a way to simplify further?",,"['differential-geometry', 'manifolds', 'differential-forms']"
9,Examples of qualities intrinsic vs extrinsic to a surface besides Gaussian Curvature,Examples of qualities intrinsic vs extrinsic to a surface besides Gaussian Curvature,,"Gauss's Theorema Egregium states that Gaussian curvature is intrinsic to a surface, meaning that it can be ""measured inside of the surface"". However I can't make sense of what this really means. What are other quantities that can be measured inside a surface? Are there quantities that can only be measured outside a surface?","Gauss's Theorema Egregium states that Gaussian curvature is intrinsic to a surface, meaning that it can be ""measured inside of the surface"". However I can't make sense of what this really means. What are other quantities that can be measured inside a surface? Are there quantities that can only be measured outside a surface?",,"['differential-geometry', 'curvature']"
10,The extension of diffeomorphism,The extension of diffeomorphism,,"Let ${\Omega _1}$,${\Omega _2}$ be two open sets in $\mathbb R^n$ and $f$ is a diffeomorphism between them. For every $x$ in ${\Omega _1}$, is there an open set $\Omega_{x} \subset \Omega_1$ and a diffeomorphism $g$ of $\mathbb R^n$ such that $g=f$ when restricted to $\Omega_{x}$?","Let ${\Omega _1}$,${\Omega _2}$ be two open sets in $\mathbb R^n$ and $f$ is a diffeomorphism between them. For every $x$ in ${\Omega _1}$, is there an open set $\Omega_{x} \subset \Omega_1$ and a diffeomorphism $g$ of $\mathbb R^n$ such that $g=f$ when restricted to $\Omega_{x}$?",,['differential-geometry']
11,Tori and metrics,Tori and metrics,,"I have been doing some reading on tori. What I can make out of it is that a torus can be equipped with different metrics -- locally Euclidean or as an embedded surface. It is said however that the torus with the locally Euclidean metric cannot be realized as an embedded surface. Why is this true and what is the metric as an embedded surface like? Why would we want the latter metric, since it seems to me the former is more natural? Thanks.","I have been doing some reading on tori. What I can make out of it is that a torus can be equipped with different metrics -- locally Euclidean or as an embedded surface. It is said however that the torus with the locally Euclidean metric cannot be realized as an embedded surface. Why is this true and what is the metric as an embedded surface like? Why would we want the latter metric, since it seems to me the former is more natural? Thanks.",,"['differential-geometry', 'metric-spaces']"
12,"extension/""globalization"" of inverse function theorem","extension/""globalization"" of inverse function theorem",,"I am curious as to what changes do we need to make to the hypotheses of the inverse function theorem in order to be able to find the global differentiable inverse to a differentiable function. We obviously need $f$ to be a bijection, and $f'$ to be non-zero. Is this sufficient for the existence of a global differentiable inverse? For functions $f\colon\mathbb{R}\to\mathbb{R}$, we have Motivation: $f^{-1}(f(x))=x$, so $(f')^{-1}(f(x))f'(x)=1$ Then, we could define $(f')^{^-1}(f(x))$ to be $1/f'(x)$   ( this is the special case of the formula for the differentiable inverse -- when it exists -- in the IFT) (and we are assumming $f'(x)\neq 0$) In the case of $\mathbb{R}^2$, I guess we could think of all the branches of $\log z$ and $\exp z$, and we do have at least a branch-wise global inverse , i.e., if/when $\exp z$ is 1-1 (and it is , of course onto $\mathbb{C}-{0}$), then we have a differentiable inverse. I guess my question would be: once the conditions of the IFT are satisfied: in how big of a neighborhood of $x$ can we define this local diffeomorphism, and, in which case would this neighborhood be the entire domain of definition of $f$? I guess the case for manifolds would be a generalization of the case of $\mathbb{R}^n$, but it seems like we would need for the manifolds to have a single chart. So, are the conditions of f being a bijective, differentiable map sufficient for the existence of a global differentiable inverse? And, if $f$ is differentiable, but not bijective,  does the IFT hold in the largest subset of the domain of definition of $f$ where $f$ is a bijection? Thanks.","I am curious as to what changes do we need to make to the hypotheses of the inverse function theorem in order to be able to find the global differentiable inverse to a differentiable function. We obviously need $f$ to be a bijection, and $f'$ to be non-zero. Is this sufficient for the existence of a global differentiable inverse? For functions $f\colon\mathbb{R}\to\mathbb{R}$, we have Motivation: $f^{-1}(f(x))=x$, so $(f')^{-1}(f(x))f'(x)=1$ Then, we could define $(f')^{^-1}(f(x))$ to be $1/f'(x)$   ( this is the special case of the formula for the differentiable inverse -- when it exists -- in the IFT) (and we are assumming $f'(x)\neq 0$) In the case of $\mathbb{R}^2$, I guess we could think of all the branches of $\log z$ and $\exp z$, and we do have at least a branch-wise global inverse , i.e., if/when $\exp z$ is 1-1 (and it is , of course onto $\mathbb{C}-{0}$), then we have a differentiable inverse. I guess my question would be: once the conditions of the IFT are satisfied: in how big of a neighborhood of $x$ can we define this local diffeomorphism, and, in which case would this neighborhood be the entire domain of definition of $f$? I guess the case for manifolds would be a generalization of the case of $\mathbb{R}^n$, but it seems like we would need for the manifolds to have a single chart. So, are the conditions of f being a bijective, differentiable map sufficient for the existence of a global differentiable inverse? And, if $f$ is differentiable, but not bijective,  does the IFT hold in the largest subset of the domain of definition of $f$ where $f$ is a bijection? Thanks.",,[]
13,Leibniz rule for wedge product of differential forms with values in associated vector bundles,Leibniz rule for wedge product of differential forms with values in associated vector bundles,,"Before stating the claim, let my define all the objects which I need: To start with, let me fix notation: Let $P$ be a principal $G$ -bundle over a (smooth, compact, oriented) manifold $\mathcal{M}$ (possibly with boundary) and $\mathfrak{g}$ be the Lie algebra of $G$ . Furthemore, let us choose a connection $1$ -form $A\in\Omega^{1}(P,\mathfrak{g})$ . Let $(V,\rho)$ be a (finite-dimensional real/complex) representation of $G$ and $E:=P\times_{\rho} V$ be the associated vector bundle. Let $\langle\cdot,\cdot\rangle_{V}$ be a non-degenerate symmetric bilinear form on $V$ . Then it is a general fact that this induces a bundle metric $\langle\cdot,\cdot\rangle_{E}\in\Gamma(E^{\ast}\otimes E^{\ast})$ on $E$ via $$\langle [p,v],[p,w]\rangle_{E_{x}}:=\langle v,w\rangle_{V}$$ for all $x\in\mathcal{M}$ and for all $[p,v],[p,w]\in E_{x}\cong P_{x}\times_{\rho}V$ . Furthermore, I need two further definitions: First of all, the wedge-product $\mathrm{tr}(\cdot\wedge\cdot):\Omega^{k}(\mathcal{M},E)\times\Omega^{l}(\mathcal{M},E)\to\Omega^{k+l}(\mathcal{M})$ is defined in the obvious way, i.e. $$\mathrm{tr}(\alpha\wedge\beta)_{x}(v_{1},\dots,v_{k+l}):=\frac{1}{k!l!}\sum_{\sigma\in\mathfrak{S}^{k+l}}\mathrm{sgn}(\sigma)\langle \alpha_{x}(v_{\sigma(1)},\dots,v_{\sigma(k)}),\beta_{x}(v_{\sigma(k+1)},\dots,v_{\sigma(k+l)})\rangle_{E_{x}}$$ for all $x\in\mathcal{M}$ and for all $v_{1},\dots,v_{k+l}\in T_{x}\mathcal{M}$ . Secondly, I need the ""exterior covariant derivative induced by a connection 1-form $A$ "", which is the exterior covariant derivative induced by a connection $\nabla^{A}$ on $E$ , whose definition is not so important right now. This is a map $\mathrm{d}_{A}:\Omega^{k}(\mathcal{M},E)\to\Omega^{k+1}(\mathcal{M},E)$ defined using a local frame $\{e_{a}\}_{a}\subset\Gamma(U,E)$ defined on some open set $U\subset\mathcal{M}$ via $$\mathrm{d}_{A}\alpha\vert_{U}:=\sum_{a}(\mathrm{d}\alpha^{a}e_{a}+(-1)^{k}\alpha^{a}\wedge\nabla^{A}e_{a})$$ where $\alpha\vert_{U}=\sum_{a}\alpha^{a}e_{a}$ for coordinates $\alpha^{a}\in\Omega^{k}(U)$ . (Strictly speaking, I should write $\alpha^{a}\otimes e_{a}$ , but let me keep notation simple) Now I would like to prove the following: $$\mathrm{d}(\mathrm{tr}(\alpha\wedge\beta))=\mathrm{tr}(\mathrm{d}_{A}\alpha\wedge\beta)+(-1)^{k}\mathrm{tr}(\alpha\wedge\mathrm{d}_{A}\beta)$$ I have to say that I am not sure if this is actually true in this form. It is rather an educated  guess. For context, the reason for this is that something like this is implicitely used on page $4$ of arXiv:gr-qc/9905087 in the proof of invariance of the BF-action under translational symmetry. (In this context, the bundle $E$ is given by the adjoint bundle $\mathrm{Ad}(P)$ ). In this paper, the authors used ""integration by parts"" for an expression of the type $\mathrm{tr}(\mathrm{d}_{A}\eta\wedge F)$ , where $\eta\in\Omega^{d-3}(\mathcal{M},\mathrm{Ad}(P))$ and where $F\in\Omega^{2}(\mathcal{M},\mathrm{Ad}(P))$ denotes the curvature of $A$ . Now my attempt is the following: I think it is easier to proof this in the local frame on $U$ . Let us write $\alpha\in\Omega^{k}(\mathcal{M},E)$ and $\beta\in\Omega^{l}(\mathcal{M},E)$ in this frame, i.e. $$\alpha\vert_{U}=\sum_{a}\alpha^{a}e_{a}\hspace{1cm}\text{and}\hspace{1cm}\beta\vert_{U}=\sum_{a}\beta^{a}e_{a}$$ for real-valued coordinate forms $\alpha^{a}\in\Omega^{k}(U)$ , $\beta^{a}\in\Omega^{l}(U)$ . Then the above defined trace-wedge product is in coordinates given by $$\mathrm{tr}(\alpha\wedge\beta)\vert_{U}=\sum_{a,b}(\alpha^{a}\wedge\beta^{b})\langle e_{a},e_{b}\rangle_{E}$$ where $\langle e_{a},e_{b}\rangle_{E}$ is defined in the obious way, i.e. $\langle e_{a},e_{b}\rangle_{E}(x):=\langle e_{a}(x),e_{a}(x)\rangle_{E_{x}}$ . With this, the left-hand side of the conjectured equation is given by $$\mathrm{d}(\mathrm{tr}(\alpha\wedge\beta))\vert_{U}=\sum_{a,b}(\mathrm{d}\alpha^{a}\wedge\beta^{b}+(-1)^{k}\alpha^{a}\wedge\mathrm{d}\beta^{b})\langle e_{a},e_{b}\rangle_{E}$$ where we just used the standard Leibniz rule for real-valued forms. Now for the right-hand side, let us firstly write $\nabla^{A}e_{a}$ in terms of local connection $1$ -forms ${\omega^{i}}_{j}\in\Omega^{1}(U)$ via $$\nabla^{A}e_{a}=\sum_{b}{\omega^{b}}_{a}e_{b}.$$ With this, we have that $$\mathrm{d}_{A}\alpha\vert_{U}:=\sum_{a}(\mathrm{d}\alpha^{a}e_{a}+(-1)^{k}\sum_{c}(\alpha^{a}\wedge{\omega^{c}}_{a})e_{c})=\sum_{a}(\mathrm{d}\alpha^{a}+(-1)^{k}\sum_{c}(\alpha^{c}\wedge{\omega^{a}}_{c}))e_{a}$$ Now we know how the coordinate forms of $\mathrm{d}_{A}\alpha$ look like and hence we can compute the right-hand side: First of all, we have that $$\mathrm{tr}(\mathrm{d}_{A}\alpha\wedge\beta)\vert_{U}=\sum_{a,b}(\mathrm{d}\alpha^{a}\wedge\beta)\langle e_{a},e_{b}\rangle_{E}+(-1)^{k}\sum_{a,b,c}(\alpha^{c}\wedge{\omega^{a}}_{c}\wedge\beta^{b})\langle e_{a},e_{b}\rangle_{E}$$ Completely analogues, we find that $$\mathrm{tr}(\alpha\wedge\mathrm{d}_{A}\beta)\vert_{U}=\sum_{a,b}(\alpha^{a}\wedge\mathrm{d}\beta^{b})\langle e_{a},e_{b}\rangle_{E}+(-1)^{l}\sum_{a,b,c}(\alpha^{a}\wedge\beta^{c}\wedge{\omega^{b}}_{c})\langle e_{a},e_{b}\rangle_{E}$$ Hence, if the above formula is true, we must have that $$\sum_{a,b,c}(\alpha^{c}\wedge{\omega^{a}}_{c}\wedge\beta^{b}+(-1)^{l}\alpha^{a}\wedge\beta^{c}\wedge{\omega^{b}}_{c})\langle e_{a},e_{b}\rangle_{E}\stackrel{!}{=}0$$ I can't see why this is the case. Again, I should stress that I am not even sure if the claimed equality is true. Maybe it is false, or maybe the factor $(-1)^{k}$ is different. Furthemore, in the paper cited above this is only used for the case $E=\mathrm{Ad}(P)$ , $k=d-2$ and $l=2$ , where $d=\mathrm{dim}(\mathcal{M})$ , so maybe it is only true in this specific case. Any help and comment is appreciated!","Before stating the claim, let my define all the objects which I need: To start with, let me fix notation: Let be a principal -bundle over a (smooth, compact, oriented) manifold (possibly with boundary) and be the Lie algebra of . Furthemore, let us choose a connection -form . Let be a (finite-dimensional real/complex) representation of and be the associated vector bundle. Let be a non-degenerate symmetric bilinear form on . Then it is a general fact that this induces a bundle metric on via for all and for all . Furthermore, I need two further definitions: First of all, the wedge-product is defined in the obvious way, i.e. for all and for all . Secondly, I need the ""exterior covariant derivative induced by a connection 1-form "", which is the exterior covariant derivative induced by a connection on , whose definition is not so important right now. This is a map defined using a local frame defined on some open set via where for coordinates . (Strictly speaking, I should write , but let me keep notation simple) Now I would like to prove the following: I have to say that I am not sure if this is actually true in this form. It is rather an educated  guess. For context, the reason for this is that something like this is implicitely used on page of arXiv:gr-qc/9905087 in the proof of invariance of the BF-action under translational symmetry. (In this context, the bundle is given by the adjoint bundle ). In this paper, the authors used ""integration by parts"" for an expression of the type , where and where denotes the curvature of . Now my attempt is the following: I think it is easier to proof this in the local frame on . Let us write and in this frame, i.e. for real-valued coordinate forms , . Then the above defined trace-wedge product is in coordinates given by where is defined in the obious way, i.e. . With this, the left-hand side of the conjectured equation is given by where we just used the standard Leibniz rule for real-valued forms. Now for the right-hand side, let us firstly write in terms of local connection -forms via With this, we have that Now we know how the coordinate forms of look like and hence we can compute the right-hand side: First of all, we have that Completely analogues, we find that Hence, if the above formula is true, we must have that I can't see why this is the case. Again, I should stress that I am not even sure if the claimed equality is true. Maybe it is false, or maybe the factor is different. Furthemore, in the paper cited above this is only used for the case , and , where , so maybe it is only true in this specific case. Any help and comment is appreciated!","P G \mathcal{M} \mathfrak{g} G 1 A\in\Omega^{1}(P,\mathfrak{g}) (V,\rho) G E:=P\times_{\rho} V \langle\cdot,\cdot\rangle_{V} V \langle\cdot,\cdot\rangle_{E}\in\Gamma(E^{\ast}\otimes E^{\ast}) E \langle [p,v],[p,w]\rangle_{E_{x}}:=\langle v,w\rangle_{V} x\in\mathcal{M} [p,v],[p,w]\in E_{x}\cong P_{x}\times_{\rho}V \mathrm{tr}(\cdot\wedge\cdot):\Omega^{k}(\mathcal{M},E)\times\Omega^{l}(\mathcal{M},E)\to\Omega^{k+l}(\mathcal{M}) \mathrm{tr}(\alpha\wedge\beta)_{x}(v_{1},\dots,v_{k+l}):=\frac{1}{k!l!}\sum_{\sigma\in\mathfrak{S}^{k+l}}\mathrm{sgn}(\sigma)\langle \alpha_{x}(v_{\sigma(1)},\dots,v_{\sigma(k)}),\beta_{x}(v_{\sigma(k+1)},\dots,v_{\sigma(k+l)})\rangle_{E_{x}} x\in\mathcal{M} v_{1},\dots,v_{k+l}\in T_{x}\mathcal{M} A \nabla^{A} E \mathrm{d}_{A}:\Omega^{k}(\mathcal{M},E)\to\Omega^{k+1}(\mathcal{M},E) \{e_{a}\}_{a}\subset\Gamma(U,E) U\subset\mathcal{M} \mathrm{d}_{A}\alpha\vert_{U}:=\sum_{a}(\mathrm{d}\alpha^{a}e_{a}+(-1)^{k}\alpha^{a}\wedge\nabla^{A}e_{a}) \alpha\vert_{U}=\sum_{a}\alpha^{a}e_{a} \alpha^{a}\in\Omega^{k}(U) \alpha^{a}\otimes e_{a} \mathrm{d}(\mathrm{tr}(\alpha\wedge\beta))=\mathrm{tr}(\mathrm{d}_{A}\alpha\wedge\beta)+(-1)^{k}\mathrm{tr}(\alpha\wedge\mathrm{d}_{A}\beta) 4 E \mathrm{Ad}(P) \mathrm{tr}(\mathrm{d}_{A}\eta\wedge F) \eta\in\Omega^{d-3}(\mathcal{M},\mathrm{Ad}(P)) F\in\Omega^{2}(\mathcal{M},\mathrm{Ad}(P)) A U \alpha\in\Omega^{k}(\mathcal{M},E) \beta\in\Omega^{l}(\mathcal{M},E) \alpha\vert_{U}=\sum_{a}\alpha^{a}e_{a}\hspace{1cm}\text{and}\hspace{1cm}\beta\vert_{U}=\sum_{a}\beta^{a}e_{a} \alpha^{a}\in\Omega^{k}(U) \beta^{a}\in\Omega^{l}(U) \mathrm{tr}(\alpha\wedge\beta)\vert_{U}=\sum_{a,b}(\alpha^{a}\wedge\beta^{b})\langle e_{a},e_{b}\rangle_{E} \langle e_{a},e_{b}\rangle_{E} \langle e_{a},e_{b}\rangle_{E}(x):=\langle e_{a}(x),e_{a}(x)\rangle_{E_{x}} \mathrm{d}(\mathrm{tr}(\alpha\wedge\beta))\vert_{U}=\sum_{a,b}(\mathrm{d}\alpha^{a}\wedge\beta^{b}+(-1)^{k}\alpha^{a}\wedge\mathrm{d}\beta^{b})\langle e_{a},e_{b}\rangle_{E} \nabla^{A}e_{a} 1 {\omega^{i}}_{j}\in\Omega^{1}(U) \nabla^{A}e_{a}=\sum_{b}{\omega^{b}}_{a}e_{b}. \mathrm{d}_{A}\alpha\vert_{U}:=\sum_{a}(\mathrm{d}\alpha^{a}e_{a}+(-1)^{k}\sum_{c}(\alpha^{a}\wedge{\omega^{c}}_{a})e_{c})=\sum_{a}(\mathrm{d}\alpha^{a}+(-1)^{k}\sum_{c}(\alpha^{c}\wedge{\omega^{a}}_{c}))e_{a} \mathrm{d}_{A}\alpha \mathrm{tr}(\mathrm{d}_{A}\alpha\wedge\beta)\vert_{U}=\sum_{a,b}(\mathrm{d}\alpha^{a}\wedge\beta)\langle e_{a},e_{b}\rangle_{E}+(-1)^{k}\sum_{a,b,c}(\alpha^{c}\wedge{\omega^{a}}_{c}\wedge\beta^{b})\langle e_{a},e_{b}\rangle_{E} \mathrm{tr}(\alpha\wedge\mathrm{d}_{A}\beta)\vert_{U}=\sum_{a,b}(\alpha^{a}\wedge\mathrm{d}\beta^{b})\langle e_{a},e_{b}\rangle_{E}+(-1)^{l}\sum_{a,b,c}(\alpha^{a}\wedge\beta^{c}\wedge{\omega^{b}}_{c})\langle e_{a},e_{b}\rangle_{E} \sum_{a,b,c}(\alpha^{c}\wedge{\omega^{a}}_{c}\wedge\beta^{b}+(-1)^{l}\alpha^{a}\wedge\beta^{c}\wedge{\omega^{b}}_{c})\langle e_{a},e_{b}\rangle_{E}\stackrel{!}{=}0 (-1)^{k} E=\mathrm{Ad}(P) k=d-2 l=2 d=\mathrm{dim}(\mathcal{M})","['differential-geometry', 'solution-verification', 'differential-forms', 'vector-bundles', 'principal-bundles']"
14,$\mathbb{CP}^1$ is diffeomorphic to $S^2$.,is diffeomorphic to .,\mathbb{CP}^1 S^2,"I just want to double check that I established that diffeomorphism correctly. First, let's recover the definition of a diffeomorphism $F$ between two smooth manifolds $M$ and $N$ . We say that $F:M\to N$ is a diffeomorphism if $F$ is bijective, $F$ is smooth and $F^{-1}$ is smooth. Consider the map $F:S^2\to\mathbb{CP}^1$ where $$F(x,y,z)=\begin{cases}       [1;\frac{x}{1-z}+\frac{y}{1-z}i], & \text{if}\ (x,y,z)\neq (0,0,1) \\       [0;1], & \text{otherwise}     \end{cases}$$ and the map $F^{-1}:\mathbb{CP}^1\to S^2$ where $$F^{-1}([1,u+vi])=(\frac{2u}{u^2+v^2+1},\frac{2v}{u^2+v^2+1},\frac{u^2+v^2-1}{u^2+v^2+1})$$ and $F^{-1}([0;1])=(0,0,1)$ . We can easily see that $F$ is bijective as $F\circ F^{-1}=F^{-1}\circ F=id$ . Next, consider the stereographic projection charts $\{U_0,U_1\}$ for $S^2$ and the standard charts $\{V_0,V_1\}$ for $\mathbb{CP}^1$ where, for example, $V_0=\{[z_0,z_1]|z_0\neq 0\}$ with the corresponding homeomorphisms $\phi_i$ and $\psi_i$ , $i=0,1$ . To show that $F$ is smooth we want to show that $$\psi_i\circ F\circ \phi^{-1}_j:\phi_j(U_j\cap F^{-1}(V_i))\to V_i\text{ is a smooth map, for all }i,j$$ which follows from the basic computations. For example, $$\psi_1\circ F\circ \phi_0^{-1}(u,v)=(\frac{u}{u^2+v^2},\frac{-v}{u^2+v^2}).$$ Is there another faster way to establish a diffeomorphism?","I just want to double check that I established that diffeomorphism correctly. First, let's recover the definition of a diffeomorphism between two smooth manifolds and . We say that is a diffeomorphism if is bijective, is smooth and is smooth. Consider the map where and the map where and . We can easily see that is bijective as . Next, consider the stereographic projection charts for and the standard charts for where, for example, with the corresponding homeomorphisms and , . To show that is smooth we want to show that which follows from the basic computations. For example, Is there another faster way to establish a diffeomorphism?","F M N F:M\to N F F F^{-1} F:S^2\to\mathbb{CP}^1 F(x,y,z)=\begin{cases}
      [1;\frac{x}{1-z}+\frac{y}{1-z}i], & \text{if}\ (x,y,z)\neq (0,0,1) \\
      [0;1], & \text{otherwise}
    \end{cases} F^{-1}:\mathbb{CP}^1\to S^2 F^{-1}([1,u+vi])=(\frac{2u}{u^2+v^2+1},\frac{2v}{u^2+v^2+1},\frac{u^2+v^2-1}{u^2+v^2+1}) F^{-1}([0;1])=(0,0,1) F F\circ F^{-1}=F^{-1}\circ F=id \{U_0,U_1\} S^2 \{V_0,V_1\} \mathbb{CP}^1 V_0=\{[z_0,z_1]|z_0\neq 0\} \phi_i \psi_i i=0,1 F \psi_i\circ F\circ \phi^{-1}_j:\phi_j(U_j\cap F^{-1}(V_i))\to V_i\text{ is a smooth map, for all }i,j \psi_1\circ F\circ \phi_0^{-1}(u,v)=(\frac{u}{u^2+v^2},\frac{-v}{u^2+v^2}).","['differential-geometry', 'manifolds', 'diffeomorphism']"
15,An example of a non-rectifiable curve,An example of a non-rectifiable curve,,"How can I solve this problem? Let the curve in $\mathbb{R}^2$ of the equation $\alpha(t)=(t,g(t)), t\in [0,1]$ , where $$g(t)=\left\{ \begin{aligned} t \cos\left( \frac{\pi}{2t}\right), \quad t\not=0 \\ 0, \quad t=0\end{aligned}\right.$$ For $n \in \mathbb{N}$ , let the partition $P$ of $[0,1]$ given by $$P=\left\{ 0, \frac{1}{2n},\frac{1}{2n-1},\ldots, \frac{1}{3},\frac{1}{2},1\right\},$$ prove the length $\ell_n$ of the polygonal inscribed satisfies $$\ell_n>\sum_{k=1}^{2n}\frac{1}{k}$$ and and deduce that the curve $\alpha$ is not rectifiable. My approach: I know for example that if I prove that arc length of $\alpha$ is infinite, so I can say that $\alpha$ is not rectifiable, so I need to calculate $I_{n}$ . I know that the arc-length of a curve $\alpha$ is $$s(t)=\int_{t_0}^t \|\dot{\alpha}(t)\| \, dt$$ so I need to prove that $s(t)\to \infty \implies \alpha$ is not rectifiable. I know how calculate $\dot{\alpha}(t)$ , but how can I choose $t_0$ and $t$ ? Questions: Now, How can I prove the first part? It's to say, how can I prove that $\ell_n>\sum_{k=1}^{2n}\frac{1}{k}$ ? and how can I relate that result to the fact that alpha is not rectifiable?","How can I solve this problem? Let the curve in of the equation , where For , let the partition of given by prove the length of the polygonal inscribed satisfies and and deduce that the curve is not rectifiable. My approach: I know for example that if I prove that arc length of is infinite, so I can say that is not rectifiable, so I need to calculate . I know that the arc-length of a curve is so I need to prove that is not rectifiable. I know how calculate , but how can I choose and ? Questions: Now, How can I prove the first part? It's to say, how can I prove that ? and how can I relate that result to the fact that alpha is not rectifiable?","\mathbb{R}^2 \alpha(t)=(t,g(t)), t\in [0,1] g(t)=\left\{ \begin{aligned} t \cos\left( \frac{\pi}{2t}\right), \quad t\not=0 \\ 0, \quad t=0\end{aligned}\right. n \in \mathbb{N} P [0,1] P=\left\{ 0, \frac{1}{2n},\frac{1}{2n-1},\ldots, \frac{1}{3},\frac{1}{2},1\right\}, \ell_n \ell_n>\sum_{k=1}^{2n}\frac{1}{k} \alpha \alpha \alpha I_{n} \alpha s(t)=\int_{t_0}^t \|\dot{\alpha}(t)\| \, dt s(t)\to \infty \implies \alpha \dot{\alpha}(t) t_0 t \ell_n>\sum_{k=1}^{2n}\frac{1}{k}",['differential-geometry']
16,What is the structure behind $ \partial \partial M = \varnothing $?,What is the structure behind ?, \partial \partial M = \varnothing ,"In my lectures about manifolds, I learned about the statement $ \partial \partial M = \varnothing $ where $M$ notates a manifold and $\partial M$ its boundary. My professor said, it is similar to the statement in differential geometry, that $ d^2 = 0 $ where $d$ is the exterior derivative. What is the underlying cause for $ \partial \partial M $ being always empty? What theory connects the statements $d^2 = 0$ and $\partial\partial M = \varnothing$ ? Are there similar statements like the two given? Please note, that I am not looking for a proof or explanation of why $\partial \partial M = \varnothing$ is true. I am asking about a theory explaining the underlying structure of the given statements. I believe it could be something about comology theory but please enlighten me. Edit: The comment from @Aurelio is a very good reformulation of my questions: My understanding is that OP wants to know the general framework in which to say that $\partial^2=0$ is the same phenomenon as $d^2=0$ .","In my lectures about manifolds, I learned about the statement where notates a manifold and its boundary. My professor said, it is similar to the statement in differential geometry, that where is the exterior derivative. What is the underlying cause for being always empty? What theory connects the statements and ? Are there similar statements like the two given? Please note, that I am not looking for a proof or explanation of why is true. I am asking about a theory explaining the underlying structure of the given statements. I believe it could be something about comology theory but please enlighten me. Edit: The comment from @Aurelio is a very good reformulation of my questions: My understanding is that OP wants to know the general framework in which to say that is the same phenomenon as .", \partial \partial M = \varnothing  M \partial M  d^2 = 0  d  \partial \partial M  d^2 = 0 \partial\partial M = \varnothing \partial \partial M = \varnothing \partial^2=0 d^2=0,"['differential-geometry', 'homology-cohomology', 'smooth-manifolds', 'exterior-derivative']"
17,Coordinates Free Cauchy-Riemann equations,Coordinates Free Cauchy-Riemann equations,,"Cauchy-Riemann equations can be seen as a system of 2 PDEs for two functions on the plane: $$ \begin{align*} L_{\frac{\partial}{\partial x}}(u) &= L_{\frac{\partial}{\partial y}}(v) \\  L_{\frac{\partial}{\partial y}}(u) &= -L_{\frac{\partial}{\partial x}}(v) \end{align*} $$ where $L_X$ denotes the Lie derivative along vector field $X$ . Since the vector fields $\frac{\partial}{\partial x}$ and $\frac{\partial}{\partial y}$ commutes, we have natural integrability conditions: $$ \begin{align*} \Delta u &= 0\\  \Delta v &= 0, \end{align*} $$ and we know that there exists smooth (even analytic) solutions. I am surprised that I did not found any results about the natural generalisation of those equations, namely: $$ \begin{align*} L_A(u)&=L_B(v)\\ L_B(u)&=-L_A(v) \end{align*} $$ where $A$ and $B$ are any linearly independant smooth vector fields on $\mathbb{R}^2$ . We can also derive integrability conditions but we obtain two complicate elliptic PDEs and it is not trivial that a solution exists. Question : Is there references treating this equations? and giving conditions for the existence of $C^{\infty}$ smooth solutions ?","Cauchy-Riemann equations can be seen as a system of 2 PDEs for two functions on the plane: where denotes the Lie derivative along vector field . Since the vector fields and commutes, we have natural integrability conditions: and we know that there exists smooth (even analytic) solutions. I am surprised that I did not found any results about the natural generalisation of those equations, namely: where and are any linearly independant smooth vector fields on . We can also derive integrability conditions but we obtain two complicate elliptic PDEs and it is not trivial that a solution exists. Question : Is there references treating this equations? and giving conditions for the existence of smooth solutions ?","
\begin{align*}
L_{\frac{\partial}{\partial x}}(u) &= L_{\frac{\partial}{\partial y}}(v) \\ 
L_{\frac{\partial}{\partial y}}(u) &= -L_{\frac{\partial}{\partial x}}(v)
\end{align*}
 L_X X \frac{\partial}{\partial x} \frac{\partial}{\partial y} 
\begin{align*}
\Delta u &= 0\\ 
\Delta v &= 0,
\end{align*}
 
\begin{align*}
L_A(u)&=L_B(v)\\
L_B(u)&=-L_A(v)
\end{align*}
 A B \mathbb{R}^2 C^{\infty}","['differential-geometry', 'partial-differential-equations', 'smooth-manifolds', 'cauchy-riemann-equations']"
18,Hessian form of a real valued function on a submanifold of $\mathbb{R}^{n+m}$,Hessian form of a real valued function on a submanifold of,\mathbb{R}^{n+m},"I recently came across a result in a text in the field of differential geometry and I'm wondering why it is true. Let $M\subset\mathbb{R}^{n+m}$ be an $n$ -dimensional submanifold and $w:M\longrightarrow\mathbb{R},\,w(x)=u(x)-\langle x,z\rangle$ , where $u:M\longrightarrow\mathbb{R}$ , $z\in\mathbb{R}^{n+m}$ and $\langle\cdot,\cdot\rangle$ denotes the canonical inner product on $\mathbb{R}^{n+m}$ . The author states that we have $D_{M}^{2}w(x)=D_{M}^{2}u(x)-\langle II_{x}(\cdot,\cdot),z\rangle$ , where $II_{x}$ is the second fundamental form at the point $x$ and $x$ being a critical point of $w$ . How is the exact computation to get this result? What I tried is to first compute the gradient w.r.t $M$ of $w$ : $\nabla^{M}w(x)=\nabla^{M}u(x)-z^{tan}$ , where $z^{tan}$ is the tangential component of $z$ . If this is correct (is it?), I don't know how to get the Hessian of $w$ at $x$ . Thanks in advance!","I recently came across a result in a text in the field of differential geometry and I'm wondering why it is true. Let be an -dimensional submanifold and , where , and denotes the canonical inner product on . The author states that we have , where is the second fundamental form at the point and being a critical point of . How is the exact computation to get this result? What I tried is to first compute the gradient w.r.t of : , where is the tangential component of . If this is correct (is it?), I don't know how to get the Hessian of at . Thanks in advance!","M\subset\mathbb{R}^{n+m} n w:M\longrightarrow\mathbb{R},\,w(x)=u(x)-\langle x,z\rangle u:M\longrightarrow\mathbb{R} z\in\mathbb{R}^{n+m} \langle\cdot,\cdot\rangle \mathbb{R}^{n+m} D_{M}^{2}w(x)=D_{M}^{2}u(x)-\langle II_{x}(\cdot,\cdot),z\rangle II_{x} x x w M w \nabla^{M}w(x)=\nabla^{M}u(x)-z^{tan} z^{tan} z w x","['differential-geometry', 'riemannian-geometry', 'hessian-matrix', 'submanifold']"
19,"""sheaves of germs of differentiable functions are by no means coherent""?","""sheaves of germs of differentiable functions are by no means coherent""?",,"This is related to a remark in Iitaka's algebraic geometry sec 1.12. ""...It should be noted that sheaves of germs of differentiable functions are by no means coherent. These facts seem to suggest coherence is linked with the property of being algebraic or analytic."" $\textbf{Q1:}$ What is the example of non-coherence for the differentiable case? First what is the sheaf of rings in the context? Is it ring of smooth functions? $\textbf{Q2:}$ If I recall correctly, there are analytic sheaves which are not coherent.(I do not think I will recall this correctly.) Coherence is related notion to algebraic for sure but I have to use GAGA to say it is analytic. However, in analytic setting, there are non-coherent sheaves as well. Should I naively interpret coherence is subcase of analytic or algebraic?(But not the reverse in general?)","This is related to a remark in Iitaka's algebraic geometry sec 1.12. ""...It should be noted that sheaves of germs of differentiable functions are by no means coherent. These facts seem to suggest coherence is linked with the property of being algebraic or analytic."" What is the example of non-coherence for the differentiable case? First what is the sheaf of rings in the context? Is it ring of smooth functions? If I recall correctly, there are analytic sheaves which are not coherent.(I do not think I will recall this correctly.) Coherence is related notion to algebraic for sure but I have to use GAGA to say it is analytic. However, in analytic setting, there are non-coherent sheaves as well. Should I naively interpret coherence is subcase of analytic or algebraic?(But not the reverse in general?)",\textbf{Q1:} \textbf{Q2:},"['differential-geometry', 'algebraic-geometry', 'sheaf-theory', 'coherent-sheaves']"
20,Integrability of a distribution on $S^{2n-1}$,Integrability of a distribution on,S^{2n-1},"Let $\theta$ be the restriction of $$ \eta = x^2 dx^1 - x^1 dx^2 + \cdots + x^{2n} dx^{2n-1} - x^{2n-1} dx^{2n} $$ to the unit sphere $S^{2n-1} \subset \mathbb{R}^{2n}$ . Since $\theta$ is a nowhere vanishing $1$ -form, $\ker \theta$ defines a distribution on $S^{2n-1}$ . Is it integrable? As I understand it an equivalent condition for integrability here is that $\theta \wedge d \theta = 0$ , which holds trivially for $n = 1$ . If I computed correctly, I've gotten that $\eta \wedge d \eta \neq 0$ on $\mathbb{R}^{2n}$ except when $n = 1$ (so $\ker \eta$ is not integrable on $\mathbb{R}^{2n}$ for $n \geq 2$ ), but this does not necessarily mean that the pullback $i^*(\eta \wedge d \eta) = \theta \wedge d \theta$ along the inclusion map $S^{2n-1} \to \mathbb{R}^{2n}$ is nonzero as well, right? In which case I'm not sure how to go about this, since checking whether $\theta \wedge d \theta = 0$ directly in local coordinates on $S^{2n-1}$ seems messier than an intended solution.. (this is an old exam problem). Any help would be appreciated!","Let be the restriction of to the unit sphere . Since is a nowhere vanishing -form, defines a distribution on . Is it integrable? As I understand it an equivalent condition for integrability here is that , which holds trivially for . If I computed correctly, I've gotten that on except when (so is not integrable on for ), but this does not necessarily mean that the pullback along the inclusion map is nonzero as well, right? In which case I'm not sure how to go about this, since checking whether directly in local coordinates on seems messier than an intended solution.. (this is an old exam problem). Any help would be appreciated!",\theta  \eta = x^2 dx^1 - x^1 dx^2 + \cdots + x^{2n} dx^{2n-1} - x^{2n-1} dx^{2n}  S^{2n-1} \subset \mathbb{R}^{2n} \theta 1 \ker \theta S^{2n-1} \theta \wedge d \theta = 0 n = 1 \eta \wedge d \eta \neq 0 \mathbb{R}^{2n} n = 1 \ker \eta \mathbb{R}^{2n} n \geq 2 i^*(\eta \wedge d \eta) = \theta \wedge d \theta S^{2n-1} \to \mathbb{R}^{2n} \theta \wedge d \theta = 0 S^{2n-1},['differential-geometry']
21,Interpretation of higher direct images,Interpretation of higher direct images,,"In my algebraic geometry course the higher direct images $R^i f_* \mathcal{F}$ of a sheaf of abelian groups $\mathcal{F}$ on a topological space $X$ were introduced as the right-derived functors of the pushforward $f_*$ . While I have a good intuition of what the pushforward is supposed to do (thinking about pushforwards of vector bundles in differential geometry), I have know idea about how to visualize the higher direct images. Is there any concept from differential geometry which is analogous to higher direct images or any other interpretation?","In my algebraic geometry course the higher direct images of a sheaf of abelian groups on a topological space were introduced as the right-derived functors of the pushforward . While I have a good intuition of what the pushforward is supposed to do (thinking about pushforwards of vector bundles in differential geometry), I have know idea about how to visualize the higher direct images. Is there any concept from differential geometry which is analogous to higher direct images or any other interpretation?",R^i f_* \mathcal{F} \mathcal{F} X f_*,"['differential-geometry', 'algebraic-geometry', 'soft-question', 'sheaf-theory', 'sheaf-cohomology']"
22,Is every compact solvmanifold the quotient of a simply connected solvable Lie group by a discrete subgroup?,Is every compact solvmanifold the quotient of a simply connected solvable Lie group by a discrete subgroup?,,"Recall that a manifold is called a nilmanifold if it is a homogeneous space for a connected nilpotent Lie group. Mal'cev showed that every compact nilmanifold is diffeomorphic to the quotient of a simply connected nilpotent Lie group by a discrete subgroup acting cocompactly. A manifold is called a solvmanifold if it is a homogeneous space for a connected solvable Lie group. Every nilpotent group is solvable, so every nilmanifold is a solvmanifold. Is there an anologue of Mal'cev's result for solvmanifolds? That is, Is every compact solvmanifold diffeomorphic to the quotient of a simply connected solvable Lie group by a discrete subgroup acting cocompactly?","Recall that a manifold is called a nilmanifold if it is a homogeneous space for a connected nilpotent Lie group. Mal'cev showed that every compact nilmanifold is diffeomorphic to the quotient of a simply connected nilpotent Lie group by a discrete subgroup acting cocompactly. A manifold is called a solvmanifold if it is a homogeneous space for a connected solvable Lie group. Every nilpotent group is solvable, so every nilmanifold is a solvmanifold. Is there an anologue of Mal'cev's result for solvmanifolds? That is, Is every compact solvmanifold diffeomorphic to the quotient of a simply connected solvable Lie group by a discrete subgroup acting cocompactly?",,"['differential-geometry', 'lie-groups', 'smooth-manifolds', 'solvable-groups']"
23,Why are Klein geometries $G/H$?,Why are Klein geometries ?,G/H,"The idea behind Klein geometries is simple, clear and beautiful. Simply we have a manifold M and a Lie group G who acts on it and we study the properties that remain invariants under this action. But then, when I open the books about Klein geometry they start with something like: choose a point $x \in M$ , take the stabilizer $H$ of x, then the Klein geometry is $G/H$ ; instead of $(M, x)$ we can study $(G, H)$ . Now, even if I ""understand"" what they say, I cannot really understand what this means and why one chooses this instead of the natural definition. In particular What does it really mean to study $G/H$ instead of $M$ ? For example if I want to study properties of curves, I will consider $\gamma: I \to M$ and not something like $\gamma: I \to G/H$ . For example if I consider $M = \mathbb{R}^2$ , $x = \vec O$ and $G = SO(2)$ (i.e I do not consider translations) I will have $H = SO(2)$ and $G/H = \{0\}$ : what does it mean that my geometry is ""empty""? What is $G/H$ in practice? Why do every one define them so? Which are the advantages? Thanks in advance","The idea behind Klein geometries is simple, clear and beautiful. Simply we have a manifold M and a Lie group G who acts on it and we study the properties that remain invariants under this action. But then, when I open the books about Klein geometry they start with something like: choose a point , take the stabilizer of x, then the Klein geometry is ; instead of we can study . Now, even if I ""understand"" what they say, I cannot really understand what this means and why one chooses this instead of the natural definition. In particular What does it really mean to study instead of ? For example if I want to study properties of curves, I will consider and not something like . For example if I consider , and (i.e I do not consider translations) I will have and : what does it mean that my geometry is ""empty""? What is in practice? Why do every one define them so? Which are the advantages? Thanks in advance","x \in M H G/H (M, x) (G, H) G/H M \gamma: I \to M \gamma: I \to G/H M = \mathbb{R}^2 x = \vec O G = SO(2) H = SO(2) G/H = \{0\} G/H","['differential-geometry', 'lie-groups', 'homogeneous-spaces']"
24,Does the geometric version of Nakayama's lemma hold for smooth manifolds?,Does the geometric version of Nakayama's lemma hold for smooth manifolds?,,"Consider the following geometric formulation of Nakayama's lemma. Proposition. Let $F$ be a quasi-coherent sheaf locally of finite type on a scheme $X$ . Consider the quotient map $\pi:F_x\to F_x\otimes\Bbbk (x)$ . Given $s_1,\dots ,s_n\in F_x$ , suppose their image generates $F_x\otimes \Bbbk (x)$ . Then the $s_i$ extend to a neighborhood $U\subset X$ of $x$ on which they define a surjective arrow $$(\mathcal O _X|_U)^n\overset{(s_1,\dots ,s_n)}{\longrightarrow}F|_U\to \bf 0$$ on $U$ . When this holds, we say $s_1,\dots ,s_n$ generate $F$ over $U$ . Let $(M,\mathcal T_M)$ be a manifold with the sheaf of sections of its tangent bundle. The $x$ -fiber of $\mathcal T_M$ is the vector space of tangents at $x$ . The $x$ -stalk is the module of germs at $x$ of vector fields. Does ""Nakayama"" hold for $(M,\mathcal T_M)$ ?","Consider the following geometric formulation of Nakayama's lemma. Proposition. Let be a quasi-coherent sheaf locally of finite type on a scheme . Consider the quotient map . Given , suppose their image generates . Then the extend to a neighborhood of on which they define a surjective arrow on . When this holds, we say generate over . Let be a manifold with the sheaf of sections of its tangent bundle. The -fiber of is the vector space of tangents at . The -stalk is the module of germs at of vector fields. Does ""Nakayama"" hold for ?","F X \pi:F_x\to F_x\otimes\Bbbk (x) s_1,\dots ,s_n\in F_x F_x\otimes \Bbbk (x) s_i U\subset X x (\mathcal O _X|_U)^n\overset{(s_1,\dots ,s_n)}{\longrightarrow}F|_U\to \bf 0 U s_1,\dots ,s_n F U (M,\mathcal T_M) x \mathcal T_M x x x (M,\mathcal T_M)","['differential-geometry', 'algebraic-geometry', 'commutative-algebra', 'smooth-manifolds', 'sheaf-theory']"
25,Tangent spaces to the orbit of a Lie group,Tangent spaces to the orbit of a Lie group,,"Let $G\subset GL(n)$ be a Lie subgroup and denote  $$ M:=G x_0 = \{ Ax_0\ :\ A\in G\}\subset \mathbb R^n,$$ where $x_0\ne 0$ is a fixed vector in $\mathbb R^n$. Then $M$ is a smooth submanifold of $\mathbb R^n$. Question . Is it true that $$\tag{1}A(T_{x_0} M)=T_{Ax_0} M,\qquad \forall A\in G\ ?$$ At first sight I would say that (1) is true. However, if the Lie algebra $\mathfrak g$ is given by $$\mathfrak g = \text{span}\ (g_1, g_2\ldots g_m), $$  then  $$T_{x_0} M = \text{span}\, (g_1 x_0, \ldots ,g_mx_0),$$ and analogously  $$ T_{Ax_0} M=\text{span}\, (g_1 Ax_0, \ldots, g_mAx_0), $$ while  $$ A(T_{x_0} M) = \text{span}\, (Ag_1 x_0, \ldots ,Ag_mx_0),$$ and I don't see a reason why the last two vector spaces should coincide. I don't know how to handle the commutators $[g_j, A]$, where $g_j\in\mathfrak g$ and $A\in G$.","Let $G\subset GL(n)$ be a Lie subgroup and denote  $$ M:=G x_0 = \{ Ax_0\ :\ A\in G\}\subset \mathbb R^n,$$ where $x_0\ne 0$ is a fixed vector in $\mathbb R^n$. Then $M$ is a smooth submanifold of $\mathbb R^n$. Question . Is it true that $$\tag{1}A(T_{x_0} M)=T_{Ax_0} M,\qquad \forall A\in G\ ?$$ At first sight I would say that (1) is true. However, if the Lie algebra $\mathfrak g$ is given by $$\mathfrak g = \text{span}\ (g_1, g_2\ldots g_m), $$  then  $$T_{x_0} M = \text{span}\, (g_1 x_0, \ldots ,g_mx_0),$$ and analogously  $$ T_{Ax_0} M=\text{span}\, (g_1 Ax_0, \ldots, g_mAx_0), $$ while  $$ A(T_{x_0} M) = \text{span}\, (Ag_1 x_0, \ldots ,Ag_mx_0),$$ and I don't see a reason why the last two vector spaces should coincide. I don't know how to handle the commutators $[g_j, A]$, where $g_j\in\mathfrak g$ and $A\in G$.",,"['differential-geometry', 'lie-groups', 'lie-algebras']"
26,"If I'm given $\xi^b$, how do I calculate $\omega^{ab}$ given $\xi^b = \nabla_a \omega ^{ab}$? [closed]","If I'm given , how do I calculate  given ? [closed]",\xi^b \omega^{ab} \xi^b = \nabla_a \omega ^{ab},"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question I'm given a one-form, $\xi^b$. Then, I'm given a relation for a two-form, $\omega^{ab}$,  which says that $$ \xi^b = \nabla_a \omega^{ab}$$ How do I calculate $\omega^{ab}$ given this relation?","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question I'm given a one-form, $\xi^b$. Then, I'm given a relation for a two-form, $\omega^{ab}$,  which says that $$ \xi^b = \nabla_a \omega^{ab}$$ How do I calculate $\omega^{ab}$ given this relation?",,"['differential-geometry', 'differential-forms']"
27,"Norm of $(0,2)$ tensor",Norm of  tensor,"(0,2)","If we have a $(0,2)$ tensor $A$ (in my situation, it is actually second fundamental form), I am confused by this notation $|A|$.If we think it as Frobenius norm, write $A$ in local coordinate,i.e., $A=A_{ij}dx^i\otimes dx^j$ where $A_{ij}=A(\partial_i,\partial_j)$, then $$|A|=(\sum A^2_{ij})^{1/2}.$$ But if we think it is a norm induced by metric, then $$|A|=<A,A>^{1/2}=<A_{ij}dx^i\otimes dx^j,A_{mn}dx^m\otimes dx^n>^{1/2}=(g^{im}g^{jn}A_{ij}A_{mn})^{1/2}.$$ It seems that if I choose local orthonormal frame, they are same since $g^{im}=\delta^i_m$. Or the truth is they are same all the time? Any explanation will be helpful.","If we have a $(0,2)$ tensor $A$ (in my situation, it is actually second fundamental form), I am confused by this notation $|A|$.If we think it as Frobenius norm, write $A$ in local coordinate,i.e., $A=A_{ij}dx^i\otimes dx^j$ where $A_{ij}=A(\partial_i,\partial_j)$, then $$|A|=(\sum A^2_{ij})^{1/2}.$$ But if we think it is a norm induced by metric, then $$|A|=<A,A>^{1/2}=<A_{ij}dx^i\otimes dx^j,A_{mn}dx^m\otimes dx^n>^{1/2}=(g^{im}g^{jn}A_{ij}A_{mn})^{1/2}.$$ It seems that if I choose local orthonormal frame, they are same since $g^{im}=\delta^i_m$. Or the truth is they are same all the time? Any explanation will be helpful.",,"['differential-geometry', 'riemannian-geometry']"
28,Is the “distance to boundary” function smooth in a neighborhood?,Is the “distance to boundary” function smooth in a neighborhood?,,"Let $M$ be a connected Riemannian manifold with boundary. We define the “distance to boundary” function $d(p)=d(p,\partial M)$, i.e. the infimum of lengths of (piecewise) smooth paths connecting $p$ with some point in $\partial M$. Does there always exist a neighborhood $U$ of $\partial M$, so that $d$ is smooth in $U$? This is not true if we replace $\partial M$ by an arbitrary subset $A$, e.g. consider $A=\text{point}$.","Let $M$ be a connected Riemannian manifold with boundary. We define the “distance to boundary” function $d(p)=d(p,\partial M)$, i.e. the infimum of lengths of (piecewise) smooth paths connecting $p$ with some point in $\partial M$. Does there always exist a neighborhood $U$ of $\partial M$, so that $d$ is smooth in $U$? This is not true if we replace $\partial M$ by an arbitrary subset $A$, e.g. consider $A=\text{point}$.",,"['differential-geometry', 'differential-topology', 'riemannian-geometry']"
29,De Rham cohomology groups of projective real space,De Rham cohomology groups of projective real space,,"I would like to calculate the de De Rham cohomology groups of projective real space $\mathbb{RP}^{n}$. Well, i know all groups of De Rham cohomology os $n$-sphere $\mathbb{S}^{n}$ and that the map $\pi:\mathbb{S}^{n}\to \mathbb{RP}^{n}$ (the restriction to the projection map on $\mathbb{S}^{n}$) is a smooth submersion. With these tools, can I compute the cohomology groups of real projective space? How can I do this?","I would like to calculate the de De Rham cohomology groups of projective real space $\mathbb{RP}^{n}$. Well, i know all groups of De Rham cohomology os $n$-sphere $\mathbb{S}^{n}$ and that the map $\pi:\mathbb{S}^{n}\to \mathbb{RP}^{n}$ (the restriction to the projection map on $\mathbb{S}^{n}$) is a smooth submersion. With these tools, can I compute the cohomology groups of real projective space? How can I do this?",,"['differential-geometry', 'algebraic-topology', 'smooth-manifolds', 'projective-space', 'de-rham-cohomology']"
30,geodesic flow and the vector field on $TM$,geodesic flow and the vector field on,TM,"I'm trying to understand what my teacher wrote. We build a vector field $\cal{X}$ on $TM$ for which the flow, called geodesic flow , consists in the curves $(\gamma(t),\dot{\gamma}(t))$ where $\gamma$ is a geodesic $${\cal{X}}_X=(X^1,\cdots,X^n,-\Gamma^1_{ij}X^iX^j,\cdots,-\Gamma^n_{ij}X^iX^j)$$ Then $$\frac{d\gamma^k}{dt} = X^k\\ \frac{dX^k}{dt} = -\Gamma^k_{ij}X^iX^j$$   is the system of equations of the flow of $\cal{X}$. Why is that system the set of equations defining the flow of $\cal{X}$? it is clear that the curves $(\gamma(t),\dot{\gamma}(t))$, with $\gamma$ a geodesic, satisfy the equations but how do we know that no other curve on $TM$ satisfies these equations","I'm trying to understand what my teacher wrote. We build a vector field $\cal{X}$ on $TM$ for which the flow, called geodesic flow , consists in the curves $(\gamma(t),\dot{\gamma}(t))$ where $\gamma$ is a geodesic $${\cal{X}}_X=(X^1,\cdots,X^n,-\Gamma^1_{ij}X^iX^j,\cdots,-\Gamma^n_{ij}X^iX^j)$$ Then $$\frac{d\gamma^k}{dt} = X^k\\ \frac{dX^k}{dt} = -\Gamma^k_{ij}X^iX^j$$   is the system of equations of the flow of $\cal{X}$. Why is that system the set of equations defining the flow of $\cal{X}$? it is clear that the curves $(\gamma(t),\dot{\gamma}(t))$, with $\gamma$ a geodesic, satisfy the equations but how do we know that no other curve on $TM$ satisfies these equations",,"['differential-geometry', 'riemannian-geometry', 'geodesic']"
31,Understanding curvature as rate of change of angle between neighbouring tangents,Understanding curvature as rate of change of angle between neighbouring tangents,,"When introducing the concept of curvature in ""Differential Geometry of Curves and Surfaces"", do Carmo makes the statement the norm $|\alpha''(s)|$ of the second derivative measure the rate of change of the angle which neighbouring tangents make with the tangent at $s$. Here $\alpha(s)$ is a curve parametrized by arc length. I have read similar things elsewhere, e.g. Wikipedia states the curvature of a plane curve at any point is the limiting ratio of $d\theta$, an infinitesimal angle (in radians) between tangents to that curve at the ends of an infinitesimal segment of the curve, to the length of that segment $ds$, i.e., $d\theta/ds$. If the tangents at the ends of the segment are represented by unit vectors, it is easy to show that in this limit, the magnitude of the difference vector is equal to $d\theta$, which leads to the given expression in the second definition of curvature. Accompanying this is the following potentially useful diagram: I cannot understand how to make this interpretation rigorous. In particular, interpreting do Carmo at face value, if we define $\theta_{s_0}(s)$ to be the angle between $\alpha'(s)$ and $\alpha'(s_0)$ for some fixed $s_0$, then $$\theta_{s_0}(s) = \arccos\left[\alpha'(s) \cdot \alpha'(s_0)\right]$$ (since $||\alpha'(s)|| = 1$). However, this has derivative $$\theta_{s_0}'(s) = -\frac{\alpha'(s_0) \cdot \alpha''(s)}{\sqrt{1 - (\alpha'(s) \cdot \alpha'(s_0))^2}},$$ which I do not believe is equal to $||\alpha''(s_0)||$. Can anyone explain do Carmo's comment or the Wikipedia passage in precise terms?","When introducing the concept of curvature in ""Differential Geometry of Curves and Surfaces"", do Carmo makes the statement the norm $|\alpha''(s)|$ of the second derivative measure the rate of change of the angle which neighbouring tangents make with the tangent at $s$. Here $\alpha(s)$ is a curve parametrized by arc length. I have read similar things elsewhere, e.g. Wikipedia states the curvature of a plane curve at any point is the limiting ratio of $d\theta$, an infinitesimal angle (in radians) between tangents to that curve at the ends of an infinitesimal segment of the curve, to the length of that segment $ds$, i.e., $d\theta/ds$. If the tangents at the ends of the segment are represented by unit vectors, it is easy to show that in this limit, the magnitude of the difference vector is equal to $d\theta$, which leads to the given expression in the second definition of curvature. Accompanying this is the following potentially useful diagram: I cannot understand how to make this interpretation rigorous. In particular, interpreting do Carmo at face value, if we define $\theta_{s_0}(s)$ to be the angle between $\alpha'(s)$ and $\alpha'(s_0)$ for some fixed $s_0$, then $$\theta_{s_0}(s) = \arccos\left[\alpha'(s) \cdot \alpha'(s_0)\right]$$ (since $||\alpha'(s)|| = 1$). However, this has derivative $$\theta_{s_0}'(s) = -\frac{\alpha'(s_0) \cdot \alpha''(s)}{\sqrt{1 - (\alpha'(s) \cdot \alpha'(s_0))^2}},$$ which I do not believe is equal to $||\alpha''(s_0)||$. Can anyone explain do Carmo's comment or the Wikipedia passage in precise terms?",,['differential-geometry']
32,Covairant Derivative along the Constant Curve. What is the Mistake?,Covairant Derivative along the Constant Curve. What is the Mistake?,,"Let $(M, g)$ be a Riemannian manifold, equipped with the Riemannian connection. Let $f:I\to M$ be the constant curve, mapping all elements of $I$ to a point $p$ on the manifold. Let $V$ be a vector field along $f$. Thus $V$ can be thought of as a smooth map $V:I\to T_pM$. Question. What is the covariant derivative of $V$ along $f$? By definition, the covariant derivative $\frac{DV}{dt}(t_0)=\nabla_{f'(t_0)}\tilde V$, where $\tilde V$ is any extension of $V$ in a neihborhood of $f'(t_0)$. But $f'(t_0)=0$ since $f$ is constant. Thus $\nabla_{f'(t_0)}\tilde V=0$, and thus the required covariant derivative is also $0$. This is not the right answer, for Problem 6 of Chapter 2 of Do Carmo's Riemannian Geometry asks to prove that the covariant derivative is same as the derivative of the smooth map $V:I\to T_pM$, which might not be $0$. I am unable to locate my mistake.","Let $(M, g)$ be a Riemannian manifold, equipped with the Riemannian connection. Let $f:I\to M$ be the constant curve, mapping all elements of $I$ to a point $p$ on the manifold. Let $V$ be a vector field along $f$. Thus $V$ can be thought of as a smooth map $V:I\to T_pM$. Question. What is the covariant derivative of $V$ along $f$? By definition, the covariant derivative $\frac{DV}{dt}(t_0)=\nabla_{f'(t_0)}\tilde V$, where $\tilde V$ is any extension of $V$ in a neihborhood of $f'(t_0)$. But $f'(t_0)=0$ since $f$ is constant. Thus $\nabla_{f'(t_0)}\tilde V=0$, and thus the required covariant derivative is also $0$. This is not the right answer, for Problem 6 of Chapter 2 of Do Carmo's Riemannian Geometry asks to prove that the covariant derivative is same as the derivative of the smooth map $V:I\to T_pM$, which might not be $0$. I am unable to locate my mistake.",,"['differential-geometry', 'riemannian-geometry']"
33,On the Arakelov metric in the construction of the Kawazumi-Zhang invariant,On the Arakelov metric in the construction of the Kawazumi-Zhang invariant,,"For a compact Riemann surface $\Sigma$ of genus $h\geq 1$, the Kawazumi-Zhang invariant is defined as, $$\varphi(\Sigma) = \sum_{\ell >0}\frac{2}{\lambda_\ell} \sum_{m,n=1}^h \bigg\vert \int_\Sigma \phi_\ell \omega_m \wedge \bar \omega_n\bigg\vert^2$$ where we have $\Delta_\Sigma \phi_\ell = \lambda_\ell \phi_\ell$ and $\{\omega_1, \dots, \omega_n\}$ form an orthonormal basis of holomorphic forms on $\Sigma$ and it is stressed $\Delta_\Sigma$ is with respect to the Arakelov metric on $\Sigma$. There are other equivalent ways of expressing the invariant, which may be more suitable for explicit computation. For hyperbolic Riemann surfaces of certain genus, it can also be directly related to the Faltings invariant. However, many rely on this notion of an Arakelov metric, and as a string theorist, I have not delved into Arakelov theory. As such, I would greatly appreciate if someone could elucidate what the Arakelov metric is, perhaps explicitly for a particular manifold, given this seems to be the only thing from Arakelov theory I need to be able to compute $\varphi(\Sigma)$. For those curious, the motivation is that the integration of $\varphi(\Sigma)$ over the moduli space of Riemann surfaces of genus $h= 2$ arises in the evaluation of an amplitude in type II string theory.","For a compact Riemann surface $\Sigma$ of genus $h\geq 1$, the Kawazumi-Zhang invariant is defined as, $$\varphi(\Sigma) = \sum_{\ell >0}\frac{2}{\lambda_\ell} \sum_{m,n=1}^h \bigg\vert \int_\Sigma \phi_\ell \omega_m \wedge \bar \omega_n\bigg\vert^2$$ where we have $\Delta_\Sigma \phi_\ell = \lambda_\ell \phi_\ell$ and $\{\omega_1, \dots, \omega_n\}$ form an orthonormal basis of holomorphic forms on $\Sigma$ and it is stressed $\Delta_\Sigma$ is with respect to the Arakelov metric on $\Sigma$. There are other equivalent ways of expressing the invariant, which may be more suitable for explicit computation. For hyperbolic Riemann surfaces of certain genus, it can also be directly related to the Faltings invariant. However, many rely on this notion of an Arakelov metric, and as a string theorist, I have not delved into Arakelov theory. As such, I would greatly appreciate if someone could elucidate what the Arakelov metric is, perhaps explicitly for a particular manifold, given this seems to be the only thing from Arakelov theory I need to be able to compute $\varphi(\Sigma)$. For those curious, the motivation is that the integration of $\varphi(\Sigma)$ over the moduli space of Riemann surfaces of genus $h= 2$ arises in the evaluation of an amplitude in type II string theory.",,"['differential-geometry', 'complex-geometry', 'riemann-surfaces']"
34,Geometric interpretation of the second covariant derivative,Geometric interpretation of the second covariant derivative,,"I'm having some doubts about the geometric representation of the second covariant derivative. I know that $\triangledown^{}_a(\triangledown^{}_bv)=(\triangledown^{}_a\triangledown^{}_b)v+\triangledown^{}_{\triangledown^{}_ab}v$ So the Riemann tensor can be defined in two ways : $R(a,b)v=\triangledown^{}_{a}(\triangledown^{}_{b}v)-\triangledown^{}_{b}(\triangledown^{}_{a}v)-\triangledown^{}_{[a,b]}v\quad$ or $\quad R(a,b)v=(\triangledown^{}_{a}\triangledown^{}_{b})v-(\triangledown^{}_{b}\triangledown^{}_{a})v$ So far so good (correct me if I'm wrong). But the problem arises when I read that the Riemann tensor represents the difference between a parallel transported vector along two parts of a closed path. Because if $\triangledown^{}_{b}v$ is the parallel transported vector along b, then it stands to reason that $\triangledown^{}_{a}(\triangledown^{}_{b}v)$ is the transported vector along b and then a. But there would be a correction term, so the representation would be inexact. And conversely, if $(\triangledown^{}_{a}\triangledown^{}_{b})v$ is the transported vector along the path b and then a, the representation would be correct, but I don't understand why... So, which is correct, A or B ? Edit : would the difference be linked with the torsion ? Are $\triangledown^{}_{a}(\triangledown^{}_{b}v)$ and $(\triangledown^{}_{a}\triangledown^{}_{b})v$ equal if the connection is torsion free ? PS : why is the image not integrated in the post ? too large ?","I'm having some doubts about the geometric representation of the second covariant derivative. I know that So the Riemann tensor can be defined in two ways : or So far so good (correct me if I'm wrong). But the problem arises when I read that the Riemann tensor represents the difference between a parallel transported vector along two parts of a closed path. Because if is the parallel transported vector along b, then it stands to reason that is the transported vector along b and then a. But there would be a correction term, so the representation would be inexact. And conversely, if is the transported vector along the path b and then a, the representation would be correct, but I don't understand why... So, which is correct, A or B ? Edit : would the difference be linked with the torsion ? Are and equal if the connection is torsion free ? PS : why is the image not integrated in the post ? too large ?","\triangledown^{}_a(\triangledown^{}_bv)=(\triangledown^{}_a\triangledown^{}_b)v+\triangledown^{}_{\triangledown^{}_ab}v R(a,b)v=\triangledown^{}_{a}(\triangledown^{}_{b}v)-\triangledown^{}_{b}(\triangledown^{}_{a}v)-\triangledown^{}_{[a,b]}v\quad \quad R(a,b)v=(\triangledown^{}_{a}\triangledown^{}_{b})v-(\triangledown^{}_{b}\triangledown^{}_{a})v \triangledown^{}_{b}v \triangledown^{}_{a}(\triangledown^{}_{b}v) (\triangledown^{}_{a}\triangledown^{}_{b})v \triangledown^{}_{a}(\triangledown^{}_{b}v) (\triangledown^{}_{a}\triangledown^{}_{b})v",['differential-geometry']
35,What is the definition of a complex manifold with boundary?,What is the definition of a complex manifold with boundary?,,Can anybody help me to be clear about this definition. I know the definition of a real manifold with boundary (as in Lee's book) and the definition of a complex manifold (locally diffeomophic to an open set in $\mathbb{C}^{n}$ and transition maps are holomorphic). What is the definition of a complex manifold with boundary? I see it many times while reading about the complex-Monge Ampere equations on Kahler manifolds.,Can anybody help me to be clear about this definition. I know the definition of a real manifold with boundary (as in Lee's book) and the definition of a complex manifold (locally diffeomophic to an open set in $\mathbb{C}^{n}$ and transition maps are holomorphic). What is the definition of a complex manifold with boundary? I see it many times while reading about the complex-Monge Ampere equations on Kahler manifolds.,,['differential-geometry']
36,How did Do Carmo get the following differential of the Gauss map?,How did Do Carmo get the following differential of the Gauss map?,,"Below is an example from Do Carmo's Differential Geometry page 139 ""The Geometry of the Gauss Map"". Let us analyse the point $p=(0,0,0)$ of the hyperbolic paraboloid $z=y^2-x^2$. For this, we consider a parametrisation $\textbf{x}(u,v)$ given by  $$\textbf{x}(u,v)=(u,v,v^2-u^2),$$ and compute the normal vector $N(u,v)$. We obtain successively $\textbf{x}_u=(1,0,-2u),$ $\textbf{x}_v=(0,1,2v),$ $N=\Big(\frac{u}{\sqrt{u^2+v^2+\frac{1}{4}}},\frac{-v}{\sqrt{u^2+v^2+\frac{1}{4}}},\frac{1}{2\sqrt{u^2+v^2+\frac{1}{4}}}\Big)$. Notice that at $p=(0,0,0)$ $\textbf{x}_u$ and $\textbf{x}_v$ agree with the unit vectors along the $x$ and $y$ axes, respectively. Therefore, the tangent vector at $p$ to the curve $\alpha(t)=\textbf{x}(u(t),v(t))$, with $\alpha(0)=p$, has, in $\mathbb{R}^3$, coordinates $(u'(0),v'(0),0)$. I understand up until this point. Now my question is what follows: How can Do Carmo get the following: Restricting $N(u,v)$ to this curve and computing $N'(0)$, we obtain $N'(0)=(2u'(0),-2v'(0),0)$ I have little clue on how can he get $2u'(0)$ and $2v'(0)$? Could somebody please help clarify this confusion? Thanks.","Below is an example from Do Carmo's Differential Geometry page 139 ""The Geometry of the Gauss Map"". Let us analyse the point $p=(0,0,0)$ of the hyperbolic paraboloid $z=y^2-x^2$. For this, we consider a parametrisation $\textbf{x}(u,v)$ given by  $$\textbf{x}(u,v)=(u,v,v^2-u^2),$$ and compute the normal vector $N(u,v)$. We obtain successively $\textbf{x}_u=(1,0,-2u),$ $\textbf{x}_v=(0,1,2v),$ $N=\Big(\frac{u}{\sqrt{u^2+v^2+\frac{1}{4}}},\frac{-v}{\sqrt{u^2+v^2+\frac{1}{4}}},\frac{1}{2\sqrt{u^2+v^2+\frac{1}{4}}}\Big)$. Notice that at $p=(0,0,0)$ $\textbf{x}_u$ and $\textbf{x}_v$ agree with the unit vectors along the $x$ and $y$ axes, respectively. Therefore, the tangent vector at $p$ to the curve $\alpha(t)=\textbf{x}(u(t),v(t))$, with $\alpha(0)=p$, has, in $\mathbb{R}^3$, coordinates $(u'(0),v'(0),0)$. I understand up until this point. Now my question is what follows: How can Do Carmo get the following: Restricting $N(u,v)$ to this curve and computing $N'(0)$, we obtain $N'(0)=(2u'(0),-2v'(0),0)$ I have little clue on how can he get $2u'(0)$ and $2v'(0)$? Could somebody please help clarify this confusion? Thanks.",,['differential-geometry']
37,Is there a relationship between the pullback in differential geometry and that in category theory?,Is there a relationship between the pullback in differential geometry and that in category theory?,,"1. Is there a relationship between the pullback in differential geometry and the pullback in category theory? [ 2. Is there a relationship between the pushforward/pushout in differential geometry and the pushforward/pushout in category theory? Although the answer to the above ( 1. ) is equivalent to the answer to this question ( 2. ) by duality.] As far as I can tell, (for the terms in differential geometry) the pullback is a contravariant functor, and the pushforward is a covariant functor. 3. Is there a way to turn every contravariant functor into a category theory pullback or vice versa? (Or every covariant functor into a category theory pushforward or vice versa?) If the answer to 3. is no, then it seems like the fact that the two concepts have the same name is just a historical accident, and does not indicate that one is meant to generalize the other. 4. Is it true that the similar terminology between the two fields is a historical accident? Or are they both meant to evoke the same type of basic example?","1. Is there a relationship between the pullback in differential geometry and the pullback in category theory? [ 2. Is there a relationship between the pushforward/pushout in differential geometry and the pushforward/pushout in category theory? Although the answer to the above ( 1. ) is equivalent to the answer to this question ( 2. ) by duality.] As far as I can tell, (for the terms in differential geometry) the pullback is a contravariant functor, and the pushforward is a covariant functor. 3. Is there a way to turn every contravariant functor into a category theory pullback or vice versa? (Or every covariant functor into a category theory pushforward or vice versa?) If the answer to 3. is no, then it seems like the fact that the two concepts have the same name is just a historical accident, and does not indicate that one is meant to generalize the other. 4. Is it true that the similar terminology between the two fields is a historical accident? Or are they both meant to evoke the same type of basic example?",,"['differential-geometry', 'category-theory', 'terminology']"
38,Restriction of a $C^{\infty}$ vector bundle over a regular submanifold.,Restriction of a  vector bundle over a regular submanifold.,C^{\infty},"This question is about the content of page 134 of Tu's An Introduction to Manifolds . A $C^{\infty}$ vector bundle or rank r is a triple $(E,M,\pi)$ consisting of manifolds $E$ and $M$ and a surjective smooth map $\pi:E\rightarrow M$ that is locally trivial of rank $r$. More precisely, (i) each fiber $\pi^{-1}(p)$ has the structure of a vector space of dimension $r$, (ii) for each $p\in M$, there are an open neighborhood $U$ of $p$ and a fiber-preserving diffeomorphism $\phi:\pi^{-1}(U)\rightarrow U\times\mathbb{R}^n$ such that for every $q\in U$ the restriction $$\phi\mid_{\pi^{-1}(q)}:\pi^{-1}(q)\rightarrow \{q\}\times\mathbb{R}^r$$ is a vector space isomorphism. My question is: Given any regular submanifold $S\subset M$, is the triple $(\pi^{-1}S,S,\pi\mid_{\pi^{-1}S})$ also a $C^{\infty}$ vector bundle over S? I tried to resolve this issue by checking the conditions (i) and (ii). Condition (i) is obviously satisfied. To prove (ii), I chose an adapted chart $(U,\phi)$ with $p\in U$  (which gives a chart for $S$) and tried showing that the map $$\phi\mid_{\pi^{-1}(U\cap S)}:\pi^{-1}(U\cap S)\rightarrow U\cap S\times\mathbb{R}^r$$ is a fiber-preserving diffeomorphism. But is this map necessarily a diffeomorphism? This is a restriction of a diffeomorphism, and even though it possesses an inverse (using $\phi^{-1}$) which looks like a smooth inverse for $\phi$, we don't know what manifold structures the sets $\pi^{-1}(U\cap S),U\cap S\times\mathbb{R}^r$ have yet, and I'm hesistated to say for sure that those maps are smooth maps, let alone inverse maps to each other. In summary: Do the sets $\pi^{-1}(U\cap S),U\cap S\times\mathbb{R}^r$ have manifold strutures? Canonical ones? Is this true in general? In what sense? : Restriction of a vector bundle is a vector bundle. Thanks in advance.","This question is about the content of page 134 of Tu's An Introduction to Manifolds . A $C^{\infty}$ vector bundle or rank r is a triple $(E,M,\pi)$ consisting of manifolds $E$ and $M$ and a surjective smooth map $\pi:E\rightarrow M$ that is locally trivial of rank $r$. More precisely, (i) each fiber $\pi^{-1}(p)$ has the structure of a vector space of dimension $r$, (ii) for each $p\in M$, there are an open neighborhood $U$ of $p$ and a fiber-preserving diffeomorphism $\phi:\pi^{-1}(U)\rightarrow U\times\mathbb{R}^n$ such that for every $q\in U$ the restriction $$\phi\mid_{\pi^{-1}(q)}:\pi^{-1}(q)\rightarrow \{q\}\times\mathbb{R}^r$$ is a vector space isomorphism. My question is: Given any regular submanifold $S\subset M$, is the triple $(\pi^{-1}S,S,\pi\mid_{\pi^{-1}S})$ also a $C^{\infty}$ vector bundle over S? I tried to resolve this issue by checking the conditions (i) and (ii). Condition (i) is obviously satisfied. To prove (ii), I chose an adapted chart $(U,\phi)$ with $p\in U$  (which gives a chart for $S$) and tried showing that the map $$\phi\mid_{\pi^{-1}(U\cap S)}:\pi^{-1}(U\cap S)\rightarrow U\cap S\times\mathbb{R}^r$$ is a fiber-preserving diffeomorphism. But is this map necessarily a diffeomorphism? This is a restriction of a diffeomorphism, and even though it possesses an inverse (using $\phi^{-1}$) which looks like a smooth inverse for $\phi$, we don't know what manifold structures the sets $\pi^{-1}(U\cap S),U\cap S\times\mathbb{R}^r$ have yet, and I'm hesistated to say for sure that those maps are smooth maps, let alone inverse maps to each other. In summary: Do the sets $\pi^{-1}(U\cap S),U\cap S\times\mathbb{R}^r$ have manifold strutures? Canonical ones? Is this true in general? In what sense? : Restriction of a vector bundle is a vector bundle. Thanks in advance.",,"['differential-geometry', 'algebraic-topology', 'differential-topology']"
39,Killing fields on product metrics,Killing fields on product metrics,,"Let $(M_i,g_i)$ be Riemannian manifolds, $i=1,2$. (Save Euclidiean factors) Is it true that a Killing field $Z$ on $(M_1\times M_2,g_1\times g_2)$ will split as a sum of Killing fields $Z=X+Y$, where $X$ is Killing on $M_1$ and $Y$ on $M_2$? The converse is obviously true: if $X$ and $Y$ are Killing, so it is $Z$; and it is obviously false for a product of Euclidean spaces: $(\mathbb R^2,dx^2+dy^2)=(\mathbb R, dt^2)\times(\mathbb R, dt^2)$ and the isometry group of $\mathbb R^2$ is pretty bigger then the product of the groups of $\mathbb R$. The question arises from a question on foliations: does Riemannian foliations with (reducible) totally geodesic leaves (locally) splits as products of orthogonal Riemannian foliations?","Let $(M_i,g_i)$ be Riemannian manifolds, $i=1,2$. (Save Euclidiean factors) Is it true that a Killing field $Z$ on $(M_1\times M_2,g_1\times g_2)$ will split as a sum of Killing fields $Z=X+Y$, where $X$ is Killing on $M_1$ and $Y$ on $M_2$? The converse is obviously true: if $X$ and $Y$ are Killing, so it is $Z$; and it is obviously false for a product of Euclidean spaces: $(\mathbb R^2,dx^2+dy^2)=(\mathbb R, dt^2)\times(\mathbb R, dt^2)$ and the isometry group of $\mathbb R^2$ is pretty bigger then the product of the groups of $\mathbb R$. The question arises from a question on foliations: does Riemannian foliations with (reducible) totally geodesic leaves (locally) splits as products of orthogonal Riemannian foliations?",,"['differential-geometry', 'riemannian-geometry']"
40,Geometric meaning of the contact condition?,Geometric meaning of the contact condition?,,"I am trying to understand contact structures. The definition of a contact manifold is this: Let $M$  be a $2n + 1$-manifold and let $\omega$ be a differential $1$-form such that $\omega \wedge (d\omega)^n \neq 0$ pointwise. Then $M$ is a contact manifold and $\omega$ defines a contact structure on $M$. Without using differential forms I think it means something like this: A contact structure on $M$ is a smooth distribution of hyperplanes. This means that there is a smooth map $D$, the distribution, with the property that $D(m)$ is a $2n$-dimensional subspace of $T_m M$ for all $m \in M$. At least, this is my understanding so far. Finding uninteresting examples seems easy: For example, take the sphere $S^2 \subset \mathbb R^3$ and consider tangent lines that vary smoothly with $m \in S^2$. Writing down an explicit expression for these smooth tangent lines poses a slight challenge to me I admit and I am wondering whether if I could write down a formula that defines a tangent line to $S^2$ in $\mathbb R^3$ if it would help me gain intuitive understanding of this mysterious condition $\omega \wedge (d\omega)^n \neq 0$. So my question is: What are we trying to achieve by requiring $\omega \wedge (d\omega)^n  \neq 0$? What does it achieve in terms of the geometric properties of   the distribution of hyperplanes?","I am trying to understand contact structures. The definition of a contact manifold is this: Let $M$  be a $2n + 1$-manifold and let $\omega$ be a differential $1$-form such that $\omega \wedge (d\omega)^n \neq 0$ pointwise. Then $M$ is a contact manifold and $\omega$ defines a contact structure on $M$. Without using differential forms I think it means something like this: A contact structure on $M$ is a smooth distribution of hyperplanes. This means that there is a smooth map $D$, the distribution, with the property that $D(m)$ is a $2n$-dimensional subspace of $T_m M$ for all $m \in M$. At least, this is my understanding so far. Finding uninteresting examples seems easy: For example, take the sphere $S^2 \subset \mathbb R^3$ and consider tangent lines that vary smoothly with $m \in S^2$. Writing down an explicit expression for these smooth tangent lines poses a slight challenge to me I admit and I am wondering whether if I could write down a formula that defines a tangent line to $S^2$ in $\mathbb R^3$ if it would help me gain intuitive understanding of this mysterious condition $\omega \wedge (d\omega)^n \neq 0$. So my question is: What are we trying to achieve by requiring $\omega \wedge (d\omega)^n  \neq 0$? What does it achieve in terms of the geometric properties of   the distribution of hyperplanes?",,"['differential-geometry', 'intuition', 'contact-topology']"
41,How to prove that the wedge product is the determinant (Spivak's Claim),How to prove that the wedge product is the determinant (Spivak's Claim),,"In the book I am using now, Spivak's A comprehensive introduction to differential geometry volume 1 I have a question on page 205. Because he says the following: \begin{align*}                    \phi_1\wedge\cdots\wedge\phi_n &= \frac{(1+\cdots+1)!}{1!\cdots_1!}\operatorname{Alt}\left( \phi_1 \otimes\cdot\otimes\phi_n \right)\\                                      &=  \sum_{\sigma\in S_n} \operatorname{sgn}\sigma\cdot\left( \phi_1\otimes\cdots\otimes\phi _n \right)   \circ \sigma    .    \end{align*} In particular, $$            \left( \phi_1\wedge\cdots\wedge\phi _n \right) \left( v_1,\ldots,v_n \right) =1    .$$ (So if $v_1,\ldots,v_n$ is the standard basis for $\mathbb{R}^{n}$ , then $\phi_1\wedge\cdots\wedge\phi _n=\det$ .) A basis for $\Omega ^{k}(V)$ can n    ow be described. I think this is equivalent to say the following Let $\{e_i\}$ be the standard basis for $\mathbb{R}^{n}$ and let $\{e_i^{\ast}\}$ be dual basis then I want to conclude that $e_1^{\ast} \wedge e_2^{\ast} \wedge ... \wedge e_n^{\ast}$ is the determinant tensor because I have seen that is books or courses this is given as the definition but for me in dimension 2 is little bit different, $$v_1^{\ast} \wedge v_2^{\ast}=v_1^{\ast} \otimes v_2^{\ast}-v_2^{\ast} \otimes v_1^{\ast}$$ I know that somehow this could be interpret as the determinant but I can't figure out how can I prove the equivalence of the definitions and what Spivak is claiming in that part of the book. I was trying to figure out this knowing how the wedge product $e_1^{\ast} \wedge e_2^{\ast} \wedge \cdots \wedge e_n^{\ast}$ evaluate on the standard basis, and using skew symmetry and multi-linearity, but I'm still puzzled. Thanks a lot in advance. Attempts I was trying to do something of the following sort We take $T \in \Lambda^{k}(V^{k})$ and $\{v_i\}$ a basis for V, then we can form k-tuples but we discard the ones that are $v_i\times \cdots \times v_i$ since this is zero so $T$ is uniquely determined by $T(v_1,\cdots,v_k)=c$ . But then $$c(v_1^{\ast} \wedge v_2^{\ast} \wedge \cdots \wedge v_n^{\ast})$$ is in $\Lambda^{k}(V^{k})$ and $c(v_1^{\ast} \wedge v_2^{\ast} \wedge \cdots \wedge v_n^{\ast})(v_1,\cdots,v_k)=c$ so that implies that $T=c(v_1^{\ast} \wedge v_2^{\ast} \wedge \cdots \wedge v_n^{\ast})$ But I don't know if this is right or how to perform this in my case. The reason because of I was trying to use the evaluation in the standard basis is because I have the following lemma Lemma: Let $A: V \to V$ be a linear map. Then if $w_i=Av_i$ , $v_1,v_2 \in V$ then $$v_1^{*} \wedge v_2^{*}(w_1,w_2)=detA (v_1^{*} \wedge v_2^{*})(v_1,v_2)$$ May be another way to prove this is to prove that that the wedge product satisfies the definition of determinant given in the book Second Year Calculus by Bressoud but by definition the wedge product is linear and the conditions that $e_1^{\ast} \wedge e_2^{\ast} \wedge \cdots \wedge e_n^{\ast}(e_1,\cdots,e_n)=1$ holds (I don't know how to prove that) the same for the condition that $e_1^{\ast} \wedge e_2^{\ast} \wedge \cdots \wedge e_n^{\ast}(e_1,e_2,\cdots,e_2,e_n)=0$ So I don't know if this is a good way to proceed.","In the book I am using now, Spivak's A comprehensive introduction to differential geometry volume 1 I have a question on page 205. Because he says the following: In particular, (So if is the standard basis for , then .) A basis for can n    ow be described. I think this is equivalent to say the following Let be the standard basis for and let be dual basis then I want to conclude that is the determinant tensor because I have seen that is books or courses this is given as the definition but for me in dimension 2 is little bit different, I know that somehow this could be interpret as the determinant but I can't figure out how can I prove the equivalence of the definitions and what Spivak is claiming in that part of the book. I was trying to figure out this knowing how the wedge product evaluate on the standard basis, and using skew symmetry and multi-linearity, but I'm still puzzled. Thanks a lot in advance. Attempts I was trying to do something of the following sort We take and a basis for V, then we can form k-tuples but we discard the ones that are since this is zero so is uniquely determined by . But then is in and so that implies that But I don't know if this is right or how to perform this in my case. The reason because of I was trying to use the evaluation in the standard basis is because I have the following lemma Lemma: Let be a linear map. Then if , then May be another way to prove this is to prove that that the wedge product satisfies the definition of determinant given in the book Second Year Calculus by Bressoud but by definition the wedge product is linear and the conditions that holds (I don't know how to prove that) the same for the condition that So I don't know if this is a good way to proceed.","\begin{align*}
                   \phi_1\wedge\cdots\wedge\phi_n &= \frac{(1+\cdots+1)!}{1!\cdots_1!}\operatorname{Alt}\left( \phi_1 \otimes\cdot\otimes\phi_n \right)\\                                      &=  \sum_{\sigma\in S_n} \operatorname{sgn}\sigma\cdot\left( \phi_1\otimes\cdots\otimes\phi _n \right)   \circ \sigma
   .
   \end{align*} 
           \left( \phi_1\wedge\cdots\wedge\phi _n \right) \left( v_1,\ldots,v_n \right) =1
   . v_1,\ldots,v_n \mathbb{R}^{n} \phi_1\wedge\cdots\wedge\phi _n=\det \Omega ^{k}(V) \{e_i\} \mathbb{R}^{n} \{e_i^{\ast}\} e_1^{\ast} \wedge e_2^{\ast} \wedge ... \wedge e_n^{\ast} v_1^{\ast} \wedge v_2^{\ast}=v_1^{\ast} \otimes v_2^{\ast}-v_2^{\ast} \otimes v_1^{\ast} e_1^{\ast} \wedge e_2^{\ast} \wedge \cdots \wedge e_n^{\ast} T \in \Lambda^{k}(V^{k}) \{v_i\} v_i\times \cdots \times v_i T T(v_1,\cdots,v_k)=c c(v_1^{\ast} \wedge v_2^{\ast} \wedge \cdots \wedge v_n^{\ast}) \Lambda^{k}(V^{k}) c(v_1^{\ast} \wedge v_2^{\ast} \wedge \cdots \wedge v_n^{\ast})(v_1,\cdots,v_k)=c T=c(v_1^{\ast} \wedge v_2^{\ast} \wedge \cdots \wedge v_n^{\ast}) A: V \to V w_i=Av_i v_1,v_2 \in V v_1^{*} \wedge v_2^{*}(w_1,w_2)=detA (v_1^{*} \wedge v_2^{*})(v_1,v_2) e_1^{\ast} \wedge e_2^{\ast} \wedge \cdots \wedge e_n^{\ast}(e_1,\cdots,e_n)=1 e_1^{\ast} \wedge e_2^{\ast} \wedge \cdots \wedge e_n^{\ast}(e_1,e_2,\cdots,e_2,e_n)=0",['differential-geometry']
42,Why is this proof that a circular cone is not a surface not rigorous?,Why is this proof that a circular cone is not a surface not rigorous?,,"In example $4.1.5$, page $73$ of Pressley's Elementary Differential Geometry, a ""heuristic"" argument is given to prove that the circular cone with vertex the origin and angle $\pi/4$, is not a surface. Here are the exact words: To see that it is not a surface, suppose that $\sigma: U \to S \cap W$ is a surface patch containing the vertex $(0,0,0)$ of the cone, and let $a\in U$ correspond to the vertex. We can assume that $U$ is an open ball with center $a$, since any open set $U$ containing $a$ must contain such an open ball. The open set $W$ must obviously contain a point $p$ in the lower half $S_{-}$ of $S$ where $z < 0$ and a point $q$ in the upper half $S^{+}$ where $z>0$; let $b$ and $c$ be the corresponding points in $U$. It is clear that there's a curve $\pi$ in $U$ passing through $b$ and $c$, but not passing through $a$. This is mapped by $\sigma$ into a curve $\gamma = \sigma \circ \pi$ lying entirely in $S$, passing through $p$ and $q$, and not passing through the vertex. (It is true that $\gamma$ will, in general, only be continuous, and not smooth, but this does not affect the argument.) This is clearly impossible. (Readers familiar with point set topology will be able to make this heuristic argument rigorous). Why is this argument not considered rigorous? Can someone give an outline of how a rigorous argument should be?","In example $4.1.5$, page $73$ of Pressley's Elementary Differential Geometry, a ""heuristic"" argument is given to prove that the circular cone with vertex the origin and angle $\pi/4$, is not a surface. Here are the exact words: To see that it is not a surface, suppose that $\sigma: U \to S \cap W$ is a surface patch containing the vertex $(0,0,0)$ of the cone, and let $a\in U$ correspond to the vertex. We can assume that $U$ is an open ball with center $a$, since any open set $U$ containing $a$ must contain such an open ball. The open set $W$ must obviously contain a point $p$ in the lower half $S_{-}$ of $S$ where $z < 0$ and a point $q$ in the upper half $S^{+}$ where $z>0$; let $b$ and $c$ be the corresponding points in $U$. It is clear that there's a curve $\pi$ in $U$ passing through $b$ and $c$, but not passing through $a$. This is mapped by $\sigma$ into a curve $\gamma = \sigma \circ \pi$ lying entirely in $S$, passing through $p$ and $q$, and not passing through the vertex. (It is true that $\gamma$ will, in general, only be continuous, and not smooth, but this does not affect the argument.) This is clearly impossible. (Readers familiar with point set topology will be able to make this heuristic argument rigorous). Why is this argument not considered rigorous? Can someone give an outline of how a rigorous argument should be?",,['differential-geometry']
43,On a proof that the metric volume form is parallel wrt to the Levi-Civita connection,On a proof that the metric volume form is parallel wrt to the Levi-Civita connection,,"In the context of (semi-)Riemannian geometry, the following fact is well-known: if a (semi-)Riemannian manifold $(M,g)$ is oriented, then the unique volume form $\epsilon = \mathrm{vol}_g$, induced by the metric together with the orientation, is parallel with respect to the Levi-Civita connection $\nabla$. That is, $$ \nabla \epsilon = 0$$ or, using indices, $\nabla_b \epsilon _{a_1 \cdots a_n}=0$ where $n = \mathrm{dim}(M)$. I am aware of a few different ways of proving this result and most make good sense to me. My problem is that I can't seem to completely follow the logic in one particular proof which I found in Robert M. Wald's ""General Relativity"" (Appendix B, page 432). The argument there goes as follows: $\epsilon$ is uniquely specified by the choice of orientation together with the condition $$ \epsilon^{a_1 \cdots a_n}  \epsilon_{a_1 \cdots a_n} = (-1)^s n! $$ where $s$ is the number of negative eigenvalues of $g$ (so $s=0$ for a Riemannian metric) and indices are raised and lowered using $g$. Taking covariant derivatives, since the RHS is constant, one has $$ 0 = \nabla_b (\epsilon^{a_1 \cdots a_n}  \epsilon_{a_1 \cdots a_n}) = (\nabla_b \epsilon^{a_1 \cdots a_n})  \epsilon_{a_1 \cdots a_n} + \epsilon^{a_1 \cdots a_n} \nabla_b \epsilon_{a_1 \cdots a_n} = 2\epsilon^{a_1 \cdots a_n} \nabla_b \epsilon_{a_1 \cdots a_n}$$ using the fact that the metric is parallel with respect to $g$ in the last step. So far so good, we have obtained that $\epsilon^{a_1 \cdots a_n} \nabla_b \epsilon_{a_1 \cdots a_n} = 0$. Question. But then it is argued that this, ""in turn, implies that $\nabla_b \epsilon_{a_1 \cdots a_n}=0$ since $\epsilon_{a_1 \cdots a_n}$ is totally antisymmetric in its last $n$ indices and $\epsilon^{a_1 \cdots a_n}$ is non-vanishing"". Can anyone expand on the logic of how this implication works? I have tried to interpret this by thinking of $\epsilon^{a_1 \cdots a_n}$ and of $\nabla_j \epsilon_{a_1 \cdots a_n}$, for each fixed $j$, as analogous to two antisymmetric matrices $A$ and $B$ respectively, and the desired statement is then something like $$ \mathrm{Tr}(A^TB) = 0 \ \Longrightarrow \ B = 0,$$ but I can't seem to get very far with this reasoning. Thanks in advance for your help!","In the context of (semi-)Riemannian geometry, the following fact is well-known: if a (semi-)Riemannian manifold $(M,g)$ is oriented, then the unique volume form $\epsilon = \mathrm{vol}_g$, induced by the metric together with the orientation, is parallel with respect to the Levi-Civita connection $\nabla$. That is, $$ \nabla \epsilon = 0$$ or, using indices, $\nabla_b \epsilon _{a_1 \cdots a_n}=0$ where $n = \mathrm{dim}(M)$. I am aware of a few different ways of proving this result and most make good sense to me. My problem is that I can't seem to completely follow the logic in one particular proof which I found in Robert M. Wald's ""General Relativity"" (Appendix B, page 432). The argument there goes as follows: $\epsilon$ is uniquely specified by the choice of orientation together with the condition $$ \epsilon^{a_1 \cdots a_n}  \epsilon_{a_1 \cdots a_n} = (-1)^s n! $$ where $s$ is the number of negative eigenvalues of $g$ (so $s=0$ for a Riemannian metric) and indices are raised and lowered using $g$. Taking covariant derivatives, since the RHS is constant, one has $$ 0 = \nabla_b (\epsilon^{a_1 \cdots a_n}  \epsilon_{a_1 \cdots a_n}) = (\nabla_b \epsilon^{a_1 \cdots a_n})  \epsilon_{a_1 \cdots a_n} + \epsilon^{a_1 \cdots a_n} \nabla_b \epsilon_{a_1 \cdots a_n} = 2\epsilon^{a_1 \cdots a_n} \nabla_b \epsilon_{a_1 \cdots a_n}$$ using the fact that the metric is parallel with respect to $g$ in the last step. So far so good, we have obtained that $\epsilon^{a_1 \cdots a_n} \nabla_b \epsilon_{a_1 \cdots a_n} = 0$. Question. But then it is argued that this, ""in turn, implies that $\nabla_b \epsilon_{a_1 \cdots a_n}=0$ since $\epsilon_{a_1 \cdots a_n}$ is totally antisymmetric in its last $n$ indices and $\epsilon^{a_1 \cdots a_n}$ is non-vanishing"". Can anyone expand on the logic of how this implication works? I have tried to interpret this by thinking of $\epsilon^{a_1 \cdots a_n}$ and of $\nabla_j \epsilon_{a_1 \cdots a_n}$, for each fixed $j$, as analogous to two antisymmetric matrices $A$ and $B$ respectively, and the desired statement is then something like $$ \mathrm{Tr}(A^TB) = 0 \ \Longrightarrow \ B = 0,$$ but I can't seem to get very far with this reasoning. Thanks in advance for your help!",,"['differential-geometry', 'riemannian-geometry', 'tensors', 'general-relativity', 'semi-riemannian-geometry']"
44,Does it necessarily follow that the integral curves of $k^a$ are null geodesics?,Does it necessarily follow that the integral curves of  are null geodesics?,k^a,"Let $f$ be a function on a spacetime $(M, g_{ab})$ whose gradient, $k_a = \nabla_a f$, ie everywhere null, i.e., $k_ak^a = 0$ throughout $M$. Does it necessarily follow that the integral curves of $k^a$ are null geodesics?","Let $f$ be a function on a spacetime $(M, g_{ab})$ whose gradient, $k_a = \nabla_a f$, ie everywhere null, i.e., $k_ak^a = 0$ throughout $M$. Does it necessarily follow that the integral curves of $k^a$ are null geodesics?",,"['differential-geometry', 'manifolds', 'riemannian-geometry', 'mathematical-physics', 'general-relativity']"
45,The knowledge of $n=n(s)$ can be used to determine the curvature $k(s)$ and the torsion $\tau (s)$,The knowledge of  can be used to determine the curvature  and the torsion,n=n(s) k(s) \tau (s),"Question: Show that the knowledge of the vector function $n=n(s)$ of a curve $\alpha:I\rightarrow \mathbb{R^3}$ with nonzero torsion everywhere, determines the curvature $k(s)$ and the torsion $\tau (s)$ of $\alpha$. Notes: $n$ is the normal versor to $\alpha$. Attempt: I tried using Frenet-Serret formulas, and then using the vector product between $n$ and $n'$, but it seems like I can't get to any result.","Question: Show that the knowledge of the vector function $n=n(s)$ of a curve $\alpha:I\rightarrow \mathbb{R^3}$ with nonzero torsion everywhere, determines the curvature $k(s)$ and the torsion $\tau (s)$ of $\alpha$. Notes: $n$ is the normal versor to $\alpha$. Attempt: I tried using Frenet-Serret formulas, and then using the vector product between $n$ and $n'$, but it seems like I can't get to any result.",,['differential-geometry']
46,How to simplify $\frac{\partial^m}{\partial y_i^m}\mathrm{div }(A\nabla u({\bf x}({\bf y})))$,How to simplify,\frac{\partial^m}{\partial y_i^m}\mathrm{div }(A\nabla u({\bf x}({\bf y}))),"Let $\bf{x}\in\mathbb{R}^n$ (interesting in $n\in\{2,3\}$) and let $A=A_{n\times  n}=\mathrm{diag}(a_1({\bf x}),\dots,a_n({\bf x}))$, that is  $$A_{2\times2}=\begin{bmatrix} a_1(\bf{x})&0\\0&a_2(\bf{x}) \end{bmatrix} \quad \text{or}\quad A_{3\times3}=\begin{bmatrix} a_1(\bf{x})&0&0\\0&a_2(\bf{x})&0\\ 0&0& a_3(\bf{x}) \end{bmatrix} $$ Assume that $a_i\ne a_j, \forall 1\le i,j\le n$. Let $\bf y$ be some curvilinear coordinates, e.g. elliptic, spherical, normal-tangential. I'm interesting to differentiate $$\mathrm{L}u({\bf x}) =\{\mathrm{div }(A\nabla u)\}({\bf x})$$ with respect to $y_i$ , that is to express  $$\frac{\partial^m}{\partial y_i^m} \mathrm{L}u({\bf x}),\quad \text{interesting in no more then }0\le m\le4$$  explicitly but compact (by $m=0$ I mean just change of coordinates). The expression, that I got so far (using scale factors\metrics), become too long and ugly. Say it is become pretty much unmanageable when I need to program it, which make it vulnerable for bugs and may affect numerical stability as well. Example in 2D Let $a_1=a, a_2=b$ one translates $$ \mathrm{L} u = \frac{\partial}{\partial x} \left( a u_x \right) +  \frac{\partial}{\partial y} \left( b u_y \right) =   a_x u_x + a u_{xx} + b_y u_y + b u_{yy}  $$ to some (s,t) coordinates to get $$  \alpha u_s + \beta u_t  +\gamma u_{st} +\delta u_{tt} +\sigma u_{ss} $$ and differentiate it, for an instant with respect to $s$ it to get $$\begin{align} & \alpha_s u_s +\alpha u_{ss} + \beta_s u_t + \beta u_{ts}   +\gamma_s u_{st}+\gamma u_{sst} +\delta_s u_{tt}+\delta u_{tts} +\sigma_s u_{ss}+\sigma u_{sss}\\ =& \alpha_s u_s + \beta_s u_t+ (\alpha +\sigma_s) u_{ss}  +\delta_s u_{tt}+ (\beta +\gamma_s) u_{st} +\gamma u_{sst}+\delta u_{tts}+\sigma u_{sss} \end{align}$$ Any help will be appreciated.","Let $\bf{x}\in\mathbb{R}^n$ (interesting in $n\in\{2,3\}$) and let $A=A_{n\times  n}=\mathrm{diag}(a_1({\bf x}),\dots,a_n({\bf x}))$, that is  $$A_{2\times2}=\begin{bmatrix} a_1(\bf{x})&0\\0&a_2(\bf{x}) \end{bmatrix} \quad \text{or}\quad A_{3\times3}=\begin{bmatrix} a_1(\bf{x})&0&0\\0&a_2(\bf{x})&0\\ 0&0& a_3(\bf{x}) \end{bmatrix} $$ Assume that $a_i\ne a_j, \forall 1\le i,j\le n$. Let $\bf y$ be some curvilinear coordinates, e.g. elliptic, spherical, normal-tangential. I'm interesting to differentiate $$\mathrm{L}u({\bf x}) =\{\mathrm{div }(A\nabla u)\}({\bf x})$$ with respect to $y_i$ , that is to express  $$\frac{\partial^m}{\partial y_i^m} \mathrm{L}u({\bf x}),\quad \text{interesting in no more then }0\le m\le4$$  explicitly but compact (by $m=0$ I mean just change of coordinates). The expression, that I got so far (using scale factors\metrics), become too long and ugly. Say it is become pretty much unmanageable when I need to program it, which make it vulnerable for bugs and may affect numerical stability as well. Example in 2D Let $a_1=a, a_2=b$ one translates $$ \mathrm{L} u = \frac{\partial}{\partial x} \left( a u_x \right) +  \frac{\partial}{\partial y} \left( b u_y \right) =   a_x u_x + a u_{xx} + b_y u_y + b u_{yy}  $$ to some (s,t) coordinates to get $$  \alpha u_s + \beta u_t  +\gamma u_{st} +\delta u_{tt} +\sigma u_{ss} $$ and differentiate it, for an instant with respect to $s$ it to get $$\begin{align} & \alpha_s u_s +\alpha u_{ss} + \beta_s u_t + \beta u_{ts}   +\gamma_s u_{st}+\gamma u_{sst} +\delta_s u_{tt}+\delta u_{tts} +\sigma_s u_{ss}+\sigma u_{sss}\\ =& \alpha_s u_s + \beta_s u_t+ (\alpha +\sigma_s) u_{ss}  +\delta_s u_{tt}+ (\beta +\gamma_s) u_{st} +\gamma u_{sst}+\delta u_{tts}+\sigma u_{sss} \end{align}$$ Any help will be appreciated.",,"['differential-geometry', 'tensor-products', 'tensors', 'curvature', 'chain-rule']"
47,First variation of an action?,First variation of an action?,,"I'm working on a problem and I must compute the first variation of an action. Let $\Omega$ is a 2-form on a semi-Riemannian manifold $M$ and $f$ is a smooth function and $\Gamma$ is an 1-form on $M$. I obtained the following equality \begin{equation} \int_M (\langle\Gamma-\Omega(\nabla h,.),\delta\rangle+f(x)h )dV_g=0 \end{equation} for all $h\in C^\infty (M)$ and all 1-form $\delta$ on $M$. This equality cannot be simpler. $\nabla h$ is gradient of $h$. What can I deduce frome this equality? Is this true that $\Omega$ and $f$ and $\Gamma$ must be identical to zero?","I'm working on a problem and I must compute the first variation of an action. Let $\Omega$ is a 2-form on a semi-Riemannian manifold $M$ and $f$ is a smooth function and $\Gamma$ is an 1-form on $M$. I obtained the following equality \begin{equation} \int_M (\langle\Gamma-\Omega(\nabla h,.),\delta\rangle+f(x)h )dV_g=0 \end{equation} for all $h\in C^\infty (M)$ and all 1-form $\delta$ on $M$. This equality cannot be simpler. $\nabla h$ is gradient of $h$. What can I deduce frome this equality? Is this true that $\Omega$ and $f$ and $\Gamma$ must be identical to zero?",,['differential-geometry']
48,Lie derivative for a wedge product $\omega_{1}\wedge\omega_{2}$,Lie derivative for a wedge product,\omega_{1}\wedge\omega_{2},"Question: I have to prove that $$\mathcal L_X\omega_{1}\wedge\omega_{2}=(\mathcal L_X\omega_{1})\wedge\omega_{2}+\omega_{1}\wedge(\mathcal L_X\omega_{2})$$ using the definition $$\mathcal L_X\omega=\frac{d}{dt}\bigg|_{t=0}\varphi_t^*\omega=\lim_{t\rightarrow 0} \frac{\varphi_t^*\omega-\omega}{t}$$ Attempt: I get $$\mathcal L_X(\omega_{1}\wedge\omega_{2})=\frac{d}{dt}\bigg |_{t=0}\varphi_t^*(\omega_{1}\wedge\omega_{2})$$ The homework hint says : Use $\varphi_t^*(\omega_{1}\wedge\omega_{2})=(\varphi_t^*\omega_{1})\wedge(\varphi_t^*\omega_{2})$ and the result is immediate, but I can't see the next step and I figure that thes proof hidden a trick.","Question: I have to prove that using the definition Attempt: I get The homework hint says : Use and the result is immediate, but I can't see the next step and I figure that thes proof hidden a trick.",\mathcal L_X\omega_{1}\wedge\omega_{2}=(\mathcal L_X\omega_{1})\wedge\omega_{2}+\omega_{1}\wedge(\mathcal L_X\omega_{2}) \mathcal L_X\omega=\frac{d}{dt}\bigg|_{t=0}\varphi_t^*\omega=\lim_{t\rightarrow 0} \frac{\varphi_t^*\omega-\omega}{t} \mathcal L_X(\omega_{1}\wedge\omega_{2})=\frac{d}{dt}\bigg |_{t=0}\varphi_t^*(\omega_{1}\wedge\omega_{2}) \varphi_t^*(\omega_{1}\wedge\omega_{2})=(\varphi_t^*\omega_{1})\wedge(\varphi_t^*\omega_{2}),"['differential-geometry', 'differential-forms', 'lie-derivative']"
49,"Hausdorff measure, volume form, reference","Hausdorff measure, volume form, reference",,"Could you tell me where I can find a reference to the fourth corollary in this encyclopedia ? Corollary $4$: Assume that $\Sigma \subset \mathbb{R}^m$ is an $n$-dimensional $C^1$   submanifold. Then the Hausdorff dimension of $\Sigma$ is $n$ and, for   any relatively open set $U \subset \Sigma$ $$\mathcal{H}^n(U)=  \int_U \mathrm{dvol}$$ where $\mathrm{dvol}$ denotes the usual volume form of   $\Sigma$ as Riemannian submanifold of $\mathbb{R}^n$ It is also stated in this article of the encyclopedia.","Could you tell me where I can find a reference to the fourth corollary in this encyclopedia ? Corollary $4$: Assume that $\Sigma \subset \mathbb{R}^m$ is an $n$-dimensional $C^1$   submanifold. Then the Hausdorff dimension of $\Sigma$ is $n$ and, for   any relatively open set $U \subset \Sigma$ $$\mathcal{H}^n(U)=  \int_U \mathrm{dvol}$$ where $\mathrm{dvol}$ denotes the usual volume form of   $\Sigma$ as Riemannian submanifold of $\mathbb{R}^n$ It is also stated in this article of the encyclopedia.",,"['differential-geometry', 'reference-request', 'manifolds', 'volume', 'geometric-measure-theory']"
50,Does the Riemann tensor encode all information about the second derivatives of the metric?,Does the Riemann tensor encode all information about the second derivatives of the metric?,,In answer to this question I suggested the following as a motivation for the definition of the Riemann tensor: Let $\mathcal M$ and $\mathcal N$ be two dim-$n$ Lorentzian   manifolds with points $x\in\mathcal M$ and $y\in\mathcal N$. Then you   can pick local coordinates on $\mathcal M$ and $\mathcal N$ such that   the expressions for $g_{\mu\nu}$ agree to second order near $x$ and   $y$ iff you can find bases at $x$ and $y$ such that the Riemann   tensors are equal. Is the preceding theorem in fact true? Where can I find a proof of it?,In answer to this question I suggested the following as a motivation for the definition of the Riemann tensor: Let $\mathcal M$ and $\mathcal N$ be two dim-$n$ Lorentzian   manifolds with points $x\in\mathcal M$ and $y\in\mathcal N$. Then you   can pick local coordinates on $\mathcal M$ and $\mathcal N$ such that   the expressions for $g_{\mu\nu}$ agree to second order near $x$ and   $y$ iff you can find bases at $x$ and $y$ such that the Riemann   tensors are equal. Is the preceding theorem in fact true? Where can I find a proof of it?,,"['differential-geometry', 'reference-request', 'curvature', 'general-relativity', 'semi-riemannian-geometry']"
51,Trouble understanding the tangent bundle,Trouble understanding the tangent bundle,,"First of all, have I understood the preliminary notion of a tangent space to a point on a manifold correctly? To each point $p\in\mathcal{M}$ on an $n$-dimensional manifold $\mathcal{M}$ there exists a tangent space $T_{p}\mathcal{M}$ whose elements are the set of vectors $\lbrace\mathbf{v}\rbrace$ whose 'base' is fixed at $p\in\mathcal{M}$. Given a local coordinate chart, these vectors can be identified with the set of derivative operators which encode information about all possible speeds and directions in which one could pass through said point (at which they are bound to). The tangent space to a particular point will be an $n$-dimensional vector space, and thus, in general, contains an infinite number of vectors (as one can construct an infinite number of vectors from a chosen $n$-dimensional basis). As such, once a point is chosen, one can (essentially) independently choose a vector in the tangent space to that point [This part I'm very unsure of?!] So, as I understand it, given this one can construct a new manifold by taking the disjoint union of the tangent spaces of all the points on the manifold. This new manifold is called the tangent bundle, $$\mathcal{TM}= \bigcup_{p\in\mathcal{M}} T_{p}\mathcal{M}$$ Intuitively I kind of see how this is a $2n$-dimensional manifold, as for each point $p\in\mathcal{M}$ on the $n$-dimensional manifold $\mathcal{M}$ there is an $n$-dimensional tangent space $T_{p}\mathcal{M}$, and as such a point in the manifold $\mathcal{TM}$ is an ordered pair, $(p,\mathbf{v})\in \mathcal{TM}$, uniquely determined by specifying a point $p\in\mathcal{M}$ and a vector $\mathbf{v}\in T_{p}\mathcal{M}$ in the tangent space to that point. However, my confusion arises in why we can treat $p$ and $\mathbf{v}$ as independent variables (surely we need to specify a particular value of $p$ be we can choose a tangent vector $\mathbf{v}$. If they were truly independent shouldn't it be possible to choose them in any order, e.g. choose a $\mathbf{v}$ be choosing a value $p$)?","First of all, have I understood the preliminary notion of a tangent space to a point on a manifold correctly? To each point $p\in\mathcal{M}$ on an $n$-dimensional manifold $\mathcal{M}$ there exists a tangent space $T_{p}\mathcal{M}$ whose elements are the set of vectors $\lbrace\mathbf{v}\rbrace$ whose 'base' is fixed at $p\in\mathcal{M}$. Given a local coordinate chart, these vectors can be identified with the set of derivative operators which encode information about all possible speeds and directions in which one could pass through said point (at which they are bound to). The tangent space to a particular point will be an $n$-dimensional vector space, and thus, in general, contains an infinite number of vectors (as one can construct an infinite number of vectors from a chosen $n$-dimensional basis). As such, once a point is chosen, one can (essentially) independently choose a vector in the tangent space to that point [This part I'm very unsure of?!] So, as I understand it, given this one can construct a new manifold by taking the disjoint union of the tangent spaces of all the points on the manifold. This new manifold is called the tangent bundle, $$\mathcal{TM}= \bigcup_{p\in\mathcal{M}} T_{p}\mathcal{M}$$ Intuitively I kind of see how this is a $2n$-dimensional manifold, as for each point $p\in\mathcal{M}$ on the $n$-dimensional manifold $\mathcal{M}$ there is an $n$-dimensional tangent space $T_{p}\mathcal{M}$, and as such a point in the manifold $\mathcal{TM}$ is an ordered pair, $(p,\mathbf{v})\in \mathcal{TM}$, uniquely determined by specifying a point $p\in\mathcal{M}$ and a vector $\mathbf{v}\in T_{p}\mathcal{M}$ in the tangent space to that point. However, my confusion arises in why we can treat $p$ and $\mathbf{v}$ as independent variables (surely we need to specify a particular value of $p$ be we can choose a tangent vector $\mathbf{v}$. If they were truly independent shouldn't it be possible to choose them in any order, e.g. choose a $\mathbf{v}$ be choosing a value $p$)?",,"['differential-geometry', 'vector-analysis']"
52,"Finding two inequivalent closed, non-exact $1$-forms on $T = S^1 \times S^1$","Finding two inequivalent closed, non-exact -forms on",1 T = S^1 \times S^1,"I've been studying the torus and the first cohomology group $H^1_{dR}(T)$ for a couple of weeks now. I finally had a breakthrough of understanding and would like to kindly request the community to check my understanding for correctness. It was my goal to find two inequivalent, closed, non-exact $1$-forms on $T=S^1 \times S^1$. Here is what I did: Step 1: Recall the basic example of $$d\theta = {x \,dy - y \,dx\over x^2 + y^2}$$ on $S^1$ and recall that it is closed and not exact. Step 2: Since $T = S^1 \times S^1$ this suggests that $d\theta, d\varphi$ are closed and not exact where $\varphi$ and $\theta$ denote the angle functions $S^1 \to (0,2\pi)$. Step 3: To prove that they are not exact we have to calculate $\oint_{S^1}$ for each. This is a line integral and the way to calculate line integrals is by choosing a parametrisation and then substituting it into the integral. We choose the parametrisations $$ \gamma(t)= (t,0)$$ and $$ \gamma'(t) = (0,t)$$ for $t \in (0,2\pi)$ and calculate $$ \oint d\theta = \int_0^{2\pi} (1,0)\cdot (1,0) \,dt = \int_0^{2\pi}dt = 2 \pi$$ and similarly $$ \oint d \varphi = 2\pi$$ So as claimed both are not exact! Step 4: $\theta$ and $\varphi$ are not equivalent if they do not differ by a closed $1$-form. Assume there was a closed $1$-form $d\eta$ such that $d \theta = d\varphi + d\eta$. Then integrating on both sides yields $$ \eta = 0$$ therefore $d\theta$ and $d\varphi$ are not equivalent. Please, if you read my work, be nitpicky and meticulous. I really   really want to understand. If there is anything above that is missing   detail then it is probably not due to my being lazy but rather due to   my lack of understanding. Any feedback is appreciated.","I've been studying the torus and the first cohomology group $H^1_{dR}(T)$ for a couple of weeks now. I finally had a breakthrough of understanding and would like to kindly request the community to check my understanding for correctness. It was my goal to find two inequivalent, closed, non-exact $1$-forms on $T=S^1 \times S^1$. Here is what I did: Step 1: Recall the basic example of $$d\theta = {x \,dy - y \,dx\over x^2 + y^2}$$ on $S^1$ and recall that it is closed and not exact. Step 2: Since $T = S^1 \times S^1$ this suggests that $d\theta, d\varphi$ are closed and not exact where $\varphi$ and $\theta$ denote the angle functions $S^1 \to (0,2\pi)$. Step 3: To prove that they are not exact we have to calculate $\oint_{S^1}$ for each. This is a line integral and the way to calculate line integrals is by choosing a parametrisation and then substituting it into the integral. We choose the parametrisations $$ \gamma(t)= (t,0)$$ and $$ \gamma'(t) = (0,t)$$ for $t \in (0,2\pi)$ and calculate $$ \oint d\theta = \int_0^{2\pi} (1,0)\cdot (1,0) \,dt = \int_0^{2\pi}dt = 2 \pi$$ and similarly $$ \oint d \varphi = 2\pi$$ So as claimed both are not exact! Step 4: $\theta$ and $\varphi$ are not equivalent if they do not differ by a closed $1$-form. Assume there was a closed $1$-form $d\eta$ such that $d \theta = d\varphi + d\eta$. Then integrating on both sides yields $$ \eta = 0$$ therefore $d\theta$ and $d\varphi$ are not equivalent. Please, if you read my work, be nitpicky and meticulous. I really   really want to understand. If there is anything above that is missing   detail then it is probably not due to my being lazy but rather due to   my lack of understanding. Any feedback is appreciated.",,"['differential-geometry', 'homology-cohomology', 'differential-forms']"
53,Sub-manifold with boundary,Sub-manifold with boundary,,"Let $f:M\rightarrow \mathbb{R}$ be a smooth function ($M$ is a smooth manifold). Let $a$ be a regular value of $f$. Is it true that $f^{-1}(-\infty ,a]$ is a smooth manifold with boundary $f^{-1}\{a\}$? My feel is that it is correct and the proof is very similar to the proof that $f^{-1}\{a\}$ is a smooth manifold. Am I right?","Let $f:M\rightarrow \mathbb{R}$ be a smooth function ($M$ is a smooth manifold). Let $a$ be a regular value of $f$. Is it true that $f^{-1}(-\infty ,a]$ is a smooth manifold with boundary $f^{-1}\{a\}$? My feel is that it is correct and the proof is very similar to the proof that $f^{-1}\{a\}$ is a smooth manifold. Am I right?",,['differential-geometry']
54,tangent bundle and normal bundle,tangent bundle and normal bundle,,"I have a problem about tangent bundle. It is known that the tangent bundle of most manifolds is not trivial: for example, the tangent bundle for $S^2$ is not $S^2\times \mathbb{R}^2$. However, for a surface embedded in $\mathbb{R}^n$, the normal bundle is simply a direct product (for example, in Novikov et al. book ""Modern Geometry""). I am not quite clear about this. So how to visualize tangent bundle and normal bundle? When I try to visualize them, I just imagine a manifold with a tangent (normal) plane attached at each point. Why is this not a product space? And what is the difference between tangent bundle and normal bundle from this point? Thanks a lot!","I have a problem about tangent bundle. It is known that the tangent bundle of most manifolds is not trivial: for example, the tangent bundle for $S^2$ is not $S^2\times \mathbb{R}^2$. However, for a surface embedded in $\mathbb{R}^n$, the normal bundle is simply a direct product (for example, in Novikov et al. book ""Modern Geometry""). I am not quite clear about this. So how to visualize tangent bundle and normal bundle? When I try to visualize them, I just imagine a manifold with a tangent (normal) plane attached at each point. Why is this not a product space? And what is the difference between tangent bundle and normal bundle from this point? Thanks a lot!",,"['differential-geometry', 'manifolds']"
55,Conformal transformation of curvature tensor,Conformal transformation of curvature tensor,,"I'm asked to calculate the curvature Riemann and Ricci tensors and the curvature scalar of a metric that comes from a conformal transformation from a flat metric, that is, of a metric $g'=\Omega^2g$ where $g$ is flat. Now, I've been able to calculate the Riemann tensor of the $g'$ metric in terms of the other one, getting to this result: $$R'{_{abc}}^d=R{_{abc}}^d+2C{_{c[a}}^d\nabla_{b]}+2\nabla_{[a}C{_{b]c}}^d+2C{_{c[a}}^eC{_{b]e}}^d$$ Where $R{_{abc}}^d$ are the components of the Riemann tensor in the $g$ metric. Now for the Ricci, I just contract $b$ and $d$ indices in both sides and the same for the curvature scalar. I don't know though, if the $g$ metric is flat, what to get besides those expressions. Thank you in advance. EDIT: I calculated that by using $R{_{abc}}^d\omega_d=(\nabla_a\nabla_b-\nabla_b\nabla_a)\omega_c$ for  $1$-forms $\omega$.  And $C{_{abc}}^d$ is the components of the difference tensor of both cov. derivatives. Now, obviously, the terms that go like $C\nabla$ must vanish because it wouldn't be a linear operator. That means that it must be tru for $1$-forms that $$C{_{c[a}}^d\nabla_{b]}\omega_d$$ must be $0$, but I can't see why.","I'm asked to calculate the curvature Riemann and Ricci tensors and the curvature scalar of a metric that comes from a conformal transformation from a flat metric, that is, of a metric $g'=\Omega^2g$ where $g$ is flat. Now, I've been able to calculate the Riemann tensor of the $g'$ metric in terms of the other one, getting to this result: $$R'{_{abc}}^d=R{_{abc}}^d+2C{_{c[a}}^d\nabla_{b]}+2\nabla_{[a}C{_{b]c}}^d+2C{_{c[a}}^eC{_{b]e}}^d$$ Where $R{_{abc}}^d$ are the components of the Riemann tensor in the $g$ metric. Now for the Ricci, I just contract $b$ and $d$ indices in both sides and the same for the curvature scalar. I don't know though, if the $g$ metric is flat, what to get besides those expressions. Thank you in advance. EDIT: I calculated that by using $R{_{abc}}^d\omega_d=(\nabla_a\nabla_b-\nabla_b\nabla_a)\omega_c$ for  $1$-forms $\omega$.  And $C{_{abc}}^d$ is the components of the difference tensor of both cov. derivatives. Now, obviously, the terms that go like $C\nabla$ must vanish because it wouldn't be a linear operator. That means that it must be tru for $1$-forms that $$C{_{c[a}}^d\nabla_{b]}\omega_d$$ must be $0$, but I can't see why.",,['differential-geometry']
56,Normal Bundle of a Manifold,Normal Bundle of a Manifold,,"I was reading ""Morse Theory"" by J.Milnor and at page number 32 there is remark ""It is not difficult that N is an n-dimensional manifold differentiably embedded in $\mathbb{R}^{2n}$ ( N is the total space of the normal vector bundle of M)"" If anyone can please justify claim .","I was reading ""Morse Theory"" by J.Milnor and at page number 32 there is remark ""It is not difficult that N is an n-dimensional manifold differentiably embedded in $\mathbb{R}^{2n}$ ( N is the total space of the normal vector bundle of M)"" If anyone can please justify claim .",,['differential-geometry']
57,Integral of a differential 1-form along a curve (clarification on the definition),Integral of a differential 1-form along a curve (clarification on the definition),,"Let's denote with $(e_1,\dots,e_d)$ the usual basis of $\Bbb R^d$, and with $({e_1}^*,\dots,{e_d}^*)$ the dual basis of its dual space $\Bbb {(R^d)}^*$. Let $U$ be an open subset of $\Bbb R^d$ and $\omega:U\to \Bbb {(R^d)}^*$ be a $C^\infty$ differential 1-form. So, by definition, there exist $C^\infty$ functions $\omega_1,\dots,\omega_d:U\to\Bbb R$ such that $\omega=\sum_{j=1}^d\omega_j\,dx^{\,j}$, where each $x^{\,j}$ is the restriction to $U$ of ${e_j}^*$ (so $dx^{\,j}$, the differential of ${x^{\,j}}$, is the constant map $U\to ({\Bbb R^d})^*$, $u\mapsto {e_j}^*$). Let $\gamma:[a,b]\to U$ be a $C^\infty$ curve.  So, for all $t\in[a,b]$ it is defined $\gamma'(t)$ as an element of $\Bbb R^d$.  Being $\omega(\gamma(t))$ a functional, we can associate to it a vector of $\Bbb R^d$ (its representation with respect to the usual basis, which happens to be the vector $^t(\omega_1(\gamma(t)),\dots,\omega_d(\gamma(t)))\,\,$). Now, it is licit to take the scalar product $\langle\omega(\gamma(t)),\gamma'(t)\rangle$. So we define $$\int_\gamma\omega:=\int_a^b\langle\omega(\gamma(t)),\gamma'(t)\rangle\,dt=\int_a^b\biggl(\sum_{j=1}^d\omega_j(\gamma(t))(\gamma^{\,j})'(t)\biggr)dt.$$ and call it the INTEGRAL OF $\omega$ ALONG $\gamma$. The question is: what is this definition supposed to mean?  What does this integral represent?","Let's denote with $(e_1,\dots,e_d)$ the usual basis of $\Bbb R^d$, and with $({e_1}^*,\dots,{e_d}^*)$ the dual basis of its dual space $\Bbb {(R^d)}^*$. Let $U$ be an open subset of $\Bbb R^d$ and $\omega:U\to \Bbb {(R^d)}^*$ be a $C^\infty$ differential 1-form. So, by definition, there exist $C^\infty$ functions $\omega_1,\dots,\omega_d:U\to\Bbb R$ such that $\omega=\sum_{j=1}^d\omega_j\,dx^{\,j}$, where each $x^{\,j}$ is the restriction to $U$ of ${e_j}^*$ (so $dx^{\,j}$, the differential of ${x^{\,j}}$, is the constant map $U\to ({\Bbb R^d})^*$, $u\mapsto {e_j}^*$). Let $\gamma:[a,b]\to U$ be a $C^\infty$ curve.  So, for all $t\in[a,b]$ it is defined $\gamma'(t)$ as an element of $\Bbb R^d$.  Being $\omega(\gamma(t))$ a functional, we can associate to it a vector of $\Bbb R^d$ (its representation with respect to the usual basis, which happens to be the vector $^t(\omega_1(\gamma(t)),\dots,\omega_d(\gamma(t)))\,\,$). Now, it is licit to take the scalar product $\langle\omega(\gamma(t)),\gamma'(t)\rangle$. So we define $$\int_\gamma\omega:=\int_a^b\langle\omega(\gamma(t)),\gamma'(t)\rangle\,dt=\int_a^b\biggl(\sum_{j=1}^d\omega_j(\gamma(t))(\gamma^{\,j})'(t)\biggr)dt.$$ and call it the INTEGRAL OF $\omega$ ALONG $\gamma$. The question is: what is this definition supposed to mean?  What does this integral represent?",,"['differential-geometry', 'definition']"
58,Formula for curvature of two intersecting surfaces in terms of their normal curvature.,Formula for curvature of two intersecting surfaces in terms of their normal curvature.,,"I have been privately reading DoCarmo recently, and have been attempting to do some of the problems. I am stuck on this one, it is problem 14 in section 3.2 for those interested. If someone could show me how to do it, or even offer a hint, it would be much appreciated. If the surface $S_1$ intersects the surface $S_2$ along the regular curve $C$, then the curvature $k$ of $C$ at $p\in C$ is given by $k^2\sin^2\theta=\lambda_1^2+\lambda_2^2-2\lambda_1\lambda_2\cos\theta$ Where $\lambda_1$ and $\lambda_2$ are the normal curvatures at $p$, along th tangent line to $C$, of $S_1$ and $S_2$, respectively, and $\theta$ is the angle made up by the normal vectors in $S_1$ and $S_2$ at $p$. My attempt at the proof: Since $\lambda_i=\langle T',\nu_i\rangle$, where $T$ is the tangent vector along $C$ and $\nu_i$ is the vector normal to $S_i$ at $p$. So, $\lambda_1^2+\lambda_2^2-2\lambda_1\lambda_2\cos\theta$ $=\langle T',\nu_1\rangle^2+\langle T',\nu_2\rangle^2-2\langle T',\nu_1\rangle\langle T',\nu_2\rangle\cos\theta$ $=|\langle T',\nu_1\rangle\nu_1-\langle T',\nu_2\rangle\nu_2|^2$ $=|\langle kN,\nu_1\rangle\nu_1-\langle kN,\nu_2\rangle\nu_2|^2$ $=k^2|\langle N,\nu_1\rangle\nu_1-\langle N,\nu_2\rangle\nu_2|^2$ So if I could show that $=|\langle N,\nu_1\rangle\nu_1-\langle N,\nu_2\rangle\nu_2|^2=\sin^2\theta$ I am done. Any ideas?","I have been privately reading DoCarmo recently, and have been attempting to do some of the problems. I am stuck on this one, it is problem 14 in section 3.2 for those interested. If someone could show me how to do it, or even offer a hint, it would be much appreciated. If the surface $S_1$ intersects the surface $S_2$ along the regular curve $C$, then the curvature $k$ of $C$ at $p\in C$ is given by $k^2\sin^2\theta=\lambda_1^2+\lambda_2^2-2\lambda_1\lambda_2\cos\theta$ Where $\lambda_1$ and $\lambda_2$ are the normal curvatures at $p$, along th tangent line to $C$, of $S_1$ and $S_2$, respectively, and $\theta$ is the angle made up by the normal vectors in $S_1$ and $S_2$ at $p$. My attempt at the proof: Since $\lambda_i=\langle T',\nu_i\rangle$, where $T$ is the tangent vector along $C$ and $\nu_i$ is the vector normal to $S_i$ at $p$. So, $\lambda_1^2+\lambda_2^2-2\lambda_1\lambda_2\cos\theta$ $=\langle T',\nu_1\rangle^2+\langle T',\nu_2\rangle^2-2\langle T',\nu_1\rangle\langle T',\nu_2\rangle\cos\theta$ $=|\langle T',\nu_1\rangle\nu_1-\langle T',\nu_2\rangle\nu_2|^2$ $=|\langle kN,\nu_1\rangle\nu_1-\langle kN,\nu_2\rangle\nu_2|^2$ $=k^2|\langle N,\nu_1\rangle\nu_1-\langle N,\nu_2\rangle\nu_2|^2$ So if I could show that $=|\langle N,\nu_1\rangle\nu_1-\langle N,\nu_2\rangle\nu_2|^2=\sin^2\theta$ I am done. Any ideas?",,"['differential-geometry', 'riemannian-geometry', 'surfaces']"
59,Non-vanishing vector field on $\mathbb{R}P^{2n+1}$,Non-vanishing vector field on,\mathbb{R}P^{2n+1},"I'm trying to cook up a non-vanishing vector field on $\mathbb{R}P^{2n+1}$. I know that $S^{2n+1}$ admits one, namely $(x_1,\dots,x_{2n+2})\mapsto (-x_2,x_1,\dots,-x_{2n+2},x_{2n+1})$. Moreover, I know that $S^{2n+1}$ is a smooth double cover of $\mathbb{R}P^{2n+1}$ via the map $x\mapsto \{x,-x\}$. Since this vector field is odd, $X(p)=-X(-p)$, I was hoping there might be a way to cook up a vector field on $\mathbb{R}P^{2n+1}$. So, this motivates the two following questions: Specifically, how may one explicitly construct a non-vanishing vector field on $\mathbb{R}P^{2n+1}$ (using the route above or not). Say $\tilde M$ and $M$ are smooth manifolds, and $p:\tilde{M}\to M$ is a smooth covering map. If $X(p)$ is a smooth vector field on $\tilde{M}$, under what conditions is there a natural way to cook up a vector field on $M$? (I don't mean natural in the rigorous sense). Thanks!","I'm trying to cook up a non-vanishing vector field on $\mathbb{R}P^{2n+1}$. I know that $S^{2n+1}$ admits one, namely $(x_1,\dots,x_{2n+2})\mapsto (-x_2,x_1,\dots,-x_{2n+2},x_{2n+1})$. Moreover, I know that $S^{2n+1}$ is a smooth double cover of $\mathbb{R}P^{2n+1}$ via the map $x\mapsto \{x,-x\}$. Since this vector field is odd, $X(p)=-X(-p)$, I was hoping there might be a way to cook up a vector field on $\mathbb{R}P^{2n+1}$. So, this motivates the two following questions: Specifically, how may one explicitly construct a non-vanishing vector field on $\mathbb{R}P^{2n+1}$ (using the route above or not). Say $\tilde M$ and $M$ are smooth manifolds, and $p:\tilde{M}\to M$ is a smooth covering map. If $X(p)$ is a smooth vector field on $\tilde{M}$, under what conditions is there a natural way to cook up a vector field on $M$? (I don't mean natural in the rigorous sense). Thanks!",,"['differential-geometry', 'manifolds', 'differential-topology']"
60,A learning question about volume forms,A learning question about volume forms,,"I am learning differential manifold and got a question. How do we calculate the surface area? Or how to calculate the volume of a submanifold? Like for the surface area of $S^n$, if $\phi$ is the embedding map, then it seems that $S=\int\phi^*(\sum_{j=1}^{n+1}(-1)^{j-1}x_j dx_1\wedge dx_2...dx_{j-1}\wedge dx_{j+1}...\wedge dx_{n+1})$ according to some webpage I found. But where did that volume form come from? For a general case, if $(N,\phi)$ is a n-dimension submanifold embedding in a m-dimension manifold M, what is the n-form in $A(M)$ that should be pulled back and integrate on $N$? Thank you for your patience.","I am learning differential manifold and got a question. How do we calculate the surface area? Or how to calculate the volume of a submanifold? Like for the surface area of $S^n$, if $\phi$ is the embedding map, then it seems that $S=\int\phi^*(\sum_{j=1}^{n+1}(-1)^{j-1}x_j dx_1\wedge dx_2...dx_{j-1}\wedge dx_{j+1}...\wedge dx_{n+1})$ according to some webpage I found. But where did that volume form come from? For a general case, if $(N,\phi)$ is a n-dimension submanifold embedding in a m-dimension manifold M, what is the n-form in $A(M)$ that should be pulled back and integrate on $N$? Thank you for your patience.",,['differential-geometry']
61,Reference for spin structure,Reference for spin structure,,"I am looking for some elementary books (may be introduction) about $\operatorname{Spin}$ structures in general, and $\operatorname{Spin}$ structure on Riemannian manifolds.","I am looking for some elementary books (may be introduction) about structures in general, and structure on Riemannian manifolds.",\operatorname{Spin} \operatorname{Spin},"['differential-geometry', 'reference-request', 'book-recommendation', 'spin-geometry']"
62,"how to parameterize a curve f(x,y)?","how to parameterize a curve f(x,y)?",,"Given a curve defined as any differentiable function, e.g. $f(x,y)=ax^2+bxy+cy^2+d $, how can I parameterize it into a vector-valued function $c(t) = (x(t), y(t))$? I appreciate any suggestion.","Given a curve defined as any differentiable function, e.g. $f(x,y)=ax^2+bxy+cy^2+d $, how can I parameterize it into a vector-valued function $c(t) = (x(t), y(t))$? I appreciate any suggestion.",,['differential-geometry']
63,Riemannian metric. Help with notation.,Riemannian metric. Help with notation.,,"I was just reading about the hyperbolic space (upper-half plane model) and i'm getting kind of confused about the notation for the Riemannian metric. The half-plane is defined as $$ H = \{(x,y) \in \mathbb{R}^2 | y > 0\}, $$ and the metric is defined as  $$ ds^2 = \frac{dx^2 + dy^2}{y^2}. $$ I've just taken a first course in Riemannian geometry and I have absolutely no idea where this notation comes from and what it means. We usually defined metrics explicitely as some bilinear map $g$. Thanks for your time.","I was just reading about the hyperbolic space (upper-half plane model) and i'm getting kind of confused about the notation for the Riemannian metric. The half-plane is defined as $$ H = \{(x,y) \in \mathbb{R}^2 | y > 0\}, $$ and the metric is defined as  $$ ds^2 = \frac{dx^2 + dy^2}{y^2}. $$ I've just taken a first course in Riemannian geometry and I have absolutely no idea where this notation comes from and what it means. We usually defined metrics explicitely as some bilinear map $g$. Thanks for your time.",,"['differential-geometry', 'riemannian-geometry']"
64,Calculation of the total curvature of Jordan curves,Calculation of the total curvature of Jordan curves,,"I am looking for direct proofs that the total curvature $\int_0^{L_\gamma} \! \gamma''(s) \, \mathrm{d} s$ of any Jordan curve $\gamma$ resp. $\int_0^{L_\gamma} \! |\gamma''(s)| \, \mathrm{d} s$ of a convex Jordan curve equals $2\pi$. Direct proof means: a calculation and not a special case of the theorem of Gauss-Bonnet or of I have no idea even how to show that the integral $$\int_0^1 \frac{\mathrm{d} x}{(1-(1-b^2)x^2)^{3/2}}$$ evaluates to $\frac{1}{b}$ which would prove the above at least for ellipses with major axis $a=1$ and minor axis $b$. Let alone for arbitrary (convex) curves/functions.","I am looking for direct proofs that the total curvature $\int_0^{L_\gamma} \! \gamma''(s) \, \mathrm{d} s$ of any Jordan curve $\gamma$ resp. $\int_0^{L_\gamma} \! |\gamma''(s)| \, \mathrm{d} s$ of a convex Jordan curve equals $2\pi$. Direct proof means: a calculation and not a special case of the theorem of Gauss-Bonnet or of I have no idea even how to show that the integral $$\int_0^1 \frac{\mathrm{d} x}{(1-(1-b^2)x^2)^{3/2}}$$ evaluates to $\frac{1}{b}$ which would prove the above at least for ellipses with major axis $a=1$ and minor axis $b$. Let alone for arbitrary (convex) curves/functions.",,['differential-geometry']
65,Sections of a bundle,Sections of a bundle,,I would like that someone explain to me why in general $ \Gamma ( T^*M \otimes TM ) = \Gamma ( T^*M ) \otimes_{\mathcal{C}^{\infty} ( M )} \Gamma ( TM ) $ with $ \Gamma ( T^*M ) $ is a set of sections of the bundle $ T^*M $ ? Thanks a lot.,I would like that someone explain to me why in general $ \Gamma ( T^*M \otimes TM ) = \Gamma ( T^*M ) \otimes_{\mathcal{C}^{\infty} ( M )} \Gamma ( TM ) $ with $ \Gamma ( T^*M ) $ is a set of sections of the bundle $ T^*M $ ? Thanks a lot.,,['differential-geometry']
66,Covariant derivative on hypersurface in $\mathbb{R}^n$,Covariant derivative on hypersurface in,\mathbb{R}^n,I saw in a talk that a surface gradient of $f:M \to \mathbb{R}$ where $M$ is a hypersurface in $\mathbb{R}^n$ defined as $$\nabla_M f = \nabla f - (\nabla f \cdot N)N$$ where $N$ is the unit normal vector on $M$ and $\nabla$ is the ordinary gradient. I just started learning about the connection/covariant derivative on a manifold and am wondering about the link. Is the surface gradient as defined above just a choice of a particular connection? Does it have anything to do with the Levi-Civita connection?,I saw in a talk that a surface gradient of $f:M \to \mathbb{R}$ where $M$ is a hypersurface in $\mathbb{R}^n$ defined as $$\nabla_M f = \nabla f - (\nabla f \cdot N)N$$ where $N$ is the unit normal vector on $M$ and $\nabla$ is the ordinary gradient. I just started learning about the connection/covariant derivative on a manifold and am wondering about the link. Is the surface gradient as defined above just a choice of a particular connection? Does it have anything to do with the Levi-Civita connection?,,"['differential-geometry', 'surfaces']"
67,The area form of a Riemannian surface,The area form of a Riemannian surface,,"Let $(M,g)$ be an oriented Riemannian surface. Then globally $(M,g)$ has a canonical area-$2$ form $\mathrm{d}M$ defined by $$\mathrm{d}M=\sqrt{|g|} \mathrm{d}u^1 \wedge \mathrm{d}u^2$$ with respect to a positively oriented chart $(u_{\alpha}, M_{\alpha})$ where $|g|=\mathrm{det}(g_{ij})$ is the determinant of the Riemannian metric in the coordinate frame for $u_{\alpha}$. Let $u^{i}=\Phi^{i}(v^1,v^2)$ be a change of variables (so $\Phi: V \to U$ is the diffeomorphism of the coordinate change). Calculate the effect on $\sqrt{|g|}$ and $\mathrm{d}u^1 \wedge \mathrm{d}u^2$ to prove $\mathrm{d}M$ is independent of the choice of positively oriented coordinates. Remark: I know $g$ is invariant under an orientation preserving change of variables ($\mathrm{det}(\Phi)>0$), but how to compute explicitly the effect of $\Phi$ on $\mathrm{d}u^1 \wedge \mathrm{d}u^2$? I want to use this as an example to learn the exterior calculus.","Let $(M,g)$ be an oriented Riemannian surface. Then globally $(M,g)$ has a canonical area-$2$ form $\mathrm{d}M$ defined by $$\mathrm{d}M=\sqrt{|g|} \mathrm{d}u^1 \wedge \mathrm{d}u^2$$ with respect to a positively oriented chart $(u_{\alpha}, M_{\alpha})$ where $|g|=\mathrm{det}(g_{ij})$ is the determinant of the Riemannian metric in the coordinate frame for $u_{\alpha}$. Let $u^{i}=\Phi^{i}(v^1,v^2)$ be a change of variables (so $\Phi: V \to U$ is the diffeomorphism of the coordinate change). Calculate the effect on $\sqrt{|g|}$ and $\mathrm{d}u^1 \wedge \mathrm{d}u^2$ to prove $\mathrm{d}M$ is independent of the choice of positively oriented coordinates. Remark: I know $g$ is invariant under an orientation preserving change of variables ($\mathrm{det}(\Phi)>0$), but how to compute explicitly the effect of $\Phi$ on $\mathrm{d}u^1 \wedge \mathrm{d}u^2$? I want to use this as an example to learn the exterior calculus.",,"['differential-geometry', 'differential-forms']"
68,Covering $\mathbb{R}^n$ by countably many lower dimensional pieces?,Covering  by countably many lower dimensional pieces?,\mathbb{R}^n,"I would like to know if it is possible to cover $\mathbb{R}^n$ by countably many immersed submanifold of dimension less than $n$. A similar version is whether it is possible to cover $\mathbb{C}^n$ by countably many analytic subsets of lower dimension. The motivation is that an exercise I am working involves in proving a statement being true for a generic lattice, which seems to invoke statements of the sort above, but I am not sure how I can prove them. Thanks!","I would like to know if it is possible to cover $\mathbb{R}^n$ by countably many immersed submanifold of dimension less than $n$. A similar version is whether it is possible to cover $\mathbb{C}^n$ by countably many analytic subsets of lower dimension. The motivation is that an exercise I am working involves in proving a statement being true for a generic lattice, which seems to invoke statements of the sort above, but I am not sure how I can prove them. Thanks!",,[]
69,Tensor calculation on mean curvature flow,Tensor calculation on mean curvature flow,,"I have two questions about tensor calculation. First question : In the book, Lectures on mean curvature flows written by Xi-Ping Zhu, there exists the equaility $g^{mn} \nabla_m \nabla_n h_{ij} = g^{mn} \nabla_m \nabla_i h_{jn}$. I do not understand this. The situation is as follows : $X(\cdot, t) : M^n \rightarrow {\bf R}^{n+1}$ is a one-parameter family of smooth hypersurface immersions in ${\bf R}^{n+1}$, and $ X_t = H \nu$ where $H$ and $\nu$ is the mean curvature and unit normal to $X$. $g_{ij} = (X_i,X_j)$, $h_{ij} = (\nu, X_{ij})$ The question is found in the proof of Lemma 2.3 in 19 page. Please help me. Second question : In the same book, there exists the equality    $\Delta h_{ij} -\epsilon \Delta H g_{ij} =   \Delta( h_{ij} - \epsilon H g_{ij}) $ (See the proof of Proposition 2.6 in 22 page) I cannot understand the equality. Please help me.","I have two questions about tensor calculation. First question : In the book, Lectures on mean curvature flows written by Xi-Ping Zhu, there exists the equaility $g^{mn} \nabla_m \nabla_n h_{ij} = g^{mn} \nabla_m \nabla_i h_{jn}$. I do not understand this. The situation is as follows : $X(\cdot, t) : M^n \rightarrow {\bf R}^{n+1}$ is a one-parameter family of smooth hypersurface immersions in ${\bf R}^{n+1}$, and $ X_t = H \nu$ where $H$ and $\nu$ is the mean curvature and unit normal to $X$. $g_{ij} = (X_i,X_j)$, $h_{ij} = (\nu, X_{ij})$ The question is found in the proof of Lemma 2.3 in 19 page. Please help me. Second question : In the same book, there exists the equality    $\Delta h_{ij} -\epsilon \Delta H g_{ij} =   \Delta( h_{ij} - \epsilon H g_{ij}) $ (See the proof of Proposition 2.6 in 22 page) I cannot understand the equality. Please help me.",,"['differential-geometry', 'mean-curvature-flows']"
70,Possibilities of an action of $S^1$ on a disk.,Possibilities of an action of  on a disk.,S^1,"I'm dealing with actions of the circle over differentiable manifolds. In the book I'm reading,  they use the fact that an action of $S^1$ over a disk has to be equivalent (there has to exist an equivariant diffeomorphism) to a rotation. Can someone give me a hint to prove this? Or maybe a reference where I can consult this result? It seems to be a ""well known fact"" but I haven't been able to find a place where they prove it.","I'm dealing with actions of the circle over differentiable manifolds. In the book I'm reading,  they use the fact that an action of $S^1$ over a disk has to be equivalent (there has to exist an equivariant diffeomorphism) to a rotation. Can someone give me a hint to prove this? Or maybe a reference where I can consult this result? It seems to be a ""well known fact"" but I haven't been able to find a place where they prove it.",,"['reference-request', 'differential-geometry', 'lie-groups']"
71,Closed and Exact forms/deRham groups,Closed and Exact forms/deRham groups,,"I'm trying to translate these theorems, below, into theorems about vector and scalar fields in $\mathbb R^n\setminus\{0\}$, in the case $n = 2$. First Theorem: Let $A = \mathbb R^n\setminus \{0\}$, with $n \ge 1$ a) If $k$ is not equal to $n-1$ then every closed $k$-form on $A$ is exact on $A$ b) There is a closed $n-1$-form $\eta_{\text{initial}}$ on $A$ that is not exact. If $\eta$ is any closed $n-1$ form on $A$, then there is a unique scalar $c$ s.t. $\eta - c\eta_{\text{initial}}$ is not exact. Second Theorem: Let $A = \mathbb R^n\setminus\{0\}$, with $n > 1$. If $\eta$ is a closed $n-1$ form in $A$, then $\eta$ is exact in $A$ iff the integral $\int_{S^{n-1}}\eta = 0$. My version: For the first theorem, we need to work out some computation, I think, that $\eta$ is not closed, with $\eta \ne \sum_{i = 1}^n (-1)^{i-1} f_i\, dx_1 \wedge \cdots \widehat{dx_i} \cdots \wedge dx_n$ with $f_i(x) = x_i/\|x\|^n$. For the second theorem, we just assume that $\eta$ is exact and Stokes' theorem follows, but how does this help in answering the question, above?","I'm trying to translate these theorems, below, into theorems about vector and scalar fields in $\mathbb R^n\setminus\{0\}$, in the case $n = 2$. First Theorem: Let $A = \mathbb R^n\setminus \{0\}$, with $n \ge 1$ a) If $k$ is not equal to $n-1$ then every closed $k$-form on $A$ is exact on $A$ b) There is a closed $n-1$-form $\eta_{\text{initial}}$ on $A$ that is not exact. If $\eta$ is any closed $n-1$ form on $A$, then there is a unique scalar $c$ s.t. $\eta - c\eta_{\text{initial}}$ is not exact. Second Theorem: Let $A = \mathbb R^n\setminus\{0\}$, with $n > 1$. If $\eta$ is a closed $n-1$ form in $A$, then $\eta$ is exact in $A$ iff the integral $\int_{S^{n-1}}\eta = 0$. My version: For the first theorem, we need to work out some computation, I think, that $\eta$ is not closed, with $\eta \ne \sum_{i = 1}^n (-1)^{i-1} f_i\, dx_1 \wedge \cdots \widehat{dx_i} \cdots \wedge dx_n$ with $f_i(x) = x_i/\|x\|^n$. For the second theorem, we just assume that $\eta$ is exact and Stokes' theorem follows, but how does this help in answering the question, above?",,['differential-geometry']
72,Normal coordinates vs. Locally flat,Normal coordinates vs. Locally flat,,If $M$ is a Riemannian manifold the inverse function theorem tells us that for any $p \in M$ the exponential map gives us a nieghborhood $U$ of $p$ and normal coordinates $(x^i)$ in which the components of the metric are $g_{ij}=\delta_{ij}$ and the Christoffel symbols vanish at $p$. Why is this not the same as saying $M$ is locally flat?,If $M$ is a Riemannian manifold the inverse function theorem tells us that for any $p \in M$ the exponential map gives us a nieghborhood $U$ of $p$ and normal coordinates $(x^i)$ in which the components of the metric are $g_{ij}=\delta_{ij}$ and the Christoffel symbols vanish at $p$. Why is this not the same as saying $M$ is locally flat?,,['differential-geometry']
73,Show a operator is not a tensor field on $\mathbb{R}^3$,Show a operator is not a tensor field on,\mathbb{R}^3,"I'm a beginner in tensors, and all my concepts of tensors are from the book: ""Munkres-Analysis on Manifolds"" Consider the $2$ tensor field $\omega$ on $\mathbb{R}^3$ . Then, from my book, it means that for each vector $x\in \mathbb{R}^3$ , $\omega(x)$ represents a $2$ tensor on the tangent space of $x$ denoted as $\mathscr{T}_{x}(\mathbb{R}^3)$ . That is, if use the notation $(x;v)$ to represent the vectors in the tangent space $\mathscr{T}_{x}(\mathbb{R}^3)$ , we have $$\begin{align} \omega(x):((x;v_{1}),(x;v_{2})) \to r \end{align}$$ where $r$ is a number on $\mathbb{R}$ Now I let the vectors $v_{1},v_{2}$ depend on $x$ , so $(x;v_{1}), \ (x;v_{2})$ become 2 vector fields $$\begin{align} F_{1}(x)=(x; v_{1}(x)) \\  \\ F_{2}(x)=(x;v_{2}(x)) \end{align}$$ on $\mathbb{R}^3$ where each of then is in the tangent space of $x$ , and $$\begin{align} v_{1}:& \mathbb{R}^3 \to \mathbb{R}^3 \\ :& x=(x^1,x^2,x^3) \to (v_{1}^1(x),v_{1}^2(x),v_{1}^3(x))=v_{1}(x) \end{align}$$ So does $v_{2}$ . Then I define a operator $T$ $$\begin{align} T: ((x;v_{1}),(x;v_{2}),(x;v_{3})) \to \frac{\partial }{\partial x} (\omega (x)((x;v_{2}),(x;v_{3}))) \cdot v_{1}  \end{align}$$ where $(x;v_{i})_{i=1,2,3}$ are vectors fields. Now I'm wondering how to prove the operator $T$ is ""not"" a tensor field on $\mathbb{R}^3$ ? Here I first notice that $T$ indeed sents $3$ vectors into a number, since $\omega (x)((x;v_{2}),(x;v_{3}))$ is a number and it only depends on $x$ , so the derivative with respect to $x$ is a $1 \times 3$ matrix. Finally, it dot products with $3 \times 1$ column $v_{1}$ , the result should be a number. Then I tried to write out a partial derivative. I think the result of $\omega (x)((x;v_{2}),(x;v_{3}))$ depends on $x$ , $v_{2}$ and $v_{3}$ where the last 2 also depend on $x$ . Thus I think I might be able to write $\omega$ as $$\begin{align} \omega(x,v_{2}(x) ,v_{3}(x)) = r \end{align}$$ Thus the partial derivative is $$\begin{align} \frac{\partial \omega}{\partial x}+ \frac{\partial \omega}{\partial v_{2}} \cdot \frac{\partial v_{2}}{\partial x}+ \frac{\partial \omega }{\partial v_{3}} \cdot \frac{\partial v_{2}}{\partial x} && (*) \end{align}$$ where $\dfrac{\partial \omega}{\partial v_{2}} \cdot \dfrac{\partial v_{2}}{\partial x}$ can be regarded as a $1 \times 3$ matrix $$\begin{align} \left( \frac{\partial \omega}{\partial v_{2}^1}  \ \frac{\partial \omega}{\partial v_{2}^2} \ \frac{\partial \omega}{\partial v_{2}^3} \right)  \end{align}$$ and $\dfrac{\partial v_{2}}{\partial x}$ is a $3 \times 3$ matrix, and hence $(*)$ is indeed a $1 \times 3$ matrix. So far, I have 2 questions 1 Are my thoughts above right? 2 If they are right, how can I tell that $T$ is ""not"" a tensor field? Any help or hints on this? Thanks!","I'm a beginner in tensors, and all my concepts of tensors are from the book: ""Munkres-Analysis on Manifolds"" Consider the tensor field on . Then, from my book, it means that for each vector , represents a tensor on the tangent space of denoted as . That is, if use the notation to represent the vectors in the tangent space , we have where is a number on Now I let the vectors depend on , so become 2 vector fields on where each of then is in the tangent space of , and So does . Then I define a operator where are vectors fields. Now I'm wondering how to prove the operator is ""not"" a tensor field on ? Here I first notice that indeed sents vectors into a number, since is a number and it only depends on , so the derivative with respect to is a matrix. Finally, it dot products with column , the result should be a number. Then I tried to write out a partial derivative. I think the result of depends on , and where the last 2 also depend on . Thus I think I might be able to write as Thus the partial derivative is where can be regarded as a matrix and is a matrix, and hence is indeed a matrix. So far, I have 2 questions 1 Are my thoughts above right? 2 If they are right, how can I tell that is ""not"" a tensor field? Any help or hints on this? Thanks!","2 \omega \mathbb{R}^3 x\in \mathbb{R}^3 \omega(x) 2 x \mathscr{T}_{x}(\mathbb{R}^3) (x;v) \mathscr{T}_{x}(\mathbb{R}^3) \begin{align}
\omega(x):((x;v_{1}),(x;v_{2})) \to r
\end{align} r \mathbb{R} v_{1},v_{2} x (x;v_{1}), \ (x;v_{2}) \begin{align}
F_{1}(x)=(x; v_{1}(x)) \\  \\ F_{2}(x)=(x;v_{2}(x))
\end{align} \mathbb{R}^3 x \begin{align}
v_{1}:& \mathbb{R}^3 \to \mathbb{R}^3 \\ :& x=(x^1,x^2,x^3) \to (v_{1}^1(x),v_{1}^2(x),v_{1}^3(x))=v_{1}(x)
\end{align} v_{2} T \begin{align}
T: ((x;v_{1}),(x;v_{2}),(x;v_{3})) \to \frac{\partial }{\partial x} (\omega (x)((x;v_{2}),(x;v_{3}))) \cdot v_{1} 
\end{align} (x;v_{i})_{i=1,2,3} T \mathbb{R}^3 T 3 \omega (x)((x;v_{2}),(x;v_{3})) x x 1 \times 3 3 \times 1 v_{1} \omega (x)((x;v_{2}),(x;v_{3})) x v_{2} v_{3} x \omega \begin{align}
\omega(x,v_{2}(x) ,v_{3}(x)) = r
\end{align} \begin{align}
\frac{\partial \omega}{\partial x}+ \frac{\partial \omega}{\partial v_{2}} \cdot \frac{\partial v_{2}}{\partial x}+ \frac{\partial \omega }{\partial v_{3}} \cdot \frac{\partial v_{2}}{\partial x} && (*)
\end{align} \dfrac{\partial \omega}{\partial v_{2}} \cdot \dfrac{\partial v_{2}}{\partial x} 1 \times 3 \begin{align}
\left( \frac{\partial \omega}{\partial v_{2}^1}  \ \frac{\partial \omega}{\partial v_{2}^2} \ \frac{\partial \omega}{\partial v_{2}^3} \right) 
\end{align} \dfrac{\partial v_{2}}{\partial x} 3 \times 3 (*) 1 \times 3 T","['differential-geometry', 'smooth-manifolds', 'tensors', 'vector-fields']"
74,Question about definition of normal bundle from the quotient space,Question about definition of normal bundle from the quotient space,,"According to Wikipedia, the definition of normal bundle is defined as, Defintion $1$ . [Normal bundle] Let $(M,g)$ be a Riemannian manifold, and $S\subset M$ a Riemannian submanifold. For a given $p \in S$ , a vector $n \in T_pM$ to be  normal to $S$ if whenever $g(n,v)=0$ for all $v \in T_pS$ . Then the set $N_pS$ of all such $n$ is called the normal space to $S$ at $p$ . $NS:= \coprod _{s \in S}N_pS$ is called the total space of normal bundle to $S$ at $p$ . ............. $(*)$ From the above definition, I understand $$N_p S := \left\{ n \in T_pM : g(n,v)=0~ for~ all~~ v ~\in T_pS \right\}$$ For example, let $M=\mathbb{R}^2$ and $S=S^1$ and pick a point $p\in S$ . Then, since $S$ is embedded in $M$ , naturally $p\in M$ . and $T_pM$ is also well defined. then since the vector $n$ is easily constructed ( clearly the every vector $v$ who lives in $T_pM$ is perpendicular to $n$ , literally, $g(n,v)=0$ . ) and like the second bullet, $NS$ is also well defined for any point $p \in M$ . (The following image is just visualizing my description. the pink vector is one of element of $N_pS $ ) Meanwhile, how about the formal definition of normal bundle? Even though such definition is slightly different from each source, essentially, the basic idea seems to use a quotient space ,  However, I think that the formal definition contradicts the first definition , $(*)$ . To begin with, based on wikipedia description, one can define a normal bundle of $N$ in $M$ , by at each point of $N$ , taking the quotient space of the tangent space on $M$ by the tangent space on $N$ . For a Riemannian manifold one can identify this quotient with the orthogonal complement, but in general one cannot... I will define for convenience, Defintion2. [General definition of normal bundle] Let $(M,g)$ be a Riemannian manifold, and $S\subset M$ a Riemannian submanifold. Then the quotient space $TM/TS$ is called a normal bundle to $S$ at $p$ . For example, also consider $M=\mathbb{R}^2$ and $S=S^1$ and metric tensor still is Riemannian metric, $g$ . if I pick two vector bundle $v,w \in TM$ , the equivalence relation ~ is given, $$v\sim w  ~if~and~only~if~ v-w \in TS  ...... (**)$$ Then we can viusalize both vector and $v$ and $w$ like the below picture, and since $\sim$ is equivalent relation, we consider a representation $\nu \in TM/TS $ . Then the representation $\nu$ would be a normal bundle. Of course, when considering $(**)$ , the representation is descirbed $$\nu=\left\{ w + \alpha u : w \in TM , \alpha \in \mathbb{R}, u \in TS \right\}$$ However, when comparing to the first definition, $\nu $ clearly does not represent normal vector . Obviously, for any point $p \in S$ , then $w+u$ is not perpendicular to the tangential vector $T_pS$ Therefore, I cannot understand why the formal definition of normal bundle , Defintion2 ,  is a reasonable statement when considering Definition1 .","According to Wikipedia, the definition of normal bundle is defined as, Defintion . [Normal bundle] Let be a Riemannian manifold, and a Riemannian submanifold. For a given , a vector to be  normal to if whenever for all . Then the set of all such is called the normal space to at . is called the total space of normal bundle to at . ............. From the above definition, I understand For example, let and and pick a point . Then, since is embedded in , naturally . and is also well defined. then since the vector is easily constructed ( clearly the every vector who lives in is perpendicular to , literally, . ) and like the second bullet, is also well defined for any point . (The following image is just visualizing my description. the pink vector is one of element of ) Meanwhile, how about the formal definition of normal bundle? Even though such definition is slightly different from each source, essentially, the basic idea seems to use a quotient space ,  However, I think that the formal definition contradicts the first definition , . To begin with, based on wikipedia description, one can define a normal bundle of in , by at each point of , taking the quotient space of the tangent space on by the tangent space on . For a Riemannian manifold one can identify this quotient with the orthogonal complement, but in general one cannot... I will define for convenience, Defintion2. [General definition of normal bundle] Let be a Riemannian manifold, and a Riemannian submanifold. Then the quotient space is called a normal bundle to at . For example, also consider and and metric tensor still is Riemannian metric, . if I pick two vector bundle , the equivalence relation ~ is given, Then we can viusalize both vector and and like the below picture, and since is equivalent relation, we consider a representation . Then the representation would be a normal bundle. Of course, when considering , the representation is descirbed However, when comparing to the first definition, clearly does not represent normal vector . Obviously, for any point , then is not perpendicular to the tangential vector Therefore, I cannot understand why the formal definition of normal bundle , Defintion2 ,  is a reasonable statement when considering Definition1 .","1 (M,g) S\subset M p \in S n \in T_pM S g(n,v)=0 v \in T_pS N_pS n S p NS:= \coprod _{s \in S}N_pS S p (*) N_p S := \left\{ n \in T_pM : g(n,v)=0~ for~ all~~ v ~\in T_pS \right\} M=\mathbb{R}^2 S=S^1 p\in S S M p\in M T_pM n v T_pM n g(n,v)=0 NS p \in M N_pS  (*) N M N M N (M,g) S\subset M TM/TS S p M=\mathbb{R}^2 S=S^1 g v,w \in TM v\sim w  ~if~and~only~if~ v-w \in TS  ...... (**) v w \sim \nu \in TM/TS  \nu (**) \nu=\left\{ w + \alpha u : w \in TM , \alpha \in \mathbb{R}, u \in TS \right\} \nu  p \in S w+u T_pS",['differential-geometry']
75,Integral curves of a vector field not tangent to an embedded submanifold $S$,Integral curves of a vector field not tangent to an embedded submanifold,S,"I got stuck on a problem. Let $M$ be a smooth $n-$ dimensional manifold and let $S$ be a compact embedded submanifold. Suppose $V$ is nowhere tangent to $S.$ Prove that there exists $\epsilon>0$ such that the flow of $V$ restrict to a smooth embedding $$\Phi:(-\epsilon,\epsilon)\times S \to M.$$ Firstly, by the compactness of $S,$ we find a positive $\epsilon>0$ for which all the integral curves with initial conditions in $S$ are defined on $(-\epsilon,\epsilon).$ The differential of $\Phi$ if I am not mistaken should be of this form: $$(\frac{\partial}{\partial t}, di_{S}),$$ where $i_{S}$ is the inclusion of $S$ in $M,$ practically by definition this should have maximum rank. The only part I'm not sure is on how to prove that $\Phi$ is open. Since $S$ is embedded for every point $y \in S$ there is a chart $(U,\varphi)$ in $M$ in which $U\cap S$ is diffeomorphic under $\varphi$ to a set of the form $$\{ x \in \mathbb{R}^{N} : (x^1,\dots,x^{k},\,0, \dots,\,0) \}.$$ Since $V$ is nowhere tangent to $S$ it's not restrictive to suppose the differential of $\varphi$ sends $V$ to the constant vector field $e_{k+1}.$ So the integral curves with initial conditions on $S$ should all be of the form $$\gamma(t)=(x^1,\dots,x^{k},t,\dots,0).$$ So the set $\Phi(S\times (-\epsilon,\epsilon))$ is diffeomorphic to the following relative open set of $\mathbb{R}^n$ $$ \{(x^1,\dots,x^{k},t,\dots,0): ((x^1,\dots,x^{k}) \in \mathbb{R}^{k+1}, \, t \in (-\epsilon,\epsilon) \},$$ so the map $\Phi$ is open on is image and we are done. Is this reasoning correct? Where should I be more precise?","I got stuck on a problem. Let be a smooth dimensional manifold and let be a compact embedded submanifold. Suppose is nowhere tangent to Prove that there exists such that the flow of restrict to a smooth embedding Firstly, by the compactness of we find a positive for which all the integral curves with initial conditions in are defined on The differential of if I am not mistaken should be of this form: where is the inclusion of in practically by definition this should have maximum rank. The only part I'm not sure is on how to prove that is open. Since is embedded for every point there is a chart in in which is diffeomorphic under to a set of the form Since is nowhere tangent to it's not restrictive to suppose the differential of sends to the constant vector field So the integral curves with initial conditions on should all be of the form So the set is diffeomorphic to the following relative open set of so the map is open on is image and we are done. Is this reasoning correct? Where should I be more precise?","M n- S V S. \epsilon>0 V \Phi:(-\epsilon,\epsilon)\times S \to M. S, \epsilon>0 S (-\epsilon,\epsilon). \Phi (\frac{\partial}{\partial t}, di_{S}), i_{S} S M, \Phi S y \in S (U,\varphi) M U\cap S \varphi \{ x \in \mathbb{R}^{N} : (x^1,\dots,x^{k},\,0, \dots,\,0) \}. V S \varphi V e_{k+1}. S \gamma(t)=(x^1,\dots,x^{k},t,\dots,0). \Phi(S\times (-\epsilon,\epsilon)) \mathbb{R}^n  \{(x^1,\dots,x^{k},t,\dots,0): ((x^1,\dots,x^{k}) \in \mathbb{R}^{k+1}, \, t \in (-\epsilon,\epsilon) \}, \Phi","['differential-geometry', 'smooth-manifolds', 'submanifold']"
76,"Lee's Proof on Top Cohomology of Orientable Noncompact, Connected Manifold","Lee's Proof on Top Cohomology of Orientable Noncompact, Connected Manifold",,"My question is about the theorem $17.32, pp. 455-456$ in Lee's book ""Introduction to Smooth Manifolds,"" second edition. With the hypotheses as in the title of the question, the conclusion is that $H_{dR}^n(M)=0,$ where $M$ is a smooth manifold of dimension $n.$ The proof begins with a choice of exhaustion function $f\in C^\infty (M)$ which can be taken to map $M$ onto $[0,\infty).$ For each integer $i>0,$ one defines open sets $V_i=f^{-1}((i-2,i)).$ These cover $M$ . The argument that follows relies on the previously proved theorem $17.30$ , $pp. 454-455,$ which would seem then to require that the $V_i$ be connected. But I do not see why the $V_i$ as defined here, must be so. I am probably missing something obvious, but I can't patch up the proof without applying $17.30$ and I cannot adjust the $f_i$ so that the $V_i$ are necessarily connected. I am thinking that perhaps this is one of those proofs that relies on a technical topological lemma, and that as Lee does not cite it, it is probably a triviality. Can someone point me in the right direction?","My question is about the theorem in Lee's book ""Introduction to Smooth Manifolds,"" second edition. With the hypotheses as in the title of the question, the conclusion is that where is a smooth manifold of dimension The proof begins with a choice of exhaustion function which can be taken to map onto For each integer one defines open sets These cover . The argument that follows relies on the previously proved theorem , which would seem then to require that the be connected. But I do not see why the as defined here, must be so. I am probably missing something obvious, but I can't patch up the proof without applying and I cannot adjust the so that the are necessarily connected. I am thinking that perhaps this is one of those proofs that relies on a technical topological lemma, and that as Lee does not cite it, it is probably a triviality. Can someone point me in the right direction?","17.32, pp. 455-456 H_{dR}^n(M)=0, M n. f\in C^\infty (M) M [0,\infty). i>0, V_i=f^{-1}((i-2,i)). M 17.30 pp. 454-455, V_i V_i 17.30 f_i V_i","['differential-geometry', 'manifolds', 'differential-topology', 'de-rham-cohomology']"
77,Proof of Klingenberg's lemma in do Carmo's Riemannian Geometry,Proof of Klingenberg's lemma in do Carmo's Riemannian Geometry,,"The following is Exercise 10.1 in Riemannian Geometry by M. do Carmo. (Klingenberg's Lemma). Let $M$ be a complete Riemannian manifold with sectional curvature $K<K_0$ , where $K_0$ is a positive constant. Let $p,q\in M$ and let $\gamma_0$ and $\gamma_1$ be two distinct geodesics joining $p$ to $q$ with $\ell(\gamma_0)<\ell(\gamma_1)$ . Assume that $\gamma_0$ is homotopic to $\gamma_1$ , that is, there exists a continuous family of curves $\alpha_t$ , $t\in[0,1]$ such that $\alpha_0=\gamma_0$ and $\alpha_1=\gamma_1$ . Prove that there exists $t_0\in(0,1]$ such that $$\ell(\gamma_0)+\ell(\alpha_{t_0})\geq\frac{2\pi}{\sqrt{K_0}}.$$ The hint goes: Hint: Assume $\ell(\gamma_0)<\pi/\sqrt{K_0}$ (otherwise, we have nothing to prove). From Ranch's Theorem, $\exp_p:TpM\to M$ has no critical point in the open ball $B$ of radius $\pi/\sqrt{K_0}$ , centered at $p$ . For $t$ small, it is possible to lift the curve at to the tangent space $T_pM$ , i.e., there exists a curve $\widetilde{\alpha}_t$ in $T_pM$ , joining $\exp_p^{-1}(0)=0$ to $\exp_p^{-1}(q)=\widetilde{q}$ , such that $\exp_p\circ\widetilde{\alpha}_t=\alpha_t$ . It is clear that it is not possible to do the same for every $t\in[0,1]$ , since $\gamma_1$ cannot be lifted keeping the endpoints fixed. We conclude that for all $\varepsilon>0$ there exists a $t(\varepsilon)$ such that $\alpha_{t(\varepsilon)}$ can be lifted to $\tilde{\alpha}_{t(\varepsilon)}$ and $\tilde{\alpha}_{t(\varepsilon)}$ contains points with distance $<\varepsilon$ from the boundary $\partial B$ of $B$ . In the contrary case, for some $\varepsilon>0$ , all lifts $\tilde{\alpha}_t$ are at the distance $\geq\varepsilon$ from $\partial B$ ; the set of $t$ 's for which it is possible to lift $\alpha_t$ will then be open and closed and $\alpha_1$ could be lifted, which is a contradiction. Therefore, for all $\varepsilon>0$ , we have $$\ell(\gamma_0)+\ell(\alpha_{t(\varepsilon)})\geq\frac{2\pi}{\sqrt{K_0}}-\varepsilon.$$ Now choose a sequence $\{\varepsilon_n\}\to0$ , and consider a convergent subsequence of $\{t(\varepsilon_n)\}\to t_0$ . Then there exists a curve $\alpha_{t_0}$ with $$\ell(\gamma_0)+\ell(\alpha_{t_0})\geq\frac{2\pi}{\sqrt{K_0}}.$$ Why do such liftings exist? We only know that $\exp_p$ is nonsingular on $B(0,R):=\{v\in T_pM:|v|<R\}$ , not that $\exp_p|_{B(0,R)}$ is a covering map or anything. Local diffeomorphisms can behave badly when it comes to lifting curves! So here is my question: Let $(M,g)$ be a complete Riemannian manifold and $p\in M$ . Suppose $\exp_p$ is nonsingular everywhere on $B(0,R)\subset T_pM$ . Does any curve on $M$ starting from $p$ with length $<R$ lift to a curve on $T_pM$ starting at $0$ ? What about homotopies of such curves? In particular, why does the hint works? Another question: While in do Carmo's book this result is called Klingenberg's lemma, I cannot find it in any other resource. When and in which paper did Klingenberg prove this?","The following is Exercise 10.1 in Riemannian Geometry by M. do Carmo. (Klingenberg's Lemma). Let be a complete Riemannian manifold with sectional curvature , where is a positive constant. Let and let and be two distinct geodesics joining to with . Assume that is homotopic to , that is, there exists a continuous family of curves , such that and . Prove that there exists such that The hint goes: Hint: Assume (otherwise, we have nothing to prove). From Ranch's Theorem, has no critical point in the open ball of radius , centered at . For small, it is possible to lift the curve at to the tangent space , i.e., there exists a curve in , joining to , such that . It is clear that it is not possible to do the same for every , since cannot be lifted keeping the endpoints fixed. We conclude that for all there exists a such that can be lifted to and contains points with distance from the boundary of . In the contrary case, for some , all lifts are at the distance from ; the set of 's for which it is possible to lift will then be open and closed and could be lifted, which is a contradiction. Therefore, for all , we have Now choose a sequence , and consider a convergent subsequence of . Then there exists a curve with Why do such liftings exist? We only know that is nonsingular on , not that is a covering map or anything. Local diffeomorphisms can behave badly when it comes to lifting curves! So here is my question: Let be a complete Riemannian manifold and . Suppose is nonsingular everywhere on . Does any curve on starting from with length lift to a curve on starting at ? What about homotopies of such curves? In particular, why does the hint works? Another question: While in do Carmo's book this result is called Klingenberg's lemma, I cannot find it in any other resource. When and in which paper did Klingenberg prove this?","M K<K_0 K_0 p,q\in M \gamma_0 \gamma_1 p q \ell(\gamma_0)<\ell(\gamma_1) \gamma_0 \gamma_1 \alpha_t t\in[0,1] \alpha_0=\gamma_0 \alpha_1=\gamma_1 t_0\in(0,1] \ell(\gamma_0)+\ell(\alpha_{t_0})\geq\frac{2\pi}{\sqrt{K_0}}. \ell(\gamma_0)<\pi/\sqrt{K_0} \exp_p:TpM\to M B \pi/\sqrt{K_0} p t T_pM \widetilde{\alpha}_t T_pM \exp_p^{-1}(0)=0 \exp_p^{-1}(q)=\widetilde{q} \exp_p\circ\widetilde{\alpha}_t=\alpha_t t\in[0,1] \gamma_1 \varepsilon>0 t(\varepsilon) \alpha_{t(\varepsilon)} \tilde{\alpha}_{t(\varepsilon)} \tilde{\alpha}_{t(\varepsilon)} <\varepsilon \partial B B \varepsilon>0 \tilde{\alpha}_t \geq\varepsilon \partial B t \alpha_t \alpha_1 \varepsilon>0 \ell(\gamma_0)+\ell(\alpha_{t(\varepsilon)})\geq\frac{2\pi}{\sqrt{K_0}}-\varepsilon. \{\varepsilon_n\}\to0 \{t(\varepsilon_n)\}\to t_0 \alpha_{t_0} \ell(\gamma_0)+\ell(\alpha_{t_0})\geq\frac{2\pi}{\sqrt{K_0}}. \exp_p B(0,R):=\{v\in T_pM:|v|<R\} \exp_p|_{B(0,R)} (M,g) p\in M \exp_p B(0,R)\subset T_pM M p <R T_pM 0","['differential-geometry', 'riemannian-geometry']"
78,Are distance functions necessarily nonsmooth on the cut locus?,Are distance functions necessarily nonsmooth on the cut locus?,,"Let $(M,g)$ be a complete Riemannian manifold and fix $p\in M$ . Consider the distance function $r(x):=d(p,x)$ . It is well-known that $r$ is smooth outside $\operatorname{cut}(p)\cup\{p\}$ where $\operatorname{cut}(p)$ is the cut locus of $p$ . My question is: Is $r$ necessarily nonsmooth on every point of $\operatorname{cut}(p)$ ? It is well-known that $x\in\operatorname{cut}(p)$ if and only if either (a) there are two distinct unit-speed minimizing geodesics $\gamma_1,\gamma_2:[0,\ell]\to M$ joining $p$ and $x$ , or (b) $x$ is a critical value of $\exp_p$ . In Peter Petersen's Riemannian Geometry , the author gave a remark on this: In case (a), $\nabla r$ could be either $\gamma_1'(\ell)$ or $\gamma_2'(\ell)$ and hence does not exist; in case (b), $\operatorname{Hess}r$ is undefined since it must tend to $-\infty$ along certain fields. I know that the part about (a) is intuitive, but is there any way to make the argument rigorous? O the other hand, I don't see why $\operatorname{Hess}r$ must blow up.","Let be a complete Riemannian manifold and fix . Consider the distance function . It is well-known that is smooth outside where is the cut locus of . My question is: Is necessarily nonsmooth on every point of ? It is well-known that if and only if either (a) there are two distinct unit-speed minimizing geodesics joining and , or (b) is a critical value of . In Peter Petersen's Riemannian Geometry , the author gave a remark on this: In case (a), could be either or and hence does not exist; in case (b), is undefined since it must tend to along certain fields. I know that the part about (a) is intuitive, but is there any way to make the argument rigorous? O the other hand, I don't see why must blow up.","(M,g) p\in M r(x):=d(p,x) r \operatorname{cut}(p)\cup\{p\} \operatorname{cut}(p) p r \operatorname{cut}(p) x\in\operatorname{cut}(p) \gamma_1,\gamma_2:[0,\ell]\to M p x x \exp_p \nabla r \gamma_1'(\ell) \gamma_2'(\ell) \operatorname{Hess}r -\infty \operatorname{Hess}r","['differential-geometry', 'riemannian-geometry']"
79,Exercise 5.40 John Lee ISM. $S \subset M$ is a level set of a smooth map $\Phi : M \to N$ with constant rank then $T_pS = {\rm Ker} d\Phi_p$ .,Exercise 5.40 John Lee ISM.  is a level set of a smooth map  with constant rank then  .,S \subset M \Phi : M \to N T_pS = {\rm Ker} d\Phi_p,"The following is Exercise 5.40 from John Lee's ISM. Suppose $S \subset M$ is a level set of a smooth map $\Phi : M \to N$ with constant rank. Show that $T_pS = {\rm Ker} d\Phi_p$ for each $p \in S$ . I am having a hard time proving this result. From Theorem 5.12 (Constant-Rank Level Set Theorem) of the txt, I know that $S$ is a properly embedded submanifold. I think the proof should be similar to Proposition 5.38. Using the fact that the inclusion map $\iota: S \hookrightarrow M$ is a smooth immersion, I can show that since $\Phi \circ \iota$ is constant on $S$ , so $d\Phi_p \circ d \iota_p$ is the zero map from $T_pS$ to $T_{\Phi(P)}N$ , and therefore ${\rm Im} d \iota_p \subset {\rm Ker} d\Phi_p$ . Up to here, is identical to the proof of Proposition 5.38. However, I cannot use that $d\Phi_p$ is surjective as in the proof, so I cannot conclude that ${\rm Im} d \iota_p = {\rm Ker} d \Phi_p$ . I am lost here. I would greatly appreciate any help.","The following is Exercise 5.40 from John Lee's ISM. Suppose is a level set of a smooth map with constant rank. Show that for each . I am having a hard time proving this result. From Theorem 5.12 (Constant-Rank Level Set Theorem) of the txt, I know that is a properly embedded submanifold. I think the proof should be similar to Proposition 5.38. Using the fact that the inclusion map is a smooth immersion, I can show that since is constant on , so is the zero map from to , and therefore . Up to here, is identical to the proof of Proposition 5.38. However, I cannot use that is surjective as in the proof, so I cannot conclude that . I am lost here. I would greatly appreciate any help.",S \subset M \Phi : M \to N T_pS = {\rm Ker} d\Phi_p p \in S S \iota: S \hookrightarrow M \Phi \circ \iota S d\Phi_p \circ d \iota_p T_pS T_{\Phi(P)}N {\rm Im} d \iota_p \subset {\rm Ker} d\Phi_p d\Phi_p {\rm Im} d \iota_p = {\rm Ker} d \Phi_p,"['differential-geometry', 'manifolds', 'smooth-manifolds']"
80,Is any parametrization of a smooth curve smooth? Can we always find a smooth parametrization of a smooth curve?,Is any parametrization of a smooth curve smooth? Can we always find a smooth parametrization of a smooth curve?,,"I assume that this must be true because the parametrization describes the same object, but I cannot recall a theorem that would state this explicitly.","I assume that this must be true because the parametrization describes the same object, but I cannot recall a theorem that would state this explicitly.",,"['differential-geometry', 'curves', 'parametrization']"
81,"What does the adjoint action of a Lie group on its Lie algebra, ${\rm Ad}:G\times{\frak g\to g}$, actually give us?","What does the adjoint action of a Lie group on its Lie algebra, , actually give us?",{\rm Ad}:G\times{\frak g\to g},"We know that a Lie group G acts on itself by conjugation. That is, $g \rightarrow I_g = R_{g^{-1}}\circ L_g$ and that this action is an automorphism associated to $G$ . We also know that conjugation maps $e$ (identity on $G$ ) to itself so we would expect the derivative of $I_g$ to map $T_eG=\mathfrak{g}\rightarrow T_eG=\mathfrak{g}$ . Now, according to Marsden and Ratiu's $\textit{Introduction to Mechanics and Symmetry}$ (Chapter 9, pg. 311), differentiating $I_g$ at $e$ gives the $\textbf{adjoint representation}$ of $G$ on $\mathfrak{g}$ : $$\textrm{Ad}_g:=T_eI_g:T_eG=\mathfrak{g}\rightarrow T_eG=\mathfrak{g}$$ Explicitly, the adjoint action of $G$ on $\mathfrak{g}$ is given by $$\textrm{Ad}:G\times \mathfrak{g}\rightarrow \mathfrak{g},\:\:\:\:\:\textrm{Ad}_g(\xi) = T_e(R_{g^{-1}}\circ L_g)\xi$$ $\textbf{Question}$ : What is that map actually giving us? What does taking the derivative actually mean here? (Yes, I know its a tangent space map but, that doesn't tell me much about this particular case) It's taking in a vector in $\mathfrak{g}$ and outputting what exactly? I feel like almost $\textit{every}$ book just gives something like 'differentiating the conjugate gives a map from $\mathfrak{g}$ to $\mathfrak{g}$ ' and hides what's happening inside. The example from Marsden and Ratiu leads to more questions than answers too. $\textbf{Example}:$ For $SO(3)$ we have $I_A(B) = ABA^{-1}$ so differentiating with respect to $B$ at $B=\textrm{identity}$ gives $\textrm{Ad}_A \hat{v} = A\hat{v}A^{-1}$ . However $$(\textrm{Ad}_A \hat{v})(w) = A\hat(v)A^{-1}w = A(v \times A^{-1}w) = Av \times w$$ so $$(\textrm{Ad}_A\hat{v})=(Av)^{\hat{}}$$ Identifying $\mathfrak{so}(3)$ with $\mathbb{R}^3$ gives $Ad_A v = Av$ . $\textbf{Question:}$ What????? How did we end up evaluating at $w$ . How did we end up taking a cross product in there? And again, what did we really end up with as a result of this map? A representation should be a matrix associated to an element of the Lie group, no? So what is our matrix in this example? Is it $A$ ? $\textbf{Further context}$ : I'm trying very hard to understand this to get to what is meant by the $\textrm{Ad}^*$ -equivariant moment map.","We know that a Lie group G acts on itself by conjugation. That is, and that this action is an automorphism associated to . We also know that conjugation maps (identity on ) to itself so we would expect the derivative of to map . Now, according to Marsden and Ratiu's (Chapter 9, pg. 311), differentiating at gives the of on : Explicitly, the adjoint action of on is given by : What is that map actually giving us? What does taking the derivative actually mean here? (Yes, I know its a tangent space map but, that doesn't tell me much about this particular case) It's taking in a vector in and outputting what exactly? I feel like almost book just gives something like 'differentiating the conjugate gives a map from to ' and hides what's happening inside. The example from Marsden and Ratiu leads to more questions than answers too. For we have so differentiating with respect to at gives . However so Identifying with gives . What????? How did we end up evaluating at . How did we end up taking a cross product in there? And again, what did we really end up with as a result of this map? A representation should be a matrix associated to an element of the Lie group, no? So what is our matrix in this example? Is it ? : I'm trying very hard to understand this to get to what is meant by the -equivariant moment map.","g \rightarrow I_g = R_{g^{-1}}\circ L_g G e G I_g T_eG=\mathfrak{g}\rightarrow T_eG=\mathfrak{g} \textit{Introduction to Mechanics and Symmetry} I_g e \textbf{adjoint representation} G \mathfrak{g} \textrm{Ad}_g:=T_eI_g:T_eG=\mathfrak{g}\rightarrow T_eG=\mathfrak{g} G \mathfrak{g} \textrm{Ad}:G\times \mathfrak{g}\rightarrow \mathfrak{g},\:\:\:\:\:\textrm{Ad}_g(\xi) = T_e(R_{g^{-1}}\circ L_g)\xi \textbf{Question} \mathfrak{g} \textit{every} \mathfrak{g} \mathfrak{g} \textbf{Example}: SO(3) I_A(B) = ABA^{-1} B B=\textrm{identity} \textrm{Ad}_A \hat{v} = A\hat{v}A^{-1} (\textrm{Ad}_A \hat{v})(w) = A\hat(v)A^{-1}w = A(v \times A^{-1}w) = Av \times w (\textrm{Ad}_A\hat{v})=(Av)^{\hat{}} \mathfrak{so}(3) \mathbb{R}^3 Ad_A v = Av \textbf{Question:} w A \textbf{Further context} \textrm{Ad}^*","['differential-geometry', 'lie-groups', 'lie-algebras', 'symplectic-geometry', 'tangent-spaces']"
82,Minimal surfaces,Minimal surfaces,,Among the definitions of minimal suraface I found these two: (1) A surface $M\subset\mathbb{R}^3$ is minimal if for any point $p\in M$ there is a neighborhood $U$ of $p$ in $M$ that minimizes the area relatively to its boundary. (2) A surface $M\subset\mathbb{R}^3$ with zero mean curvature. I would like to understand why (1) and (2) are equivalent. Thank you very much.,Among the definitions of minimal suraface I found these two: (1) A surface is minimal if for any point there is a neighborhood of in that minimizes the area relatively to its boundary. (2) A surface with zero mean curvature. I would like to understand why (1) and (2) are equivalent. Thank you very much.,M\subset\mathbb{R}^3 p\in M U p M M\subset\mathbb{R}^3,"['differential-geometry', 'area', 'surfaces', 'curvature', 'minimal-surfaces']"
83,When is the Rayleigh quotient (spherically) convex?,When is the Rayleigh quotient (spherically) convex?,,"Suppose that $A$ is a real, $n \times n$ symmetric matrix. Define the map $F: \mathbf{R}^n \to \mathbf{R}$ by $x \mapsto x^T A x$ . Question: For which matrices $A$ is the map $f = F|_{S^{n-1}}$ convex? Let us give an interpretation for convexity in the sense of the question above. Definition: Let $M$ be a Riemannian manifold. A map $f: M \to \mathbf{R}$ is convex , provided that for every geodesic $\gamma: [0, 1] \to M$ , and every $t \in [0, 1]$ , $$ f(\gamma(t)) \leq t f(\gamma(0)) + (1-t) f(\gamma(1)).$$ Let us make three remarks now. First, this definition implies that $f \circ \gamma$ is a convex map for all geodesics $\gamma$ (check this via restricting $\gamma$ , yielding yet another geodesic). Secondly, when $M = \mathbf{R}^n$ with the usual flat metric, this definition reduces to $$ f(x_t) \leq t f(x_0) + (1-t) f(x_1), \qquad \mbox{for every $x_0, x_1 \in \mathbf{R}^n$}, $$ where above $x_t:= tx_0 + (1-t)x_1$ , $t\in [0, 1]$ . In other words, the usual definition of convexity for maps $\mathbf{R}^n \to \mathbf{R}$ . Finally, if $S^{n-1}$ is replaced by $\mathbf{R}^n$ above, then the answer to the question is simply for $A$ nonnegative definite.","Suppose that is a real, symmetric matrix. Define the map by . Question: For which matrices is the map convex? Let us give an interpretation for convexity in the sense of the question above. Definition: Let be a Riemannian manifold. A map is convex , provided that for every geodesic , and every , Let us make three remarks now. First, this definition implies that is a convex map for all geodesics (check this via restricting , yielding yet another geodesic). Secondly, when with the usual flat metric, this definition reduces to where above , . In other words, the usual definition of convexity for maps . Finally, if is replaced by above, then the answer to the question is simply for nonnegative definite.","A n \times n F: \mathbf{R}^n \to \mathbf{R} x \mapsto x^T A x A f = F|_{S^{n-1}} M f: M \to \mathbf{R} \gamma: [0, 1] \to M t \in [0, 1]  f(\gamma(t)) \leq t f(\gamma(0)) + (1-t) f(\gamma(1)). f \circ \gamma \gamma \gamma M = \mathbf{R}^n 
f(x_t) \leq t f(x_0) + (1-t) f(x_1), \qquad \mbox{for every x_0, x_1 \in \mathbf{R}^n},
 x_t:= tx_0 + (1-t)x_1 t\in [0, 1] \mathbf{R}^n \to \mathbf{R} S^{n-1} \mathbf{R}^n A","['differential-geometry', 'convex-analysis', 'manifolds', 'riemannian-geometry', 'geodesic']"
84,Vector field on an odd sphere. $X = \sum_{i=1}^n -y^i \frac{\partial}{\partial x^i} + x^i \frac{\partial}{\partial y^i}$ is smooth.,Vector field on an odd sphere.  is smooth.,X = \sum_{i=1}^n -y^i \frac{\partial}{\partial x^i} + x^i \frac{\partial}{\partial y^i},"This is problem 14.2 from Loring Tu's Introduction to Manifolds. Vector field on an odd sphere. Let $x^1,y^1,\dots,x^n,y^n$ be the standard coordinates on $R^{2n}$ . The unit sphere $S^{2n-1}$ in $R^{2n}$ is defined by the equation $\sum (x^i)^2 + (y^i)^2=1$ . Show that $$X = \sum_{i=1}^n -y^i \frac{\partial}{\partial x^i} + x^i \frac{\partial}{\partial y^i}$$ is a nowhere-vanishing smooth vector field on $S^{2n-1}$ . I have shown that it is nowhere-vanishing, but I do not know how to show that this is smooth. From Proposition 14.2 of the text, it is equivalent to showing that there is an atlas on the unit sphere such that on any chart $(U,\phi) = (U,z^1,\dots z^n)$ of the atlas, the coefficients $a^i$ of $X=\sum a^i \partial/\partial z^i$ relative to the frame $\partial/\partial z^i$ are all smooth. I know of two charts for the unit sphere : the projection charts onto each hemisphere and the stereographic projection. However, for each atlas has only $2n-1$ coordinates, so there are $2n-1$ basis vectors $\partial / \partial z^i$ , whereas the standard coordinates give us $2n$ bases. How can we make a transition between two coordinates of different number of basis here? This is a solution I found for this problem. However, I can't figure out how we can formally justify $$\frac{\partial}{\partial t^i} = \sum \frac{\partial z_k}{\partial t^i}\frac{\partial}{\partial z_k}.$$ Here we are expressing the standard tangent vectors on $R^{2n}$ , i.e. $\partial / \partial t^i$ in terms of the tangent vectors $\partial / \partial z_k$ on the unit sphere $S^{2n-1}$ given by the stereographic projection. However, these two coordinate maps belong to spaces of different dimensions. So we cannot use, say the following proposition from the text. As we can see from the proof, the transition relationship depends on the fact that the two frames are with respect to the same tangent space, hence one is a linear combination of the others. However, here they belong to different spaces, so how can we come up with such a linear combination?","This is problem 14.2 from Loring Tu's Introduction to Manifolds. Vector field on an odd sphere. Let be the standard coordinates on . The unit sphere in is defined by the equation . Show that is a nowhere-vanishing smooth vector field on . I have shown that it is nowhere-vanishing, but I do not know how to show that this is smooth. From Proposition 14.2 of the text, it is equivalent to showing that there is an atlas on the unit sphere such that on any chart of the atlas, the coefficients of relative to the frame are all smooth. I know of two charts for the unit sphere : the projection charts onto each hemisphere and the stereographic projection. However, for each atlas has only coordinates, so there are basis vectors , whereas the standard coordinates give us bases. How can we make a transition between two coordinates of different number of basis here? This is a solution I found for this problem. However, I can't figure out how we can formally justify Here we are expressing the standard tangent vectors on , i.e. in terms of the tangent vectors on the unit sphere given by the stereographic projection. However, these two coordinate maps belong to spaces of different dimensions. So we cannot use, say the following proposition from the text. As we can see from the proof, the transition relationship depends on the fact that the two frames are with respect to the same tangent space, hence one is a linear combination of the others. However, here they belong to different spaces, so how can we come up with such a linear combination?","x^1,y^1,\dots,x^n,y^n R^{2n} S^{2n-1} R^{2n} \sum (x^i)^2 + (y^i)^2=1 X = \sum_{i=1}^n -y^i \frac{\partial}{\partial x^i} + x^i \frac{\partial}{\partial y^i} S^{2n-1} (U,\phi) = (U,z^1,\dots z^n) a^i X=\sum a^i \partial/\partial z^i \partial/\partial z^i 2n-1 2n-1 \partial / \partial z^i 2n \frac{\partial}{\partial t^i} = \sum \frac{\partial z_k}{\partial t^i}\frac{\partial}{\partial z_k}. R^{2n} \partial / \partial t^i \partial / \partial z_k S^{2n-1}","['differential-geometry', 'manifolds', 'smooth-manifolds', 'vector-fields']"
85,How to read the expression of an affine connection: $\nabla_X Y$?,How to read the expression of an affine connection: ?,\nabla_X Y,"I am studying Riemannian Geometry from the textbook Riemannian Geometry by do Carmo (English edition). In section 2 of chapter 2, page 50, he defines an affine connection as follows: 2.1 Definition. An affine connection $\nabla$ on a differentiable manifold $M$ is a mapping $$ \nabla : \mathfrak{X}(M) \times \mathfrak{X}(M) \to \mathfrak{X}(M) $$ which is denoted by $(X,Y) \overset{\nabla}{\to} \nabla_X Y$ and which satisfies the following properties: $\nabla_{fX + gY} Z = f \nabla_X Z + g \nabla_Y Z$ . $\nabla_X(Y+Z) = \nabla_X Y + \nabla_X Z$ . $\nabla_X (fY) = f \nabla_X Y + X(f) Y$ , in which $X,Y,Z \in \mathfrak{X}(M)$ and $f,g \in \mathcal{D}(M)$ . Here, $M$ is a smooth manifold, $\mathfrak{X}(M)$ is the set of all smooth vector fields on $M$ , and $\mathcal{D}(M)$ is the ring of real-valued smooth functions on $M$ . My question is, how do I speak (or read) the affine connection $\nabla$ , or $\nabla_X Y$ ? do Carmo does not give any suggestions, and I was unable to find any details on Wikipedia or in Google searches with terms like affine connection pronounce/pronunciation affine connection how to speak affine connection how to read I could not find any related question on this Stack Exchange either. I am aware that the $\LaTeX$ command for $\nabla$ is \nabla . In my undergraduate classes, I encountered this symbol as a gradient operator, where we called it ""grad"", and also sometimes ""del"". Can someone tell me what is (or what are) the standard pronunciation(s) for the affine connection $\nabla$ in Riemannian Geometry? To be precise, how do I read the symbol(s) $\nabla$ or $\nabla_X Y$ when I encounter them in the text, for instance in an expression like $\nabla_{X_i} X_j = \sum_k \Gamma_{ij}^k X_k$ ? Thanks in advance.","I am studying Riemannian Geometry from the textbook Riemannian Geometry by do Carmo (English edition). In section 2 of chapter 2, page 50, he defines an affine connection as follows: 2.1 Definition. An affine connection on a differentiable manifold is a mapping which is denoted by and which satisfies the following properties: . . , in which and . Here, is a smooth manifold, is the set of all smooth vector fields on , and is the ring of real-valued smooth functions on . My question is, how do I speak (or read) the affine connection , or ? do Carmo does not give any suggestions, and I was unable to find any details on Wikipedia or in Google searches with terms like affine connection pronounce/pronunciation affine connection how to speak affine connection how to read I could not find any related question on this Stack Exchange either. I am aware that the command for is \nabla . In my undergraduate classes, I encountered this symbol as a gradient operator, where we called it ""grad"", and also sometimes ""del"". Can someone tell me what is (or what are) the standard pronunciation(s) for the affine connection in Riemannian Geometry? To be precise, how do I read the symbol(s) or when I encounter them in the text, for instance in an expression like ? Thanks in advance.","\nabla M 
\nabla : \mathfrak{X}(M) \times \mathfrak{X}(M) \to \mathfrak{X}(M)
 (X,Y) \overset{\nabla}{\to} \nabla_X Y \nabla_{fX + gY} Z = f \nabla_X Z + g \nabla_Y Z \nabla_X(Y+Z) = \nabla_X Y + \nabla_X Z \nabla_X (fY) = f \nabla_X Y + X(f) Y X,Y,Z \in \mathfrak{X}(M) f,g \in \mathcal{D}(M) M \mathfrak{X}(M) M \mathcal{D}(M) M \nabla \nabla_X Y \LaTeX \nabla \nabla \nabla \nabla_X Y \nabla_{X_i} X_j = \sum_k \Gamma_{ij}^k X_k","['differential-geometry', 'riemannian-geometry']"
86,What does it mean for a complex differential form on a complex manifold to be real?,What does it mean for a complex differential form on a complex manifold to be real?,,"I am trying to read Kobayashi's ""Differential geometry of complex vector bundles"". There are many places where a complex differential form is referred to as being real . e.g Chapter I, Proposition 7.24 p. 28 "" A closed real $(p,p)$ form $\omega$ on a compact Kähler manifold M is cohomologous to zero if and only if $ \omega = id' d'' \phi $ for some real $(p-1,p-1)$ -form $\phi. $ "" Similarly, p. 41 Chapter II, Proposition 2.23 "" Given any closed real $(1,1)$ -form $\phi$ representing $c_{1}(E),$ there is an Hermitian structure $h$ in $E$ such that $\phi = c_{1}(E)$ provided $M$ is compact Kähler."" What does it mean? Does it mean that the coefficients are real valued function? Or does it mean that it is the same under complex conjugation ? i.e. $\bar{\phi} = \phi ? $ To be more explicit, Let $\alpha, \beta : \mathbb{C}^{2} \rightarrow \mathbb{R}$ be real valued smooth functions and let $$ \phi = [\alpha(z_{1}, z_{2}) + i \beta(z_{1}, z_{2})] dz_{1}\wedge d\bar{z_{2}} -  [\alpha(z_{1}, z_{2}) - i \beta(z_{1}, z_{2})] dz_{2}\wedge d\bar{z_{1}} . $$ This is a $(1,1)$ -form on $\mathbb{C}^{2}$ with the property that $\bar{\phi} = \phi, $ since $ \overline{dz_{1}\wedge d\bar{z_{2}}} = - dz_{2}\wedge d\bar{z_{1}},$ but this is a real valued form only if $\beta \equiv 0$ on $\mathbb{C}^{2}.$ Or does $\phi$ being real mean something else? Thanks in advance for any help.","I am trying to read Kobayashi's ""Differential geometry of complex vector bundles"". There are many places where a complex differential form is referred to as being real . e.g Chapter I, Proposition 7.24 p. 28 "" A closed real form on a compact Kähler manifold M is cohomologous to zero if and only if for some real -form "" Similarly, p. 41 Chapter II, Proposition 2.23 "" Given any closed real -form representing there is an Hermitian structure in such that provided is compact Kähler."" What does it mean? Does it mean that the coefficients are real valued function? Or does it mean that it is the same under complex conjugation ? i.e. To be more explicit, Let be real valued smooth functions and let This is a -form on with the property that since but this is a real valued form only if on Or does being real mean something else? Thanks in advance for any help.","(p,p) \omega  \omega = id' d'' \phi  (p-1,p-1) \phi.  (1,1) \phi c_{1}(E), h E \phi = c_{1}(E) M \bar{\phi} = \phi ?  \alpha, \beta : \mathbb{C}^{2} \rightarrow \mathbb{R}  \phi = [\alpha(z_{1}, z_{2}) + i \beta(z_{1}, z_{2})] dz_{1}\wedge d\bar{z_{2}} -  [\alpha(z_{1}, z_{2}) - i \beta(z_{1}, z_{2})] dz_{2}\wedge d\bar{z_{1}} .  (1,1) \mathbb{C}^{2} \bar{\phi} = \phi,   \overline{dz_{1}\wedge d\bar{z_{2}}} = - dz_{2}\wedge d\bar{z_{1}}, \beta \equiv 0 \mathbb{C}^{2}. \phi","['differential-geometry', 'differential-forms', 'complex-geometry']"
87,Book suggestion for Differential Geometry after kreyszig.,Book suggestion for Differential Geometry after kreyszig.,,"Preview of kreyszig's book: https://books.google.com/books/about/Differential_Geometry.html?id=B7yxgFaQKNAC&printsec=frontcover&source=kp_read_button#v=onepage&q&f=false As seen in the link, the presentations in Kreyszig's are limited to 3 dimension. Only calculus, and a bit of linear algebra, and some ODE knowledge are needed to read kreyszig's book. My purpose for studying DG is to understand General Relativity which involve 4 dimension. My math background is, calulus,123,ODE,linear algebra,basic complex integration.  I have read an introductory book on general topology,and functional analysis also by kreyszig. So far, I havn't read any text on abstract algebra. I have also briefly read Real Analysis by terrence tao. Other than all these, I have a little knowledge about PDEs and asymptotic analysis. If I want to learn some more general concepts and theorems about DG, on my level, what book do you recommend? Or perhaps, I should study Abstract algebra first?","Preview of kreyszig's book: https://books.google.com/books/about/Differential_Geometry.html?id=B7yxgFaQKNAC&printsec=frontcover&source=kp_read_button#v=onepage&q&f=false As seen in the link, the presentations in Kreyszig's are limited to 3 dimension. Only calculus, and a bit of linear algebra, and some ODE knowledge are needed to read kreyszig's book. My purpose for studying DG is to understand General Relativity which involve 4 dimension. My math background is, calulus,123,ODE,linear algebra,basic complex integration.  I have read an introductory book on general topology,and functional analysis also by kreyszig. So far, I havn't read any text on abstract algebra. I have also briefly read Real Analysis by terrence tao. Other than all these, I have a little knowledge about PDEs and asymptotic analysis. If I want to learn some more general concepts and theorems about DG, on my level, what book do you recommend? Or perhaps, I should study Abstract algebra first?",,"['differential-geometry', 'book-recommendation']"
88,Are there interesting example of pseudo-Riemannian manifold other than spacetime manifold?,Are there interesting example of pseudo-Riemannian manifold other than spacetime manifold?,,The 4 dimensional spacetime manifold is a typical example of pseudo-Riemannian manifold. Are there other mathematically or physically interesting example of it?,The 4 dimensional spacetime manifold is a typical example of pseudo-Riemannian manifold. Are there other mathematically or physically interesting example of it?,,"['differential-geometry', 'soft-question', 'riemannian-geometry', 'physics', 'motivation']"
89,Cartan subalgebra and orbits of the adjoint action,Cartan subalgebra and orbits of the adjoint action,,"While studying for the Chern-Weil description of the characteristic classes, we consider the procedure to cook up invariant polynomials under the adjoint action. That is, given a principal $G$-bundle $P \to M$, we consider symmetric multilinear maps $f: (\Omega^{\mathrm{even}}(M) \otimes \mathfrak{g})^k \to \mathbb{C}$ that are invariant under the ($k$-fold induced action) of the adjoint action $G \to \mathrm{GL} (\mathfrak{g})$. For the Chern classes, we consider $G = \mathrm{U}(n)$ and the skew-hermitian matrices $\mathfrak{g} = \mathfrak{u}(n)$. What is nice is that every element in $\mathfrak{u}(n)$ is conjugate to an element in the Cartan subalgebra $\mathbb{C}^n$ (diagonal skew-hermitian matrices) of $\mathfrak{u}(n)$, and the conjugacy classes in the Cartan subalgebra correspond to the orbits of the Weyl group $W_{\mathrm{U}(n)} = S_n$. So we can identify the adjoint invariant polynomials on $\mathfrak{g}$ as the symmetric polynomials on $n$ variables. My question is when does this behavior (that is, every element of $\mathfrak{g}$  can be taken into the Cartan subalgebra by the adjoint action, and the orbit of the restricted action on the Cartan subalgebra is equal to the orbit of the Weyl group) occur? I see this for $G = \mathrm{U}(n)$ or $G = \mathrm{O}(n)$, but I am not sure if the definition of the Cartan subalgebra yields this result. Does it work for matrix Lie groups in general? I am a bit rusty on Lie theory, but any help is appreciated!","While studying for the Chern-Weil description of the characteristic classes, we consider the procedure to cook up invariant polynomials under the adjoint action. That is, given a principal $G$-bundle $P \to M$, we consider symmetric multilinear maps $f: (\Omega^{\mathrm{even}}(M) \otimes \mathfrak{g})^k \to \mathbb{C}$ that are invariant under the ($k$-fold induced action) of the adjoint action $G \to \mathrm{GL} (\mathfrak{g})$. For the Chern classes, we consider $G = \mathrm{U}(n)$ and the skew-hermitian matrices $\mathfrak{g} = \mathfrak{u}(n)$. What is nice is that every element in $\mathfrak{u}(n)$ is conjugate to an element in the Cartan subalgebra $\mathbb{C}^n$ (diagonal skew-hermitian matrices) of $\mathfrak{u}(n)$, and the conjugacy classes in the Cartan subalgebra correspond to the orbits of the Weyl group $W_{\mathrm{U}(n)} = S_n$. So we can identify the adjoint invariant polynomials on $\mathfrak{g}$ as the symmetric polynomials on $n$ variables. My question is when does this behavior (that is, every element of $\mathfrak{g}$  can be taken into the Cartan subalgebra by the adjoint action, and the orbit of the restricted action on the Cartan subalgebra is equal to the orbit of the Weyl group) occur? I see this for $G = \mathrm{U}(n)$ or $G = \mathrm{O}(n)$, but I am not sure if the definition of the Cartan subalgebra yields this result. Does it work for matrix Lie groups in general? I am a bit rusty on Lie theory, but any help is appreciated!",,"['differential-geometry', 'algebraic-topology', 'lie-groups', 'lie-algebras', 'characteristic-classes']"
90,For which $a$ is $y^2= x^3 + a$ a submanifold?,For which  is  a submanifold?,a y^2= x^3 + a,"I am having a hard time solving the equations to find the $a \in \Bbb R$ for which $$M_a = \left \lbrace {(x,y)\in \mathbb {R}^2} \mid {y^2= x^3 + a}\right \rbrace$$ is a submanifold of $\Bbb R^2$. I defined $F: \Bbb R^2 \to \Bbb R$ with $F(x,y)=y^2-x^3-a$ such that $M_a = F^{-1}(0)$ and $F$ is smooth. By the preimage theorem $M_a$ is a $1$ dimensional submanifold if $M_a$ doesn't contain any critical values of $F$. To compute the critical values of $F$, set $$D_{(x,y)}F = \begin{bmatrix} -3x^2 & 2y \end{bmatrix} = 0$$ and for $(x,y)$ to be a critical point of $F$ it must lie on the parabola $y=-\frac{3}{2} x^2$. So we search for the intersection points of $M_a$ and the parabola, which are all the critical points of $F$ contained in $M_a$, since we want to find $a$ such that there are no intersection points. Substituting the parabola eq. in the defining eq. of $M_a$ we get $$a = \frac{9}{4} x^4-x^3 = x^3(\frac{9}{4}x-1)$$ How do I proceed from here? A simple $a \lt 0$, $a \gt 0$, $a=0$ case analysis doesn't lead to anything, since for $a \lt 0$, there are $x$, namely $0 \lt x \lt \frac{4}{9}$, such that this is true and we can also find $y$ for those $x$. By playing with the plot in Mathematica I found that $a \approx -0.01$ is the turning point. For all $a$ greater than that there are two intersection points and for all $a$ smaller than that there are none. Can somebody show me how this could be extracted from the calculations above? Here is a plot for $a=0.2$ And a plot for $a=-0.005$","I am having a hard time solving the equations to find the $a \in \Bbb R$ for which $$M_a = \left \lbrace {(x,y)\in \mathbb {R}^2} \mid {y^2= x^3 + a}\right \rbrace$$ is a submanifold of $\Bbb R^2$. I defined $F: \Bbb R^2 \to \Bbb R$ with $F(x,y)=y^2-x^3-a$ such that $M_a = F^{-1}(0)$ and $F$ is smooth. By the preimage theorem $M_a$ is a $1$ dimensional submanifold if $M_a$ doesn't contain any critical values of $F$. To compute the critical values of $F$, set $$D_{(x,y)}F = \begin{bmatrix} -3x^2 & 2y \end{bmatrix} = 0$$ and for $(x,y)$ to be a critical point of $F$ it must lie on the parabola $y=-\frac{3}{2} x^2$. So we search for the intersection points of $M_a$ and the parabola, which are all the critical points of $F$ contained in $M_a$, since we want to find $a$ such that there are no intersection points. Substituting the parabola eq. in the defining eq. of $M_a$ we get $$a = \frac{9}{4} x^4-x^3 = x^3(\frac{9}{4}x-1)$$ How do I proceed from here? A simple $a \lt 0$, $a \gt 0$, $a=0$ case analysis doesn't lead to anything, since for $a \lt 0$, there are $x$, namely $0 \lt x \lt \frac{4}{9}$, such that this is true and we can also find $y$ for those $x$. By playing with the plot in Mathematica I found that $a \approx -0.01$ is the turning point. For all $a$ greater than that there are two intersection points and for all $a$ smaller than that there are none. Can somebody show me how this could be extracted from the calculations above? Here is a plot for $a=0.2$ And a plot for $a=-0.005$",,['differential-geometry']
91,How do we define $D^2$ formally in differential geometry?,How do we define  formally in differential geometry?,D^2,"In this question @barto explains the definition of $Df|_p$ in differential geometry. This question is about the formal definition of $D^2f|_p$, given a function $f:M\to \mathbb R$ for some manifold $M$. Given that $Df_p$ gives us a mapping from the tangent space of $f$ at $p\in M$ to $\mathbb R$, we can state that $D$ is a map $(M\to \mathbb R)\times M \to (T(M)\to \mathbb R)$, where $T(M)$ is the union of tangent spaces on $M$ at all points. (I am not sure if the way I defined this is correct now.) My question is, is $D^2$ defined rigorously as an operator? By $D^2$ I mean the operator that takes $f:M\to\mathbb R$, $p\in M$, such that $D^2f|_p=D(Df|_p)$. Basically, $D^2$ should map $f$ and $p$ to a linear operator that is represented by the Hessian matrix .","In this question @barto explains the definition of $Df|_p$ in differential geometry. This question is about the formal definition of $D^2f|_p$, given a function $f:M\to \mathbb R$ for some manifold $M$. Given that $Df_p$ gives us a mapping from the tangent space of $f$ at $p\in M$ to $\mathbb R$, we can state that $D$ is a map $(M\to \mathbb R)\times M \to (T(M)\to \mathbb R)$, where $T(M)$ is the union of tangent spaces on $M$ at all points. (I am not sure if the way I defined this is correct now.) My question is, is $D^2$ defined rigorously as an operator? By $D^2$ I mean the operator that takes $f:M\to\mathbb R$, $p\in M$, such that $D^2f|_p=D(Df|_p)$. Basically, $D^2$ should map $f$ and $p$ to a linear operator that is represented by the Hessian matrix .",,"['differential-geometry', 'notation', 'hessian-matrix']"
92,Morse lemma via Moser's trick,Morse lemma via Moser's trick,,"In Abraham and Marsden's Foundations of Mechanics , they prove Morse lemma via Moser's trick. They are able to reduce the proof so that it suffices to find a smooth family of vector fields $Z_t$ such that $$\iota_{Z_t}\omega_t+(f-g)=0, \quad Z_t(0)=0,$$ where $f$ is the function under consideration in Morse lemma statement, $g(x)=\frac{1}{2}D^2f(0)(x,x)$ and $\omega_t=tdf+(1-t)dg$. Now, the book says that it is ""easy to see that $Z_t$ exists near $0$ by the nondegeneracy hypothesis"", which I assume is referring to the non-degeneracy of the hessian $D^2f(0)$. However, I can't see how it is easy to see that. For instance, $\omega_t(0)$ is $0$, so $Z_t(0)$ could be whatever we want and I see no way to easily reconcile this*. Furthermore, $\omega_t$ is a $1$-form and we want a $Z_t$ such that $\omega_t(Z_t)$ is some number. This gives a lot of redundancy for $Z_t$. My question is: How to build such $Z_t$? *This is quite different from the usage of Moser's trick on the symplectic situations (Darboux's theorem, say), where $\omega_t$, when constant on a region of interest (like the origin in this case), is usually non-degenerate (not to mention being a $2$-form, which is relevant for the next thing I am about to say) For those not familiar, Morse lemma is as follows. Let $f:M \to \mathbb{R}$ be such that $\mathrm{Hess}_p$ is non-degenerate and $f(p)=0$. Then there exists a chart $\phi$ around $p$ such that in local coordinates   $$f(x)=D^2f(0)(x,x).$$","In Abraham and Marsden's Foundations of Mechanics , they prove Morse lemma via Moser's trick. They are able to reduce the proof so that it suffices to find a smooth family of vector fields $Z_t$ such that $$\iota_{Z_t}\omega_t+(f-g)=0, \quad Z_t(0)=0,$$ where $f$ is the function under consideration in Morse lemma statement, $g(x)=\frac{1}{2}D^2f(0)(x,x)$ and $\omega_t=tdf+(1-t)dg$. Now, the book says that it is ""easy to see that $Z_t$ exists near $0$ by the nondegeneracy hypothesis"", which I assume is referring to the non-degeneracy of the hessian $D^2f(0)$. However, I can't see how it is easy to see that. For instance, $\omega_t(0)$ is $0$, so $Z_t(0)$ could be whatever we want and I see no way to easily reconcile this*. Furthermore, $\omega_t$ is a $1$-form and we want a $Z_t$ such that $\omega_t(Z_t)$ is some number. This gives a lot of redundancy for $Z_t$. My question is: How to build such $Z_t$? *This is quite different from the usage of Moser's trick on the symplectic situations (Darboux's theorem, say), where $\omega_t$, when constant on a region of interest (like the origin in this case), is usually non-degenerate (not to mention being a $2$-form, which is relevant for the next thing I am about to say) For those not familiar, Morse lemma is as follows. Let $f:M \to \mathbb{R}$ be such that $\mathrm{Hess}_p$ is non-degenerate and $f(p)=0$. Then there exists a chart $\phi$ around $p$ such that in local coordinates   $$f(x)=D^2f(0)(x,x).$$",,"['differential-geometry', 'differential-topology', 'differential-forms', 'morse-theory']"
93,Vector field of a flow's cotangent lift is Hamiltonian,Vector field of a flow's cotangent lift is Hamiltonian,,"Let $M$ be a smooth manifold, and $X\in \mathfrak{X}(M)$ be a complete vector field. Then for all $t \in \Bbb R$ we have the flow $\Phi_{t,X}\colon M \to M$ of $X$. We can consider the cotangent lift $\widehat{\Phi_{t,X}}\colon T^*M \to T^*M$ of each flow time$^1$. By properties of the flow, we have that $\widehat{\Phi_{t,X}} = \Phi_{t,\hat{X}}$ for some complete vector field $\hat{X} \in\mathfrak{X}(T^*M)$. We consider in $T^*M$ the standard symplectic strutcure $\omega_{\rm can}$. I want to check that $\hat{X}$ is Hamiltonian, and find a Hamiltonian function $H\colon T^*M \to \Bbb R$ (i.e., such that $\omega_{\rm can}(\hat{X},\cdot) = {\rm d}H$). Since cotangent lifts are symplectomorphisms, I know that $\hat{X}$ is symplectic, and so locally Hamiltonian. Also: $$\pi\circ \Phi_{t,\hat{X}} = \Phi_{t,X}\circ \pi \implies {\rm d}\pi_\xi(\hat{X}_\xi) = X_{\pi(\xi)}, \qquad \mbox{for all }\xi \in T^*M.$$The only map $T^*M \to \Bbb R$ I can immediately think of is $\alpha(\hat{X})$, where $\alpha$ is the tautological $1$-form, but this doesn't seem to work and I don't know what else to do here. Maybe treat the situation with brute force in coordinates? Please help. If $f\colon M\to N$ is a diffeomorphism, the cotangent lift is $\widehat{f}\colon T^*M \to T^*N$, given by $\widehat{f}(\xi) = \xi \circ ({\rm d}f_{\pi(\xi)})^{-1}$, where $\pi\colon T^*M \to M$ is the canonical projection.","Let $M$ be a smooth manifold, and $X\in \mathfrak{X}(M)$ be a complete vector field. Then for all $t \in \Bbb R$ we have the flow $\Phi_{t,X}\colon M \to M$ of $X$. We can consider the cotangent lift $\widehat{\Phi_{t,X}}\colon T^*M \to T^*M$ of each flow time$^1$. By properties of the flow, we have that $\widehat{\Phi_{t,X}} = \Phi_{t,\hat{X}}$ for some complete vector field $\hat{X} \in\mathfrak{X}(T^*M)$. We consider in $T^*M$ the standard symplectic strutcure $\omega_{\rm can}$. I want to check that $\hat{X}$ is Hamiltonian, and find a Hamiltonian function $H\colon T^*M \to \Bbb R$ (i.e., such that $\omega_{\rm can}(\hat{X},\cdot) = {\rm d}H$). Since cotangent lifts are symplectomorphisms, I know that $\hat{X}$ is symplectic, and so locally Hamiltonian. Also: $$\pi\circ \Phi_{t,\hat{X}} = \Phi_{t,X}\circ \pi \implies {\rm d}\pi_\xi(\hat{X}_\xi) = X_{\pi(\xi)}, \qquad \mbox{for all }\xi \in T^*M.$$The only map $T^*M \to \Bbb R$ I can immediately think of is $\alpha(\hat{X})$, where $\alpha$ is the tautological $1$-form, but this doesn't seem to work and I don't know what else to do here. Maybe treat the situation with brute force in coordinates? Please help. If $f\colon M\to N$ is a diffeomorphism, the cotangent lift is $\widehat{f}\colon T^*M \to T^*N$, given by $\widehat{f}(\xi) = \xi \circ ({\rm d}f_{\pi(\xi)})^{-1}$, where $\pi\colon T^*M \to M$ is the canonical projection.",,"['differential-geometry', 'differential-forms', 'symplectic-geometry']"
94,A vector bundle which has an orientation-reversing isomorphism has a subbundle of rank $1$?,A vector bundle which has an orientation-reversing isomorphism has a subbundle of rank ?,1,"Let $E$ be a smooth real vector bundle of even rank, over a smooth manifold $M$. Suppose there exist an orientation-reversing vector bundle isomorphism $\Phi:E \to E$. Is it true that $E$ has a subbundle of rank $1$? (We don't need an orientation on $E$, since for maps from a vector space to itself, the notion of orientation-preserving or reversing is always well-defined, without the need to actually choose an orientation on the space). Here is one approach (which was suggested to me by Amitai Yuval , who also raised this question): We can put a metric on $E$, and take the orthogonal polar factor $Q$ of $\Phi$, which will now be an isometric orientation-reversing isomorphism. So, $Q$ will have at least one non-zero fixed point at each fiber $E_x$ (see below**). My hope is that somehow we can extract a continuously changing family of fixed points along the different fibers (one at each fiber) that will form a subbundle of rank $1$. Of course, there can be problems of multiplicity, so perhaps some perturbation argument is needed. Can this approach work? **Here we use the fact $\text{rank}(E)$ is even: at each fiber $Q_x$ is essentially an orthogonal matrix with negative determinant. Since its complex eigenvalues comes in conjugate pairs, and the determinant is real negative, there must be some real negative eigenvalues. Since $\det Q_x<0$ the number of the negative eigenvalues must be odd. Since $\dim E_x$ is even, we conclude there must be a positive eigenvalue, which must be $1$, since $Q_x$ is orthogonal. Motivation: I am trying to find out which real vector bundles admit orientation-reversing isomorphisms. Of course, every bundle of odd rank admits one: the map $x \to -x$. Now suppose the rank is even . If $E$ admits a subbundle $F$ of rank $1$, we can define an orientation-reversing isomorphism as follows: $$\Phi|_F=\text{Id}_F,\Phi|_{{F}^{\perp}}=-\text{Id}|_{{F}^{\perp}}$$ where ${F}^{\perp}$ is some complement of $F$. My question is if this condition (""there exist a subbundle of rank $1$"") is necessary.","Let $E$ be a smooth real vector bundle of even rank, over a smooth manifold $M$. Suppose there exist an orientation-reversing vector bundle isomorphism $\Phi:E \to E$. Is it true that $E$ has a subbundle of rank $1$? (We don't need an orientation on $E$, since for maps from a vector space to itself, the notion of orientation-preserving or reversing is always well-defined, without the need to actually choose an orientation on the space). Here is one approach (which was suggested to me by Amitai Yuval , who also raised this question): We can put a metric on $E$, and take the orthogonal polar factor $Q$ of $\Phi$, which will now be an isometric orientation-reversing isomorphism. So, $Q$ will have at least one non-zero fixed point at each fiber $E_x$ (see below**). My hope is that somehow we can extract a continuously changing family of fixed points along the different fibers (one at each fiber) that will form a subbundle of rank $1$. Of course, there can be problems of multiplicity, so perhaps some perturbation argument is needed. Can this approach work? **Here we use the fact $\text{rank}(E)$ is even: at each fiber $Q_x$ is essentially an orthogonal matrix with negative determinant. Since its complex eigenvalues comes in conjugate pairs, and the determinant is real negative, there must be some real negative eigenvalues. Since $\det Q_x<0$ the number of the negative eigenvalues must be odd. Since $\dim E_x$ is even, we conclude there must be a positive eigenvalue, which must be $1$, since $Q_x$ is orthogonal. Motivation: I am trying to find out which real vector bundles admit orientation-reversing isomorphisms. Of course, every bundle of odd rank admits one: the map $x \to -x$. Now suppose the rank is even . If $E$ admits a subbundle $F$ of rank $1$, we can define an orientation-reversing isomorphism as follows: $$\Phi|_F=\text{Id}_F,\Phi|_{{F}^{\perp}}=-\text{Id}|_{{F}^{\perp}}$$ where ${F}^{\perp}$ is some complement of $F$. My question is if this condition (""there exist a subbundle of rank $1$"") is necessary.",,"['differential-geometry', 'differential-topology', 'vector-bundles', 'orientation']"
95,identity for the second fundamental form for cones,identity for the second fundamental form for cones,,"I'm trying to understand the following: Let $C$ be a $n$ dimensional minimal cone in $\mathbb R^{n+1}$ with vertex at $0$ with second fundamental form $h_{ij} = h_{ji}$. (Minimal implies $\sum_i h_{ii} = 0$) Also, let $h_{ijk}$ be the components of the one-form definied by $$\sum_k h_{ijk} \omega_k = \mathrm d h_{ij} - \sum_k h_{ik} \, \omega_{kj} - \sum_k h_{jk} \, \omega_{ki},$$ where all sums are from $1$ to $n$, $\{\omega_1,\cdots,\omega_n\}$ are the dual frames to $\{e_1,\cdots,e_n\}$ and $\{\omega_{ij}\}_{1\leq i,j \leq n}$ are the connection one-forms. Choose a frame $\{e_1,\cdots,e_n\}$ such that $h_{ij}$ is diagonal and $e_n$ is in radial direction (ie. $e_n = x/|x|$). Then we have $h_{ij} = h_{nn} = 0$, $i \neq j$ and $h_{ijn} = - |x|^{-1} \, h_{ij}$, $i,j = 1,\cdots,n$ Now I understand that $h_{nn} = 0$ since in the radial direction, the cone just looks like a straight line. My Question: How do I see the second identity? $$h_{ijn} = - |x|^{-1} \, h_{ij}, \quad i,j = 1,\cdots,n$$ EDIT So my idea was to look at this  \begin{align} h_{ijn} & = (\mathrm d h_{ij})(e_n) - \sum_k h_{ik} \, \omega_{kj}(e_n) - \sum_k h_{jk} \, \omega_{ki}(e_n) \\ % & = \partial_n h_{ii} \, \delta_{ij} - \Gamma^i_{nj} \, h_{ii} - \Gamma^j_{ni} \, h_{jj} \end{align} Any suggestions?","I'm trying to understand the following: Let $C$ be a $n$ dimensional minimal cone in $\mathbb R^{n+1}$ with vertex at $0$ with second fundamental form $h_{ij} = h_{ji}$. (Minimal implies $\sum_i h_{ii} = 0$) Also, let $h_{ijk}$ be the components of the one-form definied by $$\sum_k h_{ijk} \omega_k = \mathrm d h_{ij} - \sum_k h_{ik} \, \omega_{kj} - \sum_k h_{jk} \, \omega_{ki},$$ where all sums are from $1$ to $n$, $\{\omega_1,\cdots,\omega_n\}$ are the dual frames to $\{e_1,\cdots,e_n\}$ and $\{\omega_{ij}\}_{1\leq i,j \leq n}$ are the connection one-forms. Choose a frame $\{e_1,\cdots,e_n\}$ such that $h_{ij}$ is diagonal and $e_n$ is in radial direction (ie. $e_n = x/|x|$). Then we have $h_{ij} = h_{nn} = 0$, $i \neq j$ and $h_{ijn} = - |x|^{-1} \, h_{ij}$, $i,j = 1,\cdots,n$ Now I understand that $h_{nn} = 0$ since in the radial direction, the cone just looks like a straight line. My Question: How do I see the second identity? $$h_{ijn} = - |x|^{-1} \, h_{ij}, \quad i,j = 1,\cdots,n$$ EDIT So my idea was to look at this  \begin{align} h_{ijn} & = (\mathrm d h_{ij})(e_n) - \sum_k h_{ik} \, \omega_{kj}(e_n) - \sum_k h_{jk} \, \omega_{ki}(e_n) \\ % & = \partial_n h_{ii} \, \delta_{ij} - \Gamma^i_{nj} \, h_{ii} - \Gamma^j_{ni} \, h_{jj} \end{align} Any suggestions?",,"['differential-geometry', 'riemannian-geometry']"
96,Uniqueness for antipodal points of maximum distance on closed convex surface,Uniqueness for antipodal points of maximum distance on closed convex surface,,"Let $S\subset \mathbb{R}^3$ be a closed convex surface and let $p,q\in S$ be points such that $d(p,q)=\operatorname{diam}(S)$ where $\operatorname{diam}(S)$ is the diameter of $S$ with respect to the intrinsic distance $d$ of $S$. Does $d(p,q')=\operatorname{diam}(S)$ imply $q=q'$?","Let $S\subset \mathbb{R}^3$ be a closed convex surface and let $p,q\in S$ be points such that $d(p,q)=\operatorname{diam}(S)$ where $\operatorname{diam}(S)$ is the diameter of $S$ with respect to the intrinsic distance $d$ of $S$. Does $d(p,q')=\operatorname{diam}(S)$ imply $q=q'$?",,"['differential-geometry', 'riemannian-geometry', 'surfaces']"
97,On the Whitney-Graustein theorem and the $h$-principle.,On the Whitney-Graustein theorem and the -principle.,h,"If you are in a hurry and this question still has caught your interest, please jump directly to the last proposition, where my question lies. Throughout this question I am going to identity $\mathbb{S}^1$ and $[0,1]/\partial[0,1]$. Therefore, when I will talk about mappings from $\mathbb{S}^1$ to $\mathbb{R}^2$, I will consider maps $f\colon[0,1]\rightarrow\mathbb{R}^2$ such that $f(0)=f(1)$. Let $I(\mathbb{S}^1,\mathbb{R}^2)$ be the set of immersions of $\mathbb{S}^1$ into $\mathbb{R}^2$, that is the set of $C^1$-mappings from $\mathbb{S}^1$ to $\mathbb{R}^2$ such that their derivatives do not vanish. My goal is to prove the well-known: Theorem. (Whitney-Graustein) The turning number gives a bijection from $\pi_0(I(\mathbb{S}^1,\mathbb{R}^2))$ to $\mathbb{Z}$. For sake of clarity, by now let $X:=C^0(\mathbb{S}^1,\mathbb{R}^2\setminus\{(0,0)\})$. Inspired by the Gromov's $h$-principle , I introduced the following map:  $$J\colon\left\{\begin{array}{ccc}I(\mathbb{S}^1,\mathbb{R}^2)&\rightarrow&X\\f&\mapsto&f'\end{array}\right..$$ I claim that one has the following: Theorem. The map $J$ induces a well-defined bijection $$\pi_0(J)\colon\left\{\begin{array}{ccc}\pi_0(I(\mathbb{S}^1,\mathbb{R}^2))\rightarrow\pi_0(X)\\ [f]_0\mapsto [f']_0\end{array}\right..$$ I have already prove the well-definedness and the following: Proposition. Let $f\in X$, there exists $g\in I(\mathbb{S}^1,\mathbb{R}^2)$ and $H\colon\mathbb{S}^1\times[0,1]\overset{C^0}{\rightarrow}\mathbb{R}^2\setminus\{(0,0)\}$ such that $H(\cdot,0)=f$ and $H(\cdot,1)=g'$. Proof. On request. $\Box$ Which has direct corollary $\pi_0(J)$ being surjective. Hence, I am left to establish the following: Proposition. Let $g_1,g_2\in I(\mathbb{S}^1,\mathbb{R}^2)$ such that there exists $H\colon\mathbb{S}^1\times [0,1]\overset{C^0}\rightarrow\mathbb{R}^2\setminus\{(0,0)\}$ such that $H(\cdot,0)={g_1}'$ and $H(\cdot,1)={g_2}'$. Then, there exists $F\colon\mathbb{S}^1\times [0,1]\overset{C^1}{\rightarrow}\mathbb{R}^2$ such that $F(\cdot,0)=g_1$, $F(\cdot,1)=g_2$ and for all $t\in [0,1],F(\cdot,t)\in I(\mathbb{S}^1,\mathbb{R}^2)$. Proof. My idea is to integrate the homotopy $H$, that is introducing: $$F(x,t):=\int_0^xH(u,t)\,\mathrm{d}u-x\int_0^1H(u,t)\,\mathrm{d}u.$$ The removed corrective term is here to ensure that for all $t\in [0,1]$, $F(0,t)=F(1,t)$, that is for the well-definedness of $F(\cdot,t)$ on $\mathbb{S}^1$. Notice that one has $F(\cdot,0)=g_1-g_1(0)$ and $F(\cdot,1)=g_2-g_2(0)$. Therefore, if for all $t\in [0,1]$, $F(\cdot,t)\in I(\mathbb{S}^1,\mathbb{R}^2)$, I am almost done. However, it is not clear and wrong in all generality, that the following quantity is nonzero: $$\frac{\mathrm{d}}{\mathrm{d}x}F(x,t)=H(x,t)-\int_{0}^1H(u,t)\mathrm{d}u.$$ That is where I am stuck. $\Box$ Question. If $H(x,\cdot)$ is non-constant and belongs to $\mathbb{S}^1$, I am done. Indeed, $\displaystyle\int_0^1H(u,t)\mathrm{d}u$ will lie in the interior of the unit disk. However, it is not clear to me that I can boil down my problem to this case and doing a naive radial on $H(x,\cdot)$ homotopy does not seem to help in anything. If the latter proposition is true, I am done with the injectivity of $\pi_0(J)$ and with the Whitney-Graustein theorem. Indeed, I will have the following commutative diagramm, where all arrows are bijections: $$\require{AMScd}\begin{CD} \pi_0(I(\mathbb{S}^1,\mathbb{R})) @>\textrm{turning number}>> \mathbb{Z}\\ @VV\pi_0(J)V @AA\deg A\\ \pi_0(X) @>\textrm{str. def. retract}>> \pi_1(\mathbb{S}^1)\end{CD}$$ Any enlightenment will be greatly appreciated. If my approach proving the last proposition is plain wrong, could you provide me some other thoughts to manage my way toward the proof?","If you are in a hurry and this question still has caught your interest, please jump directly to the last proposition, where my question lies. Throughout this question I am going to identity $\mathbb{S}^1$ and $[0,1]/\partial[0,1]$. Therefore, when I will talk about mappings from $\mathbb{S}^1$ to $\mathbb{R}^2$, I will consider maps $f\colon[0,1]\rightarrow\mathbb{R}^2$ such that $f(0)=f(1)$. Let $I(\mathbb{S}^1,\mathbb{R}^2)$ be the set of immersions of $\mathbb{S}^1$ into $\mathbb{R}^2$, that is the set of $C^1$-mappings from $\mathbb{S}^1$ to $\mathbb{R}^2$ such that their derivatives do not vanish. My goal is to prove the well-known: Theorem. (Whitney-Graustein) The turning number gives a bijection from $\pi_0(I(\mathbb{S}^1,\mathbb{R}^2))$ to $\mathbb{Z}$. For sake of clarity, by now let $X:=C^0(\mathbb{S}^1,\mathbb{R}^2\setminus\{(0,0)\})$. Inspired by the Gromov's $h$-principle , I introduced the following map:  $$J\colon\left\{\begin{array}{ccc}I(\mathbb{S}^1,\mathbb{R}^2)&\rightarrow&X\\f&\mapsto&f'\end{array}\right..$$ I claim that one has the following: Theorem. The map $J$ induces a well-defined bijection $$\pi_0(J)\colon\left\{\begin{array}{ccc}\pi_0(I(\mathbb{S}^1,\mathbb{R}^2))\rightarrow\pi_0(X)\\ [f]_0\mapsto [f']_0\end{array}\right..$$ I have already prove the well-definedness and the following: Proposition. Let $f\in X$, there exists $g\in I(\mathbb{S}^1,\mathbb{R}^2)$ and $H\colon\mathbb{S}^1\times[0,1]\overset{C^0}{\rightarrow}\mathbb{R}^2\setminus\{(0,0)\}$ such that $H(\cdot,0)=f$ and $H(\cdot,1)=g'$. Proof. On request. $\Box$ Which has direct corollary $\pi_0(J)$ being surjective. Hence, I am left to establish the following: Proposition. Let $g_1,g_2\in I(\mathbb{S}^1,\mathbb{R}^2)$ such that there exists $H\colon\mathbb{S}^1\times [0,1]\overset{C^0}\rightarrow\mathbb{R}^2\setminus\{(0,0)\}$ such that $H(\cdot,0)={g_1}'$ and $H(\cdot,1)={g_2}'$. Then, there exists $F\colon\mathbb{S}^1\times [0,1]\overset{C^1}{\rightarrow}\mathbb{R}^2$ such that $F(\cdot,0)=g_1$, $F(\cdot,1)=g_2$ and for all $t\in [0,1],F(\cdot,t)\in I(\mathbb{S}^1,\mathbb{R}^2)$. Proof. My idea is to integrate the homotopy $H$, that is introducing: $$F(x,t):=\int_0^xH(u,t)\,\mathrm{d}u-x\int_0^1H(u,t)\,\mathrm{d}u.$$ The removed corrective term is here to ensure that for all $t\in [0,1]$, $F(0,t)=F(1,t)$, that is for the well-definedness of $F(\cdot,t)$ on $\mathbb{S}^1$. Notice that one has $F(\cdot,0)=g_1-g_1(0)$ and $F(\cdot,1)=g_2-g_2(0)$. Therefore, if for all $t\in [0,1]$, $F(\cdot,t)\in I(\mathbb{S}^1,\mathbb{R}^2)$, I am almost done. However, it is not clear and wrong in all generality, that the following quantity is nonzero: $$\frac{\mathrm{d}}{\mathrm{d}x}F(x,t)=H(x,t)-\int_{0}^1H(u,t)\mathrm{d}u.$$ That is where I am stuck. $\Box$ Question. If $H(x,\cdot)$ is non-constant and belongs to $\mathbb{S}^1$, I am done. Indeed, $\displaystyle\int_0^1H(u,t)\mathrm{d}u$ will lie in the interior of the unit disk. However, it is not clear to me that I can boil down my problem to this case and doing a naive radial on $H(x,\cdot)$ homotopy does not seem to help in anything. If the latter proposition is true, I am done with the injectivity of $\pi_0(J)$ and with the Whitney-Graustein theorem. Indeed, I will have the following commutative diagramm, where all arrows are bijections: $$\require{AMScd}\begin{CD} \pi_0(I(\mathbb{S}^1,\mathbb{R})) @>\textrm{turning number}>> \mathbb{Z}\\ @VV\pi_0(J)V @AA\deg A\\ \pi_0(X) @>\textrm{str. def. retract}>> \pi_1(\mathbb{S}^1)\end{CD}$$ Any enlightenment will be greatly appreciated. If my approach proving the last proposition is plain wrong, could you provide me some other thoughts to manage my way toward the proof?",,"['differential-geometry', 'homotopy-theory', 'h-principle']"
98,Something wrong with this do carmo exercise (1.3.3)?,Something wrong with this do carmo exercise (1.3.3)?,,"I think I have found an unreported errata to this problem. Here is my attempt to solve the problem. Differential Geometry of Curves and Surfaces - Chapter 1 Section 3 Exercise 3 And here is the errata I can found online. In particular, I believe the errata should include $ \alpha'(t) = (0, 2a) $ when $ t \to \pm \infty $, not $ \alpha'(t) = (2a, 0) $ Can anyone confirm my finding? What should I do to get this included in the errata?","I think I have found an unreported errata to this problem. Here is my attempt to solve the problem. Differential Geometry of Curves and Surfaces - Chapter 1 Section 3 Exercise 3 And here is the errata I can found online. In particular, I believe the errata should include $ \alpha'(t) = (0, 2a) $ when $ t \to \pm \infty $, not $ \alpha'(t) = (2a, 0) $ Can anyone confirm my finding? What should I do to get this included in the errata?",,['differential-geometry']
99,Diffeomorphism preserves open set?,Diffeomorphism preserves open set?,,"This question might be elementary, but I am a little confused. Does diffeomorphism preserve open sets? Suppose I have two coordinate charts $(U,\varphi)$, $(V,\psi)$ and atlas $\mathcal{A}=\{(U_{\alpha},\varphi_{\alpha})\}$ such that the two charts are compatible with $\mathcal{A}$. Then clearly $\varphi_{\alpha}(U\cap U_{\alpha})$ and $\varphi_{\alpha}(V\cap U_{\alpha})$ are open. How can I conclude then that $\varphi_{\alpha}(U\cap V\cap U_{\alpha})$ is also open? I know that $U\cap V\cap U_{\alpha}$ is open, so is the openness preserved by $\varphi_{\alpha}$?","This question might be elementary, but I am a little confused. Does diffeomorphism preserve open sets? Suppose I have two coordinate charts $(U,\varphi)$, $(V,\psi)$ and atlas $\mathcal{A}=\{(U_{\alpha},\varphi_{\alpha})\}$ such that the two charts are compatible with $\mathcal{A}$. Then clearly $\varphi_{\alpha}(U\cap U_{\alpha})$ and $\varphi_{\alpha}(V\cap U_{\alpha})$ are open. How can I conclude then that $\varphi_{\alpha}(U\cap V\cap U_{\alpha})$ is also open? I know that $U\cap V\cap U_{\alpha}$ is open, so is the openness preserved by $\varphi_{\alpha}$?",,"['differential-geometry', 'smooth-manifolds']"
