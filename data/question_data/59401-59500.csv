,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Simplification of a sum,Simplification of a sum,,Any ideas on how to approximate and/or simplify this crazy-looking sum will be massively appreciated) $$\frac{1}{\mu}\sum_{j=0}^{\frac{\lambda}{2}} \left(\frac{1}{2}+2\left(\frac{k}{n}\right)^2\right)^j\binom{\frac{\lambda}{2}}{j}\sum_{m=1}^{\mu} \left(\frac{m^2(m+2(\mu-m))^2}{\mu^4}\right)^j\left(1-\frac{m^2(m+2(\mu-m))^2}{\mu^4}\right)^{\frac{\lambda}{2}-j}$$,Any ideas on how to approximate and/or simplify this crazy-looking sum will be massively appreciated) $$\frac{1}{\mu}\sum_{j=0}^{\frac{\lambda}{2}} \left(\frac{1}{2}+2\left(\frac{k}{n}\right)^2\right)^j\binom{\frac{\lambda}{2}}{j}\sum_{m=1}^{\mu} \left(\frac{m^2(m+2(\mu-m))^2}{\mu^4}\right)^j\left(1-\frac{m^2(m+2(\mu-m))^2}{\mu^4}\right)^{\frac{\lambda}{2}-j}$$,,"['algebra-precalculus', 'sequences-and-series', 'binomial-coefficients']"
1,A lower bound for finite integer sequence with $a_n > (a_{n-1} + a_{n+1})/2$,A lower bound for finite integer sequence with,a_n > (a_{n-1} + a_{n+1})/2,"Question Cristiano Ronaldo writes a sequence $a_1$ , $a_2$$,...,$ $a_{100}$ of integers in which the first and last terms are equal to $0$ . Except for the first and last terms, each term $a_i$ is larger than the average of its neighbours $a_{i−1}$ and $a_{i+1}$ . What is the smallest possible value for the term $a_{19}$ Initial findings Since both ends of the series, i.e., $a_1, a_{100}$ are $0$ , I have a feeling that the series is symmetrical. The series increases gradually and peaks at the middle. Also, I have observed that $a_n > \min ({a_{n-1}, {a_{n+1}}})$ I also have a feeling that the first fifty terms obey this formula, $a_n > \frac {n-1}{n}{a_{n+1}}$ And that's pretty much all I can come up with. From https://gonitzoggo.com/problem/586","Question Cristiano Ronaldo writes a sequence , of integers in which the first and last terms are equal to . Except for the first and last terms, each term is larger than the average of its neighbours and . What is the smallest possible value for the term Initial findings Since both ends of the series, i.e., are , I have a feeling that the series is symmetrical. The series increases gradually and peaks at the middle. Also, I have observed that I also have a feeling that the first fifty terms obey this formula, And that's pretty much all I can come up with. From https://gonitzoggo.com/problem/586","a_1 a_2,..., a_{100} 0 a_i a_{i−1} a_{i+1} a_{19} a_1, a_{100} 0 a_n > \min ({a_{n-1}, {a_{n+1}}}) a_n > \frac {n-1}{n}{a_{n+1}}",['sequences-and-series']
2,Limits of arbitrary polynomials divided by constants greater than 1 raised to the power of n,Limits of arbitrary polynomials divided by constants greater than 1 raised to the power of n,,"Problem statement: Prove that for any $a > 1$ and any polynomial $p(x)$ , we have: \begin{align*} \lim\limits_{n \to \infty} \dfrac{p(n)}{a^n} =0	 \end{align*} Solution: We need to use squeeze theorem and consider this expression as a sequence. The goal to show that: \begin{align*} c_n	\leq \dfrac{p(n)}{a^n} \leq d_n \\ \text{where} \lim\limits_{n \to \infty}c_n =0 \text{ and }\lim\limits_{n \to \infty}d_n =0 \end{align*} For some arbitrary sequences $c_n$ and $d_n$ . consider $p(n)$ having some finite degree $k \in \mathbb{N}$ : \begin{align*} p(n) = b_kn^k + b_{k-1}n^{k-1}+ ... + b_1n+b_0 	 \end{align*} Lemma: For any $a \in (-1,1)$ and $k,n \in \mathbb{N}$ we have: \begin{align*} \lim\limits_{n \to \infty} n^ka^n =0 \end{align*} proof: when $a=0$ , the result is trivial. consider $0<a<1$ . Write: \begin{align*} 	a = \dfrac{1}{\frac{1}{a}} = \frac{1}{1+b}	 \end{align*} Where $\dfrac{1}{a} > 1$ and $b = \dfrac{1}{a} - 1 > 0$ . Using the binomial theorem: \begin{align*} a^n &= \dfrac{1}{(1+b)^n} = \dfrac{1}{1 + nb + C^n_2 b^2+...+C^n_{n-1}b^{n-1} +b^n} \\ n^ka^n &= \dfrac{n^k}{1 + nb + C^n_2 b^2+...+C^n_{n-1}b^{n-1} +b^n}	 \end{align*} WLOG assume $n>k$ hence we have: \begin{align*} 	n^ka^n &= \dfrac{n^k}{1 + nb + C^n_2 b^2+...+C^n_{k+1}b^{k+1}+...+C^n_{n-1}b^{n-1} +b^n}	 \end{align*} Observe that: \begin{align*} 	C^n_{k+1} &= \dfrac{n!}{(n-k -1)!(k+1)!} = \dfrac{n(n-1)(n-2)...(n-k)}{(k+1)!}\\  	\implies \dfrac{n^k}{C^n_{k+1}} &= \dfrac{(k+1)!}{n(1-\frac{1}{n})(1-\frac{2}{n})...(1-\frac{k}{n})} \end{align*} Now because: \begin{align*}  C^n_{k+1}b^{k+1} \leq 	1 + nb + C^n_2 b^2+...+C^n_{k+1}b^{k+1}+...+C^n_{n-1}b^{n-1} +b^n   \end{align*} We have: \begin{align*} 	n^ka^n = \dfrac{n^k}{1 + nb + C^n_2 b^2+...+C^n_{n-1}b^{n-1} +b^n}	\leq \dfrac{n^k}{C^n_{k+1}} = \dfrac{(k+1)!}{n(1-\frac{1}{n})(1-\frac{2}{n})...(1-\frac{k}{n})}\\ 	\lim\limits_{n \to \infty }\dfrac{(k+1)!}{n(1-\frac{1}{n})(1-\frac{2}{n})...(1-\frac{k}{n})} = \dfrac{\lim\limits_{n\to \infty}\frac{(k+1)!}{n}}{\lim\limits_{n\to \infty}(1-\frac{1}{n})\lim\limits_{n\to \infty}(1-\frac{2}{n})...\lim\limits_{n\to \infty}(1-\frac{k}{n})} \end{align*} Because $\lim\limits_{n\to \infty}\dfrac{k}{n} =0$ for any constant $k \in \mathbb{N}$ : \begin{align*} 	 \dfrac{\lim\limits_{n\to \infty}\frac{(k+1)!}{n}}{\lim\limits_{n\to \infty}(1-\frac{1}{n})\lim\limits_{n\to \infty}(1-\frac{2}{n})...\lim\limits_{n\to \infty}(1-\frac{k}{n})} = \dfrac{(k+1)! \times 0}{(1-0)(1-0)...(1-0)} =0 \end{align*} Hence, we can indeed bound $n^ka^n$ above and below. $n^ka^n$ has a trivial lower bound of $0$ , as here we consider $0<a<1$ : \begin{align*} 0\leq 	n^ka^n \leq \dfrac{n^k}{C^n_{k+1}} \\ \lim\limits_{n \to \infty}0 =0 ,\lim\limits_{n \to \infty}\dfrac{n^k}{C^n_{k+1}} =0\\ \implies \lim\limits_{n \to \infty} n^ka^n =0 \text{ by squeeze theorem for } a \in (0,1) \end{align*} For the negative case where $a \in (-1,0)$ consider: \begin{align*} -|n^ka^n| \leq n^ka^n \leq |n^ka^n| = n^k|a^n| =n^k|a|^n \end{align*} Because we have already proved that for $a \in (0,1)$ , $\lim\limits_{n \to \infty}n^ka^n =0$ : \begin{align*} \lim\limits_{n \to \infty} n^k|a|^n &=0 \\ \implies \lim\limits_{n \to \infty}-|n^ka^n| &=0	 \\ \text{by the squeeze theorem, } \lim\limits_{n \to \infty} n^ka^n &=0 \qquad \text{for } \quad a \in (-1,0) \end{align*} Hence, for any $a \in (-1,1)$ and $k \in \mathbb{N}$ we have: \begin{align*} \lim\limits_{n \to \infty} n^ka^n =0 \end{align*} Now back to the main proof. For a polynomial $p(n)$ of some degree $k \in \mathbb{N}$ and some $a >1$ : \begin{align*}  \lim\limits_{n \to \infty}\dfrac{p(n)}{a^n} &=  \lim\limits_{n \to \infty}\dfrac{b_kn^k + b_{k-1}n^{k-1}+ ... + b_1n+b_0}{a^n}\\  &=  \lim\limits_{n \to \infty} \left[ \dfrac{b_k}{a^n}n^k +\dfrac{b_{k-1}}{a^n}n^{k-1} +...+\dfrac{b_1}{a^n}n+\dfrac{b_0}{a^n} \right] \end{align*} consider any index $j \in (0,k)$ \begin{align*} 	b_j\dfrac{1}{a^n}n^j = b_j\left(\dfrac{1}{a}\right)^nn^j \qquad \because a>1 \implies \frac{1}{a} <1 \text{ and } \frac{1}{a} \in (-1,1)\\ 	\implies \text{from the lemma} \lim\limits_{n \to \infty}  b_j\left(\dfrac{1}{a}\right)^nn^j = \lim\limits_{n \to \infty}b_j \lim\limits_{n \to \infty} \left(\dfrac{1}{a}\right)^nn^j = \lim\limits_{n \to \infty}b_j \times 0 =0 \end{align*} Hence, \begin{align*} 	\lim\limits_{n \to \infty} \left[ \dfrac{b_k}{a^n}n^k +\dfrac{b_{k-1}}{a^n}n^{k-1} +...+\dfrac{b_1}{a^n}n+\dfrac{b_0}{a^n} \right] &=0+0+...+0+0\\ 	\lim\limits_{n \to \infty}\dfrac{p(n)}{a^n} &=0 \end{align*} Queries: Is this a valid proof? Are there more elegent ways to prove this, specifically using the properties of limits, sequences and/or polynomials? PS: This is not a homework question","Problem statement: Prove that for any and any polynomial , we have: Solution: We need to use squeeze theorem and consider this expression as a sequence. The goal to show that: For some arbitrary sequences and . consider having some finite degree : Lemma: For any and we have: proof: when , the result is trivial. consider . Write: Where and . Using the binomial theorem: WLOG assume hence we have: Observe that: Now because: We have: Because for any constant : Hence, we can indeed bound above and below. has a trivial lower bound of , as here we consider : For the negative case where consider: Because we have already proved that for , : Hence, for any and we have: Now back to the main proof. For a polynomial of some degree and some : consider any index Hence, Queries: Is this a valid proof? Are there more elegent ways to prove this, specifically using the properties of limits, sequences and/or polynomials? PS: This is not a homework question","a > 1 p(x) \begin{align*}
\lim\limits_{n \to \infty} \dfrac{p(n)}{a^n} =0	
\end{align*} \begin{align*}
c_n	\leq \dfrac{p(n)}{a^n} \leq d_n \\
\text{where} \lim\limits_{n \to \infty}c_n =0 \text{ and }\lim\limits_{n \to \infty}d_n =0
\end{align*} c_n d_n p(n) k \in \mathbb{N} \begin{align*}
p(n) = b_kn^k + b_{k-1}n^{k-1}+ ... + b_1n+b_0 	
\end{align*} a \in (-1,1) k,n \in \mathbb{N} \begin{align*}
\lim\limits_{n \to \infty} n^ka^n =0
\end{align*} a=0 0<a<1 \begin{align*}
	a = \dfrac{1}{\frac{1}{a}} = \frac{1}{1+b}	
\end{align*} \dfrac{1}{a} > 1 b = \dfrac{1}{a} - 1 > 0 \begin{align*}
a^n &= \dfrac{1}{(1+b)^n} = \dfrac{1}{1 + nb + C^n_2 b^2+...+C^n_{n-1}b^{n-1} +b^n} \\
n^ka^n &= \dfrac{n^k}{1 + nb + C^n_2 b^2+...+C^n_{n-1}b^{n-1} +b^n}	
\end{align*} n>k \begin{align*}
	n^ka^n &= \dfrac{n^k}{1 + nb + C^n_2 b^2+...+C^n_{k+1}b^{k+1}+...+C^n_{n-1}b^{n-1} +b^n}	
\end{align*} \begin{align*}
	C^n_{k+1} &= \dfrac{n!}{(n-k -1)!(k+1)!} = \dfrac{n(n-1)(n-2)...(n-k)}{(k+1)!}\\ 
	\implies \dfrac{n^k}{C^n_{k+1}} &= \dfrac{(k+1)!}{n(1-\frac{1}{n})(1-\frac{2}{n})...(1-\frac{k}{n})}
\end{align*} \begin{align*}
 C^n_{k+1}b^{k+1} \leq 	1 + nb + C^n_2 b^2+...+C^n_{k+1}b^{k+1}+...+C^n_{n-1}b^{n-1} +b^n 
 \end{align*} \begin{align*}
	n^ka^n = \dfrac{n^k}{1 + nb + C^n_2 b^2+...+C^n_{n-1}b^{n-1} +b^n}	\leq \dfrac{n^k}{C^n_{k+1}} = \dfrac{(k+1)!}{n(1-\frac{1}{n})(1-\frac{2}{n})...(1-\frac{k}{n})}\\
	\lim\limits_{n \to \infty }\dfrac{(k+1)!}{n(1-\frac{1}{n})(1-\frac{2}{n})...(1-\frac{k}{n})} = \dfrac{\lim\limits_{n\to \infty}\frac{(k+1)!}{n}}{\lim\limits_{n\to \infty}(1-\frac{1}{n})\lim\limits_{n\to \infty}(1-\frac{2}{n})...\lim\limits_{n\to \infty}(1-\frac{k}{n})}
\end{align*} \lim\limits_{n\to \infty}\dfrac{k}{n} =0 k \in \mathbb{N} \begin{align*}
	 \dfrac{\lim\limits_{n\to \infty}\frac{(k+1)!}{n}}{\lim\limits_{n\to \infty}(1-\frac{1}{n})\lim\limits_{n\to \infty}(1-\frac{2}{n})...\lim\limits_{n\to \infty}(1-\frac{k}{n})} = \dfrac{(k+1)! \times 0}{(1-0)(1-0)...(1-0)} =0
\end{align*} n^ka^n n^ka^n 0 0<a<1 \begin{align*}
0\leq 	n^ka^n \leq \dfrac{n^k}{C^n_{k+1}} \\
\lim\limits_{n \to \infty}0 =0 ,\lim\limits_{n \to \infty}\dfrac{n^k}{C^n_{k+1}} =0\\
\implies \lim\limits_{n \to \infty} n^ka^n =0 \text{ by squeeze theorem for } a \in (0,1)
\end{align*} a \in (-1,0) \begin{align*}
-|n^ka^n| \leq n^ka^n \leq |n^ka^n| = n^k|a^n| =n^k|a|^n
\end{align*} a \in (0,1) \lim\limits_{n \to \infty}n^ka^n =0 \begin{align*}
\lim\limits_{n \to \infty} n^k|a|^n &=0 \\
\implies \lim\limits_{n \to \infty}-|n^ka^n| &=0	 \\
\text{by the squeeze theorem, } \lim\limits_{n \to \infty} n^ka^n &=0 \qquad \text{for } \quad a \in (-1,0)
\end{align*} a \in (-1,1) k \in \mathbb{N} \begin{align*}
\lim\limits_{n \to \infty} n^ka^n =0
\end{align*} p(n) k \in \mathbb{N} a >1 \begin{align*}
 \lim\limits_{n \to \infty}\dfrac{p(n)}{a^n} &=  \lim\limits_{n \to \infty}\dfrac{b_kn^k + b_{k-1}n^{k-1}+ ... + b_1n+b_0}{a^n}\\
 &=  \lim\limits_{n \to \infty} \left[ \dfrac{b_k}{a^n}n^k +\dfrac{b_{k-1}}{a^n}n^{k-1} +...+\dfrac{b_1}{a^n}n+\dfrac{b_0}{a^n} \right]
\end{align*} j \in (0,k) \begin{align*}
	b_j\dfrac{1}{a^n}n^j = b_j\left(\dfrac{1}{a}\right)^nn^j \qquad \because a>1 \implies \frac{1}{a} <1 \text{ and } \frac{1}{a} \in (-1,1)\\
	\implies \text{from the lemma} \lim\limits_{n \to \infty}  b_j\left(\dfrac{1}{a}\right)^nn^j = \lim\limits_{n \to \infty}b_j \lim\limits_{n \to \infty} \left(\dfrac{1}{a}\right)^nn^j = \lim\limits_{n \to \infty}b_j \times 0 =0
\end{align*} \begin{align*}
	\lim\limits_{n \to \infty} \left[ \dfrac{b_k}{a^n}n^k +\dfrac{b_{k-1}}{a^n}n^{k-1} +...+\dfrac{b_1}{a^n}n+\dfrac{b_0}{a^n} \right] &=0+0+...+0+0\\
	\lim\limits_{n \to \infty}\dfrac{p(n)}{a^n} &=0
\end{align*}","['calculus', 'sequences-and-series', 'limits', 'polynomials', 'solution-verification']"
3,Prove that $ \sum_{n = 0 }^\infty \frac{\cos(\frac{2n\pi}{3})}{n+1}$ is convergent.,Prove that  is convergent., \sum_{n = 0 }^\infty \frac{\cos(\frac{2n\pi}{3})}{n+1},"So I've tried to show that the series is convergent with a help of Dirichlet's theroem $\sum_{n = 0 }^\infty \frac{\cos(\frac{2n\pi}{3})}{n+1}$ , but it turned out that the following sum diverges $\sum_{n = 0 }^\infty \cos(\frac{2n\pi}{3}) $ $\sum_{n = 0 }^\infty \cos(\frac{2n\pi}{3}) = 1,-\frac{1}{2},-\frac{1}{2},1,...$ and so on. I also checked the necessary conditon $\lim_{n \to \infty} \frac{\cos(\frac{2n\pi}{3})}{n+1}= 0 $ After showing the convergence of this series I should calculate the sum with a help of the following power series (that was also a hint to this exercise) $\sum_{n = 0 }^\infty \frac{\cos(\frac{2n\pi}{3})}{n+1}x^{n+1}$ this part seems to be relatively easy but to take the derivative of the sum I ought to know the radius of the power series and that comes down to calculating (probably) another limit... $\lim_{n \to \infty} \frac{\frac{\cos(\frac{2(n+1)\pi}{3})}{n+1}}{\frac{\cos(\frac{2n\pi}{3})}{n+2}}= \lim_{n \to \infty} (\frac{n+2}{n+1})\frac{\cos(\frac{2(n+1)\pi}{3})}{\cos(\frac{2n\pi}{3})} = ...$","So I've tried to show that the series is convergent with a help of Dirichlet's theroem , but it turned out that the following sum diverges and so on. I also checked the necessary conditon After showing the convergence of this series I should calculate the sum with a help of the following power series (that was also a hint to this exercise) this part seems to be relatively easy but to take the derivative of the sum I ought to know the radius of the power series and that comes down to calculating (probably) another limit...","\sum_{n = 0 }^\infty \frac{\cos(\frac{2n\pi}{3})}{n+1} \sum_{n = 0 }^\infty \cos(\frac{2n\pi}{3})  \sum_{n = 0 }^\infty \cos(\frac{2n\pi}{3}) = 1,-\frac{1}{2},-\frac{1}{2},1,... \lim_{n \to \infty} \frac{\cos(\frac{2n\pi}{3})}{n+1}= 0  \sum_{n = 0 }^\infty \frac{\cos(\frac{2n\pi}{3})}{n+1}x^{n+1} \lim_{n \to \infty} \frac{\frac{\cos(\frac{2(n+1)\pi}{3})}{n+1}}{\frac{\cos(\frac{2n\pi}{3})}{n+2}}= \lim_{n \to \infty} (\frac{n+2}{n+1})\frac{\cos(\frac{2(n+1)\pi}{3})}{\cos(\frac{2n\pi}{3})} = ...","['sequences-and-series', 'limits', 'analysis']"
4,dual space of l2 with strange norm,dual space of l2 with strange norm,,"Consider $\displaystyle(\ell_2, \lVert\cdot\rVert_\star), \lVert x\rVert_\star = \sum\limits_{k=1}^{\infty}\frac{|x(k)|}{k}$ . What is its dual space? Is this space reflexive? My idea is to consider $\displaystyle\varphi: (\ell_2, \lVert\cdot\rVert_\star) \rightarrow (\ell_1, \lVert\cdot\rVert_1), \varphi(\{x(k)\}_{k=1}^\infty) = \left\{ \frac{x(k)}{k} \right\}_{k=1}^\infty$ . Then $\lVert\varphi(x)\rVert_1 = \lVert x\rVert_\star$ and $\varphi$ is isometric isomorphism. But $\text{Im}\varphi \subsetneq \ell_1$ becasue, for example, $\displaystyle\left\{\frac{1}{k^{3/2}}\right\} \in \ell_1, \left\{\frac{1}{k^{1/2}}\right\} \notin \ell_2$ . So how to find dual space in this case?","Consider . What is its dual space? Is this space reflexive? My idea is to consider . Then and is isometric isomorphism. But becasue, for example, . So how to find dual space in this case?","\displaystyle(\ell_2, \lVert\cdot\rVert_\star), \lVert x\rVert_\star = \sum\limits_{k=1}^{\infty}\frac{|x(k)|}{k} \displaystyle\varphi: (\ell_2, \lVert\cdot\rVert_\star) \rightarrow (\ell_1, \lVert\cdot\rVert_1), \varphi(\{x(k)\}_{k=1}^\infty) = \left\{ \frac{x(k)}{k} \right\}_{k=1}^\infty \lVert\varphi(x)\rVert_1 = \lVert x\rVert_\star \varphi \text{Im}\varphi \subsetneq \ell_1 \displaystyle\left\{\frac{1}{k^{3/2}}\right\} \in \ell_1, \left\{\frac{1}{k^{1/2}}\right\} \notin \ell_2","['sequences-and-series', 'functional-analysis', 'normed-spaces', 'banach-spaces', 'dual-spaces']"
5,"Proving that, for positive integers $k_i$, there exists $x_0\in[0,\pi]$, such that $\frac12+\sum_{i = 1}^m\cos(k_ix_0)<0$","Proving that, for positive integers , there exists , such that","k_i x_0\in[0,\pi] \frac12+\sum_{i = 1}^m\cos(k_ix_0)<0","$k_i$ is a positive integer, $i=1,\ldots,m$ , please try to prove that there exist a point $x_0 \in [0,\pi]$ , such that $\frac{1}{2}+\sum\limits_{i = 1}^m {\cos ({k_i}{x_0})} < 0$ . My attempt: If $k_i$ are all equal, this question is easy; If $k_i$ forms an arithmetic sequence, using the product to difference formulas, we can simplify the expression $\frac{1}{2}+\sum\limits_{i = 1}^m {\cos ({k_i}{x})}$ , for example, $\frac{1}{2} + \sum\limits_{i = 1}^n {\cos (ix)}  = \frac{{\sin \frac{{(2n + 1)}}{2}x}}{{2\sin \frac{x}{2}}}$ . Now, however, $k_i$ are disorganized.","is a positive integer, , please try to prove that there exist a point , such that . My attempt: If are all equal, this question is easy; If forms an arithmetic sequence, using the product to difference formulas, we can simplify the expression , for example, . Now, however, are disorganized.","k_i i=1,\ldots,m x_0 \in [0,\pi] \frac{1}{2}+\sum\limits_{i = 1}^m {\cos ({k_i}{x_0})} < 0 k_i k_i \frac{1}{2}+\sum\limits_{i = 1}^m {\cos ({k_i}{x})} \frac{1}{2} + \sum\limits_{i = 1}^n {\cos (ix)}  = \frac{{\sin \frac{{(2n + 1)}}{2}x}}{{2\sin \frac{x}{2}}} k_i","['real-analysis', 'sequences-and-series', 'trigonometry']"
6,Convergence of the double series,Convergence of the double series,,"Let $\{a_i\}_{i\in \mathbb{N}}$ be a sequence of positive real numbers, whose series converges i.e. $\sum\limits_{i\in \mathbb{N}}a_i = a < \infty.$ Does this imply the convergence of the double series $\sum\limits_{i,j \in \mathbb{N}}a_i a_j?$ If yes, how can this be proven? If not, what are some counterexamples? Any help is appreciated. Thanks in advance. P.S. : A double series $\sum\limits_{i,j \in \mathbb{N}}a_i a_j$ converges to A, if for all $\epsilon > 0,$ there exists $ N_0 \in \mathbb{N}$ such that \begin{eqnarray}  \left|\sum\limits_{i=1}^m\sum\limits_{j=1}^n a_i a_j -A \right| \leq \epsilon, \qquad \text{for all } m,n \geq N_0. \end{eqnarray}","Let be a sequence of positive real numbers, whose series converges i.e. Does this imply the convergence of the double series If yes, how can this be proven? If not, what are some counterexamples? Any help is appreciated. Thanks in advance. P.S. : A double series converges to A, if for all there exists such that","\{a_i\}_{i\in \mathbb{N}} \sum\limits_{i\in \mathbb{N}}a_i = a < \infty. \sum\limits_{i,j \in \mathbb{N}}a_i a_j? \sum\limits_{i,j \in \mathbb{N}}a_i a_j \epsilon > 0,  N_0 \in \mathbb{N} \begin{eqnarray}
 \left|\sum\limits_{i=1}^m\sum\limits_{j=1}^n a_i a_j -A \right| \leq \epsilon, \qquad \text{for all } m,n \geq N_0.
\end{eqnarray}","['real-analysis', 'calculus', 'sequences-and-series', 'analysis']"
7,Show $nx_n \to 1$ for sequence defined by $x_{n+1}=\frac{x_n}{1+nx_n^2}$,Show  for sequence defined by,nx_n \to 1 x_{n+1}=\frac{x_n}{1+nx_n^2},"Let $a>0$ . Consider the sequence $x_{n+1}=\frac{x_n}{1+nx_n^2},~x_1=a,~n\in\mathbb{N}^*$ . Study the convergence of $(x_n)_{n\ge1}$ and $(nx_n)_{n\ge1}$ . It was easy for me to prove that $(x_n)_n$ is convergent with the limit equal to $0$ , but couldn't find a straightforward approach for $(nx_n)_n$ . I first proved that $x_n\le\frac{1}{n}$ , or equivalently, $nx_n\le1$ , for $n\ge2$ , using induction. Then I showed that $(nx_n)_n$ is a nondecreasing sequence: $$\frac{(n+1)x_{n+1}}{nx_n}=\frac{n+1}{n+n^2x_n^2}\ge 1$$ Thus $(nx_n)_n$ is nondecreasing and upper bounded, so it is convergent with positive finite limit $l$ . Now consider $a_n=n$ and $b_n=\frac{1}{x_n}$ , so $(b_n)_n$ is a positive, increasing sequence with infinite limit. We have that $$\frac{a_{n+1}-a_n}{b_{n+1}-b_n}=\bigg(\frac{1}{x_{n+1}}-\frac{1}{x_n}\bigg)^{-1}=\frac{1}{nx_n}\to\frac{1}{l}$$ By the Stolz–Cesàro theorem, we obtain the identity $l=\frac{1}{l}$ , so the only possible value for $l$ is $l=1$ . The hardest part was to prove the convergence of $(nx_n)_n$ , which took me a long time. I feel like I am missing an easier solution. Please let me know if there's an elegant proof for $nx_n\to1$ . Thanks in advance.","Let . Consider the sequence . Study the convergence of and . It was easy for me to prove that is convergent with the limit equal to , but couldn't find a straightforward approach for . I first proved that , or equivalently, , for , using induction. Then I showed that is a nondecreasing sequence: Thus is nondecreasing and upper bounded, so it is convergent with positive finite limit . Now consider and , so is a positive, increasing sequence with infinite limit. We have that By the Stolz–Cesàro theorem, we obtain the identity , so the only possible value for is . The hardest part was to prove the convergence of , which took me a long time. I feel like I am missing an easier solution. Please let me know if there's an elegant proof for . Thanks in advance.","a>0 x_{n+1}=\frac{x_n}{1+nx_n^2},~x_1=a,~n\in\mathbb{N}^* (x_n)_{n\ge1} (nx_n)_{n\ge1} (x_n)_n 0 (nx_n)_n x_n\le\frac{1}{n} nx_n\le1 n\ge2 (nx_n)_n \frac{(n+1)x_{n+1}}{nx_n}=\frac{n+1}{n+n^2x_n^2}\ge 1 (nx_n)_n l a_n=n b_n=\frac{1}{x_n} (b_n)_n \frac{a_{n+1}-a_n}{b_{n+1}-b_n}=\bigg(\frac{1}{x_{n+1}}-\frac{1}{x_n}\bigg)^{-1}=\frac{1}{nx_n}\to\frac{1}{l} l=\frac{1}{l} l l=1 (nx_n)_n nx_n\to1","['sequences-and-series', 'limits', 'convergence-divergence', 'recurrence-relations']"
8,"Does $\exists\ n$ such that the first $2n$ digits of Thue Morse, $X_{2n},$ is the concatenated sequence $X_n X_n?$ If not then why not?","Does  such that the first  digits of Thue Morse,  is the concatenated sequence  If not then why not?","\exists\ n 2n X_{2n}, X_n X_n?","Background : The Thue–Morse sequence is the binary sequence (an infinite sequence of $0$ s and $1$ s) obtained by starting with $0$ and successively appending the Boolean complement of the sequence obtained thus far. The first few steps of this procedure yield the strings $0$ then $01, 0110, 01101001, 0110100110010110,$ and so on, which are prefixes of the Thue–Morse sequence. The full sequence begins: $01101001100101101001011001101001....$ For each $n\in\mathbb{N},$ let $X_n$ be the (string of) first $n$ digits of the Thue-Morse sequence. Does $\ \exists\ n\ $ such that the (string of) first $2n$ digits of T-M is the concatenated sequence/string $X_n X_n\ ?$ If yes, then obviously by definition of T-M, $n\neq 2^k,\ k\in\mathbb{N}$ . I also know that the T-M sequence contains no cubes, i.e. concatenated contiguous subsequences of the form $XXX.$ Other than this observation, I don't see how to make progress on the problem. I have checked this up until $n=2^{13}\approx 8000$ and I have found no such $n,$ which makes me suspect the answer is ""no."" But the fact that the T-M sequence does contain ""squares"" in general (not necessarily from the first digit like in the question above), does make me wonder why the answer to the above question could be no , if that is in fact the answer. Below is some code. I found the code that generates the T-M sequence with a quick google search, and the rest of the code - which is trying to find an example to the problem above - I wrote myself. # Python3 Program to find nth term of # Thue-Morse sequence.  # Return the complement of the # binary string. def complement(s):     comps = """";      # finding the complement     # of the string.     for i in range(len(s)):           # if character is 0, append 1         if (s[i] == '0'):             comps += '1';          # if character is 1, append 0.         else:             comps += '0';      return comps;  # Return the nth term of  # Thue-Morse sequence. def nthTerm(n):      # Initializing the string to 0     s = ""0"";      # Running the loop for n - 1 time.     for i in range(1, n):           # appending the complement of          # the string to the string.         s += complement(s);       return s;  # Driver Code   n = 15; print(nthTerm(n)) tM_List = nthTerm(n) print(tM_List)  for i in range(2**(n-2)):     #print(i, list(tM_List[:i+1])),     #print(i, list(tM_List[i+1:2*i+2])),     if list(tM_List[:i+1]) == list(tM_List[i+1:2*i+2]):         print('success')","Background : The Thue–Morse sequence is the binary sequence (an infinite sequence of s and s) obtained by starting with and successively appending the Boolean complement of the sequence obtained thus far. The first few steps of this procedure yield the strings then and so on, which are prefixes of the Thue–Morse sequence. The full sequence begins: For each let be the (string of) first digits of the Thue-Morse sequence. Does such that the (string of) first digits of T-M is the concatenated sequence/string If yes, then obviously by definition of T-M, . I also know that the T-M sequence contains no cubes, i.e. concatenated contiguous subsequences of the form Other than this observation, I don't see how to make progress on the problem. I have checked this up until and I have found no such which makes me suspect the answer is ""no."" But the fact that the T-M sequence does contain ""squares"" in general (not necessarily from the first digit like in the question above), does make me wonder why the answer to the above question could be no , if that is in fact the answer. Below is some code. I found the code that generates the T-M sequence with a quick google search, and the rest of the code - which is trying to find an example to the problem above - I wrote myself. # Python3 Program to find nth term of # Thue-Morse sequence.  # Return the complement of the # binary string. def complement(s):     comps = """";      # finding the complement     # of the string.     for i in range(len(s)):           # if character is 0, append 1         if (s[i] == '0'):             comps += '1';          # if character is 1, append 0.         else:             comps += '0';      return comps;  # Return the nth term of  # Thue-Morse sequence. def nthTerm(n):      # Initializing the string to 0     s = ""0"";      # Running the loop for n - 1 time.     for i in range(1, n):           # appending the complement of          # the string to the string.         s += complement(s);       return s;  # Driver Code   n = 15; print(nthTerm(n)) tM_List = nthTerm(n) print(tM_List)  for i in range(2**(n-2)):     #print(i, list(tM_List[:i+1])),     #print(i, list(tM_List[i+1:2*i+2])),     if list(tM_List[:i+1]) == list(tM_List[i+1:2*i+2]):         print('success')","0 1 0 0 01, 0110, 01101001, 0110100110010110, 01101001100101101001011001101001.... n\in\mathbb{N}, X_n n \ \exists\ n\  2n X_n X_n\ ? n\neq 2^k,\ k\in\mathbb{N} XXX. n=2^{13}\approx 8000 n,","['sequences-and-series', 'examples-counterexamples', 'binary', 'natural-numbers']"
9,If $a_i/b_i$ converges then $\Sigma_m^na_i$ is infinitesimal iff $\Sigma_m^nb_i$ is too,If  converges then  is infinitesimal iff  is too,a_i/b_i \Sigma_m^na_i \Sigma_m^nb_i,"I am trying to solve question ( $6$ ) in section $6.11$ of Goldblatt's Lectures on the Hyperreals . The question asks: Given two series of positive terms $\sum_1^\infty a_i$ and $\sum_1^\infty b_i$ such that the sequence $(a_i/b_i:i\in\mathbb{N})$ converges in $\mathbb{R}$ , show that for unlimited $m$ and $n$ , $\sum_m^n a_i$ is infinitesimal if and only if $\sum_m^n b_i$ is infitesimal. I have not got very far. I tried to first show the forward implication. For all naturals $i$ , $a_i>0$ so $a_i$ is positive for all hypernatural $i$ . For all $a_j$ with $n\le j\le m$ the sum $\sum_m^na_i>a_j>0$ , so if $\sum_m^na$ is infinitesimal,all $a_j$ are also infinitesimal. The sequence $a_i/b_i$ converges to a limit $L$ , so for all hypernaturals $j$ the term $a_j/b_j=L+\varepsilon_j$ where $\varepsilon$ is infinitesimal. So $a_j=b_j(L+\varepsilon_j)$ . From this, if $L$ is non-zero $b_j$ must be infinitesimal. Here, I tried rewriting the sum $\sum_m^n a_i=\sum_m^nb_i(L+\varepsilon_j)=L\sum_m^nb_i+\sum_m^nb_j\varepsilon_j$ . If the rightmost sum is infinitesimal, then it would follow that $\sum_m^n b_j$ is infinitesimal. The rightmost sum $\sum_m^nb_j\varepsilon_j$ is a sum of infinitesimals, so for all finite sums it is infinitesimal. However, if $n-m$ is unlimited, I don't know how to fix this argument.","I am trying to solve question ( ) in section of Goldblatt's Lectures on the Hyperreals . The question asks: Given two series of positive terms and such that the sequence converges in , show that for unlimited and , is infinitesimal if and only if is infitesimal. I have not got very far. I tried to first show the forward implication. For all naturals , so is positive for all hypernatural . For all with the sum , so if is infinitesimal,all are also infinitesimal. The sequence converges to a limit , so for all hypernaturals the term where is infinitesimal. So . From this, if is non-zero must be infinitesimal. Here, I tried rewriting the sum . If the rightmost sum is infinitesimal, then it would follow that is infinitesimal. The rightmost sum is a sum of infinitesimals, so for all finite sums it is infinitesimal. However, if is unlimited, I don't know how to fix this argument.",6 6.11 \sum_1^\infty a_i \sum_1^\infty b_i (a_i/b_i:i\in\mathbb{N}) \mathbb{R} m n \sum_m^n a_i \sum_m^n b_i i a_i>0 a_i i a_j n\le j\le m \sum_m^na_i>a_j>0 \sum_m^na a_j a_i/b_i L j a_j/b_j=L+\varepsilon_j \varepsilon a_j=b_j(L+\varepsilon_j) L b_j \sum_m^n a_i=\sum_m^nb_i(L+\varepsilon_j)=L\sum_m^nb_i+\sum_m^nb_j\varepsilon_j \sum_m^n b_j \sum_m^nb_j\varepsilon_j n-m,"['sequences-and-series', 'nonstandard-analysis']"
10,reciprocals of squarefree k-almost primes,reciprocals of squarefree k-almost primes,,"First of all, I'm a novice in math and English is not my native language, so I apologize in advance for any incorrect wording, etc. Definitions and specific example Let's define the set $A_4 = \{2,3,5,7\}$ , with the first 4 prime numbers. And $r(A_4) = \frac{1}{2} + \frac{1}{3} + \frac{1}{5} +\frac{1}{7} = \frac{247}{210}$ , as the sum of the reciprocals of the elements of $A_4$ . Let's now define the set $B_4 = \{6,10,14,15,21,35\}$ , with the squarefree semiprimes with prime factors $p$ such that $p \in A_4$ . Now, $r(B_4) = \frac{1}{6} + \frac{1}{10} + \frac{1}{14} +\frac{1}{15} +\frac{1}{21} +\frac{1}{35} = \frac{101}{210}$ . And in a similar way, $C_4 = \{30,42,70,105\}$ , with the squarefree 3-almost primes and $r(C_4) = \frac{1}{30} + \frac{1}{42} + \frac{1}{70} +\frac{1}{105} = \frac{17}{210}$ . And finally, $D_4 = \{210\}$ , with a square free 4-almost prime and $r(D_4) = \frac{1}{210}$ . Observation We see: $$r(A_4) > r(B_4) > r(C_4) > r(D_4)$$ Generalization Now change $A_4$ into $A_n$ , where $n$ is a positive integer. I assume my observation holds for other - higher - values of $n$ . So that: $ r(A_n) > r(B_n) > r(C_n) > \dots > r(Z_n)$ , where Z doesn't mean the 26th term of the sequence, but in general 'the last' or n-th term. (I was running out of capitals... ) Question Does my observation holds for all values of $n$ ? Who can I prove it (Euler probably already did it for me...)? Useful links to literature are welcome. EDIT: counter example Following Greg Martin's thorough answer (thx!), I make a cautious attempt to formulate a 'counter argument'. Let's compare the first and second to last terms of the series based on $A_5 = \{a,b,c,d,e\}$ . Both terms consist of the same amount of sub-terms. first term: $$r(A_5) = u_1 = \frac{1}{a}+\frac{1}{b}+\frac{1}{c}+\frac{1}{d}+\frac{1}{e}$$ second to last term: $$u_{n-1}=\frac{1}{acde}+\frac{1}{bcde}+\frac{1}{bcde}+\frac{1}{bcde}+\frac{1}{bcde}$$ It's clear that the first sub-term in $u_{n-1}$ is smaller than the first of $u_{1}$ . The same holds for the other sub-terms. So: $$u_{1} > u_{n-1}$$ This is true for all values of $n$ . It gives me the intuitive idea that the '<' and '>' signs 'flips' at some point. So, let me restate my question. Does my observation holds for all sufficiently large values of $n$ , starting from a certain term $N$ ? So that: $$r(A_n) < r(B_n) < r(C_n) < \dots < r(N-1_n) < r(N_n) > r(N+1_n) \dots r(Z_n)$$","First of all, I'm a novice in math and English is not my native language, so I apologize in advance for any incorrect wording, etc. Definitions and specific example Let's define the set , with the first 4 prime numbers. And , as the sum of the reciprocals of the elements of . Let's now define the set , with the squarefree semiprimes with prime factors such that . Now, . And in a similar way, , with the squarefree 3-almost primes and . And finally, , with a square free 4-almost prime and . Observation We see: Generalization Now change into , where is a positive integer. I assume my observation holds for other - higher - values of . So that: , where Z doesn't mean the 26th term of the sequence, but in general 'the last' or n-th term. (I was running out of capitals... ) Question Does my observation holds for all values of ? Who can I prove it (Euler probably already did it for me...)? Useful links to literature are welcome. EDIT: counter example Following Greg Martin's thorough answer (thx!), I make a cautious attempt to formulate a 'counter argument'. Let's compare the first and second to last terms of the series based on . Both terms consist of the same amount of sub-terms. first term: second to last term: It's clear that the first sub-term in is smaller than the first of . The same holds for the other sub-terms. So: This is true for all values of . It gives me the intuitive idea that the '<' and '>' signs 'flips' at some point. So, let me restate my question. Does my observation holds for all sufficiently large values of , starting from a certain term ? So that:","A_4 = \{2,3,5,7\} r(A_4) = \frac{1}{2} + \frac{1}{3} + \frac{1}{5} +\frac{1}{7} = \frac{247}{210} A_4 B_4 = \{6,10,14,15,21,35\} p p \in A_4 r(B_4) = \frac{1}{6} + \frac{1}{10} + \frac{1}{14} +\frac{1}{15} +\frac{1}{21} +\frac{1}{35} = \frac{101}{210} C_4 = \{30,42,70,105\} r(C_4) = \frac{1}{30} + \frac{1}{42} + \frac{1}{70} +\frac{1}{105} = \frac{17}{210} D_4 = \{210\} r(D_4) = \frac{1}{210} r(A_4) > r(B_4) > r(C_4) > r(D_4) A_4 A_n n n  r(A_n) > r(B_n) > r(C_n) > \dots > r(Z_n) n A_5 = \{a,b,c,d,e\} r(A_5) = u_1 = \frac{1}{a}+\frac{1}{b}+\frac{1}{c}+\frac{1}{d}+\frac{1}{e} u_{n-1}=\frac{1}{acde}+\frac{1}{bcde}+\frac{1}{bcde}+\frac{1}{bcde}+\frac{1}{bcde} u_{n-1} u_{1} u_{1} > u_{n-1} n n N r(A_n) < r(B_n) < r(C_n) < \dots < r(N-1_n) < r(N_n) > r(N+1_n) \dots r(Z_n)","['sequences-and-series', 'prime-numbers', 'semiprimes']"
11,Confusion regarding uniform boundedness,Confusion regarding uniform boundedness,,"I am estimating a sequence of functions and struggling with the following estimations. Suppose $F_n:[0,1]\rightarrow (0,\infty)$ , a continuous sequence of functions. We know the following For an arbitrary $n\in {\mathbb{N}}$ and $x_0\in [0,1]$ , there exists an $\epsilon_n>0$ (depending only on n not on $x_0$ ), and two positive constants $C_{1,x_0},C_{2,x_0}$ (only depending on $x_0$ , not on n) such that $$ C_{1,x_0}<F_n(x)<C_{2,x_0}\,\forall x\in B(x_0,\epsilon_n):=(x_0-\epsilon_n,x_0+\epsilon_n). $$ Is $F_n$ uniformly bounded on $[0,1]$ by two positive constants? My approach: I was trying to use a compactness argument for this. I first fixed a $n$ then, on each $B(x_0,\epsilon_n)$ , $F_n$ is bounded by positive constants, not depending on $n$ . So, after taking finite subcover, I tried to establish the claim. However, the issue is if I take the finite subcover then the points $x_0$ will start to depend on $n$ . Is there any solution for this? Or is the claim false? Any suggestion would be of great help.","I am estimating a sequence of functions and struggling with the following estimations. Suppose , a continuous sequence of functions. We know the following For an arbitrary and , there exists an (depending only on n not on ), and two positive constants (only depending on , not on n) such that Is uniformly bounded on by two positive constants? My approach: I was trying to use a compactness argument for this. I first fixed a then, on each , is bounded by positive constants, not depending on . So, after taking finite subcover, I tried to establish the claim. However, the issue is if I take the finite subcover then the points will start to depend on . Is there any solution for this? Or is the claim false? Any suggestion would be of great help.","F_n:[0,1]\rightarrow (0,\infty) n\in {\mathbb{N}} x_0\in [0,1] \epsilon_n>0 x_0 C_{1,x_0},C_{2,x_0} x_0 
C_{1,x_0}<F_n(x)<C_{2,x_0}\,\forall x\in B(x_0,\epsilon_n):=(x_0-\epsilon_n,x_0+\epsilon_n).
 F_n [0,1] n B(x_0,\epsilon_n) F_n n x_0 n","['real-analysis', 'sequences-and-series', 'complex-analysis']"
12,"Prove $\,\lim\limits_{n\to\infty} \sqrt{\frac{4n+1}{n}}=2$",Prove,"\,\lim\limits_{n\to\infty} \sqrt{\frac{4n+1}{n}}=2","As shown in the title, I'm asked to prove $\lim\limits_{n\to\infty} \sqrt{\dfrac{4n+1}{n}}=2$ using the $\epsilon,N$ definition only. My solution was completely different from the solution they posted so I want to know if I did something wrong. Let $\epsilon>0$ , we have to find $N$ s.t $\forall n>N$ . $\left|\sqrt{\dfrac{4n+1}{n}}-2\right|<\epsilon$ . Since $n$ is iterating over naturals, we can say that $\sqrt{\dfrac{4n+1}{n}}-2$ is always positive by plugging in the minimum of $\mathbb{N}$ . I continued by multiplying by $\left(\sqrt{\dfrac{4n+1}{n}}+2\right)$ .\ $\dfrac{\left(\sqrt{\dfrac{4n+1}{n}}-2\right)\left(\sqrt{\dfrac{4n+1}{n}}+2\right)}{\left(\sqrt{\dfrac{4n+1}{n}}+2\right)}= \dfrac{\dfrac{4n+1}{n}-4}{\left(\sqrt{\dfrac{4n+1}{n}}+2\right)}\stackrel{(*)}{<}\dfrac{1}{n}$ while (*) was using the previous conclusion that the denominator is always positive and greater than $1$ . Now I can say that we can take $N=\dfrac{1}{\epsilon}+10$ and this satisfies the desired.","As shown in the title, I'm asked to prove using the definition only. My solution was completely different from the solution they posted so I want to know if I did something wrong. Let , we have to find s.t . . Since is iterating over naturals, we can say that is always positive by plugging in the minimum of . I continued by multiplying by .\ while (*) was using the previous conclusion that the denominator is always positive and greater than . Now I can say that we can take and this satisfies the desired.","\lim\limits_{n\to\infty} \sqrt{\dfrac{4n+1}{n}}=2 \epsilon,N \epsilon>0 N \forall n>N \left|\sqrt{\dfrac{4n+1}{n}}-2\right|<\epsilon n \sqrt{\dfrac{4n+1}{n}}-2 \mathbb{N} \left(\sqrt{\dfrac{4n+1}{n}}+2\right) \dfrac{\left(\sqrt{\dfrac{4n+1}{n}}-2\right)\left(\sqrt{\dfrac{4n+1}{n}}+2\right)}{\left(\sqrt{\dfrac{4n+1}{n}}+2\right)}= \dfrac{\dfrac{4n+1}{n}-4}{\left(\sqrt{\dfrac{4n+1}{n}}+2\right)}\stackrel{(*)}{<}\dfrac{1}{n} 1 N=\dfrac{1}{\epsilon}+10","['calculus', 'sequences-and-series', 'limits', 'epsilon-delta']"
13,BMO1 number theory question on fibonacci sequence and divisibility,BMO1 number theory question on fibonacci sequence and divisibility,,"This is question 2 from the 1983 British Maths Olympaid The fibonacci sequence $f_{n}$ is defined by $f_{1} = 1, f_{2} = 1,$ and $f_{n} = f_{n-1} + f_{n-2}, n > 2$ prove that there are integers a, b and m such that $0 < a < m$ , $0 < b < m$ and $f_{n}-anb^{n}$ is divisible by $m$ for all positive integers $n$ . I'm pretty sure I've solved the question, but this is my first time solving a question like this with divisibility in sequences, so please could someone look at my solution and tell me places where there are better routes or improvements. I also think my solution is quite long for a question 2 problem, which makes me think there is an easier, quicker way that I have overlooked. My solution: By the inequality condition, we see $m = 1$ is impossible, then let $T_{n} = f_{n} - anb^{n}$ , so, $m|T_{1}$ and $m|T_{2}$ . $m|1-ab$ -----> (A) from this we can also see m must not divide a or b, or else $m|1$ which means for $m>0$ we get $m = 1$ which is impossible $m|1-2ab^{2}$ -----> (B) multiply (A) by $2b$ $m|2b-2ab^{2}$ -----> (C) $m|(C) - (A)$ so, $m|2b-1$ $m|T_{1} + T_{2}$ and $m|T_{3}$ , since these two parts have the same constant I thought to subtract one from the other and get an expression only in terms of $a$ and $b$ which I then factorised to get $m|ab(b-1)(3b+1)$ since m doesn't divide a or b, $ab$ can be removed. Also, $m|2b-1$ but m doesn't divide $b$ , so $m$ doesn't divide the difference between $2b-1$ and $b$ . So, $m|b-1$ is impossible, meaning (b-1) can be removed too, leaving us with $m|3b+1$ and $m|2b-1$ so $m|6b+2$ and $m|6b-3$ so $m|(6b+2) - (6b-3)$ so $m|5$ . Under current restrictions for $m$ only $m=5$ is possible, so $m = 5$ . $a<5, b<5$ for $T_{1} \equiv 0\pmod{5}$ it must be that $ab \equiv 1\pmod{5}$ . The only possible pairs $(a,b)$ are $(1,1)$ , $(4,4)$ and $(2,3)$ or $(3,2)$ . I just tested each pair for $T_{n}$ divisibility by $5$ , where they all failed quite quickly except for $(a,b) = (2,3)$ . Now we just have to prove that this pair works. I decided to do this by having $S_{n} = 2(n)(3^{n})$ and showing that $S_{n} \equiv f_{n}\pmod{5}$ for all $n$ . This I found I could do by showing $S_{n}$ follows the same relation as $f_{n}$ in $\mod{5}$ and has the same start terms (1 and 1). We could have done this by calculating $f_{n}\pmod{5}$ for some time and eventually see that it becomes a repeating sequence, so we could just calculate $S_{n}\pmod{5}$ upto that point and show that $S_{n}\pmod{5}$ is also repeating with the same period as $f_{n}\pmod{5}$ and that all the terms are equal, but I wanted to avoid much computation and instead tried the following. Now to show $S_{n} \equiv f_{n}\pmod{5}$ for all n: We follow the route of showing that $S_{n} \pmod{5}$ follows the same relation as $f_{n}\pmod{5}$ . we know by applying $\pmod{5}$ to the fibonacci sequence definition, $f_{n} \equiv f_{n-1} + f_{n-2} \pmod{5}$ . So, since we already have $S_{1} \equiv f_{1} \pmod{5} $ and $S_{2} \equiv f_{2} \pmod{5}$ by some calculations, we just need to show that $S_{n} \equiv S_{n-1} + S_{n-2} \pmod{5}$ . base case: $S_{3} \equiv S_{1} + S_{2}\pmod{5}$ which is true. By definition, $S_{k+1} = 2(k+1)(3^{k+1})$ $S_{k+1} = (2k+2)(3^{k+1})$ $S_{k+1} = (2k)(3^{k+1}) + 2(3^{k+1})$ $S_{k+1} = (2k)(3^{k})(3) + 2(3^{k+1})$ $S_{k+1} = (2k)(3^{k}) + 2((2k)(3^{k})) + 2(3^{k+1})$ $S_{k+1} = 2k(3^{k}) + (6)(2k)(3^{k-1}) + 2(9)(3^{k-1})$ Now since we are considering $S_{n} \pmod{5}$ , I applied $\pmod{5}$ to the above equation. $S_{k+1} \equiv 2k(3^{k}) + 2k(3^{k-1}) - 2(3^{k-1})\pmod{5}$ $S_{k+1} \equiv 2k(3^{k}) + 2(k-1)(3^{k-1})\pmod{5}$ $S_{k+1} \equiv S_{k} + S_{k-1}\pmod{5}$ This is the same recurrence relation as $f_{n}\pmod{5}$ and since they have the same starting two values, 1 and 1, $S_{n} \equiv f_{n} \pmod{5}$ for all $n$ , meaning that $f_{n} - S_{n} \equiv 0\pmod{5}$ for all $n$ ie: $5|f_{n} - 2n(3^{n}) $ for all $n$ , which means that $m =5$ , $a = 2$ and $b = 3$ are the only positive integers with $a<m$ and $b<m$ that allow $m$ to divide every term of the sequence $T_{n}$ .","This is question 2 from the 1983 British Maths Olympaid The fibonacci sequence is defined by and prove that there are integers a, b and m such that , and is divisible by for all positive integers . I'm pretty sure I've solved the question, but this is my first time solving a question like this with divisibility in sequences, so please could someone look at my solution and tell me places where there are better routes or improvements. I also think my solution is quite long for a question 2 problem, which makes me think there is an easier, quicker way that I have overlooked. My solution: By the inequality condition, we see is impossible, then let , so, and . -----> (A) from this we can also see m must not divide a or b, or else which means for we get which is impossible -----> (B) multiply (A) by -----> (C) so, and , since these two parts have the same constant I thought to subtract one from the other and get an expression only in terms of and which I then factorised to get since m doesn't divide a or b, can be removed. Also, but m doesn't divide , so doesn't divide the difference between and . So, is impossible, meaning (b-1) can be removed too, leaving us with and so and so so . Under current restrictions for only is possible, so . for it must be that . The only possible pairs are , and or . I just tested each pair for divisibility by , where they all failed quite quickly except for . Now we just have to prove that this pair works. I decided to do this by having and showing that for all . This I found I could do by showing follows the same relation as in and has the same start terms (1 and 1). We could have done this by calculating for some time and eventually see that it becomes a repeating sequence, so we could just calculate upto that point and show that is also repeating with the same period as and that all the terms are equal, but I wanted to avoid much computation and instead tried the following. Now to show for all n: We follow the route of showing that follows the same relation as . we know by applying to the fibonacci sequence definition, . So, since we already have and by some calculations, we just need to show that . base case: which is true. By definition, Now since we are considering , I applied to the above equation. This is the same recurrence relation as and since they have the same starting two values, 1 and 1, for all , meaning that for all ie: for all , which means that , and are the only positive integers with and that allow to divide every term of the sequence .","f_{n} f_{1} = 1, f_{2} = 1, f_{n} = f_{n-1} + f_{n-2}, n > 2 0 < a < m 0 < b < m f_{n}-anb^{n} m n m = 1 T_{n} = f_{n} - anb^{n} m|T_{1} m|T_{2} m|1-ab m|1 m>0 m = 1 m|1-2ab^{2} 2b m|2b-2ab^{2} m|(C) - (A) m|2b-1 m|T_{1} + T_{2} m|T_{3} a b m|ab(b-1)(3b+1) ab m|2b-1 b m 2b-1 b m|b-1 m|3b+1 m|2b-1 m|6b+2 m|6b-3 m|(6b+2) - (6b-3) m|5 m m=5 m = 5 a<5, b<5 T_{1} \equiv 0\pmod{5} ab \equiv 1\pmod{5} (a,b) (1,1) (4,4) (2,3) (3,2) T_{n} 5 (a,b) = (2,3) S_{n} = 2(n)(3^{n}) S_{n} \equiv f_{n}\pmod{5} n S_{n} f_{n} \mod{5} f_{n}\pmod{5} S_{n}\pmod{5} S_{n}\pmod{5} f_{n}\pmod{5} S_{n} \equiv f_{n}\pmod{5} S_{n} \pmod{5} f_{n}\pmod{5} \pmod{5} f_{n} \equiv f_{n-1} + f_{n-2} \pmod{5} S_{1} \equiv f_{1} \pmod{5}  S_{2} \equiv f_{2} \pmod{5} S_{n} \equiv S_{n-1} + S_{n-2} \pmod{5} S_{3} \equiv S_{1} + S_{2}\pmod{5} S_{k+1} = 2(k+1)(3^{k+1}) S_{k+1} = (2k+2)(3^{k+1}) S_{k+1} = (2k)(3^{k+1}) + 2(3^{k+1}) S_{k+1} = (2k)(3^{k})(3) + 2(3^{k+1}) S_{k+1} = (2k)(3^{k}) + 2((2k)(3^{k})) + 2(3^{k+1}) S_{k+1} = 2k(3^{k}) + (6)(2k)(3^{k-1}) + 2(9)(3^{k-1}) S_{n} \pmod{5} \pmod{5} S_{k+1} \equiv 2k(3^{k}) + 2k(3^{k-1}) - 2(3^{k-1})\pmod{5} S_{k+1} \equiv 2k(3^{k}) + 2(k-1)(3^{k-1})\pmod{5} S_{k+1} \equiv S_{k} + S_{k-1}\pmod{5} f_{n}\pmod{5} S_{n} \equiv f_{n} \pmod{5} n f_{n} - S_{n} \equiv 0\pmod{5} n 5|f_{n} - 2n(3^{n})  n m =5 a = 2 b = 3 a<m b<m m T_{n}","['sequences-and-series', 'elementary-number-theory', 'contest-math', 'divisibility', 'fibonacci-numbers']"
14,Problems regarding properties of the Floyd's Triangle,Problems regarding properties of the Floyd's Triangle,,"Setup Have a look at the Floyd's Triangle :- 1  2 3  4 5 6  7 8 9 10  11 12 13 14 15  16 17 18 19 20 21  22 23 24 25 26 27 28  29 30 31 32 33 34 35 36  37 38 39 40 41 42 43 44 45  46 47 48 49 50 51 52 53 54 55  56 57 58 59 60 61 62 63 64 65 66  67 68 69 70 71 72 73 74 75 76 77 78  79 80 81 82 83 84 85 86 87 88 89 90 91  92 93 94 95 96 97 98 99 100 101 102 103 104 105  106 107 108 109 110 111 112 113 114 115 116 117 118 119 120  121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136  ... Here, all the Natural Numbers $(\mathbb{N})$ are written consecutively, row-wise. Each row has a length of $n$ , where $n$ increments by $1$ in each succession. I noticed several properties of this triangle, related to a few of which I have questions. So, I have broken this post down into $3$ parts for related questions that I found the most perplexing. Part 1 Let's take the sum of each row. Their sequence would be:- 1, 5, 15, 34, 65, 111, 175, 260, 369, 505, 671, 870, 1105, 1379, 1695, 2056, ... which is given by the formula $\frac{n(n^2 + 1)}{2}$ . If we take the averages of all the $n$ th and $(n + 2)$ th terms (where $n$ is an odd number), we get the sequence :- (1 + 15) / 2, (15 + 65) / 2, (65 + 175) / 2, ...  or,  8, 40, 120, 272, 520, 888, ...       --- (i) Then, taking the sequence of the middle or the even $n$ th terms [( $n + 1$ )th terms, where $n$ is odd], we get this :- 5, 34, 111, 260, 505, 870, ...       --- (ii) Subtracting the sequence (ii) of middle terms from the sequence (i) of the averages of the neighbouring extremes, we get:- 8 - 5, 40 - 34, 120 - 111, 272 - 12, 520 - 505, 888 - 870, ...  or,  3, 6, 9, 12, 15, 18, ... Why are multiples of 3 showing up here? Part 2 (Here's a smaller version of the same triangle, for your ease of viewing):- 1 - 2 3 * 4 5 6 * 7 8 9 10 - 11 12 13 14 15 * 16 17 18 19 20 21 * 22 23 24 25 26 27 28 - 29 30 31 32 33 34 35 36 * 37 38 39 40 41 42 43 44 45 * ... Have a look at the ""hypotenuse"" or the right-most numbers of the rows of the triangle. Notice that they are triangular numbers , given by the formula $\frac{n(n + 1)}{2}$ . Take a look at the pairs of $2$ nd and $3$ rd, $5$ th and $6$ th, $8$ th and $9$ th, ... $(3n - 1)$ th and $(3n)$ th of these triangular numbers (shown above by * s). That is, (3, 6), (15, 21), (36, 45), (66, 78), ... Observe that, yet again, all of these numbers are divisible by 3. Written as multiples of 3, they are:- (3 * 1, 3 * 2), (3 * 5, 3 * 7), (3 * 12, 3 * 15), (3 * 22, 3 * 26), ... Here, the differences between the multiplicands in individual pairs are:- 2 - 1, 7 - 5, 13 - 12, 26 - 22, ...  or,  1, 2, 3, 4, 5, ... And their sums are:- 2 + 1, 7 + 5, 13 + 12, 26 + 22, ...  or,  3, 12, 27, 48, ...  or,  3 * 1^2, 3 * 2^2, 3 * 3^2, 3 * 4^2,... Also, observe the difference between the first term of the $(n + 1)$ th pair, and the last term of the $n$ th pair (where $n \in \mathbb{N}$ ):- 15 - 6, 36 - 21, 66 - 45, ...  or,  9, 15, 21, ...  or,  3 * 3, 3 * 5, 3 * 7, ... The multiplicands of the differences are consecutive odd numbers. Moreover, the terms that we left out (denoted by - s):- 1, 10, 28, 55, 91, 136, ... also follow a pattern. The differences between this sequence's consecutive terms are:- 10 - 1, 28 - 10, 55 - 28, 91 - 55, 136 - 91, ...  or,  9, 18, 27, 36, 45, ... What is the reason behind these specific numbers (and mainly $3$ ) popping up? What is the intuitive reason and / or proof for why things are the way they are? Part 3 (The same triangle reproduced again):- @ * - 1   *   2 3     - 4 5 6 ! *   7 8 9 10 ! *   11 12 13 14 15     - 16 17 18 19 20 21       22 23 24 25 26 27 28 @ *   29 30 31 32 33 34 35 36 @ *   37 38 39 40 41 42 43 44 45       46 47 48 49 50 51 52 53 54 55       56 57 58 59 60 61 62 63 64 65 66 ! *   67 68 69 70 71 72 73 74 75 76 77 78 ! *   79 80 81 82 83 84 85 86 87 88 89 90 91       92 93 94 95 96 97 98 99 100 101 102 103 104 105       106 107 108 109 110 111 112 113 114 115 116 117 118 119 120     - 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136       ... This time, observe the ""perpendicular"" or the left-most numbers. The following are the perfect squares that show up (shown by - s):- 1, 4, 16, 121, 529, 4096, 17956, 139129, 609961, 4726276, 20720704, ... Their respective square roots are:- 1, 2, 4, 11, 23, 64, 134, 373, 781, 2174, 4552, ... The differences between consecutive terms of this sequence are:- 1, 2, 7, 12, 41, 70, 239, 408, 1393, 2378, ...      ---- (iii) And the differences between this sequence's (iii) terms are:- 1, 5, 5, 29, 29, 169, 169, 985, 985, ... Why do only these numbers pop up, that too in pairs of two ? Let's look at the vertical gap between two consecutive numbers:- 0, 1, 2, 9, 16, 57, 98, 337, 576, 1969, 3362, ... For example, the first perfect square -- $1$ , shows up in the first row. So, there is $0$ gap between the row containing the previous perfect square and that of $1$ . Similarly, $4$ comes $1$ row after $1$ , so it has a gap of $1$ , $16$ comes $2$ rows after $4$ , so it has a gap of $2$ , $121$ comes $9$ rows after $16$ , so it has a gap of $9$ , etc. This sequence's differences are:- 1, 1, 7, 7, 41, 41, 239, 239, 1393, 1393, ... Notice that this looks like the sequence (iii) [i.e., of the differences between consecutive terms of the square roots of the perfect squares, found in the left-most perpendicular column of the triangle.] 1, 2, 7, 12, 41, 70, 239, 408, 1393, 2378, ... 1, 1, 7, 7, 41, 41, 239, 239, 1393, 1393, ... The only variation being that all of the even $n$ th terms are replaced by the term that precedes them. Why is this? Let's observe the terms that got ""ignored"" [even $n$ th terms]:- 2, 12, 70, 408, 2378, ... Dividing this by 2, 1, 6, 35, 204, 1189, ... Here, after a bit of scrutiny, we observe that the formula for the $n$ th term of this sequence would be:- \begin{align*} T_n = 6 \cdot T_{n-1} - T_{n-2} \end{align*} where $T_0 = 0$ and $T_1 = 1$ . For example, $T_2$ will be 6 * 1 - 0 , $T_3$ will be 6 * 6 - 1 , $T_4$ will be 6 * 35 - 6 , etc. What is the reason behind this exact formula here? Searching the sequence up in OEIS, we get this , having the exact formula we just noticed. But it is also given there that $T_n ^ 2$ is a triangular number. Why is this true? Now let's look at the ones that did not get ""ignored"" [odd $n$ th terms]:- 1, 7, 41, 239, 1393, ... We observe that the formula for the $n$ th term of this sequence would be the same as the previous one:- \begin{align*} T_n = 6 \cdot T_{n-1} - T_{n-2} \end{align*} where $T_0 = -1$ and $T_1 = 1$ . Note that this time, $T_0 = -1$ , and not $0$ . The same questions emerge again, why is this true? What are the relationships among these numbers and formulae, and what more is special about them? Let's now look for primes in this perpendicular (shown by * s):- 1, 2, 7, 11, 29, 37, 67, 79, 137, 191, 211, 277, 379, 631, 821, 947, 991, 1129, 1327, 1597, 1831, 2017, 2081, 2347, 2557, 2851, 2927, 3571, 3917, 4561, 4657, 4951, 5051, 5779, 6217, 6329, ... The first few of them come clumped in pairs, but then the pattern changes and becomes confusing at best. I tried seeing if there is a pattern in the fact that some are equal to $3$ (shown by ! s), while some are equal to $1$ (shown by @ s) (mod $4$ ), but no luck again. There were many such false alarms, where the patterns ultimately broke apart. Could you try and explain why these primes show up, and what are some interesting relations / properties that you can come up with? I know this is a really long question, so it would be really helpful if you could answer or extend any aspect of any problem. Moreover, more properties and relationships that you can find related to this triangle are really appreciated. Thanks a lot for giving your time.","Setup Have a look at the Floyd's Triangle :- 1  2 3  4 5 6  7 8 9 10  11 12 13 14 15  16 17 18 19 20 21  22 23 24 25 26 27 28  29 30 31 32 33 34 35 36  37 38 39 40 41 42 43 44 45  46 47 48 49 50 51 52 53 54 55  56 57 58 59 60 61 62 63 64 65 66  67 68 69 70 71 72 73 74 75 76 77 78  79 80 81 82 83 84 85 86 87 88 89 90 91  92 93 94 95 96 97 98 99 100 101 102 103 104 105  106 107 108 109 110 111 112 113 114 115 116 117 118 119 120  121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136  ... Here, all the Natural Numbers are written consecutively, row-wise. Each row has a length of , where increments by in each succession. I noticed several properties of this triangle, related to a few of which I have questions. So, I have broken this post down into parts for related questions that I found the most perplexing. Part 1 Let's take the sum of each row. Their sequence would be:- 1, 5, 15, 34, 65, 111, 175, 260, 369, 505, 671, 870, 1105, 1379, 1695, 2056, ... which is given by the formula . If we take the averages of all the th and th terms (where is an odd number), we get the sequence :- (1 + 15) / 2, (15 + 65) / 2, (65 + 175) / 2, ...  or,  8, 40, 120, 272, 520, 888, ...       --- (i) Then, taking the sequence of the middle or the even th terms [( )th terms, where is odd], we get this :- 5, 34, 111, 260, 505, 870, ...       --- (ii) Subtracting the sequence (ii) of middle terms from the sequence (i) of the averages of the neighbouring extremes, we get:- 8 - 5, 40 - 34, 120 - 111, 272 - 12, 520 - 505, 888 - 870, ...  or,  3, 6, 9, 12, 15, 18, ... Why are multiples of 3 showing up here? Part 2 (Here's a smaller version of the same triangle, for your ease of viewing):- 1 - 2 3 * 4 5 6 * 7 8 9 10 - 11 12 13 14 15 * 16 17 18 19 20 21 * 22 23 24 25 26 27 28 - 29 30 31 32 33 34 35 36 * 37 38 39 40 41 42 43 44 45 * ... Have a look at the ""hypotenuse"" or the right-most numbers of the rows of the triangle. Notice that they are triangular numbers , given by the formula . Take a look at the pairs of nd and rd, th and th, th and th, ... th and th of these triangular numbers (shown above by * s). That is, (3, 6), (15, 21), (36, 45), (66, 78), ... Observe that, yet again, all of these numbers are divisible by 3. Written as multiples of 3, they are:- (3 * 1, 3 * 2), (3 * 5, 3 * 7), (3 * 12, 3 * 15), (3 * 22, 3 * 26), ... Here, the differences between the multiplicands in individual pairs are:- 2 - 1, 7 - 5, 13 - 12, 26 - 22, ...  or,  1, 2, 3, 4, 5, ... And their sums are:- 2 + 1, 7 + 5, 13 + 12, 26 + 22, ...  or,  3, 12, 27, 48, ...  or,  3 * 1^2, 3 * 2^2, 3 * 3^2, 3 * 4^2,... Also, observe the difference between the first term of the th pair, and the last term of the th pair (where ):- 15 - 6, 36 - 21, 66 - 45, ...  or,  9, 15, 21, ...  or,  3 * 3, 3 * 5, 3 * 7, ... The multiplicands of the differences are consecutive odd numbers. Moreover, the terms that we left out (denoted by - s):- 1, 10, 28, 55, 91, 136, ... also follow a pattern. The differences between this sequence's consecutive terms are:- 10 - 1, 28 - 10, 55 - 28, 91 - 55, 136 - 91, ...  or,  9, 18, 27, 36, 45, ... What is the reason behind these specific numbers (and mainly ) popping up? What is the intuitive reason and / or proof for why things are the way they are? Part 3 (The same triangle reproduced again):- @ * - 1   *   2 3     - 4 5 6 ! *   7 8 9 10 ! *   11 12 13 14 15     - 16 17 18 19 20 21       22 23 24 25 26 27 28 @ *   29 30 31 32 33 34 35 36 @ *   37 38 39 40 41 42 43 44 45       46 47 48 49 50 51 52 53 54 55       56 57 58 59 60 61 62 63 64 65 66 ! *   67 68 69 70 71 72 73 74 75 76 77 78 ! *   79 80 81 82 83 84 85 86 87 88 89 90 91       92 93 94 95 96 97 98 99 100 101 102 103 104 105       106 107 108 109 110 111 112 113 114 115 116 117 118 119 120     - 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136       ... This time, observe the ""perpendicular"" or the left-most numbers. The following are the perfect squares that show up (shown by - s):- 1, 4, 16, 121, 529, 4096, 17956, 139129, 609961, 4726276, 20720704, ... Their respective square roots are:- 1, 2, 4, 11, 23, 64, 134, 373, 781, 2174, 4552, ... The differences between consecutive terms of this sequence are:- 1, 2, 7, 12, 41, 70, 239, 408, 1393, 2378, ...      ---- (iii) And the differences between this sequence's (iii) terms are:- 1, 5, 5, 29, 29, 169, 169, 985, 985, ... Why do only these numbers pop up, that too in pairs of two ? Let's look at the vertical gap between two consecutive numbers:- 0, 1, 2, 9, 16, 57, 98, 337, 576, 1969, 3362, ... For example, the first perfect square -- , shows up in the first row. So, there is gap between the row containing the previous perfect square and that of . Similarly, comes row after , so it has a gap of , comes rows after , so it has a gap of , comes rows after , so it has a gap of , etc. This sequence's differences are:- 1, 1, 7, 7, 41, 41, 239, 239, 1393, 1393, ... Notice that this looks like the sequence (iii) [i.e., of the differences between consecutive terms of the square roots of the perfect squares, found in the left-most perpendicular column of the triangle.] 1, 2, 7, 12, 41, 70, 239, 408, 1393, 2378, ... 1, 1, 7, 7, 41, 41, 239, 239, 1393, 1393, ... The only variation being that all of the even th terms are replaced by the term that precedes them. Why is this? Let's observe the terms that got ""ignored"" [even th terms]:- 2, 12, 70, 408, 2378, ... Dividing this by 2, 1, 6, 35, 204, 1189, ... Here, after a bit of scrutiny, we observe that the formula for the th term of this sequence would be:- where and . For example, will be 6 * 1 - 0 , will be 6 * 6 - 1 , will be 6 * 35 - 6 , etc. What is the reason behind this exact formula here? Searching the sequence up in OEIS, we get this , having the exact formula we just noticed. But it is also given there that is a triangular number. Why is this true? Now let's look at the ones that did not get ""ignored"" [odd th terms]:- 1, 7, 41, 239, 1393, ... We observe that the formula for the th term of this sequence would be the same as the previous one:- where and . Note that this time, , and not . The same questions emerge again, why is this true? What are the relationships among these numbers and formulae, and what more is special about them? Let's now look for primes in this perpendicular (shown by * s):- 1, 2, 7, 11, 29, 37, 67, 79, 137, 191, 211, 277, 379, 631, 821, 947, 991, 1129, 1327, 1597, 1831, 2017, 2081, 2347, 2557, 2851, 2927, 3571, 3917, 4561, 4657, 4951, 5051, 5779, 6217, 6329, ... The first few of them come clumped in pairs, but then the pattern changes and becomes confusing at best. I tried seeing if there is a pattern in the fact that some are equal to (shown by ! s), while some are equal to (shown by @ s) (mod ), but no luck again. There were many such false alarms, where the patterns ultimately broke apart. Could you try and explain why these primes show up, and what are some interesting relations / properties that you can come up with? I know this is a really long question, so it would be really helpful if you could answer or extend any aspect of any problem. Moreover, more properties and relationships that you can find related to this triangle are really appreciated. Thanks a lot for giving your time.","(\mathbb{N}) n n 1 3 \frac{n(n^2 + 1)}{2} n (n + 2) n n n + 1 n \frac{n(n + 1)}{2} 2 3 5 6 8 9 (3n - 1) (3n) (n + 1) n n \in \mathbb{N} 3 1 0 1 4 1 1 1 16 2 4 2 121 9 16 9 n n n \begin{align*}
T_n = 6 \cdot T_{n-1} - T_{n-2}
\end{align*} T_0 = 0 T_1 = 1 T_2 T_3 T_4 T_n ^ 2 n n \begin{align*}
T_n = 6 \cdot T_{n-1} - T_{n-2}
\end{align*} T_0 = -1 T_1 = 1 T_0 = -1 0 3 1 4","['sequences-and-series', 'elementary-number-theory', 'discrete-mathematics', 'prime-numbers']"
15,how to prove that $ \lim_{n \to \infty} \sum_{k=1} ^n \left( \sqrt[p] {\frac{n^p+k^{p-1}}{n^p}} -1 \right) = \frac{1}{p^2}$ for all $p \in \mathbb{R}$,how to prove that  for all, \lim_{n \to \infty} \sum_{k=1} ^n \left( \sqrt[p] {\frac{n^p+k^{p-1}}{n^p}} -1 \right) = \frac{1}{p^2} p \in \mathbb{R},"I saw this problem $L:=\lim_{n \to \infty}\sum_{k=1} ^ n \left( \sqrt {\frac{n^2+k} {n^2}} -1 \right)$ and I was able to prove that the limit is $\frac{1}{4}$ , I noticed my proof work for all $p \in \mathbb{N}$ so I generalised the result for all $p \in \mathbb{N}$ . my proof : for all $p \in \mathbb{N}-\{1\}$ ( if $p=1$ the answer is obviously $1$ ) $$L:=\lim_{n \to \infty} \sum_{k=1} ^ n\left( \sqrt[p] {\frac{n^p+k^{p-1}}{n^p}} -1 \right) =\lim_{n \to \infty} \frac{1}{n}\sum_{k=1} ^ n\left( \sqrt[p] {{n^p+k^{p-1}}} -n \right)$$ since $(a^p -b^p)=(a-b)(a^{p-1} +a^{p-2}b+a^{p-3}b^2+ \dots+ b^{p-1})  \ \ \forall p \in \mathbb{N}$ $$L =\lim_{n \to \infty} \frac{1}{n} \sum_{k=1} ^ n  \left( \frac{k^{p-1}}{\sum_{i=0} ^{p-1} (\sqrt[p] {{n^p+k^{p-1}}})^i n^{p-1-i}  }      \right) $$ $$\lim_{n \to \infty} \frac{1}{n} \sum_{k=1} ^ n  \left( \frac{k^{p-1}}{\sum_{i=0} ^{p-1} (\sqrt[p] {{n^p+n^{p-1}}})^i n^{p-1-i}  }      \right) \leq L \leq \lim_{n \to \infty} \frac{1}{n} \sum_{k=1} ^ n  \left( \frac{k^{p-1}}{\sum_{i=0} ^{p-1} (\sqrt[p] {{n^p}})^i n^{p-1-i}  }      \right) $$ $$\lim_{n \to \infty}  \left( \frac{(1+\frac{1}{n})^{\frac{1}{p}} -1}{\frac{1}{n} }\right)  \sum_{k=1} ^ n  \left( \frac{k^{p-1}}{n^{p}  }      \right)          \leq L \leq \lim_{n \to \infty}  \sum_{k=1} ^ n  \left( \frac{k^{p-1}}{ pn^{p}  }      \right) $$ $\lim_{n \to \infty} \left( \frac{(1+\frac{1}{n})^{\frac{1}{p}} -1}{\frac{1}{n} }\right)$ is the definition of derivative of $ x^{\frac{1}{p}}$ at $1$ so it is equal to $\frac{1}{p}$ and $\lim_{n \to \infty} \frac{1}{n} \sum_{k=1} ^ n  \left( \frac{k}{n   }      \right)^{p-1} $ is the Riemann sum of $ \int_0 ^1 x^{p-1}dx =\frac{1}{p} $ . By squeeze theorem $L = \frac{1}{p^2}$ my question is: can this result be generalised for all $p \in \mathbb{R}$ ? I believe that the limit will still be $\frac{1}{p^2}$ for all $p \neq 0$ but I couldn't prove that I tried to turn $\lim_{n \to \infty} \sum_{k=1} ^n \left( \sqrt[p] {\frac{n^p+k^{p-1}}{n^p}} -1 \right)$ for all $p \in \mathbb{R}$ to integral but I couldn't do that.","I saw this problem and I was able to prove that the limit is , I noticed my proof work for all so I generalised the result for all . my proof : for all ( if the answer is obviously ) since is the definition of derivative of at so it is equal to and is the Riemann sum of . By squeeze theorem my question is: can this result be generalised for all ? I believe that the limit will still be for all but I couldn't prove that I tried to turn for all to integral but I couldn't do that.",L:=\lim_{n \to \infty}\sum_{k=1} ^ n \left( \sqrt {\frac{n^2+k} {n^2}} -1 \right) \frac{1}{4} p \in \mathbb{N} p \in \mathbb{N} p \in \mathbb{N}-\{1\} p=1 1 L:=\lim_{n \to \infty} \sum_{k=1} ^ n\left( \sqrt[p] {\frac{n^p+k^{p-1}}{n^p}} -1 \right) =\lim_{n \to \infty} \frac{1}{n}\sum_{k=1} ^ n\left( \sqrt[p] {{n^p+k^{p-1}}} -n \right) (a^p -b^p)=(a-b)(a^{p-1} +a^{p-2}b+a^{p-3}b^2+ \dots+ b^{p-1})  \ \ \forall p \in \mathbb{N} L =\lim_{n \to \infty} \frac{1}{n} \sum_{k=1} ^ n  \left( \frac{k^{p-1}}{\sum_{i=0} ^{p-1} (\sqrt[p] {{n^p+k^{p-1}}})^i n^{p-1-i}  }      \right)  \lim_{n \to \infty} \frac{1}{n} \sum_{k=1} ^ n  \left( \frac{k^{p-1}}{\sum_{i=0} ^{p-1} (\sqrt[p] {{n^p+n^{p-1}}})^i n^{p-1-i}  }      \right) \leq L \leq \lim_{n \to \infty} \frac{1}{n} \sum_{k=1} ^ n  \left( \frac{k^{p-1}}{\sum_{i=0} ^{p-1} (\sqrt[p] {{n^p}})^i n^{p-1-i}  }      \right)  \lim_{n \to \infty}  \left( \frac{(1+\frac{1}{n})^{\frac{1}{p}} -1}{\frac{1}{n} }\right)  \sum_{k=1} ^ n  \left( \frac{k^{p-1}}{n^{p}  }      \right)          \leq L \leq \lim_{n \to \infty}  \sum_{k=1} ^ n  \left( \frac{k^{p-1}}{ pn^{p}  }      \right)  \lim_{n \to \infty} \left( \frac{(1+\frac{1}{n})^{\frac{1}{p}} -1}{\frac{1}{n} }\right)  x^{\frac{1}{p}} 1 \frac{1}{p} \lim_{n \to \infty} \frac{1}{n} \sum_{k=1} ^ n  \left( \frac{k}{n   }      \right)^{p-1}   \int_0 ^1 x^{p-1}dx =\frac{1}{p}  L = \frac{1}{p^2} p \in \mathbb{R} \frac{1}{p^2} p \neq 0 \lim_{n \to \infty} \sum_{k=1} ^n \left( \sqrt[p] {\frac{n^p+k^{p-1}}{n^p}} -1 \right) p \in \mathbb{R},"['calculus', 'integration', 'sequences-and-series', 'limits', 'definite-integrals']"
16,Checking the Convergence of the sequence $a_n=\frac{1}{n}\left(1+\frac{1}{2}+\frac{1}{3}+....\frac{1}{n}\right)$ [duplicate],Checking the Convergence of the sequence  [duplicate],a_n=\frac{1}{n}\left(1+\frac{1}{2}+\frac{1}{3}+....\frac{1}{n}\right),"This question already has answers here : Test for the convergence of the sequence $S_n =\frac1n \left(1 + \frac{1}{2} + \frac{1}{3} + \cdots+ \frac{1}{n}\right)$ (4 answers) Closed 8 months ago . Check the Convergence of the sequence $a_n=\frac{1}{n}\left(1+\frac{1}{2}+\frac{1}{3}+....\frac{1}{n}\right)$ My effort: I actually took the help of inequality(not well known I guess) $$H_n=1+\frac{1}{2}+\frac{1}{3}+...+\frac{1}{n}<2\sqrt{n}, \forall n \in \mathbb{N}$$ Now we have $a_n \geq 0$ and $a_n=\frac{H_n}{n} < \frac{2\sqrt{n}}{n}=\frac{2}{\sqrt{n}}$ Thus we have $$0 \leq a_n <\frac{2}{\sqrt{n}}$$ By Sandwich Theorem, we end up with $$\lim a_n=0$$ But is there a way without Sandwich Theorem?","This question already has answers here : Test for the convergence of the sequence $S_n =\frac1n \left(1 + \frac{1}{2} + \frac{1}{3} + \cdots+ \frac{1}{n}\right)$ (4 answers) Closed 8 months ago . Check the Convergence of the sequence My effort: I actually took the help of inequality(not well known I guess) Now we have and Thus we have By Sandwich Theorem, we end up with But is there a way without Sandwich Theorem?","a_n=\frac{1}{n}\left(1+\frac{1}{2}+\frac{1}{3}+....\frac{1}{n}\right) H_n=1+\frac{1}{2}+\frac{1}{3}+...+\frac{1}{n}<2\sqrt{n}, \forall n \in \mathbb{N} a_n \geq 0 a_n=\frac{H_n}{n} < \frac{2\sqrt{n}}{n}=\frac{2}{\sqrt{n}} 0 \leq a_n <\frac{2}{\sqrt{n}} \lim a_n=0","['sequences-and-series', 'limits', 'convergence-divergence']"
17,Divergence of Mehler's Hermite polynomial series,Divergence of Mehler's Hermite polynomial series,,"According to Mehler's formula, $$ \sum\limits_{n=0}^{\infty}\left(\cfrac{\rho}{2}\right)^n\cfrac{H_n(x)H_n(y)}{n!}=\cfrac{1}{\sqrt{1-\rho^2}}\exp\left(-\cfrac{\rho^2(x^2+y^2)-2\rho x y}{1-\rho^2}\right), $$ when $|\rho|<1$ , where $H_n(x)$ are Hermite polynomials. My questions is about what happens when $|\rho|> 1$ . Is it possible to show that the series on the left-hand goes to $+\infty$ for all $x$ and $y$ ? What happens when $|\rho|=1?$ .","According to Mehler's formula, when , where are Hermite polynomials. My questions is about what happens when . Is it possible to show that the series on the left-hand goes to for all and ? What happens when .","
\sum\limits_{n=0}^{\infty}\left(\cfrac{\rho}{2}\right)^n\cfrac{H_n(x)H_n(y)}{n!}=\cfrac{1}{\sqrt{1-\rho^2}}\exp\left(-\cfrac{\rho^2(x^2+y^2)-2\rho x y}{1-\rho^2}\right),
 |\rho|<1 H_n(x) |\rho|> 1 +\infty x y |\rho|=1?","['sequences-and-series', 'divergent-series', 'orthogonal-polynomials', 'hermite-polynomials']"
18,Finding the asymptotic of the sequence $a_{n+1}=a_n+\frac{1}{f(a_n)}$,Finding the asymptotic of the sequence,a_{n+1}=a_n+\frac{1}{f(a_n)},"We define $f(x)$ be a differentiable function with $f^\prime\ge 0$ , $f^\prime$ bounded and $f\to+\infty$ when $x\to+\infty$ . Define the sequence $\{a_n\}$ as follows: $$a_0=1, a_{n+1}=a_n+\frac{1}{f(a_n)},n\in\mathbb{N}_+.$$ My question is, how can we find the asymptotic of $a_n$ ? For instance, if $f(x)=x$ , then clearly $f(x)$ satisfies the conditions and the sequence turned out to be $$a_{n+1}=a_n+\frac{1}{a_n},$$ which we may give an estimate that $a_n=\sqrt{2n}+o(\sqrt{2n})$ . However, what about a randomly chosen $f$ ? How can we compute the asymptotic of $\{a_n\}$ ? Thanks in advance.","We define be a differentiable function with , bounded and when . Define the sequence as follows: My question is, how can we find the asymptotic of ? For instance, if , then clearly satisfies the conditions and the sequence turned out to be which we may give an estimate that . However, what about a randomly chosen ? How can we compute the asymptotic of ? Thanks in advance.","f(x) f^\prime\ge 0 f^\prime f\to+\infty x\to+\infty \{a_n\} a_0=1, a_{n+1}=a_n+\frac{1}{f(a_n)},n\in\mathbb{N}_+. a_n f(x)=x f(x) a_{n+1}=a_n+\frac{1}{a_n}, a_n=\sqrt{2n}+o(\sqrt{2n}) f \{a_n\}","['sequences-and-series', 'recurrence-relations', 'closed-form']"
19,How to Rewrite an Infinite Sum for Easier Differentiability?,How to Rewrite an Infinite Sum for Easier Differentiability?,,"I have come across the following simplification $$ g(x)=\sum_{k\in\mathbb{Z}} \frac{e^{-xk^2 }}{2k+1}=\sum_{k\in\mathbb{Z}}\frac{e^{-xk^2 }}{1-4k^2} $$ To show this, we can compute its difference $$ \sum_{k\in\mathbb{Z}} \frac{e^{-xk^2 }}{2k+1}-\sum_{k\in\mathbb{Z}}\frac{e^{-xk^2 }}{1-4k^2}=\sum_{k\in\mathbb{Z}} \frac{2ke^{-xk^2}}{4k^2-1} =0 $$ since opposite signed terms cancel out. However, my question is, provided we do not know the right-hand side a priori , how would one go about rewriting the expression on the left to get the expression on the right? The particular motivation behind this rewriting is that, in that form, it's relatively easy to show that $g$ satisfies $$ g(x)+4g'(x)=\sum_{k\in\mathbb{Z}}e^{-xk^2 }. $$ Any ideas?","I have come across the following simplification To show this, we can compute its difference since opposite signed terms cancel out. However, my question is, provided we do not know the right-hand side a priori , how would one go about rewriting the expression on the left to get the expression on the right? The particular motivation behind this rewriting is that, in that form, it's relatively easy to show that satisfies Any ideas?","
g(x)=\sum_{k\in\mathbb{Z}} \frac{e^{-xk^2 }}{2k+1}=\sum_{k\in\mathbb{Z}}\frac{e^{-xk^2 }}{1-4k^2}
 
\sum_{k\in\mathbb{Z}} \frac{e^{-xk^2 }}{2k+1}-\sum_{k\in\mathbb{Z}}\frac{e^{-xk^2 }}{1-4k^2}=\sum_{k\in\mathbb{Z}} \frac{2ke^{-xk^2}}{4k^2-1} =0
 g 
g(x)+4g'(x)=\sum_{k\in\mathbb{Z}}e^{-xk^2 }.
","['sequences-and-series', 'algebra-precalculus', 'exponential-function']"
20,$\beta_k=\sum_{n=k^2}^{k^2+2k}\alpha_n$ where $|\alpha_n|\leq\frac{1}{n}.$ If $\sum\beta_k$ converges then $\sum\alpha_n$ converges.,where  If  converges then  converges.,\beta_k=\sum_{n=k^2}^{k^2+2k}\alpha_n |\alpha_n|\leq\frac{1}{n}. \sum\beta_k \sum\alpha_n,"Let $(\alpha_n)_{n=1}^{\infty}$ be an infinite sequence of reals which satisfies: $\forall n \in \mathbb{N} \space \space :|\alpha_n| \leq \frac{1}{n}$ . Denote $\beta_k = \sum\limits_{n=k^2}^{k^2+2k} \alpha_n$ , for each $k \in \mathbb{N}$ . If $\sum\beta_k$ converges, then $\sum\alpha_n$ converges. I observed that the sequence of partial sums of the series $\sum\beta_k$ is a subsequence of those of $\sum\alpha_n$ . Additionally, I see the relation between the assumption regarding $(\alpha_n)_{n=1}^{\infty}$ to the fact that $b_k$ is a sum of exactly $2k+1$ elements of $(\alpha_n)_{n=1}^{\infty}$ . However, I struggle to see how this is actually true (intuitively speaking) since, generally, I could've only deduced that (without the additional assumption about $(\alpha_n)$ ) if $2k+1$ was bounded, which of course is not. I'm also curious to understand in what other cases similar assumptions about $(\alpha_n)$ would follow the same conclusion, and hence I hope to get some ideas about the proof of this particular case. Thanks","Let be an infinite sequence of reals which satisfies: . Denote , for each . If converges, then converges. I observed that the sequence of partial sums of the series is a subsequence of those of . Additionally, I see the relation between the assumption regarding to the fact that is a sum of exactly elements of . However, I struggle to see how this is actually true (intuitively speaking) since, generally, I could've only deduced that (without the additional assumption about ) if was bounded, which of course is not. I'm also curious to understand in what other cases similar assumptions about would follow the same conclusion, and hence I hope to get some ideas about the proof of this particular case. Thanks",(\alpha_n)_{n=1}^{\infty} \forall n \in \mathbb{N} \space \space :|\alpha_n| \leq \frac{1}{n} \beta_k = \sum\limits_{n=k^2}^{k^2+2k} \alpha_n k \in \mathbb{N} \sum\beta_k \sum\alpha_n \sum\beta_k \sum\alpha_n (\alpha_n)_{n=1}^{\infty} b_k 2k+1 (\alpha_n)_{n=1}^{\infty} (\alpha_n) 2k+1 (\alpha_n),"['real-analysis', 'calculus', 'sequences-and-series']"
21,Evaluating the series $\displaystyle{\sum_{n=1}^\infty\binom{n}{n/2}\frac{(-1)^{n}}{n(2a)^n}}$,Evaluating the series,\displaystyle{\sum_{n=1}^\infty\binom{n}{n/2}\frac{(-1)^{n}}{n(2a)^n}},"I encountered the following series while evaluating an integral \begin{equation} \sum_{n=1}^\infty\binom{n}{n/2}\frac{(-1)^{n}}{n(2a)^n}, \quad a\in\mathbb{R} \end{equation} and am looking for a closed form. I have looked up generating functions and found some close candidates such as, \begin{equation} \sum_{n=1}^\infty\binom{2n}{n}\frac{x^n}{4^nn} = 2\log\left(\frac{2}{1+\sqrt{1-x}}\right) \end{equation} but I can't figure out how to deal with the $\binom{n}{n/2}$ term. Looking at the power series for $(1+x)^n$ , I assume finding such a function may be difficult, but I hope a closed form exists. I will be happy to add my evaluation of the original integral up to the point where the series appears, if that may be necessary. Thank you in advance. Edit: Here is the integral I was evaluating, $$J(a)=\int_0^{\pi/2}\log\left(1+\frac{\sin x}{a}\right)\ dx,\quad a\in\mathbb{R}$$ which comes from this post, and the derivations of the series are in my answer there. I hope this helps @ClaudeLeibovici.","I encountered the following series while evaluating an integral and am looking for a closed form. I have looked up generating functions and found some close candidates such as, but I can't figure out how to deal with the term. Looking at the power series for , I assume finding such a function may be difficult, but I hope a closed form exists. I will be happy to add my evaluation of the original integral up to the point where the series appears, if that may be necessary. Thank you in advance. Edit: Here is the integral I was evaluating, which comes from this post, and the derivations of the series are in my answer there. I hope this helps @ClaudeLeibovici.","\begin{equation}
\sum_{n=1}^\infty\binom{n}{n/2}\frac{(-1)^{n}}{n(2a)^n}, \quad a\in\mathbb{R}
\end{equation} \begin{equation}
\sum_{n=1}^\infty\binom{2n}{n}\frac{x^n}{4^nn}
= 2\log\left(\frac{2}{1+\sqrt{1-x}}\right)
\end{equation} \binom{n}{n/2} (1+x)^n J(a)=\int_0^{\pi/2}\log\left(1+\frac{\sin x}{a}\right)\ dx,\quad a\in\mathbb{R}","['sequences-and-series', 'generating-functions', 'closed-form']"
22,Solving the infinite series [closed],Solving the infinite series [closed],,"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 11 months ago . Improve this question Let $a_1,a_2...$ and $b_1,b_2...$ be sequences of positive real numbers such that $a_1=b_1=1$ and $b_n=b_{n-1}a_n-2$ for $n=2,3...$ Assume that the sequence $b_j$ is bounded, find $$S=\sum_{n=1}^\infty \frac{1}{a_1a_2...a_n}$$ I tried to guess a sequence but couldn't continue like this. The biggest difficulty I'm facing is with $b_n$ .","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 11 months ago . Improve this question Let and be sequences of positive real numbers such that and for Assume that the sequence is bounded, find I tried to guess a sequence but couldn't continue like this. The biggest difficulty I'm facing is with .","a_1,a_2... b_1,b_2... a_1=b_1=1 b_n=b_{n-1}a_n-2 n=2,3... b_j S=\sum_{n=1}^\infty \frac{1}{a_1a_2...a_n} b_n","['sequences-and-series', 'summation']"
23,Show series $\sum_{k=1}^{\infty} \frac{(2k-2) !\left(\frac{1}{4}\right)^{k-1}\left(1-\frac{1}{4}\right)^k}{k !(k-1) !}=1.$,Show series,\sum_{k=1}^{\infty} \frac{(2k-2) !\left(\frac{1}{4}\right)^{k-1}\left(1-\frac{1}{4}\right)^k}{k !(k-1) !}=1.,"I have the following series, together with its result $$\sum_{k=1}^{\infty} \frac{(2k-2) !\left(\frac{1}{4}\right)^{k-1}\left(1-\frac{1}{4}\right)^k}{k !(k-1) !}=1.$$ This can be further simplified to $$\sum_{k=1}^{\infty} \frac{2^{-4 k} \times 3^k\left(\begin{array}{c} 2 k \\ k \end{array}\right)}{2 k-1}=\frac{1}{2}.$$ It is simple enough to verify that the series is (absolutely) convergent (ratio test), however, I have no idea how to prove the equality. Any ideas for a solution? Any tips for what could usually come in useful in this case?","I have the following series, together with its result This can be further simplified to It is simple enough to verify that the series is (absolutely) convergent (ratio test), however, I have no idea how to prove the equality. Any ideas for a solution? Any tips for what could usually come in useful in this case?","\sum_{k=1}^{\infty} \frac{(2k-2) !\left(\frac{1}{4}\right)^{k-1}\left(1-\frac{1}{4}\right)^k}{k !(k-1) !}=1. \sum_{k=1}^{\infty} \frac{2^{-4 k} \times 3^k\left(\begin{array}{c}
2 k \\
k
\end{array}\right)}{2 k-1}=\frac{1}{2}.","['calculus', 'integration', 'sequences-and-series', 'analysis', 'taylor-expansion']"
24,"Proof for $\sqrt{2}$, $\sqrt{3}$, $\sqrt{5}$ can never be the terms of a single arithmetic progression with non zero common difference.","Proof for , ,  can never be the terms of a single arithmetic progression with non zero common difference.",\sqrt{2} \sqrt{3} \sqrt{5},"Proof for $\sqrt{2}$ , $\sqrt{3}$ , $\sqrt{5}$ can never be the terms of a single arithmetic progression with non zero common difference. Here is what I have tried. Let: $$ax +c=\sqrt{2}$$ $$bx +c=\sqrt{3}$$ $$dx +c=\sqrt{5}$$ $$\frac{\sqrt2-c}{a}=\frac{\sqrt3-c}{b}=\frac{\sqrt5-c}{d}$$ What property can I use next?","Proof for , , can never be the terms of a single arithmetic progression with non zero common difference. Here is what I have tried. Let: What property can I use next?",\sqrt{2} \sqrt{3} \sqrt{5} ax +c=\sqrt{2} bx +c=\sqrt{3} dx +c=\sqrt{5} \frac{\sqrt2-c}{a}=\frac{\sqrt3-c}{b}=\frac{\sqrt5-c}{d},"['sequences-and-series', 'arithmetic-progressions']"
25,What's the result of $\sum_{k=1}^{\infty} {k \cdot \left[ (1-2^{-k})^n - (1-2^{-k+1})^n \right]}$?,What's the result of ?,\sum_{k=1}^{\infty} {k \cdot \left[ (1-2^{-k})^n - (1-2^{-k+1})^n \right]},"Came from the problem ""Expectation of maximum times of doing $n$ times of flipping coin tests until getting the reverse side"". The probability of maximum times of flipping among $n$ independent tests should be: $$ \begin{align} \text{Pr}(X = 1) &= \frac{1}{2^n} \\ \text{Pr}(X = 2) &= \sum_{i=1}^n {}_n C_i \left(\frac{1}{2^2} \right)^i \left(\frac{1}{2} \right)^{n-i} = \left(\frac{3}{4} \right)^n - \left(\frac{1}{2} \right)^n \\ \text{Pr}(X = 3) &= \sum_{i=1}^n {}_n C_i \left(\frac{1}{2^3} \right)^i \left(\frac{1}{2} + \frac{1}{2^2} \right)^{n-i} = \left(\frac{7}{8} \right)^n - \left(\frac{3}{4} \right)^n \\ & \cdots \\ \text{Pr}(X = k) &= \sum_{i=1}^n {}_n C_i \left(\frac{1}{2^k} \right)^i \left(\sum_{j=1}^{k-1}\frac{1}{2^j} \right)^{n-i} = \left(\frac{2^k-1}{2^k} \right)^n - \left(\frac{2^{k-1}-1}{2^{k-1}} \right)^n \end{align} $$ Therefore, I get the sum of series: $$ E(X) = \sum_{k=1}^{\infty} k \cdot P(X=k) = \sum_{k=1}^{\infty} {k \cdot \left[ (1-2^{-k})^n - (1-2^{-k+1})^n \right]} $$ See also Expectation of the maximum of i.i.d. geometric random variables for similar problem. Unfortunately, there seems to be no closed-form solution to this problem.","Came from the problem ""Expectation of maximum times of doing times of flipping coin tests until getting the reverse side"". The probability of maximum times of flipping among independent tests should be: Therefore, I get the sum of series: See also Expectation of the maximum of i.i.d. geometric random variables for similar problem. Unfortunately, there seems to be no closed-form solution to this problem.","n n 
\begin{align}
\text{Pr}(X = 1) &= \frac{1}{2^n}
\\
\text{Pr}(X = 2) &= \sum_{i=1}^n {}_n C_i \left(\frac{1}{2^2} \right)^i \left(\frac{1}{2} \right)^{n-i} = \left(\frac{3}{4} \right)^n - \left(\frac{1}{2} \right)^n
\\
\text{Pr}(X = 3) &= \sum_{i=1}^n {}_n C_i \left(\frac{1}{2^3} \right)^i \left(\frac{1}{2} + \frac{1}{2^2} \right)^{n-i} = \left(\frac{7}{8} \right)^n - \left(\frac{3}{4} \right)^n
\\
& \cdots
\\
\text{Pr}(X = k) &= \sum_{i=1}^n {}_n C_i \left(\frac{1}{2^k} \right)^i \left(\sum_{j=1}^{k-1}\frac{1}{2^j} \right)^{n-i} = \left(\frac{2^k-1}{2^k} \right)^n - \left(\frac{2^{k-1}-1}{2^{k-1}} \right)^n
\end{align}
 
E(X) = \sum_{k=1}^{\infty} k \cdot P(X=k) = \sum_{k=1}^{\infty} {k \cdot \left[ (1-2^{-k})^n - (1-2^{-k+1})^n \right]}
",['sequences-and-series']
26,"Find the number of distinct integers in the collection of first $500$ terms of each of the arithemetic progressions $\{1,4,...\}$ and $\{9,14,...\}$",Find the number of distinct integers in the collection of first  terms of each of the arithemetic progressions  and,"500 \{1,4,...\} \{9,14,...\}","Let $1,4,...$ and $9,14,...$ be two arithmetic progressions. Then the number of distinct integers in the collection of first $500$ terms of each of progressions is $$A. 833,\space  B. 835,\space C.837 ,\space D. 901$$ My solution goes like this: The two A.P.'s general term might be represented as $$1+(n_1-1)3=9+(n_2-1)5\implies 3n_1-5n_2=6\implies 3(n_1-2)=5n_2.$$ Hence, $3|n_2\implies n_2=3k$ and so, $3(n_1-2)=5n_2=15k\implies n_1-2=5k\implies n_1=5k+2.$ Now, $5k+2\leq 500\implies 5k\leq 498\implies k\leq 99.$ Due to this, we may conclude, $99$ terms of both the A.P.'s are similar. So, total number of common terms in both the A.P's is : $99+99=198$ and the number of distinct terms in both the A.P's in total is: $1000-198=802.$ However, I feel something's wrong with my solution, as my solution, is not matching with any of the options. But I don’t understand where is the solution going wrong, if that's the case. I am not quite getting it...","Let and be two arithmetic progressions. Then the number of distinct integers in the collection of first terms of each of progressions is My solution goes like this: The two A.P.'s general term might be represented as Hence, and so, Now, Due to this, we may conclude, terms of both the A.P.'s are similar. So, total number of common terms in both the A.P's is : and the number of distinct terms in both the A.P's in total is: However, I feel something's wrong with my solution, as my solution, is not matching with any of the options. But I don’t understand where is the solution going wrong, if that's the case. I am not quite getting it...","1,4,... 9,14,... 500 A. 833,\space  B. 835,\space C.837 ,\space D. 901 1+(n_1-1)3=9+(n_2-1)5\implies 3n_1-5n_2=6\implies 3(n_1-2)=5n_2. 3|n_2\implies n_2=3k 3(n_1-2)=5n_2=15k\implies n_1-2=5k\implies n_1=5k+2. 5k+2\leq 500\implies 5k\leq 498\implies k\leq 99. 99 99+99=198 1000-198=802.","['sequences-and-series', 'solution-verification', 'arithmetic-progressions']"
27,On a generalization of Chudnovsky's $\pi$ formula,On a generalization of Chudnovsky's  formula,\pi,"Let $q=e^{2\pi i\tau}$ and $$E_2(\tau)=1-24\sum_{n=1}^\infty n\frac{q^n}{1-q^n},$$ $$E_4(\tau)=1+240\sum_{n=1}^\infty n^3\frac{q^n}{1-q^n},$$ $$E_6(\tau)=1-504\sum_{n=1}^\infty n^5\frac{q^n}{1-q^n},$$ $$J(\tau)=\frac{E_4(\tau)^3}{E_4(\tau)^3-E_6(\tau)^2},$$ $$s_2(\tau)=\frac{E_4(\tau)}{E_6(\tau)}\left(E_2(\tau)-\frac{3}{\pi \operatorname{Im}(\tau)}\right).$$ The paper https://arxiv.org/abs/1809.00533 proves that $$\frac{1}{2\pi\operatorname{Im}(\tau)}\sqrt{\frac{J(\tau)}{J(\tau)-1}}=\sum_{n=0}^\infty \left(\frac{1-s_2(\tau)}{6}+n\right)\frac{(6n)!}{(3n)!n!^3}\frac{1}{(1728J(\tau))^n}$$ for $\operatorname{Im}(\tau)\gt 1.25$ where $√$ is the principal branch of the square root , i.e. it is the square root function ""using"" the principal complex argument , the one ranging from $-\pi$ to $\pi$ . Consequently, this principal square root function has a branch cut at the negative real axis. Obviously one can choose another square root function, the branch cut can be elsewhere, for example it can be the ray emanating from $0$ and going in the direction of $i$ towards $i\infty$ . On p. 39 of the linked paper, the author argues that ""Thus we still have to prove for any $\tau$ with $\operatorname{Im}(\tau) \gt 1.25$ that our result doesn’t contain any hidden complex roots of unity: We choose $\tau_8=\frac{i\sqrt{8}}{2}$ . Here we get that $q = e^{2\pi i\tau_8} = e^{-2π\sqrt{2}}$ is a real number. Thus (from Thm. 4.5) both $J(\tau_8)$ and $s_2(\tau_8)$ are also real-valued. The approximations together with the error estimates from Thm. 5.1 and 5.3 tell usthat both $J(\tau_8)$ and $\frac{1−s_2(\tau_8)}{6}$ are positive real numbers. This shows that all quantities in the equation of Thm. 9.7 are real-valued and positive at $\tau=\tau_8$ . The region $\operatorname{Im}(\tau) \gt 1.25$ is connected, both sides of the equation depend continuously on $\tau$ and are not zero. This proves that the equation is exact... "" What does he mean by ""depend continuously on $\tau$ ?"" What theorem does the text in bold even refer to? When I saw ""connected"", ""continuously"", it reminded me of the identity theorem, but reuns commented that $\frac{1}{2\pi\operatorname{Im}(\tau)}\sqrt{\frac{J(\tau)}{J(\tau)-1}}$ isn't holomorphic anywhere. It seems that the author proved the theorem only for some square root function, not necessarily the principal one. I can't see how choosing just one point suffices to determine the complex square root function. I took a look at the original paper of the Chudnovsky brothers. They didn't consider the equality for arbitrary $\tau$ with $\operatorname{Im}(\tau)\gt 1.25$ , but they considered $\tau$ at imaginary quadratic irrationals at which $J(\tau)$ is real , so they didn't have to take care about these subtleties.","Let and The paper https://arxiv.org/abs/1809.00533 proves that for where is the principal branch of the square root , i.e. it is the square root function ""using"" the principal complex argument , the one ranging from to . Consequently, this principal square root function has a branch cut at the negative real axis. Obviously one can choose another square root function, the branch cut can be elsewhere, for example it can be the ray emanating from and going in the direction of towards . On p. 39 of the linked paper, the author argues that ""Thus we still have to prove for any with that our result doesn’t contain any hidden complex roots of unity: We choose . Here we get that is a real number. Thus (from Thm. 4.5) both and are also real-valued. The approximations together with the error estimates from Thm. 5.1 and 5.3 tell usthat both and are positive real numbers. This shows that all quantities in the equation of Thm. 9.7 are real-valued and positive at . The region is connected, both sides of the equation depend continuously on and are not zero. This proves that the equation is exact... "" What does he mean by ""depend continuously on ?"" What theorem does the text in bold even refer to? When I saw ""connected"", ""continuously"", it reminded me of the identity theorem, but reuns commented that isn't holomorphic anywhere. It seems that the author proved the theorem only for some square root function, not necessarily the principal one. I can't see how choosing just one point suffices to determine the complex square root function. I took a look at the original paper of the Chudnovsky brothers. They didn't consider the equality for arbitrary with , but they considered at imaginary quadratic irrationals at which is real , so they didn't have to take care about these subtleties.","q=e^{2\pi i\tau} E_2(\tau)=1-24\sum_{n=1}^\infty n\frac{q^n}{1-q^n}, E_4(\tau)=1+240\sum_{n=1}^\infty n^3\frac{q^n}{1-q^n}, E_6(\tau)=1-504\sum_{n=1}^\infty n^5\frac{q^n}{1-q^n}, J(\tau)=\frac{E_4(\tau)^3}{E_4(\tau)^3-E_6(\tau)^2}, s_2(\tau)=\frac{E_4(\tau)}{E_6(\tau)}\left(E_2(\tau)-\frac{3}{\pi \operatorname{Im}(\tau)}\right). \frac{1}{2\pi\operatorname{Im}(\tau)}\sqrt{\frac{J(\tau)}{J(\tau)-1}}=\sum_{n=0}^\infty \left(\frac{1-s_2(\tau)}{6}+n\right)\frac{(6n)!}{(3n)!n!^3}\frac{1}{(1728J(\tau))^n} \operatorname{Im}(\tau)\gt 1.25 √ -\pi \pi 0 i i\infty \tau \operatorname{Im}(\tau) \gt 1.25 \tau_8=\frac{i\sqrt{8}}{2} q = e^{2\pi i\tau_8} = e^{-2π\sqrt{2}} J(\tau_8) s_2(\tau_8) J(\tau_8) \frac{1−s_2(\tau_8)}{6} \tau=\tau_8 \operatorname{Im}(\tau) \gt 1.25 \tau \tau \frac{1}{2\pi\operatorname{Im}(\tau)}\sqrt{\frac{J(\tau)}{J(\tau)-1}} \tau \operatorname{Im}(\tau)\gt 1.25 \tau J(\tau)","['sequences-and-series', 'complex-analysis', 'pi', 'modular-function']"
28,"Interchanging summations with complicated, nested indices","Interchanging summations with complicated, nested indices",,"I have a question regarding interchanging the order of three nested summations. My expression looks like \begin{align} \sum_{n=0}^\infty \sum_{k=0}^n \sum_{\nu=0}^{4n-2k}\frac{C_{nk\nu}}{k!(n-k)!}\binom{4n-2k}{\nu}, \end{align} where $C_{nk\nu}$ is a term depending on the three indices which, for the purposes of this question is irrelevant. What I want to do (assuming convergence) is to put the $\nu$ sum to the far most left, however I am not sure about the proper summation indices after interchanging the sums. For instance, I know that due to the binomial coefficient $\binom{4n-2k}{\nu}$ and the $(n-k)!$ factor we have the following summation constraints \begin{align} n-k\geq 0 \hspace{5mm} \Longrightarrow k \leq n, \end{align} \begin{align} 4n-2k-\nu\geq 0 \hspace{5mm} \Longrightarrow k \leq \dfrac{4n-\nu}{2}. \end{align} From which I can ""guess"" the new summation indices after interchanging the $k  \leftrightarrow \nu$ sums: \begin{align} \sum_{n=0}^\infty \sum_{k=0}^n \sum_{\nu=0}^{4n-2k}\frac{C_{nk\nu}}{k!(n-k)!}\binom{4n-2k}{\nu}=\sum_{n=0}^\infty \sum_{\nu=0}^\infty \sum_{k=0}^{\max\left(\lfloor \frac{4n-\nu}{2}\rfloor,n\right)}\frac{C_{nk\nu}}{k!(n-k)!}\binom{4n-2k}{\nu}, \end{align} However this is only true for the cases when $n=0$ and $\forall \ \nu$ but for instance when $n=1$ and $\nu=0$ , $\lfloor \dfrac{4(1)-0}{2} \rfloor=\lfloor 2 \rfloor = 2$ so the $k$ sum will run up to $2$ but then the term $(n-k)!=(1-(2))!=(-1)!$ is undefined so the upper limit that I put is correct for some values but incorrect for others, I have been trying to do some modifications to my upper limit but so far I have failed. Do you have any suggestions to properly flip the summations? Thanks in advance :)","I have a question regarding interchanging the order of three nested summations. My expression looks like where is a term depending on the three indices which, for the purposes of this question is irrelevant. What I want to do (assuming convergence) is to put the sum to the far most left, however I am not sure about the proper summation indices after interchanging the sums. For instance, I know that due to the binomial coefficient and the factor we have the following summation constraints From which I can ""guess"" the new summation indices after interchanging the sums: However this is only true for the cases when and but for instance when and , so the sum will run up to but then the term is undefined so the upper limit that I put is correct for some values but incorrect for others, I have been trying to do some modifications to my upper limit but so far I have failed. Do you have any suggestions to properly flip the summations? Thanks in advance :)","\begin{align}
\sum_{n=0}^\infty \sum_{k=0}^n \sum_{\nu=0}^{4n-2k}\frac{C_{nk\nu}}{k!(n-k)!}\binom{4n-2k}{\nu},
\end{align} C_{nk\nu} \nu \binom{4n-2k}{\nu} (n-k)! \begin{align}
n-k\geq 0 \hspace{5mm} \Longrightarrow k \leq n,
\end{align} \begin{align}
4n-2k-\nu\geq 0 \hspace{5mm} \Longrightarrow k \leq \dfrac{4n-\nu}{2}.
\end{align} k  \leftrightarrow \nu \begin{align}
\sum_{n=0}^\infty \sum_{k=0}^n \sum_{\nu=0}^{4n-2k}\frac{C_{nk\nu}}{k!(n-k)!}\binom{4n-2k}{\nu}=\sum_{n=0}^\infty \sum_{\nu=0}^\infty \sum_{k=0}^{\max\left(\lfloor \frac{4n-\nu}{2}\rfloor,n\right)}\frac{C_{nk\nu}}{k!(n-k)!}\binom{4n-2k}{\nu},
\end{align} n=0 \forall \ \nu n=1 \nu=0 \lfloor \dfrac{4(1)-0}{2} \rfloor=\lfloor 2 \rfloor = 2 k 2 (n-k)!=(1-(2))!=(-1)!","['sequences-and-series', 'summation', 'power-series', 'index-notation']"
29,Proving a trigonometric finite sum $\sum_{k=1}^N(-1)^k(\cos \frac{k\pi}{N})^{N-m}(\sin\frac{k\pi}{N})^m=(-1)^{m/2}\frac{N}{2^{N-1}}$,Proving a trigonometric finite sum,\sum_{k=1}^N(-1)^k(\cos \frac{k\pi}{N})^{N-m}(\sin\frac{k\pi}{N})^m=(-1)^{m/2}\frac{N}{2^{N-1}},"How to prove this following formula? $\sum_{k=1}^N(-1)^k(\cos \frac{k\pi}{N})^{N-m}(\sin\frac{k\pi}{N})^m=(-1)^{m/2}\frac{N}{2^{N-1}}$ for m is even, and $0$ for m is odd. If we know $\sum_{k=1}^N(-1)^k(\cos\frac{k\pi}{N})^m=N/2^{N-1}$ for $m=N$ , and $=-1/2(1-(-1)^{N+m})$ for $m<N$ . I have some ideas for this problem, but all fail. I tried Abel transformation or recursion. Maybe others ways can solve, like residual theory, but I'm not familiar with it. So I ask for help about this question. From the given series, Abel transformation is easy to take. That is, one series is $(-1)^k*(\cos\frac{k\pi}{N})^{N-m}$ and the other is $(\sin\frac{k\pi}{N})^m$ . But it doesn't work, because, I don't know the truncated sum for the first series, which is a necessary condition for Abel transformation calculation. (Update on 20230224) I want to add some notes on the origin of these formulas. I encounter this identity when I want to calculate the witness for GHZ state as shown in doi:10.1103/PhysRevA.76.030305 and the following picture: I hope this note would be helpful for future readers.","How to prove this following formula? for m is even, and for m is odd. If we know for , and for . I have some ideas for this problem, but all fail. I tried Abel transformation or recursion. Maybe others ways can solve, like residual theory, but I'm not familiar with it. So I ask for help about this question. From the given series, Abel transformation is easy to take. That is, one series is and the other is . But it doesn't work, because, I don't know the truncated sum for the first series, which is a necessary condition for Abel transformation calculation. (Update on 20230224) I want to add some notes on the origin of these formulas. I encounter this identity when I want to calculate the witness for GHZ state as shown in doi:10.1103/PhysRevA.76.030305 and the following picture: I hope this note would be helpful for future readers.",\sum_{k=1}^N(-1)^k(\cos \frac{k\pi}{N})^{N-m}(\sin\frac{k\pi}{N})^m=(-1)^{m/2}\frac{N}{2^{N-1}} 0 \sum_{k=1}^N(-1)^k(\cos\frac{k\pi}{N})^m=N/2^{N-1} m=N =-1/2(1-(-1)^{N+m}) m<N (-1)^k*(\cos\frac{k\pi}{N})^{N-m} (\sin\frac{k\pi}{N})^m,"['sequences-and-series', 'trigonometric-series']"
30,Prove that $\lim_{n\to\infty} a_n=0$.,Prove that .,\lim_{n\to\infty} a_n=0,"Let $a_n>0$ such that $$\lim_{n\to\infty} \left(\frac{a_{n+1}}{a_n}\right)^n<1.$$ Prove that $\lim\limits_{n\to\infty}a_n=0$ . Initially, I tried: $$\begin{split} \lim_{n\to\infty} \left(\frac{a_{n+1}}{a_n}\right)^n<1 &\implies \lim_{n\to\infty} e^{\ln\left(\dfrac{a_{n+1}}{a_n}\right)^n}<e^0\\ &\implies \lim_{n\to\infty} e^{\frac{1}{n}\ln\left(\frac{a_{n+1}}{a_n}\right)}<e^0\\ &\implies \displaystyle\lim_{n\to\infty} \frac{1}{n}\ln\left(\frac{a_{n+1}}{a_n}\right)<0 \end{split}$$ I got slighty desparate for an answer so I assumed that the limit $\displaystyle\lim_{n\to\infty} \left(\frac{a_{n+1}}{a_n}\right)$ exists. Since the limit exists and $a_n>0$ then: $$ \displaystyle\lim_{n\to\infty} \left(\frac{a_{n+1}}{a_n}\right) = \displaystyle\lim_{n\to\infty} (a_n)^\frac{1}{n} $$ Combining this with the inequality results in: $$ \displaystyle\lim_{n\to\infty}\ln(a_n)<0 $$ If anyone has any suggestions, I'll gladly listen. Thanks for the help!","Let such that Prove that . Initially, I tried: I got slighty desparate for an answer so I assumed that the limit exists. Since the limit exists and then: Combining this with the inequality results in: If anyone has any suggestions, I'll gladly listen. Thanks for the help!","a_n>0 \lim_{n\to\infty} \left(\frac{a_{n+1}}{a_n}\right)^n<1. \lim\limits_{n\to\infty}a_n=0 \begin{split}
\lim_{n\to\infty} \left(\frac{a_{n+1}}{a_n}\right)^n<1 &\implies \lim_{n\to\infty} e^{\ln\left(\dfrac{a_{n+1}}{a_n}\right)^n}<e^0\\ &\implies \lim_{n\to\infty} e^{\frac{1}{n}\ln\left(\frac{a_{n+1}}{a_n}\right)}<e^0\\ &\implies \displaystyle\lim_{n\to\infty} \frac{1}{n}\ln\left(\frac{a_{n+1}}{a_n}\right)<0
\end{split} \displaystyle\lim_{n\to\infty} \left(\frac{a_{n+1}}{a_n}\right) a_n>0 
\displaystyle\lim_{n\to\infty} \left(\frac{a_{n+1}}{a_n}\right) = \displaystyle\lim_{n\to\infty} (a_n)^\frac{1}{n}
 
\displaystyle\lim_{n\to\infty}\ln(a_n)<0
","['calculus', 'sequences-and-series', 'limits']"
31,Inverse Fibonacci sequence,Inverse Fibonacci sequence,,"I was having fun with Fibonacci numbers, and I had the idea to consider the sequence $ F_n=F_{n-1}^{-1}+F_{n-2}^{-1} $ instead. I wrote a simple program to compute the first terms and the sequence seemed chaotic, although converging to $\sqrt{2}$ whatever $F_0$ and $F_1$ were. ( $F_0,F_1\neq0$ ). How can I prove that the sequence indeed converges, and it converges to $\sqrt{2}$ ? Is it hopeless to try and find a closed-term formula for $F_n$ ?","I was having fun with Fibonacci numbers, and I had the idea to consider the sequence instead. I wrote a simple program to compute the first terms and the sequence seemed chaotic, although converging to whatever and were. ( ). How can I prove that the sequence indeed converges, and it converges to ? Is it hopeless to try and find a closed-term formula for ?","
F_n=F_{n-1}^{-1}+F_{n-2}^{-1}
 \sqrt{2} F_0 F_1 F_0,F_1\neq0 \sqrt{2} F_n","['sequences-and-series', 'discrete-mathematics', 'numerical-methods', 'fibonacci-numbers']"
32,"Convergence of a series, what is wrong with my solution?","Convergence of a series, what is wrong with my solution?",,"I have just attempted the following question Show that if $ (b_n) _{n \in \mathbb N }$ is a bounded sequence in $\mathbb R $ , then the series $\sum_{n=1}^{\infty }b_n2^{-n}$ is convergent. This is my solution. If $(b_n)$ is bounded then $\exists M \in \mathbb R$ such that $\lvert b_n \rvert \le M$ $\forall n \in \mathbb N$ . Then, by taking every term in the following series to be $M$ and the fact $\sum_{n=1}^{\infty} 2^{-n}$ converges to 1, we deduce that $$ \sum_{n=1}^{\infty } b_n2^{-n} \le \sum_{n=1}^{\infty } M2^{-n} = M $$ Therefore, by the comparison test $\sum_{n=1}^{\infty } b_n2^{-n}$ converges. However, the official solution uses Cauchy sequences and partial sums. Is there a major flaw in my solution?","I have just attempted the following question Show that if is a bounded sequence in , then the series is convergent. This is my solution. If is bounded then such that . Then, by taking every term in the following series to be and the fact converges to 1, we deduce that Therefore, by the comparison test converges. However, the official solution uses Cauchy sequences and partial sums. Is there a major flaw in my solution?"," (b_n) _{n \in \mathbb N } \mathbb R  \sum_{n=1}^{\infty }b_n2^{-n} (b_n) \exists M \in \mathbb R \lvert b_n \rvert \le M \forall n \in \mathbb N M \sum_{n=1}^{\infty} 2^{-n} 
\sum_{n=1}^{\infty } b_n2^{-n} \le \sum_{n=1}^{\infty } M2^{-n} = M
 \sum_{n=1}^{\infty } b_n2^{-n}","['real-analysis', 'sequences-and-series', 'convergence-divergence']"
33,Finding an alternative nicer method to evaluate the summation,Finding an alternative nicer method to evaluate the summation,,If $a_{n+1}=a_{n}^2+3a_n+1$ and $a_1=\frac13$ then find the value of $$\frac{1}{a_1+2}+\frac{1}{a_2+2}+\frac{1}{a_3+2}+\cdots+\frac{1}{a_{11}+2}+\frac{1}{a_{12}+1}$$ I can easily do this by calculating each $a_i$ separately then doing the calculation but that will be a tiresome task. Is there any other nicer way $?$ Any help is greatly appreciated.,If and then find the value of I can easily do this by calculating each separately then doing the calculation but that will be a tiresome task. Is there any other nicer way Any help is greatly appreciated.,a_{n+1}=a_{n}^2+3a_n+1 a_1=\frac13 \frac{1}{a_1+2}+\frac{1}{a_2+2}+\frac{1}{a_3+2}+\cdots+\frac{1}{a_{11}+2}+\frac{1}{a_{12}+1} a_i ?,['sequences-and-series']
34,How do we justify the integration of $f'(x)=\arcsin'{(x)}=\frac{1}{\sqrt{1-x^2}}=\sum\limits_{k=0}^\infty \binom{-1/2}{k}x^{2k}$?,How do we justify the integration of ?,f'(x)=\arcsin'{(x)}=\frac{1}{\sqrt{1-x^2}}=\sum\limits_{k=0}^\infty \binom{-1/2}{k}x^{2k},"Consider the function $f(x)=\arcsin{(x)}$ and the task of finding the Taylor series at $0$ for this function. We have $$f'(x)=\arcsin'{(x)}=\frac{1}{\sqrt{1-x^2}}$$ Let $g(x)=(1+x)^\alpha$ . Then, for $|x|<1$ and any $\alpha$ , $$g(x)=\sum\limits_{k=0}^\infty \binom{\alpha}{k} x^k$$ That is, $g$ can be represented as an infinite series, the binomial series. Note that this infinite series is a convergent power series centered at $0$ . Hence, it must be the Taylor series of $g$ at $0$ . Using this fact we can show that for $|x|<1$ , $$\frac{1}{\sqrt{1-x^2}}=\sum\limits_{k=0}^\infty \binom{-1/2}{k}x^{2k}$$ Thus, for $|x|<1$ , $$f'(x)=\arcsin'{(x)}=\frac{1}{\sqrt{1-x^2}}=\sum\limits_{k=0}^\infty \binom{-1/2}{k}x^{2k}$$ If we integrate we obtain the result $$f(x)=\arcsin{(x)}=\sum\limits_{k=0}^\infty \binom{-1/2}{k}\frac{x^{2k+1}}{2k+1}$$ Which, if true, means we have another convergent power series centered at $0$ so we have found the desired Taylor series of $\arcsin$ at $0$ . My question is : how do we justify this integration step? If we prove that the sequence of functions $$\{f_n'\}=\left\{\sum\limits_{k=0}^n \binom{-1/2}{k}x^{2k}\right\}$$ converges uniformly to $\arcsin'$ on some interval, then I know of a theorem that says that $$\lim\limits_{n\to\infty}\int_a^b f_n' =\int_a^b \arcsin'$$ This seems like it might involve a lot of calculations. Nonetheless, would it be a valid justification? We could also just use the fact that $\arcsin'$ is continuous and use the first fundamental theorem of calculus. Is this a correct justification?","Consider the function and the task of finding the Taylor series at for this function. We have Let . Then, for and any , That is, can be represented as an infinite series, the binomial series. Note that this infinite series is a convergent power series centered at . Hence, it must be the Taylor series of at . Using this fact we can show that for , Thus, for , If we integrate we obtain the result Which, if true, means we have another convergent power series centered at so we have found the desired Taylor series of at . My question is : how do we justify this integration step? If we prove that the sequence of functions converges uniformly to on some interval, then I know of a theorem that says that This seems like it might involve a lot of calculations. Nonetheless, would it be a valid justification? We could also just use the fact that is continuous and use the first fundamental theorem of calculus. Is this a correct justification?",f(x)=\arcsin{(x)} 0 f'(x)=\arcsin'{(x)}=\frac{1}{\sqrt{1-x^2}} g(x)=(1+x)^\alpha |x|<1 \alpha g(x)=\sum\limits_{k=0}^\infty \binom{\alpha}{k} x^k g 0 g 0 |x|<1 \frac{1}{\sqrt{1-x^2}}=\sum\limits_{k=0}^\infty \binom{-1/2}{k}x^{2k} |x|<1 f'(x)=\arcsin'{(x)}=\frac{1}{\sqrt{1-x^2}}=\sum\limits_{k=0}^\infty \binom{-1/2}{k}x^{2k} f(x)=\arcsin{(x)}=\sum\limits_{k=0}^\infty \binom{-1/2}{k}\frac{x^{2k+1}}{2k+1} 0 \arcsin 0 \{f_n'\}=\left\{\sum\limits_{k=0}^n \binom{-1/2}{k}x^{2k}\right\} \arcsin' \lim\limits_{n\to\infty}\int_a^b f_n' =\int_a^b \arcsin' \arcsin',"['calculus', 'sequences-and-series', 'uniform-convergence']"
35,Find the closed formula for the following recusive sequence.,Find the closed formula for the following recusive sequence.,,"Find the closed formula for the recursive sequence defined by $a_0 = 4$ , $a_1 = 12$ , $a_n = 6a_{n-1}-a_{n-2}$ for $n>1$ . This question is stumping me. I don't know any methods besides guess and check. Current progress: The first five terms are $4, 12, 68, 396, 2308$ . Each term is divisible by four, yielding $1, 3, 17, 99, 577$ Each of these is off of a perfect square by one or negative one $0-1, 4-3, 16-17, 100-99, 576-577$ = $-1,1,-1,1,-1$ Other than that I'm lost. Any help would be appreciated.","Find the closed formula for the recursive sequence defined by , , for . This question is stumping me. I don't know any methods besides guess and check. Current progress: The first five terms are . Each term is divisible by four, yielding Each of these is off of a perfect square by one or negative one = Other than that I'm lost. Any help would be appreciated.","a_0 = 4 a_1 = 12 a_n = 6a_{n-1}-a_{n-2} n>1 4, 12, 68, 396, 2308 1, 3, 17, 99, 577 0-1, 4-3, 16-17, 100-99, 576-577 -1,1,-1,1,-1","['sequences-and-series', 'discrete-mathematics', 'recursion']"
36,$\sum_{n=1}^\infty \frac{a_n}{n^{1+\delta}}$ converges,converges,\sum_{n=1}^\infty \frac{a_n}{n^{1+\delta}},"Let $\left\{a_n\right\}$ be real sequence, $b_n=\frac{a_1+\cdots+a_n}{n}, n\geq 1$ . Suppose that $\left\{b_n\right\}$ is bounded, show that for any $\delta>0$ , the $\sum_{n=1}^\infty \frac{a_n}{n^{1+\delta}}$ converges. My attempt: let $c_k=a_k/k$ , then by $a_k=kb_k-(k-1)b_{k-1}$ , we see readily that $$|\sum_{i=1}^n c_i|=|b_n+\sum_{k=2}^n \frac{b_{k-1}}{k}$$ But this could not prove that $|\sum_{i=1}^n c_i|$ is bounded, or else, we could use Dirichlet test... Any ideas? or other proof?","Let be real sequence, . Suppose that is bounded, show that for any , the converges. My attempt: let , then by , we see readily that But this could not prove that is bounded, or else, we could use Dirichlet test... Any ideas? or other proof?","\left\{a_n\right\} b_n=\frac{a_1+\cdots+a_n}{n}, n\geq 1 \left\{b_n\right\} \delta>0 \sum_{n=1}^\infty \frac{a_n}{n^{1+\delta}} c_k=a_k/k a_k=kb_k-(k-1)b_{k-1} |\sum_{i=1}^n c_i|=|b_n+\sum_{k=2}^n \frac{b_{k-1}}{k} |\sum_{i=1}^n c_i|","['calculus', 'sequences-and-series']"
37,A (fake) proof that $\limsup\limits_{n\to\infty}\left|\frac{a_{n+1}}{a_n}\right|>1\Rightarrow \sum_{n=m}^{\infty}a_n\ \text{ diverges}$,A (fake) proof that,\limsup\limits_{n\to\infty}\left|\frac{a_{n+1}}{a_n}\right|>1\Rightarrow \sum_{n=m}^{\infty}a_n\ \text{ diverges},"Let $(a_n)_{n=m}^{\infty}$ be a sequence of nonzero real numbers. Then we know that the implication $$\limsup\limits_{n\to\infty}\left|\frac{a_{n+1}}{a_n}\right|>1\Rightarrow \sum_{n=m}^{\infty}a_n\ \text{ diverges}$$ is false (a counterexample is the sequence $(a_n)_{n\geq 1}:=\begin{cases}\frac{1}{n^2} & \text{if } n \text{ is even }\\ \frac{2}{n^2} & \text{if }n \text{ odd}\end{cases}$ which has $\limsup\limits_{n\to\infty} |\frac{a_{n+1}}{a_n}|=2>1$ but nonetheless converges (as can be easily seen by using Comparison Test with the series $\sum_{n=1}^{\infty}\frac{2}{n^2}$ ). This notwithstanding I haven't been able to see where the following proof of the false statement, which I had come up with before stumbling upon the counterexample I described above, is wrong, so I would appreciate if someone could point it out to me. Thanks. Let $L=\limsup\limits_{n\to\infty} \left| \frac{a_{n+1}}{a_n} \right|$ ; then there exists a subsequence $\left(b_k\right)_{k\in\mathbb{N}}=\left(\left|\frac{a_{n_k+1}}{a_{n_k}}\right|\right)_{k\in\mathbb{N}}$ such that $\lim\limits_{k\to\infty}b_k=L$ so if we take $\varepsilon:=\frac{L-1}{2}$ we have that there exists $K\in\mathbb{N}$ such that $|b_k-L|\leq\varepsilon$ for every $k\geq K$ hence $b_k\geq\frac{L+1}{2}>1$ for every $k\geq K.$ So if $k>K$ we have $|a_{n_k}|=\left|\frac{a_{n_k}}{a_{n_{k-1}}}\right|\cdot \left|\frac{a_{n_{k-1}}}{a_{n_{k-2}}}\right| \cdot \dots \cdot \left|\frac{a_{n_{K+1}}}{a_{n_K}} \right|\cdot |a_{n_K}|>\left(\frac{L+1}{2}\right)^{k-K}|a_{n_K}|=A\left(\frac{L+1}{2}\right)^k$ , where $A:=\left(\frac{L+1}{2}\right)^{-K}|a_{n_K}|$ which implies that $\lim\limits_{k\to\infty}|a_{n_k}|\geq\lim\limits_{k\to\infty} A\left(\frac{L+1}{2}\right)^k=+\infty$ i.e. $\lim\limits_{k\to\infty}|a_{n_k}|=+\infty$ hence $\lim\limits_{k\to\infty} |a_{n_k}|\neq 0$ thus $\lim\limits_{n\to\infty}a_n\neq 0$ and therefore the series $\sum\limits_{n=0}^{\infty}a_n$ cannot converge, as desired. $\square$","Let be a sequence of nonzero real numbers. Then we know that the implication is false (a counterexample is the sequence which has but nonetheless converges (as can be easily seen by using Comparison Test with the series ). This notwithstanding I haven't been able to see where the following proof of the false statement, which I had come up with before stumbling upon the counterexample I described above, is wrong, so I would appreciate if someone could point it out to me. Thanks. Let ; then there exists a subsequence such that so if we take we have that there exists such that for every hence for every So if we have , where which implies that i.e. hence thus and therefore the series cannot converge, as desired.",(a_n)_{n=m}^{\infty} \limsup\limits_{n\to\infty}\left|\frac{a_{n+1}}{a_n}\right|>1\Rightarrow \sum_{n=m}^{\infty}a_n\ \text{ diverges} (a_n)_{n\geq 1}:=\begin{cases}\frac{1}{n^2} & \text{if } n \text{ is even }\\ \frac{2}{n^2} & \text{if }n \text{ odd}\end{cases} \limsup\limits_{n\to\infty} |\frac{a_{n+1}}{a_n}|=2>1 \sum_{n=1}^{\infty}\frac{2}{n^2} L=\limsup\limits_{n\to\infty} \left| \frac{a_{n+1}}{a_n} \right| \left(b_k\right)_{k\in\mathbb{N}}=\left(\left|\frac{a_{n_k+1}}{a_{n_k}}\right|\right)_{k\in\mathbb{N}} \lim\limits_{k\to\infty}b_k=L \varepsilon:=\frac{L-1}{2} K\in\mathbb{N} |b_k-L|\leq\varepsilon k\geq K b_k\geq\frac{L+1}{2}>1 k\geq K. k>K |a_{n_k}|=\left|\frac{a_{n_k}}{a_{n_{k-1}}}\right|\cdot \left|\frac{a_{n_{k-1}}}{a_{n_{k-2}}}\right| \cdot \dots \cdot \left|\frac{a_{n_{K+1}}}{a_{n_K}} \right|\cdot |a_{n_K}|>\left(\frac{L+1}{2}\right)^{k-K}|a_{n_K}|=A\left(\frac{L+1}{2}\right)^k A:=\left(\frac{L+1}{2}\right)^{-K}|a_{n_K}| \lim\limits_{k\to\infty}|a_{n_k}|\geq\lim\limits_{k\to\infty} A\left(\frac{L+1}{2}\right)^k=+\infty \lim\limits_{k\to\infty}|a_{n_k}|=+\infty \lim\limits_{k\to\infty} |a_{n_k}|\neq 0 \lim\limits_{n\to\infty}a_n\neq 0 \sum\limits_{n=0}^{\infty}a_n \square,"['real-analysis', 'sequences-and-series', 'limsup-and-liminf', 'fake-proofs']"
38,Deriving $\gamma \approx H(n)-\ln(n+1)+\frac{1}{2(n+1)}+\frac{1}{12(n+1)^2}$,Deriving,\gamma \approx H(n)-\ln(n+1)+\frac{1}{2(n+1)}+\frac{1}{12(n+1)^2},"The Euler-Mascheroni constant can be represented geometrically by the infinite sum of the areas in blue in the following picture, which is the area between the curve $y=1/x$ and the harmonic numbers. Thus, the total area can be approximated by taking a finite sum of the first $n$ areas, such that $$\gamma \approx H(n)-\ln(n+1)$$ This approximation can be improved by noting that, as $n$ increases, these areas approach a triangle with base $\frac{1}{n}-\frac{1}{n+1}$ and height $1$ . Therefore, the sum of the remaining areas is $$A \approx\sum_{k=n+1}^{\infty}\frac{1}{2} \left(\frac{1}{n}-\frac{1}{n+1} \right)=\frac{1}{2(n+1)}$$ Thus, $$\gamma \approx H(n)-\ln(n+1)+\frac{1}{2(n+1)}$$ Is there also a relatively simple way to derive the following even better approximation? $$\gamma \approx H(n)-\ln(n+1)+\frac{1}{2(n+1)}+\frac{1}{12(n+1)^2}$$ I saw an almost identical formula in the harmonic numbers Wolfram MathWorld page but it seems that it comes from the rather complex Euler-Maclaurin formula.","The Euler-Mascheroni constant can be represented geometrically by the infinite sum of the areas in blue in the following picture, which is the area between the curve and the harmonic numbers. Thus, the total area can be approximated by taking a finite sum of the first areas, such that This approximation can be improved by noting that, as increases, these areas approach a triangle with base and height . Therefore, the sum of the remaining areas is Thus, Is there also a relatively simple way to derive the following even better approximation? I saw an almost identical formula in the harmonic numbers Wolfram MathWorld page but it seems that it comes from the rather complex Euler-Maclaurin formula.",y=1/x n \gamma \approx H(n)-\ln(n+1) n \frac{1}{n}-\frac{1}{n+1} 1 A \approx\sum_{k=n+1}^{\infty}\frac{1}{2} \left(\frac{1}{n}-\frac{1}{n+1} \right)=\frac{1}{2(n+1)} \gamma \approx H(n)-\ln(n+1)+\frac{1}{2(n+1)} \gamma \approx H(n)-\ln(n+1)+\frac{1}{2(n+1)}+\frac{1}{12(n+1)^2},"['sequences-and-series', 'approximation', 'harmonic-numbers', 'approximation-theory', 'euler-mascheroni-constant']"
39,Bessel Function Series Closed Form $\sum_{m=1} \frac{1}{2m}J_{2m}(2mx)$ or $\sum_{m=1}J^2_{m\pm 1}(mx)$ or $\sum_{m=1}\frac{J^2_m(mx)}{m}$,Bessel Function Series Closed Form  or  or,\sum_{m=1} \frac{1}{2m}J_{2m}(2mx) \sum_{m=1}J^2_{m\pm 1}(mx) \sum_{m=1}\frac{J^2_m(mx)}{m},"I'm trying to find a closed form for the following sum, $$\sum_{m=1}^\infty\frac{1}{2m}J_{2m}(2mx),$$ where $0<x<1$ . I've been using standard references such as Gradshteyn and Ryzhik, Abramovitz and Stegun, Prudnikov et al. which have proven fruitful for almost all cases, except for this sum which I'm now struggling with for a closed form. Any help would be greatly appreciated! UPDATE 1: This arises in the context of finding a closed form for the series $$ \sum_{m=1}^\infty\left(J^2_{m-1}(mx)-J^2_{m+1}(mx)\right), $$ I've already found that $$ \sum_{m=1}^\infty\left(J^2_{m-1}(mx)+J^2_{m+1}(mx)\right)=\frac{1}{\sqrt{1-x^2}}, $$ so by using this, equivalent series to find a closed form of would be $$ \sum_{m=1}^\infty J^2_{m\pm1}(mx). $$ Thanks in advance! UPDATE 2: Another equivalent infinite series is by using the recurrence relations after completing the square on $$ \sum_{m=1}^\infty\left(J^2_{m-1}(mx)-J^2_{m+1}(mx)\right), $$ which gives $$ \frac{4}{x}\sum_{m=1}J_m(mx)J'_m(mx). $$ But this can be realised instead as a derivative with respect to $x$ as follows $$ \frac{2}{x}\frac{d}{dx}\sum_{m=1}\frac{J^2_m(mx)}{m}. $$ Then, a fourth equivalent series that would answer my question would be $$ \sum_{m=1}\frac{J^2_m(mx)}{m}. $$ This can be related to the original question by noting the relation $$ J^2_m(mx)=\frac{2}{\pi}\int_0^{\frac{\pi}{2}}J_{2m}(2mx\cos\theta)d\theta. $$ Fubini allows us to bring the infinite sum inside the integral and this is where the original sum involving not a squared Bessel but even order terms only. Effectively, finding a closed form to any of these series would aid me greatly! UPDATE 3 (Edited): After reading the comment below, we use the following two facts $$ J_n(a)=\frac{1}{\pi}\int_0^\pi dt\,\cos(tn-a\sin t), $$ and $$ \sum_{n=1}\frac{\cos(nx)}{n}=-\frac{1}{2}\ln(2(1-\cos x))=-\ln(2\sin(x/2)). $$ References can be find in either DLMF or Gradshteyn and Ryzhik. The sum reads $$ \frac{2}{x}\frac{d}{dx}\sum_{m=1}^\infty\frac{J^2_{m}(mx)}{m}=\frac{2}{x}\frac{d}{dx}\frac{2}{\pi}\int_0^{\frac{\pi}{2}}\sum_{m=1}^\infty\frac{J_{2m}(2mx\cos\theta)}{m}d\theta. $$ Let's define $z=x\cos\theta<1$ . Then by the expansions, we have $$ \begin{align*} &=\frac{4}{\pi^2 x}\frac{d}{dx}\int_0^{\frac{\pi}{2}}d\theta\int_0^\pi dt\sum_{m=1}^\infty \frac{\cos(2m(t-z\sin t))}{m},\\ &=-\frac{4}{\pi^2 x}\frac{d}{dx}\int_0^{\frac{\pi}{2}}d\theta\int_0^\pi dt\ln\left(\sin(t-z\sin t)\right),\\ &=\frac{4}{\pi^2 x}\int_0^{\frac{\pi}{2}}d\theta\int_0^\pi dt\cos\theta\sin t \,\text{cot}(t-x\cos\theta\sin t). \end{align*} $$","I'm trying to find a closed form for the following sum, where . I've been using standard references such as Gradshteyn and Ryzhik, Abramovitz and Stegun, Prudnikov et al. which have proven fruitful for almost all cases, except for this sum which I'm now struggling with for a closed form. Any help would be greatly appreciated! UPDATE 1: This arises in the context of finding a closed form for the series I've already found that so by using this, equivalent series to find a closed form of would be Thanks in advance! UPDATE 2: Another equivalent infinite series is by using the recurrence relations after completing the square on which gives But this can be realised instead as a derivative with respect to as follows Then, a fourth equivalent series that would answer my question would be This can be related to the original question by noting the relation Fubini allows us to bring the infinite sum inside the integral and this is where the original sum involving not a squared Bessel but even order terms only. Effectively, finding a closed form to any of these series would aid me greatly! UPDATE 3 (Edited): After reading the comment below, we use the following two facts and References can be find in either DLMF or Gradshteyn and Ryzhik. The sum reads Let's define . Then by the expansions, we have","\sum_{m=1}^\infty\frac{1}{2m}J_{2m}(2mx), 0<x<1 
\sum_{m=1}^\infty\left(J^2_{m-1}(mx)-J^2_{m+1}(mx)\right),
 
\sum_{m=1}^\infty\left(J^2_{m-1}(mx)+J^2_{m+1}(mx)\right)=\frac{1}{\sqrt{1-x^2}},
 
\sum_{m=1}^\infty J^2_{m\pm1}(mx).
 
\sum_{m=1}^\infty\left(J^2_{m-1}(mx)-J^2_{m+1}(mx)\right),
 
\frac{4}{x}\sum_{m=1}J_m(mx)J'_m(mx).
 x 
\frac{2}{x}\frac{d}{dx}\sum_{m=1}\frac{J^2_m(mx)}{m}.
 
\sum_{m=1}\frac{J^2_m(mx)}{m}.
 
J^2_m(mx)=\frac{2}{\pi}\int_0^{\frac{\pi}{2}}J_{2m}(2mx\cos\theta)d\theta.
 
J_n(a)=\frac{1}{\pi}\int_0^\pi dt\,\cos(tn-a\sin t),
 
\sum_{n=1}\frac{\cos(nx)}{n}=-\frac{1}{2}\ln(2(1-\cos x))=-\ln(2\sin(x/2)).
 
\frac{2}{x}\frac{d}{dx}\sum_{m=1}^\infty\frac{J^2_{m}(mx)}{m}=\frac{2}{x}\frac{d}{dx}\frac{2}{\pi}\int_0^{\frac{\pi}{2}}\sum_{m=1}^\infty\frac{J_{2m}(2mx\cos\theta)}{m}d\theta.
 z=x\cos\theta<1 
\begin{align*}
&=\frac{4}{\pi^2 x}\frac{d}{dx}\int_0^{\frac{\pi}{2}}d\theta\int_0^\pi dt\sum_{m=1}^\infty \frac{\cos(2m(t-z\sin t))}{m},\\
&=-\frac{4}{\pi^2 x}\frac{d}{dx}\int_0^{\frac{\pi}{2}}d\theta\int_0^\pi dt\ln\left(\sin(t-z\sin t)\right),\\
&=\frac{4}{\pi^2 x}\int_0^{\frac{\pi}{2}}d\theta\int_0^\pi dt\cos\theta\sin t \,\text{cot}(t-x\cos\theta\sin t).
\end{align*}
","['calculus', 'sequences-and-series', 'special-functions', 'bessel-functions']"
40,When can one justify switching the limit and infinite sum?,When can one justify switching the limit and infinite sum?,,"I want to prove the following theorem $$\lim_{N\to\infty}\frac{\displaystyle\sum_{k=1}^N f(a_k)}{N}=\sum_{n=1}^\infty f(n)P(a_k=n)$$ Where $a_k$ is a sequence of non-negative integers and $P(a_k=n)$ is the probability that $a_k=n$ over all $a_k$ 's. $f(n)$ is an arbitrary function to the non negative real numbers. I want to know what a sufficient (maybe even necessary) condition is that this theorem holds. Here is what I was able to prove so far $$\lim_{N\to\infty}\frac{\displaystyle\sum_{k=1}^N f(a_k)}{N}=\lim_{N\to\infty}\frac{1}{N}\sum_{n=1}^\infty f(n)||a_k=n||_{k \le N}$$ where $||a_k=n||_{k \le N}$ is the number of $a_k$ 's with $k \le N$ for which $a_k=n$ . This is true since all that was done here is groupe together equal terms. Lets now assume the sum and the limit can be switched around (here is where I miss a proof), therefore we have $$\sum_{n=1}^\infty f(n)\lim_{N\to\infty}\frac{||a_k=n||_{k \le N}}{N}=\sum_{n=1}^\infty f(n)P(a_k=n)$$ I tried proving the missing step using Tannery's theorem but couldnt do it. So my question basically becomes, what conditions do $a_k$ and $f(n)$ have to meet in order to be able to switch the limit and sum? Any help is appreciated and thank you in advance!","I want to prove the following theorem Where is a sequence of non-negative integers and is the probability that over all 's. is an arbitrary function to the non negative real numbers. I want to know what a sufficient (maybe even necessary) condition is that this theorem holds. Here is what I was able to prove so far where is the number of 's with for which . This is true since all that was done here is groupe together equal terms. Lets now assume the sum and the limit can be switched around (here is where I miss a proof), therefore we have I tried proving the missing step using Tannery's theorem but couldnt do it. So my question basically becomes, what conditions do and have to meet in order to be able to switch the limit and sum? Any help is appreciated and thank you in advance!",\lim_{N\to\infty}\frac{\displaystyle\sum_{k=1}^N f(a_k)}{N}=\sum_{n=1}^\infty f(n)P(a_k=n) a_k P(a_k=n) a_k=n a_k f(n) \lim_{N\to\infty}\frac{\displaystyle\sum_{k=1}^N f(a_k)}{N}=\lim_{N\to\infty}\frac{1}{N}\sum_{n=1}^\infty f(n)||a_k=n||_{k \le N} ||a_k=n||_{k \le N} a_k k \le N a_k=n \sum_{n=1}^\infty f(n)\lim_{N\to\infty}\frac{||a_k=n||_{k \le N}}{N}=\sum_{n=1}^\infty f(n)P(a_k=n) a_k f(n),"['sequences-and-series', 'limits', 'infinity']"
41,Closed form for $\sum_{k=1}^\infty\frac{H_k^{(m)}}{k^n}$,Closed form for,\sum_{k=1}^\infty\frac{H_k^{(m)}}{k^n},"Let's define $$\sigma(m,n)=\sum_{k=1}^\infty\frac{H_k^{(m)}}{k^n}$$ where $H_k^{(m)}=\sum_{n=1}^{k}\frac{1}{n^m}$ is the k-th generalized harmonic number of order $m$ . In mathworld site Eq (20), I found $$\sigma(m\text{ even},n\text{ odd})=\frac12\left[\binom{m+n}{m}+1\right]\zeta(m+n)+\zeta(m)\zeta(n)$$ $$-\sum_{j=1}^{m+n}\left[\binom{2j-2}{m-1}+\binom{2j-2}{n-1}\right]\zeta(2j-1)\zeta(m+n-2j+1)\label{1}\tag{1}$$ and $$\sigma(m\text{ odd},n\text{ even})=-\frac12\left[\binom{m+n}{m}+1\right]\zeta(m+n)$$ $$+\sum_{j=1}^{m+n}\left[\binom{2j-2}{m-1}+\binom{2j-2}{n-1}\right]\zeta(2j-1)\zeta(m+n-2j+1)\label{2}\tag{2}$$ I know that \eqref{2} follows from \eqref{1} by using the well-known identity $$\sum_{k=1}^\infty \frac{H_k^{(m)}}{k^n}+\sum_{k=1}^\infty \frac{H_k^{(n)}}{k^m}=\zeta(m)\zeta(n)+\zeta(m+n)$$ The proof of \eqref{1} may be found here but I am looking for different ones if possible. Thanks Update (Nov 2 2023) In this preprint , we proved the following generalizations for integers $p$ and $q$ : \begin{multline*} i)\sum_{n=1}^\infty\frac{H_n^{(p)}}{n^q}=\frac12\zeta(p+q)-(-1)^q\sum_{k=0}^{\lfloor{\frac{q-1}{2}}\rfloor}\binom{p+q-2k-1}{p-1}\zeta(2k)\zeta(p+q-2k)\\ -(-1)^q\sum_{k=0}^{\lfloor{\frac{p}{2}}\rfloor}\binom{p+q-2k-1}{q-1}\zeta(2k)\zeta(p+q-2k); \end{multline*} \begin{multline*}  ii)\sum_{n=1}^\infty\frac{(-1)^nH_n^{(p)}}{n^q}=-\frac12\eta(p+q)+(-1)^q\sum_{k=0}^{\lfloor{\frac{q-1}{2}}\rfloor}\binom{p+q-2k-1}{p-1}\eta(2k)\zeta(p+q-2k)\\ -(-1)^q\sum_{k=0}^{\lfloor{\frac{p}{2}}\rfloor}\binom{p+q-2k-1}{q-1}\eta(2k)\eta(p+q-2k); \end{multline*} \begin{multline*} iii)\sum_{n=1}^\infty\frac{\overline{H}_n^{(p)}}{n^q}=\frac12\eta(p+q)+\frac12(1+(-1)^{q})\zeta(q)\eta(p)\\ +(-1)^q\sum_{k=0}^{\lfloor{\frac{q}{2}}\rfloor}\binom{p+q-2k-1}{p-1}\eta(2k)\eta(p+q-2k)\\ -(-1)^q\sum_{k=0}^{\lfloor{\frac{p}{2}}\rfloor}\binom{p+q-2k-1}{q-1}\eta(2k)\zeta(p+q-2k); \end{multline*} \begin{multline*}iv)\sum_{n=1}^\infty\frac{(-1)^n \overline{H}_n^{(p)}}{n^q}=-\frac12\zeta(p+q)-\frac12(1+(-1)^q)\eta(q)\eta(p)\\ -(-1)^q\sum_{k=0}^{\lfloor{\frac{q}{2}}\rfloor}\binom{p+q-2k-1}{p-1}\zeta(2k)\eta(p+q-2k)\\ -(-1)^q\sum_{k=0}^{\lfloor{\frac{p}{2}}\rfloor}\binom{p+q-2k-1}{q-1}\zeta(2k)\eta(p+q-2k); \end{multline*} \begin{multline*} v)\sum_{n=1}^\infty\frac{H_n^{(p)}}{(2n+1)^q}=-(1+(-1)^q)2^{p-1}\lambda(q)\eta(p)\\ -(-1)^q2^{p}\sum_{k=0}^{\lfloor{\frac{q-1}{2}}\rfloor}\binom{p+q-2k-1}{p-1}\lambda(2k)\lambda(p+q-2k)\\ -(-1)^q2^{p}\sum_{k=0}^{\lfloor{\frac{p}{2}}\rfloor}\binom{p+q-2k-1}{q-1}2^{-2k}\zeta(2k)\lambda(p+q-2k); \end{multline*} \begin{multline*} vi)\sum_{n=1}^\infty\frac{\overline{H}_n^{(p)}}{(2n+1)^q}=\frac12(1+(-1)^q)\lambda(q)\eta(p)\\ +(-1)^q2^{p-1}\sum_{k=0}^{\lfloor{\frac{q-1}{2}}\rfloor}\binom{p+q-2k-2}{p-1}\frac{|E_{2k}|}{(2k)!}\left(\frac{\pi}{2}\right)^{2k+1}\beta(p+q-2k-1)\\ -(-1)^q2^{p}\sum_{k=0}^{\lfloor{\frac{p}{2}}\rfloor}\binom{p+q-2k-1}{q-1}2^{-2k}\eta(2k)\lambda(p+q-2k); \end{multline*} \begin{multline*} vii)\sum_{n=1}^\infty \frac{(-1)^{n}H_n^{(p)}}{(2n+1)^q}=-(1-(-1)^q)2^{p-2}\frac{|E_{q-1}|}{(q-1)!}\left(\frac{\pi}{2}\right)^{q}\eta(p)\\ +(-1)^q2^{p-1}\sum_{k=0}^{\lfloor{\frac{q-2}{2}}\rfloor}\binom{p+q-2k-2}{p-1}\frac{|E_{2k}|}{(2k)!}\left(\frac{\pi}{2}\right)^{2k+1}\lambda(p+q-2k-1)\\ -(-1)^q2^{p}\sum_{k=0}^{\lfloor{\frac{p}{2}}\rfloor}\binom{p+q-2k-1}{q-1}2^{-2k}\eta(2k)\beta(p+q-2k); \end{multline*} \begin{multline*} viii)\sum_{n=1}^\infty\frac{(-1)^n\overline{H}_n^{(p)}}{(2n+1)^q}=\frac{1-(-1)^q}{4(q-1)!}|E_{q-1}|\left(\frac{\pi}{2}\right)^q\eta(p)\\ -(-1)^q2^{p}\sum_{k=0}^{\lfloor{\frac{q}{2}}\rfloor}\binom{p+q-2k-1}{p-1}\lambda(2k)\beta(p+q-2k)\\ -(-1)^q2^{p}\sum_{k=0}^{\lfloor{\frac{p}{2}}\rfloor}\binom{p+q-2k-1}{q-1}2^{-2k}\zeta(2k)\beta(p+q-2k), \end{multline*} where $\zeta(s)$ is the Riemann zeta function, $\eta(s)=(1-2^{1-s})\zeta(s)$ is the Dirichlet eta function, $\lambda(s)=(1-2^{-s})\zeta(s)$ is the Dirichlet lambda function, $\beta$ is the Dirichlet beta function, and $E$ is the Euler number. Note that $p\ge1$ and $q\ge2$ in the non-alternating sums, and $p,q\ge1$ in the alternating sums. We also have the sum weight $(p+q)$ is odd in the first six generalizations and even in the last two generalizations.","Let's define where is the k-th generalized harmonic number of order . In mathworld site Eq (20), I found and I know that \eqref{2} follows from \eqref{1} by using the well-known identity The proof of \eqref{1} may be found here but I am looking for different ones if possible. Thanks Update (Nov 2 2023) In this preprint , we proved the following generalizations for integers and : where is the Riemann zeta function, is the Dirichlet eta function, is the Dirichlet lambda function, is the Dirichlet beta function, and is the Euler number. Note that and in the non-alternating sums, and in the alternating sums. We also have the sum weight is odd in the first six generalizations and even in the last two generalizations.","\sigma(m,n)=\sum_{k=1}^\infty\frac{H_k^{(m)}}{k^n} H_k^{(m)}=\sum_{n=1}^{k}\frac{1}{n^m} m \sigma(m\text{ even},n\text{ odd})=\frac12\left[\binom{m+n}{m}+1\right]\zeta(m+n)+\zeta(m)\zeta(n) -\sum_{j=1}^{m+n}\left[\binom{2j-2}{m-1}+\binom{2j-2}{n-1}\right]\zeta(2j-1)\zeta(m+n-2j+1)\label{1}\tag{1} \sigma(m\text{ odd},n\text{ even})=-\frac12\left[\binom{m+n}{m}+1\right]\zeta(m+n) +\sum_{j=1}^{m+n}\left[\binom{2j-2}{m-1}+\binom{2j-2}{n-1}\right]\zeta(2j-1)\zeta(m+n-2j+1)\label{2}\tag{2} \sum_{k=1}^\infty \frac{H_k^{(m)}}{k^n}+\sum_{k=1}^\infty \frac{H_k^{(n)}}{k^m}=\zeta(m)\zeta(n)+\zeta(m+n) p q \begin{multline*}
i)\sum_{n=1}^\infty\frac{H_n^{(p)}}{n^q}=\frac12\zeta(p+q)-(-1)^q\sum_{k=0}^{\lfloor{\frac{q-1}{2}}\rfloor}\binom{p+q-2k-1}{p-1}\zeta(2k)\zeta(p+q-2k)\\
-(-1)^q\sum_{k=0}^{\lfloor{\frac{p}{2}}\rfloor}\binom{p+q-2k-1}{q-1}\zeta(2k)\zeta(p+q-2k);
\end{multline*} \begin{multline*}
 ii)\sum_{n=1}^\infty\frac{(-1)^nH_n^{(p)}}{n^q}=-\frac12\eta(p+q)+(-1)^q\sum_{k=0}^{\lfloor{\frac{q-1}{2}}\rfloor}\binom{p+q-2k-1}{p-1}\eta(2k)\zeta(p+q-2k)\\
-(-1)^q\sum_{k=0}^{\lfloor{\frac{p}{2}}\rfloor}\binom{p+q-2k-1}{q-1}\eta(2k)\eta(p+q-2k);
\end{multline*} \begin{multline*}
iii)\sum_{n=1}^\infty\frac{\overline{H}_n^{(p)}}{n^q}=\frac12\eta(p+q)+\frac12(1+(-1)^{q})\zeta(q)\eta(p)\\
+(-1)^q\sum_{k=0}^{\lfloor{\frac{q}{2}}\rfloor}\binom{p+q-2k-1}{p-1}\eta(2k)\eta(p+q-2k)\\
-(-1)^q\sum_{k=0}^{\lfloor{\frac{p}{2}}\rfloor}\binom{p+q-2k-1}{q-1}\eta(2k)\zeta(p+q-2k);
\end{multline*} \begin{multline*}iv)\sum_{n=1}^\infty\frac{(-1)^n \overline{H}_n^{(p)}}{n^q}=-\frac12\zeta(p+q)-\frac12(1+(-1)^q)\eta(q)\eta(p)\\
-(-1)^q\sum_{k=0}^{\lfloor{\frac{q}{2}}\rfloor}\binom{p+q-2k-1}{p-1}\zeta(2k)\eta(p+q-2k)\\
-(-1)^q\sum_{k=0}^{\lfloor{\frac{p}{2}}\rfloor}\binom{p+q-2k-1}{q-1}\zeta(2k)\eta(p+q-2k);
\end{multline*} \begin{multline*}
v)\sum_{n=1}^\infty\frac{H_n^{(p)}}{(2n+1)^q}=-(1+(-1)^q)2^{p-1}\lambda(q)\eta(p)\\
-(-1)^q2^{p}\sum_{k=0}^{\lfloor{\frac{q-1}{2}}\rfloor}\binom{p+q-2k-1}{p-1}\lambda(2k)\lambda(p+q-2k)\\
-(-1)^q2^{p}\sum_{k=0}^{\lfloor{\frac{p}{2}}\rfloor}\binom{p+q-2k-1}{q-1}2^{-2k}\zeta(2k)\lambda(p+q-2k);
\end{multline*} \begin{multline*}
vi)\sum_{n=1}^\infty\frac{\overline{H}_n^{(p)}}{(2n+1)^q}=\frac12(1+(-1)^q)\lambda(q)\eta(p)\\
+(-1)^q2^{p-1}\sum_{k=0}^{\lfloor{\frac{q-1}{2}}\rfloor}\binom{p+q-2k-2}{p-1}\frac{|E_{2k}|}{(2k)!}\left(\frac{\pi}{2}\right)^{2k+1}\beta(p+q-2k-1)\\
-(-1)^q2^{p}\sum_{k=0}^{\lfloor{\frac{p}{2}}\rfloor}\binom{p+q-2k-1}{q-1}2^{-2k}\eta(2k)\lambda(p+q-2k);
\end{multline*} \begin{multline*}
vii)\sum_{n=1}^\infty \frac{(-1)^{n}H_n^{(p)}}{(2n+1)^q}=-(1-(-1)^q)2^{p-2}\frac{|E_{q-1}|}{(q-1)!}\left(\frac{\pi}{2}\right)^{q}\eta(p)\\
+(-1)^q2^{p-1}\sum_{k=0}^{\lfloor{\frac{q-2}{2}}\rfloor}\binom{p+q-2k-2}{p-1}\frac{|E_{2k}|}{(2k)!}\left(\frac{\pi}{2}\right)^{2k+1}\lambda(p+q-2k-1)\\
-(-1)^q2^{p}\sum_{k=0}^{\lfloor{\frac{p}{2}}\rfloor}\binom{p+q-2k-1}{q-1}2^{-2k}\eta(2k)\beta(p+q-2k);
\end{multline*} \begin{multline*}
viii)\sum_{n=1}^\infty\frac{(-1)^n\overline{H}_n^{(p)}}{(2n+1)^q}=\frac{1-(-1)^q}{4(q-1)!}|E_{q-1}|\left(\frac{\pi}{2}\right)^q\eta(p)\\
-(-1)^q2^{p}\sum_{k=0}^{\lfloor{\frac{q}{2}}\rfloor}\binom{p+q-2k-1}{p-1}\lambda(2k)\beta(p+q-2k)\\
-(-1)^q2^{p}\sum_{k=0}^{\lfloor{\frac{p}{2}}\rfloor}\binom{p+q-2k-1}{q-1}2^{-2k}\zeta(2k)\beta(p+q-2k),
\end{multline*} \zeta(s) \eta(s)=(1-2^{1-s})\zeta(s) \lambda(s)=(1-2^{-s})\zeta(s) \beta E p\ge1 q\ge2 p,q\ge1 (p+q)","['sequences-and-series', 'reference-request', 'alternative-proof', 'riemann-zeta', 'harmonic-numbers']"
42,Evaluating $\{1+\sum\limits_{\mu=1}^{\infty}(-1)^{\mu}\frac{z^{2\mu}}{2^{2^{\mu}}\cdot(\mu !)^2}\}^2$,Evaluating,\{1+\sum\limits_{\mu=1}^{\infty}(-1)^{\mu}\frac{z^{2\mu}}{2^{2^{\mu}}\cdot(\mu !)^2}\}^2,"Question Calculate the following formula, $$\{1+\sum\limits_{\mu=1}^{\infty}(-1)^{\mu}\frac{z^{2\mu}}{2^{2^{\mu}}\cdot(\mu !)^2}\}^2$$ where $z$ is arbitrary. We are given the hint that we can quote the identity: $$\sum\limits_{\mu=0}^{\nu}(\text{C}_{\nu}^{\mu})^2=\text{C}_{2\nu}^{\nu}=\frac{(2\nu)!}{(\nu!)^2}$$ Attempt Below is my attempt: \begin{align} \{1+\sum\limits_{\mu=1}^{\infty}(-1)^{\mu}\frac{z^{2\mu}}{2^{2^{\mu}}\cdot(\mu !)^2}\}^2 &=\{\sum\limits_{\mu=0}^{\infty}(-1)^{\mu}\frac{z^{2\mu}}{2^{2^{\mu}}\cdot(\mu !)^2}\}^2\\ &=\sum\limits_{\mu=0}^{\infty}(-1)^{\mu}\frac{z^{2\mu}}{2^{2^{\mu}}\cdot(\mu !)^2}\sum\limits_{\nu=0}^{\infty}(-1)^{\nu}\frac{z^{2\nu}}{2^{2^{\nu}}\cdot(\nu !)^2}\\ &=\sum_{\mu+\nu=0}^{\infty}(-1)^{\mu+\nu}\frac{z^{2(\mu+\nu)}}{2^{2^{\mu}+2^{\nu}}\cdot(\nu!)^2 (\mu!)^2} \end{align} But I can't find a proper way to use the identity which is supported by the hint.\ Thanks for your help in advance!","Question Calculate the following formula, where is arbitrary. We are given the hint that we can quote the identity: Attempt Below is my attempt: But I can't find a proper way to use the identity which is supported by the hint.\ Thanks for your help in advance!","\{1+\sum\limits_{\mu=1}^{\infty}(-1)^{\mu}\frac{z^{2\mu}}{2^{2^{\mu}}\cdot(\mu !)^2}\}^2 z \sum\limits_{\mu=0}^{\nu}(\text{C}_{\nu}^{\mu})^2=\text{C}_{2\nu}^{\nu}=\frac{(2\nu)!}{(\nu!)^2} \begin{align}
\{1+\sum\limits_{\mu=1}^{\infty}(-1)^{\mu}\frac{z^{2\mu}}{2^{2^{\mu}}\cdot(\mu !)^2}\}^2 &=\{\sum\limits_{\mu=0}^{\infty}(-1)^{\mu}\frac{z^{2\mu}}{2^{2^{\mu}}\cdot(\mu !)^2}\}^2\\ &=\sum\limits_{\mu=0}^{\infty}(-1)^{\mu}\frac{z^{2\mu}}{2^{2^{\mu}}\cdot(\mu !)^2}\sum\limits_{\nu=0}^{\infty}(-1)^{\nu}\frac{z^{2\nu}}{2^{2^{\nu}}\cdot(\nu !)^2}\\
&=\sum_{\mu+\nu=0}^{\infty}(-1)^{\mu+\nu}\frac{z^{2(\mu+\nu)}}{2^{2^{\mu}+2^{\nu}}\cdot(\nu!)^2 (\mu!)^2}
\end{align}","['calculus', 'sequences-and-series', 'analysis']"
43,At most finite elements of the sequence $\{x_{n}\}_{n\in \mathbb{Z}^+}$ is nonzero under certain conditions.,At most finite elements of the sequence  is nonzero under certain conditions.,\{x_{n}\}_{n\in \mathbb{Z}^+},Let $\{x_{n}: n\in \mathbb{Z}_{+}\}$ be a sequence of complex numbers such that $$\sum\limits_{p\in \mathbb{Z}_{+}}\vert x_{p} \vert^2=1$$ and $$\sum\limits_{p\in \mathbb{Z}_{+} }x_{p} \overline{x_{p+r}}=0~~ \text{for all}~~ r\geq 1.$$ Does it imply at most finitely many $x_{p}$ can be non zero. Can you please provide  ideas how to solve this? Any help is appreciated. Thank you in advance!,Let be a sequence of complex numbers such that and Does it imply at most finitely many can be non zero. Can you please provide  ideas how to solve this? Any help is appreciated. Thank you in advance!,\{x_{n}: n\in \mathbb{Z}_{+}\} \sum\limits_{p\in \mathbb{Z}_{+}}\vert x_{p} \vert^2=1 \sum\limits_{p\in \mathbb{Z}_{+} }x_{p} \overline{x_{p+r}}=0~~ \text{for all}~~ r\geq 1. x_{p},"['sequences-and-series', 'complex-numbers', 'soft-question', 'operator-theory', 'matrix-equations']"
44,Show that $\frac{\binom{n}{1}}{1} + \frac{\binom{n}{2}}{2} + \frac{\binom{n}{3}}{3} + \cdots + \frac{\binom{n}{n}}{n} = \sum_{r=1}^{n}\frac{2^r-1}{r}$,Show that,\frac{\binom{n}{1}}{1} + \frac{\binom{n}{2}}{2} + \frac{\binom{n}{3}}{3} + \cdots + \frac{\binom{n}{n}}{n} = \sum_{r=1}^{n}\frac{2^r-1}{r},"Good day, I was solving this problem: Show that $$\frac{\binom{n}{1}}{1} + \frac{\binom{n}{2}}{2} + \frac{\binom{n}{3}}{3} + \cdots + \frac{\binom{n}{n}}{n} = \sum_{r=1}^{n}\frac{2^r-1}{r}$$ I had already made some progress here , and we can prove using induction $$\int_{0}^{1}{\frac{(1 + x) ^ {n} - 1}{x}}dx = \sum_{r=1}^{n}\frac{2^r-1}{r}$$ But this seems too lengthy. Is there a shorter, more elementary solution? Thanks","Good day, I was solving this problem: Show that I had already made some progress here , and we can prove using induction But this seems too lengthy. Is there a shorter, more elementary solution? Thanks",\frac{\binom{n}{1}}{1} + \frac{\binom{n}{2}}{2} + \frac{\binom{n}{3}}{3} + \cdots + \frac{\binom{n}{n}}{n} = \sum_{r=1}^{n}\frac{2^r-1}{r} \int_{0}^{1}{\frac{(1 + x) ^ {n} - 1}{x}}dx = \sum_{r=1}^{n}\frac{2^r-1}{r},"['sequences-and-series', 'combinatorics', 'binomial-coefficients', 'binomial-theorem']"
45,"Find the number of all sequences $\{ a_{n}\}$ in $\{-5,-4,-3,...,0,1,...,100\}$ such that $ |a_{n}| < |a_{n+1}|$.",Find the number of all sequences  in  such that .,"\{ a_{n}\} \{-5,-4,-3,...,0,1,...,100\}  |a_{n}| < |a_{n+1}|","Find the number of all sequences $\{ a_{n}\}$ in $\{-5,-4,-3,...,0,1,...,100\}$ such that $ |a_{n}| < |a_{n+1}|$ . I think we can find a unique sequence for every non empty subset of $\{0,1,\ldots ,100\}$ so we have at least $2^{101}-1$ .",Find the number of all sequences in such that . I think we can find a unique sequence for every non empty subset of so we have at least .,"\{ a_{n}\} \{-5,-4,-3,...,0,1,...,100\}  |a_{n}| < |a_{n+1}| \{0,1,\ldots ,100\} 2^{101}-1","['sequences-and-series', 'combinatorics', 'discrete-mathematics']"
46,The sum of $\sum_{n=1}^{\infty}\frac 1{2n^2-1}$ using the beta function,The sum of  using the beta function,\sum_{n=1}^{\infty}\frac 1{2n^2-1},"I am trying to find the sum of the series $$ \sum_{n=1}^{\infty}\frac 1{2n^2-1} $$ using definite integrals. After several substitutions I get $$ \sum_{n=1}^{\infty}\frac 1{2n^2-1}=\dots=\frac{\sqrt 2}{4}\int_0^1\frac{(1-t)^{-\frac{\sqrt 2}{2}}-(1-t)^{\frac{\sqrt 2}{2}}}{t}\,\mathrm dt $$ Now I am in stuck. It's like the combination of two beta functions $B(0,1-\sqrt 2/2)$ and $B(0,1+\sqrt 2/2)$ , however they are not defined at $0$ in the first input. Is there any way of handling with the integral? Thank you in advance. Derivation of the integral: \begin{align*} \sum_{n=1}^{\infty}\frac 1{2n^2-1} &=\frac 12\sum_{n=1}^{\infty}\left(\frac 1{\sqrt 2n-1}-\frac 1{\sqrt 2n+1}\right) =\frac 12\sum_{n=1}^{\infty}\int_0^1\left(x^{\sqrt 2n-2}-x^{\sqrt 2n}\right)\mathrm dx\\[12pt] &=\frac 12\int_0^1\sum_{n=1}^{\infty}\left(x^{\sqrt 2n-2}-x^{\sqrt 2n}\right)\mathrm dx =\frac 12\int_0^1\frac{x^{\sqrt 2-2}-x^{\sqrt 2}}{1-x^{\sqrt 2}}\,\mathrm dx\\[12pt] &=\left[\text{subst. $x=y^{\sqrt 2}$}\right]\ \frac {\sqrt 2}2\int_0^1\frac{y^{-\sqrt 2}-y^{\sqrt 2}}{1-y^2}\cdot y\,\mathrm dy\\[12pt] &=\left[\text{subst. $t=1-y^2$}\right]\ \frac {\sqrt 2}4\int_0^1\frac{(1-t)^{-\frac{\sqrt 2}{2}}-(1-t)^{\frac{\sqrt 2}{2}}}{t}\,\mathrm dt \end{align*}","I am trying to find the sum of the series using definite integrals. After several substitutions I get Now I am in stuck. It's like the combination of two beta functions and , however they are not defined at in the first input. Is there any way of handling with the integral? Thank you in advance. Derivation of the integral:","
\sum_{n=1}^{\infty}\frac 1{2n^2-1}
 
\sum_{n=1}^{\infty}\frac 1{2n^2-1}=\dots=\frac{\sqrt 2}{4}\int_0^1\frac{(1-t)^{-\frac{\sqrt 2}{2}}-(1-t)^{\frac{\sqrt 2}{2}}}{t}\,\mathrm dt
 B(0,1-\sqrt 2/2) B(0,1+\sqrt 2/2) 0 \begin{align*}
\sum_{n=1}^{\infty}\frac 1{2n^2-1}
&=\frac 12\sum_{n=1}^{\infty}\left(\frac 1{\sqrt 2n-1}-\frac 1{\sqrt 2n+1}\right)
=\frac 12\sum_{n=1}^{\infty}\int_0^1\left(x^{\sqrt 2n-2}-x^{\sqrt 2n}\right)\mathrm dx\\[12pt]
&=\frac 12\int_0^1\sum_{n=1}^{\infty}\left(x^{\sqrt 2n-2}-x^{\sqrt 2n}\right)\mathrm dx
=\frac 12\int_0^1\frac{x^{\sqrt 2-2}-x^{\sqrt 2}}{1-x^{\sqrt 2}}\,\mathrm dx\\[12pt]
&=\left[\text{subst. x=y^{\sqrt 2}}\right]\ \frac {\sqrt 2}2\int_0^1\frac{y^{-\sqrt 2}-y^{\sqrt 2}}{1-y^2}\cdot y\,\mathrm dy\\[12pt]
&=\left[\text{subst. t=1-y^2}\right]\ \frac {\sqrt 2}4\int_0^1\frac{(1-t)^{-\frac{\sqrt 2}{2}}-(1-t)^{\frac{\sqrt 2}{2}}}{t}\,\mathrm dt
\end{align*}","['sequences-and-series', 'definite-integrals', 'beta-function']"
47,"Let $p_n\ $ be the $n-$th prime. Is there a decreasing positive real sequence $(a_n)$ such that $\sum a_n$ diverges, but $\sum a_{p_n}$ converges?","Let  be the th prime. Is there a decreasing positive real sequence  such that  diverges, but  converges?",p_n\  n- (a_n) \sum a_n \sum a_{p_n},"Let the $\ n-$ th prime be denoted by $\ p_n.\ $ Is there a (not necessarily strictly) decreasing sequence of positive real numbers $\ (a_n)_{n\in\mathbb{N}}\ $ such that $\ \sum a_n\ $ diverges, but $\ \sum a_{p_n}\ $ converges? Remarks/thoughts: $\ a_n = \frac{1}{n}\ $ fails because $\ \sum\frac{1}{n}\ $ diverges but so does $\ \sum \frac{1}{p_n}.$ If $\ \sum a_n\ $ diverges and $\ k\in\mathbb{N}\ $ then any subseries of the form $\ \sum a_{kn}\ $ also diverges. To see this, consider the contrapositive of this statement. However, there is no $\ k\ $ to compare to prime numbers because the $\ n-$ th prime is approximately $\ n\ln(n) \gg n\ $ for large $\ n.$ Maybe there are arguments you can make based on the asymptotic behaviour of the primes - but I am not very good at these, so would be interested to see some. Or maybe there are other, easier methods, which again I don't see.","Let the th prime be denoted by Is there a (not necessarily strictly) decreasing sequence of positive real numbers such that diverges, but converges? Remarks/thoughts: fails because diverges but so does If diverges and then any subseries of the form also diverges. To see this, consider the contrapositive of this statement. However, there is no to compare to prime numbers because the th prime is approximately for large Maybe there are arguments you can make based on the asymptotic behaviour of the primes - but I am not very good at these, so would be interested to see some. Or maybe there are other, easier methods, which again I don't see.","\ n- \ p_n.\  \
(a_n)_{n\in\mathbb{N}}\  \ \sum a_n\  \
\sum a_{p_n}\  \ a_n = \frac{1}{n}\  \ \sum\frac{1}{n}\  \ \sum \frac{1}{p_n}. \ \sum a_n\  \ k\in\mathbb{N}\  \ \sum a_{kn}\  \ k\  \ n- \ n\ln(n) \gg n\  \ n.","['real-analysis', 'sequences-and-series', 'convergence-divergence', 'prime-numbers']"
48,Does the finite sequence belong to $\ell^p$?,Does the finite sequence belong to ?,\ell^p,"For $1\leqq p<\infty,$ $\ell^p$ is defined by $\ell^p=\{ \{x_n\}_{n=1}^\infty \subset K \mid \sum_{n=1}^\infty |x_n|^p<\infty\}.$ Does the arbitrary sequence $\{a_n\}_{n=1}^N \subset K$ belong to $\ell^p$ ? Of course, $\sum_{n=1}^N |a_n|^p<\infty$ but I wonder whether $\{a_n \}_{n=1}^N$ belongs to $\ell^p$ because this is not the form $\{ \cdot \}_{n=1}^\infty$ but the form $\{ \cdot \}_{n=1}^N.$ I think that for given $\{a_n \}_{n=1}^N$ , if I define $a_n=0$ for $n\geqq N+1$ , I can check $\{a_n \}_{n=1}^\infty \in \ell^p$ , but can I say $\{a_n \}_{n=1}^N$ itself is in $\ell^p$ ? Or, in the first place, isn't $\{a_n\}_{n=1}^N$ called ""sequence"" ?","For is defined by Does the arbitrary sequence belong to ? Of course, but I wonder whether belongs to because this is not the form but the form I think that for given , if I define for , I can check , but can I say itself is in ? Or, in the first place, isn't called ""sequence"" ?","1\leqq p<\infty, \ell^p \ell^p=\{ \{x_n\}_{n=1}^\infty \subset K \mid \sum_{n=1}^\infty |x_n|^p<\infty\}. \{a_n\}_{n=1}^N \subset K \ell^p \sum_{n=1}^N |a_n|^p<\infty \{a_n \}_{n=1}^N \ell^p \{ \cdot \}_{n=1}^\infty \{ \cdot \}_{n=1}^N. \{a_n \}_{n=1}^N a_n=0 n\geqq N+1 \{a_n \}_{n=1}^\infty \in \ell^p \{a_n \}_{n=1}^N \ell^p \{a_n\}_{n=1}^N","['sequences-and-series', 'functional-analysis', 'lp-spaces']"
49,Finding $\lim_{n\to\infty} \frac{z_{n}}{z_{n-1}}$ where $3z_{n}=z_{n-1}+z_{n-2}+z_{n-1}z_{n-2}$,Finding  where,\lim_{n\to\infty} \frac{z_{n}}{z_{n-1}} 3z_{n}=z_{n-1}+z_{n-2}+z_{n-1}z_{n-2},"Question. Let $(z_n)$ be a real sequence such that $$ z_0 = 0,\quad  z_1=1, \quad 3z_{n}=z_{n-1}+z_{n-2}+z_{n-1}z_{n-2}\quad (n>1)\tag{1} $$ Prove that the limit of the sequence $(b_n)$ with $b_n:=\frac{z_{n}}{z_{n-1}}$ exists. Observations. Diving by $z_{n-1}$ on both sides of (1), we get $$ b_n = f(b_{n-1})+z_{n-2} $$ where $f(x)=\frac13(1+\frac1x)$ . An answer to this question shows that $\lim_{n\to 0}z_n = 0$ . One straightforward idea is to show that the sequence is Cauchy. By the triangle inequality $$ |b_n-b_m| = |f(b_{n-1})-f(b_{m-1})|+|z_{n-2}-z_{m-2}|\;. $$ The second term on the right-hand side can be handled easily by Observation 2. But then one needs to estimate $|f(b_{n-1})-f(b_{m-1})|$ . One can find the derivative $f'(x)=\frac{-3}{x^2}$ , which seems not very much helpful here.","Question. Let be a real sequence such that Prove that the limit of the sequence with exists. Observations. Diving by on both sides of (1), we get where . An answer to this question shows that . One straightforward idea is to show that the sequence is Cauchy. By the triangle inequality The second term on the right-hand side can be handled easily by Observation 2. But then one needs to estimate . One can find the derivative , which seems not very much helpful here.","(z_n) 
z_0 = 0,\quad  z_1=1, \quad 3z_{n}=z_{n-1}+z_{n-2}+z_{n-1}z_{n-2}\quad (n>1)\tag{1}
 (b_n) b_n:=\frac{z_{n}}{z_{n-1}} z_{n-1} 
b_n = f(b_{n-1})+z_{n-2}
 f(x)=\frac13(1+\frac1x) \lim_{n\to 0}z_n = 0 
|b_n-b_m| = |f(b_{n-1})-f(b_{m-1})|+|z_{n-2}-z_{m-2}|\;.
 |f(b_{n-1})-f(b_{m-1})| f'(x)=\frac{-3}{x^2}",['real-analysis']
50,Proof that Dirichlet series $\sum_{n=1}^{\infty}\frac{2^{\omega(n)}}{n^2}=\frac{5}{2}$,Proof that Dirichlet series,\sum_{n=1}^{\infty}\frac{2^{\omega(n)}}{n^2}=\frac{5}{2},"So I want to prove the following: $$\sum_{n=1}^{\infty}\frac{2^{\omega(n)}}{n^2}=\frac{5}{2},$$ where $\omega(n)$ is the number of distinct prime factors of $n.$ I computed it to $10^{10}$ and it does seem to be slowly approaching $\frac{5}{2}.$ Also, I am aware of the following result: $$\sum_{n=1}^{\infty}\frac{\omega(n)}{n^2}=\zeta(2)P(2),$$ where $P(2)$ is the prime zeta function. I am not quite sure how exactly to go about this, there doesn't seem to be a way to get from the known result to the one I'm trying to solve.","So I want to prove the following: where is the number of distinct prime factors of I computed it to and it does seem to be slowly approaching Also, I am aware of the following result: where is the prime zeta function. I am not quite sure how exactly to go about this, there doesn't seem to be a way to get from the known result to the one I'm trying to solve.","\sum_{n=1}^{\infty}\frac{2^{\omega(n)}}{n^2}=\frac{5}{2}, \omega(n) n. 10^{10} \frac{5}{2}. \sum_{n=1}^{\infty}\frac{\omega(n)}{n^2}=\zeta(2)P(2), P(2)","['sequences-and-series', 'number-theory', 'elementary-number-theory', 'dirichlet-series']"
51,convergence $\sum_{n=1}^{\infty}\frac{1}{n}\sin\left(\frac{\pi}{n^{2}}\right)$,convergence,\sum_{n=1}^{\infty}\frac{1}{n}\sin\left(\frac{\pi}{n^{2}}\right),"I'm checking convergence of the series $\sum_{n=1}^{\infty}\frac{1}{n}\sin\left(\frac{\pi}{n^{2}}\right)$ using the integral test. I calculated the integral $\int_{1}^{+\infty}\frac{1}{x}\sin\left(\frac{\pi}{x^{2}}\right)dx$ using substitution $u=\frac{\pi}{x^{2}}$ , I got: $\frac{1}{2}\int_{0}^{\pi}\frac{\sin u}{u}du$ but I don't know what to do next thanks for any help, and sorry if I have English mistakes.","I'm checking convergence of the series using the integral test. I calculated the integral using substitution , I got: but I don't know what to do next thanks for any help, and sorry if I have English mistakes.",\sum_{n=1}^{\infty}\frac{1}{n}\sin\left(\frac{\pi}{n^{2}}\right) \int_{1}^{+\infty}\frac{1}{x}\sin\left(\frac{\pi}{x^{2}}\right)dx u=\frac{\pi}{x^{2}} \frac{1}{2}\int_{0}^{\pi}\frac{\sin u}{u}du,"['integration', 'sequences-and-series']"
52,"Is there a closed form for this sequence $a_n = m, \ \binom{m}{2}\le n < \binom{m+1}{2}$?",Is there a closed form for this sequence ?,"a_n = m, \ \binom{m}{2}\le n < \binom{m+1}{2}","I was playing around with the sequence: $$ 2,2, 3,3,3,4,4,4,4,\dots $$ If I denote the first element of said sequence by $a_1$ I realized the sequence can be written as $$ a_n = m, \quad  \binom{m}{2}\le n < \binom{m+1}{2} $$ for $m \ge 2$ . Although the above does work, I would like to find a closed for of a sequence that gives $a_n$ in terms of common functions like the floor function. Does anyone know how I could do this? I managed to re-arrange the condition $ \binom{m}{2}\le n < \binom{m+1}{2}$ into $$ 0\le \frac{n}{m} + \frac{1-m}{2} < 1  $$ with hopes of using something like the floor function on it, but I couldn't seem to make it work.","I was playing around with the sequence: If I denote the first element of said sequence by I realized the sequence can be written as for . Although the above does work, I would like to find a closed for of a sequence that gives in terms of common functions like the floor function. Does anyone know how I could do this? I managed to re-arrange the condition into with hopes of using something like the floor function on it, but I couldn't seem to make it work.","
2,2, 3,3,3,4,4,4,4,\dots
 a_1 
a_n = m, \quad  \binom{m}{2}\le n < \binom{m+1}{2}
 m \ge 2 a_n  \binom{m}{2}\le n < \binom{m+1}{2} 
0\le \frac{n}{m} + \frac{1-m}{2} < 1 
","['calculus', 'sequences-and-series', 'closed-form']"
53,"a value of an infinite series, how to obtain this result [closed]","a value of an infinite series, how to obtain this result [closed]",,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question I'm reading some books about series: convergence/divergence and methods of computing sums. Here is a problem stated by myself: what method allows to compute $$ \sum_{n=0}^{\infty}\left(\frac{1}{8n+1}-\frac{1}{8n+3}\right) $$ I know some series have nonelementary value, but this one has. The value can be written with known constants, as WolframAlpha says. The sum does not telescope. Also differentiating $\sum_{n=0}^{\infty}\left(\frac{1}{8n+1}-\frac{1}{8n+3}\right)x^{8n+1 \text{ or } 3}$ gives nothing.","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question I'm reading some books about series: convergence/divergence and methods of computing sums. Here is a problem stated by myself: what method allows to compute I know some series have nonelementary value, but this one has. The value can be written with known constants, as WolframAlpha says. The sum does not telescope. Also differentiating gives nothing.","
\sum_{n=0}^{\infty}\left(\frac{1}{8n+1}-\frac{1}{8n+3}\right)
 \sum_{n=0}^{\infty}\left(\frac{1}{8n+1}-\frac{1}{8n+3}\right)x^{8n+1 \text{ or } 3}","['sequences-and-series', 'convergence-divergence']"
54,How does this infinite sum series switch between ln(2) and -(1-ln(2))?,How does this infinite sum series switch between ln(2) and -(1-ln(2))?,,"I found this simple infinite series of summed terms: 0/1 + 1/2 - 2/3 + 3/4 - 4/5 + 5/6 - 6/7 ....etc When I tried calculating a bunch of terms, weirdly enough, it seems that an even number of terms produces ln(2) and an odd number of terms produces -(1-ln(2)). (You can test that out in this codepen I made) My question is: How does this sequence produce the two numbers? Is there a certain property in it that results in this? Can a known sequence be rearranged and simplified to produce this sequence, or maybe this sequence re-written in a different form? Thanks in advance! Edit #1: I found that taking the known series for ln(2), substracting it from 1 and inversing addition and substraction results in this same series, which should calculate -(1-ln(2)) by definition . My question remains: How does it produce ln(2) and how does it alternate between the two?","I found this simple infinite series of summed terms: 0/1 + 1/2 - 2/3 + 3/4 - 4/5 + 5/6 - 6/7 ....etc When I tried calculating a bunch of terms, weirdly enough, it seems that an even number of terms produces ln(2) and an odd number of terms produces -(1-ln(2)). (You can test that out in this codepen I made) My question is: How does this sequence produce the two numbers? Is there a certain property in it that results in this? Can a known sequence be rearranged and simplified to produce this sequence, or maybe this sequence re-written in a different form? Thanks in advance! Edit #1: I found that taking the known series for ln(2), substracting it from 1 and inversing addition and substraction results in this same series, which should calculate -(1-ln(2)) by definition . My question remains: How does it produce ln(2) and how does it alternate between the two?",,['sequences-and-series']
55,What is the motivation for sequence invariant?,What is the motivation for sequence invariant?,,"I am working on q16 of chapter 1 in Arthur Engel's book: Problem Solving Strategies. Question: Each term in a sequence $1, 0, 1, 0, 1, 0, ...$ starting with the seventh is the sum of the last $6$ terms mod $10$ . Prove that the sequence $..., 0, 1, 0, 1, 0, 1, ...$ never occurs. Official solution: The invariant is $f(a_1, a_2, a_3, a_4, a_5, a_6) = 2a_1 + 4a_2 + 6a_3 + 8a_4 + 10a_5 + 12a_6 \quad(\text{mod } 10)$ . We have $f(1, 0, 1, 0, 1, 0) = 4$ but $f(0, 1, 0, 1, 0, 1) = 8$ , hence $0, 1, 0, 1, 0, 1$ can never occur. My translation/understanding of the solution: We want to find some property that holds in $1, 0, 1, 0, 1, 0$ and is preserved throughout the sequence but not in $0, 1, 0, 1, 0, 1$ , thus implying the latter can never occur. First we compute a few of the terms in the sequence using the recurrence $a_{i+1} = 2a_i - a_{i-6}$ , $$1, 0, 1, 0, 1, 0, 3, 5, 0, 9, 8, 5, 0, 7, 9, 8, 7, 6, 7, 4, 1, 3, 8, 9$$ but an invariant is not immediately obvious. We then note that $1, 0, 1, 0, 1, 0$ shifted one right is $0, 1, 0, 1, 0, 1$ , hence the former has more terms to the left and the latter has more terms to the right. If we take the weighted sum of the first $6$ elements and weight them more if they are on the left we would be assigning a larger value to $1, 0, 1, 0, 1, 0$ indicating that it has more non-zero terms on the left. More concretely: $$f(a_1, a_2, a_3, a_4, a_5, a_6) = w_1a_1 + w_2a_2 + w_3a_3 + w_4a_4 + w_5a_5 + w_6a_6$$ where $w_1 > w_2 > w_3 > w_4 > w_5 > w_6$ . However, how do we choose the weights (trial and error?), and why should $f \text{ mod } 10$ be invariant? (I know how to prove it is invariant, but don't understand why one would intuitively think of it as an invariant without being told beforehand.) Essentially, I am trying to answer: how could I have come up with the invariant?","I am working on q16 of chapter 1 in Arthur Engel's book: Problem Solving Strategies. Question: Each term in a sequence starting with the seventh is the sum of the last terms mod . Prove that the sequence never occurs. Official solution: The invariant is . We have but , hence can never occur. My translation/understanding of the solution: We want to find some property that holds in and is preserved throughout the sequence but not in , thus implying the latter can never occur. First we compute a few of the terms in the sequence using the recurrence , but an invariant is not immediately obvious. We then note that shifted one right is , hence the former has more terms to the left and the latter has more terms to the right. If we take the weighted sum of the first elements and weight them more if they are on the left we would be assigning a larger value to indicating that it has more non-zero terms on the left. More concretely: where . However, how do we choose the weights (trial and error?), and why should be invariant? (I know how to prove it is invariant, but don't understand why one would intuitively think of it as an invariant without being told beforehand.) Essentially, I am trying to answer: how could I have come up with the invariant?","1, 0, 1, 0, 1, 0, ... 6 10 ..., 0, 1, 0, 1, 0, 1, ... f(a_1, a_2, a_3, a_4, a_5, a_6) = 2a_1 + 4a_2 + 6a_3 + 8a_4 + 10a_5 + 12a_6 \quad(\text{mod } 10) f(1, 0, 1, 0, 1, 0) = 4 f(0, 1, 0, 1, 0, 1) = 8 0, 1, 0, 1, 0, 1 1, 0, 1, 0, 1, 0 0, 1, 0, 1, 0, 1 a_{i+1} = 2a_i - a_{i-6} 1, 0, 1, 0, 1, 0, 3, 5, 0, 9, 8, 5, 0, 7, 9, 8, 7, 6, 7, 4, 1, 3, 8, 9 1, 0, 1, 0, 1, 0 0, 1, 0, 1, 0, 1 6 1, 0, 1, 0, 1, 0 f(a_1, a_2, a_3, a_4, a_5, a_6) = w_1a_1 + w_2a_2 + w_3a_3 + w_4a_4 + w_5a_5 + w_6a_6 w_1 > w_2 > w_3 > w_4 > w_5 > w_6 f \text{ mod } 10","['sequences-and-series', 'solution-verification', 'contest-math']"
56,How does one find such a number?,How does one find such a number?,,"Not really one of those who usually ask for help here, but this case seems to be too much for me. I have been going over Courant’s “Differential and Integral Calculus”, and I have finally reached the problems section of the chapter 1.5 (i.e. “The limit of a sequence”). I would not have come here if it hasn’t been for the problem 9, namely the (e) part of it. The problem is generally about the sequence $a_n = \frac{10^n}{n!}$ . I have, as all the parts (a)-(d) asked me to, found the limit of the mentioned sequence (=0), concluded whether it is monotonic or not, found the value of n such that the sequence is monotonic onwards and estimated the difference between the sequence and its limit respectively. Now, the (e) part demands that I calculate the exact value of n such that the difference mentioned is less than $\frac{1}{100}$ . I have attempted to expand the factorial and try to deduce some helpful corollaries, but that does not seem to work. I am genuinely confused by this problem and not certain how I should approach it. It is of utmost importance that I note the following: I do not require the solution, I only need a HINT. Not a very crucial one, which virtually solves it (the problem), but one sufficient enough to proceed. I should be grateful for any help provided. P.S. Please excuse me for some fairly probable mistakes in my writing (happens for I am not a native).","Not really one of those who usually ask for help here, but this case seems to be too much for me. I have been going over Courant’s “Differential and Integral Calculus”, and I have finally reached the problems section of the chapter 1.5 (i.e. “The limit of a sequence”). I would not have come here if it hasn’t been for the problem 9, namely the (e) part of it. The problem is generally about the sequence . I have, as all the parts (a)-(d) asked me to, found the limit of the mentioned sequence (=0), concluded whether it is monotonic or not, found the value of n such that the sequence is monotonic onwards and estimated the difference between the sequence and its limit respectively. Now, the (e) part demands that I calculate the exact value of n such that the difference mentioned is less than . I have attempted to expand the factorial and try to deduce some helpful corollaries, but that does not seem to work. I am genuinely confused by this problem and not certain how I should approach it. It is of utmost importance that I note the following: I do not require the solution, I only need a HINT. Not a very crucial one, which virtually solves it (the problem), but one sufficient enough to proceed. I should be grateful for any help provided. P.S. Please excuse me for some fairly probable mistakes in my writing (happens for I am not a native).",a_n = \frac{10^n}{n!} \frac{1}{100},"['calculus', 'sequences-and-series', 'limits', 'analysis']"
57,Why is the following recurrent sequence convergent?,Why is the following recurrent sequence convergent?,,"Let $a, b , c, d$ be reals. Define the sequence $(x_n)$ as: $$x_0 = a,\,\, x_1 = b$$ $$x_n = \left(1 - \frac{b^2}{n^2}\right)x_{n-1} + \frac{1}{n-1}\sum_{k=0}^{n-2}\binom{2n+1}{2k+1}^{-1} (x_{k+1}-x_k)(c\, x_{n-k-1}- d\, x_{n-k-2}),\,\,\, n \geq2.$$ I want to prove that $(x_n)$ is convergent. Here are two examples for different values of $(a, b , c, d).$ It seems (after several numerical tests) that the sequence is bounded and monotone from specific $n_0.$ The boundness of the sequence imply that $$\sum_{k=0}^{n-2}\binom{2n+1}{2k+1}^{-1} (x_{k+1}-x_k)(c\, x_{n-k-1}- d\, x_{n-k-2})$$ is bounded and the term with the sum goes to zero. Thank you for any hint",Let be reals. Define the sequence as: I want to prove that is convergent. Here are two examples for different values of It seems (after several numerical tests) that the sequence is bounded and monotone from specific The boundness of the sequence imply that is bounded and the term with the sum goes to zero. Thank you for any hint,"a, b , c, d (x_n) x_0 = a,\,\, x_1 = b x_n = \left(1 - \frac{b^2}{n^2}\right)x_{n-1} + \frac{1}{n-1}\sum_{k=0}^{n-2}\binom{2n+1}{2k+1}^{-1} (x_{k+1}-x_k)(c\, x_{n-k-1}- d\, x_{n-k-2}),\,\,\, n \geq2. (x_n) (a, b , c, d). n_0. \sum_{k=0}^{n-2}\binom{2n+1}{2k+1}^{-1} (x_{k+1}-x_k)(c\, x_{n-k-1}- d\, x_{n-k-2})","['real-analysis', 'sequences-and-series']"
58,How to derive this series for $\gamma$ that is only involving odd integer values of $\zeta(s)$?,How to derive this series for  that is only involving odd integer values of ?,\gamma \zeta(s),"With $\gamma$ being the Euler Mascheroni constant , this series is well known: $$1- \sum_{n=2}^{\infty} \frac{\zeta(n)-1}{n} = \gamma \tag{1}$$ The following series involving $\zeta(2n+1)$ also seems to converge to the same value, albeit slower: $$1- \sum_{n=1}^{\infty} \frac{\zeta(2n+1)}{(n+1)\,(2n+1)} = \gamma \tag{2}$$ Is there a way to derive (2) from (1) ?","With being the Euler Mascheroni constant , this series is well known: The following series involving also seems to converge to the same value, albeit slower: Is there a way to derive (2) from (1) ?","\gamma 1- \sum_{n=2}^{\infty} \frac{\zeta(n)-1}{n} = \gamma \tag{1} \zeta(2n+1) 1- \sum_{n=1}^{\infty} \frac{\zeta(2n+1)}{(n+1)\,(2n+1)} = \gamma \tag{2}","['sequences-and-series', 'riemann-zeta', 'euler-mascheroni-constant']"
59,An Interesting Property Of Fibonacci Numbers,An Interesting Property Of Fibonacci Numbers,,"I gave an exam today that had a question which goes like- a. We will call a binary sequence 'sparse' if there are no two consecutive $1$ 's in it. Calculate number of sparse strings of length $n$ . b. Prove that every integer can be expressed as the sum of non-consecutive distinct Fibonacci numbers. c. Prove that the sum in (b) is unique. d. Either derive (a) using (b) and (c) or derive (c) using (a) and (b) . Now, I know very well how to find the recurrence relation in (a) . I also studied the proofs of (b) and (c) a couple of years back, and didn't have much difficulty in constructing them from memory. But, I got stuck in (d) . I was trying to understand how to connect the results of (a) , (b) and (c) . After giving it a thought, I came up with this expression \begin{equation*} S(x_1,x_2,\dots ,x_n)=x_1F_1+x_2F_2+\dots +x_nF_n \end{equation*} for a given $k$ where $F_n$ is the largest Fibonacci number before $k$ and $x_i\in \{0,1\}\;\forall i\in\{1,2,\dots ,n\}$ . Now, if we want $S=k$ , then the sequence $x_1,x_2,\dots ,x_n$ must be sparse. But, from (a) , we know that there are only $F_{n+2}$ such sparse sequences. Also, by (b) , there exists a choice $(y_1,y_2,\dots ,y_n)=(x_1,x_2,\dots ,x_n)$ with $y_i\in \{0,1\}\;\forall i\in\{1,2,\dots ,n\}$ such that $S(y_1,y_2,\dots ,y_n)=k$ . Also, it is clear that the values of $S$ that we can get by changing the choices of $x_i$ 's are arranged in a strict order (i.e., any two of them cannot be equal). So, there is exactly one choice of $x_i$ 's such that $S=k$ . But, there seems to be something fishy about my proof. I have not used the fact that there are $F_{n+1}$ choices of $x_i$ 's anywhere in here. So, is my proof correct? If not, then is my approach correct? Can anybody please help me with this?","I gave an exam today that had a question which goes like- a. We will call a binary sequence 'sparse' if there are no two consecutive 's in it. Calculate number of sparse strings of length . b. Prove that every integer can be expressed as the sum of non-consecutive distinct Fibonacci numbers. c. Prove that the sum in (b) is unique. d. Either derive (a) using (b) and (c) or derive (c) using (a) and (b) . Now, I know very well how to find the recurrence relation in (a) . I also studied the proofs of (b) and (c) a couple of years back, and didn't have much difficulty in constructing them from memory. But, I got stuck in (d) . I was trying to understand how to connect the results of (a) , (b) and (c) . After giving it a thought, I came up with this expression for a given where is the largest Fibonacci number before and . Now, if we want , then the sequence must be sparse. But, from (a) , we know that there are only such sparse sequences. Also, by (b) , there exists a choice with such that . Also, it is clear that the values of that we can get by changing the choices of 's are arranged in a strict order (i.e., any two of them cannot be equal). So, there is exactly one choice of 's such that . But, there seems to be something fishy about my proof. I have not used the fact that there are choices of 's anywhere in here. So, is my proof correct? If not, then is my approach correct? Can anybody please help me with this?","1 n \begin{equation*}
S(x_1,x_2,\dots ,x_n)=x_1F_1+x_2F_2+\dots +x_nF_n
\end{equation*} k F_n k x_i\in \{0,1\}\;\forall i\in\{1,2,\dots ,n\} S=k x_1,x_2,\dots ,x_n F_{n+2} (y_1,y_2,\dots ,y_n)=(x_1,x_2,\dots ,x_n) y_i\in \{0,1\}\;\forall i\in\{1,2,\dots ,n\} S(y_1,y_2,\dots ,y_n)=k S x_i x_i S=k F_{n+1} x_i","['sequences-and-series', 'elementary-number-theory', 'fibonacci-numbers']"
60,Reference to an explicit formula for the Hadamard product of two rational generating functions,Reference to an explicit formula for the Hadamard product of two rational generating functions,,"It is a theorem that if two sequences $\{f_n\}_{n=0}^\infty$ and $\{g_n\}_{n=0}^\infty$ have generating functions $f(x) = \sum_{n=0}^\infty f_n x^n$ and $g(x) = \sum_{n=0}^\infty g_n x^n$ that can be expressed as rational functions $f(x) = p_1(x)/q_1(x)$ and $g(x)=p_2(x)/q_2(x)$ , then the Hadamard product of these two sequences, i.e. the sequence $\{h_n\}_{n=0}^\infty$ with $h_n = f_n g_n$ for all $n \geq 0$ , has a generating function $h(x) = \sum_{n=0}^\infty h_n x^n$ that also can be expressed as a rational function $h(x) = p(x)/q(x)$ .  An existing thread here, ""Algorithm for computing Hadamard product of two rational generating functions"" outlines a explicit procedure to explicitly calculate the coefficients of the polynomials $p(x)$ and $q(x)$ from the coefficients of the polynomials $p_1(x)$ , $q_1(x)$ , $p_2(x)$ , and $q_2(x)$ . Does anyone know a citation to a paper or a textbook in which the procedure given in that thread (or any procedure like it) is given completely explicitly and also completely proven, as opposed to being just outlined?  I have not had any luck in finding such a citation, but I feel that there must be one out there.","It is a theorem that if two sequences and have generating functions and that can be expressed as rational functions and , then the Hadamard product of these two sequences, i.e. the sequence with for all , has a generating function that also can be expressed as a rational function .  An existing thread here, ""Algorithm for computing Hadamard product of two rational generating functions"" outlines a explicit procedure to explicitly calculate the coefficients of the polynomials and from the coefficients of the polynomials , , , and . Does anyone know a citation to a paper or a textbook in which the procedure given in that thread (or any procedure like it) is given completely explicitly and also completely proven, as opposed to being just outlined?  I have not had any luck in finding such a citation, but I feel that there must be one out there.",\{f_n\}_{n=0}^\infty \{g_n\}_{n=0}^\infty f(x) = \sum_{n=0}^\infty f_n x^n g(x) = \sum_{n=0}^\infty g_n x^n f(x) = p_1(x)/q_1(x) g(x)=p_2(x)/q_2(x) \{h_n\}_{n=0}^\infty h_n = f_n g_n n \geq 0 h(x) = \sum_{n=0}^\infty h_n x^n h(x) = p(x)/q(x) p(x) q(x) p_1(x) q_1(x) p_2(x) q_2(x),"['sequences-and-series', 'combinatorics', 'generating-functions']"
61,Find a sequence satisfying a specific limit,Find a sequence satisfying a specific limit,,"Find a positive sequence $\{a_n\}$ , such that $$\lim_{n\to\infty}n\left({1+a_{n+1}\over a_n}-1\right)=1.$$ This problem arises when proving that Given a positive sequence $\{a_n\}$ , the RHS 1 in $$\varlimsup_{n\to\infty}n\left({1+a_{n+1}\over a_n}-1\right)\geq1$$ cannot be replaced by any greater number. So, I think that we can construct such a sequence such that this limit (and thus upper limit) is exactly 1, to prove that we cannot reach a stronger result. The solution directly gives the sequence $a_n=n\ln n$ without any rough work, and I can verify the alleged limit is indeed 1. But I wonder how to come up with such an example?","Find a positive sequence , such that This problem arises when proving that Given a positive sequence , the RHS 1 in cannot be replaced by any greater number. So, I think that we can construct such a sequence such that this limit (and thus upper limit) is exactly 1, to prove that we cannot reach a stronger result. The solution directly gives the sequence without any rough work, and I can verify the alleged limit is indeed 1. But I wonder how to come up with such an example?",\{a_n\} \lim_{n\to\infty}n\left({1+a_{n+1}\over a_n}-1\right)=1. \{a_n\} \varlimsup_{n\to\infty}n\left({1+a_{n+1}\over a_n}-1\right)\geq1 a_n=n\ln n,"['calculus', 'sequences-and-series', 'limits', 'limsup-and-liminf']"
62,Divergence of $\sum_{n=1}^\infty\frac{2\cdot 4\cdot 6\cdot.....(2n)}{n!}$,Divergence of,\sum_{n=1}^\infty\frac{2\cdot 4\cdot 6\cdot.....(2n)}{n!},"I was solving practice problems for my upcoming calculus 1 final and came across this problem. I'm honestly still a little lost about the series and ratio tests. The problem itself is $$\sum_{n=1}^∞\frac{2\cdot 4\cdot 6\cdot.....(2n)}{n!}$$ I identified $$a_n = \frac{2\cdot 4\cdot 6\cdot \ldots (2n)}{n!}$$ but I'm not sure if a $$a_{n+1} = \frac{2\cdot 4\cdot 6\cdot \ldots (2n)^{n+1}}{(n+1)!}$$ or something else? Please help evaluate the limit using, $$\left|\frac{a_{n+1}}{a_n}\right|.$$ Thank you in advance!","I was solving practice problems for my upcoming calculus 1 final and came across this problem. I'm honestly still a little lost about the series and ratio tests. The problem itself is I identified but I'm not sure if a or something else? Please help evaluate the limit using, Thank you in advance!",\sum_{n=1}^∞\frac{2\cdot 4\cdot 6\cdot.....(2n)}{n!} a_n = \frac{2\cdot 4\cdot 6\cdot \ldots (2n)}{n!} a_{n+1} = \frac{2\cdot 4\cdot 6\cdot \ldots (2n)^{n+1}}{(n+1)!} \left|\frac{a_{n+1}}{a_n}\right|.,"['calculus', 'sequences-and-series', 'divergent-series']"
63,Bounding a complicated sequence,Bounding a complicated sequence,,"I ecountered the following horrible sequence during an inductive proof of a bound for another sequence: $$ \sum\limits_{k = 0}^n {\frac{{(n + 3)^{1.47} }}{{(k + 1)^{1.47} (n - k + 1)^{1.47} }}}  $$ for $n\geq 0$ . I would like to show that this sequence is bounded by $5.63$ . It seems to have a maximum at $n=3$ and that it is increasing for $n\geq 89$ . Using the symmetry about $n/2$ and Tannery's theorem, I was able to show that it converges to $2\zeta (1.47) = 5.475994 \ldots$ . Thus, the bound is true for $n$ large enough. It would be sufficient to show that the bound holds after some explicit value of $n$ and finish the proof by computing the first several terms numerically. Any comments and/or suggestions are welcome.","I ecountered the following horrible sequence during an inductive proof of a bound for another sequence: for . I would like to show that this sequence is bounded by . It seems to have a maximum at and that it is increasing for . Using the symmetry about and Tannery's theorem, I was able to show that it converges to . Thus, the bound is true for large enough. It would be sufficient to show that the bound holds after some explicit value of and finish the proof by computing the first several terms numerically. Any comments and/or suggestions are welcome.","
\sum\limits_{k = 0}^n {\frac{{(n + 3)^{1.47} }}{{(k + 1)^{1.47} (n - k + 1)^{1.47} }}} 
 n\geq 0 5.63 n=3 n\geq 89 n/2 2\zeta (1.47) = 5.475994 \ldots n n","['sequences-and-series', 'inequality']"
64,Approximate value of Series,Approximate value of Series,,"Consider the series $$ \sum_{k=2}^\infty \frac{\ln(k)}{k^p}, $$ which is easily seen to converge if $p>1$ . Numerical computations seems to reveal that, if $n\in\mathbb N$ $$ \left\lceil\sum_{k=2}^\infty \frac{\ln(k)}{k^{1+10^{-n}}}\right\rceil=10^{2n}. $$ Is there an easy way to prove this?","Consider the series which is easily seen to converge if . Numerical computations seems to reveal that, if Is there an easy way to prove this?","
\sum_{k=2}^\infty \frac{\ln(k)}{k^p},
 p>1 n\in\mathbb N 
\left\lceil\sum_{k=2}^\infty \frac{\ln(k)}{k^{1+10^{-n}}}\right\rceil=10^{2n}.
",['sequences-and-series']
65,$\sum_{n=1}^{\infty}\frac{(2^n + 3^n)\sin(n)}{2^n + n^2\cdot3^n}$,,\sum_{n=1}^{\infty}\frac{(2^n + 3^n)\sin(n)}{2^n + n^2\cdot3^n},Proving the convergence of a series by Weierstrass M-test. $$\sum_{n=1}^{\infty}\frac{(2^n + 3^n)\sin(n)}{2^n + n^2\cdot3^n}.$$ $$\frac{(2^n + 3^n)\sin(n)}{2^n + n^2\cdot3^n} \leq \frac{2^n + 3^n}{2^n + n^2 \cdot 3^n} = \frac{1 + \left(\frac{3}{2}\right)^n}{1 + n^2 \left(\frac{3}{2}\right)^n}.$$ Further I got stuck how to evaluate and get convergence.,Proving the convergence of a series by Weierstrass M-test. Further I got stuck how to evaluate and get convergence.,\sum_{n=1}^{\infty}\frac{(2^n + 3^n)\sin(n)}{2^n + n^2\cdot3^n}. \frac{(2^n + 3^n)\sin(n)}{2^n + n^2\cdot3^n} \leq \frac{2^n + 3^n}{2^n + n^2 \cdot 3^n} = \frac{1 + \left(\frac{3}{2}\right)^n}{1 + n^2 \left(\frac{3}{2}\right)^n}.,"['sequences-and-series', 'analysis', 'convergence-divergence']"
66,Positive integer solutions to $y^2=a(1+xy-x^2)$,Positive integer solutions to,y^2=a(1+xy-x^2),"Let $a>3$ be an integer. Define a sequence $X$ as : \begin{equation}   \begin{aligned}     x_1 & = 1\\     x_2  & = a-1\\       x_n & = (a-2)x_{n-1}-x_{n-2}, \ \ n\ge3   \end{aligned} \end{equation} if $a$ is not a perfect square and \begin{equation}   \begin{aligned}     x_1 & = 1\\     x_2  & = \sqrt{a} > 0\\     x_3 & =a-1\\     x_4 & =(a-2)\sqrt{a} > 0\\       x_{2n+1} & = (a-2)x_{2n-1}-x_{2n-3} , \ \ \ \ \ \ \  n\ge 2\\  x_{2n} & = (a-2)x_{2n-2}-x_{2n-4}, \ \ \ \ \ \ \  n\ge 3   \end{aligned} \end{equation} if $a$ is a perfect sqaure. From a maple output, it appears the terms of this sequence form a complete solution for $x$ in positive integers for the given diophantine equation $y^2=a(1+xy-x^2)$ . How do we go about proving this i.e each term of sequence $X$ is a solution and that these are the only positive solutions. I tried mathematical induction but got stuck.","Let be an integer. Define a sequence as : if is not a perfect square and if is a perfect sqaure. From a maple output, it appears the terms of this sequence form a complete solution for in positive integers for the given diophantine equation . How do we go about proving this i.e each term of sequence is a solution and that these are the only positive solutions. I tried mathematical induction but got stuck.","a>3 X \begin{equation}
  \begin{aligned}
    x_1 & = 1\\
    x_2  & = a-1\\
      x_n & = (a-2)x_{n-1}-x_{n-2}, \ \ n\ge3
  \end{aligned}
\end{equation} a \begin{equation}
  \begin{aligned}
    x_1 & = 1\\
    x_2  & = \sqrt{a} > 0\\
    x_3 & =a-1\\
    x_4 & =(a-2)\sqrt{a} > 0\\
      x_{2n+1} & = (a-2)x_{2n-1}-x_{2n-3} , \ \ \ \ \ \ \  n\ge 2\\
 x_{2n} & = (a-2)x_{2n-2}-x_{2n-4}, \ \ \ \ \ \ \  n\ge 3
  \end{aligned}
\end{equation} a x y^2=a(1+xy-x^2) X","['real-analysis', 'sequences-and-series', 'elementary-number-theory', 'algebraic-geometry', 'diophantine-equations']"
67,Convergence of $\sum_{n=1}^{\infty} x\frac{\sin(n^2x)}{n^2}$. My try.,Convergence of . My try.,\sum_{n=1}^{\infty} x\frac{\sin(n^2x)}{n^2},"Examine the convergence of: $$\sum_{n=1}^{\infty} x\frac{\sin(n^2x)}{n^2}$$ Pointwise convergence (for every $ x \in \mathbb{R}$ ): $\displaystyle \lim_{n \to \infty} x\frac{\sin(n^2x)}{n^2} = 0$ , because $\sin(n^2x) \in [-1, 1]$ Uniform convergence (for every $ x \in \mathbb{R}$ and $n \in \mathbb{N}$ ): form dirichlet criterion: $$\displaystyle \sum_{n=1}^{\infty} x\frac{\sin(n^2x)}{n^2} = \displaystyle \sum_{n=1}^{\infty} f_n(x) \cdot g_n(x) $$ where: $f_n(x) = \frac{\sin(n^2x)}{n} \leq 2$ which works for: $ \forall x \in \mathbb{R}, n \in \mathbb{N}$ $g_n(x) = \frac{x}{n} \implies \displaystyle \lim_{n \to \infty} g_n(x) = 0$ (monotonously) Therefore the series is uniformly convergent for $x \in \mathbb{R}$ . Is that correct?","Examine the convergence of: Pointwise convergence (for every ): , because Uniform convergence (for every and ): form dirichlet criterion: where: which works for: (monotonously) Therefore the series is uniformly convergent for . Is that correct?","\sum_{n=1}^{\infty} x\frac{\sin(n^2x)}{n^2}  x \in \mathbb{R} \displaystyle \lim_{n \to \infty} x\frac{\sin(n^2x)}{n^2} = 0 \sin(n^2x) \in [-1, 1]  x \in \mathbb{R} n \in \mathbb{N} \displaystyle \sum_{n=1}^{\infty} x\frac{\sin(n^2x)}{n^2} = \displaystyle \sum_{n=1}^{\infty} f_n(x) \cdot g_n(x)  f_n(x) = \frac{\sin(n^2x)}{n} \leq 2  \forall x \in \mathbb{R}, n \in \mathbb{N} g_n(x) = \frac{x}{n} \implies \displaystyle \lim_{n \to \infty} g_n(x) = 0 x \in \mathbb{R}","['real-analysis', 'sequences-and-series', 'analysis', 'convergence-divergence', 'uniform-convergence']"
68,Derivatives of the geometric series to prove equality,Derivatives of the geometric series to prove equality,,"I have to show that $(1-p)^{-r} = \sum_{k=0}^{\infty} \binom{k+r-1}{k}p^k$ where $p \in (0,1)$ and $r \in \mathbb{N}_{\geq 1}$ . I got the hint that I have to consider the derivatives of the geometric series. Those would be: $\sum_{k=1}^{\infty} kx^{k-1}, \sum_{k=2}^{\infty}\frac{(n-1)n}{2}x^{n-2}, \dots$ I don't see the pattern to somehow connect this to prove my equality. SOLUTION We will prove the statement by induction. Base case: $r=1$ $(1-p)^{-1} = \sum_{k=0}^{\infty} p ^k$ (geometric series), hence base case is true Induction step: Assume $(1-p)^{-r} = \sum_{k=0}^{\infty} \binom{k+r-1}{k}p^k$ for some $r$ . We will show that it is true for $r+1$ . $(1-p)^{-(r+1)}= \sum_{k=0}^{\infty} \binom{k+r-1}{k}p^k \sum_{k=0}^{\infty}p^k$ Using the Cauchy-Product we get: $=\sum_{k=0}^{\infty} p^k\sum_{n=0}^k \binom{n+r-1}{n} $ Sub-Claim $\sum_{n=0}^k \binom{n+r-1}{n} = \binom{k+r}{k}$ Base-Case : $k=0$ is true Induction-step: Assume $\sum_{n=0}^k \binom{n+r-1}{n} = \binom{k+r}{k}$ for some $k$ . We will show it for $k+1$ . $\sum_{n=0}^{k+1}\binom{n+r-1}{n} = \binom{k+1+r-1}{k+1} + \binom{k+r}{k} = \binom{k+1+r}{k+1}$ $\implies $ Sub-claim is true. We will continue with our first induction: $=\sum_{k=0}^{\infty} p^k\sum_{n=0}^k \binom{n+r-1}{n} $ $=\sum_{k=0}^{\infty} p^k \binom{k+r}{k}$ $\implies$ Claim proven","I have to show that where and . I got the hint that I have to consider the derivatives of the geometric series. Those would be: I don't see the pattern to somehow connect this to prove my equality. SOLUTION We will prove the statement by induction. Base case: (geometric series), hence base case is true Induction step: Assume for some . We will show that it is true for . Using the Cauchy-Product we get: Sub-Claim Base-Case : is true Induction-step: Assume for some . We will show it for . Sub-claim is true. We will continue with our first induction: Claim proven","(1-p)^{-r} = \sum_{k=0}^{\infty} \binom{k+r-1}{k}p^k p \in (0,1) r \in \mathbb{N}_{\geq 1} \sum_{k=1}^{\infty} kx^{k-1}, \sum_{k=2}^{\infty}\frac{(n-1)n}{2}x^{n-2}, \dots r=1 (1-p)^{-1} = \sum_{k=0}^{\infty} p ^k (1-p)^{-r} = \sum_{k=0}^{\infty} \binom{k+r-1}{k}p^k r r+1 (1-p)^{-(r+1)}= \sum_{k=0}^{\infty} \binom{k+r-1}{k}p^k \sum_{k=0}^{\infty}p^k =\sum_{k=0}^{\infty} p^k\sum_{n=0}^k \binom{n+r-1}{n}  \sum_{n=0}^k \binom{n+r-1}{n} = \binom{k+r}{k} k=0 \sum_{n=0}^k \binom{n+r-1}{n} = \binom{k+r}{k} k k+1 \sum_{n=0}^{k+1}\binom{n+r-1}{n} = \binom{k+1+r-1}{k+1} + \binom{k+r}{k} = \binom{k+1+r}{k+1} \implies  =\sum_{k=0}^{\infty} p^k\sum_{n=0}^k \binom{n+r-1}{n}  =\sum_{k=0}^{\infty} p^k \binom{k+r}{k} \implies","['sequences-and-series', 'solution-verification', 'geometric-series']"
69,Let $(x_n)$ and $(y_n)$ be sequences such that $(x_n)$ is a subsequence of $(y_n)$ and $(y_n)$ is a subsequence of $(x_n)$. $x_n=y_n$ for all $n$?,Let  and  be sequences such that  is a subsequence of  and  is a subsequence of .  for all ?,(x_n) (y_n) (x_n) (y_n) (y_n) (x_n) x_n=y_n n,"Let $(x_n)$ and $(y_n)$ be sequences such that $(x_n)$ is a subsequence of $(y_n)$ and $(y_n)$ is a subsequence of $(x_n)$ . Given that $x_n$ converges, does it follow that $x_n=y_n$ for all $n$ ? I strongly suspect this is true. I have an idea but I'm not convinced its super tight. By our subsequence fact, let $x_{a_n}=y_n$ and $y_{b_n}=x_n$ . Since we have to fit these terms in the sequence and they are all in order, we must have $a_n\ge n$ and $b_n \ge n$ with equality if and only if the first $n-1$ terms are identical. Assume BWOC $\exists k: x_k\neq y_k$ with $k$ minimal. Well $x_{a_k}=y_k$ with $a_k\gt k$ , but $y_{b_{a_k}}=x_{a_k}, b_{a_k}\gt a_k \ (>k)$ . In other words, $x_k \neq y_k \implies \text{$y_k$ appears later in the sequence ($x_n$)}\implies \text{another $y_k$ appears later in the sequence $(y_n)$}$ and this keeps going on back and forth. Since $(x_n)$ converges and $y_k$ appears infinitely many times in $(x_n)$ , it must converge to $y_k$ . But, by the same argument, we can show it converges to $x_k$ . Since $x_k\neq y_k$ , this is a contradiction. After writing this out, I feel like my idea is right but I just have this doubt in my execution that I can't shake. Is my argument correct or is the proposition false after all?","Let and be sequences such that is a subsequence of and is a subsequence of . Given that converges, does it follow that for all ? I strongly suspect this is true. I have an idea but I'm not convinced its super tight. By our subsequence fact, let and . Since we have to fit these terms in the sequence and they are all in order, we must have and with equality if and only if the first terms are identical. Assume BWOC with minimal. Well with , but . In other words, and this keeps going on back and forth. Since converges and appears infinitely many times in , it must converge to . But, by the same argument, we can show it converges to . Since , this is a contradiction. After writing this out, I feel like my idea is right but I just have this doubt in my execution that I can't shake. Is my argument correct or is the proposition false after all?","(x_n) (y_n) (x_n) (y_n) (y_n) (x_n) x_n x_n=y_n n x_{a_n}=y_n y_{b_n}=x_n a_n\ge n b_n \ge n n-1 \exists k: x_k\neq y_k k x_{a_k}=y_k a_k\gt k y_{b_{a_k}}=x_{a_k}, b_{a_k}\gt a_k \ (>k) x_k \neq y_k \implies \text{y_k appears later in the sequence (x_n)}\implies \text{another y_k appears later in the sequence (y_n)} (x_n) y_k (x_n) y_k x_k x_k\neq y_k","['real-analysis', 'sequences-and-series', 'solution-verification']"
70,Finding the limit for a rational expression involving factorials,Finding the limit for a rational expression involving factorials,,"The task is to find $$L=\lim_{n\rightarrow \infty} \frac{1}{2n}\sqrt[n]{\frac{(2n+1)!}{n!}}.$$ I say we resort to Sirling's approximation $k!\approx \sqrt{2\pi k} (\frac{k}{e})^k$ : $$ L \approx \lim_n \frac{1}{2n}\frac{\bigg(\sqrt{2\pi (2n+1)}(\frac{2n+1}{e})^{2n+1}\bigg)^{1/n}}{\bigg(\sqrt{2\pi n}(\frac{n}{e})^{n}\bigg)^{1/n}}\approx \frac {4n^2/e^2}{2n^2/e} \approx \frac {2}{e}.$$ however, as usual there is a solution manual that disagrees and says $L=2$ . I'd appreciate it if you could help me figure out what's wrong.","The task is to find I say we resort to Sirling's approximation : however, as usual there is a solution manual that disagrees and says . I'd appreciate it if you could help me figure out what's wrong.",L=\lim_{n\rightarrow \infty} \frac{1}{2n}\sqrt[n]{\frac{(2n+1)!}{n!}}. k!\approx \sqrt{2\pi k} (\frac{k}{e})^k  L \approx \lim_n \frac{1}{2n}\frac{\bigg(\sqrt{2\pi (2n+1)}(\frac{2n+1}{e})^{2n+1}\bigg)^{1/n}}{\bigg(\sqrt{2\pi n}(\frac{n}{e})^{n}\bigg)^{1/n}}\approx \frac {4n^2/e^2}{2n^2/e} \approx \frac {2}{e}. L=2,"['calculus', 'sequences-and-series', 'limits', 'approximation', 'factorial']"
71,What is the logic behind the balls colours in MarkSix lottery?,What is the logic behind the balls colours in MarkSix lottery?,,"I am not familiar with this kind of problem and I am trying to find what could be the general term or pattern used for the color assignment in the Mark Six lottery ( This is the matrix of colors ). There are three sequences: Red balls: [1, 2, 7, 8, 12, 13, 18, 19, 23, 24, 29, 30, 34, 35, 40, 45, 46]; Red(n) = ? Blue balls: [3, 4, 9, 10, 14, 15, 20, 25, 26, 31, 36, 37, 41, 42, 47, 48]; Blue(n) = ? Green balls: [5, 6, 11, 16, 17, 21, 22, 27, 28, 32, 33, 38, 39, 43, 44, 49]; Green(n) = ? How do you think would be the best approach to find the pattern followed there? What would be the general term for those number sequences? Thanks in advance!","I am not familiar with this kind of problem and I am trying to find what could be the general term or pattern used for the color assignment in the Mark Six lottery ( This is the matrix of colors ). There are three sequences: Red balls: [1, 2, 7, 8, 12, 13, 18, 19, 23, 24, 29, 30, 34, 35, 40, 45, 46]; Red(n) = ? Blue balls: [3, 4, 9, 10, 14, 15, 20, 25, 26, 31, 36, 37, 41, 42, 47, 48]; Blue(n) = ? Green balls: [5, 6, 11, 16, 17, 21, 22, 27, 28, 32, 33, 38, 39, 43, 44, 49]; Green(n) = ? How do you think would be the best approach to find the pattern followed there? What would be the general term for those number sequences? Thanks in advance!",,['sequences-and-series']
72,Sum of a dyadic sequence satisfying $\delta\omega_\lambda \leq \omega_{2\lambda}\leq \kappa\omega_\lambda$ with $1<\delta<\kappa$,Sum of a dyadic sequence satisfying  with,\delta\omega_\lambda \leq \omega_{2\lambda}\leq \kappa\omega_\lambda 1<\delta<\kappa,"I was reading the proof of a lemma and I found something that seemed to be a ""trivial inequality"" but I haven't been able to prove it, so I was wondering if anyone has a good answer for it. Lets fix two real numbers $1<\delta<\kappa$ . Now, consider a sequence $(\omega_{\lambda})_{\lambda}\subset\mathbb{R}_+$ with $\lambda$ running over the integer dyadic numbers and where $\mathbb{R}_+=(0,+\infty)$ . Suposse that $(\omega_\lambda)_\lambda$ satisfies the following inequalities: $$ \delta\omega_\lambda \leq \omega_{2\lambda}\leq \kappa\omega_\lambda. $$ Then, there exists a constant $c>0$ such that $$ \sum_{\mu\geq \lambda/8}\omega_\mu^{-1}\leq c\omega_{\lambda}^{-1}. $$ Here, notation $\sum_\lambda \omega_\lambda$ means $\sum_{n=0}^{+\infty}\omega_{2^n}$ . I think it should be a silly trick using power series but I am getting confuse since I am not very used to dyadic stuffs.","I was reading the proof of a lemma and I found something that seemed to be a ""trivial inequality"" but I haven't been able to prove it, so I was wondering if anyone has a good answer for it. Lets fix two real numbers . Now, consider a sequence with running over the integer dyadic numbers and where . Suposse that satisfies the following inequalities: Then, there exists a constant such that Here, notation means . I think it should be a silly trick using power series but I am getting confuse since I am not very used to dyadic stuffs.","1<\delta<\kappa (\omega_{\lambda})_{\lambda}\subset\mathbb{R}_+ \lambda \mathbb{R}_+=(0,+\infty) (\omega_\lambda)_\lambda 
\delta\omega_\lambda \leq \omega_{2\lambda}\leq \kappa\omega_\lambda.
 c>0 
\sum_{\mu\geq \lambda/8}\omega_\mu^{-1}\leq c\omega_{\lambda}^{-1}.
 \sum_\lambda \omega_\lambda \sum_{n=0}^{+\infty}\omega_{2^n}","['real-analysis', 'calculus', 'sequences-and-series', 'analysis', 'power-series']"
73,"Writing a Recursive Sequence and finding out limit by a ""weird"" property","Writing a Recursive Sequence and finding out limit by a ""weird"" property",,"I apologize for lacking of a better title and for potencial math language mistakes as I'm not an english native so there's some terms I might miss. I found out a note of my college that had the following written on: Calculate $\lim(x_n)$ if $$x_n=\frac{n}{2^{n+1}}\sum_{i=1}^{n}\frac{2^i}{i}$$ Then their resolution follows as: This sequence can be defined by recursion as $$x_{n+1}= \frac{n+1}{2n}.\underbrace{\frac{n}{2^{n+1}}\sum_{i=1}^{n}\frac{2^i}{i}}_{x_n} + \frac{n+1}{2^{n+2}}\frac{2^{n+1}}{n+1} = $$ $$\frac{n+1}{2n}x_n + \frac{1}{2} = x_{n+1}$$ I really don't understand how they defined the recursive sequence, I tried to calculate $x_{n+1}$ and had a different result than the solution everytime I tried (if I even did it correctly). The next step is perhaps the most confuse to me, as they said: $\frac{n+1}{2n} \to \frac{1}{2}\hspace{1.5mm}\text{(obvious to me)}$ and as stated in a theorem we studied before (I really don't recognize this theorem and can't search for it) $x_n$ has a limit and it is given by $$\frac{\frac{1}{2}}{1 - \frac{1}{2}} = 1$$ Besides not getting how they defined the recursive sequence I believe I'm not aware of the theorem they stated as well (even though the outcome looks like the sum of a geometric series of ratio $\frac{1}{2}$ starting on the first term) so I would really appreciate it if someone could help me figuring out both things. Thank you so much for your attention.","I apologize for lacking of a better title and for potencial math language mistakes as I'm not an english native so there's some terms I might miss. I found out a note of my college that had the following written on: Calculate if Then their resolution follows as: This sequence can be defined by recursion as I really don't understand how they defined the recursive sequence, I tried to calculate and had a different result than the solution everytime I tried (if I even did it correctly). The next step is perhaps the most confuse to me, as they said: and as stated in a theorem we studied before (I really don't recognize this theorem and can't search for it) has a limit and it is given by Besides not getting how they defined the recursive sequence I believe I'm not aware of the theorem they stated as well (even though the outcome looks like the sum of a geometric series of ratio starting on the first term) so I would really appreciate it if someone could help me figuring out both things. Thank you so much for your attention.",\lim(x_n) x_n=\frac{n}{2^{n+1}}\sum_{i=1}^{n}\frac{2^i}{i} x_{n+1}= \frac{n+1}{2n}.\underbrace{\frac{n}{2^{n+1}}\sum_{i=1}^{n}\frac{2^i}{i}}_{x_n} + \frac{n+1}{2^{n+2}}\frac{2^{n+1}}{n+1} =  \frac{n+1}{2n}x_n + \frac{1}{2} = x_{n+1} x_{n+1} \frac{n+1}{2n} \to \frac{1}{2}\hspace{1.5mm}\text{(obvious to me)} x_n \frac{\frac{1}{2}}{1 - \frac{1}{2}} = 1 \frac{1}{2},"['calculus', 'sequences-and-series', 'limits', 'recurrence-relations', 'recursion']"
74,Uniform convergence implies pointwise convergence,Uniform convergence implies pointwise convergence,,"I am having trouble proving a simple proposition regarding uniform convergence and pointwise convergence in Real Analysis . Problem: Suppose that $\left(f_{n}\right)$ is a sequence of functions $f_{n}: A \rightarrow \mathbb{R}$ such that $\left(f_{n}\right)$ converges uniformly to $f: A \rightarrow \mathbb{R}$ . Prove that $\left(f_{n}\right)$ also converges pointwise to $f: A \rightarrow \mathbb{R}$ Relevant definitions/Notations: One says that $f_{n} \rightarrow f$ uniformly on $A$ if, for every $\epsilon>0,$ there exists $N \in \mathbb{N}$ such that $n>N$ implies that $$\left|f_{n}(x)-f(x)\right|<\epsilon$$ for all $x \in A$ . Finally, we say that $f_{n} \rightarrow f$ pointwise on $A$ if, given $\epsilon>0,$ for each $x \in A$ there exists $N \in \mathbb{N}$ such that $n>N$ implies that $$\left|f_{n}(x)-f(x)\right|<\epsilon$$ Attempts: I tried to write down the definition of uniform convergence and then arguing that, in particular, since $N \in \mathbb{N}$ from uniform convergence works for any given point in $x \in A$ , then it must work for a given point and from that conclude pointwise convergence. I also checked some proofs like the one that states that uniform continuity implies continuity and write something similar, but i just dont know how to do it. I would highly appreciate a detailed proof regarding this fact, i am trying to become proeficient at proof writing. Thanks in advance, Lucas","I am having trouble proving a simple proposition regarding uniform convergence and pointwise convergence in Real Analysis . Problem: Suppose that is a sequence of functions such that converges uniformly to . Prove that also converges pointwise to Relevant definitions/Notations: One says that uniformly on if, for every there exists such that implies that for all . Finally, we say that pointwise on if, given for each there exists such that implies that Attempts: I tried to write down the definition of uniform convergence and then arguing that, in particular, since from uniform convergence works for any given point in , then it must work for a given point and from that conclude pointwise convergence. I also checked some proofs like the one that states that uniform continuity implies continuity and write something similar, but i just dont know how to do it. I would highly appreciate a detailed proof regarding this fact, i am trying to become proeficient at proof writing. Thanks in advance, Lucas","\left(f_{n}\right) f_{n}: A \rightarrow \mathbb{R} \left(f_{n}\right) f: A \rightarrow \mathbb{R} \left(f_{n}\right) f: A \rightarrow \mathbb{R} f_{n} \rightarrow f A \epsilon>0, N \in \mathbb{N} n>N \left|f_{n}(x)-f(x)\right|<\epsilon x \in A f_{n} \rightarrow f A \epsilon>0, x \in A N \in \mathbb{N} n>N \left|f_{n}(x)-f(x)\right|<\epsilon N \in \mathbb{N} x \in A","['real-analysis', 'sequences-and-series', 'proof-writing', 'solution-verification', 'uniform-convergence']"
75,Show that $b_nb_k\mid b_{n+k}$,Show that,b_nb_k\mid b_{n+k},"Let ${a_n}$ be sequence such that $\forall n,k\in\mathbb{N}, a_n\mid a_{n+k}-a_k$ and, let $b_n=\Pi^{n}_{i=1} a_i$ . Then prove that $\forall n, k\in\mathbb{N}, b_nb_k\mid b_{n+k}$ . $a_i=ci, c\in\mathbb{N}$ satisfies the condition: I'll prove $m!k!\mid (m+k)!$ . $p\in\mathbb{P}$ , let $\upsilon_p(a)=k\iff p^k\mid\mid a$ . $\forall p\in\mathbb{P}$ , $\upsilon_p(\frac{(m+k)!}{m!k!})=\sum_{i=1}^{\infty}([\frac{m+k}{p^i}]-[\frac{m}{p^i}]-[\frac{k}{p^i}])$ and since $[x+y]\ge [x]+[y]$ , $[\frac{m+k}{p^i}]\ge [\frac{m}{p^i}]+[\frac{k}{p^i}]$ for all $i\implies \forall p\in\mathbb{P}, \upsilon_p(m!k!)\le\upsilon_p((m+k)!)\implies m!k!\mid (m+k)!$ . And I want to prove that there is no more solutions. Can anyone help me?","Let be sequence such that and, let . Then prove that . satisfies the condition: I'll prove . , let . , and since , for all . And I want to prove that there is no more solutions. Can anyone help me?","{a_n} \forall n,k\in\mathbb{N}, a_n\mid a_{n+k}-a_k b_n=\Pi^{n}_{i=1} a_i \forall n, k\in\mathbb{N}, b_nb_k\mid b_{n+k} a_i=ci, c\in\mathbb{N} m!k!\mid (m+k)! p\in\mathbb{P} \upsilon_p(a)=k\iff p^k\mid\mid a \forall p\in\mathbb{P} \upsilon_p(\frac{(m+k)!}{m!k!})=\sum_{i=1}^{\infty}([\frac{m+k}{p^i}]-[\frac{m}{p^i}]-[\frac{k}{p^i}]) [x+y]\ge [x]+[y] [\frac{m+k}{p^i}]\ge [\frac{m}{p^i}]+[\frac{k}{p^i}] i\implies \forall p\in\mathbb{P}, \upsilon_p(m!k!)\le\upsilon_p((m+k)!)\implies m!k!\mid (m+k)!","['sequences-and-series', 'number-theory', 'elementary-number-theory', 'contest-math', 'divisibility']"
76,Integration and periodic divergent series,Integration and periodic divergent series,,"Consider the divergent infinite series $$ \sum_{n=1}^\infty 5^n \cos(nt) $$ where $t \in \mathbb{R}$ .  I don't believe it has a closed form.  However, if I take the integral with respect to $t$ : $$ \int_{-\pi}^\pi \sum_{n=1}^\infty 5^n \cos(nt) \, dt = \sum_{n=1}^\infty 5^n \int_{-\pi}^\pi \cos(nt) \, dt$$ $$ = \sum_{n=1}^\infty 5^n \cdot 0 = 0$$ So even though the series is divergent it still has a finite integral.  This seems to be a consequence of the fact that it's periodic over the integration domain: the infinities sort of cancel each other out. This can extend also to the product of series: $$ \int_{-\pi}^\pi \left( \sum_{n=1}^\infty 5^n \cos(nt) \right) \left(\sum_{n=1}^\infty \frac 1 {7^n} \cos(nt) \right) \,dt$$ $$ = \pi \sum_{n=1}^\infty \left( \frac 5 7 \right)^n = \frac 5 2 \pi$$ I'm trying to understand the underlying properties at work here.  Specifically, is there a way to come up with a ""closed form"" for a periodic infinite divergent series which behaves the same under integration (for instance, something I could use with integration by parts) without actually being the limit of the partial sums of $f(t)$ ?  That is, something like a proxy function with the infinities sort of preemptively normalized out?","Consider the divergent infinite series where .  I don't believe it has a closed form.  However, if I take the integral with respect to : So even though the series is divergent it still has a finite integral.  This seems to be a consequence of the fact that it's periodic over the integration domain: the infinities sort of cancel each other out. This can extend also to the product of series: I'm trying to understand the underlying properties at work here.  Specifically, is there a way to come up with a ""closed form"" for a periodic infinite divergent series which behaves the same under integration (for instance, something I could use with integration by parts) without actually being the limit of the partial sums of ?  That is, something like a proxy function with the infinities sort of preemptively normalized out?"," \sum_{n=1}^\infty 5^n \cos(nt)  t \in \mathbb{R} t  \int_{-\pi}^\pi \sum_{n=1}^\infty 5^n \cos(nt) \, dt = \sum_{n=1}^\infty 5^n \int_{-\pi}^\pi \cos(nt) \, dt  = \sum_{n=1}^\infty 5^n \cdot 0 = 0  \int_{-\pi}^\pi \left( \sum_{n=1}^\infty 5^n \cos(nt) \right) \left(\sum_{n=1}^\infty \frac 1 {7^n} \cos(nt) \right) \,dt  = \pi \sum_{n=1}^\infty \left( \frac 5 7 \right)^n = \frac 5 2 \pi f(t)","['integration', 'sequences-and-series', 'divergent-series', 'periodic-functions']"
77,$\mathbb{R}^{\mathbb{N}}$ Hilbert space with uncountable orthonormal basis?,Hilbert space with uncountable orthonormal basis?,\mathbb{R}^{\mathbb{N}},"Let's say we have a Hilbert space of sequences $u_n\in\mathbb{R}^{\mathbb{N}}$ , equipped with some inner product $(\cdot,\cdot)$ . Let's say there is a Hermitian operator $M$ acting on this space, with a continuous spectrum of eigenvalues $\lambda\in\mathbb{R}$ . Because $M$ is Hermitian, its eigenvectors are automatically orthogonal to each other $(a^{\lambda},a^{\lambda'})=0$ for $\lambda\neq\lambda'$ . The eigenvectors are assumed to be in the Hilbert space (i.e. have finite norm). Owing to the existence of this Hermitian operator $M$ , this Hilbert space has an uncountable orthonormal basis. I don't see any obstacles for such a scenario to occur, but it seems counter-intuitive for a sequence $u_n$ to have finite norm while also being orthogonal to an uncountable number of sequences. Does this scenario make sense? Or is there something about $M$ and the Hilbert space which makes it impossible? Edit : The reason I ask this question is that I seem to have come across a scenario in which this does in fact occur. The Hilbert space in question has the unusual inner product $$(u,v)=\sum_{n=0}^{\infty}\frac{(2n+1)!!}{(2n)!!}u_nv_n.$$ And the Hermitian operator is $$M_{nm}=(4n+3)\delta_{nm}+2n\delta_{n-1m}+(2n+3)\delta_{n+1m}.$$ You can check that it is Hermitian with respect to this inner product by noting that $\frac{(2n+1)!!}{(2n)!!}M_{nm}$ is symmetric. This operator can be written in the form $M=A+A^{\dagger}+3$ , where $$A_{nm}=2n\delta_{nm}+(2n+3)\delta_{n+1m}.$$ These operators obey the commutator $$[A,A^{\dagger}]=2M.$$ This means in particular that $$e^{cA}Me^{-cA}=e^{2c}M$$ Which implies that if $v$ is an eigenvector of $M$ with eigenvalue $\lambda$ , then $e^{-cA}v$ is an eigenvector with eigenvalue $e^{2c}\lambda$ , for any constant $c$ . Thus providing a continuous spectrum of eigenvalues. To find an eigenvector $v$ , we may solve the recursive relation associated with the equation $Mv=\lambda v$ , and find that there are normalizeable solutions for real $\lambda<0$ , with asymptotic behavior $$v_n\sim(-1)^n\frac{1}{\sqrt{n}}e^{-\sqrt{2n|\lambda|}},\quad n\to\infty$$ Hermiticity of $M$ Since this has been questioned a couple of times I will show that $M$ is Hermitian with respect to this inner product. As I mentioned it is equivalent to showing that $\frac{(2n+1)!!}{(2n)!!}M_{nm}$ is symmetric. $$\frac{(2n+1)!!}{(2n)!!}M_{nm}=\frac{(2n+1)!!}{(2n)!!}(4n+3)\delta_{nm}+\frac{(2n+1)!!}{(2n-2)!!}\delta_{n-1m}+\frac{(2n+3)!!}{(2n)!!}\delta_{n+1m}$$ This is symmetric since $$\frac{(2n+1)!!}{(2n-2)!!}\delta_{n-1m}=\frac{(2m+3)!!}{(2m)!!}\delta_{m+1n}.$$ Reviewing the definition of a Hermitian operator, it presumes it is a bounded operator, which we have found that this operator is not (assuming the rest of my calculations are correct). Perhaps the statement about orthogonality of eigenvectors is not true when the ""Hermitian"" operator is unbounded?","Let's say we have a Hilbert space of sequences , equipped with some inner product . Let's say there is a Hermitian operator acting on this space, with a continuous spectrum of eigenvalues . Because is Hermitian, its eigenvectors are automatically orthogonal to each other for . The eigenvectors are assumed to be in the Hilbert space (i.e. have finite norm). Owing to the existence of this Hermitian operator , this Hilbert space has an uncountable orthonormal basis. I don't see any obstacles for such a scenario to occur, but it seems counter-intuitive for a sequence to have finite norm while also being orthogonal to an uncountable number of sequences. Does this scenario make sense? Or is there something about and the Hilbert space which makes it impossible? Edit : The reason I ask this question is that I seem to have come across a scenario in which this does in fact occur. The Hilbert space in question has the unusual inner product And the Hermitian operator is You can check that it is Hermitian with respect to this inner product by noting that is symmetric. This operator can be written in the form , where These operators obey the commutator This means in particular that Which implies that if is an eigenvector of with eigenvalue , then is an eigenvector with eigenvalue , for any constant . Thus providing a continuous spectrum of eigenvalues. To find an eigenvector , we may solve the recursive relation associated with the equation , and find that there are normalizeable solutions for real , with asymptotic behavior Hermiticity of Since this has been questioned a couple of times I will show that is Hermitian with respect to this inner product. As I mentioned it is equivalent to showing that is symmetric. This is symmetric since Reviewing the definition of a Hermitian operator, it presumes it is a bounded operator, which we have found that this operator is not (assuming the rest of my calculations are correct). Perhaps the statement about orthogonality of eigenvectors is not true when the ""Hermitian"" operator is unbounded?","u_n\in\mathbb{R}^{\mathbb{N}} (\cdot,\cdot) M \lambda\in\mathbb{R} M (a^{\lambda},a^{\lambda'})=0 \lambda\neq\lambda' M u_n M (u,v)=\sum_{n=0}^{\infty}\frac{(2n+1)!!}{(2n)!!}u_nv_n. M_{nm}=(4n+3)\delta_{nm}+2n\delta_{n-1m}+(2n+3)\delta_{n+1m}. \frac{(2n+1)!!}{(2n)!!}M_{nm} M=A+A^{\dagger}+3 A_{nm}=2n\delta_{nm}+(2n+3)\delta_{n+1m}. [A,A^{\dagger}]=2M. e^{cA}Me^{-cA}=e^{2c}M v M \lambda e^{-cA}v e^{2c}\lambda c v Mv=\lambda v \lambda<0 v_n\sim(-1)^n\frac{1}{\sqrt{n}}e^{-\sqrt{2n|\lambda|}},\quad n\to\infty M M \frac{(2n+1)!!}{(2n)!!}M_{nm} \frac{(2n+1)!!}{(2n)!!}M_{nm}=\frac{(2n+1)!!}{(2n)!!}(4n+3)\delta_{nm}+\frac{(2n+1)!!}{(2n-2)!!}\delta_{n-1m}+\frac{(2n+3)!!}{(2n)!!}\delta_{n+1m} \frac{(2n+1)!!}{(2n-2)!!}\delta_{n-1m}=\frac{(2m+3)!!}{(2m)!!}\delta_{m+1n}.","['sequences-and-series', 'hilbert-spaces']"
78,Specific value of $\zeta(3/2)$?,Specific value of ?,\zeta(3/2),Is anything known about the value of $$\zeta(3/2)=\sum_{n\geq 1}\frac{1}{n^{3/2}}?$$ It is a classical result that $\displaystyle \zeta(2)= \frac{\pi^2}{6}$ and $\zeta(3)$ has been shown to be irrational by Roger Apéry in 1979. Do we even know if $$\zeta(3/2)=\sum_{n\geq 1}\frac{1}{n^{3/2}}$$ is an irrational number or not? Is it  true that $$\zeta(3/2)=\sum_{n\geq 1}\frac{1}{n^{3/2}}=\frac{a}{b}\sum_{n\geq 1}\frac{(-1)^{k-1}}{n^{3/2}\binom{2n}{n}}?$$ Not sure if Apéry's proof can be adapted here since I haven't read it.,Is anything known about the value of It is a classical result that and has been shown to be irrational by Roger Apéry in 1979. Do we even know if is an irrational number or not? Is it  true that Not sure if Apéry's proof can be adapted here since I haven't read it.,\zeta(3/2)=\sum_{n\geq 1}\frac{1}{n^{3/2}}? \displaystyle \zeta(2)= \frac{\pi^2}{6} \zeta(3) \zeta(3/2)=\sum_{n\geq 1}\frac{1}{n^{3/2}} \zeta(3/2)=\sum_{n\geq 1}\frac{1}{n^{3/2}}=\frac{a}{b}\sum_{n\geq 1}\frac{(-1)^{k-1}}{n^{3/2}\binom{2n}{n}}?,"['sequences-and-series', 'number-theory', 'riemann-zeta', 'zeta-functions']"
79,the limit of $\frac{1}{\sqrt{n}}(1+\frac{2}{1+\sqrt2}+\frac{3}{1+\sqrt2+\sqrt3}+\dots+\frac{n}{1+\sqrt2+\sqrt3+\dots+\sqrt n})$ as $n\to\infty$,the limit of  as,\frac{1}{\sqrt{n}}(1+\frac{2}{1+\sqrt2}+\frac{3}{1+\sqrt2+\sqrt3}+\dots+\frac{n}{1+\sqrt2+\sqrt3+\dots+\sqrt n}) n\to\infty,"I need to find: $$\lim_{n \to +\infty} \frac{1}{\sqrt{n}}(1+\frac{2}{1+\sqrt{2}} + \frac{3}{1+\sqrt{2}+\sqrt{3}} + \ldots + \frac{n}{1+\sqrt{2}+\sqrt{3}+\ldots+\sqrt{n}}), n \in \mathbb{N}$$ Looking at denominators, I see that [(...) represents any element between] : $$ 1 \le (\ldots) \le 1+\sqrt{2}+\sqrt{3}+\ldots+\sqrt{n}$$ Then I take reverses and get: $$ 1 \ge (\ldots) \ge \frac{1}{1+\sqrt{2}+\sqrt{3}+\ldots+\sqrt{n}}$$ Then I put the other sequence on top of the former one (I see that the rightmost element is still the smallest one) $$ 1 \ge (\ldots) \ge \frac{n}{1+\sqrt{2}+\sqrt{3}+\ldots+\sqrt{n}}$$ Then I take the sum of n elements on every end of inequality (to sum up n times the biggest element and n times the smallest element) and get: $$ n \ge (\ldots) \ge \frac{n^2}{1+\sqrt{2}+\sqrt{3}+\ldots+\sqrt{n}}$$ Ultimately I take into consideration $\frac{1}{\sqrt{2}}$ and get: $$ \frac{n}{\sqrt{n}} \ge (\ldots) \ge \frac{n^2}{\sqrt{n}(1+\sqrt{2}+\sqrt{3}+\ldots+\sqrt{n})}$$ Now I can use the squeeze theorem and get: $\lim_{n \to +\infty} \frac{n}{\sqrt{n}} = \infty$ $\lim_{n \to +\infty} \frac{n^2}{\sqrt{n}(1+\sqrt{2}+\sqrt{3}+\ldots+\sqrt{n})} = \lim_{n \to +\infty} \frac{\frac{n^2}{\sqrt{n}}}{(1+\sqrt{2}+\sqrt{3}+\ldots+\sqrt{n})} \implies Stolz = \lim_{n \to +\infty} \frac{\frac{(n+1)^2}{\sqrt{n+1}}-\frac{(n)^2 }{\sqrt{n}}}{\sqrt{n+1}}$ And that is pretty disappointing - I think that the solution is wrong. Does anybody see an error in my way of thinking? Unfortunately, I can not use integrals while doing that exercise.","I need to find: Looking at denominators, I see that [(...) represents any element between] : Then I take reverses and get: Then I put the other sequence on top of the former one (I see that the rightmost element is still the smallest one) Then I take the sum of n elements on every end of inequality (to sum up n times the biggest element and n times the smallest element) and get: Ultimately I take into consideration and get: Now I can use the squeeze theorem and get: And that is pretty disappointing - I think that the solution is wrong. Does anybody see an error in my way of thinking? Unfortunately, I can not use integrals while doing that exercise.","\lim_{n \to +\infty} \frac{1}{\sqrt{n}}(1+\frac{2}{1+\sqrt{2}} + \frac{3}{1+\sqrt{2}+\sqrt{3}} + \ldots + \frac{n}{1+\sqrt{2}+\sqrt{3}+\ldots+\sqrt{n}}), n \in \mathbb{N}  1 \le (\ldots) \le 1+\sqrt{2}+\sqrt{3}+\ldots+\sqrt{n}  1 \ge (\ldots) \ge \frac{1}{1+\sqrt{2}+\sqrt{3}+\ldots+\sqrt{n}}  1 \ge (\ldots) \ge \frac{n}{1+\sqrt{2}+\sqrt{3}+\ldots+\sqrt{n}}  n \ge (\ldots) \ge \frac{n^2}{1+\sqrt{2}+\sqrt{3}+\ldots+\sqrt{n}} \frac{1}{\sqrt{2}}  \frac{n}{\sqrt{n}} \ge (\ldots) \ge \frac{n^2}{\sqrt{n}(1+\sqrt{2}+\sqrt{3}+\ldots+\sqrt{n})} \lim_{n \to +\infty} \frac{n}{\sqrt{n}} = \infty \lim_{n \to +\infty} \frac{n^2}{\sqrt{n}(1+\sqrt{2}+\sqrt{3}+\ldots+\sqrt{n})} = \lim_{n \to +\infty} \frac{\frac{n^2}{\sqrt{n}}}{(1+\sqrt{2}+\sqrt{3}+\ldots+\sqrt{n})} \implies Stolz = \lim_{n \to +\infty} \frac{\frac{(n+1)^2}{\sqrt{n+1}}-\frac{(n)^2 }{\sqrt{n}}}{\sqrt{n+1}}","['real-analysis', 'sequences-and-series', 'analysis']"
80,Finite Sum of Infinite Sums is Infinite Sum of Finite Sums?,Finite Sum of Infinite Sums is Infinite Sum of Finite Sums?,,"If I have a finite sequence of $N$ functions $f_n\colon\mathbb{N}\to\mathbb{C}$ and a sequence of complex numbers $z_k$ , must it be true that $$\sum_{n=1}^{N} \sum_{k=1}^\infty f_n(z_k) = \sum_{k=1}^\infty \sum_{n=1}^N f_n(z_k)?$$ It seems that a similar question is addressed at Summation Symbol: Changing the Order , but this question addresses only the case where both sums are finite or both are infinite and doesn't seem to address what happens when we're considering the finite sequence of functions. Motivation for this question It seems like an equality of this form is used to prove Lemma 5.4 in the proof of Dirichlet's Theorem on Arithmetic Progressions in http://people.csail.mit.edu/kuat/courses/dirichlet.pdf , but the use of the identity isn't explicit so I'm not sure if I'm understading this right. I think I could make sense of the lemma's proof if the above formula always holds, but I don't know if that is a valid assumption or not. Any assistance is greatly appreciated!","If I have a finite sequence of functions and a sequence of complex numbers , must it be true that It seems that a similar question is addressed at Summation Symbol: Changing the Order , but this question addresses only the case where both sums are finite or both are infinite and doesn't seem to address what happens when we're considering the finite sequence of functions. Motivation for this question It seems like an equality of this form is used to prove Lemma 5.4 in the proof of Dirichlet's Theorem on Arithmetic Progressions in http://people.csail.mit.edu/kuat/courses/dirichlet.pdf , but the use of the identity isn't explicit so I'm not sure if I'm understading this right. I think I could make sense of the lemma's proof if the above formula always holds, but I don't know if that is a valid assumption or not. Any assistance is greatly appreciated!",N f_n\colon\mathbb{N}\to\mathbb{C} z_k \sum_{n=1}^{N} \sum_{k=1}^\infty f_n(z_k) = \sum_{k=1}^\infty \sum_{n=1}^N f_n(z_k)?,"['sequences-and-series', 'summation', 'proof-explanation', 'sequence-of-function']"
81,Ultraproduct construction: are finite hyperreals just a thinly disguised version of Cauchy sequences?,Ultraproduct construction: are finite hyperreals just a thinly disguised version of Cauchy sequences?,,"Periodically I've tried to wrap my head around nonstandard calculus and hyperreals, but I always thought I needed a lot more of a background in formal logic and/or set theory to understand what's going on with them. Last night I had a sudden flash of insight about how they work, based on the ultrapower construction, but it was so anticlimactic that I wonder if I'm missing something. I want to outline my understanding to see if I actually have the basic idea correct. The construction I'm following is per Wikipedia , and I'm heavily paraphrasing: One way to construct the hyperreals is as equivalence classes of real-valued sequences $\mathbf{x} =  \{ x_i \}_{i \in \Bbb{N}} \in \Bbb{R}^\Bbb{N}.$ The construction is not dissimilar to using Cauchy sequences of rationals to define the reals, except that our equivalence relation doesn't necessarily treat Cauchy sequences that converge to the same number as being ""equal""; rather, they are considered to be ""infinitesimally different"". Any operation or function that we can define on the real numbers - addition, multiplication, comparison, absolute value, floor function - is extended to these sequences componentwise. This gives us a ring with a lot of the same nice structure and operations as we had on $\Bbb{R}$ originally; we can identify the elements $r$ of $\Bbb{R}$ with the constant sequences $(r, r, r, r, ...)$ ; and we can put a partial order on these sequences via componentwise comparison $\leq$ : $\mathbf{a} \leq \mathbf{b}$ iff $a_i \leq b_i$ for all $i \in \Bbb{N}$ . This partial order also lets us talk about sequences like $\mathbf{ε} = (1, 0.5, 0.25, 0.125, ..., 2^{-i}, ...)$ , which are ""greater than"" the sequence $\mathbf{0} = (0, 0, 0, 0, ...)$ but ""less than"" any sequence $\mathbf{r} = (r, r, r, r, ...)$ for $r > 0$ , as being infinitesimal in some sense, since $\mathbf{0} < \mathbf{ε} < \mathbf{r}$ for any positive $r$ . However, most sequences in $\Bbb{R}^\Bbb{N}$ are not comparable in this partial order, and the ring of such sequences is also rife with zero divisors, both of which are serious deficiencies if we hope to do any calculus. If possible, we would also like two sequences $\mathbf{a}, \mathbf{b} \in \Bbb{R}^\Bbb{N}$ to be considered ""equivalent"" (i.e. different names for the same sequence) if $a_i = b_i$ for all but finitely many $i$ . We use an ultrafilter to accomplish this, and also to extend the partial order $\leq$ on sequences to a total order on equivalence classes of sequences (where the equivalence classes are given by "" $\mathbf{a} \sim \mathbf{b}$ "" iff "" $\mathbf{a} \leq \mathbf{b}$ and $\mathbf{b} \leq \mathbf{a}$ ""). The set of all equivalence classes, $\Bbb{R}^\Bbb{N} / \sim$ , is the hyperreal numbers $^*\Bbb{R}$ . Every function $f: \Bbb{R} \to \Bbb{R}$ has a nonstandard counterpart $^*f: ^*\Bbb{R} \to ^*\Bbb{R}$ given by $$^*f([x_1, x_2, x_3, ...]) := [f(x_1), f(x_2), f(x_3), ...]$$ where $[x_1, x_2, x_3, ...]$ means the equivalence class of the sequence $(x_1, x_2, x_3, ...) \in \Bbb{R}^\Bbb{N}$ . Under this interpretation, every infinitesimal hyperreal is the equivalence class of a Cauchy sequence with limit zero; every finite hyperreal is the equivalence class of a Cauchy sequence; and the ""infinite hyperreals"" are equivalence classes of unbounded sequences that either approach $+\infty$ or $-\infty$ (which gives an interesting way to rigorously interpret Big O notation ). The standard part of a finite hyperreal is just the limit of a Cauchy sequence in its equivalence class . Now that I understand how this works, it seems pretty clever to treat ""essentially different"" Cauchy sequences as different numbers ""infinitesimally close"" to a given one, since these sequences are the foundation of the limiting processes in calculus. But it also seems surprising to me that such heavy machinery was applied to proving that nonstandard calculus is logically equivalent to regular calculus, and such pedagogical emphasis (in the sources I've perused, like Robinson's original Nonstandard Analysis ) is placed on the transfer principle. Because now that I have this understanding, nonstandard analysis almost seems like a trivial rewording of regular calculus; and I have such confidence that it works just like regular calculus, because the rewording is so mechanical once you understand that ""standard part of a finite hyperreal"" means ""limit of a Cauchy sequence in its equivalence class"": Continuity Standard: $f: \Bbb{R} \to \Bbb{R}$ is continuous iff $\{ f(x_i) \}_{i \in \Bbb{N}}$ is Cauchy whenever $\{ (x_i) \}_{i \in \Bbb{N}}$ is Cauchy (using the standard definition of a Cauchy sequence.) Nonstandard: $^*f: ^*\Bbb{R} \to ^*\Bbb{R}$ is continuous iff $\operatorname{st}(^*f(\mathbf{x})) = f(\operatorname{st}(\mathbf{x}))$ . Differentiability Standard: $f: \Bbb{R} \to \Bbb{R}$ is differentiable iff $\{ \frac{f(x + h_i) - f(x)}{h_i} \}_{i \in \Bbb{N}}$ is a Cauchy sequence converging to a specific number $f'(x)$ independent of the sequence $\{ h_i \}_{i \in \Bbb{N}}$ , whenever $\{ h_i \}$ is Cauchy and converges to $0$ . Nonstandard: $^*f: ^*\Bbb{R} \to ^*\Bbb{R}$ is differentiable iff for any infinitesimal $\mathbf{h}$ , $\operatorname{st}\left(\frac{^*f(\mathbf{x}+\mathbf{h}) - ^*f(\mathbf{x})}{\mathbf{h}}\right) = f'(\operatorname{st}(\mathbf{x}))$ independent of the value of $\mathbf{h}$ . So I guess my questions are: Am I understanding this right and, on some level, the ""infinitesimals"" are just a thinly disguised version of Cauchy sequences with limit zero? That seems significantly more mundane than the name's suggestion of ""infinitely small numbers"" would imply. What is the gain in clarity, elegance, speed, etc. one gets by working with ""finite hyperreals"" rather than the representative Cauchy sequences, per se? That is, what are some specific instances when one gains meaningful new insight into a result from standard analysis (as opposed to a spiffy new phrasing of the result) by working in the nonstandard/hyperreal setting?","Periodically I've tried to wrap my head around nonstandard calculus and hyperreals, but I always thought I needed a lot more of a background in formal logic and/or set theory to understand what's going on with them. Last night I had a sudden flash of insight about how they work, based on the ultrapower construction, but it was so anticlimactic that I wonder if I'm missing something. I want to outline my understanding to see if I actually have the basic idea correct. The construction I'm following is per Wikipedia , and I'm heavily paraphrasing: One way to construct the hyperreals is as equivalence classes of real-valued sequences The construction is not dissimilar to using Cauchy sequences of rationals to define the reals, except that our equivalence relation doesn't necessarily treat Cauchy sequences that converge to the same number as being ""equal""; rather, they are considered to be ""infinitesimally different"". Any operation or function that we can define on the real numbers - addition, multiplication, comparison, absolute value, floor function - is extended to these sequences componentwise. This gives us a ring with a lot of the same nice structure and operations as we had on originally; we can identify the elements of with the constant sequences ; and we can put a partial order on these sequences via componentwise comparison : iff for all . This partial order also lets us talk about sequences like , which are ""greater than"" the sequence but ""less than"" any sequence for , as being infinitesimal in some sense, since for any positive . However, most sequences in are not comparable in this partial order, and the ring of such sequences is also rife with zero divisors, both of which are serious deficiencies if we hope to do any calculus. If possible, we would also like two sequences to be considered ""equivalent"" (i.e. different names for the same sequence) if for all but finitely many . We use an ultrafilter to accomplish this, and also to extend the partial order on sequences to a total order on equivalence classes of sequences (where the equivalence classes are given by "" "" iff "" and ""). The set of all equivalence classes, , is the hyperreal numbers . Every function has a nonstandard counterpart given by where means the equivalence class of the sequence . Under this interpretation, every infinitesimal hyperreal is the equivalence class of a Cauchy sequence with limit zero; every finite hyperreal is the equivalence class of a Cauchy sequence; and the ""infinite hyperreals"" are equivalence classes of unbounded sequences that either approach or (which gives an interesting way to rigorously interpret Big O notation ). The standard part of a finite hyperreal is just the limit of a Cauchy sequence in its equivalence class . Now that I understand how this works, it seems pretty clever to treat ""essentially different"" Cauchy sequences as different numbers ""infinitesimally close"" to a given one, since these sequences are the foundation of the limiting processes in calculus. But it also seems surprising to me that such heavy machinery was applied to proving that nonstandard calculus is logically equivalent to regular calculus, and such pedagogical emphasis (in the sources I've perused, like Robinson's original Nonstandard Analysis ) is placed on the transfer principle. Because now that I have this understanding, nonstandard analysis almost seems like a trivial rewording of regular calculus; and I have such confidence that it works just like regular calculus, because the rewording is so mechanical once you understand that ""standard part of a finite hyperreal"" means ""limit of a Cauchy sequence in its equivalence class"": Continuity Standard: is continuous iff is Cauchy whenever is Cauchy (using the standard definition of a Cauchy sequence.) Nonstandard: is continuous iff . Differentiability Standard: is differentiable iff is a Cauchy sequence converging to a specific number independent of the sequence , whenever is Cauchy and converges to . Nonstandard: is differentiable iff for any infinitesimal , independent of the value of . So I guess my questions are: Am I understanding this right and, on some level, the ""infinitesimals"" are just a thinly disguised version of Cauchy sequences with limit zero? That seems significantly more mundane than the name's suggestion of ""infinitely small numbers"" would imply. What is the gain in clarity, elegance, speed, etc. one gets by working with ""finite hyperreals"" rather than the representative Cauchy sequences, per se? That is, what are some specific instances when one gains meaningful new insight into a result from standard analysis (as opposed to a spiffy new phrasing of the result) by working in the nonstandard/hyperreal setting?","\mathbf{x} =  \{ x_i \}_{i \in \Bbb{N}} \in \Bbb{R}^\Bbb{N}. \Bbb{R} r \Bbb{R} (r, r, r, r, ...) \leq \mathbf{a} \leq \mathbf{b} a_i \leq b_i i \in \Bbb{N} \mathbf{ε} = (1, 0.5, 0.25, 0.125, ..., 2^{-i}, ...) \mathbf{0} = (0, 0, 0, 0, ...) \mathbf{r} = (r, r, r, r, ...) r > 0 \mathbf{0} < \mathbf{ε} < \mathbf{r} r \Bbb{R}^\Bbb{N} \mathbf{a}, \mathbf{b} \in \Bbb{R}^\Bbb{N} a_i = b_i i \leq \mathbf{a} \sim \mathbf{b} \mathbf{a} \leq \mathbf{b} \mathbf{b} \leq \mathbf{a} \Bbb{R}^\Bbb{N} / \sim ^*\Bbb{R} f: \Bbb{R} \to \Bbb{R} ^*f: ^*\Bbb{R} \to ^*\Bbb{R} ^*f([x_1, x_2, x_3, ...]) := [f(x_1), f(x_2), f(x_3), ...] [x_1, x_2, x_3, ...] (x_1, x_2, x_3, ...) \in \Bbb{R}^\Bbb{N} +\infty -\infty f: \Bbb{R} \to \Bbb{R} \{ f(x_i) \}_{i \in \Bbb{N}} \{ (x_i) \}_{i \in \Bbb{N}} ^*f: ^*\Bbb{R} \to ^*\Bbb{R} \operatorname{st}(^*f(\mathbf{x})) = f(\operatorname{st}(\mathbf{x})) f: \Bbb{R} \to \Bbb{R} \{ \frac{f(x + h_i) - f(x)}{h_i} \}_{i \in \Bbb{N}} f'(x) \{ h_i \}_{i \in \Bbb{N}} \{ h_i \} 0 ^*f: ^*\Bbb{R} \to ^*\Bbb{R} \mathbf{h} \operatorname{st}\left(\frac{^*f(\mathbf{x}+\mathbf{h}) - ^*f(\mathbf{x})}{\mathbf{h}}\right) = f'(\operatorname{st}(\mathbf{x})) \mathbf{h}","['sequences-and-series', 'cauchy-sequences', 'filters', 'nonstandard-analysis', 'infinitesimals']"
82,recursive sequence proofs,recursive sequence proofs,,"I'm kinda new to recursive sequences and I'm struggling with an excercise. I apologize in advance for the long question and my lack of knowledge on how to approach such problems. Let $x_n$ be defined such that $x_1 = 1$ , $x_{n+1} = \frac{x_n^2+1}5$ And there there are 4 things I have to prove/show, (1) Show that $x_n$ $\leq$ $1$ for all $n$ . I'm not sure if I can prove this directly or by induction? What would be best for this? I don't know how to approach this when it's defined recursively. (2) Show that $\lvert x_{n+1} - x_n \rvert$ $\leq (\frac{2}{5})^{n-1}$ I'm not sure but could I use $\lvert\frac{x_{n+1}^2+1}{5}$ $-$ $\frac{x_n^2+1}{5}\rvert$$\leq (\frac{2}{5})^{n-1}$ and then try to solve this. How do i deal with the $x_n$ ? (3) Show that $x_n$ is a Cauchy-sequence. I know that a Cauchy sequence is defined as : For every positive real number $\varepsilon$ , there is a positive integer $N$ such that for all natural numbers $m, n \gt N$ : $\lvert x_m - x_n \rvert \lt \varepsilon$ . Can I apply this definition directly in this sequence and the go on from there? (4) Calculate the limit of $x_n$ . This should be straightforward if it weren't a recursively defined sequence. If I however, calculate the first few elements of the sequence I get: $x_1 = 1$ , $x_2 = \frac{2}{5}$ , $x_3 = \frac{29}{125}$ , $x_4 = \frac{841}{15625}$ $\ldots$ This approaches $0$ (I'm guessing) since the second term is smaller than $1$ . And since a square of a number less than $1$ is always smaller than the original number, $\lim \limits_{n \to \infty}$ $= 0$ . How can I prove this correctly without just trying different numbers? Thank you in advance!","I'm kinda new to recursive sequences and I'm struggling with an excercise. I apologize in advance for the long question and my lack of knowledge on how to approach such problems. Let be defined such that , And there there are 4 things I have to prove/show, (1) Show that for all . I'm not sure if I can prove this directly or by induction? What would be best for this? I don't know how to approach this when it's defined recursively. (2) Show that I'm not sure but could I use and then try to solve this. How do i deal with the ? (3) Show that is a Cauchy-sequence. I know that a Cauchy sequence is defined as : For every positive real number , there is a positive integer such that for all natural numbers : . Can I apply this definition directly in this sequence and the go on from there? (4) Calculate the limit of . This should be straightforward if it weren't a recursively defined sequence. If I however, calculate the first few elements of the sequence I get: , , , This approaches (I'm guessing) since the second term is smaller than . And since a square of a number less than is always smaller than the original number, . How can I prove this correctly without just trying different numbers? Thank you in advance!","x_n x_1 = 1 x_{n+1} = \frac{x_n^2+1}5 x_n \leq 1 n \lvert x_{n+1} - x_n \rvert \leq (\frac{2}{5})^{n-1} \lvert\frac{x_{n+1}^2+1}{5} - \frac{x_n^2+1}{5}\rvert\leq (\frac{2}{5})^{n-1} x_n x_n \varepsilon N m, n \gt N \lvert x_m - x_n \rvert \lt \varepsilon x_n x_1 = 1 x_2 = \frac{2}{5} x_3 = \frac{29}{125} x_4 = \frac{841}{15625} \ldots 0 1 1 \lim \limits_{n \to \infty} = 0",['sequences-and-series']
83,Bound of sum of cos(kx),Bound of sum of cos(kx),,"How can I show that for each $x\in (0,2\pi)$ , there is a number $C(x)>0$ such that $|\sum^n_{k=1}\cos(kx)|\leq C(x)$ , independent of $n$ . I know that \begin{align} 2\sin(\frac{x}{2})\sum^n_{k=1}\cos(kx)=\sum^n_{k=1}\sin((k+\frac{1}{2})x)-\sin((k-\frac{1}{2})x) \end{align} Any help is much appreciated!","How can I show that for each , there is a number such that , independent of . I know that Any help is much appreciated!","x\in (0,2\pi) C(x)>0 |\sum^n_{k=1}\cos(kx)|\leq C(x) n \begin{align}
2\sin(\frac{x}{2})\sum^n_{k=1}\cos(kx)=\sum^n_{k=1}\sin((k+\frac{1}{2})x)-\sin((k-\frac{1}{2})x)
\end{align}",['real-analysis']
84,Show that the sum of a function series is bounded,Show that the sum of a function series is bounded,,"For every $k\in\mathbb{N}$ , with $k\geq 1$ , let $f_k=f_k(x,t)$ be the real-valued function defined over the set $(x,t) \in [-\pi,\pi]\times[0,+\infty)$ by $$f_k(x,t)=(-1)^{k+1}\frac{2}{k}e^{-k^{2} t}\sin(kx).$$ We then consider the corresponding function series $$\sum_{k=1}^{+\infty}f_k(x,t)=\sum_{k=1}^{+\infty}(-1)^{k+1}\frac{2}{k}e^{-k^{2} t}\sin(kx). \tag{1}$$ It is simple to show that $(1)$ converges pointwise on the whole $[-\pi,\pi]\times[0,+\infty)$ , and uniformly on every $[-\pi,\pi]\times[t_0,+\infty)$ , with $t_0>0$ . Let $u=u(x,t)$ be its sum, i.e $$u(x,t)=\sum_{k=1}^{+\infty}f_k(x,t)=\sum_{k=1}^{+\infty}(-1)^{k+1}\frac{2}{k}e^{-k^{2} t}\sin(kx).$$ The sum $u$ it is a superposition of sinusoids of increasing frequency $\frac{k}{2\pi}$ and of strongly damped amplitude because of the negative exponential, at least when $t > 0$ . For this reason, it is simple to show that $u$ is smooth on the set $[-\pi,\pi]\times(0,+\infty)$ , ie $u\in C^{\infty}([-\pi,\pi]\times(0,+\infty))$ . Notice also that: $u=u(x,t)$ is the solution of the one-dimensional Heat Equation problem with periodic boundary conditions $$\begin{cases} u_t-u_{xx} = 0 \qquad &x \in (-\pi,\pi),t>0 \\ u(x,0) = x \qquad &x \in (-\pi,\pi) \\  u(-\pi,t) = u(\pi,t) \qquad &t \geq 0 \end{cases}. \tag{2}$$ For every $x_0\in (-\pi,\pi)$ one has $$\lim_{(x,t)\to(x_0,0)}u(x,t)=x_0,$$ and then $u$ is also continuous at every point of the open segment $(-\pi,\pi)\times\{0\}$ . The limits $$\lim_{(x,t)\to(\pm \pi,0)}u(x,t)\qquad \nexists.$$ I'm not able to prove that $u$ is bounded on the whole $[-\pi,\pi]\times [0,+\infty)$ . By uniform convergence (as suggested me in comments), we just need to prove that partial sums of $(1)$ are uniformly bounded on $[-\pi,\pi]\times [0,+\infty)$ , but I really don't know how to obtain this uniform bound. Any hint would be really appreciated.","For every , with , let be the real-valued function defined over the set by We then consider the corresponding function series It is simple to show that converges pointwise on the whole , and uniformly on every , with . Let be its sum, i.e The sum it is a superposition of sinusoids of increasing frequency and of strongly damped amplitude because of the negative exponential, at least when . For this reason, it is simple to show that is smooth on the set , ie . Notice also that: is the solution of the one-dimensional Heat Equation problem with periodic boundary conditions For every one has and then is also continuous at every point of the open segment . The limits I'm not able to prove that is bounded on the whole . By uniform convergence (as suggested me in comments), we just need to prove that partial sums of are uniformly bounded on , but I really don't know how to obtain this uniform bound. Any hint would be really appreciated.","k\in\mathbb{N} k\geq 1 f_k=f_k(x,t) (x,t) \in [-\pi,\pi]\times[0,+\infty) f_k(x,t)=(-1)^{k+1}\frac{2}{k}e^{-k^{2} t}\sin(kx). \sum_{k=1}^{+\infty}f_k(x,t)=\sum_{k=1}^{+\infty}(-1)^{k+1}\frac{2}{k}e^{-k^{2} t}\sin(kx). \tag{1} (1) [-\pi,\pi]\times[0,+\infty) [-\pi,\pi]\times[t_0,+\infty) t_0>0 u=u(x,t) u(x,t)=\sum_{k=1}^{+\infty}f_k(x,t)=\sum_{k=1}^{+\infty}(-1)^{k+1}\frac{2}{k}e^{-k^{2} t}\sin(kx). u \frac{k}{2\pi} t > 0 u [-\pi,\pi]\times(0,+\infty) u\in C^{\infty}([-\pi,\pi]\times(0,+\infty)) u=u(x,t) \begin{cases} u_t-u_{xx} = 0 \qquad &x \in (-\pi,\pi),t>0 \\
u(x,0) = x \qquad &x \in (-\pi,\pi) \\ 
u(-\pi,t) = u(\pi,t) \qquad &t \geq 0 \end{cases}. \tag{2} x_0\in (-\pi,\pi) \lim_{(x,t)\to(x_0,0)}u(x,t)=x_0, u (-\pi,\pi)\times\{0\} \lim_{(x,t)\to(\pm \pi,0)}u(x,t)\qquad \nexists. u [-\pi,\pi]\times [0,+\infty) (1) [-\pi,\pi]\times [0,+\infty)","['real-analysis', 'sequences-and-series', 'partial-differential-equations', 'fourier-series', 'heat-equation']"
85,Show that this sequence converges to $0$ [duplicate],Show that this sequence converges to  [duplicate],0,"This question already has answers here : Find the limit of $\frac{n^{x}}{(1 + x)^{n}}$ (2 answers) Closed 3 years ago . The Question For any fixed $k'\in\mathbb{N}$ , for any $a\in\mathbb{R}^+$ and for any $n\in\mathbb{N}$ , define the function $f:\mathbb{N}\to\mathbb{R}$ given by \begin{equation*} 	x_n=f(n)=\frac{n^{k'}}{(1+a)^n}.  	\end{equation*} I want to show that $(x_n)$ converges to $0$ . For clarification, I don't include $0$ in $\mathbb{N}$ . Attempts at Solution For any $\varepsilon>0$ , I need to find a $N\in\mathbb{N}$ such that for any integer $n \geq \mathbb{N}$ , the following holds: \begin{equation*} 	\left | \,\frac{n^{k'}}{(1+a)^n}-0 \, \right | <\varepsilon.  	\end{equation*} Since $x_m>0$ for any $m\in\mathbb{N}$ , I can drop the absolute value signs and we get \begin{equation*} 	\frac{n^{k'}}{(1+a)^n}<\varepsilon.  	\end{equation*} So, I considered $x^{k'}=\varepsilon(1+a)^x$ for any $x\in\mathbb{R}^+$ . That equation does not have a closed form solution I think, so I will denote the bigger root of that as $x^*$ . Now $N=\lceil x^* \rceil$ should be a candidate for the convergence definition. This is where I get stuck: how do I put that $N$ back to the convergence definition and show that $N$ really is a good candidate? I wonder if there are any elegant proofs for this; mine is too ugly. Also, I have a simple inequality that should play a role in this but I do not see how it fits. (My ""proof"" did not use the inequality) For any fixed $k'\in\mathbb{N}$ and for any $n\geq k'$ , consider $(1+a)^n$ . \begin{align*} 	(1+a)^n&=\sum_{k=0}^{n}\binom{n}{k}a^k1^{n-k}\\ 	&=\sum_{k=0}^{k'-1}\binom{n}{k}a^k+\binom{n}{k'}a^{k'}+\sum_{k=k'+1}^{n}\binom{n}{k}a^k\\ 	&>\sum_{k=0}^{k'-1}\binom{n}{k}0^k +\binom{n}{k'}a^{k'}+ \sum_{k=k'+1}^{n}\binom{n}{k}0^k\\ 	&=\binom{n}{k'}a^{k'}.  	\end{align*} Thanks in advance!!","This question already has answers here : Find the limit of $\frac{n^{x}}{(1 + x)^{n}}$ (2 answers) Closed 3 years ago . The Question For any fixed , for any and for any , define the function given by I want to show that converges to . For clarification, I don't include in . Attempts at Solution For any , I need to find a such that for any integer , the following holds: Since for any , I can drop the absolute value signs and we get So, I considered for any . That equation does not have a closed form solution I think, so I will denote the bigger root of that as . Now should be a candidate for the convergence definition. This is where I get stuck: how do I put that back to the convergence definition and show that really is a good candidate? I wonder if there are any elegant proofs for this; mine is too ugly. Also, I have a simple inequality that should play a role in this but I do not see how it fits. (My ""proof"" did not use the inequality) For any fixed and for any , consider . Thanks in advance!!","k'\in\mathbb{N} a\in\mathbb{R}^+ n\in\mathbb{N} f:\mathbb{N}\to\mathbb{R} \begin{equation*}
	x_n=f(n)=\frac{n^{k'}}{(1+a)^n}. 
	\end{equation*} (x_n) 0 0 \mathbb{N} \varepsilon>0 N\in\mathbb{N} n
\geq \mathbb{N} \begin{equation*}
	\left | \,\frac{n^{k'}}{(1+a)^n}-0 \, \right | <\varepsilon. 
	\end{equation*} x_m>0 m\in\mathbb{N} \begin{equation*}
	\frac{n^{k'}}{(1+a)^n}<\varepsilon. 
	\end{equation*} x^{k'}=\varepsilon(1+a)^x x\in\mathbb{R}^+ x^* N=\lceil x^* \rceil N N k'\in\mathbb{N} n\geq k' (1+a)^n \begin{align*}
	(1+a)^n&=\sum_{k=0}^{n}\binom{n}{k}a^k1^{n-k}\\
	&=\sum_{k=0}^{k'-1}\binom{n}{k}a^k+\binom{n}{k'}a^{k'}+\sum_{k=k'+1}^{n}\binom{n}{k}a^k\\
	&>\sum_{k=0}^{k'-1}\binom{n}{k}0^k +\binom{n}{k'}a^{k'}+ \sum_{k=k'+1}^{n}\binom{n}{k}0^k\\
	&=\binom{n}{k'}a^{k'}. 
	\end{align*}","['real-analysis', 'sequences-and-series', 'convergence-divergence']"
86,Solving cyclic infinite nested square roots of 2 as cosine functions,Solving cyclic infinite nested square roots of 2 as cosine functions,,"Common infinite nested square roots of 2 are well known from school grade. We used to solve $$\sqrt{2+\sqrt{2+\sqrt{2+...}}}$$ as $x=\sqrt{2+x}$ which becomes $x^2 = x+2$ ==> $x^2-x-2=0$ The possible result is positive value which is $2$ . We also know similar negative infinite counterpart $$\sqrt{2-\sqrt{2-\sqrt{2-...}}}$$ as $x=\sqrt{2-x}$ which becomes $x^2 = 2-x$ ==> $x^2+x-2=0$ The possible result is positive value which is $1$ . Even we can solve alternate signs of nested radicals like $$ \sqrt{2-\sqrt{2+\sqrt{2-\sqrt{2+...}}}}$$ as $\sqrt5-1 \over 2$ and $$ \sqrt{2+\sqrt{2-\sqrt{2+\sqrt{2-...}}}}$$ as $\sqrt5+1 \over 2$ Now the question is, is it possible to solve infinite nested square roots of of 'm' positive signs and 'n' negative signs in the infinite nested square roots of 2 in cyclic manner Example 1 $$\sqrt{2-\sqrt{2-\sqrt{2+\sqrt{2-\sqrt{2-\sqrt{2+...}}}}}}$$ as [- - +] as infinite cycles Example 2 $$\sqrt{2-\sqrt{2-\sqrt{2+\sqrt{2+\sqrt{2-\sqrt{2-\sqrt{2+\sqrt{2+...}}}}}}}}$$ as [- - + +] as infinite cycles. To generalise the question how to solve $$\sqrt{2-\sqrt{2-...\text{m times} \sqrt{2+\sqrt{2+...\text{n times}}}}}$$ where $m, n \in {N}$ Is there anyway to solve?","Common infinite nested square roots of 2 are well known from school grade. We used to solve as which becomes ==> The possible result is positive value which is . We also know similar negative infinite counterpart as which becomes ==> The possible result is positive value which is . Even we can solve alternate signs of nested radicals like as and as Now the question is, is it possible to solve infinite nested square roots of of 'm' positive signs and 'n' negative signs in the infinite nested square roots of 2 in cyclic manner Example 1 as [- - +] as infinite cycles Example 2 as [- - + +] as infinite cycles. To generalise the question how to solve where Is there anyway to solve?","\sqrt{2+\sqrt{2+\sqrt{2+...}}} x=\sqrt{2+x} x^2 = x+2 x^2-x-2=0 2 \sqrt{2-\sqrt{2-\sqrt{2-...}}} x=\sqrt{2-x} x^2 = 2-x x^2+x-2=0 1  \sqrt{2-\sqrt{2+\sqrt{2-\sqrt{2+...}}}} \sqrt5-1 \over 2  \sqrt{2+\sqrt{2-\sqrt{2+\sqrt{2-...}}}} \sqrt5+1 \over 2 \sqrt{2-\sqrt{2-\sqrt{2+\sqrt{2-\sqrt{2-\sqrt{2+...}}}}}} \sqrt{2-\sqrt{2-\sqrt{2+\sqrt{2+\sqrt{2-\sqrt{2-\sqrt{2+\sqrt{2+...}}}}}}}} \sqrt{2-\sqrt{2-...\text{m times} \sqrt{2+\sqrt{2+...\text{n times}}}}} m, n \in {N}","['sequences-and-series', 'trigonometry', 'nested-radicals']"
87,Proof of $\lim_{n \to \infty}(1+\frac{1}{n})^n=e$,Proof of,\lim_{n \to \infty}(1+\frac{1}{n})^n=e,"I have this messy proof of $\lim_{n \to \infty}(1+\frac{1}{n})^n=e$ in my notebook. I can't find it anywhere else, but I need it since the professor accepts only this version at the exam. At the time I am only stuck with the first part, so I will write the proof only to that point. Also, there is a few steps with missing reasoning between them. Proof. We are given two sequences: $$x_n=1+\frac{1}{1!}+\frac{1}{2!}+\frac{1}{3!}+\dots+\frac{1}{n!}$$ $$y_n=\left(1+\frac{1}{n}\right)^n$$ If $x_n$ converges, then $\lim_{n \to \infty}x_n=e$ . (This is given.) Let's prove that $x_n$ converges. To prove that, the Monotone Convergence Theorem will be used. Since $x_{n+1}>x_{n}$ the sequence is increasing. (I skipped the unnecessary reasoning for this.) Now let's prove that it is bounded from above. $$n!=1\cdot 2\cdot 3\cdots n>2^{n-1}\tag{1.1}$$ $$\frac{1}{n!}\leq \frac{1}{2^{n-1}}\tag{1.2}$$ $$\underbrace{2}_{\text{?}}\leq x_n\leq 1+1+\frac{1}{2}+\frac{1}{2^2}+\dots+\frac{1}{2^{n-1}}\tag{1.3}$$ $$1+q+q^2+\dots+q^{n-1}=\underbrace{\overbrace{\frac{1-q^n}{1-q}}^{?}=\frac{q^n-1}{q-1}}_{\text{?}}\tag{1.4}$$ $$q=\frac{1}{2}$$ $$\underbrace{1}_{\text{?}}+\frac{1-\frac{1}{q^n}}{1-\frac{1}{q}}=1+2\left(1-\frac{1}{2^n}\right)<1+2=3\tag{1.5}$$ And so $2\leq x_n\leq3$ , $x_n$ is bounded and increasing, hence it converges. Therefore $\lim_{n \to \infty}x_n=e$ . The proof proceeds with proving that $\lim_{n\to \infty}y_n=Y$ , and then showing $y\geq e$ and $y \leq e$ , and thereby $y=e$ . This part is very long and already looking messy in the notebook. Because of that I will skip it, since it isn't important for the question. My questions: Is there any obvious reason why $2^{n-1}$ is a good (necessary?) choice for the inequality (1.1)? How does (1.2) follow from (1.1)? Why is it $\leq$ and not $ < $ ? I see that $\leq$ is the right choice since for $n=1$ , we have $\frac{1}{1!}=\frac{1}{2^{1-1}}$ , but is there any way to know this without evaluating for choices of $n$ ? Why is that $2$ there in inequality (1.3)? Where did it come from ? Considering inequality (1.4) there is few things; a) How was the overbraced fraction derived from the geometric series? b) The underbraced equality at first didn't make sense to me, but when I evaluated for few $n$ s, I realized it actually holds. Is this a known thing, that the order of subracting isn't important for two fractions to be equal, as long as both the numerator and the denominator of the fraction are both $<0$ or $>0$ ? Also what was the role of the equality in the proof, or was it just a remark ? EDIT: I just realized that we can do that since the fraction is always positive. But it still doesn't seem so obvious to notice. Should it be obvious? Why is that $1$ there in the inequality (1.5) ? Where did it come from ? If you have a source for this proof please send me a link or tell me where I can find it. Thanks","I have this messy proof of in my notebook. I can't find it anywhere else, but I need it since the professor accepts only this version at the exam. At the time I am only stuck with the first part, so I will write the proof only to that point. Also, there is a few steps with missing reasoning between them. Proof. We are given two sequences: If converges, then . (This is given.) Let's prove that converges. To prove that, the Monotone Convergence Theorem will be used. Since the sequence is increasing. (I skipped the unnecessary reasoning for this.) Now let's prove that it is bounded from above. And so , is bounded and increasing, hence it converges. Therefore . The proof proceeds with proving that , and then showing and , and thereby . This part is very long and already looking messy in the notebook. Because of that I will skip it, since it isn't important for the question. My questions: Is there any obvious reason why is a good (necessary?) choice for the inequality (1.1)? How does (1.2) follow from (1.1)? Why is it and not ? I see that is the right choice since for , we have , but is there any way to know this without evaluating for choices of ? Why is that there in inequality (1.3)? Where did it come from ? Considering inequality (1.4) there is few things; a) How was the overbraced fraction derived from the geometric series? b) The underbraced equality at first didn't make sense to me, but when I evaluated for few s, I realized it actually holds. Is this a known thing, that the order of subracting isn't important for two fractions to be equal, as long as both the numerator and the denominator of the fraction are both or ? Also what was the role of the equality in the proof, or was it just a remark ? EDIT: I just realized that we can do that since the fraction is always positive. But it still doesn't seem so obvious to notice. Should it be obvious? Why is that there in the inequality (1.5) ? Where did it come from ? If you have a source for this proof please send me a link or tell me where I can find it. Thanks",\lim_{n \to \infty}(1+\frac{1}{n})^n=e x_n=1+\frac{1}{1!}+\frac{1}{2!}+\frac{1}{3!}+\dots+\frac{1}{n!} y_n=\left(1+\frac{1}{n}\right)^n x_n \lim_{n \to \infty}x_n=e x_n x_{n+1}>x_{n} n!=1\cdot 2\cdot 3\cdots n>2^{n-1}\tag{1.1} \frac{1}{n!}\leq \frac{1}{2^{n-1}}\tag{1.2} \underbrace{2}_{\text{?}}\leq x_n\leq 1+1+\frac{1}{2}+\frac{1}{2^2}+\dots+\frac{1}{2^{n-1}}\tag{1.3} 1+q+q^2+\dots+q^{n-1}=\underbrace{\overbrace{\frac{1-q^n}{1-q}}^{?}=\frac{q^n-1}{q-1}}_{\text{?}}\tag{1.4} q=\frac{1}{2} \underbrace{1}_{\text{?}}+\frac{1-\frac{1}{q^n}}{1-\frac{1}{q}}=1+2\left(1-\frac{1}{2^n}\right)<1+2=3\tag{1.5} 2\leq x_n\leq3 x_n \lim_{n \to \infty}x_n=e \lim_{n\to \infty}y_n=Y y\geq e y \leq e y=e 2^{n-1} \leq  <  \leq n=1 \frac{1}{1!}=\frac{1}{2^{1-1}} n 2 n <0 >0 1,"['real-analysis', 'sequences-and-series', 'limits', 'proof-writing', 'proof-explanation']"
88,A periodic function with no fundamental period and continous at one point is constant.,A periodic function with no fundamental period and continous at one point is constant.,,"Theorm : Let $f:\mathbb{R} \to \mathbb{R}$ be a periodic function and suppose $f$ is continous at some $\zeta \in \mathbb{R}$ and that $f$ has no fundamental period then prove that $f$ is constant . My trial proof using sequences Let $\{p_n\}$ be a decreasing sequence of periods of $f$ converging to $0$ . If $f$ is not constant then $\exists $ a point $a$ such that $f(a) \neq f(\zeta)$ . Let $ a\gt \zeta$ . There exist $ m\in \mathbb{N}$ such that $0\lt p_n \lt a-\zeta, \forall n \gt m$ We choose $x_1, x_2 , ..., x_m$ as the same real number $a$ For $n\gt m$ , we select $x_n \in (\zeta, \zeta+p_n) $ such that $f(x_n)=f(a)$ which is possible by the periodicity of $f$ Clearly $x_n \to \zeta$ as $n\to \infty$ but the corresponding functional sequence $f(x_n)=f(a)\to f(a)\neq f(\zeta) $ as $n\to \infty$ thus contradicting that $f$ is continous at $\zeta$ Similar technique for $a\lt \zeta$ Thus there is no such $a$ and so the result follows. I know there are several questions like this posted here but as far as I have seen none of them use sequences. My proof looks too simple . Is everything correct or am I overlooking something? Thanks for your time.","Theorm : Let be a periodic function and suppose is continous at some and that has no fundamental period then prove that is constant . My trial proof using sequences Let be a decreasing sequence of periods of converging to . If is not constant then a point such that . Let . There exist such that We choose as the same real number For , we select such that which is possible by the periodicity of Clearly as but the corresponding functional sequence as thus contradicting that is continous at Similar technique for Thus there is no such and so the result follows. I know there are several questions like this posted here but as far as I have seen none of them use sequences. My proof looks too simple . Is everything correct or am I overlooking something? Thanks for your time.","f:\mathbb{R} \to \mathbb{R} f \zeta \in \mathbb{R} f f \{p_n\} f 0 f \exists  a f(a) \neq f(\zeta)  a\gt \zeta  m\in \mathbb{N} 0\lt p_n \lt a-\zeta, \forall n \gt m x_1, x_2 , ..., x_m a n\gt m x_n \in (\zeta, \zeta+p_n)  f(x_n)=f(a) f x_n \to \zeta n\to \infty f(x_n)=f(a)\to f(a)\neq f(\zeta)  n\to \infty f \zeta a\lt \zeta a","['real-analysis', 'sequences-and-series', 'continuity', 'solution-verification', 'periodic-functions']"
89,Partial sums over rational functions,Partial sums over rational functions,,"I recently came across the result that $$\sum_{n=2}^\infty \frac{n^4-n^3+n+1}{n^6-1} = \frac{1}{2}$$ I am wondering how one could proof this, generally how one could evaluate a sum over rational functions. If I plug the sum into Wolfram Alpha it gives $$\frac{3k^4-k-2}{6k(k+1)(k^2+k+1)}$$ as the $k$ -th partial sum. Taking the limit as $n \to \infty$ , this would in fact proof the upper equality. Sadly, I could not wrap my head around how to get to Wolfram Alphas partial sum result. If anyone has an idea let me know. Any tips are appreciated.","I recently came across the result that I am wondering how one could proof this, generally how one could evaluate a sum over rational functions. If I plug the sum into Wolfram Alpha it gives as the -th partial sum. Taking the limit as , this would in fact proof the upper equality. Sadly, I could not wrap my head around how to get to Wolfram Alphas partial sum result. If anyone has an idea let me know. Any tips are appreciated.",\sum_{n=2}^\infty \frac{n^4-n^3+n+1}{n^6-1} = \frac{1}{2} \frac{3k^4-k-2}{6k(k+1)(k^2+k+1)} k n \to \infty,"['sequences-and-series', 'summation']"
90,"Solution to recurrence $c_{l+1,t}=c_{l,t+1}-c_{l-1,t+1}$.",Solution to recurrence .,"c_{l+1,t}=c_{l,t+1}-c_{l-1,t+1}","I have the following recurrence: $$c_{l+1,t}=c_{l,t+1}-c_{l-1,t+1}\tag{1}$$ I know the initial conditions: $$c_{k,t}=0 \;\;\forall \;\; k<0$$ $$c_{0,t}=\frac{{2t \choose t}}{t+1}$$ I know the solution to the recurrence is: $$c_{l,t}={2t+l \choose t}\frac{l+1}{t+l+1}$$ How do I get this closed form expression (I can prove it with induction when I know the solution, but how would I have found it)? My attempt: Substitute $l=0$ in equation (1). $$c_{1,t}=c_{0,t+1}$$ Now substitute $l=1$ $$c_{2,t}=c_{0,t+2}-c_{0,t+1}$$ With $l=2$ $$c_{3,t}=c_{0,t+3}-2c_{0,t+2}$$ Going on like this, $$c_{4,t}=c_{0,t+4}-3c_{0,t+3}+c_{0,t+2}$$ $$c_{5,t}=c_{0,t+5}-4c_{0,t+4}+3c_{0,t+3}$$ $$c_{6,t}=c_{0,t+6}-5c_{0,t+5}+3c_{0,t+4}+2c_{0,t+3}$$ $$c_{7,t}=c_{0,t+7}-6c_{0,t+6}+4c_{0,t+5}+3c_{0,t+4}-c_{0,t+3}$$ I can't see any pattern (apart from $c_{l,t}=c_{0,t+l}-(l-1)c_{0,t+l-1}+<stuff>$ ) emerging.","I have the following recurrence: I know the initial conditions: I know the solution to the recurrence is: How do I get this closed form expression (I can prove it with induction when I know the solution, but how would I have found it)? My attempt: Substitute in equation (1). Now substitute With Going on like this, I can't see any pattern (apart from ) emerging.","c_{l+1,t}=c_{l,t+1}-c_{l-1,t+1}\tag{1} c_{k,t}=0 \;\;\forall \;\; k<0 c_{0,t}=\frac{{2t \choose t}}{t+1} c_{l,t}={2t+l \choose t}\frac{l+1}{t+l+1} l=0 c_{1,t}=c_{0,t+1} l=1 c_{2,t}=c_{0,t+2}-c_{0,t+1} l=2 c_{3,t}=c_{0,t+3}-2c_{0,t+2} c_{4,t}=c_{0,t+4}-3c_{0,t+3}+c_{0,t+2} c_{5,t}=c_{0,t+5}-4c_{0,t+4}+3c_{0,t+3} c_{6,t}=c_{0,t+6}-5c_{0,t+5}+3c_{0,t+4}+2c_{0,t+3} c_{7,t}=c_{0,t+7}-6c_{0,t+6}+4c_{0,t+5}+3c_{0,t+4}-c_{0,t+3} c_{l,t}=c_{0,t+l}-(l-1)c_{0,t+l-1}+<stuff>","['sequences-and-series', 'recurrence-relations', 'binomial-coefficients']"
91,"What is the closed form of the sequence $\{-\frac12,\frac19,\frac{13}{100},\frac{71}{588},\frac{71}{648},\frac{1447}{14520},\frac{617}{6760},...\}$?",What is the closed form of the sequence ?,"\{-\frac12,\frac19,\frac{13}{100},\frac{71}{588},\frac{71}{648},\frac{1447}{14520},\frac{617}{6760},...\}","I am trying to find the closed form of the following sequence: $$ \left\lbrace -\frac{1}{2} , \frac{1}{9} , \frac{13}{100} , \frac{71}{588} , \frac{71}{648} , \frac{1447}{14520} , \frac{617}{6760} , \frac{1061}{12600} , ... \right\rbrace \tag{1}$$ These form the coefficients $a_k$ with $k=1,3,5,...$ of a power series expansion of the following form: $$f(x) = \sum_{k=1,3,5,...}^\infty a_k x^k = a_1 x + a_3 x^3 + a_5 x^5 + ..., \tag{2}$$ for which I wish to find a closed form. I could not find anything in Wolfram Alpha nor in OEIS . Here is a plot of $(1)$ : Note that these coefficients were found numerically, and the rational forms given above agree up to at least 15 significant digits. If needed I can probably obtain any desired coefficient, although the precision may decrease. EDIT : Here is some context, as suggested in the comments. This sequence arises when trying to solve the following integral: $$I(x) = \frac{1}{2^9\pi^5} \int_{-\infty}^\infty d\tau \left\lbrace \frac{1}{1+\tau^2} \arctan^2 \frac{\tau}{x} + \frac{x}{x^2 + \tau^2} \arctan^2 \tau \right\rbrace \tag{3}$$ with $x>0$ . I managed to obtain the following form numerically: $$I(x) = \frac{1}{2^{13} \pi^4} + \frac{1}{2^{10}\pi^6} \tanh^{-1}(x) \left\lbrace \log(x) - \tanh^{-1}(x) + 2\log 2 \right\rbrace + \frac{1}{2^9 \pi^6} \sum_{k=1,3,5,...} a_k x^k. \tag{4}$$ So finding a closed form for $(1)$ would give me the exact solution of the integral $I(x)$ . Note that the integral exhibits the curious symmetry $I(x) = I(1/x)$ .","I am trying to find the closed form of the following sequence: These form the coefficients with of a power series expansion of the following form: for which I wish to find a closed form. I could not find anything in Wolfram Alpha nor in OEIS . Here is a plot of : Note that these coefficients were found numerically, and the rational forms given above agree up to at least 15 significant digits. If needed I can probably obtain any desired coefficient, although the precision may decrease. EDIT : Here is some context, as suggested in the comments. This sequence arises when trying to solve the following integral: with . I managed to obtain the following form numerically: So finding a closed form for would give me the exact solution of the integral . Note that the integral exhibits the curious symmetry ."," \left\lbrace -\frac{1}{2} , \frac{1}{9} , \frac{13}{100} , \frac{71}{588} , \frac{71}{648} , \frac{1447}{14520} , \frac{617}{6760} , \frac{1061}{12600} , ... \right\rbrace \tag{1} a_k k=1,3,5,... f(x) = \sum_{k=1,3,5,...}^\infty a_k x^k = a_1 x + a_3 x^3 + a_5 x^5 + ..., \tag{2} (1) I(x) = \frac{1}{2^9\pi^5} \int_{-\infty}^\infty d\tau \left\lbrace \frac{1}{1+\tau^2} \arctan^2 \frac{\tau}{x} + \frac{x}{x^2 + \tau^2} \arctan^2 \tau \right\rbrace \tag{3} x>0 I(x) = \frac{1}{2^{13} \pi^4} + \frac{1}{2^{10}\pi^6} \tanh^{-1}(x) \left\lbrace \log(x) - \tanh^{-1}(x) + 2\log 2 \right\rbrace + \frac{1}{2^9 \pi^6} \sum_{k=1,3,5,...} a_k x^k. \tag{4} (1) I(x) I(x) = I(1/x)","['sequences-and-series', 'closed-form']"
92,Fibonacci and tossing coins,Fibonacci and tossing coins,,"Consider the following scheme starting with a sequence $\sigma_0 = \langle 1,1,\dots,1\rangle$ of length $k$ , successively followed by sequences $\sigma_i$ of the same length but shifted by one to the right, where the first entry $\sigma_{i0}$ equals the sum of all values above, and $\sigma_{ij} = \sigma_{i0}$ . For $k = 5$ one has: 1  1  1  1  1                             1  1  1  1  1                             2  2  2  2  2                             4  4  4  4   4                           8  8  8   8   8                          15 15  15  15  15                         29  29  29  29  29                         56  56  56  56  56                          108 108 108 108 108                              208 208 208 208 208 Calculating the sum for each column one gets e.g. for $k = 5$ : 1  2  4  8 16 30 58 112 216 416 802 1546 2980 5744 ... It turns out that for $k = 3$ and $k = 4$ these sequences, namely 1 2 4 6 10 16 26 42 68 110 178 288 466 754 1220 1974 ... and 1 2 4 8 14 26 48 88 162 298 548 1008 1854 3410 6272 ... seem to be the numbers of ways to toss a coin $n$ times and not get a run of $k$ (see A128588 and A135491 ). Conjecture : This holds in general, i.e. for arbitrary $k$ . My question is two-fold: How to prove this conjecture? What do the schemes above have to do with tossing a coin and counting runs? Guess : When you try to calculate the numbers of ways to toss a coin $n$ times and not get a run of $k$ you may come up with those schemes. But how? Note that the sequence for $k=3$ ( A128588 ) happens to be double the Fibonacci numbers. The schemes arose when I tried to mimic epidemic spread in a SIR-like discrete model (see here ).","Consider the following scheme starting with a sequence of length , successively followed by sequences of the same length but shifted by one to the right, where the first entry equals the sum of all values above, and . For one has: 1  1  1  1  1                             1  1  1  1  1                             2  2  2  2  2                             4  4  4  4   4                           8  8  8   8   8                          15 15  15  15  15                         29  29  29  29  29                         56  56  56  56  56                          108 108 108 108 108                              208 208 208 208 208 Calculating the sum for each column one gets e.g. for : 1  2  4  8 16 30 58 112 216 416 802 1546 2980 5744 ... It turns out that for and these sequences, namely 1 2 4 6 10 16 26 42 68 110 178 288 466 754 1220 1974 ... and 1 2 4 8 14 26 48 88 162 298 548 1008 1854 3410 6272 ... seem to be the numbers of ways to toss a coin times and not get a run of (see A128588 and A135491 ). Conjecture : This holds in general, i.e. for arbitrary . My question is two-fold: How to prove this conjecture? What do the schemes above have to do with tossing a coin and counting runs? Guess : When you try to calculate the numbers of ways to toss a coin times and not get a run of you may come up with those schemes. But how? Note that the sequence for ( A128588 ) happens to be double the Fibonacci numbers. The schemes arose when I tried to mimic epidemic spread in a SIR-like discrete model (see here ).","\sigma_0 = \langle 1,1,\dots,1\rangle k \sigma_i \sigma_{i0} \sigma_{ij} = \sigma_{i0} k = 5 k = 5 k = 3 k = 4 n k k n k k=3","['sequences-and-series', 'combinatorics']"
93,Variant of Parseval equality in Hilbert space,Variant of Parseval equality in Hilbert space,,"We know that if $(x_n)_{n\in\mathbb{N}}$ is a sequence of element in a Hilbert space $(\mathcal{H}, \langle\cdot,\cdot\rangle)$ such that for $n\neq m$ , $x_n\perp x_m$ . Then the series $\sum_{n\in\mathbb{N}} x_n$ converges if and only if the series $\sum_{n\in\mathbb{N}}\Vert x_n\Vert^2$ converges, and in that case, we have $$ \Bigl\Vert \sum_{n\in\mathbb{N}}x_n\Bigr\Vert^2 = \sum_{n\in\mathbb{N}}\Vert x_n\Vert^2 $$ Now, if we take another sequence $(x_n)_{n\in\mathbb{N}}$ in $\mathcal{H}$ such that there exists $N_0\geqslant 1$ such that if $\vert n-m\vert\geqslant N_0$ , then $x_n\perp x_m$ . We also suppose that $\sum_{n\in\mathbb{N}}\Vert x_n\Vert^2$ exists (i.e. is finite). Prove that the series $\sum_{n\in\mathbb{N}}x_n$ is convergent and that there exists a constant $C$ which only depends on $N_0$ , such that $$ \Bigl\Vert \sum_{n\in\mathbb{N}}x_n\Bigr\Vert^2 \leqslant C\sum_{n\in\mathbb{N}}\Vert x_n\Vert^2 $$ My try: Like in the Parseval equality proof, I try to prove that $S_q=\sum_{n\leqslant q}x_n$ is a Cauchy sequence: $$ \begin{align} \Vert S_{q+q'}-S_q\Vert^2 &=\sum_{n=q+1}^{q'}\Vert x_n\Vert^2+\sum_{n=q+1}^{q'}\sum_{j=q+1}^{q'}\langle x_n,x_j\rangle + \overline{\langle x_n,x_j\rangle}\\ &=\sum_{n=q+1}^{q'}\Vert x_n\Vert^2+\sum_{n=q+1}^{q'}\sum_{j\in I_n}\langle x_n,x_j\rangle + \overline{\langle x_n,x_j\rangle}\\ &\leqslant \sum_{n=q+1}^{+\infty}\Vert x_n\Vert^2+2\sum_{n=q+1}^{q'}\sum_{j\in I_n}\vert\langle x_n,x_j\rangle\vert\\ &\leqslant \sum_{n=q+1}^{+\infty}\Vert x_n\Vert^2+2\sum_{n=q+1}^{q'}\Vert x_n\Vert\sum_{j\in I_n}\Vert x_j\Vert \end{align} $$ where $I_n=\{j:\vert n-j\vert\leqslant N_0\}$ . I know that $\vert I_n\vert\leqslant N_0$ , but I can only seem to have $$ \sum_{j\in I_n}\Vert x_j\Vert\leqslant N_0\sup_{j\in I_n}\Vert x_j\Vert $$ I cannot seem to go further than that.  I am able to bound $\sup_{j\in I_n}\Vert x_j\Vert$ by $C_j\Vert x_q\Vert^2$ if $x_q\neq 0$ with $C_j\in\mathbb{R}$ but this does not seem to be sharp enough, as the sequence $(C_j)_{j\in\mathbb{N}}$ is not easily bounded. The same happens if I consider $\Vert S_q\Vert$ when trying to prove the inequality. Note that $N_0=1$ is the same case as in the Parseval equality. Any help would be appreciated, thanks!","We know that if is a sequence of element in a Hilbert space such that for , . Then the series converges if and only if the series converges, and in that case, we have Now, if we take another sequence in such that there exists such that if , then . We also suppose that exists (i.e. is finite). Prove that the series is convergent and that there exists a constant which only depends on , such that My try: Like in the Parseval equality proof, I try to prove that is a Cauchy sequence: where . I know that , but I can only seem to have I cannot seem to go further than that.  I am able to bound by if with but this does not seem to be sharp enough, as the sequence is not easily bounded. The same happens if I consider when trying to prove the inequality. Note that is the same case as in the Parseval equality. Any help would be appreciated, thanks!","(x_n)_{n\in\mathbb{N}} (\mathcal{H}, \langle\cdot,\cdot\rangle) n\neq m x_n\perp x_m \sum_{n\in\mathbb{N}} x_n \sum_{n\in\mathbb{N}}\Vert x_n\Vert^2 
\Bigl\Vert \sum_{n\in\mathbb{N}}x_n\Bigr\Vert^2 = \sum_{n\in\mathbb{N}}\Vert x_n\Vert^2
 (x_n)_{n\in\mathbb{N}} \mathcal{H} N_0\geqslant 1 \vert n-m\vert\geqslant N_0 x_n\perp x_m \sum_{n\in\mathbb{N}}\Vert x_n\Vert^2 \sum_{n\in\mathbb{N}}x_n C N_0 
\Bigl\Vert \sum_{n\in\mathbb{N}}x_n\Bigr\Vert^2 \leqslant C\sum_{n\in\mathbb{N}}\Vert x_n\Vert^2
 S_q=\sum_{n\leqslant q}x_n 
\begin{align}
\Vert S_{q+q'}-S_q\Vert^2
&=\sum_{n=q+1}^{q'}\Vert x_n\Vert^2+\sum_{n=q+1}^{q'}\sum_{j=q+1}^{q'}\langle x_n,x_j\rangle + \overline{\langle x_n,x_j\rangle}\\
&=\sum_{n=q+1}^{q'}\Vert x_n\Vert^2+\sum_{n=q+1}^{q'}\sum_{j\in I_n}\langle x_n,x_j\rangle + \overline{\langle x_n,x_j\rangle}\\
&\leqslant \sum_{n=q+1}^{+\infty}\Vert x_n\Vert^2+2\sum_{n=q+1}^{q'}\sum_{j\in I_n}\vert\langle x_n,x_j\rangle\vert\\
&\leqslant \sum_{n=q+1}^{+\infty}\Vert x_n\Vert^2+2\sum_{n=q+1}^{q'}\Vert x_n\Vert\sum_{j\in I_n}\Vert x_j\Vert
\end{align}
 I_n=\{j:\vert n-j\vert\leqslant N_0\} \vert I_n\vert\leqslant N_0 
\sum_{j\in I_n}\Vert x_j\Vert\leqslant N_0\sup_{j\in I_n}\Vert x_j\Vert
 \sup_{j\in I_n}\Vert x_j\Vert C_j\Vert x_q\Vert^2 x_q\neq 0 C_j\in\mathbb{R} (C_j)_{j\in\mathbb{N}} \Vert S_q\Vert N_0=1","['sequences-and-series', 'inner-products']"
94,"How does one prove $\ln \zeta (s)=\sum _{{n=2}}^{\infty}{\frac{\Lambda (n)}{\log(n)}}\,{\frac{1}{n^{s}}}$",How does one prove,"\ln \zeta (s)=\sum _{{n=2}}^{\infty}{\frac{\Lambda (n)}{\log(n)}}\,{\frac{1}{n^{s}}}","Introduction The Von Mangoldt function is defined as follows: $$\Lambda (n)={\begin{cases}\log p&{\text{if }}n=p^{k}{\text{ for some prime }}p{\text{ and integer }}k\geq 1,\\0&{\text{otherwise.}}\end{cases}}$$ On the Wikipedia page over the Von Mangoldt function the identity below is listed: $$\ln\zeta(s)=\sum _{{n=2}}^{\infty}{\frac{\Lambda (n)}{\ln(n)}}{\frac{1}{n^{s}}}\qquad {\text{Re}}(s)>1$$ Question How do you prove this? I'm not familiar with the Von Mangoldt function so pardon me if the identity has a completely trivial derivation, but I couldn't find it anywhere so I had to ask here.","Introduction The Von Mangoldt function is defined as follows: On the Wikipedia page over the Von Mangoldt function the identity below is listed: Question How do you prove this? I'm not familiar with the Von Mangoldt function so pardon me if the identity has a completely trivial derivation, but I couldn't find it anywhere so I had to ask here.","\Lambda (n)={\begin{cases}\log p&{\text{if }}n=p^{k}{\text{ for some prime }}p{\text{ and integer }}k\geq 1,\\0&{\text{otherwise.}}\end{cases}} \ln\zeta(s)=\sum _{{n=2}}^{\infty}{\frac{\Lambda (n)}{\ln(n)}}{\frac{1}{n^{s}}}\qquad {\text{Re}}(s)>1","['sequences-and-series', 'number-theory']"
95,Proof that $\sum_{n=0}^{\infty}(-1)^{n} = \frac{1}{2}$. Is there any error?,Proof that . Is there any error?,\sum_{n=0}^{\infty}(-1)^{n} = \frac{1}{2},"So, I proved that: $$\int f(\ln x)\ dx = x \sum_{n=0}^{\infty}(-1)^{n} f^{(n)}(\ln x) \ \ \ +\ \ C$$ where $f^{(n)}$ is the nth derivative of $f$ . if we let $f(x) = e^{x}$ then $f^{(n)}(x) = e^x$ as well, so: $$\int e^{\ln x}\ dx = x \sum_{n=0}^{\infty}(-1)^{n} e^{\ln x} \ \ \ +\ \ C$$ giving us: $$\int x\ dx = x^{2} \sum_{n=0}^{\infty}(-1)^{n} \ \ \ +\ \ C$$ if we differentiate both sides with respect to $x$ we end up with: $$x=2x \sum_{n=0}^{\infty}(-1)^{n}$$ giving us: $$\sum_{n=0}^{\infty}(-1)^{n} = \frac{1}{2}$$ Am I doing something wrong or is this valid? Because I've learned that that series is divergent, yet through this method I've proven it to be $\frac{1}{2}$ wich is also its Cesàro sum.","So, I proved that: where is the nth derivative of . if we let then as well, so: giving us: if we differentiate both sides with respect to we end up with: giving us: Am I doing something wrong or is this valid? Because I've learned that that series is divergent, yet through this method I've proven it to be wich is also its Cesàro sum.",\int f(\ln x)\ dx = x \sum_{n=0}^{\infty}(-1)^{n} f^{(n)}(\ln x) \ \ \ +\ \ C f^{(n)} f f(x) = e^{x} f^{(n)}(x) = e^x \int e^{\ln x}\ dx = x \sum_{n=0}^{\infty}(-1)^{n} e^{\ln x} \ \ \ +\ \ C \int x\ dx = x^{2} \sum_{n=0}^{\infty}(-1)^{n} \ \ \ +\ \ C x x=2x \sum_{n=0}^{\infty}(-1)^{n} \sum_{n=0}^{\infty}(-1)^{n} = \frac{1}{2} \frac{1}{2},"['sequences-and-series', 'paradoxes', 'cesaro-summable']"
96,Properties of three terms of a geometric series,Properties of three terms of a geometric series,,"I’m [still!] working on the equation in this question , namely $$(b^2+2)^2=(a^2+2c^2)(bc-a).  \tag{$\star$}$$ where $a,b,c$ are integers. Evidently, $(\star)$ implies $$\frac{b^2+2}{bc-a} = \frac{a^2+2c^2}{b^2+2},  \tag{1}$$ which is to say that $\{bc-a,b^2+2,a^2+2c^2\}$ are three consecutive terms of a geometric series. QUESTION: Does that fact provide any information that would help in solving $(\star)$ ? i.e. , are there properties of geometric series that can be brought to bear on the problem? Each fraction in $(1)$ is actually an integer, in case that provides more leverage/structure. EDIT: The reason I know this is that I derived this equation from the equation $x^3=y^2+2$ , where $x=(b^2+2)/(bc-a)$ is a positive integer by assumption.","I’m [still!] working on the equation in this question , namely where are integers. Evidently, implies which is to say that are three consecutive terms of a geometric series. QUESTION: Does that fact provide any information that would help in solving ? i.e. , are there properties of geometric series that can be brought to bear on the problem? Each fraction in is actually an integer, in case that provides more leverage/structure. EDIT: The reason I know this is that I derived this equation from the equation , where is a positive integer by assumption.","(b^2+2)^2=(a^2+2c^2)(bc-a).  \tag{\star} a,b,c (\star) \frac{b^2+2}{bc-a} = \frac{a^2+2c^2}{b^2+2},  \tag{1} \{bc-a,b^2+2,a^2+2c^2\} (\star) (1) x^3=y^2+2 x=(b^2+2)/(bc-a)","['sequences-and-series', 'elementary-number-theory', 'divisibility', 'diophantine-equations', 'geometric-series']"
97,Infinite Product Series,Infinite Product Series,,"I was solving my school book and got bored so I made my own question for solving myself and to entertain myself. I made something like this:  Find solution of $$ \log_{e}x= \sqrt{x\sqrt{x\sqrt{x\sqrt{x...\infty}}}} $$ What I did in solution was this(sorry I was not able to add the solution in coded form for better representation as I am using stack exchange from my Android):- https://bit.ly/3cLFCgv So, I got x=1 as my solution BUT if we put x=1 in the former statement it will not hold true as it will come as 0=1 which is actually not true!! Please let me know where have I mistaken!! Thank you in Advance!!","I was solving my school book and got bored so I made my own question for solving myself and to entertain myself. I made something like this:  Find solution of What I did in solution was this(sorry I was not able to add the solution in coded form for better representation as I am using stack exchange from my Android):- https://bit.ly/3cLFCgv So, I got x=1 as my solution BUT if we put x=1 in the former statement it will not hold true as it will come as 0=1 which is actually not true!! Please let me know where have I mistaken!! Thank you in Advance!!", \log_{e}x= \sqrt{x\sqrt{x\sqrt{x\sqrt{x...\infty}}}} ,"['calculus', 'sequences-and-series', 'algebra-precalculus', 'infinite-product']"
98,Estimate $n$ such that $\log(n^C)<n$,Estimate  such that,n \log(n^C)<n,"Given $C\in \Bbb N$ (which we can assume to be big), is there a simple way to estimate de value of $n$ such that the following formula is satisfied? $$\log(n^C)<n.$$ Equivalently, how can we estimate the index $n$ where the sequence $x_n=\frac{n}{\log(n)}$ exceed a given value $C\in\Bbb N$ ?","Given (which we can assume to be big), is there a simple way to estimate de value of such that the following formula is satisfied? Equivalently, how can we estimate the index where the sequence exceed a given value ?",C\in \Bbb N n \log(n^C)<n. n x_n=\frac{n}{\log(n)} C\in\Bbb N,"['real-analysis', 'sequences-and-series', 'real-numbers', 'estimation']"
99,Is this alternative representation of $f(x)=xe^x$ as Maclaurin series correct?,Is this alternative representation of  as Maclaurin series correct?,f(x)=xe^x,"Let $f(x)=xe^x$ . I know $$e^x=\sum_{n=0}^\infty \frac{x^n}{n!}$$ and so $$f(x)=x\sum_{n=0}^\infty \frac{x^n}{n!}=x(1+x+\frac{x^2}{2!}+\frac{x^3}{3!}+...)=x+x^2+\frac{x^3}{2!}+\frac{x^4}{3!}+...=\sum_{n=0}^\infty \frac{x^{n+1}}{n!}$$ But shouldn't this other representation be also correct? $f'(x)=e^x+xe^x, f''(x)=2e^x+xe^x, f'''(x)=3e^x+xe^x,... \implies f^{(n)}(x)=ne^x+xe^x \implies f^{(n)}(0)=n$ Because I want $f(x)=\sum_{n=0}^\infty \frac{f^{(n)}(0)}{n!}x^n$ then $$f(x)=\sum_{n=0}^\infty \frac{n}{n!}x^n$$ If this other representation is also correct, then how $\sum_{n=0}^\infty \frac{n}{n!}x^n=\sum_{n=0}^\infty \frac{x^{n+1}}{n!}$ ?","Let . I know and so But shouldn't this other representation be also correct? Because I want then If this other representation is also correct, then how ?","f(x)=xe^x e^x=\sum_{n=0}^\infty \frac{x^n}{n!} f(x)=x\sum_{n=0}^\infty \frac{x^n}{n!}=x(1+x+\frac{x^2}{2!}+\frac{x^3}{3!}+...)=x+x^2+\frac{x^3}{2!}+\frac{x^4}{3!}+...=\sum_{n=0}^\infty \frac{x^{n+1}}{n!} f'(x)=e^x+xe^x, f''(x)=2e^x+xe^x, f'''(x)=3e^x+xe^x,... \implies f^{(n)}(x)=ne^x+xe^x \implies f^{(n)}(0)=n f(x)=\sum_{n=0}^\infty \frac{f^{(n)}(0)}{n!}x^n f(x)=\sum_{n=0}^\infty \frac{n}{n!}x^n \sum_{n=0}^\infty \frac{n}{n!}x^n=\sum_{n=0}^\infty \frac{x^{n+1}}{n!}","['sequences-and-series', 'power-series', 'taylor-expansion']"
