,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Convergence of sum with binomial coefficient,Convergence of sum with binomial coefficient,,"I found this exercise in a book and I don't know how to start: With the help of probabilistic methods, prove that $$ \lim_{n\rightarrow\infty} \frac{1}{4^n} \sum_{k=0}^n  \binom{2n}{k} = 1/2 $$ One cannot use the binomial theorem because the sum just goes to $n$ and not to $2n$ and besides that, am I supposed to use one of the limit theorems in stochastics? If so, which one and how can I approach this exercise.","I found this exercise in a book and I don't know how to start: With the help of probabilistic methods, prove that One cannot use the binomial theorem because the sum just goes to and not to and besides that, am I supposed to use one of the limit theorems in stochastics? If so, which one and how can I approach this exercise.","
\lim_{n\rightarrow\infty} \frac{1}{4^n} \sum_{k=0}^n  \binom{2n}{k} = 1/2
 n 2n","['probability', 'convergence-divergence']"
1,"Supplementary exercise 51, chapter 3 from 'A walk through combinatorics' 4th edition","Supplementary exercise 51, chapter 3 from 'A walk through combinatorics' 4th edition",,"I'm selfstudying 'A walk through combinatorics' by Miklós Bóna. This book has some supplementary exercises at the end of each chapter, no solution provided. I'm trying exercise 51, chapter 3. Problemstatement: A store has $n$ different products for sale. Each of them has a different price that is at least one dollar, at most $n$ dollars, and is a whole dollar. A customer only has the time to inspect $k$ different products. After doing so, she buys the product that has the lowest price among the $k$ products she inspected. Prove that on average she will pay $\frac{n+1}{k+1}$ dollars. Attempt at solution: The customer pays: 1 dollar if the product with price 1 dollar is the cheapest among the $k$ inspected products. This is possible in $\binom{n-1}{k-1}$ ways, since we need to pick $k-1$ products with prices in $\{2, \ldots, n\}$ . 2 dollars if the product with price 2 dollars is the cheapest among the $k$ inspected products. This is possible in $\binom{n-2}{k-1}$ ways, since we need to pick $k-1$ products with prices in $\{3, \ldots, n\}$ . $\ldots$ $n-k+1$ dollar if the product with price $n-k+1$ is the cheapest among the $k$ inspected products. There are only $k-1$ products which are more expensive, so this is possible in $\binom{n-(n-k+1)}{k-1} = \binom{k-1}{k-1}$ ways. This implies that the customer has to pay, on average $$\frac{1}{\binom{n}{k}}\cdot\left(1\cdot \binom{n-1}{k-1} + 2 \cdot \binom{n-2}{k-1} + \ldots + (n-k+1) \cdot \binom{k-1}{k-1}\right).$$ This is where I'm stuck : I want to show that the sum in brackets equals $\binom{n+1}{k+1}$ (guess based on what we need to prove, checked with some values of $n,k$ . This seems to be correct). Question: How to prove that $$1\cdot \binom{n-1}{k-1} + 2 \cdot \binom{n-2}{k-1} + \ldots + (n-k+1) \cdot \binom{k-1}{k-1} = \binom{n+1}{k+1},$$ a hint would be appreciated. I tried to give a combinatorial proof, but failed.","I'm selfstudying 'A walk through combinatorics' by Miklós Bóna. This book has some supplementary exercises at the end of each chapter, no solution provided. I'm trying exercise 51, chapter 3. Problemstatement: A store has different products for sale. Each of them has a different price that is at least one dollar, at most dollars, and is a whole dollar. A customer only has the time to inspect different products. After doing so, she buys the product that has the lowest price among the products she inspected. Prove that on average she will pay dollars. Attempt at solution: The customer pays: 1 dollar if the product with price 1 dollar is the cheapest among the inspected products. This is possible in ways, since we need to pick products with prices in . 2 dollars if the product with price 2 dollars is the cheapest among the inspected products. This is possible in ways, since we need to pick products with prices in . dollar if the product with price is the cheapest among the inspected products. There are only products which are more expensive, so this is possible in ways. This implies that the customer has to pay, on average This is where I'm stuck : I want to show that the sum in brackets equals (guess based on what we need to prove, checked with some values of . This seems to be correct). Question: How to prove that a hint would be appreciated. I tried to give a combinatorial proof, but failed.","n n k k \frac{n+1}{k+1} k \binom{n-1}{k-1} k-1 \{2, \ldots, n\} k \binom{n-2}{k-1} k-1 \{3, \ldots, n\} \ldots n-k+1 n-k+1 k k-1 \binom{n-(n-k+1)}{k-1} = \binom{k-1}{k-1} \frac{1}{\binom{n}{k}}\cdot\left(1\cdot \binom{n-1}{k-1} + 2 \cdot \binom{n-2}{k-1} + \ldots + (n-k+1) \cdot \binom{k-1}{k-1}\right). \binom{n+1}{k+1} n,k 1\cdot \binom{n-1}{k-1} + 2 \cdot \binom{n-2}{k-1} + \ldots + (n-k+1) \cdot \binom{k-1}{k-1} = \binom{n+1}{k+1},","['probability', 'combinatorics', 'combinations', 'combinatorial-proofs']"
2,Expected number of ball tosses to have at least 5 balls in 4 out of 5 bins (Skyrim application),Expected number of ball tosses to have at least 5 balls in 4 out of 5 bins (Skyrim application),,"I have a bit of an interesting probability question that has an application to Skyrim and the number of quests you need to complete to get an achievement for the Thieves Guild. I can generalize the problem in terms of balls and bins. Say you have an infinite number of balls available, and there are 5 bins , we can label them bins 1-5 ( the bins are distinct ). When you toss a ball, it is equally likely to fall into each bin (1/5 chance). What is the expected number of tosses so bins 1-4 have at least 5 balls in them ? Each bin can hold an infinite number of balls, and we don't care about the balls falling into bin 5 (meaning it can't necessarily be the first 4 bins to have 5 balls). I know that if I only cared about 1 bin reaching 5 balls, the expected value would be 5/p where p is the probability (1/5), but I can't continue this logic once one of the bins has 5 balls since the other bins may already have balls in them (the ""misses"" from trying to fill the first bin) so I have to use some other reasoning. I wrote some code that I think simulates the rules above and I am getting around 29.7, which is lower than I would expect (the absolute minimum tosses is 20) so I would like to confirm or disprove this result as well as know how to generate a mathematical formula and calculate this without code. Link to the code: https://github.com/nodnarb22/Skyrim-Thieves-Guild-Radiant-Quest-Simulator/blob/main/thievesguild Any help or input would be much appreciated!","I have a bit of an interesting probability question that has an application to Skyrim and the number of quests you need to complete to get an achievement for the Thieves Guild. I can generalize the problem in terms of balls and bins. Say you have an infinite number of balls available, and there are 5 bins , we can label them bins 1-5 ( the bins are distinct ). When you toss a ball, it is equally likely to fall into each bin (1/5 chance). What is the expected number of tosses so bins 1-4 have at least 5 balls in them ? Each bin can hold an infinite number of balls, and we don't care about the balls falling into bin 5 (meaning it can't necessarily be the first 4 bins to have 5 balls). I know that if I only cared about 1 bin reaching 5 balls, the expected value would be 5/p where p is the probability (1/5), but I can't continue this logic once one of the bins has 5 balls since the other bins may already have balls in them (the ""misses"" from trying to fill the first bin) so I have to use some other reasoning. I wrote some code that I think simulates the rules above and I am getting around 29.7, which is lower than I would expect (the absolute minimum tosses is 20) so I would like to confirm or disprove this result as well as know how to generate a mathematical formula and calculate this without code. Link to the code: https://github.com/nodnarb22/Skyrim-Thieves-Guild-Radiant-Quest-Simulator/blob/main/thievesguild Any help or input would be much appreciated!",,"['probability', 'expected-value']"
3,Average number of couples in dance competition finale,Average number of couples in dance competition finale,,"11 pairs of dancers will participate in a dance competition finale. However, on the day of the competition, 7 dancers were tested Covid positive and had to be eliminated. Given that partners aren’t interchangeable, meaning, if two dancers are left without their pair, they can’t dance together to form another pair, how many pairs on average are going to compete? Well, I am not sure how to approach this. Best case scenario is when the 7 sick dancers form $3.5$ pairs, that is, $4$ pairs can't participate, so we are left with $7$ pairs. There are 22 ways to select the first sick dancer. Then for the second, there is $1$ of $21$ left, to choose his pair, so ${22\choose 2}$ for one pair, then ${20\choose 2}$ for a second one and ${18\choose 2}$ for a third. It is getting very complicated to consider all the remaining cases. I would appreciate your assistance as it's been years since I worked with combinatorics and probabilities. Thank you.","11 pairs of dancers will participate in a dance competition finale. However, on the day of the competition, 7 dancers were tested Covid positive and had to be eliminated. Given that partners aren’t interchangeable, meaning, if two dancers are left without their pair, they can’t dance together to form another pair, how many pairs on average are going to compete? Well, I am not sure how to approach this. Best case scenario is when the 7 sick dancers form pairs, that is, pairs can't participate, so we are left with pairs. There are 22 ways to select the first sick dancer. Then for the second, there is of left, to choose his pair, so for one pair, then for a second one and for a third. It is getting very complicated to consider all the remaining cases. I would appreciate your assistance as it's been years since I worked with combinatorics and probabilities. Thank you.",3.5 4 7 1 21 {22\choose 2} {20\choose 2} {18\choose 2},"['probability', 'combinatorics']"
4,Minimizing the probability that two iid binomials RVs are equal,Minimizing the probability that two iid binomials RVs are equal,,"Let $X$ and $Y$ be iid with distribution $\text{Bin}(n,p)$ . I would like to show $P(X=Y)$ is minimzed when $p=1/2$ . $$P(X=Y)=\sum_{i=0}^n P(X=i)P(Y=i)=(1-p)^{2 n} \, _2F_1\left(-n,-n;1;\frac{p^2}{(p-1)^2}\right)$$ ( $_2F_1$ is the Hypergeometric Function ) I'm wondering how to show that such a complicated function is minimzed at $p=1/2$ or if there is an all-around simpler approach for this problem.",Let and be iid with distribution . I would like to show is minimzed when . ( is the Hypergeometric Function ) I'm wondering how to show that such a complicated function is minimzed at or if there is an all-around simpler approach for this problem.,"X Y \text{Bin}(n,p) P(X=Y) p=1/2 P(X=Y)=\sum_{i=0}^n P(X=i)P(Y=i)=(1-p)^{2 n} \, _2F_1\left(-n,-n;1;\frac{p^2}{(p-1)^2}\right) _2F_1 p=1/2","['probability', 'optimization', 'binomial-distribution']"
5,Easy question on probability,Easy question on probability,,"I know this is a trivial question but I want to make sure I'm not missing anything: We have a biased 6-sided die, which brings any of the 6 numbers with equal probability in the first roll, but in the second and all subsequent rolls, brings the previous result with probability $\frac {1}{2}$ and all others with probability $\frac {1}{10}$ . The question is: Suppose we get a 4 in the first roll; what is the probability we also get a 4 in the 3rd roll? In the 4th? And so on. If we get a 4 in the 1st roll, then for the 2nd roll we have $\frac {1}{2}$ probability to get a 4 and $\frac {1}{10}$ for all other numbers in the 2nd roll. So in the 3rd roll, we already have the results of the previous roll of getting a 4 with probability $\frac {1}{2}$ , so now the probability is $\frac {1}{4}$ ?","I know this is a trivial question but I want to make sure I'm not missing anything: We have a biased 6-sided die, which brings any of the 6 numbers with equal probability in the first roll, but in the second and all subsequent rolls, brings the previous result with probability and all others with probability . The question is: Suppose we get a 4 in the first roll; what is the probability we also get a 4 in the 3rd roll? In the 4th? And so on. If we get a 4 in the 1st roll, then for the 2nd roll we have probability to get a 4 and for all other numbers in the 2nd roll. So in the 3rd roll, we already have the results of the previous roll of getting a 4 with probability , so now the probability is ?",\frac {1}{2} \frac {1}{10} \frac {1}{2} \frac {1}{10} \frac {1}{2} \frac {1}{4},['probability']
6,Concentration of the $\ell_2$ error of the empirical distribution,Concentration of the  error of the empirical distribution,\ell_2,"Let $X$ be a random variable that takes values only in the set $\{1,2, \dots, m\}$ such that $\Pr(X = i) = p_i$ for all $i = 1,2, \dots, m$ . Let $S = \{X_1, X_2, \dots, X_n\}$ be a set of $n$ i.i.d. realisations of $X$ . We can then construct the empirical distribution $\{\hat{p}_i\}_{i = 1}^m$ using the samples from $S$ , where $\hat{p}_i = \frac{1}{n} |\{ j : X_j = i\}|$ . I am interested in the concentration inequalities for the random variable $Z := Y - \mathbb{E}[Y]$ where $Y = \| \hat{p} - p \|^2_2$ , the square of the $\ell_2$ norm of the difference between the true and the empirical distribution. I have found results in the literature on the concentration of the $\| \hat{p} - p\|_1$ , $D(\hat{p} \| p)$ and $\sup_{i} |\hat{p}_i - p_i |$ , where $D(p\|q)$ is the KL divergence between $p$ and $q$ . However, quite surprisingly, I haven't come across any result on the concentration of the $\ell_2$ norm. While it is possible to directly use the results for other norm for my case, it turns out that the resulting bounds are not tight enough for my case. Any leads or references will be appreciated. Thanks!","Let be a random variable that takes values only in the set such that for all . Let be a set of i.i.d. realisations of . We can then construct the empirical distribution using the samples from , where . I am interested in the concentration inequalities for the random variable where , the square of the norm of the difference between the true and the empirical distribution. I have found results in the literature on the concentration of the , and , where is the KL divergence between and . However, quite surprisingly, I haven't come across any result on the concentration of the norm. While it is possible to directly use the results for other norm for my case, it turns out that the resulting bounds are not tight enough for my case. Any leads or references will be appreciated. Thanks!","X \{1,2, \dots, m\} \Pr(X = i) = p_i i = 1,2, \dots, m S = \{X_1, X_2, \dots, X_n\} n X \{\hat{p}_i\}_{i = 1}^m S \hat{p}_i = \frac{1}{n} |\{ j : X_j = i\}| Z := Y - \mathbb{E}[Y] Y = \| \hat{p} - p \|^2_2 \ell_2 \| \hat{p} - p\|_1 D(\hat{p} \| p) \sup_{i} |\hat{p}_i - p_i | D(p\|q) p q \ell_2","['probability', 'random-variables', 'concentration-of-measure']"
7,Negative moments of Marchenko-Pastur law,Negative moments of Marchenko-Pastur law,,"Let $Z \sim \mu_\lambda$ be a the Marchenko-Pastur law with parameter $\lambda \in (0,\infty)$ , and let $k$ be a negative integer Question. Is there an analytic formula the $k$ th moment for $m_k(\lambda) = \mathbb E[Z^k]$ ? Note. I'm particularly inteteresting in $m_{-1}(\lambda)$ and $m_{-2}(\lambda)$ . Motivation $m_k(\lambda)$ is the trace of the pseudo-inverse of the $k$ th power a Wishart random matrix (inverse covariance matrix in gaussian iid random design). Application: generalization error of least-squares regression Consider a distribution $P$ on $\mathbb R^d \times \mathbb R$ defined by $(x,y) \sim P$ iff $x \sim N(0,(1/d)I_d)$ and $y|x \sim N(w_\star^\top x,\sigma^2)$ , where $w_\star \in \mathbb R^d$ and $\sigma \ge 0$ are fixed by unknown. Thus a point drawn from $P$ is of the form $(x,y)$ where $y=xw_\star+\eta$ , with $\eta \sim N(0,\sigma^2)$ . Let $\mathcal D_n := \{(x_1,y_1),\ldots,(x_n,y_n)\} \sim P^n$ be an iid sample from $P$ . Consider the problem of estimating $w_\star$ from the data $\mathcal D_n$ . For $n < d$ , $XX^\top$ is invertible w.p $1$ and the least-squares solution is given by $\hat{w} = X^\top(XX^\top)^{-1}y=P_X w_\star + X(XX^\top)^{-1}\varepsilon$ , where $X$ is the $n \times d$ matrix with $i$ th row $x_i$ , $P_X := X^\top (XX^\top)^{-1} X$ is the orthogonal projection matrix onto the row space of $X$ , $\epsilon$ is a column vector in $\mathbb R^n$ with iid components from $N(0,\sigma^2 I)$ , and $y = Xw_\star+\varepsilon$ . For any $w \in \mathbb R^d$ , let $f_w:\mathbb R^d \to \mathbb R$ be the linear function $f_w(x):=w_\star^\top x$ . Thus, the generalization error of the model $f_{\hat{w}}$ is given by $$ \begin{split} E_g &:= \mathbb E_{x}\mathbb E_\varepsilon[(w_\star^\top P_X x + \varepsilon^\top (XX^\top)^{-1} Xx - w_\star^\top x)^2]\\ &= (1/d)\|(I-P_X)w_\star\|^2+(\sigma^2/d)\mbox{tr}((XX^\top)^{-1}). \end{split} $$ Noise only model. For simplicity, assume $w_\star = 0$ . Then, in the limit when $n,d \to \infty$ with $n/d \to \lambda \in [0,1)$ , we have $$ E_g = \sigma^2\frac{1}{d}\mbox{tr}((XX^\top)^{-1}) \to \sigma^2 m_{-1}(\lambda),\,X\text{-a.s}. $$ Thanks to the accepted answer, we conclude that $E_g \to \dfrac{\sigma^2}{1-\lambda}$ , $X$ -a.s.","Let be a the Marchenko-Pastur law with parameter , and let be a negative integer Question. Is there an analytic formula the th moment for ? Note. I'm particularly inteteresting in and . Motivation is the trace of the pseudo-inverse of the th power a Wishart random matrix (inverse covariance matrix in gaussian iid random design). Application: generalization error of least-squares regression Consider a distribution on defined by iff and , where and are fixed by unknown. Thus a point drawn from is of the form where , with . Let be an iid sample from . Consider the problem of estimating from the data . For , is invertible w.p and the least-squares solution is given by , where is the matrix with th row , is the orthogonal projection matrix onto the row space of , is a column vector in with iid components from , and . For any , let be the linear function . Thus, the generalization error of the model is given by Noise only model. For simplicity, assume . Then, in the limit when with , we have Thanks to the accepted answer, we conclude that , -a.s.","Z \sim \mu_\lambda \lambda \in (0,\infty) k k m_k(\lambda) = \mathbb E[Z^k] m_{-1}(\lambda) m_{-2}(\lambda) m_k(\lambda) k P \mathbb R^d \times \mathbb R (x,y) \sim P x \sim N(0,(1/d)I_d) y|x \sim N(w_\star^\top x,\sigma^2) w_\star \in \mathbb R^d \sigma \ge 0 P (x,y) y=xw_\star+\eta \eta \sim N(0,\sigma^2) \mathcal D_n := \{(x_1,y_1),\ldots,(x_n,y_n)\} \sim P^n P w_\star \mathcal D_n n < d XX^\top 1 \hat{w} = X^\top(XX^\top)^{-1}y=P_X w_\star + X(XX^\top)^{-1}\varepsilon X n \times d i x_i P_X := X^\top (XX^\top)^{-1} X X \epsilon \mathbb R^n N(0,\sigma^2 I) y = Xw_\star+\varepsilon w \in \mathbb R^d f_w:\mathbb R^d \to \mathbb R f_w(x):=w_\star^\top x f_{\hat{w}} 
\begin{split}
E_g &:= \mathbb E_{x}\mathbb E_\varepsilon[(w_\star^\top P_X x + \varepsilon^\top (XX^\top)^{-1} Xx - w_\star^\top x)^2]\\
&= (1/d)\|(I-P_X)w_\star\|^2+(\sigma^2/d)\mbox{tr}((XX^\top)^{-1}).
\end{split}
 w_\star = 0 n,d \to \infty n/d \to \lambda \in [0,1) 
E_g = \sigma^2\frac{1}{d}\mbox{tr}((XX^\top)^{-1}) \to \sigma^2 m_{-1}(\lambda),\,X\text{-a.s}.
 E_g \to \dfrac{\sigma^2}{1-\lambda} X","['probability', 'statistics', 'random-matrices']"
8,The Broken Calculator Problem,The Broken Calculator Problem,,"So here is the Problem :- Tom has a specific calculator . Unfortunately, all keys are broken except for one row $: 1,2,3,+,-$ . Tom presses a sequence of $5$ random keys; where at each stroke, each key is equally likely to be pressed. The calculator then evaluates the entire expression, yielding a result of E. Find the Expected Value of E. Before doing this we need to remember some facts :- $(i)$ Excess Operators will be parsed as signs. For e.g. :- $-2-+3$ gives $E = -5$ .and $-+-31$ gives $E = 31$ $(ii)$ Trailing Operators are discarded . For e.g. :- $2-+--$ gives $E = 2$ $(iii)$ Negative Sums are allowed . For e.g. :- $13 - 22$ give $E = -9$ . $(iv)$ A string consisting only of operators , gives $E$ as $0$ . This Problem looks very interesting to me . First of all there can be many different types of sums for E and second, it's definitely not quite easy to get the expected value of it, and I don't know who to start doing it . Any ideas for this problem will be greatly appreciated !!","So here is the Problem :- Tom has a specific calculator . Unfortunately, all keys are broken except for one row . Tom presses a sequence of random keys; where at each stroke, each key is equally likely to be pressed. The calculator then evaluates the entire expression, yielding a result of E. Find the Expected Value of E. Before doing this we need to remember some facts :- Excess Operators will be parsed as signs. For e.g. :- gives .and gives Trailing Operators are discarded . For e.g. :- gives Negative Sums are allowed . For e.g. :- give . A string consisting only of operators , gives as . This Problem looks very interesting to me . First of all there can be many different types of sums for E and second, it's definitely not quite easy to get the expected value of it, and I don't know who to start doing it . Any ideas for this problem will be greatly appreciated !!",": 1,2,3,+,- 5 (i) -2-+3 E = -5 -+-31 E = 31 (ii) 2-+-- E = 2 (iii) 13 - 22 E = -9 (iv) E 0","['probability', 'probability-distributions', 'recreational-mathematics', 'expected-value', 'calculator']"
9,Wimbledon's final,Wimbledon's final,,"Tom and Jack are playing the final of Wimbledon and they are 6:6 at the last set. They play to the bitter end until one of them is ahead by two games. For Tom the probability to win the next games is $p$ , and for Jack $1-p$ . Every games is independent from the others. Find the probability that the match end 9 to 7 for one of them. For $A=($ Tom wins 9 to 7 $)$ and $B=($ Jack wins 9 to 7 $)$ , we have $\rightarrow \mathbb{P}(A\cup B)=2p(1-p)[p^2+(1-p)^2]$ Find the probability that it needs more than 4 games to end the match. For $X=($ # games to the end $)$ , we have $\rightarrow \mathbb{P}(X>4)=1-\mathbb{P}(X\leq 4)=1-\mathbb{P}(X\leq 4|A\cup B)=1-\frac{\mathbb{P}(X\leq 4 \cap A)+\mathbb{P}(X\leq4\cap B)}{\mathbb{P}(A)+\mathbb{P}(B)}=1-\frac{2[p^2+(1-p)^2]}{[p^2-(1-p)^2]}$ Find the probability that Tom wins. Hoping 1) and 2) are right, do you have any ideas for point 3)? Thanks in advance.","Tom and Jack are playing the final of Wimbledon and they are 6:6 at the last set. They play to the bitter end until one of them is ahead by two games. For Tom the probability to win the next games is , and for Jack . Every games is independent from the others. Find the probability that the match end 9 to 7 for one of them. For Tom wins 9 to 7 and Jack wins 9 to 7 , we have Find the probability that it needs more than 4 games to end the match. For # games to the end , we have Find the probability that Tom wins. Hoping 1) and 2) are right, do you have any ideas for point 3)? Thanks in advance.",p 1-p A=( ) B=( ) \rightarrow \mathbb{P}(A\cup B)=2p(1-p)[p^2+(1-p)^2] X=( ) \rightarrow \mathbb{P}(X>4)=1-\mathbb{P}(X\leq 4)=1-\mathbb{P}(X\leq 4|A\cup B)=1-\frac{\mathbb{P}(X\leq 4 \cap A)+\mathbb{P}(X\leq4\cap B)}{\mathbb{P}(A)+\mathbb{P}(B)}=1-\frac{2[p^2+(1-p)^2]}{[p^2-(1-p)^2]},['probability']
10,Are all almost regular languages regular?,Are all almost regular languages regular?,,"Let’s define a randomized acceptor as a tuple $V = (A, Q, \Omega, \mathfrak{F}, P, \phi, q_i, Q_t)$ , where $A$ is the input alphabet , $Q$ is the set of states , $(\Omega, \mathfrak{F}, P)$ is a probability space, $\phi: Q \times A \times \Omega \to Q$ is the transition function and $q_i \in Q$ is the initial state and $Q_t \subset Q$ are the terminal states accordingly. We will call $V$ finite iff both $A$ and $Q$ are finite. Let’s extend the transition function $\phi$ from $Q \times A \times \Omega$ to $Q \times A^* \times \Omega$ using the recurrence formulas: $$\phi(q, \Lambda, \omega) = q$$ $$\phi(q, \alpha a, \omega) = \phi(\phi(q, \alpha, \omega), a, \omega) \forall a \in A \alpha \in A^*$$ Now define the acceptance probability of a word $w \in A^*$ in $V$ as $P_V(w) := P(\{\omega \in \Omega| \phi(q_i, w, \omega) \in Q_t)$ . Using this we can define for an arbitrary language $L \subset A^*$ the absolute error of $V$ in respect to it as $Err(V, L) := sup\{|P_V(w) - \mathbb{I}_V(w)| | w \in A^* \}$ . Let’s call a formal language $L \subset A^*$ almost regular iff $\forall \epsilon > 0$ $\exists$ a finite randomized acceptor $V$ such that $Err(V, L) < \epsilon$ . It is not hard to see, that all regular languages are almost regular. Bug is the converse true? Or does there exist an almost regular formal language, which is not regular?","Let’s define a randomized acceptor as a tuple , where is the input alphabet , is the set of states , is a probability space, is the transition function and is the initial state and are the terminal states accordingly. We will call finite iff both and are finite. Let’s extend the transition function from to using the recurrence formulas: Now define the acceptance probability of a word in as . Using this we can define for an arbitrary language the absolute error of in respect to it as . Let’s call a formal language almost regular iff a finite randomized acceptor such that . It is not hard to see, that all regular languages are almost regular. Bug is the converse true? Or does there exist an almost regular formal language, which is not regular?","V = (A, Q, \Omega, \mathfrak{F}, P, \phi, q_i, Q_t) A Q (\Omega, \mathfrak{F}, P) \phi: Q \times A \times \Omega \to Q q_i \in Q Q_t \subset Q V A Q \phi Q \times A \times \Omega Q \times A^* \times \Omega \phi(q, \Lambda, \omega) = q \phi(q, \alpha a, \omega) = \phi(\phi(q, \alpha, \omega), a, \omega) \forall a \in A \alpha \in A^* w \in A^* V P_V(w) := P(\{\omega \in \Omega| \phi(q_i, w, \omega) \in Q_t) L \subset A^* V Err(V, L) := sup\{|P_V(w) - \mathbb{I}_V(w)| | w \in A^* \} L \subset A^* \forall \epsilon > 0 \exists V Err(V, L) < \epsilon","['probability', 'discrete-mathematics', 'formal-languages', 'automata', 'regular-language']"
11,Dice rolling probability game,Dice rolling probability game,,"In a hockey-themed board game, players start the game in the penalty box. If rolling the same number on both dice is required to escape from the penalty box, and Piper, Quincy, and Riley take turns, in he order named, rolling a pair of standard six sided dice, what is the probability that Piper is the last player to escape from the penalty box? My initial thought was that riley and quincy both escape with a 1/36 probability. So, we multiply the three together getting $\frac{1}{36^3}$ , but this is clearly incorrect. Then I took more thinking to this problem. To satisfy the problem we need Piper to lose her first throw, Quincy to win her throw, Riley to win her throw, then Piper will eventually win her throw. So we have $\dfrac{5}{6} \cdot \dfrac{1}{6} \cdot \dfrac{1}{6} \cdot = \dfrac{5}{6^{3}}$ . However, there other cases where Piper looses, Quincy looses, Riley looses, Piper looses, then Quincy and Riley wins, or where Riley wins before Quincy. So this can account into what I'm thinking of an infinitely long geometric sequence that later converges to a rational number. There are many, many more cases. To account for this, I have to keep analyzing all possibilities at each turn, and I believe that eventually I will get some geometric progressions. However, this seems tedious and error prone. So then I thought that I could just denote the probabilities that I am interested in by letters and write some equations. For instance, if the probability of Piper escaping last is $p$ , then after a turn in which nobody escapes the probability of Piper escaping last is still $p$ . This allows me to write the equation: $$p= {5\over 6}^3\cdot p +\text{other cases }.$$ But however, I cannot seem to find that ""other cases"" thing, and I even further doubted that the $p$ in the equation is stable. But after some further examination, I find this is not so. I considered first the case with two players: Let $p$ be the probability that the player who starts first escapes first and $q$ the probability that the second player escapes first. I could write the equation $p=1/6+5/6\cdot q$ because the probability of the first player escaping is 1/6 plus the probability of him not escaping (5/6) times the probability of him winning as second player, because now the other player rolls the dice first. Another equation I could write is $p+q=1$ because one of them will escape eventually (with probability 1). Solving this I get $p=1/6+5/6(1-p)$ etc. which leads to $p=6/11$ . This is incorrect. And, after a long time of thoughts, I finally figured the way to write the infinite sum, $p=1/6 + (5/6)^2\cdot 1/6+(5/6)^4\cdot 1/6+\dots$ , because the probability of the first player escaping first is 1/6 (if he rolls a double) + (5/6)^2 (=probability of both not rolling a double) times 1/6 (rolling a double at the second turn) and so on... The sum of that infinite progression is $$p=1/6\cdot {1\over 1-(5/6)^2}$$ which still gives $6/11$ , and is wrong again. I cannot think of a way to continue. Help please?","In a hockey-themed board game, players start the game in the penalty box. If rolling the same number on both dice is required to escape from the penalty box, and Piper, Quincy, and Riley take turns, in he order named, rolling a pair of standard six sided dice, what is the probability that Piper is the last player to escape from the penalty box? My initial thought was that riley and quincy both escape with a 1/36 probability. So, we multiply the three together getting , but this is clearly incorrect. Then I took more thinking to this problem. To satisfy the problem we need Piper to lose her first throw, Quincy to win her throw, Riley to win her throw, then Piper will eventually win her throw. So we have . However, there other cases where Piper looses, Quincy looses, Riley looses, Piper looses, then Quincy and Riley wins, or where Riley wins before Quincy. So this can account into what I'm thinking of an infinitely long geometric sequence that later converges to a rational number. There are many, many more cases. To account for this, I have to keep analyzing all possibilities at each turn, and I believe that eventually I will get some geometric progressions. However, this seems tedious and error prone. So then I thought that I could just denote the probabilities that I am interested in by letters and write some equations. For instance, if the probability of Piper escaping last is , then after a turn in which nobody escapes the probability of Piper escaping last is still . This allows me to write the equation: But however, I cannot seem to find that ""other cases"" thing, and I even further doubted that the in the equation is stable. But after some further examination, I find this is not so. I considered first the case with two players: Let be the probability that the player who starts first escapes first and the probability that the second player escapes first. I could write the equation because the probability of the first player escaping is 1/6 plus the probability of him not escaping (5/6) times the probability of him winning as second player, because now the other player rolls the dice first. Another equation I could write is because one of them will escape eventually (with probability 1). Solving this I get etc. which leads to . This is incorrect. And, after a long time of thoughts, I finally figured the way to write the infinite sum, , because the probability of the first player escaping first is 1/6 (if he rolls a double) + (5/6)^2 (=probability of both not rolling a double) times 1/6 (rolling a double at the second turn) and so on... The sum of that infinite progression is which still gives , and is wrong again. I cannot think of a way to continue. Help please?",\frac{1}{36^3} \dfrac{5}{6} \cdot \dfrac{1}{6} \cdot \dfrac{1}{6} \cdot = \dfrac{5}{6^{3}} p p p= {5\over 6}^3\cdot p +\text{other cases }. p p q p=1/6+5/6\cdot q p+q=1 p=1/6+5/6(1-p) p=6/11 p=1/6 + (5/6)^2\cdot 1/6+(5/6)^4\cdot 1/6+\dots p=1/6\cdot {1\over 1-(5/6)^2} 6/11,['probability']
12,Expected number of wrong seats on plane,Expected number of wrong seats on plane,,"Many people will be familiar with the set up of this problem: you have an aeroplane with 100 seats, and 100 passengers who have been allocated unique seats. The first passenger forgets their ticket, and so takes a random seat. The remaining passengers enter the plane. If their seat is empty, they take it. If it is occupied, they take a random seat on the plane. At this point, the question that is usually asked it ""what is the probability that the 100th person gets their allocated seat"". This was asked here . My question is a bit different. By the time all the passengers have boarded what is the expected number of passengers in the wrong seat? I have seen many people ask this as a follow up question to the first on some other online forums, but there doesn't appear to be a convincing answer anywhere. Attempt: Looking at smaller sized planes, we can come up with a conjecture than for a plane of size $n$, we have $$\text{expectation}=\begin{cases}1+\frac12+\cdots+\frac1{n-1}&n\text{ is even}\\\frac12+\frac13+\cdots+\frac1n&n\text{ is odd}\end{cases}$$ When trying to compute the expectation for even $n$ as a sum, we get a very complicated expression, of the form $$\frac1n\left(2\sum_{i=1}^{n-1}\frac1i+3\sum_{i\ne j,i,j=1}^{n-1}\frac1{ij}+4\sum_{i\ne j\ne k,i,j,k=1}^{n-1}\frac1{ijk}\cdots\right)$$ How can we derive the result I have conjectured? $\small\text{Edit:}$ $\small\text{The conjecture was wrong in the odd case - the expectation is always equal to }\small\sum_{i=1}^{n-1}\frac1i\small\text{whether }n\small\text{ is even or odd. (As shown by the answers and @Akababa's comment)}$","Many people will be familiar with the set up of this problem: you have an aeroplane with 100 seats, and 100 passengers who have been allocated unique seats. The first passenger forgets their ticket, and so takes a random seat. The remaining passengers enter the plane. If their seat is empty, they take it. If it is occupied, they take a random seat on the plane. At this point, the question that is usually asked it ""what is the probability that the 100th person gets their allocated seat"". This was asked here . My question is a bit different. By the time all the passengers have boarded what is the expected number of passengers in the wrong seat? I have seen many people ask this as a follow up question to the first on some other online forums, but there doesn't appear to be a convincing answer anywhere. Attempt: Looking at smaller sized planes, we can come up with a conjecture than for a plane of size $n$, we have $$\text{expectation}=\begin{cases}1+\frac12+\cdots+\frac1{n-1}&n\text{ is even}\\\frac12+\frac13+\cdots+\frac1n&n\text{ is odd}\end{cases}$$ When trying to compute the expectation for even $n$ as a sum, we get a very complicated expression, of the form $$\frac1n\left(2\sum_{i=1}^{n-1}\frac1i+3\sum_{i\ne j,i,j=1}^{n-1}\frac1{ij}+4\sum_{i\ne j\ne k,i,j,k=1}^{n-1}\frac1{ijk}\cdots\right)$$ How can we derive the result I have conjectured? $\small\text{Edit:}$ $\small\text{The conjecture was wrong in the odd case - the expectation is always equal to }\small\sum_{i=1}^{n-1}\frac1i\small\text{whether }n\small\text{ is even or odd. (As shown by the answers and @Akababa's comment)}$",,"['probability', 'combinatorics', 'expectation', 'puzzle']"
13,Probability that a stick randomly broken in three places can form a triangle,Probability that a stick randomly broken in three places can form a triangle,,"I like questions about geometric probability, and two of my favourite questions here on math.SE are Probability that a stick randomly broken in two places can form a triangle and Probability that a stick randomly broken in five places can form a tetrahedron . I wondered about the probability that a stick randomly broken in three places can form a triangle. More generally, we can ask for the probability distribution of the number of triangles that can be formed from the four pieces. Since each triple of the pieces has probability $\frac14$ of forming a triangle, the expected number of triangles we can form is $\frac14\cdot4=1$, which is already a rather nice result. I tried various ways of applying inclusion–exclusion, with or without first ordering the segments by size, but it all seemed too complicated and unenlightening, and I ended up writing a program to output all the inequalities in order to let qhull compute the volumes of the polytopes they define. The result (confirmed by simulations) is: \begin{array}{c|c|c} &\text{probability}&\text{probability}\\ \#\triangle&\text{(reduced)}&\text{(unreduced)}\\\hline 0&\frac37&\frac{45}{105}\\ 1&\frac{11}{35}&\frac{33}{105}\\ 2&\frac{16}{105}&\frac{16}{105}\\ 3&\frac4{105}&\frac4{105}\\ 4&\frac1{15}&\frac7{105} \end{array} You can check that the expected number of triangles comes out as $1$. While the overall distribution is somewhat complicated, the probabilities that we can form all triangles ($\frac1{15}$), any triangle ($\frac47$) and no triangles ($\frac37$) come out as nice low fractions, so I thought that maybe there's hope to find an elegant way to compute (one of) them after all. Do you see one? (The three places where the stick is broken are independently uniformly chosen along its length.)","I like questions about geometric probability, and two of my favourite questions here on math.SE are Probability that a stick randomly broken in two places can form a triangle and Probability that a stick randomly broken in five places can form a tetrahedron . I wondered about the probability that a stick randomly broken in three places can form a triangle. More generally, we can ask for the probability distribution of the number of triangles that can be formed from the four pieces. Since each triple of the pieces has probability $\frac14$ of forming a triangle, the expected number of triangles we can form is $\frac14\cdot4=1$, which is already a rather nice result. I tried various ways of applying inclusion–exclusion, with or without first ordering the segments by size, but it all seemed too complicated and unenlightening, and I ended up writing a program to output all the inequalities in order to let qhull compute the volumes of the polytopes they define. The result (confirmed by simulations) is: \begin{array}{c|c|c} &\text{probability}&\text{probability}\\ \#\triangle&\text{(reduced)}&\text{(unreduced)}\\\hline 0&\frac37&\frac{45}{105}\\ 1&\frac{11}{35}&\frac{33}{105}\\ 2&\frac{16}{105}&\frac{16}{105}\\ 3&\frac4{105}&\frac4{105}\\ 4&\frac1{15}&\frac7{105} \end{array} You can check that the expected number of triangles comes out as $1$. While the overall distribution is somewhat complicated, the probabilities that we can form all triangles ($\frac1{15}$), any triangle ($\frac47$) and no triangles ($\frac37$) come out as nice low fractions, so I thought that maybe there's hope to find an elegant way to compute (one of) them after all. Do you see one? (The three places where the stick is broken are independently uniformly chosen along its length.)",,"['probability', 'alternative-proof', 'inclusion-exclusion', 'geometric-probability']"
14,Probability event with $70$% success rate occurs three consecutive times for sample size $n$,Probability event with % success rate occurs three consecutive times for sample size,70 n,"It has been a long time since I've done probability so I am not sure which to do (if either are correct). Thank you for taking the time to look at my work. Probability an event occurs is $70$%. I'm looking for the probability our event occurs three times in a row for sample size $n$. $(.7)^3=.343$ is the probability to occur three consecutive times $1-.343=.657$ would be the chance to fail. First idea: For $n=3$ our success rate is $.343$ $n=4$ we have two opportunities for success, thus $1-(.657)^2=.568351$ $n=5$, three opportunities for success, thus $1-(.657)^3=.71640$... Generalization: Probability for success: $$1 - (.657)^{n-2}$$ Second idea: Probability when $n=3$ would be $(.7)^3$ At $n=4$ we'd have $(.7)^3+(.3)(.7)^3$ For $n=5$ we'd have $(.7)^3+(.3)(.7)^3+(.3)^2(.7)^3+(.3)(.7)^4$ I'm leaning towards the second idea...but I'm failing to see a generalization for it. Please excuse my LaTeX it has been a long time since I've asked/answered any questions. Thank you.","It has been a long time since I've done probability so I am not sure which to do (if either are correct). Thank you for taking the time to look at my work. Probability an event occurs is $70$%. I'm looking for the probability our event occurs three times in a row for sample size $n$. $(.7)^3=.343$ is the probability to occur three consecutive times $1-.343=.657$ would be the chance to fail. First idea: For $n=3$ our success rate is $.343$ $n=4$ we have two opportunities for success, thus $1-(.657)^2=.568351$ $n=5$, three opportunities for success, thus $1-(.657)^3=.71640$... Generalization: Probability for success: $$1 - (.657)^{n-2}$$ Second idea: Probability when $n=3$ would be $(.7)^3$ At $n=4$ we'd have $(.7)^3+(.3)(.7)^3$ For $n=5$ we'd have $(.7)^3+(.3)(.7)^3+(.3)^2(.7)^3+(.3)(.7)^4$ I'm leaning towards the second idea...but I'm failing to see a generalization for it. Please excuse my LaTeX it has been a long time since I've asked/answered any questions. Thank you.",,"['probability', 'combinatorics']"
15,Probability that $A \cup B$ = S and $A \cap B = \phi $,Probability that  = S and,A \cup B A \cap B = \phi ,Let $S$ be a set containing $n$ elements and we select two subsets: $A$ and $B$ at random then the probability that $A \cup B$ = S and $A \cap B = \varnothing $ is? My attempt Total number of cases= $3^n$ as each element in set $S$ has three option: Go to $A$ or $B$ or to neither of $A$ or $B$ For favourable cases: Each element has two options: Either go to $A$ or to $B$ which gives $2^n$ favourable cases. Is my approach correct?,Let $S$ be a set containing $n$ elements and we select two subsets: $A$ and $B$ at random then the probability that $A \cup B$ = S and $A \cap B = \varnothing $ is? My attempt Total number of cases= $3^n$ as each element in set $S$ has three option: Go to $A$ or $B$ or to neither of $A$ or $B$ For favourable cases: Each element has two options: Either go to $A$ or to $B$ which gives $2^n$ favourable cases. Is my approach correct?,,"['probability', 'proof-verification']"
16,Almost sure bounded imply finite expectation?,Almost sure bounded imply finite expectation?,,"Suppose that the random variable $X$ is $\mid X \mid<M$ almost surely, for some constant $M<\infty.$ Then can we say that $E(X)<C$ for some constant $C<\infty$? If the expectation is not bounded, is there any additional (other than bounded a.s.) conditions on $X$ that would give us a finite expectation? My confusion is there could be $0\cdot \infty$ terms where the random variable is infinite with probability $0$. And these terms are not defined well. I believe this post disproves the converse. This is not homework just self studying. Thank you.","Suppose that the random variable $X$ is $\mid X \mid<M$ almost surely, for some constant $M<\infty.$ Then can we say that $E(X)<C$ for some constant $C<\infty$? If the expectation is not bounded, is there any additional (other than bounded a.s.) conditions on $X$ that would give us a finite expectation? My confusion is there could be $0\cdot \infty$ terms where the random variable is infinite with probability $0$. And these terms are not defined well. I believe this post disproves the converse. This is not homework just self studying. Thank you.",,"['probability', 'measure-theory']"
17,Conditional expectation of a bivariate normal distribution,Conditional expectation of a bivariate normal distribution,,"Can you help me? Find the conditional expectation $\mathbb{E}[X|Y]$ if $(X,Y)$ possesses a bivariate normal distribution. Is $\mathbb{E}[X|Y=y]=\mu_X+\sigma_X\rho(\frac{\displaystyle y-\mu_Y}{\displaystyle \sigma_Y})$ the solution? My question: Is the same $\mathbb{E}[X|Y=y]$ and $\mathbb{E}[X|Y]$?","Can you help me? Find the conditional expectation $\mathbb{E}[X|Y]$ if $(X,Y)$ possesses a bivariate normal distribution. Is $\mathbb{E}[X|Y=y]=\mu_X+\sigma_X\rho(\frac{\displaystyle y-\mu_Y}{\displaystyle \sigma_Y})$ the solution? My question: Is the same $\mathbb{E}[X|Y=y]$ and $\mathbb{E}[X|Y]$?",,"['probability', 'statistics', 'conditional-expectation']"
18,Family of functions that are bounded in $L^1$ but *NOT* Uniformly Integrable,Family of functions that are bounded in  but *NOT* Uniformly Integrable,L^1,"I'm having a difficult time constructing a counter example to this. My intuition (sloppily) is to construct a family of functions {$X_n$} that have Dirac pulses at $n$ and $-n$. Such that $\sup_n \Bbb E[|X_n|\Bbb 1_{X≥n}]=1$ However, I'm not sure if this is correct.","I'm having a difficult time constructing a counter example to this. My intuition (sloppily) is to construct a family of functions {$X_n$} that have Dirac pulses at $n$ and $-n$. Such that $\sup_n \Bbb E[|X_n|\Bbb 1_{X≥n}]=1$ However, I'm not sure if this is correct.",,"['probability', 'measure-theory', 'probability-theory', 'uniform-integrability']"
19,Find the expected number of people who select their own name tag,Find the expected number of people who select their own name tag,,"At a party n people throw their name tags on a table. The name tags are mixed up and then each people randomly and simultaneously selects one. Find the expected number of people who select their own name tag. Since the people choose simultaneously, I assumed that each has  $\frac{(n-1)!}{n!}$ or $\frac{1}{n}$ chance of selecting their own, thus expected number of people who get their own name tag is $ n\cdot \frac{1}{n} = 1 $. Am I correct in this?","At a party n people throw their name tags on a table. The name tags are mixed up and then each people randomly and simultaneously selects one. Find the expected number of people who select their own name tag. Since the people choose simultaneously, I assumed that each has  $\frac{(n-1)!}{n!}$ or $\frac{1}{n}$ chance of selecting their own, thus expected number of people who get their own name tag is $ n\cdot \frac{1}{n} = 1 $. Am I correct in this?",,"['probability', 'statistics']"
20,Independence of sum and difference for random vectors,Independence of sum and difference for random vectors,,"Suppose I have two independent random vectors $X,Y\in \mathbb R^n$ such that each entry $x_i\sim\mathcal{N}(0,1)$ i.i.d., $y_i\sim\mathcal{N}(0,1)$ i.i.d.  Define $$ S = X+Y, \qquad D = X-Y .$$ I seem to remember learning that $S$ and $D$ are independent RVs but can't find a reference.  Is this even true, and how could I go about showing this? Does the same apply for any other distributions for $X$ and $Y$ (in particular with non-independent entries)?","Suppose I have two independent random vectors $X,Y\in \mathbb R^n$ such that each entry $x_i\sim\mathcal{N}(0,1)$ i.i.d., $y_i\sim\mathcal{N}(0,1)$ i.i.d.  Define $$ S = X+Y, \qquad D = X-Y .$$ I seem to remember learning that $S$ and $D$ are independent RVs but can't find a reference.  Is this even true, and how could I go about showing this? Does the same apply for any other distributions for $X$ and $Y$ (in particular with non-independent entries)?",,['probability']
21,Determining a consistent estimator/asymptotic relative efficiency,Determining a consistent estimator/asymptotic relative efficiency,,"Question: Let $X_1,\ldots,X_n$ be i.i.d. as $N(0,\sigma^2)$. a) Show that $\delta_1 = k \sum_{i=1}^n |X_i|/n$ is a consistent estimator of $\sigma$ if and only if $ k = \sqrt{\pi/2}$. b) Determine the asymptotic relative efficiency of $\delta_1$ with respect to $\delta_2 = \sqrt{\sum X_i^2/n}$ Attempt: a) i) Given $ k = \sqrt{\pi/2}$. We must find a variance that converges to 0. Calculating the variance of $\delta_1 $: $$ \begin{align} & = E\left[ \left(\sqrt{\frac\pi2} \sum_{i=1}^n |X_i|/n\right)-\mu\right]^2 \\[8pt] & = \frac \pi 2 E\left[ \left(\sum_{i=1}^n |X_i|/n\right)-\mu\right]^2 \end{align} $$ I'm stuck here, however, this should come to: $$\frac{\pi}{2}\frac{1}{n}\left[\sigma^2 + \frac{2}{\pi}\sigma^2\right]$$ which converges to zero. ii) Since $\delta_1$ converges in probability to $\sigma$, and since k must be unique,  k must equal $\sqrt{\pi/2}$ b) I know this involves the Central Limit Theorem; however, I'm not able to piece the whole thing together. I know that $$E(|X_i|) = \int_{-\infty}^\infty |x|\frac{1}{\sqrt{2\pi\sigma}}\exp\left(\frac{-x}{2\sigma^2}\right)\,dx = \sqrt{\frac{2}{\pi}}\sigma$$ and $\operatorname{Var}(|X_i|) = \sigma^2 - \frac{2}{\pi}\sigma^2$ Also, $$\sqrt{n}(\delta_1 - \sigma)\xrightarrow[]{L} N\left(0,\left(\frac{\pi}{2}-1\right)\sigma^2\right)$$ Not sure how to proceed.","Question: Let $X_1,\ldots,X_n$ be i.i.d. as $N(0,\sigma^2)$. a) Show that $\delta_1 = k \sum_{i=1}^n |X_i|/n$ is a consistent estimator of $\sigma$ if and only if $ k = \sqrt{\pi/2}$. b) Determine the asymptotic relative efficiency of $\delta_1$ with respect to $\delta_2 = \sqrt{\sum X_i^2/n}$ Attempt: a) i) Given $ k = \sqrt{\pi/2}$. We must find a variance that converges to 0. Calculating the variance of $\delta_1 $: $$ \begin{align} & = E\left[ \left(\sqrt{\frac\pi2} \sum_{i=1}^n |X_i|/n\right)-\mu\right]^2 \\[8pt] & = \frac \pi 2 E\left[ \left(\sum_{i=1}^n |X_i|/n\right)-\mu\right]^2 \end{align} $$ I'm stuck here, however, this should come to: $$\frac{\pi}{2}\frac{1}{n}\left[\sigma^2 + \frac{2}{\pi}\sigma^2\right]$$ which converges to zero. ii) Since $\delta_1$ converges in probability to $\sigma$, and since k must be unique,  k must equal $\sqrt{\pi/2}$ b) I know this involves the Central Limit Theorem; however, I'm not able to piece the whole thing together. I know that $$E(|X_i|) = \int_{-\infty}^\infty |x|\frac{1}{\sqrt{2\pi\sigma}}\exp\left(\frac{-x}{2\sigma^2}\right)\,dx = \sqrt{\frac{2}{\pi}}\sigma$$ and $\operatorname{Var}(|X_i|) = \sigma^2 - \frac{2}{\pi}\sigma^2$ Also, $$\sqrt{n}(\delta_1 - \sigma)\xrightarrow[]{L} N\left(0,\left(\frac{\pi}{2}-1\right)\sigma^2\right)$$ Not sure how to proceed.",,"['probability', 'statistics', 'probability-theory', 'probability-distributions', 'asymptotics']"
22,Similarity between two probability distribution,Similarity between two probability distribution,,"I am not sure how to put the question. I am not even sure if this question makes sense at all. I know that the similarity of two discrete (or continuous) distributions can be quantified by Kullback–Leibler distance. However, I wonder if it makes sense to quantify the Kullback–Leibler distance between two random variables which one is discrete and the other one is continuous? Is there any probabilistic measure for quantifying the similarity of continuos distribution with a discrete one.","I am not sure how to put the question. I am not even sure if this question makes sense at all. I know that the similarity of two discrete (or continuous) distributions can be quantified by Kullback–Leibler distance. However, I wonder if it makes sense to quantify the Kullback–Leibler distance between two random variables which one is discrete and the other one is continuous? Is there any probabilistic measure for quantifying the similarity of continuos distribution with a discrete one.",,"['probability', 'probability-theory', 'probability-distributions', 'stochastic-processes', 'information-theory']"
23,Logical issues with the weak law of large numbers and its interpretation,Logical issues with the weak law of large numbers and its interpretation,,"In several probability textbooks I have found what amounts to the following argument: Let A be an event in some probabilistic experiment. Let p=P(A) be the   probability of this event occurring in n trials. Let $M$ be the   fraction of time $A$ occurs in $n$ trials: $M = \frac{X_1+...+X_n}{n}$ where $X_i$ is 1 whenever A occurs, and 0 otherwise; in particular   $E[X_i]=p$. From simple properties of expectation and variance: $E[M] = \frac{E[X_1+...+X_n]}{n} = \frac{E[X_1]+...+E[X_n]}{n} =  \frac{np}{n} = p$ $Var[M] = \frac{Var[X_1+...+X_n]}{n^2} = \frac{Var[X_1]+...+Var[X_n]}{n^2} = \frac{n\sigma^2}{n^2} = \frac{\sigma^2}{n}$ So using Chebyshev's inequality: $P(|M-p|>\epsilon) \le \frac{\sigma^2}{n\epsilon^2}$ And so: $\lim_{n \to \infty} P(|M-p|) = 0$ It is often claimed that this derivation links the mathematical theory of probability with the concept of frequency, but I think is not true and the derivation is either pointless or tautological, for consider the following: if you proceed purely from mathematical axioms, the result holds true in an abstract sense, but there is no logical reason for the particular quantities to have the interpretations we give to them intuitively, e.g. one can not interpret M as a frequency of occurrence without adding an additional axiom specifying what P(A) is, at least this is how it seems to me. On the other hand, if you choose the frequency interpretation of probability, the moment you say ""let p=P(A) be the probability of A"" the very same moment you make an assumption of  existence of a single number p that is the limit of the relative frequency of occurrence of the event A, so what amounts to placing: $\lim_{n \to \infty} P(|M-p|) = 0$ among the axioms . Ideally I would like to know what someone familiar with mathematical logic or research in foundations of mathematics where such issues are examined thinks about this, while in areas like set theory there are volumes written about issues of this kind, in probability theory, while there are plenty of philosophical books about various ways of interpreting probability, I have not found a single work on the mathematical logic of the subject, besides Kolmogorov's Grundbegriffe. My questions are the following: Is my reasoning correct? Is there any reason I miss for this derivation to be important or interesting in some sense? Are there any works that examine probability theory from the standpoint of mathematical logic, where issues of this kind are made more clear? For reference, textbooks are either very mysterious about this, or altogether avoid motivating or interpreting the result. Jim Pitman's ""Probability"", page 101 this is called a ""mathematical confirmation of our intuitive idea of probability as a limit of long-run sequences"". In Bertsekas and Tsitskilis, page 270, M is called the empirical frequency, and it is said that ""Loosely speaking, this allows us to conclude that em­pirical frequencies are faithful estimates of p. Alternatively, this is a step towards interpreting the probability p as the frequency of occurrence of A."". Mark Kac in ""Probability and related topics in the physical sciences"", page 4, writes: Actually, the theorem says disappointingly little. All it says, in   fact, is the following: If the probability of a certain event was   calculated in accordance with certain assumptions and rules, then the   probability (again calculated, according to the same assumptions and   rules) that the frequency with which the event will occur in a large   assembly of trials will differ significantly form the calculated   probability is low. In the notes for a probability theory course by Rota and Baclawski, the interpretation seems more similar to what I have written above: This is essentially just a psychological theorem, for it does not   provide the information necessary for concrete applications. The   Central Limit Theorem is far more useful and in fact the law of large   numbers is a consequence of the Central Limit Theorem. We leave the   proof as an exercise. In any case the law of large numbers is a purely mathematical theorem.   In order for it to make sense we must already have the concepts of   probability, random variables, means, variances, etc. We cannot use   this as a definition of probability. But we cannot even use the law of   large numbers as a justification of the frequentist point of view.   This point of view says that probabilities represent a physically   measurable quantity (at least in principle). But there is no concept   of a physical ""measurement"" corresponding to the mathematical concept   of the limit: lim n->inf of (X_1+...+X_n)/n The relationship between physical experiments and the theory of   probability is much more subtle than the frequentist point of view   would have one belive. Finally, Grinstead and Snell write what seems also very reasonable, but not very precise: The Law of Large Numbers, which is a theorem proved about the   mathematical model of probability, shows that this model is consistent   with the frequency interpretation of probability.","In several probability textbooks I have found what amounts to the following argument: Let A be an event in some probabilistic experiment. Let p=P(A) be the   probability of this event occurring in n trials. Let $M$ be the   fraction of time $A$ occurs in $n$ trials: $M = \frac{X_1+...+X_n}{n}$ where $X_i$ is 1 whenever A occurs, and 0 otherwise; in particular   $E[X_i]=p$. From simple properties of expectation and variance: $E[M] = \frac{E[X_1+...+X_n]}{n} = \frac{E[X_1]+...+E[X_n]}{n} =  \frac{np}{n} = p$ $Var[M] = \frac{Var[X_1+...+X_n]}{n^2} = \frac{Var[X_1]+...+Var[X_n]}{n^2} = \frac{n\sigma^2}{n^2} = \frac{\sigma^2}{n}$ So using Chebyshev's inequality: $P(|M-p|>\epsilon) \le \frac{\sigma^2}{n\epsilon^2}$ And so: $\lim_{n \to \infty} P(|M-p|) = 0$ It is often claimed that this derivation links the mathematical theory of probability with the concept of frequency, but I think is not true and the derivation is either pointless or tautological, for consider the following: if you proceed purely from mathematical axioms, the result holds true in an abstract sense, but there is no logical reason for the particular quantities to have the interpretations we give to them intuitively, e.g. one can not interpret M as a frequency of occurrence without adding an additional axiom specifying what P(A) is, at least this is how it seems to me. On the other hand, if you choose the frequency interpretation of probability, the moment you say ""let p=P(A) be the probability of A"" the very same moment you make an assumption of  existence of a single number p that is the limit of the relative frequency of occurrence of the event A, so what amounts to placing: $\lim_{n \to \infty} P(|M-p|) = 0$ among the axioms . Ideally I would like to know what someone familiar with mathematical logic or research in foundations of mathematics where such issues are examined thinks about this, while in areas like set theory there are volumes written about issues of this kind, in probability theory, while there are plenty of philosophical books about various ways of interpreting probability, I have not found a single work on the mathematical logic of the subject, besides Kolmogorov's Grundbegriffe. My questions are the following: Is my reasoning correct? Is there any reason I miss for this derivation to be important or interesting in some sense? Are there any works that examine probability theory from the standpoint of mathematical logic, where issues of this kind are made more clear? For reference, textbooks are either very mysterious about this, or altogether avoid motivating or interpreting the result. Jim Pitman's ""Probability"", page 101 this is called a ""mathematical confirmation of our intuitive idea of probability as a limit of long-run sequences"". In Bertsekas and Tsitskilis, page 270, M is called the empirical frequency, and it is said that ""Loosely speaking, this allows us to conclude that em­pirical frequencies are faithful estimates of p. Alternatively, this is a step towards interpreting the probability p as the frequency of occurrence of A."". Mark Kac in ""Probability and related topics in the physical sciences"", page 4, writes: Actually, the theorem says disappointingly little. All it says, in   fact, is the following: If the probability of a certain event was   calculated in accordance with certain assumptions and rules, then the   probability (again calculated, according to the same assumptions and   rules) that the frequency with which the event will occur in a large   assembly of trials will differ significantly form the calculated   probability is low. In the notes for a probability theory course by Rota and Baclawski, the interpretation seems more similar to what I have written above: This is essentially just a psychological theorem, for it does not   provide the information necessary for concrete applications. The   Central Limit Theorem is far more useful and in fact the law of large   numbers is a consequence of the Central Limit Theorem. We leave the   proof as an exercise. In any case the law of large numbers is a purely mathematical theorem.   In order for it to make sense we must already have the concepts of   probability, random variables, means, variances, etc. We cannot use   this as a definition of probability. But we cannot even use the law of   large numbers as a justification of the frequentist point of view.   This point of view says that probabilities represent a physically   measurable quantity (at least in principle). But there is no concept   of a physical ""measurement"" corresponding to the mathematical concept   of the limit: lim n->inf of (X_1+...+X_n)/n The relationship between physical experiments and the theory of   probability is much more subtle than the frequentist point of view   would have one belive. Finally, Grinstead and Snell write what seems also very reasonable, but not very precise: The Law of Large Numbers, which is a theorem proved about the   mathematical model of probability, shows that this model is consistent   with the frequency interpretation of probability.",,"['probability', 'probability-theory', 'logic', 'philosophy']"
24,Square of Bernoulli Random Variable,Square of Bernoulli Random Variable,,"I was wondering about the distribution of the square of a Bernoulli RV. My background in statistics is not too good, so maybe this doesn't even make sense, or it is a trivial problem. Let, $Z\sim X^2$, where $X\sim \text{Ber}(p)$. $F_Z(z)=\Pr(X^2\leq z)$ $=\Pr(-z^{1/2}\leq X\leq z^{1/2})$ $=F_X(z^{1/2})-F_X(-z^{1/2})$ At this point I'm pretty confused I mean the CDF is right-continuous while I know $Z$ is a discrete RV. $\implies P_Z(z)=\frac{ d}{dz}\{F_X(z^{1/2})-F_X(-z^{1/2})\}$ I guess you can define the derivative to be: $\frac{d}{dx}f(x)=\frac{f(x+1)-f(x)}{1}$ or something... and we have $F_X(x)=\begin{cases} 0, & \text{if }x<0 \\ 1-p, & \text{if }0\leq x\lt 1 \\ 1, & \text{if } x\geq1 \end{cases}$ Any help is appreciated (is my approach correct?)","I was wondering about the distribution of the square of a Bernoulli RV. My background in statistics is not too good, so maybe this doesn't even make sense, or it is a trivial problem. Let, $Z\sim X^2$, where $X\sim \text{Ber}(p)$. $F_Z(z)=\Pr(X^2\leq z)$ $=\Pr(-z^{1/2}\leq X\leq z^{1/2})$ $=F_X(z^{1/2})-F_X(-z^{1/2})$ At this point I'm pretty confused I mean the CDF is right-continuous while I know $Z$ is a discrete RV. $\implies P_Z(z)=\frac{ d}{dz}\{F_X(z^{1/2})-F_X(-z^{1/2})\}$ I guess you can define the derivative to be: $\frac{d}{dx}f(x)=\frac{f(x+1)-f(x)}{1}$ or something... and we have $F_X(x)=\begin{cases} 0, & \text{if }x<0 \\ 1-p, & \text{if }0\leq x\lt 1 \\ 1, & \text{if } x\geq1 \end{cases}$ Any help is appreciated (is my approach correct?)",,"['probability', 'statistics']"
25,Quantile function continuity,Quantile function continuity,,"Given an increasing, right continuous function $$F:\mathbb{R} \rightarrow [0,1]$$ such that $\lim_{x\rightarrow \infty} F(x)=1  $ and $\lim_{x\rightarrow -\infty} F(x)=0$ then we can define $G:(0,1)\rightarrow \mathbb{R}$ $$G(y)= \inf\{x : F(x)\geq y\}$$ I could show that $G$ is increasing and that $F(x) \geq y$ is equivalent to $x \geq G(y)$. How can I prove that G is also left-continuous? Any help would be appreciated!","Given an increasing, right continuous function $$F:\mathbb{R} \rightarrow [0,1]$$ such that $\lim_{x\rightarrow \infty} F(x)=1  $ and $\lim_{x\rightarrow -\infty} F(x)=0$ then we can define $G:(0,1)\rightarrow \mathbb{R}$ $$G(y)= \inf\{x : F(x)\geq y\}$$ I could show that $G$ is increasing and that $F(x) \geq y$ is equivalent to $x \geq G(y)$. How can I prove that G is also left-continuous? Any help would be appreciated!",,"['probability', 'probability-theory']"
26,A fair 6 sided dice is rolled 4 times. What is the probability that at least 3 of the numbers will be either 1 or 6?,A fair 6 sided dice is rolled 4 times. What is the probability that at least 3 of the numbers will be either 1 or 6?,,I'd really love a sanity check here as I walk through what I believe is the solution. Total possible outcomes = $6^4 = 1296$ Possible combinations of 3 rolls being either 1 or 6 = $({}_4C_3)\cdot2 = (4)\cdot2 = 8$ Also take into account all 1's and all 6's = $1 + 1 = 2$ Answer = $\frac{8+2}{ 1296} = \frac{10}{1296} = \mathbf{\frac{5}{648}} $ Really appreciate the help! :),I'd really love a sanity check here as I walk through what I believe is the solution. Total possible outcomes = $6^4 = 1296$ Possible combinations of 3 rolls being either 1 or 6 = $({}_4C_3)\cdot2 = (4)\cdot2 = 8$ Also take into account all 1's and all 6's = $1 + 1 = 2$ Answer = $\frac{8+2}{ 1296} = \frac{10}{1296} = \mathbf{\frac{5}{648}} $ Really appreciate the help! :),,"['probability', 'combinatorics']"
27,Example of a random process which is strictly stationary but not iid,Example of a random process which is strictly stationary but not iid,,I understand $IID\subseteq SSS\subseteq WSS$. What could be an example of a stochastic process which is not iid but is strict sense stationary? I will appreciate examples for $SSS\setminus IID$ and $WSS\setminus SSS$...,I understand $IID\subseteq SSS\subseteq WSS$. What could be an example of a stochastic process which is not iid but is strict sense stationary? I will appreciate examples for $SSS\setminus IID$ and $WSS\setminus SSS$...,,"['probability', 'stochastic-processes']"
28,Pinsker $\sigma$-Algebra,Pinsker -Algebra,\sigma,"Let $(X,A,\nu)$ be a probability space and $T:X\to X$ a measure-preserving transformation. The Pinsker $\sigma$ -algebra is defined as the lower sigma algebra that contains all partition P of measurable sets such that $h(T,P)=0$ ( entropy of T with respect to P ). How can one calculate the Pinsker $\sigma$ -algebra of the Bernoulli shift $\left(\dfrac{1}{2},\dfrac{1}{2}\right)$ ? I think that the Pinsker $\sigma$ -algebra is the $\sigma$ -algebra of all measurable sets of measure $0$ or $1$ . And another question: Why is  the Pinsker $\sigma$ -algebra important in ergodic theory?",Let be a probability space and a measure-preserving transformation. The Pinsker -algebra is defined as the lower sigma algebra that contains all partition P of measurable sets such that ( entropy of T with respect to P ). How can one calculate the Pinsker -algebra of the Bernoulli shift ? I think that the Pinsker -algebra is the -algebra of all measurable sets of measure or . And another question: Why is  the Pinsker -algebra important in ergodic theory?,"(X,A,\nu) T:X\to X \sigma h(T,P)=0 \sigma \left(\dfrac{1}{2},\dfrac{1}{2}\right) \sigma \sigma 0 1 \sigma",['probability']
29,probability of A dice with X faces beating B dice with Y faces,probability of A dice with X faces beating B dice with Y faces,,"I am looking for a formula to determine the probability of a A Die with X faces rolling higher than B die with Y faces. An example would be: what is the probability of 4d10 rolling greater than 3d12 Edit: I thought the last edit summary would pop up but it didnt, so added here. Corrected the question a bit and added example. Edit #2: I had come up with a similar conclusion for percentages (x-1/2y) in a case of dx vs dy But I didnt took into account the difference on whether ""x"" was larger or smaller than ""y"". However what about when there is more than one dice of the same type is it still the same formula? considering the sum is a bit more irregular since some numbers repeat more often than others do I replace ""x"" and ""y"" with the total sum of possible outcomes of each die combination? (in xda I assume the total is a^x)","I am looking for a formula to determine the probability of a A Die with X faces rolling higher than B die with Y faces. An example would be: what is the probability of 4d10 rolling greater than 3d12 Edit: I thought the last edit summary would pop up but it didnt, so added here. Corrected the question a bit and added example. Edit #2: I had come up with a similar conclusion for percentages (x-1/2y) in a case of dx vs dy But I didnt took into account the difference on whether ""x"" was larger or smaller than ""y"". However what about when there is more than one dice of the same type is it still the same formula? considering the sum is a bit more irregular since some numbers repeat more often than others do I replace ""x"" and ""y"" with the total sum of possible outcomes of each die combination? (in xda I assume the total is a^x)",,"['probability', 'dice']"
30,What's the probability of tossing $r$ heads in a row before $s$ tails in a row?,What's the probability of tossing  heads in a row before  tails in a row?,r s,"I know that the probability of tossing $r$ heads in a row is eventually $1$, but how about tossing $r$ heads in a row before $s$ tails in a row? What's the easiest way to compute this probability? And what if the coin is biased, say, with probability $p$ showing a head?","I know that the probability of tossing $r$ heads in a row is eventually $1$, but how about tossing $r$ heads in a row before $s$ tails in a row? What's the easiest way to compute this probability? And what if the coin is biased, say, with probability $p$ showing a head?",,"['probability', 'combinatorics', 'discrete-mathematics']"
31,Cauchy-Schwarz matrix inequality for random vectors,Cauchy-Schwarz matrix inequality for random vectors,,"If $X$ and $Y$ are random scalars, then Cauchy-Schwarz says that $$| \mathrm{Cov}(X,Y) | \le \mathrm{Var}(X)^{1/2}\mathrm{Var}(Y)^{1/2}.$$ If $X$ and $Y$ are random vectors, is there a way to bound the covariance matrix $\mathrm{Cov}(X,Y)$ in terms of the matrices $\mathrm{Var}(X)$ and $\mathrm{Var}(Y)$? In particular, is it true that $$\mathrm{Cov}(X,Y) \le \mathrm{Var}(X)^{1/2}\mathrm{Var}(Y)^{1/2},$$ where the square roots are Cholesky decompositions, and the inequality is read as meaning that the right hand side minus the left hand side is positive semidefinite?","If $X$ and $Y$ are random scalars, then Cauchy-Schwarz says that $$| \mathrm{Cov}(X,Y) | \le \mathrm{Var}(X)^{1/2}\mathrm{Var}(Y)^{1/2}.$$ If $X$ and $Y$ are random vectors, is there a way to bound the covariance matrix $\mathrm{Cov}(X,Y)$ in terms of the matrices $\mathrm{Var}(X)$ and $\mathrm{Var}(Y)$? In particular, is it true that $$\mathrm{Cov}(X,Y) \le \mathrm{Var}(X)^{1/2}\mathrm{Var}(Y)^{1/2},$$ where the square roots are Cholesky decompositions, and the inequality is read as meaning that the right hand side minus the left hand side is positive semidefinite?",,"['probability', 'matrices', 'statistics', 'inequality']"
32,Distribution of maximum of partial sums of independent random variables,Distribution of maximum of partial sums of independent random variables,,"I have been looking all over the net to find a way to work out a probability distribution of a maximum of partial sums of independent random variables, but to no avail. So I have decided to try to work it out for myself. Here are the results of this endeavour and I would appreciate if people with better understanding of probability than me would give it a look over to see if I’ve made a mess of it somewhere. Many thanks.  Here it goes. Given a set $\{X_i:i=0,1,\ldots,n \}$ of independent random variables with $X_0 = 0$ and with given p.d.f.'s $f_{X_i}(x)$ and corresponding c.d.f's $F_{X_i}(x)$, define $S_k=\Sigma_{i=0}^k\,X_i$, and $M_k=\max\{S_0,S_1,\ldots,S_k \}$, and we want to find a distrinution of $M_n$. We have $$ \begin{eqnarray*} P(M_n<m)&=&P(\max\{M_{n-1},S_n\}<m)\\ &=&P(M_{n-1}<m,S_n<m)\\ &=&P(S_n<m|M_{n-1}<m)P(M_{n-1}<m),\\ \end{eqnarray*} $$ where $$ \begin{eqnarray*} P(S_n<m|M_{n-1}<m) &=&P(S_n<m|\max\{M_{n-2},S_{n-1}\}<m)\\ &=&P(S_n<m|S_{n-1}<m)\\ &=&P(S_n<m,S_{n-1}<m)/P(S_{n-1}<m), \end{eqnarray*} $$ where $$ \begin{eqnarray*} P(S_n<m,S_{n-1}<m) &=&P(S_{n-1}+X_n<m,S_{n-1}<m)\\ &=&\int\limits_{-\infty}^m f_{S_{n-1}}(s)\int\limits_{-\infty}^{m-s}f_{X_n}(x)\mathrm dx\,\mathrm ds\\ &=&\int\limits_{-\infty}^m f_{S_{n-1}}(s)F_{X_n}(m-s)\mathrm ds, \end{eqnarray*} $$ where $$ \begin{eqnarray*} f_{S_k}(s)&=&\int\limits_{-\infty}^{\infty} f_{X_k}(x)\,f_{S_{k-1}}(s-x)\mathrm dx, \end{eqnarray*} $$ with $$ \begin{eqnarray*} f_{S_0}(s)=\delta (s), \end{eqnarray*} $$ so that putting it all together gives a recursion formula $$ \begin{eqnarray*} F_{M_n}(m) = \frac{F_{M_{n-1}}(m)}{F_{S_{n-1}}(m)} \int\limits_{-\infty}^m f_{S_{n-1}}(s)F_{X_n}(m-s)\mathrm ds \end{eqnarray*} $$ with $$ \begin{eqnarray*} F_{M_0}(m) = H(m) \end{eqnarray*} $$ the Heaviside step function. Added 1: Using another approach, I have obtained the following result $$ f_{M_n}(m) = f_{M_{n-1}}(m)F_{X_n}(0) + \int\limits_0^m f_{X_n}(m-x)f_{M_{n-1}}(x)\mathrm dx $$ which for 2 normal r.v. seems to give a result that agrees with the one put forward in one of the answers by Sasha. Added 2: Finally I got some free time to look at this problem again and here are my thought on it.  Once again, I would appreciate any comments on it. We begin by considering a joint distribution of $f_{S_1,S_2}(s_1,s_2)$ where $S_1 = X_1$,  $S_2 = S_1 + X_2$, $X_1 \sim X_2 \sim X$, and $X_1$ and $X_2$ are independent. We have $$ f_{S_1,S_2}(s_1,s_2) = f_{S_2 \mid S_1}(s_2 \mid s_1)f_{S_1}(s_1) = f_{X_2}(s_2 - s_1)f_{X_1}(s_1) = f_{X}(s_2 - s_1)f_{X}(s_1) $$ Next, we have $ \begin{eqnarray*} F_{M_n}(m)&=&P(M_n<m)\\ &=&P(\max\{S_{n},S_{n-1},...,S_1\}<m)\\ &=&P(S_{n}<m,S_{n-1}<m,...,S_1<m)\\  &=&\int\limits_{-\infty}^m ... \int\limits_{-\infty}^m f_{S_n,S_{n-1},...,S_1}(s_n,s_{n-1},...,s_1)\mathrm ds_n \mathrm ds_{n-1} ... \mathrm ds_1 \\  &=&\int\limits_{-\infty}^m ... \int\limits_{-\infty}^m  f_{S_n \mid S_{n-1},...,S_1}(s_n \mid s_{n-1},...,s_1)... f_{S_2 \mid S_1}(s_2 \mid s_1)f_{S_1}(s_1) \mathrm ds_n \mathrm ds_{n-1} ... \mathrm ds_1 \\  &=&\int\limits_{-\infty}^m ... \int\limits_{-\infty}^m  f_{S_n \mid S_{n-1}}(s_n \mid s_{n-1})... f_{S_2 \mid S_1}(s_2 \mid s_1)f_{S_1}(s_1) \mathrm ds_n \mathrm ds_{n-1} ... \mathrm ds_1 \\  &=&\int\limits_{-\infty}^m ... \int\limits_{-\infty}^m  f_X(s_n - s_{n-1})... f_X(s_2 - s_1)f_X(s_1) \mathrm ds_n \mathrm ds_{n-1} ... \mathrm ds_1 \\  &=& \prod_{i=1}^n \int\limits_{-\infty}^m f_X(s_i - s_{i-1}) \mathrm ds_i \end{eqnarray*} $$ where $s_0 \equiv 0$. I hope the above notation is clear enough. Now $$ \begin{eqnarray*} F_{M_n}(m) = \mathbb E[\mathbb I_{ M_n \leq m}] = \prod_{i=1}^n \int\limits_{-\infty}^{-\infty} f_X(s_i - s_{i-1}) \mathbb I_{s_i \leq m} \mathrm ds_i. \end{eqnarray*} $$ The characteristic function $\varphi_{M_n}(t) = \mathbb E[\mathbb e^{i t M_n}]$ is then $$ \begin{eqnarray*} \varphi_{M_n}(t) = \prod_{i=1}^n \int\limits_{-\infty}^{-\infty} f_X(s_i - s_{i-1}) \mathbb e^{i t s_i} \mathrm ds_i \end{eqnarray*} $$","I have been looking all over the net to find a way to work out a probability distribution of a maximum of partial sums of independent random variables, but to no avail. So I have decided to try to work it out for myself. Here are the results of this endeavour and I would appreciate if people with better understanding of probability than me would give it a look over to see if I’ve made a mess of it somewhere. Many thanks.  Here it goes. Given a set $\{X_i:i=0,1,\ldots,n \}$ of independent random variables with $X_0 = 0$ and with given p.d.f.'s $f_{X_i}(x)$ and corresponding c.d.f's $F_{X_i}(x)$, define $S_k=\Sigma_{i=0}^k\,X_i$, and $M_k=\max\{S_0,S_1,\ldots,S_k \}$, and we want to find a distrinution of $M_n$. We have $$ \begin{eqnarray*} P(M_n<m)&=&P(\max\{M_{n-1},S_n\}<m)\\ &=&P(M_{n-1}<m,S_n<m)\\ &=&P(S_n<m|M_{n-1}<m)P(M_{n-1}<m),\\ \end{eqnarray*} $$ where $$ \begin{eqnarray*} P(S_n<m|M_{n-1}<m) &=&P(S_n<m|\max\{M_{n-2},S_{n-1}\}<m)\\ &=&P(S_n<m|S_{n-1}<m)\\ &=&P(S_n<m,S_{n-1}<m)/P(S_{n-1}<m), \end{eqnarray*} $$ where $$ \begin{eqnarray*} P(S_n<m,S_{n-1}<m) &=&P(S_{n-1}+X_n<m,S_{n-1}<m)\\ &=&\int\limits_{-\infty}^m f_{S_{n-1}}(s)\int\limits_{-\infty}^{m-s}f_{X_n}(x)\mathrm dx\,\mathrm ds\\ &=&\int\limits_{-\infty}^m f_{S_{n-1}}(s)F_{X_n}(m-s)\mathrm ds, \end{eqnarray*} $$ where $$ \begin{eqnarray*} f_{S_k}(s)&=&\int\limits_{-\infty}^{\infty} f_{X_k}(x)\,f_{S_{k-1}}(s-x)\mathrm dx, \end{eqnarray*} $$ with $$ \begin{eqnarray*} f_{S_0}(s)=\delta (s), \end{eqnarray*} $$ so that putting it all together gives a recursion formula $$ \begin{eqnarray*} F_{M_n}(m) = \frac{F_{M_{n-1}}(m)}{F_{S_{n-1}}(m)} \int\limits_{-\infty}^m f_{S_{n-1}}(s)F_{X_n}(m-s)\mathrm ds \end{eqnarray*} $$ with $$ \begin{eqnarray*} F_{M_0}(m) = H(m) \end{eqnarray*} $$ the Heaviside step function. Added 1: Using another approach, I have obtained the following result $$ f_{M_n}(m) = f_{M_{n-1}}(m)F_{X_n}(0) + \int\limits_0^m f_{X_n}(m-x)f_{M_{n-1}}(x)\mathrm dx $$ which for 2 normal r.v. seems to give a result that agrees with the one put forward in one of the answers by Sasha. Added 2: Finally I got some free time to look at this problem again and here are my thought on it.  Once again, I would appreciate any comments on it. We begin by considering a joint distribution of $f_{S_1,S_2}(s_1,s_2)$ where $S_1 = X_1$,  $S_2 = S_1 + X_2$, $X_1 \sim X_2 \sim X$, and $X_1$ and $X_2$ are independent. We have $$ f_{S_1,S_2}(s_1,s_2) = f_{S_2 \mid S_1}(s_2 \mid s_1)f_{S_1}(s_1) = f_{X_2}(s_2 - s_1)f_{X_1}(s_1) = f_{X}(s_2 - s_1)f_{X}(s_1) $$ Next, we have $ \begin{eqnarray*} F_{M_n}(m)&=&P(M_n<m)\\ &=&P(\max\{S_{n},S_{n-1},...,S_1\}<m)\\ &=&P(S_{n}<m,S_{n-1}<m,...,S_1<m)\\  &=&\int\limits_{-\infty}^m ... \int\limits_{-\infty}^m f_{S_n,S_{n-1},...,S_1}(s_n,s_{n-1},...,s_1)\mathrm ds_n \mathrm ds_{n-1} ... \mathrm ds_1 \\  &=&\int\limits_{-\infty}^m ... \int\limits_{-\infty}^m  f_{S_n \mid S_{n-1},...,S_1}(s_n \mid s_{n-1},...,s_1)... f_{S_2 \mid S_1}(s_2 \mid s_1)f_{S_1}(s_1) \mathrm ds_n \mathrm ds_{n-1} ... \mathrm ds_1 \\  &=&\int\limits_{-\infty}^m ... \int\limits_{-\infty}^m  f_{S_n \mid S_{n-1}}(s_n \mid s_{n-1})... f_{S_2 \mid S_1}(s_2 \mid s_1)f_{S_1}(s_1) \mathrm ds_n \mathrm ds_{n-1} ... \mathrm ds_1 \\  &=&\int\limits_{-\infty}^m ... \int\limits_{-\infty}^m  f_X(s_n - s_{n-1})... f_X(s_2 - s_1)f_X(s_1) \mathrm ds_n \mathrm ds_{n-1} ... \mathrm ds_1 \\  &=& \prod_{i=1}^n \int\limits_{-\infty}^m f_X(s_i - s_{i-1}) \mathrm ds_i \end{eqnarray*} $$ where $s_0 \equiv 0$. I hope the above notation is clear enough. Now $$ \begin{eqnarray*} F_{M_n}(m) = \mathbb E[\mathbb I_{ M_n \leq m}] = \prod_{i=1}^n \int\limits_{-\infty}^{-\infty} f_X(s_i - s_{i-1}) \mathbb I_{s_i \leq m} \mathrm ds_i. \end{eqnarray*} $$ The characteristic function $\varphi_{M_n}(t) = \mathbb E[\mathbb e^{i t M_n}]$ is then $$ \begin{eqnarray*} \varphi_{M_n}(t) = \prod_{i=1}^n \int\limits_{-\infty}^{-\infty} f_X(s_i - s_{i-1}) \mathbb e^{i t s_i} \mathrm ds_i \end{eqnarray*} $$",,"['probability', 'probability-distributions']"
33,"The Expected Value of ""Descending Dice Problem"" and Harmonic Numbers","The Expected Value of ""Descending Dice Problem"" and Harmonic Numbers",,"I named the ""Descending Dice Problem"", but not sure if there is another name to it. This is how it goes: You start with a N sided dice. Throw it, suppose you rolled R as your result, and then throw another dice with R sides. Continue this process until you get a 1. You only roll one dice at a time. Once you rolled a dice and got a number different from 1 you forget about this dice and then only focus on the next one. What is the expected value of dice rolls until I get a 1 if I started with a N sided dice? I searched just for the problem's description and find nothing. Even less about its solution. After some days of thinking I got the exact result for the $N = 2, 3, 4$ cases and started looking for patterns. It seems that the solution is: $E(Dice(n)) = 1 + H(n-1)$ Where $H(n)$ is the n-th Harmonic Number . After checking with some python code the results were pretty much exact. Can you help me prove that this is actually the formula?","I named the ""Descending Dice Problem"", but not sure if there is another name to it. This is how it goes: You start with a N sided dice. Throw it, suppose you rolled R as your result, and then throw another dice with R sides. Continue this process until you get a 1. You only roll one dice at a time. Once you rolled a dice and got a number different from 1 you forget about this dice and then only focus on the next one. What is the expected value of dice rolls until I get a 1 if I started with a N sided dice? I searched just for the problem's description and find nothing. Even less about its solution. After some days of thinking I got the exact result for the cases and started looking for patterns. It seems that the solution is: Where is the n-th Harmonic Number . After checking with some python code the results were pretty much exact. Can you help me prove that this is actually the formula?","N = 2, 3, 4 E(Dice(n)) = 1 + H(n-1) H(n)","['probability', 'expected-value', 'dice', 'harmonic-numbers']"
34,How to get the distribution of a random variable from the distribution of their summation?,How to get the distribution of a random variable from the distribution of their summation?,,"Let ${\textstyle \{X_{1},\ldots ,X_{n}}\}$ be a sequence of independent and identical random variables. The distribution of $X_n$ is unknown. Assuming that we know the distribution of the following summation: $${S}\equiv \sum_{n=1}^{\infty}\frac{X_n}{n^2}$$ Would it be possible to find the distribution of $X_n$ from $S$ ?",Let be a sequence of independent and identical random variables. The distribution of is unknown. Assuming that we know the distribution of the following summation: Would it be possible to find the distribution of from ?,"{\textstyle \{X_{1},\ldots ,X_{n}}\} X_n {S}\equiv \sum_{n=1}^{\infty}\frac{X_n}{n^2} X_n S","['probability', 'probability-distributions', 'random-variables', 'central-limit-theorem']"
35,"Why is $E[X|X+Y] = E[Y |X+Y]$ if X,Y are i.i.d random variables","Why is  if X,Y are i.i.d random variables",E[X|X+Y] = E[Y |X+Y],"In proof of the fact that $E[X|X+Y] = \frac{X+Y}{2}$ when $X,Y$ are independent, identically distributed random variables, one uses the observation that $E[X|X+Y] = E[Y|X+Y]$ but I don't see why this is the case. Is there an easy proof of this statement?","In proof of the fact that when are independent, identically distributed random variables, one uses the observation that but I don't see why this is the case. Is there an easy proof of this statement?","E[X|X+Y] = \frac{X+Y}{2} X,Y E[X|X+Y] = E[Y|X+Y]","['probability', 'probability-theory', 'random-variables', 'lebesgue-integral', 'conditional-expectation']"
36,Probability of more than ${3\over 4}N$ heads in $N$ flips of a coin?,Probability of more than  heads in  flips of a coin?,{3\over 4}N N,What is the probability of getting more than $ \frac { 3 N } 4 $ heads in $ N $ flips of coins? I know we need to use binomial distribution formula for this and sum it from $ N = \frac { 3 N } 4 $ to $ N $ . I can solve this when numbers are given but I'm struggling to solve because a general case is given. Any help appreciated.,What is the probability of getting more than heads in flips of coins? I know we need to use binomial distribution formula for this and sum it from to . I can solve this when numbers are given but I'm struggling to solve because a general case is given. Any help appreciated., \frac { 3 N } 4   N   N = \frac { 3 N } 4   N ,"['probability', 'binomial-distribution', 'distribution-tails']"
37,Is the posterior always a compromise between the prior and the data?,Is the posterior always a compromise between the prior and the data?,,"Suppose that we are interested in learning the proportion of the population $\theta$ with a particular property (for instance, the fraction of the population who are male). Suppose that we randomly sample $n$ members of this population (with replacement, to make things easier) and observe that $y$ of them have the property (so the fraction of the sample with the property is $y/n$ ). We start with a continuous prior $p(\theta)$ with full support $[0, 1]$ and update this using Bayes rule. Question: does the expected value of the posterior always lie between the prior expectation and the sample fraction $y/n$ ? Comments : I know this is true in the case where my prior takes the form of a beta distribution (with parameters $\alpha$ , $\beta$ ). In that case, we know that the prior expectation is $$ \mathbb{E}[\theta] = \frac{\alpha}{\alpha + \beta} $$ Due to random sampling, the probability that $y$ of the $n$ draws have the property is $$ P(\text{data}\mid\theta) = \binom{n}{y} \theta^y (1 - \theta)^{n-y} $$ which means (see, e.g., here ) that the posterior $P(\theta\mid\text{data})$ is also beta distributed and has expected value $$ \mathbb{E}[\theta\mid\text{data}] = \frac{\alpha + y}{\alpha + \beta + n} $$ Moreover, it can be shown that $$ \frac{\alpha + y}{\alpha + \beta + n} \in \left[\frac{y}{n}, \frac{\alpha}{\alpha + \beta}\right] $$ where both inequalities are strict provided that $y/n \neq \alpha / (\alpha+\beta)$ . So the posterior expectation does indeed lie between the prior expectation and the sample fraction in this instance. To now examine the more general case, consider an arbitrary smooth prior $p(\theta)$ with full support on $[0, 1]$ and expected value $\mathbb{E[\theta]}$ . By Bayes theorem, the posterior is \begin{split} p(\theta\mid\text{data}) &= \frac{p(\text{data}\mid\theta)P(\theta)}{P(\text{data})} \\ &= \frac{\binom{n}{y} \theta^y (1 - \theta)^{n-y}P(\theta)}{\int_0^1 P(\text{data}\mid\theta)P(\theta) d\theta}  \\ &= \frac{\binom{n}{y} \theta^y (1 - \theta)^{n-y}P(\theta)}{\int_0^1 \binom{n}{y} \theta^y (1 - \theta)^{n-y}P(\theta) \, d\theta} \\ &= \frac{\theta^y (1 - \theta)^{n-y}P(\theta)}{\int_0^1 \theta^y (1 - \theta)^{n-y}P(\theta) \, d\theta}  \end{split} and so the posterior expectation is \begin{split} \mathbb{E[\theta}\mid\text{data}] &= \int_0^1 p(\theta\mid\text{data}) \theta \, d\theta \\ &= \int_0^1 \frac{\theta^y (1 - \theta)^{n-y}P(\theta)}{\int_0^1 \theta^y (1 - \theta)^{n-y}P(\theta) \, d\theta}  \theta \, d\theta \\ &= \frac{\int_0^1  \theta^y (1 - \theta)^{n-y}P(\theta) \theta \, d\theta}{\int_0^1 \theta^y (1 - \theta)^{n-y}P(\theta) \, d\theta}   \\ &= \frac{\mathbb{E}[\theta^{y+1} (1 - \theta)^{n-y}]}{\mathbb{E}[\theta^y (1 - \theta)^{n-y}]} \end{split} It remains to show that $$ \frac{\mathbb{E}[\theta^{y+1} (1 - \theta)^{n-y}]}{\mathbb{E}[\theta^y (1 - \theta)^{n-y}]} \in \left[ \mathbb{E}[\theta], \frac{y}{n} \right]; $$ but this is where things begin to get tricky. Very heuristically (apologies for what is to come!), one might try to obtain one bound using an argument like \begin{split} \frac{\mathbb{E}[\theta^{y+1} (1 - \theta)^{n-y}]}{\mathbb{E}[\theta^y (1 - \theta)^{n-y}]} &\geq \frac{\mathbb{E}[\theta^{y+1}] \mathbb{E}[(1 - \theta)^{n-y}]}{\mathbb{E}[\theta^y] \mathbb{E}[(1 - \theta)^{n-y}]} \\ &\geq \frac{\mathbb{E}[\theta]^{y+1} \mathbb{E}[(1 - \theta)]^{n-y}}{\mathbb{E}[\theta]^y \mathbb{E}[(1 - \theta)]^{n-y}} \\ &=  \mathbb{E}[\theta] \end{split} ...although, quite aside from the very dubious feel to this argument, it doesn't give us the $y/n$ bound. Any help would be much appreciated!","Suppose that we are interested in learning the proportion of the population with a particular property (for instance, the fraction of the population who are male). Suppose that we randomly sample members of this population (with replacement, to make things easier) and observe that of them have the property (so the fraction of the sample with the property is ). We start with a continuous prior with full support and update this using Bayes rule. Question: does the expected value of the posterior always lie between the prior expectation and the sample fraction ? Comments : I know this is true in the case where my prior takes the form of a beta distribution (with parameters , ). In that case, we know that the prior expectation is Due to random sampling, the probability that of the draws have the property is which means (see, e.g., here ) that the posterior is also beta distributed and has expected value Moreover, it can be shown that where both inequalities are strict provided that . So the posterior expectation does indeed lie between the prior expectation and the sample fraction in this instance. To now examine the more general case, consider an arbitrary smooth prior with full support on and expected value . By Bayes theorem, the posterior is and so the posterior expectation is It remains to show that but this is where things begin to get tricky. Very heuristically (apologies for what is to come!), one might try to obtain one bound using an argument like ...although, quite aside from the very dubious feel to this argument, it doesn't give us the bound. Any help would be much appreciated!","\theta n y y/n p(\theta) [0, 1] y/n \alpha \beta 
\mathbb{E}[\theta] = \frac{\alpha}{\alpha + \beta}
 y n 
P(\text{data}\mid\theta) = \binom{n}{y} \theta^y (1 - \theta)^{n-y}
 P(\theta\mid\text{data}) 
\mathbb{E}[\theta\mid\text{data}] = \frac{\alpha + y}{\alpha + \beta + n}
 
\frac{\alpha + y}{\alpha + \beta + n} \in \left[\frac{y}{n}, \frac{\alpha}{\alpha + \beta}\right]
 y/n \neq \alpha / (\alpha+\beta) p(\theta) [0, 1] \mathbb{E[\theta]} \begin{split}
p(\theta\mid\text{data}) &= \frac{p(\text{data}\mid\theta)P(\theta)}{P(\text{data})} \\
&= \frac{\binom{n}{y} \theta^y (1 - \theta)^{n-y}P(\theta)}{\int_0^1 P(\text{data}\mid\theta)P(\theta) d\theta}  \\
&= \frac{\binom{n}{y} \theta^y (1 - \theta)^{n-y}P(\theta)}{\int_0^1 \binom{n}{y} \theta^y (1 - \theta)^{n-y}P(\theta) \, d\theta} \\
&= \frac{\theta^y (1 - \theta)^{n-y}P(\theta)}{\int_0^1 \theta^y (1 - \theta)^{n-y}P(\theta) \, d\theta} 
\end{split} \begin{split}
\mathbb{E[\theta}\mid\text{data}] &= \int_0^1 p(\theta\mid\text{data}) \theta \, d\theta \\
&= \int_0^1 \frac{\theta^y (1 - \theta)^{n-y}P(\theta)}{\int_0^1 \theta^y (1 - \theta)^{n-y}P(\theta) \, d\theta}  \theta \, d\theta \\
&= \frac{\int_0^1  \theta^y (1 - \theta)^{n-y}P(\theta) \theta \, d\theta}{\int_0^1 \theta^y (1 - \theta)^{n-y}P(\theta) \, d\theta}   \\
&= \frac{\mathbb{E}[\theta^{y+1} (1 - \theta)^{n-y}]}{\mathbb{E}[\theta^y (1 - \theta)^{n-y}]}
\end{split} 
\frac{\mathbb{E}[\theta^{y+1} (1 - \theta)^{n-y}]}{\mathbb{E}[\theta^y (1 - \theta)^{n-y}]} \in \left[ \mathbb{E}[\theta], \frac{y}{n} \right];
 \begin{split}
\frac{\mathbb{E}[\theta^{y+1} (1 - \theta)^{n-y}]}{\mathbb{E}[\theta^y (1 - \theta)^{n-y}]} &\geq
\frac{\mathbb{E}[\theta^{y+1}] \mathbb{E}[(1 - \theta)^{n-y}]}{\mathbb{E}[\theta^y] \mathbb{E}[(1 - \theta)^{n-y}]} \\ &\geq
\frac{\mathbb{E}[\theta]^{y+1} \mathbb{E}[(1 - \theta)]^{n-y}}{\mathbb{E}[\theta]^y \mathbb{E}[(1 - \theta)]^{n-y}} \\ &= 
\mathbb{E}[\theta]
\end{split} y/n","['probability', 'bayes-theorem']"
38,Give a counterexample of the compactness property,Give a counterexample of the compactness property,,"I want to refute that if $\Omega$ is complete metric space, $F$ is Borel $\sigma$ -algebra $\Omega$ , then for any positive $\varepsilon$ there is a compact set $K$ such that $\mathbb{P}(K)>1−\varepsilon$ . I know that for this limitation to be true, I need need separability of $\Omega$ or at least separable support of $\mathbb P$ . Therefore, I need to give a counterexample, but unfortunately I cannot come up with one. I would be very grateful for help","I want to refute that if is complete metric space, is Borel -algebra , then for any positive there is a compact set such that . I know that for this limitation to be true, I need need separability of or at least separable support of . Therefore, I need to give a counterexample, but unfortunately I cannot come up with one. I would be very grateful for help",\Omega F \sigma \Omega \varepsilon K \mathbb{P}(K)>1−\varepsilon \Omega \mathbb P,"['probability', 'probability-theory']"
39,Which threshold maximizes the expected size of the final sample?,Which threshold maximizes the expected size of the final sample?,,"For $c>0$ , sample repeatedly and independently from $(0, 1)$ until the sum of the samples exceeds $c$ . Let $\mu_c$ be the expected size of the final sample. For which $c$ is $\mu_c$ maximised? It is clear that as $c$ tends to $0$ , $\mu_c$ tends to $\frac{1}{2}$ and this is its minimum value.","For , sample repeatedly and independently from until the sum of the samples exceeds . Let be the expected size of the final sample. For which is maximised? It is clear that as tends to , tends to and this is its minimum value.","c>0 (0, 1) c \mu_c c \mu_c c 0 \mu_c \frac{1}{2}",[]
40,Expected value of the number of bills,Expected value of the number of bills,,"Every day I put 1 or 2 dollars in the piggy bank with probability $1/2$ .  What's is expected value number of 2-dollar bills when in the piggy bank will be for the first time at least 100 dollars ? I know what is going on. Let $X$ - number of 2-dollar bills. 1) $X=1$ : 1 dollar - 98 bills and 2 dollars - 1 bill or 1 dollar - 99 bills and 2-dollars - 1 bill 2) $X=2$ 1 dollar - 96 bills and 2 dollars - 2 bills or 1 dollar - 97 bills and 2 dollars - 2 bills etc. Unfortunately, I can't think of a quick way.","Every day I put 1 or 2 dollars in the piggy bank with probability .  What's is expected value number of 2-dollar bills when in the piggy bank will be for the first time at least 100 dollars ? I know what is going on. Let - number of 2-dollar bills. 1) : 1 dollar - 98 bills and 2 dollars - 1 bill or 1 dollar - 99 bills and 2-dollars - 1 bill 2) 1 dollar - 96 bills and 2 dollars - 2 bills or 1 dollar - 97 bills and 2 dollars - 2 bills etc. Unfortunately, I can't think of a quick way.",1/2 X X=1 X=2,"['probability', 'expected-value']"
41,Probability - Brick in box,Probability - Brick in box,,"From the set {1, 2, 3, ... 999}, 6 distinct numbers are chosen. These are divided into two groups $a_1,a_2,a_3$ and $b_1,b_2,b_3$ . Find the probability that a brick made from the dimensions of group $a$ fits into a box made from the dimensions of $b$ . Assume that the brick can be rotated in a suitable manner to be made to fit inside the box I am able to comprehend this question and what it asks. However, I don't have a strategy in place to solve this question. The solution provided has the following to say: without loss of generality, we can say that out of the 20 possible cases, 5 are suitable. Therefore, the probability is $\frac 1 4$ . What are the twenty possible cases here? How can we set conditions on $a$ and $b$ such that we can obtain these cases? The ability to rotate the brick before placing in the box has confused me. Any help would be appreciated!","From the set {1, 2, 3, ... 999}, 6 distinct numbers are chosen. These are divided into two groups and . Find the probability that a brick made from the dimensions of group fits into a box made from the dimensions of . Assume that the brick can be rotated in a suitable manner to be made to fit inside the box I am able to comprehend this question and what it asks. However, I don't have a strategy in place to solve this question. The solution provided has the following to say: without loss of generality, we can say that out of the 20 possible cases, 5 are suitable. Therefore, the probability is . What are the twenty possible cases here? How can we set conditions on and such that we can obtain these cases? The ability to rotate the brick before placing in the box has confused me. Any help would be appreciated!","a_1,a_2,a_3 b_1,b_2,b_3 a b \frac 1 4 a b",['probability']
42,Do the 12 lines of a bingo card have equal chance of winning?,Do the 12 lines of a bingo card have equal chance of winning?,,"(This question is inspired by: If I have an event where the outcomes aren't uniformly distributed, how would I make the ""fairest"" bingo card out of the events? ) You have a $5 \times 5$ bingo card filled with $25$ distinct numbers, one per square.  There is also a pot containing each number once and you draw them out one by one without replacement. A line is any of the $5$ rows, $5$ columns, or $2$ main diagonals.  A line is completed when its $5$ numbers have been drawn.  A line wins if it is the first line to be completed. Question: Do the $12$ lines have equal chance of winning?  If not, which lines have higher chance of winning? Why I ask: Define $T_l$ to be the time to completion for line $l$ .  It is obvious that all $T_l$ are equi-distributed, and thus all $E[T_l]$ are equal.  However, because the lines overlap, the different $T_l$ 's are dependent, and it is not clear to me that they have equal chances of being first. In particular, imagine that the $5$ -subsets are not arranged in rows, columns and diagonals, but are clustered in some non-uniform way.  Then a subset that shares a lot of elements with other subsets might have a lower chance to win than a subset that does not share a lot of elements with other subsets.  (I can provide a simple example if there is interest.) On the bingo card, the $5$ -subsets are pretty uniform but not exactly uniform, due to the diagonals.  So my suspicion is that the line win chances are almost equal but not exactly equal.  And I am curious as to which lines have higher chances. I imagine (but would be happy to be proven wrong) that calculating the exact win prob for a line might be difficult/tedious, so qualitative arguments based on e.g. symmetry are also welcome. Clarifications: A drawn number can complete multiple lines, so that needs some special handling.  However what I am interested in is the question of equality, so I will accept any reasonable way to handle such ""shared"" wins, i.e. if $N>1$ lines are completed at the same draw (and no line has been completed before this draw), then you can treat this as if... they all win (in which case the sum of the $12$ win probabilities exceed $1$ , but that doesn't matter since I am interested in which are higher/lower), or, the whole experiment is repeated from the beginning (i.e. we condition on such shared wins not happening), or, you flip an $N$ -sided die to determine the winner (i.e. this effectively counts as $1/N$ win for each involved line), etc.","(This question is inspired by: If I have an event where the outcomes aren't uniformly distributed, how would I make the ""fairest"" bingo card out of the events? ) You have a bingo card filled with distinct numbers, one per square.  There is also a pot containing each number once and you draw them out one by one without replacement. A line is any of the rows, columns, or main diagonals.  A line is completed when its numbers have been drawn.  A line wins if it is the first line to be completed. Question: Do the lines have equal chance of winning?  If not, which lines have higher chance of winning? Why I ask: Define to be the time to completion for line .  It is obvious that all are equi-distributed, and thus all are equal.  However, because the lines overlap, the different 's are dependent, and it is not clear to me that they have equal chances of being first. In particular, imagine that the -subsets are not arranged in rows, columns and diagonals, but are clustered in some non-uniform way.  Then a subset that shares a lot of elements with other subsets might have a lower chance to win than a subset that does not share a lot of elements with other subsets.  (I can provide a simple example if there is interest.) On the bingo card, the -subsets are pretty uniform but not exactly uniform, due to the diagonals.  So my suspicion is that the line win chances are almost equal but not exactly equal.  And I am curious as to which lines have higher chances. I imagine (but would be happy to be proven wrong) that calculating the exact win prob for a line might be difficult/tedious, so qualitative arguments based on e.g. symmetry are also welcome. Clarifications: A drawn number can complete multiple lines, so that needs some special handling.  However what I am interested in is the question of equality, so I will accept any reasonable way to handle such ""shared"" wins, i.e. if lines are completed at the same draw (and no line has been completed before this draw), then you can treat this as if... they all win (in which case the sum of the win probabilities exceed , but that doesn't matter since I am interested in which are higher/lower), or, the whole experiment is repeated from the beginning (i.e. we condition on such shared wins not happening), or, you flip an -sided die to determine the winner (i.e. this effectively counts as win for each involved line), etc.",5 \times 5 25 5 5 2 5 12 T_l l T_l E[T_l] T_l 5 5 N>1 12 1 N 1/N,"['probability', 'combinatorics']"
43,"Is it true that $\lim_{n \to \infty} {(P(\forall i,j\leq n \text{ } [X_i, X_j] = e))}^{\frac{1}{n}} = P(X_1 \in Z(G))$?",Is it true that ?,"\lim_{n \to \infty} {(P(\forall i,j\leq n \text{ } [X_i, X_j] = e))}^{\frac{1}{n}} = P(X_1 \in Z(G))","Suppose $G$ is a group. $\{X_n\}_{n = 1}^{\infty}$ is a sequence of i.i.d. random elements of $G$ satisfying the condition that $$\forall H \leq G, \qquad P(X_1 \in H) = \begin{cases}    \frac{1}{[G:H]} & \quad \text{if $[G:H]$ is finite}\\    0  & \quad \text{if $[G:H]$ is infinite}  \end{cases}$$ Is it true that $$\lim_{n \to \infty} P(\forall i,j\leq n, \ [X_i, X_j] = e)^{\frac{1}{n}} = P(X_1 \in Z(G)) \ ? $$ What have I tried so far? If we accept an additional supposition, that the events $\{\forall i \leq p, \ X_i \in C_G(X_p) \}$ and $\{\forall i \leq q, \ X_i \in C_G(X_q) \}$ are independent for any natural $p \neq q$ . Then we can see, that $$P(\forall i,j\leq n, \ [X_i, X_j] = e) = \prod_{i = 1}^{n} P(\{\forall j \leq i, \ X_j \in C_G(X_i) \}).$$ Now, let’s see, that on one hand \begin{align*} &P(\{\forall j \leq i, \ X_j \in C_G(X_i) \}) \\ &= P(X_i \in Z(G)) + (1 - P(X_i \in Z(G))P(X_1 \in C_G(X_i))^{i - 1} \\ &\leq P(X_1 \in Z(G)) + (1 - P(X_1 \in Z(G))\left(\frac{1}{2}\right)^{i - 1} \\ &= \frac{1}{2^{i - 1}} + \left(1 - \frac{1}{2^{i - 1}}\right)P(X_1 \in Z(G)) \\ &= P(X_1 \in Z(G))\left(1 - \frac{1}{2^{i - 1}} + \frac{1}{2^{i - 1}P(X_1 \in Z(G))}\right) \end{align*} and on the other hand \begin{align*} &P(\{\forall j \leq i, \ X_j \in C_G(X_i) \}) \\ &= P(X_i \in Z(G)) + (1 - P(X_i \in Z(G))P(X_1 \in C_G(X_i))^{i - 1} \\ &\geq P(X_1 \in Z(G)) + (1 - P(X_1 \in Z(G))P(X_1 \in Z(G))^{i - 1} \\ &= P(X_1 \in Z(G))^{i - 1} + \left(1 - P(X_1 \in Z(G))^{i - 1}\right)P(X_1 \in Z(G)) \\ &= P(X_1 \in Z(G))\left(1 - P(X_1 \in Z(G))^{i - 1} + P(X_1 \in Z(G))^{i - 2}\right) \end{align*} So, we have \begin{align*} &P(X_1 \in Z(G)) \\ &= \lim_{i \to \infty} P(X_1 \in Z(G))\left(1 - P(X_1 \in Z(G))^{i - 1} + P(X_1 \in Z(G))^{i - 2}\right) \\ &= \lim_{n \to \infty} \left( \prod_{i = 1}^n P(X_1 \in Z(G)) \left(1 - P(X_1 \in Z(G))^{i - 1} + P(X_1 \in Z(G))^{i - 2} \right) \right)^{\frac{1}{n}} \\ &\leq \lim_{n \to \infty} P(\forall i,j\leq n, \ [X_i, X_j] = e)^{\frac{1}{n}} \\ &\leq \lim_{n \to \infty} \left( \prod_{i = 1}^n P(X_1 \in Z(G)) P(X_1 \in Z(G)) \left(1 - \frac{1}{2^{i - 1}} + \frac{1}{2^{i - 1}P(X_1 \in Z(G))} \right) \right)^{\frac{1}{n}} \\ &= \lim_{i \to \infty} P(X_1 \in Z(G))\left(1 - \frac{1}{2^{i - 1}} + \frac{1}{2^{i - 1}P(X_1 \in Z(G))} \right) \\ &= P(X_1 \in Z(G)). \end{align*} However, I do not know how to prove that the events in our supposition are always independent (or is there a counterexample?). And neither do I know, how to prove the main statement of the question without using the aforementioned supposition.","Suppose is a group. is a sequence of i.i.d. random elements of satisfying the condition that Is it true that What have I tried so far? If we accept an additional supposition, that the events and are independent for any natural . Then we can see, that Now, let’s see, that on one hand and on the other hand So, we have However, I do not know how to prove that the events in our supposition are always independent (or is there a counterexample?). And neither do I know, how to prove the main statement of the question without using the aforementioned supposition.","G \{X_n\}_{n = 1}^{\infty} G \forall H \leq G, \qquad P(X_1 \in H) = \begin{cases}
   \frac{1}{[G:H]} & \quad \text{if [G:H] is finite}\\
   0  & \quad \text{if [G:H] is infinite}
 \end{cases} \lim_{n \to \infty} P(\forall i,j\leq n, \ [X_i, X_j] = e)^{\frac{1}{n}} = P(X_1 \in Z(G)) \ ?  \{\forall i \leq p, \ X_i \in C_G(X_p) \} \{\forall i \leq q, \ X_i \in C_G(X_q) \} p \neq q P(\forall i,j\leq n, \ [X_i, X_j] = e) = \prod_{i = 1}^{n} P(\{\forall j \leq i, \ X_j \in C_G(X_i) \}). \begin{align*}
&P(\{\forall j \leq i, \ X_j \in C_G(X_i) \}) \\
&= P(X_i \in Z(G)) + (1 - P(X_i \in Z(G))P(X_1 \in C_G(X_i))^{i - 1} \\
&\leq P(X_1 \in Z(G)) + (1 - P(X_1 \in Z(G))\left(\frac{1}{2}\right)^{i - 1} \\
&= \frac{1}{2^{i - 1}} + \left(1 - \frac{1}{2^{i - 1}}\right)P(X_1 \in Z(G)) \\
&= P(X_1 \in Z(G))\left(1 - \frac{1}{2^{i - 1}} + \frac{1}{2^{i - 1}P(X_1 \in Z(G))}\right)
\end{align*} \begin{align*}
&P(\{\forall j \leq i, \ X_j \in C_G(X_i) \}) \\
&= P(X_i \in Z(G)) + (1 - P(X_i \in Z(G))P(X_1 \in C_G(X_i))^{i - 1} \\
&\geq P(X_1 \in Z(G)) + (1 - P(X_1 \in Z(G))P(X_1 \in Z(G))^{i - 1} \\
&= P(X_1 \in Z(G))^{i - 1} + \left(1 - P(X_1 \in Z(G))^{i - 1}\right)P(X_1 \in Z(G)) \\
&= P(X_1 \in Z(G))\left(1 - P(X_1 \in Z(G))^{i - 1} + P(X_1 \in Z(G))^{i - 2}\right)
\end{align*} \begin{align*}
&P(X_1 \in Z(G)) \\
&= \lim_{i \to \infty} P(X_1 \in Z(G))\left(1 - P(X_1 \in Z(G))^{i - 1} + P(X_1 \in Z(G))^{i - 2}\right) \\
&= \lim_{n \to \infty} \left( \prod_{i = 1}^n P(X_1 \in Z(G)) \left(1 - P(X_1 \in Z(G))^{i - 1} + P(X_1 \in Z(G))^{i - 2} \right) \right)^{\frac{1}{n}} \\
&\leq \lim_{n \to \infty} P(\forall i,j\leq n, \ [X_i, X_j] = e)^{\frac{1}{n}} \\
&\leq \lim_{n \to \infty} \left( \prod_{i = 1}^n P(X_1 \in Z(G)) P(X_1 \in Z(G)) \left(1 - \frac{1}{2^{i - 1}} + \frac{1}{2^{i - 1}P(X_1 \in Z(G))} \right) \right)^{\frac{1}{n}} \\
&= \lim_{i \to \infty} P(X_1 \in Z(G))\left(1 - \frac{1}{2^{i - 1}} + \frac{1}{2^{i - 1}P(X_1 \in Z(G))} \right) \\
&= P(X_1 \in Z(G)).
\end{align*}","['probability', 'abstract-algebra', 'group-theory', 'probability-theory', 'independence']"
44,Explain about the Correlation of Error Terms in Linear Regression Models,Explain about the Correlation of Error Terms in Linear Regression Models,,"I would like to ask for the interpretation, both mathematically and intuitively if possible, about the homoscedasticity of the variance of errors in linear regression models. If there is correlation among the error terms, then how it would affect the estimated standard errors of regression coefficients $\beta_i's$ , the confidence and prediction intervals (if we were to keep the assumption of homoscedasticity of errors and run the linear regression models) and how is it compared to the true standard errors $Var(\epsilon)$ (like underestimate or overestimate the true standard errors) and why? My question arises from the section about ""Correlation of Error Terms"" in the book ""Introduction to Statistical Learning"". It is as follows: An important assumption of the linear regression model is that the error terms, $\epsilon_1, \epsilon_2, ..., \epsilon_n$ , are uncorrelated. What does this mean? For instance, if the errors are uncorrelated, then the fact that $\epsilon_i$ is positive provides little or no information about the sign of $\epsilon_{i+1}$ . The standard errors that are computed for the estimated regression coefficients or the fitted values are based on the assumption of uncorrelated error terms. If in fact there is correlation among the error terms, then the estimated standard errors will tend to underestimate the true standard errors. As a result, confidence and prediction intervals will be narrower than they should be. For example, a 95 % confidence interval may in reality have a much lower probability than 0.95 of containing the true value of the parameter. In addition, p-values associated with the model will be lower than they should be; this could cause us to erroneously conclude that a parameter is statistically significant. In short, if the error terms are correlated, we may have an unwarranted sense of confidence in our model.   As an extreme example, suppose we accidentally doubled our data, leading to observations and error terms identical in pairs. If we ignored this, our standard error calculations would be as if we had a sample of size $2n$ , when in fact we have only n samples. Our estimated parameters would be the same for the $2n$ samples as for the $n$ samples, but the confidence intervals would be narrower by a factor of $\sqrt2$ ! I hope my question is clear. Many thanks in advance for sharing your insights on the question!","I would like to ask for the interpretation, both mathematically and intuitively if possible, about the homoscedasticity of the variance of errors in linear regression models. If there is correlation among the error terms, then how it would affect the estimated standard errors of regression coefficients , the confidence and prediction intervals (if we were to keep the assumption of homoscedasticity of errors and run the linear regression models) and how is it compared to the true standard errors (like underestimate or overestimate the true standard errors) and why? My question arises from the section about ""Correlation of Error Terms"" in the book ""Introduction to Statistical Learning"". It is as follows: An important assumption of the linear regression model is that the error terms, , are uncorrelated. What does this mean? For instance, if the errors are uncorrelated, then the fact that is positive provides little or no information about the sign of . The standard errors that are computed for the estimated regression coefficients or the fitted values are based on the assumption of uncorrelated error terms. If in fact there is correlation among the error terms, then the estimated standard errors will tend to underestimate the true standard errors. As a result, confidence and prediction intervals will be narrower than they should be. For example, a 95 % confidence interval may in reality have a much lower probability than 0.95 of containing the true value of the parameter. In addition, p-values associated with the model will be lower than they should be; this could cause us to erroneously conclude that a parameter is statistically significant. In short, if the error terms are correlated, we may have an unwarranted sense of confidence in our model.   As an extreme example, suppose we accidentally doubled our data, leading to observations and error terms identical in pairs. If we ignored this, our standard error calculations would be as if we had a sample of size , when in fact we have only n samples. Our estimated parameters would be the same for the samples as for the samples, but the confidence intervals would be narrower by a factor of ! I hope my question is clear. Many thanks in advance for sharing your insights on the question!","\beta_i's Var(\epsilon) \epsilon_1, \epsilon_2, ..., \epsilon_n \epsilon_i \epsilon_{i+1} 2n 2n n \sqrt2","['probability', 'statistics', 'variance', 'linear-regression', 'standard-error']"
45,Bounding the degree of very sparse random graph,Bounding the degree of very sparse random graph,,"I am confused with how to manipulating with big O notation ,here is a problem from section 2.4(Exercise 2.4.3) high dimensional probability by Roman Vershynin Consider a random graph $G \sim G(n,p)$ with expected degree $d=O(1)$ . Show that with high probability , all vertices of $G$ have degrees $$O (\frac{\log n}{\log \log n})$$ I want use Chernoff bound below to bound the degree of vertices: $$Pr\left[| X-\mu|\geq \delta \mu \right] \leq 2e^ {-c\mu\delta ^2}$$ where c is a constant $\DeclareMathOperator*{\E}{\mathbb{E}} \delta \in [0,1), \mu = \E {X}$ and X is binomial random variable. how should I do that ?","I am confused with how to manipulating with big O notation ,here is a problem from section 2.4(Exercise 2.4.3) high dimensional probability by Roman Vershynin Consider a random graph with expected degree . Show that with high probability , all vertices of have degrees I want use Chernoff bound below to bound the degree of vertices: where c is a constant and X is binomial random variable. how should I do that ?","G \sim G(n,p) d=O(1) G O (\frac{\log n}{\log \log n}) Pr\left[| X-\mu|\geq \delta \mu \right] \leq 2e^ {-c\mu\delta ^2} \DeclareMathOperator*{\E}{\mathbb{E}} \delta \in [0,1), \mu = \E {X}","['probability', 'asymptotics', 'random-graphs', 'network', 'concentration-of-measure']"
46,Concentration of two independent sub-Gaussian random variables,Concentration of two independent sub-Gaussian random variables,,"Suppose $X$ and $Y$ are independent sub-Gaussian random variables with 0 mean and $\sigma^2$ sub-Gaussian parameter. More specifically, $\mathbb E[\exp(a^T X)]\leq \exp\{\|a\|_2^2\sigma^2/2\}$ for all $a$, and the same holds for $Y$ as well. I wish to upper bound the tail probability $$ \Pr\left[|X^T Y|>t\right] $$ using $\sigma^2$ and dimension $n$ (that is, both $X$ and $Y$ are $d$-dimensional random variables). How can I achieve this?  $X^T Y$ does not seem to be either sub-Gaussian or sub-exponential.","Suppose $X$ and $Y$ are independent sub-Gaussian random variables with 0 mean and $\sigma^2$ sub-Gaussian parameter. More specifically, $\mathbb E[\exp(a^T X)]\leq \exp\{\|a\|_2^2\sigma^2/2\}$ for all $a$, and the same holds for $Y$ as well. I wish to upper bound the tail probability $$ \Pr\left[|X^T Y|>t\right] $$ using $\sigma^2$ and dimension $n$ (that is, both $X$ and $Y$ are $d$-dimensional random variables). How can I achieve this?  $X^T Y$ does not seem to be either sub-Gaussian or sub-exponential.",,"['probability', 'concentration-of-measure']"
47,"If five coins are flipped simultaneously, find the probability of each of the following:","If five coins are flipped simultaneously, find the probability of each of the following:",,"If five coins are flipped simultaneously, find the probability of each of the following: (a) At least one coin lands heads; My answer: $\frac{2^5 -1}{2^5}$ . I took the complement for the numerator. (b) At most one coin lands heads. My answer: $\frac{6}{2^5}$ . I counted how many times heads appears $1$ or $0$ times. Is this correct?","If five coins are flipped simultaneously, find the probability of each of the following: (a) At least one coin lands heads; My answer: . I took the complement for the numerator. (b) At most one coin lands heads. My answer: . I counted how many times heads appears or times. Is this correct?",\frac{2^5 -1}{2^5} \frac{6}{2^5} 1 0,"['probability', 'combinatorics', 'discrete-mathematics']"
48,Expectation and variance of the Pareto distribution,Expectation and variance of the Pareto distribution,,"Given the distribution funciton of the r.v. $X$ for $\alpha, \beta >0$ $$ F(x) = 1-\Big( \frac{\beta}{\beta +x}\Big)^{\alpha} $$ for $x \geq 0$ and $0$ elsewhere What is the expectation and variance of $X$ for those values of parameters, where it is defined? Furthermore, how can one estimate the parameters $(\alpha, \beta)$ with given data using the method of moments? My idea was to first of all calculate the density, i.e. $$f(x) = \frac{\alpha \beta^{\alpha}}{(\beta + x)^{\alpha+1}}$$ for $x \geq 0$ . Then $$E[X] = \alpha \beta^{\alpha}\int_0^{\infty}\frac{x}{(\beta + x)^{\alpha+1}} dx$$ How can I proceed now?","Given the distribution funciton of the r.v. for for and elsewhere What is the expectation and variance of for those values of parameters, where it is defined? Furthermore, how can one estimate the parameters with given data using the method of moments? My idea was to first of all calculate the density, i.e. for . Then How can I proceed now?","X \alpha, \beta >0  F(x) = 1-\Big( \frac{\beta}{\beta +x}\Big)^{\alpha}  x \geq 0 0 X (\alpha, \beta) f(x) = \frac{\alpha \beta^{\alpha}}{(\beta + x)^{\alpha+1}} x \geq 0 E[X] = \alpha \beta^{\alpha}\int_0^{\infty}\frac{x}{(\beta + x)^{\alpha+1}} dx","['probability', 'probability-theory', 'random-variables', 'expectation', 'variance']"
49,Definition of a probability kernel,Definition of a probability kernel,,"I don't quite understand the definition of a probability kernel (or Markov kernel). Is this correct, the reason to introduce this a transition kernel is, if we have a source $(X,\mathcal{A})$ and a target $(Y,\mathcal{B})$ , both measurable spaces, we want to have a new measurable space $(X,\mathcal{B})$ ? There is this example on Wikipedia for a random walk: Take $X=Y=\mathbb{Z}$ and $\mathcal A = \mathcal B = \mathcal P(\mathbb{Z})$ , then the Markov kernel $\kappa$ with $$\kappa(x,B)=\frac{1}{2}\mathbf{1}_{B}(x-1)+\frac{1}{2}\mathbf{1}_{B}(x+1), \quad \forall x \in \mathbb{Z}, \quad \forall B \in \mathcal P(\mathbb{Z})$$ describes the transition rule But I don't understand it. Why are we using here $Y$ and $\mathcal{A}$ ? Is the measurable space $(Y,\mathcal{B})$ the next position on the random walk with new event from $\mathcal{B}$ ?","I don't quite understand the definition of a probability kernel (or Markov kernel). Is this correct, the reason to introduce this a transition kernel is, if we have a source and a target , both measurable spaces, we want to have a new measurable space ? There is this example on Wikipedia for a random walk: Take and , then the Markov kernel with describes the transition rule But I don't understand it. Why are we using here and ? Is the measurable space the next position on the random walk with new event from ?","(X,\mathcal{A}) (Y,\mathcal{B}) (X,\mathcal{B}) X=Y=\mathbb{Z} \mathcal A = \mathcal B = \mathcal P(\mathbb{Z}) \kappa \kappa(x,B)=\frac{1}{2}\mathbf{1}_{B}(x-1)+\frac{1}{2}\mathbf{1}_{B}(x+1), \quad \forall x \in \mathbb{Z}, \quad \forall B \in \mathcal P(\mathbb{Z}) Y \mathcal{A} (Y,\mathcal{B}) \mathcal{B}","['probability', 'probability-theory', 'stochastic-processes', 'markov-chains', 'markov-process']"
50,Measure on the positive integers respecting independence of prime divisors,Measure on the positive integers respecting independence of prime divisors,,"I want to know if there exists a measure $\mu$ on the positive integers (equipped with the $\sigma-$algebra of all subsets) satisfying: 1) For all $n > 1$, $\mu(A_n) = 1/n$, where $A_n = \{n, 2n, \ldots \}$ is the multiples of $n$, and 2) The events $A_m, A_n$ are independent when $m$ and $n$ are relatively prime. If such a measure existed, it would mimic the notion of drawing a ""random integer"" from all of $\mathbb{N}$, at least with respect to these divisibility properties. 1) and 2) hold approximately for the uniform distribution on $\mathbb{N} \cap [1,X]$ for large $X$; a similar weakening of the question is to use asymptotic density, i.e. define $\mu(A) = \lim_{n \to \infty} \frac{|A \cap \{1, 2, 3, \ldots, n\}|}{n}$, which satisfies 1) and 2) but is not countably additive. The zeta distribution, given by (for any $s > 1$) the density $\nu_s(n) = \frac{1}{\zeta(s)} n^{-s}$, comes very close: it is an easy check that 2) holds, but $\nu_s(A_n) = n^{-s}$ for all $n$. (Interestingly, as $s \to 1^+$, for a fixed subset $A \subset \mathbb{N}, \nu_s(A)$ converges to the asymptotic density of $A$, if it exists.) I suspect the answer is that no such measure exists: the fact that the zeta distribution fails makes me think 1 and 2 are somehow at odds. I believe any $\mu$ satisfying 1) and 2) should have $\mu(\mathbb{N}) = \infty$, but I don't have a proof. Thanks! Edit: As people have pointed out, 1) clearly implies 2). (Whoops!) And @Zhoraster has given a nice proof that no measure can exist in this case. Here's what (I think) will be a harder question: Can we find a measure $\mu$ satisfying 1a) $\mu(A_p) = 1/p$ for primes $p$, and 2a) The events $A_p$ and $A_q$ are independent when $p$ and $q$ are prime. Now it's not obvious that $1$ and $2$ hold for products of many primes: we do get $\mu(A_{pq}) = 1/pq$ for distinct primes $p$ and $q$, but that's it. I don't think the inclusion-exclusion proof will work as stated, but perhaps a similar idea can be used...","I want to know if there exists a measure $\mu$ on the positive integers (equipped with the $\sigma-$algebra of all subsets) satisfying: 1) For all $n > 1$, $\mu(A_n) = 1/n$, where $A_n = \{n, 2n, \ldots \}$ is the multiples of $n$, and 2) The events $A_m, A_n$ are independent when $m$ and $n$ are relatively prime. If such a measure existed, it would mimic the notion of drawing a ""random integer"" from all of $\mathbb{N}$, at least with respect to these divisibility properties. 1) and 2) hold approximately for the uniform distribution on $\mathbb{N} \cap [1,X]$ for large $X$; a similar weakening of the question is to use asymptotic density, i.e. define $\mu(A) = \lim_{n \to \infty} \frac{|A \cap \{1, 2, 3, \ldots, n\}|}{n}$, which satisfies 1) and 2) but is not countably additive. The zeta distribution, given by (for any $s > 1$) the density $\nu_s(n) = \frac{1}{\zeta(s)} n^{-s}$, comes very close: it is an easy check that 2) holds, but $\nu_s(A_n) = n^{-s}$ for all $n$. (Interestingly, as $s \to 1^+$, for a fixed subset $A \subset \mathbb{N}, \nu_s(A)$ converges to the asymptotic density of $A$, if it exists.) I suspect the answer is that no such measure exists: the fact that the zeta distribution fails makes me think 1 and 2 are somehow at odds. I believe any $\mu$ satisfying 1) and 2) should have $\mu(\mathbb{N}) = \infty$, but I don't have a proof. Thanks! Edit: As people have pointed out, 1) clearly implies 2). (Whoops!) And @Zhoraster has given a nice proof that no measure can exist in this case. Here's what (I think) will be a harder question: Can we find a measure $\mu$ satisfying 1a) $\mu(A_p) = 1/p$ for primes $p$, and 2a) The events $A_p$ and $A_q$ are independent when $p$ and $q$ are prime. Now it's not obvious that $1$ and $2$ hold for products of many primes: we do get $\mu(A_{pq}) = 1/pq$ for distinct primes $p$ and $q$, but that's it. I don't think the inclusion-exclusion proof will work as stated, but perhaps a similar idea can be used...",,"['probability', 'elementary-number-theory', 'measure-theory']"
51,Monitoring a data stream,Monitoring a data stream,,"You are monitoring a data stream which is delivering very many $32$-bit quantities at a rate of $10$ Megabytes per second. You know that either: $A$: All values occur equally often, $or$ $B$: Half of the values occur $2^{10}$ times more often than others (but you dont know anything about which would be the more common values). You are allowed to read the values off the data stream, but you only have $2^{20}$ bytes of memory. Describe a method for determining which of the two situations, $A$ or $B$, occurs. Roughly how many data values do you need to read to be confident of your result with a probability of $0.999$? [This is about the $3$ sigma level – $3$ standard deviations of a normal distribution.] Please could I have some thoughts on the solution, it is a difficult problem.","You are monitoring a data stream which is delivering very many $32$-bit quantities at a rate of $10$ Megabytes per second. You know that either: $A$: All values occur equally often, $or$ $B$: Half of the values occur $2^{10}$ times more often than others (but you dont know anything about which would be the more common values). You are allowed to read the values off the data stream, but you only have $2^{20}$ bytes of memory. Describe a method for determining which of the two situations, $A$ or $B$, occurs. Roughly how many data values do you need to read to be confident of your result with a probability of $0.999$? [This is about the $3$ sigma level – $3$ standard deviations of a normal distribution.] Please could I have some thoughts on the solution, it is a difficult problem.",,"['probability', 'statistics', 'computer-science', 'normal-distribution', 'data-analysis']"
52,The tea bag problem: probability of extracting a single bag of tea,The tea bag problem: probability of extracting a single bag of tea,,"Suppose you have a bunch of tea bags in a box, initially in pairs, like these: Let us suppose the box initially contains only joined pairs of tea bags, say $N_0$ of them (thus making for a total of $2N_0$ tea bags). Every time you want to make yourself a tea, you put a hand in the box and randomly extract a tea bag. Sometimes you will find yourself with a joined pair, in which case you split it, take one for your tea, and put the other back into the box. If you instead extract a single tea bag (which was already split before), you just take it. Now if you ever happened to be in a similar situation, you will probably have noticed that after a while you will almost always extract single tea bags and seldolmly find doubles (which is not surprising of course). The question is, what exactly is the probability $p_k$ of extracting a single tea bag, after $k$ tea bags have already been picked? Suppose for this problem that each time there is an equal probability of extracting any of the tea bags, regardless of them being joined with another or not, so that after the first step (in which we necessarily extract and split a double) the probability of extracting a single bag is $p_1=\frac{1}{2N_0-1}$. It is relatively easy, just by computing the values of $p_k$ for the first $k$s, to see that the answer to the problem is quite nice: $$p_k = \frac{k}{2N_0 -1}.$$ How can we prove this? An interesting variation of the problem is asking what happens if we instead consider the picking of a pair as a single event (instead that as two, as in the above considered case). With this assumption the previous formula does not hold, as computing the first values of $p_k$ shows: $$ p_1 = \frac{1}{N_0}, \\ p_2 = \frac{2(N_0-1)}{N_0^2} .$$","Suppose you have a bunch of tea bags in a box, initially in pairs, like these: Let us suppose the box initially contains only joined pairs of tea bags, say $N_0$ of them (thus making for a total of $2N_0$ tea bags). Every time you want to make yourself a tea, you put a hand in the box and randomly extract a tea bag. Sometimes you will find yourself with a joined pair, in which case you split it, take one for your tea, and put the other back into the box. If you instead extract a single tea bag (which was already split before), you just take it. Now if you ever happened to be in a similar situation, you will probably have noticed that after a while you will almost always extract single tea bags and seldolmly find doubles (which is not surprising of course). The question is, what exactly is the probability $p_k$ of extracting a single tea bag, after $k$ tea bags have already been picked? Suppose for this problem that each time there is an equal probability of extracting any of the tea bags, regardless of them being joined with another or not, so that after the first step (in which we necessarily extract and split a double) the probability of extracting a single bag is $p_1=\frac{1}{2N_0-1}$. It is relatively easy, just by computing the values of $p_k$ for the first $k$s, to see that the answer to the problem is quite nice: $$p_k = \frac{k}{2N_0 -1}.$$ How can we prove this? An interesting variation of the problem is asking what happens if we instead consider the picking of a pair as a single event (instead that as two, as in the above considered case). With this assumption the previous formula does not hold, as computing the first values of $p_k$ shows: $$ p_1 = \frac{1}{N_0}, \\ p_2 = \frac{2(N_0-1)}{N_0^2} .$$",,['probability']
53,Generating the equation for probability,Generating the equation for probability,,"I have one red die and a green die. I want to find the probability of rolling at least one 4. Now, because they are 2 different dice, there are 36 possibilities. So the first possibility is a 4 from the red and some other number for the green. Second possibility is a 4 from the green and some other number for the red. Both roll a 4. So I can clearly see that the answer is 3 ways. However, if I want to arrive at the answer using combinatoric equations, how would I do so?","I have one red die and a green die. I want to find the probability of rolling at least one 4. Now, because they are 2 different dice, there are 36 possibilities. So the first possibility is a 4 from the red and some other number for the green. Second possibility is a 4 from the green and some other number for the red. Both roll a 4. So I can clearly see that the answer is 3 ways. However, if I want to arrive at the answer using combinatoric equations, how would I do so?",,"['probability', 'combinatorics']"
54,What is the optimal strategy when driving to my university: Wait or take alternative route and (possibly) wait?,What is the optimal strategy when driving to my university: Wait or take alternative route and (possibly) wait?,,"When bicycling to my university, I'm faced with a difficult decision. The situation is shown here: I have to get to point marked with the $\times$, but in order to do so, I must cross a big road with a traffic light at both places where crossing is possible. If the first traffic light (at the bottom) is green, then there's no debate; I simply cross and go up $A$ with no waiting time at all. The choice arises when it is red (as is always the case anyway), since I can choose to wait for the first light to change, or go up a smaller road $B$ and then try to cross at the second light. Let's assume that the two traffic lights are identical w.r.t. the percent of the time they are red (let's call this quantity $\Theta$), but that the second is phase-shifted with $\tau$ w.r.t. the first, s.t. the second changes to e.g. green a time $\tau$ after the first. The length $L$ of the paths are identical and I bicycle with a constant speed $v$ (although I suspect these last two are irrelevant to the solution). I don't know anything about the light before I arrive at it. The question then becomes If I arrive at a random time during which the first traffic light is red, given $\Theta$ and $\tau$ (and $L$ and $v$), should I wait at the first light and go by path $A$, or should I go by path $B$ in order to minimize waiting time? The type of solution I'm looking for can better be formulated if we first look at two examples: The $\mathbf{I}$'s represent the time during which the traffic light is red - the space in between them represent the green lights. The drawn lines represent my position if I chose to go by $B$. If I arrive at the first red light during the blue stretch, I should go by $B$; if I, on the other hand, arrive during the red stretch, I should go wait and go by $A$. As can be seen from the two scenarios $(a)$ and $(b)$ (where the lines represent my position should I choose path $B$, and where the slope is determined by $L$ and $v$), my choice depends on $\tau$, which is the only parameter that has been changed. If we call the length of the blue strip $t_{\text{go}}$ and the length of the red strip $t_{\text{wait}}$, s.t. $t_{\text{go}}+t_{\text{wait}}=\Theta$, the solution should be of the form $$t_{\text{go}}(\tau)$$ I don't think $v$ and $L$ should play a role, since the effect of changing these can be incorporated into $\tau$, so we could probably set $v=L=1$. I'm guessing there should be a pretty simple geometric way of solving this, but for the time being it is eluding me. Some random observations: If $v=\frac{L}{\tau}$ it doesn't matter what I choose. Also, if the second light was independent of the first, I should always go by $B$, since there I will at least have a $1-\Theta$ chance of getting a green light. Any help is much appreciated!","When bicycling to my university, I'm faced with a difficult decision. The situation is shown here: I have to get to point marked with the $\times$, but in order to do so, I must cross a big road with a traffic light at both places where crossing is possible. If the first traffic light (at the bottom) is green, then there's no debate; I simply cross and go up $A$ with no waiting time at all. The choice arises when it is red (as is always the case anyway), since I can choose to wait for the first light to change, or go up a smaller road $B$ and then try to cross at the second light. Let's assume that the two traffic lights are identical w.r.t. the percent of the time they are red (let's call this quantity $\Theta$), but that the second is phase-shifted with $\tau$ w.r.t. the first, s.t. the second changes to e.g. green a time $\tau$ after the first. The length $L$ of the paths are identical and I bicycle with a constant speed $v$ (although I suspect these last two are irrelevant to the solution). I don't know anything about the light before I arrive at it. The question then becomes If I arrive at a random time during which the first traffic light is red, given $\Theta$ and $\tau$ (and $L$ and $v$), should I wait at the first light and go by path $A$, or should I go by path $B$ in order to minimize waiting time? The type of solution I'm looking for can better be formulated if we first look at two examples: The $\mathbf{I}$'s represent the time during which the traffic light is red - the space in between them represent the green lights. The drawn lines represent my position if I chose to go by $B$. If I arrive at the first red light during the blue stretch, I should go by $B$; if I, on the other hand, arrive during the red stretch, I should go wait and go by $A$. As can be seen from the two scenarios $(a)$ and $(b)$ (where the lines represent my position should I choose path $B$, and where the slope is determined by $L$ and $v$), my choice depends on $\tau$, which is the only parameter that has been changed. If we call the length of the blue strip $t_{\text{go}}$ and the length of the red strip $t_{\text{wait}}$, s.t. $t_{\text{go}}+t_{\text{wait}}=\Theta$, the solution should be of the form $$t_{\text{go}}(\tau)$$ I don't think $v$ and $L$ should play a role, since the effect of changing these can be incorporated into $\tau$, so we could probably set $v=L=1$. I'm guessing there should be a pretty simple geometric way of solving this, but for the time being it is eluding me. Some random observations: If $v=\frac{L}{\tau}$ it doesn't matter what I choose. Also, if the second light was independent of the first, I should always go by $B$, since there I will at least have a $1-\Theta$ chance of getting a green light. Any help is much appreciated!",,"['probability', 'optimization', 'recreational-mathematics']"
55,Could the Monty-Hall Problem be applied to multiple choice tests?,Could the Monty-Hall Problem be applied to multiple choice tests?,,"Given a multiple choice test where each question contains 4 possible answers, what would happen if before beginning the test (before reading the questions), someone were to make a random selection for each question? At this point it seems logical that for a given question the student has a 1/4 chance of their choice being correct and a 3/4 chance of one of the other choices being correct. Let's say that they now begin to read the questions and in some cases they can deduce that one of the provided answers which was not the one that they picked is not correct (let's assume that there is no error in this deduction). In the scenario with the Monty Hall Problem, the probabilities did not change once the door was opened, they just shifted. By applying the same logic, the original selected answer has a 1/4 chance of being correct and the other three have a 3/4 chance of being correct, except that since one was deduced to be incorrect, the two remaining options have a 3/4 chance of being correct and so switching answers would increase the odds of being correct to $\frac{1}{2} * \frac{3}{4}$. Is this an accurate assumption or are there pitfalls in doing this? If this is the case, then what happens if another deduction is made such that their original answer was determined to be incorrect? It seems that there would be no change in the odds, but that seems unlikely.","Given a multiple choice test where each question contains 4 possible answers, what would happen if before beginning the test (before reading the questions), someone were to make a random selection for each question? At this point it seems logical that for a given question the student has a 1/4 chance of their choice being correct and a 3/4 chance of one of the other choices being correct. Let's say that they now begin to read the questions and in some cases they can deduce that one of the provided answers which was not the one that they picked is not correct (let's assume that there is no error in this deduction). In the scenario with the Monty Hall Problem, the probabilities did not change once the door was opened, they just shifted. By applying the same logic, the original selected answer has a 1/4 chance of being correct and the other three have a 3/4 chance of being correct, except that since one was deduced to be incorrect, the two remaining options have a 3/4 chance of being correct and so switching answers would increase the odds of being correct to $\frac{1}{2} * \frac{3}{4}$. Is this an accurate assumption or are there pitfalls in doing this? If this is the case, then what happens if another deduction is made such that their original answer was determined to be incorrect? It seems that there would be no change in the odds, but that seems unlikely.",,"['probability', 'monty-hall']"
56,Not a run of the mill 20 balls in a bag problem!,Not a run of the mill 20 balls in a bag problem!,,"I'm trying to work out this problem with mixed results and have tried several ways. Here is the problem in its easiest way to explain: There is a bag of 20 coloured balls: 3 Blue 4 Pink 5 Yellow 8 Green If I pick balls out the bag without replacement until I have 3 the same colour, what are the probabilities that the 3 balls of the same color are Blue, Pink, Yellow or Green? I can work out things like getting 3 greens from just 3 picks etc as I believe this is  0.049122807 but am I right in that there is 27 ways to end up with 3 greens with all different probability? As the order is only relevant on the final pick that gives you 3 the same, up to that point its irrelevant? But it gets far more complex when your picking until 3 the same only!","I'm trying to work out this problem with mixed results and have tried several ways. Here is the problem in its easiest way to explain: There is a bag of 20 coloured balls: 3 Blue 4 Pink 5 Yellow 8 Green If I pick balls out the bag without replacement until I have 3 the same colour, what are the probabilities that the 3 balls of the same color are Blue, Pink, Yellow or Green? I can work out things like getting 3 greens from just 3 picks etc as I believe this is  0.049122807 but am I right in that there is 27 ways to end up with 3 greens with all different probability? As the order is only relevant on the final pick that gives you 3 the same, up to that point its irrelevant? But it gets far more complex when your picking until 3 the same only!",,"['probability', 'combinatorics']"
57,20 balloons are distributed amongst 6 children: Probability that one child gets no balloon?,20 balloons are distributed amongst 6 children: Probability that one child gets no balloon?,,"20 balloons are randomly distributed amongst 6 children. What is the probability, that at least one child gets no balloon? What's the mistake in the following reasoning (I know there has to be a mistake; by simulation I know, that the actual probability has to be appr. 0.15, which is not what the following formula gives): I start to think about the opposite case: What is the probability that every child gets at least one balloon. There are all together ${20+6-1\choose 20} = {25\choose 20}$ ways to distribute the balloons amongst the children. The number of the desired ways (i.e. distribute balloons so that every child gets at least one balloon) is ${14+6-1\choose 14} = {19\choose 14}$. So, the probability that every child gets at least one balloon, when the balloons are randomly distributed amongst the children should be $$ \frac{19\choose 14}{25\choose 20}$$ For the opposite  case, i.e. the probability that at least one child gets no balloon is:  $$ 1 - \frac{19\choose 14}{25\choose 20} = 0.78114...$$ At which point did I get wrong?? BTW: I used the following R-Code to simulate: v <- vector()   for (i in 1:100000){      t <- table(sample(1:6, 20, replace=T))      v[i] <- length(t)<6   }   print mean(v) One Remark : The answer from mlu is in my opinion correct; thank you very much for it! However: My questions was, where my mistake is in the above reasoning? The number of different ways to distribute k indistinguishable balls (=balloons) into n distinguishable boxes (=children) is ${n+k-1\choose k}$. So: where did I actually got wrong, because the denominator as specified above is correct, right? So whats wrong about the counter? Solution Thank you very much, again, mlu, for the answer as a commentary below. Now I got it: I counted the number of partitions and tried to calculate the probability with the Laplace-Technique (the nominator for the total number of cases, and the counter for the number of cases we are interested in) but I missed, that not every partition is equally probable. For instance the partition where one child gets all balloons is much more improbable than the partition, that child1 to child4 gets 3 balloons and child5 and child6 get 4 balloons is much more probable, which is clear even by intuition: In the first case, there is always just one possibility to put the balloon whereas in the second case there are (at least at the beginning) many possibilities to put balloons.","20 balloons are randomly distributed amongst 6 children. What is the probability, that at least one child gets no balloon? What's the mistake in the following reasoning (I know there has to be a mistake; by simulation I know, that the actual probability has to be appr. 0.15, which is not what the following formula gives): I start to think about the opposite case: What is the probability that every child gets at least one balloon. There are all together ${20+6-1\choose 20} = {25\choose 20}$ ways to distribute the balloons amongst the children. The number of the desired ways (i.e. distribute balloons so that every child gets at least one balloon) is ${14+6-1\choose 14} = {19\choose 14}$. So, the probability that every child gets at least one balloon, when the balloons are randomly distributed amongst the children should be $$ \frac{19\choose 14}{25\choose 20}$$ For the opposite  case, i.e. the probability that at least one child gets no balloon is:  $$ 1 - \frac{19\choose 14}{25\choose 20} = 0.78114...$$ At which point did I get wrong?? BTW: I used the following R-Code to simulate: v <- vector()   for (i in 1:100000){      t <- table(sample(1:6, 20, replace=T))      v[i] <- length(t)<6   }   print mean(v) One Remark : The answer from mlu is in my opinion correct; thank you very much for it! However: My questions was, where my mistake is in the above reasoning? The number of different ways to distribute k indistinguishable balls (=balloons) into n distinguishable boxes (=children) is ${n+k-1\choose k}$. So: where did I actually got wrong, because the denominator as specified above is correct, right? So whats wrong about the counter? Solution Thank you very much, again, mlu, for the answer as a commentary below. Now I got it: I counted the number of partitions and tried to calculate the probability with the Laplace-Technique (the nominator for the total number of cases, and the counter for the number of cases we are interested in) but I missed, that not every partition is equally probable. For instance the partition where one child gets all balloons is much more improbable than the partition, that child1 to child4 gets 3 balloons and child5 and child6 get 4 balloons is much more probable, which is clear even by intuition: In the first case, there is always just one possibility to put the balloon whereas in the second case there are (at least at the beginning) many possibilities to put balloons.",,"['probability', 'combinatorics', 'discrete-mathematics']"
58,Distribution of quotient of random variables,Distribution of quotient of random variables,,"If $X$ and $Y$ are independent random variables such that $X\sim \Gamma(a,b)$ and $Y\sim\Gamma(a,c)$. What is the distribution of random variable $\frac{Y}{X+Y}$? Any help with this ?","If $X$ and $Y$ are independent random variables such that $X\sim \Gamma(a,b)$ and $Y\sim\Gamma(a,c)$. What is the distribution of random variable $\frac{Y}{X+Y}$? Any help with this ?",,"['probability', 'statistics', 'random-variables']"
59,Flipping $n$ coins in a circle until they are all gone,Flipping  coins in a circle until they are all gone,n,"You have $n$ coins arranged in a circle, labeled $1$ to $n$. You start at the first coin and go around. At each coin you flip it - if it lands heads you keep it, if it lands tails you remove it. Which coin is most likely to be the last coin remaining? The answer is the coin labeled $n$ is the most likely. Indeed, the last coin is twice as likely than the first and the probabilities are strictly increasing from $1$ to $n$. This is an interview question I had and I came up with a couple intuitive ways to explain it. The clearest one is that when you reach coin $k$ for the $m$th time, $k-1$ coins have had $m$ chances to disappear and $n-k+1$ coins have had $m-1$ chances to disappear (including coin $k$). When $k$ is the last coin, then every other coin has had one more chance to be removed than that coin and when $k$ is the first coin, then every other coin has had the same amount of chances to be removed than it (which is why the last coin is twice as likely). What other ways, intuitive or rigorous, can you use to explain this phenomenon? Also, can you find exact evaluations for $P(k, n)$, i.e. the probability that the $k$th coin in a circle of $n$ coins is the last remaining coin?","You have $n$ coins arranged in a circle, labeled $1$ to $n$. You start at the first coin and go around. At each coin you flip it - if it lands heads you keep it, if it lands tails you remove it. Which coin is most likely to be the last coin remaining? The answer is the coin labeled $n$ is the most likely. Indeed, the last coin is twice as likely than the first and the probabilities are strictly increasing from $1$ to $n$. This is an interview question I had and I came up with a couple intuitive ways to explain it. The clearest one is that when you reach coin $k$ for the $m$th time, $k-1$ coins have had $m$ chances to disappear and $n-k+1$ coins have had $m-1$ chances to disappear (including coin $k$). When $k$ is the last coin, then every other coin has had one more chance to be removed than that coin and when $k$ is the first coin, then every other coin has had the same amount of chances to be removed than it (which is why the last coin is twice as likely). What other ways, intuitive or rigorous, can you use to explain this phenomenon? Also, can you find exact evaluations for $P(k, n)$, i.e. the probability that the $k$th coin in a circle of $n$ coins is the last remaining coin?",,['probability']
60,How to shift two CDF's to maximize the number of crossings,How to shift two CDF's to maximize the number of crossings,,"So suppose I have two continuous, monotone increasing function $F$ and $G$ defined on an interval $I_F=\{x:0<F(x)<1\}=(l_F,u_F)$ and $I_G=\{x:0<G(x)<1\}=(l_G,u_G)$ which can be computed but don't have an analytical form.$(l_G,u_G)$ and $(l_F,u_F)$, however, are known. Consider the function: $$M=\max_{a\in I_A}S(F,G,a)$$ --where $S(F,G,a)$ counts the number of times $F(x)$ and $G(x+a)$ cross-- Given $F$ and $G$ and $I_A$, I would like to know if $M>1$. The issue is that $F(x)$ and $G(x+a)$  are very expensive to evaluate. What I mean is computing $F$ and $G$ for a grid of values of $x$ on $I_F$ and $I_G$ is do-able but trying all values of $G(x+a)$ for all shifts $a\in I_A$ (the naive solution) is definitely not. What is the smart way to approach this problem? P.S.: @Modo: if you think this is not the correct venue to ask this type of question, please let me know and I will try to find a better place. Thanks in advance!","So suppose I have two continuous, monotone increasing function $F$ and $G$ defined on an interval $I_F=\{x:0<F(x)<1\}=(l_F,u_F)$ and $I_G=\{x:0<G(x)<1\}=(l_G,u_G)$ which can be computed but don't have an analytical form.$(l_G,u_G)$ and $(l_F,u_F)$, however, are known. Consider the function: $$M=\max_{a\in I_A}S(F,G,a)$$ --where $S(F,G,a)$ counts the number of times $F(x)$ and $G(x+a)$ cross-- Given $F$ and $G$ and $I_A$, I would like to know if $M>1$. The issue is that $F(x)$ and $G(x+a)$  are very expensive to evaluate. What I mean is computing $F$ and $G$ for a grid of values of $x$ on $I_F$ and $I_G$ is do-able but trying all values of $G(x+a)$ for all shifts $a\in I_A$ (the naive solution) is definitely not. What is the smart way to approach this problem? P.S.: @Modo: if you think this is not the correct venue to ask this type of question, please let me know and I will try to find a better place. Thanks in advance!",,"['probability', 'numerical-methods']"
61,Impact of weight of the dice,Impact of weight of the dice,,"If you throw a 6-sided die there is a probability of 1/6 to throw any specific value. However, this assumes that dice are exactly symmetrical, and we all know that they are not, in reality. Let's assume that the sides with more eyes weigh less , because the eyes are carved in the surface of the dice. Would that mean that the probability of throwing a 6 becomes bigger ? At first sight, that seems to make sense, because the heavier side of the dice is impacted more by gravity . On the other hand, while the die makes a circular movement through the air, the heavier side is more likely to hit ground first . Assuming that a dice always roles after hitting the ground, that again makes it just a little less likely to actually finish in the position that it landed at. So, do you think that weight increases/decreases the probability ?","If you throw a 6-sided die there is a probability of 1/6 to throw any specific value. However, this assumes that dice are exactly symmetrical, and we all know that they are not, in reality. Let's assume that the sides with more eyes weigh less , because the eyes are carved in the surface of the dice. Would that mean that the probability of throwing a 6 becomes bigger ? At first sight, that seems to make sense, because the heavier side of the dice is impacted more by gravity . On the other hand, while the die makes a circular movement through the air, the heavier side is more likely to hit ground first . Assuming that a dice always roles after hitting the ground, that again makes it just a little less likely to actually finish in the position that it landed at. So, do you think that weight increases/decreases the probability ?",,"['probability', 'physics']"
62,Formula for the variance of a renewal process,Formula for the variance of a renewal process,,"Let $N(t)$ be a renewal process, with a sequence of IID inter-arrival times $X_{1}, X_{2}, \dots$ having finite second moment: $EX_{i}^{2} < \infty$. How would I show that $$\mathrm{Var}N(t)= 2 \int^{t}_{0} m(t-s) \cdot m'(s)ds + m(t) - m(t)^{2}$$ where $m(t) = E[N(t)]$ and can be written $m(t) = F(t) + \int_{0}^{t} m(t-x)f(x)dx$ where $f$ is the density of the inter-arrival times and $F$ is the CDF. I'd just like to know how this works out since I'm weak in computation. I've tried using the usual identity for variance, but I didn't know if that would lead anywhere.","Let $N(t)$ be a renewal process, with a sequence of IID inter-arrival times $X_{1}, X_{2}, \dots$ having finite second moment: $EX_{i}^{2} < \infty$. How would I show that $$\mathrm{Var}N(t)= 2 \int^{t}_{0} m(t-s) \cdot m'(s)ds + m(t) - m(t)^{2}$$ where $m(t) = E[N(t)]$ and can be written $m(t) = F(t) + \int_{0}^{t} m(t-x)f(x)dx$ where $f$ is the density of the inter-arrival times and $F$ is the CDF. I'd just like to know how this works out since I'm weak in computation. I've tried using the usual identity for variance, but I didn't know if that would lead anywhere.",,"['probability', 'stochastic-processes', 'renewal-processes']"
63,Joint distribution of range $(R=X_n-X_1)$ and mid-range $(V=\frac{1}{2}(X_1+X_n))$ order statistics,Joint distribution of range  and mid-range  order statistics,(R=X_n-X_1) (V=\frac{1}{2}(X_1+X_n)),"Let $X_1,X_2, \ldots , X_n$ be independent and identically distributed Uniform random variables on the interval (0, a) for a > 0, each having a density function $f(x) = \frac{1}{a}$, $0<x<a$. Let $X_{(1)},X_{(2)}, \ldots , X_{(n)}$ denote the order statistics. The range of the data is defined as $R = X_{(n)}−X_{(1)}$ and the midrange is defined as $V = \frac{1}{2}(X_{(1)}+X_{(n)})$ Derive the joint distribution of $(R, V )$ and deduce the marginal distributions of $R$ and $V.$ Attempt: First I am attempting to generate the joint distribution of $(V,X_{(1)})$ and then integrate out the $X_{(1)}$. For the joint distribution of $(V,X_{(1)})$ I have: $$ f_{v,x_{(1)}}(v,x_{(1)})=2n(n-1)\int_{-\infty}^v [F(2v-x_{(1)})-F(x_{(1)})]^{n-2} f(2v-x_{(1)})f(x_{(1)}) \, dx_{(1)}$$ At this point I have no idea how to integrate out the $x_{(1)}$. Edit: I have located the joint distribution of the range and mid-range: $$ f_{r,v}(r,v) = n(n-1) \left[F\left(v+\frac{r}{2}\right) - \left(F\left(v-\frac{r}{2}\right)\right)\right]^{n-2} f\left(v-\frac r 2 \right) f(v+\frac{r}{2})$$ For each marginal distribution, I have to integrate out: $$ f_r(r) = \int_{-\infty}^\infty n(n-1)[F(v+\frac{r}{2})-(F(v-\frac{r}{2})]^{n-2}f(v-\frac{r}{2})f(v+\frac{r}{2}) \, dv$$ $$ f_v(v) = \int_0^{\infty}n(n-1)[F(v+\frac{r}{2})-(F(v-\frac{r}{2})]^{n-2}f(v-\frac{r}{2})f(v+\frac{r}{2}) \, dr$$","Let $X_1,X_2, \ldots , X_n$ be independent and identically distributed Uniform random variables on the interval (0, a) for a > 0, each having a density function $f(x) = \frac{1}{a}$, $0<x<a$. Let $X_{(1)},X_{(2)}, \ldots , X_{(n)}$ denote the order statistics. The range of the data is defined as $R = X_{(n)}−X_{(1)}$ and the midrange is defined as $V = \frac{1}{2}(X_{(1)}+X_{(n)})$ Derive the joint distribution of $(R, V )$ and deduce the marginal distributions of $R$ and $V.$ Attempt: First I am attempting to generate the joint distribution of $(V,X_{(1)})$ and then integrate out the $X_{(1)}$. For the joint distribution of $(V,X_{(1)})$ I have: $$ f_{v,x_{(1)}}(v,x_{(1)})=2n(n-1)\int_{-\infty}^v [F(2v-x_{(1)})-F(x_{(1)})]^{n-2} f(2v-x_{(1)})f(x_{(1)}) \, dx_{(1)}$$ At this point I have no idea how to integrate out the $x_{(1)}$. Edit: I have located the joint distribution of the range and mid-range: $$ f_{r,v}(r,v) = n(n-1) \left[F\left(v+\frac{r}{2}\right) - \left(F\left(v-\frac{r}{2}\right)\right)\right]^{n-2} f\left(v-\frac r 2 \right) f(v+\frac{r}{2})$$ For each marginal distribution, I have to integrate out: $$ f_r(r) = \int_{-\infty}^\infty n(n-1)[F(v+\frac{r}{2})-(F(v-\frac{r}{2})]^{n-2}f(v-\frac{r}{2})f(v+\frac{r}{2}) \, dv$$ $$ f_v(v) = \int_0^{\infty}n(n-1)[F(v+\frac{r}{2})-(F(v-\frac{r}{2})]^{n-2}f(v-\frac{r}{2})f(v+\frac{r}{2}) \, dr$$",,"['probability', 'statistics', 'probability-distributions', 'uniform-distribution', 'order-statistics']"
64,probability of collision with randomly generated ID,probability of collision with randomly generated ID,,"Reworded: If 10,000 events occur each second, and each event needs a unique ID, how many random bits does each ID require to insure collisions are minimized? $10,000$ events could occur near the same time, so the time stamp is not sufficient for a unique ID.  I want to add a number of random bits (but not too many) to make collisions unlikely.  This sounds like the birthday paradox problem. If I add $12$-bits of randomness, that too low because $10,000$ events into $4096$ boxes must have some duplicates. If I add $18$-bits of randomness, $$p()=1-\left(\frac{262143}{262144}\right)^{(10000(10000-1))/2)} = 100 \%$$ If I add $24$-bits of randomness, $$p()=1-\left(\frac{16777215}{16777216}\right)^{10000(10000-1))/2} = 94.9 \%$$ Did I do this right? My math sense expects this to be more than enough, since each event has $1677$ possible places to go without collision. At $32$ bits, there is a $1.1\%$ chance, and at $36$ bits the probability of a collision is $727$ parts per million. I am starting to understand why the standard UUID generators use $128$ bits. What do you think?","Reworded: If 10,000 events occur each second, and each event needs a unique ID, how many random bits does each ID require to insure collisions are minimized? $10,000$ events could occur near the same time, so the time stamp is not sufficient for a unique ID.  I want to add a number of random bits (but not too many) to make collisions unlikely.  This sounds like the birthday paradox problem. If I add $12$-bits of randomness, that too low because $10,000$ events into $4096$ boxes must have some duplicates. If I add $18$-bits of randomness, $$p()=1-\left(\frac{262143}{262144}\right)^{(10000(10000-1))/2)} = 100 \%$$ If I add $24$-bits of randomness, $$p()=1-\left(\frac{16777215}{16777216}\right)^{10000(10000-1))/2} = 94.9 \%$$ Did I do this right? My math sense expects this to be more than enough, since each event has $1677$ possible places to go without collision. At $32$ bits, there is a $1.1\%$ chance, and at $36$ bits the probability of a collision is $727$ parts per million. I am starting to understand why the standard UUID generators use $128$ bits. What do you think?",,['probability']
65,Number of dice rolls taken to reach a certain sum,Number of dice rolls taken to reach a certain sum,,"I was reading about sums of dice rolls and Chernoff bounds, and I thought of a question I couldn't obviously answer with the techniques I know. You're given some number $x$ and told it was generated by summing subsequent (I.I.D.) rolls of an $n$-sided die, where the sides are numbered $1, 2, ..., n$. Let $X$ be a random variable representing the number of rolls that were summed. What do we know about the distribution of $X$? Can we analyze it using Chernoff bounds? To make it more concrete, say you're given the number 36 and told it is the sum of rolls of a standard six-sided die. It's very unlikely that it took 36 rolls for the sum to be 36 (the probability of 36 '1's in a row) and it's similarly unlikely that it only took six rolls (six '6's in a row - interestingly this is much more likely than the other extreme). Thanks very much for your help.","I was reading about sums of dice rolls and Chernoff bounds, and I thought of a question I couldn't obviously answer with the techniques I know. You're given some number $x$ and told it was generated by summing subsequent (I.I.D.) rolls of an $n$-sided die, where the sides are numbered $1, 2, ..., n$. Let $X$ be a random variable representing the number of rolls that were summed. What do we know about the distribution of $X$? Can we analyze it using Chernoff bounds? To make it more concrete, say you're given the number 36 and told it is the sum of rolls of a standard six-sided die. It's very unlikely that it took 36 rolls for the sum to be 36 (the probability of 36 '1's in a row) and it's similarly unlikely that it only took six rolls (six '6's in a row - interestingly this is much more likely than the other extreme). Thanks very much for your help.",,"['probability', 'probability-theory', 'dice']"
66,Random Triangle Inscribed in a Circular Sector,Random Triangle Inscribed in a Circular Sector,,"Lately, I have been thinking about expected area and perimeter of a triangle inscribed in a 'partial' circle or circular sector with radius $r$ and truth be told, I couldn't answer these questions. I hope someone here could give me a good answer. Let's say circular sector as $\frac{2\pi}{n}$ circle for $n\in\mathbb{N}$. My questions are: What is expected area and perimeter of a triangle inscribed in a circular sector with radius $r$, where one of its vertex lies on center of the circular sector and the other vertexs are uniformly, independently, and randomly drawn inside the circular sector. What is expected area and perimeter of a triangle inscribed in a circular sector with radius $r$, where one of its vertex lies on center of the circular sector and the other vertexs are uniformly, independently, and randomly drawn along the circumference/ perimeter circular sector. My approach for the first one is (based on Wolfram MathWorld ): $$ \begin{align} \text{E}[A]&=\int_0^r\int_0^r\int_0^{\frac{2\pi}{n}}\int_0^{\theta_1}A(r_1,r_2,\theta_1,\theta_2)\cdot f(r_1,r_2,\theta_1,\theta_2)\,d\theta_1d\theta_2dr_1dr_2\\ &=\int_0^r\int_0^r\int_0^{\frac{2\pi}{n}}\int_0^{\theta_1}\frac{1}{2}\left|\sqrt{r_1r_2}\sin(\theta_1-\theta_2)\right|\cdot \left(\frac{n}{2\pi r}\right)^2\,d\theta_1d\theta_2dr_1dr_2\\ &=\frac{1}{8}\left(\frac{n}{\pi r}\right)^2\int_0^r\int_0^r\int_0^{\frac{2\pi}{n}}\int_0^{\theta_1}\left|\sqrt{r_1r_2}\sin(\theta_1-\theta_2)\right|\,d\theta_1d\theta_2dr_1dr_2,\\ \end{align} $$ where $$ \begin{align} f(r_1,r_2,\theta_1,\theta_2)&=f(r_1)\cdot f(r_2)\cdot f(\theta_1)\cdot f(\theta_2)\\ &=\frac{1}{(r-0)}\cdot\frac{1}{(r-0)}\cdot\frac{1}{\left(\frac{2\pi}{n}-0\right)}\cdot\frac{1}{\left(\frac{2\pi}{n}-0\right)}\\ &=\left(\frac{n}{2\pi r}\right)^2. \end{align} $$ But I didn't quite sure about that especially for the integral limits and the pdf $f(r_1,r_2,\theta_1,\theta_2)$. For the expected perimeter and the second one question, I don't have any idea. Could someone here provide me answers about these problems? I'd be grateful for any help you are able to provide.","Lately, I have been thinking about expected area and perimeter of a triangle inscribed in a 'partial' circle or circular sector with radius $r$ and truth be told, I couldn't answer these questions. I hope someone here could give me a good answer. Let's say circular sector as $\frac{2\pi}{n}$ circle for $n\in\mathbb{N}$. My questions are: What is expected area and perimeter of a triangle inscribed in a circular sector with radius $r$, where one of its vertex lies on center of the circular sector and the other vertexs are uniformly, independently, and randomly drawn inside the circular sector. What is expected area and perimeter of a triangle inscribed in a circular sector with radius $r$, where one of its vertex lies on center of the circular sector and the other vertexs are uniformly, independently, and randomly drawn along the circumference/ perimeter circular sector. My approach for the first one is (based on Wolfram MathWorld ): $$ \begin{align} \text{E}[A]&=\int_0^r\int_0^r\int_0^{\frac{2\pi}{n}}\int_0^{\theta_1}A(r_1,r_2,\theta_1,\theta_2)\cdot f(r_1,r_2,\theta_1,\theta_2)\,d\theta_1d\theta_2dr_1dr_2\\ &=\int_0^r\int_0^r\int_0^{\frac{2\pi}{n}}\int_0^{\theta_1}\frac{1}{2}\left|\sqrt{r_1r_2}\sin(\theta_1-\theta_2)\right|\cdot \left(\frac{n}{2\pi r}\right)^2\,d\theta_1d\theta_2dr_1dr_2\\ &=\frac{1}{8}\left(\frac{n}{\pi r}\right)^2\int_0^r\int_0^r\int_0^{\frac{2\pi}{n}}\int_0^{\theta_1}\left|\sqrt{r_1r_2}\sin(\theta_1-\theta_2)\right|\,d\theta_1d\theta_2dr_1dr_2,\\ \end{align} $$ where $$ \begin{align} f(r_1,r_2,\theta_1,\theta_2)&=f(r_1)\cdot f(r_2)\cdot f(\theta_1)\cdot f(\theta_2)\\ &=\frac{1}{(r-0)}\cdot\frac{1}{(r-0)}\cdot\frac{1}{\left(\frac{2\pi}{n}-0\right)}\cdot\frac{1}{\left(\frac{2\pi}{n}-0\right)}\\ &=\left(\frac{n}{2\pi r}\right)^2. \end{align} $$ But I didn't quite sure about that especially for the integral limits and the pdf $f(r_1,r_2,\theta_1,\theta_2)$. For the expected perimeter and the second one question, I don't have any idea. Could someone here provide me answers about these problems? I'd be grateful for any help you are able to provide.",,"['probability', 'geometry', 'expectation', 'geometric-probability']"
67,Thinning a Poisson Process,Thinning a Poisson Process,,"Suppose that events are produced according to a Poisson process with an average of lambda events per minute. Each event has a probability $p$ of being Type A event, independent of other events. Let the random variable $Y$ represent the number of Type A events that occur in a one-minute period. Prove that $Y$ has a Poisson distribution with mean $\lambda p$. I read over it and I feel like I'm missing something because I still see it as having the mean as lambda not $\lambda p$.","Suppose that events are produced according to a Poisson process with an average of lambda events per minute. Each event has a probability $p$ of being Type A event, independent of other events. Let the random variable $Y$ represent the number of Type A events that occur in a one-minute period. Prove that $Y$ has a Poisson distribution with mean $\lambda p$. I read over it and I feel like I'm missing something because I still see it as having the mean as lambda not $\lambda p$.",,['probability']
68,Probability of equality mod p,Probability of equality mod p,,"Consider two positive integers $x \ne y$  and let  $n = max\{\lfloor \log_2{x} \rfloor +1 ,\lfloor \log_2{y} \rfloor +1 \}$.  Choose a prime $p$ randomly from the first $3n$ primes.   What is the probability that $x \bmod p = y \bmod p$? I believe it is at most $1/3$. My reasoning is that there are only $n$ primes at most for which $x \bmod p = y \bmod p$.  Does this make sense and is there a self contained proof?","Consider two positive integers $x \ne y$  and let  $n = max\{\lfloor \log_2{x} \rfloor +1 ,\lfloor \log_2{y} \rfloor +1 \}$.  Choose a prime $p$ randomly from the first $3n$ primes.   What is the probability that $x \bmod p = y \bmod p$? I believe it is at most $1/3$. My reasoning is that there are only $n$ primes at most for which $x \bmod p = y \bmod p$.  Does this make sense and is there a self contained proof?",,"['probability', 'elementary-number-theory']"
69,Sums of Products of Two Normal Variables,Sums of Products of Two Normal Variables,,"Suppose that $X_1 ,\ldots,X_n,Y_1,\ldots,Y_n$ are all independent normal random variables with different means and variances. What is the PDF of the following random variable? $$X_1Y_1+\cdots+X_nY_n$$ or is there any way that I can find an approximation for its PDF?","Suppose that $X_1 ,\ldots,X_n,Y_1,\ldots,Y_n$ are all independent normal random variables with different means and variances. What is the PDF of the following random variable? $$X_1Y_1+\cdots+X_nY_n$$ or is there any way that I can find an approximation for its PDF?",,"['probability', 'probability-theory', 'probability-distributions', 'normal-distribution', 'random-variables']"
70,At least two people have the same birthday,At least two people have the same birthday,,"If there are 85 students in a statistics class and we assume that there are 365 days in a year, what is the probability that at least two students in the class have the same birthday? I tried solving it by taking into account the fact that it will be extremely difficult to solve for the probability of at least having the same birthday and started off by solving it in the complement fashion, where P(at least two people having the same birthday) = 1 - P(every person's birthday is unique), but have been trying to the possible numerator/denominator for this problem.","If there are 85 students in a statistics class and we assume that there are 365 days in a year, what is the probability that at least two students in the class have the same birthday? I tried solving it by taking into account the fact that it will be extremely difficult to solve for the probability of at least having the same birthday and started off by solving it in the complement fashion, where P(at least two people having the same birthday) = 1 - P(every person's birthday is unique), but have been trying to the possible numerator/denominator for this problem.",,"['probability', 'permutations', 'birthday']"
71,"Randomly selected subset, expected value of the sum","Randomly selected subset, expected value of the sum",,"Interesting problem I spotted while learning: Let $X=\left\{1,..,n\right\}$ . We randomly select subset of $X$ and name it $A$ . Each subset if equally likely. a) Find the expected value of the sum of elements of A. b) Find the expected value of the sum of elements of A, on condition that it has $k$ elements. a) I think I know how to solve a). If each subset is selected with the same probability then I think it is equivalent to selecting each element of $X$ with probability $\frac{1}{2}$ . So, using indicators, we got that expected value we are looking for is $\frac{n(n+1)}{4}$ . But I can't find any rigorous argument why it is equivalent to selecting each element with probability $1/2$ . b) Small observation with $k=1$ (each element selected with probability $1/n$ ) and $k=n$ (each element selected with probability $1$ ) gives me feeling that approach from a) can be used with probability $k/n$ and then the result is $\frac{k(n+1)}{2}$ . But it is much less intuitive than observation in a). No idea, how to prove this. Can anyone help?","Interesting problem I spotted while learning: Let . We randomly select subset of and name it . Each subset if equally likely. a) Find the expected value of the sum of elements of A. b) Find the expected value of the sum of elements of A, on condition that it has elements. a) I think I know how to solve a). If each subset is selected with the same probability then I think it is equivalent to selecting each element of with probability . So, using indicators, we got that expected value we are looking for is . But I can't find any rigorous argument why it is equivalent to selecting each element with probability . b) Small observation with (each element selected with probability ) and (each element selected with probability ) gives me feeling that approach from a) can be used with probability and then the result is . But it is much less intuitive than observation in a). No idea, how to prove this. Can anyone help?","X=\left\{1,..,n\right\} X A k X \frac{1}{2} \frac{n(n+1)}{4} 1/2 k=1 1/n k=n 1 k/n \frac{k(n+1)}{2}",['probability']
72,What is this operation on random variables called?,What is this operation on random variables called?,,"Let $X$ be a random variable and let $N$ be a discrete random variable which takes values in the non-negative integers. Let $X_1, X_2, ...$ be a sequence of i.i.d. random variables with the same distribution as $X$, all of which are also independent of $N$. Is there a name for the random variable $$Y = X_1 + X_2 + ... + X_N?$$ The only hint I've found is that this appears to be what actuaries call the aggregate risk model. One reason I ask is that there is a very nice expression for the cumulant generating function $C_Y$ of $Y$ in terms of the cumulant generating functions $C_X, C_N$ of $X, N$, namely $$C_Y = C_N \circ C_X.$$","Let $X$ be a random variable and let $N$ be a discrete random variable which takes values in the non-negative integers. Let $X_1, X_2, ...$ be a sequence of i.i.d. random variables with the same distribution as $X$, all of which are also independent of $N$. Is there a name for the random variable $$Y = X_1 + X_2 + ... + X_N?$$ The only hint I've found is that this appears to be what actuaries call the aggregate risk model. One reason I ask is that there is a very nice expression for the cumulant generating function $C_Y$ of $Y$ in terms of the cumulant generating functions $C_X, C_N$ of $X, N$, namely $$C_Y = C_N \circ C_X.$$",,"['probability', 'terminology', 'random-variables']"
73,Is there a way to check the correctness of your answer to a probability question?,Is there a way to check the correctness of your answer to a probability question?,,"In CS, there's a systematic way to check if your code is buggy or not as you write code. Is there a way to check the correctness of your answer to a probability question without using a textbook? For example, my friend proposed a solution to a probability question that seemed right. Question: Suppose that each of N men at a party throws his hat into the center of the room. The hats are first mixed up, and then each man randomly selects a hat. What is the probability that none of the men selects his own hat? Proposed Solution: if we suppose there are 8 men, then the suggestionw as (7 / 8) * (6 / 7) * (5 /6 )... * (1/2) * 1 which for the n case simplifies to 1/n The argument sounded reasonable, but the answer was wrong which I found out from the textbook. I had to think about it a bit before I realized he had undercounted. Is there a more systematic way to check answers for probability questions?","In CS, there's a systematic way to check if your code is buggy or not as you write code. Is there a way to check the correctness of your answer to a probability question without using a textbook? For example, my friend proposed a solution to a probability question that seemed right. Question: Suppose that each of N men at a party throws his hat into the center of the room. The hats are first mixed up, and then each man randomly selects a hat. What is the probability that none of the men selects his own hat? Proposed Solution: if we suppose there are 8 men, then the suggestionw as (7 / 8) * (6 / 7) * (5 /6 )... * (1/2) * 1 which for the n case simplifies to 1/n The argument sounded reasonable, but the answer was wrong which I found out from the textbook. I had to think about it a bit before I realized he had undercounted. Is there a more systematic way to check answers for probability questions?",,"['probability', 'statistics']"
74,Show that $P(X+Y+Z\text{ is a multiple of }3)\ge 1/4$,Show that,P(X+Y+Z\text{ is a multiple of }3)\ge 1/4,"Suppose a box contains tickets, each labeled by an integer. Let $X,Y$ and $Z$ be the results of draws at random with replacement from thw box. Show that no matter what the distribution of numbers in the box, $$P(X+Y+Z\text{ is a multiple of }3)\ge 1/4\;.$$ Hint: think about remainders when dividing by 3","Suppose a box contains tickets, each labeled by an integer. Let $X,Y$ and $Z$ be the results of draws at random with replacement from thw box. Show that no matter what the distribution of numbers in the box, $$P(X+Y+Z\text{ is a multiple of }3)\ge 1/4\;.$$ Hint: think about remainders when dividing by 3",,['probability']
75,An inequality about binomial distribution,An inequality about binomial distribution,,"The question is: Consider $n$ Bernoulli trials, where for $i = 1, 2,..., n$, the $i$th trial has probability $p_i$ of success, and let $X$ be the random variable denoting the total number of successes. Let $ p \ge p_i$ for all $i = 1, 2, \ldots , n$. Prove that for $ 1 \le k \le n$, $$\Pr \{ X < k \} \ge \sum_{i=0}^{k-1}b(i; n, p)$$ I tried to use induction on $k$ but obviously it doesn't work.","The question is: Consider $n$ Bernoulli trials, where for $i = 1, 2,..., n$, the $i$th trial has probability $p_i$ of success, and let $X$ be the random variable denoting the total number of successes. Let $ p \ge p_i$ for all $i = 1, 2, \ldots , n$. Prove that for $ 1 \le k \le n$, $$\Pr \{ X < k \} \ge \sum_{i=0}^{k-1}b(i; n, p)$$ I tried to use induction on $k$ but obviously it doesn't work.",,['probability']
76,The down-cross probability of a general random walk,The down-cross probability of a general random walk,,"Let $\{X_t\}_{t=0,1,2\dots}$ be a random walk, defined by $X_0 = x$ and $$ X_{t+1} = X_0 + \sum_{\tau=1}^t q_\tau, $$ where $q_t$ is an iid random variable. We let $$ q_t = \begin{cases} a & \text{ w.p. }p\\ -b & \text{ w.p. }1-p \end{cases}, $$ where $\mathbb{E}[q_t]>0$ and $a,b>0$ . Thus, the state space is a continuum and this random walk has a positive drift. For $z < x$ , I want to compute the probability that $\{X_t\}$ does NOT down-cross $z$ . Intuitively, this probability is positive, because the process has a positive drift. At least, I'd like to show formally that this probability is indeed positive. I have no idea how to start. Resources I can find online or in textbooks deal with random walks on lattices, not on continuums. Since I cannot write a recursive equation for each state as in the countable state space case, I think I need to take a different approach from the case where $a,b\in\mathbb{Z}$ .","Let be a random walk, defined by and where is an iid random variable. We let where and . Thus, the state space is a continuum and this random walk has a positive drift. For , I want to compute the probability that does NOT down-cross . Intuitively, this probability is positive, because the process has a positive drift. At least, I'd like to show formally that this probability is indeed positive. I have no idea how to start. Resources I can find online or in textbooks deal with random walks on lattices, not on continuums. Since I cannot write a recursive equation for each state as in the countable state space case, I think I need to take a different approach from the case where .","\{X_t\}_{t=0,1,2\dots} X_0 = x 
X_{t+1} = X_0 + \sum_{\tau=1}^t q_\tau,
 q_t 
q_t = \begin{cases}
a & \text{ w.p. }p\\
-b & \text{ w.p. }1-p
\end{cases},
 \mathbb{E}[q_t]>0 a,b>0 z < x \{X_t\} z a,b\in\mathbb{Z}","['probability', 'stochastic-processes', 'random-walk']"
77,"Does ""Entropy"" explain why the Normal Distribution is so ""Popular""?","Does ""Entropy"" explain why the Normal Distribution is so ""Popular""?",,"Recently, I have learned about the Principle of Maximum Entropy with regards to Probability Distribution - in particular, when certain ""information"" (i.e. constraints) is available about some class of probability distribution function (e.g. domain over which the probability function is defined, expectation, etc.), we can use the principle of Maximum Entropy to determine the ""most informative"" probability distribution function from this class of probability distribution functions in this situation. Apparently, in many real world situations (e.g. when the data is continuous and can take any value between negative infinity and positive infinity) - the Normal Distribution ends up being the probability distribution function with the Maximum Entropy, thus often resulting in the ""most informative"" choice of probability distribution function when compared to any other candidate. My Question: Can this fact about the ""Maximum Entropy"" of the Normal Distribution corresponding to the ""most informative"" probability distribution function be used to explain its prevalence and popularity in statistics? Perhaps this ""most informativeness"" property of the normal distribution ""naturally"" resulted in ""more successful applications"" (e.g. real world statistical models with higher consistency, higher accuracy and lower variance) and in turn made it more ""popular""? Thanks!","Recently, I have learned about the Principle of Maximum Entropy with regards to Probability Distribution - in particular, when certain ""information"" (i.e. constraints) is available about some class of probability distribution function (e.g. domain over which the probability function is defined, expectation, etc.), we can use the principle of Maximum Entropy to determine the ""most informative"" probability distribution function from this class of probability distribution functions in this situation. Apparently, in many real world situations (e.g. when the data is continuous and can take any value between negative infinity and positive infinity) - the Normal Distribution ends up being the probability distribution function with the Maximum Entropy, thus often resulting in the ""most informative"" choice of probability distribution function when compared to any other candidate. My Question: Can this fact about the ""Maximum Entropy"" of the Normal Distribution corresponding to the ""most informative"" probability distribution function be used to explain its prevalence and popularity in statistics? Perhaps this ""most informativeness"" property of the normal distribution ""naturally"" resulted in ""more successful applications"" (e.g. real world statistical models with higher consistency, higher accuracy and lower variance) and in turn made it more ""popular""? Thanks!",,"['probability', 'statistics', 'optimization', 'soft-question', 'entropy']"
78,"Is $f:[a,b] \times \Omega \to E$ measurable?",Is  measurable?,"f:[a,b] \times \Omega \to E","Problem: Suppose that $[a,b] \subset \mathbb{R}$ , $(\Omega, \mathcal{F})$ is a measure space and $E$ is a topological space. Suppose $f : [a,b] \times \Omega \to E$ is such that: $\forall t$ $f(t, \cdot): \Omega \to E$ is measurable. (Here the $\sigma$ -fields of $E$ is the one generated by open sets) $\forall \omega \in \Omega$ $f(\cdot, \omega) : [a,b] \to E$ is right-continuous. How can I conclude that $f$ is $\mathcal{B}([a,b])\otimes\mathcal{F} - \mathcal{B}(E)$ measurable? Attempt: I tried in the following way. Let us define $f_n : [a,b] \times \Omega \to E$ in the following way, $f_n ([\frac{k}{n}, \frac{k+1}{n}), \omega)=f(\frac{k+1}{n}, \omega)$ for all $0 \leq k \leq n-1$ . Since $f_n$ is measurable in $[\frac{k}{n}, \frac{k+1}{n}) \times \Omega$ bye the first hypothesis on $f$ we get that $f_n$ is measurable and right-continuous. Now I noticed that $f_n$ point wise converge to $f$ . In fact we have that for a fixed $(t,\omega)$ we obtain $t\in [\frac{k}{n}, \frac{k+1}{n})$ and thus $f_n(t,\omega)=f(\frac{k+1}{n},\omega) \to f(t,\omega)$ by the fact that $f$ is right-continuous. Now I proved the following lemma: Lemma: if $(X, \mathcal{X})$ is a measure space and $E$ is a metric space we have that if $f_n : X \to E$ are measurable and point wise converge to $f$ that $f$ is measurable. Proof: If $A$ is an open set then: $$f^{-1}(A)=\bigcup\limits_{n} \bigcap\limits_{k \geq n} \{ x \in X: dist(f_k(x), A^c) > \frac 1 n \}$$ is a measurable set $\Box$ . Is this correct? Does this lemma hold also for general $E$ topological space? Are there different hypotheses to make on $E$ ?","Problem: Suppose that , is a measure space and is a topological space. Suppose is such that: is measurable. (Here the -fields of is the one generated by open sets) is right-continuous. How can I conclude that is measurable? Attempt: I tried in the following way. Let us define in the following way, for all . Since is measurable in bye the first hypothesis on we get that is measurable and right-continuous. Now I noticed that point wise converge to . In fact we have that for a fixed we obtain and thus by the fact that is right-continuous. Now I proved the following lemma: Lemma: if is a measure space and is a metric space we have that if are measurable and point wise converge to that is measurable. Proof: If is an open set then: is a measurable set . Is this correct? Does this lemma hold also for general topological space? Are there different hypotheses to make on ?","[a,b] \subset \mathbb{R} (\Omega, \mathcal{F}) E f : [a,b] \times \Omega \to E \forall t f(t, \cdot): \Omega \to E \sigma E \forall \omega \in \Omega f(\cdot, \omega) : [a,b] \to E f \mathcal{B}([a,b])\otimes\mathcal{F} - \mathcal{B}(E) f_n : [a,b] \times \Omega \to E f_n ([\frac{k}{n}, \frac{k+1}{n}), \omega)=f(\frac{k+1}{n}, \omega) 0 \leq k \leq n-1 f_n [\frac{k}{n}, \frac{k+1}{n}) \times \Omega f f_n f_n f (t,\omega) t\in [\frac{k}{n}, \frac{k+1}{n}) f_n(t,\omega)=f(\frac{k+1}{n},\omega) \to f(t,\omega) f (X, \mathcal{X}) E f_n : X \to E f f A f^{-1}(A)=\bigcup\limits_{n} \bigcap\limits_{k \geq n} \{ x \in X: dist(f_k(x), A^c) > \frac 1 n \} \Box E E","['probability', 'measure-theory', 'stochastic-processes', 'measurable-functions']"
79,What is the mode of a continuous random variable?,What is the mode of a continuous random variable?,,"Consider a ""discrete"" random variable $X$ . A mode of $X$ is just a maximizer of $P(X = x)$ . This is obviously useful, and we can easily see that a mode is a ""most likely"" value for $X$ . If, instead, we have a ""continuous"" real-valued random variable $X$ with a PDF $f_{X}$ , I think we usually define a mode of $X$ to be a maximizer of $f_{X}$ . I have two questions: How can we interpret the mode of a continuous random variable? In other words, why is the mode of a continuous random variable useful to probability theory? Some websites say that it is ""the value most likely to lie within the same interval as the outcome"", but I can't make sense of that. Some people point to the obvious geometric visualization of the mode (as the peak of the PDF) but I don't think that justifies the usefulness of the mode at all. Is there a more general definition of mode, removing the assumptions above that $X$ is real-valued and has a PDF?","Consider a ""discrete"" random variable . A mode of is just a maximizer of . This is obviously useful, and we can easily see that a mode is a ""most likely"" value for . If, instead, we have a ""continuous"" real-valued random variable with a PDF , I think we usually define a mode of to be a maximizer of . I have two questions: How can we interpret the mode of a continuous random variable? In other words, why is the mode of a continuous random variable useful to probability theory? Some websites say that it is ""the value most likely to lie within the same interval as the outcome"", but I can't make sense of that. Some people point to the obvious geometric visualization of the mode (as the peak of the PDF) but I don't think that justifies the usefulness of the mode at all. Is there a more general definition of mode, removing the assumptions above that is real-valued and has a PDF?",X X P(X = x) X X f_{X} X f_{X} X,"['probability', 'soft-question']"
80,We choose $5$ numbers from $1$ to $100$. We order them by value. What is the expected difference between the second and the third?,We choose  numbers from  to . We order them by value. What is the expected difference between the second and the third?,5 1 100,"I came across this peculiar problem. We choose $5$ numbers from $1$ to $100$ (with repetition). We order them in decreasing order by value. What is the expected difference between the second and the third? For example, we draw $6,67,89,45,33$ . Difference is $67-45=22$ .","I came across this peculiar problem. We choose numbers from to (with repetition). We order them in decreasing order by value. What is the expected difference between the second and the third? For example, we draw . Difference is .","5 1 100 6,67,89,45,33 67-45=22","['probability', 'probability-theory', 'expected-value', 'order-statistics']"
81,"Finding out if a sequence of digits is a ""numpad path""","Finding out if a sequence of digits is a ""numpad path""",,"I noticed that several of my old credit cards have verification codes which have an interesting property which I'll call ""numpathable"". A numpad is a graph that looks like this: 7 - 8 - 9 |   |   | 4 - 5 - 6 |   |   | 1 - 2 - 3 A number $n$ is a numpad path (or numpath , if you like) if its digits can be produced by moving along the edges of this graph, with at most one edge in between consecutive digits in $n$ . For example, $4556$ is a numpad path, as are $1$ , $12$ , and $123$ and $12321$ . $987456321$ is the largest number that's a numpad path without repeating any digits. However $4553$ isn't a numpad path, because you must traverse more than one edge between $5$ and $3$ . $1234$ is also not a numpad path for the same reason. Similarly, any number containing $0$ isn't a numpad path since $0$ doesn't appear on this graph. Q: What is the probability $P(d)$ that a random $d$ -digit number ( $d > 0$ ) is a numpad path? (Clearly, all 1 digit-numbers except 0 are numpad paths, so $P(1) = 0.9$ .) Edit: I previously called these ""numpad tours"", but a commenter pointed out that tours typically touch every node in a graph, so I've renamed it to numpad paths .","I noticed that several of my old credit cards have verification codes which have an interesting property which I'll call ""numpathable"". A numpad is a graph that looks like this: 7 - 8 - 9 |   |   | 4 - 5 - 6 |   |   | 1 - 2 - 3 A number is a numpad path (or numpath , if you like) if its digits can be produced by moving along the edges of this graph, with at most one edge in between consecutive digits in . For example, is a numpad path, as are , , and and . is the largest number that's a numpad path without repeating any digits. However isn't a numpad path, because you must traverse more than one edge between and . is also not a numpad path for the same reason. Similarly, any number containing isn't a numpad path since doesn't appear on this graph. Q: What is the probability that a random -digit number ( ) is a numpad path? (Clearly, all 1 digit-numbers except 0 are numpad paths, so .) Edit: I previously called these ""numpad tours"", but a commenter pointed out that tours typically touch every node in a graph, so I've renamed it to numpad paths .",n n 4556 1 12 123 12321 987456321 4553 5 3 1234 0 0 P(d) d d > 0 P(1) = 0.9,['probability']
82,Looking to optimise my Runescape grind (probability),Looking to optimise my Runescape grind (probability),,"I know there's gaming stackexchange for gaming questions, but I believe this is purely maths related. I'll try to avoid using game jargon and keep it simple. I'm collecting keys in game, each key taking a fair bit of time to obtain. They open a chest, which generates one random reward from a predeterimed table. On the loot table, there are five different armor pieces, each with a chance of 1/1000 to obtain. The catch is, because of game's inventory limitations, I can't open the chest every time I get a key and just get the five armor pieces that way - I have to do big openings of multiple keys at once. If I don't get a full set, but, for example, 4 out of 5 pieces, it would limit the speed of obtaining future keys. Which is why I would like to count an optimal amount of keys to have to get the full set at once. Is there a set method or a formula for similar problems? If the above explaination is too convoluted, I can try to further simplify it if needed.","I know there's gaming stackexchange for gaming questions, but I believe this is purely maths related. I'll try to avoid using game jargon and keep it simple. I'm collecting keys in game, each key taking a fair bit of time to obtain. They open a chest, which generates one random reward from a predeterimed table. On the loot table, there are five different armor pieces, each with a chance of 1/1000 to obtain. The catch is, because of game's inventory limitations, I can't open the chest every time I get a key and just get the five armor pieces that way - I have to do big openings of multiple keys at once. If I don't get a full set, but, for example, 4 out of 5 pieces, it would limit the speed of obtaining future keys. Which is why I would like to count an optimal amount of keys to have to get the full set at once. Is there a set method or a formula for similar problems? If the above explaination is too convoluted, I can try to further simplify it if needed.",,['probability']
83,"Flip a coin, but you lose when tails appears","Flip a coin, but you lose when tails appears",,"I have the following game: you flip a coin (heads with probability $p$ ), and if you get heads you earn $1000$ dollars, and you can decide if you want to flip again. If not, you keep the money. However, if you get tails, the game is over and you go home with nothing. I am having trouble calculating an optimal strategy for this game: I would like to maximize the winning amount by stopping at turn $f(p)$ , but... what is $f(p)$ ? If you did not lose all the money when tails appears, the expected winning value would just be a standard geometric distribution $\sum_{i=0}^\infty i p^{i-1} (1-p) = \frac{1}{1-p}$ , but I am having trouble evaluating the risk at each turn. Clearly never stopping is a good strategy only when $p=1$ , but intuitively when $p$ is very close to $1$ then stopping after the first win is not the best strategy. I am confused on how to model this phenomenon.","I have the following game: you flip a coin (heads with probability ), and if you get heads you earn dollars, and you can decide if you want to flip again. If not, you keep the money. However, if you get tails, the game is over and you go home with nothing. I am having trouble calculating an optimal strategy for this game: I would like to maximize the winning amount by stopping at turn , but... what is ? If you did not lose all the money when tails appears, the expected winning value would just be a standard geometric distribution , but I am having trouble evaluating the risk at each turn. Clearly never stopping is a good strategy only when , but intuitively when is very close to then stopping after the first win is not the best strategy. I am confused on how to model this phenomenon.",p 1000 f(p) f(p) \sum_{i=0}^\infty i p^{i-1} (1-p) = \frac{1}{1-p} p=1 p 1,['probability']
84,Mathematical reason behind exponential distribution in random shuffling of balls in boxes,Mathematical reason behind exponential distribution in random shuffling of balls in boxes,,"Let's take a very simple problem where 1000 identical boxes initially each have 10 balls. Then we select at random one box, take out a ball from it and put it into another box chosen again randomly. This algorithm repeated large number of times always give exponential distribution with most boxes being empty and only few with large number of balls. Sample code for problem illustration: import numpy as np   import matplotlib.pyplot as plt    box = np.ones(1000)   box = box*10   for i in range(100000):       rand = np.random.randint(low=0, high=1000, size=2)       if box[rand[0]] > 0:           box[rand[0]] = box[rand[0]] - 1           box[rand[1]] = box[rand[1]] + 1   #     print(box)   plt.hist(box,bins=50)   plt.show() Question: Probability of choosing a box is equal for any box, then can't we assume that in large number of trials, each box is chosen equal number of times for removal of ball and similarly each box is chosen equal number of times to add a ball to it? Why after a large repeated trials, the number of balls in each box does not reach equilibrium value 10. Why most of the boxes are emptied and only handful are filled with huge number of balls. This seems counter-intuitive. Is it something to do with the way random number generators are designed so we indeed get binomial distribution to imitate some physical behavior? Or there is a purely mathematical intuition behind?","Let's take a very simple problem where 1000 identical boxes initially each have 10 balls. Then we select at random one box, take out a ball from it and put it into another box chosen again randomly. This algorithm repeated large number of times always give exponential distribution with most boxes being empty and only few with large number of balls. Sample code for problem illustration: import numpy as np   import matplotlib.pyplot as plt    box = np.ones(1000)   box = box*10   for i in range(100000):       rand = np.random.randint(low=0, high=1000, size=2)       if box[rand[0]] > 0:           box[rand[0]] = box[rand[0]] - 1           box[rand[1]] = box[rand[1]] + 1   #     print(box)   plt.hist(box,bins=50)   plt.show() Question: Probability of choosing a box is equal for any box, then can't we assume that in large number of trials, each box is chosen equal number of times for removal of ball and similarly each box is chosen equal number of times to add a ball to it? Why after a large repeated trials, the number of balls in each box does not reach equilibrium value 10. Why most of the boxes are emptied and only handful are filled with huge number of balls. This seems counter-intuitive. Is it something to do with the way random number generators are designed so we indeed get binomial distribution to imitate some physical behavior? Or there is a purely mathematical intuition behind?",,"['probability', 'statistics']"
85,Probability for specific outcomes in fair die rolls,Probability for specific outcomes in fair die rolls,,"We roll a fair die n times. We are looking for the maximum n, for which, the probability that the maximum value that appears in all outcomes is 5, is >24%. At the beginning I thought that the probability would be $(\frac{5}{6})^n$ , that is, the probability for one particular number not to be included in the outcomes (6, in our case). But then I figured out that we could have also cases where some other numbers are missing, but 5 is still the largest of those that appear. Any ideas?","We roll a fair die n times. We are looking for the maximum n, for which, the probability that the maximum value that appears in all outcomes is 5, is >24%. At the beginning I thought that the probability would be , that is, the probability for one particular number not to be included in the outcomes (6, in our case). But then I figured out that we could have also cases where some other numbers are missing, but 5 is still the largest of those that appear. Any ideas?",(\frac{5}{6})^n,"['probability', 'combinatorics']"
86,Proof of Blumenthal's 0-1 law for Brownian Motion,Proof of Blumenthal's 0-1 law for Brownian Motion,,"I am currently reading the book ""Brownian Motion, Martingales, and Stochastic calculus"" by Jean-François Le Gall and am stuck at understanding the proof of Blumenthal's 0-1 law for Brownian Motion. The Setup is the following: Assume we have a one-dimensional Brownian $(B_t)_{t \geq 0}$ on some probability space $(\Omega, \mathcal{F}, P)$ . For $t \geq 0$ let $\mathcal{F}_t= \sigma(B_s: 0 \leq s \leq t)$ and define $\mathcal{F}_{0+}= \cap_{\epsilon > 0} \mathcal{F}_\epsilon$ . Then the following theorem holds. Theorem : The sigma-algebra $\mathcal{F}_{0+}$ is trivial in the sense that for all $A \in \mathcal{F}_{0+}$ , the probability of $A$ is either $0$ or $1$ . I will outline the proof that can be found in the book with the part I do not understand: Proof outline: Using $\cap$ -stable generators, it will be enough to proof that for all $n \in \mathbb{N}$ and $0 < t_1 < ... < t_n$ the sigma-algebra $\mathcal{F}_{0+}$ and $\sigma(B_{t_1},...,B_{t_n})$ are independent. Now let $g: \mathbb{R}^n \rightarrow \mathbb{R}$ be bounded and continuous and $A \in \mathcal{F}_{0+}$ . By continuity and dominated convergence we can write for $0 < \epsilon < t_1$ , $$ \begin{align} E [1_A g(B_{t_1},...,B_{t_n})] = \lim_{\epsilon \rightarrow 0} E [1_A g(B_{t_1} - B_\epsilon,...,B_{t_n}- B_\epsilon)]. \end{align} $$ Now by the simple Markov property of Brownian Motion, $(B_{t+\epsilon}-B_\epsilon)_{t \geq 0}$ is independent of $\mathcal{F}_\epsilon$ and thus we can continue to write the above to $$ \begin{align} \lim_{\epsilon \rightarrow 0} E [1_A g(B_{t_1} - B_\epsilon,...,B_{t_n}- B_\epsilon)] &= P(A) \lim_{\epsilon \rightarrow 0} E[g(B_{t_1} - B_\epsilon,...,B_{t_n}- B_\epsilon)] \\ &= P(A) E[g(B_{t_1},...,B_{t_n})]. \end{align} $$ This then should be enough to conclude independence. I do not know why this should suffice. If $g$ was allowed to be measurable, then it would be clear. But how does independence of $\mathcal{F}_{0+}$ and $\sigma(B_{t_1},...,B_{t_n})$ follow from $g$ only being bounded continuous? Thanks a lot in advance!","I am currently reading the book ""Brownian Motion, Martingales, and Stochastic calculus"" by Jean-François Le Gall and am stuck at understanding the proof of Blumenthal's 0-1 law for Brownian Motion. The Setup is the following: Assume we have a one-dimensional Brownian on some probability space . For let and define . Then the following theorem holds. Theorem : The sigma-algebra is trivial in the sense that for all , the probability of is either or . I will outline the proof that can be found in the book with the part I do not understand: Proof outline: Using -stable generators, it will be enough to proof that for all and the sigma-algebra and are independent. Now let be bounded and continuous and . By continuity and dominated convergence we can write for , Now by the simple Markov property of Brownian Motion, is independent of and thus we can continue to write the above to This then should be enough to conclude independence. I do not know why this should suffice. If was allowed to be measurable, then it would be clear. But how does independence of and follow from only being bounded continuous? Thanks a lot in advance!","(B_t)_{t \geq 0} (\Omega, \mathcal{F}, P) t \geq 0 \mathcal{F}_t= \sigma(B_s: 0 \leq s \leq t) \mathcal{F}_{0+}= \cap_{\epsilon > 0} \mathcal{F}_\epsilon \mathcal{F}_{0+} A \in \mathcal{F}_{0+} A 0 1 \cap n \in \mathbb{N} 0 < t_1 < ... < t_n \mathcal{F}_{0+} \sigma(B_{t_1},...,B_{t_n}) g: \mathbb{R}^n \rightarrow \mathbb{R} A \in \mathcal{F}_{0+} 0 < \epsilon < t_1 
\begin{align}
E [1_A g(B_{t_1},...,B_{t_n})] = \lim_{\epsilon \rightarrow 0} E [1_A g(B_{t_1} - B_\epsilon,...,B_{t_n}- B_\epsilon)].
\end{align}
 (B_{t+\epsilon}-B_\epsilon)_{t \geq 0} \mathcal{F}_\epsilon 
\begin{align}
\lim_{\epsilon \rightarrow 0} E [1_A g(B_{t_1} - B_\epsilon,...,B_{t_n}- B_\epsilon)] &= P(A) \lim_{\epsilon \rightarrow 0} E[g(B_{t_1} - B_\epsilon,...,B_{t_n}- B_\epsilon)] \\
&= P(A) E[g(B_{t_1},...,B_{t_n})].
\end{align}
 g \mathcal{F}_{0+} \sigma(B_{t_1},...,B_{t_n}) g","['probability', 'probability-theory', 'stochastic-processes', 'stochastic-calculus', 'brownian-motion']"
87,Minimizing the sum of KL divergences,Minimizing the sum of KL divergences,,"Given a list of probability distributions $q_i$ , what distribution $p$ minimizes the sum of KL divergences (if they exist) to and from each of them? That is, how do I determine $$\operatorname*{argmin}_p \sum_i D_\text{KL}(p \mathbin{\Vert} q_i)$$ and $$\operatorname*{argmin}_p \sum_i D_\text{KL}(q_i \mathbin{\Vert} p)$$ I recall reading somewhere that, in the Jensen-Shannon divergence, \begin{align*}   D_\text{JS}(p, q) &= \frac{D_\text{KL}(p \mathbin{\Vert} r) + D_\text{KL}(q \mathbin{\Vert} r)}{2} \\   r = &\frac{p + q}{2} \end{align*} The midpoint distribution $r$ is precisely $$r = \operatorname*{argmin}_s \frac{D_\text{KL}(p \mathbin{\Vert} s) + D_\text{KL}(q \mathbin{\Vert} s)}{2}$$ I can't find a reference for this, however.","Given a list of probability distributions , what distribution minimizes the sum of KL divergences (if they exist) to and from each of them? That is, how do I determine and I recall reading somewhere that, in the Jensen-Shannon divergence, The midpoint distribution is precisely I can't find a reference for this, however.","q_i p \operatorname*{argmin}_p \sum_i D_\text{KL}(p \mathbin{\Vert} q_i) \operatorname*{argmin}_p \sum_i D_\text{KL}(q_i \mathbin{\Vert} p) \begin{align*}
  D_\text{JS}(p, q) &= \frac{D_\text{KL}(p \mathbin{\Vert} r) + D_\text{KL}(q \mathbin{\Vert} r)}{2} \\
  r = &\frac{p + q}{2}
\end{align*} r r = \operatorname*{argmin}_s \frac{D_\text{KL}(p \mathbin{\Vert} s) + D_\text{KL}(q \mathbin{\Vert} s)}{2}","['probability', 'probability-distributions', 'reference-request']"
88,Expected number of balls to pick to select three balls of the same colour,Expected number of balls to pick to select three balls of the same colour,,"A bag contains 64 balls of eight different colours, with eight of each colour. What is the expected number of balls you would have to pick (without looking) to select three balls of the same colour?","A bag contains 64 balls of eight different colours, with eight of each colour. What is the expected number of balls you would have to pick (without looking) to select three balls of the same colour?",,"['probability', 'combinatorics', 'expectation']"
89,Where Gaussian Random Distribution came from?,Where Gaussian Random Distribution came from?,,"I'm studying an introduction to probability, and before the explanation of the Central Limit Theorem the author presents the Gaussian Normal Distribution. It has a complex and a non-intuitive formula, even if it's very important in the Probability field. Was the gaussian distribution found before the deduction of the CLT ? How was this distribution discovered ? And what are the properties that makes it so special ?","I'm studying an introduction to probability, and before the explanation of the Central Limit Theorem the author presents the Gaussian Normal Distribution. It has a complex and a non-intuitive formula, even if it's very important in the Probability field. Was the gaussian distribution found before the deduction of the CLT ? How was this distribution discovered ? And what are the properties that makes it so special ?",,"['probability', 'statistics']"
90,probability of getting the same number of tails,probability of getting the same number of tails,,"Alice tosses a fair coin $n$ independent times and Bob tosses a fair coin $m$ independent times. Find an elegant or clever argument to compute the probability that they have equal numbers of Tails.  It had better not involve any lengthy sums. The only way I can think of to approach this problem is to express the probability as a sum: $$\sum_{k = 1}^{\min(m, n)} P(\text{Alice gets $k$ tails})*P(\text{Bob gets $k$ tails}) \\ = \sum_{k = 1}^{\min(m, n)} \binom{n}{k} 0.5^n * \binom{m}{k} 0.5^m \\ = 0.5^{n + m}\sum_{k = 1}^{\min(m, n)} \binom{n}{k}\binom{m}{k} $$ However, I am not supposed to involve lengthy sums, but I cannot think of a more elegant way to solve this.","Alice tosses a fair coin $n$ independent times and Bob tosses a fair coin $m$ independent times. Find an elegant or clever argument to compute the probability that they have equal numbers of Tails.  It had better not involve any lengthy sums. The only way I can think of to approach this problem is to express the probability as a sum: $$\sum_{k = 1}^{\min(m, n)} P(\text{Alice gets $k$ tails})*P(\text{Bob gets $k$ tails}) \\ = \sum_{k = 1}^{\min(m, n)} \binom{n}{k} 0.5^n * \binom{m}{k} 0.5^m \\ = 0.5^{n + m}\sum_{k = 1}^{\min(m, n)} \binom{n}{k}\binom{m}{k} $$ However, I am not supposed to involve lengthy sums, but I cannot think of a more elegant way to solve this.",,['probability']
91,How to win in this game,How to win in this game,,"You select 10 numbers from the set $\{2,3,\dots,12\}$.  You then continually roll 2 fair dice and sum them up, until your selection of 10  numbers come up. For example if your selection was 7,7,7,7,8,8,8,6,6,6 (4 7's, 3 8's and 3 6's), and you roll the dice repeatedly and get 7,7,6,5,8,7,7,9,8,3,5,10,12,6,6,3,2,5,7,9,8, you may stop now because 4 7's have come up, 3 8's and 3 6's. What is the best choice of 10 numbers so as to minimise the number of rolls ?","You select 10 numbers from the set $\{2,3,\dots,12\}$.  You then continually roll 2 fair dice and sum them up, until your selection of 10  numbers come up. For example if your selection was 7,7,7,7,8,8,8,6,6,6 (4 7's, 3 8's and 3 6's), and you roll the dice repeatedly and get 7,7,6,5,8,7,7,9,8,3,5,10,12,6,6,3,2,5,7,9,8, you may stop now because 4 7's have come up, 3 8's and 3 6's. What is the best choice of 10 numbers so as to minimise the number of rolls ?",,"['probability', 'stochastic-processes', 'game-theory', 'dice']"
92,Linearity of expectation,Linearity of expectation,,"I understand the algebraic proof of the linearity of expectation, but I cannot grasp the intuition, especially when the random variables are not independent. It is even counterintuitive as you cannot simply add the probabilities of dependent random variables, but it does not affect on the expected value. Can anyone explain the intuition behind the algebraic formula? How to think about it?","I understand the algebraic proof of the linearity of expectation, but I cannot grasp the intuition, especially when the random variables are not independent. It is even counterintuitive as you cannot simply add the probabilities of dependent random variables, but it does not affect on the expected value. Can anyone explain the intuition behind the algebraic formula? How to think about it?",,"['probability', 'expectation']"
93,Suppose that each of $n$ men at a party throws his hat into the center of the room...,Suppose that each of  men at a party throws his hat into the center of the room...,n,Suppose that each of $n$ men at a party throws his hat into the center of the room. The hats are mixed up and then each man randomly selects a hat. What is the probability that at least one of the men selects his own hat?,Suppose that each of men at a party throws his hat into the center of the room. The hats are mixed up and then each man randomly selects a hat. What is the probability that at least one of the men selects his own hat?,n,"['probability', 'derangements']"
94,"Probability that the sum of $k$ distinct integers selected from $1, 2, \dots, n$ is divisible by $n$",Probability that the sum of  distinct integers selected from  is divisible by,"k 1, 2, \dots, n n","Would you please help me solve Problem 7 of Section 4.5, ""Combinatorial Number Theory,"" in An Introduction to the Theory of Numbers, Niven, Zuckerman, Montgomery, 5th ed., Wiley (New York), 1991: Let $n$ and $k$ be positive, relatively-prime integers with $n > k$ .  Prove that if $k$ distinct integers are selected at random from $1, 2, \dots, n$ , the probability that their sum is divisible by $n$ is $1/n$ . The authors describe three methods for solving combinatorial problems: (1) the pigeonhole principle, (2) the one-to-one correspondence procedure, in which elements in a finite set or between two sets are paired off to determine the number of elements, and (3) the inclusion-exclusion principle.  I know that the denominator of the probability fraction is $n \choose k$ , so I tried (without success) to use the second method to count the number of desired outcomes to be $(n - 1)!/((n - k)! k!)$ . Because $n$ and $k$ are relatively prime, I know that $n \choose k$ is divisible by $n$ .  In that case, numerical evidence suggests that the sum in question is uniformly distributed modulo $n$ .  If I can prove that conjecture, I am done. I found similar problems with particular values for $n$ and $k$ , but the solutions do not help me solve this general case.","Would you please help me solve Problem 7 of Section 4.5, ""Combinatorial Number Theory,"" in An Introduction to the Theory of Numbers, Niven, Zuckerman, Montgomery, 5th ed., Wiley (New York), 1991: Let and be positive, relatively-prime integers with .  Prove that if distinct integers are selected at random from , the probability that their sum is divisible by is . The authors describe three methods for solving combinatorial problems: (1) the pigeonhole principle, (2) the one-to-one correspondence procedure, in which elements in a finite set or between two sets are paired off to determine the number of elements, and (3) the inclusion-exclusion principle.  I know that the denominator of the probability fraction is , so I tried (without success) to use the second method to count the number of desired outcomes to be . Because and are relatively prime, I know that is divisible by .  In that case, numerical evidence suggests that the sum in question is uniformly distributed modulo .  If I can prove that conjecture, I am done. I found similar problems with particular values for and , but the solutions do not help me solve this general case.","n k n > k k 1, 2, \dots, n n 1/n n \choose k (n - 1)!/((n - k)! k!) n k n \choose k n n n k","['probability', 'combinatorial-number-theory']"
95,Probability that $\sin\theta \cos\phi < 0.999772$,Probability that,\sin\theta \cos\phi < 0.999772,I am solving a kinematics question in particle scattering. The final answers lies in finding the probability such that $$\sin\theta \cos\phi < 0.999772$$ The ranges of $\theta$ and $\phi$ are $0\leq\theta<\pi$ and $0\leq\phi<2\pi$.,I am solving a kinematics question in particle scattering. The final answers lies in finding the probability such that $$\sin\theta \cos\phi < 0.999772$$ The ranges of $\theta$ and $\phi$ are $0\leq\theta<\pi$ and $0\leq\phi<2\pi$.,,['probability']
96,There must exist a random variable with certain given law?,There must exist a random variable with certain given law?,,"Let $(\Omega,\mathcal F,\mathbb P)$ and $(E,\mathcal G,\mu)$ be two probability spaces . My question is the following: Measure-theoretically, is there exist a measurable mapping $X:(\Omega,\mathcal F)\to(E,\mathcal G)$ , such that $\mu$ is just the push-forward measure of $\mathbb P$ w.r.t $X$ , i.e., $\mu(A)=\mathbb P(X^{-1}(A))$ for $\forall A\in\mathcal G$ . Or equivalently in probability, is there exist a random variable $X:(\Omega,\mathcal F)\to(E,\mathcal G)$ , such that $\mu$ is just the law of $X$ . For stochastic processes, there is the well-known Kolmogorov extension theorem to guarantee the existence of stochastic processes for given finite-dimensional distributions. But for random variables, is there some theorem to guarantee the existence for given law? Any comments or references will be appreciated.","Let and be two probability spaces . My question is the following: Measure-theoretically, is there exist a measurable mapping , such that is just the push-forward measure of w.r.t , i.e., for . Or equivalently in probability, is there exist a random variable , such that is just the law of . For stochastic processes, there is the well-known Kolmogorov extension theorem to guarantee the existence of stochastic processes for given finite-dimensional distributions. But for random variables, is there some theorem to guarantee the existence for given law? Any comments or references will be appreciated.","(\Omega,\mathcal F,\mathbb P) (E,\mathcal G,\mu) X:(\Omega,\mathcal F)\to(E,\mathcal G) \mu \mathbb P X \mu(A)=\mathbb P(X^{-1}(A)) \forall A\in\mathcal G X:(\Omega,\mathcal F)\to(E,\mathcal G) \mu X","['probability', 'probability-theory', 'measure-theory', 'stochastic-processes']"
97,Why the probability distribution of a uniform random variable is the Lebesgue measure?,Why the probability distribution of a uniform random variable is the Lebesgue measure?,,"Consider the random variable $X$ defined on the probability space $(\Omega, \mathcal{F}, P)$ distributed as a uniform on $[0,1]$. The probability distribution function of $X$ is defined as a map $$ p:\mathcal{B}(\mathbb{R})\rightarrow [0,1] $$ such that, for any $E\in \mathcal{B}(\mathbb{R})$,  $$ p(E):=\mathbb{P}(X^{-1}(E)) $$ $p$ is a probability measure for $(\mathbb{R}, \mathcal{B}(\mathbb{R}))$ and $(\mathbb{R}, \mathcal{B}(\mathbb{R}), p)$ is a probability space. Let $\mu$ be the Lebesgue measure on $(\mathbb{R}, \mathcal{B}(\mathbb{R}))$. Why $p(E)=\mu(E)$ for any $E\subseteq [0,1]$? Is that by definition? My attempt which I think is wrong is that: the probability density function of $X$ is $$ f(t)=\begin{cases} 1 \text{ if $t$ $\in$ $[0,1]$}\\ 0 \text{ otherwise} \end{cases} $$ We know that $f$ is the probability density function of $X$ with respect to $\mu$ meaning that $$ f:=\frac{dp}{d\mu} $$ Is this somehow related with having $p(E)=\mu(E)$ for any $E\subseteq [0,1]$?","Consider the random variable $X$ defined on the probability space $(\Omega, \mathcal{F}, P)$ distributed as a uniform on $[0,1]$. The probability distribution function of $X$ is defined as a map $$ p:\mathcal{B}(\mathbb{R})\rightarrow [0,1] $$ such that, for any $E\in \mathcal{B}(\mathbb{R})$,  $$ p(E):=\mathbb{P}(X^{-1}(E)) $$ $p$ is a probability measure for $(\mathbb{R}, \mathcal{B}(\mathbb{R}))$ and $(\mathbb{R}, \mathcal{B}(\mathbb{R}), p)$ is a probability space. Let $\mu$ be the Lebesgue measure on $(\mathbb{R}, \mathcal{B}(\mathbb{R}))$. Why $p(E)=\mu(E)$ for any $E\subseteq [0,1]$? Is that by definition? My attempt which I think is wrong is that: the probability density function of $X$ is $$ f(t)=\begin{cases} 1 \text{ if $t$ $\in$ $[0,1]$}\\ 0 \text{ otherwise} \end{cases} $$ We know that $f$ is the probability density function of $X$ with respect to $\mu$ meaning that $$ f:=\frac{dp}{d\mu} $$ Is this somehow related with having $p(E)=\mu(E)$ for any $E\subseteq [0,1]$?",,"['probability', 'measure-theory', 'probability-distributions', 'lebesgue-measure', 'uniform-distribution']"
98,Monty Hall Problem extended,Monty Hall Problem extended,,"After seeing the popularity of the standard $3$ door problem, Monty thought to put a twist in the story. There are $N$ doors, $1$ car, $N-1$ goats. We need to choose any one of the doors. After we have chosen the door, Monty deliberately reveals one of the doors that has a goat and asks us if we wish to change our choice. After we decide our choice, Monty then again reveals one more door that has a goat and asks us if we wish to change our choice (both 1st and 2nd). This goes on. What strategy should we follow? Keep switching? And if we keep switching, is it okay to switch to some of the previous choices (provided they are still not revealed!!)","After seeing the popularity of the standard $3$ door problem, Monty thought to put a twist in the story. There are $N$ doors, $1$ car, $N-1$ goats. We need to choose any one of the doors. After we have chosen the door, Monty deliberately reveals one of the doors that has a goat and asks us if we wish to change our choice. After we decide our choice, Monty then again reveals one more door that has a goat and asks us if we wish to change our choice (both 1st and 2nd). This goes on. What strategy should we follow? Keep switching? And if we keep switching, is it okay to switch to some of the previous choices (provided they are still not revealed!!)",,"['probability', 'probability-theory', 'recreational-mathematics', 'puzzle', 'monty-hall']"
99,What does $-p \ln p$ mean if p is probability?,What does  mean if p is probability?,-p \ln p,"In statistical mechanics entropy is defined with the following relation: $$S=-k_B\sum_{i=1}^N p_i\ln p_i,$$ where $p_i$ is probability of occupying $i$th state, and $N$ is number of accessible states. I understand easily what probability is: for a frequentist it's just average frequency of getting this result. But I have a hard time trying to intuitively understand what $-p_i \ln p_i$ means. In the case where $p_i=p_j\; \forall i\ne j$ this reduces to $\ln N$, i.e. logarithm of number of accessible states. But in general case of unequal probabilities, what does $-p_i\ln p_i$ really represent? Is it some sort of ""(logarithm of) average number of accessible states""? Or maybe it's more useful to try to understand what $p_i^{p_i}$ is (but this seems even harder)?","In statistical mechanics entropy is defined with the following relation: $$S=-k_B\sum_{i=1}^N p_i\ln p_i,$$ where $p_i$ is probability of occupying $i$th state, and $N$ is number of accessible states. I understand easily what probability is: for a frequentist it's just average frequency of getting this result. But I have a hard time trying to intuitively understand what $-p_i \ln p_i$ means. In the case where $p_i=p_j\; \forall i\ne j$ this reduces to $\ln N$, i.e. logarithm of number of accessible states. But in general case of unequal probabilities, what does $-p_i\ln p_i$ really represent? Is it some sort of ""(logarithm of) average number of accessible states""? Or maybe it's more useful to try to understand what $p_i^{p_i}$ is (but this seems even harder)?",,"['probability', 'statistical-mechanics']"
