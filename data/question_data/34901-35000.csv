,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"For any events A,B,C is the following true?","For any events A,B,C is the following true?",,Is the following statement true? How? I'm having trouble seeing whether not it is true or false. $$P(A\mid B) = P(A\mid B \cap C)P(C\mid B) + P(A\mid B \cap C')P(C'\mid B)$$,Is the following statement true? How? I'm having trouble seeing whether not it is true or false. $$P(A\mid B) = P(A\mid B \cap C)P(C\mid B) + P(A\mid B \cap C')P(C'\mid B)$$,,['probability']
1,lower bound for the min function,lower bound for the min function,,"We all know the well known upper bound: $$ \min(a,b) \leq a^s b^{1-s}$$ for $$a,b \geq 0, 0 < s < 1$$ I am looking for a lower bound on $\min(a,b)$.","We all know the well known upper bound: $$ \min(a,b) \leq a^s b^{1-s}$$ for $$a,b \geq 0, 0 < s < 1$$ I am looking for a lower bound on $\min(a,b)$.",,"['real-analysis', 'probability', 'analysis', 'numerical-methods']"
2,Tail $\sigma$-algebra and transition invariant events.,Tail -algebra and transition invariant events.,\sigma,"I have the following exercise: Let $\Omega=\left\{0,1\right\}^{\infty}$ and $\mathcal{F}$ the cylynders sigma algebra on $\Omega$. The function $\varphi\left(\omega_1,\omega_2,\ldots\right)=\left(\omega_2,\omega_3,\ldots\right)$ defined on $\Omega$ is called a shift. An event $A\in\mathcal{F}$ is said to be shift invariant if $\varphi^{-1}\left(A\right)=A$. Let $\mathcal{C}$ be the class of shift-invariant events in $\mathcal{F}$. Show $\mathcal{C}$ is a sigma algebra. Let $A_n=\left\{\omega\in\Omega:\omega_n=1\right\}$. Show that $\mathcal{C}$ is not included in the tail sigma-algebra of $\left(A_n\right)_n$. Having been able to show that $\mathcal{C}$ is indeed a sigma-algebra and that it contains the events $\liminf_n A_n$ and $\limsup_n A_n$, I was not able to show the last point, i.e. I can't exhibit an event which is shift invariant but does not belong to the tail sigma-algebra. I would really appreciate a hint in order to visualize the problem better!","I have the following exercise: Let $\Omega=\left\{0,1\right\}^{\infty}$ and $\mathcal{F}$ the cylynders sigma algebra on $\Omega$. The function $\varphi\left(\omega_1,\omega_2,\ldots\right)=\left(\omega_2,\omega_3,\ldots\right)$ defined on $\Omega$ is called a shift. An event $A\in\mathcal{F}$ is said to be shift invariant if $\varphi^{-1}\left(A\right)=A$. Let $\mathcal{C}$ be the class of shift-invariant events in $\mathcal{F}$. Show $\mathcal{C}$ is a sigma algebra. Let $A_n=\left\{\omega\in\Omega:\omega_n=1\right\}$. Show that $\mathcal{C}$ is not included in the tail sigma-algebra of $\left(A_n\right)_n$. Having been able to show that $\mathcal{C}$ is indeed a sigma-algebra and that it contains the events $\liminf_n A_n$ and $\limsup_n A_n$, I was not able to show the last point, i.e. I can't exhibit an event which is shift invariant but does not belong to the tail sigma-algebra. I would really appreciate a hint in order to visualize the problem better!",,"['probability', 'measure-theory']"
3,Generalization of subsubsequence argument for stochastic convergence,Generalization of subsubsequence argument for stochastic convergence,,"It is well known that a sequence of random variables $(X_n)_{n\in\mathbb N}$ converges in probability to some random variable $X$ if and only if every subsequence $(X_{n_k})_{k\in\mathbb N}$ has a further subsubsequence $(X_{n_{k_l}})_{l\in\mathbb N}$ which converges almost surely to $X$. I am struggling with the following generalization: Consider a sequence of random variables $(X_n)_{n\in\mathbb N}$ and another random variable $X$ with the following property: Any subsequence $(X_{n_k})_{k\in\mathbb N}$ satisfies $$\liminf_{k\to\infty} X_{n_k} = X \quad\text{almost surely}.$$ Does $(X_n)_{n\in\mathbb N}$ converge in probability to $X$? I am struggling for the following reason: Since $\liminf$ is defined pathwise only, we cannot extract a (deterministic) subsequence which converges almost surely. Therefore, my assumption seems to be weaker in some sense. Are there any ideas for proving this statement or any counterexamples?","It is well known that a sequence of random variables $(X_n)_{n\in\mathbb N}$ converges in probability to some random variable $X$ if and only if every subsequence $(X_{n_k})_{k\in\mathbb N}$ has a further subsubsequence $(X_{n_{k_l}})_{l\in\mathbb N}$ which converges almost surely to $X$. I am struggling with the following generalization: Consider a sequence of random variables $(X_n)_{n\in\mathbb N}$ and another random variable $X$ with the following property: Any subsequence $(X_{n_k})_{k\in\mathbb N}$ satisfies $$\liminf_{k\to\infty} X_{n_k} = X \quad\text{almost surely}.$$ Does $(X_n)_{n\in\mathbb N}$ converge in probability to $X$? I am struggling for the following reason: Since $\liminf$ is defined pathwise only, we cannot extract a (deterministic) subsequence which converges almost surely. Therefore, my assumption seems to be weaker in some sense. Are there any ideas for proving this statement or any counterexamples?",,"['probability', 'probability-theory', 'convergence-divergence']"
4,Poisson Process - non-zero probability of more than one arrival,Poisson Process - non-zero probability of more than one arrival,,"Quoting Bertsekas' Introduction to Probability : An arrival process is called a Poisson process with rate $\lambda$ if   it has the following properties: a) Time homogenity - the probability $P(k,\tau)$ of $k$ arrivals is   the same for all intervals of the same length $\tau$ b) The number of arrivals during a particular interval is independent   of the history of arrivals outside this interval. c) Small interval probabilities - The probabilities $P(k,\tau)$   satisfy: $P(0,\tau)=1-\lambda\tau + o(\tau)$ $P(1,\tau)=\lambda\tau + o_1(\tau)$ $P(k,\tau)=o_k(\tau)$ for $k=2,3,...$ Here, $o(\tau)$ and $o_k(\tau)$ are functions of $\tau$ that satisfy $\mathbb{lim}_{r\to0}\frac{o(\tau)}{\tau}=0$,   $\mathbb{lim}_{r\to0}\frac{o_k(\tau)}{\tau}=0$ Then we are given the formula: $$P(k,\tau)=e^{-\lambda\tau}\frac{(\lambda\tau)^k}{k!}$$ Note that a Taylor series expansion of $e^{-\lambda\tau}$ yields: $P(0,\tau)=e^{-\lambda\tau}=1-\lambda\tau+o(\tau)$ $P(1,\tau)=\lambda\tau  e^{-\lambda\tau}=\lambda\tau-\lambda^2\tau^2+O(\tau^3)=\lambda\tau+o_1(\tau)$. First of all, what are $o(\tau)$, $o_1(\tau)$ and $O(\tau)$ in the Taylor expansion? Does it have anything to do with Taylor expansion per se? I thought that $o$ is the little-o notation, but its definition is quite different - $ f(n) = o(g(n))$ if $g(n)$ grows much faster than $f(n)$. In this case, it's quite different. Then what is it? Secondly, the author doesn't prove that the $o$ terms above satisfy $\mathbb{lim}_{r\to0}\frac{o(\tau)}{\tau}=0$,   $\mathbb{lim}_{r\to0}\frac{o_k(\tau)}{\tau}=0$ as stated in the definition of Poisson process. How can we prove it? Most importantly - why do we want it to satisfy the properties described in 'c) Small interval probabilities'? These 3 formulas are not arbitrary, there has to be a good reason for them. Ideally, if we let $\lambda \to 0$ and it's natural to expect that the probability $P(k,\tau)$ to equal exactly $0$ in the limit, but apparently it's not possible (there will always be that tiny number, $o_k(\tau)$). Or does it equal $0$ in the limit?","Quoting Bertsekas' Introduction to Probability : An arrival process is called a Poisson process with rate $\lambda$ if   it has the following properties: a) Time homogenity - the probability $P(k,\tau)$ of $k$ arrivals is   the same for all intervals of the same length $\tau$ b) The number of arrivals during a particular interval is independent   of the history of arrivals outside this interval. c) Small interval probabilities - The probabilities $P(k,\tau)$   satisfy: $P(0,\tau)=1-\lambda\tau + o(\tau)$ $P(1,\tau)=\lambda\tau + o_1(\tau)$ $P(k,\tau)=o_k(\tau)$ for $k=2,3,...$ Here, $o(\tau)$ and $o_k(\tau)$ are functions of $\tau$ that satisfy $\mathbb{lim}_{r\to0}\frac{o(\tau)}{\tau}=0$,   $\mathbb{lim}_{r\to0}\frac{o_k(\tau)}{\tau}=0$ Then we are given the formula: $$P(k,\tau)=e^{-\lambda\tau}\frac{(\lambda\tau)^k}{k!}$$ Note that a Taylor series expansion of $e^{-\lambda\tau}$ yields: $P(0,\tau)=e^{-\lambda\tau}=1-\lambda\tau+o(\tau)$ $P(1,\tau)=\lambda\tau  e^{-\lambda\tau}=\lambda\tau-\lambda^2\tau^2+O(\tau^3)=\lambda\tau+o_1(\tau)$. First of all, what are $o(\tau)$, $o_1(\tau)$ and $O(\tau)$ in the Taylor expansion? Does it have anything to do with Taylor expansion per se? I thought that $o$ is the little-o notation, but its definition is quite different - $ f(n) = o(g(n))$ if $g(n)$ grows much faster than $f(n)$. In this case, it's quite different. Then what is it? Secondly, the author doesn't prove that the $o$ terms above satisfy $\mathbb{lim}_{r\to0}\frac{o(\tau)}{\tau}=0$,   $\mathbb{lim}_{r\to0}\frac{o_k(\tau)}{\tau}=0$ as stated in the definition of Poisson process. How can we prove it? Most importantly - why do we want it to satisfy the properties described in 'c) Small interval probabilities'? These 3 formulas are not arbitrary, there has to be a good reason for them. Ideally, if we let $\lambda \to 0$ and it's natural to expect that the probability $P(k,\tau)$ to equal exactly $0$ in the limit, but apparently it's not possible (there will always be that tiny number, $o_k(\tau)$). Or does it equal $0$ in the limit?",,"['calculus', 'probability', 'taylor-expansion', 'poisson-distribution']"
5,An urn contains 2 white and 2 black balls. Balls are drawn successively at random without replacement.,An urn contains 2 white and 2 black balls. Balls are drawn successively at random without replacement.,,"An urn contains 2 white and 2 black balls. Balls are drawn successively  at random without replacement. What is the probability that black ball appears for the second time in the 4th draw? I am trying in this way : There can be 3 possibilities - a) B W W B b) W B W B c) W W B B for a) $$(\frac{2}{4}) * (\frac{2}{3}) * (\frac{1}{2}) * 1 $$ for b) and c) $$(\frac{2}{4}) * (\frac{2}{3}) * (\frac{1}{2}) * 1 $$ as well. So , it comes down to $$(\frac{1}{6}) * 3 = 0.5$$ Am I correct ?","An urn contains 2 white and 2 black balls. Balls are drawn successively  at random without replacement. What is the probability that black ball appears for the second time in the 4th draw? I am trying in this way : There can be 3 possibilities - a) B W W B b) W B W B c) W W B B for a) $$(\frac{2}{4}) * (\frac{2}{3}) * (\frac{1}{2}) * 1 $$ for b) and c) $$(\frac{2}{4}) * (\frac{2}{3}) * (\frac{1}{2}) * 1 $$ as well. So , it comes down to $$(\frac{1}{6}) * 3 = 0.5$$ Am I correct ?",,['probability']
6,Convolution of two Uniform random variables,Convolution of two Uniform random variables,,"We have $X \sim \mathrm{Unif}[0,2]$ and $Y \sim \mathrm{Unif}[3,4]$. The random variables $X,Y$ are independent. We define a random variable $Z = X + Y$ and want to find the PDF of $Z$ using convolution.  Here is my work so far: The definition of convolution is: $f_Z(z) = \int_{-\infty}^{\infty}f_X(x)f_Y(z-x)\mathrm{d} x$ We know the PDF's of $X$ and $Y$ because they are just uniform distributions. The hard part for me is finding the limits of integration. We have to solve for the constraints. The integrand is nonzero when $3 \leq z-x \leq 4$ and when $0 \leq x \leq 2$. Together these constraints imply that $\max \{0, z-4\} \leq x \leq \min \{2, z-3 \}$. These constraints imply that there are three cases: Case 1 - $z \leq 4 \implies f_Z(z) = \int_0^{z-3}$ Case 2 - $4 \leq z \leq 5 \implies f_Z(z) = \int_{z-4}^{z-3}$ Case 3 - $z \geq 5 \implies f_Z(z) = \int_{z-4}^{2}$ My question is how to find the bounds of $Z$ i.e. what are the possible values of $Z$? Does $Z$ run from $0 \to 6$ since it is the sum of $X+Y$ and this sum will have some value for every value $\in [0,6]$?","We have $X \sim \mathrm{Unif}[0,2]$ and $Y \sim \mathrm{Unif}[3,4]$. The random variables $X,Y$ are independent. We define a random variable $Z = X + Y$ and want to find the PDF of $Z$ using convolution.  Here is my work so far: The definition of convolution is: $f_Z(z) = \int_{-\infty}^{\infty}f_X(x)f_Y(z-x)\mathrm{d} x$ We know the PDF's of $X$ and $Y$ because they are just uniform distributions. The hard part for me is finding the limits of integration. We have to solve for the constraints. The integrand is nonzero when $3 \leq z-x \leq 4$ and when $0 \leq x \leq 2$. Together these constraints imply that $\max \{0, z-4\} \leq x \leq \min \{2, z-3 \}$. These constraints imply that there are three cases: Case 1 - $z \leq 4 \implies f_Z(z) = \int_0^{z-3}$ Case 2 - $4 \leq z \leq 5 \implies f_Z(z) = \int_{z-4}^{z-3}$ Case 3 - $z \geq 5 \implies f_Z(z) = \int_{z-4}^{2}$ My question is how to find the bounds of $Z$ i.e. what are the possible values of $Z$? Does $Z$ run from $0 \to 6$ since it is the sum of $X+Y$ and this sum will have some value for every value $\in [0,6]$?",,"['probability', 'probability-theory', 'probability-distributions', 'convolution']"
7,What does it mean for a probability distribution to have a finite fourth moment?,What does it mean for a probability distribution to have a finite fourth moment?,,"For example, suppose that some probability distribution X has a finite fourth moment. What distinguishes this distribution from another one, Y, which does not have a finite fourth moment? I am to understand that this gives us greater control over the ""tails"" of the distribution, but I don't understand how so.","For example, suppose that some probability distribution X has a finite fourth moment. What distinguishes this distribution from another one, Y, which does not have a finite fourth moment? I am to understand that this gives us greater control over the ""tails"" of the distribution, but I don't understand how so.",,"['probability', 'expectation']"
8,Why Dominated Convergence Theorem is not applicable in this case?,Why Dominated Convergence Theorem is not applicable in this case?,,"Suppose $\omega$ is distributed uniformly over $(0,1]$. Define random variables $$X_n:=n\mathbf{1}_{(0,1/n]}.$$ Obviously, $X_n\rightarrow X=\mathbf{0}$ and $\lim_{n}E[X_n]$ is not equal to E[X]. In this case the Dominated Convergence Theorem (DCT) is not applicable here. I was wondering how to show that we could not find an integrable random varible Y (i.e. $E[|Y|]<\infty$) such that $|X_n| < |Y| \;a.e.$ At first I think if $Y$ is integrable, then it should be essentially bounded. But afterwards I found it was not true. Then I got stuck...","Suppose $\omega$ is distributed uniformly over $(0,1]$. Define random variables $$X_n:=n\mathbf{1}_{(0,1/n]}.$$ Obviously, $X_n\rightarrow X=\mathbf{0}$ and $\lim_{n}E[X_n]$ is not equal to E[X]. In this case the Dominated Convergence Theorem (DCT) is not applicable here. I was wondering how to show that we could not find an integrable random varible Y (i.e. $E[|Y|]<\infty$) such that $|X_n| < |Y| \;a.e.$ At first I think if $Y$ is integrable, then it should be essentially bounded. But afterwards I found it was not true. Then I got stuck...",,"['real-analysis', 'probability', 'probability-theory', 'measure-theory']"
9,Expected value using indicator variables,Expected value using indicator variables,,"Randomly, $k$ distinguishable balls are placed into $n$ distinguishable boxes, with all possibilities equally likely. Find the expected number of empty boxes. PROPOSED SOLUTION: Let $I_j$ be the indicator random variable for the $j^{th}$ box being empty, so $I_1 + ··· + I_n$ is the number of empty boxes. Now $E(I_j) = P(I_j = 1) $ Given both boxes AND balls are distinguishable total number of ways to place balls in boxes is $(n + k)!$ Now lets assume $j^{th}$ box is left empty, remaining $(n-1)$ boxes can be filled as $(k + n - 1)!$ ways Therefore,  $I_j = \dfrac{(k + n -1)!}{(k + n)! }= E(I_j)$ By linearity of Expectation, $E(\sum_{k=1}^n[I_j]) = \sum_{k=1}^n(E(I_j))$ = $\sum_{k=1}^n(\dfrac{(k + n -1)!}{(k + n)!})$ = $\dfrac{n(k + n - 1)!}{(k + n)!}$ solution guide gives answer as $n(1 - 1/n)^k$ which is arrived at by saying $I_j = (1 - 1/n)^k$ Any insights in what is wrong above.","Randomly, $k$ distinguishable balls are placed into $n$ distinguishable boxes, with all possibilities equally likely. Find the expected number of empty boxes. PROPOSED SOLUTION: Let $I_j$ be the indicator random variable for the $j^{th}$ box being empty, so $I_1 + ··· + I_n$ is the number of empty boxes. Now $E(I_j) = P(I_j = 1) $ Given both boxes AND balls are distinguishable total number of ways to place balls in boxes is $(n + k)!$ Now lets assume $j^{th}$ box is left empty, remaining $(n-1)$ boxes can be filled as $(k + n - 1)!$ ways Therefore,  $I_j = \dfrac{(k + n -1)!}{(k + n)! }= E(I_j)$ By linearity of Expectation, $E(\sum_{k=1}^n[I_j]) = \sum_{k=1}^n(E(I_j))$ = $\sum_{k=1}^n(\dfrac{(k + n -1)!}{(k + n)!})$ = $\dfrac{n(k + n - 1)!}{(k + n)!}$ solution guide gives answer as $n(1 - 1/n)^k$ which is arrived at by saying $I_j = (1 - 1/n)^k$ Any insights in what is wrong above.",,"['probability', 'expectation']"
10,Translation invariance of Brownian motion,Translation invariance of Brownian motion,,"Beginner here. I'm working through Durrett's textbook's and am just getting into the section on Brownian motion. He gives a 2-line proof for a simple fact but I'm a little stuck understanding the details. Let $B_t$ be a one-dimensional Brownian motion. The simple fact is: $\{B_t - B_0, t \geq 0\}$ is independent of $B_0$ and has the same   distribution as Brownian motion with $B_0 = 0$. Durrett's proof: Let $\mathcal{A}_1 = \sigma(B_0)$ and $\mathcal{A}_2$ be events of the form $$\{B(t_1)-B(t_0) \in A_1, \ldots, B(t_n)-B(t_{n-1}) \in A_n\}$$ The $\mathcal{A}_i$ are $\pi$-systems that are independent, so the desired result follows from the $\pi-\lambda$ theorem. $\blacksquare$ So I'm assuming that this hinges on $\sigma(\mathcal{A}_2) = \sigma\{B_t-B_0, t \geq 0\}$. But what's the easiest way to see this? I know it has to do with finite-dimensional distributions, but I'm getting hung up somehow.","Beginner here. I'm working through Durrett's textbook's and am just getting into the section on Brownian motion. He gives a 2-line proof for a simple fact but I'm a little stuck understanding the details. Let $B_t$ be a one-dimensional Brownian motion. The simple fact is: $\{B_t - B_0, t \geq 0\}$ is independent of $B_0$ and has the same   distribution as Brownian motion with $B_0 = 0$. Durrett's proof: Let $\mathcal{A}_1 = \sigma(B_0)$ and $\mathcal{A}_2$ be events of the form $$\{B(t_1)-B(t_0) \in A_1, \ldots, B(t_n)-B(t_{n-1}) \in A_n\}$$ The $\mathcal{A}_i$ are $\pi$-systems that are independent, so the desired result follows from the $\pi-\lambda$ theorem. $\blacksquare$ So I'm assuming that this hinges on $\sigma(\mathcal{A}_2) = \sigma\{B_t-B_0, t \geq 0\}$. But what's the easiest way to see this? I know it has to do with finite-dimensional distributions, but I'm getting hung up somehow.",,"['probability', 'brownian-motion']"
11,Probability of Punctures for a group of cyclists,Probability of Punctures for a group of cyclists,,"The matter of the probability of punctures occurring cropped up during a ride yesterday with a friend. His view is this, (As we can't let a subject drop....  ;-) ) ""Eric, There must be more chance of a puncture occurring if there are more riders. The way I see it is this: If there is a 20% chance of a rider getting a puncture, then that means there is a 1 in 5 chance of a puncture for that rider. As a fraction that is 1/5. It follows that if there were 5 riders, the chances would be 5/5 for the group (i.e., one puncture). It follows that if there were 10 riders it would be 10/5 which means there would be 2 punctures. Therefore, the more riders there are, the more there is a chance of a puncture."" My view was that yes, 1/5 (20%) can be a figure to agree on, but that figure is stand alone, irrespective of the number of riders on the ride. I know probability is very counter intuitive to the human mind, so what seems to be the case is not always the case. Can anyone give a view, given that we're probably both high school grade mathematicians...if we're lucky! Eric","The matter of the probability of punctures occurring cropped up during a ride yesterday with a friend. His view is this, (As we can't let a subject drop....  ;-) ) ""Eric, There must be more chance of a puncture occurring if there are more riders. The way I see it is this: If there is a 20% chance of a rider getting a puncture, then that means there is a 1 in 5 chance of a puncture for that rider. As a fraction that is 1/5. It follows that if there were 5 riders, the chances would be 5/5 for the group (i.e., one puncture). It follows that if there were 10 riders it would be 10/5 which means there would be 2 punctures. Therefore, the more riders there are, the more there is a chance of a puncture."" My view was that yes, 1/5 (20%) can be a figure to agree on, but that figure is stand alone, irrespective of the number of riders on the ride. I know probability is very counter intuitive to the human mind, so what seems to be the case is not always the case. Can anyone give a view, given that we're probably both high school grade mathematicians...if we're lucky! Eric",,"['probability', 'probability-theory', 'probability-distributions']"
12,Expected value when die is rolled $N$ times,Expected value when die is rolled  times,N,"Suppose we have a die with $K$ faces with numbers from 1 to $K$ written on it, and integers $L$ and $F$ ($0 < L \leq K$). We roll it $N$ times. Let $a_i$ be the number of times (out of the $N$ rolls) that a face with number $i$ written on it came up as the top face of the die. I need to find the expectation of the value $a_1^F \times a_2^F \times \cdots a_L^F$ For example, let $N=2, K=6, L=2$ and $F=1$ Then, we roll the $6$-face die $2$ times, and we are interested in the value $a_1 \times a_2$. The only two possible scenarios when this value is not zero are $(1, 2)$ and $(2, 1)$. Both of them have $a_1 \times a_2 = 1$ and happen with probability $1 / 36$ each. So $P / Q = (1 + 1) / 36 = 1 / 18$","Suppose we have a die with $K$ faces with numbers from 1 to $K$ written on it, and integers $L$ and $F$ ($0 < L \leq K$). We roll it $N$ times. Let $a_i$ be the number of times (out of the $N$ rolls) that a face with number $i$ written on it came up as the top face of the die. I need to find the expectation of the value $a_1^F \times a_2^F \times \cdots a_L^F$ For example, let $N=2, K=6, L=2$ and $F=1$ Then, we roll the $6$-face die $2$ times, and we are interested in the value $a_1 \times a_2$. The only two possible scenarios when this value is not zero are $(1, 2)$ and $(2, 1)$. Both of them have $a_1 \times a_2 = 1$ and happen with probability $1 / 36$ each. So $P / Q = (1 + 1) / 36 = 1 / 18$",,"['probability', 'combinatorics', 'number-theory', 'algorithms']"
13,Euler and probability - a $\zeta$-distributed random variable,Euler and probability - a -distributed random variable,\zeta,"Let's consider a random variable $X$ on  $\mathbb{N}^*$ such as $\mathbb{P}[X=n]=n^{-s}\zeta(s)$. Thanks to that random variable we can prove that  $\zeta(s)= \underset{i=1}{\overset{\infty}{\prod}}\frac{1}{1-p_i^{-s}}$, where $p_i$ is the $i^\text{th}$ prime number, by calculating the probability of the event $\mathbb{P}[k \mid X]$. Then there a question I couldn't solve. Let's take a random variable $Y$ defined on $\mathbb{N}^*$, which has the same distribution of $X$. $X$ and $Y$ are independent. Calculate the distribution of $Z = \gcd(X,Y)$ where $\gcd$ represents the greatest common divisor. I would be grateful for any suggestions or ideas.","Let's consider a random variable $X$ on  $\mathbb{N}^*$ such as $\mathbb{P}[X=n]=n^{-s}\zeta(s)$. Thanks to that random variable we can prove that  $\zeta(s)= \underset{i=1}{\overset{\infty}{\prod}}\frac{1}{1-p_i^{-s}}$, where $p_i$ is the $i^\text{th}$ prime number, by calculating the probability of the event $\mathbb{P}[k \mid X]$. Then there a question I couldn't solve. Let's take a random variable $Y$ defined on $\mathbb{N}^*$, which has the same distribution of $X$. $X$ and $Y$ are independent. Calculate the distribution of $Z = \gcd(X,Y)$ where $\gcd$ represents the greatest common divisor. I would be grateful for any suggestions or ideas.",,"['probability', 'arithmetic']"
14,Expected number of occurences in Poisson process that can stop under certain conditions,Expected number of occurences in Poisson process that can stop under certain conditions,,"We have a fisherman who catches fish according to a Poisson distribution with $\lambda = 0.6$ fish per hour. The fisherman always fishes for at least $2$ hours. If during these $2$ hours he catches at least $1$ fish, he goes back home, else, he keeps fishing until he catches his first fish and then immediately leaves (we assume that he cannot catch $2$ fish at once, as per a Poisson process). Q. What is the expected number of caught fishes? Let $X_t$ denote the Poisson (counting) process. I made two attempts. Attempt 1 $$ \begin{align*} \mathbb{E}\left[\lim_{t \to +\infty} X_t - X_0\right] &= \mathbb{P}(X_2 = 0) \times \mathbb{E}\left[\lim_{t \to +\infty} X_t - X_0\mid X_2 = 0 \right] \\ &+ \mathbb{P}(X_2 > 0) \times \mathbb{E}\left[\lim_{t \to +\infty} X_t - X_0\mid X_2 > 0 \right] \end{align*} $$ We know that if $X_2 = 0$, then the fisherman will catch only $1$ fish, and if $X_2 > 0$, then he will catch $X_2$ fish. So, we get $$ \mathbb{P}(X_2 = 0) \times 1 + \mathbb{P}(X_2 > 0) \times \mathbb{E}\left[X_2 \right] \approx 0.3011942 + 0.8385669 = 1.139761 $$ Attempt 2 $$ \begin{align*} \mathbb{E}\left[\lim_{t \to +\infty} X_t - X_0\right] &= \mathbb{E}\left[\lim_{t \to +\infty} ((X_t - X_2) + (X_2 - X_0)\right] \\ &= \mathbb{E}\left[X_2 - X_0\right] + \mathbb{E}\left[\lim_{t \to +\infty} X_t - X_2\right] \end{align*} $$ Now, $\mathbb{E}\left[\lim_{t \to +\infty} X_t - X_2\right]$ is $1$ if and only if $X_2 = 0$, so $\mathbb{E}\left[\lim_{t \to +\infty} X_t - X_2\right] = \mathbb{P}(X_2 = 0)$. We calculate now $$ 1.2 + \mathbb{P}(X_2 = 0) \approx 1.2 + 0.3011942 = 1.501194 $$ A quick simulation suggests that attempt #2 is correct. However, I do not see why either of these attempts would be incorrect. Could anyone please shed some light?","We have a fisherman who catches fish according to a Poisson distribution with $\lambda = 0.6$ fish per hour. The fisherman always fishes for at least $2$ hours. If during these $2$ hours he catches at least $1$ fish, he goes back home, else, he keeps fishing until he catches his first fish and then immediately leaves (we assume that he cannot catch $2$ fish at once, as per a Poisson process). Q. What is the expected number of caught fishes? Let $X_t$ denote the Poisson (counting) process. I made two attempts. Attempt 1 $$ \begin{align*} \mathbb{E}\left[\lim_{t \to +\infty} X_t - X_0\right] &= \mathbb{P}(X_2 = 0) \times \mathbb{E}\left[\lim_{t \to +\infty} X_t - X_0\mid X_2 = 0 \right] \\ &+ \mathbb{P}(X_2 > 0) \times \mathbb{E}\left[\lim_{t \to +\infty} X_t - X_0\mid X_2 > 0 \right] \end{align*} $$ We know that if $X_2 = 0$, then the fisherman will catch only $1$ fish, and if $X_2 > 0$, then he will catch $X_2$ fish. So, we get $$ \mathbb{P}(X_2 = 0) \times 1 + \mathbb{P}(X_2 > 0) \times \mathbb{E}\left[X_2 \right] \approx 0.3011942 + 0.8385669 = 1.139761 $$ Attempt 2 $$ \begin{align*} \mathbb{E}\left[\lim_{t \to +\infty} X_t - X_0\right] &= \mathbb{E}\left[\lim_{t \to +\infty} ((X_t - X_2) + (X_2 - X_0)\right] \\ &= \mathbb{E}\left[X_2 - X_0\right] + \mathbb{E}\left[\lim_{t \to +\infty} X_t - X_2\right] \end{align*} $$ Now, $\mathbb{E}\left[\lim_{t \to +\infty} X_t - X_2\right]$ is $1$ if and only if $X_2 = 0$, so $\mathbb{E}\left[\lim_{t \to +\infty} X_t - X_2\right] = \mathbb{P}(X_2 = 0)$. We calculate now $$ 1.2 + \mathbb{P}(X_2 = 0) \approx 1.2 + 0.3011942 = 1.501194 $$ A quick simulation suggests that attempt #2 is correct. However, I do not see why either of these attempts would be incorrect. Could anyone please shed some light?",,"['probability', 'stochastic-processes', 'poisson-distribution']"
15,A random walk question: what is the given probability?,A random walk question: what is the given probability?,,"Let $\{X_n\}_{n\in\Bbb N_0}$ be a simple random walk, given $n\in \Bbb N$ what is the probability $$ \mathbb P(X_1\ge0,X_2\ge0,\ldots, X_{2n-1}\ge0,X_{2n}=0) $$ I think that I should benefit from reflection principle but I cannot use it. Please help me. Thank you","Let $\{X_n\}_{n\in\Bbb N_0}$ be a simple random walk, given $n\in \Bbb N$ what is the probability $$ \mathbb P(X_1\ge0,X_2\ge0,\ldots, X_{2n-1}\ge0,X_{2n}=0) $$ I think that I should benefit from reflection principle but I cannot use it. Please help me. Thank you",,"['probability', 'stochastic-processes', 'random-walk']"
16,Local maximum of brownian motions,Local maximum of brownian motions,,"Let $B=(B_t)_{t\geq 0}$ be the standard Brownian motion. I want to show that for every $t_0 \geq 0$ $\mathbb{P}$($B$ has a local maximum in $t_0$)=0. I've already shown that for every $0<a<b<\infty$ $B$ is $\mathbb{P}$-a.s. not monotone on the interval [$a,b$]. My ideas were the following: Suppose $B_t$ attains a local maximum in $t_0$. Can I assume that since $B$ has a.s. continuous paths, $t_0$ is preceded by an interval ($t_0-\epsilon, t_0$) where $B_t$ increases and is followed by an interval ($t_0,t_0+\epsilon$) where $B_t$ decreases? ($\epsilon > 0$) Then I would have two intervals where $B$ is monotone and since $B$ is not monotone on these intervals $\mathbb{P}$-a.s., I get $\mathbb{P}$($B$ has a local maximum in $t_0$) = $\mathbb{P}$($B$ is monotone on ($t_0-\epsilon,t_0$) and $(t_0,t_0+\epsilon)$)=0. Is that correct or do I have to argue in a different way? Can I always find those non-empty increasing and decreasing intervals ""before"" the next extremum? Thanks in advance.","Let $B=(B_t)_{t\geq 0}$ be the standard Brownian motion. I want to show that for every $t_0 \geq 0$ $\mathbb{P}$($B$ has a local maximum in $t_0$)=0. I've already shown that for every $0<a<b<\infty$ $B$ is $\mathbb{P}$-a.s. not monotone on the interval [$a,b$]. My ideas were the following: Suppose $B_t$ attains a local maximum in $t_0$. Can I assume that since $B$ has a.s. continuous paths, $t_0$ is preceded by an interval ($t_0-\epsilon, t_0$) where $B_t$ increases and is followed by an interval ($t_0,t_0+\epsilon$) where $B_t$ decreases? ($\epsilon > 0$) Then I would have two intervals where $B$ is monotone and since $B$ is not monotone on these intervals $\mathbb{P}$-a.s., I get $\mathbb{P}$($B$ has a local maximum in $t_0$) = $\mathbb{P}$($B$ is monotone on ($t_0-\epsilon,t_0$) and $(t_0,t_0+\epsilon)$)=0. Is that correct or do I have to argue in a different way? Can I always find those non-empty increasing and decreasing intervals ""before"" the next extremum? Thanks in advance.",,"['probability', 'probability-theory', 'stochastic-processes', 'stochastic-calculus', 'brownian-motion']"
17,What are the chances that 5 people are all born on the same day#?,What are the chances that 5 people are all born on the same day#?,,"Assuming 30-day months, given 10 people in a room.  What are the chances that 5 or more people are all born on the same day#?  (i.e., 5 born on the 28th, or 5 born on the 6th, etc) (EDIT: changed from chances of 5 to chances of 5 or more) I have tried two answers so far. In the first, you pick any person, and see what the chances are of the other 9, then 8, etc to match the first.  This seems to be 10 * 9/30 * 8/30 * 7/30 * 6/30. In the second, I suppose you could calculate the chances of 5 of the 10 having a birthday on day 1 + the chances of 5 having a birthday on day 2, etc. These answers seem quite different.  What do you all think?","Assuming 30-day months, given 10 people in a room.  What are the chances that 5 or more people are all born on the same day#?  (i.e., 5 born on the 28th, or 5 born on the 6th, etc) (EDIT: changed from chances of 5 to chances of 5 or more) I have tried two answers so far. In the first, you pick any person, and see what the chances are of the other 9, then 8, etc to match the first.  This seems to be 10 * 9/30 * 8/30 * 7/30 * 6/30. In the second, I suppose you could calculate the chances of 5 of the 10 having a birthday on day 1 + the chances of 5 having a birthday on day 2, etc. These answers seem quite different.  What do you all think?",,['probability']
18,I draw a hand of 13 from a deck of 52 cards. What is the probability that I do not have a card from every suit?,I draw a hand of 13 from a deck of 52 cards. What is the probability that I do not have a card from every suit?,,"I draw a hand of 13 from a deck of 52 standard playing cards. What is the probability that I do not have a card from every suit? I count the number of ways I can draw 13 from 3 suits $$\frac{{4\choose3}{39\choose13}}{52\choose13}$$ but I mind the intersection. Each possible pair of suits that I may have drawn from only is counted twice. And in the possibility that I pick from only one suit: each possibility is counted three times. $$\frac{{4\choose3}{39\choose13}-{4\choose2}{26\choose13}}{52\choose13}$$ This removes the overcounted iterations from the pair of suits I could have drawn from, but now I'm not considering the possibility that I drew from only one suit, so: $$\frac{{4\choose3}{39\choose13}-{4\choose2}{26\choose13}+{4\choose1}{13\choose13}}{52\choose13}$$ which is the probability I'm looking for. Is my reasoning sound? Have I made any mistakes? Is there a better solution?","I draw a hand of 13 from a deck of 52 standard playing cards. What is the probability that I do not have a card from every suit? I count the number of ways I can draw 13 from 3 suits $$\frac{{4\choose3}{39\choose13}}{52\choose13}$$ but I mind the intersection. Each possible pair of suits that I may have drawn from only is counted twice. And in the possibility that I pick from only one suit: each possibility is counted three times. $$\frac{{4\choose3}{39\choose13}-{4\choose2}{26\choose13}}{52\choose13}$$ This removes the overcounted iterations from the pair of suits I could have drawn from, but now I'm not considering the possibility that I drew from only one suit, so: $$\frac{{4\choose3}{39\choose13}-{4\choose2}{26\choose13}+{4\choose1}{13\choose13}}{52\choose13}$$ which is the probability I'm looking for. Is my reasoning sound? Have I made any mistakes? Is there a better solution?",,"['probability', 'combinatorics']"
19,Is there any short proof of this classical problem?,Is there any short proof of this classical problem?,,"Let $X,Y$ be two i.i.d. r.v.'s with zero mean and unit variance. If $X+Y$ and $X-Y$ are independent, then $X$ and $Y$ are both standard normal distributed. Is there any short proof for this problem?","Let $X,Y$ be two i.i.d. r.v.'s with zero mean and unit variance. If $X+Y$ and $X-Y$ are independent, then $X$ and $Y$ are both standard normal distributed. Is there any short proof for this problem?",,"['probability', 'probability-theory', 'probability-distributions', 'characteristic-functions']"
20,Expected number of rolls on a die until each face has appeared at least twice,Expected number of rolls on a die until each face has appeared at least twice,,"Note: The die is fair, normal 1 - 6 die. So I understand that the expected number of rolls until each face occurs is 14.7 by the following post: Expected time to roll all 1 through 6 on a die but what is the expected number of rolls until each face has appeared at least 2 times?","Note: The die is fair, normal 1 - 6 die. So I understand that the expected number of rolls until each face occurs is 14.7 by the following post: Expected time to roll all 1 through 6 on a die but what is the expected number of rolls until each face has appeared at least 2 times?",,"['probability', 'probability-theory']"
21,Wiener process - proof of independent increments,Wiener process - proof of independent increments,,"I have defined the Wiener process to be a stochastic process $X_t$ with values in $\mathbb{R}$ such that $X_0=0$, the paths $t \mapsto X_t$ are continuous, and for any times $0<t_1<\dots<t_n$ and Borel sets $A_1,\dots,A_n \subset \mathbb{R}$: $$ \mathbb{P}(X_{t_1} \in A_1, \dots, X_{t_n} \in A_n) = \int_{A_1}\dots\int_{A_n}p_{t_1}(0,x_1)\dots p_{t_n-t_{n-1}}(x_{n-1},x_n) \; \textrm{d}x_1\dots \textrm{d}x_n $$ where $$ p_t(x,y) = \frac{1}{\sqrt{2\pi t}}e^{-\frac{(x-y)^2}{2t}}  $$ is the transition density. From this definition, how do I prove that for any $0=t_0 \leq t_1 \leq \dots \leq t_n$, the increments $$ X_{t_1}-X_{t_0}, \dots, X_{t_n}-X_{t_{n-1}} $$ are independent? In general, the only way I know how to show that two RVs are independent is to show that their joint density function factorises into the product of the marginals, but I can't see how to do that here. Thanks for any help.","I have defined the Wiener process to be a stochastic process $X_t$ with values in $\mathbb{R}$ such that $X_0=0$, the paths $t \mapsto X_t$ are continuous, and for any times $0<t_1<\dots<t_n$ and Borel sets $A_1,\dots,A_n \subset \mathbb{R}$: $$ \mathbb{P}(X_{t_1} \in A_1, \dots, X_{t_n} \in A_n) = \int_{A_1}\dots\int_{A_n}p_{t_1}(0,x_1)\dots p_{t_n-t_{n-1}}(x_{n-1},x_n) \; \textrm{d}x_1\dots \textrm{d}x_n $$ where $$ p_t(x,y) = \frac{1}{\sqrt{2\pi t}}e^{-\frac{(x-y)^2}{2t}}  $$ is the transition density. From this definition, how do I prove that for any $0=t_0 \leq t_1 \leq \dots \leq t_n$, the increments $$ X_{t_1}-X_{t_0}, \dots, X_{t_n}-X_{t_{n-1}} $$ are independent? In general, the only way I know how to show that two RVs are independent is to show that their joint density function factorises into the product of the marginals, but I can't see how to do that here. Thanks for any help.",,"['probability', 'probability-theory', 'brownian-motion']"
22,Why the principal components correspond to the eigenvalues?,Why the principal components correspond to the eigenvalues?,,"Suppose ${\bf{X}} = ({X_1},{X_2},\ldots,{X_n})$ are the original components (also random variables) and ${{\bf{w}}_j} = ({\omega _1},{\omega _2},\ldots,{\omega _n})$ are loadings for the $j$th principal component satisfying ${\bf{w}}_j^\rm{T}{{\bf{w}}_j} = 1$ and ${\bf{w}}_\rm{i}^\rm{T}{\bf{w}}_j = 0$ for $i\neq j$, thus ${z_j} = {\bf{w }}_j^{\rm{T}}{\bf{X}}$ is the $j$th component. To find out the first principal component, we try to maximize the variance of $z_1$, which is $\rm{var}(z_1)=\rm{var}({\bf{w }}_1^{\rm{T}}{\bf{X}})=\bf{w}_\rm{1}^\rm{T}\rm{var}(\bf{X})\bf{w}_\rm{1}$. We estimate $\rm{var}(\bf{X}\rm{)}$ by the sample co-variance matrix $\bf{S}$, we maximize $L=\bf{w}_\rm{1}^\rm{T}\bf{S}\bf{w}_\rm{1}-\lambda({\bf{w}}_1^\rm{T}{{\bf{w}}_1} - 1)$ where $\lambda$ is the Lagrange multiplier. By taking derivative we arrive at $(\bf{S}-\lambda\bf{I})\bf{w}_\rm{1}=0$. It is obvious $\bf{w}_1$ is an eigenvector of the sample co-variance matrix $\bf{S}$. Now the problem comes . Solving the equation gets you all eignenvalues and eigenvectors. I searched the internet all materials I found simply tell you to rank the eigenvalues and the eigenvector of the largest eigenvalue is the first principal component, and the eigenvector of the second eigenvalue is the second principal component, and so one so forth. My question is how do we show or prove the largest eigenvalue corresponds to the largest variance and the second largest eigenvalue corresponds to the second largest variance and so on. Thank you.","Suppose ${\bf{X}} = ({X_1},{X_2},\ldots,{X_n})$ are the original components (also random variables) and ${{\bf{w}}_j} = ({\omega _1},{\omega _2},\ldots,{\omega _n})$ are loadings for the $j$th principal component satisfying ${\bf{w}}_j^\rm{T}{{\bf{w}}_j} = 1$ and ${\bf{w}}_\rm{i}^\rm{T}{\bf{w}}_j = 0$ for $i\neq j$, thus ${z_j} = {\bf{w }}_j^{\rm{T}}{\bf{X}}$ is the $j$th component. To find out the first principal component, we try to maximize the variance of $z_1$, which is $\rm{var}(z_1)=\rm{var}({\bf{w }}_1^{\rm{T}}{\bf{X}})=\bf{w}_\rm{1}^\rm{T}\rm{var}(\bf{X})\bf{w}_\rm{1}$. We estimate $\rm{var}(\bf{X}\rm{)}$ by the sample co-variance matrix $\bf{S}$, we maximize $L=\bf{w}_\rm{1}^\rm{T}\bf{S}\bf{w}_\rm{1}-\lambda({\bf{w}}_1^\rm{T}{{\bf{w}}_1} - 1)$ where $\lambda$ is the Lagrange multiplier. By taking derivative we arrive at $(\bf{S}-\lambda\bf{I})\bf{w}_\rm{1}=0$. It is obvious $\bf{w}_1$ is an eigenvector of the sample co-variance matrix $\bf{S}$. Now the problem comes . Solving the equation gets you all eignenvalues and eigenvectors. I searched the internet all materials I found simply tell you to rank the eigenvalues and the eigenvector of the largest eigenvalue is the first principal component, and the eigenvector of the second eigenvalue is the second principal component, and so one so forth. My question is how do we show or prove the largest eigenvalue corresponds to the largest variance and the second largest eigenvalue corresponds to the second largest variance and so on. Thank you.",,"['linear-algebra', 'probability', 'matrices', 'statistics']"
23,What constitutes an outcome in probability?,What constitutes an outcome in probability?,,"In probability, I often have trouble determining which situations to take as distinct outcomes for calculation. For instance, if we have a die with its faces numbered $1, 2, 2, 3, 3, 6$ and we roll it twice. We get $2$ on the first roll and $3$ on the second. Again rolling it twice we get $2$ and $3$. But the $2$ we got the second time is not the same $2$ as the first one. Its the other $2$ inscribed on the face of the die (the die has two $2$'s). So, for the purpose of calculating the probability that the sum of the two rolls in a die will be a certain number $4$, say, will these two situations constitute distinct outcomes? This is just a simplified, distilled example of a persistent problem I face in probability. Is there any way to think about outcomes that can make this clearer?","In probability, I often have trouble determining which situations to take as distinct outcomes for calculation. For instance, if we have a die with its faces numbered $1, 2, 2, 3, 3, 6$ and we roll it twice. We get $2$ on the first roll and $3$ on the second. Again rolling it twice we get $2$ and $3$. But the $2$ we got the second time is not the same $2$ as the first one. Its the other $2$ inscribed on the face of the die (the die has two $2$'s). So, for the purpose of calculating the probability that the sum of the two rolls in a die will be a certain number $4$, say, will these two situations constitute distinct outcomes? This is just a simplified, distilled example of a persistent problem I face in probability. Is there any way to think about outcomes that can make this clearer?",,['probability']
24,Does this stopping time always have infinite first moment?,Does this stopping time always have infinite first moment?,,"Let $X_1, X_2, X_3, \ldots$ be i.i.d. random variables with zero mean and let $S_n := X_1 + \ldots + X_n$. Does $T := \inf\{n: S_n > 0\}$ always have infinite first moment? In the trivial case, where $X_i = 0$, we have $T = \infty$. For random walk, in which $X_i = \pm 1$ with probability $1/2$, it can be shown that $\mathbb{E}[T]=\infty$. I am wondering if it is always the case that $\mathbb{E}[T]=\infty$.","Let $X_1, X_2, X_3, \ldots$ be i.i.d. random variables with zero mean and let $S_n := X_1 + \ldots + X_n$. Does $T := \inf\{n: S_n > 0\}$ always have infinite first moment? In the trivial case, where $X_i = 0$, we have $T = \infty$. For random walk, in which $X_i = \pm 1$ with probability $1/2$, it can be shown that $\mathbb{E}[T]=\infty$. I am wondering if it is always the case that $\mathbb{E}[T]=\infty$.",,"['probability', 'martingales']"
25,Random variables with equal joint distributions have equal marginal distributions?,Random variables with equal joint distributions have equal marginal distributions?,,"We are given two vectors $X=(X_1,X_2, . . . ,X_n)$ and $Y=(Y_1, Y_2, . . . , Y_n)$ with equal joint distributions. Do their marginal distributions $P_{X_i}$ and $ P_{Y_i}$ have to be equal? I have no idea so far how to approach this problem. I'm sure there is a simple counterexample with a small $n$. I suppose I should look for dependent random variables. Could you help me a bit?","We are given two vectors $X=(X_1,X_2, . . . ,X_n)$ and $Y=(Y_1, Y_2, . . . , Y_n)$ with equal joint distributions. Do their marginal distributions $P_{X_i}$ and $ P_{Y_i}$ have to be equal? I have no idea so far how to approach this problem. I'm sure there is a simple counterexample with a small $n$. I suppose I should look for dependent random variables. Could you help me a bit?",,"['probability', 'probability-distributions']"
26,"A chess player, X, plays a series of games against an opponent, Y","A chess player, X, plays a series of games against an opponent, Y",,"A chess player $X$ plays a series of games against an opponent $Y$. For each game, the probability that $X$ wins is $p$, independently of the results of other games. If $X$ plays 4 games against $Y$, show that the probability that this series of games contains at least 2 consecutive wins by $X$ is $p^2(3-2p)$. I know this can be done by listing all the possible ways and then summing the probabilities, but is there another way of doing this?","A chess player $X$ plays a series of games against an opponent $Y$. For each game, the probability that $X$ wins is $p$, independently of the results of other games. If $X$ plays 4 games against $Y$, show that the probability that this series of games contains at least 2 consecutive wins by $X$ is $p^2(3-2p)$. I know this can be done by listing all the possible ways and then summing the probabilities, but is there another way of doing this?",,['probability']
27,Are the odds one in a million? [closed],Are the odds one in a million? [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question This is a from a card game call Magic the Gathering And my question is regarding this video during a tournament match (best of 5). One in a million . You dont need watch the video I will explain the scenario here, but is very exciting. In this match, player Gabriel Nassif is at 9 life. And player Patrick Chappin cast 5x copies of Ignite Memories targeting Nassif Ignite memories: select a card a random from player hand and deal damage equal to that card convert mana cost or CC for short. Nassif have 3 cards in hand at that moment. Ignite Memories CC = 5 Grapeshot CC = 2 Rite of Flames CC = 1 Dont be confused because the 5x Ignite Memories are from Chappin. But Nassif also have one Ignite Memories in hand. In Magic this is call a mirror match because players are using similar strategies So if a single Ignite Memories is select from Nassif hand, Nassif will loss 1x 5 CC + 4 * {1 CC or 2CC} >= 9 life If select 5x Grapeshot mean 10 life, also lose. Max damage possible is selecting 5x the Ignite of Memories for 5x 5CC = 25 life loss Min damage possible is selecting 5x the Rite of Flames for 5x 1CC = 5 life loss Again Nassing beign at 9 and 5x copies of Ignite Memories, You loss if your life reach 0 or lower. What are the odd of survive?. At the end Nassif survive and won that game at 1 life but finish lossing the match in the next game. I only could add 2 link so if anyone want check for the other 2 cards: gatherer.wizards.com/Pages/Card/Details.aspx?name=GRAPESHOT gatherer.wizards.com/Pages/Card/Details.aspx?name=rite+of+flame I will try to add some context. As far I can go the total number of outcomes is $3^5$ Now how count wich of those outcomes cause the player to lose can't figure it out. Also give the motivation of because this is interesting, for a game planning the possible outcomes afect how you make the strategy.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question This is a from a card game call Magic the Gathering And my question is regarding this video during a tournament match (best of 5). One in a million . You dont need watch the video I will explain the scenario here, but is very exciting. In this match, player Gabriel Nassif is at 9 life. And player Patrick Chappin cast 5x copies of Ignite Memories targeting Nassif Ignite memories: select a card a random from player hand and deal damage equal to that card convert mana cost or CC for short. Nassif have 3 cards in hand at that moment. Ignite Memories CC = 5 Grapeshot CC = 2 Rite of Flames CC = 1 Dont be confused because the 5x Ignite Memories are from Chappin. But Nassif also have one Ignite Memories in hand. In Magic this is call a mirror match because players are using similar strategies So if a single Ignite Memories is select from Nassif hand, Nassif will loss 1x 5 CC + 4 * {1 CC or 2CC} >= 9 life If select 5x Grapeshot mean 10 life, also lose. Max damage possible is selecting 5x the Ignite of Memories for 5x 5CC = 25 life loss Min damage possible is selecting 5x the Rite of Flames for 5x 1CC = 5 life loss Again Nassing beign at 9 and 5x copies of Ignite Memories, You loss if your life reach 0 or lower. What are the odd of survive?. At the end Nassif survive and won that game at 1 life but finish lossing the match in the next game. I only could add 2 link so if anyone want check for the other 2 cards: gatherer.wizards.com/Pages/Card/Details.aspx?name=GRAPESHOT gatherer.wizards.com/Pages/Card/Details.aspx?name=rite+of+flame I will try to add some context. As far I can go the total number of outcomes is $3^5$ Now how count wich of those outcomes cause the player to lose can't figure it out. Also give the motivation of because this is interesting, for a game planning the possible outcomes afect how you make the strategy.",,"['probability', 'recreational-mathematics', 'puzzle']"
28,PDF of the ratio of two independent Gamma random variables,PDF of the ratio of two independent Gamma random variables,,"Let $X \sim \operatorname{Gamma}(a,\lambda)$ and $Y \sim \operatorname{Gamma}(b,\lambda)$ being independent. Find the PDF of the ratio $W=X/Y$. I found $$ f_W(w) = \frac{\Gamma(a+b)}{\Gamma(a) + \Gamma(b)} \left(\frac{w}{w+1}\right)^a \left(\frac{1}{w+1}\right)^b \frac{1}{w} $$ So, $$ f_W(w) = \operatorname{dbeta}\left(\frac{w}{w+1}, a+1, b+1 \right) \frac{1}{w} $$ or $$ f_{X/Y}(x/y) = \operatorname{dbeta}\left(\frac{x}{x+y}, a+1, b+1 \right) \frac{y}{x} $$ Is there any story or interpretations behind this result? I know that $$ \frac{X}{X+Y} \sim \operatorname{Beta}(a,b), $$ but how does this relate to $X/Y$?","Let $X \sim \operatorname{Gamma}(a,\lambda)$ and $Y \sim \operatorname{Gamma}(b,\lambda)$ being independent. Find the PDF of the ratio $W=X/Y$. I found $$ f_W(w) = \frac{\Gamma(a+b)}{\Gamma(a) + \Gamma(b)} \left(\frac{w}{w+1}\right)^a \left(\frac{1}{w+1}\right)^b \frac{1}{w} $$ So, $$ f_W(w) = \operatorname{dbeta}\left(\frac{w}{w+1}, a+1, b+1 \right) \frac{1}{w} $$ or $$ f_{X/Y}(x/y) = \operatorname{dbeta}\left(\frac{x}{x+y}, a+1, b+1 \right) \frac{y}{x} $$ Is there any story or interpretations behind this result? I know that $$ \frac{X}{X+Y} \sim \operatorname{Beta}(a,b), $$ but how does this relate to $X/Y$?",,"['probability', 'probability-distributions']"
29,better expression for simple random walk,better expression for simple random walk,,"Let $P_{k,j}$ be the probability that a simple symmetric random walk starting from the origin reaches the point $k \in \mathbb{N}$ precisely in $j$ steps without ever returning to the origin. Obviously, $P_{k,j}>0$ if and only if $j \geq k$. Let $ 0<c <1$ be a constant. Is there a way to rewrite the following sum in a ""nicer"" way, without computing $P_{k,j}$ explicitly, by using the properties of simple symmetric random walk? $$ \sum_{k=1}^{\infty} \sum_{j=k}^{\infty} P_{k,j} \, \, c^{j-1}$$","Let $P_{k,j}$ be the probability that a simple symmetric random walk starting from the origin reaches the point $k \in \mathbb{N}$ precisely in $j$ steps without ever returning to the origin. Obviously, $P_{k,j}>0$ if and only if $j \geq k$. Let $ 0<c <1$ be a constant. Is there a way to rewrite the following sum in a ""nicer"" way, without computing $P_{k,j}$ explicitly, by using the properties of simple symmetric random walk? $$ \sum_{k=1}^{\infty} \sum_{j=k}^{\infty} P_{k,j} \, \, c^{j-1}$$",,"['probability', 'probability-theory', 'probability-distributions', 'random-variables', 'random-walk']"
30,Montmort's card matching problem: Distribution of the number of matching cards?,Montmort's card matching problem: Distribution of the number of matching cards?,,"(Introduction to Probability, Blitzstein and Nwang) Recall de Montmort’s matching problem from Chapter 1: in a deck of n cards labeled 1   through n, a match occurs when the number on the card matches the card’s position in   the deck. Let X be the number of matching cards. Is X Binomial? Is X Hypergeometric? Again stuck at a textbook problem that was probability designed for 2 minutes... It's clearly not binomial, as the 'draws' are not independent, but I can't see why it should be hypergeometric. As I understand it, the story behind the hypergeomtric was that there is a urn with black and white balls, we take a sample of size n without replacement and count the number of white (or black) balls we see. But where are the black and white ball analogues in the card matching problem? To get the PMF, I would have guess something like $$ P(X=k) = \frac{\binom{n}{k} !(n-k)}{n!}, $$ where $n!$ is the number of possible card arrangements, $\binom{n}{k}$ the number of possibilities to have $k$ matching cards out of $n$ and the subfactorial $!(n-k)$ the number of possibilities to derange the remaining cards such that there is no additional match. What is the 'Hypergeometric story' behind the card matching problem? How to derive the hypergeometric distribution from the problem?","(Introduction to Probability, Blitzstein and Nwang) Recall de Montmort’s matching problem from Chapter 1: in a deck of n cards labeled 1   through n, a match occurs when the number on the card matches the card’s position in   the deck. Let X be the number of matching cards. Is X Binomial? Is X Hypergeometric? Again stuck at a textbook problem that was probability designed for 2 minutes... It's clearly not binomial, as the 'draws' are not independent, but I can't see why it should be hypergeometric. As I understand it, the story behind the hypergeomtric was that there is a urn with black and white balls, we take a sample of size n without replacement and count the number of white (or black) balls we see. But where are the black and white ball analogues in the card matching problem? To get the PMF, I would have guess something like $$ P(X=k) = \frac{\binom{n}{k} !(n-k)}{n!}, $$ where $n!$ is the number of possible card arrangements, $\binom{n}{k}$ the number of possibilities to have $k$ matching cards out of $n$ and the subfactorial $!(n-k)$ the number of possibilities to derange the remaining cards such that there is no additional match. What is the 'Hypergeometric story' behind the card matching problem? How to derive the hypergeometric distribution from the problem?",,"['probability', 'statistics', 'probability-distributions']"
31,Possibilities for passwords with at least one lowercase and one uppercase letter [duplicate],Possibilities for passwords with at least one lowercase and one uppercase letter [duplicate],,"This question already has answers here : How many ways can you create a password of 10 characters long that has at least one lowercase letter (a-z) and at least one number ($0-9$)? (2 answers) Closed last year . Fred needs to choose a password for a certain website. Assume that he will choose an   8-character password, and that the legal characters are the lowercase letters a, b, c, . . . , z, the uppercase letters A, B, C, . . . , Z, and the numbers 0, 1, . . . , 9.   (a) How many possibilities are there if he is required to have at least one lowercase letter   in his password?   (b) How many possibilities are there if he is required to have at least one lowercase   letter and at least one uppercase letter in his password?   (c) How many possibilities are there if he is required to have at least one lowercase   letter, at least one uppercase letter, and at least one number in his password? (Introduction to Probability, Blitzstein and Nwang, p.38) Part a) is no problem, but I don't know how to define the events for b) and c). Any hint for defining the events to be able to use inclusion-exclusion? EDIT1 Here is how I did part a). The question is how many ways are there to choose a password having at least one lowercase letter. Define $A_i$ as the set of all passwords with lowercase letter at the $i^{th}$ position. $|A_i| = 26^1 \; 62^{8-1}$ $|A_i \cap A_j| = 26^2 \; 62^{8-2}$ $|\cap_{i=1}^8 A_i| = 26^i \; 62^{8-i}$ \begin{equation} |\cup_{i=1}^8 A_i| = \sum_{i=1}^8 \binom{8}{i} 26^i \; 62^{8-i} (-1)^{i+1} \end{equation} I would like to solve the other parts in exactly the same manner, however, I don't know how to define my sets $A_i$ etc. in this case. EDIT2 I try part c) with @AlexR's approach: $|C| = |\Omega| - (|\neg U| + |\neg L| + |\neg N|) + (|\neg U \cap \neg L| + |\neg U \cap \neg N| + |\neg L \cap \neg N|) - |\neg U \cap \neg L \cap \neg N| = 62^8 - (36^8 + 36^8 + 52^8) + (10^8 + 26^8 + 26^8) - 0^8$ The probability of this to happen would be $0.7312$.","This question already has answers here : How many ways can you create a password of 10 characters long that has at least one lowercase letter (a-z) and at least one number ($0-9$)? (2 answers) Closed last year . Fred needs to choose a password for a certain website. Assume that he will choose an   8-character password, and that the legal characters are the lowercase letters a, b, c, . . . , z, the uppercase letters A, B, C, . . . , Z, and the numbers 0, 1, . . . , 9.   (a) How many possibilities are there if he is required to have at least one lowercase letter   in his password?   (b) How many possibilities are there if he is required to have at least one lowercase   letter and at least one uppercase letter in his password?   (c) How many possibilities are there if he is required to have at least one lowercase   letter, at least one uppercase letter, and at least one number in his password? (Introduction to Probability, Blitzstein and Nwang, p.38) Part a) is no problem, but I don't know how to define the events for b) and c). Any hint for defining the events to be able to use inclusion-exclusion? EDIT1 Here is how I did part a). The question is how many ways are there to choose a password having at least one lowercase letter. Define $A_i$ as the set of all passwords with lowercase letter at the $i^{th}$ position. $|A_i| = 26^1 \; 62^{8-1}$ $|A_i \cap A_j| = 26^2 \; 62^{8-2}$ $|\cap_{i=1}^8 A_i| = 26^i \; 62^{8-i}$ \begin{equation} |\cup_{i=1}^8 A_i| = \sum_{i=1}^8 \binom{8}{i} 26^i \; 62^{8-i} (-1)^{i+1} \end{equation} I would like to solve the other parts in exactly the same manner, however, I don't know how to define my sets $A_i$ etc. in this case. EDIT2 I try part c) with @AlexR's approach: $|C| = |\Omega| - (|\neg U| + |\neg L| + |\neg N|) + (|\neg U \cap \neg L| + |\neg U \cap \neg N| + |\neg L \cap \neg N|) - |\neg U \cap \neg L \cap \neg N| = 62^8 - (36^8 + 36^8 + 52^8) + (10^8 + 26^8 + 26^8) - 0^8$ The probability of this to happen would be $0.7312$.",,"['probability', 'combinatorics']"
32,"How do you find $f(x_1, x_3)$?",How do you find ?,"f(x_1, x_3)","$X_i$ is the number of times (out of 100) that a die's face has $i$ dots. I know that $X_i\sim \text{binomial}(100, 1/6)$, so $f(x_i)={100 \choose x_i}(1/6)^{x_i}(5/6)^{100-x_i}$. How do you find the joint probability mass function for $X_1$ and $X_3$ (the number of times you roll $1$s and $3$s, respectively? I'm unfamiliar with joint pmfs so I'm not sure how to even begin figuring this out.","$X_i$ is the number of times (out of 100) that a die's face has $i$ dots. I know that $X_i\sim \text{binomial}(100, 1/6)$, so $f(x_i)={100 \choose x_i}(1/6)^{x_i}(5/6)^{100-x_i}$. How do you find the joint probability mass function for $X_1$ and $X_3$ (the number of times you roll $1$s and $3$s, respectively? I'm unfamiliar with joint pmfs so I'm not sure how to even begin figuring this out.",,"['probability', 'probability-distributions']"
33,A die whose score cannot be as before (Markov chains),A die whose score cannot be as before (Markov chains),,"A die is ""fixed"" so that each time it is rolled the score cannot be the same as the preceding score, all other scores having probability $1/5$. Given that the first score is 6, what is the probability that the $n$th score is 6 and what is it if the $n$th score is 1? HINT: You can simplify things by selecting an appropriate state-space; do you really need a 6-state chain to answer the question? Define $u_n(j) := P(X_n = j \mid X_1 = 6) = P_6 (X_n = j)$ and note that $P_6(X_n = j) = \frac{1}{5} P_6(X_{n-1} \neq 6) = \frac{1}{5} (1 - P_6(X_{n-1} = 6))$ So $u_n = \frac{1}{5} (1 - u_{n-1})$ and solving the difference equation for the cases $j=6,1$ we have $u_n(6) = \frac{1}{6} (1+5(-\frac{1}{5})^{n-1})$ $u_n(1) = \frac{1}{6} (1-(-\frac{1}{5})^{n-1})$ However, I feel that by using difference equations to obtain the solutions I am missing the point of the question and the hint. I tried selecting several state-spaces but couldn't get anywhere. Can anyone shed some light on this?","A die is ""fixed"" so that each time it is rolled the score cannot be the same as the preceding score, all other scores having probability $1/5$. Given that the first score is 6, what is the probability that the $n$th score is 6 and what is it if the $n$th score is 1? HINT: You can simplify things by selecting an appropriate state-space; do you really need a 6-state chain to answer the question? Define $u_n(j) := P(X_n = j \mid X_1 = 6) = P_6 (X_n = j)$ and note that $P_6(X_n = j) = \frac{1}{5} P_6(X_{n-1} \neq 6) = \frac{1}{5} (1 - P_6(X_{n-1} = 6))$ So $u_n = \frac{1}{5} (1 - u_{n-1})$ and solving the difference equation for the cases $j=6,1$ we have $u_n(6) = \frac{1}{6} (1+5(-\frac{1}{5})^{n-1})$ $u_n(1) = \frac{1}{6} (1-(-\frac{1}{5})^{n-1})$ However, I feel that by using difference equations to obtain the solutions I am missing the point of the question and the hint. I tried selecting several state-spaces but couldn't get anywhere. Can anyone shed some light on this?",,"['probability', 'probability-distributions', 'stochastic-processes', 'markov-chains', 'markov-process']"
34,Selecting a Random Point Inside a Cube,Selecting a Random Point Inside a Cube,,"A point $P$ is selected at random inside a cube. Find the probability that $\angle APB \geq 135^o$, where $\overline{AB}$ is a body diagonal of the cube. I am not able to come up with the right condition or the right variable to integrate. Geometrically, I think, $P$ has to move in a region which is an intersection of two spheres and the given cube. I am not able to visualise that out properly too. Please help me out. Thank you.","A point $P$ is selected at random inside a cube. Find the probability that $\angle APB \geq 135^o$, where $\overline{AB}$ is a body diagonal of the cube. I am not able to come up with the right condition or the right variable to integrate. Geometrically, I think, $P$ has to move in a region which is an intersection of two spheres and the given cube. I am not able to visualise that out properly too. Please help me out. Thank you.",,"['probability', 'geometry', 'geometric-probability']"
35,Help with conditional expectation on the circle,Help with conditional expectation on the circle,,"Let $p >1$ a integer, $X = \mathbb{R} / \mathbb{Z}$ and $\mu\colon \mathcal{B}\to [0,1]$ a probability measure on the Borel subsets of $X$ which is $T \colon X \ni x \to (px  \text{ mod }1)$ invariant.  I need to find a formula for  $$E_\mu(f \ | \ T^{-n}\mathcal{B}) $$ for all $f\in L^1(\mu)$. The only thing I know is that $E_\mu(f \ | \ T^{-n}\mathcal{B}) = g \circ T^n$ for some measurable function $g \colon X \to \mathbb{R}$. Any help will be appreciated.","Let $p >1$ a integer, $X = \mathbb{R} / \mathbb{Z}$ and $\mu\colon \mathcal{B}\to [0,1]$ a probability measure on the Borel subsets of $X$ which is $T \colon X \ni x \to (px  \text{ mod }1)$ invariant.  I need to find a formula for  $$E_\mu(f \ | \ T^{-n}\mathcal{B}) $$ for all $f\in L^1(\mu)$. The only thing I know is that $E_\mu(f \ | \ T^{-n}\mathcal{B}) = g \circ T^n$ for some measurable function $g \colon X \to \mathbb{R}$. Any help will be appreciated.",,"['probability', 'measure-theory', 'ergodic-theory', 'conditional-expectation']"
36,"Confusion regarding almost sure events. If given infinite time, will a discrete-time gaussian process cover the entire real line?","Confusion regarding almost sure events. If given infinite time, will a discrete-time gaussian process cover the entire real line?",,"This question really pertains to any discrete time continuous-valued, stationary stochastic process on the real line, but the Gaussian process will be adequate for this question. I have this confusion about zero-probability events. If we observe a discrete-time Gaussian process for any finite length of time, the probability that it will hit a particular real number is $0$. However, this does not imply that it is impossible for the process to take on this value, as impossible events are only a subset of zero-probability events. Now, instead of watching the process for a finite period of time, lets say that you are going to make a bet that at some time in the future, the Gaussian process will take a particular (real-number) value at least once. So here's my confusion: it seems that I can argue this both ways. I can say that since it is a zero probability event, there are an infinite number of other numbers it can visit, so its zero. On the other hand, with infinite time, the empirical CDF that results from the Gaussian process sample path will converge to the actual CDF of a Gaussian RV, so it converges to a distribution that has visited all points in the real line. Can someone provide some insight into which of the above is more accurate when $T=\infty$? As a related question: It seems that the continuous time, nonstationary version of this (Brownian Motion) is actually easier to think about, as the sample paths are continuous and hence must cover all values between its most extreme endpoints, which is asymptotically the entire real line.","This question really pertains to any discrete time continuous-valued, stationary stochastic process on the real line, but the Gaussian process will be adequate for this question. I have this confusion about zero-probability events. If we observe a discrete-time Gaussian process for any finite length of time, the probability that it will hit a particular real number is $0$. However, this does not imply that it is impossible for the process to take on this value, as impossible events are only a subset of zero-probability events. Now, instead of watching the process for a finite period of time, lets say that you are going to make a bet that at some time in the future, the Gaussian process will take a particular (real-number) value at least once. So here's my confusion: it seems that I can argue this both ways. I can say that since it is a zero probability event, there are an infinite number of other numbers it can visit, so its zero. On the other hand, with infinite time, the empirical CDF that results from the Gaussian process sample path will converge to the actual CDF of a Gaussian RV, so it converges to a distribution that has visited all points in the real line. Can someone provide some insight into which of the above is more accurate when $T=\infty$? As a related question: It seems that the continuous time, nonstationary version of this (Brownian Motion) is actually easier to think about, as the sample paths are continuous and hence must cover all values between its most extreme endpoints, which is asymptotically the entire real line.",,"['probability', 'probability-theory']"
37,probability that the white balls are left in the urn,probability that the white balls are left in the urn,,"I don´t understand the solution of next problem: An urn contains n white balls and m black balls. The balls are withdrawn one at a time until only those of the same color are left. Show that with probability $$n\over m+n$$ they are all white The hint is: imagine that the experiment continues until all the balls are removed, and consider the last ball withdrawn. So if we take into account the hint, there are $(n+m)!$ outcomes of withdrawing all the balls from the urn (in order) and the event that the last ball removed is white has n(n+m-1)! possible outcomes hence the probability is $${n(n+m-1)!\over (n+m)!}= {n\over n+m}$$ The thing is that why do we have to consider the last ball withdrawn? why if the last ball drawn is white implies that all white balls are left in the urn? I don´t get it I was trying to do it like this: there are $(n+m)!$ outcomes of withdrawing all the balls and there are $m$ black balls wich wan be arrenged in $m!$ ways and the white balls can be arrenged in $n!$ ways so the probability is $$m!n!\over (n+m)!$$ but this is just my assumption. I know this is a silly question but can you please explain me why do we have to consider that the last ball withdrawn is white? and why does this implies that all the white balls are the left in the urn? Is there another way to solve this problem? I really would appreciate your help :D","I don´t understand the solution of next problem: An urn contains n white balls and m black balls. The balls are withdrawn one at a time until only those of the same color are left. Show that with probability $$n\over m+n$$ they are all white The hint is: imagine that the experiment continues until all the balls are removed, and consider the last ball withdrawn. So if we take into account the hint, there are $(n+m)!$ outcomes of withdrawing all the balls from the urn (in order) and the event that the last ball removed is white has n(n+m-1)! possible outcomes hence the probability is $${n(n+m-1)!\over (n+m)!}= {n\over n+m}$$ The thing is that why do we have to consider the last ball withdrawn? why if the last ball drawn is white implies that all white balls are left in the urn? I don´t get it I was trying to do it like this: there are $(n+m)!$ outcomes of withdrawing all the balls and there are $m$ black balls wich wan be arrenged in $m!$ ways and the white balls can be arrenged in $n!$ ways so the probability is $$m!n!\over (n+m)!$$ but this is just my assumption. I know this is a silly question but can you please explain me why do we have to consider that the last ball withdrawn is white? and why does this implies that all the white balls are the left in the urn? Is there another way to solve this problem? I really would appreciate your help :D",,['probability']
38,"Mean and Variance of ""Piecewise"" Normal Distribution","Mean and Variance of ""Piecewise"" Normal Distribution",,"Note - I put piecewise in quotes because I don't think it's the right term to use (I can't figure out what to call it). I am building a program to model the load that a user places on a server. The load a user produces follows a normal distribution. Depending on which application the user is using, however, the mean and variance of that normal distribution will be different. What I am trying to do is calculate the overall mean and variance for a user's activity given the proportions of time they use each application. For example, Application A follows $\mathcal{N}(100, 50)$ and Application B follows $\mathcal{N}(500, 20)$.  If a user uses A 50% of the time and B the other 50%, what is the mean and variance of the data that the user would produce during a day? I'm able to simulate this by selecting a number from a uniform distribution between 0 and 1 and then generating a value from the appropriate distribution.  Something like this: $f(x) = \begin{cases} \mathcal{N}(100, 50), &0 \le x \lt 0.5\\ \mathcal{N}(500, 20), &0.5 \le x \lt 1\\ \end{cases} $ When I simulate a large number of these values and measure the results, it looks like the mean is just $\sum\limits_{i=1}^n\mu_ip$ where $p$ is the percentage of the day a user is using each application. I can't figure out what pattern the variance follows or what the formula might be to determine it without measuring a bunch of simulated values (When I simulate the above example, the variance looks to be something close to 41500). I'd appreciate confirmation that how I'm calculating the combined mean is correct and some help in figuring out how to determine the variance of the overall distribution.","Note - I put piecewise in quotes because I don't think it's the right term to use (I can't figure out what to call it). I am building a program to model the load that a user places on a server. The load a user produces follows a normal distribution. Depending on which application the user is using, however, the mean and variance of that normal distribution will be different. What I am trying to do is calculate the overall mean and variance for a user's activity given the proportions of time they use each application. For example, Application A follows $\mathcal{N}(100, 50)$ and Application B follows $\mathcal{N}(500, 20)$.  If a user uses A 50% of the time and B the other 50%, what is the mean and variance of the data that the user would produce during a day? I'm able to simulate this by selecting a number from a uniform distribution between 0 and 1 and then generating a value from the appropriate distribution.  Something like this: $f(x) = \begin{cases} \mathcal{N}(100, 50), &0 \le x \lt 0.5\\ \mathcal{N}(500, 20), &0.5 \le x \lt 1\\ \end{cases} $ When I simulate a large number of these values and measure the results, it looks like the mean is just $\sum\limits_{i=1}^n\mu_ip$ where $p$ is the percentage of the day a user is using each application. I can't figure out what pattern the variance follows or what the formula might be to determine it without measuring a bunch of simulated values (When I simulate the above example, the variance looks to be something close to 41500). I'd appreciate confirmation that how I'm calculating the combined mean is correct and some help in figuring out how to determine the variance of the overall distribution.",,"['probability', 'normal-distribution']"
39,"Show that $\max \left(\frac{|X_1|}{\sqrt{n}}, \dots, \frac{|X_n|}{\sqrt{n}}\right) \overset{d}{\to} 0, n \to \infty$",Show that,"\max \left(\frac{|X_1|}{\sqrt{n}}, \dots, \frac{|X_n|}{\sqrt{n}}\right) \overset{d}{\to} 0, n \to \infty","$X_1, X_2, \dots, X_n, \dots$ is a sequence of i.i.d random variables with $E[X_1] = 0$ and $E[X_1^2] = 1$. Show that    $$ \max \left(\frac{|X_1|}{\sqrt{n}}, \dots, \frac{|X_n|}{\sqrt{n}}\right) \overset{d}{\to} 0, n \to \infty $$ I attempted to use the continuity theorem. Putting $Y_n = \max \left(\frac{|X_1|}{\sqrt{n}}, \dots, \frac{|X_n|}{\sqrt{n}}\right) $, we can show that the distribution function of $Y_n$ is  $$ F_{Y_n}(y) = [F(\sqrt{n}y)]^n, $$ where $F(\cdot)$ is the distribution function of $X_1$. Then the characteristic function of $Y_n$ is  $$ \varphi_{Y_n}(t) = \int_{\mathbb{R}} n^{\frac 32} [F(\sqrt{n}y)]^n e^{ity}\,\mathrm{d}F(y) $$ I can only get to this step and don't know how to proceed the proof. Is there an alternative way to prove it? Thanks for any help in advance!","$X_1, X_2, \dots, X_n, \dots$ is a sequence of i.i.d random variables with $E[X_1] = 0$ and $E[X_1^2] = 1$. Show that    $$ \max \left(\frac{|X_1|}{\sqrt{n}}, \dots, \frac{|X_n|}{\sqrt{n}}\right) \overset{d}{\to} 0, n \to \infty $$ I attempted to use the continuity theorem. Putting $Y_n = \max \left(\frac{|X_1|}{\sqrt{n}}, \dots, \frac{|X_n|}{\sqrt{n}}\right) $, we can show that the distribution function of $Y_n$ is  $$ F_{Y_n}(y) = [F(\sqrt{n}y)]^n, $$ where $F(\cdot)$ is the distribution function of $X_1$. Then the characteristic function of $Y_n$ is  $$ \varphi_{Y_n}(t) = \int_{\mathbb{R}} n^{\frac 32} [F(\sqrt{n}y)]^n e^{ity}\,\mathrm{d}F(y) $$ I can only get to this step and don't know how to proceed the proof. Is there an alternative way to prove it? Thanks for any help in advance!",,['probability']
40,conditional probability about sum and product rule,conditional probability about sum and product rule,,"I am reading Bishop's Pattern Recognition and Machine Learning. In page 73, chapter 2.1. I can't understand the formula 2.19 : $$p(x=1|\mathcal{D})=\int_0^1 p(x=1|\mu)p(\mu|\mathcal{D})\text{d}\mu $$ The author say, this is obtained by sum and product rules. The sum rule is: $$p(X) = \sum_Y p(X,Y)$$ and the product rule is: $$p(X,Y)=p(Y|X)p(X)$$ But from this, I can't deduce the formula. Could you help me ... thanks very much.","I am reading Bishop's Pattern Recognition and Machine Learning. In page 73, chapter 2.1. I can't understand the formula 2.19 : $$p(x=1|\mathcal{D})=\int_0^1 p(x=1|\mu)p(\mu|\mathcal{D})\text{d}\mu $$ The author say, this is obtained by sum and product rules. The sum rule is: $$p(X) = \sum_Y p(X,Y)$$ and the product rule is: $$p(X,Y)=p(Y|X)p(X)$$ But from this, I can't deduce the formula. Could you help me ... thanks very much.",,"['probability', 'probability-distributions']"
41,countably additive function P,countably additive function P,,"This problem comes from exercise 1.3.5(b) of 'A First Look at Rigorous Probability Theory'. It asks to give an example of a countably additive function $P$, defined on all subsets of $[0,1]$, which satisfies countable additivity and $P(A \bigoplus r)=P(A)$, $0\leq r \leq 1$(r-shift), but it does not satisfy $P([a,b])=P((a,b])=P([a,b))=P((a,b))$,$0\leq a \leq b \leq 1$. Can anyone give me a example?","This problem comes from exercise 1.3.5(b) of 'A First Look at Rigorous Probability Theory'. It asks to give an example of a countably additive function $P$, defined on all subsets of $[0,1]$, which satisfies countable additivity and $P(A \bigoplus r)=P(A)$, $0\leq r \leq 1$(r-shift), but it does not satisfy $P([a,b])=P((a,b])=P([a,b))=P((a,b))$,$0\leq a \leq b \leq 1$. Can anyone give me a example?",,"['probability', 'measure-theory']"
42,"Laplace transform of : $t^{\gamma-1} F(\alpha,\beta,\delta,\frac{t}{d})$, where $F$ is the Gauss' hypergeometric function","Laplace transform of : , where  is the Gauss' hypergeometric function","t^{\gamma-1} F(\alpha,\beta,\delta,\frac{t}{d}) F","What is the Laplace transform of : $t^{\gamma-1} F(\alpha,\beta,\delta,\frac{t}{d})$, where $\gamma >0 $ and $F$ is the Gauss' hypergeometric function. Note that I have the Laplace transform of : $t^{\gamma-1} F(\alpha,\beta,\delta,-t)$. Thanks!","What is the Laplace transform of : $t^{\gamma-1} F(\alpha,\beta,\delta,\frac{t}{d})$, where $\gamma >0 $ and $F$ is the Gauss' hypergeometric function. Note that I have the Laplace transform of : $t^{\gamma-1} F(\alpha,\beta,\delta,-t)$. Thanks!",,"['probability', 'integration', 'definite-integrals', 'improper-integrals', 'laplace-transform']"
43,Prove increase of expected value,Prove increase of expected value,,"I am trying to prove the following: For $x$ distributed on $X=[a,b]\subset \mathbb{R}^+$ with the cumulative distribution function $F(\cdot)$ s.t. $F'(x)=f(x)>0\ \forall x\in X$: $E[x\mid x\leq\bar{x}]$ is strictly increasing in $\bar{x}\ \forall\bar{x}\in(a,b)$, where $E[\cdot]$ denotes the expected value. My current approach is: $$ \frac{\partial}{\partial\bar{x}} E[x\mid x\leq\bar{x}] = \frac{\partial}{\partial\bar{x}}\frac{\int_a^\bar{x}x\cdot f(x)\mathrm{d}x}{\underbrace{\int_a^\bar{x}f(x)\mathrm{d}x}_{=F(\bar{x})}} = \frac{\left(\bar{x}\cdot f(\bar{x})\right)\cdot F(\bar{x})-\overbrace{F'(\bar{x})}^{=f(\bar{x})}}{(F(\bar{x}))^2}=\frac{f(\bar{x})}{F(\bar{x})}\left(\bar{x}-\frac{1}{F(\bar{x})}\right) $$ which is strictly greater than zero if and only if $\bar{x}>\frac{1}{F(\bar{x})}$, but since  $F(\bar{x})\in (0,1]$ this would require that $\bar{x}>1$, which does not necessarily hold. Any help on where I went wrong would be greatly appreciated. If information is missing, please let me know.","I am trying to prove the following: For $x$ distributed on $X=[a,b]\subset \mathbb{R}^+$ with the cumulative distribution function $F(\cdot)$ s.t. $F'(x)=f(x)>0\ \forall x\in X$: $E[x\mid x\leq\bar{x}]$ is strictly increasing in $\bar{x}\ \forall\bar{x}\in(a,b)$, where $E[\cdot]$ denotes the expected value. My current approach is: $$ \frac{\partial}{\partial\bar{x}} E[x\mid x\leq\bar{x}] = \frac{\partial}{\partial\bar{x}}\frac{\int_a^\bar{x}x\cdot f(x)\mathrm{d}x}{\underbrace{\int_a^\bar{x}f(x)\mathrm{d}x}_{=F(\bar{x})}} = \frac{\left(\bar{x}\cdot f(\bar{x})\right)\cdot F(\bar{x})-\overbrace{F'(\bar{x})}^{=f(\bar{x})}}{(F(\bar{x}))^2}=\frac{f(\bar{x})}{F(\bar{x})}\left(\bar{x}-\frac{1}{F(\bar{x})}\right) $$ which is strictly greater than zero if and only if $\bar{x}>\frac{1}{F(\bar{x})}$, but since  $F(\bar{x})\in (0,1]$ this would require that $\bar{x}>1$, which does not necessarily hold. Any help on where I went wrong would be greatly appreciated. If information is missing, please let me know.",,"['probability', 'derivatives']"
44,PDF of sum of two random variables,PDF of sum of two random variables,,Assume an $n$ dimensional random variable $U$ that is uniformly distributed in the volume of an $n$-sphere with radius $R$. Assume another $n$ dimensional random variable $N$ that is distributed according to Gaussian distribution with variance $\sigma^2$ per dimension and zero mean. Is it possible to derive the pdf (or cdf) of the sum of two random variables $U+N$? Note that $U$ and $N$ are independent.,Assume an $n$ dimensional random variable $U$ that is uniformly distributed in the volume of an $n$-sphere with radius $R$. Assume another $n$ dimensional random variable $N$ that is distributed according to Gaussian distribution with variance $\sigma^2$ per dimension and zero mean. Is it possible to derive the pdf (or cdf) of the sum of two random variables $U+N$? Note that $U$ and $N$ are independent.,,"['probability', 'probability-theory', 'probability-distributions', 'random-variables', 'uniform-distribution']"
45,Warren's proof for Benford's Law,Warren's proof for Benford's Law,,"Warren has a little proof of Benford's law in Hacker's Delight. To quote: Let $f(x)$ for $1 \leq x < 10$ be the probability density function for   the leading digits of the set of numbers with units. $f(x)$ has the   property that: $$\int_a^b f(x) dx$$ is the proportion of numbers that   have leading digits ranging from a to b. For a small increment $\Delta x$ in x, f must satisfy (Ed: I leave out a figure that shows the same   graphically) $$f(1) * \Delta x = f(x) * x \Delta x$$ because $f(1) * \Delta x$ is, approximately, the proportion of numbers   ranging from 1 to 1 + $\Delta x$ (ignoring a multiplier of a power of   10), and $f(x) * x \Delta x$ is the approximate proportion of numbers   ranging from x to $x + x\Delta x$. Because the latter set is the   first multiplied by x, their proportions must be equal. The rest of it is very straight-forward, but I don't understand the bolded sentence which is the justification for the whole approach. It is clearly not true in general, so it must follow from the fact that we deal with numbers with units.","Warren has a little proof of Benford's law in Hacker's Delight. To quote: Let $f(x)$ for $1 \leq x < 10$ be the probability density function for   the leading digits of the set of numbers with units. $f(x)$ has the   property that: $$\int_a^b f(x) dx$$ is the proportion of numbers that   have leading digits ranging from a to b. For a small increment $\Delta x$ in x, f must satisfy (Ed: I leave out a figure that shows the same   graphically) $$f(1) * \Delta x = f(x) * x \Delta x$$ because $f(1) * \Delta x$ is, approximately, the proportion of numbers   ranging from 1 to 1 + $\Delta x$ (ignoring a multiplier of a power of   10), and $f(x) * x \Delta x$ is the approximate proportion of numbers   ranging from x to $x + x\Delta x$. Because the latter set is the   first multiplied by x, their proportions must be equal. The rest of it is very straight-forward, but I don't understand the bolded sentence which is the justification for the whole approach. It is clearly not true in general, so it must follow from the fact that we deal with numbers with units.",,"['probability', 'probability-theory', 'probability-distributions', 'proof-verification']"
46,Conditional expectation with normal distribution - Clarification needed,Conditional expectation with normal distribution - Clarification needed,,"I am trying to figure out conditional expectation for the following case: Suppose $\theta$ has normal distribution with mean $0$ and variance $1$ i.e., standard normal. Let $x_i=\theta+\epsilon_i$ where $\epsilon_i$ has normal distribution with mean $0$ and variance $\frac{1-v}{v}$ for some $v\in(0,1)$. Given this it is claimed $\mathbf{E}[\theta\mid x_i]=vx_i$. To my mind,  since $\theta=x_i-\epsilon_i$, thus $\mathbf E[\theta\mid x_i]=x_i$. To obtain answer I tried proper way which is using pdf of normal and expectation but I couldn't figure out how to solve integrals. Thanks for any help! P.S. After a comment, $\theta$ and $\epsilon_i$ independent.","I am trying to figure out conditional expectation for the following case: Suppose $\theta$ has normal distribution with mean $0$ and variance $1$ i.e., standard normal. Let $x_i=\theta+\epsilon_i$ where $\epsilon_i$ has normal distribution with mean $0$ and variance $\frac{1-v}{v}$ for some $v\in(0,1)$. Given this it is claimed $\mathbf{E}[\theta\mid x_i]=vx_i$. To my mind,  since $\theta=x_i-\epsilon_i$, thus $\mathbf E[\theta\mid x_i]=x_i$. To obtain answer I tried proper way which is using pdf of normal and expectation but I couldn't figure out how to solve integrals. Thanks for any help! P.S. After a comment, $\theta$ and $\epsilon_i$ independent.",,"['probability', 'conditional-probability']"
47,Find the bias for the Maximum-likelihood estimator,Find the bias for the Maximum-likelihood estimator,,"Let $X_1,...,X_n$ be a random sample from the pdf $$f(x|\theta) = \theta x^{\theta-1} , 0 \leq x \leq 1, \theta >0.$$ I found the Maximum-likelihood estimator of $\theta$ is $$\hat{\theta} = \frac{-n}{\sum_{i=1}^N \ln(X_i)}.$$ Can anyone confirm that this is right? Then, I want to determine whether $\hat{\theta}$ has bias. My approach is to calculate  ${\bf E}[\hat{\theta}] = {\bf E}\left[\frac{-n}{\sum_{i=1}^N \ln(X_i)}\right]$...Then I am stuck. Could someone help me with this?","Let $X_1,...,X_n$ be a random sample from the pdf $$f(x|\theta) = \theta x^{\theta-1} , 0 \leq x \leq 1, \theta >0.$$ I found the Maximum-likelihood estimator of $\theta$ is $$\hat{\theta} = \frac{-n}{\sum_{i=1}^N \ln(X_i)}.$$ Can anyone confirm that this is right? Then, I want to determine whether $\hat{\theta}$ has bias. My approach is to calculate  ${\bf E}[\hat{\theta}] = {\bf E}\left[\frac{-n}{\sum_{i=1}^N \ln(X_i)}\right]$...Then I am stuck. Could someone help me with this?",,"['probability', 'statistics', 'probability-theory', 'probability-distributions']"
48,Rouché theorem in queuing theory,Rouché theorem in queuing theory,,"I was looking for the uses of Rouché's theorem, and I came across queuing theory. An article stated that it is a workhorse theorem in this field, but as much as I tried to find some examples on the ways it can be used I still could not. Could someone show some examples or recommend me some articles / webpages where I can see how this theorem is used for calculating the probability generating function? (A not too complicated example would be nice.)","I was looking for the uses of Rouché's theorem, and I came across queuing theory. An article stated that it is a workhorse theorem in this field, but as much as I tried to find some examples on the ways it can be used I still could not. Could someone show some examples or recommend me some articles / webpages where I can see how this theorem is used for calculating the probability generating function? (A not too complicated example would be nice.)",,"['probability', 'complex-analysis', 'queueing-theory']"
49,"Let $Y_1, Y_2,\ldots,Y_n$ denote a random sample from the uniform distrib... Help find finding $ \text{Var}\left[\hat{\theta}_{2}\right]$",Let  denote a random sample from the uniform distrib... Help find finding,"Y_1, Y_2,\ldots,Y_n  \text{Var}\left[\hat{\theta}_{2}\right]","Let $Y_1, Y_2,\ldots,Y_n$ denote a random sample from the uniform distribution on the interval $(θ, θ + 1)$. Let $$ \hat{\theta}_2 = Y_{(n)} - \frac{n}{n+1}$$ Find the efficiency of $θ^1$ relative to $θ^2$ We have $Y_i\sim\mathcal{U}(\theta,\theta+1)$ and CDF of $Y_i$ based on Wikipedia $$ G_{Y_i}(y)=\Pr[Y_i\le y]=\frac{y-\theta}{\theta+1-\theta}=y-\theta. $$ Here, $Y_{(n)}$ is $n$-th order statistics. Therefore, $Y_{(n)}=\max[Y_1,\ldots, Y_n]$. Note that $Y_{(n)}\le y$ equivalence to $Y_i\le y$ for $i=1,2,\ldots,n$. Hence, for $\theta< y<\theta+1$, the fact that $Y_1,Y_2,\ldots, Y_n$ are i.i.d. implies $$ G_{Y_{(n)}}(y)=\Pr[Y_{(n)}\le y]=\Pr[Y_1\le y,Y_2\le y,\ldots, Y_n\le y]=(\Pr[Y_i\le y])^n=\left(y-\theta\right)^{n}. $$ The PDF of $Y_{(n)}$ is $$ g_{Y_{(n)}}(y)=\frac{d}{dy}G_{Y_{(n)}}(y)=\frac{d}{dy}(y-\theta)^n=n(y-\theta)^{n-1}. $$ The expected value of $Y_{(n)}$ is $$ \begin{align} \text{E}\left[Y_{(n)}\right]&=\int_{y=\theta}^{\theta+1}yg_{Y_{(n)}}(y)\ dy\\ &=\int_{y=\theta}^{\theta+1}yn(y-\theta)^{n-1}\ dy\\ &=n\int_{y=\theta}^{\theta+1}y(y-\theta)^{n-1}\ dy. \end{align} $$ I have trouble finding  $$ \text{Var}\left[\hat{\theta}_{2}\right]=\text{Var}\left[Y_{(n)}-\frac{n}{n+1}\right]=\text{Var}\left[Y_{(n)}\right]=\text{E}\left[Y_{(n)}^2\right]-\left(\text{E}\left[Y_{(n)}\right]\right)^2. $$ I found that $$ \begin{align} \text{E}\left[Y_{(n)}\right]&=n\left[\frac{y(y-\theta)^n}{n+1}-\frac{\theta(y-\theta)^n}{n(n+1)}\right]_{y=\theta}^{\theta+1}\\ &=\frac{n(\theta+1)}{n+1}+\frac{\theta}{n+1}\\ &=\theta+\frac{n}{n+1}. \end{align} $$ The way I calculate $E(Y_{(n)}^2)$ is the following: $$E(Y_{(n)}^2) = ny^2(y-\theta)^{n-1} = n\left[\left.y^2\frac{(y-\theta)^n}{n} \right|_\theta^{\theta+1} - \frac{2}{n} \int_\theta^{\theta+1} y(y-\theta)^n  \,dy\right]$$ $$= \left.(\theta+1)^2 - 2\left(y\frac{(y-\theta)^{n+1}}{n+1} \right|_\theta^{\theta+1} - \int_\theta^{\theta+1} \frac{(y-\theta)^{n+1}}{n+1} dy\right) = (\theta+1)^2 -2 \left(\frac{\theta+1}{n+1} - \left.\frac{(y-\theta)^{n+2}}{(n+1)(n+2)}\right|_\theta^{\theta+1}\right)$$ $$= (\theta+1)^2- 2\frac{\theta +1}{n+1} - \frac{1}{(n+1)(n+2)}$$ Then I use $E(Y_{(n)}^2) - E(Y_{(n)})^2$, based on wolframalpha which gives me the following result ...please go here ...which is different from the correct answer $\text {Var} [\hat{\theta}_2]= V(Y(n))=\frac{n}{(n+2)(n+1)^2}$....Could anyone please check why?","Let $Y_1, Y_2,\ldots,Y_n$ denote a random sample from the uniform distribution on the interval $(θ, θ + 1)$. Let $$ \hat{\theta}_2 = Y_{(n)} - \frac{n}{n+1}$$ Find the efficiency of $θ^1$ relative to $θ^2$ We have $Y_i\sim\mathcal{U}(\theta,\theta+1)$ and CDF of $Y_i$ based on Wikipedia $$ G_{Y_i}(y)=\Pr[Y_i\le y]=\frac{y-\theta}{\theta+1-\theta}=y-\theta. $$ Here, $Y_{(n)}$ is $n$-th order statistics. Therefore, $Y_{(n)}=\max[Y_1,\ldots, Y_n]$. Note that $Y_{(n)}\le y$ equivalence to $Y_i\le y$ for $i=1,2,\ldots,n$. Hence, for $\theta< y<\theta+1$, the fact that $Y_1,Y_2,\ldots, Y_n$ are i.i.d. implies $$ G_{Y_{(n)}}(y)=\Pr[Y_{(n)}\le y]=\Pr[Y_1\le y,Y_2\le y,\ldots, Y_n\le y]=(\Pr[Y_i\le y])^n=\left(y-\theta\right)^{n}. $$ The PDF of $Y_{(n)}$ is $$ g_{Y_{(n)}}(y)=\frac{d}{dy}G_{Y_{(n)}}(y)=\frac{d}{dy}(y-\theta)^n=n(y-\theta)^{n-1}. $$ The expected value of $Y_{(n)}$ is $$ \begin{align} \text{E}\left[Y_{(n)}\right]&=\int_{y=\theta}^{\theta+1}yg_{Y_{(n)}}(y)\ dy\\ &=\int_{y=\theta}^{\theta+1}yn(y-\theta)^{n-1}\ dy\\ &=n\int_{y=\theta}^{\theta+1}y(y-\theta)^{n-1}\ dy. \end{align} $$ I have trouble finding  $$ \text{Var}\left[\hat{\theta}_{2}\right]=\text{Var}\left[Y_{(n)}-\frac{n}{n+1}\right]=\text{Var}\left[Y_{(n)}\right]=\text{E}\left[Y_{(n)}^2\right]-\left(\text{E}\left[Y_{(n)}\right]\right)^2. $$ I found that $$ \begin{align} \text{E}\left[Y_{(n)}\right]&=n\left[\frac{y(y-\theta)^n}{n+1}-\frac{\theta(y-\theta)^n}{n(n+1)}\right]_{y=\theta}^{\theta+1}\\ &=\frac{n(\theta+1)}{n+1}+\frac{\theta}{n+1}\\ &=\theta+\frac{n}{n+1}. \end{align} $$ The way I calculate $E(Y_{(n)}^2)$ is the following: $$E(Y_{(n)}^2) = ny^2(y-\theta)^{n-1} = n\left[\left.y^2\frac{(y-\theta)^n}{n} \right|_\theta^{\theta+1} - \frac{2}{n} \int_\theta^{\theta+1} y(y-\theta)^n  \,dy\right]$$ $$= \left.(\theta+1)^2 - 2\left(y\frac{(y-\theta)^{n+1}}{n+1} \right|_\theta^{\theta+1} - \int_\theta^{\theta+1} \frac{(y-\theta)^{n+1}}{n+1} dy\right) = (\theta+1)^2 -2 \left(\frac{\theta+1}{n+1} - \left.\frac{(y-\theta)^{n+2}}{(n+1)(n+2)}\right|_\theta^{\theta+1}\right)$$ $$= (\theta+1)^2- 2\frac{\theta +1}{n+1} - \frac{1}{(n+1)(n+2)}$$ Then I use $E(Y_{(n)}^2) - E(Y_{(n)})^2$, based on wolframalpha which gives me the following result ...please go here ...which is different from the correct answer $\text {Var} [\hat{\theta}_2]= V(Y(n))=\frac{n}{(n+2)(n+1)^2}$....Could anyone please check why?",,"['probability', 'statistics', 'probability-theory', 'probability-distributions']"
50,De Morgan's law in probability theory,De Morgan's law in probability theory,,"I'm wondering if this holds $$\overline{(A\cup \overline{B})}=\overline{A}\cap B$$ I have this problem in probability theory, if $A$ and $\overline{B}$ are independent events then $\overline{A} $ and $B$ are also independent events. Can I use De Morgan's law to approach this?","I'm wondering if this holds $$\overline{(A\cup \overline{B})}=\overline{A}\cap B$$ I have this problem in probability theory, if $A$ and $\overline{B}$ are independent events then $\overline{A} $ and $B$ are also independent events. Can I use De Morgan's law to approach this?",,['probability']
51,Random variables independent from each other?,Random variables independent from each other?,,"I was wondering about the following: Let's say we have two random variables $X,Y$ that obey both Poisson's distribution.  Now, if we take $X=Y$ then they are clearly dependent. But what happens if we say that $X$ and $Y$ are Poisson distributions with different parameters $\lambda_x \neq \lambda_y$? Does this mean, that they are independent? If this is not true: Is it true for any distribution, that if you have random variables with different parameters, then they are automotically independent?","I was wondering about the following: Let's say we have two random variables $X,Y$ that obey both Poisson's distribution.  Now, if we take $X=Y$ then they are clearly dependent. But what happens if we say that $X$ and $Y$ are Poisson distributions with different parameters $\lambda_x \neq \lambda_y$? Does this mean, that they are independent? If this is not true: Is it true for any distribution, that if you have random variables with different parameters, then they are automotically independent?",,['probability']
52,What is the expected number of k-length streaks in n rolls?,What is the expected number of k-length streaks in n rolls?,,"Given $n$ flips of a coin with success probability $p$, what is the expected number of $k$-length win streaks in $n$? (I've looked for this question online, but the answers always restrict $n$ to be a power of $2$ or $k$ to be written in terms of $\log$ base $2$.  Refrain from that here, if possible.)","Given $n$ flips of a coin with success probability $p$, what is the expected number of $k$-length win streaks in $n$? (I've looked for this question online, but the answers always restrict $n$ to be a power of $2$ or $k$ to be written in terms of $\log$ base $2$.  Refrain from that here, if possible.)",,"['probability', 'statistics', 'dice']"
53,What is the probability to win? Die game [closed],What is the probability to win? Die game [closed],,"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 10 years ago . Improve this question You have a die. If you get one pip at any point in the game you lose. If you get two,..., six pips you start adding the number of pips to a sum. To win the sum must get greater or equal to 100. What is the probability to win the game?","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 10 years ago . Improve this question You have a die. If you get one pip at any point in the game you lose. If you get two,..., six pips you start adding the number of pips to a sum. To win the sum must get greater or equal to 100. What is the probability to win the game?",,['probability']
54,Probability of 9 persons walking into a 3-carriage train.,Probability of 9 persons walking into a 3-carriage train.,,"Nine persons go into a 3-carriage tram. Each person chooses the carriage at random. What is the probability that there will be 3 persons in each carriage? The probability of a person entering any carriage is $ \frac{1}{3} $. I thought of solving it using the multinomial scheme, which gave me $$\frac{9!}{3!3!3!} \Bigl(\frac{1}{3}\Bigr)^9=35 \cdot\frac{2^4}{3^7}$$ However the book lists $\frac{25}{4}\cdot\bigl(\frac{2}{3}\bigr)^7$ as the answer. Where do i go wrong?","Nine persons go into a 3-carriage tram. Each person chooses the carriage at random. What is the probability that there will be 3 persons in each carriage? The probability of a person entering any carriage is $ \frac{1}{3} $. I thought of solving it using the multinomial scheme, which gave me $$\frac{9!}{3!3!3!} \Bigl(\frac{1}{3}\Bigr)^9=35 \cdot\frac{2^4}{3^7}$$ However the book lists $\frac{25}{4}\cdot\bigl(\frac{2}{3}\bigr)^7$ as the answer. Where do i go wrong?",,"['probability', 'discrete-mathematics']"
55,Finding the better coin: what is the probability of success?,Finding the better coin: what is the probability of success?,,"Just for fun, I'm working my way through Motwani and Raghavan's Randomized Algorithms textbook. As part of a solution to one of the problems they've posed, I've come across a probability problem I don't know how to solve: Suppose that you have two coins, one of which flips heads $\frac{2}{3}$ of the time and one of which flips heads $\frac{1}{3}$ of the time. You flip each coin $k$ times and guess which coin flips heads $\frac{2}{3}$ of the time by choosing the coin that flipped the most heads. (If there's a tie, assume that you guess incorrectly). What is the probability, as a function of $k$, that you choose the correct coin? To try to solve this, I tried to model the distributions of heads from the coins as two binomial distributions and then subtracting them to get a distribution on the difference between the good coin's number of heads and the bad coin's number of heads, but I couldn't make much progress because I don't know how to subtract these distributions. I also tried modeling the binomial distributions as normal distributions and subtracting those, but ran into a similar problem (I don't know how to subtract them). Does anyone have any advice on how to approach this problem?","Just for fun, I'm working my way through Motwani and Raghavan's Randomized Algorithms textbook. As part of a solution to one of the problems they've posed, I've come across a probability problem I don't know how to solve: Suppose that you have two coins, one of which flips heads $\frac{2}{3}$ of the time and one of which flips heads $\frac{1}{3}$ of the time. You flip each coin $k$ times and guess which coin flips heads $\frac{2}{3}$ of the time by choosing the coin that flipped the most heads. (If there's a tie, assume that you guess incorrectly). What is the probability, as a function of $k$, that you choose the correct coin? To try to solve this, I tried to model the distributions of heads from the coins as two binomial distributions and then subtracting them to get a distribution on the difference between the good coin's number of heads and the bad coin's number of heads, but I couldn't make much progress because I don't know how to subtract these distributions. I also tried modeling the binomial distributions as normal distributions and subtracting those, but ran into a similar problem (I don't know how to subtract them). Does anyone have any advice on how to approach this problem?",,"['probability', 'probability-distributions']"
56,When does a measurable function exist with a given distribution?,When does a measurable function exist with a given distribution?,,"Let's suppose (A,X,P) and (B,Y,Q) are two probability spaces (A,B underlying spaces, X,Y sigma-algebras, P,Q probability measures, respectively). Under what (topological and/or measure theoretic) conditions on these two spaces does there exist a measurable map M: A -> B such that P(M in b) = Q(b)   for an arbitrary element b of Y. Thanks a lot for your help.","Let's suppose (A,X,P) and (B,Y,Q) are two probability spaces (A,B underlying spaces, X,Y sigma-algebras, P,Q probability measures, respectively). Under what (topological and/or measure theoretic) conditions on these two spaces does there exist a measurable map M: A -> B such that P(M in b) = Q(b)   for an arbitrary element b of Y. Thanks a lot for your help.",,"['probability', 'measure-theory', 'probability-theory']"
57,"How to prove that max{$X_1$,...,$X_n$} is a sufficient statistic for $b$ in the Uniform distribution on$ [a,b]$","How to prove that max{,...,} is a sufficient statistic for  in the Uniform distribution on","X_1 X_n b  [a,b]","I am having a bit of difficulty with the following: I have the Uniform distribution on [a,b] where a is known and b is unknown and $b>a$, I'd like to show that the $T=max$($X_1$,...,$X_n$) is a sufficient statistic for $b$. Here is my proof: Since for any $x_i$$<0$, $f_n$($\vec{x}$,$b$)= $0$, we only look at the case where $x_i$$\geq$$0$: We have: $f_n$($\vec{x}$,$b$)= $(1/(b-a))^n$ for $t$$\leq$$b$ and  0 otherwise, As a result, let $h(t,b)$$=$$f_n$($\vec{x}$,$b$)= $(1/(b-a))^n$ for $t$$\leq$$b$ and  0 otherwise, Then, let $u(x)$$=$$1$. Since we can write $f_n$($\vec{x}$,$b$) = $h(t,b)$$u(x)$, then T is a sufficient statistic. However, I have seen in other places that the right answer is to let write the likelihood as: $f_n$($\vec{x}$,$b$) = $\frac{h(t,b)}{(b-a)^n}$ where here I have no idea what $h(t,b)$ should be. Thank you!","I am having a bit of difficulty with the following: I have the Uniform distribution on [a,b] where a is known and b is unknown and $b>a$, I'd like to show that the $T=max$($X_1$,...,$X_n$) is a sufficient statistic for $b$. Here is my proof: Since for any $x_i$$<0$, $f_n$($\vec{x}$,$b$)= $0$, we only look at the case where $x_i$$\geq$$0$: We have: $f_n$($\vec{x}$,$b$)= $(1/(b-a))^n$ for $t$$\leq$$b$ and  0 otherwise, As a result, let $h(t,b)$$=$$f_n$($\vec{x}$,$b$)= $(1/(b-a))^n$ for $t$$\leq$$b$ and  0 otherwise, Then, let $u(x)$$=$$1$. Since we can write $f_n$($\vec{x}$,$b$) = $h(t,b)$$u(x)$, then T is a sufficient statistic. However, I have seen in other places that the right answer is to let write the likelihood as: $f_n$($\vec{x}$,$b$) = $\frac{h(t,b)}{(b-a)^n}$ where here I have no idea what $h(t,b)$ should be. Thank you!",,"['probability', 'statistics']"
58,How can $n$ variables have $2n$ degrees of freedom?,How can  variables have  degrees of freedom?,n 2n,"Formally, if $Y_i\sim \mathrm{Exp}(\lambda)$, then $2\sum_{i=1}^n Y_i \sim \Gamma(n,2)$, which is the chi-squared distribution with $2n$ degrees of freedom. Intuitively, however, I think of degrees of freedom as the number of variables that are free to vary minus the number of constraints. In other words, the degrees of freedom of a problem, such as a hypothesis test, is like the dimension of the space that the data lives in. And this is, in fact, how most of the webpages I have visited suggest we think about degrees of freedom. But in many tests $2n$ degrees of freedom are used for sample size $n$ without much explanation except the formal one above. An example is a one sided test of the mean of $n$ independent exponential variables or confidence intervals on failure times. So I'm having a hard time trying to attach a meaning to the extra $n$ degrees. I'm thinking that even though there are $n$ variables there is some underlying geometry that is higher dimensional. There has to be an intuitive explanation for the extra ""wiggle room"" in these problems. This question arose from a specific question from a review sheet in my class. The question is if $X_1, X_2, \ldots, X_n$ are iid $N(0,1)$, find a Uniformly Most Powerful test of size $\alpha$ for $H_0: \sigma^2=\sigma_0^2$ vs. $H_1: \sigma^2>\sigma_0^2$. I found that the family of distributions has a monotone likelihood ratio in $Y(X)=\sum X_i^2$ so that a UMP is \begin{align*}  T(X)=\begin{cases}         1 & Y(X)>c, \\         0 & Y(X)<c.    \end{cases} \end{align*} Thus, $\alpha=\mathrm{P}_0\left(\frac{Y(X)}{\sigma_0^2}>c/\sigma_0^2\right)$, and since the sum of squares of standard normal variables has a $\chi^2$ distribution with $n$ degrees of freedom, I would have said $c=\sigma_0^2\chi^2_\alpha(n)$. The professor, however says that the notation for this is $c = \sigma_0^2 \chi^2_\alpha(2n)$. The professor is unavailable for comment, but she's used the same review sheet for years so think she means what she says. Thanks!","Formally, if $Y_i\sim \mathrm{Exp}(\lambda)$, then $2\sum_{i=1}^n Y_i \sim \Gamma(n,2)$, which is the chi-squared distribution with $2n$ degrees of freedom. Intuitively, however, I think of degrees of freedom as the number of variables that are free to vary minus the number of constraints. In other words, the degrees of freedom of a problem, such as a hypothesis test, is like the dimension of the space that the data lives in. And this is, in fact, how most of the webpages I have visited suggest we think about degrees of freedom. But in many tests $2n$ degrees of freedom are used for sample size $n$ without much explanation except the formal one above. An example is a one sided test of the mean of $n$ independent exponential variables or confidence intervals on failure times. So I'm having a hard time trying to attach a meaning to the extra $n$ degrees. I'm thinking that even though there are $n$ variables there is some underlying geometry that is higher dimensional. There has to be an intuitive explanation for the extra ""wiggle room"" in these problems. This question arose from a specific question from a review sheet in my class. The question is if $X_1, X_2, \ldots, X_n$ are iid $N(0,1)$, find a Uniformly Most Powerful test of size $\alpha$ for $H_0: \sigma^2=\sigma_0^2$ vs. $H_1: \sigma^2>\sigma_0^2$. I found that the family of distributions has a monotone likelihood ratio in $Y(X)=\sum X_i^2$ so that a UMP is \begin{align*}  T(X)=\begin{cases}         1 & Y(X)>c, \\         0 & Y(X)<c.    \end{cases} \end{align*} Thus, $\alpha=\mathrm{P}_0\left(\frac{Y(X)}{\sigma_0^2}>c/\sigma_0^2\right)$, and since the sum of squares of standard normal variables has a $\chi^2$ distribution with $n$ degrees of freedom, I would have said $c=\sigma_0^2\chi^2_\alpha(n)$. The professor, however says that the notation for this is $c = \sigma_0^2 \chi^2_\alpha(2n)$. The professor is unavailable for comment, but she's used the same review sheet for years so think she means what she says. Thanks!",,"['probability', 'probability-distributions', 'statistical-inference']"
59,Distribution function of the sum of poisson and uniform random variable.,Distribution function of the sum of poisson and uniform random variable.,,"Merry Christmas to everybody. I am working on the following problem. Let $X$ and $Y$ be independent Poisson($\lambda$), respectively Uniform$(0,1)$ random variables. Find the distribution function of the random variable $Z := X+Y$. I have the solution here but I don't understand it completely. \begin{align*} F_Z(a) &= \mathbb P(X+Y \le a) = \sum_{i = 0}^{\lfloor a\rfloor-1} \mathbb P(X = i) + \mathbb P(X = \lfloor a\rfloor, Y \le a-\lfloor a\rfloor) \\ &= \sum_{i = 0}^{\lfloor a\rfloor-1} \mathbb P(X = i) + \mathbb P(X = \lfloor a\rfloor) \cdot \mathbb P(Y \le a-\lfloor a\rfloor) = \sum_{i = 0}^{\lfloor a\rfloor-1} \frac{\lambda^i}{i!} e^{-\lambda} + \frac{\lambda^{\lfloor a\rfloor}}{\lfloor a\rfloor!} e^{-\lambda} \cdot (a-\lfloor a\rfloor). \end{align*} What I don't understand is: \begin{align*} \mathbb P(X+Y \le a) = \sum_{i = 0}^{\lfloor a\rfloor-1} \mathbb P(X = i) + \mathbb P(X = \lfloor a\rfloor, Y \le a-\lfloor a\rfloor) \end{align*} $\lfloor \cdot \rfloor$ denotes the floor function.","Merry Christmas to everybody. I am working on the following problem. Let $X$ and $Y$ be independent Poisson($\lambda$), respectively Uniform$(0,1)$ random variables. Find the distribution function of the random variable $Z := X+Y$. I have the solution here but I don't understand it completely. \begin{align*} F_Z(a) &= \mathbb P(X+Y \le a) = \sum_{i = 0}^{\lfloor a\rfloor-1} \mathbb P(X = i) + \mathbb P(X = \lfloor a\rfloor, Y \le a-\lfloor a\rfloor) \\ &= \sum_{i = 0}^{\lfloor a\rfloor-1} \mathbb P(X = i) + \mathbb P(X = \lfloor a\rfloor) \cdot \mathbb P(Y \le a-\lfloor a\rfloor) = \sum_{i = 0}^{\lfloor a\rfloor-1} \frac{\lambda^i}{i!} e^{-\lambda} + \frac{\lambda^{\lfloor a\rfloor}}{\lfloor a\rfloor!} e^{-\lambda} \cdot (a-\lfloor a\rfloor). \end{align*} What I don't understand is: \begin{align*} \mathbb P(X+Y \le a) = \sum_{i = 0}^{\lfloor a\rfloor-1} \mathbb P(X = i) + \mathbb P(X = \lfloor a\rfloor, Y \le a-\lfloor a\rfloor) \end{align*} $\lfloor \cdot \rfloor$ denotes the floor function.",,"['probability', 'probability-theory', 'probability-distributions', 'random-variables', 'uniform-distribution']"
60,"Compute Cov(X,Y) while X is the number of 1's and Y is the number of 2's in n dice rolls","Compute Cov(X,Y) while X is the number of 1's and Y is the number of 2's in n dice rolls",,"Let $X$ be the number of 1's and $Y$ be the number of 2's that occur in $n$ rolls of a fair die. Compute $Cov(X,Y)$. What's wrong with my solution? Here it is: $Cov(X,Y)=E[XY]-E[X]E[Y]$ Compute $E[X]$ as follows: $E[X]=1*{n\choose 1}*\frac{1}{6}*(\frac{5}{6})^{n-1}+2*{n\choose 2}*\frac{1}{6^{2}}*(\frac{5}{6})^{n-2}+...+n*{n\choose n}*\frac{1}{6^{n}}$ This is binomial distribution so $$E[X]=np=\frac{n}{6}$$ There's no difference between $E[X]$ and $E[Y]$ so $$E[X]=E[Y]$$ I believe all's correct so far. My problem is in computing $E[XY]$. This is what i've done: $E[XY]$ is the number of times we got 1 and 2 at the same time. Which is impossible. Hence $$E[XY]=0$$ Finally we can say $$Cov(X,Y)=0-\frac{n^2}{36}=-\frac{n^2}{36}$$ I found in some website that they got a final answer of $\frac{n}{36}$ because they divided the problem into 2 parts: (1) $X$ and $Y$ are dependent , (2) $X$ and $Y$ are independent. When they're independent $Cov(X,Y)=0$ , and when they're dependent $E[XY]=0$ and thus for roll $i$: $$Cov(X,Y)=E[X_i Y_i]-E[X_i]E[Y_i]=0-\frac{1}{36}=-\frac{1}{36}$$ And consequently: $$Cov(X,Y)=\sum_{i=1}^{n}\sum_{j=1}^{n}{Cov(X_i Y_j)}=\sum_{i=1}^{n}{Cov(X_i Y_i)}=-\frac{n}{36}$$ I mainly don't understand why the 2 sums turned into 1 sum. I think it should be $n$ times the answer. edit(after considering @blf's answer): So i guess: $$E[XY]=2\sum_{i=1}^{n}\sum_{j=i}^{n-i}i*j*{n\choose i}{n-i\choose j}*\frac{1}{6^{i}}*\frac{1}{6^j}*(\frac{4}{6})^{n-i-j}$$ $$-\sum_{i=1}^{n}i*i*{n\choose i}{n-i\choose i}*\frac{1}{6^{i}}*\frac{1}{6^i}*(\frac{4}{6})^{n-2i}$$ (I substract that last value because i counted the cases $i=j$ twice.) So if this is correct, i have no clue how to compute that. Help?","Let $X$ be the number of 1's and $Y$ be the number of 2's that occur in $n$ rolls of a fair die. Compute $Cov(X,Y)$. What's wrong with my solution? Here it is: $Cov(X,Y)=E[XY]-E[X]E[Y]$ Compute $E[X]$ as follows: $E[X]=1*{n\choose 1}*\frac{1}{6}*(\frac{5}{6})^{n-1}+2*{n\choose 2}*\frac{1}{6^{2}}*(\frac{5}{6})^{n-2}+...+n*{n\choose n}*\frac{1}{6^{n}}$ This is binomial distribution so $$E[X]=np=\frac{n}{6}$$ There's no difference between $E[X]$ and $E[Y]$ so $$E[X]=E[Y]$$ I believe all's correct so far. My problem is in computing $E[XY]$. This is what i've done: $E[XY]$ is the number of times we got 1 and 2 at the same time. Which is impossible. Hence $$E[XY]=0$$ Finally we can say $$Cov(X,Y)=0-\frac{n^2}{36}=-\frac{n^2}{36}$$ I found in some website that they got a final answer of $\frac{n}{36}$ because they divided the problem into 2 parts: (1) $X$ and $Y$ are dependent , (2) $X$ and $Y$ are independent. When they're independent $Cov(X,Y)=0$ , and when they're dependent $E[XY]=0$ and thus for roll $i$: $$Cov(X,Y)=E[X_i Y_i]-E[X_i]E[Y_i]=0-\frac{1}{36}=-\frac{1}{36}$$ And consequently: $$Cov(X,Y)=\sum_{i=1}^{n}\sum_{j=1}^{n}{Cov(X_i Y_j)}=\sum_{i=1}^{n}{Cov(X_i Y_i)}=-\frac{n}{36}$$ I mainly don't understand why the 2 sums turned into 1 sum. I think it should be $n$ times the answer. edit(after considering @blf's answer): So i guess: $$E[XY]=2\sum_{i=1}^{n}\sum_{j=i}^{n-i}i*j*{n\choose i}{n-i\choose j}*\frac{1}{6^{i}}*\frac{1}{6^j}*(\frac{4}{6})^{n-i-j}$$ $$-\sum_{i=1}^{n}i*i*{n\choose i}{n-i\choose i}*\frac{1}{6^{i}}*\frac{1}{6^i}*(\frac{4}{6})^{n-2i}$$ (I substract that last value because i counted the cases $i=j$ twice.) So if this is correct, i have no clue how to compute that. Help?",,"['probability', 'probability-distributions', 'expectation']"
61,If $X$ is independent of $Z$ and $Y$ is dependent with $Z$ is it possible for $X + Y$ to be independent of $Z$?,If  is independent of  and  is dependent with  is it possible for  to be independent of ?,X Z Y Z X + Y Z,"Suppose $X, Y$ and $Z$ are three non-degenerate random variables. Suppose that $X$ and $Z$ are independent and that $Y$ and $Z$ are not independent. Is it possible for $X + Y$ to be independent of $Z$? Can you provide an example? I am also interested in strengthening the assumptions about the relationship between $Y$ and $Z$. Suppose that $Y$ is discretely distributed with support $\{y_{1},y_{2},y_{3}\}$ and $Z$ is discretely distributed with support $\{z_{1}, z_{2}\}$. Suppose that $P[Y = y_{j} \vert Z = z_{0}] \neq P[Y = y_{j} \vert Z = z_{1}]$ for each $j = 1,2,3$. As before, assume that $X$ and $Z$ are independent. Now is it possible for $X + Y$ to be independent of $Z$? Does the answer change if $X$ is continuously distributed?","Suppose $X, Y$ and $Z$ are three non-degenerate random variables. Suppose that $X$ and $Z$ are independent and that $Y$ and $Z$ are not independent. Is it possible for $X + Y$ to be independent of $Z$? Can you provide an example? I am also interested in strengthening the assumptions about the relationship between $Y$ and $Z$. Suppose that $Y$ is discretely distributed with support $\{y_{1},y_{2},y_{3}\}$ and $Z$ is discretely distributed with support $\{z_{1}, z_{2}\}$. Suppose that $P[Y = y_{j} \vert Z = z_{0}] \neq P[Y = y_{j} \vert Z = z_{1}]$ for each $j = 1,2,3$. As before, assume that $X$ and $Z$ are independent. Now is it possible for $X + Y$ to be independent of $Z$? Does the answer change if $X$ is continuously distributed?",,"['probability', 'statistics']"
62,Expected number of random binary vectors to make matrix of order n,Expected number of random binary vectors to make matrix of order n,,"I have the following problem: I pick random vectors from $\mathrm{F}_2^n$. The chance that position $i$ is $1$ equals $p_i$, $0$ otherwise (each position is picked independently). Let $X$ be a random variable - a minimal number of vectors needed so that they span the whole space (in other words, number of vectors required to create a matrix of order $n$). What is the expected value of $X$? Or its variance? (the answer depends on $p_1$, $p_2$, $\ldots$). The answer for a special case of $p_1 = p_2 = \ldots = p_n = 0.5$ is: $E(X)$ is asymptotically $n + E$ where E is Erdős-Borwein Constant ($\approx 1.6$) $Var(X)$ is something close to $2.74403388876$ (asymptotically). I leave it as an exercise to warm up before the main question :). I see a blurry connection to Markov Chains, but I somewhat cannot make it work. Does anybody has any idea how to attack this? Cheers, Tomasz PS. It seems related to: Expected rank of a random binary matrix?","I have the following problem: I pick random vectors from $\mathrm{F}_2^n$. The chance that position $i$ is $1$ equals $p_i$, $0$ otherwise (each position is picked independently). Let $X$ be a random variable - a minimal number of vectors needed so that they span the whole space (in other words, number of vectors required to create a matrix of order $n$). What is the expected value of $X$? Or its variance? (the answer depends on $p_1$, $p_2$, $\ldots$). The answer for a special case of $p_1 = p_2 = \ldots = p_n = 0.5$ is: $E(X)$ is asymptotically $n + E$ where E is Erdős-Borwein Constant ($\approx 1.6$) $Var(X)$ is something close to $2.74403388876$ (asymptotically). I leave it as an exercise to warm up before the main question :). I see a blurry connection to Markov Chains, but I somewhat cannot make it work. Does anybody has any idea how to attack this? Cheers, Tomasz PS. It seems related to: Expected rank of a random binary matrix?",,"['linear-algebra', 'probability', 'matrices', 'markov-chains', 'expectation']"
63,"Conditional expectation by $\sigma (G_n,Y)$ when $Y$ is $G_\infty$-measurable",Conditional expectation by  when  is -measurable,"\sigma (G_n,Y) Y G_\infty","Let $G_n$ be a filtration (an increasing sequence of sigma-algebras), $Y$ a random variable that is $G_\infty$-measurable, and $X$ a random variable. Is it true that in $L^2$-norm, $$ \mathbb{E}[X \mid \sigma (G_n,Y)]- \mathbb{E}[X \mid G_n] \stackrel{n \rightarrow + \infty}{\rightarrow} 0 $$","Let $G_n$ be a filtration (an increasing sequence of sigma-algebras), $Y$ a random variable that is $G_\infty$-measurable, and $X$ a random variable. Is it true that in $L^2$-norm, $$ \mathbb{E}[X \mid \sigma (G_n,Y)]- \mathbb{E}[X \mid G_n] \stackrel{n \rightarrow + \infty}{\rightarrow} 0 $$",,"['probability', 'probability-theory', 'martingales', 'conditional-expectation']"
64,"Eigenvalues of the transition matrix for a periodic, irreducible markov chain [closed]","Eigenvalues of the transition matrix for a periodic, irreducible markov chain [closed]",,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question For an irreducible periodic Markov Chain with period $d >1$, the transition probability matrix will have $d$ eigenvalues with absolute value 1. Why ?","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question For an irreducible periodic Markov Chain with period $d >1$, the transition probability matrix will have $d$ eigenvalues with absolute value 1. Why ?",,"['probability', 'markov-chains']"
65,Probability problem- Are there atleast 3 balls with same colour radius and in same box?,Probability problem- Are there atleast 3 balls with same colour radius and in same box?,,"The question is as follows, it came in RMO in 1990. It most likely involves probability..as far I think. Two boxes contain between them 65 balls of several different sizes. Each ball is white, black, red or yellow. If you take any five balls of the same colour, at least two of them will always be of the same size (radius). Prove that there are at least three balls which lie in the same box, have the same colour and the same size (radius).","The question is as follows, it came in RMO in 1990. It most likely involves probability..as far I think. Two boxes contain between them 65 balls of several different sizes. Each ball is white, black, red or yellow. If you take any five balls of the same colour, at least two of them will always be of the same size (radius). Prove that there are at least three balls which lie in the same box, have the same colour and the same size (radius).",,"['probability', 'pigeonhole-principle']"
66,Proof that $A\subseteq B\implies\Bbb P(A) \le\Bbb P(B)$,Proof that,A\subseteq B\implies\Bbb P(A) \le\Bbb P(B),"I have to prove that $A\subseteq B\implies\Bbb P(A) \le\Bbb P(B)$, where $\Bbb P$ is probability. So far I have learned about direct proof, mathematical induction and proof by contraposition. This exact proposition is solved in my literature ( Elementare Einführung in die Wahrscheinlichkeitsrechnung by Karl Bosch), but it isn't explained at all and I don't want to copy sth. I don't understand. Which method should I choose and how is it done? Thanks! (c means ""is subset of"")","I have to prove that $A\subseteq B\implies\Bbb P(A) \le\Bbb P(B)$, where $\Bbb P$ is probability. So far I have learned about direct proof, mathematical induction and proof by contraposition. This exact proposition is solved in my literature ( Elementare Einführung in die Wahrscheinlichkeitsrechnung by Karl Bosch), but it isn't explained at all and I don't want to copy sth. I don't understand. Which method should I choose and how is it done? Thanks! (c means ""is subset of"")",,"['probability', 'probability-theory']"
67,Probability of insurance claims,Probability of insurance claims,,"Under an insurance policy, a maximum of five claims may be filed per year by a policy holder. Let $p_n$ be the probability that a policy holder files $n$ claims during a given year, where $n = 0, 1, 2, 3, 4, 5.$ An actuary makes the following observations: (i) $p_n\geq p_{n+1}$ for $0\leq n \leq 4$ (ii) The difference between $p_n$ and $p_{n+1}$ is the same for $0 \leq n \leq 4$ (iii) Exactly $40\%$ of policyholders file fewer than two claims during a given year. Calculate the probability that a random policyholder will file more than three claims during a given year. Source: Marcel B. Finan's A Probability Course for the Actuaries My thoughts: The goal is to find $P(n > 3)$ . We are given that $P(n<2)=.4$ , which means that $P(n\geq2)=.6$ . $P(n>3) = p_4 + p_5$ . From this, we know that $p_0 + p_1 = .4$ , and $p_2 + p_3 + p_4 + p_5 = .6$ ; so, $p_2 + p_3 + P(n > 3) = .6$ . But I don't know how to solve for $p_2$ or $p_3$ to find $P(n > 3)$ . Any help would be greatly appreciated.","Under an insurance policy, a maximum of five claims may be filed per year by a policy holder. Let be the probability that a policy holder files claims during a given year, where An actuary makes the following observations: (i) for (ii) The difference between and is the same for (iii) Exactly of policyholders file fewer than two claims during a given year. Calculate the probability that a random policyholder will file more than three claims during a given year. Source: Marcel B. Finan's A Probability Course for the Actuaries My thoughts: The goal is to find . We are given that , which means that . . From this, we know that , and ; so, . But I don't know how to solve for or to find . Any help would be greatly appreciated.","p_n n n = 0, 1, 2, 3, 4, 5. p_n\geq p_{n+1} 0\leq n \leq 4 p_n p_{n+1} 0 \leq n \leq 4 40\% P(n > 3) P(n<2)=.4 P(n\geq2)=.6 P(n>3) = p_4 + p_5 p_0 + p_1 = .4 p_2 + p_3 + p_4 + p_5 = .6 p_2 + p_3 + P(n > 3) = .6 p_2 p_3 P(n > 3)",['probability']
68,Probability - exactly one of A and B occurs,Probability - exactly one of A and B occurs,,"$A$ and $B$ are events that are subsets of the sample space. $C$ is the event that exactly one of $A$ and $B$ occurs. 1) Write an expression for $C$ in terms of unions, intersections and complements involving the events $A$ and $B$ 2) Let $P$ be a probability defined on the events of the sample space. Write an expression for $P(C)$ in terms of $P(A)$, $P(B)$ and $P(A \cap B)$. Give proof of your result. Would I be right in saying that 1) is just $C=(A \cup B)-(A \cap B)$ Or would it be? $(A \cap B^c) \cup (A^c \cap B)$","$A$ and $B$ are events that are subsets of the sample space. $C$ is the event that exactly one of $A$ and $B$ occurs. 1) Write an expression for $C$ in terms of unions, intersections and complements involving the events $A$ and $B$ 2) Let $P$ be a probability defined on the events of the sample space. Write an expression for $P(C)$ in terms of $P(A)$, $P(B)$ and $P(A \cap B)$. Give proof of your result. Would I be right in saying that 1) is just $C=(A \cup B)-(A \cap B)$ Or would it be? $(A \cap B^c) \cup (A^c \cap B)$",,['probability']
69,special sum of binomials distributions,special sum of binomials distributions,,"Let $X$ be a random variable. Let $X_p$ be distributed as a Binomial distribution with number of outcomes $X$ and probability $p$, i.e. $Bin(p, X)$. Consider the random variable, $$ Y = X_p + X_{1-p}. $$ What is the probability distribution of $Z : = Y - X$? Note that by linearity of expectations, $\mathbb{E}[Z]=0$.","Let $X$ be a random variable. Let $X_p$ be distributed as a Binomial distribution with number of outcomes $X$ and probability $p$, i.e. $Bin(p, X)$. Consider the random variable, $$ Y = X_p + X_{1-p}. $$ What is the probability distribution of $Z : = Y - X$? Note that by linearity of expectations, $\mathbb{E}[Z]=0$.",,"['probability', 'probability-theory', 'probability-distributions', 'random-variables', 'expectation']"
70,"How do I show that for any set of $n$ measurements, the fraction included in the interval $\bar{y} - ks$ to $\bar{y} + ks$ is at least $1 - 1/k^2$","How do I show that for any set of  measurements, the fraction included in the interval  to  is at least",n \bar{y} - ks \bar{y} + ks 1 - 1/k^2,"I'm having trouble showing this. From Mathematical Statistics (7 ed.) , problem 1.32: Let $k \geq 1$ . Show that for any set of $n$ measurements, the fraction included in the interval $\bar{y} - ks$ to $\bar{y} + ks$ it at least $(1 - 1/k^2)$ . $\bar{y}$ is the mean. The problem gives a hint: [ Hint : $$s^2 = \frac{1}{n-1}\left[\sum_{i=1}^n(y_i - \bar{y})^2\right].$$ In this expression, replace all deviations for which $|y_i - \bar{y}|$ is greater than or equal to $ks$ with $ks$ . Simplify.] I'm not sure what that means.","I'm having trouble showing this. From Mathematical Statistics (7 ed.) , problem 1.32: Let . Show that for any set of measurements, the fraction included in the interval to it at least . is the mean. The problem gives a hint: [ Hint : In this expression, replace all deviations for which is greater than or equal to with . Simplify.] I'm not sure what that means.",k \geq 1 n \bar{y} - ks \bar{y} + ks (1 - 1/k^2) \bar{y} s^2 = \frac{1}{n-1}\left[\sum_{i=1}^n(y_i - \bar{y})^2\right]. |y_i - \bar{y}| ks ks,"['probability', 'statistics']"
71,Memorylessness and Expectation,Memorylessness and Expectation,,"I have a specific problem I'm working on.  Let $X$ be an exponential random variable, and let $Y$ be a random variable defined by: $$ Y =  \begin{cases} 0      & \text{ if } X < d \\              (X - d) & \text{ if } X > d \end{cases} $$ So that $Y$ is $X$ ""with a deductible $d$"".  We are told that $E(Y) = 0.9 E(X)$, and by applying the law of total expectation and memoryless-ness, we can conclude that $P(X>d) = 0.9$. I've run into a few problems in computing $E(Y^2)$, and I've noticed a possible theorem that would make it all work very neatly.  In general, is it true that for a memoryless random variable $X$ and integrable function $g$, $$ E(g(X - d) \mid X > d) = E(g(X)) ? $$","I have a specific problem I'm working on.  Let $X$ be an exponential random variable, and let $Y$ be a random variable defined by: $$ Y =  \begin{cases} 0      & \text{ if } X < d \\              (X - d) & \text{ if } X > d \end{cases} $$ So that $Y$ is $X$ ""with a deductible $d$"".  We are told that $E(Y) = 0.9 E(X)$, and by applying the law of total expectation and memoryless-ness, we can conclude that $P(X>d) = 0.9$. I've run into a few problems in computing $E(Y^2)$, and I've noticed a possible theorem that would make it all work very neatly.  In general, is it true that for a memoryless random variable $X$ and integrable function $g$, $$ E(g(X - d) \mid X > d) = E(g(X)) ? $$",,"['probability', 'actuarial-science']"
72,Probability that a 3-digit randomly chosen number is divisible by 5,Probability that a 3-digit randomly chosen number is divisible by 5,,"$$\text{Set}\; = \{0,1,2,3,4,5,6\}$$ Find the probability that a three digit number which does not have the digit $0$ chosen  at the far left and is chosen at random from the set, is NOT a multiple of 5. $$P(\text{NOT A multiple of 5}) = \dfrac{6\cdot 7 \cdot 5}{6\cdot 7\cdot 7} = \dfrac{210}{294} = \frac{5}{7}$$ Is this correct?","$$\text{Set}\; = \{0,1,2,3,4,5,6\}$$ Find the probability that a three digit number which does not have the digit $0$ chosen  at the far left and is chosen at random from the set, is NOT a multiple of 5. $$P(\text{NOT A multiple of 5}) = \dfrac{6\cdot 7 \cdot 5}{6\cdot 7\cdot 7} = \dfrac{210}{294} = \frac{5}{7}$$ Is this correct?",,['probability']
73,Roulette betting system probability,Roulette betting system probability,,"The Fibonacci is a popular Roulette betting system that is based on a naturally occurring mathematical sequence. The sequence itself is cumulative. In other words, the next number is equal to the sum of the two previous ones. So the first 12 numbers in the sequence are: 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144 How this system works is: You progress through the sequence on losing bets and return towards the start with winning bets. Each time you lose, you move on to the next number in the sequence. Each time you win, you step back two numbers. I was wondering, if I were to use £10 as my initial bet betting on red and black only on the American Roulette wheel (with the double zeros), what are the chances of winning once in a series of 12 bets? That is, what are my chances of winning at least £10 in the total sum of money that I need to put in for the whole series of 12 bets: £10, £10, £20, £30, £50, £80, £130, £210, £340, £550, £890, £1440 Note that this is different than the Martingale system in that once you win a bet, you don't start over at the beginning of the sequence (£10 initial bet). Instead, you step back two numbers.","The Fibonacci is a popular Roulette betting system that is based on a naturally occurring mathematical sequence. The sequence itself is cumulative. In other words, the next number is equal to the sum of the two previous ones. So the first 12 numbers in the sequence are: 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144 How this system works is: You progress through the sequence on losing bets and return towards the start with winning bets. Each time you lose, you move on to the next number in the sequence. Each time you win, you step back two numbers. I was wondering, if I were to use £10 as my initial bet betting on red and black only on the American Roulette wheel (with the double zeros), what are the chances of winning once in a series of 12 bets? That is, what are my chances of winning at least £10 in the total sum of money that I need to put in for the whole series of 12 bets: £10, £10, £20, £30, £50, £80, £130, £210, £340, £550, £890, £1440 Note that this is different than the Martingale system in that once you win a bet, you don't start over at the beginning of the sequence (£10 initial bet). Instead, you step back two numbers.",,"['probability', 'fibonacci-numbers']"
74,Guess the birthday,Guess the birthday,,"I've come across the following little quiz game problem, which I've failed to solve. Say we have $15$ people, each of them of different age, and you want to guess their actual birthday - not just their age. You are allowed to guess as many times as you want, but the guessing goes as follows: Choose $5$ random people from the group. Each of them gives you four distinct possible dates, which they have chosen before the quiz started (so they will not change their options later in the game). One of these is correct. When you have guessed on the date for all five, they will tell you how many correct guesses, you had. They will not tell you which guesses were correct. Now the questions are: What is the probability to guess one specific person's birthday in the first try? How many times would you expect, you have to guess to get one person's birthday right? How many times would you expect, you have to guess to get all $15$ people's birthday right? What is the probability to get one person's birthday right in less than $200$ guesses? What is the probability to get all the people's birthday right in less than $3000$ guesses? The first question was rather easy to answer. When you pick randomly, you have to pick the person, whose birthday you would like to know, the probability of this is $\dfrac{1}{3}$, since we pick $\dfrac{1}{3}$ of the people in the group. To know one person's birthday for sure in the first try, you will have to answer his question correct. But as you will not know which question, you answered correct, when you ask, unless you answered all of them correct, you will have to answer correct, which has the probability $\left(\dfrac{1}{4}\right)^5 = \dfrac{1}{1024}$. So the answer to the first question is $\dfrac{1}{3072}$. To solve the next questions, I've tried to assume that we only have $5$ people, and that they are always chosen. This gives me a strategy to find one specific person's birthday, since I can just alter my answers to his question, and after maximum four guesses, I've guessed his birthday. Unfortunately, I cannot be sure that he will come up every time, I ask. Actually, I cannot be sure that he will ever come up, but I ""only"" have to find the expected amount of guesses. And this is where I got stuck. Any help in tackle this question will be so much appreciated! Hints or even solutions, anything. Thank you very much in advance!","I've come across the following little quiz game problem, which I've failed to solve. Say we have $15$ people, each of them of different age, and you want to guess their actual birthday - not just their age. You are allowed to guess as many times as you want, but the guessing goes as follows: Choose $5$ random people from the group. Each of them gives you four distinct possible dates, which they have chosen before the quiz started (so they will not change their options later in the game). One of these is correct. When you have guessed on the date for all five, they will tell you how many correct guesses, you had. They will not tell you which guesses were correct. Now the questions are: What is the probability to guess one specific person's birthday in the first try? How many times would you expect, you have to guess to get one person's birthday right? How many times would you expect, you have to guess to get all $15$ people's birthday right? What is the probability to get one person's birthday right in less than $200$ guesses? What is the probability to get all the people's birthday right in less than $3000$ guesses? The first question was rather easy to answer. When you pick randomly, you have to pick the person, whose birthday you would like to know, the probability of this is $\dfrac{1}{3}$, since we pick $\dfrac{1}{3}$ of the people in the group. To know one person's birthday for sure in the first try, you will have to answer his question correct. But as you will not know which question, you answered correct, when you ask, unless you answered all of them correct, you will have to answer correct, which has the probability $\left(\dfrac{1}{4}\right)^5 = \dfrac{1}{1024}$. So the answer to the first question is $\dfrac{1}{3072}$. To solve the next questions, I've tried to assume that we only have $5$ people, and that they are always chosen. This gives me a strategy to find one specific person's birthday, since I can just alter my answers to his question, and after maximum four guesses, I've guessed his birthday. Unfortunately, I cannot be sure that he will come up every time, I ask. Actually, I cannot be sure that he will ever come up, but I ""only"" have to find the expected amount of guesses. And this is where I got stuck. Any help in tackle this question will be so much appreciated! Hints or even solutions, anything. Thank you very much in advance!",,"['probability', 'combinatorics']"
75,Bottom to top explanation of the Mahanalobis distance?,Bottom to top explanation of the Mahanalobis distance?,,"I'm studying Pattern recognition and statistics and almost every book I open on the subject I bump into the concept of Mahanalobis distance . The books give sort of intuitive explanations, but still not good enough ones for me to actually really understand what is going on. If someone would ask me ""What is the Mahanalobis distance?"" I could only answer: ""It's this nice thing, which measures distance of some kind"" :) The definitions usually also contain eigenvectors and eigenvalues, which I have little trouble connecting to the Mahanalobis distance. I understand the definition of eigenvectors and eigenvalues, but how are they related to the Mahanalobis distance? Does it have something to do with changing the base in Linear Algebra etc.? I have also read these former questions on the subject: https://stats.stackexchange.com/questions/41222/what-is-mahanalobis-distance-how-is-it-used-in-pattern-recognition Intuitive explanations for Gaussian distribution function and mahalanobis distance http://www.jennessent.com/arcview/mahalanobis_description.htm The answers are good and pictures nice, but still I don't really get it...I have an idea but it's still in the dark. Can someone give a ""How would you explain it to your grandma""-explanation so that I could finally wrap this up and never again wonder what the heck is a Mahanalobis distance? :) Where does it come from, what, why? I will post this question on two different forums so that more people could have a chance answering it and I think many other people might be interested besides me :) Thank you in advance for help!","I'm studying Pattern recognition and statistics and almost every book I open on the subject I bump into the concept of Mahanalobis distance . The books give sort of intuitive explanations, but still not good enough ones for me to actually really understand what is going on. If someone would ask me ""What is the Mahanalobis distance?"" I could only answer: ""It's this nice thing, which measures distance of some kind"" :) The definitions usually also contain eigenvectors and eigenvalues, which I have little trouble connecting to the Mahanalobis distance. I understand the definition of eigenvectors and eigenvalues, but how are they related to the Mahanalobis distance? Does it have something to do with changing the base in Linear Algebra etc.? I have also read these former questions on the subject: https://stats.stackexchange.com/questions/41222/what-is-mahanalobis-distance-how-is-it-used-in-pattern-recognition Intuitive explanations for Gaussian distribution function and mahalanobis distance http://www.jennessent.com/arcview/mahalanobis_description.htm The answers are good and pictures nice, but still I don't really get it...I have an idea but it's still in the dark. Can someone give a ""How would you explain it to your grandma""-explanation so that I could finally wrap this up and never again wonder what the heck is a Mahanalobis distance? :) Where does it come from, what, why? I will post this question on two different forums so that more people could have a chance answering it and I think many other people might be interested besides me :) Thank you in advance for help!",,"['linear-algebra', 'probability', 'statistics', 'pattern-recognition']"
76,Probabilities of one-off events,Probabilities of one-off events,,"I am teaching 15 year olds basic probability. I am teaching them ""experimental probabilities"" (eg the probability that it will rain on a given day in August is 0.15) vs ""theoretical probabilities"" (eg the probability of throwing 3 Heads in a row is 1/8). When I asked them for some examples of experimental probabilities, a couple mentioned one-off events, like the probability that their team wins their next match, or that it rains tomorrow. I can't see that one-off events can have a probability other than 0 or 1. They cannot be re-run and hence their is no basis for determining or assigning a probability. I would like to correct my students if and when they next make this error, but before doing so I would like to make sure of my facts. Is it legitimate, for example, to talk about a 40% chance of rain tomorrow, and if so, what does it mean?","I am teaching 15 year olds basic probability. I am teaching them ""experimental probabilities"" (eg the probability that it will rain on a given day in August is 0.15) vs ""theoretical probabilities"" (eg the probability of throwing 3 Heads in a row is 1/8). When I asked them for some examples of experimental probabilities, a couple mentioned one-off events, like the probability that their team wins their next match, or that it rains tomorrow. I can't see that one-off events can have a probability other than 0 or 1. They cannot be re-run and hence their is no basis for determining or assigning a probability. I would like to correct my students if and when they next make this error, but before doing so I would like to make sure of my facts. Is it legitimate, for example, to talk about a 40% chance of rain tomorrow, and if so, what does it mean?",,['probability']
77,A basic intuition on a probability problem,A basic intuition on a probability problem,,"Two players take turns shooting at a target, with each shot by player $i$ hitting the target with probability $p_i$, $i=1,2$. Shooting ends when two consecutive shots hit the target. Let $\mu_i$ denote the mean number of shots taken when player $i$ shoots first, $i=1,2$. Now, I have calculated that $$\mu_1 - \mu_2 = \frac{p_2 - p_1}{p_1+p_2-p_1p_2-2}=\frac{q_2-q_1}{1+q_1q_2}$$ where $q_i=1-p_i, i=1,2 $ i.e. if the player with higher winning probability starts the game then the mean number of shots taken is higher than the case when the the player with lower winning probability starts the game. I don't understand the intuition behind this.","Two players take turns shooting at a target, with each shot by player $i$ hitting the target with probability $p_i$, $i=1,2$. Shooting ends when two consecutive shots hit the target. Let $\mu_i$ denote the mean number of shots taken when player $i$ shoots first, $i=1,2$. Now, I have calculated that $$\mu_1 - \mu_2 = \frac{p_2 - p_1}{p_1+p_2-p_1p_2-2}=\frac{q_2-q_1}{1+q_1q_2}$$ where $q_i=1-p_i, i=1,2 $ i.e. if the player with higher winning probability starts the game then the mean number of shots taken is higher than the case when the the player with lower winning probability starts the game. I don't understand the intuition behind this.",,['probability']
78,Existence of a $k$-coloring of a complete graph with no monochromatic subgraph,Existence of a -coloring of a complete graph with no monochromatic subgraph,k,"I'm currently working on the exercises of Noga Alon's book ""The Probabilistic method"". One exercise said that we are given a graph $H$ with $p$ vertices and that there exists a graph $G$ with $n > p$ vertices and $m$ edges containing no copy of $H$. We have to prove that if we have $k > \frac{n^2ln(n)}m$ and we can find a $k$-coloring of a complete graph $K_n$ with $k$ colors then there exists a graph with no monochromatic $H$. I know this should be proved with probabilistic method, I just don't know how. Could any one give me a hint?","I'm currently working on the exercises of Noga Alon's book ""The Probabilistic method"". One exercise said that we are given a graph $H$ with $p$ vertices and that there exists a graph $G$ with $n > p$ vertices and $m$ edges containing no copy of $H$. We have to prove that if we have $k > \frac{n^2ln(n)}m$ and we can find a $k$-coloring of a complete graph $K_n$ with $k$ colors then there exists a graph with no monochromatic $H$. I know this should be proved with probabilistic method, I just don't know how. Could any one give me a hint?",,"['probability', 'graph-theory', 'coloring']"
79,A basic doubt on Lebesgue integration,A basic doubt on Lebesgue integration,,Can anyone tell me at a high level (I am not aware of measure theory much) about Lebesgue integration and why measure is needed in case of Lebesgue integration? How the measure is used to calculate the horizontal strip mapped for a particular range?,Can anyone tell me at a high level (I am not aware of measure theory much) about Lebesgue integration and why measure is needed in case of Lebesgue integration? How the measure is used to calculate the horizontal strip mapped for a particular range?,,['probability']
80,$P(|X|\ge\lambda a)\ge (1-\lambda)^2a^2$ for $0\le \lambda \le 1$,for,P(|X|\ge\lambda a)\ge (1-\lambda)^2a^2 0\le \lambda \le 1,"If $E(X^2)=1$ and $E(|X|)\ge a >0$, then $P(|X|\ge\lambda a)\ge (1-\lambda)^2a^2$ for $0\le \lambda \le 1$. I can see from the well known inequality $E(|X|) \le E(|X|^2)^{1/2}$ that it must be the case that $a\le 1$. But what to do next I'm not sure.","If $E(X^2)=1$ and $E(|X|)\ge a >0$, then $P(|X|\ge\lambda a)\ge (1-\lambda)^2a^2$ for $0\le \lambda \le 1$. I can see from the well known inequality $E(|X|) \le E(|X|^2)^{1/2}$ that it must be the case that $a\le 1$. But what to do next I'm not sure.",,"['probability', 'probability-theory', 'inequality']"
81,Solution gives wrong answer to probability problem,Solution gives wrong answer to probability problem,,"Great Northern Airlines flies small planes in northern Canada and Alaska. Their largest plane can seat 16 passengers seated in 8 rows of 2. On a certain flight flown on this plane, they have 12 passengers and one large piece of equipment to transport. The equipment is so large that it requires two seats in the same row. The computer randomly assigns seats to the 12 passengers (no 2 passengers will have the same seat). What is the probability that there are two seats in the same row available for the equipment? This problem was posed on Brilliant last week, and now that the official solution is posted, I would like to know why my solution gives wrong result. Here is my solution: The number of ways we can seat 12 (identical) people on 16 seats is $16\choose 12$. Now the equipment can occupy any of the rows (8 possibilities), and the 12 people must be seated on the remaining 14 seats ($14 \choose12$ ways). Thus the desired probability is $$\frac{8 {14\choose12}}{16\choose12}=\frac25$$ The official solution gives $\frac5{13}$, but I don't understand what is wrong with mine.","Great Northern Airlines flies small planes in northern Canada and Alaska. Their largest plane can seat 16 passengers seated in 8 rows of 2. On a certain flight flown on this plane, they have 12 passengers and one large piece of equipment to transport. The equipment is so large that it requires two seats in the same row. The computer randomly assigns seats to the 12 passengers (no 2 passengers will have the same seat). What is the probability that there are two seats in the same row available for the equipment? This problem was posed on Brilliant last week, and now that the official solution is posted, I would like to know why my solution gives wrong result. Here is my solution: The number of ways we can seat 12 (identical) people on 16 seats is $16\choose 12$. Now the equipment can occupy any of the rows (8 possibilities), and the 12 people must be seated on the remaining 14 seats ($14 \choose12$ ways). Thus the desired probability is $$\frac{8 {14\choose12}}{16\choose12}=\frac25$$ The official solution gives $\frac5{13}$, but I don't understand what is wrong with mine.",,"['probability', 'combinatorics']"
82,Stopping time computations via martingales,Stopping time computations via martingales,,"I'm studying probability, and having trouble with the following problem (from this exam ). Suppose $X_j$ are i.i.d. random variables with $P(X_i=1) = P(X_i = -1) = 1/2$. Let $S_0=0$ and $S_n = X_1 + X_2, + \ldots + X_n$ (a simple symmetric random walk).  Define a stopping time $$T := \inf\{n: S_n \notin (-a,b)\},$$ where $a,b \in \mathbb{N}$. (1) Show $S_n^2-n$ is a martingale and compute $P(S_T = b)$. (2) Find $ET$. (3) Show that $S_n^4-6nS_n^2+3n^2+2n$ is a martingale and find $\text{var}(T)$. (1) Showing that $S_n^2 -n$ is a martingale is simple.  Also, $S_n$ is a martingale. Then since $T < \infty$ a.s., we get $$(-a)P(S_T = -a) + b(1-P(S_T=-a)) $$$$= ES_T = E\lim S_{\min(T,n)} \overset{D.C.T.}{=} \lim ES_{\min(T,n)} = \lim ES_0 = 0.$$ Thus $P(S_T = -a) = b/(a+b)$ and $P(S_T = b) = a/(a+b)$. (2) I want to say this: $$E(S_T^2-T) = E\lim(S_{\min(T,n)}^2-\min(T,n)) \overset{?}{=} \lim E(S_{\min(T,n)}^2 - \min(T,n)) = \lim E(S_0^2 - 0) = 0,$$ but I don't know how to justify interchanging the limit and expectation there. If this equality holds, then $ET = ES_T^2$, which I can compute. (3) I can show that the given expression is a martingale. Again, if exchanging limits and expectations is justified, I get $$ E(S_T^4-6TS_T^2+3T^2 +2T) = E(S_0^4-6\cdot 0 \cdot S_0 +3\cdot 0 +2 \cdot 0) = 0.$$ I can compute $ES_T^4$ and $E(2T)$, given part (2), but I don't know how to compute $ETS_T^2$. Any suggestions for how to fill the gaps here? Thanks.","I'm studying probability, and having trouble with the following problem (from this exam ). Suppose $X_j$ are i.i.d. random variables with $P(X_i=1) = P(X_i = -1) = 1/2$. Let $S_0=0$ and $S_n = X_1 + X_2, + \ldots + X_n$ (a simple symmetric random walk).  Define a stopping time $$T := \inf\{n: S_n \notin (-a,b)\},$$ where $a,b \in \mathbb{N}$. (1) Show $S_n^2-n$ is a martingale and compute $P(S_T = b)$. (2) Find $ET$. (3) Show that $S_n^4-6nS_n^2+3n^2+2n$ is a martingale and find $\text{var}(T)$. (1) Showing that $S_n^2 -n$ is a martingale is simple.  Also, $S_n$ is a martingale. Then since $T < \infty$ a.s., we get $$(-a)P(S_T = -a) + b(1-P(S_T=-a)) $$$$= ES_T = E\lim S_{\min(T,n)} \overset{D.C.T.}{=} \lim ES_{\min(T,n)} = \lim ES_0 = 0.$$ Thus $P(S_T = -a) = b/(a+b)$ and $P(S_T = b) = a/(a+b)$. (2) I want to say this: $$E(S_T^2-T) = E\lim(S_{\min(T,n)}^2-\min(T,n)) \overset{?}{=} \lim E(S_{\min(T,n)}^2 - \min(T,n)) = \lim E(S_0^2 - 0) = 0,$$ but I don't know how to justify interchanging the limit and expectation there. If this equality holds, then $ET = ES_T^2$, which I can compute. (3) I can show that the given expression is a martingale. Again, if exchanging limits and expectations is justified, I get $$ E(S_T^4-6TS_T^2+3T^2 +2T) = E(S_0^4-6\cdot 0 \cdot S_0 +3\cdot 0 +2 \cdot 0) = 0.$$ I can compute $ES_T^4$ and $E(2T)$, given part (2), but I don't know how to compute $ETS_T^2$. Any suggestions for how to fill the gaps here? Thanks.",,"['probability', 'measure-theory']"
83,"Probability that a string of $5$ characters from set$\{a,b,c,d,e,f\}$ contains exactly one '$a$', given that it contains at least one vowel","Probability that a string of  characters from set contains exactly one '', given that it contains at least one vowel","5 \{a,b,c,d,e,f\} a","This is a past paper exam question. It doesn't have a mark scheme, so I was hoping somebody could check this answer for me. It's non-calculator, but I don't expect that affects the method used. My solution is based on the accepted answer here: Combinatorics question about english letters (with consonants and vowels) Let P(A) be the probability that the string contains exactly one '$a$' Let P(B) be the probability that the string contains at least one vowel. Need to find $P(A|B) = \frac {P(B|A) \cdot P(A)} {P(B)}$ Total combinations of $5$ letters from the set of $5 = 6^5$ $P(A)$ can be satisfied by a single 'a' being in any of 5 places - $5 \choose 1$ , and the other 4 places in the string can be any of 5 characters - $4^5$. Then $P(A) = \frac {5 \cdot 4^5} {6^5}$ $P(B)$ : There are $6^5$ total combinations, as above.  Of these, There are $4^5$ with no vowels. Then, $P(B) = \frac {6^5 - 4^5} {6^5}$ Now, $P(B|A) = 1$, since $A$ is sufficient for $B$ - there must be a vowel if there is an 'a' So, $P(A|B) = \frac {P(B|A) \cdot P(A)} {P(B)} = \frac {P(A)} {P(B)} = \frac {\frac {5 \cdot 4^5} {6^5}} {\frac {6^5 - 4^5} {6^5}}$ -- This seems to make sense, but I'm not completely convinced about my calculations, particularly for $P(A)$. Would anybody be able to either confirm my solution or point out where I went wrong?","This is a past paper exam question. It doesn't have a mark scheme, so I was hoping somebody could check this answer for me. It's non-calculator, but I don't expect that affects the method used. My solution is based on the accepted answer here: Combinatorics question about english letters (with consonants and vowels) Let P(A) be the probability that the string contains exactly one '$a$' Let P(B) be the probability that the string contains at least one vowel. Need to find $P(A|B) = \frac {P(B|A) \cdot P(A)} {P(B)}$ Total combinations of $5$ letters from the set of $5 = 6^5$ $P(A)$ can be satisfied by a single 'a' being in any of 5 places - $5 \choose 1$ , and the other 4 places in the string can be any of 5 characters - $4^5$. Then $P(A) = \frac {5 \cdot 4^5} {6^5}$ $P(B)$ : There are $6^5$ total combinations, as above.  Of these, There are $4^5$ with no vowels. Then, $P(B) = \frac {6^5 - 4^5} {6^5}$ Now, $P(B|A) = 1$, since $A$ is sufficient for $B$ - there must be a vowel if there is an 'a' So, $P(A|B) = \frac {P(B|A) \cdot P(A)} {P(B)} = \frac {P(A)} {P(B)} = \frac {\frac {5 \cdot 4^5} {6^5}} {\frac {6^5 - 4^5} {6^5}}$ -- This seems to make sense, but I'm not completely convinced about my calculations, particularly for $P(A)$. Would anybody be able to either confirm my solution or point out where I went wrong?",,"['probability', 'combinatorics', 'discrete-mathematics']"
84,Probability someone's phone will ring during a movie?,Probability someone's phone will ring during a movie?,,"Trying to figure out what the probability is that in a room of 200 people what the probability that at least one will get a phone call during a certain time window... In this case 2 hours Assumptions: Average person gets 5 calls a day (distributed randomly over 16 hours). Those calls happen during a 16 hour time window. Movie length = 2 hours (120 minutes) If there was only one person in the room, it's pretty easy to calculate... If caller only got 1 call a day, the chances of it happening while in the movie would be 1/(16/2) = 1/8. = 5 calls/day * 1/8 = 5/8 But, now how do I then apply this if there is 200 people in the room.  I think I need to do some type of binomial coefficient? Real Life Application My actual application is to determine what the likelyhood of someone getting a call is during a 5 minute presentation at a conference.  But, thought the movie example was more universal.","Trying to figure out what the probability is that in a room of 200 people what the probability that at least one will get a phone call during a certain time window... In this case 2 hours Assumptions: Average person gets 5 calls a day (distributed randomly over 16 hours). Those calls happen during a 16 hour time window. Movie length = 2 hours (120 minutes) If there was only one person in the room, it's pretty easy to calculate... If caller only got 1 call a day, the chances of it happening while in the movie would be 1/(16/2) = 1/8. = 5 calls/day * 1/8 = 5/8 But, now how do I then apply this if there is 200 people in the room.  I think I need to do some type of binomial coefficient? Real Life Application My actual application is to determine what the likelyhood of someone getting a call is during a 5 minute presentation at a conference.  But, thought the movie example was more universal.",,"['probability', 'binomial-coefficients']"
85,Uniformly distributed probability problem,Uniformly distributed probability problem,,"May you have an idea for the following exercise I found from some olympiad. Each day you have to bring home one full can of water. To do so you go to the next well and make the can full. On the way home you loose a proportion which is uniformly distributed on [0,1]. Question: How many times, on average, do you need to go and get water each day? Intuitively I would guess the answer is 2 but I do not know how to show this formally.","May you have an idea for the following exercise I found from some olympiad. Each day you have to bring home one full can of water. To do so you go to the next well and make the can full. On the way home you loose a proportion which is uniformly distributed on [0,1]. Question: How many times, on average, do you need to go and get water each day? Intuitively I would guess the answer is 2 but I do not know how to show this formally.",,"['probability', 'contest-math']"
86,"Conditional independence: does $(X \bot Y \mid Z) \land (X \bot Y \mid W) \implies (X \bot Y \mid Z , W)$?",Conditional independence: does ?,"(X \bot Y \mid Z) \land (X \bot Y \mid W) \implies (X \bot Y \mid Z , W)","I'm reading a book about probabilistic graphical models by Daphie Koller and Nir Friedman and I'm stuck at the following exercise: Is it true that $ (X \bot Y \mid Z) \land (X \bot Y \mid W) \implies (X \bot Y \mid Z , W) $? Any ideas how to prove or disprove the statement? $X \bot Y \mid Z$ denotes conditional independence of X and Y given Z, i.e., $P(X\mid Z)=P(X\mid Y,Z)$.","I'm reading a book about probabilistic graphical models by Daphie Koller and Nir Friedman and I'm stuck at the following exercise: Is it true that $ (X \bot Y \mid Z) \land (X \bot Y \mid W) \implies (X \bot Y \mid Z , W) $? Any ideas how to prove or disprove the statement? $X \bot Y \mid Z$ denotes conditional independence of X and Y given Z, i.e., $P(X\mid Z)=P(X\mid Y,Z)$.",,"['probability', 'conditional-probability']"
87,Derivation of softmax function,Derivation of softmax function,,"I'm reading Bishop's book on Pattern Recognition and machine learning and I wanted to reproduce a calculation for the softmax function, also known as normalized exponential. Basically, the calculation requires to get the multinomial distribution into its form as a member of the exponential family: $$p(x|\eta) = h(x)g(\eta)\exp{\{\eta^{T}u(x)\}}$$ Starting from $\exp{\{\sum_{k=1}^{M}x_{k}\ln{\mu_{k}}\}}$ and after a few steps, we recognize that $\eta_{k}$ is given by: $$\ln{\left[{\frac{\mu_{k}}{1-\sum_{j}^{M-1}{\mu_{j}}} }\right]} = \eta_{k}$$ then it says: which we can solve for $\mu_{k}$ by first summing both sides over $k$ and then rearranging and back-substituting to give: $$\mu_{k}=\frac{\exp{\{\eta_{k}\}}}{1+\sum_{j}\exp{\{\eta_{j}\}}}$$ But that's not what I get. Instead, I obtained (assuming $\sum_{k}\mu_{k}=1$) $$\mu_{k}=\frac{\exp{\{\eta_{k}\}}}{\sum_{j}\exp{\{\eta_{j}\}}}$$ Wikipedia seems to agree with my answer but I'd like to get a confirmation or correct the derivation I did.","I'm reading Bishop's book on Pattern Recognition and machine learning and I wanted to reproduce a calculation for the softmax function, also known as normalized exponential. Basically, the calculation requires to get the multinomial distribution into its form as a member of the exponential family: $$p(x|\eta) = h(x)g(\eta)\exp{\{\eta^{T}u(x)\}}$$ Starting from $\exp{\{\sum_{k=1}^{M}x_{k}\ln{\mu_{k}}\}}$ and after a few steps, we recognize that $\eta_{k}$ is given by: $$\ln{\left[{\frac{\mu_{k}}{1-\sum_{j}^{M-1}{\mu_{j}}} }\right]} = \eta_{k}$$ then it says: which we can solve for $\mu_{k}$ by first summing both sides over $k$ and then rearranging and back-substituting to give: $$\mu_{k}=\frac{\exp{\{\eta_{k}\}}}{1+\sum_{j}\exp{\{\eta_{j}\}}}$$ But that's not what I get. Instead, I obtained (assuming $\sum_{k}\mu_{k}=1$) $$\mu_{k}=\frac{\exp{\{\eta_{k}\}}}{\sum_{j}\exp{\{\eta_{j}\}}}$$ Wikipedia seems to agree with my answer but I'd like to get a confirmation or correct the derivation I did.",,"['probability', 'probability-distributions']"
88,Number of possible positions for the Rush Hour puzzle,Number of possible positions for the Rush Hour puzzle,,"I'm working on a 2-d Puzzle Rush Hour which is a six * six bored that can be filled with various items : 2 blocks length horizontally vertically oriented car - let's call it 1 3 blocks length horizontally  oriented car ----------- 2 2 blocks length vertically oriented car -------------- 3 3 blocks length vertically oriented car -------------- 4 2 blocks length horizontally oriented target car --- 5 1 empty block. --------------------------------------- 6 http://www.1800pocketpc.com/blog/wp-content/uploads/2009/11/rushhour.jpg each square on the board can only be filled from one of the above. What I'm trying to calculate is the number of possible combinations we could have for this puzzle. My first thought was (6^36) since we have 36 field with 6 options for each ( just like coin flipping) but that is n * 10^28. which is a lot ! and far from accurate. The solution is a partial set of that value because we have a lot of extra constrains on it, which are: 1 must come only after 1 (since the car is two blocks in length) and not at the end of the line ( location (1) % 6 != 5). same condition apply to 2 but this time 2 is repeated 3 times and (location (2) % 6 < 5) 5 must only be between (12 and 17) and follow 1 restrictions. 6 similar rules to 1 but applies vertically. ..... Now the question is how can I represent these limitations to write an equation that will give me the number of all possible outcomes. Note I've read in this: Paper that the solution is around 10^10 . which is ridiculously lower than the first value (10^28). Note: I'm searching for an answer out of pure curiosity.","I'm working on a 2-d Puzzle Rush Hour which is a six * six bored that can be filled with various items : 2 blocks length horizontally vertically oriented car - let's call it 1 3 blocks length horizontally  oriented car ----------- 2 2 blocks length vertically oriented car -------------- 3 3 blocks length vertically oriented car -------------- 4 2 blocks length horizontally oriented target car --- 5 1 empty block. --------------------------------------- 6 http://www.1800pocketpc.com/blog/wp-content/uploads/2009/11/rushhour.jpg each square on the board can only be filled from one of the above. What I'm trying to calculate is the number of possible combinations we could have for this puzzle. My first thought was (6^36) since we have 36 field with 6 options for each ( just like coin flipping) but that is n * 10^28. which is a lot ! and far from accurate. The solution is a partial set of that value because we have a lot of extra constrains on it, which are: 1 must come only after 1 (since the car is two blocks in length) and not at the end of the line ( location (1) % 6 != 5). same condition apply to 2 but this time 2 is repeated 3 times and (location (2) % 6 < 5) 5 must only be between (12 and 17) and follow 1 restrictions. 6 similar rules to 1 but applies vertically. ..... Now the question is how can I represent these limitations to write an equation that will give me the number of all possible outcomes. Note I've read in this: Paper that the solution is around 10^10 . which is ridiculously lower than the first value (10^28). Note: I'm searching for an answer out of pure curiosity.",,"['probability', 'statistics']"
89,probabilty problem how to solve,probabilty problem how to solve,,Six cards are drawn with replacement form on ordinary deck. What is the probabilty that each of four suits will be represented at least once among the six cards?,Six cards are drawn with replacement form on ordinary deck. What is the probabilty that each of four suits will be represented at least once among the six cards?,,['probability']
90,Combinatorics and Probability Problem Concerning Poker Hands,Combinatorics and Probability Problem Concerning Poker Hands,,"The problem I am currently working on is: In five-card poker, a straight consists of five cards with adja-cent denominations (e.g., 9 of clubs, 10 of hearts, jack of hearts, queen of spades, and king of clubs). Assuming that aces can be high or low, if you are dealt a five-card hand, what is the probability that it will be a straight with high card 10? What is the probability that it will be a straight? What is the probability that it will be a straight flush (all cards in the same suit)? ---------------------------------------------------------------------------------- First, I calculated the number of possible 5-card hands that can be dealt out: ${{52}\choose{5}}=2598960$. To answer the first question, I imagined how the cards could be dealt out to generate a straight, since order doesn't matter. I know that, to make a straight, Jacks , Queens, Kings, Aces, 1s, 2s ,3s 4s, and 5s are out of the question. So, if I was dealt a 10, there would be 4 choices (two black and two red); and since either a red or a black will be chosen, then there are only two possibilities for the 9. If the 10 happened to be hearts or diamonds, then the the 9 would have to be a spades or clubs. Using this reasoning for the rest of them, I calculated that there would $4⋅2⋅2⋅2⋅2=64$ different straight hands with 10 as the highest card. Thus, the probability would be $64/2598960=.000024625$. However, the answer is .000394. What did I do wrong? EDIT: To calculate the probability of getting a straight, would it be easier to find the number of hands that aren't straights and subtract that from the total number of hands? Or is there some direct method that I can't seem to reason through?","The problem I am currently working on is: In five-card poker, a straight consists of five cards with adja-cent denominations (e.g., 9 of clubs, 10 of hearts, jack of hearts, queen of spades, and king of clubs). Assuming that aces can be high or low, if you are dealt a five-card hand, what is the probability that it will be a straight with high card 10? What is the probability that it will be a straight? What is the probability that it will be a straight flush (all cards in the same suit)? ---------------------------------------------------------------------------------- First, I calculated the number of possible 5-card hands that can be dealt out: ${{52}\choose{5}}=2598960$. To answer the first question, I imagined how the cards could be dealt out to generate a straight, since order doesn't matter. I know that, to make a straight, Jacks , Queens, Kings, Aces, 1s, 2s ,3s 4s, and 5s are out of the question. So, if I was dealt a 10, there would be 4 choices (two black and two red); and since either a red or a black will be chosen, then there are only two possibilities for the 9. If the 10 happened to be hearts or diamonds, then the the 9 would have to be a spades or clubs. Using this reasoning for the rest of them, I calculated that there would $4⋅2⋅2⋅2⋅2=64$ different straight hands with 10 as the highest card. Thus, the probability would be $64/2598960=.000024625$. However, the answer is .000394. What did I do wrong? EDIT: To calculate the probability of getting a straight, would it be easier to find the number of hands that aren't straights and subtract that from the total number of hands? Or is there some direct method that I can't seem to reason through?",,"['probability', 'combinatorics', 'statistics']"
91,Probability of rolling the same number twice,Probability of rolling the same number twice,,"Math novice here. With a 10-sided die, the probably of rolling '1' is 10%. I'm tempted to think the probability of rolling '1' with two consecutive rolls is 20%. Would I be correct? Not sure if I need to factor in the first roll i.e. 10% + (10% - probability of NOT rolling 1 in the first roll). Or am I overthinking this? CLARIFICATION: I mean the probability of rolling a 1, then another 1.","Math novice here. With a 10-sided die, the probably of rolling '1' is 10%. I'm tempted to think the probability of rolling '1' with two consecutive rolls is 20%. Would I be correct? Not sure if I need to factor in the first roll i.e. 10% + (10% - probability of NOT rolling 1 in the first roll). Or am I overthinking this? CLARIFICATION: I mean the probability of rolling a 1, then another 1.",,"['probability', 'dice']"
92,Compute $P(X>40\; |\; X>10)$ where $X$ has an exponential distribution,Compute  where  has an exponential distribution,P(X>40\; |\; X>10) X,"Please could someone advise if I have interpreted this problem correctly Let $X$ have an exponential distribution  with a mean of $i = 20$ (1) Compute $P(X>40 \;| \;X>10)$ I believe the correct solution here is to find $P(X>40)$ because of the inclusion / exclusion principle. That is if we define the event $A = P(X>40)$ and the event $B = P(X>10)$. In addition, define $A \cap B$ as $P(X>10)$. Then to compute (1) we find the following $P(X>40) \cup P(X>10) - P(X>10)$ which is $$1- (1-e^{-\frac{30}{20}})=0.2231$$ EDIT Due to the ""memorylessness"" of the probability distribution $$P(X>40 \mid X>10)= P(X>30) $$ Thanks in advance","Please could someone advise if I have interpreted this problem correctly Let $X$ have an exponential distribution  with a mean of $i = 20$ (1) Compute $P(X>40 \;| \;X>10)$ I believe the correct solution here is to find $P(X>40)$ because of the inclusion / exclusion principle. That is if we define the event $A = P(X>40)$ and the event $B = P(X>10)$. In addition, define $A \cap B$ as $P(X>10)$. Then to compute (1) we find the following $P(X>40) \cup P(X>10) - P(X>10)$ which is $$1- (1-e^{-\frac{30}{20}})=0.2231$$ EDIT Due to the ""memorylessness"" of the probability distribution $$P(X>40 \mid X>10)= P(X>30) $$ Thanks in advance",,"['probability', 'statistics']"
93,Is Uncorrelatedness sufficient for the CLT?,Is Uncorrelatedness sufficient for the CLT?,,"I am looking for a ""counterexample"" to a central limit type setup. Here is my question: Is there an example of a sequence of identically distributed random variables $(X_n)_{n\in\mathbb{N}}$, with mean zero and variance 1, which is only UNCORRELATED, but not independent (so we do not have an i.i.d. sequence), that violates the statement of the central limit theorem, i.e., we do NOT have that $$T^{-1/2}\sum_{t=1}^TX_t \Rightarrow N(0,1), \quad \text{ as }\,\,T \rightarrow \infty.$$ (In particular, is there an example where the above expression does not converge in distribution at all?) This would show that independence in the CLT cannot be weakened to mere uncorrelatedness. I can't figure out an example for the above. Many thanks for any thoughts!","I am looking for a ""counterexample"" to a central limit type setup. Here is my question: Is there an example of a sequence of identically distributed random variables $(X_n)_{n\in\mathbb{N}}$, with mean zero and variance 1, which is only UNCORRELATED, but not independent (so we do not have an i.i.d. sequence), that violates the statement of the central limit theorem, i.e., we do NOT have that $$T^{-1/2}\sum_{t=1}^TX_t \Rightarrow N(0,1), \quad \text{ as }\,\,T \rightarrow \infty.$$ (In particular, is there an example where the above expression does not converge in distribution at all?) This would show that independence in the CLT cannot be weakened to mere uncorrelatedness. I can't figure out an example for the above. Many thanks for any thoughts!",,"['probability', 'statistics', 'probability-theory']"
94,Brownian motion interesting question,Brownian motion interesting question,,"I found this interesting question on the internet, but unfortunately I could not solve it. What is probability that Brownian motion (starting at origin) has value 1 before having value -2?","I found this interesting question on the internet, but unfortunately I could not solve it. What is probability that Brownian motion (starting at origin) has value 1 before having value -2?",,"['probability', 'stochastic-processes', 'brownian-motion']"
95,Expectation inequality,Expectation inequality,,"Let $X, Y$ be random variables with $0 \leq X \leq Y$ and $\mathbb E[Y]=1$. Let $t>0$. Does the inequality $$ \mathbb E[e^{tX}] \leq x\, \mathbb E[e^{tY}]+1-x $$ where $x=\mathbb E[X]$ hold?","Let $X, Y$ be random variables with $0 \leq X \leq Y$ and $\mathbb E[Y]=1$. Let $t>0$. Does the inequality $$ \mathbb E[e^{tX}] \leq x\, \mathbb E[e^{tY}]+1-x $$ where $x=\mathbb E[X]$ hold?",,"['probability', 'inequality']"
96,What is the law of the ratio of two independent gaussian random variables? [duplicate],What is the law of the ratio of two independent gaussian random variables? [duplicate],,"This question already has answers here : Closed 11 years ago . Possible Duplicate: How calculate the probability density function of $Z = X_1/X_2$ The probability density function of the ratio of two normal R.V.s Consider two independent randon variables $N , N' \sim \mathcal N (0,1)$ .What is the law of $N/N'$ ?",This question already has answers here : Closed 11 years ago . Possible Duplicate: How calculate the probability density function of The probability density function of the ratio of two normal R.V.s Consider two independent randon variables .What is the law of ?,"Z = X_1/X_2 N , N' \sim \mathcal N (0,1) N/N'","['probability', 'probability-theory']"
97,Funny problem about stochastic integrals and Ito' s lemma,Funny problem about stochastic integrals and Ito' s lemma,,"Consider a probability filtred space  $ (\Omega, \mathcal F, \mathcal F_ t, \mathbb P)$ and a continuous $\mathcal F _t$-martingal starting from $0$, $ M = (M_t)_{t \geq 0}$, such that $\left \langle M \right \rangle_\infty \leq 1$ $\mathbb P$-ps. Now, we define by recurence $ \forall n \in \mathbb{N}$ $$  I^{(o)}_t \equiv  1, \ I^{(n+1)}_t = \int _0 ^t I^{(n)}_s d M_s \ , \ t \geq 0 $$ The question: How to show the following relation ? $$ \forall n \geq 2 :  \ \ n I ^{(n)}_t = I ^{(n-1)}_t M_t - I ^{(n-2)}_t \left \langle M \right \rangle_t$$ Elements of answer: Let's suppose by induction hypothesis that $(n -1) I ^{(n-1)}_t = I ^{(n-2)}_t M_t - I ^{(n-3)}_t \left \langle M \right \rangle_t$ By Ito's lemma, we have that \begin{align} I ^{(n-1)}_t M_t &=  \int _0 ^t  I ^{(n-1)}_s dM_s+  \int _0 ^t   M_s \ d I ^{(n-1)}_s + \left \langle I ^{(n-1)},M \right \rangle_t  \\& =I ^{(n)}_t +\int _0 ^t   M_s \ I ^{(n-2)}_s  d M_s+ \int _0 ^t    \ I ^{(n-2)}_s  \ I ^{(0)}_s d \left \langle M \right \rangle_s \\&=  I ^{(n)}_t +\int _0 ^t  \left[ (n -1) I ^{(n-1)}_t+ I ^{(n-3)}_t \left \langle M \right \rangle_t\right]  d M_s+ \int _0 ^t    \ I ^{(n-2)}_s  \ I ^{(0)}_s d \left \langle M \right \rangle_s \\& = nI ^{(n)}_t + \int _0 ^t   I ^{(n-3)}_t \left \langle M \right \rangle_t  d M_s+ \int _0 ^t    \ I ^{(n-2)}_s  \ I ^{(0)}_s d \left \langle M \right \rangle_s \\ & \overset{\text{Ito's lemma}}{=} nI ^{(n)}_t +I ^{(n-2)}_t \left \langle M \right \rangle_t -\left \langle I ^{(n-2)},\left \langle  M \right \rangle\right\rangle_t\end{align} which is almost the proof except the fact that I still don't know how to show that   $$\left \langle I ^{(n-2)},\left \langle  M \right \rangle\right\rangle_t=0$$ Someone can help me on it, please?","Consider a probability filtred space  $ (\Omega, \mathcal F, \mathcal F_ t, \mathbb P)$ and a continuous $\mathcal F _t$-martingal starting from $0$, $ M = (M_t)_{t \geq 0}$, such that $\left \langle M \right \rangle_\infty \leq 1$ $\mathbb P$-ps. Now, we define by recurence $ \forall n \in \mathbb{N}$ $$  I^{(o)}_t \equiv  1, \ I^{(n+1)}_t = \int _0 ^t I^{(n)}_s d M_s \ , \ t \geq 0 $$ The question: How to show the following relation ? $$ \forall n \geq 2 :  \ \ n I ^{(n)}_t = I ^{(n-1)}_t M_t - I ^{(n-2)}_t \left \langle M \right \rangle_t$$ Elements of answer: Let's suppose by induction hypothesis that $(n -1) I ^{(n-1)}_t = I ^{(n-2)}_t M_t - I ^{(n-3)}_t \left \langle M \right \rangle_t$ By Ito's lemma, we have that \begin{align} I ^{(n-1)}_t M_t &=  \int _0 ^t  I ^{(n-1)}_s dM_s+  \int _0 ^t   M_s \ d I ^{(n-1)}_s + \left \langle I ^{(n-1)},M \right \rangle_t  \\& =I ^{(n)}_t +\int _0 ^t   M_s \ I ^{(n-2)}_s  d M_s+ \int _0 ^t    \ I ^{(n-2)}_s  \ I ^{(0)}_s d \left \langle M \right \rangle_s \\&=  I ^{(n)}_t +\int _0 ^t  \left[ (n -1) I ^{(n-1)}_t+ I ^{(n-3)}_t \left \langle M \right \rangle_t\right]  d M_s+ \int _0 ^t    \ I ^{(n-2)}_s  \ I ^{(0)}_s d \left \langle M \right \rangle_s \\& = nI ^{(n)}_t + \int _0 ^t   I ^{(n-3)}_t \left \langle M \right \rangle_t  d M_s+ \int _0 ^t    \ I ^{(n-2)}_s  \ I ^{(0)}_s d \left \langle M \right \rangle_s \\ & \overset{\text{Ito's lemma}}{=} nI ^{(n)}_t +I ^{(n-2)}_t \left \langle M \right \rangle_t -\left \langle I ^{(n-2)},\left \langle  M \right \rangle\right\rangle_t\end{align} which is almost the proof except the fact that I still don't know how to show that   $$\left \langle I ^{(n-2)},\left \langle  M \right \rangle\right\rangle_t=0$$ Someone can help me on it, please?",,"['probability', 'stochastic-processes', 'stochastic-calculus', 'stochastic-integrals']"
98,probability that the maximal value drawn from normal distributions was drawn from each,probability that the maximal value drawn from normal distributions was drawn from each,,"This is somewhat similar to a number of existing questions, e.g. this one , but I couldn't find a way to use them to solve this specific case. Let $X_1..X_n$ be normally distributed variables, with means $\mu_1..\mu_n$ and standard deviations $\sigma_1..\sigma_n$. Let $z_1..z_n$ be numbers drawn from each of the respective distributions, and let $z_{max}=max\{z_i\}$. What can be said about the probability that $z_{max}$  was drawn from each of the distributions $\{X_i\}$? In other words (and I'm not sure about the notation here), can $P[number\ drawn\ from\ X_i\ is\ maximal]$ be calculated? At first glance this doesn't seem very tough, but I've tried various approaches here and none seemed to yield the correct answers for obvious cases, e.g. three normal distributions with the same mean and standard deviation. Any ideas or hints will be appreciated.","This is somewhat similar to a number of existing questions, e.g. this one , but I couldn't find a way to use them to solve this specific case. Let $X_1..X_n$ be normally distributed variables, with means $\mu_1..\mu_n$ and standard deviations $\sigma_1..\sigma_n$. Let $z_1..z_n$ be numbers drawn from each of the respective distributions, and let $z_{max}=max\{z_i\}$. What can be said about the probability that $z_{max}$  was drawn from each of the distributions $\{X_i\}$? In other words (and I'm not sure about the notation here), can $P[number\ drawn\ from\ X_i\ is\ maximal]$ be calculated? At first glance this doesn't seem very tough, but I've tried various approaches here and none seemed to yield the correct answers for obvious cases, e.g. three normal distributions with the same mean and standard deviation. Any ideas or hints will be appreciated.",,"['probability', 'normal-distribution']"
99,Probability of Picking the Same Password from a $k$ letter alphabet,Probability of Picking the Same Password from a  letter alphabet,k,"John and Mary both pick passwords at random from a $k$ letter alphabet.  There are up to $n$ letters allowed in the password.  Repetitions are allowed.  What is the probability that they pick the same password? There are $\sum _{i=1}^{n}k^i$ possible passwords, and $\frac{1}{\sum _{i=1}^{n}k^i}$ probability of picking any particular password. I'm not sure how to set the problem up from here.  I know that the answer is either John or Mary picks a password and then the probability of the other picking the same password is $\frac{1}{\sum _{i=1}^{n}k^i}$, but I'm not sure why.  I initially thought it would be $(\frac{1}{\sum _{i=1}^{n}k^i})^2$","John and Mary both pick passwords at random from a $k$ letter alphabet.  There are up to $n$ letters allowed in the password.  Repetitions are allowed.  What is the probability that they pick the same password? There are $\sum _{i=1}^{n}k^i$ possible passwords, and $\frac{1}{\sum _{i=1}^{n}k^i}$ probability of picking any particular password. I'm not sure how to set the problem up from here.  I know that the answer is either John or Mary picks a password and then the probability of the other picking the same password is $\frac{1}{\sum _{i=1}^{n}k^i}$, but I'm not sure why.  I initially thought it would be $(\frac{1}{\sum _{i=1}^{n}k^i})^2$",,"['probability', 'combinatorics']"
