,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Probabilistic bound on difference of Lipschitz random function,Probabilistic bound on difference of Lipschitz random function,,"I am currently facing the following problem : Let $(X_1,Z_1),\ldots,(X_n,Z_n)$ be $n$ i.i.d. sample points from some distribution $p$ supported on $\mathcal X\times\{-1,1\}$ where $\mathcal X\subseteq \mathbb R^d$ is some compact subset. From this sample, I can define a function $$g :\lambda\mapsto g(\lambda\ |\ (X_i,Z_i)_{1\le i\le n})=:\theta_\lambda\in\mathbb R^p$$ Defined for any $\lambda >0$ . I do not know the explicit relation between $g$ and the $(X_i,Z_i)$ (it is the unique argmin of a function of the sample), but I know that $g$ is Lipschitz-continuous with respect to $\lambda$ (it is even differentiable if that helps). I would like to bound $\|\theta_\lambda-\theta_{\lambda/2}\| $ in probability. That is, for any positive $\varepsilon>0$ , I would like to get $$\mathbb P\left(\|\theta_\lambda-\theta_{\lambda/2}\| >\varepsilon\right)\le G(\varepsilon,n)\tag1 $$ Where $G$ is some deterministic function that goes to zero when $n$ goes to infinity. Here, the choice of norm $\|\cdot\| $ doesn't really matter since all norms in $\mathbb R^p$ are equivalent. My question : How to prove (or disprove ?) inequality $(1)$ ? Are some additional assumptions on $g$ needed for it to hold ? This a a bit different from usual concentration inequalities so I'm not sure how to proceed here. Thanks for any help. Update : I'm not 100% there yet, but I've made some progress. The way of getting an upper bound involving $n$ that occurred to me is by using a martingale difference sequence : First off, let's define the function $F:\lambda\mapsto\|g(\lambda)-g(\lambda/2)\|$ and the Martingale sequence $Y_k(\lambda) := \mathbb E[F(\lambda)\ |\ X_1,\ldots,X_k] $ . In my setting, $Y_0=0$ and so it follows that $Y_n =\sum_{k=1}^{n} Y_k - Y_{k-1} $ . By Azuma-Hoeffding inequality , it follows that $$\mathbb P\left(Y_n(\lambda)\ge\varepsilon\right) =\mathbb P\left(\|\theta_\lambda-\theta_{\lambda/2}\|\ge\varepsilon\right) \le\exp\left(\frac{-2\varepsilon^2}{2\sum_{k=1}^{n}c_k^2}\right)  $$ Where the $c_k$ are such that $|Y_k(\lambda) - Y_{k-1}(\lambda)|\le c_k$ . Now this isn't quite the desired result as the $c_k$ are not necessarily small enough (I want them of order $1/n$ ), but they can be upper bounded as follows : $$\begin{align}|Y_k-Y_{k-1}|&=\left|\mathbb E[F(\lambda)\ |\ X_1,\ldots,X_k]-\mathbb E[F(\lambda)\ |\ X_1,\ldots,X_{k-1}]\right|\\ &\le\mathbb E[F(\lambda)\ |\ X_1,\ldots,X_k]+\mathbb E[F(\lambda)\ |\ X_1,\ldots,X_{k-1}]\tag1\\ &=\mathbb E[\|g(\lambda)-g(\lambda/2)\|\ |\ X_1,\ldots,X_k]+\mathbb E[\|g(\lambda)-g(\lambda/2)\| |\ X_1,\ldots,X_{k-1}]\\  &\le\mathbb E[L_g\cdot \lambda/2\ |\ X_1,\ldots,X_k]+\mathbb E[L_g\cdot \lambda/2\ |\ X_1,\ldots,X_{k-1}]\tag2\\  &= \lambda/2\cdot\big(\mathbb E[L_g\ |\ X_1,\ldots,X_k]+\mathbb E[L_g\ |\ X_1,\ldots,X_{k-1}]\big)\end{align} $$ Where I used triangle inequality in $(1)$ and Lipschitz continuity of $g$ in $(2)$ . Now, for my desired result to hold, it is sufficient that there exists some constant $G$ such that the Lipschitz constant of $g$ is bounded by $G/n$ , but I think this is rather harsh... Can this approach be refined in any way to get the result under less restrictive assumptions ? I initially though that I could circumvent the problem by introducing a partition $$\lambda/2=:\lambda_0<\lambda_1<\ldots<\lambda_K:=\lambda $$ Such that each $|\lambda_i-\lambda_{i-1}|$ is smaller than $1/n$ , which would then allow me to conclude by splitting the probability accordingly, but sadly the subdivision depends on $n$ so it is not helpful...","I am currently facing the following problem : Let be i.i.d. sample points from some distribution supported on where is some compact subset. From this sample, I can define a function Defined for any . I do not know the explicit relation between and the (it is the unique argmin of a function of the sample), but I know that is Lipschitz-continuous with respect to (it is even differentiable if that helps). I would like to bound in probability. That is, for any positive , I would like to get Where is some deterministic function that goes to zero when goes to infinity. Here, the choice of norm doesn't really matter since all norms in are equivalent. My question : How to prove (or disprove ?) inequality ? Are some additional assumptions on needed for it to hold ? This a a bit different from usual concentration inequalities so I'm not sure how to proceed here. Thanks for any help. Update : I'm not 100% there yet, but I've made some progress. The way of getting an upper bound involving that occurred to me is by using a martingale difference sequence : First off, let's define the function and the Martingale sequence . In my setting, and so it follows that . By Azuma-Hoeffding inequality , it follows that Where the are such that . Now this isn't quite the desired result as the are not necessarily small enough (I want them of order ), but they can be upper bounded as follows : Where I used triangle inequality in and Lipschitz continuity of in . Now, for my desired result to hold, it is sufficient that there exists some constant such that the Lipschitz constant of is bounded by , but I think this is rather harsh... Can this approach be refined in any way to get the result under less restrictive assumptions ? I initially though that I could circumvent the problem by introducing a partition Such that each is smaller than , which would then allow me to conclude by splitting the probability accordingly, but sadly the subdivision depends on so it is not helpful...","(X_1,Z_1),\ldots,(X_n,Z_n) n p \mathcal X\times\{-1,1\} \mathcal X\subseteq \mathbb R^d g :\lambda\mapsto g(\lambda\ |\ (X_i,Z_i)_{1\le i\le n})=:\theta_\lambda\in\mathbb R^p \lambda >0 g (X_i,Z_i) g \lambda \|\theta_\lambda-\theta_{\lambda/2}\|  \varepsilon>0 \mathbb P\left(\|\theta_\lambda-\theta_{\lambda/2}\| >\varepsilon\right)\le G(\varepsilon,n)\tag1  G n \|\cdot\|  \mathbb R^p (1) g n F:\lambda\mapsto\|g(\lambda)-g(\lambda/2)\| Y_k(\lambda) := \mathbb E[F(\lambda)\ |\ X_1,\ldots,X_k]  Y_0=0 Y_n =\sum_{k=1}^{n} Y_k - Y_{k-1}  \mathbb P\left(Y_n(\lambda)\ge\varepsilon\right) =\mathbb P\left(\|\theta_\lambda-\theta_{\lambda/2}\|\ge\varepsilon\right) \le\exp\left(\frac{-2\varepsilon^2}{2\sum_{k=1}^{n}c_k^2}\right)   c_k |Y_k(\lambda) - Y_{k-1}(\lambda)|\le c_k c_k 1/n \begin{align}|Y_k-Y_{k-1}|&=\left|\mathbb E[F(\lambda)\ |\ X_1,\ldots,X_k]-\mathbb E[F(\lambda)\ |\ X_1,\ldots,X_{k-1}]\right|\\
&\le\mathbb E[F(\lambda)\ |\ X_1,\ldots,X_k]+\mathbb E[F(\lambda)\ |\ X_1,\ldots,X_{k-1}]\tag1\\
&=\mathbb E[\|g(\lambda)-g(\lambda/2)\|\ |\ X_1,\ldots,X_k]+\mathbb E[\|g(\lambda)-g(\lambda/2)\| |\ X_1,\ldots,X_{k-1}]\\ 
&\le\mathbb E[L_g\cdot \lambda/2\ |\ X_1,\ldots,X_k]+\mathbb E[L_g\cdot \lambda/2\ |\ X_1,\ldots,X_{k-1}]\tag2\\ 
&= \lambda/2\cdot\big(\mathbb E[L_g\ |\ X_1,\ldots,X_k]+\mathbb E[L_g\ |\ X_1,\ldots,X_{k-1}]\big)\end{align}  (1) g (2) G g G/n \lambda/2=:\lambda_0<\lambda_1<\ldots<\lambda_K:=\lambda  |\lambda_i-\lambda_{i-1}| 1/n n","['probability-theory', 'statistics', 'inequality', 'upper-lower-bounds']"
1,"two-dimensional version of ""$F_X(X)$ is uniformly distributed""?","two-dimensional version of "" is uniformly distributed""?",F_X(X),"It is a well-known fact in probability theory that if $X$ is a continuous random variable and $F_X$ is a cdf of $X$ , then $F_X(X)$ is uniformly distributed over $[0, 1]$ . Is there a two-dimensional version of this statement? In other words, given a continuous random vector $(X, Y)$ , can we find some function $T: \mathbb{R}^2 \rightarrow [0, 1]^2$ such that $T(X, Y)$ is uniformly distributed over $[0, 1]^2$ ? Thank you.","It is a well-known fact in probability theory that if is a continuous random variable and is a cdf of , then is uniformly distributed over . Is there a two-dimensional version of this statement? In other words, given a continuous random vector , can we find some function such that is uniformly distributed over ? Thank you.","X F_X X F_X(X) [0, 1] (X, Y) T: \mathbb{R}^2 \rightarrow [0, 1]^2 T(X, Y) [0, 1]^2","['probability', 'statistics', 'random-variables', 'uniform-distribution', 'cumulative-distribution-functions']"
2,Is the induced Fisher information metric equal to the Fisher metric of a submanifold?,Is the induced Fisher information metric equal to the Fisher metric of a submanifold?,,"If $M = \{p_\theta : \theta \in \Theta \subset \mathbb R^d \}$ is a statistical manifold parametrized by $\theta$ , with the Fisher information metric \begin{equation*} g_{ij}(\theta) = \int_{\mathcal X} p_\theta(x) \partial_{i}\log(p_\theta(x)) \partial_{j}\log(p_\theta(x)) dx \end{equation*} and we take a submanifold $N \subset M$ , then $N$ can be considered as a Riemannian submanifold with the induced metric. But if $N$ is a submanifold parametrized by some parameters $\eta \in H\subset \mathbb R^k$ with $k\le d$ , then there is another construction, which is the Fisher metric of $N$ with parameters $\eta$ . My question: are these two metrics the same?","If is a statistical manifold parametrized by , with the Fisher information metric and we take a submanifold , then can be considered as a Riemannian submanifold with the induced metric. But if is a submanifold parametrized by some parameters with , then there is another construction, which is the Fisher metric of with parameters . My question: are these two metrics the same?","M = \{p_\theta : \theta \in \Theta \subset \mathbb R^d \} \theta \begin{equation*}
g_{ij}(\theta) = \int_{\mathcal X} p_\theta(x) \partial_{i}\log(p_\theta(x)) \partial_{j}\log(p_\theta(x)) dx
\end{equation*} N \subset M N N \eta \in H\subset \mathbb R^k k\le d N \eta","['statistics', 'differential-geometry', 'geometric-probability', 'fisher-information', 'information-geometry']"
3,Conditional expectation of the smaller uniform random variable,Conditional expectation of the smaller uniform random variable,,"Suppose $U_1, U_2 \sim \mathcal{U}[0,1]$ and both random variables are independent. I want to compute $E[U_1 \mid U_1 < U_2]$ . I think the correct ansewr is $$ E[U_{1}\mid U_{1}<U_{2}]=E[U_{1}\mid U_{1}=\min\{U_{1},U_{2}\}]=E[\min\{U_{1},U_{2}\}]=\int_{0}^{1}2(1-x)xdx=\frac{1}{3}. $$ But, I was wondering why the following reasoning leads to incorrect solution. If we fix $U_2 =u$ , then $E[U_1\mid U_1 <u]=u/2$ . Each $u$ happens equally likely, i.e., $U_2\sim \mathcal{U}[0,1]$ , so $E[U_1\mid U_1 < U_2] = E[U_2]/2=1/4$ . Or, more formally, $$ E[U_{1}\mid U_{1}<U_{2}]=\int_{0}^{1}\int_{0}^{u}\frac{x}{u}dxdu=\int_{0}^{1}\frac{u}{2}du=\frac{1}{4}. $$ Where did I make a mistake?","Suppose and both random variables are independent. I want to compute . I think the correct ansewr is But, I was wondering why the following reasoning leads to incorrect solution. If we fix , then . Each happens equally likely, i.e., , so . Or, more formally, Where did I make a mistake?","U_1, U_2 \sim \mathcal{U}[0,1] E[U_1 \mid U_1 < U_2] 
E[U_{1}\mid U_{1}<U_{2}]=E[U_{1}\mid U_{1}=\min\{U_{1},U_{2}\}]=E[\min\{U_{1},U_{2}\}]=\int_{0}^{1}2(1-x)xdx=\frac{1}{3}.
 U_2 =u E[U_1\mid U_1 <u]=u/2 u U_2\sim \mathcal{U}[0,1] E[U_1\mid U_1 < U_2] = E[U_2]/2=1/4 
E[U_{1}\mid U_{1}<U_{2}]=\int_{0}^{1}\int_{0}^{u}\frac{x}{u}dxdu=\int_{0}^{1}\frac{u}{2}du=\frac{1}{4}.
","['statistics', 'conditional-expectation']"
4,Approximating CDF for an aggregate loss model using FFT,Approximating CDF for an aggregate loss model using FFT,,"For a class assignment, I was asked to calculate the VaR at levels 95% and 99.9% for an aggregate loss random variable $S=\sum_{i=1}^{N}{X_i}$ , where $N \sim \mathrm{NB}(r=5,\beta=\frac{1}{5})$ , and $X_i \overset{iid}{\sim} \exp{(\theta=1)}$ . We were to do this by using an FFT on a discretization of the continuous RV $X$ . The way to do this is by choosing a grid width $h$ and an integer $n$ such that $r:=2^n$ is the number of elements to discretize $X$ on, discretizing $X$ and calculating the probabilities of being in equally spaced intervals of width $h$ , applying the FFT to the discretized $X$ , applying the PGF of $N$ to the elements of the Fourier-transformed $X$ , applying the inverse FFT to this vector. The resulting vector should be an approximation for the probability masses of each such interval for $S$ . Below I attach my Python code. I know from previous methods that the 95% VaR ought to be ~4 and the 99.9% VaR ought to be ~10. But my code returns nonsensical results. Generally speaking, my index where the ECDF reaches levels $>0.95$ is way too late, and even after hours of debugging I have not managed to find where I am going wrong. The probability generating function for this parametrization of a negative binomial distribution is $P(z)=[1-\beta(z-1)]^{-r}$ . I hope that this is the correct place to ask this question, as I find it is mostly math- and only minorly programming related. import numpy as np from scipy.stats import expon from scipy.fft import fft, ifft  r, beta, theta = 5, .2, 1 var_levels = [.95, .999]   def discretize_X(h: float, m: int):     X = expon(scale=theta)     f_X = [X.cdf(h / 2),            *[X.cdf(j * h + h / 2) - X.cdf(j * h - h / 2) for j in range(1, m - 1)],            X.sf((m - 1) * h - h / 2)]     return f_X   # Probability generating function of N ~ NB(r, beta) def PGF(z: [float, complex]):     return (1 - beta * (z - 1)) ** (-r)   h = 1e-2 n = 10 r = 2 ** n  VaRs, TVaRs = [], []  # discretize X with (r-1) cells of width h and one final cell with the survival function at h*(r-1) f_X = discretize_X(h, r) phi_vec = fft(f_X) f_tilde_vec_fft = np.array([PGF(phi) for phi in phi_vec]) f_S = np.real(ifft(f_tilde_vec_fft)) ecdf_S = np.cumsum(f_S)  # calc cumsum to get ECDF  for p in var_levels:     var_idx = np.where(ecdf_S >= p)[0][0]  # get lowest index where ecdf_S >= p     print(""p ="", p, ""\nVaR idx:"", var_idx)     var = h * var_idx  # VaR should be this index times the cell width     print(""VaR:"", var)     tvar = 1 / (1 - p) * np.sum(f_S[var_idx:] * np.array([i * h for i in range(var_idx, r)]))  # TVaR should be each cell's probability times the value inside that cell      VaRs.append(var)     TVaRs.append(tvar)  return VaRs, TVaRs ```","For a class assignment, I was asked to calculate the VaR at levels 95% and 99.9% for an aggregate loss random variable , where , and . We were to do this by using an FFT on a discretization of the continuous RV . The way to do this is by choosing a grid width and an integer such that is the number of elements to discretize on, discretizing and calculating the probabilities of being in equally spaced intervals of width , applying the FFT to the discretized , applying the PGF of to the elements of the Fourier-transformed , applying the inverse FFT to this vector. The resulting vector should be an approximation for the probability masses of each such interval for . Below I attach my Python code. I know from previous methods that the 95% VaR ought to be ~4 and the 99.9% VaR ought to be ~10. But my code returns nonsensical results. Generally speaking, my index where the ECDF reaches levels is way too late, and even after hours of debugging I have not managed to find where I am going wrong. The probability generating function for this parametrization of a negative binomial distribution is . I hope that this is the correct place to ask this question, as I find it is mostly math- and only minorly programming related. import numpy as np from scipy.stats import expon from scipy.fft import fft, ifft  r, beta, theta = 5, .2, 1 var_levels = [.95, .999]   def discretize_X(h: float, m: int):     X = expon(scale=theta)     f_X = [X.cdf(h / 2),            *[X.cdf(j * h + h / 2) - X.cdf(j * h - h / 2) for j in range(1, m - 1)],            X.sf((m - 1) * h - h / 2)]     return f_X   # Probability generating function of N ~ NB(r, beta) def PGF(z: [float, complex]):     return (1 - beta * (z - 1)) ** (-r)   h = 1e-2 n = 10 r = 2 ** n  VaRs, TVaRs = [], []  # discretize X with (r-1) cells of width h and one final cell with the survival function at h*(r-1) f_X = discretize_X(h, r) phi_vec = fft(f_X) f_tilde_vec_fft = np.array([PGF(phi) for phi in phi_vec]) f_S = np.real(ifft(f_tilde_vec_fft)) ecdf_S = np.cumsum(f_S)  # calc cumsum to get ECDF  for p in var_levels:     var_idx = np.where(ecdf_S >= p)[0][0]  # get lowest index where ecdf_S >= p     print(""p ="", p, ""\nVaR idx:"", var_idx)     var = h * var_idx  # VaR should be this index times the cell width     print(""VaR:"", var)     tvar = 1 / (1 - p) * np.sum(f_S[var_idx:] * np.array([i * h for i in range(var_idx, r)]))  # TVaR should be each cell's probability times the value inside that cell      VaRs.append(var)     TVaRs.append(tvar)  return VaRs, TVaRs","S=\sum_{i=1}^{N}{X_i} N \sim \mathrm{NB}(r=5,\beta=\frac{1}{5}) X_i \overset{iid}{\sim} \exp{(\theta=1)} X h n r:=2^n X X h X N X S >0.95 P(z)=[1-\beta(z-1)]^{-r} ```","['statistics', 'random-variables', 'stochastic-analysis', 'python', 'actuarial-science']"
5,Bayesian analysis for multiple unknowns,Bayesian analysis for multiple unknowns,,"I've encountered this problem but my stats is rusty and I've been having trouble formalizing it enough to tackle it. I have something like a family tree where each node in the tree has two parents and can be one of two parents for some other node(s) (or not if it's a leaf node).  Each node is either red or black and inherited its color from one of its parents, chosen randomly with equal probability of being from either parent. Each node has a prior probability for being red (based on some educated guesses).  I'm then told the color of a certain subset of nodes.  I want to update my tree with posterior probabilities given the new information.  That is, the nodes I'm given have their prosterior probabilities to be red set to either 1 or 0 and the unknown node probabilities are updated to incorporate the new information. As an example, this tree has some known nodes (the ones colored red or black) and some unknown nodes (the blank ones).  I want to update the probabilities of the unknown nodes given the known nodes. This feels like an obvious problem for Bayesian analysis, and it's very similar to something like this , but the simultaneous nature of updating the posterior probabilities for all nodes in the tree is confusing me and I haven't figured out how to set up the update.","I've encountered this problem but my stats is rusty and I've been having trouble formalizing it enough to tackle it. I have something like a family tree where each node in the tree has two parents and can be one of two parents for some other node(s) (or not if it's a leaf node).  Each node is either red or black and inherited its color from one of its parents, chosen randomly with equal probability of being from either parent. Each node has a prior probability for being red (based on some educated guesses).  I'm then told the color of a certain subset of nodes.  I want to update my tree with posterior probabilities given the new information.  That is, the nodes I'm given have their prosterior probabilities to be red set to either 1 or 0 and the unknown node probabilities are updated to incorporate the new information. As an example, this tree has some known nodes (the ones colored red or black) and some unknown nodes (the blank ones).  I want to update the probabilities of the unknown nodes given the known nodes. This feels like an obvious problem for Bayesian analysis, and it's very similar to something like this , but the simultaneous nature of updating the posterior probabilities for all nodes in the tree is confusing me and I haven't figured out how to set up the update.",,"['statistics', 'statistical-inference', 'bayesian']"
6,Confidence interval for Poisson distribution,Confidence interval for Poisson distribution,,"$X_{1}, X_{2}, ..., X_{n}$ is a random sample from $Poisson(\lambda)$ population. I need to show that when sample size n is large, the approximate two-sided (1- $\alpha$ )% C.I. is $$ \left[   \bar{x} + \frac{1}{2n} z_{\alpha/2}^2 - \frac{1}{2}   \sqrt{\left(2\bar{x}+\frac{1}{n}z_{\alpha/2}^2\right)^2-4\bar{x}^2},   \bar{x} + \frac{1}{2n} z_{\alpha/2}^2 + \frac{1}{2}   \sqrt{\left(2\bar{x}+\frac{1}{n}z_{\alpha/2}^2\right)^2-4\bar{x}^2} \right] $$ I got $\frac{\bar{x}-\lambda}{\sqrt{\lambda/n}}\sim N(0,1)$ and $\bar{x}\pm z_{\alpha/2}\sqrt{\bar{x}/n}$ by myself and found from a paper that $\frac{1}{2n}z_{\alpha/2}^2$ is the tail probability for small sample size. Now I'm confused with $\frac{1}{2}\sqrt{(2\bar{x}+\frac{1}{n}z_{\alpha/2}^2)^2-4\bar{x}^2}$ . From the structure of the equation, I guess it is the error? But I'm not sure about it and have no idea how to get it. Can anyone give me some hints or guide for this part please?","is a random sample from population. I need to show that when sample size n is large, the approximate two-sided (1- )% C.I. is I got and by myself and found from a paper that is the tail probability for small sample size. Now I'm confused with . From the structure of the equation, I guess it is the error? But I'm not sure about it and have no idea how to get it. Can anyone give me some hints or guide for this part please?","X_{1}, X_{2}, ..., X_{n} Poisson(\lambda) \alpha 
\left[
  \bar{x}
+ \frac{1}{2n} z_{\alpha/2}^2
- \frac{1}{2}
  \sqrt{\left(2\bar{x}+\frac{1}{n}z_{\alpha/2}^2\right)^2-4\bar{x}^2},
  \bar{x}
+ \frac{1}{2n} z_{\alpha/2}^2
+ \frac{1}{2}
  \sqrt{\left(2\bar{x}+\frac{1}{n}z_{\alpha/2}^2\right)^2-4\bar{x}^2}
\right]
 \frac{\bar{x}-\lambda}{\sqrt{\lambda/n}}\sim N(0,1) \bar{x}\pm z_{\alpha/2}\sqrt{\bar{x}/n} \frac{1}{2n}z_{\alpha/2}^2 \frac{1}{2}\sqrt{(2\bar{x}+\frac{1}{n}z_{\alpha/2}^2)^2-4\bar{x}^2}","['statistics', 'poisson-distribution', 'confidence-interval']"
7,What is the MLE for centered Gaussian:$ S_y=\frac{1}{n}\boldsymbol{X}^T\boldsymbol{X}$ or $S_y=\frac{1}{n}\boldsymbol{XX}^T$,What is the MLE for centered Gaussian: or, S_y=\frac{1}{n}\boldsymbol{X}^T\boldsymbol{X} S_y=\frac{1}{n}\boldsymbol{XX}^T,"What is the Maximum Likelihood Estimator  (MLE) for the centered ( $\mu=0$ ) multivariate Gaussian? My book gives the MLE as $$ S_y=\frac{1}{n}\boldsymbol{X}^T\boldsymbol{X} $$ while I've seen online resources derive the MLE as $$ S_y=\frac{1}{n}\boldsymbol{XX}^T $$ The context is to use PCA: $$\boldsymbol{X}=\boldsymbol{U\Sigma V}^T$$ and if the first definition is used, I would get the eigenvalues/eigenvectors of $\boldsymbol{U}$ while $\boldsymbol{V}$ if the second definition is used.","What is the Maximum Likelihood Estimator  (MLE) for the centered ( ) multivariate Gaussian? My book gives the MLE as while I've seen online resources derive the MLE as The context is to use PCA: and if the first definition is used, I would get the eigenvalues/eigenvectors of while if the second definition is used.","\mu=0 
S_y=\frac{1}{n}\boldsymbol{X}^T\boldsymbol{X}
 
S_y=\frac{1}{n}\boldsymbol{XX}^T
 \boldsymbol{X}=\boldsymbol{U\Sigma V}^T \boldsymbol{U} \boldsymbol{V}","['probability', 'statistics', 'probability-distributions', 'maximum-likelihood']"
8,Light Bulb hypothesis testing,Light Bulb hypothesis testing,,"One claims that the life time distribution of its Everyday light bulbs is exponential with mean 1000 hours. If you test a random sample of 4 light bulbs and find that the average life time is 900 hours, do you have significant evidence against the this claim? Set up an appropriate hypothesis testing problem. Use the nominal level of 0.05 for your test. (Hint: You may view the exponential distribution as a gamma distribution. With data collected from a sample of 4 light bulbs, what is the power of your test if the actual mean life time is only 900 hours? My attempt: $\mu = 1000, \sigma = 1000, \bar X_4 = 900$ $H_0: \mu \geq 1000$ $H_a: \mu \lt 1000$ Since $\bar X_4 = 900, \sum_{i=1}^{4} X_i = 3600$ I then conduct the integration $$\int_{3600}^{\infty} \frac{(\frac{1}{1000})^4}{\gamma(4-1)}x^{4-1}e^{-0.001x} dx \approx 1.546$$ compare this result with $\alpha = 0.05$ , which is 2.353 after checking the t-test table. So I should not reject $H_0$ Is everything alright? I have no idea about the second part. Any hint or suggestion would be appreciated!","One claims that the life time distribution of its Everyday light bulbs is exponential with mean 1000 hours. If you test a random sample of 4 light bulbs and find that the average life time is 900 hours, do you have significant evidence against the this claim? Set up an appropriate hypothesis testing problem. Use the nominal level of 0.05 for your test. (Hint: You may view the exponential distribution as a gamma distribution. With data collected from a sample of 4 light bulbs, what is the power of your test if the actual mean life time is only 900 hours? My attempt: Since I then conduct the integration compare this result with , which is 2.353 after checking the t-test table. So I should not reject Is everything alright? I have no idea about the second part. Any hint or suggestion would be appreciated!","\mu = 1000, \sigma = 1000, \bar X_4 = 900 H_0: \mu \geq 1000 H_a: \mu \lt 1000 \bar X_4 = 900, \sum_{i=1}^{4} X_i = 3600 \int_{3600}^{\infty} \frac{(\frac{1}{1000})^4}{\gamma(4-1)}x^{4-1}e^{-0.001x} dx \approx 1.546 \alpha = 0.05 H_0","['statistics', 'solution-verification', 'statistical-inference', 'hypothesis-testing', 'exponential-distribution']"
9,Is the Likelihood of a Regression Model usually Convex?,Is the Likelihood of a Regression Model usually Convex?,,"This is a question I have always had about Likelihood Functions (e.g. Regression Models): When dealing with Regression Models in the field of statistics, we are interested in fitting a model to some data (e.g. Covariates and a Response Variable) that describes the ""Expected Probability for Observing some Response Conditional on Observing some Specific Set of Covariates"": This is the classical regression framework - given some data, we want to create a regression model that allows us to predict the ""most likely"" value of the response variable given some covariates. There are different estimation methods that allow us to create this regression model based on the data we have observed. One of these methods is called ""Ordinary Least Squares"" (OLS) - this method estimates the ""Beta Regression Coefficients"" that result in the smallest squared distance between the Actual Response and the corresponding Predicted Response by the statistical model. Another method is called ""Maximum Likelihood Estimation"" (MLE), in which the ""Beta Regression Coefficients"" are estimated in such a way that the probability of observing the data is maximized, provided that we assume the data actually originated from some (multivariate) probability distribution function (e.g. a Normal Distribution). For a Simple Linear Regression Model (i.e. with only two Beta Regression Coefficients), for the Maximum Likelihood Formulation, we can write this conditional probability as follows: We soon see that the estimation of these Beta Regression Coefficients is effectively an optimization problem - we are interested in finding the values of ""b_0, b_1 and s^2"" that result in the likelihood formula being maximized (i.e. Arg_Min of the Likelihood): Normally, such Optimization Problems would have required us to use some iterative Optimization Algorithm such as Gradient Descent - however, due to the ""attractive and convenient"" theoretical properties of the Normal Distribution, the above Optimization Problem can give us exact formulas for these Beta Regression Coefficients: My Question: Do we know if the above Likelihood Equation L(b_0, b_1, s^2) that we are trying to Maximize (i.e Optimize) is Convex or Non-Convex? I know that in many regression models, the Optimization Problem being solved has exact solutions which do not require iterative Optimization Algorithms - however, I know that some other regression models (e.g. Logistic Regression) do not have exact solutions and do in fact require some iterative Optimization Algorithm (e.g. Newton-Raphson) to estimate the Beta Regression Coefficients. By doing a quick Google Images Search, it seems that perhaps some of these Likelihood Functions might be Convex and some others might be Non-Convex: But in general, do we ever study the Convexity of Likelihood Functions in Regression Models? Do we know that if some of these Likelihood Functions are usually Convex (e.g. Linear Regression) and if some of these Likelihood Functions are usually Non-Convex (e.g. Logistic Regression)? Does the existence of an exact solution to the Beta Regression Coefficients provide some sort of indication regarding the Convexity of the Likelihood Function (e.g. IF exact solution to the Likelihood Function exists THEN Convex ELSE Non-Convex)? Thanks! Reference: https://www.stat.cmu.edu/~cshalizi/mreg/15/lectures/06/lecture-06.pdf","This is a question I have always had about Likelihood Functions (e.g. Regression Models): When dealing with Regression Models in the field of statistics, we are interested in fitting a model to some data (e.g. Covariates and a Response Variable) that describes the ""Expected Probability for Observing some Response Conditional on Observing some Specific Set of Covariates"": This is the classical regression framework - given some data, we want to create a regression model that allows us to predict the ""most likely"" value of the response variable given some covariates. There are different estimation methods that allow us to create this regression model based on the data we have observed. One of these methods is called ""Ordinary Least Squares"" (OLS) - this method estimates the ""Beta Regression Coefficients"" that result in the smallest squared distance between the Actual Response and the corresponding Predicted Response by the statistical model. Another method is called ""Maximum Likelihood Estimation"" (MLE), in which the ""Beta Regression Coefficients"" are estimated in such a way that the probability of observing the data is maximized, provided that we assume the data actually originated from some (multivariate) probability distribution function (e.g. a Normal Distribution). For a Simple Linear Regression Model (i.e. with only two Beta Regression Coefficients), for the Maximum Likelihood Formulation, we can write this conditional probability as follows: We soon see that the estimation of these Beta Regression Coefficients is effectively an optimization problem - we are interested in finding the values of ""b_0, b_1 and s^2"" that result in the likelihood formula being maximized (i.e. Arg_Min of the Likelihood): Normally, such Optimization Problems would have required us to use some iterative Optimization Algorithm such as Gradient Descent - however, due to the ""attractive and convenient"" theoretical properties of the Normal Distribution, the above Optimization Problem can give us exact formulas for these Beta Regression Coefficients: My Question: Do we know if the above Likelihood Equation L(b_0, b_1, s^2) that we are trying to Maximize (i.e Optimize) is Convex or Non-Convex? I know that in many regression models, the Optimization Problem being solved has exact solutions which do not require iterative Optimization Algorithms - however, I know that some other regression models (e.g. Logistic Regression) do not have exact solutions and do in fact require some iterative Optimization Algorithm (e.g. Newton-Raphson) to estimate the Beta Regression Coefficients. By doing a quick Google Images Search, it seems that perhaps some of these Likelihood Functions might be Convex and some others might be Non-Convex: But in general, do we ever study the Convexity of Likelihood Functions in Regression Models? Do we know that if some of these Likelihood Functions are usually Convex (e.g. Linear Regression) and if some of these Likelihood Functions are usually Non-Convex (e.g. Logistic Regression)? Does the existence of an exact solution to the Beta Regression Coefficients provide some sort of indication regarding the Convexity of the Likelihood Function (e.g. IF exact solution to the Likelihood Function exists THEN Convex ELSE Non-Convex)? Thanks! Reference: https://www.stat.cmu.edu/~cshalizi/mreg/15/lectures/06/lecture-06.pdf",,"['probability', 'statistics', 'optimization', 'convex-analysis', 'normal-distribution']"
10,Conditional variance of Y given X when y is a continuous function of x,Conditional variance of Y given X when y is a continuous function of x,,"Technically the problem term would be $E[Y^2|X]$ For simplicity, let us for a minute assume that $y = a + bx$ Is it mathematically correct to write: $E[Y^2|X] = E[(a+bx)^2]$ , and if so why? And how would this apply to the direct formula of variance? Can we formulate $$V[Y|X] = E[(Y - E[Y|X])^2 \ | \ X] = E[((a+bx)-E[Y|X])^2 ]$$ Also does anyone have a link where I can read more about this?","Technically the problem term would be For simplicity, let us for a minute assume that Is it mathematically correct to write: , and if so why? And how would this apply to the direct formula of variance? Can we formulate Also does anyone have a link where I can read more about this?",E[Y^2|X] y = a + bx E[Y^2|X] = E[(a+bx)^2] V[Y|X] = E[(Y - E[Y|X])^2 \ | \ X] = E[((a+bx)-E[Y|X])^2 ],"['statistics', 'expected-value']"
11,Is this a conjugate prior?,Is this a conjugate prior?,,"I have a parameter $\theta = (\theta_1, \theta_2)^\top\in\mathbb{R}^2$ with a multivariate normal prior $p(\theta) = \mathcal{N}(\theta\mid 0, I)$ . The likelihood is a univariate normal distribution $\mathcal{N}(y \mid \theta_1 + \theta_2, \sigma^2)$ . Is the posterior a normal distribution as well? I know in general the product of normals is not normal. But I was wondering if in this case it is. Not sure how to check it.",I have a parameter with a multivariate normal prior . The likelihood is a univariate normal distribution . Is the posterior a normal distribution as well? I know in general the product of normals is not normal. But I was wondering if in this case it is. Not sure how to check it.,"\theta = (\theta_1, \theta_2)^\top\in\mathbb{R}^2 p(\theta) = \mathcal{N}(\theta\mid 0, I) \mathcal{N}(y \mid \theta_1 + \theta_2, \sigma^2)","['probability', 'probability-theory', 'statistics', 'probability-distributions', 'bayesian']"
12,A random vector satisfying invariance under rotation and belonging to the unit sphere must be uniform distribution on the unit sphere?,A random vector satisfying invariance under rotation and belonging to the unit sphere must be uniform distribution on the unit sphere?,,"If a random vector $u \in\mathbb{R}^n$ has $\|u\|_2=1$ , and for any orthogonal matrix $Q$ , it has $Qu \overset{d}{=}u$ , does this imply $u \sim Unif(S^{n-1})$ ?","If a random vector has , and for any orthogonal matrix , it has , does this imply ?",u \in\mathbb{R}^n \|u\|_2=1 Q Qu \overset{d}{=}u u \sim Unif(S^{n-1}),"['probability', 'measure-theory', 'statistics', 'probability-distributions', 'normal-distribution']"
13,"A dimension-free upper bound for $\| X \|_{\infty}$ when $X \sim N(0,\Sigma)$",A dimension-free upper bound for  when,"\| X \|_{\infty} X \sim N(0,\Sigma)","For a $p$ -dimensional random vector $X \sim N(0,\Sigma)$ , it is known that with high probability $$ \| X \|_{\max} \le C \sqrt{\log p} $$ where $C$ is some constant possibly depending on $\Sigma$ . I would like to know if there is a simple dimension free bound that generalizes this result. For context on a related problem, consider the $\| \cdot \|_2$ setting, then example Exercise 6.3.5. in Vershynin's High Dimensional Probability states that for a $m \times n$ constant matrix $B$ , $Z \sim N(0,I)$ , that $$ P( \| BZ\|_{2} \ge C \| B \|_F + t) \le \exp \left ( -\frac{ct^2}{\| B \|^2_\text{op}}\right) $$ where the subscript $F$ is the frobenius norm. Choosing $B = \sqrt{\Sigma}$ yields $$ P( \| X \|_{2} \ge C \sqrt{\text{Tr}(\Sigma)} + t) \le \exp \left ( -\frac{ct^2}{\|\Sigma\|^2_{\text{op}}}\right), $$ so that with high probability $\| X \|_2 \le C\sqrt{\text{Tr}(\Sigma)}$ . In the worst case, $\Sigma = I$ and we get back the standard bound $\| X \|_2 \le C\sqrt{p}$ , but for many problems of interest $\Sigma$ has a nice structure that makes the first bound more useful. Is there a similar bound that generalizes the $\sqrt{\log p}$ bound? Ideally it would involve the trace, $\|X\|_{\max} \stackrel{?}{\le} C \sqrt{\log \text{Tr}(\Sigma)}$ . Note also that all results mentioned hold more generally for subGaussian random variables (with different universal constants), but for simplicity I am just looking at the Gaussian case. An update : I have found a related dimension free result, Lemma 2.3 of this paper by Van Handel states that for $X_1,\dots, X_n$ be not necessarily independent subGaussian random variables with subGaussian norm $\sigma_i$ , then $$ E [\max_{i \le n} X_i] \le C \max_{i \le n} \sigma_{(i)} \sqrt{\log(i+1)} $$ where $\sigma_{(1)} \ge \sigma_{(2)} \ge \dots \sigma_{(n)}$ are the ordered subGaussian norms. If the $X$ 's are independent Gaussian there is a matching lower bound.","For a -dimensional random vector , it is known that with high probability where is some constant possibly depending on . I would like to know if there is a simple dimension free bound that generalizes this result. For context on a related problem, consider the setting, then example Exercise 6.3.5. in Vershynin's High Dimensional Probability states that for a constant matrix , , that where the subscript is the frobenius norm. Choosing yields so that with high probability . In the worst case, and we get back the standard bound , but for many problems of interest has a nice structure that makes the first bound more useful. Is there a similar bound that generalizes the bound? Ideally it would involve the trace, . Note also that all results mentioned hold more generally for subGaussian random variables (with different universal constants), but for simplicity I am just looking at the Gaussian case. An update : I have found a related dimension free result, Lemma 2.3 of this paper by Van Handel states that for be not necessarily independent subGaussian random variables with subGaussian norm , then where are the ordered subGaussian norms. If the 's are independent Gaussian there is a matching lower bound.","p X \sim N(0,\Sigma) 
\| X \|_{\max} \le C \sqrt{\log p}
 C \Sigma \| \cdot \|_2 m \times n B Z \sim N(0,I) 
P( \| BZ\|_{2} \ge C \| B \|_F + t) \le \exp \left ( -\frac{ct^2}{\| B \|^2_\text{op}}\right)
 F B = \sqrt{\Sigma} 
P( \| X \|_{2} \ge C \sqrt{\text{Tr}(\Sigma)} + t) \le \exp \left ( -\frac{ct^2}{\|\Sigma\|^2_{\text{op}}}\right),
 \| X \|_2 \le C\sqrt{\text{Tr}(\Sigma)} \Sigma = I \| X \|_2 \le C\sqrt{p} \Sigma \sqrt{\log p} \|X\|_{\max} \stackrel{?}{\le} C \sqrt{\log \text{Tr}(\Sigma)} X_1,\dots, X_n \sigma_i 
E [\max_{i \le n} X_i] \le C \max_{i \le n} \sigma_{(i)} \sqrt{\log(i+1)}
 \sigma_{(1)} \ge \sigma_{(2)} \ge \dots \sigma_{(n)} X","['probability-theory', 'statistics', 'normal-distribution', 'concentration-of-measure']"
14,Bayesian Prediction,Bayesian Prediction,,"It is Question #35 from this https://math.illinoisstate.edu/actuary/ExamC/ExamCMay2005.pdf . I understand all other parts except the first line of the answer key. For the geometric distribution, $Pr(X_1=2|\beta) = \frac{\beta^2}{(1+\beta)^3}$ . I can see that it is based on the equation $\frac{\beta^{k-1}}{(1+β)^k}$ , but I have no idea where did that come from. Can someone please help me? From what I understand, the geometric distribution is $p(1-p)^k$ .","It is Question #35 from this https://math.illinoisstate.edu/actuary/ExamC/ExamCMay2005.pdf . I understand all other parts except the first line of the answer key. For the geometric distribution, . I can see that it is based on the equation , but I have no idea where did that come from. Can someone please help me? From what I understand, the geometric distribution is .",Pr(X_1=2|\beta) = \frac{\beta^2}{(1+\beta)^3} \frac{\beta^{k-1}}{(1+β)^k} p(1-p)^k,"['statistics', 'bayesian', 'actuarial-science']"
15,Some calculation about expectation of empirical CDF,Some calculation about expectation of empirical CDF,,"Given iid random samples $X_1,\dots, X_n$ with CDF $F(x)$ and $f(x)$ that is continuous and symmetric around $0$ . (Then $E X=0$ and 50% quantile is $0$ ). Define the empirical CDF as $F_n(x)=\frac{1}{n}\sum_{i=1}^n I(X_i\le x)$ . How to simplify the following expectation in terms of $\mu_k=E|X_1|^k$ for $k=1,2,...$ ? (1) $$  E\left[|X_1|^2(2F_n(0)-1)^2\right] $$ (2) $$  E[X_1|X_1|(2F_n(0)-1)] $$ For (1), This becomes $$ E\left[4|X_1|^2F_n(0)^2+|X_1|^2-4F_n(0)|X_1|^2\right]=E[4|X_1|^2F_n(0)^2]+E[|X_1|^2]-4E[F_n(0)|X_1|^2] $$ where the third term is $4E[I(X_1\le 0)|X_1|^2]=4*0.5*\mu_2=2\mu_2$ , and the first term is $$ 4E\left[|X_1|^2\left(\frac{1}{n^2}\sum_{i,j=1}^{n}I(X_i\le 0, X_j\le 0)\right)\right] $$ but I am stuck here... For (2), since $E[X_1|X_1|]=0$ , it becomes $$ E[2X_1|X_1|F_n(0)]=2E[X_1|X_1|I(X_1\le 0)]=-2\int_0^\infty x|x|dF(x)=-\mu_2 $$ Does this one correct?","Given iid random samples with CDF and that is continuous and symmetric around . (Then and 50% quantile is ). Define the empirical CDF as . How to simplify the following expectation in terms of for ? (1) (2) For (1), This becomes where the third term is , and the first term is but I am stuck here... For (2), since , it becomes Does this one correct?","X_1,\dots, X_n F(x) f(x) 0 E X=0 0 F_n(x)=\frac{1}{n}\sum_{i=1}^n I(X_i\le x) \mu_k=E|X_1|^k k=1,2,... 
 E\left[|X_1|^2(2F_n(0)-1)^2\right]
 
 E[X_1|X_1|(2F_n(0)-1)]
 
E\left[4|X_1|^2F_n(0)^2+|X_1|^2-4F_n(0)|X_1|^2\right]=E[4|X_1|^2F_n(0)^2]+E[|X_1|^2]-4E[F_n(0)|X_1|^2]
 4E[I(X_1\le 0)|X_1|^2]=4*0.5*\mu_2=2\mu_2 
4E\left[|X_1|^2\left(\frac{1}{n^2}\sum_{i,j=1}^{n}I(X_i\le 0, X_j\le 0)\right)\right]
 E[X_1|X_1|]=0 
E[2X_1|X_1|F_n(0)]=2E[X_1|X_1|I(X_1\le 0)]=-2\int_0^\infty x|x|dF(x)=-\mu_2
","['probability', 'analysis', 'statistics']"
16,Measure of correlation between two random variables,Measure of correlation between two random variables,,"I have two random variables, $X$ and $Y$ that are jointly distributed according to CDF $F(.,.)$ and a pdf $f(.,.)$ with support $[0,1]\times [0,1]$ . Moreover, the marginal distributions, $F_X(x):= \int_0^1 f(x,y) dy$ and $F_Y(y)$ (defined analogously) coincide. I want to define the following notion of correlation or interdependence between $X$ and $Y$ . $(X,Y)$ are more correlated than $(\hat X,\hat Y)$ if, The marginal distributions of $X,Y,\hat X,\hat Y$ coincide. And, for a.e. $x$ and interval $I$ such that $x \in I$ , \begin{align*} \mathbb P(Y \in I \vert X = x) \ge \mathbb P(\hat Y \in I \vert \hat X = x)  \end{align*} I am unable to find any order that says something like this. Does anyone know if this notion has been used by anyone? Any references would be great.","I have two random variables, and that are jointly distributed according to CDF and a pdf with support . Moreover, the marginal distributions, and (defined analogously) coincide. I want to define the following notion of correlation or interdependence between and . are more correlated than if, The marginal distributions of coincide. And, for a.e. and interval such that , I am unable to find any order that says something like this. Does anyone know if this notion has been used by anyone? Any references would be great.","X Y F(.,.) f(.,.) [0,1]\times [0,1] F_X(x):= \int_0^1 f(x,y) dy F_Y(y) X Y (X,Y) (\hat X,\hat Y) X,Y,\hat X,\hat Y x I x \in I \begin{align*}
\mathbb P(Y \in I \vert X = x) \ge \mathbb P(\hat Y \in I \vert \hat X = x) 
\end{align*}","['probability', 'statistics', 'correlation']"
17,Convergence in probability and convergence in distribution in the context of OLS,Convergence in probability and convergence in distribution in the context of OLS,,"What I am missing here? Let there be three iid variables $(W_i, D_i, U_i)$ where $U_i$ may have an error interpretation in a traditional OLS context. That is $E[W_iU_i]=0$ and $E[D_iU_i]=0$ . Moreover, everything is properly defined, second moments and covariances across all three variables exist and for simplicity the expectations of all three variables equal $0$ . Consider now the following problem: We are interested in identifying the limiting behavior (as n grows to $\infty$ ) of these two expressions $\frac{1}{n}\sum{W_i^2}\frac{1}{\sqrt{n}}\sum{D_iU_i}$ which should be completely identical to $\frac{1}{\sqrt{n}}\sum{W_i^2}\frac{1}{n}\sum{D_iU_i}$ . This kind of settings are very common in OLS consistency proofs. These problems are usually tackled by invoking some sort of CLT on the error component (which will be distributed as a $N(0, E[D_i^2U_i^2])$ and some convergence in probability on the first term. We apply Slutsky Theorem and we are essentially done. However, and even if I strongly belive I am wrong, I don't manage to understand why the opposite does not lead to the same result. That is, apply the CLT over the $W_i^2$ component (assuming the existence of fourth moments) and then use the convergence in probability of $\frac{1}{n}\sum{D_iU_i}$ to $E[D_iU_i] = 0$ . But, and this is the key problem. Then we will obtain deterministic result of the form $N(0,0)$ rather than $N(0,\sigma_{w}^2E[D_i^2U_i^2])$ . What I am missing here? Thank you for your help!","What I am missing here? Let there be three iid variables where may have an error interpretation in a traditional OLS context. That is and . Moreover, everything is properly defined, second moments and covariances across all three variables exist and for simplicity the expectations of all three variables equal . Consider now the following problem: We are interested in identifying the limiting behavior (as n grows to ) of these two expressions which should be completely identical to . This kind of settings are very common in OLS consistency proofs. These problems are usually tackled by invoking some sort of CLT on the error component (which will be distributed as a and some convergence in probability on the first term. We apply Slutsky Theorem and we are essentially done. However, and even if I strongly belive I am wrong, I don't manage to understand why the opposite does not lead to the same result. That is, apply the CLT over the component (assuming the existence of fourth moments) and then use the convergence in probability of to . But, and this is the key problem. Then we will obtain deterministic result of the form rather than . What I am missing here? Thank you for your help!","(W_i, D_i, U_i) U_i E[W_iU_i]=0 E[D_iU_i]=0 0 \infty \frac{1}{n}\sum{W_i^2}\frac{1}{\sqrt{n}}\sum{D_iU_i} \frac{1}{\sqrt{n}}\sum{W_i^2}\frac{1}{n}\sum{D_iU_i} N(0, E[D_i^2U_i^2]) W_i^2 \frac{1}{n}\sum{D_iU_i} E[D_iU_i] = 0 N(0,0) N(0,\sigma_{w}^2E[D_i^2U_i^2])","['probability', 'statistics', 'probability-distributions', 'central-limit-theorem', 'probability-limit-theorems']"
18,Consistently estimate the covariance matrix with weakly correlated observations,Consistently estimate the covariance matrix with weakly correlated observations,,"Suppose there are T k-dimensional observations following the generating process: $Y_t = \mu + \epsilon_t$ , where $\mu$ is the mean and $\epsilon$ is a weak stationary error with zero mean and time-invariant covariance matrix $\Sigma = E(\epsilon_t\epsilon_t')$ for all t. The goal is to estimate $\Sigma$ by empirical covariance $\frac{1}{T}(Y_t - \mu_Y)(Y_t - \mu_Y)'$ , where $\mu_Y$ is the empirical mean of $Y$ . However, we allow some kind of time dependence in the error term. And the question is under which weak correlation can this estimator be consistent for $\Sigma$ ? I know there is a classic result about weakly correlated random variables and for mean-estimation: if $X_1, X_2,\dots, X_n$ are random variables with the same means and $\operatorname{corr}(X_m, X_{m+t}) \to 0$ as $t \to \infty$ , then the empirical mean $\frac{1}{n}(X_1+X_2+\dots +X_n) \to E(X) $ in probability. But in the vector case and for second-moment estimation, I find it hard to set a good condition, maybe uniformly convergence to zero of all entries of correlation variance should be enough? And it seems a basic problem maybe in time series study or general statistics. I'm wondering if anyone has seen this problem, references or direction are appreciated.","Suppose there are T k-dimensional observations following the generating process: , where is the mean and is a weak stationary error with zero mean and time-invariant covariance matrix for all t. The goal is to estimate by empirical covariance , where is the empirical mean of . However, we allow some kind of time dependence in the error term. And the question is under which weak correlation can this estimator be consistent for ? I know there is a classic result about weakly correlated random variables and for mean-estimation: if are random variables with the same means and as , then the empirical mean in probability. But in the vector case and for second-moment estimation, I find it hard to set a good condition, maybe uniformly convergence to zero of all entries of correlation variance should be enough? And it seems a basic problem maybe in time series study or general statistics. I'm wondering if anyone has seen this problem, references or direction are appreciated.","Y_t = \mu + \epsilon_t \mu \epsilon \Sigma = E(\epsilon_t\epsilon_t') \Sigma \frac{1}{T}(Y_t - \mu_Y)(Y_t - \mu_Y)' \mu_Y Y \Sigma X_1, X_2,\dots, X_n \operatorname{corr}(X_m, X_{m+t}) \to 0 t \to \infty \frac{1}{n}(X_1+X_2+\dots +X_n) \to E(X) ","['statistics', 'estimation', 'time-series', 'law-of-large-numbers', 'parameter-estimation']"
19,A weaker version of sample quantile,A weaker version of sample quantile,,"If $X_1,\dots, X_n$ iid samples from CDF $F(x)$ and assume that $F$ is first order differentiable at $\xi_p$ with $f(\xi_p)>0$ . Let $F_n$ be the empirical CDF of $F(x)$ . Then $\hat{\xi}_p=F^{-1}_n(p)$ is the sample p-th quantile.  Ghosh (1971) obtained a weaker version of Bahadur’s (1966) representation: $$ \hat{\xi}_p-\xi_p=\frac{p-F_n(\xi_p)}{f(\xi_p)}+o_p(n^{-1/2}). $$ I try to prove this result as follows. Note that $F(\xi_p)=p$ and $$ \{\sqrt{n}(\hat{\xi}_p-\xi_p)\le t\}=\{p\le F_n(\xi_p+\frac{t}{\sqrt{n}})\}=\{ \frac{F(\xi_p+\frac{t}{\sqrt{n}})-F_n(\xi_p+\frac{t}{\sqrt{n}})}{f(\xi_p)}\le \frac{F(\xi_p+\frac{t}{\sqrt{n}})-F(\xi_p)}{f(\xi_p)} \} \, (*) $$ where $$ F(\xi_p+\frac{t}{\sqrt{n}})-F(\xi_p)=f(\xi_p)(\frac{t}{\sqrt{n}})+o(n^{-1/2}) $$ then the RHS on  (*) $$\sqrt{n}\times \frac{F(\xi_p+\frac{t}{\sqrt{n}})-F(\xi_p)}{f(\xi_p)}\to t$$ Also, the LHS on (*) is $$ \sqrt{n}\times\left(\frac{F(\xi_p+\frac{t}{\sqrt{n}})-F_n(\xi_p+\frac{t}{\sqrt{n}})}{f(\xi_p)}-\frac{F(\xi_p)-F_n(\xi_p)}{f(\xi_p)}\right)\to 0 $$ in probability. There is an asymptotic distribution of $\sqrt{n}\frac{F(\xi_p)-F_n(\xi_p)}{f(\xi_p)}$ to a Normal distribution from CLT. But how to prove that $$ \sqrt{n}\left((\hat{\xi}_p-\xi_p)-\frac{p-F_n(\xi_p)}{f(\xi_p)}\right)=o_p(1)? $$","If iid samples from CDF and assume that is first order differentiable at with . Let be the empirical CDF of . Then is the sample p-th quantile.  Ghosh (1971) obtained a weaker version of Bahadur’s (1966) representation: I try to prove this result as follows. Note that and where then the RHS on  (*) Also, the LHS on (*) is in probability. There is an asymptotic distribution of to a Normal distribution from CLT. But how to prove that","X_1,\dots, X_n F(x) F \xi_p f(\xi_p)>0 F_n F(x) \hat{\xi}_p=F^{-1}_n(p) 
\hat{\xi}_p-\xi_p=\frac{p-F_n(\xi_p)}{f(\xi_p)}+o_p(n^{-1/2}).
 F(\xi_p)=p 
\{\sqrt{n}(\hat{\xi}_p-\xi_p)\le t\}=\{p\le F_n(\xi_p+\frac{t}{\sqrt{n}})\}=\{
\frac{F(\xi_p+\frac{t}{\sqrt{n}})-F_n(\xi_p+\frac{t}{\sqrt{n}})}{f(\xi_p)}\le \frac{F(\xi_p+\frac{t}{\sqrt{n}})-F(\xi_p)}{f(\xi_p)}
\} \, (*)
 
F(\xi_p+\frac{t}{\sqrt{n}})-F(\xi_p)=f(\xi_p)(\frac{t}{\sqrt{n}})+o(n^{-1/2})
 \sqrt{n}\times \frac{F(\xi_p+\frac{t}{\sqrt{n}})-F(\xi_p)}{f(\xi_p)}\to t 
\sqrt{n}\times\left(\frac{F(\xi_p+\frac{t}{\sqrt{n}})-F_n(\xi_p+\frac{t}{\sqrt{n}})}{f(\xi_p)}-\frac{F(\xi_p)-F_n(\xi_p)}{f(\xi_p)}\right)\to 0
 \sqrt{n}\frac{F(\xi_p)-F_n(\xi_p)}{f(\xi_p)} 
\sqrt{n}\left((\hat{\xi}_p-\xi_p)-\frac{p-F_n(\xi_p)}{f(\xi_p)}\right)=o_p(1)?
","['probability', 'analysis', 'statistics', 'statistical-inference']"
20,Effect of conditioning on quantiles,Effect of conditioning on quantiles,,"Cross posted on Cross Validated https://stats.stackexchange.com/questions/565661/effect-of-conditioning-on-quantiles Suppose that we have three continuous, independent, non-negative random variables $X,Y,Z$ . Fix $q\in(0,1)$ and suppose that $$q=\mathbb{P}(X+Y\leqslant \tau)=\mathbb{P}(X+Y+Z\leqslant \pi).$$ For $\mu>0$ such that $\mathbb{P}(X\leqslant \mu)>0$ , is it true that $$\mathbb{P}(X+Y\leqslant \tau|X\leqslant \mu) \geqslant \mathbb{P}(X+Y+Z\leqslant \pi|X\leqslant \mu)?$$ In other words, what effect does replacing the unconditional sums $X+Y, X+Y+Z$ with $(X+Y)|(X\leqslant \mu)$ , $(X+Y+Z)|(X\leqslant \mu)$ have on the quantiles?","Cross posted on Cross Validated https://stats.stackexchange.com/questions/565661/effect-of-conditioning-on-quantiles Suppose that we have three continuous, independent, non-negative random variables . Fix and suppose that For such that , is it true that In other words, what effect does replacing the unconditional sums with , have on the quantiles?","X,Y,Z q\in(0,1) q=\mathbb{P}(X+Y\leqslant \tau)=\mathbb{P}(X+Y+Z\leqslant \pi). \mu>0 \mathbb{P}(X\leqslant \mu)>0 \mathbb{P}(X+Y\leqslant \tau|X\leqslant \mu) \geqslant \mathbb{P}(X+Y+Z\leqslant \pi|X\leqslant \mu)? X+Y, X+Y+Z (X+Y)|(X\leqslant \mu) (X+Y+Z)|(X\leqslant \mu)","['probability', 'probability-theory', 'statistics', 'probability-distributions']"
21,Ask a question about probability calculation in statistics,Ask a question about probability calculation in statistics,,"Suppose that the time to death X has an exponential distribution with hazard rate $\lambda$ and that the right-censoring time C is exponential with hazard rate $\theta$ . Let T = min(X,C) and $\delta$ = 1 if X $\leq$ C; 0,if X > C. Assume that X and C are independent. Show that $\delta$ and T are independent. My attempt: We only need to show that $P(\delta=1, T>t)= P(\delta=1) P(T>t)$ , for any non-negative t, and $P(\delta=0, T>t)= P(\delta=0) P(T>t)$ . $P(\delta=1, T>t)= P(X \leq C, T>t)= P(X \leq C, \min(X,C)>t) = P(X \leq C, X>t,C>t)= P(X \leq C, X>t | C>t) P(C>t)$ , The second term is easy to find since C is exponential distributed. I find $P(C>t) = e^{- \theta t}$ . I am stuck with the first term. $P(X \leq C, X>t | C>t) = \int_{s=t}^\infty P(X \leq C, X>t | C=S) ds = \int_{s=t}^\infty P(X \leq S, X>t | C=S) ds = \int_{s=t}^\infty P(X \leq S, X>t) ds$ since X and C are independent. Then I find $P(X \leq S, X>t) = e^{- \lambda t} - e^{- \lambda s}$ . Then I plug this value back, I get $\int_{s=t}^\infty (e^{- \lambda t} - e^{- \lambda s}) ds$ , which the first term gives me infinity, which is wrong.","Suppose that the time to death X has an exponential distribution with hazard rate and that the right-censoring time C is exponential with hazard rate . Let T = min(X,C) and = 1 if X C; 0,if X > C. Assume that X and C are independent. Show that and T are independent. My attempt: We only need to show that , for any non-negative t, and . , The second term is easy to find since C is exponential distributed. I find . I am stuck with the first term. since X and C are independent. Then I find . Then I plug this value back, I get , which the first term gives me infinity, which is wrong.","\lambda \theta \delta \leq \delta P(\delta=1, T>t)= P(\delta=1) P(T>t) P(\delta=0, T>t)= P(\delta=0) P(T>t) P(\delta=1, T>t)= P(X \leq C, T>t)= P(X \leq C, \min(X,C)>t) = P(X \leq C, X>t,C>t)= P(X \leq C, X>t | C>t) P(C>t) P(C>t) = e^{- \theta t} P(X \leq C, X>t | C>t) = \int_{s=t}^\infty P(X \leq C, X>t | C=S) ds = \int_{s=t}^\infty P(X \leq S, X>t | C=S) ds = \int_{s=t}^\infty P(X \leq S, X>t) ds P(X \leq S, X>t) = e^{- \lambda t} - e^{- \lambda s} \int_{s=t}^\infty (e^{- \lambda t} - e^{- \lambda s}) ds","['integration', 'statistics']"
22,Convergence in Law for Sum of gamma variables,Convergence in Law for Sum of gamma variables,,"Let $X_1,X_2,...,X_n \overset{\text{iid}}{\sim} \text{gamma}(\alpha , \text{scale}=\theta )$ . Let $Y_n := \sum_{i=1}^n X_i$ . I have found that for each positive integer $n$ , $Y_n \sim \text{gamma}(n\alpha ,\beta )$ (using moment generating functions). I am now asked to find two constants $c_1$ and $c_2$ so that $$\sqrt{n} \left ( Y_n - c_1 \right ) \overset{L}{\longrightarrow} \text{N}(0,c_2) .$$ My first thought is to quote central limit theorem, but that is only defined with sample means. I also attempted to use moment generating functions, but I had trouble with the $\sqrt{n}$ affecting when the moment generating functions exist finitely. If anyone can give a suggestion, that would be very helpful.","Let . Let . I have found that for each positive integer , (using moment generating functions). I am now asked to find two constants and so that My first thought is to quote central limit theorem, but that is only defined with sample means. I also attempted to use moment generating functions, but I had trouble with the affecting when the moment generating functions exist finitely. If anyone can give a suggestion, that would be very helpful.","X_1,X_2,...,X_n \overset{\text{iid}}{\sim} \text{gamma}(\alpha , \text{scale}=\theta ) Y_n := \sum_{i=1}^n X_i n Y_n \sim \text{gamma}(n\alpha ,\beta ) c_1 c_2 \sqrt{n} \left ( Y_n - c_1 \right ) \overset{L}{\longrightarrow} \text{N}(0,c_2) . \sqrt{n}","['statistics', 'statistical-inference']"
23,Minimum KL divergence distribution with constant shift,Minimum KL divergence distribution with constant shift,,"I have a little trouble calculating the optimal distribution $P$ with fixed variance value that minimizes the following KL divergence: $$KL(x||x-\epsilon),$$ where $\epsilon$ is known and $x\sim P$ . Not sure whether it would be related but if the objective is the entropy instead of the KL, the optimal solution would be Gaussian distribution by solving the Lagrangian function of the objective. I wonder whether there would be some similar solutions when the objective is KL divergence instead of the entropy?","I have a little trouble calculating the optimal distribution with fixed variance value that minimizes the following KL divergence: where is known and . Not sure whether it would be related but if the objective is the entropy instead of the KL, the optimal solution would be Gaussian distribution by solving the Lagrangian function of the objective. I wonder whether there would be some similar solutions when the objective is KL divergence instead of the entropy?","P KL(x||x-\epsilon), \epsilon x\sim P","['probability', 'statistics', 'optimization']"
24,Show that $E \sup_n |\frac{\xi_n}{n}|<\infty \Leftrightarrow E|\xi_1| \log^+ |\xi_1|<\infty$.,Show that .,E \sup_n |\frac{\xi_n}{n}|<\infty \Leftrightarrow E|\xi_1| \log^+ |\xi_1|<\infty,"Problem: Let $\xi_1,\xi_2,...$ be a sequence of independent ientically distributed random variables. Show that $E \sup_n |\frac{\xi_n}{n}|<\infty \Leftrightarrow E|\xi_1| \log^+ |\xi_1|<\infty$ . This is a problem from Shiryaev's Probability Theory. Kolmogorov's Law of Large numbers: If $\xi_1,\xi_2,...$ be independent identically distributed random variables, then $E |\xi_1|<\infty \Leftrightarrow n^{-1} S_n \rightarrow E \xi_1$ and $E |\xi_1|=\infty \Leftrightarrow \lim \sup n^{-1} S_n=+\infty$ . Back to the problem, for $\Rightarrow$ , $E |\xi_1| \log^+ |\xi_1|<\infty$ , we get $E |\xi_1|<\infty$ . From Kolmogorov's law of large number, we get $\frac{\xi_n}{n} \rightarrow E \xi_1$ . So $\frac{\xi_n}{n}=\frac{S_n-S_{n-1}}{n}=E\xi_1-E\xi_1=0$ . So $P(|\xi_n|>n i.o)=0$ and $\sup_n |\frac{\xi_n}{n}| \leq 1$ , and $E \sup_n |\frac{\xi_n}{n}|<\infty$ . For $\Leftarrow$ ,I am stuck here. I think the approach is based on Kolmogorov's Law of Large number again, but I am not sure how to apply $E|\xi_1|<\infty$ to get $E|\xi_1| \log^+ |\xi_1|<\infty$ , and how to apply $E \sup_n |\frac{\xi_n}{n}|<\infty$ to get $\frac{S_n}{n}$ to converge. Thanks in advance!","Problem: Let be a sequence of independent ientically distributed random variables. Show that . This is a problem from Shiryaev's Probability Theory. Kolmogorov's Law of Large numbers: If be independent identically distributed random variables, then and . Back to the problem, for , , we get . From Kolmogorov's law of large number, we get . So . So and , and . For ,I am stuck here. I think the approach is based on Kolmogorov's Law of Large number again, but I am not sure how to apply to get , and how to apply to get to converge. Thanks in advance!","\xi_1,\xi_2,... E \sup_n |\frac{\xi_n}{n}|<\infty \Leftrightarrow E|\xi_1| \log^+ |\xi_1|<\infty \xi_1,\xi_2,... E |\xi_1|<\infty \Leftrightarrow n^{-1} S_n \rightarrow E \xi_1 E |\xi_1|=\infty \Leftrightarrow \lim \sup n^{-1} S_n=+\infty \Rightarrow E |\xi_1| \log^+ |\xi_1|<\infty E |\xi_1|<\infty \frac{\xi_n}{n} \rightarrow E \xi_1 \frac{\xi_n}{n}=\frac{S_n-S_{n-1}}{n}=E\xi_1-E\xi_1=0 P(|\xi_n|>n i.o)=0 \sup_n |\frac{\xi_n}{n}| \leq 1 E \sup_n |\frac{\xi_n}{n}|<\infty \Leftarrow E|\xi_1|<\infty E|\xi_1| \log^+ |\xi_1|<\infty E \sup_n |\frac{\xi_n}{n}|<\infty \frac{S_n}{n}","['probability', 'statistics', 'law-of-large-numbers']"
25,Can I use Bayes Theorem to understand Medvedev vs Nadal win predictor probabilities at AO 2022?,Can I use Bayes Theorem to understand Medvedev vs Nadal win predictor probabilities at AO 2022?,,"In recent days this picture constantly popped up in my LinkedIn feed. It shows two predictions for the outcome of the 2022 Australian Open Final between Medvedev and Nadal, made in two different points in time: one before the match and the second when the score was 2-0 Medvedev (remember: the first who gets to 3 wins). In the end Nadal won 2-3 against all odds, but it's not what I'm interested in. I am rather interested in understanding if it makes sense to apply some Bayesian notions to this scenario. Specifically, what I asked myself is: can I imagine that the model which output the second prediction was a Bayesian model and treat these two sets of predictions as the prior and the posterior? If I can, can I compute the likelihood that made the model output that posterior? And anyway, does it make any sense? I mean, is it something interesting/relevant? With this in mind, I defined: $P(H)$ = prior hypothesis: Medvedev's initial probability of winning = $64/100$ $P(\neg H)$ = Medvedev's prior propability of losing = $36/100$ $P(E|H)$ = (not sure how to phrase it, any help is appreciated...) = $\lambda$ $P(E|\neg H)$ = (not sure how to phrase it, any help is appreciated...) = $\mu$ $P(H|E)$ = Medvedev's updated probability of winning = $96/100$ Then I applied the formula as follows: $$ P(H|E) = \frac {P(H) P(E|H)}{P(E)} = \frac {P(H) P(E|H)} {P(H) P(E|H) + P(\neg H) P(E|\neg H)} $$ $$ \frac{96}{100} = \frac {\frac{64}{100} \lambda} {\frac{64}{100} \lambda+ \frac{36}{100} \mu} $$ Following some advice, I solved for $\lambda / \mu$ : $$ \frac{\lambda}{\mu} = \frac{27}{2} = 13.5 $$ Also, for simplicity, I found two values $\lambda_0$ and $\mu_0$ such that $\lambda_0 + \mu_0 = 1$ and I got: $$ \lambda_0 = 27/29 \approx 93\% \text{  ;  } \mu_0 = 2/29 \approx 7\% $$ Given this I'd conclude that a Bayesian model that started with a 64-36% prior would have needed to compute a 93% likelihood in Medvedev's win to update it to 96%. I mean, it had to believe that Medvedev would win 93% of those 64 matches. Is my claim valid? Is this formulation correct? Is this a correct way to apply the Bayesian Theorem in a practical scenario? I would like to hear and learn from the community! :) Note You might have encountered this question, slightly differently on CrossValidated but I preferred to move it here since I discovered it is a bigger community and it is possibly even more relevant here.","In recent days this picture constantly popped up in my LinkedIn feed. It shows two predictions for the outcome of the 2022 Australian Open Final between Medvedev and Nadal, made in two different points in time: one before the match and the second when the score was 2-0 Medvedev (remember: the first who gets to 3 wins). In the end Nadal won 2-3 against all odds, but it's not what I'm interested in. I am rather interested in understanding if it makes sense to apply some Bayesian notions to this scenario. Specifically, what I asked myself is: can I imagine that the model which output the second prediction was a Bayesian model and treat these two sets of predictions as the prior and the posterior? If I can, can I compute the likelihood that made the model output that posterior? And anyway, does it make any sense? I mean, is it something interesting/relevant? With this in mind, I defined: = prior hypothesis: Medvedev's initial probability of winning = = Medvedev's prior propability of losing = = (not sure how to phrase it, any help is appreciated...) = = (not sure how to phrase it, any help is appreciated...) = = Medvedev's updated probability of winning = Then I applied the formula as follows: Following some advice, I solved for : Also, for simplicity, I found two values and such that and I got: Given this I'd conclude that a Bayesian model that started with a 64-36% prior would have needed to compute a 93% likelihood in Medvedev's win to update it to 96%. I mean, it had to believe that Medvedev would win 93% of those 64 matches. Is my claim valid? Is this formulation correct? Is this a correct way to apply the Bayesian Theorem in a practical scenario? I would like to hear and learn from the community! :) Note You might have encountered this question, slightly differently on CrossValidated but I preferred to move it here since I discovered it is a bigger community and it is possibly even more relevant here.","P(H) 64/100 P(\neg H) 36/100 P(E|H) \lambda P(E|\neg H) \mu P(H|E) 96/100 
P(H|E) = \frac {P(H) P(E|H)}{P(E)} = \frac {P(H) P(E|H)} {P(H) P(E|H) + P(\neg H) P(E|\neg H)}
 
\frac{96}{100} = \frac {\frac{64}{100} \lambda} {\frac{64}{100} \lambda+ \frac{36}{100} \mu}
 \lambda / \mu 
\frac{\lambda}{\mu} = \frac{27}{2} = 13.5
 \lambda_0 \mu_0 \lambda_0 + \mu_0 = 1 
\lambda_0 = 27/29 \approx 93\% \text{  ;  } \mu_0 = 2/29 \approx 7\%
","['probability', 'statistics', 'statistical-inference', 'bayesian', 'bayes-theorem']"
26,Verifying the Bernstein condition for random matrices,Verifying the Bernstein condition for random matrices,,"Theorem 6.2 of the following paper by J. Tropp states the matrix Bernstein inequality for the subexponential case. Given two i.i.d. sequences $X_1,\dots,X_n \sim N(0,\Sigma)$ and $Y_1,\dots,Y_n \sim N(0, \Gamma)$ , I am trying to bound the maximal eigenvalue of $$ \sum_{i=1}^n Z_i=\sum_{i=1}^n X_i Y_i^T. $$ The summands are products of Gaussian vectors so they are subexponential and I should be able to use the Bernstein bound directly. I am a bit confused on verifying (and identifying the relevant parameters) in the condition: $$ E[Z_i^p] \preceq\frac{p!}{2} R^{p-2} A^2_k, \qquad p=2,3,4,\dots. $$ Is there a simple way to show that this holds? An update a slightly more straight forward statement of the matrix Bernstein result is given in Wainwright's High Dimensional Statistics text (Theorem 6.17). It is stated as follows: Let $\{ Q_i\}$ be a sequence of independent, zero mean and symmetric random matrices, and assume all matrices in the sequence satisfy the Bernstein condition with parameter $b>0$ , that is, for $i=1,2,\dots,n$ \begin{align*}          E[Q_i^p] \preceq \frac{1}{2}p! b^{p-2} \text{var}(Q_i), \quad p=2,3,4,\dots,      \end{align*} where $\text{var}(Q) := E[Q^2]-(E[Q])^2$ . Then for all $\varepsilon \ge 0$ , \begin{align*}          P \left(\frac{1}{n} \| \sum_{i=1}^n Q_i\| \ge \varepsilon \right)          \le           2 \text{rank}           \left ( \sum_{i=1}^n \text{var}(Q_i) \right )          \exp \left \{-\frac{n\varepsilon^2}{2(\sigma^2 + b \varepsilon)} \right \},      \end{align*} where \begin{align*}          \sigma^2 := \frac{1}{n} \|\sum_{i=1}^n \text{var}(Q_i)\|.      \end{align*} The result is easier to work with since it gives us the Bernstein condition should hold with the variance matrix. For my problem, we can show that $$ \text{var}(Z_i) = \Sigma \Gamma, $$ and since $Z_i$ is a product of two gaussian vectors, we know it must be subexponential, so we can conclude that there exists some b>0 (that I do not know how to solve for) such that $$ E[Z_i^p] \preceq\frac{p!}{2} b^{p-2} \Sigma \Gamma. $$ Further, assuming $\Sigma, \Gamma$ are full rank, we have that $$ \text{rank}(\sum_{i=1}^n \text{var}(Z_i)) \le nd $$ where $d$ is the dimension of the $X_i$ 's. We can therefore show that for some $b>0$ and for all $\varepsilon>0$ \begin{align*}         P \left(\frac{1}{n} \| \sum_{i=1}^n Z_i\| \ge \varepsilon \right)         \le          2 nd         \exp \left \{-\frac{n\varepsilon^2}{2(\|\Sigma\Gamma\| + b \varepsilon)} \right \},     \end{align*} This pretty much answers most of my question, but if anyone has a way to identify the correct $b$ that would be very helpful. Edit 2 My previous approach is incorrect because I assumed that the $Z_i$ are symmetric which they of course are not. The correct way to use the Bernstein result is to define the block matrix: $$ Q_i = \begin{bmatrix} O & X_iY_i^T\\ Y_iX_i^T & O\\ \end{bmatrix} $$ Then note that $Q_i$ is mean zero and has variance $\text{diag}(\text{tr}(\Gamma)\Sigma, \text{tr}(\Sigma)\Gamma)$ . The odd moments of $Q$ with $p=2k+1$ take the form: $$ Q_i^{2k+1} =  \begin{bmatrix} O & \|X_i\|^{2k} \|Y_i\|^{2k} X_iY_i^T\\ \|X_i\|^{2k} \|Y_i\|^{2k} Y_iX_i^T & O\\ \end{bmatrix} $$ and the even moments $p=2k$ take the form $$ Q_i^{2k} = \begin{bmatrix} \|X_i\|^{2k-2} \|Y_i\|^{2k} X_iX_i^T & O\\ O &\|X_i\|^{2k} \|Y_i\|^{2k-2} Y_iY_i^T \\ \end{bmatrix} $$ I am pretty stumped on how to argue that the expectation of either of these matrices is less than or equal to the right hand side of the bernstein condition with respect to the semi-definite ordering.","Theorem 6.2 of the following paper by J. Tropp states the matrix Bernstein inequality for the subexponential case. Given two i.i.d. sequences and , I am trying to bound the maximal eigenvalue of The summands are products of Gaussian vectors so they are subexponential and I should be able to use the Bernstein bound directly. I am a bit confused on verifying (and identifying the relevant parameters) in the condition: Is there a simple way to show that this holds? An update a slightly more straight forward statement of the matrix Bernstein result is given in Wainwright's High Dimensional Statistics text (Theorem 6.17). It is stated as follows: Let be a sequence of independent, zero mean and symmetric random matrices, and assume all matrices in the sequence satisfy the Bernstein condition with parameter , that is, for where . Then for all , where The result is easier to work with since it gives us the Bernstein condition should hold with the variance matrix. For my problem, we can show that and since is a product of two gaussian vectors, we know it must be subexponential, so we can conclude that there exists some b>0 (that I do not know how to solve for) such that Further, assuming are full rank, we have that where is the dimension of the 's. We can therefore show that for some and for all This pretty much answers most of my question, but if anyone has a way to identify the correct that would be very helpful. Edit 2 My previous approach is incorrect because I assumed that the are symmetric which they of course are not. The correct way to use the Bernstein result is to define the block matrix: Then note that is mean zero and has variance . The odd moments of with take the form: and the even moments take the form I am pretty stumped on how to argue that the expectation of either of these matrices is less than or equal to the right hand side of the bernstein condition with respect to the semi-definite ordering.","X_1,\dots,X_n \sim N(0,\Sigma) Y_1,\dots,Y_n \sim N(0, \Gamma) 
\sum_{i=1}^n Z_i=\sum_{i=1}^n X_i Y_i^T.
 
E[Z_i^p] \preceq\frac{p!}{2} R^{p-2} A^2_k, \qquad p=2,3,4,\dots.
 \{ Q_i\} b>0 i=1,2,\dots,n \begin{align*}
         E[Q_i^p] \preceq \frac{1}{2}p! b^{p-2} \text{var}(Q_i),
\quad p=2,3,4,\dots,
     \end{align*} \text{var}(Q) := E[Q^2]-(E[Q])^2 \varepsilon \ge 0 \begin{align*}
         P \left(\frac{1}{n} \| \sum_{i=1}^n Q_i\| \ge \varepsilon \right)
         \le 
         2 \text{rank} 
         \left ( \sum_{i=1}^n \text{var}(Q_i) \right )
         \exp \left \{-\frac{n\varepsilon^2}{2(\sigma^2 + b \varepsilon)} \right \},
     \end{align*} \begin{align*}
         \sigma^2 := \frac{1}{n} \|\sum_{i=1}^n \text{var}(Q_i)\|.
     \end{align*} 
\text{var}(Z_i) = \Sigma \Gamma,
 Z_i 
E[Z_i^p] \preceq\frac{p!}{2} b^{p-2} \Sigma \Gamma.
 \Sigma, \Gamma 
\text{rank}(\sum_{i=1}^n \text{var}(Z_i)) \le nd
 d X_i b>0 \varepsilon>0 \begin{align*}
        P \left(\frac{1}{n} \| \sum_{i=1}^n Z_i\| \ge \varepsilon \right)
        \le 
        2 nd
        \exp \left \{-\frac{n\varepsilon^2}{2(\|\Sigma\Gamma\| + b \varepsilon)} \right \},
    \end{align*} b Z_i 
Q_i = \begin{bmatrix}
O & X_iY_i^T\\
Y_iX_i^T & O\\
\end{bmatrix}
 Q_i \text{diag}(\text{tr}(\Gamma)\Sigma, \text{tr}(\Sigma)\Gamma) Q p=2k+1 
Q_i^{2k+1} = 
\begin{bmatrix}
O & \|X_i\|^{2k} \|Y_i\|^{2k} X_iY_i^T\\
\|X_i\|^{2k} \|Y_i\|^{2k} Y_iX_i^T & O\\
\end{bmatrix}
 p=2k 
Q_i^{2k} = \begin{bmatrix}
\|X_i\|^{2k-2} \|Y_i\|^{2k} X_iX_i^T & O\\
O &\|X_i\|^{2k} \|Y_i\|^{2k-2} Y_iY_i^T \\
\end{bmatrix}
","['probability', 'matrices', 'statistics', 'concentration-of-measure']"
27,Why do we use specific probability distributions in certain contexts?,Why do we use specific probability distributions in certain contexts?,,"For instance, in survival analysis and modelling time to failure, one is likely to use a weibull distribution or exponential distribution. I'm struggling to understand the intuition behind this. What makes these distributions more suited to the context than, say, a chi-square distribution or a beta distribution or a log-normal distribution?","For instance, in survival analysis and modelling time to failure, one is likely to use a weibull distribution or exponential distribution. I'm struggling to understand the intuition behind this. What makes these distributions more suited to the context than, say, a chi-square distribution or a beta distribution or a log-normal distribution?",,"['statistics', 'probability-distributions']"
28,Lining up 6 blocks when 2 can't touch,Lining up 6 blocks when 2 can't touch,,"Did I do this correctly?: edit: I’m told I did this correctly if I distinguish the blue blocks from each other. That’s what I intended I have to find how many ways I can line up $6$ colored blocks (blue, blue, green, yellow, red, orange) such that the two blue blocks are not next to each other . I found there to be 5 ways their positions can be next to each other (numbers represent position): ${(1,2),(2,3),(3,4),(4,5),(5,6)}$ Now, for each of these possibilities, the pair has $2!$ ways to align in relation to each other while the remaining $4$ blocks have $4!$ ways to line up in relation to each other... so I get $6! - (5)*(2!)*(4!) = 480$ ways the 2 blue blocks are not next to each other. Thanks for any pointers and help.","Did I do this correctly?: edit: I’m told I did this correctly if I distinguish the blue blocks from each other. That’s what I intended I have to find how many ways I can line up colored blocks (blue, blue, green, yellow, red, orange) such that the two blue blocks are not next to each other . I found there to be 5 ways their positions can be next to each other (numbers represent position): Now, for each of these possibilities, the pair has ways to align in relation to each other while the remaining blocks have ways to line up in relation to each other... so I get ways the 2 blue blocks are not next to each other. Thanks for any pointers and help.","6 {(1,2),(2,3),(3,4),(4,5),(5,6)} 2! 4 4! 6! - (5)*(2!)*(4!) = 480","['combinatorics', 'statistics']"
29,Two-sided confidence interval for the sample for the mean length,Two-sided confidence interval for the sample for the mean length,,"A sample of $n \in \mathbb{N}$ screws is taken from a large batch of screws that are produced. The length of a bolt is approximated as normally distributed with variance $4$ and the lengths of the screws are distributed as independent and identical. (a) $n = 10$ screws were taken and their length (in mm) was measured, with the following result: $$10 \ \ \ 8 \ \ \ 9 \ \ \ 10 \ \ \ 11 \ \ \ 11 \ \ \ 9 \ \ \ 12 \ \ \ 12 \ \ \ 8$$ Calculate the sample mean and determine a two-sided confidence interval for the above sample for the mean length of the confidence probability $0.95$ . Also state the quantile used and its (approximate) value. (b) How many screws had to be tested at least, thus a confidence interval for the mean length with a confidence level of $0.95$ has at most the length $2$ or length 1? Explain. $$$$ I have done the following : (a) The sample mean is equal to \begin{equation*}\overline{x}_{10}=\frac{1}{10}\left (10+8+9 + 10 + 11 + 11 + 9 + 12 + 12 +8\right )=\frac{1}{10}\cdot 100=10\end{equation*} For the two-sided confidence interval do we use the formula \begin{equation*}\left [M(x)-\frac{\sigma}{\sqrt{n}}q_{1-\frac{a}{2}},M(x)+\frac{\sigma}{\sqrt{n}}q_{1-\frac{a}{2}}\right ] \end{equation*} where $M(x)$ is the mean, i.e. $M(x)=10$ and $\sigma=\sqrt{4}=2$ ? The value of $q$ is related to the confidence level, right?","A sample of screws is taken from a large batch of screws that are produced. The length of a bolt is approximated as normally distributed with variance and the lengths of the screws are distributed as independent and identical. (a) screws were taken and their length (in mm) was measured, with the following result: Calculate the sample mean and determine a two-sided confidence interval for the above sample for the mean length of the confidence probability . Also state the quantile used and its (approximate) value. (b) How many screws had to be tested at least, thus a confidence interval for the mean length with a confidence level of has at most the length or length 1? Explain. I have done the following : (a) The sample mean is equal to For the two-sided confidence interval do we use the formula where is the mean, i.e. and ? The value of is related to the confidence level, right?","n \in \mathbb{N} 4 n = 10 10 \ \ \ 8 \ \ \ 9 \ \ \ 10 \ \ \ 11 \ \ \ 11 \ \ \ 9 \ \ \ 12 \ \ \ 12 \ \ \ 8 0.95 0.95 2  \begin{equation*}\overline{x}_{10}=\frac{1}{10}\left (10+8+9 + 10 + 11 + 11 + 9 + 12 + 12 +8\right )=\frac{1}{10}\cdot 100=10\end{equation*} \begin{equation*}\left [M(x)-\frac{\sigma}{\sqrt{n}}q_{1-\frac{a}{2}},M(x)+\frac{\sigma}{\sqrt{n}}q_{1-\frac{a}{2}}\right ] \end{equation*} M(x) M(x)=10 \sigma=\sqrt{4}=2 q","['probability', 'statistics', 'means', 'confidence-interval']"
30,Double integral with absolute function,Double integral with absolute function,,"If we have a double integral that $$ \frac{1}{2\theta} \int_{x_2 - \theta}^{x_2 + \theta} \int_{x_1 - \theta}^{x_1 + \theta} \exp\Big(- \frac{|z_1 - z_2|}{\phi}\Big) dz_1dz_2, $$ where $x_i, z_i \in\mathbb R$ , I think that it may be good to pass $$ d = x_1 - x_2 $$ into the integral but I don't know how to deal with the lower and upper bound in double integral.","If we have a double integral that where , I think that it may be good to pass into the integral but I don't know how to deal with the lower and upper bound in double integral.","
\frac{1}{2\theta} \int_{x_2 - \theta}^{x_2 + \theta} \int_{x_1 - \theta}^{x_1 + \theta} \exp\Big(- \frac{|z_1 - z_2|}{\phi}\Big) dz_1dz_2,
 x_i, z_i \in\mathbb R 
d = x_1 - x_2
","['calculus', 'integration', 'statistics', 'exponential-function', 'stochastic-integrals']"
31,application of Neyman–Pearson Lemma,application of Neyman–Pearson Lemma,,"Suppose that the distribution of lifetimes of TV tubes can be modelled by an exponential distribution with mean $\lambda$ so $f(x|\lambda)$ = $\frac{1}{\lambda}$ $e^\frac{-x}{\lambda}$ , $x>0$ . Under usual production conditions the mean lifetime is $50$ hours but if a fault occurs in the process the mean lifetime drops to $40$ hours A random sample of $20$ tube lifetimes is to taken in order to test the hypothesis $H_0:\lambda = 50$ vs $H_1:\lambda = 30$ and the following statistics is observed $\sum_{i=0}^n X_i = 680$ . Use Neyman–Pearson lemma to find the most powerful test with signficance level $\alpha = 0.05$ . My attempt was to start with the joint probability ratio under $H_0$ and $H_1$ $$\frac{\frac{1}{50^{20}}e^{\frac{-\sum_{i=1}^{20} x_i}{50}}}{ \frac{1}{30^{20}}e^{\frac{-\sum_{i=1}^{20} x_i}{30}}} .$$ We reject $H_0$ when $(\frac{1}{\lambda_1} -\frac{1}{\lambda_0}) \sum_{i=1}^n X_i <k$ . Since in the parenthesis we have a positive quantity should we reject $H_0$ ? I do not understand the importance of the data $40$ since the alternative hypothesis is $30$ and not $40$ . Is this the right way to solve this exercise? I am trying to understand Neyman–Pearson lemma and any help would be appreciate.","Suppose that the distribution of lifetimes of TV tubes can be modelled by an exponential distribution with mean so = , . Under usual production conditions the mean lifetime is hours but if a fault occurs in the process the mean lifetime drops to hours A random sample of tube lifetimes is to taken in order to test the hypothesis vs and the following statistics is observed . Use Neyman–Pearson lemma to find the most powerful test with signficance level . My attempt was to start with the joint probability ratio under and We reject when . Since in the parenthesis we have a positive quantity should we reject ? I do not understand the importance of the data since the alternative hypothesis is and not . Is this the right way to solve this exercise? I am trying to understand Neyman–Pearson lemma and any help would be appreciate.",\lambda f(x|\lambda) \frac{1}{\lambda} e^\frac{-x}{\lambda} x>0 50 40 20 H_0:\lambda = 50 H_1:\lambda = 30 \sum_{i=0}^n X_i = 680 \alpha = 0.05 H_0 H_1 \frac{\frac{1}{50^{20}}e^{\frac{-\sum_{i=1}^{20} x_i}{50}}}{ \frac{1}{30^{20}}e^{\frac{-\sum_{i=1}^{20} x_i}{30}}} . H_0 (\frac{1}{\lambda_1} -\frac{1}{\lambda_0}) \sum_{i=1}^n X_i <k H_0 40 30 40,"['statistics', 'statistical-inference', 'hypothesis-testing']"
32,Some questions about single sample sign test,Some questions about single sample sign test,,"$S^+$ : number of values greater than the median. $S^-$ : number of values less than the median. Question 1 For the given hypothesis and sample size, state whether the null hypothesis should be rejected at the 5% significance level $H_0:$ median = k $H_1:$ median < k $n=8$ and $S^+= 3$ . My work for Question 1: $X$ : number of values, out of 8, greater than median. $X \sim B (8,0.5)$ $P(X \le 3)=0.5^8\sum _{r=0}^{3}8Cr=0.363$ . Since the test statistic ( $=3$ ) is not within rejection region, we do not reject null hypothesis. Is this the correct way to do this question? Here's another question where I used the above method but got the incorrect answer : Question 2 For the given hypothesis and sample size, state whether the null hypothesis should be rejected at the 5% significance level $H_0:$ median = k $H_1:$ median > k $n=15$ and $S^+= 11$ . My work for Question 2: $X$ : number of values, out of 15, greater than median. $X \sim B (15,0.5)$ $P(X \ge 11)=0.5^{15}\sum _{r=11}^{15}15Cr=0.059$ . Since the test statistic ( $=11$ ) is not within rejection region, we do not reject null hypothesis. However, according to the answer sheet, my answer for question 2 is incorrect. Null hypothesis should have been rejected. Where did I mess up? Some additional questions about single sample sign test : Would the procedure/conclusion change if we were told instead that $S^-=3$ for first question and $S^-=11$ for the second question? If $H_1$ : median $>k$ and $s^+<n/2$ , on which tail do I place the rejection region?",": number of values greater than the median. : number of values less than the median. Question 1 For the given hypothesis and sample size, state whether the null hypothesis should be rejected at the 5% significance level median = k median < k and . My work for Question 1: : number of values, out of 8, greater than median. . Since the test statistic ( ) is not within rejection region, we do not reject null hypothesis. Is this the correct way to do this question? Here's another question where I used the above method but got the incorrect answer : Question 2 For the given hypothesis and sample size, state whether the null hypothesis should be rejected at the 5% significance level median = k median > k and . My work for Question 2: : number of values, out of 15, greater than median. . Since the test statistic ( ) is not within rejection region, we do not reject null hypothesis. However, according to the answer sheet, my answer for question 2 is incorrect. Null hypothesis should have been rejected. Where did I mess up? Some additional questions about single sample sign test : Would the procedure/conclusion change if we were told instead that for first question and for the second question? If : median and , on which tail do I place the rejection region?","S^+ S^- H_0: H_1: n=8 S^+= 3 X X \sim B (8,0.5) P(X \le 3)=0.5^8\sum _{r=0}^{3}8Cr=0.363 =3 H_0: H_1: n=15 S^+= 11 X X \sim B (15,0.5) P(X \ge 11)=0.5^{15}\sum _{r=11}^{15}15Cr=0.059 =11 S^-=3 S^-=11 H_1 >k s^+<n/2","['probability', 'statistics', 'statistical-inference', 'hypothesis-testing']"
33,Why is the Kolmogorov-Smirnov statistic distribution free?,Why is the Kolmogorov-Smirnov statistic distribution free?,,"Context Let $X_1,..X_n$ iid from X with an unknown cumulative distribution function F. Let $F_0$ be the hypothetized cdf of X. One may use the Kolmogorov-Smirnov (KS) statistic to test for the hypothesis test : \begin{align} H_0 : F = F_0 \\ H_1 : F \neq F_0  \end{align} The Kolmogorov-Smirnov (KS) statistic is : \begin{align}     D_n = sup_x |F_n(x)-F_0(x)| \end{align} The empirical cdf F_n(x) is : \begin{align}     F_n(x) = \frac{i}{n} \ \text{for} \ X_{(i)}\leq x < X_{(i+1)} i = 0,1..,n \end{align} Question I fail to understand the distribution-free property of the KS statistic. If by $D^+_n$ I denote : \begin{align}     D^+_n = sup_x(F_n(x)-F_0(x)) \end{align} Then I get the following : \begin{align}     D^+_n = \sup_x(F_n(x)-F_0(x)) &= \max_{0<i\leq n} \sup_{X_{(i)}\leq x < X_{(i+1)}} (F_n(x) - F_0(x)) \\     &= \max_{0<i\leq n} \sup_{X_{(i)}\leq x < X_{(i+1)}} (F_0(x) - \frac{i}{n}) \\     &= \max_{1<j\leq n+1} (F_0(X_{(j)}) - \frac{j-1}{n}) \end{align} Which according to one of my textbook shows the distribution-free property of the KS statistic, because $(F_0(X_{(j)})$ would be the order statistic from a uniform distribution (0,1). I fail to understand why $(F_0(X_{(j)})$ are the order statistics from the uniform distribution.","Context Let iid from X with an unknown cumulative distribution function F. Let be the hypothetized cdf of X. One may use the Kolmogorov-Smirnov (KS) statistic to test for the hypothesis test : The Kolmogorov-Smirnov (KS) statistic is : The empirical cdf F_n(x) is : Question I fail to understand the distribution-free property of the KS statistic. If by I denote : Then I get the following : Which according to one of my textbook shows the distribution-free property of the KS statistic, because would be the order statistic from a uniform distribution (0,1). I fail to understand why are the order statistics from the uniform distribution.","X_1,..X_n F_0 \begin{align}
H_0 : F = F_0 \\
H_1 : F \neq F_0 
\end{align} \begin{align}
    D_n = sup_x |F_n(x)-F_0(x)|
\end{align} \begin{align}
    F_n(x) = \frac{i}{n} \ \text{for} \ X_{(i)}\leq x < X_{(i+1)} i = 0,1..,n
\end{align} D^+_n \begin{align}
    D^+_n = sup_x(F_n(x)-F_0(x))
\end{align} \begin{align}
    D^+_n = \sup_x(F_n(x)-F_0(x)) &= \max_{0<i\leq n} \sup_{X_{(i)}\leq x < X_{(i+1)}} (F_n(x) - F_0(x)) \\
    &= \max_{0<i\leq n} \sup_{X_{(i)}\leq x < X_{(i+1)}} (F_0(x) - \frac{i}{n}) \\
    &= \max_{1<j\leq n+1} (F_0(X_{(j)}) - \frac{j-1}{n})
\end{align} (F_0(X_{(j)}) (F_0(X_{(j)})","['probability-theory', 'statistics', 'probability-distributions']"
34,Prove non-existence of UMP test for Cauchy distribution,Prove non-existence of UMP test for Cauchy distribution,,"I wish to prove for $X_1,\dots,X_n$ i.i.d. Cauchy( $\theta,1$ ) random variables that there doesn't exist a UMP for $H_0: \theta = 0$ against $H_1: \theta>0$ . For $\theta_1<\theta_2$ , NP tests $(\varphi_1)$ for $H_0: \theta = 0$ against $H_1: \theta=\theta_1$ and $(\varphi_2)$ $H_0: \theta = 0$ against $H_1: \theta=\theta_2$ should produce the respective critical regions $$\prod_{i=1}^n \frac{1+(x_i-\theta_1)^2}{1+x_i^2} < k$$ and $$\prod_{i=1}^n \frac{1+(x_i-\theta_2)^2}{1+x_i^2} < k$$ I'm at a bit of a loss how to proceed from here. How do I show with rigor that these regions are not equal?","I wish to prove for i.i.d. Cauchy( ) random variables that there doesn't exist a UMP for against . For , NP tests for against and against should produce the respective critical regions and I'm at a bit of a loss how to proceed from here. How do I show with rigor that these regions are not equal?","X_1,\dots,X_n \theta,1 H_0: \theta = 0 H_1: \theta>0 \theta_1<\theta_2 (\varphi_1) H_0: \theta = 0 H_1: \theta=\theta_1 (\varphi_2) H_0: \theta = 0 H_1: \theta=\theta_2 \prod_{i=1}^n \frac{1+(x_i-\theta_1)^2}{1+x_i^2} < k \prod_{i=1}^n \frac{1+(x_i-\theta_2)^2}{1+x_i^2} < k","['statistics', 'hypothesis-testing']"
35,How to find joint distribution of two normally distributed random variables?,How to find joint distribution of two normally distributed random variables?,,"I have a problem with this exercise. Let $Y_1$ and $Y_2$ be independent random variables with $Y_1∼N(1,3)$ and $Y_2∼N(2,5)$ . If $W_1=Y_1+2Y_2$ and $W_2=4Y_1−Y_2$ , what is the joint distribution of $W_1$ and $W_2$ ? So I know that $W_1∼N(5,23)$ and $W_2∼N(2,53)$ . But I also need the correlation coefficient for $W_1$ and $W_2$ for the variance-covariance matrix, how do I calculate this? Do I need to calculate the covariance first, and in that case, how do I do that?","I have a problem with this exercise. Let and be independent random variables with and . If and , what is the joint distribution of and ? So I know that and . But I also need the correlation coefficient for and for the variance-covariance matrix, how do I calculate this? Do I need to calculate the covariance first, and in that case, how do I do that?","Y_1 Y_2 Y_1∼N(1,3) Y_2∼N(2,5) W_1=Y_1+2Y_2 W_2=4Y_1−Y_2 W_1 W_2 W_1∼N(5,23) W_2∼N(2,53) W_1 W_2","['statistics', 'random-variables', 'normal-distribution', 'covariance', 'correlation']"
36,Question on credible intervals for the parameter of an exponential distribution with Gamma prior,Question on credible intervals for the parameter of an exponential distribution with Gamma prior,,"Suppose we have a random sample $X_1, ..., X_n$ where $X \sim$ Expo $(\theta)$ (here $\theta$ is the rate). We're studying the Bayes estimator of $\theta$ and its properties. For a Gamma $(\alpha, \beta)$ ( $\beta$ as scale) prior, I found the posterior distribution to be $$\text{Gamma}(\alpha + n, \left( \sum X_i + 1 / \beta \right)^{-1})$$ and consequently the Bayes estimator as $$T^{B}(X_1, ..., X_n) = \frac{\alpha + n}{\sum X_i + 1 / \beta}. $$ Now I'm tasked to find a credible region for $\theta$ , but I'm quite confused on how to find this. Initially I thought this could just be the quantiles of our posterior distribution, but looking a bit around online, this doesn't seem to be the case...","Suppose we have a random sample where Expo (here is the rate). We're studying the Bayes estimator of and its properties. For a Gamma ( as scale) prior, I found the posterior distribution to be and consequently the Bayes estimator as Now I'm tasked to find a credible region for , but I'm quite confused on how to find this. Initially I thought this could just be the quantiles of our posterior distribution, but looking a bit around online, this doesn't seem to be the case...","X_1, ..., X_n X \sim (\theta) \theta \theta (\alpha, \beta) \beta \text{Gamma}(\alpha + n, \left( \sum X_i + 1 / \beta \right)^{-1}) T^{B}(X_1, ..., X_n) = \frac{\alpha + n}{\sum X_i + 1 / \beta}.  \theta","['statistics', 'statistical-inference', 'bayesian']"
37,Confidence interval for the variance of exponential distribution?,Confidence interval for the variance of exponential distribution?,,"I know that if $X \sim \operatorname{Exp}(\theta)$ , and $Y=\theta X \implies Y \sim \operatorname{Exp}(1)$ . I want a confidence interval for $E(X)= \frac{1}{\theta}$ and $\operatorname{Var}(X)= \frac{1}{\theta^2}$ The confidence interval for the mean is: $P(a<Y<b)=1-\alpha \implies P(a<\theta X<b)=1-\alpha $ And then $P(\frac{X}{b}<\frac{1}{\theta}<\frac{X}{a})=1-\alpha$ . Can I do this? : $P((\frac{X}{b})^2<(\frac{1}{\theta})^2<(\frac{X}{a})^2)=1-\alpha \ $ is a confidence interval for the variance. I'm not sure if this is correct.","I know that if , and . I want a confidence interval for and The confidence interval for the mean is: And then . Can I do this? : is a confidence interval for the variance. I'm not sure if this is correct.",X \sim \operatorname{Exp}(\theta) Y=\theta X \implies Y \sim \operatorname{Exp}(1) E(X)= \frac{1}{\theta} \operatorname{Var}(X)= \frac{1}{\theta^2} P(a<Y<b)=1-\alpha \implies P(a<\theta X<b)=1-\alpha  P(\frac{X}{b}<\frac{1}{\theta}<\frac{X}{a})=1-\alpha P((\frac{X}{b})^2<(\frac{1}{\theta})^2<(\frac{X}{a})^2)=1-\alpha \ ,"['probability', 'statistics', 'probability-distributions', 'statistical-inference', 'confidence-interval']"
38,Higher derivatives of the log-partition function,Higher derivatives of the log-partition function,,"I need higher derivatives of the log-partition function $Z(z)=\log \sum_i \exp(z_i)$ , has anyone derived the formula? Looking at concrete values of derivatives up to order 8, evaluated at $z=(1,1,1)$ makes me suspect there's a nice formula in terms of $p_i=\frac{\exp z_i}{Z}$ $$H_2= \left( \begin{array}{ccc}  \frac{2}{9} & -\frac{1}{9} & -\frac{1}{9} \\  -\frac{1}{9} & \frac{2}{9} & -\frac{1}{9} \\  -\frac{1}{9} & -\frac{1}{9} & \frac{2}{9} \\ \end{array} \right)=\text{diag}(p)-pp' $$ $$H_3=\left[\left( \begin{array}{ccc}  \frac{2}{27} & -\frac{1}{27} & -\frac{1}{27} \\  -\frac{1}{27} & -\frac{1}{27} & \frac{2}{27} \\  -\frac{1}{27} & \frac{2}{27} & -\frac{1}{27} \\ \end{array} \right),\left( \begin{array}{ccc}  -\frac{1}{27} & -\frac{1}{27} & \frac{2}{27} \\  -\frac{1}{27} & \frac{2}{27} & -\frac{1}{27} \\  \frac{2}{27} & -\frac{1}{27} & -\frac{1}{27} \\ \end{array} \right),\left( \begin{array}{ccc}  -\frac{1}{27} & \frac{2}{27} & -\frac{1}{27} \\  \frac{2}{27} & -\frac{1}{27} & -\frac{1}{27} \\  -\frac{1}{27} & -\frac{1}{27} & \frac{2}{27} \\ \end{array}\right) \right]$$ ( crossposted on physics.SE)","I need higher derivatives of the log-partition function , has anyone derived the formula? Looking at concrete values of derivatives up to order 8, evaluated at makes me suspect there's a nice formula in terms of ( crossposted on physics.SE)","Z(z)=\log \sum_i \exp(z_i) z=(1,1,1) p_i=\frac{\exp z_i}{Z} H_2=
\left(
\begin{array}{ccc}
 \frac{2}{9} & -\frac{1}{9} & -\frac{1}{9} \\
 -\frac{1}{9} & \frac{2}{9} & -\frac{1}{9} \\
 -\frac{1}{9} & -\frac{1}{9} & \frac{2}{9} \\
\end{array}
\right)=\text{diag}(p)-pp'
 H_3=\left[\left(
\begin{array}{ccc}
 \frac{2}{27} & -\frac{1}{27} & -\frac{1}{27} \\
 -\frac{1}{27} & -\frac{1}{27} & \frac{2}{27} \\
 -\frac{1}{27} & \frac{2}{27} & -\frac{1}{27} \\
\end{array}
\right),\left(
\begin{array}{ccc}
 -\frac{1}{27} & -\frac{1}{27} & \frac{2}{27} \\
 -\frac{1}{27} & \frac{2}{27} & -\frac{1}{27} \\
 \frac{2}{27} & -\frac{1}{27} & -\frac{1}{27} \\
\end{array}
\right),\left(
\begin{array}{ccc}
 -\frac{1}{27} & \frac{2}{27} & -\frac{1}{27} \\
 \frac{2}{27} & -\frac{1}{27} & -\frac{1}{27} \\
 -\frac{1}{27} & -\frac{1}{27} & \frac{2}{27} \\
\end{array}\right)
\right]","['probability', 'statistics', 'statistical-mechanics']"
39,Can someone help me with this statistic question?,Can someone help me with this statistic question?,,"A firm decided to have a sales event that they take name cards from 1000 of their customers, and randomly distribute the cards back to those customers. And the customers who receive their own card will get 50% sales for all of the firms products. When X is a random variable of number of people who gets back their own card, what is the variance of X I tried by first let $A_i$ be the event that $i^{th}$ person getting back his own card. which so $P(A_i) = 1/1000$ and $P(A_i \bigcap A_j)=1/(1000)(999)$ from here I am kind of lost what to do","A firm decided to have a sales event that they take name cards from 1000 of their customers, and randomly distribute the cards back to those customers. And the customers who receive their own card will get 50% sales for all of the firms products. When X is a random variable of number of people who gets back their own card, what is the variance of X I tried by first let be the event that person getting back his own card. which so and from here I am kind of lost what to do",A_i i^{th} P(A_i) = 1/1000 P(A_i \bigcap A_j)=1/(1000)(999),['statistics']
40,How to find the probability that the sample variance (given in the question below) is this low/lower when given the true population variance?,How to find the probability that the sample variance (given in the question below) is this low/lower when given the true population variance?,,"I'm not sure how to answer the question below. I have gone through worked examples and I have the answer for this question as well. However, the answer doesn't really provide any working. There are similar questions to this that are basically structured in the same way: 'what is the probability that a sample variance this high/low would be found if the population variance is x'. I'm assuming the same process is used to solve them. Some context: I am an undergraduate student and I was working through my book when I came across this question. Relating to sample variance, I know that: Given a random sample of 'n' observations from a normally distributed population whose population variance is $\sigma^2$ and whose resulting sample variance is $s^2$ , it can be shown that: $$\chi^{2} = \frac{(n-1)s^2}{\sigma^2}$$ has a chi-square distribution with n-1 degrees of freedom. I know for the below question I may have to find values for the cumulative distribution of $\chi^{2}$ , which could be either the upper or lower tail of the distribution: P( $\chi^{2}$ <K) = 0.05 for example or P( $\chi^{2}$ >K) = 0.05 [where K can be any critical value based on the (n-1) degrees of freedom, for example: 3.94 for the lower distribution, when (n-1)=10]. I'm not sure if I have to use an upper or lower tail for the below question and what value to find from the above expression. It would be great if you could explain the process behind solving this question: Q. A manufacturer has been purchasing raw materials from a supplier whose consignments have a variance of 15.4 (in squared pounds) in impurity levels. A rival supplier claims that she can supply consignments of this raw material with the same mean impurity level but with lower variance. For a random sample of 25 consignments from the second supplier, the variance in impurity levels was found to be 12.2 . What is the probability of observing a value this low or lower for the sample variance if, in fact, the true population variance is 15.4 ? Assume that the population distribution is normal. [if this helps: Supplier 1: variance: 15.4 ; Supplier 2: n= 25 , variance: 12.2 ; true population variance: 15.4 ] Also, I apologise in advance if this isn't the right stack exchange to ask this question. Let me know if it's more appropriate in another stack exchange (as I posted it here since it part of my statistics course in economics). Any help you could provide would be much appreciated. Thanks a lot!","I'm not sure how to answer the question below. I have gone through worked examples and I have the answer for this question as well. However, the answer doesn't really provide any working. There are similar questions to this that are basically structured in the same way: 'what is the probability that a sample variance this high/low would be found if the population variance is x'. I'm assuming the same process is used to solve them. Some context: I am an undergraduate student and I was working through my book when I came across this question. Relating to sample variance, I know that: Given a random sample of 'n' observations from a normally distributed population whose population variance is and whose resulting sample variance is , it can be shown that: has a chi-square distribution with n-1 degrees of freedom. I know for the below question I may have to find values for the cumulative distribution of , which could be either the upper or lower tail of the distribution: P( <K) = 0.05 for example or P( >K) = 0.05 [where K can be any critical value based on the (n-1) degrees of freedom, for example: 3.94 for the lower distribution, when (n-1)=10]. I'm not sure if I have to use an upper or lower tail for the below question and what value to find from the above expression. It would be great if you could explain the process behind solving this question: Q. A manufacturer has been purchasing raw materials from a supplier whose consignments have a variance of 15.4 (in squared pounds) in impurity levels. A rival supplier claims that she can supply consignments of this raw material with the same mean impurity level but with lower variance. For a random sample of 25 consignments from the second supplier, the variance in impurity levels was found to be 12.2 . What is the probability of observing a value this low or lower for the sample variance if, in fact, the true population variance is 15.4 ? Assume that the population distribution is normal. [if this helps: Supplier 1: variance: 15.4 ; Supplier 2: n= 25 , variance: 12.2 ; true population variance: 15.4 ] Also, I apologise in advance if this isn't the right stack exchange to ask this question. Let me know if it's more appropriate in another stack exchange (as I posted it here since it part of my statistics course in economics). Any help you could provide would be much appreciated. Thanks a lot!",\sigma^2 s^2 \chi^{2} = \frac{(n-1)s^2}{\sigma^2} \chi^{2} \chi^{2} \chi^{2},"['statistics', 'variance', 'sampling']"
41,Expectation of the product between two dependent Bernoulli random variables,Expectation of the product between two dependent Bernoulli random variables,,"I have two dependent Bernoulli random variables $X$ and $Y$ , and I know that: $$ \begin{align} P(X=0)&=P(X=1)=1/2 \\ P(Y=1)&=11/24 \\ P(Y=0|X=0)&=1/3 \\ P(Y=1|X=1)&=1/4 \\ \end{align} $$ Is it possible to get the expectation $\mathbb{E}[XY]$ ?","I have two dependent Bernoulli random variables and , and I know that: Is it possible to get the expectation ?","X Y 
\begin{align}
P(X=0)&=P(X=1)=1/2 \\
P(Y=1)&=11/24 \\
P(Y=0|X=0)&=1/3 \\
P(Y=1|X=1)&=1/4 \\
\end{align}
 \mathbb{E}[XY]","['probability', 'statistics', 'random-variables', 'expected-value']"
42,Can someone help me with the intuition behind this combinatorics problem from Blitzstein's Stats 110?,Can someone help me with the intuition behind this combinatorics problem from Blitzstein's Stats 110?,,"Premise: ""A jar contains r red balls and g green balls, where r and g are fixed positive integers. A ball is drawn from the jar randomly (with all probabilities equally likely), and then a second ball is drawn randomly"" Question: ""Suppose that there are 16 balls in total, and that the probability that the two balls are the same color is the same as the probability that they are different colors. What are r and g?"" I understand that the only way the two probabilities equal each other are if they're both 1/2 - that's obvious. I also understand that the denominator in terms of how many combinations that can be selected is (g+r) (g+r-1). But I don't understand why in the solutions, they state the numerator as 2gr. I understand the algebra after setting (2gr)/((g+r) (g+r-1)) equal to 1/2 and solving the quadratic equation. I just don't get the intuition of why the numerator is 2gr in the first place.","Premise: ""A jar contains r red balls and g green balls, where r and g are fixed positive integers. A ball is drawn from the jar randomly (with all probabilities equally likely), and then a second ball is drawn randomly"" Question: ""Suppose that there are 16 balls in total, and that the probability that the two balls are the same color is the same as the probability that they are different colors. What are r and g?"" I understand that the only way the two probabilities equal each other are if they're both 1/2 - that's obvious. I also understand that the denominator in terms of how many combinations that can be selected is (g+r) (g+r-1). But I don't understand why in the solutions, they state the numerator as 2gr. I understand the algebra after setting (2gr)/((g+r) (g+r-1)) equal to 1/2 and solving the quadratic equation. I just don't get the intuition of why the numerator is 2gr in the first place.",,"['probability', 'combinatorics', 'statistics']"
43,Why is coin tossing combination *without* repetition?,Why is coin tossing combination *without* repetition?,,"As per the title, for a traditional statistics question like: Find the probability of landing 7 heads in 10 throws of fair coin, P(head) = 0.5 No problems with this being a combination (as opposed to a permutation), but I cannot convince myself why it's the WITHOUT repetition sub category of combinations. Thus allowing one to use the Binomial Distribution via nCr. As opposed to using the n+r-1Cr distribution for WITH repetition. What exactly does ""without repetition"" physically mean in this real life example?","As per the title, for a traditional statistics question like: Find the probability of landing 7 heads in 10 throws of fair coin, P(head) = 0.5 No problems with this being a combination (as opposed to a permutation), but I cannot convince myself why it's the WITHOUT repetition sub category of combinations. Thus allowing one to use the Binomial Distribution via nCr. As opposed to using the n+r-1Cr distribution for WITH repetition. What exactly does ""without repetition"" physically mean in this real life example?",,"['combinatorics', 'statistics', 'permutations', 'combinations']"
44,Extreme value distribution- member of the exponential family?,Extreme value distribution- member of the exponential family?,,"I am asked to prove whether or not the following distribution (extreme value distribution) is part of the exponential family: $$ f_Y(y;\mu,\phi)=\frac{1}{\phi}\exp[-\frac{y-\mu}{\phi}+\exp(-\frac{y-\mu}{\phi})]$$ My definition of the exponential family is the following: I have tried rewriting the density function and obtained: $$f_Y(y;\mu,\phi)=\exp \left[\log\frac{1}{\phi}-\frac{y}{\phi}+\frac{\mu}{\phi}-\exp\left(\frac{-y+\mu}{\phi}\right)\right]$$ However, at this point I am stuck. How do I get the density function into the form of the exponential family distribution from this point? Any help would be very much appreciated!","I am asked to prove whether or not the following distribution (extreme value distribution) is part of the exponential family: My definition of the exponential family is the following: I have tried rewriting the density function and obtained: However, at this point I am stuck. How do I get the density function into the form of the exponential family distribution from this point? Any help would be very much appreciated!"," f_Y(y;\mu,\phi)=\frac{1}{\phi}\exp[-\frac{y-\mu}{\phi}+\exp(-\frac{y-\mu}{\phi})] f_Y(y;\mu,\phi)=\exp \left[\log\frac{1}{\phi}-\frac{y}{\phi}+\frac{\mu}{\phi}-\exp\left(\frac{-y+\mu}{\phi}\right)\right]","['probability-theory', 'statistics', 'probability-distributions', 'density-function', 'exponential-distribution']"
45,Large sample properties of classical estimator for scale parameter,Large sample properties of classical estimator for scale parameter,,"I've also post this question on Stats Stackexchange as advised in the comment. Suppose $X=(X_1,X_2,\ldots,X_n)$ are non-negative and have a joint probability density $$\frac{1}{\sigma^n}f\bigl(\frac{x}{\sigma}\bigr)=\frac{1}{\sigma^n}f\bigl(\frac{x_1}{\sigma}, \frac{x_2}{\sigma},\ldots, \frac{x_n}{\sigma}\bigr),$$ where $f$ is known, and $\sigma>0$ is the only unknown parameter. In classical decision theory, we may choose an estimator $d$ to minimize the risk $$\mathbb{E}[L(\sigma,d)|\sigma],$$ here $L(\sigma,d)$ is the loss function. For example, Stein’s loss $L(\sigma,d)=d/\sigma-\log(d/\sigma)-1$ . Then the minimum risk estimator can be written as $$d=X_{1}/\mathbb{E}[X_{1}|\sigma=1,Z],$$ where $Z=(Z_1,\ldots,Z_n)$ with $Z_i=X_i/X_n$ is the maximal invariant. With the different choice of loss function, we may get a different minimum risk estimator. So far they are just some well-established results in the theory of point estimation. Usually, in large sample, we prefer MLE since $f$ is known and MLE is the most efficient $\sqrt{n}$ -consistent estimator in this case. I’m just curious about the limiting behavior of above kind of estimators. Intuitively, it is consistent. But what is the convergence rate and limiting distribution? I’ve searched for literature but got no general results about this question. I know the limiting behavior depends on $f$ , in a special case that $f$ is normal, then above estimator coincides with MLE. Will above estimator sometimes have a faster/slower convergence rate than MLE if $f$ satisfies certain conditions? Any references or ideas are welcome!","I've also post this question on Stats Stackexchange as advised in the comment. Suppose are non-negative and have a joint probability density where is known, and is the only unknown parameter. In classical decision theory, we may choose an estimator to minimize the risk here is the loss function. For example, Stein’s loss . Then the minimum risk estimator can be written as where with is the maximal invariant. With the different choice of loss function, we may get a different minimum risk estimator. So far they are just some well-established results in the theory of point estimation. Usually, in large sample, we prefer MLE since is known and MLE is the most efficient -consistent estimator in this case. I’m just curious about the limiting behavior of above kind of estimators. Intuitively, it is consistent. But what is the convergence rate and limiting distribution? I’ve searched for literature but got no general results about this question. I know the limiting behavior depends on , in a special case that is normal, then above estimator coincides with MLE. Will above estimator sometimes have a faster/slower convergence rate than MLE if satisfies certain conditions? Any references or ideas are welcome!","X=(X_1,X_2,\ldots,X_n) \frac{1}{\sigma^n}f\bigl(\frac{x}{\sigma}\bigr)=\frac{1}{\sigma^n}f\bigl(\frac{x_1}{\sigma}, \frac{x_2}{\sigma},\ldots, \frac{x_n}{\sigma}\bigr), f \sigma>0 d \mathbb{E}[L(\sigma,d)|\sigma], L(\sigma,d) L(\sigma,d)=d/\sigma-\log(d/\sigma)-1 d=X_{1}/\mathbb{E}[X_{1}|\sigma=1,Z], Z=(Z_1,\ldots,Z_n) Z_i=X_i/X_n f \sqrt{n} f f f","['statistics', 'statistical-inference', 'parameter-estimation']"
46,Probability of reaching target after n tries with regression on failure.,Probability of reaching target after n tries with regression on failure.,,"I used to play MMO game with upgrading system such that when failing to upgrade an item it does not get destroyed but insted get weakened. So let's say i have an item that is +3. When i try to upgrade it to +4 (with some chance of success p , and failure 1-p ) and fail, it gets weakened to +2. So let's say upgrade levels are +0 ... +9 and the odds of success are as follows: (this is an example, they can be arbitrary, +0 to +1 is always 1) P(+0 -> +1) = 1 P(+1 -> +2) = 0.9 P(+2 -> +3) = 0.8 P(+3 -> +4) = 0.7 P(+4 -> +5) = 0.6 P(+5 -> +6) = 0.5 P(+6 -> +7) = 0.4 P(+7 -> +8) = 0.3 P(+8 -> +9) = 0.2 What is the probability that I will fail exactly n times before reaching max upgrade? I have been thinking about it many times. I can only sumulate it, I don't even know if there is a nice general approach to it. And of course simulation is only approximate and I don't get meaningful results for failure counts of ~>300 because they are hit very rarely. The result for 100,000,000 runs can be found here https://pastebin.com/mXdNHd6z (code: https://pastebin.com/LKRwj4nk ) It plots like this for the first 200 probabilities The plot may suggest that there is a nice formula, possibly exponential. For practical purposes the values that I get from the simulation are more than sufficient, but my curiosity is not fullfilled. So the question one is if there's a way to compute exact results.  Or even a nice iterative method. And if I wanted to find out what is the average amount of times I will fail before reaching +9, would it be the smallest n failures such that the sum of all probabilities for exactly k: k < n failures is greater than 0.5?  If so then it would be around between 53 and 54. And what if we gave each upgrade a cost. Would it be possible to calculate average cost of upgrading from +0 to +9 with a similar approach (if there is one)?","I used to play MMO game with upgrading system such that when failing to upgrade an item it does not get destroyed but insted get weakened. So let's say i have an item that is +3. When i try to upgrade it to +4 (with some chance of success p , and failure 1-p ) and fail, it gets weakened to +2. So let's say upgrade levels are +0 ... +9 and the odds of success are as follows: (this is an example, they can be arbitrary, +0 to +1 is always 1) P(+0 -> +1) = 1 P(+1 -> +2) = 0.9 P(+2 -> +3) = 0.8 P(+3 -> +4) = 0.7 P(+4 -> +5) = 0.6 P(+5 -> +6) = 0.5 P(+6 -> +7) = 0.4 P(+7 -> +8) = 0.3 P(+8 -> +9) = 0.2 What is the probability that I will fail exactly n times before reaching max upgrade? I have been thinking about it many times. I can only sumulate it, I don't even know if there is a nice general approach to it. And of course simulation is only approximate and I don't get meaningful results for failure counts of ~>300 because they are hit very rarely. The result for 100,000,000 runs can be found here https://pastebin.com/mXdNHd6z (code: https://pastebin.com/LKRwj4nk ) It plots like this for the first 200 probabilities The plot may suggest that there is a nice formula, possibly exponential. For practical purposes the values that I get from the simulation are more than sufficient, but my curiosity is not fullfilled. So the question one is if there's a way to compute exact results.  Or even a nice iterative method. And if I wanted to find out what is the average amount of times I will fail before reaching +9, would it be the smallest n failures such that the sum of all probabilities for exactly k: k < n failures is greater than 0.5?  If so then it would be around between 53 and 54. And what if we gave each upgrade a cost. Would it be possible to calculate average cost of upgrading from +0 to +9 with a similar approach (if there is one)?",,['probability']
47,Geolocation from multiple timestamps,Geolocation from multiple timestamps,,"I'm trying to geolocate where in the world a particular piece of data was sent from (via the Internet). I have multiple computers located in various cities around the world, and they all receive the data at different timestamps. I can potentially take thousands of measurements throughout the day. If I make the huge assumption that latency is proportional to the great circle distance between two points, is there a way to combined my timestamp measurements to come up with a statistical best guess for where a particular piece of data is sent from? For what it's worth, I'm trying to figure out location at the granularity of what country the data is coming from, not down to a residential area or something like that.","I'm trying to geolocate where in the world a particular piece of data was sent from (via the Internet). I have multiple computers located in various cities around the world, and they all receive the data at different timestamps. I can potentially take thousands of measurements throughout the day. If I make the huge assumption that latency is proportional to the great circle distance between two points, is there a way to combined my timestamp measurements to come up with a statistical best guess for where a particular piece of data is sent from? For what it's worth, I'm trying to figure out location at the granularity of what country the data is coming from, not down to a residential area or something like that.",,"['geometry', 'statistics']"
48,Orthogonal transformation of multivariate Bernoulli-Gaussian distribution,Orthogonal transformation of multivariate Bernoulli-Gaussian distribution,,"Recently, I studied multivariate Bernoulli-Gaussian distribution which is very useful for sparse signal processing. Suppose $X = (X_{1}, \cdots, X_{n})$ are i.i.d BG( $p, \sigma^{2}$ ), we can know that $\mathbb{E}(X) = \mathbf{0}$ and Cov( $X$ ) = diag( $p \sigma^{2}$ ). Suppose $A$ is an orthogonal matrix with proper size and $Y = AX$ , we can also know that $\mathbb{E}(Y) = \mathbf{0}$ and Cov( $Y$ ) = diag( $p \sigma^{2}$ ). Is it possible for us to know the distribution of $Y$ and is it possible for us to know $Y = (Y_{1}, \cdots, Y_{n})$ are i.i.d? Thank you.","Recently, I studied multivariate Bernoulli-Gaussian distribution which is very useful for sparse signal processing. Suppose are i.i.d BG( ), we can know that and Cov( ) = diag( ). Suppose is an orthogonal matrix with proper size and , we can also know that and Cov( ) = diag( ). Is it possible for us to know the distribution of and is it possible for us to know are i.i.d? Thank you.","X = (X_{1}, \cdots, X_{n}) p, \sigma^{2} \mathbb{E}(X) = \mathbf{0} X p \sigma^{2} A Y = AX \mathbb{E}(Y) = \mathbf{0} Y p \sigma^{2} Y Y = (Y_{1}, \cdots, Y_{n})","['statistics', 'probability-distributions', 'independence', 'signal-processing', 'correlation']"
49,Random walk with stopping time,Random walk with stopping time,,"$T_n=\Sigma_{j=1}^n Y_j$ is a symmetric simple random walk with $P(Y_j=1)=\frac{1}{2}, P(Y_j=-1)=\frac{1}{2}$ and $T_0=0$ . Define $M=\mbox{min}\{i:|T_i|=n\}$ . We are require to find $\mathbb{E}(M)$ and $\mathbb{E}(M^2)$ . My thought: We can have $\mathbb{E}(Y_j)=0$ and $\operatorname{Var}(Y_j) = 1$ . Also $\mathbb{E}(T_n)=0$ and $\operatorname{Var}(T_n)=n$ . But how to calculate $\mathbb{E}(M)$ and $\mathbb{E}(M^2)$ . Please help.",is a symmetric simple random walk with and . Define . We are require to find and . My thought: We can have and . Also and . But how to calculate and . Please help.,"T_n=\Sigma_{j=1}^n Y_j P(Y_j=1)=\frac{1}{2}, P(Y_j=-1)=\frac{1}{2} T_0=0 M=\mbox{min}\{i:|T_i|=n\} \mathbb{E}(M) \mathbb{E}(M^2) \mathbb{E}(Y_j)=0 \operatorname{Var}(Y_j) = 1 \mathbb{E}(T_n)=0 \operatorname{Var}(T_n)=n \mathbb{E}(M) \mathbb{E}(M^2)","['statistics', 'probability-distributions', 'markov-chains', 'random-walk', 'probability-limit-theorems']"
50,Provably Unwinnable Spider Games,Provably Unwinnable Spider Games,,"I would like to know what fraction of Spider Solitaire games (played with 104 cards and four suits) are provably unwinnable.  It seems various people have various ideas about what constitutes an unwinnable game, and so I will restrict my question to ""provably unwinnable"" games.  By ""provably unwinnable"" I mean that it can be demonstrated from logical argument that a game, or a class of games, is fundamentally unwinnable. I am (so far) aware of two classes of what I currently believe to be provably unwinnable games.  The wording of this last sentence was carefully chosen to convey the error bars that I assign to my present understanding. The ""No Possible Move"" Class: This is a class of games in which there are no moves at all, regardless of the skill of the player.  Two criteria must be satisfied for a game to fall into this class: 1) in each row of face-up dealt cards there must be no moves between the face-up dealt cards, and 2) there must be no moves that are enabled by picking up multiple cards.  An example will help to make this clear.  Consider the following game in which the cards denoted by ""X"" are dealt face-down and rows 7..11 are in the stock: Row  1 >>   X           X           X           X          Row  2 >>   X   X   X   X   X   X   X   X   X   X          Row  3 >>   X   X   X   X   X   X   X   X   X   X          Row  4 >>   X   X   X   X   X   X   X   X   X   X          Row  5 >>   X   X   X   X   X   X   X   X   X   X          Row  6 >>   AS  AS  3S  3S  5S  5S  7S  7S  9S  9S            Row  7 >>   AH  AH  3H  3H  5H  5H  7H  7H  9H  9H          Row  8 >>   AC  AC  3C  3C  5C  5C  7C  7C  9C  9C          Row  9 >>   AD  AD  3D  3D  5D  5D  7D  7D  9D  9D          Row 10 >>   2S  2S  4S  4S  6S  6S  8S  8S  10S 10S          Row 11 >>   2H  2H  4H  4H  6H  6H  8H  8H  10H 10H Such a game has no possible moves and is therefore provably unwinnable. The ""Wall of Death"" Class: This is a class of games in which all of the cards that would enable a lifting of a card are dealt face down and ""walled off"" by other cards that also cannot be lifted for the same reason.  I call this wall the Wall of Death . An example will be of benefit. Consider the following game in which rows 1..5 are dealt face down, ""Y"" denotes a card of arbitrary value and suit, and rows 7..11 are in the stock: Row  1 >>   Y           QC          Y           Y          Row  2 >>   Y   QS  Y   Y   Y   Y   4C  Y   4D  Y          Row  3 >>   4C  Y   Y   Y   QD  Y   Y   QS  QH  Y          Row  4 >>   Y   4D  Y   Y   Y   Y   4S  Y   Y   QD          Row  5 >>   QC  QH  4S  Y   Y   Y   4H  Y   4H  Y          Row  6 >>   JS  JS  3S  JD  3C  3H  JC  3D  3S  JH            Row  7 >>   Y   Y   Y   Y   Y   Y   Y   Y   Y   Y           Row  8 >>   Y   Y   Y   Y   Y   Y   Y   Y   Y   Y          Row  9 >>   Y   Y   Y   Y   Y   Y   Y   Y   Y   Y          Row 10 >>   Y   Y   Y   Y   Y   Y   Y   Y   Y   Y          Row 11 >>   Y   Y   Y   Y   Y   Y   Y   Y   Y   Y Row 6, composed solely of Jacks and 3's, is the Wall of Death .  None of the Jacks can ever be moved because all eight Queens are buried face down in rows 1..5 behind the Wall of Death . Similarly, none of the 3's can ever be moved because all eight 4's are buried behind the Wall of Death . In such a game all of the cards that comprise the Wall of Death can never be moved. Such a game is provably unwinnable.  Note that each column must contain a member of the Wall of Death but that the member of the Wall of Death need not be in row 6.  For instance, the Jack in column 4 of the above game could be relocated from row 6 to row 2: Row  1 >>   Y           QC          Y           Y          Row  2 >>   Y   QS  Y   JD   Y   Y   4C  Y   4D  Y          Row  3 >>   4C  Y   Y   Y   QD  Y   Y   QS  QH  Y          Row  4 >>   Y   4D  Y   Y   Y   Y   4S  Y   Y   QD          Row  5 >>   QC  QH  4S  Y   Y   Y   4H  Y   4H  Y          Row  6 >>   JS  JS  3S  Y   3C  3H  JC  3D  3S  JH            Row  7 >>   Y   Y   Y   Y   Y   Y   Y   Y   Y   Y           Row  8 >>   Y   Y   Y   Y   Y   Y   Y   Y   Y   Y          Row  9 >>   Y   Y   Y   Y   Y   Y   Y   Y   Y   Y          Row 10 >>   Y   Y   Y   Y   Y   Y   Y   Y   Y   Y          Row 11 >>   Y   Y   Y   Y   Y   Y   Y   Y   Y   Y and the game remains unwinnable. It is also possible for a King to be part of a Wall of Death , but the nature of what cards must be buried behind the wall is somewhat different.  An example will help to make this clear. Row  1 >>   Y           QC          3S          Y          Row  2 >>   Y   QS  Y   Y   Y   Y   4C  Y   4D  Y          Row  3 >>   4C  Y   Y   Y   QD  Y   Y   QS  QH  Y          Row  4 >>   Y   4D  Y   Y   Y   3S  4S  Y   Y   QD          Row  5 >>   QC  QH  4S  Y   Y   Y   4H  Y   4H  Y          Row  6 >>   JS  KS  3S  JD  3C  3H  JC  3D  3S  JH            Row  7 >>   Y   Y   Y   Y   Y   Y   Y   Y   Y   Y           Row  8 >>   Y   Y   Y   Y   Y   Y   Y   Y   Y   Y          Row  9 >>   Y   Y   Y   Y   Y   Y   Y   Y   Y   Y          Row 10 >>   Y   Y   Y   Y   Y   Y   Y   Y   Y   Y          Row 11 >>   Y   Y   Y   Y   Y   Y   Y   Y   Y   Y In this example I have inserted the King-of-Spades into row 6, column 2.  But note that I have also buried both of the Three-of-Spades behind the wall.  In doing so, I have created a situation in which the King-of-Spades can never be lifted because to do so would require completing a continuous series of Spades from the King-of-Spades down to the Ace-of-Spades, and such a continuous series cannot be constructed without a Three-of-Spades.  So to utilize a King as part of a Wall of Death one must bury at least one pair of value-equivalent cards of the same suit as the King behind the Wall of Death . Note also that a game may belong to both the No Possible Move class and the Wall of Death class. At this juncture I think it worthwhile to ask questions that are somewhat more refined than my original question. Q1: What fraction of games are in the No Possible Move class of games? Q2: What fraction of games are in the Wall of Death class of games? Q3: What fraction of games are in both the No Possible Move class and the Wall of Death class of games? Q4: Are there other classes of provably unwinnable games, and if so, what fraction of games are in those classes? Q5: Are there games that are unwinnable but not provably unwinnable? This needs some elaboration. Recall that my definition of provably unwinnable was that a game can be demonstrated unwinnable by means of logical argument. This question concerns whether there exist truly unwinnable games that cannot be proven to be unwinnable by means of logic.  Such games could in principle be proven unwinnable by a brute-force search of the entire tree of possible moves. I am interested in both analytic and numerical-simulation answers to these questions.  I have made a very crude estimate of the answer to Q1.  I estimate that roughly $1$ in $10^{13}$ games (give or take an order of magnitude) are in the No Possible Move class. I suspect (but do not know) that one could play 10 games of Spider per day for their entire life and never come upon a provably unwinnable game. The implication (of course) is that when you loose a game it is almost certainly because you gave up, not because the game was unwinnable. Note Added: A Spider-playing computer program ( plspider ) is reported to have a win rate of 99.994%, loosing just 2 out of 32,000 unique games that were tested.  This lends credence to the notion that provably unwinnable games are extremely rare. Of some interest is game #14934 - a game that the website author(s) says ""appears to be unwinnable."" Upon examination it can be readily discerned that game #14934 is neither a No Possible Move game or a Wall of Death game.  If it is truly unwinnable then either: 1) it is a member of a new class of provably unwinnable games, or 2) it proves the existence of unwinnable games that are not provably unwinnable games (except by brute-force searching of the entire tree of moves). Kudos to the author(s) of the website for their care in stating that the game ""appears"" to be unwinnable.","I would like to know what fraction of Spider Solitaire games (played with 104 cards and four suits) are provably unwinnable.  It seems various people have various ideas about what constitutes an unwinnable game, and so I will restrict my question to ""provably unwinnable"" games.  By ""provably unwinnable"" I mean that it can be demonstrated from logical argument that a game, or a class of games, is fundamentally unwinnable. I am (so far) aware of two classes of what I currently believe to be provably unwinnable games.  The wording of this last sentence was carefully chosen to convey the error bars that I assign to my present understanding. The ""No Possible Move"" Class: This is a class of games in which there are no moves at all, regardless of the skill of the player.  Two criteria must be satisfied for a game to fall into this class: 1) in each row of face-up dealt cards there must be no moves between the face-up dealt cards, and 2) there must be no moves that are enabled by picking up multiple cards.  An example will help to make this clear.  Consider the following game in which the cards denoted by ""X"" are dealt face-down and rows 7..11 are in the stock: Row  1 >>   X           X           X           X          Row  2 >>   X   X   X   X   X   X   X   X   X   X          Row  3 >>   X   X   X   X   X   X   X   X   X   X          Row  4 >>   X   X   X   X   X   X   X   X   X   X          Row  5 >>   X   X   X   X   X   X   X   X   X   X          Row  6 >>   AS  AS  3S  3S  5S  5S  7S  7S  9S  9S            Row  7 >>   AH  AH  3H  3H  5H  5H  7H  7H  9H  9H          Row  8 >>   AC  AC  3C  3C  5C  5C  7C  7C  9C  9C          Row  9 >>   AD  AD  3D  3D  5D  5D  7D  7D  9D  9D          Row 10 >>   2S  2S  4S  4S  6S  6S  8S  8S  10S 10S          Row 11 >>   2H  2H  4H  4H  6H  6H  8H  8H  10H 10H Such a game has no possible moves and is therefore provably unwinnable. The ""Wall of Death"" Class: This is a class of games in which all of the cards that would enable a lifting of a card are dealt face down and ""walled off"" by other cards that also cannot be lifted for the same reason.  I call this wall the Wall of Death . An example will be of benefit. Consider the following game in which rows 1..5 are dealt face down, ""Y"" denotes a card of arbitrary value and suit, and rows 7..11 are in the stock: Row  1 >>   Y           QC          Y           Y          Row  2 >>   Y   QS  Y   Y   Y   Y   4C  Y   4D  Y          Row  3 >>   4C  Y   Y   Y   QD  Y   Y   QS  QH  Y          Row  4 >>   Y   4D  Y   Y   Y   Y   4S  Y   Y   QD          Row  5 >>   QC  QH  4S  Y   Y   Y   4H  Y   4H  Y          Row  6 >>   JS  JS  3S  JD  3C  3H  JC  3D  3S  JH            Row  7 >>   Y   Y   Y   Y   Y   Y   Y   Y   Y   Y           Row  8 >>   Y   Y   Y   Y   Y   Y   Y   Y   Y   Y          Row  9 >>   Y   Y   Y   Y   Y   Y   Y   Y   Y   Y          Row 10 >>   Y   Y   Y   Y   Y   Y   Y   Y   Y   Y          Row 11 >>   Y   Y   Y   Y   Y   Y   Y   Y   Y   Y Row 6, composed solely of Jacks and 3's, is the Wall of Death .  None of the Jacks can ever be moved because all eight Queens are buried face down in rows 1..5 behind the Wall of Death . Similarly, none of the 3's can ever be moved because all eight 4's are buried behind the Wall of Death . In such a game all of the cards that comprise the Wall of Death can never be moved. Such a game is provably unwinnable.  Note that each column must contain a member of the Wall of Death but that the member of the Wall of Death need not be in row 6.  For instance, the Jack in column 4 of the above game could be relocated from row 6 to row 2: Row  1 >>   Y           QC          Y           Y          Row  2 >>   Y   QS  Y   JD   Y   Y   4C  Y   4D  Y          Row  3 >>   4C  Y   Y   Y   QD  Y   Y   QS  QH  Y          Row  4 >>   Y   4D  Y   Y   Y   Y   4S  Y   Y   QD          Row  5 >>   QC  QH  4S  Y   Y   Y   4H  Y   4H  Y          Row  6 >>   JS  JS  3S  Y   3C  3H  JC  3D  3S  JH            Row  7 >>   Y   Y   Y   Y   Y   Y   Y   Y   Y   Y           Row  8 >>   Y   Y   Y   Y   Y   Y   Y   Y   Y   Y          Row  9 >>   Y   Y   Y   Y   Y   Y   Y   Y   Y   Y          Row 10 >>   Y   Y   Y   Y   Y   Y   Y   Y   Y   Y          Row 11 >>   Y   Y   Y   Y   Y   Y   Y   Y   Y   Y and the game remains unwinnable. It is also possible for a King to be part of a Wall of Death , but the nature of what cards must be buried behind the wall is somewhat different.  An example will help to make this clear. Row  1 >>   Y           QC          3S          Y          Row  2 >>   Y   QS  Y   Y   Y   Y   4C  Y   4D  Y          Row  3 >>   4C  Y   Y   Y   QD  Y   Y   QS  QH  Y          Row  4 >>   Y   4D  Y   Y   Y   3S  4S  Y   Y   QD          Row  5 >>   QC  QH  4S  Y   Y   Y   4H  Y   4H  Y          Row  6 >>   JS  KS  3S  JD  3C  3H  JC  3D  3S  JH            Row  7 >>   Y   Y   Y   Y   Y   Y   Y   Y   Y   Y           Row  8 >>   Y   Y   Y   Y   Y   Y   Y   Y   Y   Y          Row  9 >>   Y   Y   Y   Y   Y   Y   Y   Y   Y   Y          Row 10 >>   Y   Y   Y   Y   Y   Y   Y   Y   Y   Y          Row 11 >>   Y   Y   Y   Y   Y   Y   Y   Y   Y   Y In this example I have inserted the King-of-Spades into row 6, column 2.  But note that I have also buried both of the Three-of-Spades behind the wall.  In doing so, I have created a situation in which the King-of-Spades can never be lifted because to do so would require completing a continuous series of Spades from the King-of-Spades down to the Ace-of-Spades, and such a continuous series cannot be constructed without a Three-of-Spades.  So to utilize a King as part of a Wall of Death one must bury at least one pair of value-equivalent cards of the same suit as the King behind the Wall of Death . Note also that a game may belong to both the No Possible Move class and the Wall of Death class. At this juncture I think it worthwhile to ask questions that are somewhat more refined than my original question. Q1: What fraction of games are in the No Possible Move class of games? Q2: What fraction of games are in the Wall of Death class of games? Q3: What fraction of games are in both the No Possible Move class and the Wall of Death class of games? Q4: Are there other classes of provably unwinnable games, and if so, what fraction of games are in those classes? Q5: Are there games that are unwinnable but not provably unwinnable? This needs some elaboration. Recall that my definition of provably unwinnable was that a game can be demonstrated unwinnable by means of logical argument. This question concerns whether there exist truly unwinnable games that cannot be proven to be unwinnable by means of logic.  Such games could in principle be proven unwinnable by a brute-force search of the entire tree of possible moves. I am interested in both analytic and numerical-simulation answers to these questions.  I have made a very crude estimate of the answer to Q1.  I estimate that roughly in games (give or take an order of magnitude) are in the No Possible Move class. I suspect (but do not know) that one could play 10 games of Spider per day for their entire life and never come upon a provably unwinnable game. The implication (of course) is that when you loose a game it is almost certainly because you gave up, not because the game was unwinnable. Note Added: A Spider-playing computer program ( plspider ) is reported to have a win rate of 99.994%, loosing just 2 out of 32,000 unique games that were tested.  This lends credence to the notion that provably unwinnable games are extremely rare. Of some interest is game #14934 - a game that the website author(s) says ""appears to be unwinnable."" Upon examination it can be readily discerned that game #14934 is neither a No Possible Move game or a Wall of Death game.  If it is truly unwinnable then either: 1) it is a member of a new class of provably unwinnable games, or 2) it proves the existence of unwinnable games that are not provably unwinnable games (except by brute-force searching of the entire tree of moves). Kudos to the author(s) of the website for their care in stating that the game ""appears"" to be unwinnable.",1 10^{13},"['probability', 'combinatorics', 'statistics', 'card-games']"
51,How to derive the decomposition of the MSE of a Rao-Blackwellized estimator?,How to derive the decomposition of the MSE of a Rao-Blackwellized estimator?,,"In the Wikipedia article for the Rao-Blackwell theorem , the following step is used in the proof, namely a decomposition of the Rao-Blackwellized estimator's decomposition: $$\mathbb{E}[(\delta_1(X) - \theta)^2] = \mathbb{E}[(\delta(X) - \theta)^2] - \mathbb{E}[\text{Var}(\delta(X) | T(X))]$$ I'm aware there's other questions regarding proofs of the Rao-Blackwell theorem, but none seem to be about this specific step. I've tried replacing $\delta_1$ with its expression in terms of $\delta$ and expanding the square to no avail...","In the Wikipedia article for the Rao-Blackwell theorem , the following step is used in the proof, namely a decomposition of the Rao-Blackwellized estimator's decomposition: I'm aware there's other questions regarding proofs of the Rao-Blackwell theorem, but none seem to be about this specific step. I've tried replacing with its expression in terms of and expanding the square to no avail...",\mathbb{E}[(\delta_1(X) - \theta)^2] = \mathbb{E}[(\delta(X) - \theta)^2] - \mathbb{E}[\text{Var}(\delta(X) | T(X))] \delta_1 \delta,"['probability', 'statistics', 'estimation']"
52,Prove Wold's theorem from abstract Wold's decomposition,Prove Wold's theorem from abstract Wold's decomposition,,"I see that Wold's theorem in time series analysis is proven by the abstract Wold's decomposition in operator theory. The abstract theorem states that: Every isometry is a direct sum of copies of the unilateral shift and a unitary operator. I want to understand intuitively the connection between the two theorems: so in the time series version $Y_t = \sum_{j=0}^\infty b_j \epsilon_{t-j} + \eta_t$ , which are the isometry, the shift and the unitary operator? PS: I see in some document which states the lag operator is the isometry, then which is the shift operator in the time series version?","I see that Wold's theorem in time series analysis is proven by the abstract Wold's decomposition in operator theory. The abstract theorem states that: Every isometry is a direct sum of copies of the unilateral shift and a unitary operator. I want to understand intuitively the connection between the two theorems: so in the time series version , which are the isometry, the shift and the unitary operator? PS: I see in some document which states the lag operator is the isometry, then which is the shift operator in the time series version?",Y_t = \sum_{j=0}^\infty b_j \epsilon_{t-j} + \eta_t,"['functional-analysis', 'statistics', 'operator-theory', 'operator-algebras', 'time-series']"
53,Cramer rao low bound of uniform distribution,Cramer rao low bound of uniform distribution,,"I was given a task to show empirically that the scattering holds up Cramer rao low bound. At first I had to calculate the estimator $ T' = E(2X_1\mid \max X_i)$ which is equal to $=\frac{n+1}{n} \max X_i$ Then I was need to run a sample in R with some parameters. Here is my code: theta = 5 n = 1000 error1 = c() error2 = c()  for (i in 1:15){   U = runif(n, min=0, max = 5)   T_1 = 2*U[1]   T_2 = ((n+1)/n)*max(U)   error1 = c(error1, (T_1-theta)^2)   error2 = c(error2, (T_2-theta)^2)    } Ok, now for Cramer rao low bound I have to calculate $\frac{1}{I(\theta)}$ but there is no Fisher information for $U\sim[0,\theta]$ So, how can I show empirically (in R) that Cramer rao low bound hold here?","I was given a task to show empirically that the scattering holds up Cramer rao low bound. At first I had to calculate the estimator which is equal to Then I was need to run a sample in R with some parameters. Here is my code: theta = 5 n = 1000 error1 = c() error2 = c()  for (i in 1:15){   U = runif(n, min=0, max = 5)   T_1 = 2*U[1]   T_2 = ((n+1)/n)*max(U)   error1 = c(error1, (T_1-theta)^2)   error2 = c(error2, (T_2-theta)^2)    } Ok, now for Cramer rao low bound I have to calculate but there is no Fisher information for So, how can I show empirically (in R) that Cramer rao low bound hold here?"," T' = E(2X_1\mid \max X_i) =\frac{n+1}{n} \max X_i \frac{1}{I(\theta)} U\sim[0,\theta]","['statistics', 'statistical-inference', 'uniform-distribution', 'estimation']"
54,Complete statistic for beta distribution,Complete statistic for beta distribution,,"Let $X_1, ..., X_n$ identical independent variables that follows a beta distribution $\text{Beta}(\theta,1)$ Is $S = \sum_{i=1}^{n}X_i$ a complete statistic for $\theta$ ? I have proved that the sum is not a sufficient statistic for $\theta$ but I'm having a difficult time about completeness. If the statistic is not complete, then I need to find a function $g$ such that $E[g(S)] = 0 $ implies $g(S) = 0$ almost surely for every $\theta$ . Unfortunately I have not been able to find such function. I would really appreciate any hints or sugestions with this problem","Let identical independent variables that follows a beta distribution Is a complete statistic for ? I have proved that the sum is not a sufficient statistic for but I'm having a difficult time about completeness. If the statistic is not complete, then I need to find a function such that implies almost surely for every . Unfortunately I have not been able to find such function. I would really appreciate any hints or sugestions with this problem","X_1, ..., X_n \text{Beta}(\theta,1) S = \sum_{i=1}^{n}X_i \theta \theta g E[g(S)] = 0  g(S) = 0 \theta","['probability', 'statistics', 'probability-distributions', 'statistical-inference', 'estimation']"
55,Has anyone studied the quasimetric induced by the KL divergence?,Has anyone studied the quasimetric induced by the KL divergence?,,"Recall that, for probability measures $p$ and $q$ on a finite set $X$ , the Kullback-Leibler divergence $$ D(p||q) = \sum_{x\in X} p(x) \log \dfrac{p(x)}{q(x)} $$ is famously not a metric, in particular it does not satisfy a triangle inequality. However, in principle one could look at the following quantity $$ d(p,q) := \inf_{n\in \Bbb{N}} \inf_{p_1,\dots,p_n} \Big( d(p,p_1) + d(p_1,p_2) + \dots + d(p_n, q) \Big) , $$ which does satisfy the triangle inequality, it is the largest quasimetric which is less or equal than $D(p||q)$ . Has this quantity been studied anywhere? Is it trivial (i.e. zero)?","Recall that, for probability measures and on a finite set , the Kullback-Leibler divergence is famously not a metric, in particular it does not satisfy a triangle inequality. However, in principle one could look at the following quantity which does satisfy the triangle inequality, it is the largest quasimetric which is less or equal than . Has this quantity been studied anywhere? Is it trivial (i.e. zero)?","p q X 
D(p||q) = \sum_{x\in X} p(x) \log \dfrac{p(x)}{q(x)}
 
d(p,q) := \inf_{n\in \Bbb{N}} \inf_{p_1,\dots,p_n} \Big( d(p,p_1) + d(p_1,p_2) + \dots + d(p_n, q) \Big) ,
 D(p||q)","['probability', 'statistics', 'metric-spaces', 'information-theory', 'information-geometry']"
56,Prove $C(X^\mathrm{T}X+C^\mathrm{T}C)^{-1}C^\mathrm{T}= I$ [closed],Prove  [closed],C(X^\mathrm{T}X+C^\mathrm{T}C)^{-1}C^\mathrm{T}= I,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question Consider the linear model $Y = X \beta + \epsilon$ , where $\beta \in \Bbb R^{p}$ . Suppose that $r := \mbox{rank}(X) < p $ and let $C \in \Bbb R^{m\times p}$ be a matrix satisfying the condition $\mbox{rank}(C) = p-r$ , $\mathcal{R}(X^\mathrm{T})\cap \mathcal{R}(C^\mathrm{T})=\{0\}$ . then $$(X^\mathrm{T}X+C^\mathrm{T}C)^{-1} \text{ is a generalized inverse of } C^\mathrm{T}C \tag{a}$$ $$C(X^\mathrm{T}X+C^\mathrm{T}C)^{-1}C^\mathrm{T}=I \tag{b}$$ I think one can be obtained by another, since if $C(X^\mathrm{T}X+C^\mathrm{T}C)^{-1}C^\mathrm{T}=I$ , then $C^\mathrm{T}C(X^\mathrm{T}X+C^\mathrm{T}C)^{-1}C^\mathrm{T}=C^\mathrm{T}I$ , which implies $$C^\mathrm{T}C(X^\mathrm{T}X+C^\mathrm{T}C)^{-1}C^\mathrm{T}C=C^\mathrm{T}IC=C^\mathrm{T}C,$$ Hence we prove the (a). now I am not sure how to prove (b), thank you for help me to figure it out.","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question Consider the linear model , where . Suppose that and let be a matrix satisfying the condition , . then I think one can be obtained by another, since if , then , which implies Hence we prove the (a). now I am not sure how to prove (b), thank you for help me to figure it out.","Y = X \beta + \epsilon \beta \in \Bbb R^{p} r := \mbox{rank}(X) < p  C \in \Bbb R^{m\times p} \mbox{rank}(C) = p-r \mathcal{R}(X^\mathrm{T})\cap \mathcal{R}(C^\mathrm{T})=\{0\} (X^\mathrm{T}X+C^\mathrm{T}C)^{-1} \text{ is a generalized inverse of } C^\mathrm{T}C \tag{a} C(X^\mathrm{T}X+C^\mathrm{T}C)^{-1}C^\mathrm{T}=I \tag{b} C(X^\mathrm{T}X+C^\mathrm{T}C)^{-1}C^\mathrm{T}=I C^\mathrm{T}C(X^\mathrm{T}X+C^\mathrm{T}C)^{-1}C^\mathrm{T}=C^\mathrm{T}I C^\mathrm{T}C(X^\mathrm{T}X+C^\mathrm{T}C)^{-1}C^\mathrm{T}C=C^\mathrm{T}IC=C^\mathrm{T}C,","['linear-algebra', 'statistics', 'statistical-inference']"
57,"Poisson Process with $\lambda = 3$, suppose $6$ cars arrive after $2$ hours, what is the probability only $1$ arrived in the first hour?","Poisson Process with , suppose  cars arrive after  hours, what is the probability only  arrived in the first hour?",\lambda = 3 6 2 1,"Suppose the number of cars arriving at a gas station per hour follows a Poisson Process with $\lambda = 3$ , Suppose $6$ cars arrive after $2$ hours, what is the probability only $1$ arrived in the first hour? So I know that $P(X_t=k)=e^{\lambda t}\frac{(\lambda t)^k}{k!}$ represents the probability the process is at k at time t. So because the states are independent, I should just have the $P(X_1=1)P(X_1=5)$ ? Since the probability of $5$ cars arriving in the 2nd hour should be the same as the probability $5$ arrive in the first hour? Which gives me $P(X_1=1)P(X_1=5)=(3e^3)(\frac{3^5e^3}{5!})$ ? Or does independence mean knowing the total after $2$ hours doesn't matter? And I only need to compute $P(X_1=1)$","Suppose the number of cars arriving at a gas station per hour follows a Poisson Process with , Suppose cars arrive after hours, what is the probability only arrived in the first hour? So I know that represents the probability the process is at k at time t. So because the states are independent, I should just have the ? Since the probability of cars arriving in the 2nd hour should be the same as the probability arrive in the first hour? Which gives me ? Or does independence mean knowing the total after hours doesn't matter? And I only need to compute",\lambda = 3 6 2 1 P(X_t=k)=e^{\lambda t}\frac{(\lambda t)^k}{k!} P(X_1=1)P(X_1=5) 5 5 P(X_1=1)P(X_1=5)=(3e^3)(\frac{3^5e^3}{5!}) 2 P(X_1=1),"['statistics', 'poisson-process']"
58,Prediction interval method explanation,Prediction interval method explanation,,"For making prediction intervals, the book ( Applied statistics and probability for engineers by montgomery and runger 5th edition ) creates a new random variable called prediction error and based on that (after translation and scaling to standard $T$ ) it creates a PI for $X_{n+1}$ . My question is this: Why not use $\overline{X}$ as an estimate for mean of $X_{n+1}$ and use sample standard dev as estimate for std of $X_{n+1}$ and basically create a PI based on that like we do for confidence interval. Why use prediction error? What is wrong with my method? Thank you","For making prediction intervals, the book ( Applied statistics and probability for engineers by montgomery and runger 5th edition ) creates a new random variable called prediction error and based on that (after translation and scaling to standard ) it creates a PI for . My question is this: Why not use as an estimate for mean of and use sample standard dev as estimate for std of and basically create a PI based on that like we do for confidence interval. Why use prediction error? What is wrong with my method? Thank you",T X_{n+1} \overline{X} X_{n+1} X_{n+1},"['statistics', 'normal-distribution', 'confidence-interval']"
59,How to derive the distribution of the uncertainty of the measurement of vector's components from the distribution of the uncertainty of its modulus?,How to derive the distribution of the uncertainty of the measurement of vector's components from the distribution of the uncertainty of its modulus?,,"Consider a real vector $$ \mathbf{p} = (p_{x},p_{y},p_{z}) $$ representing some observable. Its measurement allows determining the modulus $p\equiv \sqrt{p_{x}^{2}+p_{y}^{2}+p_{z}^{2}}$ only up to some uncertainty $\Delta p$ , i.e. what we measure is $$ P = p+ \Delta p, $$ The probability distribution for $\Delta p$ is the Gauss distribution that has $p$ -dependent sigma: $$ f(\Delta p) = \frac{1}{\sqrt{2\pi}\sigma(p)}\exp\left[-\frac{1}{2}\left(\frac{\Delta p}{\sigma(p)}\right)^{2} \right] \tag 1 $$ Let us assume that the uncertainty is non-zero only for $p_{x}$ and $p_{y}$ , i.e., $$ \mathbf{P} = (p_{x}+\Delta p_{x}, p_{y}+\Delta p_{y},p_{z}) \Rightarrow P = p+\Delta p $$ Then, my question is: how to find the distribution corresponding to the uncertainties $\Delta p_{x}$ and $\Delta p_{y}$ if knowing the distribution corresponding to the uncertainty $\Delta p$ ? P.S. $\sigma(p)$ has the property $\sigma(p)\ll p$ . Another property is that $\Delta p_{x}$ , $\Delta p_{y}$ are distributed identically.","Consider a real vector representing some observable. Its measurement allows determining the modulus only up to some uncertainty , i.e. what we measure is The probability distribution for is the Gauss distribution that has -dependent sigma: Let us assume that the uncertainty is non-zero only for and , i.e., Then, my question is: how to find the distribution corresponding to the uncertainties and if knowing the distribution corresponding to the uncertainty ? P.S. has the property . Another property is that , are distributed identically.","
\mathbf{p} = (p_{x},p_{y},p_{z})
 p\equiv \sqrt{p_{x}^{2}+p_{y}^{2}+p_{z}^{2}} \Delta p 
P = p+ \Delta p,
 \Delta p p 
f(\Delta p) = \frac{1}{\sqrt{2\pi}\sigma(p)}\exp\left[-\frac{1}{2}\left(\frac{\Delta p}{\sigma(p)}\right)^{2} \right]
\tag 1
 p_{x} p_{y} 
\mathbf{P} = (p_{x}+\Delta p_{x}, p_{y}+\Delta p_{y},p_{z}) \Rightarrow P = p+\Delta p
 \Delta p_{x} \Delta p_{y} \Delta p \sigma(p) \sigma(p)\ll p \Delta p_{x} \Delta p_{y}","['statistics', 'probability-distributions']"
60,Unbiased estimator of $1/(1-a)$ when random variables are Poisson(a),Unbiased estimator of  when random variables are Poisson(a),1/(1-a),"Let $X_1,...,X_n$ be Poisson with parameter $a$ . I am looking for a unbiased estimator of $h(a)=\frac{1}{1-a}$ Let $T$ be a statistic and $g(t)$ be it's pmf. Then if we have $E(T)= h(a)$ then $T$ is unbiased for $h$ . So we must have $$\frac{e^a}{1-a}= \sum _k \frac{g(k)a^k}{k!} $$ If $ 0<a<1 $ we can expand left hand side and get the values of $ g(k) $ by equating corresponding coefficients. But in this case I'm not able to get the estimator. I am also having difficulty to figure out what to do if $ a>1 $ Any help is appreciated ☺️",Let be Poisson with parameter . I am looking for a unbiased estimator of Let be a statistic and be it's pmf. Then if we have then is unbiased for . So we must have If we can expand left hand side and get the values of by equating corresponding coefficients. But in this case I'm not able to get the estimator. I am also having difficulty to figure out what to do if Any help is appreciated ☺️,"X_1,...,X_n a h(a)=\frac{1}{1-a} T g(t) E(T)= h(a) T h \frac{e^a}{1-a}= \sum _k \frac{g(k)a^k}{k!}   0<a<1   g(k)   a>1 ","['statistics', 'poisson-distribution', 'estimation']"
61,Xi are i.n.i.d bounded rv show a central limit exists,Xi are i.n.i.d bounded rv show a central limit exists,,"We are asked to show if $X_i$ are independent but not i.d. and where $X_i$ are all bounded with $S_n = \sum_n X_i$ and $s^2_n = Var(S_n)$ with $s^2_n \to \inf$ then $\frac{S_n}{s_n}$ has a central limit thus converging in distribution to $N(0,1)$ . I'm trying this with either Lindeburg or Lyapunov with the following statement: if $X_i$ are bounded then $|X_i| <= M$ for some M and thus $X^2$ is bounded too by $M^2$ .  The Lindeburg condition is: $\lim_{n \to \inf}$ $\frac{1}{s^2_n}\sum_n$ $\int_{|X_i| \gt \epsilon*s_n} X^2_i dP$ Since the $X^2_i$ are bounded then they can be taken out of the integral and thus the sum becomes a sum of constants divided by inf $\to$ 0 and thus the Lindeburg condition holds which means a central limit exists.",We are asked to show if are independent but not i.d. and where are all bounded with and with then has a central limit thus converging in distribution to . I'm trying this with either Lindeburg or Lyapunov with the following statement: if are bounded then for some M and thus is bounded too by .  The Lindeburg condition is: Since the are bounded then they can be taken out of the integral and thus the sum becomes a sum of constants divided by inf 0 and thus the Lindeburg condition holds which means a central limit exists.,"X_i X_i S_n = \sum_n X_i s^2_n = Var(S_n) s^2_n \to \inf \frac{S_n}{s_n} N(0,1) X_i |X_i| <= M X^2 M^2 \lim_{n \to \inf} \frac{1}{s^2_n}\sum_n \int_{|X_i| \gt \epsilon*s_n} X^2_i dP X^2_i \to","['probability-theory', 'statistics', 'central-limit-theorem']"
62,What is the logic behind the use of the harmonic mean?,What is the logic behind the use of the harmonic mean?,,"I'm a self-taught student in mathematics, and I only began self-study about half a year ago. I was thinking about the harmonic mean, and the logic behind its use. Firstly, let's begin with the arithmetic mean which equals the sum of the set of numbers divided by the number of numbers. For example: say you have a set $(4, 3, 2)$ , and you want the mean. You simply divide: $\frac{4+3+2}{3}$ . You get 3 in this case. Thus, in a way, the logic behind is to generalize it. It's to take all of the numbers, and distribute them equally to these 3 ""slots"" if that make sense. In doing this, you ""generalize"" all the numbers to one single number if that makes sense. The geometric mean is easy to understand too. Imagine you have a set of numbers which are constantly being multiplied. Say you have a set whose first number is multiplied by 1.3, 1.2, and 1.5. So, starting with 4: $(4, 8, 12, 36)$ . We can ""generalize"" this as we did with the arithmetic mean, because: $4*8*12*36=x^4$ . So, we can ""generalize"" those numbers to the variable x like we did with the arithmetic mean. In the words of a Stackoverflow user by the name of Domagoj Pandzha (who I thank for allowing me to rationalize the geometric mean): ""We are, essentially looking for a value which, when multiplied by itself 3 times (the number of percentages per respective years), gives the same final value as if we simply repeatedly multiplied each year with the respective 1.3, 1.4 and 1.5."" So, $\sqrt[4]{x^4}$ = $\sqrt[4]{4*8*12*36}$ Makes sense to me to use it, since we're trying to average out the products here. But the harmonic mean I struggle with in my mind. What is the logic behind its use? Thanks.","I'm a self-taught student in mathematics, and I only began self-study about half a year ago. I was thinking about the harmonic mean, and the logic behind its use. Firstly, let's begin with the arithmetic mean which equals the sum of the set of numbers divided by the number of numbers. For example: say you have a set , and you want the mean. You simply divide: . You get 3 in this case. Thus, in a way, the logic behind is to generalize it. It's to take all of the numbers, and distribute them equally to these 3 ""slots"" if that make sense. In doing this, you ""generalize"" all the numbers to one single number if that makes sense. The geometric mean is easy to understand too. Imagine you have a set of numbers which are constantly being multiplied. Say you have a set whose first number is multiplied by 1.3, 1.2, and 1.5. So, starting with 4: . We can ""generalize"" this as we did with the arithmetic mean, because: . So, we can ""generalize"" those numbers to the variable x like we did with the arithmetic mean. In the words of a Stackoverflow user by the name of Domagoj Pandzha (who I thank for allowing me to rationalize the geometric mean): ""We are, essentially looking for a value which, when multiplied by itself 3 times (the number of percentages per respective years), gives the same final value as if we simply repeatedly multiplied each year with the respective 1.3, 1.4 and 1.5."" So, = Makes sense to me to use it, since we're trying to average out the products here. But the harmonic mean I struggle with in my mind. What is the logic behind its use? Thanks.","(4, 3, 2) \frac{4+3+2}{3} (4, 8, 12, 36) 4*8*12*36=x^4 \sqrt[4]{x^4} \sqrt[4]{4*8*12*36}","['algebra-precalculus', 'statistics']"
63,Expectation of inverse of sum of iid random variables,Expectation of inverse of sum of iid random variables,,"Description: There is an indicator function called $I_{i}^{k}$ as follows: \begin{align*}  \begin{split}  I_{i}^{k}= \left\{  \begin{array}{lr}  1, \; {\rm if \; the  \; event \;  happened\; at\; time \;k\; for\; player\; i;}\\  0, \; {\rm if  \; not.}  \end{array}  \right.  \end{split}		  \end{align*} The event happened at least once, so $\mathbb{E}[I_{i}^{k}]=p_{i}>0$ .  Besides,  the indicators $I_{i}^{k}, \left\lbrace i=1,\dots N \right\rbrace $ are independent and identically distributed (i.i.d.) with a fixed distribution across time steps. Now, we Let $\Gamma_{i}^{k}=\sum_{t=1}^{k}I_{i}^{t}$ and $\gamma_{i,k}={1}/{(\Gamma_{i}^{k})^{a}}$ , $a\in (1/2, 1]$ for all $i$ and $k\geq 1$ . Can we give the upper bound of the following? \begin{align*} (a) \sum_{k=1}^{K}\mathbb{E}\left[ \gamma_{i,k}^{2}\right] \leq ?   \quad\quad   (b) \sum_{k=1}^{K}\mathbb{E}\left[ \left|  \gamma_{i,k}-\frac{1}{k^{a}p_{i}^{a}} \right| \right]  \leq ? \end{align*} where $K$ is some constant. PS: I think maybe it can be proved by Taylor expansion , but I don't know how to calculate it, maybe the following link is useful: https://stats.stackexchange.com/questions/399261/expectation-of-inverse-of-sum-of-positive-iid-variables/399289#399289","Description: There is an indicator function called as follows: The event happened at least once, so .  Besides,  the indicators are independent and identically distributed (i.i.d.) with a fixed distribution across time steps. Now, we Let and , for all and . Can we give the upper bound of the following? where is some constant. PS: I think maybe it can be proved by Taylor expansion , but I don't know how to calculate it, maybe the following link is useful: https://stats.stackexchange.com/questions/399261/expectation-of-inverse-of-sum-of-positive-iid-variables/399289#399289","I_{i}^{k} \begin{align*}
 \begin{split}
 I_{i}^{k}= \left\{
 \begin{array}{lr}
 1, \; {\rm if \; the  \; event \;  happened\; at\; time \;k\; for\; player\; i;}\\
 0, \; {\rm if  \; not.}
 \end{array}
 \right.
 \end{split}		
 \end{align*} \mathbb{E}[I_{i}^{k}]=p_{i}>0 I_{i}^{k}, \left\lbrace i=1,\dots N \right\rbrace  \Gamma_{i}^{k}=\sum_{t=1}^{k}I_{i}^{t} \gamma_{i,k}={1}/{(\Gamma_{i}^{k})^{a}} a\in (1/2, 1] i k\geq 1 \begin{align*}
(a) \sum_{k=1}^{K}\mathbb{E}\left[ \gamma_{i,k}^{2}\right] \leq ?   \quad\quad  
(b) \sum_{k=1}^{K}\mathbb{E}\left[ \left| 
\gamma_{i,k}-\frac{1}{k^{a}p_{i}^{a}} \right| \right] 
\leq ?
\end{align*} K","['probability', 'statistics', 'expected-value', 'inverse', 'distribution-tails']"
64,How does Wikipedia derive the formula for the Asymptotic Mean Integrated Square Error (AMISE)?,How does Wikipedia derive the formula for the Asymptotic Mean Integrated Square Error (AMISE)?,,"In this Wikipedia article they show that the Mean Integrated Square Error (MISE) is given by $$\mathrm{MISE}(h)=\mathrm{E}\left[\int(\hat{f}_h(x)-f(x))^2dx\right],$$ where $f(x)$ is the real density function, $\hat{f}_h(x)$ is the estimate given by $$\hat{f}_h(x)=\frac{1}{nh}\sum_{i=1}^nK\left(\frac{x-x_i}{h}\right),$$ $K$ is the kernel, $x_i$ are sample points, $n$ is the number of samples and $h$ is the bandwidth. They then show that the Asymptotic MISE (AMISE) is given by $$\mathrm{AMISE}(h)=\frac{R(K)}{nh}+\frac{1}{4}m_2(K)^2h^4R(f''),$$ where $$R(g)=\int g(x)^2dx,$$ for a function $g(x)$ , $$m_2(K)=\int x^2K(x)dx$$ and $f''(x)$ is the second derivative of $f(x)$ . My question is how is the formula for $\mathrm{AMISE}$ derived? I understand terms of of order $o\left(\frac{1}{nh} + h^4\right)$ are neglected. But other than that I cannot see how this formula is derived.","In this Wikipedia article they show that the Mean Integrated Square Error (MISE) is given by where is the real density function, is the estimate given by is the kernel, are sample points, is the number of samples and is the bandwidth. They then show that the Asymptotic MISE (AMISE) is given by where for a function , and is the second derivative of . My question is how is the formula for derived? I understand terms of of order are neglected. But other than that I cannot see how this formula is derived.","\mathrm{MISE}(h)=\mathrm{E}\left[\int(\hat{f}_h(x)-f(x))^2dx\right], f(x) \hat{f}_h(x) \hat{f}_h(x)=\frac{1}{nh}\sum_{i=1}^nK\left(\frac{x-x_i}{h}\right), K x_i n h \mathrm{AMISE}(h)=\frac{R(K)}{nh}+\frac{1}{4}m_2(K)^2h^4R(f''), R(g)=\int g(x)^2dx, g(x) m_2(K)=\int x^2K(x)dx f''(x) f(x) \mathrm{AMISE} o\left(\frac{1}{nh} + h^4\right)","['calculus', 'statistics', 'asymptotics', 'mean-square-error']"
65,How to solve for the value of a discrete random variable without brute force? (Poisson Distribution),How to solve for the value of a discrete random variable without brute force? (Poisson Distribution),,"Say I had a question like so: $X$ ~ $Po(3.1)$ Given $P(X < a) = 0.8$ (1 s.f) Solve for $a$ I can brute force it by summing the value of the probability mass function at $X=0$ , $X=1$ , $X=2$ etc. up until I reach the probability of $0.8$ If I do that, then I get: $a = 5$ $$ \sum_{k=0}^{4} [\frac{e^{-3.1} \cdot 3.1^{k}}{k!}] = 0.7981... $$ $ = 0.8$ (1 s.f) so I get $P(X < 5) = 0.8$ thus $a=5$ My question is: is there a cleaner and non-brute-force method of solving for this?","Say I had a question like so: ~ Given (1 s.f) Solve for I can brute force it by summing the value of the probability mass function at , , etc. up until I reach the probability of If I do that, then I get: (1 s.f) so I get thus My question is: is there a cleaner and non-brute-force method of solving for this?",X Po(3.1) P(X < a) = 0.8 a X=0 X=1 X=2 0.8 a = 5  \sum_{k=0}^{4} [\frac{e^{-3.1} \cdot 3.1^{k}}{k!}] = 0.7981...   = 0.8 P(X < 5) = 0.8 a=5,"['statistics', 'poisson-distribution']"
66,"Joint Pdf Of (min(x1,x2),min(x2,x3))","Joint Pdf Of (min(x1,x2),min(x2,x3))",,"hello everyone i need help to find the JPDF of (min(x1,x2),min(x2,x3)) where x_{1},x2,x3 are independent weibull distribution. my attempt P(min(x1,x2)≤y1 , min(x2,x3)≤y2 , x1<x2) =P(x2≤y1 ,min(x2,x3)≤y2 , x1<x2)+P(x1≤y1 ,min(x2,x3)≤y2 , x1<x2) since x1, x2 and x3 are independent P(x1≤y1 ,min(x2,x3)≤y2 , x1<x2)=P(x1≤y1) P(min(x2,x3)≤y2 , x1<x2)) my problem is how to find P(x2≤y1 ,min(x2,x3)≤y2 , x1<x2)?","hello everyone i need help to find the JPDF of (min(x1,x2),min(x2,x3)) where x_{1},x2,x3 are independent weibull distribution. my attempt P(min(x1,x2)≤y1 , min(x2,x3)≤y2 , x1<x2) =P(x2≤y1 ,min(x2,x3)≤y2 , x1<x2)+P(x1≤y1 ,min(x2,x3)≤y2 , x1<x2) since x1, x2 and x3 are independent P(x1≤y1 ,min(x2,x3)≤y2 , x1<x2)=P(x1≤y1) P(min(x2,x3)≤y2 , x1<x2)) my problem is how to find P(x2≤y1 ,min(x2,x3)≤y2 , x1<x2)?",,"['probability-theory', 'statistics']"
67,Confused about the relationship between PCA and robust PCA,Confused about the relationship between PCA and robust PCA,,"I recently learned about PCA and robust PCA. I understand that PCA is identifying the principal components by finding the eigenvectors of the covariance matrix (which of course contains information about the ""directionality"" of the data). These principal components are then used to transform the data so that it is reoriented along the principal components (lets call this reoriented data matrix $D$ ). I also understand that robust-PCA can be written as a convex relaxation problem whereby solving it - using Lagrangian methods - yields a low rank matrix $L$ and a sparse matrix $S$ . Is it correct to say this low rank matrix L would be the analogue to the $D$ matrix I described earlier? To find what the principal components are in robust-PCA, would I simply take the eigenvectors of the low rank matrix $L$ ? Lastly, are robust PCA and PCA titled as such because they both will allow you to produce low rank representations of data, not because there is any algorithmic similarity in how they are performed?","I recently learned about PCA and robust PCA. I understand that PCA is identifying the principal components by finding the eigenvectors of the covariance matrix (which of course contains information about the ""directionality"" of the data). These principal components are then used to transform the data so that it is reoriented along the principal components (lets call this reoriented data matrix ). I also understand that robust-PCA can be written as a convex relaxation problem whereby solving it - using Lagrangian methods - yields a low rank matrix and a sparse matrix . Is it correct to say this low rank matrix L would be the analogue to the matrix I described earlier? To find what the principal components are in robust-PCA, would I simply take the eigenvectors of the low rank matrix ? Lastly, are robust PCA and PCA titled as such because they both will allow you to produce low rank representations of data, not because there is any algorithmic similarity in how they are performed?",D L S D L,"['statistics', 'principal-component-analysis', 'robust-statistics']"
68,"Specify the classes of the following Markov chains, and determine whether they are transient or recurrent","Specify the classes of the following Markov chains, and determine whether they are transient or recurrent",,"Specify the classes of the following Markov chains, and determine whether they are transient or recurrent: $$\mathbb{P}_1=\begin{Vmatrix}0 & 1/2 & 1/2\\ 1/2 & 0 & 1/2\\ 1/2 & 1/2 & 0\end{Vmatrix},\quad\quad \mathbb{P}_2=\begin{Vmatrix}0 & 0 & 0 & 1\\ 0 & 0 & 0 & 1\\ 1/2 & 1/2 & 0 & 0\\ 0 & 0 & 1 & 0\end{Vmatrix}$$ $$\mathbb{P}_3=\begin{Vmatrix}1/2&0&1/2&0&0\\1/4&1/2&1/4&0&0\\1/2&0&1/2&0&0\\0&0&0&1/2&1/2\\0&0&0&1/2&1/2\end{Vmatrix},\quad \mathbb{P}_4=\begin{Vmatrix}1/4&3/4&0&0&0\\1/2&1/2&0&0&0\\0&0&1&0&0\\0&0&1/3&2/3&0\\1&0&0&0&0\end{Vmatrix}$$ My Attempt $\mathbb{P}_1$ : Closed class: $\{0,1,2\}$ . All states are recurrent. $\mathbb{P}_2$ : Closed classes: $\{0,1,2,3\}$ . States 0 and 1 communicate with state 3, which communicates with state 2, which communicates with states 0 and 1 again. Thus, all states are recurrent. $\mathbb{P}_3$ : Closed classes: $\{0,2\},\{3,4\}$ because states 0 and 2 communicate with each other and states 3 and 4 communicate with each other. Open class: $\{1\}$ because state 1 communicates with 0 but 0 does not communicate with 1. State 1 communicates with 2 but 2 does not communicate with 1. States 0, 2, 3, and 4 are recurrent. State 1 is transient. $\mathbb{P}_4$ : Closed classes: $\{0,1\},\{2\}$ because states 0 and 1 communicate with each other, and state 2 communicates with itself. States 0 and 1 are recurrent, states 2, 3, and 4 are transient. Can I get a formal and an intuitive definition of open and closed classes? I was able to figure this problem out from the patterns I have seen, but I would love to have a definition to go by. I am not entirely sure if I did this correctly, so any help would be appreciated. Thanks.","Specify the classes of the following Markov chains, and determine whether they are transient or recurrent: My Attempt : Closed class: . All states are recurrent. : Closed classes: . States 0 and 1 communicate with state 3, which communicates with state 2, which communicates with states 0 and 1 again. Thus, all states are recurrent. : Closed classes: because states 0 and 2 communicate with each other and states 3 and 4 communicate with each other. Open class: because state 1 communicates with 0 but 0 does not communicate with 1. State 1 communicates with 2 but 2 does not communicate with 1. States 0, 2, 3, and 4 are recurrent. State 1 is transient. : Closed classes: because states 0 and 1 communicate with each other, and state 2 communicates with itself. States 0 and 1 are recurrent, states 2, 3, and 4 are transient. Can I get a formal and an intuitive definition of open and closed classes? I was able to figure this problem out from the patterns I have seen, but I would love to have a definition to go by. I am not entirely sure if I did this correctly, so any help would be appreciated. Thanks.","\mathbb{P}_1=\begin{Vmatrix}0 & 1/2 & 1/2\\ 1/2 & 0 & 1/2\\ 1/2 & 1/2 & 0\end{Vmatrix},\quad\quad \mathbb{P}_2=\begin{Vmatrix}0 & 0 & 0 & 1\\ 0 & 0 & 0 & 1\\ 1/2 & 1/2 & 0 & 0\\ 0 & 0 & 1 & 0\end{Vmatrix} \mathbb{P}_3=\begin{Vmatrix}1/2&0&1/2&0&0\\1/4&1/2&1/4&0&0\\1/2&0&1/2&0&0\\0&0&0&1/2&1/2\\0&0&0&1/2&1/2\end{Vmatrix},\quad \mathbb{P}_4=\begin{Vmatrix}1/4&3/4&0&0&0\\1/2&1/2&0&0&0\\0&0&1&0&0\\0&0&1/3&2/3&0\\1&0&0&0&0\end{Vmatrix} \mathbb{P}_1 \{0,1,2\} \mathbb{P}_2 \{0,1,2,3\} \mathbb{P}_3 \{0,2\},\{3,4\} \{1\} \mathbb{P}_4 \{0,1\},\{2\}","['statistics', 'stochastic-processes', 'markov-chains', 'transition-matrix']"
69,Offline manual backpropagation - Is it correct?,Offline manual backpropagation - Is it correct?,,"I want to understand the algorithm of backpropagation so I created this example by myself: I want to backpropagate through the network offline when Additionally in last layer we consider linear activation function and MSE as loss function. My solution I generally understand the idea behind backpropagation, I want just to assure if I understand how it works in offline case. I have question about two derivatives: First is about backpropagating error with respect to weight 9 And second is about backpropagation MSE with respect to weight 6: where neth_2 means input in node h2. Additionally: Can I please ask you to check whether those derivatives make sense? I'm really not sure how backpropagation works in offline case so it would be very handy for me if you could check it!","I want to understand the algorithm of backpropagation so I created this example by myself: I want to backpropagate through the network offline when Additionally in last layer we consider linear activation function and MSE as loss function. My solution I generally understand the idea behind backpropagation, I want just to assure if I understand how it works in offline case. I have question about two derivatives: First is about backpropagating error with respect to weight 9 And second is about backpropagation MSE with respect to weight 6: where neth_2 means input in node h2. Additionally: Can I please ask you to check whether those derivatives make sense? I'm really not sure how backpropagation works in offline case so it would be very handy for me if you could check it!",,"['statistics', 'vector-analysis', 'gradient-descent', 'neural-networks']"
70,Finding covariance from a transformed random variable given its covariance matrix,Finding covariance from a transformed random variable given its covariance matrix,,"Let the bivariate random variable $A=(A_1,A_2)^T$ have a Gaussian distribution on $\mathbb{R}^2$ with zero mean and covariance matrix be given by $$\begin{pmatrix} 1 & -0.4\\-0.4 & 1\end{pmatrix}$$ . Let $B$ = $\begin{pmatrix} 1 \\ 2 \end{pmatrix}$ and $C$ = $\begin{pmatrix} 2 \\ 1 \end{pmatrix}$ . Define $X=B^TA,Y=C^TA$ . How do I find the covariance of X and Y? I know that $cov(X,Y) = E(XY)-E(X)E(Y)$ . I don't quite understand how to read a covariance matrix.",Let the bivariate random variable have a Gaussian distribution on with zero mean and covariance matrix be given by . Let = and = . Define . How do I find the covariance of X and Y? I know that . I don't quite understand how to read a covariance matrix.,"A=(A_1,A_2)^T \mathbb{R}^2 \begin{pmatrix} 1 & -0.4\\-0.4 & 1\end{pmatrix} B \begin{pmatrix} 1 \\ 2 \end{pmatrix} C \begin{pmatrix} 2 \\ 1 \end{pmatrix} X=B^TA,Y=C^TA cov(X,Y) = E(XY)-E(X)E(Y)","['matrices', 'statistics']"
71,low $p$-value and low explained variation connection in multiple regression analysis,low -value and low explained variation connection in multiple regression analysis,p,"I've just started studying multiple linear regression and I'm stuck at creating a dataset for which a multiple regression model would have a low $p$ -value (the coefficients are non zero) and also low explained variation $R^2$ . The following is what I've come up. To create a dataset with low explained variation it is necessary that the output variable is not in linear correspondence with the predictor variables. very low $p$ -value of coefficients it is necessary that the coefficients are non zero. If predictors are independent the coefficient $i$ th $a_i$ is equal to $\rho(X_i,Y)$ (correlation between $X_i$ and $Y$ ). If $X_i$ and $Y$ are not connected by linear relation, the coefficient $\rho$ is almost zero so this scenario has to be excluded. On the other hand, if I define $Y$ so has to have linear relation to $X_i$ for every $i$ , the condition on explained variation not holds anymore. However, if the predictors are not independent, although I know the formula for the coefficients, it's not very clear to me how to proceed.","I've just started studying multiple linear regression and I'm stuck at creating a dataset for which a multiple regression model would have a low -value (the coefficients are non zero) and also low explained variation . The following is what I've come up. To create a dataset with low explained variation it is necessary that the output variable is not in linear correspondence with the predictor variables. very low -value of coefficients it is necessary that the coefficients are non zero. If predictors are independent the coefficient th is equal to (correlation between and ). If and are not connected by linear relation, the coefficient is almost zero so this scenario has to be excluded. On the other hand, if I define so has to have linear relation to for every , the condition on explained variation not holds anymore. However, if the predictors are not independent, although I know the formula for the coefficients, it's not very clear to me how to proceed.","p R^2 p i a_i \rho(X_i,Y) X_i Y X_i Y \rho Y X_i i","['statistics', 'linear-regression', 'regression-analysis']"
72,Find the Maximum Likelihood Estimator,Find the Maximum Likelihood Estimator,,"Let $X_1,X_2 ,X_3 ,..., X_n$ be iid with cdf $𝐹(𝑥) = 1 − 𝑥^{−𝜃}, 𝑥 > 0, 𝜃 > 0$. What I have done so far, $L(\theta)=\prod\limits_{i=1}^n\theta x_i^{\theta -1}=\theta^n\prod\limits_{i=1}^n\ x_i^{\theta -1}$ $ln(L(\theta))=nln(\theta)+(\theta-1)^{n}\prod\limits_{i=1}^n ln(x_i)$ $\frac{d}{d\theta}ln(L(\theta))=\frac{n}{\theta}+n(\theta-1)^{n-1}\prod\limits_{i=1}^nln(x_i)=0$ $\theta(\theta -1)^{n-1}=\frac{-1}{\prod\limits_{i=1}^nln(x_i)}$ How do I proceed?","Let $X_1,X_2 ,X_3 ,..., X_n$ be iid with cdf $𝐹(𝑥) = 1 − 𝑥^{−𝜃}, 𝑥 > 0, 𝜃 > 0$. What I have done so far, $L(\theta)=\prod\limits_{i=1}^n\theta x_i^{\theta -1}=\theta^n\prod\limits_{i=1}^n\ x_i^{\theta -1}$ $ln(L(\theta))=nln(\theta)+(\theta-1)^{n}\prod\limits_{i=1}^n ln(x_i)$ $\frac{d}{d\theta}ln(L(\theta))=\frac{n}{\theta}+n(\theta-1)^{n-1}\prod\limits_{i=1}^nln(x_i)=0$ $\theta(\theta -1)^{n-1}=\frac{-1}{\prod\limits_{i=1}^nln(x_i)}$ How do I proceed?",,['statistics']
73,How to find or approximate probability distribution from known values of the characteristic function?,How to find or approximate probability distribution from known values of the characteristic function?,,"If I have a known discrete values for the characteristic function (I know $a_n$ values for specific values of $\omega_n = \frac{2\pi i n}{d}$ ): $$a_n = \phi_x\left(\omega = \frac{2\pi in}{d}\right),$$ How do I find the probability distribution for this characteristic function? I've seen some stuff online about possibly needing an inverse discrete-time Fourier transform, but I haven't had much luck unfortunately. (Edit: I believe its actually related to the discrete-frequency Fourier Transform (DFFT), but this is much less well-documented on the internet.    A paper discussing the topic is here: The discrete frequency Fourier transform .  The DFFT differs from the DTFT in that it's defined for discrete values of frequency, giving a continuous function of time, whereas the DTFT is defined for discrete values of time, giving a continuous function of frequency) Alternatively, I'm just trying to find the variance in this probability distribution, so if there's a way to get the variance directly from discrete values of the characteristic function, I'd be happy to hear that :).","If I have a known discrete values for the characteristic function (I know values for specific values of ): How do I find the probability distribution for this characteristic function? I've seen some stuff online about possibly needing an inverse discrete-time Fourier transform, but I haven't had much luck unfortunately. (Edit: I believe its actually related to the discrete-frequency Fourier Transform (DFFT), but this is much less well-documented on the internet.    A paper discussing the topic is here: The discrete frequency Fourier transform .  The DFFT differs from the DTFT in that it's defined for discrete values of frequency, giving a continuous function of time, whereas the DTFT is defined for discrete values of time, giving a continuous function of frequency) Alternatively, I'm just trying to find the variance in this probability distribution, so if there's a way to get the variance directly from discrete values of the characteristic function, I'd be happy to hear that :).","a_n \omega_n = \frac{2\pi i n}{d} a_n = \phi_x\left(\omega = \frac{2\pi in}{d}\right),","['probability', 'statistics', 'fourier-transform', 'characteristic-functions', 'discrete-time']"
74,Characteristic function of non-central $\chi^2$,Characteristic function of non-central,\chi^2,"Consider $X_1,\ldots, X_n$ iid random variables with $X_1\sim\mathcal{N}(0,1)$ , some real numbers $\alpha_1,\ldots,\alpha_n$ . Define $Z:=\sum_{i=1}^n (X_i+\alpha_i)^2$ and $\kappa:=\sum_{i=1}^n\alpha_i^2$ I want to show by direct integration, that $$E[e^{uZ}]=\frac{\exp({\frac{\kappa u}{1-2u}})}{(1-2u)^\frac{\kappa}{2}}$$ for any $u\in\mathbb{C}$ with $\Re(u)\le 0$ . What I have done so far is the following: $$ \begin{align} E[e^{uZ}]&=E[e^{u\sum_{i=1}^n (X_i+\alpha_i)^2}]\\ &=\prod_{i=1}^nE[e^{u (X_i+\alpha_i)^2}]\text{, since }X_i\text{ are independent}\\ &=\prod_{i=1}^n \frac{1}{\sqrt{2\pi}}\int_{-\infty}^\infty e^{u (x+\alpha_i)^2}e^{-\frac{x^2}{2}}dx\text{, since }X_i\sim\mathcal{N}(0,1)\\ &=\prod_{i=1}^n \frac{1}{\sqrt{2\pi}}\int_{-\infty}^\infty e^{(2u-1) (\frac{x+\alpha_i}{\sqrt{2}})^2}e^{x\alpha_i+\frac{1}{2}\alpha_i^2}dx\\ \end{align} $$ The right hand side can be written as $$ \begin{align} \frac{\exp({\frac{\kappa u}{1-2u}})}{(1-2u)^\frac{\kappa}{2}}&=\exp\Big({\frac{\kappa u}{1-2u}}-\frac{\kappa}{2}\ln(1-2u)\Big)\\ \end{align} $$ How can I go on from here? Maybe I can apply some Fourier Inversion formula? Thanks in advance!","Consider iid random variables with , some real numbers . Define and I want to show by direct integration, that for any with . What I have done so far is the following: The right hand side can be written as How can I go on from here? Maybe I can apply some Fourier Inversion formula? Thanks in advance!","X_1,\ldots, X_n X_1\sim\mathcal{N}(0,1) \alpha_1,\ldots,\alpha_n Z:=\sum_{i=1}^n (X_i+\alpha_i)^2 \kappa:=\sum_{i=1}^n\alpha_i^2 E[e^{uZ}]=\frac{\exp({\frac{\kappa u}{1-2u}})}{(1-2u)^\frac{\kappa}{2}} u\in\mathbb{C} \Re(u)\le 0 
\begin{align}
E[e^{uZ}]&=E[e^{u\sum_{i=1}^n (X_i+\alpha_i)^2}]\\
&=\prod_{i=1}^nE[e^{u (X_i+\alpha_i)^2}]\text{, since }X_i\text{ are independent}\\
&=\prod_{i=1}^n \frac{1}{\sqrt{2\pi}}\int_{-\infty}^\infty e^{u (x+\alpha_i)^2}e^{-\frac{x^2}{2}}dx\text{, since }X_i\sim\mathcal{N}(0,1)\\
&=\prod_{i=1}^n \frac{1}{\sqrt{2\pi}}\int_{-\infty}^\infty e^{(2u-1) (\frac{x+\alpha_i}{\sqrt{2}})^2}e^{x\alpha_i+\frac{1}{2}\alpha_i^2}dx\\
\end{align}
 
\begin{align}
\frac{\exp({\frac{\kappa u}{1-2u}})}{(1-2u)^\frac{\kappa}{2}}&=\exp\Big({\frac{\kappa u}{1-2u}}-\frac{\kappa}{2}\ln(1-2u)\Big)\\
\end{align}
","['probability-theory', 'statistics', 'fourier-analysis', 'fourier-transform', 'characteristic-functions']"
75,Probability of a egg surviving with a Poisson distribution,Probability of a egg surviving with a Poisson distribution,,"The probability that a bird deposits $r$ eggs in its nest is given by the Poisson distribution with parameter $\lambda$ . Assume that the probability of a egg to survive in nature is $p$ and that the survival of each egg is independent. Knowing that a bird deposited at most $3$ eggs, what is the probability that there is exactly one survival egg? My attempt to solve this was as follows: P(exactly one survives| at most $3$ deposited) = P(exactly one survives and at most $3$ deposited)/P(at most $3$ deposited) P(at most $3$ deposited) = $\sum_{r=0}^{3}\frac{e^{-\lambda}{\lambda}^r}{r!}$ P(exactly one survives and at most $3$ deposited) = $\sum_{r=1}^{3}\frac{e^{-\lambda}{\lambda}^r \cdot {r \choose 1} \cdot p \cdot (1-p)^{r-1}}{r!}$ where the $r=0$ term vanishes because we can't have a egg surviving if there is none in the nest. Finally the result follows dividing 3./2. is that correct, could someone help me?","The probability that a bird deposits eggs in its nest is given by the Poisson distribution with parameter . Assume that the probability of a egg to survive in nature is and that the survival of each egg is independent. Knowing that a bird deposited at most eggs, what is the probability that there is exactly one survival egg? My attempt to solve this was as follows: P(exactly one survives| at most deposited) = P(exactly one survives and at most deposited)/P(at most deposited) P(at most deposited) = P(exactly one survives and at most deposited) = where the term vanishes because we can't have a egg surviving if there is none in the nest. Finally the result follows dividing 3./2. is that correct, could someone help me?",r \lambda p 3 3 3 3 3 \sum_{r=0}^{3}\frac{e^{-\lambda}{\lambda}^r}{r!} 3 \sum_{r=1}^{3}\frac{e^{-\lambda}{\lambda}^r \cdot {r \choose 1} \cdot p \cdot (1-p)^{r-1}}{r!} r=0,"['probability', 'statistics', 'probability-distributions', 'poisson-distribution']"
76,Growth function $\tau_{\mathcal{H}}(m)$ lower bound,Growth function  lower bound,\tau_{\mathcal{H}}(m),"I have been working on this problem for a long time and I would like some help. They ask me to find for each $ n $ a hypothesis class $ \mathcal {H} \subset \{\pm 1 \}^{\mathbb {N}} $ with $ n $ elements such that the growth function is $ \tau_{\mathcal{H}}(m) =\min\{ m+1,n \}$ . And they ask me to prove that in general $\tau_{\mathcal{H}}(m) \geqslant \min\{ m+1,n \}$ if $|\mathcal{H}|=n$ . I have worked with the indicator functions of the sets $\{1\}, \{2\},\ldots, \{n\}$ and $\{1\}, \{1,2\},\ldots, \{1,2,\ldots,n\}$ but in no case have I obtained results. I would appreciate if you could help me. A hypothesis class is just a designation for that subset of functions of $ \{\pm 1 \}^{\mathbb{N}}$ (in this case). And the growth function is $$\tau_{\mathcal{H}}(m)=\sup |\mathcal{H}_{C}|$$ where the supreme is taken over all subsets $ C \subset \mathbb{N}$ such that $|C|=m$ . Here, $$\mathcal{H}_{C}=\{ h|_{C}: h\in \mathcal{H} \}$$","I have been working on this problem for a long time and I would like some help. They ask me to find for each a hypothesis class with elements such that the growth function is . And they ask me to prove that in general if . I have worked with the indicator functions of the sets and but in no case have I obtained results. I would appreciate if you could help me. A hypothesis class is just a designation for that subset of functions of (in this case). And the growth function is where the supreme is taken over all subsets such that . Here,"," n   \mathcal {H} \subset \{\pm 1 \}^{\mathbb {N}}   n   \tau_{\mathcal{H}}(m) =\min\{ m+1,n \} \tau_{\mathcal{H}}(m) \geqslant \min\{ m+1,n \} |\mathcal{H}|=n \{1\}, \{2\},\ldots, \{n\} \{1\}, \{1,2\},\ldots, \{1,2,\ldots,n\}  \{\pm 1 \}^{\mathbb{N}} \tau_{\mathcal{H}}(m)=\sup |\mathcal{H}_{C}|  C \subset \mathbb{N} |C|=m \mathcal{H}_{C}=\{ h|_{C}: h\in \mathcal{H} \}","['probability-theory', 'statistics', 'machine-learning']"
77,How many books are in a library?,How many books are in a library?,,"My cousin is at elementary school and every week is given a book by his teacher.  He then reads it and returns it in time to get another one the next week. After a while we started noticing that he was getting books he had read before and this became gradually more common over time.   Naturally, I started to wonder how one could estimate the total number of books in their library. Say the true number of books in the library is $N$ and the teacher picks one uniformly at random (with replacement) to give to you each week.  If at week $t$ you have received a book you have read before $x$ times, is there an unbiased estimator for the total number of books in the library and what is the variance of this estimator? Is there another biased estimator with lower variance? In my cousin's case, in the first $30$ weeks he received a book he had received before $3$ times.","My cousin is at elementary school and every week is given a book by his teacher.  He then reads it and returns it in time to get another one the next week. After a while we started noticing that he was getting books he had read before and this became gradually more common over time.   Naturally, I started to wonder how one could estimate the total number of books in their library. Say the true number of books in the library is $N$ and the teacher picks one uniformly at random (with replacement) to give to you each week.  If at week $t$ you have received a book you have read before $x$ times, is there an unbiased estimator for the total number of books in the library and what is the variance of this estimator? Is there another biased estimator with lower variance? In my cousin's case, in the first $30$ weeks he received a book he had received before $3$ times.",,['probability']
78,Probability of Random Variable Question | Probability Error,Probability of Random Variable Question | Probability Error,,"I had this question in my past paper: Bags of sugar are packed in boxes, each box containing 20 bags. The masses of the boxes, when empty, are normally distributed with mean 0.4 kg and standard deviation 0.01 kg. The masses of the bags are normally distributed with mean 1.02 kg and standard deviation 0.03 kg. i) Two full boxes are chosen at random. Find the probability that they differ in mass by less than 0.02 kg I did the calculations and I got my probability as 2 x 0.4582 however in the marking scheme they've deducted the final answer from 1. Why is that so?","I had this question in my past paper: Bags of sugar are packed in boxes, each box containing 20 bags. The masses of the boxes, when empty, are normally distributed with mean 0.4 kg and standard deviation 0.01 kg. The masses of the bags are normally distributed with mean 1.02 kg and standard deviation 0.03 kg. i) Two full boxes are chosen at random. Find the probability that they differ in mass by less than 0.02 kg I did the calculations and I got my probability as 2 x 0.4582 however in the marking scheme they've deducted the final answer from 1. Why is that so?",,"['probability', 'statistics', 'random-variables']"
79,Wasserman IID Samples Convergence in Quadratic Mean,Wasserman IID Samples Convergence in Quadratic Mean,,"Here is the question: Exercise 6.8.3. Let $X_1, X_2, \dots, X_n$ be iid and let $\mu = \mathbb{E}(X_i)$ . Suppose that variance is finite. Show that $\overline{X}_n \xrightarrow{\text{qm}} \mu$ . Here is the given answer: Let $Y_i = X_i - \mu$ . It has variance $\sigma_Y = \sigma$ and mean $\mu_Y = 0$ . We have: $$ \begin{align} & \mathbb{E}[(\overline{X}_n - \mu)^2] = \\ & = \mathbb{E}\left[\left(\frac{1}{n} \sum_{i=1}^n (X_i - \mu) \right)^2\right] \\ & = \frac{1}{n^2} \mathbb{E} \left[ \left(\sum_{i=1}^n Y_i \right)^2 \right] \\ & = \frac{1}{n^2} \left( \sum_{i=1}^n \mathbb{E}[Y_i^2] - \sum_{i=1}^n \sum_{j=1, j \neq i}^n \mathbb{E}[Y_i Y_j] \right) \\ & = \frac{1}{n} \left( (\sigma_Y^2 + \mu_Y^2) - (n-1) \mu_Y^2 \right) \\ & = \frac{\sigma}{n} \end{align} $$ Therefore, $\lim _{n \rightarrow \infty} \mathbb{E}[(\overline{X}_n - \mu)^2] = \lim _{n \rightarrow \infty} \sigma / n = 0$ , and so $\overline{X}_n \xrightarrow{\text{qm}} \mu$ . Unfortunately I follow until about step 3. For one thing, I am not sure how the $ \frac{1}{n}\ $ turned into $ \frac{1}{n^2}\ $ . Furthermore, I do not see how the double summations from i=1 to n and j=1, j $\neq$ i come in. If anyone could explain the concept used or even just point a resource to learn it, I would appreciate that. The book is Wasserman's All of Statistics.","Here is the question: Exercise 6.8.3. Let be iid and let . Suppose that variance is finite. Show that . Here is the given answer: Let . It has variance and mean . We have: Therefore, , and so . Unfortunately I follow until about step 3. For one thing, I am not sure how the turned into . Furthermore, I do not see how the double summations from i=1 to n and j=1, j i come in. If anyone could explain the concept used or even just point a resource to learn it, I would appreciate that. The book is Wasserman's All of Statistics.","X_1, X_2, \dots, X_n \mu = \mathbb{E}(X_i) \overline{X}_n \xrightarrow{\text{qm}} \mu Y_i = X_i - \mu \sigma_Y = \sigma \mu_Y = 0 
\begin{align}
& \mathbb{E}[(\overline{X}_n - \mu)^2] = \\
& = \mathbb{E}\left[\left(\frac{1}{n} \sum_{i=1}^n (X_i - \mu) \right)^2\right] \\
& = \frac{1}{n^2} \mathbb{E} \left[ \left(\sum_{i=1}^n Y_i \right)^2 \right] \\
& = \frac{1}{n^2} \left( \sum_{i=1}^n \mathbb{E}[Y_i^2] - \sum_{i=1}^n \sum_{j=1, j \neq i}^n \mathbb{E}[Y_i Y_j] \right) \\
& = \frac{1}{n} \left( (\sigma_Y^2 + \mu_Y^2) - (n-1) \mu_Y^2 \right) \\
& = \frac{\sigma}{n}
\end{align}
 \lim _{n \rightarrow \infty} \mathbb{E}[(\overline{X}_n - \mu)^2] = \lim _{n \rightarrow \infty} \sigma / n = 0 \overline{X}_n \xrightarrow{\text{qm}} \mu  \frac{1}{n}\   \frac{1}{n^2}\  \neq","['statistics', 'expected-value', 'statistical-inference']"
80,Combining Covariances of Two Sets,Combining Covariances of Two Sets,,"According to Wikipedia , the formula for combining the covariances of two sets is: $$C_X=C_A+C_B+(\overline{x}_A-\overline{x}_B)(\overline{y}_A-\overline{y}_B) \cdot\frac{n_An_B}{n_X} $$ where: $A$ and $B$ are the first and second sets. $C$ is the Covariance. $n$ is the number of samples. $n_X = n_A + n_B$ . $x$ and $y$ are the features. I implemented this formula by splitting one dataset into two equal sets, for testing purposes, yet the result is quite different from the original dataset covariance. Now, let $M_{AB}$ be this part of the above formula: $$(\overline{x}_A-\overline{x}_B)(\overline{y}_A-\overline{y}_B) \cdot\frac{n_An_B}{n_X}$$ Looking at this implementation , the author basically applied the following formula: $$ C_X = \frac{(C_A \color{red}{\cdot n_A})  + (C_B \color{red}{\cdot n_B}) + M_{AB}}{\color{red}{n_X}} $$ which gives the correct combined covariance !. I could not understand how the latter is derived or achieved algebraically ? Or if it's even similar to the former formula? because there are extra $\color{red}{n_A}$ and $\color{red}{n_B}$ that are added to the second formula! Your help is appreciated.","According to Wikipedia , the formula for combining the covariances of two sets is: where: and are the first and second sets. is the Covariance. is the number of samples. . and are the features. I implemented this formula by splitting one dataset into two equal sets, for testing purposes, yet the result is quite different from the original dataset covariance. Now, let be this part of the above formula: Looking at this implementation , the author basically applied the following formula: which gives the correct combined covariance !. I could not understand how the latter is derived or achieved algebraically ? Or if it's even similar to the former formula? because there are extra and that are added to the second formula! Your help is appreciated.","C_X=C_A+C_B+(\overline{x}_A-\overline{x}_B)(\overline{y}_A-\overline{y}_B) \cdot\frac{n_An_B}{n_X}  A B C n n_X = n_A + n_B x y M_{AB} (\overline{x}_A-\overline{x}_B)(\overline{y}_A-\overline{y}_B) \cdot\frac{n_An_B}{n_X} 
C_X = \frac{(C_A \color{red}{\cdot n_A})  + (C_B \color{red}{\cdot n_B}) + M_{AB}}{\color{red}{n_X}}
 \color{red}{n_A} \color{red}{n_B}","['statistics', 'algorithms', 'covariance']"
81,Unbiased Estimator of $\sigma^2$ using Least square estimates,Unbiased Estimator of  using Least square estimates,\sigma^2,"Suppose I have $Y_i \sim N(\beta_i ,\sigma^2)$ for $i=1,2,3$ . It is given that $\beta_1 + \beta_2= \beta_3$ and $\hat{\beta}_1 = \frac{2Y_1 - Y_2 +Y_3}{3} , \hat{\beta}_2 = \frac{2Y_2-Y_1+Y_3}{3},\hat{\beta}_3= \frac{Y_1+Y_2+2Y_3}{3}$ where $\hat{\beta}_i$ 's are the least square estimates of $\beta_i$ 's. I am trying to find an unbiased estimator for $\sigma^2$ using the Least squares estimates, but I can't guess how should I combine the $\hat{\beta}_i $ 's?","Suppose I have for . It is given that and where 's are the least square estimates of 's. I am trying to find an unbiased estimator for using the Least squares estimates, but I can't guess how should I combine the 's?","Y_i \sim N(\beta_i ,\sigma^2) i=1,2,3 \beta_1 + \beta_2= \beta_3 \hat{\beta}_1 = \frac{2Y_1 - Y_2 +Y_3}{3} , \hat{\beta}_2 = \frac{2Y_2-Y_1+Y_3}{3},\hat{\beta}_3= \frac{Y_1+Y_2+2Y_3}{3} \hat{\beta}_i \beta_i \sigma^2 \hat{\beta}_i ","['statistics', 'statistical-inference', 'regression', 'least-squares', 'estimation']"
82,Gaussian Processes Clarification,Gaussian Processes Clarification,,"$\newcommand\mycolv[1]{\begin{bmatrix}#1\end{bmatrix}}$ Hi all, I've been trying to learn all about Gaussian processes for a few days but I find myself stuck on some notation. The book that I have been mainly reading and other articles I've found split up a given multivariate Gaussian distribution into two random vectors $\textbf{x}$ and $\textbf{y}$ where $\textbf{y}$ contains the observed points. This makes sense to me until the redefinition of the gaussian comes up: $$\mycolv{\textbf{x} \\ \textbf{y}} \sim N(\mycolv{\mu_x \\ \mu_y}, \begin{bmatrix}\Sigma_{xx} & \Sigma_{xy} \\ \Sigma_{yx} & \Sigma_{yy}\end{bmatrix})$$ Unfortunately I am not clear on how to compute the values in this definition. Are the mean vectors just the mean of all of the distribution in each random vector i.e some scalar? Or are they a vector simply containing all of the means of each distribution contained in the corresponding vector? As for the covariance matrix I can imagine having each $\Sigma$ be a covariance matrix, however, since this would cause the dimensions of the $\Sigma_{yx}$ and $\Sigma_{xy}$ matrices to be larger than the other matrices, making multiplication between those two matrices and the other two incompatible. This poses an issue since the product of $\Sigma_{yy}^{-1}$ and $\Sigma_{xy}$ is required when conditioning the multivariate. Sorry if I made any errors. Any help would be appreciated.","Hi all, I've been trying to learn all about Gaussian processes for a few days but I find myself stuck on some notation. The book that I have been mainly reading and other articles I've found split up a given multivariate Gaussian distribution into two random vectors and where contains the observed points. This makes sense to me until the redefinition of the gaussian comes up: Unfortunately I am not clear on how to compute the values in this definition. Are the mean vectors just the mean of all of the distribution in each random vector i.e some scalar? Or are they a vector simply containing all of the means of each distribution contained in the corresponding vector? As for the covariance matrix I can imagine having each be a covariance matrix, however, since this would cause the dimensions of the and matrices to be larger than the other matrices, making multiplication between those two matrices and the other two incompatible. This poses an issue since the product of and is required when conditioning the multivariate. Sorry if I made any errors. Any help would be appreciated.","\newcommand\mycolv[1]{\begin{bmatrix}#1\end{bmatrix}} \textbf{x} \textbf{y} \textbf{y} \mycolv{\textbf{x} \\ \textbf{y}} \sim N(\mycolv{\mu_x \\ \mu_y}, \begin{bmatrix}\Sigma_{xx} & \Sigma_{xy} \\ \Sigma_{yx} & \Sigma_{yy}\end{bmatrix}) \Sigma \Sigma_{yx} \Sigma_{xy} \Sigma_{yy}^{-1} \Sigma_{xy}","['statistics', 'normal-distribution', 'gaussian']"
83,Is there a closed form for this mean of conditional expected order statistics?,Is there a closed form for this mean of conditional expected order statistics?,,"$X_1, X_2, X_3, ..., X_n$ are iid distributed according to $U[0,1]$ . Computing the mean of the expected order statistics is easy: $$\frac{1}{n}\sum_{i=1}^n\mathbb{E}[X_{(i)}] = \sum_{i=1}^n \int_0^1 {n-1\choose i-1}X^i(1-X)^{n-i}dX = \frac{1}{2}.$$ Instead I would like to multiply each order statistic by the probability that it lies below some value $z$ . $$\sum_{i=1}^n F_i(z) \int_0^1 {n-1\choose i-1}X^i(1-X)^{n-i}dX = \sum_{i=1}^n \sum_{j=i}^n {n \choose j}z^j(1-z)^{n-j} \int_0^1 {n-1\choose i-1}X^i(1-X)^{n-i}dX $$ Suddenly the computation is not so easy anymore. Is there a closed form?",are iid distributed according to . Computing the mean of the expected order statistics is easy: Instead I would like to multiply each order statistic by the probability that it lies below some value . Suddenly the computation is not so easy anymore. Is there a closed form?,"X_1, X_2, X_3, ..., X_n U[0,1] \frac{1}{n}\sum_{i=1}^n\mathbb{E}[X_{(i)}] = \sum_{i=1}^n \int_0^1 {n-1\choose i-1}X^i(1-X)^{n-i}dX = \frac{1}{2}. z \sum_{i=1}^n F_i(z) \int_0^1 {n-1\choose i-1}X^i(1-X)^{n-i}dX = \sum_{i=1}^n \sum_{j=i}^n {n \choose j}z^j(1-z)^{n-j} \int_0^1 {n-1\choose i-1}X^i(1-X)^{n-i}dX ","['probability', 'statistics', 'conditional-expectation', 'order-statistics']"
84,"How to formally argue that concentration bounds are valid for dependent samples that are drawn ""better than"" i.i.d.","How to formally argue that concentration bounds are valid for dependent samples that are drawn ""better than"" i.i.d.",,"I'm looking for references that help me formally argue that, in a special case of non-independent sampling, we can apply concentration bounds as if the sample was i.i.d..  Below is a simple concrete example to explain my question. Suppose we are interested in some statistic (e.g., the expected value) of a probability distribution represented by the rolls of two 6-sided weighted dice.  With probability $p$ , dice A is thrown, and we get a number in $\{1, 2, \dotsc, 6\}$ (with some unknown probabilities).  With probability $1-p$ , dice B is thrown, and we get a number in $\{1, 2, \dotsc, 6\}$ (with some unknown probabilities that are different from A).  So the result is always an integer in $\{1, 2, \dotsc, 6\}$ . Now suppose we are given an i.i.d. sample of size $n$ (assume $n$ is even, for reasons that will become apparent soon), and then apply something like Hoeffding's inequality to get a probabilistic bound on the mean of the distribution (or some other concentration bound/statistic), but we are forced to discard half of our sample first ( for reasons that are not important for the purposes of this question ). We could of course, randomly partition our sample into 2 equally-sized sets, and throw away one of those sets, which results in the remaining set being an i.i.d. sample, to which we can straightforwardly apply our concentration bounds (let's call this the vanilla procedure ).  Notice that the vanilla procedure is equivalent to drawing an i.i.d. sample of size $n/2$ . Alternatively, if we know which samples are from A and which are from B, we could split things so we throw away half of the rolls from A and half of the rolls from B.  For example, following this procedure, if $n=100$ and we got 60 rolls from A and 40 from B, we would throw away 30 randomly selected rolls from A, and 20 randomly selected rolls from B, leaving us with a 30 A rolls and 20 B rolls to estimate our statistic.  We'll call this the alternative procedure below. In other words, instead of randomly throwing away half of the data, the alternative procedure does something similar to (but not exactly the same as) stratification when deciding what data to discard, in an attempt to reduce variance of the estimator. Intuitively, while a sample from alternative procedure is not sampled independently, it is clearly ""more representative of the distribution in expectation"" than an i.i.d. sample obtained from the vanilla procedure (sorry for the informal terms, this is the core of the question and I don't know the correct terms). (It is trivial to show that the resulting sample results in an unbiased estimator of the mean.  Intuitively, it may also result in a lower variance estimator of the mean compared to the vanilla procedure, since we avoid situations where we discard a disproportionate number of the rolls from one of the dice. In other words, we are more likely to get rolls of the dice that more closely match the proportions $p$ and $1-p$ .) So, since this sampling method is ""better than i.i.d."", it seems very intuitive that we should be able to use concentration bounds as if the sample from the alternative procedure was sampled i.i.d..  How can I formally argue this idea?  What limits are there on this argument in terms of applicability? (I am convinced that this method applies to estimating statistics like the mean, but am not sure if it is generally applicable, e.g., the expected sample variance might be higher compared to that of an i.i.d. sample.)  Thank you! Things I've looked at/considered already (reading this section may be helpful, but is not necessary to answer the question): I've noticed that the alternative procedure can be categorized as producing an exchangeable sequence of random variables ( https://en.wikipedia.org/wiki/Exchangeable_random_variables ).  I can't find any sources that help me exploit this fact. I've seen several papers like https://arxiv.org/pdf/1309.4029.pdf , which are closely related to this idea, but do not directly help since this is not a simple ""sampling without replacement"" scenario.","I'm looking for references that help me formally argue that, in a special case of non-independent sampling, we can apply concentration bounds as if the sample was i.i.d..  Below is a simple concrete example to explain my question. Suppose we are interested in some statistic (e.g., the expected value) of a probability distribution represented by the rolls of two 6-sided weighted dice.  With probability , dice A is thrown, and we get a number in (with some unknown probabilities).  With probability , dice B is thrown, and we get a number in (with some unknown probabilities that are different from A).  So the result is always an integer in . Now suppose we are given an i.i.d. sample of size (assume is even, for reasons that will become apparent soon), and then apply something like Hoeffding's inequality to get a probabilistic bound on the mean of the distribution (or some other concentration bound/statistic), but we are forced to discard half of our sample first ( for reasons that are not important for the purposes of this question ). We could of course, randomly partition our sample into 2 equally-sized sets, and throw away one of those sets, which results in the remaining set being an i.i.d. sample, to which we can straightforwardly apply our concentration bounds (let's call this the vanilla procedure ).  Notice that the vanilla procedure is equivalent to drawing an i.i.d. sample of size . Alternatively, if we know which samples are from A and which are from B, we could split things so we throw away half of the rolls from A and half of the rolls from B.  For example, following this procedure, if and we got 60 rolls from A and 40 from B, we would throw away 30 randomly selected rolls from A, and 20 randomly selected rolls from B, leaving us with a 30 A rolls and 20 B rolls to estimate our statistic.  We'll call this the alternative procedure below. In other words, instead of randomly throwing away half of the data, the alternative procedure does something similar to (but not exactly the same as) stratification when deciding what data to discard, in an attempt to reduce variance of the estimator. Intuitively, while a sample from alternative procedure is not sampled independently, it is clearly ""more representative of the distribution in expectation"" than an i.i.d. sample obtained from the vanilla procedure (sorry for the informal terms, this is the core of the question and I don't know the correct terms). (It is trivial to show that the resulting sample results in an unbiased estimator of the mean.  Intuitively, it may also result in a lower variance estimator of the mean compared to the vanilla procedure, since we avoid situations where we discard a disproportionate number of the rolls from one of the dice. In other words, we are more likely to get rolls of the dice that more closely match the proportions and .) So, since this sampling method is ""better than i.i.d."", it seems very intuitive that we should be able to use concentration bounds as if the sample from the alternative procedure was sampled i.i.d..  How can I formally argue this idea?  What limits are there on this argument in terms of applicability? (I am convinced that this method applies to estimating statistics like the mean, but am not sure if it is generally applicable, e.g., the expected sample variance might be higher compared to that of an i.i.d. sample.)  Thank you! Things I've looked at/considered already (reading this section may be helpful, but is not necessary to answer the question): I've noticed that the alternative procedure can be categorized as producing an exchangeable sequence of random variables ( https://en.wikipedia.org/wiki/Exchangeable_random_variables ).  I can't find any sources that help me exploit this fact. I've seen several papers like https://arxiv.org/pdf/1309.4029.pdf , which are closely related to this idea, but do not directly help since this is not a simple ""sampling without replacement"" scenario.","p \{1, 2, \dotsc, 6\} 1-p \{1, 2, \dotsc, 6\} \{1, 2, \dotsc, 6\} n n n/2 n=100 p 1-p","['statistics', 'sampling']"
85,Find hazard rate of $X$ from its residual lifetime survival function,Find hazard rate of  from its residual lifetime survival function,X,"Given a random variable $X$ with survival function $S_X(x)$ , I know that I can find the survival function of the residual lifetime rv $T_t=X-t|X>t$ by $S_{T_t}(x)=\frac{S_X(t+x)}{S_X(t)}$ . But can I go the other way around, and find the survival function of $X$ starting with knowing the survival function of $T_t$ ? Here's the problem: Given a random variable $X>0$ , the associated residual lifetime random variable is defined as $T_t=X-t|X>t$ for a constant $t\geq 0$ . Given that $S_{T_t}(y)=e^{-y^2-(t+5)y}$ , $y>0$ , determine the hazard rate of $X$ , i.e. $h_X(s)$ . Here's what I tried: I attempted to get the survival function of $X$ by setting $t=0$ and using that to calculate the hazard rate. But when I set $t=0$ I get $S_X(y)=e^{-y^2-5y}$ . When plugging that back into the formula for the residual lifetime rv survival function I get $$S_{T_t(y)}=\frac{S_X(t+y)}{S_X(y)}=\frac{e^{-(t+y)^2-5(t+y)}}{e^{-t^2-5t}}=\frac{e^{-t^2-2ty-y^2-5t-5y}}{e^{-t^2-5t}}=e^{-y^2-2yt-5y}$$ This no longer matches the original problem where $S_{T_t}(y)=e^{-y^2-(t+5)y}$ . Where am I going wrong?","Given a random variable with survival function , I know that I can find the survival function of the residual lifetime rv by . But can I go the other way around, and find the survival function of starting with knowing the survival function of ? Here's the problem: Given a random variable , the associated residual lifetime random variable is defined as for a constant . Given that , , determine the hazard rate of , i.e. . Here's what I tried: I attempted to get the survival function of by setting and using that to calculate the hazard rate. But when I set I get . When plugging that back into the formula for the residual lifetime rv survival function I get This no longer matches the original problem where . Where am I going wrong?",X S_X(x) T_t=X-t|X>t S_{T_t}(x)=\frac{S_X(t+x)}{S_X(t)} X T_t X>0 T_t=X-t|X>t t\geq 0 S_{T_t}(y)=e^{-y^2-(t+5)y} y>0 X h_X(s) X t=0 t=0 S_X(y)=e^{-y^2-5y} S_{T_t(y)}=\frac{S_X(t+y)}{S_X(y)}=\frac{e^{-(t+y)^2-5(t+y)}}{e^{-t^2-5t}}=\frac{e^{-t^2-2ty-y^2-5t-5y}}{e^{-t^2-5t}}=e^{-y^2-2yt-5y} S_{T_t}(y)=e^{-y^2-(t+5)y},['statistics']
86,Probability of X lying within one standard deviation for different distributions?,Probability of X lying within one standard deviation for different distributions?,,"We know that for the normal distribution (denote this $P_N(x)$ ), the probability of a random variable having a value within one standard deviation of the mean is approximately $68$ %. That is $$\int_{\mu-\sigma}^{\mu+\sigma} P_N(x)\approx 0.68$$ This is true for all Normal distributions. Similarly, for all normal distributions, the ratio of the standard deviation to the mean absolute deviation is $$R\equiv \frac{\sigma}{MAD}=\sqrt{\frac{\pi}{2}}\approx1.25$$ I will refer to this quantity as the characteristic ratio of the distribution and denote it by $R$ . I have noticed that for any distribution I analyze, if the distributions characteristic ratio ( $R=\frac{\sigma}{MAD}$ ) is small, then the the probability contained within one standard deviation is small. For example, for the constant distribution $P_a(x)=1/a$ , we have that $$R=\frac{\sigma}{MAD}\approx 1.1547$$ This is less than the characteristic ratio of the normal distribution and so sure enough, if we calculate the probability contained within one standard deviation of the mean, we get a value less than that of a normal distribution (which is $0.68$ ) $$\int_{\mu-\sigma}^{\mu+\sigma} P_a(x)\approx 0.577$$ I have tried numerous distributions and always get a higher probability contained within one standard deviation given a higher characteristic ratio and vice versa. Is there a theorem or proof relating these 2 quantities for a distribution? That is, given the characteristic ratio of a distribution, is there a formula that relates the characteristic ratio to the the probability contained within one standard deviation? My second question is: Is there an intuitive way to interpret why a large characteristic ratio implies a large probability within one standard deviation?","We know that for the normal distribution (denote this ), the probability of a random variable having a value within one standard deviation of the mean is approximately %. That is This is true for all Normal distributions. Similarly, for all normal distributions, the ratio of the standard deviation to the mean absolute deviation is I will refer to this quantity as the characteristic ratio of the distribution and denote it by . I have noticed that for any distribution I analyze, if the distributions characteristic ratio ( ) is small, then the the probability contained within one standard deviation is small. For example, for the constant distribution , we have that This is less than the characteristic ratio of the normal distribution and so sure enough, if we calculate the probability contained within one standard deviation of the mean, we get a value less than that of a normal distribution (which is ) I have tried numerous distributions and always get a higher probability contained within one standard deviation given a higher characteristic ratio and vice versa. Is there a theorem or proof relating these 2 quantities for a distribution? That is, given the characteristic ratio of a distribution, is there a formula that relates the characteristic ratio to the the probability contained within one standard deviation? My second question is: Is there an intuitive way to interpret why a large characteristic ratio implies a large probability within one standard deviation?",P_N(x) 68 \int_{\mu-\sigma}^{\mu+\sigma} P_N(x)\approx 0.68 R\equiv \frac{\sigma}{MAD}=\sqrt{\frac{\pi}{2}}\approx1.25 R R=\frac{\sigma}{MAD} P_a(x)=1/a R=\frac{\sigma}{MAD}\approx 1.1547 0.68 \int_{\mu-\sigma}^{\mu+\sigma} P_a(x)\approx 0.577,"['probability', 'statistics', 'probability-distributions']"
87,Interpretation of standard deviation,Interpretation of standard deviation,,"I've come across many articles that describe standard deviation to be a measure of how much spread out our distribution is. In other words, it is a measure of how far away from the mean, we expect a data point to land. Now, imagine we have a distribution of random variables, like in the case of a symmetric random walk. The mean of the distribution is obviously $0$ . So we can write $\langle x_i \rangle = 0 $ . In this case, let $\sigma$ be the standard deviation. Then we have the following : $$\sigma^2 = \langle x_i^2 \rangle - \langle x_i\rangle^2$$ In our example, we can say : $$\sigma = \sqrt{\langle x_i^2\rangle}$$ The term on the right is often referred to as root mean squared distance in random walk and other problems of the sort. It is often interpreted as, if we repeat the experiment many many times, and take the squares of the final outcome, and average it, and then take the square root, our average outcome is $\sigma.$ What I know is, the likelihood of getting a data point is maximum between $+\sigma$ and $-\sigma$ i.e. within one standard deviation of the mean with a likelihood of around $70 $ percent. However, I still don't understand why many authors, interpret the root mean squared distance to be the average distance where we find the final answer. To me, the root mean squared distance is actually the boundary of the region (strip) where we are most likely to obtain our results. However, even though we are likely to obtain our data within the root mean squared distance, or the standard deviation, we do find many data points outside of this range. If we take an average of all these distances where we happen to find the range, it does lie around the standard deviation. Is this alternate interpretation of standard deviation correct? Normally standard deviation marks the boundary of the region in which, we are most likely to obtain the outcomes. However, it is also the average distance from the mean, where we expect our outcomes to be. This is usually the description of the root mean squared position, but in this instance, it is equivalent to the standard deviation. In random walk, most of our walkers, about $70$ percent of them, are found within the region bounded by $\pm \sigma.$ These walkers have taken more steps in one direction compared to the other. Since $\sigma \approx  \sqrt{n}$ , the difference in steps for 70 percent of walkers is less than $\sqrt{n}$ . However, for the rest of the walkers, about 30 percent of them, this difference is more than $\sqrt{n}$ and can be enormously large. So, we have 70 percent of walkers with a small difference in steps and a small no. of walkers with a large difference in steps. The average difference thus happens to lie around the standard deviation, and so it is often interpreted as the average distance where we happen to find our walker. Is this reasoning correct?","I've come across many articles that describe standard deviation to be a measure of how much spread out our distribution is. In other words, it is a measure of how far away from the mean, we expect a data point to land. Now, imagine we have a distribution of random variables, like in the case of a symmetric random walk. The mean of the distribution is obviously . So we can write . In this case, let be the standard deviation. Then we have the following : In our example, we can say : The term on the right is often referred to as root mean squared distance in random walk and other problems of the sort. It is often interpreted as, if we repeat the experiment many many times, and take the squares of the final outcome, and average it, and then take the square root, our average outcome is What I know is, the likelihood of getting a data point is maximum between and i.e. within one standard deviation of the mean with a likelihood of around percent. However, I still don't understand why many authors, interpret the root mean squared distance to be the average distance where we find the final answer. To me, the root mean squared distance is actually the boundary of the region (strip) where we are most likely to obtain our results. However, even though we are likely to obtain our data within the root mean squared distance, or the standard deviation, we do find many data points outside of this range. If we take an average of all these distances where we happen to find the range, it does lie around the standard deviation. Is this alternate interpretation of standard deviation correct? Normally standard deviation marks the boundary of the region in which, we are most likely to obtain the outcomes. However, it is also the average distance from the mean, where we expect our outcomes to be. This is usually the description of the root mean squared position, but in this instance, it is equivalent to the standard deviation. In random walk, most of our walkers, about percent of them, are found within the region bounded by These walkers have taken more steps in one direction compared to the other. Since , the difference in steps for 70 percent of walkers is less than . However, for the rest of the walkers, about 30 percent of them, this difference is more than and can be enormously large. So, we have 70 percent of walkers with a small difference in steps and a small no. of walkers with a large difference in steps. The average difference thus happens to lie around the standard deviation, and so it is often interpreted as the average distance where we happen to find our walker. Is this reasoning correct?",0 \langle x_i \rangle = 0  \sigma \sigma^2 = \langle x_i^2 \rangle - \langle x_i\rangle^2 \sigma = \sqrt{\langle x_i^2\rangle} \sigma. +\sigma -\sigma 70  70 \pm \sigma. \sigma \approx  \sqrt{n} \sqrt{n} \sqrt{n},"['probability', 'statistics', 'probability-distributions', 'random-walk', 'standard-deviation']"
88,"I have a square, and place three dots along the 4 edges at random. What is the probability that the dots lie on distinct edges?","I have a square, and place three dots along the 4 edges at random. What is the probability that the dots lie on distinct edges?",,"The correct answer is listed as (3/4) * (1/2) = 3/8. The reasoning is because it doesn't matter where you put the first dot, but after you put the first dot, it is 3/4 chance of a different edge, and then 1/2 chance of another different edge. However, if I think about it from a purely combinatorics way, there are ""4"" ways that three dots can be arranged on the square in which all dots are on distinct edges. There are then 12 ways that two dots can be on one edge and the third dot is on another edge (4 edges to put two dots, multiplied by 3 possible edges to put the third dot). Finally, there are 4 ways to put all three dots onto a single edge. This gives us (4/20) probability where the three dots are on distinct edges. This should work since each dot is independent of the previous dot and we can assume a uniform probability distribution. Why are these two values different?","The correct answer is listed as (3/4) * (1/2) = 3/8. The reasoning is because it doesn't matter where you put the first dot, but after you put the first dot, it is 3/4 chance of a different edge, and then 1/2 chance of another different edge. However, if I think about it from a purely combinatorics way, there are ""4"" ways that three dots can be arranged on the square in which all dots are on distinct edges. There are then 12 ways that two dots can be on one edge and the third dot is on another edge (4 edges to put two dots, multiplied by 3 possible edges to put the third dot). Finally, there are 4 ways to put all three dots onto a single edge. This gives us (4/20) probability where the three dots are on distinct edges. This should work since each dot is independent of the previous dot and we can assume a uniform probability distribution. Why are these two values different?",,"['probability', 'combinatorics', 'statistics']"
89,Understanding the confidence interval and statistical significance,Understanding the confidence interval and statistical significance,,"I am struggling to understand confidence intervals and their relationships to a null hypothesis. The basic definition of the confidence interval is: (1−α), where α is the statistical significance. So let's say I have two cases: I've allocated a 70 percent confidence level of meeting the probability of my null hypothesis, this means I have a statistical significance of of .30. I've allocated a 95 percent confidence level of meeting the probability of my null hypothesis. α = .05. Is it always better to have the case of a 95 percent confidence level, as I have the higher probability of not rejecting my null hypothesis? With the 70 percent confidence region, I always have a higher probably of falling outside the (1-α) region which rejects my null hypothesis. To me having a 95 percent confidence is always better. Is there a reason to ever prefer 70 percent confidence interval? Would the 95 percent confidence scenario require less resources to sample from?","I am struggling to understand confidence intervals and their relationships to a null hypothesis. The basic definition of the confidence interval is: (1−α), where α is the statistical significance. So let's say I have two cases: I've allocated a 70 percent confidence level of meeting the probability of my null hypothesis, this means I have a statistical significance of of .30. I've allocated a 95 percent confidence level of meeting the probability of my null hypothesis. α = .05. Is it always better to have the case of a 95 percent confidence level, as I have the higher probability of not rejecting my null hypothesis? With the 70 percent confidence region, I always have a higher probably of falling outside the (1-α) region which rejects my null hypothesis. To me having a 95 percent confidence is always better. Is there a reason to ever prefer 70 percent confidence interval? Would the 95 percent confidence scenario require less resources to sample from?",,"['probability', 'statistics', 'confidence-interval']"
90,multiplication principle and permutation rule; when to use what,multiplication principle and permutation rule; when to use what,,"Problem: You have CDs of which n1= # of classical, n2= # of rocks, n3= # of pop. How many ways can we place the CDs on a rack but keep the genres together? The Answer is: Because there are n1 ways to order classical, n1i (n1 factorial), similarly we have n2i, n3i. And because there are 3 different ways to order classical, rock and pop, we want to multiply by 3 factorial. The answer is (3!) (n1!) (n2!)*(n3!) MY QUESTION: In this problem, the order matters, but it doesn't specify which genre should come first or second, or third. But since the order matters , can we still apply the permutation rule? For instance, r = 3 since there are 3 ways to order 3 genres. We can say the total # of ways to place the CDs and keeping the genres together are: Permutation(n1 and r=3*Permutation(n2 and r=2)*Permutation(n3=r=1) Since the problem didn't specify which genre will come first or second, we don't know which of n1,n2, or n3 will get r=3 or 2 or 1, so I understand this way isn't correct, but I'm struggling to understand when to use Permutation rule and when to use simply just multiplication principle. Experiment: I assigned random numbers to n1,n2,n3 (n1=5,n2=6, n3=7) and tried both ways and the correct way ( 3! (n1!) (n2!) (n3!)) shows a lot more ways then using the permutation rule. 3!(5!)(6!)(7!) vs. (5!/2!) (6!/4!)*(7!/6!) Can someone help me understand what I'm missing?","Problem: You have CDs of which n1= # of classical, n2= # of rocks, n3= # of pop. How many ways can we place the CDs on a rack but keep the genres together? The Answer is: Because there are n1 ways to order classical, n1i (n1 factorial), similarly we have n2i, n3i. And because there are 3 different ways to order classical, rock and pop, we want to multiply by 3 factorial. The answer is (3!) (n1!) (n2!)*(n3!) MY QUESTION: In this problem, the order matters, but it doesn't specify which genre should come first or second, or third. But since the order matters , can we still apply the permutation rule? For instance, r = 3 since there are 3 ways to order 3 genres. We can say the total # of ways to place the CDs and keeping the genres together are: Permutation(n1 and r=3*Permutation(n2 and r=2)*Permutation(n3=r=1) Since the problem didn't specify which genre will come first or second, we don't know which of n1,n2, or n3 will get r=3 or 2 or 1, so I understand this way isn't correct, but I'm struggling to understand when to use Permutation rule and when to use simply just multiplication principle. Experiment: I assigned random numbers to n1,n2,n3 (n1=5,n2=6, n3=7) and tried both ways and the correct way ( 3! (n1!) (n2!) (n3!)) shows a lot more ways then using the permutation rule. 3!(5!)(6!)(7!) vs. (5!/2!) (6!/4!)*(7!/6!) Can someone help me understand what I'm missing?",,"['probability', 'statistics', 'permutations']"
91,Probability that one weighted mean of iid random variables is greater than the other,Probability that one weighted mean of iid random variables is greater than the other,,"I read somewhere that if $X_1,\dots, X_n,Y_1,\dots,Y_m$ are all i.i.d. and admit probability densities w.r.t the Lebesgue measure and we choose weights $\omega_1,\dots,\omega_n,\rho_1,\dots,\rho_m$ such that $\sum_{i=1}^n\omega_i=\sum_{i=1}^m\rho_i=1$ , we have: $$\mathbb{P}\left(\sum_{i=1}^n\omega_iX_i\leq \sum_{i=1}^m\rho_iY_i\right)=1/2.$$ I have tested this numerically and it seems to hold, but I cannot seem to prove it, does someone have an idea on how to do this?","I read somewhere that if are all i.i.d. and admit probability densities w.r.t the Lebesgue measure and we choose weights such that , we have: I have tested this numerically and it seems to hold, but I cannot seem to prove it, does someone have an idea on how to do this?","X_1,\dots, X_n,Y_1,\dots,Y_m \omega_1,\dots,\omega_n,\rho_1,\dots,\rho_m \sum_{i=1}^n\omega_i=\sum_{i=1}^m\rho_i=1 \mathbb{P}\left(\sum_{i=1}^n\omega_iX_i\leq \sum_{i=1}^m\rho_iY_i\right)=1/2.","['probability', 'statistics']"
92,Need help in understanding how to Calculate Estimation and Variance,Need help in understanding how to Calculate Estimation and Variance,,"I have this problem at hand and have no idea on how to approach it. Any leads/solution would be appreciated. You roll a fair $6$ -sided die, and flip a coin n times where n is the number on the die. If $H$ refers to the number of heads observed after n coin flips, find $E[H|n]$ and $\operatorname{Var}(H|n)$ for $n$ in set ${1,2,3,4,5,6}$ Find $E[H]$ and $\operatorname{Var}(H|n)$","I have this problem at hand and have no idea on how to approach it. Any leads/solution would be appreciated. You roll a fair -sided die, and flip a coin n times where n is the number on the die. If refers to the number of heads observed after n coin flips, find and for in set Find and","6 H E[H|n] \operatorname{Var}(H|n) n {1,2,3,4,5,6} E[H] \operatorname{Var}(H|n)","['probability', 'statistics', 'expected-value', 'variance']"
93,Expectation of random variable with two vectors,Expectation of random variable with two vectors,,"I am reading this paper ""Continuous Diffusion Analysis"" and in page 7 there are a next formula $\mathbb{E}_{x,y}[d_S(x,y)]=\dfrac{1}{4}\sum_{i=0}^{n-1}\int^{1}_{-1}\int^{1}_{-1}|sgn(x_i)-sgn(y_i)|dx_idy_i$ . I am trying to obtain this formula using the formula $\mathbb{E}[z]=\int_{\mathbb{R}}zf(z)dz$ presented in ""Absolutely continuous case"" of wikipedia , but I do not understand how the authors of ""Continuous Diffusion Analysis"" reach that formula. For now, considering $z=d_S{(x,y)}$ follows the uniform distribution, I think that the probability density function of $d_S{(x,y)}$ is $\dfrac{1}{2n}$ . Then according to wikipedia $\mathbb{E}[z]=\int_{\mathbb{R}}zf(z)dz=\mathbb{E}[z]=\int_{\mathbb{R}}\dfrac{1}{2n}d_S(x,y)dz$ . Could you help to obtain that formula with an explanation, please? For example, how they go from $\mathbb{R}$ to $-1, 1$ limits?","I am reading this paper ""Continuous Diffusion Analysis"" and in page 7 there are a next formula . I am trying to obtain this formula using the formula presented in ""Absolutely continuous case"" of wikipedia , but I do not understand how the authors of ""Continuous Diffusion Analysis"" reach that formula. For now, considering follows the uniform distribution, I think that the probability density function of is . Then according to wikipedia . Could you help to obtain that formula with an explanation, please? For example, how they go from to limits?","\mathbb{E}_{x,y}[d_S(x,y)]=\dfrac{1}{4}\sum_{i=0}^{n-1}\int^{1}_{-1}\int^{1}_{-1}|sgn(x_i)-sgn(y_i)|dx_idy_i \mathbb{E}[z]=\int_{\mathbb{R}}zf(z)dz z=d_S{(x,y)} d_S{(x,y)} \dfrac{1}{2n} \mathbb{E}[z]=\int_{\mathbb{R}}zf(z)dz=\mathbb{E}[z]=\int_{\mathbb{R}}\dfrac{1}{2n}d_S(x,y)dz \mathbb{R} -1, 1",['statistics']
94,Second derivative of a log function,Second derivative of a log function,,"I am trying to calculate the Fisher Information (covariance matrix) for categorical random variable. I can calculate the first and the second derivatives of the following function, but to calculate their joint second derivative, I got lost. Can anyone explain how to derive off diagonal entries of covariance matrix? $\frac{dev^2L}{dev_pdev_(1-p)}$ $\log(p) + \log(1-p)$ =","I am trying to calculate the Fisher Information (covariance matrix) for categorical random variable. I can calculate the first and the second derivatives of the following function, but to calculate their joint second derivative, I got lost. Can anyone explain how to derive off diagonal entries of covariance matrix? =",\frac{dev^2L}{dev_pdev_(1-p)} \log(p) + \log(1-p),"['calculus', 'statistics']"
95,maximum-likelihood function for the SST distribution,maximum-likelihood function for the SST distribution,,"The SST distribution is a reparametrization of $ST3$ , which is the skew t-student type 3. Below is some information. Let $Z_0 \sim ST3 (0, 1, \nu, \tau)$ and $Y = \mu + \sigma\left(\frac{Z_0 - m}{s}\right)$ , where, \begin{equation} m = E(Z_0) = \frac{2\tau^\frac{1}{2}(\nu-\nu^{-1})}{(\tau - 1)B\left(\frac{1}{2},\frac{\tau}{2}\right)} \end{equation} \begin{equation} s^2 = Var(Z_0) = \frac{\tau}{\tau - 2}(\nu^2 + \nu^{-2} - 1) - m^2 \end{equation} Hence, $Y = \mu_0 + \sigma_0Z_0$ , where $\mu_0 = \mu - \frac{\sigma m}{s}$ e $\sigma_0 = \frac{\sigma}{s}$ , and so $Y \sim ST3(\mu_0, \sigma_0, \nu, \tau)$ with $E(Y) = \mu$ and $Var(Y) = \sigma^2$ for $\tau > 2$ . Let $Y \sim SST(\mu, \sigma, \nu, \tau) = ST3(\mu_0, \sigma_0, \nu, \tau)$ for $\tau > 2$ . The pdf of the skew Student t distribution, denoted by $Y \sim SST(\mu, \sigma, \nu, \tau)$ , is given by: \begin{equation} f_Y(y|\mu, \sigma, \nu, \tau) = \left\{ \begin{array}{rcl} \frac{c}{\sigma_0}\left(1 + \frac{\nu^2 z^2}{\tau} \right)^{\frac{-(\tau + 1)}{2}} & \mbox{if} & y<\mu_0 \\ \frac{c}{\sigma_0}\left(1 + \frac{z^2}{\nu^2 \tau} \right)^{\frac{-(\tau + 1)}{2}} & \mbox{if} & y\geq \mu_0  \end{array}\right. \end{equation} for $-\infty < y < \infty$ , where $-\infty < \mu < \infty$ , $\sigma >0$ , $\nu > 0$ and $\tau > 2$ and where $z=\frac{(y-\mu_0)}{\sigma_0}$ , $\mu_0 = \mu - \frac{\sigma m}{s}$ , $\sigma_0 = \frac{\sigma}{s}$ and $c = 2\nu [(1+\nu^2)B\left(\frac{1}{2},\frac{\tau}{2}\right)\tau^{\frac{1}{2}}]^{-1}$ . Note that $E(Y) = \mu$ and $Var(Y) = \sigma^2$ and the moment based skewness and excess kurtosis of $SST(\mu, \sigma, \nu, \tau)$ are the same as for $ST3(\mu_0, \sigma_0, \nu, \tau)$ , and hence the same as for $ST3(0, 1, \nu, \tau)$ , depending only on $\nu$ and $\tau$ . How would the likelihood function of this distribution be expressed, according to the parameters? It is known that the link functions for $(\mu, \sigma, \nu, \tau)$ is the $identity$ , $log$ , $log$ , and $log-2$ .","The SST distribution is a reparametrization of , which is the skew t-student type 3. Below is some information. Let and , where, Hence, , where e , and so with and for . Let for . The pdf of the skew Student t distribution, denoted by , is given by: for , where , , and and where , , and . Note that and and the moment based skewness and excess kurtosis of are the same as for , and hence the same as for , depending only on and . How would the likelihood function of this distribution be expressed, according to the parameters? It is known that the link functions for is the , , , and .","ST3 Z_0 \sim ST3 (0, 1, \nu, \tau) Y = \mu + \sigma\left(\frac{Z_0 - m}{s}\right) \begin{equation}
m = E(Z_0) = \frac{2\tau^\frac{1}{2}(\nu-\nu^{-1})}{(\tau - 1)B\left(\frac{1}{2},\frac{\tau}{2}\right)}
\end{equation} \begin{equation}
s^2 = Var(Z_0) = \frac{\tau}{\tau - 2}(\nu^2 + \nu^{-2} - 1) - m^2
\end{equation} Y = \mu_0 + \sigma_0Z_0 \mu_0 = \mu - \frac{\sigma m}{s} \sigma_0 = \frac{\sigma}{s} Y \sim ST3(\mu_0, \sigma_0, \nu, \tau) E(Y) = \mu Var(Y) = \sigma^2 \tau > 2 Y \sim SST(\mu, \sigma, \nu, \tau) = ST3(\mu_0, \sigma_0, \nu, \tau) \tau > 2 Y \sim SST(\mu, \sigma, \nu, \tau) \begin{equation}
f_Y(y|\mu, \sigma, \nu, \tau) = \left\{ \begin{array}{rcl}
\frac{c}{\sigma_0}\left(1 + \frac{\nu^2 z^2}{\tau} \right)^{\frac{-(\tau + 1)}{2}} & \mbox{if}
& y<\mu_0 \\ \frac{c}{\sigma_0}\left(1 + \frac{z^2}{\nu^2 \tau} \right)^{\frac{-(\tau + 1)}{2}} & \mbox{if} & y\geq \mu_0 
\end{array}\right.
\end{equation} -\infty < y < \infty -\infty < \mu < \infty \sigma >0 \nu > 0 \tau > 2 z=\frac{(y-\mu_0)}{\sigma_0} \mu_0 = \mu - \frac{\sigma m}{s} \sigma_0 = \frac{\sigma}{s} c = 2\nu [(1+\nu^2)B\left(\frac{1}{2},\frac{\tau}{2}\right)\tau^{\frac{1}{2}}]^{-1} E(Y) = \mu Var(Y) = \sigma^2 SST(\mu, \sigma, \nu, \tau) ST3(\mu_0, \sigma_0, \nu, \tau) ST3(0, 1, \nu, \tau) \nu \tau (\mu, \sigma, \nu, \tau) identity log log log-2","['probability', 'statistics', 'probability-distributions', 'regression', 'maximum-likelihood']"
96,Minimal Sufficient Statistics theorem 6.6.5 C&B proof,Minimal Sufficient Statistics theorem 6.6.5 C&B proof,,"The theorem goes as follows: Suppose the family of densities $\{f_0(x), .., f_k(0)\}$ all have common support. Then, (a) $$T(X) = \Big(\frac{f_1(X)}{f_0(X)}, \frac{f_2(X)}{f_0(X)}, .., \frac{f_k(X)}{f_0(X)}\Big)$$ is minimal sufficient for the family above. (b) If $\mathcal{F}$ is a family of densities with common support, and $\quad$ i) $f_i(x) \in \mathcal{F}, i= 0, 1, .., k$ $\quad$ ii) T(x) is sufficient for $\mathcal{F}$ then $T(x)$ is minimal sufficient for $\mathcal{F}$ . I already proved (a), but the textbook (Casella-Berger exercise 6.28) suggests to show that any sufficient statistic of $\mathcal{F}$ is a function of $T(x)$ defined in (a) somehow. I was thinking of picking a random set of densities from $\mathcal{F}$ , assuming that $T(x) = T(y)$ , and then showing that some arbitrary sufficient statistic $T'(x) = T'(y)$ for $\mathcal{F}$ is implied. But somehow got stuck.","The theorem goes as follows: Suppose the family of densities all have common support. Then, (a) is minimal sufficient for the family above. (b) If is a family of densities with common support, and i) ii) T(x) is sufficient for then is minimal sufficient for . I already proved (a), but the textbook (Casella-Berger exercise 6.28) suggests to show that any sufficient statistic of is a function of defined in (a) somehow. I was thinking of picking a random set of densities from , assuming that , and then showing that some arbitrary sufficient statistic for is implied. But somehow got stuck.","\{f_0(x), .., f_k(0)\} T(X) = \Big(\frac{f_1(X)}{f_0(X)}, \frac{f_2(X)}{f_0(X)}, .., \frac{f_k(X)}{f_0(X)}\Big) \mathcal{F} \quad f_i(x) \in \mathcal{F}, i= 0, 1, .., k \quad \mathcal{F} T(x) \mathcal{F} \mathcal{F} T(x) \mathcal{F} T(x) = T(y) T'(x) = T'(y) \mathcal{F}","['probability', 'statistics', 'statistical-inference']"
97,What is the minimum number of tests to achieve statistical significance?,What is the minimum number of tests to achieve statistical significance?,,I'm dealing with a situation where in a large manufacturing facility we have approximately $2000$ plumbing fittings of the same make and model. $3$ of those fitting have failed within the last year. Each causing major property damage. We suspect that the plumbing components suffered degradation and we want to test a sample of the remaining plumbing components to see how wide spread the issue is (if at all). What is the best way to decide how big of a sample we should choose so that we do not under test or over test the installed components. Any idea where to begin?,I'm dealing with a situation where in a large manufacturing facility we have approximately plumbing fittings of the same make and model. of those fitting have failed within the last year. Each causing major property damage. We suspect that the plumbing components suffered degradation and we want to test a sample of the remaining plumbing components to see how wide spread the issue is (if at all). What is the best way to decide how big of a sample we should choose so that we do not under test or over test the installed components. Any idea where to begin?,2000 3,['statistics']
98,Logarithm of normal distribution is constant plus Chi squared?,Logarithm of normal distribution is constant plus Chi squared?,,"I'm reading Bayesian data analysis . On page 85 it is stated that ""In the d dimensional normal distribution, the logarithm of the density function is a constant plus a $χ^2_d$ distribution divided by −2."" Can someone clarify how to derive this? For example, let's use $d = 1$ . Then the logarithm of the density function of the normal distribution is: $$ \begin{align} ln(p(\theta)) &= ln\left({\frac {1}{\sigma {\sqrt {2\pi }}}}e^{-{\frac {1}{2}}\left({\frac {\theta-\mu }{\sigma }}\right)^{2}}\right) \\ &= ln\left(\frac {1}{\sigma {\sqrt {2\pi }}}\right) -{\frac {1}{2}}\left({\frac {\theta-\mu }{\sigma }}\right)^{2} \\ &= C -{\frac {1}{2}}\left({\frac {\theta-\mu }{\sigma }}\right)^{2} \end{align} $$ So the above statement would imply that $\left({\frac {\theta-\mu }{\sigma }}\right)^{2}$ is a $χ^2_1$ distribution. However, when I look up that distribution I get: $$ \begin{align} χ^2_1(\theta) &= {\frac {1}{2^{d/2}\Gamma (d/2)}}\;\theta^{d/2-1}e^{-\theta/2} \\ &= {\frac {1}{2^{1/2}\Gamma (1/2)}}\;\theta^{1/2-1}e^{-\theta/2} \\ &= \frac{1}{\sqrt{2\pi}}\;\theta^{-1/2}e^{-\theta/2} \end{align} $$ I do not see how these two things are the same. Especially the exponent of theta seems to behave very differently from what is in essence a quadratic formula in theta above.","I'm reading Bayesian data analysis . On page 85 it is stated that ""In the d dimensional normal distribution, the logarithm of the density function is a constant plus a distribution divided by −2."" Can someone clarify how to derive this? For example, let's use . Then the logarithm of the density function of the normal distribution is: So the above statement would imply that is a distribution. However, when I look up that distribution I get: I do not see how these two things are the same. Especially the exponent of theta seems to behave very differently from what is in essence a quadratic formula in theta above.","χ^2_d d = 1 
\begin{align}
ln(p(\theta)) &= ln\left({\frac {1}{\sigma {\sqrt {2\pi }}}}e^{-{\frac {1}{2}}\left({\frac {\theta-\mu }{\sigma }}\right)^{2}}\right) \\
&= ln\left(\frac {1}{\sigma {\sqrt {2\pi }}}\right) -{\frac {1}{2}}\left({\frac {\theta-\mu }{\sigma }}\right)^{2} \\
&= C -{\frac {1}{2}}\left({\frac {\theta-\mu }{\sigma }}\right)^{2}
\end{align}
 \left({\frac {\theta-\mu }{\sigma }}\right)^{2} χ^2_1 
\begin{align}
χ^2_1(\theta) &= {\frac {1}{2^{d/2}\Gamma (d/2)}}\;\theta^{d/2-1}e^{-\theta/2} \\
&= {\frac {1}{2^{1/2}\Gamma (1/2)}}\;\theta^{1/2-1}e^{-\theta/2} \\
&= \frac{1}{\sqrt{2\pi}}\;\theta^{-1/2}e^{-\theta/2}
\end{align}
","['statistics', 'normal-distribution', 'bayesian', 'chi-squared']"
99,Would you ‘buy’ a prediction from Prof. Gott?,Would you ‘buy’ a prediction from Prof. Gott?,,"As a young man Mr Gott visits Berlin in 1969. He’s surprised that he cannot cross into East Berlin since there is a wall separating the two halves of the city. He’s told that the wall was erected 8 years previously. He reasons that : The wall will have a finite lifespan; his ignorance means that he arrives uniformly at random at some time in the lifespan of the wall. Since only 5% of the time one would arrive in the first or last 2.5% of the lifespan of the wall he asserts that with 95% confidence the wall will survive between 8/0.975 ≈ 8.2 and 8/0.025 = 320 years. In 1989 the now Professor Gott is pleased to find that his prediction was correct and promotes his prediction method in elite journals. This ‘delta-t’ method is widely adopted and used to form predictions in a range of scenarios about which researchers are ‘totally ignorant’. Would you ‘buy’ a prediction from Prof. Gott? Explain carefully your reasoning. My answer to this question is no, I would not buy a prediction from Prof. Gott as his ""confidence interval"" is very large and hence it was not too accurate. But how exactly would one go about explaining this more rigourously?","As a young man Mr Gott visits Berlin in 1969. He’s surprised that he cannot cross into East Berlin since there is a wall separating the two halves of the city. He’s told that the wall was erected 8 years previously. He reasons that : The wall will have a finite lifespan; his ignorance means that he arrives uniformly at random at some time in the lifespan of the wall. Since only 5% of the time one would arrive in the first or last 2.5% of the lifespan of the wall he asserts that with 95% confidence the wall will survive between 8/0.975 ≈ 8.2 and 8/0.025 = 320 years. In 1989 the now Professor Gott is pleased to find that his prediction was correct and promotes his prediction method in elite journals. This ‘delta-t’ method is widely adopted and used to form predictions in a range of scenarios about which researchers are ‘totally ignorant’. Would you ‘buy’ a prediction from Prof. Gott? Explain carefully your reasoning. My answer to this question is no, I would not buy a prediction from Prof. Gott as his ""confidence interval"" is very large and hence it was not too accurate. But how exactly would one go about explaining this more rigourously?",,"['probability', 'statistics']"
