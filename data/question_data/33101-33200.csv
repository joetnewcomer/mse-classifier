,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Is the distribution of a product of M iid uniform random variables really Log Normal?,Is the distribution of a product of M iid uniform random variables really Log Normal?,,"Conventional wisdom says yes or mostly.  But consider the following simple derivation: Let $y = \prod_{i=1}^M x_i$ where $x_i\sim U(0,1)$.  Then from independence, $E[y] = 2^{-M}$. Now, if we let $z = \ln y = \sum_{i=0}^M \ln x_i$ we can use the central limit theorem to claim that $z\sim Norm(\mu=-M,\sigma^2 = M)$ where we get $\mu = M \int_0^1 \ln x dx = -M$ and $\sigma^2 = M\int_0^1 (\ln x + 1)^2 dx = M$ from the standard change-of-variable equations for $\ln x$ combined with the CLT.  This leads to a Log-Normal distribution of y as: $$f_Y(y) = \frac{1}{y\sqrt{2\pi M}}e^{-\frac{(\ln y +M)^2}{2M}} $$ Great! We got a distribution for $y$.  But if you try and calculate the expectation now, you get $e^{\mu + \frac{\sigma^2}{2}} = e^{-M/2} \neq 2^{-M}$.  What's worse, if you look at the asymptotic behavior, $e^{-M/2} \gg 2^{-M}$ as $M\rightarrow \infty$. This doesn't make sense to me.  How can $z$ be considered ""normal"" in the limit of large numbers if it leads to a divergent systematic deviation in the calculation of the expectation of $y$? Is this an artifact of the finite support in $x_i$? If so, how to take it into account? More importantly, if $y$ is not really Log-Normal, to what degree are calculations of other properties valid? Ultimately, I need to be able to predict the most probable value (mode) of $y$.  Can I quantify the extent to which $y$ is not quite Log Normal and present some kind of bounds on the accuracy of my calculations?","Conventional wisdom says yes or mostly.  But consider the following simple derivation: Let $y = \prod_{i=1}^M x_i$ where $x_i\sim U(0,1)$.  Then from independence, $E[y] = 2^{-M}$. Now, if we let $z = \ln y = \sum_{i=0}^M \ln x_i$ we can use the central limit theorem to claim that $z\sim Norm(\mu=-M,\sigma^2 = M)$ where we get $\mu = M \int_0^1 \ln x dx = -M$ and $\sigma^2 = M\int_0^1 (\ln x + 1)^2 dx = M$ from the standard change-of-variable equations for $\ln x$ combined with the CLT.  This leads to a Log-Normal distribution of y as: $$f_Y(y) = \frac{1}{y\sqrt{2\pi M}}e^{-\frac{(\ln y +M)^2}{2M}} $$ Great! We got a distribution for $y$.  But if you try and calculate the expectation now, you get $e^{\mu + \frac{\sigma^2}{2}} = e^{-M/2} \neq 2^{-M}$.  What's worse, if you look at the asymptotic behavior, $e^{-M/2} \gg 2^{-M}$ as $M\rightarrow \infty$. This doesn't make sense to me.  How can $z$ be considered ""normal"" in the limit of large numbers if it leads to a divergent systematic deviation in the calculation of the expectation of $y$? Is this an artifact of the finite support in $x_i$? If so, how to take it into account? More importantly, if $y$ is not really Log-Normal, to what degree are calculations of other properties valid? Ultimately, I need to be able to predict the most probable value (mode) of $y$.  Can I quantify the extent to which $y$ is not quite Log Normal and present some kind of bounds on the accuracy of my calculations?",,"['probability', 'probability-theory', 'probability-distributions', 'law-of-large-numbers', 'independence']"
1,Asymptotics of sum of binomial distributions,Asymptotics of sum of binomial distributions,,"Definition 1: For any random variable $X$, we define $\mathrm{Bin}(p,X)$ as a variable with binomial distribution having parameters $p$ and $X$. Definition 2: For all $i \in \mathbb{N}$, define recursively the following random variables, $$X_{i+1} = \mathrm{Bin}(p, X_{i}^1) + \mathrm{Bin}(1-p, X_{i}^2),$$ where the two random variables ""$\mathrm{Bin}$"" in the sum are independent for every $i\in \mathbb{N}$ and where $X_{i}^1$ and $X_{i}^2$ are independent and distributed the same as $X_i$. The initial random variable $X_0$ is given and it has expectation $\lambda>0$. Question 1: Is the probability distribution of $X_\infty$ well defined and unique? Question 2: If yes, does the probability distribution of $X_\infty$ solve the following equation, $X_\infty = \mathrm{Bin}(p, X_{\infty}^1) + \mathrm{Bin}(1-p, X_{\infty}^2)$, where $X_\infty^1$ and $X_\infty^2$ have the same probability distribution of $X_\infty$ and the variables in the sum are independent? Clearly for all $i\in \mathbb{N}$, $\mathbb{E}[X_i] = \mathbb{E}[X_0]=\lambda$. This question is related to my other question, Solution of equation of binomial random variables , where the equation $X = \mathrm{Bin}(p, X^1) + \mathrm{Bin}(1-p, X^2)$ has been solved, under the assumption that $X$, $X^1$ and $X^2$ are independent and identically distributed.","Definition 1: For any random variable $X$, we define $\mathrm{Bin}(p,X)$ as a variable with binomial distribution having parameters $p$ and $X$. Definition 2: For all $i \in \mathbb{N}$, define recursively the following random variables, $$X_{i+1} = \mathrm{Bin}(p, X_{i}^1) + \mathrm{Bin}(1-p, X_{i}^2),$$ where the two random variables ""$\mathrm{Bin}$"" in the sum are independent for every $i\in \mathbb{N}$ and where $X_{i}^1$ and $X_{i}^2$ are independent and distributed the same as $X_i$. The initial random variable $X_0$ is given and it has expectation $\lambda>0$. Question 1: Is the probability distribution of $X_\infty$ well defined and unique? Question 2: If yes, does the probability distribution of $X_\infty$ solve the following equation, $X_\infty = \mathrm{Bin}(p, X_{\infty}^1) + \mathrm{Bin}(1-p, X_{\infty}^2)$, where $X_\infty^1$ and $X_\infty^2$ have the same probability distribution of $X_\infty$ and the variables in the sum are independent? Clearly for all $i\in \mathbb{N}$, $\mathbb{E}[X_i] = \mathbb{E}[X_0]=\lambda$. This question is related to my other question, Solution of equation of binomial random variables , where the equation $X = \mathrm{Bin}(p, X^1) + \mathrm{Bin}(1-p, X^2)$ has been solved, under the assumption that $X$, $X^1$ and $X^2$ are independent and identically distributed.",,"['probability', 'probability-distributions', 'stochastic-processes', 'random-variables', 'random']"
2,Game Theory/Bayesian approach to a bluffing game,Game Theory/Bayesian approach to a bluffing game,,"Two players play the following card game with a deck consisting of (A,2,3,4,5). A dollar is placed in the pot by some third party, and player 1 is dealt a card. If it is an A, he has a winning card, otherwise he has a losing card. Player 1 can decide whether to fold (conceding the dollar to player 2) or bet, by placing an additional dollar in the pot. If Player 1 bets, player 2 can decide to fold (conceding the pot to player 1) or call, by placing an additional dollar in the pot. If player 2 calls, player 1 reveals his card - if it is a A, he takes the pot, otherwise player 2 takes the pot. It's not hard to see that there's a Nash equilibrium where player 1 always bets if he has an ace, and bluffs 12.5% of the time if he doesn't. Player 2 calls 50% of player 1's bets. The long-run expectation is \$0.30/round for player 1, and \$0.70/round for player 2. However, in reality it is unlikely that both players will play the Nash equilibrium strategy (they may not be rational, they may not believe that the other player is rational, they may just be playing for fun, etc etc). From player 1's perspective, if player 2 calls a fraction $p$ of the time, then player 1 should always bluff if $p<0.5$ and never bluff if $p>0.5$, in order to maximize his own expectation. That is, the optimal bluffing frequency is $$B(p) = \begin{cases} 1 && p < 0.5 \\ 0 && p > 0.5\end{cases}$$ Now, player 1 might have a probability distribution $f(p)$ on player 2's calling frequency. In that case, it seems to make sense that the bluffing frequency for player 1 would be the probability-weighted average of the optimal action for each specific $p$ - $$p_{\rm Bluff} = \int_0^1 {B}(p) f(p) dp = \int_0^{0.5} f(p) dp \tag{1}$$ But that leads to the conclusion that if player 1 has an uninformative prior $f(p)=1$, he should bluff with frequency $p_{\rm Bluff} = 0.5$. That contrasts with my intuition that if you have no information about player 2's strategy, you should play the Nash equilibrium strategy. I'm concerned that equation (1) doesn't make any mention of the Nash equilibrium strategy at all - it seems that it should play a role, which makes me think that (1) cannot be correct. Which is it? Does game theory have anything to say about the situation where one player might not play optimally, but you don't know exactly how he plays? Is there a way of deriving the ""correct"" play if you have a probability distribution for your opponent's strategy?","Two players play the following card game with a deck consisting of (A,2,3,4,5). A dollar is placed in the pot by some third party, and player 1 is dealt a card. If it is an A, he has a winning card, otherwise he has a losing card. Player 1 can decide whether to fold (conceding the dollar to player 2) or bet, by placing an additional dollar in the pot. If Player 1 bets, player 2 can decide to fold (conceding the pot to player 1) or call, by placing an additional dollar in the pot. If player 2 calls, player 1 reveals his card - if it is a A, he takes the pot, otherwise player 2 takes the pot. It's not hard to see that there's a Nash equilibrium where player 1 always bets if he has an ace, and bluffs 12.5% of the time if he doesn't. Player 2 calls 50% of player 1's bets. The long-run expectation is \$0.30/round for player 1, and \$0.70/round for player 2. However, in reality it is unlikely that both players will play the Nash equilibrium strategy (they may not be rational, they may not believe that the other player is rational, they may just be playing for fun, etc etc). From player 1's perspective, if player 2 calls a fraction $p$ of the time, then player 1 should always bluff if $p<0.5$ and never bluff if $p>0.5$, in order to maximize his own expectation. That is, the optimal bluffing frequency is $$B(p) = \begin{cases} 1 && p < 0.5 \\ 0 && p > 0.5\end{cases}$$ Now, player 1 might have a probability distribution $f(p)$ on player 2's calling frequency. In that case, it seems to make sense that the bluffing frequency for player 1 would be the probability-weighted average of the optimal action for each specific $p$ - $$p_{\rm Bluff} = \int_0^1 {B}(p) f(p) dp = \int_0^{0.5} f(p) dp \tag{1}$$ But that leads to the conclusion that if player 1 has an uninformative prior $f(p)=1$, he should bluff with frequency $p_{\rm Bluff} = 0.5$. That contrasts with my intuition that if you have no information about player 2's strategy, you should play the Nash equilibrium strategy. I'm concerned that equation (1) doesn't make any mention of the Nash equilibrium strategy at all - it seems that it should play a role, which makes me think that (1) cannot be correct. Which is it? Does game theory have anything to say about the situation where one player might not play optimally, but you don't know exactly how he plays? Is there a way of deriving the ""correct"" play if you have a probability distribution for your opponent's strategy?",,"['probability', 'game-theory', 'gambling']"
3,How can this population extinct because of gender inequality?,How can this population extinct because of gender inequality?,,"This population has the properties as follows: (1) It is an isolated population, which means the individuals can only mate with others in this population. (2) It is a monogamy population, which means each individual should only has one mate. (3a) Each couple should give birth to N children. N is an integer. (3b)(alternative to 3a) Each couple gives birth to k children, and k follows a Poisson distribution: P(k)=$\frac{N^k}{k!}e^{-N}$. N can be a non-integer. (4) The length of breeding cycle in this population is constant and consistent from individual to individual. All the individuals only give birth at their fixed breeding age. (5) There is a gene called DOOM. If one spouse in a couple carries the DOOM gene, they will give birth to male children at the probability of Pm. A couple without DOOM has the same probability to give birth to male children and female children. (6) If one spouse in a couple carries the DOOM gene, their children will carry DOOM gene. (7) All the individuals can not distinguish those with DOOM from those without DOOM. (8) Initial conditions: The percentage of male DOOM carriers equals to female DOOM carriers, and is $q_0$. The percentage of male DOOM non-carriers equals to female DOOM non-carriers, and is $(1-2q_0)/2$. At the beginning, all the individuals are at their breeding age. [Question] In what condition given by N, Pm and $q_0$, this population will diminish gradually?","This population has the properties as follows: (1) It is an isolated population, which means the individuals can only mate with others in this population. (2) It is a monogamy population, which means each individual should only has one mate. (3a) Each couple should give birth to N children. N is an integer. (3b)(alternative to 3a) Each couple gives birth to k children, and k follows a Poisson distribution: P(k)=$\frac{N^k}{k!}e^{-N}$. N can be a non-integer. (4) The length of breeding cycle in this population is constant and consistent from individual to individual. All the individuals only give birth at their fixed breeding age. (5) There is a gene called DOOM. If one spouse in a couple carries the DOOM gene, they will give birth to male children at the probability of Pm. A couple without DOOM has the same probability to give birth to male children and female children. (6) If one spouse in a couple carries the DOOM gene, their children will carry DOOM gene. (7) All the individuals can not distinguish those with DOOM from those without DOOM. (8) Initial conditions: The percentage of male DOOM carriers equals to female DOOM carriers, and is $q_0$. The percentage of male DOOM non-carriers equals to female DOOM non-carriers, and is $(1-2q_0)/2$. At the beginning, all the individuals are at their breeding age. [Question] In what condition given by N, Pm and $q_0$, this population will diminish gradually?",,"['probability', 'probability-theory', 'stochastic-processes']"
4,Poisson point process (PPP) and Voronoi cells,Poisson point process (PPP) and Voronoi cells,,"Say we have a homogeneous PPP with rate $\lambda$ in the 2-D plane $\mathbb R^2$ . In one realization of the PPP we get the points $\phi=\{x_1,x_2,...,x_i,...\}$ . Now we generate the Voronoi cells with the $k$ nearest points ( $k$ order Voronoi cell WiKi , Demo ). Then consider the number of these cells in which a given point $x_i\in \phi$ takes part. Can we claim that the expected number of cells in which a point takes part is the same for any point $\{x_1,x_2,...,x_i,...\}$ ? It seems intuitive and I tried with crude simulation and it seems to hold. But I don't know how to define expectation because the points will change with each trial. Then also how do we take expectation of a area the PPP only defines probabilities of points. I think this problem might be Related to Correlations between neighboring Voronoi cells . Many thanks for any suggestions or a reference.","Say we have a homogeneous PPP with rate in the 2-D plane . In one realization of the PPP we get the points . Now we generate the Voronoi cells with the nearest points ( order Voronoi cell WiKi , Demo ). Then consider the number of these cells in which a given point takes part. Can we claim that the expected number of cells in which a point takes part is the same for any point ? It seems intuitive and I tried with crude simulation and it seems to hold. But I don't know how to define expectation because the points will change with each trial. Then also how do we take expectation of a area the PPP only defines probabilities of points. I think this problem might be Related to Correlations between neighboring Voronoi cells . Many thanks for any suggestions or a reference.","\lambda \mathbb R^2 \phi=\{x_1,x_2,...,x_i,...\} k k x_i\in \phi \{x_1,x_2,...,x_i,...\}","['probability', 'stochastic-processes', 'computational-geometry', 'discrete-geometry']"
5,The problem of the drunkard in a valley.,The problem of the drunkard in a valley.,,"We consider a Markov chain on a subset of positive integers $S =$ {$0, 1, 2, 3, .......N$}, with transition probabilities defined as follows: The chain jumps only one unit to the left or right. $p(i, j) = 0$ if  $|i - j|>1$ $p(i, i + 1) = (N - i) /N$ , for $i$ in {$1, 2, 3, ....., N-1$}. $p(i, i - 1) = i/N$ , for $i$ in {$1, 2, 3, ....., N-1$}. We assume that we have absorbing barriers at $0$ and $N$, so we have $p(0, 0) = p(N, N) = 1$. What is the expected time it takes for the chain to be absorbed at $0$ or $N$, starting at $i$ in {$0, 1, 2, 3, .......N$}? If $T_i$ is the time it takes for the chain to be absorbed at $0$ or $N$, when starting at $i$, what is $E(T_i)$? This Markov chain can be seen as a particular case of a birth and death chain, or as a one dimensional random walk with 2 absorbing barriers and probabilities varying from place to place. I would call this the problem of the drunken man in a valley. The closer he gets to the absorbing barriers (the top of the hill), less likely it is that he will continue towards them. Then what is the expected time of the drunkard to reach the top of the hills surrounding him? Main question. Is the expected time to absorption polynomial or exponential (in $N$)? Note that this problem is related to a class of problems of practical interest.","We consider a Markov chain on a subset of positive integers $S =$ {$0, 1, 2, 3, .......N$}, with transition probabilities defined as follows: The chain jumps only one unit to the left or right. $p(i, j) = 0$ if  $|i - j|>1$ $p(i, i + 1) = (N - i) /N$ , for $i$ in {$1, 2, 3, ....., N-1$}. $p(i, i - 1) = i/N$ , for $i$ in {$1, 2, 3, ....., N-1$}. We assume that we have absorbing barriers at $0$ and $N$, so we have $p(0, 0) = p(N, N) = 1$. What is the expected time it takes for the chain to be absorbed at $0$ or $N$, starting at $i$ in {$0, 1, 2, 3, .......N$}? If $T_i$ is the time it takes for the chain to be absorbed at $0$ or $N$, when starting at $i$, what is $E(T_i)$? This Markov chain can be seen as a particular case of a birth and death chain, or as a one dimensional random walk with 2 absorbing barriers and probabilities varying from place to place. I would call this the problem of the drunken man in a valley. The closer he gets to the absorbing barriers (the top of the hill), less likely it is that he will continue towards them. Then what is the expected time of the drunkard to reach the top of the hills surrounding him? Main question. Is the expected time to absorption polynomial or exponential (in $N$)? Note that this problem is related to a class of problems of practical interest.",,"['probability', 'markov-chains', 'random-walk']"
6,Prove Reverse Fatou's lemma,Prove Reverse Fatou's lemma,,"Question I am trying to prove the Reverse Fatou's lemma but I can't seem to get it. The statement is the following: Suppose that $(f_n)_{n \in \mathbb{N}}$ is a sequence of measurable functions and $g$ an integrable function such that $f_n \leq g$ for all $n \in \mathbb{N}$ . Then, $\limsup _{n \rightarrow \infty} \mu (f_n) = \mu ( \limsup _{n \rightarrow \infty} f_n)$ where $\mu$ is the integral on a specified measure space. Attempt We have a sequence $\lbrace f_k \rbrace$ in $\mathbb R$ and $E\subset \mathbb R$ . We know that $\limsup f_k = \lim\limits_{j\rightarrow \infty} g_j$ where $g_j = \sup\limits_{k\geq j } f_k$ . Thus we get that $$f_k \leq g_j \Rightarrow \int_E f_k \leq \int_E g_j \implies \sup\limits_{k\geq j }\int_E f_k \leq \int_E g_j $$ Taking the limit of both sides yields $$\lim\limits_{j\rightarrow \infty}\sup\limits_{k\geq j }\int_E f_k \leq \lim\limits_{j\rightarrow \infty}\int_E g_j $$ Which is equivalent to $$\limsup\limits_{j\rightarrow \infty}\int_E f_k \leq \liminf\limits_{j\rightarrow \infty}\int_E g_j $$ This is where I get stuck. I want to use Fatou's lemma but it won't work in this case. Is there a better way to prove this?","Question I am trying to prove the Reverse Fatou's lemma but I can't seem to get it. The statement is the following: Suppose that is a sequence of measurable functions and an integrable function such that for all . Then, where is the integral on a specified measure space. Attempt We have a sequence in and . We know that where . Thus we get that Taking the limit of both sides yields Which is equivalent to This is where I get stuck. I want to use Fatou's lemma but it won't work in this case. Is there a better way to prove this?",(f_n)_{n \in \mathbb{N}} g f_n \leq g n \in \mathbb{N} \limsup _{n \rightarrow \infty} \mu (f_n) = \mu ( \limsup _{n \rightarrow \infty} f_n) \mu \lbrace f_k \rbrace \mathbb R E\subset \mathbb R \limsup f_k = \lim\limits_{j\rightarrow \infty} g_j g_j = \sup\limits_{k\geq j } f_k f_k \leq g_j \Rightarrow \int_E f_k \leq \int_E g_j \implies \sup\limits_{k\geq j }\int_E f_k \leq \int_E g_j  \lim\limits_{j\rightarrow \infty}\sup\limits_{k\geq j }\int_E f_k \leq \lim\limits_{j\rightarrow \infty}\int_E g_j  \limsup\limits_{j\rightarrow \infty}\int_E f_k \leq \liminf\limits_{j\rightarrow \infty}\int_E g_j ,"['probability', 'measure-theory', 'convergence-divergence', 'solution-verification']"
7,"Probability of a ""run"" of coin tosses.","Probability of a ""run"" of coin tosses.",,"Given probability of tails is p, so heads is 1-p. Define X as a random variable for the length of a run (X=5 is either TTTTTH or HHHHHT). Find pmf. So I think a run of just heads or just tails is pretty straightforward. A run of tails being, $P(X=x)=p(1-p)^x$ and a run of heads being $P(X=x)=(1-p)p^x$. I'm just not really sure how I would combine the two. At first I considered the pmf being $p(1-p)^x+(1-p)p^x$, But $\sum_{x=0}^\infty p(1-p)^x+(1-p)p^x=2$, so it's not a valid pmf. Any help on this one?","Given probability of tails is p, so heads is 1-p. Define X as a random variable for the length of a run (X=5 is either TTTTTH or HHHHHT). Find pmf. So I think a run of just heads or just tails is pretty straightforward. A run of tails being, $P(X=x)=p(1-p)^x$ and a run of heads being $P(X=x)=(1-p)p^x$. I'm just not really sure how I would combine the two. At first I considered the pmf being $p(1-p)^x+(1-p)p^x$, But $\sum_{x=0}^\infty p(1-p)^x+(1-p)p^x=2$, so it's not a valid pmf. Any help on this one?",,"['probability', 'probability-distributions']"
8,probability of flipping a total of 20 heads before flipping 10 tails in a row?,probability of flipping a total of 20 heads before flipping 10 tails in a row?,,"I want to find the probability that I will flip a fair coin and get $10$ heads in a row before I flip a total of $20$ tails. Or the opposite, the probability that I will flip a total of $20$ heads before I flip $10$ tails in a row. I would like to see the work and have an explanation. Also, this should be able to be applied to an unfair coin. Thanks! The probability of flipping $10$ heads or tails in a row would be $(0.5)^{10}$ for a fair coin. I know how to figure out the probability of a total of $20$ tails in $x$ flips, but $x$ has to be defined to get an answer, at least as far as I am aware. Thanks!","I want to find the probability that I will flip a fair coin and get $10$ heads in a row before I flip a total of $20$ tails. Or the opposite, the probability that I will flip a total of $20$ heads before I flip $10$ tails in a row. I would like to see the work and have an explanation. Also, this should be able to be applied to an unfair coin. Thanks! The probability of flipping $10$ heads or tails in a row would be $(0.5)^{10}$ for a fair coin. I know how to figure out the probability of a total of $20$ tails in $x$ flips, but $x$ has to be defined to get an answer, at least as far as I am aware. Thanks!",,['probability']
9,How Many Harry Potter Chocolate Frogs Must I Buy? [duplicate],How Many Harry Potter Chocolate Frogs Must I Buy? [duplicate],,"This question already has an answer here : Probability distribution in the coupon collector's problem (1 answer) Closed 4 years ago . Each Chocolate Frog comes with one collectable illustrated wizard card (very cool and not dorky at all, honest). There are equal odds of each card being in a pack (i.e., they have all been produced and distributed evenly). How many packs must we buy in order to have an 80% chance of having obtained all 12 cards? How about 90%? Thanks.","This question already has an answer here : Probability distribution in the coupon collector's problem (1 answer) Closed 4 years ago . Each Chocolate Frog comes with one collectable illustrated wizard card (very cool and not dorky at all, honest). There are equal odds of each card being in a pack (i.e., they have all been produced and distributed evenly). How many packs must we buy in order to have an 80% chance of having obtained all 12 cards? How about 90%? Thanks.",,"['probability', 'coupon-collector']"
10,Please help on this Probability problem,Please help on this Probability problem,,"A bag contains 5 red marbles and 7 green marbles. Two marbles are drawn randomly one at a time, and without replacement. Find the probability of picking a red and a green, without order. This is how I attempted the question: I first go $P(\text{Red})= 5/12$ and $P(\text{Green})= 7/11$ and multiplied the two: $$\frac{7}{11}\times \frac{5}{12}= \frac{35}{132}$$ Then I got $P(\text{Green})= 7/12$ and $P(\text{Red})= 5/11$ $\implies$ $$\frac{5}{11} × \frac{7}{12}= \frac{35}{132}$$ So I decided that $$P(\text{G and R}) \;\text{ or }\; P(\text{R and G}) =\frac{35}{132} + \frac{35}{132} =\frac{35}{66}$$ Is this correct?","A bag contains 5 red marbles and 7 green marbles. Two marbles are drawn randomly one at a time, and without replacement. Find the probability of picking a red and a green, without order. This is how I attempted the question: I first go $P(\text{Red})= 5/12$ and $P(\text{Green})= 7/11$ and multiplied the two: $$\frac{7}{11}\times \frac{5}{12}= \frac{35}{132}$$ Then I got $P(\text{Green})= 7/12$ and $P(\text{Red})= 5/11$ $\implies$ $$\frac{5}{11} × \frac{7}{12}= \frac{35}{132}$$ So I decided that $$P(\text{G and R}) \;\text{ or }\; P(\text{R and G}) =\frac{35}{132} + \frac{35}{132} =\frac{35}{66}$$ Is this correct?",,['probability']
11,Probability of being at a certain point after $N$ steps in Random Walk with a single absorbing barrier,Probability of being at a certain point after  steps in Random Walk with a single absorbing barrier,N,A random walker in $1$ dimension starts walking from a point $k>0$ with an absorbing barrier at point $0$. What is the probability that he will reach a point $m>0$ in $N$ steps? How should I think about the problem?,A random walker in $1$ dimension starts walking from a point $k>0$ with an absorbing barrier at point $0$. What is the probability that he will reach a point $m>0$ in $N$ steps? How should I think about the problem?,,"['probability', 'markov-chains', 'random-walk']"
12,How to calculate probability using multinomial distribution?,How to calculate probability using multinomial distribution?,,"So according to the multinomial distribution, the probability function $\Pr(X_1 = x_1, X_2 = x_2, \dots, X_k = x_k)$ is equal to $\dfrac{n!}{x_1! x_2! \cdots x_k!} \cdot p_1^{x_1}\cdot p_2^{x_2} \cdots p_k^{x_k}$ (See http://en.wikipedia.org/wiki/Multinomial_distribution ). And if we were to sum all of the probabilites for all possible values of $x_1, x_2, \dots x_k$, we would get one. The thing is that summing all of those probablities also includes the situations in which at least one $x_j = 0$. How would I go about computing the following probablity function?: $$\Pr(X_1=x_1>0, X_2=x_2>0, \ldots, X_k=x_k>0) = ?$$ So basically, the sum of all probabilities of the scenarios in which no $x_j = 0$ and the sum of all the probabilities of the scenarios in which at least one $x_j = 0$ is equal to $1$. I want to find the sum of all probabilities of the scenarios in which no $x_j = 0$","So according to the multinomial distribution, the probability function $\Pr(X_1 = x_1, X_2 = x_2, \dots, X_k = x_k)$ is equal to $\dfrac{n!}{x_1! x_2! \cdots x_k!} \cdot p_1^{x_1}\cdot p_2^{x_2} \cdots p_k^{x_k}$ (See http://en.wikipedia.org/wiki/Multinomial_distribution ). And if we were to sum all of the probabilites for all possible values of $x_1, x_2, \dots x_k$, we would get one. The thing is that summing all of those probablities also includes the situations in which at least one $x_j = 0$. How would I go about computing the following probablity function?: $$\Pr(X_1=x_1>0, X_2=x_2>0, \ldots, X_k=x_k>0) = ?$$ So basically, the sum of all probabilities of the scenarios in which no $x_j = 0$ and the sum of all the probabilities of the scenarios in which at least one $x_j = 0$ is equal to $1$. I want to find the sum of all probabilities of the scenarios in which no $x_j = 0$",,"['probability', 'probability-distributions', 'statistical-inference', 'parameter-estimation', 'multinomial-coefficients']"
13,Distribution of Digit Products,Distribution of Digit Products,,"A digit product $P(n)$ of a natural number $n$ is given by the product of its decimal digits. For example: $$P(1234) = 24,\;\;\; P(24) = 8,\;\;\; P(8) = 8$$ $$1\times2\times3\times4 = 24, \;\;\; 2\times4 = 8$$ Clearly $P(x) \leq x$ as a number with digits ""abcd..."" gives a product less than $a\times10\times10\times10...$. So $$P(x) < x\;\;\; \text{or}\;\;\; P(x) < 10$$ Letting $P^n(x)$ represent applying $P$ $n$ times, I have a question about $$P^\infty(x) = \lim_{n\rightarrow\infty}P^n(x)$$ The larger the number the more likely it is that it will contain a zero. So, for a random $x$ we expect that almost always $P^\infty(x)=0$. But we can get rid of all these from the number line: $$S = \{x\in\mathbb{N}_0|P^\infty(x)\neq0\}$$ What is the distribution of $P^\infty(s)$ for $s\in S$? How likely are the remaining digits? Is one infinitely more likely than the others? Here's a graph of $10$ to $1,000,000$:","A digit product $P(n)$ of a natural number $n$ is given by the product of its decimal digits. For example: $$P(1234) = 24,\;\;\; P(24) = 8,\;\;\; P(8) = 8$$ $$1\times2\times3\times4 = 24, \;\;\; 2\times4 = 8$$ Clearly $P(x) \leq x$ as a number with digits ""abcd..."" gives a product less than $a\times10\times10\times10...$. So $$P(x) < x\;\;\; \text{or}\;\;\; P(x) < 10$$ Letting $P^n(x)$ represent applying $P$ $n$ times, I have a question about $$P^\infty(x) = \lim_{n\rightarrow\infty}P^n(x)$$ The larger the number the more likely it is that it will contain a zero. So, for a random $x$ we expect that almost always $P^\infty(x)=0$. But we can get rid of all these from the number line: $$S = \{x\in\mathbb{N}_0|P^\infty(x)\neq0\}$$ What is the distribution of $P^\infty(s)$ for $s\in S$? How likely are the remaining digits? Is one infinitely more likely than the others? Here's a graph of $10$ to $1,000,000$:",,"['probability', 'number-theory', 'products']"
14,finding the number of circles we get when randomly placing given patterns into a grid of squares,finding the number of circles we get when randomly placing given patterns into a grid of squares,,"We have an 11$\times$11 table of squares (consist of 121 squares of dimension 1$\times$1). we have 3 tiles shown in the picture. Each tile has dimension 1$\times$1. we now randomly pick 3 tiles into the table. Let $N$ denote the total of number of circles we get in a random drawing. Compute expected value of $N$, mean of $N$ and standard deviation of $N$. I think of an idea that we construct a $X$-$Y$ coordinate in accordance with the 11$\times$11 table, the only way to get a circle is to put the first tile in square $(x,y)$ and $(x+1,y-1)$ and put the third tile in square $(x+1,y+1)$ and $(x,y-1)$ for $0 \le x,y \le 11$. I want to construct a variable that takes on value 1 if this arrangement occurs and 0 if not, then construct what I want. But now I get stuck. Any help would be really appreciated. thanks The image of the three tile patterns is below","We have an 11$\times$11 table of squares (consist of 121 squares of dimension 1$\times$1). we have 3 tiles shown in the picture. Each tile has dimension 1$\times$1. we now randomly pick 3 tiles into the table. Let $N$ denote the total of number of circles we get in a random drawing. Compute expected value of $N$, mean of $N$ and standard deviation of $N$. I think of an idea that we construct a $X$-$Y$ coordinate in accordance with the 11$\times$11 table, the only way to get a circle is to put the first tile in square $(x,y)$ and $(x+1,y-1)$ and put the third tile in square $(x+1,y+1)$ and $(x,y-1)$ for $0 \le x,y \le 11$. I want to construct a variable that takes on value 1 if this arrangement occurs and 0 if not, then construct what I want. But now I get stuck. Any help would be really appreciated. thanks The image of the three tile patterns is below",,"['probability', 'probability-distributions', 'conditional-probability', 'geometric-probability']"
15,"Why does adding 3 random decimals in the range [-1,1] give a normal dist with std. dev 1?","Why does adding 3 random decimals in the range [-1,1] give a normal dist with std. dev 1?",,"I've used Math.random()*2-1+Math.random()*2-1+Math.random()*2-1 many times in the past to get normally-distributed random numbers with a standard deviation of 1.  Of course, it's a bit of an approximate, but it works, and I usually don't want numbers outside of the third standard deviation anyway.  And I sort of understand why this works out the way it does (as in it makes sense in my head why numbers further from zero are much less likely), but I have no idea how to prove it legitimately. Why is it that adding randoms in the range of [-1,1] three times specifically yields a standard deviation of 1?  I did some tests and found adding four times gives a std. dev. of about 1.155, and adding twice gives around 0.813.  Why is this? I want to understand the real math behind this.","I've used Math.random()*2-1+Math.random()*2-1+Math.random()*2-1 many times in the past to get normally-distributed random numbers with a standard deviation of 1.  Of course, it's a bit of an approximate, but it works, and I usually don't want numbers outside of the third standard deviation anyway.  And I sort of understand why this works out the way it does (as in it makes sense in my head why numbers further from zero are much less likely), but I have no idea how to prove it legitimately. Why is it that adding randoms in the range of [-1,1] three times specifically yields a standard deviation of 1?  I did some tests and found adding four times gives a std. dev. of about 1.155, and adding twice gives around 0.813.  Why is this? I want to understand the real math behind this.",,"['probability', 'normal-distribution', 'random']"
16,Probability of Extinction in a simple Birth and Death Process,Probability of Extinction in a simple Birth and Death Process,,"We are asked to show that the probability of extinction $\zeta=\lim_{t\to \infty} P\left(X(t)=0\right)$ given by:  $$\zeta=\begin{cases}1&\text{if }\lambda\le \mu,\\ \left(\frac \mu\lambda \right)^{i}&\text{if }\lambda\gt\mu.\end{cases}$$ where $i$ is the initial population size. Now I found the probability generating function of the BDP:  $$P(t,s)=\left({{r\mu-1\over r\lambda-1}}\right)^{i}$$ Where $r=e^{(\lambda-\mu)t}\left({{1-s\over \mu-\lambda s}}\right)$ But afterwards I get stuck when trying to find $P\left(X(t)=0\right)=p_{0}(t)$ Any help is greatly appreciated!","We are asked to show that the probability of extinction $\zeta=\lim_{t\to \infty} P\left(X(t)=0\right)$ given by:  $$\zeta=\begin{cases}1&\text{if }\lambda\le \mu,\\ \left(\frac \mu\lambda \right)^{i}&\text{if }\lambda\gt\mu.\end{cases}$$ where $i$ is the initial population size. Now I found the probability generating function of the BDP:  $$P(t,s)=\left({{r\mu-1\over r\lambda-1}}\right)^{i}$$ Where $r=e^{(\lambda-\mu)t}\left({{1-s\over \mu-\lambda s}}\right)$ But afterwards I get stuck when trying to find $P\left(X(t)=0\right)=p_{0}(t)$ Any help is greatly appreciated!",,"['probability', 'probability-theory', 'stochastic-processes', 'markov-process']"
17,Markov chain from Poisson process,Markov chain from Poisson process,,"Let $K_t$ be a Poisson process with rate $1$ and $X_n=K_n-n$ $,  \  \  \        n\in \mathbb{N}$ Then we know that $X_n$ is a recurrent Markov chain. I am asked to determine whether the chain is null or positive recurrent. I tried to compute the mean return time to zero, but, using the law of total probability, I got huge sums... If $T=\min(n \geq 1 : X_n=0 |X_0 = 0) $ then I get: $$ \mathbb{P}(T=k) = \sum_{t_1\not = 1}\sum _{t2\not = 2} \cdots \sum_{t_{k-1}\not = k-1} \mathbb{P}(K_1 = t_1)\mathbb{P}(K_2 = t_2)\cdots \mathbb{P}(K_{k-1}=t_{k-1})\mathbb{P}(N_k=k) $$ It does not look right.... How can I go on? thank you very much","Let $K_t$ be a Poisson process with rate $1$ and $X_n=K_n-n$ $,  \  \  \        n\in \mathbb{N}$ Then we know that $X_n$ is a recurrent Markov chain. I am asked to determine whether the chain is null or positive recurrent. I tried to compute the mean return time to zero, but, using the law of total probability, I got huge sums... If $T=\min(n \geq 1 : X_n=0 |X_0 = 0) $ then I get: $$ \mathbb{P}(T=k) = \sum_{t_1\not = 1}\sum _{t2\not = 2} \cdots \sum_{t_{k-1}\not = k-1} \mathbb{P}(K_1 = t_1)\mathbb{P}(K_2 = t_2)\cdots \mathbb{P}(K_{k-1}=t_{k-1})\mathbb{P}(N_k=k) $$ It does not look right.... How can I go on? thank you very much",,"['probability', 'markov-chains', 'poisson-process']"
18,Probability of finding adjacent colored squares in a line of white squares,Probability of finding adjacent colored squares in a line of white squares,,"So this question has a small science background, but the problem itself is purely mathematical. Consider a one-dimensional row of squares, some are white, some are blue. The blue squares represent water, and the white ones represent some other irrelevant compound. If there are $N$ total squares and $n$ water squares, and you are given the concentration of water in the solution (say it is any multiple of $10\%$ from $0\%$ to $100\%$), how would you calculate the probability for each concentration that two water squares are touching? How would you calculate the average number of water-water bonds in each concentration? Two adjacent blue squares represents one water-water bond. EDIT:  My model in one-dimension seems to be working to my liking, and I would now like to extrapolate it to two and three dimensions.  I will be posting my personal results/progress here, but what is the best way to move this into higher dimensions?","So this question has a small science background, but the problem itself is purely mathematical. Consider a one-dimensional row of squares, some are white, some are blue. The blue squares represent water, and the white ones represent some other irrelevant compound. If there are $N$ total squares and $n$ water squares, and you are given the concentration of water in the solution (say it is any multiple of $10\%$ from $0\%$ to $100\%$), how would you calculate the probability for each concentration that two water squares are touching? How would you calculate the average number of water-water bonds in each concentration? Two adjacent blue squares represents one water-water bond. EDIT:  My model in one-dimension seems to be working to my liking, and I would now like to extrapolate it to two and three dimensions.  I will be posting my personal results/progress here, but what is the best way to move this into higher dimensions?",,"['probability', 'combinatorics']"
19,Mixture Gaussian distribution quantiles,Mixture Gaussian distribution quantiles,,"Let $f_1(x), \dots, f_n(x)$ be Gaussian density functions with different parameters, and $w_1, \dots, w_n$ be real numbers that sum-up to unity. Now the function $g(x) = \sum_i w_i f_i(x)$ is also a density function and I call it mixture-Gaussian density. It is easy to calculate central moments (e.g. mean) of this distribution when we know the central moments of the underlying normal distributions, using linearity of integrals: $$\int x^k g(x) dx = \int x^k \sum_i w_i f_i(x) dx = \sum_i w_i \int x^k f_i(x) dx$$ (please correct me if I am wrong). How can I however calculate the quantiles of the new distribution (e.g. median)? Ideally I would like to get the quantile function , given quantile functions of the underlying normal distributions. Is there closed form solution? If not, what would be an efficient numerical solution?","Let $f_1(x), \dots, f_n(x)$ be Gaussian density functions with different parameters, and $w_1, \dots, w_n$ be real numbers that sum-up to unity. Now the function $g(x) = \sum_i w_i f_i(x)$ is also a density function and I call it mixture-Gaussian density. It is easy to calculate central moments (e.g. mean) of this distribution when we know the central moments of the underlying normal distributions, using linearity of integrals: $$\int x^k g(x) dx = \int x^k \sum_i w_i f_i(x) dx = \sum_i w_i \int x^k f_i(x) dx$$ (please correct me if I am wrong). How can I however calculate the quantiles of the new distribution (e.g. median)? Ideally I would like to get the quantile function , given quantile functions of the underlying normal distributions. Is there closed form solution? If not, what would be an efficient numerical solution?",,"['probability', 'probability-distributions', 'normal-distribution']"
20,Uniformly Most Powerful Test and Rejection Region of Poisson Distribution,Uniformly Most Powerful Test and Rejection Region of Poisson Distribution,,"Let $X_1, \dots,X_n$ be a random sample from a Poisson$(\lambda)$ distribution where $\lambda > 0$. (1) Find the Uniformly Most Powerful (UMP) level $\alpha$ test for the following set of hypotheses: $H_0: \lambda\leq1$ versus $H_A: \lambda >1$. $\bf{My \ thoughts:}$ I know I can use Karlin-Rubin to help me with this part of the problem. Using Factorization Theorem, I get that $\sum^n_{i=1}X_i$ is a sufficient and complete statistic.  Checking the MLR and using Karlin-Rubin,I get $\alpha = P_{\lambda} \Bigl(\sum^n_{i=1}X_i > 1 \Bigr).$ (2) Using the CLT, provide an expression for the rejection region for this test. $\bf{My \ thoughts:}$ Using the CLT, I know I need to start by finding the asymptotic distribution of $\sum^n_{i=1}X_i$ and go from there.  Just not sure on setting that up. (3) Find the power function for this test. $\bf{My \ thoughts:}$ This doesn't seem like it would be too difficult and should come from having what I need from 1 and 2. Any help is greatly appreciated.","Let $X_1, \dots,X_n$ be a random sample from a Poisson$(\lambda)$ distribution where $\lambda > 0$. (1) Find the Uniformly Most Powerful (UMP) level $\alpha$ test for the following set of hypotheses: $H_0: \lambda\leq1$ versus $H_A: \lambda >1$. $\bf{My \ thoughts:}$ I know I can use Karlin-Rubin to help me with this part of the problem. Using Factorization Theorem, I get that $\sum^n_{i=1}X_i$ is a sufficient and complete statistic.  Checking the MLR and using Karlin-Rubin,I get $\alpha = P_{\lambda} \Bigl(\sum^n_{i=1}X_i > 1 \Bigr).$ (2) Using the CLT, provide an expression for the rejection region for this test. $\bf{My \ thoughts:}$ Using the CLT, I know I need to start by finding the asymptotic distribution of $\sum^n_{i=1}X_i$ and go from there.  Just not sure on setting that up. (3) Find the power function for this test. $\bf{My \ thoughts:}$ This doesn't seem like it would be too difficult and should come from having what I need from 1 and 2. Any help is greatly appreciated.",,"['probability', 'statistics', 'probability-distributions', 'statistical-inference', 'hypothesis-testing']"
21,What is the probability that the bacteria population eventually dies out? [duplicate],What is the probability that the bacteria population eventually dies out? [duplicate],,"This question already has an answer here : probability of dying of a bacteria [closed] (1 answer) Closed 11 years ago . A jar begins with one bacteria. Every minute, every bacteria turns into 0, 1, 2, or 3 bacteria with a probability of 25% for each case (dies, does nothing, splits into 2, or splits into 3). What is the probability that the bacteria population eventually dies out?","This question already has an answer here : probability of dying of a bacteria [closed] (1 answer) Closed 11 years ago . A jar begins with one bacteria. Every minute, every bacteria turns into 0, 1, 2, or 3 bacteria with a probability of 25% for each case (dies, does nothing, splits into 2, or splits into 3). What is the probability that the bacteria population eventually dies out?",,['probability']
22,"Monthly rental fee to achieve given profit on average, given probabilities of numbers of rentals","Monthly rental fee to achieve given profit on average, given probabilities of numbers of rentals",,"I have this problem here and I'm very unsure of how to start this. I have an idea but I'm not sure where to go from a certain point. The problem says: A video rental store is analyzing a flat fee rental program it is planning to offer and the program allows a subscriber to rent up to $8$ movies a month for a flat monthly fee. Each rental costs the store $1.25$ dollars in processing and personnel fees. Let $p_n$ be the probability that a subscriber rents $n$ movies in one month. We have the following: $1)$ $p_0=a$ $2)$ $p_n-p_{n+1}=c\gt 0$ where $c$ is some constant for $n=0,1,...,7$ $3)$ The probability of a subscriber renting fewer than $3$ movies in one month is $0.55$ The store would like to make a profit of $1$ dollar per rental on average. What should the monthly fee be for the program to achieve this profit? My first instinct is to find the expected number of rentals per month and multiply it by $1.25$ to see how much it would cost. Then find the expected cost of this program and charge a dollar more than that. But I can't think of how to find the probability. Any help here?","I have this problem here and I'm very unsure of how to start this. I have an idea but I'm not sure where to go from a certain point. The problem says: A video rental store is analyzing a flat fee rental program it is planning to offer and the program allows a subscriber to rent up to $8$ movies a month for a flat monthly fee. Each rental costs the store $1.25$ dollars in processing and personnel fees. Let $p_n$ be the probability that a subscriber rents $n$ movies in one month. We have the following: $1)$ $p_0=a$ $2)$ $p_n-p_{n+1}=c\gt 0$ where $c$ is some constant for $n=0,1,...,7$ $3)$ The probability of a subscriber renting fewer than $3$ movies in one month is $0.55$ The store would like to make a profit of $1$ dollar per rental on average. What should the monthly fee be for the program to achieve this profit? My first instinct is to find the expected number of rentals per month and multiply it by $1.25$ to see how much it would cost. Then find the expected cost of this program and charge a dollar more than that. But I can't think of how to find the probability. Any help here?",,"['probability', 'probability-theory', 'actuarial-science']"
23,A Laplace transform question,A Laplace transform question,,"Suppose I have a positive integrable random variable $X$ s.t. $$E[e^X]=+\infty$$ Now let's take a series with general term $p_n$, summing to one, and define $$Z=\sum_{n>0}p_ne^{X_n}$$ and $U=\ln Z$ where $X_n$ are i.i.d. copies of $X$. Now I have two questions : I think that $$\mathcal{L}_U(\lambda)=\cases{+\infty & if $\lambda>0$ \\ 1 & otherwise}$$ is that true? (Here $\mathcal{L}_U (\lambda)$ is the Laplace transform of $U$ at $\lambda$). My proof here is a fraud I think and before giving it I would like to see other people's ideas. If 1 is true can I deduce from this fact that $U$ is not integrable, and why? (Here I hope it's true) Best regards","Suppose I have a positive integrable random variable $X$ s.t. $$E[e^X]=+\infty$$ Now let's take a series with general term $p_n$, summing to one, and define $$Z=\sum_{n>0}p_ne^{X_n}$$ and $U=\ln Z$ where $X_n$ are i.i.d. copies of $X$. Now I have two questions : I think that $$\mathcal{L}_U(\lambda)=\cases{+\infty & if $\lambda>0$ \\ 1 & otherwise}$$ is that true? (Here $\mathcal{L}_U (\lambda)$ is the Laplace transform of $U$ at $\lambda$). My proof here is a fraud I think and before giving it I would like to see other people's ideas. If 1 is true can I deduce from this fact that $U$ is not integrable, and why? (Here I hope it's true) Best regards",,"['probability', 'laplace-transform']"
24,Expected number of overlaps between intervals,Expected number of overlaps between intervals,,"Suppose $N$ intervals of length $\delta$ are positioned in $[0,1]$. The starting point $l_i$ of each interval is drawn from an uniform distribution, i.e., $l_i \in [0, 1-\delta]$, thus it will determine the position of the $i$-th interval. These intervals may overlap at some point in $[0,1]$. I call ""overlap"" each superimposition of an interval over another interval. E.g. A = [0, 0.2]      B = [0.1, 0.3]      C = [0.25 0.45]. Number of overlaps = 2 (A with B, B with C) Since an overlap occurs between a pair of intervals, $\frac{N(N-1)}{2}$ is the maximum number of overlaps. I would like to compute the expected number of overlaps between the intervals in $[0,1]$.","Suppose $N$ intervals of length $\delta$ are positioned in $[0,1]$. The starting point $l_i$ of each interval is drawn from an uniform distribution, i.e., $l_i \in [0, 1-\delta]$, thus it will determine the position of the $i$-th interval. These intervals may overlap at some point in $[0,1]$. I call ""overlap"" each superimposition of an interval over another interval. E.g. A = [0, 0.2]      B = [0.1, 0.3]      C = [0.25 0.45]. Number of overlaps = 2 (A with B, B with C) Since an overlap occurs between a pair of intervals, $\frac{N(N-1)}{2}$ is the maximum number of overlaps. I would like to compute the expected number of overlaps between the intervals in $[0,1]$.",,"['probability', 'probability-distributions', 'uniform-distribution']"
25,Question on page 339 of Shiryaev's Probability,Question on page 339 of Shiryaev's Probability,,"Suppose that for each $n\geq1$ there is a given sequence of independent random variables $$\xi_{n1},\xi_{n2},\ldots,\xi_{nn}$$ with $E\xi_{nk}=0$, $V\xi_{nk}=\sigma_{nk}^2$, $\sum_{k=1}^n\sigma_{nk}^2=1$. Let $S_n=\xi_{n1}+\ldots+\xi_{nn},$ $$F_{nk}(x)=P\{\xi_{nk}\leq x\},\ \Phi(x)=(2\pi)^{-1/2}\int_{-\infty}^x e^{-y^2/2}dy,\ \Phi_{nk}(x)=\Phi\left(\frac{x}{\sigma_{nk}}\right)$$ On page 339 there is an inequality: $$\sum_{k=1}^n\left| t\int_{-\infty}^{\infty}(e^{itx}-1-itx)(F_{nk}(x)-\Phi_{nk}(x))dx\right|\leq\frac{|t|^3}{2}\varepsilon\sum_{k=1}^n\int_{|x|\leq\varepsilon}|x||F_{nk}(x)-\Phi_{nk}(x)|dx+2t^2\sum_{k=1}^n\int_{|x|>\varepsilon}|x||F_{nk}(x)-\Phi_{nk}(x)|dx$$ How can I get it? Then the book says we can use $$E|\xi|^n=\int_{-\infty}^{\infty}|x|^ndF(x)=n\int_0^\infty x^{n-1}[1-F(x)+F(-x)]dx$$ to prove $$\int_{|x|\leq\varepsilon}|x||F_{nk}(x)-\Phi_{nk}(x)|dx\leq2\sigma_{nk}^2$$ But I can't figure why. Thank you!","Suppose that for each $n\geq1$ there is a given sequence of independent random variables $$\xi_{n1},\xi_{n2},\ldots,\xi_{nn}$$ with $E\xi_{nk}=0$, $V\xi_{nk}=\sigma_{nk}^2$, $\sum_{k=1}^n\sigma_{nk}^2=1$. Let $S_n=\xi_{n1}+\ldots+\xi_{nn},$ $$F_{nk}(x)=P\{\xi_{nk}\leq x\},\ \Phi(x)=(2\pi)^{-1/2}\int_{-\infty}^x e^{-y^2/2}dy,\ \Phi_{nk}(x)=\Phi\left(\frac{x}{\sigma_{nk}}\right)$$ On page 339 there is an inequality: $$\sum_{k=1}^n\left| t\int_{-\infty}^{\infty}(e^{itx}-1-itx)(F_{nk}(x)-\Phi_{nk}(x))dx\right|\leq\frac{|t|^3}{2}\varepsilon\sum_{k=1}^n\int_{|x|\leq\varepsilon}|x||F_{nk}(x)-\Phi_{nk}(x)|dx+2t^2\sum_{k=1}^n\int_{|x|>\varepsilon}|x||F_{nk}(x)-\Phi_{nk}(x)|dx$$ How can I get it? Then the book says we can use $$E|\xi|^n=\int_{-\infty}^{\infty}|x|^ndF(x)=n\int_0^\infty x^{n-1}[1-F(x)+F(-x)]dx$$ to prove $$\int_{|x|\leq\varepsilon}|x||F_{nk}(x)-\Phi_{nk}(x)|dx\leq2\sigma_{nk}^2$$ But I can't figure why. Thank you!",,"['probability', 'probability-theory']"
26,Probability distribution for the position of a biased random walker on the positive integers,Probability distribution for the position of a biased random walker on the positive integers,,"I initialize a biased one-dimensional random walk on the positive integers at the origin, $x = 0$, which also serves as a reflecting boundary blocking steps onto the negative integers.  Let's say that a $+1$ step for the walker has probability $p$, and an $-1$ step (away from the origin) has probability $q$, where $(p+q) \leq 1$ allowing the walker to stay in place with probability $r = 1 - (p+q)$. If $p < q$, what is the probability distribution for the walker on the positive integers?  What are the implications if $p = q$ provided that a 1D random walk shouldn't be transient? I've always appealed to simulations when problems like this arise, however, the formulation of this system seems simple enough that I'd imagine an analytic solution should exist (beyond the generalization that we should have exponential increasing hitting times as we linearly increase the distance to the origin)?  Is there a formulation of, say, Gambler's ruin that deals with this problem?  We can of course eliminate the reflecting boundary by making $p$ the probability of stepping away from the origin, $q$ the probability of stepping towards the origin, etc. Some additional questions that come to mind: how long would it take a randomly placed walker to achieve this distribution?  If we place a walker at the origin, how fair or unfair would it be to assume that the hitting time at some site $x_{t}$ would be proportional to its occupancy probability from the distribution?  And, in the case that this is unfair, what does the probability distribution look like for initial hitting times on the positive integers conditioned on the walker being initialized at the origin? Clarification - A walker can occupy the origin, though here, we have a $-1$ step probability of $q = 0$, the same $+1$ step probability $p$, and a probability of remaining at the origin for a step of $r = (1 - p)$.","I initialize a biased one-dimensional random walk on the positive integers at the origin, $x = 0$, which also serves as a reflecting boundary blocking steps onto the negative integers.  Let's say that a $+1$ step for the walker has probability $p$, and an $-1$ step (away from the origin) has probability $q$, where $(p+q) \leq 1$ allowing the walker to stay in place with probability $r = 1 - (p+q)$. If $p < q$, what is the probability distribution for the walker on the positive integers?  What are the implications if $p = q$ provided that a 1D random walk shouldn't be transient? I've always appealed to simulations when problems like this arise, however, the formulation of this system seems simple enough that I'd imagine an analytic solution should exist (beyond the generalization that we should have exponential increasing hitting times as we linearly increase the distance to the origin)?  Is there a formulation of, say, Gambler's ruin that deals with this problem?  We can of course eliminate the reflecting boundary by making $p$ the probability of stepping away from the origin, $q$ the probability of stepping towards the origin, etc. Some additional questions that come to mind: how long would it take a randomly placed walker to achieve this distribution?  If we place a walker at the origin, how fair or unfair would it be to assume that the hitting time at some site $x_{t}$ would be proportional to its occupancy probability from the distribution?  And, in the case that this is unfair, what does the probability distribution look like for initial hitting times on the positive integers conditioned on the walker being initialized at the origin? Clarification - A walker can occupy the origin, though here, we have a $-1$ step probability of $q = 0$, the same $+1$ step probability $p$, and a probability of remaining at the origin for a step of $r = (1 - p)$.",,"['probability', 'markov-chains', 'random-walk']"
27,How is the Erlang pdf derived?,How is the Erlang pdf derived?,,"If each arrival is exponentially distributed, then the $k$th arrival time is Erlang distributed. The Erlang PDF is: $$ f_{Y_k}(y) = \lambda e^{-\lambda y} \frac{(\lambda y)^{k-1}}{(k-1)!} $$ How is this derived?","If each arrival is exponentially distributed, then the $k$th arrival time is Erlang distributed. The Erlang PDF is: $$ f_{Y_k}(y) = \lambda e^{-\lambda y} \frac{(\lambda y)^{k-1}}{(k-1)!} $$ How is this derived?",,['probability']
28,Probabilistic approach to a combinatorics problem,Probabilistic approach to a combinatorics problem,,"Problem: In Duma, there are 1600 delegates, who have formed 16000 committees of 80 persons each. Prove that one can find two committees having at least four common members. There is a probabilistic solution to this question, which I am having trouble following because I have no background in probability. It begins by calculating the expected number of common members of any two given committees and using this to find the solution. How exactly does this work? I am also interested to know if anyone has a non-probabilistic solution. Source: http://www.math.cmu.edu/~ploh/docs/math/mop2011/prob-method.pdf EDIT: After further searching, I found the solution worked out in full detail on page 2 here: http://www.math.cmu.edu/~ploh/docs/math/mop2010/prob-comb-soln.pdf","Problem: In Duma, there are 1600 delegates, who have formed 16000 committees of 80 persons each. Prove that one can find two committees having at least four common members. There is a probabilistic solution to this question, which I am having trouble following because I have no background in probability. It begins by calculating the expected number of common members of any two given committees and using this to find the solution. How exactly does this work? I am also interested to know if anyone has a non-probabilistic solution. Source: http://www.math.cmu.edu/~ploh/docs/math/mop2011/prob-method.pdf EDIT: After further searching, I found the solution worked out in full detail on page 2 here: http://www.math.cmu.edu/~ploh/docs/math/mop2010/prob-comb-soln.pdf",,"['probability', 'combinatorics']"
29,Understanding large deviation theory/principle,Understanding large deviation theory/principle,,"From WIkipedia Given a Polish space $\mathcal{X}$, let $\{ \mathbb{P}_N\}$ be a   sequence of Borel probability measures on $\mathcal{X}$, let $\{a_N\}$   be a sequence of positive real numbers such that $\lim_N a_N=+\infty$,   and finally let $I:\mathcal{X}\to [0,+\infty]$ be a lower   semicontinuous functional on $\mathcal{X}$. The sequence $\{  \mathbb{P}_N\}$ is said to satisfy a large deviation principle with   speed $\{a_n\}$ and rate $I$ if, and only if, for each Borel   measurable set $E \subset \mathcal{X}$, $$     -\inf_{x \in E^\circ} I(x) \le \varliminf_N a_N^{-1} \log\big(\mathbb{P}_N(E)\big) \le \varlimsup_N a_N^{-1}  \log\big(\mathbb{P}_N(E)\big) \le -\inf_{x \in \bar{E}} I(x) , $$   where $\bar{E}$ and $E^\circ$ denote respectively the closure and   interior of $E$. I was wondering how the above formal definition corresponds to the following informal interpretation: the theory of large deviations concerns the asymptotic behaviour of remote tails of sequences of probability distributions. ... Roughly speaking, large deviations theory concerns itself with the exponential decay of the probability measures of certain kinds of extreme or tail events , as the number of observations grows   arbitrarily large. In particular, what are the certain kinds of extreme or tail events in the formal definition?  $E \subset \mathcal{X}$  is any Borel measurable set, not necessarily tail or extreme events. How is the ""exponential decay"" represented in the formal definition? Is it represented as $a_n$ being a exponential function of $n$? What are the interpretations for $a_n$ and $I$ in the formal definition? Thanks!","From WIkipedia Given a Polish space $\mathcal{X}$, let $\{ \mathbb{P}_N\}$ be a   sequence of Borel probability measures on $\mathcal{X}$, let $\{a_N\}$   be a sequence of positive real numbers such that $\lim_N a_N=+\infty$,   and finally let $I:\mathcal{X}\to [0,+\infty]$ be a lower   semicontinuous functional on $\mathcal{X}$. The sequence $\{  \mathbb{P}_N\}$ is said to satisfy a large deviation principle with   speed $\{a_n\}$ and rate $I$ if, and only if, for each Borel   measurable set $E \subset \mathcal{X}$, $$     -\inf_{x \in E^\circ} I(x) \le \varliminf_N a_N^{-1} \log\big(\mathbb{P}_N(E)\big) \le \varlimsup_N a_N^{-1}  \log\big(\mathbb{P}_N(E)\big) \le -\inf_{x \in \bar{E}} I(x) , $$   where $\bar{E}$ and $E^\circ$ denote respectively the closure and   interior of $E$. I was wondering how the above formal definition corresponds to the following informal interpretation: the theory of large deviations concerns the asymptotic behaviour of remote tails of sequences of probability distributions. ... Roughly speaking, large deviations theory concerns itself with the exponential decay of the probability measures of certain kinds of extreme or tail events , as the number of observations grows   arbitrarily large. In particular, what are the certain kinds of extreme or tail events in the formal definition?  $E \subset \mathcal{X}$  is any Borel measurable set, not necessarily tail or extreme events. How is the ""exponential decay"" represented in the formal definition? Is it represented as $a_n$ being a exponential function of $n$? What are the interpretations for $a_n$ and $I$ in the formal definition? Thanks!",,"['probability', 'large-deviation-theory']"
30,Bypassing a series of stochastic stoplights,Bypassing a series of stochastic stoplights,,"In order for me to drive home, I need to sequentially bypass $(S_1, S_2, ..., S_N)$ stoplights that behave stochastically.  Each stoplight, $S_i$ has some individual probability $r_i$ of being red, and an associated probability, $g_i$, per minute of time of turning from red to green. What is the probability density function for the number of minutes I spend waiting at the $N$ stoplights on my way home? Update 2: The first update is incorrect since the $T$ variable $T$ is a mix of a discrete and continuous measures (as Sasha noted), to generate our distribution for $T$, and assuming all lights are the same, we need to compute the weighted sum: Distribution for $x = T = \sum^N_{j=1} Pr[j$ lights are red upon approach$] * Erlang[j, g]$ Here, Pr[$j$ lights are red upon approach] is just the probability of $j$ successes in $N$ trials, where the probability of success is $r$. In the case where all the lights are unique, we perform the same sort of weighted sum with the hypoexponential distribution, where we have to account for all possible subsets of the lights, with unique $g_i$, being red. Update 1 (see update 2 first, this is incorrect!) : from Raskolnikov and Sasha's comments, I'm supposing that the following is the case: If we allow all the spotlights, $S_i$ to be the same, following from (http://en.wikipedia.org/wiki/Erlang_distribution), we have an Erlang (or Gamma) distribution where $k = N$ and the rate parameter is $\lambda = \frac{g}{r}$.  This gives us a mean waiting time at all the red lights, $x = T$ minutes, of $\frac{k}{\lambda} = \frac{N}{(\frac{g}{r})}$ and the following PDF for $x = T$: $\frac{\lambda^k x^{k-1} e^{-\lambda x}}{(k-1)!}$ = $\frac{(\frac{g}{r})^N T^{N-1} e^{-(\frac{g}{r}) T}}{(N-1)!}$ Now if all of the stoplights are not the same, following from (http://en.wikipedia.org/wiki/Hypoexponential_distribution), we have a hypoexponential distribution where $k = N$ and the rate parameters are $(\lambda_1, \lambda_2, ..., \lambda_N) = ((\frac{g_1}{r_1}), (\frac{g_2}{r_2}), ..., (\frac{g_N}{r_N}))$.  This gives us a mean waiting time at all of the red lights, $x = T$ minutes, of $\sum^{k}_{i=1} \frac{1}{\lambda_i} = \sum^{N}_{i=1} \frac{1}{(\frac{g_i}{r_i})}$.  I'm having trouble, however, understanding how to correctly calculate the PDF for the hypoexponential distribution. Is the above correct? (answer: no, but the means are correct)","In order for me to drive home, I need to sequentially bypass $(S_1, S_2, ..., S_N)$ stoplights that behave stochastically.  Each stoplight, $S_i$ has some individual probability $r_i$ of being red, and an associated probability, $g_i$, per minute of time of turning from red to green. What is the probability density function for the number of minutes I spend waiting at the $N$ stoplights on my way home? Update 2: The first update is incorrect since the $T$ variable $T$ is a mix of a discrete and continuous measures (as Sasha noted), to generate our distribution for $T$, and assuming all lights are the same, we need to compute the weighted sum: Distribution for $x = T = \sum^N_{j=1} Pr[j$ lights are red upon approach$] * Erlang[j, g]$ Here, Pr[$j$ lights are red upon approach] is just the probability of $j$ successes in $N$ trials, where the probability of success is $r$. In the case where all the lights are unique, we perform the same sort of weighted sum with the hypoexponential distribution, where we have to account for all possible subsets of the lights, with unique $g_i$, being red. Update 1 (see update 2 first, this is incorrect!) : from Raskolnikov and Sasha's comments, I'm supposing that the following is the case: If we allow all the spotlights, $S_i$ to be the same, following from (http://en.wikipedia.org/wiki/Erlang_distribution), we have an Erlang (or Gamma) distribution where $k = N$ and the rate parameter is $\lambda = \frac{g}{r}$.  This gives us a mean waiting time at all the red lights, $x = T$ minutes, of $\frac{k}{\lambda} = \frac{N}{(\frac{g}{r})}$ and the following PDF for $x = T$: $\frac{\lambda^k x^{k-1} e^{-\lambda x}}{(k-1)!}$ = $\frac{(\frac{g}{r})^N T^{N-1} e^{-(\frac{g}{r}) T}}{(N-1)!}$ Now if all of the stoplights are not the same, following from (http://en.wikipedia.org/wiki/Hypoexponential_distribution), we have a hypoexponential distribution where $k = N$ and the rate parameters are $(\lambda_1, \lambda_2, ..., \lambda_N) = ((\frac{g_1}{r_1}), (\frac{g_2}{r_2}), ..., (\frac{g_N}{r_N}))$.  This gives us a mean waiting time at all of the red lights, $x = T$ minutes, of $\sum^{k}_{i=1} \frac{1}{\lambda_i} = \sum^{N}_{i=1} \frac{1}{(\frac{g_i}{r_i})}$.  I'm having trouble, however, understanding how to correctly calculate the PDF for the hypoexponential distribution. Is the above correct? (answer: no, but the means are correct)",,"['probability', 'stochastic-processes']"
31,Is Fuzzy Logic Needed? [closed],Is Fuzzy Logic Needed? [closed],,"As it currently stands, this question is not a good fit for our Q&A format. We expect answers to be supported by facts, references, or expertise, but this question will likely solicit debate, arguments, polling, or extended discussion. If you feel that this question can be improved and possibly reopened, visit the help center for guidance. Closed 11 years ago . I had a very big doubt in my mind about Fuzzyness. When statistics is answering all the questions, which we see generally in Fuzzy theory. Then why one SHOULD learn Fuzzy Theory. Or is there any gap in statistics, I mean: Is there any problems  which can be solved by Fuzzy theory and not by statistics? Please clarify with examples. Thanks in advance.","As it currently stands, this question is not a good fit for our Q&A format. We expect answers to be supported by facts, references, or expertise, but this question will likely solicit debate, arguments, polling, or extended discussion. If you feel that this question can be improved and possibly reopened, visit the help center for guidance. Closed 11 years ago . I had a very big doubt in my mind about Fuzzyness. When statistics is answering all the questions, which we see generally in Fuzzy theory. Then why one SHOULD learn Fuzzy Theory. Or is there any gap in statistics, I mean: Is there any problems  which can be solved by Fuzzy theory and not by statistics? Please clarify with examples. Thanks in advance.",,"['probability', 'statistics', 'probability-theory', 'probability-distributions', 'fuzzy-logic']"
32,Stochastic Integral which is almost surely zero at fixed time,Stochastic Integral which is almost surely zero at fixed time,,"This is an exercise from Karatzas and Shreve. Find a $(Y_s)_{s \in [0,1]}$ progressively measurable such that $ 0 < \int_0^1 Y_s ^2 ds < \infty$ almost surely, and $\int _0^1 Y_s dW_s  = 0$ almost surely where $W$ is a Brownian Motion. Not having much luck so far. I know $Y$ cannot be deterministic and that the integral cannot be a true martingale but that is about it.","This is an exercise from Karatzas and Shreve. Find a $(Y_s)_{s \in [0,1]}$ progressively measurable such that $ 0 < \int_0^1 Y_s ^2 ds < \infty$ almost surely, and $\int _0^1 Y_s dW_s  = 0$ almost surely where $W$ is a Brownian Motion. Not having much luck so far. I know $Y$ cannot be deterministic and that the integral cannot be a true martingale but that is about it.",,"['probability', 'stochastic-integrals']"
33,Might such a sequence of mathematical expectations be able to predict uncertain events?,Might such a sequence of mathematical expectations be able to predict uncertain events?,,"This question might sound a little bit mystical, but it seemed like an interesting idea, so I am posting it here. Despite the title, I know it probably does not work miracles, but here goes anyway. I have been thinking about predicting outcomes of random events, and had the following idea. Let $X$ be a random variable. Then the average value we can expect $X$ to have is $\mu := E(X)$, its mathematical expectation. This seems like a good start, but as we know from probability, random variables also have a cerain degree of dispersion. But here instead of the standard deviation, I'll use $\delta_1 := E(|X-E(X)|)$ instead, because what I'm really interested in is: ""How far away from the expected value can I expect to find the value of my variable?"" This also generalizes more faithfully, I think. So, this would lead me to think that I'd most likely find the value of my variable to be $\mu\pm\delta_1$. But here comes the next question: ""How far from $\delta_1$ will the actual error $|X-E(X)|$ lie on average?"" So we define $\delta_2:=E(\big||X-E(X)|-\delta_1\big|)$. So we have another correction: we predict that the value should be $\mu\pm\delta_1\pm\delta_2$, where the choices of $+$ and $-$ in the $\pm$ are independent (not necessarily in any statistical sense of the word). We can of course continue this indefinitely and recursively define: $$X_0:=X$$ $$\delta_0:=\mu = E(X)$$ $$X_{n+1}:=|X_n-\delta_n|$$ $$\delta_{n+1}:=E(X_{n+1})$$ And now we take the final prediction for where the value of $X$ is going to be found to be: $$\mu +\sum_{n=1}^\infty(\pm\delta_n)$$ where the choices of $+$ and $-$ in $\pm$ are again completely arbitrary and mutually independent. My questions are: What exactly does this sum describe? To me, since I do not know much physics and ascribe mystical properties to it, this looks like some sort of quantum states for the variable. On a more serious note: I'd expect (maybe after adding some appropriate conditions) the set of such sums to be dense in the interval $(\mu -\sum_{n=1}^\infty\delta_n,\mu +\sum_{n=1}^\infty\delta_n)$. [Edit: actually, after thinking about this some more, it doesn't seem so likely anymore. My intuition about it has completely abandoned me, to be honest.] Has this been explored before? (And does it have a name?) Also, if you prefer to work with standard deviations (or their squares), you can modify the above recursive definition to read $X_{n+1}=(X_n-\delta_n)^2$. Such a sequence may seem more standard, but I'm not sure it is so intuitively obvious what it describes anymore. So thoughts about this variant are also welcome.","This question might sound a little bit mystical, but it seemed like an interesting idea, so I am posting it here. Despite the title, I know it probably does not work miracles, but here goes anyway. I have been thinking about predicting outcomes of random events, and had the following idea. Let $X$ be a random variable. Then the average value we can expect $X$ to have is $\mu := E(X)$, its mathematical expectation. This seems like a good start, but as we know from probability, random variables also have a cerain degree of dispersion. But here instead of the standard deviation, I'll use $\delta_1 := E(|X-E(X)|)$ instead, because what I'm really interested in is: ""How far away from the expected value can I expect to find the value of my variable?"" This also generalizes more faithfully, I think. So, this would lead me to think that I'd most likely find the value of my variable to be $\mu\pm\delta_1$. But here comes the next question: ""How far from $\delta_1$ will the actual error $|X-E(X)|$ lie on average?"" So we define $\delta_2:=E(\big||X-E(X)|-\delta_1\big|)$. So we have another correction: we predict that the value should be $\mu\pm\delta_1\pm\delta_2$, where the choices of $+$ and $-$ in the $\pm$ are independent (not necessarily in any statistical sense of the word). We can of course continue this indefinitely and recursively define: $$X_0:=X$$ $$\delta_0:=\mu = E(X)$$ $$X_{n+1}:=|X_n-\delta_n|$$ $$\delta_{n+1}:=E(X_{n+1})$$ And now we take the final prediction for where the value of $X$ is going to be found to be: $$\mu +\sum_{n=1}^\infty(\pm\delta_n)$$ where the choices of $+$ and $-$ in $\pm$ are again completely arbitrary and mutually independent. My questions are: What exactly does this sum describe? To me, since I do not know much physics and ascribe mystical properties to it, this looks like some sort of quantum states for the variable. On a more serious note: I'd expect (maybe after adding some appropriate conditions) the set of such sums to be dense in the interval $(\mu -\sum_{n=1}^\infty\delta_n,\mu +\sum_{n=1}^\infty\delta_n)$. [Edit: actually, after thinking about this some more, it doesn't seem so likely anymore. My intuition about it has completely abandoned me, to be honest.] Has this been explored before? (And does it have a name?) Also, if you prefer to work with standard deviations (or their squares), you can modify the above recursive definition to read $X_{n+1}=(X_n-\delta_n)^2$. Such a sequence may seem more standard, but I'm not sure it is so intuitively obvious what it describes anymore. So thoughts about this variant are also welcome.",,"['probability', 'statistics']"
34,area ratios when random line cuts regular polygon,area ratios when random line cuts regular polygon,,"A point is randomly selected on one side of a polygon, and another point is randomly selected on one of the other sides. A line is drawn through those points. What is the mean expected ratio of the areas of the larger and smaller pieces created?","A point is randomly selected on one side of a polygon, and another point is randomly selected on one of the other sides. A line is drawn through those points. What is the mean expected ratio of the areas of the larger and smaller pieces created?",,"['probability', 'geometry']"
35,Problem about the sum of independent exponential variable,Problem about the sum of independent exponential variable,,"Let $X_1,\ldots,X_{n}$ be independent exponential variables with mean 1, and let $S_k = X_1+\cdots+ X_k$, it is not hard to get $\mathbb{E}(S_k)=k$. Let random variable $Y_k=|S_k-k|$, My first question is: what is the probability of $Y>t$ for some $t>0$, in another word: $\Pr(Y>t)$? Define another random variable $Z=\max_{k=1}^n Y_k$ The second question is: how to calculate $\Pr(Z>t)$ for some $t>0$ or $\mathbb {E} (Z)$.","Let $X_1,\ldots,X_{n}$ be independent exponential variables with mean 1, and let $S_k = X_1+\cdots+ X_k$, it is not hard to get $\mathbb{E}(S_k)=k$. Let random variable $Y_k=|S_k-k|$, My first question is: what is the probability of $Y>t$ for some $t>0$, in another word: $\Pr(Y>t)$? Define another random variable $Z=\max_{k=1}^n Y_k$ The second question is: how to calculate $\Pr(Z>t)$ for some $t>0$ or $\mathbb {E} (Z)$.",,['probability']
36,where are my calculations wrong? Expected value,where are my calculations wrong? Expected value,,"I am given a pdf $f(x) = |x-1|$ for $0 \leq x \leq 2,$ 0 otherwise, and asked to find expected value of $X^{2} + X.$ I simply integrated $(x^{2} + x)|x-1|$ from 0 to 2, checked with mathematica, and got $\frac{5}{2}.$ The answer in the back of the book, however, is $\frac{13}6.$ What am I doing wrong? Thanks.","I am given a pdf $f(x) = |x-1|$ for $0 \leq x \leq 2,$ 0 otherwise, and asked to find expected value of $X^{2} + X.$ I simply integrated $(x^{2} + x)|x-1|$ from 0 to 2, checked with mathematica, and got $\frac{5}{2}.$ The answer in the back of the book, however, is $\frac{13}6.$ What am I doing wrong? Thanks.",,['probability']
37,Dividing colored balls between children,Dividing colored balls between children,,"The following was an exercise I solved: We have 8 numbered balls - two blue, two red, two green, and two yellow. When dividing them between 4 children, 2 balls each, what is the probability at least one child will get two balls of the same color? I solved it using the exclusion-inclusion principle, and got the end result $3/7$. My question is, since this is such a nice fraction, was there any way of solving the problem such that I could've arrived at the fraction directly? (This is the calculation I did: http://www.wolframalpha.com/input/?i=C(4%2c1 )*(4*C(6%2c2)*C(4%2c2) C(2%2c2))%2f2520-C(4%2c2) (4*3*C(4%2c2) C(2%2c2))%2f2520%2bC(4%2c3) (4*3*2*C(2%2c2))%2f2520-C(4%2c4)*(4*3*2*1)%2f2520&incParTime=true)","The following was an exercise I solved: We have 8 numbered balls - two blue, two red, two green, and two yellow. When dividing them between 4 children, 2 balls each, what is the probability at least one child will get two balls of the same color? I solved it using the exclusion-inclusion principle, and got the end result $3/7$. My question is, since this is such a nice fraction, was there any way of solving the problem such that I could've arrived at the fraction directly? (This is the calculation I did: http://www.wolframalpha.com/input/?i=C(4%2c1 )*(4*C(6%2c2)*C(4%2c2) C(2%2c2))%2f2520-C(4%2c2) (4*3*C(4%2c2) C(2%2c2))%2f2520%2bC(4%2c3) (4*3*2*C(2%2c2))%2f2520-C(4%2c4)*(4*3*2*1)%2f2520&incParTime=true)",,['probability']
38,Probability for rearranging balls in particular order,Probability for rearranging balls in particular order,,"Given $N$ boxes, each containing one ball each say numbered as $B_1, B_2, B_3, \ldots, B_N$. We take all of these balls out and put them back in different boxes but not their original one. So, $B_1$ can be put in box $B_2, B_3, B_4, \ldots, B_N$. We can put more than one ball in a box given that the previous condition holds. What is the probability that we will end up putting one ball in a box. I am unable to solve it. Total number of cases will be $(N-1)^N$. But when calculating favorable cases I am unable to give do so correctly. If I at first put the first ball ($B_1$) back, then it has $N-1$ places to choose from. Suppose I put back it in 2nd box. Then the 2nd ball ($B_2$) has again $N-1$ positions to choose from. But if first it put back into any other box except $1$ and $2$, then $B_2$ ball has only $N-2$ positions to choose from.","Given $N$ boxes, each containing one ball each say numbered as $B_1, B_2, B_3, \ldots, B_N$. We take all of these balls out and put them back in different boxes but not their original one. So, $B_1$ can be put in box $B_2, B_3, B_4, \ldots, B_N$. We can put more than one ball in a box given that the previous condition holds. What is the probability that we will end up putting one ball in a box. I am unable to solve it. Total number of cases will be $(N-1)^N$. But when calculating favorable cases I am unable to give do so correctly. If I at first put the first ball ($B_1$) back, then it has $N-1$ places to choose from. Suppose I put back it in 2nd box. Then the 2nd ball ($B_2$) has again $N-1$ positions to choose from. But if first it put back into any other box except $1$ and $2$, then $B_2$ ball has only $N-2$ positions to choose from.",,"['probability', 'combinatorics']"
39,Statistical Inference Question,Statistical Inference Question,,"From Statistical Inference Second Edition (George Casella, Roger L. Berger) ""My telephone rings 12 times each week, the calls being randomly distributed among the 7 days. What is the probability that I get a least one call each day?"" The answer is .2285, but I don't know how they got it. My reasoning was as follows: There are 12 calls and thus 13 places to put ""day dividers"" to produce possible distributions of calls. There should be 6 day dividers for the week. One possibility: _1|2_3|4_5_6|7|8||9_10_11_12 (1 on Monday, 2 on Tuesday, 3 on Wednesday, 1 on Thursday, 1 on Friday, 0 on Saturday, 4 on Sunday) There are 13^6 possible distributions (using this method). In order to satisfy 1 call/day, dividers can't be at the beginning or end, nor can they be on top of one another (signifying a day with no calls). This means there are: 11*10*9*8*7*6 Valid distributions and a probability of: 0.069. Where am I going wrong? (P.S. This isn't homework as I'm not in school.) Edit: I don't think each ""distribution"" is equally likely. That's probably my error. But I still don't know how to get to the correct answer :)","From Statistical Inference Second Edition (George Casella, Roger L. Berger) ""My telephone rings 12 times each week, the calls being randomly distributed among the 7 days. What is the probability that I get a least one call each day?"" The answer is .2285, but I don't know how they got it. My reasoning was as follows: There are 12 calls and thus 13 places to put ""day dividers"" to produce possible distributions of calls. There should be 6 day dividers for the week. One possibility: _1|2_3|4_5_6|7|8||9_10_11_12 (1 on Monday, 2 on Tuesday, 3 on Wednesday, 1 on Thursday, 1 on Friday, 0 on Saturday, 4 on Sunday) There are 13^6 possible distributions (using this method). In order to satisfy 1 call/day, dividers can't be at the beginning or end, nor can they be on top of one another (signifying a day with no calls). This means there are: 11*10*9*8*7*6 Valid distributions and a probability of: 0.069. Where am I going wrong? (P.S. This isn't homework as I'm not in school.) Edit: I don't think each ""distribution"" is equally likely. That's probably my error. But I still don't know how to get to the correct answer :)",,"['probability', 'statistics']"
40,Sum of dependent Bernoulli random variables,Sum of dependent Bernoulli random variables,,"I tried solving this problem. Let $X_1,X_2, \dots$ be independent and identically distributed variables with $X_i∼\text{Ber}(\frac{1}{2})$ for all $i\in \mathbb{N}$ . Define $Y_i=\max\{X_i,X_{i+1}\}$ for all $i\in \mathbb{N}.$ Let $Z_n=\sum_{i=1}^nY_i.$ Calculate the mean and variance of $Z_n$ . Prove that $\lim_{n\to \infty}P(Z_n=n/2)=0$ . Prove that the sequence of independent variables ( $Z_n/n$ ) converges in probability to $3/4$ as $n\to\infty$ . I did solve 1 and 3, the mean and the variance, the mean is $3n/4$ and the variance is $5n/16-1/8$ . I have a problem with the second question. I do know that $Y_i$ is $\text{Ber}(3/4)$ , but I can't deduce that $Z_n$ distribution is $\text{bin}(n,p)$ because the $Y_i$ are dependent. I tried using the law of total probability on $X_1$ , and so on the next $X_i$ , but I just couldn't find any pattern. I also tried Chebyshev's inequality, but it doesn't work as well. Any help with this question?","I tried solving this problem. Let be independent and identically distributed variables with for all . Define for all Let Calculate the mean and variance of . Prove that . Prove that the sequence of independent variables ( ) converges in probability to as . I did solve 1 and 3, the mean and the variance, the mean is and the variance is . I have a problem with the second question. I do know that is , but I can't deduce that distribution is because the are dependent. I tried using the law of total probability on , and so on the next , but I just couldn't find any pattern. I also tried Chebyshev's inequality, but it doesn't work as well. Any help with this question?","X_1,X_2, \dots X_i∼\text{Ber}(\frac{1}{2}) i\in \mathbb{N} Y_i=\max\{X_i,X_{i+1}\} i\in \mathbb{N}. Z_n=\sum_{i=1}^nY_i. Z_n \lim_{n\to \infty}P(Z_n=n/2)=0 Z_n/n 3/4 n\to\infty 3n/4 5n/16-1/8 Y_i \text{Ber}(3/4) Z_n \text{bin}(n,p) Y_i X_1 X_i","['probability', 'probability-theory', 'statistics']"
41,Distribution of the maximum point defined by a sequence of random variables,Distribution of the maximum point defined by a sequence of random variables,,"Suppose $X_1,\cdots,X_n,\cdots$ are i.i.d. and follow the uniform distribution on $(0,1)$ : $U(0,1)$ . Define $T_n$ to be the maximum point of the function $$f_n(t)=\sum_{i=1}^{n}\frac{\log(1+t^2X_i)}{t}.$$ (1) Show that $T_n$ converges to a constant $c$ in probability. (2) Find the limiting distribution of $\sqrt{n}(T_n-c)$ . I encountered this problem when I was reviewing for the exam of statistical inference, and this problem appeared in the exam in 2022, but I didn't see how statistical inference is related to this. Anyway, I discussed this problem with my classmates and only thing we did is to write $T_n$ as the solution of the equation $$0=t^2f_n'(t)=\sum_{i=1}^{n}\left(\frac{2t^2X_i}{1+t^2X_i}-\log(1+t^2X_i)\right).$$ Then we found it pretty hard to proceed. Indeed we didn't see how to use the standard results (e.g. Laws of large numbers or Central limit theorems) or how to apply to the standard trick(e.g. calculate the characteristic function or the generating function of $T_n$ ). Any help will be appreciated.","Suppose are i.i.d. and follow the uniform distribution on : . Define to be the maximum point of the function (1) Show that converges to a constant in probability. (2) Find the limiting distribution of . I encountered this problem when I was reviewing for the exam of statistical inference, and this problem appeared in the exam in 2022, but I didn't see how statistical inference is related to this. Anyway, I discussed this problem with my classmates and only thing we did is to write as the solution of the equation Then we found it pretty hard to proceed. Indeed we didn't see how to use the standard results (e.g. Laws of large numbers or Central limit theorems) or how to apply to the standard trick(e.g. calculate the characteristic function or the generating function of ). Any help will be appreciated.","X_1,\cdots,X_n,\cdots (0,1) U(0,1) T_n f_n(t)=\sum_{i=1}^{n}\frac{\log(1+t^2X_i)}{t}. T_n c \sqrt{n}(T_n-c) T_n 0=t^2f_n'(t)=\sum_{i=1}^{n}\left(\frac{2t^2X_i}{1+t^2X_i}-\log(1+t^2X_i)\right). T_n","['probability', 'probability-theory', 'random-variables', 'statistical-inference', 'uniform-distribution']"
42,Probability of tournament never ending,Probability of tournament never ending,,"Three players $A,B,C$ play tennis matches. There is always one player waiting to face the winner of the match between the other two. For a given match both players have the same probability of winning. The tournament ends whenever a player wins two consecutive matches. What is the probability of the tournament never ending? Do all players have same chance of winning? Intuitively I would say that the probability of the match going on forever is $0$ . How can I show this formally. For the tournament to keep on going we need that player that wins first match loses the second one, the player that wins second match loses the third and so on. How can I show that the probability of the intersection of these events is $0$ . For the second question the players that play the first game clearly have the same probability of winning the tournament, however I don't know whether the one that doesn't play the first match has the same probability of winning the tournament than the other two.","Three players play tennis matches. There is always one player waiting to face the winner of the match between the other two. For a given match both players have the same probability of winning. The tournament ends whenever a player wins two consecutive matches. What is the probability of the tournament never ending? Do all players have same chance of winning? Intuitively I would say that the probability of the match going on forever is . How can I show this formally. For the tournament to keep on going we need that player that wins first match loses the second one, the player that wins second match loses the third and so on. How can I show that the probability of the intersection of these events is . For the second question the players that play the first game clearly have the same probability of winning the tournament, however I don't know whether the one that doesn't play the first match has the same probability of winning the tournament than the other two.","A,B,C 0 0",['probability']
43,Expected rank of champion in a tournament where $P$(higher rank wins)$=\frac35$. Bracket is sorted by rank.,Expected rank of champion in a tournament where (higher rank wins). Bracket is sorted by rank.,P =\frac35,"This problem is from the Simon Marais Mathematics Competition Paper B which was conducted a couple of weeks ago (on October 14, 2023). Problem statement (verbatim): There are $256$ players in a tennis tournament who are ranked from $1$ to $256$ , with $1$ corresponding to the highest rank and $256$ corresponding to the lowest rank. When two players play a match in the tournament, the player whose rank is higher wins the match with probability $\frac{3}{5}$ . In each round of the tournament, the player with the highest rank plays against the player with the second highest rank, the player with the third highest rank plays against the player with the fourth highest rank, and so on. At the end of the round, the players who win proceed to the next round and the players who lose exit the tournament. After eight rounds, there is one player remaining in the tournament and they are declared the winner. Determine the expected value of the rank of the winner. My attempt : Define a random variable $X$ denoting rank of a player. Define $P(X=n)$ to be the probability that a player with rank $n$ will be the winner. We want to determine $$\mathbb E[X]=\sum_{n=1}^{256} n\cdot P(X=n) $$ There are $2^8$ players in the first round, $2^7$ in the second round after elimination,..., $2^{9-k}$ in the $k$ -th round, and finally $2$ players in the $8$ -th i.e., final round. With this in mind, I attempted to find a probability distribution. $P(X=1)=\left(\frac{3}{5}\right)^8$ because 1 is the highest rank and this player has equal chances to win all the $8$ rounds. $P(X=2)=\left(\frac{2}{5}\right)\left(\frac{3}{5}\right)^7$ because if rank 2 can beat 1 in the first round, in following rounds, the opponents will be lower ranked. For the sake of brevity, let $a:=3/5$ and $b:=2/5$ . I computed like this till $n=10$ on my own speculating on the opponent and rounds for each player. I hope I haven't made mistake anywhere. $\displaystyle \begin{array}{ c|c|c|c|c|c|c|c|c|c|c } \text{Rank} \ n & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10\\ \hline P( X=n) & a^{8} & a^{7} b^{1} & a^{7} b^{1} & a^{6} b^{2} & a^{7} b^{1} & a^{6} b^{2} & a^{6} b^{2} & a^{5} b^{3} & a^{7} b^{1} & a^{6} b^{2} \end{array}$ I could generalize that $$P(X=2^k)=a^{8-k}b^k$$ $$P(X=2^k-1)=P(X=2^k-2)=a^{8-k+1}b^{k-1}$$ I am unable to proceed further.","This problem is from the Simon Marais Mathematics Competition Paper B which was conducted a couple of weeks ago (on October 14, 2023). Problem statement (verbatim): There are players in a tennis tournament who are ranked from to , with corresponding to the highest rank and corresponding to the lowest rank. When two players play a match in the tournament, the player whose rank is higher wins the match with probability . In each round of the tournament, the player with the highest rank plays against the player with the second highest rank, the player with the third highest rank plays against the player with the fourth highest rank, and so on. At the end of the round, the players who win proceed to the next round and the players who lose exit the tournament. After eight rounds, there is one player remaining in the tournament and they are declared the winner. Determine the expected value of the rank of the winner. My attempt : Define a random variable denoting rank of a player. Define to be the probability that a player with rank will be the winner. We want to determine There are players in the first round, in the second round after elimination,..., in the -th round, and finally players in the -th i.e., final round. With this in mind, I attempted to find a probability distribution. because 1 is the highest rank and this player has equal chances to win all the rounds. because if rank 2 can beat 1 in the first round, in following rounds, the opponents will be lower ranked. For the sake of brevity, let and . I computed like this till on my own speculating on the opponent and rounds for each player. I hope I haven't made mistake anywhere. I could generalize that I am unable to proceed further.","256 1 256 1 256 \frac{3}{5} X P(X=n) n \mathbb E[X]=\sum_{n=1}^{256} n\cdot P(X=n)  2^8 2^7 2^{9-k} k 2 8 P(X=1)=\left(\frac{3}{5}\right)^8 8 P(X=2)=\left(\frac{2}{5}\right)\left(\frac{3}{5}\right)^7 a:=3/5 b:=2/5 n=10 \displaystyle \begin{array}{ c|c|c|c|c|c|c|c|c|c|c }
\text{Rank} \ n & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10\\
\hline
P( X=n) & a^{8} & a^{7} b^{1} & a^{7} b^{1} & a^{6} b^{2} & a^{7} b^{1} & a^{6} b^{2} & a^{6} b^{2} & a^{5} b^{3} & a^{7} b^{1} & a^{6} b^{2}
\end{array} P(X=2^k)=a^{8-k}b^k P(X=2^k-1)=P(X=2^k-2)=a^{8-k+1}b^{k-1}","['probability', 'contest-math', 'expected-value']"
44,Good bound on $ \max_{|z| \le A} \left | \frac{\mathbb{E} [ X^2 \exp( -z X) ]}{ \mathbb{E} [ X \exp( -z X) ]} \right| $ where $z \in \mathbb{C}$,Good bound on  where, \max_{|z| \le A} \left | \frac{\mathbb{E} [ X^2 \exp( -z X) ]}{ \mathbb{E} [ X \exp( -z X) ]} \right|  z \in \mathbb{C},"Consider a random variable $X \in (0,1]$ and consider the following quantity \begin{align} \max_{|z| \le A} \left |  \frac{\mathbb{E} [  X^2 \exp( -z X) ]}{ \mathbb{E} [  X \exp( -z X) ]} \right|    \end{align} in the above $z \in \mathbb{C}$ . The question is the following: Can we find a good upper bound on this quantity? Here is what I did: \begin{align} \max_{|z| \le A} \left |  \frac{\mathbb{E} [  X^2 \exp( -z X) ]}{ \mathbb{E} [  X \exp( -z X) ]} \right|  & \le  \max_{|z| \le A}   \frac{\mathbb{E} [ \left |  X^2 \exp( -z X) \right| ]}{|  \mathbb{E} [  X \exp( -z X) ] | } \\ &\le \exp(A) \max_{|z| \le A}   \frac{\mathbb{E} [  X^2   ]}{ | \mathbb{E} [  X \exp( -z X) ]| }\\ &\le \exp(A)  \frac{\mathbb{E} [   X^2   ]}{ \exp(-A)  \mathbb{E} [  X  ] }   \text{ **Edit:** this step is actually not true see comment below }\\ &\le \exp(2 A)  \frac{\mathbb{E} [  X^2   ]}{   \mathbb{E} [  X  ] }\\ & \le \exp(2 A) \end{align} My question is, can we do better?  Can some kind of joint optimization be done? Edit: It might be useful to add some examples. If $X$ uniform, then we have that \begin{align} \frac{\mathbb{E} [  X^2 \exp( -z X) ]}{ \mathbb{E} [  X \exp( -z X) ]} = \frac{z}{z-e^z+1}+\frac{2}{z} \end{align} Edit2: Note that $ L(z) = \mathbb{E} [  \exp( -z X) ]$ is the Laplace transform of a random variable $X$ . The question can be equivalently rested as \begin{align} \max_{|z| \le A}  \left|  \frac{L^{(2)}(z)}{L^{(1)}(z)} \right|  \end{align}","Consider a random variable and consider the following quantity in the above . The question is the following: Can we find a good upper bound on this quantity? Here is what I did: My question is, can we do better?  Can some kind of joint optimization be done? Edit: It might be useful to add some examples. If uniform, then we have that Edit2: Note that is the Laplace transform of a random variable . The question can be equivalently rested as","X \in (0,1] \begin{align}
\max_{|z| \le A} \left |  \frac{\mathbb{E} [  X^2 \exp( -z X) ]}{ \mathbb{E} [  X \exp( -z X) ]} \right|   
\end{align} z \in \mathbb{C} \begin{align}
\max_{|z| \le A} \left |  \frac{\mathbb{E} [  X^2 \exp( -z X) ]}{ \mathbb{E} [  X \exp( -z X) ]} \right|  & \le  \max_{|z| \le A}   \frac{\mathbb{E} [ \left |  X^2 \exp( -z X) \right| ]}{|  \mathbb{E} [  X \exp( -z X) ] | } \\
&\le \exp(A) \max_{|z| \le A}   \frac{\mathbb{E} [  X^2   ]}{ | \mathbb{E} [  X \exp( -z X) ]| }\\
&\le \exp(A)  \frac{\mathbb{E} [   X^2   ]}{ \exp(-A)  \mathbb{E} [  X  ] }   \text{ **Edit:** this step is actually not true see comment below }\\
&\le \exp(2 A)  \frac{\mathbb{E} [  X^2   ]}{   \mathbb{E} [  X  ] }\\
& \le \exp(2 A)
\end{align} X \begin{align}
\frac{\mathbb{E} [  X^2 \exp( -z X) ]}{ \mathbb{E} [  X \exp( -z X) ]} = \frac{z}{z-e^z+1}+\frac{2}{z}
\end{align}  L(z) = \mathbb{E} [  \exp( -z X) ] X \begin{align}
\max_{|z| \le A}  \left|  \frac{L^{(2)}(z)}{L^{(1)}(z)} \right| 
\end{align}","['probability', 'complex-analysis', 'probability-distributions', 'laplace-transform']"
45,we throw $n$ uniform dices each with $m$ diffferent faces,we throw  uniform dices each with  diffferent faces,n m,"I'm having a hard time solving the following problem : We have $n$ uniform dices, each with $m$ different faces. We throw the dices simultaneously and see what comes out. Then we order the results in increasing order to get a number read in base $m$ . Call this $r$ . What is the average of $r$ ? I thought of representing $r$ as a random variable and calculate the mean, but I'm not sure how. The problem is that some faces may appear more than one time, and that's what makes the problem hard. There's an intuitive trick that I failed to see here.","I'm having a hard time solving the following problem : We have uniform dices, each with different faces. We throw the dices simultaneously and see what comes out. Then we order the results in increasing order to get a number read in base . Call this . What is the average of ? I thought of representing as a random variable and calculate the mean, but I'm not sure how. The problem is that some faces may appear more than one time, and that's what makes the problem hard. There's an intuitive trick that I failed to see here.",n m m r r r,"['probability', 'dice']"
46,Why is $E[X_{A \text{ or } B}]$ equal to half the harmonic mean of $E[X_A]$ and $E[X_B]$?,Why is  equal to half the harmonic mean of  and ?,E[X_{A \text{ or } B}] E[X_A] E[X_B],"[In the title I was attempting to reference a relationship similar to that of two resistors in parallel, i.e. $\dfrac{1}{R} = \dfrac{1}{R_1} + \dfrac{1}{R_2}$ ; if there's a name for such a relationship please let me know and I'll edit the title.] This question arose from an answer I recently wrote to a dice-rolling question; I'll add a link to it at the bottom but here's a a quick summary: The original question asked what the expected number of rolls of a fair 6-sided die would be until one gets either a $1$ or two consecutive $6$ 's; it also noted that the expected numbers of rolls for each of those two events considered separately are $6$ and $42$ respectively. As it turned out, the answer to that question was $\dfrac{21}{4}$ , which struck me as being somehow related to the two previously-mentioned expected values, and pretty quickly a surprising (to me, anyway) connection popped up. Let $X_A$ be the number of rolls taken until a $1$ appears, $X_B$ the number of rolls until two consecutive $6$ 's appear, and $X_{A \text{ or } B}$ the number of rolls until either a $1$ or two consecutive $6$ 's appear. Then it turned out that $$\frac{1}{\mathbb{E}[X_{A \text{ or } B}]}=\frac{1}{\mathbb{E}[X_A]}+ \frac{1}{\mathbb{E}[X_B]}$$ Trying to make sense of this, the first thing that came to mind was that if somehow these reciprocals of expected values could be thought of as probabilities, then the equation would essentially be $\Pr(A \text{ or } B)$ for mutually exclusive events, which these particular $A$ and $B$ are. The only such relationship I know of is for geometric probability distributions, where we have $\mathbb{E}[X] = \dfrac{1}{p}$ ; the probability distribution of the number of rolls until a $1$ appears is of course geometric, but I can't see how either of the other two are. Despite that, I tried to make sense of $\frac{1}{42}$ as a probability related to rolling two consecutive $6$ 's and couldn't; I also checked whether there was some property of expected values I was unfamiliar with that would explain this but came up empty. So is there an explanation for this relationship between these expected values? [Here's the link to the original question .]","[In the title I was attempting to reference a relationship similar to that of two resistors in parallel, i.e. ; if there's a name for such a relationship please let me know and I'll edit the title.] This question arose from an answer I recently wrote to a dice-rolling question; I'll add a link to it at the bottom but here's a a quick summary: The original question asked what the expected number of rolls of a fair 6-sided die would be until one gets either a or two consecutive 's; it also noted that the expected numbers of rolls for each of those two events considered separately are and respectively. As it turned out, the answer to that question was , which struck me as being somehow related to the two previously-mentioned expected values, and pretty quickly a surprising (to me, anyway) connection popped up. Let be the number of rolls taken until a appears, the number of rolls until two consecutive 's appear, and the number of rolls until either a or two consecutive 's appear. Then it turned out that Trying to make sense of this, the first thing that came to mind was that if somehow these reciprocals of expected values could be thought of as probabilities, then the equation would essentially be for mutually exclusive events, which these particular and are. The only such relationship I know of is for geometric probability distributions, where we have ; the probability distribution of the number of rolls until a appears is of course geometric, but I can't see how either of the other two are. Despite that, I tried to make sense of as a probability related to rolling two consecutive 's and couldn't; I also checked whether there was some property of expected values I was unfamiliar with that would explain this but came up empty. So is there an explanation for this relationship between these expected values? [Here's the link to the original question .]",\dfrac{1}{R} = \dfrac{1}{R_1} + \dfrac{1}{R_2} 1 6 6 42 \dfrac{21}{4} X_A 1 X_B 6 X_{A \text{ or } B} 1 6 \frac{1}{\mathbb{E}[X_{A \text{ or } B}]}=\frac{1}{\mathbb{E}[X_A]}+ \frac{1}{\mathbb{E}[X_B]} \Pr(A \text{ or } B) A B \mathbb{E}[X] = \dfrac{1}{p} 1 \frac{1}{42} 6,"['probability', 'expected-value']"
47,Limit behavior of discounted sum of Bernoulli.,Limit behavior of discounted sum of Bernoulli.,,"I am interested in studying the limit behavior of a system described by a sequence of variables $(\alpha_t)_{t=0}^\infty$ which take values in $[0,1]$ whose law of motion is as follows: $$\begin{cases}\alpha_0\in [0,1]\\ \alpha_{t+1}=\kappa\alpha_t+(1-\kappa)w_t \end{cases}$$ where $\kappa\in (0,1)$ is a persistence parameter and $w_t$ is the realization of a Bernoulli $W_t$ , whose probability of sucess depends on $\alpha_t$ : $$W_t\sim \textrm{Bern}(F(\alpha_t))$$ where $F:[0,1]\to [0,1]$ is a surjective and weakly decreasing function The specific shape of $F$ depends on the primitive of the model I am studying, but it is always ""step like"". In particular it is always the case that, $$\exists 0<a<b<1\quad st.\quad F(\alpha)=1\quad \forall \alpha\leq a\quad\land\quad F(\alpha)=0\quad \forall \alpha\geq b$$ then, either $F$ is strictly decreasing in $(a.b)$ or $F$ has a constant piece $(a^{\prime},b^{\prime})$ for some $a^{\prime}>a$ and $b^{\prime}<b$ where $F((a^{\prime},b^{\prime}))=\frac{1}{2}$ and it is strictly decreasing otherwise. Notice that $\alpha_t$ should rewrite $\alpha_t=\kappa^t\alpha_0+(1-\kappa)\sum_{i=0}^t\kappa^{t-i}w_{i-1}$ , whence the title of the question. My question is: What can I say about the limit behavior of $\alpha$ ? It seems clear to me that, doing a qualitatively study of the system, almost surely, $\alpha_t$ will eventually be in $(a-\delta_a,b+\delta_b)$ where $\delta$ 's are due to the discrete sizes of the jumps of $\alpha_t$ . But beyond this, my null experience with stochastic processes and dynamical systems lets me say nothing. Another variable of interest for me would be the average of the Bernoullis: $$\theta_{t}=\frac{\sum_{i=1}^t W_i}{t}$$ Usually, one uses some law of large numbers to study its convergence. Here, the Bernoullis are all correlated and not identically distributed, so the standard results do not apply. Is there any result I could exploit? Any help or reference on systems of this kind would be really appreciated.","I am interested in studying the limit behavior of a system described by a sequence of variables which take values in whose law of motion is as follows: where is a persistence parameter and is the realization of a Bernoulli , whose probability of sucess depends on : where is a surjective and weakly decreasing function The specific shape of depends on the primitive of the model I am studying, but it is always ""step like"". In particular it is always the case that, then, either is strictly decreasing in or has a constant piece for some and where and it is strictly decreasing otherwise. Notice that should rewrite , whence the title of the question. My question is: What can I say about the limit behavior of ? It seems clear to me that, doing a qualitatively study of the system, almost surely, will eventually be in where 's are due to the discrete sizes of the jumps of . But beyond this, my null experience with stochastic processes and dynamical systems lets me say nothing. Another variable of interest for me would be the average of the Bernoullis: Usually, one uses some law of large numbers to study its convergence. Here, the Bernoullis are all correlated and not identically distributed, so the standard results do not apply. Is there any result I could exploit? Any help or reference on systems of this kind would be really appreciated.","(\alpha_t)_{t=0}^\infty [0,1] \begin{cases}\alpha_0\in [0,1]\\
\alpha_{t+1}=\kappa\alpha_t+(1-\kappa)w_t
\end{cases} \kappa\in (0,1) w_t W_t \alpha_t W_t\sim \textrm{Bern}(F(\alpha_t)) F:[0,1]\to [0,1] F \exists 0<a<b<1\quad st.\quad F(\alpha)=1\quad \forall \alpha\leq a\quad\land\quad F(\alpha)=0\quad \forall \alpha\geq b F (a.b) F (a^{\prime},b^{\prime}) a^{\prime}>a b^{\prime}<b F((a^{\prime},b^{\prime}))=\frac{1}{2} \alpha_t \alpha_t=\kappa^t\alpha_0+(1-\kappa)\sum_{i=0}^t\kappa^{t-i}w_{i-1} \alpha \alpha_t (a-\delta_a,b+\delta_b) \delta \alpha_t \theta_{t}=\frac{\sum_{i=1}^t W_i}{t}","['real-analysis', 'probability', 'reference-request', 'stochastic-processes', 'dynamical-systems']"
48,The mathematical problem with beer,The mathematical problem with beer,,"A problem is given: $322$ mathematicians walk into a bar, numbered from $1$ to $322$ , each picks someone other than himself at random and writes down his number on a piece of paper. The barman names the first mathematician, he orders a beer for the one he has written on the slip, then the next mathematician in line comes to the barman who has not yet been ordered a beer, orders the one he has written on the slip and so on. How many mathematicians will be left without beer in the expectation? My attempt at a solution: Let's denote by $X_i$ a random variable that equals 1 if the $i$ th mathematician did not get a beer, and equals 0 if the $i$ th mathematician got a beer. We want to find the mathematical expectation of the number of mathematicians who will remain without beer $$\mathbb{E}\left [ \sum_{i=1}^{322}X_i \right ]=\sum_{i=1}^{322}\mathbb{E}[X_i]$$ Now we need to find the mathematical expectation of $X_i$ . Consider the $i$ th mathematician. The chance that he won't get a beer is equal to the probability that his name won't be written on a piece of paper by someone else. The probability that $i$ th mathematician will not be chosen by $j$ th mathematician is $\frac{321}{321}$ (since $j$ cannot choose himself). The probability that $i$ -th mathematician will not be chosen by any of the other $321$ -mathematicians is equal to: $$\left ( 1-\frac{1}{321} \right )^{321}$$ We can now find the mathematical expectation of $X_i$ : $$\mathbb{E}[X_i]=1\cdot \left ( 1-\frac{1}{321} \right )^{321}+0\cdot \left ( 1-\left ( 1-\frac{1}{321} \right )^{321} \right )\approx 0,368$$ On average about $0,368 \cdot 322 \approx 118,6$ of maths will be left without beer. The answer is $\boxed{119}$ I'm not at all sure about the decision. Could you tell me if I have solved it correctly ?","A problem is given: mathematicians walk into a bar, numbered from to , each picks someone other than himself at random and writes down his number on a piece of paper. The barman names the first mathematician, he orders a beer for the one he has written on the slip, then the next mathematician in line comes to the barman who has not yet been ordered a beer, orders the one he has written on the slip and so on. How many mathematicians will be left without beer in the expectation? My attempt at a solution: Let's denote by a random variable that equals 1 if the th mathematician did not get a beer, and equals 0 if the th mathematician got a beer. We want to find the mathematical expectation of the number of mathematicians who will remain without beer Now we need to find the mathematical expectation of . Consider the th mathematician. The chance that he won't get a beer is equal to the probability that his name won't be written on a piece of paper by someone else. The probability that th mathematician will not be chosen by th mathematician is (since cannot choose himself). The probability that -th mathematician will not be chosen by any of the other -mathematicians is equal to: We can now find the mathematical expectation of : On average about of maths will be left without beer. The answer is I'm not at all sure about the decision. Could you tell me if I have solved it correctly ?","322 1 322 X_i i i \mathbb{E}\left [ \sum_{i=1}^{322}X_i \right ]=\sum_{i=1}^{322}\mathbb{E}[X_i] X_i i i j \frac{321}{321} j i 321 \left ( 1-\frac{1}{321} \right )^{321} X_i \mathbb{E}[X_i]=1\cdot \left ( 1-\frac{1}{321} \right )^{321}+0\cdot \left ( 1-\left ( 1-\frac{1}{321} \right )^{321} \right )\approx 0,368 0,368 \cdot 322 \approx 118,6 \boxed{119}","['probability', 'probability-theory', 'expected-value']"
49,A game that costs the square root of your winnings,A game that costs the square root of your winnings,,"Imagine a sequence of games that charges you the square root of your total winnings to play. Your winnings at time $n + 1$ are $$S_{n + 1} = S_n + R_{n + 1} - \sqrt{S_n},$$ where $R_{n + 1}$ is your reward at time $n + 1$ . Say that you start at $S_0 = 0$ and your reward is always at least $1$ . Empirically, when $R_n$ are iid variables and $E[R_n] = \mu$ is big, it seems like $S_n$ converges to $\mu^2$ , and that the convergence is better when the variance of $R_n$ is small. Is this true? Why? What kind of convergence is it? Pointwise? In measure? L2? The analogous deterministic sequence $a_{n + 1} = a_n + r - \sqrt{a_n}$ does converge to $r^2$ , but the proof relies on inequalities that don't make sense in the random case. Here's a picture of some realizations of this sequence where the rewards are Poisson random variables with mean $30$ . I expect them to converge to $30^2 = 900$ , and they more or less do.","Imagine a sequence of games that charges you the square root of your total winnings to play. Your winnings at time are where is your reward at time . Say that you start at and your reward is always at least . Empirically, when are iid variables and is big, it seems like converges to , and that the convergence is better when the variance of is small. Is this true? Why? What kind of convergence is it? Pointwise? In measure? L2? The analogous deterministic sequence does converge to , but the proof relies on inequalities that don't make sense in the random case. Here's a picture of some realizations of this sequence where the rewards are Poisson random variables with mean . I expect them to converge to , and they more or less do.","n + 1 S_{n + 1} = S_n + R_{n + 1} - \sqrt{S_n}, R_{n + 1} n + 1 S_0 = 0 1 R_n E[R_n] = \mu S_n \mu^2 R_n a_{n + 1} = a_n + r - \sqrt{a_n} r^2 30 30^2 = 900","['probability', 'probability-theory']"
50,Law of large numbers for the number of connected components in a random graph,Law of large numbers for the number of connected components in a random graph,,"A network evolves similarly to the Preferential Attachment model, with some important modification. The network starts at time $t = 1$ with one isolated vertex. At any step $t ≥ 2$ , a new vertex, $v_t$ , arrives and connects to precisely one of the already existing vertices with probability $1/t$ , while it connects to itself (forming a loop) also with probability $1/t$ . Let $N_t$ denote the number of connected components in this evolving graph at time $t$ . To show : there exists a deterministic sequence $a_t$ such that $N_t/a_t \xrightarrow{\mathbb{P}} 1$ as $t \to \infty$ . Here, $t = 1, 2, \dotsc$ . My attempt so far: I was thinking of computing $\mathbb{E}[N_t]$ and show that for any $\varepsilon > 0$ , $$ \lim_{t \to \infty}\mathbb{P}(|N_t - \mathbb{E}[N_t]| \geq \varepsilon) = 0. $$ First I of course need to determine what $\mathbb{E}[N_t]$ is. Let $G_t$ be a graph at step $t$ and $n_t = |V(G_t)|$ . From the given information, I know that for $i, j \in [n_t]$ and $i \neq j$ , $$ \mathbb{P}(i \longrightarrow j | G_t) = \frac{1}{t} = \mathbb{P}(i \longrightarrow i | G_t). $$ I have that $$ \mathbb{E}[N_{t+1}] = \mathbb{E}[\mathbb{E}[N_{t+1}|G_t]] = \mathbb{E}[\mathbb{E}[N_{t+1} - N_t + N_t|G_t]] = \mathbb{E}[N_t] + \mathbb{E}[\mathbb{E}[N_{t+1} - N_t|G_t]]. $$ I can only think of one possibility that $N_{t+1} - N_t$ is non zero, given $G_t$ . This is because if a vertex at step $t + 1$ connects to any vertex from $G_t$ , then the number of connected components does not increase, meaning that $N_{t+1} = N_t$ . However, if that vertex at step $t + 1$ forms a self-loop, then the number of connected component increases by one with probability $1/(t+1)$ . Therefore, $$ \mathbb{E}[N_{t+1}] = \mathbb{E}[N_{t}] + \frac{1}{t+1}. $$ This is a recurrence relation that I can solve. Let $\mathbb{E}[N_1] = 1$ , which is reasonable because at $t = 1$ , there is only one isolated point and so there is only one connected component. Then, $$ \mathbb{E}[N_2] = 1 + \frac{1}{2}; \ \mathbb{E}[N_3] = 1 + \frac{1}{2} + \frac{1}{3}; \ \mathbb{E}[N_4] = 1 + \frac{1}{2} + \frac{1}{3} + \frac{1}{4}; \cdots; \ \mathbb{E}[N_t] = \sum_{k=1}^t\frac{1}{k}. $$ Now I need to prove the convergence in probability. By using the Chebychev inequality, $$ \mathbb{P}(|N_t - \mathbb{E}[N_t]| \geq \varepsilon) \leq \frac{\operatorname{Var}(N_t)}{\varepsilon^2} = \frac{\mathbb{E}[N_t^2] - \mathbb{E}[N_t]^2}{\varepsilon^2} $$ Here is where I get stuck: I have no idea what the second moment of $N_t$ is. There is hint that $$ \log(t+1) \leq \sum_{k=1}^t\frac{1}{k} \leq 1 + \log t $$ But with this I can bound $\mathbb{E}[N_t]^2$ from above. Other thing that I have tried to write the probability as the following: $$ \mathbb{P}(|N_t - \mathbb{E}[N_t]| \geq \varepsilon) = \mathbb{P}(N_t - \mathbb{E}[N_t] \leq-\varepsilon) + \mathbb{P}(N_t - \mathbb{E}[N_t] \geq \varepsilon) $$ Then, by Markov's inequality and the given hint, $$ \mathbb{P}(N_t - \mathbb{E}[N_t] \geq \varepsilon) \leq \frac{\mathbb{E}[N_t]}{\varepsilon + \mathbb{E}[N_t]} \leq \frac{1 + \log t}{\varepsilon + \log(t+1)^{-1}}. $$ This won't go to zero and I am not sure how to bound $\mathbb{P}(N_t - \mathbb{E}[N_t] \leq-\varepsilon)$ as well. What should I do?","A network evolves similarly to the Preferential Attachment model, with some important modification. The network starts at time with one isolated vertex. At any step , a new vertex, , arrives and connects to precisely one of the already existing vertices with probability , while it connects to itself (forming a loop) also with probability . Let denote the number of connected components in this evolving graph at time . To show : there exists a deterministic sequence such that as . Here, . My attempt so far: I was thinking of computing and show that for any , First I of course need to determine what is. Let be a graph at step and . From the given information, I know that for and , I have that I can only think of one possibility that is non zero, given . This is because if a vertex at step connects to any vertex from , then the number of connected components does not increase, meaning that . However, if that vertex at step forms a self-loop, then the number of connected component increases by one with probability . Therefore, This is a recurrence relation that I can solve. Let , which is reasonable because at , there is only one isolated point and so there is only one connected component. Then, Now I need to prove the convergence in probability. By using the Chebychev inequality, Here is where I get stuck: I have no idea what the second moment of is. There is hint that But with this I can bound from above. Other thing that I have tried to write the probability as the following: Then, by Markov's inequality and the given hint, This won't go to zero and I am not sure how to bound as well. What should I do?","t = 1 t ≥ 2 v_t 1/t 1/t N_t t a_t N_t/a_t \xrightarrow{\mathbb{P}} 1 t \to \infty t = 1, 2, \dotsc \mathbb{E}[N_t] \varepsilon > 0 
\lim_{t \to \infty}\mathbb{P}(|N_t - \mathbb{E}[N_t]| \geq \varepsilon) = 0.
 \mathbb{E}[N_t] G_t t n_t = |V(G_t)| i, j \in [n_t] i \neq j 
\mathbb{P}(i \longrightarrow j | G_t) = \frac{1}{t} = \mathbb{P}(i \longrightarrow i | G_t).
 
\mathbb{E}[N_{t+1}] = \mathbb{E}[\mathbb{E}[N_{t+1}|G_t]] = \mathbb{E}[\mathbb{E}[N_{t+1} - N_t + N_t|G_t]] = \mathbb{E}[N_t] + \mathbb{E}[\mathbb{E}[N_{t+1} - N_t|G_t]].
 N_{t+1} - N_t G_t t + 1 G_t N_{t+1} = N_t t + 1 1/(t+1) 
\mathbb{E}[N_{t+1}] = \mathbb{E}[N_{t}] + \frac{1}{t+1}.
 \mathbb{E}[N_1] = 1 t = 1 
\mathbb{E}[N_2] = 1 + \frac{1}{2}; \ \mathbb{E}[N_3] = 1 + \frac{1}{2} + \frac{1}{3}; \ \mathbb{E}[N_4] = 1 + \frac{1}{2} + \frac{1}{3} + \frac{1}{4}; \cdots; \ \mathbb{E}[N_t] = \sum_{k=1}^t\frac{1}{k}.
 
\mathbb{P}(|N_t - \mathbb{E}[N_t]| \geq \varepsilon) \leq \frac{\operatorname{Var}(N_t)}{\varepsilon^2} = \frac{\mathbb{E}[N_t^2] - \mathbb{E}[N_t]^2}{\varepsilon^2}
 N_t 
\log(t+1) \leq \sum_{k=1}^t\frac{1}{k} \leq 1 + \log t
 \mathbb{E}[N_t]^2 
\mathbb{P}(|N_t - \mathbb{E}[N_t]| \geq \varepsilon) = \mathbb{P}(N_t - \mathbb{E}[N_t] \leq-\varepsilon) + \mathbb{P}(N_t - \mathbb{E}[N_t] \geq \varepsilon)
 
\mathbb{P}(N_t - \mathbb{E}[N_t] \geq \varepsilon) \leq \frac{\mathbb{E}[N_t]}{\varepsilon + \mathbb{E}[N_t]} \leq \frac{1 + \log t}{\varepsilon + \log(t+1)^{-1}}.
 \mathbb{P}(N_t - \mathbb{E}[N_t] \leq-\varepsilon)","['probability', 'convergence-divergence', 'probability-limit-theorems', 'law-of-large-numbers', 'random-graphs']"
51,"Birthday paradox - variance, parallelisation, simple proofs?","Birthday paradox - variance, parallelisation, simple proofs?",,"I am looking for an elementary proof of the fact that expected time for finding a colision with $n$ bins is $\sqrt{\frac{\pi n}{2}} + O(1)$ . The proof that I knows relies on the asymptotic expansion of the Ramanujan $Q$ -function. Additional information on the parallel algorithm (discussed below) is welcome too. Background information below Suppose we sample uniformly random elements from a set of cardinality $n$ , and save them in a table. We continue doing this process (each sampling is one step) until we get a collision. What is the expected number of steps until we find the first collision? This is a common problem, also known as the birthday paradox, since the solution is $O(\sqrt{n})$ which is rather unintuitive. Suppose we sample $k$ times. Then, the probability of having no collisions after $k$ steps is $$ \prod_{i=0}^{k-1}\left(\frac{n-i}{n}\right) = \prod_{i=0}^{k-1}\left(1-\frac{i}{n}\right) \leq \prod_{i=0}^{k-1}e^{\frac{-i}{n}} = e^{-\sum_{i=0}^{k-1}\frac{i}{n}}=e^{\frac{-k(k-1)}{2n}}\approx e^{-\frac{k^2}{n}}, $$ and so the probability of a collision with $k$ steps is $$ 1 - \prod_{i=0}^{k-1}\left(\frac{n-i}{n}\right) \geq 1 - e^{-\frac{k^2}{n}} $$ which is $O(1)$ when $k=\Theta(\sqrt{n})$ . The probability of no collision after $k$ steps can also be written as $\frac{n!}{(n-(k-1))! n^k}$ . Now consider the following question What is the expected number of steps until the first collision? I haven't seen an easy solution to this problem. This question and the corresponding Wikipedia page treat it, without a proof. Let $X$ is the random variable ""index of step of first collision"". Then $$ \mathbb{E}[X] = \sum_{k=1}^{\infty} \mathbb{P}[X \geq k] = 1 + \sum_{k=1}^n \frac{n!}{n^k (n-k)!}, $$ which is easy to prove from the above formula. Now comes the non-trivial part. The function $$ Q(n) = \sum_{k=1}^n \frac{n!}{n^k (n-k)!} $$ is known as the Ramanujan $Q$ -function, and has the asymptotic expansion (in $\sqrt{n}$ ) $$ Q(n) = \sqrt{\frac{\pi n}{2}} - \frac{1}{3} + \frac{1}{12}\sqrt{\frac{\pi}{2n}} + O\left(\frac{1}{n}\right), $$ and therefore the expected number of steps until first collision is $\sqrt{\frac{\pi n}{2}} + O(1)$ . Is there a simpler proof that the expected number of steps is $\Theta(\sqrt{n})$ ? What is the variance of $X$ ? Now suppose we parallelise, i.e., we run the same algorithm on $m$ different machines which do not communicate with each other. What is the expected run time until we find the first collision? The interesting thing here is that parallelisation with $m$ machines only gives a $\sqrt{m}$ improvement in the run-time. One can do a similar argument to show that after $k$ steps the probability of having no collisions is $$ \prod_{i=0}^{k-1}\left(\frac{n-i}{n}\right)^m = \cdots \approx e^{-\frac{k^2m}{2n}}, $$ so we will have an $O(1)$ probability of collision when $k^2m \approx n$ . Since the run-time is $k$ we have $k \geq \sqrt{\frac{n}{m}}$ , so increasing $m$ only gives a square-root improvement in the run-time $k$ . However, I read here that the expected number of steps until first collision is $\sqrt{\frac{\pi n}{2m}} + O(1)$ , which is a statement that I can't prove, so my final question is How do I prove that for the parallel algorithm the expected number of steps until first collision is $\sqrt{\frac{\pi n}{2m}} + O(1)$ ? But I'd also like to ask Is there a simple proof that this expected number of steps is $\Theta(\sqrt{\frac{n}{m}})$ ? What is the variance of the number of steps ? I feel like the parallelisation questions should be easily provable if one knowns the variance of $X$ .","I am looking for an elementary proof of the fact that expected time for finding a colision with bins is . The proof that I knows relies on the asymptotic expansion of the Ramanujan -function. Additional information on the parallel algorithm (discussed below) is welcome too. Background information below Suppose we sample uniformly random elements from a set of cardinality , and save them in a table. We continue doing this process (each sampling is one step) until we get a collision. What is the expected number of steps until we find the first collision? This is a common problem, also known as the birthday paradox, since the solution is which is rather unintuitive. Suppose we sample times. Then, the probability of having no collisions after steps is and so the probability of a collision with steps is which is when . The probability of no collision after steps can also be written as . Now consider the following question What is the expected number of steps until the first collision? I haven't seen an easy solution to this problem. This question and the corresponding Wikipedia page treat it, without a proof. Let is the random variable ""index of step of first collision"". Then which is easy to prove from the above formula. Now comes the non-trivial part. The function is known as the Ramanujan -function, and has the asymptotic expansion (in ) and therefore the expected number of steps until first collision is . Is there a simpler proof that the expected number of steps is ? What is the variance of ? Now suppose we parallelise, i.e., we run the same algorithm on different machines which do not communicate with each other. What is the expected run time until we find the first collision? The interesting thing here is that parallelisation with machines only gives a improvement in the run-time. One can do a similar argument to show that after steps the probability of having no collisions is so we will have an probability of collision when . Since the run-time is we have , so increasing only gives a square-root improvement in the run-time . However, I read here that the expected number of steps until first collision is , which is a statement that I can't prove, so my final question is How do I prove that for the parallel algorithm the expected number of steps until first collision is ? But I'd also like to ask Is there a simple proof that this expected number of steps is ? What is the variance of the number of steps ? I feel like the parallelisation questions should be easily provable if one knowns the variance of .","n \sqrt{\frac{\pi n}{2}} + O(1) Q n O(\sqrt{n}) k k 
\prod_{i=0}^{k-1}\left(\frac{n-i}{n}\right) = \prod_{i=0}^{k-1}\left(1-\frac{i}{n}\right) \leq \prod_{i=0}^{k-1}e^{\frac{-i}{n}} = e^{-\sum_{i=0}^{k-1}\frac{i}{n}}=e^{\frac{-k(k-1)}{2n}}\approx e^{-\frac{k^2}{n}},
 k 
1 - \prod_{i=0}^{k-1}\left(\frac{n-i}{n}\right) \geq 1 - e^{-\frac{k^2}{n}}
 O(1) k=\Theta(\sqrt{n}) k \frac{n!}{(n-(k-1))! n^k} X 
\mathbb{E}[X] = \sum_{k=1}^{\infty} \mathbb{P}[X \geq k] = 1 + \sum_{k=1}^n \frac{n!}{n^k (n-k)!},
 
Q(n) = \sum_{k=1}^n \frac{n!}{n^k (n-k)!}
 Q \sqrt{n} 
Q(n) = \sqrt{\frac{\pi n}{2}} - \frac{1}{3} + \frac{1}{12}\sqrt{\frac{\pi}{2n}} + O\left(\frac{1}{n}\right),
 \sqrt{\frac{\pi n}{2}} + O(1) \Theta(\sqrt{n}) X m m \sqrt{m} k 
\prod_{i=0}^{k-1}\left(\frac{n-i}{n}\right)^m = \cdots \approx e^{-\frac{k^2m}{2n}},
 O(1) k^2m \approx n k k \geq \sqrt{\frac{n}{m}} m k \sqrt{\frac{\pi n}{2m}} + O(1) \sqrt{\frac{\pi n}{2m}} + O(1) \Theta(\sqrt{\frac{n}{m}}) X","['probability', 'expected-value', 'variance', 'birthday', 'collision-detection']"
52,Dice game: bidding for sum,Dice game: bidding for sum,,"Consider the following two-player game. Both players roll a fair die. They can see their own roll, but not their opponent's roll. Then, both players simultaneously choose a (possibly fractional) amount to bid. Whoever bids higher wins the sum of the two die rolls minus their bid, while the lower bidder gains nothing. When they bid the same amount, both players get nothing. What is the best strategy for this game? What are the Nash equilibria? Let n be the number you roll, then the random variable for the sum is uniform between $[n+1, n+6]$ . The expected value for the opponent’s roll is 3.5 and so the expected sum would be $n + 3.5$ , I will bid as close to the expected sum as possible (so the first whole number that is below the expected sum $n + 3.5$ ), which would give me an expected payoff of $0.5$ . Is this solution correct? I don't know if adding the expected value part is the best strategy, but I assume I want to lower the chance of the opponent getting around the expected value. Edit: The question was not clear about whether the bid is announced to the other player, but since if it is announced we have to consider the sequence (whether I am first or second), I assume the bids are secret. Though I want to know what the strategies would be for the two different cases (secret and non-secret), if I can choose to bid first/second? You can bid any amount and the opponent is a rational player. To give an example of the run, you got 3 and your‍‍‌‌‍‌‌‌‍‌‌‌‍‍‍‍‌‍‍‍ opponent got 6, and if you bid 7 and the opponent bids 8, whoever wins the bid will get 9 points minus the points they bid, so the opponent wins and get 1 point in this case. If there is a tie in the bids, then there is no prize. If you bid a 10 instead of a 7, then you would win the bid, and get -1 point.","Consider the following two-player game. Both players roll a fair die. They can see their own roll, but not their opponent's roll. Then, both players simultaneously choose a (possibly fractional) amount to bid. Whoever bids higher wins the sum of the two die rolls minus their bid, while the lower bidder gains nothing. When they bid the same amount, both players get nothing. What is the best strategy for this game? What are the Nash equilibria? Let n be the number you roll, then the random variable for the sum is uniform between . The expected value for the opponent’s roll is 3.5 and so the expected sum would be , I will bid as close to the expected sum as possible (so the first whole number that is below the expected sum ), which would give me an expected payoff of . Is this solution correct? I don't know if adding the expected value part is the best strategy, but I assume I want to lower the chance of the opponent getting around the expected value. Edit: The question was not clear about whether the bid is announced to the other player, but since if it is announced we have to consider the sequence (whether I am first or second), I assume the bids are secret. Though I want to know what the strategies would be for the two different cases (secret and non-secret), if I can choose to bid first/second? You can bid any amount and the opponent is a rational player. To give an example of the run, you got 3 and your‍‍‌‌‍‌‌‌‍‌‌‌‍‍‍‍‌‍‍‍ opponent got 6, and if you bid 7 and the opponent bids 8, whoever wins the bid will get 9 points minus the points they bid, so the opponent wins and get 1 point in this case. If there is a tie in the bids, then there is no prize. If you bid a 10 instead of a 7, then you would win the bid, and get -1 point.","[n+1, n+6] n + 3.5 n + 3.5 0.5","['probability', 'probability-theory', 'expected-value', 'game-theory', 'dice']"
53,Bound the probability of multivariate gaussian vector norm.,Bound the probability of multivariate gaussian vector norm.,,"Let's say $v \in \mathbb{R}^n \sim \mathcal{N}(0, \sigma I)$ . That is, $v$ is a gaussian random vector, whose entries are distributed $\mathcal{N}(0, \sigma)$ i.i.d. From the book ""C. Giraud. Introduction to high-dimensional statistics"", it can be concluded that $$ P\left(\frac{\sigma}{\sqrt{2}} \le \frac{\|v\|}{\sqrt{n}} \le \left( 2 - \frac{1}{\sqrt{2}} \right) \sigma \right) \ge 1 - (1 + e^2) e^{-n/24} $$ Now, $W \in \mathbb{R}^{m \times n}$ is a deterministic matrix with normalized rows. My goal is to bound the event $$ P\left(\frac{\sigma}{\sqrt{2}} \le \frac{\|W v\|}{\sqrt{m}} \le 2 \sigma \right) $$ preferably with a similar bound as above. We can see that $W v \in \mathbb{R}^m \sim \mathcal{N}(0, \sigma W W^T)$ . My first idea was to define it as a generalized chi-squared distribution. It seems as an overkill, since this case is a lot simpler than the generalized one and it doesn't have a closed form. Second, I tried writing it as a sum of weighted chi-squared, where the weights are the eigenvalues of $W$ . This could work, but I'd rather have it in terms of $W$ , not its eigenvalues. Is there a better way? I would like it very much to hear new interesting approaches. Thank you! I really appreciate the help!","Let's say . That is, is a gaussian random vector, whose entries are distributed i.i.d. From the book ""C. Giraud. Introduction to high-dimensional statistics"", it can be concluded that Now, is a deterministic matrix with normalized rows. My goal is to bound the event preferably with a similar bound as above. We can see that . My first idea was to define it as a generalized chi-squared distribution. It seems as an overkill, since this case is a lot simpler than the generalized one and it doesn't have a closed form. Second, I tried writing it as a sum of weighted chi-squared, where the weights are the eigenvalues of . This could work, but I'd rather have it in terms of , not its eigenvalues. Is there a better way? I would like it very much to hear new interesting approaches. Thank you! I really appreciate the help!","v \in \mathbb{R}^n \sim \mathcal{N}(0, \sigma I) v \mathcal{N}(0, \sigma) 
P\left(\frac{\sigma}{\sqrt{2}} \le \frac{\|v\|}{\sqrt{n}} \le \left( 2 - \frac{1}{\sqrt{2}} \right) \sigma \right) \ge 1 - (1 + e^2) e^{-n/24}
 W \in \mathbb{R}^{m \times n} 
P\left(\frac{\sigma}{\sqrt{2}} \le \frac{\|W v\|}{\sqrt{m}} \le 2 \sigma \right)
 W v \in \mathbb{R}^m \sim \mathcal{N}(0, \sigma W W^T) W W","['probability', 'statistics', 'probability-distributions', 'normal-distribution', 'chi-squared']"
54,Permutations of Independent Probabilities,Permutations of Independent Probabilities,,"Problem: Say that I have a list of $n$ tasks to complete. Each of the tasks have independent probabilities $p_1, p_2, ..., p_n$ of completing that task. There is a particular task on the list that I want to get completed. However, the list will be generated in a random order and I have to complete each task in order. Once I complete the particular task that I have in mind, I have succeeded and the rest of the list does not matter. What is the probability that I will complete the task? My attempt at solving it: To make it easier, I assume that the task that I want to complete is task $n$ (the task with independent probability $p_n$ ). I hope I'm not messing anything up by making that assumption. I read something that basically said that the total probability of completing task $n$ would be $$P(task_n) = \frac{1}{n}\sum_{i=1}^n \left(p_n*\left(\frac{\sum_{j=1}^{n-1} p_j}{n-1}\right)^{i-1}\right)$$ But although the equation seems to work for $i=1$ and $i=2$ , it stops working after that point. I'm pretty sure that's because this equation is not taking into account that there is no repetition in the tasks. Basically what that equation is trying to do is taking each possible location for $task_n$ to show up on the list, calculating the probability that you get to that task given that it is put in that position, and then averaging all of those together. That general approach made sense to me, because there is an equal probability of that task showing up in each position. So I tried figuring out equations given each position to see if I could find the pattern and extrapolate a general equation. I didn't get very far. Case 1 : $task_n$ shows up in position 1. $$P(task_n, pos_1)=p_n$$ This is the most straightforward case. If $task_n$ shows up first on the list, then the total probability of completing it is exactly the same as the independent probability of completing that task. Case 2 : $task_n$ shows up in position 2. $$P(task_n, pos_2)=p_n \left( \frac{\sum_{j=1}^{n-1}p_j}{n-1} \right)$$ Still pretty straightforward. If $task_n$ shows up second on the list, then the total probability of completing it is equal to its individual probability times the probability of whatever shows up in position 1. Since all other tasks on the list have an equal chance of showing up, average all those probabilities together. Case 3 : $task_n$ shows up in position 3. $$P(task_n, pos_3)=p_n \left( \frac{\sum_{j=1}^{n-1}p_j\left( \sum_{k=1}^{n-1}(p_k)-p_j \right)}{(n-1)(n-2)} \right)$$ So this is where it starts getting complicated, and I wasn't able to figure out any equation for position 4 or after. At this point, I can see that I'm just multiplying the probabilities of all previous tasks, but I'm basically subtracting out the instance that the task is repeated. I know that another way to look at this is that we're finding the product of all possible ways to choose 1 out of $p_1, p_2, ..., p_{n-1}$ , then choose 2, then choose 3, ... then choose $n-1$ , and averaging that all out. I just don't know how to put that into a single formula. I feel like I'm on the right track, but at the same time the equation gets so much more complicated after this that I feel like I'm not getting anywhere. I tried looking it up because this equation must exist out there somewhere, but I couldn't figure out how to search it because if I try looking for ""permutations of probabilities"" then I all I get is basic prealgebra homework problems. Please help, this has been killing my brain for days.","Problem: Say that I have a list of tasks to complete. Each of the tasks have independent probabilities of completing that task. There is a particular task on the list that I want to get completed. However, the list will be generated in a random order and I have to complete each task in order. Once I complete the particular task that I have in mind, I have succeeded and the rest of the list does not matter. What is the probability that I will complete the task? My attempt at solving it: To make it easier, I assume that the task that I want to complete is task (the task with independent probability ). I hope I'm not messing anything up by making that assumption. I read something that basically said that the total probability of completing task would be But although the equation seems to work for and , it stops working after that point. I'm pretty sure that's because this equation is not taking into account that there is no repetition in the tasks. Basically what that equation is trying to do is taking each possible location for to show up on the list, calculating the probability that you get to that task given that it is put in that position, and then averaging all of those together. That general approach made sense to me, because there is an equal probability of that task showing up in each position. So I tried figuring out equations given each position to see if I could find the pattern and extrapolate a general equation. I didn't get very far. Case 1 : shows up in position 1. This is the most straightforward case. If shows up first on the list, then the total probability of completing it is exactly the same as the independent probability of completing that task. Case 2 : shows up in position 2. Still pretty straightforward. If shows up second on the list, then the total probability of completing it is equal to its individual probability times the probability of whatever shows up in position 1. Since all other tasks on the list have an equal chance of showing up, average all those probabilities together. Case 3 : shows up in position 3. So this is where it starts getting complicated, and I wasn't able to figure out any equation for position 4 or after. At this point, I can see that I'm just multiplying the probabilities of all previous tasks, but I'm basically subtracting out the instance that the task is repeated. I know that another way to look at this is that we're finding the product of all possible ways to choose 1 out of , then choose 2, then choose 3, ... then choose , and averaging that all out. I just don't know how to put that into a single formula. I feel like I'm on the right track, but at the same time the equation gets so much more complicated after this that I feel like I'm not getting anywhere. I tried looking it up because this equation must exist out there somewhere, but I couldn't figure out how to search it because if I try looking for ""permutations of probabilities"" then I all I get is basic prealgebra homework problems. Please help, this has been killing my brain for days.","n p_1, p_2, ..., p_n n p_n n P(task_n) = \frac{1}{n}\sum_{i=1}^n \left(p_n*\left(\frac{\sum_{j=1}^{n-1} p_j}{n-1}\right)^{i-1}\right) i=1 i=2 task_n task_n P(task_n, pos_1)=p_n task_n task_n P(task_n, pos_2)=p_n \left( \frac{\sum_{j=1}^{n-1}p_j}{n-1} \right) task_n task_n P(task_n, pos_3)=p_n \left( \frac{\sum_{j=1}^{n-1}p_j\left( \sum_{k=1}^{n-1}(p_k)-p_j \right)}{(n-1)(n-2)} \right) p_1, p_2, ..., p_{n-1} n-1","['probability', 'summation', 'permutations', 'products']"
55,Nonnegative random variable whose characteristic function is differentiable at 0 has first moment,Nonnegative random variable whose characteristic function is differentiable at 0 has first moment,,"I’m trying to prove the following claim: Let $X$ be a nonnegative random variable, and let $\phi(t) = \mathbb E\left[e^{itX}\right]$ be its characteristic function. Suppose $\phi$ is differentiable at $t=0$ . Then $\mathbb E[X] < \infty$ . This is a component of an exercise in my probability theory textbook (Achim Klenke, “Probability Theory: A Comprehensive Course”, Exercise 15.4.4(iii)). This question has also been asked here , and there’s an answer that supposedly gives a counterexample, but I’m not convinced: the counterexample is a symmetric random variable instead of nonnegative, and it’s not clear to me how the characteristic function of a a symmetric random variable relates to the corresponding nonnegative random variable (i.e. its absolute value). What I’ve tried: Klenke has a proof of the existence of $2n^\textrm{th}$ moments when $\phi^{(2n)}(0)$ exists for some $n \geq 1$ , but I’ve been having trouble adapting the proof to the first derivative case. I tried considering a symmetric random variable $Y$ for which $Y^2 = X$ (and thus $\mathbb E[Y^2] = \mathbb E[X]$ ). If I were able to prove $\phi_Y’’(0)$ exists, then I’d be done. But letting $f(x) = x^2$ , and noting that $f_* \mathbb P_Y = \mathbb P_X$ , I ended up computing: $$ \phi_Y(t) = \int_{\mathbb R} e^{ity} \mathbb P_Y[dy] = \mathbb P[Y=0] + 2\int_{(0,\infty)} \cos\left(t\sqrt x\right) \mathbb P_X[dx] $$ and it’s not at all obvious to me that this map should be differentiable (let alone twice differentiable). Any suggestions/places to find the answer?","I’m trying to prove the following claim: Let be a nonnegative random variable, and let be its characteristic function. Suppose is differentiable at . Then . This is a component of an exercise in my probability theory textbook (Achim Klenke, “Probability Theory: A Comprehensive Course”, Exercise 15.4.4(iii)). This question has also been asked here , and there’s an answer that supposedly gives a counterexample, but I’m not convinced: the counterexample is a symmetric random variable instead of nonnegative, and it’s not clear to me how the characteristic function of a a symmetric random variable relates to the corresponding nonnegative random variable (i.e. its absolute value). What I’ve tried: Klenke has a proof of the existence of moments when exists for some , but I’ve been having trouble adapting the proof to the first derivative case. I tried considering a symmetric random variable for which (and thus ). If I were able to prove exists, then I’d be done. But letting , and noting that , I ended up computing: and it’s not at all obvious to me that this map should be differentiable (let alone twice differentiable). Any suggestions/places to find the answer?","X \phi(t) = \mathbb E\left[e^{itX}\right] \phi t=0 \mathbb E[X] < \infty 2n^\textrm{th} \phi^{(2n)}(0) n \geq 1 Y Y^2 = X \mathbb E[Y^2] = \mathbb E[X] \phi_Y’’(0) f(x) = x^2 f_* \mathbb P_Y = \mathbb P_X 
\phi_Y(t) = \int_{\mathbb R} e^{ity} \mathbb P_Y[dy] = \mathbb P[Y=0] + 2\int_{(0,\infty)} \cos\left(t\sqrt x\right) \mathbb P_X[dx]
","['probability', 'probability-theory', 'characteristic-functions']"
56,Estimating Lambda in a Poisson population where not all samples can be observed,Estimating Lambda in a Poisson population where not all samples can be observed,,"Let $(x_1, x_2, \dots , x_n)$ be a random sample from a population which follows a Poisson distribution with an unknown mean $\lambda$ . If we assume that $C$ is a known constant and we can only observe the values of the sample for which $x_i < C$ . I want to try to estimate $\lambda$ by only using these samples. I first define two variables, $r$ and $p$ , which can be defined as: $$r = max(i: x_{(i)} < C)$$ $$p = max(i: x_{(i)} \le C-2)$$ , where $x_{(i)}$ denotes the $i$ th order statistic. I assume for convenience that $x_1, x_2, \dots, x_p,\dots, x_r$ are the observed samples so they are ordered. So if $X$ is a Poisson distributed random variable with density function $p(x)$ , mean $\lambda$ and $C$ as being any constant, then $$\lambda = \sum_{x=0}^{\infty}\space x\space p(x)$$ can be split up to $$\lambda = \sum_{x=C}^{\infty}\space x\space p(x) + \sum_{x=0}^{C-1}\space x\space p(x)$$ I can calculate the first part directly: $$\sum_{x=C}^{\infty}\space x\space p(x) = \lambda(1-F(C-2))$$ , where $F(.)$ is the CDF of the Poisson distribution. An estimation of the second part would be: $$\frac{1}{n} \sum_{i=1}^r x_i$$ and if $\bar{x_r}$ is the mean of the first $r$ observations, we can write this as: $$\frac{r}{n} \bar{x_r}$$ Now, we could estimate $F(C-2)$ as $\frac{p}{n}$ So combining the terms and working out for $\lambda$ , I get: $$\lambda = \frac{r\bar{x_r}}{p}$$ This seems to be a good estimator, but when $C$ becomes very small compared against the real mean, the estimation loses accuracy. The reason seems to be that estimating $F(C-2)$ from the observed samples isn't that accurate when $C$ gets small compared to $\lambda$ , even if I use a large sample size (>100K). So the questions I'm thinking about: Is there a more accurate way to estimate $F(C-2)$ ? Or maybe there ís something wrong with the math? In which case, please point out. Or maybe there is an easier way to estimate $\lambda$ from limited observed samples? EDIT I want to expand a bit based on the comments. We can also say that $X$ follows a truncated Poisson distribution conditional on the event that $X < C$ with a known $C$ , which is the truncation level. If I read from the definition then I can write the PMF of a C-truncated Poisson distribution as $$\frac{p(x)}{F(C-1)}$$ If I then work out the log-likelihood function for $\lambda$ , given the samples $x_1, x_2, \dots, x_p, \dots, x_r$ , I get: $$L(\lambda|x_1, x_2, \dots, x_p, \dots, x_r) = \log(\lambda)\sum_{i=1}^r x_i - r\log(\sum_{i=0}^{C-1} \frac{\lambda^i}{i!}) $$ Maximizing this function in $\lambda$ indeed gives me a good estimation for $\lambda$ , but it seems that we always need a numerical method for it. If someone can elaborate more from this perspective, this is always welcome as well.","Let be a random sample from a population which follows a Poisson distribution with an unknown mean . If we assume that is a known constant and we can only observe the values of the sample for which . I want to try to estimate by only using these samples. I first define two variables, and , which can be defined as: , where denotes the th order statistic. I assume for convenience that are the observed samples so they are ordered. So if is a Poisson distributed random variable with density function , mean and as being any constant, then can be split up to I can calculate the first part directly: , where is the CDF of the Poisson distribution. An estimation of the second part would be: and if is the mean of the first observations, we can write this as: Now, we could estimate as So combining the terms and working out for , I get: This seems to be a good estimator, but when becomes very small compared against the real mean, the estimation loses accuracy. The reason seems to be that estimating from the observed samples isn't that accurate when gets small compared to , even if I use a large sample size (>100K). So the questions I'm thinking about: Is there a more accurate way to estimate ? Or maybe there ís something wrong with the math? In which case, please point out. Or maybe there is an easier way to estimate from limited observed samples? EDIT I want to expand a bit based on the comments. We can also say that follows a truncated Poisson distribution conditional on the event that with a known , which is the truncation level. If I read from the definition then I can write the PMF of a C-truncated Poisson distribution as If I then work out the log-likelihood function for , given the samples , I get: Maximizing this function in indeed gives me a good estimation for , but it seems that we always need a numerical method for it. If someone can elaborate more from this perspective, this is always welcome as well.","(x_1, x_2, \dots , x_n) \lambda C x_i < C \lambda r p r = max(i: x_{(i)} < C) p = max(i: x_{(i)} \le C-2) x_{(i)} i x_1, x_2, \dots, x_p,\dots, x_r X p(x) \lambda C \lambda = \sum_{x=0}^{\infty}\space x\space p(x) \lambda = \sum_{x=C}^{\infty}\space x\space p(x) + \sum_{x=0}^{C-1}\space x\space p(x) \sum_{x=C}^{\infty}\space x\space p(x) = \lambda(1-F(C-2)) F(.) \frac{1}{n} \sum_{i=1}^r x_i \bar{x_r} r \frac{r}{n} \bar{x_r} F(C-2) \frac{p}{n} \lambda \lambda = \frac{r\bar{x_r}}{p} C F(C-2) C \lambda F(C-2) \lambda X X < C C \frac{p(x)}{F(C-1)} \lambda x_1, x_2, \dots, x_p, \dots, x_r L(\lambda|x_1, x_2, \dots, x_p, \dots, x_r) = \log(\lambda)\sum_{i=1}^r x_i - r\log(\sum_{i=0}^{C-1} \frac{\lambda^i}{i!})  \lambda \lambda","['probability', 'poisson-distribution', 'estimation']"
57,"Two ""racing"" sequences, what is the probability and expected stopping time that one will ""catch up"" to the other?","Two ""racing"" sequences, what is the probability and expected stopping time that one will ""catch up"" to the other?",,"Let $a_n$ and $b_n$ be two sequences with $a_0 = 0$ and $b_0 = c$ with $c > 0$ . For simplicity, we can assume that $c$ is some small, positive integer, such as 3. Then, at every step, we flip a fair coin, and let $X_n$ denote the result of the coin flip. If $X_n = H$ , then $$  a_{n+1} = a_n + 2\\ b_{n+1} = b_n + 1 $$ Otherwise if $X_n = T$ , then $$  a_{n+1} = 0\\ b_{n+1} = b_n $$ So the $a_n$ sequence gets ""zeroed out"" whenever we flip a $T$ . My interest is in the probability that $a_n$ catches up to $b_n$ , i.e. $a_n \geq b_n$ , at step $n$ . In other words, what is $P(a_n \geq b_n)$ ? In addition, if we define the stopping time $\tau$ to be the first $n$ such that $a_n \geq b_n$ , I am also interested in $P(\tau \leq k)$ , i.e. what is the probability that $a_n$ will have caught up to $b_n$ by step $k$ ? After running some simulations, I'm pretty sure this $\tau$ has infinite expectation, i.e. $E(\tau) = \infty$ . I think showing that $P(\tau = \infty) > 0$ may be easier than finding the probabilities above (I am still interested in those probabilities though). However, I haven't been able to find a way to prove even this yet.","Let and be two sequences with and with . For simplicity, we can assume that is some small, positive integer, such as 3. Then, at every step, we flip a fair coin, and let denote the result of the coin flip. If , then Otherwise if , then So the sequence gets ""zeroed out"" whenever we flip a . My interest is in the probability that catches up to , i.e. , at step . In other words, what is ? In addition, if we define the stopping time to be the first such that , I am also interested in , i.e. what is the probability that will have caught up to by step ? After running some simulations, I'm pretty sure this has infinite expectation, i.e. . I think showing that may be easier than finding the probabilities above (I am still interested in those probabilities though). However, I haven't been able to find a way to prove even this yet.","a_n b_n a_0 = 0 b_0 = c c > 0 c X_n X_n = H  
a_{n+1} = a_n + 2\\
b_{n+1} = b_n + 1
 X_n = T  
a_{n+1} = 0\\
b_{n+1} = b_n
 a_n T a_n b_n a_n \geq b_n n P(a_n \geq b_n) \tau n a_n \geq b_n P(\tau \leq k) a_n b_n k \tau E(\tau) = \infty P(\tau = \infty) > 0","['probability', 'stochastic-processes', 'stopping-times']"
58,Is $Var(x | x \le \tau)$ weakly increasing in $\tau$?,Is  weakly increasing in ?,Var(x | x \le \tau) \tau,"I am interested in $Var(x | x\le \tau)$ is increasing in $\tau$ , where $x$ is some random variable with differentiable cdf. I can show that $E[x | x\le \tau]$ is increasing in $\tau$ , which is intuitively obvious, by the following computation: $$ \frac{\partial}{\partial\tau}E[x\mid x\le\tau]=\frac{\partial}{\partial\tau}\left(\int_{-\infty}^{\tau}\frac{xf(x)}{F(\tau)}dx\right)=\frac{f(\tau)}{F(\tau)}(\tau-E[x\mid x\le\tau]). $$ In a similar vein, I tried the following: $$ \begin{align*} \frac{\partial}{\partial\tau}Var[x\mid x\le\tau] & =\frac{\partial}{\partial\tau}\left(E[x^{2}\mid x\le\tau]-E[x\mid x\le\tau]^{2}\right)\\  & =\frac{\partial}{\partial\tau}\left(\int_{-\infty}^{\tau}\frac{x^{2}f(x)}{F(\tau)}dx-(\int_{-\infty}^{\tau}\frac{x f(x)}{F(\tau)}dx)^{2}\right)\\  & =\frac{f(\tau)}{F(\tau)}\left[\tau^{2}-E[x^{2}\mid x\le\tau]-2(E[x\mid x\le\tau]-\tau)\right] \end{align*} $$ Is this correct? I have a doubt because (i) a simulation result does not match with the analytical formula I have here (although the derivative of $E[x\mid x\le \tau]$ is verified by a simulation) and (ii) it is not clear if $Var[x\mid x\le \tau]$ is increasing in $\tau$ from the result, although a bunch of simulation suggests it is increasing. If $Var(x\mid x\le \tau)$ is not increasing in general, under what conditions are they increasing? For example, what if $x$ is supported on positive values?","I am interested in is increasing in , where is some random variable with differentiable cdf. I can show that is increasing in , which is intuitively obvious, by the following computation: In a similar vein, I tried the following: Is this correct? I have a doubt because (i) a simulation result does not match with the analytical formula I have here (although the derivative of is verified by a simulation) and (ii) it is not clear if is increasing in from the result, although a bunch of simulation suggests it is increasing. If is not increasing in general, under what conditions are they increasing? For example, what if is supported on positive values?","Var(x | x\le \tau) \tau x E[x | x\le \tau] \tau 
\frac{\partial}{\partial\tau}E[x\mid x\le\tau]=\frac{\partial}{\partial\tau}\left(\int_{-\infty}^{\tau}\frac{xf(x)}{F(\tau)}dx\right)=\frac{f(\tau)}{F(\tau)}(\tau-E[x\mid x\le\tau]).
 
\begin{align*}
\frac{\partial}{\partial\tau}Var[x\mid x\le\tau] & =\frac{\partial}{\partial\tau}\left(E[x^{2}\mid x\le\tau]-E[x\mid x\le\tau]^{2}\right)\\
 & =\frac{\partial}{\partial\tau}\left(\int_{-\infty}^{\tau}\frac{x^{2}f(x)}{F(\tau)}dx-(\int_{-\infty}^{\tau}\frac{x f(x)}{F(\tau)}dx)^{2}\right)\\
 & =\frac{f(\tau)}{F(\tau)}\left[\tau^{2}-E[x^{2}\mid x\le\tau]-2(E[x\mid x\le\tau]-\tau)\right]
\end{align*}
 E[x\mid x\le \tau] Var[x\mid x\le \tau] \tau Var(x\mid x\le \tau) x","['probability', 'statistics', 'conditional-expectation']"
59,Determine the value of $\mathbb{E}[X]\mathbb{E}[1/X]$ with $X$ a random variable such that $0<a\leq X\leq b$ [duplicate],Determine the value of  with  a random variable such that  [duplicate],\mathbb{E}[X]\mathbb{E}[1/X] X 0<a\leq X\leq b,"This question already has an answer here : Kantorovich inequality and Cauchy-Schwarz inequality (1 answer) Closed 2 years ago . Let b>a>0, determine the set $$\{\mathbb{E}[X]\mathbb{E}[1/X]\colon X \ \text{is a random variable and } X(\omega)\in[a,b],\ \forall \omega\in\Omega  \}$$ It is clear that we have $$\mathbb{E}[X]\mathbb{E}[1/X]\geq \big(\mathbb{E}[\sqrt{X}\sqrt{1/X}]\big)^2=1$$ by the Cauchy-Schwarz inequality, but I have no idea about how to determine the upper bound of the product, any help would be appreciated .","This question already has an answer here : Kantorovich inequality and Cauchy-Schwarz inequality (1 answer) Closed 2 years ago . Let b>a>0, determine the set It is clear that we have by the Cauchy-Schwarz inequality, but I have no idea about how to determine the upper bound of the product, any help would be appreciated .","\{\mathbb{E}[X]\mathbb{E}[1/X]\colon X \ \text{is a random variable and } X(\omega)\in[a,b],\ \forall \omega\in\Omega  \} \mathbb{E}[X]\mathbb{E}[1/X]\geq \big(\mathbb{E}[\sqrt{X}\sqrt{1/X}]\big)^2=1",['probability']
60,On estimating the number of iid samples,On estimating the number of iid samples,,"Suppose we have iid samples $X_1,\cdots,X_n$ , with the number of samples $n$ unknown, but I can sample from their sum $m=\sum_{i=1}^n X_i$ . Further suppose $\mathbb{E}[X_i]=\mu$ and $Var[X_t]=\sigma^2$ , with both $\mu$ and $\sigma$ known. If I want to estimate the number of samples $n$ , intuitively, one would find the nearest integer from $\frac{m}{\mu}$ (or is there any better way to estimate $n$ ?) If I want the estimate to be 95% trust-worthy, I guess there should be some requirements on the variance $\sigma^2$ and the true sample number $n$ . My attempt: Suppose $n$ is huge and according to central limit theorem, the distribution of $\frac{m}{n}$ is approximately $\mathcal{N}(\mu,\frac{\sigma^2}{n})$ . But I have a trouble handling the ""rounding function"". And probably central limit theorem is probably not proper for this circumstance, since it says what would happen for $n$ goes to infinity, but what we are trying to do here is exactly estimating $n$ . I tried to use Hoeffding's inequality, but since $n$ is stochastic here, I am not sure Hoeffding's inequality is proper for this circumstance.","Suppose we have iid samples , with the number of samples unknown, but I can sample from their sum . Further suppose and , with both and known. If I want to estimate the number of samples , intuitively, one would find the nearest integer from (or is there any better way to estimate ?) If I want the estimate to be 95% trust-worthy, I guess there should be some requirements on the variance and the true sample number . My attempt: Suppose is huge and according to central limit theorem, the distribution of is approximately . But I have a trouble handling the ""rounding function"". And probably central limit theorem is probably not proper for this circumstance, since it says what would happen for goes to infinity, but what we are trying to do here is exactly estimating . I tried to use Hoeffding's inequality, but since is stochastic here, I am not sure Hoeffding's inequality is proper for this circumstance.","X_1,\cdots,X_n n m=\sum_{i=1}^n X_i \mathbb{E}[X_i]=\mu Var[X_t]=\sigma^2 \mu \sigma n \frac{m}{\mu} n \sigma^2 n n \frac{m}{n} \mathcal{N}(\mu,\frac{\sigma^2}{n}) n n n","['probability', 'statistics', 'central-limit-theorem']"
61,Probability of passing a T/F exam?,Probability of passing a T/F exam?,,"There are $n$ questions in an examination ( $n \in \mathbb{N}$ ), and the answer to each question is True or False. You know that exactly $t$ of the answers are True ( $0 \le t \le n$ ), so you randomly answer $t$ questions as True and the rest as False. What is your probability of getting at least a $50\%$ score in the exam (in terms of $n$ and $t$ )? My attempt: WLOG assume you answer the first $t$ questions as True. Let there be $k$ questions out of the first $t$ of which the answer is True. Thus, out of the other $n-t$ questions where you replied False, $(n-t)-(t-k)=n-2t+k$ questions are really False. Thus, the fraction of correct answers for the whole examination is equal to $\frac{n-2t+2k}{n}$ . If this is at least $1/2$ , then $n+2k \ge 4t$ . However, I can't calculate the probability of this happening.","There are questions in an examination ( ), and the answer to each question is True or False. You know that exactly of the answers are True ( ), so you randomly answer questions as True and the rest as False. What is your probability of getting at least a score in the exam (in terms of and )? My attempt: WLOG assume you answer the first questions as True. Let there be questions out of the first of which the answer is True. Thus, out of the other questions where you replied False, questions are really False. Thus, the fraction of correct answers for the whole examination is equal to . If this is at least , then . However, I can't calculate the probability of this happening.",n n \in \mathbb{N} t 0 \le t \le n t 50\% n t t k t n-t (n-t)-(t-k)=n-2t+k \frac{n-2t+2k}{n} 1/2 n+2k \ge 4t,"['probability', 'random']"
62,Conditions on stopping time being finite,Conditions on stopping time being finite,,"Let $(Y_n)_{n \in \mathbb{N}}$ be independent random variables taking values in $\{-1, 0, 1\}$ such that $EY_n = 0$ . Let the process $(X_n)_{n \in \mathbb{N}}$ with $X_n = \sum_{k = 1}^n Y_k$ . Let $\tau = \inf \{n : X_n = 1\}$ . For what conditions on $Y_n$ is $\tau$ finite almost surely? I know if $Y_n$ are iid, then if $P(Y_n = 0) < 1$ , then $\tau$ will be finite a.s. I am having trouble with this exercise though. It's seems possible to me that the condition is $\sum (1 - P(Y_n = 0)) = \infty$ . Any pointers?","Let be independent random variables taking values in such that . Let the process with . Let . For what conditions on is finite almost surely? I know if are iid, then if , then will be finite a.s. I am having trouble with this exercise though. It's seems possible to me that the condition is . Any pointers?","(Y_n)_{n \in \mathbb{N}} \{-1, 0, 1\} EY_n = 0 (X_n)_{n \in \mathbb{N}} X_n = \sum_{k = 1}^n Y_k \tau = \inf \{n : X_n = 1\} Y_n \tau Y_n P(Y_n = 0) < 1 \tau \sum (1 - P(Y_n = 0)) = \infty","['probability', 'probability-theory', 'martingales', 'stopping-times']"
63,Bayes theorem problem example,Bayes theorem problem example,,"In an urn we have 3 fair dice and 1 unfair. The fair ones are cubic and the unfair is a tetrahedron with all 6s. We put our hand inside the urn and pick one die at random. Assuming we can't tell from its shape if it's fair or not, with eyes blindfolded, we roll the die we picked. Find the probability we bring a 6. Then, given we got a 6, find the probability we had picked the unfair die. Lastly, given that we got a 6 in the previous case, find the probability we get one more 6, by re-rolling this same die. In the first question, since the sample space is $(1,1,1,2,2,2,3,3,3,4,4,4,5,5,5,6,6,6,6,6,6,6)$ , the probability of getting a 6 is $\frac{7}{22}$ . In the second question, since we have 4 6s from the unfair die and 3 6s from the 3 fair dice, given that we got a 6, the probability of having picked the unfair die is $\frac{4}{7}$ . I am not sure about the last question: Clearly we must use Bayes' theorem but I am not very familiar with it. $P(A|B) = \frac {P(B|A)(P(A))}{P(B)}$ . $A$ is the event of picking the unfair die and $B$ the event of rolling a second 6 after the first roll is a 6. $P(B|A) = 1$ , $P(A) = \frac {1}{4}$ since the unfair die is 1 in 4. $P(B)$ So $P(A|B) = \frac {P(B|A)(P(A))}{P(B)}$ . Can you help me finish the last question? Thanking you in advance!","In an urn we have 3 fair dice and 1 unfair. The fair ones are cubic and the unfair is a tetrahedron with all 6s. We put our hand inside the urn and pick one die at random. Assuming we can't tell from its shape if it's fair or not, with eyes blindfolded, we roll the die we picked. Find the probability we bring a 6. Then, given we got a 6, find the probability we had picked the unfair die. Lastly, given that we got a 6 in the previous case, find the probability we get one more 6, by re-rolling this same die. In the first question, since the sample space is , the probability of getting a 6 is . In the second question, since we have 4 6s from the unfair die and 3 6s from the 3 fair dice, given that we got a 6, the probability of having picked the unfair die is . I am not sure about the last question: Clearly we must use Bayes' theorem but I am not very familiar with it. . is the event of picking the unfair die and the event of rolling a second 6 after the first roll is a 6. , since the unfair die is 1 in 4. So . Can you help me finish the last question? Thanking you in advance!","(1,1,1,2,2,2,3,3,3,4,4,4,5,5,5,6,6,6,6,6,6,6) \frac{7}{22} \frac{4}{7} P(A|B) = \frac {P(B|A)(P(A))}{P(B)} A B P(B|A) = 1 P(A) = \frac {1}{4} P(B) P(A|B) = \frac {P(B|A)(P(A))}{P(B)}","['probability', 'bayes-theorem']"
64,Show that $\mathbb E[\exp(-\lambda(T_{a}\land T_{b}))]=\cosh(\frac{a+b}{2}\sqrt{2\lambda})/\cosh(\frac{a-b}{2}\sqrt{2\lambda})$,Show that,\mathbb E[\exp(-\lambda(T_{a}\land T_{b}))]=\cosh(\frac{a+b}{2}\sqrt{2\lambda})/\cosh(\frac{a-b}{2}\sqrt{2\lambda}),"Let $a < 0 < b$ and further for a standard Brownian motion $(B_{t})$ define the stopping times $T_{x}:=\inf\{t \geq 0: B_{t}=x\}$ . Show that: $$\mathbb E[\exp(-\lambda(T_{a}\land T_{b}))]=\cosh(\frac{a+b}{2}\sqrt{2\lambda})/\cosh(\frac{a-b}{2}\sqrt{2\lambda})$$ My attempt: I have already shown that $\mathbb E[\exp(-\lambda T_{a})]=\exp(-a\sqrt{2\lambda}) \; (*)$ through the Optional sampling theorem as well as the choice of martingale $\left(\exp(\alpha B_{t}-\frac{\alpha^{2}}{2}t)\right)_{t\geq 0}$ , i.e. choosing the martingale $\left(\exp(\sqrt{2\lambda} B_{t}-\lambda t)\right)_{t\geq 0}$ , we obtain $(*)$ . Now I am supposing we need to find a suitable exponential martingale again, but I am struggling to find one, any suggestions? Additional question: How does the knowledge of $$E[\exp(-\lambda(T_{a}\land T_{b}))]=\cosh(\frac{a+b}{2}\sqrt{2\lambda})/\cosh(\frac{a-b}{2}\sqrt{2\lambda})$$ allow us to deduce $\mathbb E[T_{a}\land T_{b}]=b\lvert a \rvert$ ? I cannot see it.","Let and further for a standard Brownian motion define the stopping times . Show that: My attempt: I have already shown that through the Optional sampling theorem as well as the choice of martingale , i.e. choosing the martingale , we obtain . Now I am supposing we need to find a suitable exponential martingale again, but I am struggling to find one, any suggestions? Additional question: How does the knowledge of allow us to deduce ? I cannot see it.",a < 0 < b (B_{t}) T_{x}:=\inf\{t \geq 0: B_{t}=x\} \mathbb E[\exp(-\lambda(T_{a}\land T_{b}))]=\cosh(\frac{a+b}{2}\sqrt{2\lambda})/\cosh(\frac{a-b}{2}\sqrt{2\lambda}) \mathbb E[\exp(-\lambda T_{a})]=\exp(-a\sqrt{2\lambda}) \; (*) \left(\exp(\alpha B_{t}-\frac{\alpha^{2}}{2}t)\right)_{t\geq 0} \left(\exp(\sqrt{2\lambda} B_{t}-\lambda t)\right)_{t\geq 0} (*) E[\exp(-\lambda(T_{a}\land T_{b}))]=\cosh(\frac{a+b}{2}\sqrt{2\lambda})/\cosh(\frac{a-b}{2}\sqrt{2\lambda}) \mathbb E[T_{a}\land T_{b}]=b\lvert a \rvert,"['probability', 'probability-theory', 'stochastic-calculus', 'martingales', 'stopping-times']"
65,Brownian motion started at infinity,Brownian motion started at infinity,,"It is known (Theorem 3.46 in Peres-Mörters) that the harmonic measure of a set $A$ from infinity is well-defined by taking the limit as $x\to \infty$ of a Brownian motion started at $x$ , or by averaging the starting point on a sphere. This works in arbitrary dimension. Can the path itself be defined, rather than just the hitting distribution? Concretely, is it the same as running Brownian motion on the sphere (by stereographic projection) from the north pole until it hits $A$ ? Does it work then in all dimensions or just in dimension 2?","It is known (Theorem 3.46 in Peres-Mörters) that the harmonic measure of a set from infinity is well-defined by taking the limit as of a Brownian motion started at , or by averaging the starting point on a sphere. This works in arbitrary dimension. Can the path itself be defined, rather than just the hitting distribution? Concretely, is it the same as running Brownian motion on the sphere (by stereographic projection) from the north pole until it hits ? Does it work then in all dimensions or just in dimension 2?",A x\to \infty x A,"['probability', 'random-variables', 'brownian-motion']"
66,A question on exchangeable variables in Erdős-Rényi graphs,A question on exchangeable variables in Erdős-Rényi graphs,,"Let $H$ be a subgraph of the complete graph on $n$ vertices without isolated vertices, and let $\Gamma$ be the set of isomorphic copies of $H$ . For any $\alpha\in \Gamma$ , let $X_\alpha$ be the indicatrix of the event $\alpha\in G(n,p)$ . I am told that $\{X_\alpha\}$ is a sequence of exchangeable random variables, but I do not see how to prove it (apart from the fact that is suffices to prove exchangeability for permutations of type $(a,b)$ ). Actually, I am not even sure this is true: it could be the case, for example, that $\{X_1=1,\dots, X_k=1\}$ implies $X_{k+1}=1$ , while it does not necessarily imply $X_n=1$ (for example, if $H$ is a triangle, it could be the case that the existence of a certain number of triangles in $G$ implies the existence of another one without implying the existence of all the remaining ones). Am I right, or am I missing something?","Let be a subgraph of the complete graph on vertices without isolated vertices, and let be the set of isomorphic copies of . For any , let be the indicatrix of the event . I am told that is a sequence of exchangeable random variables, but I do not see how to prove it (apart from the fact that is suffices to prove exchangeability for permutations of type ). Actually, I am not even sure this is true: it could be the case, for example, that implies , while it does not necessarily imply (for example, if is a triangle, it could be the case that the existence of a certain number of triangles in implies the existence of another one without implying the existence of all the remaining ones). Am I right, or am I missing something?","H n \Gamma H \alpha\in \Gamma X_\alpha \alpha\in G(n,p) \{X_\alpha\} (a,b) \{X_1=1,\dots, X_k=1\} X_{k+1}=1 X_n=1 H G","['probability', 'probability-theory', 'graph-theory', 'random-graphs']"
67,"""Reverse"" Chebyshev Inequality that gives lower bound of being far from mean [closed]","""Reverse"" Chebyshev Inequality that gives lower bound of being far from mean [closed]",,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question Chebyshev's inequality gives an upper bound on $P(|X - \mu| \geq k\sigma)$ but I was wondering if there was a way to find a lower bound for this probability or, equivalently an upper bound on $P(|X - \mu| < k\sigma)$ . What about with added assumptions? For example, is there any way to get a lower bound for the probability that a $\textrm{Binomial}(n, p)$ variable takes a value more than a constant $K$ away from the mean?","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question Chebyshev's inequality gives an upper bound on but I was wondering if there was a way to find a lower bound for this probability or, equivalently an upper bound on . What about with added assumptions? For example, is there any way to get a lower bound for the probability that a variable takes a value more than a constant away from the mean?","P(|X - \mu| \geq k\sigma) P(|X - \mu| < k\sigma) \textrm{Binomial}(n, p) K","['probability', 'variance', 'binomial-distribution']"
68,Math genius needed for combinatorics calculation of my card game (Shannon number-like),Math genius needed for combinatorics calculation of my card game (Shannon number-like),,"My name is Lych, I am a game developer from Germany. My card game is a quite complex one and I am very curious about the question, what amount of different matches are possible in this game. Just like the Shannon number in chess. However, this will most likely be bigger than the Shannon number. In the following, I will describe everything you need to know. Some of the instructions are already simplified to not make it harder than necessary. After all, it is not important to get an exact result, just a rough calculation. Please keep in mind that I am not especially gifted when it comes to math. Therefore, I do hope that my instructions are clear. If they are not, please ask me. Thank you really much in advance! I am grateful to have the opportunity to ask people for help who can do this better than me. 4 players in total. After each turn, the next player clock-wise is next with their turn. Everyone has 5 cards in their hands in the beginning. 75 cards are available in total, all different, no equal ones. (First interposed calculation that could help later: How many possible combinations of starter hand cards are possible?) Per turn, the player can set 2 cards from his hand to the field (choose freely from the 5 hand cards). Every single card on the field can do 21 different actions. In ANY order. (That means that the order of options ""1, 2, 3, 4, 5 ... 21"" is a different one than ""1, 3, 2, 4, 5, ... 21"" and therefore another match obviously). Also, the 2 cards can take turns in their actions as the order is completely free again. (Therefore, the amount of possible orders with those two cards has to be an incredible high number already). However, the players will not always add 2 more cards per turn. In average (for this calculation), they will keep having 2 cards on the field to use, constantly. Every turn, they are destroyed and 2 new cards will be placed from the hand again, freely. In the beginning of each new turn, the player draws 3 more cards (don't mind because only 2 are used in the previous point. One card of them is always directly destroyed, but do not take this into the calculation. Just act like the player only gets 2 cards per turn, but 3 are removed from the total card stack). (Still keep in mind that every card of those 75 is unique and all possibilities of card drawings from the stack that are still available, and also all card settings from the hand to the field must be taken into the calculation). In total, there are 20 turns, but only 18 of them the players draw cards because then, the card stack is empty (55/3 = 18 roughly. 55 because in the beginning, 20 cards are already drawn). In the last 2 turns, they don't draw but still play as before with 2 cards on the field. -> How many different matches are possible in this game? Closing words: As I said, thank you very much for your effort to everyone who helps me with this. If anything should be not clear, please ask. After all, it is enough if the result is an estimation and not exact. ~ Lych","My name is Lych, I am a game developer from Germany. My card game is a quite complex one and I am very curious about the question, what amount of different matches are possible in this game. Just like the Shannon number in chess. However, this will most likely be bigger than the Shannon number. In the following, I will describe everything you need to know. Some of the instructions are already simplified to not make it harder than necessary. After all, it is not important to get an exact result, just a rough calculation. Please keep in mind that I am not especially gifted when it comes to math. Therefore, I do hope that my instructions are clear. If they are not, please ask me. Thank you really much in advance! I am grateful to have the opportunity to ask people for help who can do this better than me. 4 players in total. After each turn, the next player clock-wise is next with their turn. Everyone has 5 cards in their hands in the beginning. 75 cards are available in total, all different, no equal ones. (First interposed calculation that could help later: How many possible combinations of starter hand cards are possible?) Per turn, the player can set 2 cards from his hand to the field (choose freely from the 5 hand cards). Every single card on the field can do 21 different actions. In ANY order. (That means that the order of options ""1, 2, 3, 4, 5 ... 21"" is a different one than ""1, 3, 2, 4, 5, ... 21"" and therefore another match obviously). Also, the 2 cards can take turns in their actions as the order is completely free again. (Therefore, the amount of possible orders with those two cards has to be an incredible high number already). However, the players will not always add 2 more cards per turn. In average (for this calculation), they will keep having 2 cards on the field to use, constantly. Every turn, they are destroyed and 2 new cards will be placed from the hand again, freely. In the beginning of each new turn, the player draws 3 more cards (don't mind because only 2 are used in the previous point. One card of them is always directly destroyed, but do not take this into the calculation. Just act like the player only gets 2 cards per turn, but 3 are removed from the total card stack). (Still keep in mind that every card of those 75 is unique and all possibilities of card drawings from the stack that are still available, and also all card settings from the hand to the field must be taken into the calculation). In total, there are 20 turns, but only 18 of them the players draw cards because then, the card stack is empty (55/3 = 18 roughly. 55 because in the beginning, 20 cards are already drawn). In the last 2 turns, they don't draw but still play as before with 2 cards on the field. -> How many different matches are possible in this game? Closing words: As I said, thank you very much for your effort to everyone who helps me with this. If anything should be not clear, please ask. After all, it is enough if the result is an estimation and not exact. ~ Lych",,"['probability', 'combinatorics', 'probability-distributions', 'combinations', 'card-games']"
69,Bit strings and probability,Bit strings and probability,,"Given a bit string of length $n$ , I should develop a probabilistic algorithm that answers one of the following questions: Does the bit string have more zeros than ones? Does the bit string have more ones than zeros? Does the number of zeros (/ones respectively) lies between $0.4n$ and $0.6n$ ? The probability that the answer is correct should be at least $0.99$ . Notice that the algorithm has to answer only one of the three questions for a given bit string, and it does not always have to be the same question it answers. The algorithm should run in $O(1)$ . Generally, my method would be to choose some sample set of $k$ bits of the bit string  at random and then approximate the ratio with this sample set, which yields the desired probability when choosing the size accordingly. But since the runtime constraint is that tight, I don't really think that I could proceed with this method. If I could somehow get a bound for the ratio that doesn't depend on $n$ , I could get a constant runtime, but I don't really know how to do this. I thought about letting the ratio be $0.5$ which would be the expected ratio for a randomly chosen bit string, but I don't think that this approach would be valid. Any ideas how one could tackle this problem? Edit: I am not allowed to use the normal distribution, the problem is solvable without using it.","Given a bit string of length , I should develop a probabilistic algorithm that answers one of the following questions: Does the bit string have more zeros than ones? Does the bit string have more ones than zeros? Does the number of zeros (/ones respectively) lies between and ? The probability that the answer is correct should be at least . Notice that the algorithm has to answer only one of the three questions for a given bit string, and it does not always have to be the same question it answers. The algorithm should run in . Generally, my method would be to choose some sample set of bits of the bit string  at random and then approximate the ratio with this sample set, which yields the desired probability when choosing the size accordingly. But since the runtime constraint is that tight, I don't really think that I could proceed with this method. If I could somehow get a bound for the ratio that doesn't depend on , I could get a constant runtime, but I don't really know how to do this. I thought about letting the ratio be which would be the expected ratio for a randomly chosen bit string, but I don't think that this approach would be valid. Any ideas how one could tackle this problem? Edit: I am not allowed to use the normal distribution, the problem is solvable without using it.",n 0.4n 0.6n 0.99 O(1) k n 0.5,"['probability', 'probability-theory', 'algorithms', 'bit-strings']"
70,Normalizing constants preserve metric entropy,Normalizing constants preserve metric entropy,,"Suppose $\mathcal{F}=\left\{f\in L^2([a,b]): 0<\underline{c}\leq f\leq\overline{c} \right\}$ . Consider the following transformation $$\tilde{\mathcal{F}} := \left\{\frac{f}{\int f d\mu}: f\in \mathcal{F}\right\}$$ Want to show the claim that $\mathcal{F}$ and $\tilde{\mathcal{F}}$ have the $\epsilon$ -metric entropy (log of covering/packing number under $L_2$ norm) of same order. To put this in a more concrete context, suppose that $\mathcal{F}$ is a Sobolev ellipsoid, i.e $$\mathcal{F} = \mathcal{E}_k(A) = \left\{f\in L^2([a,b]): f = \sum_{j=0}^\infty \theta_j\phi_j(X), \sum_{j=0}^\infty \theta_j^2j^{2k}< A\right\}$$ Suppose $k>1$ and $\phi_j$ 's are uniformly bounded so that $\mathcal{E}_k(A)$ is uniformly bounded, say by a constant $\rho$ . We can see that a transformation of $\mathcal{E}_k(A)$ , say $$ \tilde{\mathcal{E}}_k(A) := \left\{\frac{f + \rho + 1}{\int f d\mu + \rho + 1}: f\in \mathcal{E}_k(A) \right\}$$ is a subset of $\mathcal{E}_k(A')$ for some $A'$ . In some well-published papers (eg. Yang and Barron 1999, p. 1591-), the authors claim that for $A$ large enough, $\tilde{\mathcal{E}}_k(A)$ and and $\mathcal{E}_k(A)$ have the same order of $L^2$ metric entropy. They stated in the paper ""it is easy to see"". While I can ""see"" it intuitively, I have yet to be able to come up with a rigorous proof. In Yang and Barron's paper, they also give some other function classes that they claim such property holds. Note 1: for the Sobolev ellipsoid, I think the convex property may play a role. Note 2: One direction is easy. Consider any $f,g \in\mathcal{F}$ , and let $\tilde{f} = f/\int f$ and $\tilde{g} = g/\int g$ . We can show that for some constant $C$ , $$ \|\tilde{f}-\tilde{g}\|_2 \leq C \|f - g\|_2 $$ The question is however if there's a reverse inequality of the form $\|f - g\|_2\leq C'\|\tilde{f}-\tilde{g}\|_2 $ for some constant $C'$ .","Suppose . Consider the following transformation Want to show the claim that and have the -metric entropy (log of covering/packing number under norm) of same order. To put this in a more concrete context, suppose that is a Sobolev ellipsoid, i.e Suppose and 's are uniformly bounded so that is uniformly bounded, say by a constant . We can see that a transformation of , say is a subset of for some . In some well-published papers (eg. Yang and Barron 1999, p. 1591-), the authors claim that for large enough, and and have the same order of metric entropy. They stated in the paper ""it is easy to see"". While I can ""see"" it intuitively, I have yet to be able to come up with a rigorous proof. In Yang and Barron's paper, they also give some other function classes that they claim such property holds. Note 1: for the Sobolev ellipsoid, I think the convex property may play a role. Note 2: One direction is easy. Consider any , and let and . We can show that for some constant , The question is however if there's a reverse inequality of the form for some constant .","\mathcal{F}=\left\{f\in L^2([a,b]): 0<\underline{c}\leq f\leq\overline{c} \right\} \tilde{\mathcal{F}} := \left\{\frac{f}{\int f d\mu}: f\in \mathcal{F}\right\} \mathcal{F} \tilde{\mathcal{F}} \epsilon L_2 \mathcal{F} \mathcal{F} = \mathcal{E}_k(A) = \left\{f\in L^2([a,b]): f = \sum_{j=0}^\infty \theta_j\phi_j(X), \sum_{j=0}^\infty \theta_j^2j^{2k}< A\right\} k>1 \phi_j \mathcal{E}_k(A) \rho \mathcal{E}_k(A)  \tilde{\mathcal{E}}_k(A) := \left\{\frac{f + \rho + 1}{\int f d\mu + \rho + 1}: f\in \mathcal{E}_k(A) \right\} \mathcal{E}_k(A') A' A \tilde{\mathcal{E}}_k(A) \mathcal{E}_k(A) L^2 f,g \in\mathcal{F} \tilde{f} = f/\int f \tilde{g} = g/\int g C  \|\tilde{f}-\tilde{g}\|_2 \leq C \|f - g\|_2  \|f - g\|_2\leq C'\|\tilde{f}-\tilde{g}\|_2  C'","['real-analysis', 'probability', 'functional-analysis', 'probability-theory', 'entropy']"
71,Probability of Yahtzee straight with strict re-roll rules,Probability of Yahtzee straight with strict re-roll rules,,"Assuming you have 5 fair dice and up to 3 re-roll attempts (during which you can re-roll any dice, as per standard Yahtzee rules) what is the probability of succesfully rolling a ""Small Straight"" (aka 1-2-3-4, 2-3-4-5, or 3-4-5-6)? Also, what is the probability of rolling a ""Large Straight"" (aka 1-2-3-4-5 or 2-3-4-5-6)? In either case, assume the following rules for keeping and re-rolling dice: Keep exactly one of each 2, 3, 4, and 5 result Only keep a 1 or 6 result if it is already part of a Small Straight or Large Straight Unfortunately I'm quite unfamiliar with even basic probability problems let alone something with this level of complexity, and online research hasn't helped much. I'm much more comfortable backing into probabilities by simulating roll outcomes like this in Python, though I've hit a wall with those efforts as well for straights in particular, even with these defined rules. Would deeply appreciate some help. Thanks!","Assuming you have 5 fair dice and up to 3 re-roll attempts (during which you can re-roll any dice, as per standard Yahtzee rules) what is the probability of succesfully rolling a ""Small Straight"" (aka 1-2-3-4, 2-3-4-5, or 3-4-5-6)? Also, what is the probability of rolling a ""Large Straight"" (aka 1-2-3-4-5 or 2-3-4-5-6)? In either case, assume the following rules for keeping and re-rolling dice: Keep exactly one of each 2, 3, 4, and 5 result Only keep a 1 or 6 result if it is already part of a Small Straight or Large Straight Unfortunately I'm quite unfamiliar with even basic probability problems let alone something with this level of complexity, and online research hasn't helped much. I'm much more comfortable backing into probabilities by simulating roll outcomes like this in Python, though I've hit a wall with those efforts as well for straights in particular, even with these defined rules. Would deeply appreciate some help. Thanks!",,"['probability', 'dice']"
72,Optimal control of a certain Poisson process,Optimal control of a certain Poisson process,,"I am trying to understand this paper in which the optimal expected value of a certain Poisson process is computed. Following the notation of op. cit, let $N_s$ ( $0 \le s \le t$ ) be the associated counting process. The intensity of the process is given by $\lambda_s = \lambda (p_s)$ , where $\lambda$ is a known decreasing function and $p_s$ is a real-valued stochastic process depending on the control $u$ . We wish to find a control $u$ such that $$J_u (n, t) = \mathbf{E}_u \left[ \int_0^t p_s \mathrm{d} N_s \right]$$ is maximised, where $\mathbf{E}_u$ denotes the expectation operator under control $u$ . Let $J^* (n, t) = \sup \{ J_u (n, t) : u \in \mathscr{U} \}$ , where $\mathscr{U}$ is the set of controls such that $N_t \le n$ a.s. In op. cit., there is a heuristic dynamic programming argument showing that $$\frac{\partial J^* (n, t)}{\partial t} = \lambda (p^* (n, t)) \left( p^* (n, t) - J^* (n, t) + J^* (n - 1, t) \right)$$ where $p^* (n, t)$ is the $p$ maximising $\lambda (p) \left( p - J^* (n, t) + J^* (n - 1, t) \right)$ . This argument seems plausible enough to me, so I have no issue here. Now suppose $\lambda (p) = a \exp (- \alpha p)$ . The following solution is given in op. cit.: $$J^* (n, t) = p^* (n, t) \log \left( \sum_{k = 0}^n \frac{(\lambda (1 / \alpha) t)^k}{k !} \right)$$ $$p^* (n, t) = \frac{1}{\alpha} + J^* (n, t) - J^* (n - 1, t)$$ How do I verify that this is indeed a solution, or better yet, how might I have found this solution in the first place?","I am trying to understand this paper in which the optimal expected value of a certain Poisson process is computed. Following the notation of op. cit, let ( ) be the associated counting process. The intensity of the process is given by , where is a known decreasing function and is a real-valued stochastic process depending on the control . We wish to find a control such that is maximised, where denotes the expectation operator under control . Let , where is the set of controls such that a.s. In op. cit., there is a heuristic dynamic programming argument showing that where is the maximising . This argument seems plausible enough to me, so I have no issue here. Now suppose . The following solution is given in op. cit.: How do I verify that this is indeed a solution, or better yet, how might I have found this solution in the first place?","N_s 0 \le s \le t \lambda_s = \lambda (p_s) \lambda p_s u u J_u (n, t) = \mathbf{E}_u \left[ \int_0^t p_s \mathrm{d} N_s \right] \mathbf{E}_u u J^* (n, t) = \sup \{ J_u (n, t) : u \in \mathscr{U} \} \mathscr{U} N_t \le n \frac{\partial J^* (n, t)}{\partial t} = \lambda (p^* (n, t)) \left( p^* (n, t) - J^* (n, t) + J^* (n - 1, t) \right) p^* (n, t) p \lambda (p) \left( p - J^* (n, t) + J^* (n - 1, t) \right) \lambda (p) = a \exp (- \alpha p) J^* (n, t) = p^* (n, t) \log \left( \sum_{k = 0}^n \frac{(\lambda (1 / \alpha) t)^k}{k !} \right) p^* (n, t) = \frac{1}{\alpha} + J^* (n, t) - J^* (n - 1, t)","['probability', 'stochastic-processes', 'optimal-control']"
73,How can we derive the dot product from the covariance of two random vectors?,How can we derive the dot product from the covariance of two random vectors?,,"I'm trying to understand a geometric interpretation of covariance as explained in this lecture pdf , which states: If X, Y are two random variables of zero mean, then the covariance Cov[XY ] = E[X · Y ] is the dot product of X and Y. The standard deviation of X is the length of X. The correlation is the cosine of the angle between the two vectors. I can understand how, given a zero mean, the standard deviation of X is the length of X. What I don't understand is how the the covariance of X and Y is equal to it's dot product. Specifically, the covariance is defined as: $Cov(X,Y) = E[(X - \mu_X) (Y - \mu_Y)]$ Which with we can write as: $Cov(X,Y) = \sum\limits_{i}\sum\limits_{j} p_{ij} (x- \mu_X) (y-\mu_Y)$ And since for two centered random variables the means are zero, and the probability is uniform, we can rewrite the formula as: $Cov(X,Y) = \dfrac{1}{N} \sum\limits_{i}\sum\limits_{j} x y$ (Eqn 1) The dot product, in contrast consists of a single summation: $dot(X,Y) = \sum\limits_{i} x_i y_i$ (Eqn 2) Note that the $\frac{1}{N}$ factors out of Eqn 1 when I divide by the standard deviations of X and Y. So I almost can derive the dot product from the covariance, but the covariance still contains a double summation and the dot product has a single element-wise summation. What am I missing? UPDATE I don't have the answer, but I realize that this formula: $Cov(X,Y) = \sum\limits_{i}\sum\limits_{j} p_{ij} (x- \mu_X) (y-\mu_Y)$ ... where N is the dimension of the vectors, is not equal to Eqn 1: $Cov(X,Y) = \dfrac{1}{N} \sum\limits_{i}\sum\limits_{j} x y$ (Eqn 1) Since if $p_{ij}$ equals $\dfrac{1}{N}$ , it would sum to be greater then one in the double summation. $p_{ij}$ only equals $\dfrac{1}{N}$ when it's a single summation, which maps easily to the dot product. I've posted a new question here to try and address this confusion in isolation, which I hope in turn will clarify this derivation problem.","I'm trying to understand a geometric interpretation of covariance as explained in this lecture pdf , which states: If X, Y are two random variables of zero mean, then the covariance Cov[XY ] = E[X · Y ] is the dot product of X and Y. The standard deviation of X is the length of X. The correlation is the cosine of the angle between the two vectors. I can understand how, given a zero mean, the standard deviation of X is the length of X. What I don't understand is how the the covariance of X and Y is equal to it's dot product. Specifically, the covariance is defined as: Which with we can write as: And since for two centered random variables the means are zero, and the probability is uniform, we can rewrite the formula as: (Eqn 1) The dot product, in contrast consists of a single summation: (Eqn 2) Note that the factors out of Eqn 1 when I divide by the standard deviations of X and Y. So I almost can derive the dot product from the covariance, but the covariance still contains a double summation and the dot product has a single element-wise summation. What am I missing? UPDATE I don't have the answer, but I realize that this formula: ... where N is the dimension of the vectors, is not equal to Eqn 1: (Eqn 1) Since if equals , it would sum to be greater then one in the double summation. only equals when it's a single summation, which maps easily to the dot product. I've posted a new question here to try and address this confusion in isolation, which I hope in turn will clarify this derivation problem.","Cov(X,Y) = E[(X - \mu_X) (Y - \mu_Y)] Cov(X,Y) = \sum\limits_{i}\sum\limits_{j} p_{ij} (x- \mu_X) (y-\mu_Y) Cov(X,Y) = \dfrac{1}{N} \sum\limits_{i}\sum\limits_{j} x y dot(X,Y) = \sum\limits_{i} x_i y_i \frac{1}{N} Cov(X,Y) = \sum\limits_{i}\sum\limits_{j} p_{ij} (x- \mu_X) (y-\mu_Y) Cov(X,Y) = \dfrac{1}{N} \sum\limits_{i}\sum\limits_{j} x y p_{ij} \dfrac{1}{N} p_{ij} \dfrac{1}{N}","['probability', 'proof-explanation', 'inner-products', 'covariance']"
74,Extension of Bayes' Theorem coin flipping example - finding a fair coin in a bag of biased coins,Extension of Bayes' Theorem coin flipping example - finding a fair coin in a bag of biased coins,,"There's a fairly common example of Bayes' Theorem in which a coin is drawn from a population with a known amount of biased coins and fair coins. A coin is drawn, flipped a certain amount of times, and then one is challenged to determine the probability that the flipped coin was biased, resulting in a standard implementation of Bayes' Theorem. I was thinking of an extension of this question, where the goal is to find a fair coin drawn from a population. As a concrete example, suppose we have $N$ coins, of which $n$ are fair coins and the remainder will always flip heads. Our goal then is essentially to flip a tails so that we know we have a fair coin. Beforehand we decide after $m$ heads flipped from an individual coin, we will draw a new coin. How would I approach the problem of calculating how many coins I would need to draw before reaching a certain probability threshold $p$ of having at some point flipped a tails? In this case Bayes' Theorem tells us that the probability the first randomly chosen coin is biased after $m$ heads is given by: $$\frac{\frac{N-n}{N}}{\frac{N-n}{N}+\frac{1}{2}^m*\frac{n}{N}}$$ My initial thought was to approach the problem in the vein of ""how many coin flips do I need to have a probability $p$ of having flipped a heads?""-type problems and using Bayes' Theorem between each flip, but the examples of those questions that I've encountered require mutually independent events so I don't think that applies to this problem. Additionally, would the question of finding an ""optimal"" $m$ be related to stopping time? edit : After coming back to this question with a fresh mind, I had the thought that in the case there is only one fair coin (i.e. $n=1$ ) then we could say that the probability we would flip $i$ coins and not see a tails would be: $$\frac{i}{N}*\frac{1}{2}^m+\frac{N-i}{N}$$ which would compute the probability that the fair coin was in the first $i$ coins drawn and that it was flipped $m$ times without seeing a tails, and add that to the probability that the fair coin hasn't yet been drawn. If this is valid, then I think I see how to extend it to $n$ fair coins (by summing over the different amounts of possibly drawn fair coins) as well as how to extend it to individual flips, but I'm also worried I'm violating some assumption in probability and intuiting something incorrectly. Would this work?","There's a fairly common example of Bayes' Theorem in which a coin is drawn from a population with a known amount of biased coins and fair coins. A coin is drawn, flipped a certain amount of times, and then one is challenged to determine the probability that the flipped coin was biased, resulting in a standard implementation of Bayes' Theorem. I was thinking of an extension of this question, where the goal is to find a fair coin drawn from a population. As a concrete example, suppose we have coins, of which are fair coins and the remainder will always flip heads. Our goal then is essentially to flip a tails so that we know we have a fair coin. Beforehand we decide after heads flipped from an individual coin, we will draw a new coin. How would I approach the problem of calculating how many coins I would need to draw before reaching a certain probability threshold of having at some point flipped a tails? In this case Bayes' Theorem tells us that the probability the first randomly chosen coin is biased after heads is given by: My initial thought was to approach the problem in the vein of ""how many coin flips do I need to have a probability of having flipped a heads?""-type problems and using Bayes' Theorem between each flip, but the examples of those questions that I've encountered require mutually independent events so I don't think that applies to this problem. Additionally, would the question of finding an ""optimal"" be related to stopping time? edit : After coming back to this question with a fresh mind, I had the thought that in the case there is only one fair coin (i.e. ) then we could say that the probability we would flip coins and not see a tails would be: which would compute the probability that the fair coin was in the first coins drawn and that it was flipped times without seeing a tails, and add that to the probability that the fair coin hasn't yet been drawn. If this is valid, then I think I see how to extend it to fair coins (by summing over the different amounts of possibly drawn fair coins) as well as how to extend it to individual flips, but I'm also worried I'm violating some assumption in probability and intuiting something incorrectly. Would this work?",N n m p m \frac{\frac{N-n}{N}}{\frac{N-n}{N}+\frac{1}{2}^m*\frac{n}{N}} p m n=1 i \frac{i}{N}*\frac{1}{2}^m+\frac{N-i}{N} i m n,"['probability', 'bayesian', 'bayes-theorem']"
75,Conditional Probability of $P(X|X^2)$ for uniform distribution.,Conditional Probability of  for uniform distribution.,P(X|X^2),"Assume $X \sim U[-1,1]$ is a uniform distribution. We can tell intuitively that $$P(X=k|X^2=x^2) =   \begin{cases}     1/2 \;\;\;\;\;\;\;\text{if} \;\; k=-x  \\     1/2 \;\;\;\;\;\;\;\text{if} \;\; k=x   \end{cases}$$ But I want to confirm this using regular conditional probability . However, when I try the definition as $P(X\in A|Y=y):=\lim\limits_{\{Y=y\}\in U}\frac{P(A\cap U)}{P(U)}$ , the conditional probability is $0$ since for example if trying to compute $P(X=2|X^2=4):=\lim\limits_{\epsilon  \to 0}\frac{P(X=2 \;\cap\; X^2 \in [4-\epsilon,4+\epsilon])}{P(X^2 \in [4-\epsilon,4+\epsilon])}$ , which is just $0$ because $X$ is continuous distribution. Maybe I got something wrong. Please help me compute this conditional probability formally.","Assume is a uniform distribution. We can tell intuitively that But I want to confirm this using regular conditional probability . However, when I try the definition as , the conditional probability is since for example if trying to compute , which is just because is continuous distribution. Maybe I got something wrong. Please help me compute this conditional probability formally.","X \sim U[-1,1] P(X=k|X^2=x^2) =
  \begin{cases}
    1/2 \;\;\;\;\;\;\;\text{if} \;\; k=-x  \\
    1/2 \;\;\;\;\;\;\;\text{if} \;\; k=x
  \end{cases} P(X\in A|Y=y):=\lim\limits_{\{Y=y\}\in U}\frac{P(A\cap U)}{P(U)} 0 P(X=2|X^2=4):=\lim\limits_{\epsilon  \to 0}\frac{P(X=2 \;\cap\; X^2 \in [4-\epsilon,4+\epsilon])}{P(X^2 \in [4-\epsilon,4+\epsilon])} 0 X","['probability', 'measure-theory', 'conditional-probability']"
76,Probability of finding the fly inside a range,Probability of finding the fly inside a range,,"A fly is traversing the non-negative x-axis. It starts at $x_0=k$ . At the $i^{th}$ step (starting from the zeroth step), it uniformly randomly jumps to a point in the range $[0,x_i]$ . Probability that the fly is in the range $[a,b]$ after $n$ jumps is denoted by $P_n(a,b)$ . Find $$\lim_{y \to 0}\frac{P_n(1,1+y)}{y}$$ Any help will be appreciated. EDIT: Sorry for the late response. Here is my brief try. If we consider the condition that after $n$ jumps, the fly is at a position $> a$ , but exclude the condition that it should be $< b$ . Let $p=a/k$ \begin{align} \begin{split} P_n(a)&=\int\limits_{x1=a}^k ~\int\limits_{x_2=a}^{x_!}....\int\limits_{x_n=a}^{x_{n-1}}\frac{1}{k}\frac{1}{x_1}...\frac{1}{x_{n-1}}\ dx_1 \ dx_2 ... \ dx_n\\ &=1-p+p\sum_{i=1}^{n-1}\frac{(\log p)^i}{i!} \end{split} \end{align}","A fly is traversing the non-negative x-axis. It starts at . At the step (starting from the zeroth step), it uniformly randomly jumps to a point in the range . Probability that the fly is in the range after jumps is denoted by . Find Any help will be appreciated. EDIT: Sorry for the late response. Here is my brief try. If we consider the condition that after jumps, the fly is at a position , but exclude the condition that it should be . Let","x_0=k i^{th} [0,x_i] [a,b] n P_n(a,b) \lim_{y \to 0}\frac{P_n(1,1+y)}{y} n > a < b p=a/k \begin{align}
\begin{split}
P_n(a)&=\int\limits_{x1=a}^k ~\int\limits_{x_2=a}^{x_!}....\int\limits_{x_n=a}^{x_{n-1}}\frac{1}{k}\frac{1}{x_1}...\frac{1}{x_{n-1}}\ dx_1 \ dx_2 ... \ dx_n\\
&=1-p+p\sum_{i=1}^{n-1}\frac{(\log p)^i}{i!}
\end{split}
\end{align}","['probability', 'probability-theory', 'probability-distributions']"
77,Calling the firefighters,Calling the firefighters,,"Consider the following problem: Suppose a house with $n$ apartments is on fire. Every person living there can call the firefighters. Suppose the call costs $1 \$ $ . If at least one person calls firefighters the fire will be extinguished. If noone calls them, then the house will burn down and everyone living there will lose $m \$ $ of property ( $m > 1$ ). The people living in this house do not talk to each other and decide to call or not to call completely independently. For what $n$ the firefighters are less likely to be called? The solution is the following one: People living in the house not talking to each other means that we need to find a symmetric mixed Nash equilibrium. Suppose $\alpha$ is the probability of any given person calling the firefighters. Then anyones expected gain (in comparison to the situation when everything burns down) is $$(1 - \alpha)^{n-1} \alpha (m - 1) + (1 - (1 - \alpha))^{n - 1} (\alpha (m - 1) + (1 - \alpha) m) = m - \alpha - (1 - \alpha)^n m$$ Let’s find for which $\alpha$ it is maximised. $$\frac{\partial (m - \alpha - (1 - \alpha)^n m)}{\partial \alpha} = -1 + n (1 - \alpha)^{n-1} m$$ Thus the point of extremum is $$\alpha = 1 - (\frac{1}{m n})^{\frac{1}{n-1}} = \frac{\ln (n)}{n} + \frac{\ln(m)}{n} + O(\frac{\ln^2(n)}{n^2})$$ This indeed is what we need: the total value at this point is greater than at both ends of $[0; 1]$ . Now, when we know $\alpha$ let’s calculate the probability of firefighters being called. It is $1 - (1 - \alpha)^{n} = 1 - (\frac{1}{m n})^{1 + \frac{1}{n - 1}}$ . It is not hard to see, that it is $1$ (it’s maximal possible value) both when $n = 1$ and $n \to \infty$ . Thus the minimum is reached in the internal infimum. $$\frac{\partial (1 - (\frac{1}{m n})^{1 + \frac{1}{n - 1}})}{\partial n} =  - (\frac{1}{m n})^{1 + \frac{1}{n - 1}} \frac{1 + \ln(m) - \ln(n) - n}{n - 1}$$ Thus the minimum is reached when $m = n e^{n - 1}$ . So the answer is $n = W(e m) = \ln(m) - \ln(\ln(m)) + o(1)$ Now, let’s make the problem a bit more complex: Suppose a house with $n$ apartments is on fire. Every person living there can call the firefighters. Suppose the call costs $1 \$ $ . If anyone calls firefighters the fire will be extinguished. If no-one calls them, then the house will burn down and $i$ -th person living there will lose $X_i \$ $ of property ( $X_i > 1$ ). Everyone knows only their value of $X_i$ and consider the corresponding values of everyone else to be i.i.d. random values, uniformly distributed on $[1;m]$ ( $m > 1$ ). The people living in this house do not talk to each other and decide to call or not to call completely independently. For what $n$ the firefighters are less likely to be called? I attempted to use a similar method: look for a symmetric Bayes-Nash equilibrium and see what is happening there, however the problem appears to be much trickier. Now, the strategy of each player is defined not as a single value $\alpha$ (probability of calling the firefighters), but as a function $\alpha: [1; +\infty) \to [0; 1]$ , where $\alpha(x)$ is the probability of any given player calling the firefighters if they know they lose $x$ dollars if the fire will not be extinguished. Then for a fixed $X_i = x$ the expected gain of the $i$ -th player will be $$x - \alpha(x) - x(1 - \alpha(x)) E (\Pi_{j \leq n, j \neq i}(1 - \alpha(X_j))) = x - \alpha(x) - x (1 - \alpha(x))  \big(\frac{\int_1^m (1 - \alpha(t))dt}{m - 1}\big)^{n-1}$$ And here I am stuck because I do not know how to find the function $\alpha$ (dependent on $m$ ) for which $x - \alpha(x) - x (1 - \alpha(x))  \big(\frac{\int_1^m (1 - \alpha(t))dt}{m - 1}\big)^{n-1}$ is maximal for every $x \in [1; m]$ . Any help will be appreciated.","Consider the following problem: Suppose a house with apartments is on fire. Every person living there can call the firefighters. Suppose the call costs . If at least one person calls firefighters the fire will be extinguished. If noone calls them, then the house will burn down and everyone living there will lose of property ( ). The people living in this house do not talk to each other and decide to call or not to call completely independently. For what the firefighters are less likely to be called? The solution is the following one: People living in the house not talking to each other means that we need to find a symmetric mixed Nash equilibrium. Suppose is the probability of any given person calling the firefighters. Then anyones expected gain (in comparison to the situation when everything burns down) is Let’s find for which it is maximised. Thus the point of extremum is This indeed is what we need: the total value at this point is greater than at both ends of . Now, when we know let’s calculate the probability of firefighters being called. It is . It is not hard to see, that it is (it’s maximal possible value) both when and . Thus the minimum is reached in the internal infimum. Thus the minimum is reached when . So the answer is Now, let’s make the problem a bit more complex: Suppose a house with apartments is on fire. Every person living there can call the firefighters. Suppose the call costs . If anyone calls firefighters the fire will be extinguished. If no-one calls them, then the house will burn down and -th person living there will lose of property ( ). Everyone knows only their value of and consider the corresponding values of everyone else to be i.i.d. random values, uniformly distributed on ( ). The people living in this house do not talk to each other and decide to call or not to call completely independently. For what the firefighters are less likely to be called? I attempted to use a similar method: look for a symmetric Bayes-Nash equilibrium and see what is happening there, however the problem appears to be much trickier. Now, the strategy of each player is defined not as a single value (probability of calling the firefighters), but as a function , where is the probability of any given player calling the firefighters if they know they lose dollars if the fire will not be extinguished. Then for a fixed the expected gain of the -th player will be And here I am stuck because I do not know how to find the function (dependent on ) for which is maximal for every . Any help will be appreciated.","n 1 \  m \  m > 1 n \alpha (1 - \alpha)^{n-1} \alpha (m - 1) + (1 - (1 - \alpha))^{n - 1} (\alpha (m - 1) + (1 - \alpha) m) = m - \alpha - (1 - \alpha)^n m \alpha \frac{\partial (m - \alpha - (1 - \alpha)^n m)}{\partial \alpha} = -1 + n (1 - \alpha)^{n-1} m \alpha = 1 - (\frac{1}{m n})^{\frac{1}{n-1}} = \frac{\ln (n)}{n} + \frac{\ln(m)}{n} + O(\frac{\ln^2(n)}{n^2}) [0; 1] \alpha 1 - (1 - \alpha)^{n} = 1 - (\frac{1}{m n})^{1 + \frac{1}{n - 1}} 1 n = 1 n \to \infty \frac{\partial (1 - (\frac{1}{m n})^{1 + \frac{1}{n - 1}})}{\partial n} =  - (\frac{1}{m n})^{1 + \frac{1}{n - 1}} \frac{1 + \ln(m) - \ln(n) - n}{n - 1} m = n e^{n - 1} n = W(e m) = \ln(m) - \ln(\ln(m)) + o(1) n 1 \  i X_i \  X_i > 1 X_i [1;m] m > 1 n \alpha \alpha: [1; +\infty) \to [0; 1] \alpha(x) x X_i = x i x - \alpha(x) - x(1 - \alpha(x)) E (\Pi_{j \leq n, j \neq i}(1 - \alpha(X_j))) = x - \alpha(x) - x (1 - \alpha(x))  \big(\frac{\int_1^m (1 - \alpha(t))dt}{m - 1}\big)^{n-1} \alpha m x - \alpha(x) - x (1 - \alpha(x))  \big(\frac{\int_1^m (1 - \alpha(t))dt}{m - 1}\big)^{n-1} x \in [1; m]","['probability', 'optimization', 'game-theory', 'calculus-of-variations', 'nash-equilibrium']"
78,Proving the variance of the distribution of $m$-fold products of elements of a generating set is asymptotic to $c^m$ without advanced tools,Proving the variance of the distribution of -fold products of elements of a generating set is asymptotic to  without advanced tools,m c^m,"Let $G$ be abelian with $n$ elements and let $G' = \{g_1 = e, \dots, g_k\} \subsetneq G$ be a (not necessarily minimal) set of generators. An element $g \in G$ is obtained by independently, uniformly at random (repetitions possible) selecting $m$ elements of $G'$ and multiplying them together. Prove there exists $b \in (0,1)$ such that $\lim\limits_{m \to \infty} \frac{1}{b^{2m}} \sum\limits_{x \in G} (\text{Pr}(g = x) - \frac{1}{n})^2$ is finite and non-zero. Fedja remarked here that ""Either you know the basic Fourier analysis on finite groups and then the problem is trivial (the convolution becomes just multiplication on the character group), or you don't and then you have almost no chance."" I don't know basic Fourier analysis on finite groups, but I'm hoping to prove him wrong. My attempt: Let $h_m$ be a random variable indicating the element selected after choosing $m$ elements of $G'.$ Then $\text{Pr}(h_m = x) = \frac{1}{k}\sum\limits_{i=1}^k \text{Pr}(h_m = xg_i^{-1}),$ so $$\left(\text{Pr}(h_m = x) - \frac{1}{n}\right)^2 = \frac{1}{k^2}\left(\sum\limits_{i=1}^k \left( \text{Pr}(h_{m-1} = g_i^{-1}x) - \frac{1}{n}\right)\right)^2 \le \frac{1}{k}\sum\limits_{i=1}^k \left( \text{Pr}(h_{m-1} = g_i^{-1}x) - \frac{1}{n}\right)^2$$ by Cauchy-Schwarz. Since the list of $nk$ elements $g_i^{-1}x, x \in G$ contains every element of $G$ exactly $k$ times, we get $$\sum\limits_{x \in G} \left(\text{Pr}(h_m = x) - \frac{1}{n}\right)^2 \le \sum\limits_{x \in G} \left(\text{Pr}(h_{m-1} = x) - \frac{1}{n}\right)^2.$$ This proves that the limit without the $b^{-2m}$ term exists by monotone boundedness. However, this limit is certainly zero, which is why the term is present in the first place. How do I obtain a finer estimate that allows me to deal with the entire limit?","Let be abelian with elements and let be a (not necessarily minimal) set of generators. An element is obtained by independently, uniformly at random (repetitions possible) selecting elements of and multiplying them together. Prove there exists such that is finite and non-zero. Fedja remarked here that ""Either you know the basic Fourier analysis on finite groups and then the problem is trivial (the convolution becomes just multiplication on the character group), or you don't and then you have almost no chance."" I don't know basic Fourier analysis on finite groups, but I'm hoping to prove him wrong. My attempt: Let be a random variable indicating the element selected after choosing elements of Then so by Cauchy-Schwarz. Since the list of elements contains every element of exactly times, we get This proves that the limit without the term exists by monotone boundedness. However, this limit is certainly zero, which is why the term is present in the first place. How do I obtain a finer estimate that allows me to deal with the entire limit?","G n G' = \{g_1 = e, \dots, g_k\} \subsetneq G g \in G m G' b \in (0,1) \lim\limits_{m \to \infty} \frac{1}{b^{2m}} \sum\limits_{x \in G} (\text{Pr}(g = x) - \frac{1}{n})^2 h_m m G'. \text{Pr}(h_m = x) = \frac{1}{k}\sum\limits_{i=1}^k \text{Pr}(h_m = xg_i^{-1}), \left(\text{Pr}(h_m = x) - \frac{1}{n}\right)^2 = \frac{1}{k^2}\left(\sum\limits_{i=1}^k \left( \text{Pr}(h_{m-1} = g_i^{-1}x) - \frac{1}{n}\right)\right)^2 \le \frac{1}{k}\sum\limits_{i=1}^k \left( \text{Pr}(h_{m-1} = g_i^{-1}x) - \frac{1}{n}\right)^2 nk g_i^{-1}x, x \in G G k \sum\limits_{x \in G} \left(\text{Pr}(h_m = x) - \frac{1}{n}\right)^2 \le \sum\limits_{x \in G} \left(\text{Pr}(h_{m-1} = x) - \frac{1}{n}\right)^2. b^{-2m}","['probability', 'group-theory', 'abelian-groups', 'finitely-generated']"
79,What is the distribution of $N-X_N$ if $X_i$'s are i.i.d $\operatorname{Exp}(1)$ and $N=\min\{n\ge1:X_n>1\}$?,What is the distribution of  if 's are i.i.d  and ?,N-X_N X_i \operatorname{Exp}(1) N=\min\{n\ge1:X_n>1\},"Suppose $(X_n)_{n\in\mathbb N}$ is an i.i.d sequence of random variables where $X_1$ has an exponential distribution with mean $1$ . Let $N=\min\{n\ge1:X_n>1\}$ . I am asked to find the distribution of $N-X_N$ . Now $N$ has a geometric distribution, with $$P(N>n)=P(X_1\le 1,\ldots,X_n\le 1)=(1-e^{-1})^n\quad,\,n\in\mathbb N$$ And it can be shown that distribution function of $X_N$ is just $$P(X_N\le x)=P(X_1\le x\mid X_1>1)\,,$$ so that $X_N$ has a shifted exponential distribution with density $$f_{X_N}(x)=e^{-(x-1)}1_{x>1}$$ Since a joint distribution of $N$ and $X_N$ is not given, the question would have made sense if $N$ and $X_N$ were independent. In any case, I tried to find the distribution function as \begin{align} P(N-X_N\le x)&=\sum_{n=1}^\infty P(n-X_n\le x,N=n) \\&=\sum_{n=1}^\infty P(X_n\ge n-x,X_1\le 1,\ldots,X_{n-1}\le 1,X_n>1) \\&=\sum_{n=1}^\infty P(X_1 > \max(n-x,1))(P(X_1\le 1))^{n-1} \\&=\sum_{n=1}^\infty e^{-\max(n-x,1)}(1-e^{-1})^{n-1} \\&\stackrel{?}=\sum_{n=1}^{x+1}e^{-1}(1-e^{-1})^{n-1}+\sum_{n=x+2}^\infty e^{-(n-x)}(1-e^{-1})^{n-1} \end{align} The last two sums can be evaluated, but I am not sure if I arrive at a valid answer. Is there a simpler way to solve this, perhaps using some independence argument? Is it guaranteed that $N-X_N$ will be absolutely continuous? I could say that if $N$ and $X_N$ were independent, but don't think that is true here. @Henry has pointed out that $N$ and $X_N$ are indeed independent. I think I understand the logic but would like to see a formal proof of the independence. Assuming independence, I get \begin{align} P(N-X_N\le y)&=\int P(N\le y+x)f_{X_N}(x)\,dx \\&=\int_{1-y}^\infty \left(1-(1-e^{-1})^{y+x}\right)e^{-(x-1)}dx\,1_{y<0}+\int_1^\infty \left(1-(1-e^{-1})^{y+x}\right)e^{-(x-1)}dx\,1_{y>0} \end{align} Does this look right?","Suppose is an i.i.d sequence of random variables where has an exponential distribution with mean . Let . I am asked to find the distribution of . Now has a geometric distribution, with And it can be shown that distribution function of is just so that has a shifted exponential distribution with density Since a joint distribution of and is not given, the question would have made sense if and were independent. In any case, I tried to find the distribution function as The last two sums can be evaluated, but I am not sure if I arrive at a valid answer. Is there a simpler way to solve this, perhaps using some independence argument? Is it guaranteed that will be absolutely continuous? I could say that if and were independent, but don't think that is true here. @Henry has pointed out that and are indeed independent. I think I understand the logic but would like to see a formal proof of the independence. Assuming independence, I get Does this look right?","(X_n)_{n\in\mathbb N} X_1 1 N=\min\{n\ge1:X_n>1\} N-X_N N P(N>n)=P(X_1\le 1,\ldots,X_n\le 1)=(1-e^{-1})^n\quad,\,n\in\mathbb N X_N P(X_N\le x)=P(X_1\le x\mid X_1>1)\,, X_N f_{X_N}(x)=e^{-(x-1)}1_{x>1} N X_N N X_N \begin{align}
P(N-X_N\le x)&=\sum_{n=1}^\infty P(n-X_n\le x,N=n)
\\&=\sum_{n=1}^\infty P(X_n\ge n-x,X_1\le 1,\ldots,X_{n-1}\le 1,X_n>1)
\\&=\sum_{n=1}^\infty P(X_1 > \max(n-x,1))(P(X_1\le 1))^{n-1}
\\&=\sum_{n=1}^\infty e^{-\max(n-x,1)}(1-e^{-1})^{n-1}
\\&\stackrel{?}=\sum_{n=1}^{x+1}e^{-1}(1-e^{-1})^{n-1}+\sum_{n=x+2}^\infty e^{-(n-x)}(1-e^{-1})^{n-1}
\end{align} N-X_N N X_N N X_N \begin{align}
P(N-X_N\le y)&=\int P(N\le y+x)f_{X_N}(x)\,dx
\\&=\int_{1-y}^\infty \left(1-(1-e^{-1})^{y+x}\right)e^{-(x-1)}dx\,1_{y<0}+\int_1^\infty \left(1-(1-e^{-1})^{y+x}\right)e^{-(x-1)}dx\,1_{y>0}
\end{align}","['probability', 'probability-distributions', 'independence', 'stopping-times', 'exponential-distribution']"
80,Help understanding the concept of full rank exponential families,Help understanding the concept of full rank exponential families,,"I am studying Exponential Families and there are some concept I do not quite understand completely. Here are a two definitions for rank of an exponential family and a full rank exponential family: Definition 1: Let $\mathscr{P}=\{P_\eta:\eta\in H\}$ is an $s-$ dimensional minimal exponential family. If $H$ contains an open $s-$ dimensional rectangle, then $\mathscr{P}$ is called full-rank. Otherwise, $\mathscr{P}$ is called curved. Definition 2: An exponential family is of rank $k$ if and only if the generating statistic $T$ is $k-$ dimensional and $\{1, T_1(X), \ldots,T_k(X)\}$ are linearly independent with positive probability. Formally, $P_\eta\left(\sum_{j=1}^{k}a_jT_j(X)=a_{k+1}\right)<1$ unless all $a_j$ are zeros. Here, definition 1 I took from this note and definition 2 is from Doksum & Bickel's. It is definition 2 that makes me confused. When I read the first sentence of definition 2, I translate it as follows: There exists a set $A$ such that $P_\eta(A)>0$ , and if $\sum_{j=1}^{k}a_jT_j(X)=a_{k+1}$ for all $x\in A$ , then $a_1=a_2=\cdots=a_{k+1}=0.$ But then how is it equivalent to the second sentence of definition 2? In other words, how should I understand the sentence "" Formally, $P_\eta(\sum_{j=1}^{k}a_jT_j(X)=a_{k+1})<1$ unless all $a_j$ are zeros "" correctly?","I am studying Exponential Families and there are some concept I do not quite understand completely. Here are a two definitions for rank of an exponential family and a full rank exponential family: Definition 1: Let is an dimensional minimal exponential family. If contains an open dimensional rectangle, then is called full-rank. Otherwise, is called curved. Definition 2: An exponential family is of rank if and only if the generating statistic is dimensional and are linearly independent with positive probability. Formally, unless all are zeros. Here, definition 1 I took from this note and definition 2 is from Doksum & Bickel's. It is definition 2 that makes me confused. When I read the first sentence of definition 2, I translate it as follows: There exists a set such that , and if for all , then But then how is it equivalent to the second sentence of definition 2? In other words, how should I understand the sentence "" Formally, unless all are zeros "" correctly?","\mathscr{P}=\{P_\eta:\eta\in H\} s- H s- \mathscr{P} \mathscr{P} k T k- \{1, T_1(X), \ldots,T_k(X)\} P_\eta\left(\sum_{j=1}^{k}a_jT_j(X)=a_{k+1}\right)<1 a_j A P_\eta(A)>0 \sum_{j=1}^{k}a_jT_j(X)=a_{k+1} x\in A a_1=a_2=\cdots=a_{k+1}=0. P_\eta(\sum_{j=1}^{k}a_jT_j(X)=a_{k+1})<1 a_j","['probability', 'statistics', 'statistical-inference']"
81,Probability no male- female pairs share same birthday,Probability no male- female pairs share same birthday,,There are 8 people in a room. There are 4 males(M) and 4 females(F).  What is the probability that there are no M-F pairs that have the same birthday ? It is OK for males to share a birthday and for females to share a birthday. Assume there are $10$ total birthdays. I give a solution below. Not sure if is correct and is there a more general way to approach it ? I break it into 5 cases-summing these cases gives the total ways M-F do not share. If divide the sum by $10^8$ would obtain desired probability. Case 1: all men have different birthdays $N_1 = 10 \cdot 9 \cdot 8 \cdot 7 \cdot (10-4)^4$ Case 2: one pair men exact + two single men $N_2 = {\sideset{_{10}}{_1} C} \cdot {\sideset{_4}{_2} C} \cdot 9 \cdot 8 \cdot (10-3)^4$ the first term chooses the single BD for the pair of men. The second term selects the 2 men in the pair. The $9\cdot 8$ are the number of ways the two single men can choose their birthdays. The final term is the number of ways the $4$ woman can select the remaining $10-3 = 7$ birthdays which do not equal the men which have used $3$ birthdays. Case 3: two pair men exact $N_3 = {\sideset{_{10}}{_2} C} \cdot {\sideset{_4}{_2} C} \cdot {\sideset{_2}{_2} C} \cdot (10-2)^4$ Case 4: one triple and one single man $N_4 = {\sideset{_{10}}{_1} C} \cdot {\sideset{_4}{_3} C} \cdot {\sideset{_1}{_1} C} \cdot {\sideset{_9}{_1} C} \cdot (10-2)^4$ Case 5: all men have same birthday $N_5 = {\sideset{_{10}}{_1} C} \cdot (10-1)^4$ The sum of Case $1$ to $5$ is the total ways for no M-F pairs. The last term  in each case is the number of permutations of the 4 woman with $(10-k)^4$ choices where $k$ is the number of unique birthdays used up for the men. I do not believe the order of the people matters: I calculate assuming all the men come first. Please comment on my approach. I have not found an understandable solution on this website.,There are 8 people in a room. There are 4 males(M) and 4 females(F).  What is the probability that there are no M-F pairs that have the same birthday ? It is OK for males to share a birthday and for females to share a birthday. Assume there are total birthdays. I give a solution below. Not sure if is correct and is there a more general way to approach it ? I break it into 5 cases-summing these cases gives the total ways M-F do not share. If divide the sum by would obtain desired probability. Case 1: all men have different birthdays Case 2: one pair men exact + two single men the first term chooses the single BD for the pair of men. The second term selects the 2 men in the pair. The are the number of ways the two single men can choose their birthdays. The final term is the number of ways the woman can select the remaining birthdays which do not equal the men which have used birthdays. Case 3: two pair men exact Case 4: one triple and one single man Case 5: all men have same birthday The sum of Case to is the total ways for no M-F pairs. The last term  in each case is the number of permutations of the 4 woman with choices where is the number of unique birthdays used up for the men. I do not believe the order of the people matters: I calculate assuming all the men come first. Please comment on my approach. I have not found an understandable solution on this website.,10 10^8 N_1 = 10 \cdot 9 \cdot 8 \cdot 7 \cdot (10-4)^4 N_2 = {\sideset{_{10}}{_1} C} \cdot {\sideset{_4}{_2} C} \cdot 9 \cdot 8 \cdot (10-3)^4 9\cdot 8 4 10-3 = 7 3 N_3 = {\sideset{_{10}}{_2} C} \cdot {\sideset{_4}{_2} C} \cdot {\sideset{_2}{_2} C} \cdot (10-2)^4 N_4 = {\sideset{_{10}}{_1} C} \cdot {\sideset{_4}{_3} C} \cdot {\sideset{_1}{_1} C} \cdot {\sideset{_9}{_1} C} \cdot (10-2)^4 N_5 = {\sideset{_{10}}{_1} C} \cdot (10-1)^4 1 5 (10-k)^4 k,"['probability', 'combinations', 'birthday']"
82,Card game only by talking - e.g. werewolf,Card game only by talking - e.g. werewolf,,"Recently I was wondering if it was possible to play card games with my math friends without having anything else than communication (no computing device, no sheets of paper), e.g. to play werewolf or mafia without cards. Formally, for n cards and n players, I want an algorithm such that: At the end, each player is assigned a number between 1 and n All assigned numbers are different No player knows the assigned numbers of other players without doing a substantial computation that one can easily not think about. All computations can be done in a reasonable time by a human brain. Nothing is secret except internal thinking I was able to devise a probabilistic algorithm that seems to work for n=3 Each player independently picks a random number between [1,3,5] Each player creates a 3-digit number whose modulo 7 is the chosen random number. Each player shares its 3-digit number. If the sum of these three numbers modulo 7 is 2 and the product modulo 7 is 1, then we have the guarantee that these numbers are 1, 3 and 5 in any order. If not, restart at 1. Add 1 to the chosen number and divide by 2. However, there is only 6 chances over 27 that this algorithm works... Could there be an algorithm that always works? For example that obtains permutation in an uniform way, such that each participant is expected to compute their own card number? And for more cards?","Recently I was wondering if it was possible to play card games with my math friends without having anything else than communication (no computing device, no sheets of paper), e.g. to play werewolf or mafia without cards. Formally, for n cards and n players, I want an algorithm such that: At the end, each player is assigned a number between 1 and n All assigned numbers are different No player knows the assigned numbers of other players without doing a substantial computation that one can easily not think about. All computations can be done in a reasonable time by a human brain. Nothing is secret except internal thinking I was able to devise a probabilistic algorithm that seems to work for n=3 Each player independently picks a random number between [1,3,5] Each player creates a 3-digit number whose modulo 7 is the chosen random number. Each player shares its 3-digit number. If the sum of these three numbers modulo 7 is 2 and the product modulo 7 is 1, then we have the guarantee that these numbers are 1, 3 and 5 in any order. If not, restart at 1. Add 1 to the chosen number and divide by 2. However, there is only 6 chances over 27 that this algorithm works... Could there be an algorithm that always works? For example that obtains permutation in an uniform way, such that each participant is expected to compute their own card number? And for more cards?",,"['probability', 'algorithms', 'uniform-distribution']"
83,How to interpret clusters on Markov chain time characteristics?,How to interpret clusters on Markov chain time characteristics?,,"I have a complex network $G=(V,E)$ from multivariate financial time series in which a single vertex $v_i$ represents the types of states corresponding to the combination of the fluctuations of the prices on a given time frame, a single edge $(v_i,v_j)$ denotes the transition from node $v_i$ to node $v_j$ . Then, I associated the graph $G$ with a first-order discrete-time Markov Chain as follows. The node set $$V(G)= \{v_1, v_2, \ldots, v_n\}$$ is the finite discrete state space and the edge set $$E(G) \subseteq V(G) \times V(G)$$ determined by the rule $e=(v_i, v_j) \in E(G)$ for $v_i, v_j \in V(G)$ , corresponds to states’ transitions, and the edge weight is the transition probability between two states $v_i$ and $v_j$ . I have computed the eigenvalues of the transition matrix. All eigenvalues ​​lie in a unit circle (except 1) and the spectral gap equals $1- |\lambda_2|=0.38$ . The Markov chain is aperiodic (because self-loops exist) and is irreducible. I have found the mean recurrence time (left graph) and then sorted mean recurrence time (right graph). As on the left graph as on the right graph, one can see three 'clusters' (sets). I think that is not a typical case.  Maybe the transition matrix has a specific form? My question is: How to interpret obtained clusters (subgraphs) for Markov chain time characteristics? I am looking for a possible practical interpretation. Edit 1. I have plotted the original graph $G$ with tree 'clusters'. Then densities, diameters for subgraphs were calculated. cluster vertexN edgeN     density diameter        1      35   105  0.088235294  1.30119        2      23    12  0.023715415  1.00000        3      46    10  0.004830918  2.00000 Density of original graph is 0.0229649. Refs Meyn S P and Tweedie R L 2005 Markov Chains and Stochastic Stability Zhang  N. Prediction of financial time series with hidden markov models: Shandong university, China, 2001","I have a complex network from multivariate financial time series in which a single vertex represents the types of states corresponding to the combination of the fluctuations of the prices on a given time frame, a single edge denotes the transition from node to node . Then, I associated the graph with a first-order discrete-time Markov Chain as follows. The node set is the finite discrete state space and the edge set determined by the rule for , corresponds to states’ transitions, and the edge weight is the transition probability between two states and . I have computed the eigenvalues of the transition matrix. All eigenvalues ​​lie in a unit circle (except 1) and the spectral gap equals . The Markov chain is aperiodic (because self-loops exist) and is irreducible. I have found the mean recurrence time (left graph) and then sorted mean recurrence time (right graph). As on the left graph as on the right graph, one can see three 'clusters' (sets). I think that is not a typical case.  Maybe the transition matrix has a specific form? My question is: How to interpret obtained clusters (subgraphs) for Markov chain time characteristics? I am looking for a possible practical interpretation. Edit 1. I have plotted the original graph with tree 'clusters'. Then densities, diameters for subgraphs were calculated. cluster vertexN edgeN     density diameter        1      35   105  0.088235294  1.30119        2      23    12  0.023715415  1.00000        3      46    10  0.004830918  2.00000 Density of original graph is 0.0229649. Refs Meyn S P and Tweedie R L 2005 Markov Chains and Stochastic Stability Zhang  N. Prediction of financial time series with hidden markov models: Shandong university, China, 2001","G=(V,E) v_i (v_i,v_j) v_i v_j G V(G)= \{v_1, v_2, \ldots, v_n\} E(G) \subseteq V(G) \times V(G) e=(v_i, v_j) \in E(G) v_i, v_j \in V(G) v_i v_j 1- |\lambda_2|=0.38 G","['probability', 'markov-chains', 'markov-process', 'transition-matrix', 'hidden-markov-models']"
84,Determine the probability that the group will score more than 80 points,Determine the probability that the group will score more than 80 points,,"A group of $20$ students take the exam. The probability that the student will receive a grade of $2$ - $0.1$ , grade $3$ - $0.3$ , grade $4$ - $0.4$ , grade $5$ - $0.2$ . Determine the probability that the group will score more than $80$ points. Can you tell me in which direction I should think to solve the problem because I have no ideas yet. Thanks in advance!","A group of students take the exam. The probability that the student will receive a grade of - , grade - , grade - , grade - . Determine the probability that the group will score more than points. Can you tell me in which direction I should think to solve the problem because I have no ideas yet. Thanks in advance!",20 2 0.1 3 0.3 4 0.4 5 0.2 80,['probability']
85,Difficult probability question,Difficult probability question,,"Four French teams make it to the final eight of the Champions League. The draw for the round is made at random. What is the probability that exactly one pairing has two french teams? ... At first, I recognised that there could only either be 0 matching teams, 1 matching team, or two matching teams. If we denote french as $f$ and not french as $nf$ , we can see that with 0 matching teams, the order of the teams must be: $f$ v $nf$ , $f$ v $nf$ , $f$ v $nf$ , $f$ v $nf$ , with one matching team: $f$ v $f$ , $f$ v $nf$ , $f$ v $nf$ , $nf$ v $nf$ , and two matching teams: $f$ v $f$ , $f$ v $f$ , $nf$ v $nf$ , $nf$ v $nf$ , I then proceeded to calculate the probability of 0 matching teams and two matching teams occuring, and subtracting them from 1 to calculate the probability for 1 matching team. However, I was not sure what approach to take when calculating this probability. Thanks, Field","Four French teams make it to the final eight of the Champions League. The draw for the round is made at random. What is the probability that exactly one pairing has two french teams? ... At first, I recognised that there could only either be 0 matching teams, 1 matching team, or two matching teams. If we denote french as and not french as , we can see that with 0 matching teams, the order of the teams must be: v , v , v , v , with one matching team: v , v , v , v , and two matching teams: v , v , v , v , I then proceeded to calculate the probability of 0 matching teams and two matching teams occuring, and subtracting them from 1 to calculate the probability for 1 matching team. However, I was not sure what approach to take when calculating this probability. Thanks, Field",f nf f nf f nf f nf f nf f f f nf f nf nf nf f f f f nf nf nf nf,['probability']
86,Math of Jury Sizes,Math of Jury Sizes,,"If we go by the assumption that a Jury is a representation of the public at large, then is 12 people statistically signficant? When doing any scientific survey or poll, a sample of 12 people would be laughable. Particularly if the results are close to 50-50. Is there any math done on this? For example. We might go by some axioms such as, we should only convict someone if 2/3 of the public think they are guilty. Then with that we can calculate the probability that a jury of 12 will wrongly convict or wrongly release a suspect. For example if the proportional of the public that think the man is guilty is $x$ . Then the probability that the jury will convict is if we convict if 2/3 of the Jury (8 or more men) say they are guilty is: $$P(convict) = x^{12} + 12 (1-x)x^{11} + 66 (1-x)^2 x^{10} + 220 (1-x)^3 x^9 + 594 (1-x)^4 x^8$$ So for example if 3/4 of the public think the man is guilty he should be convicted. But the jury will convict 88% of the time and release on 12% of the time. With the assumptions here is my question: Assume public is effectively infinite A man should be convicted if 2/3 of the public think he is guilty. Given a number of jurors $N$ and what proportional of jurors $f(N)$ should we convict a man so that there is a 95% agreement with the public and the jury when 3/4 of the public think the man is guilty. (Extra: Does this suggest an ideal jury size?)","If we go by the assumption that a Jury is a representation of the public at large, then is 12 people statistically signficant? When doing any scientific survey or poll, a sample of 12 people would be laughable. Particularly if the results are close to 50-50. Is there any math done on this? For example. We might go by some axioms such as, we should only convict someone if 2/3 of the public think they are guilty. Then with that we can calculate the probability that a jury of 12 will wrongly convict or wrongly release a suspect. For example if the proportional of the public that think the man is guilty is . Then the probability that the jury will convict is if we convict if 2/3 of the Jury (8 or more men) say they are guilty is: So for example if 3/4 of the public think the man is guilty he should be convicted. But the jury will convict 88% of the time and release on 12% of the time. With the assumptions here is my question: Assume public is effectively infinite A man should be convicted if 2/3 of the public think he is guilty. Given a number of jurors and what proportional of jurors should we convict a man so that there is a 95% agreement with the public and the jury when 3/4 of the public think the man is guilty. (Extra: Does this suggest an ideal jury size?)",x P(convict) = x^{12} + 12 (1-x)x^{11} + 66 (1-x)^2 x^{10} + 220 (1-x)^3 x^9 + 594 (1-x)^4 x^8 N f(N),"['probability', 'combinatorics', 'statistics', 'applications']"
87,Norm of the sum of random vectors from a unit ball,Norm of the sum of random vectors from a unit ball,,"Let $x_1,\dots, x_n\in \mathbb{R}^d$ be independently distributed from a uniform distribution on a ball of radius $1$ . That is for every $i$ : $x_i \sim U(\{x\in \mathbb{R}^d: \|x\|_2\leq 1\})$ . We look at the norm of the sum of the vectors: X = $\left\|\sum_{i=1}^n x_i \right\|_2$ . I need the following properties of X: 1) $\mathbb{E}[X] = ?$ 2) $Var(X) = ?$ 3) Given some $\alpha >0$ what is $P(X \leq \alpha)$ ? If the vectors would have been distributed by a standard Gaussian distribution then I could answer these questions by considering the coordinate-wise distribution of the sum, which would also be Gaussian with a mean of $0$ and variance of $\sqrt{n}$ . Thus, we could also calculate the mean and variance of the norm of the sum of the vectors, and for the third question the probability would be exponentially small. Also, if we would consider a uniform distribution on the cube it could be calculated quite easily. But I don't know how to do the same calculation for a uniform distribution on the unit ball (note that this is not the unit sphere, the vectors may have different norms).","Let be independently distributed from a uniform distribution on a ball of radius . That is for every : . We look at the norm of the sum of the vectors: X = . I need the following properties of X: 1) 2) 3) Given some what is ? If the vectors would have been distributed by a standard Gaussian distribution then I could answer these questions by considering the coordinate-wise distribution of the sum, which would also be Gaussian with a mean of and variance of . Thus, we could also calculate the mean and variance of the norm of the sum of the vectors, and for the third question the probability would be exponentially small. Also, if we would consider a uniform distribution on the cube it could be calculated quite easily. But I don't know how to do the same calculation for a uniform distribution on the unit ball (note that this is not the unit sphere, the vectors may have different norms).","x_1,\dots, x_n\in \mathbb{R}^d 1 i x_i \sim U(\{x\in \mathbb{R}^d: \|x\|_2\leq 1\}) \left\|\sum_{i=1}^n x_i \right\|_2 \mathbb{E}[X] = ? Var(X) = ? \alpha >0 P(X \leq \alpha) 0 \sqrt{n}","['probability', 'vectors']"
88,fair die is rolled until a number that has been obtained before is repeated,fair die is rolled until a number that has been obtained before is repeated,,"A fair die is rolled until a number that has been obtained before is repeated. Let the random variable X denote the number of rolls. Compute the probability mass function of X. Here's how I tackled this problem. Could you please check if this true? If it is not could you please hint We have that supp(X) is {2,3,4,5,6,7} Then P(X=2)=(6/6)(1/6)= 1/6 because we have 1/6 choices that we obtain the previous number. P(X=3)=(5/6)(2/6)=10/36. Because 5/6 is the second roll where it is the probability that we do not land the first value of the roll and 2/6 is the probability that we land the first two values of the rolls. P(X=4)=(5.4.3)/6^3 P(X=5)=(5.4.3.4)/6^4 P(X=6)=(5.4.3.2.5)/6^5 P(X=7)=(5.4.3.2.1.6)/6^6","A fair die is rolled until a number that has been obtained before is repeated. Let the random variable X denote the number of rolls. Compute the probability mass function of X. Here's how I tackled this problem. Could you please check if this true? If it is not could you please hint We have that supp(X) is {2,3,4,5,6,7} Then P(X=2)=(6/6)(1/6)= 1/6 because we have 1/6 choices that we obtain the previous number. P(X=3)=(5/6)(2/6)=10/36. Because 5/6 is the second roll where it is the probability that we do not land the first value of the roll and 2/6 is the probability that we land the first two values of the rolls. P(X=4)=(5.4.3)/6^3 P(X=5)=(5.4.3.4)/6^4 P(X=6)=(5.4.3.2.5)/6^5 P(X=7)=(5.4.3.2.1.6)/6^6",,['probability']
89,The Infamous $E[\max X_i| X_1 < X_2 < X_3] $ Solution,The Infamous  Solution,E[\max X_i| X_1 < X_2 < X_3] ,"If $X_i, i = 1,2,3$ are independent exponential random variables with rates $\lambda_i$ , $i = 1,2,3,$ find $E[max X_i| X_1 < X_2 < X_3]$ This question from Ross' textbook has been asked many times in mathstackexchange (see comment). After reading all the solutions and discussion in this website, now I understand that why $E[X_3] \neq \frac{1}{\lambda_3}$ . I have calculated the integral of three p.m.f's to get the result and verified the answer. However, I still would like to understand the ""simpler"" way of calculating the expectation. The solution is given as below: I don't understand how $E[X_2-X_1|X_1 < X_2 < X_3 ] + E[X_3-X_2|X_1 < X_2 < X_3 ]$ went $E[X_2|X_1< X_2 < X_3 ]+ E[X_3 ]$ . I don't understand how it is related to memoryless property of exponential distribution as the solution suggests. Please someone help....!","If are independent exponential random variables with rates , find This question from Ross' textbook has been asked many times in mathstackexchange (see comment). After reading all the solutions and discussion in this website, now I understand that why . I have calculated the integral of three p.m.f's to get the result and verified the answer. However, I still would like to understand the ""simpler"" way of calculating the expectation. The solution is given as below: I don't understand how went . I don't understand how it is related to memoryless property of exponential distribution as the solution suggests. Please someone help....!","X_i, i = 1,2,3 \lambda_i i = 1,2,3, E[max X_i| X_1 < X_2 < X_3] E[X_3] \neq \frac{1}{\lambda_3} E[X_2-X_1|X_1 < X_2 < X_3 ] + E[X_3-X_2|X_1 < X_2 < X_3 ] E[X_2|X_1< X_2 < X_3 ]+ E[X_3 ]","['probability', 'statistics', 'stochastic-processes', 'markov-chains', 'exponential-distribution']"
90,Concentration inequality for $k$-dependent Bernoulli r.v.s,Concentration inequality for -dependent Bernoulli r.v.s,k,"Given $X_1,X_2, \cdots$ are iid $Ber(p)$ , and we define $$Z_1 = X_1X_2\cdots X_k\\ Z_2 = X_2 X_3 \cdots X_{k+1}\\ \cdots$$ Is there a concentration inequality (like Hoeffding's inequality) for $$\mathbb{P}\bigg(\sum_{i=1}^n Z_i - \mathbb{E}\Big[\sum_{i=1}^n Z_i\Big]\geq t\bigg) \leq e^{(\cdots)}?$$","Given are iid , and we define Is there a concentration inequality (like Hoeffding's inequality) for","X_1,X_2, \cdots Ber(p) Z_1 = X_1X_2\cdots X_k\\ Z_2 = X_2 X_3 \cdots X_{k+1}\\ \cdots \mathbb{P}\bigg(\sum_{i=1}^n Z_i - \mathbb{E}\Big[\sum_{i=1}^n Z_i\Big]\geq t\bigg) \leq e^{(\cdots)}?","['probability', 'probability-theory', 'concentration-of-measure']"
91,"Relation between total variation and KS distance between measures on $[0,1]^d$",Relation between total variation and KS distance between measures on,"[0,1]^d","Let $P$ and $Q$ be two probability measures on the space $[0,1]^d$ , $d \in \{1, 2, \ldots \}$ , endowed with the $L_\infty$ norm and the corresponding Borel $\sigma$ -field, $\mathcal{B}$ . Let $$F_P(\mathbf{u})=P([\mathbf{0},\mathbf{u}]), \, \quad F_Q(\mathbf{u})=Q([\mathbf{0},\mathbf{u}]),$$ denote the distribution functions associated to $P$ and $Q$ , respectively. Then, we have that $$ d_{KS}(F_P,F_Q):=\sup_{\mathbf{u}\in[0,1]^d} |F_P(\mathbf{u})-F_Q(\mathbf{u})| \leq \sup_{B \in \mathcal{B}}|P(B)-Q(B)|=:d_{TV}(P,Q). $$ My question is the following: assume $F_P$ and $F_Q$ are Lipschitz continuous, then does (some form of) converse inequality also hold true? I was reasoning in this way: since $P$ and $Q$ are regular, for every $B \in \mathcal{B}$ and $\epsilon>0$ there exist closed sets $C_{B,\epsilon}^{(P)},C_{B,\epsilon}^{(Q)}$ and open sets $O_{B,\epsilon}^{(P)},O_{B,\epsilon}^{(Q)}$ such that $O_{B,\epsilon}^{(\bullet)} \subset B \subset C_{B,\epsilon}^{(\bullet)}$ and $$ P(C_{B,\epsilon}^{(P)}\setminus O_{B,\epsilon}^{(P)})\leq \epsilon, \quad Q(C_{B,\epsilon}^{(Q)}\setminus O_{B,\epsilon}^{(Q)})\leq \epsilon. $$ Whence, $ |P(B)-Q(B)| \leq 2 \epsilon + |P(O_{B,\epsilon}^{(P)})-Q(O_{B,\epsilon}^{(Q)})|. $ Yet, from now on it is not clear how to proceed. Maybe cover each open set with uniform metric-balls $\{B_1^\bullet,\ldots,B_{m_\bullet}^\bullet\}$ of radius $\delta$ ? Herein , we could maybe exploit the covering number inequality $m_\bullet \leq (3d/\delta)^d$ . Observe that each ball is of the form $$ B_i^\bullet=\times_{j=1}^d(u_{i,j}^\bullet-\delta,u_{i,j}^\bullet+\delta), $$ where $\mathbf{u}_i^\bullet=(u_{i,1}^\bullet, \ldots, u_{i,d}^\bullet) \in [0,1]^d. $ In particular, by absolute continuity, we could choose $\delta$ such that $$ |F_P(\mathbf{u}_i^Q+\delta \mathbf{1})-F_Q(\mathbf{u}_i^Q-\delta \mathbf{1})|\leq \epsilon', \quad |F_Q(\mathbf{u}_i^P+\delta \mathbf{1})-F_P(\mathbf{u}_i^P-\delta \mathbf{1})|\leq \epsilon' $$ for some arbitrarily small $\epsilon'>0$ . But still it is not evident to me that this could lead to a suitable upperbound encompassing $d_{KS}(F_p,F_Q)$ . Do you have any clue?","Let and be two probability measures on the space , , endowed with the norm and the corresponding Borel -field, . Let denote the distribution functions associated to and , respectively. Then, we have that My question is the following: assume and are Lipschitz continuous, then does (some form of) converse inequality also hold true? I was reasoning in this way: since and are regular, for every and there exist closed sets and open sets such that and Whence, Yet, from now on it is not clear how to proceed. Maybe cover each open set with uniform metric-balls of radius ? Herein , we could maybe exploit the covering number inequality . Observe that each ball is of the form where In particular, by absolute continuity, we could choose such that for some arbitrarily small . But still it is not evident to me that this could lead to a suitable upperbound encompassing . Do you have any clue?","P Q [0,1]^d d \in \{1, 2, \ldots \} L_\infty \sigma \mathcal{B} F_P(\mathbf{u})=P([\mathbf{0},\mathbf{u}]), \, \quad F_Q(\mathbf{u})=Q([\mathbf{0},\mathbf{u}]), P Q 
d_{KS}(F_P,F_Q):=\sup_{\mathbf{u}\in[0,1]^d}
|F_P(\mathbf{u})-F_Q(\mathbf{u})| \leq \sup_{B \in \mathcal{B}}|P(B)-Q(B)|=:d_{TV}(P,Q).
 F_P F_Q P Q B \in \mathcal{B} \epsilon>0 C_{B,\epsilon}^{(P)},C_{B,\epsilon}^{(Q)} O_{B,\epsilon}^{(P)},O_{B,\epsilon}^{(Q)} O_{B,\epsilon}^{(\bullet)} \subset B \subset C_{B,\epsilon}^{(\bullet)} 
P(C_{B,\epsilon}^{(P)}\setminus O_{B,\epsilon}^{(P)})\leq \epsilon, \quad
Q(C_{B,\epsilon}^{(Q)}\setminus O_{B,\epsilon}^{(Q)})\leq \epsilon.
 
|P(B)-Q(B)| \leq 2 \epsilon + |P(O_{B,\epsilon}^{(P)})-Q(O_{B,\epsilon}^{(Q)})|.
 \{B_1^\bullet,\ldots,B_{m_\bullet}^\bullet\} \delta m_\bullet \leq (3d/\delta)^d 
B_i^\bullet=\times_{j=1}^d(u_{i,j}^\bullet-\delta,u_{i,j}^\bullet+\delta),
 \mathbf{u}_i^\bullet=(u_{i,1}^\bullet, \ldots, u_{i,d}^\bullet) \in [0,1]^d.
 \delta 
|F_P(\mathbf{u}_i^Q+\delta \mathbf{1})-F_Q(\mathbf{u}_i^Q-\delta \mathbf{1})|\leq \epsilon',
\quad |F_Q(\mathbf{u}_i^P+\delta \mathbf{1})-F_P(\mathbf{u}_i^P-\delta \mathbf{1})|\leq \epsilon'
 \epsilon'>0 d_{KS}(F_p,F_Q)","['real-analysis', 'probability', 'probability-distributions', 'metric-spaces', 'total-variation']"
92,Expected time until a repeat in a sequence of infinitely many coin flips?,Expected time until a repeat in a sequence of infinitely many coin flips?,,"Consider flipping infinitely many coins and recording the result in a string $x_0 x_1 x_2 \dots$ Let $s_t$ be the substring of length $n$ starting from position $t$ . Let $\tau_n = \min(t > 0 : s_0 = s_t)$ be the random variable calculating the first time from when the initial substring $s_0$ is repeated. What is $\Bbb{E}(\tau_n)$ ? It is easy to show $\Bbb{E}(\tau_1) = 2$ : in the case that $n = 1$ , what we are calculating is simply the average minimum $t > 0$ such that $x_t = x_0$ , and we can take advantage of the independence of the coin flips. The probability that $x_t = x_0$ and $x_i \ne x_0 \ \ \forall \ 0 < i < t$ is $\left(\frac12\right) \cdot \left( \frac12 \right)^{t-1}$ , then $$\Bbb{E}(\tau_1) = \sum_{n=1}^\infty n \cdot \Pr(\tau_1 = n) = \sum_{n=1}^\infty n \cdot \left(\frac12\right) \cdot \left( \frac12 \right)^{n-1} = 2$$ Experimental data suggests $\Bbb{E}(\tau_n) = 2^n$ . I considered an inductive argument: waiting for a repeat of $n+1$ flips necessarily requires a repeat of $n$ flips, and then additional wait time until the last, single $n+1$ -th character occurs - a wait time equal in distribution(?) to $\tau_1$ , in which case $\Bbb{E}(\tau_{n+1}) = \Bbb{E}(\tau_n) \cdot \Bbb{E}(\tau_1)$ ? I don't know how to make this rigorous though.","Consider flipping infinitely many coins and recording the result in a string Let be the substring of length starting from position . Let be the random variable calculating the first time from when the initial substring is repeated. What is ? It is easy to show : in the case that , what we are calculating is simply the average minimum such that , and we can take advantage of the independence of the coin flips. The probability that and is , then Experimental data suggests . I considered an inductive argument: waiting for a repeat of flips necessarily requires a repeat of flips, and then additional wait time until the last, single -th character occurs - a wait time equal in distribution(?) to , in which case ? I don't know how to make this rigorous though.",x_0 x_1 x_2 \dots s_t n t \tau_n = \min(t > 0 : s_0 = s_t) s_0 \Bbb{E}(\tau_n) \Bbb{E}(\tau_1) = 2 n = 1 t > 0 x_t = x_0 x_t = x_0 x_i \ne x_0 \ \ \forall \ 0 < i < t \left(\frac12\right) \cdot \left( \frac12 \right)^{t-1} \Bbb{E}(\tau_1) = \sum_{n=1}^\infty n \cdot \Pr(\tau_1 = n) = \sum_{n=1}^\infty n \cdot \left(\frac12\right) \cdot \left( \frac12 \right)^{n-1} = 2 \Bbb{E}(\tau_n) = 2^n n+1 n n+1 \tau_1 \Bbb{E}(\tau_{n+1}) = \Bbb{E}(\tau_n) \cdot \Bbb{E}(\tau_1),"['probability', 'random-variables', 'expected-value']"
93,Grade 12: Data Management; Probability/binomial distributions -Homework help needed,Grade 12: Data Management; Probability/binomial distributions -Homework help needed,,"Struggling to figure these out, I have tried on my own a few times and have yet to get an answer that is remotely close to the correct one or what would be correct. In answer please include all steps 1) It is estimated that $17\%$ of cars are black. In a sample of $150$ cars, what is the probability that less than $20$ will be black? 2) It is estimated that $7\%$ of cars are blue. in a sample of $50$ cars, what is the probability that more than $10$ are blue? I have tried to solve for if no black cars and then subtract it from one to get the total for black cars but that didn’t work. I did a bunch of the ways we did in class but none of them seem to work, one of the ways I tried got me a negative number which is not possible for these. I have been attempting by using the formula $\displaystyle P(x=k) = \binom{n}{k} p^k q^{n-k}$ I am not $100\%$ sure what the answer is, we weren’t  given it to be able to check. I have been trying this for a few hours now and haven’t made a dent. This is for an online class and the teacher is no help. I am not sure how to do a sum of all the binomials that won’t take a million year with writing every single one out. Is their a short form? I don’t understand this. That video is not what we have learned so far And we have used tables in the past but not yet for this.","Struggling to figure these out, I have tried on my own a few times and have yet to get an answer that is remotely close to the correct one or what would be correct. In answer please include all steps 1) It is estimated that of cars are black. In a sample of cars, what is the probability that less than will be black? 2) It is estimated that of cars are blue. in a sample of cars, what is the probability that more than are blue? I have tried to solve for if no black cars and then subtract it from one to get the total for black cars but that didn’t work. I did a bunch of the ways we did in class but none of them seem to work, one of the ways I tried got me a negative number which is not possible for these. I have been attempting by using the formula I am not sure what the answer is, we weren’t  given it to be able to check. I have been trying this for a few hours now and haven’t made a dent. This is for an online class and the teacher is no help. I am not sure how to do a sum of all the binomials that won’t take a million year with writing every single one out. Is their a short form? I don’t understand this. That video is not what we have learned so far And we have used tables in the past but not yet for this.",17\% 150 20 7\% 50 10 \displaystyle P(x=k) = \binom{n}{k} p^k q^{n-k} 100\%,"['probability', 'binomial-distribution']"
94,Independence of Events and Conditional Probability,Independence of Events and Conditional Probability,,"A person tried by a 3-judge panel is declared guilty if at least 2 judges cast votes of guilty. Suppose that when the defendant is in fact guilty, each judge will independently vote guilty with probability 0.7, whereas when the defendant is in fact innocent, this probability drops to 0.2. Assume 70 percent of defendants are guilty. Let Ei, i = 1, 2, 3 denote the event that judge i casts a guilty vote. Are these events independent? Explain Are Ei’s, i = 1, 2, 3, conditionally independent? Explain. Compute the conditional probability that judge number 3 votes guilty given that judges 1 and 2 vote guilty. I am honestly stuck on where to even start with this problem. I would assume that the events are independent because the problem states it as such.","A person tried by a 3-judge panel is declared guilty if at least 2 judges cast votes of guilty. Suppose that when the defendant is in fact guilty, each judge will independently vote guilty with probability 0.7, whereas when the defendant is in fact innocent, this probability drops to 0.2. Assume 70 percent of defendants are guilty. Let Ei, i = 1, 2, 3 denote the event that judge i casts a guilty vote. Are these events independent? Explain Are Ei’s, i = 1, 2, 3, conditionally independent? Explain. Compute the conditional probability that judge number 3 votes guilty given that judges 1 and 2 vote guilty. I am honestly stuck on where to even start with this problem. I would assume that the events are independent because the problem states it as such.",,"['probability', 'conditional-probability', 'independence']"
95,Bayes' Theorem with Multiple Tests,Bayes' Theorem with Multiple Tests,,"I'm having difficulties with this problem: Suppose you have an entire city afflicted with four distinct and exclusive diseases and a laboratory is assigned to test which disease each citizen has. The reliability of these tests are as follows: Disease A = 72.7% Disease B = 81.1% Disease C = 75.2% Disease D = 80.1% The percentage of the population of people afflicted is as follows: P(B1) = 18.1% (Disease A) P(B2) = 31.9% (Disease B) P(B3) = 18.9% (Disease C) P(B4) = 31.1% (Disease D) If a random person were to selected from the entire population and then tested positive for disease A, what is the probability that they actually have disease A? I think that the problem is asking for P(B1|A1), so I used this formula: P(B1|A) = P(A|B1)P(B1) / ( P(A|B1)P(B1) + P(A|B2)P(B2) + P(A|B3)P(B3) + P(A|B4)P(B4) ) These are the values that I am sure of: P(A|B1) = .727 , because that is the chance of a true positive result of disease A being detected P(B1) to P(B4) = the population listed above, corresponding to A, B, C and D. The problem is now, I don't know what values to put inside P(A|B2) to P(A|B4) Do I put in just the rate of false positive (.273)? Or do I use the corresponding tests for disease B, C and D (.811, .752, .801, respectively)? Or am I missing something here?","I'm having difficulties with this problem: Suppose you have an entire city afflicted with four distinct and exclusive diseases and a laboratory is assigned to test which disease each citizen has. The reliability of these tests are as follows: Disease A = 72.7% Disease B = 81.1% Disease C = 75.2% Disease D = 80.1% The percentage of the population of people afflicted is as follows: P(B1) = 18.1% (Disease A) P(B2) = 31.9% (Disease B) P(B3) = 18.9% (Disease C) P(B4) = 31.1% (Disease D) If a random person were to selected from the entire population and then tested positive for disease A, what is the probability that they actually have disease A? I think that the problem is asking for P(B1|A1), so I used this formula: P(B1|A) = P(A|B1)P(B1) / ( P(A|B1)P(B1) + P(A|B2)P(B2) + P(A|B3)P(B3) + P(A|B4)P(B4) ) These are the values that I am sure of: P(A|B1) = .727 , because that is the chance of a true positive result of disease A being detected P(B1) to P(B4) = the population listed above, corresponding to A, B, C and D. The problem is now, I don't know what values to put inside P(A|B2) to P(A|B4) Do I put in just the rate of false positive (.273)? Or do I use the corresponding tests for disease B, C and D (.811, .752, .801, respectively)? Or am I missing something here?",,"['probability', 'discrete-mathematics', 'bayes-theorem']"
96,Divergence between Probability Distributions from Samples via the Chamfer Distance,Divergence between Probability Distributions from Samples via the Chamfer Distance,,"Suppose I have two probability distributions $P$ and $Q$ . I want to compute a divergence/distance between them. I do not have access to their densities, but I can draw samples $x\in D \subset \mathbb{R}^m$ from them. Let $X = \{x_i\mid x_i\sim P\}_{i=1}^n$ and $Y = \{y_j\mid y_j\sim Q\}_{j=1}^n$ . Ideally, I'd like to be able to compute this fairly quickly as well. There are a few simple candidates: the Earth Mover's (Wasserstein) distance (EMD) is good, but this one is a bit costly. I can use kernel density estimation, and then estimate the KL divergence with a Monte Carlo estimator (e.g., here or here ), or fit a probability distribution to $X$ and $Y$ (e.g. Gaussian or GMM), and then come up with a distance (e.g. based on parameters or analytic KL divergences say), but simple distributions don't fit well, this has too many parameters I need to tweak, and it seems unnecessarily complex. (The Monte Carlo KL estimates didn't perform well either; I'd like to avoid density estimation). There's also the Hausdorff distance which has some probabilistic connections but depends wildly on $n$ . I haven't yet explored kernelized maximum mean discrepancy much, which seems promising though. However, I have seen quite a few papers lately use the Chamfer Distance (it is not a metric , but it is some form of divergence nonetheless) as an efficient (yet still quite effective in practice) substitute for the EMD. (e.g. see [1] , [2] ). It is written $$ \mathcal{D}_C[X,Y] = \frac{1}{|X|} \sum_{x\in X} \min_{y\in Y} d(x,y) + \frac{1}{|Y|} \sum_{y\in Y} \min_{x\in X} d(x,y) $$ where $d:D\times D\rightarrow\mathbb{R}^+$ is some distance metric, e.g. $d(x,y)=||x-y||_2^2$ . Basically, for each point in one set, we get the closest point in the other set, and compute the distance between them - summing the result over the set, and then doing the same for the other set. Sometimes the normalizing fractions are left out. My questions : Is there a probabilistic connection to using this on samples? E.g., for a particular $d$ , is there a well-known continuous divergence that this approximates/bounds? Can $\mathcal{D}_C$ be used as a reasonable (pseudo)-distance between $P$ and $Q$ ? For example, can we guarantee that, as $n\rightarrow\infty$ , if $D_C[X,Y]\rightarrow 0$ , then, say, the KL or JS-divergence must also shrink to zero or be bounded by it? What sort of assumptions would be needed for this?","Suppose I have two probability distributions and . I want to compute a divergence/distance between them. I do not have access to their densities, but I can draw samples from them. Let and . Ideally, I'd like to be able to compute this fairly quickly as well. There are a few simple candidates: the Earth Mover's (Wasserstein) distance (EMD) is good, but this one is a bit costly. I can use kernel density estimation, and then estimate the KL divergence with a Monte Carlo estimator (e.g., here or here ), or fit a probability distribution to and (e.g. Gaussian or GMM), and then come up with a distance (e.g. based on parameters or analytic KL divergences say), but simple distributions don't fit well, this has too many parameters I need to tweak, and it seems unnecessarily complex. (The Monte Carlo KL estimates didn't perform well either; I'd like to avoid density estimation). There's also the Hausdorff distance which has some probabilistic connections but depends wildly on . I haven't yet explored kernelized maximum mean discrepancy much, which seems promising though. However, I have seen quite a few papers lately use the Chamfer Distance (it is not a metric , but it is some form of divergence nonetheless) as an efficient (yet still quite effective in practice) substitute for the EMD. (e.g. see [1] , [2] ). It is written where is some distance metric, e.g. . Basically, for each point in one set, we get the closest point in the other set, and compute the distance between them - summing the result over the set, and then doing the same for the other set. Sometimes the normalizing fractions are left out. My questions : Is there a probabilistic connection to using this on samples? E.g., for a particular , is there a well-known continuous divergence that this approximates/bounds? Can be used as a reasonable (pseudo)-distance between and ? For example, can we guarantee that, as , if , then, say, the KL or JS-divergence must also shrink to zero or be bounded by it? What sort of assumptions would be needed for this?","P Q x\in D \subset \mathbb{R}^m X = \{x_i\mid x_i\sim P\}_{i=1}^n Y = \{y_j\mid y_j\sim Q\}_{j=1}^n X Y n  \mathcal{D}_C[X,Y] = \frac{1}{|X|} \sum_{x\in X} \min_{y\in Y} d(x,y) + \frac{1}{|Y|} \sum_{y\in Y} \min_{x\in X} d(x,y)  d:D\times D\rightarrow\mathbb{R}^+ d(x,y)=||x-y||_2^2 d \mathcal{D}_C P Q n\rightarrow\infty D_C[X,Y]\rightarrow 0","['probability', 'statistics', 'probability-distributions', 'convergence-divergence', 'sampling']"
97,"Definition of a Markov process: What does $\mathbb P_x\{X_u\in \Gamma \mid \mathcal F_t\}=p(u-t,X_t,\Gamma)$ mean?",Definition of a Markov process: What does  mean?,"\mathbb P_x\{X_u\in \Gamma \mid \mathcal F_t\}=p(u-t,X_t,\Gamma)","I am reading the book Random perturbation of dynamical sustem of Freidlin and Wantzell (2nd edition). On page 20, they define a Markov process as follow: Let $(\Omega ,\mathcal F,\mathbb P)$ a probability space and $(X,\mathcal B)$ the state space. Let $(\mathcal F_t)$ a filtration. Let $(\mathbb P_x)_{x\in X}$ a familly of probability measure. Define the function $p$ as $$p(t,x,\Gamma )=\mathbb P_x\{X_t\in \Gamma \},\quad \Gamma \in \mathcal B, t\in [0,T],x\in X.$$ Then $X=(X_t)_{t\leq T}$ is a Markov process in $X$ if: a) $X$ is adapted to the filtration. b) $x\mapsto p(t,x,\Gamma )$ is measurable wrt $\mathcal B$ . c) $p(0,x, X\setminus \{x\})=0$ . d) $\mathbb P_x\{X_u\in Γ\mid \mathcal F_t\}=p(u-t,X_t,\Gamma )$ for all $t,u\in [0,T]$ , $t\leq u$ , $x\in X$ and $\Gamma \in \mathcal B$ . I am not sure how to interpret c) and d). Would these be correct? Q1) For c), is it $\mathbb P_x\{X_0=x\}=1$ ? Q2) For d), is it $$\mathbb P_{X_0=0}\{X_{t+h}\in \Gamma \mid X_t=k\}=\mathbb P_{X_0=k}\{X_h\in \Gamma \}?$$ But I don't really know how to interpret it.","I am reading the book Random perturbation of dynamical sustem of Freidlin and Wantzell (2nd edition). On page 20, they define a Markov process as follow: Let a probability space and the state space. Let a filtration. Let a familly of probability measure. Define the function as Then is a Markov process in if: a) is adapted to the filtration. b) is measurable wrt . c) . d) for all , , and . I am not sure how to interpret c) and d). Would these be correct? Q1) For c), is it ? Q2) For d), is it But I don't really know how to interpret it.","(\Omega ,\mathcal F,\mathbb P) (X,\mathcal B) (\mathcal F_t) (\mathbb P_x)_{x\in X} p p(t,x,\Gamma )=\mathbb P_x\{X_t\in \Gamma \},\quad \Gamma \in \mathcal B, t\in [0,T],x\in X. X=(X_t)_{t\leq T} X X x\mapsto p(t,x,\Gamma ) \mathcal B p(0,x, X\setminus \{x\})=0 \mathbb P_x\{X_u\in Γ\mid \mathcal F_t\}=p(u-t,X_t,\Gamma ) t,u\in [0,T] t\leq u x\in X \Gamma \in \mathcal B \mathbb P_x\{X_0=x\}=1 \mathbb P_{X_0=0}\{X_{t+h}\in \Gamma \mid X_t=k\}=\mathbb P_{X_0=k}\{X_h\in \Gamma \}?","['probability', 'stochastic-processes', 'markov-process']"
98,How to calculate probability of having at least one 2X2 same color square block on a random pixel generator?,How to calculate probability of having at least one 2X2 same color square block on a random pixel generator?,,"Let's assume we have random pixel generator which has  10X10 resolution (100 pixels in total) and each pixels can have 3 different colors. I'm trying to calculate probability of having at least one 2X2 same color square block on that screen . Here is my logic for such calculation: 1) Odds of all pixels having same color in 2X2 square block is 1/27 (3/3^4) 2) Odds of there is at least two different colors in 2X2 square block is 26/27 (1-1/27), which is complement probability of (1) 3) There are 81 different group of 2X2 square blocks on 10X10 grid. 4) Probability of that one 2X2 square block at least having two different colors is (26/27)^81 , based on complement probability. 5) Therefore probability of at least one 2X2 square block having same color is 1-(26/27)^81=95% approximately. However, -4 pixels on 10X10 grid which are located at the corners (top left,top  right,bottom left & bottom right) can be only in one 2X2 square block each -All pixels located in outermost parts except these 4, can be in two different 2X2 square blocks each -All remaining pixels inside outermost lines can be in four different 2X2 square blocks each. As I treated all pixels equally I didn't reflect the condition above in my calculation. How can I reflect the condition above in my calculation and have the correct probability? Is this mathematically possible to demonstrate via calculations? Thanks a lot!","Let's assume we have random pixel generator which has  10X10 resolution (100 pixels in total) and each pixels can have 3 different colors. I'm trying to calculate probability of having at least one 2X2 same color square block on that screen . Here is my logic for such calculation: 1) Odds of all pixels having same color in 2X2 square block is 1/27 (3/3^4) 2) Odds of there is at least two different colors in 2X2 square block is 26/27 (1-1/27), which is complement probability of (1) 3) There are 81 different group of 2X2 square blocks on 10X10 grid. 4) Probability of that one 2X2 square block at least having two different colors is (26/27)^81 , based on complement probability. 5) Therefore probability of at least one 2X2 square block having same color is 1-(26/27)^81=95% approximately. However, -4 pixels on 10X10 grid which are located at the corners (top left,top  right,bottom left & bottom right) can be only in one 2X2 square block each -All pixels located in outermost parts except these 4, can be in two different 2X2 square blocks each -All remaining pixels inside outermost lines can be in four different 2X2 square blocks each. As I treated all pixels equally I didn't reflect the condition above in my calculation. How can I reflect the condition above in my calculation and have the correct probability? Is this mathematically possible to demonstrate via calculations? Thanks a lot!",,"['probability', 'sequences-and-series', 'combinatorics', 'statistics', 'random-variables']"
99,Bound for cumulants of bounded random variables,Bound for cumulants of bounded random variables,,"Let $X$ be a random variable taking values in $[-1,1]$ .  The cumulant generating function is defined as $$ K(t) = \log \mathbb{E} [e^{tX}], $$ and the cumulants of $X$ are $$ \kappa_n = K^{(n)}(0). $$ I would like to know the best possible bounds on $\kappa_n$ .   I would be interested in any bound of the form $$ |\kappa_n| \leq C^n $$ which holds for bounded random variables $X$ .  Does this bound hold? With my limited understanding of cumulants, I would guess that the biggest cumulants would come from the Bernoulli random variable $X$ which takes the values $\pm 1$ equally often.  In this case one has $K(t)=\tanh(t)$ , and the cumulants decay to $0$ as $n\to\infty$ .  I expect that there should be worse examples, but I cannot find them.","Let be a random variable taking values in .  The cumulant generating function is defined as and the cumulants of are I would like to know the best possible bounds on .   I would be interested in any bound of the form which holds for bounded random variables .  Does this bound hold? With my limited understanding of cumulants, I would guess that the biggest cumulants would come from the Bernoulli random variable which takes the values equally often.  In this case one has , and the cumulants decay to as .  I expect that there should be worse examples, but I cannot find them.","X [-1,1] 
K(t) = \log \mathbb{E} [e^{tX}],
 X 
\kappa_n = K^{(n)}(0).
 \kappa_n 
|\kappa_n| \leq C^n
 X X \pm 1 K(t)=\tanh(t) 0 n\to\infty","['real-analysis', 'probability', 'cumulants']"
