,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Prove that the four-group $\{1,a,b,c \}$ is not cyclic.",Prove that the four-group  is not cyclic.,"\{1,a,b,c \}","I just want to make sure I have the right idea here. The Statement of the Problem: Prove that the four-group $\{1,a,b,c \}$ is not cyclic. My Answer: As far as I can tell, this is the Klein four-group and I just need to check the subgroups generated by each element. If any of them is the entire group, then it is cyclic; otherwise, it is not cyclic. Well: \begin{align}\langle1\rangle &= \{ 1 \} \\ \langle a\rangle  &= \{ 1, a \} \\ \langle b\rangle &= \{ 1,b \} \\ \langle c\rangle &= \{ 1, c \}\end{align} Obviously, none of these are equal to $\{1,a,b,c \}$ , therefore the group is not cyclic. Is that it?","I just want to make sure I have the right idea here. The Statement of the Problem: Prove that the four-group is not cyclic. My Answer: As far as I can tell, this is the Klein four-group and I just need to check the subgroups generated by each element. If any of them is the entire group, then it is cyclic; otherwise, it is not cyclic. Well: Obviously, none of these are equal to , therefore the group is not cyclic. Is that it?","\{1,a,b,c \} \begin{align}\langle1\rangle &= \{ 1 \} \\ \langle a\rangle  &= \{ 1, a \} \\ \langle b\rangle &= \{ 1,b \} \\ \langle c\rangle &= \{ 1, c \}\end{align} \{1,a,b,c \}","['abstract-algebra', 'group-theory', 'solution-verification', 'finite-groups', 'cyclic-groups']"
1,Multiplicative identity being equal to additive identity in a field,Multiplicative identity being equal to additive identity in a field,,"Is it even possible? What consequences would this have if it is possible? My attempt: Let us call this hypothetical universal identity $e$ . Fields require distributivity, right? $(a-a)a^{-1} = aa^{-1} - aa^{-1} = e-e = e$ But calculating without using distributivity $(a-a)a^{-1} = ea^{-1} = a^{-1}$ So any multiplicative inverse must be the identity. Then we can not have elements other than $e$ regardless of how we try and define addition?","Is it even possible? What consequences would this have if it is possible? My attempt: Let us call this hypothetical universal identity . Fields require distributivity, right? But calculating without using distributivity So any multiplicative inverse must be the identity. Then we can not have elements other than regardless of how we try and define addition?",e (a-a)a^{-1} = aa^{-1} - aa^{-1} = e-e = e (a-a)a^{-1} = ea^{-1} = a^{-1} e,['abstract-algebra']
2,Symmetric tensor powers as tensors over symmetric group algebra,Symmetric tensor powers as tensors over symmetric group algebra,,"Let $V$ be a $k$-vector space and $V^{\otimes n}$ the $n$-fold tensor power of $V$ and let $\mathbb{S}_n$ be the symmetric group of an n-element set, with its signum representation denoted by $(-1)^\sigma$ for $\sigma\in \mathbb{S}_n$. Now on one side we have the ""usual"" symmetric tensor power  $V^{\odot n}$ of $V$ defined by quotienting the ordinary tensor power by the maximal ideal generated by ""sums over antisymmetriezed permutations"", i.e.: $V^{\odot n}:= V^{\otimes n} /  \langle\{\sum_{\sigma\in \mathbb{S}_n} (-1)^\sigma v_{\sigma(1)}\otimes...\otimes v_{\sigma(n)}\;|\; v_1\otimes...\otimes v_n \in V^{\otimes n}\}\rangle$ On the other side it is said, that the same symmetric tensor power can be obtained as the following tensor product: $V^{\otimes n} \otimes_{k[\mathbb{S}_n]} k$ where $k[\mathbb{S}_n]$ is the group algebra over $\mathbb{S}_n$, with  $k$ a left $\mathbb{S}_n$-module, induced from the trivial representation and with $V^{\otimes n}$ a right $\mathbb{S}_n$ module induced from the right representation of $\mathbb{S}_n$ which permutes the indices. Can someone explain, how $V^{\otimes n} \otimes_{k[\mathbb{S}_n]} k$ is equivalent to the symmetric tensor product $V^{\odot n}$? I'm not sure, how we should think about $V^{\otimes n} \otimes_{k[\mathbb{S}_n]} k$ or tensor products $\bullet \otimes_{k[\mathbb{S}_n]} \bullet$ in general.","Let $V$ be a $k$-vector space and $V^{\otimes n}$ the $n$-fold tensor power of $V$ and let $\mathbb{S}_n$ be the symmetric group of an n-element set, with its signum representation denoted by $(-1)^\sigma$ for $\sigma\in \mathbb{S}_n$. Now on one side we have the ""usual"" symmetric tensor power  $V^{\odot n}$ of $V$ defined by quotienting the ordinary tensor power by the maximal ideal generated by ""sums over antisymmetriezed permutations"", i.e.: $V^{\odot n}:= V^{\otimes n} /  \langle\{\sum_{\sigma\in \mathbb{S}_n} (-1)^\sigma v_{\sigma(1)}\otimes...\otimes v_{\sigma(n)}\;|\; v_1\otimes...\otimes v_n \in V^{\otimes n}\}\rangle$ On the other side it is said, that the same symmetric tensor power can be obtained as the following tensor product: $V^{\otimes n} \otimes_{k[\mathbb{S}_n]} k$ where $k[\mathbb{S}_n]$ is the group algebra over $\mathbb{S}_n$, with  $k$ a left $\mathbb{S}_n$-module, induced from the trivial representation and with $V^{\otimes n}$ a right $\mathbb{S}_n$ module induced from the right representation of $\mathbb{S}_n$ which permutes the indices. Can someone explain, how $V^{\otimes n} \otimes_{k[\mathbb{S}_n]} k$ is equivalent to the symmetric tensor product $V^{\odot n}$? I'm not sure, how we should think about $V^{\otimes n} \otimes_{k[\mathbb{S}_n]} k$ or tensor products $\bullet \otimes_{k[\mathbb{S}_n]} \bullet$ in general.",,"['abstract-algebra', 'tensor-products', 'operads']"
3,Is there an infinite topological meadow with non-trivial topology?,Is there an infinite topological meadow with non-trivial topology?,,"For reference meadows are a generalization of fields that were designed to be compatible with the requirements of universal algebra. Specifically a meadow is a commutative ring equiped with an involution $x\mapsto x^{-1}$ which obeys $$x\cdot x\cdot x^{-1}=x$$ for all $x$. (A field can be turned into a meadow by letting $x^{-1}$ be the multiplicative inverse when $x\neq0$ and $0^{-1}=0$.) A topological meadow would be a commutative topological ring with such a $x\mapsto x^{-1}$ such that $x\mapsto x^{-1}$ is a continuous function. It was established in a previous question that none of the standard fields can be thought of as topological meadows with their standard topologies. (I'm also fairly certain the $p$-adics aren't topological meadows under their standard topologies either.) So my question is: Does there exist an infinite topological meadow with non-trivial topology? Non-trivial is somewhat vague, but I think essentially what I'm looking for is the space being Hausdorff and connected (if you take the topology of a topological field and make 0 an isolated point I believe you get a topological meadow, but it's disconnected), although failing these I would like to know 'how close' you can get. And if there is an infinite Hausdorff, connected topological meadow I would like to know how much more geoemtric structure you can have. Is there a topological meadow that is a connected (smooth) manifold (that isn't the zero meadow)?","For reference meadows are a generalization of fields that were designed to be compatible with the requirements of universal algebra. Specifically a meadow is a commutative ring equiped with an involution $x\mapsto x^{-1}$ which obeys $$x\cdot x\cdot x^{-1}=x$$ for all $x$. (A field can be turned into a meadow by letting $x^{-1}$ be the multiplicative inverse when $x\neq0$ and $0^{-1}=0$.) A topological meadow would be a commutative topological ring with such a $x\mapsto x^{-1}$ such that $x\mapsto x^{-1}$ is a continuous function. It was established in a previous question that none of the standard fields can be thought of as topological meadows with their standard topologies. (I'm also fairly certain the $p$-adics aren't topological meadows under their standard topologies either.) So my question is: Does there exist an infinite topological meadow with non-trivial topology? Non-trivial is somewhat vague, but I think essentially what I'm looking for is the space being Hausdorff and connected (if you take the topology of a topological field and make 0 an isolated point I believe you get a topological meadow, but it's disconnected), although failing these I would like to know 'how close' you can get. And if there is an infinite Hausdorff, connected topological meadow I would like to know how much more geoemtric structure you can have. Is there a topological meadow that is a connected (smooth) manifold (that isn't the zero meadow)?",,"['abstract-algebra', 'general-topology', 'field-theory', 'topological-rings']"
4,Stone Representation Theorem and Gelfand-Naimark-Segal Theorem?,Stone Representation Theorem and Gelfand-Naimark-Segal Theorem?,,"I just would like to know whethere Stone Representation Theorem http://en.wikipedia.org/wiki/Stone%27s_representation_theorem_for_Boolean_algebras has a direct connection (and if so, of what kind) with the Gelfand-Naimark-Segal Construction http://en.wikipedia.org/wiki/Gelfand%E2%80%93Naimark%E2%80%93Segal_construction They seem to me to share the same spirit, but I would be happy to hear more fro you about technicalities. Are they objects of the same family, so to speak? Thanks in advance.","I just would like to know whethere Stone Representation Theorem http://en.wikipedia.org/wiki/Stone%27s_representation_theorem_for_Boolean_algebras has a direct connection (and if so, of what kind) with the Gelfand-Naimark-Segal Construction http://en.wikipedia.org/wiki/Gelfand%E2%80%93Naimark%E2%80%93Segal_construction They seem to me to share the same spirit, but I would be happy to hear more fro you about technicalities. Are they objects of the same family, so to speak? Thanks in advance.",,"['abstract-algebra', 'functional-analysis']"
5,"Proof that if $a,b \in G$ and $a^4b = ba$ and $a^3 = e$ then $ab = ba$",Proof that if  and  and  then,"a,b \in G a^4b = ba a^3 = e ab = ba","I tried to prove one of the examples in my Abstract Algebra book that stated: Prove that if $a,b \in G$ and $a^4b = ba$ and $a^3 = e$ then $ab = ba$ I went about just saying that $a^4b = ba \iff a^3(ab) = ba \iff e(ab) = ba$ and the result follows. However, the book takes a longer route and proves it this way: $a^4b = ba \implies b = a^6b = a^2ba \implies ab = a^3ba = ba$ Are both of our proofs valid and equivalent or am I missing something? Thanks","I tried to prove one of the examples in my Abstract Algebra book that stated: Prove that if $a,b \in G$ and $a^4b = ba$ and $a^3 = e$ then $ab = ba$ I went about just saying that $a^4b = ba \iff a^3(ab) = ba \iff e(ab) = ba$ and the result follows. However, the book takes a longer route and proves it this way: $a^4b = ba \implies b = a^6b = a^2ba \implies ab = a^3ba = ba$ Are both of our proofs valid and equivalent or am I missing something? Thanks",,"['abstract-algebra', 'group-theory', 'proof-verification']"
6,What does it mean for a prime ideal to split completely?,What does it mean for a prime ideal to split completely?,,See here . What does it mean for a prime ideal to split completely?,See here . What does it mean for a prime ideal to split completely?,,"['abstract-algebra', 'number-theory']"
7,Example of Transcendental Extension with no Intermediate Field,Example of Transcendental Extension with no Intermediate Field,,"It can be shown that given $F \subset R \subset K$, where $K/F$ is an algebraic extension and $R$ is an integral domain, that $R$ is then an intermediate field. However, is there an explicit counter example for this statement when $K$ is not algebraic over $F$. I was considering $\mathbb{Q}(\pi)/ \mathbb{Q}$ which is a transcendental extension because there does not exist a polynomial with rational coefficients for which $\pi$ is a root. However how can one show that there does not exist intermediary fields. Is it recommended that I got about in showing that for $R$ where $\mathbb{Q} \subset R \subset \mathbb{Q}(\pi)$, $R$ does not contain multiplicative inverses? Or should I focus on the infinite degree of $[\mathbb{Q}(\pi):\mathbb{Q}]$. Any and all help would be appreciated!","It can be shown that given $F \subset R \subset K$, where $K/F$ is an algebraic extension and $R$ is an integral domain, that $R$ is then an intermediate field. However, is there an explicit counter example for this statement when $K$ is not algebraic over $F$. I was considering $\mathbb{Q}(\pi)/ \mathbb{Q}$ which is a transcendental extension because there does not exist a polynomial with rational coefficients for which $\pi$ is a root. However how can one show that there does not exist intermediary fields. Is it recommended that I got about in showing that for $R$ where $\mathbb{Q} \subset R \subset \mathbb{Q}(\pi)$, $R$ does not contain multiplicative inverses? Or should I focus on the infinite degree of $[\mathbb{Q}(\pi):\mathbb{Q}]$. Any and all help would be appreciated!",,"['abstract-algebra', 'field-theory', 'extension-field']"
8,"Find $f_{1}, f_{2}$ in $\mathbb{Z_{6}}[x]$ such that deg$(f_{1})$ = deg$(f_{2}) = 2$ and deg$(f_{1}+f_{2})=1$",Find  in  such that deg = deg and deg,"f_{1}, f_{2} \mathbb{Z_{6}}[x] (f_{1}) (f_{2}) = 2 (f_{1}+f_{2})=1","Find $f_{1}, f_{2}$ in $\mathbb{Z_{6}}[x]$ such that deg$(f_{1})$ = deg$(f_{2}) = 2$ and deg$(f_{1}+f_{2})=1$ Find $g_{1}, g_{2}$ in $\mathbb{Z_{6}}[x]$ such that deg$(g_{1})$ = deg$(g_{2}) = 1$ and deg$(g_{1}.g_{2})=1$","Find $f_{1}, f_{2}$ in $\mathbb{Z_{6}}[x]$ such that deg$(f_{1})$ = deg$(f_{2}) = 2$ and deg$(f_{1}+f_{2})=1$ Find $g_{1}, g_{2}$ in $\mathbb{Z_{6}}[x]$ such that deg$(g_{1})$ = deg$(g_{2}) = 1$ and deg$(g_{1}.g_{2})=1$",,"['abstract-algebra', 'modular-arithmetic']"
9,"Galois group, algebraic closure over maximal extension","Galois group, algebraic closure over maximal extension",,"Let $\overline{\mathbb{Q}}$ be the algebraic closure of $\mathbb{Q}$. Let $\alpha \in \overline{\mathbb{Q}}\setminus \mathbb{Q}$ and let $K \subset \overline{\mathbb{Q}}$ be a maximal extension of $\mathbb{Q}$ in respect to not containing $\alpha$ (so $\alpha \notin K$, but $\alpha$ in every nontrivial extension of $K$). Let $G$ be the Galois group of $\overline{Q}$ over $K$. Show that either $G = \mathbb{Z}/2\mathbb{Z}$ or $G = \mathbb{Z}_p$ ($p$-adic integers) for some prime $p$.","Let $\overline{\mathbb{Q}}$ be the algebraic closure of $\mathbb{Q}$. Let $\alpha \in \overline{\mathbb{Q}}\setminus \mathbb{Q}$ and let $K \subset \overline{\mathbb{Q}}$ be a maximal extension of $\mathbb{Q}$ in respect to not containing $\alpha$ (so $\alpha \notin K$, but $\alpha$ in every nontrivial extension of $K$). Let $G$ be the Galois group of $\overline{Q}$ over $K$. Show that either $G = \mathbb{Z}/2\mathbb{Z}$ or $G = \mathbb{Z}_p$ ($p$-adic integers) for some prime $p$.",,"['abstract-algebra', 'group-theory']"
10,An example of a simple infinite $2$-group,An example of a simple infinite -group,2,"Is there an example of a simple infinite $2$-group? Informations If a $2$-group is Artinian I know that it also locally finite, so the simple $2$-group cannot be Artinian. Take the subgroup generated by the elements of order $2$, it must coincide with $G$. If we have a periodic subgroup generated by two elements of order $2$, like $\langle a,\, b\rangle$, it must be finite.","Is there an example of a simple infinite $2$-group? Informations If a $2$-group is Artinian I know that it also locally finite, so the simple $2$-group cannot be Artinian. Take the subgroup generated by the elements of order $2$, it must coincide with $G$. If we have a periodic subgroup generated by two elements of order $2$, like $\langle a,\, b\rangle$, it must be finite.",,"['abstract-algebra', 'group-theory', 'examples-counterexamples', 'simple-groups', 'p-groups']"
11,Divisibility of group exponents when the subgroup has finite index.,Divisibility of group exponents when the subgroup has finite index.,,"Let $G$ be a group (not necessary finite) and $H$ a subgroup of $G$ of index $n$ such that exp $(H)<+\infty$ . Show that $$\exp(G)<+\infty$$ and $$\exp(G)\mid\exp(H)\cdot n.$$ Remarks. The case when $H$ is normal is a consequence of the group structure on the cosets. If $g\in G$, in general $g^n\not\in H$, for example $G=S_5$, $H=S_4$ and $g=(12)(345)$.","Let $G$ be a group (not necessary finite) and $H$ a subgroup of $G$ of index $n$ such that exp $(H)<+\infty$ . Show that $$\exp(G)<+\infty$$ and $$\exp(G)\mid\exp(H)\cdot n.$$ Remarks. The case when $H$ is normal is a consequence of the group structure on the cosets. If $g\in G$, in general $g^n\not\in H$, for example $G=S_5$, $H=S_4$ and $g=(12)(345)$.",,"['abstract-algebra', 'group-theory']"
12,Irreducibility of an integer polynomial with exponents in linear sequence?,Irreducibility of an integer polynomial with exponents in linear sequence?,,"Let $b$ and $n$ be two positive integers. Is there are a general result which tell us when the polynomial $$1+x^{b}+x^{2b}+x^{3b}+\cdots+x^{nb}$$   is irreducible over the integers? I know that $$1+x+\cdots+x^{n-1}$$ is irreducible if and only if $n$ is prime. I also know that $$1+x^n$$ is irreducible if and only if $n=2^k$ for some $k\geq 0$. However, I'd like to look at a linear sequence and know irreducibility before painstakingly looking for factors. I've noticed that the $n$ above in the question must be even for otherwise we could factor out $1+x^b$. But other than that I haven't made much ground except for particular values of $n$. I'm kind of hoping for a 'one-fell-swoop' result, but if there isn't, I'd like a recommendation for a general plan of approach for determining irreducibility of these polynomials. Any help is appreciated.","Let $b$ and $n$ be two positive integers. Is there are a general result which tell us when the polynomial $$1+x^{b}+x^{2b}+x^{3b}+\cdots+x^{nb}$$   is irreducible over the integers? I know that $$1+x+\cdots+x^{n-1}$$ is irreducible if and only if $n$ is prime. I also know that $$1+x^n$$ is irreducible if and only if $n=2^k$ for some $k\geq 0$. However, I'd like to look at a linear sequence and know irreducibility before painstakingly looking for factors. I've noticed that the $n$ above in the question must be even for otherwise we could factor out $1+x^b$. But other than that I haven't made much ground except for particular values of $n$. I'm kind of hoping for a 'one-fell-swoop' result, but if there isn't, I'd like a recommendation for a general plan of approach for determining irreducibility of these polynomials. Any help is appreciated.",,"['abstract-algebra', 'polynomials']"
13,What is the formal definition of polynomial ring of several variables?,What is the formal definition of polynomial ring of several variables?,,"Let's consider a polynomial ring of single variable. One can define them informally by saying $P(X)=\sum_{i=1}^n a_n X^n$ while $X$ is an indeterminate variable. However, since mathematics is based on first-order logic, one can only talk about something that actually exists (as a set). So as its name says, indeterminate variable is not a sentence in $ZFC$ . Nevertheless, we can formally define a polynomial ring $R[X]$ as a subset of $R^\omega$ whose support is finite. ( $R$ is a commutative ring with unity) Just like a single variable, I want to know what would be the formal definition of a polynomial ring of several variables . What would be a formal definition? === I have figured out a candidate. That is, Candidate for a ""Definition of a polynomial ring $R[X_1,...,X_n]$ "". ( $R$ is a commutative ring with unity) Let $R[X_1,...,X_n]$ be the set of all functions $f:\omega^n \rightarrow R$ whose support is finite. Define $(f+g)(a,b,c)=f(a,b,c)+g(a,b,c)$ and $(f•g)(a'',b'',c'')=\sum_{a+a'=a''} f(a,b,c)•g(a',b',c')$ (Note that in this way, $+,•$ are well defined.) Then, it can be checked that $(R[X_1,...,X_n],+,•)$ is a ring. Is this a formal definition of a polynomial ring?","Let's consider a polynomial ring of single variable. One can define them informally by saying while is an indeterminate variable. However, since mathematics is based on first-order logic, one can only talk about something that actually exists (as a set). So as its name says, indeterminate variable is not a sentence in . Nevertheless, we can formally define a polynomial ring as a subset of whose support is finite. ( is a commutative ring with unity) Just like a single variable, I want to know what would be the formal definition of a polynomial ring of several variables . What would be a formal definition? === I have figured out a candidate. That is, Candidate for a ""Definition of a polynomial ring "". ( is a commutative ring with unity) Let be the set of all functions whose support is finite. Define and (Note that in this way, are well defined.) Then, it can be checked that is a ring. Is this a formal definition of a polynomial ring?","P(X)=\sum_{i=1}^n a_n X^n X ZFC R[X] R^\omega R R[X_1,...,X_n] R R[X_1,...,X_n] f:\omega^n \rightarrow R (f+g)(a,b,c)=f(a,b,c)+g(a,b,c) (f•g)(a'',b'',c'')=\sum_{a+a'=a''} f(a,b,c)•g(a',b',c') +,• (R[X_1,...,X_n],+,•)","['abstract-algebra', 'polynomials', 'definition']"
14,Quotients of topological rings,Quotients of topological rings,,"Let $\varphi\colon R\to S$ be a surjective ring homomorphism and let $R$ be a topological ring. Is there some nice characterization of the finest topology on $S$ for with both $S$ becomes a topological ring and $\varphi$ becomes continuous? If needs be, further conditions can be imposed on $R$, $S$ and/or $\varphi$. Thanks for any help!","Let $\varphi\colon R\to S$ be a surjective ring homomorphism and let $R$ be a topological ring. Is there some nice characterization of the finest topology on $S$ for with both $S$ becomes a topological ring and $\varphi$ becomes continuous? If needs be, further conditions can be imposed on $R$, $S$ and/or $\varphi$. Thanks for any help!",,"['abstract-algebra', 'general-topology', 'functional-analysis', 'ring-theory', 'topological-rings']"
15,Algebraic proof of Ehrhart's theorem,Algebraic proof of Ehrhart's theorem,,"Let $P \subset \mathbb{R}^d$ be a $d$-dimensional polytope, where all vertices lie on integral coordinates, and let $L(P,n)$ denote the number of integral lattice points contained in the scaled polytope $n \cdot P$, i.e. $L(P,n) := \# ((n \cdot P) \cap \mathbb{Z}^d)$. Then we know by a theorem of Ehrhart: The generating function $E(P,t) := \sum_{n=0}^\infty L(P,n) \cdot t^n$ is a rational function of the form $E(P,t) = \frac{h(t)}{(1-t)^{d+1}}$, where $h$ is a polynomial with $h(1) \neq 0$. $L(P,n)$ is a polynomial in $n$ for all positive integers. I wonder if these results can also be obtained by the following algebraic approach: Let $k$ be an arbitrary field and $M := \text{Cone}(P \times \{1\}) \cap \mathbb{Z}^{d+1}$ considered as submonoid of $\mathbb{R}^{d+1}$. Then the Noetherian monoid algebra $k[M]$ is $\mathbb{Z}$-graded with respect to the $(d+1)$-th coordinate, and the corresponding Hilbert series of $k[M]$ coincides with $E(P,t)$. By the Hilbert-Serre theorem this series is a rational function of the form $E(P,t) = \frac{f(t)}{\prod_i 1-t^{e_i}}$. It is also clear that if we can show that all $e_i$ can be chosen to be $1$, it follows that $L(P,n)$ is a polynomial function for all sufficiently large $n$. Is there an elegant way to proceed with this approach to get the same results as above?","Let $P \subset \mathbb{R}^d$ be a $d$-dimensional polytope, where all vertices lie on integral coordinates, and let $L(P,n)$ denote the number of integral lattice points contained in the scaled polytope $n \cdot P$, i.e. $L(P,n) := \# ((n \cdot P) \cap \mathbb{Z}^d)$. Then we know by a theorem of Ehrhart: The generating function $E(P,t) := \sum_{n=0}^\infty L(P,n) \cdot t^n$ is a rational function of the form $E(P,t) = \frac{h(t)}{(1-t)^{d+1}}$, where $h$ is a polynomial with $h(1) \neq 0$. $L(P,n)$ is a polynomial in $n$ for all positive integers. I wonder if these results can also be obtained by the following algebraic approach: Let $k$ be an arbitrary field and $M := \text{Cone}(P \times \{1\}) \cap \mathbb{Z}^{d+1}$ considered as submonoid of $\mathbb{R}^{d+1}$. Then the Noetherian monoid algebra $k[M]$ is $\mathbb{Z}$-graded with respect to the $(d+1)$-th coordinate, and the corresponding Hilbert series of $k[M]$ coincides with $E(P,t)$. By the Hilbert-Serre theorem this series is a rational function of the form $E(P,t) = \frac{f(t)}{\prod_i 1-t^{e_i}}$. It is also clear that if we can show that all $e_i$ can be chosen to be $1$, it follows that $L(P,n)$ is a polynomial function for all sufficiently large $n$. Is there an elegant way to proceed with this approach to get the same results as above?",,"['abstract-algebra', 'geometry', 'commutative-algebra', 'integer-lattices', 'discrete-geometry']"
16,"Show that if the prime $p$ divides $|G|$, then $|X|$ is divisible by $p$.","Show that if the prime  divides , then  is divisible by .",p |G| |X| p,Question : Let $p$ be a prime number that divides the order of the finite group $G$. Let $X$ = $\bigcup_{P \in Syl_p(G)}P$. Show that $|X|$ is divisible by $p$.,Question : Let $p$ be a prime number that divides the order of the finite group $G$. Let $X$ = $\bigcup_{P \in Syl_p(G)}P$. Show that $|X|$ is divisible by $p$.,,"['abstract-algebra', 'group-theory', 'finite-groups', 'sylow-theory']"
17,Image of the Brauer group under a field extension,Image of the Brauer group under a field extension,,"For $k$ a field, let $Br(k)$ - the Brauer group of $k$ - denote the group of finite-dimensional central simple algebras over $k$, modulo Morita equivalence $(A\equiv B\iff \exists m, n(A\otimes_k M_n(k)\cong B\otimes_k M_m(k))$, with the group operation given by the tensor product $\otimes_k$. Given a Galois field extension $k\subset K$, we get a natural map $Br(k)\rightarrow Br(K)$. The kernel of this map, $Br(K\vert k)$, is just the subgroup of $Br(k)$ of algebras which split over $K$; this is a pretty snappy description. My question is: Is there an equally snappy description of the image of $Br(k)$ in $Br(K)$? (I'm asking this here, as opposed to MO, since I suspect the answer is pretty simple and I just haven't run across it.) I've tagged this question with the ""algebraic geometry"" and ""group theory"" tags; I'm not sure they are appropriate, though, so feel free to delete/replace them.","For $k$ a field, let $Br(k)$ - the Brauer group of $k$ - denote the group of finite-dimensional central simple algebras over $k$, modulo Morita equivalence $(A\equiv B\iff \exists m, n(A\otimes_k M_n(k)\cong B\otimes_k M_m(k))$, with the group operation given by the tensor product $\otimes_k$. Given a Galois field extension $k\subset K$, we get a natural map $Br(k)\rightarrow Br(K)$. The kernel of this map, $Br(K\vert k)$, is just the subgroup of $Br(k)$ of algebras which split over $K$; this is a pretty snappy description. My question is: Is there an equally snappy description of the image of $Br(k)$ in $Br(K)$? (I'm asking this here, as opposed to MO, since I suspect the answer is pretty simple and I just haven't run across it.) I've tagged this question with the ""algebraic geometry"" and ""group theory"" tags; I'm not sure they are appropriate, though, so feel free to delete/replace them.",,"['abstract-algebra', 'group-theory', 'algebraic-geometry', 'galois-theory', 'homology-cohomology']"
18,There are no maximal $\mathbb{Z}$-submodules in $\mathbb{Q}$,There are no maximal -submodules in,\mathbb{Z} \mathbb{Q},Is it true that $\mathbb{Q}$ viewed as  $\mathbb{Z}$-module (i.e. abelian group) has no maximal $\mathbb{Z}$-submodules? Why ?,Is it true that $\mathbb{Q}$ viewed as  $\mathbb{Z}$-module (i.e. abelian group) has no maximal $\mathbb{Z}$-submodules? Why ?,,"['abstract-algebra', 'group-theory', 'modules', 'abelian-groups']"
19,"Subfields of $\mathbb{Q}(\sqrt{2},\sqrt{3})$",Subfields of,"\mathbb{Q}(\sqrt{2},\sqrt{3})","Suppose one doesn't know any Galois theory, but they are familiar with the basic theory of field extensions. Then how would one justify the following picture? I'm pretty sure they're just saying these are the known subfields, and there could be more but they just write down those ones (which seems weird, which is why I'm asking). Or have they deduced that this is a comprehensive list of subfields just by using basic theory? This occurs on page 573 of Dummit and Foote's Abstract Algebra .","Suppose one doesn't know any Galois theory, but they are familiar with the basic theory of field extensions. Then how would one justify the following picture? I'm pretty sure they're just saying these are the known subfields, and there could be more but they just write down those ones (which seems weird, which is why I'm asking). Or have they deduced that this is a comprehensive list of subfields just by using basic theory? This occurs on page 573 of Dummit and Foote's Abstract Algebra .",,"['abstract-algebra', 'field-theory']"
20,Maximal ideal not containing the set of powers of an element is prime,Maximal ideal not containing the set of powers of an element is prime,,"In the midst of attempting to prove that for a commutative ring $A$ with identity, and an ideal $I$ of $A$, $I = \operatorname{rad}(I)$, where $\operatorname{rad}(I) = \{x: x^m \in I, m >0\}$, implies that $I$ is an intersection of prime ideals, I've run into a little bit of confusion. An answer to another question on this site, this one to be exact , indicates a strategy that I am attempting to use. I know that if $x$ is an element of $A\setminus I$, then so too is $x^m$ for any positive integer $m$. I use this fact to consider a subset $X = \{x^m : m > 0\}$, which is closed under multiplication, and use Zorn's lemma to find an ideal of $A$ containing $I$ maximal with respect to the constraint that said ideal, $J$, is disjoint from X. I want to prove $J$ is prime by contradiction. I suppose that $J$ were not prime; this also means that $J$ is not maximal in $A$. Then there would exist two elements, $f$ and $g$, of $A$ so that $fg$ is in $J$, but neither $f$ nor $g$ is in $J$. Following the prompting of the aforementioned answer, I know that $J + \langle a\rangle$ and $J + \langle b\rangle$ would be ideals strictly containing $J$, and since J is the maximal ideal disjoint from $X$, both $J +  \langle a\rangle$ and $J + \langle b\rangle$ contain at least some elements of $X$ (I am tempted to say all of them, but I'm not entirely sure that's true, in case for example $\langle a\rangle$ started containing powers of $x$ at $x^2$, in which case it isn't necessarily true that $\langle a\rangle$ contains $x$ itself), and so both $\langle a\rangle$ and $\langle b\rangle$ must themselves contain elements of $X$. And this is where I am stuck. I feel like there is something I should know about multiplicative subsets of rings that would help me arrive at the desired contradiction, but I can't remember what it might be.","In the midst of attempting to prove that for a commutative ring $A$ with identity, and an ideal $I$ of $A$, $I = \operatorname{rad}(I)$, where $\operatorname{rad}(I) = \{x: x^m \in I, m >0\}$, implies that $I$ is an intersection of prime ideals, I've run into a little bit of confusion. An answer to another question on this site, this one to be exact , indicates a strategy that I am attempting to use. I know that if $x$ is an element of $A\setminus I$, then so too is $x^m$ for any positive integer $m$. I use this fact to consider a subset $X = \{x^m : m > 0\}$, which is closed under multiplication, and use Zorn's lemma to find an ideal of $A$ containing $I$ maximal with respect to the constraint that said ideal, $J$, is disjoint from X. I want to prove $J$ is prime by contradiction. I suppose that $J$ were not prime; this also means that $J$ is not maximal in $A$. Then there would exist two elements, $f$ and $g$, of $A$ so that $fg$ is in $J$, but neither $f$ nor $g$ is in $J$. Following the prompting of the aforementioned answer, I know that $J + \langle a\rangle$ and $J + \langle b\rangle$ would be ideals strictly containing $J$, and since J is the maximal ideal disjoint from $X$, both $J +  \langle a\rangle$ and $J + \langle b\rangle$ contain at least some elements of $X$ (I am tempted to say all of them, but I'm not entirely sure that's true, in case for example $\langle a\rangle$ started containing powers of $x$ at $x^2$, in which case it isn't necessarily true that $\langle a\rangle$ contains $x$ itself), and so both $\langle a\rangle$ and $\langle b\rangle$ must themselves contain elements of $X$. And this is where I am stuck. I feel like there is something I should know about multiplicative subsets of rings that would help me arrive at the desired contradiction, but I can't remember what it might be.",,"['abstract-algebra', 'commutative-algebra', 'ring-theory', 'ideals']"
21,"Transcendental extension, rational functions and field tower","Transcendental extension, rational functions and field tower",,"I would like to solve this exercise (Lang, Algebra): Let $E=F(x)$ where $x$ is transcendental over $F$ . Let $K \neq F$ be a subfield of $E$ which contains $F$ . Show that $x$ is algebraic over $K$ . Let $E=F(x)$ . Let $y=f(x)/g(x)$ be a rational function, with relatively prime polynomials $f, g \in F[x]$ . Let $n= \max(\deg f, \deg g)$ . Suppose $n > 1$ . Prove that $[F(x) : F(y)]=n$ . The first point is quite simple and is solved here: For field extensions $F\subsetneq K \subset F(x)$, $x$ is algebraic over $K$ In fact, it is sufficient to consider the polynomial $$p(t):=f(t)-g(t) \frac{f(x)}{g(x)} \in K[t]$$ The second point essentially asks to prove that $p(t)$ is irreducible, but I can't see how to do that. I think that it is possible to use Bezout's lemma, but I don't know how. Thank you","I would like to solve this exercise (Lang, Algebra): Let where is transcendental over . Let be a subfield of which contains . Show that is algebraic over . Let . Let be a rational function, with relatively prime polynomials . Let . Suppose . Prove that . The first point is quite simple and is solved here: For field extensions $F\subsetneq K \subset F(x)$, $x$ is algebraic over $K$ In fact, it is sufficient to consider the polynomial The second point essentially asks to prove that is irreducible, but I can't see how to do that. I think that it is possible to use Bezout's lemma, but I don't know how. Thank you","E=F(x) x F K \neq F E F x K E=F(x) y=f(x)/g(x) f, g \in F[x] n= \max(\deg f, \deg g) n > 1 [F(x) : F(y)]=n p(t):=f(t)-g(t) \frac{f(x)}{g(x)} \in K[t] p(t)","['abstract-algebra', 'polynomials', 'extension-field', 'irreducible-polynomials']"
22,$f(X^p)$ irreducible or $p$th power if $f$ irreducible,irreducible or th power if  irreducible,f(X^p) p f,"An exercise in Bourbaki: Let $K$ be a field of characteristic $p>0$ and $f$ irreducible monic polynomial of $K[X]$. Show that in $K[X]$ the polynomial $f(X^p)$ is either irreducible or the $p$th power of an irreducible polynomial, depending of whether or not there exists a coefficient of $f$ not belonging to $K^p$. The given suggestion is to decompose $f(X^p)$ in linear factors in an algebraic closure of K. Thus far I have done this: I take $\theta$ to be a root of $f(X^p)$. By considering the subextions $K(\theta ^p)/K$ of $K(\theta)/K$, we see that $f$ is irreducible iff  the degree of $K(\theta ^p)/K(\theta)$ is $p$ to $K(\theta^p)$, iff $K(\theta)=K(\theta^p)$.","An exercise in Bourbaki: Let $K$ be a field of characteristic $p>0$ and $f$ irreducible monic polynomial of $K[X]$. Show that in $K[X]$ the polynomial $f(X^p)$ is either irreducible or the $p$th power of an irreducible polynomial, depending of whether or not there exists a coefficient of $f$ not belonging to $K^p$. The given suggestion is to decompose $f(X^p)$ in linear factors in an algebraic closure of K. Thus far I have done this: I take $\theta$ to be a root of $f(X^p)$. By considering the subextions $K(\theta ^p)/K$ of $K(\theta)/K$, we see that $f$ is irreducible iff  the degree of $K(\theta ^p)/K(\theta)$ is $p$ to $K(\theta^p)$, iff $K(\theta)=K(\theta^p)$.",,"['abstract-algebra', 'polynomials', 'field-theory', 'irreducible-polynomials']"
23,Finite generation of Tate cohomology groups,Finite generation of Tate cohomology groups,,"Let $G$ be a finite group, and let $F$ be a complete resolution for $G$.  In other words, $F$ is an acyclic chain complex of projective $\mathbb{Z}G$-modules together with a map $\varepsilon:F_0\to\mathbb{Z}$ such that $\varepsilon:F_+\to\mathbb{Z}$ is a projective resolution of $\mathbb{Z}$ over $\mathbb{Z}G$. It can be shown that we may construct a complete resolution for $G$ in such a way that each $F_n$ is finitely generated.  Such a resolution is said to be of finite type. If $M$ is a $\mathbb{Z}G$-module, we can define the Tate cohomology groups of $G$ with coefficients in $M$ as follows: $$\hat{H}\,^n(G,M):=H^n(\mathrm{Hom}_G(F,M))$$ This definition is independent of choice of resolution $F$ because any two choices are homotopy equivalent. Now, let $M=\mathbb{Z}$ be the trivial $\mathbb{Z}G$-module.  Using what I've written down, I'd like to see why $\hat{H}\,^n(G,\mathbb{Z})$ is a finitely generated abelian group for all $n$.  I know that in this case $\mathrm{Hom}_G(F_n,\mathbb{Z})\cong F_n^G$ is the group of invariants of $F_n$, so that we are considering the abelian groups $H^n(F^G)$, but how do we show that they are finitely generated?","Let $G$ be a finite group, and let $F$ be a complete resolution for $G$.  In other words, $F$ is an acyclic chain complex of projective $\mathbb{Z}G$-modules together with a map $\varepsilon:F_0\to\mathbb{Z}$ such that $\varepsilon:F_+\to\mathbb{Z}$ is a projective resolution of $\mathbb{Z}$ over $\mathbb{Z}G$. It can be shown that we may construct a complete resolution for $G$ in such a way that each $F_n$ is finitely generated.  Such a resolution is said to be of finite type. If $M$ is a $\mathbb{Z}G$-module, we can define the Tate cohomology groups of $G$ with coefficients in $M$ as follows: $$\hat{H}\,^n(G,M):=H^n(\mathrm{Hom}_G(F,M))$$ This definition is independent of choice of resolution $F$ because any two choices are homotopy equivalent. Now, let $M=\mathbb{Z}$ be the trivial $\mathbb{Z}G$-module.  Using what I've written down, I'd like to see why $\hat{H}\,^n(G,\mathbb{Z})$ is a finitely generated abelian group for all $n$.  I know that in this case $\mathrm{Hom}_G(F_n,\mathbb{Z})\cong F_n^G$ is the group of invariants of $F_n$, so that we are considering the abelian groups $H^n(F^G)$, but how do we show that they are finitely generated?",,"['abstract-algebra', 'group-theory', 'finite-groups', 'homology-cohomology', 'group-cohomology']"
24,When a group is cyclic,When a group is cyclic,,"If $G$ is a finite group and has at most one subgroup of an arbitrary order (of course, dividing order of $G$) could we deduce that $G$ is cyclic ?","If $G$ is a finite group and has at most one subgroup of an arbitrary order (of course, dividing order of $G$) could we deduce that $G$ is cyclic ?",,"['abstract-algebra', 'group-theory', 'cyclic-groups']"
25,"Computing the action of $S_3$ on $H^n(\mathbb{Z}_3,\mathbb{Z})$",Computing the action of  on,"S_3 H^n(\mathbb{Z}_3,\mathbb{Z})","Let $G=S_3$ and let $H$ be the Sylow $3$-subgroup in $G$.  If $\mathbb{Z}$ is the trivial module, then it can be shown that $$H^n(H,\mathbb{Z})=\begin{cases}\mathbb{Z}&n=0\\0&n\text{ odd}\\\mathbb{Z}_3&n\text{ even}\end{cases}$$ Since $H$ is normal in $G$, $G$ acts on $H^n(H,\mathbb{Z})$ as follows.  Let $g\in G$ and define $c_g:H\to H$ by $c_g(h)=ghg^{-1}$.  Since $H^*(-,M)$ is contravariant, we obtain an isomorphism $c_g^*:H^n(H,\mathbb{Z})\to H^n(H,\mathbb{Z})$.  Then, for $z\in H^n(H,\mathbb{Z})$, define $g\cdot z=(c_g^*)^{-1}(z)$. There is another way to define this action on cochains.  If $F\to\mathbb{Z}$ is a projective resolution over $\mathbb{Z}G$, and $f\in\operatorname{Hom}_H(F,\mathbb{Z})$, then the $G$ action on cohomology is induced by the action $(g\cdot f)(x)=gf(g^{-1}x)=f(g^{-1}x)$ (notice that the action on $\mathbb{Z}$ is trivial). I'm trying to compute explicitly the action of $G$ on $H^n(H,\mathbb{Z})$. This question addresses my ultimate goal, which is to compute the integral cohomology of $G$, but the answer given skips over what I've asked here (it answers my question referencing some mysterious exercise AE.9, which I cannot find in Brown). Can someone show me how $G$ acts on $H^n(H,\mathbb{Z})$, using either (or both) of the definitions given above?","Let $G=S_3$ and let $H$ be the Sylow $3$-subgroup in $G$.  If $\mathbb{Z}$ is the trivial module, then it can be shown that $$H^n(H,\mathbb{Z})=\begin{cases}\mathbb{Z}&n=0\\0&n\text{ odd}\\\mathbb{Z}_3&n\text{ even}\end{cases}$$ Since $H$ is normal in $G$, $G$ acts on $H^n(H,\mathbb{Z})$ as follows.  Let $g\in G$ and define $c_g:H\to H$ by $c_g(h)=ghg^{-1}$.  Since $H^*(-,M)$ is contravariant, we obtain an isomorphism $c_g^*:H^n(H,\mathbb{Z})\to H^n(H,\mathbb{Z})$.  Then, for $z\in H^n(H,\mathbb{Z})$, define $g\cdot z=(c_g^*)^{-1}(z)$. There is another way to define this action on cochains.  If $F\to\mathbb{Z}$ is a projective resolution over $\mathbb{Z}G$, and $f\in\operatorname{Hom}_H(F,\mathbb{Z})$, then the $G$ action on cohomology is induced by the action $(g\cdot f)(x)=gf(g^{-1}x)=f(g^{-1}x)$ (notice that the action on $\mathbb{Z}$ is trivial). I'm trying to compute explicitly the action of $G$ on $H^n(H,\mathbb{Z})$. This question addresses my ultimate goal, which is to compute the integral cohomology of $G$, but the answer given skips over what I've asked here (it answers my question referencing some mysterious exercise AE.9, which I cannot find in Brown). Can someone show me how $G$ acts on $H^n(H,\mathbb{Z})$, using either (or both) of the definitions given above?",,"['abstract-algebra', 'group-theory', 'homological-algebra', 'homology-cohomology', 'group-cohomology']"
26,What is the definition of 'span' in a module?,What is the definition of 'span' in a module?,,"$\newcommand{\supp}{\operatorname{supp}} \newcommand{\span}{\operatorname{span}}$Let $M$ be a module over a ring $R$ and $S\subset M$ Define $\mathscr{A} = \bigcap\{N\subset M: N \text{ is a submodule of } M , S\subset N\}$ Define $\mathscr{B} = \{\sum_{i\in\text{supp}(f)} f(i)i : f\in R^S , \supp(f) \text{ is finite } \}$. Here, if $R$ has a unity, then these two sets are the same. However, if $R$ does not contain a unity, then these two sets may not be the same. Which one should i use for the definition of $\span (S)$? Moreover, i don't know where a concept of module is useful when $R$ has no unity.. Should I just assume that $R$ has a unity?","$\newcommand{\supp}{\operatorname{supp}} \newcommand{\span}{\operatorname{span}}$Let $M$ be a module over a ring $R$ and $S\subset M$ Define $\mathscr{A} = \bigcap\{N\subset M: N \text{ is a submodule of } M , S\subset N\}$ Define $\mathscr{B} = \{\sum_{i\in\text{supp}(f)} f(i)i : f\in R^S , \supp(f) \text{ is finite } \}$. Here, if $R$ has a unity, then these two sets are the same. However, if $R$ does not contain a unity, then these two sets may not be the same. Which one should i use for the definition of $\span (S)$? Moreover, i don't know where a concept of module is useful when $R$ has no unity.. Should I just assume that $R$ has a unity?",,"['abstract-algebra', 'modules', 'rngs']"
27,A submodule of a free module is torsion-free?,A submodule of a free module is torsion-free?,,"I am studying for a comprehensive exam and looking at a large bank of problems.  One problem has six statements about module and asks for a a proof or a counter-example of the statements.  I am able to solve all except two related to torsion .  Assume that $R$ is an integral domain and the modules below are $R$ -modules.  So an element $m \in M$ is torsion if there is an $r \in R-0$ s.t. $rm=0$ . A submodule of a free module is torsion-free. A submodule of a torsion module is a torsion module. For #1, I know that a submodule of a free module is not necessarily free and I know that a free module is torsion-free but I can't put these to use to find a counterexample.  For #2, this seems logical but again I am unable to provide a proof.  By the way, to be clear a torsion module has only torsion elements. Thanks!","I am studying for a comprehensive exam and looking at a large bank of problems.  One problem has six statements about module and asks for a a proof or a counter-example of the statements.  I am able to solve all except two related to torsion .  Assume that is an integral domain and the modules below are -modules.  So an element is torsion if there is an s.t. . A submodule of a free module is torsion-free. A submodule of a torsion module is a torsion module. For #1, I know that a submodule of a free module is not necessarily free and I know that a free module is torsion-free but I can't put these to use to find a counterexample.  For #2, this seems logical but again I am unable to provide a proof.  By the way, to be clear a torsion module has only torsion elements. Thanks!",R R m \in M r \in R-0 rm=0,"['abstract-algebra', 'modules']"
28,Understanding the right-exactness of the tensor product using *only* its universal property and the Yoneda lemma,Understanding the right-exactness of the tensor product using *only* its universal property and the Yoneda lemma,,"I would like to get an intuition for why $(-)\otimes N$ is right-exact using its universal property involving bilinear maps, not by appealing to higher-level observations such as ""left-adjoints preserve colimits"". The argument below is the best I could do towards this goal, but clearly it is in need of rigorization (if indeed something along these lines is correct). I have indicated two spots in the argument below that I would like to ask for detailed explanations of how to rigorize and/or fix. This is an attempt to re-ask an earlier question of mine , which apparently was easy to misinterpret. Basic idea: Let $\mathcal{C}$ be a category. For any object $X$ of $\mathcal{C}$, let $h^X:\mathcal{C}\to\mathsf{Set}$ be the covariant hom functor:   $$h^X(Y):=\mathrm{Mor}_{\mathcal{C}}(X,Y),\qquad h^X\left(Y\xrightarrow{\;f\;}Z\right)=\mathrm{Mor}_{\mathcal{C}}(X,Y)\xrightarrow{\;f\,\circ\, -\;}\mathrm{Mor}_{\mathcal{C}}(X,Z)$$   The Yoneda lemma implies that a natural transformation $\gamma:h^X\Rightarrow h^W$ must come from a morphism $g:W\to X$; that is, we must have that $\gamma_Y(k)=k\circ g$ for some such $g$. If $\gamma_Y$ is injective for all objects $Y$ of $\mathcal{C}$, the corresponding $g$ is an epimorphism (by definition). Let $A$ be a ring, and fix an $A$-module $N$. If an $A$-module map $\psi:M_1\to M_2$ is surjective, then $(\psi,\mathrm{id}_N):M_1\times N\to M_2\times N$ is surjective, so that for all $A$-modules $P$, the map $$\mathrm{Hom}(M_2\otimes N,P)\underset{\text{natural}}{\cong}\mathrm{Bilin}(M_2,N;P)\xrightarrow{-\circ(\psi,\mathrm{id}_N)}\mathrm{Bilin}(M_1,N;P)\underset{\text{natural}}{\cong}\mathrm{Hom}(M_1\otimes N,P)$$ is injective. Therefore (?) the induced map $M_1\otimes_AN\to M_2\otimes_AN$ is an epimorphism, which is equivalent to being a surjection for $A$-modules. A short exact sequence $$M_1\xrightarrow{\;\psi\;}M_2\xrightarrow{\;\rho\;} M_3\longrightarrow 0$$ is equivalent to having a surjective map $\rho:M_2\to M_3$ and a surjective map $\psi:M_1\to\ker(\rho)$. Because the functor $(-)\otimes_AN$ ""preserves surjectivity"", it must therefore (?) be right-exact.","I would like to get an intuition for why $(-)\otimes N$ is right-exact using its universal property involving bilinear maps, not by appealing to higher-level observations such as ""left-adjoints preserve colimits"". The argument below is the best I could do towards this goal, but clearly it is in need of rigorization (if indeed something along these lines is correct). I have indicated two spots in the argument below that I would like to ask for detailed explanations of how to rigorize and/or fix. This is an attempt to re-ask an earlier question of mine , which apparently was easy to misinterpret. Basic idea: Let $\mathcal{C}$ be a category. For any object $X$ of $\mathcal{C}$, let $h^X:\mathcal{C}\to\mathsf{Set}$ be the covariant hom functor:   $$h^X(Y):=\mathrm{Mor}_{\mathcal{C}}(X,Y),\qquad h^X\left(Y\xrightarrow{\;f\;}Z\right)=\mathrm{Mor}_{\mathcal{C}}(X,Y)\xrightarrow{\;f\,\circ\, -\;}\mathrm{Mor}_{\mathcal{C}}(X,Z)$$   The Yoneda lemma implies that a natural transformation $\gamma:h^X\Rightarrow h^W$ must come from a morphism $g:W\to X$; that is, we must have that $\gamma_Y(k)=k\circ g$ for some such $g$. If $\gamma_Y$ is injective for all objects $Y$ of $\mathcal{C}$, the corresponding $g$ is an epimorphism (by definition). Let $A$ be a ring, and fix an $A$-module $N$. If an $A$-module map $\psi:M_1\to M_2$ is surjective, then $(\psi,\mathrm{id}_N):M_1\times N\to M_2\times N$ is surjective, so that for all $A$-modules $P$, the map $$\mathrm{Hom}(M_2\otimes N,P)\underset{\text{natural}}{\cong}\mathrm{Bilin}(M_2,N;P)\xrightarrow{-\circ(\psi,\mathrm{id}_N)}\mathrm{Bilin}(M_1,N;P)\underset{\text{natural}}{\cong}\mathrm{Hom}(M_1\otimes N,P)$$ is injective. Therefore (?) the induced map $M_1\otimes_AN\to M_2\otimes_AN$ is an epimorphism, which is equivalent to being a surjection for $A$-modules. A short exact sequence $$M_1\xrightarrow{\;\psi\;}M_2\xrightarrow{\;\rho\;} M_3\longrightarrow 0$$ is equivalent to having a surjective map $\rho:M_2\to M_3$ and a surjective map $\psi:M_1\to\ker(\rho)$. Because the functor $(-)\otimes_AN$ ""preserves surjectivity"", it must therefore (?) be right-exact.",,"['abstract-algebra', 'commutative-algebra', 'category-theory', 'tensor-products', 'exact-sequence']"
29,Permutations that preserve all algebraic relations between the roots of a polynomial,Permutations that preserve all algebraic relations between the roots of a polynomial,,"When trying to answer the question of whether a given equation can be solved with radicals, historically people have paid lots of attention to permutations that preserve all algebraic relations between the roots of the polynomial. The idea finally led to the solution of the problem by Galois, but the idea of looking at such permutations pre-dates him. Is there any nice simple explanation of why such permutations are related with solve-ability of polynomial equations with radicals? (An explanation that doesn't directly involve the Galois group).","When trying to answer the question of whether a given equation can be solved with radicals, historically people have paid lots of attention to permutations that preserve all algebraic relations between the roots of the polynomial. The idea finally led to the solution of the problem by Galois, but the idea of looking at such permutations pre-dates him. Is there any nice simple explanation of why such permutations are related with solve-ability of polynomial equations with radicals? (An explanation that doesn't directly involve the Galois group).",,"['abstract-algebra', 'reference-request', 'math-history']"
30,"If $\gcd(f(x), g(x))\ne1$, then $F[x]/(fg)$ is not isomorphic to $F[x]/(f)\times F[x]/(g)$","If , then  is not isomorphic to","\gcd(f(x), g(x))\ne1 F[x]/(fg) F[x]/(f)\times F[x]/(g)","So I thought up this question as an extension to the corresponding one for $Z_m$, $Z_n$, $(m, n)\ne1$. The problems is I am unable to prove it, or disprove it. I try, but I keep getting tripped up since an isomorphism doesn't necessarily have to be the identity when restricted to $F$. I managed to prove it for all finite fields and fields generated by their identity (my 'proof' is far to long to put here though). Can anyone shine some light on the general case? I would really appreciate it. The converse is clearly true, but the problem is that there is no clear way to extend the proof since 1 doesn't generate the arbitrary field.","So I thought up this question as an extension to the corresponding one for $Z_m$, $Z_n$, $(m, n)\ne1$. The problems is I am unable to prove it, or disprove it. I try, but I keep getting tripped up since an isomorphism doesn't necessarily have to be the identity when restricted to $F$. I managed to prove it for all finite fields and fields generated by their identity (my 'proof' is far to long to put here though). Can anyone shine some light on the general case? I would really appreciate it. The converse is clearly true, but the problem is that there is no clear way to extend the proof since 1 doesn't generate the arbitrary field.",,"['abstract-algebra', 'polynomials', 'ring-theory']"
31,Question about order of elements of a subgroup,Question about order of elements of a subgroup,,"Given a subgroup $H \subset \mathbb{Z}^4$, defined as the 4-tuples $(a,b,c,d)$ that satisfy $$ 8| (a-c); a+2b+3c+4d=0$$ The question is: give all orders of the elements of $\mathbb{Z}^4 /H$. I don't have any idea how to start with this problem. Can anybody give some hints, strategies etc to solve this one? thanks","Given a subgroup $H \subset \mathbb{Z}^4$, defined as the 4-tuples $(a,b,c,d)$ that satisfy $$ 8| (a-c); a+2b+3c+4d=0$$ The question is: give all orders of the elements of $\mathbb{Z}^4 /H$. I don't have any idea how to start with this problem. Can anybody give some hints, strategies etc to solve this one? thanks",,"['abstract-algebra', 'group-theory']"
32,"If $f\colon G\to H$ is a surjective homomorphism, then $|C_G(g)| \geq |C_H(f(g))|$","If  is a surjective homomorphism, then",f\colon G\to H |C_G(g)| \geq |C_H(f(g))|,"Let $G$ be finite, $f\colon G\to H$  be a surjective homomorphism (hence $H$ is finite) and $g \in G$. Prove the order of center of $g$ in $G$ is greater than or equal to the order of the center of $f(g)$ in $H$, i.e. $$|C_G(g)| \ge |C_H(f(g))|.$$ Attempts at solution. If $f$ is an isomorphism this is clear. So if $\ker f=K$ we can consider $G \to G/K \xrightarrow{f'} H$, where $f'$ is the induced map. So we can reduce this problem to the case where $f$ is a projection map. Also if $f(x)f(g) = f(g)f(x)$ then $f(x^{-1}g^{-1}xg) = e$. So if $h = f(y)$, $h \in C_H(f(g))$ iff $[h,g] \in K$. The center of $g$ is the set of fixed points of the conjugation map (by $g$). And the center of $h$ is the set of fixed points under conjugation by $h$. So maybe this can be done by considering how the orbits collapse mod a normal subgroup?","Let $G$ be finite, $f\colon G\to H$  be a surjective homomorphism (hence $H$ is finite) and $g \in G$. Prove the order of center of $g$ in $G$ is greater than or equal to the order of the center of $f(g)$ in $H$, i.e. $$|C_G(g)| \ge |C_H(f(g))|.$$ Attempts at solution. If $f$ is an isomorphism this is clear. So if $\ker f=K$ we can consider $G \to G/K \xrightarrow{f'} H$, where $f'$ is the induced map. So we can reduce this problem to the case where $f$ is a projection map. Also if $f(x)f(g) = f(g)f(x)$ then $f(x^{-1}g^{-1}xg) = e$. So if $h = f(y)$, $h \in C_H(f(g))$ iff $[h,g] \in K$. The center of $g$ is the set of fixed points of the conjugation map (by $g$). And the center of $h$ is the set of fixed points under conjugation by $h$. So maybe this can be done by considering how the orbits collapse mod a normal subgroup?",,"['abstract-algebra', 'group-theory', 'finite-groups']"
33,What are the ring morphisms $\mathbb{Q}[[X]]\to R$ for a ring $R$?,What are the ring morphisms  for a ring ?,\mathbb{Q}[[X]]\to R R,"If $\mathbb{Q}[[X]]$ is the ring of power series over a field $F$, then can we describe ring morphisms $\mathbb{Q}[[X]] \to R$ for rings $R$ in simple terms? I am guessing that a ""substitution principle"" wouldn't make sense for series unless $R$ has a notion of convergence of series.","If $\mathbb{Q}[[X]]$ is the ring of power series over a field $F$, then can we describe ring morphisms $\mathbb{Q}[[X]] \to R$ for rings $R$ in simple terms? I am guessing that a ""substitution principle"" wouldn't make sense for series unless $R$ has a notion of convergence of series.",,"['abstract-algebra', 'ring-theory']"
34,"Main use of tensor, symmetric and exterior algebras outside differential geometry?","Main use of tensor, symmetric and exterior algebras outside differential geometry?",,"So I've seen these defined when constructing differential forms and in the construction of integration of manifolds. However, these seem to be a standard subject in most graduate algebra books, yet, I've never seen them applied anywhere else than in differential geometry. My question is: What use do these have as abstract objects? What information do they convey?","So I've seen these defined when constructing differential forms and in the construction of integration of manifolds. However, these seem to be a standard subject in most graduate algebra books, yet, I've never seen them applied anywhere else than in differential geometry. My question is: What use do these have as abstract objects? What information do they convey?",,['abstract-algebra']
35,Where can I find the original papers by Frobenius concerning solutions to $x^n = 1$ in a finite group?,Where can I find the original papers by Frobenius concerning solutions to  in a finite group?,x^n = 1,"A theorem proven by Frobenius states that If $n$ divides the order of a finite group $G$, then the number of solutions to $x^n = 1$ in $G$ is a multiple of $n$. Articles discussing this theorem say that this result was proven by Frobenius in 1895, a precise reference given is F. G. Frobenius, Verallgemeinerung des Sylow'schen Satzes , Sitzungsberichte der Königl. Preuß. Akad. der Wissenschaften (Berlin) (1895), 981-993 I am currently studying this theorem and its generalizations, and I would be interested in reading the original paper by Frobenius. However, I haven't been able to find a copy of it anywhere. Does anyone know where I could find it (preferably online)? If the paper cannot be found, I would like to know what the original proof of Frobenius was like. The usual double induction proof can be found in Burnside's Theory of Finite Groups (1897), I guess the proof there might be very similar to the original proof of Frobenius. The same proof is also given in the book Theory and Applications of Finite Groups by G. A. Miller, H. F. Blichfeldt and L. E. Dickson (1916). Also, according to Finkelstein [*], Frobenius discusses the theorem and its generalizations in the following papers: F. G. Frobenius, Über auflösbare Gruppen , Sitzungberichte der Königl. Preuß. Akad. Wissenschaften (Berlin) (1893), 337-345. F. G. Frobenius, Über endliche Gruppen ,Sitzungsberichte der Königl. Preuß. Akad. der Wissenschaften (Berlin) (1895), 81-112. F. G. Frobenius, Verallgemeinerung des Sylow'schen Satzes ,Sitzungsberichte der Königl. Preuß. Akad. der Wissenschaften (Berlin) (1895), 981-993. F. G. Frobenius, Über auflösbare Gruppen II ,Sitzungsberichte der Königl. Preuß. Akad. der Wissenschaften (Berlin) (1895), 1027-1044. F. G. Frobenius, Über auflösbare Gruppen III ,Sitzungsberichte der Königl. Preuß. Akad. der Wissenschaften (Berlin) (1901), 849-875. F. G. Frobenius, Über einen Fundamentalsatz der Gruppentheorie , Sitzungsberichte der Königl. Preuß. Akad. der Wissenschaften (Berlin) (1903), 987-991. F. G. Frobenius, Über einen Fundamentalsatz der Gruppentheorie II ,Sitzungsberichte der Königl. Preuß. Akad. der Wissenschaften (Berlin) (1907), 428-437. Any idea where these could be found? Again, I haven't been able to find a copy of any of these papers and I'm not sure if they have been published anywhere afterwards. [*] H. Finkelstein, Solving equations in groups: A survey of Frobenius' theorem Periodica Mathematica Hungarica Volume 9, Issue 3, pp 187-204, (1978).","A theorem proven by Frobenius states that If $n$ divides the order of a finite group $G$, then the number of solutions to $x^n = 1$ in $G$ is a multiple of $n$. Articles discussing this theorem say that this result was proven by Frobenius in 1895, a precise reference given is F. G. Frobenius, Verallgemeinerung des Sylow'schen Satzes , Sitzungsberichte der Königl. Preuß. Akad. der Wissenschaften (Berlin) (1895), 981-993 I am currently studying this theorem and its generalizations, and I would be interested in reading the original paper by Frobenius. However, I haven't been able to find a copy of it anywhere. Does anyone know where I could find it (preferably online)? If the paper cannot be found, I would like to know what the original proof of Frobenius was like. The usual double induction proof can be found in Burnside's Theory of Finite Groups (1897), I guess the proof there might be very similar to the original proof of Frobenius. The same proof is also given in the book Theory and Applications of Finite Groups by G. A. Miller, H. F. Blichfeldt and L. E. Dickson (1916). Also, according to Finkelstein [*], Frobenius discusses the theorem and its generalizations in the following papers: F. G. Frobenius, Über auflösbare Gruppen , Sitzungberichte der Königl. Preuß. Akad. Wissenschaften (Berlin) (1893), 337-345. F. G. Frobenius, Über endliche Gruppen ,Sitzungsberichte der Königl. Preuß. Akad. der Wissenschaften (Berlin) (1895), 81-112. F. G. Frobenius, Verallgemeinerung des Sylow'schen Satzes ,Sitzungsberichte der Königl. Preuß. Akad. der Wissenschaften (Berlin) (1895), 981-993. F. G. Frobenius, Über auflösbare Gruppen II ,Sitzungsberichte der Königl. Preuß. Akad. der Wissenschaften (Berlin) (1895), 1027-1044. F. G. Frobenius, Über auflösbare Gruppen III ,Sitzungsberichte der Königl. Preuß. Akad. der Wissenschaften (Berlin) (1901), 849-875. F. G. Frobenius, Über einen Fundamentalsatz der Gruppentheorie , Sitzungsberichte der Königl. Preuß. Akad. der Wissenschaften (Berlin) (1903), 987-991. F. G. Frobenius, Über einen Fundamentalsatz der Gruppentheorie II ,Sitzungsberichte der Königl. Preuß. Akad. der Wissenschaften (Berlin) (1907), 428-437. Any idea where these could be found? Again, I haven't been able to find a copy of any of these papers and I'm not sure if they have been published anywhere afterwards. [*] H. Finkelstein, Solving equations in groups: A survey of Frobenius' theorem Periodica Mathematica Hungarica Volume 9, Issue 3, pp 187-204, (1978).",,"['abstract-algebra', 'group-theory', 'reference-request', 'finite-groups']"
36,Exercise on finite intermediate extensions,Exercise on finite intermediate extensions,,"Let $E/K$ be a field extension, and let $L_1$ and $L_2$ be intermediate fields of finite degree over $K$. Prove that $[L_1L_2:K] = [L_1 : K][L_2 : K]$ implies $L_1\cap L_2 = K$. My thinking process so far: I've gotten that $K \subseteq L_1 \cap L_2$ because trivially both are intermediate fields over K. I want to show that $L_1 \cap L_2 \subseteq K$, or equivalently that any element of $L_1 \cap L_2$ is also an element of $K$. So I suppose there exists some element $x\in L_1 \cap L_2\setminus K$. Well then I know that this element is algebraic over $K$, implying that $L_1:K=[L_1:K(x)][K(x):K]$, and similarly for $L_2$, implying that that these multiplied together equal $L_1L_2:K$ by hypothesis. And now I’m stuck in the mud... not knowing exactly where the contradiction is.","Let $E/K$ be a field extension, and let $L_1$ and $L_2$ be intermediate fields of finite degree over $K$. Prove that $[L_1L_2:K] = [L_1 : K][L_2 : K]$ implies $L_1\cap L_2 = K$. My thinking process so far: I've gotten that $K \subseteq L_1 \cap L_2$ because trivially both are intermediate fields over K. I want to show that $L_1 \cap L_2 \subseteq K$, or equivalently that any element of $L_1 \cap L_2$ is also an element of $K$. So I suppose there exists some element $x\in L_1 \cap L_2\setminus K$. Well then I know that this element is algebraic over $K$, implying that $L_1:K=[L_1:K(x)][K(x):K]$, and similarly for $L_2$, implying that that these multiplied together equal $L_1L_2:K$ by hypothesis. And now I’m stuck in the mud... not knowing exactly where the contradiction is.",,"['abstract-algebra', 'field-theory']"
37,Splitting field of $x^{13}+1$ over $\mathbb{Q}$,Splitting field of  over,x^{13}+1 \mathbb{Q},"I want to know how to calculate the degree of the field extension $[K:Q]$ where $K$ is the splitting field of $x^{13}+1$ over $\mathbb{Q}$. I'm new to this area and this is not really covered in my course properly. So please don't assume I'm familiar to much when answering. Since $-1$ is a root should I conclude that all roots are $-1w^{n}$, where $w\in\mathbb{C}$ and $w^{13}=1$ or am I searching for the solutions to $x^{13}=-1 \in\mathbb{C}$, or is this just the same thing since $-1\in\mathbb{Q}$ already? How do I go about finding solutions to these equations in $\mathbb{C}$? After finding solutions how do I know which are the minimal polynomials satisfying these? A lot of questions at the same time, but I don't really have anyone else to ask. Btw this is not a school assignment! Are the roots $-w^{n}$ where $1\leq$n$\leq12$ and $w=\mathbb{e}^{\frac{2\pi}{13}i}$? And if we are searching for the $n$'th roots of unity when $n$ is composite why do we only include powers that are coprime to $n$?","I want to know how to calculate the degree of the field extension $[K:Q]$ where $K$ is the splitting field of $x^{13}+1$ over $\mathbb{Q}$. I'm new to this area and this is not really covered in my course properly. So please don't assume I'm familiar to much when answering. Since $-1$ is a root should I conclude that all roots are $-1w^{n}$, where $w\in\mathbb{C}$ and $w^{13}=1$ or am I searching for the solutions to $x^{13}=-1 \in\mathbb{C}$, or is this just the same thing since $-1\in\mathbb{Q}$ already? How do I go about finding solutions to these equations in $\mathbb{C}$? After finding solutions how do I know which are the minimal polynomials satisfying these? A lot of questions at the same time, but I don't really have anyone else to ask. Btw this is not a school assignment! Are the roots $-w^{n}$ where $1\leq$n$\leq12$ and $w=\mathbb{e}^{\frac{2\pi}{13}i}$? And if we are searching for the $n$'th roots of unity when $n$ is composite why do we only include powers that are coprime to $n$?",,"['abstract-algebra', 'field-theory']"
38,Are all groups of order 175 abelian?,Are all groups of order 175 abelian?,,"Question. Are all groups of order 175 abelian? I can show that there exists only one Sylow 5-subgroup of order 25, call it $H$ , and one Sylow 7-subgroup of order 7, denote $K$ . I know that $K$ is cyclic, and thus abelian. I know that $|H| = p^2$ , where $p=5$ is prime, and so $H$ is abelian too. I also know the $|G| = |H| \cdot |K|$ . Further, I know that $G$ happens to be the direct product of these two groups as they intersect trivially, and this completes the proof. Could somebody please explain: Why the group is the direct product, is this always so if the groups intersect trivially, and the product of the orders of subgroups matches the group order? Why the direct product is abelian. Is this always the case if the subgroups $H$ and $K$ intersect trivially, or is it because they are both abelian too? Anything else I should know? Thanks","Question. Are all groups of order 175 abelian? I can show that there exists only one Sylow 5-subgroup of order 25, call it , and one Sylow 7-subgroup of order 7, denote . I know that is cyclic, and thus abelian. I know that , where is prime, and so is abelian too. I also know the . Further, I know that happens to be the direct product of these two groups as they intersect trivially, and this completes the proof. Could somebody please explain: Why the group is the direct product, is this always so if the groups intersect trivially, and the product of the orders of subgroups matches the group order? Why the direct product is abelian. Is this always the case if the subgroups and intersect trivially, or is it because they are both abelian too? Anything else I should know? Thanks",H K K |H| = p^2 p=5 H |G| = |H| \cdot |K| G H K,"['abstract-algebra', 'group-theory', 'finite-groups']"
39,Ideals in non-associative rings and the identity $(xy)z=y(zx)$.,Ideals in non-associative rings and the identity .,(xy)z=y(zx),"I have come across this paper . The authors prove that magmas satisfying the identity $$(xy)z=y(zx)\tag1$$ are nearly both associative and commutative. To be precise, they show that in such magmas, products of at least five elements are independent of the placement of brackets and the order of elements. They call this property five-niceness . Then they say that if a non-associative ring (which means not necessarily associative) has multiplication satisfying this identity and the ring is semiprime , then it is both associative and commutative. Semiprimality means that for an ideal $I,$ we have $I^2=0\implies I=0.$ I have no experience with non-associative rings whatsoever. In particular, I have never seen a definition of an ideal in such a ring. I tried to find one on the internet but in vain. So my main question is (a) What are ideals in non-associative rings? And where can I read about them? Are they as useful in the theory of non-associative rings as ideals in associative rings? It's very difficult for me to start ""thinking non-associatively"" and I'm having trouble seeing what the problems could be. Finally, I would like to ask about the identity. I probably have little chance of receiving an answer to these questions, but there's no harm in trying. (b) Is there an example of a ring that satisfies $(1)$ , is associative, but isn't commutative? (c) Is there an example of a ring that satisfies $(1)$ , is commutative, but isn't associative? (d) Is there an example of a ring that satisfies $(1)$ , but is neither commutative nor associative? I do not require the rings to have identities.","I have come across this paper . The authors prove that magmas satisfying the identity are nearly both associative and commutative. To be precise, they show that in such magmas, products of at least five elements are independent of the placement of brackets and the order of elements. They call this property five-niceness . Then they say that if a non-associative ring (which means not necessarily associative) has multiplication satisfying this identity and the ring is semiprime , then it is both associative and commutative. Semiprimality means that for an ideal we have I have no experience with non-associative rings whatsoever. In particular, I have never seen a definition of an ideal in such a ring. I tried to find one on the internet but in vain. So my main question is (a) What are ideals in non-associative rings? And where can I read about them? Are they as useful in the theory of non-associative rings as ideals in associative rings? It's very difficult for me to start ""thinking non-associatively"" and I'm having trouble seeing what the problems could be. Finally, I would like to ask about the identity. I probably have little chance of receiving an answer to these questions, but there's no harm in trying. (b) Is there an example of a ring that satisfies , is associative, but isn't commutative? (c) Is there an example of a ring that satisfies , is commutative, but isn't associative? (d) Is there an example of a ring that satisfies , but is neither commutative nor associative? I do not require the rings to have identities.","(xy)z=y(zx)\tag1 I, I^2=0\implies I=0. (1) (1) (1)","['abstract-algebra', 'reference-request']"
40,An example of a Grothendieck topology,An example of a Grothendieck topology,,"A Grothendieck topology on a category $\mathcal{C}$ with finite limits consists of, for each object $U$ in $\mathcal{C}$ a collection $\text{Cov}(U)$ of sets $\{ U_i \to U \}$ such that Isomorphisms are covers, e.g if $V \to U$ is an isomorphism then $\{ V \to U \} \in \text{Cov}(U)$ Transitivity: If $\{V_i \to U \}$ and $\{V_{ij} \to V_i \}$ are coverings then $\{V_{ij} \to U \}$ is also a covering If $\{U_i \to U \} \in \text{Cov}(U)$ and $V \to U$ a morphism then $\{V \times_U U_i \to V \} \in \text{Cov(V)}$ The claim is that the following is a covering: $\mathcal{C} = \text{Rings}^{\text{op}}$, and coverings are the opposite of collections $\{R \to R_i \}$ where Each $R \to R_i$ is flat If $M$ is an $R$-module such that $M \otimes_R R_i=0$ for all $i$ then $M=0$ (I have interpreted $R \to R_i$ as flat as meaning $R_i$ is flat as an $R$-module) I (think) I have verified the first two conditions (isomorphism and transitivity). For example the second part of transitivity will follow since: $$ \begin{align} 0 &\simeq M\otimes_{U} V_{ij}\\  &\simeq M \otimes_{U}\left(U_i \otimes_{U_i}V_{ij}\right) \\  &\simeq \left(M \otimes_{U} U_i \right) \otimes_{U_i} V_{ij}  \end{align}$$ which gives that $M \otimes_U U_i=0$ which in turn gives $M=0$ I'm not sure how to interpret the fiber product in item 3. For example I want to show that $M \otimes_V (V \times_U U_i)=0$ gives $M=0$, but I have no idea what the fiber product is in this category, and how it interacts with the tensor product.","A Grothendieck topology on a category $\mathcal{C}$ with finite limits consists of, for each object $U$ in $\mathcal{C}$ a collection $\text{Cov}(U)$ of sets $\{ U_i \to U \}$ such that Isomorphisms are covers, e.g if $V \to U$ is an isomorphism then $\{ V \to U \} \in \text{Cov}(U)$ Transitivity: If $\{V_i \to U \}$ and $\{V_{ij} \to V_i \}$ are coverings then $\{V_{ij} \to U \}$ is also a covering If $\{U_i \to U \} \in \text{Cov}(U)$ and $V \to U$ a morphism then $\{V \times_U U_i \to V \} \in \text{Cov(V)}$ The claim is that the following is a covering: $\mathcal{C} = \text{Rings}^{\text{op}}$, and coverings are the opposite of collections $\{R \to R_i \}$ where Each $R \to R_i$ is flat If $M$ is an $R$-module such that $M \otimes_R R_i=0$ for all $i$ then $M=0$ (I have interpreted $R \to R_i$ as flat as meaning $R_i$ is flat as an $R$-module) I (think) I have verified the first two conditions (isomorphism and transitivity). For example the second part of transitivity will follow since: $$ \begin{align} 0 &\simeq M\otimes_{U} V_{ij}\\  &\simeq M \otimes_{U}\left(U_i \otimes_{U_i}V_{ij}\right) \\  &\simeq \left(M \otimes_{U} U_i \right) \otimes_{U_i} V_{ij}  \end{align}$$ which gives that $M \otimes_U U_i=0$ which in turn gives $M=0$ I'm not sure how to interpret the fiber product in item 3. For example I want to show that $M \otimes_V (V \times_U U_i)=0$ gives $M=0$, but I have no idea what the fiber product is in this category, and how it interacts with the tensor product.",,"['abstract-algebra', 'algebraic-geometry', 'sheaf-theory', 'topos-theory', 'grothendieck-topologies']"
41,In this special case the quotient polynomial ring is a UFD?,In this special case the quotient polynomial ring is a UFD?,,"I would like to know if the following is true. Let $F$ be a field and let $p\in F[x]$ be a square-free polynomial. Then, the quotient ring $F[x,y]/\langle y^2-p\rangle$ is a UFD. I am not sure how to approach this question. Thanks!","I would like to know if the following is true. Let $F$ be a field and let $p\in F[x]$ be a square-free polynomial. Then, the quotient ring $F[x,y]/\langle y^2-p\rangle$ is a UFD. I am not sure how to approach this question. Thanks!",,"['abstract-algebra', 'ring-theory', 'commutative-algebra', 'unique-factorization-domains', 'dedekind-domain']"
42,How to determine injectivity and surjectivity for a map $\mathbb{Z}_n \to \mathbb{Z}_{n}$?,How to determine injectivity and surjectivity for a map ?,\mathbb{Z}_n \to \mathbb{Z}_{n},"I know how to determine injectivity and surjectivity for maps between regular sets, but in this case I've got some problems. How can I solve this? Given the following map $\psi:\overline{x} \in  \mathbb{Z}_{16}\mapsto \overline{7}\overline{x}\in\mathbb{Z}_{16}$.   Without calculating a single element's image, and just using the properties   of $\overline{7}$ in $\mathbb{Z}_{16}$, decide if $\psi$ is injective,   surjective or both. If possible, find the inverse of   $\psi$.","I know how to determine injectivity and surjectivity for maps between regular sets, but in this case I've got some problems. How can I solve this? Given the following map $\psi:\overline{x} \in  \mathbb{Z}_{16}\mapsto \overline{7}\overline{x}\in\mathbb{Z}_{16}$.   Without calculating a single element's image, and just using the properties   of $\overline{7}$ in $\mathbb{Z}_{16}$, decide if $\psi$ is injective,   surjective or both. If possible, find the inverse of   $\psi$.",,['abstract-algebra']
43,Elements of $K$ which are separable over $F$ form a subfield of $K$?,Elements of  which are separable over  form a subfield of ?,K F K,"I'm trying to prove the following statement: If $K$ is an extension of $F$ prove that the set of elements in $K$ which are separable over $F$ forms a subfield of $K$. I have a proof for the set of algebraic elements in $K$ forming a subfield, but I'm stuck with the separable elements. I'm assuming I should be splitting this into cases of characteristic = 0 and characteristic $\neq$ 0. Any help? I'm at a loss.","I'm trying to prove the following statement: If $K$ is an extension of $F$ prove that the set of elements in $K$ which are separable over $F$ forms a subfield of $K$. I have a proof for the set of algebraic elements in $K$ forming a subfield, but I'm stuck with the separable elements. I'm assuming I should be splitting this into cases of characteristic = 0 and characteristic $\neq$ 0. Any help? I'm at a loss.",,"['abstract-algebra', 'galois-theory']"
44,Description of $R \otimes R$ for $R$ a ring of integers,Description of  for  a ring of integers,R \otimes R R,"If $K/k$ is a finite Galois extension of fields, with Galois group $G$, there's an isomorphism $$ K \ \otimes_k \ K \simeq \oplus_{\sigma_i \in G} \ K$$ given by sending $a \otimes b$ to $ (...,  \sigma_i(a) b, ...)$ and extending linearly. This is even an isomorphism of $K$-vector spaces, where $a \in K$ is acting by multiplication on the first factor in $K \otimes K$, and by multiplication by $(\sigma_i(a))$ on $\oplus_{\sigma_i} K$. There's also an obvious $k[G]$-module structure that's preserved. My question is what happens if instead of $K$, we consider $R \otimes_S R$, where $R$ and $S$ are the rings of integers of number fields $K$ and $k$ respectively. I tried playing around with quadratic extensions, and I'm pretty sure that the same map above from $R \otimes R$ to $\oplus R$ is not surjective, so the same argument doesn't work? Is there a nice description of $R \otimes R$ as either an $R$ module, or an $S[G]$ module? Thanks.","If $K/k$ is a finite Galois extension of fields, with Galois group $G$, there's an isomorphism $$ K \ \otimes_k \ K \simeq \oplus_{\sigma_i \in G} \ K$$ given by sending $a \otimes b$ to $ (...,  \sigma_i(a) b, ...)$ and extending linearly. This is even an isomorphism of $K$-vector spaces, where $a \in K$ is acting by multiplication on the first factor in $K \otimes K$, and by multiplication by $(\sigma_i(a))$ on $\oplus_{\sigma_i} K$. There's also an obvious $k[G]$-module structure that's preserved. My question is what happens if instead of $K$, we consider $R \otimes_S R$, where $R$ and $S$ are the rings of integers of number fields $K$ and $k$ respectively. I tried playing around with quadratic extensions, and I'm pretty sure that the same map above from $R \otimes R$ to $\oplus R$ is not surjective, so the same argument doesn't work? Is there a nice description of $R \otimes R$ as either an $R$ module, or an $S[G]$ module? Thanks.",,"['number-theory', 'abstract-algebra']"
45,What is the use of representation ring,What is the use of representation ring,,"In the representation theory, the representation ring is defined and some results can be expressed with the representation ring R(G).  What is the benefit of having this extra definition and what insights can it provide?","In the representation theory, the representation ring is defined and some results can be expressed with the representation ring R(G).  What is the benefit of having this extra definition and what insights can it provide?",,['abstract-algebra']
46,Computing ideal intersections in polynomial rings,Computing ideal intersections in polynomial rings,,"Suppose, $R=k[x_1,...,x_n]$ and $I,J,A,B,C,D$ are ideals in $R$. Suppose, I can write $A,B,C,D$ explicitly in terms of generators and I can also compute $A\cap B$ explicitly in terms of generators. It is also known, $I=A+C$ $J=B+D$ How would I go about computing $I\cap J$, if this can be done at all. To clarify what I mean by explicitly, I can write an ideal as $(f_1,...,f_n)$, where the polynomials $f_i$ are not specified, but I know certain properties of these (so I can write down examples). So, I would like to write down $I\cap J$ in terms of the generators of $A,B,C,D,A\cap B$.","Suppose, $R=k[x_1,...,x_n]$ and $I,J,A,B,C,D$ are ideals in $R$. Suppose, I can write $A,B,C,D$ explicitly in terms of generators and I can also compute $A\cap B$ explicitly in terms of generators. It is also known, $I=A+C$ $J=B+D$ How would I go about computing $I\cap J$, if this can be done at all. To clarify what I mean by explicitly, I can write an ideal as $(f_1,...,f_n)$, where the polynomials $f_i$ are not specified, but I know certain properties of these (so I can write down examples). So, I would like to write down $I\cap J$ in terms of the generators of $A,B,C,D,A\cap B$.",,"['abstract-algebra', 'commutative-algebra']"
47,Showing that the path-connected component of the identity matrix in a subgroup of $GL_n(\Bbb R)$ is a normal subgroup,Showing that the path-connected component of the identity matrix in a subgroup of  is a normal subgroup,GL_n(\Bbb R),"Let $M(n;\mathbb{R})$ denote the set of all $n \times n$ matrices with real entries (identified with $\mathbb{R}^{n^{2}}$ and endowed with its usual topology) and let $GL(n;\mathbb{R})$ denote the group of invertible matrices. Let $G$ be a subgroup of $GL(n;\mathbb{R})$. Define $$H = \biggl\{ A \in G  \ \biggl| \ \exists \ \varphi:[0,1] \to G \ \text{continuous such that} \ \varphi(0)=A , \ \varphi(1)=I\biggr\}$$ Then is $H$ normal in $G$? For proving $H$ normal i should verify two things: First $H$ is a subgroup. For all $A \in G, B \in H$, we must have $A \cdot B \cdot A^{-1} \in H$. That's it i  am not able to proceed any further.","Let $M(n;\mathbb{R})$ denote the set of all $n \times n$ matrices with real entries (identified with $\mathbb{R}^{n^{2}}$ and endowed with its usual topology) and let $GL(n;\mathbb{R})$ denote the group of invertible matrices. Let $G$ be a subgroup of $GL(n;\mathbb{R})$. Define $$H = \biggl\{ A \in G  \ \biggl| \ \exists \ \varphi:[0,1] \to G \ \text{continuous such that} \ \varphi(0)=A , \ \varphi(1)=I\biggr\}$$ Then is $H$ normal in $G$? For proving $H$ normal i should verify two things: First $H$ is a subgroup. For all $A \in G, B \in H$, we must have $A \cdot B \cdot A^{-1} \in H$. That's it i  am not able to proceed any further.",,"['abstract-algebra', 'general-topology']"
48,Quadratic and quartic subfields of $\mathbb{Q}(\zeta_{2023})$,Quadratic and quartic subfields of,\mathbb{Q}(\zeta_{2023}),"Let $\zeta_{2023}=e^{2\pi i /2023}$ be a primitive $2023$ th root of unity. Describe : Quadratic subfields of $\mathbb{Q}(\zeta_{2023})$ . Quartic subfields $E$ of $\mathbb{Q}(\zeta_{2023})$ such that $\mathcal{Gal}(E/\mathbb{Q})\cong \mathbb{Z}/4\mathbb{Z}$ . Since $2023=7\cdot 17^2$ , we have $\mathbb{Q}(\zeta_{2023})=\mathbb{Q}(\zeta_{7})\cdot\mathbb{Q}(\zeta_{17^2})$ , and then $$\begin{align} \mathcal{Gal}(\mathbb{Q}(\zeta_{2023})/\mathbb{Q})&\cong\mathcal{Gal}(\mathbb{Q}(\zeta_{7})/\mathbb{Q})\times\mathcal{Gal}(\mathbb{Q}(\zeta_{17^2})/\mathbb{Q})\cong(\mathbb{Z}/7\mathbb{Z})^*\times(\mathbb{Z}/17^2\mathbb{Z})^* \\ &\cong\mathbb{Z}/6\mathbb{Z}\times\mathbb{Z}/17\cdot16\mathbb{Z} \end{align} $$ Furthermore $(\mathbb{Z}/7\mathbb{Z})^*=\langle [3]_7 \rangle$ and $(\mathbb{Z}/17^2\mathbb{Z})^*=\langle [3]_{17^2} \rangle$ , thus $\mathcal{Gal}(\mathbb{Q}(\zeta_{7})/\mathbb{Q})=\langle\sigma\rangle$ with $\sigma(\zeta_7)=\zeta_{7}^3$ , and $\mathcal{Gal}(\mathbb{Q}(\zeta_{17^2})/\mathbb{Q})=\langle\tau\rangle$ with $\tau(\zeta_{17^2})=\zeta_{17^2}^3$ . Finally, by extending $\sigma$ and $\tau$ to automorphisms of $\mathbb{Q}(\zeta_{2023})$ , we get $$ \mathcal{Gal}(\mathbb{Q}(\zeta_{2023})/\mathbb{Q})=\langle\sigma\rangle\times\langle\tau\rangle $$ The only subgroups of index $2$ in $\mathcal{Gal}(\mathbb{Q}(\zeta_{2023})/\mathbb{Q})$ are $$ \begin{align}  H&:=\langle\sigma^2\rangle\times\langle\tau\rangle\cong\mathbb{Z/3Z}\times\mathbb{Z/17\cdot 16Z} \\ L&:=\langle\sigma^4\rangle\times\langle\tau\rangle\cong\mathbb{Z/3Z}\times\mathbb{Z/17\cdot 16Z} \\ K&:=\langle\sigma\rangle\times\langle\tau^2\rangle\cong\mathbb{Z/6Z}\times\mathbb{Z/17\cdot 8Z}   \end{align} $$ Thus, the only quadratic subfield are $\mathbb{Q}(\zeta_{2023})^H$ , $\mathbb{Q}(\zeta_{2023})^L$ and $\mathbb{Q}(\zeta_{2023})^K$ . Unfortunately, I couldn't find an explicit description of these subfields through generators. Again, with some groups theory arguments I could find the desired subgroups of $\mathcal{Gal}(\mathbb{Q}(\zeta_{2023})/\mathbb{Q})$ , but I couldn't get an explicit description of the corresponding subfields.","Let be a primitive th root of unity. Describe : Quadratic subfields of . Quartic subfields of such that . Since , we have , and then Furthermore and , thus with , and with . Finally, by extending and to automorphisms of , we get The only subgroups of index in are Thus, the only quadratic subfield are , and . Unfortunately, I couldn't find an explicit description of these subfields through generators. Again, with some groups theory arguments I could find the desired subgroups of , but I couldn't get an explicit description of the corresponding subfields.","\zeta_{2023}=e^{2\pi i /2023} 2023 \mathbb{Q}(\zeta_{2023}) E \mathbb{Q}(\zeta_{2023}) \mathcal{Gal}(E/\mathbb{Q})\cong \mathbb{Z}/4\mathbb{Z} 2023=7\cdot 17^2 \mathbb{Q}(\zeta_{2023})=\mathbb{Q}(\zeta_{7})\cdot\mathbb{Q}(\zeta_{17^2}) \begin{align}
\mathcal{Gal}(\mathbb{Q}(\zeta_{2023})/\mathbb{Q})&\cong\mathcal{Gal}(\mathbb{Q}(\zeta_{7})/\mathbb{Q})\times\mathcal{Gal}(\mathbb{Q}(\zeta_{17^2})/\mathbb{Q})\cong(\mathbb{Z}/7\mathbb{Z})^*\times(\mathbb{Z}/17^2\mathbb{Z})^* \\
&\cong\mathbb{Z}/6\mathbb{Z}\times\mathbb{Z}/17\cdot16\mathbb{Z}
\end{align}
 (\mathbb{Z}/7\mathbb{Z})^*=\langle [3]_7 \rangle (\mathbb{Z}/17^2\mathbb{Z})^*=\langle [3]_{17^2} \rangle \mathcal{Gal}(\mathbb{Q}(\zeta_{7})/\mathbb{Q})=\langle\sigma\rangle \sigma(\zeta_7)=\zeta_{7}^3 \mathcal{Gal}(\mathbb{Q}(\zeta_{17^2})/\mathbb{Q})=\langle\tau\rangle \tau(\zeta_{17^2})=\zeta_{17^2}^3 \sigma \tau \mathbb{Q}(\zeta_{2023}) 
\mathcal{Gal}(\mathbb{Q}(\zeta_{2023})/\mathbb{Q})=\langle\sigma\rangle\times\langle\tau\rangle
 2 \mathcal{Gal}(\mathbb{Q}(\zeta_{2023})/\mathbb{Q}) 
\begin{align} 
H&:=\langle\sigma^2\rangle\times\langle\tau\rangle\cong\mathbb{Z/3Z}\times\mathbb{Z/17\cdot 16Z} \\
L&:=\langle\sigma^4\rangle\times\langle\tau\rangle\cong\mathbb{Z/3Z}\times\mathbb{Z/17\cdot 16Z} \\
K&:=\langle\sigma\rangle\times\langle\tau^2\rangle\cong\mathbb{Z/6Z}\times\mathbb{Z/17\cdot 8Z}  
\end{align}
 \mathbb{Q}(\zeta_{2023})^H \mathbb{Q}(\zeta_{2023})^L \mathbb{Q}(\zeta_{2023})^K \mathcal{Gal}(\mathbb{Q}(\zeta_{2023})/\mathbb{Q})","['abstract-algebra', 'field-theory', 'galois-theory']"
49,Prove that the polynomial $x^4 -5x^2+x+1$ is irreducible over the ring $\mathbb{Z}[x]$.,Prove that the polynomial  is irreducible over the ring .,x^4 -5x^2+x+1 \mathbb{Z}[x],"I do not have an idea on how to approach this problem. Similar problems that I found online try to show that there does not exist a linear factor of the given equation in $\mathbb{Q}$ . But my question is, how is that sufficient to prove that the polynomial is irreducible? It could also be a product of two quadratic polynomials which do not have a solution in $\mathbb{Q}$ . Any help is appreciated!","I do not have an idea on how to approach this problem. Similar problems that I found online try to show that there does not exist a linear factor of the given equation in . But my question is, how is that sufficient to prove that the polynomial is irreducible? It could also be a product of two quadratic polynomials which do not have a solution in . Any help is appreciated!",\mathbb{Q} \mathbb{Q},"['abstract-algebra', 'ring-theory', 'irreducible-polynomials']"
50,"The Collatz Conjecture function should induce a collection of Grothendieck groups, one for each $n \in \Bbb{Z}$ or $\Bbb{N}$. Their properties?","The Collatz Conjecture function should induce a collection of Grothendieck groups, one for each  or . Their properties?",n \in \Bbb{Z} \Bbb{N},"This question is about the Collatz conjecture . Let $\Bbb{N}$ include $0$ . The Collatz conjecture function is given by: $$ f: \Bbb{N} \to \Bbb{N}, \\ f(n) = \begin{cases}  \dfrac{n}{2}, \text{ if } n = 0 \pmod 2,\\ \dfrac{3n + 1}{2}, \text{ if } n = 1\pmod 2 \text{ and } n \gt 1\\ \end{cases} $$ Now, break up the conjecture into an infinite number of cases, one for each $n \in \Bbb{N}$ as is what usually happens when mathematicians collectively attack problems.  The result is a proven special cases section on the conjecture's Wikipedia page. We can also extend $f$ to $\Bbb{Z}$ as is and get several all-negaive value loops. Anyway, let the domain and range space be $\Bbb{N}$ for now.  We know that $\Bbb{N}$ forms a commutative monoid under addition.  Define the equivalence relation: Fix $n \in \Bbb{N}$ .  Define the equivalence relation on $\Bbb{N}$ : $$ i\sim j \iff f^i(n) = f^j(n) $$ Then $i\sim j, i' \sim j' \implies$ $i + i' \sim j + j'$ so that the equivalence relation respects $+$ on $\Bbb{N}$ . Then you can form a congruence monoid $N = \Bbb{N} / \sim$ .  For example for $n = 1$ this is $f^0(1) = 1$ , $f^1(1) = 2$ , $f^2(1) = 1, \dots$ so that the equivalence classes are $2 \Bbb{N}$ and $2\Bbb{N} + 1$ . Therefore we say that the Collatz conjecture induces the group $\Bbb{Z}/2 = G(M/\sim) = $ the Grothendieck group of $\Bbb{N}/\sim$ . That makes perfect sense!  There's a loop of ""length 2"" there namely $(1,2,1,2,1,\dots)$ where entries are iterate values $f^i(1), i \geq 0$ (so the entries are $0$ -based indexed). Therefore, I reckon that the Grothendieck groups $G(\Bbb{N}/\sim_{n})$ where $\sim_n$ means $n$ is the input to $f^i(n)$ in the definition of $\sim$ must have some property that flags whether or not $n$ gives an example to the conjecture, is there? I don't think it's finiteness.  For example $n$ terminating at $1$ gives a finite group as well as $n$ going off and then self-looping somewhere else would give a finite group. Further Attempt. The $f^i(n)$ sequence can either shoot off to infinity, self-loop somewhere (here at $i = 0$ or further at $i = x \gt 0$ ), or it can drop back down to a value $m \lt n$ .  In the first case we have that $G_n := G(\Bbb{N}/\sim_n)$ is trivial.  In the second case we have: $$ n, n_1, n_2, \dots, n_j, n_{j+1}, \dots, n_{k-1}, n_k = n_j, n_{j+1}, \dots $$ for some $n_k \gt n_{j} \geq n$ .  And in the third case we have: $n, n_1, n_2, \dots, n_{k-1}, n_{k} = 2, 1, 2, 1, \dots$ for some $k \gt 0$ , since by induction on $n$ we've handled all cases $m \lt n$ and they go to the 1-2 loop. The Grothendieck group in the second case is that of the monoid: $$ \{[0], [1], [2], \dots, [j-1], [j],[j+1], \dots, [k-1] \} $$ What is the Grothendieck group isomorphic to in this case?","This question is about the Collatz conjecture . Let include . The Collatz conjecture function is given by: Now, break up the conjecture into an infinite number of cases, one for each as is what usually happens when mathematicians collectively attack problems.  The result is a proven special cases section on the conjecture's Wikipedia page. We can also extend to as is and get several all-negaive value loops. Anyway, let the domain and range space be for now.  We know that forms a commutative monoid under addition.  Define the equivalence relation: Fix .  Define the equivalence relation on : Then so that the equivalence relation respects on . Then you can form a congruence monoid .  For example for this is , , so that the equivalence classes are and . Therefore we say that the Collatz conjecture induces the group the Grothendieck group of . That makes perfect sense!  There's a loop of ""length 2"" there namely where entries are iterate values (so the entries are -based indexed). Therefore, I reckon that the Grothendieck groups where means is the input to in the definition of must have some property that flags whether or not gives an example to the conjecture, is there? I don't think it's finiteness.  For example terminating at gives a finite group as well as going off and then self-looping somewhere else would give a finite group. Further Attempt. The sequence can either shoot off to infinity, self-loop somewhere (here at or further at ), or it can drop back down to a value .  In the first case we have that is trivial.  In the second case we have: for some .  And in the third case we have: for some , since by induction on we've handled all cases and they go to the 1-2 loop. The Grothendieck group in the second case is that of the monoid: What is the Grothendieck group isomorphic to in this case?","\Bbb{N} 0 
f: \Bbb{N} \to \Bbb{N}, \\
f(n) = \begin{cases} 
\dfrac{n}{2}, \text{ if } n = 0 \pmod 2,\\
\dfrac{3n + 1}{2}, \text{ if } n = 1\pmod 2 \text{ and } n \gt 1\\
\end{cases}
 n \in \Bbb{N} f \Bbb{Z} \Bbb{N} \Bbb{N} n \in \Bbb{N} \Bbb{N} 
i\sim j \iff f^i(n) = f^j(n)
 i\sim j, i' \sim j' \implies i + i' \sim j + j' + \Bbb{N} N = \Bbb{N} / \sim n = 1 f^0(1) = 1 f^1(1) = 2 f^2(1) = 1, \dots 2 \Bbb{N} 2\Bbb{N} + 1 \Bbb{Z}/2 = G(M/\sim) =  \Bbb{N}/\sim (1,2,1,2,1,\dots) f^i(1), i \geq 0 0 G(\Bbb{N}/\sim_{n}) \sim_n n f^i(n) \sim n n 1 n f^i(n) i = 0 i = x \gt 0 m \lt n G_n := G(\Bbb{N}/\sim_n) 
n, n_1, n_2, \dots, n_j, n_{j+1}, \dots, n_{k-1}, n_k = n_j, n_{j+1}, \dots
 n_k \gt n_{j} \geq n n, n_1, n_2, \dots, n_{k-1}, n_{k} = 2, 1, 2, 1, \dots k \gt 0 n m \lt n 
\{[0], [1], [2], \dots, [j-1], [j],[j+1], \dots, [k-1] \}
","['abstract-algebra', 'group-theory', 'collatz-conjecture', 'open-problem', 'grothendieck-construction']"
51,"A more succinct group object diagram (all axioms in one connected diagram), questions about its properties...","A more succinct group object diagram (all axioms in one connected diagram), questions about its properties...",,"Here is the definition of group object from nLab.  They give 3 associated maps $* \xrightarrow{1} G$ , $m: G^2 \to G$ , and $-^{-1}: G \to G$ and require 3 commutative diagrams to complete the axioms for a ""group"". Here, however, I've managed to condense these down into one (connected) diagram: We say that $G \in \text{Ob}(C)$ (a category with binary products and a terminal object $*$ ) forms a group object precisely when the above diagram commutes. Note that $1\times \text{id}$ is notation implying that we use the map $1 =$ the composition of the two maps $(G \xrightarrow{!} * \xrightarrow{1} G)$ , and the appropriate $\Delta$ is used wherever it is needed.  I like the simpler notation that I've used. Anyway, this diagram is more economical than the combined other 3 since we re-use arrows such as $m\times \text{id}$ at least twice (two commutative shapes described - triangles or squares). So, that's background and what I've done on the problem so far.  My questions are: Can we define a group object to be an object $G$ such that the above diagram commutes when we replace each $m \times \text{id}, 1\times \text{id}, \text{id}\times -^{-1} \times \text{id}$ with  general morphisms $f, g, h$ in the category $C$ ( $G \in \text{Ob}(C)$ )?  Or can you only recover a group object if you define these edges using products, the diagonal morphism, etc, as shown? In either case, is $G$ the limit of a commutative square (the outer one), since a cone seems to be formed.","Here is the definition of group object from nLab.  They give 3 associated maps , , and and require 3 commutative diagrams to complete the axioms for a ""group"". Here, however, I've managed to condense these down into one (connected) diagram: We say that (a category with binary products and a terminal object ) forms a group object precisely when the above diagram commutes. Note that is notation implying that we use the map the composition of the two maps , and the appropriate is used wherever it is needed.  I like the simpler notation that I've used. Anyway, this diagram is more economical than the combined other 3 since we re-use arrows such as at least twice (two commutative shapes described - triangles or squares). So, that's background and what I've done on the problem so far.  My questions are: Can we define a group object to be an object such that the above diagram commutes when we replace each with  general morphisms in the category ( )?  Or can you only recover a group object if you define these edges using products, the diagonal morphism, etc, as shown? In either case, is the limit of a commutative square (the outer one), since a cone seems to be formed.","* \xrightarrow{1} G m: G^2 \to G -^{-1}: G \to G G \in \text{Ob}(C) * 1\times \text{id} 1 = (G \xrightarrow{!} * \xrightarrow{1} G) \Delta m\times \text{id} G m \times \text{id}, 1\times \text{id}, \text{id}\times -^{-1} \times \text{id} f, g, h C G \in \text{Ob}(C) G","['abstract-algebra', 'group-theory', 'category-theory', 'limits-colimits', 'morphism']"
52,"Exercise 1.5.xi from Emily Riehl's ""Category Theory in Context"" on properties of some functors","Exercise 1.5.xi from Emily Riehl's ""Category Theory in Context"" on properties of some functors",,"I've been going through Emily Riehl's textbook on categories, and struggle with the exercise 1.5.xi. Consider the functors $Ab \to Grp$ (inclusion), $Ring \to Ab$ (forgetting the multiplication), $(-)^\times: Ring \to Grp$ (taking the group of units), $Ring \to Rng$ (inclusion), $Fld \to Ring$ (inclusion) and $Mod_R \to Ab$ (forgetful). Determine which functors are full, which are faithful, and which are essentially surjective. Do any define an equivalence of categories? (Warning: A few of these questions conceal research-level problems, but they can be fun to think about even if full solutions are hard to come by.) As mentioned, some of the problems are pretty hard, so I skipped some of them. For now, I've determined that properties only for $Ab \to Grp$ , $Ring \to Ab$ and $Fld \to Ring$ . This are my solutions: $Ab \to Grp$ : almost obviously, this functor is not essentially surjective, whileas it's fully faithful: if two groups are abelian, then any abelian homomorphism between them is just a group homomorphism, so it's faithful, and if two groups in $Grp$ are in fact abelian groups, then they have the same set of morphisms as objects in $Ab$ , so it's fully faithful, and really $Ab$ is a full subcategory of $Grp$ . $Ring \to Ab$ : this functor is not essentially surjective(because e.g. $\mathbb{Q}/\mathbb{Z}$ is not a ring); it's faithful, since different ring homomorphisms are going to be different group homomorphisms under functor action. But this functor is not full: consider rings $\mathbb{Z}/n\mathbb{Z}$ and $\mathbb{Z}$ . If $U: Ring \to Ab%$ , then consider $\varphi: U(\mathbb{Z}/n\mathbb{Z}) \to U(\mathbb{Z}): x \mapsto 0$ . There's no $\psi: \mathbb{Z}/n\mathbb{Z} \to \mathbb{Z}$ such that $U(\psi) = \varphi$ , so this functor is not full. $Fld \to Ring$ : in some sense same as for $Ab \to Grp$ : $Fld$ is full subcategory of $Ring$ and this functor is not obviously essentially surjective. I'd like to know whether I am correct. Seems like there was nothing hard, but I have doubts on my solutions. Also I'm interested in the properties of another functors. I was thinking about $Mod_R \to Ab$ : since it's forgetful, it's faithful. But is it full? Or essentially surjective? Obviously, not both(otherwise, this is an equivalence of categories), and the answer is somehow depends on the ring(because if $R = \mathbb{Z}$ , then this is the equivalence of categories). Probably I can show that such functor is essentially surjective, since I kinda can create module via tensor product $G \otimes_\mathbb{Z} R$ (which is kinda left-adjoint to $Mod_R \to Ab$ ), but I'm not sure in it. So, can anyone elaborate the situation with $Mod_R \to Ab$ and the other functors? Or maybe give a tip on it. Concretely, I have no clue on: $(-)^\times: Ring \to Grp$ (taking the group of units) $Ring \to Rng$ (inclusion) Thanks!","I've been going through Emily Riehl's textbook on categories, and struggle with the exercise 1.5.xi. Consider the functors (inclusion), (forgetting the multiplication), (taking the group of units), (inclusion), (inclusion) and (forgetful). Determine which functors are full, which are faithful, and which are essentially surjective. Do any define an equivalence of categories? (Warning: A few of these questions conceal research-level problems, but they can be fun to think about even if full solutions are hard to come by.) As mentioned, some of the problems are pretty hard, so I skipped some of them. For now, I've determined that properties only for , and . This are my solutions: : almost obviously, this functor is not essentially surjective, whileas it's fully faithful: if two groups are abelian, then any abelian homomorphism between them is just a group homomorphism, so it's faithful, and if two groups in are in fact abelian groups, then they have the same set of morphisms as objects in , so it's fully faithful, and really is a full subcategory of . : this functor is not essentially surjective(because e.g. is not a ring); it's faithful, since different ring homomorphisms are going to be different group homomorphisms under functor action. But this functor is not full: consider rings and . If , then consider . There's no such that , so this functor is not full. : in some sense same as for : is full subcategory of and this functor is not obviously essentially surjective. I'd like to know whether I am correct. Seems like there was nothing hard, but I have doubts on my solutions. Also I'm interested in the properties of another functors. I was thinking about : since it's forgetful, it's faithful. But is it full? Or essentially surjective? Obviously, not both(otherwise, this is an equivalence of categories), and the answer is somehow depends on the ring(because if , then this is the equivalence of categories). Probably I can show that such functor is essentially surjective, since I kinda can create module via tensor product (which is kinda left-adjoint to ), but I'm not sure in it. So, can anyone elaborate the situation with and the other functors? Or maybe give a tip on it. Concretely, I have no clue on: (taking the group of units) (inclusion) Thanks!",Ab \to Grp Ring \to Ab (-)^\times: Ring \to Grp Ring \to Rng Fld \to Ring Mod_R \to Ab Ab \to Grp Ring \to Ab Fld \to Ring Ab \to Grp Grp Ab Ab Grp Ring \to Ab \mathbb{Q}/\mathbb{Z} \mathbb{Z}/n\mathbb{Z} \mathbb{Z} U: Ring \to Ab% \varphi: U(\mathbb{Z}/n\mathbb{Z}) \to U(\mathbb{Z}): x \mapsto 0 \psi: \mathbb{Z}/n\mathbb{Z} \to \mathbb{Z} U(\psi) = \varphi Fld \to Ring Ab \to Grp Fld Ring Mod_R \to Ab R = \mathbb{Z} G \otimes_\mathbb{Z} R Mod_R \to Ab Mod_R \to Ab (-)^\times: Ring \to Grp Ring \to Rng,"['abstract-algebra', 'solution-verification', 'category-theory', 'adjoint-functors', 'functors']"
53,Factoring a polynomial modulo prime,Factoring a polynomial modulo prime,,"How would I go about factoring a polynomial $x^{5}-4$ over a finite field $\mathbb{F}_{29}=\mathbb{Z}/29\mathbb{Z}$ ? I know that $29$ is prime, so that will be relevant at the very least. Moreover, if we solve the equation $x^{5}\equiv 4 \mod 29$ , we would get the solution $x=6$ unique up to modulo $29$ . Is there a way to factor this over $\mathbb{Z}/29\mathbb{Z}$ by using the solution obtained from the equation?","How would I go about factoring a polynomial over a finite field ? I know that is prime, so that will be relevant at the very least. Moreover, if we solve the equation , we would get the solution unique up to modulo . Is there a way to factor this over by using the solution obtained from the equation?",x^{5}-4 \mathbb{F}_{29}=\mathbb{Z}/29\mathbb{Z} 29 x^{5}\equiv 4 \mod 29 x=6 29 \mathbb{Z}/29\mathbb{Z},['abstract-algebra']
54,Let $\alpha$ be a root of $x^3+x+1$ and $\beta$ be a root of $x^3+x+3$. Show that it is not possible that $\alpha\in\mathbb Q(\beta)$,Let  be a root of  and  be a root of . Show that it is not possible that,\alpha x^3+x+1 \beta x^3+x+3 \alpha\in\mathbb Q(\beta),"Question : Let $\alpha$ be a root of $x^3+x+1$ and $\beta$ be a root of $x^3+x+3$ . Show that it is not possible that $\alpha\in \mathbb Q(\beta)$ . My proof : Given $\beta$ is a root of $x^3+x+3$ . Thus $\beta^3+\beta+3 = 0$ . Then $(\beta^3+\beta+2 ) + 1 = 0$ . If $\alpha\in\mathbb Q(\beta)$ , then $\alpha = r_1 + r_2\beta$ for some rationals $r_1$ and $r_2$ . Also $(r_1+r_2\beta)^3+r_1+r_2\beta+1 = 0$ . Therefore for some rationals $r_1$ and $r_2$ we have $(r_1+r_2\beta)^3+r_1 + r_2\beta = \beta^3+\beta+2$ . But equating and solving such $r_1$ and $r_2$ doesn't exist. Thus, $\alpha$ doesn't belong to $\mathbb Q(\beta)$ . Do you think my proof is right? If not correct me or provide a better easier  proof","Question : Let be a root of and be a root of . Show that it is not possible that . My proof : Given is a root of . Thus . Then . If , then for some rationals and . Also . Therefore for some rationals and we have . But equating and solving such and doesn't exist. Thus, doesn't belong to . Do you think my proof is right? If not correct me or provide a better easier  proof",\alpha x^3+x+1 \beta x^3+x+3 \alpha\in \mathbb Q(\beta) \beta x^3+x+3 \beta^3+\beta+3 = 0 (\beta^3+\beta+2 ) + 1 = 0 \alpha\in\mathbb Q(\beta) \alpha = r_1 + r_2\beta r_1 r_2 (r_1+r_2\beta)^3+r_1+r_2\beta+1 = 0 r_1 r_2 (r_1+r_2\beta)^3+r_1 + r_2\beta = \beta^3+\beta+2 r_1 r_2 \alpha \mathbb Q(\beta),"['abstract-algebra', 'ring-theory', 'field-theory', 'irreducible-polynomials']"
55,"How do I show that if the product of idempotents is idempotent, then idempotents commute with other elements?","How do I show that if the product of idempotents is idempotent, then idempotents commute with other elements?",,"I was not able to prove the following theorem. I would appreciate some help regarding it: If the product of each two idempotent elements in a unity ring is an idempotent element itself, prove that the product of idempotent and a specifically non-idempotent element is commutative. (The ring $R$ is a unity ring).  In notation: $$\forall a \in R \forall x \in R (a^2=a \land x^2 \neq x \longrightarrow xa=ax).$$ I'm very new to group theory in general, so I can't properly find an example to demonstrate my point. I'm not even aware exactly of terms such as ""ideals"" etc. I will however state the original theorem which this was a derivative of: For a unity ring $R$ , prove that if the product of two idempotent elements is also idempotent, then all idempotent elements of the ring are an element of its center. Since one has to prove that for all elements of the ring $R$ multiplied by an arbitrary idempotent element such as $a$ have the commutative property, I divided the case for the arbitrary element $x$ in two cases: for $x$ which is idempotent, and for $x$ which is not. I was able to prove that if $x$ is idempotent, the commutative property holds for its product with $a$ (the arbitrary idempotent element of $a$ ), but I wasn't able to do it for when $x$ is strictly non-idempotent; and that's why I stated the theorem above. I'll be thankful if you provide a solution for the first theorem and not a different method to prove the original theorem in a different way.","I was not able to prove the following theorem. I would appreciate some help regarding it: If the product of each two idempotent elements in a unity ring is an idempotent element itself, prove that the product of idempotent and a specifically non-idempotent element is commutative. (The ring is a unity ring).  In notation: I'm very new to group theory in general, so I can't properly find an example to demonstrate my point. I'm not even aware exactly of terms such as ""ideals"" etc. I will however state the original theorem which this was a derivative of: For a unity ring , prove that if the product of two idempotent elements is also idempotent, then all idempotent elements of the ring are an element of its center. Since one has to prove that for all elements of the ring multiplied by an arbitrary idempotent element such as have the commutative property, I divided the case for the arbitrary element in two cases: for which is idempotent, and for which is not. I was able to prove that if is idempotent, the commutative property holds for its product with (the arbitrary idempotent element of ), but I wasn't able to do it for when is strictly non-idempotent; and that's why I stated the theorem above. I'll be thankful if you provide a solution for the first theorem and not a different method to prove the original theorem in a different way.",R \forall a \in R \forall x \in R (a^2=a \land x^2 \neq x \longrightarrow xa=ax). R R a x x x x a a x,"['abstract-algebra', 'ring-theory', 'idempotents']"
56,Rings with non-zero intersection of all non-zero ideals,Rings with non-zero intersection of all non-zero ideals,,"Let $R$ be a ring such that $\bigcap_{I\neq 0} I \neq 0$ , ie. has a non-zero intersection of all non-zero ideals. This is equivalent to ask for the existence of an element $a\in R$ which is a multiple of all non-zero elements of the ring. What can be said of such rings? Can they be classified? Right now the only examples I can think of are $\Bbb Z/(p^k)$ and fields. I also know that if $R$ is an integral domain with this property then it must be a field. Are there other examples? Thank you in advance.","Let be a ring such that , ie. has a non-zero intersection of all non-zero ideals. This is equivalent to ask for the existence of an element which is a multiple of all non-zero elements of the ring. What can be said of such rings? Can they be classified? Right now the only examples I can think of are and fields. I also know that if is an integral domain with this property then it must be a field. Are there other examples? Thank you in advance.",R \bigcap_{I\neq 0} I \neq 0 a\in R \Bbb Z/(p^k) R,"['abstract-algebra', 'ring-theory']"
57,Intuition for the invariance lemma,Intuition for the invariance lemma,,"The invariance lemma, as stated below, is commonly used to prove Lie’s theorem. Lemma (Invariance lemma). Let $\mathbb{k}$ be a field of characteristic zero. Let $\mathfrak{g}$ be a $\mathbb{k}$ -Lie algebra, let $M$ be a finite-dimensional representation of $\mathfrak{g}$ and let $I$ be an ideal of $\mathfrak{g}$ . Let $\lambda$ be an element of the dual space $I^*$ and let $$   M_\lambda   :=   \{     m \in M     \mid     \text{$x m = \lambda(x) m$ for all $x \in I$}   \} $$ be the corresponding $I$ -weight space of $M$ . This weight space is already a $\mathfrak{g}$ -subrepresentation of $M$ . Every time I’m reading through my old notes on representation theory of Lie algebras I’m wondering where this lemma comes from. I have no intuition for why it should be true, and if I hadn’t seen a proof of it I would probably even suspect it to be false. What is the intuition behind the invariance lemma?","The invariance lemma, as stated below, is commonly used to prove Lie’s theorem. Lemma (Invariance lemma). Let be a field of characteristic zero. Let be a -Lie algebra, let be a finite-dimensional representation of and let be an ideal of . Let be an element of the dual space and let be the corresponding -weight space of . This weight space is already a -subrepresentation of . Every time I’m reading through my old notes on representation theory of Lie algebras I’m wondering where this lemma comes from. I have no intuition for why it should be true, and if I hadn’t seen a proof of it I would probably even suspect it to be false. What is the intuition behind the invariance lemma?","\mathbb{k} \mathfrak{g} \mathbb{k} M \mathfrak{g} I \mathfrak{g} \lambda I^* 
  M_\lambda
  :=
  \{
    m \in M
    \mid
    \text{x m = \lambda(x) m for all x \in I}
  \}
 I M \mathfrak{g} M","['abstract-algebra', 'representation-theory', 'lie-algebras', 'intuition']"
58,Functoriality of the module of Kähler differentials,Functoriality of the module of Kähler differentials,,"In Eisenbud's Commutative Algebra , at the start of Chapter 16, he describes the module of Kähler differentials: given a ring $R$ and an $R$ -algebra $S$ , we have the associated $S$ -module $\Omega_{S/R}$ . This comes equipped with an $R$ -module homomorphism $d: S \to \Omega_{S/R}$ , called the universal $R$ -linear derivation , which satisfies an associated universal property. He goes on to state that the module of Kähler differentials is functorial in the following sense: given a commutative diagram of rings $\require{AMScd}$ \begin{CD} R @>>> R'\\ @V{}VV @VVV\\ S @>>> S', \end{CD} where $S$ is an $R$ -algebra, and $S'$ is an $R'$ -algebra, there is a commutative square of abelian groups $\require{AMScd}$ \begin{CD} S @>>> S'\\ @V{d}VV @VV{d}V\\ \Omega_{S/R} @>>> \Omega_{S'/R'}, \end{CD} where $S \to S'$ is the associated $R$ -algebra homomorphism, $\Omega_{S/R} \to \Omega_{S'/R'}$ is an $S$ -module homomorphism, and $d$ denotes the universal derivation in each context. As Eisenbud notes, this is quite complicated to state. I am curious if this can be rephrased in a simpler way. My question can be stated concisely as follows: As the module of Kähler differentials is functorial, we should be able to understand it as a functor of the form $\Omega_{-/-}: \mathscr{C} \to \mathscr{D}$ . In this context, what are the categories $\mathscr{C}$ and $\mathscr{D}$ ? Once question 1 is answered, how do you understand the universal property of the module of Kähler differentials in this categorical framework?","In Eisenbud's Commutative Algebra , at the start of Chapter 16, he describes the module of Kähler differentials: given a ring and an -algebra , we have the associated -module . This comes equipped with an -module homomorphism , called the universal -linear derivation , which satisfies an associated universal property. He goes on to state that the module of Kähler differentials is functorial in the following sense: given a commutative diagram of rings where is an -algebra, and is an -algebra, there is a commutative square of abelian groups where is the associated -algebra homomorphism, is an -module homomorphism, and denotes the universal derivation in each context. As Eisenbud notes, this is quite complicated to state. I am curious if this can be rephrased in a simpler way. My question can be stated concisely as follows: As the module of Kähler differentials is functorial, we should be able to understand it as a functor of the form . In this context, what are the categories and ? Once question 1 is answered, how do you understand the universal property of the module of Kähler differentials in this categorical framework?","R R S S \Omega_{S/R} R d: S \to \Omega_{S/R} R \require{AMScd} \begin{CD}
R @>>> R'\\
@V{}VV @VVV\\
S @>>> S',
\end{CD} S R S' R' \require{AMScd} \begin{CD}
S @>>> S'\\
@V{d}VV @VV{d}V\\
\Omega_{S/R} @>>> \Omega_{S'/R'},
\end{CD} S \to S' R \Omega_{S/R} \to \Omega_{S'/R'} S d \Omega_{-/-}: \mathscr{C} \to \mathscr{D} \mathscr{C} \mathscr{D}","['abstract-algebra', 'commutative-algebra', 'category-theory', 'modules']"
59,A weak cancellation property for monoids,A weak cancellation property for monoids,,"Suppose $M$ is a (commutative) monoid. Typically the cancellation property is defined as $a + c = b + c \Rightarrow a = b$ for all $a,b,c \in M$ . Recently I was working on a problem where I thought I needed cancellation, but it turned out that the weaker version $a + c = c \Rightarrow a = 0$ for all $a,c \in M$ would already be sufficient. My questions are: Is this actually a weaker property than cancellation? It is implied by cancellation by choosing $b = 0$ , but despite trying some things out myself I am not yet 100% convinced that it is not just cancellation in disguise. If it is actually a weaker version of cancellation, is there some reading or other material on it anywhere or does it even have a name? Note: Commutativity is not really needed, but it was where I stumbled upon this so I just kept it for the sake of simplicity.","Suppose is a (commutative) monoid. Typically the cancellation property is defined as for all . Recently I was working on a problem where I thought I needed cancellation, but it turned out that the weaker version for all would already be sufficient. My questions are: Is this actually a weaker property than cancellation? It is implied by cancellation by choosing , but despite trying some things out myself I am not yet 100% convinced that it is not just cancellation in disguise. If it is actually a weaker version of cancellation, is there some reading or other material on it anywhere or does it even have a name? Note: Commutativity is not really needed, but it was where I stumbled upon this so I just kept it for the sake of simplicity.","M a + c = b + c \Rightarrow a = b a,b,c \in M a + c = c \Rightarrow a = 0 a,c \in M b = 0","['abstract-algebra', 'monoid']"
60,Non-zero element in exterior power,Non-zero element in exterior power,,"Let $R=\mathbb{Z}[\sqrt{5}]$ and consider $I=(2,\, 1+\sqrt{5})$ as an $R$ -module. I'm struggling to prove that the element $2\wedge (1+\sqrt{5})$ of the exterior power $\Lambda^2(I)$ is non-zero. I should construct some alternating bilinear map from $I\times I$ in $\mathbb{Z}$ (regarded in some way as an $R$ -module?) not sending $(2,\, 1+\sqrt{5})$ in $0$ : I'm thinking of something similar to the determinant since each element $u\in I$ can be expressed as $2a+b(1+\sqrt{5})$ , but it seems it doesn't work so well... Any idea about how to do this? See also Remark 4.7 here: https://kconrad.math.uconn.edu/blurbs/linmultialg/extmod.pdf","Let and consider as an -module. I'm struggling to prove that the element of the exterior power is non-zero. I should construct some alternating bilinear map from in (regarded in some way as an -module?) not sending in : I'm thinking of something similar to the determinant since each element can be expressed as , but it seems it doesn't work so well... Any idea about how to do this? See also Remark 4.7 here: https://kconrad.math.uconn.edu/blurbs/linmultialg/extmod.pdf","R=\mathbb{Z}[\sqrt{5}] I=(2,\, 1+\sqrt{5}) R 2\wedge (1+\sqrt{5}) \Lambda^2(I) I\times I \mathbb{Z} R (2,\, 1+\sqrt{5}) 0 u\in I 2a+b(1+\sqrt{5})","['abstract-algebra', 'ring-theory', 'tensor-products']"
61,$G$ is a non-abelian group of order 6 $ \implies G \approx S_3 $. Simpler proof?,is a non-abelian group of order 6 . Simpler proof?,G  \implies G \approx S_3 ,"I've seen some proofs of this fact but they seemed more complicated than necessary, so I've tried to come up with my own, which is hopefully simpler. Can you kindly tell me if it's correct? Proof. $G$ cannot have an element of order 6, else it would be cyclic and thus abelian. So the elements of $G$ different from $e$ can only have order 3 or 2. If all $g \in G$ have order 2 then $G$ is abelian, so there must be at least one element $a \in G$ of order 3. The subgroup $H= \langle a \rangle$ is normal in $G$ because its index is 2. $G/H$ is a cyclic group of order 2. Let $b \not \in H$ . We have $(bH)^2=H \implies b^2 \in H$ . If $o(b)=3$ , then $ b=b^4=b^2b^2 \in H$ , a contradiction. So we must conclude that every $g \in bH$ has order 2. We have $G= H \cup bH = \{e, a, a^2, b, ba, ba^2 \}$ .  Moreover, $ab \in Hb = bH$ so $(ab)^2=e$ . Then $ab=b^{-1}a^{-1}=ba^2$ , which is exactly the relation in $S_3$ . $\square$","I've seen some proofs of this fact but they seemed more complicated than necessary, so I've tried to come up with my own, which is hopefully simpler. Can you kindly tell me if it's correct? Proof. cannot have an element of order 6, else it would be cyclic and thus abelian. So the elements of different from can only have order 3 or 2. If all have order 2 then is abelian, so there must be at least one element of order 3. The subgroup is normal in because its index is 2. is a cyclic group of order 2. Let . We have . If , then , a contradiction. So we must conclude that every has order 2. We have .  Moreover, so . Then , which is exactly the relation in .","G G e g \in G G a \in G H= \langle a \rangle G G/H b \not \in H (bH)^2=H \implies b^2 \in H o(b)=3  b=b^4=b^2b^2 \in H g \in bH G= H \cup bH = \{e, a, a^2, b, ba, ba^2 \} ab \in Hb = bH (ab)^2=e ab=b^{-1}a^{-1}=ba^2 S_3 \square","['abstract-algebra', 'group-theory', 'proof-verification', 'finite-groups', 'group-isomorphism']"
62,"Prove that $[\mathbf{Q}(\sqrt{1+i},\sqrt{2}):\mathbf{Q}]=8$.",Prove that .,"[\mathbf{Q}(\sqrt{1+i},\sqrt{2}):\mathbf{Q}]=8","I am trying to calculate the Galois group of the polynomial $f=X^4-2X^2+2$ . $f$ is Eisenstein with $p=2$ , so irreducible over $\mathbf{Q}$ . I calculated the zeros to be $\alpha_1=\sqrt{1+i},\alpha_2=\sqrt{1-i},\alpha_3=-\alpha_1$ and $\alpha_4=-\alpha_2$ . Let $\Omega_f=\mathbf{Q}(\alpha_1,\alpha_2,\alpha_3,\alpha_4)=\mathbf{Q}(\alpha_1,\alpha_2)$ be a splitting field of $f$ over $\mathbf{Q}$ . Since $\alpha_1\alpha_2=\sqrt{1+i}\sqrt{1-i}=\sqrt{2}$ , we have $\Omega_f=\mathbf{Q}(\sqrt{1+i},\sqrt{2})$ . So if we can prove that $[\Omega_f:\mathbf{Q}]=8$ , then we have $\#\operatorname{Gal} (f)=8$ and for $\operatorname{Gal}(f)\subset S_4$ , we must have that it is isomorphic to the dihedral group $D_4$ . How do I go about proving $[\mathbf{Q}(\sqrt{1+i},\sqrt{2})]=8$ ?","I am trying to calculate the Galois group of the polynomial . is Eisenstein with , so irreducible over . I calculated the zeros to be and . Let be a splitting field of over . Since , we have . So if we can prove that , then we have and for , we must have that it is isomorphic to the dihedral group . How do I go about proving ?","f=X^4-2X^2+2 f p=2 \mathbf{Q} \alpha_1=\sqrt{1+i},\alpha_2=\sqrt{1-i},\alpha_3=-\alpha_1 \alpha_4=-\alpha_2 \Omega_f=\mathbf{Q}(\alpha_1,\alpha_2,\alpha_3,\alpha_4)=\mathbf{Q}(\alpha_1,\alpha_2) f \mathbf{Q} \alpha_1\alpha_2=\sqrt{1+i}\sqrt{1-i}=\sqrt{2} \Omega_f=\mathbf{Q}(\sqrt{1+i},\sqrt{2}) [\Omega_f:\mathbf{Q}]=8 \#\operatorname{Gal} (f)=8 \operatorname{Gal}(f)\subset S_4 D_4 [\mathbf{Q}(\sqrt{1+i},\sqrt{2})]=8","['abstract-algebra', 'galois-theory', 'splitting-field']"
63,Degree of splitting field of $X^4+2X^2+2$ over $\mathbf{Q}$,Degree of splitting field of  over,X^4+2X^2+2 \mathbf{Q},"Find the degree of splitting field of $f=X^4+2X^2+2$ over $\mathbf{Q}$ . By Eisenstein, $f$ is irreducible. By setting $Y=X^2$ , we can solve for the roots: $Y=-1\pm i \iff X=\sqrt[4]{2}e^{a\pi i/8}$ , $a\in\{3,5,11,13\}$ . Clearly $f$ splits in $\mathbf{Q}(\sqrt[4]{2},\zeta_{16})$ . $\zeta_{16}$ is a zero of $X^8+1$ , which is irreducible over $\mathbf{Q}$ by Eisenstein applied to $(X+1)^8+1$ . I was not able to go further. Could someone help me to proceed?","Find the degree of splitting field of over . By Eisenstein, is irreducible. By setting , we can solve for the roots: , . Clearly splits in . is a zero of , which is irreducible over by Eisenstein applied to . I was not able to go further. Could someone help me to proceed?","f=X^4+2X^2+2 \mathbf{Q} f Y=X^2 Y=-1\pm i \iff X=\sqrt[4]{2}e^{a\pi i/8} a\in\{3,5,11,13\} f \mathbf{Q}(\sqrt[4]{2},\zeta_{16}) \zeta_{16} X^8+1 \mathbf{Q} (X+1)^8+1","['abstract-algebra', 'galois-theory', 'irreducible-polynomials', 'splitting-field', 'quartics']"
64,Blow-up of affine space along subvariety,Blow-up of affine space along subvariety,,"Brief summary of the question: Let $C\subset \mathbb A^n$ be a singular curve and $\pi:X=Bl_C\mathbb A^n\to \mathbb A^n$ be the blow-up along $C$ . 1) Is there a reference showing that $\pi^{-1}(C)=\mathbb P(\mathcal N_{C/\mathbb A^n})$ ? 2) Is $\pi^{-1}(C)\to C$ a locally trivial algebraic $\mathbb P^{n-2}$ -bundle, i.e. locally looking like $C\times \mathbb P^{n-2}$ ? Or is it rather looking like $Bl_pC\times \mathbb P^{n-2}$ where $p$ is the singular point of $C$ ? I was reading about blow-ups along sub varieties recently in Shafarevich's book and have a question concerning it. Let us take a curve $C$ in $\mathbb A^n$ and consider $X=Bl_C\mathbb A^n$ . Since $C$ is one-dimensional, we need (locally) $m=n-1$ equations to define it and thus, according to my textbook, $$X\subset \mathbb A^n\times \mathbb P^{m-1}=\mathbb A^n\times \mathbb P^{n-2}.$$ Back to the curve case, locally the situation can be described explicitly and over each point of $C$ we find a $\mathbb P^{n-2}$ in $X$ . In particular, $\pi^{-1}(C)\to C$ is an algebraic fibre bundle with fibres $\mathbb P^{n-2}$ . By $\pi$ I of course mean the blow-up map. Shafarevich further gives the nice global description that $$\pi^{-1}(C)=\mathbb P(N_{C/\mathbb A^n}),$$ where $N_{C/ \mathbb A^n}$ denotes the normal bundle. So far so good, I think I understood that, at least the parts from the book. Now, if $C$ is a curve with a singular point, say $p\in C$ , I think we have a similar description and that $$\pi^{-1}(C)=\mathbb P(\mathcal N_{C/ \mathbb A^n}),$$ where $\mathcal N_{C/ \mathbb A^n}$ denotes the normal sheaf . Is this correct? The only reference I have for blow-ups along general subschemes I could find was the Algebraic geometry book by Hartshorne and I can't translate his description of blowing up into the one by Shafarevich. So if you can give me some reference you would really help me. Up to this point I think myself to be more or less on the safe side. However, I was thinking about how $\mathbb P (\mathcal N_{C/ \mathbb A^n})$ will look like in general and how I can interpret such a blow-up along $C$ . My naive thinking is that we kind of blow-up all point on $C$ at once. But then we would in particular blow-up the singular point of $C$ . So does $\mathcal N_{C/ \mathbb A^n}$ locally look like $C\times \mathbb P^{n-2}$ or rather like $Bl_pC\times \mathbb P^{n-2}$ ? And if the latter is the case, what happens to the divisor from the blow-up of $C$ at $p$ ? I hope this question is not too vague. If there is a way to improve it, please let me know. I'm aware that a question is supposed to show ""research effort"" but since these questions just came to me whilst reading a textbook, I don't really have a clue of how to start and was unable to say more than what I just wrote. EDIT: Here are some examples: 1) $C=\{x^2+y^2+z=z=0\}\subset \mathbb A^3$ . The blow-up is given in the respective affine charts by $a_0(x^2+y^2)=0$ and $a_1(x^2+y^2)=0$ . So here it looks like $C\times \mathbb P^1$ . 2) $C=\{xy+z^2=x^3+y^3=0\}\subset \mathbb A^3$ . In the respective charts we obtain $$a_0(xy+z^2)=x^3+y^3=0\quad\text{and}\quad xy+z^2=a_1(x^3+y^3)=0.$$ And here I am unable to proceed. Probably more light can be shed on the situation by computing the normal sheaf explicitly. I asked a related question Compute normal sheaf from equations some time ago but I can't manage to adapt the answer to the new situation here.","Brief summary of the question: Let be a singular curve and be the blow-up along . 1) Is there a reference showing that ? 2) Is a locally trivial algebraic -bundle, i.e. locally looking like ? Or is it rather looking like where is the singular point of ? I was reading about blow-ups along sub varieties recently in Shafarevich's book and have a question concerning it. Let us take a curve in and consider . Since is one-dimensional, we need (locally) equations to define it and thus, according to my textbook, Back to the curve case, locally the situation can be described explicitly and over each point of we find a in . In particular, is an algebraic fibre bundle with fibres . By I of course mean the blow-up map. Shafarevich further gives the nice global description that where denotes the normal bundle. So far so good, I think I understood that, at least the parts from the book. Now, if is a curve with a singular point, say , I think we have a similar description and that where denotes the normal sheaf . Is this correct? The only reference I have for blow-ups along general subschemes I could find was the Algebraic geometry book by Hartshorne and I can't translate his description of blowing up into the one by Shafarevich. So if you can give me some reference you would really help me. Up to this point I think myself to be more or less on the safe side. However, I was thinking about how will look like in general and how I can interpret such a blow-up along . My naive thinking is that we kind of blow-up all point on at once. But then we would in particular blow-up the singular point of . So does locally look like or rather like ? And if the latter is the case, what happens to the divisor from the blow-up of at ? I hope this question is not too vague. If there is a way to improve it, please let me know. I'm aware that a question is supposed to show ""research effort"" but since these questions just came to me whilst reading a textbook, I don't really have a clue of how to start and was unable to say more than what I just wrote. EDIT: Here are some examples: 1) . The blow-up is given in the respective affine charts by and . So here it looks like . 2) . In the respective charts we obtain And here I am unable to proceed. Probably more light can be shed on the situation by computing the normal sheaf explicitly. I asked a related question Compute normal sheaf from equations some time ago but I can't manage to adapt the answer to the new situation here.","C\subset \mathbb A^n \pi:X=Bl_C\mathbb A^n\to \mathbb A^n C \pi^{-1}(C)=\mathbb P(\mathcal N_{C/\mathbb A^n}) \pi^{-1}(C)\to C \mathbb P^{n-2} C\times \mathbb P^{n-2} Bl_pC\times \mathbb P^{n-2} p C C \mathbb A^n X=Bl_C\mathbb A^n C m=n-1 X\subset \mathbb A^n\times \mathbb P^{m-1}=\mathbb A^n\times \mathbb P^{n-2}. C \mathbb P^{n-2} X \pi^{-1}(C)\to C \mathbb P^{n-2} \pi \pi^{-1}(C)=\mathbb P(N_{C/\mathbb A^n}), N_{C/ \mathbb A^n} C p\in C \pi^{-1}(C)=\mathbb P(\mathcal N_{C/ \mathbb A^n}), \mathcal N_{C/ \mathbb A^n} \mathbb P (\mathcal N_{C/ \mathbb A^n}) C C C \mathcal N_{C/ \mathbb A^n} C\times \mathbb P^{n-2} Bl_pC\times \mathbb P^{n-2} C p C=\{x^2+y^2+z=z=0\}\subset \mathbb A^3 a_0(x^2+y^2)=0 a_1(x^2+y^2)=0 C\times \mathbb P^1 C=\{xy+z^2=x^3+y^3=0\}\subset \mathbb A^3 a_0(xy+z^2)=x^3+y^3=0\quad\text{and}\quad xy+z^2=a_1(x^3+y^3)=0.",['abstract-algebra']
65,Non cyclic group of order $p^3$ satisfies $G \simeq H \rtimes_{\theta}K$,Non cyclic group of order  satisfies,p^3 G \simeq H \rtimes_{\theta}K,"Let $G$ be a non-cyclic group of order $p^3$ for an odd prime $p$ . Prove that $G \simeq H \rtimes_{\theta}K$ , where $H$ is a normal subgroup of $G$ of order $p^2$ , $K$ is a subgroup of order $p$ , and $\theta : K \to Aut(H)$ is a homomorphism. I managed to prove that there exists a normal subgroup $H$ of order $p^2$ . Then I took some $g \in G-H$ . If $g$ is of order $p$ , I am done since $G \simeq H \rtimes \langle g \rangle $ . But what if all $g \in G - H$ are of order $p^2 $ ?","Let be a non-cyclic group of order for an odd prime . Prove that , where is a normal subgroup of of order , is a subgroup of order , and is a homomorphism. I managed to prove that there exists a normal subgroup of order . Then I took some . If is of order , I am done since . But what if all are of order ?",G p^3 p G \simeq H \rtimes_{\theta}K H G p^2 K p \theta : K \to Aut(H) H p^2 g \in G-H g p G \simeq H \rtimes \langle g \rangle  g \in G - H p^2 ,"['abstract-algebra', 'group-theory', 'finite-groups', 'semidirect-product']"
66,Showing $Tr_{L/K} \circ Tr_{M/L} = Tr_{M/K}$ where $K \subseteq L \subseteq M$ is a tower of field extensions - *Algebraic Number Theory* by Neukerich,Showing  where  is a tower of field extensions - *Algebraic Number Theory* by Neukerich,Tr_{L/K} \circ Tr_{M/L} = Tr_{M/K} K \subseteq L \subseteq M,"I'm reading Algebraic Number Theory by Neukirch and I'm having trouble the proof for the statement: (2.7) Corollary: I a tower of finite field extensions $K \subseteq L \subseteq M$ , one has $$Tr_{L/K} \circ Tr_{M/L} = Tr_{M/K}, \qquad N_{L/K} \circ N_{M/L} = N_{M/K}.$$ Here we assume $M/K$ is separable. The part of the proof im having trouble with is the identity $$Tr_{M/K}(x) = \sum_{i = 1}^{m}\sum_{\sigma \sim \sigma_{i}}\sigma(x) = \sum_{i = 1}^{m}Tr_{\sigma_{i}M/\sigma_{i}L}(\sigma_{i}(x)) = \sum_{i = 1}^{m}\sigma_{i}Tr_{M/L}(x) = Tr_{L/K}(Tr_{M/L}(x))$$ where $m = [L:K]$ and the $\sigma_{i}$ are representatives for equivalence classes under the relation $\sigma \sim \tau \iff \sigma|_{L} = \tau|_{L}$ . I believe the first equality, but I don't see how the second and third hold. I understand the $\sigma:M \rightarrow \overline{K}$ in $[\sigma_{i}]$ are $K$ -embeddings, and hence restricted to $L$ are also $K$ -embeddings, but I dont see how the inner sum corresponds to $Tr_{\sigma_{i}M/\sigma_{i}L}(\sigma_{i}(x))$ . We can express $Tr_{\sigma_{i}M/\sigma_{i}L}(\sigma_{i}(x))$ as a sum of $\sigma_{i}L$ embeddings from $\sigma_{i}M$ into $\overline{\sigma_{i}L}$ evaluated at $\sigma_{i}(x)$ but these aren't the $\sigma$ in $\sigma_{i}$ above, are they? They certainly don't look like them as maps. Also what justification do we have to factor the $\sigma_{i}$ out in the third equality? I think these two questions have trivial answers, but I just cant see it. Any help is appreciated!","I'm reading Algebraic Number Theory by Neukirch and I'm having trouble the proof for the statement: (2.7) Corollary: I a tower of finite field extensions , one has Here we assume is separable. The part of the proof im having trouble with is the identity where and the are representatives for equivalence classes under the relation . I believe the first equality, but I don't see how the second and third hold. I understand the in are -embeddings, and hence restricted to are also -embeddings, but I dont see how the inner sum corresponds to . We can express as a sum of embeddings from into evaluated at but these aren't the in above, are they? They certainly don't look like them as maps. Also what justification do we have to factor the out in the third equality? I think these two questions have trivial answers, but I just cant see it. Any help is appreciated!","K \subseteq L \subseteq M Tr_{L/K} \circ Tr_{M/L} = Tr_{M/K}, \qquad N_{L/K} \circ N_{M/L} = N_{M/K}. M/K Tr_{M/K}(x) = \sum_{i = 1}^{m}\sum_{\sigma \sim \sigma_{i}}\sigma(x) = \sum_{i = 1}^{m}Tr_{\sigma_{i}M/\sigma_{i}L}(\sigma_{i}(x)) = \sum_{i = 1}^{m}\sigma_{i}Tr_{M/L}(x) = Tr_{L/K}(Tr_{M/L}(x)) m = [L:K] \sigma_{i} \sigma \sim \tau \iff \sigma|_{L} = \tau|_{L} \sigma:M \rightarrow \overline{K} [\sigma_{i}] K L K Tr_{\sigma_{i}M/\sigma_{i}L}(\sigma_{i}(x)) Tr_{\sigma_{i}M/\sigma_{i}L}(\sigma_{i}(x)) \sigma_{i}L \sigma_{i}M \overline{\sigma_{i}L} \sigma_{i}(x) \sigma \sigma_{i} \sigma_{i}","['abstract-algebra', 'field-theory']"
67,Cap product for Hochschild (co)chains,Cap product for Hochschild (co)chains,,"Let $A$ be an associative algebra and $M$ be an $A$ -bimodule. Then we can form the Hochschild cochains $C^\bullet(A,A)$ and chains $C_\bullet(A, M)$ and define a pairing (cap product) $$   C^\bullet(A,A) \otimes C_\bullet(A, M)   \xrightarrow{\enspace\frown\enspace}   C_\bullet(A, M) $$ in the following way: for $f\in C^n(A,A)$ and $g = m \otimes a_1 \otimes \dotsb \otimes a_p \in C_p(A,M)$ , $$f\frown g :=  \begin{cases}   (-1)^n m f(a_1 \otimes \dotsb \otimes a_n) \otimes a_{n+1} \otimes \dotsb \otimes a_n & \text{for $p \geq n$},\\   0 & \text{for $p < n$}, \end{cases}   $$ which is an element of $C_{n-p}(A, M)$ . There is the following simple assertion: Proposition. $C_\bullet(A, M)$ is a differential graded module over $C^\bullet(A, A)$ with respect to the cap product, i.e., $$   d(f \frown g) = d(f) \frown g + (-1)^{\deg(f)} f \frown d(g) \,.   \tag{1} $$ The reference for this is https://pbelmans.ncag.info/assets/hh-2018-notes.pdf page 24 or http://www.math.tamu.edu/~sarah.witherspoon/pub/HH-25August2018.pdf page 17. This looked to be an easy exercise, but even in simple cases the computations went wrong. For example, let $f \in C^1(A, A)$ and $g = m \otimes a_1 \otimes a_2 \in C_2(A, M)$ . Then $f \frown g = -m f(a_1) \otimes a_2$ and the left-hand side of $(1)$ is $$   d(f \frown g)   = d(-m f(a_1) \otimes a_2)   = -(m f(a_1) a_2 - a_2 m f(a_1))   = a_2 m f(a_1) - m f(a_1) a_2 \,. $$ At the same time, the right-hand side is \begin{align*}   {}&   d(f) \frown g + (-1)^{\deg(f)} f \frown d(g) \\   ={}& m \cdot d(f)(a_1 \otimes a_2) - f \frown (m a_1 \otimes a_2 - m \otimes a_1 a_2 + a_2 m \otimes a_1) \\   ={}& m a_1 f(a_2) - m f(a_1 a_2) + m f(a_1) a_2 + m a_1 f(a_2) - m f(a_1 a_2) + a_2 m f(a_1) \\   ={}& 2 m a_1 f(a_2) - 2 m f(a_1 a_2) + m f(a_1) a_2 + a_2 m f(a_1) \,. \end{align*} These two expressions obviously do not coincide. Where I was wrong? Edit. It seems that there is a sign mistake in the definition of the cap product given above and the right definition should be $$   f \frown g := m f(a_1 \otimes \dotsb \otimes a_n) \otimes a_{n+1} \otimes \dotsb \otimes a_n \,. $$","Let be an associative algebra and be an -bimodule. Then we can form the Hochschild cochains and chains and define a pairing (cap product) in the following way: for and , which is an element of . There is the following simple assertion: Proposition. is a differential graded module over with respect to the cap product, i.e., The reference for this is https://pbelmans.ncag.info/assets/hh-2018-notes.pdf page 24 or http://www.math.tamu.edu/~sarah.witherspoon/pub/HH-25August2018.pdf page 17. This looked to be an easy exercise, but even in simple cases the computations went wrong. For example, let and . Then and the left-hand side of is At the same time, the right-hand side is These two expressions obviously do not coincide. Where I was wrong? Edit. It seems that there is a sign mistake in the definition of the cap product given above and the right definition should be","A M A C^\bullet(A,A) C_\bullet(A, M) 
  C^\bullet(A,A) \otimes C_\bullet(A, M)
  \xrightarrow{\enspace\frown\enspace}
  C_\bullet(A, M)
 f\in C^n(A,A) g = m \otimes a_1 \otimes \dotsb \otimes a_p \in C_p(A,M) f\frown g := 
\begin{cases}
  (-1)^n m f(a_1 \otimes \dotsb \otimes a_n) \otimes a_{n+1} \otimes \dotsb \otimes a_n & \text{for p \geq n},\\
  0 & \text{for p < n},
\end{cases}
   C_{n-p}(A, M) C_\bullet(A, M) C^\bullet(A, A) 
  d(f \frown g) = d(f) \frown g + (-1)^{\deg(f)} f \frown d(g) \,.
  \tag{1}
 f \in C^1(A, A) g = m \otimes a_1 \otimes a_2 \in C_2(A, M) f \frown g = -m f(a_1) \otimes a_2 (1) 
  d(f \frown g)
  = d(-m f(a_1) \otimes a_2)
  = -(m f(a_1) a_2 - a_2 m f(a_1))
  = a_2 m f(a_1) - m f(a_1) a_2 \,.
 \begin{align*}
  {}&
  d(f) \frown g + (-1)^{\deg(f)} f \frown d(g) \\
  ={}& m \cdot d(f)(a_1 \otimes a_2) - f \frown (m a_1 \otimes a_2 - m \otimes a_1 a_2 + a_2 m \otimes a_1) \\
  ={}& m a_1 f(a_2) - m f(a_1 a_2) + m f(a_1) a_2 + m a_1 f(a_2) - m f(a_1 a_2) + a_2 m f(a_1) \\
  ={}& 2 m a_1 f(a_2) - 2 m f(a_1 a_2) + m f(a_1) a_2 + a_2 m f(a_1) \,.
\end{align*} 
  f \frown g := m f(a_1 \otimes \dotsb \otimes a_n) \otimes a_{n+1} \otimes \dotsb \otimes a_n \,.
","['abstract-algebra', 'homological-algebra', 'hochschild-cohomology']"
68,Intuition about turning a polynomial ring into a field,Intuition about turning a polynomial ring into a field,,"Let's consider the polynomial ring $R=F[x]$ over a field $F$. Then by taking the quotient by a principal ideal $I=(f(x))$ generated by an irreducible polynomial $f(x)$, we obtain a field $R'=F[x]/(f(x))$. It's easy to see that $R'$ is indeed a field. Since the ideals of $R$ which contain $I$ are in bijective correspondence with the ideals of $R'$, we can conclude that $R'$ has only two ideals and is therefore a field (as $I$ is maximal in $R$ since $f(x)$ is irreducible). I wanted to ask, is there an intuitive way of understanding why taking the quotient by some ideal makes $F[x]$ into a field? I would ideally like some way of demonstrating that the existence of a nonzero polynomial equivalent to zero in $R'$ somehow allows us to describe an algorithm to calculate multiplicative inverses...","Let's consider the polynomial ring $R=F[x]$ over a field $F$. Then by taking the quotient by a principal ideal $I=(f(x))$ generated by an irreducible polynomial $f(x)$, we obtain a field $R'=F[x]/(f(x))$. It's easy to see that $R'$ is indeed a field. Since the ideals of $R$ which contain $I$ are in bijective correspondence with the ideals of $R'$, we can conclude that $R'$ has only two ideals and is therefore a field (as $I$ is maximal in $R$ since $f(x)$ is irreducible). I wanted to ask, is there an intuitive way of understanding why taking the quotient by some ideal makes $F[x]$ into a field? I would ideally like some way of demonstrating that the existence of a nonzero polynomial equivalent to zero in $R'$ somehow allows us to describe an algorithm to calculate multiplicative inverses...",,"['abstract-algebra', 'polynomials']"
69,How to show that $Z/12Z×Z/90Z×Z/25Z$ and $Z/100Z×Z/30Z×Z/9Z$ are isomorph?,How to show that  and  are isomorph?,Z/12Z×Z/90Z×Z/25Z Z/100Z×Z/30Z×Z/9Z,How to show that $G = \Bbb Z/12\Bbb Z \times \Bbb Z/90 \Bbb Z\times \Bbb Z/25 \Bbb Z$ and  $H = \Bbb Z/100 \Bbb Z \times \Bbb Z/30\Bbb Z\times \Bbb Z/9\Bbb Z$ are isomorph? The way I would go is to use the decomposition in primary groups: For G: $12 = 2^2 * 3$ $90 = 3^2*2*5$ $25 = 5^2$ So $G \simeq G(2) \times G(3) \times G(5)$ with $G(2)= (\Bbb Z/2\Bbb Z) \times (\Bbb Z/2^2\Bbb Z)$ $G(3)= (\Bbb Z/3\Bbb Z) \times (\Bbb Z/3^2\Bbb Z)$ $G(5)= (\Bbb Z/5\Bbb Z) \times (\Bbb Z/5^2\Bbb Z)$ For H: $100 = 5^2 * 2^2$ $30 = 5*3*2$ $9 = 3^2$ So $H \simeq H(2) \times H(3) \times H(5)$ with $H(2)= (\Bbb Z/2\Bbb Z) \times (\Bbb Z/2^2\Bbb Z)$ $H(3)= (\Bbb Z/3\Bbb Z) \times (\Bbb Z/3^2\Bbb Z)$ $H(5)= (\Bbb Z/5\Bbb Z) \times (\Bbb Z/5^2\Bbb Z)$ As $G$ and $H$ have the same decomposition they are isomorph. Is it right? Is there a better/faster/easier way to prove it?,How to show that $G = \Bbb Z/12\Bbb Z \times \Bbb Z/90 \Bbb Z\times \Bbb Z/25 \Bbb Z$ and  $H = \Bbb Z/100 \Bbb Z \times \Bbb Z/30\Bbb Z\times \Bbb Z/9\Bbb Z$ are isomorph? The way I would go is to use the decomposition in primary groups: For G: $12 = 2^2 * 3$ $90 = 3^2*2*5$ $25 = 5^2$ So $G \simeq G(2) \times G(3) \times G(5)$ with $G(2)= (\Bbb Z/2\Bbb Z) \times (\Bbb Z/2^2\Bbb Z)$ $G(3)= (\Bbb Z/3\Bbb Z) \times (\Bbb Z/3^2\Bbb Z)$ $G(5)= (\Bbb Z/5\Bbb Z) \times (\Bbb Z/5^2\Bbb Z)$ For H: $100 = 5^2 * 2^2$ $30 = 5*3*2$ $9 = 3^2$ So $H \simeq H(2) \times H(3) \times H(5)$ with $H(2)= (\Bbb Z/2\Bbb Z) \times (\Bbb Z/2^2\Bbb Z)$ $H(3)= (\Bbb Z/3\Bbb Z) \times (\Bbb Z/3^2\Bbb Z)$ $H(5)= (\Bbb Z/5\Bbb Z) \times (\Bbb Z/5^2\Bbb Z)$ As $G$ and $H$ have the same decomposition they are isomorph. Is it right? Is there a better/faster/easier way to prove it?,,"['abstract-algebra', 'group-theory', 'group-isomorphism']"
70,"On Atiyah-Macdonald, Exercise 1.22 [duplicate]","On Atiyah-Macdonald, Exercise 1.22 [duplicate]",,"This question already has an answer here : Show that a ring with disconnected spectrum is a product of two subrings. [duplicate] (1 answer) Closed 5 months ago . I am trying to solve the following question, which appears as the part of an exercise in Atiyah-Macdonald Chapter I.22: For a ring $A$, if $\mathrm{Spec}(A)$ is disconnected, then we have $A\cong A_1\times A_2$ for some rings $A_1,A_2$. Actually, the original question is to show three equivalent conditions and we can avoid the above. But I would like to see if there is a possibility to prove this. Here is my attempt: Let $\mathrm{Spec}(A)=V(I_1)\cup V(I_2)$, where $V(I_i)$ are proper closed sets and $V(I_1)\cap V(I_2)=\emptyset$. Then we have  $$I_1+I_2=(1)$$ So if we have $I_1\cap I_2=\{0\}$, we can use the Chinese remainder theorem to show  $$A\cong A/\{0\}\cong (A/I_1)\times (A/I_2)$$  then we are done. Unfortunately, from $V(I_1)\cup V(I_2)=V(I_1\cap I_2)=\mathrm{Spec}(A)$, we can only obtain  $$I_1\cap I_2\subset \mathfrak{N}$$ where $\mathfrak{N}$ is the nilradical of $A$. So I was wondering if we can shrink $I_1$ and $I_2$ so that complete the above argument. The obvious try is $I_1$ and the ideal generated by $I_2\setminus I_1$, but it is apparent to see $I_1\cap \langle I_2\setminus I_1 \rangle\neq \{0\}$... I really appreciate any kind of help!","This question already has an answer here : Show that a ring with disconnected spectrum is a product of two subrings. [duplicate] (1 answer) Closed 5 months ago . I am trying to solve the following question, which appears as the part of an exercise in Atiyah-Macdonald Chapter I.22: For a ring $A$, if $\mathrm{Spec}(A)$ is disconnected, then we have $A\cong A_1\times A_2$ for some rings $A_1,A_2$. Actually, the original question is to show three equivalent conditions and we can avoid the above. But I would like to see if there is a possibility to prove this. Here is my attempt: Let $\mathrm{Spec}(A)=V(I_1)\cup V(I_2)$, where $V(I_i)$ are proper closed sets and $V(I_1)\cap V(I_2)=\emptyset$. Then we have  $$I_1+I_2=(1)$$ So if we have $I_1\cap I_2=\{0\}$, we can use the Chinese remainder theorem to show  $$A\cong A/\{0\}\cong (A/I_1)\times (A/I_2)$$  then we are done. Unfortunately, from $V(I_1)\cup V(I_2)=V(I_1\cap I_2)=\mathrm{Spec}(A)$, we can only obtain  $$I_1\cap I_2\subset \mathfrak{N}$$ where $\mathfrak{N}$ is the nilradical of $A$. So I was wondering if we can shrink $I_1$ and $I_2$ so that complete the above argument. The obvious try is $I_1$ and the ideal generated by $I_2\setminus I_1$, but it is apparent to see $I_1\cap \langle I_2\setminus I_1 \rangle\neq \{0\}$... I really appreciate any kind of help!",,"['abstract-algebra', 'commutative-algebra']"
71,Show that $\cdots\circ$ Fr$^{3!}\circ$Fr$^{2!}\circ$ Fr$^{1!} \in\operatorname{Gal}(\overline{\mathbb F_p}/\mathbb F_p)\setminus\langle$ Fr $\rangle$,Show that  FrFr Fr Fr,\cdots\circ ^{3!}\circ ^{2!}\circ ^{1!} \in\operatorname{Gal}(\overline{\mathbb F_p}/\mathbb F_p)\setminus\langle \rangle,"Let $\varphi=\cdots\circ \operatorname{Fr}^{3!}\circ \operatorname{Fr}^{2!}\circ \operatorname{Fr}^{1!}$ , where $\operatorname{Fr}$ is the Frobenius endomorphism. Show that $\varphi \in \operatorname{Gal}(\overline{\mathbb F_p}/\mathbb F_p)\setminus\langle\operatorname{Fr}\rangle$ . First of all, I had to show that $\varphi$ is well-defined. For this argument I proved that for every $\mathbb F_p\subset\mathbb K \subset  \overline{\mathbb F_p}$ , if $[\mathbb K:\mathbb F_p]< \infty$ , then there exists $N$ such that for every $n\geq N$ , $\operatorname{Fr}^{n!}|_\mathbb K=\operatorname{Id}$ . How do I continue from here?","Let , where is the Frobenius endomorphism. Show that . First of all, I had to show that is well-defined. For this argument I proved that for every , if , then there exists such that for every , . How do I continue from here?",\varphi=\cdots\circ \operatorname{Fr}^{3!}\circ \operatorname{Fr}^{2!}\circ \operatorname{Fr}^{1!} \operatorname{Fr} \varphi \in \operatorname{Gal}(\overline{\mathbb F_p}/\mathbb F_p)\setminus\langle\operatorname{Fr}\rangle \varphi \mathbb F_p\subset\mathbb K \subset  \overline{\mathbb F_p} [\mathbb K:\mathbb F_p]< \infty N n\geq N \operatorname{Fr}^{n!}|_\mathbb K=\operatorname{Id},"['abstract-algebra', 'field-theory', 'galois-theory']"
72,"Let $G$ be a group, $G'=[G,G]$ and $G''=[G',G']$ the first and second derived subgroups and assume $G''$ is cyclic. Prove that $G''\subset Z(G')$.","Let  be a group,  and  the first and second derived subgroups and assume  is cyclic. Prove that .","G G'=[G,G] G''=[G',G'] G'' G''\subset Z(G')","I'm trying to prove the following, but I'm stuck and I don't see how to continue. Any help is much appreciated! Let $G$ be a group, $G'=[G,G]$ and $G''=[G',G']$ the first and second derived subgroups and assume $G''$ is cyclic. Prove that $G''\subset Z(G')$. My work this far: Since $G''$ is cyclic, it is abelian. Since it is the commutator subgroup of $G'$, it is also known that $G''$ is normal. Thus (using a theorem from my syllabus), there exists a homomorphism $g:G'/G''\to\mathrm{Aut}(G'')$ such that $g(aG'')=\phi_{a|G''}$ for $a\in G'$, where $\phi_{a|G'}:G''\to G'':x\mapsto axa^{-1}$, thus the conjugation map by $a$. Now it suffices to proof $\phi_{a|G'}=Id_{G'}$ for all $a\in G'$. But how to prove this? I don't see it. The work I did this far follows a hint that was given for the question.","I'm trying to prove the following, but I'm stuck and I don't see how to continue. Any help is much appreciated! Let $G$ be a group, $G'=[G,G]$ and $G''=[G',G']$ the first and second derived subgroups and assume $G''$ is cyclic. Prove that $G''\subset Z(G')$. My work this far: Since $G''$ is cyclic, it is abelian. Since it is the commutator subgroup of $G'$, it is also known that $G''$ is normal. Thus (using a theorem from my syllabus), there exists a homomorphism $g:G'/G''\to\mathrm{Aut}(G'')$ such that $g(aG'')=\phi_{a|G''}$ for $a\in G'$, where $\phi_{a|G'}:G''\to G'':x\mapsto axa^{-1}$, thus the conjugation map by $a$. Now it suffices to proof $\phi_{a|G'}=Id_{G'}$ for all $a\in G'$. But how to prove this? I don't see it. The work I did this far follows a hint that was given for the question.",,"['abstract-algebra', 'group-theory']"
73,Proof of Maschke’s theorem: Why is $\hat{p}$ again a projection?,Proof of Maschke’s theorem: Why is  again a projection?,\hat{p},"Question : In the proof of Maschke’s theorem we construct for every subrepresentation $U \subseteq V$ a $G$-equivariant projection onto $U$.   How can we abstractly see that for any $k$-linear projection $p \colon V \to V$ onto $U$, the resulting $G$-equivariant map $\hat{p} = \frac{1}{|G|} \sum_{g \in G} (g.\!p) \colon V \to V$ must again be a projection onto $U$? Setup : Let $G$ be a finite group and $k$ a field with $\operatorname{char} k \nmid |G|$. Then for every representation $V$ of $G$ the map $$           V   \to     V   \quad   v   \mapsto \hat{v}   :=      \frac{1}{|G|} \sum_{g \in G} g.\!v $$ is a projection onto the subspace $V^G \subseteq V$ of $G$-invariants. We will refer to this as the projection onto invariants . This is famously used in (one of) the proofs of Maschke’s theorem: Let $V$ be a representation of $G$ over $k$ and let $U \subseteq V$ be a subrepresentation. Starting off with any $k$-linear projection $p \colon V \to V$ onto $U$, one can apply the projection onto invariants to the representation $\operatorname{Hom}_k(V,V)$ to get a new map $$     \hat{p} \in \operatorname{Hom}_k(V,V)^G =   \operatorname{Hom}_G(V,V) \,. $$ One can then check that this $G$-endomorphism $\hat{p}$ is again a projection onto $U$, e.g. by checking that $\operatorname{im} \hat{p} \subseteq U$ and that $\hat{p}(u) = u$ for every $u \in U$. While the projection onto invariants nicely explains how to translate the $k$-linear projection $p$ into a $G$-endomorphism $V \to V$, I have not yet found an explanation for why $\hat{p}$ will again be a projection onto $U$. (“Checking on elements” proves that it works, but doesn’t explain why it works.) How can we abstractly see that by applying the projection onto invariants to $p$, the resulting $G$-endomorphism $\hat{p}$ must again be a projection onto $U$? This is what I tried/figured out so far: Suppose that $W \subseteq V$ is a $k$-linear subspace which is not a subrepresentation, and let $q \colon V \to V$ be a projection onto $W$. Then $\hat{q} \colon V \to V$ doesn’t have image $W$ since $\hat{q}$ is $G$-equivariant and $\operatorname{im} \hat{q}$ is therefore a subrepresentation of $V$. But $\operatorname{im} \hat{q}$ is contained in the subrepresentation generated by $W$. $\hat{q}$ is not necessarily a projection. (Example: Let $\mathbb{Z}/4$ acts on $V = \mathbb{R}^2$, let $W$ be the $x$-axis and $q$ the orthogonal projection. Then $\hat{q}(x) = x/2$ for every $x \in W$, so that $\hat{q}^2 \neq \hat{q}$.) So it seems pretty important for $U$ to be a subrepresentation of $V$. For every $G$-homomorphism $f \colon V \to W$ one has that $f(\hat{v}) = \widehat{f(v)}$. In fancy language we may regard $\widehat{(-)}$ as a natural transformation from the identity functor to the taking-invariants functor $(-)^G$. Since $\widehat{(-)}_V$ is a projection for every representation $V$, this generalizes to a natural decomposition $V = V^G \oplus V^{\text{non-triv}}$. Given $k$-linear maps $f \colon U \to V$, $g \colon V \to W$ the first point shows that it does not always hold that $\widehat{f \circ g} = \hat{f} \circ \hat{g}$ (otherwise $\hat{q}$ would again be a projection). But it follows from the second point that $$   \widehat{\hat{f} \circ g} = \hat{f} \circ \hat{g} = \widehat{f \circ \hat{g}}   $$ since $\operatorname{Hom}_k(U,V) \to \operatorname{Hom}_k(U,W)$, $h \mapsto \hat{g} \circ h$ and $\operatorname{Hom}_k(V,W) \to \operatorname{Hom}_k(U,W)$, $h \mapsto h \circ \hat{f}$ are $G$-homomorphisms (which holds because $\hat{g}$ and $\hat{f}$ are $G$-homomorphisms). One can use the projection onto invariants to give different, more abstract proofs of Maschke’s theorem (e.g. section 3.2 here , which uses the natural decomposition from the second point). But I have not yet found such an abstract proof which better explains the “classical” proof. Any help is appreciated.","Question : In the proof of Maschke’s theorem we construct for every subrepresentation $U \subseteq V$ a $G$-equivariant projection onto $U$.   How can we abstractly see that for any $k$-linear projection $p \colon V \to V$ onto $U$, the resulting $G$-equivariant map $\hat{p} = \frac{1}{|G|} \sum_{g \in G} (g.\!p) \colon V \to V$ must again be a projection onto $U$? Setup : Let $G$ be a finite group and $k$ a field with $\operatorname{char} k \nmid |G|$. Then for every representation $V$ of $G$ the map $$           V   \to     V   \quad   v   \mapsto \hat{v}   :=      \frac{1}{|G|} \sum_{g \in G} g.\!v $$ is a projection onto the subspace $V^G \subseteq V$ of $G$-invariants. We will refer to this as the projection onto invariants . This is famously used in (one of) the proofs of Maschke’s theorem: Let $V$ be a representation of $G$ over $k$ and let $U \subseteq V$ be a subrepresentation. Starting off with any $k$-linear projection $p \colon V \to V$ onto $U$, one can apply the projection onto invariants to the representation $\operatorname{Hom}_k(V,V)$ to get a new map $$     \hat{p} \in \operatorname{Hom}_k(V,V)^G =   \operatorname{Hom}_G(V,V) \,. $$ One can then check that this $G$-endomorphism $\hat{p}$ is again a projection onto $U$, e.g. by checking that $\operatorname{im} \hat{p} \subseteq U$ and that $\hat{p}(u) = u$ for every $u \in U$. While the projection onto invariants nicely explains how to translate the $k$-linear projection $p$ into a $G$-endomorphism $V \to V$, I have not yet found an explanation for why $\hat{p}$ will again be a projection onto $U$. (“Checking on elements” proves that it works, but doesn’t explain why it works.) How can we abstractly see that by applying the projection onto invariants to $p$, the resulting $G$-endomorphism $\hat{p}$ must again be a projection onto $U$? This is what I tried/figured out so far: Suppose that $W \subseteq V$ is a $k$-linear subspace which is not a subrepresentation, and let $q \colon V \to V$ be a projection onto $W$. Then $\hat{q} \colon V \to V$ doesn’t have image $W$ since $\hat{q}$ is $G$-equivariant and $\operatorname{im} \hat{q}$ is therefore a subrepresentation of $V$. But $\operatorname{im} \hat{q}$ is contained in the subrepresentation generated by $W$. $\hat{q}$ is not necessarily a projection. (Example: Let $\mathbb{Z}/4$ acts on $V = \mathbb{R}^2$, let $W$ be the $x$-axis and $q$ the orthogonal projection. Then $\hat{q}(x) = x/2$ for every $x \in W$, so that $\hat{q}^2 \neq \hat{q}$.) So it seems pretty important for $U$ to be a subrepresentation of $V$. For every $G$-homomorphism $f \colon V \to W$ one has that $f(\hat{v}) = \widehat{f(v)}$. In fancy language we may regard $\widehat{(-)}$ as a natural transformation from the identity functor to the taking-invariants functor $(-)^G$. Since $\widehat{(-)}_V$ is a projection for every representation $V$, this generalizes to a natural decomposition $V = V^G \oplus V^{\text{non-triv}}$. Given $k$-linear maps $f \colon U \to V$, $g \colon V \to W$ the first point shows that it does not always hold that $\widehat{f \circ g} = \hat{f} \circ \hat{g}$ (otherwise $\hat{q}$ would again be a projection). But it follows from the second point that $$   \widehat{\hat{f} \circ g} = \hat{f} \circ \hat{g} = \widehat{f \circ \hat{g}}   $$ since $\operatorname{Hom}_k(U,V) \to \operatorname{Hom}_k(U,W)$, $h \mapsto \hat{g} \circ h$ and $\operatorname{Hom}_k(V,W) \to \operatorname{Hom}_k(U,W)$, $h \mapsto h \circ \hat{f}$ are $G$-homomorphisms (which holds because $\hat{g}$ and $\hat{f}$ are $G$-homomorphisms). One can use the projection onto invariants to give different, more abstract proofs of Maschke’s theorem (e.g. section 3.2 here , which uses the natural decomposition from the second point). But I have not yet found such an abstract proof which better explains the “classical” proof. Any help is appreciated.",,"['abstract-algebra', 'group-theory', 'finite-groups', 'representation-theory', 'proof-explanation']"
74,"Radical ideal in $k[X_{1},...,X_{n}]$",Radical ideal in,"k[X_{1},...,X_{n}]","Let $k$ be an field with $\mathrm{char}(k) = 0$ and $f_{1},...,f_{n} \in k[X_{1},...,X_{n}]$. Consider the jacobian matrix $A := (\frac{\partial f_{j}}{\partial X_{l}})$ and suppose that $\det(A) = 1$. Is it true that $\sqrt{(f_{1},...,f_{n})} = (f_{1},...,f_{n})$? Note that if $n = 1$, then $\det(A) = 1 \Longrightarrow f_{1} = X+b$ with $b \in k$. So, $\sqrt{(f_{1})} = (f_{1})$.","Let $k$ be an field with $\mathrm{char}(k) = 0$ and $f_{1},...,f_{n} \in k[X_{1},...,X_{n}]$. Consider the jacobian matrix $A := (\frac{\partial f_{j}}{\partial X_{l}})$ and suppose that $\det(A) = 1$. Is it true that $\sqrt{(f_{1},...,f_{n})} = (f_{1},...,f_{n})$? Note that if $n = 1$, then $\det(A) = 1 \Longrightarrow f_{1} = X+b$ with $b \in k$. So, $\sqrt{(f_{1})} = (f_{1})$.",,"['abstract-algebra', 'commutative-algebra']"
75,Are there axioms for dividing by zero that don't destroy math?,Are there axioms for dividing by zero that don't destroy math?,,"I concluded that - in a certain sense - all fractions are made up. That is, when we say $$\frac{a}{b}=x$$ We are merely declaring the number $x$ to satisfy the equation: $$b\cdot x=a$$ Of course there is much more to fractions than this. But it naturally came next - why not define division by zero to be exist? So write that $$\omega=\ ""\frac{1}{0}"" \quad\text{meaning simply that}\quad \omega\cdot 0 =1$$ We declare $\omega$ to have this property $\textit{and only this property}$. If we were to give $\omega$ the same properties every other number has then math is quickly ""destroyed"" - meaning every number is equal to every other number. The next goal is to give $\omega$ as many properties of other integers as possible without destroying algebra. For an example failed attempt, let's give $\omega$ $\textbf{distributivity}$ and an $\textbf{additive inverse}$. We have $$1=\omega\cdot 0=\omega\cdot(1-1)=\omega-\omega=0$$ and it happened. It seems safe to give $\omega$ the following commutative properties $$\omega \cdot a=a\cdot\omega$$ $$\omega + a = a + \omega = \omega$$ Is there a foolproof way to check if giving $\omega$ some particular property is ""safe""? (i.e. leaves us with a consistent number theory)","I concluded that - in a certain sense - all fractions are made up. That is, when we say $$\frac{a}{b}=x$$ We are merely declaring the number $x$ to satisfy the equation: $$b\cdot x=a$$ Of course there is much more to fractions than this. But it naturally came next - why not define division by zero to be exist? So write that $$\omega=\ ""\frac{1}{0}"" \quad\text{meaning simply that}\quad \omega\cdot 0 =1$$ We declare $\omega$ to have this property $\textit{and only this property}$. If we were to give $\omega$ the same properties every other number has then math is quickly ""destroyed"" - meaning every number is equal to every other number. The next goal is to give $\omega$ as many properties of other integers as possible without destroying algebra. For an example failed attempt, let's give $\omega$ $\textbf{distributivity}$ and an $\textbf{additive inverse}$. We have $$1=\omega\cdot 0=\omega\cdot(1-1)=\omega-\omega=0$$ and it happened. It seems safe to give $\omega$ the following commutative properties $$\omega \cdot a=a\cdot\omega$$ $$\omega + a = a + \omega = \omega$$ Is there a foolproof way to check if giving $\omega$ some particular property is ""safe""? (i.e. leaves us with a consistent number theory)",,['abstract-algebra']
76,Local Fields with isomorphic multiplicative group,Local Fields with isomorphic multiplicative group,,"If two local fields have isomorphic multiplicative groups (as abstract groups), can we conclude that they are isomorphic as fields? What if they are isomorphic as topological groups?","If two local fields have isomorphic multiplicative groups (as abstract groups), can we conclude that they are isomorphic as fields? What if they are isomorphic as topological groups?",,"['abstract-algebra', 'group-theory']"
77,"R integral domain, Q its field of fraction, M R-module with nontrivial annihilator. Is Ext(Q,M) always 0? [duplicate]","R integral domain, Q its field of fraction, M R-module with nontrivial annihilator. Is Ext(Q,M) always 0? [duplicate]",,"This question already has an answer here : Ext$_R^n(Q,A)=0=$Tor$_n^R(Q,A)$ where $Q$ is the field of fractions of a domain $R$ (1 answer) Closed 7 years ago . Let $R$ be an integral domain, let $Q$ be its field of fractions, and let $M$ be an $R$-module with nontrivial annihilator. Determine if $\mathrm{Ext}_{R}^{n}(Q,M) = 0$ for all $n \geq 0$. Intuitively, I believe it is true, because the most natural example $R = \mathbb{Z}$, $Q = \mathbb{Q}$, and $M = \mathbb{Z}_m$ looks promising. However, this example is ""bad"", because $\mathbb{Z}$ is a PID, and therefore divisible is equivalent to injective. My first thought is constructing a short exact sequence, for example, $0 \to Ann_R(M) \to Q \to M \to 0$ and look at its induced long exact sequence on the cohomology. However, I never succeed. My professor suggests that I should somehow use the fact that $Q$ is the field of fractions, maybe though the fact that $Q$ will kill all the torsions (considering the induced cohomology on $Tor$). Can anyone give me some more suggestions? Thanks!","This question already has an answer here : Ext$_R^n(Q,A)=0=$Tor$_n^R(Q,A)$ where $Q$ is the field of fractions of a domain $R$ (1 answer) Closed 7 years ago . Let $R$ be an integral domain, let $Q$ be its field of fractions, and let $M$ be an $R$-module with nontrivial annihilator. Determine if $\mathrm{Ext}_{R}^{n}(Q,M) = 0$ for all $n \geq 0$. Intuitively, I believe it is true, because the most natural example $R = \mathbb{Z}$, $Q = \mathbb{Q}$, and $M = \mathbb{Z}_m$ looks promising. However, this example is ""bad"", because $\mathbb{Z}$ is a PID, and therefore divisible is equivalent to injective. My first thought is constructing a short exact sequence, for example, $0 \to Ann_R(M) \to Q \to M \to 0$ and look at its induced long exact sequence on the cohomology. However, I never succeed. My professor suggests that I should somehow use the fact that $Q$ is the field of fractions, maybe though the fact that $Q$ will kill all the torsions (considering the induced cohomology on $Tor$). Can anyone give me some more suggestions? Thanks!",,"['abstract-algebra', 'homological-algebra']"
78,A special subset of nilradical,A special subset of nilradical,,"For a commutative and unitary ring $R$ and an ideal $I$ of $R$, suppose that $\mathrm{Id}(I)$ is the ideal of $R$ generated by idempotent elements of $I$. It is well-known that $\mathrm{Nil}(R)=\bigcap_{P\in \mathrm{Spec}(R)} P$ is the set of all nilpotent elements of $R$, and if $e^2=e\in \mathrm{Nil}(R)$, then $e$ must be zero element. Now I want to know if the following is true: $$\bigcap_{P\in \mathrm{Spec}(R)} \mathrm{Id}(P)=\{0\}.$$","For a commutative and unitary ring $R$ and an ideal $I$ of $R$, suppose that $\mathrm{Id}(I)$ is the ideal of $R$ generated by idempotent elements of $I$. It is well-known that $\mathrm{Nil}(R)=\bigcap_{P\in \mathrm{Spec}(R)} P$ is the set of all nilpotent elements of $R$, and if $e^2=e\in \mathrm{Nil}(R)$, then $e$ must be zero element. Now I want to know if the following is true: $$\bigcap_{P\in \mathrm{Spec}(R)} \mathrm{Id}(P)=\{0\}.$$",,"['abstract-algebra', 'ring-theory', 'commutative-algebra', 'idempotents']"
79,Differences between symmetries and isometries,Differences between symmetries and isometries,,"throughout the following question, whenever I'm wrong please correct me! Recently I came across the notions of symmetry and isometry. Though, there is something obscure (definitely in my head) concerning the distinction of those two things. For instance, let's say that $\Sigma \subset \mathbb{R}^{n},$ is an arbitrary geometric object (I'm looking for the general point view of the notion of symmetries and isometries, hence am going to assume that at the moment no further structure has been assumed on this object). Then the group of symmetries of $\Sigma$, is  $$Symm(\Sigma)= \{ \sigma \in Isom(\mathbb{R}^n) \thinspace | \thinspace \sigma(\Sigma) = \Sigma \},$$ whilst isometries of $\mathbb{R}^n$ are defined as usually, being distance-preserving maps $\sigma : \mathbb{R}^n \rightarrow \mathbb{R}^n,$ which turn out to be continuous , one -to- one and onto (hence homeomorphisms of the underlying topological structure induced by the metric). Now, let's say that a geometric figure $\Sigma \subset \mathbb{R}^{n},$ is given on its own again and someone asks, "" What's the group of isomotries and symmetries of $\Sigma$? "".  Then there are two possibilities: $\Sigma$, inherits the metric by $\mathbb{R}^n,$ as a subspace. $\Sigma$, becomes a metric space with some other metric and we examine it by forgetting any ambient space. Now, for the first one, I think the symmetries and isometries coincide, right (if no, a counterexample suffices)? It's just another name for the same map $\sigma: \Sigma \rightarrow \Sigma$ which preserves distances. But what happens for the second case? For instance, for the last question I have in my mind the distinctive case $\Sigma= \mathbb{S}^{n-1},$ the $(n-1)$-dimensional sphere which naturally inherits a metric by $\mathbb{R}^n$, but it can be equipped with another metric too, hence the isometries change in those two cases since different type of measurment is being applied each time. What happens if moreover we assume some differentiable structure and someone asks for the isomotries/symmetries of Riemmanian manifolds instead of subsets of $\mathbb{R}^n$? What about the symmetries and isometries in that case? Thank you, I hope haven't done something wrong, because is my first post! If yes, do let me know.","throughout the following question, whenever I'm wrong please correct me! Recently I came across the notions of symmetry and isometry. Though, there is something obscure (definitely in my head) concerning the distinction of those two things. For instance, let's say that $\Sigma \subset \mathbb{R}^{n},$ is an arbitrary geometric object (I'm looking for the general point view of the notion of symmetries and isometries, hence am going to assume that at the moment no further structure has been assumed on this object). Then the group of symmetries of $\Sigma$, is  $$Symm(\Sigma)= \{ \sigma \in Isom(\mathbb{R}^n) \thinspace | \thinspace \sigma(\Sigma) = \Sigma \},$$ whilst isometries of $\mathbb{R}^n$ are defined as usually, being distance-preserving maps $\sigma : \mathbb{R}^n \rightarrow \mathbb{R}^n,$ which turn out to be continuous , one -to- one and onto (hence homeomorphisms of the underlying topological structure induced by the metric). Now, let's say that a geometric figure $\Sigma \subset \mathbb{R}^{n},$ is given on its own again and someone asks, "" What's the group of isomotries and symmetries of $\Sigma$? "".  Then there are two possibilities: $\Sigma$, inherits the metric by $\mathbb{R}^n,$ as a subspace. $\Sigma$, becomes a metric space with some other metric and we examine it by forgetting any ambient space. Now, for the first one, I think the symmetries and isometries coincide, right (if no, a counterexample suffices)? It's just another name for the same map $\sigma: \Sigma \rightarrow \Sigma$ which preserves distances. But what happens for the second case? For instance, for the last question I have in my mind the distinctive case $\Sigma= \mathbb{S}^{n-1},$ the $(n-1)$-dimensional sphere which naturally inherits a metric by $\mathbb{R}^n$, but it can be equipped with another metric too, hence the isometries change in those two cases since different type of measurment is being applied each time. What happens if moreover we assume some differentiable structure and someone asks for the isomotries/symmetries of Riemmanian manifolds instead of subsets of $\mathbb{R}^n$? What about the symmetries and isometries in that case? Thank you, I hope haven't done something wrong, because is my first post! If yes, do let me know.",,"['abstract-algebra', 'group-theory', 'symmetry', 'isometry']"
80,Size of a sandpile.,Size of a sandpile.,,"Introduction There is a structure called sandpile . Let us introduce it in the following way. Suppose we have a set of whole points $\mathbb{Z}^2$. Next, we have a function $g:\mathbb{Z}^2 \rightarrow\mathbb{N}$, which shows how many grains are in the point $(x,y).$ Also, there is a number of a maximum possible grains in a point which leaves point stable. We will denote this number through $T$ (threshold). Now execute the following algorithm: if $g(x,y) > T$ then subtract 4 grains from $(x,y)$ and add one grain to each neighbor of $(x,y)$ i.e. $(x\pm 1, y)$ and $(x, y\pm 1)$. if there is no points with $g(x,y) > T$ then terminate. Else, start with step 1. Simple example with $T=4$ and starting amount of grains $S$ (seed) at $(2,2)$ equals to 11 showed below.  $$\begin{pmatrix} 0 & 0 & 0\\ 0 & 11 & 0\\ 0 & 0 & 0 \end{pmatrix} \rightarrow \begin{pmatrix} 0 & 2 & 0\\ 2 & 3 & 2\\ 0 & 2 & 0 \end{pmatrix}$$ More information about this here Question Suppose we have sandpile with $T=t$ and $S=n_0$ at (0,0). Let us denote such sandpiles through $\Delta(n_0;t)$. My question is Given a sandpile $\Delta(n_0;t)$ find the size of this sandpile, where $$\text{size} := |\Delta(n_0;t)| =\max_{g(x,y)>0}|x|=\max_{g(x,y)>0}|y|$$ Tries Some reasons lead me to the answer $$|\Delta(n_0;t)| \leq 3\log_{4}\frac{n_0}{t} + 1,$$ but empirical results say that for sufficiently large $n_0$ it is not true. Pictures Here are some pictures I made with Sage. The darker color the more grains in pixel. The first three pictures with threshold equals to 4, two last - 3. EDIT: 1D sandpiles Starting from the suggestion to look at 1-dim sandpile it is possible to say that there is nothing special (i.e. interesting) about that. It is almost obvious how they (1-dim SP's) look like (take a guess). More over, one can calculate the size of 1-dim SP: $$\Delta_{1}(n_0; t) \sim \frac{n_0}{2t}$$","Introduction There is a structure called sandpile . Let us introduce it in the following way. Suppose we have a set of whole points $\mathbb{Z}^2$. Next, we have a function $g:\mathbb{Z}^2 \rightarrow\mathbb{N}$, which shows how many grains are in the point $(x,y).$ Also, there is a number of a maximum possible grains in a point which leaves point stable. We will denote this number through $T$ (threshold). Now execute the following algorithm: if $g(x,y) > T$ then subtract 4 grains from $(x,y)$ and add one grain to each neighbor of $(x,y)$ i.e. $(x\pm 1, y)$ and $(x, y\pm 1)$. if there is no points with $g(x,y) > T$ then terminate. Else, start with step 1. Simple example with $T=4$ and starting amount of grains $S$ (seed) at $(2,2)$ equals to 11 showed below.  $$\begin{pmatrix} 0 & 0 & 0\\ 0 & 11 & 0\\ 0 & 0 & 0 \end{pmatrix} \rightarrow \begin{pmatrix} 0 & 2 & 0\\ 2 & 3 & 2\\ 0 & 2 & 0 \end{pmatrix}$$ More information about this here Question Suppose we have sandpile with $T=t$ and $S=n_0$ at (0,0). Let us denote such sandpiles through $\Delta(n_0;t)$. My question is Given a sandpile $\Delta(n_0;t)$ find the size of this sandpile, where $$\text{size} := |\Delta(n_0;t)| =\max_{g(x,y)>0}|x|=\max_{g(x,y)>0}|y|$$ Tries Some reasons lead me to the answer $$|\Delta(n_0;t)| \leq 3\log_{4}\frac{n_0}{t} + 1,$$ but empirical results say that for sufficiently large $n_0$ it is not true. Pictures Here are some pictures I made with Sage. The darker color the more grains in pixel. The first three pictures with threshold equals to 4, two last - 3. EDIT: 1D sandpiles Starting from the suggestion to look at 1-dim sandpile it is possible to say that there is nothing special (i.e. interesting) about that. It is almost obvious how they (1-dim SP's) look like (take a guess). More over, one can calculate the size of 1-dim SP: $$\Delta_{1}(n_0; t) \sim \frac{n_0}{2t}$$",,"['abstract-algebra', 'graph-theory', 'recurrence-relations']"
81,Proof that a set is a group,Proof that a set is a group,,"Let $G$ be a nonempty set with an associative operation and for each $a\in G$ exists only one $a'\in G$  such that $aa'a=a$. Prove that $G$ is a group. I tried playing with the fact that $aa'a=a$ and the only thing I found is that $(a')'=a$. Then I tried proving that for each $a,b\in G$, $aa'=bb'$ (which means we can write $e=aa'$ and then $G$ has an identity) but I couldn't get anything meaningful. Proof that $(a')'=a$ (by request): $aa'a=a$ $a'aa'a=a'a$ (multiply by $a'$ from left side) $a(a'aa')a=a(a')a$ (multiply by $a$ from right side) We know that $a'$ is the only one that satisfy $aa'a=a$ and therfore $a'aa'=a'$ (whice means that $(a')'=a$.","Let $G$ be a nonempty set with an associative operation and for each $a\in G$ exists only one $a'\in G$  such that $aa'a=a$. Prove that $G$ is a group. I tried playing with the fact that $aa'a=a$ and the only thing I found is that $(a')'=a$. Then I tried proving that for each $a,b\in G$, $aa'=bb'$ (which means we can write $e=aa'$ and then $G$ has an identity) but I couldn't get anything meaningful. Proof that $(a')'=a$ (by request): $aa'a=a$ $a'aa'a=a'a$ (multiply by $a'$ from left side) $a(a'aa')a=a(a')a$ (multiply by $a$ from right side) We know that $a'$ is the only one that satisfy $aa'a=a$ and therfore $a'aa'=a'$ (whice means that $(a')'=a$.",,"['abstract-algebra', 'group-theory']"
82,$\Bbb F_2[X]$ modules with 8 elements,modules with 8 elements,\Bbb F_2[X],"Problem 4. Let $\Bbb F_2$ be the field with 2 elements and let $R=\Bbb F_2[X]$. List, up to isomorphism, all $R$-modules with 8 elements. Solution. We use the classification theorem of modules over a PID. Since $R$ is a finite module, it is in particular an $\Bbb F_2$ vector space. We can write   $$M\cong R/n_1R\oplus R/n_2 R\oplus\cdots\oplus R/n_r R$$   for polynmials $n_1\mid n_2\mid\cdots\mid n_r$. In our case, we have $\sum_{i=1}^r\deg n_i=3$, so we have three options: $r=1,\deg n_1=3$, $r=2,\deg n_2=2$, and $r=3,\deg n_3=1$. The first case yields 8 options. For the second case, we need $n_2$ to be reducible, so we have $X(X+1),X^2,(X+1)^2$ as choices. The first choice yields 2 decompositions, and the latter choices yield 1 decomposition each, for a total of 4. For the linear case, we need the same linear term repeated thrice, which is 2 choices. Therefore there are 14 in all, listed by invariant factors below:   $$\begin{align} &\{X^3+(0/1)X^2+(0/1)X+(0/1)\}\\ &\{X^2,X\},\{X^2+X,X+(0/1)\},\{X^2+1,X+1\}\\ &\{X,X,X\},\{X+1,X+1,X+1\}. \end{align}$$ My question is the problem above. I can understand the solution, but how can I see that the solutions given are from distinct isomorphism classes ? For instance, is the below true? $$R/(X)\oplus R/(X)\oplus R/(X)\cong R/(X+1)\oplus R/(X+1)\oplus R/(X+1)\\ \cong F_2\oplus F_2\oplus F_2$$ Thanks for any help.","Problem 4. Let $\Bbb F_2$ be the field with 2 elements and let $R=\Bbb F_2[X]$. List, up to isomorphism, all $R$-modules with 8 elements. Solution. We use the classification theorem of modules over a PID. Since $R$ is a finite module, it is in particular an $\Bbb F_2$ vector space. We can write   $$M\cong R/n_1R\oplus R/n_2 R\oplus\cdots\oplus R/n_r R$$   for polynmials $n_1\mid n_2\mid\cdots\mid n_r$. In our case, we have $\sum_{i=1}^r\deg n_i=3$, so we have three options: $r=1,\deg n_1=3$, $r=2,\deg n_2=2$, and $r=3,\deg n_3=1$. The first case yields 8 options. For the second case, we need $n_2$ to be reducible, so we have $X(X+1),X^2,(X+1)^2$ as choices. The first choice yields 2 decompositions, and the latter choices yield 1 decomposition each, for a total of 4. For the linear case, we need the same linear term repeated thrice, which is 2 choices. Therefore there are 14 in all, listed by invariant factors below:   $$\begin{align} &\{X^3+(0/1)X^2+(0/1)X+(0/1)\}\\ &\{X^2,X\},\{X^2+X,X+(0/1)\},\{X^2+1,X+1\}\\ &\{X,X,X\},\{X+1,X+1,X+1\}. \end{align}$$ My question is the problem above. I can understand the solution, but how can I see that the solutions given are from distinct isomorphism classes ? For instance, is the below true? $$R/(X)\oplus R/(X)\oplus R/(X)\cong R/(X+1)\oplus R/(X+1)\oplus R/(X+1)\\ \cong F_2\oplus F_2\oplus F_2$$ Thanks for any help.",,"['abstract-algebra', 'modules', 'finite-fields']"
83,Structure and normality of the Galois group of $x^{15}-15 \in \mathbb{Q}[x]$.,Structure and normality of the Galois group of .,x^{15}-15 \in \mathbb{Q}[x],"Let $f(x) = x^{15}-15\in \mathbb{Q}[x]$. By Eisenstein's Criterion (using 3 or 5), $f$ is irreducible. Then $L=\mathbb{Q}(\sqrt[15]{15}, \omega)$ is the splitting field of $f$, where $\omega$ is a primitive $15$th root of unity. We then have that the order of the Galois group $G=Gal(L/\mathbb{Q})$ is just $15\cdot \phi(15) =120$ - the product of the extensions. My question is, knowing this, can we determine which Sylow subgroups are normal along with their structure? Of course the 3 and 5 Sylow subgroups will be isomorphic to $\mathbb{Z}_3$ and $\mathbb{Z}_5$ respectively, but I'm not sure if there's enough info to determine the 2-Sylow subgroup nor the number of each of them to determine normality. Should I focus on looking at subfields of $L$?","Let $f(x) = x^{15}-15\in \mathbb{Q}[x]$. By Eisenstein's Criterion (using 3 or 5), $f$ is irreducible. Then $L=\mathbb{Q}(\sqrt[15]{15}, \omega)$ is the splitting field of $f$, where $\omega$ is a primitive $15$th root of unity. We then have that the order of the Galois group $G=Gal(L/\mathbb{Q})$ is just $15\cdot \phi(15) =120$ - the product of the extensions. My question is, knowing this, can we determine which Sylow subgroups are normal along with their structure? Of course the 3 and 5 Sylow subgroups will be isomorphic to $\mathbb{Z}_3$ and $\mathbb{Z}_5$ respectively, but I'm not sure if there's enough info to determine the 2-Sylow subgroup nor the number of each of them to determine normality. Should I focus on looking at subfields of $L$?",,"['abstract-algebra', 'galois-theory']"
84,Equivalent definitions of a root system.,Equivalent definitions of a root system.,,"For studying root systems many authors start from a vector space $V$ over $\mathbb{R}$ with a positive definite scalar product $(\cdot,\cdot)$, in which a reflection $\sigma_\alpha$ is a linear application that fixes the hyperplane $H_\alpha$ and send $\alpha$ to its opposite. In formulas \begin{gather} \sigma_\alpha(\beta)=\beta- <\beta,\alpha>\alpha \end{gather} where $<\beta,\alpha>=$$2(\alpha,\beta)\over (\alpha,\alpha) $. Then a root system is defined as a subset $R$ of $V$ such that $\langle R \rangle =V$, $R$ finite and $0 \notin R$ $\mathbb{R}\{ \alpha\} \cap R=\{\pm \alpha \}$ if $\alpha \in R$ for every $\alpha, \beta \in R$, $R$ is invariant under $\sigma_\alpha$ and $<\beta,\alpha>$ is an integer. This is a quite strong structure, but all the properties envolved arise naturally in the form of the weights $\mu \in H^*$, where $H$ is the Cartan subalgebra of a complex Lie algebra $L$ (we are considering the adjoint representation). Then we can consider on $H^*$ the dual of the Killing form, that is again symmetric and positive definite. In this environment, we can restrict to $V_\mathbb{Q}$, the $\mathbb{Q}$-span of the non zero weights in $H^*$, (indeed one can prove that the dual of the killing form take rational values, see the chapter ""Integrality Properties"" of ""Introduction of Lie Algebras and Representation theory"", Humphreys) then consider $V=V_\mathbb{Q} \otimes_\mathbb{Q} \mathbb{R}$ and check that these are a root system in $V$. For proving the characterization of semisimple lie algebras, this can be a start point. Nevethless, some authors need to weak slightly the definition of a root system, starting from a vector space $V$ on $\mathbb{R}$ (without scalar product) and define a root system $R$ as a subset of $V$ such that $R$ is finite, generates $V$ and $0 \notin R$ $\alpha \in R \implies$$ \alpha \over 2$$ \notin R$ for each $\alpha, \beta \in R$ there is $\alpha^\vee \in V^*$ with $\alpha^\vee (\alpha)=2$ and $\alpha^\vee(\beta) \in \mathbb{Z}$ and $s_{\alpha^\vee,\alpha}(R) \subseteq R$ Where for $\lambda \in V^*, w \in V$ $s_{\lambda,v}(w)=w-\lambda(w)v$. Then, considerd $G$ the finite subgroup of $GL(V)$ that preserves $R$ and $(\cdot,\cdot)$ a generic positive definite scalar product, we define \begin{gather} (\alpha,\beta)'=\sum_{g\in G}(g\alpha,g\beta) \end{gather} After realizing that $(\cdot,\cdot)'$ is a positive definite scalar product by which $G$ acts by isometries, we can prove that $\alpha^\vee$ is uniquely determined by $\alpha$ $\alpha^\vee(\lambda)=2\frac{(\alpha,\lambda)'}{(\alpha,\alpha)'}$ Here the identifications: $\alpha^\vee$ is the element $h_\alpha$ such that $x_\alpha,y_\alpha,[x_\alpha,y_\alpha]=h_\alpha$ are the usual generators of a copy of $sl_2$ and $\alpha^\vee(\lambda)=\lambda(h_\alpha)$ after $H^{**}=H$. My first question: what is the relation between $(\cdot,\cdot)'$ and the dual of the Killing form? My guess is that they differ from a scalar, but I cant prove it directly. My second question: the second approach has the property that make easier to prove that the non zero weights of a Lie algebra via the adjoint representation are a root system, indeed we can avoid the use of the ""orthogonality relations"", but we need more work to return to the stronger situation of the first definition. So what is the real advantage of the second way?","For studying root systems many authors start from a vector space $V$ over $\mathbb{R}$ with a positive definite scalar product $(\cdot,\cdot)$, in which a reflection $\sigma_\alpha$ is a linear application that fixes the hyperplane $H_\alpha$ and send $\alpha$ to its opposite. In formulas \begin{gather} \sigma_\alpha(\beta)=\beta- <\beta,\alpha>\alpha \end{gather} where $<\beta,\alpha>=$$2(\alpha,\beta)\over (\alpha,\alpha) $. Then a root system is defined as a subset $R$ of $V$ such that $\langle R \rangle =V$, $R$ finite and $0 \notin R$ $\mathbb{R}\{ \alpha\} \cap R=\{\pm \alpha \}$ if $\alpha \in R$ for every $\alpha, \beta \in R$, $R$ is invariant under $\sigma_\alpha$ and $<\beta,\alpha>$ is an integer. This is a quite strong structure, but all the properties envolved arise naturally in the form of the weights $\mu \in H^*$, where $H$ is the Cartan subalgebra of a complex Lie algebra $L$ (we are considering the adjoint representation). Then we can consider on $H^*$ the dual of the Killing form, that is again symmetric and positive definite. In this environment, we can restrict to $V_\mathbb{Q}$, the $\mathbb{Q}$-span of the non zero weights in $H^*$, (indeed one can prove that the dual of the killing form take rational values, see the chapter ""Integrality Properties"" of ""Introduction of Lie Algebras and Representation theory"", Humphreys) then consider $V=V_\mathbb{Q} \otimes_\mathbb{Q} \mathbb{R}$ and check that these are a root system in $V$. For proving the characterization of semisimple lie algebras, this can be a start point. Nevethless, some authors need to weak slightly the definition of a root system, starting from a vector space $V$ on $\mathbb{R}$ (without scalar product) and define a root system $R$ as a subset of $V$ such that $R$ is finite, generates $V$ and $0 \notin R$ $\alpha \in R \implies$$ \alpha \over 2$$ \notin R$ for each $\alpha, \beta \in R$ there is $\alpha^\vee \in V^*$ with $\alpha^\vee (\alpha)=2$ and $\alpha^\vee(\beta) \in \mathbb{Z}$ and $s_{\alpha^\vee,\alpha}(R) \subseteq R$ Where for $\lambda \in V^*, w \in V$ $s_{\lambda,v}(w)=w-\lambda(w)v$. Then, considerd $G$ the finite subgroup of $GL(V)$ that preserves $R$ and $(\cdot,\cdot)$ a generic positive definite scalar product, we define \begin{gather} (\alpha,\beta)'=\sum_{g\in G}(g\alpha,g\beta) \end{gather} After realizing that $(\cdot,\cdot)'$ is a positive definite scalar product by which $G$ acts by isometries, we can prove that $\alpha^\vee$ is uniquely determined by $\alpha$ $\alpha^\vee(\lambda)=2\frac{(\alpha,\lambda)'}{(\alpha,\alpha)'}$ Here the identifications: $\alpha^\vee$ is the element $h_\alpha$ such that $x_\alpha,y_\alpha,[x_\alpha,y_\alpha]=h_\alpha$ are the usual generators of a copy of $sl_2$ and $\alpha^\vee(\lambda)=\lambda(h_\alpha)$ after $H^{**}=H$. My first question: what is the relation between $(\cdot,\cdot)'$ and the dual of the Killing form? My guess is that they differ from a scalar, but I cant prove it directly. My second question: the second approach has the property that make easier to prove that the non zero weights of a Lie algebra via the adjoint representation are a root system, indeed we can avoid the use of the ""orthogonality relations"", but we need more work to return to the stronger situation of the first definition. So what is the real advantage of the second way?",,"['abstract-algebra', 'modules', 'lie-algebras', 'root-systems']"
85,"In an extension field, is there any difference between the original field and its isomorphic copy in the extension field?","In an extension field, is there any difference between the original field and its isomorphic copy in the extension field?",,"I recently came to the topic of field extensions in my abstract algebra course, and there has been a slight issue which has been bothering me that I was hoping I might be able to clear up. We have defined an extension field for a field F to be a field E such that $F \subseteq E$ and that $F$ is a field under the operations of $E$ restricted to $F$. Sounds easy enough and I realize that we have been using objects like this for a long time. For example we know that $\mathbb{C}$ is an extension field of $\mathbb{R}$. Something that has been bothering me a little bit though is that we have started proving theorems where we need to construct extension fields, but these extension fields don't seem to contain the original field $F$ but rather an isomorphic copy of $F$. For example if our field was $F$, then $F[x]/(p(x))$ is a field if $p(x)$ is irreducible, which contains a subfield isomorphic to $F$. It seems strange that in the theorems (Gallian's Text) that $F[x]/(p(x))$ is considered an extension field for $F$ even though it doesn't really contain $F$ as a subset, but rather another set which is isomorphic. I don't think I would have normally though this as being much of a problem, but I remember that earlier in the text Gallian seems to mention that even when structures are isomorphic and that they behave essentially the same, that we need to keep in mind that they are not exactly the same. If this distinction does matter, why not make the definition of an extension field just say that $E$ is an extension field of $F$ if $E$ has a subfield isomorphic to $F$? This would seem to include all cases. Is this largely a historical issue related to how mathematicians thought about isomorphic structures in the past?","I recently came to the topic of field extensions in my abstract algebra course, and there has been a slight issue which has been bothering me that I was hoping I might be able to clear up. We have defined an extension field for a field F to be a field E such that $F \subseteq E$ and that $F$ is a field under the operations of $E$ restricted to $F$. Sounds easy enough and I realize that we have been using objects like this for a long time. For example we know that $\mathbb{C}$ is an extension field of $\mathbb{R}$. Something that has been bothering me a little bit though is that we have started proving theorems where we need to construct extension fields, but these extension fields don't seem to contain the original field $F$ but rather an isomorphic copy of $F$. For example if our field was $F$, then $F[x]/(p(x))$ is a field if $p(x)$ is irreducible, which contains a subfield isomorphic to $F$. It seems strange that in the theorems (Gallian's Text) that $F[x]/(p(x))$ is considered an extension field for $F$ even though it doesn't really contain $F$ as a subset, but rather another set which is isomorphic. I don't think I would have normally though this as being much of a problem, but I remember that earlier in the text Gallian seems to mention that even when structures are isomorphic and that they behave essentially the same, that we need to keep in mind that they are not exactly the same. If this distinction does matter, why not make the definition of an extension field just say that $E$ is an extension field of $F$ if $E$ has a subfield isomorphic to $F$? This would seem to include all cases. Is this largely a historical issue related to how mathematicians thought about isomorphic structures in the past?",,"['abstract-algebra', 'field-theory', 'extension-field']"
86,Examples where $H\ne \mathrm{Aut}(E/E^H)$,Examples where,H\ne \mathrm{Aut}(E/E^H),"If $E/F$ is a field extension, and $H$ is a subgroup of $\mathrm{Aut}(E/F)$, it is quite trivial to see that $H\subset \mathrm{Aut}(E/E^H)$. Since the theorem only shows the inclusion relationship, I think there must be a lot of examples where $\subset$ is actually $\subsetneq$. But due to lack of knowledge I can't come up with one. Could you help me with this? Best regards.","If $E/F$ is a field extension, and $H$ is a subgroup of $\mathrm{Aut}(E/F)$, it is quite trivial to see that $H\subset \mathrm{Aut}(E/E^H)$. Since the theorem only shows the inclusion relationship, I think there must be a lot of examples where $\subset$ is actually $\subsetneq$. But due to lack of knowledge I can't come up with one. Could you help me with this? Best regards.",,"['abstract-algebra', 'field-theory', 'galois-theory', 'examples-counterexamples', 'extension-field']"
87,Need for projective modules,Need for projective modules,,"I wanted to ask why we require projective modules. After studying all the essential ingredients my guess is - Firstly, we worked with vector spaces (say modules over field $F$) (which are free modules)  and in that we could extend any basis of a submodule to get a basis for whole $V$ and thus property P P - ""any submodule of $V$ is a direct summand of $V$"" is satisfied. But in general for $R$-modules we could not express any submodule to be a direct summand, and thus we coined  semisimple rings whose definition is those rings $R$ for which every $R$ module $M$ satisfies P But what inspired people to go for projective modules, what do they generalize? Two equivalent definitions of a projective module P are- P is isomorphic to a direct summand of a free $R$ module. every exact sequence of the form $$0 \to M'\to M\to P\to 0$$ splits. I was looking for the inspiration that led to the study of projective modules and how do they help in simplifying studies of modules?","I wanted to ask why we require projective modules. After studying all the essential ingredients my guess is - Firstly, we worked with vector spaces (say modules over field $F$) (which are free modules)  and in that we could extend any basis of a submodule to get a basis for whole $V$ and thus property P P - ""any submodule of $V$ is a direct summand of $V$"" is satisfied. But in general for $R$-modules we could not express any submodule to be a direct summand, and thus we coined  semisimple rings whose definition is those rings $R$ for which every $R$ module $M$ satisfies P But what inspired people to go for projective modules, what do they generalize? Two equivalent definitions of a projective module P are- P is isomorphic to a direct summand of a free $R$ module. every exact sequence of the form $$0 \to M'\to M\to P\to 0$$ splits. I was looking for the inspiration that led to the study of projective modules and how do they help in simplifying studies of modules?",,"['abstract-algebra', 'modules', 'projective-module']"
88,"The relationship of $\hom(M\otimes_RN,M'\otimes_RN')$ and $\hom_R(M,M')\otimes\hom_R(N,N')$.",The relationship of  and .,"\hom(M\otimes_RN,M'\otimes_RN') \hom_R(M,M')\otimes\hom_R(N,N')","Let $R$ be a ring with identity, $M$ and $M'$ two right $R$-module, $N$ and $N'$ two left $R$-module. There is a natural way to define a homomorphism $$f:\hom_R(M,M')  \otimes \hom_R(N,N')\to     \hom(M\otimes_R N, M'\otimes_RN').$$ My question is that, is $f$ always monic, epic, or isomorphic? And if any answer is no, then is there any characterization of the case when $f$ is so?","Let $R$ be a ring with identity, $M$ and $M'$ two right $R$-module, $N$ and $N'$ two left $R$-module. There is a natural way to define a homomorphism $$f:\hom_R(M,M')  \otimes \hom_R(N,N')\to     \hom(M\otimes_R N, M'\otimes_RN').$$ My question is that, is $f$ always monic, epic, or isomorphic? And if any answer is no, then is there any characterization of the case when $f$ is so?",,"['abstract-algebra', 'modules', 'homological-algebra', 'tensor-products', 'additive-categories']"
89,Complement of open set is finite in Zariski topology,Complement of open set is finite in Zariski topology,,"This problem has two parts: a) Let $M$ be a finitely generated module over a Noetherian ring $A$. Prove that $S=\{ P \in\operatorname{Spec}(A) : M_P \mbox{ is a free }A_P\mbox{-module} \}$ is an open subset of $\operatorname{Spec}(A)$. b) If $M \subset A^r$ and $A=K[X,Y]$ (where $K$ is a field), prove that the complement of $S$ (as defined above) is a finite set. I did the first part. I proved that for a prime ideal $P \in\operatorname{Spec}(A)$, if $M_P \mbox{ is a free }A_P\mbox{-module}$, then there exists $f_P \notin P$ and an $n \in \mathbb{N}$ such that $M_{f_P} \cong A_{f_P}^n$. If $D(f)=i^{*}(\operatorname{Spec}(A_f))$ (which are open in Zariski topology), then we can prove that $S= \cup_{P \in S} D(f_P)$ , hence $S$ is open. I cannot solve part two. It is weird, since to prove that the complement of an open set in $\operatorname{Spec}(K[X])$ is always a finite set, since it is a PID. But $K[X,Y]$ is not, so we need to use the structure of $S$. Unfortunately I do not know how. Thank you.","This problem has two parts: a) Let $M$ be a finitely generated module over a Noetherian ring $A$. Prove that $S=\{ P \in\operatorname{Spec}(A) : M_P \mbox{ is a free }A_P\mbox{-module} \}$ is an open subset of $\operatorname{Spec}(A)$. b) If $M \subset A^r$ and $A=K[X,Y]$ (where $K$ is a field), prove that the complement of $S$ (as defined above) is a finite set. I did the first part. I proved that for a prime ideal $P \in\operatorname{Spec}(A)$, if $M_P \mbox{ is a free }A_P\mbox{-module}$, then there exists $f_P \notin P$ and an $n \in \mathbb{N}$ such that $M_{f_P} \cong A_{f_P}^n$. If $D(f)=i^{*}(\operatorname{Spec}(A_f))$ (which are open in Zariski topology), then we can prove that $S= \cup_{P \in S} D(f_P)$ , hence $S$ is open. I cannot solve part two. It is weird, since to prove that the complement of an open set in $\operatorname{Spec}(K[X])$ is always a finite set, since it is a PID. But $K[X,Y]$ is not, so we need to use the structure of $S$. Unfortunately I do not know how. Thank you.",,"['abstract-algebra', 'algebraic-geometry', 'commutative-algebra']"
90,"How many pairs of polynomials $(U,V)\in \Bbb Z[x]^2$ such that $P=U^2+V^2$ for a given polynomial with integer coefficients?",How many pairs of polynomials  such that  for a given polynomial with integer coefficients?,"(U,V)\in \Bbb Z[x]^2 P=U^2+V^2","This question is no more than curiosity question. For integers we know that a positive integer $n$ is a sum of two squares if and only if for any prime $p$ such that $p\equiv 3 \mod 4$ we have $v_p(n)$ is even, and we know also that the number of possible representations $n=x^2+y^2$ is $r_2(n)=4(d_{4,1}(n)-d_{4,3}(n))$. My question asks for similar results for other rings $\Bbb Z[x]$ for example Given a polynomial $P\in \Bbb Z[x]$ how many pairs of polynomials $(U,V)\in \Bbb Z[x]^2$ such that $P=U^2+V^2$ This can be interpreted in $\Bbb Z[i][x]$ as a factorization of $P$ but the problem is how many divisors $P$ in $\Bbb Z[i][x]$ may have, for example: $x^2+1=(x+i)(x-i)=(x^2+1)1 $","This question is no more than curiosity question. For integers we know that a positive integer $n$ is a sum of two squares if and only if for any prime $p$ such that $p\equiv 3 \mod 4$ we have $v_p(n)$ is even, and we know also that the number of possible representations $n=x^2+y^2$ is $r_2(n)=4(d_{4,1}(n)-d_{4,3}(n))$. My question asks for similar results for other rings $\Bbb Z[x]$ for example Given a polynomial $P\in \Bbb Z[x]$ how many pairs of polynomials $(U,V)\in \Bbb Z[x]^2$ such that $P=U^2+V^2$ This can be interpreted in $\Bbb Z[i][x]$ as a factorization of $P$ but the problem is how many divisors $P$ in $\Bbb Z[i][x]$ may have, for example: $x^2+1=(x+i)(x-i)=(x^2+1)1 $",,"['abstract-algebra', 'number-theory', 'polynomials']"
91,"Why is $(3,1+\sqrt{-5})^2=(2-\sqrt{-5})$ in $\mathbb{Z}[\sqrt{-5}]$",Why is  in,"(3,1+\sqrt{-5})^2=(2-\sqrt{-5}) \mathbb{Z}[\sqrt{-5}]","I want to show $(3,1+\sqrt{-5})^2=(2-\sqrt{-5})$ in $\mathbb{Z}[\sqrt{-5}]$. It's easy to see $(2-\sqrt{-5})\subset (3,1+\sqrt{-5})^2$ since $2-\sqrt{-5}=3-(1+\sqrt{-5})$ is in $(3,1+\sqrt{-5})^2$. But I have difficulty proving the converse inclusion. $(3,1+\sqrt{-5})^2=(3)(3)+(3)(1+\sqrt{-5})+(1+\sqrt{-5})^2=(3)(3,1+\sqrt{-5})+(2)(2-\sqrt{-5})$. How should I proceed?","I want to show $(3,1+\sqrt{-5})^2=(2-\sqrt{-5})$ in $\mathbb{Z}[\sqrt{-5}]$. It's easy to see $(2-\sqrt{-5})\subset (3,1+\sqrt{-5})^2$ since $2-\sqrt{-5}=3-(1+\sqrt{-5})$ is in $(3,1+\sqrt{-5})^2$. But I have difficulty proving the converse inclusion. $(3,1+\sqrt{-5})^2=(3)(3)+(3)(1+\sqrt{-5})+(1+\sqrt{-5})^2=(3)(3,1+\sqrt{-5})+(2)(2-\sqrt{-5})$. How should I proceed?",,"['abstract-algebra', 'elementary-number-theory', 'algebraic-number-theory']"
92,An example of a nilpotent group,An example of a nilpotent group,,"Is there an example of a nilpotent group such that $G/G'$ is (non-trivial) torsion-free while $G$ is not? I cannot think of any example of this kind and I think that it is not proved any result like this, am I wrong?","Is there an example of a nilpotent group such that $G/G'$ is (non-trivial) torsion-free while $G$ is not? I cannot think of any example of this kind and I think that it is not proved any result like this, am I wrong?",,"['abstract-algebra', 'group-theory', 'examples-counterexamples', 'nilpotence']"
93,Do these groups have a meaning?,Do these groups have a meaning?,,"Let $G$ be a group. We can say that $Aut(G)\leq S_G$ where $S_G$ denotes the set of all bijection from $G$ to $G$. But $S_G$ is not a good bound for $Aut(G)$ as $S_G$ grows very fast. Let's define new groups. $$C(G)=\{f\in S_G|f(x^k)=f(x)^k \text{for all $x\in G $ and $k \in \mathbb Z$}  \}$$  $$A(G)=\{f\in S_G|f(xy)=f(x)f(y) \text{if $xy=yx$}  \}$$ It is easy to see that $C(G)$ and $A(G)$ are both subgroups of $S_G$ and we can see that $$Aut(G)\leq A(G)\leq C(G)\leq S_G$$ Are these groups good bound for $Aut(G)$  or are they important for determining the structure of $G$ ? Edit: One simple observation; If $G$ is abelian then $Aut(G)=A(G)$ and if $G$ is cyclic then $Aut(G)=C(G)$. Edit$2$: Ahulpke provides a nice table for $A(G),C(G)$ and $Aut(G)$. In the table, for some groups, $|A(G):Aut(G)|=2$ so $Aut(G)$ is normal in $A(G)$. Is $Aut(G)$ always normal in $A(G)$ ?","Let $G$ be a group. We can say that $Aut(G)\leq S_G$ where $S_G$ denotes the set of all bijection from $G$ to $G$. But $S_G$ is not a good bound for $Aut(G)$ as $S_G$ grows very fast. Let's define new groups. $$C(G)=\{f\in S_G|f(x^k)=f(x)^k \text{for all $x\in G $ and $k \in \mathbb Z$}  \}$$  $$A(G)=\{f\in S_G|f(xy)=f(x)f(y) \text{if $xy=yx$}  \}$$ It is easy to see that $C(G)$ and $A(G)$ are both subgroups of $S_G$ and we can see that $$Aut(G)\leq A(G)\leq C(G)\leq S_G$$ Are these groups good bound for $Aut(G)$  or are they important for determining the structure of $G$ ? Edit: One simple observation; If $G$ is abelian then $Aut(G)=A(G)$ and if $G$ is cyclic then $Aut(G)=C(G)$. Edit$2$: Ahulpke provides a nice table for $A(G),C(G)$ and $Aut(G)$. In the table, for some groups, $|A(G):Aut(G)|=2$ so $Aut(G)$ is normal in $A(G)$. Is $Aut(G)$ always normal in $A(G)$ ?",,"['abstract-algebra', 'group-theory', 'finite-groups']"
94,Find orbit of $1$ for $\sigma$,Find orbit of  for,1 \sigma,"$\sigma = \left( \begin{array}{cc}1&2&3&4&5&6\\3&1&4&5&6&2\end{array}\right)$ $ 1 \mathop{\rightarrow}^{\sigma} 3 \mathop{\rightarrow}^{\sigma} 4 \mathop{\rightarrow}^{\sigma} 5 \mathop{\rightarrow}^{\sigma} 6 \mathop{\rightarrow}^{\sigma} 2 \mathop{\rightarrow}^{\sigma} 1 \mathop{\rightarrow}^{\sigma} \ldots$ following the notation in my book. But the question asks the orbit of $1$, so is that the orbit containing one, or one orbit? If it is the orbit containing one it would be $\{1,3,4,5,6,2\}$ If that is not what is meant then I am not sure what to do.","$\sigma = \left( \begin{array}{cc}1&2&3&4&5&6\\3&1&4&5&6&2\end{array}\right)$ $ 1 \mathop{\rightarrow}^{\sigma} 3 \mathop{\rightarrow}^{\sigma} 4 \mathop{\rightarrow}^{\sigma} 5 \mathop{\rightarrow}^{\sigma} 6 \mathop{\rightarrow}^{\sigma} 2 \mathop{\rightarrow}^{\sigma} 1 \mathop{\rightarrow}^{\sigma} \ldots$ following the notation in my book. But the question asks the orbit of $1$, so is that the orbit containing one, or one orbit? If it is the orbit containing one it would be $\{1,3,4,5,6,2\}$ If that is not what is meant then I am not sure what to do.",,"['abstract-algebra', 'group-theory', 'permutations']"
95,Group theory problems manual,Group theory problems manual,,"It would be really a worthy contribution if someone please,From the point of view ,of covering all the problems which are based on application of theorems of group theory, recommend a manual of problems with solutions. The book which satisfies following conditions: It should contain large set of problems on group theory with solution Problems should NOT be Proofs.., Show That.. types but instead They SHOULD be based on their applications.example : number of generators of of cyclic group having the given order... or number of homomorphisms between given groups etc...  In short it should not focus on problems involving proofs,But their applications. Book like Abstract algebra Problem and solution by ayman badawi. Which unfortunately is probably not available in SAARC countries. Is it possible to list such books along with links?","It would be really a worthy contribution if someone please,From the point of view ,of covering all the problems which are based on application of theorems of group theory, recommend a manual of problems with solutions. The book which satisfies following conditions: It should contain large set of problems on group theory with solution Problems should NOT be Proofs.., Show That.. types but instead They SHOULD be based on their applications.example : number of generators of of cyclic group having the given order... or number of homomorphisms between given groups etc...  In short it should not focus on problems involving proofs,But their applications. Book like Abstract algebra Problem and solution by ayman badawi. Which unfortunately is probably not available in SAARC countries. Is it possible to list such books along with links?",,"['abstract-algebra', 'group-theory']"
96,Isomorphism of semidirect products [D&F],Isomorphism of semidirect products [D&F],,"I want to solve the following problem from Dummit & Foote's Abstract Algebra text (p. 184 Exercise 6): Assume that $K$ is a cyclic group, $H$ is an arbitrary group and $\varphi_1$ and $\varphi_2$ are homomorphisms from $K$ into $\text{Aut}(H)$ such that $\varphi_1(K)$ and $\varphi_2(K)$ are subgroups of $\text{Aut}(H)$. If $K$ is infinite assume $\varphi_1$ and $\varphi_2$ are injective. Prove by constructing an explicit isomorphism that $H \rtimes_{\varphi_1} K \cong H \rtimes_{\varphi_2} K$ (in particular, if the subgroups $\varphi_1(K)$ and $\varphi_2(K)$ are equal in $\text{Aut}(H)$, then the resulting semidirect products are isomorphic). [Suppose $\sigma \varphi_1(K) \sigma^{-1}=\varphi_2(K)$ so that for some $a \in \mathbb{Z}$ we have $\sigma \varphi_1(k) \sigma^{-1}=\varphi_2(k)^a$ for all $k \in K$. Show that the map $\psi:H \rtimes_{\varphi_1} K \to H \rtimes_{\varphi_2} K$ defined by $\psi((h,k))=(\sigma(h),k^a)$ is a homomorphism. Show $\psi$ is bijective by constructing a 2-sided inverse.] My attempt: Let $K=\langle x \rangle$, and suppose $\sigma \in \text{Aut}(H)$ conjugates $\varphi_1(K)$ to $\varphi_2(K)$, that is $$\sigma \varphi_1(K) \sigma^{-1}=\varphi_2(K) \tag{1}.$$ From this we find $$\sigma \varphi_1(x) \sigma^{-1}=\varphi_2(x^a) \tag{2} $$ for some $a \in \mathbb{Z}$. Since all elements of $K$ are powers $x^n$ of $x$, raising this equality to the $n$-th power gives $$\forall k \in K:\sigma \varphi_1(k) \sigma^{-1}=\varphi_2(k^a)=\varphi_2(k)^a \tag{3}.$$ We now prove that the suggested $\psi$ is a group homomorphism: \begin{equation} \begin{split} \psi((h_1,k_1)(h_2,k_2))&=\psi(h_1 \varphi_1(k_1)(h_2),k_1k_2)=(\sigma(h_1 \varphi_1(k_1)(h_2)),(k_1k_2)^a)\\ &=(\sigma(h_1)(\sigma \varphi_1(k_1))(h_2),k_1^a k_2^a)=(\sigma(h_1)(\varphi_2(k_1^a) \sigma)(h_2),k_1^ak_2^a)\\ &=(\sigma(h_1),k_1^a)(\sigma(h_2),k_2^a)=\psi((h_1,k_1))\psi((h_2,k_2)) \end{split} \end{equation} Where we have used the fact that $K$ is abelian, alongside with the homomorphism law for $\sigma$ and equation $(3)$. We're left with showing that $\psi$ has a 2-sided inverse, which will be done in two cases: Assume $K=\langle x \rangle$ is infinite cyclic. Property $(3)$ gives  $$\varphi_2(K)=\varphi_2(K^a) \tag{4}$$ where $K^a$ is the image of $K$ under the $a$-th power homomorphism $K \to K:k \mapsto k^a$. Since $\varphi_2$ is injective, this is only possible if the $a$-th power homomorphism is surjective, which happens iff $a=\pm 1$. We can thus see that $$\chi((h,k))=(\sigma^{-1}(h),k^a)$$ is a 2-sided inverse of $\psi$. Assume $K=\langle x \rangle \cong Z_n$ is finite cyclic of order $n$, and denote the orders of the cyclic groups $\varphi_1(K),\varphi_2(K)$ by $m$. I believe that $(a,n) = 1$ so that there is some integer $b$ such that $ab \equiv 1 \pmod{n}$. If we have this, we can see that $$\chi((h,k))=(\sigma^{-1}(h),k^b) $$ is a 2-sided inverse of $\psi$. However, all I could show is the following. Obviously, $m|n$. Since $\varphi_1(K)=\langle \varphi_1(x) \rangle$ and $\varphi_2(K)=\langle \varphi_2(K) \rangle$ we have $|\varphi_1(x)|=|\varphi_2(x)|$. According to equation (3) $\varphi_2(K)$ is also generated by $\varphi_2(x^a)$, so that $|\varphi_2(x^a)|=|\varphi_2(x)|$ which gives $(a,m)=1$. Raising equation $(2)$ to the power of $|x^a|=\frac{n}{(a,n)}$ gives $1=\varphi_2(1)=\varphi_2((x^{a})^{\frac{n}{(a,n)}})=\varphi_2(x^a)^{\frac{n}{(a,n)}}$, so  that $m| \frac{n}{(a,n)}$. From the first occurrence of ""$a$"" in equation $(2)$, and the fact that $\varphi_2(x^a)=\varphi_2(x)^a$ we can see that $a$ may shifted by any multiple of $m$. My questions: Are there any flaws with my proof? It seems that in the infinite case, it is only necessary to assume one of the $\varphi_i$'s to be injective. Is this true? Is it possible to prove that ""$a$"" can be chosen coprime with $n$? Thank you!","I want to solve the following problem from Dummit & Foote's Abstract Algebra text (p. 184 Exercise 6): Assume that $K$ is a cyclic group, $H$ is an arbitrary group and $\varphi_1$ and $\varphi_2$ are homomorphisms from $K$ into $\text{Aut}(H)$ such that $\varphi_1(K)$ and $\varphi_2(K)$ are subgroups of $\text{Aut}(H)$. If $K$ is infinite assume $\varphi_1$ and $\varphi_2$ are injective. Prove by constructing an explicit isomorphism that $H \rtimes_{\varphi_1} K \cong H \rtimes_{\varphi_2} K$ (in particular, if the subgroups $\varphi_1(K)$ and $\varphi_2(K)$ are equal in $\text{Aut}(H)$, then the resulting semidirect products are isomorphic). [Suppose $\sigma \varphi_1(K) \sigma^{-1}=\varphi_2(K)$ so that for some $a \in \mathbb{Z}$ we have $\sigma \varphi_1(k) \sigma^{-1}=\varphi_2(k)^a$ for all $k \in K$. Show that the map $\psi:H \rtimes_{\varphi_1} K \to H \rtimes_{\varphi_2} K$ defined by $\psi((h,k))=(\sigma(h),k^a)$ is a homomorphism. Show $\psi$ is bijective by constructing a 2-sided inverse.] My attempt: Let $K=\langle x \rangle$, and suppose $\sigma \in \text{Aut}(H)$ conjugates $\varphi_1(K)$ to $\varphi_2(K)$, that is $$\sigma \varphi_1(K) \sigma^{-1}=\varphi_2(K) \tag{1}.$$ From this we find $$\sigma \varphi_1(x) \sigma^{-1}=\varphi_2(x^a) \tag{2} $$ for some $a \in \mathbb{Z}$. Since all elements of $K$ are powers $x^n$ of $x$, raising this equality to the $n$-th power gives $$\forall k \in K:\sigma \varphi_1(k) \sigma^{-1}=\varphi_2(k^a)=\varphi_2(k)^a \tag{3}.$$ We now prove that the suggested $\psi$ is a group homomorphism: \begin{equation} \begin{split} \psi((h_1,k_1)(h_2,k_2))&=\psi(h_1 \varphi_1(k_1)(h_2),k_1k_2)=(\sigma(h_1 \varphi_1(k_1)(h_2)),(k_1k_2)^a)\\ &=(\sigma(h_1)(\sigma \varphi_1(k_1))(h_2),k_1^a k_2^a)=(\sigma(h_1)(\varphi_2(k_1^a) \sigma)(h_2),k_1^ak_2^a)\\ &=(\sigma(h_1),k_1^a)(\sigma(h_2),k_2^a)=\psi((h_1,k_1))\psi((h_2,k_2)) \end{split} \end{equation} Where we have used the fact that $K$ is abelian, alongside with the homomorphism law for $\sigma$ and equation $(3)$. We're left with showing that $\psi$ has a 2-sided inverse, which will be done in two cases: Assume $K=\langle x \rangle$ is infinite cyclic. Property $(3)$ gives  $$\varphi_2(K)=\varphi_2(K^a) \tag{4}$$ where $K^a$ is the image of $K$ under the $a$-th power homomorphism $K \to K:k \mapsto k^a$. Since $\varphi_2$ is injective, this is only possible if the $a$-th power homomorphism is surjective, which happens iff $a=\pm 1$. We can thus see that $$\chi((h,k))=(\sigma^{-1}(h),k^a)$$ is a 2-sided inverse of $\psi$. Assume $K=\langle x \rangle \cong Z_n$ is finite cyclic of order $n$, and denote the orders of the cyclic groups $\varphi_1(K),\varphi_2(K)$ by $m$. I believe that $(a,n) = 1$ so that there is some integer $b$ such that $ab \equiv 1 \pmod{n}$. If we have this, we can see that $$\chi((h,k))=(\sigma^{-1}(h),k^b) $$ is a 2-sided inverse of $\psi$. However, all I could show is the following. Obviously, $m|n$. Since $\varphi_1(K)=\langle \varphi_1(x) \rangle$ and $\varphi_2(K)=\langle \varphi_2(K) \rangle$ we have $|\varphi_1(x)|=|\varphi_2(x)|$. According to equation (3) $\varphi_2(K)$ is also generated by $\varphi_2(x^a)$, so that $|\varphi_2(x^a)|=|\varphi_2(x)|$ which gives $(a,m)=1$. Raising equation $(2)$ to the power of $|x^a|=\frac{n}{(a,n)}$ gives $1=\varphi_2(1)=\varphi_2((x^{a})^{\frac{n}{(a,n)}})=\varphi_2(x^a)^{\frac{n}{(a,n)}}$, so  that $m| \frac{n}{(a,n)}$. From the first occurrence of ""$a$"" in equation $(2)$, and the fact that $\varphi_2(x^a)=\varphi_2(x)^a$ we can see that $a$ may shifted by any multiple of $m$. My questions: Are there any flaws with my proof? It seems that in the infinite case, it is only necessary to assume one of the $\varphi_i$'s to be injective. Is this true? Is it possible to prove that ""$a$"" can be chosen coprime with $n$? Thank you!",,"['abstract-algebra', 'group-theory', 'semidirect-product']"
97,Homotopy of double chain complexes,Homotopy of double chain complexes,,"Consider complexes $(A,d_1), (A',d_1)$, $(C,d_2), (C',d_2)$ and morphisms $f_1,f_2: (A,d_1)\to (A',d_1)$ and $g_1,g_2: (C,d_2)\to (C',d_2)$ of degrees $0$. Consider the functor $(-\otimes-)$, then  $$A\otimes C = \bigoplus_{m,n} A^m\otimes C^n, \text{along with differentials}$$ $$ \partial_1 = d_1\otimes C: A^n\otimes C^m\to A^{n+1}\otimes C^m, $$ $$ \partial_2 = (-1)^n A\otimes d_2: A^n\otimes C^m\to A^n\otimes C^{m+1} $$  forms a double complex. Given homotopies $s:f_1\cong f_2$ and $t:g_1\cong g_2$, Cartan Eilenberg claims that $(s\otimes C, (-1)^nA\otimes t)$ yields a homotopy between $f_1\otimes g_1$ and $f_2\otimes g_2$ which I failed to see. As a first step, we need to check that  $$ (s\otimes C)\partial_1+\partial_1(s\otimes C)+ (-1)^n(A\otimes t)\partial_2+ (-1)^n\partial_2(A\otimes t) = f_1\otimes g_1-f_2\otimes g_2 $$ but this is not true, as the left hand side simplifies to \begin{align*} & (s\otimes C)\partial_1+\partial_1(s\otimes C)+ (-1)^n(A\otimes t)\partial_2+ (-1)^n\partial_2(A\otimes t)\\ = & (sd_1+d_1s)\otimes C+ (-1)^{2n} A\otimes (td_2+d_2t)\\ = &(f_1-f_2)\otimes C+ A\otimes (g_1-g_2) \end{align*} which is not equal to the right hand side. Could you please help me point out what went wrong? Thank you. The relevant material is page 63 last but one paragraph of Cartan Eilenberg, see attached.","Consider complexes $(A,d_1), (A',d_1)$, $(C,d_2), (C',d_2)$ and morphisms $f_1,f_2: (A,d_1)\to (A',d_1)$ and $g_1,g_2: (C,d_2)\to (C',d_2)$ of degrees $0$. Consider the functor $(-\otimes-)$, then  $$A\otimes C = \bigoplus_{m,n} A^m\otimes C^n, \text{along with differentials}$$ $$ \partial_1 = d_1\otimes C: A^n\otimes C^m\to A^{n+1}\otimes C^m, $$ $$ \partial_2 = (-1)^n A\otimes d_2: A^n\otimes C^m\to A^n\otimes C^{m+1} $$  forms a double complex. Given homotopies $s:f_1\cong f_2$ and $t:g_1\cong g_2$, Cartan Eilenberg claims that $(s\otimes C, (-1)^nA\otimes t)$ yields a homotopy between $f_1\otimes g_1$ and $f_2\otimes g_2$ which I failed to see. As a first step, we need to check that  $$ (s\otimes C)\partial_1+\partial_1(s\otimes C)+ (-1)^n(A\otimes t)\partial_2+ (-1)^n\partial_2(A\otimes t) = f_1\otimes g_1-f_2\otimes g_2 $$ but this is not true, as the left hand side simplifies to \begin{align*} & (s\otimes C)\partial_1+\partial_1(s\otimes C)+ (-1)^n(A\otimes t)\partial_2+ (-1)^n\partial_2(A\otimes t)\\ = & (sd_1+d_1s)\otimes C+ (-1)^{2n} A\otimes (td_2+d_2t)\\ = &(f_1-f_2)\otimes C+ A\otimes (g_1-g_2) \end{align*} which is not equal to the right hand side. Could you please help me point out what went wrong? Thank you. The relevant material is page 63 last but one paragraph of Cartan Eilenberg, see attached.",,"['abstract-algebra', 'homological-algebra', 'tensor-products', 'abelian-categories', 'spectral-sequences']"
98,Intuitive meaning of left and right cosets?,Intuitive meaning of left and right cosets?,,"What is the difference between left and right cosets? I know their definition, but what I am seeking is the intuition behind left and right coset. I used to think of cosets as slicing a group (since I am learning group theory) into different segments that has no intersection. However, why then is there left and right cosets? I came across this thing that I found very puzzling if $gH = Hk$ for some $k,g$ in group $G$ then $gH = Hg$. I prove it using $g1_H = hk$ so $1_Hg =hk$ and hence Hg = Hk = gH. I cannot get the intuition behind it. Can someone enlighten me please.","What is the difference between left and right cosets? I know their definition, but what I am seeking is the intuition behind left and right coset. I used to think of cosets as slicing a group (since I am learning group theory) into different segments that has no intersection. However, why then is there left and right cosets? I came across this thing that I found very puzzling if $gH = Hk$ for some $k,g$ in group $G$ then $gH = Hg$. I prove it using $g1_H = hk$ so $1_Hg =hk$ and hence Hg = Hk = gH. I cannot get the intuition behind it. Can someone enlighten me please.",,"['abstract-algebra', 'group-theory']"
99,Exhibiting an isomorphism between two finite fields,Exhibiting an isomorphism between two finite fields,,So I want to find the isomorphism $\phi$ that takes $F = \mathbb{Z}_3/\langle x^3 - x - 1\rangle$ to $E = \mathbb{Z}_3/\langle x^3 - x + 1\rangle$.  I understand that these are both finite fields of size 3^3 since $x^3 - x - 1$ and $x^3 - x + 1$ are both irreducible polynomials of degree 3.  I feel like a good start would be to take the subfield $\mathbb{Z_3}$ in $F$ to the subfield $\mathbb{Z_3}$ in $E$.  Or maybe find the right generator of each multiplicative group of size $3^3-1$ of each field and send those to each other.,So I want to find the isomorphism $\phi$ that takes $F = \mathbb{Z}_3/\langle x^3 - x - 1\rangle$ to $E = \mathbb{Z}_3/\langle x^3 - x + 1\rangle$.  I understand that these are both finite fields of size 3^3 since $x^3 - x - 1$ and $x^3 - x + 1$ are both irreducible polynomials of degree 3.  I feel like a good start would be to take the subfield $\mathbb{Z_3}$ in $F$ to the subfield $\mathbb{Z_3}$ in $E$.  Or maybe find the right generator of each multiplicative group of size $3^3-1$ of each field and send those to each other.,,"['abstract-algebra', 'finite-fields']"
