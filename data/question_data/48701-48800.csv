,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Find multiple integrals $I_{\max}(k,n)$ and $I_{\min}(k,n)$ in various ways",Find multiple integrals  and  in various ways,"I_{\max}(k,n) I_{\min}(k,n)","$I_{\max}(k,n)=\underbrace{\int\limits_0^1\int\limits_0^1\dots\int\limits_0^1}_k\left(\max\limits_{1\le i\le k}x_i\right)^n\,dx_1dx_2\dots dx_k$ $I_{\min}(k,n)=\underbrace{\int\limits_0^1\int\limits_0^1\dots\int\limits_0^1}_k\left(\min\limits_{1\le i\le k}x_i\right)^n\,dx_1dx_2\dots dx_k$ Various solutions are welcome. P.S. I added my solution as an answer.","$I_{\max}(k,n)=\underbrace{\int\limits_0^1\int\limits_0^1\dots\int\limits_0^1}_k\left(\max\limits_{1\le i\le k}x_i\right)^n\,dx_1dx_2\dots dx_k$ $I_{\min}(k,n)=\underbrace{\int\limits_0^1\int\limits_0^1\dots\int\limits_0^1}_k\left(\min\limits_{1\le i\le k}x_i\right)^n\,dx_1dx_2\dots dx_k$ Various solutions are welcome. P.S. I added my solution as an answer.",,"['integration', 'multivariable-calculus', 'definite-integrals', 'big-list']"
1,How find this integral $I=\int_{0}^{1}\sqrt{1-W^2(x)}dx$,How find this integral,I=\int_{0}^{1}\sqrt{1-W^2(x)}dx,"How find this nice integral $$I=\int_{0}^{1}\sqrt{1-W^2(x)}dx$$ where, $W(x)$ is Lambert W function My try: let $$\sqrt{1-W^2(x)}=u\Longrightarrow W(x)=\sqrt{1-u^2}$$ and since $x=W(x)e^{W(x)}$ so $$x=W^{-1}(\sqrt{1-u^2})=\sqrt{1-u^2}e^{\sqrt{1-u^2}}?$$   so   $$dx=-ue^{1-u^2}\dfrac{1+\sqrt{1-u^2}}{\sqrt{1-u^2}}du$$   so   $$I=\int_{1}^{a}-u^2e^{1-u^2}\dfrac{1+\sqrt{1-u^2}}{\sqrt{1-u^2}}du$$ where $a$ such $$\sqrt{1-a^2}e^{\sqrt{1-a^2}}=1(a>0)$$ then I can't,Thank you very much .","How find this nice integral $$I=\int_{0}^{1}\sqrt{1-W^2(x)}dx$$ where, $W(x)$ is Lambert W function My try: let $$\sqrt{1-W^2(x)}=u\Longrightarrow W(x)=\sqrt{1-u^2}$$ and since $x=W(x)e^{W(x)}$ so $$x=W^{-1}(\sqrt{1-u^2})=\sqrt{1-u^2}e^{\sqrt{1-u^2}}?$$   so   $$dx=-ue^{1-u^2}\dfrac{1+\sqrt{1-u^2}}{\sqrt{1-u^2}}du$$   so   $$I=\int_{1}^{a}-u^2e^{1-u^2}\dfrac{1+\sqrt{1-u^2}}{\sqrt{1-u^2}}du$$ where $a$ such $$\sqrt{1-a^2}e^{\sqrt{1-a^2}}=1(a>0)$$ then I can't,Thank you very much .",,"['integration', 'definite-integrals', 'lambert-w']"
2,Evaluating the integral: $\int_{0}^{\infty} \frac{|2-2\cos(x)-x\sin(x)|}{x^4}~dx$,Evaluating the integral:,\int_{0}^{\infty} \frac{|2-2\cos(x)-x\sin(x)|}{x^4}~dx,"I am interested in evaluating the following integral: $$ \int_{0}^{\infty} \frac{|2-2\cos(x)-x\sin(x)|}{x^4}~dx $$ Using Matlab, Numerically it seems that the integral is convergent,  but I'm not sure about it. How can we prove that the integral is convergent or not? Many Thanks in advance.","I am interested in evaluating the following integral: $$ \int_{0}^{\infty} \frac{|2-2\cos(x)-x\sin(x)|}{x^4}~dx $$ Using Matlab, Numerically it seems that the integral is convergent,  but I'm not sure about it. How can we prove that the integral is convergent or not? Many Thanks in advance.",,['integration']
3,Integral of $x^2 \exp(-ax^2)$ using the gamma function?,Integral of  using the gamma function?,x^2 \exp(-ax^2),"I'm struggling with this integral: $$\int_{-\infty}^{\infty}x^{2}e^{-ax^{2}}dx = \frac{\sqrt{\pi}}{2a^{3/2}}$$ Is there a way to do this integration without using integration by parts and then explicitly relying on the Gaussian integral, instead using the Gamma function $\Gamma(a)=\int_{0}^{\infty}x^{a-1}e^{-x} dx$ ? I had tried the substitution $u=ax^2$ to give $\frac{2}{a}\int_{0}^{\infty}ue^{-u}du$ but that doesn't seem to get me far. Thanks in advance for any help or hints !","I'm struggling with this integral: $$\int_{-\infty}^{\infty}x^{2}e^{-ax^{2}}dx = \frac{\sqrt{\pi}}{2a^{3/2}}$$ Is there a way to do this integration without using integration by parts and then explicitly relying on the Gaussian integral, instead using the Gamma function $\Gamma(a)=\int_{0}^{\infty}x^{a-1}e^{-x} dx$ ? I had tried the substitution $u=ax^2$ to give $\frac{2}{a}\int_{0}^{\infty}ue^{-u}du$ but that doesn't seem to get me far. Thanks in advance for any help or hints !",,"['integration', 'gamma-function']"
4,Integral via complex analysis. Integral via hypercomplex analysis,Integral via complex analysis. Integral via hypercomplex analysis,,If I remember rightly there are some integrals of real functions which are easier to compute by using complex analysis. Is this because of properties of the particular function or because of a lack of a known real analysis technique? Are there functions which would require hypercomplex analysis to integrate?,If I remember rightly there are some integrals of real functions which are easier to compute by using complex analysis. Is this because of properties of the particular function or because of a lack of a known real analysis technique? Are there functions which would require hypercomplex analysis to integrate?,,"['integration', 'complex-analysis', 'analysis']"
5,Encountered $\displaystyle{\sum_{k=1}^\infty\frac{(-1)^k\sin(kt)}{k}}$ while solving another integral,Encountered  while solving another integral,\displaystyle{\sum_{k=1}^\infty\frac{(-1)^k\sin(kt)}{k}},"I am trying to evaluate the following, $$\zeta=\sum_{k=1}^{\infty}\frac{1}{k}\int_{\pi k}^{\infty}\frac{\sin(x)}{x}\ dx$$ but I encountered the $\color{orange}{\text{series}}$ , $$\color{orange}{\sum_{k=1}^\infty\frac{(-1)^k\sin(kt)}{k},\quad t\in(0,2\pi)}$$ which I do not know how to compute. By a little search I found that, $$\sum_{k=1}^\infty\frac{\sin(kt)}{k}=\frac{\pi-t}{2},\quad t\in(0,2\pi)$$ which would be useful if I was evaluating, $$\sum_{k=1}^\infty\frac{1}{k}\int^\infty_{\color{red}{2\pi k}}\frac{\sin(x)}{x}\ dx$$ but that is not the case. Any ideas on $\zeta$ or the series is welcome. My attempt is below. Let $x=u+\pi k$ , $$\sum_{k=1}^{\infty}\frac{1}{k}\int_{\pi k}^{\infty}\frac{\sin(x)}{x}\ dx=\sum_{k=1}^\infty\frac{1}{k}\int_{0}^\infty\frac{\sin(u+\pi k)}{u+\pi k}\ du$$ note that for $k\in\mathbb{N}$ , $\sin(u+\pi k)=\sin(u)\cos(\pi k)+\sin(\pi k)\cos(u)=(-1)^k\sin(u)$ , $$\sum_{k=1}^\infty\frac{(-1)^k}{k}\int_{0}^\infty\frac{\sin(u)}{u+\pi k}\ du=\sum_{k=1}^\infty\frac{(-1)^k}{k}\int_0^\infty\frac{\sin(ks)}{s+\pi }\ ds$$ after $s=u/k$ . Then we can exploit the periodicity of the integrand as follows, $$\int_0^\infty\frac{\sin(ks)}{s+\pi}\ ds=\sum_{n=0}^\infty\int_{2\pi n}^{2\pi(n+1)}\frac{\sin(ks)}{s+\pi}\ ds=\sum_{n=1}^\infty\int_0^{2\pi}\frac{\sin(kt)}{t+(2n-1)\pi}\ dt$$ where we made the substitution $t=s-2\pi n$ and re-indexed the series. After interchanging the series' and summing over $k$ pops up, $$\sum_{n=1}^\infty\int_0^{2\pi}\color{orange}{\sum_{k=1}^\infty\frac{(-1)^k\sin(kt)}{k\color{black}{(t+(2n-1)\pi)}}}\ dt$$ Edit: Looking at the answers I am receiving, evaluating $\zeta$ may not be as straightforward as I initially thought; the $\color{\orange}{\text{series}}$ seems to complicate convergence a bit. I am going to add calculations for the analogous series, so maybe someone can help me find a solution to $\zeta$ . Let $u=x-2\pi k$ then $t=u/k$ (we could combine these substutions into one), $$\sum_{k=1}^\infty\frac{1}{k}\int^\infty_{\color{red}{2\pi k}}\frac{\sin(x)}{x}\ dx=\sum_{k=1}^\infty\frac{1}{k}\int_0^\infty\frac{\sin(u)}{u+2\pi k}\ du=\sum_{k=1}^\infty\frac{1}{k}\int_0^\infty\frac{\sin(kt)}{t+2\pi}\ dt$$ working similarly as above, $$\sum_{k=1}^\infty\frac{1}{k}\int_0^\infty\frac{\sin(kt)}{t+2\pi}\ dt=\sum_{k=1}^\infty\frac{1}{k}\sum_{n=0}^\infty\int_{2\pi n}^{2\pi(n+1)}\frac{\sin(kt)}{t+2\pi}\ dt=\sum_{k=1}^\infty\frac{1}{k}\sum_{n=1}^\infty\int_0^{2\pi}\frac{\sin(ks)}{s+2\pi n}\ ds$$ after $s=t-2\pi n$ and re-indexing. Switching the order of summation, $$\sum_{n=1}^\infty\sum_{k=1}^\infty\int_0^{2\pi}\frac{\sin(ks)}{k(s+2\pi n)}\ ds=\frac{1}{2}\sum_{n=1}^\infty\int_0^{2\pi}\frac{\pi-s}{s+2\pi n}\ ds$$ where I used the nicer result, $$\sum_{k=1}^\infty\frac{\sin(ks)}{k}=\frac{\pi-s}{2},\quad s\in(0,2\pi)$$ the integral is now easy considering the two numerators. Simple integration yields, $$\frac{\pi}{2}\sum_{n=1}^\infty\left((1+2n)\log\left(1+\frac{1}{n}\right)-2\right)$$ distributing the $1/2$ factor into the sum and rewriting as a product (we take limits), $$\lim_{N\to\infty}\pi\log\frac{1}{e^N}\prod_{n=1}^N\left(\frac{n+1}{n}\right)^{(n+1/2)}$$ the product telescopes, $$\lim_{N\to\infty}\pi\log\frac{\sqrt{N+1}}{e^N}\frac{(N+1)^N}{N!}$$ by Taylor's and Stirling's formula, $$\frac{\sqrt{N+1}}{e^N}\frac{(N+1)^N}{N!}\sim\frac{e}{\sqrt{2\pi}}\left(1-\frac{1}{12N}+\frac{25}{288N^2}-\cdots\right)$$ as $N\to+\infty$ , hence, $$\sum_{k=1}^\infty\frac{1}{k}\int^\infty_{\color{red}{2\pi k}}\frac{\sin(x)}{x}\ dx=\pi \log\frac{e}{\sqrt{2\pi}}.$$","I am trying to evaluate the following, but I encountered the , which I do not know how to compute. By a little search I found that, which would be useful if I was evaluating, but that is not the case. Any ideas on or the series is welcome. My attempt is below. Let , note that for , , after . Then we can exploit the periodicity of the integrand as follows, where we made the substitution and re-indexed the series. After interchanging the series' and summing over pops up, Edit: Looking at the answers I am receiving, evaluating may not be as straightforward as I initially thought; the seems to complicate convergence a bit. I am going to add calculations for the analogous series, so maybe someone can help me find a solution to . Let then (we could combine these substutions into one), working similarly as above, after and re-indexing. Switching the order of summation, where I used the nicer result, the integral is now easy considering the two numerators. Simple integration yields, distributing the factor into the sum and rewriting as a product (we take limits), the product telescopes, by Taylor's and Stirling's formula, as , hence,","\zeta=\sum_{k=1}^{\infty}\frac{1}{k}\int_{\pi k}^{\infty}\frac{\sin(x)}{x}\ dx \color{orange}{\text{series}} \color{orange}{\sum_{k=1}^\infty\frac{(-1)^k\sin(kt)}{k},\quad t\in(0,2\pi)} \sum_{k=1}^\infty\frac{\sin(kt)}{k}=\frac{\pi-t}{2},\quad t\in(0,2\pi) \sum_{k=1}^\infty\frac{1}{k}\int^\infty_{\color{red}{2\pi k}}\frac{\sin(x)}{x}\ dx \zeta x=u+\pi k \sum_{k=1}^{\infty}\frac{1}{k}\int_{\pi k}^{\infty}\frac{\sin(x)}{x}\ dx=\sum_{k=1}^\infty\frac{1}{k}\int_{0}^\infty\frac{\sin(u+\pi k)}{u+\pi k}\ du k\in\mathbb{N} \sin(u+\pi k)=\sin(u)\cos(\pi k)+\sin(\pi k)\cos(u)=(-1)^k\sin(u) \sum_{k=1}^\infty\frac{(-1)^k}{k}\int_{0}^\infty\frac{\sin(u)}{u+\pi k}\ du=\sum_{k=1}^\infty\frac{(-1)^k}{k}\int_0^\infty\frac{\sin(ks)}{s+\pi }\ ds s=u/k \int_0^\infty\frac{\sin(ks)}{s+\pi}\ ds=\sum_{n=0}^\infty\int_{2\pi n}^{2\pi(n+1)}\frac{\sin(ks)}{s+\pi}\ ds=\sum_{n=1}^\infty\int_0^{2\pi}\frac{\sin(kt)}{t+(2n-1)\pi}\ dt t=s-2\pi n k \sum_{n=1}^\infty\int_0^{2\pi}\color{orange}{\sum_{k=1}^\infty\frac{(-1)^k\sin(kt)}{k\color{black}{(t+(2n-1)\pi)}}}\ dt \zeta \color{\orange}{\text{series}} \zeta u=x-2\pi k t=u/k \sum_{k=1}^\infty\frac{1}{k}\int^\infty_{\color{red}{2\pi k}}\frac{\sin(x)}{x}\ dx=\sum_{k=1}^\infty\frac{1}{k}\int_0^\infty\frac{\sin(u)}{u+2\pi k}\ du=\sum_{k=1}^\infty\frac{1}{k}\int_0^\infty\frac{\sin(kt)}{t+2\pi}\ dt \sum_{k=1}^\infty\frac{1}{k}\int_0^\infty\frac{\sin(kt)}{t+2\pi}\ dt=\sum_{k=1}^\infty\frac{1}{k}\sum_{n=0}^\infty\int_{2\pi n}^{2\pi(n+1)}\frac{\sin(kt)}{t+2\pi}\ dt=\sum_{k=1}^\infty\frac{1}{k}\sum_{n=1}^\infty\int_0^{2\pi}\frac{\sin(ks)}{s+2\pi n}\ ds s=t-2\pi n \sum_{n=1}^\infty\sum_{k=1}^\infty\int_0^{2\pi}\frac{\sin(ks)}{k(s+2\pi n)}\ ds=\frac{1}{2}\sum_{n=1}^\infty\int_0^{2\pi}\frac{\pi-s}{s+2\pi n}\ ds \sum_{k=1}^\infty\frac{\sin(ks)}{k}=\frac{\pi-s}{2},\quad s\in(0,2\pi) \frac{\pi}{2}\sum_{n=1}^\infty\left((1+2n)\log\left(1+\frac{1}{n}\right)-2\right) 1/2 \lim_{N\to\infty}\pi\log\frac{1}{e^N}\prod_{n=1}^N\left(\frac{n+1}{n}\right)^{(n+1/2)} \lim_{N\to\infty}\pi\log\frac{\sqrt{N+1}}{e^N}\frac{(N+1)^N}{N!} \frac{\sqrt{N+1}}{e^N}\frac{(N+1)^N}{N!}\sim\frac{e}{\sqrt{2\pi}}\left(1-\frac{1}{12N}+\frac{25}{288N^2}-\cdots\right) N\to+\infty \sum_{k=1}^\infty\frac{1}{k}\int^\infty_{\color{red}{2\pi k}}\frac{\sin(x)}{x}\ dx=\pi \log\frac{e}{\sqrt{2\pi}}.","['integration', 'sequences-and-series', 'solution-verification', 'definite-integrals']"
6,What is ⨋ (U+2A0B: summation with integral) used for?,What is ⨋ (U+2A0B: summation with integral) used for?,,"I initially thought that symbol ⨋ is some sort of joke, but apparently it is used, and it made it's way to Unicode in 2002. The only reference to its meaning or usage I found is its site on wiktionary , which references ""The principles of modern thermodynamics"" by Deffner and Campbell: The distribution of work values is then given by averaging over an ensemble of realizations of the same process, $ P(W) = \left< \delta(W - W[\left| m\right>; \left| n \right>] )\right>$ which can be rewritten as $ P(W) = \operatorname{⨋}_{m, n}\delta(W - W[\left| m\right>; \left| n \right>] )p(\left|m\right> \to \left|n\right>)$ . In the latter equation the symbol ⨋ denotes that we have to sum over the discrete part of the eigenvalue spectrum and integrate over the continuous part. I admit that I have no Idea what author is talking about, but it seems that the ""summation over the discrete part and integration over the continuous part"" could be achieved by integrating with respect to adequate measure. Since integral itself can be viewed as generalization of summation, why bother with this ⨋ symbol? I think it could be some sort of notation convention used by physicists to link visuals to the method of computation involved, but that's just my blind guess. Does this symbol have formal (precise) meaning? Where is it used?","I initially thought that symbol ⨋ is some sort of joke, but apparently it is used, and it made it's way to Unicode in 2002. The only reference to its meaning or usage I found is its site on wiktionary , which references ""The principles of modern thermodynamics"" by Deffner and Campbell: The distribution of work values is then given by averaging over an ensemble of realizations of the same process, which can be rewritten as . In the latter equation the symbol ⨋ denotes that we have to sum over the discrete part of the eigenvalue spectrum and integrate over the continuous part. I admit that I have no Idea what author is talking about, but it seems that the ""summation over the discrete part and integration over the continuous part"" could be achieved by integrating with respect to adequate measure. Since integral itself can be viewed as generalization of summation, why bother with this ⨋ symbol? I think it could be some sort of notation convention used by physicists to link visuals to the method of computation involved, but that's just my blind guess. Does this symbol have formal (precise) meaning? Where is it used?"," P(W) = \left< \delta(W - W[\left| m\right>; \left| n \right>] )\right>  P(W) = \operatorname{⨋}_{m, n}\delta(W - W[\left| m\right>; \left| n \right>] )p(\left|m\right> \to \left|n\right>)","['integration', 'summation', 'notation', 'mathematical-physics']"
7,Improper Integrals as Riemann Sums and a Beautiful Limit $\lim_{n \to \infty}\frac{\sqrt[n]{n!}}{n}$,Improper Integrals as Riemann Sums and a Beautiful Limit,\lim_{n \to \infty}\frac{\sqrt[n]{n!}}{n},"For some context, I recently encountered a beautiful limit. $$\lim_{n \to \infty}\frac{\sqrt[n]{n!}}{n}$$ To solve this we begin by taking the natural log of the inside. $$\ln\left(\frac{\sqrt[n]{n!}}{n}\right)=\ln\left(\frac{n!}{n^n}\right)^\frac{1}{n}=\frac{1}{n}\ln\left(\frac{n!}{n^n}\right)$$ Writing out the terms inside the $\ln$ makes it clear that we can express it as a sum. $$\ln\left(\frac{n!}{n^n}\right)=\ln\left(\frac{1\cdot2 \dotsm n}{n\cdot n \dotsm n}\right)=\ln\left(\frac{1}{n}\right)+\ln\left(\frac{2}{n}\right)+\dotsm+\ln\left(\frac{n}{n}\right)=\sum_{i=1}^n\ln\left(\frac{i}{n}\right)$$ So what we are looking for is the following. $$\lim_{n \to \infty}\frac{1}{n}\sum_{i=1}^n\ln\left(\frac{i}{n}\right)$$ Notice that this is the Riemann Sum from $0$ to $1$ of $\ln(x)$ so we have, $$\lim_{n \to \infty}\frac{1}{n}\sum_{i=1}^n\ln\left(\frac{i}{n}\right)=\int_{0}^{1}\ln(x)\ dx$$ The integral can be solved using integration by parts which I will not include here but it evaluates to $-1$ . $$\int_{0}^{1}\ln(x)\ dx=-1$$ But as we took the natural log of the expression, we must undo it by putting it to the power of $e$ . $$\therefore\lim_{n \to \infty}\frac{\sqrt[n]{n!}}{n}=\frac{1}{e}$$ I was wondering if I could use the same kind of steps to make an expression equal to $e^\pi$ . I realized I needed an integral based on $\ln(x)$ which evaluates to $\pi$ and found the following. $$\int_{0}^{\infty}\ln\left(1+\frac{1}{x^2}\right)\ dx=\pi$$ However, the problem here is that this is an improper integral and the upper bound is at $\infty$ . I've been looking for ways to express this as a Riemann Sum but intuitively it does not make sense to me. The point of Riemann Sums was to keep adding infinitely thin boxes infinite times, so is there any room to expand that so that the upper bound is at infinity? Also, if you find any other integrals which can be used to make a nice expression like the one above, please include that too. I would love to solve it. ps. This is my first post and also my first time using latex to write these equations. Any advice or suggestion is welcome. Thank you.","For some context, I recently encountered a beautiful limit. To solve this we begin by taking the natural log of the inside. Writing out the terms inside the makes it clear that we can express it as a sum. So what we are looking for is the following. Notice that this is the Riemann Sum from to of so we have, The integral can be solved using integration by parts which I will not include here but it evaluates to . But as we took the natural log of the expression, we must undo it by putting it to the power of . I was wondering if I could use the same kind of steps to make an expression equal to . I realized I needed an integral based on which evaluates to and found the following. However, the problem here is that this is an improper integral and the upper bound is at . I've been looking for ways to express this as a Riemann Sum but intuitively it does not make sense to me. The point of Riemann Sums was to keep adding infinitely thin boxes infinite times, so is there any room to expand that so that the upper bound is at infinity? Also, if you find any other integrals which can be used to make a nice expression like the one above, please include that too. I would love to solve it. ps. This is my first post and also my first time using latex to write these equations. Any advice or suggestion is welcome. Thank you.",\lim_{n \to \infty}\frac{\sqrt[n]{n!}}{n} \ln\left(\frac{\sqrt[n]{n!}}{n}\right)=\ln\left(\frac{n!}{n^n}\right)^\frac{1}{n}=\frac{1}{n}\ln\left(\frac{n!}{n^n}\right) \ln \ln\left(\frac{n!}{n^n}\right)=\ln\left(\frac{1\cdot2 \dotsm n}{n\cdot n \dotsm n}\right)=\ln\left(\frac{1}{n}\right)+\ln\left(\frac{2}{n}\right)+\dotsm+\ln\left(\frac{n}{n}\right)=\sum_{i=1}^n\ln\left(\frac{i}{n}\right) \lim_{n \to \infty}\frac{1}{n}\sum_{i=1}^n\ln\left(\frac{i}{n}\right) 0 1 \ln(x) \lim_{n \to \infty}\frac{1}{n}\sum_{i=1}^n\ln\left(\frac{i}{n}\right)=\int_{0}^{1}\ln(x)\ dx -1 \int_{0}^{1}\ln(x)\ dx=-1 e \therefore\lim_{n \to \infty}\frac{\sqrt[n]{n!}}{n}=\frac{1}{e} e^\pi \ln(x) \pi \int_{0}^{\infty}\ln\left(1+\frac{1}{x^2}\right)\ dx=\pi \infty,"['integration', 'sequences-and-series', 'limits', 'improper-integrals', 'riemann-sum']"
8,How can I prove that this limit is equal to the Natural Logarithm?,How can I prove that this limit is equal to the Natural Logarithm?,,"Earlier, I was messing around a little bit with the reverse power rule/power rule for integration which is typically written as follows. Let $f\colon\mathbb{R} \to \mathbb{R}$ be a function satisfying $f(x) = x^r$ for all $x$ , with $r \in \mathbb{R}$ . Then, $$ \int f(x) \,\mathrm{d}x = \int x^r \,\mathrm{d}x = \frac{x^{r+1}}{r+1} + C $$ for any real number $r\neq -1$ and some arbitrary constant $C$ . I was trying to figure out what happens as $r\to -1$ and how in the limit it might approach the natural logarithm of $x$ because of $$ \int x^{-1} \,\mathrm{d}x = \int \frac{1}{x} \,\mathrm{d}x = \begin{cases} \ln(x) + C &\text{if $x>0$} \\ \ln(-x) + C&\text{if $x<0$} \end{cases} = \ln|x| + C.$$ I am aware that $$ \int_{1}^{x} t^{-1} \,\mathrm{d}t = \int_{1}^{x} \frac{1}{t} \,\mathrm{d}t = \ln(x) - \ln(1) = \ln(x) $$ and that $$ \begin{aligned} \lim_{r\to -1}\,\int_{1}^{x} t^{r} \,\mathrm{d}t &= \lim_{r\to -1} \left(\frac{x^{r+1}}{r+1} - \frac{1}{r+1} \right) \\[10pt] &= \lim_{r\to -1} \frac{x^{r+1}-1}{r+1} \\[10pt] &\overset{\scriptscriptstyle\text{L'H}}{=} \lim_{r\to -1} \frac{\frac{\mathrm{d}}{\mathrm{d}r} (x^{r+1}-1)}{\frac{\mathrm{d}}{\mathrm{d}r} (r+1)} \\[10pt] &= \lim_{r\to -1} \frac{x^{r+1}\ln(x) \cdot 1}{1} \\[10pt] &= \ln(x). \end{aligned} $$ I tried graphing both $\dfrac{x^{r+1}}{r+1}$ and $\ln(x)$ on Desmos and after manually tinkering with the values of $r$ close to $-1$ (e.g., $-0.9,-0.99,-0.999$ , etc.) for a little bit, I came up with this function $g\colon\mathbb{R} \to \mathbb{R}$ with $r \in \mathbb{R}$ and $n \in \mathbb{Z}^+$ where $$ \begin{align} r &= -\sum_{k=0}^{n-1}\, 9 \cdot 10^{k-n}, \tag{$\lim_{n\to\infty} r = -1$} \\[10pt] g(x) &= \frac{x^{r+1}}{r+1} - 10^n. \end{align} $$ From what I gathered, it seems that $g$ approaches $\ln(x)$ as $n$ increases. Finally, my question is (if my assumption is true) how can I prove that the following limit is equal to the natural logarithm? $$ \begin{align} \lim_{n\to\infty} g(x) &= \lim_{n\to\infty} \left(\frac{x^{r+1}}{r+1} - 10^n\right) \\[10pt] &= \lim_{n\to\infty} \left(\frac{x^{\displaystyle\left(-\sum_{k=0}^{n-1}\, 9 \cdot 10^{k-n}\right)+1}}{\displaystyle\left(-\sum_{k=0}^{n-1}\, 9 \cdot 10^{k-n}\right)+1} - 10^n \right) \\[10pt] &\overset{\text{?}}{=} \ln(x).  \end{align}$$ Thank you.","Earlier, I was messing around a little bit with the reverse power rule/power rule for integration which is typically written as follows. Let be a function satisfying for all , with . Then, for any real number and some arbitrary constant . I was trying to figure out what happens as and how in the limit it might approach the natural logarithm of because of I am aware that and that I tried graphing both and on Desmos and after manually tinkering with the values of close to (e.g., , etc.) for a little bit, I came up with this function with and where From what I gathered, it seems that approaches as increases. Finally, my question is (if my assumption is true) how can I prove that the following limit is equal to the natural logarithm? Thank you.","f\colon\mathbb{R} \to \mathbb{R} f(x) = x^r x r \in \mathbb{R}  \int f(x) \,\mathrm{d}x = \int x^r \,\mathrm{d}x = \frac{x^{r+1}}{r+1} + C  r\neq -1 C r\to -1 x  \int x^{-1} \,\mathrm{d}x = \int \frac{1}{x} \,\mathrm{d}x = \begin{cases} \ln(x) + C &\text{if x>0} \\ \ln(-x) + C&\text{if x<0} \end{cases} = \ln|x| + C.  \int_{1}^{x} t^{-1} \,\mathrm{d}t = \int_{1}^{x} \frac{1}{t} \,\mathrm{d}t = \ln(x) - \ln(1) = \ln(x)   \begin{aligned}
\lim_{r\to -1}\,\int_{1}^{x} t^{r} \,\mathrm{d}t &= \lim_{r\to -1} \left(\frac{x^{r+1}}{r+1} - \frac{1}{r+1} \right) \\[10pt]
&= \lim_{r\to -1} \frac{x^{r+1}-1}{r+1} \\[10pt]
&\overset{\scriptscriptstyle\text{L'H}}{=} \lim_{r\to -1} \frac{\frac{\mathrm{d}}{\mathrm{d}r} (x^{r+1}-1)}{\frac{\mathrm{d}}{\mathrm{d}r} (r+1)} \\[10pt]
&= \lim_{r\to -1} \frac{x^{r+1}\ln(x) \cdot 1}{1} \\[10pt]
&= \ln(x).
\end{aligned}  \dfrac{x^{r+1}}{r+1} \ln(x) r -1 -0.9,-0.99,-0.999 g\colon\mathbb{R} \to \mathbb{R} r \in \mathbb{R} n \in \mathbb{Z}^+  \begin{align}
r &= -\sum_{k=0}^{n-1}\, 9 \cdot 10^{k-n}, \tag{\lim_{n\to\infty} r = -1} \\[10pt]
g(x) &= \frac{x^{r+1}}{r+1} - 10^n.
\end{align}  g \ln(x) n  \begin{align}
\lim_{n\to\infty} g(x) &= \lim_{n\to\infty} \left(\frac{x^{r+1}}{r+1} - 10^n\right) \\[10pt]
&= \lim_{n\to\infty} \left(\frac{x^{\displaystyle\left(-\sum_{k=0}^{n-1}\, 9 \cdot 10^{k-n}\right)+1}}{\displaystyle\left(-\sum_{k=0}^{n-1}\, 9 \cdot 10^{k-n}\right)+1} - 10^n \right) \\[10pt]
&\overset{\text{?}}{=} \ln(x). 
\end{align}","['integration', 'limits', 'logarithms', 'graphing-functions']"
9,Riemann vs. Darboux integrability for multiple integrals,Riemann vs. Darboux integrability for multiple integrals,,"It is well-known that for bounded functions of one variable, Darboux integrability (via upper and lower sums) is equivalent to Riemann integrability (via Riemann sums.) I tried to generalize this to functions of two variables, and I encountered some technical issues; consider, for example, a bounded function in two variables defined on a unit disk; the lower sum is built from the little squares inside the disk and infimum of function values, while the upper sum is built from the little squares intersecting the disk and supremum of function values; ( Notice that there are more little squares for the upper sum than for the lower sum. ) then one defines the Darboux integrability as the lower sum and upper sum being equal in some limit as the little squares become smaller; to make this sandwiching to work via monotone convergence theorem, one needs to assume that the function is nonnegative. A general bounded function is Darboux integrable if it is the difference between two nonnegative Darboux integrable functions. As for the Riemann integrability, the Riemann sum is built from the little squares inside the disk and  function values at an arbitrary point in each little square. It is straightforward to show that Darboux integrability implies Riemann integrability. What I'm having trouble with is the converse: Does Riemann integrability imply Darboux integrability? I can prove this only if the function is nonnegative; since upper and lower sums are used for nonnegative functions only, the usual technique cannot be applied for signed functions. Is there a way around it? Or, could it be that Riemann integrability does not imply Darboux integrability for functions of more than one variable?","It is well-known that for bounded functions of one variable, Darboux integrability (via upper and lower sums) is equivalent to Riemann integrability (via Riemann sums.) I tried to generalize this to functions of two variables, and I encountered some technical issues; consider, for example, a bounded function in two variables defined on a unit disk; the lower sum is built from the little squares inside the disk and infimum of function values, while the upper sum is built from the little squares intersecting the disk and supremum of function values; ( Notice that there are more little squares for the upper sum than for the lower sum. ) then one defines the Darboux integrability as the lower sum and upper sum being equal in some limit as the little squares become smaller; to make this sandwiching to work via monotone convergence theorem, one needs to assume that the function is nonnegative. A general bounded function is Darboux integrable if it is the difference between two nonnegative Darboux integrable functions. As for the Riemann integrability, the Riemann sum is built from the little squares inside the disk and  function values at an arbitrary point in each little square. It is straightforward to show that Darboux integrability implies Riemann integrability. What I'm having trouble with is the converse: Does Riemann integrability imply Darboux integrability? I can prove this only if the function is nonnegative; since upper and lower sums are used for nonnegative functions only, the usual technique cannot be applied for signed functions. Is there a way around it? Or, could it be that Riemann integrability does not imply Darboux integrability for functions of more than one variable?",,"['integration', 'multivariable-calculus', 'riemann-integration', 'multiple-integral', 'riemann-sum']"
10,"Proving $\int_0^{\pi} \frac{\log (1+r-2\sqrt{r}\cos(t))}{1+r-2\sqrt{r} \cos(t)}\,dt = \frac{2\pi}{1-r}\log(1-r)$, when $0 < r < 1$.","Proving , when .","\int_0^{\pi} \frac{\log (1+r-2\sqrt{r}\cos(t))}{1+r-2\sqrt{r} \cos(t)}\,dt = \frac{2\pi}{1-r}\log(1-r) 0 < r < 1","I'm trying to prove that when $0 < r < 1$ , \begin{equation} \int_0^{\pi} \frac{\log (1+r-2\sqrt{r}\cos(t))}{1+r-2\sqrt{r} \cos(t)}\,dt = \frac{2\pi}{1-r}\log(1-r).\end{equation} References : Evaluating an easier integral $\int_0^{\pi} \log (1+r-2\sqrt{r}\cos(t))\,dt$ has many references, for example: A question in Complex Analysis $\int_0^{2\pi}\log(1-2r\cos x +r^2)\,dx$ But I couldn't find a direct reference for the above problem. My approach : Motivated by solutions in the above post, I tried to express my integral as a contour integral: $$ \int_0^{\pi} \frac{\log (1+r-2\sqrt{r}\cos(t))}{1+r-2\sqrt{r} \cos(t)}\,dt = \frac{1}{2} \int_0^{2\pi} \frac{\log (1+r-2\sqrt{r}\cos(t))}{1+r-2\sqrt{r} \cos(t)}\,dt = \int_{\gamma} \frac{\log |1-z|^2}{2iz|1-z|^2} \,dz, $$ here $\gamma$ is the circle of radius $\sqrt{r}$ centered at the origin. I couldn't proceed further. Could you help me with my approach or any other approach? Thank you in advance.","I'm trying to prove that when , References : Evaluating an easier integral has many references, for example: A question in Complex Analysis $\int_0^{2\pi}\log(1-2r\cos x +r^2)\,dx$ But I couldn't find a direct reference for the above problem. My approach : Motivated by solutions in the above post, I tried to express my integral as a contour integral: here is the circle of radius centered at the origin. I couldn't proceed further. Could you help me with my approach or any other approach? Thank you in advance.","0 < r < 1 \begin{equation} \int_0^{\pi} \frac{\log (1+r-2\sqrt{r}\cos(t))}{1+r-2\sqrt{r} \cos(t)}\,dt = \frac{2\pi}{1-r}\log(1-r).\end{equation} \int_0^{\pi} \log (1+r-2\sqrt{r}\cos(t))\,dt 
\int_0^{\pi} \frac{\log (1+r-2\sqrt{r}\cos(t))}{1+r-2\sqrt{r} \cos(t)}\,dt = \frac{1}{2} \int_0^{2\pi} \frac{\log (1+r-2\sqrt{r}\cos(t))}{1+r-2\sqrt{r} \cos(t)}\,dt = \int_{\gamma} \frac{\log |1-z|^2}{2iz|1-z|^2} \,dz,
 \gamma \sqrt{r}","['integration', 'contour-integration', 'complex-integration']"
11,Compute $\sum_{n=1}^\infty\frac{H_nH_{2n}}{(2n+1)^3}$,Compute,\sum_{n=1}^\infty\frac{H_nH_{2n}}{(2n+1)^3},"How to prove that $$\small{\sum_{n=1}^\infty\frac{H_nH_{2n}}{(2n+1)^3}=\frac1{12}\ln^52+\frac{13}{128}\zeta(5)-\frac12\ln^32\zeta(2)+\frac74\ln^22\zeta(3)-\frac{17}{8}\ln2\zeta(4)+2\ln2\operatorname{Li}_4\left(\frac12\right)}$$ whre $H_n$ is the harmonic number, $\zeta$ is the Riemann zeta function and $\operatorname{Li}_a(x)$ is the polylogarithm function. This problem is proposed by Cornel ( can be found here ) and no solution has been submitted yet. I tried all the tools I used in solving the other tough series but did not work, so I consider this series very hard to crack. Any idea ? I am tagging "" integration"" as logarithmic integrals are very related to harmonic series.","How to prove that whre is the harmonic number, is the Riemann zeta function and is the polylogarithm function. This problem is proposed by Cornel ( can be found here ) and no solution has been submitted yet. I tried all the tools I used in solving the other tough series but did not work, so I consider this series very hard to crack. Any idea ? I am tagging "" integration"" as logarithmic integrals are very related to harmonic series.",\small{\sum_{n=1}^\infty\frac{H_nH_{2n}}{(2n+1)^3}=\frac1{12}\ln^52+\frac{13}{128}\zeta(5)-\frac12\ln^32\zeta(2)+\frac74\ln^22\zeta(3)-\frac{17}{8}\ln2\zeta(4)+2\ln2\operatorname{Li}_4\left(\frac12\right)} H_n \zeta \operatorname{Li}_a(x),"['integration', 'sequences-and-series', 'riemann-zeta', 'harmonic-numbers', 'polylogarithm']"
12,"Prove $\sum _{n \geq 1} \left[\frac{1}{n}-\frac{2}{n+1}{_2F_1}(1,\frac{n+1}{2};\frac{n+3}{2};-1)\right]=\frac{\pi}{4}-\frac{\log 2}{2}$",Prove,"\sum _{n \geq 1} \left[\frac{1}{n}-\frac{2}{n+1}{_2F_1}(1,\frac{n+1}{2};\frac{n+3}{2};-1)\right]=\frac{\pi}{4}-\frac{\log 2}{2}","Can we prove the following closed form by directly using hypergeometric series? $$S=\sum _{n=1}^{\infty} \left[\frac{1}{n}-\frac{2 }{n+1}\, _2F_1\left(1,\frac{n+1}{2};\frac{n+3}{2};-1\right)\right]=\frac{\pi}{4}-\frac{\log 2}{2}$$ I have come to this result by considering the integral: $$I = \int_0^\infty \frac{1-\frac{1}{\cosh x}}{e^x-1} dx$$ We can expand the denominator as geometric series and then find the integrals for each term. $$\int_0^\infty \frac{2 e^{-n x}dx}{e^x+e^{-x}}=2 \int_0^\infty \frac{t^n dt}{1+t^2}=\int_0^\infty \frac{u^{(n-1)/2} du}{1+u}= \\ = B \left(1,\frac{n+1}{2} \right) \, _2F_1\left(1,\frac{n+1}{2};\frac{n+3}{2};-1\right)$$ As for the integral as a whole, it's easy enough to rewrite it: $$I= \int_0^\infty \frac{e^x+e^{-x}-2}{(e^x-1)(e^x+e^{-x})}dx= \\ =\int_0^\infty \frac{dx}{e^x+e^{-x}}-\int_0^\infty \frac{dx}{e^{2x}+1}= \\ =\int_1^\infty \frac{dt}{t^2+1}-\int_1^\infty \frac{dt}{t(t^2+1)}= \frac{\pi}{4}-\frac{\log 2}{2}$$","Can we prove the following closed form by directly using hypergeometric series? I have come to this result by considering the integral: We can expand the denominator as geometric series and then find the integrals for each term. As for the integral as a whole, it's easy enough to rewrite it:","S=\sum _{n=1}^{\infty} \left[\frac{1}{n}-\frac{2 }{n+1}\, _2F_1\left(1,\frac{n+1}{2};\frac{n+3}{2};-1\right)\right]=\frac{\pi}{4}-\frac{\log 2}{2} I = \int_0^\infty \frac{1-\frac{1}{\cosh x}}{e^x-1} dx \int_0^\infty \frac{2 e^{-n x}dx}{e^x+e^{-x}}=2 \int_0^\infty \frac{t^n dt}{1+t^2}=\int_0^\infty \frac{u^{(n-1)/2} du}{1+u}= \\ = B \left(1,\frac{n+1}{2} \right) \, _2F_1\left(1,\frac{n+1}{2};\frac{n+3}{2};-1\right) I= \int_0^\infty \frac{e^x+e^{-x}-2}{(e^x-1)(e^x+e^{-x})}dx= \\ =\int_0^\infty \frac{dx}{e^x+e^{-x}}-\int_0^\infty \frac{dx}{e^{2x}+1}= \\ =\int_1^\infty \frac{dt}{t^2+1}-\int_1^\infty \frac{dt}{t(t^2+1)}= \frac{\pi}{4}-\frac{\log 2}{2}","['integration', 'sequences-and-series', 'hypergeometric-function']"
13,What is the term for this family of improper integrals?,What is the term for this family of improper integrals?,,What is the name of the integrals of this form? $$\int_{0}^{\infty} \frac{\sin\left(\frac{x}{1}\right)\sin\left(\frac{x}{3}\right)\cdots\sin\left(\frac{x}{2n + 1}\right)}{\left(\frac{x}{1}\right)\left(\frac{x}{3}\right)\cdots\left(\frac{x}{2n + 1}\right)} \:dx$$,What is the name of the integrals of this form?,\int_{0}^{\infty} \frac{\sin\left(\frac{x}{1}\right)\sin\left(\frac{x}{3}\right)\cdots\sin\left(\frac{x}{2n + 1}\right)}{\left(\frac{x}{1}\right)\left(\frac{x}{3}\right)\cdots\left(\frac{x}{2n + 1}\right)} \:dx,['integration']
14,Show that $\int_0^{\pi/2}\frac{\sin x\cdot \cos x}{x+1}dx=\frac12(\frac12+\frac1{\pi +2}-A)$,Show that,\int_0^{\pi/2}\frac{\sin x\cdot \cos x}{x+1}dx=\frac12(\frac12+\frac1{\pi +2}-A),Show that $\int_{0}^{\pi/2}\frac{\sin x\cdot \cos x}{x+1}dx=\frac{1}{2}(\frac{1}{2}+\frac{1}{\pi +2}-A)$   where $A=\int_0^\pi\frac{\cos x}{(x+2)^2}dx$. I tried using partial integration on the integral $\int_0^{\pi/2}\frac{\sin x\cdot \cos x}{x+1}dx$ but I am in no luck. Also tried using $\frac12A=\int_0^{\pi/2}\frac{\cos x}{(x+2)^2}dx$. But still something is going wrong . Please suggest. The best I could think of is : $\int {\dfrac{sin2x}{2x+2}dx}=-\dfrac{1}{2x+2}cos2x+\dfrac{1}{4}\int {\dfrac{cos2x}{(x+1)^2}dx}$ Notice carefully that $\int_0^\pi\frac{\cos x}{(x+2)^2}dx$ has the same structure as $\int {\dfrac{cos2x}{(x+1)^2}dx}$ P.S.  See I purposefully avoided the long details of my efforts as that would hamper the understandibility of the problem and may mislead the answerer as well.,Show that $\int_{0}^{\pi/2}\frac{\sin x\cdot \cos x}{x+1}dx=\frac{1}{2}(\frac{1}{2}+\frac{1}{\pi +2}-A)$   where $A=\int_0^\pi\frac{\cos x}{(x+2)^2}dx$. I tried using partial integration on the integral $\int_0^{\pi/2}\frac{\sin x\cdot \cos x}{x+1}dx$ but I am in no luck. Also tried using $\frac12A=\int_0^{\pi/2}\frac{\cos x}{(x+2)^2}dx$. But still something is going wrong . Please suggest. The best I could think of is : $\int {\dfrac{sin2x}{2x+2}dx}=-\dfrac{1}{2x+2}cos2x+\dfrac{1}{4}\int {\dfrac{cos2x}{(x+1)^2}dx}$ Notice carefully that $\int_0^\pi\frac{\cos x}{(x+2)^2}dx$ has the same structure as $\int {\dfrac{cos2x}{(x+1)^2}dx}$ P.S.  See I purposefully avoided the long details of my efforts as that would hamper the understandibility of the problem and may mislead the answerer as well.,,"['integration', 'definite-integrals']"
15,Extending Sophomore's Dream to include a constant in the exponent.,Extending Sophomore's Dream to include a constant in the exponent.,,"I am trying to extend the Sophomore's Dream by proving the formula: $$\int _0^1\limits  x^{a-x}\text d x=\sum _{n=1}^\infty \limits \frac{1}{(a+n)^n}$$ I have tried induction, integration by parts, and using the same proof as here and substituting $a-x$, but haven't had much luck. Thanks in advance!","I am trying to extend the Sophomore's Dream by proving the formula: $$\int _0^1\limits  x^{a-x}\text d x=\sum _{n=1}^\infty \limits \frac{1}{(a+n)^n}$$ I have tried induction, integration by parts, and using the same proof as here and substituting $a-x$, but haven't had much luck. Thanks in advance!",,"['integration', 'sequences-and-series']"
16,Hypergeometric integral $\int_0^1 dx ~e^{-(\frac{1}{x}+\frac{1}{1-x})}(x)^{b-a-1}(1-x)^{a-1}$.,Hypergeometric integral .,\int_0^1 dx ~e^{-(\frac{1}{x}+\frac{1}{1-x})}(x)^{b-a-1}(1-x)^{a-1},"I have an this integral $$\int_0^1 dx ~e^{-(\frac{1}{x}+\frac{1}{1-x})}(x)^{b-a-1}(1-x)^{a-1}$$ how can I calculate the integral in form of Bessel function or Hypergeometric function. As mentioned in Arfken (special function-chapter) $$M(a,c;x)=\frac{\Gamma(c)}{\Gamma(a)\Gamma(c-a)}\int_0^1 e^{xt}t^{a-1}(1-t)^{c-a-1}dt$$ and  $M(a,c;x)= e^x M(c-a,c;-x) $ But I couldn't find  useful variable to simplify the integral","I have an this integral $$\int_0^1 dx ~e^{-(\frac{1}{x}+\frac{1}{1-x})}(x)^{b-a-1}(1-x)^{a-1}$$ how can I calculate the integral in form of Bessel function or Hypergeometric function. As mentioned in Arfken (special function-chapter) $$M(a,c;x)=\frac{\Gamma(c)}{\Gamma(a)\Gamma(c-a)}\int_0^1 e^{xt}t^{a-1}(1-t)^{c-a-1}dt$$ and  $M(a,c;x)= e^x M(c-a,c;-x) $ But I couldn't find  useful variable to simplify the integral",,"['integration', 'definite-integrals', 'special-functions']"
17,Evaluate the integral $\int_0^{2a}\int_0^\sqrt{2ax-x^2}\frac{\phi'(y)(x^2+y^2)x dxdy}{\sqrt{4a^2x^2-(x^2+y^2)^2}}$,Evaluate the integral,\int_0^{2a}\int_0^\sqrt{2ax-x^2}\frac{\phi'(y)(x^2+y^2)x dxdy}{\sqrt{4a^2x^2-(x^2+y^2)^2}},"Change the order of integration in: $$\int_0^{2a}\int_0^\sqrt{2ax-x^2}\frac{\phi'(y)(x^2+y^2)x }{\sqrt{4a^2x^2-(x^2+y^2)^2}}dxdy$$ and hence evaluate it. I changed the order of integration and got the limits $y=0$ to $a$ and $x=a-\sqrt{a^2-y^2}$ to $a+\sqrt{a^2-y^2}$. I then tried changing to polar coordinates, but it is only making the integrand more complex.","Change the order of integration in: $$\int_0^{2a}\int_0^\sqrt{2ax-x^2}\frac{\phi'(y)(x^2+y^2)x }{\sqrt{4a^2x^2-(x^2+y^2)^2}}dxdy$$ and hence evaluate it. I changed the order of integration and got the limits $y=0$ to $a$ and $x=a-\sqrt{a^2-y^2}$ to $a+\sqrt{a^2-y^2}$. I then tried changing to polar coordinates, but it is only making the integrand more complex.",,"['integration', 'definite-integrals']"
18,Analytical evaluation of double integral,Analytical evaluation of double integral,,"I'm looking to evaluate the following integral: $$\int^a_{-a}\int^a_{-a}\frac{\sqrt{x^2+y^2}}{4a^2} \,\mathrm{d}x \mathrm{d}y,$$ where $a> 0$. Mathematica gives the following answer: $$ \frac{a}{3} (\sqrt{2} + \sinh^{-1}(1)).$$ This goes well beyond my basic calculus 101 training. Is anybody able to give me a step-by-step analytical solution? Regards","I'm looking to evaluate the following integral: $$\int^a_{-a}\int^a_{-a}\frac{\sqrt{x^2+y^2}}{4a^2} \,\mathrm{d}x \mathrm{d}y,$$ where $a> 0$. Mathematica gives the following answer: $$ \frac{a}{3} (\sqrt{2} + \sinh^{-1}(1)).$$ This goes well beyond my basic calculus 101 training. Is anybody able to give me a step-by-step analytical solution? Regards",,"['integration', 'multivariable-calculus']"
19,Periodic function implies periodic primitive?,Periodic function implies periodic primitive?,,"If $f$ is a periodic function with $T = \pi$, does that mean that $F$ (a primitive of $f$) has the same period ? What about the inverse implication (periodic primitive implies periodic function) ?","If $f$ is a periodic function with $T = \pi$, does that mean that $F$ (a primitive of $f$) has the same period ? What about the inverse implication (periodic primitive implies periodic function) ?",,"['integration', 'periodic-functions']"
20,Hints on integrating (rather complicated) exponential function,Hints on integrating (rather complicated) exponential function,,"I am interested in computing the following integral $$\int_0^\infty \frac{1}{\sqrt{t}}\exp\left(-\frac{(x-t)^2}{t} - t\right)\, dt. $$ A hint is good enough for me!","I am interested in computing the following integral $$\int_0^\infty \frac{1}{\sqrt{t}}\exp\left(-\frac{(x-t)^2}{t} - t\right)\, dt. $$ A hint is good enough for me!",,"['integration', 'partial-differential-equations']"
21,Calculating $\int_0^{\pi/2} (x \sin x)^n dx$,Calculating,\int_0^{\pi/2} (x \sin x)^n dx,"Define $$I_n = \int_0^{\pi/2} (x \sin x)^n dx$$ for $n \ge 0$ . I calculate the value for $n = 0, 1$ and $2$ . $$I_0 = \frac{\pi}{2}, \>\>\>I_1 = 1, \>\>\>I_2 = \frac{{\pi}^3 + 6 \pi}{48} .$$ In general, what's the value of $I_n$ ? P.S. WolframAlpha produces $$I_3 = \frac{7{\pi}^2}{12} - \frac{122}{27},$$ $$ I_4 = \frac{6{\pi}^5 + 170 {\pi}^3 -975 \pi}{2560},$$ $$ I_5 = \frac{149{\pi}^4}{720} - \frac{31841{\pi}^2}{3375} + \frac{56992552}{759375}\\$$ n = 3 ( http://www.wolframalpha.com/input/?i=integrate+%5B(x+sin(x))%5E3,+%7Bx,+0,+PI%2F2%7D%5D ), n = 4 ( http://www.wolframalpha.com/input/?i=integrate+%5B(x+sin(x))%5E4,+%7Bx,+0,+PI%2F2%7D%5D ), n = 5 ( http://www.wolframalpha.com/input/?i=integrate+%5B(x+sin(x))%5E5,+%7Bx,+0,+PI%2F2%7D%5D )","Define for . I calculate the value for and . In general, what's the value of ? P.S. WolframAlpha produces n = 3 ( http://www.wolframalpha.com/input/?i=integrate+%5B(x+sin(x))%5E3,+%7Bx,+0,+PI%2F2%7D%5D ), n = 4 ( http://www.wolframalpha.com/input/?i=integrate+%5B(x+sin(x))%5E4,+%7Bx,+0,+PI%2F2%7D%5D ), n = 5 ( http://www.wolframalpha.com/input/?i=integrate+%5B(x+sin(x))%5E5,+%7Bx,+0,+PI%2F2%7D%5D )","I_n = \int_0^{\pi/2} (x \sin x)^n dx n \ge 0 n = 0, 1 2 I_0 = \frac{\pi}{2}, \>\>\>I_1 = 1, \>\>\>I_2 = \frac{{\pi}^3 + 6 \pi}{48} . I_n I_3 = \frac{7{\pi}^2}{12} - \frac{122}{27},  I_4 = \frac{6{\pi}^5 + 170 {\pi}^3 -975 \pi}{2560},  I_5 = \frac{149{\pi}^4}{720} - \frac{31841{\pi}^2}{3375} + \frac{56992552}{759375}\\","['integration', 'definite-integrals', 'trigonometric-integrals']"
22,Asymptotic of an integral involving sine and erf,Asymptotic of an integral involving sine and erf,,"In a recent paper with two colleagues http://arxiv.org/pdf/1408.5720.pdf we derived a certain integral ruling the distribution of eigenvalues spacings for a model of random matrices. The integral reads $$ J_M(s)=\int_0^\infty dt\ \frac{\sin(s t)}{t^{M-1}}[\mathrm{erf}(t)]^M\ , $$ where $\mathrm{erf}(x)=(2/\sqrt{\pi})\int_0^x\ e^{-y^2}dy$ is the Error function. $M$ is a large positive parameter. I am somehow struggling to find the asymptotic behavior of this integral as $M\to +\infty$. A saddle-point approach seemed a natural candidate, but somehow the oscillating part is getting in the way (unless I am making a silly mistake). Any help would be much appreciated.","In a recent paper with two colleagues http://arxiv.org/pdf/1408.5720.pdf we derived a certain integral ruling the distribution of eigenvalues spacings for a model of random matrices. The integral reads $$ J_M(s)=\int_0^\infty dt\ \frac{\sin(s t)}{t^{M-1}}[\mathrm{erf}(t)]^M\ , $$ where $\mathrm{erf}(x)=(2/\sqrt{\pi})\int_0^x\ e^{-y^2}dy$ is the Error function. $M$ is a large positive parameter. I am somehow struggling to find the asymptotic behavior of this integral as $M\to +\infty$. A saddle-point approach seemed a natural candidate, but somehow the oscillating part is getting in the way (unless I am making a silly mistake). Any help would be much appreciated.",,"['integration', 'definite-integrals', 'asymptotics']"
23,"Closed form for ${\large\int}_0^1x\,\operatorname{li}\!\left(\frac1x\right)\ln^{1/4}\!\left(\frac1x\right)dx$",Closed form for,"{\large\int}_0^1x\,\operatorname{li}\!\left(\frac1x\right)\ln^{1/4}\!\left(\frac1x\right)dx","Let $\operatorname{li}(x)$ denote the logarithmic integral : $$\operatorname{li}(x)=\int_0^x\frac{dt}{\ln t}.$$ How can we prove the following conjectured closed form? $${\large\int}_0^1x\,\operatorname{li}\!\left(\frac1x\right)\ln^{1/4}\!\left(\frac1x\right)dx\stackrel{\color{gray}?}=\left(\frac12-\frac{\operatorname{arctan}\left(\sqrt[4]2\right)+\operatorname{arcoth}\left(\sqrt[4]2\right)}{4\sqrt[4]2}\right)\cdot\Gamma\!\left(\frac14\right)$$ Related questions: [1] [2] .","Let $\operatorname{li}(x)$ denote the logarithmic integral : $$\operatorname{li}(x)=\int_0^x\frac{dt}{\ln t}.$$ How can we prove the following conjectured closed form? $${\large\int}_0^1x\,\operatorname{li}\!\left(\frac1x\right)\ln^{1/4}\!\left(\frac1x\right)dx\stackrel{\color{gray}?}=\left(\frac12-\frac{\operatorname{arctan}\left(\sqrt[4]2\right)+\operatorname{arcoth}\left(\sqrt[4]2\right)}{4\sqrt[4]2}\right)\cdot\Gamma\!\left(\frac14\right)$$ Related questions: [1] [2] .",,"['integration', 'definite-integrals', 'logarithms', 'special-functions', 'closed-form']"
24,"Integrating volume of a sphere with a cylinder ""drilled"" out of it","Integrating volume of a sphere with a cylinder ""drilled"" out of it",,"Unfortunately, I am stuck again on another integration problem. Famous last words, this should be simple. $$ \text{A cylindrical drill with radius 5 is used to bore a hole through}\\\text{the center of a sphere of radius 7. Find the volume of the ring shaped solid that remains.} $$ So we can setup our problem by first defining our change in $\theta$ as the first region, because we can do some simple multiplication to fill the rest of the sphere symmetrically. We should just be able to calculate the change in $r$ inside of that. $$ \begin{align} &=8 \int_{0}^{\frac{\pi}{4}} \int_{5}^{7} r\:dr\:d\theta\\ &=\frac{8}{2}\int_{0}^{\frac{\pi}{4}}49-25\:d\theta\\ &=24 \times \frac{8}{2} \times \frac{\pi}{4}\\ &=24\pi \end{align} $$ Edit: I attempted to re-evaluate my process, but the problem was still not correct. I attempted to set my integrand to the arc length of the sphere - the arc length of the cylinder, but the integrand $\frac{r^3}{2}-5r$ was not the correct integrand to use.","Unfortunately, I am stuck again on another integration problem. Famous last words, this should be simple. $$ \text{A cylindrical drill with radius 5 is used to bore a hole through}\\\text{the center of a sphere of radius 7. Find the volume of the ring shaped solid that remains.} $$ So we can setup our problem by first defining our change in $\theta$ as the first region, because we can do some simple multiplication to fill the rest of the sphere symmetrically. We should just be able to calculate the change in $r$ inside of that. $$ \begin{align} &=8 \int_{0}^{\frac{\pi}{4}} \int_{5}^{7} r\:dr\:d\theta\\ &=\frac{8}{2}\int_{0}^{\frac{\pi}{4}}49-25\:d\theta\\ &=24 \times \frac{8}{2} \times \frac{\pi}{4}\\ &=24\pi \end{align} $$ Edit: I attempted to re-evaluate my process, but the problem was still not correct. I attempted to set my integrand to the arc length of the sphere - the arc length of the cylinder, but the integrand $\frac{r^3}{2}-5r$ was not the correct integrand to use.",,"['integration', 'volume']"
25,"Lebesgue integrable function over $(0,1)$ vs $[0,1]$",Lebesgue integrable function over  vs,"(0,1) [0,1]","Up till now, I thought saying $u \in L^2([0,1])$ is the same as saying $u \in L^2((0,1))$, because I see people emphasizing ""$u$ is Lebesgue integrable over $[0,1)$"". I thought the whole point of the Lebesgue integral is that null sets don't matter, so it doesn't matter whether the endpoint is included or not. What do I miss?","Up till now, I thought saying $u \in L^2([0,1])$ is the same as saying $u \in L^2((0,1))$, because I see people emphasizing ""$u$ is Lebesgue integrable over $[0,1)$"". I thought the whole point of the Lebesgue integral is that null sets don't matter, so it doesn't matter whether the endpoint is included or not. What do I miss?",,"['integration', 'measure-theory', 'lebesgue-integral']"
26,Integral for which numeric methods will always give an incorrect result?,Integral for which numeric methods will always give an incorrect result?,,"I was thinking about the following function: $$f(x) = \begin{cases}0 & x\;\mathrm{computable}\\1&\mathrm{otherwise}\end{cases}$$ And the following definite integral: $$I = \int_0^1 f(x)\;\mathrm dx$$ I know that since the computable numbers are countable, $I=1$. However, am I correct in assuming that any numerical method will give $I=0$ (because of the computable nature of any $x$ a computer can create)?","I was thinking about the following function: $$f(x) = \begin{cases}0 & x\;\mathrm{computable}\\1&\mathrm{otherwise}\end{cases}$$ And the following definite integral: $$I = \int_0^1 f(x)\;\mathrm dx$$ I know that since the computable numbers are countable, $I=1$. However, am I correct in assuming that any numerical method will give $I=0$ (because of the computable nature of any $x$ a computer can create)?",,"['integration', 'definite-integrals', 'numerical-methods']"
27,"Integrate $\int \sqrt{(\sec{x} +\tan{x})}\ \cdot \sec^2x\,dx$",Integrate,"\int \sqrt{(\sec{x} +\tan{x})}\ \cdot \sec^2x\,dx","Integrate: $$\int \sqrt{(\sec{x} +\tan{x})}\ \cdot \sec^2x\,dx$$ My attempt : I substituted $\sec{x} + \tan{x} $ as $t^2$ Then, $$ (\sec{x} \cdot \tan{x} + \sec^2x) dx =2tdt$$ $$\sec{x}(  \tan{x} + \sec{x}) dx =2tdt$$ $$\sec{x}\cdot t^2 dx =2tdt$$ But there is  $\sec{x}$ left outside.","Integrate: $$\int \sqrt{(\sec{x} +\tan{x})}\ \cdot \sec^2x\,dx$$ My attempt : I substituted $\sec{x} + \tan{x} $ as $t^2$ Then, $$ (\sec{x} \cdot \tan{x} + \sec^2x) dx =2tdt$$ $$\sec{x}(  \tan{x} + \sec{x}) dx =2tdt$$ $$\sec{x}\cdot t^2 dx =2tdt$$ But there is  $\sec{x}$ left outside.",,['integration']
28,Green's Function vs. Fundamental Solution,Green's Function vs. Fundamental Solution,,"From the texts I've used, the Green's function is of a problem is $G(x,y)$ such that $LG(x,y) = \delta(x-y)$. The fundamental solution is u(x) such that $Lu(x)=\delta(x)$. They seem to be used for the same purpose (solving inhomogenous odes/pdes), but I'm curious how they are related. For example, there is a general methodology for finding Green's functions for simple types of ODEs (i.e. regular Sturm-Liouville problems), but I'm having trouble finding such a methodology for finding fundamental solutions. Also, are the Green's functions and fundamental solutions directly related in some way? I was talking to a friend and his idea was that the Green's function had the convolution built into it (since you use it as a kernel), whereas the fundamental solution is kind of more basic than that since you convolve it with the inhomogenous part.","From the texts I've used, the Green's function is of a problem is $G(x,y)$ such that $LG(x,y) = \delta(x-y)$. The fundamental solution is u(x) such that $Lu(x)=\delta(x)$. They seem to be used for the same purpose (solving inhomogenous odes/pdes), but I'm curious how they are related. For example, there is a general methodology for finding Green's functions for simple types of ODEs (i.e. regular Sturm-Liouville problems), but I'm having trouble finding such a methodology for finding fundamental solutions. Also, are the Green's functions and fundamental solutions directly related in some way? I was talking to a friend and his idea was that the Green's function had the convolution built into it (since you use it as a kernel), whereas the fundamental solution is kind of more basic than that since you convolve it with the inhomogenous part.",,"['integration', 'ordinary-differential-equations', 'partial-differential-equations', 'convolution']"
29,Integrate $u_t - \Delta u = 0$ to get $\frac12 \frac{d}{dt} \int_{\Omega} u^2 + \int_{\Omega}|\nabla u|^2 = 0$?,Integrate  to get ?,u_t - \Delta u = 0 \frac12 \frac{d}{dt} \int_{\Omega} u^2 + \int_{\Omega}|\nabla u|^2 = 0,"In my PDE class, my instructor wrote the following notes: Consider equations $u_t - \Delta u = 0$ in $\Omega$, where $\Omega \subset \mathbb{R}^n$ is bounded. Suppose boundary conditions $u = u_0(x)$ at $t=0$, and $u=0$ at $\partial \Omega$. Multiplying the equation by $u$ and integrating by parts gives $$\frac12 \frac{d}{dt} \int_{\Omega} u^2 + \int_{\Omega}|\nabla u|^2 = 0$$ (with no boundary terms, using the bc). This already shows $$\frac{d}{dt} \int_{\Omega}u^2 \leq 0 \tag{1}$$ which gives uniqueness, since the problem is linear (so the difference of two solutions has initial data 0). My Questions: I'm not seeing the integration by parts here, can someone talk me through it? How are we deducing (1)? How does (1) show uniqueness? Thanks for your help, the details are eluding me here.","In my PDE class, my instructor wrote the following notes: Consider equations $u_t - \Delta u = 0$ in $\Omega$, where $\Omega \subset \mathbb{R}^n$ is bounded. Suppose boundary conditions $u = u_0(x)$ at $t=0$, and $u=0$ at $\partial \Omega$. Multiplying the equation by $u$ and integrating by parts gives $$\frac12 \frac{d}{dt} \int_{\Omega} u^2 + \int_{\Omega}|\nabla u|^2 = 0$$ (with no boundary terms, using the bc). This already shows $$\frac{d}{dt} \int_{\Omega}u^2 \leq 0 \tag{1}$$ which gives uniqueness, since the problem is linear (so the difference of two solutions has initial data 0). My Questions: I'm not seeing the integration by parts here, can someone talk me through it? How are we deducing (1)? How does (1) show uniqueness? Thanks for your help, the details are eluding me here.",,"['multivariable-calculus', 'integration', 'partial-differential-equations', 'derivatives']"
30,"Is the following statement true? $\int_{-1}^{x}\ {2x+x^2}\,dx = \int_{-1}^{x}\ F'(x) = F(x) = \int_{-1}^{x}\ {2t+t^2}\,dt$",Is the following statement true?,"\int_{-1}^{x}\ {2x+x^2}\,dx = \int_{-1}^{x}\ F'(x) = F(x) = \int_{-1}^{x}\ {2t+t^2}\,dt","I have trouble understanding easy integral concept. Here, one of the integral theorem states: And I was wondering what would happen if $F'(x)$ is back in to the integral. For example, $F(x) = \int_{-1}^{x}\ {2t+t^2}, x \in [-1,5]$ $$F'(x) = 2x + x^2, x \in (-1,5)$$ Then if $F'(x)$ is back in to $\int_{-1}^{x}$ as in $\int_{-1}^{x}\ {2x+x^2}$, should it return $F(x)$? I mean is the following statement true? $$\int_{-1}^{x}\ {2x+x^2} = \int_{-1}^{x}\ F'(x) = F(x) = \int_{-1}^{x}\ {2t+t^2}$$ What I am confused about is the change of the variable above.","I have trouble understanding easy integral concept. Here, one of the integral theorem states: And I was wondering what would happen if $F'(x)$ is back in to the integral. For example, $F(x) = \int_{-1}^{x}\ {2t+t^2}, x \in [-1,5]$ $$F'(x) = 2x + x^2, x \in (-1,5)$$ Then if $F'(x)$ is back in to $\int_{-1}^{x}$ as in $\int_{-1}^{x}\ {2x+x^2}$, should it return $F(x)$? I mean is the following statement true? $$\int_{-1}^{x}\ {2x+x^2} = \int_{-1}^{x}\ F'(x) = F(x) = \int_{-1}^{x}\ {2t+t^2}$$ What I am confused about is the change of the variable above.",,['integration']
31,"The indefinite integral $\int x^2\sqrt{1-x}\,\mathrm dx$",The indefinite integral,"\int x^2\sqrt{1-x}\,\mathrm dx","I'm trying get the integral $\int x^2\sqrt{1-x}\,\mathrm dx$ but I don't know how to proceed. I know I have to use substitution, but that's it. I tried to get some help with the wolfram alpha step-by-step integral calculation, but I don't quite get how it gets there It subtitutes $u=\sqrt{1-x}$ and $\mathrm du = -\frac{1}{2\sqrt{1-x}}$ and then it becomes $-2 \int u^2(1-u^2)^2\,\mathrm du$ I don't understand how it becomes like that?","I'm trying get the integral $\int x^2\sqrt{1-x}\,\mathrm dx$ but I don't know how to proceed. I know I have to use substitution, but that's it. I tried to get some help with the wolfram alpha step-by-step integral calculation, but I don't quite get how it gets there It subtitutes $u=\sqrt{1-x}$ and $\mathrm du = -\frac{1}{2\sqrt{1-x}}$ and then it becomes $-2 \int u^2(1-u^2)^2\,\mathrm du$ I don't understand how it becomes like that?",,"['integration', 'indefinite-integrals']"
32,"Calculating the following integral using complex analysis: $\int_{0}^{\pi}e^{a\cos(\theta)}\cos(a\sin(\theta))\, d\theta$",Calculating the following integral using complex analysis:,"\int_{0}^{\pi}e^{a\cos(\theta)}\cos(a\sin(\theta))\, d\theta","I am trying to solve a question from my complex analysis test that I didn't manage to do during the test in order to practice for the next exam. The problem is as follows: Calculate $\int_{0}^{\pi}e^{a\cos(\theta)}\cos(a\sin(\theta))\,  d\theta$ Where the method used should be using complex analysis. What I tried: I have noticed $$e^{a\cos(\theta)}\cos(a\sin(\theta))=Re(e^{acis(\theta)})$$ where $cis(\theta):=\cos(\theta)+i\sin(\theta)$ Hence the integral is $$\int_{0}^{\pi}Re(e^{a(\cos(\theta)+i\sin(\theta))}\, d\theta$$ I did the change of variables: $z=ae^{i\theta}$, $dz=iae^{i\theta}\, d\theta\implies d\theta=\frac{dz}{iz}$. When $\theta=0$ we have that $z=a$ and when $\theta=\pi$ we get $z=-ia$ and so I wrote that the integral is $$\int_{a}^{-ia}Re(e^{z})\,\frac{dz}{iz}$$ Now I don't understand how I got $e^{z}$, which seems wrong to me, but what the checker actually marked in red and wrote a question mark by were the integration limits: $a,-ia$ . Can someone please help me understand what was wrong with what the integration limits, and how to actually solve this integral ? Any help is greatly appreciated!","I am trying to solve a question from my complex analysis test that I didn't manage to do during the test in order to practice for the next exam. The problem is as follows: Calculate $\int_{0}^{\pi}e^{a\cos(\theta)}\cos(a\sin(\theta))\,  d\theta$ Where the method used should be using complex analysis. What I tried: I have noticed $$e^{a\cos(\theta)}\cos(a\sin(\theta))=Re(e^{acis(\theta)})$$ where $cis(\theta):=\cos(\theta)+i\sin(\theta)$ Hence the integral is $$\int_{0}^{\pi}Re(e^{a(\cos(\theta)+i\sin(\theta))}\, d\theta$$ I did the change of variables: $z=ae^{i\theta}$, $dz=iae^{i\theta}\, d\theta\implies d\theta=\frac{dz}{iz}$. When $\theta=0$ we have that $z=a$ and when $\theta=\pi$ we get $z=-ia$ and so I wrote that the integral is $$\int_{a}^{-ia}Re(e^{z})\,\frac{dz}{iz}$$ Now I don't understand how I got $e^{z}$, which seems wrong to me, but what the checker actually marked in red and wrote a question mark by were the integration limits: $a,-ia$ . Can someone please help me understand what was wrong with what the integration limits, and how to actually solve this integral ? Any help is greatly appreciated!",,"['complex-analysis', 'integration']"
33,how do you do this integral from fourier transform.,how do you do this integral from fourier transform.,,"I am trying to find the fourier transform of $$\frac{\sin(ax)}{x}$$ for $a >0$. This is clearly an even function so we only need to do the real part, but I could not evaluate $$\int_{-\infty}^{\infty} \cos(kx) \sin(ax) \frac{dx}{x}. $$ Can someone please help me? I tried wolfram alpha but it only gave an answer which is not very helpful.","I am trying to find the fourier transform of $$\frac{\sin(ax)}{x}$$ for $a >0$. This is clearly an even function so we only need to do the real part, but I could not evaluate $$\int_{-\infty}^{\infty} \cos(kx) \sin(ax) \frac{dx}{x}. $$ Can someone please help me? I tried wolfram alpha but it only gave an answer which is not very helpful.",,"['integration', 'fourier-analysis']"
34,"Why is $\int\limits_{1}^{n} \log x \,dx \le \sum\limits_{x = 1}^{n}\log x$?",Why is ?,"\int\limits_{1}^{n} \log x \,dx \le \sum\limits_{x = 1}^{n}\log x","It has been a long time since I studied integrals, so this question may sound stupid. I was going through this wiki page, and came across the following inequality: $$\int_{1}^{n} \log x \,dx \le \sum_{x = 1}^{n}\log x$$ Why is this inequality true? Now, my understanding is that the integral on the left side is the area under the curve of $y = \log x$ from $x = 1 \text{ to } n$. Also, this curve is always increasing, and non-negative in $[1 \dots \infty)$. As for the summation, it can be graphically/geometrically represented as rectangles of width 1 on the X-axis, and height $\log x$ for integral values of $x$. So, $\log 3$ can be represented as a rectangle from $x = 3 \text{ to } 4$ of height $\log 3$. Then the summation is the total area of these rectangles. Since the last rectangle goes upto $n+1$, it is beyond the upper limit of the integral. Apart from that, all other rectangles have area lesser than the corresponding sections of the curve (since it is non-negative and increasing in the any section after $x = 1$). So, we get the obvious inequality: $$\int_{1}^{n} \log x \,dx \ge \sum_{x = 1}^{n-1}\log x$$ How does the addition of the $\log n$ term to the right hand side change the inequality? How can the first inequality be proven?","It has been a long time since I studied integrals, so this question may sound stupid. I was going through this wiki page, and came across the following inequality: $$\int_{1}^{n} \log x \,dx \le \sum_{x = 1}^{n}\log x$$ Why is this inequality true? Now, my understanding is that the integral on the left side is the area under the curve of $y = \log x$ from $x = 1 \text{ to } n$. Also, this curve is always increasing, and non-negative in $[1 \dots \infty)$. As for the summation, it can be graphically/geometrically represented as rectangles of width 1 on the X-axis, and height $\log x$ for integral values of $x$. So, $\log 3$ can be represented as a rectangle from $x = 3 \text{ to } 4$ of height $\log 3$. Then the summation is the total area of these rectangles. Since the last rectangle goes upto $n+1$, it is beyond the upper limit of the integral. Apart from that, all other rectangles have area lesser than the corresponding sections of the curve (since it is non-negative and increasing in the any section after $x = 1$). So, we get the obvious inequality: $$\int_{1}^{n} \log x \,dx \ge \sum_{x = 1}^{n-1}\log x$$ How does the addition of the $\log n$ term to the right hand side change the inequality? How can the first inequality be proven?",,"['inequality', 'integration', 'logarithms', 'summation']"
35,Fourier transform of Cauchy principal value,Fourier transform of Cauchy principal value,,I try to understand the direct computation of the Fourier transform of the distribution `Cauchy principal value' $p.v. \frac{1}{x}$ . I don't understand the following change of order of integration: $$ p.v.\int_\mathbb{R} \frac{1}{x}\Bigg(\int_\mathbb{R} e^{-kix}\varphi(k)dk\Bigg)dx=\int_\mathbb{R} \varphi(k)\Bigg(p.v.\int_\mathbb{R} \frac{e^{-kix}}{x}dx\Bigg)dk $$ where $\varphi$ is a Schwartz function and where p.v. denotes the principal value of the integral. Why and how justify rigourously this change of order of integration?,I try to understand the direct computation of the Fourier transform of the distribution `Cauchy principal value' . I don't understand the following change of order of integration: where is a Schwartz function and where p.v. denotes the principal value of the integral. Why and how justify rigourously this change of order of integration?,"p.v. \frac{1}{x} 
p.v.\int_\mathbb{R} \frac{1}{x}\Bigg(\int_\mathbb{R} e^{-kix}\varphi(k)dk\Bigg)dx=\int_\mathbb{R} \varphi(k)\Bigg(p.v.\int_\mathbb{R} \frac{e^{-kix}}{x}dx\Bigg)dk
 \varphi","['integration', 'fourier-analysis', 'improper-integrals', 'distribution-theory']"
36,Analytic integral of diverging function,Analytic integral of diverging function,,"Is it possible to obtain the result of the following integral analytically? $$\int_0^x \cfrac{{\rm d}u}{1-u^n}$$ I've tried using quadrature, but the function goes to infinity at $u=1$, hence the integral. EDIT I suppose an analytic solution is not possible, so is there any way to calculate it numerically for $u>1$? I managed to write: from math import * from scipy.integrate import quad f = lambda u,n: 1./(1.-(u**n)) eps = 0.0001; n=2.6; # from 0 to 1.005 print quad(lambda x:f(x,n),0.0,1.-eps)[0]+ quad(lambda x:f(x,n) ,1.+eps,1.005)[0] I implemented the Cauchy principle value method in python 2.7 using scipy. Is there are particular reason for it not to work. For (u=1.005, n=2.6, x=u) the result should have been 2.022 (according to this ( Open-Channel Flow by Subhash C. Jain, p78)). Instead, it is 2.48. Am I missing something? Can we say that $$\int_0^{x+\epsilon}\frac{\mathrm{d}u}{1-u^n} = \int_0^{x-\epsilon}\frac{\mathrm{d}u}{1-u^n}$$ Here are the numerical solutions that are supposedly correct: Solution: Here is a snippet in python2.7 using the hyp2f1() function from the mpmath package def F(u,n):     if u < 1:         return u*mpmath.hyp2f1(1/n,1,1/n+1,u**n)     elif u >1:         return (u**(1-n))/(n-1)* \             mpmath.hyp2f1(1-1/n, 1 , 2-1/n ,u**(-1*n)) #+ pi/n/tan(pi/n)     else:         return 0.","Is it possible to obtain the result of the following integral analytically? $$\int_0^x \cfrac{{\rm d}u}{1-u^n}$$ I've tried using quadrature, but the function goes to infinity at $u=1$, hence the integral. EDIT I suppose an analytic solution is not possible, so is there any way to calculate it numerically for $u>1$? I managed to write: from math import * from scipy.integrate import quad f = lambda u,n: 1./(1.-(u**n)) eps = 0.0001; n=2.6; # from 0 to 1.005 print quad(lambda x:f(x,n),0.0,1.-eps)[0]+ quad(lambda x:f(x,n) ,1.+eps,1.005)[0] I implemented the Cauchy principle value method in python 2.7 using scipy. Is there are particular reason for it not to work. For (u=1.005, n=2.6, x=u) the result should have been 2.022 (according to this ( Open-Channel Flow by Subhash C. Jain, p78)). Instead, it is 2.48. Am I missing something? Can we say that $$\int_0^{x+\epsilon}\frac{\mathrm{d}u}{1-u^n} = \int_0^{x-\epsilon}\frac{\mathrm{d}u}{1-u^n}$$ Here are the numerical solutions that are supposedly correct: Solution: Here is a snippet in python2.7 using the hyp2f1() function from the mpmath package def F(u,n):     if u < 1:         return u*mpmath.hyp2f1(1/n,1,1/n+1,u**n)     elif u >1:         return (u**(1-n))/(n-1)* \             mpmath.hyp2f1(1-1/n, 1 , 2-1/n ,u**(-1*n)) #+ pi/n/tan(pi/n)     else:         return 0.",,"['integration', 'regularization']"
37,Evaluate a definite integral involving Airy functions,Evaluate a definite integral involving Airy functions,,"I'd like to show: $$ I \equiv \frac{1}{(2 \pi {\rm i})^2} \int_{a - {\rm i} \infty}^{a + {\rm i} \infty} \int_{b - {\rm i} \infty}^{b + {\rm i} \infty} \frac{1}{{\rm Ai}(u) {\rm Ai}(v) (u-v)} \,dv \,du = \frac{1}{2} \;, $$ where each integral is over a vertical contour in the complex plane (like for an inverse Laplace transform) and the only restriction on $a$ and $b$ is: $$ 0 < b < a \;. $$ The Airy function of the first kind, $$ {\rm Ai}(z) \equiv \frac{1}{\pi} \int_0^\infty \cos \left( \frac{t^3}{3} + zt \right) \,dt \;, $$ satisfies ${\rm Ai}''(z) = z {\rm Ai}(z)$ and is an entire function with zeros on the negative real axis. Numerical integration gives me $I = \frac{1}{2}$, but how can I prove it?","I'd like to show: $$ I \equiv \frac{1}{(2 \pi {\rm i})^2} \int_{a - {\rm i} \infty}^{a + {\rm i} \infty} \int_{b - {\rm i} \infty}^{b + {\rm i} \infty} \frac{1}{{\rm Ai}(u) {\rm Ai}(v) (u-v)} \,dv \,du = \frac{1}{2} \;, $$ where each integral is over a vertical contour in the complex plane (like for an inverse Laplace transform) and the only restriction on $a$ and $b$ is: $$ 0 < b < a \;. $$ The Airy function of the first kind, $$ {\rm Ai}(z) \equiv \frac{1}{\pi} \int_0^\infty \cos \left( \frac{t^3}{3} + zt \right) \,dt \;, $$ satisfies ${\rm Ai}''(z) = z {\rm Ai}(z)$ and is an entire function with zeros on the negative real axis. Numerical integration gives me $I = \frac{1}{2}$, but how can I prove it?",,"['complex-analysis', 'integration', 'definite-integrals']"
38,"Equivalent of $\int_0^{\infty} \frac{\mathrm dx}{(1+x^3)^n},n\rightarrow\infty$",Equivalent of,"\int_0^{\infty} \frac{\mathrm dx}{(1+x^3)^n},n\rightarrow\infty",According to my calculations $$ \int_0^\infty \frac{\mathrm dx}{(1+x^3)^n}=\frac{(3n-4)\times(3n-7)\times\cdots\times5\times2}{3^{n+1/2}(n-1)!}2\pi$$ How can an equivalent of $$ \int_0^\infty \frac{\mathrm dx}{(1+x^3)^n}$$ be derived from this formula? (Given that my objective is to study the nature of the series $ \sum \int_0^\infty \frac{\mathrm dx}{(1+x^3)^n} $) So my question is simply: is there a simple equivalent for $(3n-4)\times(3n-7)\times\cdots\times5\times2$ ?,According to my calculations $$ \int_0^\infty \frac{\mathrm dx}{(1+x^3)^n}=\frac{(3n-4)\times(3n-7)\times\cdots\times5\times2}{3^{n+1/2}(n-1)!}2\pi$$ How can an equivalent of $$ \int_0^\infty \frac{\mathrm dx}{(1+x^3)^n}$$ be derived from this formula? (Given that my objective is to study the nature of the series $ \sum \int_0^\infty \frac{\mathrm dx}{(1+x^3)^n} $) So my question is simply: is there a simple equivalent for $(3n-4)\times(3n-7)\times\cdots\times5\times2$ ?,,"['sequences-and-series', 'integration', 'asymptotics']"
39,Isoperimetric Ratio of an Ellipse,Isoperimetric Ratio of an Ellipse,,"The isoperimetric theorem states that the area A of a plane region with perimeter P cannot exceed $\pi ({P/2\pi})^2\ = P^2/4\pi.$ That is, $P \geqslant \sqrt{4\pi A} $ Considering an ellipse with major and minor semi-axes a and b respectively, its area is $\pi ab$ and its perimeter is given  by $\int\limits_{0}^{2\pi}\sqrt{a^2sin^2t + b^2cos^2t}\  dt$ So we have $\int\limits_{0}^{2\pi}\sqrt{a^2sin^2t + b^2cos^2t}\ dt \geqslant \sqrt{4\pi(\pi ab)}$ But by quartering and rearranging the elllpse as in the diagram below, with a central square of area $(a - b)^2 $, we can state the stronger $\int\limits_{0}^{2\pi}\sqrt{a^2sin^2t + b^2cos^2t}\, dt \geqslant \sqrt{4\pi[\pi ab + (a - b)^2]}$ And my question is whether this last inequality can be proven analytically.","The isoperimetric theorem states that the area A of a plane region with perimeter P cannot exceed $\pi ({P/2\pi})^2\ = P^2/4\pi.$ That is, $P \geqslant \sqrt{4\pi A} $ Considering an ellipse with major and minor semi-axes a and b respectively, its area is $\pi ab$ and its perimeter is given  by $\int\limits_{0}^{2\pi}\sqrt{a^2sin^2t + b^2cos^2t}\  dt$ So we have $\int\limits_{0}^{2\pi}\sqrt{a^2sin^2t + b^2cos^2t}\ dt \geqslant \sqrt{4\pi(\pi ab)}$ But by quartering and rearranging the elllpse as in the diagram below, with a central square of area $(a - b)^2 $, we can state the stronger $\int\limits_{0}^{2\pi}\sqrt{a^2sin^2t + b^2cos^2t}\, dt \geqslant \sqrt{4\pi[\pi ab + (a - b)^2]}$ And my question is whether this last inequality can be proven analytically.",,"['integration', 'inequality']"
40,"If $(a,b,c)$ are the sides of a triangle, is it true that probability that $a+b > c^{\frac{3}{c}}$ is $\zeta(2)-1$?","If  are the sides of a triangle, is it true that probability that  is ?","(a,b,c) a+b > c^{\frac{3}{c}} \zeta(2)-1","Let $(a,b,c)$ be the sides of a triangle inscribed inside a unit circle such that the vertices of the triangle are distributed uniformly on the circumference. The solution of this question unexpectedly showed that the simple triangle inequality $a+b \ge c$ is equivalent to the famous Basel problem . $$ \zeta(2) = 1 + \frac{1}{2^2} + \frac{1}{3^2} + \cdots = \frac{\pi^2}{6} $$ Motivated by this, I was exploring if there are other relationship interesting relationships between the Riemann zeta function and the triangle inequality and I observed numerically that the probability $$ P\left(a+b \ge c^{\frac{3}{c}}\right) = \zeta(2) - 1 $$ Can this be proved or disproved? Julia Code: step = 10^7 target = step count = 0 f = 0  while 1 > 0     count += 1     angles = (rand(3) .* 2 * π)     vertices_x = cos.(angles)     vertices_y = sin.(angles)          push!(vertices_x, vertices_x[1])     push!(vertices_y, vertices_y[1])          x_diff = diff(vertices_x)     y_diff = diff(vertices_y)     side_lengths = sqrt.(x_diff.^2 + y_diff.^2)          a = side_lengths[1]     c = side_lengths[2]     b = side_lengths[3]              if (a+b) >= c^(3/c)         f += 1     end          if count == target         println(f,"" "", count,"" "", string(f/count)[1:end-1])         target += step     end end For $3.5 \times 10^9$ trails, this code gives the probability as $0.64492$ which agrees with $\zeta(2)-1$ to four decimal places.","Let be the sides of a triangle inscribed inside a unit circle such that the vertices of the triangle are distributed uniformly on the circumference. The solution of this question unexpectedly showed that the simple triangle inequality is equivalent to the famous Basel problem . Motivated by this, I was exploring if there are other relationship interesting relationships between the Riemann zeta function and the triangle inequality and I observed numerically that the probability Can this be proved or disproved? Julia Code: step = 10^7 target = step count = 0 f = 0  while 1 > 0     count += 1     angles = (rand(3) .* 2 * π)     vertices_x = cos.(angles)     vertices_y = sin.(angles)          push!(vertices_x, vertices_x[1])     push!(vertices_y, vertices_y[1])          x_diff = diff(vertices_x)     y_diff = diff(vertices_y)     side_lengths = sqrt.(x_diff.^2 + y_diff.^2)          a = side_lengths[1]     c = side_lengths[2]     b = side_lengths[3]              if (a+b) >= c^(3/c)         f += 1     end          if count == target         println(f,"" "", count,"" "", string(f/count)[1:end-1])         target += step     end end For trails, this code gives the probability as which agrees with to four decimal places.","(a,b,c) a+b \ge c 
\zeta(2) = 1 + \frac{1}{2^2} + \frac{1}{3^2} + \cdots = \frac{\pi^2}{6}
 
P\left(a+b \ge c^{\frac{3}{c}}\right) = \zeta(2) - 1
 3.5 \times 10^9 0.64492 \zeta(2)-1","['integration', 'geometry', 'number-theory', 'inequality', 'triangles']"
41,When is this integral a polynomial?,When is this integral a polynomial?,,"Consider the functions or integrals $f : \mathbb{R} \to \mathbb{R}$ of the form, $$ f(x) = \int_{a}^{b}K(|x-y|)u(y)dy $$ where $u$ is known and $K$ is a weakly singular kernel (or a continuous kernel for simplicity). How do we show that this function $f$ is a polynomial ? One approach would be to actually compute the integral, however, that is a difficult task. For example, consider the integral $$ \int_{-1}^{1} |x-y|^{-s}(1-y^2)^{\frac{1+s}{2}} dy = \frac{\pi (1+s)}{2\sin{\left( \pi\frac{1+s}{2} \right)}}(1-sx^2),$$ where $s  \in (-1,1)$ , $x\in[-1,1]$ . Another approach would be to show higher order derivatives of this integral are zero, but that seems impossible because of the weakly singular kernel. Any hints? P.S : I have not proven the integral above yet. Edit : Maybe the question I have asked is too general. We can also start with the following problem: For what values of $s \in (0,1)$ is $$\int_{-1}^{1}(1-y^2)^s\ln{|x-y|}dy $$ a polynomial in $x$ ? Edit 2 : It appears that above integral is a polynomial for $x\in[-1,1]$ , $s=1/2$ .","Consider the functions or integrals of the form, where is known and is a weakly singular kernel (or a continuous kernel for simplicity). How do we show that this function is a polynomial ? One approach would be to actually compute the integral, however, that is a difficult task. For example, consider the integral where , . Another approach would be to show higher order derivatives of this integral are zero, but that seems impossible because of the weakly singular kernel. Any hints? P.S : I have not proven the integral above yet. Edit : Maybe the question I have asked is too general. We can also start with the following problem: For what values of is a polynomial in ? Edit 2 : It appears that above integral is a polynomial for , .","f : \mathbb{R} \to \mathbb{R}  f(x) = \int_{a}^{b}K(|x-y|)u(y)dy  u K f  \int_{-1}^{1} |x-y|^{-s}(1-y^2)^{\frac{1+s}{2}} dy = \frac{\pi (1+s)}{2\sin{\left( \pi\frac{1+s}{2} \right)}}(1-sx^2), s 
\in (-1,1) x\in[-1,1] s \in (0,1) \int_{-1}^{1}(1-y^2)^s\ln{|x-y|}dy  x x\in[-1,1] s=1/2","['integration', 'derivatives', 'polynomials', 'singular-integrals']"
42,Sum with reciprocal central binomial and harmonic number $\sum_{n=1}^{\infty}\frac{H_{2n}}{n^2 C_{2n}^{n}}$,Sum with reciprocal central binomial and harmonic number,\sum_{n=1}^{\infty}\frac{H_{2n}}{n^2 C_{2n}^{n}},"I am trying to calculate this sum,and below is my attempt: $$\displaystyle{S}=\underset{{n}=\mathrm{1}} {\overset{\infty} {\sum}}\frac{{H}_{\mathrm{2}{n}} }{{n}^{\mathrm{2}} \left({C}_{\mathrm{2}{n}} ^{{n}} \right)}=\underset{{n}=\mathrm{1}} {\overset{\infty} {\sum}}\frac{\mathrm{2}}{{n}\left({C}_{\mathrm{2}{n}} ^{{n}} \right)}\left(\frac{{H}_{\mathrm{2}{n}} }{\mathrm{2}{n}}\right)=-\mathrm{2}\underset{{n}=\mathrm{1}} {\overset{\infty} {\sum}}\frac{\mathrm{1}}{{n}\left({C}_{\mathrm{2}{n}} ^{{n}} \right)}\left(\int_{\mathrm{0}} ^{\mathrm{1}} {x}^{\mathrm{2}{n}−\mathrm{1}} \mathrm{ln}\left(\mathrm{1}−{x}\right){dx}\right) \\=−\mathrm{2}\int_{\mathrm{0}} ^{\mathrm{1}} \mathrm{ln}\left(\mathrm{1}−{x}\right){dx}\left(\underset{{n}=\mathrm{1}} {\overset{\infty} {\sum}}\frac{{x}^{\mathrm{2}{n}−\mathrm{1}} }{{n}\left({C}_{\mathrm{2}{n}} ^{{n}} \right)}\right)=−\mathrm{4}\int_{\mathrm{0}} ^{\mathrm{1}} \mathrm{ln}\left(\mathrm{1}−{x}\right)\frac{\mathrm{sin}^{−\mathrm{1}} \left(\frac{{x}}{\mathrm{2}}\right)}{\:\sqrt{\mathrm{4}−{x}^{\mathrm{2}} }}{dx} \\{x}=\mathrm{2sin}\left({t}\right)\Rightarrow{t}=\mathrm{sin}^{−\mathrm{1}} \left(\frac{{x}}{\mathrm{2}}\right)\Rightarrow{dt}=\frac{{dx}}{\:\sqrt{\mathrm{4}−{x}^{\mathrm{2}} }} \\\Rightarrow{S}=−\mathrm{4}\int_{\mathrm{0}} ^{\frac{\pi}{\mathrm{6}}} {t}\mathrm{ln}\left(\mathrm{1}−\mathrm{2sin}\left({t}\right)\right){dt} \\ $$ But at this step, I don't know how to process further. Can I ask a hint or another approach? Thank you so much.","I am trying to calculate this sum,and below is my attempt: But at this step, I don't know how to process further. Can I ask a hint or another approach? Thank you so much.",\displaystyle{S}=\underset{{n}=\mathrm{1}} {\overset{\infty} {\sum}}\frac{{H}_{\mathrm{2}{n}} }{{n}^{\mathrm{2}} \left({C}_{\mathrm{2}{n}} ^{{n}} \right)}=\underset{{n}=\mathrm{1}} {\overset{\infty} {\sum}}\frac{\mathrm{2}}{{n}\left({C}_{\mathrm{2}{n}} ^{{n}} \right)}\left(\frac{{H}_{\mathrm{2}{n}} }{\mathrm{2}{n}}\right)=-\mathrm{2}\underset{{n}=\mathrm{1}} {\overset{\infty} {\sum}}\frac{\mathrm{1}}{{n}\left({C}_{\mathrm{2}{n}} ^{{n}} \right)}\left(\int_{\mathrm{0}} ^{\mathrm{1}} {x}^{\mathrm{2}{n}−\mathrm{1}} \mathrm{ln}\left(\mathrm{1}−{x}\right){dx}\right) \\=−\mathrm{2}\int_{\mathrm{0}} ^{\mathrm{1}} \mathrm{ln}\left(\mathrm{1}−{x}\right){dx}\left(\underset{{n}=\mathrm{1}} {\overset{\infty} {\sum}}\frac{{x}^{\mathrm{2}{n}−\mathrm{1}} }{{n}\left({C}_{\mathrm{2}{n}} ^{{n}} \right)}\right)=−\mathrm{4}\int_{\mathrm{0}} ^{\mathrm{1}} \mathrm{ln}\left(\mathrm{1}−{x}\right)\frac{\mathrm{sin}^{−\mathrm{1}} \left(\frac{{x}}{\mathrm{2}}\right)}{\:\sqrt{\mathrm{4}−{x}^{\mathrm{2}} }}{dx} \\{x}=\mathrm{2sin}\left({t}\right)\Rightarrow{t}=\mathrm{sin}^{−\mathrm{1}} \left(\frac{{x}}{\mathrm{2}}\right)\Rightarrow{dt}=\frac{{dx}}{\:\sqrt{\mathrm{4}−{x}^{\mathrm{2}} }} \\\Rightarrow{S}=−\mathrm{4}\int_{\mathrm{0}} ^{\frac{\pi}{\mathrm{6}}} {t}\mathrm{ln}\left(\mathrm{1}−\mathrm{2sin}\left({t}\right)\right){dt} \\ ,"['integration', 'sequences-and-series', 'summation']"
43,"Do We Actually Calculate ""Inverse Laplace Transforms""?","Do We Actually Calculate ""Inverse Laplace Transforms""?",,"In all my classes (engineering) in which the Inverse Laplace Transform ( https://en.wikipedia.org/wiki/Inverse_Laplace_transform ) was required, we used to have a ""lookup table"" in which the Inverse Laplace Transform was provided for many common functions. When trying to find out the Inverse Laplace Transform for some function - we would try to ""strategically"" factor the function of interest, and use this ""lookup table"" to try and recognize these factors and ""piece together"" the Inverse Laplace Transform. This of course worked for many standard functions, but I always wondered how we might be able to calculate the Inverse Laplace Transform for ""non-standard"" functions for which this ""lookup table"" did not contain the Inverse Laplace Transforms. When reading the Wikipedia page about this topic ( https://en.wikipedia.org/wiki/Inverse_Laplace_transform ), I noticed that there seem to be some mathematical formulas (e.g. Mellin's Formula, Post's Inversion Formula) that seem to provide analytical solutions (I think) for the Inverse Laplace Transform of any function - ""standard"" or ""non-standard"". This brings me to my question: How was the ""lookup table"" I was using originally created? How do I calculate the Inverse Laplace Transforms WITHOUT my ""Lookup Table""? The Wikipedia article mentions that Post's Inversion is impractical in the cases of higher-order functions since derivatives are required (I am guessing that for multivariate functions, this will require a Jacobian Matrix). As for Mellin's Formula, this integral is integrated over "" $\gamma + \sqrt{-1} T$ ""  and "" $\gamma - \sqrt{-1} T$ "" : supposedly ""if singularities of the function (i.e. derivatives of the function) are in the left half-plane"" (I don't know how someone can determine if this condition is met - I am guessing that ""singularities of the function being in the left hand plane"" means that all derivatives of the function are ""complex""), ""gamma"" becomes 0 and Mellin's Formula becomes identical to the Inverse Fourier Transform. However, I am not sure how someone would evaluate the integral required for Mellin's Formula in practice (i.e. what do the integral ranges converge to). For instance, if I wanted to use Mellin's Formula to calculate the Inverse Laplace Transform of $\sqrt t$ - what should the values of ""gamma and T"" be? I might be able to somehow figure out how to calculate the integral of "" $e^{st}F(s)$ "" - but I am not sure how to correctly define the limits over which this integral is evaluated! Is Mellin's Formula practical to use for calculating Inverse Laplace Transforms - in other words, how was the ""lookup table"" I was using originally created? How do I calculate the Inverse Laplace Transforms without my ""Lookup Table""? Thank you! Note: It would be really interesting to see if someone here could try to calculate the Inverse Laplace Transform of some function using Mellin's Formula (or some other formula) and then see if their answer matches the true Inverse Laplace Transform! Note: I am guessing that in most cases, ""Gamma"" will usually end up being 0 and ""iT"" will usually end up being infinity - is this reasonable?","In all my classes (engineering) in which the Inverse Laplace Transform ( https://en.wikipedia.org/wiki/Inverse_Laplace_transform ) was required, we used to have a ""lookup table"" in which the Inverse Laplace Transform was provided for many common functions. When trying to find out the Inverse Laplace Transform for some function - we would try to ""strategically"" factor the function of interest, and use this ""lookup table"" to try and recognize these factors and ""piece together"" the Inverse Laplace Transform. This of course worked for many standard functions, but I always wondered how we might be able to calculate the Inverse Laplace Transform for ""non-standard"" functions for which this ""lookup table"" did not contain the Inverse Laplace Transforms. When reading the Wikipedia page about this topic ( https://en.wikipedia.org/wiki/Inverse_Laplace_transform ), I noticed that there seem to be some mathematical formulas (e.g. Mellin's Formula, Post's Inversion Formula) that seem to provide analytical solutions (I think) for the Inverse Laplace Transform of any function - ""standard"" or ""non-standard"". This brings me to my question: How was the ""lookup table"" I was using originally created? How do I calculate the Inverse Laplace Transforms WITHOUT my ""Lookup Table""? The Wikipedia article mentions that Post's Inversion is impractical in the cases of higher-order functions since derivatives are required (I am guessing that for multivariate functions, this will require a Jacobian Matrix). As for Mellin's Formula, this integral is integrated over "" ""  and "" "" : supposedly ""if singularities of the function (i.e. derivatives of the function) are in the left half-plane"" (I don't know how someone can determine if this condition is met - I am guessing that ""singularities of the function being in the left hand plane"" means that all derivatives of the function are ""complex""), ""gamma"" becomes 0 and Mellin's Formula becomes identical to the Inverse Fourier Transform. However, I am not sure how someone would evaluate the integral required for Mellin's Formula in practice (i.e. what do the integral ranges converge to). For instance, if I wanted to use Mellin's Formula to calculate the Inverse Laplace Transform of - what should the values of ""gamma and T"" be? I might be able to somehow figure out how to calculate the integral of "" "" - but I am not sure how to correctly define the limits over which this integral is evaluated! Is Mellin's Formula practical to use for calculating Inverse Laplace Transforms - in other words, how was the ""lookup table"" I was using originally created? How do I calculate the Inverse Laplace Transforms without my ""Lookup Table""? Thank you! Note: It would be really interesting to see if someone here could try to calculate the Inverse Laplace Transform of some function using Mellin's Formula (or some other formula) and then see if their answer matches the true Inverse Laplace Transform! Note: I am guessing that in most cases, ""Gamma"" will usually end up being 0 and ""iT"" will usually end up being infinity - is this reasonable?",\gamma + \sqrt{-1} T \gamma - \sqrt{-1} T \sqrt t e^{st}F(s),"['integration', 'complex-analysis', 'complex-numbers', 'laplace-transform']"
44,"Why did my contour integration for $\int_0^{\pi/2}\frac{1}{1+\sin x}\,\mathrm{d}x$ fail?",Why did my contour integration for  fail?,"\int_0^{\pi/2}\frac{1}{1+\sin x}\,\mathrm{d}x","$\newcommand{\d}{\,\mathrm{d}}$ Integrals of the titular form can be successfully contour-integrated, e.g.: $$\int_0^{2\pi}\frac{1}{4\cos x-5}\d x=-\frac{2}{3}\pi$$ Follows from a complex substitution very similar to what I've done here. However: $$\int_0^{\pi/2}\frac{1}{1+\sin x}\d x=1$$ Is easily evaluated with Weierstrass's substitution, but out of curiosity I attempted to form a contour integration approach, which failed: First translate by $\pi/4$ : $$\int_{-\pi/4}^{\pi/4}\frac{1}{1+\sin(x+\pi/4)}\d x=\sqrt{2}\int_{-\pi/4}^{\pi/4}\frac{1}{\sqrt{2}+\sin x+\cos x}\d x$$ Let $\Bbb T=\{z\in\Bbb C:|z|=1\}$ . Let $\log$ be the principal branch, and put $x=\frac{1}{4i}\log z$ , $z=e^{4ix}$ and $[-\pi/4,\pi/4)\mapsto\Bbb T$ : $$\begin{align}\frac{\sqrt{2}}{4i}\oint_{\Bbb T}\frac{1}{\sqrt{2}+\sin\left(\frac{1}{4i}\log z\right)+\cos\left(\frac{1}{4i}\log z\right)}\frac{\d z}{z}&=\frac{\sqrt{2}}{4i}\oint_{\Bbb T}\frac{1}{\sqrt{2}+z^{1/4}}\frac{\d z}{z}\\&=\pi\frac{\sqrt{2}}{2}\sum\mathrm{Res}\end{align}$$ We have a pole at $z=0$ which is contained by $\Bbb T$ . The other pole is when $\exp\frac{1}{4}\log z=-2^{1/2}$ : $$\exp\frac{1}{4}\log z=\exp(\pi i+\frac{1}{2}\ln 2),\,\log z=4\pi i+2\ln 2+8\pi i\cdot k$$ But this doesn't really make sense, since the principal $\log z$ should have imaginary part contained in $(-\pi,\pi]$ , but this expression clearly does not satisfy this for any $k$ . I will infer from this that no principal solutions exist, and then that $z=0$ is the only pole, with residue $\frac{1}{\sqrt{2}}$ . We then arrive at the incorrect answer: $$\int_0^{\pi/2}\frac{1}{1+\sin x}\d x=\frac{\pi}{2}$$ What did I do wrong?","Integrals of the titular form can be successfully contour-integrated, e.g.: Follows from a complex substitution very similar to what I've done here. However: Is easily evaluated with Weierstrass's substitution, but out of curiosity I attempted to form a contour integration approach, which failed: First translate by : Let . Let be the principal branch, and put , and : We have a pole at which is contained by . The other pole is when : But this doesn't really make sense, since the principal should have imaginary part contained in , but this expression clearly does not satisfy this for any . I will infer from this that no principal solutions exist, and then that is the only pole, with residue . We then arrive at the incorrect answer: What did I do wrong?","\newcommand{\d}{\,\mathrm{d}} \int_0^{2\pi}\frac{1}{4\cos x-5}\d x=-\frac{2}{3}\pi \int_0^{\pi/2}\frac{1}{1+\sin x}\d x=1 \pi/4 \int_{-\pi/4}^{\pi/4}\frac{1}{1+\sin(x+\pi/4)}\d x=\sqrt{2}\int_{-\pi/4}^{\pi/4}\frac{1}{\sqrt{2}+\sin x+\cos x}\d x \Bbb T=\{z\in\Bbb C:|z|=1\} \log x=\frac{1}{4i}\log z z=e^{4ix} [-\pi/4,\pi/4)\mapsto\Bbb T \begin{align}\frac{\sqrt{2}}{4i}\oint_{\Bbb T}\frac{1}{\sqrt{2}+\sin\left(\frac{1}{4i}\log z\right)+\cos\left(\frac{1}{4i}\log z\right)}\frac{\d z}{z}&=\frac{\sqrt{2}}{4i}\oint_{\Bbb T}\frac{1}{\sqrt{2}+z^{1/4}}\frac{\d z}{z}\\&=\pi\frac{\sqrt{2}}{2}\sum\mathrm{Res}\end{align} z=0 \Bbb T \exp\frac{1}{4}\log z=-2^{1/2} \exp\frac{1}{4}\log z=\exp(\pi i+\frac{1}{2}\ln 2),\,\log z=4\pi i+2\ln 2+8\pi i\cdot k \log z (-\pi,\pi] k z=0 \frac{1}{\sqrt{2}} \int_0^{\pi/2}\frac{1}{1+\sin x}\d x=\frac{\pi}{2}","['integration', 'complex-analysis', 'logarithms', 'contour-integration']"
45,"Is there any formula for $S(k)=\sum_{n=1}^{\infty} \frac{1}{n^{k} k^{n}},$ where $k\in \mathbb{N}$?",Is there any formula for  where ?,"S(k)=\sum_{n=1}^{\infty} \frac{1}{n^{k} k^{n}}, k\in \mathbb{N}","I had just used the definite integral $$\int_{0}^{\frac{1}{2}} \frac{\ln (1-x)}{x}  d x $$ to evaluate the infinite sum $$ \displaystyle S=\sum_{n=1}^{\infty} \frac{1}{n^{2} 2^{n}}. $$ However, I just wonder if there is a formula for a more general series $$ \displaystyle S(k)=\sum_{n=1}^{\infty} \frac{1}{n^{k} k^{n}}, \text{ where }k \in \mathbb{N}. $$ Now let me start with the former using the infinite geometric series $ \displaystyle \frac{1}{1-t}=\sum_{n=0}^{\infty} t^{n} \quad \text { for }|t|<1 \tag*{(1)}$ Integrating both sides of (1) w.r.t. t from 0 to x yields $ \displaystyle \begin{array}{r} \displaystyle \int_{0}^{x} \frac{1}{1-t} d t= \displaystyle \sum_{n=0}^{\infty} \int_{0}^{x} t^{n} d t \\ \displaystyle -\ln (1-x)=\sum_{n=1}^{\infty} \frac{x^{n}}{n}\end{array} \tag*{(2)}$ Dividing the equation (2) by x and integrating both sides from $0$ to $\frac{1}{2} $ gives $ \displaystyle \sum_{n=1}^{\infty} \frac{1}{n^{2} 2^{n}}=\displaystyle -\int_{0}^{\frac{1}{2}} \frac{\ln (1-x) d x}{x} \tag*{(3)}$ Now let’s tackle the integral $ \displaystyle J:=\int_{0}^{\frac{1}{2}} \frac{\ln (1-x) d x}{x} \tag*{} $ by the substitution $y=\ln (1-x) $ . $\displaystyle  \begin{aligned}J &=\int_{-\ln 2}^{0} \frac{y}{1-e^{y}} e^{y} d y \\&=\int_{-\ln 2}^{0} y \sum_{k=0}^{\infty} e^{(k+1) y} d y \\&=\sum_{k=0}^{\infty} \int_{-\ln 2}^{0} y e^{(k+1) y} d y\\ &\stackrel{I B P}{=} \sum_{k=0}^{\infty} \frac{1}{k+1}\left(\ln 2 \cdot \frac{1}{2^{k+1}}-\left[\frac{e^{(k+1) y}}{k+1}\right]_{-\ln 2}^{0}\right) \\&= \ln 2 \sum_{k=1}^{\infty} \frac{1}{k \cdot 2^{k}}-\sum_{k=1}^{\infty}\frac{1}{k^{2}}+\sum_{k=1}^{\infty} \frac{1}{k^{2} 2^{k}} \\&= \ln 2 \sum_{k=1}^{\infty} \frac{1}{k \cdot 2^{k}}-\frac{\pi^{2}}{6}+S\end{aligned} \tag*{} $ $ \displaystyle \textrm{Putting }x= \dfrac{1}{2} \textrm{ in (2) yields }$ $\displaystyle  \sum_{k=1}^{\infty} \frac{1}{k \cdot 2^{k}}=-\ln 2 \tag*{} $ Now we can conclude that $ \displaystyle \begin{array}{c}\displaystyle S=-\left(\ln ^{2} 2-\frac{\pi^{2}}{6}+S \right) \\\boxed{S(2)=\sum_{n=1}^{\infty} \frac{1}{n^{2} 2^{n}} =\frac{1}{2}\left(\frac{\pi^{2}}{6}-\ln ^{2} 2\right)}\end{array}\tag*{} $ How about the general series $S(k)$ ? :|D Wish you enjoy the proof! Your suggestion, comments and formula for evaluating the general series S(k) are warmly welcome!","I had just used the definite integral to evaluate the infinite sum However, I just wonder if there is a formula for a more general series Now let me start with the former using the infinite geometric series Integrating both sides of (1) w.r.t. t from 0 to x yields Dividing the equation (2) by x and integrating both sides from to gives Now let’s tackle the integral by the substitution . Now we can conclude that How about the general series ? :|D Wish you enjoy the proof! Your suggestion, comments and formula for evaluating the general series S(k) are warmly welcome!","\int_{0}^{\frac{1}{2}} \frac{\ln (1-x)}{x}  d x   \displaystyle S=\sum_{n=1}^{\infty} \frac{1}{n^{2} 2^{n}}.   \displaystyle S(k)=\sum_{n=1}^{\infty} \frac{1}{n^{k} k^{n}}, \text{ where }k \in \mathbb{N}.   \displaystyle \frac{1}{1-t}=\sum_{n=0}^{\infty} t^{n} \quad \text { for }|t|<1 \tag*{(1)}  \displaystyle \begin{array}{r} \displaystyle \int_{0}^{x} \frac{1}{1-t} d t= \displaystyle \sum_{n=0}^{\infty} \int_{0}^{x} t^{n} d t \\ \displaystyle -\ln (1-x)=\sum_{n=1}^{\infty} \frac{x^{n}}{n}\end{array} \tag*{(2)} 0 \frac{1}{2}   \displaystyle \sum_{n=1}^{\infty} \frac{1}{n^{2} 2^{n}}=\displaystyle -\int_{0}^{\frac{1}{2}} \frac{\ln (1-x) d x}{x} \tag*{(3)}  \displaystyle J:=\int_{0}^{\frac{1}{2}} \frac{\ln (1-x) d x}{x} \tag*{}  y=\ln (1-x)  \displaystyle  \begin{aligned}J &=\int_{-\ln 2}^{0} \frac{y}{1-e^{y}} e^{y} d y \\&=\int_{-\ln 2}^{0} y \sum_{k=0}^{\infty} e^{(k+1) y} d y \\&=\sum_{k=0}^{\infty} \int_{-\ln 2}^{0} y e^{(k+1) y} d y\\ &\stackrel{I B P}{=} \sum_{k=0}^{\infty} \frac{1}{k+1}\left(\ln 2 \cdot \frac{1}{2^{k+1}}-\left[\frac{e^{(k+1) y}}{k+1}\right]_{-\ln 2}^{0}\right) \\&= \ln 2 \sum_{k=1}^{\infty} \frac{1}{k \cdot 2^{k}}-\sum_{k=1}^{\infty}\frac{1}{k^{2}}+\sum_{k=1}^{\infty} \frac{1}{k^{2} 2^{k}} \\&= \ln 2 \sum_{k=1}^{\infty} \frac{1}{k \cdot 2^{k}}-\frac{\pi^{2}}{6}+S\end{aligned} \tag*{}   \displaystyle \textrm{Putting }x= \dfrac{1}{2} \textrm{ in (2) yields } \displaystyle  \sum_{k=1}^{\infty} \frac{1}{k \cdot 2^{k}}=-\ln 2 \tag*{}   \displaystyle \begin{array}{c}\displaystyle S=-\left(\ln ^{2} 2-\frac{\pi^{2}}{6}+S \right) \\\boxed{S(2)=\sum_{n=1}^{\infty} \frac{1}{n^{2} 2^{n}} =\frac{1}{2}\left(\frac{\pi^{2}}{6}-\ln ^{2} 2\right)}\end{array}\tag*{}  S(k)","['integration', 'sequences-and-series', 'power-series']"
46,"Evaluate $\int_0^{\pi/2} \frac{\cos ((1-a) x)}{\cos ^{a-1}(x) (\cosh (2 b)-\cos (2 x))} \, dx$",Evaluate,"\int_0^{\pi/2} \frac{\cos ((1-a) x)}{\cos ^{a-1}(x) (\cosh (2 b)-\cos (2 x))} \, dx","How to prove $$\int_0^{\pi/2} \frac{\cos ((1-a) x)\cos ^{1-a}(x)}{ (\cosh (2 b)-\cos (2 x))} \, dx=\frac{\pi  e^{(a-1)b}}{4\sinh (b) \cosh ^a(b)}$$ So far I've got no idea of tackling it (my intuition is on contour integration). I'd like you to give some suggestions. Thanks in advance! Update: I found an alternate proof for @pisco's general formula. By using Fourier expansion $$\frac{\sinh (2 b)}{\cosh (2 b)-\cos (2 x)}=2 \sum _{k=1}^{\infty } e^{-2kb} \cos (2 k x)+1$$ and trigonometric identities $\cos*\cos\to \cos+\cos$ , one have $$\small I=\int_0^{\pi /2} {\frac{{{{(\cos x)}^a}\cos cx}}{{\cosh 2b - \cos 2x}}dx} =\frac{\sum _{k=1}^{\infty } \exp (-2 b k) (f(a+1,c+2 k)+f(a+1,c-2 k))+f(a+1,c)}{\sinh (2 b)}$$ Where $f$ denotes the classic Cauchy integral ( $\Re v>0$ ) $$f(v,a)=\int_0^{\frac{\pi }{2}} \cos (a x) \cos ^{v-1}(x) \, dx=\frac{\pi }{2^v v B\left(\frac{1}{2} (a+v+1),\frac{1}{2} (-a+v+1)\right)}$$ Performing the summation using definition of hypergeometric functions one have $$\small I=\frac{\pi  2^{-a-1} \text{csch}(2 b) \left(e^{-2 b} \left(\frac{\, _2F_1\left(1,\frac{1}{2} (-a-c+2);\frac{1}{2} (a-c+4);-e^{-2 b}\right)}{B\left(\frac{a+c}{2},\frac{1}{2} (a-c+4)\right)}+\frac{\, _2F_1\left(1,\frac{1}{2} (-a+c+2);\frac{1}{2} (a+c+4);-e^{-2 b}\right)}{B\left(\frac{1}{2} (a+c+4),\frac{a-c}{2}\right)}\right)+\frac{1}{B\left(\frac{1}{2} (a+c+2),\frac{1}{2} (a-c+2)\right)}\right)}{a+1}$$ Which, after simplifications, should agree with @pisco's result (it passed my numeric verification so I won't simplify it further).","How to prove So far I've got no idea of tackling it (my intuition is on contour integration). I'd like you to give some suggestions. Thanks in advance! Update: I found an alternate proof for @pisco's general formula. By using Fourier expansion and trigonometric identities , one have Where denotes the classic Cauchy integral ( ) Performing the summation using definition of hypergeometric functions one have Which, after simplifications, should agree with @pisco's result (it passed my numeric verification so I won't simplify it further).","\int_0^{\pi/2} \frac{\cos ((1-a) x)\cos ^{1-a}(x)}{ (\cosh (2 b)-\cos (2 x))} \, dx=\frac{\pi  e^{(a-1)b}}{4\sinh (b) \cosh ^a(b)} \frac{\sinh (2 b)}{\cosh (2 b)-\cos (2 x)}=2 \sum _{k=1}^{\infty } e^{-2kb} \cos (2 k x)+1 \cos*\cos\to \cos+\cos \small I=\int_0^{\pi /2} {\frac{{{{(\cos x)}^a}\cos cx}}{{\cosh 2b - \cos 2x}}dx} =\frac{\sum _{k=1}^{\infty } \exp (-2 b k) (f(a+1,c+2 k)+f(a+1,c-2 k))+f(a+1,c)}{\sinh (2 b)} f \Re v>0 f(v,a)=\int_0^{\frac{\pi }{2}} \cos (a x) \cos ^{v-1}(x) \, dx=\frac{\pi }{2^v v B\left(\frac{1}{2} (a+v+1),\frac{1}{2} (-a+v+1)\right)} \small I=\frac{\pi  2^{-a-1} \text{csch}(2 b) \left(e^{-2 b} \left(\frac{\, _2F_1\left(1,\frac{1}{2} (-a-c+2);\frac{1}{2} (a-c+4);-e^{-2 b}\right)}{B\left(\frac{a+c}{2},\frac{1}{2} (a-c+4)\right)}+\frac{\, _2F_1\left(1,\frac{1}{2} (-a+c+2);\frac{1}{2} (a+c+4);-e^{-2 b}\right)}{B\left(\frac{1}{2} (a+c+4),\frac{a-c}{2}\right)}\right)+\frac{1}{B\left(\frac{1}{2} (a+c+2),\frac{1}{2} (a-c+2)\right)}\right)}{a+1}","['integration', 'complex-analysis', 'definite-integrals', 'fourier-analysis']"
47,Limit $\lim _{t\to 0 }\frac{ \int_0^{\infty} \frac{e^{-xt}}{\pi^2+(\log x)^2}dx }{ \int_0^{1/t}\frac{dx}{(\log x)^2}}$,Limit,\lim _{t\to 0 }\frac{ \int_0^{\infty} \frac{e^{-xt}}{\pi^2+(\log x)^2}dx }{ \int_0^{1/t}\frac{dx}{(\log x)^2}},"$$ \mbox{Prove}\qquad \lim _{t \to 0}{\displaystyle\int_{0}^{\infty}{\mathrm{e}^{-xt} \over \pi^{2} + \log^{2}\left(x\right)}\,\mathrm{d}x \over \displaystyle \int_{0}^{1/t}{\mathrm{d}x \over \ln^{2}\left(x\right)}} \qquad\mbox{tends to a finite limit.} $$ ( It might be the case that the limit is in fact $1$ , but I am not sure. ) I was not able to find any theorem regarding a situation in which both the range and function depends on $t$ . The Monotone Convergence theorems I have seen are the closest related, but they are either only for ""function independent of $t$ and range dependent on $t$ "" or ""function dependent on $t$ and range independent of $t$ "". Any help appreciated !.","( It might be the case that the limit is in fact , but I am not sure. ) I was not able to find any theorem regarding a situation in which both the range and function depends on . The Monotone Convergence theorems I have seen are the closest related, but they are either only for ""function independent of and range dependent on "" or ""function dependent on and range independent of "". Any help appreciated !.","
\mbox{Prove}\qquad
\lim _{t \to 0}{\displaystyle\int_{0}^{\infty}{\mathrm{e}^{-xt} \over
\pi^{2} + \log^{2}\left(x\right)}\,\mathrm{d}x
\over
\displaystyle
\int_{0}^{1/t}{\mathrm{d}x \over \ln^{2}\left(x\right)}}
\qquad\mbox{tends to a finite limit.}
 1 t t t t t","['integration', 'limits']"
48,Prove that $\int_1^a \frac{T_n(x) T_n(x/a)}{\sqrt{a^2 - x^2} \sqrt{x^2 - 1^2}} \frac{a}{x} \mathrm{d}x = \frac{\pi}{2}$,Prove that,\int_1^a \frac{T_n(x) T_n(x/a)}{\sqrt{a^2 - x^2} \sqrt{x^2 - 1^2}} \frac{a}{x} \mathrm{d}x = \frac{\pi}{2},"In the paper, Representation of a Function by Its Line Integrals, with Some Radiological Applications , A. M. Cormack, Journal of Applied Physics 34, 2722 (1963), an integral identity is expressed which can be reduced to: $$I_n(a) = \int_1^a \frac{T_n(x)  T_n(x/a)}{\sqrt{a^2 - x^2} \sqrt{x^2 - 1^2}}  \frac{a}{x} \mathrm{d}x = \frac{\pi}{2}$$ where $T_n(x)$ is the $n^\text{th}$ order Chebyshev polynomial of the first kind. I'm not quite sure where this result comes from, and was looking to see how it could be derived. The paper notes that it can be shown that $$I_{n+1} = I_{n-1}, \quad I_0 = I_1 = \frac{\pi}{2}$$ from which then it is apparent that $I_n(a) = \frac{\pi}{2}$ However, I'm not sure where the $I_{n+1} = I_{n-1}$ comes from. Attempting to substitute the recurrence relationship $$T_n(x) = \frac{T_{n-1}(x) + T_{n+1}(x)}{2x}$$ seemed like a good start, but ends up converting the integral to a form that's different from $I_{n-1}(a)$ and $I_{n+1}(a)$ , and also generates some unwanted cross terms. Could anyone suggest a push in the right direction?","In the paper, Representation of a Function by Its Line Integrals, with Some Radiological Applications , A. M. Cormack, Journal of Applied Physics 34, 2722 (1963), an integral identity is expressed which can be reduced to: where is the order Chebyshev polynomial of the first kind. I'm not quite sure where this result comes from, and was looking to see how it could be derived. The paper notes that it can be shown that from which then it is apparent that However, I'm not sure where the comes from. Attempting to substitute the recurrence relationship seemed like a good start, but ends up converting the integral to a form that's different from and , and also generates some unwanted cross terms. Could anyone suggest a push in the right direction?","I_n(a) = \int_1^a \frac{T_n(x)  T_n(x/a)}{\sqrt{a^2 - x^2} \sqrt{x^2 - 1^2}}  \frac{a}{x} \mathrm{d}x = \frac{\pi}{2} T_n(x) n^\text{th} I_{n+1} = I_{n-1}, \quad I_0 = I_1 = \frac{\pi}{2} I_n(a) = \frac{\pi}{2} I_{n+1} = I_{n-1} T_n(x) = \frac{T_{n-1}(x) + T_{n+1}(x)}{2x} I_{n-1}(a) I_{n+1}(a)","['integration', 'definite-integrals', 'proof-explanation', 'chebyshev-polynomials']"
49,Difficult Bessel integral,Difficult Bessel integral,,"In my research involving quantum field theory and computing correlation functions in perturbation theory, I encountered the following integral that seems pretty hard to solve: $$f(x)=\int_{0}^{\infty}\frac{dz}{z(z^2+1)}\text{arcsinh}^2(z)J_0(xz)$$ I wonder if anyone has any insights towards a solution. A series expansion and it's convergence properties would be fantastic as well.","In my research involving quantum field theory and computing correlation functions in perturbation theory, I encountered the following integral that seems pretty hard to solve: I wonder if anyone has any insights towards a solution. A series expansion and it's convergence properties would be fantastic as well.",f(x)=\int_{0}^{\infty}\frac{dz}{z(z^2+1)}\text{arcsinh}^2(z)J_0(xz),"['integration', 'improper-integrals', 'mathematical-physics', 'contour-integration']"
50,How to evaluate $\int_0^y\frac{\ln x\ln^2(1-x)}{x}dx$,How to evaluate,\int_0^y\frac{\ln x\ln^2(1-x)}{x}dx,"How to find $$\int_0^y\frac{\ln x\ln^2(1-x)}{x}dx\ ?$$ I came across this integral while I was trying to find $\displaystyle \sum_{n=1}^\infty\frac{H_n}{n^3}x^n$ and here is my work, Divide the identity $$\sum_{n=1}^\infty\frac{H_{n}}{n^2}x^{n}=\operatorname{Li}_3(x)+\zeta(3)-\operatorname{Li}_3(1-x)+\ln(1-x)\operatorname{Li}_2(1-x)+\frac12\ln x\ln^2(1-x)$$ by $x$ then integrate from $x=0$ to $x=y $ we get $$\small{\color{red}{\sum_{n=1}^\infty\frac{H_{n}}{n^3}y^{n}}=\operatorname{Li}_4(y)+\underbrace{\int_0^y\frac{\zeta(3)-\operatorname{Li}_3(1-x)}{x}dx}_{A}+\underbrace{\int_0^y\frac{\ln(1-x)\operatorname{Li}_2(1-x)}{x}dx}_{B}+\underbrace{\frac12\int_0^y\frac{\ln x\ln^2(1-x)}{x}dx}_{C}}$$ For the integral $A$ , integrate by parts $$A=\ln y\zeta(3)-\ln y\operatorname{Li}_3(1-y)-\int_0^y\frac{\ln x\operatorname{Li}_2(1-x)}{1-x}dx$$ $$=\ln y\zeta(3)-\ln y\operatorname{Li}_3(1-y)-\frac12\operatorname{Li}_2^2(1-x)|_0^y$$ $$=\ln y\zeta(3)-\ln y\operatorname{Li}_3(1-y)-\frac12\operatorname{Li}_2^2(1-y)+\frac54\zeta(4)$$ Integrate by parts for $B$ too $$B=\operatorname{Li}_2(y)\operatorname{Li}_2(1-y)+\int_0^y\frac{\ln x\operatorname{Li}_2(x)}{1-x}dx$$ $$=\operatorname{Li}_2(y)\operatorname{Li}_2(1-y)+\sum_{n=1}^\infty \left(H_n^{(2)}-\frac1{n^2}\right)\int_0^y x^{n-1}\ln x\ dx$$ $$=\operatorname{Li}_2(y)\operatorname{Li}_2(1-y)+\sum_{n=1}^\infty \left(H_n^{(2)}-\frac1{n^2}\right)\left(\ln y\frac{y^n}{n}-\frac{y^n}{n^2}\right)$$ $$=\operatorname{Li}_2(y)\operatorname{Li}_2(1-y)-\ln y\operatorname{Li}_3(y)+\operatorname{Li}_4(y)+\ln y\sum_{n=1}^\infty\frac{H_n^{(2)}}{n}y^n-\sum_{n=1}^\infty\frac{H_n^{(2)}}{n^2}y^n$$ by Cauchy product we have $$\frac12\operatorname{Li}_2^2(y)=2\sum_{n=1}^\infty\frac{H_n}{n^3}y^n+\sum_{n=1}^\infty\frac{H_n^{(2)}}{n^2}y^n-3\operatorname{Li}_4(y)$$ which gives $$B=\operatorname{Li}_2(y)\operatorname{Li}_2(1-y)-\frac12\operatorname{Li}_2^2(y)-\ln y\operatorname{Li}_3(y)-2\operatorname{Li}_4(y)+\ln y\sum_{n=1}^\infty\frac{H_n^{(2)}}{n}y^n+2\color{red}{\sum_{n=1}^\infty\frac{H_n}{n^3}y^n}$$ For $C$ , if we use $$\frac12\ln^2(1-x)=\sum_{n=1}^\infty\left(\frac{H_n}{n}-\frac1{n^2}\right)x^n$$ we get $$C=\operatorname{Li}_4(y)-\ln y\operatorname{Li}_3(y)+\ln y\sum_{n=1}^\infty\frac{H_n}{n^2}y^n-\color{red}{\sum_{n=1}^\infty\frac{H_n} {n^3}y^n}$$ Now if we combine the results of $A$ , $B$ and $C$ , the red sum will cancel out from both sides and that's why I am trying to find a different way to evaluate $C$ or we can use the result of $C$ but we have to find a different way to evaluate $B$ . any idea? Thank you, By the way, mathematica gives","How to find I came across this integral while I was trying to find and here is my work, Divide the identity by then integrate from to we get For the integral , integrate by parts Integrate by parts for too by Cauchy product we have which gives For , if we use we get Now if we combine the results of , and , the red sum will cancel out from both sides and that's why I am trying to find a different way to evaluate or we can use the result of but we have to find a different way to evaluate . any idea? Thank you, By the way, mathematica gives","\int_0^y\frac{\ln x\ln^2(1-x)}{x}dx\ ? \displaystyle \sum_{n=1}^\infty\frac{H_n}{n^3}x^n \sum_{n=1}^\infty\frac{H_{n}}{n^2}x^{n}=\operatorname{Li}_3(x)+\zeta(3)-\operatorname{Li}_3(1-x)+\ln(1-x)\operatorname{Li}_2(1-x)+\frac12\ln x\ln^2(1-x) x x=0 x=y  \small{\color{red}{\sum_{n=1}^\infty\frac{H_{n}}{n^3}y^{n}}=\operatorname{Li}_4(y)+\underbrace{\int_0^y\frac{\zeta(3)-\operatorname{Li}_3(1-x)}{x}dx}_{A}+\underbrace{\int_0^y\frac{\ln(1-x)\operatorname{Li}_2(1-x)}{x}dx}_{B}+\underbrace{\frac12\int_0^y\frac{\ln x\ln^2(1-x)}{x}dx}_{C}} A A=\ln y\zeta(3)-\ln y\operatorname{Li}_3(1-y)-\int_0^y\frac{\ln x\operatorname{Li}_2(1-x)}{1-x}dx =\ln y\zeta(3)-\ln y\operatorname{Li}_3(1-y)-\frac12\operatorname{Li}_2^2(1-x)|_0^y =\ln y\zeta(3)-\ln y\operatorname{Li}_3(1-y)-\frac12\operatorname{Li}_2^2(1-y)+\frac54\zeta(4) B B=\operatorname{Li}_2(y)\operatorname{Li}_2(1-y)+\int_0^y\frac{\ln x\operatorname{Li}_2(x)}{1-x}dx =\operatorname{Li}_2(y)\operatorname{Li}_2(1-y)+\sum_{n=1}^\infty \left(H_n^{(2)}-\frac1{n^2}\right)\int_0^y x^{n-1}\ln x\ dx =\operatorname{Li}_2(y)\operatorname{Li}_2(1-y)+\sum_{n=1}^\infty \left(H_n^{(2)}-\frac1{n^2}\right)\left(\ln y\frac{y^n}{n}-\frac{y^n}{n^2}\right) =\operatorname{Li}_2(y)\operatorname{Li}_2(1-y)-\ln y\operatorname{Li}_3(y)+\operatorname{Li}_4(y)+\ln y\sum_{n=1}^\infty\frac{H_n^{(2)}}{n}y^n-\sum_{n=1}^\infty\frac{H_n^{(2)}}{n^2}y^n \frac12\operatorname{Li}_2^2(y)=2\sum_{n=1}^\infty\frac{H_n}{n^3}y^n+\sum_{n=1}^\infty\frac{H_n^{(2)}}{n^2}y^n-3\operatorname{Li}_4(y) B=\operatorname{Li}_2(y)\operatorname{Li}_2(1-y)-\frac12\operatorname{Li}_2^2(y)-\ln y\operatorname{Li}_3(y)-2\operatorname{Li}_4(y)+\ln y\sum_{n=1}^\infty\frac{H_n^{(2)}}{n}y^n+2\color{red}{\sum_{n=1}^\infty\frac{H_n}{n^3}y^n} C \frac12\ln^2(1-x)=\sum_{n=1}^\infty\left(\frac{H_n}{n}-\frac1{n^2}\right)x^n C=\operatorname{Li}_4(y)-\ln y\operatorname{Li}_3(y)+\ln y\sum_{n=1}^\infty\frac{H_n}{n^2}y^n-\color{red}{\sum_{n=1}^\infty\frac{H_n}
{n^3}y^n} A B C C C B","['integration', 'sequences-and-series', 'generating-functions', 'closed-form', 'harmonic-numbers']"
51,Limit of the ratio of two non-Riemann sums.,Limit of the ratio of two non-Riemann sums.,,"Let $\left[ {a,b} \right] \subset \mathbb{R}$ and $f,g:\left[ {a,b} \right] \to \mathbb{R}$ be two Riemann-integrable functions. Let $a = {x_0} < {x_1} < {x_2}... < {x_n} = b$ be a partition of $\left[ {a,b} \right]$ and let $\Delta x = \mathop {\max }\limits_{i = 0}^{n - 1} \left( {{x_{i + 1}} - {x_i}} \right)$ . Let ${t_i} \in \left[ {{x_i},{x_{i + 1}}} \right],\;i = 0,n - 1$ and let $k \in {\mathbb{N}^*}$ . I’d like to prove that $\mathop {\lim }\limits_{\Delta x \to 0} \frac{{\sum\limits_{i = 0}^{n - 1} {{{\left( {{x_{i + 1}} - {x_i}} \right)}^k}f\left( {{t_i}} \right)} }}{{\sum\limits_{i = 0}^{n - 1} {{{\left( {{x_{i + 1}} - {x_i}} \right)}^k}g\left( {{t_i}} \right)} }} = \frac{{\int\limits_a^b {f\left( x \right){\text{d}}x} }}{{\int\limits_a^b {g\left( x \right){\text{d}}x} }}$ It is obvious for equally spaced partitions ${x_{i + 1}} - {x_i} \equiv \Delta x$ $\mathop {\lim }\limits_{\Delta x \to 0} \frac{{\sum\limits_{i = 0}^{n - 1} {\Delta {x^k}f\left( {{t_i}} \right)} }}{{\sum\limits_{i = 0}^{n - 1} {\Delta {x^k}g\left( {{t_i}} \right)} }} = \mathop {\lim }\limits_{\Delta x \to 0} \frac{{\sum\limits_{i = 0}^{n - 1} {\Delta xf\left( {{t_i}} \right)} }}{{\sum\limits_{i = 0}^{n - 1} {\Delta xg\left( {{t_i}} \right)} }} = \frac{{\int\limits_a^b {f\left( x \right){\text{d}}x} }}{{\int\limits_a^b {g\left( x \right){\text{d}}x} }}$ But I don’t see how to do it in the general case?",Let and be two Riemann-integrable functions. Let be a partition of and let . Let and let . I’d like to prove that It is obvious for equally spaced partitions But I don’t see how to do it in the general case?,"\left[ {a,b} \right] \subset \mathbb{R} f,g:\left[ {a,b} \right] \to \mathbb{R} a = {x_0} < {x_1} < {x_2}... < {x_n} = b \left[ {a,b} \right] \Delta x = \mathop {\max }\limits_{i = 0}^{n - 1} \left( {{x_{i + 1}} - {x_i}} \right) {t_i} \in \left[ {{x_i},{x_{i + 1}}} \right],\;i = 0,n - 1 k \in {\mathbb{N}^*} \mathop {\lim }\limits_{\Delta x \to 0} \frac{{\sum\limits_{i = 0}^{n - 1} {{{\left( {{x_{i + 1}} - {x_i}} \right)}^k}f\left( {{t_i}} \right)} }}{{\sum\limits_{i = 0}^{n - 1} {{{\left( {{x_{i + 1}} - {x_i}} \right)}^k}g\left( {{t_i}} \right)} }} = \frac{{\int\limits_a^b {f\left( x \right){\text{d}}x} }}{{\int\limits_a^b {g\left( x \right){\text{d}}x} }} {x_{i + 1}} - {x_i} \equiv \Delta x \mathop {\lim }\limits_{\Delta x \to 0} \frac{{\sum\limits_{i = 0}^{n - 1} {\Delta {x^k}f\left( {{t_i}} \right)} }}{{\sum\limits_{i = 0}^{n - 1} {\Delta {x^k}g\left( {{t_i}} \right)} }} = \mathop {\lim }\limits_{\Delta x \to 0} \frac{{\sum\limits_{i = 0}^{n - 1} {\Delta xf\left( {{t_i}} \right)} }}{{\sum\limits_{i = 0}^{n - 1} {\Delta xg\left( {{t_i}} \right)} }} = \frac{{\int\limits_a^b {f\left( x \right){\text{d}}x} }}{{\int\limits_a^b {g\left( x \right){\text{d}}x} }}","['integration', 'riemann-sum', 'partitions-for-integration']"
52,Gamma-Distribution-like integral,Gamma-Distribution-like integral,,"I have numerically checked this result and although it doesn't hold to a significant number of decimal places I believe this result is true: $$\Large \int_0^\infty \frac{x^x e^{-x}}{\Gamma(x+2)}\text{d}x = 1$$ This only vaguely resembles a Gamma Distribution, so I do not see how to explain it using distributions. I would imagine complex analysis is the way to go with such an integral but I have no idea where to even begin. I tried using Stirling's (Convergent) Approximation but given how complicated the product expansion is in terms of exponentiated inverted rising factorials, I don't think that is a very nice method.","I have numerically checked this result and although it doesn't hold to a significant number of decimal places I believe this result is true: This only vaguely resembles a Gamma Distribution, so I do not see how to explain it using distributions. I would imagine complex analysis is the way to go with such an integral but I have no idea where to even begin. I tried using Stirling's (Convergent) Approximation but given how complicated the product expansion is in terms of exponentiated inverted rising factorials, I don't think that is a very nice method.",\Large \int_0^\infty \frac{x^x e^{-x}}{\Gamma(x+2)}\text{d}x = 1,"['integration', 'improper-integrals', 'gamma-function', 'complex-integration']"
53,Evaluate $\int_0^1 \frac{\log ^2(x+1) \log \left(x^2+1\right)}{x^2+1} dx$,Evaluate,\int_0^1 \frac{\log ^2(x+1) \log \left(x^2+1\right)}{x^2+1} dx,How can we evaluate $$\int_0^1 \frac{\log ^2(x+1) \log \left(x^2+1\right)}{x^2+1}  dx$$ Any kind of help is appreciated.,How can we evaluate Any kind of help is appreciated.,\int_0^1 \frac{\log ^2(x+1) \log \left(x^2+1\right)}{x^2+1}  dx,"['integration', 'definite-integrals', 'logarithms']"
54,Integration over parametrizations in the border of a manifold with corners (John M. Lee Introduction to Smooth Manifolds exercise 16.22),Integration over parametrizations in the border of a manifold with corners (John M. Lee Introduction to Smooth Manifolds exercise 16.22),,"In exercise $16.22$ of Lee's Introduction to Smooth Manifolds , the author wants us to translate the result of proposition $16.8$ , the integration over parametrizations, to the border of a manifold with corners. I think the precise statement is the following one: Let $\partial M$ be the border a compact, oriented smooth $(n+1)-$ manifold with corners $M$ , and let $\omega$ be a compactly supported $n-$ form on $\partial M$ . Suppose $D_1,\dots,D_k$ are open domains of integration in $\mathbb{R}^n$ (this means that each $D_i$ is bounded and its (topological) boundary $\partial D_i$ has measure zero as a subset of $\mathbb{R}^n$ ), and for $i=1,\dots,k$ we are given smooth maps $F_i:\bar D_i\rightarrow\partial M$ satisfying: $(i)\;F_i$ restricts to an orientation-preserving diffeomorphism from $D_i$ onto an open subset $W_i\subseteq \partial M$ ; $(ii)\;W_i\cap W_j=\varnothing$ when $i\not=j$ ; $(iii)\;\text{supp }\omega\subseteq\bar W_1\cup\dots\cup\bar W_k$ . Then $$\int_{\partial M}\omega=\sum_{i=1}^k\int_{D_i} F_i^*\omega$$ However, I don't understand the following points: First $-$ why is $M$ required to be compact, while the statement of proposition $16.8$ doesn't require the manifolds in question to be compact? Second $-$ is my restatement of $16.8$ complete? I feel like something is missing, but I am not sure. After seeing an application of this result in the demonstration of Stokes' Theorem for chains, I can't help thinking that what I have written is good enough Third $-$ is there any point in the proof of $16.8$ where any step has to be completely rewritten? After reading the proof several times, I feel like there is nothing wrong with it when we change the sets and maps to adapt this demonstration to the case we are studying. However, there must be some technical detail I am not seeing at all. Thanks for your interest. PS1 : First point is somewhat obvious, since one can construct spaces where no finite decomposition $D_1,\dots,D_k$ and maps $F_i:\bar D_i\rightarrow \partial M$ exists (for instance, think of $M$ as a ""snake"" made of solid parallelepipeds that extends indefinitely across $\mathbb{R}^3$ ) PS2 : Needless to say, the sets $W_i$ cover the whole space $\partial M$ with the exception of some subset of measure zero in $\partial M$","In exercise of Lee's Introduction to Smooth Manifolds , the author wants us to translate the result of proposition , the integration over parametrizations, to the border of a manifold with corners. I think the precise statement is the following one: Let be the border a compact, oriented smooth manifold with corners , and let be a compactly supported form on . Suppose are open domains of integration in (this means that each is bounded and its (topological) boundary has measure zero as a subset of ), and for we are given smooth maps satisfying: restricts to an orientation-preserving diffeomorphism from onto an open subset ; when ; . Then However, I don't understand the following points: First why is required to be compact, while the statement of proposition doesn't require the manifolds in question to be compact? Second is my restatement of complete? I feel like something is missing, but I am not sure. After seeing an application of this result in the demonstration of Stokes' Theorem for chains, I can't help thinking that what I have written is good enough Third is there any point in the proof of where any step has to be completely rewritten? After reading the proof several times, I feel like there is nothing wrong with it when we change the sets and maps to adapt this demonstration to the case we are studying. However, there must be some technical detail I am not seeing at all. Thanks for your interest. PS1 : First point is somewhat obvious, since one can construct spaces where no finite decomposition and maps exists (for instance, think of as a ""snake"" made of solid parallelepipeds that extends indefinitely across ) PS2 : Needless to say, the sets cover the whole space with the exception of some subset of measure zero in","16.22 16.8 \partial M (n+1)- M \omega n- \partial M D_1,\dots,D_k \mathbb{R}^n D_i \partial D_i \mathbb{R}^n i=1,\dots,k F_i:\bar D_i\rightarrow\partial M (i)\;F_i D_i W_i\subseteq \partial M (ii)\;W_i\cap W_j=\varnothing i\not=j (iii)\;\text{supp }\omega\subseteq\bar W_1\cup\dots\cup\bar W_k \int_{\partial M}\omega=\sum_{i=1}^k\int_{D_i} F_i^*\omega - M 16.8 - 16.8 - 16.8 D_1,\dots,D_k F_i:\bar D_i\rightarrow \partial M M \mathbb{R}^3 W_i \partial M \partial M","['integration', 'differential-geometry', 'differential-topology', 'smooth-manifolds']"
55,Antiderivative of $(1+x^3)^{-1/3}$.,Antiderivative of .,(1+x^3)^{-1/3},"I tried multiple substitutions while trying to solve for: $$ \int\frac{{\rm d}x}{(1+x^3)^{\frac{1}{3}}} $$ According to some online sources it is non-elementary, although the question was taken from a book that says otherwise. Any ideas? Closest I got was using $$u=\frac{1}{x(1+x^3)^{1/3}}$$ but it didn't work.","I tried multiple substitutions while trying to solve for: According to some online sources it is non-elementary, although the question was taken from a book that says otherwise. Any ideas? Closest I got was using but it didn't work.","
\int\frac{{\rm d}x}{(1+x^3)^{\frac{1}{3}}}
 u=\frac{1}{x(1+x^3)^{1/3}}","['integration', 'substitution']"
56,The average radius of an ellipse [closed],The average radius of an ellipse [closed],,Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 5 years ago . Improve this question I have recently been studying the 3rd Kepler´s law which uses the average radius of an orbit. I would love to know how to find the geometric average radius of an ellipse. Would you please show me or at least help me with the process of integration?,Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 5 years ago . Improve this question I have recently been studying the 3rd Kepler´s law which uses the average radius of an orbit. I would love to know how to find the geometric average radius of an ellipse. Would you please show me or at least help me with the process of integration?,,"['integration', 'geometry']"
57,"closed form for $\int_{1/4}^{3/4} x^n(1-x)^n \, dx$",closed form for,"\int_{1/4}^{3/4} x^n(1-x)^n \, dx","The integrand being a polynomial, I used the binomial formula to separate the monomials: $$\int_{\frac{1}{4}}^{\frac{3}{4}} x^n(1-x)^n \, dx = \sum_{k = 0}^{n}{ n \choose k}(-1)^{k}\int_{\frac{1}{4}}^{\frac{3}{4}} x^{n+k} \, dx = \sum_{k = 0}^{n}{ n \choose k}(-1)^{k}\left[\frac{(\frac{3}{4})^{n+k+1}-(\frac{1}{4})^{n+k+1}}{n+k+1}\right]. $$ I'm looking to get a closed form of the following sum or at least make it 'nicer' in terms of looks: $$f(a) =\sum_{k = 0}^{n}{ n \choose k}(-1)^{k}\frac{a^{n+k+1}}{n+k+1},\,\, 0<a < 1.$$ We have $$f'(a) =\sum_{k = 0}^{n}{ n \choose k}(-1)^{k}a^{n+k} $$ Then : $$f'(a) =a^n(-1)^n\sum_{k = 0}^{n}{ n \choose k}(-1)^{n-k}a^{k} = a^n(-1)^{n}(a-1)^n = a^n(1-a)^n $$ so we are back to square one. Past this circular simplification, I thought of integrating but that will just make the formula much messier. Maybe there's another approach? Edit 1: My main goal is to get a closed form of the integral, so if $\frac14$ and $\frac34$ give some cancellations, it would be great if someone pointed them out. Edit 2: the original problem : let $(X_1,\cdots,X_{2n+1})$ be a $2n+1$ sample of independant, identically distributed random variables that are uniformly distributed over $[0,1]$ -Find the probability that the median $\in [\frac14,\frac34]$ . Edit 3: using @JamesArathoon Observation $$\begin{align}I_n & =\int_0^1 x^n (1-x)^n \, dx-2\int_0^{\frac{1}{4}} x^n (1-x)^n \, dx = B(n+1,n+1) - 2B(\frac14;n+1,n+1) \end{align}$$ where first special function is the beta function and second one is the incomplete beta. $$\begin{align}I_n & = B(n+1,n+1) - 2B(\frac14;n+1,n+1) = \frac{\Gamma^2(n+1)}{\Gamma(2n+2)} -\frac{2}{4^{n+1}n+1}{_{2}}F_{1}(n+1,-n,n+2,\frac{1}{4}) \\ &=\frac{(n^2)!}{(2n+1)!} -\frac{2}{4^{n+1}n+1} {_{2}}F_{1}(n+1,-n,n+2,\frac{1}{4}) \end{align}$$ because one of the arguments of the hypergeomtric function is negative then the series terminates and is given by $$\begin{align}{_{2}}F_{1}(n+1,-n,n+2,\frac{1}{4}) &=  \sum_{k=0}^{n} (-1)^k \binom{n}{k} \frac{(n+1)_k}{4^k(n+2)_k}   \\ &= 1 + \sum_{k=1}^{n} (-1)^k \frac{n!}{k!(n-k)!} \frac{(n+1)(n+2)\cdots(n+k)}{4^k(n+2)(n+3)\cdots(n+k+1)} \\ &=1 + \sum_{k=1}^{n} (-1)^k \frac{n!}{k!(n-k)!} \frac{(n+1)}{4^k(n+k+1)} \\ \end{align}$$ now that looks like it's got the potential to be turned into a binomial formula with $a = -1, b = \frac14$ but I still can't see it Thanks in advance!","The integrand being a polynomial, I used the binomial formula to separate the monomials: I'm looking to get a closed form of the following sum or at least make it 'nicer' in terms of looks: We have Then : so we are back to square one. Past this circular simplification, I thought of integrating but that will just make the formula much messier. Maybe there's another approach? Edit 1: My main goal is to get a closed form of the integral, so if and give some cancellations, it would be great if someone pointed them out. Edit 2: the original problem : let be a sample of independant, identically distributed random variables that are uniformly distributed over -Find the probability that the median . Edit 3: using @JamesArathoon Observation where first special function is the beta function and second one is the incomplete beta. because one of the arguments of the hypergeomtric function is negative then the series terminates and is given by now that looks like it's got the potential to be turned into a binomial formula with but I still can't see it Thanks in advance!","\int_{\frac{1}{4}}^{\frac{3}{4}} x^n(1-x)^n \, dx = \sum_{k = 0}^{n}{ n \choose k}(-1)^{k}\int_{\frac{1}{4}}^{\frac{3}{4}} x^{n+k} \, dx = \sum_{k = 0}^{n}{ n \choose k}(-1)^{k}\left[\frac{(\frac{3}{4})^{n+k+1}-(\frac{1}{4})^{n+k+1}}{n+k+1}\right].  f(a) =\sum_{k = 0}^{n}{ n \choose k}(-1)^{k}\frac{a^{n+k+1}}{n+k+1},\,\, 0<a < 1. f'(a) =\sum_{k = 0}^{n}{ n \choose k}(-1)^{k}a^{n+k}  f'(a) =a^n(-1)^n\sum_{k = 0}^{n}{ n \choose k}(-1)^{n-k}a^{k} = a^n(-1)^{n}(a-1)^n = a^n(1-a)^n  \frac14 \frac34 (X_1,\cdots,X_{2n+1}) 2n+1 [0,1] \in [\frac14,\frac34] \begin{align}I_n & =\int_0^1 x^n (1-x)^n \, dx-2\int_0^{\frac{1}{4}} x^n (1-x)^n \, dx = B(n+1,n+1) - 2B(\frac14;n+1,n+1)
\end{align} \begin{align}I_n & = B(n+1,n+1) - 2B(\frac14;n+1,n+1) = \frac{\Gamma^2(n+1)}{\Gamma(2n+2)} -\frac{2}{4^{n+1}n+1}{_{2}}F_{1}(n+1,-n,n+2,\frac{1}{4}) \\
&=\frac{(n^2)!}{(2n+1)!} -\frac{2}{4^{n+1}n+1} {_{2}}F_{1}(n+1,-n,n+2,\frac{1}{4})
\end{align} \begin{align}{_{2}}F_{1}(n+1,-n,n+2,\frac{1}{4}) &=  \sum_{k=0}^{n} (-1)^k \binom{n}{k} \frac{(n+1)_k}{4^k(n+2)_k}   \\
&= 1 + \sum_{k=1}^{n} (-1)^k \frac{n!}{k!(n-k)!} \frac{(n+1)(n+2)\cdots(n+k)}{4^k(n+2)(n+3)\cdots(n+k+1)} \\
&=1 + \sum_{k=1}^{n} (-1)^k \frac{n!}{k!(n-k)!} \frac{(n+1)}{4^k(n+k+1)} \\
\end{align} a = -1, b = \frac14","['integration', 'sequences-and-series', 'definite-integrals', 'summation', 'closed-form']"
58,Seeking methods to solve: $\int_0^\infty \frac{\ln(t)}{t^n + 1}\:dt$,Seeking methods to solve:,\int_0^\infty \frac{\ln(t)}{t^n + 1}\:dt,"Seeking Methods to solve the following two definite integrals: \begin{equation} I_(n) = \int_0^\infty \frac{\ln(t)}{t^n + 1}\:dt \qquad J(n) = \int_0^\infty \frac{\ln^2(t)}{t^n + 1}\:dt \end{equation} For $n \in \mathbb{R},\:n \gt 1$ The method I took was to take the following integral: \begin{equation}  \int_0^\infty \frac{t^k}{\left(t^n + 1\right)^m}\:dt = \frac{1}{n}B\left(m - \frac{k + 1}{n}, \frac{k + 1}{n} \right) \end{equation} Where: $0 \leq k \lt n$ . Here let $m = 1$ . Differentiate under the curve with respect to $k$ and taking the limit as $k \rightarrow 0^+$ (via the Dominated Convergence Theorem ), i.e. \begin{align} \lim_{k \rightarrow 0+} \frac{d}{dk} \left[ \int_0^\infty \frac{t^k}{t^n + 1}\:dt \right] &= \lim_{k \rightarrow 0+} \frac{d}{dk} \left[\frac{1}{n}B\left(1 - \frac{k + 1}{n}, \frac{k + 1}{n} \right) \right] \\ \lim_{k \rightarrow 0+}  \int_0^\infty \frac{t^k \ln(t)}{t^n + 1}\:dt  &= \lim_{k \rightarrow 0+}  \left[\frac{1}{n^2} B\left(1 - \frac{k + 1}{n}, \frac{k + 1}{n}\right)\left[\psi^{(0)}\left(\frac{k + 1}{n} \right) - \psi^{(0)}\left(1 - \frac{k + 1}{n} \right)\right] \right] \\ \int_0^\infty \frac{\ln(t)}{t^n + 1}\:dt&= \frac{1}{n^2} B\left(1 - \frac{1}{n}, \frac{1}{n}\right)\left[\psi^{(0)}\left(\frac{1}{n} \right) - \psi^{(0)}\left(1 - \frac{1}{n} \right)\right] \\ &=- \frac{\pi^2}{n^2}\operatorname{cosec}\left(\frac{\pi}{n}\right)\cot\left(\frac{\pi}{n} \right) \end{align} Which is our expression for $I_n$ . Taking the same approach but differentiating twice with respect to $k$ we arrive at our expression for $J_n$ : \begin{equation}  J(n) = \int_0^\infty \frac{\ln^2(t)}{t^n + 1}\:dt = \frac{\pi^3}{n^3}\operatorname{cosec}\left(\frac{\pi}{n} \right)\left[\operatorname{cosec}^2\left(\frac{\pi}{n}\right) + \cot^2\left(\frac{\pi}{n}\right) \right] \end{equation} And in fact we may generalise: \begin{equation}     \int_0^\infty \frac{\ln^p(t)}{\left(t^n + 1\right)^m}\:dt = \lim_{k\rightarrow 0}\frac{d^p}{dk^p}\left[\frac{1}{n} B\left(m - \frac{k + 1}{n}, \frac{k + 1}{n}\right)\right] \end{equation} Where $p \in \mathbb{N}$ This method however was just an extension of another integral. I'm curious, if I had just started with $I_n, J_n$ what alternative methods could be used?","Seeking Methods to solve the following two definite integrals: For The method I took was to take the following integral: Where: . Here let . Differentiate under the curve with respect to and taking the limit as (via the Dominated Convergence Theorem ), i.e. Which is our expression for . Taking the same approach but differentiating twice with respect to we arrive at our expression for : And in fact we may generalise: Where This method however was just an extension of another integral. I'm curious, if I had just started with what alternative methods could be used?","\begin{equation}
I_(n) = \int_0^\infty \frac{\ln(t)}{t^n + 1}\:dt \qquad J(n) = \int_0^\infty \frac{\ln^2(t)}{t^n + 1}\:dt
\end{equation} n \in \mathbb{R},\:n \gt 1 \begin{equation}
 \int_0^\infty \frac{t^k}{\left(t^n + 1\right)^m}\:dt = \frac{1}{n}B\left(m - \frac{k + 1}{n}, \frac{k + 1}{n} \right)
\end{equation} 0 \leq k \lt n m = 1 k k \rightarrow 0^+ \begin{align}
\lim_{k \rightarrow 0+} \frac{d}{dk} \left[ \int_0^\infty \frac{t^k}{t^n + 1}\:dt \right] &= \lim_{k \rightarrow 0+} \frac{d}{dk} \left[\frac{1}{n}B\left(1 - \frac{k + 1}{n}, \frac{k + 1}{n} \right) \right] \\
\lim_{k \rightarrow 0+}  \int_0^\infty \frac{t^k \ln(t)}{t^n + 1}\:dt  &= \lim_{k \rightarrow 0+}  \left[\frac{1}{n^2} B\left(1 - \frac{k + 1}{n}, \frac{k + 1}{n}\right)\left[\psi^{(0)}\left(\frac{k + 1}{n} \right) - \psi^{(0)}\left(1 - \frac{k + 1}{n} \right)\right] \right] \\
\int_0^\infty \frac{\ln(t)}{t^n + 1}\:dt&= \frac{1}{n^2} B\left(1 - \frac{1}{n}, \frac{1}{n}\right)\left[\psi^{(0)}\left(\frac{1}{n} \right) - \psi^{(0)}\left(1 - \frac{1}{n} \right)\right] \\
&=- \frac{\pi^2}{n^2}\operatorname{cosec}\left(\frac{\pi}{n}\right)\cot\left(\frac{\pi}{n} \right)
\end{align} I_n k J_n \begin{equation}
 J(n) = \int_0^\infty \frac{\ln^2(t)}{t^n + 1}\:dt = \frac{\pi^3}{n^3}\operatorname{cosec}\left(\frac{\pi}{n} \right)\left[\operatorname{cosec}^2\left(\frac{\pi}{n}\right) + \cot^2\left(\frac{\pi}{n}\right) \right]
\end{equation} \begin{equation}
    \int_0^\infty \frac{\ln^p(t)}{\left(t^n + 1\right)^m}\:dt = \lim_{k\rightarrow 0}\frac{d^p}{dk^p}\left[\frac{1}{n} B\left(m - \frac{k + 1}{n}, \frac{k + 1}{n}\right)\right]
\end{equation} p \in \mathbb{N} I_n, J_n","['integration', 'limits']"
59,Evaluating $\int_{0}^{\infty} \frac{1}{a_{n}x^{n} + ... + a_{2}x^{2} + a_{o}}dx$ via Residue Theory?,Evaluating  via Residue Theory?,\int_{0}^{\infty} \frac{1}{a_{n}x^{n} + ... + a_{2}x^{2} + a_{o}}dx,"In the text ""Functions of a Complex Variable"" by Robert E. Greene and Steven G.Krantz I'm having trouble verifying my solution to $\text{Problem (1)}$ $\text{Problem (1)}$ Using Calculus of Residue evaluate the following $$\int_{0}^{\infty} \frac{1}{a_{n}x^{n} + ... + a_{2}x^{2} + a_{o}}dx \, \, \, $$ $\text{Remark}$ $p(x)$ is any polynomial with no zero's on the nonnegative real axis $\text{Solution}$ For $(1)$ real variable methods would be fruitless we have to take the, $$\oint_{\eta_{R}} \frac{\log(z)}{a_{n}z^{n} + ... + a_{2}z^{2} + a_{o}}dz.$$ For our choice $f$ , we initially let $$\, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \eta_{R}^{1}(t)  =  t + i/\sqrt{2R},  \, \, \, \,   1/\sqrt{2R} \leq t \leq R,$$ $$\eta_{R}^{2}(t)= Re^{it}, \, \, \, \,  \theta_{0} \leq t \leq 2 \pi - \theta_{0},$$ where $\theta_{0} = \theta_{0}(R) = \sin^{-1}(1/(R \sqrt{2R}))$ $$\, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \eta_{R}^{3}(t)  =  R -t -i/\sqrt{2R},  \, \, \, \, 0 \leq t \leq R-1/\sqrt{2R}.$$ $$\eta_{R}^{4}(t)  =  e^{it}/\sqrt{R}, \, \, \, \, \,  \, \, \, \, \, \, \, \, \, \, \, \, \, \pi/4 \leq t \leq 7 \pi /4.$$ It's important to consider that, $$\oint_{\eta_{R}} \frac{\log(z)}{a_{n}z^{n} + ... + a_{2}z^{2} + a_{o}}dz = 2 \pi i \bigg( \sum_{j} \operatorname{Ind_{\eta_{R}}}(P_{j}) \cdot \operatorname{Res_{\eta_{R}}}(P_{j}) \bigg) $$ Clearly our choice of $f$ has a pole of the order of $P$ and a pole of the order $n$ . Clearly, \begin{align*}  \operatorname{Res_{f}(P)} &=  \frac{1}{(n-1)!} \bigg( \partial_{z} \bigg)^{n-1} \bigg( (z-n)^{n} \frac{\log(z)}{a_{n}z^{n} + ... + a_{2}z^{2} + a_{o}}\bigg) \bigg|_{z=P}\\  \, \, \,  &=  \frac{1}{(n)!} \bigg( \partial_{z} \frac{\log(z)}{a_{n}x^{n} + ... + a_{n}z^{2} + a_{o}}\bigg|_{z = P} \bigg) \\  &= \frac{1}{(n!)}\frac{\log(z) - a_{n}z^{n} + ... + a_{2}P^{2} + a_{o}}{(\log(x)^{2})}\\   &= \frac{1}{(n!)}\frac{\log(P) - a_{n}P^{n} + ... + a_{2}P^{2} + a_{o}}{(\log(P)^{2})}. \end{align*} Putting the pieces together, $(*)$ $$\oint_{\eta_{R}} \frac{\log(z)}{a_{n}z^{n} + ... + a_{2}z^{2} + a_{o}}dz  = 2 \pi i \bigg(  \frac{1}{(n!)}\frac{\log(P) - a_{n}P^{n} + ... + a_{2}P^{2} + a_{o}}{(\log(P)^{2})} \bigg) \cdot 1$$ Applying the  Residue Theorem unfortunately isn't enough to finish our game so it becomes imperative to claim that $(**)$ $$ \Bigg| \lim_{R \rightarrow \infty}\oint_{\eta^{2}_{R}} f(z)dz \Bigg| \rightarrow 0 $$ and that, $(***)$ $$ \Bigg| \lim_{R \rightarrow \infty}\oint_{\eta^{4}_{R}} f(z)dz\Bigg| \rightarrow 0.$$ A particular device used to justify convergence over $\eta_{4}$ and $\eta_{2}$ is the fact that $$\bigg(\log \bigg( \frac{x + i \sqrt{2R}}{(x-i/\sqrt{2R}} \bigg) \bigg)\rightarrow -2 \pi i \text{.}$$ We will return to this particular device after dealing with our analysis of convergence over $\eta_{4}$ and $\eta_{2}$ . First we take that, $$\sum_{\psi}^{4} \bigg(\oint_{\eta_{R}^{\psi}} \frac{\log(z)}{a_{n}z^{n} + ... + a_{2}z^{2} + a_{o}}dz \bigg). $$ Now over $\eta_{2}$ one can see that, \begin{align*} \bigg| \oint_{\eta_{R}^{2}}\frac{\log(z)}{a_{n}z^{n} + ... + a_{2}z^{2} + a_{o}}dz\bigg|& = \bigg| \int_{-R}^{+Ri} \frac{\log(Re^{it})}{a_{n}(Re^{it})^{n} + ... + a_{2}(Re^{it})^{2} + a_{o}} iRe^{i \theta} d \theta\bigg|\\&=  \int_{-R}^{+Ri} \bigg|\frac{\log(Re^{it})}{{a_{n}(Re^{it})^{n} + ... + a_{2}(Re^{it})^{2} + a_{o}}} \bigg| \big| iRe^{i \theta} d \theta \big|\\&= \int_{-R}^{+Ri} \frac{\bigg|\log(Re^{it}) \bigg|}{\bigg| {a_{n}(Re^{it})^{n} + ... + a_{2}(Re^{it})^{2} + a_{o}} \bigg|}  \bigg|iRe^{i \theta} \bigg| d \theta  \bigg| \\& = \int_{\theta_{0}}^{2 \pi - \theta_{0}} \frac{\bigg|\log(Re^{it}) \bigg|}{\bigg|{a_{n}(Re^{it})^{n} + ... + a_{2}(Re^{it})^{2} + a_{o}} \bigg|}  \bigg|iRe^{i \theta} \bigg| \bigg|d \theta  \bigg|. \end{align*} Now we can establish a precise estimate for $\eta_{2}$ $$\bigg| \oint_{\eta_{R}^{2}} \frac{\log(z)}{a_{n}z^{n} + ... + a_{2}z^{2} + a_{o}}dz\bigg| \leq  \frac{\ln(R) + \pi }{R^{n} - a_{o}} \pi R \, \, \text{as} \, \, \, R \rightarrow \infty.$$ A similar process for $\eta_{4}$ says that, \begin{align*} \bigg| \oint_{\eta_{R}^{4}} \frac{\log(e^{it}/\sqrt{R})}{{a_{n}z^{n} + ... + a_{2}z^{2} + a_{o}}}  dz\bigg|& =  \oint_{\eta_{R}^{4}} \bigg| \frac{\log(e^{it}/\sqrt{R})}{{a_{n}(e^{it}/\sqrt{R})^{n} + ... + a_{2}(e^{it}/ \sqrt{R})^{2} + a_{o}}}  iRe^{i \theta} d \theta\bigg|\\&= \oint_{\eta_{R}^{4}}  \frac{\bigg|\log(e^{it}/\sqrt{R}) \bigg|}{\bigg|a_{n}(e^{it}/\sqrt{R})^{n} + ... + a_{2}(e^{it}/ \sqrt{R})^{2} + a_{o} \bigg|}  iRe^{i \theta} d \theta \\&= \oint_{\eta_{R}^{4}}  \frac{\bigg| \log(e^{it})- \frac{1}{2}\log(R^{}) \bigg|}{ \bigg|a_{n}(e^{it}/\sqrt{R})^{n} + ... + a_{2}(e^{it}/ \sqrt{R})^{2} + a_{o} \bigg|} \bigg|  iRe^{i \theta} d \theta \bigg|\\& =\oint_{\frac{\pi}{4}}^{\frac{7 \pi}{4}}  \frac{\bigg| it\log(e^{})- \frac{1}{2}\log(R^{}) \bigg|}{ \bigg|a_{n}(e^{it}/\sqrt{R})^{n} + ... + a_{2}(e^{it}/ \sqrt{R})^{2} + a_{o}\bigg|} \bigg|  iRe^{i \theta}\bigg| d \theta \bigg|.  \end{align*} Now we can establish a precise estimate for $\eta_{4}$ hence, $$\bigg| \oint_{\eta_{R}^{4}} \frac{\log(e^{it}/\sqrt{R})}{{a_{n}z^{n} + ... + a_{2}z^{2} + a_{o}}}  dz\bigg|   \leq  \text{length}(\eta_{R}^{4})  \cdot \sup_{\eta_{R}^{4}}(g) \leq \pi R \frac{O(\log(R))}{\sqrt{R}} \, \text{as} \, R \rightarrow \infty.$$ By taking care to provide estimates over $\eta_{2}$ and $\eta_{4}$ we have proved $(***)$ and $(**)$ . Applying Szeto's Lemma it becomes apparent that, $(****)$ $$\oint_{\eta^{1}_{R}}g(z) dz + \oint_{\eta^{3}_{R}}g(z) dz \rightarrow  - 2 \pi i \int_{0}^{\infty} \frac{1}{a_{n}t^{n} + ... + a_{2}t^{2} + a_{o}}dx \, \, \,$$ Now taking $(*)$ , $(**)$ , $(***)$ , $(****)$ taken together yield, $$\int_{0}^{\infty} \frac{1}{a_{n}x^{n} + ... + a_{2}x^{2} + a_{o}}dx = 2 \pi i \bigg(  \frac{1}{(n!)}\frac{\log(P) - a_{n}P^{n} + ... + a_{2}P^{2} + a_{o}}{(\log(P)^{2})} \bigg)$$","In the text ""Functions of a Complex Variable"" by Robert E. Greene and Steven G.Krantz I'm having trouble verifying my solution to Using Calculus of Residue evaluate the following is any polynomial with no zero's on the nonnegative real axis For real variable methods would be fruitless we have to take the, For our choice , we initially let where It's important to consider that, Clearly our choice of has a pole of the order of and a pole of the order . Clearly, Putting the pieces together, Applying the  Residue Theorem unfortunately isn't enough to finish our game so it becomes imperative to claim that and that, A particular device used to justify convergence over and is the fact that We will return to this particular device after dealing with our analysis of convergence over and . First we take that, Now over one can see that, Now we can establish a precise estimate for A similar process for says that, Now we can establish a precise estimate for hence, By taking care to provide estimates over and we have proved and . Applying Szeto's Lemma it becomes apparent that, Now taking , , , taken together yield,","\text{Problem (1)} \text{Problem (1)} \int_{0}^{\infty} \frac{1}{a_{n}x^{n} + ... + a_{2}x^{2} + a_{o}}dx \, \, \,  \text{Remark} p(x) \text{Solution} (1) \oint_{\eta_{R}} \frac{\log(z)}{a_{n}z^{n} + ... + a_{2}z^{2} + a_{o}}dz. f \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \eta_{R}^{1}(t)  =  t + i/\sqrt{2R},  \, \, \, \,   1/\sqrt{2R} \leq t \leq R, \eta_{R}^{2}(t)= Re^{it}, \, \, \, \,  \theta_{0} \leq t \leq 2 \pi - \theta_{0}, \theta_{0} = \theta_{0}(R) = \sin^{-1}(1/(R \sqrt{2R})) \, \, \, \, \, \, \, \, \, \, \, \, \, \, \, \eta_{R}^{3}(t)  =  R -t -i/\sqrt{2R},  \, \, \, \, 0 \leq t \leq R-1/\sqrt{2R}. \eta_{R}^{4}(t)  =  e^{it}/\sqrt{R}, \, \, \, \, \,  \, \, \, \, \, \, \, \, \, \, \, \, \, \pi/4 \leq t \leq 7 \pi /4. \oint_{\eta_{R}} \frac{\log(z)}{a_{n}z^{n} + ... + a_{2}z^{2} + a_{o}}dz = 2 \pi i \bigg( \sum_{j} \operatorname{Ind_{\eta_{R}}}(P_{j}) \cdot \operatorname{Res_{\eta_{R}}}(P_{j}) \bigg)  f P n \begin{align*} 
\operatorname{Res_{f}(P)} &=  \frac{1}{(n-1)!} \bigg( \partial_{z} \bigg)^{n-1} \bigg( (z-n)^{n} \frac{\log(z)}{a_{n}z^{n} + ... + a_{2}z^{2} + a_{o}}\bigg) \bigg|_{z=P}\\ 
\, \, \,  &=  \frac{1}{(n)!} \bigg( \partial_{z} \frac{\log(z)}{a_{n}x^{n} + ... + a_{n}z^{2} + a_{o}}\bigg|_{z = P} \bigg) \\
 &= \frac{1}{(n!)}\frac{\log(z) - a_{n}z^{n} + ... + a_{2}P^{2} + a_{o}}{(\log(x)^{2})}\\   &= \frac{1}{(n!)}\frac{\log(P) - a_{n}P^{n} + ... + a_{2}P^{2} + a_{o}}{(\log(P)^{2})}.
\end{align*} (*) \oint_{\eta_{R}} \frac{\log(z)}{a_{n}z^{n} + ... + a_{2}z^{2} + a_{o}}dz  = 2 \pi i \bigg(  \frac{1}{(n!)}\frac{\log(P) - a_{n}P^{n} + ... + a_{2}P^{2} + a_{o}}{(\log(P)^{2})} \bigg) \cdot 1 (**)  \Bigg| \lim_{R \rightarrow \infty}\oint_{\eta^{2}_{R}} f(z)dz \Bigg| \rightarrow 0  (***)  \Bigg| \lim_{R \rightarrow \infty}\oint_{\eta^{4}_{R}} f(z)dz\Bigg| \rightarrow 0. \eta_{4} \eta_{2} \bigg(\log \bigg( \frac{x + i \sqrt{2R}}{(x-i/\sqrt{2R}} \bigg) \bigg)\rightarrow -2 \pi i \text{.} \eta_{4} \eta_{2} \sum_{\psi}^{4} \bigg(\oint_{\eta_{R}^{\psi}} \frac{\log(z)}{a_{n}z^{n} + ... + a_{2}z^{2} + a_{o}}dz \bigg).  \eta_{2} \begin{align*}
\bigg| \oint_{\eta_{R}^{2}}\frac{\log(z)}{a_{n}z^{n} + ... + a_{2}z^{2} + a_{o}}dz\bigg|& = \bigg| \int_{-R}^{+Ri} \frac{\log(Re^{it})}{a_{n}(Re^{it})^{n} + ... + a_{2}(Re^{it})^{2} + a_{o}} iRe^{i \theta} d \theta\bigg|\\&=  \int_{-R}^{+Ri} \bigg|\frac{\log(Re^{it})}{{a_{n}(Re^{it})^{n} + ... + a_{2}(Re^{it})^{2} + a_{o}}} \bigg| \big| iRe^{i \theta} d \theta \big|\\&= \int_{-R}^{+Ri} \frac{\bigg|\log(Re^{it}) \bigg|}{\bigg| {a_{n}(Re^{it})^{n} + ... + a_{2}(Re^{it})^{2} + a_{o}} \bigg|}  \bigg|iRe^{i \theta} \bigg| d \theta  \bigg| \\& = \int_{\theta_{0}}^{2 \pi - \theta_{0}} \frac{\bigg|\log(Re^{it}) \bigg|}{\bigg|{a_{n}(Re^{it})^{n} + ... + a_{2}(Re^{it})^{2} + a_{o}} \bigg|}  \bigg|iRe^{i \theta} \bigg| \bigg|d \theta  \bigg|.
\end{align*} \eta_{2} \bigg| \oint_{\eta_{R}^{2}} \frac{\log(z)}{a_{n}z^{n} + ... + a_{2}z^{2} + a_{o}}dz\bigg| \leq  \frac{\ln(R) + \pi }{R^{n} - a_{o}} \pi R \, \, \text{as} \, \, \, R \rightarrow \infty. \eta_{4} \begin{align*}
\bigg| \oint_{\eta_{R}^{4}} \frac{\log(e^{it}/\sqrt{R})}{{a_{n}z^{n} + ... + a_{2}z^{2} + a_{o}}}  dz\bigg|& =  \oint_{\eta_{R}^{4}} \bigg| \frac{\log(e^{it}/\sqrt{R})}{{a_{n}(e^{it}/\sqrt{R})^{n} + ... + a_{2}(e^{it}/ \sqrt{R})^{2} + a_{o}}}  iRe^{i \theta} d \theta\bigg|\\&= \oint_{\eta_{R}^{4}}  \frac{\bigg|\log(e^{it}/\sqrt{R}) \bigg|}{\bigg|a_{n}(e^{it}/\sqrt{R})^{n} + ... + a_{2}(e^{it}/ \sqrt{R})^{2} + a_{o} \bigg|}  iRe^{i \theta} d \theta \\&= \oint_{\eta_{R}^{4}}  \frac{\bigg| \log(e^{it})- \frac{1}{2}\log(R^{}) \bigg|}{ \bigg|a_{n}(e^{it}/\sqrt{R})^{n} + ... + a_{2}(e^{it}/ \sqrt{R})^{2} + a_{o} \bigg|} \bigg|  iRe^{i \theta} d \theta \bigg|\\& =\oint_{\frac{\pi}{4}}^{\frac{7 \pi}{4}}  \frac{\bigg| it\log(e^{})- \frac{1}{2}\log(R^{}) \bigg|}{ \bigg|a_{n}(e^{it}/\sqrt{R})^{n} + ... + a_{2}(e^{it}/ \sqrt{R})^{2} + a_{o}\bigg|} \bigg|  iRe^{i \theta}\bigg| d \theta \bigg|.  \end{align*} \eta_{4} \bigg| \oint_{\eta_{R}^{4}} \frac{\log(e^{it}/\sqrt{R})}{{a_{n}z^{n} + ... + a_{2}z^{2} + a_{o}}}  dz\bigg|   \leq  \text{length}(\eta_{R}^{4})  \cdot \sup_{\eta_{R}^{4}}(g) \leq \pi R \frac{O(\log(R))}{\sqrt{R}} \, \text{as} \, R \rightarrow \infty. \eta_{2} \eta_{4} (***) (**) (****) \oint_{\eta^{1}_{R}}g(z) dz + \oint_{\eta^{3}_{R}}g(z) dz \rightarrow  - 2 \pi i \int_{0}^{\infty} \frac{1}{a_{n}t^{n} + ... + a_{2}t^{2} + a_{o}}dx \, \, \, (*) (**) (***) (****) \int_{0}^{\infty} \frac{1}{a_{n}x^{n} + ... + a_{2}x^{2} + a_{o}}dx = 2 \pi i \bigg(  \frac{1}{(n!)}\frac{\log(P) - a_{n}P^{n} + ... + a_{2}P^{2} + a_{o}}{(\log(P)^{2})} \bigg)","['integration', 'complex-analysis', 'proof-verification', 'improper-integrals', 'contour-integration']"
60,Different definitions of closed differential form,Different definitions of closed differential form,,"I have recently read, out of curiosity, Tao's very motivating introduction to Differential forms and integration . At pages 5 and 8 he seems to define a closed $k-$form (on some manifold) to be a $k-$form whose integral along any closed $k-$submanifold (i.e., one with zero boundary) vanishes. I am used, instead, to the definition that a form is closed iff its differential is zero. I think that in general Tao's definition is strictly stronger than mine . Here are my thoughts. In the following, we only consider oriented (and, if necessary, compact) manifolds. I believe that the following conditions should all be equivalent for a $k-$form $\omega$: $d\omega=0$ (my definition of being closed) $\int_S d\omega = 0$ for all $(k+1)-$submanifolds $S$ $\int_{\partial S} \omega=0$ for all $(k+1)-$submanifolds $S$, i.e., $\omega$ vanishes on all exact submanifolds The equivalence of 2. and 3. is given by Stokes' theorem. 1. clearly implies 2. and I think that 2. implies 1. because the integration pairing is non-degenerate. In particular, if the above holds, I think that Tao's condition is equivalent to mine iff the $k-$th singular homology of the ambient manifold vanishes $(*)$. I thought maybe de Rham's theorem could solve the problem, but if I interpret it right, it only implies that $\omega$ is exact if and only if its integration along every closed $k-$submanifold gives $0$ $(!)$. Which is kind of dual to 1. $\Leftrightarrow$ 3. above. Now, it seems very strange to me that Tao should use a definition that is not equivalent to the usual one, so I think I must be missing something. Please help me to answer the following: A) Are my three conditions above equivalent and is $(!)$ correct? B) Is $(*)$ right? In particular, when considering singular homology of manifolds, can we restrict to smooth submanifolds (with boundary) instead of arbitrary continuous images of simplices? C) Did I get Tao's definition of closed form right? If so, is it really different from mine? Why?","I have recently read, out of curiosity, Tao's very motivating introduction to Differential forms and integration . At pages 5 and 8 he seems to define a closed $k-$form (on some manifold) to be a $k-$form whose integral along any closed $k-$submanifold (i.e., one with zero boundary) vanishes. I am used, instead, to the definition that a form is closed iff its differential is zero. I think that in general Tao's definition is strictly stronger than mine . Here are my thoughts. In the following, we only consider oriented (and, if necessary, compact) manifolds. I believe that the following conditions should all be equivalent for a $k-$form $\omega$: $d\omega=0$ (my definition of being closed) $\int_S d\omega = 0$ for all $(k+1)-$submanifolds $S$ $\int_{\partial S} \omega=0$ for all $(k+1)-$submanifolds $S$, i.e., $\omega$ vanishes on all exact submanifolds The equivalence of 2. and 3. is given by Stokes' theorem. 1. clearly implies 2. and I think that 2. implies 1. because the integration pairing is non-degenerate. In particular, if the above holds, I think that Tao's condition is equivalent to mine iff the $k-$th singular homology of the ambient manifold vanishes $(*)$. I thought maybe de Rham's theorem could solve the problem, but if I interpret it right, it only implies that $\omega$ is exact if and only if its integration along every closed $k-$submanifold gives $0$ $(!)$. Which is kind of dual to 1. $\Leftrightarrow$ 3. above. Now, it seems very strange to me that Tao should use a definition that is not equivalent to the usual one, so I think I must be missing something. Please help me to answer the following: A) Are my three conditions above equivalent and is $(!)$ correct? B) Is $(*)$ right? In particular, when considering singular homology of manifolds, can we restrict to smooth submanifolds (with boundary) instead of arbitrary continuous images of simplices? C) Did I get Tao's definition of closed form right? If so, is it really different from mine? Why?",,"['integration', 'differential-geometry', 'differential-forms']"
61,"How can I evaluate $\displaystyle\int_{0}^{\infty}\frac{x\log(x)}{1+e^x}\,dx$?",How can I evaluate ?,"\displaystyle\int_{0}^{\infty}\frac{x\log(x)}{1+e^x}\,dx","My attempt : Evaluate a more general case, $$F(a) = \int_{0}^{\infty}\frac{x\log x}{1+e^x}\cdot a^{1+e^x} \,dx$$ $$F'(a) = \int_{0}^{\infty}x\cdot \log(x)\cdot a^{e^x} \,dx$$ Is there any way to take it from here without using by parts multiple times ? Will Feynman's trick be of any help here ? Please don't give away the entire solution. Thanks :)","My attempt : Evaluate a more general case, $$F(a) = \int_{0}^{\infty}\frac{x\log x}{1+e^x}\cdot a^{1+e^x} \,dx$$ $$F'(a) = \int_{0}^{\infty}x\cdot \log(x)\cdot a^{e^x} \,dx$$ Is there any way to take it from here without using by parts multiple times ? Will Feynman's trick be of any help here ? Please don't give away the entire solution. Thanks :)",,['integration']
62,Confused about developing a Taylor series of a function that implicates an integral,Confused about developing a Taylor series of a function that implicates an integral,,"There is a function that makes me confused: $$f(x)=\int_{\frac{\pi}{2}}^x \frac{\cos(t)}{t-\frac{\pi}{2}}~dt$$ The question wants me to find its Taylor series centered in $a=π/2$ and I don't know how, I tried separating $\cos(t)$ of $\dfrac{1}{t-π/2}$ and make the MacLaurin series of $\cos(t)$, and then multiply the series by $\dfrac{1}{t-\frac{π}{2}} ~dt$ .  But at the end, it doesn't end as a Taylor series centered in $π/2$, it's more like a MacLaurin series : I found  $$\sum_{n=0}^{\infty} \frac{t^n}{n!\cdot (t-\frac{π}{2})}$$ Please could you help me with this series ? Thank you a lot !","There is a function that makes me confused: $$f(x)=\int_{\frac{\pi}{2}}^x \frac{\cos(t)}{t-\frac{\pi}{2}}~dt$$ The question wants me to find its Taylor series centered in $a=π/2$ and I don't know how, I tried separating $\cos(t)$ of $\dfrac{1}{t-π/2}$ and make the MacLaurin series of $\cos(t)$, and then multiply the series by $\dfrac{1}{t-\frac{π}{2}} ~dt$ .  But at the end, it doesn't end as a Taylor series centered in $π/2$, it's more like a MacLaurin series : I found  $$\sum_{n=0}^{\infty} \frac{t^n}{n!\cdot (t-\frac{π}{2})}$$ Please could you help me with this series ? Thank you a lot !",,"['integration', 'sequences-and-series']"
63,Integrating Powers of $\frac{\sin x}{x}$ using Fourier Transforms,Integrating Powers of  using Fourier Transforms,\frac{\sin x}{x},"This is a problem from a past qualifying exam: The Fourier transform of the characteristic function $h=\chi_{[-1,1]}$ of the interval $[-1,1]$ is  $$\hat h(\xi) =\sqrt{\frac{2}{\pi}} \frac{\sin \xi}{\xi}.$$  Using various properties of the Fourier transform, calculate $$\int_0^\infty \frac{\sin x}{x}dx$$ $$\int_0^\infty \big(\frac{\sin x}{x}\big)^2dx$$ $$\int_0^\infty \big(\frac{\sin x}{x}\big)^4dx.$$  Note: Here we are using the definition of the Fourier transform $$\hat f(\xi) = \frac{1}{\sqrt{2\pi}} \int_{-\infty}^\infty e^{-ix\xi} f(x) dx.$$  To evaluate the third integral, you may make use of the formula $$ (h\ast h)(x) = \begin{cases} 2-|x| & \ |x|<2 \\ 0 & \ |x| \geq 2 \end{cases}$$. I figured out the $\int_0^\infty \big(\frac{\sin x}{x}\big)^2dx$ portion by simply using Plancherel, i.e. $||h||_2^2 = ||\hat h||_2^2$. I am still struggling with the other cases, however. I have tried the Fourier Inversion as well as multiplication formula. Because of the hint, I would gather that in the last case you are also supposed to use the fact that $\widehat{h\ast h} = \hat h \cdot \hat h$.","This is a problem from a past qualifying exam: The Fourier transform of the characteristic function $h=\chi_{[-1,1]}$ of the interval $[-1,1]$ is  $$\hat h(\xi) =\sqrt{\frac{2}{\pi}} \frac{\sin \xi}{\xi}.$$  Using various properties of the Fourier transform, calculate $$\int_0^\infty \frac{\sin x}{x}dx$$ $$\int_0^\infty \big(\frac{\sin x}{x}\big)^2dx$$ $$\int_0^\infty \big(\frac{\sin x}{x}\big)^4dx.$$  Note: Here we are using the definition of the Fourier transform $$\hat f(\xi) = \frac{1}{\sqrt{2\pi}} \int_{-\infty}^\infty e^{-ix\xi} f(x) dx.$$  To evaluate the third integral, you may make use of the formula $$ (h\ast h)(x) = \begin{cases} 2-|x| & \ |x|<2 \\ 0 & \ |x| \geq 2 \end{cases}$$. I figured out the $\int_0^\infty \big(\frac{\sin x}{x}\big)^2dx$ portion by simply using Plancherel, i.e. $||h||_2^2 = ||\hat h||_2^2$. I am still struggling with the other cases, however. I have tried the Fourier Inversion as well as multiplication formula. Because of the hint, I would gather that in the last case you are also supposed to use the fact that $\widehat{h\ast h} = \hat h \cdot \hat h$.",,"['integration', 'convolution', 'fourier-transform']"
64,Integration of a Periodic Function,Integration of a Periodic Function,,"Problem: $f : \mathbb{R} \to  \mathbb{R}$  is a continuous and periodic function with period $T>0.$ Prove that: $$\lim_{n\to +\infty} \int_{a}^{b} f(nx) dx =\frac{b-a}{T} \int_{0}^{T} f(x) dx$$ I tried substituting $nx=t$, but it gave me $\frac{1}{n} \int_{na}^{nb} f(t)dt$, and I don't know what to do. Can anyone give me hints to solve this? Or is there another way to solve this problem?","Problem: $f : \mathbb{R} \to  \mathbb{R}$  is a continuous and periodic function with period $T>0.$ Prove that: $$\lim_{n\to +\infty} \int_{a}^{b} f(nx) dx =\frac{b-a}{T} \int_{0}^{T} f(x) dx$$ I tried substituting $nx=t$, but it gave me $\frac{1}{n} \int_{na}^{nb} f(t)dt$, and I don't know what to do. Can anyone give me hints to solve this? Or is there another way to solve this problem?",,"['integration', 'limits', 'definite-integrals', 'periodic-functions']"
65,Do we really need a partition of unity to define integration on manifolds,Do we really need a partition of unity to define integration on manifolds,,"On wikipedia , there is the following : A partition of unity can be used to define the integral (with respect   to a volume form) of a function defined over a manifold: One first   defines the integral of a function whose support is contained in a   single coordinate patch of the manifold; then one uses a partition of   unity to define the integral of an arbitrary function; finally one   shows that the definition is independent of the chosen partition of   unity. My question is the following : do we really need to use a partition of unity to define the integral of a function defined over a manifold ? Couldn't we just use a sequence $(U_n)$ of chart domains that cover the manifold, and then define the sequence of Borel sets  $B_{n+1}:=U_{n+1}\backslash U_n$, and $B_0=U_0$, and then just define the integral of a function $f$ with respect to a volume form to be the sum of all integrals of $f$ over $B_n$ (since $B_n$ is in a chart domain, the integral can be computed through a chart).","On wikipedia , there is the following : A partition of unity can be used to define the integral (with respect   to a volume form) of a function defined over a manifold: One first   defines the integral of a function whose support is contained in a   single coordinate patch of the manifold; then one uses a partition of   unity to define the integral of an arbitrary function; finally one   shows that the definition is independent of the chosen partition of   unity. My question is the following : do we really need to use a partition of unity to define the integral of a function defined over a manifold ? Couldn't we just use a sequence $(U_n)$ of chart domains that cover the manifold, and then define the sequence of Borel sets  $B_{n+1}:=U_{n+1}\backslash U_n$, and $B_0=U_0$, and then just define the integral of a function $f$ with respect to a volume form to be the sum of all integrals of $f$ over $B_n$ (since $B_n$ is in a chart domain, the integral can be computed through a chart).",,"['integration', 'differential-geometry', 'manifolds']"
66,Is really $f(x)=\int g(x) dx$ a function?,Is really  a function?,f(x)=\int g(x) dx,"I saw many of this kind of questions on some text/question books. Is there any other explanation of this, or is it really wrong as I thought? Here is a question of that kind: If $\displaystyle f(x)=\int x(x^2-a)^2 dx$ and $f(a)=7$ then $f(-a)=?$ Here what is $f(0)$ or $f(1)$? $\displaystyle f(0)=\int 0(0^2-a)^2 d0$ or $\displaystyle f(1)=\int 1(1^2-a)^2 d1$ does not make sense. For me, a right function need to be as: $\displaystyle  f_c(x)=\int_c^xt(t^2-a)^2dt$ (where $c$ is some constant, can be $0$ as usual).","I saw many of this kind of questions on some text/question books. Is there any other explanation of this, or is it really wrong as I thought? Here is a question of that kind: If $\displaystyle f(x)=\int x(x^2-a)^2 dx$ and $f(a)=7$ then $f(-a)=?$ Here what is $f(0)$ or $f(1)$? $\displaystyle f(0)=\int 0(0^2-a)^2 d0$ or $\displaystyle f(1)=\int 1(1^2-a)^2 d1$ does not make sense. For me, a right function need to be as: $\displaystyle  f_c(x)=\int_c^xt(t^2-a)^2dt$ (where $c$ is some constant, can be $0$ as usual).",,"['integration', 'functions', 'definition']"
67,What is the closed form for $\int_{0}^{\infty}\frac{1}{1+x^2}\cdot\frac{x^{\pi}}{1+x^{\pi}}\cdot\frac{1}{1+x^ e}dx $?,What is the closed form for ?,\int_{0}^{\infty}\frac{1}{1+x^2}\cdot\frac{x^{\pi}}{1+x^{\pi}}\cdot\frac{1}{1+x^ e}dx ,On my previou page Jack D'Aurizio offered a concise elegant prove of Vladimir Reshetnikov's identity and a closed form for it. (1) $$\int_{0}^{\infty}\frac{1}{1+x^2}\cdot\frac{1}{1+x^{\pi}}dx=\int_{0}^{\infty}\frac{1}{1+x^2}\cdot\frac{1}{1+x^{e}}dx=\frac{\pi}{4}$$ Here we have another imitation of Vladimir Reshetnikov's identity (2) $$\int_{0}^{\infty}\frac{1}{1+x^2}\cdot\frac{x^{\pi}}{1+x^{\pi}}\cdot\frac{1}{1+x^e}dx =\int_{0}^{\infty}\frac{1}{1+x^2}\cdot\frac{x^e}{1+x^e}\cdot\frac{1}{1+x^{\pi}}dx$$ A closed form of (2) is unknown We ask if this identity (2) can be proven in the same way as (1) and with a closed form.,On my previou page Jack D'Aurizio offered a concise elegant prove of Vladimir Reshetnikov's identity and a closed form for it. (1) $$\int_{0}^{\infty}\frac{1}{1+x^2}\cdot\frac{1}{1+x^{\pi}}dx=\int_{0}^{\infty}\frac{1}{1+x^2}\cdot\frac{1}{1+x^{e}}dx=\frac{\pi}{4}$$ Here we have another imitation of Vladimir Reshetnikov's identity (2) $$\int_{0}^{\infty}\frac{1}{1+x^2}\cdot\frac{x^{\pi}}{1+x^{\pi}}\cdot\frac{1}{1+x^e}dx =\int_{0}^{\infty}\frac{1}{1+x^2}\cdot\frac{x^e}{1+x^e}\cdot\frac{1}{1+x^{\pi}}dx$$ A closed form of (2) is unknown We ask if this identity (2) can be proven in the same way as (1) and with a closed form.,,[]
68,Evaluating an integral - is it a two dimensional beta function? This arises from a variant of Goldbach's conjecture.,Evaluating an integral - is it a two dimensional beta function? This arises from a variant of Goldbach's conjecture.,,"Let $\gamma>0$. I would like a nice way to prove that $$\int_{\begin{array}{c} 0\leq s,t\leq1\\ s+t\leq1 \end{array}}t^{\gamma-1}s^{\gamma-1}(1-t-s)^{\gamma-1}dtds=\frac{\Gamma(\gamma)^3}{\Gamma(3\gamma)}.$$ Edit/Remark: zhoraster's answer along with induction allows one to prove the generalized identity when integrating over the simplex $$\int_{\begin{array}{c} 0\leq t_{i}\leq1\\ t_{1}+\cdots+t_{k}\leq1 \end{array}}t_{1}^{x_{1}-1}\cdots t_{k}^{x_{k}-1}\left(1-\sum_{i=1}^{k}t_{i}\right)^{x_{k+1}-1}dt_{1}\cdots dt_{k}=\frac{\Gamma(x_{1})\Gamma(x_{2})\cdots\Gamma(x_{k+1})}{\Gamma(x_{1}+\cdots+x_{k+1})}  $$ for any $0<x_i<1$ This integral came about while I was reading through Balog and Friedlander's paper A Hybrid Theorem of Vinogradov and Piatetski-Shapiro. Let $0<\gamma<1$, and let$$P_{\gamma}=\left\{ p\ :\ p=\lfloor n^{1/\gamma}\rfloor\ \text{for some }n\right\}   $$ be the set of Piatetski-Shapiro primes. While this set of primes is very sparse, it has many nice properties and it is known that a version of the Prime number theorem holds when $\gamma$ is not too small ( see this paper of Heath-Brown ) $$\sum_{\begin{array}{c} p\leq x\\ p\in P_{\gamma} \end{array}}1\sim\frac{x^{\gamma}}{\log x}.  $$ In the paper of Balog and Friedlander, they prove that for $\gamma$ in some range close to $1$, we have $$\frac{1}{\gamma^{3}}\sum_{\begin{array}{c} p_{1}+p_{2}+p_{3}=N\\ p_{i}\in P_{\gamma} \end{array}}p_{1}^{1-\gamma}p_{2}^{1-\gamma}p_{3}^{1-\gamma}\log p_{1}\log p_{2}\log p_{3}\sim\frac{1}{2}\mathfrak{S}(N)N^{2},  $$ where $\mathfrak{S}(N)$   is a particular singular series. Note that this implies that every sufficiently large integer can be written as the sum of three Piatetski-Shapiro primes, which proves a variant of Goldbach's Ternary conjecture for all sufficient large integers. From this they deduce without proof that $$\sum_{\begin{array}{c} p_{1}+p_{2}+p_{3}=N\\ p_{i}\in P_{\gamma} \end{array}}1\sim\frac{1}{2}\frac{\mathfrak{S}(N)N^{3\gamma-1}}{\left(\log N\right)^{3}}\frac{\gamma^{3}\Gamma(\gamma)^{3}}{\Gamma(3\gamma)}.$$ When I applied partial summation, this deduction reduced to evaluating the integral written above.","Let $\gamma>0$. I would like a nice way to prove that $$\int_{\begin{array}{c} 0\leq s,t\leq1\\ s+t\leq1 \end{array}}t^{\gamma-1}s^{\gamma-1}(1-t-s)^{\gamma-1}dtds=\frac{\Gamma(\gamma)^3}{\Gamma(3\gamma)}.$$ Edit/Remark: zhoraster's answer along with induction allows one to prove the generalized identity when integrating over the simplex $$\int_{\begin{array}{c} 0\leq t_{i}\leq1\\ t_{1}+\cdots+t_{k}\leq1 \end{array}}t_{1}^{x_{1}-1}\cdots t_{k}^{x_{k}-1}\left(1-\sum_{i=1}^{k}t_{i}\right)^{x_{k+1}-1}dt_{1}\cdots dt_{k}=\frac{\Gamma(x_{1})\Gamma(x_{2})\cdots\Gamma(x_{k+1})}{\Gamma(x_{1}+\cdots+x_{k+1})}  $$ for any $0<x_i<1$ This integral came about while I was reading through Balog and Friedlander's paper A Hybrid Theorem of Vinogradov and Piatetski-Shapiro. Let $0<\gamma<1$, and let$$P_{\gamma}=\left\{ p\ :\ p=\lfloor n^{1/\gamma}\rfloor\ \text{for some }n\right\}   $$ be the set of Piatetski-Shapiro primes. While this set of primes is very sparse, it has many nice properties and it is known that a version of the Prime number theorem holds when $\gamma$ is not too small ( see this paper of Heath-Brown ) $$\sum_{\begin{array}{c} p\leq x\\ p\in P_{\gamma} \end{array}}1\sim\frac{x^{\gamma}}{\log x}.  $$ In the paper of Balog and Friedlander, they prove that for $\gamma$ in some range close to $1$, we have $$\frac{1}{\gamma^{3}}\sum_{\begin{array}{c} p_{1}+p_{2}+p_{3}=N\\ p_{i}\in P_{\gamma} \end{array}}p_{1}^{1-\gamma}p_{2}^{1-\gamma}p_{3}^{1-\gamma}\log p_{1}\log p_{2}\log p_{3}\sim\frac{1}{2}\mathfrak{S}(N)N^{2},  $$ where $\mathfrak{S}(N)$   is a particular singular series. Note that this implies that every sufficiently large integer can be written as the sum of three Piatetski-Shapiro primes, which proves a variant of Goldbach's Ternary conjecture for all sufficient large integers. From this they deduce without proof that $$\sum_{\begin{array}{c} p_{1}+p_{2}+p_{3}=N\\ p_{i}\in P_{\gamma} \end{array}}1\sim\frac{1}{2}\frac{\mathfrak{S}(N)N^{3\gamma-1}}{\left(\log N\right)^{3}}\frac{\gamma^{3}\Gamma(\gamma)^{3}}{\Gamma(3\gamma)}.$$ When I applied partial summation, this deduction reduced to evaluating the integral written above.",,"['integration', 'number-theory', 'definite-integrals', 'special-functions', 'analytic-number-theory']"
69,how to compute this limit,how to compute this limit,,"compute $I=\lim\limits_{n\to+\infty}\sqrt[n]{\int\limits_0^1x^{n+1}(1-x)\cdots(1-x^n)dx}$ attempt: I tried to evaluate the integral $$\begin{align} \int\limits_0^1x^{n+1}(1-x)\cdots(1-x^n)dx&=\int\limits_0^1x^{n+1}\left(1-x-x^2-x^3+x^5+\cdots\right)dx\\ &=\int\limits_0^1x^{n+1}-x^{n+2}-x^{n+3}-x^{n+4}+x^{n+6}+\cdots dx\\ &=\left.\frac{x^{n+2}}{n+2}-\frac{x^{n+3}}{n+3}-\frac{x^{n+4}}{n+4}-\frac{x^{n+5}}{n+5}+\frac{x^{n+6}}{n+6}+\cdots\right|_0^1\\ &=\frac{1}{n+2}-\frac{1}{n+3}-\frac{1}{n+4}-\frac{1}{n+5}+\frac{1}{n+6}+\cdots \end{align}$$ attempt 2: I think I can use mean value theorem for integrals if $f$ are continuous into $[a,b]$ then exists $\xi\in[0,1]$ such that $\int\limits_a^b f(x)dx=f(\xi)(b-a)$ then using it for $[a,b]=[0,1]$ since the function inside integral are continuous, then exists $\xi\in[0,1]$ such that $$\begin{align} \sqrt[n]{\int\limits_0^1x^{n+1}(1-x)\cdots(1-x^n)dx}&=\sqrt[n]{\xi^{n+1}(1-\xi)\cdots(1-\xi^n)(1-0)}\\ &=\sqrt[n]{\xi^{n+1}(1-\xi)\cdots(1-\xi^n)} \end{align}$$ then making for $n\in\mathbb{N}^*$ $$\begin{align} a_n&=\sqrt[n]{\xi^{n+1}(1-\xi)\cdots(1-\xi^n)}\\ a_{n+1}&=\sqrt[n+1]{\xi^{n+2}(1-\xi)\cdots(1-\xi^n)(1-\xi^{n+1})}\\ &=\sqrt[n+1]{\xi\xi^{n+1}(1-\xi)\cdots(1-\xi^n)(1-\xi^{n+1})}\\ &=\sqrt[n+1]{\xi\left[\sqrt[n]{\xi^{n+1}(1-\xi)\cdots(1-\xi^n)}\right]^n(1-\xi^{n+1})}\\ &=\sqrt[n+1]{a_n^n\xi(1-\xi^{n+1})}\\ a_{n+1}^{n+1}&=a_n^n\xi(1-\xi^{n+1}) \end{align}$$ and $\xi\in(0,1)\Rightarrow\xi^n\in(0,1)\Rightarrow 1-\xi^n\in(0,1)\Rightarrow a_n>0$ and $a_n\in(0,1)$ then $$\begin{align} a_{1}&=\xi^2(1-\xi)\\ a_{2}&=\sqrt{\xi^3(1-\xi)(1-\xi^2)}\\ &=\sqrt{\xi^3(1-\xi)^2(1+\xi)}\\ &=\xi(1-\xi)\sqrt{\xi(1+\xi)} \end{align}$$ for $\xi\in(0,1)\Rightarrow \xi(1-\xi)>0$ $$\begin{align} 0<\xi&<1+\xi\\ 0<\xi^2&<\xi(1+\xi)=\xi+\xi^2\\ \xi&<\sqrt{\xi(1+\xi)}\\ \xi^2(1-\xi)&<\xi(1-\xi)\sqrt{\xi(1+\xi)}\\ a_1&<a_2 \end{align}$$ then i think if i can proof that $a_{n+1}>a_n,n\in\mathbb{N}^*$ and $\xi\in(0,1)$ then the limit would be $1$","compute $I=\lim\limits_{n\to+\infty}\sqrt[n]{\int\limits_0^1x^{n+1}(1-x)\cdots(1-x^n)dx}$ attempt: I tried to evaluate the integral $$\begin{align} \int\limits_0^1x^{n+1}(1-x)\cdots(1-x^n)dx&=\int\limits_0^1x^{n+1}\left(1-x-x^2-x^3+x^5+\cdots\right)dx\\ &=\int\limits_0^1x^{n+1}-x^{n+2}-x^{n+3}-x^{n+4}+x^{n+6}+\cdots dx\\ &=\left.\frac{x^{n+2}}{n+2}-\frac{x^{n+3}}{n+3}-\frac{x^{n+4}}{n+4}-\frac{x^{n+5}}{n+5}+\frac{x^{n+6}}{n+6}+\cdots\right|_0^1\\ &=\frac{1}{n+2}-\frac{1}{n+3}-\frac{1}{n+4}-\frac{1}{n+5}+\frac{1}{n+6}+\cdots \end{align}$$ attempt 2: I think I can use mean value theorem for integrals if $f$ are continuous into $[a,b]$ then exists $\xi\in[0,1]$ such that $\int\limits_a^b f(x)dx=f(\xi)(b-a)$ then using it for $[a,b]=[0,1]$ since the function inside integral are continuous, then exists $\xi\in[0,1]$ such that $$\begin{align} \sqrt[n]{\int\limits_0^1x^{n+1}(1-x)\cdots(1-x^n)dx}&=\sqrt[n]{\xi^{n+1}(1-\xi)\cdots(1-\xi^n)(1-0)}\\ &=\sqrt[n]{\xi^{n+1}(1-\xi)\cdots(1-\xi^n)} \end{align}$$ then making for $n\in\mathbb{N}^*$ $$\begin{align} a_n&=\sqrt[n]{\xi^{n+1}(1-\xi)\cdots(1-\xi^n)}\\ a_{n+1}&=\sqrt[n+1]{\xi^{n+2}(1-\xi)\cdots(1-\xi^n)(1-\xi^{n+1})}\\ &=\sqrt[n+1]{\xi\xi^{n+1}(1-\xi)\cdots(1-\xi^n)(1-\xi^{n+1})}\\ &=\sqrt[n+1]{\xi\left[\sqrt[n]{\xi^{n+1}(1-\xi)\cdots(1-\xi^n)}\right]^n(1-\xi^{n+1})}\\ &=\sqrt[n+1]{a_n^n\xi(1-\xi^{n+1})}\\ a_{n+1}^{n+1}&=a_n^n\xi(1-\xi^{n+1}) \end{align}$$ and $\xi\in(0,1)\Rightarrow\xi^n\in(0,1)\Rightarrow 1-\xi^n\in(0,1)\Rightarrow a_n>0$ and $a_n\in(0,1)$ then $$\begin{align} a_{1}&=\xi^2(1-\xi)\\ a_{2}&=\sqrt{\xi^3(1-\xi)(1-\xi^2)}\\ &=\sqrt{\xi^3(1-\xi)^2(1+\xi)}\\ &=\xi(1-\xi)\sqrt{\xi(1+\xi)} \end{align}$$ for $\xi\in(0,1)\Rightarrow \xi(1-\xi)>0$ $$\begin{align} 0<\xi&<1+\xi\\ 0<\xi^2&<\xi(1+\xi)=\xi+\xi^2\\ \xi&<\sqrt{\xi(1+\xi)}\\ \xi^2(1-\xi)&<\xi(1-\xi)\sqrt{\xi(1+\xi)}\\ a_1&<a_2 \end{align}$$ then i think if i can proof that $a_{n+1}>a_n,n\in\mathbb{N}^*$ and $\xi\in(0,1)$ then the limit would be $1$",,"['integration', 'sequences-and-series', 'limits', 'definite-integrals', 'special-functions']"
70,Dogbone countor integral (evalutate $\int_0^1 \frac{x^n}{x^a(1-x)^{1-a}}dx$),Dogbone countor integral (evalutate ),\int_0^1 \frac{x^n}{x^a(1-x)^{1-a}}dx,"I'm confronted with the following problem which I really don't seem to find a way to solve properly: Let $n\in \mathbb{Z}$ be fixed. Determine for what values of the parameter $a\in\mathbb{C}$ the following integral converges, and then evaluate it . $$\int_0^1 \frac{x^n}{x^a(1-x)^{1-a}}dx$$ It's quite easy to show that the constraint on $a$ for the function to be integrable on that interval is: $0<\text{Re}({a})<n+1$. But now I'm stuck with the evaluation part. Since it is at the end of the chapter about exterior domains I'm assuming it should/can be solved using a dogbone contour integration... but I cannot find a nice way to evaluate the resiude at infinity of this particular function... and furthermore I cannot seem to find a nice value for the bottom slit, because I would expect something like a constant times my starting integral as it often occurs... Can someone help me out? Many thanks in advance","I'm confronted with the following problem which I really don't seem to find a way to solve properly: Let $n\in \mathbb{Z}$ be fixed. Determine for what values of the parameter $a\in\mathbb{C}$ the following integral converges, and then evaluate it . $$\int_0^1 \frac{x^n}{x^a(1-x)^{1-a}}dx$$ It's quite easy to show that the constraint on $a$ for the function to be integrable on that interval is: $0<\text{Re}({a})<n+1$. But now I'm stuck with the evaluation part. Since it is at the end of the chapter about exterior domains I'm assuming it should/can be solved using a dogbone contour integration... but I cannot find a nice way to evaluate the resiude at infinity of this particular function... and furthermore I cannot seem to find a nice value for the bottom slit, because I would expect something like a constant times my starting integral as it often occurs... Can someone help me out? Many thanks in advance",,"['integration', 'complex-analysis', 'definite-integrals']"
71,Gamma Type Integral,Gamma Type Integral,,I was hoping someone could help me with a question I came across recently: essentially it's a gamma type integral that your asked to evaluate/reduce: P=$\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty}e^{-\frac{x^{2}}{2}-\frac{cx^{4}}{4}}dx$ where c is a constant. The way your asked to evaluate it is to reduce the integrand using a taylor expansion to order 1 for the exponential function and then use the fact that $\int_{-\infty}^{\infty}e^{-\frac{x^{2}}{2}}dx=\sqrt{2\pi}$ I can't come to any plausible solutions to this problem. I mean you could say that  $e^{-\frac{x^{2}}{2}-\frac{cx^{4}}{4}}\approx1-\frac{x^{2}}{2}-\frac{cx^{4}}{4}+\dots$ but to order 1 this would just result in the integrand becoming 1 and this doesn't make sense? If the question said using the exponential to order 2 then the integral would evaluate to $\sqrt{2\pi}$ and thus P itself would be 1 but my thoughts are that the reduced P is wanted in terms of c? Can someone please provide some guidance or a possible way to reduce P. Thanks very much.,I was hoping someone could help me with a question I came across recently: essentially it's a gamma type integral that your asked to evaluate/reduce: P=$\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\infty}e^{-\frac{x^{2}}{2}-\frac{cx^{4}}{4}}dx$ where c is a constant. The way your asked to evaluate it is to reduce the integrand using a taylor expansion to order 1 for the exponential function and then use the fact that $\int_{-\infty}^{\infty}e^{-\frac{x^{2}}{2}}dx=\sqrt{2\pi}$ I can't come to any plausible solutions to this problem. I mean you could say that  $e^{-\frac{x^{2}}{2}-\frac{cx^{4}}{4}}\approx1-\frac{x^{2}}{2}-\frac{cx^{4}}{4}+\dots$ but to order 1 this would just result in the integrand becoming 1 and this doesn't make sense? If the question said using the exponential to order 2 then the integral would evaluate to $\sqrt{2\pi}$ and thus P itself would be 1 but my thoughts are that the reduced P is wanted in terms of c? Can someone please provide some guidance or a possible way to reduce P. Thanks very much.,,"['integration', 'functions', 'taylor-expansion', 'exponential-function', 'gamma-function']"
72,Slope function of a curve,Slope function of a curve,,"I have a question I am having trouble answering: The slope function of a curve is: $$\frac{dy}{dx}=ux+k$$ u and k are constants. The curve passes through $(0,-1)$ and $(2,-5)$ At $(2,-5)$ the slope equals $1$. How do I get the equation? I have tried integrating and pluging the two above points in and trying to solve for u and k but I end up getting the integration constant $c=-1$ and $k=2-u$  I then plug this into the integrated slope function: $$\frac{ux^2}{2} + kx -1$$ but I don't get the correct answer. Could someone point out where I am going wrong wrong and how to correct it.","I have a question I am having trouble answering: The slope function of a curve is: $$\frac{dy}{dx}=ux+k$$ u and k are constants. The curve passes through $(0,-1)$ and $(2,-5)$ At $(2,-5)$ the slope equals $1$. How do I get the equation? I have tried integrating and pluging the two above points in and trying to solve for u and k but I end up getting the integration constant $c=-1$ and $k=2-u$  I then plug this into the integrated slope function: $$\frac{ux^2}{2} + kx -1$$ but I don't get the correct answer. Could someone point out where I am going wrong wrong and how to correct it.",,['integration']
73,How to prove a generalized integral identity,How to prove a generalized integral identity,,$$ \int_{0}^{\infty }\frac{t}{(e^{2\pi t}-1)(1+t^{2})}dt=-\frac{1}{4}+\frac{\gamma}{2} $$ where $\gamma$ = Euler Gamma $$ \int_{0}^{\infty }\frac{t}{( e^{2\pi t}-1)(1+t^{2}) ^{2}}dt=\frac{\pi^2}{24} -\frac{3}{8} $$ $$ \int_{0}^{\infty }\frac{t}{(e^{2\pi t}-1)( 1+t^{2})^{3}}dt=\frac{\pi^2}{96} +\frac{\zeta(3)}{8} -\frac{7}{32}  $$,$$ \int_{0}^{\infty }\frac{t}{(e^{2\pi t}-1)(1+t^{2})}dt=-\frac{1}{4}+\frac{\gamma}{2} $$ where $\gamma$ = Euler Gamma $$ \int_{0}^{\infty }\frac{t}{( e^{2\pi t}-1)(1+t^{2}) ^{2}}dt=\frac{\pi^2}{24} -\frac{3}{8} $$ $$ \int_{0}^{\infty }\frac{t}{(e^{2\pi t}-1)( 1+t^{2})^{3}}dt=\frac{\pi^2}{96} +\frac{\zeta(3)}{8} -\frac{7}{32}  $$,,"['integration', 'special-functions', 'definite-integrals', 'improper-integrals', 'closed-form']"
74,What is the best state-of-the-art numerical integral algorithm?,What is the best state-of-the-art numerical integral algorithm?,,"I'm trying to implement a numerical integrator that should have the minimum relative error and is not slow. So I was looking for the best accepted state-of-the-art algorithm to do so but there seems to be so many approaches that I could not understand which one should I choose. So I'm turning to you for a recommendation. Thank you for your attention,","I'm trying to implement a numerical integrator that should have the minimum relative error and is not slow. So I was looking for the best accepted state-of-the-art algorithm to do so but there seems to be so many approaches that I could not understand which one should I choose. So I'm turning to you for a recommendation. Thank you for your attention,",,"['integration', 'algorithms', 'numerical-methods', 'definite-integrals']"
75,Online Calculator for Complex Calculus - path in. C z3(z 1− 1)2 dz; |z − 2| = 5tegrals [closed],Online Calculator for Complex Calculus - path in. C z3(z 1− 1)2 dz; |z − 2| = 5tegrals [closed],,"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 3 years ago . Improve this question Does anyone know of an online calculator/tool that allows you to calculate integrals in the complex number set over a path? I've searched in the standard websites ( Symbolab , Wolfram , Integral Calculator ) and none of them has this option for complex calculus (they do have, as it has been pointed out, regular integration in the complex plain, but none has an option to integrate over paths).","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 3 years ago . Improve this question Does anyone know of an online calculator/tool that allows you to calculate integrals in the complex number set over a path? I've searched in the standard websites ( Symbolab , Wolfram , Integral Calculator ) and none of them has this option for complex calculus (they do have, as it has been pointed out, regular integration in the complex plain, but none has an option to integrate over paths).",,"['integration', 'complex-analysis', 'complex-numbers', 'complex-integration', 'online-resources']"
76,Evaluate $\int _0^{2 \pi }\int _0^{2 \pi }\log (3-\cos (x+y)-\cos (x)-\cos (y))dxdy$,Evaluate,\int _0^{2 \pi }\int _0^{2 \pi }\log (3-\cos (x+y)-\cos (x)-\cos (y))dxdy,How to prove $$\small\int _0^{2 \pi }\int _0^{2 \pi }\log (3-\cos (x+y)-\cos (x)-\cos (y))dxdy= -4 \pi ^2 \left(\frac{\pi }{\sqrt{3}}+\log (2)-\frac{\psi ^{(1)}\left(\frac{1}{6}\right)}{2 \sqrt{3} \pi }\right)$$ Where $\psi^{(1)}$ denotes Trigamma? This identity arises from J. Borwein's review on experimental mathematics (which refer this formula to V. Adamchik) with no related source offered. Any help will be appreciated!,How to prove Where denotes Trigamma? This identity arises from J. Borwein's review on experimental mathematics (which refer this formula to V. Adamchik) with no related source offered. Any help will be appreciated!,"\small\int _0^{2 \pi }\int _0^{2 \pi }\log (3-\cos (x+y)-\cos (x)-\cos (y))dxdy=
-4 \pi ^2 \left(\frac{\pi }{\sqrt{3}}+\log (2)-\frac{\psi ^{(1)}\left(\frac{1}{6}\right)}{2 \sqrt{3} \pi }\right) \psi^{(1)}","['integration', 'definite-integrals', 'closed-form', 'polygamma']"
77,"How to cure ""I don't appreciate Lebesgue integration because I was taught Riemannian integration throughout university""","How to cure ""I don't appreciate Lebesgue integration because I was taught Riemannian integration throughout university""",,"I was a physics major with applied computation EM background and throughout university I was only taught Riemannian integration. Every textbook I have read used Riemannian integrals (almost by default assumption). No measure theory were ever introduced. Only in grad school did I finally learn Lebesgue integration. But I cannot really appreciate all these beautiful theorems, etc. that can be done using Lebesgue integration because I have to teach other people using textbook written by authors who relies on Riemannian integral by default Many computation software packages seem to have built upon Riemannian integration by default. Too much overhead with Lebesgue integration. I feel like I always have to introduce measure theory (and getting all the miscellaneous technical things) to someone before I can talk about it. At the end of the day, if I were to calculate something, like flux through a plane, or anything involving complex contour integrals, I feel like I have to resort back to Riemannian integration (and the textbooks that base off of it) Is there anything that can be done in this situation for me to appreciate Lebesgue integration theory?","I was a physics major with applied computation EM background and throughout university I was only taught Riemannian integration. Every textbook I have read used Riemannian integrals (almost by default assumption). No measure theory were ever introduced. Only in grad school did I finally learn Lebesgue integration. But I cannot really appreciate all these beautiful theorems, etc. that can be done using Lebesgue integration because I have to teach other people using textbook written by authors who relies on Riemannian integral by default Many computation software packages seem to have built upon Riemannian integration by default. Too much overhead with Lebesgue integration. I feel like I always have to introduce measure theory (and getting all the miscellaneous technical things) to someone before I can talk about it. At the end of the day, if I were to calculate something, like flux through a plane, or anything involving complex contour integrals, I feel like I have to resort back to Riemannian integration (and the textbooks that base off of it) Is there anything that can be done in this situation for me to appreciate Lebesgue integration theory?",,"['integration', 'soft-question', 'lebesgue-integral', 'physics', 'math-software']"
78,Mnemonic for Integration by Parts formula?,Mnemonic for Integration by Parts formula?,,"The Integration by Parts formula may be stated as: $$\int uv' = uv - \int u'v.$$ I wonder if anyone has a clever mnemonic for the above formula. What I often do is to derive it from the Product Rule (for differentiation), but this isn't very efficient. One mnemonic I have come across is ""ultraviolet voodoo"", which works well if we instead write the formula as: $$\int u \ \textrm{d}v = uv - \int v \ \textrm{d}u.$$ I am however looking for a mnemonic for the first formula.","The Integration by Parts formula may be stated as: I wonder if anyone has a clever mnemonic for the above formula. What I often do is to derive it from the Product Rule (for differentiation), but this isn't very efficient. One mnemonic I have come across is ""ultraviolet voodoo"", which works well if we instead write the formula as: I am however looking for a mnemonic for the first formula.",\int uv' = uv - \int u'v. \int u \ \textrm{d}v = uv - \int v \ \textrm{d}u.,['integration']
79,"How to evaluate the integral $\int_{0}^{2\pi}e^{-iA(x\cos\varphi+y\sin\varphi)}\cos(l\varphi)\,d\varphi$?",How to evaluate the integral ?,"\int_{0}^{2\pi}e^{-iA(x\cos\varphi+y\sin\varphi)}\cos(l\varphi)\,d\varphi","$$\int_{0}^{2\pi}\exp\left(-iA(x\cos\varphi+y\sin\varphi)\right)\cos(l\varphi)\,d\varphi$$ I'm trying to evaluate the integral for an interference problem in Physics. When $y=0$, this reduces to the Bessel Function of the first kind, and when $l=1$, I can differentiate under the integral w.r.t. $x$ and evaluate the integral (which gives a first order Bessel function of the first kind). However, I'm looking for a more general answer, where $l$ is any integer, and $A$ is an arbitrary constant. Here's a link to a similar question posted 2 years ago. How to solve integral $\int_0^{2\pi} e^{i(a\cos\phi + b\sin\phi)} \cos\phi\ d\phi$","$$\int_{0}^{2\pi}\exp\left(-iA(x\cos\varphi+y\sin\varphi)\right)\cos(l\varphi)\,d\varphi$$ I'm trying to evaluate the integral for an interference problem in Physics. When $y=0$, this reduces to the Bessel Function of the first kind, and when $l=1$, I can differentiate under the integral w.r.t. $x$ and evaluate the integral (which gives a first order Bessel function of the first kind). However, I'm looking for a more general answer, where $l$ is any integer, and $A$ is an arbitrary constant. Here's a link to a similar question posted 2 years ago. How to solve integral $\int_0^{2\pi} e^{i(a\cos\phi + b\sin\phi)} \cos\phi\ d\phi$",,"['integration', 'definite-integrals', 'bessel-functions']"
80,Integration with respect to sum of signed measures.,Integration with respect to sum of signed measures.,,"Consider two finite signed measures $\mu$ and $\nu$ on a measurable space and a measurable mapping $f$ integrable with respect to both measure. The Jordan-Hahn decomposition yields $$ \mu= \mu^+ - \mu^-, \quad \quad\text{and} \quad \quad  \nu=\nu^+-\nu^-. $$  We know that in general $(\mu+\nu)^+ \not = \mu^+ +\nu^+$ and $(\mu+\nu)^-\not= \mu^-+\nu^-$, but can I say that $$ \int f d(\mu+\nu) \stackrel{?}{=} \int fd(\mu^++\nu^+) -\int f d(\mu^-+\nu^-). $$ I have found two counterexamples for $\theta^+  = \mu^+ +\nu^+$ and $\theta^-= \mu^-+\nu^-$, but these examples still satisfy the above equality: $\mu=\delta_a-\delta_b$, $\nu=\delta_b -\delta_c$, such that $(\mu+\nu)^+ =\delta_a \not = \delta_a+\delta_b$ and $(\mu+\nu)^- = \delta_c \not = \delta_b+\delta_c$, but in this case we see that $$ \int f d(\mu+\nu)= \int f d\delta_a - \int f d\delta_c = \int f d\delta_a +\int f d\delta_b - \int f d\delta_b- \int f d\delta_c $$ $$ = \int fd(\mu^++\nu^+) - \int f d(\mu^-+\nu^-) $$ so the equality still holds. Non-zero measures with $\mu=-\nu$, such that $(\mu+\nu)^+=0\not = \mu^++\nu^+$  and $(\mu+\nu)^-=0\not = \mu^-+\nu^-$, but $$ \int f d(\mu+\nu) =0 $$ and we have that $\mu^+=\nu^-$ and $\mu^-=\nu^+$, yielding that $$ \int fd\mu^+ -\int f d\mu^-+\int fd\nu^+ -\int fd\nu^- = \int fd\mu^+ -\int f d\mu^-+\int fd\mu^- -\int fd\mu^+ =0, $$ so equality still holds. This gives me reason to to thinks that the equality holds. Can anyone please help me understand why the equality holds, or at least give me a counterexample for which it does not hold?","Consider two finite signed measures $\mu$ and $\nu$ on a measurable space and a measurable mapping $f$ integrable with respect to both measure. The Jordan-Hahn decomposition yields $$ \mu= \mu^+ - \mu^-, \quad \quad\text{and} \quad \quad  \nu=\nu^+-\nu^-. $$  We know that in general $(\mu+\nu)^+ \not = \mu^+ +\nu^+$ and $(\mu+\nu)^-\not= \mu^-+\nu^-$, but can I say that $$ \int f d(\mu+\nu) \stackrel{?}{=} \int fd(\mu^++\nu^+) -\int f d(\mu^-+\nu^-). $$ I have found two counterexamples for $\theta^+  = \mu^+ +\nu^+$ and $\theta^-= \mu^-+\nu^-$, but these examples still satisfy the above equality: $\mu=\delta_a-\delta_b$, $\nu=\delta_b -\delta_c$, such that $(\mu+\nu)^+ =\delta_a \not = \delta_a+\delta_b$ and $(\mu+\nu)^- = \delta_c \not = \delta_b+\delta_c$, but in this case we see that $$ \int f d(\mu+\nu)= \int f d\delta_a - \int f d\delta_c = \int f d\delta_a +\int f d\delta_b - \int f d\delta_b- \int f d\delta_c $$ $$ = \int fd(\mu^++\nu^+) - \int f d(\mu^-+\nu^-) $$ so the equality still holds. Non-zero measures with $\mu=-\nu$, such that $(\mu+\nu)^+=0\not = \mu^++\nu^+$  and $(\mu+\nu)^-=0\not = \mu^-+\nu^-$, but $$ \int f d(\mu+\nu) =0 $$ and we have that $\mu^+=\nu^-$ and $\mu^-=\nu^+$, yielding that $$ \int fd\mu^+ -\int f d\mu^-+\int fd\nu^+ -\int fd\nu^- = \int fd\mu^+ -\int f d\mu^-+\int fd\mu^- -\int fd\mu^+ =0, $$ so equality still holds. This gives me reason to to thinks that the equality holds. Can anyone please help me understand why the equality holds, or at least give me a counterexample for which it does not hold?",,"['integration', 'analysis', 'measure-theory', 'lebesgue-integral']"
81,"""minimal"" conditions for Leibniz Rule for changing the integral and derivative","""minimal"" conditions for Leibniz Rule for changing the integral and derivative",,"I am trying to find ""minimal"" conditions for Leibniz Rule: $$\dfrac{d}{dx}\left(\displaystyle\int_{a}^{b}f(x,y)\;dy\right)=\displaystyle\int_{a}^{b}f_x(x,y)\;dy.$$ Let $$F(x)=\displaystyle\int_{a}^{b}f(x,y)\;dy,$$ which is a single variable function. Let us take the derivative of $F(x)$ using the definition of derivative: $$\dfrac{d}{dx}F(x)=\lim\limits_{h\to0}\dfrac{\displaystyle\int_{a}^{b}f(x+h,y)dy-\displaystyle\int_{a}^{b}f(x,y)dy}{h}$$ $$=\lim\limits_{h\to0}\dfrac{\displaystyle\int_{a}^{b}(f(x+h,y)-f(x,y))dy}{h}$$ $$=\lim\limits_{h\to0}\displaystyle\int_{a}^{b}\dfrac{f(x+h,y)-f(x,y)}{h}dy.$$ To rest of prove, I want to continue with definition of limit: Given $\epsilon>0$. I need to find $\delta >0$ such that if $$|h|<\delta,$$ then $$\left|\displaystyle\int_{a}^{b}\dfrac{f(x+h,y)-f(x,y)}{h}dy-\displaystyle\int_{a}^{b}f_x(x,y)dy\right|$$$$=\left|\displaystyle\int_{a}^{b}\left[\dfrac{f(x+h,y)-f(x,y)}{h}-f_x(x,y) \right]dy\right|<\epsilon.$$ I know that $$\left|\displaystyle\int_{a}^{b}\left[\dfrac{f(x+h,y)-f(x,y)}{h}-f_x(x,y) \right]dy\right|\le \displaystyle\int_{a}^{b}\left|\dfrac{f(x+h,y)-f(x,y)}{h}-f_x(x,y) \right|dy.$$ Therefore, I want to continue with this inequality. If I will find a $\delta>0$ for all $y\in[a,b]$ such that $$\left|\dfrac{f(x+h,y)-f(x,y)}{h}-f_x(x,y) \right|<\frac{\epsilon}{b-a}$$ whenever $|h|<\delta$, then the  proof will complete. First Attempt: (Uniformly Continuous) If $f_x(x,y)$ is continuous on $C\times[a,b]$ where $x\in C$ is a closed interval having more than one element, then it will be uniformly continuous and so we can find such $\delta>0$. Second Attempt: If $f_x(x,y)$ is piece-wise continuous on $y$, we can separate the integral and make the pieces continuous and then apply the First Attempt to the pieces. (I wrote that proof by myself. Am I correct with this proof; and are the Attempts correct?) How can I make the conditions weaker? (Please don't say dominated convergence theorem directly, I am trying to understand proofs). Thanks for help in advance.","I am trying to find ""minimal"" conditions for Leibniz Rule: $$\dfrac{d}{dx}\left(\displaystyle\int_{a}^{b}f(x,y)\;dy\right)=\displaystyle\int_{a}^{b}f_x(x,y)\;dy.$$ Let $$F(x)=\displaystyle\int_{a}^{b}f(x,y)\;dy,$$ which is a single variable function. Let us take the derivative of $F(x)$ using the definition of derivative: $$\dfrac{d}{dx}F(x)=\lim\limits_{h\to0}\dfrac{\displaystyle\int_{a}^{b}f(x+h,y)dy-\displaystyle\int_{a}^{b}f(x,y)dy}{h}$$ $$=\lim\limits_{h\to0}\dfrac{\displaystyle\int_{a}^{b}(f(x+h,y)-f(x,y))dy}{h}$$ $$=\lim\limits_{h\to0}\displaystyle\int_{a}^{b}\dfrac{f(x+h,y)-f(x,y)}{h}dy.$$ To rest of prove, I want to continue with definition of limit: Given $\epsilon>0$. I need to find $\delta >0$ such that if $$|h|<\delta,$$ then $$\left|\displaystyle\int_{a}^{b}\dfrac{f(x+h,y)-f(x,y)}{h}dy-\displaystyle\int_{a}^{b}f_x(x,y)dy\right|$$$$=\left|\displaystyle\int_{a}^{b}\left[\dfrac{f(x+h,y)-f(x,y)}{h}-f_x(x,y) \right]dy\right|<\epsilon.$$ I know that $$\left|\displaystyle\int_{a}^{b}\left[\dfrac{f(x+h,y)-f(x,y)}{h}-f_x(x,y) \right]dy\right|\le \displaystyle\int_{a}^{b}\left|\dfrac{f(x+h,y)-f(x,y)}{h}-f_x(x,y) \right|dy.$$ Therefore, I want to continue with this inequality. If I will find a $\delta>0$ for all $y\in[a,b]$ such that $$\left|\dfrac{f(x+h,y)-f(x,y)}{h}-f_x(x,y) \right|<\frac{\epsilon}{b-a}$$ whenever $|h|<\delta$, then the  proof will complete. First Attempt: (Uniformly Continuous) If $f_x(x,y)$ is continuous on $C\times[a,b]$ where $x\in C$ is a closed interval having more than one element, then it will be uniformly continuous and so we can find such $\delta>0$. Second Attempt: If $f_x(x,y)$ is piece-wise continuous on $y$, we can separate the integral and make the pieces continuous and then apply the First Attempt to the pieces. (I wrote that proof by myself. Am I correct with this proof; and are the Attempts correct?) How can I make the conditions weaker? (Please don't say dominated convergence theorem directly, I am trying to understand proofs). Thanks for help in advance.",,"['integration', 'derivatives']"
82,"Continuous but not compact operator on $L^2(0,\infty)$",Continuous but not compact operator on,"L^2(0,\infty)","Define the following operator on $L^2(0,\infty)$: $$Tf(x)=\frac{1}{x} \int_0^xf(y)dy,\quad f\in L^2(0\infty).$$ I would like to see that it is continuous but not compact. So, this is an integral operator with kernel $k(x,y)=\frac{1}{x}\mathbf1_{(0,x)}(y)$. The problem is that $k$ is not even in $L^2(0,\infty)^2$. Thus, the usual bound $\|Tf\|_2\leq \|k\|_2\cdot \|f\|_2$ does not work. Hence I am not even sure why the operator is well-defined. I.e. why is $Tf$ even in $L^2(0,\infty)$? And how might we show continuity/non-compactness?","Define the following operator on $L^2(0,\infty)$: $$Tf(x)=\frac{1}{x} \int_0^xf(y)dy,\quad f\in L^2(0\infty).$$ I would like to see that it is continuous but not compact. So, this is an integral operator with kernel $k(x,y)=\frac{1}{x}\mathbf1_{(0,x)}(y)$. The problem is that $k$ is not even in $L^2(0,\infty)^2$. Thus, the usual bound $\|Tf\|_2\leq \|k\|_2\cdot \|f\|_2$ does not work. Hence I am not even sure why the operator is well-defined. I.e. why is $Tf$ even in $L^2(0,\infty)$? And how might we show continuity/non-compactness?",,"['integration', 'functional-analysis', 'operator-theory']"
83,Integral $\int_0^\frac{\pi}{2} \left(\operatorname{chi}(\cot^2x)+\text{shi}(\cot^2x)\right)\csc^2(x)e^{-\csc^2(x)}dx$,Integral,\int_0^\frac{\pi}{2} \left(\operatorname{chi}(\cot^2x)+\text{shi}(\cot^2x)\right)\csc^2(x)e^{-\csc^2(x)}dx,The following problem was posted here a while ago by Cornel Ioan Valean. Evaluate: $$\int_0^\frac{\pi}{2} [\text{chi}(\cot^2x)+\text{shi}(\cot^2 x)]\csc^2(x)e^{-\csc^2(x)}dx$$ where $\operatorname{shi}(x)=\int_{0}^{x}\frac{\sinh t}{t}dt$ and $\operatorname{chi}(x)=\gamma +\log(x)+\int_{0}^{x}\frac{\cosh(t)-1}{t} dt.$ I have tried to use integral by parts but I didn't succeed as I crossed this: $$\int_0^\frac{\pi}{2}\csc^2(x)e^{-\csc^2(x)}dx$$ Which is: $\frac {\sqrt{\pi}}{2e}.$ I don't know how I can complete integration by parts since it doesn't have a closed form. Note : I guess this integral is $0$ (integration over closed path).,The following problem was posted here a while ago by Cornel Ioan Valean. Evaluate: where and I have tried to use integral by parts but I didn't succeed as I crossed this: Which is: I don't know how I can complete integration by parts since it doesn't have a closed form. Note : I guess this integral is (integration over closed path).,\int_0^\frac{\pi}{2} [\text{chi}(\cot^2x)+\text{shi}(\cot^2 x)]\csc^2(x)e^{-\csc^2(x)}dx \operatorname{shi}(x)=\int_{0}^{x}\frac{\sinh t}{t}dt \operatorname{chi}(x)=\gamma +\log(x)+\int_{0}^{x}\frac{\cosh(t)-1}{t} dt. \int_0^\frac{\pi}{2}\csc^2(x)e^{-\csc^2(x)}dx \frac {\sqrt{\pi}}{2e}. 0,"['integration', 'trigonometry', 'proof-verification', 'definite-integrals']"
84,Showing the Riemann integral is a linear operator over step functions,Showing the Riemann integral is a linear operator over step functions,,"Given an interval $[a,b]$, let $S[a,b]$ be the set of all step functions for all possible finite partitions of $[a,b]$. Given a partition $x_0,\dots, x_n$ of $[a,b]$, define $\chi_i$ as the characteristic function on $[x_{i-1},x_i)$. For the step function $\sum_{i=1} ^ns_i\chi_i(x)$, define $I\Big(\sum_{i=1} ^ns_i\chi_i(x)\Big)=\sum_{i=1} ^ns_i(x_i-x_{i-1})$. I am having difficulty showing $I$ is linear. Given two partitions $x_0,\ldots, x_n$ and $y_0,\ldots, y_m$, how can I show $$I\Big(\alpha\sum_{i=1}^ns_i\chi_i(x)+\beta\sum_{i=1}^mt_i \chi_i(x)\Big)=\alpha I\Big(\sum_{i=1}^ns_i\chi_i(x) \Big)+\beta I\Big(\sum_{i=1}^m t_i\chi_i(x)\Big)$$ I tried to write  $\alpha\sum_{i=1}^ns_i\chi_i(x)+\beta\sum_{i=1}^mt_i \chi_i(x)$ as a single sum $\delta\sum_{i=1}^lr_i\chi_i(x)$, but I don't see how to relate $\gamma$ to $\alpha, \beta$, how to relate $l$ to $m,n$, etc.","Given an interval $[a,b]$, let $S[a,b]$ be the set of all step functions for all possible finite partitions of $[a,b]$. Given a partition $x_0,\dots, x_n$ of $[a,b]$, define $\chi_i$ as the characteristic function on $[x_{i-1},x_i)$. For the step function $\sum_{i=1} ^ns_i\chi_i(x)$, define $I\Big(\sum_{i=1} ^ns_i\chi_i(x)\Big)=\sum_{i=1} ^ns_i(x_i-x_{i-1})$. I am having difficulty showing $I$ is linear. Given two partitions $x_0,\ldots, x_n$ and $y_0,\ldots, y_m$, how can I show $$I\Big(\alpha\sum_{i=1}^ns_i\chi_i(x)+\beta\sum_{i=1}^mt_i \chi_i(x)\Big)=\alpha I\Big(\sum_{i=1}^ns_i\chi_i(x) \Big)+\beta I\Big(\sum_{i=1}^m t_i\chi_i(x)\Big)$$ I tried to write  $\alpha\sum_{i=1}^ns_i\chi_i(x)+\beta\sum_{i=1}^mt_i \chi_i(x)$ as a single sum $\delta\sum_{i=1}^lr_i\chi_i(x)$, but I don't see how to relate $\gamma$ to $\alpha, \beta$, how to relate $l$ to $m,n$, etc.",,"['integration', 'linear-transformations', 'riemann-sum']"
85,To what fractional Sobolev spaces does the step function belong? (Sobolev-Slobodeckij norm of step function),To what fractional Sobolev spaces does the step function belong? (Sobolev-Slobodeckij norm of step function),,"I'm new to fractional Sobolev spaces and I'm curious about the regularity of some simple functions like e.$\,$g. step functions in order to understand these spaces better. In more detail, for $\Omega = [-1,1]^n \subseteq \mathbb{R^n}$ and $A = [-\frac{1}{2},\frac{1}{2}]^n\subseteq \Omega$ consider the function $$ \begin{align} f \colon \ \Omega & \longrightarrow \mathbb{R} \\ x & \longmapsto \begin{cases} 1 & \text{ for } x \in A \\ 0 & \text{ for } x \notin A\text{.}\end{cases} \end{align} $$ For which $s \in [0,1]$ does $f$ have a finite Sobolev-Slobodeckij norm? The norm that is meant here is defined by $$ \Vert f\Vert_{s}^2 := \int_\Omega \int_\Omega \frac{\vert f(x) - f(y)\vert^2}{\Vert x-y\Vert^{2s+n}} \, \mathrm{d}x \, \mathrm{d}y\text{.} $$ Is there a way to determine the value of the integral analytically in dependence of $n$ and $s$? Or can one at least easily determine those $s$ for which this integral would be finite? Can it at least be done for $n=2$? So far I tried the simple case $n=1$ for which I get that $s\in [0,\frac{1}{2})$ has to be fulfilled. I expect that to be the case for any $n$ but at the moment I'm not quite sure since I did not prove it. For $n=2$ I would try to integrate by hand but with my approach it's about to become a rather long calculation. Is there maybe an elegant way to do it? I don't mind if $A$ is replaced by another set like for example a scaled $n$-Sphere or some simplex.","I'm new to fractional Sobolev spaces and I'm curious about the regularity of some simple functions like e.$\,$g. step functions in order to understand these spaces better. In more detail, for $\Omega = [-1,1]^n \subseteq \mathbb{R^n}$ and $A = [-\frac{1}{2},\frac{1}{2}]^n\subseteq \Omega$ consider the function $$ \begin{align} f \colon \ \Omega & \longrightarrow \mathbb{R} \\ x & \longmapsto \begin{cases} 1 & \text{ for } x \in A \\ 0 & \text{ for } x \notin A\text{.}\end{cases} \end{align} $$ For which $s \in [0,1]$ does $f$ have a finite Sobolev-Slobodeckij norm? The norm that is meant here is defined by $$ \Vert f\Vert_{s}^2 := \int_\Omega \int_\Omega \frac{\vert f(x) - f(y)\vert^2}{\Vert x-y\Vert^{2s+n}} \, \mathrm{d}x \, \mathrm{d}y\text{.} $$ Is there a way to determine the value of the integral analytically in dependence of $n$ and $s$? Or can one at least easily determine those $s$ for which this integral would be finite? Can it at least be done for $n=2$? So far I tried the simple case $n=1$ for which I get that $s\in [0,\frac{1}{2})$ has to be fulfilled. I expect that to be the case for any $n$ but at the moment I'm not quite sure since I did not prove it. For $n=2$ I would try to integrate by hand but with my approach it's about to become a rather long calculation. Is there maybe an elegant way to do it? I don't mind if $A$ is replaced by another set like for example a scaled $n$-Sphere or some simplex.",,"['integration', 'sobolev-spaces']"
86,"Concerning Hurwitz Zeta function, how to prove the following identity?","Concerning Hurwitz Zeta function, how to prove the following identity?",,"It is claimed that $$\zeta'(0,s)=\ln\left(\frac{\Gamma(s)}{\sqrt{2\pi}}\right)$$ where the derivative is meant by the first argument (as usual with Hurwitz Zeta). How to prove this? Wolfram Alpha confirms this: http://www.wolframalpha.com/input/?i=D[HurwitzZeta[s%2C+p]%2C+s]+at+s%3D0 but I have no other clue. Is there a more general form of the identity (with a variable instead of 0)?","It is claimed that $$\zeta'(0,s)=\ln\left(\frac{\Gamma(s)}{\sqrt{2\pi}}\right)$$ where the derivative is meant by the first argument (as usual with Hurwitz Zeta). How to prove this? Wolfram Alpha confirms this: http://www.wolframalpha.com/input/?i=D[HurwitzZeta[s%2C+p]%2C+s]+at+s%3D0 but I have no other clue. Is there a more general form of the identity (with a variable instead of 0)?",,"['integration', 'special-functions', 'gamma-function', 'zeta-functions']"
87,Why is area of a surface of revolution integral $2\pi y~ds$? not '$dx$'? [duplicate],Why is area of a surface of revolution integral ? not ''? [duplicate],2\pi y~ds dx,"This question already has answers here : Areas versus volumes of revolution: why does the area require approximation by a cone? (4 answers) Closed 4 years ago . For me, intuitively, integral $2\pi y~dx$ make more sense. I know intuition can not be proof, but by far, most part of math I've learned does match with my intuition. So, I think this one should 'make sense' as well. Probably I didn't understand the way surface area is measured. It will be great if any one could tell me how 'integral $2\pi y~dx$' is wrong. (By the way, how to use mathematical symbols in texts?)","This question already has answers here : Areas versus volumes of revolution: why does the area require approximation by a cone? (4 answers) Closed 4 years ago . For me, intuitively, integral $2\pi y~dx$ make more sense. I know intuition can not be proof, but by far, most part of math I've learned does match with my intuition. So, I think this one should 'make sense' as well. Probably I didn't understand the way surface area is measured. It will be great if any one could tell me how 'integral $2\pi y~dx$' is wrong. (By the way, how to use mathematical symbols in texts?)",,"['integration', 'surfaces']"
88,Integral $\int^{1}_{-1} \frac{\ln(ax^2+2bx+a)}{x^2+1}dx$ if $a>b>0$,Integral  if,\int^{1}_{-1} \frac{\ln(ax^2+2bx+a)}{x^2+1}dx a>b>0,"I am trying to evaluate the following integral: $$\int^{1}_{-1} \frac{\ln(ax^2+2bx+a)}{x^2+1}dx,$$ where $a>b>0$ . I can't really think of a way to find it. So, please give me a hint.","I am trying to evaluate the following integral: where . I can't really think of a way to find it. So, please give me a hint.","\int^{1}_{-1} \frac{\ln(ax^2+2bx+a)}{x^2+1}dx, a>b>0",['integration']
89,A Sine integral: problem I,A Sine integral: problem I,,"Is it possible to demonstrate a solution for the integral \begin{align} \int_{0}^{\infty} x^{n} \, \sin\left( a x^{2} + \frac{b}{x^{2}} \right) \, dx  \end{align}","Is it possible to demonstrate a solution for the integral \begin{align} \int_{0}^{\infty} x^{n} \, \sin\left( a x^{2} + \frac{b}{x^{2}} \right) \, dx  \end{align}",,"['integration', 'definite-integrals', 'gamma-function', 'hypergeometric-function']"
90,Solving a tough integral,Solving a tough integral,,"I am studying telecommunications theory and I was doing an exercise where it's required to find the (infinite) taps of a zero forcing equalizer. Here's the point where I am stuck at: $$ p_\ell=T\int_{-\frac{1}{2T}}^{\frac{1}{2T}}\frac{e^{j2\pi f\ell T}}{1+\alpha e^{-j2\pi fT}}df $$ Where: $\ell\in \mathbb{Z}$ $0<\alpha<\frac{1}{2}$ $T>0$ $T,\alpha\in\mathbb{R}$ That comes out because the channel time domain response is: $$ g(t)=\delta(t)+\alpha\delta(t-T) $$ And its fourier transform of course is: $$ G(f)=1+\alpha e^{-j2\pi fT} $$ In a ZF equalizer it is required that the total f-response of the channel and equalizer is unity, i.e. $ P(f)\cdot G(f)=1 $, so to find the $p_\ell$ sequence one has to anti-transform $\frac{1}{G(f)}$. It doesn't look to me I've done any errors before the integral but I don't have a clue on how to solve it, if possible. Some help/hints would be very appreciated. Thanks to PhoemueX answer : $$ \frac{1}{1 + \alpha e^{-2\pi i f T}} = \frac{1}{1 - (- \alpha e^{-2\pi i f T})} = \sum_{n=0}^{\infty} (-\alpha \cdot e^{-2\pi i f T})^n, $$ So let's start rocking: $$ p_\ell=T\int_{-\frac{1}{2T}}^{\frac{1}{2T}}e^{j2\pi f\ell T}\sum_{n=0}^{\infty} (-\alpha \cdot e^{-2\pi i f T})^ndf=\\ =T\sum_{n=0}^{\infty}\int_{-\frac{1}{2T}}^{\frac{1}{2T}}(-\alpha)^ne^{j2\pi f T(\ell-n)}df=\\ =\frac{T}{j2\pi T}\sum_{n=0}^{\infty}\frac{(-\alpha)^n}{\ell-n} \left(e^{j\pi(\ell-n)}-e^{-j\pi(\ell-n)}\right)=\\ =\frac{2j}{2j\pi}\sum_{n=0}^{\infty}(-\alpha)^n\frac{\sin[\pi(\ell-n)]}{\ell-n}=\\ =\sum_{n=0}^{\infty}(-\alpha)^n\text{sinc}(\ell-n) $$ That last line equals zero whenever $\ell\neq n$, while when $\ell=n$ the sinc is not defined. We can not compute the limit because that is nonsense in $\mathbb{Z}$ but looking at the second equation we can see that when $\ell=n$ the integral becomes trivial and that sum equals $(-\alpha)^\ell$ To sum up: $$ p_\ell=(-\alpha)^\ell $$ Math is awesome.","I am studying telecommunications theory and I was doing an exercise where it's required to find the (infinite) taps of a zero forcing equalizer. Here's the point where I am stuck at: $$ p_\ell=T\int_{-\frac{1}{2T}}^{\frac{1}{2T}}\frac{e^{j2\pi f\ell T}}{1+\alpha e^{-j2\pi fT}}df $$ Where: $\ell\in \mathbb{Z}$ $0<\alpha<\frac{1}{2}$ $T>0$ $T,\alpha\in\mathbb{R}$ That comes out because the channel time domain response is: $$ g(t)=\delta(t)+\alpha\delta(t-T) $$ And its fourier transform of course is: $$ G(f)=1+\alpha e^{-j2\pi fT} $$ In a ZF equalizer it is required that the total f-response of the channel and equalizer is unity, i.e. $ P(f)\cdot G(f)=1 $, so to find the $p_\ell$ sequence one has to anti-transform $\frac{1}{G(f)}$. It doesn't look to me I've done any errors before the integral but I don't have a clue on how to solve it, if possible. Some help/hints would be very appreciated. Thanks to PhoemueX answer : $$ \frac{1}{1 + \alpha e^{-2\pi i f T}} = \frac{1}{1 - (- \alpha e^{-2\pi i f T})} = \sum_{n=0}^{\infty} (-\alpha \cdot e^{-2\pi i f T})^n, $$ So let's start rocking: $$ p_\ell=T\int_{-\frac{1}{2T}}^{\frac{1}{2T}}e^{j2\pi f\ell T}\sum_{n=0}^{\infty} (-\alpha \cdot e^{-2\pi i f T})^ndf=\\ =T\sum_{n=0}^{\infty}\int_{-\frac{1}{2T}}^{\frac{1}{2T}}(-\alpha)^ne^{j2\pi f T(\ell-n)}df=\\ =\frac{T}{j2\pi T}\sum_{n=0}^{\infty}\frac{(-\alpha)^n}{\ell-n} \left(e^{j\pi(\ell-n)}-e^{-j\pi(\ell-n)}\right)=\\ =\frac{2j}{2j\pi}\sum_{n=0}^{\infty}(-\alpha)^n\frac{\sin[\pi(\ell-n)]}{\ell-n}=\\ =\sum_{n=0}^{\infty}(-\alpha)^n\text{sinc}(\ell-n) $$ That last line equals zero whenever $\ell\neq n$, while when $\ell=n$ the sinc is not defined. We can not compute the limit because that is nonsense in $\mathbb{Z}$ but looking at the second equation we can see that when $\ell=n$ the integral becomes trivial and that sum equals $(-\alpha)^\ell$ To sum up: $$ p_\ell=(-\alpha)^\ell $$ Math is awesome.",,"['integration', 'fourier-analysis']"
91,"Integral with parameter: $\int_{0}^{\pi/2}\frac{\sin \left ( ax \right )}{\sin x\ +\ \cos x}\, {\rm d}x $",Integral with parameter:,"\int_{0}^{\pi/2}\frac{\sin \left ( ax \right )}{\sin x\ +\ \cos x}\, {\rm d}x ","Is it possible to express in a closed form the integral $$\int_{0}^{\pi/2}\frac{\sin \left ( ax \right )}{\sin x+\cos x}\, {\rm d}x,\,\,\, a\in \mathbb{N}\quad?$$ Well, I find it very difficult. Well, I know how to express the integral $$\int_{0}^{\pi/2}\frac{\sin x}{\sin x+\cos x}\,{\rm d}x \;=\; \int_{0}^{\pi/2}\frac{\cos x}{\sin x+\cos x}\, {\rm d}x\;=\;\frac{\pi}{4}$$ by applying the substitution $u=\frac{\pi}{2}-x$ , but in general I don't have a clue. If someone could help me, that would be nice!","Is it possible to express in a closed form the integral Well, I find it very difficult. Well, I know how to express the integral by applying the substitution , but in general I don't have a clue. If someone could help me, that would be nice!","\int_{0}^{\pi/2}\frac{\sin \left ( ax \right )}{\sin x+\cos x}\, {\rm d}x,\,\,\, a\in \mathbb{N}\quad? \int_{0}^{\pi/2}\frac{\sin x}{\sin x+\cos x}\,{\rm d}x \;=\; \int_{0}^{\pi/2}\frac{\cos x}{\sin x+\cos x}\, {\rm d}x\;=\;\frac{\pi}{4} u=\frac{\pi}{2}-x","['integration', 'analysis', 'definite-integrals', 'trigonometric-integrals']"
92,Why is $\displaystyle\int^{\infty}_{0}{(1-\cos x)\over{x^{2}}}dx = \frac\pi{2}$?,Why is ?,\displaystyle\int^{\infty}_{0}{(1-\cos x)\over{x^{2}}}dx = \frac\pi{2},"I have been having trouble understanding Fourier series and analysis in one of my classes. This is one problem from the text and we have to show that this is true. I have done other problems related to this one, but they do not help me. I tried to solve this manually and it has come to naught. As there is already the answer, I would like an explanation so that I may understand this material better. Thanks for all the help. $$\int^{\infty}_{0}{(1-\cos x)\over{x^{2}}}dx = \frac\pi{2}$$ This is the integral for reference.","I have been having trouble understanding Fourier series and analysis in one of my classes. This is one problem from the text and we have to show that this is true. I have done other problems related to this one, but they do not help me. I tried to solve this manually and it has come to naught. As there is already the answer, I would like an explanation so that I may understand this material better. Thanks for all the help. $$\int^{\infty}_{0}{(1-\cos x)\over{x^{2}}}dx = \frac\pi{2}$$ This is the integral for reference.",,"['integration', 'trigonometry', 'definite-integrals']"
93,Integral calculation,Integral calculation,,"I have a power spectral density function of the form $$S(\omega) = \frac{a}{(\omega^2-K^2)^2 + K^2 h^2 \omega^2},$$ in which $a, K, h$ are some positive constants. I want to calculate the corresponding spatial correlation  function which is defined as follows: $$R(x) = \int_{0}^{+\infty} \frac{\sin(\omega x) \omega \, d\omega}{(\omega^2-K^2)^2 + K^2 h^2 \omega^2}.$$ Does anyone have an idea about how to calculate this integral? Thanks in advance.","I have a power spectral density function of the form $$S(\omega) = \frac{a}{(\omega^2-K^2)^2 + K^2 h^2 \omega^2},$$ in which $a, K, h$ are some positive constants. I want to calculate the corresponding spatial correlation  function which is defined as follows: $$R(x) = \int_{0}^{+\infty} \frac{\sin(\omega x) \omega \, d\omega}{(\omega^2-K^2)^2 + K^2 h^2 \omega^2}.$$ Does anyone have an idea about how to calculate this integral? Thanks in advance.",,['integration']
94,"Proving $\int^{\infty}_0 \cos(tx)\left (\frac{\sin(t)}{t} \right )^n \, dt = 0$",Proving,"\int^{\infty}_0 \cos(tx)\left (\frac{\sin(t)}{t} \right )^n \, dt = 0","I've been asked to prove that $$ \int^\infty_0 \cos(tx)\left (\frac{\sin(t)}{t} \right )^n \, dt = 0, \space \forall x > n \geq 2.$$ My approach so far has been to use a theorem proved in class that, for a random variable $X$ with characteristic function $\phi(t)$ and $a,b\in\mathbb{R}$, $$ \mathbb{P}(a<X<b) + \frac{\mathbb{P}(X=a) + \mathbb{P}(X=b)}{2} = \lim_{T \to \infty} \frac{1}{2\pi}\int^{T}_{-T}\frac{e^{-ita}+e^{-itb}}{it}\phi(t)\,dt.$$ So, choosing $a = -b$, I get $$\mathbb{P}(|X| \leq b) =  \lim_{T \to \infty} \frac{1}{\pi}\int^{T}_{-T}\frac{\sin(t)}{t}\phi(t)\,dt$$ which makes it seem like I need to find a random variable that satisfies $\phi(t)$ and $\mathbb{P}(|X|<b)=0$... but I'm losing confidence in this approach, since it doesn't account for why $x > n \geq 2$ is required or incorporate the behavior of $\left(\frac{\sin t}{t}\right)^n$. A solution using probability techniques would be preferable to pure analysis, but all help is appreciated.","I've been asked to prove that $$ \int^\infty_0 \cos(tx)\left (\frac{\sin(t)}{t} \right )^n \, dt = 0, \space \forall x > n \geq 2.$$ My approach so far has been to use a theorem proved in class that, for a random variable $X$ with characteristic function $\phi(t)$ and $a,b\in\mathbb{R}$, $$ \mathbb{P}(a<X<b) + \frac{\mathbb{P}(X=a) + \mathbb{P}(X=b)}{2} = \lim_{T \to \infty} \frac{1}{2\pi}\int^{T}_{-T}\frac{e^{-ita}+e^{-itb}}{it}\phi(t)\,dt.$$ So, choosing $a = -b$, I get $$\mathbb{P}(|X| \leq b) =  \lim_{T \to \infty} \frac{1}{\pi}\int^{T}_{-T}\frac{\sin(t)}{t}\phi(t)\,dt$$ which makes it seem like I need to find a random variable that satisfies $\phi(t)$ and $\mathbb{P}(|X|<b)=0$... but I'm losing confidence in this approach, since it doesn't account for why $x > n \geq 2$ is required or incorporate the behavior of $\left(\frac{\sin t}{t}\right)^n$. A solution using probability techniques would be preferable to pure analysis, but all help is appreciated.",,"['integration', 'analysis', 'probability-theory', 'definite-integrals']"
95,Show that $\int_{0}^{1}{\frac{\sin{x}}{x}\mathrm dx}$ converges,Show that  converges,\int_{0}^{1}{\frac{\sin{x}}{x}\mathrm dx},"As title says, I need to show that the following integral converges, and I can honestly say I don't really have an idea of where to start. I tried evaluating it using integration by parts, but that only left me with an $I = I$ situation. $$\int \limits_{0}^{1}{\frac{\sin{x}}{x} \mathrm dx}$$","As title says, I need to show that the following integral converges, and I can honestly say I don't really have an idea of where to start. I tried evaluating it using integration by parts, but that only left me with an $I = I$ situation. $$\int \limits_{0}^{1}{\frac{\sin{x}}{x} \mathrm dx}$$",,[]
96,Highly Oscillating Integrals,Highly Oscillating Integrals,,"I'd like to know the behavior of integrals of the form: $$  \int_0^1 f(x) \cos(k x) dx $$ as $ k \rightarrow \infty $ where f is a smooth function. It is easy to see, by expanding f in power series, that the integral is bounded by $ \approx \frac{1}{k} $, but I'd like to know the coefficient. Is there some way to know this easily?","I'd like to know the behavior of integrals of the form: $$  \int_0^1 f(x) \cos(k x) dx $$ as $ k \rightarrow \infty $ where f is a smooth function. It is easy to see, by expanding f in power series, that the integral is bounded by $ \approx \frac{1}{k} $, but I'd like to know the coefficient. Is there some way to know this easily?",,"['analysis', 'integration', 'fourier-analysis']"
97,Stokes' Theorem Example,Stokes' Theorem Example,,"I am reading Wade's Introduction to Analysis .  One of the exercises is to show that  $$ \int_{\partial M}\sum_{k=1}^n \, dx_1dx_2\cdots \hat{dx_i}\cdots dx_n $$ is equal to the volume of $M$ if $n$ is odd and $0$ if $n$ is even. Let's take $n=3$.  Then the integral is $$ \int_{\partial M}\,dydz+dxdz+dxdy $$ By Stokes' Theorem we can take the differential of  $$ \omega=dydz+dxdz+dxdy $$ and integrate it over all of $M$.  My question is why $d\omega\neq 0$.  Shouldn't I be taking partial derivatives of $1$, which would all be $0$?","I am reading Wade's Introduction to Analysis .  One of the exercises is to show that  $$ \int_{\partial M}\sum_{k=1}^n \, dx_1dx_2\cdots \hat{dx_i}\cdots dx_n $$ is equal to the volume of $M$ if $n$ is odd and $0$ if $n$ is even. Let's take $n=3$.  Then the integral is $$ \int_{\partial M}\,dydz+dxdz+dxdy $$ By Stokes' Theorem we can take the differential of  $$ \omega=dydz+dxdz+dxdy $$ and integrate it over all of $M$.  My question is why $d\omega\neq 0$.  Shouldn't I be taking partial derivatives of $1$, which would all be $0$?",,"['multivariable-calculus', 'integration']"
98,"Finding the Moment Generating Function of $X^2$ when $X\sim N(0,1)$",Finding the Moment Generating Function of  when,"X^2 X\sim N(0,1)","If $X\sim N(0,1)$ , integrate to find the moment generating function of a random variable $X^2$ and identify the distribution of $X^2$ using the moment generating function. $$E\left[e^{tX^2}\right]=\int_{-\infty}^{\infty}{e^{tx^2}e^{-x^2}\over{\sqrt{2\pi}}}dx$$ which reduces to $$=\frac1{\sqrt{2\pi}} \int_{-\infty}^{\infty}{e^{tx^2}e^{-x^2}}dx =\frac1{\sqrt{2\pi}} \int_{-\infty}^{\infty}{e^{x^2(t-\frac12)}}dx$$ and thus I am stuck. I'm sure there must be some trick to this (like completely the square for the mgf of a standard normal variable X) but I can't figure out what it might be. Any hints?","If , integrate to find the moment generating function of a random variable and identify the distribution of using the moment generating function. which reduces to and thus I am stuck. I'm sure there must be some trick to this (like completely the square for the mgf of a standard normal variable X) but I can't figure out what it might be. Any hints?","X\sim N(0,1) X^2 X^2 E\left[e^{tX^2}\right]=\int_{-\infty}^{\infty}{e^{tx^2}e^{-x^2}\over{\sqrt{2\pi}}}dx =\frac1{\sqrt{2\pi}} \int_{-\infty}^{\infty}{e^{tx^2}e^{-x^2}}dx
=\frac1{\sqrt{2\pi}} \int_{-\infty}^{\infty}{e^{x^2(t-\frac12)}}dx","['integration', 'statistics', 'probability-distributions', 'normal-distribution', 'moment-generating-functions']"
99,Integral of exponential function with polynomial argument,Integral of exponential function with polynomial argument,,"I am looking for an effcient way to evaluate $$ I = \int_{-\infty}^\infty dx\  e^{-ax+bx^2+cx^4}\\ \text{where } a,b,c \in \mathbb{R}^+ $$ I have already read about a solution involving the series expansion of the exponential here Computing the integrals of the form $\exp(P(x))$, $P(x)$ a polynomial but I am looking for something computationally more efficient... Any help is greatly appreciated!","I am looking for an effcient way to evaluate $$ I = \int_{-\infty}^\infty dx\  e^{-ax+bx^2+cx^4}\\ \text{where } a,b,c \in \mathbb{R}^+ $$ I have already read about a solution involving the series expansion of the exponential here Computing the integrals of the form $\exp(P(x))$, $P(x)$ a polynomial but I am looking for something computationally more efficient... Any help is greatly appreciated!",,"['integration', 'exponential-function']"
