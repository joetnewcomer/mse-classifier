,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Is maximizing entropy equivalent to minimizing the defined variance?,Is maximizing entropy equivalent to minimizing the defined variance?,,"Assume there is multi-set of some integers : $D = \{a_1,a_2,\cdots,a_{N-1}\}$ such that $\sum_i a_i = A$ we can build a discrete probability distribution by dividing elements of set by $A$, i.e. $p_i = a_i/A$ for $i=1,2,\cdots,N-1$ We define Entropy and Variance as: Entropy : $H(P) = -\sum_i p_i \log p_i$ Defined variance : $V(P) = \frac1{N-1} \sum_i (p_i - \frac1{N-1})^2$ Is minimizing the defined variance equal to maximizing entropy for this problem? Intuitively the answer is yes since maximum entropy is obtained when the distribution is uniform and the defined variance is minimum when all variables are equal.","Assume there is multi-set of some integers : $D = \{a_1,a_2,\cdots,a_{N-1}\}$ such that $\sum_i a_i = A$ we can build a discrete probability distribution by dividing elements of set by $A$, i.e. $p_i = a_i/A$ for $i=1,2,\cdots,N-1$ We define Entropy and Variance as: Entropy : $H(P) = -\sum_i p_i \log p_i$ Defined variance : $V(P) = \frac1{N-1} \sum_i (p_i - \frac1{N-1})^2$ Is minimizing the defined variance equal to maximizing entropy for this problem? Intuitively the answer is yes since maximum entropy is obtained when the distribution is uniform and the defined variance is minimum when all variables are equal.",,"['probability', 'probability-theory', 'information-theory']"
1,Flipping heads 10 times in a row,Flipping heads 10 times in a row,,"If I flip a coin 10 times in a row, obviously the probability of rolling heads ten times in a row is $\left(\frac{1}{2}\right)^{10}$. However, I am not sure how to calculate the exact odds that I will have at some point rolled heads 10 times in a row during a series of n flips. I have written a program to calculate the odds, but it runs in exponential time on n so it is relatively unusable. Here are the first couple results: in 10 rolls, 0.0009765625. in 11 rolls, 0.00146484375. in 12 rolls, 0.001953125. in 13 rolls, 0.00244140625. in 14 rolls, 0.0029296875. in 15 rolls, 0.00341796875. in 16 rolls, 0.00390625. in 17 rolls, 0.00439453125. in 18 rolls, 0.0048828125. in 19 rolls, 0.00537109375. in 20 rolls, 0.005859375. in 21 rolls, 0.006347179412841797. in 22 rolls, 0.006834745407104492. in 23 rolls, 0.007322072982788086. in 24 rolls, 0.007809162139892578. in 25 rolls, 0.008296012878417969. in 26 rolls, 0.008782625198364258. in 27 rolls, 0.009268999099731445. in 28 rolls, 0.009755134582519531. in 29 rolls, 0.010241031646728516. in 30 rolls, 0.010726690292358398. The source code is here","If I flip a coin 10 times in a row, obviously the probability of rolling heads ten times in a row is $\left(\frac{1}{2}\right)^{10}$. However, I am not sure how to calculate the exact odds that I will have at some point rolled heads 10 times in a row during a series of n flips. I have written a program to calculate the odds, but it runs in exponential time on n so it is relatively unusable. Here are the first couple results: in 10 rolls, 0.0009765625. in 11 rolls, 0.00146484375. in 12 rolls, 0.001953125. in 13 rolls, 0.00244140625. in 14 rolls, 0.0029296875. in 15 rolls, 0.00341796875. in 16 rolls, 0.00390625. in 17 rolls, 0.00439453125. in 18 rolls, 0.0048828125. in 19 rolls, 0.00537109375. in 20 rolls, 0.005859375. in 21 rolls, 0.006347179412841797. in 22 rolls, 0.006834745407104492. in 23 rolls, 0.007322072982788086. in 24 rolls, 0.007809162139892578. in 25 rolls, 0.008296012878417969. in 26 rolls, 0.008782625198364258. in 27 rolls, 0.009268999099731445. in 28 rolls, 0.009755134582519531. in 29 rolls, 0.010241031646728516. in 30 rolls, 0.010726690292358398. The source code is here",,"['probability', 'combinatorics']"
2,How many ways to choose $k$ out of $n$ numbers with exactly/at least $m$ consecutive numbers?,How many ways to choose  out of  numbers with exactly/at least  consecutive numbers?,k n m,"How many ways to choose $k$ out of $n$ numbers is a standard problem in undergraduate probability theory that has the binomial coefficient as its solution. An example would be lottery games were you have $13983816$ ways to choose $6$ numbers out of $49$. My question is: How many ways are there to choose $k$ out of $n$ numbers with exactly/at least $m$ consecutive numbers? An example would be how many ways are there to choose $6$ out of $49$ numbers with exactly/at least $5$ consecutive numbers, e.g. $\{2,3,4,5,6,26\}$? I read that the answer here is $1936$ ways for the ""at least""-case. I would like to have a general formula and if possible a derivation of it. Good references are also welcome. Thank you.","How many ways to choose $k$ out of $n$ numbers is a standard problem in undergraduate probability theory that has the binomial coefficient as its solution. An example would be lottery games were you have $13983816$ ways to choose $6$ numbers out of $49$. My question is: How many ways are there to choose $k$ out of $n$ numbers with exactly/at least $m$ consecutive numbers? An example would be how many ways are there to choose $6$ out of $49$ numbers with exactly/at least $5$ consecutive numbers, e.g. $\{2,3,4,5,6,26\}$? I read that the answer here is $1936$ ways for the ""at least""-case. I would like to have a general formula and if possible a derivation of it. Good references are also welcome. Thank you.",,"['probability', 'combinatorics', 'binomial-coefficients']"
3,PDF of summation of independent random variables with different mean and variances,PDF of summation of independent random variables with different mean and variances,,"What can we say about the probability distribution function of $n$ independent random variables with different means and variances but the same PDF? For example, lets say $X_1,X_2,\dots,X_n$ are independent random variables with the following PDFs: $$ \begin{align} X_1 & \sim N(μ_1,σ_1) \\ X_2 & \sim N(μ_2,σ_2) \\ & {}\,\vdots \\ X_n & \sim N(μ_n,σ_n) \end{align} $$ So they are all Normal random variables with different means and variances and their summation would also have Normal distribution. Now my question is what about other distribution functions?","What can we say about the probability distribution function of $n$ independent random variables with different means and variances but the same PDF? For example, lets say $X_1,X_2,\dots,X_n$ are independent random variables with the following PDFs: $$ \begin{align} X_1 & \sim N(μ_1,σ_1) \\ X_2 & \sim N(μ_2,σ_2) \\ & {}\,\vdots \\ X_n & \sim N(μ_n,σ_n) \end{align} $$ So they are all Normal random variables with different means and variances and their summation would also have Normal distribution. Now my question is what about other distribution functions?",,"['probability', 'probability-distributions', 'random-variables']"
4,Expected return value of a recursive probabilistic function,Expected return value of a recursive probabilistic function,,"In this question asked on Stackoverflow, the asker gives a Java function similar to this: public int f(){     if(Math.random() >= 0.5){         return 1;     }     else{         return 1 + Math.max(f(), f());     } } In math-speak, that would be written something like this: $$f = \left\{     \begin{array}{ll}         50\%\ chance : & 1 \\         50\%\ chance : & 1 + max(f, f)     \end{array} \right.$$ So basically, $f()$ is a probabilistic function that calls itself twice with 50% probability, and returns the maximum depth of its calls. If you draw the call-tree and label the first case ""tails"" and the second case ""heads,"" you can see that the question ""What is the probability that this function eventually returns"" is the same as the question ""What is the probability of eventually getting more heads than tails."" .  Thus, this function terminates with probability 1 . This also allows you to calculate the expected number of total times that $f()$ is called. However, the one question I haven't been able to answer is, what is the expected return value of $f()$? My first thought was that the expected value $E_f$ should be $$E_f = 0.5 * 1 + 0.5 * (1 + max(E_f, E_f))$$ However, that is clearly wrong; that would mean that, no matter how many calls $f()$ makes to itself in the second case, $E_f = 2$ ! So, does anyone know how to calculate the expected return value of $f()$?","In this question asked on Stackoverflow, the asker gives a Java function similar to this: public int f(){     if(Math.random() >= 0.5){         return 1;     }     else{         return 1 + Math.max(f(), f());     } } In math-speak, that would be written something like this: $$f = \left\{     \begin{array}{ll}         50\%\ chance : & 1 \\         50\%\ chance : & 1 + max(f, f)     \end{array} \right.$$ So basically, $f()$ is a probabilistic function that calls itself twice with 50% probability, and returns the maximum depth of its calls. If you draw the call-tree and label the first case ""tails"" and the second case ""heads,"" you can see that the question ""What is the probability that this function eventually returns"" is the same as the question ""What is the probability of eventually getting more heads than tails."" .  Thus, this function terminates with probability 1 . This also allows you to calculate the expected number of total times that $f()$ is called. However, the one question I haven't been able to answer is, what is the expected return value of $f()$? My first thought was that the expected value $E_f$ should be $$E_f = 0.5 * 1 + 0.5 * (1 + max(E_f, E_f))$$ However, that is clearly wrong; that would mean that, no matter how many calls $f()$ makes to itself in the second case, $E_f = 2$ ! So, does anyone know how to calculate the expected return value of $f()$?",,['probability']
5,Expected steps to obtain a connected graph,Expected steps to obtain a connected graph,,"We have a country containing $N$ cities with no road between any two cities (what a poor country). Each day we choose two cities such that there is no road between them and build a road between them. We choose each pair of non-connected cities with equal probability. Let $X$ be the number of days until we obtain a connected country. What is the expected value of $X$? A friend asked me, I have no idea yet.","We have a country containing $N$ cities with no road between any two cities (what a poor country). Each day we choose two cities such that there is no road between them and build a road between them. We choose each pair of non-connected cities with equal probability. Let $X$ be the number of days until we obtain a connected country. What is the expected value of $X$? A friend asked me, I have no idea yet.",,"['probability', 'graph-theory', 'random-graphs']"
6,Independence of conditional random variables,Independence of conditional random variables,,"Assume I have two random variables $A$ and $B$, which are not independent. In my particular case they will be values of a stochastic process at two given points in time, where $A$ is observed at an earlier time. Define $(B|A)$ to be a conditional random variable, i.e. a random variable defined by the conditional distribution of $B$ given $A$. Question: is $(B|A)$ independent of $A$? Why? Why not? Under what conditions it is? EXAMPLE: Let $A$ and $C$ be two independent Gaussian (0, 1) random variables, and let $B=A+C$. Then $(B|A=a)$ is Gaussian (a, 1) and seems to be independent of $A$, but I am not sure how to work formally with these kind of things. EDIT: As Sebastian Andersson pointed out in the comment, $A$ and $(B|A)$ seem not to be independent. However, what if we condition on $A=a$, where $a$ is a constant? The intuition would be that first we are interested in the uncertain event $A$, and then after it happens (and we know the outcome), we are interested in an event $(B|A=a)$. Does it make sense?","Assume I have two random variables $A$ and $B$, which are not independent. In my particular case they will be values of a stochastic process at two given points in time, where $A$ is observed at an earlier time. Define $(B|A)$ to be a conditional random variable, i.e. a random variable defined by the conditional distribution of $B$ given $A$. Question: is $(B|A)$ independent of $A$? Why? Why not? Under what conditions it is? EXAMPLE: Let $A$ and $C$ be two independent Gaussian (0, 1) random variables, and let $B=A+C$. Then $(B|A=a)$ is Gaussian (a, 1) and seems to be independent of $A$, but I am not sure how to work formally with these kind of things. EDIT: As Sebastian Andersson pointed out in the comment, $A$ and $(B|A)$ seem not to be independent. However, what if we condition on $A=a$, where $a$ is a constant? The intuition would be that first we are interested in the uncertain event $A$, and then after it happens (and we know the outcome), we are interested in an event $(B|A=a)$. Does it make sense?",,"['probability', 'probability-theory', 'random-variables', 'conditional-probability']"
7,Find density functions of $Z=X+Y$ when the joint density function is known.,Find density functions of  when the joint density function is known.,Z=X+Y,"Find the density function of $Z=X+Y$, $X$, $Y$ where the joint density function of $(X,Y)$ is given by $f(x,y) = \frac{1}{2} (x+y) e^{-(x+y)},\, x,y \geq 0$. My initial idea is to calculate the distribution function of $Z$ like this: $P(Z < z) = P(X+Y < z) = P(X < z-Y)$ $F_{z} = \frac{1}{2}\int\limits^{z}_{0}\int\limits^{z-y}_{0} (x+y) e^{-(x+y)} dx\, dy$ and then calculate its derivative $F_{z}^{'}$ Is this the way to go ?","Find the density function of $Z=X+Y$, $X$, $Y$ where the joint density function of $(X,Y)$ is given by $f(x,y) = \frac{1}{2} (x+y) e^{-(x+y)},\, x,y \geq 0$. My initial idea is to calculate the distribution function of $Z$ like this: $P(Z < z) = P(X+Y < z) = P(X < z-Y)$ $F_{z} = \frac{1}{2}\int\limits^{z}_{0}\int\limits^{z-y}_{0} (x+y) e^{-(x+y)} dx\, dy$ and then calculate its derivative $F_{z}^{'}$ Is this the way to go ?",,"['probability', 'probability-distributions']"
8,Proving that a function is negligible,Proving that a function is negligible,,"In mathematics, a negligible function is a function $\mu(x):\mathbb{N}{\rightarrow}\mathbb{R}$ such that for every positive integer $c$ there exists an integer $N_c$ such that for all $x > N_c$,     $\mu(x)<\frac{1}{x^c}$. (From wikipedia) What exactly is $N_c$? The definition is quite confusing for me, but I think the intuition is that a negligible function is something that shrinks faster than 1 divided by any polynomial function? Is $2^{-x}$ negligible? I think so, but don't know how to show this. Is $x^{-100}$ negligible? No, not negligible. The condition can be written as $x^{-100} < x^{-c}$ but this will only hold for values of $c$ that are smaller than $100$ Is $2^x$ negligible? No, this is clear because as $\lim_{x->\infty} 2^x = \infty$, whereas $\lim_{x->\infty}x^{-c} = 0$, thus the inequality will not hold","In mathematics, a negligible function is a function $\mu(x):\mathbb{N}{\rightarrow}\mathbb{R}$ such that for every positive integer $c$ there exists an integer $N_c$ such that for all $x > N_c$,     $\mu(x)<\frac{1}{x^c}$. (From wikipedia) What exactly is $N_c$? The definition is quite confusing for me, but I think the intuition is that a negligible function is something that shrinks faster than 1 divided by any polynomial function? Is $2^{-x}$ negligible? I think so, but don't know how to show this. Is $x^{-100}$ negligible? No, not negligible. The condition can be written as $x^{-100} < x^{-c}$ but this will only hold for values of $c$ that are smaller than $100$ Is $2^x$ negligible? No, this is clear because as $\lim_{x->\infty} 2^x = \infty$, whereas $\lim_{x->\infty}x^{-c} = 0$, thus the inequality will not hold",,"['probability', 'analysis', 'computational-complexity']"
9,Counting 6 seats 3 couples,Counting 6 seats 3 couples,,"There are 3 married couples should sit in a straight row of 6 seats. If couples sit random, what is the chance that at least one man sits next to his wife? And, what is the chance that exactly $3$ ( $2$ , and $1$ also) couples are thogether? Attempt Total number of combinations: $6!=720$ I want to counting $3$ disjoints sets. $A_1$ : the number of combinations in which there are exactly 3 men next to his wifes, denoting each couple by $P_i$ we have $3!$ possible combinations $P_1 P_2 P_3, P_2P_3P_1,$ etc.. But each couple can order in $2!$ forms then: $A_1=3!2!2!2!=48$ $A_2$ : the number of combinations in which there are exactly 2 men next to his wife, denoting each couple by $P_i$ we have $4!-3$ possible combinations if we fix $2$ couples $P_1, P_2$ , since there are $2!3$ of $4!$ combinations in which the third couple is not togheter namely $P_1 a P_2 b$ , $a P_1 b P_2$ and $a P_1 P_2 b$ and changing $P_1$ with $P_2$ . And since each couple can ordered in $2!$ forms we need to add factors $2!2!2!$ like previous case. Then $A_2=2!2!2!3(4!-2!3)=432$ But im not sure!!! There is an error in $A_2=2!2!2!3(4!-2!3)=432$ , since $2!2!3$ of $4!$ was favorable cases. Then: $A_2=2!2!3(2!2!3)=2!^43^2=144$ as noted Brian. $A_3$ : the number of combinations in which there are exactly 1 man next to his wife. I have not idea how to compute this monster. $A_3=288$ solved by Brian. $A_1+A_2+A_3=480$","There are 3 married couples should sit in a straight row of 6 seats. If couples sit random, what is the chance that at least one man sits next to his wife? And, what is the chance that exactly ( , and also) couples are thogether? Attempt Total number of combinations: I want to counting disjoints sets. : the number of combinations in which there are exactly 3 men next to his wifes, denoting each couple by we have possible combinations etc.. But each couple can order in forms then: : the number of combinations in which there are exactly 2 men next to his wife, denoting each couple by we have possible combinations if we fix couples , since there are of combinations in which the third couple is not togheter namely , and and changing with . And since each couple can ordered in forms we need to add factors like previous case. Then But im not sure!!! There is an error in , since of was favorable cases. Then: as noted Brian. : the number of combinations in which there are exactly 1 man next to his wife. I have not idea how to compute this monster. solved by Brian.","3 2 1 6!=720 3 A_1 P_i 3! P_1 P_2 P_3, P_2P_3P_1, 2! A_1=3!2!2!2!=48 A_2 P_i 4!-3 2 P_1, P_2 2!3 4! P_1 a P_2 b a P_1 b P_2 a P_1 P_2 b P_1 P_2 2! 2!2!2! A_2=2!2!2!3(4!-2!3)=432 A_2=2!2!2!3(4!-2!3)=432 2!2!3 4! A_2=2!2!3(2!2!3)=2!^43^2=144 A_3 A_3=288 A_1+A_2+A_3=480","['probability', 'combinatorics']"
10,A number from 1 to 1000 is selected. What is P(The Last Two Digits of the Cube = 1)?,A number from 1 to 1000 is selected. What is P(The Last Two Digits of the Cube = 1)?,,Y.A. Rozanov. Probability Theory: A Concise Course Chapter 1 Problem 9. A number from 1 to 1000 is selected at random. What is probability that the last two digits of  it's cube are equal to 1? The book reports that the  answer is .01. I believe the  answer follows from the fact that number $100x^2+10y+z$ cubed has the form $(100x^2+10y+z)^3$ = A trinomial expansion and using this knowledge to somehow show that there are only two solutions and each is 1/10 likely.,Y.A. Rozanov. Probability Theory: A Concise Course Chapter 1 Problem 9. A number from 1 to 1000 is selected at random. What is probability that the last two digits of  it's cube are equal to 1? The book reports that the  answer is .01. I believe the  answer follows from the fact that number $100x^2+10y+z$ cubed has the form $(100x^2+10y+z)^3$ = A trinomial expansion and using this knowledge to somehow show that there are only two solutions and each is 1/10 likely.,,"['probability', 'elementary-number-theory']"
11,Characterizing a distribution by its projections,Characterizing a distribution by its projections,,"Consider the density $f(x,y)=\large\frac{1}{2\pi}\frac{1}{\sqrt{1-x^2-y^2}}$ on the unit disk centered at the origin. There is a particular characterization of this distribution: it is the unique circularly symmetric distribution whose projections onto any line through the origin are uniformly distributed. Showing the projections of $f(x,y)$ are uniform is simple calculus. However I can't seem to think of an elegant proof for uniform projections implying $f$ must have the above density. If we let $R$ denote any rotation of coordinates $x,y\rightarrow x',y'$, then by assumption, $f(x,y)=R\circ f(x,y):=f(x',y')$. It would then suffice to show that $f(x,0)=\large\frac{1}{2\pi}\frac{1}{\sqrt{1-x^2}}$. Writing out the projected density as $u(x)$: $$u(x):=\int_{-\sqrt{1-x^2}}^{\sqrt{1-x^2}}f(x,y)dy$$ and we must have that $u(x)=1/2$ (being uniform on $[-1,1]$). Differentiating in $x$ with Leibnitz's rule seems to get nowhere. I've also tried considering the characteristic function of $f$ but got nowhere. If it helps, $f(x,y)$ arises from projecting the uniform distribution on the sphere to the $x,y$ plane. So in essence this is Archimedes rule for the sphere inscribed in a cylinder: the surface areas are equal. My gut feeling is that this is not entirely dissimilar from showing that the multivariate Gaussian distribution is the only rotationally invariant distribution with independent components.","Consider the density $f(x,y)=\large\frac{1}{2\pi}\frac{1}{\sqrt{1-x^2-y^2}}$ on the unit disk centered at the origin. There is a particular characterization of this distribution: it is the unique circularly symmetric distribution whose projections onto any line through the origin are uniformly distributed. Showing the projections of $f(x,y)$ are uniform is simple calculus. However I can't seem to think of an elegant proof for uniform projections implying $f$ must have the above density. If we let $R$ denote any rotation of coordinates $x,y\rightarrow x',y'$, then by assumption, $f(x,y)=R\circ f(x,y):=f(x',y')$. It would then suffice to show that $f(x,0)=\large\frac{1}{2\pi}\frac{1}{\sqrt{1-x^2}}$. Writing out the projected density as $u(x)$: $$u(x):=\int_{-\sqrt{1-x^2}}^{\sqrt{1-x^2}}f(x,y)dy$$ and we must have that $u(x)=1/2$ (being uniform on $[-1,1]$). Differentiating in $x$ with Leibnitz's rule seems to get nowhere. I've also tried considering the characteristic function of $f$ but got nowhere. If it helps, $f(x,y)$ arises from projecting the uniform distribution on the sphere to the $x,y$ plane. So in essence this is Archimedes rule for the sphere inscribed in a cylinder: the surface areas are equal. My gut feeling is that this is not entirely dissimilar from showing that the multivariate Gaussian distribution is the only rotationally invariant distribution with independent components.",,"['probability', 'probability-theory', 'multivariable-calculus', 'probability-distributions']"
12,Example for a simple game of chance where the average value converges fast to the expected value,Example for a simple game of chance where the average value converges fast to the expected value,,"I want to introduce the concept of expected value (for a discrete random variable, finite case) in a high school class. My first idea was to start with a simple game of chance and let the students play it. Suppose there are 25 students. If everybody plays the game once I have 25 outcomes which I could take to calculate the mean value of profits for this game. Then I want to discuss it and go over to calculate the probabilities of the game and then introduce the concept of expected value. My first idea for a game was this one: Throw a fair dice twice (= two random integers $i$ and $j$ between 1 and 6). If $i = 4$ and $j = 4$ you win 4\$, if exactly one of them is 4 you win 2\$ if $i \neq 4$ and $j \neq 4$ you lose 1\$. The expected value for this game turns out to be -0,03\$. However if you simulate this by playing the game 25 times you never end up with a mean value close to this, even if I let each student play it two times, such that I get 50 values it is most times far away from the mean value. I simulated it with a little python script and noticed that you have to play it at least 1000 times to come close to some extent to the expected value, so this example converges too slow for my purpose. So is there another game (of similar complexity) which converges very much faster and which is such that I can play it with the students as described above before discussing it?","I want to introduce the concept of expected value (for a discrete random variable, finite case) in a high school class. My first idea was to start with a simple game of chance and let the students play it. Suppose there are 25 students. If everybody plays the game once I have 25 outcomes which I could take to calculate the mean value of profits for this game. Then I want to discuss it and go over to calculate the probabilities of the game and then introduce the concept of expected value. My first idea for a game was this one: Throw a fair dice twice (= two random integers $i$ and $j$ between 1 and 6). If $i = 4$ and $j = 4$ you win 4\$, if exactly one of them is 4 you win 2\$ if $i \neq 4$ and $j \neq 4$ you lose 1\$. The expected value for this game turns out to be -0,03\$. However if you simulate this by playing the game 25 times you never end up with a mean value close to this, even if I let each student play it two times, such that I get 50 values it is most times far away from the mean value. I simulated it with a little python script and noticed that you have to play it at least 1000 times to come close to some extent to the expected value, so this example converges too slow for my purpose. So is there another game (of similar complexity) which converges very much faster and which is such that I can play it with the students as described above before discussing it?",,"['probability', 'convergence-divergence', 'education']"
13,How follows the Strong Law of Large Numbers from Birkhoff's Ergodic Theorem?,How follows the Strong Law of Large Numbers from Birkhoff's Ergodic Theorem?,,"We want to prove the strong law of large numbers with Birkhoff's ergodic theorem. Let $X_k$ be an i.i.d. sequence of $\mathcal{L}^1$ random variables. This is a stochastic process with measure-preserving operation $\theta$ (the shift operator). From Birkhoff's ergodic theorem, we obtain $\frac{X_0 + \dotsb + X_{n-1}}{n} \to Y$ a.s., with $Y=\mathbb{E}[X_1 \mid \mathcal{J}_{\theta}]$ a.s. Now, if $Y$ constant a.s., $Y= \mathbb{E}[X_1]$ a.s., and we would have the desired result. But why is $Y$ constant a.s.?","We want to prove the strong law of large numbers with Birkhoff's ergodic theorem. Let $X_k$ be an i.i.d. sequence of $\mathcal{L}^1$ random variables. This is a stochastic process with measure-preserving operation $\theta$ (the shift operator). From Birkhoff's ergodic theorem, we obtain $\frac{X_0 + \dotsb + X_{n-1}}{n} \to Y$ a.s., with $Y=\mathbb{E}[X_1 \mid \mathcal{J}_{\theta}]$ a.s. Now, if $Y$ constant a.s., $Y= \mathbb{E}[X_1]$ a.s., and we would have the desired result. But why is $Y$ constant a.s.?",,"['probability', 'probability-theory', 'ergodic-theory']"
14,Flaw in expected value solving logic (Project Euler 323),Flaw in expected value solving logic (Project Euler 323),,"The problem statement for Project Euler #323 is as follows: Let $y_0, y_1, y_2, ...$ be a sequence of random unsigned 32 bit integers (i.e. $0 \leq y_i < 2^{32}$ , every value equally likely). For the sequence $x_i$ the following recursion is given: $x_0 = 0$ and $x_i = x_{i-1} | y_{i-1}$ , for $i > 0$ . ( | is the bitwise-OR operator) It can be seen that eventually there will be an index N such that $x_i = 2^{32} -1$ (a bit-pattern of all ones) for all $i \geq  N$ . Find the expected value of N.  Give your answer rounded to 10 digits after the decimal point. I'm not interested in the actual solution to the problem, but I wish to understand where my attempts have gone wrong. My attempt to the problem thus far has been as follows: For any $y_i$ , the chance of any bit being a 1 is $\frac{1}{2}$ as all values are equally likely. In other words, the chance that a bit will ""flip"" from a 0 to a 1 on the next turn is $\frac{1}{2}$ . Thus the expected number of 1s in $x_1$ is $32 \div 2 = 16$ Following this logic, the expected number of 1s in $x_2$ is 24, as half of the sixteen zeroes would flip. Then the expected number of 1s in $x_3$ is 28, for $x_4$ it's 30 and for $x_5$ it's 31. The expected value for the last bit is equivalent to flipping a coin until we hit a head (1), which would be $\sum_{1}^{\infty} \frac{n}{2^n} = 2$ . Therefore the expected value of N is 5 + 2 = 7. However, apart from the fact that the answer is completely wrong, something makes me think that expected values just don't work that way. Can someone please clarify where I've made a mistake? Disclaimer: Although I try to refrain from posting questions related to Project Euler on Math StackExchange, I believe that the answer to my problem would make it no easier for anyone else to solve the problem, and might in fact help others understand where they went wrong.","The problem statement for Project Euler #323 is as follows: Let be a sequence of random unsigned 32 bit integers (i.e. , every value equally likely). For the sequence the following recursion is given: and , for . ( | is the bitwise-OR operator) It can be seen that eventually there will be an index N such that (a bit-pattern of all ones) for all . Find the expected value of N.  Give your answer rounded to 10 digits after the decimal point. I'm not interested in the actual solution to the problem, but I wish to understand where my attempts have gone wrong. My attempt to the problem thus far has been as follows: For any , the chance of any bit being a 1 is as all values are equally likely. In other words, the chance that a bit will ""flip"" from a 0 to a 1 on the next turn is . Thus the expected number of 1s in is Following this logic, the expected number of 1s in is 24, as half of the sixteen zeroes would flip. Then the expected number of 1s in is 28, for it's 30 and for it's 31. The expected value for the last bit is equivalent to flipping a coin until we hit a head (1), which would be . Therefore the expected value of N is 5 + 2 = 7. However, apart from the fact that the answer is completely wrong, something makes me think that expected values just don't work that way. Can someone please clarify where I've made a mistake? Disclaimer: Although I try to refrain from posting questions related to Project Euler on Math StackExchange, I believe that the answer to my problem would make it no easier for anyone else to solve the problem, and might in fact help others understand where they went wrong.","y_0, y_1, y_2, ... 0 \leq y_i < 2^{32} x_i x_0 = 0 x_i = x_{i-1} | y_{i-1} i > 0 x_i = 2^{32} -1 i \geq  N y_i \frac{1}{2} \frac{1}{2} x_1 32 \div 2 = 16 x_2 x_3 x_4 x_5 \sum_{1}^{\infty} \frac{n}{2^n} = 2","['probability', 'project-euler']"
15,About the total variance and the inter- and inter-class variances,About the total variance and the inter- and inter-class variances,,"Given a set of data samples, we classify it into two classes, A and B. We can calculate the total variance $\sigma^2_\text{total}$, the inter-class variance $\sigma^2_\text{inter}$, and intra-class variance $\sigma^2_\text{intra}$. Can anyone prove that $\sigma^2_\text{total}= \sigma^2_\text{inter}+\sigma^2_\text{intra}$.? Thanks.","Given a set of data samples, we classify it into two classes, A and B. We can calculate the total variance $\sigma^2_\text{total}$, the inter-class variance $\sigma^2_\text{inter}$, and intra-class variance $\sigma^2_\text{intra}$. Can anyone prove that $\sigma^2_\text{total}= \sigma^2_\text{inter}+\sigma^2_\text{intra}$.? Thanks.",,"['probability', 'statistics']"
16,Conditional expectation and almost sure equality,Conditional expectation and almost sure equality,,"Let $X$, $Y$ be r.v. with finite second moments. Suppose $\mathbb{E}(X\mid\sigma (Y))=Y$, and $\mathbb{E}(Y\mid\sigma(X))=X$, show that $\Pr(X=Y)=1$. So what I have done is this, I first consider $\mathbb{E}((X-Y)^2)$ by conditioning on $X$ and $Y$ $\mathbb{E}((X-Y)^2\mid X)=\mathbb{E}(X^2\mid X)-2\mathbb{E}[XY\mid X]+\mathbb{E}[Y^2\mid X]=X^2-2X^2+\mathbb{E}(Y^2\mid X)=-X^2+\mathbb{E}[Y^2\mid X]$, and similarly for conditioning on $Y$, but I am not sure how to subtract them properly to make use of them. Thanks In the end I have $\mathbb{E}((X-Y)^2\mid X)=-X^2+\mathbb{E}[Y^2\mid X]$; $\mathbb{E}((X-Y)^2\mid Y)=-Y^2+\mathbb{E}[X^2\mid Y]$","Let $X$, $Y$ be r.v. with finite second moments. Suppose $\mathbb{E}(X\mid\sigma (Y))=Y$, and $\mathbb{E}(Y\mid\sigma(X))=X$, show that $\Pr(X=Y)=1$. So what I have done is this, I first consider $\mathbb{E}((X-Y)^2)$ by conditioning on $X$ and $Y$ $\mathbb{E}((X-Y)^2\mid X)=\mathbb{E}(X^2\mid X)-2\mathbb{E}[XY\mid X]+\mathbb{E}[Y^2\mid X]=X^2-2X^2+\mathbb{E}(Y^2\mid X)=-X^2+\mathbb{E}[Y^2\mid X]$, and similarly for conditioning on $Y$, but I am not sure how to subtract them properly to make use of them. Thanks In the end I have $\mathbb{E}((X-Y)^2\mid X)=-X^2+\mathbb{E}[Y^2\mid X]$; $\mathbb{E}((X-Y)^2\mid Y)=-Y^2+\mathbb{E}[X^2\mid Y]$",,"['probability', 'probability-theory']"
17,Almost sure convergence on an inductively defined random variable,Almost sure convergence on an inductively defined random variable,,"Define a sequence of random variables inductively with $X_0=1$ and $X_{n+1}$ selected randomly and uniformly from $[0,X_n]$. Show $\dfrac{1}{n}\log X_n$ converges almost surely to a constant and evaluate the limit. A sequence of random variables $X_n$ goes to $c$ almost surely if $P(\lim_{n\to\infty} X_n=c)=1$. From the definition of $X_n$ it is clear that $X_{n-1}\geq X_n \;\forall\; n\geq0$ and since $X_n$ is uniform, $P(X_k)=\frac{1}{X_{k-1}}$. But I'm not really sure where to go from here since the limit is on the inside of the probability. Am I supposed to apply to weak or long law of strong numbers somewhere? Any help would be greatly appreciated.","Define a sequence of random variables inductively with $X_0=1$ and $X_{n+1}$ selected randomly and uniformly from $[0,X_n]$. Show $\dfrac{1}{n}\log X_n$ converges almost surely to a constant and evaluate the limit. A sequence of random variables $X_n$ goes to $c$ almost surely if $P(\lim_{n\to\infty} X_n=c)=1$. From the definition of $X_n$ it is clear that $X_{n-1}\geq X_n \;\forall\; n\geq0$ and since $X_n$ is uniform, $P(X_k)=\frac{1}{X_{k-1}}$. But I'm not really sure where to go from here since the limit is on the inside of the probability. Am I supposed to apply to weak or long law of strong numbers somewhere? Any help would be greatly appreciated.",,['probability']
18,How difficult is to find a small clear round spot on a large sheet contaminated by random dirty dots,How difficult is to find a small clear round spot on a large sheet contaminated by random dirty dots,,"The problem arose after a discussion why larger digital camera photo sensors is much more expensive than little bit smaller ones, and the reason was given that it's due to difficulty of finding a larger area spot on a big CCD or CMOS panel. Consider a large clear white sheet (of a given area $S$, and we may consider it of any convenient non-degenerate shape, such as square or circle) with some black dirt dots on it. The average density of the dirt dots is uniform and known to be $p$ dots per unit area. Somebody wants to find a clear round spot of radius $r$ on it. Question 1: how difficult is it to find such a spot (and the term ""difficult"" maybe is defined as ""the probability of a random disc being clear?""). How many such non-overlapping spots there are on the sheet on average? Question 2: how much more difficult is it to find a spot of radius $k\cdot r$ with $k \gt 1$ than a spot of a radius $r$? When $S\gg s=\pi r^2$, this looks easy, but when $S$ is comparable to $s$, the result is not so obvious.","The problem arose after a discussion why larger digital camera photo sensors is much more expensive than little bit smaller ones, and the reason was given that it's due to difficulty of finding a larger area spot on a big CCD or CMOS panel. Consider a large clear white sheet (of a given area $S$, and we may consider it of any convenient non-degenerate shape, such as square or circle) with some black dirt dots on it. The average density of the dirt dots is uniform and known to be $p$ dots per unit area. Somebody wants to find a clear round spot of radius $r$ on it. Question 1: how difficult is it to find such a spot (and the term ""difficult"" maybe is defined as ""the probability of a random disc being clear?""). How many such non-overlapping spots there are on the sheet on average? Question 2: how much more difficult is it to find a spot of radius $k\cdot r$ with $k \gt 1$ than a spot of a radius $r$? When $S\gg s=\pi r^2$, this looks easy, but when $S$ is comparable to $s$, the result is not so obvious.",,['probability']
19,Doob's inequality in probability,Doob's inequality in probability,,"In the book ""Optimal Stopping and Free-Boundary Problems"" there is given Doob's inequality of the following form. Let $X = (X_t,F_t)$ be a submartingale. Then for any $\varepsilon>0$ and each $T>0$   $$ \mathsf P\left\{\sup\limits_{t\leq T}|X_t|\geq \varepsilon\right\}\leq \frac 1\varepsilon \sup\limits_{t\leq T}\,\,\,\mathsf E\,|X_t|. $$ On the other hand, George Lowther presented the following example. Let $X_0 = 0$,  $$ X_1 = \begin{cases} 1, &\quad p = 1/3; \\ 0, &\quad p = 1/3; \\ -1,&\quad p =1/3. \end{cases} $$ and $X_2 = 1$ if $X_1 = 1$, $X_2 = 0$ if $X_1 = -1$ and $$ X_2 = \begin{cases} 1, &\quad p = 1/2; \ -1,&\quad p =1/2. \end{cases} $$ if $X_1 = 0$. Finally, $X_n = X_2$ for all $n\geq 2$. It is easy to check that this is a submartingale. On the other hand, for $\varepsilon = 1$ we have $$ \mathsf P\left\{\sup\limits_{n\leq 2}|X_n|\geq 1\right\} = 1 $$ but $\mathsf E[|X_0|] = 0$, $\mathsf E[|X_1|] = 2/3$ and $\mathsf E[|X_2|] = 2/3$ - so we have inequality $1\leq 2/3$. Could you help with finding a mistake since I am confused? The reference can be seen here: http://books.google.com/books?id=UinZbLqpUDEC&pg=PA60&source=gbs_toc_r&cad=4#v=onepage&q&f=false page 62. This question raised from the discussion here: Bounds for submartingale","In the book ""Optimal Stopping and Free-Boundary Problems"" there is given Doob's inequality of the following form. Let $X = (X_t,F_t)$ be a submartingale. Then for any $\varepsilon>0$ and each $T>0$   $$ \mathsf P\left\{\sup\limits_{t\leq T}|X_t|\geq \varepsilon\right\}\leq \frac 1\varepsilon \sup\limits_{t\leq T}\,\,\,\mathsf E\,|X_t|. $$ On the other hand, George Lowther presented the following example. Let $X_0 = 0$,  $$ X_1 = \begin{cases} 1, &\quad p = 1/3; \\ 0, &\quad p = 1/3; \\ -1,&\quad p =1/3. \end{cases} $$ and $X_2 = 1$ if $X_1 = 1$, $X_2 = 0$ if $X_1 = -1$ and $$ X_2 = \begin{cases} 1, &\quad p = 1/2; \ -1,&\quad p =1/2. \end{cases} $$ if $X_1 = 0$. Finally, $X_n = X_2$ for all $n\geq 2$. It is easy to check that this is a submartingale. On the other hand, for $\varepsilon = 1$ we have $$ \mathsf P\left\{\sup\limits_{n\leq 2}|X_n|\geq 1\right\} = 1 $$ but $\mathsf E[|X_0|] = 0$, $\mathsf E[|X_1|] = 2/3$ and $\mathsf E[|X_2|] = 2/3$ - so we have inequality $1\leq 2/3$. Could you help with finding a mistake since I am confused? The reference can be seen here: http://books.google.com/books?id=UinZbLqpUDEC&pg=PA60&source=gbs_toc_r&cad=4#v=onepage&q&f=false page 62. This question raised from the discussion here: Bounds for submartingale",,"['probability', 'stochastic-processes']"
20,Random $3-$element subsets of $[n]$,Random element subsets of,3- [n],"I am given $2n$ $3-$element subsets of $\{1,2,...,n\}$ that were chosen uniformly and independently at random (out of all possible 3-element subsets). How can I prove that with probability $\geq 1-e^{-\Theta(n)}$ one can select $n$ subsets out of the total $2n$, such that no element of $\{1,2,...,n\}$ appears in more than $40$ subsets? I'm pretty sure that a Chernoff bound should be used here, but I couldn't get rid of the dependency between the random variables... Any ideas..?","I am given $2n$ $3-$element subsets of $\{1,2,...,n\}$ that were chosen uniformly and independently at random (out of all possible 3-element subsets). How can I prove that with probability $\geq 1-e^{-\Theta(n)}$ one can select $n$ subsets out of the total $2n$, such that no element of $\{1,2,...,n\}$ appears in more than $40$ subsets? I'm pretty sure that a Chernoff bound should be used here, but I couldn't get rid of the dependency between the random variables... Any ideas..?",,"['probability', 'combinatorics']"
21,Bounds for die roll,Bounds for die roll,,"Given a $n$-sided fair die, show that the probability $P$ that all faces from $1$ to $11$ show when doing $3n$-rolls is bounded by $1 - 11 \cdot \frac{(n-1)^{3n}}{n^{3n}} \leq P \leq 1 -  11 \cdot \frac{11(n-1)^{3n}}{n^{3n}} + 5 \cdot 11 \cdot \frac{(n-2)^{3n}}{n^{3n}}$ I am really stuck on this one. I figured that the exact probability is very hard to find and stirling numbers are involved. So the only chance I have is to figure out what events where used for that bounds. My guess is that the left one comes from the assumtion that (Edit: Warning this is not quite correct, check the comments ) $\mathbb{P}($Faces 1-11 don't occur at all$)=\frac{|E|}{|Q|}=\frac{11 \cdot (n-1)^{3n}}{n^{3n}}$ And if you look at the complement it is that all faces 1-11 at least occur once. Surely this is a lower bound but how could I get the upper bound, I hope that I did not overlook something very easy.","Given a $n$-sided fair die, show that the probability $P$ that all faces from $1$ to $11$ show when doing $3n$-rolls is bounded by $1 - 11 \cdot \frac{(n-1)^{3n}}{n^{3n}} \leq P \leq 1 -  11 \cdot \frac{11(n-1)^{3n}}{n^{3n}} + 5 \cdot 11 \cdot \frac{(n-2)^{3n}}{n^{3n}}$ I am really stuck on this one. I figured that the exact probability is very hard to find and stirling numbers are involved. So the only chance I have is to figure out what events where used for that bounds. My guess is that the left one comes from the assumtion that (Edit: Warning this is not quite correct, check the comments ) $\mathbb{P}($Faces 1-11 don't occur at all$)=\frac{|E|}{|Q|}=\frac{11 \cdot (n-1)^{3n}}{n^{3n}}$ And if you look at the complement it is that all faces 1-11 at least occur once. Surely this is a lower bound but how could I get the upper bound, I hope that I did not overlook something very easy.",,"['probability', 'dice']"
22,How many steps does it take the computer to solve a Sudoku puzzle?,How many steps does it take the computer to solve a Sudoku puzzle?,,"We all know what Sudoku is. Given a Sudoku puzzle, one can use a simple recursive procedure to solve it using a computer. Before describing the algorithm, we make some definitions. A partial solution is a Sudoku puzzle with only some of the numbers entered. Given an empty square in a partial solution, an assignment of a digit to the square is consistent if it doesn't appear in the same row, column or $3\times 3$ square. The algorithm is as follows: If there is any square for which there is no consistent assignment, give up. Otherwise, pick an empty square $S$ (*). Calculate the set of all consistent assignments $A$ to this square. Go over all assignments $a \in A$ in some order (**): Put $a$ in $S$, and recurse. We have two degrees of freedom: choosing an empty square, and choosing and order for the assignments to the square. In practice, it seems that whatever the choice is, the algorithm reaches a solution very fast. Suppose we give the algorithm a partial Sudoku with a unique solution. Can we bound the number of steps the algorithm takes to find the solution? To make life easier, you can choose any rule you wish for ( * ) and (**), even a random rule (in that case, the relevant quantity is probably the expectation); any analyzable choice would be interesting. Also, if it helps, you can assume something about the input - say at least $X$ squares are filled in. I'm also willing to relax the restriction that there be a unique solution - indeed, even given an empty board, the algorithm above finds a complete Sudoku very fast. Analyzes for random inputs (in whatever meaningful sense) are also welcome.","We all know what Sudoku is. Given a Sudoku puzzle, one can use a simple recursive procedure to solve it using a computer. Before describing the algorithm, we make some definitions. A partial solution is a Sudoku puzzle with only some of the numbers entered. Given an empty square in a partial solution, an assignment of a digit to the square is consistent if it doesn't appear in the same row, column or $3\times 3$ square. The algorithm is as follows: If there is any square for which there is no consistent assignment, give up. Otherwise, pick an empty square $S$ (*). Calculate the set of all consistent assignments $A$ to this square. Go over all assignments $a \in A$ in some order (**): Put $a$ in $S$, and recurse. We have two degrees of freedom: choosing an empty square, and choosing and order for the assignments to the square. In practice, it seems that whatever the choice is, the algorithm reaches a solution very fast. Suppose we give the algorithm a partial Sudoku with a unique solution. Can we bound the number of steps the algorithm takes to find the solution? To make life easier, you can choose any rule you wish for ( * ) and (**), even a random rule (in that case, the relevant quantity is probably the expectation); any analyzable choice would be interesting. Also, if it helps, you can assume something about the input - say at least $X$ squares are filled in. I'm also willing to relax the restriction that there be a unique solution - indeed, even given an empty board, the algorithm above finds a complete Sudoku very fast. Analyzes for random inputs (in whatever meaningful sense) are also welcome.",,"['probability', 'algorithms', 'recreational-mathematics']"
23,Correlated Brownian motion and Poisson process,Correlated Brownian motion and Poisson process,,"Is there an easy way to construct, on the same filtered probability space, a Brownian motion $W$ and a Poisson process $N$, such that $W$ and $N$ are not independent ?","Is there an easy way to construct, on the same filtered probability space, a Brownian motion $W$ and a Poisson process $N$, such that $W$ and $N$ are not independent ?",,"['probability', 'stochastic-processes']"
24,A short proof of de Finetti's theorem,A short proof of de Finetti's theorem,,"Consider de Finetti's theorem in the following form. Theorem. Let $E$ be a Polish space and $(X_1,X_2,\ldots)$ an exchangable sequence of $E$ -valued random variables. Then there exists a (necessarily unique) random probability measure $\mu$ on $E$ such that, for every $n\in \mathbb{N}$ , and $A_1,\ldots,A_n \subset E$ measurable, $$\label{eq1}\tag{1} \mathbb{P}(X_1\in A_1,\ldots , X_n \in A_n) = \mathbb{E}\left[\mu(A_1) \ldots \mu(A_n)\right]. $$ Furthermore, the weak limit of the empirical measures $$ Z^n = \frac 1n \sum_{i=1}^n \delta_{X_i} $$ as $n\to \infty$ exists almost-surely and is equal in law to $\mu$ . I wasn't aware of the theorem in this form, and ""accidentally"" reproved it. The proof is quite short and only builds on standard facts from the theory of weak convergence, see the proof sketch below. Question : Is a proof of this length and method novel or interesting? The proof does not feel extremely innovative so I would assume it to be standard, but I am struggling to find out. I found some proofs in the literature that are much more complicated but also more general (like in the paper of Hewitt and Savage), and in standard textbooks like that of Kallenberg the proof is short but builds on so many lemmas developed in the book that I find it hard to say what the main argument is and how complicated it is. Proof sketch: Denote by $\mathcal{M}_1(X)$ for a Polish space $X$ the space of probability measures on $X$ , equipped with the topology of weak convergence. To show that the sequence of empirical measures $(Z^n)$ is relatively compact as a subset of $\mathcal{M}_1(\mathcal{M}_1(E))$ it is sufficient to find for every $\varepsilon > 0$ a compact set $K\subset E$ such that $\mathbb{P}(Z^n(E\setminus K) > \varepsilon) < \varepsilon$ for all $n\in \mathbb{N}$ . Given $\varepsilon > 0$ there exists $K\subset E$ compact such that $\mathbb{P}(X_1 \in E\setminus K) < \varepsilon^2$ , so $$ \mathbb{P}(Z^n(E\setminus K) > \varepsilon) = \mathbb{P}\left( \sum_{i=1}^n \mathbf{1}_{\{X_i \in E\setminus K\}} > n\varepsilon \right) \le \frac{1}{n\varepsilon} \sum_{i=1}^n \mathbb{P}(X_i \in E\setminus K) < \varepsilon $$ for every $n\in \mathbb{N}$ , where we used that all $X_i$ have the same marginal distribution by exchangability. Now suppose that a subsequence (which we denote by $Z^n$ again for ease of notation) converges in law to a random probability measure, $Z^n \implies \mu$ . Let $k\in \mathbb{N}$ , and $f_1,\ldots f_k \colon E \to \mathbb{R}$ be continuous and bounded. Then $m \mapsto \int f_1 dm \ldots \int f_k dm$ is a continuous bounded functional on $\mathcal{M}_1(E)$ , so \begin{align} \mathbb{E}\left[\int f_1 d\mu \ldots \int f_k d\mu\right]  &= \lim_{n\to \infty} \left[\int f_1 dZ^n \ldots \int f_k dZ^n\right]\\ &=\lim_{n\to \infty} \frac{1}{n^k}\sum_{l_1,\ldots l_k=1}^n \mathbb{E}\left[ f_1(X_{l_1}) \ldots f_k(X_{l_k})\right]\\ &= \mathbb{E}\left[ f_1(X_1) \ldots f_k(X_k)\right], \end{align} where the last equation uses exchangability and the fact that the number of summands where some number of indices collide is $O(n^{k-1})$ . This implies uniqueness of the subsequential limit and thus convergence of $Z^n$ in law to a random probability measure $\mu$ which satisfies \eqref{eq1}. Almost sure convergence of the $Z^n$ then follows from the general fact that the sequence of normalised empirical measures of a sequence of i.i.d. samples converges almost-surely to the probability measure from which they are sampled. Hewitt, Edwin; Savage, Leonard J. , Symmetric measures on Cartesian products , Trans. Am. Math. Soc. 80, 470-501 (1955). ZBL0066.29604 .","Consider de Finetti's theorem in the following form. Theorem. Let be a Polish space and an exchangable sequence of -valued random variables. Then there exists a (necessarily unique) random probability measure on such that, for every , and measurable, Furthermore, the weak limit of the empirical measures as exists almost-surely and is equal in law to . I wasn't aware of the theorem in this form, and ""accidentally"" reproved it. The proof is quite short and only builds on standard facts from the theory of weak convergence, see the proof sketch below. Question : Is a proof of this length and method novel or interesting? The proof does not feel extremely innovative so I would assume it to be standard, but I am struggling to find out. I found some proofs in the literature that are much more complicated but also more general (like in the paper of Hewitt and Savage), and in standard textbooks like that of Kallenberg the proof is short but builds on so many lemmas developed in the book that I find it hard to say what the main argument is and how complicated it is. Proof sketch: Denote by for a Polish space the space of probability measures on , equipped with the topology of weak convergence. To show that the sequence of empirical measures is relatively compact as a subset of it is sufficient to find for every a compact set such that for all . Given there exists compact such that , so for every , where we used that all have the same marginal distribution by exchangability. Now suppose that a subsequence (which we denote by again for ease of notation) converges in law to a random probability measure, . Let , and be continuous and bounded. Then is a continuous bounded functional on , so where the last equation uses exchangability and the fact that the number of summands where some number of indices collide is . This implies uniqueness of the subsequential limit and thus convergence of in law to a random probability measure which satisfies \eqref{eq1}. Almost sure convergence of the then follows from the general fact that the sequence of normalised empirical measures of a sequence of i.i.d. samples converges almost-surely to the probability measure from which they are sampled. Hewitt, Edwin; Savage, Leonard J. , Symmetric measures on Cartesian products , Trans. Am. Math. Soc. 80, 470-501 (1955). ZBL0066.29604 .","E (X_1,X_2,\ldots) E \mu E n\in \mathbb{N} A_1,\ldots,A_n \subset E \label{eq1}\tag{1}
\mathbb{P}(X_1\in A_1,\ldots , X_n \in A_n) = \mathbb{E}\left[\mu(A_1) \ldots \mu(A_n)\right].
 
Z^n = \frac 1n \sum_{i=1}^n \delta_{X_i}
 n\to \infty \mu \mathcal{M}_1(X) X X (Z^n) \mathcal{M}_1(\mathcal{M}_1(E)) \varepsilon > 0 K\subset E \mathbb{P}(Z^n(E\setminus K) > \varepsilon) < \varepsilon n\in \mathbb{N} \varepsilon > 0 K\subset E \mathbb{P}(X_1 \in E\setminus K) < \varepsilon^2 
\mathbb{P}(Z^n(E\setminus K) > \varepsilon) = \mathbb{P}\left( \sum_{i=1}^n \mathbf{1}_{\{X_i \in E\setminus K\}} > n\varepsilon \right) \le \frac{1}{n\varepsilon} \sum_{i=1}^n \mathbb{P}(X_i \in E\setminus K) < \varepsilon
 n\in \mathbb{N} X_i Z^n Z^n \implies \mu k\in \mathbb{N} f_1,\ldots f_k \colon E \to \mathbb{R} m \mapsto \int f_1 dm \ldots \int f_k dm \mathcal{M}_1(E) \begin{align}
\mathbb{E}\left[\int f_1 d\mu \ldots \int f_k d\mu\right] 
&= \lim_{n\to \infty} \left[\int f_1 dZ^n \ldots \int f_k dZ^n\right]\\
&=\lim_{n\to \infty} \frac{1}{n^k}\sum_{l_1,\ldots l_k=1}^n \mathbb{E}\left[ f_1(X_{l_1}) \ldots f_k(X_{l_k})\right]\\
&= \mathbb{E}\left[ f_1(X_1) \ldots f_k(X_k)\right],
\end{align} O(n^{k-1}) Z^n \mu Z^n","['probability', 'probability-theory', 'weak-convergence']"
25,What is the distribution of distances between two random points in RGB space?,What is the distribution of distances between two random points in RGB space?,,"Suppose we pick pairs of triples from $\{ 0, 1, 2, \dots, 255\}^3$ with a uniform distribution and would like to find a closed form for the distribution of the Euclidean distances $$ d((x_1, x_2, x_3), (y_1, y_2, y_3)) = \left( \sum_{j=1}^3 (x_j-y_j)^2 \right)^{1/2}.$$ The motivation for this question comes from the cubic lattice that is one of the RGB color spaces . It would be nice to have an exact probability distribution because it would likely have interesting applications in image processing. This question gives the answer for when a cube includes all real numbers in it, and there's Mathai et al. $^\color{magenta}{\star}$ , but what about when it is discrete, like for a cubic lattice ? $\color{magenta}{\star}$ Arak M. Mathai, Peter Moschopoulos, Giorgio Pederzoli, Distance between random points in a cube [ PDF ], Statistica, Volume 59, Number 1, 1999.","Suppose we pick pairs of triples from with a uniform distribution and would like to find a closed form for the distribution of the Euclidean distances The motivation for this question comes from the cubic lattice that is one of the RGB color spaces . It would be nice to have an exact probability distribution because it would likely have interesting applications in image processing. This question gives the answer for when a cube includes all real numbers in it, and there's Mathai et al. , but what about when it is discrete, like for a cubic lattice ? Arak M. Mathai, Peter Moschopoulos, Giorgio Pederzoli, Distance between random points in a cube [ PDF ], Statistica, Volume 59, Number 1, 1999.","\{ 0, 1, 2, \dots, 255\}^3  d((x_1, x_2, x_3), (y_1, y_2, y_3)) = \left( \sum_{j=1}^3 (x_j-y_j)^2 \right)^{1/2}. ^\color{magenta}{\star} \color{magenta}{\star}","['probability', 'discrete-mathematics', 'probability-distributions', 'discrete-geometry', 'image-processing']"
26,$X$ uncorrelated with any function of $Y$ implies $X$ and $Y$ independent.,uncorrelated with any function of  implies  and  independent.,X Y X Y,"This question is purely out of curiosity and mainly to question my intuitions about independence of random variables. Q: Take two non trivial random variables, with non disjoint support (see edit below) $X,Y \in \mathbb{L}_2(\Omega, \mathcal{F}, \mathbb{P})$ , so that projections and covariance formulas are well defined. If $X$ is uncorrelated with any function $g$ of $Y$ , i.e. $\operatorname{Corr}(X,g(Y)) = 0, \: \forall \: g$ measurable, this implies $X$ and $Y$ are independent. Is the above statement true? I could not find any post on mathstack on this. One way I tried to prove the above is by proving the following: Assume that $X$ and $Y$ are dependent, then there exists a function $f$ such that the correlation between $X$ and $f(Y)$ is nonzero. Reason why $\mathbb{L}_2$ is important: This is also the reason why we have to take the random variables in $\mathbb{L}_2$ , otherwise one could find counterexamples to the second statement by taking $X$ with undefined variance or expectation and show that the covariance can never be nonzero, as it is not well defined. Thoughts: Any ideas or references? Maybe something additional must be assumed about the functions $g$ ? Maybe instead of this, one should assume that the correlation is zero with any random variable $Z$ which is $X$ -measurable? Thank you very much for your help and time. Reason why non disjoint support is important: EDIT. Here I post a counterexample that contradicts the second statement , if we do not assume that the random variables have non disjoint support, i.e.: Assume that $X$ and $Y$ are dependent, then there exists a function $f$ such that the correlation between $X$ and $f(Y)$ is nonzero. Take $([0,1], \mathcal{B}([0,1]), \lambda)$ , where $\lambda$ is the Lebesgue measure. The key idea is that if they have disjoint support we can find a counterexample. Take: $$ X(x) = \left(x - \frac{1}{2} \right) \mathbb{1}_{[0,1/2]}(x)$$ and: $$ Y(x) = \left(x - \frac{3}{2} \right) \mathbb{1}_{[1/2,1]}(x)$$ Take any function $f$ , then $f(Y(x)) = f(0)$ constant for any $x \in [0,1/2]$ thus: $$ X(x)f(Y(x)) = f(0)X(x) \mathbb{1}_{[0,1/2]}(x)$$ which, as $\int X d\lambda = 0$ , implies: $$\int X f(Y) d \lambda = 0$$ for any $f$ . This implies they are uncorrelated and it provides a counterexample.","This question is purely out of curiosity and mainly to question my intuitions about independence of random variables. Q: Take two non trivial random variables, with non disjoint support (see edit below) , so that projections and covariance formulas are well defined. If is uncorrelated with any function of , i.e. measurable, this implies and are independent. Is the above statement true? I could not find any post on mathstack on this. One way I tried to prove the above is by proving the following: Assume that and are dependent, then there exists a function such that the correlation between and is nonzero. Reason why is important: This is also the reason why we have to take the random variables in , otherwise one could find counterexamples to the second statement by taking with undefined variance or expectation and show that the covariance can never be nonzero, as it is not well defined. Thoughts: Any ideas or references? Maybe something additional must be assumed about the functions ? Maybe instead of this, one should assume that the correlation is zero with any random variable which is -measurable? Thank you very much for your help and time. Reason why non disjoint support is important: EDIT. Here I post a counterexample that contradicts the second statement , if we do not assume that the random variables have non disjoint support, i.e.: Assume that and are dependent, then there exists a function such that the correlation between and is nonzero. Take , where is the Lebesgue measure. The key idea is that if they have disjoint support we can find a counterexample. Take: and: Take any function , then constant for any thus: which, as , implies: for any . This implies they are uncorrelated and it provides a counterexample.","X,Y \in \mathbb{L}_2(\Omega, \mathcal{F}, \mathbb{P}) X g Y \operatorname{Corr}(X,g(Y)) = 0, \: \forall \: g X Y X Y f X f(Y) \mathbb{L}_2 \mathbb{L}_2 X g Z X X Y f X f(Y) ([0,1], \mathcal{B}([0,1]), \lambda) \lambda  X(x) = \left(x - \frac{1}{2} \right) \mathbb{1}_{[0,1/2]}(x)  Y(x) = \left(x - \frac{3}{2} \right) \mathbb{1}_{[1/2,1]}(x) f f(Y(x)) = f(0) x \in [0,1/2]  X(x)f(Y(x)) = f(0)X(x) \mathbb{1}_{[0,1/2]}(x) \int X d\lambda = 0 \int X f(Y) d \lambda = 0 f","['probability', 'probability-theory', 'analysis', 'statistics', 'random-variables']"
27,Probability of partially sortedness of a perfectly shuffled array of unique numbers,Probability of partially sortedness of a perfectly shuffled array of unique numbers,,"Sorry that I don't know any better way to express this question. Assuming that we have a perfectly shuffled array of unique numbers, we know that the array is in fact consisted of ascending or descending sorted subarrays. In average howmany such sorted subarrays consist this one particular perfectly shuffled array is the question. As a simple example, please consider an array of 20 integers [0...19] shuffled as [14,2,5,16,18,19,7,6,12,17,3,4,8,11,15,13,1,0,9,10] which is internally sorted in chunks as [[14,2],[5,6,18,19],[7,6],[12,17],[3,4,8,11,15],[13,1,0],[9,10]] so in total we obtain 7 subarrays. Now this observation just paves the way for a very efficient sorting algorithm once you merge them cleverly. Yet it's even better than that. I naively assumed that the number of subarrays in average should be like half the length of the initial array (50% sorted internally). But no, that's only the worst case which you very rarely get. It's like hitting 10101010 or 01010101 in 8 bits. So for 8 bits per se the chance of hitting worst case is $2\times\frac{1}{2^8} = \frac{1}{128}$ . Similarly hitting the best case where we end up with only one subarray (given the shuffled array is already sorted ascending or descending) should have the same chance (or is it?). As a result, in average we get better than 50% internal sorting but howmuch better? In my tests I have observed that in average a perfectly shuffled array of unique items turns out to be ~58.68% sorted internally. In other words a 1000 item array would yield in average ~410 sorted subarrays to merge. While my algorithm seems just fine, perhaps it misses some edge cases. I would appreciate helps to know if this 58.68% figure is inline with the math of it. Edit: To gain further insight, I have decided to add some more observations when repeatition is allowed . 2 choices in n length array i.e. (0,1) yields 75% (25 subarrays from 100 items array) 3 choices in n length array (0,1,2) yields 67.28% 4 choices in n length array yields 64.385% 13 choices yields %60.06 n choices in n length array yields 58.68% (same as no repetition)","Sorry that I don't know any better way to express this question. Assuming that we have a perfectly shuffled array of unique numbers, we know that the array is in fact consisted of ascending or descending sorted subarrays. In average howmany such sorted subarrays consist this one particular perfectly shuffled array is the question. As a simple example, please consider an array of 20 integers [0...19] shuffled as [14,2,5,16,18,19,7,6,12,17,3,4,8,11,15,13,1,0,9,10] which is internally sorted in chunks as [[14,2],[5,6,18,19],[7,6],[12,17],[3,4,8,11,15],[13,1,0],[9,10]] so in total we obtain 7 subarrays. Now this observation just paves the way for a very efficient sorting algorithm once you merge them cleverly. Yet it's even better than that. I naively assumed that the number of subarrays in average should be like half the length of the initial array (50% sorted internally). But no, that's only the worst case which you very rarely get. It's like hitting 10101010 or 01010101 in 8 bits. So for 8 bits per se the chance of hitting worst case is . Similarly hitting the best case where we end up with only one subarray (given the shuffled array is already sorted ascending or descending) should have the same chance (or is it?). As a result, in average we get better than 50% internal sorting but howmuch better? In my tests I have observed that in average a perfectly shuffled array of unique items turns out to be ~58.68% sorted internally. In other words a 1000 item array would yield in average ~410 sorted subarrays to merge. While my algorithm seems just fine, perhaps it misses some edge cases. I would appreciate helps to know if this 58.68% figure is inline with the math of it. Edit: To gain further insight, I have decided to add some more observations when repeatition is allowed . 2 choices in n length array i.e. (0,1) yields 75% (25 subarrays from 100 items array) 3 choices in n length array (0,1,2) yields 67.28% 4 choices in n length array yields 64.385% 13 choices yields %60.06 n choices in n length array yields 58.68% (same as no repetition)",2\times\frac{1}{2^8} = \frac{1}{128},['probability']
28,Closed form expression of $\int_{-\infty}^\infty \frac{e^{-x^2}}{1+ae^{bx}}dx$,Closed form expression of,\int_{-\infty}^\infty \frac{e^{-x^2}}{1+ae^{bx}}dx,"I am trying to find an expression for $$ I(a,b) = \int_{-\infty}^\infty \frac{e^{-x^2}}{1+ae^{bx}}dx $$ where $a \ge 0, b$ real but so far without success. There are some easy special values like $I(0,b)=\sqrt{\pi}$ and $I(1,b)=\frac{\sqrt{\pi}}{2}$ . These following identities are not hard to prove by substituting $x\mapsto -x$ and using $\frac{1}{1+p}=1-\frac{1}{1+1/p}$ : \begin{align} &(1) \hspace{1em} I(a,b) = I(a,-b) \\ &(2) \hspace{1em} I\left(a,b\right)+I\left(\frac{1}{a},-b\right)=\sqrt{\pi} \\ &(3) \hspace{1em} I(a,0)=\frac{\sqrt{\pi}}{1+a} \end{align} $(1)$ and $(2)$ two imply $$ (4)\hspace{1em} I\left(a,b\right)+I\left(\frac{1}{a},b\right)=\sqrt{\pi} $$ The asymptotic behaviour is $I(\infty,b)=0$ , $I(a,\infty)=\frac{\sqrt{\pi}}{2}$ . By experimenting I found that $$f(a,b) = \sqrt{\pi}\left(b^{2n} \log a + \frac{1}{1+a}\right)$$ is a solution to $(1)-(4)$ but obviously fails the limits. I tried complex methods, series expansions, Feynman/Fubini tricks, all to no avail. My initial results made me confident enough to give it a go but now I have doubts there is even a solution. Context : The integral showed up in the calculation of the expected value of $\frac{A}{1+BX}$ where $X$ is log-normally distributed; or expected value of $\frac{A}{1+Be^X}$ for normally distributed $X$ . I am also interested in the case where the denominator is squared to find the variance. Additional : Graph of $I(a,b)$","I am trying to find an expression for where real but so far without success. There are some easy special values like and . These following identities are not hard to prove by substituting and using : and two imply The asymptotic behaviour is , . By experimenting I found that is a solution to but obviously fails the limits. I tried complex methods, series expansions, Feynman/Fubini tricks, all to no avail. My initial results made me confident enough to give it a go but now I have doubts there is even a solution. Context : The integral showed up in the calculation of the expected value of where is log-normally distributed; or expected value of for normally distributed . I am also interested in the case where the denominator is squared to find the variance. Additional : Graph of","
I(a,b) = \int_{-\infty}^\infty \frac{e^{-x^2}}{1+ae^{bx}}dx
 a \ge 0, b I(0,b)=\sqrt{\pi} I(1,b)=\frac{\sqrt{\pi}}{2} x\mapsto -x \frac{1}{1+p}=1-\frac{1}{1+1/p} \begin{align}
&(1) \hspace{1em} I(a,b) = I(a,-b) \\
&(2) \hspace{1em} I\left(a,b\right)+I\left(\frac{1}{a},-b\right)=\sqrt{\pi} \\
&(3) \hspace{1em} I(a,0)=\frac{\sqrt{\pi}}{1+a}
\end{align} (1) (2) 
(4)\hspace{1em} I\left(a,b\right)+I\left(\frac{1}{a},b\right)=\sqrt{\pi}
 I(\infty,b)=0 I(a,\infty)=\frac{\sqrt{\pi}}{2} f(a,b) = \sqrt{\pi}\left(b^{2n} \log a + \frac{1}{1+a}\right) (1)-(4) \frac{A}{1+BX} X \frac{A}{1+Be^X} X I(a,b)","['probability', 'integration', 'definite-integrals', 'expected-value']"
29,Surprising appearance of triangular numbers during simple coin flip game,Surprising appearance of triangular numbers during simple coin flip game,,"I have the following problem: You have $n$ coins in a row in some beginning state of heads/tails. Define a process as follows: If you have $k>0$ heads, flip over the coin in the $k$ th position from the left. If you have $k=0$ heads, stop. Otherwise repeat. For example, for THT, the process goes THT $\to$ HHT $\to$ HTT $\to$ TTT For fixed $n$ , calculate the average number of steps it takes to terminate over all $2^n$ possible beginning states. I saw the correct answer is $$\frac{n^2+n}{4}$$ which is the $n_{th}$ triangular number divided by $2$ . I'm not sure why this is the case. I assume this involves a recursive computation. I can see that for $k$ heads and $n$ total coins, you have a $\frac{k}{n}$ probability of flipping a head to a tail, which leaves you with $k-1$ heads. You could then solve for every value of $k \leq n$ , and take the average. However this problem is deterministic and not probabilistic, so I don't think this approach is valid.","I have the following problem: You have coins in a row in some beginning state of heads/tails. Define a process as follows: If you have heads, flip over the coin in the th position from the left. If you have heads, stop. Otherwise repeat. For example, for THT, the process goes THT HHT HTT TTT For fixed , calculate the average number of steps it takes to terminate over all possible beginning states. I saw the correct answer is which is the triangular number divided by . I'm not sure why this is the case. I assume this involves a recursive computation. I can see that for heads and total coins, you have a probability of flipping a head to a tail, which leaves you with heads. You could then solve for every value of , and take the average. However this problem is deterministic and not probabilistic, so I don't think this approach is valid.",n k>0 k k=0 \to \to \to n 2^n \frac{n^2+n}{4} n_{th} 2 k n \frac{k}{n} k-1 k \leq n,"['probability', 'combinatorics', 'probability-theory', 'statistics', 'expected-value']"
30,Mutual information is maximized when Poisson-Binomial reduces to Binomial?,Mutual information is maximized when Poisson-Binomial reduces to Binomial?,,"I have two random variables $X$ and $Y$ . $X$ follows Poisson-Binomial distribution with parameters $\{q_1, \ldots, q_k\}$ . Thus, $X$ can take values in the set $\{0,1,\ldots,k\}$ . $Y$ is a binary random variable. $Y=0$ with probability $\frac{0.1}{1+x}$ when $X=x$ .  Thus, the transition probabilities $\frac{0.1}{1+x}$ is decreasing in $x$ . I am interested in the mutual information between $X$ and $Y$ denoted by $I(X;Y)$ . Specifically, I have a conjecture that the mutual information $I(X;Y)$ is maximum when all $q_i$ 's are equal which leads to a Binomial distribution for $X$ . Also, my intuition is that any transition probability which is decreasing in $x$ ( Similar to $\frac{0.1}{1+x}$ ) leads to this conjecture. Can someone help me prove this? Or provide a counter example? $\underline{\text{Some useful facts that I noted}}$ : For a given $\sum q_i$ and $k$ , the Binomial distribution has the maximum variance. The entropy of Poisson- Binomial distribution is bounded above by the entropy of a binomial distribution with the same $k$ and $\sum q_i$ . I have asked this question in cstheroySE as well to gather attention as the topics on Information Theory don't have a large audience comparatively.","I have two random variables and . follows Poisson-Binomial distribution with parameters . Thus, can take values in the set . is a binary random variable. with probability when .  Thus, the transition probabilities is decreasing in . I am interested in the mutual information between and denoted by . Specifically, I have a conjecture that the mutual information is maximum when all 's are equal which leads to a Binomial distribution for . Also, my intuition is that any transition probability which is decreasing in ( Similar to ) leads to this conjecture. Can someone help me prove this? Or provide a counter example? : For a given and , the Binomial distribution has the maximum variance. The entropy of Poisson- Binomial distribution is bounded above by the entropy of a binomial distribution with the same and . I have asked this question in cstheroySE as well to gather attention as the topics on Information Theory don't have a large audience comparatively.","X Y X \{q_1, \ldots, q_k\} X \{0,1,\ldots,k\} Y Y=0 \frac{0.1}{1+x} X=x \frac{0.1}{1+x} x X Y I(X;Y) I(X;Y) q_i X x \frac{0.1}{1+x} \underline{\text{Some useful facts that I noted}} \sum q_i k k \sum q_i","['probability', 'optimization', 'random-variables', 'binomial-distribution', 'mutual-information']"
31,"If $X_{1},\ldots,X_{n}$ are independent Bernoulli random variables, calculate $E[S_{\tau_{2}}]$","If  are independent Bernoulli random variables, calculate","X_{1},\ldots,X_{n} E[S_{\tau_{2}}]","Let $X_{1},\ldots,X_{n}$ be independent Bernoulli random variables. $P(X_{i}=1)=p$ , $P(X_{i}=0)=q=1-p$ . We denote $S_{n}=X_{1}+\cdots+X_{n}$ . There are $\tau_{1}=\min \{n: X_{n}=1\}$ and $\tau_{2}=\min \{n: X_{n}=X_{n-1}=1\}$ . How to calculate $E[S_{\tau_{2}}]$ ? I've tried through the total expectation formula. I got $$E[S_{\tau_{2}}]=\frac2p+\frac{E[S_{\tau_{2}-\tau_{1}}]+1}{1-p}$$ But it is not clear how to proceed further. A similar question for $\tau_{3}=\min \{n: X_{n}=X_{n-1}=X_{n-2}=1\}$ . How to calculate $E[S_{\tau_{3}}]$ ?","Let be independent Bernoulli random variables. , . We denote . There are and . How to calculate ? I've tried through the total expectation formula. I got But it is not clear how to proceed further. A similar question for . How to calculate ?","X_{1},\ldots,X_{n} P(X_{i}=1)=p P(X_{i}=0)=q=1-p S_{n}=X_{1}+\cdots+X_{n} \tau_{1}=\min \{n: X_{n}=1\} \tau_{2}=\min \{n: X_{n}=X_{n-1}=1\} E[S_{\tau_{2}}] E[S_{\tau_{2}}]=\frac2p+\frac{E[S_{\tau_{2}-\tau_{1}}]+1}{1-p} \tau_{3}=\min \{n: X_{n}=X_{n-1}=X_{n-2}=1\} E[S_{\tau_{3}}]","['probability', 'probability-distributions', 'expected-value']"
32,"Annette, Babette, Colette playing in a $16$ person single elimination tournament","Annette, Babette, Colette playing in a  person single elimination tournament",16,"Annette, Babette, Colette, and $13$ other girls are playing in a $16$ -player, single-elimination tennis tournament. The $16$ players are placed at random in the first column of the bracket shown in the figure to play $8$ games in Round $1$ . The winners of very match are then written into the bracket and play in Round $2$ , and so on. The tournament proceeds until only one player remains. Given that Annette is the best player of the $16$ in the tournament, Babette is $2$ nd best, and Colette is $3$ rd best, and that the best player always wins each match, find the probability that: (a) Annette wins the tournament. (b) Babette is the runner-up of the tournament (she gets to the finals, but loses). (c) Colette is the runner-up of the tournament. For (a), I ended up getting $1$ since Annette defeats everyone in her way. For (b), I ended up getting ${8\over{15}}$ since if Annette's position is fixed on one half of the brackets in Round $1$ , then there's 15 positions remaining and Babette has to occupy one of the $8$ positions in the other half of the brackets in Round $1$ , hence ${8\over{15}}$ . For (c), we need Annette and Babette to be on one half of the brackets in Round $1$ , and Colette to be on the other half. Fix Annette's position, then there's a ${7\over{15}}$ chance of Babette being on Annette's half, and then a ${8\over{14}}$ chance of Colette being on the other half, so the probability that Colette is the runner-up of the tournament is ${7\over{15}}{8\over{14}} = {4\over{15}}$ . Is this correct?","Annette, Babette, Colette, and other girls are playing in a -player, single-elimination tennis tournament. The players are placed at random in the first column of the bracket shown in the figure to play games in Round . The winners of very match are then written into the bracket and play in Round , and so on. The tournament proceeds until only one player remains. Given that Annette is the best player of the in the tournament, Babette is nd best, and Colette is rd best, and that the best player always wins each match, find the probability that: (a) Annette wins the tournament. (b) Babette is the runner-up of the tournament (she gets to the finals, but loses). (c) Colette is the runner-up of the tournament. For (a), I ended up getting since Annette defeats everyone in her way. For (b), I ended up getting since if Annette's position is fixed on one half of the brackets in Round , then there's 15 positions remaining and Babette has to occupy one of the positions in the other half of the brackets in Round , hence . For (c), we need Annette and Babette to be on one half of the brackets in Round , and Colette to be on the other half. Fix Annette's position, then there's a chance of Babette being on Annette's half, and then a chance of Colette being on the other half, so the probability that Colette is the runner-up of the tournament is . Is this correct?",13 16 16 8 1 2 16 2 3 1 {8\over{15}} 1 8 1 {8\over{15}} 1 {7\over{15}} {8\over{14}} {7\over{15}}{8\over{14}} = {4\over{15}},['probability']
33,Find the best upper bound on the probability that I catch at least 5 salmon given that the total number of fish I catch is 10 on average,Find the best upper bound on the probability that I catch at least 5 salmon given that the total number of fish I catch is 10 on average,,"Let X be the number of fishes that I fish every day. Assume that $X \sim Poisson(\lambda)$ . Each fish that I fish is a salmon with probability $0.3$ , a tuna with probability $0.4$ , a swordfish with probability $0.2$ and a carp with probability $0.1$ . Are the numbers of salmons, tunas, swordfishes and carps that I fish every day independent? Using some concentration inequality, give an upper bound on the probability that I fish at least 5 salmons given that the total number of fish that I get is on average 10 (you can admit that the number of salmons is distributed as $Poisson(\lambda p_1)$ ). Make sure that you obtain the best possible bound from the different concentration inequalities that you know. My Attempt For this one, Since you catch on average 10 fish a day, this would mean that if you catch more salmon, then you would catch fewer other types of fish, so intuitively, the number of salmons, tunas, swordfish, and carp are not independent. However, this is not formal enough. Let $W$ denote the number of salmon per day, $V$ the number of tuna, $Y$ the number of swordfishes and $Z$ the number of carp. Then I to show independence, I need to show $$\mathbb{P}(W=w)\mathbb{P}(V=v)=\mathbb{P}(W=w, V=v)$$ and so on for the other random variables. Would the random variables for each fish also be a Poisson distribution? If so, how would I find $\mathbb{P}(W=w, V=v)$ ? The concentration inequalities I know are Markov's inequality, Chebyshev's inequality, and Chernoff's bound. The formulas are $$\mathbb{P}(X\geq c)\leq\frac{\mathbb{E}[X]}{c}$$ $$\mathbb{P}(|X-\mathbb{E}[X]|\geq c)\leq\frac{Var(X)}{c^2}$$ $$\mathbb{P}(X\geq c)\leq\frac{\mathbb{E}[e^{tX}]}{e^{ct}}$$ My question for this part is, if we are only given the average number of fish caught a day, how would we figure out the average number of salmons caught? Also, is it always true that Chebyshev's inequality is more accurate than Markov's and Chernoff's bound is the best?","Let X be the number of fishes that I fish every day. Assume that . Each fish that I fish is a salmon with probability , a tuna with probability , a swordfish with probability and a carp with probability . Are the numbers of salmons, tunas, swordfishes and carps that I fish every day independent? Using some concentration inequality, give an upper bound on the probability that I fish at least 5 salmons given that the total number of fish that I get is on average 10 (you can admit that the number of salmons is distributed as ). Make sure that you obtain the best possible bound from the different concentration inequalities that you know. My Attempt For this one, Since you catch on average 10 fish a day, this would mean that if you catch more salmon, then you would catch fewer other types of fish, so intuitively, the number of salmons, tunas, swordfish, and carp are not independent. However, this is not formal enough. Let denote the number of salmon per day, the number of tuna, the number of swordfishes and the number of carp. Then I to show independence, I need to show and so on for the other random variables. Would the random variables for each fish also be a Poisson distribution? If so, how would I find ? The concentration inequalities I know are Markov's inequality, Chebyshev's inequality, and Chernoff's bound. The formulas are My question for this part is, if we are only given the average number of fish caught a day, how would we figure out the average number of salmons caught? Also, is it always true that Chebyshev's inequality is more accurate than Markov's and Chernoff's bound is the best?","X \sim Poisson(\lambda) 0.3 0.4 0.2 0.1 Poisson(\lambda p_1) W V Y Z \mathbb{P}(W=w)\mathbb{P}(V=v)=\mathbb{P}(W=w, V=v) \mathbb{P}(W=w, V=v) \mathbb{P}(X\geq c)\leq\frac{\mathbb{E}[X]}{c} \mathbb{P}(|X-\mathbb{E}[X]|\geq c)\leq\frac{Var(X)}{c^2} \mathbb{P}(X\geq c)\leq\frac{\mathbb{E}[e^{tX}]}{e^{ct}}","['probability', 'poisson-distribution', 'upper-lower-bounds']"
34,Taking the sup inside the expectation for an infinite collection of random variables,Taking the sup inside the expectation for an infinite collection of random variables,,"Let $(X_t)_{t \in T}$ be an infinite collection of real-valued random variables, where $T$ is a topological space (not necessarily countable). Under which conditions on $t \rightarrow X_t$ and on $T$ it true that $$ \sup_{\substack{K \subset T: \\ |K| < \infty }} \mathbb{E} \big ( \sup_{t \in K} X_t   \big ) = \mathbb{E} \big ( \sup_{t \in T} X_t   \big ). $$ where $\mathbb{E}$ is the expectation. Is continuity of the function $t \mapsto X_t(\omega)$ for example necessary/sufficient? Do we need $T$ to be separable? It seems to me that one direction is always true: $$ \sup_{\substack{K \subset T : \\ |K| < \infty }} \mathbb{E} \big ( \sup_{t \in K} X_t   \big ) =  \sup_{\substack{K \subset T : \\ |K| < \infty }}\int d P(\omega) \, \, \sup_{t \in K} X_t(\omega) \leq  \sup_{\substack{K \subset T: \\ |K| < \infty }}\int d P(\omega) \, \, \sup_{t \in T} X_t(\omega) = \mathbb{E} \big ( \sup_{t \in T} X_t   \big ). $$","Let be an infinite collection of real-valued random variables, where is a topological space (not necessarily countable). Under which conditions on and on it true that where is the expectation. Is continuity of the function for example necessary/sufficient? Do we need to be separable? It seems to me that one direction is always true:","(X_t)_{t \in T} T t \rightarrow X_t T 
\sup_{\substack{K \subset T: \\ |K| < \infty }} \mathbb{E} \big ( \sup_{t \in K} X_t   \big ) = \mathbb{E} \big ( \sup_{t \in T} X_t   \big ).
 \mathbb{E} t \mapsto X_t(\omega) T 
\sup_{\substack{K \subset T : \\ |K| < \infty }} \mathbb{E} \big ( \sup_{t \in K} X_t   \big ) = 
\sup_{\substack{K \subset T : \\ |K| < \infty }}\int d P(\omega) \, \, \sup_{t \in K} X_t(\omega)
\leq 
\sup_{\substack{K \subset T: \\ |K| < \infty }}\int d P(\omega) \, \, \sup_{t \in T} X_t(\omega)
= \mathbb{E} \big ( \sup_{t \in T} X_t   \big ).
","['probability', 'probability-theory', 'probability-distributions', 'random-variables']"
35,How do I approach this Combinatorics problem?,How do I approach this Combinatorics problem?,,"This is a question put up by Jane Street in their monthly Puzzle Archive. The Problem I'll write the problem here as well. Jane received 78 figurines as gifts this holiday season:  12 drummers drumming, 11 pipers piping, 10 lords a-leaping, etc., down to 1 partridge in a pear tree. They are all mixed together in a big bag.  She agrees with her friend Alex that this seems like too many figurines for one person to have, so she decides to give some of her figurines to Alex. Jane will uniformly randomly pull figurines out of the bag one at a time until she pulls out the partridge in a pear tree, and will give Alex all of the figurines she pulled out of the bag (except the partridge, that’s Jane’s favorite). If n is the maximum number of any one type of ornament that Alex gets, what is the expected value of n, to seven significant figures? I approached the problem in this way. Please have a look. My Approach I'll assume the following (in my approach) - Let Ci - Selecting 'i' Identical candies before partridge is taken out. Then I'll compute for each, C2 to C12 - for each type of figurine that fits the criteria. Example C5 - Selecting 5 identical candies before partridge is taken out. It can be anything from type-5 figurine to type 12 (Drummers). Is this the right way to solve it. Am i right in the fundamentals ? Is there a better way to go about the problem.","This is a question put up by Jane Street in their monthly Puzzle Archive. The Problem I'll write the problem here as well. Jane received 78 figurines as gifts this holiday season:  12 drummers drumming, 11 pipers piping, 10 lords a-leaping, etc., down to 1 partridge in a pear tree. They are all mixed together in a big bag.  She agrees with her friend Alex that this seems like too many figurines for one person to have, so she decides to give some of her figurines to Alex. Jane will uniformly randomly pull figurines out of the bag one at a time until she pulls out the partridge in a pear tree, and will give Alex all of the figurines she pulled out of the bag (except the partridge, that’s Jane’s favorite). If n is the maximum number of any one type of ornament that Alex gets, what is the expected value of n, to seven significant figures? I approached the problem in this way. Please have a look. My Approach I'll assume the following (in my approach) - Let Ci - Selecting 'i' Identical candies before partridge is taken out. Then I'll compute for each, C2 to C12 - for each type of figurine that fits the criteria. Example C5 - Selecting 5 identical candies before partridge is taken out. It can be anything from type-5 figurine to type 12 (Drummers). Is this the right way to solve it. Am i right in the fundamentals ? Is there a better way to go about the problem.",,"['probability', 'combinatorics', 'permutations', 'combinations', 'expected-value']"
36,Sampling from an arbitrary distribution on Polish spaces,Sampling from an arbitrary distribution on Polish spaces,,"Let $U\sim \text{Unif}(0,1)$ , and let $\mu \in \mathcal{P}(\mathbb{R})$ be an arbitrary probability measure on $\mathbb{R}$ . Then from $\mu$ , we can derive an associated CDF $F(x) = \mu((-\infty,x])$ . We consider the following inverse of $F$ : $$F^{-1}(u) = \inf\{x \in \mathbb{R}: F(x) \geq u\}.$$ Then it's easy to show that $F^{-1}(U)\sim \mu$ . In other words, $F^{-1}(U)$ is a sample of a random variable distributed like $\mu$ . Is there a similar construction when we now assume that $\mu \in \mathcal{P}(S)$ is a probability distribution on some arbitrary Polish space $S$ ? That is, does there exist a random element $X$ taking values in some other Polish space $T$ and a mapping $\psi: \mathcal{P}(S) \to (T \to S)$ from probability measures on $S$ to measurable functions from $T$ to $S$ such that $\psi(\mu)(X)\sim \mu$ for all $\mu \in \mathcal{P}(S)$ ? I would be interested in proofs that such a mapping exists (or even more interesting, doesn't), but it would be absolutely amazing if the proof was constructive. I'd also be interested in references to the literature where this problem may have already been addressed. Thank you!","Let , and let be an arbitrary probability measure on . Then from , we can derive an associated CDF . We consider the following inverse of : Then it's easy to show that . In other words, is a sample of a random variable distributed like . Is there a similar construction when we now assume that is a probability distribution on some arbitrary Polish space ? That is, does there exist a random element taking values in some other Polish space and a mapping from probability measures on to measurable functions from to such that for all ? I would be interested in proofs that such a mapping exists (or even more interesting, doesn't), but it would be absolutely amazing if the proof was constructive. I'd also be interested in references to the literature where this problem may have already been addressed. Thank you!","U\sim \text{Unif}(0,1) \mu \in \mathcal{P}(\mathbb{R}) \mathbb{R} \mu F(x) = \mu((-\infty,x]) F F^{-1}(u) = \inf\{x \in \mathbb{R}: F(x) \geq u\}. F^{-1}(U)\sim \mu F^{-1}(U) \mu \mu \in \mathcal{P}(S) S X T \psi: \mathcal{P}(S) \to (T \to S) S T S \psi(\mu)(X)\sim \mu \mu \in \mathcal{P}(S)","['probability', 'probability-theory', 'probability-distributions', 'sampling', 'coupling']"
37,A generalization of SLLN: Convergence of combination of iid variables,A generalization of SLLN: Convergence of combination of iid variables,,"Problem: Let $(\varepsilon_i)_{i\geq 1}$ be a sequence of iid random variables . Let $(x_i)_{i\geq 1}$ be a sequence of real numbers. Assume that: $\mathbb E[|\varepsilon_1|]<\infty$ and $\mathbb E[\varepsilon_1]=0$ . $\frac{1}{n} \sum_{i=1}^n (x_i)^2$ is bouned for all $n$ . Prove that: $\lim_{n\rightarrow \infty} \frac{1}{n} \sum_{i=1}^n x_i \varepsilon_i=0$ with probability $1$ . Consequence: If we choose $x_i=1$ for all $i$ . Then (loosely speaking) above problem recovers the strong law of large number . My question: My teacher suggests that I can prove the problem using Kronecker's lemma . But, I have no idea how to apply it. Could anyone give me a hint. Thank you in advance! Edit: Based on the useful comments below, the first condition is redundant. I mean: If the expectation is defined as Lebesgue Integral, then we have: $\mathbb E[\varepsilon_1]=0$ implies $\mathbb E[|\varepsilon|]<\infty$ . Therefore, the first condition should be rewritten: "" $\mathbb E[\varepsilon_1]=0$ in the sense of Lebesgue Integral"" . It is important to note that, the problem does not hold for Cauchy distribution. Indeed, if $\varepsilon_1$ has Cauchy distribution, then $\mathbb E[\varepsilon]$ is undefined in the sense of Lebesgue Integral (see mean of Cauchy ).","Problem: Let be a sequence of iid random variables . Let be a sequence of real numbers. Assume that: and . is bouned for all . Prove that: with probability . Consequence: If we choose for all . Then (loosely speaking) above problem recovers the strong law of large number . My question: My teacher suggests that I can prove the problem using Kronecker's lemma . But, I have no idea how to apply it. Could anyone give me a hint. Thank you in advance! Edit: Based on the useful comments below, the first condition is redundant. I mean: If the expectation is defined as Lebesgue Integral, then we have: implies . Therefore, the first condition should be rewritten: "" in the sense of Lebesgue Integral"" . It is important to note that, the problem does not hold for Cauchy distribution. Indeed, if has Cauchy distribution, then is undefined in the sense of Lebesgue Integral (see mean of Cauchy ).",(\varepsilon_i)_{i\geq 1} (x_i)_{i\geq 1} \mathbb E[|\varepsilon_1|]<\infty \mathbb E[\varepsilon_1]=0 \frac{1}{n} \sum_{i=1}^n (x_i)^2 n \lim_{n\rightarrow \infty} \frac{1}{n} \sum_{i=1}^n x_i \varepsilon_i=0 1 x_i=1 i \mathbb E[\varepsilon_1]=0 \mathbb E[|\varepsilon|]<\infty \mathbb E[\varepsilon_1]=0 \varepsilon_1 \mathbb E[\varepsilon],"['probability', 'probability-limit-theorems', 'law-of-large-numbers']"
38,Proof that Expected Lifetime is longer than Remaining Lifetime if the Hazard Rate is increasing.,Proof that Expected Lifetime is longer than Remaining Lifetime if the Hazard Rate is increasing.,,"Let $X$ be a positive, continuous random variable. Denote the density of $X$ by $f(x)$ and its CDF by $F(x)$ . Let $\bar{F}(x) = 1- F(x)$ be the survival function of $X$ . Given that the Hazard Rate, \begin{align} \lambda(x) &= \frac{f(x)}{\bar{F}(x)} \end{align} is increasing, i.e. $\lambda'(x) \geq 0$ , I want to prove that \begin{align} \mathbf{E}\left[ X-c \mid X>c \right] &\leq \mathbf{E}\left[ X \right]  \end{align} for any constant $c >0$ . Here's what I have tried so far: Let \begin{align} \Lambda(x) &= \int_0^x \lambda(s) \mathop{}\!\mathrm{d} s. \end{align} This implies the following \begin{align} \lambda(x) &= \Lambda'(x), \\ -\Lambda(x) &= \log \left(\bar{F}(x) \right), \\ \bar{F}(x) &= e^{-\Lambda(x) }. \end{align} Writing the expected values as integrals (using the Darth Vader rule) and using the above, I can rewrite the inequality as \begin{align} \int_c^\infty e^{-\int_c^s \lambda(x) \mathop{}\!\mathrm{d}x } \mathop{}\!\mathrm{d}s &\leq \int_0^\infty e^{ -\int_0^s \lambda(x) \mathop{}\!\mathrm{d}x } \mathop{}\!\mathrm{d}s. \end{align} However, I do not see how this holds given $\lambda$ in increasing, and I can't think of a way using that assumption.","Let be a positive, continuous random variable. Denote the density of by and its CDF by . Let be the survival function of . Given that the Hazard Rate, is increasing, i.e. , I want to prove that for any constant . Here's what I have tried so far: Let This implies the following Writing the expected values as integrals (using the Darth Vader rule) and using the above, I can rewrite the inequality as However, I do not see how this holds given in increasing, and I can't think of a way using that assumption.","X X f(x) F(x) \bar{F}(x) = 1- F(x) X \begin{align}
\lambda(x) &= \frac{f(x)}{\bar{F}(x)}
\end{align} \lambda'(x) \geq 0 \begin{align}
\mathbf{E}\left[ X-c \mid X>c \right] &\leq \mathbf{E}\left[ X \right] 
\end{align} c >0 \begin{align}
\Lambda(x) &= \int_0^x \lambda(s) \mathop{}\!\mathrm{d} s.
\end{align} \begin{align}
\lambda(x) &= \Lambda'(x),
\\
-\Lambda(x) &= \log \left(\bar{F}(x) \right),
\\
\bar{F}(x) &= e^{-\Lambda(x) }.
\end{align} \begin{align}
\int_c^\infty e^{-\int_c^s \lambda(x) \mathop{}\!\mathrm{d}x } \mathop{}\!\mathrm{d}s &\leq
\int_0^\infty e^{
-\int_0^s \lambda(x) \mathop{}\!\mathrm{d}x } \mathop{}\!\mathrm{d}s.
\end{align} \lambda","['probability', 'probability-theory', 'inequality', 'conditional-expectation', 'expected-value']"
39,Average squared absolute value of inner product between some unit vectors in a Hilbert space,Average squared absolute value of inner product between some unit vectors in a Hilbert space,,"Let $S$ be a finite set of unit vectors in $d$ -dimensional complex Hilbert space $l_2^d$ . I believe (from numerical experiment) that $\frac{1}{\lvert S \rvert^2} \sum_{x,y \in S} \lvert \langle x,y \rangle \rvert^2 \geq \frac1d$ . In other words, if I choose two vectors from $S$ at random and take the squared absolute value of their inner product, the expectation is at least $\frac1d$ , for any initial choice of $S$ . This feels like it should have a simple proof but it has eluded me. Edited to add: a more general, but actually equivalent, statement is the following. Given an arbitrary probability distribution on the unit sphere of $l_2^d(\mathbb{C})$ , if $x$ and $y$ are chosen independently from this distribution, then $\mathbf{E}(\lvert \langle x, y \rangle \rvert^2) \geq \frac1d$ .","Let be a finite set of unit vectors in -dimensional complex Hilbert space . I believe (from numerical experiment) that . In other words, if I choose two vectors from at random and take the squared absolute value of their inner product, the expectation is at least , for any initial choice of . This feels like it should have a simple proof but it has eluded me. Edited to add: a more general, but actually equivalent, statement is the following. Given an arbitrary probability distribution on the unit sphere of , if and are chosen independently from this distribution, then .","S d l_2^d \frac{1}{\lvert S \rvert^2} \sum_{x,y \in S} \lvert \langle x,y \rangle \rvert^2 \geq \frac1d S \frac1d S l_2^d(\mathbb{C}) x y \mathbf{E}(\lvert \langle x, y \rangle \rvert^2) \geq \frac1d","['probability', 'inequality', 'complex-numbers', 'hilbert-spaces', 'inner-products']"
40,"If two random customers pick four chopsticks at random, what is the probability that they pick one for each color?","If two random customers pick four chopsticks at random, what is the probability that they pick one for each color?",,"Did I solve this probability problem correctly? The question goes like this: In every table in Earl’s Diner, there are exactly four pairs of chopsticks, and each pair is uniquely colored. If two random customers pick four chopsticks at random, what is the probability that they pick one for each color? The answer is in the form $\alpha/\beta$ for some coprime integers $\alpha$ and $\beta$ . Determine the value of $\alpha + \beta$ . My approach went like this: there are four times that the customers will pick a chopstick, and since there are $2$ chopsticks for every color, then by FCP the number of ways that they will pick one of each color will be $$ 2 \times 2 \times 2 \times 2 = 16 $$ And then the total number of ways you can select four chopsticks would be $8C4$ , which would be equivalent to $70$ . Then the probability would be $16:70$ or $8:35$ giving the answer of $43$ . I am unsure if this is the correct solution and answer, can someone please verify it?","Did I solve this probability problem correctly? The question goes like this: In every table in Earl’s Diner, there are exactly four pairs of chopsticks, and each pair is uniquely colored. If two random customers pick four chopsticks at random, what is the probability that they pick one for each color? The answer is in the form for some coprime integers and . Determine the value of . My approach went like this: there are four times that the customers will pick a chopstick, and since there are chopsticks for every color, then by FCP the number of ways that they will pick one of each color will be And then the total number of ways you can select four chopsticks would be , which would be equivalent to . Then the probability would be or giving the answer of . I am unsure if this is the correct solution and answer, can someone please verify it?","\alpha/\beta \alpha \beta \alpha + \beta 2 
2 \times 2 \times 2 \times 2 = 16
 8C4 70 16:70 8:35 43",['probability']
41,Tossing a ring over pegs: Snaring exactly one peg?,Tossing a ring over pegs: Snaring exactly one peg?,,"Let there be a point peg at every $\mathbb{Z}^2$ lattice point. Let a ring be a radius $r$ circle. Q1 . Which value of $r$ maximizes the chance that a randomly placed ring will enclose exactly one peg? Small $r$ may capture no pegs; large $r$ may capture more than one peg. I know this is elementary, but I am not seeing an easy route to calculate $r$ . My real question is this generalization: Q2 . Which value of $r$ maximizes the chance that a randomly placed $(d{-}1)$ sphere in $\mathbb{R}^d$ will enclose exactly one lattice point of $\mathbb{Z}^d$ ? Questions inspired by ""ring toss"": (Image from gameplanent .) Added . Following @GussB's suggestion, I compute $r=0.541$ :","Let there be a point peg at every lattice point. Let a ring be a radius circle. Q1 . Which value of maximizes the chance that a randomly placed ring will enclose exactly one peg? Small may capture no pegs; large may capture more than one peg. I know this is elementary, but I am not seeing an easy route to calculate . My real question is this generalization: Q2 . Which value of maximizes the chance that a randomly placed sphere in will enclose exactly one lattice point of ? Questions inspired by ""ring toss"": (Image from gameplanent .) Added . Following @GussB's suggestion, I compute :",\mathbb{Z}^2 r r r r r r (d{-}1) \mathbb{R}^d \mathbb{Z}^d r=0.541,"['probability', 'geometry', 'plane-geometry']"
42,Independence via conditional expectation and characteristic function,Independence via conditional expectation and characteristic function,,"I have encountered the following statement but can't think of a proper argument to explain/prove it: If for every $A \in \mathcal F$ s.t. $P(A>0)$ we have $ E\left[ \exp (i \lambda X) | A \right] = E \left[\exp(i \lambda X)\right]$ , then $X$ is independent from $\mathcal F$ . I know that the characteristic function defines the distribution completely and independence is somewhat a distribution property, but I am still not very convinced. In particular, only $E\left[ X | A \right] = E \left[X \right] \Rightarrow$ $X$ and $\mathcal F$ are independent, is false, isn't it?","I have encountered the following statement but can't think of a proper argument to explain/prove it: If for every s.t. we have , then is independent from . I know that the characteristic function defines the distribution completely and independence is somewhat a distribution property, but I am still not very convinced. In particular, only and are independent, is false, isn't it?",A \in \mathcal F P(A>0)  E\left[ \exp (i \lambda X) | A \right] = E \left[\exp(i \lambda X)\right] X \mathcal F E\left[ X | A \right] = E \left[X \right] \Rightarrow X \mathcal F,"['probability', 'conditional-expectation', 'independence', 'characteristic-functions']"
43,What are some limitations of the Markovian assumption?,What are some limitations of the Markovian assumption?,,"The Markovian assumption is used to model a number of different phenomena. It basically says that the probability of a state is independent of its history, but only depends upon its immediately previous state. That is, $p(x_i|x_0,x_1, ..., x_{i-1}) = p(x_i|x_{i-1})$ Such a property has been used to model a number of phenomena, like the strength degradation of a structural component using dynamic bayesian networks. I'm curious, what could be the limitations of such an assumption? Can you give some practical examples when such an assumption would be invalid? What could be the consequences in such a case?","The Markovian assumption is used to model a number of different phenomena. It basically says that the probability of a state is independent of its history, but only depends upon its immediately previous state. That is, Such a property has been used to model a number of phenomena, like the strength degradation of a structural component using dynamic bayesian networks. I'm curious, what could be the limitations of such an assumption? Can you give some practical examples when such an assumption would be invalid? What could be the consequences in such a case?","p(x_i|x_0,x_1, ..., x_{i-1}) = p(x_i|x_{i-1})","['probability', 'statistics', 'markov-chains', 'markov-process', 'bayesian']"
44,"$\varphi_{X+Y}(t)=\varphi_X(t) \cdot \varphi_Y(t)$, but X and Y are not independent",", but X and Y are not independent",\varphi_{X+Y}(t)=\varphi_X(t) \cdot \varphi_Y(t),"Consider $X,Y$ random variables with joint distribution: $$f_{X,Y}(x,y)=\begin{cases} \frac14\left[ 1+xy(x^2-y^2)\right] &  |x|\leq 1,\;|y|\leq 1  \\ 0 & \text{otherwise} \end{cases}$$ Proof $\varphi_{X+Y}(t)=\varphi_X(t) \cdot \varphi_Y(t)$ , but $X$ and $Y$ are not independent. Here $\varphi_V(t)$ denotes a characteristic function of random variable $V$ . My step-by-step calculation is shown below, but I think something is wrong. 1. $f_X(x)=\frac{1}{2}$ if $|x|\leq 1$ 2. $f_Y(y)=\frac{1}{2}$ if $|y|\leq 1$ 3. $f_{X,Y}(x,y)\neq f_X(x)f_Y(y)$ implies X and Y are not independent 4. $\varphi_X(t)=\frac{1}{2it}(e^{it}-e^{-it})$ 5. $\varphi_Y(t)=\frac{1}{2it}(e^{it}-e^{-it})$ 6. $\varphi_{X+Y}(t)=\frac{1}{2it}(e^{it}-e^{-it})$ Obviously I got $\varphi_{X+Y}(t) \neq \varphi_X(t) \cdot \varphi_Y(t)$ . What went wrong?","Consider random variables with joint distribution: Proof , but and are not independent. Here denotes a characteristic function of random variable . My step-by-step calculation is shown below, but I think something is wrong. 1. if 2. if 3. implies X and Y are not independent 4. 5. 6. Obviously I got . What went wrong?","X,Y f_{X,Y}(x,y)=\begin{cases}
\frac14\left[ 1+xy(x^2-y^2)\right] &  |x|\leq 1,\;|y|\leq 1  \\
0 & \text{otherwise}
\end{cases} \varphi_{X+Y}(t)=\varphi_X(t) \cdot \varphi_Y(t) X Y \varphi_V(t) V f_X(x)=\frac{1}{2} |x|\leq 1 f_Y(y)=\frac{1}{2} |y|\leq 1 f_{X,Y}(x,y)\neq f_X(x)f_Y(y) \varphi_X(t)=\frac{1}{2it}(e^{it}-e^{-it}) \varphi_Y(t)=\frac{1}{2it}(e^{it}-e^{-it}) \varphi_{X+Y}(t)=\frac{1}{2it}(e^{it}-e^{-it}) \varphi_{X+Y}(t) \neq \varphi_X(t) \cdot \varphi_Y(t)","['probability', 'characteristic-functions']"
45,What can be said about i.i.d. $X$ and $Y$ such that $XY=(X+Y)/2$ in distribution?,What can be said about i.i.d.  and  such that  in distribution?,X Y XY=(X+Y)/2,"Let $X$ and $Y$ be i.i.d. If $(X+Y)/2$ is equal in distribution to $XY$ , then what do we know about the distributions of $X$ and $Y$ ? I feel like I can't say much about these distributions.  I can only think of degenerate examples, but I have a feeling that there is something crafty going on here that I am missing.","Let and be i.i.d. If is equal in distribution to , then what do we know about the distributions of and ? I feel like I can't say much about these distributions.  I can only think of degenerate examples, but I have a feeling that there is something crafty going on here that I am missing.",X Y (X+Y)/2 XY X Y,"['probability', 'probability-theory', 'probability-distributions', 'independence']"
46,I wake up in a random class and hear 6 biology-related words. How certain should I be that I'm in Biology class?,I wake up in a random class and hear 6 biology-related words. How certain should I be that I'm in Biology class?,,"Suppose I'm sleeping in some class. I wake up and I hear 6 topic-specific words that seem related to biology. I'm asked to guess whether I'm in Biology class? How confident should I be? I think this can be presented with the following Bayesian network, with one parent node and 6 children nodes. Suppose that $$P(word_1|biology)=0.6$$ $$P(word_2|biology)=0.6$$ $$P(word_3|biology)=0.7$$ $$P(word_4|biology)=0.7$$ $$P(word_5|biology)=0.8$$ $$P(word_6|biology)=0.8$$ Suppose that I think there's some chance I could hear these words in some other class, such as chemistry. Hence, let $P(word_i|\neg biology)$ be $P(word_i|biology)-0.1$ : $$P(word_1|\neg biology)=0.5$$ $$P(word_2|\neg biology)=0.5$$ $$P(word_3|\neg biology)=0.6$$ $$P(word_4|biology)=0.6$$ $$P(word_5|\neg biology)=0.7$$ $$P(word_6|\neg biology)=0.7$$ My prior credence of being in biology class is $0.1$ . How do I update to form a posterior after hearing these 6 words? Upon hearing word 1, using Bayes rule I update as follows: $$P(class=bio|word_1)=\frac{p(word_1|bio)*p(bio)}{p(word_1|bio)*p(bio)+p(word_1|\neg bio)*p(\neg bio)}=\frac{0.6*0.1}{(0.1*0.6)+(0.5*0.9)} \approx 0.1176$$ Do I keep updating like this sequentially for each word, plugging in the previous posterior as the next prior? Such as, $$P(class=bio|word_2)=\frac{p(word_2|bio)*p(bio)}{p(word_2|bio)*p(bio)+p(word_2|\neg bio)*p(\neg bio)}=\frac{0.6*0.1176}{(0.1176*0.6)+(0.5*0.8824)} \approx 0.1378$$ And so on... Is that correct?","Suppose I'm sleeping in some class. I wake up and I hear 6 topic-specific words that seem related to biology. I'm asked to guess whether I'm in Biology class? How confident should I be? I think this can be presented with the following Bayesian network, with one parent node and 6 children nodes. Suppose that Suppose that I think there's some chance I could hear these words in some other class, such as chemistry. Hence, let be : My prior credence of being in biology class is . How do I update to form a posterior after hearing these 6 words? Upon hearing word 1, using Bayes rule I update as follows: Do I keep updating like this sequentially for each word, plugging in the previous posterior as the next prior? Such as, And so on... Is that correct?",P(word_1|biology)=0.6 P(word_2|biology)=0.6 P(word_3|biology)=0.7 P(word_4|biology)=0.7 P(word_5|biology)=0.8 P(word_6|biology)=0.8 P(word_i|\neg biology) P(word_i|biology)-0.1 P(word_1|\neg biology)=0.5 P(word_2|\neg biology)=0.5 P(word_3|\neg biology)=0.6 P(word_4|biology)=0.6 P(word_5|\neg biology)=0.7 P(word_6|\neg biology)=0.7 0.1 P(class=bio|word_1)=\frac{p(word_1|bio)*p(bio)}{p(word_1|bio)*p(bio)+p(word_1|\neg bio)*p(\neg bio)}=\frac{0.6*0.1}{(0.1*0.6)+(0.5*0.9)} \approx 0.1176 P(class=bio|word_2)=\frac{p(word_2|bio)*p(bio)}{p(word_2|bio)*p(bio)+p(word_2|\neg bio)*p(\neg bio)}=\frac{0.6*0.1176}{(0.1176*0.6)+(0.5*0.8824)} \approx 0.1378,"['probability', 'bayesian', 'bayes-theorem', 'bayesian-network']"
47,Dirac measure as an image of pushforward map,Dirac measure as an image of pushforward map,,"Let $X, Y$ be two compact spaces and let $Q: X\times Y \to X$ be the canonical projection map. Denote by $Q_*: M(X\times Y)\to M(X)$ the pushforward map, where $M(\cdot)$ is the space of probability Radon measures. Let $Z$ be a subset of $M(X\times Y)$ and assume that $\delta_x\in Q_*(Z)$ , where $\delta_x$ denotes the point mass measure. Then, I want to show that there exists a measure $\nu\in M(Y)$ s.t. $\delta_x\otimes \nu\in Z$ . I am not sure how to do it since I know that not every measure on a product space is given by a product of measures. Thanks!","Let be two compact spaces and let be the canonical projection map. Denote by the pushforward map, where is the space of probability Radon measures. Let be a subset of and assume that , where denotes the point mass measure. Then, I want to show that there exists a measure s.t. . I am not sure how to do it since I know that not every measure on a product space is given by a product of measures. Thanks!","X, Y Q: X\times Y \to X Q_*: M(X\times Y)\to M(X) M(\cdot) Z M(X\times Y) \delta_x\in Q_*(Z) \delta_x \nu\in M(Y) \delta_x\otimes \nu\in Z","['probability', 'measure-theory']"
48,Finding the distribution of the reciprocal of a random variable,Finding the distribution of the reciprocal of a random variable,,"Let $X\sim \text{Exp}(\lambda)$ be an exponentially distributed random variable.  That is it has the probability density function $f(x)=\lambda e^{-\lambda x}1_{[0,\infty)}(x)$ and cumulative distribution function $$F_X(x)=\int_ {0}^x\lambda e^{-\lambda x}=[-e^{-\lambda x}]_{0}^x=1-e^{-\lambda x}$$ Let $Y:= \frac{1}{X}$. We have for $F_Y(x)$: $$F_Y(x)=\mathbb{P}({Y \leq x})=\mathbb{P}\left(\frac{1}{X}\leq x\right )=\mathbb{P}\left(X\geq\frac{1}{x}\right )=1-\mathbb{P}\left(X < \frac{1}{x} \right)=^!1-F_X\left(\frac{1}{x}\right)$$ The problem at $!$ is that definition of cumulative density function requires a non strict inequality so I don't know why this holds. Aside from that, how does one get the distribution of $Y$ from the cumulative density function/probability density function? How do we deal with $Y$ at $X=0$ (does $X$ attain $0$ as a value even)","Let $X\sim \text{Exp}(\lambda)$ be an exponentially distributed random variable.  That is it has the probability density function $f(x)=\lambda e^{-\lambda x}1_{[0,\infty)}(x)$ and cumulative distribution function $$F_X(x)=\int_ {0}^x\lambda e^{-\lambda x}=[-e^{-\lambda x}]_{0}^x=1-e^{-\lambda x}$$ Let $Y:= \frac{1}{X}$. We have for $F_Y(x)$: $$F_Y(x)=\mathbb{P}({Y \leq x})=\mathbb{P}\left(\frac{1}{X}\leq x\right )=\mathbb{P}\left(X\geq\frac{1}{x}\right )=1-\mathbb{P}\left(X < \frac{1}{x} \right)=^!1-F_X\left(\frac{1}{x}\right)$$ The problem at $!$ is that definition of cumulative density function requires a non strict inequality so I don't know why this holds. Aside from that, how does one get the distribution of $Y$ from the cumulative density function/probability density function? How do we deal with $Y$ at $X=0$ (does $X$ attain $0$ as a value even)",,"['probability', 'inequality']"
49,A coin-tossing game with an unexpected expected value?,A coin-tossing game with an unexpected expected value?,,"Consider independent tosses of a rather biased coin that has $$\begin{align} \Pr({\tt Head})&=1/G\\ \Pr({\tt Tail})&=1-\Pr({\tt Head}),\end{align}$$  where $G$ is Graham's Number . Let the first $100$ tosses establish a ""target"" pattern, then let $N$ be the number of additional tosses needed to get a repetition of that target pattern (allowing overlap). E.g., a sequence that begins with $101$ consecutive ${\tt Tail}$s would have $N=1$. Question : $\ \mathbb{E}(N)\ =\ ?\quad$ I'm posting in the spirit of this advice , and will eventually post the answer if no one else does so.","Consider independent tosses of a rather biased coin that has $$\begin{align} \Pr({\tt Head})&=1/G\\ \Pr({\tt Tail})&=1-\Pr({\tt Head}),\end{align}$$  where $G$ is Graham's Number . Let the first $100$ tosses establish a ""target"" pattern, then let $N$ be the number of additional tosses needed to get a repetition of that target pattern (allowing overlap). E.g., a sequence that begins with $101$ consecutive ${\tt Tail}$s would have $N=1$. Question : $\ \mathbb{E}(N)\ =\ ?\quad$ I'm posting in the spirit of this advice , and will eventually post the answer if no one else does so.",,"['probability', 'combinatorics']"
50,Optimal strategy for guessing game,Optimal strategy for guessing game,,"The game goes like this: I pick a random number between 1 and 1000. You have to guess what the number is. If you guess right, you get 1150. If you guess wrong, you lose 98. You may also ask for any number of hints, but the first hint will cost you 2, the second hint will cost 4, third will cost 8, etc. The hints are only yes/no questions. What is the optimal strategy? I thought about doing this with binary search but that uses too many hints. However binary search removes half the values every time and I can't figure out something that is more efficient. Is there a better strategy?","The game goes like this: I pick a random number between 1 and 1000. You have to guess what the number is. If you guess right, you get 1150. If you guess wrong, you lose 98. You may also ask for any number of hints, but the first hint will cost you 2, the second hint will cost 4, third will cost 8, etc. The hints are only yes/no questions. What is the optimal strategy? I thought about doing this with binary search but that uses too many hints. However binary search removes half the values every time and I can't figure out something that is more efficient. Is there a better strategy?",,"['probability', 'game-theory']"
51,Is a sequence of bounded random variables uniformly integrable?,Is a sequence of bounded random variables uniformly integrable?,,"It seems to me that a sequence of uniformly bounded random variables $\{X_n\}_{n=1}^\infty$ on a probability space $(\Omega_n, \mathcal{F}_n, P)$ such that $|X_n(\omega)| \leq M$ for all $\omega \in \Omega_n$ is uniform integrable. For if $I$ is the indicator function, suppose $\varepsilon > 0$ is given and let $k = 2M$, then $$ E(|X_n| I(|X_n| \geq k)) = E(|X_n| I(|X_n| \geq 2M)) = E(|X_n|\cdot 0) = 0 < \varepsilon $$ Is it true that a sequence of uniformly bounded random variables are uniformly integrable?","It seems to me that a sequence of uniformly bounded random variables $\{X_n\}_{n=1}^\infty$ on a probability space $(\Omega_n, \mathcal{F}_n, P)$ such that $|X_n(\omega)| \leq M$ for all $\omega \in \Omega_n$ is uniform integrable. For if $I$ is the indicator function, suppose $\varepsilon > 0$ is given and let $k = 2M$, then $$ E(|X_n| I(|X_n| \geq k)) = E(|X_n| I(|X_n| \geq 2M)) = E(|X_n|\cdot 0) = 0 < \varepsilon $$ Is it true that a sequence of uniformly bounded random variables are uniformly integrable?",,"['probability', 'probability-theory', 'random-variables', 'uniform-integrability']"
52,"For a random variable $X$, how can we characterize the events that unambigously describe possible properties of the outcome of $X$?","For a random variable , how can we characterize the events that unambigously describe possible properties of the outcome of ?",X X,"Let $(\Omega, \mathcal{A}, P)$ be a probability space, $(\hat{\Omega}, \hat{\mathcal{A}})$ be a measurable space and $X : \Omega \rightarrow \hat{\Omega}$ be a random variable. We say that an event $A \in \mathcal{A}$ is a possible property of $X$ if and only if, for all $w \in \Omega$, knowing the value of $X(w)$ is enough information to unambigously decide whether $w \in A$ or $w \in A^{c}$ ( = whether $A$ happened or did not happen). In other words, $A \in \mathcal{A}$ is a possible property of $X$ if and only if there is a set $E \subseteq \hat{\Omega}$ such that $A = X^{-1}(E)$. If $A$ is a possible property of $X$, one can always choose $E \subseteq X(\Omega)$. We denote the set of all possible properties of $X$ as $\mathcal{B}(X)$. I am trying to characterize $\mathcal{B}(X)$  and understand its relation to the $\sigma$-algebra generated by $X$. The $\sigma$-algebra generated by $X$ is the smallest $\sigma$-algebra such that $X$ is measurable and is given by $$ \sigma(X) := X^{-1}(\hat{\mathcal{A}}) =\{X^{-1}(\hat{A}) \ \vert \ \hat{A} \in \hat{\mathcal{A}}  \}. $$ Clearly, all events in $\sigma(X)$ are possible properties of $X$ and it holds that $\sigma(X) \subseteq \mathcal{B}(X) \subseteq \mathcal{A} $. Note, that $\sigma(X)$ depends on $X$ and $\hat{\mathcal{A}}$. I wonder what necessary and sufficient conditions on $X$ and $\hat{\mathcal{A}}$ are such that $$ \sigma(X) = \mathcal{B}(X).  $$ It is not hard to see that $$ \mathcal{B}(X) =  X^{-1}(\mathcal{P}(\hat{\Omega})) \cap \mathcal{A}, $$ where $\mathcal{P}$ denotes the power set. In particular, this implies that $\mathcal{B}(X)$ is always a $\sigma$-algebra. If we write $$ \sigma(X) =  X^{-1}(\hat{\mathcal{A}}) \cap \mathcal{A}  ,$$ it becomes clear that $\hat{\mathcal{A}} = \mathcal{P}(\hat{\Omega})$ is a sufficient condition for $ \sigma(X) = \mathcal{B}(X)$. However, I do not think this condition is necessary and it is rarely fulfilled in practical applications. What are conditions on $X$ and $\hat{\mathcal{A}}$ for $ \sigma(X) = \mathcal{B}(X)$ that are both necessary and sufficient? I'm happy to hear as many thoughts as possible on this! Kind regards, Joker","Let $(\Omega, \mathcal{A}, P)$ be a probability space, $(\hat{\Omega}, \hat{\mathcal{A}})$ be a measurable space and $X : \Omega \rightarrow \hat{\Omega}$ be a random variable. We say that an event $A \in \mathcal{A}$ is a possible property of $X$ if and only if, for all $w \in \Omega$, knowing the value of $X(w)$ is enough information to unambigously decide whether $w \in A$ or $w \in A^{c}$ ( = whether $A$ happened or did not happen). In other words, $A \in \mathcal{A}$ is a possible property of $X$ if and only if there is a set $E \subseteq \hat{\Omega}$ such that $A = X^{-1}(E)$. If $A$ is a possible property of $X$, one can always choose $E \subseteq X(\Omega)$. We denote the set of all possible properties of $X$ as $\mathcal{B}(X)$. I am trying to characterize $\mathcal{B}(X)$  and understand its relation to the $\sigma$-algebra generated by $X$. The $\sigma$-algebra generated by $X$ is the smallest $\sigma$-algebra such that $X$ is measurable and is given by $$ \sigma(X) := X^{-1}(\hat{\mathcal{A}}) =\{X^{-1}(\hat{A}) \ \vert \ \hat{A} \in \hat{\mathcal{A}}  \}. $$ Clearly, all events in $\sigma(X)$ are possible properties of $X$ and it holds that $\sigma(X) \subseteq \mathcal{B}(X) \subseteq \mathcal{A} $. Note, that $\sigma(X)$ depends on $X$ and $\hat{\mathcal{A}}$. I wonder what necessary and sufficient conditions on $X$ and $\hat{\mathcal{A}}$ are such that $$ \sigma(X) = \mathcal{B}(X).  $$ It is not hard to see that $$ \mathcal{B}(X) =  X^{-1}(\mathcal{P}(\hat{\Omega})) \cap \mathcal{A}, $$ where $\mathcal{P}$ denotes the power set. In particular, this implies that $\mathcal{B}(X)$ is always a $\sigma$-algebra. If we write $$ \sigma(X) =  X^{-1}(\hat{\mathcal{A}}) \cap \mathcal{A}  ,$$ it becomes clear that $\hat{\mathcal{A}} = \mathcal{P}(\hat{\Omega})$ is a sufficient condition for $ \sigma(X) = \mathcal{B}(X)$. However, I do not think this condition is necessary and it is rarely fulfilled in practical applications. What are conditions on $X$ and $\hat{\mathcal{A}}$ for $ \sigma(X) = \mathcal{B}(X)$ that are both necessary and sufficient? I'm happy to hear as many thoughts as possible on this! Kind regards, Joker",,"['probability', 'measure-theory', 'random-variables', 'stochastic-filtering']"
53,Almost sure convergence of posterior distribution to parameter,Almost sure convergence of posterior distribution to parameter,,"I'm trying to solve an exercise form Rick Durrett's book on probability, following  a section on almost sure convergence of martingales: Let $Z_1,Z_2,...$ be i.i.d standard normal random variables, let $\theta$ be an independent random variable with finite mean, and let $Y_i:=Z_i+\theta$. $\;$ Show that $\mathbb{E}[\theta \vert Y_1,...,Y_n] \overset{n\rightarrow \infty}{\rightarrow}\theta$ almost surely. I know that $\mathbb{E}\Big[ \frac{1}{n} \sum_{i=1}^n Y_i \Big \vert Y_1,...,Y_n \Big]=  \frac{1}{n} \sum_{i=1}^nY_i$, and that by the strong law of large numbers we know that $\frac{1}{n} \sum_{i=1}^nY_i \overset{n\rightarrow \infty}{\rightarrow}\theta$ almost surely. I'm unsure as to how best to proceed from here, or in fact how to use the independence of $\theta$. $\;$ I would appreciate any help or hints.","I'm trying to solve an exercise form Rick Durrett's book on probability, following  a section on almost sure convergence of martingales: Let $Z_1,Z_2,...$ be i.i.d standard normal random variables, let $\theta$ be an independent random variable with finite mean, and let $Y_i:=Z_i+\theta$. $\;$ Show that $\mathbb{E}[\theta \vert Y_1,...,Y_n] \overset{n\rightarrow \infty}{\rightarrow}\theta$ almost surely. I know that $\mathbb{E}\Big[ \frac{1}{n} \sum_{i=1}^n Y_i \Big \vert Y_1,...,Y_n \Big]=  \frac{1}{n} \sum_{i=1}^nY_i$, and that by the strong law of large numbers we know that $\frac{1}{n} \sum_{i=1}^nY_i \overset{n\rightarrow \infty}{\rightarrow}\theta$ almost surely. I'm unsure as to how best to proceed from here, or in fact how to use the independence of $\theta$. $\;$ I would appreciate any help or hints.",,"['probability', 'conditional-expectation', 'martingales']"
54,"Probability of ""union"" of events","Probability of ""union"" of events",,"Let $\{X(t)\}$ be a stochastic process with $t\in [0, T]$. It is possible to prove that $P(\exists t\in [0, T] : X(t) >a) \leq\int_0^TP(X(t)>a)dt$? My idea was to write the left hand side as union of events, the problem is this union is not countable... Is that a problem?","Let $\{X(t)\}$ be a stochastic process with $t\in [0, T]$. It is possible to prove that $P(\exists t\in [0, T] : X(t) >a) \leq\int_0^TP(X(t)>a)dt$? My idea was to write the left hand side as union of events, the problem is this union is not countable... Is that a problem?",,"['probability', 'probability-theory']"
55,"Prove $\lim_{n\rightarrow \infty}\left(\sup_{\theta\in \Theta}\left| \frac{1}{n}\sum_{i=1}^n f(X_i,\theta)-E(f(X,\theta)) \right|\right)=0$",Prove,"\lim_{n\rightarrow \infty}\left(\sup_{\theta\in \Theta}\left| \frac{1}{n}\sum_{i=1}^n f(X_i,\theta)-E(f(X,\theta)) \right|\right)=0","$\Theta\in\mathbb{R}^d$ is a compact set, $f(x,\theta):\mathbb{R}^p\times Y\in \mathbb{R}^+$ are continous functions in $\theta$ for every $x$ . Let $X,X_1,\dots,X_n,\dots$ be i.i.d random vectors. Then $\displaystyle E\left( \sup_{\theta\in \Theta}f(X,\theta)\right)<\infty\implies \lim_{n\rightarrow \infty}\left(\sup_{\theta\in \Theta}\left| \frac{1}{n}\sum_{i=1}^n f(X_i,\theta)-E(f(X,\theta)) \right|\right)=0$ I don't see an immediate way of doing this rather than working with the definition of limit. The idea is to show that there is $N$ such that $\sup_{\theta\in \Theta}\left| \frac{1}{n}\sum_{i=1}^n f(X_i,\theta)-E(f(X,\theta)) \right|<\epsilon$ for a given $\epsilon$ . I think the compactness of $\Theta$ might be used to argue that there is a $\theta_0$ for which $\sup_{\theta\in \Theta}f(X,\theta) = f(X,\theta_0)$ . Then I would apply the same to the second equation $\left| \frac{1}{n}\sum_{i=1}^n f(X_i,\theta_0)-E(f(X,\theta_0)) \right|<\epsilon$ . But I find the $ \frac{1}{n}$ in $\displaystyle\frac{1}{n}\sum_{i=1}^n f(X_i,\theta_0)$ problematic because it will make the term smaller meanwhile $E(f(X,\theta_0))$ doesn't seem to decrease.","is a compact set, are continous functions in for every . Let be i.i.d random vectors. Then I don't see an immediate way of doing this rather than working with the definition of limit. The idea is to show that there is such that for a given . I think the compactness of might be used to argue that there is a for which . Then I would apply the same to the second equation . But I find the in problematic because it will make the term smaller meanwhile doesn't seem to decrease.","\Theta\in\mathbb{R}^d f(x,\theta):\mathbb{R}^p\times Y\in \mathbb{R}^+ \theta x X,X_1,\dots,X_n,\dots \displaystyle E\left( \sup_{\theta\in \Theta}f(X,\theta)\right)<\infty\implies \lim_{n\rightarrow \infty}\left(\sup_{\theta\in \Theta}\left| \frac{1}{n}\sum_{i=1}^n f(X_i,\theta)-E(f(X,\theta)) \right|\right)=0 N \sup_{\theta\in \Theta}\left| \frac{1}{n}\sum_{i=1}^n f(X_i,\theta)-E(f(X,\theta)) \right|<\epsilon \epsilon \Theta \theta_0 \sup_{\theta\in \Theta}f(X,\theta) = f(X,\theta_0) \left| \frac{1}{n}\sum_{i=1}^n f(X_i,\theta_0)-E(f(X,\theta_0)) \right|<\epsilon  \frac{1}{n} \displaystyle\frac{1}{n}\sum_{i=1}^n f(X_i,\theta_0) E(f(X,\theta_0))","['probability', 'limits', 'probability-theory']"
56,"Probability of ending on a certain point of a circle after randomly moving clockwise or counterclockwise, in succession.","Probability of ending on a certain point of a circle after randomly moving clockwise or counterclockwise, in succession.",,"Suppose that $100$ points are equally spaced around a circular path, and at $99$ of these points there are sheep which do not move, and at the other point there is a wolf who will randomly move. Suppose that each time the wolf moves, he will be equally likely to move clockwise by one point or counterclockwise by one point, and if a sheep is at his new location he will eat it. If the wolf continues moving randomly until all of the sheep are eaten, what is the probability that the sheep who is located directly opposite the wolf’s starting point will be the last one eaten? Start at a Solution: I think there would be $2^{99}$ different ways the wolf could move. Consider a more simple situation where there are $8$ points where the wolf starts at point $1$ and the points are numbered $1$-$8$ going clockwise. Then the wolf must end on point $5$. After writing out all the possibilities where it ends on $5$, it appears as if it initially has $2$ numbers to go to, followed by $4,6,6,4,2$. Then maybe with $10$ points it would be $2,4,6,8,8,6,4,2$. So perhaps there is a pattern but I don't know how I'd use it to find a solution. Edit: I think both of my above thoughts are incorrect because from my understanding, the wolf wouldn't skip points where no sheep are present.","Suppose that $100$ points are equally spaced around a circular path, and at $99$ of these points there are sheep which do not move, and at the other point there is a wolf who will randomly move. Suppose that each time the wolf moves, he will be equally likely to move clockwise by one point or counterclockwise by one point, and if a sheep is at his new location he will eat it. If the wolf continues moving randomly until all of the sheep are eaten, what is the probability that the sheep who is located directly opposite the wolf’s starting point will be the last one eaten? Start at a Solution: I think there would be $2^{99}$ different ways the wolf could move. Consider a more simple situation where there are $8$ points where the wolf starts at point $1$ and the points are numbered $1$-$8$ going clockwise. Then the wolf must end on point $5$. After writing out all the possibilities where it ends on $5$, it appears as if it initially has $2$ numbers to go to, followed by $4,6,6,4,2$. Then maybe with $10$ points it would be $2,4,6,8,8,6,4,2$. So perhaps there is a pattern but I don't know how I'd use it to find a solution. Edit: I think both of my above thoughts are incorrect because from my understanding, the wolf wouldn't skip points where no sheep are present.",,"['probability', 'combinatorics', 'statistics']"
57,First approximation of the expected value of the positive part of a random variable,First approximation of the expected value of the positive part of a random variable,,"Consider a random variable $X$ with mean zero ( $\mu_X = 0$ ), known variance ( $\sigma_X^2$ ), and all other moments finite but unknown. I am interested in obtaining an estimate of the expected value of the positive part of this random variable, i.e., given $X^{+} \equiv \max(0, X)$ I want $\mathbb{E}(X^{+})$ . Preferably this would only be a function of the variance as I have no other information, but this may not be possible. It is simple to apply a standard Taylor series approach to this problem, e.g. if $f$ is the positive part function: $$\mathbb{E}\left[f(X)\right]\approx f(\mu _{X})+{\frac  {f''(\mu _{X})}{2}}\sigma _{X}^{2}$$ However, as $\mu_X = 0$ , we need to find $f''(\mu_X)$ , which is undefined. It is easy to make a function which converges to $X^+$ in some limit and has defined $f''(\mu_X)$ , but this behavior is not unique, so I don't expect the behavior this function has to also apply to $X^+$ . It is not difficult to show that $\mathbb{E}(X^{+}) < \sigma_X$ , but I'd prefer to know something like $\mathbb{E}(X^{+}) \approx \alpha \, \sigma_X$ , where $\alpha$ is a constant to be determined. (Thanks to stud_iisc for noting that the inequality is strict.) If it is necessary to assume that $X$ is Gaussian to get a result, that may be acceptable, though $X$ may not be Gaussian.","Consider a random variable with mean zero ( ), known variance ( ), and all other moments finite but unknown. I am interested in obtaining an estimate of the expected value of the positive part of this random variable, i.e., given I want . Preferably this would only be a function of the variance as I have no other information, but this may not be possible. It is simple to apply a standard Taylor series approach to this problem, e.g. if is the positive part function: However, as , we need to find , which is undefined. It is easy to make a function which converges to in some limit and has defined , but this behavior is not unique, so I don't expect the behavior this function has to also apply to . It is not difficult to show that , but I'd prefer to know something like , where is a constant to be determined. (Thanks to stud_iisc for noting that the inequality is strict.) If it is necessary to assume that is Gaussian to get a result, that may be acceptable, though may not be Gaussian.","X \mu_X = 0 \sigma_X^2 X^{+} \equiv \max(0, X) \mathbb{E}(X^{+}) f \mathbb{E}\left[f(X)\right]\approx f(\mu _{X})+{\frac  {f''(\mu _{X})}{2}}\sigma _{X}^{2} \mu_X = 0 f''(\mu_X) X^+ f''(\mu_X) X^+ \mathbb{E}(X^{+}) < \sigma_X \mathbb{E}(X^{+}) \approx \alpha \, \sigma_X \alpha X X","['probability', 'random-variables']"
58,Maximum of stopping times is not a stopping time,Maximum of stopping times is not a stopping time,,"Is the maximum of two stopping times a stopping time? I wrote $$\{max(\tau, \sigma) \le t\} = \{\tau \le t\} \cap \{\sigma \le t\} \in \mathcal F_t$$ Because both $\tau$ and $\sigma$ are stopping times. In my book there is written that it isn't though. Can you tell me where the error is?","Is the maximum of two stopping times a stopping time? I wrote $$\{max(\tau, \sigma) \le t\} = \{\tau \le t\} \cap \{\sigma \le t\} \in \mathcal F_t$$ Because both $\tau$ and $\sigma$ are stopping times. In my book there is written that it isn't though. Can you tell me where the error is?",,"['probability', 'probability-theory', 'stopping-times']"
59,Intuition behind a probability measure,Intuition behind a probability measure,,"These are some related questions to the question posed here . I don't think it's a duplicate. What is a probability measure? How do they differ from measure spaces? And could anyone elaborate on the ""physical"" interpretation of a probability measure? For any measurable subset here, what is its interpretation of its measure? Can anybody answer these questions by providing some enlightening examples along the way?","These are some related questions to the question posed here . I don't think it's a duplicate. What is a probability measure? How do they differ from measure spaces? And could anyone elaborate on the ""physical"" interpretation of a probability measure? For any measurable subset here, what is its interpretation of its measure? Can anybody answer these questions by providing some enlightening examples along the way?",,"['probability', 'probability-theory', 'measure-theory']"
60,Construction of random elements in Hilbert space which are almost surely orthogonal.,Construction of random elements in Hilbert space which are almost surely orthogonal.,,"Let $(\mathcal{H},\langle \cdot, \cdot \rangle)$ be an arbitrary Hilbert space. Can one construct two independent and identically distributed random elements $X,Y:(\Omega,\mathbb{F},P)\to (\mathcal{H},\langle \cdot, \cdot \rangle)$ with $\text{supp}(X)\not = \{0\}$,  such that $$ \langle X(\omega),Y(\omega) \rangle  =0 $$ for almost all $\omega\in\Omega$, i.e.  $X$ and $Y$ are almost surely orthogonal. Question: I have shown that this can not be done for separable Hilbert spaces $\mathcal{H}$, but is it possible to make such a construction in non-separable Hilbert spaces?","Let $(\mathcal{H},\langle \cdot, \cdot \rangle)$ be an arbitrary Hilbert space. Can one construct two independent and identically distributed random elements $X,Y:(\Omega,\mathbb{F},P)\to (\mathcal{H},\langle \cdot, \cdot \rangle)$ with $\text{supp}(X)\not = \{0\}$,  such that $$ \langle X(\omega),Y(\omega) \rangle  =0 $$ for almost all $\omega\in\Omega$, i.e.  $X$ and $Y$ are almost surely orthogonal. Question: I have shown that this can not be done for separable Hilbert spaces $\mathcal{H}$, but is it possible to make such a construction in non-separable Hilbert spaces?",,"['probability', 'general-topology', 'functional-analysis', 'probability-theory', 'hilbert-spaces']"
61,Probability that no couple sits together in a circle,Probability that no couple sits together in a circle,,"Suppose $n$ couples are seated in a circle, and let $P_n$ be the probability that no couple is sitting together. Using Inclusion-Exclusion, I believe it can be shown that $\hspace{.2 in}\displaystyle P_n=1-\sum_{i=1}^n (-1)^{i+1}\binom{n}{i}2^i\frac{(2n-1-i)!}{(2n-1)!},$ and I would like to find out how to prove that  $\displaystyle\lim_{n\to\infty}P_n=\frac{1}{e}\;\;$ (or show that this is not the case). Here are some numerical values: $P_3\approx.267,\;P_4\approx.295,\;P_5\approx.310\;, P_6\approx.320,\;P_7\approx.327,\;P_8\approx.332,\;P_9\approx.336,\;\;P_{10}\approx.340$ For a related question, see Showing probability no husband next to wife converges to $e^{-1}$","Suppose $n$ couples are seated in a circle, and let $P_n$ be the probability that no couple is sitting together. Using Inclusion-Exclusion, I believe it can be shown that $\hspace{.2 in}\displaystyle P_n=1-\sum_{i=1}^n (-1)^{i+1}\binom{n}{i}2^i\frac{(2n-1-i)!}{(2n-1)!},$ and I would like to find out how to prove that  $\displaystyle\lim_{n\to\infty}P_n=\frac{1}{e}\;\;$ (or show that this is not the case). Here are some numerical values: $P_3\approx.267,\;P_4\approx.295,\;P_5\approx.310\;, P_6\approx.320,\;P_7\approx.327,\;P_8\approx.332,\;P_9\approx.336,\;\;P_{10}\approx.340$ For a related question, see Showing probability no husband next to wife converges to $e^{-1}$",,"['probability', 'combinatorics', 'discrete-mathematics']"
62,Show that $\sum_{n=1}^{\infty}X_n<\infty$ almost surely if and only if $\sum_{n=1}^{\infty}\mathbb E[\frac{X_n}{1+X_n}]<\infty$.,Show that  almost surely if and only if .,\sum_{n=1}^{\infty}X_n<\infty \sum_{n=1}^{\infty}\mathbb E[\frac{X_n}{1+X_n}]<\infty,"Suppose $X_1, X_2, ...$ are independent non-negative random variables. Show that $\sum_{n=1}^{\infty}X_n<\infty$ almost surely if and only if $\sum_{n=1}^{\infty}\mathbb E[\frac{X_n}{1+X_n}]<\infty$. There is a hint here but I don't know how to use: Consider the truncated variables $X'_n=\min(X_n ,1)$. My thoughts are: if the sum of expectation are finite, then the expectation should converge to zero which means $X_n$ should converge to zero almost surely and since they are independent, the sum should converges almost surely. For the other direction, maybe I should use Kolmogrov's 3-series theorem? I don't know whether this is correct. Thank you!","Suppose $X_1, X_2, ...$ are independent non-negative random variables. Show that $\sum_{n=1}^{\infty}X_n<\infty$ almost surely if and only if $\sum_{n=1}^{\infty}\mathbb E[\frac{X_n}{1+X_n}]<\infty$. There is a hint here but I don't know how to use: Consider the truncated variables $X'_n=\min(X_n ,1)$. My thoughts are: if the sum of expectation are finite, then the expectation should converge to zero which means $X_n$ should converge to zero almost surely and since they are independent, the sum should converges almost surely. For the other direction, maybe I should use Kolmogrov's 3-series theorem? I don't know whether this is correct. Thank you!",,"['probability', 'probability-theory']"
63,Average distance between two points on a unit square. [duplicate],Average distance between two points on a unit square. [duplicate],,"This question already has an answer here : Average distance between two random points in a square (1 answer) Closed 7 years ago . Consider the unit square $S =[0,1]\times[0,1]$.  I'm interested in the average distance between random points in the square. Let $ \mathbf{a} = \left< x_1,y_1 \right>$ and  $ \mathbf{b} = \left< x_2,y_2 \right>$ be random points in the unit square.  By random, I mean that $x_i$ and $y_i$ are uniformly distributed on $[0,1]$. The normal approach is to use multiple integration to determine the average value of the distance between $\mathbf{b}$ and $\mathbf{a}$.  I would like to try another approach. $\mathbf{a}$ and $\mathbf{b}$ are random vectors, and each element has known distribution. So, the vector between them also has known distribution.  The difference between two uniformly random variables has triangular distribution. So $\mathbf{c} = \mathbf{b} - \mathbf{a}$.  Then, the average distance is the expectation of $\lVert \mathbf{c} \rVert$.  Perhaps it would be easier to calculate the expectation of $\lVert \mathbf{c} \rVert^2$. In any case, I am not sure how to calculate the expectation for $\lVert \mathbf{c} \rVert^2$. Can someone guide me in the right direction?","This question already has an answer here : Average distance between two random points in a square (1 answer) Closed 7 years ago . Consider the unit square $S =[0,1]\times[0,1]$.  I'm interested in the average distance between random points in the square. Let $ \mathbf{a} = \left< x_1,y_1 \right>$ and  $ \mathbf{b} = \left< x_2,y_2 \right>$ be random points in the unit square.  By random, I mean that $x_i$ and $y_i$ are uniformly distributed on $[0,1]$. The normal approach is to use multiple integration to determine the average value of the distance between $\mathbf{b}$ and $\mathbf{a}$.  I would like to try another approach. $\mathbf{a}$ and $\mathbf{b}$ are random vectors, and each element has known distribution. So, the vector between them also has known distribution.  The difference between two uniformly random variables has triangular distribution. So $\mathbf{c} = \mathbf{b} - \mathbf{a}$.  Then, the average distance is the expectation of $\lVert \mathbf{c} \rVert$.  Perhaps it would be easier to calculate the expectation of $\lVert \mathbf{c} \rVert^2$. In any case, I am not sure how to calculate the expectation for $\lVert \mathbf{c} \rVert^2$. Can someone guide me in the right direction?",,['probability']
64,How much area in a unit square is not covered by $k$ disjoint disks of maximal area centered at random points within the square?,How much area in a unit square is not covered by  disjoint disks of maximal area centered at random points within the square?,k,"1 . Paint a $1\times 1$ square in blue. 2 . Take $k$ points randomly and uniformly from the square. 3 . Paint $k$ disks centered at each point in red. The radius of the disk centered at point $p$ is $d/2$ , where $d$ is the distance from $p$ to its closest point. What is the expected remaining blue area? Related question: How much area in a unit square is not covered by $k$ disks of area $1/k$ centered at random points within the square?","1 . Paint a square in blue. 2 . Take points randomly and uniformly from the square. 3 . Paint disks centered at each point in red. The radius of the disk centered at point is , where is the distance from to its closest point. What is the expected remaining blue area? Related question: How much area in a unit square is not covered by $k$ disks of area $1/k$ centered at random points within the square?",1\times 1 k k p d/2 d p,"['probability', 'expectation']"
65,Why was I wrong about the monster-gem riddler,Why was I wrong about the monster-gem riddler,,"Every week I like to do the fivethirtyeight.com Riddler , an interesting and pleasantly challenging (at least for me) weekly math puzzle which comes out Fridays, with the answer and explanation to the previous problem being supplied when the new one is posted.  I just looked at the solution to last week's problem, and while I understand the explanation given, I am at a loss as to why my approach produced an incorrect answer. The problem is as follows: You're playing a game in which you kill monsters. Each time you kill a monster, it drops a gem, which you then collect.  The gems can be either common, uncommon or rare, with probabilities ${1\over2}$, ${1\over3}$, and ${1\over6}$, respectively.  If you play until you have 1 gem of each type, how many common gems will you have on average? The official answer is 3.65, and the explanation is available here (scroll down past the introduction and todays puzzle-- not quite halfway down the page).  My answer was 4.65 (interesting that I was off by exactly 1), and my reasoning was as follows: It's possible that you collect both other rarities before you find your first common gem.  This occurs with probability $ {1 \over 3} * {1 \over 4} +{1 \over 6 }*{2\over5}={3\over20}$.  In such cases you will stop after you find your first common gem, and the number you've collected (henceforth $N$) will be 1. In all other cases, play will proceed in two phases: Phase 1: you find some number $N_a$ (possibly 0) of common gems followed by a single non-common gem (call it type $a$) Phase 2: you find some number $N_b$ (possibly 0) of common gems, mixed with an irrelevant number of type $a$ gems, followed by a single gem of the other non-common type (call it type $b$). Now I make a couple of simplifying observations. First, since the case addressed above where the common gem was the last one we found corresponds to the case were $N_a=N_b=0$, we don't need to explicitly remove this case to avoid double-counting.  It represents the situation where $N$ exceeds $N_a+N_b$ rather than a case where the 2-phase model doesn't apply at all. Second, for given types $a$ and $b$, $N_a$ and $N_b$ are independent, because the individual gem drops are independent. Third, because there are (by definition) no type $b$ gems found in phase 1 and type $a$ gems found in Phase 2 are irrelevant, it doesn't matter which non-common type (rare or uncommon) is type $a$ and which is type $b$ because in either case $N_{rare}$ (the number of common gems found in the phase terminated by a rare gem) will be a geometrically distributed random variable with $p=$ (the probability of a rare gem being dropped given that an uncommon gem is not dropped) $= {1\over4}$, and likewise for $N_{uncommon}$. Thus we have $$E[N]=E[N_{rare}]+E[N_{uncommon}]+{3\over20}=\frac{3\over5}{2\over5}+\frac{3\over4}{1\over4}+{3\over20}={3\over2}+3+{3\over20}={93\over20}=4.65$$ What's wrong with this method?","Every week I like to do the fivethirtyeight.com Riddler , an interesting and pleasantly challenging (at least for me) weekly math puzzle which comes out Fridays, with the answer and explanation to the previous problem being supplied when the new one is posted.  I just looked at the solution to last week's problem, and while I understand the explanation given, I am at a loss as to why my approach produced an incorrect answer. The problem is as follows: You're playing a game in which you kill monsters. Each time you kill a monster, it drops a gem, which you then collect.  The gems can be either common, uncommon or rare, with probabilities ${1\over2}$, ${1\over3}$, and ${1\over6}$, respectively.  If you play until you have 1 gem of each type, how many common gems will you have on average? The official answer is 3.65, and the explanation is available here (scroll down past the introduction and todays puzzle-- not quite halfway down the page).  My answer was 4.65 (interesting that I was off by exactly 1), and my reasoning was as follows: It's possible that you collect both other rarities before you find your first common gem.  This occurs with probability $ {1 \over 3} * {1 \over 4} +{1 \over 6 }*{2\over5}={3\over20}$.  In such cases you will stop after you find your first common gem, and the number you've collected (henceforth $N$) will be 1. In all other cases, play will proceed in two phases: Phase 1: you find some number $N_a$ (possibly 0) of common gems followed by a single non-common gem (call it type $a$) Phase 2: you find some number $N_b$ (possibly 0) of common gems, mixed with an irrelevant number of type $a$ gems, followed by a single gem of the other non-common type (call it type $b$). Now I make a couple of simplifying observations. First, since the case addressed above where the common gem was the last one we found corresponds to the case were $N_a=N_b=0$, we don't need to explicitly remove this case to avoid double-counting.  It represents the situation where $N$ exceeds $N_a+N_b$ rather than a case where the 2-phase model doesn't apply at all. Second, for given types $a$ and $b$, $N_a$ and $N_b$ are independent, because the individual gem drops are independent. Third, because there are (by definition) no type $b$ gems found in phase 1 and type $a$ gems found in Phase 2 are irrelevant, it doesn't matter which non-common type (rare or uncommon) is type $a$ and which is type $b$ because in either case $N_{rare}$ (the number of common gems found in the phase terminated by a rare gem) will be a geometrically distributed random variable with $p=$ (the probability of a rare gem being dropped given that an uncommon gem is not dropped) $= {1\over4}$, and likewise for $N_{uncommon}$. Thus we have $$E[N]=E[N_{rare}]+E[N_{uncommon}]+{3\over20}=\frac{3\over5}{2\over5}+\frac{3\over4}{1\over4}+{3\over20}={3\over2}+3+{3\over20}={93\over20}=4.65$$ What's wrong with this method?",,"['probability', 'probability-distributions', 'puzzle']"
66,lottery to pick a group while respecting pairs,lottery to pick a group while respecting pairs,,"I am running an event that will be oversubscribed, so I'd like to use a lottery to randomly pick the participants that will be accepted.  (For example, 29 people want to attend, but I can accommodate only 17.) The twist is that there are some couples among the people who want to attend, so I must either accept both of them or neither of them. I would like to run this lottery so that any single person has an equally likely chance of being selected, regardless of whether that person is part of a couple or not. Is it even possible to make the lottery fair in this manner?  If so, how should I run the lottery?  If not, what would be the fairest way to run the lottery? I have thought of a few things that don't work. Suppose you take all the combinations (choose 17 from 29 in my example), throw out the ones that do not violate any of the couples constraints, and pick one of the remaining combinations at random with uniform probability.  In general, the number of combinations with a member of a couple is not the same as the number of combinations with an individual. Another simple scheme would be to write each individual's name on a slip of paper, write both names of each couple on a single slip of paper, throw all the pieces of paper in an urn, and draw slips of paper until the total number of names reaches the capacity of the event.  Let's say that if the slip you draw for the last spot has two names of a couple, you throw it out.  This also does not provide the same odds of an individual and one member of a couple being selected. Perhaps there is a way of weighting the combinations in such a way to provide fair odds to an individual?  (Though when there are several couples this could get complicated...)","I am running an event that will be oversubscribed, so I'd like to use a lottery to randomly pick the participants that will be accepted.  (For example, 29 people want to attend, but I can accommodate only 17.) The twist is that there are some couples among the people who want to attend, so I must either accept both of them or neither of them. I would like to run this lottery so that any single person has an equally likely chance of being selected, regardless of whether that person is part of a couple or not. Is it even possible to make the lottery fair in this manner?  If so, how should I run the lottery?  If not, what would be the fairest way to run the lottery? I have thought of a few things that don't work. Suppose you take all the combinations (choose 17 from 29 in my example), throw out the ones that do not violate any of the couples constraints, and pick one of the remaining combinations at random with uniform probability.  In general, the number of combinations with a member of a couple is not the same as the number of combinations with an individual. Another simple scheme would be to write each individual's name on a slip of paper, write both names of each couple on a single slip of paper, throw all the pieces of paper in an urn, and draw slips of paper until the total number of names reaches the capacity of the event.  Let's say that if the slip you draw for the last spot has two names of a couple, you throw it out.  This also does not provide the same odds of an individual and one member of a couple being selected. Perhaps there is a way of weighting the combinations in such a way to provide fair odds to an individual?  (Though when there are several couples this could get complicated...)",,"['probability', 'combinatorics']"
67,Is this casino promotion exploitable?,Is this casino promotion exploitable?,,The promotion is like this: Starting credit: 500 dollars Maximum bet: 500 dollars Win up to 10000 dollars and get 10000 dollars free . House edge 52.5%. Is this exploitable?,The promotion is like this: Starting credit: 500 dollars Maximum bet: 500 dollars Win up to 10000 dollars and get 10000 dollars free . House edge 52.5%. Is this exploitable?,,"['probability', 'gambling']"
68,Probability of rolling dice twice,Probability of rolling dice twice,,"Did I calculate the correct probability for these simple scenarios: 1: What is the probability of rolling 3 and 4 with two dice in two rolls? If you roll either 3 or 4 in the first roll, you put that die aside and roll the second die again. I would break the probability down like this: 1/18 chance of getting both 3 and 4 (or 4 and 3) in the first roll. 1/4 chance of rolling 3 (31, 32, 33, 35, 36, 13, 23, 53 and 63), and then 1/6 chance of rolling the 4 in the second roll. 1/4 chance of rolling 4 (41, 42, 44, 45, 46, 14, 24, 54 and 64), and then 1/6 chance of rolling the 3 in the second roll. 1/18 of rolling both 3 and 4 on the second roll (having rolled neither in the first). This adds up to: $$\frac{1}{18} + (\frac{1}{4} \times \frac{1}{6}) + (\frac{1}{4} \times \frac{1}{6}) + \frac{1}{18} = \frac{7}{36}$$ Is that correct? 2: What is the probability of rolling double 6 in two rolls? Slightly different breakdown: 1/36 chance of getting 66 in the first roll. 10/36 chance of getting a single 6 (all combinations of 6, except 66), then 1/6 of getting the second 6 in the second roll. 1/36 chance of getting 66 in the second roll. $$\frac{1}{36} + (\frac{5}{18} \times \frac{1}{6}) + \frac{1}{36} = \frac{11}{108}$$ Correct? I've watched several videos on probability calculations, the usual ""pick a coin in a bag with some unfair coins"", and this is the first time I'm actually trying to apply what I've learned. Update: I was wrong Correct answers: $$\frac{1}{18} + (\frac{1}{4} \times \frac{1}{6}) + (\frac{1}{4} \times \frac{1}{6}) + (\frac{4}{9} \times \frac{1}{18}) = \frac{53}{324} = 16.4\%$$ and $$\frac{1}{36} + (\frac{10}{36} \times \frac{1}{6}) + (\frac{25}{36} \times \frac{1}{36}) = \frac{121}{1296} = 9.3\% $$","Did I calculate the correct probability for these simple scenarios: 1: What is the probability of rolling 3 and 4 with two dice in two rolls? If you roll either 3 or 4 in the first roll, you put that die aside and roll the second die again. I would break the probability down like this: 1/18 chance of getting both 3 and 4 (or 4 and 3) in the first roll. 1/4 chance of rolling 3 (31, 32, 33, 35, 36, 13, 23, 53 and 63), and then 1/6 chance of rolling the 4 in the second roll. 1/4 chance of rolling 4 (41, 42, 44, 45, 46, 14, 24, 54 and 64), and then 1/6 chance of rolling the 3 in the second roll. 1/18 of rolling both 3 and 4 on the second roll (having rolled neither in the first). This adds up to: $$\frac{1}{18} + (\frac{1}{4} \times \frac{1}{6}) + (\frac{1}{4} \times \frac{1}{6}) + \frac{1}{18} = \frac{7}{36}$$ Is that correct? 2: What is the probability of rolling double 6 in two rolls? Slightly different breakdown: 1/36 chance of getting 66 in the first roll. 10/36 chance of getting a single 6 (all combinations of 6, except 66), then 1/6 of getting the second 6 in the second roll. 1/36 chance of getting 66 in the second roll. $$\frac{1}{36} + (\frac{5}{18} \times \frac{1}{6}) + \frac{1}{36} = \frac{11}{108}$$ Correct? I've watched several videos on probability calculations, the usual ""pick a coin in a bag with some unfair coins"", and this is the first time I'm actually trying to apply what I've learned. Update: I was wrong Correct answers: $$\frac{1}{18} + (\frac{1}{4} \times \frac{1}{6}) + (\frac{1}{4} \times \frac{1}{6}) + (\frac{4}{9} \times \frac{1}{18}) = \frac{53}{324} = 16.4\%$$ and $$\frac{1}{36} + (\frac{10}{36} \times \frac{1}{6}) + (\frac{25}{36} \times \frac{1}{36}) = \frac{121}{1296} = 9.3\% $$",,"['probability', 'dice']"
69,Interpretation of Hellinger distance,Interpretation of Hellinger distance,,"Given to discrete probability distribution $\mathbf{p}:=(p_1,p_2,\dots,p_n)$ and $\mathbf{q}:=(q_1,q_2,\dots,q_n)$, the Hellinger distance between $\mathbf{p}$ and $\mathbf{q}$ is defined as: $$ d_H(\mathbf{p},\mathbf{q}):=\frac{1}{\sqrt{2}}\left\|\mathbf{p}^{1/2}-\mathbf{q}^{1/2}\right\|_2=\frac{1}{\sqrt{2}}\left(\sum_{i=1}^n \left(\sqrt{p_i}-\sqrt{q_i}\right)^2\right)^{1/2}, $$ Why is this distance extensively exploited in statistics and probability? What is the geometrical/statistical interpretation of this distance? Assuming that $\mathbf{p},\mathbf{q}$ represent vectors and not probability distributions, has this distance been studied in other areas different from statistics? My questions are not technical, but I was not able to find references which clearly address them. Thank you for your help.","Given to discrete probability distribution $\mathbf{p}:=(p_1,p_2,\dots,p_n)$ and $\mathbf{q}:=(q_1,q_2,\dots,q_n)$, the Hellinger distance between $\mathbf{p}$ and $\mathbf{q}$ is defined as: $$ d_H(\mathbf{p},\mathbf{q}):=\frac{1}{\sqrt{2}}\left\|\mathbf{p}^{1/2}-\mathbf{q}^{1/2}\right\|_2=\frac{1}{\sqrt{2}}\left(\sum_{i=1}^n \left(\sqrt{p_i}-\sqrt{q_i}\right)^2\right)^{1/2}, $$ Why is this distance extensively exploited in statistics and probability? What is the geometrical/statistical interpretation of this distance? Assuming that $\mathbf{p},\mathbf{q}$ represent vectors and not probability distributions, has this distance been studied in other areas different from statistics? My questions are not technical, but I was not able to find references which clearly address them. Thank you for your help.",,"['probability', 'statistics', 'reference-request']"
70,Cramer-Rao lower bound and efficiency vs biased estimator efficiency,Cramer-Rao lower bound and efficiency vs biased estimator efficiency,,"I am a bit confused on the Cramer-Rao (CR) lower bound. If an estimator achieves the CR lower bound, then it is UMVUE, right? And for any given set of unbiased estimators, the one with the lowest variance is the most efficient. So for any set of unbiased estimators, the one that achieves the CR lower bound is the most efficient of the group since it is uniformly min-var., but is it possible to find a biased estimator that could be more efficient? If I did find one, is comparing the two really worth while, or should I just stick with the CR lower bound estimator. Thanks for looking","I am a bit confused on the Cramer-Rao (CR) lower bound. If an estimator achieves the CR lower bound, then it is UMVUE, right? And for any given set of unbiased estimators, the one with the lowest variance is the most efficient. So for any set of unbiased estimators, the one that achieves the CR lower bound is the most efficient of the group since it is uniformly min-var., but is it possible to find a biased estimator that could be more efficient? If I did find one, is comparing the two really worth while, or should I just stick with the CR lower bound estimator. Thanks for looking",,"['probability', 'probability-theory']"
71,An Average of Probabilities,An Average of Probabilities,,"This is an open ended question in that the desired end result is not well posed.  Still, it may be of some interest. Suppose you have a number of teams which play against each other in two team competitions (all pairings occur with equal likehood, no ties allowed).  Let $P(A,B)$ be the probability that A triumphs in a match between A and B.  Clearly, if you know all the $P(A,B)$ you can compute the team average $P(A)$, the probability that A will win against an unknown opponent.  You can't go the other way, though.  To see this, look at 3 teams $A,B,C$ and suppose $P(A) = P(B) = P(C) = \frac{1}{2}$.  One way we might have gotten this outcome is if $P(X,Y) = \frac{1}{2}$ for any pair of teams X,Y.  In some vague sense, I suppose this is the ""most natural"" guess.  But it is not the only possibility.  We might, for instance,  be in ""Rock, Paper, Scissors"" world, where A always beats B, B always beats C, and C always beats A. The Question:  Given all the P(A), is there a reasonably natural way to produce a   list of probabilities P(A, *)? Of course the probabilities must be consistent (so that the list of P(A,B)'s does imply the given list of team averages). Sample attempt:  attach a ""greatness factor"" $\lambda_i$ to each team and then define $$P(A_i,A_j) = .5 + \lambda_i - \lambda_j$$ You can even make the $\lambda$'s sum to 1.  This is easily computable and gives plausible results so long as all the team averages are reasonably near .5.  In more extreme cases, though, you get unphysical results (probabilities greater than 1 and so on). For baseball statistics, where this problem first arose, this crude method works fairly well. Absent any actual ideas, my impulse is to minimize variance.  That is: ""choose the solution which is as nearly constant as possible.""  That is obviously one way to go, but perhaps someone has a better idea?","This is an open ended question in that the desired end result is not well posed.  Still, it may be of some interest. Suppose you have a number of teams which play against each other in two team competitions (all pairings occur with equal likehood, no ties allowed).  Let $P(A,B)$ be the probability that A triumphs in a match between A and B.  Clearly, if you know all the $P(A,B)$ you can compute the team average $P(A)$, the probability that A will win against an unknown opponent.  You can't go the other way, though.  To see this, look at 3 teams $A,B,C$ and suppose $P(A) = P(B) = P(C) = \frac{1}{2}$.  One way we might have gotten this outcome is if $P(X,Y) = \frac{1}{2}$ for any pair of teams X,Y.  In some vague sense, I suppose this is the ""most natural"" guess.  But it is not the only possibility.  We might, for instance,  be in ""Rock, Paper, Scissors"" world, where A always beats B, B always beats C, and C always beats A. The Question:  Given all the P(A), is there a reasonably natural way to produce a   list of probabilities P(A, *)? Of course the probabilities must be consistent (so that the list of P(A,B)'s does imply the given list of team averages). Sample attempt:  attach a ""greatness factor"" $\lambda_i$ to each team and then define $$P(A_i,A_j) = .5 + \lambda_i - \lambda_j$$ You can even make the $\lambda$'s sum to 1.  This is easily computable and gives plausible results so long as all the team averages are reasonably near .5.  In more extreme cases, though, you get unphysical results (probabilities greater than 1 and so on). For baseball statistics, where this problem first arose, this crude method works fairly well. Absent any actual ideas, my impulse is to minimize variance.  That is: ""choose the solution which is as nearly constant as possible.""  That is obviously one way to go, but perhaps someone has a better idea?",,['probability']
72,Conditional expectation acting on square of a random variable,Conditional expectation acting on square of a random variable,,"Suppose that $X$ and $Y$ are random variables such that $E(Y¦X) =X$ and $E(Y^2¦X)=X^2$; also, $Y$ is in $L^2(\Omega,\mathcal{A},\mathbb{P})$. I need to show that $Y=X$ almost surely. I know the definition of conditional expectation as a projection, I. E. $E(X¦Y) =W$ is the unique $W$ in $L^2(\Omega,\sigma(X),\mathbb{P})$ satisfying $E(WZ) =E(YZ) $ for all $Z$ in that same $L^2$. My intuition is that we get the result by applying this definition and making appropriate choices for $Z$. I've tried,  but I got stuck. I am also worried that I don't know where the $L^2$ should come in. Why not $L^3$ or $L^1$, instead? Whats this have to do with it?","Suppose that $X$ and $Y$ are random variables such that $E(Y¦X) =X$ and $E(Y^2¦X)=X^2$; also, $Y$ is in $L^2(\Omega,\mathcal{A},\mathbb{P})$. I need to show that $Y=X$ almost surely. I know the definition of conditional expectation as a projection, I. E. $E(X¦Y) =W$ is the unique $W$ in $L^2(\Omega,\sigma(X),\mathbb{P})$ satisfying $E(WZ) =E(YZ) $ for all $Z$ in that same $L^2$. My intuition is that we get the result by applying this definition and making appropriate choices for $Z$. I've tried,  but I got stuck. I am also worried that I don't know where the $L^2$ should come in. Why not $L^3$ or $L^1$, instead? Whats this have to do with it?",,"['probability', 'probability-theory', 'conditional-expectation']"
73,Techniques for proving asymptotic normality by Taylor expansion?,Techniques for proving asymptotic normality by Taylor expansion?,,"Suppose I have a sequence of densities $$ f_{X_n}(x) = \exp[\ell_n(x)], \qquad (x \in A). $$ My goal is to prove a statement like $\sqrt n (X_n - \mu) \to N(0, \sigma^2)$ in distribution, for an appropriate $\sigma^2$ and some choice of $\mu$. We often teach undergraduates to do this using moment generating functions or characteristic functions, or by direct manipulation of the cdf. By contrast, I would like to do this by expanding $f_{X_n}(x)$ about the mode $\hat x_n$ (suppose $f_{X_n}(x)$ is unimodal with $\ell''_n(x) < 0)$. Then we expand $T_n = \sqrt n (X_n - \hat x_n)$ $$ f_{T_n}(t) \approx n^{-1/2}f_{X_n}(\hat x_n) \exp \left\{\frac 1 {2n} t^2 \ell''_n(\hat x_n)\right\}. $$ Under the condition that $\hat x_n = \mu + o(n^{-1/2})$ and $\ell''_n(\mu) / n \to -I(\mu)$ for some function $I(\mu)$, one then might guess $$ T_n \stackrel{\cdot}{\sim} N(0, I(\mu)^{-1}). $$ Now for the question: I'm essentially looking for conditions which allow me to make this result rigorous. The heuristic seems very similar to what one does when trying to prove asymptotic normality of maximum likelihood estimators, and so I would hope for some conditions in terms of $\ell''_n(x)$ and $I(x)$, or perhaps a third derivative $\ell'''_n(x)$. The best I can do at the moment is try to expand things out  $$ f_{T_n}(t) = n^{-1/2} \exp\left[\ell_n (\hat x_n) + \underbrace{t / \sqrt n \ell_n(\hat x_n)}_{=0} + \frac{t^2}{2n}\ell''_n(\hat x_n + n^{-1/2} t^\star)\right] $$ with remainder $\frac 1 {2n} t^2 \ell''(\hat x_n + n^{-1/2} t^\star)$, which works for showing that the unnormalized density converges to a Gaussian density. But this doesn't finish the job because I still have to show that the normalizing constant converges to the right answer if I want to finish off the proof with Scheffe's theorem. I could try to finish it by applying dominated convergence to the exponential term, but this hasn't worked so far for the problem I'm interested in, and doesn't feel like a sensible thing to do anyways.","Suppose I have a sequence of densities $$ f_{X_n}(x) = \exp[\ell_n(x)], \qquad (x \in A). $$ My goal is to prove a statement like $\sqrt n (X_n - \mu) \to N(0, \sigma^2)$ in distribution, for an appropriate $\sigma^2$ and some choice of $\mu$. We often teach undergraduates to do this using moment generating functions or characteristic functions, or by direct manipulation of the cdf. By contrast, I would like to do this by expanding $f_{X_n}(x)$ about the mode $\hat x_n$ (suppose $f_{X_n}(x)$ is unimodal with $\ell''_n(x) < 0)$. Then we expand $T_n = \sqrt n (X_n - \hat x_n)$ $$ f_{T_n}(t) \approx n^{-1/2}f_{X_n}(\hat x_n) \exp \left\{\frac 1 {2n} t^2 \ell''_n(\hat x_n)\right\}. $$ Under the condition that $\hat x_n = \mu + o(n^{-1/2})$ and $\ell''_n(\mu) / n \to -I(\mu)$ for some function $I(\mu)$, one then might guess $$ T_n \stackrel{\cdot}{\sim} N(0, I(\mu)^{-1}). $$ Now for the question: I'm essentially looking for conditions which allow me to make this result rigorous. The heuristic seems very similar to what one does when trying to prove asymptotic normality of maximum likelihood estimators, and so I would hope for some conditions in terms of $\ell''_n(x)$ and $I(x)$, or perhaps a third derivative $\ell'''_n(x)$. The best I can do at the moment is try to expand things out  $$ f_{T_n}(t) = n^{-1/2} \exp\left[\ell_n (\hat x_n) + \underbrace{t / \sqrt n \ell_n(\hat x_n)}_{=0} + \frac{t^2}{2n}\ell''_n(\hat x_n + n^{-1/2} t^\star)\right] $$ with remainder $\frac 1 {2n} t^2 \ell''(\hat x_n + n^{-1/2} t^\star)$, which works for showing that the unnormalized density converges to a Gaussian density. But this doesn't finish the job because I still have to show that the normalizing constant converges to the right answer if I want to finish off the proof with Scheffe's theorem. I could try to finish it by applying dominated convergence to the exponential term, but this hasn't worked so far for the problem I'm interested in, and doesn't feel like a sensible thing to do anyways.",,"['probability', 'statistics', 'probability-theory', 'statistical-inference']"
74,probability circle determined by chord determined by two random points is enclosed in bigger circle,probability circle determined by chord determined by two random points is enclosed in bigger circle,,Two points $A$ and $B$ are chosen uniformly at random from the interior of a circle $X_1$. Let $X_2$ be the circle whose diameter is the segment $AB$. What is the probability that $X_2$ is contained entirely inside $X_1$? Progress: Not much luck with random integrating.,Two points $A$ and $B$ are chosen uniformly at random from the interior of a circle $X_1$. Let $X_2$ be the circle whose diameter is the segment $AB$. What is the probability that $X_2$ is contained entirely inside $X_1$? Progress: Not much luck with random integrating.,,['probability']
75,true story about probability? [duplicate],true story about probability? [duplicate],,"This question already has answers here : More examples of Simpson's Paradox, barring the ones on Wikipedia, Titanic, and delayed flights. (4 answers) Closed 9 years ago . A women's organization was contemplating suing a famous American university when it learned that the percentage of women who received tenure in the university was smaller than the percentage of men. But then it was discovered that in every department, the percentage of women who received tenure in that department was greater than the percentage of men who did. How can that be?","This question already has answers here : More examples of Simpson's Paradox, barring the ones on Wikipedia, Titanic, and delayed flights. (4 answers) Closed 9 years ago . A women's organization was contemplating suing a famous American university when it learned that the percentage of women who received tenure in the university was smaller than the percentage of men. But then it was discovered that in every department, the percentage of women who received tenure in that department was greater than the percentage of men who did. How can that be?",,['probability']
76,How can I write this power series as a power series representation?,How can I write this power series as a power series representation?,,How can I write this power series ($1+x+2x^2+2x^3+3x^4+3x^5+4x^6+4x^7+5x^8....$) as a power series representation (like $\dfrac{1}{1-x}$ or something neat like that)?,How can I write this power series ($1+x+2x^2+2x^3+3x^4+3x^5+4x^6+4x^7+5x^8....$) as a power series representation (like $\dfrac{1}{1-x}$ or something neat like that)?,,"['probability', 'power-series', 'generating-functions']"
77,Definition of conditional probabiliy as function dependent on $\sigma$-Algebra,Definition of conditional probabiliy as function dependent on -Algebra,\sigma,"I know that for events $A,B$ with $P(B) > 0$ the conditional probability is defined as $$  P(A | B) = \frac{P(A \cap B)}{P(B)}.  $$ Of course by regarding $A$ as constant, and varying $B$ we get a function $P(A | \cdot)$ by $B \mapsto P(A | B)$, and so we get a function $P(A | \{ \cdot \}) : \Omega \to \mathbb [0,1]$ by $\omega \in \Omega \mapsto P(A | \{ \omega \})$ (assuming each $\omega$ has a non-zero probability). Is this function a random variable? Guess not because there is no measure space given on $[0,1]$ for a measure (like $P$). Also I stumble in the way conditional probabilities for $\sigma$-Algebra are defined. For this let $\mathcal F$ be an $\sigma$-Algebra, then the conditional probability $P(A | \mathcal F)$ is a $\mathcal F$-measurable and integrable random variable such that $$  \int_G P(A | \mathcal F) d P = P(A \cap G) $$ for all $G \in \mathcal F$. This makes no sense to me, why now a function. In the classical definition I got a number, which could be interpreted as the probability of an event given another event, but here I have a collection of events I depend on, and the conditional probability is a function... makes no sense to me? Has my construction above something to do with the way conditional probabilites for $\sigma$-Algebras are defined? I just tried to come from the classical definition to the new one...","I know that for events $A,B$ with $P(B) > 0$ the conditional probability is defined as $$  P(A | B) = \frac{P(A \cap B)}{P(B)}.  $$ Of course by regarding $A$ as constant, and varying $B$ we get a function $P(A | \cdot)$ by $B \mapsto P(A | B)$, and so we get a function $P(A | \{ \cdot \}) : \Omega \to \mathbb [0,1]$ by $\omega \in \Omega \mapsto P(A | \{ \omega \})$ (assuming each $\omega$ has a non-zero probability). Is this function a random variable? Guess not because there is no measure space given on $[0,1]$ for a measure (like $P$). Also I stumble in the way conditional probabilities for $\sigma$-Algebra are defined. For this let $\mathcal F$ be an $\sigma$-Algebra, then the conditional probability $P(A | \mathcal F)$ is a $\mathcal F$-measurable and integrable random variable such that $$  \int_G P(A | \mathcal F) d P = P(A \cap G) $$ for all $G \in \mathcal F$. This makes no sense to me, why now a function. In the classical definition I got a number, which could be interpreted as the probability of an event given another event, but here I have a collection of events I depend on, and the conditional probability is a function... makes no sense to me? Has my construction above something to do with the way conditional probabilites for $\sigma$-Algebras are defined? I just tried to come from the classical definition to the new one...",,"['probability', 'probability-theory', 'conditional-probability']"
78,A problem on distributing 29 disks on $7\times 7$ grid,A problem on distributing 29 disks on  grid,7\times 7,"I got this problem: Given a $7\times 7$ grid, if we distribute $29$ disks on the grid such that each square cannot hold more than $1$ disk, what is the probability that there will be at least one row full of disks on the grid? My first try: $P(\{\text{there is at least one row full of disks}\}= \frac{7\times{42\choose 22}}{49\choose 29}$ Since we have $7$ ways to choose the row that we will fill by disks, and then we have remaining $22$ disks which we will distribute over the remaining $42$ squares. But this is obviously wrong since we count some combinations multiple times. My second try: $P(\{ \text{there is at least one row full of disks}\}= P(\{\text{there is exactly 1 row full of disks}\}\cup\{\text{there is exactly 2 rows full of disks}\}\cup\{\text{there is exactly 3 rows full of disks}\}\cup\{\text{there is exactly 4 rows full of disks}\})=P(\{\text{there is exactly 1 row full of disks}\}+P(\{\text{there is exactly 2 rows full of disks}\}+P(\{\text{there is exactly 3 rows full of disks}\}+P(\{\text{there is exactly 4 rows full of disks}\}$ But this probably makes things harder and does not simplifies things. My third try: $P(\{\text{there is at least one row full of disks}\}= 1-P(\{\text{there are no rows full of disks}\})$ But I got stuck, I tried to count the number of combinations in which each row got an empty square but here too I counted some combinations multiple times. Any hint/help will be appreciated.","I got this problem: Given a $7\times 7$ grid, if we distribute $29$ disks on the grid such that each square cannot hold more than $1$ disk, what is the probability that there will be at least one row full of disks on the grid? My first try: $P(\{\text{there is at least one row full of disks}\}= \frac{7\times{42\choose 22}}{49\choose 29}$ Since we have $7$ ways to choose the row that we will fill by disks, and then we have remaining $22$ disks which we will distribute over the remaining $42$ squares. But this is obviously wrong since we count some combinations multiple times. My second try: $P(\{ \text{there is at least one row full of disks}\}= P(\{\text{there is exactly 1 row full of disks}\}\cup\{\text{there is exactly 2 rows full of disks}\}\cup\{\text{there is exactly 3 rows full of disks}\}\cup\{\text{there is exactly 4 rows full of disks}\})=P(\{\text{there is exactly 1 row full of disks}\}+P(\{\text{there is exactly 2 rows full of disks}\}+P(\{\text{there is exactly 3 rows full of disks}\}+P(\{\text{there is exactly 4 rows full of disks}\}$ But this probably makes things harder and does not simplifies things. My third try: $P(\{\text{there is at least one row full of disks}\}= 1-P(\{\text{there are no rows full of disks}\})$ But I got stuck, I tried to count the number of combinations in which each row got an empty square but here too I counted some combinations multiple times. Any hint/help will be appreciated.",,"['probability', 'combinatorics']"
79,What is the joint distribution of sample mean and sample variance of normal distribution?,What is the joint distribution of sample mean and sample variance of normal distribution?,,"$X_i \sim N( \mu,\sigma^2)$, define $\overline X =\dfrac{1}{n} \sum\limits_{i = 1}^n X_i $, $S^2 = \dfrac{1}{n - 1}\sum\limits_{n = 1}^n \left( {X_i - \overline X} \right)^2$. What is the distribution of $$ \sqrt n \left( \begin{array}{c} \overline X  - \mu \\ S^2 - \sigma ^2 \end{array} \right) $$","$X_i \sim N( \mu,\sigma^2)$, define $\overline X =\dfrac{1}{n} \sum\limits_{i = 1}^n X_i $, $S^2 = \dfrac{1}{n - 1}\sum\limits_{n = 1}^n \left( {X_i - \overline X} \right)^2$. What is the distribution of $$ \sqrt n \left( \begin{array}{c} \overline X  - \mu \\ S^2 - \sigma ^2 \end{array} \right) $$",,"['probability', 'statistics', 'probability-theory', 'probability-distributions', 'normal-distribution']"
80,Property of uniformly tight random variables?,Property of uniformly tight random variables?,,"I'm stumped on the following question, which is problem 1.3.9 in the book Weak Convergence and Empirical Proceses by van der Vaart and Wellner. It is based on the following notion of asymptotic tightness: Definition : A sequence of random variables $X_1, X_2, \ldots$ taking values in a metric space with metric $d$ is asymptotically tight if for every $\epsilon > 0$ there exists a compact $K_0$ such that for every $\delta > 0$ we have $\varliminf_{n \to \infty} P(X_n \in K_0^\delta) \ge 1 - \epsilon$ where $K_0^\delta = \{x: d(x, K_0) < \delta\}$ is the $\delta$-enlargement of $K_0$. For convenience, the definition of uniform tightness is Definition : A sequence of random variables $X_1, X_2, \ldots$ is uniformly tight if for every $\epsilon > 0$ there exists a compact $K$ such that $P(X_n \in K) \ge 1 - \epsilon$ for every $K$. The problem is: Claim :  A sequence $X_n$ is uniformly tight if and only if it is asymptotically tight and each $X_n$ is tight. I cannot seem to prove the non-trivial direction of this claim. The following hint is given: Hint : Fix $\epsilon > 0$. Take a compact $K_0$ with $\varliminf P(X_n \in K_0^\delta) \ge 1 - \epsilon$ for every $\delta$. Choose $n_1 < n_2 < \cdots $ such that $P(X_n \in K_0^{1/m}) \ge 1 - 2 \epsilon$ for $n \ge n_m$. For $n_m < n  \le n_{m+1}$ choose a compact $K_n$ with $P(X_n \in K_0^{1/m} - K_n) < \epsilon$. Now $K = \bigcup_{n = 0} ^ \infty K_n$ is compact and $P(X_n \in K) \ge 1 - 3 \epsilon$. Now, I understand everything in the hint except for the claim that $K = \bigcup_{n = 0} ^ \infty K_n$ is compact. I assume I'm missing something in how $K_n$ is constructed that makes the countable union compact, since obviously a countable union of compact sets isn't necessarily compact. I also can't seem to find a proof of this claim anywhere other than this book, except a proof in the book Introduction to Empirical Processes and Semiparametric Inference which apparently just copies this hint and leaves the claim that $K$ is compact as ""an exercise left to the reader."" EDIT : I think I have a sketch now for compactness, so if anyone could verify it I would be appreciative. The $K_n$ can be chosen so that $K_0 \subseteq K_n \subseteq K_0^{1/m}$ for $n_m < n \le n_{m+1}$. Given an open cover $\{U_\alpha\}$ of $K$, find a finite subcover of $K_0$, $U_1, \ldots, U_K$. Next, find $m$ such that $K_0^{1/m} \subseteq \bigcup_{k = 1} ^K U_k$ (exists because $K_0$ is compact and $\bigcup_{k = 1} ^ K U_k$ is open). Hence $U_1, \ldots, U_K$ is an open cover for $K_n$ for all $n > n_m$. Now, just use compactness of $K_1, \ldots, K_{n_m}$ extend the open cover $K_{n_m + 1}, K_{n_m + 2}, \ldots$ to one which covers all $K_n$.","I'm stumped on the following question, which is problem 1.3.9 in the book Weak Convergence and Empirical Proceses by van der Vaart and Wellner. It is based on the following notion of asymptotic tightness: Definition : A sequence of random variables $X_1, X_2, \ldots$ taking values in a metric space with metric $d$ is asymptotically tight if for every $\epsilon > 0$ there exists a compact $K_0$ such that for every $\delta > 0$ we have $\varliminf_{n \to \infty} P(X_n \in K_0^\delta) \ge 1 - \epsilon$ where $K_0^\delta = \{x: d(x, K_0) < \delta\}$ is the $\delta$-enlargement of $K_0$. For convenience, the definition of uniform tightness is Definition : A sequence of random variables $X_1, X_2, \ldots$ is uniformly tight if for every $\epsilon > 0$ there exists a compact $K$ such that $P(X_n \in K) \ge 1 - \epsilon$ for every $K$. The problem is: Claim :  A sequence $X_n$ is uniformly tight if and only if it is asymptotically tight and each $X_n$ is tight. I cannot seem to prove the non-trivial direction of this claim. The following hint is given: Hint : Fix $\epsilon > 0$. Take a compact $K_0$ with $\varliminf P(X_n \in K_0^\delta) \ge 1 - \epsilon$ for every $\delta$. Choose $n_1 < n_2 < \cdots $ such that $P(X_n \in K_0^{1/m}) \ge 1 - 2 \epsilon$ for $n \ge n_m$. For $n_m < n  \le n_{m+1}$ choose a compact $K_n$ with $P(X_n \in K_0^{1/m} - K_n) < \epsilon$. Now $K = \bigcup_{n = 0} ^ \infty K_n$ is compact and $P(X_n \in K) \ge 1 - 3 \epsilon$. Now, I understand everything in the hint except for the claim that $K = \bigcup_{n = 0} ^ \infty K_n$ is compact. I assume I'm missing something in how $K_n$ is constructed that makes the countable union compact, since obviously a countable union of compact sets isn't necessarily compact. I also can't seem to find a proof of this claim anywhere other than this book, except a proof in the book Introduction to Empirical Processes and Semiparametric Inference which apparently just copies this hint and leaves the claim that $K$ is compact as ""an exercise left to the reader."" EDIT : I think I have a sketch now for compactness, so if anyone could verify it I would be appreciative. The $K_n$ can be chosen so that $K_0 \subseteq K_n \subseteq K_0^{1/m}$ for $n_m < n \le n_{m+1}$. Given an open cover $\{U_\alpha\}$ of $K$, find a finite subcover of $K_0$, $U_1, \ldots, U_K$. Next, find $m$ such that $K_0^{1/m} \subseteq \bigcup_{k = 1} ^K U_k$ (exists because $K_0$ is compact and $\bigcup_{k = 1} ^ K U_k$ is open). Hence $U_1, \ldots, U_K$ is an open cover for $K_n$ for all $n > n_m$. Now, just use compactness of $K_1, \ldots, K_{n_m}$ extend the open cover $K_{n_m + 1}, K_{n_m + 2}, \ldots$ to one which covers all $K_n$.",,"['probability', 'measure-theory', 'probability-theory']"
81,Integral of Wiener Process and Central Limit Theorem,Integral of Wiener Process and Central Limit Theorem,,"I am trying to solve the following exercise: (1) Given $W$ is a Wiener process, find a constant $M$ such that   $\lim\limits_{t\to\infty} \frac{1}{t}\int_{0}^{t}\sin^2W_s ds=M$ (2) Then show that   $\frac{1}{\sqrt{t}}\int_{0}^{t}(\sin^2W_s-M) ds$ converges to $N(0,\sigma^2)$ and compute $\sigma^2$. So far I have only started the first part of the question before getting stumped.  I started the following: I simply integrated by parts with respect to s and evaluated at the bounds 0 and t $$\lim_{t\to\infty} \frac{1}{t}\int_{0}^{t}\sin^2W_s ds= \lim_{t\to\infty} \frac{1}{t}\left(\frac{1}{2}\Big((W_t-\sin(W_t)\cos(W_t)-(W_0-\sin(W_0)\cos(W_0)\Big)-\int_{0}^{t}sd(\sin^2W_s)\right)$$ Given $W_0=0$ We have the following: $$\lim_{t\to\infty} \frac{1}{t}\left(\frac{1}{2}(W_t-\sin(W_t)\cos(W_t))-\int_{0}^{t}sd(\sin^2W_s)\right)$$ I am assuming I have to apply something like Ito's formula to the stochastic integral term on the RHS. However, I am stumped how to show this limit equals a constant M, and how to begin the second part of the problem statement.","I am trying to solve the following exercise: (1) Given $W$ is a Wiener process, find a constant $M$ such that   $\lim\limits_{t\to\infty} \frac{1}{t}\int_{0}^{t}\sin^2W_s ds=M$ (2) Then show that   $\frac{1}{\sqrt{t}}\int_{0}^{t}(\sin^2W_s-M) ds$ converges to $N(0,\sigma^2)$ and compute $\sigma^2$. So far I have only started the first part of the question before getting stumped.  I started the following: I simply integrated by parts with respect to s and evaluated at the bounds 0 and t $$\lim_{t\to\infty} \frac{1}{t}\int_{0}^{t}\sin^2W_s ds= \lim_{t\to\infty} \frac{1}{t}\left(\frac{1}{2}\Big((W_t-\sin(W_t)\cos(W_t)-(W_0-\sin(W_0)\cos(W_0)\Big)-\int_{0}^{t}sd(\sin^2W_s)\right)$$ Given $W_0=0$ We have the following: $$\lim_{t\to\infty} \frac{1}{t}\left(\frac{1}{2}(W_t-\sin(W_t)\cos(W_t))-\int_{0}^{t}sd(\sin^2W_s)\right)$$ I am assuming I have to apply something like Ito's formula to the stochastic integral term on the RHS. However, I am stumped how to show this limit equals a constant M, and how to begin the second part of the problem statement.",,"['probability', 'probability-theory', 'stochastic-processes', 'stochastic-calculus', 'stochastic-integrals']"
82,"X,Y,Z are mutually independent random variables. Is X and Y+Z independent?","X,Y,Z are mutually independent random variables. Is X and Y+Z independent?",,"X,Y,Z are mutually independent random variables. Is X and Y+Z   independent? Please, give me a hint how to prove it?","X,Y,Z are mutually independent random variables. Is X and Y+Z   independent? Please, give me a hint how to prove it?",,"['probability', 'probability-theory']"
83,Probability of drawing a run of a specific color from an urn with two colors of balls,Probability of drawing a run of a specific color from an urn with two colors of balls,,"I was sent a puzzle involving an urn with 128 white balls and 288 black. If the balls are drawn without replacement until the urn is exhausted, what is the probability that a sequence of 10 or more consecutive white balls will be drawn? I solved this algorithmically using recursion and arrived at ~0.00170843. Simulations match this result well. Is there a more direct conbinatorial method to answer this kind of question?","I was sent a puzzle involving an urn with 128 white balls and 288 black. If the balls are drawn without replacement until the urn is exhausted, what is the probability that a sequence of 10 or more consecutive white balls will be drawn? I solved this algorithmically using recursion and arrived at ~0.00170843. Simulations match this result well. Is there a more direct conbinatorial method to answer this kind of question?",,"['probability', 'combinatorics', 'balls-in-bins']"
84,In a tournament $n$ players take part in a series of duels,In a tournament  players take part in a series of duels,n,"I've recently been thinking about this problem and I think I solved it correctly. However, I was using a rather peculiar method with lots of algebra. I'll post my solution as an answer below. Is there a better (or just different) way of solving this problem? Problem In a tournament $n$ players take part in a series of duels in which both players have equal chances of winning. After each duel the winner plays against the player, that hasn't played for the longest time (or in the beginning someone that hasn't played yet). The first player to beat all other players in consecutive duels wins the tournament. What is the probability that a player wins the tournament given that he takes part in the first duel? An example with $n=3$ Alice and Bob start and Colin sits out first. Alice beats Bob, Colin beats Alice, Bob beats Colin, Bob beats Alice. Bob wins the tournament. Here Alice, Bob and Colin had winning probabilities $\frac{5}{14}$, $\frac{5}{14}$, $\frac{4}{14}$ respectively. EDIT: Only 3 days left for the bounty. We don't want those points to disappear into nirvana, do we? :(","I've recently been thinking about this problem and I think I solved it correctly. However, I was using a rather peculiar method with lots of algebra. I'll post my solution as an answer below. Is there a better (or just different) way of solving this problem? Problem In a tournament $n$ players take part in a series of duels in which both players have equal chances of winning. After each duel the winner plays against the player, that hasn't played for the longest time (or in the beginning someone that hasn't played yet). The first player to beat all other players in consecutive duels wins the tournament. What is the probability that a player wins the tournament given that he takes part in the first duel? An example with $n=3$ Alice and Bob start and Colin sits out first. Alice beats Bob, Colin beats Alice, Bob beats Colin, Bob beats Alice. Bob wins the tournament. Here Alice, Bob and Colin had winning probabilities $\frac{5}{14}$, $\frac{5}{14}$, $\frac{4}{14}$ respectively. EDIT: Only 3 days left for the bounty. We don't want those points to disappear into nirvana, do we? :(",,"['probability', 'markov-chains']"
85,Spinners from yesteryear: A challenging probability problem,Spinners from yesteryear: A challenging probability problem,,"While browsing the Internet I found an old horse racing game where the results were determined by a spinner. The names of 6 different horses were listed an equal number of times on the spinner. Each time the spinner landed on a particular horse, you moved that horse forward 1 space. The first horse to move 5 spaces, won the race. It was obvious that each horse had an equal probability of winning. I wondered, though, what would happen if we weighted each horse differently, say p1,p2,...,p6, where p1+p2+...+p6 = 1. With this in mind, how would these weightings relate to their probability of winning the race? The problem is, to me at least, difficult. I simulated a few ""races"" as an example: Race 1: p = [p1,p2,...,p6] = [50,10,10,10,10,10] --> Total wins for each horse from 100,000 simulations = [95928,831,776,839,825,801] Race 2: p= [50,30,5,5,5,5] --> [78231,21636,29,43,30,31] You get the idea. So the question is given an initial set of probabilities for each of the 6 horses, what are the final ""winning"" probabilities? Is there a formula (complicated or not) that describes this? Thanks to everyone who gives it a shot!","While browsing the Internet I found an old horse racing game where the results were determined by a spinner. The names of 6 different horses were listed an equal number of times on the spinner. Each time the spinner landed on a particular horse, you moved that horse forward 1 space. The first horse to move 5 spaces, won the race. It was obvious that each horse had an equal probability of winning. I wondered, though, what would happen if we weighted each horse differently, say p1,p2,...,p6, where p1+p2+...+p6 = 1. With this in mind, how would these weightings relate to their probability of winning the race? The problem is, to me at least, difficult. I simulated a few ""races"" as an example: Race 1: p = [p1,p2,...,p6] = [50,10,10,10,10,10] --> Total wins for each horse from 100,000 simulations = [95928,831,776,839,825,801] Race 2: p= [50,30,5,5,5,5] --> [78231,21636,29,43,30,31] You get the idea. So the question is given an initial set of probabilities for each of the 6 horses, what are the final ""winning"" probabilities? Is there a formula (complicated or not) that describes this? Thanks to everyone who gives it a shot!",,"['probability', 'statistics']"
86,Distribution of the sum of the $q$th largest observations to the sum of total for a power-law.,Distribution of the sum of the th largest observations to the sum of total for a power-law.,q,"Where $X_{(1)}, X_{(2)}, \ldots,X_{(n)}$ are sorted independents r.v.s, where we index and order in such a way that $X_{(i)} \geq X_{(i-1)}$ , $i>1$ where all realizations follow the same Standard Pareto distribution with density $\phi_\alpha (x)=\alpha \, x_\min^\alpha x^{-\alpha -1}\mathbb{1}_{x\geq x_\min }$ ; What is the in-sample distribution of the ratio of the ordered sum above the $q^{th}$ largest observation to the total,with a total sample of $n$ ? $$ \hat{\kappa}=\frac{X_{(q)}+X_{(q+1)}+\cdots+X_{(n)}}{X_{(1)}+X_{(2)}+\cdots+X_{(n)}}$$ All I have is $0 \leq \hat{\kappa} \leq 1$ . Where $\kappa$ is the true value of the estimator, which we were able to derive in closed form, we see biases in Monte Carlo where $\hat{\kappa} < \kappa$ even for large $n$ (at an exponent $\alpha=1.1$ and would like to get an idea of the in-sample distribution. We assume $1 < \alpha \leq 2$ .","Where are sorted independents r.v.s, where we index and order in such a way that , where all realizations follow the same Standard Pareto distribution with density ; What is the in-sample distribution of the ratio of the ordered sum above the largest observation to the total,with a total sample of ? All I have is . Where is the true value of the estimator, which we were able to derive in closed form, we see biases in Monte Carlo where even for large (at an exponent and would like to get an idea of the in-sample distribution. We assume .","X_{(1)}, X_{(2)}, \ldots,X_{(n)} X_{(i)} \geq X_{(i-1)} i>1 \phi_\alpha (x)=\alpha \, x_\min^\alpha x^{-\alpha -1}\mathbb{1}_{x\geq
x_\min } q^{th} n  \hat{\kappa}=\frac{X_{(q)}+X_{(q+1)}+\cdots+X_{(n)}}{X_{(1)}+X_{(2)}+\cdots+X_{(n)}} 0 \leq \hat{\kappa} \leq 1 \kappa \hat{\kappa} < \kappa n \alpha=1.1 1 < \alpha \leq 2","['probability', 'statistics', 'probability-distributions', 'order-statistics']"
87,When does distribution convergence imply expectation convergence?,When does distribution convergence imply expectation convergence?,,"If $X_n \xrightarrow{d} X$ what are the minimal hypothesis to have $E[X_n]\rightarrow E[X]$ ? For example I think that if all the second moments are bounded it's true, but I'm not sure if is true if the first moments are bounded.","If $X_n \xrightarrow{d} X$ what are the minimal hypothesis to have $E[X_n]\rightarrow E[X]$ ? For example I think that if all the second moments are bounded it's true, but I'm not sure if is true if the first moments are bounded.",,"['probability', 'probability-theory', 'random-variables']"
88,"""Poissonization"" and intuition","""Poissonization"" and intuition",,"In a french book, ""Calcul des probabilités"" from Foata and Fuchs, I found this theorem, which they call ""Poissonization"". ""Let $(I_k)_{k \in \mathbb{N}}$ be a sequence of independent variables with Bernoulli distribution, each of the same parameter, $p$. Let $N$ be a variable integer-valued independent from the $I_k$, and define $N_1:= \sum_{k=1\ldots N} I_k$, and $N_2:=\sum_{k=1\ldots N} (1−I_k)$. Then if $N$ has a Poisson distribution with parameter $\lambda$, then $N_1$ and $N_2$ are independent, and have Poisson laws, of parameters $\lambda p$ and $\lambda (1-p)$. Conversely, if $N_1$ and $N_2$ are independent, then $N$ has a Poisson distribution."" What does this situation modelize ? Is there a natural problem where this situation arises ? I really don't understand what I am dealing with.","In a french book, ""Calcul des probabilités"" from Foata and Fuchs, I found this theorem, which they call ""Poissonization"". ""Let $(I_k)_{k \in \mathbb{N}}$ be a sequence of independent variables with Bernoulli distribution, each of the same parameter, $p$. Let $N$ be a variable integer-valued independent from the $I_k$, and define $N_1:= \sum_{k=1\ldots N} I_k$, and $N_2:=\sum_{k=1\ldots N} (1−I_k)$. Then if $N$ has a Poisson distribution with parameter $\lambda$, then $N_1$ and $N_2$ are independent, and have Poisson laws, of parameters $\lambda p$ and $\lambda (1-p)$. Conversely, if $N_1$ and $N_2$ are independent, then $N$ has a Poisson distribution."" What does this situation modelize ? Is there a natural problem where this situation arises ? I really don't understand what I am dealing with.",,"['probability', 'intuition']"
89,Markov Chain: prove that state is positive recurrent by calculating expected # of transitions to return to this state,Markov Chain: prove that state is positive recurrent by calculating expected # of transitions to return to this state,,"Given the transitional probabilities below (states: 0,1,2,3), I need to prove that state 3 is positive recurrent by calculating expected # of transitions to return to this state $$P = \pmatrix{0.65& 0.35 &0 &0\\ 0.5& 0.1& 0.4 &0 \\ 0.1 &0 &0 &0.9\\ 0.6 &0 &0 &0.4\\}$$ now I see the all states communicate and the matrix is finite, then the MC is irreducible and there is only one class. it also follows that the states are positive recurrent. however, I need to make the claim about the positive recurrence of state 3 through calculating expected # of transitions to return to this state if starting from state 3. How would I calculate this? I know there are some formulas for special Markov Chains, but I can't seem to understand the correct approach here. I cannot calculate it as E[..] by conditioning since it becomes infinite recurrence..","Given the transitional probabilities below (states: 0,1,2,3), I need to prove that state 3 is positive recurrent by calculating expected # of transitions to return to this state $$P = \pmatrix{0.65& 0.35 &0 &0\\ 0.5& 0.1& 0.4 &0 \\ 0.1 &0 &0 &0.9\\ 0.6 &0 &0 &0.4\\}$$ now I see the all states communicate and the matrix is finite, then the MC is irreducible and there is only one class. it also follows that the states are positive recurrent. however, I need to make the claim about the positive recurrence of state 3 through calculating expected # of transitions to return to this state if starting from state 3. How would I calculate this? I know there are some formulas for special Markov Chains, but I can't seem to understand the correct approach here. I cannot calculate it as E[..] by conditioning since it becomes infinite recurrence..",,"['probability', 'stochastic-processes']"
90,Elementary proof of geometric / negative binomial distribution in birth-death processes,Elementary proof of geometric / negative binomial distribution in birth-death processes,,"The birth-death process concerns a population of $n_0$ individuals, each of which reproduces and dies at a constant rate as time $t$ increases from $t=0$ . Each individual splits into two individuals (birth) with rate $\lambda$ , and each individual dies at rate $\mu$ . One can conceptualize this process as a continuous-time Markov chain with states $0, 1, 2,\ldots$ representing the current size of the population. We are interested in the distribution $P_t(n) = P(N(t) = n)$ of the population size $N(t)$ at time $t$ . It can be shown that for the pure birth process ( $\mu = 0$ ), at fixed time $t$ the probability $P_t(n)$ has the form of a negative binomial distribution: $$ P_t(n) = {n-1 \choose n-n_0} (e^{- \lambda  t})^{n_0} (1 - e^{-\lambda t})^{n - n_0}. $$ A similar negative binomial formula can be derived for a nonzero death rate. This is typically proven by solving a PDE involving the generating function governing the process; see for example these slides or (Grimmett and Stirzaker, section 6.11). It would be interesting to prove the formula in a more elementary fashion, by identifying how exactly the birth-death process corresponds with the process that defines the binomial distribution. This is similar to how combinatorialists want a bijective proof of an enumeration theorem after they find a generating function proof. I have not been able to find the desired elementary proof, even for the special case of a pure birth process starting from 1 individual ( $n_0 = 1$ and $\mu = 0$ ), in which case the negative binomial simplifies to the geometric distribution. Does anyone know where to find it, or how to derive it from first principles? Here's what I've got so far: recall that the negative binomial distribution is the distribution of ""the number of successes in a sequence of Bernoulli trials before a specified number of failures occurs."" In the case of the formula above, we can compare with the formula on wikipedia to see that the number of successes is $n - n_0$ , the number of failures is $n_0$ , the success probability on each Bernoulli trial is $1 - e^{\lambda t}$ , and the failure probability is $e^{\lambda t}$ . The failure probability is recognizable as the probability that an exponentially distributed waiting time (with rate $\lambda$ ) exceeds $t$ . Thus, the formula seems to be telling us that the birth process can be simulated by throwing exponential waiting times onto the real line until $n_0$ of them have exceeded the threshold $t$ . But it's unclear what realizations of the process are generated by this simulation method, and how it is able to automagically place the proper probabilistic weight on these realizations.","The birth-death process concerns a population of individuals, each of which reproduces and dies at a constant rate as time increases from . Each individual splits into two individuals (birth) with rate , and each individual dies at rate . One can conceptualize this process as a continuous-time Markov chain with states representing the current size of the population. We are interested in the distribution of the population size at time . It can be shown that for the pure birth process ( ), at fixed time the probability has the form of a negative binomial distribution: A similar negative binomial formula can be derived for a nonzero death rate. This is typically proven by solving a PDE involving the generating function governing the process; see for example these slides or (Grimmett and Stirzaker, section 6.11). It would be interesting to prove the formula in a more elementary fashion, by identifying how exactly the birth-death process corresponds with the process that defines the binomial distribution. This is similar to how combinatorialists want a bijective proof of an enumeration theorem after they find a generating function proof. I have not been able to find the desired elementary proof, even for the special case of a pure birth process starting from 1 individual ( and ), in which case the negative binomial simplifies to the geometric distribution. Does anyone know where to find it, or how to derive it from first principles? Here's what I've got so far: recall that the negative binomial distribution is the distribution of ""the number of successes in a sequence of Bernoulli trials before a specified number of failures occurs."" In the case of the formula above, we can compare with the formula on wikipedia to see that the number of successes is , the number of failures is , the success probability on each Bernoulli trial is , and the failure probability is . The failure probability is recognizable as the probability that an exponentially distributed waiting time (with rate ) exceeds . Thus, the formula seems to be telling us that the birth process can be simulated by throwing exponential waiting times onto the real line until of them have exceeded the threshold . But it's unclear what realizations of the process are generated by this simulation method, and how it is able to automagically place the proper probabilistic weight on these realizations.","n_0 t t=0 \lambda \mu 0, 1, 2,\ldots P_t(n) = P(N(t) = n) N(t) t \mu = 0 t P_t(n) 
P_t(n) = {n-1 \choose n-n_0} (e^{- \lambda  t})^{n_0} (1 - e^{-\lambda t})^{n - n_0}.
 n_0 = 1 \mu = 0 n - n_0 n_0 1 - e^{\lambda t} e^{\lambda t} \lambda t n_0 t","['probability', 'stochastic-processes', 'markov-chains', 'markov-process']"
91,Question about Markov chain,Question about Markov chain,,"We know that if $\{X_n\}$ is a Markov chain, then $X_{n+1}$ is independent with the past states $X_0,\ldots,X_{n-1}$ given current state $X_n$, that is $$P\{X_{n+1}=j|X_0=i_0,\ldots,X_n=i\}=P\{X_{n+1}=j|X_n=i\}$$ What if we give several possible current states, do we still have $$P\{X_{n+1}=j|X_0=i_0,\ldots,X_n=i\ \text{or}\ i'\}=P\{X_{n+1}=j|X_n=i\ \text{or}\ i'\}$$ Intuitively it is correct, but I wonder how to prove it using the original definition.","We know that if $\{X_n\}$ is a Markov chain, then $X_{n+1}$ is independent with the past states $X_0,\ldots,X_{n-1}$ given current state $X_n$, that is $$P\{X_{n+1}=j|X_0=i_0,\ldots,X_n=i\}=P\{X_{n+1}=j|X_n=i\}$$ What if we give several possible current states, do we still have $$P\{X_{n+1}=j|X_0=i_0,\ldots,X_n=i\ \text{or}\ i'\}=P\{X_{n+1}=j|X_n=i\ \text{or}\ i'\}$$ Intuitively it is correct, but I wonder how to prove it using the original definition.",,"['probability', 'probability-theory', 'stochastic-processes', 'markov-chains', 'markov-process']"
92,Brownian Bridge as a Gaussian Process,Brownian Bridge as a Gaussian Process,,"Let $B=\{B_t:t\geq 0\}$ be a standard Brownian motion. Define the Brownian brige $X=\{X_t:t\geq0\}$ as $$ X_t=B_t-tB_1\quad t\in[0,1] $$ Show that $X$ is (i) Gaussian and find its (ii) mean and (iii) covariance. TWO questions: Due to my lack of basics on the subsject, can I see a full proof of (ii) and (iii) ? Can anybody check my attempt on (i)? Attempt on (i). Given that $X$ is a stochastic process by definition only need to show that $\sum_i^n \lambda_i X_{t_i}$ is Gaussian for some real $\lambda_1,\lambda_2,...,\lambda_n$. \begin{equation*} \begin{split} \sum_i^n \lambda_i( B_{t_i}-t_iB_1) & = \sum_i^n \lambda_i B_{t_i}-\gamma_iB_1 \ \ \text{ where }\gamma_i=\lambda_it_i \\ & = \sum_i^n \phi_iB_{t_i} +\gamma_i(B_{t_i}-B_1)\text{ where }\phi_i=\lambda_i-\gamma_i\\ & = \sum_i^n \phi_iB_{t_i} +\sum_i^n \gamma_i(B_{t_i}-B_1)\\ & = \sum_i^{n }\theta_i(B_{t_i}-B_{t_{i-s}} )+\sum_i^n \gamma_i(B_{t_i}-B_1), \end{split} \end{equation*} scalar multiplication for normal distribution was used in every step. Then using the independence property of BM and the sum of independent normal variable property we satisfy the definition of a Gaussian process (doubts on the last equality/rearranging, namely on $\theta$ and $n$ in the first sum). $\blacksquare$","Let $B=\{B_t:t\geq 0\}$ be a standard Brownian motion. Define the Brownian brige $X=\{X_t:t\geq0\}$ as $$ X_t=B_t-tB_1\quad t\in[0,1] $$ Show that $X$ is (i) Gaussian and find its (ii) mean and (iii) covariance. TWO questions: Due to my lack of basics on the subsject, can I see a full proof of (ii) and (iii) ? Can anybody check my attempt on (i)? Attempt on (i). Given that $X$ is a stochastic process by definition only need to show that $\sum_i^n \lambda_i X_{t_i}$ is Gaussian for some real $\lambda_1,\lambda_2,...,\lambda_n$. \begin{equation*} \begin{split} \sum_i^n \lambda_i( B_{t_i}-t_iB_1) & = \sum_i^n \lambda_i B_{t_i}-\gamma_iB_1 \ \ \text{ where }\gamma_i=\lambda_it_i \\ & = \sum_i^n \phi_iB_{t_i} +\gamma_i(B_{t_i}-B_1)\text{ where }\phi_i=\lambda_i-\gamma_i\\ & = \sum_i^n \phi_iB_{t_i} +\sum_i^n \gamma_i(B_{t_i}-B_1)\\ & = \sum_i^{n }\theta_i(B_{t_i}-B_{t_{i-s}} )+\sum_i^n \gamma_i(B_{t_i}-B_1), \end{split} \end{equation*} scalar multiplication for normal distribution was used in every step. Then using the independence property of BM and the sum of independent normal variable property we satisfy the definition of a Gaussian process (doubts on the last equality/rearranging, namely on $\theta$ and $n$ in the first sum). $\blacksquare$",,"['probability', 'normal-distribution', 'brownian-motion']"
93,Probability that one player rolls more more 5s or 6s than the other player when one player rolls $X$ dice and the other player rolls $Y$ dice,Probability that one player rolls more more 5s or 6s than the other player when one player rolls  dice and the other player rolls  dice,X Y,"There is a game I play that utilizes a particular mechanic that I am trying to assess mathematically. Me being a layman, I am having some problems figuring out one of the aspects for myself. The basic mechanic works like this: you roll a number of 6 sided dice. Any die that rolls a 5 or a 6 nets you a success. You count your total number of successes, and the more of them there are the better. Now, I know how to calculate the chance that I will succeed when I am trying to roll a fixed number of successes. But, sometimes the game has you roll against someone else's roll. For example: Player A rolls X number of dice with 6 sides. Player B rolls Y number of dice with 6 sides. The person who rolls more results of 5 or 6 succeeds. How do I calculate the probability that player A will succeed? Thank you very much in advance!","There is a game I play that utilizes a particular mechanic that I am trying to assess mathematically. Me being a layman, I am having some problems figuring out one of the aspects for myself. The basic mechanic works like this: you roll a number of 6 sided dice. Any die that rolls a 5 or a 6 nets you a success. You count your total number of successes, and the more of them there are the better. Now, I know how to calculate the chance that I will succeed when I am trying to roll a fixed number of successes. But, sometimes the game has you roll against someone else's roll. For example: Player A rolls X number of dice with 6 sides. Player B rolls Y number of dice with 6 sides. The person who rolls more results of 5 or 6 succeeds. How do I calculate the probability that player A will succeed? Thank you very much in advance!",,"['probability', 'dice']"
94,Distribution of $Y = \sin X$ when $X$ is normal?,Distribution of  when  is normal?,Y = \sin X X,"Assume $X$ is Normally distributed :  $X\sim N(\mu,\sigma)$ What is the distribution of $Y = \sin X$ ? I think we should start with $F_Y(y)=P(\sin X < y)$. But how to continue?","Assume $X$ is Normally distributed :  $X\sim N(\mu,\sigma)$ What is the distribution of $Y = \sin X$ ? I think we should start with $F_Y(y)=P(\sin X < y)$. But how to continue?",,"['probability', 'probability-theory', 'probability-distributions', 'normal-distribution']"
95,A consequence of the law of large numbers,A consequence of the law of large numbers,,"Let $(X_k)_{k=1}$ be Poisson random variables with expectation $\mu$, let $Y_n = \sum_{k=1}^{n} X_k$. The weak law of large numbers states that, $$ \forall \delta>0, \forall \epsilon>0 \, \, \exists N>0\, \,\, s.t.\, \forall n >N \, \, P ( |Y_n/n - \mu|  > \delta ) < \epsilon, $$ From this statement, is there a simple way to prove that there exists a constant $q>0$ which does not depend on $n$ such that $\forall n$, $$  P (\, Y_n/n - \mu   \geq 0 \, )\, > q \,? $$ Probably the fact that the random variables are Poisson is not essential.","Let $(X_k)_{k=1}$ be Poisson random variables with expectation $\mu$, let $Y_n = \sum_{k=1}^{n} X_k$. The weak law of large numbers states that, $$ \forall \delta>0, \forall \epsilon>0 \, \, \exists N>0\, \,\, s.t.\, \forall n >N \, \, P ( |Y_n/n - \mu|  > \delta ) < \epsilon, $$ From this statement, is there a simple way to prove that there exists a constant $q>0$ which does not depend on $n$ such that $\forall n$, $$  P (\, Y_n/n - \mu   \geq 0 \, )\, > q \,? $$ Probably the fact that the random variables are Poisson is not essential.",,"['probability', 'random-variables', 'random', 'law-of-large-numbers']"
96,"Prove that expected value of X is greater than Y, if given that $P(X\ge Y)=1$","Prove that expected value of X is greater than Y, if given that",P(X\ge Y)=1,"I have to prove that $E(X)$ (Expected Value of a random variable X), is greater than $E(Y)$, if given that $P(X\ge Y)=1$. my thoughts so far: I know from the $P(X\ge Y)=1$ statement, that the values that X ""receives"" are always greater than the values that Y ""receives"", and because the expected value of a random variable is always a weighted mean of its valid values, than of course $E(X) \ge E(Y)$. But how do I prove it formally?","I have to prove that $E(X)$ (Expected Value of a random variable X), is greater than $E(Y)$, if given that $P(X\ge Y)=1$. my thoughts so far: I know from the $P(X\ge Y)=1$ statement, that the values that X ""receives"" are always greater than the values that Y ""receives"", and because the expected value of a random variable is always a weighted mean of its valid values, than of course $E(X) \ge E(Y)$. But how do I prove it formally?",,"['probability', 'random-variables']"
97,Associated random variables,Associated random variables,,Can some one point some good references on associated sequences of random variables?,Can some one point some good references on associated sequences of random variables?,,"['probability', 'reference-request', 'random-variables']"
98,Interesting probability question about islands and bridges,Interesting probability question about islands and bridges,,"The inhabitants of the beautiful and ancient canal city of Pentapolis live on 5 islands separated from each other by water. Bridges cross from one island to another as shown. On any day, a bridge can be closed, with probability $p$, for restoration work. Assuming that the 8 bridges are closed independently, find the mean and variance of the number of islands which are completely cut off because of restoration work.","The inhabitants of the beautiful and ancient canal city of Pentapolis live on 5 islands separated from each other by water. Bridges cross from one island to another as shown. On any day, a bridge can be closed, with probability $p$, for restoration work. Assuming that the 8 bridges are closed independently, find the mean and variance of the number of islands which are completely cut off because of restoration work.",,"['probability', 'statistics']"
99,Probability of winning blackjack dice game?,Probability of winning blackjack dice game?,,"I know a little bit about probability but I am not sure how to calculate this: In a dice game of blackjack, there are two parties. The player and the dealer. The aim of this game is to get as close to $21$ without going over, using six sided dice which has an equal chance of landing on each side. Both parties may use as many dice as they like. If the player goes over 21 then they lose and similarly to casino blackjack, the player's turn is first. For the purpose of this question, assume that the player will always keep (stay) the value of either 19, 20, 21 and would continue if the value is 18 or under. If there is a draw then the game is repeated and there is no winner. Thanks in advance and I hope this is enough information to draw a reasonable answer.","I know a little bit about probability but I am not sure how to calculate this: In a dice game of blackjack, there are two parties. The player and the dealer. The aim of this game is to get as close to $21$ without going over, using six sided dice which has an equal chance of landing on each side. Both parties may use as many dice as they like. If the player goes over 21 then they lose and similarly to casino blackjack, the player's turn is first. For the purpose of this question, assume that the player will always keep (stay) the value of either 19, 20, 21 and would continue if the value is 18 or under. If there is a draw then the game is repeated and there is no winner. Thanks in advance and I hope this is enough information to draw a reasonable answer.",,"['probability', 'dice']"
