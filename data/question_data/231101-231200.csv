,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Prove the relation is an equivalence relation.,Prove the relation is an equivalence relation.,,"Problem Define the relation $R$ on the set of natural numbers as $(a,b) \in R > \iff 2 \vert(a^2 + b) $. Prove that $R$ is an equivalence relation. This is what I have so far. Claim: Define the relation $R$ on the set of natural numbers as $(a,b) \in R > \iff 2 \mid(a^2 + b) $. The relation $R$ is an equivalence relation. Proof: Part 1 (Reflixivity): Let $R = \{(a,b) \in \Bbb{N} \times \Bbb{N} \mid 2 \mid (a^2+b)\}$ be given and suppose that $b \in \Bbb{N}$. Then, for some integer $k$: $$\require{enclose} \enclose{downdiagonalstrike}{\begin{align} 2 \mid b^2 +b \iff 2k &= b^2 +b \\  & = b^2 + b - (b^2 + b) + (b^2 + b) \\   & = 2b^2 + 2b - (b^2 + b) \\   & = -2b^2 - 2b + (b^2 + b) \end{align}}$$ Therefore,  $$\enclose{downdiagonalstrike}{\begin{align} 2 \mid b^2 +b \iff b^2 + b &= 2k -2b^2 - 2b \\  & = 2(k - b^2 - b)\\    &  \end{align}}$$ $\enclose{horizontalstrike}{\text{Thus, $2 \mid b^2 +b$ for some integer $(k - b^2 - b)$. Which implies that $R$ is Reflexive.}} $ EDIT: Thanks to some positive feed back I have been let known that this is not showing Reflexivity. Part 2 (Symmetry) Let $R = \{(a,b) \in \Bbb{N} \times \Bbb{N} \mid 2 \mid (a^2+b)\}$ be given and suppose that, for any $a,b \in \Bbb{N}$, $ a\mathbf{R}b \leftrightarrow b\mathbf{R}a.$  Then, for some integer $k$: $$\enclose{updiagonalstrike}{\begin{align} 2 \mid a^2 + b  & \iff 2k = a^2 + b \\  & \iff 2k + (a + b^2) = (a^2 + b) + (a + b^2)\\   & \iff (a + b^2) = (a + b) + (a^2 + b^2) - 2k \\   &  \end{align}}$$ $\enclose{horizontalstrike}{\text{Since, the relation $R$ is proven to be Reflexive, let the integer $ m = a = b $ and let the integer $ n = a^2 = b^2 $. Then, }}$ EDIT: This is not a valid way to show Symmetry, since Part 1 (Reflexivity) has not been proven. $$\enclose{updiagonalstrike}{\begin{align} a + b^2 = (a + b) + (a^2 + b^2) - 2k & \iff (a + b^2) = 2m + 2n - 2k \\  & \iff (a + b^2) = 2(m + n -k)\\    &  \end{align}}$$ $\enclose{horizontalstrike}{\text{Thus, $2 \mid b^2 + a$ which implies that $R$ is Symmetric since $ a\mathbf{R}b \leftrightarrow b\mathbf{R}a $.}}$ Part 3 (Transitivity) Let $R = \{(a,b) \in \Bbb{N} \times \Bbb{N} \mid 2 \mid (a^2+b)\}$ be given and suppose that, for any $a,b,c \in \Bbb{N}$, $ a\mathbf{R}b \text{ and } b\mathbf{R}c.$ Then, let $k$ and $h$ be some integers: \begin{align} 2k = a^2 + b \text{ and } 2h = b^2 + c & \implies 2(k + h) = (a^2 + b) + (b^2 + c) \\  & \\   & \\   &  \end{align} Comment: And, this is where I get stuck. I am struggling to find a way to show that $ (2 \mid a^2 + b) \land (2 \mid b^2 + c) \implies 2 \mid a^2 + c$. I've also tried eliminating $b$ like so, $2h = (2k - a^2)^2 + c$, but this doesn't seem to get me any where. I feel like I'm running in circles here. My Question Can you argue that $R$ is transitive since it has already been shown that $2 \mid b^2 + b$? This would imply something like ""$2(k - b^2 - b) + 2h = (a^2 + c) +(b^2 + b)$ is logically equivalent to $(2 \mid b^2 + b) \land (2 \mid a^2 + c)$."" And, this simplifies to just $2 \mid a^2 + c$ by the inference rule of simplification [$(p \land q) \to p$]. Which ultimatily I believe gets me to my goal, but I'm not sure if it is two far of a leep to go from $2(k - b^2 - b) + 2h = (a^2 + c) +(b^2 + b) \implies (2 \mid b^2 + b) \land (2 \mid a^2 + c)$. I hope my question was specific enough. Otherwise, I would much appreciate some guidance on showing how this relation is transitive if anyone is feeling generous. Thanks!","Problem Define the relation $R$ on the set of natural numbers as $(a,b) \in R > \iff 2 \vert(a^2 + b) $. Prove that $R$ is an equivalence relation. This is what I have so far. Claim: Define the relation $R$ on the set of natural numbers as $(a,b) \in R > \iff 2 \mid(a^2 + b) $. The relation $R$ is an equivalence relation. Proof: Part 1 (Reflixivity): Let $R = \{(a,b) \in \Bbb{N} \times \Bbb{N} \mid 2 \mid (a^2+b)\}$ be given and suppose that $b \in \Bbb{N}$. Then, for some integer $k$: $$\require{enclose} \enclose{downdiagonalstrike}{\begin{align} 2 \mid b^2 +b \iff 2k &= b^2 +b \\  & = b^2 + b - (b^2 + b) + (b^2 + b) \\   & = 2b^2 + 2b - (b^2 + b) \\   & = -2b^2 - 2b + (b^2 + b) \end{align}}$$ Therefore,  $$\enclose{downdiagonalstrike}{\begin{align} 2 \mid b^2 +b \iff b^2 + b &= 2k -2b^2 - 2b \\  & = 2(k - b^2 - b)\\    &  \end{align}}$$ $\enclose{horizontalstrike}{\text{Thus, $2 \mid b^2 +b$ for some integer $(k - b^2 - b)$. Which implies that $R$ is Reflexive.}} $ EDIT: Thanks to some positive feed back I have been let known that this is not showing Reflexivity. Part 2 (Symmetry) Let $R = \{(a,b) \in \Bbb{N} \times \Bbb{N} \mid 2 \mid (a^2+b)\}$ be given and suppose that, for any $a,b \in \Bbb{N}$, $ a\mathbf{R}b \leftrightarrow b\mathbf{R}a.$  Then, for some integer $k$: $$\enclose{updiagonalstrike}{\begin{align} 2 \mid a^2 + b  & \iff 2k = a^2 + b \\  & \iff 2k + (a + b^2) = (a^2 + b) + (a + b^2)\\   & \iff (a + b^2) = (a + b) + (a^2 + b^2) - 2k \\   &  \end{align}}$$ $\enclose{horizontalstrike}{\text{Since, the relation $R$ is proven to be Reflexive, let the integer $ m = a = b $ and let the integer $ n = a^2 = b^2 $. Then, }}$ EDIT: This is not a valid way to show Symmetry, since Part 1 (Reflexivity) has not been proven. $$\enclose{updiagonalstrike}{\begin{align} a + b^2 = (a + b) + (a^2 + b^2) - 2k & \iff (a + b^2) = 2m + 2n - 2k \\  & \iff (a + b^2) = 2(m + n -k)\\    &  \end{align}}$$ $\enclose{horizontalstrike}{\text{Thus, $2 \mid b^2 + a$ which implies that $R$ is Symmetric since $ a\mathbf{R}b \leftrightarrow b\mathbf{R}a $.}}$ Part 3 (Transitivity) Let $R = \{(a,b) \in \Bbb{N} \times \Bbb{N} \mid 2 \mid (a^2+b)\}$ be given and suppose that, for any $a,b,c \in \Bbb{N}$, $ a\mathbf{R}b \text{ and } b\mathbf{R}c.$ Then, let $k$ and $h$ be some integers: \begin{align} 2k = a^2 + b \text{ and } 2h = b^2 + c & \implies 2(k + h) = (a^2 + b) + (b^2 + c) \\  & \\   & \\   &  \end{align} Comment: And, this is where I get stuck. I am struggling to find a way to show that $ (2 \mid a^2 + b) \land (2 \mid b^2 + c) \implies 2 \mid a^2 + c$. I've also tried eliminating $b$ like so, $2h = (2k - a^2)^2 + c$, but this doesn't seem to get me any where. I feel like I'm running in circles here. My Question Can you argue that $R$ is transitive since it has already been shown that $2 \mid b^2 + b$? This would imply something like ""$2(k - b^2 - b) + 2h = (a^2 + c) +(b^2 + b)$ is logically equivalent to $(2 \mid b^2 + b) \land (2 \mid a^2 + c)$."" And, this simplifies to just $2 \mid a^2 + c$ by the inference rule of simplification [$(p \land q) \to p$]. Which ultimatily I believe gets me to my goal, but I'm not sure if it is two far of a leep to go from $2(k - b^2 - b) + 2h = (a^2 + c) +(b^2 + b) \implies (2 \mid b^2 + b) \land (2 \mid a^2 + c)$. I hope my question was specific enough. Otherwise, I would much appreciate some guidance on showing how this relation is transitive if anyone is feeling generous. Thanks!",,"['elementary-set-theory', 'proof-verification', 'proof-writing', 'relations']"
1,Why is this not a matroid?,Why is this not a matroid?,,"If I recall correctly both of these definitions are equivalent: $(E,I)$ is an independence system and satisfies the augmentation property. $(E,I)$ is an independence system and all maximal independent sets in I have the same size. However I would say that the following system satisfies the second definition but not the first: $(\{1,2,3,4\},\{A|$ all numbers in A have equal parity$\})$ The maximal independent sets are $\{1,3\}$ and $\{2,4\}$, but at the same time if we take $A_1=\{1\}$ and $A_2=\{2,4\}$ we can't find any $a \in \{2,4\} \setminus \{1\}$ so that $(\{1\} \cup a) \in I$. What am I missing here?","If I recall correctly both of these definitions are equivalent: $(E,I)$ is an independence system and satisfies the augmentation property. $(E,I)$ is an independence system and all maximal independent sets in I have the same size. However I would say that the following system satisfies the second definition but not the first: $(\{1,2,3,4\},\{A|$ all numbers in A have equal parity$\})$ The maximal independent sets are $\{1,3\}$ and $\{2,4\}$, but at the same time if we take $A_1=\{1\}$ and $A_2=\{2,4\}$ we can't find any $a \in \{2,4\} \setminus \{1\}$ so that $(\{1\} \cup a) \in I$. What am I missing here?",,"['elementary-set-theory', 'matroids']"
2,Is this example of an inductive (sub)set correct?,Is this example of an inductive (sub)set correct?,,"Note: It seems that the term inductive set has varying definitions . I am not referring (I think) to the definition used here , so this question is not a duplicate of that one. Specifically, consider the definition found on p. 12 of Dudley, Real Analysis and Probability : More generally, let $(X, <)$ be any partially ordered set. A subset $Y \subset X$ will be called inductive if, for every $x \in X$ such that $y \in Y$ for all $y \in X$ such that $y<x$, we have $x \in Y$. The author then goes on to state that the set $( -\infty, 0)$ in $\mathbb{R}$ is inductive (presumably $\mathbb{R}$ with the standard partial order is meant), but: Question: Is that a typo? I.e. how is $(-\infty, 0)$ inductive using the above definition? It seems like $(-\infty, 0]$ might be inductive using the above definition, but not $(- \infty, 0)$. Either a correction of my flawed reasoning, or a sanity check that it is indeed a typo, would help. (Flawed) reasoning: If we take $X = \mathbb{R}$ and $Y = (-\infty, 0)$, then seemingly $0 \in X$ is such that for all $y \in \mathbb{R}$ with $y < 0$, $ y \in (-\infty, 0)$. (That's literally the definition of that half-open interval, right?) So then seemingly by the definition of inductive set, if $(-\infty, 0)$ were inductive, we would have $0 \in (-\infty,0)$, which is obviously untrue. However, the way the definition is worded in Dudley is very confusing to me and it seems likely that I am messing up the order of logical quantifiers and connectives to get a non-equivalent statement in my mind, in particular how I am thinking of the definition is as follows: A subset $Y \subset X$ is inductive if, for all $x \in X$ such that ($y<x \implies y \in Y$) , $x \in Y$. (Now that I write it out my wording of the definition, in addition to most likely being wrong, is also rather opaque.) Anyway, $y <0$ clearly implies $y \in (-\infty, 0)$, hence my ""reasoning"" above.","Note: It seems that the term inductive set has varying definitions . I am not referring (I think) to the definition used here , so this question is not a duplicate of that one. Specifically, consider the definition found on p. 12 of Dudley, Real Analysis and Probability : More generally, let $(X, <)$ be any partially ordered set. A subset $Y \subset X$ will be called inductive if, for every $x \in X$ such that $y \in Y$ for all $y \in X$ such that $y<x$, we have $x \in Y$. The author then goes on to state that the set $( -\infty, 0)$ in $\mathbb{R}$ is inductive (presumably $\mathbb{R}$ with the standard partial order is meant), but: Question: Is that a typo? I.e. how is $(-\infty, 0)$ inductive using the above definition? It seems like $(-\infty, 0]$ might be inductive using the above definition, but not $(- \infty, 0)$. Either a correction of my flawed reasoning, or a sanity check that it is indeed a typo, would help. (Flawed) reasoning: If we take $X = \mathbb{R}$ and $Y = (-\infty, 0)$, then seemingly $0 \in X$ is such that for all $y \in \mathbb{R}$ with $y < 0$, $ y \in (-\infty, 0)$. (That's literally the definition of that half-open interval, right?) So then seemingly by the definition of inductive set, if $(-\infty, 0)$ were inductive, we would have $0 \in (-\infty,0)$, which is obviously untrue. However, the way the definition is worded in Dudley is very confusing to me and it seems likely that I am messing up the order of logical quantifiers and connectives to get a non-equivalent statement in my mind, in particular how I am thinking of the definition is as follows: A subset $Y \subset X$ is inductive if, for all $x \in X$ such that ($y<x \implies y \in Y$) , $x \in Y$. (Now that I write it out my wording of the definition, in addition to most likely being wrong, is also rather opaque.) Anyway, $y <0$ clearly implies $y \in (-\infty, 0)$, hence my ""reasoning"" above.",,"['elementary-set-theory', 'order-theory']"
3,Can we prove the same cardinality of the sets $\mathbb{N}$ and $\mathbb{N^2}$ this way?,Can we prove the same cardinality of the sets  and  this way?,\mathbb{N} \mathbb{N^2},"I tried  to prove that the sets $\mathbb{N}$ and $\mathbb{N^2}$ have the same cardinality and I concluded the following: Consider the function $f:\mathbb{N}\rightarrow \mathbb{N^2}$ that achieves the mapping: $ \begin{cases} 1 \rightarrow (0,0) \end{cases} \\  \begin{cases} 2 \rightarrow (1,0) \\  3 \rightarrow (1,1) \\  4 \rightarrow (0,1) \end{cases} \\  \begin{cases} 5 \rightarrow (2,0) \\  6 \rightarrow (2,1) \\  7 \rightarrow (2,2) \\  8 \rightarrow (1,2) \\  9 \rightarrow (0,2) \end{cases} \\  \quad \vdots$ This way $\forall k \in \mathbb{N}\cup\{0\}$ we construct the function: $f(n) = \begin{cases} \begin{aligned}  &(\sqrt{n-1},0) \\ &(\sqrt{n-1},1) \\ \vdots \\  &(\sqrt{n-1},\sqrt{n-1}-1) \\  &(\sqrt{n-1},\sqrt{n-1}) \\  &(\sqrt{n-1}-1,\sqrt{n-1}) \\ \vdots \\  &(1,\sqrt{n-1}) \\  &(0,\sqrt{n-1})  \end{aligned}  &&  \begin{aligned}  &, n=k^2+1 \\  &, n=k^2+2 \\ \\  &, n=k^2+k \\  &, n=k^2+k+1 \\  &, n=k^2+(k+1)+1 \\ \\  &, n=k^2+(2k-1)+1 \\  &, n=k^2+2k+1=(k+1)^2  \end{aligned} \end{cases}$ Is the above mapping correct? If not then why? If yes then how can I prove rigorously that this function is bijective?","I tried  to prove that the sets $\mathbb{N}$ and $\mathbb{N^2}$ have the same cardinality and I concluded the following: Consider the function $f:\mathbb{N}\rightarrow \mathbb{N^2}$ that achieves the mapping: $ \begin{cases} 1 \rightarrow (0,0) \end{cases} \\  \begin{cases} 2 \rightarrow (1,0) \\  3 \rightarrow (1,1) \\  4 \rightarrow (0,1) \end{cases} \\  \begin{cases} 5 \rightarrow (2,0) \\  6 \rightarrow (2,1) \\  7 \rightarrow (2,2) \\  8 \rightarrow (1,2) \\  9 \rightarrow (0,2) \end{cases} \\  \quad \vdots$ This way $\forall k \in \mathbb{N}\cup\{0\}$ we construct the function: $f(n) = \begin{cases} \begin{aligned}  &(\sqrt{n-1},0) \\ &(\sqrt{n-1},1) \\ \vdots \\  &(\sqrt{n-1},\sqrt{n-1}-1) \\  &(\sqrt{n-1},\sqrt{n-1}) \\  &(\sqrt{n-1}-1,\sqrt{n-1}) \\ \vdots \\  &(1,\sqrt{n-1}) \\  &(0,\sqrt{n-1})  \end{aligned}  &&  \begin{aligned}  &, n=k^2+1 \\  &, n=k^2+2 \\ \\  &, n=k^2+k \\  &, n=k^2+k+1 \\  &, n=k^2+(k+1)+1 \\ \\  &, n=k^2+(2k-1)+1 \\  &, n=k^2+2k+1=(k+1)^2  \end{aligned} \end{cases}$ Is the above mapping correct? If not then why? If yes then how can I prove rigorously that this function is bijective?",,"['elementary-set-theory', 'proof-writing']"
4,"Equivalence relation class of $X=\{0,1\}^{\mathbb{N}}$",Equivalence relation class of,"X=\{0,1\}^{\mathbb{N}}","Consider $X=\{0,1\}^{\mathbb{N}}$, i.e. the set of functions $\Bbb N \to \{0,1\}$. Let $R$ be a relation on $X$ such that for every $f, g \in X$, $fRg$ iff the set $\{n\in\mathbb{N}|f(n)\neq g(n)\}$ is finite. I proved that the relation $R$ is an equivalence relation. Now I am trying to find the cardinality of $X/R$, the set of equivalence classes of $X$ modulo $R$. But I have some trouble to understand how to do so.","Consider $X=\{0,1\}^{\mathbb{N}}$, i.e. the set of functions $\Bbb N \to \{0,1\}$. Let $R$ be a relation on $X$ such that for every $f, g \in X$, $fRg$ iff the set $\{n\in\mathbb{N}|f(n)\neq g(n)\}$ is finite. I proved that the relation $R$ is an equivalence relation. Now I am trying to find the cardinality of $X/R$, the set of equivalence classes of $X$ modulo $R$. But I have some trouble to understand how to do so.",,['elementary-set-theory']
5,Proof Check: Prove $A\cup \varnothing = A$ and $A\cap \varnothing = \varnothing$.,Proof Check: Prove  and .,A\cup \varnothing = A A\cap \varnothing = \varnothing,"Can someone please verify whether my proofs are logically correct? :-) $A\cup \varnothing = A $ Proof: Let $x\in A \cup \varnothing$. Then $x \in A$ or $x \in \varnothing$. If $x \in A$, then $A \subseteq A$. If $x \in \varnothing$, this forms a contradiction (since the empty set is empty). Therefore $x \in A$ and so $A \cup \varnothing \subset A$. Now let $x \in A$. Then $x \in A \cup \varnothing$ by disjunctive amplification. Then $A \subset A \cup \varnothing$, and so $A\cup \varnothing = A$. $\square$ $A\cap \varnothing = \varnothing$ Proof: Let $x \in A \cap \varnothing$. Then $x \in A$ and $x \in \varnothing$. This forms a contradiction, since the empty set is empty. Therefore, there does not exist such an $x \in A \cap \varnothing$, and so $A\cap \varnothing =\varnothing$. $\square$","Can someone please verify whether my proofs are logically correct? :-) $A\cup \varnothing = A $ Proof: Let $x\in A \cup \varnothing$. Then $x \in A$ or $x \in \varnothing$. If $x \in A$, then $A \subseteq A$. If $x \in \varnothing$, this forms a contradiction (since the empty set is empty). Therefore $x \in A$ and so $A \cup \varnothing \subset A$. Now let $x \in A$. Then $x \in A \cup \varnothing$ by disjunctive amplification. Then $A \subset A \cup \varnothing$, and so $A\cup \varnothing = A$. $\square$ $A\cap \varnothing = \varnothing$ Proof: Let $x \in A \cap \varnothing$. Then $x \in A$ and $x \in \varnothing$. This forms a contradiction, since the empty set is empty. Therefore, there does not exist such an $x \in A \cap \varnothing$, and so $A\cap \varnothing =\varnothing$. $\square$",,['elementary-set-theory']
6,Maximal chain with upper bound has at least one element,Maximal chain with upper bound has at least one element,,"Let $\left({E, \preceq}\right)$ be a poset, and let $K \subseteq E$ be a maximal chain in $E$ such that $K$ has an upper bound in $E$. Then $K$ has at least one element. Proof : $K$ is a maximal chain. That is, for every element $x \in E \setminus K$ there is a $y \in K$ such that $(x,y) \notin \, \preceq$ and $(y,x) \notin \, \preceq$. This means that if an $x \in E$ belongs to $E \setminus K$, we surely have an element of $K$ that isn't comparable with this $x$ (and so no element of the chain is comparable with $x$, because of transitivity). Now let $m \in E$ be an upper bound for $K$; we can compare $m$ with any element the chain. But this is the same as saying that $m \notin E \setminus K$ and so $m \in K$. $\blacksquare$ In other words, if $m$ is an upper bound for $K$, it must belongs to $K$ because it has to be comparable with all elements of $K$ itself, and we said that $K$ is maximal (if we are able to compare $m \notin K$ with every element of the chain, it's reasonable to ""expand"" it including $m$, in contrast with the hypothesis that $K$ is maximal). Is it a correct proof?","Let $\left({E, \preceq}\right)$ be a poset, and let $K \subseteq E$ be a maximal chain in $E$ such that $K$ has an upper bound in $E$. Then $K$ has at least one element. Proof : $K$ is a maximal chain. That is, for every element $x \in E \setminus K$ there is a $y \in K$ such that $(x,y) \notin \, \preceq$ and $(y,x) \notin \, \preceq$. This means that if an $x \in E$ belongs to $E \setminus K$, we surely have an element of $K$ that isn't comparable with this $x$ (and so no element of the chain is comparable with $x$, because of transitivity). Now let $m \in E$ be an upper bound for $K$; we can compare $m$ with any element the chain. But this is the same as saying that $m \notin E \setminus K$ and so $m \in K$. $\blacksquare$ In other words, if $m$ is an upper bound for $K$, it must belongs to $K$ because it has to be comparable with all elements of $K$ itself, and we said that $K$ is maximal (if we are able to compare $m \notin K$ with every element of the chain, it's reasonable to ""expand"" it including $m$, in contrast with the hypothesis that $K$ is maximal). Is it a correct proof?",,"['elementary-set-theory', 'proof-verification']"
7,"If $A\thicksim B$ and $C\thicksim D$, then $^{A}C\thicksim$ $^{B}D$.","If  and , then  .",A\thicksim B C\thicksim D ^{A}C\thicksim ^{B}D,"Is the following proof Correct? SOME PRELIMARY NOTATION $A\thicksim B\Leftrightarrow$ There is a bijection from A to B $5.3.2$ - if $f:A\to B$ and $f^{-1}:B\to A$ then $f\circ f^{-1} = i_B = \{(x,x)| x\in B\}$ and $f\circ f^{-1} =i_A=\{(y,y)|y\in A\}$ Theorem. For any sets $A$ and $B$ let $^{A}B$ denote the set of all functions from $A$ to $B$. If $A\thicksim B$ and $C\thicksim D$, then $^{A}C\thicksim$ $^{B}D$. Proof. Assume that $A\thicksim B$ and $C\thicksim D$ consequently we invoke the existence $h_1:A\to B$ and $h_2:C\to D$ such that $h_1$ is a bijection from $A$ to $B$ and $h_2$ is a bijection from $C$ to $D$. We know define the the function $\mathcal{Z}:^{A}C\to$ $^{B}D$ and show that is a bijection from $^{A}C$ to $^{B}D$. $$\mathcal{Z}(f) = h_2\circ f\circ h_1^{-1}$$ Now let $f_1$ and $f_2$ be arbitrary functions in $^{A}C$ and assume that $\mathcal{Z}(f_1) = \mathcal{Z}(f_2)$ consequently $h_2\circ f_1\circ h_1^{-1} = h_2\circ f_2\circ h_1^{-1}$, making use of theorem $\textbf{5.3.2}$ we have  the following equivalences. $$\Leftrightarrow h_2\circ f_1\circ h_1^{-1} = h_2\circ f_2\circ h_1^{-1}$$ $$\Leftrightarrow h_2\circ f_1\circ (h_1^{-1}\circ h_1) = h_2\circ f_2\circ (h_1^{-1}\circ h_1)$$ $$\Leftrightarrow h_2\circ f_1\circ i_A = h_2\circ f_2\circ i_A$$ $$\Leftrightarrow h_2\circ f_1= h_2\circ f_2$$ $$\Leftrightarrow (h_2^{-1}\circ h_2)\circ f_1= (h_2^{-1}\circ h_2)\circ f_2$$ $$\Leftrightarrow i_C\circ f_1 = i_C\circ f_2$$ $$\Leftrightarrow f_1 = f_2$$ Since our choice of $f_1$ and $f_2$ was arbitrary it follows that $\mathcal{Z}(f)$ is one-to-one . Now let $g$ be an arbitrary function in $^B{D}$ and consider the function $f = h_2^{-1}\circ g\circ h_1$ consequently we see that $\mathcal{Z}(f) = h_2\circ(h_2^{-1}\circ g\circ h_1)\circ h_1^{-1}$ using associativity of function composition in conjunction with theorem $\textbf{5.3.2}$ we have the following equivalences. $$\Leftrightarrow (h_2\circ h_2^{-1})\circ g\circ (h_1 \circ h_1^{-1})$$ $$\Leftrightarrow i_D \circ g\circ i_B$$ $$\Leftrightarrow (i_D \circ g)\circ i_B$$ $$\Leftrightarrow g\circ i_B$$ $$\Leftrightarrow g$$ Thus $\mathcal{Z}(f) = g$, since our choice of $g$ was arbitrary it follows that $\mathcal{Z}$ is onto . With this we have established that $\mathcal{Z}$ is a bijection from $^{A}C$ to $^{B}D$ consequently $^{A}C\thicksim$ $^{B}D$.","Is the following proof Correct? SOME PRELIMARY NOTATION $A\thicksim B\Leftrightarrow$ There is a bijection from A to B $5.3.2$ - if $f:A\to B$ and $f^{-1}:B\to A$ then $f\circ f^{-1} = i_B = \{(x,x)| x\in B\}$ and $f\circ f^{-1} =i_A=\{(y,y)|y\in A\}$ Theorem. For any sets $A$ and $B$ let $^{A}B$ denote the set of all functions from $A$ to $B$. If $A\thicksim B$ and $C\thicksim D$, then $^{A}C\thicksim$ $^{B}D$. Proof. Assume that $A\thicksim B$ and $C\thicksim D$ consequently we invoke the existence $h_1:A\to B$ and $h_2:C\to D$ such that $h_1$ is a bijection from $A$ to $B$ and $h_2$ is a bijection from $C$ to $D$. We know define the the function $\mathcal{Z}:^{A}C\to$ $^{B}D$ and show that is a bijection from $^{A}C$ to $^{B}D$. $$\mathcal{Z}(f) = h_2\circ f\circ h_1^{-1}$$ Now let $f_1$ and $f_2$ be arbitrary functions in $^{A}C$ and assume that $\mathcal{Z}(f_1) = \mathcal{Z}(f_2)$ consequently $h_2\circ f_1\circ h_1^{-1} = h_2\circ f_2\circ h_1^{-1}$, making use of theorem $\textbf{5.3.2}$ we have  the following equivalences. $$\Leftrightarrow h_2\circ f_1\circ h_1^{-1} = h_2\circ f_2\circ h_1^{-1}$$ $$\Leftrightarrow h_2\circ f_1\circ (h_1^{-1}\circ h_1) = h_2\circ f_2\circ (h_1^{-1}\circ h_1)$$ $$\Leftrightarrow h_2\circ f_1\circ i_A = h_2\circ f_2\circ i_A$$ $$\Leftrightarrow h_2\circ f_1= h_2\circ f_2$$ $$\Leftrightarrow (h_2^{-1}\circ h_2)\circ f_1= (h_2^{-1}\circ h_2)\circ f_2$$ $$\Leftrightarrow i_C\circ f_1 = i_C\circ f_2$$ $$\Leftrightarrow f_1 = f_2$$ Since our choice of $f_1$ and $f_2$ was arbitrary it follows that $\mathcal{Z}(f)$ is one-to-one . Now let $g$ be an arbitrary function in $^B{D}$ and consider the function $f = h_2^{-1}\circ g\circ h_1$ consequently we see that $\mathcal{Z}(f) = h_2\circ(h_2^{-1}\circ g\circ h_1)\circ h_1^{-1}$ using associativity of function composition in conjunction with theorem $\textbf{5.3.2}$ we have the following equivalences. $$\Leftrightarrow (h_2\circ h_2^{-1})\circ g\circ (h_1 \circ h_1^{-1})$$ $$\Leftrightarrow i_D \circ g\circ i_B$$ $$\Leftrightarrow (i_D \circ g)\circ i_B$$ $$\Leftrightarrow g\circ i_B$$ $$\Leftrightarrow g$$ Thus $\mathcal{Z}(f) = g$, since our choice of $g$ was arbitrary it follows that $\mathcal{Z}$ is onto . With this we have established that $\mathcal{Z}$ is a bijection from $^{A}C$ to $^{B}D$ consequently $^{A}C\thicksim$ $^{B}D$.",,"['elementary-set-theory', 'proof-verification']"
8,(Another) Alternative Proof to Baby Rudin 2.8,(Another) Alternative Proof to Baby Rudin 2.8,,"Theorem: Every infinite subset of a countable subset A is countable. (Note: below A is the subset of B) I try to do the proofs on my own before reading Rudin's. Sometimes I fail heroically, sometimes comically. I can't see why I failed here, if I did. Consider any $A\subset B$ where $B$ is countable. Assume for contradiction that $A$ is uncountable. Then, by definition, $\exists \alpha\in A : \nexists f(\alpha)\mapsto j\in J= \mathbb{Z}$. Because $B$ is countable, for $\forall\beta\in B, \exists j\in J$ and $\exists g:g(\beta)\mapsto j$ but this is a contradction because $\alpha\in A\subset B$. edit: After a bunch of really unnecessary insults and vagueness, I see that the error is in my taking A from uncountable to there being no map onto Z. Thank you for everyone who (finally) helped me see that. It would have been very simple to point that out and explain it without all of the extracurriculars. Also, I guess the re-tagging on this is OK, but it is literally in a book on analysis in a chapter called basic topology, so I'm not sure why my initial tags were wrong.","Theorem: Every infinite subset of a countable subset A is countable. (Note: below A is the subset of B) I try to do the proofs on my own before reading Rudin's. Sometimes I fail heroically, sometimes comically. I can't see why I failed here, if I did. Consider any $A\subset B$ where $B$ is countable. Assume for contradiction that $A$ is uncountable. Then, by definition, $\exists \alpha\in A : \nexists f(\alpha)\mapsto j\in J= \mathbb{Z}$. Because $B$ is countable, for $\forall\beta\in B, \exists j\in J$ and $\exists g:g(\beta)\mapsto j$ but this is a contradction because $\alpha\in A\subset B$. edit: After a bunch of really unnecessary insults and vagueness, I see that the error is in my taking A from uncountable to there being no map onto Z. Thank you for everyone who (finally) helped me see that. It would have been very simple to point that out and explain it without all of the extracurriculars. Also, I guess the re-tagging on this is OK, but it is literally in a book on analysis in a chapter called basic topology, so I'm not sure why my initial tags were wrong.",,['elementary-set-theory']
9,A supermodular game is superadditive. But is a superadditive game is supermodular?,A supermodular game is superadditive. But is a superadditive game is supermodular?,,"I came across a presentation by Mohammad T. Hajiaghayi from University of Maryland, where he talks about Coalition Game Theory, and he states that ""every super-additive game is a convex game"". He also states that, $ \lbrace \text{Additive games} \rbrace \subseteq \lbrace \text{Super-additive games} \rbrace \subseteq \lbrace \text{Convex games} \rbrace $. Now I don't quite get it. Where I can easily prove that a convex or supermodular game is super-additive, I can't prove the converse. Definitions: A game $G = (N, v)$ with $v(\varnothing) = 0$ is convex (supermodular) if for all $S,T \subseteq N$, $$v(S \cup T) + v(S \cap T) \geq v(S) + v(T)$$ Also is a superadditive game if for all $S,T \subseteq N$, if $S \cap T = \varnothing$, $$v (S \cup T) \geq v (S) + v (T)$$","I came across a presentation by Mohammad T. Hajiaghayi from University of Maryland, where he talks about Coalition Game Theory, and he states that ""every super-additive game is a convex game"". He also states that, $ \lbrace \text{Additive games} \rbrace \subseteq \lbrace \text{Super-additive games} \rbrace \subseteq \lbrace \text{Convex games} \rbrace $. Now I don't quite get it. Where I can easily prove that a convex or supermodular game is super-additive, I can't prove the converse. Definitions: A game $G = (N, v)$ with $v(\varnothing) = 0$ is convex (supermodular) if for all $S,T \subseteq N$, $$v(S \cup T) + v(S \cap T) \geq v(S) + v(T)$$ Also is a superadditive game if for all $S,T \subseteq N$, if $S \cap T = \varnothing$, $$v (S \cup T) \geq v (S) + v (T)$$",,"['elementary-set-theory', 'game-theory']"
10,"Using only logical symbols and $\in$, and $=$ translate into first-order logic: ""$A$ is the power set of $B$""","Using only logical symbols and , and  translate into first-order logic: "" is the power set of """,\in = A B,"Using only logical symbols and $\in$, and $=$ translate into first-order logic: ""$A$ is the power set of $B$"" I've attempted to solve this, but I am not sure whether my solution contains no errors. I'd be glad if you gave me some kind of feedback. $$(\forall x)(x\in A \Rightarrow ((\forall y)(y \in x \Rightarrow y \in B))$$ My reasoning: If $A$ is the power set of $B$ then every element $x$ of $A$ will be a subset of $B$, and so any object in $x$ will also be in $B$.","Using only logical symbols and $\in$, and $=$ translate into first-order logic: ""$A$ is the power set of $B$"" I've attempted to solve this, but I am not sure whether my solution contains no errors. I'd be glad if you gave me some kind of feedback. $$(\forall x)(x\in A \Rightarrow ((\forall y)(y \in x \Rightarrow y \in B))$$ My reasoning: If $A$ is the power set of $B$ then every element $x$ of $A$ will be a subset of $B$, and so any object in $x$ will also be in $B$.",,"['elementary-set-theory', 'logic', 'propositional-calculus', 'logic-translation']"
11,Prove: the union of all n-tuples is countable,Prove: the union of all n-tuples is countable,,"Prove: $\mathbb N^*=\bigcup_{n\in \mathbb N} \mathbb N^n$ is countable. My idea is to show this for $\mathbb N^2$ first, which is not difficult. After this I say, that every tuple, could be reduced to a 2-tuple: $(n_1,n_2,n_3,n_4) \mapsto ((n_1,n_2),n_3,n_4)$, $((n_1,n_2),n_3,n_4) \mapsto (((n_1,n_2),n_3),n_4)$ and so on. Can I do this? If yes, is it formally correct? If not, does someone has hints?","Prove: $\mathbb N^*=\bigcup_{n\in \mathbb N} \mathbb N^n$ is countable. My idea is to show this for $\mathbb N^2$ first, which is not difficult. After this I say, that every tuple, could be reduced to a 2-tuple: $(n_1,n_2,n_3,n_4) \mapsto ((n_1,n_2),n_3,n_4)$, $((n_1,n_2),n_3,n_4) \mapsto (((n_1,n_2),n_3),n_4)$ and so on. Can I do this? If yes, is it formally correct? If not, does someone has hints?",,"['real-analysis', 'elementary-set-theory']"
12,"If the empty set is a subset of all sets, why isn't it a member of every subset of a power set?","If the empty set is a subset of all sets, why isn't it a member of every subset of a power set?",,"If $s=\{1,2\}$, then we say that $P(s) = \{\{\},\{1\},\{2\},\{1,2\}\}$. But the power set is the set of all subsets, of which $\{\}$ is one of them. So why doesn't the power set also include sets such as $\{\{\},1\}$, $\{\{\},2\}$, and $\{\{\},1,2\}$?","If $s=\{1,2\}$, then we say that $P(s) = \{\{\},\{1\},\{2\},\{1,2\}\}$. But the power set is the set of all subsets, of which $\{\}$ is one of them. So why doesn't the power set also include sets such as $\{\{\},1\}$, $\{\{\},2\}$, and $\{\{\},1,2\}$?",,['elementary-set-theory']
13,Prove that no uncountable family of subsets of $\mathbb{N}$ is well-ordered by relation of inclusion.,Prove that no uncountable family of subsets of  is well-ordered by relation of inclusion.,\mathbb{N},"Prove that no uncountable family of subsets of $\mathbb{N}$ is well-ordered by relation of inclusion. I had two ideas how to do it. First was to show that if such family is uncountable, then it is not true that all proper beginning segment (is it correct english name for that?) is of the form $O(x)=\{y:y<x\}$ for some $x$. Another idea was to assume that $(A,\subseteq)$ is such well-order. There are $a,b\in A, a\subset b$, such that between $a$ and $b$ there are uncountably many elements. Let's take subset $B$ which contains $a,b$ and all elements between them. Let's define sequence $z_n$, where $z_0=b$ and $z_{n+1}$ is element of set $\{x\in B:x<z_n$ and there are uncountably many elements between $a$ and $x\}$. By axiom of choice such sequence exists. Let's define $C=\{z_n:n\in\mathbb N\}$. Of course $C\subset A$ and $C$ does not contain minimal element. Therefore $(A,\subseteq)$ is not well-order. Is it correct?","Prove that no uncountable family of subsets of $\mathbb{N}$ is well-ordered by relation of inclusion. I had two ideas how to do it. First was to show that if such family is uncountable, then it is not true that all proper beginning segment (is it correct english name for that?) is of the form $O(x)=\{y:y<x\}$ for some $x$. Another idea was to assume that $(A,\subseteq)$ is such well-order. There are $a,b\in A, a\subset b$, such that between $a$ and $b$ there are uncountably many elements. Let's take subset $B$ which contains $a,b$ and all elements between them. Let's define sequence $z_n$, where $z_0=b$ and $z_{n+1}$ is element of set $\{x\in B:x<z_n$ and there are uncountably many elements between $a$ and $x\}$. By axiom of choice such sequence exists. Let's define $C=\{z_n:n\in\mathbb N\}$. Of course $C\subset A$ and $C$ does not contain minimal element. Therefore $(A,\subseteq)$ is not well-order. Is it correct?",,"['elementary-set-theory', 'order-theory']"
14,"Prove $ |A \cup B| = |[0,1]| \Rightarrow |A|=|[0,1]| \bigvee |B|=|[0,1]| $",Prove," |A \cup B| = |[0,1]| \Rightarrow |A|=|[0,1]| \bigvee |B|=|[0,1]| ","I've tried the argument by contradiction, but did not succeed. Intuitively I understand that union of less-than-continuum sets cannot equal to $|\mathbb{R}|$. I'm curious what a formal proof could be.","I've tried the argument by contradiction, but did not succeed. Intuitively I understand that union of less-than-continuum sets cannot equal to $|\mathbb{R}|$. I'm curious what a formal proof could be.",,"['elementary-set-theory', 'cardinals']"
15,Finding Finite vs. Infinite Interections,Finding Finite vs. Infinite Interections,,"T/F: Let $A_n$ = $(0, \frac{1}{n})$ (a bounded set), and $B_n$ = [$n, \infty)$ (a closed set). Any finite intersection of $A_n$'s and $B_n$'s is non-empty, but the infinite intersection of $A_n$'s and $B_n$'s is empty. I think the answer is true, but my logic behind it is a bit iffy. Does it involve limits? This is my reasoning: As $n \rightarrow k$, where $k$ is some finite number, then $(0, \frac{1}{k})$ and $B_n$ = [$k, \infty)$ have finitely many numbers in it. So, we have a finite intersection of finite numbers, which makes it non-empty. On the other hand, As $n \rightarrow \infty$, then $(0, \frac{1}{\infty})$ and $B_n$ = [$\infty, \infty)$, then they're approaching ""emptiness""? I can't really grasp the ideas behind these finite/infinite intersections, so any clarification would be tremendously helpful. Thank you.","T/F: Let $A_n$ = $(0, \frac{1}{n})$ (a bounded set), and $B_n$ = [$n, \infty)$ (a closed set). Any finite intersection of $A_n$'s and $B_n$'s is non-empty, but the infinite intersection of $A_n$'s and $B_n$'s is empty. I think the answer is true, but my logic behind it is a bit iffy. Does it involve limits? This is my reasoning: As $n \rightarrow k$, where $k$ is some finite number, then $(0, \frac{1}{k})$ and $B_n$ = [$k, \infty)$ have finitely many numbers in it. So, we have a finite intersection of finite numbers, which makes it non-empty. On the other hand, As $n \rightarrow \infty$, then $(0, \frac{1}{\infty})$ and $B_n$ = [$\infty, \infty)$, then they're approaching ""emptiness""? I can't really grasp the ideas behind these finite/infinite intersections, so any clarification would be tremendously helpful. Thank you.",,"['real-analysis', 'general-topology', 'elementary-set-theory']"
16,Image of the union is the union of the images,Image of the union is the union of the images,,"$$ f\left(\bigcup\limits_{\lambda \in \wedge} A_{\lambda}\right) = \bigcup\limits_{\lambda \in \wedge} f(A_\lambda)$$ Let $b \in f(\bigcup\limits_{\lambda \in \wedge} A_{\lambda})$ $\rightarrow b=f(a)$ for some $a \in (\bigcup\limits_{\lambda \in \wedge} A_{\lambda})$. Since $a \in (\bigcup\limits_{\lambda \in \wedge} A_{\lambda}) \rightarrow a \in A_{\lambda}$ for some $\lambda \in \wedge$. Since $b=f(a)$, then $b \in f(A_{\lambda})$ for some $\lambda \in \wedge$. $\rightarrow b \in \bigcup\limits_{\lambda \in \wedge} f(A_\lambda)$ $\rightarrow f(\bigcup\limits_{\lambda \in \wedge} A_{\lambda}) \subset \bigcup\limits_{\lambda \in \wedge} f(A_\lambda)$. I used a similar argument to prove $\bigcup\limits_{\lambda \in \wedge} f(A_\lambda) \subset f(\bigcup\limits_{\lambda \in \wedge} A_{\lambda})$. Which shows $ f(\bigcup\limits_{\lambda \in \wedge} A_{\lambda}) = \bigcup\limits_{\lambda \in \wedge} f(A_\lambda)$. Please let me know if this is valid.","$$ f\left(\bigcup\limits_{\lambda \in \wedge} A_{\lambda}\right) = \bigcup\limits_{\lambda \in \wedge} f(A_\lambda)$$ Let $b \in f(\bigcup\limits_{\lambda \in \wedge} A_{\lambda})$ $\rightarrow b=f(a)$ for some $a \in (\bigcup\limits_{\lambda \in \wedge} A_{\lambda})$. Since $a \in (\bigcup\limits_{\lambda \in \wedge} A_{\lambda}) \rightarrow a \in A_{\lambda}$ for some $\lambda \in \wedge$. Since $b=f(a)$, then $b \in f(A_{\lambda})$ for some $\lambda \in \wedge$. $\rightarrow b \in \bigcup\limits_{\lambda \in \wedge} f(A_\lambda)$ $\rightarrow f(\bigcup\limits_{\lambda \in \wedge} A_{\lambda}) \subset \bigcup\limits_{\lambda \in \wedge} f(A_\lambda)$. I used a similar argument to prove $\bigcup\limits_{\lambda \in \wedge} f(A_\lambda) \subset f(\bigcup\limits_{\lambda \in \wedge} A_{\lambda})$. Which shows $ f(\bigcup\limits_{\lambda \in \wedge} A_{\lambda}) = \bigcup\limits_{\lambda \in \wedge} f(A_\lambda)$. Please let me know if this is valid.",,"['elementary-set-theory', 'proof-verification']"
17,How many similar disjoint drawings can be done in $\mathbb{R}^2$?,How many similar disjoint drawings can be done in ?,\mathbb{R}^2,"Long ago I encounter the following question: How many disjoint similar $0$'s can be drawn in $\mathbb{R}^2$? Answer is simple, it just suffices to draw $0$'s centered at the origin making them with increasing diameter over the real numbers. They all are disjoint and there are not enumerable ones of them. How many disjoint similar $8$'s can be drawn in $\mathbb{R}^2$? This case is more interesting. Every disjoint $8$ can be uniquely mapped to a pair of elements in $\mathbb{Q}^2$, where the first one is in the upper half of the $8$ and the second one in the lower half. There are only enumerable of those. A similar technique could be used to proof that there are enumerable $X$'s or $H$'s. However, I cannot figure out the condition that the letter (or drawing) must have in order for its disjoint similar drawings to be enumerable in $\mathbb{R}^2$. I have been thinking about this with letters and numbers, but I am sure it can be generalized to more interesting (even discontinuous) figures and more interesting deformations of the figure than just rotating or increasing its size maintaining its proportions.","Long ago I encounter the following question: How many disjoint similar $0$'s can be drawn in $\mathbb{R}^2$? Answer is simple, it just suffices to draw $0$'s centered at the origin making them with increasing diameter over the real numbers. They all are disjoint and there are not enumerable ones of them. How many disjoint similar $8$'s can be drawn in $\mathbb{R}^2$? This case is more interesting. Every disjoint $8$ can be uniquely mapped to a pair of elements in $\mathbb{Q}^2$, where the first one is in the upper half of the $8$ and the second one in the lower half. There are only enumerable of those. A similar technique could be used to proof that there are enumerable $X$'s or $H$'s. However, I cannot figure out the condition that the letter (or drawing) must have in order for its disjoint similar drawings to be enumerable in $\mathbb{R}^2$. I have been thinking about this with letters and numbers, but I am sure it can be generalized to more interesting (even discontinuous) figures and more interesting deformations of the figure than just rotating or increasing its size maintaining its proportions.",,"['combinatorics', 'general-topology', 'geometry', 'elementary-set-theory', 'real-numbers']"
18,"Suppose $A$, $B$, and $C$ are sets. Prove that $C ⊆ A △ B$ iff $C ⊆ A ∪ B$ and $A ∩ B ∩ C = ∅$.","Suppose , , and  are sets. Prove that  iff  and .",A B C C ⊆ A △ B C ⊆ A ∪ B A ∩ B ∩ C = ∅,"This is Velleman's exercise 3.5.21 ( And NO, not a duplicate of "" Suppose $A, B$, and C are sets. Prove that $C\subset A\Delta B \Leftrightarrow C \subset A \cup B$ and $A \cap B \cap C = \emptyset $ "", my question is different ): Suppose $A$, $B$, and $C$ are sets. Prove that $C \subseteq A\,\triangle\,B$ iff $C \subseteq A \cup B$ and $A \cap B \cap C = \emptyset$. And here's my proof of it: Proof. ($\rightarrow$) Suppose $C ⊆ A △ B$ and let $x$ be an arbitrary element of $C$, then we have  $x ∈ A △ B$. We now consider two cases: Case 1. $x ∈ A\setminus B$, which means $x ∈ A$ but $x ∉ B$. Thus $x ∈ A ∪ B$. Case 2. $x ∈ B\setminus A$, which means $x ∈ B$ but $x ∉ A$. Thus $x ∈ A ∪ B$. Now suppose $A ∩ B ∩ C \neq ∅$. From $x ∈ A △ B$ we have that either $x ∉ A$ or $x ∉ B$ which in either case is a contradiction and hence $A ∩ B ∩ C = ∅$. We have $x ∈ A ∪ B$ and $A ∩ B ∩ C = ∅$ and therefore, if $C ⊆ A △ B$, then $C ⊆ A ∪ B$ and $A ∩ B ∩ C = ∅$. ($\leftarrow$) Suppose $C ⊆ A ∪ B$ and $A ∩ B ∩ C = ∅$ and let $x$ be an arbitrary element of $C$. We now have two different cases to consider: Case 1. $x ∈ B\setminus A$, then clearly $x ∈ A △ B$. Case 2. $x ∉ B\setminus A$, which means $x ∈ A$ but $x ∉ B$. Since $A ∩ B ∩ C = ∅$ is equivalent to $∀x(x ∈ A \Rightarrow (x ∈ C \Rightarrow x ∉ B))$, then by $x ∈ A$ we have $(x ∈ C \Rightarrow x ∉ B)$. Since we had $x ∈ C$, then $x ∉ B$ and then $x ∈ A\setminus B$. Ergo $x ∈ A △ B$. From both case we have $x ∈ A △ B$. Since $x$ was arbitrary, $C ⊆ A △ B$ and therefore, if $C ⊆ A ∪ B$ and $A ∩ B ∩ C = ∅$, then $C ⊆ A △ B$. By ($\rightarrow$) and ($\leftarrow$) we have $C ⊆ A △ B$ iff $C ⊆ A ∪ B$ and $A ∩ B ∩ C = ∅$. Now here are my questions: Is my proof valid? In part one (i.e. ($\rightarrow$)), is there anything wrong with the proof of $A ∩ B ∩ C = ∅$? In part two (i.e. ($\leftarrow$)), the second case seems to be a little redundant to me! Is that correct (i.e. is my proof of it correct)? Thanks in advance.","This is Velleman's exercise 3.5.21 ( And NO, not a duplicate of "" Suppose $A, B$, and C are sets. Prove that $C\subset A\Delta B \Leftrightarrow C \subset A \cup B$ and $A \cap B \cap C = \emptyset $ "", my question is different ): Suppose $A$, $B$, and $C$ are sets. Prove that $C \subseteq A\,\triangle\,B$ iff $C \subseteq A \cup B$ and $A \cap B \cap C = \emptyset$. And here's my proof of it: Proof. ($\rightarrow$) Suppose $C ⊆ A △ B$ and let $x$ be an arbitrary element of $C$, then we have  $x ∈ A △ B$. We now consider two cases: Case 1. $x ∈ A\setminus B$, which means $x ∈ A$ but $x ∉ B$. Thus $x ∈ A ∪ B$. Case 2. $x ∈ B\setminus A$, which means $x ∈ B$ but $x ∉ A$. Thus $x ∈ A ∪ B$. Now suppose $A ∩ B ∩ C \neq ∅$. From $x ∈ A △ B$ we have that either $x ∉ A$ or $x ∉ B$ which in either case is a contradiction and hence $A ∩ B ∩ C = ∅$. We have $x ∈ A ∪ B$ and $A ∩ B ∩ C = ∅$ and therefore, if $C ⊆ A △ B$, then $C ⊆ A ∪ B$ and $A ∩ B ∩ C = ∅$. ($\leftarrow$) Suppose $C ⊆ A ∪ B$ and $A ∩ B ∩ C = ∅$ and let $x$ be an arbitrary element of $C$. We now have two different cases to consider: Case 1. $x ∈ B\setminus A$, then clearly $x ∈ A △ B$. Case 2. $x ∉ B\setminus A$, which means $x ∈ A$ but $x ∉ B$. Since $A ∩ B ∩ C = ∅$ is equivalent to $∀x(x ∈ A \Rightarrow (x ∈ C \Rightarrow x ∉ B))$, then by $x ∈ A$ we have $(x ∈ C \Rightarrow x ∉ B)$. Since we had $x ∈ C$, then $x ∉ B$ and then $x ∈ A\setminus B$. Ergo $x ∈ A △ B$. From both case we have $x ∈ A △ B$. Since $x$ was arbitrary, $C ⊆ A △ B$ and therefore, if $C ⊆ A ∪ B$ and $A ∩ B ∩ C = ∅$, then $C ⊆ A △ B$. By ($\rightarrow$) and ($\leftarrow$) we have $C ⊆ A △ B$ iff $C ⊆ A ∪ B$ and $A ∩ B ∩ C = ∅$. Now here are my questions: Is my proof valid? In part one (i.e. ($\rightarrow$)), is there anything wrong with the proof of $A ∩ B ∩ C = ∅$? In part two (i.e. ($\leftarrow$)), the second case seems to be a little redundant to me! Is that correct (i.e. is my proof of it correct)? Thanks in advance.",,"['elementary-set-theory', 'logic', 'proof-verification']"
19,When is interchange of quantifiers allowed? Ex: $\forall w \in \bigcup A_n$,When is interchange of quantifiers allowed? Ex:,\forall w \in \bigcup A_n,"There is a myriad of question for the interchange of different quantifiers, mainly between $\exists$ and $\forall$. I'm interested in knowing when both can be interchanged. The motivation came from this: $\forall w \in \bigcup_n A_n \Leftrightarrow\forall_{n,w} w \in A_n$, when $w \in \bigcup_n A_n \Leftrightarrow\exists_{n} w \in A_n$. Any help would be appreciated.","There is a myriad of question for the interchange of different quantifiers, mainly between $\exists$ and $\forall$. I'm interested in knowing when both can be interchanged. The motivation came from this: $\forall w \in \bigcup_n A_n \Leftrightarrow\forall_{n,w} w \in A_n$, when $w \in \bigcup_n A_n \Leftrightarrow\exists_{n} w \in A_n$. Any help would be appreciated.",,"['elementary-set-theory', 'logic']"
20,"If $A\approx A', B\approx B'$, then $B^A\approx B'^{A'}$","If , then","A\approx A', B\approx B' B^A\approx B'^{A'}","My attempt: Suppose $A\approx A', B\approx B'$, then there exists bijections $f_A:A\to A',f_B:B \to B'$. We need to show that $B^A\approx B'^{A'}$. That is, there is a bijection from the set $F$ of all functions from $A$ to $B$ to the set $F'$ of functions from $A'$ to $B'$. Define function $g:F\to F'$ as: for each function from $f\in F$, for $f(a)=b$ where $a\in A$ and $b\in B$, $g(f)=f'\in F'$ send $f_A(a)\in A'$ to $f_B(b)\in B'$. But I have trouble proving that the $g$ we defined is a bijection. I think it would be better if we describe $g$ in a more formal way instead of giving a plain sentence. So how may I prove it, or if there is some better way to do that? Thanks. EDIT： Following the hint from the comment. The following is my attempt to define the inverse of $g$. For each function $f'\in F'$. Define $h(f')$ as: for each function $f'$ in $F'$ such that $f'(a')=b'$, $h(f')$ sends $f^{-1}_A(a')$ to $f^{-1}_B(b')$. We can do this because the function $f$ is invertible. I still think in order to prove formally that $h$ and $g$ are inverses of each other, we need to formalize the definition of both of them... So could someone tell me if we could do this? Or is there other way to verify that they are inverses? EDIT': Given $f\colon A\to B$, then the composition $f\circ f_A^{-1}$ is a function from $A'$ to $B$; and if we then compose $f_B$ on top of this we get a function $f_B\circ f\circ f_A^{-1}$ which is indeed from $A'$ to $B'$. Define $g: F\to F'$ as $g(f)=f_B\circ f\circ f_A^{-1}$. We prove that $g$ is a bijection. Suppose $g(f_1)=g(f_2)$, then for every $a'\in A'$ we have that $g(f_1)(a')=g(f_2)(a')$. Thus $f_B\circ f_1\circ f^{-1}_A(a')=f_B\circ f_2\circ f^{-1}_A(a')$. Use the fact that $f_B$ is bijective, we have $f_1(f_A^{-1}(a'))=f_2(f_A^{-1}(a'))$ for all $a'\in A'$. As $f^{-1}_A$ is surjective, $f_1(a)=f_2(a)$ for each $a\in A$ and therefore $f_1=f_2$. For each $f'\in F'$, we need to prove that there exist $f\in F$ such that $g(f)=f'$. For $f'\in F'$, define $f$ as $f^{-1}_B\circ f'\circ f_A$. Thus $f\in F$ and $g(f)=f'$ as desired. This proves $g$ is surjective.","My attempt: Suppose $A\approx A', B\approx B'$, then there exists bijections $f_A:A\to A',f_B:B \to B'$. We need to show that $B^A\approx B'^{A'}$. That is, there is a bijection from the set $F$ of all functions from $A$ to $B$ to the set $F'$ of functions from $A'$ to $B'$. Define function $g:F\to F'$ as: for each function from $f\in F$, for $f(a)=b$ where $a\in A$ and $b\in B$, $g(f)=f'\in F'$ send $f_A(a)\in A'$ to $f_B(b)\in B'$. But I have trouble proving that the $g$ we defined is a bijection. I think it would be better if we describe $g$ in a more formal way instead of giving a plain sentence. So how may I prove it, or if there is some better way to do that? Thanks. EDIT： Following the hint from the comment. The following is my attempt to define the inverse of $g$. For each function $f'\in F'$. Define $h(f')$ as: for each function $f'$ in $F'$ such that $f'(a')=b'$, $h(f')$ sends $f^{-1}_A(a')$ to $f^{-1}_B(b')$. We can do this because the function $f$ is invertible. I still think in order to prove formally that $h$ and $g$ are inverses of each other, we need to formalize the definition of both of them... So could someone tell me if we could do this? Or is there other way to verify that they are inverses? EDIT': Given $f\colon A\to B$, then the composition $f\circ f_A^{-1}$ is a function from $A'$ to $B$; and if we then compose $f_B$ on top of this we get a function $f_B\circ f\circ f_A^{-1}$ which is indeed from $A'$ to $B'$. Define $g: F\to F'$ as $g(f)=f_B\circ f\circ f_A^{-1}$. We prove that $g$ is a bijection. Suppose $g(f_1)=g(f_2)$, then for every $a'\in A'$ we have that $g(f_1)(a')=g(f_2)(a')$. Thus $f_B\circ f_1\circ f^{-1}_A(a')=f_B\circ f_2\circ f^{-1}_A(a')$. Use the fact that $f_B$ is bijective, we have $f_1(f_A^{-1}(a'))=f_2(f_A^{-1}(a'))$ for all $a'\in A'$. As $f^{-1}_A$ is surjective, $f_1(a)=f_2(a)$ for each $a\in A$ and therefore $f_1=f_2$. For each $f'\in F'$, we need to prove that there exist $f\in F$ such that $g(f)=f'$. For $f'\in F'$, define $f$ as $f^{-1}_B\circ f'\circ f_A$. Thus $f\in F$ and $g(f)=f'$ as desired. This proves $g$ is surjective.",,"['elementary-set-theory', 'cardinals']"
21,Partitions of $\mathbb Z$,Partitions of,\mathbb Z,"Question Does there exist a partition of $\mathbb Z$ in three non-empty sets $A,B,C$ such that $A+B, B+C, C+A$ are all pairwise disjoint? Thoughts I'm very new to set theory, so while I grasp the terminology, I can't really solve any problems like this with great confidence. The only thing I've come up with so far is to simply partition $\mathbb Z$ into three segments, but then the pairwise disjoint criteria falls flat.","Question Does there exist a partition of $\mathbb Z$ in three non-empty sets $A,B,C$ such that $A+B, B+C, C+A$ are all pairwise disjoint? Thoughts I'm very new to set theory, so while I grasp the terminology, I can't really solve any problems like this with great confidence. The only thing I've come up with so far is to simply partition $\mathbb Z$ into three segments, but then the pairwise disjoint criteria falls flat.",,['elementary-set-theory']
22,The given relation is not equivalence,The given relation is not equivalence,,"A relation $R$ is defined on the set of integers as follows:  $$(a,b)\in R\iff a^b=b^a$$ Clearly, it is reflexive and symmetric. But I am unable to give a counter example that it is not transitive. Thanks.","A relation $R$ is defined on the set of integers as follows:  $$(a,b)\in R\iff a^b=b^a$$ Clearly, it is reflexive and symmetric. But I am unable to give a counter example that it is not transitive. Thanks.",,"['elementary-set-theory', 'equivalence-relations']"
23,"Prove that For every two sets, only one can be an element of the other","Prove that For every two sets, only one can be an element of the other",,"I'm trying to show that if X $\in$ Y then Y$\notin$X or if $Y\in$X then X$\notin$Y. Here's what I think by wikipedia Let X and Y be sets. Then apply the axiom of regularity to the set {X,Y}. We see there must be an element of {X,Y} which is also disjoint from it. It must be either X or Y. By the definition of disjoint then, we must have either Y is not an element of {X,Y} or X is not an element of {X,Y}. Next I think I need to show that if Y $\notin${X,Y}, then Y$\notin$X?","I'm trying to show that if X $\in$ Y then Y$\notin$X or if $Y\in$X then X$\notin$Y. Here's what I think by wikipedia Let X and Y be sets. Then apply the axiom of regularity to the set {X,Y}. We see there must be an element of {X,Y} which is also disjoint from it. It must be either X or Y. By the definition of disjoint then, we must have either Y is not an element of {X,Y} or X is not an element of {X,Y}. Next I think I need to show that if Y $\notin${X,Y}, then Y$\notin$X?",,[]
24,Category theoretic proof that $\mathbb{N}$ is infinite,Category theoretic proof that  is infinite,\mathbb{N},"I have been going through the proof of Theorem 9.4 in ""Sets for Mathematics"" by Lawvere and Rosebrugh, which proves that $1+\mathbb{N} \cong \mathbb{N}$, but I am a little confused over how to prove from that, that the successor map $\sigma:\mathbb{N} \rightarrow \mathbb{N}$ is not surjective, which is the exercise 9.15. I know from corollary 9.6 in the book that $\sigma: \mathbb{N} \to \mathbb{N}$ is injective since the predecessor map $p$ is a retraction for $\sigma$. The definition of infinite is that of Dedekind, i.e. a set $X$ is infinite if there exists an $s:X \to X$ which is injective but not surjective. Now, I though about using proof by contradiction, so that I suppose that $\sigma$ surjective, and get a contradiction from the fact that $\sigma$ surjective implies that $\sigma(n)=0$ for some $n$, but the proof of theorem 9.4 doesn't immediately suggest any relevant angle of attack on the problem. In the proof of 9.4, one proves that $1+\mathbb{N} \cong \mathbb{N}$ by constructing an inverse $g:\mathbb{N} \to 1 + \mathbb{N}$ to the unique $f:1+\mathbb{N} \to \mathbb{N}$ via recursion. $g$ can be shown to satisfy: $$ g(0) = i_\ast$$ $$ g(n+1)=i_\mathbb{N}(n)$$ Where $i_\ast:1 \to 1+\mathbb{N}$ and $i_\mathbb{N}:\mathbb{N} \to 1+\mathbb{N}$ are the injections into $1 + \mathbb{N}$. $1$ denotes the terminal object in the category of sets, and $\mathbb{N}$ is a natural numbers object in the category of sets. All morphisms in the category are supposed to be total functions. Many thanks in advance!","I have been going through the proof of Theorem 9.4 in ""Sets for Mathematics"" by Lawvere and Rosebrugh, which proves that $1+\mathbb{N} \cong \mathbb{N}$, but I am a little confused over how to prove from that, that the successor map $\sigma:\mathbb{N} \rightarrow \mathbb{N}$ is not surjective, which is the exercise 9.15. I know from corollary 9.6 in the book that $\sigma: \mathbb{N} \to \mathbb{N}$ is injective since the predecessor map $p$ is a retraction for $\sigma$. The definition of infinite is that of Dedekind, i.e. a set $X$ is infinite if there exists an $s:X \to X$ which is injective but not surjective. Now, I though about using proof by contradiction, so that I suppose that $\sigma$ surjective, and get a contradiction from the fact that $\sigma$ surjective implies that $\sigma(n)=0$ for some $n$, but the proof of theorem 9.4 doesn't immediately suggest any relevant angle of attack on the problem. In the proof of 9.4, one proves that $1+\mathbb{N} \cong \mathbb{N}$ by constructing an inverse $g:\mathbb{N} \to 1 + \mathbb{N}$ to the unique $f:1+\mathbb{N} \to \mathbb{N}$ via recursion. $g$ can be shown to satisfy: $$ g(0) = i_\ast$$ $$ g(n+1)=i_\mathbb{N}(n)$$ Where $i_\ast:1 \to 1+\mathbb{N}$ and $i_\mathbb{N}:\mathbb{N} \to 1+\mathbb{N}$ are the injections into $1 + \mathbb{N}$. $1$ denotes the terminal object in the category of sets, and $\mathbb{N}$ is a natural numbers object in the category of sets. All morphisms in the category are supposed to be total functions. Many thanks in advance!",,"['elementary-set-theory', 'category-theory']"
25,"Induction, Well-Ordering, and my Failed Proof Attempt","Induction, Well-Ordering, and my Failed Proof Attempt",,"I recognize there are posts already generally on the logical equivalence of induction and the well-ordering principle, however, I'd really appreciate some advice for finding the monster lurking underneath this marsh of poor reasoning. Thanks! Complete induction $\implies$ well-ordering principle Consider a statement $S$ where $S(n)$ states that a given subset of $\mathbb{N}$ with cardinality of $n$ has a least element. Let, for a set $X \subseteq \mathbb{N}$, $|X| = 1$. By the reflexive axiom, $\forall a \in X, a \le a$ so $S(1)$ holds. Now we assume $S(n)$ is true so $|X_{n}| = n$ and $\exists \ a\ \forall \ b\ : (a,b \in X) \implies a \le b$. $S(n+1)$ would state that the well-ordering principle holds for a set $X_n \cup {z}$ where $z$ is a new element. Since the well ordering principle held on $X$, there is a least element of $X$, call it $a$. Now $(z \le a)\vee (z > a) $. If the former is true than $z$ is now the least element. If the latter is true then $a$ is still the least element. Why is this seemingly much more obvious ""solution"" wrong? I have a gut feeling this has something to do with considering arbitrary elements of the power-set of $\mathbb{N}$ - which is uncountably infinite - and forming a bijection from $\mathbb{N}$ to these subsets of $P(\mathbb{N})$.","I recognize there are posts already generally on the logical equivalence of induction and the well-ordering principle, however, I'd really appreciate some advice for finding the monster lurking underneath this marsh of poor reasoning. Thanks! Complete induction $\implies$ well-ordering principle Consider a statement $S$ where $S(n)$ states that a given subset of $\mathbb{N}$ with cardinality of $n$ has a least element. Let, for a set $X \subseteq \mathbb{N}$, $|X| = 1$. By the reflexive axiom, $\forall a \in X, a \le a$ so $S(1)$ holds. Now we assume $S(n)$ is true so $|X_{n}| = n$ and $\exists \ a\ \forall \ b\ : (a,b \in X) \implies a \le b$. $S(n+1)$ would state that the well-ordering principle holds for a set $X_n \cup {z}$ where $z$ is a new element. Since the well ordering principle held on $X$, there is a least element of $X$, call it $a$. Now $(z \le a)\vee (z > a) $. If the former is true than $z$ is now the least element. If the latter is true then $a$ is still the least element. Why is this seemingly much more obvious ""solution"" wrong? I have a gut feeling this has something to do with considering arbitrary elements of the power-set of $\mathbb{N}$ - which is uncountably infinite - and forming a bijection from $\mathbb{N}$ to these subsets of $P(\mathbb{N})$.",,"['elementary-set-theory', 'proof-writing', 'induction']"
26,What are Parameters in Set Theory,What are Parameters in Set Theory,,"I'm totally lost about what parameters are in Set Theory. I've been looking through a bunch of books but none explicitly state what they are, only how they are used in formulas to make sets. Can someone please explain this idea?","I'm totally lost about what parameters are in Set Theory. I've been looking through a bunch of books but none explicitly state what they are, only how they are used in formulas to make sets. Can someone please explain this idea?",,"['elementary-set-theory', 'intuition']"
27,Proving equality of sets,Proving equality of sets,,How do I prove the following equations (I am new to statistics and not sure where to begin even after trying to figure it out): (a) $A - B = A - A \cap B = A \cup B - B$ (b) $A \mathbin{\Delta} B = A \cup B - A \cap B$,How do I prove the following equations (I am new to statistics and not sure where to begin even after trying to figure it out): (a) $A - B = A - A \cap B = A \cup B - B$ (b) $A \mathbin{\Delta} B = A \cup B - A \cap B$,,"['elementary-set-theory', 'logic']"
28,Set Theory Contradiction Proof Verification,Set Theory Contradiction Proof Verification,,"Let A, B and C be subsets of a universal set U. Prove by contradiction that $$A\cap B \subseteq C \to (A-C)\cap B = \emptyset$$ Suppose otherwise, $A\cap B\subseteq C \land (A-C)\cap B \neq \emptyset$.  Let $n\in A$, then by definition of the subset, $n\in C$. Since $n\in A \land n\in C, n\not \in (A-C)$, by definition of the set difference, this means $(A-C)= \emptyset$. Therefor, $n\not \in (A-C)\cap B$, by definition of the intersection. Thus, by definition of the empty set, $(A-C)\cap B = \emptyset$. This is a contradiction. Thus, $A\cap B \subseteq C \to (A-C)\cap B = \emptyset$ must be true. Can someone tell me whether I did this right. I think it makes sense, but it also seems like I made a mistake somewhere because it seems too easy and short. Thank you.","Let A, B and C be subsets of a universal set U. Prove by contradiction that $$A\cap B \subseteq C \to (A-C)\cap B = \emptyset$$ Suppose otherwise, $A\cap B\subseteq C \land (A-C)\cap B \neq \emptyset$.  Let $n\in A$, then by definition of the subset, $n\in C$. Since $n\in A \land n\in C, n\not \in (A-C)$, by definition of the set difference, this means $(A-C)= \emptyset$. Therefor, $n\not \in (A-C)\cap B$, by definition of the intersection. Thus, by definition of the empty set, $(A-C)\cap B = \emptyset$. This is a contradiction. Thus, $A\cap B \subseteq C \to (A-C)\cap B = \emptyset$ must be true. Can someone tell me whether I did this right. I think it makes sense, but it also seems like I made a mistake somewhere because it seems too easy and short. Thank you.",,"['elementary-set-theory', 'proof-verification', 'proof-writing']"
29,"If $\bigcup\{A_\alpha \,:\, \alpha \in\Lambda\} \ne \emptyset$, then for each $\beta \in\Lambda$, $A_\beta \ne\emptyset$","If , then for each ,","\bigcup\{A_\alpha \,:\, \alpha \in\Lambda\} \ne \emptyset \beta \in\Lambda A_\beta \ne\emptyset","Prove or disprove , where $A$ , $B$ are sets: a)Let $\{A_\alpha\, :\, \alpha \in \Lambda\}$ be an indexed collection of sets. If $\bigcup\{A_\alpha \,:\, \alpha \in\Lambda\} \ne \emptyset$ , then for each $\beta \in\Lambda$ , $A_\beta \ne\emptyset$ . b) $A \subseteq (B \setminus A)$ if and only if $A = \emptyset$ . For (a) , I think it is false: let $A_1=\{1,2\}$ , and $A_2=\emptyset$ , $A_3=\{5\}$ So, $A_1 \cup A_2 \cup A_3 =\{1,2,5\}$ For (b) , I think it is true , and I know how I can prove it. Could you please check these for me?","Prove or disprove , where , are sets: a)Let be an indexed collection of sets. If , then for each , . b) if and only if . For (a) , I think it is false: let , and , So, For (b) , I think it is true , and I know how I can prove it. Could you please check these for me?","A B \{A_\alpha\, :\, \alpha \in \Lambda\} \bigcup\{A_\alpha \,:\, \alpha \in\Lambda\} \ne \emptyset \beta \in\Lambda A_\beta \ne\emptyset A \subseteq (B \setminus A) A = \emptyset A_1=\{1,2\} A_2=\emptyset A_3=\{5\} A_1 \cup A_2 \cup A_3 =\{1,2,5\}","['elementary-set-theory', 'logic', 'proof-writing']"
30,Prove $(A\times C)\setminus (B\times D)=(A\times (C\setminus D))\cup((A\setminus B)\times C)$,Prove,(A\times C)\setminus (B\times D)=(A\times (C\setminus D))\cup((A\setminus B)\times C),"Given $A,B\subseteq X$ and $C,D\subseteq Y$, prove $(A\times C)\setminus (B\times D)=(A\times (C\setminus D))\cup((A\setminus B)\times C)$. My attempt: $$(A\times C)\setminus (B\times D)$$ $$(x,y)\in (A\times C) \wedge (x,y)\notin (B\times D)$$ $$(x\in A \wedge y\in C)\wedge (x\notin B \wedge y\notin D)$$ $$(x\in A \wedge y \in C \wedge y \notin D)\wedge (x\in A \wedge y\in C \wedge x\notin B)$$ $$(x\in A \wedge (y \in C \wedge y \notin D))\wedge ((x\in A \wedge x\notin B) \wedge y\in C)$$ $$(x\in A \wedge y\in (C\setminus D))\wedge (x\in (A\setminus B) \wedge y\in C)$$ $$(x,y)\in (A \times (C\setminus D))\wedge (x,y)\in ((A\setminus B)\times C)$$ $$(A\times (C\setminus D))\cup((A\setminus B)\times C)$$ Is that a valid proof? Are the rules I applied for the logic operator correct? How could I simplify the proof or find another way to do it?","Given $A,B\subseteq X$ and $C,D\subseteq Y$, prove $(A\times C)\setminus (B\times D)=(A\times (C\setminus D))\cup((A\setminus B)\times C)$. My attempt: $$(A\times C)\setminus (B\times D)$$ $$(x,y)\in (A\times C) \wedge (x,y)\notin (B\times D)$$ $$(x\in A \wedge y\in C)\wedge (x\notin B \wedge y\notin D)$$ $$(x\in A \wedge y \in C \wedge y \notin D)\wedge (x\in A \wedge y\in C \wedge x\notin B)$$ $$(x\in A \wedge (y \in C \wedge y \notin D))\wedge ((x\in A \wedge x\notin B) \wedge y\in C)$$ $$(x\in A \wedge y\in (C\setminus D))\wedge (x\in (A\setminus B) \wedge y\in C)$$ $$(x,y)\in (A \times (C\setminus D))\wedge (x,y)\in ((A\setminus B)\times C)$$ $$(A\times (C\setminus D))\cup((A\setminus B)\times C)$$ Is that a valid proof? Are the rules I applied for the logic operator correct? How could I simplify the proof or find another way to do it?",,"['elementary-set-theory', 'proof-verification', 'proof-explanation', 'alternative-proof']"
31,Need help for proving: $f(f^{−1}(A)) ⊆ A$. [duplicate],Need help for proving: . [duplicate],f(f^{−1}(A)) ⊆ A,This question already has answers here : Need help for proving that: $f(f^{-1}(A)) ⊆ A$ (4 answers) Closed 7 years ago . Informations: $f:X \longrightarrow X$ and $A \subseteq X$. How can i prove this statement: $f(f^{-1}(A)) \subseteq A$ This is my thoughts until now: $f^1(A)=\{x\in X |f(x)\in A\} \subseteq X$. $f(A)=\{f(x)|x\in A\}$ $f(f^1(A))=\{y\in A:\exists \in f^1(A):y=f(x)\} \in A$,This question already has answers here : Need help for proving that: $f(f^{-1}(A)) ⊆ A$ (4 answers) Closed 7 years ago . Informations: $f:X \longrightarrow X$ and $A \subseteq X$. How can i prove this statement: $f(f^{-1}(A)) \subseteq A$ This is my thoughts until now: $f^1(A)=\{x\in X |f(x)\in A\} \subseteq X$. $f(A)=\{f(x)|x\in A\}$ $f(f^1(A))=\{y\in A:\exists \in f^1(A):y=f(x)\} \in A$,,['elementary-set-theory']
32,Help with my proof that the union of two countably infinite sets is countably infinite,Help with my proof that the union of two countably infinite sets is countably infinite,,"Let $A, B$ be countably infinite sets. Prove that the union of $A$ and $B$ is also countably infinite. I'm aware that this question already exists on stack exchange, but I'm trying it a different way and am having difficulty finishing it. Let the union of $A$ and $B$ be denoted by $C$. For $C$ to be countably infinite, we need to find a bijection between $C$ and the natural numbers. Let $f(n)$ be the bijective function mapping the natural numbers to $A$, and $g(n)$ be the bijective function mapping the natural numbers to $B$. Define $h(n)$ to be the function mapping the natural numbers to $C$ given by: $$h(2n) = f(n)$$ $$h(2n-1) = g(n)$$ To show that $h(n)$ is bijective, we need to show that it is both surjective and injective. I was able to do the surjective part without problem, but am having trouble proving injectivity. Attempt: if $n_1, n_2$ are even, then $n_j = 2k_j$ for some other natural numbers $k_j$. Thus, $$h(2k_1) = h(2k_2)$$ $$f(k_1) = f(k_2)$$ $$k_1 = k_2$$ since $f(n)$ is bijective. Simlarly, if $n_1, n_2$ are odd, then $n_j = 2k_j - 1$ for some natural numbers $k_j$. So, $$h(2k_1 - 1) = h(2k_2 - 1)$$ $$g(k_1) = g(k_2)$$ $$k_1 = k_2$$ since $g(n)$ is bijective. However, we could also have the case that $n_1$ is even and $n_2$ is odd. Then, $$h(n_1) = h(n_2)$$ $$h(2k_1) = h(2k_2 - 1)$$ $$f(k_1) = g(k_2)$$ this is where I get stuck. If I can show this, I've shown that $h(n)$ is injective, and in turn, bijective. For reference, this site uses a very similar technique, but seems to completely disregard injectivity for some reason. http://planetmath.org/unionofcountablesets EDIT: Let $A' = A \text{\ } B$. It is clear that $A' \cup B = A \cup B$, as: if $c \in A' \cup B$, then $c \in A'$ or $c \in B$. If $c \in B$, then $c \in A \cup B$. If $c \in A'$, then, by definition, $c \in A$, so that $c \in A \cup B$. It is also clear that $A'$ must be a countable set, as $A$ is countable and $A'$ has, at most, the same number of elements as $A$. If $A'$ is finite, then $A' \cup B$ is countably infinite, as we have added only a finite number of elements to $B$ (is this obvious enough to take as fact without proof?). If $A'$ is countably infinite, then redefine $f(n)$ to be a bijective function from natural numbers to $A'$. The cases of surjectivity and injectivity above are unchanged. Now, if $$f(k_1) = g(k_2)$$ we have that for some $a \in A'$ and $b \in B$, $a = b$. This contradicts the fact that $A'$ and $B$ are disjoint, so we must have that $h(2k_1) \ne h(2k_2 - 1)$ for any natural numbers $k_j$. Therefore, $h(n)$ is bijective. QED.","Let $A, B$ be countably infinite sets. Prove that the union of $A$ and $B$ is also countably infinite. I'm aware that this question already exists on stack exchange, but I'm trying it a different way and am having difficulty finishing it. Let the union of $A$ and $B$ be denoted by $C$. For $C$ to be countably infinite, we need to find a bijection between $C$ and the natural numbers. Let $f(n)$ be the bijective function mapping the natural numbers to $A$, and $g(n)$ be the bijective function mapping the natural numbers to $B$. Define $h(n)$ to be the function mapping the natural numbers to $C$ given by: $$h(2n) = f(n)$$ $$h(2n-1) = g(n)$$ To show that $h(n)$ is bijective, we need to show that it is both surjective and injective. I was able to do the surjective part without problem, but am having trouble proving injectivity. Attempt: if $n_1, n_2$ are even, then $n_j = 2k_j$ for some other natural numbers $k_j$. Thus, $$h(2k_1) = h(2k_2)$$ $$f(k_1) = f(k_2)$$ $$k_1 = k_2$$ since $f(n)$ is bijective. Simlarly, if $n_1, n_2$ are odd, then $n_j = 2k_j - 1$ for some natural numbers $k_j$. So, $$h(2k_1 - 1) = h(2k_2 - 1)$$ $$g(k_1) = g(k_2)$$ $$k_1 = k_2$$ since $g(n)$ is bijective. However, we could also have the case that $n_1$ is even and $n_2$ is odd. Then, $$h(n_1) = h(n_2)$$ $$h(2k_1) = h(2k_2 - 1)$$ $$f(k_1) = g(k_2)$$ this is where I get stuck. If I can show this, I've shown that $h(n)$ is injective, and in turn, bijective. For reference, this site uses a very similar technique, but seems to completely disregard injectivity for some reason. http://planetmath.org/unionofcountablesets EDIT: Let $A' = A \text{\ } B$. It is clear that $A' \cup B = A \cup B$, as: if $c \in A' \cup B$, then $c \in A'$ or $c \in B$. If $c \in B$, then $c \in A \cup B$. If $c \in A'$, then, by definition, $c \in A$, so that $c \in A \cup B$. It is also clear that $A'$ must be a countable set, as $A$ is countable and $A'$ has, at most, the same number of elements as $A$. If $A'$ is finite, then $A' \cup B$ is countably infinite, as we have added only a finite number of elements to $B$ (is this obvious enough to take as fact without proof?). If $A'$ is countably infinite, then redefine $f(n)$ to be a bijective function from natural numbers to $A'$. The cases of surjectivity and injectivity above are unchanged. Now, if $$f(k_1) = g(k_2)$$ we have that for some $a \in A'$ and $b \in B$, $a = b$. This contradicts the fact that $A'$ and $B$ are disjoint, so we must have that $h(2k_1) \ne h(2k_2 - 1)$ for any natural numbers $k_j$. Therefore, $h(n)$ is bijective. QED.",,['elementary-set-theory']
33,"Proof that all natural numbers can be compared with each other from Halmos' ""Naive Set Theory""","Proof that all natural numbers can be compared with each other from Halmos' ""Naive Set Theory""",,"I'm having a hard time understanding a proof from ""Naive Set Theory"" by Paul Halmos. First of all, Halmos defines $\mathbb{N}$ as an intersection of all inductive subsets of any inductive set $I$. ($I$ is inductive if $\varnothing \in I$ and $x \in I \Rightarrow x\cup \{ x \} \in I$). He then proceeds to proof that $\cap \{ A \subseteq I \ | \ A$ is inductive $\}$ doesn't depend on the choice of $I$, that is, $\mathbb{N}$ is well-defined. He also denotes $\varnothing$ by $0$ and $n \cup \{n \}$ by $n^{+}$ in the context of $\mathbb{N}$ Now, what I don't understand is the following proof ($p.51$ of the book): Two natural numbers $m$ and $n$ are comparable is $m \in n, \ n \in m,$ or $m = n$.   Any two natural numbers are comparable. Proof: For any $n \in \mathbb{N}$, $S(n) = \{ m \in \mathbb{N} \ | \ m$ and $n$ are comparable $\}$. Then $S = \{ n \in \mathbb{N} \ | \ S(n) = \mathbb{N} \}$ The proof is by induction. First, we show that $0 \in S$ ( $ \Leftrightarrow S(0) = \mathbb{N}$).   Clearly $0 \in S(0)$ (as $0 = 0$). If $m \in S(o)$, then it's either $0 \in m$ or $0 = m$. In the latter case, $0 \in m^{+}$, so $m^{+} \in S(0)$. In the former case, $0 \in m\cup \{ m \} = m^{+}$ as $0 \in m$. So, by induction, $S(0) = \mathbb{N}$, and $0 \in S$. Now, assume that $n \in S$. That is, $S(n) = \mathbb{N}$. We now need to prove that $n^{+} \in S$, that is, $S(n^{+}) = \mathbb{N}$.   Clearly, $0 \in S(n^{+})$ (as $n^{+} \in S(0)$). Now, assume $m \in S(n^{+})$.    It follows that $m \in n^{+} , \ n^{+} \in m$ (in which case $n^{+} \in m^{+}$) , or $m = n^{+}$ (in which case $n^{+} \in m^{+}$). In the first case, it's either $m = n$, or $m \in n$. If $m = n$, we're done.   If $m \neq n$, then $m \in n$. The last case splits according to the behavior of $m^{+}$ and $n$: since $m^{+} \in S(n)$ , we must have either $n \in m^{+}, \ n = m^{+},$ or $m^{+} \in n$. What I don't understand is the bold-faced part in the last paragraph. Why we have $m^{+} \in S(n)$ then?","I'm having a hard time understanding a proof from ""Naive Set Theory"" by Paul Halmos. First of all, Halmos defines $\mathbb{N}$ as an intersection of all inductive subsets of any inductive set $I$. ($I$ is inductive if $\varnothing \in I$ and $x \in I \Rightarrow x\cup \{ x \} \in I$). He then proceeds to proof that $\cap \{ A \subseteq I \ | \ A$ is inductive $\}$ doesn't depend on the choice of $I$, that is, $\mathbb{N}$ is well-defined. He also denotes $\varnothing$ by $0$ and $n \cup \{n \}$ by $n^{+}$ in the context of $\mathbb{N}$ Now, what I don't understand is the following proof ($p.51$ of the book): Two natural numbers $m$ and $n$ are comparable is $m \in n, \ n \in m,$ or $m = n$.   Any two natural numbers are comparable. Proof: For any $n \in \mathbb{N}$, $S(n) = \{ m \in \mathbb{N} \ | \ m$ and $n$ are comparable $\}$. Then $S = \{ n \in \mathbb{N} \ | \ S(n) = \mathbb{N} \}$ The proof is by induction. First, we show that $0 \in S$ ( $ \Leftrightarrow S(0) = \mathbb{N}$).   Clearly $0 \in S(0)$ (as $0 = 0$). If $m \in S(o)$, then it's either $0 \in m$ or $0 = m$. In the latter case, $0 \in m^{+}$, so $m^{+} \in S(0)$. In the former case, $0 \in m\cup \{ m \} = m^{+}$ as $0 \in m$. So, by induction, $S(0) = \mathbb{N}$, and $0 \in S$. Now, assume that $n \in S$. That is, $S(n) = \mathbb{N}$. We now need to prove that $n^{+} \in S$, that is, $S(n^{+}) = \mathbb{N}$.   Clearly, $0 \in S(n^{+})$ (as $n^{+} \in S(0)$). Now, assume $m \in S(n^{+})$.    It follows that $m \in n^{+} , \ n^{+} \in m$ (in which case $n^{+} \in m^{+}$) , or $m = n^{+}$ (in which case $n^{+} \in m^{+}$). In the first case, it's either $m = n$, or $m \in n$. If $m = n$, we're done.   If $m \neq n$, then $m \in n$. The last case splits according to the behavior of $m^{+}$ and $n$: since $m^{+} \in S(n)$ , we must have either $n \in m^{+}, \ n = m^{+},$ or $m^{+} \in n$. What I don't understand is the bold-faced part in the last paragraph. Why we have $m^{+} \in S(n)$ then?",,"['elementary-number-theory', 'elementary-set-theory', 'proof-explanation']"
34,"If $A_n\cap A_{n+1}\neq \emptyset$, and each $A_n$ is connected, show that $\cup A_n$ is connected","If , and each  is connected, show that  is connected",A_n\cap A_{n+1}\neq \emptyset A_n \cup A_n,"One strategy for this is to suppose a separation $C\cup D$ for the union and see that if one of them is connect, then it's entirely in $C$ or $D$. Let's suppose $D$. Then the others having a point in common with this one, will also lie in $D$. Now, can I do it like this: The union of two connected spaces with a point in common is connected. So by induction I'm always uniting a connected space with another connected space which has a point in common. ?","One strategy for this is to suppose a separation $C\cup D$ for the union and see that if one of them is connect, then it's entirely in $C$ or $D$. Let's suppose $D$. Then the others having a point in common with this one, will also lie in $D$. Now, can I do it like this: The union of two connected spaces with a point in common is connected. So by induction I'm always uniting a connected space with another connected space which has a point in common. ?",,"['general-topology', 'elementary-set-theory', 'connectedness']"
35,"Bijection from $[0, 1]\cup(1,2)\cup${$3$} to ($0, 1$)",Bijection from {} to (),"[0, 1]\cup(1,2)\cup 3 0, 1","I need a bijection from $[0, 1]\cup(1,2)\cup${$3$} to $(0, 1)$. At first I thought it was a trivial problem, but after struggling with it for some time I think it's harder than it looks. For instance, if you try to try to send $(0, 1)$ to $(0, \frac{1}{2})$ and {$3$} to $\frac{1}{2}$ and ($1, 2$) to ($\frac{1}{2}, 1$), then you are still left with a place to send $0, 1$ since they are included in [$0, 1$]. I've tried some variations but can't get it. Help/hints would be appreciated.","I need a bijection from $[0, 1]\cup(1,2)\cup${$3$} to $(0, 1)$. At first I thought it was a trivial problem, but after struggling with it for some time I think it's harder than it looks. For instance, if you try to try to send $(0, 1)$ to $(0, \frac{1}{2})$ and {$3$} to $\frac{1}{2}$ and ($1, 2$) to ($\frac{1}{2}, 1$), then you are still left with a place to send $0, 1$ since they are included in [$0, 1$]. I've tried some variations but can't get it. Help/hints would be appreciated.",,['elementary-set-theory']
36,Cartesian product $\Bbb R^n \times \Bbb R^m$,Cartesian product,\Bbb R^n \times \Bbb R^m,Can someone tell me whether $\Bbb R^{n+m}$ equals Cartesian product $\Bbb R^n \times \Bbb R^m$ for some positive integers $n$ and $m$?,Can someone tell me whether $\Bbb R^{n+m}$ equals Cartesian product $\Bbb R^n \times \Bbb R^m$ for some positive integers $n$ and $m$?,,['elementary-set-theory']
37,Conditions for an order-embedding wrt $\mathbb{R}$,Conditions for an order-embedding wrt,\mathbb{R},"I am trying to understand a proposition which goes like this: Let $(X,\precsim)$ be a nonempty totally preordered set. Let $(\hat{X}, \precsim)$ be the set of all equivalence classes in $(X,\precsim)$, i.e. $X$'s quotient set endowed with the same order as $X$ (thus clearly a totally-ordered set). Then $\exists f: \hat{X} \rightarrow \mathbb{R}$, where $f$ is order-embedding, iff $\exists X^* \subset \hat{X}$ such that $X^*$ is at most countable and order-dense (close-packed) in $\hat{X}$. ($\mathbb{R}$ is ordered as usual). I just can't understand how to prove this nor get any intuition why this is so. (The fact that it starts with a proset and not a toset is irrelevant to my lack of understanding, I just wanted to state it in full.) Edit: Order-embedding, not order-isomorphic. Sorry for the confusion. (bis)","I am trying to understand a proposition which goes like this: Let $(X,\precsim)$ be a nonempty totally preordered set. Let $(\hat{X}, \precsim)$ be the set of all equivalence classes in $(X,\precsim)$, i.e. $X$'s quotient set endowed with the same order as $X$ (thus clearly a totally-ordered set). Then $\exists f: \hat{X} \rightarrow \mathbb{R}$, where $f$ is order-embedding, iff $\exists X^* \subset \hat{X}$ such that $X^*$ is at most countable and order-dense (close-packed) in $\hat{X}$. ($\mathbb{R}$ is ordered as usual). I just can't understand how to prove this nor get any intuition why this is so. (The fact that it starts with a proset and not a toset is irrelevant to my lack of understanding, I just wanted to state it in full.) Edit: Order-embedding, not order-isomorphic. Sorry for the confusion. (bis)",,"['elementary-set-theory', 'order-theory']"
38,"What is the domain of a set operation (e.g., union and intersection)?","What is the domain of a set operation (e.g., union and intersection)?",,"My understanding: The set operations (such as union and intersection) are operations and so functions with a domain and codomain. A function's domain and codomain are always sets. The input to a set operation is either a set or a tuple of sets. My thoughts: My thoughts about what the domain of a set operation would be (based on the above understanding) has brought me to ""the set of all sets"". This is clearly wrong. My Question: What is in fact the domain of a set operation? Am I to instead understand the domain of such an operation to be a class? This would cause me to revise my current understanding of a function to allow the domain and codomain to be classes. Thanks.","My understanding: The set operations (such as union and intersection) are operations and so functions with a domain and codomain. A function's domain and codomain are always sets. The input to a set operation is either a set or a tuple of sets. My thoughts: My thoughts about what the domain of a set operation would be (based on the above understanding) has brought me to ""the set of all sets"". This is clearly wrong. My Question: What is in fact the domain of a set operation? Am I to instead understand the domain of such an operation to be a class? This would cause me to revise my current understanding of a function to allow the domain and codomain to be classes. Thanks.",,"['elementary-set-theory', 'binary-operations']"
39,Can we multiply cardinalities,Can we multiply cardinalities,,"Given sets $A$ and $B$, is their an appropriate notion of the product $$\DeclareMathOperator{\card}{card}\card(A)\card(B)$$ of their cardinalities, which gives the standard product of natural numbers when $A$ and $B$ are finite? We would like $\card(A)\card(B)$ to be again a cardinal number.","Given sets $A$ and $B$, is their an appropriate notion of the product $$\DeclareMathOperator{\card}{card}\card(A)\card(B)$$ of their cardinalities, which gives the standard product of natural numbers when $A$ and $B$ are finite? We would like $\card(A)\card(B)$ to be again a cardinal number.",,['elementary-set-theory']
40,Number Theory and Self-Written Numbers,Number Theory and Self-Written Numbers,,"Given a natural number $N = a_{n}a_{n-1}\ldots a_{1}$ and its digits' multiset $D_{N} = \{a_{1},a_{2},\ldots,a_{n}\}$, we shall call it a self-written number if, and only if, it exists multisets $B = \{b_{1},b_{2},\ldots,b_{k}\}\subseteq D_{N}$ and $E = \{e_{1},e_{2},\ldots,e_{j}\}\subseteq D_{N}$ such that $B\cap E = \varnothing$ which satisfy the next condition: $$N = b^{e}\quad\text{where}\quad b = b_{k}b_{k-1}\ldots b_{1}\,\,\,\text{and}\,\,\, e = e_{j}e_{j-1}\ldots e_{1}$$ Once the definition has been made clear, we may now expose some examples. For instance, $121$ is self-written since $121 = 11^2$. The same happens to $1331$ once it can be rewritten as $1331 = 11^3$. Moreover, so it does to $14641$ given that $14641 = 11^4$. Thence it comes my first question: is there infinitely many self-written numbers? Secondly, is there any criteria to identify them quickly? I think this is it. Thank you in advance for any contribution.","Given a natural number $N = a_{n}a_{n-1}\ldots a_{1}$ and its digits' multiset $D_{N} = \{a_{1},a_{2},\ldots,a_{n}\}$, we shall call it a self-written number if, and only if, it exists multisets $B = \{b_{1},b_{2},\ldots,b_{k}\}\subseteq D_{N}$ and $E = \{e_{1},e_{2},\ldots,e_{j}\}\subseteq D_{N}$ such that $B\cap E = \varnothing$ which satisfy the next condition: $$N = b^{e}\quad\text{where}\quad b = b_{k}b_{k-1}\ldots b_{1}\,\,\,\text{and}\,\,\, e = e_{j}e_{j-1}\ldots e_{1}$$ Once the definition has been made clear, we may now expose some examples. For instance, $121$ is self-written since $121 = 11^2$. The same happens to $1331$ once it can be rewritten as $1331 = 11^3$. Moreover, so it does to $14641$ given that $14641 = 11^4$. Thence it comes my first question: is there infinitely many self-written numbers? Secondly, is there any criteria to identify them quickly? I think this is it. Thank you in advance for any contribution.",,"['sequences-and-series', 'combinatorics', 'number-theory', 'elementary-set-theory', 'integers']"
41,"Schröder-Bernstein, check proof","Schröder-Bernstein, check proof",,"Theorem: if $r:A\to B, s:B\to A$ are injections, there is a bijection $t:A\to B$. I will prove this lemma: ""if exist $f:A\to B\subset A$ injective, then exist $h:A\to B$ bijective. With this lemma, consider the injective function $f=s\circ r:A\to s(B)\subset A$, and exist $h:A\to s(B)$ bijective. Now, $s_{|B}:B\to s(B)$ is bijective. Finally, $t= s_{|B}^{-1}\circ h:A\to B$ is a bijection. I want check the proof of lemma: Put $Y=A-B$, $X=Y\cup (\bigcup_{i\in \mathbb{N}}f^i(Y))$, where $ f^i(Y)=f(f(...f(Y)...)), i$ times. Because $Y\cap B=\emptyset$, $ f^k(Y)\subset B$ and $Y$ are disjoint. Because $f$ is injective, $Y\cap f^k(Y)=\emptyset \to f^m(Y)\cap f^{m+k}(Y)=\emptyset $ for all $k,m$. Note in the definition of $X$ that the union is disjoint, and $X=Y\cup f(X)$. Finally, Note that $A-X=(Y\cup B)-(Y\cup f(X))=B-f(X)$. If we define $h:A\to B$ as $h=f$ in $X$ and $h=id$ in $A-X$, is bijective.","Theorem: if $r:A\to B, s:B\to A$ are injections, there is a bijection $t:A\to B$. I will prove this lemma: ""if exist $f:A\to B\subset A$ injective, then exist $h:A\to B$ bijective. With this lemma, consider the injective function $f=s\circ r:A\to s(B)\subset A$, and exist $h:A\to s(B)$ bijective. Now, $s_{|B}:B\to s(B)$ is bijective. Finally, $t= s_{|B}^{-1}\circ h:A\to B$ is a bijection. I want check the proof of lemma: Put $Y=A-B$, $X=Y\cup (\bigcup_{i\in \mathbb{N}}f^i(Y))$, where $ f^i(Y)=f(f(...f(Y)...)), i$ times. Because $Y\cap B=\emptyset$, $ f^k(Y)\subset B$ and $Y$ are disjoint. Because $f$ is injective, $Y\cap f^k(Y)=\emptyset \to f^m(Y)\cap f^{m+k}(Y)=\emptyset $ for all $k,m$. Note in the definition of $X$ that the union is disjoint, and $X=Y\cup f(X)$. Finally, Note that $A-X=(Y\cup B)-(Y\cup f(X))=B-f(X)$. If we define $h:A\to B$ as $h=f$ in $X$ and $h=id$ in $A-X$, is bijective.",,"['elementary-set-theory', 'proof-verification', 'cardinals']"
42,Proving that R is a partial Order.,Proving that R is a partial Order.,,"Define the relation $\Bbb R \times \Bbb R$ by $(a,b) \; R$ $ (x,y)$ iff $a \le x$ and $b \le y$ , prove that R is a partial ordering for $\Bbb R\times\Bbb R $ . A partial order is if R is reflexive on A, antisymmetric and transitive. One must prove these properties true. My question for this problem is trying to comprehend why this problem is antisymmetric and why it is transitive. $(i)$  $R $ is reflexive as we say $x=a$ and $y = b$. Thus we can conclude that that $x\le x , y\le y$. $(x,y)R(x,y)$. $(ii)$ if $a\le x$ and $x\le a$ then $x= a $ If $ b \le y $ and $ y \le b$ then $y =b$. Since you interchange these would it not be symmetric? $(iii)$ Suppose $(a,b) R(x,y)$ and $(x,y) R (c,d)$ This is as far as I got for transitive. Any advice on how prove this partial ordering true would be appreciated.","Define the relation $\Bbb R \times \Bbb R$ by $(a,b) \; R$ $ (x,y)$ iff $a \le x$ and $b \le y$ , prove that R is a partial ordering for $\Bbb R\times\Bbb R $ . A partial order is if R is reflexive on A, antisymmetric and transitive. One must prove these properties true. My question for this problem is trying to comprehend why this problem is antisymmetric and why it is transitive. $(i)$  $R $ is reflexive as we say $x=a$ and $y = b$. Thus we can conclude that that $x\le x , y\le y$. $(x,y)R(x,y)$. $(ii)$ if $a\le x$ and $x\le a$ then $x= a $ If $ b \le y $ and $ y \le b$ then $y =b$. Since you interchange these would it not be symmetric? $(iii)$ Suppose $(a,b) R(x,y)$ and $(x,y) R (c,d)$ This is as far as I got for transitive. Any advice on how prove this partial ordering true would be appreciated.",,"['elementary-set-theory', 'relations', 'order-theory']"
43,The cardinality of the classic Hilbert space,The cardinality of the classic Hilbert space,,"Question. The classic Hilbert space consists of all infinite sequences $(x_n)$ of real numbers, called points, for which the series $x_1^2+x_2^2+\cdots $ converges. Show that the classic Hilbert space contains just as many points as the real in $\mathbb R$. Proof says $c\le \vert H\vert \le c^{\aleph_0} =(2^{\aleph_0})^{\aleph_0}=2^{\aleph_0 \aleph_0}=c. $ Why is $c\le \vert H\vert \le c^{\aleph_0}$ so trivial that the book adds no explanation to it?","Question. The classic Hilbert space consists of all infinite sequences $(x_n)$ of real numbers, called points, for which the series $x_1^2+x_2^2+\cdots $ converges. Show that the classic Hilbert space contains just as many points as the real in $\mathbb R$. Proof says $c\le \vert H\vert \le c^{\aleph_0} =(2^{\aleph_0})^{\aleph_0}=2^{\aleph_0 \aleph_0}=c. $ Why is $c\le \vert H\vert \le c^{\aleph_0}$ so trivial that the book adds no explanation to it?",,['elementary-set-theory']
44,Can I define the set of natural numbers without the axiom of infinity?,Can I define the set of natural numbers without the axiom of infinity?,,"The exercise asks if exists a definition of $Nat(x)$ such that $Nat(x) \Rightarrow Nat(S(x))$, and $\exists x $such that $ Nat(x)$ is false without the use of axiom of infinity. Here $Nat(x) \Leftrightarrow x$ is a natural number, and $S(x)$ is the successor of $x$. I tried to define $$S(a)=\{a\}.$$ Then I define $$a \in C_a \Leftrightarrow (a\in C_a \Rightarrow S(s) \in C_a).$$ So $$\emptyset\in \cap C_i \forall i. $$ At the end I define $$Nat (a) \Leftrightarrow a\in C_\emptyset.$$  Can you ckech my idea or suggest another one?","The exercise asks if exists a definition of $Nat(x)$ such that $Nat(x) \Rightarrow Nat(S(x))$, and $\exists x $such that $ Nat(x)$ is false without the use of axiom of infinity. Here $Nat(x) \Leftrightarrow x$ is a natural number, and $S(x)$ is the successor of $x$. I tried to define $$S(a)=\{a\}.$$ Then I define $$a \in C_a \Leftrightarrow (a\in C_a \Rightarrow S(s) \in C_a).$$ So $$\emptyset\in \cap C_i \forall i. $$ At the end I define $$Nat (a) \Leftrightarrow a\in C_\emptyset.$$  Can you ckech my idea or suggest another one?",,[]
45,Existence of an inverse relation for $R \subseteq A \times A$.,Existence of an inverse relation for .,R \subseteq A \times A,"I'm stuck with the following problem: Given the set $A = \{1,2,3,4,5\}$, construct a relation $R \subseteq A \times A$ such $$ R \circ R^{-1} = \triangle_A = \{(a,a) \hspace{5pt} | \hspace{5pt} a \in A\}$$ and $$R^{-1} \circ R = \{(a,a)\};$$ that is, the set that consists of all the ordered pairs in $A \times A$ where both elements are equal, and a set that consists of only one point. Now, here's where I've got so far: Let $R = \{(1,1), (1,2) , (1,3) , (1,4) , (1,5) \}$, so that $R^{-1} = \{(1,1), (2,1) , (3,1) , (4,1) , (5,1) \}$. Then, $$R^{-1} \circ R = \{ (1,1)\} $$ But, as you can see, taking $R \circ R^{-1}$, gives back all of $R$. I've taken similar choices of $R$ and none of them work. Now, for example, for the set that contains all ordered pairs with equal entries let $R = \{ (1,2),(2,3),(3,4),(4,5), (5,1) \}$, then $ R^{-1} = \{ (2,1) , (3,2), (4,3) , (5,4) , (5,1)\}$. Taking the composition from either side yields $\triangle_A$. My guess is that there is no such $R$: in order to get $\triangle_A$, our relation must be in a way that $R \circ R^{-1} = R^{-1} \circ R$, which would imply that the other condition cannot be met. So, provided I'm not wrong, lets say $X= \{ R \subseteq A \times A \hspace{5pt} | \hspace{5pt} R \circ R^{-1} = \triangle_A\}$, that is, the set of all appropriate choices of $R$ such that $R \circ R^{-1} = \triangle_A$, and in a similar way, let $Y = \{ R \subseteq A \times A \hspace{5pt} | \hspace{5pt} R \circ R^{-1} = \{(a,a)\} \hspace{5pt} \text{for some} \hspace{5pt} a \in A\}$. How would I prove that $X \cap Y = \varnothing$? Edit If we arrange all the members of $A \times A$ in the following matrix/array, we can make the following conclusions: $$ \left( \begin{array}{[ccccc} (1,1) &(1,2)&(1,3)&(1,4)&(1,5)\\ (2,1)&(2,2)&(2,3)&(2,4)&(2,5)\\ (3,1)&(3,2)&(3,3)&(3,4)&(3,5)\\ (4,1)&(4,2)&(4,3)&(4,4)&(4,5)\\ (5,1)&(5,2)&(5,3)&(5,4)&(5,5)\\ \end{array} \right) $$ Let $R_{(n,n)} = \{ (n,n)\}$. Define $R_{(n,a_i)} = \{ (n,a_i) \hspace{5pt} | \hspace{5pt} a_i \in A \hspace{5pt} \text{for} \hspace{5pt} i = 1, ... ,5 \}$, this is represented as the $n$-th row in the matrix. Similarly, $R_{(a_i,n)} = (R_{(n,a_i)})^{-1}$, is the $n$-th column in the matrix. Now, if we want to choose a relation on $A$ such that $ R \circ R^{-1} = \triangle_A $ contains all the ordered pairs with equal entries in $A \times A$, and $R_{(n,n)}$ is possible, then we have only five options, namely, the five rows of the matrix. Since none of those rows is an appropriate choice of $R$, then we can conclude that there does not exist any relation on $A$ that has the properties requested. Does this count as a proof or does it lack something?","I'm stuck with the following problem: Given the set $A = \{1,2,3,4,5\}$, construct a relation $R \subseteq A \times A$ such $$ R \circ R^{-1} = \triangle_A = \{(a,a) \hspace{5pt} | \hspace{5pt} a \in A\}$$ and $$R^{-1} \circ R = \{(a,a)\};$$ that is, the set that consists of all the ordered pairs in $A \times A$ where both elements are equal, and a set that consists of only one point. Now, here's where I've got so far: Let $R = \{(1,1), (1,2) , (1,3) , (1,4) , (1,5) \}$, so that $R^{-1} = \{(1,1), (2,1) , (3,1) , (4,1) , (5,1) \}$. Then, $$R^{-1} \circ R = \{ (1,1)\} $$ But, as you can see, taking $R \circ R^{-1}$, gives back all of $R$. I've taken similar choices of $R$ and none of them work. Now, for example, for the set that contains all ordered pairs with equal entries let $R = \{ (1,2),(2,3),(3,4),(4,5), (5,1) \}$, then $ R^{-1} = \{ (2,1) , (3,2), (4,3) , (5,4) , (5,1)\}$. Taking the composition from either side yields $\triangle_A$. My guess is that there is no such $R$: in order to get $\triangle_A$, our relation must be in a way that $R \circ R^{-1} = R^{-1} \circ R$, which would imply that the other condition cannot be met. So, provided I'm not wrong, lets say $X= \{ R \subseteq A \times A \hspace{5pt} | \hspace{5pt} R \circ R^{-1} = \triangle_A\}$, that is, the set of all appropriate choices of $R$ such that $R \circ R^{-1} = \triangle_A$, and in a similar way, let $Y = \{ R \subseteq A \times A \hspace{5pt} | \hspace{5pt} R \circ R^{-1} = \{(a,a)\} \hspace{5pt} \text{for some} \hspace{5pt} a \in A\}$. How would I prove that $X \cap Y = \varnothing$? Edit If we arrange all the members of $A \times A$ in the following matrix/array, we can make the following conclusions: $$ \left( \begin{array}{[ccccc} (1,1) &(1,2)&(1,3)&(1,4)&(1,5)\\ (2,1)&(2,2)&(2,3)&(2,4)&(2,5)\\ (3,1)&(3,2)&(3,3)&(3,4)&(3,5)\\ (4,1)&(4,2)&(4,3)&(4,4)&(4,5)\\ (5,1)&(5,2)&(5,3)&(5,4)&(5,5)\\ \end{array} \right) $$ Let $R_{(n,n)} = \{ (n,n)\}$. Define $R_{(n,a_i)} = \{ (n,a_i) \hspace{5pt} | \hspace{5pt} a_i \in A \hspace{5pt} \text{for} \hspace{5pt} i = 1, ... ,5 \}$, this is represented as the $n$-th row in the matrix. Similarly, $R_{(a_i,n)} = (R_{(n,a_i)})^{-1}$, is the $n$-th column in the matrix. Now, if we want to choose a relation on $A$ such that $ R \circ R^{-1} = \triangle_A $ contains all the ordered pairs with equal entries in $A \times A$, and $R_{(n,n)}$ is possible, then we have only five options, namely, the five rows of the matrix. Since none of those rows is an appropriate choice of $R$, then we can conclude that there does not exist any relation on $A$ that has the properties requested. Does this count as a proof or does it lack something?",,"['elementary-set-theory', 'relations']"
46,Prove that an infinite chain of proper containments of compact sets is non empty [duplicate],Prove that an infinite chain of proper containments of compact sets is non empty [duplicate],,"This question already has an answer here : Let $\{K_i\}_{i=1}^{\infty}$ a decreasing sequence of compact and non-empty sets on $\mathbb{R}^n.$ Then $\cap_{i = 1}^{\infty} K_i \neq \emptyset.$ (1 answer) Closed 8 years ago . I need to prove that if $K_1\supset K_2 \supset K_3 \supset K_4 \supset \ldots$ is a chain of proper containments and each $K_{i}\subseteq \mathbb{R}^{n}$ is compact, then $\bigcap_{i=1}^{\infty} K_{i} \neq \emptyset$. I understand that $K_i \neq \emptyset, \forall i$ because of the proper subset condition and since the empty set has no proper subsets. I also understand that the compact condition is necessary in order to prevent sets that limit, at infinity, to an empty set but for no $i$ are empty themselves (example: $K_i=(0, 1/i)$). However, I'm not sure how to complete.","This question already has an answer here : Let $\{K_i\}_{i=1}^{\infty}$ a decreasing sequence of compact and non-empty sets on $\mathbb{R}^n.$ Then $\cap_{i = 1}^{\infty} K_i \neq \emptyset.$ (1 answer) Closed 8 years ago . I need to prove that if $K_1\supset K_2 \supset K_3 \supset K_4 \supset \ldots$ is a chain of proper containments and each $K_{i}\subseteq \mathbb{R}^{n}$ is compact, then $\bigcap_{i=1}^{\infty} K_{i} \neq \emptyset$. I understand that $K_i \neq \emptyset, \forall i$ because of the proper subset condition and since the empty set has no proper subsets. I also understand that the compact condition is necessary in order to prevent sets that limit, at infinity, to an empty set but for no $i$ are empty themselves (example: $K_i=(0, 1/i)$). However, I'm not sure how to complete.",,"['elementary-set-theory', 'compactness']"
47,Notation for conditional set complement?,Notation for conditional set complement?,,"As far as I know, given $U=\{1,2,3,4,5,6\},A=\{1,2,3\}$ the notation for its set complement is $A^C = \{4,5,6\}$ Is there any sort of notation for a conditional set complement? For example, lets say I had a true/false variable $x_1$ who determines in an equation if $A$ should be itself or its complement. I think I could do a piece-wise function like so: $$B=\begin{cases} A& \text{if $x_1$ is true},\\ A^C& \text{if $x_1$ is false}. \end{cases}$$ but I actually have many conditionally complemented sets that I am using. If I use a single piece-wise function, that would be $2^{n}$ cases, or I could use set operators between $n$ different piece-wise functions, but that seems very verbose. Thanks!","As far as I know, given $U=\{1,2,3,4,5,6\},A=\{1,2,3\}$ the notation for its set complement is $A^C = \{4,5,6\}$ Is there any sort of notation for a conditional set complement? For example, lets say I had a true/false variable $x_1$ who determines in an equation if $A$ should be itself or its complement. I think I could do a piece-wise function like so: $$B=\begin{cases} A& \text{if $x_1$ is true},\\ A^C& \text{if $x_1$ is false}. \end{cases}$$ but I actually have many conditionally complemented sets that I am using. If I use a single piece-wise function, that would be $2^{n}$ cases, or I could use set operators between $n$ different piece-wise functions, but that seems very verbose. Thanks!",,"['elementary-set-theory', 'notation']"
48,Proving that the powerset of $\Bbb N$ is uncountable,Proving that the powerset of  is uncountable,\Bbb N,"The question I'm facing off with: (a) Consider the set $A$ defined as the set of all subsets of $\Bbb N$: $A = ${$B : B \subset \Bbb N$}. Show that $A$ is in one-to-one correspondence with the set of all (infinite) binary sequences: $C = \{ b_1, b_2, b_3,...  | b_i \in \{ 0,1 \} \}$. To do this I tried to assign each number in $\Bbb N$ a unique binary sequence (e.g. $5 = 001, 9 = 101, 59 = 001101$). Thus, any subset of $\Bbb N$ would translate to a unique sequence of binary numbers in $C$. This has a few issues, however. A subset of $\Bbb N$ could be finite, and my method would thus translate that subset to a finite binary sequence in $C$, which can't happen because $C$ is the set of all infinite binary sequences. How do I correct this? Just hints please. I'm also running into a notational issue, which I would like some clarification on. I'm not sure I understand the notation used for $C$; are $b_1, b_2, ...$ infinite sequences themselves, or do they each individually represent either a 0 or a 1? (b) Show that $C$ is in one-to-one correspondence with $[0, 1]$. For this one I took the same approach, unfortunately to no avail. I'm confident that whatever method I use to attack the first part of the question, I can easily use to attack the second. Which leads me to my next question: Is there any general method in showing that two sets have a one-to-one correspondence with each other?","The question I'm facing off with: (a) Consider the set $A$ defined as the set of all subsets of $\Bbb N$: $A = ${$B : B \subset \Bbb N$}. Show that $A$ is in one-to-one correspondence with the set of all (infinite) binary sequences: $C = \{ b_1, b_2, b_3,...  | b_i \in \{ 0,1 \} \}$. To do this I tried to assign each number in $\Bbb N$ a unique binary sequence (e.g. $5 = 001, 9 = 101, 59 = 001101$). Thus, any subset of $\Bbb N$ would translate to a unique sequence of binary numbers in $C$. This has a few issues, however. A subset of $\Bbb N$ could be finite, and my method would thus translate that subset to a finite binary sequence in $C$, which can't happen because $C$ is the set of all infinite binary sequences. How do I correct this? Just hints please. I'm also running into a notational issue, which I would like some clarification on. I'm not sure I understand the notation used for $C$; are $b_1, b_2, ...$ infinite sequences themselves, or do they each individually represent either a 0 or a 1? (b) Show that $C$ is in one-to-one correspondence with $[0, 1]$. For this one I took the same approach, unfortunately to no avail. I'm confident that whatever method I use to attack the first part of the question, I can easily use to attack the second. Which leads me to my next question: Is there any general method in showing that two sets have a one-to-one correspondence with each other?",,['sequences-and-series']
49,"When is $(X, \mathcal{T}_{trivial})$ Hausdorff?",When is  Hausdorff?,"(X, \mathcal{T}_{trivial})","When is $(X, \mathcal{T}_{trivial})$ Hausdorff? Recall: $\mathcal{T}_{trivial} = \{\varnothing, X\}$ I want to say that this space is Hausdorff is $X$ is a singleton But I can't actually produce two open sets that satisfy the condition: $\forall x,y \in X$, there exists disjoint $U, V \in \mathcal{T}_{trivial}$ such that $x \in U$ and $y \in V$ Suppose $X = \{x\}$, then yes we have a $x \in U = \{x\}$, but do we have $y \in \varnothing$, since $\varnothing$ is empty?, or is the condition trivially satisified since there is only one point?","When is $(X, \mathcal{T}_{trivial})$ Hausdorff? Recall: $\mathcal{T}_{trivial} = \{\varnothing, X\}$ I want to say that this space is Hausdorff is $X$ is a singleton But I can't actually produce two open sets that satisfy the condition: $\forall x,y \in X$, there exists disjoint $U, V \in \mathcal{T}_{trivial}$ such that $x \in U$ and $y \in V$ Suppose $X = \{x\}$, then yes we have a $x \in U = \{x\}$, but do we have $y \in \varnothing$, since $\varnothing$ is empty?, or is the condition trivially satisified since there is only one point?",,"['general-topology', 'elementary-set-theory']"
50,Is $2^{2^{\aleph_0}}$ a higher cardinality than $2^{\aleph_0}$?,Is  a higher cardinality than ?,2^{2^{\aleph_0}} 2^{\aleph_0},"As far as I understand, $2^{\aleph_0}$ is the cardinality of the real numbers (and whether this equals $\aleph_1$ is the continuum hypothesis). But would $2^{2^{\aleph_0}}$ be of a higher cardinality than the cardinality of the real numbers?","As far as I understand, $2^{\aleph_0}$ is the cardinality of the real numbers (and whether this equals $\aleph_1$ is the continuum hypothesis). But would $2^{2^{\aleph_0}}$ be of a higher cardinality than the cardinality of the real numbers?",,"['elementary-set-theory', 'cardinals']"
51,Non-cofinite element of non-principle ultrafilters,Non-cofinite element of non-principle ultrafilters,,"Say, we have $n$ non-principal ultrafilters $\mathcal{U}_1,...,\mathcal{U}_n$ on an infinite set $X$. Obviously they all contain all cofinite subsets of $X$. But can they all contain some common element which is not cofinite, i.e. is there anything non-cofinite in their intersection? This seems obvious there should be such an element (I think), but the proof... I don't know :(","Say, we have $n$ non-principal ultrafilters $\mathcal{U}_1,...,\mathcal{U}_n$ on an infinite set $X$. Obviously they all contain all cofinite subsets of $X$. But can they all contain some common element which is not cofinite, i.e. is there anything non-cofinite in their intersection? This seems obvious there should be such an element (I think), but the proof... I don't know :(",,"['elementary-set-theory', 'filters']"
52,Is it true that finite intersection distributes over arbitrary unions?,Is it true that finite intersection distributes over arbitrary unions?,,"I have come across the problem of showing that $$\bigcap_{i=1}^n \Big ( \bigcup_{\alpha\in A} X_\alpha^{(i)}\Big) = \bigcup_{\alpha\in A} \Big ( \bigcap_{i=1}^n X_\alpha^{(i)} \Big)$$ for some family of sets $\{ A_\alpha^{(i)} \}$. Is this statement even true for arbitrary sets? If not, what conditions do I need to assert this.","I have come across the problem of showing that $$\bigcap_{i=1}^n \Big ( \bigcup_{\alpha\in A} X_\alpha^{(i)}\Big) = \bigcup_{\alpha\in A} \Big ( \bigcap_{i=1}^n X_\alpha^{(i)} \Big)$$ for some family of sets $\{ A_\alpha^{(i)} \}$. Is this statement even true for arbitrary sets? If not, what conditions do I need to assert this.",,"['general-topology', 'elementary-set-theory']"
53,Set counting of failed students in all subjects,Set counting of failed students in all subjects,,"There are $100$ students in a class. In a test, $50$ of them failed in mathematics, $45$ failed in physics and $40$ failed in chemistry. $32$ failed in exactly two of these three subjects.Only one student passed in all the three subjects.The number of students failing in all three subjects is My solution: As only one student has passed in all three subjects so $99$ students have failed in at least one subject. Denoting fail in mathematics as $M$, physics as $P$, chemistry as $C$. $MP$ denotes fail in math and phy. similarly $PC$ and $MC$. $MPC$ denote fail in all three subjects. Number of students failed in $M$ OR $P$ OR $C$ = $M+P+C-MP-PC-MC+MPC$ Given that $32$ students failed exactly in two of these subjects. so $MP+PC+MC=32$. $99=50+45+40-32+MPC$,  $MPC=-4$ Whats wrong here? Help appreciated :)","There are $100$ students in a class. In a test, $50$ of them failed in mathematics, $45$ failed in physics and $40$ failed in chemistry. $32$ failed in exactly two of these three subjects.Only one student passed in all the three subjects.The number of students failing in all three subjects is My solution: As only one student has passed in all three subjects so $99$ students have failed in at least one subject. Denoting fail in mathematics as $M$, physics as $P$, chemistry as $C$. $MP$ denotes fail in math and phy. similarly $PC$ and $MC$. $MPC$ denote fail in all three subjects. Number of students failed in $M$ OR $P$ OR $C$ = $M+P+C-MP-PC-MC+MPC$ Given that $32$ students failed exactly in two of these subjects. so $MP+PC+MC=32$. $99=50+45+40-32+MPC$,  $MPC=-4$ Whats wrong here? Help appreciated :)",,"['combinatorics', 'elementary-set-theory']"
54,If $|A|=|B|$ and $|C|=|D|$ then $|A\times C|=|B\times D|$ proof,If  and  then  proof,|A|=|B| |C|=|D| |A\times C|=|B\times D|,I have done previous questions regarding these but this one seems too abstract. I have tried to build bijective functions with no success. Any help would be appreciated.,I have done previous questions regarding these but this one seems too abstract. I have tried to build bijective functions with no success. Any help would be appreciated.,,['elementary-set-theory']
55,Separation of $X$ - open and closed subsets,Separation of  - open and closed subsets,X,"I'm trying to decipher some notes from a lecture I missed. What I have is: If $U$, $V$ is a separation of $X$, then $U = X \setminus V$, $V = X \setminus U$. So $U$ and $V$ are open and closed subsets of $X$ not $X$, $\varnothing$. What does the ""not $X$, $\varnothing$"" part mean? Everything else makes sense, but this part seems to be an incomplete thought that the lecturer probably filled in verbally.","I'm trying to decipher some notes from a lecture I missed. What I have is: If $U$, $V$ is a separation of $X$, then $U = X \setminus V$, $V = X \setminus U$. So $U$ and $V$ are open and closed subsets of $X$ not $X$, $\varnothing$. What does the ""not $X$, $\varnothing$"" part mean? Everything else makes sense, but this part seems to be an incomplete thought that the lecturer probably filled in verbally.",,"['general-topology', 'elementary-set-theory', 'connectedness']"
56,How to prove this topology equality?,How to prove this topology equality?,,"Suppose $(A,\tau_A)$ is the subspace of $(X,\tau)$, show that for all $B\in 2^A$ the following relationship holds: $$\text{int}B=\text{int}_A B\cap \text{int} A.$$ Here subtopology $\tau_A$ is defined as follows: $V\in\tau_A$ if there exists some $U\in\tau$ such that $V=U\cap A$.  And $\text{int}$ denotes the interior of a set, which is defined as the union of every open subset it contains. So here I go. From definitions $$\text{RHS}=\text{int}A\cap (\bigcup_{C\subset B,C\in\tau_A}C)=\text{int}A\cap (\bigcup_{C^*\cap A\subset B,C^*\in\tau}(C^*\cap A))=(\bigcup_{C^*\cap A\subset B,C^*\in\tau}(C^*\cap \text{int}A)).$$ Don't know what to do next. Most probably I'm on the wrong track. So I really need help from you guys now. Clues and complete answers are both appreciated. Thanks in advance.","Suppose $(A,\tau_A)$ is the subspace of $(X,\tau)$, show that for all $B\in 2^A$ the following relationship holds: $$\text{int}B=\text{int}_A B\cap \text{int} A.$$ Here subtopology $\tau_A$ is defined as follows: $V\in\tau_A$ if there exists some $U\in\tau$ such that $V=U\cap A$.  And $\text{int}$ denotes the interior of a set, which is defined as the union of every open subset it contains. So here I go. From definitions $$\text{RHS}=\text{int}A\cap (\bigcup_{C\subset B,C\in\tau_A}C)=\text{int}A\cap (\bigcup_{C^*\cap A\subset B,C^*\in\tau}(C^*\cap A))=(\bigcup_{C^*\cap A\subset B,C^*\in\tau}(C^*\cap \text{int}A)).$$ Don't know what to do next. Most probably I'm on the wrong track. So I really need help from you guys now. Clues and complete answers are both appreciated. Thanks in advance.",,"['general-topology', 'elementary-set-theory']"
57,Order type in finite sets,Order type in finite sets,,"This is a general question regarding power (cardinal number)  and type (ordinal number) of a set. These definitions are taken from Kolmogorov and Fomin(1970). I can see why given power there are (uncountably) many sets with different types with this power in the infinite case. For instance, $\aleph_0$ corresponds to the usual order $\omega$ of $\mathbb{N}$ which is  $$ 1,2,3,\dots, $$  but another order type can be written as  $$ 1,3,5,\dots,2,4,6\dots. $$ However, it is claimed that in the finite case there is a unique type for given power. I do not understand this because we can follow the same arguments. For instance take a set with power $2n$, usual order type is $$ 1,2,,\dots,2n $$ in which $2n$ is the maximal element. However, another order type $$ 1,3,5,\dots,2n-1,2n,\dots 2 $$ in which $2$ is the maximal element. I do not see why this argument should not hold. Thanks for any help","This is a general question regarding power (cardinal number)  and type (ordinal number) of a set. These definitions are taken from Kolmogorov and Fomin(1970). I can see why given power there are (uncountably) many sets with different types with this power in the infinite case. For instance, $\aleph_0$ corresponds to the usual order $\omega$ of $\mathbb{N}$ which is  $$ 1,2,3,\dots, $$  but another order type can be written as  $$ 1,3,5,\dots,2,4,6\dots. $$ However, it is claimed that in the finite case there is a unique type for given power. I do not understand this because we can follow the same arguments. For instance take a set with power $2n$, usual order type is $$ 1,2,,\dots,2n $$ in which $2n$ is the maximal element. However, another order type $$ 1,3,5,\dots,2n-1,2n,\dots 2 $$ in which $2$ is the maximal element. I do not see why this argument should not hold. Thanks for any help",,['elementary-set-theory']
58,Does $|X|<|Y|$ imply $\mathcal{P}(X)<\mathcal{P}(Y)?$ [duplicate],Does  imply  [duplicate],|X|<|Y| \mathcal{P}(X)<\mathcal{P}(Y)?,"This question already has an answer here : Bijection between power sets of sets implies bijection between sets? [duplicate] (1 answer) Closed 8 years ago . This might be a terribly simple question, but I cannot convince myself whether the answer is yes or no. Maybe I am missing something simple. I am not well-versed in the area of elementary set theory so excuse the simplicity of the question. Note within a world where $\mathsf{GCH}$ is true we clearly have a yes; but with $\mathsf{GCH}$ false the answer is no longer obvious to me. Exclude the triviality of finite sets. If $|X|<|Y|$ then $|X|<|Y\setminus X|$ so say $|X|=\kappa$, then $|Y|=\kappa+\lambda$ with $\kappa<\lambda$. But then proving $2^{\kappa}<2^{\lambda}$ is equivalent to the initial problem. Am I being silly or is it consistent with $\mathsf{ZFC}$ that this implication is false?","This question already has an answer here : Bijection between power sets of sets implies bijection between sets? [duplicate] (1 answer) Closed 8 years ago . This might be a terribly simple question, but I cannot convince myself whether the answer is yes or no. Maybe I am missing something simple. I am not well-versed in the area of elementary set theory so excuse the simplicity of the question. Note within a world where $\mathsf{GCH}$ is true we clearly have a yes; but with $\mathsf{GCH}$ false the answer is no longer obvious to me. Exclude the triviality of finite sets. If $|X|<|Y|$ then $|X|<|Y\setminus X|$ so say $|X|=\kappa$, then $|Y|=\kappa+\lambda$ with $\kappa<\lambda$. But then proving $2^{\kappa}<2^{\lambda}$ is equivalent to the initial problem. Am I being silly or is it consistent with $\mathsf{ZFC}$ that this implication is false?",,"['elementary-set-theory', 'cardinals']"
59,"A bijection between $[0,1]$ and all $k$-encoded strings",A bijection between  and all -encoded strings,"[0,1] k","Let $X_k$ be a set containing $k$ characters: $X_k=\{x_1, x_2, ..., x_k\}$. $S_n$ is the set of all possible strings encoded by characters in $X_k$ with length $n$: $S_n=\{y_1y_2...y_n|y_i \in X_k, i=1,2,...,n\}$. $S$ is the union of all $S_n$ (all $k$-encoded strings):  $$S=\bigcup_{i=1}^{\infty} S_i$$ Question : Is it possible, or how to write a bijection between $S$ and all reals in $[0,1]$ ? ($[0,1]$ could also be $(0,1)$, $[0,1)$ or $(0,1]$ if the answer is more concise. ) I have found some similar but different questions: Bijection between the reals and the set of permutations of the natural numbers . However, the sequence described in this question is infinite, while my strings have all possible lengths. A bijection between the reals and infinite binary strings . The strings in this question are still infinite. Besides, they're binary. This question originates from my attempt to map all DNA sequences (4-encoded) to $[0,1]$. Then I was wondering if this question could be expanded to any $k$-encoded string. The basic idea was to consider every string as a decimal of base $k$. For example, suppose $X_4=\{0,1,2,3\}$, then string ""23102"" is mapped to 0.23102 (base 4), and string ""321"" is mapped to 0.321 (base 4). However, string ""23102"", ""231020"" and ""2310200"" will all be mapped to 0.23102 (base 4). This situation can be circumvented if the string is binary by adding one extra 1 after the string. For example, consider string ""01"" and ""010"". Transform them by adding the extra 1, and they become ""011"" and ""0101"". Then map them to 0.011 and 0.0101 (both base 2), respectively. This way works because every finite decimal of base 2 will necessarily end up with 1 (and infinite decimals don't have the problem above). But this trick doesn't work when the string is not binary ($k\ne2$).","Let $X_k$ be a set containing $k$ characters: $X_k=\{x_1, x_2, ..., x_k\}$. $S_n$ is the set of all possible strings encoded by characters in $X_k$ with length $n$: $S_n=\{y_1y_2...y_n|y_i \in X_k, i=1,2,...,n\}$. $S$ is the union of all $S_n$ (all $k$-encoded strings):  $$S=\bigcup_{i=1}^{\infty} S_i$$ Question : Is it possible, or how to write a bijection between $S$ and all reals in $[0,1]$ ? ($[0,1]$ could also be $(0,1)$, $[0,1)$ or $(0,1]$ if the answer is more concise. ) I have found some similar but different questions: Bijection between the reals and the set of permutations of the natural numbers . However, the sequence described in this question is infinite, while my strings have all possible lengths. A bijection between the reals and infinite binary strings . The strings in this question are still infinite. Besides, they're binary. This question originates from my attempt to map all DNA sequences (4-encoded) to $[0,1]$. Then I was wondering if this question could be expanded to any $k$-encoded string. The basic idea was to consider every string as a decimal of base $k$. For example, suppose $X_4=\{0,1,2,3\}$, then string ""23102"" is mapped to 0.23102 (base 4), and string ""321"" is mapped to 0.321 (base 4). However, string ""23102"", ""231020"" and ""2310200"" will all be mapped to 0.23102 (base 4). This situation can be circumvented if the string is binary by adding one extra 1 after the string. For example, consider string ""01"" and ""010"". Transform them by adding the extra 1, and they become ""011"" and ""0101"". Then map them to 0.011 and 0.0101 (both base 2), respectively. This way works because every finite decimal of base 2 will necessarily end up with 1 (and infinite decimals don't have the problem above). But this trick doesn't work when the string is not binary ($k\ne2$).",,"['combinatorics', 'elementary-set-theory']"
60,What does this notation |_| mean?,What does this notation |_| mean?,,"I don't know what it is even called so I cannot really type it out properly, sorry. I've seen things like $X$|_|$[0,1)$. The symbol in question looks like $\cup$ but without curvy, round bits, its like the bottom half of a square. I don't know how else to describe it and it look bizarre. Can anyone tell me? Thank you","I don't know what it is even called so I cannot really type it out properly, sorry. I've seen things like $X$|_|$[0,1)$. The symbol in question looks like $\cup$ but without curvy, round bits, its like the bottom half of a square. I don't know how else to describe it and it look bizarre. Can anyone tell me? Thank you",,"['abstract-algebra', 'elementary-set-theory', 'notation']"
61,"Is there a general term for $A\oplus B = \{a \oplus b | a\in A, b\in B\} $?",Is there a general term for ?,"A\oplus B = \{a \oplus b | a\in A, b\in B\} ","Is there a general term that specifies that if an operator $\oplus$ is applied to two sets, it's actually applied to all possible pairs of elements of the two sets? Or is that always the case and goes without saying? Matrix addition for example is also an elemtent-wise operation, but it does not apply the operator to every possible combination of elements, but only some. How would that way-of-applying-an-operator-to-things-that-have-more-things-in-them be called?","Is there a general term that specifies that if an operator $\oplus$ is applied to two sets, it's actually applied to all possible pairs of elements of the two sets? Or is that always the case and goes without saying? Matrix addition for example is also an elemtent-wise operation, but it does not apply the operator to every possible combination of elements, but only some. How would that way-of-applying-an-operator-to-things-that-have-more-things-in-them be called?",,"['elementary-set-theory', 'terminology']"
62,Predicting the number of unique elements in the Cartesian product of a set with itself,Predicting the number of unique elements in the Cartesian product of a set with itself,,"I am a linguist, not a mathematician, so I apologize if there's something wrong with my terminology and/or notation. I have two structures that I want to merge (partially or completely). To generate a list of all possible combinations, I compute the Cartesian product of the two sets of objects, which gives me a set of pairs, and then I compute the [1, ..., n ]-fold Cartesian product of my set of pairs with itself where n is the highest cardinality out of the two structures (here, 5). A = (a1, a2, a3, a4, a5) and B = (b1, b2, b3, b4, b5) Basically, I'm generating 1-tuples like ((a1, b1)), ((a1, b2)), ..., ((a5, b5)) that merge one pair of objects, 2-tuples that merge two pairs of objects, etc. up to n -tuples. I end up with $\sum\limits_{i=1}^{n} (\bar{\bar{A}}\times \bar{\bar{B}})^i$ tuples, where $\bar{\bar{A}}$ and $\bar{\bar{B}}$ represent the cardinalities of the two structures. In this case, I get 10172525 tuples, which is way too high for my needs. I filter my list to only keep tuples if the pairs they contain are all different and cannot be found in another tuple with the same length. This removes up to 99% of the original tuples. For example: ((a1, b1), (a2, b2), (a3, b3)) ((a1, b1), (a3, b3), (a2, b2)) has the same pairs as the preceding tuple, but in a different order ((a1, b1), (a1, b1), (a3, b3)) has the pair (a1, b1) more than once I'm looking for an equation that will help me predict the number of unique tuples. For 1-tuples, there's $\bar{\bar{P}}$ unique tuples where $\bar{\bar{P}}$ is the number of pairs. For 2-tuples, I do $\frac{\bar{\bar{P}}\times (\bar{\bar{P}}-1)}{2}$. I'm sure there's an equation that works for any tuple length, but I can't figure it out. Here are the numbers of tuples generated vs. unique tuples for two structures with 4 objects each: +--------+-----------+--------+ | Length | generated | unique | +--------+-----------+--------+ | 1      |        16 |     16 | | 2      |       256 |    120 | | 3      |      4096 |    560 | | 4      |     65536 |   1820 | | Total  |     69904 |   2516 | +--------+-----------+--------+","I am a linguist, not a mathematician, so I apologize if there's something wrong with my terminology and/or notation. I have two structures that I want to merge (partially or completely). To generate a list of all possible combinations, I compute the Cartesian product of the two sets of objects, which gives me a set of pairs, and then I compute the [1, ..., n ]-fold Cartesian product of my set of pairs with itself where n is the highest cardinality out of the two structures (here, 5). A = (a1, a2, a3, a4, a5) and B = (b1, b2, b3, b4, b5) Basically, I'm generating 1-tuples like ((a1, b1)), ((a1, b2)), ..., ((a5, b5)) that merge one pair of objects, 2-tuples that merge two pairs of objects, etc. up to n -tuples. I end up with $\sum\limits_{i=1}^{n} (\bar{\bar{A}}\times \bar{\bar{B}})^i$ tuples, where $\bar{\bar{A}}$ and $\bar{\bar{B}}$ represent the cardinalities of the two structures. In this case, I get 10172525 tuples, which is way too high for my needs. I filter my list to only keep tuples if the pairs they contain are all different and cannot be found in another tuple with the same length. This removes up to 99% of the original tuples. For example: ((a1, b1), (a2, b2), (a3, b3)) ((a1, b1), (a3, b3), (a2, b2)) has the same pairs as the preceding tuple, but in a different order ((a1, b1), (a1, b1), (a3, b3)) has the pair (a1, b1) more than once I'm looking for an equation that will help me predict the number of unique tuples. For 1-tuples, there's $\bar{\bar{P}}$ unique tuples where $\bar{\bar{P}}$ is the number of pairs. For 2-tuples, I do $\frac{\bar{\bar{P}}\times (\bar{\bar{P}}-1)}{2}$. I'm sure there's an equation that works for any tuple length, but I can't figure it out. Here are the numbers of tuples generated vs. unique tuples for two structures with 4 objects each: +--------+-----------+--------+ | Length | generated | unique | +--------+-----------+--------+ | 1      |        16 |     16 | | 2      |       256 |    120 | | 3      |      4096 |    560 | | 4      |     65536 |   1820 | | Total  |     69904 |   2516 | +--------+-----------+--------+",,['elementary-set-theory']
63,"Is there a metric space $X$ having either $1012$ , or $1036$ , or $1089$ many open sets?","Is there a metric space  having either  , or  , or  many open sets?",X 1012 1036 1089,"Let $X$ be a metric space , $n$ be the no. of open sets in $X$ , then the possible values of $n$ are : 1) $1012$ 2)$1024$ 3)$1036$ 4)$1089$ I know that $1024$ is a possible value because it is a power of $2$ , so if we endow $X$ with discrete metric we are done . My question is , is any other value from the options possible ?","Let $X$ be a metric space , $n$ be the no. of open sets in $X$ , then the possible values of $n$ are : 1) $1012$ 2)$1024$ 3)$1036$ 4)$1089$ I know that $1024$ is a possible value because it is a power of $2$ , so if we endow $X$ with discrete metric we are done . My question is , is any other value from the options possible ?",,['general-topology']
64,Clarification wanted: Let $T$ be the set of all infinite sequences of $0$'s and $1$'s with finitely many $1$'s. Prove that $T$ is denumerable.,Clarification wanted: Let  be the set of all infinite sequences of 's and 's with finitely many 's. Prove that  is denumerable.,T 0 1 1 T,"I think I'm misunderstanding the following proposition. Let $T$ be the set of all infinite sequence of $0$'s and $1$'s with only finitely many $1$'s. Prove that $T$ is denumerable. I'm also given the following lemma to use: Let $\{A_{i}| i\in\mathbb{N}\}$ be a denumerable family of finite non-nonempty sets which are pairwise disjoint, then $\bigcup _{i\in\mathbb{N}}A_{i}$ is denumberable. I'm not quite seeing how adding the condition that there are finitely many $1$'s makes this the set $T$ countable, since there is still a possibility of infintely many $0$'s. It still looks susceptible to the diagonalization argument. Could anyone clear up why the the set is countable?","I think I'm misunderstanding the following proposition. Let $T$ be the set of all infinite sequence of $0$'s and $1$'s with only finitely many $1$'s. Prove that $T$ is denumerable. I'm also given the following lemma to use: Let $\{A_{i}| i\in\mathbb{N}\}$ be a denumerable family of finite non-nonempty sets which are pairwise disjoint, then $\bigcup _{i\in\mathbb{N}}A_{i}$ is denumberable. I'm not quite seeing how adding the condition that there are finitely many $1$'s makes this the set $T$ countable, since there is still a possibility of infintely many $0$'s. It still looks susceptible to the diagonalization argument. Could anyone clear up why the the set is countable?",,[]
65,Is this a way to define an ordinal $\lambda$?,Is this a way to define an ordinal ?,\lambda,A set $\lambda$ is by definition an ordinal if $\forall x\in\lambda : x\subseteq \lambda$ and $\lambda$ is well-ordered by $\in$ . May I equally define an ordinal as a set $\lambda$ having property (1.) and the property $\lambda$ is well-ordered by $\subseteq$ ? A reformulation of the question is this: Let $\lambda$ be a set satisfying property (1.). Does $\lambda$ then satisfies property (2.) if and only if it satisfies property (3.)?,A set $\lambda$ is by definition an ordinal if $\forall x\in\lambda : x\subseteq \lambda$ and $\lambda$ is well-ordered by $\in$ . May I equally define an ordinal as a set $\lambda$ having property (1.) and the property $\lambda$ is well-ordered by $\subseteq$ ? A reformulation of the question is this: Let $\lambda$ be a set satisfying property (1.). Does $\lambda$ then satisfies property (2.) if and only if it satisfies property (3.)?,,"['elementary-set-theory', 'ordinals']"
66,"Prove that $S \subseteq T$ if, and only if, $S \cup T = T$.","Prove that  if, and only if, .",S \subseteq T S \cup T = T,"Prove that $S \subseteq T$ if, and only if, $S \cup T = T$. I tried to solve this question but it seems confusing, here is what i tried to do: Suppose $S \subseteq T$, then we need to show that $S \cup T = T$. So since $S \subseteq T$, we know $x \in S$ so $x \in T$ as well, $S \cup T = T$ is true, due to the fact that if $X \in S$ then  $X \in T$, But I'm not sure about the second part of the proof, I need help.","Prove that $S \subseteq T$ if, and only if, $S \cup T = T$. I tried to solve this question but it seems confusing, here is what i tried to do: Suppose $S \subseteq T$, then we need to show that $S \cup T = T$. So since $S \subseteq T$, we know $x \in S$ so $x \in T$ as well, $S \cup T = T$ is true, due to the fact that if $X \in S$ then  $X \in T$, But I'm not sure about the second part of the proof, I need help.",,['elementary-set-theory']
67,Logical form of family of sets/ power set,Logical form of family of sets/ power set,,"I am working through Daniel Velleman's How To Prove It, but I am having difficulty understanding the given solution. I am asked to translate the following into a logical form (one which explicates set membership with predicate logic): $$ B\in\{ \mathscr P(A) | A\in\mathcal F\}  $$ where $$\mathscr P(A)$$ is the power set of A and $$\mathcal F $$ is a family of sets. $$ B\in\{ \mathscr P(A) | A\in\mathcal F\}  $$ as proven in earlier page, just means $$\exists A\in\mathcal F (B=\mathscr P(A))$$ And the equal sign just means $$ \forall x (x\in B \iff x\in \mathscr P(A)) $$ On the other hand, $$ x\in \mathscr P(A)$$ just means x is a subset of A, where $$\forall y(y \in x \to y\in A) $$. Thus my answer is this: $$\exists A\in\mathcal F\forall y(y\in B \iff y \in x \to y \in A) $$ But the answer given is this: $$\exists A\in\mathcal F\forall x(x\in B \iff \forall y(y \in x \to y \in A)) $$ I know all he did was substituting $$ x\in \mathscr P(A)$$ with $$\forall y(y \in x \to y\in A) $$ but the $$\forall x(x\in B$$ really bugs me. Firstly, since x is an element of the powerset, it must be a set by definition. So why the universal quantifier? Secondly, and this is the most important point, the answer given on the whole just doesn't look like a subset membership formula you normally see. Instead of saying 'All elements of B also belong to the powerset of A', this is saying anything but. Could anyone please help clarify the thinking behind the given answer and verify if my own answer is correct please? Thank you so much! (Pardon my spacing, I am still learning how to use MathJax)","I am working through Daniel Velleman's How To Prove It, but I am having difficulty understanding the given solution. I am asked to translate the following into a logical form (one which explicates set membership with predicate logic): $$ B\in\{ \mathscr P(A) | A\in\mathcal F\}  $$ where $$\mathscr P(A)$$ is the power set of A and $$\mathcal F $$ is a family of sets. $$ B\in\{ \mathscr P(A) | A\in\mathcal F\}  $$ as proven in earlier page, just means $$\exists A\in\mathcal F (B=\mathscr P(A))$$ And the equal sign just means $$ \forall x (x\in B \iff x\in \mathscr P(A)) $$ On the other hand, $$ x\in \mathscr P(A)$$ just means x is a subset of A, where $$\forall y(y \in x \to y\in A) $$. Thus my answer is this: $$\exists A\in\mathcal F\forall y(y\in B \iff y \in x \to y \in A) $$ But the answer given is this: $$\exists A\in\mathcal F\forall x(x\in B \iff \forall y(y \in x \to y \in A)) $$ I know all he did was substituting $$ x\in \mathscr P(A)$$ with $$\forall y(y \in x \to y\in A) $$ but the $$\forall x(x\in B$$ really bugs me. Firstly, since x is an element of the powerset, it must be a set by definition. So why the universal quantifier? Secondly, and this is the most important point, the answer given on the whole just doesn't look like a subset membership formula you normally see. Instead of saying 'All elements of B also belong to the powerset of A', this is saying anything but. Could anyone please help clarify the thinking behind the given answer and verify if my own answer is correct please? Thank you so much! (Pardon my spacing, I am still learning how to use MathJax)",,"['elementary-set-theory', 'proof-verification']"
68,Tricky set proof in Halmos Naive Set Theory,Tricky set proof in Halmos Naive Set Theory,,"Proposition: All sets obtained from successive applications of the axiom of pairing to the empty set are unique. My attempts on this so far are to start with the empty set and pair upwards to an arbitrary number of nested sets, but my professor slams this approach because we haven't yet constructed the idea of ""numbers"", so this proof is meaningless. Instead I'm supposed to ""start from above"" with ""any number(!!) of applications of pairing, and then start stripping away using extension."" What the hell is going on? How do I prove this?","Proposition: All sets obtained from successive applications of the axiom of pairing to the empty set are unique. My attempts on this so far are to start with the empty set and pair upwards to an arbitrary number of nested sets, but my professor slams this approach because we haven't yet constructed the idea of ""numbers"", so this proof is meaningless. Instead I'm supposed to ""start from above"" with ""any number(!!) of applications of pairing, and then start stripping away using extension."" What the hell is going on? How do I prove this?",,['elementary-set-theory']
69,Prove Two Equivalence Relations are Equal,Prove Two Equivalence Relations are Equal,,"I'm doing a self-study through Velleman's ""How to Prove It"" and am working through exercises on equivalence relations.  My proof for the statement below seems unconvincing, and am wondering if someone can help me fill the gaps in the argument. Thanks in advance! Suppose $R$ and $S$ are equivalence relations on $A$ and $A/R = A/S$.  Prove that $R = S$. Proof: Let $(x, y)$ be an element of $R$.  Since $R$ is an equivalence relation, then $x \sim y$, and so $x \in [y]_R$ and $y \in [y]_R$. By definition of $A/R$, we can choose some $X \in A/R$ such that both $x$ and $y$ are elements of $X$.  But since $X \in A/R$,  then $X \in A/S$. And since $S$ is an equivalence relation on $A$, and $x \in X$ and $y \in X$, then $(x, y)$ is also an element of $S$.  Since $(x, y)$ is an arbitrary element of $R$, we have $R \subset S$.  The proof for $S \subset R$ proceeds in the same manner.","I'm doing a self-study through Velleman's ""How to Prove It"" and am working through exercises on equivalence relations.  My proof for the statement below seems unconvincing, and am wondering if someone can help me fill the gaps in the argument. Thanks in advance! Suppose $R$ and $S$ are equivalence relations on $A$ and $A/R = A/S$.  Prove that $R = S$. Proof: Let $(x, y)$ be an element of $R$.  Since $R$ is an equivalence relation, then $x \sim y$, and so $x \in [y]_R$ and $y \in [y]_R$. By definition of $A/R$, we can choose some $X \in A/R$ such that both $x$ and $y$ are elements of $X$.  But since $X \in A/R$,  then $X \in A/S$. And since $S$ is an equivalence relation on $A$, and $x \in X$ and $y \in X$, then $(x, y)$ is also an element of $S$.  Since $(x, y)$ is an arbitrary element of $R$, we have $R \subset S$.  The proof for $S \subset R$ proceeds in the same manner.",,"['elementary-set-theory', 'proof-verification']"
70,Prove composition of two surjections is surjection,Prove composition of two surjections is surjection,,"Suppose $f: A \to B$ and $g: B \to C$ are both surjections. Since $f$ is surjective, then for every $b \in B$ there exists $a \in A$ such that $f(a)= b$.  Since $g$ is surjective, for every $c \in C$, there's  $b \in B$ such that $g(b) = c$. Then $g(f(a)) = g(b) = c$. Would this work? edit; I didn't realize there are similar questions on this site. Don't mind if this post is deleted.","Suppose $f: A \to B$ and $g: B \to C$ are both surjections. Since $f$ is surjective, then for every $b \in B$ there exists $a \in A$ such that $f(a)= b$.  Since $g$ is surjective, for every $c \in C$, there's  $b \in B$ such that $g(b) = c$. Then $g(f(a)) = g(b) = c$. Would this work? edit; I didn't realize there are similar questions on this site. Don't mind if this post is deleted.",,"['elementary-set-theory', 'proof-verification']"
71,"Let $A,B,C,D \subseteq X$ Show that $(A \setminus B ) \bigtriangleup (C \setminus D) \subseteq (A \bigtriangleup C) \cup (B \bigtriangleup D)$",Let  Show that,"A,B,C,D \subseteq X (A \setminus B ) \bigtriangleup (C \setminus D) \subseteq (A \bigtriangleup C) \cup (B \bigtriangleup D)","Let $A,B,C,D \subseteq X$ Show that   $(A \setminus B ) \bigtriangleup (C \setminus D) \subseteq (A \bigtriangleup C) \cup (B \bigtriangleup D)$ My advances $(A \setminus B ) \bigtriangleup (C \setminus D) $ $\rightarrow  \left [ (A \setminus B ) \cap (C \cap D^{c} )^{c} \right ] \cup$  $\left [ (C \setminus D ) \cap ( A \cap B^{c} )^{c} \right ]   $ $\rightarrow \left [ (A \cap B^{c}) \cap (C \cap D^{c} )^{c} \right ] \cup$    $\left [ (C \cap D ^{c}) \cap ( A \cap B^{c} )^{c} \right ]  $ $\rightarrow \left [ (A \cap B^{c}) \cap (C^{c} \cup D) \right] \cup \left [ (C \cap D ^{c}) \cap ( A^{c} \cup B ) \right ]   $ I can't conclude.. I Think, that is necessary find ... $(A \bigtriangleup C ) \cup (B \bigtriangleup D) $ $=\left [ (A \setminus C) \cup (C \setminus  A ) \right ] \cup \left [ (B \setminus  D) \cup (D  \setminus B ) \right ]   $ $\rightarrow \left [ (A \cap C^{c}) \cup (C \cap A ^{c}) \right ] \cup \left [ (B \cap D ^{c}) \cup ( D \cap B^{c}) \right ]   $ but I can't find their relationship..... I need help. Please!!!","Let $A,B,C,D \subseteq X$ Show that   $(A \setminus B ) \bigtriangleup (C \setminus D) \subseteq (A \bigtriangleup C) \cup (B \bigtriangleup D)$ My advances $(A \setminus B ) \bigtriangleup (C \setminus D) $ $\rightarrow  \left [ (A \setminus B ) \cap (C \cap D^{c} )^{c} \right ] \cup$  $\left [ (C \setminus D ) \cap ( A \cap B^{c} )^{c} \right ]   $ $\rightarrow \left [ (A \cap B^{c}) \cap (C \cap D^{c} )^{c} \right ] \cup$    $\left [ (C \cap D ^{c}) \cap ( A \cap B^{c} )^{c} \right ]  $ $\rightarrow \left [ (A \cap B^{c}) \cap (C^{c} \cup D) \right] \cup \left [ (C \cap D ^{c}) \cap ( A^{c} \cup B ) \right ]   $ I can't conclude.. I Think, that is necessary find ... $(A \bigtriangleup C ) \cup (B \bigtriangleup D) $ $=\left [ (A \setminus C) \cup (C \setminus  A ) \right ] \cup \left [ (B \setminus  D) \cup (D  \setminus B ) \right ]   $ $\rightarrow \left [ (A \cap C^{c}) \cup (C \cap A ^{c}) \right ] \cup \left [ (B \cap D ^{c}) \cup ( D \cap B^{c}) \right ]   $ but I can't find their relationship..... I need help. Please!!!",,['elementary-set-theory']
72,Rationals as a dense subset of the reals.,Rationals as a dense subset of the reals.,,"I am having difficulty with a problem in one of my textbooks. It gives three definitions $1$. A set is called a closed set if its complement is open . $2$. The closure of a set E is the intersection of all Closed sets C of which E is a subset . $3$. If is a sets closure is equal to $\mathbb R^n$, then it is dense . The question asks to show that the set of rational numbers are a dense subset of the reals. This is a second year university textbook. Here is what I have so far: To show that the of set rational numbers is dense, it suffices to show that its closure is the set of Real Numbers. The closure of the set of rational numbers is defined to be the intersection of closed sets containing the rational numbers, and is thus the smallest closed set containing the rational numbers. A real number is defined to be the limit of a sequence of rational numbers, and therefore the smallest set that can contain all rational numbers (of which there exists a rational number between every two real numbers) as well as their boundary points (the irrational numbers) is the set of real numbers.","I am having difficulty with a problem in one of my textbooks. It gives three definitions $1$. A set is called a closed set if its complement is open . $2$. The closure of a set E is the intersection of all Closed sets C of which E is a subset . $3$. If is a sets closure is equal to $\mathbb R^n$, then it is dense . The question asks to show that the set of rational numbers are a dense subset of the reals. This is a second year university textbook. Here is what I have so far: To show that the of set rational numbers is dense, it suffices to show that its closure is the set of Real Numbers. The closure of the set of rational numbers is defined to be the intersection of closed sets containing the rational numbers, and is thus the smallest closed set containing the rational numbers. A real number is defined to be the limit of a sequence of rational numbers, and therefore the smallest set that can contain all rational numbers (of which there exists a rational number between every two real numbers) as well as their boundary points (the irrational numbers) is the set of real numbers.",,"['general-topology', 'elementary-set-theory']"
73,Combinatory and Calculus. Computing the sum of...,Combinatory and Calculus. Computing the sum of...,,"Let $S={1,2,....2015}$ all first positive integers. Let $n = 2^{2015} - 1$ for convenience and let $A_1, A_2, .... A_n$ the non-empty subsets of S. For each subset $A_k$, let $P_k$ be the product of its elements (a product of 1 number is itself). Compute the sum $Q_{2015} = P_1+P_2+...P_n$. This what I am thinking: 1# fact: there are $n$ non empty sets formed in S. Knowing this I count the sum of the product when $P_1$={1}, $P_2$ = {1,2} etc. Then: $P_1=1$, $P_2=2!$ , $P_3=3!$, etc  And I will have the first sum $Q_1= 1+2!=3!$.... But I need to count the others sum where the set $P_2$ could be {3, 123}. How can I do this?  Have I any problem in my logic? Is there any way to compute the sum $Q_{2015} = P_1+P_2+...P_n$ ?","Let $S={1,2,....2015}$ all first positive integers. Let $n = 2^{2015} - 1$ for convenience and let $A_1, A_2, .... A_n$ the non-empty subsets of S. For each subset $A_k$, let $P_k$ be the product of its elements (a product of 1 number is itself). Compute the sum $Q_{2015} = P_1+P_2+...P_n$. This what I am thinking: 1# fact: there are $n$ non empty sets formed in S. Knowing this I count the sum of the product when $P_1$={1}, $P_2$ = {1,2} etc. Then: $P_1=1$, $P_2=2!$ , $P_3=3!$, etc  And I will have the first sum $Q_1= 1+2!=3!$.... But I need to count the others sum where the set $P_2$ could be {3, 123}. How can I do this?  Have I any problem in my logic? Is there any way to compute the sum $Q_{2015} = P_1+P_2+...P_n$ ?",,"['calculus', 'combinatorics', 'elementary-set-theory']"
74,Show that $(g \circ f)^{-1}$ is equal to $f^{-1}\circ g^{-1}$ as maps $\mathcal{P}(Z) \rightarrow \mathcal{P}(X)$.,Show that  is equal to  as maps .,(g \circ f)^{-1} f^{-1}\circ g^{-1} \mathcal{P}(Z) \rightarrow \mathcal{P}(X),"Let $f:X\rightarrow Y$ and $g:Y\rightarrow Z$ be maps where the co-domain of $f$ is the domain of $g$; the composite map $g \circ f:X\rightarrow Z$ is thus defined. Show that $(g \circ f)^{-1}$ is equal to $f^{-1}\circ g^{-1}$ as maps $\mathcal{P}(Z) \rightarrow \mathcal{P}(X)$. We know that a map $f:X\rightarrow Y$ can be viewed as a map from $\mathcal{P}(Y)$ to $\mathcal{P}(X)$ which can be further denoted by $f^{-1}$. It's quite straightforward that $(g \circ f)^{-1}$ is define as $\mathcal{P}(Z) \rightarrow \mathcal{P}(X)$ $f^{-1}$ is defined as $Y\rightarrow X$ and $g^{-1}$ is defined as $Z\rightarrow Y$ Hence, $f^{-1}\circ g^{-1}$ is clearly $Z\rightarrow X$ which essentially is $\mathcal{P}(Z) \rightarrow \mathcal{P}(X)$ But is there a more rigorous proof? Because this seems rather obvious. a little TOO obvious if you ask me. Do i have to prove $Z\rightarrow X$ maps to $\mathcal{P}(Z) \rightarrow \mathcal{P}(X)$? The inverse matrix product already gives this fact so i'm not sure if there is a more rigorous proof since it seems so trivial.","Let $f:X\rightarrow Y$ and $g:Y\rightarrow Z$ be maps where the co-domain of $f$ is the domain of $g$; the composite map $g \circ f:X\rightarrow Z$ is thus defined. Show that $(g \circ f)^{-1}$ is equal to $f^{-1}\circ g^{-1}$ as maps $\mathcal{P}(Z) \rightarrow \mathcal{P}(X)$. We know that a map $f:X\rightarrow Y$ can be viewed as a map from $\mathcal{P}(Y)$ to $\mathcal{P}(X)$ which can be further denoted by $f^{-1}$. It's quite straightforward that $(g \circ f)^{-1}$ is define as $\mathcal{P}(Z) \rightarrow \mathcal{P}(X)$ $f^{-1}$ is defined as $Y\rightarrow X$ and $g^{-1}$ is defined as $Z\rightarrow Y$ Hence, $f^{-1}\circ g^{-1}$ is clearly $Z\rightarrow X$ which essentially is $\mathcal{P}(Z) \rightarrow \mathcal{P}(X)$ But is there a more rigorous proof? Because this seems rather obvious. a little TOO obvious if you ask me. Do i have to prove $Z\rightarrow X$ maps to $\mathcal{P}(Z) \rightarrow \mathcal{P}(X)$? The inverse matrix product already gives this fact so i'm not sure if there is a more rigorous proof since it seems so trivial.",,['elementary-set-theory']
75,Into how many equivalences classes does $R$ partition $\mathbb{Z}$?,Into how many equivalences classes does  partition ?,R \mathbb{Z},"Let $R= \{ (a,b) \in\mathbb{Z}\times\mathbb{Z} \mid a^2\equiv b^2 \bmod 7\}$. Into how many equivalences classes does $R$ partition $\mathbb{Z}$? My best guess is that there are $7$ equivalence classes: $a^2-b^2$ has remainder $0 \bmod 7$, $a^2-b^2$ has remainder $1 \bmod 7$, $a^2-b^2$ has remainder $2 \bmod 7, \ldots, a^2-b^2$ has remainder $6 \bmod 7$. Am I misunderstanding equivalence class partitions?","Let $R= \{ (a,b) \in\mathbb{Z}\times\mathbb{Z} \mid a^2\equiv b^2 \bmod 7\}$. Into how many equivalences classes does $R$ partition $\mathbb{Z}$? My best guess is that there are $7$ equivalence classes: $a^2-b^2$ has remainder $0 \bmod 7$, $a^2-b^2$ has remainder $1 \bmod 7$, $a^2-b^2$ has remainder $2 \bmod 7, \ldots, a^2-b^2$ has remainder $6 \bmod 7$. Am I misunderstanding equivalence class partitions?",,"['elementary-set-theory', 'equivalence-relations', 'set-partition']"
76,Indicator Function Distributive Property Proof,Indicator Function Distributive Property Proof,,"This is my first post(: I'm trying to understand how to prove the distributive property using the indicator function.  I have made the truth tables and understand how this is proved using set notation as in this question: Set Distributive Property Proof But I cant seem to understand how to write this using indicator function notation. $\mathbb{A}$ is a proposition about elements $x \in X$ and we put the corresponding set $A = \{x \ \in X: \mathbb{A}(x)\}$. For each $x \in X$ and $A \subset X$ define the indicator function of the set A by \[1_A (x) := \begin{cases}  1 & if \; x \in A \\  0 & if \; x \notin A  \end{cases} \] Further, the ""and"" and ""or"" of this are given by: $ (1_A \wedge 1_B)(x) = 1_A(x) \cdot 1_B(x) = 1_A \cdot 1_B $ $ (1_A \vee 1_B)(x) = 1_A(x) + 1_B(x) - 1_A(x) \cdot 1_B(x) = 1_A + 1_B - 1_A \cdot 1_B$ Prove: $ (\mathbb{A} \vee (\mathbb{B} \wedge \mathbb{C})) \iff ((\mathbb{A} \vee \mathbb{B}) \wedge (\mathbb{A} \vee \mathbb{C})) $ Writing the left side in indicator function notation I think it should be: $ 1_A \vee (1_B \wedge 1_C)(x) = 1_A \vee ( 1_B \cdot 1_C ) = 1_A + (1_B \cdot 1_C) - 1_A \cdot (1_B \cdot 1_C) $ However, the textbook says it should be: $ 1_A \cdot (1_B + 1_C - 1_B \cdot 1_C) $ Which looks like the reverse order of what I think, so I'm stuck here. Thank you!","This is my first post(: I'm trying to understand how to prove the distributive property using the indicator function.  I have made the truth tables and understand how this is proved using set notation as in this question: Set Distributive Property Proof But I cant seem to understand how to write this using indicator function notation. $\mathbb{A}$ is a proposition about elements $x \in X$ and we put the corresponding set $A = \{x \ \in X: \mathbb{A}(x)\}$. For each $x \in X$ and $A \subset X$ define the indicator function of the set A by \[1_A (x) := \begin{cases}  1 & if \; x \in A \\  0 & if \; x \notin A  \end{cases} \] Further, the ""and"" and ""or"" of this are given by: $ (1_A \wedge 1_B)(x) = 1_A(x) \cdot 1_B(x) = 1_A \cdot 1_B $ $ (1_A \vee 1_B)(x) = 1_A(x) + 1_B(x) - 1_A(x) \cdot 1_B(x) = 1_A + 1_B - 1_A \cdot 1_B$ Prove: $ (\mathbb{A} \vee (\mathbb{B} \wedge \mathbb{C})) \iff ((\mathbb{A} \vee \mathbb{B}) \wedge (\mathbb{A} \vee \mathbb{C})) $ Writing the left side in indicator function notation I think it should be: $ 1_A \vee (1_B \wedge 1_C)(x) = 1_A \vee ( 1_B \cdot 1_C ) = 1_A + (1_B \cdot 1_C) - 1_A \cdot (1_B \cdot 1_C) $ However, the textbook says it should be: $ 1_A \cdot (1_B + 1_C - 1_B \cdot 1_C) $ Which looks like the reverse order of what I think, so I'm stuck here. Thank you!",,"['elementary-set-theory', 'proof-writing']"
77,Exercise in set theory,Exercise in set theory,,"Let $\mathbb{N}^{[2]}$ be the set of all sets with two elements in $\mathbb{N}$, and let $\mathbb{N}^{[2]}=A\cup B$. Prove that there is an infinite set $M\subseteq \mathbb{N}$ such that either $M^{[2]}\subseteq A$ or $M^{[2]}\subseteq B$. Any ideas? I found a hint telling to use the well-ordering principle","Let $\mathbb{N}^{[2]}$ be the set of all sets with two elements in $\mathbb{N}$, and let $\mathbb{N}^{[2]}=A\cup B$. Prove that there is an infinite set $M\subseteq \mathbb{N}$ such that either $M^{[2]}\subseteq A$ or $M^{[2]}\subseteq B$. Any ideas? I found a hint telling to use the well-ordering principle",,"['elementary-set-theory', 'infinitary-combinatorics']"
78,Alternate Axiom of Infinity,Alternate Axiom of Infinity,,"The Axiom of Infinity states that there is a set $S$ containing $\varnothing$ such that if $x$ is an element of $S$ then so is $x\cup\{x\}$. Is the following variant equivalent? There exists a nonempty set $S$ such that if $x$ is an element of $S$ then so is $\{x\}$. This one also guarantees an infinite set, and it's shorter. The fact that we use the longer, more complicated one makes me think that the shorter version isn't as strong. Is this correct? EDIT: To be clear, I'm wondering if they're equivalent if I leave the other axioms of ZFC unchanged.","The Axiom of Infinity states that there is a set $S$ containing $\varnothing$ such that if $x$ is an element of $S$ then so is $x\cup\{x\}$. Is the following variant equivalent? There exists a nonempty set $S$ such that if $x$ is an element of $S$ then so is $\{x\}$. This one also guarantees an infinite set, and it's shorter. The fact that we use the longer, more complicated one makes me think that the shorter version isn't as strong. Is this correct? EDIT: To be clear, I'm wondering if they're equivalent if I leave the other axioms of ZFC unchanged.",,"['elementary-set-theory', 'infinity', 'axioms']"
79,Set theory: $A-(B-C)=(A-B)\cup C$.,Set theory: .,A-(B-C)=(A-B)\cup C,"I'm working through the set theory exercises in Apostol's Calculus Volume 1. I'm down to the last problem: Show that one of the following results is always correct and the other one is sometimes wrong. Then find a necessary and sufficient condition for the one that is sometimes wrong to always be correct. i) $A-(B-C)=(A-B)\cup C$ ii) $A-(B\cup C)=(A-B)-C$. So far I've worked out (by drawing some venn diagrams) that (i) is sometimes wrong and (ii) is always correct. I even found a counter-example to (i) so it's definitely sometimes wrong. I proved (ii) is always correct. The ""necessary and sufficient"" condition part is the one that I'm stuck on but I think I found the answer. Basically I've also worked out that if $C\underline{\subset} A$ then $x\in (A-B)\cup C\Rightarrow x\in A-(B-C)$. The motivation for $C\subseteq A$ is as follows: From the right side we see that if $x\in (A-B)\cup C$ then $x\in$ at least one of $(A-B)$ or $C$; now in the case that $x\in C$, we see that $x\not\in A-(B-C)$ unless $C\subseteq A$; this is because $B-C$ gets rid of all $C$ elements in $B$, so that $A-(B-C)$ doesn't get rid of any $C$ elements in $A$, SO ALL $C$'s in $A$ are still there; therefore, in order for $x\in C\Rightarrow x\in A-(B-C)$, we must have $C\subseteq A$, so I'm thinking that maybe $C\subseteq A$ is the condition we are looking for. The only problem now is proving that if $C\subseteq A$ then $x\in A-(B-C)\Rightarrow x\in (A-B)\cup C$ and this is proving difficult. I think my main problem is that I don't know how to manipulate $A-(B-C)$. I've reasoned as follows so far: If $x\in A-(B-C)$ then $x\in A$ and $\not\in (B-C)$. Then $x\in A$ and $\not\in$ the part of $B$ that isn't $C$. (I think saying it like this isn't rigorous enough, but correct if if I'm wrong.) Then there are two cases: $x\in A$ and $x\in B$, so then $x\in C$, since it cannot be in the part of $B$ that isn't $C$. This checks, because $C\subseteq A$. So one possibility is $x\in C$. On the other hand, we could also have $x\in A$ and $x\not\in B$, i.e. $x\in (A-B)$. Thus $x\in(A-B)\cup C$. I'm not sure how rigorous this is and would really like to know how someone experienced would write such a proof. It just seems to be hard to word and I'm having trouble going from step to step in set theory proofs in general due to the ""vagueness"" of such proofs. E.g. What if someone else doesn't agree that my above casework is obvious, and wants something more rigorous? Thanks","I'm working through the set theory exercises in Apostol's Calculus Volume 1. I'm down to the last problem: Show that one of the following results is always correct and the other one is sometimes wrong. Then find a necessary and sufficient condition for the one that is sometimes wrong to always be correct. i) $A-(B-C)=(A-B)\cup C$ ii) $A-(B\cup C)=(A-B)-C$. So far I've worked out (by drawing some venn diagrams) that (i) is sometimes wrong and (ii) is always correct. I even found a counter-example to (i) so it's definitely sometimes wrong. I proved (ii) is always correct. The ""necessary and sufficient"" condition part is the one that I'm stuck on but I think I found the answer. Basically I've also worked out that if $C\underline{\subset} A$ then $x\in (A-B)\cup C\Rightarrow x\in A-(B-C)$. The motivation for $C\subseteq A$ is as follows: From the right side we see that if $x\in (A-B)\cup C$ then $x\in$ at least one of $(A-B)$ or $C$; now in the case that $x\in C$, we see that $x\not\in A-(B-C)$ unless $C\subseteq A$; this is because $B-C$ gets rid of all $C$ elements in $B$, so that $A-(B-C)$ doesn't get rid of any $C$ elements in $A$, SO ALL $C$'s in $A$ are still there; therefore, in order for $x\in C\Rightarrow x\in A-(B-C)$, we must have $C\subseteq A$, so I'm thinking that maybe $C\subseteq A$ is the condition we are looking for. The only problem now is proving that if $C\subseteq A$ then $x\in A-(B-C)\Rightarrow x\in (A-B)\cup C$ and this is proving difficult. I think my main problem is that I don't know how to manipulate $A-(B-C)$. I've reasoned as follows so far: If $x\in A-(B-C)$ then $x\in A$ and $\not\in (B-C)$. Then $x\in A$ and $\not\in$ the part of $B$ that isn't $C$. (I think saying it like this isn't rigorous enough, but correct if if I'm wrong.) Then there are two cases: $x\in A$ and $x\in B$, so then $x\in C$, since it cannot be in the part of $B$ that isn't $C$. This checks, because $C\subseteq A$. So one possibility is $x\in C$. On the other hand, we could also have $x\in A$ and $x\not\in B$, i.e. $x\in (A-B)$. Thus $x\in(A-B)\cup C$. I'm not sure how rigorous this is and would really like to know how someone experienced would write such a proof. It just seems to be hard to word and I'm having trouble going from step to step in set theory proofs in general due to the ""vagueness"" of such proofs. E.g. What if someone else doesn't agree that my above casework is obvious, and wants something more rigorous? Thanks",,"['elementary-set-theory', 'proof-verification']"
80,Show that $T$ is the Set of All Sets Using the ZF Axioms,Show that  is the Set of All Sets Using the ZF Axioms,T,"Let x be a set. Define the ""set"" $S = \left\{ y:x\subseteq y \right\}$ and $T = \cup\left\{y:y\in S \right\}$. Given any set $w$, let $z=x \cup \left\{w\right\}$. Then $x \subseteq z$, so $z \in S$. But $w \in z$, so $w \in T$. I'm supposed to be able to conclude that $T$ happens to be the ""set of all sets"", but I have no idea how to do this and I do not understand the last sentence above this one beginning with ""but"". Please offer some insight to me. Thank you","Let x be a set. Define the ""set"" $S = \left\{ y:x\subseteq y \right\}$ and $T = \cup\left\{y:y\in S \right\}$. Given any set $w$, let $z=x \cup \left\{w\right\}$. Then $x \subseteq z$, so $z \in S$. But $w \in z$, so $w \in T$. I'm supposed to be able to conclude that $T$ happens to be the ""set of all sets"", but I have no idea how to do this and I do not understand the last sentence above this one beginning with ""but"". Please offer some insight to me. Thank you",,['elementary-set-theory']
81,Subsets of the empty set,Subsets of the empty set,,Having read Velleman's 'How to prove it' I came across a question I am not sure I can answer. He states that the power set of the empty set is equal to a set consisting only of the empty set: $ \mathscr P (\emptyset) = \{\emptyset \}. $ That is clear. He then asks what the power set of $\{\emptyset \}$ is. What is $ \mathscr P (\{\emptyset \})$ equal to? Thanks in advance.,Having read Velleman's 'How to prove it' I came across a question I am not sure I can answer. He states that the power set of the empty set is equal to a set consisting only of the empty set: $ \mathscr P (\emptyset) = \{\emptyset \}. $ That is clear. He then asks what the power set of $\{\emptyset \}$ is. What is $ \mathscr P (\{\emptyset \})$ equal to? Thanks in advance.,,['elementary-set-theory']
82,The Union of $n$ Independent Events Equals the Complement of the Complement of Their Product,The Union of  Independent Events Equals the Complement of the Complement of Their Product,n,"The Statement of the Problem: If the events $A_1,...,A_n$ are independent, show that $$ P\left(\bigcup_{i=1}^n A_i \right) = 1-\prod_{i=1}^n P(A_i^c) .$$ Where I Am: So, I've seen this equality stated before, but it doesn't actually make sense to me for the following reason: $$ P\left(\bigcup_{i=1}^n A_i \right)= P\left(\bigcap_{i=1}^n A_i^c \right) \text{(by De Morgan's Laws) and}$$ $$ P\left(\bigcap_{i=1}^n A_i^c \right) = \prod_{i=1}^n P(A_i^c) $$ ...rather than the complement of the products of these independent events. Where did I go wrong?","The Statement of the Problem: If the events $A_1,...,A_n$ are independent, show that $$ P\left(\bigcup_{i=1}^n A_i \right) = 1-\prod_{i=1}^n P(A_i^c) .$$ Where I Am: So, I've seen this equality stated before, but it doesn't actually make sense to me for the following reason: $$ P\left(\bigcup_{i=1}^n A_i \right)= P\left(\bigcap_{i=1}^n A_i^c \right) \text{(by De Morgan's Laws) and}$$ $$ P\left(\bigcap_{i=1}^n A_i^c \right) = \prod_{i=1}^n P(A_i^c) $$ ...rather than the complement of the products of these independent events. Where did I go wrong?",,"['probability', 'elementary-set-theory']"
83,Proof of recursion theorem,Proof of recursion theorem,,"I was going through a real analysis textbook The Real Numbers and Real Analysis this morning, and I encountered a theorem stating that: Let $H$ be a set, let $e\in H$ and $k:H\rightarrow H$ be a function. Then there always exists a unique function $f:\mathbb{N}\rightarrow H$ such that $f(1)=e$, and that $f(n+1)=k(f(n))$ for all $n\in\mathbb{N}$. As a 1st year undergrad in maths, I have little knowledge in set theory except for the basics, but I simply couldn't help but wonder why does one have to consider the set $$C=\lbrace W\subseteq \mathbb{N}\times H\mid (1,e) \in W,\,\text{and if}\,(n,y)\in W,\,(n+1,k(y))\in W\rbrace$$ and let $f=\bigcap W\in C$ to prove $f$ does have the desired property and it is indeed a function. Instead, could I not just define the relation to be $$W=\lbrace (a,b)\in \mathbb{N}\times H\mid (1,e) \in W,\,\text{and if}\,(n,y)\in W,\,(n+1,k(y))\in W\rbrace?$$ I know this sounds rather silly, but is there a reason why I can't define a set in this way? Is it because that the set builder notation actually involves the set itself, so I have to justify the existence of such a set beforehand? Or is it because of some other reason?","I was going through a real analysis textbook The Real Numbers and Real Analysis this morning, and I encountered a theorem stating that: Let $H$ be a set, let $e\in H$ and $k:H\rightarrow H$ be a function. Then there always exists a unique function $f:\mathbb{N}\rightarrow H$ such that $f(1)=e$, and that $f(n+1)=k(f(n))$ for all $n\in\mathbb{N}$. As a 1st year undergrad in maths, I have little knowledge in set theory except for the basics, but I simply couldn't help but wonder why does one have to consider the set $$C=\lbrace W\subseteq \mathbb{N}\times H\mid (1,e) \in W,\,\text{and if}\,(n,y)\in W,\,(n+1,k(y))\in W\rbrace$$ and let $f=\bigcap W\in C$ to prove $f$ does have the desired property and it is indeed a function. Instead, could I not just define the relation to be $$W=\lbrace (a,b)\in \mathbb{N}\times H\mid (1,e) \in W,\,\text{and if}\,(n,y)\in W,\,(n+1,k(y))\in W\rbrace?$$ I know this sounds rather silly, but is there a reason why I can't define a set in this way? Is it because that the set builder notation actually involves the set itself, so I have to justify the existence of such a set beforehand? Or is it because of some other reason?",,"['real-analysis', 'elementary-set-theory']"
84,Does the Russell Set exist?,Does the Russell Set exist?,,"I am currently reading ""Naive set Theory"" by Paul Halmos. In the second chapter, on the axiom of specification we show that the Universal Set does not exist. The proof is the following: Lets define $R$ as: $R=\{x \in A\mid x \notin x\}$ Lets suppose that $R \in A$, there are two options: $R \in R$. We reach an immediate contradiction, since, if $R \in R$ then $R \not\in R.$ $R \not\in R$. And again we reach a contradiction since, if $R \not\in R$, and $R \in A$, then $R \in R$. We can conclude therefore that $R \not\in A$. And since the set $A$ is completely arbitrary, we conclude that no set contains everything, because no set contains $R$. Therefore, there is no universe. But, if we suppose that $R$ does exist, and assuming the existence of the empty set, with the Axiom of Pairing, I should be able to create a set in which both $R$ and $\emptyset$, belong to. Let's call this new set $U$. But since we said that $R$ can not be a member of any set, then $R$ can not be a member of $U$. The only solution to this problem I can think of, would be to restrict the Axiom of Pairing, such that it could be expressed as: For any two sets $X$, $Y$, if $X$ is a member of a set $N$, and $Y$ is a member of a set $M$, then there exists a set $U$, such that both $X$, $Y$ are members of it. And since $R$ is not a member of any set, it wouldn't be a valid choice for the Axiom of Pairing. Is the solution correct? Have I maybe completely misunderstood the axiom of Pairing? And even if we define the axiom of Pairing as above, $R$ is not a member of any set, but does it exist? Because if we conclude that it doesn't, we can ignore our proof that the Universe does not exist.","I am currently reading ""Naive set Theory"" by Paul Halmos. In the second chapter, on the axiom of specification we show that the Universal Set does not exist. The proof is the following: Lets define $R$ as: $R=\{x \in A\mid x \notin x\}$ Lets suppose that $R \in A$, there are two options: $R \in R$. We reach an immediate contradiction, since, if $R \in R$ then $R \not\in R.$ $R \not\in R$. And again we reach a contradiction since, if $R \not\in R$, and $R \in A$, then $R \in R$. We can conclude therefore that $R \not\in A$. And since the set $A$ is completely arbitrary, we conclude that no set contains everything, because no set contains $R$. Therefore, there is no universe. But, if we suppose that $R$ does exist, and assuming the existence of the empty set, with the Axiom of Pairing, I should be able to create a set in which both $R$ and $\emptyset$, belong to. Let's call this new set $U$. But since we said that $R$ can not be a member of any set, then $R$ can not be a member of $U$. The only solution to this problem I can think of, would be to restrict the Axiom of Pairing, such that it could be expressed as: For any two sets $X$, $Y$, if $X$ is a member of a set $N$, and $Y$ is a member of a set $M$, then there exists a set $U$, such that both $X$, $Y$ are members of it. And since $R$ is not a member of any set, it wouldn't be a valid choice for the Axiom of Pairing. Is the solution correct? Have I maybe completely misunderstood the axiom of Pairing? And even if we define the axiom of Pairing as above, $R$ is not a member of any set, but does it exist? Because if we conclude that it doesn't, we can ignore our proof that the Universe does not exist.",,"['elementary-set-theory', 'axioms', 'paradoxes']"
85,formal definition of ordinal addition by recursion,formal definition of ordinal addition by recursion,,"I'm reading Kunen's Set Theory, An Introduction to Independence Proofs (1980). On page 26 he explains how to introduce ordinal addition through recursion. For the sake of convenience i'll give the necessary information. What does Transfinite Recursion state? It states the following: For any formula F $(x,y)$ we can define a formula G $(v,y)$ such that $$\forall x \; \exists ! \; y F(x,y) \to [\forall \alpha \; \exists ! \; y \; \mathrm{{\bf G}}(\alpha, y) \wedge \forall \alpha \exists x \exists y \; (\mathrm{{\bf G}}(\alpha, y) \wedge \mathrm{{\bf F}}(x, y) \wedge x = \mathrm{{\bf G}}|\alpha)],$$   where $x = \mathrm{{\bf G}}|\alpha$ abbreviates   $$ x \mathrm{\;is\; a \; function} \wedge \mathrm{dom}\;x = \alpha \wedge \forall \beta\in\mathrm{dom}\;x \;\; \mathrm{{\bf G}}(\beta,x(\beta))$$ So it says in fact that for any formula F $(x,y)$ which under certain conditions (if applied for instance by Comprehension Scheme to define a subset of some set) can define a set of ordered pairs (i.e. a relation) which is a function, then we can define a formula G $(v,y)$ which is also a function (it can be viewed as a function on the class of all ordinals) such that its value on any ordinal is exactly the value of F on the set which is the restriction of G to $\alpha$. Next addition of ordinals by means of recursion is defined as follows. For any ordinal $\alpha$ a function $\mathrm{{\bf F}}_\alpha$ is defined so that $\mathrm{{\bf F}}_\alpha(x) = 0$ unless $x$ is a function with domain some ordinal $\beta$, in which case $\mathrm{{\bf F}}_\alpha(x)$ is $\alpha$ if $\beta = 0$, $S(x(\beta - 1))$ if $\beta$ is a successor and $\bigcup \{x(\xi) : \xi < \beta\}$ if $\beta$ is limit. and here my troubles begin, in fact. First of all, The successor function $S$ was previously defined only for ordinals. Okay, we may count that $S(x) = x\cup \{x\}$ for any set $x$. But then the definition of $\mathrm{{\bf F}}_\alpha$ just doesn't make sense... i mean why it gives the desired result... Then we get this unique function $\mathrm{{\bf G}}_\alpha$ (these formulas are treated as functions on classes) defined on ordinals such that $\forall \beta [\mathrm{{\bf G}}_\alpha(\beta) = \mathrm{{\bf F}}_\alpha(\mathrm{{\bf G}}_\alpha|\beta)]$. So this function gives us the addition in fact because, given any ordinal $\beta$, what is $\mathrm{{\bf G}}_\alpha |\beta$? it is, loosely speaking, the set of all ordered pairs $(a,y)$ such that $a\in\beta$ and $y = \mathrm{{\bf G}}_\alpha (\beta)$ (so it is a function which assigns to each ordinal $a \subset \beta$ some $y$ such that $y = \mathrm{{\bf G}}_\alpha(a)$)... And then we say that if $\beta$ is a successor, to calculate $\mathrm{{\bf G}}_\alpha (\beta)$ this $\mathrm{{\bf F}}_\alpha$ has to give out the successor of the value of $\mathrm{{\bf G}}_\alpha$ on $\beta - 1$ (i.e. it is $S(\alpha + \beta - 1)$ in fact, and if $\beta$ is limit, $\mathrm{{\bf F}}_\alpha$ has to give out an ordinal in fact which is the supremum of the values of $\mathrm{{\bf G}}_\alpha$ on ordinals lesser than $\beta$, i.e. it is (in different notation) $\bigcup \{\alpha + \xi | \xi < \beta\}$, so hence this function $\mathrm{{\bf G}}_\alpha$ defines the true addition (which can be defined without recursion as the unique ordinal isomorphic to a certain well-ordered set obtained on the basis of $\alpha$ and $\beta$)? Okay, how can we define multiplication formally then? First we define this $\mathrm{{\bf F}}_\alpha$ to be again 0 unless $x$ is a function with domain some ordinal $\beta$. In case $x$ is as desired, define $\mathrm{{\bf F}}_\alpha(x)$ to be 0 if $\beta = 0$, $x(\beta - 1) + \alpha$ if $\beta$ is a successor and $\bigcup \{x(\xi)|\xi < \beta\}$ if $\beta$ is limit. And then we get the unique $\mathrm{{\bf G}}_\alpha$ which in fact for any ordinal $\beta$ gives us the $\alpha\cdot \beta$? is that right? Thank you for reading and any suggestions...","I'm reading Kunen's Set Theory, An Introduction to Independence Proofs (1980). On page 26 he explains how to introduce ordinal addition through recursion. For the sake of convenience i'll give the necessary information. What does Transfinite Recursion state? It states the following: For any formula F $(x,y)$ we can define a formula G $(v,y)$ such that $$\forall x \; \exists ! \; y F(x,y) \to [\forall \alpha \; \exists ! \; y \; \mathrm{{\bf G}}(\alpha, y) \wedge \forall \alpha \exists x \exists y \; (\mathrm{{\bf G}}(\alpha, y) \wedge \mathrm{{\bf F}}(x, y) \wedge x = \mathrm{{\bf G}}|\alpha)],$$   where $x = \mathrm{{\bf G}}|\alpha$ abbreviates   $$ x \mathrm{\;is\; a \; function} \wedge \mathrm{dom}\;x = \alpha \wedge \forall \beta\in\mathrm{dom}\;x \;\; \mathrm{{\bf G}}(\beta,x(\beta))$$ So it says in fact that for any formula F $(x,y)$ which under certain conditions (if applied for instance by Comprehension Scheme to define a subset of some set) can define a set of ordered pairs (i.e. a relation) which is a function, then we can define a formula G $(v,y)$ which is also a function (it can be viewed as a function on the class of all ordinals) such that its value on any ordinal is exactly the value of F on the set which is the restriction of G to $\alpha$. Next addition of ordinals by means of recursion is defined as follows. For any ordinal $\alpha$ a function $\mathrm{{\bf F}}_\alpha$ is defined so that $\mathrm{{\bf F}}_\alpha(x) = 0$ unless $x$ is a function with domain some ordinal $\beta$, in which case $\mathrm{{\bf F}}_\alpha(x)$ is $\alpha$ if $\beta = 0$, $S(x(\beta - 1))$ if $\beta$ is a successor and $\bigcup \{x(\xi) : \xi < \beta\}$ if $\beta$ is limit. and here my troubles begin, in fact. First of all, The successor function $S$ was previously defined only for ordinals. Okay, we may count that $S(x) = x\cup \{x\}$ for any set $x$. But then the definition of $\mathrm{{\bf F}}_\alpha$ just doesn't make sense... i mean why it gives the desired result... Then we get this unique function $\mathrm{{\bf G}}_\alpha$ (these formulas are treated as functions on classes) defined on ordinals such that $\forall \beta [\mathrm{{\bf G}}_\alpha(\beta) = \mathrm{{\bf F}}_\alpha(\mathrm{{\bf G}}_\alpha|\beta)]$. So this function gives us the addition in fact because, given any ordinal $\beta$, what is $\mathrm{{\bf G}}_\alpha |\beta$? it is, loosely speaking, the set of all ordered pairs $(a,y)$ such that $a\in\beta$ and $y = \mathrm{{\bf G}}_\alpha (\beta)$ (so it is a function which assigns to each ordinal $a \subset \beta$ some $y$ such that $y = \mathrm{{\bf G}}_\alpha(a)$)... And then we say that if $\beta$ is a successor, to calculate $\mathrm{{\bf G}}_\alpha (\beta)$ this $\mathrm{{\bf F}}_\alpha$ has to give out the successor of the value of $\mathrm{{\bf G}}_\alpha$ on $\beta - 1$ (i.e. it is $S(\alpha + \beta - 1)$ in fact, and if $\beta$ is limit, $\mathrm{{\bf F}}_\alpha$ has to give out an ordinal in fact which is the supremum of the values of $\mathrm{{\bf G}}_\alpha$ on ordinals lesser than $\beta$, i.e. it is (in different notation) $\bigcup \{\alpha + \xi | \xi < \beta\}$, so hence this function $\mathrm{{\bf G}}_\alpha$ defines the true addition (which can be defined without recursion as the unique ordinal isomorphic to a certain well-ordered set obtained on the basis of $\alpha$ and $\beta$)? Okay, how can we define multiplication formally then? First we define this $\mathrm{{\bf F}}_\alpha$ to be again 0 unless $x$ is a function with domain some ordinal $\beta$. In case $x$ is as desired, define $\mathrm{{\bf F}}_\alpha(x)$ to be 0 if $\beta = 0$, $x(\beta - 1) + \alpha$ if $\beta$ is a successor and $\bigcup \{x(\xi)|\xi < \beta\}$ if $\beta$ is limit. And then we get the unique $\mathrm{{\bf G}}_\alpha$ which in fact for any ordinal $\beta$ gives us the $\alpha\cdot \beta$? is that right? Thank you for reading and any suggestions...",,"['elementary-set-theory', 'ordinals']"
86,Isomorphic or equal?,Isomorphic or equal?,,"Let $\sim_n$ be the usual equivalence relation of congruence modulo $n$ in $\mathbb{Z}$, i.e., for $a,b\in\mathbb{Z}$, $a\sim_nb\Leftrightarrow a-b=k\cdot n$ for some $k\in\mathbb{Z}$. For $n=0$ the element in the equivalence class of, say, $a\in\mathbb{Z}$ is just $a$ itself . So to every element of $\mathbb{Z}/\sim_0$ corresponds one, and only one, element of $\mathbb{Z}$. My question is: What is mathematically more correct, to say that the two sets $\mathbb{Z}/\sim_0$ and $\mathbb{Z}$ are equal or to say that those rings are isomorphic ?","Let $\sim_n$ be the usual equivalence relation of congruence modulo $n$ in $\mathbb{Z}$, i.e., for $a,b\in\mathbb{Z}$, $a\sim_nb\Leftrightarrow a-b=k\cdot n$ for some $k\in\mathbb{Z}$. For $n=0$ the element in the equivalence class of, say, $a\in\mathbb{Z}$ is just $a$ itself . So to every element of $\mathbb{Z}/\sim_0$ corresponds one, and only one, element of $\mathbb{Z}$. My question is: What is mathematically more correct, to say that the two sets $\mathbb{Z}/\sim_0$ and $\mathbb{Z}$ are equal or to say that those rings are isomorphic ?",,"['abstract-algebra', 'elementary-set-theory', 'ring-theory', 'terminology', 'equivalence-relations']"
87,Cantor-Bernstein Proof,Cantor-Bernstein Proof,,"Currently, I am studying Set Theory, and have come to the point of proving the Cantor-Bernstein Theorem (if $|A| \leq |B|$ and $|B| \leq |A|$, then $|A| = |B|$).  Now, I am studying from Jech and Hrbacek's ""Introduction to Set Theory,"" but my professor provided me with a proof of the theorem that is significantly different from the book.  I worked through it, and I think I get the gist of it, but things start unravelling at the end and I need help understanding it.  So, Statement:  If $\phi:A\rightarrow B$ and $\psi:B\rightarrow A$ are one-to-one functions, then $A$ is equipotent to $B$. Proof: For $a,a'\in A$, set $a\equiv a' \iff \exists\ k\in\mathbb{N}\ s.t. (\phi^{-1}\circ\psi^{-1})^k(a)=a'$. Then clearly $\equiv$ is an equivalence relation (I have a hard time proving this, but this is beyond the point I suppose). Consider the set of equivalence classes $H$ of $\equiv$.  Then, any $E\in H$ is one of two types: i) $\forall\ a\in E, \exists\ a'\ s.t.\ a' = \phi^{-1}\circ\psi^{-1}(a)$ ii) $\exists\ \dot a\in E \ s.t.\ \dot a \notin\ any\ (\psi\circ\phi)$ In this case, $\dot a$ is at the top of the class (in the obvious order).  Such an $\dot a$ is of two types: 1) $\psi^{-1}(\dot a)$ exists but $\phi^{-1}\circ\psi^{-1}(\dot a)$ doesn't. 2) $\psi^{-1}(\dot a)$ doesn't exist. We then define $\eta: A\rightarrow B$ by: $\eta(a) = \phi(a)$ if $[a]$ is of type (i) or of type (ii)-2 and $\eta(a) = \psi^{-1}(a)$ if otherwise. Claim: $\eta$ is one-to-one:  Consider $\eta(a)=\eta(a')$.  Then clearly $[a]=[a']$.  Hence, if $[a]$ is of type (ii)-1, then $\eta(a) = \psi^{-1}(a) = \psi^{-1}(a') = \eta(a')$, and since $\psi^{-1}$ is one-to-one, $a=a'$.  If $[a]$ is of type (i) or (ii)-2, then $\eta(a) = \phi(a) = \phi(a') = \eta(a')$, and since $\phi$ is one-to-one, $a=a'$. Claim: $\eta$ is onto:  Let $b\in B$ and consider $\psi(b)=a$.  If $[a]$ is of type (i) or (ii)-2, then $\phi^{-1}(b)$ exists and $\eta(\phi^{-1}(b))=b$.  If $[a]$ is of type (ii)-1, then $\eta(a)=b$. Therefore, there exists a bijection between $A$ and $B$ so that they are equipotent. QED Really, defining our $\equiv$ relation is straightforward and makes since in pictures.  But when we start getting into the different types I get a little shaky.  Type (i) is just saying that $(\phi^{-1}\circ\psi^{-1})$ gets mapped to something for any $a$ within the equivalence class.  Is type (ii) just saying the opposite?  That is, there is some $a$ within the equivalence class that $(\phi^{-1}\circ\psi^{-1})$ can't be mapped from?  The changing of the wording throws me off, and I'm not sure the significance of it. Now, if (ii) is true, then it has to be one of the other two types trivially, correct?  For either (1) or (2), $(\phi^{-1}\circ\psi^{-1})(\dot a)$ can't exist simply because it fell into type (ii).  At this point, are we just saying $\phi^{-1}(\dot a$ either works or doesn't? I suppose the big problem here is that I'm not understanding things intuitively.  He drew a picture which looks like a function mapping some $a$ between $A$ and $B$ in a cascading way, but I don't know what to make of the picture other than that fact that we can keep reapplying out composite or one of our original functions to move around between the sets. If anyone can shed any light on this proof that may make it easier for me to understand, I'd appreciate it.  And I tried my best to eliminate any errors in it, but if something seems wrong, there's a good chance it is, so let me know.","Currently, I am studying Set Theory, and have come to the point of proving the Cantor-Bernstein Theorem (if $|A| \leq |B|$ and $|B| \leq |A|$, then $|A| = |B|$).  Now, I am studying from Jech and Hrbacek's ""Introduction to Set Theory,"" but my professor provided me with a proof of the theorem that is significantly different from the book.  I worked through it, and I think I get the gist of it, but things start unravelling at the end and I need help understanding it.  So, Statement:  If $\phi:A\rightarrow B$ and $\psi:B\rightarrow A$ are one-to-one functions, then $A$ is equipotent to $B$. Proof: For $a,a'\in A$, set $a\equiv a' \iff \exists\ k\in\mathbb{N}\ s.t. (\phi^{-1}\circ\psi^{-1})^k(a)=a'$. Then clearly $\equiv$ is an equivalence relation (I have a hard time proving this, but this is beyond the point I suppose). Consider the set of equivalence classes $H$ of $\equiv$.  Then, any $E\in H$ is one of two types: i) $\forall\ a\in E, \exists\ a'\ s.t.\ a' = \phi^{-1}\circ\psi^{-1}(a)$ ii) $\exists\ \dot a\in E \ s.t.\ \dot a \notin\ any\ (\psi\circ\phi)$ In this case, $\dot a$ is at the top of the class (in the obvious order).  Such an $\dot a$ is of two types: 1) $\psi^{-1}(\dot a)$ exists but $\phi^{-1}\circ\psi^{-1}(\dot a)$ doesn't. 2) $\psi^{-1}(\dot a)$ doesn't exist. We then define $\eta: A\rightarrow B$ by: $\eta(a) = \phi(a)$ if $[a]$ is of type (i) or of type (ii)-2 and $\eta(a) = \psi^{-1}(a)$ if otherwise. Claim: $\eta$ is one-to-one:  Consider $\eta(a)=\eta(a')$.  Then clearly $[a]=[a']$.  Hence, if $[a]$ is of type (ii)-1, then $\eta(a) = \psi^{-1}(a) = \psi^{-1}(a') = \eta(a')$, and since $\psi^{-1}$ is one-to-one, $a=a'$.  If $[a]$ is of type (i) or (ii)-2, then $\eta(a) = \phi(a) = \phi(a') = \eta(a')$, and since $\phi$ is one-to-one, $a=a'$. Claim: $\eta$ is onto:  Let $b\in B$ and consider $\psi(b)=a$.  If $[a]$ is of type (i) or (ii)-2, then $\phi^{-1}(b)$ exists and $\eta(\phi^{-1}(b))=b$.  If $[a]$ is of type (ii)-1, then $\eta(a)=b$. Therefore, there exists a bijection between $A$ and $B$ so that they are equipotent. QED Really, defining our $\equiv$ relation is straightforward and makes since in pictures.  But when we start getting into the different types I get a little shaky.  Type (i) is just saying that $(\phi^{-1}\circ\psi^{-1})$ gets mapped to something for any $a$ within the equivalence class.  Is type (ii) just saying the opposite?  That is, there is some $a$ within the equivalence class that $(\phi^{-1}\circ\psi^{-1})$ can't be mapped from?  The changing of the wording throws me off, and I'm not sure the significance of it. Now, if (ii) is true, then it has to be one of the other two types trivially, correct?  For either (1) or (2), $(\phi^{-1}\circ\psi^{-1})(\dot a)$ can't exist simply because it fell into type (ii).  At this point, are we just saying $\phi^{-1}(\dot a$ either works or doesn't? I suppose the big problem here is that I'm not understanding things intuitively.  He drew a picture which looks like a function mapping some $a$ between $A$ and $B$ in a cascading way, but I don't know what to make of the picture other than that fact that we can keep reapplying out composite or one of our original functions to move around between the sets. If anyone can shed any light on this proof that may make it easier for me to understand, I'd appreciate it.  And I tried my best to eliminate any errors in it, but if something seems wrong, there's a good chance it is, so let me know.",,['elementary-set-theory']
88,Proof that every field $F$ has an algebraic closure $\bar F$,Proof that every field  has an algebraic closure,F \bar F,"I am reading the book A First Course in Abstract Algebra written by Fraleigh and I do not really understand the proof of theorem 31.22, that every field $F$ has and algebraic closure $\bar F$. I notice that many people has asked this question before but I still don't understand. Basically, one need to construct a set $S$ that contains all algebraic extension fields of $F$ and use Zorn's Lemma to assure the maximal element $\bar F$. However we need to assure the set $S$ is a 'legal' set which won't fall into the trap of Russell paradox, as shown below (by Fraleigh): I am confused with the construction of $\Omega$. I assume that $A$ is the set of all zeros in $F[x]$ and $\Omega=P(A)$ which has $\it{cardinallity}$ strictly greater then $A$. Since every $\alpha\in F$ is a zero of the polynomial $f_\alpha=x-\alpha$, one has $\omega _{f_\alpha1}=\alpha$. I rename $\{\omega _{f_\alpha1}\}\in P(A)=\Omega$ as the element $\alpha$ so $F\subset \Omega$ would make sense. Then choose any $\gamma \in E$ and rename every element in $F(\gamma)$ with different $\omega\in \Omega\backslash F$. This is how I understand Fraleigh's proof. My question is: After assigning names to every element in $F(\gamma)$ by $F(\omega)$, then the 'remaining elements' in $\Omega$ would have the size $\Omega\backslash (F\cup F(\omega))$. How can one guarantee that it is still large enough to rename the other extension fields? Also, in the proof, $\gamma$ is get from $E$. What we know is all elements in $F(\gamma)$ is renamed and contained in $\Omega$. But it does not mean that $E\subset \Omega$. And thirdly, I suppose the construction is followed in this procedures: Find $\gamma_1$ and make $F(\gamma_1)$ into $\Omega$. Find another $\gamma_2$ and make $F(\gamma_2)$ into $\Omega$, and so on. This is a step by step procedures and I can only make $countably$ many $F(\gamma_i)$ into $\Omega$. How can I know $\Omega$ is actually large enough to contain maybe uncountably many extension fields?","I am reading the book A First Course in Abstract Algebra written by Fraleigh and I do not really understand the proof of theorem 31.22, that every field $F$ has and algebraic closure $\bar F$. I notice that many people has asked this question before but I still don't understand. Basically, one need to construct a set $S$ that contains all algebraic extension fields of $F$ and use Zorn's Lemma to assure the maximal element $\bar F$. However we need to assure the set $S$ is a 'legal' set which won't fall into the trap of Russell paradox, as shown below (by Fraleigh): I am confused with the construction of $\Omega$. I assume that $A$ is the set of all zeros in $F[x]$ and $\Omega=P(A)$ which has $\it{cardinallity}$ strictly greater then $A$. Since every $\alpha\in F$ is a zero of the polynomial $f_\alpha=x-\alpha$, one has $\omega _{f_\alpha1}=\alpha$. I rename $\{\omega _{f_\alpha1}\}\in P(A)=\Omega$ as the element $\alpha$ so $F\subset \Omega$ would make sense. Then choose any $\gamma \in E$ and rename every element in $F(\gamma)$ with different $\omega\in \Omega\backslash F$. This is how I understand Fraleigh's proof. My question is: After assigning names to every element in $F(\gamma)$ by $F(\omega)$, then the 'remaining elements' in $\Omega$ would have the size $\Omega\backslash (F\cup F(\omega))$. How can one guarantee that it is still large enough to rename the other extension fields? Also, in the proof, $\gamma$ is get from $E$. What we know is all elements in $F(\gamma)$ is renamed and contained in $\Omega$. But it does not mean that $E\subset \Omega$. And thirdly, I suppose the construction is followed in this procedures: Find $\gamma_1$ and make $F(\gamma_1)$ into $\Omega$. Find another $\gamma_2$ and make $F(\gamma_2)$ into $\Omega$, and so on. This is a step by step procedures and I can only make $countably$ many $F(\gamma_i)$ into $\Omega$. How can I know $\Omega$ is actually large enough to contain maybe uncountably many extension fields?",,"['abstract-algebra', 'elementary-set-theory', 'field-theory', 'axiom-of-choice']"
89,Unordered cartesian product?,Unordered cartesian product?,,"I have a set $\Omega=\{1;2;6\}$ and I want to define another set $A$ consisting of all triples $(a,b,c)$ with $a,b,c\in\Omega$, which contain exactly two 6's. My first attempt looked like this: $A=\{a^2\times b\vert a=\{6\},b=\{1;2\}\}$ But after looking at the cartesian product's definition, it looks like my set $A$ consists of all triples having two 6's as their first two elements instead of all triples containing two 6's. So here is my second attempt: $A=\{(a^2\times b)\cup(a\times b\times a)\cup(b\times a^2)\vert a=\{6\},b=\{1;2\}\}$ So my questions are, if my last definition of $A$ would be correct (?), if there is a way to shorten the definition of $A$ (?) and if there is something like an ""unordered cartesian product""?","I have a set $\Omega=\{1;2;6\}$ and I want to define another set $A$ consisting of all triples $(a,b,c)$ with $a,b,c\in\Omega$, which contain exactly two 6's. My first attempt looked like this: $A=\{a^2\times b\vert a=\{6\},b=\{1;2\}\}$ But after looking at the cartesian product's definition, it looks like my set $A$ consists of all triples having two 6's as their first two elements instead of all triples containing two 6's. So here is my second attempt: $A=\{(a^2\times b)\cup(a\times b\times a)\cup(b\times a^2)\vert a=\{6\},b=\{1;2\}\}$ So my questions are, if my last definition of $A$ would be correct (?), if there is a way to shorten the definition of $A$ (?) and if there is something like an ""unordered cartesian product""?",,"['elementary-set-theory', 'cross-product']"
90,How to prove that $\aleph_0+\aleph_0=\aleph_0$,How to prove that,\aleph_0+\aleph_0=\aleph_0,"How to prove that $\aleph_0+\aleph_0=\aleph_0$ In my exercise book I have that proof: Let $B=2\mathbb{N}+1$ and $A=2\mathbb{N}$ $A,B $ disjoint and $A+B=\aleph_0$ But to me it looks like example and not a proof.",How to prove that In my exercise book I have that proof: Let and disjoint and But to me it looks like example and not a proof.,"\aleph_0+\aleph_0=\aleph_0 B=2\mathbb{N}+1 A=2\mathbb{N} A,B  A+B=\aleph_0",[]
91,Having trouble in understanding what subset of a poset means.,Having trouble in understanding what subset of a poset means.,,"I am having a problem to visualise a subset of a poset. Let $S = \{a,b,c\}$. Then $\mathcal{P}(S) = \{\{\},\{a\}, \{b\},\{c\},\{a,b\},\{a,c\},\{b,c\},\{a,b,c\} \}$. Now if I impose $\subseteq$ on $\mathcal{P}(S)$, then the partial order relation is $ R = \{(\{\},\{a\}),(\{\},\{b\}),(\{a\},\{a,b\})(\{c\},\{a,b,c\}),(\{a,b\},\{a,b,c\}), \cdots\}$. Now, the partial order set or poset is $(S, R)$. I am not understanding what should be the subset of a poset like this. Can any kind-hearted one help me understanding this?","I am having a problem to visualise a subset of a poset. Let $S = \{a,b,c\}$. Then $\mathcal{P}(S) = \{\{\},\{a\}, \{b\},\{c\},\{a,b\},\{a,c\},\{b,c\},\{a,b,c\} \}$. Now if I impose $\subseteq$ on $\mathcal{P}(S)$, then the partial order relation is $ R = \{(\{\},\{a\}),(\{\},\{b\}),(\{a\},\{a,b\})(\{c\},\{a,b,c\}),(\{a,b\},\{a,b,c\}), \cdots\}$. Now, the partial order set or poset is $(S, R)$. I am not understanding what should be the subset of a poset like this. Can any kind-hearted one help me understanding this?",,['elementary-set-theory']
92,Empty conditional,Empty conditional,,"I have the following set $$M_{\delta} = \{x\in\mathbb{R}^n\mid x_i\ge1,i=1,\ldots,n,x_j\le 1+\delta , j\in\varnothing\}$$ and I'm not sure how to evaluate it. There is no such $j$ such that the empty set contains it, so is $M_\delta$ empty, or does the condition on $x_j$ just become meaningless?","I have the following set $$M_{\delta} = \{x\in\mathbb{R}^n\mid x_i\ge1,i=1,\ldots,n,x_j\le 1+\delta , j\in\varnothing\}$$ and I'm not sure how to evaluate it. There is no such $j$ such that the empty set contains it, so is $M_\delta$ empty, or does the condition on $x_j$ just become meaningless?",,['elementary-set-theory']
93,A challenge in Prof.Terence Tao's book “Analysis”: Using axiom of specification to define image of a function,A challenge in Prof.Terence Tao's book “Analysis”: Using axiom of specification to define image of a function,,"On page 64 (3.4 Images and Inverse Images) of ""Analysis I"" by Terence Tao, it says: Note that the set $f(S)$ ($f$ is a function) is well-defined thanks to the axiom of   replacement (Axiom 3.6). One can also define $f(S)$ using the axiom of   specification (Axiom 3.5) instead of replacement, but we leave this as   a challenge to the reader. right below the definition 3.4.1 (image of sets). (In case any ambiguity caused by incompleteness of pre-knowledge, here is the definition of function given in the same book: Definition 3.3.1 (Functions). Let $X$, $Y$ be sets, and let $P(x,y)$ be a   property pertaining to an object $x\in X$ and an object $y \in Y$, such that   for every $x\in X$, there is exactly one $y \in Y$ for which $P(x,y)$ is true   (this is sometimes known as the vertical line test). Then we define   the function $f:X\rightarrow Y$ defined by $P$ on the domain $X$ and range $Y$ to be   the object which, given any input $x\in X$, assigns an output $f(x) \in Y$,   defined to be the unique object $f(x)$ for which $P(x, f(x))$ is true.   Thus, for any $x\in X$ and $y \in Y$, $$y=f(x) \Leftrightarrow P(x, y) \textrm{ is true.}$$ ) It is quite obvious for me to see how to define f(S) by using axiom of replacement. However, it bothers me for a bit too long to ""beat off"" the challenge left to the reader. My thinking so far is to somehow construct a property $P(y)\ $that just depends on $y \in Y$ and somehow relates to the domain $S \subseteq X$ (motivation is simply from the format of the set given by axiom of specification $ \lbrace x \in A\mid P(x) \rbrace $). I am not sure but I guess that I did not understand the dependence between the property and the variables very well. That means, I am not sure in which situation the appearance of two variables like ($x$ and $y$) would be allowed to construct a property $P(x)$ or $P(y)$, or even it's not possible to do this. I don't know... So I wish I could get some useful hint or enlightenment. In fact, I would be more excited about the feeling of reading three lines then ""Ah-Ha! That's how it's done"", than a complete solution (though I accept it definitely). By the way, I am a pre-service math teacher right now (not an undergrad student), thus this is not a question for any assignment. I appreciate for any help on this question. Zach","On page 64 (3.4 Images and Inverse Images) of ""Analysis I"" by Terence Tao, it says: Note that the set $f(S)$ ($f$ is a function) is well-defined thanks to the axiom of   replacement (Axiom 3.6). One can also define $f(S)$ using the axiom of   specification (Axiom 3.5) instead of replacement, but we leave this as   a challenge to the reader. right below the definition 3.4.1 (image of sets). (In case any ambiguity caused by incompleteness of pre-knowledge, here is the definition of function given in the same book: Definition 3.3.1 (Functions). Let $X$, $Y$ be sets, and let $P(x,y)$ be a   property pertaining to an object $x\in X$ and an object $y \in Y$, such that   for every $x\in X$, there is exactly one $y \in Y$ for which $P(x,y)$ is true   (this is sometimes known as the vertical line test). Then we define   the function $f:X\rightarrow Y$ defined by $P$ on the domain $X$ and range $Y$ to be   the object which, given any input $x\in X$, assigns an output $f(x) \in Y$,   defined to be the unique object $f(x)$ for which $P(x, f(x))$ is true.   Thus, for any $x\in X$ and $y \in Y$, $$y=f(x) \Leftrightarrow P(x, y) \textrm{ is true.}$$ ) It is quite obvious for me to see how to define f(S) by using axiom of replacement. However, it bothers me for a bit too long to ""beat off"" the challenge left to the reader. My thinking so far is to somehow construct a property $P(y)\ $that just depends on $y \in Y$ and somehow relates to the domain $S \subseteq X$ (motivation is simply from the format of the set given by axiom of specification $ \lbrace x \in A\mid P(x) \rbrace $). I am not sure but I guess that I did not understand the dependence between the property and the variables very well. That means, I am not sure in which situation the appearance of two variables like ($x$ and $y$) would be allowed to construct a property $P(x)$ or $P(y)$, or even it's not possible to do this. I don't know... So I wish I could get some useful hint or enlightenment. In fact, I would be more excited about the feeling of reading three lines then ""Ah-Ha! That's how it's done"", than a complete solution (though I accept it definitely). By the way, I am a pre-service math teacher right now (not an undergrad student), thus this is not a question for any assignment. I appreciate for any help on this question. Zach",,"['real-analysis', 'elementary-set-theory']"
94,Is it consistent without the axiom of choice that every permutation of some infinite set have fixed points?,Is it consistent without the axiom of choice that every permutation of some infinite set have fixed points?,,"A ""permutation"" of a non-empty set means an injective mapping of the set onto itself. Let $S(1)$ be the statement ""There exists a permutation of every set containing at least two elements, which has no fixed points"". Let $S(2)$ be the statement ""There exists an infinite set, all of whose permutations have at least one fixed point"". All the proofs I have seen of $S(1)$ make use of Zorn's Lemma, which is equivalent to the Axiom of Choice. Is it possibe that the consistency of ZF-without the Axiom of Choice-implies the consistency of ZF $+S(2)$?","A ""permutation"" of a non-empty set means an injective mapping of the set onto itself. Let $S(1)$ be the statement ""There exists a permutation of every set containing at least two elements, which has no fixed points"". Let $S(2)$ be the statement ""There exists an infinite set, all of whose permutations have at least one fixed point"". All the proofs I have seen of $S(1)$ make use of Zorn's Lemma, which is equivalent to the Axiom of Choice. Is it possibe that the consistency of ZF-without the Axiom of Choice-implies the consistency of ZF $+S(2)$?",,"['elementary-set-theory', 'permutations', 'axiom-of-choice']"
95,How do I find the coordinate relationship between numbers on a number spiral?,How do I find the coordinate relationship between numbers on a number spiral?,,"For instance, considering the number spiral below, If I wanted to say where the number $10$ was in relation to the number $18$, I might say something like relationship $(18,10) = (4,-2)$ since it is $4$ places to the right and two places down. Is there a general formula for this or a relatively simple algorithm to compute this relationship for any two positive integers on the spiral?","For instance, considering the number spiral below, If I wanted to say where the number $10$ was in relation to the number $18$, I might say something like relationship $(18,10) = (4,-2)$ since it is $4$ places to the right and two places down. Is there a general formula for this or a relatively simple algorithm to compute this relationship for any two positive integers on the spiral?",,"['number-theory', 'elementary-set-theory']"
96,Composition of equivalence relations,Composition of equivalence relations,,"As part of a HW assignment in the course elementary set theory, I was given the following question: Let $A$ be a set and let $T$ and $S$ be two equivalence relations on $A$ . Prove: $S\circ T=T\circ S \iff S\circ T$ is an equivalence relation The $\Longleftarrow $ direction was not so difficult but I had a problem with the $\Longrightarrow $ direction. I managed to prove reflexiveness and symmetry of $S\circ T$ , but cannot prove the transitivity of $S\circ T$ . Any suggestions?","As part of a HW assignment in the course elementary set theory, I was given the following question: Let be a set and let and be two equivalence relations on . Prove: is an equivalence relation The direction was not so difficult but I had a problem with the direction. I managed to prove reflexiveness and symmetry of , but cannot prove the transitivity of . Any suggestions?",A T S A S\circ T=T\circ S \iff S\circ T \Longleftarrow  \Longrightarrow  S\circ T S\circ T,"['elementary-set-theory', 'equivalence-relations']"
97,"The sets $\{-x,x\}$ form a partition of $\mathbb Z$",The sets  form a partition of,"\{-x,x\} \mathbb Z","I've been really trying to understand how some of these proofs work; I've spent a majority of my time studying the material for this class, but I'm still performing poorly in it. It doesn't help that the book is very vague; what's worse is that it contains little to no solutions and does not have a solutions manual, so I don't even know if I'm right or wrong half the time. Anyways, in the problem, we are asked to prove that a set is a partition. A problem from the book: Prove that $P=\left\{X: X = \{-x,x\} \space \text{and} \space x\in\mathbb{N} \cup\{0\}\right\}$ is a partition on $\mathbb{Z}$. Recalling that the three criteria of a partition are that: If $X$ is an element of the partition, $X$ cannot be empty. If $X$ and $Y$ are elements of the partition, they are equal or pairwise disjoint. The union of all the elements in the partition are equal to the set we are taking the partition of. I'd greatly appreciate help. I understand what the criteria demand intuitively, but I just can't seem to connect the logic when I do the proofs.","I've been really trying to understand how some of these proofs work; I've spent a majority of my time studying the material for this class, but I'm still performing poorly in it. It doesn't help that the book is very vague; what's worse is that it contains little to no solutions and does not have a solutions manual, so I don't even know if I'm right or wrong half the time. Anyways, in the problem, we are asked to prove that a set is a partition. A problem from the book: Prove that $P=\left\{X: X = \{-x,x\} \space \text{and} \space x\in\mathbb{N} \cup\{0\}\right\}$ is a partition on $\mathbb{Z}$. Recalling that the three criteria of a partition are that: If $X$ is an element of the partition, $X$ cannot be empty. If $X$ and $Y$ are elements of the partition, they are equal or pairwise disjoint. The union of all the elements in the partition are equal to the set we are taking the partition of. I'd greatly appreciate help. I understand what the criteria demand intuitively, but I just can't seem to connect the logic when I do the proofs.",,"['elementary-set-theory', 'set-partition']"
98,"Prove that if $A$ is a countable set, and is a subset of $\Bbb R$, then there exists a real number $x$ such that $A$ intersect $A + x$ is disjoint.","Prove that if  is a countable set, and is a subset of , then there exists a real number  such that  intersect  is disjoint.",A \Bbb R x A A + x,"I am struggling with this question, and any help would be appreciated. I hope I'm clear with the terminology though.","I am struggling with this question, and any help would be appreciated. I hope I'm clear with the terminology though.",,['elementary-set-theory']
99,Can we halve the real number,Can we halve the real number,,"Intuitive formulation:Can we halve the real numbers in a way that changes its density by half and does not alter its analytic properties. Formal statement:Is there a subset $A$ of $\mathbb{R}$ such that $A$ is dense and $$|A\cap[a,b]|=|(\mathbb{R}-A)\cap[a,b]|=|\mathbb{R}\cap[a,b]|$$ for all $a,b\in\mathbb{R}$","Intuitive formulation:Can we halve the real numbers in a way that changes its density by half and does not alter its analytic properties. Formal statement:Is there a subset $A$ of $\mathbb{R}$ such that $A$ is dense and $$|A\cap[a,b]|=|(\mathbb{R}-A)\cap[a,b]|=|\mathbb{R}\cap[a,b]|$$ for all $a,b\in\mathbb{R}$",,"['elementary-set-theory', 'real-numbers']"
