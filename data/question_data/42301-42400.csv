,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Showing $K(\sqrt \alpha)/F$ is Galois if and only if $\sigma(\alpha)/\alpha$ is a unit and a square.,Showing  is Galois if and only if  is a unit and a square.,K(\sqrt \alpha)/F \sigma(\alpha)/\alpha,"I would like help solving is the following problem: Assume that $K/F$ is a finite Galois extension and $\text{char} F \neq 2$ . Let $G:= \text{Gal}(K/F)$ be its Galois group and let $\alpha \in K^\times$ . Show that $K(\sqrt{\alpha})/F$ is a Galois extension if and only if $\frac{\sigma(\alpha)}{\alpha} \in K^{\times 2}$ for all $\sigma \in G$ , where $K^{\times 2} := \{x^2 \mid x \in K^\times\}$ . I have part of a solution for the reverse implication, but I am unsure where I use the hypothesis, so I am not confident of its validity. My argument goes as follows: if $\alpha$ is a perfect square, then $K(\sqrt{\alpha}) = K$ and the solution is trivial. Suppose $\alpha$ is not a perfect square. Then, the minimal polynomial of $\sqrt \alpha$ over $K$ is $x^2 - \alpha$ . This means $[K(\sqrt\alpha) : K] = 2$ . By the tower law, we have $[K(\sqrt{\alpha}), F] = [K(\sqrt{\alpha}): K] [K : F] = 2 |G|$ . Given any $\sigma \in G$ , we can extend it to an automorphism of $K(\sqrt \alpha)$ by choosing whether sigma will send $\sqrt \alpha$ to $+\sqrt{\sigma(\alpha)}$ or $-\sqrt{\sigma(\alpha)}$ (SEE EDIT BELOW). As $\text{char} F \neq 2$ , this gives 2 choices for every $\sigma \in G$ , hence we can have $2 |G|$ automorphisms, constructed in this way. As $|\text{Gal}(K(\sqrt \alpha), F)|$ is bounded above by $[K(\sqrt \alpha): F] = 2|G|$ , we have constructed every possible automorphism and $|\text{Gal}(K(\sqrt \alpha), F)| = [K(\sqrt \alpha): F]$ , so the extension is Galois. As far as I can tell, this doesn't use the hypothesis on $\frac{\sigma(\alpha)}{\alpha}$ , so I am sceptical. Help with both directions of the proof would be greatly appreciated. Edit: Following the comments from Μάρκος Καραμέρης, as $\sigma(\alpha) =  \alpha . k^2$ , $\sigma(\sqrt(\alpha)) = \pm k \sqrt \alpha$ , for some fixed $k \in K^\times$ . This gives us our extensions from $\sigma \in \text{Gal}(K/F)$ to some pair $\sigma_+, \sigma_- \in K(\sqrt \alpha)$ , where $\sigma_\pm (\sqrt(\alpha)) = \pm k \sqrt \alpha$ . This completes the reverse implication.","I would like help solving is the following problem: Assume that is a finite Galois extension and . Let be its Galois group and let . Show that is a Galois extension if and only if for all , where . I have part of a solution for the reverse implication, but I am unsure where I use the hypothesis, so I am not confident of its validity. My argument goes as follows: if is a perfect square, then and the solution is trivial. Suppose is not a perfect square. Then, the minimal polynomial of over is . This means . By the tower law, we have . Given any , we can extend it to an automorphism of by choosing whether sigma will send to or (SEE EDIT BELOW). As , this gives 2 choices for every , hence we can have automorphisms, constructed in this way. As is bounded above by , we have constructed every possible automorphism and , so the extension is Galois. As far as I can tell, this doesn't use the hypothesis on , so I am sceptical. Help with both directions of the proof would be greatly appreciated. Edit: Following the comments from Μάρκος Καραμέρης, as , , for some fixed . This gives us our extensions from to some pair , where . This completes the reverse implication.","K/F \text{char} F \neq 2 G:= \text{Gal}(K/F) \alpha \in K^\times K(\sqrt{\alpha})/F \frac{\sigma(\alpha)}{\alpha} \in K^{\times 2} \sigma \in G K^{\times 2} := \{x^2 \mid x \in K^\times\} \alpha K(\sqrt{\alpha}) = K \alpha \sqrt \alpha K x^2 - \alpha [K(\sqrt\alpha) : K] = 2 [K(\sqrt{\alpha}), F] = [K(\sqrt{\alpha}): K] [K : F] = 2 |G| \sigma \in G K(\sqrt \alpha) \sqrt \alpha +\sqrt{\sigma(\alpha)} -\sqrt{\sigma(\alpha)} \text{char} F \neq 2 \sigma \in G 2 |G| |\text{Gal}(K(\sqrt \alpha), F)| [K(\sqrt \alpha): F] = 2|G| |\text{Gal}(K(\sqrt \alpha), F)| = [K(\sqrt \alpha): F] \frac{\sigma(\alpha)}{\alpha} \sigma(\alpha) =  \alpha . k^2 \sigma(\sqrt(\alpha)) = \pm k \sqrt \alpha k \in K^\times \sigma \in \text{Gal}(K/F) \sigma_+, \sigma_- \in K(\sqrt \alpha) \sigma_\pm (\sqrt(\alpha)) = \pm k \sqrt \alpha","['abstract-algebra', 'field-theory', 'galois-theory', 'galois-extensions']"
1,ideals with fixed norm in a Dedekind domain,ideals with fixed norm in a Dedekind domain,,"Given a general Dedekind domain $R$ is it true that there are at most finitely many prime ideals of $R$ with the same given norm? By ""norm"" I mean the index of the ideal in $R$ , assumed to be finite.","Given a general Dedekind domain is it true that there are at most finitely many prime ideals of with the same given norm? By ""norm"" I mean the index of the ideal in , assumed to be finite.",R R R,"['abstract-algebra', 'ring-theory', 'commutative-algebra']"
2,The importance and applications of order of a group?,The importance and applications of order of a group?,,"Recently, I'm exposed to some exercises and theorems concerning order of a group. For example, If an abelian group has subgroups of orders $m$ and $n$, respectively, then it has a subgroup whose order is $\operatorname{lcm}(m,n)$. A simple proof of Sylow theorem for abelian groups If a finite group $G$ of order $n$ has at most one subgroup of each order $d|n$, then $G$ is cyclic IMHO, the classic result of this kind is Sylow theorems that appear in most standard textbooks about abstract algebra. As such, I would like to ask about the importance of order of a group in abstract algebra and its applications in other branches of mathemactics. Thank you for your elaboration!","Recently, I'm exposed to some exercises and theorems concerning order of a group. For example, If an abelian group has subgroups of orders $m$ and $n$, respectively, then it has a subgroup whose order is $\operatorname{lcm}(m,n)$. A simple proof of Sylow theorem for abelian groups If a finite group $G$ of order $n$ has at most one subgroup of each order $d|n$, then $G$ is cyclic IMHO, the classic result of this kind is Sylow theorems that appear in most standard textbooks about abstract algebra. As such, I would like to ask about the importance of order of a group in abstract algebra and its applications in other branches of mathemactics. Thank you for your elaboration!",,"['abstract-algebra', 'group-theory', 'sylow-theory']"
3,A computation with ramification groups,A computation with ramification groups,,"I am trying to solve Exercise 3, Chapter 4, $\S 2$ of Local Fields by Serre. The exercise is about ramification groups. Let $L/K$ be a $p$ -adic field extension with uniformizer $\pi$ . Assume it is Galois with Galois group $G$ . Let $e$ be the ramification index of $L$ over $\mathbf Q_p$ . Take $s$ in the $i$ -th ramification group $G_i$ , $i \geq 1$ , and denote by $a\in (\pi^i)$ the element such that $s(\pi) = \pi(1+a)$ . Knowing that $s(x)-x \equiv jax \pmod{\pi^{i+j+1}}$ for all $x\in \pi^{j}$ , show that for all $x \in (\pi^j)$ and $i > \frac{e}{p-1}$ the following holds: $$   s^p(x) -x \equiv pjax \pmod{\pi^{i+j+e+1}} $$ Does anybody have an idea of how to solve this? The book gives as a hint ""use the binomial formula"".","I am trying to solve Exercise 3, Chapter 4, of Local Fields by Serre. The exercise is about ramification groups. Let be a -adic field extension with uniformizer . Assume it is Galois with Galois group . Let be the ramification index of over . Take in the -th ramification group , , and denote by the element such that . Knowing that for all , show that for all and the following holds: Does anybody have an idea of how to solve this? The book gives as a hint ""use the binomial formula"".","\S 2 L/K p \pi G e L \mathbf Q_p s i G_i i \geq 1 a\in (\pi^i) s(\pi) = \pi(1+a) s(x)-x \equiv jax \pmod{\pi^{i+j+1}} x\in \pi^{j} x \in (\pi^j) i > \frac{e}{p-1} 
  s^p(x) -x \equiv pjax \pmod{\pi^{i+j+e+1}}
","['abstract-algebra', 'number-theory', 'algebraic-number-theory']"
4,Show that the number of nonisomorphic finite groups of order $n$ is at most $n^{n^2}.$,Show that the number of nonisomorphic finite groups of order  is at most,n n^{n^2}.,"I have a question. I am supposed to prove the following theorem: Let $n \in \mathbb{N}$ be a natural number. Show that: the number of nonisomorphic groups of order $n$ is less than or equal to $n^{n^2}$ . My reasoning: A set $G$ is a group if it's equiped with a binary operation/map: $G\times G \rightarrow G, \space (g_1,g_2)\rightarrow g_1 \circ g_2$ . Additionally two groups $G,H$ are isomorphic $G \cong H$ if there exists a isomorphism $f:G \rightarrow H$ . Now, for each such map $G\times G \rightarrow G$ we get a different group. Because there are $n^{n^2}$ such different maps (for $|G|=n$ ), the number of all possible different groups should be $\leq n^{n^2}$ . And since we have different binary operations defined on the same set, we should get different multiplication (Cayley) tables, we would have $f(a)\star f(b)\neq f(a \circ b)$ for $a,b \in G$ and some bijection $f$ . Meaning that, since homomorphisms don't exist, all those different groups are nonisomorphic and we have therefore shown the above theorem to be true. More intuitively: The statement of beeing (non) isomorphic can be translated to (not) having the same multiplication table. If we have a group of order $n$ , then the multiplication table should be of size $n\times n= n^2$ . Each of the $n^2$ entries (in the table) has $n$ possible entries, representing a different choice of the above mentioned binary operation. Because those possibilities multiply, we would have: $n\times \cdots \times n=n^{n^2}$ and each table beeing different, those groups are nonisomorphic. My question: Is my reasoning, in both cases, correct? Am I missing something? How would I prove, more formally,  that for different binary operations defined on the same set we get different nonisomorphic groups? Related questions: Number of distinct groups of order n upto isomorphism, for a fixed integer n. The number of groups of order n(upto isomorphism)is Comment: I am a physicist and don't have major ambitions in abstract algebra, please be nice.","I have a question. I am supposed to prove the following theorem: Let be a natural number. Show that: the number of nonisomorphic groups of order is less than or equal to . My reasoning: A set is a group if it's equiped with a binary operation/map: . Additionally two groups are isomorphic if there exists a isomorphism . Now, for each such map we get a different group. Because there are such different maps (for ), the number of all possible different groups should be . And since we have different binary operations defined on the same set, we should get different multiplication (Cayley) tables, we would have for and some bijection . Meaning that, since homomorphisms don't exist, all those different groups are nonisomorphic and we have therefore shown the above theorem to be true. More intuitively: The statement of beeing (non) isomorphic can be translated to (not) having the same multiplication table. If we have a group of order , then the multiplication table should be of size . Each of the entries (in the table) has possible entries, representing a different choice of the above mentioned binary operation. Because those possibilities multiply, we would have: and each table beeing different, those groups are nonisomorphic. My question: Is my reasoning, in both cases, correct? Am I missing something? How would I prove, more formally,  that for different binary operations defined on the same set we get different nonisomorphic groups? Related questions: Number of distinct groups of order n upto isomorphism, for a fixed integer n. The number of groups of order n(upto isomorphism)is Comment: I am a physicist and don't have major ambitions in abstract algebra, please be nice.","n \in \mathbb{N} n n^{n^2} G G\times G \rightarrow G, \space (g_1,g_2)\rightarrow g_1 \circ g_2 G,H G \cong H f:G \rightarrow H G\times G \rightarrow G n^{n^2} |G|=n \leq n^{n^2} f(a)\star f(b)\neq f(a \circ b) a,b \in G f n n\times n= n^2 n^2 n n\times \cdots \times n=n^{n^2}","['abstract-algebra', 'group-theory', 'finite-groups']"
5,"Prove there are no simple groups of even order $<500$ except orders $2$, $60$, $168$, and $360$.","Prove there are no simple groups of even order  except orders , , , and .",<500 2 60 168 360,"In Dummit & Foote, Abstract Algebra , $\S6.2$ , Exercise 17(b) is: Prove there are no simple groups of even order $<500$ except orders $2$ , $60$ , $168$ , and $360$ . The fact that the we have to check all groups of less $<500$ makes me think there is a faster way of solving this rather than brute force. Even using various formulas to wipe out entire families of orders still seems like it would take an unreasonable amount of effort for an exercise. Is there something I'm missing with this problem? Is there a faster way to reduce the work that I am not seeing?","In Dummit & Foote, Abstract Algebra , , Exercise 17(b) is: Prove there are no simple groups of even order except orders , , , and . The fact that the we have to check all groups of less makes me think there is a faster way of solving this rather than brute force. Even using various formulas to wipe out entire families of orders still seems like it would take an unreasonable amount of effort for an exercise. Is there something I'm missing with this problem? Is there a faster way to reduce the work that I am not seeing?",\S6.2 <500 2 60 168 360 <500,"['abstract-algebra', 'group-theory', 'finite-groups', 'simple-groups']"
6,Role of $d^2 = 0$ in chain complex,Role of  in chain complex,d^2 = 0,"What is the motivation for requiring that the square of a differential be $0$ for a complex, aside from enabling us to speak of the homology of a complex? Other homological notions like chain maps, homotopic maps, homotopy equivalences seem to be meaningful without any restriction on the differential (of course, no longer do homotopic maps induce isomorphisms on Homology, for Homology no longer is meaningful). If we ignore any connections to Homology, is there some other moral reason to want that the differential square to $0$ ?","What is the motivation for requiring that the square of a differential be for a complex, aside from enabling us to speak of the homology of a complex? Other homological notions like chain maps, homotopic maps, homotopy equivalences seem to be meaningful without any restriction on the differential (of course, no longer do homotopic maps induce isomorphisms on Homology, for Homology no longer is meaningful). If we ignore any connections to Homology, is there some other moral reason to want that the differential square to ?",0 0,"['abstract-algebra', 'homology-cohomology', 'homological-algebra', 'differential-forms']"
7,Is the free product of residually finite groups always residually finite?,Is the free product of residually finite groups always residually finite?,,"Suppose groups $G$ and $H$ are residually finite. Does that imply, that $G \ast H$ is residually finite? What have I tried to prove this: Suppose, $a = g_1h_1g_2h_2…g_nh_n \in G \ast H$ , $g_1, .. g_n \in G$ , $h_1, … , h_n \in H$ and $b = g_1g_2…g_n \neq e$ , then the natural homomorphism $\alpha: G \ast H \to \frac{G \ast H}{\langle \langle H \rangle \rangle} \cong G$ maps $a$ to $b$ . Now suppose, that $\beta$ is the homomorphism from $G$ to a finite group $K$ , such that $\beta(b)$ is non-trivial (such homomorphism exists as $G$ is residually finite). Then $\beta \alpha$ is the homomorphism that maps $a$ to a non-trivial element of a finite group. The same arguments can be applied in case, when $h_1h_2 …  h_n \neq e$ . However, I do not know, what to do in case, when $g_1g_2…g_n = h_1h_2 …  h_n = e$ .","Suppose groups and are residually finite. Does that imply, that is residually finite? What have I tried to prove this: Suppose, , , and , then the natural homomorphism maps to . Now suppose, that is the homomorphism from to a finite group , such that is non-trivial (such homomorphism exists as is residually finite). Then is the homomorphism that maps to a non-trivial element of a finite group. The same arguments can be applied in case, when . However, I do not know, what to do in case, when .","G H G \ast H a = g_1h_1g_2h_2…g_nh_n \in G \ast H g_1, .. g_n \in G h_1, … , h_n \in H b = g_1g_2…g_n \neq e \alpha: G \ast H \to \frac{G \ast H}{\langle \langle H \rangle \rangle} \cong G a b \beta G K \beta(b) G \beta \alpha a h_1h_2 …  h_n \neq e g_1g_2…g_n = h_1h_2 …  h_n = e","['abstract-algebra', 'group-theory', 'group-homomorphism', 'infinite-groups', 'free-product']"
8,Cokernel in Categories of Module (Exercise 4.4 in Blyth's book),Cokernel in Categories of Module (Exercise 4.4 in Blyth's book),,"i have been working on ""Module Theory:An Approach to Linear Algebra"" by T. S. Blyth and i am stuck on exercise 4.4 which is ""Let $f: M \to N $ be an $R$ -morphism. By a cokernel of $f$ we mean a pair $(P,\pi)$ consisting of an $R$ -module $P$ together with an $R$ -epimorphism $\pi: N\to P$ such that (1) $\pi \circ f = 0$ (2) for every $R$ -module X and every $R$ -morphism $g:N\to X$ such that $g\circ f = 0$ there is a unique $R$ -morphism $\alpha: X\to P$ such that $\pi = g \circ \alpha$ . Prove that $(N/Imf, \phi)$ ( $\phi$ is the canonical mapping) is a cokernel of $f$ . "" (1) is not that hard, but for (2) i can only prove that there exist a unique $R$ -morphism $h:N/Imf \to X$ not the other way around which is required. Am i missing something? Is it possible that the definition of the cokernel is wrong? Thanks","i have been working on ""Module Theory:An Approach to Linear Algebra"" by T. S. Blyth and i am stuck on exercise 4.4 which is ""Let be an -morphism. By a cokernel of we mean a pair consisting of an -module together with an -epimorphism such that (1) (2) for every -module X and every -morphism such that there is a unique -morphism such that . Prove that ( is the canonical mapping) is a cokernel of . "" (1) is not that hard, but for (2) i can only prove that there exist a unique -morphism not the other way around which is required. Am i missing something? Is it possible that the definition of the cokernel is wrong? Thanks","f: M \to N  R f (P,\pi) R P R \pi: N\to P \pi \circ f = 0 R R g:N\to X g\circ f = 0 R \alpha: X\to P \pi = g \circ \alpha (N/Imf, \phi) \phi f R h:N/Imf \to X","['abstract-algebra', 'category-theory', 'modules']"
9,Is $\underset{i}\varprojlim R/(I+J)^i \cong \underset{i}\varprojlim \left( \underset{j}\varprojlim R/(I^i + J^j)\right)$?,Is ?,\underset{i}\varprojlim R/(I+J)^i \cong \underset{i}\varprojlim \left( \underset{j}\varprojlim R/(I^i + J^j)\right),"I am studying $I$-adic completions of a ring and I was wondering if the following holds for any commutative ring $R$ and ideals $I, J \subset R$ $\underset{i}\varprojlim R/(I+J)^i \cong \underset{i}\varprojlim \left( \underset{j}\varprojlim R/(I^i + J^j)\right)$ I don't know whether this is true or not, but I can't find a proof nor a counterexample of the above. Thank you!","I am studying $I$-adic completions of a ring and I was wondering if the following holds for any commutative ring $R$ and ideals $I, J \subset R$ $\underset{i}\varprojlim R/(I+J)^i \cong \underset{i}\varprojlim \left( \underset{j}\varprojlim R/(I^i + J^j)\right)$ I don't know whether this is true or not, but I can't find a proof nor a counterexample of the above. Thank you!",,"['abstract-algebra', 'ring-theory', 'commutative-algebra', 'limits-colimits']"
10,"Finding a colouring of an octahedron such that the stabilizer is $S_3$, $V_4$ or $A_4$","Finding a colouring of an octahedron such that the stabilizer is ,  or",S_3 V_4 A_4,"I am a bit playing around with the octahedral symmetry, and inspired by another exercise I did on finding configurations of the cube such that the stabilizer is equal to a certain group, I tried doing the same for an octahedron. I considered two ways to 'colour' the octahedron. The first is using colouring each face either black or white (the colours do not have to be used equally often), the second is to draw on each face an arrow pointing towards one of the three adjacent vertices. EDIT 2 : My work on the colouring of the octahedron with stabilizer $S_3$ was incorrect, as pointed out by Clément Guérin. Therefore I deleted this. I also just thought about the following. If we allow all rotations that leave one middle-of-two-opposite-faces-connecting line fixed (i.e. stabilizer is $S_3$), this means that we might colour one pair of opposite faces black, and the rest of the $6$ faces white, to get that $S_3$ is the stabilizer of this colouring. To me, this seems correct, and maybe someone can verify this. If so, we found colourings with stabilizer $S_3$, $V_4$, $A_4$ and $C_4$. Similarly I conjecture that a colouring of an octahedron with all but two faces white, and the two black faces are on the bottom of the octahedron, and not adjacent, would have stabilizer $C_2$. If this is correct, the question is completely answered for the case of a colouring. Perhaps someone also knows how to deal with arrow configurations then, and I will also think about this. EDIT As Steven Stadnicki pointed out a 'checkerboard pattern colouring (i.e. colour one face black and each adjacent face with a the other colour then the neighbours) the stabilizer is $A_4$ indeed! I coloured the printout below. Question: Am I right in my claims? $A_4$ was solved by Steven Stadnicki, $V_4$ and $C_4$ by Clément Guérin, and following the thoughts of Clément Guérin I have a conjecture on $C_2$ and $S_3$. The arrow configurations are still unclear to me. If you find a configuration such that the stabilizer is isomorphic to either $A_4$, $V_4$ or $S_3$ , I would find it most helpful if you draw it explicitly on a printout or an octahedron. I hope I made my question clear, because I am really in doubt about my work and my spatial visualization ability is not that strong.","I am a bit playing around with the octahedral symmetry, and inspired by another exercise I did on finding configurations of the cube such that the stabilizer is equal to a certain group, I tried doing the same for an octahedron. I considered two ways to 'colour' the octahedron. The first is using colouring each face either black or white (the colours do not have to be used equally often), the second is to draw on each face an arrow pointing towards one of the three adjacent vertices. EDIT 2 : My work on the colouring of the octahedron with stabilizer $S_3$ was incorrect, as pointed out by Clément Guérin. Therefore I deleted this. I also just thought about the following. If we allow all rotations that leave one middle-of-two-opposite-faces-connecting line fixed (i.e. stabilizer is $S_3$), this means that we might colour one pair of opposite faces black, and the rest of the $6$ faces white, to get that $S_3$ is the stabilizer of this colouring. To me, this seems correct, and maybe someone can verify this. If so, we found colourings with stabilizer $S_3$, $V_4$, $A_4$ and $C_4$. Similarly I conjecture that a colouring of an octahedron with all but two faces white, and the two black faces are on the bottom of the octahedron, and not adjacent, would have stabilizer $C_2$. If this is correct, the question is completely answered for the case of a colouring. Perhaps someone also knows how to deal with arrow configurations then, and I will also think about this. EDIT As Steven Stadnicki pointed out a 'checkerboard pattern colouring (i.e. colour one face black and each adjacent face with a the other colour then the neighbours) the stabilizer is $A_4$ indeed! I coloured the printout below. Question: Am I right in my claims? $A_4$ was solved by Steven Stadnicki, $V_4$ and $C_4$ by Clément Guérin, and following the thoughts of Clément Guérin I have a conjecture on $C_2$ and $S_3$. The arrow configurations are still unclear to me. If you find a configuration such that the stabilizer is isomorphic to either $A_4$, $V_4$ or $S_3$ , I would find it most helpful if you draw it explicitly on a printout or an octahedron. I hope I made my question clear, because I am really in doubt about my work and my spatial visualization ability is not that strong.",,"['abstract-algebra', 'group-theory', 'geometry', 'symmetric-groups']"
11,Modulus Operation with Negative Numbers,Modulus Operation with Negative Numbers,,"This topic has been asked many times and I have seen all the answers but none of them was helpful in clearing my doubt which is why this question is here. First of all, let's get the definitions out of the way. Division Algorithm: Let $a$ and $b\ (\neq0)$ be any integers. Then there exist unique integers $q$ and $r$ with the property that $a=bq+r$ , where $0 \leq r \lt |b|$ $\bmod{}$ Operator: For the same $a,b,q$ and $r$ as stated in the definition above, we say $$a \bmod b=r$$ Note that $a,b$ and $q$ can either be positive, negative or even $0$ (if we exclude $b$ ) whereas $r$ can only be non-negative. Case $1$ : Positive Divisor and Positive Dividend: $$68 \bmod 12=8$$ Reasoning: $68=12(5)+8$ Case $2$ : Positive Divisor and Negative Dividend: $$-68 \bmod 12=4$$ Reasoning: $-68=12(-6)+4$ Case $3$ : Negative Divisor and Positive Dividend: $$68 \bmod -12=8$$ Reasoning: $68=-12(-5)+8$ Case $4$ : Negative Divisor and Negative Dividend: $$-68 \bmod -12=4$$ Reasoning: $-68=-12(6)+4$ Doubt: Are all the cases that I listed sound along with their reasoning? If not, please show me how to evaluate $\bmod{}$ correctly. Also, would you like to add something which would enhance my knowledge of modulo arithmetic or anything in general?","This topic has been asked many times and I have seen all the answers but none of them was helpful in clearing my doubt which is why this question is here. First of all, let's get the definitions out of the way. Division Algorithm: Let and be any integers. Then there exist unique integers and with the property that , where Operator: For the same and as stated in the definition above, we say Note that and can either be positive, negative or even (if we exclude ) whereas can only be non-negative. Case : Positive Divisor and Positive Dividend: Reasoning: Case : Positive Divisor and Negative Dividend: Reasoning: Case : Negative Divisor and Positive Dividend: Reasoning: Case : Negative Divisor and Negative Dividend: Reasoning: Doubt: Are all the cases that I listed sound along with their reasoning? If not, please show me how to evaluate correctly. Also, would you like to add something which would enhance my knowledge of modulo arithmetic or anything in general?","a b\ (\neq0) q r a=bq+r 0 \leq r \lt |b| \bmod{} a,b,q r a \bmod b=r a,b q 0 b r 1 68 \bmod 12=8 68=12(5)+8 2 -68 \bmod 12=4 -68=12(-6)+4 3 68 \bmod -12=8 68=-12(-5)+8 4 -68 \bmod -12=4 -68=-12(6)+4 \bmod{}","['abstract-algebra', 'modular-arithmetic']"
12,Homomorphic images of $p$-adic integers,Homomorphic images of -adic integers,p,"Let $J_p$ be the additive group of $p$-adic integers for a fixed prime $p$. I would like to know if the structure of its homomorphic images is known. In particular, if $J_p/N$ is a homomorphic image with finite exponent, is $J_p/N$ also finite?","Let $J_p$ be the additive group of $p$-adic integers for a fixed prime $p$. I would like to know if the structure of its homomorphic images is known. In particular, if $J_p/N$ is a homomorphic image with finite exponent, is $J_p/N$ also finite?",,"['abstract-algebra', 'group-theory', 'p-adic-number-theory']"
13,An example of symmetric associative increasing function which cannot be represented as addition,An example of symmetric associative increasing function which cannot be represented as addition,,"Let $X$ be some connected subset of $\mathbb{R}$. Let $f: X^2\to X$ have following properties: $\forall x, y$: $f(x, y)=f(y,x)$ (Symmetry) $\forall x, y, z$: $f(x, y)>f(x,z)\iff y>z$ (Strictly increasing on any argument) $\forall x, y, z$: $f(x, f(y, z))=f(f(x, y), z)$ (Associativity) We call $f$ addition-like, if there exists an injection $\phi:X\to\mathbb{R}$ such that $\forall x, y$: $\phi(f(x,y))=\phi(x)+\phi(y)$. Can $f$ be not addition-like? Some examples: $f(x,y)=xy, x>0,y>0$, then $\phi(x)=\ln(x)$ $f(x,y)=xy+x+y, x>0,y>0$, then $\phi(x)=\ln(x+1)$ I do not know the answer to the question because I have trouble finding such $f$ at all except explitictly using addition/multiplication with some mapping, which obviously yields addition-like function by definition and multiplication being addition-like.","Let $X$ be some connected subset of $\mathbb{R}$. Let $f: X^2\to X$ have following properties: $\forall x, y$: $f(x, y)=f(y,x)$ (Symmetry) $\forall x, y, z$: $f(x, y)>f(x,z)\iff y>z$ (Strictly increasing on any argument) $\forall x, y, z$: $f(x, f(y, z))=f(f(x, y), z)$ (Associativity) We call $f$ addition-like, if there exists an injection $\phi:X\to\mathbb{R}$ such that $\forall x, y$: $\phi(f(x,y))=\phi(x)+\phi(y)$. Can $f$ be not addition-like? Some examples: $f(x,y)=xy, x>0,y>0$, then $\phi(x)=\ln(x)$ $f(x,y)=xy+x+y, x>0,y>0$, then $\phi(x)=\ln(x+1)$ I do not know the answer to the question because I have trouble finding such $f$ at all except explitictly using addition/multiplication with some mapping, which obviously yields addition-like function by definition and multiplication being addition-like.",,['abstract-algebra']
14,"In a ring, are cosets always additive?","In a ring, are cosets always additive?",,"In our introductory course on groups, we defined cosets and quotient groups in the following way. Let $N\trianglelefteq G$ be a normal subgroup of a group $(G,\,\cdot\,)$. Then the quotient group $G/N$ contains all the cosets of $N$ with respect to the elements of $G$, i.e. $G/N=\{Ng:g\in G\}$. Later on, we generalised this idea to rings: Let $I$ be an ideal of a ring $(R, +, \,\cdot\,)$. Then the quotient ring $R/I$ is defined $R/I = \{I+r:r\in R\}$. My question is: why do we take the `additive' cosets of $R$ in this case? i.e. does $R/I$ always contain cosets of the form $I+r$, and not $I\cdot r$? I reasoned that perhaps we take the $+$ cosets since $(R,+)$ forms a group, but $(R,\,\cdot\,)$ does not. But what if we have a field?","In our introductory course on groups, we defined cosets and quotient groups in the following way. Let $N\trianglelefteq G$ be a normal subgroup of a group $(G,\,\cdot\,)$. Then the quotient group $G/N$ contains all the cosets of $N$ with respect to the elements of $G$, i.e. $G/N=\{Ng:g\in G\}$. Later on, we generalised this idea to rings: Let $I$ be an ideal of a ring $(R, +, \,\cdot\,)$. Then the quotient ring $R/I$ is defined $R/I = \{I+r:r\in R\}$. My question is: why do we take the `additive' cosets of $R$ in this case? i.e. does $R/I$ always contain cosets of the form $I+r$, and not $I\cdot r$? I reasoned that perhaps we take the $+$ cosets since $(R,+)$ forms a group, but $(R,\,\cdot\,)$ does not. But what if we have a field?",,"['abstract-algebra', 'ring-theory']"
15,Prove that $U_k(n)$ is a subgroup of $U(n)$,Prove that  is a subgroup of,U_k(n) U(n),"For each divisor $k\gt 1$ of $n$, let $U_k(n) = \{x \in U(n) ~|~ x\pmod {k} = 1\}$. Prove that $U_k(n)$ is a subgroup of $U(n)$ ($U(n)$ is the group formed by the positive integers less than $n$ that are coprime to $n$) My attempt : 1) $1\equiv 1 \pmod{k}$, so $e\in U_k(n)$ 2) $a,b \in U_k(n) \implies ab\equiv 1 \cdot 1 \equiv 1 \pmod{k}$, so $ab \in U_k(n)$ 3) Since $\gcd(a,n)=1$ and $k\mid n$, we have $\gcd(a,k)=1$, for all $a\in U(n)$. Also, since $a^{-1}\in U(n)$, we have $\gcd(a^{-1}, k) = 1$. I'm not sure how to proceed from here. Appreciate any help. Thanks! (I'm trying to show $a^{-1} \equiv 1 \pmod{k}$ at 3rd step )","For each divisor $k\gt 1$ of $n$, let $U_k(n) = \{x \in U(n) ~|~ x\pmod {k} = 1\}$. Prove that $U_k(n)$ is a subgroup of $U(n)$ ($U(n)$ is the group formed by the positive integers less than $n$ that are coprime to $n$) My attempt : 1) $1\equiv 1 \pmod{k}$, so $e\in U_k(n)$ 2) $a,b \in U_k(n) \implies ab\equiv 1 \cdot 1 \equiv 1 \pmod{k}$, so $ab \in U_k(n)$ 3) Since $\gcd(a,n)=1$ and $k\mid n$, we have $\gcd(a,k)=1$, for all $a\in U(n)$. Also, since $a^{-1}\in U(n)$, we have $\gcd(a^{-1}, k) = 1$. I'm not sure how to proceed from here. Appreciate any help. Thanks! (I'm trying to show $a^{-1} \equiv 1 \pmod{k}$ at 3rd step )",,"['abstract-algebra', 'group-theory', 'elementary-number-theory']"
16,On relationship of two categorical characterization of finitely generated objects.,On relationship of two categorical characterization of finitely generated objects.,,"I've encountered The following categorical characterization of finitely generated modules: A $R$ -module $M$ is finitely generated iff it satifies one of the following properties: a): for any family of $R$ -module $\{U_i\}_{i\in\mathcal I}$ and any epimorphism $f:\bigoplus_{i\in\mathcal I} U_i\twoheadrightarrow M$ , there exists a finite subset $\mathcal F$ of $\mathcal I$ such that the restriction of $f$ on $\bigoplus_{i\in\mathcal F} U_i$ is also epic. b): for any category $\mathscr I$ representing a directed partially ordered set and any functor $F:\mathscr I\to R\text -\mathsf{Mod}$ such that every arrow of $\mathscr I$ is mapped to an injection via $F$ , then the canonical homomorphism $\varphi:\varinjlim\text{Hom}(M,-)\circ F\to\text{Hom}(M,\varinjlim F)$ is epic in $\mathsf{Ab}$ . My question is: If $R\text -\mathsf{Mod}$ is replaced by an arbitrary cocomplete abelian category, are characterization a) and b) remain equivalent? I've already proved that b) always implies a).","I've encountered The following categorical characterization of finitely generated modules: A -module is finitely generated iff it satifies one of the following properties: a): for any family of -module and any epimorphism , there exists a finite subset of such that the restriction of on is also epic. b): for any category representing a directed partially ordered set and any functor such that every arrow of is mapped to an injection via , then the canonical homomorphism is epic in . My question is: If is replaced by an arbitrary cocomplete abelian category, are characterization a) and b) remain equivalent? I've already proved that b) always implies a).","R M R \{U_i\}_{i\in\mathcal I} f:\bigoplus_{i\in\mathcal I} U_i\twoheadrightarrow M \mathcal F \mathcal I f \bigoplus_{i\in\mathcal F} U_i \mathscr I F:\mathscr I\to R\text -\mathsf{Mod} \mathscr I F \varphi:\varinjlim\text{Hom}(M,-)\circ F\to\text{Hom}(M,\varinjlim F) \mathsf{Ab} R\text -\mathsf{Mod}","['abstract-algebra', 'category-theory', 'modules', 'abelian-categories', 'limits-colimits']"
17,"Does $K[\alpha_1, ..., \alpha_n]=K(\alpha_1, ..., \alpha_n)$ imply $\alpha_1, ..., \alpha_n$ are algebraic over $K$?",Does  imply  are algebraic over ?,"K[\alpha_1, ..., \alpha_n]=K(\alpha_1, ..., \alpha_n) \alpha_1, ..., \alpha_n K","I know how to prove that if $\alpha_1, ..., \alpha_n$ are algebraic over $K$ , then $K[\alpha_1, ..., \alpha_n]$ is a field (i.e., $K[\alpha_1, ..., \alpha_n]=K(\alpha_1, ..., \alpha_n)$ ). I also know the converse is true for $n=1$ and also know how to prove it. However, I'm having real trouble to deal with the case $n\geq 2$ . I've tried to use the same strategy with $n=1$ , which envolves the surjective homomorphism $\psi:K[X]\to K[\alpha]$ with $F \mapsto F(\alpha)$ and the fact that $K[X]$ is a principal ideal domain. But that doesn't work with a similar map $\psi:K[X_1, ..., X_n]\to K[\alpha_1, ..., \alpha_n]$ since $K[X_1, ..., X_n]$ is not a principal domain. I couldn't disprove it either. I tried to find a small example with $K=\mathbb{R}$ and $n=2$ , but it also couldn't figure it out. Any ideas? Thanks!","I know how to prove that if are algebraic over , then is a field (i.e., ). I also know the converse is true for and also know how to prove it. However, I'm having real trouble to deal with the case . I've tried to use the same strategy with , which envolves the surjective homomorphism with and the fact that is a principal ideal domain. But that doesn't work with a similar map since is not a principal domain. I couldn't disprove it either. I tried to find a small example with and , but it also couldn't figure it out. Any ideas? Thanks!","\alpha_1, ..., \alpha_n K K[\alpha_1, ..., \alpha_n] K[\alpha_1, ..., \alpha_n]=K(\alpha_1, ..., \alpha_n) n=1 n\geq 2 n=1 \psi:K[X]\to K[\alpha] F \mapsto F(\alpha) K[X] \psi:K[X_1, ..., X_n]\to K[\alpha_1, ..., \alpha_n] K[X_1, ..., X_n] K=\mathbb{R} n=2","['abstract-algebra', 'field-theory']"
18,"What is $\Bbb Z^n/(a_1, \dots, a_n)$ or $\Bbb Z^n / I$ isomorphic to?",What is  or  isomorphic to?,"\Bbb Z^n/(a_1, \dots, a_n) \Bbb Z^n / I","I would like to know: What is $\Bbb Z^n/\langle(a_1, \dots, a_n)\rangle$ isomorphic to, as abelian group? More generally, if $I$ is a subgroup of $\Bbb Z^n$, then would you proceed to find $\Bbb Z^n/I$? Is there any algorithm? For instance for $I=\langle(4,0,2),(2,-2,0)\rangle$ or $J=\langle(-2,4,0,2),(2,-2,0,1)\rangle$? My aim is to know how to compute a quotient of $\Bbb Z^n$, which has the form $$\Bbb Z^m \oplus \bigoplus_{i=1}^s \Bbb Z/p_i^{r_i} \Bbb Z$$ because it is finitely generated. I am aware of this particular case, and of this one, and also maybe this one. Thank you for your help!","I would like to know: What is $\Bbb Z^n/\langle(a_1, \dots, a_n)\rangle$ isomorphic to, as abelian group? More generally, if $I$ is a subgroup of $\Bbb Z^n$, then would you proceed to find $\Bbb Z^n/I$? Is there any algorithm? For instance for $I=\langle(4,0,2),(2,-2,0)\rangle$ or $J=\langle(-2,4,0,2),(2,-2,0,1)\rangle$? My aim is to know how to compute a quotient of $\Bbb Z^n$, which has the form $$\Bbb Z^m \oplus \bigoplus_{i=1}^s \Bbb Z/p_i^{r_i} \Bbb Z$$ because it is finitely generated. I am aware of this particular case, and of this one, and also maybe this one. Thank you for your help!",,"['abstract-algebra', 'group-theory', 'abelian-groups', 'finitely-generated']"
19,Reasoning about finite sums,Reasoning about finite sums,,"Let $X$ denote a finite set, and $q:X \rightarrow \mathbb{R}$ denote a function. Then $$\sum_{x \in X}q(x) \in \mathbb{R}.$$ Now suppose we have a function $f : X \rightarrow Y$. Then we can use $f$ to break up the above sum as follows: $$\sum_{x \in X}q(x) \overset{*}{=} \sum_{x \in X, y \in Y, y = f(x)} q(x) = \sum_{y \in Y}\sum_{x \in X, y = f(x)} q(x) = \sum_{y \in Y} \sum_{x \in f^{-1}(y)} q(x)$$ Seems legit, but to be honest, I don't really understand the $\overset{*}{=}$ step at a purely logical level; all I can say about it is: ""Its obvious!"" So define $\Phi = (x \in X)$ and $\Psi = (x \in X \wedge y \in Y \wedge y=f(x))$. It would be nice if it were true that: $$(*)\qquad \forall x\forall y(\Phi \iff \Psi),$$ but that just isn't true. Question. If not $(*)$, then what relationship between $\Phi$ and $\Psi$ allows us to deduce $$\sum_{\Phi} q(x) = \sum_{\Psi} q(x),$$ and why does it work? Please don't remove the abstract algebra tag; the above question makes sense for $\mathbb{R}$ replaced by an arbitrary commutative monoid, and I'd like to see what that community has to say about the issue.","Let $X$ denote a finite set, and $q:X \rightarrow \mathbb{R}$ denote a function. Then $$\sum_{x \in X}q(x) \in \mathbb{R}.$$ Now suppose we have a function $f : X \rightarrow Y$. Then we can use $f$ to break up the above sum as follows: $$\sum_{x \in X}q(x) \overset{*}{=} \sum_{x \in X, y \in Y, y = f(x)} q(x) = \sum_{y \in Y}\sum_{x \in X, y = f(x)} q(x) = \sum_{y \in Y} \sum_{x \in f^{-1}(y)} q(x)$$ Seems legit, but to be honest, I don't really understand the $\overset{*}{=}$ step at a purely logical level; all I can say about it is: ""Its obvious!"" So define $\Phi = (x \in X)$ and $\Psi = (x \in X \wedge y \in Y \wedge y=f(x))$. It would be nice if it were true that: $$(*)\qquad \forall x\forall y(\Phi \iff \Psi),$$ but that just isn't true. Question. If not $(*)$, then what relationship between $\Phi$ and $\Psi$ allows us to deduce $$\sum_{\Phi} q(x) = \sum_{\Psi} q(x),$$ and why does it work? Please don't remove the abstract algebra tag; the above question makes sense for $\mathbb{R}$ replaced by an arbitrary commutative monoid, and I'd like to see what that community has to say about the issue.",,"['abstract-algebra', 'logic', 'soft-question', 'summation']"
20,Show that $\alpha^n\notin k$ for $n\ge 4$ where $\alpha\in\bar{k}$ and $[K:k]=n!.$,Show that  for  where  and,\alpha^n\notin k n\ge 4 \alpha\in\bar{k} [K:k]=n!.,"Let $k$ be a field, let $f(X) \in k[X]$ be a separable polynomial of degree $n$ whose Galois group is isomorphic to $S_n$ , and let $\alpha$ be a root of $f(X)$ in some algebraic closure $k$ . (a) Show that $f(X)$ is irreducible. (b) Show that $Aut_k(k(\alpha)) = \{\mathrm{id}\}$ if $n \ge 3.$ (c) Show that $\alpha^n \notin k$ if $ n\ge 4.$ I know what to do for (a) and (b): (a) Let $G$ be the Galois group of $f$ . For the sake of argument, suppose $f(x)$ is reducible. Then $f$ can be written as a product of distinct irreducible factors (since $k[x]$ is a UFD). Let $\alpha_i, \alpha_j$ be distinct roots of two such irreducible factors. But then any $\sigma\in G$ must send $\alpha_i$ to another root of its minimal polynomial. In particular, we can't have $\sigma(\alpha_i) = \alpha_j$ , hence $G$ is not isomorphic to a transitive subgroup of $S_n$ . But $S_n$ is a transitive subgroup of itself, a contradiction. (b) It suffices to show that $\alpha$ is the only root of $f(x)$ in $k(\alpha)$ . Suppose there is another root $\beta\in k(\alpha)$ . Then over $k(\alpha)$ , $$f(x) = (x-\alpha)(x-\beta)g(x),$$ where $\deg g(x) = n-2.$ Let $K$ be the splitting field of $f$ over $k$ . Then since $G\cong S_n,$ we have $[K:k]=n!.$ And since $\deg g = n-2,$ we have $[K:k(\alpha)]\le (n-2)!,$ and $[k(\alpha):k]=n$ by the irreducibility of $f$ over $k$ . But then $$[K:k] = [K:k(\alpha)][k(\alpha):k]\le (n-2)!\cdot n<n!,$$ contradicting that $G\cong S_n.$ Now how do we attack (c)?","Let be a field, let be a separable polynomial of degree whose Galois group is isomorphic to , and let be a root of in some algebraic closure . (a) Show that is irreducible. (b) Show that if (c) Show that if I know what to do for (a) and (b): (a) Let be the Galois group of . For the sake of argument, suppose is reducible. Then can be written as a product of distinct irreducible factors (since is a UFD). Let be distinct roots of two such irreducible factors. But then any must send to another root of its minimal polynomial. In particular, we can't have , hence is not isomorphic to a transitive subgroup of . But is a transitive subgroup of itself, a contradiction. (b) It suffices to show that is the only root of in . Suppose there is another root . Then over , where Let be the splitting field of over . Then since we have And since we have and by the irreducibility of over . But then contradicting that Now how do we attack (c)?","k f(X) \in k[X] n S_n \alpha f(X) k f(X) Aut_k(k(\alpha)) = \{\mathrm{id}\} n \ge 3. \alpha^n \notin k  n\ge 4. G f f(x) f k[x] \alpha_i, \alpha_j \sigma\in G \alpha_i \sigma(\alpha_i) = \alpha_j G S_n S_n \alpha f(x) k(\alpha) \beta\in k(\alpha) k(\alpha) f(x) = (x-\alpha)(x-\beta)g(x), \deg g(x) = n-2. K f k G\cong S_n, [K:k]=n!. \deg g = n-2, [K:k(\alpha)]\le (n-2)!, [k(\alpha):k]=n f k [K:k] = [K:k(\alpha)][k(\alpha):k]\le (n-2)!\cdot n<n!, G\cong S_n.","['abstract-algebra', 'galois-theory']"
21,A field in which every element (that is not 1 or 0) is a root of -1,A field in which every element (that is not 1 or 0) is a root of -1,,"Let $\mathbb{F}$ be a field with $char(\mathbb{F}) \neq 2$ such that for every element $q \in \mathbb{F}$ if $q \neq 0$ and $q \neq 1$ then there is a power n such that $q^n = -1$. (E.g. $\mathbb{F}_3$, $\mathbb{F}_5$, $\mathbb{F}_{9}$, $\mathbb{F}_{17}$, ...). Obviously $char(\mathbb{F}) > 0$ (since $\mathbb{F}$ cannot have a $\mathbb{Q}$ subfield).  Furthermore, I guess in finite fields this happens if and only if $|\mathbb{F}| = 2^k+1$ for some k (since in this case $\mathbb{F}^*$ is a cyclic group of order $2^k$ and -1 lies in every non-trivial subgroup) Of course $\mathbb{F}$ is not algebraically closed (since every element has even multiplicative order and thus $x^{(2n+1)} - 1$ has only 1 root $\forall n$). But can $\mathbb{F}$ be infinite?  Also is there an infinite number of (finite) fields with this property?","Let $\mathbb{F}$ be a field with $char(\mathbb{F}) \neq 2$ such that for every element $q \in \mathbb{F}$ if $q \neq 0$ and $q \neq 1$ then there is a power n such that $q^n = -1$. (E.g. $\mathbb{F}_3$, $\mathbb{F}_5$, $\mathbb{F}_{9}$, $\mathbb{F}_{17}$, ...). Obviously $char(\mathbb{F}) > 0$ (since $\mathbb{F}$ cannot have a $\mathbb{Q}$ subfield).  Furthermore, I guess in finite fields this happens if and only if $|\mathbb{F}| = 2^k+1$ for some k (since in this case $\mathbb{F}^*$ is a cyclic group of order $2^k$ and -1 lies in every non-trivial subgroup) Of course $\mathbb{F}$ is not algebraically closed (since every element has even multiplicative order and thus $x^{(2n+1)} - 1$ has only 1 root $\forall n$). But can $\mathbb{F}$ be infinite?  Also is there an infinite number of (finite) fields with this property?",,"['abstract-algebra', 'field-theory']"
22,Polynomial ring with isomorphic quotients [duplicate],Polynomial ring with isomorphic quotients [duplicate],,"This question already has answers here : What is necessary and/or sufficient for polynomials to provide isomorphic quotient rings? (2 answers) Closed 7 years ago . If $R$ is a commutative ring and $f(x), g(x) \in R[x]$ two polynomials such that $R[x]/f(x)\cong R[x]/g(x)$ as $R$-algebras, what can we say about $f$ and $g$? Or given $f(x)\in R[x]$, what can we say about the set $\{g \in R[x]\mid R[x]/f(x) \cong R[x]/g(x)\}$? Can we conclude that $\mathrm{deg}(f) = \mathrm{deg}(g)$? Is there an automorphism of $R[x]$ taking $f$ to $g$? I'm most concerned about the cases where $R=k$ is a field, $R=\mathbb{Z}$, or $R=\mathcal{O}_k$ is the ring of integers of a number field, but I'd be interested in the most general results possible.","This question already has answers here : What is necessary and/or sufficient for polynomials to provide isomorphic quotient rings? (2 answers) Closed 7 years ago . If $R$ is a commutative ring and $f(x), g(x) \in R[x]$ two polynomials such that $R[x]/f(x)\cong R[x]/g(x)$ as $R$-algebras, what can we say about $f$ and $g$? Or given $f(x)\in R[x]$, what can we say about the set $\{g \in R[x]\mid R[x]/f(x) \cong R[x]/g(x)\}$? Can we conclude that $\mathrm{deg}(f) = \mathrm{deg}(g)$? Is there an automorphism of $R[x]$ taking $f$ to $g$? I'm most concerned about the cases where $R=k$ is a field, $R=\mathbb{Z}$, or $R=\mathcal{O}_k$ is the ring of integers of a number field, but I'd be interested in the most general results possible.",,"['abstract-algebra', 'polynomials', 'ring-theory', 'commutative-algebra']"
23,Two different comultiplications on a Hopf algebra,Two different comultiplications on a Hopf algebra,,"I am pretty sure this statement is false : let $K$ be a field and let $(A, \eta, \mu, \Delta, \epsilon, c)$ be a Hopf Algebra. If we forget the comultiplication $\Delta$, is it forced by $(A, \eta, \mu, \epsilon, c)$ ? In other words, can we put two Hopf algebra structures on a $K$-algebra which only differ by their comultiplication ?","I am pretty sure this statement is false : let $K$ be a field and let $(A, \eta, \mu, \Delta, \epsilon, c)$ be a Hopf Algebra. If we forget the comultiplication $\Delta$, is it forced by $(A, \eta, \mu, \epsilon, c)$ ? In other words, can we put two Hopf algebra structures on a $K$-algebra which only differ by their comultiplication ?",,"['abstract-algebra', 'hopf-algebras']"
24,"Show that if $|G| = 30$, then $G$ has normal 3-Sylow and 5-Sylow subgroups.","Show that if , then  has normal 3-Sylow and 5-Sylow subgroups.",|G| = 30 G,"Show that if $|G| = 30$, then $G$ has normal $3$-Sylow and $5$-Sylow subgroups. Let $n_3$ denote the number of 3-Sylow subgroups and $n_5$ the number of $5$-Sylow subgroups. Then, by the third Sylow theorem, $n_3$ divides $10$ and $n_3 \equiv 1 \mod 3$. From these two, we see that $n_3 = 1$. This implies that $G$ has a normal 3-Sylow subgroup. Similarly, let $n_5$ denote the number of $5$-Sylow subgroups. Then, by the third Sylow theorem, $n_5$ divides $6$, and $n_5 \equiv 1 \mod 5$. So, we can infer that either $n_5 = 1$ or $n_5 = 6$. I don't know how to proceed from here. Can someone please help me? (This is not homework, only self study)","Show that if $|G| = 30$, then $G$ has normal $3$-Sylow and $5$-Sylow subgroups. Let $n_3$ denote the number of 3-Sylow subgroups and $n_5$ the number of $5$-Sylow subgroups. Then, by the third Sylow theorem, $n_3$ divides $10$ and $n_3 \equiv 1 \mod 3$. From these two, we see that $n_3 = 1$. This implies that $G$ has a normal 3-Sylow subgroup. Similarly, let $n_5$ denote the number of $5$-Sylow subgroups. Then, by the third Sylow theorem, $n_5$ divides $6$, and $n_5 \equiv 1 \mod 5$. So, we can infer that either $n_5 = 1$ or $n_5 = 6$. I don't know how to proceed from here. Can someone please help me? (This is not homework, only self study)",,"['abstract-algebra', 'group-theory', 'sylow-theory']"
25,Equivalent Definitions of Prime Subfield,Equivalent Definitions of Prime Subfield,,"I found two definitions for a prime subfield $K$ of a field $F$. 1. Wolfram $-$ $K$ is the subfield of $F$ generated by the multiplicative identity $1$ of $F$. 2. ProofWiki $-$ $K$ is the intersection of all the subfields, say $\{ K_c \}$, of $F$. I am aware that in the first definition, $\langle 1 \rangle = \{ n \cdot 1 : n \in \mathbb Z \}$.  Since $1$ is in each $K_c$, $\langle 1 \rangle \subset K$.  But, how are they equal?  I tried two approaches and they ran into the same problem. One, prove directly that $K \subset \langle 1 \rangle$.  But how do I know each $x \in K$ is of the form $1 + 1 ... +1$?  Another approach is to show that $\langle 1 \rangle$ is a subfield of $F$, ie an element in $\{ K_c \}$.  But how do I show that the inverse, $x^{-1}$, of each $x \in \langle 1 \rangle$ is also of the form $1 + 1 ... +1$?","I found two definitions for a prime subfield $K$ of a field $F$. 1. Wolfram $-$ $K$ is the subfield of $F$ generated by the multiplicative identity $1$ of $F$. 2. ProofWiki $-$ $K$ is the intersection of all the subfields, say $\{ K_c \}$, of $F$. I am aware that in the first definition, $\langle 1 \rangle = \{ n \cdot 1 : n \in \mathbb Z \}$.  Since $1$ is in each $K_c$, $\langle 1 \rangle \subset K$.  But, how are they equal?  I tried two approaches and they ran into the same problem. One, prove directly that $K \subset \langle 1 \rangle$.  But how do I know each $x \in K$ is of the form $1 + 1 ... +1$?  Another approach is to show that $\langle 1 \rangle$ is a subfield of $F$, ie an element in $\{ K_c \}$.  But how do I show that the inverse, $x^{-1}$, of each $x \in \langle 1 \rangle$ is also of the form $1 + 1 ... +1$?",,"['abstract-algebra', 'field-theory']"
26,Is normal extension algebraic?,Is normal extension algebraic?,,"Let $E/F$ be a field extension. Then $E/F$ is called normal iff there exists $\mathscr{A}\subset F[X]\setminus\{0\}$ such that $\forall f\in\mathscr{A}$ , $f$ splits over $E$ and $E=F(\{\alpha\in E: \exists f\in \mathscr{A} f(\alpha)=0\}$ Usually normal extension is defined for algebraic extensions, so that the standard definition of normal extensions is ""the above definition + algebraic extension"". However, doesn't the above definition (for arbitrary field extension) imply that the extension is algebraic? That is, isn't ""algebriac"" condition superfluous in the standard definition of normal extension?","Let be a field extension. Then is called normal iff there exists such that , splits over and Usually normal extension is defined for algebraic extensions, so that the standard definition of normal extensions is ""the above definition + algebraic extension"". However, doesn't the above definition (for arbitrary field extension) imply that the extension is algebraic? That is, isn't ""algebriac"" condition superfluous in the standard definition of normal extension?",E/F E/F \mathscr{A}\subset F[X]\setminus\{0\} \forall f\in\mathscr{A} f E E=F(\{\alpha\in E: \exists f\in \mathscr{A} f(\alpha)=0\},"['abstract-algebra', 'field-theory', 'definition']"
27,Subgroups of finite index have finitely many conjugates,Subgroups of finite index have finitely many conjugates,,"is it true the following statement: Let $G$ be a group and let $H$ be a subgroup of $G$. If the index $[G:H]$ of $H$ in $G$ is finite, then $H$ have finitely many conjugates. What I think, is that it's true. I proceed as follows: Suppose $[G:H]=n<\infty$ and let $\{g_{1}H,\dots,g_{n}H\}$ be its left cosets. For every $g\in G$ there exists a unique $1\leq i\leq n$ such that $g=g_{i}h$ for some $h\in H$. This implies that $gHg^{-1}=g_{i}Hg_{i}^{-1}$. So there can be at most $n$ conjugates of $H$. Is this correct? Thanks in advance.","is it true the following statement: Let $G$ be a group and let $H$ be a subgroup of $G$. If the index $[G:H]$ of $H$ in $G$ is finite, then $H$ have finitely many conjugates. What I think, is that it's true. I proceed as follows: Suppose $[G:H]=n<\infty$ and let $\{g_{1}H,\dots,g_{n}H\}$ be its left cosets. For every $g\in G$ there exists a unique $1\leq i\leq n$ such that $g=g_{i}h$ for some $h\in H$. This implies that $gHg^{-1}=g_{i}Hg_{i}^{-1}$. So there can be at most $n$ conjugates of $H$. Is this correct? Thanks in advance.",,"['abstract-algebra', 'group-theory']"
28,Length of tensor product of finite length modules is finite,Length of tensor product of finite length modules is finite,,"Let $R$ be a commutative ring. If $M$ and $N$ are finite length $R$-modules, then $M\otimes_R N$ has finite length, and $l(M\otimes_R N) \le l(M)l(N)$. I know the question has been posted previously here , but only half of it was answered and I do not understand the argument about the inequality. I have tried to explicitly construct a composition series and use exact sequences, but in using the latter I can't see what modules to use in the sequences.","Let $R$ be a commutative ring. If $M$ and $N$ are finite length $R$-modules, then $M\otimes_R N$ has finite length, and $l(M\otimes_R N) \le l(M)l(N)$. I know the question has been posted previously here , but only half of it was answered and I do not understand the argument about the inequality. I have tried to explicitly construct a composition series and use exact sequences, but in using the latter I can't see what modules to use in the sequences.",,"['abstract-algebra', 'commutative-algebra', 'modules', 'tensor-products']"
29,"A noncommutative counterexample to the following property: If $I,J$ are comaximal ideals, then $IJ=I\cap J$.","A noncommutative counterexample to the following property: If  are comaximal ideals, then .","I,J IJ=I\cap J","Let $R$ be a commutative ring with $1$ . If $I+J=R$ , then $IJ = I \cap J$ . The post below has already given a solution. However, I am wondering what happens if $R$ is not commutative? Can anyone provide me with a counterexample? If I am not wrong, the counterexample given in the post is the case when $R$ is commutative and does not have unity. Which part of the proof uses commutativity of the ring? Thank you. If $I+J=R$, where $R$ is a commutative rng, prove that $IJ=I\cap J$.","Let be a commutative ring with . If , then . The post below has already given a solution. However, I am wondering what happens if is not commutative? Can anyone provide me with a counterexample? If I am not wrong, the counterexample given in the post is the case when is commutative and does not have unity. Which part of the proof uses commutativity of the ring? Thank you. If $I+J=R$, where $R$ is a commutative rng, prove that $IJ=I\cap J$.",R 1 I+J=R IJ = I \cap J R R,"['abstract-algebra', 'ideals']"
30,Converse to Chinese Remainder Theorem,Converse to Chinese Remainder Theorem,,"So as seen on this question Converse of the Chinese Remainder Theorem , we know that if $(n,m) \neq 1$, then $\mathbb{Z} /mn \mathbb{Z} \ncong \mathbb{Z}/n\mathbb{Z} \times \mathbb{Z}/m\mathbb{Z}$, because the right hand side does not have an element of order $nm$. But take a more general setting. Let $R$ be a commutative ring, and let $A,B$ be ideals in $R$. $A$ and $B$ are said to be comaximal if $A+B=R$. If $A, B$ are comaximal, then we have: $R/AB \cong R/A \times R/B$. In this setup, is the converse true? If we have $A, B$ ideals in $R$ such that $R/AB \cong R/A \times R/B$, do we always have that $A$ and $B$ are comaximal?","So as seen on this question Converse of the Chinese Remainder Theorem , we know that if $(n,m) \neq 1$, then $\mathbb{Z} /mn \mathbb{Z} \ncong \mathbb{Z}/n\mathbb{Z} \times \mathbb{Z}/m\mathbb{Z}$, because the right hand side does not have an element of order $nm$. But take a more general setting. Let $R$ be a commutative ring, and let $A,B$ be ideals in $R$. $A$ and $B$ are said to be comaximal if $A+B=R$. If $A, B$ are comaximal, then we have: $R/AB \cong R/A \times R/B$. In this setup, is the converse true? If we have $A, B$ ideals in $R$ such that $R/AB \cong R/A \times R/B$, do we always have that $A$ and $B$ are comaximal?",,"['abstract-algebra', 'ring-theory', 'commutative-algebra', 'ideals', 'chinese-remainder-theorem']"
31,Show that there is a positive integer $n$ such that $G \cong \ker(\phi^{n}) \times \phi^{n}(G)$,Show that there is a positive integer  such that,n G \cong \ker(\phi^{n}) \times \phi^{n}(G),"Let $G$ be a finite abelian group and let $\phi: G \rightarrow G$ be a group homomorphism. I am trying to show that there is a positive integer $n$ such that $G \cong \ker(\phi^{n}) \times \phi^{n}(G)$. I know that since $G$ is abelian we have that $\ker(\phi^{k})$ and $\phi^{k}(G)$ are normal subgroups of $G$ for any $k$ I also suspect we have the following towers which stabilize at $m$ and $m'$ $$\phi(G) \unrhd \phi^{2}(G) \unrhd \cdots \unrhd \phi^{m}(G)=\phi^{m+1}(G)=\cdots$$ $$\ker(\phi) \unlhd \ker^{2}(\phi) \unlhd \cdots \unlhd \ker^{m'}(\phi)=\ker^{m'+1}(\phi)=\cdots$$ I know that if given a group of the form $HK$ where $H$ and $K$ are normal subgroups of $HK$ and $H\cap K=1$ then $H \times K \cong HK$. I want to apply this to this situation but I am unable to show how write $G$ as a product $HK$ Resolution One of the comments directed me to the following article: http://en.wikipedia.org/wiki/Fitting_lemma The last part of which answers the question. Below is what is says: Choose $n=\max(m,m')$, then we have for $x \in \ker^{n}(\phi) \cap \phi^{n}(x)$, this means that $x=\phi^{n}(y)$ for some $y \in G$. This gives: $0=\phi^{n}(x)=\phi^{2n}(y)$ which means that $y \in \ker^{2n}\phi=\ker^{n}{\phi}$. and then we have that $0=x=\phi^{n}(y)$. The answer below kindly points out that every element $x$ is contained in one of the cosets of $G/\ker^{n}(\phi)$, this means that $x=k+g$ for some $k \in \ker^{n}(\phi)$ and $g \in G$. We also have that $g=\phi^{n}(h)$ for some $h \in G$. Writing $x=k+\phi^{n}(h)$ essentially shows that $G=\ker(\phi^{n}) + \phi^{n}(G)$. Using the fact above, the claim follows.","Let $G$ be a finite abelian group and let $\phi: G \rightarrow G$ be a group homomorphism. I am trying to show that there is a positive integer $n$ such that $G \cong \ker(\phi^{n}) \times \phi^{n}(G)$. I know that since $G$ is abelian we have that $\ker(\phi^{k})$ and $\phi^{k}(G)$ are normal subgroups of $G$ for any $k$ I also suspect we have the following towers which stabilize at $m$ and $m'$ $$\phi(G) \unrhd \phi^{2}(G) \unrhd \cdots \unrhd \phi^{m}(G)=\phi^{m+1}(G)=\cdots$$ $$\ker(\phi) \unlhd \ker^{2}(\phi) \unlhd \cdots \unlhd \ker^{m'}(\phi)=\ker^{m'+1}(\phi)=\cdots$$ I know that if given a group of the form $HK$ where $H$ and $K$ are normal subgroups of $HK$ and $H\cap K=1$ then $H \times K \cong HK$. I want to apply this to this situation but I am unable to show how write $G$ as a product $HK$ Resolution One of the comments directed me to the following article: http://en.wikipedia.org/wiki/Fitting_lemma The last part of which answers the question. Below is what is says: Choose $n=\max(m,m')$, then we have for $x \in \ker^{n}(\phi) \cap \phi^{n}(x)$, this means that $x=\phi^{n}(y)$ for some $y \in G$. This gives: $0=\phi^{n}(x)=\phi^{2n}(y)$ which means that $y \in \ker^{2n}\phi=\ker^{n}{\phi}$. and then we have that $0=x=\phi^{n}(y)$. The answer below kindly points out that every element $x$ is contained in one of the cosets of $G/\ker^{n}(\phi)$, this means that $x=k+g$ for some $k \in \ker^{n}(\phi)$ and $g \in G$. We also have that $g=\phi^{n}(h)$ for some $h \in G$. Writing $x=k+\phi^{n}(h)$ essentially shows that $G=\ker(\phi^{n}) + \phi^{n}(G)$. Using the fact above, the claim follows.",,"['abstract-algebra', 'group-theory', 'finite-groups', 'abelian-groups']"
32,Extensions of $\mathbb{Z}$ by $\mathbb{Z}_2$,Extensions of  by,\mathbb{Z} \mathbb{Z}_2,"Well. My question is very concrete. Does anybody know all the groups $G$ such that it fits in a short exact sequence $1\to \mathbb{Z}\to G\to \mathbb{Z}_2 \to 1$, where $\mathbb{Z}_2$ are the integers modulo $2$. It is well known that such extensions are classified by $H^2(\mathbb{Z}_2,\mathbb{Z})$, and this cohomology group is isomorphic to $\mathbb{Z}_2$. Now the trivial element is represented by any semidirect product, and there are just two of them, explicitely: $\mathbb{Z}\times\mathbb{Z}_2$ and $\mathbb{Z}\rtimes \mathbb{Z}_2 \cong D_\infty$ the inifnite dihedral group. And the nontrivial element can be represented by $\mathbb{Z}$ clearly. Is there any extension missing?","Well. My question is very concrete. Does anybody know all the groups $G$ such that it fits in a short exact sequence $1\to \mathbb{Z}\to G\to \mathbb{Z}_2 \to 1$, where $\mathbb{Z}_2$ are the integers modulo $2$. It is well known that such extensions are classified by $H^2(\mathbb{Z}_2,\mathbb{Z})$, and this cohomology group is isomorphic to $\mathbb{Z}_2$. Now the trivial element is represented by any semidirect product, and there are just two of them, explicitely: $\mathbb{Z}\times\mathbb{Z}_2$ and $\mathbb{Z}\rtimes \mathbb{Z}_2 \cong D_\infty$ the inifnite dihedral group. And the nontrivial element can be represented by $\mathbb{Z}$ clearly. Is there any extension missing?",,"['abstract-algebra', 'group-extensions']"
33,Proving that $GL_n(F)$ is non-abelian for $n \geq 2$ and for any field $F$,Proving that  is non-abelian for  and for any field,GL_n(F) n \geq 2 F,"I'm trying to show that $GL_n(F)$ is non-abelian for any field $F$ and $n \geq 2$. I'm doing so by constructing two $2 \times 2$ matrices that do not commute and ""extending"" them to $n \times n$ matrices with zeros in every other entry. We define $\displaystyle A = \left[ \begin{array}{cc} 1 & 1 \\ 0 & 1 \end{array}\right]$ and $\displaystyle B = \left[ \begin{array}{cc} 1 & 0 \\ 1 & 1 \end{array}\right]$. A quick calculation reveals that $AB \neq BA$, so the products of the extended $n \times n$ matrices are also not equivalent. My question is: does this suffice in proving the statement for any field $F$? The only field that I can think of where this might fail is in $\mathbb{Z}/2\mathbb{Z}$, but that turns out to not be the case.","I'm trying to show that $GL_n(F)$ is non-abelian for any field $F$ and $n \geq 2$. I'm doing so by constructing two $2 \times 2$ matrices that do not commute and ""extending"" them to $n \times n$ matrices with zeros in every other entry. We define $\displaystyle A = \left[ \begin{array}{cc} 1 & 1 \\ 0 & 1 \end{array}\right]$ and $\displaystyle B = \left[ \begin{array}{cc} 1 & 0 \\ 1 & 1 \end{array}\right]$. A quick calculation reveals that $AB \neq BA$, so the products of the extended $n \times n$ matrices are also not equivalent. My question is: does this suffice in proving the statement for any field $F$? The only field that I can think of where this might fail is in $\mathbb{Z}/2\mathbb{Z}$, but that turns out to not be the case.",,"['abstract-algebra', 'matrices']"
34,Is algebra over a set also algebra over a field?,Is algebra over a set also algebra over a field?,,"During my studies I have come across two different notions of the term ""algebra"", namely algebra over a set and algebra over a field ( the field its vector space always being Euclidean space in my case). While both of those concepts use the same term, I can't seem to find any relation between them, e.g. one being a sub-case of the other. Is there any such relation? Is there a reason why they are called the same?","During my studies I have come across two different notions of the term ""algebra"", namely algebra over a set and algebra over a field ( the field its vector space always being Euclidean space in my case). While both of those concepts use the same term, I can't seem to find any relation between them, e.g. one being a sub-case of the other. Is there any such relation? Is there a reason why they are called the same?",,"['abstract-algebra', 'elementary-set-theory', 'terminology']"
35,Reduced Group algebras,Reduced Group algebras,,Take a finite group and a field of characteristic zero. The group algebra is due to Maschke's theorem semisimple so that its a finite direct sum of matrix algebras over division algebras. I like to know when the case occurs that the decomposition is a direct sum of division algebras (such algebras are called reduced which is equivalent to that there are no nilpotent elements). Clearly this is the case when the group is abelian. Is there any other example? In the case of rational group algebras over dihedral and quanternion groups there is always a matrix algebra involved. Of course in the case of complex numbers the answer is also no.,Take a finite group and a field of characteristic zero. The group algebra is due to Maschke's theorem semisimple so that its a finite direct sum of matrix algebras over division algebras. I like to know when the case occurs that the decomposition is a direct sum of division algebras (such algebras are called reduced which is equivalent to that there are no nilpotent elements). Clearly this is the case when the group is abelian. Is there any other example? In the case of rational group algebras over dihedral and quanternion groups there is always a matrix algebra involved. Of course in the case of complex numbers the answer is also no.,,"['abstract-algebra', 'group-theory', 'representation-theory']"
36,A question about Sylow subgroups,A question about Sylow subgroups,,"Let $G$ be a finite group and $P\neq\{e\}$ be a Sylow $p$-subgroup of $G$ and $P^g\neq P$ be its conjugate in $G$. If we know that $P\cap P^g\neq \{e\}$, can we conclude that $Z(P)\cap Z(P^g)\neq \{e\}$?","Let $G$ be a finite group and $P\neq\{e\}$ be a Sylow $p$-subgroup of $G$ and $P^g\neq P$ be its conjugate in $G$. If we know that $P\cap P^g\neq \{e\}$, can we conclude that $Z(P)\cap Z(P^g)\neq \{e\}$?",,"['abstract-algebra', 'group-theory', 'finite-groups', 'sylow-theory']"
37,$M \oplus M \simeq N \oplus N$ then $M \simeq N.$,then,M \oplus M \simeq N \oplus N M \simeq N.,Let $M$ and $N$ be finitely generated $R$-modules where $R$ principal domain. Show that if $M \oplus M \simeq N \oplus N$ then $M \simeq N.$,Let $M$ and $N$ be finitely generated $R$-modules where $R$ principal domain. Show that if $M \oplus M \simeq N \oplus N$ then $M \simeq N.$,,"['abstract-algebra', 'modules', 'principal-ideal-domains']"
38,How many monoids of order three are there?,How many monoids of order three are there?,,http://oeis.org/A058129 In the above link we can see the answer is 7. I have tried counting these and don't get 7. I am not sure what I am doing wrong so could someone go through counting these step by step?,http://oeis.org/A058129 In the above link we can see the answer is 7. I have tried counting these and don't get 7. I am not sure what I am doing wrong so could someone go through counting these step by step?,,"['abstract-algebra', 'combinatorics', 'monoid']"
39,Prove that the number of subgroups in $D_n = \tau (n) + \sigma (n)$,Prove that the number of subgroups in,D_n = \tau (n) + \sigma (n),"Prove that the number of subgroups in $D_n = \tau (n) + \sigma (n)$ where $\tau (n)$ represents number of divisors of $n$ and $\sigma (n)$ represnts the sum of divisors of $n$. Attempt: $D_n = \{e,r,r^2, \cdot \cdot \cdot, r^{n-1},s,rs,r^2s, \cdot \cdot \cdot, r^{n-1}s \}$ Then, $\{e,r,r^2, \cdot \cdot \cdot, r^{n-1}\}$ is a cyclic subgroup of $G$. There are $\tau(n)$ such cyclic subgroups. Total number of subgroups of order $2=n+1$ if $n$ is even and $=n$ if $n$ is odd. Hence, the sum is $\tau(n)+n$ or $\tau(n)+n+1$ Now, let $H$ denote the set of reflections, then if $a=r^is,b=r^js ~\in~H$, then $r^is~ (r^js)^{-1} = (r^is)^{-1}r^js=sr^{-i}r^js=sr^{j-i}s=s^2r^{i-j}=r^{i-j} \notin H$ Hence, the set of reflections cannot form a subgroup in themselves in any case. Now, we must consider sets involving both rotations and reflections and find conditions for them to form subgroups. By Lagrange's theorem, order of such a subgroup $H$ must divide $n$ as we have already found out the total number of subgroups of order $2$ So : (a) A reflection is it's self inverse (b) A reflection times a reflection is always a rotation (c) Inverse of a rotation $r^i = r^{n-i}$ (d) A rotation times a rotation is always a rotation. How do I choose such rotation and reflective elements such that they form a group. Suppose, $|H|=4$, In that case, $H$ should look something like this: $H = \{f_1,f_2,r^i,r^{n-i}\}$ where $f_1,f_2$ are reflections and $f_1f_2=r^i$ How can I extend this to $n$ variables? A hint to move ahead would be really appreciated. Thanks","Prove that the number of subgroups in $D_n = \tau (n) + \sigma (n)$ where $\tau (n)$ represents number of divisors of $n$ and $\sigma (n)$ represnts the sum of divisors of $n$. Attempt: $D_n = \{e,r,r^2, \cdot \cdot \cdot, r^{n-1},s,rs,r^2s, \cdot \cdot \cdot, r^{n-1}s \}$ Then, $\{e,r,r^2, \cdot \cdot \cdot, r^{n-1}\}$ is a cyclic subgroup of $G$. There are $\tau(n)$ such cyclic subgroups. Total number of subgroups of order $2=n+1$ if $n$ is even and $=n$ if $n$ is odd. Hence, the sum is $\tau(n)+n$ or $\tau(n)+n+1$ Now, let $H$ denote the set of reflections, then if $a=r^is,b=r^js ~\in~H$, then $r^is~ (r^js)^{-1} = (r^is)^{-1}r^js=sr^{-i}r^js=sr^{j-i}s=s^2r^{i-j}=r^{i-j} \notin H$ Hence, the set of reflections cannot form a subgroup in themselves in any case. Now, we must consider sets involving both rotations and reflections and find conditions for them to form subgroups. By Lagrange's theorem, order of such a subgroup $H$ must divide $n$ as we have already found out the total number of subgroups of order $2$ So : (a) A reflection is it's self inverse (b) A reflection times a reflection is always a rotation (c) Inverse of a rotation $r^i = r^{n-i}$ (d) A rotation times a rotation is always a rotation. How do I choose such rotation and reflective elements such that they form a group. Suppose, $|H|=4$, In that case, $H$ should look something like this: $H = \{f_1,f_2,r^i,r^{n-i}\}$ where $f_1,f_2$ are reflections and $f_1f_2=r^i$ How can I extend this to $n$ variables? A hint to move ahead would be really appreciated. Thanks",,"['abstract-algebra', 'group-theory', 'dihedral-groups']"
40,What is the Betti number of a group?,What is the Betti number of a group?,,"I'm studying the Fundamental Theorem of finitely generated Abelian group, and it says that the number of factors equal to $\mathbb Z$ (textbook says it is the Betti number of the group) is unique up to isomorphism. So what is ""the number of factors""? I tried to find through Wikipedia, and it says that it is the number of generators. So if I'm right, the Betti number of Z_6 is 2 (since 1 and 5 are the generators). Then, what is Betti number of Z_360? Should I try all the cases that are relatively prime to 360? Is there any way to get it easier? I really want to fully understand the definition and applications. Thanks for your help :)","I'm studying the Fundamental Theorem of finitely generated Abelian group, and it says that the number of factors equal to $\mathbb Z$ (textbook says it is the Betti number of the group) is unique up to isomorphism. So what is ""the number of factors""? I tried to find through Wikipedia, and it says that it is the number of generators. So if I'm right, the Betti number of Z_6 is 2 (since 1 and 5 are the generators). Then, what is Betti number of Z_360? Should I try all the cases that are relatively prime to 360? Is there any way to get it easier? I really want to fully understand the definition and applications. Thanks for your help :)",,"['abstract-algebra', 'group-theory', 'abelian-groups', 'betti-numbers']"
41,Algebraic numbers and their closure,Algebraic numbers and their closure,,"Are all of the roots/zeroes of a polynomial of finite degree with algebraic coefficients algebraic? How about for a generalization of a polynomial wherein the indefinite is exponentiated to an algebraic power and then multiplied by an algebraic coefficient, where the number of terms is finite, provided that such a zero/root/value exists? In other words, must the values $z$ for which sums of summands of the form $az^b$ , where $a$ and $b$ are algebraic, evaluate to zero be algebraic (if such $z$ exists)?","Are all of the roots/zeroes of a polynomial of finite degree with algebraic coefficients algebraic? How about for a generalization of a polynomial wherein the indefinite is exponentiated to an algebraic power and then multiplied by an algebraic coefficient, where the number of terms is finite, provided that such a zero/root/value exists? In other words, must the values for which sums of summands of the form , where and are algebraic, evaluate to zero be algebraic (if such exists)?",z az^b a b z,"['abstract-algebra', 'algebraic-number-theory']"
42,Two-dimensional unital complex Banach algebras,Two-dimensional unital complex Banach algebras,,"Let $A_1$ be the matrix algebra consisting of matrices of the form $$ \pmatrix{ \alpha & 0 \\ 0 & \beta\\ }$$ and let $A_2$ be the matrix algebra consisting of matrices of the form $$ \pmatrix{ \alpha & \beta \\ 0 & \alpha\\ }.$$ I want to prove that these algebras are not isomorphic and that every two-dimensional unital complex Banach algebra is isomorphic to one of them. I have proved the first part: If such isomorphism exists, it would have to be multiplicative and bijective. Hence, a idempotent matrix in $A_1$ would be transformed to idempotent matrix in $A_2$. But those algebras have different numbers of idempotent algebras; a contradiction. Sadly, I have been defeated by the second part. Anyone can help?","Let $A_1$ be the matrix algebra consisting of matrices of the form $$ \pmatrix{ \alpha & 0 \\ 0 & \beta\\ }$$ and let $A_2$ be the matrix algebra consisting of matrices of the form $$ \pmatrix{ \alpha & \beta \\ 0 & \alpha\\ }.$$ I want to prove that these algebras are not isomorphic and that every two-dimensional unital complex Banach algebra is isomorphic to one of them. I have proved the first part: If such isomorphism exists, it would have to be multiplicative and bijective. Hence, a idempotent matrix in $A_1$ would be transformed to idempotent matrix in $A_2$. But those algebras have different numbers of idempotent algebras; a contradiction. Sadly, I have been defeated by the second part. Anyone can help?",,"['abstract-algebra', 'banach-algebras']"
43,Can we make an abelian group into a ring by defining multiplication only on a generating set?,Can we make an abelian group into a ring by defining multiplication only on a generating set?,,"Suppose we have an abelian group $(G,+)$ that is generated by some set $A\subseteq G$. Suppose that we are able to define a binary operation $\ast$ on $A$, i.e. $$\ast:A\times A\to A,\quad (a,b)\mapsto a\ast b,$$ such that $\ast$ is commutative, associative and such that there is an element $1\in A$ with the property that $1\ast a=a$, $\forall a\in A$. Can we always make $G$ into a ring $(G,+,\ast)$ by just ""imposing"" the distributivity laws? That is, we just define, for example, $a\ast(b+c):=a\ast b+a\ast c$ for $a,b,c\in A$, and so on. Is this always well-defined? If not, what do we need to check to say it is well-defined? Are there additional properties that $\ast$ has to satisfy?","Suppose we have an abelian group $(G,+)$ that is generated by some set $A\subseteq G$. Suppose that we are able to define a binary operation $\ast$ on $A$, i.e. $$\ast:A\times A\to A,\quad (a,b)\mapsto a\ast b,$$ such that $\ast$ is commutative, associative and such that there is an element $1\in A$ with the property that $1\ast a=a$, $\forall a\in A$. Can we always make $G$ into a ring $(G,+,\ast)$ by just ""imposing"" the distributivity laws? That is, we just define, for example, $a\ast(b+c):=a\ast b+a\ast c$ for $a,b,c\in A$, and so on. Is this always well-defined? If not, what do we need to check to say it is well-defined? Are there additional properties that $\ast$ has to satisfy?",,"['abstract-algebra', 'group-theory', 'ring-theory']"
44,Where is $k$ algebraically closed used?,Where is  algebraically closed used?,k,"Suppose $k$ is algebraically closed, $A$, $B$ are $k$-algebras and $A$ is an affine $k$-algebra. It is known that then $A\otimes_k B$ is a domain if $A$ and $B$ are domains. This can be found in Milne's Algebraic Geometry notes as Proposition 4.15(b). I do not see where the assumption $k$ algebraically closed is used. He gives an example that the above is not true if $k$ is not algebraically closed. But i dont see where this assumption is being used in the proof. I think that for an affine $k$-algebra the Jacobson radical is the nilradical, so here we do not need $k$ to be algebraically closed.","Suppose $k$ is algebraically closed, $A$, $B$ are $k$-algebras and $A$ is an affine $k$-algebra. It is known that then $A\otimes_k B$ is a domain if $A$ and $B$ are domains. This can be found in Milne's Algebraic Geometry notes as Proposition 4.15(b). I do not see where the assumption $k$ algebraically closed is used. He gives an example that the above is not true if $k$ is not algebraically closed. But i dont see where this assumption is being used in the proof. I think that for an affine $k$-algebra the Jacobson radical is the nilradical, so here we do not need $k$ to be algebraically closed.",,['abstract-algebra']
45,Possible Class equation for a group,Possible Class equation for a group,,"Determine the possible class equation for a group of order 21? Until now I have found the following: $1+3+3+7+7$ $1+1+1+3+3+3+9$ $1+1+1+1+1+1+1+7+7$ $1+1+1+1+1+1+1+1+1+3+3+3+3$ $1+1+1+\cdots +1 \ (21 \ \text{times})$ Is there any way to eliminate the choices from this equation? More importantly, how would we know that this is a complete list (Until now my attempt has just been guess and check after I found possible occurences of 1's) Is there any easier way to determine the class equation?","Determine the possible class equation for a group of order 21? Until now I have found the following: $1+3+3+7+7$ $1+1+1+3+3+3+9$ $1+1+1+1+1+1+1+7+7$ $1+1+1+1+1+1+1+1+1+3+3+3+3$ $1+1+1+\cdots +1 \ (21 \ \text{times})$ Is there any way to eliminate the choices from this equation? More importantly, how would we know that this is a complete list (Until now my attempt has just been guess and check after I found possible occurences of 1's) Is there any easier way to determine the class equation?",,"['abstract-algebra', 'finite-groups']"
46,Group of order 24 with no element of order 6 is isomorphic to $S_4$,Group of order 24 with no element of order 6 is isomorphic to,S_4,"Proposition : Given a group $G$ with $|G|=24$ such that $\nexists g\in G$ with $|g|=6$, then $G\cong S_4$. I understand methods you can employ to deduce the number of Sylow $p$-groups in $G$ by counting elements or reasoning about permutation representations. But how can we construct an isomorphism to $S_4$ given that $n_{2-\text{Sylow}}=3$ and $n_{3-\text{Sylow}}=4$? Or otherwise, rule out all other possible cases (perhaps reasoning with Cayley's Theorem)? I am also interested in finding a proof that is perhaps less direct, but more elegant, in particular one that may involve the irreducible representations of $S_4$. Any insight appreciated.","Proposition : Given a group $G$ with $|G|=24$ such that $\nexists g\in G$ with $|g|=6$, then $G\cong S_4$. I understand methods you can employ to deduce the number of Sylow $p$-groups in $G$ by counting elements or reasoning about permutation representations. But how can we construct an isomorphism to $S_4$ given that $n_{2-\text{Sylow}}=3$ and $n_{3-\text{Sylow}}=4$? Or otherwise, rule out all other possible cases (perhaps reasoning with Cayley's Theorem)? I am also interested in finding a proof that is perhaps less direct, but more elegant, in particular one that may involve the irreducible representations of $S_4$. Any insight appreciated.",,"['abstract-algebra', 'finite-groups', 'representation-theory', 'sylow-theory']"
47,Prime Number Theorem in $\mathbb{F}_p[x]$,Prime Number Theorem in,\mathbb{F}_p[x],"What is the probability that a randomly chosen monic polynomial of large degree $n$ in $\mathbb{F}_p[x]$ is irreducible? We can interpret this probability as $\displaystyle\lim_{n\to\infty}\frac{N_p(n)}{p^n},$ where $$N_p(n)=\frac{1}{n}\sum_{d|n}p^d\mu\left(\frac{n}{d}\right)$$ is the number of monic irreducibles of degree $n$ in $\mathbb{F}_p[x]$. I'm having trouble seeing how one would go about evaluating/describing the asymptotic behavior of this limit, any help is appreciated.","What is the probability that a randomly chosen monic polynomial of large degree $n$ in $\mathbb{F}_p[x]$ is irreducible? We can interpret this probability as $\displaystyle\lim_{n\to\infty}\frac{N_p(n)}{p^n},$ where $$N_p(n)=\frac{1}{n}\sum_{d|n}p^d\mu\left(\frac{n}{d}\right)$$ is the number of monic irreducibles of degree $n$ in $\mathbb{F}_p[x]$. I'm having trouble seeing how one would go about evaluating/describing the asymptotic behavior of this limit, any help is appreciated.",,"['abstract-algebra', 'analytic-number-theory']"
48,"If $H$ and $K$ are conjugate in $G$, are they conjugate in","If  and  are conjugate in , are they conjugate in",H K G,"Suppose $G$ is a group, with $H$ a subgroup.  Suppose that $K$ and $L$ are subgroups in $H$ that are conjugate in $G$, so we have an element $g\in G$ with $gKg^{-1}=L$.  Does it follow that $K$ and $L$ are conjugate in $N_G(H)$? Since $G=N_G(H)$ if $H$ is normal, the result holds for normal $H$.  If the result is not true in general, are there any less strict conditions (besides normality of $H$) to place on $(G,H,K,L)$ so that it is true?","Suppose $G$ is a group, with $H$ a subgroup.  Suppose that $K$ and $L$ are subgroups in $H$ that are conjugate in $G$, so we have an element $g\in G$ with $gKg^{-1}=L$.  Does it follow that $K$ and $L$ are conjugate in $N_G(H)$? Since $G=N_G(H)$ if $H$ is normal, the result holds for normal $H$.  If the result is not true in general, are there any less strict conditions (besides normality of $H$) to place on $(G,H,K,L)$ so that it is true?",,"['abstract-algebra', 'group-theory']"
49,The structure of the group $(\mathbb{Z}/2^n\mathbb{Z})^*$,The structure of the group,(\mathbb{Z}/2^n\mathbb{Z})^*,"I really got stuck with this exercise, can you help me? This is the total exercise. Calculate $(1+4)^{2^{n-3}}\in (\mathbb{Z}/2^n\mathbb{Z})^*$, and show that the element $5$ has order $2^{n-2}$ for $n \geq 2$. Prove that $5$ and $-1$ generate the group $(\mathbb{Z}/2^n\mathbb{Z})^*$. Prove that $ -1 \notin \langle 5\rangle$ Prove that $(\mathbb{Z}/2^n\mathbb{Z})^* \cong \mathbb{Z}/2\mathbb{Z} \times \mathbb{Z}/2^{n-2}\mathbb{Z}$. (This is an isomorphism of groups.) Here is what I tried to do. 1) The first thing I thought about is the binomial theorem: $$(1+4)^{2^{n-3}} \quad = \quad \sum_{i=0}^{2^{n-3}}\left( {\begin{array}{*{20}c} {2^{n-3}} \\ i \\ \end{array}} \right) 4^i \quad = \quad \sum_{i=0}^{2^{n-3}}\frac{2^{n-3}!\cdot 4^i}{i!(2^{n-3}-i)!}$$ And that is pretty much how far I came.  For the next part we should show that $5^{2^n-2}-1 = k\cdot 2^n$ for some integer $k$. What I knew is that $5^{2^n-2}$ is odd, so $5^{2^n-2}-1$ must be even. For more insight, I tried induction: base case . $5^{2^2 -2}-1= 0\cdot 2^n$ Induction step. Assume that $\exists n \in \mathbb{N},\exists k \in \mathbb{Z},5^{2^n-2}-1 = k\cdot 2^n$. Now we want to proof that for some integer $k'$ the identity $5^{2^{n+1}-2}-1 = k'\cdot 2^{n+1}$ holds. So this is what I did. $5^{2^{n+1}-2}=(5^{2^n-1})^2=(5^{2^n-2}\cdot 5)^2=(5^{2^n-2})^2\cdot 25$. From the induction hypotesis we obtain $5^{2^n-2}=2^n k+1 \quad \text{so that}\quad \ (5^{2^n-2})^2\cdot 25 = (2^n k+1)^2\cdot 25-1 = 25(2^n k +1)^2-1$. Let's expand this. $25(2^nk+1)^2-1 = 25\cdot 2^{2n}k^2 +25\cdot 2^{n+1}k+24$. This is another point where I got stuck. 2) Well, let's take an arbitrary element $x \in \mathbb{Z}$. Can we find $a,b \in \mathbb{Z}$ such that $(-1)^a\cdot 5^b = 2^n\cdot k$ for some integer $k$? I calculated $|(\mathbb{Z}/2^n\mathbb{Z})^*|=2^{n-1}$ by using Euler's product formula. By this, using the previous bits of the exercise, it's enough to show that $\langle -\bar{1}\rangle \cap \langle \bar{5}\rangle = \{1\}$ Because in that case $$|\langle -\bar{1},\bar{5}\rangle| =|\langle -\bar{1} \rangle| \cdot |\langle\bar{5}\rangle|=2 \cdot 2^{n-2} = |(\mathbb{Z}/2^n\mathbb{Z})^*|$$ This brings us to the next part. 3) Clearly $ -1 \notin \langle 5\rangle \iff \langle -\bar{1}\rangle \cap \langle \bar{5}\rangle = \{\bar{1}\}$, since $-\bar{1}$ is the only non-trivial element in $\langle \bar{1}\rangle$. I wanted to show the desired claim by contradiction. If $ -1 \in \langle 5\rangle$, then $\langle \bar{5} \rangle = (\mathbb{Z}/2^n\mathbb{Z})^*$ as remarked. Unfortunately, I don't see how this should contradict our premises. 4) When all the previous stuff will be proved, this is not that hard. We define the mapping $\quad \eta \quad : \quad \mathbb{Z}/2\mathbb{Z} \times \mathbb{Z}/2^{n-2}\mathbb{Z} \rightarrow \quad : \quad (\bar{i},\bar{j}) \mapsto (-1)^i\cdot5^j$. The mapping is well-defined because the order of the elements divides the group's order, surjective because of 2, injective because of 3 and an homomorphism because of the commutativity of $""\cdot""$. Hopefully this long story is legible, so that some of you will take the effort to find my mistakes, and give me some hints.","I really got stuck with this exercise, can you help me? This is the total exercise. Calculate $(1+4)^{2^{n-3}}\in (\mathbb{Z}/2^n\mathbb{Z})^*$, and show that the element $5$ has order $2^{n-2}$ for $n \geq 2$. Prove that $5$ and $-1$ generate the group $(\mathbb{Z}/2^n\mathbb{Z})^*$. Prove that $ -1 \notin \langle 5\rangle$ Prove that $(\mathbb{Z}/2^n\mathbb{Z})^* \cong \mathbb{Z}/2\mathbb{Z} \times \mathbb{Z}/2^{n-2}\mathbb{Z}$. (This is an isomorphism of groups.) Here is what I tried to do. 1) The first thing I thought about is the binomial theorem: $$(1+4)^{2^{n-3}} \quad = \quad \sum_{i=0}^{2^{n-3}}\left( {\begin{array}{*{20}c} {2^{n-3}} \\ i \\ \end{array}} \right) 4^i \quad = \quad \sum_{i=0}^{2^{n-3}}\frac{2^{n-3}!\cdot 4^i}{i!(2^{n-3}-i)!}$$ And that is pretty much how far I came.  For the next part we should show that $5^{2^n-2}-1 = k\cdot 2^n$ for some integer $k$. What I knew is that $5^{2^n-2}$ is odd, so $5^{2^n-2}-1$ must be even. For more insight, I tried induction: base case . $5^{2^2 -2}-1= 0\cdot 2^n$ Induction step. Assume that $\exists n \in \mathbb{N},\exists k \in \mathbb{Z},5^{2^n-2}-1 = k\cdot 2^n$. Now we want to proof that for some integer $k'$ the identity $5^{2^{n+1}-2}-1 = k'\cdot 2^{n+1}$ holds. So this is what I did. $5^{2^{n+1}-2}=(5^{2^n-1})^2=(5^{2^n-2}\cdot 5)^2=(5^{2^n-2})^2\cdot 25$. From the induction hypotesis we obtain $5^{2^n-2}=2^n k+1 \quad \text{so that}\quad \ (5^{2^n-2})^2\cdot 25 = (2^n k+1)^2\cdot 25-1 = 25(2^n k +1)^2-1$. Let's expand this. $25(2^nk+1)^2-1 = 25\cdot 2^{2n}k^2 +25\cdot 2^{n+1}k+24$. This is another point where I got stuck. 2) Well, let's take an arbitrary element $x \in \mathbb{Z}$. Can we find $a,b \in \mathbb{Z}$ such that $(-1)^a\cdot 5^b = 2^n\cdot k$ for some integer $k$? I calculated $|(\mathbb{Z}/2^n\mathbb{Z})^*|=2^{n-1}$ by using Euler's product formula. By this, using the previous bits of the exercise, it's enough to show that $\langle -\bar{1}\rangle \cap \langle \bar{5}\rangle = \{1\}$ Because in that case $$|\langle -\bar{1},\bar{5}\rangle| =|\langle -\bar{1} \rangle| \cdot |\langle\bar{5}\rangle|=2 \cdot 2^{n-2} = |(\mathbb{Z}/2^n\mathbb{Z})^*|$$ This brings us to the next part. 3) Clearly $ -1 \notin \langle 5\rangle \iff \langle -\bar{1}\rangle \cap \langle \bar{5}\rangle = \{\bar{1}\}$, since $-\bar{1}$ is the only non-trivial element in $\langle \bar{1}\rangle$. I wanted to show the desired claim by contradiction. If $ -1 \in \langle 5\rangle$, then $\langle \bar{5} \rangle = (\mathbb{Z}/2^n\mathbb{Z})^*$ as remarked. Unfortunately, I don't see how this should contradict our premises. 4) When all the previous stuff will be proved, this is not that hard. We define the mapping $\quad \eta \quad : \quad \mathbb{Z}/2\mathbb{Z} \times \mathbb{Z}/2^{n-2}\mathbb{Z} \rightarrow \quad : \quad (\bar{i},\bar{j}) \mapsto (-1)^i\cdot5^j$. The mapping is well-defined because the order of the elements divides the group's order, surjective because of 2, injective because of 3 and an homomorphism because of the commutativity of $""\cdot""$. Hopefully this long story is legible, so that some of you will take the effort to find my mistakes, and give me some hints.",,"['abstract-algebra', 'group-theory', 'abelian-groups']"
50,"Find $\mathrm{Aut}(G)$, $\mathrm{Inn}(G)$ and $\mathrm{Aut}(G)/\mathrm{Inn}(G)$ for $G = D_4$","Find ,  and  for",\mathrm{Aut}(G) \mathrm{Inn}(G) \mathrm{Aut}(G)/\mathrm{Inn}(G) G = D_4,"Problem Find $\mathrm{Aut}(G)$, $\mathrm{Inn}(G)$ and $\mathrm{Aut}(G)/\mathrm{Inn}(G)$ for $G = D_4$ My Attempt I let $D_4 = \{e, x, y, y^2, y^3, xy, xy^2, xy^3\}$ I found that $\mathrm{Inn}(G)$ consists of 4 bijective conjugation functions, namely $\{\phi_e, \phi_x, \phi_y, \phi_{xy}\}$.  For $\mathrm{Aut}(G)$, I found that there are 12 automorphisms. Here is the following link that relates to the problem I am doing. Based on the solution: Lemma : If $\alpha$ is an automorphism of group $G$ and $G$ has generators $x$ and $y$ with orders $n$ and $m$, respectively then $\alpha(x)$ and $\alpha(y)$ are also generators for $G$ with orders $n$ and $m$. Proof: First, let us show that the orders agree.  If $g \in G$ has order $n$, let $a = \alpha(g) \in G$ have order $m$.  Then, $a^m = 1$ but by applying $\alpha^{-1} \in \mathrm{Aut}(G)$, we get $g^m = 1$.  However, $g$ has order $n$, so $n$ must divide $m$.  Similarly, $g^n = 1$ and applying $\alpha$, we note that $a^n = 1$, and so we conclude $n = m$. Secondly, since any element of $G$ can be written as a product of $x$'s and $y$'s, and $\alpha$ is a surjective homomorphism, it follows that any element of $G$ can also be written as a product of $\alpha(x)$ and $\alpha(y)$, hence they generate $G$. Using this Lemma (or a similar argument), we note that an automorphism of $D_4$ must send $y$ to $y, xy, x^2y$ or $x^3y$ and $x$ to $x$ or $x^3$.  Any such pairing is possible, thus there are $2 \cdot 4 = 8$ such automorphisms... (The notations that someone use are different from what I denote.) The question I have is: Why are there 8 automorphisms?  Shouldn't there be 12 automorphisms?  Here is what I have: $$e \mapsto e$$ $$x \mapsto \text{ either } \{x,y^2, xy^2\}$$ $$y \mapsto \text{ either } \{y, y^3, xy, xy^3\}$$ Then, there are $1 \cdot 3 \cdot 4 = 12$ automorphisms. Any advices or comments?","Problem Find $\mathrm{Aut}(G)$, $\mathrm{Inn}(G)$ and $\mathrm{Aut}(G)/\mathrm{Inn}(G)$ for $G = D_4$ My Attempt I let $D_4 = \{e, x, y, y^2, y^3, xy, xy^2, xy^3\}$ I found that $\mathrm{Inn}(G)$ consists of 4 bijective conjugation functions, namely $\{\phi_e, \phi_x, \phi_y, \phi_{xy}\}$.  For $\mathrm{Aut}(G)$, I found that there are 12 automorphisms. Here is the following link that relates to the problem I am doing. Based on the solution: Lemma : If $\alpha$ is an automorphism of group $G$ and $G$ has generators $x$ and $y$ with orders $n$ and $m$, respectively then $\alpha(x)$ and $\alpha(y)$ are also generators for $G$ with orders $n$ and $m$. Proof: First, let us show that the orders agree.  If $g \in G$ has order $n$, let $a = \alpha(g) \in G$ have order $m$.  Then, $a^m = 1$ but by applying $\alpha^{-1} \in \mathrm{Aut}(G)$, we get $g^m = 1$.  However, $g$ has order $n$, so $n$ must divide $m$.  Similarly, $g^n = 1$ and applying $\alpha$, we note that $a^n = 1$, and so we conclude $n = m$. Secondly, since any element of $G$ can be written as a product of $x$'s and $y$'s, and $\alpha$ is a surjective homomorphism, it follows that any element of $G$ can also be written as a product of $\alpha(x)$ and $\alpha(y)$, hence they generate $G$. Using this Lemma (or a similar argument), we note that an automorphism of $D_4$ must send $y$ to $y, xy, x^2y$ or $x^3y$ and $x$ to $x$ or $x^3$.  Any such pairing is possible, thus there are $2 \cdot 4 = 8$ such automorphisms... (The notations that someone use are different from what I denote.) The question I have is: Why are there 8 automorphisms?  Shouldn't there be 12 automorphisms?  Here is what I have: $$e \mapsto e$$ $$x \mapsto \text{ either } \{x,y^2, xy^2\}$$ $$y \mapsto \text{ either } \{y, y^3, xy, xy^3\}$$ Then, there are $1 \cdot 3 \cdot 4 = 12$ automorphisms. Any advices or comments?",,"['abstract-algebra', 'group-theory']"
51,How do combinations (not permutations) relate to group theory?,How do combinations (not permutations) relate to group theory?,,"First question. I'm just generally curious about combinations in group theory. How do they relate? If I take the set of permutations of $\langle 1,2,3,4 \rangle$, I get the symmetry group S4. How about the set of permutations of $\langle 0,0,1,1 \rangle$? Longer question: Suppose I look at the power-set of all permutations of $\langle 0,0,1,1 \rangle$ (or any list with repeated elements): $\{\{\}, \{\langle 0,0,1,1\rangle\}, \{\langle 0,1,0,1\rangle \},\ldots,\{\langle 0,0,1,1\rangle,\langle 0,1,0,1 \rangle \}, \ldots\}$ Now apply this equivalency relationship to partition this set into equivalency classes: $\{E_1, E_2, \ldots, E_n\} \sim \{F_1, F_2, \ldots, F_n\}$ if and only if there exists a permutation such that applying this permutation to each of $\{E_1, E_2,\ldots, E_n\}$ results in ${F_1, F_2, \ldots, F_n} Examples: $\{ \langle 0,0,1,1\rangle  \} \sim \{ \langle 0,1,0,1\rangle  \}$ (transform is to swap the second and third elements) $\{ \langle 0,0,1,1\rangle  , \langle 0,1,0,1\rangle  \} = \{ \langle 0,1,0,1\rangle  , \langle 0,0,1,1\rangle  \}$ (sets are unordered. These are equal and equivalent) $\{ \langle 0,0,1,1\rangle  , \langle 0,1,0,1\rangle  \} \sim \{ \langle 0,1,1,0\rangle  , \langle 1,1,0,0\rangle  \}$ (both sets have a single overlapping '1' and '0') $\{ \langle 0,0,1,1\rangle  , \langle 0,1,0,1\rangle  \} \not= \{ \langle 0,1,1,0\rangle  , \langle 1,0,0,1\rangle  \}$ (not equivalent. Overlapping '$1$' and '$0$' in first set, but not second) There are exactly $11$ equivalency classes for the power-set of permutations of $\langle 0,0,1,1\rangle$. I'm mostly wondering how to enumerate these for larger sets of combinations, and was curious if each class cooresponds to a mathematical group.","First question. I'm just generally curious about combinations in group theory. How do they relate? If I take the set of permutations of $\langle 1,2,3,4 \rangle$, I get the symmetry group S4. How about the set of permutations of $\langle 0,0,1,1 \rangle$? Longer question: Suppose I look at the power-set of all permutations of $\langle 0,0,1,1 \rangle$ (or any list with repeated elements): $\{\{\}, \{\langle 0,0,1,1\rangle\}, \{\langle 0,1,0,1\rangle \},\ldots,\{\langle 0,0,1,1\rangle,\langle 0,1,0,1 \rangle \}, \ldots\}$ Now apply this equivalency relationship to partition this set into equivalency classes: $\{E_1, E_2, \ldots, E_n\} \sim \{F_1, F_2, \ldots, F_n\}$ if and only if there exists a permutation such that applying this permutation to each of $\{E_1, E_2,\ldots, E_n\}$ results in ${F_1, F_2, \ldots, F_n} Examples: $\{ \langle 0,0,1,1\rangle  \} \sim \{ \langle 0,1,0,1\rangle  \}$ (transform is to swap the second and third elements) $\{ \langle 0,0,1,1\rangle  , \langle 0,1,0,1\rangle  \} = \{ \langle 0,1,0,1\rangle  , \langle 0,0,1,1\rangle  \}$ (sets are unordered. These are equal and equivalent) $\{ \langle 0,0,1,1\rangle  , \langle 0,1,0,1\rangle  \} \sim \{ \langle 0,1,1,0\rangle  , \langle 1,1,0,0\rangle  \}$ (both sets have a single overlapping '1' and '0') $\{ \langle 0,0,1,1\rangle  , \langle 0,1,0,1\rangle  \} \not= \{ \langle 0,1,1,0\rangle  , \langle 1,0,0,1\rangle  \}$ (not equivalent. Overlapping '$1$' and '$0$' in first set, but not second) There are exactly $11$ equivalency classes for the power-set of permutations of $\langle 0,0,1,1\rangle$. I'm mostly wondering how to enumerate these for larger sets of combinations, and was curious if each class cooresponds to a mathematical group.",,"['abstract-algebra', 'combinatorics', 'group-theory', 'finite-groups', 'permutations']"
52,Prove that $S_4$ has no subgroup isomorphic to $Q_8$.,Prove that  has no subgroup isomorphic to .,S_4 Q_8,"The question is to prove that $S_4$ has no subgroup isomorphic to $Q_8$. Here is an answer. But what ""then $H$ also contains all products of two 2-cycles"" means in that answer? Thanks.","The question is to prove that $S_4$ has no subgroup isomorphic to $Q_8$. Here is an answer. But what ""then $H$ also contains all products of two 2-cycles"" means in that answer? Thanks.",,"['abstract-algebra', 'group-theory', 'finite-groups']"
53,Can we really understand $R$ by studying $R$-modules? [duplicate],Can we really understand  by studying -modules? [duplicate],R R,"This question already has answers here : What does $R-\mathrm{Mod}$ tell us about $R$? (2 answers) Closed 11 years ago . According to Algebra: Chapter 0 , the category $R\operatorname{-Mod}$ reveals a lot about $R$. However after completing the first eight chapters, I still found no examples where this happens. Can someone give some honest examples where the category of modules do tell us a lot about the underlying ring? Better still, such kind of information is very difficult if one looks at the ring directly. Thanks very much!","This question already has answers here : What does $R-\mathrm{Mod}$ tell us about $R$? (2 answers) Closed 11 years ago . According to Algebra: Chapter 0 , the category $R\operatorname{-Mod}$ reveals a lot about $R$. However after completing the first eight chapters, I still found no examples where this happens. Can someone give some honest examples where the category of modules do tell us a lot about the underlying ring? Better still, such kind of information is very difficult if one looks at the ring directly. Thanks very much!",,"['abstract-algebra', 'reference-request', 'commutative-algebra', 'category-theory', 'modules']"
54,degree of a field extension,degree of a field extension,,"Let $\alpha$ be a root of $x^3+3x-1$ and $\beta$ be a root of $x^3-x+2$. What is the degree of $\mathbb{Q}(\alpha^2+\beta)$ over $\mathbb{Q}$? My guess is 9, because i found a monic polynomial of degree 9 with integer coefficient, irreducible in $\mathbb{Q}[x]$ with $\alpha^2+\beta$ as a root. But i don't know if this suffices. Any help?","Let $\alpha$ be a root of $x^3+3x-1$ and $\beta$ be a root of $x^3-x+2$. What is the degree of $\mathbb{Q}(\alpha^2+\beta)$ over $\mathbb{Q}$? My guess is 9, because i found a monic polynomial of degree 9 with integer coefficient, irreducible in $\mathbb{Q}[x]$ with $\alpha^2+\beta$ as a root. But i don't know if this suffices. Any help?",,"['abstract-algebra', 'field-theory', 'extension-field']"
55,"Prove that if H is a subgroup of G, then H is a normal subgroup of G iff $\forall x, y \in G$, xy $\in$ H iff yx $\in$ H.","Prove that if H is a subgroup of G, then H is a normal subgroup of G iff , xy  H iff yx  H.","\forall x, y \in G \in \in","So the problem is as follows: Prove that if H is a subgroup of G, then H is a normal subgroup of G iff the following condition holds : $$\forall x,y \in G, xy \in H \iff yx \in H$$ It's all completed now: We are given that H is a subgroup of G. ( $\def\impl{\;\Rightarrow\;}\impl$ ) Assume H is a normal subgroup of G. So, $$\forall h \in H, \forall g \in G, ghg^-1  \in H.$$ Suppose $$\forall x,y \in G, xy \in H.$$ Since H is a normal subgroup of G and $$y \in G,$$ we know $$y(xy)y^-1\in H \impl yx(yy^-1)\in H \impl yxe \in H \impl yx \in H.$$ Similarly, suppose $$\forall x,y \in G, yx \in H.$$ Since H is a normal subgroup of G and $$x \in G,$$ we know $$x(yx)x^-1\in H\impl xy(xx^-1)\in H\impl xye \in H\impl xy \in H.$$ ( $\;\Leftarrow\;$ ) Assume $$\forall x,y\in G, xy\in H \iff yx \in H.$$ Now let $$a=yx \impl xa=x(yx) \impl (xa)x^-1=(xy)xx^-1 \impl xax^-1 = xy.$$ So $$ \forall x\in G, \forall a\in H,  a \in H \impl xax^-1 \in H.$$ Therefore H is a normal subgroup of G.","So the problem is as follows: Prove that if H is a subgroup of G, then H is a normal subgroup of G iff the following condition holds : It's all completed now: We are given that H is a subgroup of G. ( ) Assume H is a normal subgroup of G. So, Suppose Since H is a normal subgroup of G and we know Similarly, suppose Since H is a normal subgroup of G and we know ( ) Assume Now let So Therefore H is a normal subgroup of G.","\forall x,y \in G, xy \in H \iff yx \in H \def\impl{\;\Rightarrow\;}\impl \forall h \in H, \forall g \in G, ghg^-1  \in H. \forall x,y \in G, xy \in H. y \in G, y(xy)y^-1\in H \impl yx(yy^-1)\in H \impl yxe \in H \impl yx \in H. \forall x,y \in G, yx \in H. x \in G, x(yx)x^-1\in H\impl xy(xx^-1)\in H\impl xye \in H\impl xy \in H. \;\Leftarrow\; \forall x,y\in G, xy\in H \iff yx \in H. a=yx \impl xa=x(yx) \impl (xa)x^-1=(xy)xx^-1 \impl xax^-1 = xy.  \forall x\in G, \forall a\in H,  a \in H \impl xax^-1 \in H.",['abstract-algebra']
56,Tensor product of module homomorphisms,Tensor product of module homomorphisms,,"This is an exercise problem from Hungerford's Algebra but first I'll state a result that forms the background to the problem. Let $R$ be a ring. Let $A,A'$ be right $R$-modules. Let $B,B'$ be left $R$-modules. Let $f:A\rightarrow A'$ and $g:B\rightarrow B'$ be $R$-module homomorphisms. Then there is a unique group homomorphism $f\otimes g:A\otimes_{R}B\rightarrow A'\otimes_{R}B'$ such that $a\otimes b\mapsto f(a)\otimes g(b)$ for all $a\in A,b\in B$. What is the difference between the homomorphism $f\otimes g$ above and the element $f\otimes g$ of the tensor product of abelian groups $\mathrm{Hom}_{R}(A,A')\otimes\mathrm{Hom}_{R}(B,B')$? The only answer I can think of is that the former is really a map but the latter is actually a coset. Is this right? If it is, can this answer be improved? Are there other answers?","This is an exercise problem from Hungerford's Algebra but first I'll state a result that forms the background to the problem. Let $R$ be a ring. Let $A,A'$ be right $R$-modules. Let $B,B'$ be left $R$-modules. Let $f:A\rightarrow A'$ and $g:B\rightarrow B'$ be $R$-module homomorphisms. Then there is a unique group homomorphism $f\otimes g:A\otimes_{R}B\rightarrow A'\otimes_{R}B'$ such that $a\otimes b\mapsto f(a)\otimes g(b)$ for all $a\in A,b\in B$. What is the difference between the homomorphism $f\otimes g$ above and the element $f\otimes g$ of the tensor product of abelian groups $\mathrm{Hom}_{R}(A,A')\otimes\mathrm{Hom}_{R}(B,B')$? The only answer I can think of is that the former is really a map but the latter is actually a coset. Is this right? If it is, can this answer be improved? Are there other answers?",,['abstract-algebra']
57,Roots of unity in $\mathbb Q_p$,Roots of unity in,\mathbb Q_p,"Is there a way to get the number of solutions of an equation like $x^n=1$ in the p-adic field $\mathbb Q_p$, where $p$ is a prime and $n$ a positive integer? I know that for $n=p-1$ there are $p-1$ roots of unity. Are there any theorems for other cases? Best Regards","Is there a way to get the number of solutions of an equation like $x^n=1$ in the p-adic field $\mathbb Q_p$, where $p$ is a prime and $n$ a positive integer? I know that for $n=p-1$ there are $p-1$ roots of unity. Are there any theorems for other cases? Best Regards",,"['abstract-algebra', 'number-theory', 'reference-request', 'p-adic-number-theory']"
58,Tensor on Exterior Algebra,Tensor on Exterior Algebra,,"I hope someone can help me on showing that $(\wedge^k(M))^*\otimes \wedge^n(M) = \wedge^{n-k}(M)$, where $M$ is a free $R$-module of rank $n$, and $^*$ is the dual. From what I know, $(\wedge^k(M))^* = \mbox{Hom}(\wedge^k(M), R)$. But how do I incorporate it with the tensor product, or am I even on the right track? My intuition tells me that if $\varphi \in \mbox{Hom}(\wedge^k(M), R)$, then it somehow ""reduces"" an element of $\wedge^{k}(M)$ to $R$, and so explains the $\wedge^{n-k}(M)$ part of the equality. Though I am not entirely sure of this. Any help is much appreciated. Thanks!","I hope someone can help me on showing that $(\wedge^k(M))^*\otimes \wedge^n(M) = \wedge^{n-k}(M)$, where $M$ is a free $R$-module of rank $n$, and $^*$ is the dual. From what I know, $(\wedge^k(M))^* = \mbox{Hom}(\wedge^k(M), R)$. But how do I incorporate it with the tensor product, or am I even on the right track? My intuition tells me that if $\varphi \in \mbox{Hom}(\wedge^k(M), R)$, then it somehow ""reduces"" an element of $\wedge^{k}(M)$ to $R$, and so explains the $\wedge^{n-k}(M)$ part of the equality. Though I am not entirely sure of this. Any help is much appreciated. Thanks!",,"['abstract-algebra', 'tensor-products']"
59,Localization at a Maximal Ideal,Localization at a Maximal Ideal,,"While studying, I came across this question: If $A$ is a ring in which $x^n=x$ for all $x\in A$ (where $n$ is an integer greater than $1$ and may depend on $x$), show all prime ideals are maximal. I didn't find the solution too hard (if it is correct). We let $P$ be a prime ideal. That $A/P$ is an integral domain; if we can show it is also a field, we'll know that $P$ is maximal. To that end, we know $a^n+P=a+P$, and in particular, $(a+P)(a^{n-1}+P)=(a+P)(1+P)$. Since we're in an integral domain, the cancellation law applies, so we have $(a^{n-1}+P)=(1+P)$. Now we have $(a+P)(a^{n-2}+P)=(1+P)$, hence $(a+P)$ has an inverse, so $A/P$ is a field. The next question has me confused, though: Let $\mathbf{m}$ be a prime ideal in a ring in which $x^n=x$ for all $x\in A$ (where $n$ is an integer greater than $1$ and may depend on $x$). Show that $A_\mathbf{m}$ is a field. It seems like $A_\mathbf{m}$ should not be a field since $\frac{m}{1}$, $m\in\mathbf{m}$ wouldn't have an inverse, thus it would have to be in the equivalence class of $\frac{0}{1}$, but I don't see why that is true (if it indeed is true). Please help clear this up for me!","While studying, I came across this question: If $A$ is a ring in which $x^n=x$ for all $x\in A$ (where $n$ is an integer greater than $1$ and may depend on $x$), show all prime ideals are maximal. I didn't find the solution too hard (if it is correct). We let $P$ be a prime ideal. That $A/P$ is an integral domain; if we can show it is also a field, we'll know that $P$ is maximal. To that end, we know $a^n+P=a+P$, and in particular, $(a+P)(a^{n-1}+P)=(a+P)(1+P)$. Since we're in an integral domain, the cancellation law applies, so we have $(a^{n-1}+P)=(1+P)$. Now we have $(a+P)(a^{n-2}+P)=(1+P)$, hence $(a+P)$ has an inverse, so $A/P$ is a field. The next question has me confused, though: Let $\mathbf{m}$ be a prime ideal in a ring in which $x^n=x$ for all $x\in A$ (where $n$ is an integer greater than $1$ and may depend on $x$). Show that $A_\mathbf{m}$ is a field. It seems like $A_\mathbf{m}$ should not be a field since $\frac{m}{1}$, $m\in\mathbf{m}$ wouldn't have an inverse, thus it would have to be in the equivalence class of $\frac{0}{1}$, but I don't see why that is true (if it indeed is true). Please help clear this up for me!",,"['abstract-algebra', 'ring-theory', 'ideals']"
60,"How to find all morphisms from $(\mathbb{N}, \mid)$ to $(\mathbb{N}, \mid)$?",How to find all morphisms from  to ?,"(\mathbb{N}, \mid) (\mathbb{N}, \mid)","I just need a small hint, not the full answer. I know that, if $f$ is a morphism, $a \mid b \implies f(a) \mid f(b)$ $a \mid b$ and $a \mid c \implies a \mid b+c$, so $f(a) \mid f(b),   f(a) \mid f(c), f(a) \mid f(b + c)$. Also, $f(a) \mid f(b) + f(c)$ $\forall a \in \mathbb{N}, a \mid 0$, so $\forall a \in \mathbb{N}, f(a) \mid f(0)$ $\forall a \in \mathbb{N}, 1 \mid a$, so  $\forall a \in \mathbb{N}, f(1) \mid f(a) $ From these I can draw some conclusions: a. From 3., $f(0) = a$ ($a \neq 0$), $f(\mathbb{N})$ only contains divisors of $a$. b. From 4., if $f(1) = a$, then $f(\mathbb{N})$ only contains multiples of $a$. The most general form I can think of for f is this: $f(x) = ax^{b} (a, b \in \mathbb{N})$, but I can't seem to go any further than this. Any help is appreciated.","I just need a small hint, not the full answer. I know that, if $f$ is a morphism, $a \mid b \implies f(a) \mid f(b)$ $a \mid b$ and $a \mid c \implies a \mid b+c$, so $f(a) \mid f(b),   f(a) \mid f(c), f(a) \mid f(b + c)$. Also, $f(a) \mid f(b) + f(c)$ $\forall a \in \mathbb{N}, a \mid 0$, so $\forall a \in \mathbb{N}, f(a) \mid f(0)$ $\forall a \in \mathbb{N}, 1 \mid a$, so  $\forall a \in \mathbb{N}, f(1) \mid f(a) $ From these I can draw some conclusions: a. From 3., $f(0) = a$ ($a \neq 0$), $f(\mathbb{N})$ only contains divisors of $a$. b. From 4., if $f(1) = a$, then $f(\mathbb{N})$ only contains multiples of $a$. The most general form I can think of for f is this: $f(x) = ax^{b} (a, b \in \mathbb{N})$, but I can't seem to go any further than this. Any help is appreciated.",,['abstract-algebra']
61,Isomorphism Types,Isomorphism Types,,"I'm a little panicking right now.  I have finals soon, and I don't know how to go about solving this: Classify the isomorphism types of abelian groups of order 44. Solutions or even hints would be much appreciated.","I'm a little panicking right now.  I have finals soon, and I don't know how to go about solving this: Classify the isomorphism types of abelian groups of order 44. Solutions or even hints would be much appreciated.",,['abstract-algebra']
62,The splitting field of $x^3+x^2+1$ over ${\Bbb Z}/(2)$,The splitting field of  over,x^3+x^2+1 {\Bbb Z}/(2),"Let $F=\mathbb Z/(2)$. The splitting field of $x^3+x^2+1\in F[x]$ is a finite field with eight elements. my attempt of solution: If $\alpha$ is a root in this polynomial in its splitting field, then I would like to prove that $F(\alpha)$ is the splitting field. what I get is $x^3+x^2+1=(x-\alpha)(x^2+(1+\alpha)x+(\alpha +\alpha^2))$. I'm trying to find the root of $x^2+(1+\alpha)x+(\alpha +\alpha^2)$, maybe it's a multiple of $\alpha$. I need help! thanks","Let $F=\mathbb Z/(2)$. The splitting field of $x^3+x^2+1\in F[x]$ is a finite field with eight elements. my attempt of solution: If $\alpha$ is a root in this polynomial in its splitting field, then I would like to prove that $F(\alpha)$ is the splitting field. what I get is $x^3+x^2+1=(x-\alpha)(x^2+(1+\alpha)x+(\alpha +\alpha^2))$. I'm trying to find the root of $x^2+(1+\alpha)x+(\alpha +\alpha^2)$, maybe it's a multiple of $\alpha$. I need help! thanks",,"['abstract-algebra', 'polynomials', 'field-theory']"
63,Every proper ideal contained in a maximal ideal?,Every proper ideal contained in a maximal ideal?,,"This is a true in a commutative ring with $1$, but does it also hold in a noncommutative ring with $1$?   The proof in my book is just an application of Zorn's lemma, but the commutativity of the ring is not used anywhere.","This is a true in a commutative ring with $1$, but does it also hold in a noncommutative ring with $1$?   The proof in my book is just an application of Zorn's lemma, but the commutativity of the ring is not used anywhere.",,"['abstract-algebra', 'ideals']"
64,A property of the resultant,A property of the resultant,,"Let $A$ be a domain. There's a problem in Lorenzini's An Invitation to Arithmetic Geometry , which states that if $f,g\in A[y]$, then we can find $u,v\in A[y]$ with $\deg u<\deg g$ and $\deg v<\deg f$ s.t. $$uf+vg = \textrm{Res}(f,g).$$ Is there an easy way to see this?","Let $A$ be a domain. There's a problem in Lorenzini's An Invitation to Arithmetic Geometry , which states that if $f,g\in A[y]$, then we can find $u,v\in A[y]$ with $\deg u<\deg g$ and $\deg v<\deg f$ s.t. $$uf+vg = \textrm{Res}(f,g).$$ Is there an easy way to see this?",,"['abstract-algebra', 'polynomials', 'integral-domain']"
65,Prove that R is a ring under 'special' definitions of multiplication and addition,Prove that R is a ring under 'special' definitions of multiplication and addition,,"Question: Let R be a ring with a 1. Define $\bar R$ to have the same elements of R with addition  $$\oplus: a \oplus b = a +b +1$$ andmultiplication $$\otimes: a \otimes b = ab + a +b$$ Prove that $\bar R$ is a ring under $\oplus$ and $\otimes$ and has a 1. My Attempt: My understanding of a ring is it should be a non-empty set together with operations addition and multiplication satisfying the following conditions: R is an Abelian group under multiplication R must be closed and associative under multiplication Multiplication must be distributive over addition i.e. $a(b+c) = ab + ac$ and $(a+b)c= ac +bc$ So I try to show that all those conditions are satisfied: $$1$$ $$ a \otimes b = ab + a + b$$ $$ b \otimes a = ba + b +a $$ In order for $a \otimes b$ to be equal to $b \otimes a$ it must be that $ba = ab$ (how do I prove this? - do I even need to prove this?) $$2$$ Closed: $$ a \otimes b = ab + a + b$$ if $a, b \in \bar R$ then $ab, \in \bar R$, $(a + b) \in \bar R$ and therefore $ab + a + b$ must be in $ \bar R$. (Do I need to prove this? Or is that pattern of thought good enough?) Associative: let's introduce an element $c \in \bar R$ and examine the associativity property. $$ \begin{align}  (a \otimes b) \otimes c & = \ (ab + a + b) \otimes c\\ & = \ abc + ac + bc + ab + a + b + c \\ & = \ a \otimes (bc + b + c) \\ & = \ a \otimes (b \otimes c) \\ & = \ a \otimes b \otimes c \\ \end{align} $$ So it is indeed associative under multiplication. $$3$$ $$ \begin{align} a \otimes (b \oplus c) & = \ a \otimes (b + c + 1) \\ & = \ ab + ac + a + a + b + c + 1 \\ & = \ ab + b + a + ac + a + c + 1 \\ & = \ a\otimes b \oplus \ a \otimes c \\ \end{align} $$ And I'm sure if I tinker around with the $(a + b)c = ac + bc$ equation I will find that it is also true so it does satisfy the distributive law. The second part of the question demands that I show that $ \bar R$ has a 1. I understand a 1 to have the property: $a\times1= a$. So considering it in this ring we're looking for a $x$ that does this: $$a \otimes x = a$$  $$ a \otimes x = ax + x + a = a$$ Just from looking at the equation and using my intuition one can see that when $x=0$ the equation is true. So I would say that x=0 is the 1 of this ring. 0 is the multiplicative identity of $\bar R$ My Concerns: Can I conclude after having done all this that $\bar R$ is in fact a Ring? Have I answered the question sufficiently enough?","Question: Let R be a ring with a 1. Define $\bar R$ to have the same elements of R with addition  $$\oplus: a \oplus b = a +b +1$$ andmultiplication $$\otimes: a \otimes b = ab + a +b$$ Prove that $\bar R$ is a ring under $\oplus$ and $\otimes$ and has a 1. My Attempt: My understanding of a ring is it should be a non-empty set together with operations addition and multiplication satisfying the following conditions: R is an Abelian group under multiplication R must be closed and associative under multiplication Multiplication must be distributive over addition i.e. $a(b+c) = ab + ac$ and $(a+b)c= ac +bc$ So I try to show that all those conditions are satisfied: $$1$$ $$ a \otimes b = ab + a + b$$ $$ b \otimes a = ba + b +a $$ In order for $a \otimes b$ to be equal to $b \otimes a$ it must be that $ba = ab$ (how do I prove this? - do I even need to prove this?) $$2$$ Closed: $$ a \otimes b = ab + a + b$$ if $a, b \in \bar R$ then $ab, \in \bar R$, $(a + b) \in \bar R$ and therefore $ab + a + b$ must be in $ \bar R$. (Do I need to prove this? Or is that pattern of thought good enough?) Associative: let's introduce an element $c \in \bar R$ and examine the associativity property. $$ \begin{align}  (a \otimes b) \otimes c & = \ (ab + a + b) \otimes c\\ & = \ abc + ac + bc + ab + a + b + c \\ & = \ a \otimes (bc + b + c) \\ & = \ a \otimes (b \otimes c) \\ & = \ a \otimes b \otimes c \\ \end{align} $$ So it is indeed associative under multiplication. $$3$$ $$ \begin{align} a \otimes (b \oplus c) & = \ a \otimes (b + c + 1) \\ & = \ ab + ac + a + a + b + c + 1 \\ & = \ ab + b + a + ac + a + c + 1 \\ & = \ a\otimes b \oplus \ a \otimes c \\ \end{align} $$ And I'm sure if I tinker around with the $(a + b)c = ac + bc$ equation I will find that it is also true so it does satisfy the distributive law. The second part of the question demands that I show that $ \bar R$ has a 1. I understand a 1 to have the property: $a\times1= a$. So considering it in this ring we're looking for a $x$ that does this: $$a \otimes x = a$$  $$ a \otimes x = ax + x + a = a$$ Just from looking at the equation and using my intuition one can see that when $x=0$ the equation is true. So I would say that x=0 is the 1 of this ring. 0 is the multiplicative identity of $\bar R$ My Concerns: Can I conclude after having done all this that $\bar R$ is in fact a Ring? Have I answered the question sufficiently enough?",,"['abstract-algebra', 'ring-theory', 'abelian-groups']"
66,Order of a set $X$ acted upon transitively by the Symmetric Group,Order of a set  acted upon transitively by the Symmetric Group,X,"Suppose the symmetric group $S_n$ acts transitively on a set $X$, i.e. for every $x, y \in X$, $\exists g \in S_n$ such that $gx = y$. Show that either $|X| \le 2$ or $|X| \ge n$. Small steps towards the solution: As $S_n$ acts transitively on a set $X$, the whole of $X$ is one single orbit under the action of $S_n$. By the Orbit-Stabilizer Theorem, then, $|X|$ = $|S_n : \text{Stabilizer of }x|$ for any $x \in X$. We also know that the Stabilizer of any $x \in X$ is a subgroup of $S_n$. When $|X| = 2$, the Stabilizer of $x$ is the alternating group $A_n$. I'm halfway but can't get the final result. Any help would be much appreciated, as always. Thank you.","Suppose the symmetric group $S_n$ acts transitively on a set $X$, i.e. for every $x, y \in X$, $\exists g \in S_n$ such that $gx = y$. Show that either $|X| \le 2$ or $|X| \ge n$. Small steps towards the solution: As $S_n$ acts transitively on a set $X$, the whole of $X$ is one single orbit under the action of $S_n$. By the Orbit-Stabilizer Theorem, then, $|X|$ = $|S_n : \text{Stabilizer of }x|$ for any $x \in X$. We also know that the Stabilizer of any $x \in X$ is a subgroup of $S_n$. When $|X| = 2$, the Stabilizer of $x$ is the alternating group $A_n$. I'm halfway but can't get the final result. Any help would be much appreciated, as always. Thank you.",,"['abstract-algebra', 'group-theory', 'representation-theory', 'finite-groups', 'symmetric-groups']"
67,"Prove if an element of a monoid has an inverse, that inverse is unique","Prove if an element of a monoid has an inverse, that inverse is unique",,"I'm in the beginning stages of this proof.  My question here I guess is that by definition a monoid has the properties that it is associative and has an identity. So: $(ab)c=a(bc)$ and $de=ed=e$ where $e$ is the identity. If I can prove that the identity is unique, does that prove the inverse is unique?","I'm in the beginning stages of this proof.  My question here I guess is that by definition a monoid has the properties that it is associative and has an identity. So: $(ab)c=a(bc)$ and $de=ed=e$ where $e$ is the identity. If I can prove that the identity is unique, does that prove the inverse is unique?",,"['abstract-algebra', 'monoid']"
68,A question about the proof that $(\mathbb{Z}/p\mathbb{Z})^\times$ is cyclic,A question about the proof that  is cyclic,(\mathbb{Z}/p\mathbb{Z})^\times,"Let $p>2$ be a prime number, and $y$ be an element of order $d$ in $(\mathbb{Z}/p\mathbb{Z})^\times$, $d \in \mathbb{N}$. I already know that $x^d \equiv 1 \mod p$ has $d$ solutions. Then how to show that every element of order $d$ is one of the $\varphi(d)$ generators of the group generated by $y$?","Let $p>2$ be a prime number, and $y$ be an element of order $d$ in $(\mathbb{Z}/p\mathbb{Z})^\times$, $d \in \mathbb{N}$. I already know that $x^d \equiv 1 \mod p$ has $d$ solutions. Then how to show that every element of order $d$ is one of the $\varphi(d)$ generators of the group generated by $y$?",,"['abstract-algebra', 'elementary-number-theory']"
69,Finite Field Extension,Finite Field Extension,,"Suppose $E/F$ is a field extension of degree $n$. Does it follow that $E = F(a_{1}, a_{2}, \ldots, a_{n})$ for some $a_{i} \in E$? I feel like this is true, but I'm getting confused with all the definitions.","Suppose $E/F$ is a field extension of degree $n$. Does it follow that $E = F(a_{1}, a_{2}, \ldots, a_{n})$ for some $a_{i} \in E$? I feel like this is true, but I'm getting confused with all the definitions.",,['abstract-algebra']
70,Equivalent definitions of residual finite groups,Equivalent definitions of residual finite groups,,"Let $G$ be a group. In the literature, I have encountered the following two definitions of residually finite group $G$ : Definition 1: $G$ is called residually finite if for all $x\ne 1$ , there exists a normal subgroup $N\lhd G$ of finite index such that $x\notin N$ . This is e.g. the definition on Wikipedia , where equivalent characterisations are given. On the other hand, I have also encountered the following definition in e.g. Brown-Ozawa's book "" $C^*$ -algebras and finite-dimensional approximations"" or other $C^*$ -literature: Definition 2: $G$ is called residually finite if there exists a descreasing sequence of normal subgroups $$G \supseteq G_1 \supseteq G_2 \supseteq G_3 \supseteq \dots$$ such that $G_i$ is of finite index in $G$ for all $i\ge 1$ and such that $\bigcap_{i=1}^\infty G_i = \{1\}$ . My question: Are these definitions equivalent? It is clear to me that Definition 2 implies Definition 1, so concretely, I want to know why Definition 1 implies Definition 2. I don't see how to construct the desired decreasing sequence of normal subgroups. Maybe, we need to assume that the group $G$ is countable? Any help will be highly appreciated!","Let be a group. In the literature, I have encountered the following two definitions of residually finite group : Definition 1: is called residually finite if for all , there exists a normal subgroup of finite index such that . This is e.g. the definition on Wikipedia , where equivalent characterisations are given. On the other hand, I have also encountered the following definition in e.g. Brown-Ozawa's book "" -algebras and finite-dimensional approximations"" or other -literature: Definition 2: is called residually finite if there exists a descreasing sequence of normal subgroups such that is of finite index in for all and such that . My question: Are these definitions equivalent? It is clear to me that Definition 2 implies Definition 1, so concretely, I want to know why Definition 1 implies Definition 2. I don't see how to construct the desired decreasing sequence of normal subgroups. Maybe, we need to assume that the group is countable? Any help will be highly appreciated!",G G G x\ne 1 N\lhd G x\notin N C^* C^* G G \supseteq G_1 \supseteq G_2 \supseteq G_3 \supseteq \dots G_i G i\ge 1 \bigcap_{i=1}^\infty G_i = \{1\} G,"['abstract-algebra', 'group-theory']"
71,Finitely generated modules over local domains,Finitely generated modules over local domains,,"Let $R$ be an integral domain. Let $P$ be a finitely generated $R$ -module. The problem: If we additionally assume that $R$ is a local ring (that is, $R$ is a local domain), is the following statement true? "" $P$ is torsion-free if and only if $P$ is projective."" Some facts I know/encountered and the result of my search... I apologize if this might be messy but I want to ensure everybody is on the same page as me. If $R$ is just an integral domain then the statement is not necessarily true. If $R$ is a principal ideal domain (PID) then the statement is true (easily proven using the structure theorem of modules over PIDs). If $R$ is a local ring and we drop the integral domain assumption then the statement is not necessarily true. If $R$ is a discrete valuation ring (= local ring + PID) then the statement is true (since it is a module over PID). Discrete valuation rings are valuation rings but the converse is not necessarily true. Valuation rings are integral domains and local rings. A valuation ring is Noetherian if and only if it is a discrete valuation ring or a field. (Thus, the statement above is true for Noetherian valuation rings) An integral domain is a valuation ring if and only if it is a Bézout ring and a local ring. [Proposition 1.5, Krull] A local ring is a Bézout domain if and only if it is a valuation ring. A Bézout domain is a Prüfer domain. ""A finitely generated module M over a Prüfer domain is projective if and only if it is torsion-free."" (Converse direction ""A finitely generated torsion-free module $M$ over a Prüfer domain $R$ is projective."" proven in textbook [Theorem 2.7, Modules over Non-Noetherian Domains by Fuchs & Salce, original result proven by Kaplansky]) The conclusion I have from all the statements above is: $$\{ \textit{discrete valuation ring} \} \supset \{ \textit{valuation ring} \} \supset \{ \textit{local rings} \} \cap \{ \textit{Bézout rings} \} \supset \{ \textit{local rings} \}  \cap \{ \textit{Prüfer domain}\}$$ and any ring in any collection above will make the statement true. The subquestions I am currently thinking about in hopes to answer the question above: If $R$ is a local domain, then is $R$ a Prüfer domain? If this is true, then we are done. If it is not true, I am hoping to construct a counter-example... In case this question is simpler, are there examples of rings that is a local domain but not a valuation ring?","Let be an integral domain. Let be a finitely generated -module. The problem: If we additionally assume that is a local ring (that is, is a local domain), is the following statement true? "" is torsion-free if and only if is projective."" Some facts I know/encountered and the result of my search... I apologize if this might be messy but I want to ensure everybody is on the same page as me. If is just an integral domain then the statement is not necessarily true. If is a principal ideal domain (PID) then the statement is true (easily proven using the structure theorem of modules over PIDs). If is a local ring and we drop the integral domain assumption then the statement is not necessarily true. If is a discrete valuation ring (= local ring + PID) then the statement is true (since it is a module over PID). Discrete valuation rings are valuation rings but the converse is not necessarily true. Valuation rings are integral domains and local rings. A valuation ring is Noetherian if and only if it is a discrete valuation ring or a field. (Thus, the statement above is true for Noetherian valuation rings) An integral domain is a valuation ring if and only if it is a Bézout ring and a local ring. [Proposition 1.5, Krull] A local ring is a Bézout domain if and only if it is a valuation ring. A Bézout domain is a Prüfer domain. ""A finitely generated module M over a Prüfer domain is projective if and only if it is torsion-free."" (Converse direction ""A finitely generated torsion-free module over a Prüfer domain is projective."" proven in textbook [Theorem 2.7, Modules over Non-Noetherian Domains by Fuchs & Salce, original result proven by Kaplansky]) The conclusion I have from all the statements above is: and any ring in any collection above will make the statement true. The subquestions I am currently thinking about in hopes to answer the question above: If is a local domain, then is a Prüfer domain? If this is true, then we are done. If it is not true, I am hoping to construct a counter-example... In case this question is simpler, are there examples of rings that is a local domain but not a valuation ring?",R P R R R P P R R R R M R \{ \textit{discrete valuation ring} \} \supset \{ \textit{valuation ring} \} \supset \{ \textit{local rings} \} \cap \{ \textit{Bézout rings} \} \supset \{ \textit{local rings} \}  \cap \{ \textit{Prüfer domain}\} R R,"['abstract-algebra', 'ring-theory', 'commutative-algebra', 'modules', 'local-rings']"
72,Isomorphism Classes of Real Closed Subfields of $\Bbb C$,Isomorphism Classes of Real Closed Subfields of,\Bbb C,The real line $\Bbb R$ is a maximal real closed subfield of the complex plane $\Bbb C$ . How many such maximal real closed subfields exist(up to isomorphism)? Is there a way to see that there must be at least infinitely many such maximal real closed subfields?,The real line is a maximal real closed subfield of the complex plane . How many such maximal real closed subfields exist(up to isomorphism)? Is there a way to see that there must be at least infinitely many such maximal real closed subfields?,\Bbb R \Bbb C,"['abstract-algebra', 'complex-analysis', 'logic', 'field-theory', 'model-theory']"
73,Must a ring homomorphism between $\mathbb Z_p$-algebras be a $\mathbb Z_p$-algebra homomorphism?,Must a ring homomorphism between -algebras be a -algebra homomorphism?,\mathbb Z_p \mathbb Z_p,"If $A$ and $B$ are $\mathbb Z_p$ -algebras, and $f: A \to B$ is a ring homomorphism, must $f$ be a $\mathbb Z_p$ -algebra homomorphism? In other words, must $f$ commute with the structure morphisms from $\mathbb Z_p$ to $A$ and to $B$ ? I am already interested in the answer if $A = \mathbb Z_p$ , so let's just consider this case. Note that if $B$ happens to be profinite, then the answer is yes: in this setting $f$ is automatically continuous. (Any open subgroup of $B$ has finite index, and then any finite-index subgroup of $\mathbb Z_p$ is automatically open. More generally, finite-index subgroups are open for topologically finitely generated profinite groups.) My best guess is that the answer is always yes, but I don't know how to prove this. Thanks!","If and are -algebras, and is a ring homomorphism, must be a -algebra homomorphism? In other words, must commute with the structure morphisms from to and to ? I am already interested in the answer if , so let's just consider this case. Note that if happens to be profinite, then the answer is yes: in this setting is automatically continuous. (Any open subgroup of has finite index, and then any finite-index subgroup of is automatically open. More generally, finite-index subgroups are open for topologically finitely generated profinite groups.) My best guess is that the answer is always yes, but I don't know how to prove this. Thanks!",A B \mathbb Z_p f: A \to B f \mathbb Z_p f \mathbb Z_p A B A = \mathbb Z_p B f B \mathbb Z_p,"['abstract-algebra', 'ring-theory', 'p-adic-number-theory']"
74,Orders of Paige Loops over Finite Fields,Orders of Paige Loops over Finite Fields,,"A Moufang loop $M$ is a loop that satisfies the Moufang identity: $(zx)(yz) = z((xy)z),\forall x,y,z\in M$ . From here , we get the following statement: For any field $F$ let $M(F)$ denote the Moufang loop of unit norm elements in the (unique) split-octonion algebra over $F$ . Let $Z$ denote the center of $M(F)$ . If the characteristic of $F$ is $2$ then $Z = \{e\}$ , otherwise $Z = \{±e\}$ . The Paige loop over $F$ is the loop $M^*(F) = M(F)/Z$ . Paige loops are nonassociative simple Moufang loops. All finite nonassociative simple Moufang loops are Paige loops over finite fields. So we have (see multiplication table below for $i,\ell, k$ ), $M(\mathbb{F}_{p^n})=\{x_{0}+x_{1}\,i+x_{2}\,j+x_{3}\,k+x_{4}\,\ell +x_{5}\,\ell i+x_{6}\,\ell j+x_{7}\,\ell k\}$ , where $x_m\in \mathbb{F}_{p^n}$ and unit norm: $N(x_{0}+x_{1}\,i+x_{2}\,j+x_{3}\,k+x_{4}\,\ell +x_{5}\,\ell i+x_{6}\,\ell j+x_{7}\,\ell k)=(x_{0}+x_{1}\,i+x_{2}\,j+x_{3}\,k+x_{4}\,\ell +x_{5}\,\ell i+x_{6}\,\ell j+x_{7}\,\ell k)\cdot (x_{0}-x_{1}\,i-x_{2}\,j-x_{3}\,k-x_{4}\,\ell -x_{5}\,\ell i-x_{6}\,\ell j-x_{7}\,\ell k)=1$ Question : What are the orders of these Paige loops? Examples: $|M^*(\mathbb{F}_2)|=120$ $|M^*(\mathbb{F}_3)|=624/2=312$ It gets much harder to manually compute; is there work on this?","A Moufang loop is a loop that satisfies the Moufang identity: . From here , we get the following statement: For any field let denote the Moufang loop of unit norm elements in the (unique) split-octonion algebra over . Let denote the center of . If the characteristic of is then , otherwise . The Paige loop over is the loop . Paige loops are nonassociative simple Moufang loops. All finite nonassociative simple Moufang loops are Paige loops over finite fields. So we have (see multiplication table below for ), , where and unit norm: Question : What are the orders of these Paige loops? Examples: It gets much harder to manually compute; is there work on this?","M (zx)(yz) = z((xy)z),\forall x,y,z\in M F M(F) F Z M(F) F 2 Z = \{e\} Z = \{±e\} F M^*(F) = M(F)/Z i,\ell, k M(\mathbb{F}_{p^n})=\{x_{0}+x_{1}\,i+x_{2}\,j+x_{3}\,k+x_{4}\,\ell +x_{5}\,\ell i+x_{6}\,\ell j+x_{7}\,\ell k\} x_m\in \mathbb{F}_{p^n} N(x_{0}+x_{1}\,i+x_{2}\,j+x_{3}\,k+x_{4}\,\ell +x_{5}\,\ell i+x_{6}\,\ell j+x_{7}\,\ell k)=(x_{0}+x_{1}\,i+x_{2}\,j+x_{3}\,k+x_{4}\,\ell +x_{5}\,\ell i+x_{6}\,\ell j+x_{7}\,\ell k)\cdot (x_{0}-x_{1}\,i-x_{2}\,j-x_{3}\,k-x_{4}\,\ell -x_{5}\,\ell i-x_{6}\,\ell j-x_{7}\,\ell k)=1 |M^*(\mathbb{F}_2)|=120 |M^*(\mathbb{F}_3)|=624/2=312","['abstract-algebra', 'group-theory', 'reference-request', 'finite-fields', 'octonions']"
75,Generalised form of $|HK|=\frac{|H||K|}{|H\cap K|}$ [SOLVED],Generalised form of  [SOLVED],|HK|=\frac{|H||K|}{|H\cap K|},"So for groups, we know that the cardinality of the product of two subgroups is given by the formula $|HK|=\frac{|H||K|}{|H\cap K|}$ , where $H$ and $K$ are subgroups of the group $G$ . However, after scouring the internet I cannot seem to find a formula for the cardinality of the product of three or more subgroups. Failed attempt: I conjectured that the cardinality of the product of three subgroups is given by the formula $$|XYZ|=\frac{|X||Y||Z||X \cap Y \cap Z|}{|X \cap Y||X \cap Z||Y \cap Z|},$$ where $X$ , $Y$ and $Z$ are subgroups of the group $G$ . Similarly, the cardinality of the product of four subgroups should be given by the formula $$|WXYZ|=\frac{|W||X||Y||Z| |W \cap X \cap Y| |W \cap X \cap Z| |W \cap Y \cap Z| |X \cap Y \cap Z|}{|W \cap X| |W \cap Y| |W \cap Z| |X \cap Y||X \cap Z||Y \cap Z||W\cap X \cap Y \cap Z|},$$ where $W$ , $X$ , $Y$ and $Z$ are subgroups of the group $G$ . I conjectured these formulas because the formula for the cardinality of two subgroups seems to have a similar structure to the principle of inclusion and exclusion $(|A \cup B|=|A|+|B|-|A \cap B|)$ and also the formula $\operatorname{lcm}(x,y)=\frac{xy}{\gcd(x,y)}$ . Therefore, the formula for the cardinality of the product of three subgroups should somewhat follow the pattern for $|A \cup B \cup C|$ and $\operatorname{lcm}(x,y,z)$ in my humble opinion. (although if it doesn’t, I wouldn’t be very surprised either because my argument isn’t very rigorous). I have checked that the formula $$|XYZ|=\frac{|X||Y||Z||X \cap Y \cap Z|}{|X \cap Y||X \cap Z||Y \cap Z|},$$ holds for the example $G=\mathbb{Z}/120\mathbb{Z}$ , $X= \mathbb{Z}/2\mathbb{Z}$ , $Y= \mathbb{Z}/3\mathbb{Z}$ and $Z=\mathbb{Z}/5\mathbb{Z}$ . Also, the formula holds when you let the subgroup $Z$ be the subgroup $X\cap Y$ . Sadly, reality is often times disappointing because I managed to find a counter example to the above formula. By letting the group $G$ be $S_3$ , $X=\{(1),(12)\}$ , $Y=\{(1),(13)\}$ and $Z=\{(1),(123),(132)\}$ . In this example, it isn’t hard to see that the right hand side of the formula would give us $\frac{2\cdot 2\cdot 3 \cdot 1}{1 \cdot 1 \cdot 1}=12$ . However, on the left hand side of the formula, $XYZ$ is a subset of $S_3$ and hence its cardinality has to be less than the order of $S_3$ which is 6, a contradiction. Since my formula failed to hold water, the only natural question to have is what is the formula for $|XYZ|$ ? And perhaps what is the formula of the cardinality of the product of $n$ many subgroups of $G$ be? Will somebody who is rather experienced in this field be able to satisfy my curiousity? Current progress: We can derive a formula for $|XYZ|$ if we were to assume that one of the subgroups is normal If we were to assume that one of these three subgroups are normal, then either $(XY)$ or $(YZ)$ is a subgroup of $G$ . In the case that $(XY)$ is the subgroup, we can deduce that $$|XYZ|=\frac{|XY|\cdot|Z|}{|XY\cap Z|}=\frac{|X|\cdot |Y|}{|X\cap Y|}\cdot \frac{|Z|}{|XY\cap Z|}=\frac{|X|\cdot|Y|\cdot|Z|}{|X\cap Y|\cdot|XY\cap Z|}$$ We can derive a similar formula if $(YZ)$ is a subgroup. Many of the comments seem to suggest that such a formula probably do not exists. One of the reason cited is due to the fact that there isn’t a clear cut way for us to use induction because $XY$ is usually not a group. Somebody (in an already deleted post) suggested the formula $$|H_1H_2H_3|=\frac{|H_1||H_2||H_3|}{|H_1\cap H_2||H_2\cap H_3| |H_3\cap H_1|},$$ where $H_1,H_2,H_3$ are subgroups for $n=3$ . And in general, $$|\displaystyle \prod_{i=l}^n(H_i)|=\frac{\displaystyle \prod_{i=l}^n(|H_i|)}{\displaystyle \prod_{i=l}^{n}(|H_i\cap H_{i+1}|)}$$ (Note that $H_{n+1}=H_1$ ) where the ${H_i}’s$ are subgroups of $G$ It seemed plausible at first sight. Sadly, it too was quickly disproven using the same counter example for my conjectured formula. For the case of $n=3$ , let the group $G$ be $S_3$ , $H_1=\{(1),(12)\}$ , $H_2=\{(1),(13)\}$ and $H_3=\{(1),(123),(132)\}$ . In this example, it isn’t hard to see that the right hand side of the formula would give us $\frac{2\cdot 2\cdot 3}{1 \cdot 1 \cdot 1}=12$ . However, on the left hand side of the formula, $XYZ$ is a subset of $S_3$ and hence its order has to be less than the cardinality of $S_3$ which is 6, a contradiction. My thoughts on this problem: I still think that there is a chance of there being such a formula. Clearly, one cannot simply work by induction on the number of factors because $XY$ is usually not a subgroup (as mentioned by Brauer Suzuki in the comments below). One approach that I can think of in solving this problem is to look at the proof for $|HK|=\frac{|H||K|}{|H\cap K|}$ and try to somehow replicate it for the case of $n=3$ . (I have tried this but to no success. But feel free to try it because I am kind of new to algebra and hence might have missed something crucial) At the same time, perhaps there is indeed no such formula. For arguments against such a formula do read the comments of ΑΘΩ below which I felt to be rather insightful. Conclusion: Pretty convinced that there isn’t such a formula. Do read the solution by David A. Craven.","So for groups, we know that the cardinality of the product of two subgroups is given by the formula , where and are subgroups of the group . However, after scouring the internet I cannot seem to find a formula for the cardinality of the product of three or more subgroups. Failed attempt: I conjectured that the cardinality of the product of three subgroups is given by the formula where , and are subgroups of the group . Similarly, the cardinality of the product of four subgroups should be given by the formula where , , and are subgroups of the group . I conjectured these formulas because the formula for the cardinality of two subgroups seems to have a similar structure to the principle of inclusion and exclusion and also the formula . Therefore, the formula for the cardinality of the product of three subgroups should somewhat follow the pattern for and in my humble opinion. (although if it doesn’t, I wouldn’t be very surprised either because my argument isn’t very rigorous). I have checked that the formula holds for the example , , and . Also, the formula holds when you let the subgroup be the subgroup . Sadly, reality is often times disappointing because I managed to find a counter example to the above formula. By letting the group be , , and . In this example, it isn’t hard to see that the right hand side of the formula would give us . However, on the left hand side of the formula, is a subset of and hence its cardinality has to be less than the order of which is 6, a contradiction. Since my formula failed to hold water, the only natural question to have is what is the formula for ? And perhaps what is the formula of the cardinality of the product of many subgroups of be? Will somebody who is rather experienced in this field be able to satisfy my curiousity? Current progress: We can derive a formula for if we were to assume that one of the subgroups is normal If we were to assume that one of these three subgroups are normal, then either or is a subgroup of . In the case that is the subgroup, we can deduce that We can derive a similar formula if is a subgroup. Many of the comments seem to suggest that such a formula probably do not exists. One of the reason cited is due to the fact that there isn’t a clear cut way for us to use induction because is usually not a group. Somebody (in an already deleted post) suggested the formula where are subgroups for . And in general, (Note that ) where the are subgroups of It seemed plausible at first sight. Sadly, it too was quickly disproven using the same counter example for my conjectured formula. For the case of , let the group be , , and . In this example, it isn’t hard to see that the right hand side of the formula would give us . However, on the left hand side of the formula, is a subset of and hence its order has to be less than the cardinality of which is 6, a contradiction. My thoughts on this problem: I still think that there is a chance of there being such a formula. Clearly, one cannot simply work by induction on the number of factors because is usually not a subgroup (as mentioned by Brauer Suzuki in the comments below). One approach that I can think of in solving this problem is to look at the proof for and try to somehow replicate it for the case of . (I have tried this but to no success. But feel free to try it because I am kind of new to algebra and hence might have missed something crucial) At the same time, perhaps there is indeed no such formula. For arguments against such a formula do read the comments of ΑΘΩ below which I felt to be rather insightful. Conclusion: Pretty convinced that there isn’t such a formula. Do read the solution by David A. Craven.","|HK|=\frac{|H||K|}{|H\cap K|} H K G |XYZ|=\frac{|X||Y||Z||X \cap Y \cap Z|}{|X \cap Y||X \cap Z||Y \cap Z|}, X Y Z G |WXYZ|=\frac{|W||X||Y||Z| |W \cap X \cap Y| |W \cap X \cap Z| |W \cap Y \cap Z| |X \cap Y \cap Z|}{|W \cap X| |W \cap Y| |W \cap Z| |X \cap Y||X \cap Z||Y \cap Z||W\cap X \cap Y \cap Z|}, W X Y Z G (|A \cup B|=|A|+|B|-|A \cap B|) \operatorname{lcm}(x,y)=\frac{xy}{\gcd(x,y)} |A \cup B \cup C| \operatorname{lcm}(x,y,z) |XYZ|=\frac{|X||Y||Z||X \cap Y \cap Z|}{|X \cap Y||X \cap Z||Y \cap Z|}, G=\mathbb{Z}/120\mathbb{Z} X= \mathbb{Z}/2\mathbb{Z} Y= \mathbb{Z}/3\mathbb{Z} Z=\mathbb{Z}/5\mathbb{Z} Z X\cap Y G S_3 X=\{(1),(12)\} Y=\{(1),(13)\} Z=\{(1),(123),(132)\} \frac{2\cdot 2\cdot 3 \cdot 1}{1 \cdot 1 \cdot 1}=12 XYZ S_3 S_3 |XYZ| n G |XYZ| (XY) (YZ) G (XY) |XYZ|=\frac{|XY|\cdot|Z|}{|XY\cap Z|}=\frac{|X|\cdot |Y|}{|X\cap Y|}\cdot \frac{|Z|}{|XY\cap Z|}=\frac{|X|\cdot|Y|\cdot|Z|}{|X\cap Y|\cdot|XY\cap Z|} (YZ) XY |H_1H_2H_3|=\frac{|H_1||H_2||H_3|}{|H_1\cap H_2||H_2\cap H_3| |H_3\cap H_1|}, H_1,H_2,H_3 n=3 |\displaystyle \prod_{i=l}^n(H_i)|=\frac{\displaystyle \prod_{i=l}^n(|H_i|)}{\displaystyle \prod_{i=l}^{n}(|H_i\cap H_{i+1}|)} H_{n+1}=H_1 {H_i}’s G n=3 G S_3 H_1=\{(1),(12)\} H_2=\{(1),(13)\} H_3=\{(1),(123),(132)\} \frac{2\cdot 2\cdot 3}{1 \cdot 1 \cdot 1}=12 XYZ S_3 S_3 XY |HK|=\frac{|H||K|}{|H\cap K|} n=3","['abstract-algebra', 'group-theory']"
76,Is the connecting homomorphism unique?,Is the connecting homomorphism unique?,,"Theorem : Given an exact sequence $$0 \longrightarrow A  \longrightarrow B \longrightarrow C \longrightarrow  0$$ of chain/cochain exists a connecting homomorphism $\omega : H(C)  \longrightarrow H(A)$ of degree $1$ or $-1$ which induces a long exact sequence in homology or cohomology. The construction of $\omega$ is quite explicit, in fact $\omega[\gamma] = \alpha$ where $\alpha$ is a preimage of $\partial \beta$ , where $\beta$ is the element such that $\beta \longmapsto \gamma \in C_n$ . Since in the proof one proves that doesn't depend on the choice of the $\gamma$ representing $[\gamma]$ and $\beta$ which goes to $\alpha$ , could I conclude that whenever I find an explicit function, such that respect those requirements for specific elements, that function is $\omega$ indeed since in homology they are the same function ? The question arises from the connecting homomorphism of the $Cf$ complex, where for the first time I noticed this kind of ""uniqueness"" to assert that in that scenario, the long exact sequence has $\omega = f_*$ as connecting homomorphism. Any clarification or help would be appreciated.","Theorem : Given an exact sequence of chain/cochain exists a connecting homomorphism of degree or which induces a long exact sequence in homology or cohomology. The construction of is quite explicit, in fact where is a preimage of , where is the element such that . Since in the proof one proves that doesn't depend on the choice of the representing and which goes to , could I conclude that whenever I find an explicit function, such that respect those requirements for specific elements, that function is indeed since in homology they are the same function ? The question arises from the connecting homomorphism of the complex, where for the first time I noticed this kind of ""uniqueness"" to assert that in that scenario, the long exact sequence has as connecting homomorphism. Any clarification or help would be appreciated.","0 \longrightarrow A
 \longrightarrow B \longrightarrow C \longrightarrow  0 \omega : H(C)
 \longrightarrow H(A) 1 -1 \omega \omega[\gamma] = \alpha \alpha \partial \beta \beta \beta \longmapsto \gamma \in C_n \gamma [\gamma] \beta \alpha \omega Cf \omega = f_*","['abstract-algebra', 'algebraic-topology', 'homology-cohomology', 'homological-algebra']"
77,Conceptual (homological) interpretation of a theorem about flat modules,Conceptual (homological) interpretation of a theorem about flat modules,,"I just learned the following beautiful result about flat modules from J. S. Milne's book Étale Cohomology : Lemma 2.10(b'): Let $M$ be any flat $A$ -module. If $$\sum_i a_ix_i=0,$$ $a_i\in A$ , $x_i\in M$ , then there are equations $$x_i = \sum_j a_{ij}x_j'$$ with $x_j'\in M$ , $a_{ij}\in A$ , such that $$\sum_i a_ia_{ij} = 0$$ for all $j$ . It is stated under the hypothesis that $A$ is a commutative, noetherian ring, but as far as I can tell, the proof does not use noetherianity. (Actually I am not sure it even uses commutativity, but I will leave that matter alone for the purposes of this question.) The proof given in Milne is essentially computational. However, the result struck me as almost a statement that something is exact (I'll make this precise in a moment), and of course flatness is all about exactness, so I wondered, is there a conceptual argument, or at least some reasonably satisfying conceptual handwaving, that gives us the claimed result in terms of an assertion that something is exact, or some (co)homology vanishes, in a way that is straightforwardly connected to $M$ 's flatness? (I'm using the soft-question tag because, while there could easily be a fully precise answer [which would be best possible], I will probably be happy with what I'm calling ""satisfying conceptual handwaving,"" and what I mean by ""straightforwardly"" isn't precise either. Apologies in advance about this vagueness.) Here is what I mean when I say the result struck me as ""almost a statement that something is exact"". The tuple $(a_i)_{i=1,\dots,r}$ defines a map $\varphi: M^r\rightarrow M$ by $$(y_i)_{i=1,\dots,r} \mapsto \sum_i a_iy_i.$$ If $A$ is commutative, this is a map of $A$ -modules. Then the equation $$\sum_i a_ix_i=0$$ asserts that $(x_1,\dots,x_r)\in M^r$ lies in the kernel of this map. Similarly, the matrix $(a_{ij})$ defines a map $\psi: M^s\rightarrow M^r$ by $$(y'_j)_{j=1,\dots,s}\mapsto \left(\sum_j a_{ij}y'_j\right)_{i=1,\dots,r},$$ whereupon the equations $$\sum_i a_ia_{ij} = 0$$ assert that the composed map $\psi\circ\varphi = 0$ , and the equations $$x_i = \sum_j a_{ij}x_j'$$ assert that $(x_1,\dots,x_r)$ lies in the image of $\psi$ . Thus the lemma ""comes close"" to asserting that we have a complex $M^s\xrightarrow{\psi} M^r \xrightarrow{\varphi} M$ which is exact in the middle. It is not actually asserting this because the matrix $(a_{ij})$ is allowed to depend on the tuple $(x_i)$ (and the proof indeed requires the data of the $(x_i)$ for the construction of the $(a_{ij})$ ). So the real statement is: given an $A$ -linear map $\varphi: M^r\rightarrow M$ defined by a tuple $(a_1,\dots,a_r)$ , and given an element $(x_1,\dots,x_r)$ of the kernel of this map , there is an $A$ -linear map $\varphi: M^s\rightarrow M^r$ defined by a matrix $(a_{ij})$ , such that $M^s\rightarrow M^r\rightarrow M$ forms a complex and the particular given $(x_1,\dots,x_r)\in M^r$ lies in the image of $\psi$ . There is no assertion that the entire kernel of $\varphi$ is exhausted by the image of $\psi$ . Nonetheless, these musings are sufficiently suggestive to me that I wanted to ask here: can you explain Milne's Lemma 2.10(b') in terms of the exactness of something, or the vanishing of some homology or cohomology, in a way that is evidently linked to $M$ 's flatness over $A$ ?","I just learned the following beautiful result about flat modules from J. S. Milne's book Étale Cohomology : Lemma 2.10(b'): Let be any flat -module. If , , then there are equations with , , such that for all . It is stated under the hypothesis that is a commutative, noetherian ring, but as far as I can tell, the proof does not use noetherianity. (Actually I am not sure it even uses commutativity, but I will leave that matter alone for the purposes of this question.) The proof given in Milne is essentially computational. However, the result struck me as almost a statement that something is exact (I'll make this precise in a moment), and of course flatness is all about exactness, so I wondered, is there a conceptual argument, or at least some reasonably satisfying conceptual handwaving, that gives us the claimed result in terms of an assertion that something is exact, or some (co)homology vanishes, in a way that is straightforwardly connected to 's flatness? (I'm using the soft-question tag because, while there could easily be a fully precise answer [which would be best possible], I will probably be happy with what I'm calling ""satisfying conceptual handwaving,"" and what I mean by ""straightforwardly"" isn't precise either. Apologies in advance about this vagueness.) Here is what I mean when I say the result struck me as ""almost a statement that something is exact"". The tuple defines a map by If is commutative, this is a map of -modules. Then the equation asserts that lies in the kernel of this map. Similarly, the matrix defines a map by whereupon the equations assert that the composed map , and the equations assert that lies in the image of . Thus the lemma ""comes close"" to asserting that we have a complex which is exact in the middle. It is not actually asserting this because the matrix is allowed to depend on the tuple (and the proof indeed requires the data of the for the construction of the ). So the real statement is: given an -linear map defined by a tuple , and given an element of the kernel of this map , there is an -linear map defined by a matrix , such that forms a complex and the particular given lies in the image of . There is no assertion that the entire kernel of is exhausted by the image of . Nonetheless, these musings are sufficiently suggestive to me that I wanted to ask here: can you explain Milne's Lemma 2.10(b') in terms of the exactness of something, or the vanishing of some homology or cohomology, in a way that is evidently linked to 's flatness over ?","M A \sum_i a_ix_i=0, a_i\in A x_i\in M x_i = \sum_j a_{ij}x_j' x_j'\in M a_{ij}\in A \sum_i a_ia_{ij} = 0 j A M (a_i)_{i=1,\dots,r} \varphi: M^r\rightarrow M (y_i)_{i=1,\dots,r} \mapsto \sum_i a_iy_i. A A \sum_i a_ix_i=0 (x_1,\dots,x_r)\in M^r (a_{ij}) \psi: M^s\rightarrow M^r (y'_j)_{j=1,\dots,s}\mapsto \left(\sum_j a_{ij}y'_j\right)_{i=1,\dots,r}, \sum_i a_ia_{ij} = 0 \psi\circ\varphi = 0 x_i = \sum_j a_{ij}x_j' (x_1,\dots,x_r) \psi M^s\xrightarrow{\psi} M^r \xrightarrow{\varphi} M (a_{ij}) (x_i) (x_i) (a_{ij}) A \varphi: M^r\rightarrow M (a_1,\dots,a_r) (x_1,\dots,x_r) A \varphi: M^s\rightarrow M^r (a_{ij}) M^s\rightarrow M^r\rightarrow M (x_1,\dots,x_r)\in M^r \psi \varphi \psi M A","['abstract-algebra', 'commutative-algebra', 'soft-question', 'homological-algebra', 'flatness']"
78,Is $(4+\sqrt{5})$ a prime ideal of $\mathbb{Z}[\sqrt{5}]$?,Is  a prime ideal of ?,(4+\sqrt{5}) \mathbb{Z}[\sqrt{5}],"Consider the integral domain $\mathbb{Z}[\sqrt{5}]$ . Is $(4+\sqrt{5})$ a prime ideal of $\mathbb{Z}[\sqrt{5}]$ ? I do not know the answer, so any help is welcome. Note that $4+\sqrt{5}$ is an irreducible element of $\mathbb{Z}[\sqrt{5}]$ , since its norm $N(4+\sqrt{5})=11$ is a prime number (here as usual $N(a+b\sqrt{5})=a^2-5b^2$ for every $a, b \in \mathbb{Z}$ ). Anyhow $\mathbb{Z}[\sqrt{5}]$ is not a unique factorization domain, as it can be easily seen from the following factorizations $4=2 \cdot 2 = (3+\sqrt{5})(3-\sqrt{5})$ . So the question is not so trivial, at least for me!","Consider the integral domain . Is a prime ideal of ? I do not know the answer, so any help is welcome. Note that is an irreducible element of , since its norm is a prime number (here as usual for every ). Anyhow is not a unique factorization domain, as it can be easily seen from the following factorizations . So the question is not so trivial, at least for me!","\mathbb{Z}[\sqrt{5}] (4+\sqrt{5}) \mathbb{Z}[\sqrt{5}] 4+\sqrt{5} \mathbb{Z}[\sqrt{5}] N(4+\sqrt{5})=11 N(a+b\sqrt{5})=a^2-5b^2 a, b \in \mathbb{Z} \mathbb{Z}[\sqrt{5}] 4=2 \cdot 2 = (3+\sqrt{5})(3-\sqrt{5})","['abstract-algebra', 'ring-theory', 'algebraic-number-theory']"
79,implication of the Abel–Ruffini theorem,implication of the Abel–Ruffini theorem,,"I am taking a course in abstract algebra, and we proved the following theorem: I want to prove something more specific. Let's look at polynomials of degree 5 over C. Someone is claiming he has a magic formula, which receives the coefficients of a polynomial of degree 5, and returns its roots using only basic operations and radicals. I want to understand, how I can prove this person wrong using the theorem above. In this case, the theorem talks about the field of rational functions with 5 variables over C. It shows that I can't express $t_1, ..., t_5$ (the roots of f) in terms of $s_1,...,s_5$ , in this abstract field. I understand the proof in this context, but I want to understand how I can use it concretely in order to prove this person wrong. In the sources that I have seen, they say that Abel–Ruffini theorem implies what I want to prove, but they don't show how. Can someone help me understand how you can show this? I am adding the proof we saw in the course:","I am taking a course in abstract algebra, and we proved the following theorem: I want to prove something more specific. Let's look at polynomials of degree 5 over C. Someone is claiming he has a magic formula, which receives the coefficients of a polynomial of degree 5, and returns its roots using only basic operations and radicals. I want to understand, how I can prove this person wrong using the theorem above. In this case, the theorem talks about the field of rational functions with 5 variables over C. It shows that I can't express (the roots of f) in terms of , in this abstract field. I understand the proof in this context, but I want to understand how I can use it concretely in order to prove this person wrong. In the sources that I have seen, they say that Abel–Ruffini theorem implies what I want to prove, but they don't show how. Can someone help me understand how you can show this? I am adding the proof we saw in the course:","t_1, ..., t_5 s_1,...,s_5","['abstract-algebra', 'polynomials', 'radicals']"
80,Simple C*-algebras with finite representations are matrix algebras,Simple C*-algebras with finite representations are matrix algebras,,"Let $A$ be a simple $C^*$ -algebra. I am trying to prove that $A$ admits a non-zero finite dimensional representation if and only if $A\cong M_n(\mathbb{C})$ for some $n$ . The reverse implication is trivial. For the other one, if $\varphi:A\to B(\mathbb{C}^n)$ is a non-zero finite dimensional representation of $A$ , then $\varphi$ is faithful, because $A$ is simple. Since $B(\mathbb{C}^n)\cong M_n(\mathbb{C})$ , we have that $A$ is isomorphic to a simple $*$ -subalgebra of $M_n(\mathbb{C})$ . This is as far as I can go. Any ideas on how to go on? P.S: I have seen a proof using vN algebras, but the thing is I came across this exercise in a book before the chapter on vN algebras, so I am trying to solve this without vN algebras (or irreducible representations). Also: I know the classification theorem of finite dimensional $C^*$ -algebras, but I can't use this. I want to prove this result in order to classify finite dimensional $C^*$ -algebras.","Let be a simple -algebra. I am trying to prove that admits a non-zero finite dimensional representation if and only if for some . The reverse implication is trivial. For the other one, if is a non-zero finite dimensional representation of , then is faithful, because is simple. Since , we have that is isomorphic to a simple -subalgebra of . This is as far as I can go. Any ideas on how to go on? P.S: I have seen a proof using vN algebras, but the thing is I came across this exercise in a book before the chapter on vN algebras, so I am trying to solve this without vN algebras (or irreducible representations). Also: I know the classification theorem of finite dimensional -algebras, but I can't use this. I want to prove this result in order to classify finite dimensional -algebras.",A C^* A A\cong M_n(\mathbb{C}) n \varphi:A\to B(\mathbb{C}^n) A \varphi A B(\mathbb{C}^n)\cong M_n(\mathbb{C}) A * M_n(\mathbb{C}) C^* C^*,"['abstract-algebra', 'functional-analysis', 'representation-theory', 'c-star-algebras']"
81,Formal Power Series as Initial Objects?,Formal Power Series as Initial Objects?,,"We often apply formal power series in places where it seems, at face value, somewhat suspect to do so. I'm primarily interested in why these formal manipulations work so broadly. A prime example comes from Concrete Mathematics, page 470-471. Here, $(\Delta f)(x) = f(x+1) - f(x)$ , and $Df = f'$ We can express $\Delta$ in terms of $D$ using Taylor's formula as follows: $f(x + \epsilon) = f(x) + \frac{f'(x)}{1!}\epsilon + \frac{f''(x)}{2!}\epsilon^2 + \cdots$ Setting $\epsilon = 1$ tells us that $\Delta f(x) = \\ f(x+1) - f(x) = \\ f'(x)/1! + f''(x)/2! + f'''(x)/3! + \cdots = \\ (D/1! + D^2/2! + D^3/3! + \cdots)f(x) = \\ (e^D - 1)f(x) $ The authors continue, saying the inverse operator $\sum = 1/\Delta$ should thus be $1/(e^D - 1)$ . (Here $\sum$ is meant as an operator, though the authors continue using $\sum$ in its traditional context as well, as in the following power series.) We recognize $z/(e^z-1) = \sum B_k z^k/k!$ as a known power series, and conclude, somewhat surprisingly, that $\sum = \frac{B_0}{D} + \frac{B_1}{1!} + \frac{B_2}{2!}D + \frac{B_3}{3!}D^2 + \cdots = \int + \sum \frac{B_k}{k!}D^{k-1}$ This is the asymptotic expansion for the Euler Summation Formula . This derivation seems like nonsense, except for the fact that it isn't. We get a reasonable result out the other side, and every step makes sense if you're willing to suspend your disbelief. I have seen multiple other arguments just like this, where we flippantly go back and forth between functions and their series, even in places where a topology is not clearly visible to make sense of the infinite sums! One idea that I had comes from a topic in Knapp's Basic Algebra, the Permanence of Identities (page 212-214). The idea here is that equations which are true over $\mathbb{Z}[x_1,\ldots,x_n]$ ought to remain true over general rings when we substitute ring elements for the $x_i$ . While Knapp doesn't dwell on it, I justified this to myself since $\mathbb{Z}[x_1, \ldots, x_n]$ is initial among rings with $n$ distinguished elements, and since ring homs preserve truth, we get that a formula $p = q$ in this polynomial ring implies $p(r_1,\ldots,r_n) = q(r_1,\ldots,r_n)$ is true of any $r_i$ in any (commutative) ring $R$ . By analogy, it seems reasonable that a ring of formal power series (perhaps with rational coefficients?) should be initial in a suitable category, and that the identities we derive by working formally will then be true in, say, rings of operators (which would justify the above argument, modulo convergence issues). Finally, then, Does anybody have references for the soundness of power-series methods being applied in somewhat surprising settings? Additionally, can the argument I've given be made formal? Are there broad outlines for when these formal methods are permissible, and when (if ever) they lead us astray? Thanks in advance ^_^","We often apply formal power series in places where it seems, at face value, somewhat suspect to do so. I'm primarily interested in why these formal manipulations work so broadly. A prime example comes from Concrete Mathematics, page 470-471. Here, , and We can express in terms of using Taylor's formula as follows: Setting tells us that The authors continue, saying the inverse operator should thus be . (Here is meant as an operator, though the authors continue using in its traditional context as well, as in the following power series.) We recognize as a known power series, and conclude, somewhat surprisingly, that This is the asymptotic expansion for the Euler Summation Formula . This derivation seems like nonsense, except for the fact that it isn't. We get a reasonable result out the other side, and every step makes sense if you're willing to suspend your disbelief. I have seen multiple other arguments just like this, where we flippantly go back and forth between functions and their series, even in places where a topology is not clearly visible to make sense of the infinite sums! One idea that I had comes from a topic in Knapp's Basic Algebra, the Permanence of Identities (page 212-214). The idea here is that equations which are true over ought to remain true over general rings when we substitute ring elements for the . While Knapp doesn't dwell on it, I justified this to myself since is initial among rings with distinguished elements, and since ring homs preserve truth, we get that a formula in this polynomial ring implies is true of any in any (commutative) ring . By analogy, it seems reasonable that a ring of formal power series (perhaps with rational coefficients?) should be initial in a suitable category, and that the identities we derive by working formally will then be true in, say, rings of operators (which would justify the above argument, modulo convergence issues). Finally, then, Does anybody have references for the soundness of power-series methods being applied in somewhat surprising settings? Additionally, can the argument I've given be made formal? Are there broad outlines for when these formal methods are permissible, and when (if ever) they lead us astray? Thanks in advance ^_^","(\Delta f)(x) = f(x+1) - f(x) Df = f' \Delta D f(x + \epsilon) = f(x) + \frac{f'(x)}{1!}\epsilon + \frac{f''(x)}{2!}\epsilon^2 + \cdots \epsilon = 1 \Delta f(x) = \\
f(x+1) - f(x) = \\
f'(x)/1! + f''(x)/2! + f'''(x)/3! + \cdots = \\
(D/1! + D^2/2! + D^3/3! + \cdots)f(x) = \\
(e^D - 1)f(x)
 \sum = 1/\Delta 1/(e^D - 1) \sum \sum z/(e^z-1) = \sum B_k z^k/k! \sum = \frac{B_0}{D} + \frac{B_1}{1!} + \frac{B_2}{2!}D + \frac{B_3}{3!}D^2 + \cdots = \int + \sum \frac{B_k}{k!}D^{k-1} \mathbb{Z}[x_1,\ldots,x_n] x_i \mathbb{Z}[x_1, \ldots, x_n] n p = q p(r_1,\ldots,r_n) = q(r_1,\ldots,r_n) r_i R","['abstract-algebra', 'logic', 'reference-request', 'category-theory', 'formal-power-series']"
82,The number of roots of a polynomial $p(x)=x^{12}+x^8+x^4+1$ in $\mathbb{F}_{11^2}$.,The number of roots of a polynomial  in .,p(x)=x^{12}+x^8+x^4+1 \mathbb{F}_{11^2},"I am trying to count the number of roots of a polynomial $p(x)=x^{12}+x^8+x^4+1$ in $\mathbb{F}_{11^2}$ . Of course, I can plug every element in $\mathbb{F}_{11^2}$ into $x$ in $p(x)$ . But is there any simpler way to do this? Thanks in advance!","I am trying to count the number of roots of a polynomial in . Of course, I can plug every element in into in . But is there any simpler way to do this? Thanks in advance!",p(x)=x^{12}+x^8+x^4+1 \mathbb{F}_{11^2} \mathbb{F}_{11^2} x p(x),"['abstract-algebra', 'field-theory', 'roots']"
83,"Is it true, that for any two non-isomorphic finite groups $G$ and $H$ there exists such a group word $w$, that $|V_w(G)| \neq |V_w(H)|$?","Is it true, that for any two non-isomorphic finite groups  and  there exists such a group word , that ?",G H w |V_w(G)| \neq |V_w(H)|,"Is it true, that for any two non-isomorphic finite groups $G$ and $H$ there exists such a group word $w$ , that $|V_w(G)| \neq |V_w(H)|$ ? Here $V_w(G)$ stands for the verbal subgroup of $H$ , generated by the group word $w$ . Initially, the question I wanted to ask was: “Is it true, that for any two non-isomorphic finite groups $G$ and $H$ there exist such a one-word generated group variety $\mathfrak{U}$ , such that $G$ is in $U$ and $H$ is not?” However, then I found an obvious counterexample: $C_2$ and $C_2 \times C_2$ . So, I decided to require a stronger condition. For the statement of the main question that counterexample already fails. Moreover, if $H$ and $G$ are counterexamples, then they are required to have following properties: 1) They are both non-abelian: If one of the groups is abelian the other group is not, then their commutator subgroups have different orders. If both tho both are abelian, then by the classification of finite abelian groups they can be decomposed into direct products of primary cyclic groups. $$G = (C_2^{g_2} \times ... \times C_{2^i}^{g_{2^i}} \times ...) \times ... \times (C_{p_j}^{g_{p_j}} \times ... \times C_{{p_j}^i}^{g_{{p_j}^i}} \times ...) \times ... $$ $$H = (C_2^{h_2} \times ... \times C_{2^i}^{h_{2^i}} \times ...) \times ... \times (C_{p_j}^{h_{p_j}} \times ... \times C_{{p_j}^i}^{h_{{p_j}^i}} \times ...) \times ... $$ where $$g_{{p_j}^i} = \log_p|V_{{p_j}^{i-1}}(G)| - 2\log_p|V_{{p_j}^{i}}(G)| + \log_p|V_{{p_j}^{i+1}}(G)|$$ $$h_{{p_j}^i} = \log_p|V_{{p_j}^{i-1}}(H)| - 2\log_p|V_{{p_j}^{i}}(H)| + \log_p|V_{{p_j}^{i+1}}(H)|$$ It is not hard to see, that if they satisfy the condition, they are isomorphic. 2) They have the same order: $$|G| = |V_x(G)| = |V_x(H)| = |H|$$ 3) They have the same exponent: $$exp(G) = min\{n \in \mathbb{N}: |V_{x^n}(G)| = 1\} = min\{n \in \mathbb{N}: |V_{x^n}(H)| = 1\} = exp(H)$$ 4) $var(G) = var(H)$ : A group $G$ satisfies an identity $w$ iff $|V_w(G)| = 1$ . 5) $\forall w \in F_\infty  \text{ } V_w(G) = G \iff V_w(H) = H$ Moreover, if $G$ and $H$ are counterexamples with the least possible order, they have to satisfy the additional condition: For every group word $w$ , if $V_w(G)$ is a non-trivial proper verbal subgroup, then $V_w(G) \cong V_w(H)$ and $\frac{G}{V_w(G)} \cong \frac{H}{V_w(H)}$ . If there is a group word $w$ , such that $V_w(G)$ and $V_w(H)$ are non-trivial proper verbal subgroups of the corresponding groups and not isomorphic to each other, then they are the counterexample of lesser order, as $V_{u(x_1, ... , x_m)}(V_{w(x_1, ... , x_n}(G)) = V_{w(u(x_{11}, ... , x_{m1}), ..., u(x_{1n}, ... , x_{mn}))}(G)$ . If for every group word $w$ , if $V_w(G)$ is a non-trivial proper verbal subgroup, then $V_w(G) \cong V_w(H)$ and there is a group word $w$ , such that $V_w(G)$ and $V_w(H)$ are non-trivial proper subgroups of the corresponding groups and $\frac{G}{V_w(G)}$ and $\frac{H}{V_w(H)}$ are not isomorphic to each other, then $\frac{G}{V_w(G)}$ and $\frac{H}{V_w(H)}$ are a counterexample as $V_u(\frac{G}{V_w(G)}) \cong \frac{V_u(G)}{V_w(G) \cap V_u(G)}$ However, even with all those facts in my hands, I still failed to get the contradiction.","Is it true, that for any two non-isomorphic finite groups and there exists such a group word , that ? Here stands for the verbal subgroup of , generated by the group word . Initially, the question I wanted to ask was: “Is it true, that for any two non-isomorphic finite groups and there exist such a one-word generated group variety , such that is in and is not?” However, then I found an obvious counterexample: and . So, I decided to require a stronger condition. For the statement of the main question that counterexample already fails. Moreover, if and are counterexamples, then they are required to have following properties: 1) They are both non-abelian: If one of the groups is abelian the other group is not, then their commutator subgroups have different orders. If both tho both are abelian, then by the classification of finite abelian groups they can be decomposed into direct products of primary cyclic groups. where It is not hard to see, that if they satisfy the condition, they are isomorphic. 2) They have the same order: 3) They have the same exponent: 4) : A group satisfies an identity iff . 5) Moreover, if and are counterexamples with the least possible order, they have to satisfy the additional condition: For every group word , if is a non-trivial proper verbal subgroup, then and . If there is a group word , such that and are non-trivial proper verbal subgroups of the corresponding groups and not isomorphic to each other, then they are the counterexample of lesser order, as . If for every group word , if is a non-trivial proper verbal subgroup, then and there is a group word , such that and are non-trivial proper subgroups of the corresponding groups and and are not isomorphic to each other, then and are a counterexample as However, even with all those facts in my hands, I still failed to get the contradiction.","G H w |V_w(G)| \neq |V_w(H)| V_w(G) H w G H \mathfrak{U} G U H C_2 C_2 \times C_2 H G G = (C_2^{g_2} \times ... \times C_{2^i}^{g_{2^i}} \times ...) \times ... \times (C_{p_j}^{g_{p_j}} \times ... \times C_{{p_j}^i}^{g_{{p_j}^i}} \times ...) \times ...  H = (C_2^{h_2} \times ... \times C_{2^i}^{h_{2^i}} \times ...) \times ... \times (C_{p_j}^{h_{p_j}} \times ... \times C_{{p_j}^i}^{h_{{p_j}^i}} \times ...) \times ...  g_{{p_j}^i} = \log_p|V_{{p_j}^{i-1}}(G)| - 2\log_p|V_{{p_j}^{i}}(G)| + \log_p|V_{{p_j}^{i+1}}(G)| h_{{p_j}^i} = \log_p|V_{{p_j}^{i-1}}(H)| - 2\log_p|V_{{p_j}^{i}}(H)| + \log_p|V_{{p_j}^{i+1}}(H)| |G| = |V_x(G)| = |V_x(H)| = |H| exp(G) = min\{n \in \mathbb{N}: |V_{x^n}(G)| = 1\} = min\{n \in \mathbb{N}: |V_{x^n}(H)| = 1\} = exp(H) var(G) = var(H) G w |V_w(G)| = 1 \forall w \in F_\infty  \text{ } V_w(G) = G \iff V_w(H) = H G H w V_w(G) V_w(G) \cong V_w(H) \frac{G}{V_w(G)} \cong \frac{H}{V_w(H)} w V_w(G) V_w(H) V_{u(x_1, ... , x_m)}(V_{w(x_1, ... , x_n}(G)) = V_{w(u(x_{11}, ... , x_{m1}), ..., u(x_{1n}, ... , x_{mn}))}(G) w V_w(G) V_w(G) \cong V_w(H) w V_w(G) V_w(H) \frac{G}{V_w(G)} \frac{H}{V_w(H)} \frac{G}{V_w(G)} \frac{H}{V_w(H)} V_u(\frac{G}{V_w(G)}) \cong \frac{V_u(G)}{V_w(G) \cap V_u(G)}","['abstract-algebra', 'group-theory', 'finite-groups', 'universal-algebra', 'verbal-subgroups']"
84,"Degree of $a+b$ over a field $k$, where $a$ and $b$ are distinct roots of the same polynomial","Degree of  over a field , where  and  are distinct roots of the same polynomial",a+b k a b,"Let $K/k$ be an algebraic extension of fields with $a$ and $b$ distinct roots in $K$ of the same irreducible polynomial $f(x) \in k[x]$ of degree $n$ . Show that the degree of $k(a+b)/k$ is less than or equal to $\frac{n(n-1)}{2}$ . Also, how does one construct fields $k$ and $K$ together with roots $a,b\in K$ so that the preceding inequality is actually an equality? I'm pretty sure I can get that $k(a+b)/k$ has degree less than or equal to $n(n-1)$ since the minimal polynomial of $b$ over $k(a)$ has degree less than or equal to $n-1$ , but I'm not sure how to reduce this by a factor of $1/2$ . I've also seen that there are computational techniques for computing the minimal polynomial of a sum, but a proof that avoids things such as resolvents would be ideal.","Let be an algebraic extension of fields with and distinct roots in of the same irreducible polynomial of degree . Show that the degree of is less than or equal to . Also, how does one construct fields and together with roots so that the preceding inequality is actually an equality? I'm pretty sure I can get that has degree less than or equal to since the minimal polynomial of over has degree less than or equal to , but I'm not sure how to reduce this by a factor of . I've also seen that there are computational techniques for computing the minimal polynomial of a sum, but a proof that avoids things such as resolvents would be ideal.","K/k a b K f(x) \in k[x] n k(a+b)/k \frac{n(n-1)}{2} k K a,b\in K k(a+b)/k n(n-1) b k(a) n-1 1/2","['abstract-algebra', 'field-theory', 'galois-theory']"
85,Why is $v(a) \leq v(ab)$ superfluous in Euclidean domain definition?,Why is  superfluous in Euclidean domain definition?,v(a) \leq v(ab),Can anyone make me understand in simple language why the second condition for being an Euclidean domain is superfluous ? Why $v(a)  \leq v(ab)$ is not needed?  How we can deduce from the first one?,Can anyone make me understand in simple language why the second condition for being an Euclidean domain is superfluous ? Why is not needed?  How we can deduce from the first one?,v(a)  \leq v(ab),"['abstract-algebra', 'ring-theory', 'integral-domain', 'euclidean-domain']"
86,Ring structure of $\mathbb{R}[x]/(p(x))$.,Ring structure of .,\mathbb{R}[x]/(p(x)),"Let $p(x) = ax^2 + bx + c \in \mathbb{R}[x]$ be a degree 2 polynomial with real coefficients such that $D := b^2 - 4ac$. I'd like to examine the structure of the ring $\mathbb{R}[x]/(p(x))$ in the following three cases: $D > 0, D < 0,$ and $D = 0$. (Note that $(p(x))$ is the ideal generated by $p(x)$.) Where I Am: Well, if $D>0$ (I think I've got this case)... ...then $p(x)$ has two distinct (real) roots; call them $\alpha$ and $\beta$. Therefore, we can write $p(x) = (x - \alpha)(x - \beta)$. So, by the Chinese Remainder Theorem, we have that $$ \mathbb{R}[x]/(p(x)) \cong \mathbb{R}[x]/(x - \alpha) \times \mathbb{R}[x]/(x - \beta). $$ Now, we claim that $\mathbb{R}[x]/(x - \alpha) \cong \mathbb{R}$. Indeed, consider the homomorphism $\phi:\mathbb{R}[x] \to \mathbb{R}$ given by $\phi(q(x)) = q(\alpha)$. Then, since $$ \phi(q(x)) = q(\alpha) = 0 \iff q(x) \in (x - \alpha), $$ we see that $\ker(\phi) = (x - \alpha)$. Furthermore, since we may consider every real number to be a constant polynomial, we see that $\phi$ is surjective. Thus, it follows from the First Isomorphism Theorem that $$ \mathbb{R}[x]/\ker(\phi) = \mathbb{R}[x]/(x - \alpha) \cong \phi(\mathbb{R}[x]) = \mathbb{R}. $$  Similarly, $\mathbb{R}[x]/(x - \beta) \cong \mathbb{R}$. Therefore, $$ \mathbb{R}[x]/(p(x)) \cong \mathbb{R} \times \mathbb{R}. $$ Now, if $D < 0$... ...then $p(x)$ has no real roots. Thus, $p(x)$ is irreducible. So, $\mathbb{R}[x]/(p(x))$ is certainly a field of some sort. I know that $\mathbb{C} \cong \mathbb{R}[x]/(x^2+1)$; but is this true of any quadratic irreducible in $\mathbb{R}[x]$? I would think not... but I'm having trouble describing this ring any further than this. (Note that I don't know anything about ""field extensions""...) And, finally, if $D=0$... ...then $p(x)$ has a single (real) root of multiplicity two; call it $\gamma$. Therefore, we can write $p(x) = (x - \gamma)(x - \gamma)$. May I make the same conclusion here that I did from the first case? I don't see why not, but I just don't feel all that confident doing so...","Let $p(x) = ax^2 + bx + c \in \mathbb{R}[x]$ be a degree 2 polynomial with real coefficients such that $D := b^2 - 4ac$. I'd like to examine the structure of the ring $\mathbb{R}[x]/(p(x))$ in the following three cases: $D > 0, D < 0,$ and $D = 0$. (Note that $(p(x))$ is the ideal generated by $p(x)$.) Where I Am: Well, if $D>0$ (I think I've got this case)... ...then $p(x)$ has two distinct (real) roots; call them $\alpha$ and $\beta$. Therefore, we can write $p(x) = (x - \alpha)(x - \beta)$. So, by the Chinese Remainder Theorem, we have that $$ \mathbb{R}[x]/(p(x)) \cong \mathbb{R}[x]/(x - \alpha) \times \mathbb{R}[x]/(x - \beta). $$ Now, we claim that $\mathbb{R}[x]/(x - \alpha) \cong \mathbb{R}$. Indeed, consider the homomorphism $\phi:\mathbb{R}[x] \to \mathbb{R}$ given by $\phi(q(x)) = q(\alpha)$. Then, since $$ \phi(q(x)) = q(\alpha) = 0 \iff q(x) \in (x - \alpha), $$ we see that $\ker(\phi) = (x - \alpha)$. Furthermore, since we may consider every real number to be a constant polynomial, we see that $\phi$ is surjective. Thus, it follows from the First Isomorphism Theorem that $$ \mathbb{R}[x]/\ker(\phi) = \mathbb{R}[x]/(x - \alpha) \cong \phi(\mathbb{R}[x]) = \mathbb{R}. $$  Similarly, $\mathbb{R}[x]/(x - \beta) \cong \mathbb{R}$. Therefore, $$ \mathbb{R}[x]/(p(x)) \cong \mathbb{R} \times \mathbb{R}. $$ Now, if $D < 0$... ...then $p(x)$ has no real roots. Thus, $p(x)$ is irreducible. So, $\mathbb{R}[x]/(p(x))$ is certainly a field of some sort. I know that $\mathbb{C} \cong \mathbb{R}[x]/(x^2+1)$; but is this true of any quadratic irreducible in $\mathbb{R}[x]$? I would think not... but I'm having trouble describing this ring any further than this. (Note that I don't know anything about ""field extensions""...) And, finally, if $D=0$... ...then $p(x)$ has a single (real) root of multiplicity two; call it $\gamma$. Therefore, we can write $p(x) = (x - \gamma)(x - \gamma)$. May I make the same conclusion here that I did from the first case? I don't see why not, but I just don't feel all that confident doing so...",,"['abstract-algebra', 'polynomials', 'ring-theory']"
87,Are intermediate field extensions of a Galois extension Galois?,Are intermediate field extensions of a Galois extension Galois?,,"Let $F \subset E$ be a Galois extension.  Let $F \subset G \subset E$.  What can we say about 'being Galois' for extensions $F \subset G$ and $G \subset E$? I think for $G \subset E$ the answer is that it is Galois.  To show Galois I need to show normal and separable.  I have a theorem that says it will be normal so all thats left is to show it is separable.  $F \subset E$ being separable means the irreducible polynomial of any element $u \in E$ over has no multiple roots in any further extension of $E$, but I'm not sure how this means any polynomial over $G$ would also have no multiple roots. For $F \subset G$ I'm not even sure what the answer is.  I thought no, but I see something later in my notes that makes me think it is.  I don't know how to show normal, but for separability I have: The extension of $E$ over $F$ being separable means the irreducible polynomial of any element $u \in E$ over has no multiple roots in any further extension of $E$.  If x is a root in $G$ then x will also be a root in an extension of $G$ so since there are no multiple roots in $E$ there are none in $G$ so it is separable.","Let $F \subset E$ be a Galois extension.  Let $F \subset G \subset E$.  What can we say about 'being Galois' for extensions $F \subset G$ and $G \subset E$? I think for $G \subset E$ the answer is that it is Galois.  To show Galois I need to show normal and separable.  I have a theorem that says it will be normal so all thats left is to show it is separable.  $F \subset E$ being separable means the irreducible polynomial of any element $u \in E$ over has no multiple roots in any further extension of $E$, but I'm not sure how this means any polynomial over $G$ would also have no multiple roots. For $F \subset G$ I'm not even sure what the answer is.  I thought no, but I see something later in my notes that makes me think it is.  I don't know how to show normal, but for separability I have: The extension of $E$ over $F$ being separable means the irreducible polynomial of any element $u \in E$ over has no multiple roots in any further extension of $E$.  If x is a root in $G$ then x will also be a root in an extension of $G$ so since there are no multiple roots in $E$ there are none in $G$ so it is separable.",,"['abstract-algebra', 'galois-theory']"
88,Galois group of $x^n+1$ over $\Bbb Q$,Galois group of  over,x^n+1 \Bbb Q,"Let $n\in\Bbb Z_{>0}$. Determine the Galois group of $f(x)=x^n+1$ over $\Bbb Q$. I am having some trouble with this. I started by assuming $n$ is odd, then $f(-x)=(-x)^n+1=-(x^n-1)$, then the Galois group of $f(x)$ is the same as $x^n-1$. We know that $\operatorname{Gal}(x^n-1/\Bbb Q)\cong (\Bbb Z/n\Bbb Z)^\times$, so this is the Galois group of $f(x)$ over $\Bbb Q$ for odd $n$. I am not sure what to do for the general case ($n$ odd or even). I have been doing some research, and I have seen people argue that the splitting field for $x^n+1$ over $\Bbb Q$ is equal to the one for $x^{2n}-1$ over $\Bbb Q$, since $x^{2n}-1=(x^n+1)(x^n-1)$, so any solution to $x^n+1=0$ is one to $x^{2n}-1=0$. For instance, the accepted answer here . Then I would be able to conclude that $\operatorname{Gal}(x^n+1/\Bbb Q)\cong(\Bbb Z/2n\Bbb Z)^\times$. However, I do not understand why this allows us to conclude that the splitting field for $x^n+1$ is $\Bbb Q(\zeta_{2n})$ though ($\zeta_{2n}$ a primitive $2n$-th root of unity).","Let $n\in\Bbb Z_{>0}$. Determine the Galois group of $f(x)=x^n+1$ over $\Bbb Q$. I am having some trouble with this. I started by assuming $n$ is odd, then $f(-x)=(-x)^n+1=-(x^n-1)$, then the Galois group of $f(x)$ is the same as $x^n-1$. We know that $\operatorname{Gal}(x^n-1/\Bbb Q)\cong (\Bbb Z/n\Bbb Z)^\times$, so this is the Galois group of $f(x)$ over $\Bbb Q$ for odd $n$. I am not sure what to do for the general case ($n$ odd or even). I have been doing some research, and I have seen people argue that the splitting field for $x^n+1$ over $\Bbb Q$ is equal to the one for $x^{2n}-1$ over $\Bbb Q$, since $x^{2n}-1=(x^n+1)(x^n-1)$, so any solution to $x^n+1=0$ is one to $x^{2n}-1=0$. For instance, the accepted answer here . Then I would be able to conclude that $\operatorname{Gal}(x^n+1/\Bbb Q)\cong(\Bbb Z/2n\Bbb Z)^\times$. However, I do not understand why this allows us to conclude that the splitting field for $x^n+1$ is $\Bbb Q(\zeta_{2n})$ though ($\zeta_{2n}$ a primitive $2n$-th root of unity).",,"['abstract-algebra', 'galois-theory', 'splitting-field', 'cyclotomic-fields']"
89,"Homomorphisms from $(\Bbb Q,+)$ to $(\Bbb Q,+)$ and from $(\Bbb Q^*,\cdot)$ to $(\Bbb Q^*,\cdot)$",Homomorphisms from  to  and from  to,"(\Bbb Q,+) (\Bbb Q,+) (\Bbb Q^*,\cdot) (\Bbb Q^*,\cdot)","Hope this isn't a duplicate. Considering homomorphisms from $(\Bbb Q,+)$ to itself, I notice that all the homomorphisms are of the form $\phi(x) = ax$ , where $a=\phi(1)$ . So there are exactly $\aleph_0$ number of homomorphisms from $(\Bbb Q,+)$ to itself and except the trivial 0-homomorphism, all others are onto-homomorphism . Is it correct? On the other hand, considering homomorphisms from $(\Bbb Q^*,\cdot)$ to itself, I get that $\phi(1) =1$ and also get some additional restrictions like if $x \in \Bbb Q^*$ and $x$ is a square number then $\phi(x) \neq y$ , where y is either (negative) or (positive but does not admit a rational square root) . Are there some other restrictions on a general homomorphism  from $(\Bbb Q^*,\cdot)$ to itself ? The following maps,(i) $ x \mapsto x$ and (ii) $x \mapsto x^{-1}$ (since, $(\Bbb Q^*,\cdot)$ is abelian) are automorphisms of $(\Bbb Q^*,\cdot)$ . How can one find the complete list of $Aut(\Bbb Q^*,\cdot)$ ? Thanks in advance for help.","Hope this isn't a duplicate. Considering homomorphisms from $(\Bbb Q,+)$ to itself, I notice that all the homomorphisms are of the form $\phi(x) = ax$ , where $a=\phi(1)$ . So there are exactly $\aleph_0$ number of homomorphisms from $(\Bbb Q,+)$ to itself and except the trivial 0-homomorphism, all others are onto-homomorphism . Is it correct? On the other hand, considering homomorphisms from $(\Bbb Q^*,\cdot)$ to itself, I get that $\phi(1) =1$ and also get some additional restrictions like if $x \in \Bbb Q^*$ and $x$ is a square number then $\phi(x) \neq y$ , where y is either (negative) or (positive but does not admit a rational square root) . Are there some other restrictions on a general homomorphism  from $(\Bbb Q^*,\cdot)$ to itself ? The following maps,(i) $ x \mapsto x$ and (ii) $x \mapsto x^{-1}$ (since, $(\Bbb Q^*,\cdot)$ is abelian) are automorphisms of $(\Bbb Q^*,\cdot)$ . How can one find the complete list of $Aut(\Bbb Q^*,\cdot)$ ? Thanks in advance for help.",,['abstract-algebra']
90,"If $K$ is an algebraically closed field and $F \in K[X, Y]$ is irreducible, then $\dim K[X, Y]/(F) = 1$","If  is an algebraically closed field and  is irreducible, then","K F \in K[X, Y] \dim K[X, Y]/(F) = 1","$\newcommand{\trianglelefteqslant}{\leqslant \hskip{-7.8pt} \raise{0.9pt}\vartriangleleft}$ Let $K$ be an algebraically closed field. I will now state some basic definitions as I don't know how standard they are. $K^n$ is equipped with the Zariski topology. Any closed or open subset of $K^n$ will be understood with respect to this topology; The dimension of a closed set $V \subseteq K^n$ is $$\dim V = \sup \{ n \in \mathbb{N} : (\exists V_0 \subsetneq V_1 \subsetneq \ldots \subsetneq V_n \subseteq V) \, V_k \text{'s are closed, irreducible} \};$$ The (Krull) dimension of a ring $R$ is $$\dim R = \sup \{ n \in \mathbb{N} : (\exists I_0 \supsetneq I_1 \supsetneq \ldots \supsetneq I_n ) \, I_k \text{'s are prime ideals in } R \};$$ The coordinate ring of $V \subseteq K^n$ is  $$K[V] = \{ F \upharpoonright V : F \in K[\overline{X}] \} \cong K[\overline{X}] / I(V).$$ The problem is: Suppose $F \in K[X, Y]$ is irreducible and $V = Z(F) \subseteq K^2$. Prove that $\dim V = 1$. What I know: Hilbert's Nullstellensatz: $I(Z(I)) = \sqrt{I}$; If $V \subseteq K^n$ is an affine algebraic set, then Zariski-closed subsets $U \subseteq V$ correspond bijectively to radical ideals $I \trianglelefteqslant K[\overline{X}]$ containing $I(V)$ by $U \substack{\xleftarrow{Z(I)} \\ \xrightarrow[I(U)]{}} I$; These in turn correspond to radical ideals $I \trianglelefteqslant K[V]$; In the above, irreducible closed subsets correspond to prime ideals; $\dim V = \dim K[V]$; I was presented a theorem that if $R$ is a domain and a finitely generated $K$-algebra, then $\dim R = \operatorname{td}_K R_0$, but it was said that the proof is somewhat complicated (uses an external theory), so I don't want to use that theorem; I can see how Krull's principal ideal theorem can be applied to immediately solve the problem, but I wasn't taught that theorem either, so if possible, I would rather avoid using it. However, if someone's really convinced there is no easier way, I will accept that as an answer. Now my recognition of the problem: obviously there is some $\overline{a} = (a_1, a_2) \in V$ and $(X-a_1, Y-a_2) \supsetneq (F)$ is a chain of length $n=1$ of prime ideals in $K[\overline{X}]$ containing $I(V)$. Also if there were a chain $I_0 \supsetneq I_1 \supsetneq I_2$, we can assume that $I_0 = (X-a_1, Y-a_2)$ for some $\overline{a} \in V$ and $I_2 = (F)$. As $K[X, Y]$ is Noetherian, $I_1 = (G_1, \ldots, G_n)$ for some $G_1, \ldots, G_n \in K[X, Y]$, which can be assumed to be irreducible since $I_1$ is prime, and pairwise unassociated. But that doesn't seem to give any easy contradiction. From the geometric side, suppose we have $V_0 \subsetneq V_1 \subsetneq V_2 \subseteq V$ closed, irreducible, so again we can assume $V_0 = \{ \overline{a} \}$ and $V_2 = V$ (and $V_1 = Z(I_1)$ if we want a connection). Any finite non-singleton is reducible, so $V_1$ is infinite (in fact, if $F$ depends on $Y$, the other case being trivial, then the projection $\pi_X[V_1]$ is co-finite). But I don't see any contradiction here either. Any hint would be appreciated.","$\newcommand{\trianglelefteqslant}{\leqslant \hskip{-7.8pt} \raise{0.9pt}\vartriangleleft}$ Let $K$ be an algebraically closed field. I will now state some basic definitions as I don't know how standard they are. $K^n$ is equipped with the Zariski topology. Any closed or open subset of $K^n$ will be understood with respect to this topology; The dimension of a closed set $V \subseteq K^n$ is $$\dim V = \sup \{ n \in \mathbb{N} : (\exists V_0 \subsetneq V_1 \subsetneq \ldots \subsetneq V_n \subseteq V) \, V_k \text{'s are closed, irreducible} \};$$ The (Krull) dimension of a ring $R$ is $$\dim R = \sup \{ n \in \mathbb{N} : (\exists I_0 \supsetneq I_1 \supsetneq \ldots \supsetneq I_n ) \, I_k \text{'s are prime ideals in } R \};$$ The coordinate ring of $V \subseteq K^n$ is  $$K[V] = \{ F \upharpoonright V : F \in K[\overline{X}] \} \cong K[\overline{X}] / I(V).$$ The problem is: Suppose $F \in K[X, Y]$ is irreducible and $V = Z(F) \subseteq K^2$. Prove that $\dim V = 1$. What I know: Hilbert's Nullstellensatz: $I(Z(I)) = \sqrt{I}$; If $V \subseteq K^n$ is an affine algebraic set, then Zariski-closed subsets $U \subseteq V$ correspond bijectively to radical ideals $I \trianglelefteqslant K[\overline{X}]$ containing $I(V)$ by $U \substack{\xleftarrow{Z(I)} \\ \xrightarrow[I(U)]{}} I$; These in turn correspond to radical ideals $I \trianglelefteqslant K[V]$; In the above, irreducible closed subsets correspond to prime ideals; $\dim V = \dim K[V]$; I was presented a theorem that if $R$ is a domain and a finitely generated $K$-algebra, then $\dim R = \operatorname{td}_K R_0$, but it was said that the proof is somewhat complicated (uses an external theory), so I don't want to use that theorem; I can see how Krull's principal ideal theorem can be applied to immediately solve the problem, but I wasn't taught that theorem either, so if possible, I would rather avoid using it. However, if someone's really convinced there is no easier way, I will accept that as an answer. Now my recognition of the problem: obviously there is some $\overline{a} = (a_1, a_2) \in V$ and $(X-a_1, Y-a_2) \supsetneq (F)$ is a chain of length $n=1$ of prime ideals in $K[\overline{X}]$ containing $I(V)$. Also if there were a chain $I_0 \supsetneq I_1 \supsetneq I_2$, we can assume that $I_0 = (X-a_1, Y-a_2)$ for some $\overline{a} \in V$ and $I_2 = (F)$. As $K[X, Y]$ is Noetherian, $I_1 = (G_1, \ldots, G_n)$ for some $G_1, \ldots, G_n \in K[X, Y]$, which can be assumed to be irreducible since $I_1$ is prime, and pairwise unassociated. But that doesn't seem to give any easy contradiction. From the geometric side, suppose we have $V_0 \subsetneq V_1 \subsetneq V_2 \subseteq V$ closed, irreducible, so again we can assume $V_0 = \{ \overline{a} \}$ and $V_2 = V$ (and $V_1 = Z(I_1)$ if we want a connection). Any finite non-singleton is reducible, so $V_1$ is infinite (in fact, if $F$ depends on $Y$, the other case being trivial, then the projection $\pi_X[V_1]$ is co-finite). But I don't see any contradiction here either. Any hint would be appreciated.",,"['abstract-algebra', 'algebraic-geometry']"
91,Basis of factors for large degree polynomials,Basis of factors for large degree polynomials,,"In $\mathbb{Z}_2$, the polynomial $x^{2^6}+x+1$ or $x^{64}+x+1$ factors into  $x^4+x+1$, $x^{12}+x^9+x^5+x^2+1$, $x^{12}+x^9+x^5+x^4+x^2+x+1$, $x^{12}+x^9+x^8+x^5+1$, $x^{12}+x^9+x^8+x^5+x^4+x+1$, $x^{12}+x^9+x^8+x^6+x^3+x^2+1$.  Below, under $1+x+x^{64}$, you can see the degree 12 factors arranged as columns, followed by the basis (a gray bar separates factors and basis). The same is shown for $n$ from 5 to 13. In $\mathbb{Z}_2$, $x^{2^n}+x+1$ has many factors of degree $2 n$ and the number of basis elements always seems to be $n-2$. Here are pictures of the basis for $n$ from 7 to 18. Here's Mathematica code for the first image. data = Table[Module[{ polynomials, len, polyandbasis},   polynomials = Last[Sort[SplitBy[SortBy[CoefficientList[#, x] & /@ (First /@    FactorList[x^(2^power) + x + 1, Modulus -> 2]), {Length[#], Reverse[#]} &], Length[#] &]]];   len = Length[polynomials[[1]]];   polyandbasis = Flatten /@ Transpose[{ 3 Transpose[polynomials], Table[{0, 1, 0}, {len}],    3 Transpose[Select[RowReduce[polynomials, Modulus -> 2], Total[#] > 0 &]]}];   Column[{Text[x^(2^power) + x + 1], ArrayPlot[polyandbasis, PixelConstrained -> True,    ImageSize -> {800, 2 len + 4}, Frame -> False]}, Alignment -> Center]], {power, 5, 13}]; Column[{Row[Take[data, 6], Spacer[30]], Row[Take[data, {7, 8}], Spacer[60]], Row[Take[data, {9}]]}] First question: Does the $\mathbb{Z}_2$ polynomial $x^{2^n}+x+1$ have a particular name? It has a lot of nice properties. I'd like to make pictures of higher order basis elements. Unfortunately, Mathematica doesn't want to Factor $x^{1048576}+x+1$, claiming it's out of bounds. Also, PolynomialGCD doesn't like high exponents. I've looked at the Cantor–Zassenhaus algorithm and other factorization methods over finite fields, but didn't readily understand them. Is there some clever way to get the basis of the $\mathbb{Z}_2$ factors of $x^{2^n}+x+1$ for $n$ from 19 to 120 in Mathematica? Is there some nice way of quickly getting some of the degree $2n$ factors.","In $\mathbb{Z}_2$, the polynomial $x^{2^6}+x+1$ or $x^{64}+x+1$ factors into  $x^4+x+1$, $x^{12}+x^9+x^5+x^2+1$, $x^{12}+x^9+x^5+x^4+x^2+x+1$, $x^{12}+x^9+x^8+x^5+1$, $x^{12}+x^9+x^8+x^5+x^4+x+1$, $x^{12}+x^9+x^8+x^6+x^3+x^2+1$.  Below, under $1+x+x^{64}$, you can see the degree 12 factors arranged as columns, followed by the basis (a gray bar separates factors and basis). The same is shown for $n$ from 5 to 13. In $\mathbb{Z}_2$, $x^{2^n}+x+1$ has many factors of degree $2 n$ and the number of basis elements always seems to be $n-2$. Here are pictures of the basis for $n$ from 7 to 18. Here's Mathematica code for the first image. data = Table[Module[{ polynomials, len, polyandbasis},   polynomials = Last[Sort[SplitBy[SortBy[CoefficientList[#, x] & /@ (First /@    FactorList[x^(2^power) + x + 1, Modulus -> 2]), {Length[#], Reverse[#]} &], Length[#] &]]];   len = Length[polynomials[[1]]];   polyandbasis = Flatten /@ Transpose[{ 3 Transpose[polynomials], Table[{0, 1, 0}, {len}],    3 Transpose[Select[RowReduce[polynomials, Modulus -> 2], Total[#] > 0 &]]}];   Column[{Text[x^(2^power) + x + 1], ArrayPlot[polyandbasis, PixelConstrained -> True,    ImageSize -> {800, 2 len + 4}, Frame -> False]}, Alignment -> Center]], {power, 5, 13}]; Column[{Row[Take[data, 6], Spacer[30]], Row[Take[data, {7, 8}], Spacer[60]], Row[Take[data, {9}]]}] First question: Does the $\mathbb{Z}_2$ polynomial $x^{2^n}+x+1$ have a particular name? It has a lot of nice properties. I'd like to make pictures of higher order basis elements. Unfortunately, Mathematica doesn't want to Factor $x^{1048576}+x+1$, claiming it's out of bounds. Also, PolynomialGCD doesn't like high exponents. I've looked at the Cantor–Zassenhaus algorithm and other factorization methods over finite fields, but didn't readily understand them. Is there some clever way to get the basis of the $\mathbb{Z}_2$ factors of $x^{2^n}+x+1$ for $n$ from 19 to 120 in Mathematica? Is there some nice way of quickly getting some of the degree $2n$ factors.",,"['abstract-algebra', 'polynomials', 'finite-fields', 'factoring', 'mathematica']"
92,"If $f(x+y) = f(x) + f(y)$, $f(1) = 1$ and for all $x,y$, $f(xy) = f(x)f(y)$ or $f(xy) = f(y)f(x)$, then $f$ is a homomorphism or an anti-homomorphism","If ,  and for all ,  or , then  is a homomorphism or an anti-homomorphism","f(x+y) = f(x) + f(y) f(1) = 1 x,y f(xy) = f(x)f(y) f(xy) = f(y)f(x) f","Let $R$ and $R'$ be two rings and $f: R\to R'$ be a map satisfying the conditions: $f(1) = 1$ . For all $x,y \in R$ , $f(x+y) = f(x) + f(y)$ . For all $x,y \in R$ , either $f(xy) = f(x)f(y)$ or $f(xy) = f(y)f(x)$ . Prove that $f$ is either a homomorphism or an anti-homomorphism. Where $f$ is called an anti-homomorphism if the first two conditions above are satisfied and for all $x,y$ , $f(xy) = f(y)f(x)$ . Any hints? Reference: This is exercise $9$ , page $114$ in Jacobson's Basic Algebra $1$ . The author writes (Hua.) at the start of the exercise - so apparently this result is due to Hua Luogeng ?","Let and be two rings and be a map satisfying the conditions: . For all , . For all , either or . Prove that is either a homomorphism or an anti-homomorphism. Where is called an anti-homomorphism if the first two conditions above are satisfied and for all , . Any hints? Reference: This is exercise , page in Jacobson's Basic Algebra . The author writes (Hua.) at the start of the exercise - so apparently this result is due to Hua Luogeng ?","R R' f: R\to R' f(1) = 1 x,y \in R f(x+y) = f(x) + f(y) x,y \in R f(xy) = f(x)f(y) f(xy) = f(y)f(x) f f x,y f(xy) = f(y)f(x) 9 114 1","['abstract-algebra', 'ring-theory', 'functional-equations', 'ring-homomorphism']"
93,Is an isomorphism sends any element to one of its conjugation elements inner?,Is an isomorphism sends any element to one of its conjugation elements inner?,,"If $G$ is a finite group, $f$ is an isomorphism from $G$ to $G$, s.t for any $x \in G$, there exists $y \in G$, and $f(x)=yxy^{-1}$ (note the order of quantifiers), is $f$ an inner isomorphism?","If $G$ is a finite group, $f$ is an isomorphism from $G$ to $G$, s.t for any $x \in G$, there exists $y \in G$, and $f(x)=yxy^{-1}$ (note the order of quantifiers), is $f$ an inner isomorphism?",,"['abstract-algebra', 'group-theory', 'finite-groups']"
94,Computing a Galois Group by Reducing Mod P,Computing a Galois Group by Reducing Mod P,,"On page 274 of Lang's Algebra , he states the following theorem (paraphrasing): Let $f(x) \in \mathbb{Z}[x]$ be a monic polynomial. Let $p$ be a   prime. Let $\bar{f} = f \bmod p$ be the polynomial obtained by   reducing the coefficients mod $p$. Assume that $\bar f$ has no   multiple roots in an algebraic closure of $\mathbb{F}_p$. Then there   is an embedding of the Galois group of $\bar f$ into the Galois group   of $f$. I'm confused about what this means; in particular, I don't know how exactly to interpret the phrase ""Galois group of $\bar f$."" Does it just mean the Galois group of $\bar f$ over $\mathbb{Q}$ where we forget that we ever reduced the coefficients mod $p$? Example: I think I can apply this theorem to compute the Galois group of $x^4 + 3x^2 - 3x - 2$ over $\mathbb{Q}$. Here's my argument. Please let me know if I'm applying the theorem correctly. Reducing $f$ mod 3 we get $x^4 - 2$, which has no multiple roots (since it is coprime with its derivative). The Galois group of $x^4 - 2$ over $\mathbb{Q}$ is the dihedral group with 8 elements. Reducing $f$ mod 2 we get $x^4 + x^3 - x = x(x^3 + x^2 - 1)$ which also has no multiple roots. The cubic has discriminant $-23$, which is not a square in $\mathbb{Q}$, so it has Galois group $S_3$. Let $G$ be the Galois group of $f$. We know $G$ embeds into $S_4$ since $f$ has degree 4. Now applying the theorem, both $S_3$ and $D_8$ embed into $G$, so $G$ has elements of order 3 and 4. They generate a subgroup of order at least 12, so $G$ must be $A_4$ or $S_4$. Since $D_8$ has order 8, it cannot embed into $A_4$, which has order 12, so $G = S_4$. Am I applying the theorem correctly?","On page 274 of Lang's Algebra , he states the following theorem (paraphrasing): Let $f(x) \in \mathbb{Z}[x]$ be a monic polynomial. Let $p$ be a   prime. Let $\bar{f} = f \bmod p$ be the polynomial obtained by   reducing the coefficients mod $p$. Assume that $\bar f$ has no   multiple roots in an algebraic closure of $\mathbb{F}_p$. Then there   is an embedding of the Galois group of $\bar f$ into the Galois group   of $f$. I'm confused about what this means; in particular, I don't know how exactly to interpret the phrase ""Galois group of $\bar f$."" Does it just mean the Galois group of $\bar f$ over $\mathbb{Q}$ where we forget that we ever reduced the coefficients mod $p$? Example: I think I can apply this theorem to compute the Galois group of $x^4 + 3x^2 - 3x - 2$ over $\mathbb{Q}$. Here's my argument. Please let me know if I'm applying the theorem correctly. Reducing $f$ mod 3 we get $x^4 - 2$, which has no multiple roots (since it is coprime with its derivative). The Galois group of $x^4 - 2$ over $\mathbb{Q}$ is the dihedral group with 8 elements. Reducing $f$ mod 2 we get $x^4 + x^3 - x = x(x^3 + x^2 - 1)$ which also has no multiple roots. The cubic has discriminant $-23$, which is not a square in $\mathbb{Q}$, so it has Galois group $S_3$. Let $G$ be the Galois group of $f$. We know $G$ embeds into $S_4$ since $f$ has degree 4. Now applying the theorem, both $S_3$ and $D_8$ embed into $G$, so $G$ has elements of order 3 and 4. They generate a subgroup of order at least 12, so $G$ must be $A_4$ or $S_4$. Since $D_8$ has order 8, it cannot embed into $A_4$, which has order 12, so $G = S_4$. Am I applying the theorem correctly?",,"['abstract-algebra', 'field-theory', 'galois-theory']"
95,Show $f(x)=1-\frac{1}{x\left(\lvert x\rvert_2\right)}$ converges on $0$ in finite steps,Show  converges on  in finite steps,f(x)=1-\frac{1}{x\left(\lvert x\rvert_2\right)} 0,"Let $$ f(x)=1-\frac{1}{x\lvert x\rvert_2}. $$ Show that $f^m(x)$ converges to $0$ for all $x\in\mathbb{N_{>0}}$, for   sufficiently high $m\in\mathbb{N}$. In a nutshell, $x\lvert x\rvert_2$ boils down to the odd factors of $x$. $\lvert x\rvert_2$ is the $2$-adic metric of $x$, defined by $\lvert x\rvert_2=\frac{1}{2^p}$, where $x=2^p\cdot\frac{r}{q}$ and $r,q$ are odd numbers. Note that the question is, whether for an initial integer input $x$, $f^m(x)$ converges, however $f(x)$ must be defined over rationals so we have $$f(x)=1-\frac{1}{x\lvert x\rvert_2}\quad \mathbb{Q}\mapsto\mathbb{Q}.$$ Let $x_{m+1}=f(x_m)$. Show that $\forall x_0\in\mathbb{N_{>0}}\exists > n\mid (f^m(x)=0\forall m\geq n)$ UPDATE I'm currently investigating whether Mahler's theorem and Newton's forward difference formula have something to say. Forward difference formula looks promising on the face of it but I haven't studied that in depth.","Let $$ f(x)=1-\frac{1}{x\lvert x\rvert_2}. $$ Show that $f^m(x)$ converges to $0$ for all $x\in\mathbb{N_{>0}}$, for   sufficiently high $m\in\mathbb{N}$. In a nutshell, $x\lvert x\rvert_2$ boils down to the odd factors of $x$. $\lvert x\rvert_2$ is the $2$-adic metric of $x$, defined by $\lvert x\rvert_2=\frac{1}{2^p}$, where $x=2^p\cdot\frac{r}{q}$ and $r,q$ are odd numbers. Note that the question is, whether for an initial integer input $x$, $f^m(x)$ converges, however $f(x)$ must be defined over rationals so we have $$f(x)=1-\frac{1}{x\lvert x\rvert_2}\quad \mathbb{Q}\mapsto\mathbb{Q}.$$ Let $x_{m+1}=f(x_m)$. Show that $\forall x_0\in\mathbb{N_{>0}}\exists > n\mid (f^m(x)=0\forall m\geq n)$ UPDATE I'm currently investigating whether Mahler's theorem and Newton's forward difference formula have something to say. Forward difference formula looks promising on the face of it but I haven't studied that in depth.",,"['abstract-algebra', 'number-theory', 'convergence-divergence', 'p-adic-number-theory', 'continued-fractions']"
96,Proof of extension field containing a root of irreducible polynomial,Proof of extension field containing a root of irreducible polynomial,,"I have been reading Dummit/Foote lately, and in the introductory chapter on field theory, there is the following theorem: Theorem Let F be a field and let $p(x) \in F[x]$ be irreducible.  Then there exists a field $K$ containing an isomorphic copy of $F$ in which $p(x)$ has a root. In the proof of this theorem, $K$ is defined to be $F[x]/ \langle p(x)\rangle$, so that elements of $K$ look like $f(x) + \langle p(x) \rangle$ for some $f(x) \in F[x]$.  The claim is that the element $x + \langle p(x) \rangle$ is a root of $p(x)$.  My question is: If $p(x)$ belongs to $F[x]$, why can you even ""evaluate"" $p(x)$ at the element $x + \langle p(x) \rangle$.  If $p(x) = a_nx^n + \cdots + a_1x + a_0$, evaluating at $x + \langle p(x) \rangle$ looks something like \begin{equation*} a_n \big(x + \langle p(x) \rangle\big)^n + \cdots + a_1 \big(x + \langle p(x) \rangle\big) + a_0 \end{equation*} But what does $a_1 \big(x + \langle p(x) \rangle\big)$ even mean?  I'm guessing that it is probably equal to $a_1x + \langle p(x) \rangle$.  But as far as I can tell, there is no definition (in D/F) of what this expression means or whether it even has a meaning. After thinking about this a little more, I have come up with the following hypothesis. Perhaps the theorem that I stated above could be stated as follows: Theorem (modified version) Let $F$ be a field and $p(x) \in F[x]$ be irreducible.  Then there exists a field $K$ such that the following are satisfied: There is an isomorphism $\phi: F \to \phi(F) \subset K$. The polynomial $\tilde{p}(x):= \phi(a_n) x^n + \cdots + \phi(a_1)x + \phi(a_0) \in K[x]$ contains a root, i.e. there exists $\alpha \in K$ with the property that $\tilde{p}(\alpha) = 0_K$. I would feel more comfortable about using this approach.  It seems strange (and to me, even not rigorous) to evaluate $p(x) \in F[x]$ at an element $\alpha \in K$ when $K$ is not (formally speaking) a super field of $F$.  By using the above formulation, we don't have this problem.  (Note: I know that some may take objection to my statement that $K$ is not a super field of $F$.  I realize that $K$ contains an isomorphic copy of $F$, but if $F \subset K$ does not hold in the set-theoretic sense, then it seems that you run into the problem  of defining what $a_1 \alpha$ means when $a_1 \in F$ and $\alpha \in K$.) To summarize, I guess I have outlined three general questions (although I would be grateful for comments on anything in this post) What is the meaning of the expression $a_1 \big(x + \langle p(x) \rangle \big)$ when $a_1 \in F$? If $f(x) \in F[x]$, what can I evaluate $f$ at?  Does this element need to belong to $F$? Is my restatement of the theorem correct?  If both formulations are correct, how is the one given in D/F rigorous?","I have been reading Dummit/Foote lately, and in the introductory chapter on field theory, there is the following theorem: Theorem Let F be a field and let $p(x) \in F[x]$ be irreducible.  Then there exists a field $K$ containing an isomorphic copy of $F$ in which $p(x)$ has a root. In the proof of this theorem, $K$ is defined to be $F[x]/ \langle p(x)\rangle$, so that elements of $K$ look like $f(x) + \langle p(x) \rangle$ for some $f(x) \in F[x]$.  The claim is that the element $x + \langle p(x) \rangle$ is a root of $p(x)$.  My question is: If $p(x)$ belongs to $F[x]$, why can you even ""evaluate"" $p(x)$ at the element $x + \langle p(x) \rangle$.  If $p(x) = a_nx^n + \cdots + a_1x + a_0$, evaluating at $x + \langle p(x) \rangle$ looks something like \begin{equation*} a_n \big(x + \langle p(x) \rangle\big)^n + \cdots + a_1 \big(x + \langle p(x) \rangle\big) + a_0 \end{equation*} But what does $a_1 \big(x + \langle p(x) \rangle\big)$ even mean?  I'm guessing that it is probably equal to $a_1x + \langle p(x) \rangle$.  But as far as I can tell, there is no definition (in D/F) of what this expression means or whether it even has a meaning. After thinking about this a little more, I have come up with the following hypothesis. Perhaps the theorem that I stated above could be stated as follows: Theorem (modified version) Let $F$ be a field and $p(x) \in F[x]$ be irreducible.  Then there exists a field $K$ such that the following are satisfied: There is an isomorphism $\phi: F \to \phi(F) \subset K$. The polynomial $\tilde{p}(x):= \phi(a_n) x^n + \cdots + \phi(a_1)x + \phi(a_0) \in K[x]$ contains a root, i.e. there exists $\alpha \in K$ with the property that $\tilde{p}(\alpha) = 0_K$. I would feel more comfortable about using this approach.  It seems strange (and to me, even not rigorous) to evaluate $p(x) \in F[x]$ at an element $\alpha \in K$ when $K$ is not (formally speaking) a super field of $F$.  By using the above formulation, we don't have this problem.  (Note: I know that some may take objection to my statement that $K$ is not a super field of $F$.  I realize that $K$ contains an isomorphic copy of $F$, but if $F \subset K$ does not hold in the set-theoretic sense, then it seems that you run into the problem  of defining what $a_1 \alpha$ means when $a_1 \in F$ and $\alpha \in K$.) To summarize, I guess I have outlined three general questions (although I would be grateful for comments on anything in this post) What is the meaning of the expression $a_1 \big(x + \langle p(x) \rangle \big)$ when $a_1 \in F$? If $f(x) \in F[x]$, what can I evaluate $f$ at?  Does this element need to belong to $F$? Is my restatement of the theorem correct?  If both formulations are correct, how is the one given in D/F rigorous?",,"['abstract-algebra', 'field-theory']"
97,Discriminant of a cyclotomic field,Discriminant of a cyclotomic field,,"If $\zeta$ is a primitive $n$ -th root of unity, prove that: $$d(1, \zeta,...,\zeta^{\varphi(n)-1})=(-1)^{\varphi(n)/2}n^{\varphi(n)}\prod_{p\mid n} p^{-\frac{\varphi(n)}{p-1}}$$ Let $n=\prod_{i=1}^{m}p_i^{e_i}$ . After looking it up in some books, I was able to understand why this is true for $m=1$ . However, they all ignored the general case $m>1$ or simply stated that it could be done by induction on $m$ , but I really can't see how it could be done. The only interesting thing I could find out was that for $n,m$ with $\gcd(n, m)=1$ , we get, on the right hand side of the equation: $$(-1)^{\varphi(nm)/2}nm^{\varphi(nm)}\prod_{p\mid nm} p^{-\frac{\varphi(nm)}{p-1}}=$$ $$\left((-1)^{\varphi(n)/2}n^{\varphi(n)}\prod_{p\mid n} p^{-\frac{\varphi(n)}{p-1}}\right)^{\varphi(m)}\left((-1)^{\varphi(m)/2}n^{\varphi(m)}\prod_{p\mid m} p^{-\frac{\varphi(m)}{p-1}}\right)^{\varphi(n)}$$ That makes me think I'm getting somewhere, but I'm stuck with the problem of showing that $d(1, \zeta,...,\zeta^{\varphi(nm)-1})=[d(1, \zeta,...,\zeta^{\varphi(n)-1})]^{\varphi(m)}[d(1, \zeta,...,\zeta^{\varphi(m)-1})]^{\varphi(n)}$ , which doesn't seem trivial at all. Any ideas? Thanks!","If is a primitive -th root of unity, prove that: Let . After looking it up in some books, I was able to understand why this is true for . However, they all ignored the general case or simply stated that it could be done by induction on , but I really can't see how it could be done. The only interesting thing I could find out was that for with , we get, on the right hand side of the equation: That makes me think I'm getting somewhere, but I'm stuck with the problem of showing that , which doesn't seem trivial at all. Any ideas? Thanks!","\zeta n d(1, \zeta,...,\zeta^{\varphi(n)-1})=(-1)^{\varphi(n)/2}n^{\varphi(n)}\prod_{p\mid n} p^{-\frac{\varphi(n)}{p-1}} n=\prod_{i=1}^{m}p_i^{e_i} m=1 m>1 m n,m \gcd(n, m)=1 (-1)^{\varphi(nm)/2}nm^{\varphi(nm)}\prod_{p\mid nm} p^{-\frac{\varphi(nm)}{p-1}}= \left((-1)^{\varphi(n)/2}n^{\varphi(n)}\prod_{p\mid n} p^{-\frac{\varphi(n)}{p-1}}\right)^{\varphi(m)}\left((-1)^{\varphi(m)/2}n^{\varphi(m)}\prod_{p\mid m} p^{-\frac{\varphi(m)}{p-1}}\right)^{\varphi(n)} d(1, \zeta,...,\zeta^{\varphi(nm)-1})=[d(1, \zeta,...,\zeta^{\varphi(n)-1})]^{\varphi(m)}[d(1, \zeta,...,\zeta^{\varphi(m)-1})]^{\varphi(n)}","['abstract-algebra', 'number-theory', 'algebraic-number-theory']"
98,Lüroth's theorem for complex trigonometric polynomials,Lüroth's theorem for complex trigonometric polynomials,,Is it true that a subfield $K$ of $C_t(s)$ (the quotient field of the ring of trigonometric polynomials with complex coefficients) containing a non-constant trigonometric polynomial satisfies that $K=\mathbb C(r)$ for some trigonometric polynomial $r$? (This is Lüroth's theorem for complex trigonometric polynomials.),Is it true that a subfield $K$ of $C_t(s)$ (the quotient field of the ring of trigonometric polynomials with complex coefficients) containing a non-constant trigonometric polynomial satisfies that $K=\mathbb C(r)$ for some trigonometric polynomial $r$? (This is Lüroth's theorem for complex trigonometric polynomials.),,['abstract-algebra']
99,Quotient of Polynomial Ring by Irreducible Polynomial is Simple Extension,Quotient of Polynomial Ring by Irreducible Polynomial is Simple Extension,,"Let $F$ be a field, and $f$ an irreducible polynomial in $F[x]$. Is $F[x]/(f)$ necessarily of the form $F(\alpha)$, where $\alpha$ is a root of $f$? The only examples I know, e.g. $\mathbb{R}[x]/(x^2+1)\cong\mathbb{R}(i)\cong\mathbb{C}$ seems to support the argument. What I know is $K=F[x]/(f)$ is a field when $f$ is irreducible, and $[K:F]=\deg f$. Thanks for any help in proving or disproving.","Let $F$ be a field, and $f$ an irreducible polynomial in $F[x]$. Is $F[x]/(f)$ necessarily of the form $F(\alpha)$, where $\alpha$ is a root of $f$? The only examples I know, e.g. $\mathbb{R}[x]/(x^2+1)\cong\mathbb{R}(i)\cong\mathbb{C}$ seems to support the argument. What I know is $K=F[x]/(f)$ is a field when $f$ is irreducible, and $[K:F]=\deg f$. Thanks for any help in proving or disproving.",,"['abstract-algebra', 'field-theory', 'galois-theory', 'extension-field']"
