,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Show that $A$ does not have any non-empty proper subsets if and only if $A=\{x\}$ for some object $x$.,Show that  does not have any non-empty proper subsets if and only if  for some object .,A A=\{x\} x,"I've seemingly hit a wall with this exercise, in full it states: Euclid famously defined a point to be “that which has no part”. This exercise should be reminiscent of that definition. Define a proper subset of a set $A$ to be a subset $B$ of $A$ with $B \neq A$ . Let $A$ be a non-empty set. Show that $A$ does not have any non-empty proper subsets if and only if $A$ is of the form $A = \{x\}$ for some object $x$ . This exercise is of the form $P\iff Q$ . I'll define $P$ to be the statement: $A$ does not have any non-empty proper subsets, and $Q$ to be $A$ is of the form $A = \{x\}$ for some object $x$ . Just to make it a bit easier to talk about each statement. Assume that $A$ is a non-empty set. Since $A$ is non-empty, let $x\in A$ . To prove $Q\implies P$ , by contrapositive $(Q\implies P)\iff (\neg P\implies \neg Q)$ . Suppose $\neg P$ i.e., $A$ has a non-empty proper subset $A'$ . Then $A'\subseteq A$ and $A'\neq A$ . Thus $\forall x \in A' \implies x\in A$ . Also $\exists y\in A':y\notin A$ or $\exists z \in A :z\notin A'$ . If $y \in A'$ then $y\in A$ . Suppose $x=y$ then $x\in A\implies y\in A$ , a contradiction. Thus $x\neq y$ . Thus the set $A$ has at least two elements. If $z\in A$ then $x\in A$ and $z\in A$ . Suppose $x=z$ then $z\notin A' \implies x\notin A'$ but I don't know if I can continue with this. If I were to get a contradiction on that last statement then in both cases $A$ has at least two elements and thus would've shown $\neg Q$ . To prove $P\implies Q$ , I used contradiction, $P\land \neg Q$ and supposed $\exists t \in A:t\neq x$ and the set $B=\{x,t\}$ . Since it is a subset but it can't be proper subset we get $A=B$ but I can't continue. An argument with contrapositive/contradiction seems very ""natural"" here because of the ""does not have"" but I couldn't continue with it and everytime I tried starting over, I couldn't think of anything else other than contradiction. All the steps I did, especially for $Q\implies P$ seemed very natural so assuming everything is correct, there could be a way for it to work, Now for $P\implies Q$ , I wouldn't call it very ""natural"" so I have a bit less faith in that approach. Something that seemed weird about working with $Q$ was that its negations are infinite so I could make other assumptions but the more elaborate I tried to make them, the difficulty in getting a proof remained the same, which was kind of beautiful but also annoying. Assuming they are correct, could any of my arguments work? If not, what would be another way to go? Could the first sentence about Euclid hint some way of proving this that I didn't see?","I've seemingly hit a wall with this exercise, in full it states: Euclid famously defined a point to be “that which has no part”. This exercise should be reminiscent of that definition. Define a proper subset of a set to be a subset of with . Let be a non-empty set. Show that does not have any non-empty proper subsets if and only if is of the form for some object . This exercise is of the form . I'll define to be the statement: does not have any non-empty proper subsets, and to be is of the form for some object . Just to make it a bit easier to talk about each statement. Assume that is a non-empty set. Since is non-empty, let . To prove , by contrapositive . Suppose i.e., has a non-empty proper subset . Then and . Thus . Also or . If then . Suppose then , a contradiction. Thus . Thus the set has at least two elements. If then and . Suppose then but I don't know if I can continue with this. If I were to get a contradiction on that last statement then in both cases has at least two elements and thus would've shown . To prove , I used contradiction, and supposed and the set . Since it is a subset but it can't be proper subset we get but I can't continue. An argument with contrapositive/contradiction seems very ""natural"" here because of the ""does not have"" but I couldn't continue with it and everytime I tried starting over, I couldn't think of anything else other than contradiction. All the steps I did, especially for seemed very natural so assuming everything is correct, there could be a way for it to work, Now for , I wouldn't call it very ""natural"" so I have a bit less faith in that approach. Something that seemed weird about working with was that its negations are infinite so I could make other assumptions but the more elaborate I tried to make them, the difficulty in getting a proof remained the same, which was kind of beautiful but also annoying. Assuming they are correct, could any of my arguments work? If not, what would be another way to go? Could the first sentence about Euclid hint some way of proving this that I didn't see?","A B A B \neq A A A A A = \{x\} x P\iff Q P A Q A A = \{x\} x A A x\in A Q\implies P (Q\implies P)\iff (\neg P\implies \neg Q) \neg P A A' A'\subseteq A A'\neq A \forall x \in A' \implies x\in A \exists y\in A':y\notin A \exists z \in A :z\notin A' y \in A' y\in A x=y x\in A\implies y\in A x\neq y A z\in A x\in A z\in A x=z z\notin A' \implies x\notin A' A \neg Q P\implies Q P\land \neg Q \exists t \in A:t\neq x B=\{x,t\} A=B Q\implies P P\implies Q Q","['elementary-set-theory', 'solution-verification']"
1,Dubious proof in Halmos's book: Two similar ordinal numbers are always equal,Dubious proof in Halmos's book: Two similar ordinal numbers are always equal,,"I'm studying ordinal numbers using Naive set theory of Halmos. I think there was a small mistake in his proof of the statement ""if two ordinal numbers are similar, then they are equal"" The proof goes as follow: To prove this, suppose that $\alpha$ and $\beta$ are ordinal numbers and that $f$ is a similarity from $\alpha$ onto $\beta$ ; we shall show that $f(\theta) = \theta$ for each $\theta \in \alpha$ . The proof is a straightforward transfinite induction. Write $S$ = { $\theta \in \alpha: f(\theta) = \theta $ }. For each $\theta \in \alpha$ , the least element of $\alpha$ that does not belong to $s(\theta)$ is $\theta$ itself (here s $(\theta)$ is the initial segment of $\theta$ in $\alpha$ ). Since $f$ is a similarity, it follows that the least element of $\beta$ that does not belong to the image of $s(\theta)$ under $f$ is $f(\theta)$ . These assertions imply that if $s(\theta) \subset S$ , then $f(\theta)$ and $\theta$ are ordinal numbers with the same initial segments, and hence $f(\theta) = \theta$ . We have proved thus that $\theta \in S$ whenever $s(\theta) \subset S$ . The principle of transfinite induction implies that $S = \alpha$ , and from this it follows that $\alpha = \beta$ I think that there are 2 suspicious points in the proof of the author: He does not prove the base case for $\theta = 0$ . In fact, to prove the base case, we must prove that $f(0) = 0$ , and I don't see any reason why should $f(0) = 0$ . Therefore, the transfinite induction may be broken even for the base case. There maybe a problem in the definition of the set $S$ by the author. Here he denotes $S$ = { $\theta \in \alpha: f(\theta) = \theta $ }. I think that this definition implies implicitly that the range of $f$ is the set $\alpha$ which may not be true (because $f$ maps from $\alpha$ to $\beta$ which can be 2 completely different sets). So therefore, it is not sure that the set $S$ is not empty. Could you please tell me if there is a small mistake in the proof or it's me who says stupid things ? Thank you very much for your help!","I'm studying ordinal numbers using Naive set theory of Halmos. I think there was a small mistake in his proof of the statement ""if two ordinal numbers are similar, then they are equal"" The proof goes as follow: To prove this, suppose that and are ordinal numbers and that is a similarity from onto ; we shall show that for each . The proof is a straightforward transfinite induction. Write = { }. For each , the least element of that does not belong to is itself (here s is the initial segment of in ). Since is a similarity, it follows that the least element of that does not belong to the image of under is . These assertions imply that if , then and are ordinal numbers with the same initial segments, and hence . We have proved thus that whenever . The principle of transfinite induction implies that , and from this it follows that I think that there are 2 suspicious points in the proof of the author: He does not prove the base case for . In fact, to prove the base case, we must prove that , and I don't see any reason why should . Therefore, the transfinite induction may be broken even for the base case. There maybe a problem in the definition of the set by the author. Here he denotes = { }. I think that this definition implies implicitly that the range of is the set which may not be true (because maps from to which can be 2 completely different sets). So therefore, it is not sure that the set is not empty. Could you please tell me if there is a small mistake in the proof or it's me who says stupid things ? Thank you very much for your help!",\alpha \beta f \alpha \beta f(\theta) = \theta \theta \in \alpha S \theta \in \alpha: f(\theta) = \theta  \theta \in \alpha \alpha s(\theta) \theta (\theta) \theta \alpha f \beta s(\theta) f f(\theta) s(\theta) \subset S f(\theta) \theta f(\theta) = \theta \theta \in S s(\theta) \subset S S = \alpha \alpha = \beta \theta = 0 f(0) = 0 f(0) = 0 S S \theta \in \alpha: f(\theta) = \theta  f \alpha f \alpha \beta S,"['elementary-set-theory', 'solution-verification', 'ordinals']"
2,Can infinite union of finite sets be finite? [duplicate],Can infinite union of finite sets be finite? [duplicate],,"This question already has an answer here : Infinite countable union of finite sets (1 answer) Closed 12 months ago . Intuitively, I can say no! Because just look at following example: singleton sets $\{ n\}$ where $n \in \mathbb N$ and their infinite union $\cup_{n\in \mathbb N} n$ is infinite. My question is can I find finite sets whose infinite union is finite?","This question already has an answer here : Infinite countable union of finite sets (1 answer) Closed 12 months ago . Intuitively, I can say no! Because just look at following example: singleton sets where and their infinite union is infinite. My question is can I find finite sets whose infinite union is finite?",\{ n\} n \in \mathbb N \cup_{n\in \mathbb N} n,['elementary-set-theory']
3,Proof of $(A\cup B) \times X = (A \times X) \cup (B \times X)$ [duplicate],Proof of  [duplicate],(A\cup B) \times X = (A \times X) \cup (B \times X),"This question already has an answer here : Proof verification: Cartesian Product of Sets (1 answer) Closed 12 months ago . An exercise given in Halmos' Naive Set Theory : required to prove that $$(A\cup B) \times X = (A \times X) \cup (B \times X).$$ My approach to this was as follows. Assume $z$ belongs to $(A\cup B) \times X$ , then, since $z$ is a member of a cartesian product, it must be of the form $z = (x,y)$ with $x$ in $A\cup B$ and $y$ in $X$ . Then $x$ is either in $A$ , or in $B$ . If $x$ is in $A$ , then since $y$ is also in $X$ , $(x,y)$ is, by definition, in $A \times X$ . However, if $x$ is in $B$ , then, again, by definition, $(x,y)$ must be in $B \times X$ . So then $(x,y)$ is in $A \times X$ , or it is in $B \times X$ . From this it follows that $z$ is in $(A \times X) \cup (B \times X)$ . We have just proved the ""only if"" part of the initial statement we set out to prove. Now, to prove the ""if"" part: Assume $z$ is in $(A \times X) \cup (B \times X)$ , then $(x,y)$ is either in $A\times X$ or $B \times X$ . If the former case is true, then $x$ is in $A$ , and $y$ is in $X$ , however, if the latter case is true, then $x$ is in $B$ , and $y$ is in $X$ . Since in both cases $y$ is in $X$ , it follows from disjunction elimination that $y$ is in $X$ . Then $x$ is either in $A$ or $B$ , and $y$ is in $X$ ; hence, $x$ is in $A\cup B$ and $y$ is in $X$ . Then, by definition, $(x,y)$ is in $(A\cup B) \times X$ . I have never done a proof using cartesian products before, so I must ask for guidance from some more professional. Is there any fault in my reasoning, moreover, is it ok for a proof to be formated like this? I am still fairly new to proving set-theoretic facts so I require constant affirmation from the more professional. Thank you in advance.","This question already has an answer here : Proof verification: Cartesian Product of Sets (1 answer) Closed 12 months ago . An exercise given in Halmos' Naive Set Theory : required to prove that My approach to this was as follows. Assume belongs to , then, since is a member of a cartesian product, it must be of the form with in and in . Then is either in , or in . If is in , then since is also in , is, by definition, in . However, if is in , then, again, by definition, must be in . So then is in , or it is in . From this it follows that is in . We have just proved the ""only if"" part of the initial statement we set out to prove. Now, to prove the ""if"" part: Assume is in , then is either in or . If the former case is true, then is in , and is in , however, if the latter case is true, then is in , and is in . Since in both cases is in , it follows from disjunction elimination that is in . Then is either in or , and is in ; hence, is in and is in . Then, by definition, is in . I have never done a proof using cartesian products before, so I must ask for guidance from some more professional. Is there any fault in my reasoning, moreover, is it ok for a proof to be formated like this? I am still fairly new to proving set-theoretic facts so I require constant affirmation from the more professional. Thank you in advance.","(A\cup B) \times X = (A \times X) \cup (B \times X). z (A\cup B) \times X z z = (x,y) x A\cup B y X x A B x A y X (x,y) A \times X x B (x,y) B \times X (x,y) A \times X B \times X z (A \times X) \cup (B \times X) z (A \times X) \cup (B \times X) (x,y) A\times X B \times X x A y X x B y X y X y X x A B y X x A\cup B y X (x,y) (A\cup B) \times X","['elementary-set-theory', 'solution-verification', 'proof-writing']"
4,Existence of supremum implies existence of infimum,Existence of supremum implies existence of infimum,,"I'm reading A Book of Set Theory by Charles C. Pinter. I don't know how to solve exercise 4.3.11. Let $A$ be a partially ordered class. Prove the following: a) If every subclass of $A$ has a $\sup$ and an $\inf$ in $A$ , then $A$ has a least element and a greatest element. [Hint: Use 4.27.] b) The following two statements are equivalent: Every subclass of $A$ has a $\sup$ ; every subclass of $A$ has an $\inf$ . Part a) seems straightforward: $A$ is a subclass of itself so $\sup A$ and $\inf A$ exist and must be its greatest and lowest elements respectively. However I'm confused with b). Isn't it obviously false? Consider the partial order defined on the class $A=\{1,2,3\}$ represented in this diagram or equivalently given by the graph $G=\{(1,1),(1,2),(1,3),(2,2),(3,3)\}$ . Then any subclass of $A$ has an infimum but $A$ itself does not have a supremum, right? What am I missing?","I'm reading A Book of Set Theory by Charles C. Pinter. I don't know how to solve exercise 4.3.11. Let be a partially ordered class. Prove the following: a) If every subclass of has a and an in , then has a least element and a greatest element. [Hint: Use 4.27.] b) The following two statements are equivalent: Every subclass of has a ; every subclass of has an . Part a) seems straightforward: is a subclass of itself so and exist and must be its greatest and lowest elements respectively. However I'm confused with b). Isn't it obviously false? Consider the partial order defined on the class represented in this diagram or equivalently given by the graph . Then any subclass of has an infimum but itself does not have a supremum, right? What am I missing?","A A \sup \inf A A A \sup A \inf A \sup A \inf A A=\{1,2,3\} G=\{(1,1),(1,2),(1,3),(2,2),(3,3)\} A A","['elementary-set-theory', 'order-theory', 'supremum-and-infimum']"
5,Can set operatoins be expressed in terms of symmetric difference and set complement?,Can set operatoins be expressed in terms of symmetric difference and set complement?,,"I'm trying to prove that the main set operations $A \cap B$ , $A \cup B$ and $A \backslash B$ can be expressed in terms of the symmetric difference and the set complement $A \triangle B$ and $A^{c}$ . I'm having no success, since the symmetric difference is associative and commutative and also since $(A \triangle B)^{c} = A^{c} \triangle B$ , I figured if there's any way to express $A \cup B$ in terms of it then it must be something of the form $A_{1} \triangle A_{2} \triangle ... \triangle A_{n}$ where each $A_{i}$ is either $A$ , $B$ , or $A^{c}$ or $B^{c}$ . Say we group them so that the $A_{i}$ s that have $A$ are together, then we would have something like $A \triangle A \triangle A^{c} \triangle....$ an expression of this form can only ever be equal to $\emptyset, A, A^{c}, U$ where $U$ is the universe. Same goes for the string of $B$ s and $B^{c}$ s. Try out any combination of those four possible $A$ s and the four possible $B$ s and you get none of the set operations mentioned above. For this reason I'm starting to think it might just be impossible, even tho it is listed as an exercise on this book I'm reading.","I'm trying to prove that the main set operations , and can be expressed in terms of the symmetric difference and the set complement and . I'm having no success, since the symmetric difference is associative and commutative and also since , I figured if there's any way to express in terms of it then it must be something of the form where each is either , , or or . Say we group them so that the s that have are together, then we would have something like an expression of this form can only ever be equal to where is the universe. Same goes for the string of s and s. Try out any combination of those four possible s and the four possible s and you get none of the set operations mentioned above. For this reason I'm starting to think it might just be impossible, even tho it is listed as an exercise on this book I'm reading.","A \cap B A \cup B A \backslash B A \triangle B A^{c} (A \triangle B)^{c} = A^{c} \triangle B A \cup B A_{1} \triangle A_{2} \triangle ... \triangle A_{n} A_{i} A B A^{c} B^{c} A_{i} A A \triangle A \triangle A^{c} \triangle.... \emptyset, A, A^{c}, U U B B^{c} A B",['elementary-set-theory']
6,Intersection of intersection of families of sets is intersection of union of families of sets,Intersection of intersection of families of sets is intersection of union of families of sets,,"I am going through Velleman's ""How to prove it"" and I am stuck on exercise 13b of section 2.3, where I have to show: $$(\cap \mathcal{F})\cap (\cap \mathcal{G})=\cap(\mathcal{F}\cup \mathcal{G})$$ I don't see how the union comes into place here. Here's what I have got: $$x\in (\cap \mathcal{F})\cap (\cap \mathcal{G})$$ $$x\in (\cap \mathcal{F})\land x\in(\cap \mathcal{G})$$ $$(\forall i \in I (x\in A_i)) \land (\forall i \in I (x\in B_i))$$ $$\forall i \in I ((x\in A_i) \land (x\in B_i))$$ $$x\in \cap (A_i\cap B_i)$$ Something must be wrong here, somehow the i dissappeared. Hope someone can help.","I am going through Velleman's ""How to prove it"" and I am stuck on exercise 13b of section 2.3, where I have to show: I don't see how the union comes into place here. Here's what I have got: Something must be wrong here, somehow the i dissappeared. Hope someone can help.",(\cap \mathcal{F})\cap (\cap \mathcal{G})=\cap(\mathcal{F}\cup \mathcal{G}) x\in (\cap \mathcal{F})\cap (\cap \mathcal{G}) x\in (\cap \mathcal{F})\land x\in(\cap \mathcal{G}) (\forall i \in I (x\in A_i)) \land (\forall i \in I (x\in B_i)) \forall i \in I ((x\in A_i) \land (x\in B_i)) x\in \cap (A_i\cap B_i),"['elementary-set-theory', 'logic']"
7,Determine all numbers n satisfying the given ratio,Determine all numbers n satisfying the given ratio,,"Let $n$ be an even natural number. We divide the numbers $1, 2,\dots , n^2$ into two equal sets $A$ and $B$ (that is $|A|=|B|=n^2/2$ ), such that each of the $n^2$ numbers is exactly in one of the sets. Let $S_A$ and $S_B$ be the sum of all elements in $A$ and $B$ . Determine all numbers $n$ so that there is a division satisfying $$\frac{S_A}{S_B}=\frac{39}{64}.$$ I found the value of $S_B$ . $$ \begin{aligned} &\frac{S_A}{S_B}=\frac{39}{64}\\ &\begin{aligned} \frac{S_A+S_B}{S_B} & =\frac{39+64}{64} \\ \frac{\frac{\eta^2\left(n^2+1\right)}{2}}{S_B} & =\frac{103}{64} \\ S_B & =64 \cdot \frac{n^2\left(n^2+1\right)}{103 \cdot 2} \\ & =32 \cdot \frac{n^2\left(n^2+1\right)}{103} \end{aligned} \end{aligned} $$ Now this value should be smaller than or equal to sum of last n terms and greater than sum of first n terms. $$ \begin{aligned} & \text { Sum of first in terms } \leq S_B \leqslant \text { sum of last ' } n \text { ' } \\ & \text { terms } \\ & \frac{n^2/2(n^2/2+1)}{2} \leq \frac{32}{103} n^2\left(n^2+1\right) \leq \\ & \frac{n^2\left(n^2+1\right)}{2}-\frac{n^2/2(n^2/2+1)}{2} \end{aligned} $$ I am not able to solve this inequality.Also I am not sure if this is correct direction. Because if I use geogebra then above inequality must have solution in between (0,3).","Let be an even natural number. We divide the numbers into two equal sets and (that is ), such that each of the numbers is exactly in one of the sets. Let and be the sum of all elements in and . Determine all numbers so that there is a division satisfying I found the value of . Now this value should be smaller than or equal to sum of last n terms and greater than sum of first n terms. I am not able to solve this inequality.Also I am not sure if this is correct direction. Because if I use geogebra then above inequality must have solution in between (0,3).","n 1, 2,\dots , n^2 A B |A|=|B|=n^2/2 n^2 S_A S_B A B n \frac{S_A}{S_B}=\frac{39}{64}. S_B 
\begin{aligned}
&\frac{S_A}{S_B}=\frac{39}{64}\\
&\begin{aligned}
\frac{S_A+S_B}{S_B} & =\frac{39+64}{64} \\
\frac{\frac{\eta^2\left(n^2+1\right)}{2}}{S_B} & =\frac{103}{64} \\
S_B & =64 \cdot \frac{n^2\left(n^2+1\right)}{103 \cdot 2} \\
& =32 \cdot \frac{n^2\left(n^2+1\right)}{103}
\end{aligned}
\end{aligned}
 
\begin{aligned}
& \text { Sum of first in terms } \leq S_B \leqslant \text { sum of last ' } n \text { ' } \\
& \text { terms } \\
& \frac{n^2/2(n^2/2+1)}{2} \leq \frac{32}{103} n^2\left(n^2+1\right) \leq \\
& \frac{n^2\left(n^2+1\right)}{2}-\frac{n^2/2(n^2/2+1)}{2}
\end{aligned}
","['sequences-and-series', 'elementary-set-theory', 'contest-math']"
8,Prove that $\mathcal{P}(\mathbb{Z}^+)$ is uncountable,Prove that  is uncountable,\mathcal{P}(\mathbb{Z}^+),"Prove: $\mathcal{P}(\mathbb{Z}^+)$ is uncountable Here is an excerpt from a proof of this result that I am struggling to follow: As a part of the proof that $\mathcal{P}(\mathbb{Z}^+)$ is uncountable, my textbook defines the set $\bar{{Z}}$ as can be seen in the picture above. What I am confused about, is why we can presume that $\bar{{Z}}$ is not equal to the empty set?","Prove: is uncountable Here is an excerpt from a proof of this result that I am struggling to follow: As a part of the proof that is uncountable, my textbook defines the set as can be seen in the picture above. What I am confused about, is why we can presume that is not equal to the empty set?",\mathcal{P}(\mathbb{Z}^+) \mathcal{P}(\mathbb{Z}^+) \bar{{Z}} \bar{{Z}},"['elementary-set-theory', 'proof-explanation', 'cardinals']"
9,Show that $B \setminus A \sim B$ where $A \subseteq B$ countable and $B \setminus A$ is infinite [duplicate],Show that  where  countable and  is infinite [duplicate],B \setminus A \sim B A \subseteq B B \setminus A,"This question already has an answer here : Bijection from $A$ to $S\setminus A$, where $A$ is countably infinite (1 answer) Closed last year . Given $A\subseteq B$ such that $A$ is countable and $B\setminus A$ is infinite. I want to show that the cardinality of $B\setminus A$ is the same as the cardinality of $B$ . I know that since $B \setminus A$ is infinite, there is a function $g: \mathbb{N} \rightarrow B \setminus A$ injective. But how does this help me find a bijective function $f: B \setminus A \rightarrow B$ ?","This question already has an answer here : Bijection from $A$ to $S\setminus A$, where $A$ is countably infinite (1 answer) Closed last year . Given such that is countable and is infinite. I want to show that the cardinality of is the same as the cardinality of . I know that since is infinite, there is a function injective. But how does this help me find a bijective function ?",A\subseteq B A B\setminus A B\setminus A B B \setminus A g: \mathbb{N} \rightarrow B \setminus A f: B \setminus A \rightarrow B,"['real-analysis', 'elementary-set-theory']"
10,How to draw Venn diagram of a set containing another set?,How to draw Venn diagram of a set containing another set?,,"How can I draw Venn diagram of these two sets:- S ={5,6} T={S,1}. As T={{5,6},1} 5 and 6 aren't the elements of T. So how can I draw Venn diagram. I can't think of other way than this but then 5,6 becomes elements of T","How can I draw Venn diagram of these two sets:- S ={5,6} T={S,1}. As T={{5,6},1} 5 and 6 aren't the elements of T. So how can I draw Venn diagram. I can't think of other way than this but then 5,6 becomes elements of T",,['elementary-set-theory']
11,Arithmetic properties of cardinality of unions,Arithmetic properties of cardinality of unions,,"Given that the cardinality of a countable set $A$ equal $\mathfrak a$ , and $A$ be partitioned into singleton with elements within. Can we define the cardinality of disjoint double union with index $i\in I$ and $j\in J$ , $I, J\subset \Bbb N$ such that: $$A=\bigcup_{i=1}^{|I|}\bigcup_{j=1}^{|J|}\{a_{ij}\}$$ $$\left|\bigcup_{i=1}^{|I|}\bigcup_{j=1}^{|J|}\{a_{ij}\} \right|=\sum_{i=1}^{|I|}\sum_{j=1}^{|J|}|\{a_{ij}\}|=\sum_{i=1}^{|I|}\sum_{j=1}^{|J|}1 $$ $$=|I||J|=\mathfrak a\text{ is true?}$$ And if so, can it serve as an alternate definition of same cardinality between sets as existing a bijection? EDIT: The answer provided by @Hamdiken was satisfactory. Just to add the context of my motivation: I thought of a prove that $|\{2k:k\in\Bbb N\}|=|\{2k-1:k\in\Bbb N\}|=|\Bbb N|$ like: $$|\{2k:k\in\Bbb N\}|=\left|\lim_{n\to\infty}\bigcup_{k=1}^n\{2k\} \right| $$ $$=\lim_{n\to\infty}\left|\bigcup_{k=1}^n\{2k\} \right|=\lim_{n\to\infty}\sum_{k=1}^n|\{2k\}| $$ $$\lim_{n\to\infty}\sum_{k=1}^n 1=\lim_{n\to\infty}n=|\Bbb N|  $$ The same can be done for $\{2k-1:k\in\Bbb N\}$ . So given that for that case works, then I tried to prove with the same method that $|\Bbb Z|=|\Bbb N|$ , so i tried to define $\Bbb Z=\{k:k\in \Bbb N \}\cup\{-k:k\in \Bbb N\}\cup\{0\}$ , so: $$|\Bbb Z|=\lim_{n\to\infty}\left|\{0\}\cup\left(\bigcup_{i=1}^2\bigcup_{k=1}^n\{(-1)^ik\}\right) \right| $$ $$=\lim_{n\to\infty} 1+\left|\bigcup_{i=1}^2\bigcup_{k=1}^n\{(-1)^ik\} \right|=1+\lim_{n\to\infty}\sum_{i=1}^2\sum_{k=1}^n|\{(-1)^ik\}| $$ $$=1+\lim_{n\to\infty}\sum_{i=1}^2\sum_{k=1}^n 1=1+\lim_{n\to\infty}2n $$ $$1+2|\Bbb N| $$ and by the info in this page , $1+2|\Bbb N|=|\Bbb N| $ , and then this method would also work for $|\Bbb Q|=|\Bbb N|$ . Sadly, doesn't for for all cardinality so I don't think it serve as a proof.","Given that the cardinality of a countable set equal , and be partitioned into singleton with elements within. Can we define the cardinality of disjoint double union with index and , such that: And if so, can it serve as an alternate definition of same cardinality between sets as existing a bijection? EDIT: The answer provided by @Hamdiken was satisfactory. Just to add the context of my motivation: I thought of a prove that like: The same can be done for . So given that for that case works, then I tried to prove with the same method that , so i tried to define , so: and by the info in this page , , and then this method would also work for . Sadly, doesn't for for all cardinality so I don't think it serve as a proof.","A \mathfrak a A i\in I j\in J I, J\subset \Bbb N A=\bigcup_{i=1}^{|I|}\bigcup_{j=1}^{|J|}\{a_{ij}\} \left|\bigcup_{i=1}^{|I|}\bigcup_{j=1}^{|J|}\{a_{ij}\} \right|=\sum_{i=1}^{|I|}\sum_{j=1}^{|J|}|\{a_{ij}\}|=\sum_{i=1}^{|I|}\sum_{j=1}^{|J|}1  =|I||J|=\mathfrak a\text{ is true?} |\{2k:k\in\Bbb N\}|=|\{2k-1:k\in\Bbb N\}|=|\Bbb N| |\{2k:k\in\Bbb N\}|=\left|\lim_{n\to\infty}\bigcup_{k=1}^n\{2k\} \right|  =\lim_{n\to\infty}\left|\bigcup_{k=1}^n\{2k\} \right|=\lim_{n\to\infty}\sum_{k=1}^n|\{2k\}|  \lim_{n\to\infty}\sum_{k=1}^n 1=\lim_{n\to\infty}n=|\Bbb N|   \{2k-1:k\in\Bbb N\} |\Bbb Z|=|\Bbb N| \Bbb Z=\{k:k\in \Bbb N \}\cup\{-k:k\in \Bbb N\}\cup\{0\} |\Bbb Z|=\lim_{n\to\infty}\left|\{0\}\cup\left(\bigcup_{i=1}^2\bigcup_{k=1}^n\{(-1)^ik\}\right) \right|  =\lim_{n\to\infty} 1+\left|\bigcup_{i=1}^2\bigcup_{k=1}^n\{(-1)^ik\} \right|=1+\lim_{n\to\infty}\sum_{i=1}^2\sum_{k=1}^n|\{(-1)^ik\}|  =1+\lim_{n\to\infty}\sum_{i=1}^2\sum_{k=1}^n 1=1+\lim_{n\to\infty}2n  1+2|\Bbb N|  1+2|\Bbb N|=|\Bbb N|  |\Bbb Q|=|\Bbb N|","['elementary-set-theory', 'cardinals']"
12,Generalization of Commutativity For Unions of Sets,Generalization of Commutativity For Unions of Sets,,"In Paul Halmos' book on naïve set theory (or axiomatic set theory in a naive point of view) in the chapter about families is provided a generalization of associativity for unions of sets: $\bigcup _{i\in I_j}A_i = \bigcup_{j\in J}(\bigcup_{i\in I_j}A_i)$ such that $\{I_j\}$ is a family indexed by the index set $J$ , and $\{A_i\}$ is a family indexed by the index set $\{I_j\}$ As I believe I understood here, the number of paranthetical groups of unions of members of $\{A_i\}$ depends on the size of $\{I_j\}$ , and the number of elements in union within each paranthetical group depends on how many members are in the sets $I_j$ in the family $\{I_j\}$ . (It would be kind if someone could confirm whether my apprehension is correct) The book then challenges the reader to try and construct a generalization for the commutativity of unions of sets. The way I reasoned was as follows: commutativity refers to the fact that the union of two sets denotes the same result whether it's the first set to the second, or the second to the first; hence I could easily generalize commutativity over the union of two sets as: $(\bigcup_{i\in I_1}A_i)\bigcup$ $(\bigcup_{i\in I_2}A_i) = (\bigcup_{i\in I_2}A_i) \bigcup$ $(\bigcup_{i\in I_1}A_i)$ However, this is only generalized over two sets. And I have trouble expressing this most generally. It is requested that the reader help me complete the task so required. Thank you in advance.","In Paul Halmos' book on naïve set theory (or axiomatic set theory in a naive point of view) in the chapter about families is provided a generalization of associativity for unions of sets: such that is a family indexed by the index set , and is a family indexed by the index set As I believe I understood here, the number of paranthetical groups of unions of members of depends on the size of , and the number of elements in union within each paranthetical group depends on how many members are in the sets in the family . (It would be kind if someone could confirm whether my apprehension is correct) The book then challenges the reader to try and construct a generalization for the commutativity of unions of sets. The way I reasoned was as follows: commutativity refers to the fact that the union of two sets denotes the same result whether it's the first set to the second, or the second to the first; hence I could easily generalize commutativity over the union of two sets as: However, this is only generalized over two sets. And I have trouble expressing this most generally. It is requested that the reader help me complete the task so required. Thank you in advance.",\bigcup _{i\in I_j}A_i = \bigcup_{j\in J}(\bigcup_{i\in I_j}A_i) \{I_j\} J \{A_i\} \{I_j\} \{A_i\} \{I_j\} I_j \{I_j\} (\bigcup_{i\in I_1}A_i)\bigcup (\bigcup_{i\in I_2}A_i) = (\bigcup_{i\in I_2}A_i) \bigcup (\bigcup_{i\in I_1}A_i),['elementary-set-theory']
13,Having fun with arithmetic. Can I cover a circle with irrationals using unary operation?,Having fun with arithmetic. Can I cover a circle with irrationals using unary operation?,,"Got some time to have a fun with arithmetic, but quickly went beyond the picture I can imagine and explain to myself. Here would like to ask you what mathematical structures I deal with and if it is possible to continue my thoughts one more step further. The object I work with is a circle (like in geometry) with a ""starting"" point on it. There is an unary operation ""next"" which applies to a point and gives other ""next after starting"" point on a circle. Repeating the operation on it, gives one more ""next after next after starting"" point on a circle. After some number of iterations it loops back to a ""starting"" point. Case 1. Circumference is 17. Starting point is $0$ . Operation is increment by 1 mod 17. Repeating the operation constructs a set of integers {0..16}. Case 2. Circumference is 17. Starting point is $1$ . Operation picks next element in a somewhat reduced Stern-Brocot tree. Explanation follows. Cannot post images, I refer to this picture of Stern-Brocot tree: https://mathworld.wolfram.com/images/eps-svg/SternBrocotTree_1000.svg Reduced Stern-Brocot tree is a Stern-Brocot tree with right branches after 17 cut-off. Next element is a right neighbor on the same tree level (or leftmost one on next level). For instance, ""next after 2/3"" is 3/2 for it is on the right on the same level, while ""next after 3/1"" is 1/4. Repeating the operation, covers circle with rational numbers in a continuous range (0, 17). But I also need to loop it back to a ""starting"" point $1$ . Doubt if it makes sense, but I feel like I can go with infinite ordinal $\omega$ iterations and slightly modify the operation which picks ""next"" point in such a way, that $(\omega + n)$ th point is the same as $(n - 1)$ th point on my circle. Thus it mimics ""mod 17"" from case 1. Finally the problem. Can I define some unary operation on the circle to cover it continuously with irrational or real numbers from a range (0, 17) so that it loops back after some number of iterations?","Got some time to have a fun with arithmetic, but quickly went beyond the picture I can imagine and explain to myself. Here would like to ask you what mathematical structures I deal with and if it is possible to continue my thoughts one more step further. The object I work with is a circle (like in geometry) with a ""starting"" point on it. There is an unary operation ""next"" which applies to a point and gives other ""next after starting"" point on a circle. Repeating the operation on it, gives one more ""next after next after starting"" point on a circle. After some number of iterations it loops back to a ""starting"" point. Case 1. Circumference is 17. Starting point is . Operation is increment by 1 mod 17. Repeating the operation constructs a set of integers {0..16}. Case 2. Circumference is 17. Starting point is . Operation picks next element in a somewhat reduced Stern-Brocot tree. Explanation follows. Cannot post images, I refer to this picture of Stern-Brocot tree: https://mathworld.wolfram.com/images/eps-svg/SternBrocotTree_1000.svg Reduced Stern-Brocot tree is a Stern-Brocot tree with right branches after 17 cut-off. Next element is a right neighbor on the same tree level (or leftmost one on next level). For instance, ""next after 2/3"" is 3/2 for it is on the right on the same level, while ""next after 3/1"" is 1/4. Repeating the operation, covers circle with rational numbers in a continuous range (0, 17). But I also need to loop it back to a ""starting"" point . Doubt if it makes sense, but I feel like I can go with infinite ordinal iterations and slightly modify the operation which picks ""next"" point in such a way, that th point is the same as th point on my circle. Thus it mimics ""mod 17"" from case 1. Finally the problem. Can I define some unary operation on the circle to cover it continuously with irrational or real numbers from a range (0, 17) so that it loops back after some number of iterations?",0 1 1 \omega (\omega + n) (n - 1),['elementary-set-theory']
14,Induction and Universal Generalization,Induction and Universal Generalization,,"Let $(\mathbb N,<)$ be the set of natural numbers as defined in the book Introduction to Set Theory by Hrbacek and Jech. Suppose you are asked to show that $n<m$ implies $n+1\leq m$ for all $m,n\in\mathbb N$ . Consider the following proof : Let $P(n,m)$ denote the property that $n<m$ implies $n+1\leq m$ . Fix some arbitrary $n\in \mathbb N$ . We will show that $P(n,m)$ holds for all $m\in \mathbb N$ by induction on $m$ . $P(n,0)$ holds vacuously since $n<0$ is false. Suppose $P(n,m)$ holds for some $m\in\mathbb N$ and suppose that $n<m+1$ . Then $n\leq m$ . If $n<m$ then $n+1\leq m $ by the induction hypothesis, and if $n=m$ then $n+1=m+1$ . In either case $n+1\leq m+1$ . By the induction principle we conclude that $P(n,m)$ holds for all $m\in \mathbb N$ . As $n$ is arbitrary the conclusion follows. It seems to me that this proof is ok. However the answer here seems to suggest that it is incorrect. Am I missing something?","Let be the set of natural numbers as defined in the book Introduction to Set Theory by Hrbacek and Jech. Suppose you are asked to show that implies for all . Consider the following proof : Let denote the property that implies . Fix some arbitrary . We will show that holds for all by induction on . holds vacuously since is false. Suppose holds for some and suppose that . Then . If then by the induction hypothesis, and if then . In either case . By the induction principle we conclude that holds for all . As is arbitrary the conclusion follows. It seems to me that this proof is ok. However the answer here seems to suggest that it is incorrect. Am I missing something?","(\mathbb N,<) n<m n+1\leq m m,n\in\mathbb N P(n,m) n<m n+1\leq m n\in \mathbb N P(n,m) m\in \mathbb N m P(n,0) n<0 P(n,m) m\in\mathbb N n<m+1 n\leq m n<m n+1\leq m  n=m n+1=m+1 n+1\leq m+1 P(n,m) m\in \mathbb N n","['elementary-set-theory', 'solution-verification', 'proof-writing', 'induction']"
15,Prove that $x \in B - {\bigcap_{j \in J} A_j}$ is equivalent to $x \in \bigcup_{j \in J} B-{A_j} $,Prove that  is equivalent to,x \in B - {\bigcap_{j \in J} A_j} x \in \bigcup_{j \in J} B-{A_j} ,I have to prove that $x \in B -\{ \bigcap_{j \in J} A_j\}$ is equivalent to $x \in \bigcup_{j \in J} B-\{A_j\} $ . The first statement can be written as $x \in B$ and $x \notin\bigcap_{j \in J} A_j$ I thought what one can maybe use is deMorgan's theorem and write this as: $\neg (x\notin B$ or $x\in \bigcap_{j \in J} A_j)$ I am not sure if this is correct and if how to proceed. Hope somebody can help.,I have to prove that is equivalent to . The first statement can be written as and I thought what one can maybe use is deMorgan's theorem and write this as: or I am not sure if this is correct and if how to proceed. Hope somebody can help.,x \in B -\{ \bigcap_{j \in J} A_j\} x \in \bigcup_{j \in J} B-\{A_j\}  x \in B x \notin\bigcap_{j \in J} A_j \neg (x\notin B x\in \bigcap_{j \in J} A_j),['elementary-set-theory']
16,"13.	Let f : P ({1,2,3,4}) → {0,1,2,3,4} be the function that maps each subset S ⊆ {1,2,3,4} to its cardinality, f (S)= |S|. Is f onto or 1-1?","13.	Let f : P ({1,2,3,4}) → {0,1,2,3,4} be the function that maps each subset S ⊆ {1,2,3,4} to its cardinality, f (S)= |S|. Is f onto or 1-1?",,"After working through this, I was sure that function f was one-to-one and not onto, but according to my answer key its onto but not one-to-one. I don't exactly understand how though. Here's my thought process: Function f maps elements of P{(1, 2, 3, 4)} to the set {0, 1, 2, 3, 4} Possible subsets of P({1,2,3,4)} are: {∅,{1},{2},{3},{4},{1,2},{1,3},{1,4},{2,3},{2,4},{3,4},{1,2,3},{1,2,4},{1,3,4},{2,3,4},{1,2,3,4} = 16 total subsets, each denoted as set S. Every subset set has elements that can ALL be uniquely mapped to elements in the set {0,1,2,3,4}, but 0 in this set can never be mapped to any elements of S. So, I would think the function is one-to-one, but not onto. Can someone explain where I'm going wrong? Thanks! :D","After working through this, I was sure that function f was one-to-one and not onto, but according to my answer key its onto but not one-to-one. I don't exactly understand how though. Here's my thought process: Function f maps elements of P{(1, 2, 3, 4)} to the set {0, 1, 2, 3, 4} Possible subsets of P({1,2,3,4)} are: {∅,{1},{2},{3},{4},{1,2},{1,3},{1,4},{2,3},{2,4},{3,4},{1,2,3},{1,2,4},{1,3,4},{2,3,4},{1,2,3,4} = 16 total subsets, each denoted as set S. Every subset set has elements that can ALL be uniquely mapped to elements in the set {0,1,2,3,4}, but 0 in this set can never be mapped to any elements of S. So, I would think the function is one-to-one, but not onto. Can someone explain where I'm going wrong? Thanks! :D",,['elementary-set-theory']
17,Does the set have to be pretty explicitly given as an element of the topology?,Does the set have to be pretty explicitly given as an element of the topology?,,"So I've been trying to grasp the concept of what is and isn't a topological space recently, and it has brought me upon some questions that I'm on the fence as to whether they are topological spaces or not. Suppose for example we have: $$ \tau = \{ U \subseteq \mathbb{R}^2: \text{U is an open disc or } \emptyset \}  $$ This is extremely vague to me. If we chose $(x,y)$ tending towards infinity, we would get very close to the set $X$ being included in $\tau$ , but the fact that it's never completely within makes me want to say that it's not a topological space. I think it will also fail under the union/intersection of a number of open discs, but the main issue is in understanding whether it violates the rule that the set itself and the empty set must be elements of the topological space.","So I've been trying to grasp the concept of what is and isn't a topological space recently, and it has brought me upon some questions that I'm on the fence as to whether they are topological spaces or not. Suppose for example we have: This is extremely vague to me. If we chose tending towards infinity, we would get very close to the set being included in , but the fact that it's never completely within makes me want to say that it's not a topological space. I think it will also fail under the union/intersection of a number of open discs, but the main issue is in understanding whether it violates the rule that the set itself and the empty set must be elements of the topological space.","
\tau = \{ U \subseteq \mathbb{R}^2: \text{U is an open disc or } \emptyset \} 
 (x,y) X \tau","['general-topology', 'elementary-set-theory']"
18,Question about the exercise: Prove that $\prod A_{i}$ may be identified with the set of all choice functions for $h$,Question about the exercise: Prove that  may be identified with the set of all choice functions for,\prod A_{i} h,"For the following question: $(1):$ A cartesian product of the family $(A_i|i\in I)$ of sets is the set $$\prod_{i\in I}A_i=\{f|f:I\rightarrow\cup_{i\in I}A_i \text{with } f(i)\in A_i \text{ for each } i\in I\}$$ together with the projections $\pi_{j}:\prod_{i\in I}A_i\rightarrow A_j,$ $f\mapsto f(j)$ In the context of $(1)$ , let $h:\coprod A_{i}\rightarrow I$ be defined by $h(a,i)=i$ . Prove that $\prod A_{i}$ may be identified with the set of all choice functions for $h$ in the sense of the following exercise: Exercises: Prove that for every function $f:A\rightarrow B$ with $A$ non-empty, there exists a 'choice function' $g:B\rightarrow A$ such that $f\circ g \circ f=f$ Note: $\prod_{i\in I}A_i$ denotes the cartesian product of sets $A_i$ and $\coprod_{i\in I}A_i$ denotes the coproduct of sets $A_i$ . Can someone explain what the question is asking.  Specifically, I don't understand the phrase ""...that $\prod A_{i}$ may be identified with the set of all choice functions for $h$ ..."". Thank you in advance.","For the following question: A cartesian product of the family of sets is the set together with the projections In the context of , let be defined by . Prove that may be identified with the set of all choice functions for in the sense of the following exercise: Exercises: Prove that for every function with non-empty, there exists a 'choice function' such that Note: denotes the cartesian product of sets and denotes the coproduct of sets . Can someone explain what the question is asking.  Specifically, I don't understand the phrase ""...that may be identified with the set of all choice functions for ..."". Thank you in advance.","(1): (A_i|i\in I) \prod_{i\in I}A_i=\{f|f:I\rightarrow\cup_{i\in I}A_i \text{with } f(i)\in A_i \text{ for each } i\in I\} \pi_{j}:\prod_{i\in I}A_i\rightarrow A_j, f\mapsto f(j) (1) h:\coprod A_{i}\rightarrow I h(a,i)=i \prod A_{i} h f:A\rightarrow B A g:B\rightarrow A f\circ g \circ f=f \prod_{i\in I}A_i A_i \coprod_{i\in I}A_i A_i \prod A_{i} h",['elementary-set-theory']
19,"$\mathcal P((-1,1))$ and the set of all functions $f:\Bbb R\to\Bbb R$ which attain every value in $\Bbb Z$ uncountably many times are equinumerous?",and the set of all functions  which attain every value in  uncountably many times are equinumerous?,"\mathcal P((-1,1)) f:\Bbb R\to\Bbb R \Bbb Z","Prove that $\mathcal  P((-1,1))$ and the set of all functions $f:\Bbb R\to\Bbb R$ which attain every value in $\Bbb Z$ uncountably many times are equinumerous. My attempt: My first claim: Let $S=\{A\subseteq\Bbb R\mid A\text{ is uncountable}\}.\operatorname{card}(S)=2^{\mathfrak c}.$ $\boxed{\leq}:$ $$S\subseteq\mathcal P(\Bbb R)\implies\operatorname{card}(S)\le\operatorname{card}(\mathcal P(\Bbb R))=2^{\mathfrak c}.$$ $\boxed{\geq}:$ Let $\Phi:\mathcal P((-1,1))\to S,$ $$\Phi: A\mapsto A\cup B, B=\Bbb R\setminus((-1,1)\cup\Bbb Q).$$ We see $A\cap B=\emptyset,\forall A\in\mathcal P((-1,1)),$ therefore $$\Phi(A_1)=\Phi(A_2)\implies A_1\cup B=A_2\cup B\implies A_1=A_2,$$ so $\Phi$ is injective. $\implies 2^{\mathfrak c}=\operatorname{card}(\mathcal P((-1,1))\le\operatorname{card}(S).$ Therefore, $\operatorname{card}(S)=2^{\mathfrak c}.$ Let $T:=\{f:\Bbb R\to\Bbb R\mid f^{-1}(n)\text{ is uncountable },\forall n\in\Bbb Z\}.$ $\boxed{\leq }:$ $$T\subseteq \{f:\Bbb R\to\Bbb R\}\implies \operatorname{card}(T)\le 2^{\mathfrak c}.$$ $\boxed{\geq }:$ Let $S_{\Bbb Z}=\{A\in S\mid\ A\cap (n,n+1)\text{ is uncountable },\forall n\in\Bbb Z\}.$ Let $\Psi: S_{\Bbb Z}\to T, \Psi:A\mapsto \Psi_A,$ $$\Psi_A(x)=\begin{cases}n, &x\in A\cap (n,n+1)\\ 0,& \text{otherwise}\end{cases}$$ I think $\Psi$ is well-defined because $\operatorname{card}(\Psi^{-1}_A(n))=\operatorname{card}(A\cap (n,n+1))=\mathfrak c,\forall n\in\Bbb Z,\forall A\in S_{\Bbb Z}.$ We can write each $A\in S_{\Bbb Z}$ in a unique way as $$A=\bigcup_{n\in\Bbb Z}\underbrace{A\cap (n,n+1)}_{:=A^{(n)}}.$$ For $A_1,A_2\in S_{\Bbb Z}, A_1\ne A_2,\Psi_{A_1}$ and $\Psi_{A_2}$ must differ for some $x$ because $\exists n\in\Bbb Z, A_1^{(n)}\ne A_2^{(n)}.$ So, I believe, $\Psi$ is injective and hence $$\operatorname{card}\left(S_{\Bbb Z}\right)\le\operatorname{card}(T).$$ I think $\operatorname{card}\left(S_{\Bbb Z}\right)=2^{\mathfrak c}$ because we might similiarly prove that the set $S_n$ of all uncountable subsets of $(n,n+1)$ is also of the cardinality $2^{\mathfrak c},$ each $A\in  S_{\Bbb Z}$ is of the form $$A=\bigcup_{n\in\Bbb Z}A^{(n)}, A^{(n)}\in S_n,n\in\Bbb Z$$ and $$\operatorname{card}\left(S_{\Bbb Z}\right)=\operatorname{card}\left(\displaystyle\prod_{n\in\Bbb Z} S_n\right)=\left(2^{\mathfrak c}\right)^{\aleph_0}=2^{\mathfrak c\cdot\aleph_0}=2^{\mathfrak c}$$ because $$\mathfrak c\cdot 1\le\mathfrak c\cdot\aleph_0\le\mathfrak c\cdot\mathfrak c=\mathfrak c.$$ So, $2^{\mathfrak c}\le\operatorname{card}(T).$ And finally, $\operatorname{card}(T)=2^{\mathfrak c}.$ On the other hand, $$\operatorname{card}(\mathcal P((-1,1)))=2^{\operatorname{card}((-1,1))}=2^{\mathfrak c}.$$ Are my conclusion and final answers valid? Also, is there any other way of proving this?","Prove that and the set of all functions which attain every value in uncountably many times are equinumerous. My attempt: My first claim: Let Let We see therefore so is injective. Therefore, Let Let Let I think is well-defined because We can write each in a unique way as For and must differ for some because So, I believe, is injective and hence I think because we might similiarly prove that the set of all uncountable subsets of is also of the cardinality each is of the form and because So, And finally, On the other hand, Are my conclusion and final answers valid? Also, is there any other way of proving this?","\mathcal  P((-1,1)) f:\Bbb R\to\Bbb R \Bbb Z S=\{A\subseteq\Bbb R\mid A\text{ is uncountable}\}.\operatorname{card}(S)=2^{\mathfrak c}. \boxed{\leq}: S\subseteq\mathcal P(\Bbb R)\implies\operatorname{card}(S)\le\operatorname{card}(\mathcal P(\Bbb R))=2^{\mathfrak c}. \boxed{\geq}: \Phi:\mathcal P((-1,1))\to S, \Phi: A\mapsto A\cup B, B=\Bbb R\setminus((-1,1)\cup\Bbb Q). A\cap B=\emptyset,\forall A\in\mathcal P((-1,1)), \Phi(A_1)=\Phi(A_2)\implies A_1\cup B=A_2\cup B\implies A_1=A_2, \Phi \implies 2^{\mathfrak c}=\operatorname{card}(\mathcal P((-1,1))\le\operatorname{card}(S). \operatorname{card}(S)=2^{\mathfrak c}. T:=\{f:\Bbb R\to\Bbb R\mid f^{-1}(n)\text{ is uncountable },\forall n\in\Bbb Z\}. \boxed{\leq }: T\subseteq \{f:\Bbb R\to\Bbb R\}\implies \operatorname{card}(T)\le 2^{\mathfrak c}. \boxed{\geq }: S_{\Bbb Z}=\{A\in S\mid\ A\cap (n,n+1)\text{ is uncountable },\forall n\in\Bbb Z\}. \Psi: S_{\Bbb Z}\to T, \Psi:A\mapsto \Psi_A, \Psi_A(x)=\begin{cases}n, &x\in A\cap (n,n+1)\\ 0,& \text{otherwise}\end{cases} \Psi \operatorname{card}(\Psi^{-1}_A(n))=\operatorname{card}(A\cap (n,n+1))=\mathfrak c,\forall n\in\Bbb Z,\forall A\in S_{\Bbb Z}. A\in S_{\Bbb Z} A=\bigcup_{n\in\Bbb Z}\underbrace{A\cap (n,n+1)}_{:=A^{(n)}}. A_1,A_2\in S_{\Bbb Z}, A_1\ne A_2,\Psi_{A_1} \Psi_{A_2} x \exists n\in\Bbb Z, A_1^{(n)}\ne A_2^{(n)}. \Psi \operatorname{card}\left(S_{\Bbb Z}\right)\le\operatorname{card}(T). \operatorname{card}\left(S_{\Bbb Z}\right)=2^{\mathfrak c} S_n (n,n+1) 2^{\mathfrak c}, A\in  S_{\Bbb Z} A=\bigcup_{n\in\Bbb Z}A^{(n)}, A^{(n)}\in S_n,n\in\Bbb Z \operatorname{card}\left(S_{\Bbb Z}\right)=\operatorname{card}\left(\displaystyle\prod_{n\in\Bbb Z} S_n\right)=\left(2^{\mathfrak c}\right)^{\aleph_0}=2^{\mathfrak c\cdot\aleph_0}=2^{\mathfrak c} \mathfrak c\cdot 1\le\mathfrak c\cdot\aleph_0\le\mathfrak c\cdot\mathfrak c=\mathfrak c. 2^{\mathfrak c}\le\operatorname{card}(T). \operatorname{card}(T)=2^{\mathfrak c}. \operatorname{card}(\mathcal P((-1,1)))=2^{\operatorname{card}((-1,1))}=2^{\mathfrak c}.","['elementary-set-theory', 'solution-verification', 'proof-writing']"
20,Attempting to prove $(A\setminus B) × (C\setminus D) = (A × C) \setminus [(A × D) ∪ (B × C)]$.,Attempting to prove .,(A\setminus B) × (C\setminus D) = (A × C) \setminus [(A × D) ∪ (B × C)],"I am trying to prove the following equality where A, B, C and D are sets. (A \ B) × (C \ D) = (A × C) \ [(A × D) ∪ (B × C)] x stands for the cartesian product. As I am trying to prove via inclusion equality this is my attempt so far, I am trying to construct the forward implication but I am not sure how. I understand that to prove set equality you must prove one set is a subset of the other and vice versa but this question has me stumped. Find below my thought process so far and thanks in advance for your help! Foward Implication: (A \ B) × (C \ D) ⊆ (A × C) \ [(A × D) ∪ (B × C)] (A \ B) × (C \ D) = (A\C) Reverse Implication: (A × C) \ [(A × D) ∪ (B × C)] ⊆ (A \ B) × (C \ D) I am unsure how to progress from here any help would be highly appreciated!","I am trying to prove the following equality where A, B, C and D are sets. (A \ B) × (C \ D) = (A × C) \ [(A × D) ∪ (B × C)] x stands for the cartesian product. As I am trying to prove via inclusion equality this is my attempt so far, I am trying to construct the forward implication but I am not sure how. I understand that to prove set equality you must prove one set is a subset of the other and vice versa but this question has me stumped. Find below my thought process so far and thanks in advance for your help! Foward Implication: (A \ B) × (C \ D) ⊆ (A × C) \ [(A × D) ∪ (B × C)] (A \ B) × (C \ D) = (A\C) Reverse Implication: (A × C) \ [(A × D) ∪ (B × C)] ⊆ (A \ B) × (C \ D) I am unsure how to progress from here any help would be highly appreciated!",,['elementary-set-theory']
21,Efficient way to verify if pair of numbers are medians of partition of sets,Efficient way to verify if pair of numbers are medians of partition of sets,,"Given a multi-set of multi-sets $\mathcal{S} = \{S_1, \ldots,S_i, \ldots, S_n \}, S_i \subset \mathbb{R}$ . Denote powerset of $\mathcal{S}$ as $\mathbb{P}(\mathcal{S})$ . My question is, given a pair $(x, y) \in \mathbb{R}^2$ , how can one efficiently verify $\exists P \in \mathbb{P}(\mathcal{S})$ such that, $\textbf{median}(\cup_{I \in P} I) = x$ and $\textbf{median}(\cup_{J \in \mathcal{S} \setminus P} J) = y$ ?","Given a multi-set of multi-sets . Denote powerset of as . My question is, given a pair , how can one efficiently verify such that, and ?","\mathcal{S} = \{S_1, \ldots,S_i, \ldots, S_n \}, S_i \subset \mathbb{R} \mathcal{S} \mathbb{P}(\mathcal{S}) (x, y) \in \mathbb{R}^2 \exists P \in \mathbb{P}(\mathcal{S}) \textbf{median}(\cup_{I \in P} I) = x \textbf{median}(\cup_{J \in \mathcal{S} \setminus P} J) = y","['elementary-set-theory', 'computational-complexity', 'median']"
22,Venn Diagram for Power Set,Venn Diagram for Power Set,,"I was wondering what the Venn Diagram for a power set might look like. For example for $\{A, B, C\}$ . I'm going to go out on a limb and say it's probably not this: However, that image is useful for picturing all the subsets, minus the empty set. Yet from my understanding it shows relationships between 3 sets, rather than within a power set. Can anyone shed some light on this please?","I was wondering what the Venn Diagram for a power set might look like. For example for . I'm going to go out on a limb and say it's probably not this: However, that image is useful for picturing all the subsets, minus the empty set. Yet from my understanding it shows relationships between 3 sets, rather than within a power set. Can anyone shed some light on this please?","\{A, B, C\}",['elementary-set-theory']
23,Proof by induction for infinite unions/intersections,Proof by induction for infinite unions/intersections,,"Say I want to prove the following statement: The union of a countable collection of countable sets is countable. Imagine I wrote a proof that went something like this: let $E$ be a collection of countable sets, that I can index $E=\{E_1, E_2,...\}$ with the natural numbers, and show for all $n \in \mathbb{N}$ , $\bigcup_{i<n}E_i$ is countable. I understand that this is an invalid argument. The argument above only shows for all finite collections, as we never show $P(n) \implies P(\infty)$ ; that is, we never actually consider the entire collection of sets. Now, consider a different problem. Say I want to prove the Nested Intervals Theorem( https://math.gmu.edu/~dsingman/315/sect1.6nounc.pdf ). The infinite intersection of sets is defined as $\bigcap^\infty E_i=\{ a: a\in E_i \hspace{.2cm}\forall i \in \mathbb{N}\}$ . I believe that an induction argument does work here. If I prove that there is some real number $a$ such that for all $n \in \mathbb{N}$ we have $a \in \bigcap^n_1 E_i$ , then I think that I prove $a \in \bigcap^\infty E_i$ . I think the above works because this argument: assume $a \not \in \bigcap^\infty E_i$ , then $\{i \in \mathbb{N}: a \not \in E_i \} \not = \emptyset$ . let $k$ be the least such element of this set. then, $a \not \in E_k$ but $a \in E_{k-1}$ which contradicts the proof by induction . Of course I have searched through related post. I remain unsatisfied. The best answers on this post, for example, does not agree with me: How is an induction 'proof ' of 'The principle of nested closed intervals' different that the standard proof? . Are there any errors in my thinking?","Say I want to prove the following statement: The union of a countable collection of countable sets is countable. Imagine I wrote a proof that went something like this: let be a collection of countable sets, that I can index with the natural numbers, and show for all , is countable. I understand that this is an invalid argument. The argument above only shows for all finite collections, as we never show ; that is, we never actually consider the entire collection of sets. Now, consider a different problem. Say I want to prove the Nested Intervals Theorem( https://math.gmu.edu/~dsingman/315/sect1.6nounc.pdf ). The infinite intersection of sets is defined as . I believe that an induction argument does work here. If I prove that there is some real number such that for all we have , then I think that I prove . I think the above works because this argument: assume , then . let be the least such element of this set. then, but which contradicts the proof by induction . Of course I have searched through related post. I remain unsatisfied. The best answers on this post, for example, does not agree with me: How is an induction 'proof ' of 'The principle of nested closed intervals' different that the standard proof? . Are there any errors in my thinking?","E E=\{E_1, E_2,...\} n \in \mathbb{N} \bigcup_{i<n}E_i P(n) \implies P(\infty) \bigcap^\infty E_i=\{ a: a\in E_i \hspace{.2cm}\forall i \in \mathbb{N}\} a n \in \mathbb{N} a \in \bigcap^n_1 E_i a \in \bigcap^\infty E_i a \not \in \bigcap^\infty E_i \{i \in \mathbb{N}: a \not \in E_i \} \not = \emptyset k a \not \in E_k a \in E_{k-1}","['real-analysis', 'elementary-set-theory', 'proof-explanation', 'induction']"
24,Is this an easy generalization of the Hahn-Banach separation Theorem?,Is this an easy generalization of the Hahn-Banach separation Theorem?,,"The Hahn-Banach theorem goes like If $p:X\to\mathbb R$ is sublinear and $f$ is a linear functional on a subspace $Y\subseteq X$ bounded by $p$ (on $Y$ ), then there is an extension of $f$ to $X$ that is bounded by $p$ and matches with $f$ on $Y$ . I am trying to do something similar, let $\psi:X\to2^\mathbb R$ be such that for any $x\in X$ , $\psi(x)$ is a non empty-closed interval for any $x\in X$ , $a\in \mathbb R$ , $\psi(ax)=a\psi(x)$ for any $x,y\in X$ , $\psi(x+y)\subseteq \psi(x)+\psi(y)$ One can check that $x\to \sup \psi(x)$ and $x\to -\inf \psi(x)$ are both sublinear functions (over the extended real line). I want to know if the following holds : If $f$ is a linear function on a subspace $Y\subseteq X$ such that $f(x)\in\psi(x)$ for any $x\in Y$ , then there is an extension of $f$ to $X$ such that $f(x)\in\psi(x)$ for all $x\in X$ . In a sense this is a version of Hahn-Banach where the function is sandwiched between a sublinear and a (forgive the abuse of word) superlinear function. I have never seen anything like that, but I have this feeling that Hahn Banach is actually already enough to show that, I was thinking of using $p(x)=\sup \psi(x)-\inf\psi(x)$ as a semi-norm but it is hard for me to find a new $f'$ that is less than $p$ that would correspond one to one to $f$ in some way. Any thought is welcome. For the context I am trying to make progress on this question , however I think this new question has independent interest, the formulation is pleasant to me.","The Hahn-Banach theorem goes like If is sublinear and is a linear functional on a subspace bounded by (on ), then there is an extension of to that is bounded by and matches with on . I am trying to do something similar, let be such that for any , is a non empty-closed interval for any , , for any , One can check that and are both sublinear functions (over the extended real line). I want to know if the following holds : If is a linear function on a subspace such that for any , then there is an extension of to such that for all . In a sense this is a version of Hahn-Banach where the function is sandwiched between a sublinear and a (forgive the abuse of word) superlinear function. I have never seen anything like that, but I have this feeling that Hahn Banach is actually already enough to show that, I was thinking of using as a semi-norm but it is hard for me to find a new that is less than that would correspond one to one to in some way. Any thought is welcome. For the context I am trying to make progress on this question , however I think this new question has independent interest, the formulation is pleasant to me.","p:X\to\mathbb R f Y\subseteq X p Y f X p f Y \psi:X\to2^\mathbb R x\in X \psi(x) x\in X a\in \mathbb R \psi(ax)=a\psi(x) x,y\in X \psi(x+y)\subseteq \psi(x)+\psi(y) x\to \sup \psi(x) x\to -\inf \psi(x) f Y\subseteq X f(x)\in\psi(x) x\in Y f X f(x)\in\psi(x) x\in X p(x)=\sup \psi(x)-\inf\psi(x) f' p f","['linear-algebra', 'elementary-set-theory', 'convex-analysis', 'hahn-banach-theorem']"
25,Help with proving existence of a certain set using Zorn's lemma,Help with proving existence of a certain set using Zorn's lemma,,"As part of my homework I need to prove, using Zorn's lemma, that there exists a set $A \subseteq [0,1)$ so that for every real number $r \in \mathbb{R}$ , there exists a single element $a \in A$ that satisfies $r-a \in \mathbb{Q}$ . Here's what I've tried: first I defined a weak partial order $\prec$ that satisfies $A \prec B \iff B \subseteq A$ . Then I defined a set $Q = \{A \subseteq [0,1) \mid \forall r \in \mathbb{R}~ \exists a \in A. r-a \in \mathbb{Q}\}$ , proved it's not equal to $\emptyset$ , and tried to find an upper bound for every chain $C \subseteq Q$ . Here's where I got stuck. I thought $\cap C$ would work as an upper bound for every chain $C$ , and I've managed to prove $\forall c \in C. c \prec \cap C$ . The problem is I can't prove that $\cap C \in Q$ , that is, for every $r \in \mathbb{R}$ exists $a \in \cap C$ so that $r-a \in \mathbb{Q}$ . It seems to me that the way I defined the order, $\cap C$ should be inside $C$ , but I can't prove that either. Anyways, any help will be appreciated. Thanks in advance!","As part of my homework I need to prove, using Zorn's lemma, that there exists a set so that for every real number , there exists a single element that satisfies . Here's what I've tried: first I defined a weak partial order that satisfies . Then I defined a set , proved it's not equal to , and tried to find an upper bound for every chain . Here's where I got stuck. I thought would work as an upper bound for every chain , and I've managed to prove . The problem is I can't prove that , that is, for every exists so that . It seems to me that the way I defined the order, should be inside , but I can't prove that either. Anyways, any help will be appreciated. Thanks in advance!","A \subseteq [0,1) r \in \mathbb{R} a \in A r-a \in \mathbb{Q} \prec A \prec B \iff B \subseteq A Q = \{A \subseteq [0,1) \mid \forall r \in \mathbb{R}~ \exists a \in A. r-a \in \mathbb{Q}\} \emptyset C \subseteq Q \cap C C \forall c \in C. c \prec \cap C \cap C \in Q r \in \mathbb{R} a \in \cap C r-a \in \mathbb{Q} \cap C C",['elementary-set-theory']
26,"Solution verification: Show that $a_1 <_{(-1,1)} a_2\implies f(a_1)<_{\mathbb{R}} < f(a_2)$ to prove $(-1,1)$ has the same order type as $\mathbb{R}$",Solution verification: Show that  to prove  has the same order type as,"a_1 <_{(-1,1)} a_2\implies f(a_1)<_{\mathbb{R}} < f(a_2) (-1,1) \mathbb{R}","I want to show that $(-1,1)$ and $\mathbb{R}$ have the same order type by showing that there exists a bijective correspondence $f : (-1,1) \to \mathbb{R}$ such that $$a_1 <_{(-1,1)} a_2\implies f(a_1)<_{\mathbb{R}} < f(a_2).$$ Let $f : (-1,1) \to \mathbb{R}$ be defined by $f(x) = \dfrac{x}{1 - x^2}$ . We begin by showing $f$ is injective: let $x_1, x_2 \in (-1,1)$ such that $f(x_1) = f(x_2)$ . Using elementary algebra, we find that $(x_1 - x_2)(1 + x_1x_2) = 0$ , which implies $x_1 = x_2$ or $1 + x_1x_2 = 0$ . If the former, then we are done. If the latter, then note that $x_1 \neq x_2$ , but if $x_1 = 0$ then $1 + 0x_2 = 1 \neq 0$ , which is a contradiction. Therefore, $x_1 = x_2$ , and so $f$ is injective. We will now show that $f$ is surjective. We believe the simplest way to do so is to show that $\exists g : \mathbb{R} \to (-1,1)$ such that $f \circ g = I_\mathbb{R}$ . That is, $$\frac{g(x)}{1 - (g(x))^2} = x,$$ and using elementary algebra we find that $$g(x) = \frac{-1 -\sqrt{4x^2 + 1}}{2x} \quad\text{for }x \neq 0.$$ We then define $g(0) = 0$ and we have that $\forall x \in \mathbb{R}, f(g(x)) = x$ , which implies $f$ is surjective. Therefore, $f$ is bijective. Now we let $a_1, a_2 \in (-1,1)$ such that $a_1 <_{(-1,1)} a_2$ . Since $f$ is bijective, $f(a_1) \neq f(a_2)$ , so $f(a_1) < f(a_2)$ or $f(a_2) < f(a_1)$ . If the former, then we are done. If the latter, then note that $f$ is strictly increasing $(-1,1)$ , which is a therefore a contradiction, so we are done. Remark: I tried not to use theorems from real analysis to prove the bijectivity of $f$ , instead I used first principles as defined in Munkres, however I wasn't sure how to get a contradiction without using that $f$ is increasing.","I want to show that and have the same order type by showing that there exists a bijective correspondence such that Let be defined by . We begin by showing is injective: let such that . Using elementary algebra, we find that , which implies or . If the former, then we are done. If the latter, then note that , but if then , which is a contradiction. Therefore, , and so is injective. We will now show that is surjective. We believe the simplest way to do so is to show that such that . That is, and using elementary algebra we find that We then define and we have that , which implies is surjective. Therefore, is bijective. Now we let such that . Since is bijective, , so or . If the former, then we are done. If the latter, then note that is strictly increasing , which is a therefore a contradiction, so we are done. Remark: I tried not to use theorems from real analysis to prove the bijectivity of , instead I used first principles as defined in Munkres, however I wasn't sure how to get a contradiction without using that is increasing.","(-1,1) \mathbb{R} f : (-1,1) \to \mathbb{R} a_1 <_{(-1,1)} a_2\implies f(a_1)<_{\mathbb{R}} < f(a_2). f : (-1,1) \to \mathbb{R} f(x) = \dfrac{x}{1 - x^2} f x_1, x_2 \in (-1,1) f(x_1) = f(x_2) (x_1 - x_2)(1 + x_1x_2) = 0 x_1 = x_2 1 + x_1x_2 = 0 x_1 \neq x_2 x_1 = 0 1 + 0x_2 = 1 \neq 0 x_1 = x_2 f f \exists g : \mathbb{R} \to (-1,1) f \circ g = I_\mathbb{R} \frac{g(x)}{1 - (g(x))^2} = x, g(x) = \frac{-1 -\sqrt{4x^2 + 1}}{2x} \quad\text{for }x \neq 0. g(0) = 0 \forall x \in \mathbb{R}, f(g(x)) = x f f a_1, a_2 \in (-1,1) a_1 <_{(-1,1)} a_2 f f(a_1) \neq f(a_2) f(a_1) < f(a_2) f(a_2) < f(a_1) f (-1,1) f f","['general-topology', 'elementary-set-theory', 'solution-verification', 'order-theory']"
27,limit of limit of sets is a limit of sets,limit of limit of sets is a limit of sets,,"Let $\mathcal A$ be a collecction of subsets of some set $A$ . Whenever $\{ X_n\}_{n\in\mathbb N}$ is a sequence of sets such that $\liminf_n X_n \triangleq \bigcup_{n\geq 1}\bigcap_{m\geq n} X_m$ and $\limsup_n X_n \triangleq \bigcap_{n\geq 1}\bigcup_{m\geq n} X_m$ are both equal to some set $X$ then we say that $\lim_n X_n$ exists and equal $X$ . Suppose we have a sequence of sets $\{ X_{n,k} \}_{n,k\in\mathbb N}$ in $\mathcal A$ such that for all $n$ , $\lim_n X_{n,k}=X_n$ for some $X_n$ (that may not be in $\mathcal A$ ) and suppose that $\lim_n X_n = X$ for some $X$ . I want to prove (or disprove) the following There is a sequence of sets $\{ Y_n \}_{n\in\mathbb N}$ in $\mathcal A$ such that $\lim_n Y_n=X$ . My attempt uses a bijective mapping $\phi:\mathbb N\to\mathbb N^2$ and the sequence of sets $Y_n=X_{\phi(n)}$ , it feels that this might do the trick but I can't quite finish the argument. It would be enough to show that $\liminf_n X_n\subseteq \liminf_n Y_n$ and $\limsup_n Y_n\subseteq \limsup_n X_n$ , proving those two should be very similar so let's focus on the first one. \begin{align*} \bigcup_{n\geq1}\bigcap_{m\geq n} \bigcup_{k\geq1}\bigcap_{\ell\geq k} X_{m,\ell}\subseteq \bigcup_{n\geq1}\bigcap_{m\geq n} X_{\phi(m)} \end{align*} here it feels like we would like to swap the two middle intersection and union but this would result in the other inclusion. I am not sure what kind of condition ensures that we can do the swapping or if this idea is even a good one in the first place. Any idea is most welcome. An equivalent formulation using characteristic functions : it is known that $\lim_n X_n=X$ if and only if $\psi_{X_n}$ converges to $\psi_X$ point-wise. From $\mathcal A$ we can get $\mathcal F=\{ \psi_X : X \in\mathcal A\}$ which is a set of $\{0,1\}$ valued functions. Consider $\overline{\mathcal F}=\{ \psi : \psi = \lim_n \psi_n, \psi_n\in\mathcal F \}$ the sequential closure of $\mathcal F$ . What I am trying to prove is essentially that $\overline{\overline{\mathcal F}}=\overline{\mathcal F}$ .","Let be a collecction of subsets of some set . Whenever is a sequence of sets such that and are both equal to some set then we say that exists and equal . Suppose we have a sequence of sets in such that for all , for some (that may not be in ) and suppose that for some . I want to prove (or disprove) the following There is a sequence of sets in such that . My attempt uses a bijective mapping and the sequence of sets , it feels that this might do the trick but I can't quite finish the argument. It would be enough to show that and , proving those two should be very similar so let's focus on the first one. here it feels like we would like to swap the two middle intersection and union but this would result in the other inclusion. I am not sure what kind of condition ensures that we can do the swapping or if this idea is even a good one in the first place. Any idea is most welcome. An equivalent formulation using characteristic functions : it is known that if and only if converges to point-wise. From we can get which is a set of valued functions. Consider the sequential closure of . What I am trying to prove is essentially that .","\mathcal A A \{ X_n\}_{n\in\mathbb N} \liminf_n X_n \triangleq \bigcup_{n\geq 1}\bigcap_{m\geq n} X_m \limsup_n X_n \triangleq \bigcap_{n\geq 1}\bigcup_{m\geq n} X_m X \lim_n X_n X \{ X_{n,k} \}_{n,k\in\mathbb N} \mathcal A n \lim_n X_{n,k}=X_n X_n \mathcal A \lim_n X_n = X X \{ Y_n \}_{n\in\mathbb N} \mathcal A \lim_n Y_n=X \phi:\mathbb N\to\mathbb N^2 Y_n=X_{\phi(n)} \liminf_n X_n\subseteq \liminf_n Y_n \limsup_n Y_n\subseteq \limsup_n X_n \begin{align*}
\bigcup_{n\geq1}\bigcap_{m\geq n} \bigcup_{k\geq1}\bigcap_{\ell\geq k} X_{m,\ell}\subseteq \bigcup_{n\geq1}\bigcap_{m\geq n} X_{\phi(m)}
\end{align*} \lim_n X_n=X \psi_{X_n} \psi_X \mathcal A \mathcal F=\{ \psi_X : X \in\mathcal A\} \{0,1\} \overline{\mathcal F}=\{ \psi : \psi = \lim_n \psi_n, \psi_n\in\mathcal F \} \mathcal F \overline{\overline{\mathcal F}}=\overline{\mathcal F}","['limits', 'elementary-set-theory', 'order-theory', 'limsup-and-liminf']"
28,"Given n objects shared by several sets of known sizes, what is the minimum number of objects shared by all the sets?","Given n objects shared by several sets of known sizes, what is the minimum number of objects shared by all the sets?",,"Here is what seems to be an easy case.  Suppose there are 13 objects and 3 sets A, B, and C of size 9 sharing those objects.  Set A can have any 9 of the objects.  Set B can have at most 4 objects not in A, so A and B share at least 5 objects.  Set C must share at least 5 objects with A and 5 objects with B. C can only have 9 objects, so it must share at least one of them with both A and B.  Is this reasoning correct? How can the general case of such a problem be solved?  You know the size of the union of all sets of objects and the sizes of  each set.  How can you determine the minimum size for the intersection of all the sets?","Here is what seems to be an easy case.  Suppose there are 13 objects and 3 sets A, B, and C of size 9 sharing those objects.  Set A can have any 9 of the objects.  Set B can have at most 4 objects not in A, so A and B share at least 5 objects.  Set C must share at least 5 objects with A and 5 objects with B. C can only have 9 objects, so it must share at least one of them with both A and B.  Is this reasoning correct? How can the general case of such a problem be solved?  You know the size of the union of all sets of objects and the sizes of  each set.  How can you determine the minimum size for the intersection of all the sets?",,"['combinatorics', 'elementary-set-theory', 'discrete-optimization', 'extremal-combinatorics']"
29,Proof of $(x\subseteq y)\leftrightarrow(x\cap y =x)\leftrightarrow(x\cup y=y)$,Proof of,(x\subseteq y)\leftrightarrow(x\cap y =x)\leftrightarrow(x\cup y=y),"Exercise 1.2.1(vii) from Page 5 of Keith Devlin's ""The Joy of Sets"": Prove the following assertion directly from the definitions. The drawing of ""Venn diagrams"" is forbidden; this is an exercise in the manipulation of logical formalisms. $$(x\subseteq y)\leftrightarrow(x\cap y =x)\leftrightarrow(x\cup y=y)$$ Attempt at solution : This is not a difficult claim to understand or prove in terms of sets, but I can't figure out the pure logical formalism. I guess I should break this into seven individual implications? $\forall w(w\in x\rightarrow w\in y)\rightarrow \forall z(z\in x\rightarrow (z\in x\enspace\wedge\enspace z\in y)) $ $\forall w(w\in x\rightarrow w\in y)\rightarrow \forall z((z\in x\enspace\wedge\enspace z\in y)\rightarrow z\in x))$ $\forall z(z\in x\rightarrow(z\in x \enspace\wedge\enspace z\in y))\rightarrow \forall w(w\in x\rightarrow w\in y)$ $\forall z(z\in x\rightarrow(z\in x \enspace\wedge\enspace z\in y))\rightarrow \forall w((w \in x \enspace\lor\enspace w\in y)\rightarrow w\in y)$ $\forall z(z\in x\rightarrow(z\in x \enspace\wedge\enspace z\in y))\rightarrow \forall w(w\in y\rightarrow(w \in x \enspace\lor\enspace w\in y))$ $\forall w((w\in x\enspace\lor\enspace w\in y)\rightarrow w\in y)\rightarrow\forall z((z\in x \enspace\wedge\enspace z\in y)\rightarrow z\in x)$ $\forall w((w\in x\enspace\lor\enspace w\in y)\rightarrow w\in y)\rightarrow\forall z(z\in x \rightarrow (z\in x \enspace\wedge\enspace z\in y))$ In addition to wondering if I'm doing this correctly, I also feel like I gained nothing from writing out these implications.","Exercise 1.2.1(vii) from Page 5 of Keith Devlin's ""The Joy of Sets"": Prove the following assertion directly from the definitions. The drawing of ""Venn diagrams"" is forbidden; this is an exercise in the manipulation of logical formalisms. Attempt at solution : This is not a difficult claim to understand or prove in terms of sets, but I can't figure out the pure logical formalism. I guess I should break this into seven individual implications? In addition to wondering if I'm doing this correctly, I also feel like I gained nothing from writing out these implications.","(x\subseteq y)\leftrightarrow(x\cap y =x)\leftrightarrow(x\cup y=y) \forall w(w\in x\rightarrow w\in y)\rightarrow \forall z(z\in x\rightarrow (z\in x\enspace\wedge\enspace z\in y))  \forall w(w\in x\rightarrow w\in y)\rightarrow \forall z((z\in x\enspace\wedge\enspace z\in y)\rightarrow z\in x)) \forall z(z\in x\rightarrow(z\in x \enspace\wedge\enspace z\in y))\rightarrow \forall w(w\in x\rightarrow w\in y) \forall z(z\in x\rightarrow(z\in x \enspace\wedge\enspace z\in y))\rightarrow \forall w((w
\in x \enspace\lor\enspace w\in y)\rightarrow w\in y) \forall z(z\in x\rightarrow(z\in x \enspace\wedge\enspace z\in y))\rightarrow \forall w(w\in y\rightarrow(w
\in x \enspace\lor\enspace w\in y)) \forall w((w\in x\enspace\lor\enspace w\in y)\rightarrow w\in y)\rightarrow\forall z((z\in x \enspace\wedge\enspace z\in y)\rightarrow z\in x) \forall w((w\in x\enspace\lor\enspace w\in y)\rightarrow w\in y)\rightarrow\forall z(z\in x \rightarrow (z\in x \enspace\wedge\enspace z\in y))","['elementary-set-theory', 'logic', 'first-order-logic']"
30,Prove that $Y$ is the closure of some open set if and only if $Y$ is the closure of its interior.,Prove that  is the closure of some open set if and only if  is the closure of its interior.,Y Y,"Prove that $Y$ is the closure of some open set if and only if $Y$ is the closure of its interior. $\implies: $ Let $Y=\overline Z$ for some open set $Z$ . Then $Y$ is the smallest closed set containing $Z$ . Since $\mathring Y$ is the largest open set contained in $Y$ , therefore $Z\subseteq \mathring Y$ . However, since $\overline{\mathring Y}$ is the smallest closed set containing $\mathring Y$ , we have that $\overline{\mathring Y} \subseteq Y$ , but being that $Y$ is the smallest closed set containing $Z$ it is also the case that $Y\subseteq \overline{\mathring Y}$ and hence $Y= \overline{\mathring Y}$ . $\Longleftarrow:$ Assume that $Y=\overline{\mathring Y}$ . Since $\mathring Y$ is the largest open set contained in $Y$ , for any other open set $Z$ in $Y$ we must have that $Z\subseteq \mathring Y$ . And since $\overline Z$ is the smallest closed set containing $Z$ , we have $\overline Z \subseteq \overline{\mathring Y}$ . However, since $\overline{\mathring Y}$ is the smallest closed set containing $\mathring Y$ , it is also true that $\overline{\mathring Y} \subseteq \overline Z$ , so $\overline Z = \overline{\mathring Y}=Y$ . $\Box$ Is this correct, and can this be simplified at all? The two directions seem largely similar in reasoning. This problem confused me for a while since it was basically equivalent to saying, ""Y is the smallest closed set containing an open set Z if and only if Y is the smallest closed set containing the largest open set contained in Y"" which was hard for me to parse at first.","Prove that is the closure of some open set if and only if is the closure of its interior. Let for some open set . Then is the smallest closed set containing . Since is the largest open set contained in , therefore . However, since is the smallest closed set containing , we have that , but being that is the smallest closed set containing it is also the case that and hence . Assume that . Since is the largest open set contained in , for any other open set in we must have that . And since is the smallest closed set containing , we have . However, since is the smallest closed set containing , it is also true that , so . Is this correct, and can this be simplified at all? The two directions seem largely similar in reasoning. This problem confused me for a while since it was basically equivalent to saying, ""Y is the smallest closed set containing an open set Z if and only if Y is the smallest closed set containing the largest open set contained in Y"" which was hard for me to parse at first.",Y Y \implies:  Y=\overline Z Z Y Z \mathring Y Y Z\subseteq \mathring Y \overline{\mathring Y} \mathring Y \overline{\mathring Y} \subseteq Y Y Z Y\subseteq \overline{\mathring Y} Y= \overline{\mathring Y} \Longleftarrow: Y=\overline{\mathring Y} \mathring Y Y Z Y Z\subseteq \mathring Y \overline Z Z \overline Z \subseteq \overline{\mathring Y} \overline{\mathring Y} \mathring Y \overline{\mathring Y} \subseteq \overline Z \overline Z = \overline{\mathring Y}=Y \Box,"['general-topology', 'analysis', 'elementary-set-theory', 'solution-verification']"
31,Do quasitransitivity and completeness imply transitivity?,Do quasitransitivity and completeness imply transitivity?,,"Let $X$ be a set and let $R$ be a binary relation on $X$ , i.e. $R \subseteq X^2$ . For $(a,b) \in X^2$ , let $a R b$ denote $(a,b) \in R$ . Let $P$ be the antisymmetric subset of $R$ . Define the properties: Completeness (C): $a \lnot R b \implies b R a$ Quasitransitivity (Q): $a P b P c \implies a P c$ Transitivity (T): $a R b R c \implies a R c$ Here's my confusion: I can't tell if C+Q imply T. Argument 1. C+Q imply T . Suppose $a \lnot R b \lnot R c$ . Completeness implies $c P b P a$ ; Quasitransitivity implies $c P a$ . So $R$ is transitive since $c R b R a$ and $c R a$ . Argument 2. C+Q do not imply T . Let $\succ_i$ and $\succ_j$ be complete strict transitive relations on $X$ , and suppose they are as follows: $b \succ_i c \succ_i a$ and $c \succ_j a \succ_j b$ . Define $R$ as follows: for all $(a,b) \in X^2, a R b \iff a \succ_k b \text{ for some } k \in \{i,j\}$ . Clearly, $R$ is complete. It is also quasitransitive,  since $a \lnot R b \lnot R c$ implies that $a \succ_k c$ for all $k$ due to transitivity of $\succ_k$ , and thus $c \lnot R a$ .  But it is not transitive: we have $a R b R c$ and yet $a \lnot R c$ . Where is my mistake?","Let be a set and let be a binary relation on , i.e. . For , let denote . Let be the antisymmetric subset of . Define the properties: Completeness (C): Quasitransitivity (Q): Transitivity (T): Here's my confusion: I can't tell if C+Q imply T. Argument 1. C+Q imply T . Suppose . Completeness implies ; Quasitransitivity implies . So is transitive since and . Argument 2. C+Q do not imply T . Let and be complete strict transitive relations on , and suppose they are as follows: and . Define as follows: for all . Clearly, is complete. It is also quasitransitive,  since implies that for all due to transitivity of , and thus .  But it is not transitive: we have and yet . Where is my mistake?","X R X R \subseteq X^2 (a,b) \in X^2 a R b (a,b) \in R P R a \lnot R b \implies b R a a P b P c \implies a P c a R b R c \implies a R c a \lnot R b \lnot R c c P b P a c P a R c R b R a c R a \succ_i \succ_j X b \succ_i c \succ_i a c \succ_j a \succ_j b R (a,b) \in X^2, a R b \iff a \succ_k b \text{ for some } k \in \{i,j\} R a \lnot R b \lnot R c a \succ_k c k \succ_k c \lnot R a a R b R c a \lnot R c","['elementary-set-theory', 'relations']"
32,Do we have $\mathbb{R} \times \mathbb{R}^{3}= \mathbb{R}^{4}$ or just $\mathbb{R} \times \mathbb{R}^{3} \simeq \mathbb{R}^{4}$,Do we have  or just,\mathbb{R} \times \mathbb{R}^{3}= \mathbb{R}^{4} \mathbb{R} \times \mathbb{R}^{3} \simeq \mathbb{R}^{4},"I came across this map in an exercise, $$f\colon\left\{\begin{array}{rcl} \color{red}{\mathbb{R} \times \mathbb{R}^{3}} & \longrightarrow & \mathbb{R}^{3} \\ \left(t, \begin{pmatrix} x \\ y \\ z \end{pmatrix}\right) & \longmapsto & \begin{pmatrix} x+y+z+t \\ x^{2}+y^{2}+z^{2}+t-2 \\ x^{3}+y^{3}+z^{3}+t^{2} \end{pmatrix}. \end{array}\right.$$ The question is, do we have $\mathbb{R} \times \mathbb{R}^{3}= \mathbb{R}^{4}$ and thus the author wrote $\mathbb{R} \times \mathbb{R}^{3}$ with an ordered pair $\left(t, \begin{pmatrix} x \\ y \\ z \end{pmatrix}\right)$ for conveniance/the sake of clarity in a certain purpose. Or is $\mathbb{R} \times \mathbb{R}^{3}$ really different from $\mathbb{R}^{4}$ by definition, conceptually or structurally ? And thus this notation would be mandatory and we would only have $\mathbb{R} \times \mathbb{R}^{3} \simeq \mathbb{R}^{4}$ . I guess we have the equality for two reasons: Because we have $\mathbb{R}^{n}= \underbrace{\mathbb{R} \times \ldots \times \mathbb{R}}_{n \text{ times}}$ by definition, and this definition/notation suggests that we can do $$\color{red}{\mathbb{R}} \times \mathbb{R}^{3}= \color{red}{\mathbb{R}} \times \mathbb{R} \times \mathbb{R} \times \mathbb{R}= \mathbb{R}^{4}$$ As I remember we do have by definition $(x,y,z,t):= (x,(y,z,t))$ with a recursive definition, until we get to an ordered pair defined by $(a,b)= \{ a, \{ a,b \}\}$ . Thus, since we have $\left(t, \begin{pmatrix} x \\ y \\ z \end{pmatrix}\right)=(t,x,y,z)$ which is an element of $\mathbb{R}^{4}$ , thus we would have $\color{red}{(?)}$ in $$\mathbb{R} \times \mathbb{R}^{3}:= \mathbb{R} \times \{ (x,y,z) : x,y,z \in \mathbb{R} \}= \{ (t,(x,y,z)) : t,x,y,z \in \mathbb{R} \} \underset{\color{red}{(?)}}{=} \{ (t,x,y,z) : t,x,y,z \in \mathbb{R} \} := \mathbb{R}^{4}$$","I came across this map in an exercise, The question is, do we have and thus the author wrote with an ordered pair for conveniance/the sake of clarity in a certain purpose. Or is really different from by definition, conceptually or structurally ? And thus this notation would be mandatory and we would only have . I guess we have the equality for two reasons: Because we have by definition, and this definition/notation suggests that we can do As I remember we do have by definition with a recursive definition, until we get to an ordered pair defined by . Thus, since we have which is an element of , thus we would have in","f\colon\left\{\begin{array}{rcl} \color{red}{\mathbb{R} \times \mathbb{R}^{3}} & \longrightarrow & \mathbb{R}^{3} \\ \left(t, \begin{pmatrix} x \\ y \\ z \end{pmatrix}\right) & \longmapsto & \begin{pmatrix}
x+y+z+t \\ x^{2}+y^{2}+z^{2}+t-2 \\ x^{3}+y^{3}+z^{3}+t^{2}
\end{pmatrix}. \end{array}\right. \mathbb{R} \times \mathbb{R}^{3}= \mathbb{R}^{4} \mathbb{R} \times \mathbb{R}^{3} \left(t, \begin{pmatrix} x \\ y \\ z \end{pmatrix}\right) \mathbb{R} \times \mathbb{R}^{3} \mathbb{R}^{4} \mathbb{R} \times \mathbb{R}^{3} \simeq \mathbb{R}^{4} \mathbb{R}^{n}= \underbrace{\mathbb{R} \times \ldots \times \mathbb{R}}_{n \text{ times}} \color{red}{\mathbb{R}} \times \mathbb{R}^{3}= \color{red}{\mathbb{R}} \times \mathbb{R} \times \mathbb{R} \times \mathbb{R}= \mathbb{R}^{4} (x,y,z,t):= (x,(y,z,t)) (a,b)= \{ a, \{ a,b \}\} \left(t, \begin{pmatrix} x \\ y \\ z \end{pmatrix}\right)=(t,x,y,z) \mathbb{R}^{4} \color{red}{(?)} \mathbb{R} \times \mathbb{R}^{3}:= \mathbb{R} \times \{ (x,y,z) : x,y,z \in \mathbb{R} \}= \{ (t,(x,y,z)) : t,x,y,z \in \mathbb{R} \} \underset{\color{red}{(?)}}{=} \{ (t,x,y,z) : t,x,y,z \in \mathbb{R} \} := \mathbb{R}^{4}","['elementary-set-theory', 'set-theory', 'definition']"
33,On a decomposition of pairs in the transitive closure $T$ of an arbitrary relation $R$,On a decomposition of pairs in the transitive closure  of an arbitrary relation,T R,"Let $S$ be some set, and let $R$ be a relation with $\operatorname{dom}(R) = \operatorname{ran}(R) = S$ .  Hence $R \subseteq S \times S$ .  Let $T$ be the transitive closure of $R$ , defined as the smallest transitive relation that contains $R$ .  Or, symbolically: $$T = \bigcap\, \{U:  R \subseteq U\subseteq S\times S \; \wedge \; U\,\mathrm{is\;transitive} \}.$$ (Since $S \times S$ itself is a transitive relation, the argument of the $\bigcap$ operator above is nonempty.) I recently came across the following assertion, which I think is correct, but have a hard time proving. Claim: If $x, y \in S$ and $xTy$ , then either $xRy$ or there exists a $z \in S$ such that $xTz$ and $zRy$ . I think that this claim is true, because I visualize the process of creating the transitive closure of a relation as one of ""recursively adding the pair $(a, c)$ whenever the pairs $(a, b)$ and $(b, c)$ are available, until no more pairs can be added.""  Therefore, if (1) the transitive closure $T$ of $R$ includes the pair $(a, c)$ , and (2) it is not the case that $a R c$ , then there must exist some $b \in S$ such that $aTb$ and $bTc$ .  This is not too far from the stronger claim that the $b$ is such that not only $bTc$ , but that $bRc$ . But this is all hand-waving, based on my intuitive vision of some imaginary ""process"" whereby one ""generates"" the transitive closure of a relation. The problem of proving the claim above is made all the more difficult by the fact that I came across it in the course of solving a problem on Zermelo ordinals in a textbook of set theory, and this problem occurred before the autor had gotten around describing even an order relation for Zermelo ordinals, let alone a well-ordering for them, or any notion of induction or recursion based on them 1 . In fact, for the textbook's problem, all one could assume were Zermelo's original Axiom of Infinity (i.e. $\exists w [\varnothing \in w \ \wedge \ \forall x\in w (\{x\} \in w)]$ ) together with the remaining currently standard ZF axioms 2 . Without recursion, induction, well-ordering, etc. I don't know even where to begin proving the claim above. Of course, I understand that $(R \subseteq T) \leftrightarrow ((x, y) \in R \to (x, y) \in T) \leftrightarrow (xRy \to xTy)$ .  Therefore, I see that if $xTy$ , one possibility is that $xRy$ .  My problem is to show that $$(xTy \wedge \lnot xRy)\to \exists z \in S(xTz \wedge zRy)$$ EDIT: A different way to phrase the same problem uses the notion of composition of relations.  The composition $G \circ F$ of relations $G$ and $F$ is defined as $$G \circ F := \{(x, y) \in \operatorname{dom}(F) \times \operatorname{ran}(G): \exists z[(x, z) \in F \wedge (z, y) \in G]\}.$$ This notation allows the following characterization of transitivity: a relation $U$ is transitive iff $U\circ U \subseteq U$ . This notation also can also be used to give an equivalent formulation of the claim above as an assertion about set inclusion: $$ T \subseteq R \cup (R \circ T).$$ It is not hard to show the opposite inclusion: $$R \subseteq T \to R\circ T \subseteq T \circ T = T \to R \cup (R \circ T) \subseteq T,$$ ...so proving the desired conclusion amounts to proving that $$ T = R \cup (R \circ T).$$ 1 In fact, the claim about transitive closures that this post is about arose in the context of proving that the transitive closure of the $\in$ relation could serve as a well-ordering for the set $z$ of Zermelo ordinals.  In contrast to what is the case with the now-standard von Neumman ordinals, where for any two distinct ones of them, $m$ and $n$ , either $m \in n$ or $n \in m$ , with Zermelo ordinals, the $\in$ relation holds only between such an ordinal $n$ and its successor $\{n\}$ .  Hence, $\in\!\!|_z\subseteq z \times z$ is not even an partial order for $z$ (since it is not transitive), let alone a well-ordering for it. 2 Extensionality, Foundation, Comprehension/Separation, Pairing, Union, Replacement, and Power Set.","Let be some set, and let be a relation with .  Hence .  Let be the transitive closure of , defined as the smallest transitive relation that contains .  Or, symbolically: (Since itself is a transitive relation, the argument of the operator above is nonempty.) I recently came across the following assertion, which I think is correct, but have a hard time proving. Claim: If and , then either or there exists a such that and . I think that this claim is true, because I visualize the process of creating the transitive closure of a relation as one of ""recursively adding the pair whenever the pairs and are available, until no more pairs can be added.""  Therefore, if (1) the transitive closure of includes the pair , and (2) it is not the case that , then there must exist some such that and .  This is not too far from the stronger claim that the is such that not only , but that . But this is all hand-waving, based on my intuitive vision of some imaginary ""process"" whereby one ""generates"" the transitive closure of a relation. The problem of proving the claim above is made all the more difficult by the fact that I came across it in the course of solving a problem on Zermelo ordinals in a textbook of set theory, and this problem occurred before the autor had gotten around describing even an order relation for Zermelo ordinals, let alone a well-ordering for them, or any notion of induction or recursion based on them 1 . In fact, for the textbook's problem, all one could assume were Zermelo's original Axiom of Infinity (i.e. ) together with the remaining currently standard ZF axioms 2 . Without recursion, induction, well-ordering, etc. I don't know even where to begin proving the claim above. Of course, I understand that .  Therefore, I see that if , one possibility is that .  My problem is to show that EDIT: A different way to phrase the same problem uses the notion of composition of relations.  The composition of relations and is defined as This notation allows the following characterization of transitivity: a relation is transitive iff . This notation also can also be used to give an equivalent formulation of the claim above as an assertion about set inclusion: It is not hard to show the opposite inclusion: ...so proving the desired conclusion amounts to proving that 1 In fact, the claim about transitive closures that this post is about arose in the context of proving that the transitive closure of the relation could serve as a well-ordering for the set of Zermelo ordinals.  In contrast to what is the case with the now-standard von Neumman ordinals, where for any two distinct ones of them, and , either or , with Zermelo ordinals, the relation holds only between such an ordinal and its successor .  Hence, is not even an partial order for (since it is not transitive), let alone a well-ordering for it. 2 Extensionality, Foundation, Comprehension/Separation, Pairing, Union, Replacement, and Power Set.","S R \operatorname{dom}(R) = \operatorname{ran}(R) = S R \subseteq S \times S T R R T = \bigcap\, \{U:  R \subseteq U\subseteq S\times S \; \wedge \; U\,\mathrm{is\;transitive} \}. S \times S \bigcap x, y \in S xTy xRy z \in S xTz zRy (a, c) (a, b) (b, c) T R (a, c) a R c b \in S aTb bTc b bTc bRc \exists w [\varnothing \in w \ \wedge \ \forall x\in w (\{x\} \in w)] (R \subseteq T) \leftrightarrow ((x, y) \in R \to (x, y) \in T) \leftrightarrow (xRy \to xTy) xTy xRy (xTy \wedge \lnot xRy)\to \exists z \in S(xTz \wedge zRy) G \circ F G F G \circ F := \{(x, y) \in \operatorname{dom}(F) \times \operatorname{ran}(G): \exists z[(x, z) \in F \wedge (z, y) \in G]\}. U U\circ U \subseteq U  T \subseteq R \cup (R \circ T). R \subseteq T \to R\circ T \subseteq T \circ T = T \to R \cup (R \circ T) \subseteq T,  T = R \cup (R \circ T). \in z m n m \in n n \in m \in n \{n\} \in\!\!|_z\subseteq z \times z z","['elementary-set-theory', 'relations', 'order-theory', 'well-orders']"
34,"How can I build a set using the rule ""exclude A or B"" in set theory?","How can I build a set using the rule ""exclude A or B"" in set theory?",,"I've just started learning set theory today and have been trying to understand how the notion of ""inclusion"" and ""exclusion"" fits within it, to build a subset from a set based on a set of rules - see the related question My XY problem is that I am trying to create a program that will filter a list of items based on various ""rules"", where a rule can be something like ""include/exclude items with condition A"", or ""include/exclude items with condition B"". To muddy the waters, it is possible to say something like ""include items with condition A AND B"" or ""include items with condition A OR B"", and conversely ""exclude A AND B"" or ""exclude A OR B"" To give a few practical examples, let's say we have a ""universal set"" $U = \{1, 2, 3, 4, 5, 6, 7, 8, 9, 10\}$ . I can apply ""rules"" like the following to produce a new subset. ""Include numbers that are even"" --> $\{2, 4, 6, 8, 10\}$ ""Include numbers that are even AND greater than 5"" --> $\{6, 8, 10\}$ ""Include numbers that are even OR greater than 5"" --> $\{2, 4, 6, 7, 8, 9, 10\}$ ""Exclude numbers that are even"" --> $\{1, 3, 5, 7, 9\}$ ""Exclude numbers that are even AND greater than 5"" --> $\{1, 2, 3, 4, 5, 7, 9\}$ ""Exclude numbers that are even OR greater than 5"" --> ??? I arrive at a problem at rule 6. I have no idea how to compute this set. I understand that I can use some set operations to apply these ""rules"". E.g. for rule 1, I'm coming up with a set of even numbers (call it $E$ ) and performing an intersection with the universal set, such that $U \cap E = \{2, 4, 6, 8, 10\}$ . With rule 2, I'm calculating a set of the even numbers (the aforementioned $E$ ) and the set of numbers greater than 5 (call it $G = \{6, 7, 8, 9, 10\}$ ), and then I'm again performing an intersection on these two sets: $E \cap G = \{2, 4, 6, 8, 10\} \cap \{6, 7, 8, 9, 10\} = \{6, 8, 10\}$ But I don't understand logically what the rule 6 I've laid out even means. Rule 5 is clear enough, that we take $E \cap G$ , which again is $\{6, 8, 10\}$ , and then subtract that from the universal set $U - \{6, 8, 10\} = \{1, 2, 3, 4, 5, 7, 9\}$ . What would it mean to exclude numbers that are either even or greater than 5? I'm sure this is obvious once you've got a grounding in set theory, but I'm not seeing the solution and would appreciate a pointer.","I've just started learning set theory today and have been trying to understand how the notion of ""inclusion"" and ""exclusion"" fits within it, to build a subset from a set based on a set of rules - see the related question My XY problem is that I am trying to create a program that will filter a list of items based on various ""rules"", where a rule can be something like ""include/exclude items with condition A"", or ""include/exclude items with condition B"". To muddy the waters, it is possible to say something like ""include items with condition A AND B"" or ""include items with condition A OR B"", and conversely ""exclude A AND B"" or ""exclude A OR B"" To give a few practical examples, let's say we have a ""universal set"" . I can apply ""rules"" like the following to produce a new subset. ""Include numbers that are even"" --> ""Include numbers that are even AND greater than 5"" --> ""Include numbers that are even OR greater than 5"" --> ""Exclude numbers that are even"" --> ""Exclude numbers that are even AND greater than 5"" --> ""Exclude numbers that are even OR greater than 5"" --> ??? I arrive at a problem at rule 6. I have no idea how to compute this set. I understand that I can use some set operations to apply these ""rules"". E.g. for rule 1, I'm coming up with a set of even numbers (call it ) and performing an intersection with the universal set, such that . With rule 2, I'm calculating a set of the even numbers (the aforementioned ) and the set of numbers greater than 5 (call it ), and then I'm again performing an intersection on these two sets: But I don't understand logically what the rule 6 I've laid out even means. Rule 5 is clear enough, that we take , which again is , and then subtract that from the universal set . What would it mean to exclude numbers that are either even or greater than 5? I'm sure this is obvious once you've got a grounding in set theory, but I'm not seeing the solution and would appreciate a pointer.","U = \{1, 2, 3, 4, 5, 6, 7, 8, 9, 10\} \{2, 4, 6, 8, 10\} \{6, 8, 10\} \{2, 4, 6, 7, 8, 9, 10\} \{1, 3, 5, 7, 9\} \{1, 2, 3, 4, 5, 7, 9\} E U \cap E = \{2, 4, 6, 8, 10\} E G = \{6, 7, 8, 9, 10\} E \cap G = \{2, 4, 6, 8, 10\} \cap \{6, 7, 8, 9, 10\} = \{6, 8, 10\} E \cap G \{6, 8, 10\} U - \{6, 8, 10\} = \{1, 2, 3, 4, 5, 7, 9\}",['elementary-set-theory']
35,"Prove that a ""set of all sets"" does not exist.","Prove that a ""set of all sets"" does not exist.",,"Axiom I used for the proof: The Axiom Schema of Comprehension : Let P $(x)$ be a property of $x$ . For any set $A$ , there is a set $B$ such that $x\in B$ if and only if $x\in A$ and P $(x)$ . Here is my attempt: Suppose for the sake of contradiction that the set of all sets indeed exist and we call it $V$ . Now consider the property P $(x)$ : $x\notin x$ . Then by the Comprehension Schema, there exists a set $X$ in which $x\in X$ if and only if $x\in V$ and P $(x)$ ; i.e., \begin{align*}                 x\in X\iff x\in V\text{ and }x\notin x.             \end{align*} Since $V$ is the set of all sets and $X$ is a set, then we must have $X\in V$ . If $X\in V$ then either $X\in X$ or $X\notin X$ . If $X\in X$ then we have \begin{align*}                 X\in X\iff X\in V\text{ and }X\notin X,             \end{align*} a contradiction. Now if $X\notin X$ then \begin{align*}                 X\notin X\iff X\notin V\text{ or }X\in X,             \end{align*} but if $X\notin V$ , then we are done. Now if $X\in X$ , this again yield a contradiction. In either case, a contradiction. Therefore $X\notin V$ , and thus the set of all sets does not exist. is this proof correct?","Axiom I used for the proof: The Axiom Schema of Comprehension : Let P be a property of . For any set , there is a set such that if and only if and P . Here is my attempt: Suppose for the sake of contradiction that the set of all sets indeed exist and we call it . Now consider the property P : . Then by the Comprehension Schema, there exists a set in which if and only if and P ; i.e., Since is the set of all sets and is a set, then we must have . If then either or . If then we have a contradiction. Now if then but if , then we are done. Now if , this again yield a contradiction. In either case, a contradiction. Therefore , and thus the set of all sets does not exist. is this proof correct?","(x) x A B x\in B x\in A (x) V (x) x\notin x X x\in X x\in V (x) \begin{align*}
                x\in X\iff x\in V\text{ and }x\notin x.
            \end{align*} V X X\in V X\in V X\in X X\notin X X\in X \begin{align*}
                X\in X\iff X\in V\text{ and }X\notin X,
            \end{align*} X\notin X \begin{align*}
                X\notin X\iff X\notin V\text{ or }X\in X,
            \end{align*} X\notin V X\in X X\notin V","['elementary-set-theory', 'solution-verification']"
36,"Prove that a relation R on set A is antisymmetric if and only if $R \cap R^{-1} \subseteq \{(a,a):a \in A\}$.",Prove that a relation R on set A is antisymmetric if and only if .,"R \cap R^{-1} \subseteq \{(a,a):a \in A\}","Can someone check to see if my proof is correct? If it actually is correct, can someone tell me how to be less verbose and ""make it mathy and less wordy"" for my backwards implication $(\Leftarrow)$ portion of the proof? Here's the problem: Prove that a relation $R$ on set $A$ is antisymmetric if and only if $R \cap R^{-1} \subseteq \{(a,a) : a \in A\}$ . My proof attempt: $(\Rightarrow)$ Let $R$ be an antisymmetric relation on $A$ . Suppose $(a,b),(b,a) \in R$ where $a, b \in A$ . Then by definition of antisymmetric it must the case that $a=b$ , so $(a,a) \in R \Rightarrow (a,a) \in R^{-1}$ $\Rightarrow (a,a) \in R\cap R^{-1} \Rightarrow (a,a) \in \{(a,a) : a \in A\}$ . Since $a, b$ were arbitrary elements, $R \cap R^{-1} \subseteq \{(a,a) : a \in A\}$ $(\Leftarrow)$ Let $R\cap R^{-1} \subseteq \{(a,a) : a\in A\}$ . To be a subset of $\{(a,a) : a \in A\}$ , $R\cap R^{-1}$ must be a set of ordered pairs where the 1st and 2nd terms of the ordered pairs are equal to a single element from $A$ . Consider then, any arbitrary element of A, say $a \in A$ . Then $(a,a) \in A \times A$ and $(a,a) \in R \cap R^{-1}$ . By definition of intersection, $(a,a) \in R$ as well. These results hold for all elements of $A$ , so $R \subseteq A\times A$ . Thus, $R$ is a relation on $A$ by definition. To say $R$ is an antisymmetric relation on $A$ is vacuously true since there will never be an ordered pair of the form $(x, y)$ or $(y,x)$ in $R$ , unless, of course, $x = y$ . Since $R\cap R^{-1} \subseteq \{(a,a) : a\in A\} \Rightarrow$ the relation $R$ on set $A$ is antisymmetric And since the relation $R$ on set $A$ is antisymmetric $\Rightarrow R\cap R^{-1} \subseteq \{(a,a) : a\in A\}$ Therefore the relation $R$ on set $A$ is antisymmetric $\Leftrightarrow$ $R \cap R^{-1} \subseteq \{(a,a) : a \in A\}$ . SECOND ATTEMPT : Thanks for the comments. Is this an ""improvement"" for my forward implication? $(\Rightarrow)$ We are given the relation $R$ on $A$ is antisymmetric. WTS that $R \cap R^{-1} \subseteq \{(a,a):a\in A\}$ . Let $a,b \in A$ be arbitrary elements such that $(a,b) \in R\cap R^{-1}$ . Then $(a,b) \in R$ and $(a,b) \in R^{-1}$ . If $(a,b) \in R^{-1}$ then $(b,a) \in R$ . By def of antisymmetric, since we have $(a,b)$ and $(b,a)$ in $R$ , it must be the case that $a = b$ , that is, $(a,a) \in R$ . Then $(a,a) \in R^{-1}$ as well, which means $(a,a) \in R \cap R^{-1}$ . Thus, $(a,b) \in R\cap R^{-1} \Rightarrow (a,a) \in R\cap R^{-1}$ , so $R\cap R^{-1} \subseteq \{(a,a): a \in A\}$ Which as you said, is not true since we could have the case where $R = \emptyset$ which is antisymmetric, and any non-empty $A$ like $a \in A$ then $(a,a) \notin R \cap R^{-1}$ ... how do I get around to showing this result holds for all relations R on A?","Can someone check to see if my proof is correct? If it actually is correct, can someone tell me how to be less verbose and ""make it mathy and less wordy"" for my backwards implication portion of the proof? Here's the problem: Prove that a relation on set is antisymmetric if and only if . My proof attempt: Let be an antisymmetric relation on . Suppose where . Then by definition of antisymmetric it must the case that , so . Since were arbitrary elements, Let . To be a subset of , must be a set of ordered pairs where the 1st and 2nd terms of the ordered pairs are equal to a single element from . Consider then, any arbitrary element of A, say . Then and . By definition of intersection, as well. These results hold for all elements of , so . Thus, is a relation on by definition. To say is an antisymmetric relation on is vacuously true since there will never be an ordered pair of the form or in , unless, of course, . Since the relation on set is antisymmetric And since the relation on set is antisymmetric Therefore the relation on set is antisymmetric . SECOND ATTEMPT : Thanks for the comments. Is this an ""improvement"" for my forward implication? We are given the relation on is antisymmetric. WTS that . Let be arbitrary elements such that . Then and . If then . By def of antisymmetric, since we have and in , it must be the case that , that is, . Then as well, which means . Thus, , so Which as you said, is not true since we could have the case where which is antisymmetric, and any non-empty like then ... how do I get around to showing this result holds for all relations R on A?","(\Leftarrow) R A R \cap R^{-1} \subseteq \{(a,a) : a \in A\} (\Rightarrow) R A (a,b),(b,a) \in R a, b \in A a=b (a,a) \in R \Rightarrow (a,a) \in R^{-1} \Rightarrow (a,a) \in R\cap R^{-1} \Rightarrow (a,a) \in \{(a,a) : a \in A\} a, b R \cap R^{-1} \subseteq \{(a,a) : a \in A\} (\Leftarrow) R\cap R^{-1} \subseteq \{(a,a) : a\in A\} \{(a,a) : a \in A\} R\cap R^{-1} A a \in A (a,a) \in A \times A (a,a) \in R \cap R^{-1} (a,a) \in R A R \subseteq A\times A R A R A (x, y) (y,x) R x = y R\cap R^{-1} \subseteq \{(a,a) : a\in A\} \Rightarrow R A R A \Rightarrow R\cap R^{-1} \subseteq \{(a,a) : a\in A\} R A \Leftrightarrow R \cap R^{-1} \subseteq \{(a,a) : a \in A\} (\Rightarrow) R A R \cap R^{-1} \subseteq \{(a,a):a\in A\} a,b \in A (a,b) \in R\cap R^{-1} (a,b) \in R (a,b) \in R^{-1} (a,b) \in R^{-1} (b,a) \in R (a,b) (b,a) R a = b (a,a) \in R (a,a) \in R^{-1} (a,a) \in R \cap R^{-1} (a,b) \in R\cap R^{-1} \Rightarrow (a,a) \in R\cap R^{-1} R\cap R^{-1} \subseteq \{(a,a): a \in A\} R = \emptyset A a \in A (a,a) \notin R \cap R^{-1}","['elementary-set-theory', 'solution-verification', 'relations']"
37,Logic behind need for injectivity in $f(A_0\setminus A_1)=f(A_0)\setminus f(A_1)$,Logic behind need for injectivity in,f(A_0\setminus A_1)=f(A_0)\setminus f(A_1),"Let $f:A\to B$ be a function with $A_i\subset A, i=0,1$ . I want to understand the precise logic behind the need for injectivity for $f(A_0\setminus A_1)=f(A_0)\setminus f(A_1)$ to be true. First we prove $f(A_0)\setminus f(A_1)\subset f(A_0\setminus A_1)$ since this direction does not require injectivity: Let $b\in f(A_0)\setminus f(A_1)$ . This is equivalent to $b\in f(A_0)$ and $b\notin f(A_1)\iff f^{-1}(b)\in A_0$ and $f^{-1}(b)\notin A_1$ . The latter implies, but is not equivalent to, $f^{-1}(b)\in(A_0\setminus A_1)\iff b\in f(A_0\setminus A_1).$ Thus $f(A_0)\setminus f(A_1)\subset f(A_0\setminus A_1)$ . Note here $f^{-1}(b)$ does not refer to a necessarily unique element, just an $a\in A$ such that $f(a)=b$ . So therefore $f^{-1}(b)\in A_0$ and $f^{-1}(b)\notin A_1$ only implies $f^{-1}(b)\in(A_0\setminus A_1)$ since if $f^{-1}(b)\in(A_0\setminus A_1)$ were to imply $f^{-1}(b)\in A_0$ and $f^{-1}(b)\notin A_1$ we would find in case $f(a_0)=f(a_1)=b$ with $A_0=\{a_0\}, A_1=\{a_1\}$ that $$a_0=f^{-1}(b)\in(A_0\setminus A_1)\implies a_1=f^{-1}(b)\in A_0 \text{ and } a_1=f^{-1}(b)\notin A_1$$ which is false. Now we prove $f(A_0\setminus A_1)\subset f(A_0)\setminus f(A_1)$ if $f$ is injective: Let $b\in f(A_0\setminus A_1).$ This is equivalent to $f^{-1}(b)\in (A_0\setminus A_1).$ But since $f$ is injective, the latter $f^{-1}(b)\in (A_0\setminus A_1)$ is equivalent to $f^{-1}(b)\in A_0$ and $f^{-1}(b)\notin A_1$ since $f^{-1}(b)$ is the unique $a\in A$ such that $f(a)=b.$ So we then have $b\in f(A_0)$ and $b\notin f(A_1)$ , or $b\in f(A_0)\setminus f(A_1).$ Thus $f(A_0\setminus A_1)\subset f(A_0)\setminus f(A_1)$ . So I guess my question is, is my invocation of injection for a unique $a$ really ""enough"" per se without that middle explanatory paragraph, or should I be do something like Robert Cardona does here to more directly use the injectivity condition? I use the exact same minimal justification of uniqueness of the inverse in my proof of $f(A_0\cap A_1)=f(A_0)\cap f(A_1)$ too so I'm wanting to get this right. The thing that's interesting is that injectivity turns $f^{-1}(b)$ into an element, whereas generally for non injective functions $f^{-1}(b)$ denotes a set. So therefore, you can do regular set theory containment without worrying about quantifiers when $f$ is injective.","Let be a function with . I want to understand the precise logic behind the need for injectivity for to be true. First we prove since this direction does not require injectivity: Let . This is equivalent to and and . The latter implies, but is not equivalent to, Thus . Note here does not refer to a necessarily unique element, just an such that . So therefore and only implies since if were to imply and we would find in case with that which is false. Now we prove if is injective: Let This is equivalent to But since is injective, the latter is equivalent to and since is the unique such that So we then have and , or Thus . So I guess my question is, is my invocation of injection for a unique really ""enough"" per se without that middle explanatory paragraph, or should I be do something like Robert Cardona does here to more directly use the injectivity condition? I use the exact same minimal justification of uniqueness of the inverse in my proof of too so I'm wanting to get this right. The thing that's interesting is that injectivity turns into an element, whereas generally for non injective functions denotes a set. So therefore, you can do regular set theory containment without worrying about quantifiers when is injective.","f:A\to B A_i\subset A, i=0,1 f(A_0\setminus A_1)=f(A_0)\setminus f(A_1) f(A_0)\setminus f(A_1)\subset f(A_0\setminus A_1) b\in f(A_0)\setminus f(A_1) b\in f(A_0) b\notin f(A_1)\iff f^{-1}(b)\in A_0 f^{-1}(b)\notin A_1 f^{-1}(b)\in(A_0\setminus A_1)\iff b\in f(A_0\setminus A_1). f(A_0)\setminus f(A_1)\subset f(A_0\setminus A_1) f^{-1}(b) a\in A f(a)=b f^{-1}(b)\in A_0 f^{-1}(b)\notin A_1 f^{-1}(b)\in(A_0\setminus A_1) f^{-1}(b)\in(A_0\setminus A_1) f^{-1}(b)\in A_0 f^{-1}(b)\notin A_1 f(a_0)=f(a_1)=b A_0=\{a_0\}, A_1=\{a_1\} a_0=f^{-1}(b)\in(A_0\setminus A_1)\implies a_1=f^{-1}(b)\in A_0 \text{ and } a_1=f^{-1}(b)\notin A_1 f(A_0\setminus A_1)\subset f(A_0)\setminus f(A_1) f b\in f(A_0\setminus A_1). f^{-1}(b)\in (A_0\setminus A_1). f f^{-1}(b)\in (A_0\setminus A_1) f^{-1}(b)\in A_0 f^{-1}(b)\notin A_1 f^{-1}(b) a\in A f(a)=b. b\in f(A_0) b\notin f(A_1) b\in f(A_0)\setminus f(A_1). f(A_0\setminus A_1)\subset f(A_0)\setminus f(A_1) a f(A_0\cap A_1)=f(A_0)\cap f(A_1) f^{-1}(b) f^{-1}(b) f",[]
38,Intuition regarding sequence functions,Intuition regarding sequence functions,,"I'm working my way through Halmos and am struggling with his explanation of transfinite recursion.  Specifically, I'm getting stuck on his definition of a ""sequence function,"" and I was hoping someone here could help me build some intuition around it. Halmos says: A sequence function of type $W$ in $X$ is a function $f$ whose domain consists of all sequences of type $a$ in $X$ , for all elements $a$ in $W$ , and whose range is included in $X$ .  Roughly speaking, a sequence function tells us how to ""lengthen"" a sequence; given a sequence that stretches up to (but not including) some element of $W$ we can use a sequence function to tack on one more term. Now, based on Halmos's earlier explanation, a ""sequence function of type $W$ in $X$ "" is a function from some initial segment of $a$ (where $a$ $\in$ $W$ and $W$ is well-ordered) into $X$ .  So, as I understand it, if W is a well-ordered set $\{a,b,c,d\}$ where the ordering is alphabetical, and $X$ is an arbitrary set, say $\{1,2,3,4,5\}$ , then an example of ""a sequence of type $c$ "" would be a function $f$ such that: $$ f(a)=1, f(b)=3, f(c)=5 $$ Similarly, another example of a ""sequence of type $c$ "" would be a function g such that $$ g(a)=2, g(b)=3, g(c)=4 $$ This is where I get stuck.  How do you go from here to a ""sequence function of type $W$ in $X$ "".  I see that the domain is supposed to be $\{ f, g, etc...\}$ where ""etc..."" is any other sequences of type $W$ in $X$ , and the domain is some $Y$ where $Y \subseteq X$ .  But I don't really have any intuition of what that function is or how it can be used to ""lengthen"" a sequence. I've also read through this answer a few times and I believe this bit is capturing the same point: Now, 𝐼 is a method for extending a partial function ""one step further"": if I feed 𝐼 a map 𝑝:𝛽→𝑋 for some 𝛽<𝛼, 𝐼 tells me what 𝑓(𝛽) ""ought"" to be given that 𝑝=𝑓↾𝛽. That is, if I've defined 𝑓 for the first 𝛽-many inputs, 𝐼 tells me how to define 𝑓 for the next input. But here too I similarly am not understanding the ""one step further"" notion. Can someone provide me some examples that clarify how ""sequence functions"" work? EDIT: I'm still struggling with the ""lengthen"" or ""tack on"" concept behind sequence functions, but I think I have a better understanding of what a sequence function is . Later on in the chapter on transfinite recursion, Halmos provides an example of a sequence function in proving the comparability theorem for well-ordered sets.  Specifically, he defines that, for two well ordered sets $X$ and $Y$ , if $x \in X$ and $t$ is a sequence of type $x$ in $Y$ , then let $f$ be a function from $t$ to the supremum of the range of $t$ , if one exists, otherwise, to the least member of $Y$ . $f$ , he explains, is a sequence function. So building on the example above, if $X = \{ a, b, c, d, e, f, g\}$ (ordered alphabetically) and $Y = \{1, 2, 3, 4, 5, 6, 7 \}$ (ordered numerically), we can give an example of a sequence function as follows: Let $M$ be a function from $X$ onto $Y$ that simply maps $a$ to $1$ , $b$ to 2, etc. Let $t$ be a sequence of type $x$ in $Y$ defined as the restriction of $M$ to the initial segment of $x$ for any $x \in X$ .  So, for example, $t$ for $c$ would be $\{(a,1),(b,2),(c,3)\}$ and $t$ for $d$ would be $\{(a,1),(b,2),(c,3),(d,4)\}$ Let $f$ be a function from any $t$ to to the supremum of the range of $t$ , so, for example, $f(t$ for $c) = 3$ and $f(t$ for $d) = 4$ etc. As I understand it, $f$ is a sequence function because it maps any ""sequence of type $x$ "", e.g., $t$ for $a$ , $t$ for $b$ , etc., into $Y$ .  Or, to use Halmos's language, the domain of $f$ is all sequences of type $x$ in $Y$ and the range of $f$ is a subset of $Y$ . That all makes sense to me (did I get it right?).  And it's probably enough to keep going in Halmos.  But I would still love to understand the intuition behind this notion that $f$ lengthens or tacks-on to a sequence.  I just don't see it in this example. $f$ doesn't seem to me to lengthen any sequence, or even to go from one sequence to another.  It simply maps a sequence to an element of $Y$ .  What am I missing?","I'm working my way through Halmos and am struggling with his explanation of transfinite recursion.  Specifically, I'm getting stuck on his definition of a ""sequence function,"" and I was hoping someone here could help me build some intuition around it. Halmos says: A sequence function of type in is a function whose domain consists of all sequences of type in , for all elements in , and whose range is included in .  Roughly speaking, a sequence function tells us how to ""lengthen"" a sequence; given a sequence that stretches up to (but not including) some element of we can use a sequence function to tack on one more term. Now, based on Halmos's earlier explanation, a ""sequence function of type in "" is a function from some initial segment of (where and is well-ordered) into .  So, as I understand it, if W is a well-ordered set where the ordering is alphabetical, and is an arbitrary set, say , then an example of ""a sequence of type "" would be a function such that: Similarly, another example of a ""sequence of type "" would be a function g such that This is where I get stuck.  How do you go from here to a ""sequence function of type in "".  I see that the domain is supposed to be where ""etc..."" is any other sequences of type in , and the domain is some where .  But I don't really have any intuition of what that function is or how it can be used to ""lengthen"" a sequence. I've also read through this answer a few times and I believe this bit is capturing the same point: Now, 𝐼 is a method for extending a partial function ""one step further"": if I feed 𝐼 a map 𝑝:𝛽→𝑋 for some 𝛽<𝛼, 𝐼 tells me what 𝑓(𝛽) ""ought"" to be given that 𝑝=𝑓↾𝛽. That is, if I've defined 𝑓 for the first 𝛽-many inputs, 𝐼 tells me how to define 𝑓 for the next input. But here too I similarly am not understanding the ""one step further"" notion. Can someone provide me some examples that clarify how ""sequence functions"" work? EDIT: I'm still struggling with the ""lengthen"" or ""tack on"" concept behind sequence functions, but I think I have a better understanding of what a sequence function is . Later on in the chapter on transfinite recursion, Halmos provides an example of a sequence function in proving the comparability theorem for well-ordered sets.  Specifically, he defines that, for two well ordered sets and , if and is a sequence of type in , then let be a function from to the supremum of the range of , if one exists, otherwise, to the least member of . , he explains, is a sequence function. So building on the example above, if (ordered alphabetically) and (ordered numerically), we can give an example of a sequence function as follows: Let be a function from onto that simply maps to , to 2, etc. Let be a sequence of type in defined as the restriction of to the initial segment of for any .  So, for example, for would be and for would be Let be a function from any to to the supremum of the range of , so, for example, for and for etc. As I understand it, is a sequence function because it maps any ""sequence of type "", e.g., for , for , etc., into .  Or, to use Halmos's language, the domain of is all sequences of type in and the range of is a subset of . That all makes sense to me (did I get it right?).  And it's probably enough to keep going in Halmos.  But I would still love to understand the intuition behind this notion that lengthens or tacks-on to a sequence.  I just don't see it in this example. doesn't seem to me to lengthen any sequence, or even to go from one sequence to another.  It simply maps a sequence to an element of .  What am I missing?","W X f a X a W X W W X a a \in W W X \{a,b,c,d\} X \{1,2,3,4,5\} c f 
f(a)=1, f(b)=3, f(c)=5
 c 
g(a)=2, g(b)=3, g(c)=4
 W X \{ f, g, etc...\} W X Y Y \subseteq X X Y x \in X t x Y f t t Y f X = \{ a, b, c, d, e, f, g\} Y = \{1, 2, 3, 4, 5, 6, 7 \} M X Y a 1 b t x Y M x x \in X t c \{(a,1),(b,2),(c,3)\} t d \{(a,1),(b,2),(c,3),(d,4)\} f t t f(t c) = 3 f(t d) = 4 f x t a t b Y f x Y f Y f f Y","['elementary-set-theory', 'intuition']"
39,Verify if the proposed equivalence $A \subset B \land A \subset C \iff A \subset (B \cup C)$ holds,Verify if the proposed equivalence  holds,A \subset B \land A \subset C \iff A \subset (B \cup C),"Only the right direction $(\Rightarrow)$ is true. Proof : Suppose that $A \subset B$ and $A \subset C$ and let $x \in A$ . Then clearly $x$ is also in $B$ . $A \subset B \Rightarrow x \in B \cup C$ . Since $x$ was arbitrary, this shows that $A \subset (B \cup C)$ . On the other hand, the converse is not true: suppose that $A = \{5, 6, 7\}, B = \{5, 6\}$ , and $C =\{7,8\}$ . Then $A \subset \{5, 6, 7, 8\} = B \cup C$ but it is neither true that $A \subset B$ (since $7 \in A$ but $7 \notin B$ ) nor $A \subset C$ (since $5 \in A$ but $5 \notin C$ ). Am I correct and is there another way simpler or is this the simplest or the only conventional one? Well, yeah I know this is just straightforward.","Only the right direction is true. Proof : Suppose that and and let . Then clearly is also in . . Since was arbitrary, this shows that . On the other hand, the converse is not true: suppose that , and . Then but it is neither true that (since but ) nor (since but ). Am I correct and is there another way simpler or is this the simplest or the only conventional one? Well, yeah I know this is just straightforward.","(\Rightarrow) A \subset B A \subset C x \in A x B A \subset B \Rightarrow x \in B \cup C x A \subset (B \cup C) A = \{5, 6, 7\}, B = \{5, 6\} C =\{7,8\} A \subset \{5, 6, 7, 8\} = B \cup C A \subset B 7 \in A 7 \notin B A \subset C 5 \in A 5 \notin C","['elementary-set-theory', 'solution-verification']"
40,Prove that $card(X) \le card(Y) \iff \exists Z \subseteq Y$ such that $card(X)=card(Z)$,Prove that  such that,card(X) \le card(Y) \iff \exists Z \subseteq Y card(X)=card(Z),"I would just like some guidance on whether my proof is sufficient, or if there are things I should change. Thank you! Prove that $card(X) \le card(Y) \iff \exists Z \subseteq Y$ such that $card(X)=card(Z)\\$ Assume $\exists Z \subseteq Y$ such that $card(X)=card(Z)$ $\Rightarrow card(Z) \le card(Y)$ $\Rightarrow card(X) \le card(Y)$ since $card(X)=card(Z)$ $\therefore$ $card(X) \le card(Y)\\$ Assume $card(X) \le card(Y)$ $\Rightarrow$ There is an injective function $f: X\rightarrow Y$ Now let $Z$ be the image of $f$ $\Rightarrow Z\subseteq Y$ $\Rightarrow$ Then for $\forall a \in X,\exists b \in Z$ such that $f(a)=b$ Let $g:X \rightarrow Z$ be a function from $X$ to $Z$ $\Rightarrow$ Then since the codomain and image of $g$ are equal, $g$ is an onto function $\Rightarrow$ $g$ is bijective function $\Rightarrow$ $card(X)=card(Z)$ $\therefore$ $card(X)=card(Z)$","I would just like some guidance on whether my proof is sufficient, or if there are things I should change. Thank you! Prove that such that Assume such that since Assume There is an injective function Now let be the image of Then for such that Let be a function from to Then since the codomain and image of are equal, is an onto function is bijective function","card(X) \le card(Y) \iff \exists Z \subseteq Y card(X)=card(Z)\\ \exists Z \subseteq Y card(X)=card(Z) \Rightarrow card(Z) \le card(Y) \Rightarrow card(X) \le card(Y) card(X)=card(Z) \therefore card(X) \le card(Y)\\ card(X) \le card(Y) \Rightarrow f: X\rightarrow Y Z f \Rightarrow Z\subseteq Y \Rightarrow \forall a \in X,\exists b \in Z f(a)=b g:X \rightarrow Z X Z \Rightarrow g g \Rightarrow g \Rightarrow card(X)=card(Z) \therefore card(X)=card(Z)",['elementary-set-theory']
41,"Why isn't the set V, as defined in the question body, a vector space?","Why isn't the set V, as defined in the question body, a vector space?",,"Let $V$ denote the set of ordered pairs of real numbers and define our operations as follows: For $(a_1, a_2)$ , $(b_1, b_2)$ $\in$ $V$ and $c \in R$ , $(a_1, a_2) + (b_1, b_2) = (a_1 + b_1, a_2b_2)$ and $c(a_1, a_2) = (ca_1, a_2)$ Now I've determined that this isn't a vector space, but I thought it was only because it fails one of the distributive rules, namely $(a+b)x \neq ax + bx$ for $x \in V$ and $a,b \in R$ . However, I'm told it also fails the additive inverse rule: $\forall x \in V$ , $\exists y \in V$ such that $x + y = 0$ . The potential $0$ vector in this set would be $(0, 1)$ , since $\forall x \in V$ , $x + (0, 1) = x$ . But now why can't we simply define an additive inverse as follows: $\forall x \in V$ , define $y = (-x_1, \frac{1}{x_2})$ $\Rightarrow x + y = (x_1, x_2) + (-x_1, \frac{1}{x_2}) = (x_1 + (-x_1), x_2(\frac{1}{x_2})) = (0, 1) = 0$ Are we not allowed to use division here, or something, since it's not defined as an operation in a simple vector space like this? But it is certainly defined on $R$ , which is the field we are assuming for this potential vector space, right? What am I missing?","Let denote the set of ordered pairs of real numbers and define our operations as follows: For , and , and Now I've determined that this isn't a vector space, but I thought it was only because it fails one of the distributive rules, namely for and . However, I'm told it also fails the additive inverse rule: , such that . The potential vector in this set would be , since , . But now why can't we simply define an additive inverse as follows: , define Are we not allowed to use division here, or something, since it's not defined as an operation in a simple vector space like this? But it is certainly defined on , which is the field we are assuming for this potential vector space, right? What am I missing?","V (a_1, a_2) (b_1, b_2) \in V c \in R (a_1, a_2) + (b_1, b_2) = (a_1 + b_1, a_2b_2) c(a_1, a_2) = (ca_1, a_2) (a+b)x \neq ax + bx x \in V a,b \in R \forall x \in V \exists y \in V x + y = 0 0 (0, 1) \forall x \in V x + (0, 1) = x \forall x \in V y = (-x_1, \frac{1}{x_2}) \Rightarrow x + y = (x_1, x_2) + (-x_1, \frac{1}{x_2}) = (x_1 + (-x_1), x_2(\frac{1}{x_2})) = (0, 1) = 0 R","['linear-algebra', 'elementary-set-theory', 'vector-spaces', 'inverse']"
42,Textbook on elementary set theory that includes all proofs,Textbook on elementary set theory that includes all proofs,,"NB: I have read the earlier post Textbooks on set theory , but the information in that post is not sufficiently specific to answer my question here. To put it somewhat glibly, I am looking for a book that does for elementary set theory what Edmund Landau's Foundations of Analysis does for analysis. In other words, I am looking for a book on elementary set theory that explicitly proves everything it asserts, no matter how obvious the assertion or how tedious, or ""routine"", the proof. Such a book not only avoids ""proofs"" such as ""obvious"", ""routine"", ""exercise"" but also the likes of ""by induction on $\alpha$ "", or ""proof sketches"" in general. As for coverage, the book should at least cover ordinals and cardinals, and, especially, their respective arithmetics. EDIT: Since this post has received nothing approaching an answer, I think it is in order to relax the requirements somewhat.  Please regard the description above as ""an ideal to strive for,"" and propose candidates that you consider approach it most closely.","NB: I have read the earlier post Textbooks on set theory , but the information in that post is not sufficiently specific to answer my question here. To put it somewhat glibly, I am looking for a book that does for elementary set theory what Edmund Landau's Foundations of Analysis does for analysis. In other words, I am looking for a book on elementary set theory that explicitly proves everything it asserts, no matter how obvious the assertion or how tedious, or ""routine"", the proof. Such a book not only avoids ""proofs"" such as ""obvious"", ""routine"", ""exercise"" but also the likes of ""by induction on "", or ""proof sketches"" in general. As for coverage, the book should at least cover ordinals and cardinals, and, especially, their respective arithmetics. EDIT: Since this post has received nothing approaching an answer, I think it is in order to relax the requirements somewhat.  Please regard the description above as ""an ideal to strive for,"" and propose candidates that you consider approach it most closely.",\alpha,"['elementary-set-theory', 'reference-request']"
43,Relation between a fixed point and being a well-order,Relation between a fixed point and being a well-order,,"I've been trying to prove the following, but with no particular success: Given a linear order $\leq$ on $A$ , define $\pi:2^A\to 2^A$ by $X\mapsto\{y\in A: (\forall x < y)(x\in X) \}$ . Let $A_0$ be the least fixed point of $\pi$ . Prove that $x\in A_0$ iff $\{(a,b)\in A\times A: a\leq b < x\}$ is a well order. For example, suppose that $\{(a,b)\in A\times A: a\leq b < y\}$ is a well order. I must prove that $y\in A_0$ . Here's my thought process: what does it mean that $y\in A_0$ ? $A_0$ is a fixed point for $\pi$ iff $A_0=\{y\in A:(\forall x < y)(x\in A_0)\}$ . So the condition that $y$ lies in a fixed point $A_0$ means that $(\forall x < y)(x\in A_0)$ . But to chech this condition, I'd need to check the sub-condition $x\in A_0$ , which again means that $(\forall t < x)(t\in A_0)$ , and now the same problem arises with checking the sub-condition $t\in A_0$ ... Even setting this aside, I must use somehow that $\{(a,b)\in A\times A: a\leq b < y\}$ is a well order. So I'd think I need to guess some particular non-empty subset of $A$ that I need to consider, and then I need to take a least element in that subset. I don't really see which subset to consider, and how the ""leastness"" property would help. For the other direction, I have the same problem as described at the beginning. When trying to use the condition that $y\in A_0$ , an infinite chain of conditions arises...","I've been trying to prove the following, but with no particular success: Given a linear order on , define by . Let be the least fixed point of . Prove that iff is a well order. For example, suppose that is a well order. I must prove that . Here's my thought process: what does it mean that ? is a fixed point for iff . So the condition that lies in a fixed point means that . But to chech this condition, I'd need to check the sub-condition , which again means that , and now the same problem arises with checking the sub-condition ... Even setting this aside, I must use somehow that is a well order. So I'd think I need to guess some particular non-empty subset of that I need to consider, and then I need to take a least element in that subset. I don't really see which subset to consider, and how the ""leastness"" property would help. For the other direction, I have the same problem as described at the beginning. When trying to use the condition that , an infinite chain of conditions arises...","\leq A \pi:2^A\to 2^A X\mapsto\{y\in A: (\forall x < y)(x\in X) \} A_0 \pi x\in A_0 \{(a,b)\in A\times A: a\leq b < x\} \{(a,b)\in A\times A: a\leq b < y\} y\in A_0 y\in A_0 A_0 \pi A_0=\{y\in A:(\forall x < y)(x\in A_0)\} y A_0 (\forall x < y)(x\in A_0) x\in A_0 (\forall t < x)(t\in A_0) t\in A_0 \{(a,b)\in A\times A: a\leq b < y\} A y\in A_0","['elementary-set-theory', 'order-theory', 'fixed-point-theorems', 'fixed-points', 'well-orders']"
44,Subsets which overlap in one element,Subsets which overlap in one element,,"consider the set $\{1,...,n\}$ , we want to decompose it into sets $S_1,....,S_t$ such that $\vert S_i\vert \geq  k$ for all i and $\vert S_i \cap S_j \vert \leq 1$ for all $i\neq j$ . Is there an upper bound on $t$ ? Obviously depending on n and k. Clearly for $k=1$ we get no bound. And for $k=n$ we have $t=1$ . This problem comes from Lemma 2.1 in ""On the lattice property of the plane and some problems of Dirac, Motzkin and Erdős in combinatorial geometry"" by Jozsef Beck, 1983. There for $\sqrt{2n}<k \leq n$ it is claimed that $t < \frac{2n}{k}$ , but I dont see it. The proof seems to use that $t \leq \frac{2n}{k}$ holds, if I assume that this is correct I can follow that claim. Thanks in advance! Edit: My idee is to show that $2n \geq \sum_{i=1}^t \vert S_i\vert \geq t \cdot k$ . The right inequality is clear, but I miss an argument for the left one.","consider the set , we want to decompose it into sets such that for all i and for all . Is there an upper bound on ? Obviously depending on n and k. Clearly for we get no bound. And for we have . This problem comes from Lemma 2.1 in ""On the lattice property of the plane and some problems of Dirac, Motzkin and Erdős in combinatorial geometry"" by Jozsef Beck, 1983. There for it is claimed that , but I dont see it. The proof seems to use that holds, if I assume that this is correct I can follow that claim. Thanks in advance! Edit: My idee is to show that . The right inequality is clear, but I miss an argument for the left one.","\{1,...,n\} S_1,....,S_t \vert S_i\vert \geq  k \vert S_i \cap S_j \vert \leq 1 i\neq j t k=1 k=n t=1 \sqrt{2n}<k \leq n t < \frac{2n}{k} t \leq \frac{2n}{k} 2n \geq \sum_{i=1}^t \vert S_i\vert \geq t \cdot k","['combinatorics', 'elementary-set-theory', 'combinatorial-geometry']"
45,Proof of Bourbaki's Fixed Point Theorem,Proof of Bourbaki's Fixed Point Theorem,,"I am studying GTM 139 and troubling about the proof of Bourbaki's fixed point theorem. To quote from that book: Let $X$ be a poset such that every well ordered subset has an lub in $X$ . If $f: X \rightarrow X$ is such that $f(x) \geq x$ for all $x \in X$ , then $f$ has a fixed point. Pick an element $x_{0} \in X .$ Let $\mathbf{S}$ be the collection of subsets $Y \subset X$ such that: (1) $Y$ is well ordered with least element $x_{0}$ and successor function $\left.f\right|_{Y-\{\text { lub } Y\}}$ . (2) $x_{0} \neq y \in Y \Rightarrow \operatorname{lub}_{X}\left(\operatorname{IS}_{Y}(y)\right) \in Y$ . For example, $\left\{x_{0}\right\} \in \mathbf{S},\left\{x_{0}, f\left(x_{0}\right)\right\} \in \mathbf{S}$ , etc. We need the following sublemmas (A) and (B): (A) If $Y \in \mathbf{S}$ and $Y^{\prime} \in \mathbf{S}$ , then $Y$ is an initial segment of $Y^{\prime}$ or vice versa. To prove (A) let $V=\left\{x \in Y \cap Y^{\prime} \mid \mathrm{WIS}_{Y}(x)=\mathrm{WIS}_{Y^{\prime}}(x)\right\} .$ Suppose first that $V$ has a last element $v .$ If $v$ is not the last element of $Y$ then $\operatorname{succ}_{Y}(v)=f(v)$ . If $v$ is not the last element of $Y^{\prime}$ then $\operatorname{succ}_{Y^{\prime}}(v)=f(v) .$ Hence if neither of $Y, Y^{\prime}$ is an initial segment of the other then $f(v) \in V$ , whence $f(v)=v$ and we are done. If, on the contrary, $V$ has no last element, let $z=\operatorname{lub}_{X}(V) .$ If $Y \neq V \neq Y^{\prime}$ then it follows from $(2)$ that $z \in Y \cap Y^{\prime}$ (because if $y=\inf (Y-V)$ then $V=\operatorname{IS}_{Y}(y)$ and therefore $z=\operatorname{lub}_{X}\left(\operatorname{IS}_{Y}(y)\right) \in Y$ by $\left.(2)\right) .$ Therefore, $z \in V$ , a contradiction, proving (A). (B) The set $Y_{0}=\bigcup\{Y \mid Y \in \mathbf{S}\}$ is in $\mathbf{S}$ . To prove (B) note that if $y_{0} \in Y \in \mathbf{S}$ then it follows from (A) that $\left\{y \in Y_{0} \mid y<y_{0}\right\}=\operatorname{IS}_{Y}\left(y_{0}\right)$ and so this subset is well ordered with successor function $f$ . This implies immediately that $Y_{0}$ is well ordered and satisfies (1). Also lub $_{X}\left(\operatorname{IS}\left(y_{0}\right)\right) \in Y \subset Y_{0}$ which gives condition (2) for $Y_{0}$ . Thus (B) is proved. Now we complete the proof. Let $y_{0}=l u b_{X}\left(Y_{0}\right)$ . If $y_{0} \notin Y_{0}$ then $Y_{0} \cup\left\{y_{0}\right\} \in \mathbf{S}$ and so $y_{0} \in Y_{0}$ after all. If $f\left(y_{0}\right)>y_{0}$ then $Y_{0} \cup\left\{f\left(y_{0}\right)\right\} \in \mathbf{S}$ contrary to the definition of $Y_{0}$ . Thus $f\left(y_{0}\right)=y_{0}$ as desired. First, I had no idea about what is happening. Could someone give me any general ideas about how this proof works? Second, I've tried using some concrete examples to help me understand, but they induced even more questions. For example, let $X=\{1,2,3,4,5\}$ (with normal partial order) and $x_0=1$ . Consider $Y=\{1,2,3\}$ and $Y'=\{1,2,4,5\}$ , then $V=\{1,2\}$ and has the last element $v=2$ . However, $\operatorname{succ}_{Y'}(2)=4\neq 3=f(2)$ . It contradicts the proof and I don't know where is the problem.","I am studying GTM 139 and troubling about the proof of Bourbaki's fixed point theorem. To quote from that book: Let be a poset such that every well ordered subset has an lub in . If is such that for all , then has a fixed point. Pick an element Let be the collection of subsets such that: (1) is well ordered with least element and successor function . (2) . For example, , etc. We need the following sublemmas (A) and (B): (A) If and , then is an initial segment of or vice versa. To prove (A) let Suppose first that has a last element If is not the last element of then . If is not the last element of then Hence if neither of is an initial segment of the other then , whence and we are done. If, on the contrary, has no last element, let If then it follows from that (because if then and therefore by Therefore, , a contradiction, proving (A). (B) The set is in . To prove (B) note that if then it follows from (A) that and so this subset is well ordered with successor function . This implies immediately that is well ordered and satisfies (1). Also lub which gives condition (2) for . Thus (B) is proved. Now we complete the proof. Let . If then and so after all. If then contrary to the definition of . Thus as desired. First, I had no idea about what is happening. Could someone give me any general ideas about how this proof works? Second, I've tried using some concrete examples to help me understand, but they induced even more questions. For example, let (with normal partial order) and . Consider and , then and has the last element . However, . It contradicts the proof and I don't know where is the problem.","X X f: X \rightarrow X f(x) \geq x x \in X f x_{0} \in X . \mathbf{S} Y \subset X Y x_{0} \left.f\right|_{Y-\{\text { lub } Y\}} x_{0} \neq y \in Y \Rightarrow \operatorname{lub}_{X}\left(\operatorname{IS}_{Y}(y)\right) \in Y \left\{x_{0}\right\} \in \mathbf{S},\left\{x_{0}, f\left(x_{0}\right)\right\} \in \mathbf{S} Y \in \mathbf{S} Y^{\prime} \in \mathbf{S} Y Y^{\prime} V=\left\{x \in Y \cap Y^{\prime} \mid \mathrm{WIS}_{Y}(x)=\mathrm{WIS}_{Y^{\prime}}(x)\right\} . V v . v Y \operatorname{succ}_{Y}(v)=f(v) v Y^{\prime} \operatorname{succ}_{Y^{\prime}}(v)=f(v) . Y, Y^{\prime} f(v) \in V f(v)=v V z=\operatorname{lub}_{X}(V) . Y \neq V \neq Y^{\prime} (2) z \in Y \cap Y^{\prime} y=\inf (Y-V) V=\operatorname{IS}_{Y}(y) z=\operatorname{lub}_{X}\left(\operatorname{IS}_{Y}(y)\right) \in Y \left.(2)\right) . z \in V Y_{0}=\bigcup\{Y \mid Y \in \mathbf{S}\} \mathbf{S} y_{0} \in Y \in \mathbf{S} \left\{y \in Y_{0} \mid y<y_{0}\right\}=\operatorname{IS}_{Y}\left(y_{0}\right) f Y_{0} _{X}\left(\operatorname{IS}\left(y_{0}\right)\right) \in Y \subset Y_{0} Y_{0} y_{0}=l u b_{X}\left(Y_{0}\right) y_{0} \notin Y_{0} Y_{0} \cup\left\{y_{0}\right\} \in \mathbf{S} y_{0} \in Y_{0} f\left(y_{0}\right)>y_{0} Y_{0} \cup\left\{f\left(y_{0}\right)\right\} \in \mathbf{S} Y_{0} f\left(y_{0}\right)=y_{0} X=\{1,2,3,4,5\} x_0=1 Y=\{1,2,3\} Y'=\{1,2,4,5\} V=\{1,2\} v=2 \operatorname{succ}_{Y'}(2)=4\neq 3=f(2)","['elementary-set-theory', 'set-theory', 'order-theory', 'fixed-point-theorems']"
46,"Prove for any function: $f:\:A\rightarrow B$ and any sets $C,D\subseteq A$, $f\left(C\right)$ ∖ $f\left(D\right) \subseteq f(C\backslash D) $","Prove for any function:  and any sets ,  ∖","f:\:A\rightarrow B C,D\subseteq A f\left(C\right) f\left(D\right) \subseteq f(C\backslash D) ","My thinking: Let $x\in f\left(C\right)∖f\left(D\right)$ = $x\in f\left(C\right)$ and $x\notin f\left(D\right)$ If $x\in f\left(C\right)$ , $\exists \:x_1\in C$ such that $f\left(x_1\right)=x$ If $x\notin f\left(D\right)$ , $∄ \:x_2\in D$ such that $ f\left(x_2\right)=x$ I don't know where to go from here, can someone please provide a hint?","My thinking: Let = and If , such that If , such that I don't know where to go from here, can someone please provide a hint?",x\in f\left(C\right)∖f\left(D\right) x\in f\left(C\right) x\notin f\left(D\right) x\in f\left(C\right) \exists \:x_1\in C f\left(x_1\right)=x x\notin f\left(D\right) ∄ \:x_2\in D  f\left(x_2\right)=x,"['elementary-set-theory', 'proof-writing']"
47,would a set of all countable sets have any paradoxical properties?,would a set of all countable sets have any paradoxical properties?,,"I recently talked with a friend about set theory and he mentioned ""set of all countable sets"". I think that such set does not exist (just like ""set of all sets"" does not exist) and I would like to explain to him why I think so. I could just ask him to prove, using axioms of set theory, that it exists - and reject the existence of this set until its existence is proven. However, I would prefer to show that assumption of its existence would lead to some paradoxes. So, would a set of all countable sets have any paradoxical properties?","I recently talked with a friend about set theory and he mentioned ""set of all countable sets"". I think that such set does not exist (just like ""set of all sets"" does not exist) and I would like to explain to him why I think so. I could just ask him to prove, using axioms of set theory, that it exists - and reject the existence of this set until its existence is proven. However, I would prefer to show that assumption of its existence would lead to some paradoxes. So, would a set of all countable sets have any paradoxical properties?",,"['elementary-set-theory', 'paradoxes']"
48,Understanding a proof that $|\mathbb{R}^{\mathbb{N}}| = |\mathbb{R}|$,Understanding a proof that,|\mathbb{R}^{\mathbb{N}}| = |\mathbb{R}|,"I'm reading a set of lecture notes that gives a proof that $|\mathbb{R}^{\mathbb{N}}| = |\mathbb{R}|$ . I don't think I fully follow it, though it makes sense to me that this would give a bijection. It first notes that $|\mathbb{R}| = |(0,1)|$ , so it suffices to defines a bijection $(0,1) \to (0,1)^{\mathbb{N}}$ . We do so as follows. Given $x \in (0,1)$ with decimal expansion $x = 0.r_1 r_2 r_3 \ldots$ , define \begin{align*}  x_1 & = 0. r_1 r_3 r_5 r_7 \\ x_2 & = 0.r_2 r_6 r_{10} r_{14} \\  x_3 & = 0.r_4 r_{12} r_{20} r_{28} \\  & \vdots \\  \end{align*} so I believe the general formula (but I'm not fully sure) comes out to $$ x_n = \sum\limits_{i=1}^\infty r_{2n - i} \cdot 10^{-i}. $$ I don't fully understand why this is a bijection, though it seems I really only need it to be a surjection. I can certainly inject $(0,1)$ into $(0,1)^{\mathbb{N}}$ by taking $x \in (0,1)$ and sending it to a constant sequence, so if I can surject $(0,1)$ onto $(0,1)^{\mathbb{N}}$ , I can inject $(0,1)^{\mathbb{N}}$ into $(0,1)$ and conclude there exists a bijection by the Schroeder-Bernstein theorem. The proof, for the sake of well-definedness, surely requires that I make clear which decimal expansion of $x$ I'm using, so I think I need to say, ""if $x$ has two decimal expansions, pick the one that doesn't terminate in $9$ 's."" If I fix a decimal expansion (or a ""class"" of decimal expansions), I can claim this map is well-defined. This doesn't guarantee that the resulting expansion of each $x_n$ doesn't terminate in $9$ 's, so that may be the reason this is only a surjection. If I pick a sequence in $(0,1)$ , I can expand each $x_n$ in a decimal expansion. That gives me a construction of the above form, and then I should be able to reconstruct $x$ by the above pattern. I'm not completely certain about injectivity, but I think it likely will fail because of issues with infinite $9$ 's in the decimal expansions. I would appreciate any help with making sense of this.","I'm reading a set of lecture notes that gives a proof that . I don't think I fully follow it, though it makes sense to me that this would give a bijection. It first notes that , so it suffices to defines a bijection . We do so as follows. Given with decimal expansion , define so I believe the general formula (but I'm not fully sure) comes out to I don't fully understand why this is a bijection, though it seems I really only need it to be a surjection. I can certainly inject into by taking and sending it to a constant sequence, so if I can surject onto , I can inject into and conclude there exists a bijection by the Schroeder-Bernstein theorem. The proof, for the sake of well-definedness, surely requires that I make clear which decimal expansion of I'm using, so I think I need to say, ""if has two decimal expansions, pick the one that doesn't terminate in 's."" If I fix a decimal expansion (or a ""class"" of decimal expansions), I can claim this map is well-defined. This doesn't guarantee that the resulting expansion of each doesn't terminate in 's, so that may be the reason this is only a surjection. If I pick a sequence in , I can expand each in a decimal expansion. That gives me a construction of the above form, and then I should be able to reconstruct by the above pattern. I'm not completely certain about injectivity, but I think it likely will fail because of issues with infinite 's in the decimal expansions. I would appreciate any help with making sense of this.","|\mathbb{R}^{\mathbb{N}}| = |\mathbb{R}| |\mathbb{R}| = |(0,1)| (0,1) \to (0,1)^{\mathbb{N}} x \in (0,1) x = 0.r_1 r_2 r_3 \ldots \begin{align*} 
x_1 & = 0. r_1 r_3 r_5 r_7 \\
x_2 & = 0.r_2 r_6 r_{10} r_{14} \\ 
x_3 & = 0.r_4 r_{12} r_{20} r_{28} \\ 
& \vdots \\ 
\end{align*} 
x_n = \sum\limits_{i=1}^\infty r_{2n - i} \cdot 10^{-i}.
 (0,1) (0,1)^{\mathbb{N}} x \in (0,1) (0,1) (0,1)^{\mathbb{N}} (0,1)^{\mathbb{N}} (0,1) x x 9 x_n 9 (0,1) x_n x 9","['elementary-set-theory', 'proof-explanation']"
49,Finite Cartesian product of naturals is countably infinite + notation.,Finite Cartesian product of naturals is countably infinite + notation.,,"$\newcommand{\N}{\mathbb{N}}$ I tried to prove $ |\N| = |\N^n| $ for all $n \in \N$ by mathematical induction. base step: $|\N| = |\N|$ is trivial inductive step: Let $|\N| = |\N^n|$ . Then, there is a bijection $f: \N \to \N^n$ . We can define $g: \N \times \N \to \N \times \N^n$ such that $$ \forall i, j \in \N: g(i, j) = (i, f(j)) $$ $g$ is bijective. Let $h: \N \times \N \to \N^{n+1}$ be defined as $$ \forall i, j \in \N:\forall k \le n+1: (\pi_k \circ h)(i,j) = \begin{cases} i, & k = 1\\ (\pi_{k-1} \circ f)(j), & k \neq 1 \end{cases} $$ $h$ is also bijective. Since $|\N| = |\N \times \N|$ , there is a bijection from $\N$ onto $\N^{n+1}$ Questions : Is this a valid proof? I defined $h$ from $g$ using a canonical projection $\pi_k$ to explicitly show the existence of a bijection to $\N^{n+1}$ . This is somewhat redundant, but $g(i, j) = (g_1, (g_2, g_3,\cdots))$ is actually not what we are looking for. When I am supposed to write them in a technical paper, should I explicitly define $h$ ? This question is not confined to my proof.","I tried to prove for all by mathematical induction. base step: is trivial inductive step: Let . Then, there is a bijection . We can define such that is bijective. Let be defined as is also bijective. Since , there is a bijection from onto Questions : Is this a valid proof? I defined from using a canonical projection to explicitly show the existence of a bijection to . This is somewhat redundant, but is actually not what we are looking for. When I am supposed to write them in a technical paper, should I explicitly define ? This question is not confined to my proof.","\newcommand{\N}{\mathbb{N}}  |\N| = |\N^n|  n \in \N |\N| = |\N| |\N| = |\N^n| f: \N \to \N^n g: \N \times \N \to \N \times \N^n 
\forall i, j \in \N: g(i, j) = (i, f(j))
 g h: \N \times \N \to \N^{n+1} 
\forall i, j \in \N:\forall k \le n+1: (\pi_k \circ h)(i,j)
=
\begin{cases}
i, & k = 1\\
(\pi_{k-1} \circ f)(j), & k \neq 1
\end{cases}
 h |\N| = |\N \times \N| \N \N^{n+1} h g \pi_k \N^{n+1} g(i, j) = (g_1, (g_2, g_3,\cdots)) h","['elementary-set-theory', 'notation']"
50,Are there incomplete normed spaces of arbitrary size?,Are there incomplete normed spaces of arbitrary size?,,"For every infinite cardinal, there is a vector space whose dimension is that cardinal. Is the situation the same for incomplete normed spaces? Can we have algebraic dimension of arbitrary size?","For every infinite cardinal, there is a vector space whose dimension is that cardinal. Is the situation the same for incomplete normed spaces? Can we have algebraic dimension of arbitrary size?",,"['linear-algebra', 'functional-analysis', 'elementary-set-theory']"
51,Necessary and sufficient condition on the cardinal number of quotient set,Necessary and sufficient condition on the cardinal number of quotient set,,"I'm studying for an exam, and I have found question that I'm not sure about how to solve it. The question is: Let A be finite set. Let R be equivalence relation on A. 1.Write necessary and sufficient condition on the cardinal number of quotient set so R will be equality relation (equality relation is the relation R: xRy iff x=y. 2.Is the necessary and sufficient condition from (1.) true for infinite set A? My solution for 1 is: |A/R| = |A| iff R is the equality relation. I think its true because the number of all equivalence classes equal to the the number of elements in A. For example A = {1,2,3} [1]R = {1} [2]R = {2} [3]R = {3} My solution for 2 is: Yes, The cardinal of A/R is still equal to the cardinal of A. I would like to know where my mistakes are. Tell me please if the absence of Latex notations is a problem.","I'm studying for an exam, and I have found question that I'm not sure about how to solve it. The question is: Let A be finite set. Let R be equivalence relation on A. 1.Write necessary and sufficient condition on the cardinal number of quotient set so R will be equality relation (equality relation is the relation R: xRy iff x=y. 2.Is the necessary and sufficient condition from (1.) true for infinite set A? My solution for 1 is: |A/R| = |A| iff R is the equality relation. I think its true because the number of all equivalence classes equal to the the number of elements in A. For example A = {1,2,3} [1]R = {1} [2]R = {2} [3]R = {3} My solution for 2 is: Yes, The cardinal of A/R is still equal to the cardinal of A. I would like to know where my mistakes are. Tell me please if the absence of Latex notations is a problem.",,"['elementary-set-theory', 'relations', 'cardinals']"
52,How to show a statement of the form $p\Leftrightarrow(q\wedge r)$?,How to show a statement of the form ?,p\Leftrightarrow(q\wedge r),"I am trying to prove a statement of the form: \begin{gather} p\Leftrightarrow(q\wedge r) \end{gather} Therefore, I need to show the following two statements: \begin{gather} \text{(a) }\;p\Rightarrow(q\wedge r)\\ \text{(b) }\;(q\wedge r)\Rightarrow p \end{gather} Given the nature of the statement, my approach is to show the equivalent statements: \begin{gather} \text{(a’) }\;\neg(q\wedge r)\Rightarrow\neg p\\ \text{(b’) }\;\neg p\Rightarrow\neg(q\wedge r) \end{gather} What I am currently doing is this: To show (a’), I just show that $\neg q\Rightarrow\neg p$ and $\neg r\Rightarrow\neg p$ ; To show (b’), I just show that $\neg p\Rightarrow(\neg q\vee\neg r)$ . Unfortunately, I have two doubts regarding my approach: When showing (a’), is it enough with what I am doing or do I need to also show $(\neg q\wedge\neg r)\Rightarrow\neg p$ ? When showing (b’), is it enough with what I am doing or do I need to also show $\neg p\Rightarrow(\neg q\wedge\neg r)$ ? Thank you all very much for your time.","I am trying to prove a statement of the form: Therefore, I need to show the following two statements: Given the nature of the statement, my approach is to show the equivalent statements: What I am currently doing is this: To show (a’), I just show that and ; To show (b’), I just show that . Unfortunately, I have two doubts regarding my approach: When showing (a’), is it enough with what I am doing or do I need to also show ? When showing (b’), is it enough with what I am doing or do I need to also show ? Thank you all very much for your time.","\begin{gather}
p\Leftrightarrow(q\wedge r)
\end{gather} \begin{gather}
\text{(a) }\;p\Rightarrow(q\wedge r)\\
\text{(b) }\;(q\wedge r)\Rightarrow p
\end{gather} \begin{gather}
\text{(a’) }\;\neg(q\wedge r)\Rightarrow\neg p\\
\text{(b’) }\;\neg p\Rightarrow\neg(q\wedge r)
\end{gather} \neg q\Rightarrow\neg p \neg r\Rightarrow\neg p \neg p\Rightarrow(\neg q\vee\neg r) (\neg q\wedge\neg r)\Rightarrow\neg p \neg p\Rightarrow(\neg q\wedge\neg r)","['elementary-set-theory', 'logic', 'propositional-calculus']"
53,What does $F:2^\nu \rightarrow \mathbb{R}$ mean?,What does  mean?,F:2^\nu \rightarrow \mathbb{R},"While I was watching https://www.youtube.com/watch?v=Y3u_hvxayDY , which is about submodular optimization, I found $F:2^\nu \rightarrow \mathbb{R}$ in about 1:00 in the video. Could anyone please clarify what it means? I guess that means a function $F$ gets any subset of $\nu$ as an input and it outputs a real number. Am I correct?","While I was watching https://www.youtube.com/watch?v=Y3u_hvxayDY , which is about submodular optimization, I found in about 1:00 in the video. Could anyone please clarify what it means? I guess that means a function gets any subset of as an input and it outputs a real number. Am I correct?",F:2^\nu \rightarrow \mathbb{R} F \nu,['elementary-set-theory']
54,Exsistence of limit $\lim_{k\to \infty} \prod_{i=1}^{k}P(A_i)$ and $\lim_{k\to \infty}P(\bigcap_{i=1}^{k}A_i)$,Exsistence of limit  and,\lim_{k\to \infty} \prod_{i=1}^{k}P(A_i) \lim_{k\to \infty}P(\bigcap_{i=1}^{k}A_i),Let $(A_k)_{k\in\mathbb{N}}$ be a sequence of events. Argue that both limits exist $$\lim_{k\to \infty} \prod_{i=1}^{k}P(A_i)\quad \quad \lim_{k\to \infty}P(\bigcap_{i=1}^{k}A_i)$$ I am not sure on how to answer this at all. I would have thought that they didn't as my book states the definition of independent probability only for finite values of $J\subseteq I$ $$P(\bigcap_{i \in J}A_i)=\prod_{i\in J}P(A_i)$$ Now the question above is considering cases where $I$ is the natural numbers and and the cardinality of $J$ is $\infty$ . How do I argue that these limits exists?,Let be a sequence of events. Argue that both limits exist I am not sure on how to answer this at all. I would have thought that they didn't as my book states the definition of independent probability only for finite values of Now the question above is considering cases where is the natural numbers and and the cardinality of is . How do I argue that these limits exists?,(A_k)_{k\in\mathbb{N}} \lim_{k\to \infty} \prod_{i=1}^{k}P(A_i)\quad \quad \lim_{k\to \infty}P(\bigcap_{i=1}^{k}A_i) J\subseteq I P(\bigcap_{i \in J}A_i)=\prod_{i\in J}P(A_i) I J \infty,"['probability', 'limits', 'probability-theory', 'elementary-set-theory', 'conditional-probability']"
55,"If $f : A \to B$ and $B$ is countable, given that $f$ is surjective, $A$ is countable.","If  and  is countable, given that  is surjective,  is countable.",f : A \to B B f A,"I'm attempting to prove this statement, and I'm not sure if my deductions make sense, so I'd very much appreciate it if anyone could critique, comment or (most probably) improve my train of thought. Since we're given that $B$ is countable, then by definition there must exist some $g$ s.t. $g : \mathbb{N} \to B$ , with $g$ surjective. Then, it must be the case that $A$ is similarly countable because since $B$ is countable, and $f : A \to B$ , for this to hold it's necessary that $A\subseteq \mathbb{N}$ . Because $\mathbb{N}$ is countable, then $A$ is countable. Again, I'm definitely not sure that is correct, I'm still getting my head around how exactly I'm supposed to prove statements like these, so any criticism would be amazing.","I'm attempting to prove this statement, and I'm not sure if my deductions make sense, so I'd very much appreciate it if anyone could critique, comment or (most probably) improve my train of thought. Since we're given that is countable, then by definition there must exist some s.t. , with surjective. Then, it must be the case that is similarly countable because since is countable, and , for this to hold it's necessary that . Because is countable, then is countable. Again, I'm definitely not sure that is correct, I'm still getting my head around how exactly I'm supposed to prove statements like these, so any criticism would be amazing.",B g g : \mathbb{N} \to B g A B f : A \to B A\subseteq \mathbb{N} \mathbb{N} A,"['real-analysis', 'elementary-set-theory']"
56,transitive relation question,transitive relation question,,"I need to show if the following relation is transitive : $$ R\subseteq \mathcal{P}(\mathbb{N})\times\mathcal{P}(\mathbb{N}) \space \text{with} \space XRY \space :\Leftrightarrow \exists x \in\mathbb{N}:\space x\in X \space \land \space x\in Y $$ The answer says that it is not transitive because there is: $$ \{1,2\}R\{2,3\}\space \text{and} \space \{2,3\}R\{3,4\} \space \text{but}\space \space \text{not} \space  \{1,2\} \cap \{3,4\}=\emptyset $$ what does intersection have to do with it?",I need to show if the following relation is transitive : The answer says that it is not transitive because there is: what does intersection have to do with it?,"
R\subseteq \mathcal{P}(\mathbb{N})\times\mathcal{P}(\mathbb{N}) \space \text{with} \space XRY \space :\Leftrightarrow \exists x \in\mathbb{N}:\space x\in X \space \land \space x\in Y
  \{1,2\}R\{2,3\}\space \text{and} \space \{2,3\}R\{3,4\} \space \text{but}\space \space \text{not} \space
 \{1,2\} \cap \{3,4\}=\emptyset ","['elementary-set-theory', 'relations']"
57,Countability of the set of distinct sequences that all consist of the same elements,Countability of the set of distinct sequences that all consist of the same elements,,"Let us consider an infinite binary sequence $s$ (i.e., an infinite sequence of 0s and 1s). Let us then consider set $S(s)$ , which consists of all the different sequences that can be obtained by swapping the positions of the elements of $s$ . For example, if $s_1 = (1, 0, 0, 0, 0, 0,  \dots)$ , then $S(s_1) = \{ (1, 0, 0, 0, 0, 0, \dots), (0, 1, 0, 0, 0, 0, \dots), (0, 0, 1, 0, 0, 0, \dots), \dots \}$ . Clearly, in my example case, $S(s_1)$ is a countably infinite set. However, I'm interested in whether such an infinite binary sequence $s$ exists that $S(s)$ is an uncountable set. My intuition says that the set of all infinite binary sequences can be expressed as a countable union of sets $S(s_1), S(s_2), S(s_3), \dots$ for some sequences $s_1, s_2, s_3 \dots$ , which would mean that $S(s_i)$ must indeed be an uncountable set for some $s_i$ , since the set of all infinite binary sequences is uncountable. However, I cannot figure out any $s$ such that $S(s)$ would be an uncountable set.","Let us consider an infinite binary sequence (i.e., an infinite sequence of 0s and 1s). Let us then consider set , which consists of all the different sequences that can be obtained by swapping the positions of the elements of . For example, if , then . Clearly, in my example case, is a countably infinite set. However, I'm interested in whether such an infinite binary sequence exists that is an uncountable set. My intuition says that the set of all infinite binary sequences can be expressed as a countable union of sets for some sequences , which would mean that must indeed be an uncountable set for some , since the set of all infinite binary sequences is uncountable. However, I cannot figure out any such that would be an uncountable set.","s S(s) s s_1 = (1, 0, 0, 0, 0, 0,  \dots) S(s_1) = \{ (1, 0, 0, 0, 0, 0, \dots), (0, 1, 0, 0, 0, 0, \dots), (0, 0, 1, 0, 0, 0, \dots), \dots \} S(s_1) s S(s) S(s_1), S(s_2), S(s_3), \dots s_1, s_2, s_3 \dots S(s_i) s_i s S(s)","['sequences-and-series', 'combinatorics', 'elementary-set-theory', 'binary']"
58,Finite $\sigma$-algebras are generated by unique minimal finite partitions,Finite -algebras are generated by unique minimal finite partitions,\sigma,"I am trying to prove the following statement: Let $(X,\mathcal A)$ be a measure space s.t. the $\sigma$ -algebra $\mathcal A$ is finite, then there exists a unique minimal finite partition $\mathcal P=\{P_1,\dots,P_n\}$ of $X$ s.t. $\sigma(\mathcal P)=\mathcal A$ and for all $A\in\mathcal A$ holds $$(*)\qquad A\cap P_k\in\{\emptyset,P_k\}.$$ Here's what I have so far: Let $\mathcal A=\{\emptyset,X,A_1,\dots,A_m\}$ , where $A_i$ are the nontrivial elements of the algebra (assume $m>0$ , there is nothing to prove for $\mathcal A=\{\emptyset, X\}$ ), then $\bigcup_iA_i=X$ (otherwise $\left(\bigcup_iA_i\right)^c=A_j$ for some $j$ , which is a contradiction). Disjointise the $A_i$ and get $B_i\in\mathcal A$ s.t. $\bigcup_iB_i=X$ and $B_i\cap B_j=\emptyset$ for $i\neq j$ (standard measure theoretic trick). Each $B_i$ is either empty or equal to $A_{k_i}$ for some $k_i$ , so discard the empty ones and get $P_j:=A_{k_j},1\leq j\leq n$ , which parition $X$ . For $A\in\mathcal P$ the condition (*) is trivial [for $A\in\mathcal A$ arbitrary I'm having trouble showing this]. Now, assuming (*), we get for an arbitrary $A\in\mathcal A$ : $$A=A\cap X=\bigcup_jA\cap P_j=\bigcup_kP_k,$$ so $A\in\sigma(\mathcal P)$ and therefore $\mathcal A=\sigma(\mathcal P)$ . I'm having trouble showing that the partition I get this way is both unique and minimal and that it has property (*). Any tips on how to proceed? Also, if $\mathcal A,\mathcal P$ are as above, would it be correct to say that $|\mathcal A|=2^{|\mathcal P|}$ ? It seems plausible to me that intersection and complementation in this situation do not produce anything other than (disjoint) unions of elements of $\mathcal P$ , so the number of elements of $\mathcal A$ should be given by the number of subsets of $\mathcal P$ (each subset $\{P_{k_1},\dots,P_{k_n}\}$ determines the element $\bigcup_iP_{k_i}$ of $\mathcal A$ ). In particular, the cardinality of a finite $\sigma$ -algebra is always a power of $2$ . Would this be a correct argument?","I am trying to prove the following statement: Let be a measure space s.t. the -algebra is finite, then there exists a unique minimal finite partition of s.t. and for all holds Here's what I have so far: Let , where are the nontrivial elements of the algebra (assume , there is nothing to prove for ), then (otherwise for some , which is a contradiction). Disjointise the and get s.t. and for (standard measure theoretic trick). Each is either empty or equal to for some , so discard the empty ones and get , which parition . For the condition (*) is trivial [for arbitrary I'm having trouble showing this]. Now, assuming (*), we get for an arbitrary : so and therefore . I'm having trouble showing that the partition I get this way is both unique and minimal and that it has property (*). Any tips on how to proceed? Also, if are as above, would it be correct to say that ? It seems plausible to me that intersection and complementation in this situation do not produce anything other than (disjoint) unions of elements of , so the number of elements of should be given by the number of subsets of (each subset determines the element of ). In particular, the cardinality of a finite -algebra is always a power of . Would this be a correct argument?","(X,\mathcal A) \sigma \mathcal A \mathcal P=\{P_1,\dots,P_n\} X \sigma(\mathcal P)=\mathcal A A\in\mathcal A (*)\qquad A\cap P_k\in\{\emptyset,P_k\}. \mathcal A=\{\emptyset,X,A_1,\dots,A_m\} A_i m>0 \mathcal A=\{\emptyset, X\} \bigcup_iA_i=X \left(\bigcup_iA_i\right)^c=A_j j A_i B_i\in\mathcal A \bigcup_iB_i=X B_i\cap B_j=\emptyset i\neq j B_i A_{k_i} k_i P_j:=A_{k_j},1\leq j\leq n X A\in\mathcal P A\in\mathcal A A\in\mathcal A A=A\cap X=\bigcup_jA\cap P_j=\bigcup_kP_k, A\in\sigma(\mathcal P) \mathcal A=\sigma(\mathcal P) \mathcal A,\mathcal P |\mathcal A|=2^{|\mathcal P|} \mathcal P \mathcal A \mathcal P \{P_{k_1},\dots,P_{k_n}\} \bigcup_iP_{k_i} \mathcal A \sigma 2","['measure-theory', 'elementary-set-theory', 'solution-verification']"
59,$\dim(W + U) = \dim(W) + \dim(U) - \dim(W \cap U)$ have a correlation with $|A\cup B|=|A|+|B|-|A\cap B|$ with the sets?,have a correlation with  with the sets?,\dim(W + U) = \dim(W) + \dim(U) - \dim(W \cap U) |A\cup B|=|A|+|B|-|A\cap B|,"In mathematics, the Grassmann formula is a relation concerning the dimension of the vector subspaces of a vector space or of the projective subspace of a projective space. We know that the enunciation Grassmann's formula is: Let $V$ a  vector space  on a  field $\Bbb K$ that have finite dimension. If $W$ and $U$ be two subspaces of $V$ with $$W + U := \{\mathbf{w}+\mathbf{u}, \mathbf{w} \in W, \mathbf{u} \in U\}$$ then $$\dim(W + U) = \dim(W) + \dim(U) - \dim(W \cap U) \tag 1$$ Obviously, if the sum is direct (I use the $\oplus$ symbol), then the intersection between the two subspaces consists only of the null vector ( $W \cap U=\mathbf{0}$ ), hence $$\dim(W \oplus U) = \dim(W) + \dim(U)$$ Now my question is indirectly for my 14-year old students but it is useful for me if there is a relationship with the Grassmann formula . If I have any two sets $A, B$ , it is very easy to verify with the examples that: $$\bbox[yellow,5px,border:2px solid red]{|A\cup B|=|A|+|B|-|A\cap B|} \tag 2$$ But the $(2)$ has a correlation with $(1)$ and how you can adapt it to get a suitable answer-explanation very simple with an example?","In mathematics, the Grassmann formula is a relation concerning the dimension of the vector subspaces of a vector space or of the projective subspace of a projective space. We know that the enunciation Grassmann's formula is: Let a  vector space  on a  field that have finite dimension. If and be two subspaces of with then Obviously, if the sum is direct (I use the symbol), then the intersection between the two subspaces consists only of the null vector ( ), hence Now my question is indirectly for my 14-year old students but it is useful for me if there is a relationship with the Grassmann formula . If I have any two sets , it is very easy to verify with the examples that: But the has a correlation with and how you can adapt it to get a suitable answer-explanation very simple with an example?","V \Bbb K W U V W + U := \{\mathbf{w}+\mathbf{u}, \mathbf{w} \in W, \mathbf{u} \in U\} \dim(W + U) = \dim(W) + \dim(U) - \dim(W \cap U) \tag 1 \oplus W \cap U=\mathbf{0} \dim(W \oplus U) = \dim(W) + \dim(U) A, B \bbox[yellow,5px,border:2px solid red]{|A\cup B|=|A|+|B|-|A\cap B|} \tag 2 (2) (1)","['linear-algebra', 'elementary-set-theory', 'soft-question', 'intuition', 'education']"
60,How do I prove the following equality? $(C \cup (A^C \cup(B−A))^C)^C=(A−A)^C \cap((C^C \cap A)−(C^C \cap B))\cup C^C$,How do I prove the following equality?,(C \cup (A^C \cup(B−A))^C)^C=(A−A)^C \cap((C^C \cap A)−(C^C \cap B))\cup C^C,"Let the sets A, B, C ⊆ U be such that A ⊆ C. Prove the following equality by means of the laws of set algebra: $$\biggl(C \cup \Bigl(A^C \cup (B-A)\Bigr)^C\biggr)^C = (A-A)^C \cap \Bigl((C^C \cap A)-(C^C \cap B)\Bigr) \cup C^C$$ This is what I have done: $$\biggl(C \cup \Bigl(A^C \cup (B-A)\Bigr)^C\biggr)^C = (A-A)^C \cap \Bigl((C^C \cap A)-(C^C \cap B)\Bigr) \cup C^C$$ $$ \varnothing^C \cap \bigl((C^C \cap A) - (C^C \cap B)\bigr) \cup C^C    \text{ by Set Difference Law} $$ $$ U \cap \bigl((C^C \cap A) - (C^C \cap B)\bigr) \cup C^C       \text{ by Complement Law} $$ $$ \bigl((C^C \cap A) - (C^C \cap B)\bigr) \cup C^C              \text{ by Identity Law} $$ $$ \bigl((C^C \cap A) \cap (C^C \cap B)^C \bigr) \cup C^C        \text{ by Set Difference Law} $$ $$ \bigl((C^C \cap A) \cap C \cup B^C \bigr) \cup C^C            \text{ by De Morgan Law} $$ So, as you can see, I am pretty confused about how to go about solving this. Does anyone have any ideas? By the way, I would appreciate if you could state which theorems you applied to reach your answer. P.S. In case that you think that something that I wrote sounds somewhat weird, I translated this from Spanish.","Let the sets A, B, C ⊆ U be such that A ⊆ C. Prove the following equality by means of the laws of set algebra: This is what I have done: So, as you can see, I am pretty confused about how to go about solving this. Does anyone have any ideas? By the way, I would appreciate if you could state which theorems you applied to reach your answer. P.S. In case that you think that something that I wrote sounds somewhat weird, I translated this from Spanish.",\biggl(C \cup \Bigl(A^C \cup (B-A)\Bigr)^C\biggr)^C = (A-A)^C \cap \Bigl((C^C \cap A)-(C^C \cap B)\Bigr) \cup C^C \biggl(C \cup \Bigl(A^C \cup (B-A)\Bigr)^C\biggr)^C = (A-A)^C \cap \Bigl((C^C \cap A)-(C^C \cap B)\Bigr) \cup C^C  \varnothing^C \cap \bigl((C^C \cap A) - (C^C \cap B)\bigr) \cup C^C    \text{ by Set Difference Law}   U \cap \bigl((C^C \cap A) - (C^C \cap B)\bigr) \cup C^C       \text{ by Complement Law}   \bigl((C^C \cap A) - (C^C \cap B)\bigr) \cup C^C              \text{ by Identity Law}   \bigl((C^C \cap A) \cap (C^C \cap B)^C \bigr) \cup C^C        \text{ by Set Difference Law}   \bigl((C^C \cap A) \cap C \cup B^C \bigr) \cup C^C            \text{ by De Morgan Law} ,['elementary-set-theory']
61,"Understanding n-ary Cartesian product, understanding formula","Understanding n-ary Cartesian product, understanding formula",,"While I understand the cartesian product I'm having trouble reading its set definition. What I'm having trouble with is the $x_i$ part and my misunderstanding is that there is the variable $i$ that I assumed could be only one value at a time: $X_i$ represents all the sets from $X_1$ to $X_n$ , $x_i$ represents the elements of those sets, if $i = 1$ then $x_i$ is a member of $X_1$ and further more is the first element of $X_1$ , when $i = 2$ $x_i$ is the second member of $X_2$ . I would have used two variables, one $i$ for $x_i$ and $j$ for the set. This is not correct so I would like some help translating this. I know the cartesian product is all the $n$ -tuple possibilities taking every elements of every sets but I can't translate the formula above to that definition. This formula for two sets' cartesian product makes much more sense to me:","While I understand the cartesian product I'm having trouble reading its set definition. What I'm having trouble with is the part and my misunderstanding is that there is the variable that I assumed could be only one value at a time: represents all the sets from to , represents the elements of those sets, if then is a member of and further more is the first element of , when is the second member of . I would have used two variables, one for and for the set. This is not correct so I would like some help translating this. I know the cartesian product is all the -tuple possibilities taking every elements of every sets but I can't translate the formula above to that definition. This formula for two sets' cartesian product makes much more sense to me:",x_i i X_i X_1 X_n x_i i = 1 x_i X_1 X_1 i = 2 x_i X_2 i x_i j n,['elementary-set-theory']
62,Show that there exists a finite disjoint collection $\{E_k\}_{k=1}^M$ of boxes such that $\bigcup_{i}^N R_i = \bigsqcup_{k=1}^M E_k$.,Show that there exists a finite disjoint collection  of boxes such that .,\{E_k\}_{k=1}^M \bigcup_{i}^N R_i = \bigsqcup_{k=1}^M E_k,"Let $\{R_i\}_{i=1}^N$ be finite collection of $n-$ dimensional boxes formed by the cartesian products of intervals of $\Bbb R$ . Show that there exists a finite disjoint collection $\{E_k\}_{k=1}^M$ of boxes such that $\bigcup_{i}^N R_i = \bigsqcup_{k=1}^M E_k$ . I’ve been stuck with this for a good while now. From wikipedia the definition for $\bigsqcup_{k=1}^M E_k $ seems to be that $\bigsqcup_{k=1}^M E_k = \bigcup_{k=1}^M \{(x,k) : x \in E_k \}$ , which I don’t really understand. I tought that I could approach this by elementary set theory just by looking at the elements of either set individually, but I didn’t get anywhere. If I pick $R_i \in \bigcup_{i}^N R_i $ , then $R_i = I_1 \times I_2 \times \cdots$ , but I don’t see how I can show that this $R_i \in \bigsqcup_{k=1}^M E_k $ ?","Let be finite collection of dimensional boxes formed by the cartesian products of intervals of . Show that there exists a finite disjoint collection of boxes such that . I’ve been stuck with this for a good while now. From wikipedia the definition for seems to be that , which I don’t really understand. I tought that I could approach this by elementary set theory just by looking at the elements of either set individually, but I didn’t get anywhere. If I pick , then , but I don’t see how I can show that this ?","\{R_i\}_{i=1}^N n- \Bbb R \{E_k\}_{k=1}^M \bigcup_{i}^N R_i = \bigsqcup_{k=1}^M E_k \bigsqcup_{k=1}^M E_k  \bigsqcup_{k=1}^M E_k = \bigcup_{k=1}^M \{(x,k) : x \in E_k \} R_i \in \bigcup_{i}^N R_i  R_i = I_1 \times I_2 \times \cdots R_i \in \bigsqcup_{k=1}^M E_k ","['real-analysis', 'elementary-set-theory']"
63,Treating Relations as Sets,Treating Relations as Sets,,"I've been learning about relations and so far and I think I understand the basics just fine. If $R$ is a relation from $A$ to $B$ , then $R \subseteq A \times B$ . The ordered pairs in $R$ define a relation between the objects in A and B, so $a \in A$ is related to $b \in B$ by $R$ if $(a, b) \in R$ . I'm also fine with notions such as 'relations on a set', where $R \subseteq A \times A$ . I'm also fine with concepts such as reflexive, symmetric and transitive relations. I can wrap my head around treating the symbol $\leq$ as a set. For example, we define $\mathbb{N} = \{0, 1, 2, ...\}$ , and we define conditions under which $x \leq y$ , for all $x, y \in \mathbb{N}$ . I suppose it'd be something like: $\leq \, = \{ (x, y) \in \mathbb{N} \times \mathbb{N} \text{ | } y = x + d \text{ for some } d \in \mathbb{N} \}$ We can then construct $\mathbb{Z}$ and overload the $\leq$ symbol for the ordering relation in the set of integers, and the process repeats for $\mathbb{Q}$ and $\mathbb{R}$ . We can then show $\leq$ is reflexive, anti-symmetric and transitive, and everything works out just fine. The process above is what I'm comfortable with. However, I'm having a bit of trouble wrapping my head around $\subseteq$ , $\in$ and $=$ . Relations like $\leq$ make sense for me because we start from sets, and then we define the reals, and then further define $\leq \, \subseteq \mathbb{R} \times \mathbb{R}$ (depending on the construction method $\leq$ might be defined differently but the end result is still the same). After the stage is set, we just proceed using $\leq$ as I was taught in secondary school with no trouble. However, for $\subseteq$ , I see books are referring to this symbol as a relation, but it seems like the situation is entirely different. If the domain of $\leq$ is the set of reals, then what is the domain of $\subseteq$ ? The set of all sets? Isn't this set not allowed to exist in ZF? If the domain is not the set of all sets, then do we literally have to define a new domain based on the sets we are comparing every time we use $\subseteq$ ? It's not like it's impossible, and it's not like these concerns will affect the actual process of doing math, but I just find that technically such a cumbersome process is required when we use $\subseteq$ is a bit unsatisfying. My concerns for $\in$ and $=$ are also similar. It seems like this problem arises because $\subseteq$ , $\in$ and $=$ are used to express relationships between sets, unlike $\leq$ which is designed to operate in the little pocket universe of $\mathbb{R}$ which we have defined for ourselves. (Thanks in advance for taking the time to go through my long question. I'm a physics student who has recently acquired a taste for more rigorous mathematics, and so far I know about mathematical logic, sets and things like the Peano axioms at the level of an introductory course for undergraduates. At this point, I think I understand the ZF axioms so I should be able to comprehend any answer that might touch upon these concepts. I am currently reading Mathematical Proofs: A Transition to Advanced Mathematics and a bit of Tao's Analysis I.)","I've been learning about relations and so far and I think I understand the basics just fine. If is a relation from to , then . The ordered pairs in define a relation between the objects in A and B, so is related to by if . I'm also fine with notions such as 'relations on a set', where . I'm also fine with concepts such as reflexive, symmetric and transitive relations. I can wrap my head around treating the symbol as a set. For example, we define , and we define conditions under which , for all . I suppose it'd be something like: We can then construct and overload the symbol for the ordering relation in the set of integers, and the process repeats for and . We can then show is reflexive, anti-symmetric and transitive, and everything works out just fine. The process above is what I'm comfortable with. However, I'm having a bit of trouble wrapping my head around , and . Relations like make sense for me because we start from sets, and then we define the reals, and then further define (depending on the construction method might be defined differently but the end result is still the same). After the stage is set, we just proceed using as I was taught in secondary school with no trouble. However, for , I see books are referring to this symbol as a relation, but it seems like the situation is entirely different. If the domain of is the set of reals, then what is the domain of ? The set of all sets? Isn't this set not allowed to exist in ZF? If the domain is not the set of all sets, then do we literally have to define a new domain based on the sets we are comparing every time we use ? It's not like it's impossible, and it's not like these concerns will affect the actual process of doing math, but I just find that technically such a cumbersome process is required when we use is a bit unsatisfying. My concerns for and are also similar. It seems like this problem arises because , and are used to express relationships between sets, unlike which is designed to operate in the little pocket universe of which we have defined for ourselves. (Thanks in advance for taking the time to go through my long question. I'm a physics student who has recently acquired a taste for more rigorous mathematics, and so far I know about mathematical logic, sets and things like the Peano axioms at the level of an introductory course for undergraduates. At this point, I think I understand the ZF axioms so I should be able to comprehend any answer that might touch upon these concepts. I am currently reading Mathematical Proofs: A Transition to Advanced Mathematics and a bit of Tao's Analysis I.)","R A B R \subseteq A \times B R a \in A b \in B R (a, b) \in R R \subseteq A \times A \leq \mathbb{N} = \{0, 1, 2, ...\} x \leq y x, y \in \mathbb{N} \leq \, = \{ (x, y) \in \mathbb{N} \times \mathbb{N} \text{ | } y = x + d \text{ for some } d \in \mathbb{N} \} \mathbb{Z} \leq \mathbb{Q} \mathbb{R} \leq \subseteq \in = \leq \leq \, \subseteq \mathbb{R} \times \mathbb{R} \leq \leq \subseteq \leq \subseteq \subseteq \subseteq \in = \subseteq \in = \leq \mathbb{R}",['elementary-set-theory']
64,Show that $AΔB=C$ if and only if $A=BΔC$.,Show that  if and only if .,AΔB=C A=BΔC,"Show that $AΔB=C$ if and only if $A=BΔC$ . I read this answer : Here's the long messy way. We want to show $A\triangle B = C \iff A = B\triangle C$ $\Rightarrow$ : Assume $C = A\triangle B$ Recall $A\triangle B = (A\cup B) - (A\cap B) = (B-A)\cup(A-B)$ $$\begin{align} (B\cup C) - (B\cap C) &= (B\cup [(A - B) \cup (B - A)]) - (B\cap [(A\cup B) - (A\cap B)]) \\ &= ([B\cup (A- B)] \cup (B - A)) - ([B\cap (A\cup B)] - [B\cap (A\cap B)]) \\ &= ((A\cup B) \cup (B - A)) - \color{red}{(B - (A\cap B))}\\ &= ((A\cup B) \cup (B - A)) - \color{red}{(B - A)}\\ &= (A\cup B) - (B - A)\\ &= A \end{align}$$ $\Leftarrow$ is, dare is say, symmetric. My question is in the part highlighted in red. Why is $A \cap B = A$ ?","Show that if and only if . I read this answer : Here's the long messy way. We want to show : Assume Recall is, dare is say, symmetric. My question is in the part highlighted in red. Why is ?","AΔB=C A=BΔC A\triangle B = C \iff A = B\triangle C \Rightarrow C = A\triangle B A\triangle B = (A\cup B) - (A\cap B) = (B-A)\cup(A-B) \begin{align}
(B\cup C) - (B\cap C) &= (B\cup [(A - B) \cup (B - A)]) - (B\cap [(A\cup B) - (A\cap B)]) \\
&= ([B\cup (A- B)] \cup (B - A)) - ([B\cap (A\cup B)] - [B\cap (A\cap B)]) \\
&= ((A\cup B) \cup (B - A)) - \color{red}{(B - (A\cap B))}\\
&= ((A\cup B) \cup (B - A)) - \color{red}{(B - A)}\\
&= (A\cup B) - (B - A)\\
&= A
\end{align} \Leftarrow A \cap B = A",['elementary-set-theory']
65,Basic set theory question,Basic set theory question,,"As I understand it, Cantor defined two sets as having the same cardinality iff their members can be paired 1-to-1.  He applied this to infinite sets, so ostensibly the integers (Z) and the even integers (E) have the same cardinality because we can pair each element of Z with exactly one element of E. For infinite sets, this definition seems problematic no matter which direction we come at it from:  We don't know up front that two infinite sets have the same cardinality, so we cannot conclude that their elements can be exactly paired.  And we do not know up front that two infinite sets' elements can be paired up exactly (because we don't know with certainty what happens beyond the finite cases we can verify).  So we cannot conclude that their cardinalities are the same.  The definition above therefore seems useless, since we cannot start from either side of the ""iff"". It might be argued that if we state it as follows:  ""For each element e of E, pair it with element e/2 of Z,"" then we have expressed the general case symbolically, and it works.  But we can only verify that for finite values of E and Z.  We can't know what happens beyond finite elements of those sets.  So expressing it symbolically does not seem to help. Why is Cantor's definition not circular and therefore useless for deciding the question of infinite set cardinalities?","As I understand it, Cantor defined two sets as having the same cardinality iff their members can be paired 1-to-1.  He applied this to infinite sets, so ostensibly the integers (Z) and the even integers (E) have the same cardinality because we can pair each element of Z with exactly one element of E. For infinite sets, this definition seems problematic no matter which direction we come at it from:  We don't know up front that two infinite sets have the same cardinality, so we cannot conclude that their elements can be exactly paired.  And we do not know up front that two infinite sets' elements can be paired up exactly (because we don't know with certainty what happens beyond the finite cases we can verify).  So we cannot conclude that their cardinalities are the same.  The definition above therefore seems useless, since we cannot start from either side of the ""iff"". It might be argued that if we state it as follows:  ""For each element e of E, pair it with element e/2 of Z,"" then we have expressed the general case symbolically, and it works.  But we can only verify that for finite values of E and Z.  We can't know what happens beyond finite elements of those sets.  So expressing it symbolically does not seem to help. Why is Cantor's definition not circular and therefore useless for deciding the question of infinite set cardinalities?",,['elementary-set-theory']
66,How to prove that these two sets are equal? [closed],How to prove that these two sets are equal? [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question I think I can prove that $$\bigcup_{i=1}^{n}A_i\setminus\bigcap_{i=1}^{n} A_i =(A_1\setminus A_2)\cup(A_2\setminus A_3)\cup\cdots\cup(A_{n-1}\setminus A_n)\cup(A_n\setminus A_1).$$ so,I think maybe there has(treat infinity as a circle): $$\bigcup_{n=1}^{\infty}A_n\setminus\bigcap_{n=1}^{\infty} A_n=(A_1\setminus A_2)\cup(A_2\setminus A_3)\cup\cdots$$ but I dot't know how to prove it.","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question I think I can prove that so,I think maybe there has(treat infinity as a circle): but I dot't know how to prove it.","\bigcup_{i=1}^{n}A_i\setminus\bigcap_{i=1}^{n} A_i
=(A_1\setminus A_2)\cup(A_2\setminus A_3)\cup\cdots\cup(A_{n-1}\setminus A_n)\cup(A_n\setminus A_1). \bigcup_{n=1}^{\infty}A_n\setminus\bigcap_{n=1}^{\infty} A_n=(A_1\setminus A_2)\cup(A_2\setminus A_3)\cup\cdots",['elementary-set-theory']
67,"What's wrong with the naive ""take successive smallest"" procedure in proving well-ordered subsets of $\mathbb R$ are countable?","What's wrong with the naive ""take successive smallest"" procedure in proving well-ordered subsets of  are countable?",\mathbb R,"For context, I have no set theory background and my understanding of sets is naive. I had a discussion with a friend that I thought for any well-ordered subset of the reals, I could simply take the least element, second least, etc. to show it is countable. It is the same procedure described in Is a well-ordered subset of $(\mathbb{R},<)$ countable? . However he told me I had to make use of ordinals (which I don't know about) to index into the set. Is there an intuitive (or at least relatively elementary) reason why I can't count up using my naive procedure to conclude the subset is countable? The main concern I see is about if I ever ""finish counting"" which I don't know how to reason about and seems subtle.","For context, I have no set theory background and my understanding of sets is naive. I had a discussion with a friend that I thought for any well-ordered subset of the reals, I could simply take the least element, second least, etc. to show it is countable. It is the same procedure described in Is a well-ordered subset of $(\mathbb{R},<)$ countable? . However he told me I had to make use of ordinals (which I don't know about) to index into the set. Is there an intuitive (or at least relatively elementary) reason why I can't count up using my naive procedure to conclude the subset is countable? The main concern I see is about if I ever ""finish counting"" which I don't know how to reason about and seems subtle.",,"['elementary-set-theory', 'real-numbers', 'well-orders']"
68,Proof of indexed inverse image statement,Proof of indexed inverse image statement,,"Prove that: $f^{-1}(\bigcap_{\lambda \in \Lambda}B_{\lambda})=\bigcap_{\lambda \in \Lambda}f^{-1}(B_{\lambda})$ My proof: Suppose, $x\in f^{-1}(\bigcap_{\lambda \in \Lambda }B_{\lambda}) \iff f(x) \in \bigcap_{\lambda \in \Lambda}B_{\lambda}. \iff f(x) \in B_{\lambda}, \forall \lambda \in \Lambda \iff x\in f^{-1}(B_{\lambda}),\forall \lambda \in \lambda. \iff x\in \bigcap_{\lambda \in \Lambda} f^{-1}(B_{\lambda}).$ Am I correct?","Prove that: My proof: Suppose, Am I correct?","f^{-1}(\bigcap_{\lambda \in \Lambda}B_{\lambda})=\bigcap_{\lambda \in \Lambda}f^{-1}(B_{\lambda}) x\in f^{-1}(\bigcap_{\lambda \in \Lambda }B_{\lambda}) \iff f(x) \in \bigcap_{\lambda \in \Lambda}B_{\lambda}. \iff f(x) \in B_{\lambda}, \forall \lambda \in \Lambda \iff x\in f^{-1}(B_{\lambda}),\forall \lambda \in \lambda. \iff x\in \bigcap_{\lambda \in \Lambda} f^{-1}(B_{\lambda}).","['real-analysis', 'elementary-set-theory', 'solution-verification']"
69,Finding an English translation to Kazimierz Kuratowski's finiteness paper.,Finding an English translation to Kazimierz Kuratowski's finiteness paper.,,"Dear Maths Stackexchange. I am currently doing some reading into the different notions of how finiteness is modelled in set theory. One formulation that took my eye was Kazimierz Kuratowski's formulation which seems to me rather elegant. Whist I have no problem with understanding the mathematics of this formulation, I am nonetheless interested in viewing the original  source paper for this construction. The earliest text I can find is given in this short three page paper here in French. Unfortunately I cannot read French, so this is of little use to me in the given state. I have done some poking around on google and google scholar and come up blank when looking for translations of said paper into English. Thus I open the following question up with the hopes that someone knows the location of an appropriate reference: Is there an English source to this paper?","Dear Maths Stackexchange. I am currently doing some reading into the different notions of how finiteness is modelled in set theory. One formulation that took my eye was Kazimierz Kuratowski's formulation which seems to me rather elegant. Whist I have no problem with understanding the mathematics of this formulation, I am nonetheless interested in viewing the original  source paper for this construction. The earliest text I can find is given in this short three page paper here in French. Unfortunately I cannot read French, so this is of little use to me in the given state. I have done some poking around on google and google scholar and come up blank when looking for translations of said paper into English. Thus I open the following question up with the hopes that someone knows the location of an appropriate reference: Is there an English source to this paper?",,"['elementary-set-theory', 'reference-request']"
70,How to prove |$Z^4$|=|Z|=$\aleph_0$,How to prove ||=|Z|=,Z^4 \aleph_0,"I have Theorem 1: The cardinality of the natural numbers is denoted as $ℵ_0$ . That is, |N| = $ℵ_0$ . Thus any countably infinite set has cardinality $ℵ_0$ . Theorem 2: If A and B are both countably infinite, then so is A ×B. Can I use just these 2 theorems to prove  | $Z^4$ |=|Z|= $\aleph_0$ ? My proof: Since Z is countably infinite, then Z ×Z is countably infinite( Theorem 2), and |Z|=|N|= $ℵ_0$ , Thus | $Z^2$ |= $ℵ_0$ .( Theorem 1) Using the same method for proving| $Z^4$ |.","I have Theorem 1: The cardinality of the natural numbers is denoted as . That is, |N| = . Thus any countably infinite set has cardinality . Theorem 2: If A and B are both countably infinite, then so is A ×B. Can I use just these 2 theorems to prove  | |=|Z|= ? My proof: Since Z is countably infinite, then Z ×Z is countably infinite( Theorem 2), and |Z|=|N|= , Thus | |= .( Theorem 1) Using the same method for proving| |.",ℵ_0 ℵ_0 ℵ_0 Z^4 \aleph_0 ℵ_0 Z^2 ℵ_0 Z^4,"['elementary-set-theory', 'proof-writing']"
71,Venn diagram problem with three beverages liking,Venn diagram problem with three beverages liking,,"In a group of people who like beverages tea, coffee and milk, 9 people like tea, 9 people like coffee and 15 people like milk. If 5 people like tea and milk, 7 people like coffee and milk and 3 people like all three beverages. How many people like tea and coffee but not milk? The total number of people is 20. To my understanding, there are 15 people who like milk. These 15 includes 3 that likes all the three. Since 5 likes both tea and milk, this is included with the 3 that likes all the three beverages. So, 2 likes both tea and milk only as per the Venn diagram. Similarly, 4 likes only coffee and milk. Going by this, I tried to find those that like only tea and coffee (x) which is 9-5-x under tea side (refer attached diagram). The x should be the same as 9-7-x for coffee. The equation 9-5-x=9-7-x is not solvable. I know I am wrong somewhere. Help appreciated.","In a group of people who like beverages tea, coffee and milk, 9 people like tea, 9 people like coffee and 15 people like milk. If 5 people like tea and milk, 7 people like coffee and milk and 3 people like all three beverages. How many people like tea and coffee but not milk? The total number of people is 20. To my understanding, there are 15 people who like milk. These 15 includes 3 that likes all the three. Since 5 likes both tea and milk, this is included with the 3 that likes all the three beverages. So, 2 likes both tea and milk only as per the Venn diagram. Similarly, 4 likes only coffee and milk. Going by this, I tried to find those that like only tea and coffee (x) which is 9-5-x under tea side (refer attached diagram). The x should be the same as 9-7-x for coffee. The equation 9-5-x=9-7-x is not solvable. I know I am wrong somewhere. Help appreciated.",,['elementary-set-theory']
72,Show that in general $A \cup (B \times C) \neq (A \cup B) \times (A \cup C)$.,Show that in general .,A \cup (B \times C) \neq (A \cup B) \times (A \cup C),"I have been reading the real analysis textbook ""Modern Real Analysis"" by William Ziemer. I have come to an exercise that seemed strange to me. I was able to answer it I believe, but it seemed to me that there may be an error in the book here. The question is : Show that $A \times (B \cup C) = (A \times B) \cup (A \times C)$ . Also, show that in general, $A \cup (B \times C) \neq (A \cup B) \times (A \cup C)$ . I was able to do the first part easily, but I was confused by the second. It seems easy to construct an example where the equality doesn't hold. For instance : \begin{align} A & = \{0,1\}\\ B & = \{2,3\}\\ C & = \{4,5\} \end{align} So : \begin{align} A \cup (B \times C)    & = \{0,1\} \cup \{ (2,4) , (2,5) , (3,4) , (3,5) \}\\   & = \{0,1,(2,4),(2,5),(3,4),(3,5) \} \end{align} and : \begin{align} A \cup B & = \{0,1,2,3\}\\ A \cup C & = \{0,1,4,5\} \end{align} So : \begin{equation} 0 \not \in (A \cup B) \times (A \cup C) \end{equation} and therefore : \begin{equation} A \cup (B \times C) \neq (A \cup B) \times (A \cup C) \; \checkmark \end{equation} But this second part of the problem seems strange. Is this a likely error in the book, or is there something that I am not seeing ?","I have been reading the real analysis textbook ""Modern Real Analysis"" by William Ziemer. I have come to an exercise that seemed strange to me. I was able to answer it I believe, but it seemed to me that there may be an error in the book here. The question is : Show that . Also, show that in general, . I was able to do the first part easily, but I was confused by the second. It seems easy to construct an example where the equality doesn't hold. For instance : So : and : So : and therefore : But this second part of the problem seems strange. Is this a likely error in the book, or is there something that I am not seeing ?","A \times (B \cup C) = (A \times B) \cup (A \times C) A \cup (B \times C) \neq (A \cup B) \times (A \cup C) \begin{align}
A & = \{0,1\}\\
B & = \{2,3\}\\
C & = \{4,5\}
\end{align} \begin{align}
A \cup (B \times C) 
  & = \{0,1\} \cup \{ (2,4) , (2,5) , (3,4) , (3,5) \}\\
  & = \{0,1,(2,4),(2,5),(3,4),(3,5) \}
\end{align} \begin{align}
A \cup B & = \{0,1,2,3\}\\
A \cup C & = \{0,1,4,5\}
\end{align} \begin{equation}
0 \not \in (A \cup B) \times (A \cup C)
\end{equation} \begin{equation}
A \cup (B \times C) \neq (A \cup B) \times (A \cup C) \; \checkmark
\end{equation}",['elementary-set-theory']
73,Prove that $\bigcup\limits_{i=1}^{n} B_{i}=\bigcup\limits_{i=1}^{n} A_{i}$,Prove that,\bigcup\limits_{i=1}^{n} B_{i}=\bigcup\limits_{i=1}^{n} A_{i},"It is given that $\{{A_n\}}$ is a monotone nondecreasing sequence of sets while $\{{B_n\}}$ is defined as: $B_1=A_1,B_2=A_2-A_1$ or in general: $B_n=A_n-A_{n-1}$ . Prove that $\bigcup\limits_{i=1}^{n} B_{i}=\bigcup\limits_{i=1}^{n} A_{i}$ for any $n\in\{2,3,\dots\}$ by mathematical induction. I was already able to prove that $\bigcup\limits_{i=1}^{2} B_{i}=\bigcup\limits_{i=1}^{2} A_{i}$ by using the definitions & properties of sets. For step 2, I have $\bigcup\limits_{i=1}^{k} B_{i}=\bigcup\limits_{i=1}^{k} A_{i}$ where $B_k=A_k-A_{k-1}$ . For step 3, show $\bigcup\limits_{i=1}^{k+1} B_{i}=\bigcup\limits_{i=1}^{k+1} A_{i}$ that is, $\bigcup\limits_{i=1}^{k+1} B_{i}= A_{k+1}$ . $$\bigcup\limits_{i=1}^{k+1} B_{i}=(A_{k+1}-A_k)$$ I get lost with how to show that this is equal to $A_{k+1}$ . $$(A_{k+1}-A_k)=A_{k+1}~\cap~A_k^c$$ Would it be right to assume that $A_k^c=\Omega$ ? Please let me know if I've missed something.","It is given that is a monotone nondecreasing sequence of sets while is defined as: or in general: . Prove that for any by mathematical induction. I was already able to prove that by using the definitions & properties of sets. For step 2, I have where . For step 3, show that is, . I get lost with how to show that this is equal to . Would it be right to assume that ? Please let me know if I've missed something.","\{{A_n\}} \{{B_n\}} B_1=A_1,B_2=A_2-A_1 B_n=A_n-A_{n-1} \bigcup\limits_{i=1}^{n} B_{i}=\bigcup\limits_{i=1}^{n} A_{i} n\in\{2,3,\dots\} \bigcup\limits_{i=1}^{2} B_{i}=\bigcup\limits_{i=1}^{2} A_{i} \bigcup\limits_{i=1}^{k} B_{i}=\bigcup\limits_{i=1}^{k} A_{i} B_k=A_k-A_{k-1} \bigcup\limits_{i=1}^{k+1} B_{i}=\bigcup\limits_{i=1}^{k+1} A_{i} \bigcup\limits_{i=1}^{k+1} B_{i}= A_{k+1} \bigcup\limits_{i=1}^{k+1} B_{i}=(A_{k+1}-A_k) A_{k+1} (A_{k+1}-A_k)=A_{k+1}~\cap~A_k^c A_k^c=\Omega",['elementary-set-theory']
74,Is my proof for $(A \cap B) \cup C = A \cap (B \cup C)$ only when $C \subseteq A$ correct?,Is my proof for  only when  correct?,(A \cap B) \cup C = A \cap (B \cup C) C \subseteq A,"I was working through the Chapter 3 supplementary exercises in Grimaldi's textbook, and I wanted to see if my way of answering a problem is correct.  The exercise asks you to prove $(A \cap B) \cup C = A \cap (B \cup C)$ if and only if $C \subseteq A$ .  The book answer has a rather involved proof, but in my mind it's rather simple.  I'm fairly positive that I'm missing something, though, so I wanted to share my proof for others' thoughts. Beginning with $(A \cap B) \cup C$ , by the distributive law we get $(A \cup C) \cap (B \cup C)$ .  Now, if $(A \cup C) \cap (B \cup C) = A \cap (B \cup C)$ , that can only be true when $A \cup C = A$ .  Otherwise, the intersection of $A \cup C$ and $B \cup C$ would include any elements in $C$ but not in $A$ , which means the intersection of $(A \cup C) \cap (B \cup C)$ would necessarily have more elements (because it would include other elements in $C$ ) than what is in $A \cap (B \cup C)$ alone. Therefore, for those two intersections to be equal, $A \cup C = A$ .  And if $A \cup C = A$ , then by definition $C \subseteq A$ .  Thus, we're done. Any thoughts would be greatly appreciated.  Thank you!","I was working through the Chapter 3 supplementary exercises in Grimaldi's textbook, and I wanted to see if my way of answering a problem is correct.  The exercise asks you to prove if and only if .  The book answer has a rather involved proof, but in my mind it's rather simple.  I'm fairly positive that I'm missing something, though, so I wanted to share my proof for others' thoughts. Beginning with , by the distributive law we get .  Now, if , that can only be true when .  Otherwise, the intersection of and would include any elements in but not in , which means the intersection of would necessarily have more elements (because it would include other elements in ) than what is in alone. Therefore, for those two intersections to be equal, .  And if , then by definition .  Thus, we're done. Any thoughts would be greatly appreciated.  Thank you!",(A \cap B) \cup C = A \cap (B \cup C) C \subseteq A (A \cap B) \cup C (A \cup C) \cap (B \cup C) (A \cup C) \cap (B \cup C) = A \cap (B \cup C) A \cup C = A A \cup C B \cup C C A (A \cup C) \cap (B \cup C) C A \cap (B \cup C) A \cup C = A A \cup C = A C \subseteq A,['elementary-set-theory']
75,How should exercise 1-5.7(B) from Stoll be read?,How should exercise 1-5.7(B) from Stoll be read?,,"I asked a question about this exercise in the past ( Is there a standard way to represent a general set theoretical equation in one variable. ), and don't mean to ""re-ask"".  But I'm unclear as to how I should read the phrase ""only complements of individual sets,"" in Stoll's outline of a proof. Specifically, does it mean that both an individual set and its complement may appear; or does it mean that only the complements of the given constant sets should appear? I believe it means the former, but the wording is a bit nebulous (to me). This is exercise 1-5.7(B) from Stoll, Robert R.. Set Theory and Logic (Dover Books on Mathematics) (Kindle Location 787). Dover Publications. Kindle Edition. Prove that an equation in $\mathcal{X}$ with righthand member $\emptyset$ can be reduced to one of the form $\left(\mathcal{A}\cap\mathcal{X}\right)\cup\left(\mathcal{B}\cap\mathcal{\overline{X}}\right)=\emptyset$ . (Suggestion: Sketch a proof along these lines. First, apply the DeMorgan laws until only complements of individual sets appear. Then expand the resulting lefthand side by the distributive law 3 so as to transform it into the union of several terms $\mathcal{T}_{i}$ , each of which is an intersection of several individual sets. Next, if in any $\mathcal{T}_{i}$ neither $\mathcal{X}$ nor $\mathcal{\overline{X}}$ appears, replace $\mathcal{T}_{i}$ by $\mathcal{T}_{i}\cap\left(\mathcal{X}\cup\mathcal{\overline{X}}\right)$ and expand. Finally, group together the terms containing $\mathcal{X}$ and those containing $\mathcal{\overline{X}}$ and apply the distributive law 3.) I'm not asking for a solution. My intuitive understanding is that, for any solution $\mathcal{X},$ we can exclusively group the $\mathcal{T}_{i}$ into those which are disjoint with $\mathcal{X},$ and those which are subsets of $\mathcal{X}.$","I asked a question about this exercise in the past ( Is there a standard way to represent a general set theoretical equation in one variable. ), and don't mean to ""re-ask"".  But I'm unclear as to how I should read the phrase ""only complements of individual sets,"" in Stoll's outline of a proof. Specifically, does it mean that both an individual set and its complement may appear; or does it mean that only the complements of the given constant sets should appear? I believe it means the former, but the wording is a bit nebulous (to me). This is exercise 1-5.7(B) from Stoll, Robert R.. Set Theory and Logic (Dover Books on Mathematics) (Kindle Location 787). Dover Publications. Kindle Edition. Prove that an equation in with righthand member can be reduced to one of the form . (Suggestion: Sketch a proof along these lines. First, apply the DeMorgan laws until only complements of individual sets appear. Then expand the resulting lefthand side by the distributive law 3 so as to transform it into the union of several terms , each of which is an intersection of several individual sets. Next, if in any neither nor appears, replace by and expand. Finally, group together the terms containing and those containing and apply the distributive law 3.) I'm not asking for a solution. My intuitive understanding is that, for any solution we can exclusively group the into those which are disjoint with and those which are subsets of","\mathcal{X} \emptyset \left(\mathcal{A}\cap\mathcal{X}\right)\cup\left(\mathcal{B}\cap\mathcal{\overline{X}}\right)=\emptyset \mathcal{T}_{i} \mathcal{T}_{i} \mathcal{X} \mathcal{\overline{X}} \mathcal{T}_{i} \mathcal{T}_{i}\cap\left(\mathcal{X}\cup\mathcal{\overline{X}}\right) \mathcal{X} \mathcal{\overline{X}} \mathcal{X}, \mathcal{T}_{i} \mathcal{X}, \mathcal{X}.","['elementary-set-theory', 'logic', 'proof-explanation']"
76,Are ordinal numbers produced by the power set axiom?,Are ordinal numbers produced by the power set axiom?,,"I am a nube just getting into mathematics and set theory. I am learning about how we can produce the list of ordinal numbers by purely using the null set, with 0 standing for Ø, 1 standing for {Ø}, 2 standing for {Ø, {Ø}} and so forth. What I am confused about is the operation at play here to produce the larger sets with more elements. It seems to me to be the power set axiom being applied to create a new larger set. But elsewhere I have seen this called the axiom of subsets. Is this the same thing? Or am I confused? Thanks so much :) A","I am a nube just getting into mathematics and set theory. I am learning about how we can produce the list of ordinal numbers by purely using the null set, with 0 standing for Ø, 1 standing for {Ø}, 2 standing for {Ø, {Ø}} and so forth. What I am confused about is the operation at play here to produce the larger sets with more elements. It seems to me to be the power set axiom being applied to create a new larger set. But elsewhere I have seen this called the axiom of subsets. Is this the same thing? Or am I confused? Thanks so much :) A",,['elementary-set-theory']
77,Set theory Let R a equivalence relation on A and suppose that B is a subset A...,Set theory Let R a equivalence relation on A and suppose that B is a subset A...,,"Translation: I'm attempting the following proof, but I don't know which definition to use moving forward; I appreciate the help: Let $R$ be an equivalence relation on $A$ , and suppose that $B\subset A$ . Prove that, for each $x\in B$ , we have $[x]_{R|_B}=[x]_R\cap B$ . Let $x\in[x]_{R|_B}$ . Then $(x,x)\in R|_B\implies x\in B\implies x\in A$ by hypothesis, which implies $(x,x)\in R\wedge x\in B$ . estoy intentando trabajar en la siguiente demostración pero estoy en este punto y no sé que definición utilizar para avanzar, agradezco las ayudas, The following picture shows my attempt.","Translation: I'm attempting the following proof, but I don't know which definition to use moving forward; I appreciate the help: Let be an equivalence relation on , and suppose that . Prove that, for each , we have . Let . Then by hypothesis, which implies . estoy intentando trabajar en la siguiente demostración pero estoy en este punto y no sé que definición utilizar para avanzar, agradezco las ayudas, The following picture shows my attempt.","R A B\subset A x\in B [x]_{R|_B}=[x]_R\cap B x\in[x]_{R|_B} (x,x)\in R|_B\implies x\in B\implies x\in A (x,x)\in R\wedge x\in B","['elementary-set-theory', 'equivalence-relations']"
78,Show that $\cup_{x\in\Omega}\mathcal{F}_x$ is a $\sigma$-algebra,Show that  is a -algebra,\cup_{x\in\Omega}\mathcal{F}_x \sigma,"Let $X$ be an arbitrary set and  let $\Omega$ denote the minimal uncountable well-ordered set. Given $\mathcal{E}\subset \mathcal{P}(X) $ with $\emptyset\in \mathcal{E}$ we define a collection of subsets of $\mathcal{P}(X)$ by transfinite recursion as follows: Define $\mathcal{E}^c:=\{E^c:E\in\mathcal{E}\}$ and $\mathcal{E}_{\sigma}:=\{\cup_{n=1}^{\infty}E_n:(E_n)\subset\mathcal{E}\}$ . Define $1:=\min \Omega$ and set $\mathcal{F}_1:=\mathcal{E}\cup \mathcal{E}^c$ . If $x\in\Omega$ and if $x$ has an immediate predecessor $y$ then we set $\mathcal{F}_x:=(\mathcal{F}_y)_{\sigma}\cup ((\mathcal{F}_y)_{\sigma})^c$ , and if $x$ has no immediate predecessor then we set $\mathcal{F}_x:=\cup_{y<x}\mathcal{F_y}$ . The goal is to show that $\cup_{x\in\Omega}\mathcal{F}_x$ is a $\sigma$ -algebra in $X$ . Am stuck on proving closure under countable unions: Let $(E_n)\subset \cup_{x\in\Omega}\mathcal{F}_x$ . For each $n$ choose $x_n\in\Omega$ such that $E_n\in \mathcal{F}_{x_n}$ (axiom of countable choice). Since the set $\{x_n:n\geq 1\}$ is a countable subset of $\Omega$ , it has an upper bound. Let $x$ denote the smallest upper bound. If $x\neq x_n$ for each $n$ , then $x$ has no immediate predecessor $y<x$ , for otherwise such $y$ would be a strictly smaller upper bound for $\{x_n:n\geq 1\}$ . Hence $\mathcal{F}_x=\cup_{y<x}\mathcal{F_y}\supset \cup_{n\geq 1}\mathcal{F}_{x_n}$ , and since $\Omega$ has no largest element it follows that $\cup_{n\geq 1} E_n \in (\mathcal{F_x})_{\sigma}\subset \mathcal{F_{x+1}} $ , where $x+1$ denotes the immediate sucessor of $x$ in $\Omega$ . But what about the case where $x=x_n$ for some $n$ ? EDIT: I tried to follow Troposhere's approach below. Any feedback is very appreciated.","Let be an arbitrary set and  let denote the minimal uncountable well-ordered set. Given with we define a collection of subsets of by transfinite recursion as follows: Define and . Define and set . If and if has an immediate predecessor then we set , and if has no immediate predecessor then we set . The goal is to show that is a -algebra in . Am stuck on proving closure under countable unions: Let . For each choose such that (axiom of countable choice). Since the set is a countable subset of , it has an upper bound. Let denote the smallest upper bound. If for each , then has no immediate predecessor , for otherwise such would be a strictly smaller upper bound for . Hence , and since has no largest element it follows that , where denotes the immediate sucessor of in . But what about the case where for some ? EDIT: I tried to follow Troposhere's approach below. Any feedback is very appreciated.",X \Omega \mathcal{E}\subset \mathcal{P}(X)  \emptyset\in \mathcal{E} \mathcal{P}(X) \mathcal{E}^c:=\{E^c:E\in\mathcal{E}\} \mathcal{E}_{\sigma}:=\{\cup_{n=1}^{\infty}E_n:(E_n)\subset\mathcal{E}\} 1:=\min \Omega \mathcal{F}_1:=\mathcal{E}\cup \mathcal{E}^c x\in\Omega x y \mathcal{F}_x:=(\mathcal{F}_y)_{\sigma}\cup ((\mathcal{F}_y)_{\sigma})^c x \mathcal{F}_x:=\cup_{y<x}\mathcal{F_y} \cup_{x\in\Omega}\mathcal{F}_x \sigma X (E_n)\subset \cup_{x\in\Omega}\mathcal{F}_x n x_n\in\Omega E_n\in \mathcal{F}_{x_n} \{x_n:n\geq 1\} \Omega x x\neq x_n n x y<x y \{x_n:n\geq 1\} \mathcal{F}_x=\cup_{y<x}\mathcal{F_y}\supset \cup_{n\geq 1}\mathcal{F}_{x_n} \Omega \cup_{n\geq 1} E_n \in (\mathcal{F_x})_{\sigma}\subset \mathcal{F_{x+1}}  x+1 x \Omega x=x_n n,"['real-analysis', 'measure-theory', 'elementary-set-theory', 'well-orders']"
79,Show that $X\times Y$ has cardinality $c$,Show that  has cardinality,X\times Y c,"This is problem 5 from section 1.4. of the book Real Analysis and Probability by R.M. Dudley: Let $X$ be a nonempty set of cardinality less than $c$ ( $c$ is defined as the cardinality of $2^\mathbb{N}$ ), and let $Y$ have cardinality $c$ . Show that $X\times Y$ has cardinality $c$ . Hint : Reduce to the case where $X$ has cardinality $c$ . I proved the reduced case by showing that $2^\mathbb{N}\times 2^\mathbb{N}$ has the same cardinality as $2^\mathbb{N}$ , by considering the sequence $(z_n)$ formed by alternating the terms of two sequences $(x_n)$ and $(y_n)$ . But I can't figure out how to reduce the original problem to this case. Any ideas?","This is problem 5 from section 1.4. of the book Real Analysis and Probability by R.M. Dudley: Let be a nonempty set of cardinality less than ( is defined as the cardinality of ), and let have cardinality . Show that has cardinality . Hint : Reduce to the case where has cardinality . I proved the reduced case by showing that has the same cardinality as , by considering the sequence formed by alternating the terms of two sequences and . But I can't figure out how to reduce the original problem to this case. Any ideas?",X c c 2^\mathbb{N} Y c X\times Y c X c 2^\mathbb{N}\times 2^\mathbb{N} 2^\mathbb{N} (z_n) (x_n) (y_n),"['elementary-set-theory', 'cardinals']"
80,Cardinality of a set of polynomial,Cardinality of a set of polynomial,,"Given a set $A = \{x \in \mathbb{R}: \exists m \in \mathbb{N}, \exists b_0, \ldots, b_m \in \mathbb{Z} \text{ with } b_m \neq 0 \text{ and } b_mx^m + \cdots + b_0 = 0\}$ . Im trying to find cardinality of A. One of the hints given were to write the set as a set of unions to get rid of quantifiers. Although I have no idea what sets would you even take a union of. Another thing that I thought about is that if $m$ is fixed, the by rational root theorem there are $m$ roots of the equation so would that imply that its cardinality is at most $m$ ? What would I have to include in the proof to make it formal since my arguments are just informal observations? Also just to confirm, in the set A, the $m$ is fixed right? EDIT: would the unions would be the union of sets $A_i$ for $i \in \{0,1,\ldots, m\}$ where $A_i = \{x \in \mathbb{R}: i \in \mathbb{N}, b_0, \ldots, b_i \in \mathbb{Z} \text{ with } b_i \neq 0 \text{ and } b_ix^i + \cdots + b_0 = 0\}$ ? The idea being that the unions of $A_i$ will have overlaps so it is at most $m$ .","Given a set . Im trying to find cardinality of A. One of the hints given were to write the set as a set of unions to get rid of quantifiers. Although I have no idea what sets would you even take a union of. Another thing that I thought about is that if is fixed, the by rational root theorem there are roots of the equation so would that imply that its cardinality is at most ? What would I have to include in the proof to make it formal since my arguments are just informal observations? Also just to confirm, in the set A, the is fixed right? EDIT: would the unions would be the union of sets for where ? The idea being that the unions of will have overlaps so it is at most .","A = \{x \in \mathbb{R}: \exists m \in \mathbb{N}, \exists b_0, \ldots, b_m \in \mathbb{Z} \text{ with } b_m \neq 0 \text{ and } b_mx^m + \cdots + b_0 = 0\} m m m m A_i i \in \{0,1,\ldots, m\} A_i = \{x \in \mathbb{R}: i \in \mathbb{N}, b_0, \ldots, b_i \in \mathbb{Z} \text{ with } b_i \neq 0 \text{ and } b_ix^i + \cdots + b_0 = 0\} A_i m",['elementary-set-theory']
81,"Is ""Let A be any set"", A universal or existential quantifier?","Is ""Let A be any set"", A universal or existential quantifier?",,"This is a very basic question but I can't find anything related on the internet. I know that Universal quantifiers are ""For all x"" while existential quantifiers are ""For some"" However, the statement for ""Let A be any set"" is confusing but from what I understand. It's a universal quantifier. However, if someone can clarify then Thank you!","This is a very basic question but I can't find anything related on the internet. I know that Universal quantifiers are ""For all x"" while existential quantifiers are ""For some"" However, the statement for ""Let A be any set"" is confusing but from what I understand. It's a universal quantifier. However, if someone can clarify then Thank you!",,['elementary-set-theory']
82,Proving both defining properties of a distibutive lattice are equivalent,Proving both defining properties of a distibutive lattice are equivalent,,"In class, we've defined distributive lattice to be a lattice L which verifies the following properties: $$(1) \space \space a \wedge (b \vee c) = (a \wedge b) \vee ( a \wedge c)$$ $$(2) \space \space a \vee (b \wedge c) = (a \vee b) \wedge ( a \vee c) \quad \forall a,b,c \in L$$ But were asked to show that $(1) \Leftrightarrow (2)$ . I tried to prove $(1)\Rightarrow(2)$ as follows: $$ (a \vee b) \wedge ( a \vee c) =((a \vee b)\wedge a) \vee ((a \vee b)\wedge c)=(a \vee (a \wedge b)) \vee((a \wedge c)\vee (b \wedge c))=((a\wedge b)\vee (a\wedge c))\vee (a \vee (b\wedge c))=(a \wedge (b \vee c))\vee(a\vee(b\wedge c)) $$ On the third equal sign, I'm using only commutativity and associativity. Then, I regroup the first term using (1). I'm not implying $a\vee(a\wedge b)$ = $a\wedge(b\vee c)$ but rather $(a\wedge b)\vee(a\wedge c)= a\wedge(b\vee c)$ Now, because $a \wedge (b \vee c)\leq a $ and $a\vee(b\wedge c) \geq a$ the expression above equals $a\vee(b\wedge c)$ just as we wanted. I'm not entirely convinced this reasoning is okay, though, in particular the final bit where I compare both terms at either sides of the join operator. I would appreciate it if anyone could help me clarify if this is correct. Thanks in advance!","In class, we've defined distributive lattice to be a lattice L which verifies the following properties: But were asked to show that . I tried to prove as follows: On the third equal sign, I'm using only commutativity and associativity. Then, I regroup the first term using (1). I'm not implying = but rather Now, because and the expression above equals just as we wanted. I'm not entirely convinced this reasoning is okay, though, in particular the final bit where I compare both terms at either sides of the join operator. I would appreciate it if anyone could help me clarify if this is correct. Thanks in advance!","(1) \space \space a \wedge (b \vee c) = (a \wedge b) \vee ( a \wedge c) (2) \space \space a \vee (b \wedge c) = (a \vee b) \wedge ( a \vee c) \quad \forall a,b,c \in L (1) \Leftrightarrow (2) (1)\Rightarrow(2)  (a \vee b) \wedge ( a \vee c) =((a \vee b)\wedge a) \vee ((a \vee b)\wedge c)=(a \vee (a \wedge b)) \vee((a \wedge c)\vee (b \wedge c))=((a\wedge b)\vee (a\wedge c))\vee (a \vee (b\wedge c))=(a \wedge (b \vee c))\vee(a\vee(b\wedge c))  a\vee(a\wedge b) a\wedge(b\vee c) (a\wedge b)\vee(a\wedge c)= a\wedge(b\vee c) a \wedge (b \vee c)\leq a  a\vee(b\wedge c) \geq a a\vee(b\wedge c)","['elementary-set-theory', 'solution-verification', 'proof-writing', 'lattice-orders']"
83,"Given a set $A$, define relation $R$ on $\mathcal{P}(A)$ by $\{(U,V) \in \mathcal{P}(A) \times \mathcal{P}(A) \colon \dots \}$. Is $R$ transitive?","Given a set , define relation  on  by . Is  transitive?","A R \mathcal{P}(A) \{(U,V) \in \mathcal{P}(A) \times \mathcal{P}(A) \colon \dots \} R","Given a set $A$ , define relation $R$ on $\mathcal{P}(A)$ by $$R = \{(U,V) \in \mathcal{P}(A) \times \mathcal{P}(A) \colon (U \cap V \neq \emptyset) \lor (U \cup V = \emptyset)\}.$$ I want to check if $R$ is a transitive relation. My scratch work so far: Let $A = \{a, b, c, d, e\}$ then $\mathcal{P}(A)=\{\{\emptyset\}, \{a\},\{b\},\{c\},\{d\},\{e\},\dots,\{a,b,c,d,e\}\}$ . So I know I want to prove that $URV \land VRW \Longrightarrow VRW$ for transitivity. If I let $(U,V)=(\{a\},\{a,b\})$ then $(U \cap V) = \{a\} \neq \emptyset$ , so that $URV$ , $(V,W)=(\{a,b\},\{b\})$ then $(V \cap W) = \{b\} \neq \emptyset$ , so that $VRW$ Then $(U \cap V)\cap(V \cap W) = \emptyset$ right? Which means $URV∧VRW⟹V\not RW$ .  Am I missing a key concept? Is this enough to prove it's not transitive? I know there exists subsets I can pull to show transitivity but if I show one isn't transitive, it should show the overall relation isn't transitive right? Any feedback on this is appreciated. Thanks.","Given a set , define relation on by I want to check if is a transitive relation. My scratch work so far: Let then . So I know I want to prove that for transitivity. If I let then , so that , then , so that Then right? Which means .  Am I missing a key concept? Is this enough to prove it's not transitive? I know there exists subsets I can pull to show transitivity but if I show one isn't transitive, it should show the overall relation isn't transitive right? Any feedback on this is appreciated. Thanks.","A R \mathcal{P}(A) R = \{(U,V) \in \mathcal{P}(A) \times \mathcal{P}(A) \colon (U \cap V \neq \emptyset) \lor (U \cup V = \emptyset)\}. R A = \{a, b, c, d, e\} \mathcal{P}(A)=\{\{\emptyset\}, \{a\},\{b\},\{c\},\{d\},\{e\},\dots,\{a,b,c,d,e\}\} URV \land VRW \Longrightarrow VRW (U,V)=(\{a\},\{a,b\}) (U \cap V) = \{a\} \neq \emptyset URV (V,W)=(\{a,b\},\{b\}) (V \cap W) = \{b\} \neq \emptyset VRW (U \cap V)\cap(V \cap W) = \emptyset URV∧VRW⟹V\not RW","['elementary-set-theory', 'relations']"
84,How many subsets of S contains A?,How many subsets of S contains A?,,"Given a set $S$ of size $n$ and $A \subseteq S$ of size $k$ , how many subsets of $S$ contain $A$ ? I think it should be $2^{n} - 2^{n-k}$ ? Please tell is it correct or not ?","Given a set of size and of size , how many subsets of contain ? I think it should be ? Please tell is it correct or not ?",S n A \subseteq S k S A 2^{n} - 2^{n-k},['elementary-set-theory']
85,Proving a condition for when 2 bases are linearly independent,Proving a condition for when 2 bases are linearly independent,,I'm currently attempting a problem in a linear algebra textbook. In the solution sheet this statement is said to be a necessary and sufficient condition for the union of 2 bases to be a basis but i have no clue how to prove it. $$B_1 \cup B_2 \text{ is linearly independent} \iff span(B_1 \cap B_2) = span(B_1) \cap span(B_2)$$ Where $B_1$ and $B_2$ are bases I think maybe in the $\Longrightarrow $ direction the union of $B_1$ and $B_2$ being linearly independent implies $span(B_1) \cap span(B_2) \subseteq span(B_1 \cap B_2)$ ? but i'm not sure where to go from here. I don't know where to start in the $\Longleftarrow$ direction.,I'm currently attempting a problem in a linear algebra textbook. In the solution sheet this statement is said to be a necessary and sufficient condition for the union of 2 bases to be a basis but i have no clue how to prove it. Where and are bases I think maybe in the direction the union of and being linearly independent implies ? but i'm not sure where to go from here. I don't know where to start in the direction.,B_1 \cup B_2 \text{ is linearly independent} \iff span(B_1 \cap B_2) = span(B_1) \cap span(B_2) B_1 B_2 \Longrightarrow  B_1 B_2 span(B_1) \cap span(B_2) \subseteq span(B_1 \cap B_2) \Longleftarrow,"['linear-algebra', 'elementary-set-theory', 'proof-writing']"
86,Exercise 8.5.19 Tao's Analysis 1 (Well-Ordering Theorem),Exercise 8.5.19 Tao's Analysis 1 (Well-Ordering Theorem),,"I am having some trouble with the following problem from Terence Tao's Analysis 1 (Third Edition) Let $X$ be a set, and let $\Omega$ be the space of all pairs $(Y,\leq)$ , where $Y$ is a subset of $X$ and $\leq$ is a well-ordering of $Y$ . If $(Y,\leq)$ and $(Y',\leq ')$ are elements of $\Omega$ , we say that $(Y,\leq)$ is an initial segment of $(Y',\leq ')$ if there exists an $x\in Y'$ such that $Y=\{y\in Y': y<'x\}$ (so in particular $Y\subset Y'$ ), and for any $y,y'\in Y$ , $y\leq y'$ iff $y\leq ' y'$ . Define a relation $\preceq$ on $\Omega$ by defining $(Y,\leq)\preceq (Y',\leq ')$ if either $(Y,\leq)=(Y',\leq ')$ , or if $(Y,\leq)$ is an initial segment of $(Y',\leq ')$ . I've shown that $\preceq$ is a partial ordering on $\Omega$ . Now I am trying to use Zorn's lemma to show that there is a maximal element which will then show that the Well-Ordering Theorem is true. This is what I have so far Let $Z$ be a totally ordered subset of $\Omega$ . We define the set $Y=\bigcup_{(S,\leq_S)\in Z}S$ and a relation on Y $\leq_Y$ defined as follows: $y\leq_Yy'$ if and only if there exists a $(S,\leq_s) \in Z$ such that $y,y' \in S$ and $y \leq_s y'$ . It is not hard to verify that this is a partial ordering on $Y$ and in fact it is a total ordering on $Y$ . I am having hard time figuring out how to show that this is a well-ordering on $Y$ . I have tried to show that if $W$ is a non-empty set of $Y$ then there is a $(S,\leq_S)\in Z$ such that for all $w \in W$ we have $w \in S$ so in particular there is a $w \in W$ such that $w \leq_s w'$ for all $w' \in W$ and this would imply that $W$ has a minimal element. However I am struggling to make this idea work as well. I will be very grateful for any help that is offered. In particular how could I go about showing that $\leq_Y$ is a well-ordering on $Y$ (if it is at all)?","I am having some trouble with the following problem from Terence Tao's Analysis 1 (Third Edition) Let be a set, and let be the space of all pairs , where is a subset of and is a well-ordering of . If and are elements of , we say that is an initial segment of if there exists an such that (so in particular ), and for any , iff . Define a relation on by defining if either , or if is an initial segment of . I've shown that is a partial ordering on . Now I am trying to use Zorn's lemma to show that there is a maximal element which will then show that the Well-Ordering Theorem is true. This is what I have so far Let be a totally ordered subset of . We define the set and a relation on Y defined as follows: if and only if there exists a such that and . It is not hard to verify that this is a partial ordering on and in fact it is a total ordering on . I am having hard time figuring out how to show that this is a well-ordering on . I have tried to show that if is a non-empty set of then there is a such that for all we have so in particular there is a such that for all and this would imply that has a minimal element. However I am struggling to make this idea work as well. I will be very grateful for any help that is offered. In particular how could I go about showing that is a well-ordering on (if it is at all)?","X \Omega (Y,\leq) Y X \leq Y (Y,\leq) (Y',\leq ') \Omega (Y,\leq) (Y',\leq ') x\in Y' Y=\{y\in Y': y<'x\} Y\subset Y' y,y'\in Y y\leq y' y\leq ' y' \preceq \Omega (Y,\leq)\preceq (Y',\leq ') (Y,\leq)=(Y',\leq ') (Y,\leq) (Y',\leq ') \preceq \Omega Z \Omega Y=\bigcup_{(S,\leq_S)\in Z}S \leq_Y y\leq_Yy' (S,\leq_s) \in Z y,y' \in S y \leq_s y' Y Y Y W Y (S,\leq_S)\in Z w \in W w \in S w \in W w \leq_s w' w' \in W W \leq_Y Y","['real-analysis', 'elementary-set-theory', 'set-theory', 'order-theory']"
87,Prove that the union is the maximum of the indicator function,Prove that the union is the maximum of the indicator function,,"Here is the problem: Prove that $I_{A_1\cup A_2 \cup\dots\cup A_n}(\omega)=\text{max}\{I_{A_2}(\omega),I_{A_1}(\omega),\dots,I_{A_n}(\omega)\}$ for any sets $A_1,A_2,\dots,A_n$ Here is what I know: $$I_{A_1\cup A_2 \cup\dots\cup A_n}(\omega)\begin{gathered}=\begin{cases} 1\quad\text{if}\quad\omega\in A_1\cup A_2 \cup\dots\cup A_n \\ 0\quad\text{if}\quad\omega\notin A_1\cup A_2 \cup\dots\cup A_n \end{cases}\\=\begin{cases} 1\quad\text{if}\quad\omega~\text{belongs in one of the}~A_n's \\ 0\quad\text{if}\quad\omega~\text{belongs in none of the}~A_n's\end{cases}\\=\begin{cases} 1\quad\text{if}\quad I_{A_n}(\omega)=1~\text{for at least one}~A_n \\ 0\quad\text{if}\quad I_{A_n}(\omega)=0~\text{for all}~A_n's\end{cases}\end{gathered}$$ I don't know where to go from here.",Here is the problem: Prove that for any sets Here is what I know: I don't know where to go from here.,"I_{A_1\cup A_2 \cup\dots\cup A_n}(\omega)=\text{max}\{I_{A_2}(\omega),I_{A_1}(\omega),\dots,I_{A_n}(\omega)\} A_1,A_2,\dots,A_n I_{A_1\cup A_2 \cup\dots\cup A_n}(\omega)\begin{gathered}=\begin{cases} 1\quad\text{if}\quad\omega\in A_1\cup A_2 \cup\dots\cup A_n
\\ 0\quad\text{if}\quad\omega\notin A_1\cup A_2 \cup\dots\cup A_n \end{cases}\\=\begin{cases} 1\quad\text{if}\quad\omega~\text{belongs in one of the}~A_n's
\\ 0\quad\text{if}\quad\omega~\text{belongs in none of the}~A_n's\end{cases}\\=\begin{cases} 1\quad\text{if}\quad I_{A_n}(\omega)=1~\text{for at least one}~A_n
\\ 0\quad\text{if}\quad I_{A_n}(\omega)=0~\text{for all}~A_n's\end{cases}\end{gathered}",['probability']
88,Why does an empty intersection (for families) not make sense? [duplicate],Why does an empty intersection (for families) not make sense? [duplicate],,"This question already has answers here : When would the intersection of the empty set mean anything? (1 answer) Unary intersection of the empty set (3 answers) intersection of the empty set and vacuous truth (3 answers) Closed 3 years ago . In Halmos' Naive set theory, on p. 35, he writes An empty union makes sense (and is empty), but an empty intersection does not make sense. Suppose my index set is $I = \{1, 2\}$ and my indexed sets are defined as $A_i \equiv \{-i, i\}$ . Then $A_1 = \{-1,1\}$ , $A_2 = \{-2, 2\}$ , $\bigcup A_i = \{-2, -1, 1, 2\}$ and $\bigcap A_i = \emptyset$ . I don't see why that doesn't ""make sense"".","This question already has answers here : When would the intersection of the empty set mean anything? (1 answer) Unary intersection of the empty set (3 answers) intersection of the empty set and vacuous truth (3 answers) Closed 3 years ago . In Halmos' Naive set theory, on p. 35, he writes An empty union makes sense (and is empty), but an empty intersection does not make sense. Suppose my index set is and my indexed sets are defined as . Then , , and . I don't see why that doesn't ""make sense"".","I = \{1, 2\} A_i \equiv \{-i, i\} A_1 = \{-1,1\} A_2 = \{-2, 2\} \bigcup A_i = \{-2, -1, 1, 2\} \bigcap A_i = \emptyset",['elementary-set-theory']
89,"prove that if $f$ is decreasing and bijective, then $f$ and $f^{-1}$ are strictly decreasing.","prove that if  is decreasing and bijective, then  and  are strictly decreasing.",f f f^{-1},"I have done the first part proving f is strictly decreasing, but it is so confusing to prove the inverse function is also strictly decreasing. This is what I have so far, I am not sure if it's correct or not because of so many inequality signs. Here's my proof. Let $A, B$ the domain and codomain of f. We need to prove that for any $x, y \in A$ and $u,v \in B$ , if $x < y$ and $u < v$ , we have $f(x) >  f(y)$ and $f^{-1}(u) > f^{-1}(v)$ . Assume $x < y$ . Since f is decreasing, we have $f(x) \ge f(y)$ . Since $x \neq y$ and f is bijective, $f(x) \neq f(y)$ , we must have $f(x) > f(y)$ . Next, we need to prove that $f^{-1}$ is strictly decreasing, so assume $u < v$ . set $a = f^{-1}(u)$ and $b = f^{-1}(v)$ , so we claim that $a > b$ . If not, then $a \ge b$ . Since f is decreasing, we have $u = f(a) \ge f(b) = v$ . This is a contradiction since by our choice, $u < v$ . Hence $f^{-1}$ is decreasing. I am not sure about the part which is $u = f(a) \ge f(b) = v$ is right or not. Because we have $a > b$ , $f^{-1}(u) \ge f^{-1}(v)$ which is $a>b$ . Then, we take inverse on both side which becomes to $u \ge v$ . Am I understanding the definition of decreasing function right?","I have done the first part proving f is strictly decreasing, but it is so confusing to prove the inverse function is also strictly decreasing. This is what I have so far, I am not sure if it's correct or not because of so many inequality signs. Here's my proof. Let the domain and codomain of f. We need to prove that for any and , if and , we have and . Assume . Since f is decreasing, we have . Since and f is bijective, , we must have . Next, we need to prove that is strictly decreasing, so assume . set and , so we claim that . If not, then . Since f is decreasing, we have . This is a contradiction since by our choice, . Hence is decreasing. I am not sure about the part which is is right or not. Because we have , which is . Then, we take inverse on both side which becomes to . Am I understanding the definition of decreasing function right?","A, B x, y \in A u,v \in B x < y u < v f(x) >  f(y) f^{-1}(u) > f^{-1}(v) x < y f(x) \ge f(y) x \neq y f(x) \neq f(y) f(x) > f(y) f^{-1} u < v a = f^{-1}(u) b = f^{-1}(v) a > b a \ge b u = f(a) \ge f(b) = v u < v f^{-1} u = f(a) \ge f(b) = v a > b f^{-1}(u) \ge f^{-1}(v) a>b u \ge v","['elementary-set-theory', 'solution-verification']"
90,Set Inequality Proof Check,Set Inequality Proof Check,,"Looking at a problem on an intro. analysis practice exam: Prove that $$ U\setminus(A\setminus B)\ \;=\; (U\setminus A)\setminus B $$ I don't think this is true, here is the counterexample that I cooked up: $$ U\;=\;\{1,2,3,\dots, 9, 10\}$$ $$ A\;=\;\{2,4,6,8\} $$ $$ B\;=\; \{2,4,5,7\} $$ Considering $u=2$ , we have $u\in \{1,2,3,4,5,7,9,10\}=U\setminus(A\setminus B)$ , yet $u\notin \{1,3,9,10\}=(U\setminus A)\setminus B$ . Just looking for a quick verification, seeing as the awkward scenario here is an undergraduate is claiming that a tenured professor is incorrect (maybe he did it on purpose?).","Looking at a problem on an intro. analysis practice exam: Prove that I don't think this is true, here is the counterexample that I cooked up: Considering , we have , yet . Just looking for a quick verification, seeing as the awkward scenario here is an undergraduate is claiming that a tenured professor is incorrect (maybe he did it on purpose?)."," U\setminus(A\setminus B)\ \;=\; (U\setminus A)\setminus B   U\;=\;\{1,2,3,\dots, 9, 10\}  A\;=\;\{2,4,6,8\}   B\;=\; \{2,4,5,7\}  u=2 u\in \{1,2,3,4,5,7,9,10\}=U\setminus(A\setminus B) u\notin \{1,3,9,10\}=(U\setminus A)\setminus B","['real-analysis', 'elementary-set-theory', 'solution-verification']"
91,A monotone sequence of sets is convergent,A monotone sequence of sets is convergent,,"I'm having trouble understanding the following part of a proof from Leadbetter's measure and probability book: THEOREM 1.4.2: A monotone increasing (decreasing) sequence { $E_n$ } is convergent and lim $E_n=\bigcup_{n=1}^∞ E_n (\bigcap_{n=1}^∞ E_n)$ . Proof: $$\bar{lim}E_n=\bigcap_{n=1}^∞ (\bigcup_{m=n}^∞ E_m )=\bigcap_{n=1}^∞ (\bigcup_{m=1}^∞ E_m )$$ But $\bigcup_{m=1}^∞ E_m$ does not depend on n and thus, $$\bar{lim}E_n=\bigcup_{m=1}^∞ E_m $$ In particular, I don't understand the logic behind moving from $\bar{lim}E_n=\bigcap_{n=1}^∞ (\bigcup_{m=1}^∞ E_m )$ to $\bar{lim}E_n=\bigcup_{m=1}^∞ E_m $ . I understand that $\bigcap_{n=1}^∞ (\bigcup_{m=1}^∞ E_m )$ does not depend on n, but I don't see how removing the intersection wouldn't also change the union of all members of { $E_n$ }. Since a monotone increasing sequence of sequences contains more elements per $E_n$ as n increases, wouldn't the union of all subsequences of { $E_n$ } also be increasing, whereas the intersection wouldn't?","I'm having trouble understanding the following part of a proof from Leadbetter's measure and probability book: THEOREM 1.4.2: A monotone increasing (decreasing) sequence { } is convergent and lim . Proof: But does not depend on n and thus, In particular, I don't understand the logic behind moving from to . I understand that does not depend on n, but I don't see how removing the intersection wouldn't also change the union of all members of { }. Since a monotone increasing sequence of sequences contains more elements per as n increases, wouldn't the union of all subsequences of { } also be increasing, whereas the intersection wouldn't?",E_n E_n=\bigcup_{n=1}^∞ E_n (\bigcap_{n=1}^∞ E_n) \bar{lim}E_n=\bigcap_{n=1}^∞ (\bigcup_{m=n}^∞ E_m )=\bigcap_{n=1}^∞ (\bigcup_{m=1}^∞ E_m ) \bigcup_{m=1}^∞ E_m \bar{lim}E_n=\bigcup_{m=1}^∞ E_m  \bar{lim}E_n=\bigcap_{n=1}^∞ (\bigcup_{m=1}^∞ E_m ) \bar{lim}E_n=\bigcup_{m=1}^∞ E_m  \bigcap_{n=1}^∞ (\bigcup_{m=1}^∞ E_m ) E_n E_n E_n,"['probability-theory', 'measure-theory', 'elementary-set-theory']"
92,Set theory task,Set theory task,,"Let F be a set of sets. We say a set is n-pretty  (it's writen in my text book, I don't know the exact name)(n is fixed nat. number) if $$\forall X (X \in F \iff \forall Y (Y \subseteq X \land |Y| <= n \implies Y \in F)$$ . And we say that a set is finite-pretty if: $$\forall X (X \in F \iff \forall Y (Fin(Y) \land Y \subseteq X \implies Y \in F)$$ So the task is to find if every n-pretty set is finite-pretty and if every finite-pretty set is n-pretty . I think that every finite-pretty set is n-pretty. Since it's true for every finite set, it will be true for every set with cardinality n. But I can't seem to  prove it in terms of set theory . And what about the other direction ? Any tips?","Let F be a set of sets. We say a set is n-pretty  (it's writen in my text book, I don't know the exact name)(n is fixed nat. number) if . And we say that a set is finite-pretty if: So the task is to find if every n-pretty set is finite-pretty and if every finite-pretty set is n-pretty . I think that every finite-pretty set is n-pretty. Since it's true for every finite set, it will be true for every set with cardinality n. But I can't seem to  prove it in terms of set theory . And what about the other direction ? Any tips?",\forall X (X \in F \iff \forall Y (Y \subseteq X \land |Y| <= n \implies Y \in F) \forall X (X \in F \iff \forall Y (Fin(Y) \land Y \subseteq X \implies Y \in F),['elementary-set-theory']
93,"denumerable set: If A, B are denumerable sets, AXB is a denumberable set. Prove ZXN, ZXZ and QXQ are also denumerable sets.","denumerable set: If A, B are denumerable sets, AXB is a denumberable set. Prove ZXN, ZXZ and QXQ are also denumerable sets.",,"So I prove $\mathbb{Z}\times \mathbb{N}\sim\mathbb{N}$ part: $f:\mathbb{Z}\times \mathbb{N} \to \mathbb{N}\times\mathbb{N}$ such that $$f:(z,n)\mapsto\begin{cases} (2z,n), & z>0 \\ (2(-z)+1,n), & z\leq 0\end{cases} $$ $f: \text{bijective},  \implies (z_1, n_1) \neq (z_2, n_2) \implies f(z_1, n_1) \neq f(z_2, n_2) \implies f: \text{injective}$ . $f(\mathbb{Z}\times \mathbb{N}) = \mathbb{N}\times \mathbb{N} \implies \mathbb{Z}\times \mathbb{N}\sim \mathbb{N}\times \mathbb{N} \wedge \mathbb{N} \times \mathbb{N} \sim \mathbb{N}$ i am not sure how to prove that $\mathbb{Z}\times \mathbb{Z}$ and $\mathbb{Q}\times \mathbb{Q}$ are denumerable sets. Thank you so much for your help.",So I prove part: such that . i am not sure how to prove that and are denumerable sets. Thank you so much for your help.,"\mathbb{Z}\times \mathbb{N}\sim\mathbb{N} f:\mathbb{Z}\times \mathbb{N} \to \mathbb{N}\times\mathbb{N} f:(z,n)\mapsto\begin{cases} (2z,n), & z>0 \\ (2(-z)+1,n), & z\leq 0\end{cases}  f: \text{bijective}, 
\implies (z_1, n_1) \neq (z_2, n_2)
\implies f(z_1, n_1) \neq f(z_2, n_2)
\implies f: \text{injective} f(\mathbb{Z}\times \mathbb{N}) = \mathbb{N}\times \mathbb{N}
\implies \mathbb{Z}\times \mathbb{N}\sim \mathbb{N}\times \mathbb{N} \wedge \mathbb{N} \times \mathbb{N} \sim \mathbb{N} \mathbb{Z}\times \mathbb{Z} \mathbb{Q}\times \mathbb{Q}",['elementary-set-theory']
94,Is there a way to prove that $A \setminus C = (A \setminus (B \cup C)) \cup ((A \cap B) \setminus C)$?,Is there a way to prove that ?,A \setminus C = (A \setminus (B \cup C)) \cup ((A \cap B) \setminus C),"Drawing out the Venn Diagrams I know this is true. $(A \setminus (B \cup C))$ is just all the values that are solely in A. $((A \cap B) \setminus C)$ is just all the values in both A and B but not in C. And taking the union of these two leads us to the values that are either only in A or in only A and B (but not C). I am unsure how to rigorously prove this, however. Would starting off by letting $x \in (A \setminus (B \cup C))$ be a good start? Venn Diagram","Drawing out the Venn Diagrams I know this is true. is just all the values that are solely in A. is just all the values in both A and B but not in C. And taking the union of these two leads us to the values that are either only in A or in only A and B (but not C). I am unsure how to rigorously prove this, however. Would starting off by letting be a good start? Venn Diagram",(A \setminus (B \cup C)) ((A \cap B) \setminus C) x \in (A \setminus (B \cup C)),['elementary-set-theory']
95,Let $X$ and $Y$ be finite sets. Then the set $Y^X$ is finite and $\#(Y^X) = (\#Y)^{\#X}$.,Let  and  be finite sets. Then the set  is finite and .,X Y Y^X \#(Y^X) = (\#Y)^{\#X},"Let $X$ and $Y$ be finite sets. Then the set $Y^X$ is finite and $\#(Y^X) = (\#Y)^{\#X}$ . I can see how to do it combinatorially. Let $y \in Y$ . There are $\#(X)$ choices for such y to come from x, therefore we have $\#Y^{\#X}$ choices. I am not sure how to do it bijectively.","Let and be finite sets. Then the set is finite and . I can see how to do it combinatorially. Let . There are choices for such y to come from x, therefore we have choices. I am not sure how to do it bijectively.",X Y Y^X \#(Y^X) = (\#Y)^{\#X} y \in Y \#(X) \#Y^{\#X},"['elementary-set-theory', 'self-learning']"
96,"Why is $A ∪ B$ called ""A or B"" when $A ∪ B$ means all elements in $A$, $B$ and their intersection?","Why is  called ""A or B"" when  means all elements in ,  and their intersection?",A ∪ B A ∪ B A B,"Definition: $A ∪ B$ is the set of elements that is contained in either $A$ or $B$ , or in both. My question: why is $A ∪ B$ called ""A or B"" when $A ∪ B$ is literally everything that is in $A$ , $B$ and their intersection. For example, a Venn diagram of $A ∪ B$ is having both circles A and B shaded in: $A$ , $B$ , and $A ∩ B$ . However, my confusion is that I interpret the definition above as selecting only one of the following, since it says ""or"": $A = A ∩ B^{c}$ $B = A^{c} ∩ B$ ""in both"" = $A ∩ B$ It is clear that if I combine all three subsets above, then I will have $A ∪ B$ . But the definition says ""or"" which makes me think I am selecting strictly one of the three possible subsets above. So why is $A ∪ B$ called ""A or B"" rather than ""A,B, A and B""","Definition: is the set of elements that is contained in either or , or in both. My question: why is called ""A or B"" when is literally everything that is in , and their intersection. For example, a Venn diagram of is having both circles A and B shaded in: , , and . However, my confusion is that I interpret the definition above as selecting only one of the following, since it says ""or"": ""in both"" = It is clear that if I combine all three subsets above, then I will have . But the definition says ""or"" which makes me think I am selecting strictly one of the three possible subsets above. So why is called ""A or B"" rather than ""A,B, A and B""",A ∪ B A B A ∪ B A ∪ B A B A ∪ B A B A ∩ B A = A ∩ B^{c} B = A^{c} ∩ B A ∩ B A ∪ B A ∪ B,['elementary-set-theory']
97,Bijection between a set of injections and a union of bijection,Bijection between a set of injections and a union of bijection,,"Consider $A$ a set with $n$ elements and $k\leq n$ . Show that $$ \phi:\left\{  f:\left\{  1,2,\ldots,k\right\}  \rightarrow A\mid f\text{ injective}\right\}  \rightarrow {\bigsqcup\limits_{B\subset A,card(B)=k}} \left\{  g:\left\{  1,2,\ldots,k\right\}  \rightarrow B\mid g\text{ bijective}\right\} $$ by constructing an explicit bijection. By generalizing the construction above, show that $$ \Phi:\left\{  f:A\rightarrow C\mid f\text{ injective}\right\}  \rightarrow {\bigsqcup\limits_{B\subset C.card(C)=n}} \left\{  g:B\rightarrow C\mid g\text{ bijective}\right\}  . $$ I attempted to start from the observation that every injective function $f$ has an image $\operatorname{Im}f$ as subset of $A$ with exactly $k$ elements. Reciprocally every subset of $A$ with $k$ elements is the image of some injection. But there are $k!$ injections that maps a fixed set $C$ into a subset of $A$ with $k$ elements. Now, every $$ f:\left\{  1,\ldots,k\right\}  \rightarrow A $$ gives us a bijection $g:\left\{ 1,\ldots,k\right\}  \rightarrow B,B\subset A$ and $card(B)=k$ . From this point, I don't know how to move forward. How can I find an explicit bijection?","Consider a set with elements and . Show that by constructing an explicit bijection. By generalizing the construction above, show that I attempted to start from the observation that every injective function has an image as subset of with exactly elements. Reciprocally every subset of with elements is the image of some injection. But there are injections that maps a fixed set into a subset of with elements. Now, every gives us a bijection and . From this point, I don't know how to move forward. How can I find an explicit bijection?","A n k\leq n 
\phi:\left\{  f:\left\{  1,2,\ldots,k\right\}  \rightarrow A\mid f\text{
injective}\right\}  \rightarrow
{\bigsqcup\limits_{B\subset A,card(B)=k}}
\left\{  g:\left\{  1,2,\ldots,k\right\}  \rightarrow B\mid g\text{
bijective}\right\}
 
\Phi:\left\{  f:A\rightarrow C\mid f\text{ injective}\right\}  \rightarrow
{\bigsqcup\limits_{B\subset C.card(C)=n}}
\left\{  g:B\rightarrow C\mid g\text{ bijective}\right\}  .
 f \operatorname{Im}f A k A k k! C A k 
f:\left\{  1,\ldots,k\right\}  \rightarrow A
 g:\left\{ 1,\ldots,k\right\}  \rightarrow B,B\subset A card(B)=k",['elementary-set-theory']
98,"Let $A$ be a set and $R,S$ are relations on $A$. Then....",Let  be a set and  are relations on . Then....,"A R,S A","Let $A$ be a set and $R,S$ are relations on $A$ . Define the relation $R+S$ on $A$ as $$R+S = (R-S)\cup(S-R)$$ Now show that If $A$ is countable then so does $R+S$ Give and example of a set $A$ that is uncountable but $R+S$ is countable. Prove or disprove: If $R$ and $S$ are partial orders on A then so does $R+S$ For the first part, I am thinking that a relation gives us subset of the set on which it is defined, which is in our case $A$ so if $A$ is a countable set then its subset is countable as well. For the second part, Lets say $A=\mathbb{R}$ relation $S$ gives us rational numbers (or its subset) and $R$ gives us Natural numbers (or its subset) then their symmetric difference which is $R+S$ becomes a countable set however $\mathbb{R}$ is uncountable. For third part, I am thinking of relations $R=S=\{(a,a)|a\in \mathbb{Z} \}$ which holds both reflexive and transitive property but I am not sure about anti symmetry. Also this is just an example. How can we prove (if it is right) or disprove (Give counter example) Please help","Let be a set and are relations on . Define the relation on as Now show that If is countable then so does Give and example of a set that is uncountable but is countable. Prove or disprove: If and are partial orders on A then so does For the first part, I am thinking that a relation gives us subset of the set on which it is defined, which is in our case so if is a countable set then its subset is countable as well. For the second part, Lets say relation gives us rational numbers (or its subset) and gives us Natural numbers (or its subset) then their symmetric difference which is becomes a countable set however is uncountable. For third part, I am thinking of relations which holds both reflexive and transitive property but I am not sure about anti symmetry. Also this is just an example. How can we prove (if it is right) or disprove (Give counter example) Please help","A R,S A R+S A R+S = (R-S)\cup(S-R) A R+S A R+S R S R+S A A A=\mathbb{R} S R R+S \mathbb{R} R=S=\{(a,a)|a\in \mathbb{Z} \}","['abstract-algebra', 'elementary-set-theory', 'relations']"
99,Can infinite unions in some sense be handled like limits?,Can infinite unions in some sense be handled like limits?,,"I'm stuck on a question regarding sets that are covered by an infinite union of sets. If a set $S$ is a subset of an infinite union of sets, $$S\subset\bigcup_{k=1}^{\infty}{U_k}$$ is it then correct to say that if $x_0\in S$ then $\exists N\in \mathbb{N}$ such that: $$x_0\in\bigcup_{k=1}^{N}{U_k}$$ similar to what we would say if a limit exists?","I'm stuck on a question regarding sets that are covered by an infinite union of sets. If a set is a subset of an infinite union of sets, is it then correct to say that if then such that: similar to what we would say if a limit exists?",S S\subset\bigcup_{k=1}^{\infty}{U_k} x_0\in S \exists N\in \mathbb{N} x_0\in\bigcup_{k=1}^{N}{U_k},['elementary-set-theory']
